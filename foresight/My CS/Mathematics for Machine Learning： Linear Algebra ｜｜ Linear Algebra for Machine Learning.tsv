start	end	text
0	6040	Okay, so welcome to the first lecture on the vectors course. This is the basics, vectors
6040	12560	versus scalars, vector notation, addition and scaling, and properties. Alright, so begin
12560	19040	at the beginning. Let's list some scalar quantities. Think about mass, duration, length, temperature,
19040	24200	charge. These physical quantities are all well described with a single number. Really
24200	29200	they just have a magnitude, although some of them may go negative, so it's a magnitude
29400	34120	and a sign. But still, just a simple number is adequate to describe these things. How
34120	38680	about vector quantities? What's different about vector quantities? Well, think about
38680	44400	these things, force, velocity, and therefore acceleration, or momentum. These things also
44400	52200	have a strength or a magnitude. However, so let's put that down, they have a magnitude.
52200	58360	However, they also have a direction. More than just a sign, they have a full on direction
58360	62860	in three-dimensional space. So it's not enough to know that a force is three Newtons. I want
62860	67320	to know in which direction is that force applied. And that then is the difference between a
67320	72400	vector and a scalar quantity. We're going to think about how we manipulate them. Alright,
72400	79120	so first off, the notation that we're going to use when we talk about our vectors. What
79120	85280	I'm going to do is I'm going to use a symbol such as the letter A. So let's write that
85320	91160	out, but I'm going to underline it. So an underlined symbol indicates a vector rather
91160	95720	than a simple number. And when I need to specify that vector, I'm going to write it, so we're
95720	99400	going to be three-dimensional. I'm going to write the three numbers in a column form
99400	104400	like this. Now, if you haven't seen a vector specified before, what does it mean? Well,
104400	113960	think of the Cartesian axes, the x, the x, y, z axes. Think in this case about coming
113960	122600	out from the origin two in the direction of x and one in the direction of y and three
122600	127400	in the direction of z. What we're going to do is we're going to think of our vector as
127400	133800	an arrow, an arrow that comes from the origin to this point in space. And that arrow itself,
133800	141000	whether or not it comes from the origin, that direction and that length of arrow is our visualization
141120	147320	of the vector. So let me just change color to green and go ahead and draw the tip of
147320	152920	my arrow there. There we are. So the vector is coming towards us out of the screen and
152920	158200	it has those particular three components, two, one, three. Other people may use other
158200	165560	notations. For example, a line over the symbol A is commonly used. When people write out the
165600	170760	components, they may choose to do it as a row like this or even using pointy brackets
170760	176280	like this. Now, all these notations are basically getting at the same thing. You'll be able
176280	180800	to read textbooks or look online and see these things and understand what they mean. But
180800	186600	within this course of videos, we're just going to use the notation that I've introduced
186600	193000	above. So I'll erase those for now. Now, the simplest thing that you might want to do
193000	196920	if you have a couple of vectors is to add them up. So let's think about that vector
196920	201040	addition. What does it mean? So let's give ourselves a second vector B. We'll make it
201040	206960	five minus two zero, let's say. I want to add these two vectors together. So we'll write
206960	211720	that out. I simply want to add A underline plus B underline. What does that mean? Let's
211720	219440	just substitute in two, three. Add it on two, five minus two, zero. Now, what we do is we
219440	225720	simply add the first component of vector A to the first component of vector B and so
225720	231800	on down the list. Very, very simple. So we're adding two plus five. We're going to add one
231800	237720	plus minus two and three plus zero. And we just tidy that up. So that's going to be
237720	248200	seven minus one and three. Now, how about scaling a vector? Okay. So what we can do
248240	256240	is we can multiply a vector by a simple number and correspondingly, we'll just end up multiplying
256240	262400	each of its components. So let's take an example, three, nine, minus twelve. What we notice
262400	267080	is each of the three components is a multiple of three. We can just take that common factor
267080	273480	out in front and write this instead as three times one, three, minus four. Same thing.
273760	278120	All right? Or equivalently, someone might give us a vector that's already written in
278120	284440	this form. It could be, let's say three over two onto two, four, minus four. Let's make
284440	291000	it one. All right? And we can just multiply that in, in a component by component basis.
291000	295000	So we just write ourselves a new column. Of course, three times two is three. Three times
295040	304040	minus four is minus six. And three over two times one is three over two. Okay? So there
304160	310560	we are. We can scale our vectors by a number in this simple way. So with these definitions
310560	315960	of addition and scaling, can we say anything about the properties? Okay. So if I have two
315960	320600	regular numbers a and b, then of course, a plus b is the same as b plus a. I'm not saying
320600	325200	anything fancy here. It's as simple as, I don't know, seven plus minus three is equal
325200	330680	to minus three plus seven. Obviously it is. We know that. Now, if we think about the same
330680	337080	statement for vectors, a plus b, vector b, is it the same as vector b plus a? Well, it
337080	342520	must be. Let's just write out an example, seven zero minus one, three, one, two. Is it equal
342520	351960	to three, one, two vector plus the vector seven zero minus one? Of course it is because
351960	357760	of the way we've defined vector addition as just being the addition of each element
357760	364480	to the corresponding element. And this property is called being commutative. Okay. So vector
364480	370400	addition is commutative. How about this second example? If we have three basic quantities,
370400	376520	ordinary numbers, then if we have a plus b plus c, it's the same as a plus b plus c.
376520	380680	It doesn't matter the order that we do them in. Is that going to be true for vectors? Well,
380680	385160	of course, it is going to have to be true to vectors because the way we define vector
385160	390880	addition is to add each component to the corresponding component. It's just addition. So this is
391280	401160	for vectors. Let's write down what we mean. We mean that vector a plus b plus c as a previously
401160	409840	worked out thing is equal to vector a plus vector b and then add on c. It doesn't matter
409840	414680	the order we do these things. All right. And there's a name for that property. It's called
414680	427240	being associative. All right. So vector addition has that property also. Now let's think about
427240	431240	our scaling property. If we have ordinary numbers again, then we could take some scale
431240	437240	factor k and multiply it into a plus b and it would just give us k times a plus k times
437240	441400	b. Again, I'm not saying anything that isn't utterly obvious here. Say for example, I don't
441420	450920	know, 2 into 1 plus minus 3 is equal to 2 times 1 plus 2 times minus 3. Of course it
450920	456840	is. So how about for vectors? Is it true that some scale factor k times the sum vector a
456840	463240	plus vector b, a plus b, and let's stress that this scale factor is just a pure number?
463560	471560	Yes indeed. It's going to be just k times a plus k times b. So just to stress what we're
471560	476920	doing here, let's copy down this sum of two vectors we were playing with up here. This
476920	482760	7, 0 minus 1 thing plus 3, 1, 2. Put it inside curly brackets maybe for a variety. It doesn't
482760	487960	have to be curly brackets. Multiply it by some factor. Let's have 3 over 2. Had that before.
487960	491960	Unimaginative. There we are. What's that going to be? It's just going to be 3 over 2 times
491960	500600	the first vector 7, 0, 1 and then plus 3 over 2 times the second vector 3, 1, 2. Okay. So
501560	507160	everything as you kind of would expect it works out. It must. And this latter property is called
507160	517400	being distributive, so scaling is distributive over addition. And that's the end of our first video.
518040	525720	Welcome to the second of these videos. We're going to look here at the vector dot product, also
525720	529720	called the scalar product. We'll look at also the magnitude of a vector and the meaning of unit
529720	535560	vectors, the geometric meaning of the dot product, and finding the angle between vectors using the
535560	543960	dot product. Okay. So the dot product is a way of combining two vectors in order to produce a
544280	549080	scalar, hence the alternate name scalar product. Let's give ourselves a couple of vectors. Let's
549080	558840	have a, well, vector a can be 4 minus 4. Let's have 2, 1. And we'll have a vector b, which can be
560760	570200	3, 1, 3. And we're going to do the dot product of these two guys. So we write that as vector a,
570200	576440	a nice, nice clear central dot vector b. And then we write that out as the two column vectors.
577240	583080	And we need to understand how we compute the dot product. And the answer is we're simply going to
583080	589160	multiply each component by its opposite number and then add them up. So we're going to multiply
589160	595960	the first component minus 4 by 3. And then add that to the second component to multiply by
595960	602280	its opposite number 1. And finally, the third components, 1 and 3. So that's minus 4 times
602280	616840	by 3. Add it on to 2 times by 1. Add it on to 1 times by 3. So minus 12 plus 2 plus 3. That's
616840	624680	going to be minus, minus 7. All right. There's the dot product worked out. It's pretty straightforward.
624680	629080	And of course, as you can see, it can be a minus number. It can be 0. It can be a positive number.
629080	635640	But it's a simple, pure number. Okay. So now, let's see what happens if we do the dot product
635640	641400	of a vector with itself. Let's do a dotted with itself. So that's going to be minus 4 to 1 dotted
641400	648040	with minus 4 to 1. Now, of course, because we're multiplying each component by itself, that will
648040	654360	always be a positive number. 16, minus 4 by minus 4. And 2, 2 is a 4. And 1, 1 is 1. And so that's
654360	659080	going to add up to 21. It must add up to a positive number. It's made of three positive
659080	665800	numbers summed. Now, I want to introduce a second vector called a hat. It's related to a just by
665800	671320	scaling it. And we're going to scale it by 1 over the square root of the earlier dot product with
671320	678360	itself. So 1 over square root 21. And then just minus 4, 2, 1 as before. So that's just a scaled
678360	683880	version of a. What's interesting about it? Well, now let's see what happens if we take the dot product
683880	692120	of a hat with a hat with itself. So we're going to get 1 over square root of 21 times 1 over
692120	699720	square root of 21, which is 1 over 21. And then, of course, we're going to get a dotted with a,
699720	705480	the original dot product we did, which is just 21, as we know. So, of course, the dot product
705480	712200	of a hat with itself is just 1. That means that a hat has a special property. It's what's called
712200	718520	a unit vector. Unity being, of course, a fancy word for the number 1. So when we scale a vector,
718520	723240	so that it, when dotted with itself, it comes out as 1, then it is a unit vector.
723880	730680	Meanwhile, in general for a vector, the square root of the dot product with itself has the name
730680	737320	magnitude. This is the magnitude of a vector. And it is also magnitude. It is also the length
737320	745400	of the arrow, if we think in terms of a vector as a physical displacement and arrow that lives
745400	749960	in three-dimensional space, then it would be the length of that arrow, as you can see from Pythagoras.
749960	755960	Okay, now then, a different thing. The dot product between two vectors has an alternative definition,
755960	762200	which we can show is the same as the definition we've been using so far. a dot b is also the
762200	769080	magnitude of a times the magnitude of b times cos of some angle. And what is that angle? It's
769080	775080	actually just the angle between the two vectors, between their directions. So here I'm drawing a
775080	780520	vector a going in one direction and almost in the opposite direction vector b. And then the angle in
780520	786040	question would be this angle that we see between the two vectors when we draw them coming from a
786040	791880	common point of origin. Okay, so it's important to understand then that this angle can be more
791880	797400	than 90 degrees. Here's what it isn't. Here's a mistake that's sometimes made by people as they
797400	802440	start to play with the vectors. They want the angle, for some reason, they want it to be less than 90
802440	807640	degrees. So they try and contrive this by putting the vectors together in a way that will give them
807640	814680	less than 90 degrees, like this, for example. And then we could try and draw an angle between these
814680	822120	two lines. Let's see, like, let's use a red to show that it's not correct. What we should have is
822120	826440	the two vectors coming from a common origin. Then we see that the angle between them can be more or
826440	831320	less than 90 degrees. If it was exactly 90 degrees, then of course the dot product would be zero
831320	837640	because cos of 90 is zero. That has interesting consequences. But right now let's work out the
837640	843400	angle between a couple of vectors. Let's give ourselves a, we'll make it one, zero minus one,
843400	849640	and b. We're going to make it four, one, minus one. And we'll do the dot product between those
849640	855240	guys. So first we'll work out the dot product. Actually, let's make it minus one. So a can
855240	859080	be minus one, zero, minus one. I think that will come out better. So we have minus four from minus
859080	863800	one times four. We have zero times one is zero. We have minus one times minus one is one. So it's
863800	869000	going to be minus three for the total dot product between these two guys. But we also need to find
869000	873320	out the magnitude. Fair enough. Magnitude of a is going to be the square root of minus one times
873320	879560	one times one. And again, one. So that would be the square root of two. Nice and straightforward.
879560	887080	Meanwhile, the magnitude of b is going to be four fours of sixteen plus one plus one. It's going
887080	893560	to be eighteen. The square root of eighteen. But I think we can do better than that. Square root
893560	898600	of eighteen is actually square root of nine times the square root of two. And that means it's three
898600	903720	times the square root of two. Okay, now we've got everything we need. Let's pull down a copy of that
904520	910600	definition there relating a dot b to its magnitudes in the angle and fill in what we know for this
910600	918840	particular choice of a and b. We've got minus three is therefore equal to root two times three root
918840	924520	two times cos of the angle that we're after. So now we just need to rearrange. That means that
925240	932360	cos of the angle is going to be equal to minus three divided by what we've got two lots of
932360	937240	root two. So that's just three times two. And if we simplify that down, it's just minus a half.
937800	943560	Now we may just remember or use a calculator to find out. This means that the angle in question
944120	948680	is in fact going to be simply one hundred and twenty degrees. Or you can use radians if you
948680	952680	prefer radians. So there we are. That's the answer. The angle between these two vectors,
952680	959400	120 degrees. And that's it for the second video. In this video, we're going to see how to calculate
959400	964680	something called the cross product of two vectors. It's also called the vector product because the
964680	970760	output is a new vector. And we'll see how to test that the answer is correct. So here I've written
970760	976520	a cross b is equal to c. And notice that the symbol for the cross product is just the multiplication
976520	982440	symbol that you're familiar with from basic arithmetic. I've given the vector a a particular
982440	988680	form, this two, three, four column vector. And similarly b is written as four, five, six. So
988680	993800	we're going to go ahead and find out what is the cross product of these two vectors c. Because it's
993800	998840	a vector, we'll need to do some working for each of the three components. Now what I'm going to do
998840	1004360	is I'm going to paste up some structure to help us work through the problem. So don't worry because
1004360	1008600	it's going to look like a lot. But you don't need to write all this out every time you want to do a
1008600	1013720	cross product. I'm just putting it here so we can really spell out the process. Okay so let's go
1013720	1018040	ahead and work out the first component of the output vector c. Strangely enough what we're going
1018040	1023160	to do is we're going to ignore the first component of vectors a and b. So I'm just going to cross
1023160	1028200	those out. Those aren't used. And what we're going to do is we're going to multiply a certain of the
1028200	1032600	other components. What we're going to do is we're going to multiply the second component of vector
1032600	1037880	a with the third component of vector b. I call that the falling diagonal. Because when we draw it
1037880	1043720	like this we start high and then go low. And then we're going to subtract off the multiple
1043720	1050520	of the rising diagonal 4 and 6 here. The last component of vector a and the middle component
1050520	1058440	of vector b. So what we have here is 21, that's 7 3's a 21, minus 6 4's a 24, that's minus 3.
1058440	1064120	We can go ahead now and write that in as our first element minus 3. Now let's move to the
1064120	1070920	second element of the output vector c. We'll start by ignoring the second component of the
1070920	1075400	two source vectors a and b. We can cross those off. And again we're not going to multiply
1075400	1081320	some diagonals. But what's different here is we start with the rising diagonal 4 times 5.
1081320	1087960	The last component of vector a times the first component of vector b. The rising diagonal 5
1087960	1095000	4's a 20. And then we subtract off the falling diagonal. So 2 7's a 14 and that's going to give
1095000	1102120	us 6. So we can put that in. Now let's move to the third and final component. As before we start
1102120	1108920	by noting that we will ignore the third component of the two source vectors. And we're going to
1108920	1114680	need some diagonals. It's the same pattern as the first falling diagonal first. So 2 times 6
1114680	1120040	and subtract which is 12 and then subtract off the rising diagonal 5 3's a 15.
1121320	1126840	All right so that's going to be minus 3. Pop that in. We see that we have quite a simple
1126840	1134040	vector here. There's a common factor of 3. Let's bring that out. 3 then minus 1 to minus 1. That
1134040	1141080	is our vector c. That is a cross b. Notice again the pattern. It was the falling diagonal minus the
1141080	1148040	rising diagonal for the first component. And then the rising diagonal minus the falling diagonal
1148040	1153000	for the second component. And then for the third it was back to the same pattern as for the first.
1153000	1157240	Now these look a bit like letters to me. They look a bit like a v. The middle one perhaps an
1157240	1165560	n and the final one a v. I like to remember that as a little sentence which is voles never
1166360	1172920	vary. Because in my opinion voles don't vary very much. Here's a vol. This one doesn't vary at all
1172920	1178040	because it's stuffed in a museum. However if you compare it to some other voles which I found these
1178040	1182760	on the internet I think they're all pretty much identical and it's a big difference there. So
1182760	1188120	for me voles never vary. If for you they do seem to vary then think of a different way of remembering
1188120	1192520	it. But the important thing is that the first thing is the falling diagonal and then subtract
1192520	1199640	the rising diagonal of v shape and it alternates. Okay how to check your cross product has been
1199640	1204360	worked out correctly. This is really useful stuff. So let's give ourselves another example. We'll have
1204360	1209960	two three one and then we'll have let's say three seven minus one. Let's get a minus in there.
1209960	1214520	And that's going to be equal to something. We'll work it out in a minute. For now I'll put x, y, z.
1215480	1220440	Now how am I going to test once I found those x, y and z that I haven't made some kind of slip? I
1220440	1224200	mean there's a lot of mental arithmetic. If we don't write it all out we're going to be doing a
1224200	1230120	bunch of multiplications. I could easily slip up. How am I going to test that? It turns out
1230120	1234920	there's a very interesting property of the vector c that we get out after the operation
1234920	1242040	if we've done it correctly. That is as I've written here that a dot dot product with vector c is zero
1242040	1249000	and so is b. So either of the input vectors a and b dotted with the correct cross product c
1249000	1253880	should give us zero and that's great because the dot product is very easy to work out even by i
1253880	1259000	as a check. Let's go ahead and do it. So I've copied it down here. We're going to want to work down
1259000	1264840	our various components. Let's do the first component of c. So what do we do? We ignore the first
1264840	1270200	components of a and b and we do the falling diagonal. So that's going to be three times minus one and
1270200	1277320	we subtract the rising diagonal one times seven. So that's just let's just write that out. Normally
1277320	1280680	I wouldn't bother to write all this out but let's go ahead and do it here. So it's minus three
1280680	1285640	minus seven and so that's going to be minus ten as our first component. Now we work out
1285640	1290360	second component. We ignore the second component on the input vectors. We do the rising diagonal
1290360	1297240	one times three and subtract the falling diagonal two times minus one. So what have we got? We've
1297240	1305720	got three here minus minus two and so that's going to give us five and then finally the third component
1305800	1310120	ignore the third component of the input vectors. Do the falling diagonal. Two times seven seven
1310120	1315560	two is a fourteen. Subtract the rising diagonal three three's a nine. So we're going to have
1316520	1323640	for our final component fourteen minus nine which is another five. So that's quite a simple
1323640	1329800	vector. It has a common factor of five in there if we wanted to write it out that way. Now let's
1329800	1338040	test that guy versus the a and b vectors to see if it passes our test or have we made a slip.
1339080	1345000	So let's just be completely explicit about that. We're going to start by testing the dot product
1345640	1352600	of the vector a with our hopefully correct cross product c. I'll write it out two three one
1353400	1359160	dot product minus ten five five. What's that going to be equal to minus twenty
1359800	1365400	and then three fives of fifteen and then one five is five. Aha! It does equal zero. That's
1365400	1370600	correct. That's a very very encouraging thing but for real thoroughness we're going to test the other
1370600	1377880	one as well. So this is b dot c. Let's check that out. So that's three seven minus one dotted with
1377880	1384360	again minus ten five five. This time it's going to be minus uh minus thirty from three times minus
1384360	1390600	ten and then seven fives of thirty five but then minus five from the last element zero again. Aha!
1390600	1395320	So it has in fact passed both of our tests and we're now very confident that's correct.
1395320	1400440	This is a great test to do. One word of warning though the one thing it won't pick up is if you've
1400440	1405560	done your rising and falling diagonals in exactly the wrong way around by starting with the wrong
1405560	1412920	pattern. So do remember the VNV pattern and this test will check for any particular slips in your
1412920	1421800	multiplications and that's the end of the video. Okay so in this short video I'm just going to look
1421800	1427080	at four more examples of the cross product for practice and here they are. Okay so here's the
1427080	1433000	first one. We want the first element of this cross product so we ignore the first elements of the
1433000	1439240	two source vectors. We do the falling diagonal three times zero that's zero and we subtract the
1439240	1444200	rising diagonal seven times minus one that is minus seven so we're subtracting minus seven
1444200	1449560	that means we'll get plus seven. So the first element here is in the seven. Okay so now we
1449560	1453640	want the second element that means we ignore the second element of the two source vectors.
1453640	1458920	We do however the rising diagonal first seven two is fourteen minus one times zero is zero
1458920	1464280	so that's fourteen. So the second one was the rising diagonal first if you follow me
1464280	1468840	and then finally to get the third component we ignore the third component of the source vectors
1468840	1475400	and we do the falling diagonal one times minus one is minus one minus three two six so that is minus
1475400	1484600	seven. Okay so there's our solution seven fourteen minus seven but is that correct or have we made
1485560	1491080	a slip? It's a good time to check the old dot product trick so if we call this A cross B equals
1491080	1495960	C then we should find that if we do the dot product of one of the input vectors say B
1495960	1500600	with C then it should be zero. Let's check that seven twos are fourteen minus one times fourteen
1500600	1505240	is minus fourteen zero times minus seven is zero so that's fourteen minus fourteen it's correct
1505240	1511400	let's do the other one it's harder so one times seven is seven three times fourteen is forty two
1511400	1518440	that's forty nine in total and then the final term here seven sevens are forty nine but that
1518440	1525320	was with a minus number so we've got in fact forty nine minus forty nine is zero so another one of
1525320	1534840	those dot products is correctly zero so what we found out is that A dot C and B dot C are both
1534840	1540040	equal to zero as they must be so we're now very confident that we have the right cross product
1540360	1547640	let's do another one okay so we're going to want the first element so we ignore the first element
1547640	1555320	of the two source vectors and we do eight threes eight threes are twenty four minus two two times
1555320	1559960	one is two so that's twenty two let's do the next element so we ignore the middle elements and we
1559960	1565880	do the rising diagonal four twos are eight minus eight that's just going to be zero and then finally
1565880	1571240	we ignore the bottom elements and we do the falling diagonal minus the rising diagonal one minus
1571240	1578040	twelve is minus eleven so there's our solution twenty two zero minus eleven we notice we could
1578040	1582840	take eleven out of that as a common factor it would make the next stage very easy but let's just
1583400	1589080	let's do it the hard way and do the dot product so four times twenty two is eighty eight one times
1589080	1593800	zero zero and minus eighty eight actually pretty easy to confirm that zero let's do the other one
1593800	1600200	one times twenty two is twenty two three times zero and again two times uh minus eleven again zero
1600200	1607240	so that's fine that one's past its checks as well on to the third one okay so um this time I think
1607240	1612600	I might take a common factor out just to show us doing that because I see that this twenty five
1612600	1618120	five fifteen chap is going to lead to some pretty big numbers but maybe I don't need to do that I
1618120	1623320	can just take the common factor of five out of the first vector we're calling it vector a so that's
1623320	1629480	just five one minus three and then I go ahead and write vector b which can't be simplified it's just
1629480	1635080	one three minus two we'll do this cross cross pod excuse me we'll do this cross product and then
1635080	1640760	we'll put the factor of five in at the end that's fine to do it that way around okay so let's go
1640760	1645880	ahead and write that out there's our factor of five and here's our cross product so the first
1645880	1649880	element of our cross product we ignore the first elements of the two source vectors we do the falling
1649880	1655000	diagonal that gives us a minus two we subtract the rising diagonal that's a minus nine so that's
1655000	1661480	minus two plus nine that's going to give us a seven and now the middle element we ignore the
1661480	1666040	middle elements on the two source vectors we do the rising diagonal this time gives us minus three
1666040	1671240	we subtract the falling diagonal that gives us minus uh ten which means we're gonna have to add
1671240	1678040	on ten so that's minus three plus ten it's another seven okay and then finally the third element we
1678040	1683880	ignore the third elements on the source vector we do the falling diagonal that's five threes of 15
1683880	1690360	and we subtract the rising diagonal one that's going to give us another uh a 14 so in fact a
1690360	1696120	really simple vector here because we could take out a factor of seven if we want to but um let's
1696120	1701640	check those dot products do it before or after we take out the factor of seven it's pretty easy
1702360	1709080	that's going to be uh four times seven minus uh and minus two times 14 yes that goes to zero
1709080	1719320	let's do this one just quickly uh 35 and another seven is 42 but minus three times 14 is exactly
1719320	1725080	minus 42 so that one is also satisfied we've passed our checks that looks pretty good we can
1725080	1731720	leave it like this or if we want we can take out that factor of seven and do 35 times one one two
1731720	1737480	very simple very nice uh vector there okay let's come here uh now come down to the bottom and look
1737480	1742440	at the final one we notice is actually the cross product of a vector with itself it's the same vector
1742440	1747560	here so what are we going to get well we can just easily enough work it out we ignore the first two
1747560	1753320	elements and we do four um two times minus four and minus four times two so it's something minus
1753320	1759640	itself that's just going to give us a zero obviously and uh let's keep going if we ignore the middle
1759640	1765400	terms and do the rising diagonal minus the falling diagonal again threes and minus fours the same
1765400	1771320	product so something minus itself zero and it's going to be the same for the final element so
1771320	1779080	the cross product of a vector with itself is always going to be uh the zero vector now it's
1779080	1785000	important not to write that just as the scalar zero because it is a different object it's the
1785000	1791160	vector zero it's a set of in three-dimensional space three zeros that's what we get when we cross a
1791800	1801160	vector with itself of course this is going to trivially satisfy our condition on the a dot c
1801720	1808360	is equal to zero and b dot z is equal to zero that's clear and so uh i think that's a nice set of
1808360	1812920	four examples done quite quickly there they're not too bad are they so that's the end of the video
1814360	1818760	okay in this video we're going to look again at the cross product but this time we're going to ask
1818760	1826120	about its geometric meaning and its properties when we come to manipulate it okay so if some
1826120	1832840	vector c is the cross product of two other vectors a and b we've already seen how to work that out
1832840	1840920	but what we can reasonably now ask is what does that vector c look like you know if we imagine a
1840920	1849160	particular couple of vectors a and b there in space where is this vector c how is it related
1849160	1855400	to them we know how to work it out but what's its relationship with them how should we think about it
1856440	1861720	and that's what we're gonna we're gonna figure out now so we know that c is a vector so it has
1861720	1867480	two properties it has its magnitude and direction let's think about the magnitude first what is the
1867480	1873960	magnitude of c and how does that relate to um a and b what is the length of that vector it's pretty
1873960	1881800	simple the magnitude of c is the magnitude of a times the magnitude of b times sine of the angle
1881800	1887800	between a and b this is very similar to the dot product except with a sine instead of a cos
1888760	1896040	so there we are there's our two vectors a and b and an angle between them and from those
1896760	1901320	magnitude to the lengths of those two vectors in the angle we can work out the magnitude of c
1901320	1906200	note that if we cross a vector with itself the angle will be zero and so the cross product will be
1906200	1913240	zero just as we've already seen in our examples that was easy enough what about the direction
1913240	1921720	of this new vector c how does that relate okay here's the thing the direction of c is perpendicular
1921720	1931000	sorry for my writing there we'll be writing c is perpendicular to both vectors a and b so
1931000	1937640	it's at right angles to each of those vectors separately and simultaneously what does that
1937640	1942600	look like well actually we can draw it in one of two ways one of which is right and one is wrong
1942600	1949800	let's just do that so here's um here's our vector a here's our vector b if we draw c like that and
1949800	1953880	make it clear with this little symbol that it's at right angles to those two vectors
1953880	1958920	that would be perpendicular to them both how about this we could also draw a vector a draw
1958920	1964360	vector b again and we could go in the opposite direction simply literally the opposite direction
1964360	1969800	and that would also be perpendicular to these two vectors one of these is actually strictly
1969800	1977880	the correct case and the other is wrong by essentially a minus a minus one multiple what's
1977880	1983160	the way to work that out so let's let's now figure that out there's actually a rule to remember it
1983160	1990520	by it's called the right hand screw rule so let's draw that out kind of really clearly one more time
1991240	1999880	we have two vectors a and b and we are going to say that a cross b is equal to some vector c
2000760	2008600	that's fine so what we do is we put on the line along which we know c must lie
2008600	2013960	so this is the line that's perpendicular to both a and b and we simply have to ask ourselves
2014200	2023400	um in in this picture does the vector c uh go upwards or does it go downwards the trick is
2023400	2030520	to write on the angle between a and b and give it a direction so that it's increasing from
2030520	2037080	a to b it's the angle from a to b then you imagine taking your right hand and gripping
2037080	2045080	that line in such a way that your fingers curl in the same direction as the angle increases
2045080	2051240	and then your thumb points in the direction that the uh in the actual direction of c
2051240	2057560	let's do another example uh just to uh really make that clear here's a and b again
2059000	2063640	so we know we need to be I've drawn these lying in a plane so we I'm now trying to draw a line
2063640	2069720	that's perpendicular to that plane vector c must lie in one direction or the other along this line
2069720	2076040	what do we do we draw on the angle we now take our right hand and we imagine gripping that that line
2076040	2083160	we've just drawn in such a way that our fingers curl uh in the direction in which the angle is
2083160	2089400	increasing so it's like the anticlockwise direction in this picture and that's and then our thumb points
2089400	2094360	in the correct direction for that vector so it's in fact these are the two opposite cases
2095560	2102280	so that's the rule that allows you to construct the correct direction for your vector geometrically
2102280	2109080	geometrically okay uh then let's just finally wrap up by thinking about the cross product
2109080	2114600	and asking whether it has those properties that we looked at before for a vector addition
2114600	2121240	the commutative property so for example is a cross b equal to b cross a it is not
2121880	2128520	it is not equal to it unlike the dot product unlike addition this one the cross product
2128520	2136040	it matters the order and in fact it simply uh introduces a minus sign if you swap the order
2136040	2141000	of a and b so it's not commutative it nearly is in the sense that it gives you something similar it
2141000	2147720	gives you uh the same thing up to a minus sign it's important to remember and you can just verify
2147720	2153480	that by thinking about how we work out a and b with those diagonal products now how about the
2153480	2159720	associative property can we say that a cross b cross c where b and c have already been worked out
2159720	2166680	it's the same as a cross b and then cross c uh what do we think is that going to work or not in fact
2167400	2175640	it uh this is the associative property we might ask whether this is true and the answer is no
2175640	2182200	again uh the cross product does not have this property so the order in which you do your cross
2182200	2187880	product if you have doing the cross product of three vectors does matter we can easily convince
2187880	2194520	ourselves of this just by looking at a particularly uh convenient example let's just use cartesian
2194520	2200840	vectors i j k so let's just remind ourselves where these guys lie they're perpendicular to each other
2200840	2207960	i j and k just our unit vectors going in the x y and z direction so suppose we have this guy i cross
2207960	2214520	i cross k if we try evaluating it this way around with the i cross k being worked out first well
2214520	2220040	that's just going to give us in fact minus j which you can confirm with the right hand rule that we
2220040	2227160	just introduced and then that in turn will give us k that's fine so we've worked out um in that
2227160	2232840	instance the answer is minus k now let's do it the other way around i cross i if we do that first
2232840	2238200	that's just going to be zero because i cross i is zero so it's game over already at that point
2238200	2243160	so we can see two radically different answers here just depending on our order finally we could ask
2243160	2250920	about the distributive property so are we allowed to multiply through using the cross product uh if
2250920	2258760	we um if the second object in our cross product is a sum of two vectors can we do this well uh
2258760	2264280	this at last is something that we are going to be allowed to do it is the distributive property
2265400	2272360	and the cross product operation the vector product does have this property we are allowed to do that
2272360	2279720	but of course we must make sure to make uh to keep the order the same okay so i think that's
2279720	2287080	everything for this video okay in this lecture we're going to be looking at something called the
2287080	2298760	scalar triple product so what we're dealing with here is taking three vectors and combining them
2298760	2307160	in a certain way in order to yield a single one scalar quantity so three vectors into one scalar
2307160	2316040	scalar triple product suppose we have a we dot it with b which itself is crossed with c that is the
2316040	2320840	scalar triple product that combination now here i've put brackets to emphasize to do the cross
2320840	2330280	product first but we can just write a dot b cross c without the brackets why because we have to do
2330280	2337480	it in the correct order if we try to do a dot b first and then cross that with c it's a nonsense
2337480	2343240	because that will be a scalar cross-producted with a vector doesn't make sense all right then
2343240	2350600	so let's do one we'll make up some vectors let's have a is equal to three one minus one
2350600	2363720	and b is equal to two zero four and c is equal to minus one minus two three okay there are vectors
2363720	2368600	and let's go ahead and work it out so first we'll need to do the cross product b cross c so let's
2368600	2373640	write that out so i'm bringing these down now remember you can work out the cross product by
2373640	2379320	whatever your favorite method is i'm just going to do it in the method i introduced before which
2379320	2384040	is we ignore the first elements and we do the falling diagonal here zero and subtract the
2384040	2389800	rising diagonal minus eight that gives us the first element eight then we ignore the middle
2389800	2394360	elements and we do the rising diagonal gives us minus four subtract the falling diagonal
2394360	2401960	which is six so that's going to give us a minus 10 entry and then we ignore the third elements
2401960	2408040	we do the falling diagonal gives us a minus four and subtract zero so that's going to be minus four
2408040	2412600	that is our candidate for our cross product but it's always good to test how do we test a cross
2412600	2418920	product we try dotting it with either of the input vectors and check we get zero so here we'll get
2418920	2424280	eight twos are 16 and four minus four is minus 16 add it up that is zero and now we try the other
2424280	2433000	combination here we're going to have minus one on eight minus eight and then plus 20 and then
2433000	2439720	minus 12 that does indeed add up to zero it's past our checks those were just checks but it was good
2439720	2445320	to do them and so we're now very happy that that is the correct cross product to finish the scalar
2445320	2453000	triple product we now just need to dot that with a so let's write it out again minus 10 minus four
2453000	2461800	and do the dot product that's 24 minus 10 plus four is going to be 18 that's the answer that's
2461800	2465880	our scalar triple product it could have been a positive number a negative number could have been
2465880	2473640	zero in this case it's 18 now let's do another one so I'll erase this but we'll simply use the same
2474600	2481800	the same three vectors but we'll do them in a different order as our second example
2481800	2492120	so let's do b dotted with c cross a so of course we have to start by doing that c cross a combination
2492120	2502360	first so let me write that down quickly minus one minus two three crossed with three one minus one
2502360	2508040	so we start with the falling diagonal that's going to be two and then we subtract three that's minus
2508040	2513960	one and then we have a rising diagonal that's going to be nine and subtract one that's eight
2513960	2519400	and then we have a falling diagonal minus one and subtract minus six so that's going to be
2520840	2527960	five in all okay did I get that cross product correct or not do the dot product test
2528680	2536040	minus three minus three eight minus five that one's passed let's try this dot product combination
2536040	2544280	as a second check double check one minus 16 plus 15 that's also going to come out at zero
2544280	2550120	so it's passed both of my checks that one is zero as well we're happy that this is indeed the cross
2550200	2557560	product c cross a we now need to complete it so what we're doing is um b which was 204
2558280	2565800	dotted with what we found our cross product minus 185 so again go ahead and value this
2565800	2575320	minus 20 and 20 18 again all right so our second example has also given us 18 does this
2575320	2581400	mean that it doesn't matter in which order we do the elements of the uh scalar triple product
2582120	2586600	let me just write down the answer to that and then we'll look at it it turns out that for
2586600	2594760	any vectors a b and c then a dot b cross c is equal to b dot c cross a these were the two
2594760	2604280	cases we looked at and it's also equal in fact to c dot um a cross b this will always be true
2604280	2609480	in this case it was equal to 18 but these three things will always be equal there are three other
2609480	2614280	combinations we could write down in principle there are three other ways to combine a b and c
2614840	2627160	we could have a dot c cross b or we could have b dot a cross c or we could have c dot b cross a
2627800	2632680	now it turns out that those things are easy to see what they will be because
2632760	2637880	let's just look at the difference from the ones above i've just swapped the order of the cross
2637880	2644680	product and we know that when we oops we know that when we swap the order of a cross product
2644680	2650920	we introduce a minus sign so if the top three cases were equal to 18 the bottom three cases
2650920	2658200	must be equal to each other and equal to minus 18 and in general uh this is the same rule for all
2658520	2664200	uh uh scalar triple products your three of them are equal and three of them uh are equal to
2664200	2669400	one another but equal to the minus of the first three so to speak and and how can you tell which
2669400	2676120	ones are equal it's helpful to write out this little cycle a b and c written in a circle like this
2676760	2683960	if we are going around in a clockwise direction here b dot c cross a but that's clockwise around our
2683960	2691160	wheel then um and here's another one that's clockwise c dot a cross b those guys all belong
2691160	2695800	together so the guys that are in the clockwise direction all belong together and the anti-clockwise
2695800	2703400	guys they belong uh together and they're the minus of one another these two groups all right so um
2703400	2709720	that's uh that's i think all we need to do as practice for uh doing the scalar triple product
2709720	2714120	and uh knowing what we ought to get let's think about something else i'm going to introduce you
2714120	2719560	to something called the parallely pipette uh that's why i say i'm not sure how to pronounce it
2719560	2726120	parallely pipette anyway this guy is a three-dimensional shape but first i'm going to remind you of what
2726120	2733640	a parallelogram looks like so here's a rectangle and here's a parallelogram that we get um if we
2733640	2739960	have uh the pairs of the sides are parallel to each other but they are not at right angle at
2739960	2748120	right angles around the vertex now consider this rectangular box and let's tie it up there we are
2748120	2756520	and consider what happens if we uh build it out of edges that are in groups of parallel edges but
2756520	2762280	are not all at right angles to each other so uh let's see if i can draw this reasonably
2762920	2768920	realistically as a three-dimensional object so i'm going to draw this and then i'm going to stress
2768920	2775640	which edges are parallel to each other all right here we are okay let me change color
2775640	2782680	so consider these four edges of the object are all parallel to each other in exactly the same way
2782680	2789160	that in our simple parallelogram these opposing edges were parallel and then these four edges
2789720	2794920	are all parallel to one another again in our 3d shape just as these two edges are parallel
2795720	2801640	and then we have another set these four edges here in yellow are also going to be parallel to one
2801640	2810040	another that object is a particular three-dimensional solid it's clearly a generalization of the uh
2810040	2816280	of the box in that we're allowing ourselves to um have slanting edges if we want to now let's introduce
2816280	2821720	three vectors a b and c to represent these three kinds of edges you see that all the green edges
2821720	2831400	are the same vector a and so on what happens if we do a dot b cross c that it turns out the
2831400	2837880	magnitude of that if we drop the sign then the magnitude is just the volume of this shape so it
2837880	2844440	contains uh uh of course the simple case of a rectangular box as a special case but this will
2844440	2851800	work for any parallel parallel pipette uh that we care to think of with those three vectors
2851800	2855240	can always be combined with the scalar triple product to give us the volume
2857080	2864040	and that's the end of the video welcome to the uh third um topic in this video series
2864040	2870280	where i'll be introducing the matrix and thinking about what is a matrix product
2871160	2879240	all right so essentially a matrix is nothing more than a grid of numbers simply a grid of
2879240	2887800	numbers that could be positive or negative or fractional or zeros and when we uh specify the shape
2887800	2895800	of our grid of numbers or we do so simply by stating how many rows we have and how many columns
2896600	2903480	so we're gonna hear about rows and columns a lot in this video um in this video course i'm going
2903480	2911240	to use a particular uh way of writing a matrix as a symbol and i need to do that i'm going to just
2911240	2921400	use a capital letter and i'm going to the letter is going to be double underlined i'll double
2921400	2929240	underline that symbol so here we go a underline that means the matrix a and how would we write it
2930360	2936360	so that's uh just like this essentially a grid of numbers and we put it in curvy brackets just
2936360	2941720	to give it some structure so this is three rows two columns that one here's a matrix b
2941720	2948120	let's make it a square matrix let's put in a fraction to show we can minus 10 zero okay so
2948120	2954440	there are two different examples of a matrix easy enough but it gets more interesting when we try and
2954440	2962920	combine them so i want to talk about matrix multiplication addition is simple and it's
2962920	2971640	just an element by element addition but multiplication is not so simple so here's how we write it
2971640	2977880	the multiplication of matrix a by matrix b is simply written like this a b and it gives us
2977880	2984760	some new matrix c which may be a difference shape from both a and b as we'll see let's give ourselves
2984760	2995720	a couple of examples um three zero minus one two three four and matrix b can be just um one two zero
2995720	3002440	minus three so there are our two matrices here i've chosen them such that a b that multiplication
3002440	3009000	will work it will exist but actually if we try it the other way around it will turn out that the
3009000	3015000	multiple the multiple of those two matrices doesn't even exist it's not a well-defined thing so this
3015000	3021320	is an extreme case of an operation uh not being reversible in its order in other words matrix
3021320	3031880	multiplication is not commutative okay so uh let's just erase that and go ahead and see
3032760	3042440	how the multiplication actually works the trick is to multiply the each row of matrix a the first
3042440	3052120	matrix by each entire column of matrix b what does that mean well let's write out our example
3052120	3061720	three two zero three minus four minus one minus one four uh one zero two minus three now i know
3061720	3067640	that this guy is going to have uh three rows and two columns the output matrix you'll see why in a
3067640	3073480	bit i'll just put these blanks in for now the question is how to work out each of these numbers
3073480	3080280	let's choose this one first okay now notice this guy's address if you like is row one column one
3080280	3086920	of the output matrix c i'm going to need to in order to work this guy out i'll need to look at
3086920	3097320	the whole of um row one in the first matrix in matrix a and the whole of column one in the matrix
3097880	3103880	i'll need to combine those guys and how do i combine them i just multiply element by element as i go
3103880	3111000	along the row and down the column so three times one just gives me three and then i add on the next
3111000	3118520	combination two times two is four so three plus four is going to give me seven that's how i combine
3118520	3127880	those two i'll jump back here and i'll erase there and i'll just put in my seven all right so that's
3127880	3133720	the the general way it works let's go ahead and do the other elements of our matrix c let's do this
3133720	3140040	one notice this is still row one so i want that first row it's now column two that's its address
3140040	3146040	so i want the second column three times zero and two times minus three is how i'll work that out
3146040	3153480	and that's just going to be minus six so let me jump backwards um and erase my blank symbol and
3153480	3160840	write in minus six okay maybe i went a bit fast let me um spell this one out more explicitly okay
3160840	3167400	so here i now have row two column one that's the address of that guy i want all of row two
3167400	3173080	and all of column one i want to look at those guys and i want to multiply along so zero times one
3173080	3179640	and three times two that's going to give us just six in total when we add them up so let me erase
3179640	3186280	and put in six and now this element that's uh row two column two so i want all of row two
3186280	3194600	want all of column two and multiply zero times zero and uh three times minus three is minus nine
3194600	3200440	so that's going to be a minus nine if i go backwards and just put in minus nine here now
3200440	3206120	we're finally on to the final third row so we're going to want the third row of a and in this case
3206120	3212120	the first column so that's one times minus one and four times two is eight that's going to be seven
3212120	3218600	minus one plus eight and then finally last row last column uh four times minus three is twelve
3218600	3227560	and zero minus twelve all right so there we are that is our matrix product c formed by combining
3227560	3232120	each row in each column it's quite a lot of work and it would be even more if we had bigger matrices
3232840	3238280	but we said that um we get something quite different if we try multiplying a and b in the
3238280	3245320	other order so let's go ahead and do that now what if we have one zero two minus three that's b
3245880	3253720	on to three two zero three minus one four that's a so we can try it we try and multiply row one
3253720	3259240	by column one and we immediately find we cannot because they are a different length a different
3259240	3265880	list so there is no third element of our row to multiply with our third element of the column
3265880	3272680	just pause the video here um and have a look at that and see why that must be impossible for us
3272680	3280200	and so sometimes matrix multiplication is impossible all right let's look at a few uh little um
3280200	3284280	further examples and you may want to pause the video to convince yourself in each case it's true
3284280	3291080	is this thing possible for example pause it and think this one is not possible this is not possible
3291080	3298040	again because there are two elements in say the first row of a and three elements in the column
3298040	3303960	single column of b there's no way to do that as a series of element by element products how about
3303960	3312840	this we just have this row matrix and this column matrix can we do that yes this one is perfectly
3312840	3322440	possible actually it just produces a single number in fact it's a bit like a like a um a dot product
3322440	3329560	it's the whole of row one times which is the entire matrix um and then the whole whole of column one
3330520	3336440	this thing is called a row matrix and this other guy is called a column matrix for obvious reasons
3338440	3343320	okay how about this let's have a look at this one what if i swap the order of my own column i
3343320	3350440	just swap them around can i do that is that going to produce a legitimate matrix actually yes it will
3350440	3357480	this time swapping our two matrices a and b around has produced um something which exists it's actually
3357480	3363080	a huge matrix it's three by three it must have three rows and three columns because a has three rows
3363080	3367720	and b has three columns how does it work let's look at that guy for example it's just simply the number
3367720	3373880	there which is row one is just a number and column two is just a number single number so we just do
3373880	3380360	that product there's no problem pause the video if it's confusing all right so again the point here
3380360	3388360	is that um a times b is generally not equal to b times a even if they both exist they may not be
3388360	3392760	the same they may not even be the same shape uh however we can go on and ask about the other
3392760	3399880	kinds of properties of the matrix product operation a onto b times c is that the same as a times b
3399880	3405720	onto c does the order matter actually it is the same it does work in other words we have the
3405720	3412200	associative property how about a into b plus c some of two matrices yes we can have a onto b
3412200	3420520	plus a onto c that is therefore the distributive property matrix multiplication does satisfy those
3420520	3427080	things it's just not commutative okay let me make a bit more room up here in the top of the screen
3427880	3433960	and put one final puzzle up suppose i have this two row three column matrix and then a mystery
3433960	3441320	matrix m and then i have a simple column matrix of two rows and i'm asking what shape should
3441320	3449320	matrix m be or is it even is it is it possible pause and think about that and in fact it's just
3449320	3454600	a column matrix of three elements you may want to uh just meditate on that and see that it's correct
3455240	3460680	okay that's the end of this video okay welcome to this video in this one we're going to take
3460680	3467480	a look at how to work out a determinant what is it how can you find determinants of varying sizes
3468040	3475080	so a determinant is a scalar it's just a number could be positive could be negative could be zero
3475080	3482040	and it's derived from a square matrix a single number derived from an entire matrix
3482920	3490360	um now the determinant of m would be written with m with the modulus signs either side of it
3490360	3495720	even though it can be a negative number so here's an example of m and here is how we would write
3495720	3502200	the determinant of m note that we don't bother writing squares uh straight sides and curved
3502200	3507240	brackets as well there's no point in that it's just enough to have the straight line sides
3507960	3517000	so let's start with the definition of a uh two by two determinant that's the easy case to look at
3517720	3525560	so let's write out um a general two by two just using symbols we'll have a b c d written inside
3525560	3533400	our straight line sides indicates a determinant it's simply a d minus b c okay so that's the
3533400	3539880	falling diagonal the leading diagonal is also called minus the rising diagonal multiplied together
3539880	3547080	very simple very simple and that is how you can just look at and evaluate a two by two determinant
3547640	3555000	so for our example one two three four one times four is four subtract off a two times three is six
3555800	3559560	and so that's going to give us minus two is the determinant
3560120	3570280	okay so a three by three determinant is um going to be a bit more work what we do is when we have
3570280	3578280	a three by three determinant we evaluate it by breaking it up into a number um up to three
3578920	3584520	smaller determinants each of which is a two by two and for that we have our definition for
3584680	3589720	immediate evaluation so we break up bigger determinants into little ones and then evaluate
3589720	3594440	them now i'm going to write out something here that's like a chess board but instead of black and
3594440	3599560	white i have pluses and minuses you'll see why in a moment the thing to notice though is that we
3599560	3606520	alternate plus minus plus minus along each row and each column in this three by three grid okay
3606760	3614440	so now let's work out a three by three determinant again i will just use general symbols a b c
3615160	3625160	d e f g h i right now first i have to choose a row or a column i'm going to choose this top row
3625160	3631560	for the first example and i'm going to work along this row and i'm going to start with the a symbol
3632040	3637960	now i go and i look on my chart and i see that there's a plus sign in that in that slot of my
3637960	3645800	grid that means i put down plus a and now what i do is i ignore the whole row and the whole column
3645800	3652680	that a is in and i look at the remaining four numbers and i write a little determinant just
3652680	3660120	made out of those guys in the same order they appear so e f um is going to be uh in my main
3660200	3666440	determinant there and hi those are the remaining four guys in the same order they appear now b
3666440	3673880	the next term that has a minus sign according to my chart so i will put in minus b and multiply it
3673880	3680280	by again a smaller two by two determinant the one i get if i delete the row and the column with b in
3680280	3689080	it and look at the remaining guys d f g i and i just i just uh write those guys out um in the same
3689080	3697160	order they appear as a small two by two determinant finally there's c c appears with a plus sign
3697160	3706360	according to my chart um so i need to put down plus c and i need to multiply by well we delete the
3706360	3717560	row and column with c in it and we just see the remaining determinant d e um gh so uh i simply
3717560	3722760	imagine that that row and column was not there and then that's what the determinant becomes
3723480	3728920	and then of course those two by two determinants i can just write down what they are using my uh
3730280	3734680	rule of multiplying down the diagonal and subtracting the anti-diagonal
3736440	3743720	okay there we are so that is uh in general what a three by three determinant evaluates to
3743720	3749320	but it's not the only way to do it let's write it out again and this time choose uh let's choose a
3749320	3754760	column and a different one let's choose this column i'm also allowed to work down this so i
3754760	3761080	would start with b as my first term and i delete the row and column with it in and i'd see what i
3761080	3769800	are the remaining terms and write them d f g i except i've forgotten something uh there's a
3769800	3776520	minus sign attached to that particular entry so that should actually have been minus b all right
3776520	3784760	and then similarly plus e and i delete the row and column which has e in it and then i just make a
3784760	3791320	two by two determinant from in this case it would be the corner elements a c g i and then finally
3791320	3798760	minus h and delete the row and column with h in it make a two by two determinant determinant of
3798760	3808440	what's left a c d f okay and of course i could then write out these two by two determinants
3808440	3814520	explicitly but the point is it will get give me the same answer let's do an example and see why
3814520	3819160	we would choose one method or the other so here are just some random numbers i'm making up let's
3819160	3826200	stick that in it's three by three first off let's work along the top row and as uh as we did in our
3826200	3830920	first example so that's going to be three uh let's put in the full determinant here
3831560	3837960	and then minus one and again the determinant i get by excluding the top row and middle column
3837960	3846520	and then plus two uh that's going to be seven zero five minus one and i can go ahead and i can
3846520	3852520	work out explicitly what this comes out at as you can see i'm doing here and in fact it will be
3852520	3859880	12 plus 20 minus 14 and it comes out as 18 so there we are we've worked out a three by three
3859880	3864680	but we could have done it in a different way let's say we went along this bottom row that's
3864680	3872120	fine so then it will be five and i will be left with one two zero four for my mini terminate
3872120	3877640	and the next element along a minus sign and it was a minus number anyway minus minus one
3877640	3883720	that's going to be three two seven four let's just see how we've done that three two seven four
3883720	3889880	by deleting the bottom row and middle column of that now what about the third element here
3889880	3895880	well we actually have a zero plus zero times sum determinant i don't even care what that is because
3895880	3901000	it's been multiplied by zero that's the beauty of it so i've got five into four minus zero
3901960	3907080	and then we're going to have four threes of 12 minus 14 so that's going to give us 20 minus
3907080	3915160	two is 18 same answer as before okay what about if we have even bigger determinants than our three
3915160	3922280	by three example there if we have if we go bigger still we for example a four by four we're just
3922280	3927960	going to break it up into a number of three by threes and each of those would have to be broken up
3927960	3936040	into two by twos lots of work so here we are here's a general four by four we are going to expand it
3936040	3942040	along a row or column let's say we want to expand it along this row for example and we'll take in
3942040	3948360	turn a b c d and we'll need to know what sign to use so here's our checker board or our chess board
3948360	3955080	pattern of pluses and minuses just extend it out now to a four by four and you can see the rule here
3955080	3961160	is that if you like if the row number plus the column number is an even number then there's going
3961160	3965640	to be a plus sign and if it's odd it's going to be a minus sign you can confirm that for yourself
3965640	3972440	look at this one it's going to be at row two and column three and that's five and so that's a minus
3972440	3977800	that's one way to remember it or just draw it out anyway we're going to use that rule so we go
3977800	3984280	ahead and we write plus a and now we need to do the entire three by three determinant that we get
3984280	3990120	when we delete the row and column with a in it so we just write out that little square block
3990120	3995800	that we see it's quite easy to copy across and now we're going to have minus b and we need to delete
3995800	4002200	the row and column and then transcribe across the elements that are left as a three by three
4002200	4009080	just being careful not to make any slips and you see that we're going to continue so let's
4009080	4013720	delete this just to be completely explicit I'll finish the job off so I think I hope it's off
4013720	4024120	is what we're doing we're onto plus c and now we're going to just have e f h i j l and m n p
4024840	4032680	and then finally minus d um onto what we get if we delete the top row and right most column
4032680	4040440	which is left over then e f g i j k m n oh there we are that's how we handle a four by four each
4040440	4045880	of these three by threes would then have to be evaluated and so on so a lot of work and
4045880	4052040	that's the end of the video okay welcome to this fifth topic which is eigenvalues and eigenvectors
4052040	4057560	we'll introduce the problem and we'll see how to find eigenvalues finding eigenvectors is for
4057560	4068440	the next video so suppose that we are given a square matrix um n just some matrix but we are
4068440	4078200	told that m multiplied by v is equal to lambda multiplied by v for some scalar just some number
4078200	4088040	lambda and for some column matrix uh v and a column matrix of course the same as a vector
4088760	4095240	I will just say vector from now on okay so this scalar lambda could be positive negative or zero
4096120	4103000	meanwhile this vector v could be anything except the trivial boring case of just zeros
4103000	4108360	it's something other than that our challenge then is that we're going to be given a square matrix m
4108360	4114360	and we have to look for any scalar lambda and vector v that satisfies the equation
4115080	4120440	and such a scalar is called an eigenvalue and such a vector is called an eigenvector
4120520	4127720	so in that language m multiplied by some eigenvector gives us back that eigenvector just
4127720	4136440	multiplied by a scalar the eigenvalue okay so first off let's notice that if we are given
4136440	4142440	a candidate a possible eigenvector v to try perhaps for a multiple choice then it's easy
4142440	4149160	to test we'll just go ahead and try it so here's a square matrix a two by two two four one minus one
4149800	4161400	and uh suppose we write down v is equal to one minus one and this is suggested as a possible
4161400	4167480	eigenvector well then we would just test it out to see if it matches our equation
4168120	4175160	we try multiplying m by v so here we go two four one minus one and v is one minus one
4175160	4182360	that's a column and so we do row times column that's two and minus four is minus two and again row
4182360	4188760	and column that's going to be one plus one is two and we notice we can take out minus two as a factor
4188760	4195240	and then it will be the vector left is one minus one but that is just v so minus two is indeed a
4195240	4202120	scalar that multiplies v and we've succeeded improving that v is our eigenvector and our
4202120	4207800	eigenvalue that goes with it is minus two okay so that's great if we're given eigenvectors to
4207800	4215000	check out but what if we're not given any eigenvectors or eigenvalues then we must find any possible
4215000	4221240	eigenvalues for ourselves there could be more than one and for each we must find the corresponding
4221240	4227560	eigenvector v and in this first video we're just going to be finding those eigenvalues
4228360	4234520	okay so here's a little bit of quick manipulation and a side we know our equation is mv is equal
4234520	4240840	to lambda v i can certainly just bring it all to the left hand side and write mv minus lambda v
4240840	4245080	is equal to zero as long as i don't remember to write that as vector zero but now let's do
4245080	4250600	something interesting let's insert the identity matrix which won't change the equation but it
4250600	4262200	will be important for the next step mv minus lambda times the identity times v is equal to
4262200	4267720	vector zero the identity doesn't change the equation but now i can factor out both those two matrices the
4267720	4274200	m and the minus lambda times the identity that's a matrix i can factor those out and it allows
4274200	4281080	me to write that line now that if form of the equation it turns out this can only be solved
4281080	4289160	for any interesting v any v other than just zeros if the following equation is true which we can
4289160	4295240	easily prove but we're not going to prove in this video m minus lambda times the identity the determinant
4295240	4299720	of that is equal to zero so we're going to have plenty of time to think about that but let me just
4299720	4306520	put a green box around it because that is the fundamental equation we're going to use this
4306520	4318120	will allow us to find all the eigenvalues that satisfy our basic eigenvalue equation so let's
4318120	4324440	do an example it's the best thing let's do m as a two four this was the one we had before two four
4324440	4330440	minus one little square matrix and so let's write down what this lambda times the identity is
4330440	4336280	for a two by two it's going to be lambda zero zero lambda very simple and so this matrix that's the
4336280	4342600	difference of the two of them two minus lambda four one minus one minus lambda just the difference of
4342600	4349720	those two things as a determinant is equal to zero that's all so there we have it we've just
4349720	4354440	subtracted lambda off the down the diagonal but now we need to solve this so we just write out
4354440	4359240	the determinant two minus lambda multiplied by minus one minus lambda down the diagonal minus
4359240	4366200	four the off diagonal is equal to zero all right so we expand this out minus two minus two lambda
4366200	4373960	plus lambda um plus lambda squared minus four equals zero let's come over here for a bit more
4373960	4384520	space tidy that up a bit what if we got lambda squared minus lambda minus six is equal to zero
4384520	4391640	can we solve this actually it's quite easy to factor that's going to be lambda minus three
4392200	4399800	into lambda plus two is equal to zero so that's true if either lambda is equal to three
4400440	4408040	or it's equal to minus two and those are our two eigenvalues we found them using that equation in
4408040	4419560	the square box let's crack on and do one with a three by three matrix m here we go matrix m
4419560	4427000	is equal to let's have minus two one three one minus one zero and minus one one two i've worked
4427720	4435080	i've checked that before and it will work for us nicely now let's remember of course the rule
4435080	4443240	from the previous screen and we just need to apply that so let's go ahead and write it as a
4445080	4451880	write our determinant out we need to have minus two minus lambda and then just one and minus one
4451880	4459560	and then one minus one minus lambda and then one and three zero two minus lambda i'm just
4459560	4464600	subtracting lambdas down the diagonal making it a determinant setting it equal to zero
4464600	4468680	now i'm going to work along this row because it's got a zero in it so that makes me like it a bit
4468680	4474600	more as a determinant the first number is going to be minus one why because it's a one and let me
4474600	4479080	just quickly write out our little lookup table of pluses and minuses for doing determinants
4479800	4484680	so it was a one and then it picked up a minus sign and then we have the mini determinant that's made
4484680	4492840	out of those four terms so that's one three one and two minus lambda all right and then the next
4492840	4498520	term is going to be plus and then it's going to be the term itself is minus one minus lambda
4498520	4504360	and the mini determinant that we get when we exclude that row and that column is just made
4504360	4512680	out of the corner terms that's going to be minus two minus lambda and three and one and two minus
4512680	4519320	lambda and that's it because the zero term gives us nothing so it was only those two mini determinants
4519320	4525240	let's write them out minus one two times lambda and then three times one is three let's expand that
4525240	4531560	one out and then this one has the term in front minus of one plus lambda and then we have to expand
4531560	4538600	out the determinant minus two minus lambda times two minus lambda down the league diagonal
4538600	4543800	minus minus three is plus three there we are is equal to zero and then we just need to tidy that
4543800	4550440	up we need to clean it up a bit that's going to be minus of minus lambda minus one for the first
4550440	4556200	term let's turn that it one into pluses multiply through by the minus one and here we have minus
4556200	4561160	let's make that lambda plus one right that way around and then tidy up inside here we expand
4561160	4568520	it out minus four plus two lambda minus two lambda plus lambda squared and this three is
4568520	4573400	equal to zero we need to keep on working to tidy that a bit more this term here is in fact going
4573400	4578280	to be just I see the lambdas cancel out lambda squared minus one that's very nice that's come
4578280	4584120	down very very neatly so now we can really tidy that up and we can take out a common factor of
4584120	4589720	lambda plus one and the first term was just that so there's one for that and the second term we've
4589720	4596760	just found is lambda squared minus one pause the video and check you agree that that's tidied up
4596760	4600840	version of the equation now the way that can be zero is either the first term is zero which
4600840	4607000	requires lambda is equal to minus one so there's one eigenvalue for us that's one option one of
4607000	4613240	our eigenvalues has been found or the second term here has to be zero so let's do a bit more work
4613240	4621240	with that what we're saying is to neaten that up we're saying that lambda two minus lambda squared
4621240	4628840	is equal to zero in other words lambda squared is equal to two and so lambda is going to be
4628840	4635560	plus or minus square root of two that's two more eigenvalues three in all that we found for this
4635560	4641800	three by three matrix and in the next video we'll see how to take each of these values
4641800	4649000	and derive the corresponding vector this is the second of two videos that looks at eigenvalues
4649000	4659480	and eigenvectors in the first video we have seen how to find eigenvalues and we write these as lambda
4660760	4667240	for each lambda how do we find the eigenvector an eigenvector that goes with it
4667240	4676840	we know that our fundamental equation that we're working with here is that when matrix m multiplies
4676840	4683560	an eigenvector v it just gives us back that v scaled by lambda and another way to write that
4683560	4689960	is the m minus lambda times the identity multiplied by v is equal to vector zero this is the same
4689960	4696520	equation written two different ways what we need to know now that we um have obtained our lambda
4696520	4702440	values we just need to look at one of these equations and figure out an acceptable vector
4703320	4706520	i find that it's more useful to use the form on the right hand side
4708600	4716360	okay let's look at a particular example we'll have the matrix two four one minus one we looked at
4716360	4723880	this before and we found already that its eigenvalues are equal to three and minus two
4724040	4731880	what we're going to do now is we're going to take those values one at a time and figure out an acceptable
4731880	4739640	eigenvector we're going to write our vector that we need to find as just x and y where we need to
4739640	4746600	find these x y values now take a look at this green underlined equation and in particular the matrix
4746600	4753480	which is a difference of two different matrices m and lambda times the identity now that we have
4753480	4759560	our lambda value of three we could write out that difference that difference matrix it's going to be
4759560	4767640	two minus three and then just four and then just one and minus one minus three there it is
4767640	4772280	we're saying that when that multiplies our vector x y it gives us zero zero
4774120	4779800	so let's go ahead and clean this equation up we have minus one four one minus four
4779800	4786200	four onto x and y if you want to be explicit about that we can multiply out it means minus x
4786200	4795800	plus four y and x minus four y and that we know is equal to zero zero now what we immediately notice
4795800	4803000	here is that whilst this this equation between two columns two column vectors is telling us two
4803000	4809320	things it's actually telling us the same equation twice so we can see here that we're saying
4809320	4816360	minus x plus four y is equal to zero we're also saying that x minus four y is equal to zero
4816360	4822600	that's telling us the same thing is that a problem no that's exactly what we want to see
4822600	4829080	at this stage we should find that when we work on uh eigenvalue and eigenvector problems based on a
4829080	4836760	two by two matrix then really only one of these rows in the final expression uh constrains us
4836760	4843160	and the other one doesn't add any new constraint so this is exactly what we want so now how do we
4843160	4851080	go ahead and solve it we're saying that uh minus x plus four y is equal to zero of course we can
4851080	4859080	just rearrange this to say instead that four y is equal to x and that's the only constraint we have
4859080	4871160	what we're allowed to do is choose we can choose the simplest values of x and y that will make
4871160	4876680	this work so i'm going to choose y is equal to one and then i'll find that x is equal to four
4877880	4886680	and that is a perfectly acceptable eigenvector for one to go with my eigenvalue we will always
4886680	4894440	have this freedom in choosing the elements of our eigenvector really this freedom simply corresponds
4894440	4900840	to choosing how long the eigenvector is in other words its magnitude because if a particular
4900840	4908120	eigenvector and eigenvector satisfies our equations a scaled version of that same eigenvector will
4908120	4916360	still satisfy with the same eigenvalue now while the eigenvector can have any length we might
4916360	4923560	specifically have been asked for a normalized eigenvector that simply means we need to take
4923560	4930280	the one that we found and scale it to have unit length so in this case since it's four one we
4930280	4940040	need to divide by uh root seventeen to scale to unit length simple as that so there we are
4940040	4946680	that's our eigenvector and a normalized version of it now we still haven't found the eigenvector for
4946680	4953240	the other eigenvalue which was minus two let me just move this up on the screen to make space to
4953240	4958520	do that at the bottom so here we go we do exactly the same procedure we subtract minus two on the
4958520	4965640	diagonal two minus minus two and four and one minus one minus minus two lots of minus is there
4965720	4973720	so let's uh tidy that up that's going to be four four one and in fact another one
4974520	4981640	and then times x y is equal to zero zero as before we see that really these this is the
4981640	4987160	same equation twice there's only one constraint and we can read it off simply as x is equal to
4987160	4993800	minus y so if i choose x is equal to one for example then i'm going to write down an eigenvector
4993800	4997640	one minus one or if i've chosen y is equal to one then it would have been
4997640	5003400	minus one one it doesn't matter they're both correct eigenvectors to go with our eigenvalue
5003400	5009400	but if we want to normalize well they need to divide by the magnitude one over root two okay
5009400	5018600	so there are acceptable eigenvectors to go with the eigenvalue minus two okay so now let's find
5019400	5027880	the eigenvectors that go with the eigenvalues for our three by three matrix m which was
5029400	5039960	minus two one three one minus one zero minus one one two we looked at that before in the
5039960	5050520	previous video and we found the eigenvalues which were minus one root two and minus root two
5051160	5056600	and i've put little subscripts on our lambdas here so we know which one we're dealing with
5056600	5061480	let's deal with lambda one first which is the one that has value minus one
5063080	5067160	so i'll write over here the little equation that we're using over and over again
5067160	5072600	which is that m minus lambda times the identity multiplied by our vector is zero
5073640	5078840	okay we need this difference matrix so we subtract off the diagonal one minus minus one
5078840	5088200	and then one three one and minus one minus minus one and zero minus one one and two minus minus one
5089320	5093800	and that's on x y and z because we now need an eigenvector with three elements
5094760	5103480	and it's going to be equal to uh we simplify the matrix to minus one one three one zero zero
5103480	5115240	minus one one and that'll be a three and that again is on our x y z eigenvector is equal to zero
5115640	5124280	zero now what we immediately notice is that as before we don't really have three different
5124280	5131000	equations captured by our matrix equation we only have two in fact this is very obvious in
5131000	5138120	this case because the bottom row is the same as the top row that's not always the case it's not
5138120	5144040	always the case that the rows are actually identical but we will always find if we check
5144040	5149400	that there are only really two independent equations when we're dealing with three by
5149400	5157320	three eigenvalue problems we only have two equations really now i'm going to uh highlight
5157320	5162920	this row here one zero zero that's just saying in fact that x is equal to zero
5164680	5171000	now if we take uh either the top row or the bottom run we have minus x plus y plus three z
5171000	5180120	is equal to zero or y is equal to minus three z okay so now we simply uh choose any values
5180120	5187080	of y and z x has been dictated to us but any values of i y and z that satisfy these rows
5188040	5192200	so if i choose z is equal to one that's going to give me y is equal to minus three
5192840	5198120	and i can straight away then write down a satisfactory eigenvector it will be zero
5198120	5203880	minus three one as simple as that it doesn't matter whether minus sign is i could equivalently
5203880	5211800	have chosen z is equal to minus one and then i'd have zero three minus one if i normalize then
5211800	5219160	i'll need one over root ten that being three squared plus one squared and so that is a complete
5219160	5224840	solution for our first eigenvector we found it in simple form and in normalized form this is the
5224840	5231800	eigenvector that goes with eigenvalue minus one we can go ahead however and check this eigenvector
5231800	5239720	to make sure that it works so for that we'll simply need to write out our matrix m the original matrix
5239720	5250920	which was minus two one three one minus one zero minus one one two we have our
5251720	5258680	vector zero three minus one we just need to do this sum so the first element is going to be
5259320	5264600	a minus two times zero and then so three and i see there's a minus three so that does give us zero
5265160	5269560	and our second element is the only non zero element will be minus three
5270520	5277640	and our third third element there gives us one and we can write that as simply minus one
5277640	5285240	onto zero three minus one and so indeed we found that this vector works with the eigenvalue of
5285240	5293000	minus one now we can continue to look at uh to find the other eigenvectors but first let's take a
5293000	5302280	pause and review the steps involved so we're looking at rules for solving eigenvector problems
5302280	5307480	eigenvector problem is where we have a square matrix m and we say that m multiplied by some
5307480	5315560	special eigenvector gives us back that eigenvector times just by a value the eigenvalue we find the
5315560	5321640	possible eigenvalues using this equation involving a determinant of a difference of two matrices
5323480	5330280	in general there are going to be n solutions for an n by n matrix so two solutions for a two by two
5330280	5336120	three solutions three solutions for a three by three matrix that's because when we write the
5336120	5343240	determinant it will have lambda to the power of n as its highest order so for example we have
5343240	5350280	cubed to deal with when we're working out for three by three matrices now having found those
5350360	5356120	eigenvalues we then for each value need to figure out an acceptable eigenvector
5358040	5364680	what we've noticed is that generally we only have to use n minus one of the rows in the equation
5364680	5370520	that we're working to satisfy and that meant just one row in the case of two by two problems
5371240	5373640	and two of the rows in the three by three problems
5373640	5382600	we had some freedom as to what values to choose for our eigenvector and in fact that freedom
5382600	5389960	corresponded to just scaling the entire eigenvector to a greater or smaller magnitude and if we were
5389960	5394920	asked to normalize we would simply work it out using whatever values we like the simplest values
5395560	5402600	and scale it at the last step so that it has unit length okay so we've covered a lot of ground
5402600	5408120	for one video and this would be a good place to just stop watching if you like but i would like to
5408120	5414200	carry on and solve the remaining two eigenvectors for our three by three example because they involve
5414200	5419000	a square root two they're actually a bit more messy and tricky to do and in a way i think that makes
5419000	5425880	for a good interesting example to see so let me go ahead and cut back to the screen that we had
5425880	5432920	before with our matrix m spelt out and our possible eigenvalues and we'll now take the value lambda
5432920	5440760	subscript two which is square root two so then as usual we need to subtract that down the diagonal
5440760	5448680	so we'll have minus two minus square root two one three one minus one minus square root two zero
5449480	5457000	minus one one two minus square root two and that is the thing which when multiplied by
5457000	5464600	our unknown eigenvector xyz should give us zero zero zero now one thing we notice here is the rows
5464600	5470600	look all different it looks like we've got three different equations captured in this matrix equation
5470600	5476040	but they are not if we examine them carefully enough we'd find that we could generate one of these
5476680	5482120	rows from the other two and in fact we're only therefore going to need to use two of them
5482120	5485960	you could pause the video and play with it and see if you can show this but it must always be
5485960	5491400	the case unless we've made a slip earlier okay so i see that the middle row has a zero so i'm
5491400	5498040	going to start with that one it says x plus minus two minus root two times y is equal to zero
5499240	5504360	and that means that if i choose a simple value for y of one then i can immediately say
5504360	5513000	that x moving across is going to be one plus root two good so now i'll use the top line which is
5513000	5520200	minus two minus root two x plus y plus three z is equal to zero and i'll substitute in the values
5520200	5530680	that i've already picked and inferred so i'm going to get one plus root two onto minus two minus
5530680	5536120	root two that's the x term plus the y is one plus three z yet to be found is equal to zero
5536760	5543160	rearrange so put z on one side divided by a third expand this thing out minus two
5544600	5556120	minus root two minus two root two minus two plus one all right oh and there's a minus sign
5556680	5561960	because we've moved it all to the other side from the z of course now we need to tide this up
5561960	5567800	but what i notice is that inside the brackets i have a minus three and a minus three root two
5567800	5572440	and that will cancel cancel with a factor of a minus and third of front and just give us a very
5572440	5580520	simple expression of one plus root two so that's our z term okay we've found a compatible set of
5580520	5587000	x y and z values so we can now write down an accept acceptable eigenvector one plus root two
5587000	5592840	one one plus root two there we are that is an acceptable eigenvector and here's where we found
5592840	5598920	those numbers uh that goes with the eigenvalue lambda two is equal to square root two note that
5598920	5606680	i use the same subscript two on my vector so that i make it clear that lambda subscript two goes along
5606680	5615800	with vector subscript two so now our only remaining task is to look at the third eigenvalue which was
5615800	5622120	negative root two and find a compatible eigenvector for that one so as always what we need to do is
5622120	5628600	take the vector m and subtract that the lambda value we found off down the diagonal and because
5628600	5634280	we're subtracting minus a minus number we can just add it instead of course so that will be minus two
5635000	5642440	plus root two and then one and then three and then one and minus one plus root two and zero
5642440	5649720	and minus one and one and two plus root two and that matrix when multiplied by our unknown
5649720	5657080	eigenvector x y z will give us zero zero zero now as before our middle row looks nicest here
5657080	5663960	it's just telling us that x plus root two minus one put it that way around y times y is equal to
5663960	5670840	zero that means if i chose y is equal to one obvious choice then x is equal to one minus root two
5670840	5676760	watching for signs now if i take the let's say the bottom row i can have minus x plus y
5677960	5684280	plus two plus two root plus two plus root two times z is equal to zero but i can substitute
5684280	5691720	in the values i found so that will say that square root two minus one plus one plus two
5691720	5698120	plus root two z is equal to zero okay i've got some work to do to find out the value of z here
5698120	5708200	i'll start by rearranging just to put two plus root two z is equal to minus root two on the other
5708200	5713480	side but i still need to do a bit more work divide both sides i notice i can simplify
5713480	5720200	simplify by a factor of root two i can write this as z is minus one over root two plus one
5720200	5725960	pause the video and check you agree with me um and then i'm not happy with that because i don't
5725960	5731480	want to leave z as a fraction i could do but that would make a very messy looking eigenvector
5731480	5737320	i noticed there's a trick in up i have up my sleeve i know that if i multiply the top and bottom
5737320	5745640	of a fraction like that by root two minus one it will simplify i will then find that the top of course
5745640	5753960	is one minus root two uh but the bottom will be two plus root two minus root two minus one
5753960	5761240	and that whole expression just comes down to one finally then z is equal to one minus root two
5761240	5767080	we've now found our x y and z values that are acceptable so we're seeing saying that vector
5767080	5773000	three that goes with the lambda three value is one minus root two one one minus root two that is
5773000	5779400	an acceptable eigenvector so we're done for our three by three matrix m we found that three
5779400	5785480	eigenvalues and for each of them an eigenvector the last two of these which involve the root two
5785480	5789960	were uh more tricky just because there was more to keep track of more messy expressions
5789960	5797080	but the basic maths is the same every time in this series of videos we'll talk about linear
5797080	5811400	regression and least squares and the problem that we'll be solving is first in the most
5811400	5826920	abstract setting if you're given a subspace w of r m and a vector let's call it b also in
5826920	5837640	r m the question that we want to solve is which vector w in this subspace w is closest to the
5837640	5849800	vector b now just intuitively if we take the orthogonal projection of b onto w let's call that
5850360	5857720	p subscript capital w b so the projection of b onto the subspace w the orthogonal projection
5858920	5863880	we suspect that that would minimize this distance and the distance so the distance that we're trying
5863880	5876360	to minimize is b minus w minimize this over all w inside of this subspace w equivalently you can
5876360	5883800	minimize the square of the distances and this is why this problem is called least squares because
5883800	5887640	we're minimizing the squares of each of the components of these differences when you add
5887640	5899240	them all up so that's the statement of the problem is to find w inside of w such that
5899880	5906600	that the distance between w is minimized
5911320	5919400	and it turns out that the solution to this problem is exactly w equals the projection
5920200	5925560	of b onto w and i won't give a precise proof of this statement but we should at least get
5925560	5930840	an intuition for why this is true looking at this picture i've already drawn the projection of
5930840	5940680	b onto w and another arbitrary vector w now these three vectors form
5943240	5948440	a right triangle so it looks a little bit skewed from this angle but if you turn this this way
5949000	5955000	that triangle looks something like here's b here's the projection of b onto w
5955640	5962280	and here's some arbitrary vector w in the subspace w these two vectors are in w
5964520	5971640	and so this line connecting them is also in w the vector b is perpendicular to the subspace w
5972520	5981400	and therefore this angle is a right angle here this is the hypotenuse of this triangle
5981400	5989000	and it's the distance from b to w and this distance is the minimizing distance supposedly
5989640	6003160	so that's just b minus the projection of b onto w so i i you know misused a little bit of notation
6003160	6008360	here um i hope you understand that this w now is different from this one this is the actual solution
6009640	6015960	and because this is a hypotenuse of this triangle we know that this distance is always going to be
6015960	6021880	greater than or equal to either of these two distances no matter what w is this will always
6021880	6030200	create a triangle a right triangle unless w equals this vector right here and in all other cases
6030200	6036280	except this one this distance is always going to be strictly greater than this distance so what are
6036280	6050200	some ways to compute this projection so one way is to actually find an orthonormal basis of w
6051880	6054600	so given an orthonormal basis
6057960	6063800	let's call it w1 up to wk let's say k is the dimension of w
6066760	6076360	then the projection of b onto w is just take the dot product remember the dot product of
6076360	6084600	b with any of these normal orthonormal vectors gives you the shadow of b onto that vector and
6084600	6092280	then multiply again by that vector here to give you the shadow of b onto this line in that same
6092280	6098360	direction so we take the dot product or the inner product i'll write the inner product with brackets
6100040	6107160	of each of these vectors and then we'll multiply by that vector again so that we have a vector in
6107160	6113000	the end and then sum up all of these different contributions from these different shadows
6114200	6120360	so this is how you would compute the orthogonal projection of a vector onto a specific subspace
6121320	6127800	you would need for instance an orthonormal basis for that subspace but sometimes you're not given
6127800	6133640	an orthonormal basis so it might be difficult to compute it one thing you could do is you can choose
6133640	6139240	any basis of w pick arbitrary vectors that are in w and once you find k of them and you know that
6139240	6145160	they're linearly independent then you know that that forms a basis then in order to find an orthonormal
6145160	6150760	basis you would apply the Gram-Schmidt procedure to obtain an orthonormal one but you know how
6150760	6155160	difficult that is maybe you can do it for the first few vectors pretty easily but then after a while
6155160	6169800	it gets pretty messy so we'll look at a special case of this problem where w happens to equal
6169800	6180520	the column space of some m by n matrix where a is an m by m matrix m by n matrix
6182600	6186040	so in other words you can think of a as a linear transformation
6189960	6192440	from r n to r m
6192760	6202920	and in this special case we'll find a very interesting solution to this problem in general
6202920	6208520	when we look at this problem and we're given a vector b so now let's suppose that this subspace
6208520	6217320	is the column space of a and we have some vector b that's not necessarily in the column space what
6217320	6232600	this means is that the linear system ax equals b does not have a solution unless
6235000	6241960	a is onto or more specifically or more precisely
6247400	6252920	unless the vector b is in the column space of a
6260840	6264920	but because this doesn't happen in general instead of trying to solve this system which
6264920	6271160	might not have a solution we can solve an associated system instead that says okay I might not be able
6271160	6279800	to find an x in our domain here that sort of maps to the vector b because it's impossible all x's
6279800	6286520	get mapped to this subspace what instead we can try to find is project b onto this subspace
6289320	6296040	and now this vector the projection of b onto that subspace is by definition inside the column
6296040	6302280	space of a and therefore we can solve that associated system so we make a definition
6304120	6312280	based on this idea that a least squares approximation
6312520	6325720	to the linear system ax equals b is a solution
6326840	6335000	to the associated linear system ax equals the projection onto the column space of a
6335640	6344680	apply to our given vector b and it's this problem that we'll be focusing on solving
6344680	6351160	in the next few videos let's first state a theorem that makes it a lot easier to compute
6351160	6355160	the least square solution to a given problem in the special case that we mentioned at the
6355160	6363400	end of the video in the in the last session so the theorem says given a linear transformation
6365400	6365720	from
6368520	6378600	r n to r m that's called a let me write it here and a vector b in the co-domain of this linear
6378600	6396360	transformation a let's say x in the domain in the domain that's r n is a least squares
6397960	6406200	approximation to ax equals b now this is using the definition that we had made before
6406200	6411320	which remember was x is the least squares approximation to ax equals b if and only if
6412680	6422040	ax equals the projection of b onto w where w is the column space of a if and only if
6422920	6440920	x is a solution to the system a transpose ax equals a transpose b
6442600	6449640	now we mentioned last time that so let me just say here w equals the column space of a throughout
6449640	6456040	this entire discussion now we mentioned last time that if we have an orthonormal basis of w
6456760	6461480	we can actually solve this problem relatively easily but in general we're not given an orthonormal
6461480	6469720	basis of w so this formulation of the problem makes it much simpler to compute so i said it but i
6469720	6476360	should also write this that this means the taking the transpose of this matrix and taking the
6476360	6482040	transpose is easy you just swap the columns with the rows so this just gives you a new linear system
6483000	6487800	and in general this is much much easier to solve than something like this and the reason this
6487800	6493560	simplification occurs is because we've taken our subspace to be the column space of some matrix
6495560	6500920	so before we give some examples of how to apply this theorem we'll give the proof if you want
6500920	6508200	to skip the proof you can go to the next video so this is an if and only if proof so we'll prove
6508200	6519320	it in two directions let's let's first suppose that x is a least squares suppose x is a least
6519400	6535080	square solution to ax equals b i.e x solves ax equals a projection of b onto w
6538040	6543720	now here's a little picture that'll help us visualize everything let's say this is the vector b
6544520	6555000	this is the subspace w this is the projection of b onto w if we take the difference of b with
6555000	6565320	the projection onto w so b minus the projection of b onto w then that difference is exactly this
6566040	6572200	line that's orthogonal to w in other words this vector is in the orthogonal complement
6574680	6587560	of w and because it's in the orthogonal complement of w we know that no matter which
6587560	6593400	vector we take in this subspace let's call any vector here a and the reason we're going to call it
6593400	6604200	a is because a is an element in the column space of of the matrix capital a then the dot product
6604200	6608520	of a with any of these vectors i mean with this specific vector
6611320	6617000	equals zero for all a in the column space of a
6617320	6623080	in particular
6629160	6631720	if we take the actual columns of a
6634280	6639000	so a e i let's say and we dot this is the i-th column of a
6639880	6645080	as a matrix and we dot it with
6647720	6656200	this vector this is always going to equal zero for all i from and in this case since the domain
6656200	6667160	of a is r n it's for all i going from one to n we can write this dot product using the transpose
6667160	6673080	so remember the dot product is the the multiple you multiply each of the entries in the vectors
6673080	6677800	and then you add them all up and the way you can express that is using the transpose of a particular
6677800	6684120	vector if we write this as a column vector then we can write this as a row vector by taking the
6684120	6692920	transpose and then matrix multiplying these entries so we would take a e i transpose
6693880	6707640	times the vector b minus p w b equals zero for all i but this transpose the fact that
6708200	6715640	um if we take if we look at this um column of a and we take its transpose and if this is true
6715640	6721720	for all i then this is saying that this vector is the dot product of this vector with each
6721720	6731400	of the transpose vectors from a dotted with this is zero therefore if we take the matrix a and transpose
6731400	6739880	it and we multiply it matrix multiply it with this vector it will always equal zero
6743320	6749560	and now rewrite this by moving everything over to one side we get a transpose times the vector b
6750280	6753800	equals a transpose times this projection
6756680	6764200	but by assumption this projection we know that x solves this equation so we know that this also
6764200	6773560	equals a transpose ax and this shows that if x is the least square solution in other words if
6773560	6783400	it solves this problem then a transpose a transpose a acting on x equals a transpose b so this proves
6783400	6790200	the theorem in one direction to prove the theorem in the other direction
6793000	6796680	i'm running out of space here but i can give you at least the sketch of this proof
6797560	6806600	now suppose that um this equation is satisfied so suppose x is a solution
6808440	6814440	to a transpose ax equals a transpose b
6818040	6822760	we can move everything over again as we did sort of going backwards in this calculation
6822760	6829640	and we can express this by saying that a transpose acting on ax minus b
6830680	6834600	equals zero in other words this vector
6836840	6844280	ax minus b is in the orthogonal complement of the column space of a so it's in the orthogonal
6844360	6856760	complement of w now if we go back to our picture we know that the vector b can be uniquely decomposed
6856760	6864360	as the sum of two vectors one a vector in w and one a vector in the orthogonal complement of w
6865000	6871400	so this is a theorem um that you might cover uh in in the part of your linear algebra course on
6871960	6881640	um when you talk when you discuss orthogonality so b has a unique decomposition
6887560	6894840	into a vector in w plus a vector let's say in the orthogonal complement let's call it v
6895800	6904280	where w is in w and v is in the orthogonal complement of w
6906600	6912120	but this equation here says that if we take the difference ax minus b and we get in the
6912120	6923000	orthogonal complement we know that this has to equal some vector so ax minus b equals a vector
6923000	6929640	in this orthogonal complement let's just call it v for now because it's in the orthogonal complement
6929640	6940120	rewriting this equation says that b must equal ax minus v
6940680	6953480	and a where is ax ax is in the column space of a in other words it's already in w
6955000	6962120	so this is the vector in w and therefore this vector right here has to be in the orthogonal
6962120	6969080	complement and this uniqueness decomposition theorem tells us that this vector is exactly
6970040	6979080	b minus ax so this looks this is going to look a little bit silly but b equals ax minus
6981560	6983960	ax minus b
6984120	6992920	and the uniqueness decomposition theorem tells us that this vector that's in the orthogonal
6992920	7002120	complement must equal the projection of b onto that subspace w in other words ax this term right
7002120	7010040	here has to equal the projection of b onto w minus this vector right here
7014280	7024840	in other words ax equals the projection of w onto of b onto w and that means that x is
7024840	7029960	a least square solution because it solves this equation so that follows from the uniqueness
7029960	7038440	of orthogonal decomposition of a vector into two parts if you have a given subspace one
7038440	7043640	into a vector in that subspace that's where this ax equals the projection of b onto w comes from
7043640	7048360	and the other vector is just the orthogonal complement the projection onto the orthogonal
7048360	7053320	complement which is just the difference of the vector itself minus that vector in the orthogonal
7053320	7060040	subspace so this is the the proof of this theorem that allows us to say if we want to solve a least
7060040	7065880	square solution problem when w equals the column space of a we merely have to solve this system
7065880	7070360	so the next few videos will do lots of different examples of how to actually
7071400	7075400	so the example that we'll be working out it's a quite a long example because of the
7075400	7082040	generality that we'll do it in is if you're given data and let's say the data you're given
7083320	7089400	is you have a bunch of x values and a bunch of y values so these are one dimensional input and
7089400	7098600	one dimensional output values so suppose you have given data x1 y1 x2 y2 and so on up until
7098600	7109240	the number of data points that you have x dyd and if you try to plot these data points let's say
7109240	7118360	they look maybe something like this the question that you want to solve is can you try to find
7119080	7130520	a line that sort of best approximates these data so that's the problem
7133880	7139560	is to find a best fit whatever that means
7142200	7146120	straight line let's say of the form
7148760	7156120	y equals mx plus b now if we wanted to actually try to solve this problem
7156760	7161480	and suppose that all of these points actually lied on this line we would want to solve this entire
7161480	7167160	system now m and b are our unknowns we don't know the slope we don't know the y-intercept
7167160	7175640	so we'd have y1 we want to set it equal to mx1 plus b similarly for y2 our second data point
7176200	7187800	mx2 plus b and we keep going yd equals mxd plus b now in general this is an over constrained system
7187800	7192280	because we have d equations and if d is relatively large in particular if it's bigger than two
7193080	7198680	if it's relatively large it's very unlikely for us to find a solution to this problem
7198680	7207560	we can rewrite this problem as a matrix equation by saying that we have the vector y
7207560	7214120	which is the vector of our data points in fact let me even write y as a column vector
7215560	7220120	so let's write it like y1 all the way to yd
7221000	7230360	and if we notice this our coefficients are always being added in a linear fashion
7230360	7235560	and the only thing that's changing is the value of x1 so you could actually write this
7236920	7245720	as a d by 2 matrix acting on the vector mb now what should this matrix be
7245720	7252680	we want it to satisfy the equation y1 equals mx1 so x1 has to go in this column
7253560	7260440	plus b times what's the only thing that's going to leave b exactly where it is the number one
7261720	7267640	and the same thing here if we had y2 we would want to write y2 equals m
7268600	7278200	x2 plus one times b and so on all the way down to xd and one so this matrix equation
7278200	7284600	which we can write as y vector equals a and i don't want to write x as we did before because
7284600	7290840	i don't want to conflate it with the data points that are also labeled by x and so instead we'll
7290840	7299080	write this as ax so this is the system that we would like to solve but we know that there is in
7299080	7306760	general no solution to this problem so what can we do now in this case the column space of a
7306760	7316600	happens to be a two-dimensional subspace of r what of rd so the column space of a is a two-dimensional
7316600	7322680	subspace of rd so we can actually draw something like this although the space that's in is might
7322680	7329080	be significantly larger and we have the vector y somewhere out here in general it's not in the
7329080	7333480	column space in general this line does not go through every single one of these data points
7334200	7340600	so we have some vector y and instead of trying to solve this specific equation which in general is
7340600	7349880	unsolvable we can project y onto this subspace w and we can solve that associated system and then
7349880	7355560	we'll say what that means in a moment in fact actually we can say what it means right now
7355560	7361640	if we take the difference of these two vectors y minus this projection
7362040	7370440	what are we minimizing so an arbitrary vector in this subspace let's write w as an arbitrary vector
7370440	7377640	in the subspace is a linear combination of these columns so let's write that linear combination
7377640	7386920	as m suggestively a e1 which is the first column of a which is just all of these x data points
7387000	7396360	x data points plus b times the second column of a and we want to minimize the distance between our
7396360	7402920	data set our data vector y with this vector so in other words if we take this difference
7402920	7407720	let's let's replace this with w for now because let's imagine we don't yet know that this is the
7407720	7416440	projection so this difference is trying to minimize y minus m a e1
7420040	7430040	plus b a e2 and if we look at what each of these components give you then this equals
7430040	7436520	let's square this just so we don't have to deal with square roots then this is the sum so first
7436520	7449240	let's take an arbitrary ith component here it's yi minus m times xi plus b and that's it and then we
7449240	7456520	take the sum of these squares because that's what this means and we sum over all i from one to d
7457240	7463160	so we want to minimize this expression in other words we're taking our actual data set y and
7463240	7472120	we're taking this which is our best fit curve using our data set x and so we're trying to minimize
7472120	7480600	all of these distances so these are actually the vertical distances between the best fit curve
7480600	7486120	and this line it's the vertical distances because this is seeing our y data point minus
7487080	7494280	the value of this line at that point and we take that distance that difference which is this
7494280	7500360	little vertical height we square that height and then we add up all of these heights and we want to
7500360	7505720	minimize that expression so the solution to this least squares problem is graphically given by
7506360	7512920	an expression like that and we know how to solve this to solve this we apply our previous theorem
7517080	7522120	and we know that to solve this we can solve instead
7524360	7534360	a transpose a equals a sorry a transpose a x equals a transpose oh and x is xi
7535480	7541640	let me write this as xi and a transpose y so this is the problem that we want to solve
7541640	7549000	and we want to solve this for xi and xi is our vector of unknowns so in order to do this we have
7549000	7553720	to write down what a is we already know what a is we have to write down its transpose we have
7553720	7558440	to multiply those two things there's a lot of things we have to calculate so let's do that
7559160	7566360	on a fresh board space so i've written the problem setup and we have the matrix a with
7566440	7571800	our data points for x and our vector y with y and i've taken the transpose and i've written it
7571800	7577560	on the left because we'll be applying matrix multiplication to this side to solve for a transpose
7577560	7584280	a and then we'll also matrix multiply a transpose with y so if we multiply these two matrices
7586520	7591320	it's the first row here times the first take the dot product with this with this column
7591880	7600040	and that's x1 squared plus x2 squared plus xd squared so the first top left entry is the sum
7600040	7603480	of the squares of these entries from 1 to d
7607240	7614760	and the second entry on the top is the first row times the second column of a and that's x1 times
7614840	7620200	1 plus x2 times 1 in other words we're just summing up all of the different x values
7623720	7628600	and on the bottom left it's this first this the second row here with the first column
7628600	7630760	that's the same as it was in the top right
7633960	7640600	and then the last entry on the bottom right is the second row with the second column and that's
7640600	7646840	one times one plus one times one plus one times one d times which is just d itself
7648760	7656520	so this is a transpose a and a transpose y equals first of all notice that it's just a
7656520	7662360	two by two matrix so we're going to be solving a rather simple system it's just a two by two
7662360	7668360	so a transpose y is now take the values of x multiply them with the values of y
7669000	7678040	it's sum i equals one to d x i with y i this time and then it's the second row with this
7678040	7679560	and that's just the sum of the y's
7682600	7688920	and it's our vector with two components here and we want to solve this system
7690120	7696440	now it's only a two by two so on the one hand we could probably set this up as a
7696920	7704360	as a row reduction an augmented matrix problem row reduce and isolate whatever we need to so that
7704360	7713560	we can solve for this vector c on the other hand it's only a two by two matrix and row reduction
7713560	7722040	might be a little bit complicated for instance we might want to maybe divide this entry by
7722120	7727160	the sum of the squares of all of the entries but maybe that's a problem if every single one of
7727160	7733160	these is zero you know it's a little bit tricky so it's very convenient to first of all find out
7733960	7739480	when this matrix is invertible and if this matrix is invertible we can multiply both
7739480	7749160	sides by the inverse so if a transpose a inverse exists and we'll figure out what that means
7749240	7753240	we'll compute the determinant of this to determine when this inverse actually exists
7753880	7759960	then we can solve this system pretty easily and it's c which is again remember our vector of
7759960	7771240	unknown coefficients m and b then this equals a transpose a inverse times this vector right here
7772200	7780360	a transpose y which we've already computed so you know in terms of the setup it's relatively
7780360	7784360	straightforward maybe calculating this actual inverse might be a little bit of a challenge
7784360	7790760	because of the arbitrariness the generality that we're doing this in so first let's compute the
7790760	7798600	determinant of this matrix and that's just this times this minus this times this now because
7798680	7805400	we're multiplying these two sums we really have to be careful about the indices remember this is a
7805400	7812680	sum of stuff multiplied by a sum of stuff so we can't just say that this is sum xi squared it's
7812680	7819000	actually there's a lot of foiling going on and this is given by d the sum of the squares
7821160	7826840	that's from the first term this times this minus this times this and in order in order to make that
7826920	7831960	calculation a little bit more straightforward i'll rewrite one of the indices as a j instead of an
7831960	7838600	i so that we don't get confused so this is xi times xj and each of these sums there's actually
7838600	7845560	two sums here one for the index i and one for the index j and they both go from one to d so this
7845560	7854520	is the determinant and i won't do the rest of this calculation out but this i'll make a claim
7854680	7866440	and you should check this that this equals zero if and only if xi equals xj for all i and j
7868120	7873720	so the only time that this determinant vanishes if all of the xi data points
7874280	7880200	happen to be equal to each other now it takes a little bit of time to actually show that but you
7880200	7887560	can do it and this is the only instance when this matrix is not invertible and if you're
7887560	7893000	thinking about data this basically would mean that all of your data points lie along a vertical line
7893560	7899080	and then it makes sense that you can't find a function of the form y equals mx plus b to fit this
7899720	7904520	because the only line that'll work is a vertical line and in that case the slope is infinite so you
7904520	7910520	won't find a solution so it makes a lot of sense why this is the only case where that happens
7910520	7916600	otherwise if you have even a single point that's off of this line you will be able to find some curve
7917400	7923080	that best approximates this data although you would think that maybe if all of these points
7923080	7929480	lie here and there's a data point way out here then maybe this data point is there's something wrong
7929480	7935880	with it or more investigation is needed such a point in this situation would be called an outlier
7936840	7941080	and I may discuss about this at some point but that's not the focus of this specific
7942360	7948200	video right now so that's the claim so this determinant vanishes if and only if
7948200	7951240	all of these data points are equal so let's assume that this does not happen
7951640	7960600	assume there exists an i and a j that's not equal an i and a j which they are not equal
7960600	7968680	and such that xi is different from xj so we just need to assume that we have at least two data points
7968680	7977480	that do not lie on um that are not the same when we make this assumption we can compute this inverse
7981320	7987000	and this is easy because it's just two by two we maybe remember this formula we just divide by
7987000	7993080	the determinant we swap these two entries and we negate these so this is just one over this
7993080	7998760	determinant and i don't want to keep writing it so let me just write determinant of a transpose a
7998760	8005480	and just remember that it equals this and then we swap these entries so this is d and here we have
8005480	8010760	some and there's lots of indices now and i don't want to conflate any of these indices with each
8010760	8019160	other so i'm now going to call these k or something so this is k equals one to d and this is x k
8019160	8033000	squared and here we have minus some x k oops k goes from one to d and this is minus k from one
8033960	8037480	to d and this here is the inverse of our matrix
8040120	8043640	and then what we have to do is you have to take this complicated expression
8043640	8049800	and multiply it by this vector and once we do that we'll find out what the values of m and b are
8049800	8056200	so we'll need again a little bit more board space to do that so here i've rewritten our problem and
8056200	8062520	remember we're trying to solve for the coefficients m and b for linear regression for an arbitrary
8062520	8069400	data set and we computed that a transpose a as a matrix equals one over the determinant of that
8069400	8085080	matrix which we found was d times that's a d times xi squared minus let's use the indices i and j here
8085080	8092840	xi times xj so this is one over the determinant times our matrix which was
8095640	8098840	to not conflate these indices let's call these indices k
8099640	8106600	this was i believe d here for the inverse on the bottom right we had sum of the squares
8107320	8118680	x k squared minus k x k i'll stop writing from one to d it's just getting a little bit annoying
8118680	8128120	minus sum k x k but i'll always write the the subscript that we're summing over so this is
8128200	8131880	a transpose a inverse now a transpose y
8135880	8142040	well i can't remember if i wrote it but if you remember what a transpose looks like
8142840	8148680	oh we computed a transpose y yeah now i remember but the thing is that we'll have to be careful
8148680	8154440	about indices because i believe we use the indices i there as well and we've already used i we've
8154440	8163480	already used j we've already used k so let me call them l so this was sum x l y l l goes from one to
8163480	8171560	d and on the bottom part of this uh two component vector it was just the sum of the y's
8174440	8180760	okay so all of this mess is the left hand side of this expression let's multiply these two matrices
8180760	8190920	and see what we get um so let's just do that then we get and let's keep this determinant factor here
8195560	8200120	and i'm writing all of this because you'll see that it relates to something you may have seen
8200680	8203320	in a course on statistics or probability
8204200	8214840	so then we multiply d by this and we multiply this by this i'm just going to do this all out
8214840	8223560	d times this sum uh over it's just l one index x l y l minus this expression there's two sums
8223560	8232200	here now k and l x k y l that's the first component of this vector and the second component
8232200	8237880	is this times this now we have a bunch of stuff going on here um plus this times this so let me
8237880	8247640	write the plus on the left this becomes sum over k and l and x k squared which we can write as x k
8247640	8256040	you know let's just write it x k squared y l minus x k now this is a little bit different right because
8256120	8261640	we have two sums k and l and this time it's not x k squared it's x k x l
8264040	8268200	y l and this is what equals m b
8272360	8281320	now so this actually solves the whole problem so we know that m equals this first expression here
8281320	8288600	divided by this determinant and the y intercept equals this expression here divided by that determinant
8290760	8294920	now does it equal anything um familiar if we look at m itself
8298440	8305560	and we divide the numerator and the denominator by d we get that m equals
8305560	8312280	sum over l x l y l minus
8314360	8322760	one over d sum k and l x k y l divided by
8323480	8334360	x i squared minus i j x i x j
8337320	8344760	now each of these expressions um actually show up in statistics quite often and they're actually
8344760	8351080	given special names we call the let's do the denominator first since this one's only involves
8351080	8358200	a single data set this is called the variance of the data set x
8360760	8367080	where x vector equals x one through x d and it's also written as var oops var of x
8370440	8376600	and this just equals by definition the sum of the x i squares minus x i j
8377560	8384440	x i x j so that's what the variance is by definition and the covariance
8390440	8397560	um is involves two data sets our x's and our y's so it's of x and y
8398120	8401800	and this is defined by
8404040	8407480	i think you know people have different notation i don't know what the notation is i don't really
8408600	8419800	care um but it's this expression on top so this is sum l x l y l minus one over d
8419800	8423880	oh did i forget a one over d i did this should have a one over d here
8427640	8428520	minus one over d
8431160	8440680	x k y l that's an l subscript on that last y
8443560	8449320	so we have that our linear regression problem actually derives for us the variance and the
8449320	8454360	covariance of our data set and we also have explicit expressions if we wanted to
8454600	8461560	um for the least squares uh solution if we want to fit data to a straight line curve
8463080	8470520	in the next video we won't apply this general result because i don't think anybody would
8470520	8475000	expect you to memorize something like this instead we'll set up the problem in an explicit example
8475560	8481080	redo the whole procedure just so you get a feel for it with specific numbers involved and um
8481640	8485160	and how you would actually compute the inverse without all of these sums or anything like that
8485160	8489960	if you're just given a relatively small data set if you're given relatively large data sets
8489960	8494280	then you might want to go through this approach or you might have to program something that does it
8494280	8503800	for you so let's actually do an explicit example using actual numbers um here's a a graph and here's
8503800	8513720	some data points um the x axis is the horizontal axis and the y axis is the vertical one and let's
8513720	8521000	just use a unit grid so that the distance between any two of these grid lines has length one so the
8521000	8529400	data that we're given uh according to this plot is um we have our data vector and we want to try
8529400	8537400	to fit to a line of the form y equals mx plus b so let's write down our matrix a and our matrix a
8537400	8546120	remember consists of all of the x's if we write it in this form and ones all along the right column
8546120	8552920	so how many data points do we have so what's d one two three four five six seven three four five
8552920	8561080	six seven so you should have seven um entries in this column in the columns of a and let's go
8561080	8566360	in order from left to right filling in all of these entries the order that you go in doesn't
8566360	8571240	really matter as long as you're consistent with the value with the corresponding values of y that
8571240	8579800	you use so in this case the first value of x is at x equals negative four negative three negative
8579800	8585880	one zero one three four i've chosen it to be somewhat symmetric just for convenience of the
8586760	8595320	computation so it's negative four negative three negative one zero and the x values positive x
8595320	8601640	values are one three and four so this is the matrix a and the vector y
8602200	8612360	is the corresponding values of y so for x equals negative four the value of y is at negative one
8614200	8620440	again there are d there are d entries here as well the next one is zero then it's one zero one
8622760	8625480	and the last one the last two are two and four
8626360	8630760	so this is all of the information that we need
8633320	8635080	and if we compute a transpose a
8637720	8642600	what do we get so i won't write out a transpose just take the transpose of this
8643240	8647240	then we know that we're taking the dot product of this vector with itself to get the top left
8647240	8653400	entry here so what's the dot product of this with itself it's four squared times two so it's
8653400	8662200	16 times two which is 32 nine plus nine which is 18 so 32 plus 18 which is 50 plus two
8663240	8670920	so it's 52 on the top left the dot product of this with this is zero because all the negatives
8670920	8675880	cancel out all of the positive entries again i chose that specifically so that this happens
8675880	8680760	so that computing the inverse is much easier and we can immediately solve this system
8681160	8690200	now a transpose acting on y oh sorry the bottom entry is um is is just d itself and d is seven
8691480	8692760	now a transpose y
8695720	8701160	is this times this plus so negative four times negative one plus negative three times zero
8701160	8706040	plus negative one times one and so on so negative four with negative one gives you four
8707000	8712280	that with zero doesn't change anything so we still have four then that's negative one from four so
8712280	8720440	that gives us three leftover this one brings it back up to four then this six brings it up to 10
8721000	8724520	and this is 16 so we get 26 in the first entry
8728520	8730520	maybe you have faster ways of doing this i don't know
8731400	8737080	um so then uh a transpose if we take the second row here of a transpose
8737720	8743320	which is this column of ones and we dot it with this these cancel these add so we get seven
8745880	8754840	now solving this system is pretty straightforward um right this is 52007 in one side 267 we just
8754840	8761560	have to divide everything by 50 the first row by 52 the second row by seven and we immediately arrive
8761560	8774920	at the vector mb our vector of unknowns is one half and one so this tells us that the best fit
8774920	8782200	approximation that minimizes the vertical distance squared between between that line
8783000	8790280	and all of these data points has slope one half and y intercept one so the line that we
8790280	8796360	want to fit this to is one half x plus one and if we try to sketch what that graph looks like
8796360	8799720	we know that it goes through one so let's include that point here
8802360	8808120	and it has slope one half so when it gets to this when it moves two units over it moves one
8808120	8814200	unit up so here's the next data point we connect these two with a straight line and moving over
8814200	8819400	two units to the right one unit up we connect that with a straight line and we keep doing this
8819400	8824280	i mean this is how i draw um if i don't have um a ruler or anything on hand
8826120	8827720	i would try to draw something like this
8831720	8836840	so this straight line here if you notice it happens to actually go through one of the data points
8837800	8843080	that might not happen but as you can see it doesn't go through most of them but it's a pretty
8843080	8849880	reasonable approximation to this data set so this is how you would actually solve a least squares
8849880	8857480	problem specifically in the context of a fitting data to a linear curve or rather an affine curve
8857480	8864840	to be technically correct and this is how you do it in such an example in the next few videos
8864840	8869960	we're going to generalize the idea of linear regression just in terms of a straight line
8869960	8876760	data fitting to linear regression in the sense that you can data fit your data to sort of any
8876760	8882760	curve almost any curve and the way that we're going to do this is we're going to set up
8884280	8893000	some notation and we're going to let f1 through fk be linearly independent
8895720	8899800	functions
8903320	8908120	and what i mean by this is it's the same definition of linear independence of vectors
8908120	8914440	namely that um there does not exist a set of numbers a1 through ak such that when you sum up
8915160	8919880	um so let me just say this i.e there does not exist
8926040	8930040	a set of numbers a1 through ak
8932920	8937160	so these are real numbers or complex if these are complex valued functions
8937240	8946040	such that the sum of ai fi equals zero as a function
8949880	8955320	so um let's just say the domain of our function is whatever we need to specify it to be for
8955320	8962280	example the the whole real line or maybe an interval or something like that so and imagine your given
8962280	8972120	data points and let's say the given data points again we're going to use our x and y variables
8972120	8979160	so your input is x and your output is y and you have a whole list of data x1 x2
8980920	8983880	up to xd where d is the number of data points
8984840	8992760	and you want to fit these points to these functions so in other words your hope
8994760	9008280	is to somehow fit y1 equals to a1 f1 of x1 plus dot dot dot ak f
9008280	9012360	k x1
9014760	9019000	and not only do you want this but you also want this to hold for all of your data points
9019000	9035960	so up to yd a1 f1 xd now plus dot dot dot ak fk xd so this is your hope but if d
9035960	9043160	is much much greater than k then this is unlikely
9050440	9054600	it's usually impossible to find coefficients that fit all of these data
9057640	9064360	so before moving on let's try to rewrite this expression in a linear way so that we can relate
9064360	9071720	it to the linear regression problem we solved earlier so set y to be this vector here so let's
9071720	9080600	call this the vector y and what you notice here is that each of these numbers so f1 x1 is a specific
9080600	9085640	number we're taking a linear combination of these numbers with coefficients coming from the a's
9086280	9096440	so this looks like the vector y1 down to yd this is what this equation is represented by
9096440	9106280	a matrix whose entries are given by these values of f so f1 x1 in the first column and up to yd
9106280	9117000	the coefficient front of a1 is f1 xd and then this goes up to fk still x1 so x1 is the first row
9117800	9130200	and down to fk xd in the last row and this matrix is applied to the vector of unknowns a1 through ak
9131160	9141400	so this is again of the form y equals a and let's call it xc instead of x to not confuse ourselves
9141400	9146440	with the variable x that we've used for our data so in general it's impossible to solve this
9148760	9157080	and the way that we would like to solve this is again a least square solution so a least squares
9160440	9162280	solution or approximation to
9165720	9170680	this is a actual solution to
9174520	9184520	a transpose y equals a transpose ax so just apply a transpose on the left on both sides
9184680	9191000	and this is generally what we're going to solve for and this will be our this will be fitting our
9191560	9198200	data to the set of functions defined by these but there are a few restrictions that have to be made
9198840	9204600	for example the first maybe obvious restriction if you think about it is that these coefficients
9204600	9210600	should be independent and independent in the sense that I can't take any one of these coefficients
9210600	9215000	and sort of re-express it in terms of the others I'm not talking about linear independence I'm just
9215000	9226840	talking about independence so we assume the coefficients are independent and this just means
9227640	9230360	i.e. there does not exist an i
9236760	9241400	from one through k such that
9244440	9246440	a i is determined by
9246920	9258440	a j by all the other a j's so let's just say the set of a j's where j is now
9259560	9266040	from one excluding i so I read a little hat over that to exclude i up to k so in other words in
9266040	9271240	terms of all of the other coefficients so we assume that they're independent and this is sort
9271320	9276200	of obvious right because if you wanted to fit your data to these functions and you assume that these
9276200	9281320	were all unknown coefficients and you wanted to find the best value for them then if you
9281320	9286120	suddenly did that arbitrarily then it's unlikely that this relationship between them holds
9287080	9291800	in that situation so in general we definitely want to make sure these coefficients are independent
9292440	9297480	not only that we also should assume that the functions are linearly independent so
9298440	9305400	we assume that these functions are independent
9308600	9310600	as well and this is because
9314840	9322680	so suppose that one of these actually depended on the other so because if let's say
9322680	9331960	f i equal to some linear combination of the other ones so let's say bj fj so j goes from
9331960	9337880	one to k but j is not equal to i so we're just saying like for these to be linearly independent
9337880	9343000	another way is saying that well at least um none of them can be expressed in terms of the other so
9343000	9348040	if that fails at least one of them can be expressed in terms of the others so because if for some
9348440	9350440	numbers bj
9353880	9358760	then what happens is expressions so then if we take
9362360	9367640	so then if we take f and we take its linear combinations so let's say
9368600	9374760	a i sorry let me not use the index i let me use the index j now so let's take some of a j
9378280	9384200	fj and this breaks up into two parts now right because we have a sum over j where j is not equal to i
9387000	9395800	so this is j um not equal to i and the sum goes from one to k so this is a j fj but then we also
9395800	9406280	have plus a i f i but this term equals this so this equals sum over all j not equal to i
9406920	9415080	another sum over all j that are not equal to i so we have a i sorry a j i'm just copying
9415080	9429400	this term fj plus a i times this so a i times bj fj and then this is all in parentheses
9429480	9436760	and now you notice that fj is a common factor so when you factor that out you get sum j not
9436760	9448440	equal to i and then this is a j plus a i bj fj so now what we've done is we've re-expressed
9448440	9453400	our linear combination of these functions so the way everything that's on the right hand side here
9453400	9461080	in particular and we've re-expressed it in terms of functions in terms of k minus one functions
9461800	9466200	and now our coefficients have changed so in other words there was already a dependence on
9466200	9471880	the coefficients in some sense and so we usually demand that the functions are linearly independent
9471880	9481480	so that we avoid this issue in the next video we'll explain more generally a simple situation
9481480	9487640	that occurs in which this function this linear system is always um solvable by the method that
9487640	9495800	we used earlier namely by taking a transpose a inverse let's now understand when we can solve
9496360	9504920	a transpose y equals a transpose a c using the method of taking the inverse of a transpose a
9505480	9507320	now in order to take the inverse of this
9513320	9519000	we know that we need to require that the kernel of this matrix so by the way if a is a
9520600	9529560	is a d by k matrix and again d is typically much much larger than k then we want to know when this
9529640	9533480	exists so one of the situations when this exists is when
9536600	9543480	the kernel of this matrix vanishes that's one of the criteria
9546840	9552600	so zero as a vector space as a vector subspace um of r k
9553240	9561800	so when does something like this happen so to understand when we can apply this method
9564600	9572520	let's suppose that this is the matrix a a goes from r k this is r d here and this here
9573720	9574680	is the image of a
9575080	9583000	if we take the orthogonal complement of this image in this case you know unfortunately i
9583000	9587560	can only draw the orthogonal complement as having a single dimension but you could imagine that it
9587560	9596040	has um a much much larger dimension especially if these much much larger than k so the first
9596040	9606680	claim that will prove is that the orthogonal complement of the image of a
9609720	9615560	equals the kernel now in order for this to make sense i need to take the kernel of some matrix
9615560	9622680	now the image of a is in r d its orthogonal complement is also in r d and i can't take the
9622680	9626680	kernel of a because that wouldn't make sense the kernel would live here so i have to take
9627320	9631560	the only other thing i can take the kernel of is maybe the kernel of a transpose
9631560	9636600	so we'll do that so we'll take the kernel of a transpose and it turns out that these two are
9636600	9648200	equal so how do we see this let's visualize a as a um as a matrix of vectors so a one through a k
9648200	9655320	and when we take the transpose these rows these columns just become the rows
9656360	9661480	so we'll do this proof just by showing that one is contained in the other just to make it very
9661480	9672600	explicit so suppose that the vector v is let's start with the um let's start with being an element
9672600	9681000	in the orthogonal complement so let's say v is perpendicular to a the um the image of a
9684680	9689800	and then let's see if it's in the kernel of a transpose so when we take a transpose applied
9689800	9695800	to v what do we get so we'll write the matrix a transpose now we take these columns and turn them
9695800	9708760	into rows and we apply it to the vector v but matrix multiplication tells us that when we do this
9708760	9715160	we take this row multiply it by this vector in other words we take the dot product so this equals
9715800	9726920	another vector and it's a it's a vector in r k and what we get is a one dot product with v
9728200	9736360	as the first entry all the way down to ak dot product with v but if v is in the orthogonal
9736360	9741960	complement of a then it has to be that all of these dot products are zero so this is actually
9741960	9752840	the zero vector and therefore therefore the um this containment holds the image of the orthogonal
9752840	9758040	complement of the image of a is in the kernel of a transpose so that shows half of the theorem
9760360	9762600	now let's suppose so conversely
9763240	9771400	suppose that the vector u is in the kernel of a transpose
9774920	9778520	then by the same argument being in the kernel of a transpose
9779080	9792840	a transpose u equals zero but a transpose u is a one dot u all the way down to ak dot u
9793640	9800120	but the zero vector says that all of those are zero and because the image of a is spanned by
9800200	9811240	the vectors a one through ak we know automatically by the same exact argument that u is perpendicular
9811240	9817320	to the image of a so it's almost the same argument which is why i'm not writing it and therefore
9820680	9825560	this containment holds and that's the other half of the theorem so that's the proof that
9826520	9831000	the kernel of a transpose equals the orthogonal complement of the image of a
9832920	9833880	why is this useful
9837560	9840040	it's useful for the following very important reason
9843160	9852280	and it says that the kernel of a equals the kernel of a transpose a
9853240	9858760	you can already see why this is going to be useful because instead of looking at the kernel of a
9858760	9863560	transpose a which we take two matrices multiply them it's going to be a little bit more difficult
9863560	9868040	matrix to work with if we could just look at the kernel of a that would probably save us some time
9870200	9876120	so let's prove this in one direction it's pretty obvious but i'll write it out anyway
9876120	9879560	so let's first prove the direction that the kernel of a is inside here
9880200	9887080	so let's prove on this containment so if u satisfies
9890200	9900120	a u equals zero then a transpose a u because this thing is zero also equals zero
9901640	9906440	so that direction is pretty straightforward let's look at the other containment
9906600	9911320	so suppose v satisfies
9915720	9925800	a transpose a v equals zero then what this means is that a v is in the kernel of a transpose
9926040	9937960	i.e. a v is in the kernel of a transpose but by the previous claim the kernel of a transpose
9938680	9943800	equals the image of a taking the orthogonal complement of the image of a
9947480	9953320	so what's the picture here actually let's go back right here so we have that a v which by the way
9953320	9960040	is in this plane also is contained in the orthogonal complement of that image
9960680	9967480	and the only vector that's contained both in a and in the orthogonal complement is the zero vector
9969880	9976520	this implies that a v equals the zero vector in other words v is in the kernel of a
9976760	9986520	and now the containment has been shown in both directions and that's the conclusion of the proof
9987480	9991240	and let me just write out the final corollary which is the useful one for us
9993480	9994680	it's like corollary two
9994680	10008280	is that at least so let's say a transpose how do I say this a transpose a inverse exists
10010040	10018600	if and only if the kernel of a is trivial so it's only the zero vector now
10019000	10030440	why is this reasonable so this is this isn't really an example it's sort of an idea for why
10030440	10037640	this is uh this usually occurs when you're trying to fit data so our matrix a is typically going
10037640	10049080	to be of the form f 1 x 1 dot dot dot f um what was it x k f k x 1 all the way down to f 1 x d
10050920	10056600	f k x d so typically our matrix a looks something like this
10059320	10065240	and what would it mean for this to have trivial kernel it would say that none of these so all
10065240	10070200	of these vectors are linearly the set of these vectors the column vectors are linearly independent
10070840	10079880	is that likely so when when might something like that happen so for instance if one of these functions
10081240	10087400	did depend on the others in a linear way so for instance in the last video we said that
10087400	10091800	we assume that these functions were linearly independent if they were dependent what could
10091800	10096360	happen one of these column vectors could be expressed as a linear combination of the others
10097000	10102600	and therefore these columns would be linearly dependent and if these are dependent then this
10102600	10108680	has a non-trivial kernel so that's at least the sufficient that's at least one condition
10108680	10117240	that's a necessary condition for this to have um a non-trivial kernel so we demand that these
10117240	10122040	functions are linearly independent but furthermore not only do we ask that these functions are
10122040	10127080	linearly independent but it also implies that these specific vectors after we apply our data are
10127080	10133640	linearly independent but if d is much much much larger than k we only have very few of these
10133640	10141400	vectors right so the number of entries is d but we only have k vectors so it's kind of easy if you
10141400	10146920	randomly chose if you arbitrary and randomly chose k vectors in a very large dimensional space
10147560	10153640	randomly with almost almost surely it will be that those vectors are linearly independent
10153640	10162920	think about it just choose random numbers so for example let's write pi e 1 2 square root of 3 3
10162920	10173400	and the vector 1 1 1 i'm pretty sure that these three vectors are linearly independent in r3 and
10173400	10179000	i randomly chose them so even if d is not drastically larger than k but even if it's just
10179000	10185000	greater than k almost surely you'll pick linearly independent vectors so if your data is sufficiently
10185000	10190040	you know distributed well and it's not lying exactly on one line or something like that then
10190040	10198120	chances are these vectors are linearly independent so that's where it's going to be useful and in
10198120	10203480	the next video we'll actually apply this to a simple example that you probably don't need a calculator
10203480	10209720	to compute with in the next few videos we're going to be working with arithmetic modular two
10210920	10217960	so we're going to deal with all even numbers are equal to zero and all odd numbers are equal to one
10218520	10225320	so for instance two times three is six which is an even number so zero and seven plus three
10225320	10231480	is ten which is also even which is zero for another example is negative three equals one
10231480	10236920	in this case so anytime we do arithmetic for the most part when we add we're only going to be
10236920	10243000	caring about the parity of that number and this is going to be there are multiple reasons for this
10243000	10248280	one of which is simplicity the other of which is is that it's related to computer science
10249720	10258440	so we're going to let z mod two be exactly those numbers and with the arithmetic that I just said
10258440	10263640	so zero plus zero zero zero plus one is one one plus one is two which is zero and then
10263640	10270360	multiplication similarly zero times one is zero and one times one is one and we'll also work with
10270360	10280840	vectors whose entries are elements of z mod two so these are going to be vectors of the form x one
10280840	10284360	all the way up to x n where x one through x n
10287480	10294600	are in z mod two and we can also do arithmetic the way we usually do with vectors with vectors of
10294600	10301240	this sort by just adding component wise and scalar multiplication on each components as well
10303400	10311720	the interesting thing about this vector space is that unlike the vector space r to the n this
10311720	10317560	has finitely many vectors so how many vectors does this vector space have well first of all here
10317560	10327400	there are two elements and if you have n component vectors think how many entries think what possibilities
10327400	10331880	you can put in the first entry you can either put a zero or a one and as soon as you move to the next
10331880	10337960	entry you can also put a zero or a one and therefore each time you go through these entries you have
10338600	10349880	two to the n total possibilities so the number of vectors in z mod two to the n is two to the n
10350680	10357720	and one of those vectors is very special namely the zero vector and the non-zero vectors well
10357800	10359400	there's just one less of them
10364760	10369640	and i know that sounds like a trivial thing to point out but it'll actually be important
10369640	10378040	in our discussion and so for example this is the main example that we'll be working with
10379000	10383160	z mod two to the third power has seven non-zero vectors
10386600	10393800	for example so let's make a definition first first we're going to be exploring a lot of
10393800	10399720	mathematical curiosities and then we'll see how they apply to an actual physical situation
10400600	10404680	and i rather you have a little bit of suspense before we get there so first we're going to do
10404680	10409720	some math and then we'll talk about the applications so a hamming matrix
10414840	10417080	is a matrix h
10417480	10428440	with k rows and the columns
10430840	10435720	of h consist of all
10439000	10440520	the non-zero vectors
10440920	10452840	in z mod two to the kth power so k here is a non negative integer in fact let's just
10453640	10464120	yes suppose it's a positive integer so for example when k is three we have seven non-zero
10464120	10469400	vectors and what this is telling us all right now let's try to understand these two matrices a
10469400	10476760	little bit more the matrices m and h that we introduced earlier so recall that h was the matrix
10476760	10483720	it was the identity matrix a three by three in this case and another matrix q and m
10485880	10491320	was q and then the identity four by four matrix and both of these numbers can be generalized
10491320	10497000	as long as it's an appropriate size and it satisfies the requirements that we made earlier
10497000	10502520	namely that h consists of all of the non-zero vectors in the vector space
10504040	10508600	z mod two to the power where the power is determined by the number of rows here
10510200	10514200	so given the setup let's introduce a little bit more notation
10515160	10521080	and that notation is going to be we're going to define these that subspace which was the
10521080	10528440	kernel of h and also the image of m so let's call these image of m which is also the kernel of m
10530040	10539320	kernel of h rather let's denote this by c so for the rest of these videos c will refer to exactly
10539320	10546600	that subspace now remember this is a four-dimensional subspace inside of z mod two to the seventh
10547560	10550600	okay we're also going to introduce other notation
10552280	10562520	let's see subscript i be that subspace shifted by the i-th unit vector in z mod two so it's
10562520	10570680	going to be c plus e i and this just means by definition the set of all vectors of the form
10570680	10579320	v plus e i where v is in c
10581720	10587400	now this is not a subspace right because we can't add two vectors and stay within the subspace
10588280	10594520	yes stay within the subset but at the very least you can think of this as the subspace
10594520	10597480	shifted by some vector and we can define this for all i
10600840	10605720	between one and seven because that's how many non-zero vectors there are
10605720	10613320	in sorry that's that's that gives us a basis of vectors in z mod two to the seventh power
10614120	10623480	and now let's write some additional facts regarding these subs these subsets
10628200	10635400	so the first thing is that we already know that c is the solution set of a homogeneous system
10635400	10641400	namely it's the kernel of h ci is also the solution set of some system though it's no
10641400	10654680	longer homogeneous ci is the solution set of the inhomogeneous system h x equals h e i
10657160	10668600	where this is this whole thing h e i is the i-th column of h
10671560	10673240	secondly
10676680	10686360	if we take any two of these different subsets ci and cj then ci intersect cj so if we look at all
10686360	10692360	of the vectors that are common to both of them it turns out there are none so it's the empty set
10693080	10695800	for all i not equal to j
10696600	10700600	third
10703560	10710360	each of these subsets are also disjoint from the solution set of the homogeneous system
10711080	10715800	so c intersect ci is also empty for all i
10716760	10725160	and finally and this is maybe the most interesting part of it is that
10727640	10733960	the entire vector space of all vectors is the union of every single one of these
10734840	10742280	so it's the solution set of the homogeneous system with all of these other inhomogeneous
10742280	10751000	solution sets and because these are all disjoint this is a disjoint union
10751000	10758840	so every vector in z mod 2 is in exactly one of these subsets it's either a solution set of
10758840	10765480	the homogeneous system or it's in one of these solution sets of the different inhomogeneous
10765480	10773400	systems so this is a very important claim so let's actually let's actually prove it
10776920	10786120	so the first claim now when we solve inhomogeneous systems all we have to do is find one particular
10786120	10791560	solution and if we find that a solution exists then the solution set of the inhomogeneous system
10791560	10795880	is that particular solution plus the homogeneous solution that we obtained
10797000	10805880	from solving well for the kernel of h so notice however that we can just take x to be e i to get
10805880	10819400	a solution set so e i is a particular solution and therefore the solution set of the whole system
10822280	10834040	of h x equals h e i is that particular solution plus the homogeneous one
10836760	10845400	and that's exactly what the claim is c i is the solution set of this now let's look at the second
10845480	10853160	claim the second claim says that these are all different all of these subsets for different i
10853160	10864200	and j have no common intersection so in order to prove that let's pick two vectors one in c i one in
10864200	10869960	c j and they're going to be relatively they're going to be arbitrary and then we're going to show
10869960	10875400	that the only way that they can be equal to each other is if those subscripts are equal if i and
10875400	10883800	j are equal so let's start suppose that we have two vectors now because we're a solution set of
10883800	10888840	the homogeneous system the kernel of h and the kernel of h equals the image of h our vectors
10888840	10901320	are going to have this form so suppose m u 1 plus e i so this is our vector in c i equals m u 2 because
10901320	10906200	we don't know if right these two could have different they have come from different vectors
10907000	10913560	plus e j so suppose these we have these two vectors and this one is in c i this one is in c j
10914280	10922280	okay now if we apply h to these vectors so let me just write that this is in c i this is in c j so we're totally
10922280	10935400	clear now apply h to these this to this equality what happens well because these functions are linear
10936360	10952360	and we apply h to both on the left hand side this becomes h m u 1 plus h e i equals h m u 2 plus h e j
10953720	10963240	right and h m of u 1 is zero because h m is the zero matrix so this is zero that's zero and we're
10963400	10972040	left with h e i equals h e j now the only way that this is possible is if i and j are both equal to
10972040	10981640	each other and the reason is because h by definition is the set of all non-zero vectors in z mod 2 to
10981640	10987960	the third power and they never repeat so we only use those vectors once and only one so to better
10988040	10995400	understand this application let's first notice that if we apply m acting on any vector u the
10995400	11003720	vector we get is q applied to u in the top part of that um entries of those of that vector and we
11003720	11010440	retain a copy of u in the bottom this is because the matrix m was q on top and then the identity
11010440	11017880	matrix on bottom so this is true for all u in z mod 2 to the fourth
11021400	11027400	and so a copy of your original vector sits inside of this vector so imagine you're trying to send
11027400	11034680	a message u across some sort of a channel a communication channel and you want a receiver
11034680	11041320	to obtain um that message and you would like it for them to obtain exactly the message you sent
11041320	11046440	because if you hear something else on the other end of that line or you see something else
11046440	11053640	then you may misinterpret what the sender is trying to tell you so there's a sender and a
11053640	11060440	receiver and so for example um during this transmission there could be
11065000	11070040	some noise or maybe something that alters that message you hear this all the time when you're
11070040	11074840	on the phone and sometimes the signal isn't working too well you might not hear exactly what the other
11074840	11080840	person is saying or you might hear something a little bit different so there may be disturbance
11080840	11087480	along such a line so for example if we were sending um let's say my name across this channel
11088440	11093480	and at the end of the line the receiver sees um
11096840	11103720	the word archer for example now what was the original message that was supposed to be sent
11103720	11108360	in this context you have you know you know the english language so you know that there may be
11108520	11113400	a specific word that this is corresponding to but in this example you have two possibilities
11113400	11121160	that this word could be at least one of them could be archer or maybe arthur
11123080	11128520	and in order for the receiver to verify what the message was or one way to verify what the
11128520	11133960	message is is they could send that same message back and then basically ask you know is this the
11133960	11141880	message you intended to send okay so now imagine that this person sends um let's say this person
11141880	11151560	sends archer back and imagine another error occurs and imagine that the error occurs um takes place
11151560	11158280	let's say in the first entry and it becomes archer
11159240	11166280	and then the person is like wait did you want to send me the word archer like what are you doing
11166280	11176680	with this message um are you trying to tell me escher or archer and so this person is going to
11176680	11181720	send another message back um asking and you can see that this could keep happening for a very long
11181720	11188920	time um so it would be very convenient to either this person can send multiple copies of that message
11188920	11194520	and then with lower and lower probability the more messages you send the more likely it is
11194520	11199720	that the person on the other end will figure out what that message is supposed to say so that's one
11199720	11204440	option um but this option seems to take up a lot of resources right sending a message over and over
11204440	11208680	and over again is sort of multiplying the number of resources you need by the number of times you
11208680	11215320	send that message it would be very convenient if you could somehow have a scheme where the sender
11215320	11221640	is sending a message and the receiver can apply a certain method that both the receiver and
11221640	11228040	sender have agreed upon in advance to possibly identify if if an error occurred and where an
11228040	11236920	error occurred during that transmission so that's what we're going to do and we're going to simplify
11237000	11242280	the problem by not looking at the english language we're going to look at vectors whose entries are
11242280	11247160	just zeros and ones the simplest possible language that we can come up with or at least the simplest
11248040	11256360	list of the simplest alphabet we can come up with an alphabet containing two um symbols so let's say
11256360	11265080	we initially send the vector zero one one zero across this channel now once this channel goes
11265080	11270600	i should have written it from right to left as i've been doing so but let's go um counter to
11270600	11277960	this now if one error occurs suppose one error occurred that means that error is going to occur
11277960	11284040	in one of these four entries and if it occurs in the first entry the only possible thing that
11284040	11291240	that zero could become because our language only has two symbols is one so one possibility is that
11291240	11297000	we get one one one zero at the under the line another possibility is if the error occurs in
11297000	11303480	the second entry in which case we would have zero zero one zero and so on so in the third entry zero
11303480	11312680	one zero zero and in the last entry zero one one one so these are the possible outcomes if we have
11312680	11318360	exactly one error of course if no error occurs then the receiver will see the original message
11318360	11325880	but how do they even know that an error didn't occur or not so the way that we're going to solve
11325880	11333000	this problem is by using the previous situation that we had developed we can take our original
11333000	11340360	message encode it in some larger message and then this message is going to be contained in the subspace
11340360	11347240	c so if we send the message u it's going to be contained in that subspace c and if we send that
11347320	11354120	message across the channel instead what could happen to it so initially the sender is sending the
11354920	11361960	the letter the message u is contained in the bottom part but now mu is contained in z mod
11361960	11367720	two to the seventh power so it seems like a more complicated vector but the only real messages that
11367720	11374600	could have been sent the ones that have no errors are exactly in that subspace c any other vector in
11374600	11383240	this vector space is not a message that the sender could have sent because they're only working with
11383240	11393080	images the image of the transformation associated to m so this message is going through now imagine
11393080	11402200	that an error occurs somewhere along the way error and the message becomes mu plus now there are seven
11402200	11408120	entries in the vector mu so there are now seven possible errors that could occur and these errors
11408120	11416680	are exactly quantified by adding the unit vector in the ife row or entry of that vector so this
11416680	11423880	error occurs but the reader on the other end is going to see this vector v they don't know that it
11423880	11429800	is a priori this sort of combination all they see is some vector of zeros and ones
11431400	11442040	but they can use h to identify what form the vector v is in remember we said that if h of v
11442040	11448520	equals zero and this implies that the vector v is in the subspace c which is the image of m
11448840	11459400	and if h of v equals a non-zero vector then that non-zero vector is one of the columns of h
11461000	11472280	this tells us that v is in ci but remember what ci was it was this subspace plus the unit vector
11472280	11481000	ei so it tells us that if a receiver receives receives the vector v and they apply h to it
11481000	11487960	they can identify which of these subsets it's in and if the vector that they see after they
11487960	11496120	apply h is zero that tells us that no error occurred so we're going to assume at most
11496520	11503240	at most one error occurs during the transmission
11510520	11517400	and if we make that assumption then these two applications an application of h to v will tell
11517400	11525000	us where an error occurred and if we've identified where the error occurs right this says that if
11525000	11531880	we see that the h of v is hei then we know that the vectors of this form and how do we fix it
11532520	11540920	so if if it's let's say this is case one and this is case two in case one how would the receiver
11541720	11547480	identify what the original message is they would look at the last four entries of the vector v
11547480	11552440	because that's where u is and we know that no error occurred so the original
11553080	11563160	message sent by the sender is the vector corresponding to the last four entries
11568760	11578600	of the vector v and in the second case what happens then well if in the second case we found that
11579400	11583160	h of v equals h of v i then an error occurred
11587480	11598360	in the ith entry of v and how would we fix that while we would just subtract e i but
11598360	11603400	subtracting in addition are the same in z mod 2 so to fix
11603480	11614280	we know that the original message will be v plus e i well not the original message but
11614840	11622200	what the receiver sent after applying the transformation m and when they do this then they
11622200	11632200	can read off the last four entries of this vector the last meaning the bottom four
11635400	11640120	of this vector v plus e i is the original message
11644440	11648440	so let's just do this in an example just to see how exactly this works
11649160	11659400	so imagine you're the receiver and you see the vector v equals zero zero one one zero one one
11663240	11667880	if you apply h to this vector so i'll write h to remind you because otherwise
11668200	11677160	how are we going to do this computation huh so this is one one one zero one one one zero one
11678200	11681560	one zero and then we apply the vector v here
11686200	11694440	and if we apply matrix operations here we will get the vector three two three but three is one
11694440	11701560	in z mod two and two is zero so this becomes one zero one so we take this vector and look
11701560	11709560	where it appears in this matrix and in this case it is the sixth column of h this means that an
11709560	11719880	error occurred in the sixth entry of this vector here so error in sixth entry of v
11720120	11729080	and therefore the if we alter the sixth entry that would mean we change this one the second
11729080	11741960	last one to a zero so that means the original message message is one zero zero one
11742280	11749880	because we take the last four entries of this vector and then we switch the sixth entry
11749880	11755240	if we had found that the second entry was um an error occurred in the second entry we would
11755240	11760840	have changed that zero to a one and left the original message here and that would have been our
11760840	11767960	the message that was sent by the sender so um that's the basic idea of how this works
11767960	11774200	and again we worked with a case where we were dealing with um sending messages of length four
11775720	11783400	and we used um an additional a larger vector space to encode the possibilities of computing
11783400	11793160	those errors and you could also do it by um using the um by having h to be a matrix consisting of
11793160	11800120	all the non zero vectors in z mod two to the k it will allow us to encode a message of length
11801800	11809480	given by the number of columns in that matrix q and we already calculated that the number
11809480	11814840	of columns in that matrix q is two to the k minus one because of the zero vector minus an
11814840	11820680	additional k from the k vectors we used on the left hand side of the matrix h so we can encode
11820680	11828840	quite a large um number of messages under the assumption that at most one error occurs during
11828840	11833960	transmission so let's now analyze in a little bit more detail
11839240	11846920	what is q u actually doing so we know that that matrix m that we had it was broken up into two parts
11847480	11854360	and when we send a message u across a channel we will keep our original message in one part
11854360	11860920	of that vector but we'll add a bunch of fluff to it and what is the meaning of that fluff from
11860920	11869560	maybe a more a different perspective um it turns out that there's a very interesting sort of uh
11870520	11878120	logical thing that's going on between the entries of u and what q is doing to those entries
11878120	11882680	and the idea is that it's adding those entries in such a way as to maintain the sort of consistency
11883480	11890360	so if we take actually q u and we apply that matrix q that was left over the vector we would get
11891000	11894600	in terms of the entries of u so u is going to be u one through u four
11895560	11903720	the entries of this vector are going to be u one plus u three plus u four
11905080	11911640	u one plus u two plus u four and the third entry because this is a three by four matrix
11911640	11922840	is going to be u one plus u two plus u three and these entries here are called well let's call them
11922840	11929720	p one p two and p three for now and they are called parity bits
11937640	11943160	and the reason they're called parity bits is because when this message gets sent across a channel
11944120	11951880	if an error occurs these entries are summing up the entries of the vector u in some specific way
11951960	11960360	and if an error occurred right we have some vector p one p two p three and then u one u
11960360	11969240	two u three and u four if an error occurred in one of these entries then these parity bits will
11969240	11976440	detect if an error occurred and where the error occurred based on the consistency of this formula
11977400	11985640	so let's see how this works in an explicit example let's say we have the vector zero zero one
11986360	11991080	and i'll break this up into the two different parts so that we isolate the parity bits versus the
11991080	11996040	original message and by the way this isn't the original message that i'm writing right now this
11996040	12001880	is what happens after it's sent and let's see the receiver sees this message i believe this may be
12001960	12008600	the example we were working with a moment ago so let's now look at these formulas and see what
12008600	12018680	they say so p one on the one hand equals zero but let's see if the sum of these entries is also
12018680	12025480	equal to zero so if we take u one plus u three plus u four we get one plus one plus one is three
12025480	12037240	which is one which is not equal to one which equals u one plus u three plus u four what does
12037240	12055480	this mean this means an error occurred in one of these entries
12056120	12067240	and when i say one of these entries i mean either p one u one u three or u four so let's
12067240	12075480	write that down p one u one u three or u four and we know it has to be exactly one because again
12075480	12082040	we're assuming at most one error occurred and because of this inconsistency we're guaranteed
12082040	12088200	that an error occurred the only way no error would occur is if all of these would be consistent so if
12088200	12093000	p one does equal this p two does equal that p three does equal that because this would say
12093000	12100440	that our vector is of this form m applied to the original vector u so that doesn't exactly tell us
12100440	12106840	which of the errors it is yet is it p one u one u three or u four so for that we'll look at the other
12107480	12115640	parity bits so let's look at p two the vector we see says p two is zero is that consistent with
12115640	12123480	this formula u one plus u two plus u four so u one plus u two plus u four is zero so that actually is
12123480	12136200	consistent what does this tell us this tells us that no error occurred in any of these entries
12136280	12142520	because if one error occurred it is impossible for these two to be equal to each other so this means
12145960	12150920	p two u one u two and u four are all
12153560	12161080	error free now let's compare this to the first one that we analyzed the first one said
12161720	12168040	it was possible that the error occurred at u one and it was also possible that the error occurred
12168040	12176280	at u four this new observation tells us those two possibilities it's not possible that an error
12176280	12182520	occurred in those entries so now the only possibilities left are p one and maybe u three
12183160	12188440	so we'll keep that in mind when we go to the last parity bit which will then isolate exactly
12188520	12195320	where the error occurred so p three is equal to well from this it's one and is that equal to
12195320	12201640	u one plus u two plus u three u one plus u two plus u three it's equal to zero so that's not equal
12201640	12216200	to this which is u one plus u two plus u three now this tells us that error is in one of p three
12217080	12222760	u one u two or you or u three
12225640	12234680	we already know that u one and u two are not possible right u one and u four are not possible
12237320	12245080	and the only error that's common to both of these right because we know an error
12245080	12252360	one error occurred in either p one or p r u three or it's possible that an occurred in p three or
12252360	12259480	u three but if it was p three right suppose that the error occurred in p three then this would
12259480	12264520	have been fine it would have been unaltered because we wouldn't have detected an error
12264520	12270680	u three would have also been okay so the only possibility in this case is that an error occurred
12270760	12277960	in u three the one that's singled out from these three parity bits so error
12279400	12286280	in u three and therefore if we go to this original message the message that we received rather
12286840	12292440	and then we um this is sorry this is the message we received but we would have to alter is the
12292440	12298360	u three entry of this to get back the original message therefore the original message
12301400	12310040	is the last four entries as it was before but now we alter that third message that third entry
12310040	12316280	to get one zero zero one as the original message being sent and this is consistent I believe
12316280	12323560	with the answer that we obtained earlier so you might be wondering okay this is a little bit more
12323560	12329640	intuitive because we're sort of counting up our different entries in different ways and sort of
12329640	12336200	using a process of elimination method to isolate exactly where the error occurred now of course
12336200	12340600	that is a little bit more straightforward it's easier to work with it's easier to think about
12341160	12346280	um the first time you see it perhaps on the other hand the linear algebra method
12347400	12353000	it allows you to see it from a maybe potentially different perspective and I would think that if
12353000	12359080	you're working with a much much larger message that the linear algebra method seems to be a
12359080	12363880	lot easier to work with especially when you look at the way that we multiply those matrices
12364680	12370920	and the form of the hamming matrix that we constructed so let me just say this that
12370920	12376840	the cs hamming matrix looks a little bit different for instance I think it starts out with
12378120	12384520	one zero zero zero one zero but then the third column is not zero zero one I think the fourth
12384520	12392680	column is zero zero one and these other four columns are some permutation of the leftover
12392680	12398440	columns I had and now you can see if you were to manipulate this with the other matrix m that's
12398440	12403480	associated to this one by demanding that the kernel of h equals the image of that matrix m
12404760	12409160	the algebra would be a little bit more we can't just break this up into do blocks identity
12409160	12417880	and the leftover part instead it has sort of this interpretation but I believe the linear
12417880	12423720	algebra calculations are much much simpler if you work with a block die a block matrix
12424440	12430680	of the form that I indicated earlier now this may change if you try to look at what happens if
12430680	12436920	multiple errors occur how would you potentially correct for all of those additional errors
12437640	12443000	and I'll leave you to think about that and to check out the literature in the next few videos
12443000	12452440	we're going to compute the square root of a positive matrix and the way we're going to do this
12452440	12459080	is by introducing something called the functional calculus and in fact we'll learn how to compute
12460200	12466840	given any function under suitable conditions what it means to apply that function to a given
12466840	12473080	square matrix so let me go ahead and state the statement of the theorem that will prove
12474600	12479320	and we'll prove this theorem first by doing an example and then we'll prove the general
12479320	12487160	result from scratch so it says let a be a diagonalizable
12490920	12492040	n by n matrix
12497800	12506920	and let f be a function be a complex valued function let's say
12510280	12522440	defined on what I'm going to call sigma of a and sigma of a is the set of all eigenvalues of a
12530600	12536280	now if we have this setup we can already define what f of a is so let's do that
12539560	12549400	so f of a is going to be defined as p f of d p inverse where
12554120	12565960	p is the n by n matrix is a matrix of eigenvectors
12569880	12579960	of a written as columns and d is the corresponding
12582840	12586920	matrix of eigenvalues
12587480	12593240	and what do I mean by f of d
12596040	12605240	and f of d is defined to be now d is a diagonal matrix so let me just write out exactly what
12607240	12614120	we're doing if we have a matrix of eigenvalues and these eigenvalues can repeat so let me just
12614120	12623320	write all n of them and then this is zero everywhere else we define f of this matrix to be f applied
12623320	12629400	to the elements along the diagonal and zero everywhere else so this is f of lambda one
12630840	12640200	f of lambda n and zero everywhere else so so far all we've done is set up our assumptions
12640200	12645960	so we have a matrix we have the eigenvalues we can define f applied to a provided that we
12645960	12652120	have a complex valued function defined on the set of eigenvalues and here's the statement of the
12652120	12661480	theorem then there exists a polynomial
12664440	12677960	q such that q of a now what do I mean by q of a q is a polynomial and it makes sense to multiply
12678680	12682600	so we can take a we can square it we can cube it we can also take it to the zero
12682600	12687880	power that's just the identity matrix and then we can also multiply these by coefficients so if I
12687880	12693880	have any polynomial it's very easy to define what q of a is you just write your polynomial
12693880	12700920	and where you have your variable you replace it with the matrix a so this is some polynomial in a
12701880	12710280	but it turns out to equal f of a as defined previously by this method of breaking a matrix up
12710280	12715160	into its eigenvalues and getting its eigenvectors and constructing it this way
12715880	12721880	so that's what the statement of this theorem is and it's very surprising because in general you
12721880	12728360	can think of a very strange function such as the square root and this is telling you that there
12728360	12734600	is a way to write the square root of that given matrix in terms of a single polynomial
12735400	12741480	and what we're going to do first is do this through a simple example and illustrate it with
12741480	12746520	that simple two by two matrix and then we'll prove the general theorem so we might as well start
12746520	12755640	this example now and continue it in the next video so the example is going to be let a equal 10
12756360	12775800	6 6 10 and our goal is to compute the square root of a so the first step is find the eigenvalues
12778280	12783240	so another thing that we'll do is we'll review how to do these things so to find the eigenvalues
12783240	12792680	compute the determinant of 10 minus lambda 6 6 10 minus lambda and this equals 100
12794840	12804920	plus lambda squared minus 20 lambda minus 36 and some of this simplifies we get lambda squared
12805880	12825240	minus 20 lambda plus 64 and this also factors into lambda minus four and lambda minus 16
12826200	12829720	so we know what our two eigenvalues are they are four and 16
12835560	12843240	and while we wait for the next video you can try to compute the corresponding eigenvectors
12843240	12847480	and I'll just give you the answer there in a moment so here's the matrix that we're looking at
12847480	12852680	the associated eigenvalues that we found before and corresponding eigenvectors which you should have
12852680	12860440	found by computing the corresponding eigenvectors and so now let's compute what f and f meaning the
12860440	12868280	square root of a so what is f of sorry f of the diagonal matrix d associated to these eigenvalues
12869320	12874520	this is taking the square root of each of the corresponding entries on the diagonal so it's
12874520	12884040	just two and four and the matrix p is writing down these two eigenvectors so it's just one negative
12884040	12895560	one one one its corresponding inverse is the determinant here is two so it's one half and
12895560	12902760	then the rest of this matrix we swap and we negate so that's the corresponding inverse of this matrix
12903400	12908120	so what happens when we compute p f of d
12910600	12918200	p inverse supposedly we should get the square root of our matrix which means that if we square it
12918200	12926120	then we get back our matrix a so if we multiply some of these out i'll skip some of the steps
12926120	12938840	so if we take one half when we multiply p with f of d we get two four negative two four
12939800	12943880	and then we also have p inverse still here i've already pulled that one half out
12947960	12954360	and multiplying these matrices out we get well that distributes out so we can just have one two
12954360	12966760	negative one two and when we multiply those we get three one one three so let's check that if we
12966760	12974840	square this matrix so let's um let's just call this f of a this is the definition that we gave
12974840	12984760	of f of a so what happens when we square this matrix f of a squared we get exactly 10 6 6 10
12984760	12991560	so we do get our original matrix back so this is one way of computing the square root of a matrix
12991560	12998920	or at least if it has positive eigenvalues um by computing the corresponding eigenvectors and
12998920	13005960	eigenvalues and supposedly we have another way of doing this and the interesting thing about
13005960	13012280	the following method is that we will not be able we will not need to use the corresponding eigenvectors
13012280	13018520	all we need to use are the corresponding eigenvalues and we'll find that polynomial that
13018520	13025160	allows us to compute the square root of this matrix so how do we do that for the time being
13025160	13030680	what we'll first do is we'll find a polynomial
13034760	13046280	q such that q of lambda one equals the square root of lambda one or f of lambda one
13047400	13054360	and q of lambda two equals f of lambda two so in this case these are the square roots
13054440	13058680	and we already know exactly what their values are this is two and this is four
13060120	13064520	so we're trying to do at this point now we're doing a different problem it seems like
13064520	13070360	because now we're just trying to find a polynomial that interpolates these two values of a function
13071560	13080120	so what we're trying to do is so here's lambda one here's lambda two and we have a function
13081080	13089000	which is just the square root and we know that f applied to lambda one is two and f of lambda
13090200	13096040	two is four now this is not drawn to scale in any way but what we're trying to do is
13096040	13101160	find a polynomial that goes through these two points now you know that two points determine
13101160	13106920	a line so a straight line goes through these two points and that straight line of the form
13107000	13116280	y equals mx plus b so our goal is to find out what are m and what are b such that
13116280	13121000	when we plug in x which is our values of lambda we get the corresponding values of y
13122760	13127800	so this isn't a very difficult problem but what we're going to do is set it up as a linear algebra
13127800	13132760	problem even though you could probably immediately solve for m and b and the reason we'll do that
13132760	13139000	will be made more apparent later when we try to compute f of matrices of larger sizes
13139000	13143640	where it will be more difficult to do the simpler method and it's more reasonable
13143640	13148280	to solve that system of linear equations using techniques of linear algebra
13149880	13157320	so when we set this up we write on this side since this is our y we have m lambda one
13157320	13165400	plus b and this equals m of lambda two plus b and our unknowns are m and b so if we set up our
13165400	13174600	matrix system we get and what i'll do for convenience is i'll put the ones on the left
13174600	13183000	so i'll put my b's on the left column so it's really b plus mx one one and then this is lambda one
13183000	13190600	lambda two and our two corresponding values f of lambda one which in this case is two and four
13193400	13197720	and we know what lambda one and lambda two are they are four and sixteen
13197720	13202920	so really this is equal to one four one sixteen two four
13205240	13211400	and if we try to row reduce this system and solve it what we end up getting is
13212120	13214600	b equals four thirds
13217000	13219560	and m equals
13222040	13232520	one sixth so this line is of the form y equals four thirds plus one sixth x
13233880	13237000	and that's our polynomial this is our q of x
13237080	13247640	and what we'll do in the next video is we will actually apply this polynomial to our matrix
13247640	13254120	and see if it also satisfies the same equation so here's the polynomial that we found
13254840	13263080	as a real valued function in this case and if we wanted to define q of any matrix i'm just
13263080	13269560	going to write a but it's for any matrix a we would the associated polynomial on matrices
13269560	13275880	would be four thirds times the identity matrix which in this case is an n by n matrix well
13275880	13284280	in this case it's two by two matrix plus one sixth a so let's see what happens when we actually
13284360	13289960	compute this so we have four thirds of the identity
13293400	13302440	both along the diagonal plus one sixth of our matrix a so it's 10 over six which is five thirds
13302600	13315160	one one five thirds and if we add these two matrices what do we get nine thirds which is three
13315960	13323720	one one three which is exactly what we found for f of a before so we already know that when
13323720	13331400	we square this matrix we get exactly our matrix a back now let's look at the more general situation
13333160	13341400	so we're going to go back to our setup where we have an n by n matrix a a function f on the
13341400	13351880	set of eigenvalues so we write if a is n by n and lambda one through lambda n are the eigenvalues
13351960	13358520	and f is a function
13361880	13369640	on the set of eigenvalues to let's say the complex numbers we're going to find a polynomial q
13370520	13375960	that first satisfies the initial equation we wrote down for the associated eigenvalues
13375960	13380520	so our goal is to find a polynomial
13384520	13398200	q such that q of when we plug in our corresponding eigenvalues we get f applied to those corresponding
13398200	13405080	eigenvalues and we already know that that's problem will help us solve this one by a
13405080	13410680	similar analysis that's why we're reducing our problem to finding a polynomial on just a finite
13410680	13418120	set of numbers rather than trying to find the answer to our matrix problem and in fact when we
13418120	13423560	look at the degree of this polynomial we notice that it was also matching the degree of the size
13423560	13429480	of our matrix and that's going to be true in general we'll be able to find the polynomial whose
13429480	13438280	degree is at most the size of the matrix that will solve that problem namely q of a equals f of a
13439480	13446200	and why that happens is precisely because of this equation because there are going to be
13446200	13453640	at most n distinct eigenvalues and so we only need to find a polynomial so let me draw this as
13454280	13460760	visually let's just assume everything is real so it's simple to draw this so if we have lambda 1
13460760	13469960	here lambda 3 here lambda 2 maybe another lambda 4 somewhere out here and let's say lambda 2 equals
13469960	13477160	lambda 5 for instance and if we apply f to these numbers let's say they look something like this
13478120	13486600	what we're going to try to do is find the polynomial that fits through these in this case four points
13486600	13493720	and the reason it's four is because two of our eigenvalues are repeated and so we have to find
13493720	13504520	the polynomial through these four points so and if we had n distinct eigenvalues we would have
13504600	13509720	n distinct points through which we would have to find a polynomial sorry i misspoke i think i
13509720	13515720	said degree two i meant degree one because one is the highest power but it starts from zero
13516680	13521720	so in this case we would find a degree in this case we would find a degree three polynomial
13522280	13535080	and in general it would be at most n minus one degree so and again if we have multiplicity
13535080	13540600	that's non z that's um bigger than one then the problem is going to be a little bit easier
13540600	13545560	to solve because we can find a polynomial of a lower degree so let's just assume
13545560	13551160	that all eigenvalues
13554520	13561160	are distinct just it's not it's not actually making our problem easier it's making it a little bit
13561160	13566840	harder because if some of them repeat then the problem is reduced to a smaller and simpler
13566840	13572280	matrix algebra problem so if we assume all the eigenvalues that are distinct we're really doing
13572280	13583480	the hardest case now when such a thing happens we can write our polynomial q of x as a zero plus
13583480	13591240	a one x plus a two x squared all the way up to the highest degree which you know just by
13591240	13597640	looking at the pictures we're assuming it's of the form a n minus one x to the n minus one
13597640	13604680	and if we write down all of these different equations we're going to get another linear system
13605720	13608840	and the unknowns of that linear system are these a's
13612840	13618760	and we know the values of x's those are different eigenvalues and we know the q of those x's are
13618760	13624040	it's f applied to those values so the associated linear system that we get
13624840	13633240	that looks like one ones along the vertical on the left side corresponding to the coefficient
13633240	13639000	in front of a zero the coefficients in front of a one are the different eigenvalues
13643080	13650360	the coefficients in front of a in front of x squared are the squares of our eigenvalues
13654280	13660840	and then the coefficients in front of our highest degree are
13663960	13667640	our eigenvalues to the power of that highest degree
13673320	13679800	and the augmented side of our matrix is the value of those different eigenvalues
13684680	13695000	so our goal will be to try to solve this system well actually our goal is a little bit easier than
13695000	13703320	that the statement of the theorem says that there exists a polynomial q that satisfies the equation
13703320	13709880	q of a equals f of a and so all we really have to do is show that such a polynomial exists
13710760	13718120	so we don't have to solve this solving it is what is q so given a matrix a what is what is q
13718120	13723160	the what is that polynomial q we're just trying to show that one exists in other words what we
13723160	13730200	want to do is answer the question does a solution to this system exist and if we want to know
13730360	13732760	how a solution exists
13736280	13745400	if well if we can solve this system right and one criteria that allows us to solve this system
13745960	13753720	is that if this matrix here which is an n by an n minus what is this an n by n matrix
13754440	13761960	right it's an n by n matrix and if this matrix is invertible and when is the matrix invertible
13761960	13767400	if the determinant of this matrix is non-zero so solution exists if the determinant of
13768280	13772360	this matrix which is called a van der man matrix
13777960	13780840	if this determinant is non-zero
13784680	13791400	so what we're going to do is it's going to be a little bit of a brute force method
13791400	13797320	but we will find one way to compute the determinant of this matrix and therefore
13797960	13802200	show whether or not it's zero and see if we can answer our problem
13804360	13809000	whenever we have a problem with arbitrary n it's a little bit difficult to see what the
13809080	13814600	pattern is without doing an example so i think it's good to try out a simple example
13815320	13823240	or at least somewhat simpler by computing the determinant of the same matrix but where n equals
13824440	13827960	let's say three so we have a three by three
13831480	13836920	and we want to compute this determinant and we want to compute it in such a way
13839160	13842440	so that we can use some of the ideas for computing this determinant
13842440	13849960	and abstract it to that more general case now this isn't the most simplest way to do such a thing
13849960	13855480	but it's one way and i'm sure there are many many other ways to compute this determinant
13856200	13860280	some of which may be certainly more clever than the approach that we'll take
13861720	13864760	so we're going to do this by essentially row reduction
13864760	13871480	and for the first step we're going to get rid of the ones underneath the top left one
13871480	13875720	and by just subtracting the first row from those
13877320	13886200	so if we do that that doesn't change the determinant and we get the top row is left alone
13887080	13895000	and then the rows below it look like zero zero lambda two minus one
13896360	13907080	lambda three minus one and this becomes lambda three cubed minus lambda one cubed uh sorry squared
13909320	13912520	and lambda two squared minus lambda one squared
13916520	13924120	now when we uh lambda two minus lambda one is actually a common factor in this second row
13924120	13927720	because this becomes lambda two plus lambda one when we pull that out
13927720	13935320	and this is lambda three plus lambda one so when we distribute out we get lambda two minus lambda one
13936920	13944280	lambda three minus lambda one times the determinant of what's left over which is one
13944280	13945800	lambda one lambda one squared
13949480	13954920	zero one zero one lambda
13958280	13962840	one plus lambda two lambda one plus lambda three
13965960	13971000	and this happened because the determinant remember when you take the determinant and you multiply
13971000	13976520	any row or any column by a number you can distribute out that one number for that one
13976520	13981000	column in this determinant you can think of the volume if you scale one side of the room
13981000	13985880	by a factor and another side of the room by a different factor then the determinant is computing
13985880	13992520	the area and you scale by both of those but for each side you only distribute one of them
13995720	13999720	so now we're looking at this and we want to compute the determinant of this
13999720	14004600	now of course what's left over is a two by two so it's very easy to compute the determinant
14004600	14009400	but if we wanted to have an inductive proof if we did a similar calculation here for a larger
14009400	14015560	matrix what we would have is lambda one through lambda one to the n minus first power up here
14015560	14019720	and we have a much larger matrix which isn't very easy to compute the determinant of
14019720	14026520	by some explicit formula it's sort of complicated to write so what we want to do is we want to
14026520	14033080	think of how to compute this maybe more conceptually and what we can do is notice that lambda one
14033080	14040360	appears here in each of these two terms and if we multiply the second column by lambda one
14041320	14048360	and subtract what happens is this cancels the lambda one cancels the lambda one cancels and
14048360	14054120	you're only left with lambda two and lambda three and you also don't change the determinant because
14054120	14060040	you're taking one column and adding it to another so this is also equal to
14065080	14067960	the determinant of what's left over after you do that subtraction
14072280	14078520	this is zero zero one zero one and then just lambda two and lambda three left over
14079240	14084920	well you can even do something even a little bit more simpler now now you have a one here
14084920	14089320	you can multiply this by lambda one to get rid of that so i'm not even going to write that whole
14089320	14101880	step out we can just erase this and put a zero here and now here's the amazing part what's left over
14102440	14111320	after you perform these operations is another van der man matrix on the bottom right corner
14112840	14120040	and we can continue this process now because the determinant of this because this is a one
14120040	14126440	is equal to the determinant of this so we've reduced our problem
14126680	14137880	from an n by n matrix to an n minus one by n minus one matrix of the same form
14139880	14145160	and if we keep going down further up until maybe this step or even further than that
14145800	14151480	then we would find out what the determinant of this matrix is so if we did that procedure again
14151480	14155240	of course you can compute the determinant of a two by two no problem but if you did that procedure
14155240	14162600	again subtract you get a zero here move that over you end up getting lambda two minus lambda three
14162600	14170680	it's already of that it already breaks up like that pretty easily and you get lambda two minus
14170680	14179080	lambda three that pops out so you end up getting is the product of i and j let's say i is less than
14179080	14187080	j and j is less than or equal to three and i is greater than or equal to one of lambda j minus
14187080	14194760	lambda i so you actually get the product of the differences of all of these different eigenvalues
14196360	14202520	and because we're assuming that the eigenvalues are distinct all of these numbers are not zero
14203160	14208440	therefore this is not equal to zero and so we automatically know that the determinant of this
14208440	14219080	matrix is non-zero so we can make a guess that the determinant of that more general matrix
14219800	14223640	of that more general van der man matrix
14234280	14239640	is exactly the product of the differences of all of the eigenvalues
14249800	14256120	and therefore is not zero if they're distinct
14259800	14263160	and we can prove this by induction we already know what happens when n equals one
14263960	14270840	or when n equals two and not even n equals three and so what we can do is if we assume that this
14270840	14278600	formula is true for n and go to n plus one then what we want to do is reduce that problem to this
14278600	14285400	one and show that those numbers factor out and then we can apply our induction hypothesis
14285960	14288600	and prove that this formula holds more generally
14292040	14295640	and the way we do that is very similar to this so i'll put a question mark here
14296280	14303080	and i'll write what this equals by doing this first step which was here sorry this first step
14303080	14309160	in subtracting the first row from all of the rows below it what we end up getting is
14310360	14315560	the determinant of and here we have a bunch of zeros below the ones so we have one
14316760	14323560	and i'll write two rows just so we see more of the pattern uh this is a zero sorry zero
14325160	14329320	lambda one and then this is lambda two minus lambda one
14330040	14335000	and this is all the way down to lambda n minus lambda one
14337240	14343880	all the way up to and let me write two additional terms here this is going to be lambda n minus two
14344680	14356680	lambda one n minus one now this is lambda two to the n minus tooth power minus lambda
14357640	14359720	one to the n minus tooth power
14362360	14374040	and here we have lambda n minus one minus sorry two minus one
14374520	14377400	so
14386040	14386600	that's a one
14389720	14390040	okay
14394680	14399960	now at this point we can follow a similar procedure by pulling out a lambda two minus
14399960	14406200	lambda one from each of the terms but then we would have to figure out what is lambda two to some
14406200	14412920	power minus lambda one to that same power divided by lambda two minus lambda one we could do that
14412920	14419240	and factor it out by using um polynomial division find out what the corresponding factors are but
14419240	14424840	maybe that's not the best way to do it another option although that method of course you know
14424840	14429000	teaches you a lot about how to do polynomial division in case you haven't seen it before it's
14429240	14435480	quite nice but maybe there's another easier way similar to what we did over here and what we did
14435480	14441560	here was we took the second last column and we multiplied it by lambda one and we took the
14441560	14446360	difference here we could have also done that in this step it just might have been a little bit it
14446360	14450840	might have looked a little bit more complicated because of the higher powers but let's try to
14450840	14460760	do that anyway if we multiply the second last column by lambda one from the last column
14462280	14467480	the power here will be n minus one which will match this one and these two terms will cancel and
14467480	14474120	you'll just get zero what happens to this term if you multiply this by lambda one so let's write this
14474120	14481640	out so we have lambda two n minus one minus lambda one to the n minus one minus multiply this whole
14481640	14492360	term by lambda one that becomes a plus lambda one to the n minus one and then what's left over is
14492360	14499720	minus lambda one lambda two to the n minus two these two terms conveniently cancel and what
14499720	14511480	you're left over with is lambda two appears the highest common factor is lambda two to the n minus
14511480	14519480	two so we can pull that out and what's left over after we pull that out is lambda two minus lambda
14519480	14528120	one and therefore we can much more easily see that this factors out after we do this subtraction
14528920	14534840	now we've done imagine we've done that for the last column here now we have this second last
14534840	14539240	column which still has all of these complicated terms but what does this term before it look like
14541320	14550280	lambda one to the n minus three and then it's lambda two to the n minus three minus lambda one
14550280	14557560	to the n minus three so you can just see it's of the form n minus j and if we multiply this by
14557560	14563960	lambda one and subtract it well these two terms will cancel and a similar thing will happen here
14563960	14569960	it's just that the power will now be not lambda two to the n minus two but lambda two to the n minus
14569960	14578200	three after we take this difference and so if we keep going in this direction taking all of those
14578280	14584440	successive differences we will be left over with so this determinant equals
14587160	14596520	the product of lambda j minus lambda one and j goes from two to n
14597080	14606680	and we're left over with the determinant of
14607720	14615240	a smaller bandermen matrix which looks like one zero zero and this term is one
14616280	14621640	and it's all the way one's all the way down let me write just the first and last ones
14622520	14626920	we also have zeros here up to the last term
14630120	14635400	now what is this term here it's lambda two to the n minus two now
14637560	14644920	all the way down to lambda n to the n minus two and if we assume the induction hypothesis
14644920	14650680	then we know that the determinant here is the product of lambda let me use a different letter k
14650680	14659160	and l so k minus l where k is greater than strictly greater than l and l runs from this
14659160	14669400	time two to n and and and k so we end up getting after all of this work by using that induction
14669400	14675640	hypothesis we get that this is this expression right here
14681320	14687160	and in particular this says that our determinant is non-zero so we can compute the inverse of
14687160	14694520	this matrix if we wanted to now that we have all of this set up we can prove our main theorem
14695240	14708040	which remember said that given any diagonalizable matrix a there exists and a function f on its
14708040	14718360	set of eigenvalues there exists a polynomial q such that q of a equals f of a and so far
14718920	14729800	based on the facts that we just proved we know there exists a polynomial
14733160	14742920	q such that q of lambda i equals f of lambda i for all of the eigenvalues
14743560	14747800	of that matrix therefore
14752280	14761880	if we compute f of d which was defined to be f of lambda one f of lambda n
14762200	14773560	of our diagonal matrix d then this is the same exact thing as q of lambda one
14775320	14783560	q of lambda n with zero everywhere else by this result we can find a single polynomial q that
14783560	14798920	satisfies this but this is exactly the same thing as q of d well why is that well if we
14798920	14805960	write our diagonal matrix d out and we apply the polynomial q to it right so let's just see why this
14805960	14816760	is true if we take our diagonal matrix and then we plug in our polynomial so we had what was it
14816760	14825640	it was a zero times the identity n by n matrix this is what if we view q as a polynomial and we
14825640	14835400	plug in the formula for q of d this is by definition of a matrix applied to a polynomial
14836280	14847960	sorry a polynomial um with input a matrix plus a1d plus a2d squared plus a n minus 1
14848840	14855320	d to the n minus 1 and we know what this looks like as a matrix this is the identity
14855320	14859560	it looks like a zero all along the diagonals
14862040	14870280	and zero everywhere else this is a one times lambda one all the way down to a one times lambda
14870920	14880600	to the n lambda n and then here we have plus a2d squared now d squared since d is the diagonal
14880600	14888600	matrix is just lambda i squared in each of the diagonal terms so it's a2 lambda one squared
14889320	14895240	all the way down to a2 lambda n squared and similarly for all of the other terms
14896280	14901640	up until this last one then what happens when you add all of these matrices together well you get
14901640	14907800	a zero on the top left term you get a zero plus a1 lambda one plus a2 lambda one squared plus dot
14907800	14914680	dot dot a n one minus lambda one to the n minus one that's exactly what q of lambda one is
14915640	14921560	and similarly for all of the other terms so this justifies why this equality holds
14924360	14932440	and of course q of any matrix is defined similarly so in particular q of a equals a zero times the
14932440	14943640	identity plus a1 times a plus a2 times a squared and so on so now let's show that f of a equals q
14943640	14955000	of a now f of a by definition of f of a is p times f of the diagonal matrix times p inverse where p is
14955000	14962360	the matrix of eigen vectors corresponding to those eigen values is a matrix of eigen vectors
14964200	14969720	now f of d by this calculation is also q applied to d
14975240	14977720	and so that equation is true by what we just showed
14977720	14984360	now we know what q of d looks like it looks like this and we also know what happens when
14984360	14995160	we distribute p throughout so we get something that looks like a zero p times p inverse plus
14995720	15010040	a1 pd p inverse all the way up to a n minus one pd to the n minus one p inverse
15012360	15017400	that's just what that looks like when you distribute p and p inverse on both sides
15017880	15029720	now this is a and what is this expression and likewise for all of the terms in between well
15032520	15039240	let's just let's just look at what happens if we um if we set f n is like three or something like
15039240	15048040	that or maybe even two is enough um so let's look at this term p d squared p inverse so p
15048760	15060680	d squared p inverse also equals p times d times d times p inverse and because p and p inverse are
15060680	15068520	well inverses of each other we can plug in a p inverse p between these two d's and
15069480	15081400	this gives us p d p inverse times p d p inverse again and this is just a and this is just a
15082040	15089320	so we get a squared therefore when we actually write out what all of these things equal we get
15089400	15099320	a zero p p inverse plus a one which is the identity sorry this is the identity matrix
15100280	15110200	and this is a plus a two a squared plus all the way up to a n minus one a to the n minus one
15110280	15122280	and this is the definition of q of a so this shows us that that theorem is true
15124600	15126440	so this has an interesting corollary
15131160	15133000	so let a be diagonalizable
15133560	15142840	and let b be any square matrix of the same size
15149400	15151000	and suppose that they satisfy
15155480	15159880	the fact that when we multiply them in any order they're equal to each other
15163080	15167320	then f of a
15169800	15175880	b equals b f of a for all functions
15178360	15184120	that are defined on the eigenvalues of a
15184120	15188120	and how do we prove this
15190040	15199720	well because a is diagonalizable then f of a equals q of a for some polynomial
15203880	15213320	q and because it's a polynomial if we replace this expression with q of a times b
15214840	15224680	so if we have q of a times b this is a polynomial in a and each of the terms look like
15225320	15228280	a to the jth power times b
15230760	15235720	right so you have a to the jth power times b now a to the jth power means you write the
15235720	15241960	matrix a j times and if you have a b on one side you can use this to move each of those a's
15241960	15245560	one over at a time you can move them over one at a time
15246280	15251960	therefore a j a to the jth times b equals b times a to the jth therefore
15253080	15261560	it's immediate that this equals b times q of a and it immediately solves this problem because
15261560	15269080	q of a equals f of a and the interesting thing about this is that b can be any matrix whatsoever
15269080	15272120	and a only has to be diagonalizable for this to be true
15274520	15282840	so hopefully this is an interesting fact namely that given any function at least that's defined
15282840	15290520	on the set of eigenvalues of a it could be defined on a larger set of the subset of the complex numbers
15290520	15296840	but at the very least if it's defined on those eigenvalues then we can always find a polynomial
15296840	15305080	for which when we apply that function which could be completely wild such such as the
15305080	15311400	logarithm or something like that then there's a polynomial that gives us the same value for that
15311400	15317160	matrix if we apply the polynomials of the matrix versus if we apply the function to that matrix
15319240	15325560	and a lot of this has to do with the fact that we're working with finite dimensional matrices
15327000	15333160	one of the interesting things about linear algebra is what happens when your matrices become of
15333160	15340120	infinite order and then this really becomes a much more subtle issue and clearly the method that we've
15340120	15344760	used should probably break down for instance we're not working with polynomials anymore
15345400	15350840	and a lot of this is explored for instance in functional analysis and spectral theory
15351640	15354840	and the functional calculus for such operators
15357080	15363960	in these next few videos we'll learn about affine subspaces affine combinations and affine
15363960	15369640	transformations which are very slight generalizations of linear transformations as we'll see
15371240	15377320	so the first definition that we'll need is what an affine combination of vectors is
15377560	15384120	so but to do that we'll recall what a linear combination is so a linear combination
15388760	15400360	of vectors v1 through vk in rn is a combination of the form
15407480	15417560	lambda 1 v1 so we add up all our vectors with some weights and these weights
15418600	15420360	will take to be real numbers
15423720	15425720	so that's what a linear combination is
15428200	15434600	and closely related to this an affine combination
15437560	15439880	of these same vectors
15447000	15448280	is a linear combination
15452440	15457480	and for short I may often write just using the summation notation
15457880	15468040	oops let's call this not k but j and this goes from j equals one to k
15471560	15477560	such that the sum of these coefficients is equal to one
15480760	15486600	so it's basically a linear combination but we have an additional constraint on the
15486680	15496360	coefficients so for example when k equals two we have two vectors let's say v1 and v2
15498360	15509320	then every such affine combination is of the form t v2 plus one minus t v1
15509320	15518200	where t is a real number and you can look at what this says let's say these two vectors are
15518200	15527560	different let's say v1 is here and v2 is here then at t equals zero so this right this is
15527560	15534520	describing the set of all such combinations and when t equals zero this gives me v1 so at t equals
15534520	15544040	zero i'm here and when t equals one i'm at v2 and as you vary t over the set of real numbers
15544680	15553320	you get all the points along the straight line through v1 and v2 this is very different than
15553320	15559240	the set of all linear combinations of v1 and v2 because if let's say the zero vector were here
15559240	15567800	then v1 would be this corresponding vector v2 would be this corresponding vector and all
15567800	15576200	linear combinations of these two vectors is actually the plane obtained from v1 and v2
15577880	15584200	that's what the span of these two vectors are but all affine combinations is just this line
15584840	15593720	and so just like we can define the span of vectors we can also define the affine span of vectors
15594520	15597800	so the affine span
15601720	15608200	of the vectors v1 through vk is and we denote it by aff
15608200	15620200	and it's defined to be the set of all affine combinations so the set of all
15622440	15633960	lambda j vj such that all of the lambda j's are in r and the sum of them equals one
15638440	15648680	so let's look at another example where we take three vectors so let's say v1 v2 v3
15650120	15655080	and let's just be concrete and let's say we're in r3 so that we can visualize this a little bit
15655080	15664040	better so there are several cases that we can take just like for linear combinations for instance if
15664040	15668120	one of these vectors was a linear combination of the other then the span of this would be a plane
15668520	15672120	and if all of them are scaled on multiples of each other then the span is a line
15672680	15678520	and if they are all the zero vector then we just get the zero vector and if they're all
15678520	15682520	linearly independent then we get all of r3 there are many different cases depending on the
15682520	15689240	relationships between v1 through v3 same thing happens for affine span in the sense that it
15689240	15693080	depends on how these vectors are related so let's look at three possible cases
15693880	15699400	so case one let's say v1 v2 and v3
15701480	15711080	are not collinear so this means that all these three points don't lie on the same line so maybe
15711080	15717080	they look something like this like for instance you can take the unit vectors e1 e2 and e3 and r3
15717320	15728200	then the affine span of these three vectors is equal to the two-dimensional plane
15731960	15735960	containing these vectors
15741000	15744520	and it's not so immediately obvious that that's what happens but let's just
15745160	15751400	think about this if we take v1 and v2 then it includes the affine span
15753240	15760840	of these two vectors which means we have this line through these two vectors is in our affine span
15760840	15768600	and likewise the line through v2 and v3 is here likewise the line v1 through v3 is here
15769720	15774040	and now that we have all of these lines in here we can also take affine combinations of these points
15774600	15777720	so you can take for instance the affine combination of this point with this point
15777720	15782360	which gives us this line this point with this point which gives us this line
15782360	15786360	and you can see by taking all such combinations all such affine combinations
15786360	15793000	of these three vectors we can actually get any point in the plane that contains these three points
15793240	15797480	in case two
15800040	15803960	let's imagine that v1 v2 v3 are collinear
15808040	15808280	but
15811240	15812040	at least two
15815560	15816280	are distinct
15816680	15826120	so in this case so i'm assuming that at least two so either the possibilities are something like
15826120	15832120	they're all different but they lie on the same line in which case the affine span of these three
15832120	15839400	points is equal to the straight line through those two points those three points or the other
15839400	15846040	cases the affine span if two of them happen to coincide then we just have two points
15846920	15852360	but i'm assuming that they're collinear and at least two are distinct so we also get the
15852360	15858360	straight line through those two points and the final case case three
15860680	15864600	is when all those vectors are exactly the same vector
15865240	15874600	and when this happens we only have a single point and all affine combinations of a single point
15879320	15884840	is just that point itself so these are some of the basic constructions that you can do with
15884840	15890120	vectors besides just taking linear combinations you can also take affine combinations there's yet
15890120	15896200	another type which we won't discuss is if you require that the sum of these coefficients adds
15896200	15903240	up to one but they're also not just real numbers but they're strictly non-negative so they have to
15903240	15909160	be at least zero and that's called a convex combination which is a closely related idea
15910440	15916760	and in the case of these three vectors for instance it would be the triangle
15917640	15926920	who's three vertices are those three vectors that we had here and in this case if we took
15926920	15935640	convex combinations it would be the interval between these two farthest end points and in this case
15936760	15941560	we would have the same situation as we had here where we would just get a single point
15942440	15949720	a common question that we ask given a set of vectors is if we have another vector when is
15949720	15955800	that vector in the span of those vectors and this shows up for instance if we solve a homogeneous
15955800	15962120	linear system and we have a bunch of solutions that we know are actually solving that system
15962120	15966680	but let's say we don't know exactly what that system is we just know we have this collection of
15966680	15972760	solutions and if somebody hands us another vector then we can ask is that vector
15973720	15979080	a definitely a solution of the system that we have and in this case since we don't know the
15979080	15985400	system we can't plug in that vector to check instead what we have to do is check if that vector is
15985400	15991400	in the span of the vectors that we have already if that vector is in the span of the vectors that
15991400	15998440	we already have then that vector is definitely a solution but it doesn't tell us that if it's not
15998440	16002120	in the span of those vectors and it's not a solution because we might not have had
16002920	16007480	a set of vectors that span the solution set but at the very least it gives us a criteria for
16009480	16016360	guaranteeing that if that vector is in the span it's definitely a solution and likewise you can
16016360	16022680	ask well if I have a bunch of vectors that I happen to know solve an inhomogeneous equation
16022680	16028520	and somebody hands me another vector is there a similar criteria and there is and that involves
16028520	16035080	the notion of affine span which we talked about in the last video so the question that we could
16035160	16046200	ask is given vectors v1 through vk and another vector u in rn
16048280	16058440	when is u in the affine span of these vectors v1 through vk
16059320	16067560	now in order for us to solve this problem then we have to be able to write u as a linear combination
16069800	16080920	of v1 through vk right but because it's an affine combination we have an additional
16080920	16087720	constraint on what these coefficients could be and that constraint is that lambda 1 plus lambda k
16089320	16096120	equals 1 which is also a linear system in the unknowns lambda 1 through lambda k
16097000	16102360	and therefore if we want to solve this system this question is equivalent to
16109160	16117240	the following one which is is the augmented matrix where we take our vectors v1 through vk
16118520	16124600	and we can also write vk through vk through vk through vk through vk through vk through vk
16124600	16130840	augmented with the vector u but in addition augment this further by one additional row
16131480	16139880	stating that one equals so now this is the number one equals one dot dot dot one let me write this
16139880	16144920	one so it's clear so this vector is just denoting the fact that it could have several entries
16145880	16151480	so we have an additional row in our augmented matrix and the question is is this consistent
16156120	16159560	so this is actually how we would solve such a problem and
16161960	16167400	how does it show up in solving inhomogeneous systems we'll get to that after we talk about
16167400	16173080	what an affine subspace is and the fact that the solution set of an inhomogeneous system
16173080	16178440	is an affine subspace so for this let's just briefly recall
16181480	16188760	a vector subspace i'll put vector usually in parentheses but a vector subspace
16190280	16198120	of our n is a first of all a subset let's call it v
16198520	16206200	such that three conditions hold now there are many equivalent ways to define such a thing
16206200	16213640	but this one seems pretty concise and simple and the first condition is that the zero vector is in v
16215960	16222440	the second condition is that if you take a vector in v and you scale it by any number
16222440	16231160	then that scalar multiple is also in v so lambda v is in v provided that the vector v was in v to
16231160	16241880	begin with and lambda is a real number and three the third condition is that if i take any two
16241880	16250760	vectors in v then the sum of them are in v so let's write u plus v is in v for all pairs
16250760	16257400	u and v that are already in v and this is what a vector subspace is
16260760	16267800	now this definition of a vector space is a little bit algebraic it's telling us when
16267800	16273400	certain vectors are in v and we can have a little bit more of a geometric interpretation of a what
16273400	16286280	a vector subspace is by using affine combinations so equivalently v satisfies
16288120	16291800	which means that if v satisfies the following conditions i'm about to write then it satisfies
16291800	16299080	this one and conversely let's call it instead of i and two so let's use i because the first one's the
16299080	16305320	same the zero vector is in v and the second condition which is sort of a combination of these
16305320	16320040	two is that t u plus one minus t v is in v for all t in real numbers and for all u and v in v
16322040	16327480	now this is exactly a linear combination of the vectors u and v so if i take two vectors u and v
16328280	16333480	inside of v then this affine combination is describing the set of all points
16334280	16339960	along the straight line through those two vectors so this is saying that a subspace
16340520	16348120	can also be described as a plane that contains the zero vector and plane could mean hyper plane
16348120	16352760	and this is because we always have the straight line through any two points in our subspace
16353320	16358920	now the fact that we've written it this way allows us to define an affine subspace
16359640	16365240	in a much more closely related fashion to this definition because for an affine subspace we'll
16365240	16373240	only be able to combine combine vectors in an affine way so we define an affine subspace
16373800	16388920	is a subset a of r n such that and now we drop this first condition so all we require
16388920	16396600	is that affine combinations of two vectors are always inside so t u plus one minus t v
16396600	16401320	are in v for all same conditions as here
16404280	16409400	and you can ask well maybe an affine subspace should be if i take any collection of points
16409400	16415720	inside of it then the affine span of those points is inside of v and that actually follows
16415720	16421560	from this condition and the usual properties of scalar multiplication and vector spaces
16421560	16430840	and how you add them so the main example that we want to illustrate is the solution set
16434200	16442440	of any linear system ax equals b this is just notation for a linear system where b
16443240	16455960	is a vector in r m and a is an m by n matrix
16459240	16464040	so the solution set of this is an affine subspace
16464360	16471000	of r n
16474360	16479960	now the solution set of an inhomogeneous system is not a vector subspace because in
16479960	16487160	general zero is not a solution in fact when zero is a solution then it exactly is a subspace
16487160	16492040	and when zero is not a solution we get this more general notion of an affine subspace
16492600	16494760	and it's a fact
16497960	16500120	that affine subspaces
16504680	16505800	are translates
16509160	16510920	of vector subspaces
16517000	16518280	and what do i mean by that
16522200	16528280	a is an affine subspace
16532680	16541960	if and only if there exists a vector v in r n such that if i take the subs
16541960	16550280	if i take this affine subspace a and subtract v from it now what this means is the set of all
16551000	16555720	vectors of the form u minus v where u is in a
16561240	16566840	if this subset of r n is a subspace
16569320	16571560	in this sense is a vector subspace
16577000	16577720	in fact
16581240	16590760	we can use any vector inside of a to translate it to the origin so in fact v
16593960	16600840	will be a vector in a in fact any vector in a will make this a vector subspace
16601880	16604600	so the picture for this is actually really nice
16604760	16612520	i guess i shouldn't have called it a because i called this linear system a that may be
16612520	16620200	potentially confusing so maybe let's call this script a so let me use a script a here
16622680	16631000	and fortunately the letter a was only used in this one example but let me write it like this here
16631000	16636120	so it's the same so there's no conflicting notation
16638520	16648360	okay so here's our affine subspace a and if we take any vector in here let's call it u no let's
16648360	16658280	call it v so v points from zero up to where that vector is and if we take this vector and we
16658280	16667320	subtract it then v minus itself will be zero so i know that this plane is going to contain the zero
16667320	16676680	vector and so here we have a minus v and no matter which v we picked right if we picked another one
16678920	16685320	let's say we picked this vector right here let's call this one u then if we translate that
16685320	16689320	u minus itself is zero so we also get this plane back as well
16692920	16695240	and so a good application of this
16698520	16702840	of this sort of mathematical object is
16703720	16717480	if the vector xp p for particular is a solution to ax equals b for some linear system like in the
16718200	16730600	previous example then the solution set meaning all the solutions of ax equals b
16733080	16740840	is as we know the particular solution plus the homogeneous solution set so it's a set of all
16741560	16750760	all sums of particular solutions with homogeneous solutions so axp solves the system this and
16753320	16763000	ax homogeneous solves the associated homogeneous system so if a represented the solution set
16763000	16769480	of an inhomogeneous system and a minus v represents the solution set of a homogeneous system and all
16769480	16775880	we have to do is pick one of these solutions and then all of these solutions and then take that
16775880	16783480	solution and translate it by that vector which was a particular solution of the inhomogeneous system
16785320	16790520	just as we can define linear transformations which are functions that take linear combinations
16790520	16795400	to linear combinations we can also define affine transformations and the idea is that
16795400	16801000	they take affine combinations to affine combinations which translates geometrically to
16801000	16808360	it takes lines or hyperplanes to other lines and hyperplanes as well so the definition
16809400	16812360	of an affine transformation is exactly that
16812520	16832120	an affine transformation in this case from rn to rm is a function first and foremost
16833000	16840680	and i will write my arrows as usual from right to left so it's a function let's call it s
16842840	16843480	such that
16846920	16863000	s of lambda u plus 1 minus lambda v is equal to lambda s of u plus 1 minus lambda s of v for all
16863400	16877880	u and v in rn and for all lambda in r and it's a consequence of this definition that if we take any
16877880	16883480	affine transfer if we take any affine combination of vectors then s of that affine combination
16884440	16885240	is going to be
16887720	16891560	the affine combination of s applied to each of those vectors
16893480	16911160	this is a little less obvious than it is if you take linear transformations and you show that
16911160	16916120	it follows from the assumptions of a linear transformation that it takes linear combinations
16916120	16924040	to linear combinations and the reason it's a little bit slightly more challenging is that
16924040	16929480	if you apply this in a binary fashion right if you take two vectors u and v so you think of this
16929480	16937560	as a function from let's say r cross r to the n cross r to the n to r to the m then in order to
16937560	16943000	apply this here you have to put parentheses in an appropriate place but in order to have an affine
16943080	16948200	combination with the appropriate parentheses you have to be a little bit careful about what
16948200	16954040	your resulting coefficients are and it's not so easy to see how to do that but it can be done
16957800	16962760	and here's the example that I really like to think of when comparing linear transformations
16962760	16969960	to affine transformations and things you might have seen from a while back not in my lectures but
16969960	16977240	in your early learnings of math perhaps so if we take the usual equation of the form
16977240	16986040	y of x equals mx plus b where m and b are both real numbers and x is a variable
16987480	16991880	and y is the function of x then this is an affine
16991880	16996120	transformation
16998600	17005960	from r to r because it takes a real number r x and it gives us another real number
17007640	17008680	and it's linear
17013000	17019240	if and only if b equals zero linear in the sense of being a linear transformation
17019240	17026760	so this will help you perhaps relate the difference between an affine transformation
17026760	17032360	and a linear one and we'll later talk about a theorem that relates the two exactly together
17033720	17042840	in fact we'll state that theorem now so the theorem says the following are equivalent for a function
17045880	17047320	now we're just describing a function
17049800	17057640	and these conditions are that s is affine is an affine transformation
17059800	17063960	so i'm not assuming any linearity this is just an ordinary function so s is affine
17065560	17076120	if i take the function s and subtract s of zero from it so if i take s minus s of zero
17076120	17080920	now this is a function in the sense that if i take any x the function associated to this is
17080920	17090360	defined by s of x minus s is s of zero so this is also a function from r into rm if this is linear
17090680	17093480	and c
17096120	17099000	there exists an m by n matrix
17102600	17106280	m and a vector b
17110040	17117800	in rm such that s of x equals mx plus b
17120680	17127160	and the reason i mentioned this example is precisely because of this theorem because it allows us to relate
17129160	17134280	linear transfer affine transformations to transformations that we may have seen a long
17134280	17140680	time ago and i personally think it's instructive to prove this theorem to get a feeling for how
17140680	17147880	affine combinations work so let's actually prove it and we'll prove this by proving a implies b
17147880	17156120	implies c implies a so for the first part of this proof we're going to define we i don't want to
17156120	17164040	keep writing s minus s of zero so we're going to define l to be this function s minus s of zero
17167400	17173080	and the goal is to prove that this function is linear so we have to check the associated
17173080	17180280	conditions for linearity and before we do that let's just establish that if we apply zero to l
17180840	17186280	if we apply l to zero then we get exactly zero because this is s of zero minus s of zero so it
17186280	17192120	definitely preserved zero and we know that this doesn't give us a sufficient condition for linearity
17192120	17201480	but it's definitely necessary so second if we take a coefficient lambda any real number lambda
17201560	17210520	and if we take a vector u that's inside of our n then by this definition this is s of lambda u
17211560	17224120	minus s of zero and this is an interesting combination of lambda u and zero this also
17224120	17233560	equals s of lambda u plus one minus lambda of the zero vector right the zero vector is in the domain
17233560	17239400	of s and so i can multiply by any number and i still get zero and now the interesting thing
17239400	17244600	about this is that this is an affine combination of the vectors u and zero so that's what this
17244600	17251960	term is and this just comes along for the ride because s is affine i can take these coefficients
17251960	17255720	out
17259320	17267960	and this is also an affine combination of itself so i can write minus lambda s of zero
17268840	17272120	minus one minus lambda s of zero
17275000	17280360	and so what do we have we have lambda of s of u in parentheses minus s of zero
17280440	17285800	which is exactly l of u and these two terms cancel so we're left over with lambda
17287080	17293000	l of u when we're done with this calculation so it's linear in this it's the first condition
17293000	17297880	of linearity is proven and the second condition is if we take a linear combination
17299880	17306040	this also has to go to a linear combination as well so let's just use the definition this is s of
17306040	17315000	u plus v minus s of zero and now let's draw a picture here because this is going to help
17315000	17321720	let's say we have the vector u here and the vector v here and this is the zero vector
17323240	17328280	now the vector u plus v is somewhere here
17329240	17340040	now can we express u plus v as some convenient affine combination of vectors for which we know what s
17340040	17349640	does to those vectors well if we extend u so we take combinations of u and combinations of v
17351000	17356120	then u plus v can be written as an affine combination of some multiple of u and some
17356120	17360760	multiple of v in fact it can be written like that in many ways all i have to do is pick any
17360760	17368520	point here and draw the straight line through this point and u plus v and then find out what
17368520	17375160	that vector is or we can take a simple shortcut and just notice that if we multiply this by two
17376120	17378200	this by two then
17381320	17389000	those two points to u and to v are on the same line that goes are on the line that goes through
17389000	17394920	u plus v and how do i know that well if i take half of this and half of this i get exactly this
17394920	17405480	and half and half is an affine combination so this equals s of one half to u plus one half
17405480	17414680	to v minus s of zero and because this is an affine combination we have one half s of two u
17415080	17424600	plus one half s of two v and now we can also subtract half of s of zero here
17427480	17435160	minus one half s of zero again and now one half is a common factor here so this gives us one half
17435880	17447000	l of two u plus one half l of two v but by the thing we just proved we know that we can pull out
17447000	17457480	scalars from l so this gives us l of u plus l of v and this together proves the linearity
17457480	17463720	so this is the proof that a implies b but if we have an affine transformation we subtract
17463720	17470440	by what it applies to when you plug in zero then we get a linear transformation now the rest of
17470440	17482920	the proof is actually not bad afterwards because for b implies c if we have a linear transformation
17482920	17488440	we already know we have a matrix corresponding to it so because l is linear
17489320	17494360	we get an m by m matrix
17498680	17500840	such that l of x equals m of x
17503080	17509960	equals m times x for all x in the domain of s which is r n
17510600	17527240	so set b to be equal to s of zero and when we make when we set that to be that then since l is
17527240	17537720	s minus s of zero then we take s equals l plus s zero which is b then we get y then we get the
17537720	17545560	equation of the form s of x equals m x plus b so that that's what how b implies c and then
17545560	17551000	if we have c to imply a this is much much it's very similar to these kinds of calculations of
17551000	17560520	taking affine combinations if we take s of like let's say lambda u plus one minus lambda v plug
17560520	17565400	that in here we know m acts in a linear way this is a matrix we apply matrix multiplication
17565400	17570920	distributivity associativity of all these properties of addition of vectors and scalar
17570920	17579880	multiplication of vectors in r m and we get that s is affine from this assumption so these three
17579880	17587720	conditions are equivalent for any function from r n to r m that characterize what it means for
17587800	17595400	transformation to be affine as we know functions can be composed provided that the domains and
17595400	17602280	codomains of these functions match up similarly affine transformations compose and the composition
17602280	17607720	is affine in an analogous way to how linear combinations are composed and the resulting
17607800	17619080	composition is also linear so we have a fact and this fact is that the composition
17630280	17633560	of two affine transformations s and t
17637880	17642600	is also affine
17648920	17654680	and because it's affine and we know that each of these transformations can be written in the form
17654680	17660600	of mx plus b for some appropriate matrices and appropriate vectors b we can ask what is the
17660600	17666920	resulting matrix for what is what are the resulting matrices and vectors for the composition
17667000	17683800	of two affine transformations so let's write s of x as mx plus b and t of y as nx plus ny plus c
17688760	17695800	and let's just be careful about composing these so if we take the composition s composed with t
17696920	17703160	and we apply a vector y then this by definition is s applied to t of y
17705880	17707480	and we know that t is of this form
17711400	17712920	so we get ny plus c
17713560	17725800	and this equals m times the input of this function which is ny
17730040	17736360	plus c plus the associated b oh this should be a plus from the transformation s
17737080	17741720	and if you distribute this all out we get mn
17746360	17747000	times y
17749320	17759000	plus mc plus b so the associated matrix that we get is actually just the multiplication of
17759000	17765560	the matrices that we started with and the associated vector b is some interesting combination
17765560	17773560	of the original vectors b and c but also with the matrix m and in particular
17779720	17790840	if s from same setup rm rn to rm is invertible
17791560	17799240	and we wrote our decomposition like this then we could ask what are the matrices and vectors
17799240	17804520	associated to the inverse of this matrix and that is exactly
17807800	17811400	so s inverse let's write of y just because we're changing the
17812200	17820520	codomains with the domains we get the inverse of m plus well rather minus
17821320	17828840	m inverse of the vector b and why does this work well if you just take s for instance and you
17828840	17833880	apply it to this result we know what this combination looks like we get m applied to this term which
17833880	17839480	gives us just y back m applied to this term which gives us negative b but we have a plus b and those
17839480	17846840	two cancel so just like the composition of linear transformations need not commute similarly the
17846840	17851560	composition of affine transformations need not commute so let's look at an example
17854120	17861080	and a common affine transformation is leave everything alone just translate by some vector
17861080	17865480	so let's just keep things very simple and let's assume that we translate by the vector
17865480	17868360	one zero so we shift everything along the x axis
17870760	17877160	in r2 so we shift everything along the x axis so let's say the vector let's draw a smiley face here
17878600	17883320	this smiley face transforms under this transformation let's say smiley face is it
17883320	17888200	contained in the unit box so i have to make this a little bit bigger and it gets translated along the
17888200	17893400	x axis in the positive direction so let's call this transformation t
17895480	17899080	another transformation that we can look at let's call this one s
17901320	17909080	is rotation by 90 degrees so when we rotate the face looks something like this
17910600	17917000	and then we can ask what happens when we apply s and t in that order or if we apply t then s
17917720	17921560	and what are the matrices and vectors associated to these transformations let's actually answer
17921560	17929560	that question first so t of any vector x equals well it's just translate so it says
17929560	17935480	leave everything in the plane alone so that's the matrix corresponding to the identity and
17935480	17942520	shift by the unit vector in the x direction so i call that e1 so remember e1 equals the vector
17943480	17954200	1 0 and s of x is the transformation that rotates by 90 degrees so i'm going to write
17954200	17963080	that in matrix form because rotation by 90 degrees is 0 negative 1 1 0 applied to the
17963080	17969640	vector x and the b here is 0 because this is in actually this is actually a linear transformation
17970600	17978680	so what happens when we compose these in different orders so let's just think about this imagine
17978680	17987320	you translate first and then you rotate this rotation is occurring about the origin so when
17987320	17994120	we apply t first and then we apply s again we're rotating this picture by 90 degrees with respect
17994120	17999160	to this origin so this face is actually going to be further out than it would have been if we
17999560	18004280	applied the transfer if we apply the rotation initially and then translated you can already
18004280	18014120	see the big difference between these two pictures so if we apply first t and s apply to this picture
18014120	18021480	let's start with our initial configuration that what happens after you apply this will first you
18021480	18027400	rotate and then you translate so this translates everything to something that looks like this
18027560	18036120	but if instead we applied s after t to the same initial configuration
18038360	18043080	well first we would translate and then we would rotate by 90 degrees that would look
18043080	18046600	much much different so if i were to draw this as a unit grid
18048760	18054680	that face would now be in this box rotated by 90 degrees so it looks something like that
18054680	18061800	so now let's just check the math out to make sure that this is consistent with these geometric
18061800	18068760	interpretations so if we apply t after s to any vector x
18071560	18079320	what do we get well t says first translate then rotate so we end up translating by x
18079880	18089320	then rotating because we do matrix multiplication and the resulting vector b is just e1 so we get
18089320	18100280	rotation apply to x plus e1 which is exactly what we expected from our picture here if we did it in
18100280	18109960	the other order well in that case first we translate and then we rotate and when we rotate
18109960	18114920	we not only apply the rotation to our initial vector x but we also apply the rotation to the
18114920	18123000	vector e1 and e1 gets rotated by a 90 degree rotation to the vector e2 so in this case we get
18123560	18136680	this instead so and this is consistent with this picture because if we rotate first our face ends
18136680	18141160	up somewhere here like in this picture and then how do we get from this picture to this one we
18141160	18150360	translate up by a unit vector by the unit vector e2 the next few videos are going to be a sort of
18150440	18157800	combination of probability theory and matrix algebra and we'll start by talking about finite
18157800	18162760	sets and stochastic matrices or what I call stochastic maps and we'll try to get through
18162760	18170040	a lot of interesting topics so first I just want to make sure that we have all these definitions
18170040	18175800	at hand and the first one that I want to make is a probability measure
18179720	18186680	and for simplicity we will be working with finite sets all the time so a probability measure on x
18186680	18198040	where here x is a finite set is a function that takes every element of x and it gives me a number
18198440	18203800	and that number is between 0 and 1 and the sum of these numbers
18208040	18213800	when I sum over all elements in x and let me just set notation that when I apply this probability
18213800	18220840	measure to x instead of writing p of x I will write p subscript x so such that the sum of these
18220840	18229000	numbers equals 1 and a stochastic map is something very similar to this
18238120	18242760	ah and let me even set some more notation the set of all probability measures
18242760	18255880	on x is denoted by px
18258200	18267720	so a stochastic map from x to y so another finite set is a function
18267720	18281000	from x to probability measures on y let's call that f and
18283400	18288760	we're going to introduce a convenient notation for such stochastic maps
18290200	18296280	so first let's explain a convenient notation for how to write f so if we take an element x
18296280	18302760	and we apply it we'll get a probability measure on y for now let's just call this f of x
18303960	18308920	because this is a probability measure it takes an element y and y and gives me a number between
18308920	18321720	0 and 1 so this takes an element y and maps it to f of x of y now it's a little bit annoying
18321720	18326680	to write something like this and potentially confusing so instead of writing this we will write
18327720	18335240	f subscript y x and the reason we write the y on the left is because we will end up in y
18335880	18340840	and x on the right because we started in x we'll see why this is convenient in a moment when we
18340840	18347880	talk about composition of stochastic maps and we'll also introduce graphical notation for this
18352680	18359640	instead of writing a map from x to py we will replace this by a map from x to y
18360680	18367320	but we'll use slightly different notation for our arrows and we'll make them squiggly arrows like this
18370920	18377080	and the reason we want to do this is because there's a very nice example of a stochastic map
18377800	18383400	if we have a function so if x to y is a function
18386760	18389320	this actually gives us a natural stochastic map
18395560	18400520	and just for this example we'll call it delta f oops these should be squiggly arrows now
18400520	18411400	so delta f to y which sends an element x to a probability measure on y and what should that
18411400	18417720	probability measure be well if i take let's call this delta f for now if i take an element in y
18418920	18424280	and i plug in our initial element x so again we're using this notation here then this is
18424280	18433560	defined to be the chronicer delta so if we take the element x apply f to it we know what that is
18433560	18439800	because we have a function already and then we plug in y so visually how do i think of something
18439800	18446440	like this well a stochastic map is telling us if we start off in x let me draw the arrows
18446440	18453320	backwards for a moment then it takes an element in x and it spreads that element out over y by
18453320	18460040	giving us a probability distribution on y but if we already have a function then we know where
18460040	18467560	that element x goes it goes to a specific element which we call f of x and therefore it does give
18467560	18474840	us a probability distribution and that probability distribution is one when we evaluated at f of x
18474840	18481400	and zero everywhere else so i think of this as a deterministic process in some sense because we know
18481400	18487960	given an input we know exactly what the output would be with 100 probability
18489640	18495880	so we notice that there's this close relationship between functions and stochastic maps in fact
18495880	18500760	functions are special kinds of stochastic maps and instead of writing delta f all the time
18500760	18511160	we'll simply write xf and we will think of this as a stochastic map but we'll write it as a straight
18511160	18516520	arrow another example
18521000	18526760	there is a one-to-one correspondence between
18529080	18530280	stochastic maps
18530760	18542040	from a single element set into another finite set x so this is going to be my notation for
18542040	18550120	a set containing a single element which i'm just calling bullet and probability measures
18550120	18562840	on x why is that well if i have a stochastic map i apply an element of it i apply it to an element
18562840	18567720	of the domain and that gives me a probability measure on x but this only has one element
18567720	18572440	so i only get one probability measure so in general a stochastic map is you can think of
18572440	18577960	it as a family of probability measures indexed by the domain of that stochastic map
18580120	18583080	stochastic maps define conditional probabilities
18591160	18595560	or at least some kind of restricted notion of conditional probabilities
18595880	18614520	and the reason is because f y x you can think of this as the probability of y occurring given
18614520	18624920	that x has occurred and you can if you know if you have a definition of conditional probability
18624920	18630920	and you are looking at single element events then this definition coincides with the one
18630920	18637880	you're thinking of for finite sets and again single element events but if you're not then
18637880	18645640	we're going to think of this as our notion of a conditional probability so for being very concrete
18647080	18653320	let's take x to be the set whose elements are so pick your favorite supermarket
18653320	18657240	and let's say there's a good sale at that supermarket
18661160	18665480	and let me think of that as one element of this set x and the other element is going to be
18667400	18673640	a not great sale or a not good sale at that same supermarket so two elements
18673640	18678360	and let y be
18681080	18686040	the elements that state whether I go to the supermarket this week or you go or whatever
18686040	18695960	or I don't go so I go to the supermarket let's say this week or something like that or I don't go
18703800	18705880	and let's say if there's a good sale
18709880	18716360	let's say the probability right because I might have a lot of food stocked in my pantry I may or
18716360	18721720	may not go to the grocery store this week but if there's a good sale maybe there's a good chance
18721720	18726920	that I'll go let's say there's a 90% chance that I'll go
18731640	18738920	and if there isn't a good sale well it might be that I still need to get food so there's
18738920	18745320	still going to be some chance that I go but perhaps it'll be less I'll be less enticed to go to that
18745400	18750680	supermarket this week let's just say that there is a 60% chance I'll go
18755880	18762760	and with this information we can define a stochastic map from x to y so this actually
18762760	18767720	defines the stochastic map and we'll come back to this in several examples that we'll look at
18768440	18773880	later on because it's a nice simple example and the reason you can figure out what the rest of
18773880	18779000	this is is just by using probabilities because if there is a good sale the chance that I go
18779000	18783640	is 90% then there's a 10% chance I won't go and conversely if there isn't a good sale then there's
18783640	18793160	a 40% chance I don't go so that defines this stochastic map just like with functions we can
18793160	18799320	compose stochastic maps as well but this is going to have a really nice picture so I rather
18799320	18805320	give that its own video and we'll talk about compositions in a moment all right so if we
18805320	18814280	have two finite sets rather three finite sets x y and z and a stochastic maps between them
18815640	18821800	in such a way so that the codomain of f lines up with the domain of g and I really mean source
18821800	18827240	and target here because again if I really think of x as a function it's a map from x to probability
18827240	18833400	measures on y but the domain of g is not probability measures on y it's y itself so it's really
18833400	18839160	better to think of this a little bit categorically where I'm thinking of the target of f and the
18839160	18853320	source of g so given this given stochastic maps we can define a composition of these two and before
18853320	18861080	I write down the formula let's think about how we would do this so here's x here's y here's z
18864680	18873560	what we want to define is an ocean of composition which is determined by if I give if you give me
18873560	18882600	an element in x and you give me an element in z I want to know given x what is the probability
18882600	18892040	that z occurs and there's an intermediary y here so the way that you get that is well I look at
18892040	18900280	all the elements of y and I look at given x what is the probability of that element y occurring
18900280	18907560	let's call this let's say that this is the element y then this is f y x so given x the probability
18907560	18913960	that y occurs and going from y what's the probability that z occurs that also has a probability which
18913960	18923880	is gzy and so the probability of given x the probability of z given x is taking all of these
18923880	18932440	probabilities by varying y and multiplying the corresponding ones when they match up and then
18932520	18938360	adding them all so this is defined to be the sum over all elements in y
18940920	18950920	with their respective probabilities gzy f y x so this is what the composition of
18953080	18956920	stochastic maps is
18963160	18973640	and now you can see why I chose this notation earlier of writing our subscripts in this particular
18973640	18979720	order because if I think of these as matrices indexed by the elements of these sets that we
18979720	18985720	have then this ends up just being matrix multiplication so sometimes these are also
18985720	18991080	called stochastic matrices but I'm going to stick to the calling them stochastic maps
18993160	18999800	so let's look at some interesting special cases of this definition so first let's look at the
18999800	19008600	special case where x is replaced by a single element set y is a set x and g is a function
19008600	19018120	not just a stochastic map so let's take this special example so let's take y a function f
19018120	19029560	and a probability measure on x so first of all what is a probability measure on x look like
19029560	19035000	well if I think of x as a set so let's draw some of the elements of x here
19039320	19045640	let's say here we have nine elements a probability measure sort of gives me a size
19045720	19053080	to each of these elements so I can think of these as water droplets each with a specific size
19058680	19059640	namely the volume
19062440	19068200	so this is sort of what a generic x looks like with a probability measure on it
19069080	19072840	and the sum of the volumes of these water droplets is equal to one
19072840	19083720	now if I have a function f from y to x then the composite here gives me a probability measure on
19083720	19090840	y what is that probability measure well if I just use the definition
19093960	19101160	p followed by f and I evaluated at y this is equal to just straight from the definition
19101160	19111000	we know that this is the sum over all elements in x of the function on the left which is f
19111000	19118840	but f is a function so we know that it corresponds to the direct delta the chronicle delta f
19121320	19130600	y f of x with the probability measure px now if I substitute what this looks like this says
19130600	19136600	this only gives me a non-zero contribution if f of x equals y in other words if y
19137640	19144040	is in the image of f of x is in the image of f and it comes from some x so if we look at the
19144040	19149480	inverse image of y that's going to give me a bunch of elements and that's the only case where this
19149480	19157160	gives me a non-zero contribution and what that means is that this breaks down into the sum of all
19157160	19167720	elements x in the inverse image of y so here we have the sum of all the px's that are in the
19167720	19175160	inverse image of an element y so let's look at this element y here the inverse image of this
19175160	19184280	under a map f so let's imagine that f identifies all the elements that are in the vertical direction
19185000	19191480	so right because a function f might not be one to one so it might identify some of the elements
19191480	19196440	and that's why I've drawn it this way it takes these four elements and gives me the single output y
19198040	19205320	and these two elements gives me another output and what this condition says is that the probability
19206920	19212280	here is the sum of these probabilities in other words the volume of this water droplet is the
19212280	19218440	sum of the volumes of those water droplets likewise here in order to make the volume somewhat
19218440	19224440	geometrically similar to these this would be the resulting volume after we apply this function f
19224440	19232440	and here maybe it's this big so this gives us a nice picture of what compositions like this look like
19234120	19240120	it essentially says that we take these water droplets and then we combine them and when you
19240120	19246680	combine the associated water droplets their volumes add as another example let's go back to
19246680	19251560	our previous situation in fact let me write that example here because it's a little bit it can fit
19251560	19259000	here so in this case we had that set x to be there's a good sale at the supermarket this week and
19259000	19266520	there's not a good sale and the set y is I go to the supermarket or I don't now what if we happen to
19266520	19273000	know the statistics or the probabilities of whether there is a good sale or not at the specific
19273000	19278760	supermarket given that specific week so you compile all of your data over the course of a year for
19278760	19283960	instance and you just ignore the seasons you ignore the months you just look at when is there a good
19283960	19291160	sale for whatever definition of good you might have for for you and let's just say that the
19291160	19301720	probability of a good sale is maybe only 30 percent so roughly 30 percent of the time there's a good
19301720	19309240	sale on a given week and therefore the probability of a not so good sale is 70 percent and so you
19309240	19317080	might ask what is the probability that I go to the supermarket question mark so that's the end of
19317080	19322360	the statement so all we know is that if there's a good sale we already know what those probabilities
19322360	19327880	are I think they were 90 percent and if there is a good sale and 60 percent if there isn't a good sale
19328760	19333400	because I still need to eat and if we happen to know the probability that there's a good sale
19334360	19341960	and therefore the probability of there being a bad sale or not good rather is 70 percent
19342920	19346040	then you could still ask what is the probability that I actually end up going
19347720	19352840	and that's where this composition comes in where instead of having an f like this
19354200	19358680	we instead have our f from our previous example but we also know the probabilities
19358680	19362840	of whether or not there's a good sale so it's a slight generalization of this example
19363880	19366200	and therefore the probability that I go
19366760	19376440	to the supermarket is equal to and in this case I'm going to take the probability
19377720	19385000	that there is a good sale times the probability that I go given that there's a good sale plus
19385720	19392280	so let me actually write that one down so that's 90 percent times 30 percent the probability that
19392360	19397240	there's a good sale times the probability that I go plus the probability that there isn't a good
19397240	19403480	sale but I still go and the probability that I go given that there isn't a good sale is 60 percent
19403480	19409960	and the probability that there is not a good sale is 70 percent and the resulting probability
19409960	19419560	that I go is 69 percent so given those statistics we still know that if I just chose an arbitrary
19419560	19424120	week in the year there's a 69 chance that I'll go to the supermarket that week
19426600	19430360	so now let's look at another example and this example again will come back
19430920	19436280	will come back to this perhaps a few more times so now let's look at another example
19436840	19442840	this one may seem a little bit abstract but it's a very useful one anyway
19443800	19451720	so let's take the diagonal map from x to x cross x what this does is it takes an element x
19453320	19458680	so far we've talked about stochastic maps and how to compose them and how to view ordinary
19458680	19464360	functions as specific examples of stochastic maps what we'll do now is describe how to take the
19464360	19469480	product of two stochastic maps in a way that generalizes the usual notion of the Cartesian
19469480	19483080	product of two functions so given stochastic maps f and g
19488920	19490440	we can form their product
19491400	19499400	and it's another stochastic map
19507240	19513800	that essentially takes the product of these two problems of the associated probabilities
19513800	19524520	point-wise so it's determined by the formula f cross g now remember what our notation is
19524520	19529800	for each element in the domain we get a probability distribution on the co-domain
19529800	19535640	and that probability distribution is determined by what it does to points because we're working
19535640	19542200	with finite sets so that probability distribution is determined by the value of our initial input
19542200	19549560	with our our output and it's just the product of the associated probabilities from f and g
19557880	19563560	and let's just check that make sure that this coincides with our usual definition of Cartesian
19563560	19567560	product when we specify that these stochastic maps correspond to functions
19568120	19572040	so if f and g are functions
19575160	19580920	or how I think of them as being deterministic then this product
19590200	19595240	is given by well we know what happens when these are functions then we use the the
19595320	19603640	chronicle delta and this is x prime f of x while this is delta y prime g of y
19606360	19615880	and this is nothing but it's the same exact thing as requiring that x prime coincides with
19616520	19623720	f of x simultaneously as g as y prime corresponds with coincides with g of y
19624680	19629720	and this is the usual way we think about the Cartesian product because it says what is the
19629720	19636520	value of f cross g at x y well it's f of x comma g of y and this is exactly what
19637720	19645400	encompasses that idea and all of the structure that we've defined so far the idea of this
19645400	19651240	stochastic map it's definition how it composes the fact that functions are special cases in
19651320	19656200	particular the identity function is a special kind of stochastic map it turns out that
19656200	19663320	composition is associative the identity is an identity for the composition for any finite set
19664040	19670040	and this Cartesian product it also satisfies the type of associativity condition
19671080	19679720	and together all of this all of these data give the collection of finite sets with stochastic
19679720	19686600	maps and this associated product this it gives it the structure of a symmetric minoidal category
19687880	19693320	but there's another thing that we haven't yet discussed which is a notion of almost everywhere
19693320	19699960	equivalence or in other words an almost surely notion of equivalence and this essentially takes
19699960	19706200	care of when probabilities happen to vanish and when such a thing happens we can have a
19706200	19713320	notion of equivalence between functions when their probabilities are equal versus when they're not
19713320	19719880	when they're zero and so we get a very natural definition of what it means for two stochastic
19719880	19729800	maps very similar to the way we define almost everywhere equivalence for functions so given two
19729800	19741400	stochastic maps so I'm using different notation than what's up here so given two stochastic maps
19741400	19743640	and a probability measure on x
19752680	19760520	we say that f is p almost everywhere equivalent to
19761240	19773240	g if and only if and the way we define equivalence is that these stochastic maps agree
19774040	19779800	everywhere outside a set of measure zero so outside of events that have probability zero
19780520	19787720	so the way we write that is if and only if the probability of the set of points on the domains
19787800	19793400	of these corresponding stochastic maps where these two stochastic maps differ
19797960	19806120	is equal to zero now what does this inequality mean now f of x and g of x are both probability
19806120	19814520	measures on y so when I write that they're not equal that means f subscript y x is not is is not
19814520	19822920	equal to g subscript y x for some y so this is a very intuitive notion of almost everywhere
19822920	19832280	equivalence there's another sort of diagrammatic way that you can encompass these definitions as well
19834920	19839080	so I'll write this as a theorem but we'll use this idea later on
19839640	19847640	so it turns out that given f g and p as in this definition
19854760	19861640	f is almost everywhere equivalent to g so this is the notation that we'll use if and only if
19863400	19868600	the diagram now this is going to be a little bit of an interesting diagram
19869880	19882200	so we're going to produce our probability on x we're going to duplicate x using the map that we
19882200	19891480	introduced earlier and on each of these two factors we will apply our associated
19891640	19902840	maps f and g on their corresponding terms so in this case we'll have the identity on x here cross
19903720	19911640	f and here it's the identity on x cross g where this product is the one that we justified so if
19911640	19920600	and only if this diagram commutes so first of all this is a very interesting statement
19920600	19925880	it tells us that this notion of almost everywhere equivalence can be encompassed in some diagrammatic
19925880	19934840	form and secondly if we ever discuss these in these videos we'll find out that this is very
19934840	19941240	closer related to a notion of almost everywhere equivalence in a non-commutative setting where
19941240	19947160	we replace our finite sets and stochastic maps with certain kinds of c star algebras
19947160	19953720	and completely positive unital maps and these sorts of objects are relevant in quantum information
19953720	19963000	theory okay so before we prove this we'll have a little bit of a lemma just to make the calculation
19963000	19974680	a little bit easier and that lemma is the composition of two maps of two stochastic maps
19974680	19984840	that are of this form so if i have a map phi from u into v and the map psi from u into v
19988120	19994360	and i pre-compose with this diagonal map then this composition is given by
19995880	20004360	the formula so we take phi cross psi composed with this diagonal and how do we evaluate this well
20004360	20010600	the domain has a u and the codomain has a v and a w so we can evaluate it v comma w and u
20011560	20016760	and the claim is that this is given by taking just the product of these where two of the points
20016760	20028040	happen to match up so this is phi v u psi w u for all v u and w so the proof of this is pretty
20029000	20035960	pretty easy once we have all of our definitions in place and the left hand side of this expression
20035960	20044200	by definition of the composition and by using the definition of the product is equal to a sum
20044200	20052200	and what's our intermediary step it's the sum over u cross u and u cross u therefore we have
20052200	20056600	to sum over two elements we've already we're already using a letter u so we're going to have to
20056600	20062360	introduce u prime and u double prime for instance so it's going to be u prime u double prime both
20062360	20073480	elements in u and the product here is going to be phi v u prime psi w u double prime because that's
20073480	20082440	the second coordinate and this is as we recall the direct the chronicle delta twice using the
20082440	20090360	coordinate u and u double prime and u prime so it's u prime u delta u double prime u so this
20090360	20097080	gives us two delta functions and we have a summation over those and as a result these two letters
20097080	20104120	coincide so this is exactly the right hand side quick and simple proof so this is the proof of the
20104120	20115400	lemma and then the proof of the theorem we'll now talk about Bayes theorem and first we'll
20115960	20121320	state the theorem given a probability distribution on x
20121720	20134120	and a conditional probability from x to y call it f so it's the stochastic map
20139000	20148280	there exists another map going in the opposite direction let's call it g such that
20148760	20150760	the diagram
20153720	20160760	now the diagram looks a little bit complicated but it's not too bad when we write out the equation
20160760	20168760	we'll see exactly what it means so here we'll have p and here notice we can compose p with f
20168760	20170760	to get another probability distribution
20171240	20181720	on y and we'll call that q so we have our probability distribution on x on one on y we duplicate x
20185560	20191880	we duplicate y this almost reminds me of the definition of a equivalence
20192680	20202520	x cross y and here we will apply the only maps we can and to go from x to y we apply f
20205000	20207160	and to go from y to x we apply g
20209800	20212200	so the statement is that this diagram commutes
20214440	20215560	and furthermore
20216360	20225320	for any other stochastic map that also goes in the opposite direction let's call it g prime
20227960	20228920	satisfying this
20234600	20242920	then these two maps are q are almost everywhere equivalent and in the sense of our probability q
20246440	20252200	so this is the formal statement of Bayes theorem and if you've seen if you've seen Bayes theorem in
20252200	20258840	a different context this may seem totally strange but let's just see exactly what it says
20263320	20266360	when we look at the composition of all of these arrows
20268440	20271480	we've actually computed expressions just like this if you remember
20272040	20275960	the this left hand side when we were doing the notion of almost everywhere equivalence
20275960	20281160	in that diagrammatic perspective we computed something I think it may have been exactly
20281160	20286040	this expression actually so commutativity says
20286120	20301480	says that f y x times p x equals and if we did that same calculation but on the right hand
20301480	20306760	side of this diagram it looks almost the same it's just that the g is on the other side nevertheless
20306760	20314760	we still get g x y q y and this holds for all x y
20316280	20324680	of course x is an x and y is in y now let's introduce some notation to see how to understand this
20326920	20336200	let's define p of y given x so this is the probability of y given x to be exactly f y x
20338600	20341720	that's exactly what f means f is this stochastic map it says
20342440	20347240	it's not corresponding to a function it says if you give me x I will give you y with
20347240	20352760	some probability the probability is exactly f y x so that's exactly what this conditional
20352760	20363560	probability is and the probability of x is just little p x the conditional probability of x given
20363560	20369480	y now this is going in the opposite direction it says if you give me y what's the probability of x
20369480	20380120	occurring that's exactly g x y and finally the probability of y occurring is q y and so if we
20380120	20386520	write down these expressions commutativity is of this diagram says nothing but the probability of
20386520	20394360	x given y times the probability of x is equal to the probability of y of x given y times the
20394360	20401560	probability of y which is perhaps a slightly more familiar form of base theorem at least when
20401560	20408120	your events are singleton sets and with the appropriate definitions you can also extend this
20409080	20413240	you can look at what this diagram means because these are corresponding to probability measures
20413240	20419720	and you can also define a notion of conditional probability where you replace this point with
20419720	20425240	a subset and you can use the probabilities on your corresponding spaces to make sense of what
20425240	20431320	this means when x is replaced by some event a perhaps and y is replaced by some event b
20431960	20436280	nevertheless the same equation still follows from commutativity of this diagram
20437480	20444200	so let's look at our earlier example just to see what this is saying and how to interpret it in
20444200	20453960	sort of a real-life situation so if you remember we had x and y two sets with each of which contains
20453960	20464920	two elements and x corresponded to the set where there's a good sale and the other element was
20464920	20472440	not a great sale not good sale and y is the set of elements the set containing the elements
20472440	20480200	i go to the store the grocery the grocery store or i don't go
20484040	20488920	and we also had probabilities on each of these spaces and we also knew the probabilities that
20488920	20494440	if there's a good sale how likely am i to go right that was nine nine ninety percent so ninety
20494440	20504360	percent if good i go with ninety percent probability and if not good then i still go
20505240	20514120	but with sixty percent chance and likewise the other probabilities are given by the fact that
20514120	20519080	it's one minus this one minus this and we also know the probability of there actually being a good
20519080	20524920	sale so we know what p of good sale is and the probability is thirty percent and the probability
20524920	20533000	of a not good sale is therefore seventy percent so we have all of this information now imagine you're
20533000	20540200	in that store this particular week and you happen to see me there so in that case you happen to know
20540200	20548520	i'm already at the store then you can ask what is the probability that there's a good sale this week
20548520	20553560	given the information that you see and knowing this information as well so initially you also
20553560	20558680	know the statistics that says the if i look over the entire year the probability that there's a
20558680	20563960	good sale is thirty percent but you also know that i'm more likely to go to the store if there is
20563960	20568680	a sale so if you see me then there might be a better chance that there's a sale this week
20570040	20574840	and how do you figure that out well if we look at this expression and we
20575800	20578440	compare these two sides then
20580840	20585480	we can say that f corresponds to the if there's a good sale versus if there's not a good sale
20585480	20592120	how likely am i to go or not as f y x and the probability that there's a good sale
20592120	20601320	is p x and if we wanted to know so let's say g is on the other side so g of x given y so this says
20601320	20607080	if you see me at the store so here this element y is i'm at the store
20611480	20614440	and x is there's a good sale
20618680	20622280	so if you see me at the store what's the probability of there being good sale
20622280	20630680	and we divide that by q y which we've already determined last time so q y was the probability
20630760	20632520	that i went to the store
20639240	20643080	and we know that that equals the sum of the product of the probability of
20643080	20645560	if there's a good sale i go and if there's not a good sale i go
20646440	20650840	multiplied by the corresponding probabilities corresponding to here and we found that to be
20650840	20660040	69 percent so in this case this equals 90 percent 30 percent divided by 69 percent
20661080	20667960	and when you write out what this equals it's roughly approximately equal to 39 percent
20669080	20672920	so you've updated your hypothesis based on what you see
20673880	20679880	and this is known as Bayesian inference
20683320	20691880	or inversion inversion and in fact the map g constructed here
20695000	20697160	a g from Bayes theorem
20697560	20708840	is called a Bayesian inverse
20712680	20716200	of f and it would be a little bit inappropriate to say
20716760	20723160	that it only depends on f because it also depends on your prior probability distribution p
20723400	20734040	so this is an interesting reformulation of Bayes theorem that seems to be totally in the
20734040	20741720	language of category theory and it therefore makes it amenable to a wide range of techniques
20741720	20747160	that could be used to analyze and understand it and perhaps even generalize this idea to other contexts
