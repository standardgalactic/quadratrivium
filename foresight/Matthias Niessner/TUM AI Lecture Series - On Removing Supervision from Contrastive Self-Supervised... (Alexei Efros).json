{"text": " All right, welcome everybody today to my lecture. It's a real pleasure to have Alyosha Efros today. Alyosha is a professor at UC Berkeley, where he's part of the Berkeley Artificial Intelligence Research Lab there. His work is at the intersection of graphics and computer vision, and I'm sure pretty much everybody in the community has heard of him. He's a pioneer at the intersection in these fields. He has countless of exciting papers, starting from texture synthesis to conditional GANs like Pics to Pics and Cycle GAN. He's particularly known for his creativity and thought-provoking work, which is an inspiration to many young researchers. His students have also had really great success. You can see many of his students are now professors themselves. And I think it's also, yeah, it's fair to say that he has also a very great social engagement, in particular, contributing to the research community. If you haven't met him in person, I can only recommend reach out to him at the conferences once we have them again. It's really great to have him around. It's really great hanging around with him at one of the poster sessions and chat about some really exciting research. He's particularly known for his, yeah, really cool attitude, and it's really great to have him as part of the community. So it's a real pleasure to have you here. And I'm really looking forward to the talk. And you also promised some philosophical components. So I'm really excited what that's going to be. Thank you so much for such a gracious introduction. Yeah, I'm sad that we have to do this virtually because I would love to have hung out with you guys and gone for some wonderful Barbarian beers. But next time, yes, thank you very much for inviting me. And it's such a star spangled roster of speakers that you have there. I hope I will not disappoint. And so I'm going to talk about aspects of self-supervision. Self-supervision is something that my lab has been working for a number of years. And just to make sure everyone's on the same page, self-supervised learning is when we, this is my definition, you know, hopefully there is no one set definition, but my definition is that it's when we use the tools of supervised learning, but where the labels are the raw data instead of being human-provided. And so the question that often students ask is why use self-supervised learning? What's the point? And the classic answer, the common answer is because labels are expensive. Instead of having humans provide labels and annotating them using lots of hours of work or high cost, here we get used the data itself as our labels. So this is the common answer, but that's not really my main answer. This is, it's nice, but it's not the main reason for me. For me, I actually have a couple of answers. The first one answer is that self-supervised learning allows us to get away from the tyranny of this top-down semantic categorization that goes all the way to Plato and Socrates. And I'll tell you why I think this is a good thing. And the second reason is that self-supervised learning will hopefully enable us to move away from this idea of a fixed training set to a more continuous lifelong learning where you have data streaming in and then you learn on the go. You learn as you live, rather than having this kind of training set, testing set, split that is kind of the classic thing in machine learning. So I will start, and most of the talk is going to be about the first one, and then hopefully we'll do a little bit of number two, okay? So what's the problem with semantic categories? Well, let's look at, from the visual point of view, let's look at a couple of categories from a standard visual data set. So the first is what's called a chair, okay? But you can look at all the different chairs that you could have in the wild, and you realize that this is very hard to find what is in common between all of these chairs, right? Visually, actually, there is pretty much nothing in common because between something like this and something like this, right? This chair is really more of a functional category, right? And think about it this way. We can see them all being chairs because we have seen, you know, butts being squeezed into these places. But if you are a computer, if all you've seen in your life is ImageNet data set, for example, if you've never seen any videos, you've never seen any people sitting on anything, there is basically no way for you to realize that all of these are somehow related, right? So the relationship here is not visual. The relationship is functional. The relationship is that of affordances. And it's not really fair for a computer to try really, really hard to find a way to kind of somehow bring them all into some kind of a connection where maybe there isn't that much of a connection, okay? The second example I like is this one called City, okay? And here what I'm showing here is a picture of downtown Pittsburgh in a picture of the center of Paris, okay? And frankly, you know, the fact that both of these by some fluke of the English language are termed City, the same noun, this is just kind of a coincidence because there is really nothing visually in common between those two, right? And people can argue, well, wait a minute, you know, both contain buildings, but look at the buildings. The buildings are so different visually, there is nothing in common between those buildings, right? They're so visually different. And then you can say, well, but they both have windows, but again, look at the windows. The windows don't look anything the same. Look, there is really not a single pixel in common between these two things. And so again, we are forcing the computer to do something, to somehow try to generalize across these two things that are very, very different, that might not have anything in common. And so, in a way, what we're forcing the computer to do is basically to cheat, right? It's kind of like you haven't attended classes and then now it's your final exam and you're trying to see what, you know, you're trying to cram for the final exam. And so what the computer is going to do is like, anything that looks like this, it will be called the city, anything that looks like this will also be called the city. But you're not going to basically get the concept of a city. You're just going to basically just remember the, you know, the nearest neighbors, right? So basically with labels like these, we're, I worry that we're setting ourselves up for failure, right? We're setting our algorithms up for just memorizing examples and not really even having building connections between them, okay? Which is of course very bad if we want our models to generalize, right? If we just wanted to, you know, train an image net and then test an image net, that's fine. But if we wanted to train an image net and test on, you know, the real world out there, then that's not fine. We need to somehow induce generalization, okay? And so this is where my promised bit of philosophy comes in, which is that I argue, I've been arguing functionally for many years now, that we should step away from the stop down categorization paradigm and try to think more of it as a bottom up association. And there is some movement towards that in, especially in the 20th century. The philosophers have really kind of pushed away plateaus and Socrates notions of these rigid categories and really started to think about categorization in a much more bottom up way. So Plato, of course, he argued that categories were a list of, you know, there were abstract definitions with a list of shared properties. And then in the mid 20th century, the philosopher Wittgenstein came out said, no, no, no, no, this is that people don't do this. In fact, people are much more fluid about categories. And, you know, for example, you know, if you ask people, you know, our curtains furniture, olives, fruit, different people will give you different answers. In fact, the same person might give you different answers different times of different times you ask them. Wittgenstein's classic puzzle was to ask people to name all what is in common across all games. What are the common properties shared by all games and not shared by non games? And that you cannot do it. It's just impossible that there's such a variety of games out there that you cannot think of any single thing that defines a game. It's not a definitional thing. It's much more kind of data driven, much more bottom up kind of, well, it's a game like like football. It's a game like chess, right? And so in the second half of the 20th century, psychologists in particular, Eleanor Rush have tried to kind of update the notion of categorization and tied to think about categories forming from the bottom up and her famous prototype theory of categorization has really started this trend where the idea was that you basically cluster, you do bottom up clustering of similar instances into these prototypes and the prototypes then get clustered again and then you have this kind of a bottom up hierarchy where the categories emerge directly from the data rather than being kind of this top down, okay? And later folks have, psychologists have gone even further and argued for what they call the exemplar based theory of categorization where you basically, you don't really have categories when you kind, you basically just store instances, store exemplars of everything that you see and then you basically learn associations between those examples and the things that are closer together, essentially can you can think of it as like this kind of a soft clustering of your exemplars into chunks and to groups and those groups then emerge to be categories. My favorite slogan is provided by a neuroscientist Moshe Barker who says, ask not what is it, ask what is it like to this kind of a, this idea that association bottom up association trumps this top down labeling, okay? And so this work has been very inspiring to me and my group over the years and we have been kind of chugging away at in this direction for a number of years and maybe one of the earlier works that we did was with my former student Tamash Milosevich where we basically try to kind of instantiate this exemplar based way of thinking about categorization and here the example, the idea is that we basically try to find per-exampler distances given a set of data. So you have a set of labeled data, you know, cars, people, pedestrians, trees, etc. And here instead of trying to separate all cars from all pedestrians, for example, we wanted to basically learn a way to group every single instance of say car. So for this particular focal example of a car, we wanted to find what other things are close to it, right? And so those other things should be also labeled car, but there shouldn't be all cars because, you know, this car, for example, looks nothing like this car. So should they really be in the same cluster in the same category? Maybe not. And so the idea that Tamash came up with was to basically kind of treat this as a kind of a classification problem where you basically learn a decision boundary between things that are close to your focal example and things that are far, but here we actually have instead of two classes, the ones that are inside of a category and one's out, we have three classes. There are the things that are close and these are kind of these kind of cars. There are things that are not cars and they're on the other side. And then there is a third class which is don't care. And these are basically other cars that might not actually be that close to the focal car. And then you basically optimize this, optimize this decision boundary given some set of constraints. And as a result, what you get is you get something where you learn these distances that are, that produce much more visually meaningful relationships rather than if you were just doing a standard set of distances without this, okay? And so this was kind of a, we were very excited about this, but still we're here, we're still using the label car, the labels are still being used in this computation. And we really wanted to go away from labels entirely. And this is where Tamash's next paper came in. And this work, we call it exemplar SVM, was basically kind of pushing this farther and really thinking about it in terms of classifiers and basically switching from the standard classifier where you have class A and class B instead to take every single instance, every single data point and train a separate classifier for that one instance against everyone else, whether it's your own class or a different class. So it's one against all classifier. So this is kind of an interesting way to think about it because it's really basically you're defining yourself, not by who is in your category, who is in your class, but you're defining yourself by what you are not, right? So what makes you different from everyone else in your data, okay? And then the cool result was that we were able to do one classifier for every instance and then assemble them together. And the result was that this assemble actually worked no worse in many cases than your standard two-class classifier like an SVM, okay? And this was a little bit of a, it was kind of like a bit of a trolling paper, which basically kind of tried to push the community to say, look, maybe you're not getting as much juice as you think you are from basically trying to group all those things into one class because it seems like if you don't do it, you get basically as much of performance as not, okay? And so we also use the same idea for retrieval. So basically the idea is you take, at runtime, you take your retrieval query image and then you have a big data set and you're basically training at runtime an SVM classifier to separate your query from everything else, okay? And then you order all of your data based on that, on the coefficients of that decision boundary, okay? You basically find who are the closest things, who are your support vectors inside of your data set and those tend to be the retrieval examples, the kind of the closest ones on the other side will be the retrieval examples and that also worked surprisingly well. And so we were very excited about this and we were very hopeful and then of course deep learning revolution hit and all of this became irrelevant because much better classifiers came on the scene. We tried to update it for the deep learning age and we didn't really succeed but Alexey DeSavitsky and colleagues did, okay? So one of the kind of very early influential papers was called exemplar CNN, which basically adopted the same idea of one against all classification on using neural networks, okay? And the main difference that we didn't really think of was that whereas we used a single exemplar, one image against everything else, DeSavitsky and colleagues they used what's called data augmentation. So they basically, they took one example and then they created a whole bunch of similar examples by basically applying various different transformations to it, you know, changing lighting, changing contrast, changing shapes, you know, various geometric transformation, etc. In the end, even though all of these things came from a single example, they all were a little bit different and so this became the positive class and then everything else became the negative class and that worked really, really well, okay? And this work really was an inspiration for a lot of the current contrast of self-supervised learning that we are familiar with right now. So we thought we will be very pure and just use a single image, but this of course worked much, much better. And of course, now in kind of modern day, the self-supervised learning representations that seem to work the best, they're all based on this idea of similarity learning, of instead of learning which class you are, which category you are, the idea is to learn instances that are either close or far from each other. So learning the distances between the instances in your training data, okay? So things like metric learning, SiameseNet and the new contrastive learning are all based on that same principle. So you basically, you have some sort of an embedding space and your goal is to say, okay, for a given positive like this particular instance of a dog here, you create a bunch of different positive example by data augmentation. And then you basically try to push these ones, all of them to be close to each other in this embedding space and far away from other things which are dogs or other cats, et cetera. And this learning of the similarity is really what a lot of the contemporary self-supervised learning methods are doing, okay? And so, you know, the reason why this, maybe like a year ago, this area really took off, one of the reasons is, of course, you know, the improvements in the representation learning. The contrastive formulation is actually just works much better as shown by papers like Simplier and stuff. But another reason I think that's maybe being a little bit underappreciated is that we are just much better at doing this data augmentation. So we have learned to do data augmentation in a better way than the Seitzky and his exemplar Sienna, okay? For example, now cropping is a very standard trick for data augmentation, which wasn't a standard trick before, and that gives us a lot of boost. So again, what data augmentation is, you get yourself an input image, a single instance, and then, you know, you just randomly create a whole bunch of different versions of that image by applying a whole bunch of different parameter transformation, whole transformation, cropping, flipping, blurring, et cetera, et cetera, et cetera, okay? And then once you do that, then you set up your kind of a distance function. So you basically say that I want these two images that all came from the same image really, I want those two images to be similar in our embedding space. So I'm going to try to bring them close together and farther away from the other images in my data set. That's really the whole story of contrastive learning, okay? Now the thing is that the choice of data augmentation itself turns out to be very, very critical. And in fact, I want to argue that this data augmentation is itself a little bit of supervised learning, because the way you choose your augmentation can make a huge difference in your final performance, okay? So here is an example from our recent paper in iClear 21, where you can think of, let's say that you have different types of data augmentation, like color augmentation, maybe rotation, and maybe texture, okay? So now we can look at different tasks, for example, if we want something like ImageNet, course-level categorization, then data augmentation with color makes a lot of sense, with texture also makes a lot of sense, but rotation is actually going to hurt you, because an upside-down elephant is not going to be recognized as an elephant, okay? Whereas if your task is, for example, fine-grain recognition, well, then it gets even more complicated, because if you're fine-grain the different species of birds, then actually you don't want any of those data augmentations, because they're all meaningful, like changing texture may change the species, changing the color definitely will change the species. Whereas maybe if you're classifying different types of flowers, then rotation is fine, because rotation augmentation, you know, because flowers are usually rotationally symmetric, okay? And so you can see that it really becomes very, very task-dependent. And another example is the cropping and image classification. So cropping for something like ImageNet classification makes a lot of sense, because you have one big object in the center of the image. But the same cropping for object detection actually doesn't make that much sense, because you crop it and you might lose, you know, where your object is, okay? And so this is something that we started to worry about, because we feel like a lot of the advances in the modern self-supervised learning might actually be due to us being very good at overfitting the right kind of data augmentation for a particular problem rather than the actual methods themselves, okay? So what we wanted to do is to try to do contrastive self-supervised learning without data augmentation, to really try to get it to, to figure it out on its own without this kind of help, okay? And the way we wanted to do this is to make these, these augmentations, these what they're called views, to make them latent, to make the computer come up with its own data augmentation in this, in a sense, okay? And of course, the big question here is, this is all great, but where do you get the supervisory signal, right? There is no free light. You need to get some sort of supervisory signal from somewhere in your data. So where is it going to come from? And here we're going to, I'm going to talk about a couple of papers where we answer this question differently. The first paper, the answer we have is that we want to use time as our self-supervisor signal, okay? And here I have a wonderful quote from one of my favorite writers, Jorge Luis Borges, in his short story about fumes, who is this kind of a man on the spectrum. He writes, it irritated him that the dog at 3.14 in the afternoon seen in profile should be indicated by the same down as dog at 3.15 seen in front of it, okay? So basically what he's talking about is that two different instances of time makes most of us assume that there is some continuity of what we are perceiving, that the dog here and the dog here, it's almost certainly the same dog. But nothing happened to this dog while it was jumping in the water, right? But fumes, of course, couldn't figure this out and neither can our computers, right? And so the idea is that this temporal correspondence, basically time as a way to align things together, to bring things into correspondence, is a very powerful supervisory signal that we should be using, okay? And we have evidence that biological algorithms use it very strongly. There is plenty of psychology data for human infants that shows that temporal cues are very important to learning vision. And there is this wonderful line of work by Wood who basically did this kind of this experiments with newly born chicks. So basically what he says he has is this kind of VR cave for chickens, for little chicks. So you put an egg and then the chicken is born and the chicken is born in this VR cave where he's basically projected things on all sides. So everything that the chick knows from birth is being controlled by the researcher, okay? And what he showed that some of the chicks were shown videos that were not temporally coherent, that basically broke this temporal continuity. As you can see, it was not kind of physically correct and he compared them to chicks that were shown normal, normal continuous things. And the chicks who saw these continuous patterns, they were not able to function in the world as well. They lacked some of the visual perception skills. So that showed that this is extremely important, that temporal continuity is extremely important. And so what we want to do in this work is to use video as data augmentation, as a way to create these data augmented views ourselves, okay? And basically the main thing, of course, is that this can provide correspondences across different instances and allows the computer to learn how something looks across time change, okay? But it can give us a bit more because we can also think about contextual relationships and notice things that are moving in the same way, what Bernheimer called common fate. We also use that as a way to group little points, little trajectories into groups and maybe get to the notion of objects from the notion of points, okay? Again something that you can use temporal information for, okay? And so this is basically the story. And then the question is how do we harness this information without any sort of supervisory signal, okay? And in the past, people have used things like slow feature learning where they basically kind of looked at connecting nearby frames together, basically look at nearby frames as the positives and far away frames as the negatives, but you just collapse the entire frame and so that's not really something that can give you these point tracks, it's much more coarse signal. Alternatively people use things like optical flow or tracking to create correspondences using some off the shelf methods and then use learning to connect things that are supposed to be in correspondence. But here you're using two different methods and so what we wanted to do is do something like this but kind of in one go, in one pack. And this is our paper that tries to do this, this was published in Europe's past year and here is the idea, okay? And so for a warm up, let's consider the case where you actually do have labels. Let's say that somebody went ahead and labeled that this patch corresponds to this patch, okay? And your goal is to basically learn a representation that brings things that are the same into correspondence and away from things that are different, right? So in this case of course it's very simple, you just say, okay, these two things are my two positives, I want them to be close together and all the other patches are my negatives, I want them to be pushed far away and then you have your standard self-supervised learning, contrastive learning problem and off you go, right? Nothing very exciting. So things get a little bit more exciting if you have maybe another frame in between, okay? Because now you have, these two guys are your two positives. We know this by labeling but also because this is a video, we know that from here somehow it needed to go to be in this final place and so there must have been a path, the most likely path from this guy to go from here to here and the most likely path is going to go through this patch so it's reasonable to assume that this patch should also be in our positive category, it should be in the same category as this guy and this guy. So now these triplets should be the positives and everything else should be the negatives. So now you can think of a little bit of kind of automatic data documentation that this guy just by virtue of being tracked in the video becomes a data augmented positive for our kids, okay? So this is okay but this is still requiring us to have this supervision. How could we get rid of supervision? Well, we are going to use our old trick which we've used before called cycle consistency and what we're going to do is we're going to make this video into a palindrome. Palindrome if you remember in language is a word that you read it forward and backwards and it reads the same, right? So how can we make a palindrome out of a video? Well, what we can do is we can take this video and flip it around and put it back in the reverse order, okay? So now what we have is we have something like frame one, frame two, frame three and now we're going back to frame two and then frame one, okay? So now we have this new video that's a palindrome and look what's happening. Now the final place, the destination is now exactly the same as the origin by construction. So now we don't need supervision anymore. We got rid of supervision. All we need to do is to get from the blue guy to the green guy and the way we do it is we're basically trying to do a track through this video and everything that's on this track should be in our positive category and everything else should be in the next, okay? And so now you can see the setup where we basically are getting something out of nothing. We're getting some supervisory signal just from the mere video information, okay? So basically the story is that we are going to take a video. We're going to make it a palindrome by going from t to t plus k and then minus to back to t. We're going to make it into a graph. We're going to turn the video into a graph, okay? And then we're going to walk along this graph until we get to the end, okay? And we're going to do basically a random walk on this graph and then we're going to steer that random walk such that if you start from this blue point right here, we want to steer it to get us to this green point right here, okay? And this is going to be our only supervision. The supervision is going to be at the last frame where we're going to say that the green, the positive is going to be anything that lands on the green dot and negative is going to be anything that lands anywhere else, anywhere on this red dot, okay? And that's basically going to be the signal that we're going to use, okay? So, and also notice that we don't have to have a single path through this graph. We kind of naturally, we can incorporate probabilistic information by tracing many paths through this graph, okay? So, you know, how do you turn the video into a graph? Well, it's kind of a standard thing. You know, create nodes and then, you know, you're basically, your nodes are some representation and some using some encoder, phi. And really, this phi is really the only thing that you're learning. What you're learning is you're learning the representation of each patch in your feature space. And you're basically trying to figure out how to arrange those features in your representation, who's going to be close, who's going to be far, okay? And so, now your video is going to be a graph. And then from frame T to frame T plus one, you're just going to have a transition matrix that's just going to say, you know, where did all the points from T go in T plus one? And then this is just basically like a dot product in the feature space. So, the closest things are going to be to get the higher dot product, okay? And then how are we going to do it around the work? Well, just going to compose all of these transition matrices A, just like, you know, standard Markov chain, you know, you're just multiplying all of those transition matrices and you get your full work on this graph, right? So, now kind of the nice thing is that the task of learning this representation phi is essentially the same as fitting these transition probabilities, okay? You find the right transition probabilities and it gives you your representation phi, okay? So, again, in kind of a, if we do have the target somewhere, if we do have the supervision, then this is just a standard contrast of learning problem. You basically, you want to find a representation where this query goes directly to the target. It doesn't go to the red ones, right? And this is basically just, this is your positive, this is your negative, this is your standard kind of static learning problem. If you have multiple frames in between, then in a sense, you have some latent views that you can also use, right? So, now we have, these are all the positives and these are the negatives if you, if it's an obvious path. But if you have multiple, multiple hyperability paths and these will be late, like, awaited positives and these will be weighted negatives and you can still do it. And so, again, from a single point of supervision, you get all of this data-augmented information, okay? And of course, what we can do then is we can do the palindrome trick and now we get all of these latent data-augmented positives without even providing any supervision, okay? Because this is basically by construction, the target is the same as the quick, okay? And so, where we can just set this up at training time and you can see that it's, you know, if you pick a point in the query image, in the first image, you can see that over time, it kind of gives you a little probability distribution of where that image might have gone and you can say, well, maybe we can even do this by trying to get grouping happening and find out a group which corresponds to a single object. And to do that, we have a little extra thing that we can do which is we can do a dropout. We can cut some of the engines away and force the correspondences to go through nearby paths and that basically allows us to get a little bit more of this kind of grouping happening where you basically kind of, you go through the paths that are also on the same object, okay? And, you know, we basically violated it at runtime by essentially nearest neighbor in the phi space and here are some examples. This is the kind of the state-of-the-art label propagation results and this are the results of our methods and you can see that it's it's basically behaving much better in terms of occlusion handling and just seems to do quite a bit better. Here is again state-of-the-art self-supervised method and this is ours, right? Even against supervised methods actually does pretty well even though it doesn't get any sort of supervision. So here is kind of an example of how we do compared to some of the self-supervised comparators and interestingly even for methods that are trained on image, using image net representation we are actually doing better than that, okay? And here are some examples of kind of propagating various things like skeletons or labels or things like that, okay? So this is one way to use this contrastive learning as without data augmentation but of course in my lab we also like to make pretty pictures and so I'll briefly show you another way of using the same kind of an idea of kind of creating your own latent views for an image-to-image translation setup, okay? And here the idea is of course image unfair translation. The classic thing that we've been doing for a while we want to translate horses into zebras but we don't have a correspondence between horses and zebras, okay? So we want to go from here to here but we don't have a correspondence, okay? And of course the one powerful signal here is we can use a GAN loss which basically says make this thing into a zebra by basically forcing it to look like other zebras that I have seen, okay? Using a GAN loss but that GAN loss is not enough because it can make it look like a zebra many ways, right? But we wanted to kind of be in correspondence and so this is where we also want to have another constraint and in the past in works like cycle GAN we use the cycle consistency constraint which says okay make it a zebra but also make it so that when you translate it back you'll get back to the original horse and that kind of forces this to be the right answer, not these, okay? But there is a problem with this cycle consistency constraint because the problem is that it forces it to be a bijection and forces it to be one-to-one because yes it's not going to, it's not going to go back to here but it's also going to constrain us to have to go back to this particular horse whereas these other horses might have been just good enough, right? So this is where kind of a bijection is not always desirable because sometimes these cycles are not a bijection. So how could we kind of address this problem? And here is the approach that we came up with which is we are going to have an image-to-image translation framework. We're starting with our with our horse. We want to get a zebra so we have a GAN loss that says okay make this a zebra, okay? And then what we're going to do in addition is we want to make this zebra to be similar in structure to this horse but not in texture and what we're going to do way to do this is we're going to enforce the structures to be the same by taking pairs of patches across the input and the output and say that these two patches need to be close to each other in features play the space and farther away than other patches from the horse image, okay? So you can see that again we are getting this whole similarity learning story here where we are basically bringing these two things to be closer and farther from the other patches of horse and again just unlike other methods where the positives are somehow automatic created by data augmentation here the the the positives are basically our input and our output so the output becomes our data augmentation, okay? And now we are back into our contrastive learning land we just basically formulate this and we basically say learn a representation such that these two guys are close so basically it kind of ignores the texture and focuses on the structure and these things are fine, okay? And and and of course what we do this we don't do this on just on the pixels we do it at different levels of of representation at at basically different menu multi-scale patch representation and we do this contrastive learning basically everywhere here in our decoder, okay? And of course we also have our gap losses as usual, okay? One kind of interesting cute note for for those who who are in this might appreciate this well we thought okay you know the positives that's everything is clear with negatives we just take all the patches from the same image and then we thought you know maybe it will be better if we take the negatives to be not just patches from the same image but also just add other patches from other images other negatives, right? Even should be even better even more negative data, right? And guess what? It turned out that this did not work as well these external patches actually made performance worse than if we just kept the eternal patch, okay? And this kind of goes back to some old work that that I have been doing on textures this is where we also seen that that patches from the same image actually provide much more information than if you start mixing them up with patches from other image and in fact Michala Rani has this wonderful example story of doing super resolution using a single image where she shows that you can do super resolution by learning from a single image you basically take an image down sample it train a cnn to up sample that one image, right? So you basically train a single image network and then just reuse that network for the original image. So that works better than if you're if you're training a standard thing with many with a large data set, okay? And basically we're seeing the same thing happening here that it's actually the patches that are in the same image that have the same illumination the same you know camera parameters the same setting they actually much more powerful information than if you just put a whole data set. So this is kind of a cute little story and you can see here how using the internal patches we get much better translation than if you we use external patches where you can see that there is a lot of mode collapse happening, okay? So yeah, so basically that's the story and this is our method and compared to compared to something like CycleGAN and other methods as well and basically we can we see that we're basically getting as well performance as good as CycleGAN in most cases but it's much faster and it's it's it's one sided you don't need to train a two thing two-way thing and and it's basically a we think it's kind of a much better a much better story and so here are some of the transformations that we have and one cute thing that we can also do is we can basically apply this to instances so for example let's say that we have a single image Claude Monet's painting we want to make it into photograph and maybe what we have also is a single image instead of data set we have a single photograph that is also let's say of water lilies, okay? Well we can basically use the same kind of contrastive learning basically just between a single reference photo and our output, okay? and have have have one have the same thing here for the for the positives and have a instead of instead of again have basically just a single discriminator here and we can get something that actually works quite a bit better than a lot of these kind of a stylization methods, okay? So this is this is competitors and this is ours and I think that ours actually looks quite a bit more natural and also better than CycleGAN. There are some other examples, okay? Let's see what timing is. Well you know I don't think I have time to go over the second point of why you sell supervision maybe I'll just give you a little bit of a hint of what I mean and then you can you can read the paper if you're interested. So basically the idea is that it's a little bit weird that we are in most of machine learning we are using a fixed training set. It's not very natural biologically because biological agents they never see the same data twice, right? So you live your life you never see the same thing twice. You see something first you you know you you deal with it you hopefully learn from it if you you know if you didn't deal from it you're dead if you deal with it you learn from it and then and then you you can recover some information from it but then you never see that again you see maybe something similar, okay? So every new piece of data is basically first in your test set and then in your training set, okay? And it seems like using a fixed data set it kind of encourages memorization because you see the same exact thing over and over and over again. In fact maybe this is actually another reason why data augmentation works because data augmentation is kind of random you create a random thing every time so you kind of get away a little bit from this memorization. So in fact this this might be kind of a subtle way in which data augmentation helps that actually has nothing to do with the data augmentation just basically randomization of your data, okay? But the point is that if you're using self supervised learning like the whole point of having a fixed training set was because it was expensive to do all these labels, you know? ImageNet, poor Fei Fei spent all of her startup money in Stanford labeling this huge data set, right? So it kind of makes sense that it's it's fixed because it took so much money to label it. But if you're using self supervised learning if you don't need the labels what's the point of having a fixed data set? Why can't we just keep downloading images from whatever the internet the TV whatever and just keep doing it all the time because we can generate our own labels. Seems kind of natural and so this is where kind of I've been pushing on this idea of kind of this online continual learning. So you can you can think of it in terms of of the standard a train valve separation. So you know you have your training set and kind of the standard thing in machine learning is you can separate it into a training set and a validation set, right? And we know that if you just train on a training set and then use the validation set to tune your high parameters you usually get better performance on the eventual test data than if you just train on all the training set all at once. Even though you're kind of you you think that it's less data that you're using for training but actually this is effect turns out to be more effective. Well we can think of the same thing in a continual way. So we can think of it as you train on the data that you have seen and then you're validating on the next data that comes along, okay? And then once you do that you just incorporate it into your training center you can keep going and they can keep going on forever. You don't ever need to stop, okay? And this I think is a kind of a very powerful trick that is made that we can now do because we can use self-supervision to do this kind of this evaluation, this testing, okay? And so this is the idea of test time training which is our attempt to operationalize this on an infinite smoothly changing stream and the idea is to basically use self-supervision to continuously adapt to new data, okay? And we did this already in the case of reinforcement learning with our curiosity work and this new work is basically trying to do it for images and this is the paper, test time training and it was in ICML 2000. Maybe just give me, I'll give you one slide of intuition of what we're doing. Basically, the idea is that we're, let's say we have a training set of object detection, right? And at training time we have our standard thing, we have our image and we have our label so nothing new here, we have input in, label out, we are training and then at the same time we also have a self-supervised head that basically given your image it does some self-supervised task. In this case we are basically our task here is rotation prediction. Given the rotated version of the image we want to predict which rotation it is. It doesn't really matter, it could be any task at all, okay? So at training time we do both of those tasks together but then at test time of course we don't have the labels but we still have this task, okay? And so we can basically around this, we can evaluate this task and if the result is not good, if it failed this self-supervised task we can do a little bit of fine-tuning, a little bit of fine-tuning training for this other task but as we're doing the fine tuning it's going to get changed representation in a way that will also impact the real task that we care about and that allows us to do better as we are changing, as we're going for the dataset. And so here is an example where you know given this image at test time basically the right label is elephant but initially it basically thinks it's a dog but then as we do this fine-tuning on our self-supervised task it figures out that it's actually less of a dog and more of an elephant and gives us the right answer and that's basically the story of the paper, sorry I had to rush but you can look at the paper online. And to conclude, why use self-supervision? One reason that I like is that it allows us to get away from this top-down semantic categorization and gets us more into this bottom-up association story and learn things from the bottom-up but we must be careful that the supervision doesn't leak in through things like data augmentation right and we need to be careful about this and second is that eventually self-supervision should enable us to check the datasets, forget about all these fixed datasets and and learn things continuously and it's you know we're still we're only starting on this direction I think it's very exciting direction very exciting problem so I'm hoping people will get excited about it okay thank you very much yeah awesome fantastic talk thanks a lot for all the amazing works yeah self-supervision is cool and does anybody have some some some question on Zoom maybe let's start with this we have a lot of questions on YouTube but I'm going to start to assume I have a lot of questions too but if somebody wants to ask question on Zoom just turn on your video and and just pick up probably I can start with one with a maybe a higher level question first so I mean the challenge in self-supervision is right you basically have visual data on you let's say correlate patches with whatever contrastive loss or whatever whatever people do now um I mean what do you think about if you're thinking about the 3d world right you have obviously a third dimension is it a smart idea to do this actually all on on images and videos and not think about I don't know like kind of project a 3d representation maybe first and then think about how to kind of get similarities in some 3d space learn a 3d representation and then you know try to channelize with the onscreen tasks later on right right no this is absolutely and and as you know you know I've been I've been angling for for going into 3d you know since since since a long time ago since our work with Derry Coyne on qualitative 3d I'm a I'm a big fan of 3d in my heart and it's kind of a little bit sad that once you know once we went to neural networks the kind of things dropped back to 2d plane for a while and now of course they're they're coming back again um okay so there's there's two answers to this question one the final you know the the ultimate answer is that 3d should emerge from our 2d of observation that the representation should figure out 3d on its own okay uh just like it's done with humans right humans are only seeing 2d projections of the 3d world okay if you have stereo maybe you have a little bit of 3d but you know I don't have stereo for example 10 percent of people in the world don't have stereo and we are perfectly fine seeing 3d okay so we learn 3d from uh from from a series of 2d representations uh and I think if we if we go from you know collections of images like ImageNet to videos for example hopefully and I'm very hoping that like it will encourage 3d to automatically emerge as as the you know inside of the representation okay so that's kind of a the the the the the glorious answer at the end of the rainbow okay uh but of course this is this is very hard this is kind of a a very tall order uh you know we are seeing a little bit of this happening we are seeing a little bit of kind of a maybe two and a half two or two point one d kind of occlusion occlusion reasoning you know figure ground reasoning uh a little bit of of that but but but it we're they're definitely far away from that right and so the second direction is okay can we kind of help it out a little bit how can we can we provide features that are more amenable to to to three dimensional manipulation and there I think uh things like like like holo-gan or or pie-gan this kind of directions are I think very exciting in in that it's kind of you you can inject some things that you know are physically true like rotation for example and and uh and so I think I think in the short in the short uh uh uh short term all of those things are I think going to be extremely helpful in the long term I'm still kind of hoping that I can learn 3d from scratch okay but who knows maybe it's too much to ask but I'm still kind of hoping that one day I will wake up in the morning and boom my computer learned 3d but we'll see do it with two cameras right we have stereo that's I mean that's the thing but I don't have stereo for example right like 10 percent of people don't have stereo stereo is actually not as important as as as as we we we we think stereo is only really important for like the you know half a meter in front of you it's like it's you know what what is it that I cannot do that everybody else can do okay I cannot put you know thread through the needle and I have trouble you know pouring wine right other than that I'm fine so really it stereo is kind of over overemphasized I think it's really parallax is much more important and parallax you can get from from video no good point I have another follow-up question um so in the similar spirit right like one argument is you can do contrastive learning and mostly it's about comparing things right you're saying one versus all classifiers like how similar are these things I mean what about going back to the original things when people using like auto encoders for pre-training and so on for like basically using generative tasks let's say oh I train my favorite game how good of a representation can I learn from learning the distribution basically right like how well like it's like this famous thing like you have to be able to create in order to understand and where to see that competing or maybe going going along the same line so what's your take channel is speaking on the lines there um I mean yeah I mean yeah we have definitely been also using out encoders as well I think with an outer encoder it's a little bit of a it's a little bit of a of a magic box like if you know if you get really lucky your outer encoder is going to capture exactly the right things and if you get unlikely it will capture all exactly the wrong things right it's it's kind of it's a compression mechanism it somehow compresses your data and and it it really depends on what you care about like sometimes it will compress the away the stuff that you care about or sometimes it will retain the stuff that you care about and it's it's a little bit hard to control what it's going to do so I think I think this kind of a similarity learning is it allows you to get a little bit more control and a little bit of more of kind of a intuition about what is it what is it being what is it that's being learned it's also kind of a has a very nice connection to kind of to graphs and graph theory that kind of think you you think about it like you have different entities and then you have kind of you can think of it like as a as like an as a like a network right like a like a uh a social network for example where you you can think of different people being connected in different ways and you can think about yeah we call them senses of similarity so there's many different senses of similarity between two instances and you know something like an out encoder is probably going to collapse them all together and here you can actually separate them you can have a similarity in color similarity in texture maybe similarity in 3d and they're all can be kind of exposed hopefully separately now that's interesting I mean our experiences so we've done a lot of stuff on like shape completion in 3d so whenever we had the ability to take stuff away and predict it then we got great features this was always amazing in terms of using these features to help semantics and whenever we're trying to classify it to help the completion this is this is always a total disaster it never worked we tried really hard actually I mean I think that that's that's been our our experience as well but but I think have you have you tried the latest uh contrastive learning because it's really it's to me the way I think about contrastive learning is it's really just old school triplet loss you know uh Siamese network learning except you're switching from from from from kind of a regression to to a classification but it's a classification with like huge amounts of data and it's very very fine grain classification so it's almost it's it's really not like your your grandma's classification it's uh I mean we we did something like this for for uh for when we did colorization so we we first we tried to do colorization with the regression and then we we we we got better results by doing classification but the classification was across like you know 500 classes of different colors in the in the in the color gamut right so it's it's a much more kind of narrow thing and that seemed to work for us but yeah like if you have a few classes then then then it's very hard to make it work but if you do something like either have lots of classes or do something like like contrastive learning where it's basically just really kind of push it with data yet it seems to to work for us now we've actually tried that so we had we had one one student project actually in collaboration with fair so Chihu one of my students they've been working on basically basically doing contrastive learning for pre-training 3d structures and in a similar way than you would do it in 2d it does help but the completion still seems to work a bit better it's very interesting I think so in general yeah I mean I think if if completions if if actually predicting you know pixels or predicting voxels whatever um it it has it has more data it has more information that and and we know that 3d world is actually much you know it's much more informative right so and it's also I think much more um uni model so the one thing that was hard for us for example when we did core colorization is what we're you know we're trying to colorize a bird and the birds could be yellow or the bird could be green right and so you have multi model you have two modes and if you're doing kind of a just sort of like a regression completion what's it going to do it's going to do the average right so it's going to be neither here nor there right but if you have a single mode it works really well so it might be that in 3d you're really in a world that's much more uni model in which you don't have like you're not trying to have an average between two different completions and they get something that doesn't look like either but you're actually really focusing on a single mode so in that case maybe this is why you're getting better results but if I suspect that if you had multi model like if you have a hole that's big enough that you could have many different plausible completions happen to it I suspect that that that then you're kind of uh the kind of the the prediction route might have more problems no I fully agree with you no that one is definitely true and and but most of the case right you're thinking about it's more like a dropout in a sense right so you're leaving out some stuff right and then you're trying to figure out what's missing in this case I think we've experienced that it works remarkably well if it's too large then you need probabilistic models again and stuff like that then it's a lot more difficult um yeah I agree yeah I think I think it's kind of a if it's a level of dropout and it should just work yeah I I I agree yeah yeah I think I think if it works you should definitely use it absolutely um actually any other questions maybe maybe somebody else can ask questions I don't want to dominate the discussion too much hi yeah thanks for the talk um I have a similarly high level question so speaking along the lines of like multi modality and and stuff like this it seems like you have a lot of inspiration in terms of how to learn perception based on how people perform perception and it seems like people do have naturally some kind of estimate of uncertainty multi modality and the ability to generate also for like these video tracking kind of applications that you showed like multiple hypotheses for where um the prediction should go and how far do you think you can get without this explicitly modeled or do you think it needs to be explicitly modeled good question I think I think I would go with I don't know so um yes humans are very good at at modeling uncertainty but they I don't think they're doing it in the way that was the decisions to it I don't think humans are actually probabilistic I think I think they might be doing it almost like if you remember from a long time ago like all this particle filtering where you can keep a whole bunch of hypotheses and then you kind of keep all of them going for a while and then you kind of uh drop one like you know there's illusion of like young lady old woman visual illusion where you know one day once time you see like an old lady one time you see a young woman right and you never see both of them so it seems some there's some very interesting mechanism going on but I think it's not it's not like a standard probabilistic mechanism and so yeah so I don't know how to deal with it and in the in the vision in the in this video paper that I showed you know we are really just keeping a whole bunch of hypotheses as we're going through the through the video at training time at test time we don't and but whether that's the right thing to do or not I don't know I think it's a very important question I don't I don't have an answer but frankly I think that nobody else does either sounds good I think one other somewhat unrelated thing I think there's a bit of a tension between people who think that we should be able to learn everything from scratch like you mentioned in terms of being able to learn 3d and whether this actually possible because it's unclear I guess how many how much supervision certainly for like some rantic perception people get direct supervision and so yeah okay now we're back to philosophy I think it must be possible because because it already happened right supervised learning is something that happens in nature but it's it's very very rare like like parents teaching their children things I know that a lot of modern parents they feel like it's super super important but sorry you know a developmental psychologist disagree they say that it doesn't really matter that much most of the things that a kid picks up they pick up without supervision they keep pick up on their own and and you could think about it you know from in the very beginning right in the beginning if you're you know as long as you believe in evolution you must believe in in unsupervised or self-supervised learning because in the beginning there was nothing there was no there was no teacher there was no supervision there was only data right and kind of the organism and its environment were co-involving and learning from each other and and and and and and develop so I think there is there is to me there is no question that it should be possible in theory I think that the kind of the the the interesting question is is it does it make sense to do in practice right and like you could also say well why don't we just simulate evolution for for a gazillion years and then we'll get everything right and that's of course not feasible with the current technology so I don't think that there is that much or maybe there shouldn't be that much tension because I think I think there are people like me who really want to try to learn things from first principles and I think this is very interesting if if if anything from you know from the biological plausibility point of view okay and there are people who just want to get stuff done and and and get to a good result too fast and those people should definitely just use whatever works best at the time so I'm not sure that it's either or I think both directions are are useful and I think we're learning from each other I think those two direction directions are informing each other so for example for a very long time self-supervised approaches worked worse than supervised approaches and so you know if you know we could have all quit because oh my god you know our stuff doesn't work as well as supervision but we persevered because we thought that you know there's something interesting that that we could learn anyway and now what we are seeing is that for some tasks self-supervision actually works better than supervised learning not for all not for many but for some there's definitely some cases when it actually the the the learning from the data actually gives you better results than learning from uh from from from from labels and so I think I think I think you know let all the flowers bloom it I think both directions are useful and I think it's it's great that people are are pushing in in in in both of them and I think we'll we'll get to a better point eventually and we'll learn more so I'm actually optimistic on on on all fronts it's yeah it's not a competition well it is a competition but it's not like it's not one is right another is wrong I think both are right cool all right I think that's a that's a very good um I guess ending of the live stream I think thanks a really lot for the amazing talk um we're a little bit over I have to apologize to a lot of questions on YouTube we couldn't unfortunately go into all of them um but um it was really great to have you and um I hope also for everybody who is with with here right now next week we'll have another great lecture with rock help and yeah we'll see so thanks a lot again for the for the great year I need great research okay um", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 12.8, "text": " All right, welcome everybody today to my lecture.", "tokens": [50364, 1057, 558, 11, 2928, 2201, 965, 281, 452, 7991, 13, 51004], "temperature": 0.0, "avg_logprob": -0.24777823887514264, "compression_ratio": 1.5240174672489082, "no_speech_prob": 0.050076063722372055}, {"id": 1, "seek": 0, "start": 12.8, "end": 14.96, "text": " It's a real pleasure to have Alyosha Efros today.", "tokens": [51004, 467, 311, 257, 957, 6834, 281, 362, 27008, 329, 1641, 31840, 2635, 965, 13, 51112], "temperature": 0.0, "avg_logprob": -0.24777823887514264, "compression_ratio": 1.5240174672489082, "no_speech_prob": 0.050076063722372055}, {"id": 2, "seek": 0, "start": 14.96, "end": 19.92, "text": " Alyosha is a professor at UC Berkeley, where he's part of the Berkeley Artificial Intelligence", "tokens": [51112, 27008, 329, 1641, 307, 257, 8304, 412, 14079, 23684, 11, 689, 415, 311, 644, 295, 264, 23684, 5735, 10371, 27274, 51360], "temperature": 0.0, "avg_logprob": -0.24777823887514264, "compression_ratio": 1.5240174672489082, "no_speech_prob": 0.050076063722372055}, {"id": 3, "seek": 0, "start": 19.92, "end": 22.2, "text": " Research Lab there.", "tokens": [51360, 10303, 10137, 456, 13, 51474], "temperature": 0.0, "avg_logprob": -0.24777823887514264, "compression_ratio": 1.5240174672489082, "no_speech_prob": 0.050076063722372055}, {"id": 4, "seek": 0, "start": 22.2, "end": 26.240000000000002, "text": " His work is at the intersection of graphics and computer vision, and I'm sure pretty much", "tokens": [51474, 2812, 589, 307, 412, 264, 15236, 295, 11837, 293, 3820, 5201, 11, 293, 286, 478, 988, 1238, 709, 51676], "temperature": 0.0, "avg_logprob": -0.24777823887514264, "compression_ratio": 1.5240174672489082, "no_speech_prob": 0.050076063722372055}, {"id": 5, "seek": 0, "start": 26.240000000000002, "end": 29.240000000000002, "text": " everybody in the community has heard of him.", "tokens": [51676, 2201, 294, 264, 1768, 575, 2198, 295, 796, 13, 51826], "temperature": 0.0, "avg_logprob": -0.24777823887514264, "compression_ratio": 1.5240174672489082, "no_speech_prob": 0.050076063722372055}, {"id": 6, "seek": 2924, "start": 29.24, "end": 33.4, "text": " He's a pioneer at the intersection in these fields.", "tokens": [50364, 634, 311, 257, 37668, 412, 264, 15236, 294, 613, 7909, 13, 50572], "temperature": 0.0, "avg_logprob": -0.23199135366112295, "compression_ratio": 1.5513307984790874, "no_speech_prob": 0.0033703886438161135}, {"id": 7, "seek": 2924, "start": 33.4, "end": 38.879999999999995, "text": " He has countless of exciting papers, starting from texture synthesis to conditional GANs", "tokens": [50572, 634, 575, 19223, 295, 4670, 10577, 11, 2891, 490, 8091, 30252, 281, 27708, 460, 1770, 82, 50846], "temperature": 0.0, "avg_logprob": -0.23199135366112295, "compression_ratio": 1.5513307984790874, "no_speech_prob": 0.0033703886438161135}, {"id": 8, "seek": 2924, "start": 38.879999999999995, "end": 41.72, "text": " like Pics to Pics and Cycle GAN.", "tokens": [50846, 411, 430, 1167, 281, 430, 1167, 293, 10295, 2160, 460, 1770, 13, 50988], "temperature": 0.0, "avg_logprob": -0.23199135366112295, "compression_ratio": 1.5513307984790874, "no_speech_prob": 0.0033703886438161135}, {"id": 9, "seek": 2924, "start": 41.72, "end": 46.480000000000004, "text": " He's particularly known for his creativity and thought-provoking work, which is an inspiration", "tokens": [50988, 634, 311, 4098, 2570, 337, 702, 12915, 293, 1194, 12, 49911, 5953, 589, 11, 597, 307, 364, 10249, 51226], "temperature": 0.0, "avg_logprob": -0.23199135366112295, "compression_ratio": 1.5513307984790874, "no_speech_prob": 0.0033703886438161135}, {"id": 10, "seek": 2924, "start": 46.480000000000004, "end": 48.28, "text": " to many young researchers.", "tokens": [51226, 281, 867, 2037, 10309, 13, 51316], "temperature": 0.0, "avg_logprob": -0.23199135366112295, "compression_ratio": 1.5513307984790874, "no_speech_prob": 0.0033703886438161135}, {"id": 11, "seek": 2924, "start": 48.28, "end": 51.32, "text": " His students have also had really great success.", "tokens": [51316, 2812, 1731, 362, 611, 632, 534, 869, 2245, 13, 51468], "temperature": 0.0, "avg_logprob": -0.23199135366112295, "compression_ratio": 1.5513307984790874, "no_speech_prob": 0.0033703886438161135}, {"id": 12, "seek": 2924, "start": 51.32, "end": 54.959999999999994, "text": " You can see many of his students are now professors themselves.", "tokens": [51468, 509, 393, 536, 867, 295, 702, 1731, 366, 586, 15924, 2969, 13, 51650], "temperature": 0.0, "avg_logprob": -0.23199135366112295, "compression_ratio": 1.5513307984790874, "no_speech_prob": 0.0033703886438161135}, {"id": 13, "seek": 5496, "start": 54.96, "end": 60.120000000000005, "text": " And I think it's also, yeah, it's fair to say that he has also a very great social", "tokens": [50364, 400, 286, 519, 309, 311, 611, 11, 1338, 11, 309, 311, 3143, 281, 584, 300, 415, 575, 611, 257, 588, 869, 2093, 50622], "temperature": 0.0, "avg_logprob": -0.18510469032900176, "compression_ratio": 1.9151943462897527, "no_speech_prob": 0.002470012754201889}, {"id": 14, "seek": 5496, "start": 60.120000000000005, "end": 63.84, "text": " engagement, in particular, contributing to the research community.", "tokens": [50622, 8742, 11, 294, 1729, 11, 19270, 281, 264, 2132, 1768, 13, 50808], "temperature": 0.0, "avg_logprob": -0.18510469032900176, "compression_ratio": 1.9151943462897527, "no_speech_prob": 0.002470012754201889}, {"id": 15, "seek": 5496, "start": 63.84, "end": 68.28, "text": " If you haven't met him in person, I can only recommend reach out to him at the conferences", "tokens": [50808, 759, 291, 2378, 380, 1131, 796, 294, 954, 11, 286, 393, 787, 2748, 2524, 484, 281, 796, 412, 264, 22032, 51030], "temperature": 0.0, "avg_logprob": -0.18510469032900176, "compression_ratio": 1.9151943462897527, "no_speech_prob": 0.002470012754201889}, {"id": 16, "seek": 5496, "start": 68.28, "end": 69.28, "text": " once we have them again.", "tokens": [51030, 1564, 321, 362, 552, 797, 13, 51080], "temperature": 0.0, "avg_logprob": -0.18510469032900176, "compression_ratio": 1.9151943462897527, "no_speech_prob": 0.002470012754201889}, {"id": 17, "seek": 5496, "start": 69.28, "end": 71.04, "text": " It's really great to have him around.", "tokens": [51080, 467, 311, 534, 869, 281, 362, 796, 926, 13, 51168], "temperature": 0.0, "avg_logprob": -0.18510469032900176, "compression_ratio": 1.9151943462897527, "no_speech_prob": 0.002470012754201889}, {"id": 18, "seek": 5496, "start": 71.04, "end": 75.32, "text": " It's really great hanging around with him at one of the poster sessions and chat about", "tokens": [51168, 467, 311, 534, 869, 8345, 926, 365, 796, 412, 472, 295, 264, 17171, 11081, 293, 5081, 466, 51382], "temperature": 0.0, "avg_logprob": -0.18510469032900176, "compression_ratio": 1.9151943462897527, "no_speech_prob": 0.002470012754201889}, {"id": 19, "seek": 5496, "start": 75.32, "end": 76.76, "text": " some really exciting research.", "tokens": [51382, 512, 534, 4670, 2132, 13, 51454], "temperature": 0.0, "avg_logprob": -0.18510469032900176, "compression_ratio": 1.9151943462897527, "no_speech_prob": 0.002470012754201889}, {"id": 20, "seek": 5496, "start": 76.76, "end": 81.0, "text": " He's particularly known for his, yeah, really cool attitude, and it's really great to have", "tokens": [51454, 634, 311, 4098, 2570, 337, 702, 11, 1338, 11, 534, 1627, 10157, 11, 293, 309, 311, 534, 869, 281, 362, 51666], "temperature": 0.0, "avg_logprob": -0.18510469032900176, "compression_ratio": 1.9151943462897527, "no_speech_prob": 0.002470012754201889}, {"id": 21, "seek": 5496, "start": 81.0, "end": 82.8, "text": " him as part of the community.", "tokens": [51666, 796, 382, 644, 295, 264, 1768, 13, 51756], "temperature": 0.0, "avg_logprob": -0.18510469032900176, "compression_ratio": 1.9151943462897527, "no_speech_prob": 0.002470012754201889}, {"id": 22, "seek": 8280, "start": 82.8, "end": 84.88, "text": " So it's a real pleasure to have you here.", "tokens": [50364, 407, 309, 311, 257, 957, 6834, 281, 362, 291, 510, 13, 50468], "temperature": 0.0, "avg_logprob": -0.205668427223383, "compression_ratio": 1.539906103286385, "no_speech_prob": 0.005376328714191914}, {"id": 23, "seek": 8280, "start": 84.88, "end": 86.8, "text": " And I'm really looking forward to the talk.", "tokens": [50468, 400, 286, 478, 534, 1237, 2128, 281, 264, 751, 13, 50564], "temperature": 0.0, "avg_logprob": -0.205668427223383, "compression_ratio": 1.539906103286385, "no_speech_prob": 0.005376328714191914}, {"id": 24, "seek": 8280, "start": 86.8, "end": 89.64, "text": " And you also promised some philosophical components.", "tokens": [50564, 400, 291, 611, 10768, 512, 25066, 6677, 13, 50706], "temperature": 0.0, "avg_logprob": -0.205668427223383, "compression_ratio": 1.539906103286385, "no_speech_prob": 0.005376328714191914}, {"id": 25, "seek": 8280, "start": 89.64, "end": 94.12, "text": " So I'm really excited what that's going to be.", "tokens": [50706, 407, 286, 478, 534, 2919, 437, 300, 311, 516, 281, 312, 13, 50930], "temperature": 0.0, "avg_logprob": -0.205668427223383, "compression_ratio": 1.539906103286385, "no_speech_prob": 0.005376328714191914}, {"id": 26, "seek": 8280, "start": 94.12, "end": 97.96, "text": " Thank you so much for such a gracious introduction.", "tokens": [50930, 1044, 291, 370, 709, 337, 1270, 257, 36113, 9339, 13, 51122], "temperature": 0.0, "avg_logprob": -0.205668427223383, "compression_ratio": 1.539906103286385, "no_speech_prob": 0.005376328714191914}, {"id": 27, "seek": 8280, "start": 97.96, "end": 111.67999999999999, "text": " Yeah, I'm sad that we have to do this virtually because I would love to have hung out with", "tokens": [51122, 865, 11, 286, 478, 4227, 300, 321, 362, 281, 360, 341, 14103, 570, 286, 576, 959, 281, 362, 5753, 484, 365, 51808], "temperature": 0.0, "avg_logprob": -0.205668427223383, "compression_ratio": 1.539906103286385, "no_speech_prob": 0.005376328714191914}, {"id": 28, "seek": 11168, "start": 111.68, "end": 116.4, "text": " you guys and gone for some wonderful Barbarian beers.", "tokens": [50364, 291, 1074, 293, 2780, 337, 512, 3715, 4156, 5356, 952, 34159, 13, 50600], "temperature": 0.0, "avg_logprob": -0.2717138064109673, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.2513797879219055}, {"id": 29, "seek": 11168, "start": 116.4, "end": 121.88000000000001, "text": " But next time, yes, thank you very much for inviting me.", "tokens": [50600, 583, 958, 565, 11, 2086, 11, 1309, 291, 588, 709, 337, 18202, 385, 13, 50874], "temperature": 0.0, "avg_logprob": -0.2717138064109673, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.2513797879219055}, {"id": 30, "seek": 11168, "start": 121.88000000000001, "end": 131.04000000000002, "text": " And it's such a star spangled roster of speakers that you have there.", "tokens": [50874, 400, 309, 311, 1270, 257, 3543, 637, 39101, 29892, 295, 9518, 300, 291, 362, 456, 13, 51332], "temperature": 0.0, "avg_logprob": -0.2717138064109673, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.2513797879219055}, {"id": 31, "seek": 11168, "start": 131.04000000000002, "end": 136.52, "text": " I hope I will not disappoint.", "tokens": [51332, 286, 1454, 286, 486, 406, 8505, 13, 51606], "temperature": 0.0, "avg_logprob": -0.2717138064109673, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.2513797879219055}, {"id": 32, "seek": 13652, "start": 136.52, "end": 142.96, "text": " And so I'm going to talk about aspects of self-supervision.", "tokens": [50364, 400, 370, 286, 478, 516, 281, 751, 466, 7270, 295, 2698, 12, 48172, 6763, 13, 50686], "temperature": 0.0, "avg_logprob": -0.15277268513139472, "compression_ratio": 1.6597938144329898, "no_speech_prob": 0.09873775392770767}, {"id": 33, "seek": 13652, "start": 142.96, "end": 148.36, "text": " Self-supervision is something that my lab has been working for a number of years.", "tokens": [50686, 16348, 12, 48172, 6763, 307, 746, 300, 452, 2715, 575, 668, 1364, 337, 257, 1230, 295, 924, 13, 50956], "temperature": 0.0, "avg_logprob": -0.15277268513139472, "compression_ratio": 1.6597938144329898, "no_speech_prob": 0.09873775392770767}, {"id": 34, "seek": 13652, "start": 148.36, "end": 153.52, "text": " And just to make sure everyone's on the same page, self-supervised learning is when we,", "tokens": [50956, 400, 445, 281, 652, 988, 1518, 311, 322, 264, 912, 3028, 11, 2698, 12, 48172, 24420, 2539, 307, 562, 321, 11, 51214], "temperature": 0.0, "avg_logprob": -0.15277268513139472, "compression_ratio": 1.6597938144329898, "no_speech_prob": 0.09873775392770767}, {"id": 35, "seek": 13652, "start": 153.52, "end": 161.28, "text": " this is my definition, you know, hopefully there is no one set definition, but my definition", "tokens": [51214, 341, 307, 452, 7123, 11, 291, 458, 11, 4696, 456, 307, 572, 472, 992, 7123, 11, 457, 452, 7123, 51602], "temperature": 0.0, "avg_logprob": -0.15277268513139472, "compression_ratio": 1.6597938144329898, "no_speech_prob": 0.09873775392770767}, {"id": 36, "seek": 16128, "start": 161.28, "end": 169.96, "text": " is that it's when we use the tools of supervised learning, but where the labels are the raw", "tokens": [50364, 307, 300, 309, 311, 562, 321, 764, 264, 3873, 295, 46533, 2539, 11, 457, 689, 264, 16949, 366, 264, 8936, 50798], "temperature": 0.0, "avg_logprob": -0.14710490734546217, "compression_ratio": 1.6031746031746033, "no_speech_prob": 0.012414987199008465}, {"id": 37, "seek": 16128, "start": 169.96, "end": 174.6, "text": " data instead of being human-provided.", "tokens": [50798, 1412, 2602, 295, 885, 1952, 12, 49911, 2112, 13, 51030], "temperature": 0.0, "avg_logprob": -0.14710490734546217, "compression_ratio": 1.6031746031746033, "no_speech_prob": 0.012414987199008465}, {"id": 38, "seek": 16128, "start": 174.6, "end": 181.64, "text": " And so the question that often students ask is why use self-supervised learning?", "tokens": [51030, 400, 370, 264, 1168, 300, 2049, 1731, 1029, 307, 983, 764, 2698, 12, 48172, 24420, 2539, 30, 51382], "temperature": 0.0, "avg_logprob": -0.14710490734546217, "compression_ratio": 1.6031746031746033, "no_speech_prob": 0.012414987199008465}, {"id": 39, "seek": 16128, "start": 181.64, "end": 183.48, "text": " What's the point?", "tokens": [51382, 708, 311, 264, 935, 30, 51474], "temperature": 0.0, "avg_logprob": -0.14710490734546217, "compression_ratio": 1.6031746031746033, "no_speech_prob": 0.012414987199008465}, {"id": 40, "seek": 16128, "start": 183.48, "end": 189.12, "text": " And the classic answer, the common answer is because labels are expensive.", "tokens": [51474, 400, 264, 7230, 1867, 11, 264, 2689, 1867, 307, 570, 16949, 366, 5124, 13, 51756], "temperature": 0.0, "avg_logprob": -0.14710490734546217, "compression_ratio": 1.6031746031746033, "no_speech_prob": 0.012414987199008465}, {"id": 41, "seek": 18912, "start": 189.12, "end": 196.4, "text": " Instead of having humans provide labels and annotating them using lots of hours of work", "tokens": [50364, 7156, 295, 1419, 6255, 2893, 16949, 293, 25339, 990, 552, 1228, 3195, 295, 2496, 295, 589, 50728], "temperature": 0.0, "avg_logprob": -0.1645361363202676, "compression_ratio": 1.5870646766169154, "no_speech_prob": 0.028309691697359085}, {"id": 42, "seek": 18912, "start": 196.4, "end": 205.96, "text": " or high cost, here we get used the data itself as our labels.", "tokens": [50728, 420, 1090, 2063, 11, 510, 321, 483, 1143, 264, 1412, 2564, 382, 527, 16949, 13, 51206], "temperature": 0.0, "avg_logprob": -0.1645361363202676, "compression_ratio": 1.5870646766169154, "no_speech_prob": 0.028309691697359085}, {"id": 43, "seek": 18912, "start": 205.96, "end": 210.32, "text": " So this is the common answer, but that's not really my main answer.", "tokens": [51206, 407, 341, 307, 264, 2689, 1867, 11, 457, 300, 311, 406, 534, 452, 2135, 1867, 13, 51424], "temperature": 0.0, "avg_logprob": -0.1645361363202676, "compression_ratio": 1.5870646766169154, "no_speech_prob": 0.028309691697359085}, {"id": 44, "seek": 18912, "start": 210.32, "end": 214.48000000000002, "text": " This is, it's nice, but it's not the main reason for me.", "tokens": [51424, 639, 307, 11, 309, 311, 1481, 11, 457, 309, 311, 406, 264, 2135, 1778, 337, 385, 13, 51632], "temperature": 0.0, "avg_logprob": -0.1645361363202676, "compression_ratio": 1.5870646766169154, "no_speech_prob": 0.028309691697359085}, {"id": 45, "seek": 18912, "start": 214.48000000000002, "end": 218.32, "text": " For me, I actually have a couple of answers.", "tokens": [51632, 1171, 385, 11, 286, 767, 362, 257, 1916, 295, 6338, 13, 51824], "temperature": 0.0, "avg_logprob": -0.1645361363202676, "compression_ratio": 1.5870646766169154, "no_speech_prob": 0.028309691697359085}, {"id": 46, "seek": 21832, "start": 218.32, "end": 226.35999999999999, "text": " The first one answer is that self-supervised learning allows us to get away from the tyranny", "tokens": [50364, 440, 700, 472, 1867, 307, 300, 2698, 12, 48172, 24420, 2539, 4045, 505, 281, 483, 1314, 490, 264, 41108, 11612, 50766], "temperature": 0.0, "avg_logprob": -0.14874935150146484, "compression_ratio": 1.6231155778894473, "no_speech_prob": 0.004257167223840952}, {"id": 47, "seek": 21832, "start": 226.35999999999999, "end": 233.23999999999998, "text": " of this top-down semantic categorization that goes all the way to Plato and Socrates.", "tokens": [50766, 295, 341, 1192, 12, 5093, 47982, 19250, 2144, 300, 1709, 439, 264, 636, 281, 43027, 293, 407, 50243, 13, 51110], "temperature": 0.0, "avg_logprob": -0.14874935150146484, "compression_ratio": 1.6231155778894473, "no_speech_prob": 0.004257167223840952}, {"id": 48, "seek": 21832, "start": 233.23999999999998, "end": 237.95999999999998, "text": " And I'll tell you why I think this is a good thing.", "tokens": [51110, 400, 286, 603, 980, 291, 983, 286, 519, 341, 307, 257, 665, 551, 13, 51346], "temperature": 0.0, "avg_logprob": -0.14874935150146484, "compression_ratio": 1.6231155778894473, "no_speech_prob": 0.004257167223840952}, {"id": 49, "seek": 21832, "start": 237.95999999999998, "end": 246.28, "text": " And the second reason is that self-supervised learning will hopefully enable us to move away", "tokens": [51346, 400, 264, 1150, 1778, 307, 300, 2698, 12, 48172, 24420, 2539, 486, 4696, 9528, 505, 281, 1286, 1314, 51762], "temperature": 0.0, "avg_logprob": -0.14874935150146484, "compression_ratio": 1.6231155778894473, "no_speech_prob": 0.004257167223840952}, {"id": 50, "seek": 24628, "start": 246.52, "end": 256.16, "text": " from this idea of a fixed training set to a more continuous lifelong learning where you", "tokens": [50376, 490, 341, 1558, 295, 257, 6806, 3097, 992, 281, 257, 544, 10957, 27232, 2539, 689, 291, 50858], "temperature": 0.0, "avg_logprob": -0.15773645691249683, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.02468651719391346}, {"id": 51, "seek": 24628, "start": 256.16, "end": 260.12, "text": " have data streaming in and then you learn on the go.", "tokens": [50858, 362, 1412, 11791, 294, 293, 550, 291, 1466, 322, 264, 352, 13, 51056], "temperature": 0.0, "avg_logprob": -0.15773645691249683, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.02468651719391346}, {"id": 52, "seek": 24628, "start": 260.12, "end": 264.84, "text": " You learn as you live, rather than having this kind of training set, testing set, split", "tokens": [51056, 509, 1466, 382, 291, 1621, 11, 2831, 813, 1419, 341, 733, 295, 3097, 992, 11, 4997, 992, 11, 7472, 51292], "temperature": 0.0, "avg_logprob": -0.15773645691249683, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.02468651719391346}, {"id": 53, "seek": 24628, "start": 264.84, "end": 270.12, "text": " that is kind of the classic thing in machine learning.", "tokens": [51292, 300, 307, 733, 295, 264, 7230, 551, 294, 3479, 2539, 13, 51556], "temperature": 0.0, "avg_logprob": -0.15773645691249683, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.02468651719391346}, {"id": 54, "seek": 24628, "start": 270.12, "end": 274.44, "text": " So I will start, and most of the talk is going to be about the first one, and then hopefully", "tokens": [51556, 407, 286, 486, 722, 11, 293, 881, 295, 264, 751, 307, 516, 281, 312, 466, 264, 700, 472, 11, 293, 550, 4696, 51772], "temperature": 0.0, "avg_logprob": -0.15773645691249683, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.02468651719391346}, {"id": 55, "seek": 27444, "start": 274.44, "end": 278.0, "text": " we'll do a little bit of number two, okay?", "tokens": [50364, 321, 603, 360, 257, 707, 857, 295, 1230, 732, 11, 1392, 30, 50542], "temperature": 0.0, "avg_logprob": -0.19209150365881017, "compression_ratio": 1.5575757575757576, "no_speech_prob": 0.0005523740546777844}, {"id": 56, "seek": 27444, "start": 278.0, "end": 282.52, "text": " So what's the problem with semantic categories?", "tokens": [50542, 407, 437, 311, 264, 1154, 365, 47982, 10479, 30, 50768], "temperature": 0.0, "avg_logprob": -0.19209150365881017, "compression_ratio": 1.5575757575757576, "no_speech_prob": 0.0005523740546777844}, {"id": 57, "seek": 27444, "start": 282.52, "end": 288.32, "text": " Well, let's look at, from the visual point of view, let's look at a couple of categories", "tokens": [50768, 1042, 11, 718, 311, 574, 412, 11, 490, 264, 5056, 935, 295, 1910, 11, 718, 311, 574, 412, 257, 1916, 295, 10479, 51058], "temperature": 0.0, "avg_logprob": -0.19209150365881017, "compression_ratio": 1.5575757575757576, "no_speech_prob": 0.0005523740546777844}, {"id": 58, "seek": 27444, "start": 288.32, "end": 291.44, "text": " from a standard visual data set.", "tokens": [51058, 490, 257, 3832, 5056, 1412, 992, 13, 51214], "temperature": 0.0, "avg_logprob": -0.19209150365881017, "compression_ratio": 1.5575757575757576, "no_speech_prob": 0.0005523740546777844}, {"id": 59, "seek": 27444, "start": 291.44, "end": 296.36, "text": " So the first is what's called a chair, okay?", "tokens": [51214, 407, 264, 700, 307, 437, 311, 1219, 257, 6090, 11, 1392, 30, 51460], "temperature": 0.0, "avg_logprob": -0.19209150365881017, "compression_ratio": 1.5575757575757576, "no_speech_prob": 0.0005523740546777844}, {"id": 60, "seek": 29636, "start": 296.36, "end": 306.28000000000003, "text": " But you can look at all the different chairs that you could have in the wild, and you realize", "tokens": [50364, 583, 291, 393, 574, 412, 439, 264, 819, 18299, 300, 291, 727, 362, 294, 264, 4868, 11, 293, 291, 4325, 50860], "temperature": 0.0, "avg_logprob": -0.17025559569058352, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.016642235219478607}, {"id": 61, "seek": 29636, "start": 306.28000000000003, "end": 316.36, "text": " that this is very hard to find what is in common between all of these chairs, right?", "tokens": [50860, 300, 341, 307, 588, 1152, 281, 915, 437, 307, 294, 2689, 1296, 439, 295, 613, 18299, 11, 558, 30, 51364], "temperature": 0.0, "avg_logprob": -0.17025559569058352, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.016642235219478607}, {"id": 62, "seek": 29636, "start": 316.36, "end": 321.36, "text": " Visually, actually, there is pretty much nothing in common because between something", "tokens": [51364, 10410, 671, 11, 767, 11, 456, 307, 1238, 709, 1825, 294, 2689, 570, 1296, 746, 51614], "temperature": 0.0, "avg_logprob": -0.17025559569058352, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.016642235219478607}, {"id": 63, "seek": 29636, "start": 321.36, "end": 323.24, "text": " like this and something like this, right?", "tokens": [51614, 411, 341, 293, 746, 411, 341, 11, 558, 30, 51708], "temperature": 0.0, "avg_logprob": -0.17025559569058352, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.016642235219478607}, {"id": 64, "seek": 32324, "start": 323.24, "end": 327.76, "text": " This chair is really more of a functional category, right?", "tokens": [50364, 639, 6090, 307, 534, 544, 295, 257, 11745, 7719, 11, 558, 30, 50590], "temperature": 0.0, "avg_logprob": -0.14863533876380142, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0085731390863657}, {"id": 65, "seek": 32324, "start": 327.76, "end": 329.52, "text": " And think about it this way.", "tokens": [50590, 400, 519, 466, 309, 341, 636, 13, 50678], "temperature": 0.0, "avg_logprob": -0.14863533876380142, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0085731390863657}, {"id": 66, "seek": 32324, "start": 329.52, "end": 335.84000000000003, "text": " We can see them all being chairs because we have seen, you know, butts being squeezed", "tokens": [50678, 492, 393, 536, 552, 439, 885, 18299, 570, 321, 362, 1612, 11, 291, 458, 11, 46789, 885, 39470, 50994], "temperature": 0.0, "avg_logprob": -0.14863533876380142, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0085731390863657}, {"id": 67, "seek": 32324, "start": 335.84000000000003, "end": 338.3, "text": " into these places.", "tokens": [50994, 666, 613, 3190, 13, 51117], "temperature": 0.0, "avg_logprob": -0.14863533876380142, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0085731390863657}, {"id": 68, "seek": 32324, "start": 338.3, "end": 344.24, "text": " But if you are a computer, if all you've seen in your life is ImageNet data set, for example,", "tokens": [51117, 583, 498, 291, 366, 257, 3820, 11, 498, 439, 291, 600, 1612, 294, 428, 993, 307, 29903, 31890, 1412, 992, 11, 337, 1365, 11, 51414], "temperature": 0.0, "avg_logprob": -0.14863533876380142, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0085731390863657}, {"id": 69, "seek": 32324, "start": 344.24, "end": 350.12, "text": " if you've never seen any videos, you've never seen any people sitting on anything, there", "tokens": [51414, 498, 291, 600, 1128, 1612, 604, 2145, 11, 291, 600, 1128, 1612, 604, 561, 3798, 322, 1340, 11, 456, 51708], "temperature": 0.0, "avg_logprob": -0.14863533876380142, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0085731390863657}, {"id": 70, "seek": 35012, "start": 350.12, "end": 355.92, "text": " is basically no way for you to realize that all of these are somehow related, right?", "tokens": [50364, 307, 1936, 572, 636, 337, 291, 281, 4325, 300, 439, 295, 613, 366, 6063, 4077, 11, 558, 30, 50654], "temperature": 0.0, "avg_logprob": -0.1076114256303389, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.0020822668448090553}, {"id": 71, "seek": 35012, "start": 355.92, "end": 360.6, "text": " So the relationship here is not visual.", "tokens": [50654, 407, 264, 2480, 510, 307, 406, 5056, 13, 50888], "temperature": 0.0, "avg_logprob": -0.1076114256303389, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.0020822668448090553}, {"id": 72, "seek": 35012, "start": 360.6, "end": 362.44, "text": " The relationship is functional.", "tokens": [50888, 440, 2480, 307, 11745, 13, 50980], "temperature": 0.0, "avg_logprob": -0.1076114256303389, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.0020822668448090553}, {"id": 73, "seek": 35012, "start": 362.44, "end": 366.04, "text": " The relationship is that of affordances.", "tokens": [50980, 440, 2480, 307, 300, 295, 6157, 2676, 13, 51160], "temperature": 0.0, "avg_logprob": -0.1076114256303389, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.0020822668448090553}, {"id": 74, "seek": 35012, "start": 366.04, "end": 372.2, "text": " And it's not really fair for a computer to try really, really hard to find a way to kind", "tokens": [51160, 400, 309, 311, 406, 534, 3143, 337, 257, 3820, 281, 853, 534, 11, 534, 1152, 281, 915, 257, 636, 281, 733, 51468], "temperature": 0.0, "avg_logprob": -0.1076114256303389, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.0020822668448090553}, {"id": 75, "seek": 35012, "start": 372.2, "end": 378.68, "text": " of somehow bring them all into some kind of a connection where maybe there isn't that", "tokens": [51468, 295, 6063, 1565, 552, 439, 666, 512, 733, 295, 257, 4984, 689, 1310, 456, 1943, 380, 300, 51792], "temperature": 0.0, "avg_logprob": -0.1076114256303389, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.0020822668448090553}, {"id": 76, "seek": 37868, "start": 378.68, "end": 382.40000000000003, "text": " much of a connection, okay?", "tokens": [50364, 709, 295, 257, 4984, 11, 1392, 30, 50550], "temperature": 0.0, "avg_logprob": -0.15175908925581952, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.03661254420876503}, {"id": 77, "seek": 37868, "start": 382.40000000000003, "end": 386.76, "text": " The second example I like is this one called City, okay?", "tokens": [50550, 440, 1150, 1365, 286, 411, 307, 341, 472, 1219, 4392, 11, 1392, 30, 50768], "temperature": 0.0, "avg_logprob": -0.15175908925581952, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.03661254420876503}, {"id": 78, "seek": 37868, "start": 386.76, "end": 392.32, "text": " And here what I'm showing here is a picture of downtown Pittsburgh in a picture of the", "tokens": [50768, 400, 510, 437, 286, 478, 4099, 510, 307, 257, 3036, 295, 14209, 33626, 294, 257, 3036, 295, 264, 51046], "temperature": 0.0, "avg_logprob": -0.15175908925581952, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.03661254420876503}, {"id": 79, "seek": 37868, "start": 392.32, "end": 394.44, "text": " center of Paris, okay?", "tokens": [51046, 3056, 295, 8380, 11, 1392, 30, 51152], "temperature": 0.0, "avg_logprob": -0.15175908925581952, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.03661254420876503}, {"id": 80, "seek": 37868, "start": 394.44, "end": 401.96000000000004, "text": " And frankly, you know, the fact that both of these by some fluke of the English language", "tokens": [51152, 400, 11939, 11, 291, 458, 11, 264, 1186, 300, 1293, 295, 613, 538, 512, 5029, 330, 295, 264, 3669, 2856, 51528], "temperature": 0.0, "avg_logprob": -0.15175908925581952, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.03661254420876503}, {"id": 81, "seek": 37868, "start": 401.96000000000004, "end": 408.6, "text": " are termed City, the same noun, this is just kind of a coincidence because there is really", "tokens": [51528, 366, 1433, 292, 4392, 11, 264, 912, 23307, 11, 341, 307, 445, 733, 295, 257, 22137, 570, 456, 307, 534, 51860], "temperature": 0.0, "avg_logprob": -0.15175908925581952, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.03661254420876503}, {"id": 82, "seek": 40860, "start": 408.6, "end": 412.72, "text": " nothing visually in common between those two, right?", "tokens": [50364, 1825, 19622, 294, 2689, 1296, 729, 732, 11, 558, 30, 50570], "temperature": 0.0, "avg_logprob": -0.17732235717773437, "compression_ratio": 1.9919354838709677, "no_speech_prob": 0.0517902597784996}, {"id": 83, "seek": 40860, "start": 412.72, "end": 416.32000000000005, "text": " And people can argue, well, wait a minute, you know, both contain buildings, but look", "tokens": [50570, 400, 561, 393, 9695, 11, 731, 11, 1699, 257, 3456, 11, 291, 458, 11, 1293, 5304, 7446, 11, 457, 574, 50750], "temperature": 0.0, "avg_logprob": -0.17732235717773437, "compression_ratio": 1.9919354838709677, "no_speech_prob": 0.0517902597784996}, {"id": 84, "seek": 40860, "start": 416.32000000000005, "end": 417.32000000000005, "text": " at the buildings.", "tokens": [50750, 412, 264, 7446, 13, 50800], "temperature": 0.0, "avg_logprob": -0.17732235717773437, "compression_ratio": 1.9919354838709677, "no_speech_prob": 0.0517902597784996}, {"id": 85, "seek": 40860, "start": 417.32000000000005, "end": 421.76000000000005, "text": " The buildings are so different visually, there is nothing in common between those buildings,", "tokens": [50800, 440, 7446, 366, 370, 819, 19622, 11, 456, 307, 1825, 294, 2689, 1296, 729, 7446, 11, 51022], "temperature": 0.0, "avg_logprob": -0.17732235717773437, "compression_ratio": 1.9919354838709677, "no_speech_prob": 0.0517902597784996}, {"id": 86, "seek": 40860, "start": 421.76000000000005, "end": 422.76000000000005, "text": " right?", "tokens": [51022, 558, 30, 51072], "temperature": 0.0, "avg_logprob": -0.17732235717773437, "compression_ratio": 1.9919354838709677, "no_speech_prob": 0.0517902597784996}, {"id": 87, "seek": 40860, "start": 422.76000000000005, "end": 423.76000000000005, "text": " They're so visually different.", "tokens": [51072, 814, 434, 370, 19622, 819, 13, 51122], "temperature": 0.0, "avg_logprob": -0.17732235717773437, "compression_ratio": 1.9919354838709677, "no_speech_prob": 0.0517902597784996}, {"id": 88, "seek": 40860, "start": 423.76000000000005, "end": 427.28000000000003, "text": " And then you can say, well, but they both have windows, but again, look at the windows.", "tokens": [51122, 400, 550, 291, 393, 584, 11, 731, 11, 457, 436, 1293, 362, 9309, 11, 457, 797, 11, 574, 412, 264, 9309, 13, 51298], "temperature": 0.0, "avg_logprob": -0.17732235717773437, "compression_ratio": 1.9919354838709677, "no_speech_prob": 0.0517902597784996}, {"id": 89, "seek": 40860, "start": 427.28000000000003, "end": 429.24, "text": " The windows don't look anything the same.", "tokens": [51298, 440, 9309, 500, 380, 574, 1340, 264, 912, 13, 51396], "temperature": 0.0, "avg_logprob": -0.17732235717773437, "compression_ratio": 1.9919354838709677, "no_speech_prob": 0.0517902597784996}, {"id": 90, "seek": 40860, "start": 429.24, "end": 434.96000000000004, "text": " Look, there is really not a single pixel in common between these two things.", "tokens": [51396, 2053, 11, 456, 307, 534, 406, 257, 2167, 19261, 294, 2689, 1296, 613, 732, 721, 13, 51682], "temperature": 0.0, "avg_logprob": -0.17732235717773437, "compression_ratio": 1.9919354838709677, "no_speech_prob": 0.0517902597784996}, {"id": 91, "seek": 43496, "start": 434.96, "end": 440.91999999999996, "text": " And so again, we are forcing the computer to do something, to somehow try to generalize", "tokens": [50364, 400, 370, 797, 11, 321, 366, 19030, 264, 3820, 281, 360, 746, 11, 281, 6063, 853, 281, 2674, 1125, 50662], "temperature": 0.0, "avg_logprob": -0.1379741955828923, "compression_ratio": 1.6822429906542056, "no_speech_prob": 0.02838738076388836}, {"id": 92, "seek": 43496, "start": 440.91999999999996, "end": 446.88, "text": " across these two things that are very, very different, that might not have anything in", "tokens": [50662, 2108, 613, 732, 721, 300, 366, 588, 11, 588, 819, 11, 300, 1062, 406, 362, 1340, 294, 50960], "temperature": 0.0, "avg_logprob": -0.1379741955828923, "compression_ratio": 1.6822429906542056, "no_speech_prob": 0.02838738076388836}, {"id": 93, "seek": 43496, "start": 446.88, "end": 447.96, "text": " common.", "tokens": [50960, 2689, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1379741955828923, "compression_ratio": 1.6822429906542056, "no_speech_prob": 0.02838738076388836}, {"id": 94, "seek": 43496, "start": 447.96, "end": 453.96, "text": " And so, in a way, what we're forcing the computer to do is basically to cheat, right?", "tokens": [51014, 400, 370, 11, 294, 257, 636, 11, 437, 321, 434, 19030, 264, 3820, 281, 360, 307, 1936, 281, 17470, 11, 558, 30, 51314], "temperature": 0.0, "avg_logprob": -0.1379741955828923, "compression_ratio": 1.6822429906542056, "no_speech_prob": 0.02838738076388836}, {"id": 95, "seek": 43496, "start": 453.96, "end": 462.03999999999996, "text": " It's kind of like you haven't attended classes and then now it's your final exam and you're", "tokens": [51314, 467, 311, 733, 295, 411, 291, 2378, 380, 15990, 5359, 293, 550, 586, 309, 311, 428, 2572, 1139, 293, 291, 434, 51718], "temperature": 0.0, "avg_logprob": -0.1379741955828923, "compression_ratio": 1.6822429906542056, "no_speech_prob": 0.02838738076388836}, {"id": 96, "seek": 46204, "start": 462.04, "end": 467.24, "text": " trying to see what, you know, you're trying to cram for the final exam.", "tokens": [50364, 1382, 281, 536, 437, 11, 291, 458, 11, 291, 434, 1382, 281, 941, 335, 337, 264, 2572, 1139, 13, 50624], "temperature": 0.0, "avg_logprob": -0.1904365615089341, "compression_ratio": 1.95, "no_speech_prob": 0.0330086313188076}, {"id": 97, "seek": 46204, "start": 467.24, "end": 470.36, "text": " And so what the computer is going to do is like, anything that looks like this, it will", "tokens": [50624, 400, 370, 437, 264, 3820, 307, 516, 281, 360, 307, 411, 11, 1340, 300, 1542, 411, 341, 11, 309, 486, 50780], "temperature": 0.0, "avg_logprob": -0.1904365615089341, "compression_ratio": 1.95, "no_speech_prob": 0.0330086313188076}, {"id": 98, "seek": 46204, "start": 470.36, "end": 473.92, "text": " be called the city, anything that looks like this will also be called the city.", "tokens": [50780, 312, 1219, 264, 2307, 11, 1340, 300, 1542, 411, 341, 486, 611, 312, 1219, 264, 2307, 13, 50958], "temperature": 0.0, "avg_logprob": -0.1904365615089341, "compression_ratio": 1.95, "no_speech_prob": 0.0330086313188076}, {"id": 99, "seek": 46204, "start": 473.92, "end": 477.88, "text": " But you're not going to basically get the concept of a city.", "tokens": [50958, 583, 291, 434, 406, 516, 281, 1936, 483, 264, 3410, 295, 257, 2307, 13, 51156], "temperature": 0.0, "avg_logprob": -0.1904365615089341, "compression_ratio": 1.95, "no_speech_prob": 0.0330086313188076}, {"id": 100, "seek": 46204, "start": 477.88, "end": 484.72, "text": " You're just going to basically just remember the, you know, the nearest neighbors, right?", "tokens": [51156, 509, 434, 445, 516, 281, 1936, 445, 1604, 264, 11, 291, 458, 11, 264, 23831, 12512, 11, 558, 30, 51498], "temperature": 0.0, "avg_logprob": -0.1904365615089341, "compression_ratio": 1.95, "no_speech_prob": 0.0330086313188076}, {"id": 101, "seek": 48472, "start": 484.72, "end": 492.08000000000004, "text": " So basically with labels like these, we're, I worry that we're setting ourselves up for", "tokens": [50364, 407, 1936, 365, 16949, 411, 613, 11, 321, 434, 11, 286, 3292, 300, 321, 434, 3287, 4175, 493, 337, 50732], "temperature": 0.0, "avg_logprob": -0.15720558166503906, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.029734881594777107}, {"id": 102, "seek": 48472, "start": 492.08000000000004, "end": 493.08000000000004, "text": " failure, right?", "tokens": [50732, 7763, 11, 558, 30, 50782], "temperature": 0.0, "avg_logprob": -0.15720558166503906, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.029734881594777107}, {"id": 103, "seek": 48472, "start": 493.08000000000004, "end": 502.20000000000005, "text": " We're setting our algorithms up for just memorizing examples and not really even having building", "tokens": [50782, 492, 434, 3287, 527, 14642, 493, 337, 445, 10560, 3319, 5110, 293, 406, 534, 754, 1419, 2390, 51238], "temperature": 0.0, "avg_logprob": -0.15720558166503906, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.029734881594777107}, {"id": 104, "seek": 48472, "start": 502.20000000000005, "end": 504.12, "text": " connections between them, okay?", "tokens": [51238, 9271, 1296, 552, 11, 1392, 30, 51334], "temperature": 0.0, "avg_logprob": -0.15720558166503906, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.029734881594777107}, {"id": 105, "seek": 48472, "start": 504.12, "end": 508.56, "text": " Which is of course very bad if we want our models to generalize, right?", "tokens": [51334, 3013, 307, 295, 1164, 588, 1578, 498, 321, 528, 527, 5245, 281, 2674, 1125, 11, 558, 30, 51556], "temperature": 0.0, "avg_logprob": -0.15720558166503906, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.029734881594777107}, {"id": 106, "seek": 48472, "start": 508.56, "end": 512.72, "text": " If we just wanted to, you know, train an image net and then test an image net, that's fine.", "tokens": [51556, 759, 321, 445, 1415, 281, 11, 291, 458, 11, 3847, 364, 3256, 2533, 293, 550, 1500, 364, 3256, 2533, 11, 300, 311, 2489, 13, 51764], "temperature": 0.0, "avg_logprob": -0.15720558166503906, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.029734881594777107}, {"id": 107, "seek": 51272, "start": 512.72, "end": 517.2, "text": " But if we wanted to train an image net and test on, you know, the real world out there,", "tokens": [50364, 583, 498, 321, 1415, 281, 3847, 364, 3256, 2533, 293, 1500, 322, 11, 291, 458, 11, 264, 957, 1002, 484, 456, 11, 50588], "temperature": 0.0, "avg_logprob": -0.1373512247106531, "compression_ratio": 1.5129310344827587, "no_speech_prob": 0.008838527835905552}, {"id": 108, "seek": 51272, "start": 517.2, "end": 518.2, "text": " then that's not fine.", "tokens": [50588, 550, 300, 311, 406, 2489, 13, 50638], "temperature": 0.0, "avg_logprob": -0.1373512247106531, "compression_ratio": 1.5129310344827587, "no_speech_prob": 0.008838527835905552}, {"id": 109, "seek": 51272, "start": 518.2, "end": 522.84, "text": " We need to somehow induce generalization, okay?", "tokens": [50638, 492, 643, 281, 6063, 41263, 2674, 2144, 11, 1392, 30, 50870], "temperature": 0.0, "avg_logprob": -0.1373512247106531, "compression_ratio": 1.5129310344827587, "no_speech_prob": 0.008838527835905552}, {"id": 110, "seek": 51272, "start": 522.84, "end": 532.44, "text": " And so this is where my promised bit of philosophy comes in, which is that I argue, I've been", "tokens": [50870, 400, 370, 341, 307, 689, 452, 10768, 857, 295, 10675, 1487, 294, 11, 597, 307, 300, 286, 9695, 11, 286, 600, 668, 51350], "temperature": 0.0, "avg_logprob": -0.1373512247106531, "compression_ratio": 1.5129310344827587, "no_speech_prob": 0.008838527835905552}, {"id": 111, "seek": 51272, "start": 532.44, "end": 541.44, "text": " arguing functionally for many years now, that we should step away from the stop down categorization", "tokens": [51350, 19697, 2445, 379, 337, 867, 924, 586, 11, 300, 321, 820, 1823, 1314, 490, 264, 1590, 760, 19250, 2144, 51800], "temperature": 0.0, "avg_logprob": -0.1373512247106531, "compression_ratio": 1.5129310344827587, "no_speech_prob": 0.008838527835905552}, {"id": 112, "seek": 54144, "start": 541.44, "end": 548.0, "text": " paradigm and try to think more of it as a bottom up association.", "tokens": [50364, 24709, 293, 853, 281, 519, 544, 295, 309, 382, 257, 2767, 493, 14598, 13, 50692], "temperature": 0.0, "avg_logprob": -0.16459907983478747, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.054077815264463425}, {"id": 113, "seek": 54144, "start": 548.0, "end": 555.6, "text": " And there is some movement towards that in, especially in the 20th century.", "tokens": [50692, 400, 456, 307, 512, 3963, 3030, 300, 294, 11, 2318, 294, 264, 945, 392, 4901, 13, 51072], "temperature": 0.0, "avg_logprob": -0.16459907983478747, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.054077815264463425}, {"id": 114, "seek": 54144, "start": 555.6, "end": 560.5200000000001, "text": " The philosophers have really kind of pushed away plateaus and Socrates notions of these", "tokens": [51072, 440, 36839, 362, 534, 733, 295, 9152, 1314, 5924, 8463, 293, 407, 50243, 35799, 295, 613, 51318], "temperature": 0.0, "avg_logprob": -0.16459907983478747, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.054077815264463425}, {"id": 115, "seek": 54144, "start": 560.5200000000001, "end": 568.84, "text": " rigid categories and really started to think about categorization in a much more bottom", "tokens": [51318, 22195, 10479, 293, 534, 1409, 281, 519, 466, 19250, 2144, 294, 257, 709, 544, 2767, 51734], "temperature": 0.0, "avg_logprob": -0.16459907983478747, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.054077815264463425}, {"id": 116, "seek": 54144, "start": 568.84, "end": 570.24, "text": " up way.", "tokens": [51734, 493, 636, 13, 51804], "temperature": 0.0, "avg_logprob": -0.16459907983478747, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.054077815264463425}, {"id": 117, "seek": 57024, "start": 570.24, "end": 578.32, "text": " So Plato, of course, he argued that categories were a list of, you know, there were abstract", "tokens": [50364, 407, 43027, 11, 295, 1164, 11, 415, 20219, 300, 10479, 645, 257, 1329, 295, 11, 291, 458, 11, 456, 645, 12649, 50768], "temperature": 0.0, "avg_logprob": -0.2077498140588271, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.0005352120497263968}, {"id": 118, "seek": 57024, "start": 578.32, "end": 581.1800000000001, "text": " definitions with a list of shared properties.", "tokens": [50768, 21988, 365, 257, 1329, 295, 5507, 7221, 13, 50911], "temperature": 0.0, "avg_logprob": -0.2077498140588271, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.0005352120497263968}, {"id": 119, "seek": 57024, "start": 581.1800000000001, "end": 586.4, "text": " And then in the mid 20th century, the philosopher Wittgenstein came out said, no, no, no, no,", "tokens": [50911, 400, 550, 294, 264, 2062, 945, 392, 4901, 11, 264, 29805, 343, 593, 1766, 9089, 1361, 484, 848, 11, 572, 11, 572, 11, 572, 11, 572, 11, 51172], "temperature": 0.0, "avg_logprob": -0.2077498140588271, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.0005352120497263968}, {"id": 120, "seek": 57024, "start": 586.4, "end": 588.5600000000001, "text": " this is that people don't do this.", "tokens": [51172, 341, 307, 300, 561, 500, 380, 360, 341, 13, 51280], "temperature": 0.0, "avg_logprob": -0.2077498140588271, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.0005352120497263968}, {"id": 121, "seek": 57024, "start": 588.5600000000001, "end": 594.28, "text": " In fact, people are much more fluid about categories.", "tokens": [51280, 682, 1186, 11, 561, 366, 709, 544, 9113, 466, 10479, 13, 51566], "temperature": 0.0, "avg_logprob": -0.2077498140588271, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.0005352120497263968}, {"id": 122, "seek": 57024, "start": 594.28, "end": 599.16, "text": " And, you know, for example, you know, if you ask people, you know, our curtains furniture,", "tokens": [51566, 400, 11, 291, 458, 11, 337, 1365, 11, 291, 458, 11, 498, 291, 1029, 561, 11, 291, 458, 11, 527, 36539, 15671, 11, 51810], "temperature": 0.0, "avg_logprob": -0.2077498140588271, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.0005352120497263968}, {"id": 123, "seek": 59916, "start": 599.1999999999999, "end": 603.56, "text": " olives, fruit, different people will give you different answers.", "tokens": [50366, 46746, 11, 6773, 11, 819, 561, 486, 976, 291, 819, 6338, 13, 50584], "temperature": 0.0, "avg_logprob": -0.1956969669886998, "compression_ratio": 1.8067632850241546, "no_speech_prob": 0.03335099294781685}, {"id": 124, "seek": 59916, "start": 603.56, "end": 607.76, "text": " In fact, the same person might give you different answers different times of different times", "tokens": [50584, 682, 1186, 11, 264, 912, 954, 1062, 976, 291, 819, 6338, 819, 1413, 295, 819, 1413, 50794], "temperature": 0.0, "avg_logprob": -0.1956969669886998, "compression_ratio": 1.8067632850241546, "no_speech_prob": 0.03335099294781685}, {"id": 125, "seek": 59916, "start": 607.76, "end": 608.76, "text": " you ask them.", "tokens": [50794, 291, 1029, 552, 13, 50844], "temperature": 0.0, "avg_logprob": -0.1956969669886998, "compression_ratio": 1.8067632850241546, "no_speech_prob": 0.03335099294781685}, {"id": 126, "seek": 59916, "start": 608.76, "end": 620.28, "text": " Wittgenstein's classic puzzle was to ask people to name all what is in common across all games.", "tokens": [50844, 343, 593, 1766, 9089, 311, 7230, 12805, 390, 281, 1029, 561, 281, 1315, 439, 437, 307, 294, 2689, 2108, 439, 2813, 13, 51420], "temperature": 0.0, "avg_logprob": -0.1956969669886998, "compression_ratio": 1.8067632850241546, "no_speech_prob": 0.03335099294781685}, {"id": 127, "seek": 59916, "start": 620.28, "end": 625.48, "text": " What are the common properties shared by all games and not shared by non games?", "tokens": [51420, 708, 366, 264, 2689, 7221, 5507, 538, 439, 2813, 293, 406, 5507, 538, 2107, 2813, 30, 51680], "temperature": 0.0, "avg_logprob": -0.1956969669886998, "compression_ratio": 1.8067632850241546, "no_speech_prob": 0.03335099294781685}, {"id": 128, "seek": 59916, "start": 625.48, "end": 627.6, "text": " And that you cannot do it.", "tokens": [51680, 400, 300, 291, 2644, 360, 309, 13, 51786], "temperature": 0.0, "avg_logprob": -0.1956969669886998, "compression_ratio": 1.8067632850241546, "no_speech_prob": 0.03335099294781685}, {"id": 129, "seek": 62760, "start": 627.6, "end": 632.84, "text": " It's just impossible that there's such a variety of games out there that you cannot think of", "tokens": [50364, 467, 311, 445, 6243, 300, 456, 311, 1270, 257, 5673, 295, 2813, 484, 456, 300, 291, 2644, 519, 295, 50626], "temperature": 0.0, "avg_logprob": -0.18523594084240141, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.008564572781324387}, {"id": 130, "seek": 62760, "start": 632.84, "end": 635.64, "text": " any single thing that defines a game.", "tokens": [50626, 604, 2167, 551, 300, 23122, 257, 1216, 13, 50766], "temperature": 0.0, "avg_logprob": -0.18523594084240141, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.008564572781324387}, {"id": 131, "seek": 62760, "start": 635.64, "end": 638.6800000000001, "text": " It's not a definitional thing.", "tokens": [50766, 467, 311, 406, 257, 1561, 2628, 551, 13, 50918], "temperature": 0.0, "avg_logprob": -0.18523594084240141, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.008564572781324387}, {"id": 132, "seek": 62760, "start": 638.6800000000001, "end": 643.0, "text": " It's much more kind of data driven, much more bottom up kind of, well, it's a game like", "tokens": [50918, 467, 311, 709, 544, 733, 295, 1412, 9555, 11, 709, 544, 2767, 493, 733, 295, 11, 731, 11, 309, 311, 257, 1216, 411, 51134], "temperature": 0.0, "avg_logprob": -0.18523594084240141, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.008564572781324387}, {"id": 133, "seek": 62760, "start": 643.0, "end": 644.0, "text": " like football.", "tokens": [51134, 411, 7346, 13, 51184], "temperature": 0.0, "avg_logprob": -0.18523594084240141, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.008564572781324387}, {"id": 134, "seek": 62760, "start": 644.0, "end": 647.0, "text": " It's a game like chess, right?", "tokens": [51184, 467, 311, 257, 1216, 411, 24122, 11, 558, 30, 51334], "temperature": 0.0, "avg_logprob": -0.18523594084240141, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.008564572781324387}, {"id": 135, "seek": 62760, "start": 647.0, "end": 654.52, "text": " And so in the second half of the 20th century, psychologists in particular, Eleanor Rush", "tokens": [51334, 400, 370, 294, 264, 1150, 1922, 295, 264, 945, 392, 4901, 11, 41562, 294, 1729, 11, 8024, 29330, 28389, 51710], "temperature": 0.0, "avg_logprob": -0.18523594084240141, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.008564572781324387}, {"id": 136, "seek": 65452, "start": 654.52, "end": 663.12, "text": " have tried to kind of update the notion of categorization and tied to think about categories", "tokens": [50364, 362, 3031, 281, 733, 295, 5623, 264, 10710, 295, 19250, 2144, 293, 9601, 281, 519, 466, 10479, 50794], "temperature": 0.0, "avg_logprob": -0.1715208002038904, "compression_ratio": 1.8418367346938775, "no_speech_prob": 0.0018088294891640544}, {"id": 137, "seek": 65452, "start": 663.12, "end": 669.6, "text": " forming from the bottom up and her famous prototype theory of categorization has really", "tokens": [50794, 15745, 490, 264, 2767, 493, 293, 720, 4618, 19475, 5261, 295, 19250, 2144, 575, 534, 51118], "temperature": 0.0, "avg_logprob": -0.1715208002038904, "compression_ratio": 1.8418367346938775, "no_speech_prob": 0.0018088294891640544}, {"id": 138, "seek": 65452, "start": 669.6, "end": 676.56, "text": " started this trend where the idea was that you basically cluster, you do bottom up clustering", "tokens": [51118, 1409, 341, 6028, 689, 264, 1558, 390, 300, 291, 1936, 13630, 11, 291, 360, 2767, 493, 596, 48673, 51466], "temperature": 0.0, "avg_logprob": -0.1715208002038904, "compression_ratio": 1.8418367346938775, "no_speech_prob": 0.0018088294891640544}, {"id": 139, "seek": 65452, "start": 676.56, "end": 682.48, "text": " of similar instances into these prototypes and the prototypes then get clustered again", "tokens": [51466, 295, 2531, 14519, 666, 613, 42197, 293, 264, 42197, 550, 483, 596, 38624, 797, 51762], "temperature": 0.0, "avg_logprob": -0.1715208002038904, "compression_ratio": 1.8418367346938775, "no_speech_prob": 0.0018088294891640544}, {"id": 140, "seek": 68248, "start": 682.48, "end": 688.24, "text": " and then you have this kind of a bottom up hierarchy where the categories emerge directly", "tokens": [50364, 293, 550, 291, 362, 341, 733, 295, 257, 2767, 493, 22333, 689, 264, 10479, 21511, 3838, 50652], "temperature": 0.0, "avg_logprob": -0.1663945733684383, "compression_ratio": 1.5980392156862746, "no_speech_prob": 0.002667075954377651}, {"id": 141, "seek": 68248, "start": 688.24, "end": 692.8000000000001, "text": " from the data rather than being kind of this top down, okay?", "tokens": [50652, 490, 264, 1412, 2831, 813, 885, 733, 295, 341, 1192, 760, 11, 1392, 30, 50880], "temperature": 0.0, "avg_logprob": -0.1663945733684383, "compression_ratio": 1.5980392156862746, "no_speech_prob": 0.002667075954377651}, {"id": 142, "seek": 68248, "start": 692.8000000000001, "end": 699.88, "text": " And later folks have, psychologists have gone even further and argued for what they call", "tokens": [50880, 400, 1780, 4024, 362, 11, 41562, 362, 2780, 754, 3052, 293, 20219, 337, 437, 436, 818, 51234], "temperature": 0.0, "avg_logprob": -0.1663945733684383, "compression_ratio": 1.5980392156862746, "no_speech_prob": 0.002667075954377651}, {"id": 143, "seek": 68248, "start": 699.88, "end": 708.36, "text": " the exemplar based theory of categorization where you basically, you don't really have", "tokens": [51234, 264, 24112, 289, 2361, 5261, 295, 19250, 2144, 689, 291, 1936, 11, 291, 500, 380, 534, 362, 51658], "temperature": 0.0, "avg_logprob": -0.1663945733684383, "compression_ratio": 1.5980392156862746, "no_speech_prob": 0.002667075954377651}, {"id": 144, "seek": 70836, "start": 708.36, "end": 717.64, "text": " categories when you kind, you basically just store instances, store exemplars of everything", "tokens": [50364, 10479, 562, 291, 733, 11, 291, 1936, 445, 3531, 14519, 11, 3531, 24112, 685, 295, 1203, 50828], "temperature": 0.0, "avg_logprob": -0.21001218004924496, "compression_ratio": 1.799043062200957, "no_speech_prob": 0.08990636467933655}, {"id": 145, "seek": 70836, "start": 717.64, "end": 723.08, "text": " that you see and then you basically learn associations between those examples and the", "tokens": [50828, 300, 291, 536, 293, 550, 291, 1936, 1466, 26597, 1296, 729, 5110, 293, 264, 51100], "temperature": 0.0, "avg_logprob": -0.21001218004924496, "compression_ratio": 1.799043062200957, "no_speech_prob": 0.08990636467933655}, {"id": 146, "seek": 70836, "start": 723.08, "end": 727.12, "text": " things that are closer together, essentially can you can think of it as like this kind", "tokens": [51100, 721, 300, 366, 4966, 1214, 11, 4476, 393, 291, 393, 519, 295, 309, 382, 411, 341, 733, 51302], "temperature": 0.0, "avg_logprob": -0.21001218004924496, "compression_ratio": 1.799043062200957, "no_speech_prob": 0.08990636467933655}, {"id": 147, "seek": 70836, "start": 727.12, "end": 733.36, "text": " of a soft clustering of your exemplars into chunks and to groups and those groups then", "tokens": [51302, 295, 257, 2787, 596, 48673, 295, 428, 24112, 685, 666, 24004, 293, 281, 3935, 293, 729, 3935, 550, 51614], "temperature": 0.0, "avg_logprob": -0.21001218004924496, "compression_ratio": 1.799043062200957, "no_speech_prob": 0.08990636467933655}, {"id": 148, "seek": 70836, "start": 733.36, "end": 736.4, "text": " emerge to be categories.", "tokens": [51614, 21511, 281, 312, 10479, 13, 51766], "temperature": 0.0, "avg_logprob": -0.21001218004924496, "compression_ratio": 1.799043062200957, "no_speech_prob": 0.08990636467933655}, {"id": 149, "seek": 73640, "start": 737.28, "end": 744.12, "text": " My favorite slogan is provided by a neuroscientist Moshe Barker who says, ask not what is it,", "tokens": [50408, 1222, 2954, 33052, 307, 5649, 538, 257, 28813, 5412, 468, 19430, 675, 36275, 260, 567, 1619, 11, 1029, 406, 437, 307, 309, 11, 50750], "temperature": 0.0, "avg_logprob": -0.22193111950838113, "compression_ratio": 1.5968586387434556, "no_speech_prob": 0.03893275558948517}, {"id": 150, "seek": 73640, "start": 744.12, "end": 750.0, "text": " ask what is it like to this kind of a, this idea that association bottom up association", "tokens": [50750, 1029, 437, 307, 309, 411, 281, 341, 733, 295, 257, 11, 341, 1558, 300, 14598, 2767, 493, 14598, 51044], "temperature": 0.0, "avg_logprob": -0.22193111950838113, "compression_ratio": 1.5968586387434556, "no_speech_prob": 0.03893275558948517}, {"id": 151, "seek": 73640, "start": 750.0, "end": 755.0799999999999, "text": " trumps this top down labeling, okay?", "tokens": [51044, 504, 16951, 341, 1192, 760, 40244, 11, 1392, 30, 51298], "temperature": 0.0, "avg_logprob": -0.22193111950838113, "compression_ratio": 1.5968586387434556, "no_speech_prob": 0.03893275558948517}, {"id": 152, "seek": 73640, "start": 755.0799999999999, "end": 763.4, "text": " And so this work has been very inspiring to me and my group over the years and we have", "tokens": [51298, 400, 370, 341, 589, 575, 668, 588, 15883, 281, 385, 293, 452, 1594, 670, 264, 924, 293, 321, 362, 51714], "temperature": 0.0, "avg_logprob": -0.22193111950838113, "compression_ratio": 1.5968586387434556, "no_speech_prob": 0.03893275558948517}, {"id": 153, "seek": 76340, "start": 763.4, "end": 770.24, "text": " been kind of chugging away at in this direction for a number of years and maybe one of the", "tokens": [50364, 668, 733, 295, 417, 697, 3249, 1314, 412, 294, 341, 3513, 337, 257, 1230, 295, 924, 293, 1310, 472, 295, 264, 50706], "temperature": 0.0, "avg_logprob": -0.19401037970254587, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.005724629387259483}, {"id": 154, "seek": 76340, "start": 770.24, "end": 775.72, "text": " earlier works that we did was with my former student Tamash Milosevich where we basically", "tokens": [50706, 3071, 1985, 300, 321, 630, 390, 365, 452, 5819, 3107, 8540, 1299, 7036, 541, 85, 480, 689, 321, 1936, 50980], "temperature": 0.0, "avg_logprob": -0.19401037970254587, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.005724629387259483}, {"id": 155, "seek": 76340, "start": 775.72, "end": 783.72, "text": " try to kind of instantiate this exemplar based way of thinking about categorization", "tokens": [50980, 853, 281, 733, 295, 9836, 13024, 341, 24112, 289, 2361, 636, 295, 1953, 466, 19250, 2144, 51380], "temperature": 0.0, "avg_logprob": -0.19401037970254587, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.005724629387259483}, {"id": 156, "seek": 76340, "start": 783.72, "end": 792.68, "text": " and here the example, the idea is that we basically try to find per-exampler distances", "tokens": [51380, 293, 510, 264, 1365, 11, 264, 1558, 307, 300, 321, 1936, 853, 281, 915, 680, 12, 3121, 335, 22732, 22182, 51828], "temperature": 0.0, "avg_logprob": -0.19401037970254587, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.005724629387259483}, {"id": 157, "seek": 79268, "start": 792.68, "end": 794.4399999999999, "text": " given a set of data.", "tokens": [50364, 2212, 257, 992, 295, 1412, 13, 50452], "temperature": 0.0, "avg_logprob": -0.1629686083112444, "compression_ratio": 1.5406976744186047, "no_speech_prob": 0.004899628460407257}, {"id": 158, "seek": 79268, "start": 794.4399999999999, "end": 802.4799999999999, "text": " So you have a set of labeled data, you know, cars, people, pedestrians, trees, etc.", "tokens": [50452, 407, 291, 362, 257, 992, 295, 21335, 1412, 11, 291, 458, 11, 5163, 11, 561, 11, 48339, 11, 5852, 11, 5183, 13, 50854], "temperature": 0.0, "avg_logprob": -0.1629686083112444, "compression_ratio": 1.5406976744186047, "no_speech_prob": 0.004899628460407257}, {"id": 159, "seek": 79268, "start": 802.4799999999999, "end": 807.4399999999999, "text": " And here instead of trying to separate all cars from all pedestrians, for example, we", "tokens": [50854, 400, 510, 2602, 295, 1382, 281, 4994, 439, 5163, 490, 439, 48339, 11, 337, 1365, 11, 321, 51102], "temperature": 0.0, "avg_logprob": -0.1629686083112444, "compression_ratio": 1.5406976744186047, "no_speech_prob": 0.004899628460407257}, {"id": 160, "seek": 79268, "start": 807.4399999999999, "end": 814.56, "text": " wanted to basically learn a way to group every single instance of say car.", "tokens": [51102, 1415, 281, 1936, 1466, 257, 636, 281, 1594, 633, 2167, 5197, 295, 584, 1032, 13, 51458], "temperature": 0.0, "avg_logprob": -0.1629686083112444, "compression_ratio": 1.5406976744186047, "no_speech_prob": 0.004899628460407257}, {"id": 161, "seek": 81456, "start": 814.56, "end": 823.1999999999999, "text": " So for this particular focal example of a car, we wanted to find what other things are", "tokens": [50364, 407, 337, 341, 1729, 26592, 1365, 295, 257, 1032, 11, 321, 1415, 281, 915, 437, 661, 721, 366, 50796], "temperature": 0.0, "avg_logprob": -0.13916868822915213, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.1326431781053543}, {"id": 162, "seek": 81456, "start": 823.1999999999999, "end": 824.56, "text": " close to it, right?", "tokens": [50796, 1998, 281, 309, 11, 558, 30, 50864], "temperature": 0.0, "avg_logprob": -0.13916868822915213, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.1326431781053543}, {"id": 163, "seek": 81456, "start": 824.56, "end": 830.56, "text": " And so those other things should be also labeled car, but there shouldn't be all cars because,", "tokens": [50864, 400, 370, 729, 661, 721, 820, 312, 611, 21335, 1032, 11, 457, 456, 4659, 380, 312, 439, 5163, 570, 11, 51164], "temperature": 0.0, "avg_logprob": -0.13916868822915213, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.1326431781053543}, {"id": 164, "seek": 81456, "start": 830.56, "end": 833.4799999999999, "text": " you know, this car, for example, looks nothing like this car.", "tokens": [51164, 291, 458, 11, 341, 1032, 11, 337, 1365, 11, 1542, 1825, 411, 341, 1032, 13, 51310], "temperature": 0.0, "avg_logprob": -0.13916868822915213, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.1326431781053543}, {"id": 165, "seek": 81456, "start": 833.4799999999999, "end": 837.2399999999999, "text": " So should they really be in the same cluster in the same category?", "tokens": [51310, 407, 820, 436, 534, 312, 294, 264, 912, 13630, 294, 264, 912, 7719, 30, 51498], "temperature": 0.0, "avg_logprob": -0.13916868822915213, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.1326431781053543}, {"id": 166, "seek": 81456, "start": 837.2399999999999, "end": 838.2399999999999, "text": " Maybe not.", "tokens": [51498, 2704, 406, 13, 51548], "temperature": 0.0, "avg_logprob": -0.13916868822915213, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.1326431781053543}, {"id": 167, "seek": 81456, "start": 838.2399999999999, "end": 844.3199999999999, "text": " And so the idea that Tamash came up with was to basically kind of treat this as a kind", "tokens": [51548, 400, 370, 264, 1558, 300, 8540, 1299, 1361, 493, 365, 390, 281, 1936, 733, 295, 2387, 341, 382, 257, 733, 51852], "temperature": 0.0, "avg_logprob": -0.13916868822915213, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.1326431781053543}, {"id": 168, "seek": 84432, "start": 844.32, "end": 849.9200000000001, "text": " of a classification problem where you basically learn a decision boundary between things that", "tokens": [50364, 295, 257, 21538, 1154, 689, 291, 1936, 1466, 257, 3537, 12866, 1296, 721, 300, 50644], "temperature": 0.0, "avg_logprob": -0.15486258110113904, "compression_ratio": 1.9426229508196722, "no_speech_prob": 0.005996460560709238}, {"id": 169, "seek": 84432, "start": 849.9200000000001, "end": 856.6800000000001, "text": " are close to your focal example and things that are far, but here we actually have instead", "tokens": [50644, 366, 1998, 281, 428, 26592, 1365, 293, 721, 300, 366, 1400, 11, 457, 510, 321, 767, 362, 2602, 50982], "temperature": 0.0, "avg_logprob": -0.15486258110113904, "compression_ratio": 1.9426229508196722, "no_speech_prob": 0.005996460560709238}, {"id": 170, "seek": 84432, "start": 856.6800000000001, "end": 862.5200000000001, "text": " of two classes, the ones that are inside of a category and one's out, we have three classes.", "tokens": [50982, 295, 732, 5359, 11, 264, 2306, 300, 366, 1854, 295, 257, 7719, 293, 472, 311, 484, 11, 321, 362, 1045, 5359, 13, 51274], "temperature": 0.0, "avg_logprob": -0.15486258110113904, "compression_ratio": 1.9426229508196722, "no_speech_prob": 0.005996460560709238}, {"id": 171, "seek": 84432, "start": 862.5200000000001, "end": 865.84, "text": " There are the things that are close and these are kind of these kind of cars.", "tokens": [51274, 821, 366, 264, 721, 300, 366, 1998, 293, 613, 366, 733, 295, 613, 733, 295, 5163, 13, 51440], "temperature": 0.0, "avg_logprob": -0.15486258110113904, "compression_ratio": 1.9426229508196722, "no_speech_prob": 0.005996460560709238}, {"id": 172, "seek": 84432, "start": 865.84, "end": 870.0, "text": " There are things that are not cars and they're on the other side.", "tokens": [51440, 821, 366, 721, 300, 366, 406, 5163, 293, 436, 434, 322, 264, 661, 1252, 13, 51648], "temperature": 0.0, "avg_logprob": -0.15486258110113904, "compression_ratio": 1.9426229508196722, "no_speech_prob": 0.005996460560709238}, {"id": 173, "seek": 84432, "start": 870.0, "end": 872.96, "text": " And then there is a third class which is don't care.", "tokens": [51648, 400, 550, 456, 307, 257, 2636, 1508, 597, 307, 500, 380, 1127, 13, 51796], "temperature": 0.0, "avg_logprob": -0.15486258110113904, "compression_ratio": 1.9426229508196722, "no_speech_prob": 0.005996460560709238}, {"id": 174, "seek": 87296, "start": 872.96, "end": 879.84, "text": " And these are basically other cars that might not actually be that close to the focal car.", "tokens": [50364, 400, 613, 366, 1936, 661, 5163, 300, 1062, 406, 767, 312, 300, 1998, 281, 264, 26592, 1032, 13, 50708], "temperature": 0.0, "avg_logprob": -0.14649838209152222, "compression_ratio": 1.680232558139535, "no_speech_prob": 0.002470392966642976}, {"id": 175, "seek": 87296, "start": 879.84, "end": 888.6800000000001, "text": " And then you basically optimize this, optimize this decision boundary given some set of constraints.", "tokens": [50708, 400, 550, 291, 1936, 19719, 341, 11, 19719, 341, 3537, 12866, 2212, 512, 992, 295, 18491, 13, 51150], "temperature": 0.0, "avg_logprob": -0.14649838209152222, "compression_ratio": 1.680232558139535, "no_speech_prob": 0.002470392966642976}, {"id": 176, "seek": 87296, "start": 888.6800000000001, "end": 895.4000000000001, "text": " And as a result, what you get is you get something where you learn these distances that are, that", "tokens": [51150, 400, 382, 257, 1874, 11, 437, 291, 483, 307, 291, 483, 746, 689, 291, 1466, 613, 22182, 300, 366, 11, 300, 51486], "temperature": 0.0, "avg_logprob": -0.14649838209152222, "compression_ratio": 1.680232558139535, "no_speech_prob": 0.002470392966642976}, {"id": 177, "seek": 89540, "start": 895.4, "end": 906.04, "text": " produce much more visually meaningful relationships rather than if you were just doing a standard", "tokens": [50364, 5258, 709, 544, 19622, 10995, 6159, 2831, 813, 498, 291, 645, 445, 884, 257, 3832, 50896], "temperature": 0.0, "avg_logprob": -0.2210903697543674, "compression_ratio": 1.5894736842105264, "no_speech_prob": 0.09118705242872238}, {"id": 178, "seek": 89540, "start": 906.04, "end": 910.4399999999999, "text": " set of distances without this, okay?", "tokens": [50896, 992, 295, 22182, 1553, 341, 11, 1392, 30, 51116], "temperature": 0.0, "avg_logprob": -0.2210903697543674, "compression_ratio": 1.5894736842105264, "no_speech_prob": 0.09118705242872238}, {"id": 179, "seek": 89540, "start": 910.4399999999999, "end": 915.72, "text": " And so this was kind of a, we were very excited about this, but still we're here, we're still", "tokens": [51116, 400, 370, 341, 390, 733, 295, 257, 11, 321, 645, 588, 2919, 466, 341, 11, 457, 920, 321, 434, 510, 11, 321, 434, 920, 51380], "temperature": 0.0, "avg_logprob": -0.2210903697543674, "compression_ratio": 1.5894736842105264, "no_speech_prob": 0.09118705242872238}, {"id": 180, "seek": 89540, "start": 915.72, "end": 920.92, "text": " using the label car, the labels are still being used in this computation.", "tokens": [51380, 1228, 264, 7645, 1032, 11, 264, 16949, 366, 920, 885, 1143, 294, 341, 24903, 13, 51640], "temperature": 0.0, "avg_logprob": -0.2210903697543674, "compression_ratio": 1.5894736842105264, "no_speech_prob": 0.09118705242872238}, {"id": 181, "seek": 92092, "start": 920.92, "end": 924.4, "text": " And we really wanted to go away from labels entirely.", "tokens": [50364, 400, 321, 534, 1415, 281, 352, 1314, 490, 16949, 7696, 13, 50538], "temperature": 0.0, "avg_logprob": -0.18016715610728545, "compression_ratio": 1.5108695652173914, "no_speech_prob": 0.01587633229792118}, {"id": 182, "seek": 92092, "start": 924.4, "end": 929.36, "text": " And this is where Tamash's next paper came in.", "tokens": [50538, 400, 341, 307, 689, 8540, 1299, 311, 958, 3035, 1361, 294, 13, 50786], "temperature": 0.0, "avg_logprob": -0.18016715610728545, "compression_ratio": 1.5108695652173914, "no_speech_prob": 0.01587633229792118}, {"id": 183, "seek": 92092, "start": 929.36, "end": 936.56, "text": " And this work, we call it exemplar SVM, was basically kind of pushing this farther and", "tokens": [50786, 400, 341, 589, 11, 321, 818, 309, 24112, 289, 31910, 44, 11, 390, 1936, 733, 295, 7380, 341, 20344, 293, 51146], "temperature": 0.0, "avg_logprob": -0.18016715610728545, "compression_ratio": 1.5108695652173914, "no_speech_prob": 0.01587633229792118}, {"id": 184, "seek": 92092, "start": 936.56, "end": 945.9599999999999, "text": " really thinking about it in terms of classifiers and basically switching from the standard", "tokens": [51146, 534, 1953, 466, 309, 294, 2115, 295, 1508, 23463, 293, 1936, 16493, 490, 264, 3832, 51616], "temperature": 0.0, "avg_logprob": -0.18016715610728545, "compression_ratio": 1.5108695652173914, "no_speech_prob": 0.01587633229792118}, {"id": 185, "seek": 94596, "start": 945.96, "end": 952.44, "text": " classifier where you have class A and class B instead to take every single instance, every", "tokens": [50364, 1508, 9902, 689, 291, 362, 1508, 316, 293, 1508, 363, 2602, 281, 747, 633, 2167, 5197, 11, 633, 50688], "temperature": 0.0, "avg_logprob": -0.15153423575467842, "compression_ratio": 1.75, "no_speech_prob": 0.11586309224367142}, {"id": 186, "seek": 94596, "start": 952.44, "end": 961.12, "text": " single data point and train a separate classifier for that one instance against everyone else,", "tokens": [50688, 2167, 1412, 935, 293, 3847, 257, 4994, 1508, 9902, 337, 300, 472, 5197, 1970, 1518, 1646, 11, 51122], "temperature": 0.0, "avg_logprob": -0.15153423575467842, "compression_ratio": 1.75, "no_speech_prob": 0.11586309224367142}, {"id": 187, "seek": 94596, "start": 961.12, "end": 964.0, "text": " whether it's your own class or a different class.", "tokens": [51122, 1968, 309, 311, 428, 1065, 1508, 420, 257, 819, 1508, 13, 51266], "temperature": 0.0, "avg_logprob": -0.15153423575467842, "compression_ratio": 1.75, "no_speech_prob": 0.11586309224367142}, {"id": 188, "seek": 94596, "start": 964.0, "end": 966.76, "text": " So it's one against all classifier.", "tokens": [51266, 407, 309, 311, 472, 1970, 439, 1508, 9902, 13, 51404], "temperature": 0.0, "avg_logprob": -0.15153423575467842, "compression_ratio": 1.75, "no_speech_prob": 0.11586309224367142}, {"id": 189, "seek": 94596, "start": 966.76, "end": 970.0400000000001, "text": " So this is kind of an interesting way to think about it because it's really basically you're", "tokens": [51404, 407, 341, 307, 733, 295, 364, 1880, 636, 281, 519, 466, 309, 570, 309, 311, 534, 1936, 291, 434, 51568], "temperature": 0.0, "avg_logprob": -0.15153423575467842, "compression_ratio": 1.75, "no_speech_prob": 0.11586309224367142}, {"id": 190, "seek": 97004, "start": 970.04, "end": 976.56, "text": " defining yourself, not by who is in your category, who is in your class, but you're", "tokens": [50364, 17827, 1803, 11, 406, 538, 567, 307, 294, 428, 7719, 11, 567, 307, 294, 428, 1508, 11, 457, 291, 434, 50690], "temperature": 0.0, "avg_logprob": -0.18693175580766466, "compression_ratio": 1.6358381502890174, "no_speech_prob": 0.011682135984301567}, {"id": 191, "seek": 97004, "start": 976.56, "end": 980.56, "text": " defining yourself by what you are not, right?", "tokens": [50690, 17827, 1803, 538, 437, 291, 366, 406, 11, 558, 30, 50890], "temperature": 0.0, "avg_logprob": -0.18693175580766466, "compression_ratio": 1.6358381502890174, "no_speech_prob": 0.011682135984301567}, {"id": 192, "seek": 97004, "start": 980.56, "end": 987.36, "text": " So what makes you different from everyone else in your data, okay?", "tokens": [50890, 407, 437, 1669, 291, 819, 490, 1518, 1646, 294, 428, 1412, 11, 1392, 30, 51230], "temperature": 0.0, "avg_logprob": -0.18693175580766466, "compression_ratio": 1.6358381502890174, "no_speech_prob": 0.011682135984301567}, {"id": 193, "seek": 97004, "start": 987.36, "end": 996.9599999999999, "text": " And then the cool result was that we were able to do one classifier for every instance", "tokens": [51230, 400, 550, 264, 1627, 1874, 390, 300, 321, 645, 1075, 281, 360, 472, 1508, 9902, 337, 633, 5197, 51710], "temperature": 0.0, "avg_logprob": -0.18693175580766466, "compression_ratio": 1.6358381502890174, "no_speech_prob": 0.011682135984301567}, {"id": 194, "seek": 99696, "start": 996.96, "end": 998.84, "text": " and then assemble them together.", "tokens": [50364, 293, 550, 22364, 552, 1214, 13, 50458], "temperature": 0.0, "avg_logprob": -0.18145479474748885, "compression_ratio": 1.5855855855855856, "no_speech_prob": 0.019696881994605064}, {"id": 195, "seek": 99696, "start": 998.84, "end": 1008.1600000000001, "text": " And the result was that this assemble actually worked no worse in many cases than your standard", "tokens": [50458, 400, 264, 1874, 390, 300, 341, 22364, 767, 2732, 572, 5324, 294, 867, 3331, 813, 428, 3832, 50924], "temperature": 0.0, "avg_logprob": -0.18145479474748885, "compression_ratio": 1.5855855855855856, "no_speech_prob": 0.019696881994605064}, {"id": 196, "seek": 99696, "start": 1008.1600000000001, "end": 1012.4000000000001, "text": " two-class classifier like an SVM, okay?", "tokens": [50924, 732, 12, 11665, 1508, 9902, 411, 364, 31910, 44, 11, 1392, 30, 51136], "temperature": 0.0, "avg_logprob": -0.18145479474748885, "compression_ratio": 1.5855855855855856, "no_speech_prob": 0.019696881994605064}, {"id": 197, "seek": 99696, "start": 1012.4000000000001, "end": 1018.5600000000001, "text": " And this was a little bit of a, it was kind of like a bit of a trolling paper, which basically", "tokens": [51136, 400, 341, 390, 257, 707, 857, 295, 257, 11, 309, 390, 733, 295, 411, 257, 857, 295, 257, 4495, 2669, 3035, 11, 597, 1936, 51444], "temperature": 0.0, "avg_logprob": -0.18145479474748885, "compression_ratio": 1.5855855855855856, "no_speech_prob": 0.019696881994605064}, {"id": 198, "seek": 99696, "start": 1018.5600000000001, "end": 1024.4, "text": " kind of tried to push the community to say, look, maybe you're not getting as much juice", "tokens": [51444, 733, 295, 3031, 281, 2944, 264, 1768, 281, 584, 11, 574, 11, 1310, 291, 434, 406, 1242, 382, 709, 8544, 51736], "temperature": 0.0, "avg_logprob": -0.18145479474748885, "compression_ratio": 1.5855855855855856, "no_speech_prob": 0.019696881994605064}, {"id": 199, "seek": 102440, "start": 1024.4, "end": 1030.5600000000002, "text": " as you think you are from basically trying to group all those things into one class because", "tokens": [50364, 382, 291, 519, 291, 366, 490, 1936, 1382, 281, 1594, 439, 729, 721, 666, 472, 1508, 570, 50672], "temperature": 0.0, "avg_logprob": -0.1551317756558642, "compression_ratio": 1.6494845360824741, "no_speech_prob": 0.0019545271061360836}, {"id": 200, "seek": 102440, "start": 1030.5600000000002, "end": 1037.96, "text": " it seems like if you don't do it, you get basically as much of performance as not, okay?", "tokens": [50672, 309, 2544, 411, 498, 291, 500, 380, 360, 309, 11, 291, 483, 1936, 382, 709, 295, 3389, 382, 406, 11, 1392, 30, 51042], "temperature": 0.0, "avg_logprob": -0.1551317756558642, "compression_ratio": 1.6494845360824741, "no_speech_prob": 0.0019545271061360836}, {"id": 201, "seek": 102440, "start": 1037.96, "end": 1042.92, "text": " And so we also use the same idea for retrieval.", "tokens": [51042, 400, 370, 321, 611, 764, 264, 912, 1558, 337, 19817, 3337, 13, 51290], "temperature": 0.0, "avg_logprob": -0.1551317756558642, "compression_ratio": 1.6494845360824741, "no_speech_prob": 0.0019545271061360836}, {"id": 202, "seek": 102440, "start": 1042.92, "end": 1051.3600000000001, "text": " So basically the idea is you take, at runtime, you take your retrieval query image and then", "tokens": [51290, 407, 1936, 264, 1558, 307, 291, 747, 11, 412, 34474, 11, 291, 747, 428, 19817, 3337, 14581, 3256, 293, 550, 51712], "temperature": 0.0, "avg_logprob": -0.1551317756558642, "compression_ratio": 1.6494845360824741, "no_speech_prob": 0.0019545271061360836}, {"id": 203, "seek": 105136, "start": 1051.36, "end": 1058.28, "text": " you have a big data set and you're basically training at runtime an SVM classifier to separate", "tokens": [50364, 291, 362, 257, 955, 1412, 992, 293, 291, 434, 1936, 3097, 412, 34474, 364, 31910, 44, 1508, 9902, 281, 4994, 50710], "temperature": 0.0, "avg_logprob": -0.11313011072858979, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.008973139338195324}, {"id": 204, "seek": 105136, "start": 1058.28, "end": 1062.12, "text": " your query from everything else, okay?", "tokens": [50710, 428, 14581, 490, 1203, 1646, 11, 1392, 30, 50902], "temperature": 0.0, "avg_logprob": -0.11313011072858979, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.008973139338195324}, {"id": 205, "seek": 105136, "start": 1062.12, "end": 1071.36, "text": " And then you order all of your data based on that, on the coefficients of that decision", "tokens": [50902, 400, 550, 291, 1668, 439, 295, 428, 1412, 2361, 322, 300, 11, 322, 264, 31994, 295, 300, 3537, 51364], "temperature": 0.0, "avg_logprob": -0.11313011072858979, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.008973139338195324}, {"id": 206, "seek": 105136, "start": 1071.36, "end": 1072.36, "text": " boundary, okay?", "tokens": [51364, 12866, 11, 1392, 30, 51414], "temperature": 0.0, "avg_logprob": -0.11313011072858979, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.008973139338195324}, {"id": 207, "seek": 105136, "start": 1072.36, "end": 1079.4799999999998, "text": " You basically find who are the closest things, who are your support vectors inside of your", "tokens": [51414, 509, 1936, 915, 567, 366, 264, 13699, 721, 11, 567, 366, 428, 1406, 18875, 1854, 295, 428, 51770], "temperature": 0.0, "avg_logprob": -0.11313011072858979, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.008973139338195324}, {"id": 208, "seek": 107948, "start": 1079.48, "end": 1085.3600000000001, "text": " data set and those tend to be the retrieval examples, the kind of the closest ones on", "tokens": [50364, 1412, 992, 293, 729, 3928, 281, 312, 264, 19817, 3337, 5110, 11, 264, 733, 295, 264, 13699, 2306, 322, 50658], "temperature": 0.0, "avg_logprob": -0.14835950925752714, "compression_ratio": 1.7192118226600985, "no_speech_prob": 0.0049796150997281075}, {"id": 209, "seek": 107948, "start": 1085.3600000000001, "end": 1091.92, "text": " the other side will be the retrieval examples and that also worked surprisingly well.", "tokens": [50658, 264, 661, 1252, 486, 312, 264, 19817, 3337, 5110, 293, 300, 611, 2732, 17600, 731, 13, 50986], "temperature": 0.0, "avg_logprob": -0.14835950925752714, "compression_ratio": 1.7192118226600985, "no_speech_prob": 0.0049796150997281075}, {"id": 210, "seek": 107948, "start": 1091.92, "end": 1096.56, "text": " And so we were very excited about this and we were very hopeful and then of course deep", "tokens": [50986, 400, 370, 321, 645, 588, 2919, 466, 341, 293, 321, 645, 588, 20531, 293, 550, 295, 1164, 2452, 51218], "temperature": 0.0, "avg_logprob": -0.14835950925752714, "compression_ratio": 1.7192118226600985, "no_speech_prob": 0.0049796150997281075}, {"id": 211, "seek": 107948, "start": 1096.56, "end": 1105.28, "text": " learning revolution hit and all of this became irrelevant because much better classifiers", "tokens": [51218, 2539, 8894, 2045, 293, 439, 295, 341, 3062, 28682, 570, 709, 1101, 1508, 23463, 51654], "temperature": 0.0, "avg_logprob": -0.14835950925752714, "compression_ratio": 1.7192118226600985, "no_speech_prob": 0.0049796150997281075}, {"id": 212, "seek": 110528, "start": 1105.28, "end": 1107.6399999999999, "text": " came on the scene.", "tokens": [50364, 1361, 322, 264, 4145, 13, 50482], "temperature": 0.0, "avg_logprob": -0.2717994811042907, "compression_ratio": 1.3563218390804597, "no_speech_prob": 0.08245233446359634}, {"id": 213, "seek": 110528, "start": 1107.6399999999999, "end": 1117.8799999999999, "text": " We tried to update it for the deep learning age and we didn't really succeed but Alexey", "tokens": [50482, 492, 3031, 281, 5623, 309, 337, 264, 2452, 2539, 3205, 293, 321, 994, 380, 534, 7754, 457, 5202, 2030, 50994], "temperature": 0.0, "avg_logprob": -0.2717994811042907, "compression_ratio": 1.3563218390804597, "no_speech_prob": 0.08245233446359634}, {"id": 214, "seek": 110528, "start": 1117.8799999999999, "end": 1121.28, "text": " DeSavitsky and colleagues did, okay?", "tokens": [50994, 1346, 50, 706, 1208, 4133, 293, 7734, 630, 11, 1392, 30, 51164], "temperature": 0.0, "avg_logprob": -0.2717994811042907, "compression_ratio": 1.3563218390804597, "no_speech_prob": 0.08245233446359634}, {"id": 215, "seek": 110528, "start": 1121.28, "end": 1129.04, "text": " So one of the kind of very early influential papers was called exemplar CNN, which basically", "tokens": [51164, 407, 472, 295, 264, 733, 295, 588, 2440, 22215, 10577, 390, 1219, 24112, 289, 24859, 11, 597, 1936, 51552], "temperature": 0.0, "avg_logprob": -0.2717994811042907, "compression_ratio": 1.3563218390804597, "no_speech_prob": 0.08245233446359634}, {"id": 216, "seek": 112904, "start": 1129.04, "end": 1139.84, "text": " adopted the same idea of one against all classification on using neural networks, okay?", "tokens": [50364, 12175, 264, 912, 1558, 295, 472, 1970, 439, 21538, 322, 1228, 18161, 9590, 11, 1392, 30, 50904], "temperature": 0.0, "avg_logprob": -0.19563721919405289, "compression_ratio": 1.4871794871794872, "no_speech_prob": 0.011853517964482307}, {"id": 217, "seek": 112904, "start": 1139.84, "end": 1147.36, "text": " And the main difference that we didn't really think of was that whereas we used a single", "tokens": [50904, 400, 264, 2135, 2649, 300, 321, 994, 380, 534, 519, 295, 390, 300, 9735, 321, 1143, 257, 2167, 51280], "temperature": 0.0, "avg_logprob": -0.19563721919405289, "compression_ratio": 1.4871794871794872, "no_speech_prob": 0.011853517964482307}, {"id": 218, "seek": 112904, "start": 1147.36, "end": 1156.1599999999999, "text": " exemplar, one image against everything else, DeSavitsky and colleagues they used what's", "tokens": [51280, 24112, 289, 11, 472, 3256, 1970, 1203, 1646, 11, 1346, 50, 706, 1208, 4133, 293, 7734, 436, 1143, 437, 311, 51720], "temperature": 0.0, "avg_logprob": -0.19563721919405289, "compression_ratio": 1.4871794871794872, "no_speech_prob": 0.011853517964482307}, {"id": 219, "seek": 112904, "start": 1156.1599999999999, "end": 1158.36, "text": " called data augmentation.", "tokens": [51720, 1219, 1412, 14501, 19631, 13, 51830], "temperature": 0.0, "avg_logprob": -0.19563721919405289, "compression_ratio": 1.4871794871794872, "no_speech_prob": 0.011853517964482307}, {"id": 220, "seek": 115836, "start": 1158.36, "end": 1164.0, "text": " So they basically, they took one example and then they created a whole bunch of similar", "tokens": [50364, 407, 436, 1936, 11, 436, 1890, 472, 1365, 293, 550, 436, 2942, 257, 1379, 3840, 295, 2531, 50646], "temperature": 0.0, "avg_logprob": -0.21971960725455447, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.00657911691814661}, {"id": 221, "seek": 115836, "start": 1164.0, "end": 1173.1999999999998, "text": " examples by basically applying various different transformations to it, you know, changing", "tokens": [50646, 5110, 538, 1936, 9275, 3683, 819, 34852, 281, 309, 11, 291, 458, 11, 4473, 51106], "temperature": 0.0, "avg_logprob": -0.21971960725455447, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.00657911691814661}, {"id": 222, "seek": 115836, "start": 1173.1999999999998, "end": 1180.6799999999998, "text": " lighting, changing contrast, changing shapes, you know, various geometric transformation,", "tokens": [51106, 9577, 11, 4473, 8712, 11, 4473, 10854, 11, 291, 458, 11, 3683, 33246, 9887, 11, 51480], "temperature": 0.0, "avg_logprob": -0.21971960725455447, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.00657911691814661}, {"id": 223, "seek": 115836, "start": 1180.6799999999998, "end": 1181.6799999999998, "text": " etc.", "tokens": [51480, 5183, 13, 51530], "temperature": 0.0, "avg_logprob": -0.21971960725455447, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.00657911691814661}, {"id": 224, "seek": 118168, "start": 1181.8400000000001, "end": 1188.8, "text": " In the end, even though all of these things came from a single example, they all were", "tokens": [50372, 682, 264, 917, 11, 754, 1673, 439, 295, 613, 721, 1361, 490, 257, 2167, 1365, 11, 436, 439, 645, 50720], "temperature": 0.0, "avg_logprob": -0.1462619196284901, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.008697817102074623}, {"id": 225, "seek": 118168, "start": 1188.8, "end": 1193.88, "text": " a little bit different and so this became the positive class and then everything else", "tokens": [50720, 257, 707, 857, 819, 293, 370, 341, 3062, 264, 3353, 1508, 293, 550, 1203, 1646, 50974], "temperature": 0.0, "avg_logprob": -0.1462619196284901, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.008697817102074623}, {"id": 226, "seek": 118168, "start": 1193.88, "end": 1196.88, "text": " became the negative class and that worked really, really well, okay?", "tokens": [50974, 3062, 264, 3671, 1508, 293, 300, 2732, 534, 11, 534, 731, 11, 1392, 30, 51124], "temperature": 0.0, "avg_logprob": -0.1462619196284901, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.008697817102074623}, {"id": 227, "seek": 118168, "start": 1196.88, "end": 1205.28, "text": " And this work really was an inspiration for a lot of the current contrast of self-supervised", "tokens": [51124, 400, 341, 589, 534, 390, 364, 10249, 337, 257, 688, 295, 264, 2190, 8712, 295, 2698, 12, 48172, 24420, 51544], "temperature": 0.0, "avg_logprob": -0.1462619196284901, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.008697817102074623}, {"id": 228, "seek": 118168, "start": 1205.28, "end": 1209.48, "text": " learning that we are familiar with right now.", "tokens": [51544, 2539, 300, 321, 366, 4963, 365, 558, 586, 13, 51754], "temperature": 0.0, "avg_logprob": -0.1462619196284901, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.008697817102074623}, {"id": 229, "seek": 120948, "start": 1209.48, "end": 1215.6, "text": " So we thought we will be very pure and just use a single image, but this of course worked", "tokens": [50364, 407, 321, 1194, 321, 486, 312, 588, 6075, 293, 445, 764, 257, 2167, 3256, 11, 457, 341, 295, 1164, 2732, 50670], "temperature": 0.0, "avg_logprob": -0.15955331477713078, "compression_ratio": 1.6828193832599119, "no_speech_prob": 0.0011323882499709725}, {"id": 230, "seek": 120948, "start": 1215.6, "end": 1216.84, "text": " much, much better.", "tokens": [50670, 709, 11, 709, 1101, 13, 50732], "temperature": 0.0, "avg_logprob": -0.15955331477713078, "compression_ratio": 1.6828193832599119, "no_speech_prob": 0.0011323882499709725}, {"id": 231, "seek": 120948, "start": 1216.84, "end": 1221.84, "text": " And of course, now in kind of modern day, the self-supervised learning representations", "tokens": [50732, 400, 295, 1164, 11, 586, 294, 733, 295, 4363, 786, 11, 264, 2698, 12, 48172, 24420, 2539, 33358, 50982], "temperature": 0.0, "avg_logprob": -0.15955331477713078, "compression_ratio": 1.6828193832599119, "no_speech_prob": 0.0011323882499709725}, {"id": 232, "seek": 120948, "start": 1221.84, "end": 1230.92, "text": " that seem to work the best, they're all based on this idea of similarity learning, of instead", "tokens": [50982, 300, 1643, 281, 589, 264, 1151, 11, 436, 434, 439, 2361, 322, 341, 1558, 295, 32194, 2539, 11, 295, 2602, 51436], "temperature": 0.0, "avg_logprob": -0.15955331477713078, "compression_ratio": 1.6828193832599119, "no_speech_prob": 0.0011323882499709725}, {"id": 233, "seek": 120948, "start": 1230.92, "end": 1238.96, "text": " of learning which class you are, which category you are, the idea is to learn instances that", "tokens": [51436, 295, 2539, 597, 1508, 291, 366, 11, 597, 7719, 291, 366, 11, 264, 1558, 307, 281, 1466, 14519, 300, 51838], "temperature": 0.0, "avg_logprob": -0.15955331477713078, "compression_ratio": 1.6828193832599119, "no_speech_prob": 0.0011323882499709725}, {"id": 234, "seek": 123896, "start": 1238.96, "end": 1241.76, "text": " are either close or far from each other.", "tokens": [50364, 366, 2139, 1998, 420, 1400, 490, 1184, 661, 13, 50504], "temperature": 0.0, "avg_logprob": -0.15994850158691407, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.0033192583359777927}, {"id": 235, "seek": 123896, "start": 1241.76, "end": 1249.3600000000001, "text": " So learning the distances between the instances in your training data, okay?", "tokens": [50504, 407, 2539, 264, 22182, 1296, 264, 14519, 294, 428, 3097, 1412, 11, 1392, 30, 50884], "temperature": 0.0, "avg_logprob": -0.15994850158691407, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.0033192583359777927}, {"id": 236, "seek": 123896, "start": 1249.3600000000001, "end": 1255.44, "text": " So things like metric learning, SiameseNet and the new contrastive learning are all based", "tokens": [50884, 407, 721, 411, 20678, 2539, 11, 318, 2918, 1130, 31890, 293, 264, 777, 8712, 488, 2539, 366, 439, 2361, 51188], "temperature": 0.0, "avg_logprob": -0.15994850158691407, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.0033192583359777927}, {"id": 237, "seek": 123896, "start": 1255.44, "end": 1256.92, "text": " on that same principle.", "tokens": [51188, 322, 300, 912, 8665, 13, 51262], "temperature": 0.0, "avg_logprob": -0.15994850158691407, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.0033192583359777927}, {"id": 238, "seek": 123896, "start": 1256.92, "end": 1262.56, "text": " So you basically, you have some sort of an embedding space and your goal is to say, okay,", "tokens": [51262, 407, 291, 1936, 11, 291, 362, 512, 1333, 295, 364, 12240, 3584, 1901, 293, 428, 3387, 307, 281, 584, 11, 1392, 11, 51544], "temperature": 0.0, "avg_logprob": -0.15994850158691407, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.0033192583359777927}, {"id": 239, "seek": 123896, "start": 1262.56, "end": 1268.24, "text": " for a given positive like this particular instance of a dog here, you create a bunch", "tokens": [51544, 337, 257, 2212, 3353, 411, 341, 1729, 5197, 295, 257, 3000, 510, 11, 291, 1884, 257, 3840, 51828], "temperature": 0.0, "avg_logprob": -0.15994850158691407, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.0033192583359777927}, {"id": 240, "seek": 126824, "start": 1268.24, "end": 1272.1200000000001, "text": " of different positive example by data augmentation.", "tokens": [50364, 295, 819, 3353, 1365, 538, 1412, 14501, 19631, 13, 50558], "temperature": 0.0, "avg_logprob": -0.18152578774984782, "compression_ratio": 1.6009852216748768, "no_speech_prob": 0.0020182800944894552}, {"id": 241, "seek": 126824, "start": 1272.1200000000001, "end": 1278.24, "text": " And then you basically try to push these ones, all of them to be close to each other in this", "tokens": [50558, 400, 550, 291, 1936, 853, 281, 2944, 613, 2306, 11, 439, 295, 552, 281, 312, 1998, 281, 1184, 661, 294, 341, 50864], "temperature": 0.0, "avg_logprob": -0.18152578774984782, "compression_ratio": 1.6009852216748768, "no_speech_prob": 0.0020182800944894552}, {"id": 242, "seek": 126824, "start": 1278.24, "end": 1288.16, "text": " embedding space and far away from other things which are dogs or other cats, et cetera.", "tokens": [50864, 12240, 3584, 1901, 293, 1400, 1314, 490, 661, 721, 597, 366, 7197, 420, 661, 11111, 11, 1030, 11458, 13, 51360], "temperature": 0.0, "avg_logprob": -0.18152578774984782, "compression_ratio": 1.6009852216748768, "no_speech_prob": 0.0020182800944894552}, {"id": 243, "seek": 126824, "start": 1288.16, "end": 1294.92, "text": " And this learning of the similarity is really what a lot of the contemporary self-supervised", "tokens": [51360, 400, 341, 2539, 295, 264, 32194, 307, 534, 437, 257, 688, 295, 264, 14878, 2698, 12, 48172, 24420, 51698], "temperature": 0.0, "avg_logprob": -0.18152578774984782, "compression_ratio": 1.6009852216748768, "no_speech_prob": 0.0020182800944894552}, {"id": 244, "seek": 129492, "start": 1294.92, "end": 1298.92, "text": " learning methods are doing, okay?", "tokens": [50364, 2539, 7150, 366, 884, 11, 1392, 30, 50564], "temperature": 0.0, "avg_logprob": -0.21425258822557403, "compression_ratio": 1.5784313725490196, "no_speech_prob": 0.020624956116080284}, {"id": 245, "seek": 129492, "start": 1298.92, "end": 1306.8400000000001, "text": " And so, you know, the reason why this, maybe like a year ago, this area really took off,", "tokens": [50564, 400, 370, 11, 291, 458, 11, 264, 1778, 983, 341, 11, 1310, 411, 257, 1064, 2057, 11, 341, 1859, 534, 1890, 766, 11, 50960], "temperature": 0.0, "avg_logprob": -0.21425258822557403, "compression_ratio": 1.5784313725490196, "no_speech_prob": 0.020624956116080284}, {"id": 246, "seek": 129492, "start": 1306.8400000000001, "end": 1312.1200000000001, "text": " one of the reasons is, of course, you know, the improvements in the representation learning.", "tokens": [50960, 472, 295, 264, 4112, 307, 11, 295, 1164, 11, 291, 458, 11, 264, 13797, 294, 264, 10290, 2539, 13, 51224], "temperature": 0.0, "avg_logprob": -0.21425258822557403, "compression_ratio": 1.5784313725490196, "no_speech_prob": 0.020624956116080284}, {"id": 247, "seek": 129492, "start": 1312.1200000000001, "end": 1318.04, "text": " The contrastive formulation is actually just works much better as shown by papers like", "tokens": [51224, 440, 8712, 488, 37642, 307, 767, 445, 1985, 709, 1101, 382, 4898, 538, 10577, 411, 51520], "temperature": 0.0, "avg_logprob": -0.21425258822557403, "compression_ratio": 1.5784313725490196, "no_speech_prob": 0.020624956116080284}, {"id": 248, "seek": 129492, "start": 1318.04, "end": 1320.48, "text": " Simplier and stuff.", "tokens": [51520, 3998, 564, 811, 293, 1507, 13, 51642], "temperature": 0.0, "avg_logprob": -0.21425258822557403, "compression_ratio": 1.5784313725490196, "no_speech_prob": 0.020624956116080284}, {"id": 249, "seek": 132048, "start": 1320.48, "end": 1326.64, "text": " But another reason I think that's maybe being a little bit underappreciated is that we are", "tokens": [50364, 583, 1071, 1778, 286, 519, 300, 311, 1310, 885, 257, 707, 857, 833, 1746, 3326, 770, 307, 300, 321, 366, 50672], "temperature": 0.0, "avg_logprob": -0.1827862812922551, "compression_ratio": 1.6512605042016806, "no_speech_prob": 0.001303803059272468}, {"id": 250, "seek": 132048, "start": 1326.64, "end": 1331.52, "text": " just much better at doing this data augmentation.", "tokens": [50672, 445, 709, 1101, 412, 884, 341, 1412, 14501, 19631, 13, 50916], "temperature": 0.0, "avg_logprob": -0.1827862812922551, "compression_ratio": 1.6512605042016806, "no_speech_prob": 0.001303803059272468}, {"id": 251, "seek": 132048, "start": 1331.52, "end": 1338.4, "text": " So we have learned to do data augmentation in a better way than the Seitzky and his exemplar", "tokens": [50916, 407, 321, 362, 3264, 281, 360, 1412, 14501, 19631, 294, 257, 1101, 636, 813, 264, 1100, 6862, 4133, 293, 702, 24112, 289, 51260], "temperature": 0.0, "avg_logprob": -0.1827862812922551, "compression_ratio": 1.6512605042016806, "no_speech_prob": 0.001303803059272468}, {"id": 252, "seek": 132048, "start": 1338.4, "end": 1339.56, "text": " Sienna, okay?", "tokens": [51260, 318, 26143, 11, 1392, 30, 51318], "temperature": 0.0, "avg_logprob": -0.1827862812922551, "compression_ratio": 1.6512605042016806, "no_speech_prob": 0.001303803059272468}, {"id": 253, "seek": 132048, "start": 1339.56, "end": 1345.28, "text": " For example, now cropping is a very standard trick for data augmentation, which wasn't a", "tokens": [51318, 1171, 1365, 11, 586, 4848, 3759, 307, 257, 588, 3832, 4282, 337, 1412, 14501, 19631, 11, 597, 2067, 380, 257, 51604], "temperature": 0.0, "avg_logprob": -0.1827862812922551, "compression_ratio": 1.6512605042016806, "no_speech_prob": 0.001303803059272468}, {"id": 254, "seek": 132048, "start": 1345.28, "end": 1349.56, "text": " standard trick before, and that gives us a lot of boost.", "tokens": [51604, 3832, 4282, 949, 11, 293, 300, 2709, 505, 257, 688, 295, 9194, 13, 51818], "temperature": 0.0, "avg_logprob": -0.1827862812922551, "compression_ratio": 1.6512605042016806, "no_speech_prob": 0.001303803059272468}, {"id": 255, "seek": 134956, "start": 1349.56, "end": 1355.28, "text": " So again, what data augmentation is, you get yourself an input image, a single instance,", "tokens": [50364, 407, 797, 11, 437, 1412, 14501, 19631, 307, 11, 291, 483, 1803, 364, 4846, 3256, 11, 257, 2167, 5197, 11, 50650], "temperature": 0.0, "avg_logprob": -0.1628925888626664, "compression_ratio": 1.7936507936507937, "no_speech_prob": 0.00023048273578751832}, {"id": 256, "seek": 134956, "start": 1355.28, "end": 1360.1599999999999, "text": " and then, you know, you just randomly create a whole bunch of different versions of that", "tokens": [50650, 293, 550, 11, 291, 458, 11, 291, 445, 16979, 1884, 257, 1379, 3840, 295, 819, 9606, 295, 300, 50894], "temperature": 0.0, "avg_logprob": -0.1628925888626664, "compression_ratio": 1.7936507936507937, "no_speech_prob": 0.00023048273578751832}, {"id": 257, "seek": 134956, "start": 1360.1599999999999, "end": 1368.24, "text": " image by applying a whole bunch of different parameter transformation, whole transformation,", "tokens": [50894, 3256, 538, 9275, 257, 1379, 3840, 295, 819, 13075, 9887, 11, 1379, 9887, 11, 51298], "temperature": 0.0, "avg_logprob": -0.1628925888626664, "compression_ratio": 1.7936507936507937, "no_speech_prob": 0.00023048273578751832}, {"id": 258, "seek": 134956, "start": 1368.24, "end": 1371.8799999999999, "text": " cropping, flipping, blurring, et cetera, et cetera, et cetera, okay?", "tokens": [51298, 4848, 3759, 11, 26886, 11, 14257, 2937, 11, 1030, 11458, 11, 1030, 11458, 11, 1030, 11458, 11, 1392, 30, 51480], "temperature": 0.0, "avg_logprob": -0.1628925888626664, "compression_ratio": 1.7936507936507937, "no_speech_prob": 0.00023048273578751832}, {"id": 259, "seek": 137188, "start": 1371.88, "end": 1379.72, "text": " And then once you do that, then you set up your kind of a distance function.", "tokens": [50364, 400, 550, 1564, 291, 360, 300, 11, 550, 291, 992, 493, 428, 733, 295, 257, 4560, 2445, 13, 50756], "temperature": 0.0, "avg_logprob": -0.11972125740938408, "compression_ratio": 1.7040816326530612, "no_speech_prob": 0.014060690067708492}, {"id": 260, "seek": 137188, "start": 1379.72, "end": 1387.3600000000001, "text": " So you basically say that I want these two images that all came from the same image really,", "tokens": [50756, 407, 291, 1936, 584, 300, 286, 528, 613, 732, 5267, 300, 439, 1361, 490, 264, 912, 3256, 534, 11, 51138], "temperature": 0.0, "avg_logprob": -0.11972125740938408, "compression_ratio": 1.7040816326530612, "no_speech_prob": 0.014060690067708492}, {"id": 261, "seek": 137188, "start": 1387.3600000000001, "end": 1392.8000000000002, "text": " I want those two images to be similar in our embedding space.", "tokens": [51138, 286, 528, 729, 732, 5267, 281, 312, 2531, 294, 527, 12240, 3584, 1901, 13, 51410], "temperature": 0.0, "avg_logprob": -0.11972125740938408, "compression_ratio": 1.7040816326530612, "no_speech_prob": 0.014060690067708492}, {"id": 262, "seek": 137188, "start": 1392.8000000000002, "end": 1399.0800000000002, "text": " So I'm going to try to bring them close together and farther away from the other images in", "tokens": [51410, 407, 286, 478, 516, 281, 853, 281, 1565, 552, 1998, 1214, 293, 20344, 1314, 490, 264, 661, 5267, 294, 51724], "temperature": 0.0, "avg_logprob": -0.11972125740938408, "compression_ratio": 1.7040816326530612, "no_speech_prob": 0.014060690067708492}, {"id": 263, "seek": 137188, "start": 1399.0800000000002, "end": 1400.0800000000002, "text": " my data set.", "tokens": [51724, 452, 1412, 992, 13, 51774], "temperature": 0.0, "avg_logprob": -0.11972125740938408, "compression_ratio": 1.7040816326530612, "no_speech_prob": 0.014060690067708492}, {"id": 264, "seek": 140008, "start": 1400.1999999999998, "end": 1405.1599999999999, "text": " That's really the whole story of contrastive learning, okay?", "tokens": [50370, 663, 311, 534, 264, 1379, 1657, 295, 8712, 488, 2539, 11, 1392, 30, 50618], "temperature": 0.0, "avg_logprob": -0.15490944385528566, "compression_ratio": 1.6280193236714975, "no_speech_prob": 0.0006459298892877996}, {"id": 265, "seek": 140008, "start": 1405.1599999999999, "end": 1413.4399999999998, "text": " Now the thing is that the choice of data augmentation itself turns out to be very, very critical.", "tokens": [50618, 823, 264, 551, 307, 300, 264, 3922, 295, 1412, 14501, 19631, 2564, 4523, 484, 281, 312, 588, 11, 588, 4924, 13, 51032], "temperature": 0.0, "avg_logprob": -0.15490944385528566, "compression_ratio": 1.6280193236714975, "no_speech_prob": 0.0006459298892877996}, {"id": 266, "seek": 140008, "start": 1413.4399999999998, "end": 1421.76, "text": " And in fact, I want to argue that this data augmentation is itself a little bit of supervised", "tokens": [51032, 400, 294, 1186, 11, 286, 528, 281, 9695, 300, 341, 1412, 14501, 19631, 307, 2564, 257, 707, 857, 295, 46533, 51448], "temperature": 0.0, "avg_logprob": -0.15490944385528566, "compression_ratio": 1.6280193236714975, "no_speech_prob": 0.0006459298892877996}, {"id": 267, "seek": 140008, "start": 1421.76, "end": 1429.96, "text": " learning, because the way you choose your augmentation can make a huge difference in", "tokens": [51448, 2539, 11, 570, 264, 636, 291, 2826, 428, 14501, 19631, 393, 652, 257, 2603, 2649, 294, 51858], "temperature": 0.0, "avg_logprob": -0.15490944385528566, "compression_ratio": 1.6280193236714975, "no_speech_prob": 0.0006459298892877996}, {"id": 268, "seek": 142996, "start": 1429.96, "end": 1432.8, "text": " your final performance, okay?", "tokens": [50364, 428, 2572, 3389, 11, 1392, 30, 50506], "temperature": 0.0, "avg_logprob": -0.1835562129353368, "compression_ratio": 1.5951219512195123, "no_speech_prob": 0.0017264834605157375}, {"id": 269, "seek": 142996, "start": 1432.8, "end": 1439.6000000000001, "text": " So here is an example from our recent paper in iClear 21, where you can think of, let's", "tokens": [50506, 407, 510, 307, 364, 1365, 490, 527, 5162, 3035, 294, 741, 34, 5797, 5080, 11, 689, 291, 393, 519, 295, 11, 718, 311, 50846], "temperature": 0.0, "avg_logprob": -0.1835562129353368, "compression_ratio": 1.5951219512195123, "no_speech_prob": 0.0017264834605157375}, {"id": 270, "seek": 142996, "start": 1439.6000000000001, "end": 1445.32, "text": " say that you have different types of data augmentation, like color augmentation, maybe", "tokens": [50846, 584, 300, 291, 362, 819, 3467, 295, 1412, 14501, 19631, 11, 411, 2017, 14501, 19631, 11, 1310, 51132], "temperature": 0.0, "avg_logprob": -0.1835562129353368, "compression_ratio": 1.5951219512195123, "no_speech_prob": 0.0017264834605157375}, {"id": 271, "seek": 142996, "start": 1445.32, "end": 1448.76, "text": " rotation, and maybe texture, okay?", "tokens": [51132, 12447, 11, 293, 1310, 8091, 11, 1392, 30, 51304], "temperature": 0.0, "avg_logprob": -0.1835562129353368, "compression_ratio": 1.5951219512195123, "no_speech_prob": 0.0017264834605157375}, {"id": 272, "seek": 142996, "start": 1448.76, "end": 1456.68, "text": " So now we can look at different tasks, for example, if we want something like ImageNet,", "tokens": [51304, 407, 586, 321, 393, 574, 412, 819, 9608, 11, 337, 1365, 11, 498, 321, 528, 746, 411, 29903, 31890, 11, 51700], "temperature": 0.0, "avg_logprob": -0.1835562129353368, "compression_ratio": 1.5951219512195123, "no_speech_prob": 0.0017264834605157375}, {"id": 273, "seek": 145668, "start": 1456.68, "end": 1464.2, "text": " course-level categorization, then data augmentation with color makes a lot of sense, with texture", "tokens": [50364, 1164, 12, 12418, 19250, 2144, 11, 550, 1412, 14501, 19631, 365, 2017, 1669, 257, 688, 295, 2020, 11, 365, 8091, 50740], "temperature": 0.0, "avg_logprob": -0.15852555688822045, "compression_ratio": 1.7520325203252032, "no_speech_prob": 0.0017541747074574232}, {"id": 274, "seek": 145668, "start": 1464.2, "end": 1468.5600000000002, "text": " also makes a lot of sense, but rotation is actually going to hurt you, because an upside-down", "tokens": [50740, 611, 1669, 257, 688, 295, 2020, 11, 457, 12447, 307, 767, 516, 281, 4607, 291, 11, 570, 364, 14119, 12, 5093, 50958], "temperature": 0.0, "avg_logprob": -0.15852555688822045, "compression_ratio": 1.7520325203252032, "no_speech_prob": 0.0017541747074574232}, {"id": 275, "seek": 145668, "start": 1468.5600000000002, "end": 1472.6000000000001, "text": " elephant is not going to be recognized as an elephant, okay?", "tokens": [50958, 19791, 307, 406, 516, 281, 312, 9823, 382, 364, 19791, 11, 1392, 30, 51160], "temperature": 0.0, "avg_logprob": -0.15852555688822045, "compression_ratio": 1.7520325203252032, "no_speech_prob": 0.0017541747074574232}, {"id": 276, "seek": 145668, "start": 1472.6000000000001, "end": 1478.72, "text": " Whereas if your task is, for example, fine-grain recognition, well, then it gets even more", "tokens": [51160, 13813, 498, 428, 5633, 307, 11, 337, 1365, 11, 2489, 12, 70, 7146, 11150, 11, 731, 11, 550, 309, 2170, 754, 544, 51466], "temperature": 0.0, "avg_logprob": -0.15852555688822045, "compression_ratio": 1.7520325203252032, "no_speech_prob": 0.0017541747074574232}, {"id": 277, "seek": 145668, "start": 1478.72, "end": 1483.04, "text": " complicated, because if you're fine-grain the different species of birds, then actually", "tokens": [51466, 6179, 11, 570, 498, 291, 434, 2489, 12, 70, 7146, 264, 819, 6172, 295, 9009, 11, 550, 767, 51682], "temperature": 0.0, "avg_logprob": -0.15852555688822045, "compression_ratio": 1.7520325203252032, "no_speech_prob": 0.0017541747074574232}, {"id": 278, "seek": 148304, "start": 1483.04, "end": 1487.24, "text": " you don't want any of those data augmentations, because they're all meaningful, like changing", "tokens": [50364, 291, 500, 380, 528, 604, 295, 729, 1412, 29919, 763, 11, 570, 436, 434, 439, 10995, 11, 411, 4473, 50574], "temperature": 0.0, "avg_logprob": -0.15038020701348026, "compression_ratio": 1.7345971563981042, "no_speech_prob": 0.019401008263230324}, {"id": 279, "seek": 148304, "start": 1487.24, "end": 1493.32, "text": " texture may change the species, changing the color definitely will change the species.", "tokens": [50574, 8091, 815, 1319, 264, 6172, 11, 4473, 264, 2017, 2138, 486, 1319, 264, 6172, 13, 50878], "temperature": 0.0, "avg_logprob": -0.15038020701348026, "compression_ratio": 1.7345971563981042, "no_speech_prob": 0.019401008263230324}, {"id": 280, "seek": 148304, "start": 1493.32, "end": 1499.2, "text": " Whereas maybe if you're classifying different types of flowers, then rotation is fine, because", "tokens": [50878, 13813, 1310, 498, 291, 434, 1508, 5489, 819, 3467, 295, 8085, 11, 550, 12447, 307, 2489, 11, 570, 51172], "temperature": 0.0, "avg_logprob": -0.15038020701348026, "compression_ratio": 1.7345971563981042, "no_speech_prob": 0.019401008263230324}, {"id": 281, "seek": 148304, "start": 1499.2, "end": 1506.76, "text": " rotation augmentation, you know, because flowers are usually rotationally symmetric, okay?", "tokens": [51172, 12447, 14501, 19631, 11, 291, 458, 11, 570, 8085, 366, 2673, 12447, 379, 32330, 11, 1392, 30, 51550], "temperature": 0.0, "avg_logprob": -0.15038020701348026, "compression_ratio": 1.7345971563981042, "no_speech_prob": 0.019401008263230324}, {"id": 282, "seek": 150676, "start": 1506.76, "end": 1513.36, "text": " And so you can see that it really becomes very, very task-dependent.", "tokens": [50364, 400, 370, 291, 393, 536, 300, 309, 534, 3643, 588, 11, 588, 5633, 12, 36763, 317, 13, 50694], "temperature": 0.0, "avg_logprob": -0.1586770674761604, "compression_ratio": 1.6604651162790698, "no_speech_prob": 0.04078914597630501}, {"id": 283, "seek": 150676, "start": 1513.36, "end": 1516.8, "text": " And another example is the cropping and image classification.", "tokens": [50694, 400, 1071, 1365, 307, 264, 4848, 3759, 293, 3256, 21538, 13, 50866], "temperature": 0.0, "avg_logprob": -0.1586770674761604, "compression_ratio": 1.6604651162790698, "no_speech_prob": 0.04078914597630501}, {"id": 284, "seek": 150676, "start": 1516.8, "end": 1522.76, "text": " So cropping for something like ImageNet classification makes a lot of sense, because you have one", "tokens": [50866, 407, 4848, 3759, 337, 746, 411, 29903, 31890, 21538, 1669, 257, 688, 295, 2020, 11, 570, 291, 362, 472, 51164], "temperature": 0.0, "avg_logprob": -0.1586770674761604, "compression_ratio": 1.6604651162790698, "no_speech_prob": 0.04078914597630501}, {"id": 285, "seek": 150676, "start": 1522.76, "end": 1526.16, "text": " big object in the center of the image.", "tokens": [51164, 955, 2657, 294, 264, 3056, 295, 264, 3256, 13, 51334], "temperature": 0.0, "avg_logprob": -0.1586770674761604, "compression_ratio": 1.6604651162790698, "no_speech_prob": 0.04078914597630501}, {"id": 286, "seek": 150676, "start": 1526.16, "end": 1531.28, "text": " But the same cropping for object detection actually doesn't make that much sense, because", "tokens": [51334, 583, 264, 912, 4848, 3759, 337, 2657, 17784, 767, 1177, 380, 652, 300, 709, 2020, 11, 570, 51590], "temperature": 0.0, "avg_logprob": -0.1586770674761604, "compression_ratio": 1.6604651162790698, "no_speech_prob": 0.04078914597630501}, {"id": 287, "seek": 153128, "start": 1531.28, "end": 1537.28, "text": " you crop it and you might lose, you know, where your object is, okay?", "tokens": [50364, 291, 9086, 309, 293, 291, 1062, 3624, 11, 291, 458, 11, 689, 428, 2657, 307, 11, 1392, 30, 50664], "temperature": 0.0, "avg_logprob": -0.11002147344895351, "compression_ratio": 1.561904761904762, "no_speech_prob": 0.0018964840564876795}, {"id": 288, "seek": 153128, "start": 1537.28, "end": 1543.12, "text": " And so this is something that we started to worry about, because we feel like a lot of", "tokens": [50664, 400, 370, 341, 307, 746, 300, 321, 1409, 281, 3292, 466, 11, 570, 321, 841, 411, 257, 688, 295, 50956], "temperature": 0.0, "avg_logprob": -0.11002147344895351, "compression_ratio": 1.561904761904762, "no_speech_prob": 0.0018964840564876795}, {"id": 289, "seek": 153128, "start": 1543.12, "end": 1551.8799999999999, "text": " the advances in the modern self-supervised learning might actually be due to us being", "tokens": [50956, 264, 25297, 294, 264, 4363, 2698, 12, 48172, 24420, 2539, 1062, 767, 312, 3462, 281, 505, 885, 51394], "temperature": 0.0, "avg_logprob": -0.11002147344895351, "compression_ratio": 1.561904761904762, "no_speech_prob": 0.0018964840564876795}, {"id": 290, "seek": 153128, "start": 1551.8799999999999, "end": 1558.2, "text": " very good at overfitting the right kind of data augmentation for a particular problem", "tokens": [51394, 588, 665, 412, 670, 69, 2414, 264, 558, 733, 295, 1412, 14501, 19631, 337, 257, 1729, 1154, 51710], "temperature": 0.0, "avg_logprob": -0.11002147344895351, "compression_ratio": 1.561904761904762, "no_speech_prob": 0.0018964840564876795}, {"id": 291, "seek": 155820, "start": 1558.2, "end": 1562.0800000000002, "text": " rather than the actual methods themselves, okay?", "tokens": [50364, 2831, 813, 264, 3539, 7150, 2969, 11, 1392, 30, 50558], "temperature": 0.0, "avg_logprob": -0.12589900438175644, "compression_ratio": 1.7025641025641025, "no_speech_prob": 0.020316824316978455}, {"id": 292, "seek": 155820, "start": 1562.0800000000002, "end": 1570.1200000000001, "text": " So what we wanted to do is to try to do contrastive self-supervised learning without data augmentation,", "tokens": [50558, 407, 437, 321, 1415, 281, 360, 307, 281, 853, 281, 360, 8712, 488, 2698, 12, 48172, 24420, 2539, 1553, 1412, 14501, 19631, 11, 50960], "temperature": 0.0, "avg_logprob": -0.12589900438175644, "compression_ratio": 1.7025641025641025, "no_speech_prob": 0.020316824316978455}, {"id": 293, "seek": 155820, "start": 1570.1200000000001, "end": 1578.24, "text": " to really try to get it to, to figure it out on its own without this kind of help, okay?", "tokens": [50960, 281, 534, 853, 281, 483, 309, 281, 11, 281, 2573, 309, 484, 322, 1080, 1065, 1553, 341, 733, 295, 854, 11, 1392, 30, 51366], "temperature": 0.0, "avg_logprob": -0.12589900438175644, "compression_ratio": 1.7025641025641025, "no_speech_prob": 0.020316824316978455}, {"id": 294, "seek": 155820, "start": 1578.24, "end": 1582.88, "text": " And the way we wanted to do this is to make these, these augmentations, these what they're", "tokens": [51366, 400, 264, 636, 321, 1415, 281, 360, 341, 307, 281, 652, 613, 11, 613, 29919, 763, 11, 613, 437, 436, 434, 51598], "temperature": 0.0, "avg_logprob": -0.12589900438175644, "compression_ratio": 1.7025641025641025, "no_speech_prob": 0.020316824316978455}, {"id": 295, "seek": 158288, "start": 1582.88, "end": 1588.8400000000001, "text": " called views, to make them latent, to make the computer come up with its own data augmentation", "tokens": [50364, 1219, 6809, 11, 281, 652, 552, 48994, 11, 281, 652, 264, 3820, 808, 493, 365, 1080, 1065, 1412, 14501, 19631, 50662], "temperature": 0.0, "avg_logprob": -0.13276673819272572, "compression_ratio": 1.7518248175182483, "no_speech_prob": 0.02261178195476532}, {"id": 296, "seek": 158288, "start": 1588.8400000000001, "end": 1591.5200000000002, "text": " in this, in a sense, okay?", "tokens": [50662, 294, 341, 11, 294, 257, 2020, 11, 1392, 30, 50796], "temperature": 0.0, "avg_logprob": -0.13276673819272572, "compression_ratio": 1.7518248175182483, "no_speech_prob": 0.02261178195476532}, {"id": 297, "seek": 158288, "start": 1591.5200000000002, "end": 1597.3600000000001, "text": " And of course, the big question here is, this is all great, but where do you get the supervisory", "tokens": [50796, 400, 295, 1164, 11, 264, 955, 1168, 510, 307, 11, 341, 307, 439, 869, 11, 457, 689, 360, 291, 483, 264, 34409, 827, 51088], "temperature": 0.0, "avg_logprob": -0.13276673819272572, "compression_ratio": 1.7518248175182483, "no_speech_prob": 0.02261178195476532}, {"id": 298, "seek": 158288, "start": 1597.3600000000001, "end": 1598.3600000000001, "text": " signal, right?", "tokens": [51088, 6358, 11, 558, 30, 51138], "temperature": 0.0, "avg_logprob": -0.13276673819272572, "compression_ratio": 1.7518248175182483, "no_speech_prob": 0.02261178195476532}, {"id": 299, "seek": 158288, "start": 1598.3600000000001, "end": 1599.3600000000001, "text": " There is no free light.", "tokens": [51138, 821, 307, 572, 1737, 1442, 13, 51188], "temperature": 0.0, "avg_logprob": -0.13276673819272572, "compression_ratio": 1.7518248175182483, "no_speech_prob": 0.02261178195476532}, {"id": 300, "seek": 158288, "start": 1599.3600000000001, "end": 1603.2800000000002, "text": " You need to get some sort of supervisory signal from somewhere in your data.", "tokens": [51188, 509, 643, 281, 483, 512, 1333, 295, 34409, 827, 6358, 490, 4079, 294, 428, 1412, 13, 51384], "temperature": 0.0, "avg_logprob": -0.13276673819272572, "compression_ratio": 1.7518248175182483, "no_speech_prob": 0.02261178195476532}, {"id": 301, "seek": 158288, "start": 1603.2800000000002, "end": 1605.7600000000002, "text": " So where is it going to come from?", "tokens": [51384, 407, 689, 307, 309, 516, 281, 808, 490, 30, 51508], "temperature": 0.0, "avg_logprob": -0.13276673819272572, "compression_ratio": 1.7518248175182483, "no_speech_prob": 0.02261178195476532}, {"id": 302, "seek": 158288, "start": 1605.7600000000002, "end": 1609.8400000000001, "text": " And here we're going to, I'm going to talk about a couple of papers where we answer", "tokens": [51508, 400, 510, 321, 434, 516, 281, 11, 286, 478, 516, 281, 751, 466, 257, 1916, 295, 10577, 689, 321, 1867, 51712], "temperature": 0.0, "avg_logprob": -0.13276673819272572, "compression_ratio": 1.7518248175182483, "no_speech_prob": 0.02261178195476532}, {"id": 303, "seek": 158288, "start": 1609.8400000000001, "end": 1611.5200000000002, "text": " this question differently.", "tokens": [51712, 341, 1168, 7614, 13, 51796], "temperature": 0.0, "avg_logprob": -0.13276673819272572, "compression_ratio": 1.7518248175182483, "no_speech_prob": 0.02261178195476532}, {"id": 304, "seek": 161152, "start": 1611.52, "end": 1619.6399999999999, "text": " The first paper, the answer we have is that we want to use time as our self-supervisor", "tokens": [50364, 440, 700, 3035, 11, 264, 1867, 321, 362, 307, 300, 321, 528, 281, 764, 565, 382, 527, 2698, 12, 48172, 16457, 50770], "temperature": 0.0, "avg_logprob": -0.15368764776932567, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0024669168051332235}, {"id": 305, "seek": 161152, "start": 1619.6399999999999, "end": 1621.68, "text": " signal, okay?", "tokens": [50770, 6358, 11, 1392, 30, 50872], "temperature": 0.0, "avg_logprob": -0.15368764776932567, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0024669168051332235}, {"id": 306, "seek": 161152, "start": 1621.68, "end": 1627.16, "text": " And here I have a wonderful quote from one of my favorite writers, Jorge Luis Borges,", "tokens": [50872, 400, 510, 286, 362, 257, 3715, 6513, 490, 472, 295, 452, 2954, 13491, 11, 36875, 25133, 13739, 2880, 11, 51146], "temperature": 0.0, "avg_logprob": -0.15368764776932567, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0024669168051332235}, {"id": 307, "seek": 161152, "start": 1627.16, "end": 1634.76, "text": " in his short story about fumes, who is this kind of a man on the spectrum.", "tokens": [51146, 294, 702, 2099, 1657, 466, 283, 10018, 11, 567, 307, 341, 733, 295, 257, 587, 322, 264, 11143, 13, 51526], "temperature": 0.0, "avg_logprob": -0.15368764776932567, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0024669168051332235}, {"id": 308, "seek": 161152, "start": 1634.76, "end": 1640.84, "text": " He writes, it irritated him that the dog at 3.14 in the afternoon seen in profile should", "tokens": [51526, 634, 13657, 11, 309, 43650, 796, 300, 264, 3000, 412, 805, 13, 7271, 294, 264, 6499, 1612, 294, 7964, 820, 51830], "temperature": 0.0, "avg_logprob": -0.15368764776932567, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0024669168051332235}, {"id": 309, "seek": 164084, "start": 1640.84, "end": 1646.6399999999999, "text": " be indicated by the same down as dog at 3.15 seen in front of it, okay?", "tokens": [50364, 312, 16176, 538, 264, 912, 760, 382, 3000, 412, 805, 13, 5211, 1612, 294, 1868, 295, 309, 11, 1392, 30, 50654], "temperature": 0.0, "avg_logprob": -0.1790013435559395, "compression_ratio": 1.5759162303664922, "no_speech_prob": 0.0383681021630764}, {"id": 310, "seek": 164084, "start": 1646.6399999999999, "end": 1657.04, "text": " So basically what he's talking about is that two different instances of time makes most", "tokens": [50654, 407, 1936, 437, 415, 311, 1417, 466, 307, 300, 732, 819, 14519, 295, 565, 1669, 881, 51174], "temperature": 0.0, "avg_logprob": -0.1790013435559395, "compression_ratio": 1.5759162303664922, "no_speech_prob": 0.0383681021630764}, {"id": 311, "seek": 164084, "start": 1657.04, "end": 1666.0, "text": " of us assume that there is some continuity of what we are perceiving, that the dog here", "tokens": [51174, 295, 505, 6552, 300, 456, 307, 512, 23807, 295, 437, 321, 366, 9016, 2123, 11, 300, 264, 3000, 510, 51622], "temperature": 0.0, "avg_logprob": -0.1790013435559395, "compression_ratio": 1.5759162303664922, "no_speech_prob": 0.0383681021630764}, {"id": 312, "seek": 164084, "start": 1666.0, "end": 1670.28, "text": " and the dog here, it's almost certainly the same dog.", "tokens": [51622, 293, 264, 3000, 510, 11, 309, 311, 1920, 3297, 264, 912, 3000, 13, 51836], "temperature": 0.0, "avg_logprob": -0.1790013435559395, "compression_ratio": 1.5759162303664922, "no_speech_prob": 0.0383681021630764}, {"id": 313, "seek": 167028, "start": 1670.28, "end": 1674.8, "text": " But nothing happened to this dog while it was jumping in the water, right?", "tokens": [50364, 583, 1825, 2011, 281, 341, 3000, 1339, 309, 390, 11233, 294, 264, 1281, 11, 558, 30, 50590], "temperature": 0.0, "avg_logprob": -0.10440541385264879, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.02753780037164688}, {"id": 314, "seek": 167028, "start": 1674.8, "end": 1682.28, "text": " But fumes, of course, couldn't figure this out and neither can our computers, right?", "tokens": [50590, 583, 283, 10018, 11, 295, 1164, 11, 2809, 380, 2573, 341, 484, 293, 9662, 393, 527, 10807, 11, 558, 30, 50964], "temperature": 0.0, "avg_logprob": -0.10440541385264879, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.02753780037164688}, {"id": 315, "seek": 167028, "start": 1682.28, "end": 1691.56, "text": " And so the idea is that this temporal correspondence, basically time as a way to align things together,", "tokens": [50964, 400, 370, 264, 1558, 307, 300, 341, 30881, 38135, 11, 1936, 565, 382, 257, 636, 281, 7975, 721, 1214, 11, 51428], "temperature": 0.0, "avg_logprob": -0.10440541385264879, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.02753780037164688}, {"id": 316, "seek": 167028, "start": 1691.56, "end": 1698.12, "text": " to bring things into correspondence, is a very powerful supervisory signal that we should", "tokens": [51428, 281, 1565, 721, 666, 38135, 11, 307, 257, 588, 4005, 34409, 827, 6358, 300, 321, 820, 51756], "temperature": 0.0, "avg_logprob": -0.10440541385264879, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.02753780037164688}, {"id": 317, "seek": 167028, "start": 1698.12, "end": 1699.96, "text": " be using, okay?", "tokens": [51756, 312, 1228, 11, 1392, 30, 51848], "temperature": 0.0, "avg_logprob": -0.10440541385264879, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.02753780037164688}, {"id": 318, "seek": 169996, "start": 1699.96, "end": 1706.6000000000001, "text": " And we have evidence that biological algorithms use it very strongly.", "tokens": [50364, 400, 321, 362, 4467, 300, 13910, 14642, 764, 309, 588, 10613, 13, 50696], "temperature": 0.0, "avg_logprob": -0.17132997512817383, "compression_ratio": 1.3840579710144927, "no_speech_prob": 0.003932535648345947}, {"id": 319, "seek": 169996, "start": 1706.6000000000001, "end": 1721.44, "text": " There is plenty of psychology data for human infants that shows that temporal cues are", "tokens": [50696, 821, 307, 7140, 295, 15105, 1412, 337, 1952, 38829, 300, 3110, 300, 30881, 32192, 366, 51438], "temperature": 0.0, "avg_logprob": -0.17132997512817383, "compression_ratio": 1.3840579710144927, "no_speech_prob": 0.003932535648345947}, {"id": 320, "seek": 169996, "start": 1721.44, "end": 1724.16, "text": " very important to learning vision.", "tokens": [51438, 588, 1021, 281, 2539, 5201, 13, 51574], "temperature": 0.0, "avg_logprob": -0.17132997512817383, "compression_ratio": 1.3840579710144927, "no_speech_prob": 0.003932535648345947}, {"id": 321, "seek": 172416, "start": 1724.16, "end": 1730.76, "text": " And there is this wonderful line of work by Wood who basically did this kind of this", "tokens": [50364, 400, 456, 307, 341, 3715, 1622, 295, 589, 538, 11558, 567, 1936, 630, 341, 733, 295, 341, 50694], "temperature": 0.0, "avg_logprob": -0.1389369067023782, "compression_ratio": 1.7626262626262625, "no_speech_prob": 0.16376549005508423}, {"id": 322, "seek": 172416, "start": 1730.76, "end": 1733.8200000000002, "text": " experiments with newly born chicks.", "tokens": [50694, 12050, 365, 15109, 4232, 42214, 13, 50847], "temperature": 0.0, "avg_logprob": -0.1389369067023782, "compression_ratio": 1.7626262626262625, "no_speech_prob": 0.16376549005508423}, {"id": 323, "seek": 172416, "start": 1733.8200000000002, "end": 1739.64, "text": " So basically what he says he has is this kind of VR cave for chickens, for little chicks.", "tokens": [50847, 407, 1936, 437, 415, 1619, 415, 575, 307, 341, 733, 295, 13722, 11730, 337, 22329, 11, 337, 707, 42214, 13, 51138], "temperature": 0.0, "avg_logprob": -0.1389369067023782, "compression_ratio": 1.7626262626262625, "no_speech_prob": 0.16376549005508423}, {"id": 324, "seek": 172416, "start": 1739.64, "end": 1744.52, "text": " So you put an egg and then the chicken is born and the chicken is born in this VR cave", "tokens": [51138, 407, 291, 829, 364, 3777, 293, 550, 264, 4662, 307, 4232, 293, 264, 4662, 307, 4232, 294, 341, 13722, 11730, 51382], "temperature": 0.0, "avg_logprob": -0.1389369067023782, "compression_ratio": 1.7626262626262625, "no_speech_prob": 0.16376549005508423}, {"id": 325, "seek": 172416, "start": 1744.52, "end": 1747.92, "text": " where he's basically projected things on all sides.", "tokens": [51382, 689, 415, 311, 1936, 26231, 721, 322, 439, 4881, 13, 51552], "temperature": 0.0, "avg_logprob": -0.1389369067023782, "compression_ratio": 1.7626262626262625, "no_speech_prob": 0.16376549005508423}, {"id": 326, "seek": 174792, "start": 1747.92, "end": 1754.72, "text": " So everything that the chick knows from birth is being controlled by the researcher, okay?", "tokens": [50364, 407, 1203, 300, 264, 14371, 3255, 490, 3965, 307, 885, 10164, 538, 264, 21751, 11, 1392, 30, 50704], "temperature": 0.0, "avg_logprob": -0.1915602816475762, "compression_ratio": 1.6313131313131313, "no_speech_prob": 0.004195033106952906}, {"id": 327, "seek": 174792, "start": 1754.72, "end": 1761.3600000000001, "text": " And what he showed that some of the chicks were shown videos that were not temporally", "tokens": [50704, 400, 437, 415, 4712, 300, 512, 295, 264, 42214, 645, 4898, 2145, 300, 645, 406, 8219, 379, 51036], "temperature": 0.0, "avg_logprob": -0.1915602816475762, "compression_ratio": 1.6313131313131313, "no_speech_prob": 0.004195033106952906}, {"id": 328, "seek": 174792, "start": 1761.3600000000001, "end": 1765.2, "text": " coherent, that basically broke this temporal continuity.", "tokens": [51036, 36239, 11, 300, 1936, 6902, 341, 30881, 23807, 13, 51228], "temperature": 0.0, "avg_logprob": -0.1915602816475762, "compression_ratio": 1.6313131313131313, "no_speech_prob": 0.004195033106952906}, {"id": 329, "seek": 174792, "start": 1765.2, "end": 1772.88, "text": " As you can see, it was not kind of physically correct and he compared them to chicks that", "tokens": [51228, 1018, 291, 393, 536, 11, 309, 390, 406, 733, 295, 9762, 3006, 293, 415, 5347, 552, 281, 42214, 300, 51612], "temperature": 0.0, "avg_logprob": -0.1915602816475762, "compression_ratio": 1.6313131313131313, "no_speech_prob": 0.004195033106952906}, {"id": 330, "seek": 177288, "start": 1772.88, "end": 1777.0400000000002, "text": " were shown normal, normal continuous things.", "tokens": [50364, 645, 4898, 2710, 11, 2710, 10957, 721, 13, 50572], "temperature": 0.0, "avg_logprob": -0.2277476859815193, "compression_ratio": 1.6480446927374302, "no_speech_prob": 0.2561354339122772}, {"id": 331, "seek": 177288, "start": 1777.0400000000002, "end": 1785.8000000000002, "text": " And the chicks who saw these continuous patterns, they were not able to function in the world", "tokens": [50572, 400, 264, 42214, 567, 1866, 613, 10957, 8294, 11, 436, 645, 406, 1075, 281, 2445, 294, 264, 1002, 51010], "temperature": 0.0, "avg_logprob": -0.2277476859815193, "compression_ratio": 1.6480446927374302, "no_speech_prob": 0.2561354339122772}, {"id": 332, "seek": 177288, "start": 1785.8000000000002, "end": 1786.8000000000002, "text": " as well.", "tokens": [51010, 382, 731, 13, 51060], "temperature": 0.0, "avg_logprob": -0.2277476859815193, "compression_ratio": 1.6480446927374302, "no_speech_prob": 0.2561354339122772}, {"id": 333, "seek": 177288, "start": 1786.8000000000002, "end": 1791.92, "text": " They lacked some of the visual perception skills.", "tokens": [51060, 814, 41481, 512, 295, 264, 5056, 12860, 3942, 13, 51316], "temperature": 0.0, "avg_logprob": -0.2277476859815193, "compression_ratio": 1.6480446927374302, "no_speech_prob": 0.2561354339122772}, {"id": 334, "seek": 177288, "start": 1791.92, "end": 1797.92, "text": " So that showed that this is extremely important, that temporal continuity is extremely important.", "tokens": [51316, 407, 300, 4712, 300, 341, 307, 4664, 1021, 11, 300, 30881, 23807, 307, 4664, 1021, 13, 51616], "temperature": 0.0, "avg_logprob": -0.2277476859815193, "compression_ratio": 1.6480446927374302, "no_speech_prob": 0.2561354339122772}, {"id": 335, "seek": 179792, "start": 1797.92, "end": 1806.24, "text": " And so what we want to do in this work is to use video as data augmentation, as a way", "tokens": [50364, 400, 370, 437, 321, 528, 281, 360, 294, 341, 589, 307, 281, 764, 960, 382, 1412, 14501, 19631, 11, 382, 257, 636, 50780], "temperature": 0.0, "avg_logprob": -0.16418100658215976, "compression_ratio": 1.509933774834437, "no_speech_prob": 0.007006064523011446}, {"id": 336, "seek": 179792, "start": 1806.24, "end": 1813.68, "text": " to create these data augmented views ourselves, okay?", "tokens": [50780, 281, 1884, 613, 1412, 36155, 6809, 4175, 11, 1392, 30, 51152], "temperature": 0.0, "avg_logprob": -0.16418100658215976, "compression_ratio": 1.509933774834437, "no_speech_prob": 0.007006064523011446}, {"id": 337, "seek": 179792, "start": 1813.68, "end": 1821.88, "text": " And basically the main thing, of course, is that this can provide correspondences across", "tokens": [51152, 400, 1936, 264, 2135, 551, 11, 295, 1164, 11, 307, 300, 341, 393, 2893, 6805, 2667, 2108, 51562], "temperature": 0.0, "avg_logprob": -0.16418100658215976, "compression_ratio": 1.509933774834437, "no_speech_prob": 0.007006064523011446}, {"id": 338, "seek": 182188, "start": 1821.88, "end": 1830.2, "text": " different instances and allows the computer to learn how something looks across time change,", "tokens": [50364, 819, 14519, 293, 4045, 264, 3820, 281, 1466, 577, 746, 1542, 2108, 565, 1319, 11, 50780], "temperature": 0.0, "avg_logprob": -0.21062077068891683, "compression_ratio": 1.4863387978142077, "no_speech_prob": 0.1381404995918274}, {"id": 339, "seek": 182188, "start": 1830.2, "end": 1831.3600000000001, "text": " okay?", "tokens": [50780, 1392, 30, 50838], "temperature": 0.0, "avg_logprob": -0.21062077068891683, "compression_ratio": 1.4863387978142077, "no_speech_prob": 0.1381404995918274}, {"id": 340, "seek": 182188, "start": 1831.3600000000001, "end": 1839.16, "text": " But it can give us a bit more because we can also think about contextual relationships", "tokens": [50838, 583, 309, 393, 976, 505, 257, 857, 544, 570, 321, 393, 611, 519, 466, 35526, 6159, 51228], "temperature": 0.0, "avg_logprob": -0.21062077068891683, "compression_ratio": 1.4863387978142077, "no_speech_prob": 0.1381404995918274}, {"id": 341, "seek": 182188, "start": 1839.16, "end": 1844.6000000000001, "text": " and notice things that are moving in the same way, what Bernheimer called common fate.", "tokens": [51228, 293, 3449, 721, 300, 366, 2684, 294, 264, 912, 636, 11, 437, 10781, 23542, 1219, 2689, 12738, 13, 51500], "temperature": 0.0, "avg_logprob": -0.21062077068891683, "compression_ratio": 1.4863387978142077, "no_speech_prob": 0.1381404995918274}, {"id": 342, "seek": 184460, "start": 1844.6, "end": 1852.9199999999998, "text": " We also use that as a way to group little points, little trajectories into groups and", "tokens": [50364, 492, 611, 764, 300, 382, 257, 636, 281, 1594, 707, 2793, 11, 707, 18257, 2083, 666, 3935, 293, 50780], "temperature": 0.0, "avg_logprob": -0.14664659716866232, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.1683041751384735}, {"id": 343, "seek": 184460, "start": 1852.9199999999998, "end": 1857.28, "text": " maybe get to the notion of objects from the notion of points, okay?", "tokens": [50780, 1310, 483, 281, 264, 10710, 295, 6565, 490, 264, 10710, 295, 2793, 11, 1392, 30, 50998], "temperature": 0.0, "avg_logprob": -0.14664659716866232, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.1683041751384735}, {"id": 344, "seek": 184460, "start": 1857.28, "end": 1861.6799999999998, "text": " Again something that you can use temporal information for, okay?", "tokens": [50998, 3764, 746, 300, 291, 393, 764, 30881, 1589, 337, 11, 1392, 30, 51218], "temperature": 0.0, "avg_logprob": -0.14664659716866232, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.1683041751384735}, {"id": 345, "seek": 184460, "start": 1861.6799999999998, "end": 1864.7199999999998, "text": " And so this is basically the story.", "tokens": [51218, 400, 370, 341, 307, 1936, 264, 1657, 13, 51370], "temperature": 0.0, "avg_logprob": -0.14664659716866232, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.1683041751384735}, {"id": 346, "seek": 184460, "start": 1864.7199999999998, "end": 1870.1999999999998, "text": " And then the question is how do we harness this information without any sort of supervisory", "tokens": [51370, 400, 550, 264, 1168, 307, 577, 360, 321, 19700, 341, 1589, 1553, 604, 1333, 295, 34409, 827, 51644], "temperature": 0.0, "avg_logprob": -0.14664659716866232, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.1683041751384735}, {"id": 347, "seek": 184460, "start": 1870.1999999999998, "end": 1871.1999999999998, "text": " signal, okay?", "tokens": [51644, 6358, 11, 1392, 30, 51694], "temperature": 0.0, "avg_logprob": -0.14664659716866232, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.1683041751384735}, {"id": 348, "seek": 187120, "start": 1871.2, "end": 1879.1200000000001, "text": " And in the past, people have used things like slow feature learning where they basically", "tokens": [50364, 400, 294, 264, 1791, 11, 561, 362, 1143, 721, 411, 2964, 4111, 2539, 689, 436, 1936, 50760], "temperature": 0.0, "avg_logprob": -0.2461302920085628, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.014047868549823761}, {"id": 349, "seek": 187120, "start": 1879.1200000000001, "end": 1885.8400000000001, "text": " kind of looked at connecting nearby frames together, basically look at nearby frames", "tokens": [50760, 733, 295, 2956, 412, 11015, 11184, 12083, 1214, 11, 1936, 574, 412, 11184, 12083, 51096], "temperature": 0.0, "avg_logprob": -0.2461302920085628, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.014047868549823761}, {"id": 350, "seek": 187120, "start": 1885.8400000000001, "end": 1890.52, "text": " as the positives and far away frames as the negatives, but you just collapse the entire", "tokens": [51096, 382, 264, 35127, 293, 1400, 1314, 12083, 382, 264, 40019, 11, 457, 291, 445, 15584, 264, 2302, 51330], "temperature": 0.0, "avg_logprob": -0.2461302920085628, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.014047868549823761}, {"id": 351, "seek": 187120, "start": 1890.52, "end": 1896.16, "text": " frame and so that's not really something that can give you these point tracks, it's much", "tokens": [51330, 3920, 293, 370, 300, 311, 406, 534, 746, 300, 393, 976, 291, 613, 935, 10218, 11, 309, 311, 709, 51612], "temperature": 0.0, "avg_logprob": -0.2461302920085628, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.014047868549823761}, {"id": 352, "seek": 187120, "start": 1896.16, "end": 1898.16, "text": " more coarse signal.", "tokens": [51612, 544, 39312, 6358, 13, 51712], "temperature": 0.0, "avg_logprob": -0.2461302920085628, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.014047868549823761}, {"id": 353, "seek": 189816, "start": 1898.6000000000001, "end": 1905.0, "text": " Alternatively people use things like optical flow or tracking to create correspondences", "tokens": [50386, 46167, 561, 764, 721, 411, 20674, 3095, 420, 11603, 281, 1884, 6805, 2667, 50706], "temperature": 0.0, "avg_logprob": -0.16566220816079671, "compression_ratio": 1.6683168316831682, "no_speech_prob": 0.0064848135225474834}, {"id": 354, "seek": 189816, "start": 1905.0, "end": 1910.1200000000001, "text": " using some off the shelf methods and then use learning to connect things that are supposed", "tokens": [50706, 1228, 512, 766, 264, 15222, 7150, 293, 550, 764, 2539, 281, 1745, 721, 300, 366, 3442, 50962], "temperature": 0.0, "avg_logprob": -0.16566220816079671, "compression_ratio": 1.6683168316831682, "no_speech_prob": 0.0064848135225474834}, {"id": 355, "seek": 189816, "start": 1910.1200000000001, "end": 1911.28, "text": " to be in correspondence.", "tokens": [50962, 281, 312, 294, 38135, 13, 51020], "temperature": 0.0, "avg_logprob": -0.16566220816079671, "compression_ratio": 1.6683168316831682, "no_speech_prob": 0.0064848135225474834}, {"id": 356, "seek": 189816, "start": 1911.28, "end": 1916.8000000000002, "text": " But here you're using two different methods and so what we wanted to do is do something", "tokens": [51020, 583, 510, 291, 434, 1228, 732, 819, 7150, 293, 370, 437, 321, 1415, 281, 360, 307, 360, 746, 51296], "temperature": 0.0, "avg_logprob": -0.16566220816079671, "compression_ratio": 1.6683168316831682, "no_speech_prob": 0.0064848135225474834}, {"id": 357, "seek": 189816, "start": 1916.8000000000002, "end": 1921.3600000000001, "text": " like this but kind of in one go, in one pack.", "tokens": [51296, 411, 341, 457, 733, 295, 294, 472, 352, 11, 294, 472, 2844, 13, 51524], "temperature": 0.0, "avg_logprob": -0.16566220816079671, "compression_ratio": 1.6683168316831682, "no_speech_prob": 0.0064848135225474834}, {"id": 358, "seek": 192136, "start": 1921.36, "end": 1930.6399999999999, "text": " And this is our paper that tries to do this, this was published in Europe's past year", "tokens": [50364, 400, 341, 307, 527, 3035, 300, 9898, 281, 360, 341, 11, 341, 390, 6572, 294, 3315, 311, 1791, 1064, 50828], "temperature": 0.0, "avg_logprob": -0.19164287269889535, "compression_ratio": 1.5508021390374331, "no_speech_prob": 0.03201736882328987}, {"id": 359, "seek": 192136, "start": 1930.6399999999999, "end": 1933.7199999999998, "text": " and here is the idea, okay?", "tokens": [50828, 293, 510, 307, 264, 1558, 11, 1392, 30, 50982], "temperature": 0.0, "avg_logprob": -0.19164287269889535, "compression_ratio": 1.5508021390374331, "no_speech_prob": 0.03201736882328987}, {"id": 360, "seek": 192136, "start": 1933.7199999999998, "end": 1941.08, "text": " And so for a warm up, let's consider the case where you actually do have labels.", "tokens": [50982, 400, 370, 337, 257, 4561, 493, 11, 718, 311, 1949, 264, 1389, 689, 291, 767, 360, 362, 16949, 13, 51350], "temperature": 0.0, "avg_logprob": -0.19164287269889535, "compression_ratio": 1.5508021390374331, "no_speech_prob": 0.03201736882328987}, {"id": 361, "seek": 192136, "start": 1941.08, "end": 1946.3999999999999, "text": " Let's say that somebody went ahead and labeled that this patch corresponds to this patch,", "tokens": [51350, 961, 311, 584, 300, 2618, 1437, 2286, 293, 21335, 300, 341, 9972, 23249, 281, 341, 9972, 11, 51616], "temperature": 0.0, "avg_logprob": -0.19164287269889535, "compression_ratio": 1.5508021390374331, "no_speech_prob": 0.03201736882328987}, {"id": 362, "seek": 192136, "start": 1946.3999999999999, "end": 1947.3999999999999, "text": " okay?", "tokens": [51616, 1392, 30, 51666], "temperature": 0.0, "avg_logprob": -0.19164287269889535, "compression_ratio": 1.5508021390374331, "no_speech_prob": 0.03201736882328987}, {"id": 363, "seek": 194740, "start": 1947.4, "end": 1955.2800000000002, "text": " And your goal is to basically learn a representation that brings things that are the same into", "tokens": [50364, 400, 428, 3387, 307, 281, 1936, 1466, 257, 10290, 300, 5607, 721, 300, 366, 264, 912, 666, 50758], "temperature": 0.0, "avg_logprob": -0.18285398483276366, "compression_ratio": 1.7746478873239437, "no_speech_prob": 0.003073032945394516}, {"id": 364, "seek": 194740, "start": 1955.2800000000002, "end": 1959.52, "text": " correspondence and away from things that are different, right?", "tokens": [50758, 38135, 293, 1314, 490, 721, 300, 366, 819, 11, 558, 30, 50970], "temperature": 0.0, "avg_logprob": -0.18285398483276366, "compression_ratio": 1.7746478873239437, "no_speech_prob": 0.003073032945394516}, {"id": 365, "seek": 194740, "start": 1959.52, "end": 1963.8000000000002, "text": " So in this case of course it's very simple, you just say, okay, these two things are my", "tokens": [50970, 407, 294, 341, 1389, 295, 1164, 309, 311, 588, 2199, 11, 291, 445, 584, 11, 1392, 11, 613, 732, 721, 366, 452, 51184], "temperature": 0.0, "avg_logprob": -0.18285398483276366, "compression_ratio": 1.7746478873239437, "no_speech_prob": 0.003073032945394516}, {"id": 366, "seek": 194740, "start": 1963.8000000000002, "end": 1968.48, "text": " two positives, I want them to be close together and all the other patches are my negatives,", "tokens": [51184, 732, 35127, 11, 286, 528, 552, 281, 312, 1998, 1214, 293, 439, 264, 661, 26531, 366, 452, 40019, 11, 51418], "temperature": 0.0, "avg_logprob": -0.18285398483276366, "compression_ratio": 1.7746478873239437, "no_speech_prob": 0.003073032945394516}, {"id": 367, "seek": 194740, "start": 1968.48, "end": 1972.76, "text": " I want them to be pushed far away and then you have your standard self-supervised learning,", "tokens": [51418, 286, 528, 552, 281, 312, 9152, 1400, 1314, 293, 550, 291, 362, 428, 3832, 2698, 12, 48172, 24420, 2539, 11, 51632], "temperature": 0.0, "avg_logprob": -0.18285398483276366, "compression_ratio": 1.7746478873239437, "no_speech_prob": 0.003073032945394516}, {"id": 368, "seek": 194740, "start": 1972.76, "end": 1975.8000000000002, "text": " contrastive learning problem and off you go, right?", "tokens": [51632, 8712, 488, 2539, 1154, 293, 766, 291, 352, 11, 558, 30, 51784], "temperature": 0.0, "avg_logprob": -0.18285398483276366, "compression_ratio": 1.7746478873239437, "no_speech_prob": 0.003073032945394516}, {"id": 369, "seek": 194740, "start": 1975.8000000000002, "end": 1977.0800000000002, "text": " Nothing very exciting.", "tokens": [51784, 6693, 588, 4670, 13, 51848], "temperature": 0.0, "avg_logprob": -0.18285398483276366, "compression_ratio": 1.7746478873239437, "no_speech_prob": 0.003073032945394516}, {"id": 370, "seek": 197708, "start": 1977.08, "end": 1983.6, "text": " So things get a little bit more exciting if you have maybe another frame in between, okay?", "tokens": [50364, 407, 721, 483, 257, 707, 857, 544, 4670, 498, 291, 362, 1310, 1071, 3920, 294, 1296, 11, 1392, 30, 50690], "temperature": 0.0, "avg_logprob": -0.11628717329443955, "compression_ratio": 1.561904761904762, "no_speech_prob": 0.006892213132232428}, {"id": 371, "seek": 197708, "start": 1983.6, "end": 1986.8, "text": " Because now you have, these two guys are your two positives.", "tokens": [50690, 1436, 586, 291, 362, 11, 613, 732, 1074, 366, 428, 732, 35127, 13, 50850], "temperature": 0.0, "avg_logprob": -0.11628717329443955, "compression_ratio": 1.561904761904762, "no_speech_prob": 0.006892213132232428}, {"id": 372, "seek": 197708, "start": 1986.8, "end": 1996.6, "text": " We know this by labeling but also because this is a video, we know that from here somehow", "tokens": [50850, 492, 458, 341, 538, 40244, 457, 611, 570, 341, 307, 257, 960, 11, 321, 458, 300, 490, 510, 6063, 51340], "temperature": 0.0, "avg_logprob": -0.11628717329443955, "compression_ratio": 1.561904761904762, "no_speech_prob": 0.006892213132232428}, {"id": 373, "seek": 197708, "start": 1996.6, "end": 2005.52, "text": " it needed to go to be in this final place and so there must have been a path, the most", "tokens": [51340, 309, 2978, 281, 352, 281, 312, 294, 341, 2572, 1081, 293, 370, 456, 1633, 362, 668, 257, 3100, 11, 264, 881, 51786], "temperature": 0.0, "avg_logprob": -0.11628717329443955, "compression_ratio": 1.561904761904762, "no_speech_prob": 0.006892213132232428}, {"id": 374, "seek": 200552, "start": 2006.44, "end": 2011.04, "text": " likely path from this guy to go from here to here and the most likely path is going", "tokens": [50410, 3700, 3100, 490, 341, 2146, 281, 352, 490, 510, 281, 510, 293, 264, 881, 3700, 3100, 307, 516, 50640], "temperature": 0.0, "avg_logprob": -0.15041767724669805, "compression_ratio": 1.912280701754386, "no_speech_prob": 0.2533925175666809}, {"id": 375, "seek": 200552, "start": 2011.04, "end": 2018.04, "text": " to go through this patch so it's reasonable to assume that this patch should also be in", "tokens": [50640, 281, 352, 807, 341, 9972, 370, 309, 311, 10585, 281, 6552, 300, 341, 9972, 820, 611, 312, 294, 50990], "temperature": 0.0, "avg_logprob": -0.15041767724669805, "compression_ratio": 1.912280701754386, "no_speech_prob": 0.2533925175666809}, {"id": 376, "seek": 200552, "start": 2018.04, "end": 2022.84, "text": " our positive category, it should be in the same category as this guy and this guy.", "tokens": [50990, 527, 3353, 7719, 11, 309, 820, 312, 294, 264, 912, 7719, 382, 341, 2146, 293, 341, 2146, 13, 51230], "temperature": 0.0, "avg_logprob": -0.15041767724669805, "compression_ratio": 1.912280701754386, "no_speech_prob": 0.2533925175666809}, {"id": 377, "seek": 200552, "start": 2022.84, "end": 2027.92, "text": " So now these triplets should be the positives and everything else should be the negatives.", "tokens": [51230, 407, 586, 613, 1376, 31023, 820, 312, 264, 35127, 293, 1203, 1646, 820, 312, 264, 40019, 13, 51484], "temperature": 0.0, "avg_logprob": -0.15041767724669805, "compression_ratio": 1.912280701754386, "no_speech_prob": 0.2533925175666809}, {"id": 378, "seek": 200552, "start": 2027.92, "end": 2033.24, "text": " So now you can think of a little bit of kind of automatic data documentation that this guy", "tokens": [51484, 407, 586, 291, 393, 519, 295, 257, 707, 857, 295, 733, 295, 12509, 1412, 14333, 300, 341, 2146, 51750], "temperature": 0.0, "avg_logprob": -0.15041767724669805, "compression_ratio": 1.912280701754386, "no_speech_prob": 0.2533925175666809}, {"id": 379, "seek": 203324, "start": 2033.32, "end": 2040.68, "text": " just by virtue of being tracked in the video becomes a data augmented positive for our kids,", "tokens": [50368, 445, 538, 20816, 295, 885, 31703, 294, 264, 960, 3643, 257, 1412, 36155, 3353, 337, 527, 2301, 11, 50736], "temperature": 0.0, "avg_logprob": -0.1303957998752594, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.00091077497927472}, {"id": 380, "seek": 203324, "start": 2040.68, "end": 2042.04, "text": " okay?", "tokens": [50736, 1392, 30, 50804], "temperature": 0.0, "avg_logprob": -0.1303957998752594, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.00091077497927472}, {"id": 381, "seek": 203324, "start": 2042.04, "end": 2047.0, "text": " So this is okay but this is still requiring us to have this supervision.", "tokens": [50804, 407, 341, 307, 1392, 457, 341, 307, 920, 24165, 505, 281, 362, 341, 32675, 13, 51052], "temperature": 0.0, "avg_logprob": -0.1303957998752594, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.00091077497927472}, {"id": 382, "seek": 203324, "start": 2047.0, "end": 2048.36, "text": " How could we get rid of supervision?", "tokens": [51052, 1012, 727, 321, 483, 3973, 295, 32675, 30, 51120], "temperature": 0.0, "avg_logprob": -0.1303957998752594, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.00091077497927472}, {"id": 383, "seek": 203324, "start": 2048.36, "end": 2055.4, "text": " Well, we are going to use our old trick which we've used before called cycle consistency", "tokens": [51120, 1042, 11, 321, 366, 516, 281, 764, 527, 1331, 4282, 597, 321, 600, 1143, 949, 1219, 6586, 14416, 51472], "temperature": 0.0, "avg_logprob": -0.1303957998752594, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.00091077497927472}, {"id": 384, "seek": 203324, "start": 2055.4, "end": 2060.04, "text": " and what we're going to do is we're going to make this video into a palindrome.", "tokens": [51472, 293, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 652, 341, 960, 666, 257, 3984, 471, 11505, 13, 51704], "temperature": 0.0, "avg_logprob": -0.1303957998752594, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.00091077497927472}, {"id": 385, "seek": 206004, "start": 2060.04, "end": 2065.16, "text": " Palindrome if you remember in language is a word that you read it forward and backwards", "tokens": [50364, 6116, 471, 11505, 498, 291, 1604, 294, 2856, 307, 257, 1349, 300, 291, 1401, 309, 2128, 293, 12204, 50620], "temperature": 0.0, "avg_logprob": -0.07897211547590728, "compression_ratio": 1.798283261802575, "no_speech_prob": 0.0023589457850903273}, {"id": 386, "seek": 206004, "start": 2065.16, "end": 2066.52, "text": " and it reads the same, right?", "tokens": [50620, 293, 309, 15700, 264, 912, 11, 558, 30, 50688], "temperature": 0.0, "avg_logprob": -0.07897211547590728, "compression_ratio": 1.798283261802575, "no_speech_prob": 0.0023589457850903273}, {"id": 387, "seek": 206004, "start": 2066.52, "end": 2069.0, "text": " So how can we make a palindrome out of a video?", "tokens": [50688, 407, 577, 393, 321, 652, 257, 3984, 471, 11505, 484, 295, 257, 960, 30, 50812], "temperature": 0.0, "avg_logprob": -0.07897211547590728, "compression_ratio": 1.798283261802575, "no_speech_prob": 0.0023589457850903273}, {"id": 388, "seek": 206004, "start": 2069.0, "end": 2074.7599999999998, "text": " Well, what we can do is we can take this video and flip it around and put it back", "tokens": [50812, 1042, 11, 437, 321, 393, 360, 307, 321, 393, 747, 341, 960, 293, 7929, 309, 926, 293, 829, 309, 646, 51100], "temperature": 0.0, "avg_logprob": -0.07897211547590728, "compression_ratio": 1.798283261802575, "no_speech_prob": 0.0023589457850903273}, {"id": 389, "seek": 206004, "start": 2076.44, "end": 2078.2799999999997, "text": " in the reverse order, okay?", "tokens": [51184, 294, 264, 9943, 1668, 11, 1392, 30, 51276], "temperature": 0.0, "avg_logprob": -0.07897211547590728, "compression_ratio": 1.798283261802575, "no_speech_prob": 0.0023589457850903273}, {"id": 390, "seek": 206004, "start": 2078.2799999999997, "end": 2082.68, "text": " So now what we have is we have something like frame one, frame two, frame three", "tokens": [51276, 407, 586, 437, 321, 362, 307, 321, 362, 746, 411, 3920, 472, 11, 3920, 732, 11, 3920, 1045, 51496], "temperature": 0.0, "avg_logprob": -0.07897211547590728, "compression_ratio": 1.798283261802575, "no_speech_prob": 0.0023589457850903273}, {"id": 391, "seek": 206004, "start": 2082.68, "end": 2086.04, "text": " and now we're going back to frame two and then frame one, okay?", "tokens": [51496, 293, 586, 321, 434, 516, 646, 281, 3920, 732, 293, 550, 3920, 472, 11, 1392, 30, 51664], "temperature": 0.0, "avg_logprob": -0.07897211547590728, "compression_ratio": 1.798283261802575, "no_speech_prob": 0.0023589457850903273}, {"id": 392, "seek": 208604, "start": 2086.04, "end": 2090.68, "text": " So now we have this new video that's a palindrome and look what's happening.", "tokens": [50364, 407, 586, 321, 362, 341, 777, 960, 300, 311, 257, 3984, 471, 11505, 293, 574, 437, 311, 2737, 13, 50596], "temperature": 0.0, "avg_logprob": -0.09049311876296998, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.00048771026195026934}, {"id": 393, "seek": 208604, "start": 2090.68, "end": 2099.8, "text": " Now the final place, the destination is now exactly the same as the origin by construction.", "tokens": [50596, 823, 264, 2572, 1081, 11, 264, 12236, 307, 586, 2293, 264, 912, 382, 264, 4957, 538, 6435, 13, 51052], "temperature": 0.0, "avg_logprob": -0.09049311876296998, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.00048771026195026934}, {"id": 394, "seek": 208604, "start": 2100.52, "end": 2103.56, "text": " So now we don't need supervision anymore.", "tokens": [51088, 407, 586, 321, 500, 380, 643, 32675, 3602, 13, 51240], "temperature": 0.0, "avg_logprob": -0.09049311876296998, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.00048771026195026934}, {"id": 395, "seek": 208604, "start": 2103.56, "end": 2104.92, "text": " We got rid of supervision.", "tokens": [51240, 492, 658, 3973, 295, 32675, 13, 51308], "temperature": 0.0, "avg_logprob": -0.09049311876296998, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.00048771026195026934}, {"id": 396, "seek": 208604, "start": 2104.92, "end": 2108.7599999999998, "text": " All we need to do is to get from the blue guy to the green guy", "tokens": [51308, 1057, 321, 643, 281, 360, 307, 281, 483, 490, 264, 3344, 2146, 281, 264, 3092, 2146, 51500], "temperature": 0.0, "avg_logprob": -0.09049311876296998, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.00048771026195026934}, {"id": 397, "seek": 210876, "start": 2109.0800000000004, "end": 2117.7200000000003, "text": " and the way we do it is we're basically trying to do a track through this video", "tokens": [50380, 293, 264, 636, 321, 360, 309, 307, 321, 434, 1936, 1382, 281, 360, 257, 2837, 807, 341, 960, 50812], "temperature": 0.0, "avg_logprob": -0.12656293596540177, "compression_ratio": 1.6420454545454546, "no_speech_prob": 0.0018092894461005926}, {"id": 398, "seek": 210876, "start": 2118.28, "end": 2123.8, "text": " and everything that's on this track should be in our positive category", "tokens": [50840, 293, 1203, 300, 311, 322, 341, 2837, 820, 312, 294, 527, 3353, 7719, 51116], "temperature": 0.0, "avg_logprob": -0.12656293596540177, "compression_ratio": 1.6420454545454546, "no_speech_prob": 0.0018092894461005926}, {"id": 399, "seek": 210876, "start": 2123.8, "end": 2125.96, "text": " and everything else should be in the next, okay?", "tokens": [51116, 293, 1203, 1646, 820, 312, 294, 264, 958, 11, 1392, 30, 51224], "temperature": 0.0, "avg_logprob": -0.12656293596540177, "compression_ratio": 1.6420454545454546, "no_speech_prob": 0.0018092894461005926}, {"id": 400, "seek": 210876, "start": 2125.96, "end": 2132.6000000000004, "text": " And so now you can see the setup where we basically are getting something out of nothing.", "tokens": [51224, 400, 370, 586, 291, 393, 536, 264, 8657, 689, 321, 1936, 366, 1242, 746, 484, 295, 1825, 13, 51556], "temperature": 0.0, "avg_logprob": -0.12656293596540177, "compression_ratio": 1.6420454545454546, "no_speech_prob": 0.0018092894461005926}, {"id": 401, "seek": 213260, "start": 2132.6, "end": 2140.36, "text": " We're getting some supervisory signal just from the mere video information, okay?", "tokens": [50364, 492, 434, 1242, 512, 34409, 827, 6358, 445, 490, 264, 8401, 960, 1589, 11, 1392, 30, 50752], "temperature": 0.0, "avg_logprob": -0.07929898880340241, "compression_ratio": 1.7988826815642458, "no_speech_prob": 0.002115208189934492}, {"id": 402, "seek": 213260, "start": 2140.36, "end": 2143.64, "text": " So basically the story is that we are going to take a video.", "tokens": [50752, 407, 1936, 264, 1657, 307, 300, 321, 366, 516, 281, 747, 257, 960, 13, 50916], "temperature": 0.0, "avg_logprob": -0.07929898880340241, "compression_ratio": 1.7988826815642458, "no_speech_prob": 0.002115208189934492}, {"id": 403, "seek": 213260, "start": 2143.64, "end": 2150.2799999999997, "text": " We're going to make it a palindrome by going from t to t plus k and then minus to back to t.", "tokens": [50916, 492, 434, 516, 281, 652, 309, 257, 3984, 471, 11505, 538, 516, 490, 256, 281, 256, 1804, 350, 293, 550, 3175, 281, 646, 281, 256, 13, 51248], "temperature": 0.0, "avg_logprob": -0.07929898880340241, "compression_ratio": 1.7988826815642458, "no_speech_prob": 0.002115208189934492}, {"id": 404, "seek": 213260, "start": 2150.2799999999997, "end": 2153.3199999999997, "text": " We're going to make it into a graph.", "tokens": [51248, 492, 434, 516, 281, 652, 309, 666, 257, 4295, 13, 51400], "temperature": 0.0, "avg_logprob": -0.07929898880340241, "compression_ratio": 1.7988826815642458, "no_speech_prob": 0.002115208189934492}, {"id": 405, "seek": 213260, "start": 2153.3199999999997, "end": 2156.7599999999998, "text": " We're going to turn the video into a graph, okay?", "tokens": [51400, 492, 434, 516, 281, 1261, 264, 960, 666, 257, 4295, 11, 1392, 30, 51572], "temperature": 0.0, "avg_logprob": -0.07929898880340241, "compression_ratio": 1.7988826815642458, "no_speech_prob": 0.002115208189934492}, {"id": 406, "seek": 215676, "start": 2157.48, "end": 2166.44, "text": " And then we're going to walk along this graph until we get to the end, okay?", "tokens": [50400, 400, 550, 321, 434, 516, 281, 1792, 2051, 341, 4295, 1826, 321, 483, 281, 264, 917, 11, 1392, 30, 50848], "temperature": 0.0, "avg_logprob": -0.08054086960941913, "compression_ratio": 1.883435582822086, "no_speech_prob": 0.0017819193890318274}, {"id": 407, "seek": 215676, "start": 2166.44, "end": 2170.0400000000004, "text": " And we're going to do basically a random walk on this graph", "tokens": [50848, 400, 321, 434, 516, 281, 360, 1936, 257, 4974, 1792, 322, 341, 4295, 51028], "temperature": 0.0, "avg_logprob": -0.08054086960941913, "compression_ratio": 1.883435582822086, "no_speech_prob": 0.0017819193890318274}, {"id": 408, "seek": 215676, "start": 2170.84, "end": 2173.5600000000004, "text": " and then we're going to steer that random walk", "tokens": [51068, 293, 550, 321, 434, 516, 281, 30814, 300, 4974, 1792, 51204], "temperature": 0.0, "avg_logprob": -0.08054086960941913, "compression_ratio": 1.883435582822086, "no_speech_prob": 0.0017819193890318274}, {"id": 409, "seek": 215676, "start": 2174.2000000000003, "end": 2177.96, "text": " such that if you start from this blue point right here,", "tokens": [51236, 1270, 300, 498, 291, 722, 490, 341, 3344, 935, 558, 510, 11, 51424], "temperature": 0.0, "avg_logprob": -0.08054086960941913, "compression_ratio": 1.883435582822086, "no_speech_prob": 0.0017819193890318274}, {"id": 410, "seek": 215676, "start": 2178.6000000000004, "end": 2182.5200000000004, "text": " we want to steer it to get us to this green point right here, okay?", "tokens": [51456, 321, 528, 281, 30814, 309, 281, 483, 505, 281, 341, 3092, 935, 558, 510, 11, 1392, 30, 51652], "temperature": 0.0, "avg_logprob": -0.08054086960941913, "compression_ratio": 1.883435582822086, "no_speech_prob": 0.0017819193890318274}, {"id": 411, "seek": 218252, "start": 2183.4, "end": 2186.52, "text": " And this is going to be our only supervision.", "tokens": [50408, 400, 341, 307, 516, 281, 312, 527, 787, 32675, 13, 50564], "temperature": 0.0, "avg_logprob": -0.09421990210549873, "compression_ratio": 2.0407239819004523, "no_speech_prob": 0.0006876482511870563}, {"id": 412, "seek": 218252, "start": 2186.52, "end": 2189.88, "text": " The supervision is going to be at the last frame where we're going to say that the green,", "tokens": [50564, 440, 32675, 307, 516, 281, 312, 412, 264, 1036, 3920, 689, 321, 434, 516, 281, 584, 300, 264, 3092, 11, 50732], "temperature": 0.0, "avg_logprob": -0.09421990210549873, "compression_ratio": 2.0407239819004523, "no_speech_prob": 0.0006876482511870563}, {"id": 413, "seek": 218252, "start": 2190.52, "end": 2194.28, "text": " the positive is going to be anything that lands on the green dot", "tokens": [50764, 264, 3353, 307, 516, 281, 312, 1340, 300, 5949, 322, 264, 3092, 5893, 50952], "temperature": 0.0, "avg_logprob": -0.09421990210549873, "compression_ratio": 2.0407239819004523, "no_speech_prob": 0.0006876482511870563}, {"id": 414, "seek": 218252, "start": 2194.28, "end": 2200.12, "text": " and negative is going to be anything that lands anywhere else, anywhere on this red dot, okay?", "tokens": [50952, 293, 3671, 307, 516, 281, 312, 1340, 300, 5949, 4992, 1646, 11, 4992, 322, 341, 2182, 5893, 11, 1392, 30, 51244], "temperature": 0.0, "avg_logprob": -0.09421990210549873, "compression_ratio": 2.0407239819004523, "no_speech_prob": 0.0006876482511870563}, {"id": 415, "seek": 218252, "start": 2200.12, "end": 2203.0, "text": " And that's basically going to be the signal that we're going to use, okay?", "tokens": [51244, 400, 300, 311, 1936, 516, 281, 312, 264, 6358, 300, 321, 434, 516, 281, 764, 11, 1392, 30, 51388], "temperature": 0.0, "avg_logprob": -0.09421990210549873, "compression_ratio": 2.0407239819004523, "no_speech_prob": 0.0006876482511870563}, {"id": 416, "seek": 218252, "start": 2205.08, "end": 2211.64, "text": " So, and also notice that we don't have to have a single path through this graph.", "tokens": [51492, 407, 11, 293, 611, 3449, 300, 321, 500, 380, 362, 281, 362, 257, 2167, 3100, 807, 341, 4295, 13, 51820], "temperature": 0.0, "avg_logprob": -0.09421990210549873, "compression_ratio": 2.0407239819004523, "no_speech_prob": 0.0006876482511870563}, {"id": 417, "seek": 221164, "start": 2211.64, "end": 2219.48, "text": " We kind of naturally, we can incorporate probabilistic information", "tokens": [50364, 492, 733, 295, 8195, 11, 321, 393, 16091, 31959, 3142, 1589, 50756], "temperature": 0.0, "avg_logprob": -0.16268064390938236, "compression_ratio": 1.6861924686192469, "no_speech_prob": 0.00041035987669602036}, {"id": 418, "seek": 221164, "start": 2219.48, "end": 2222.68, "text": " by tracing many paths through this graph, okay?", "tokens": [50756, 538, 25262, 867, 14518, 807, 341, 4295, 11, 1392, 30, 50916], "temperature": 0.0, "avg_logprob": -0.16268064390938236, "compression_ratio": 1.6861924686192469, "no_speech_prob": 0.00041035987669602036}, {"id": 419, "seek": 221164, "start": 2224.04, "end": 2227.72, "text": " So, you know, how do you turn the video into a graph?", "tokens": [50984, 407, 11, 291, 458, 11, 577, 360, 291, 1261, 264, 960, 666, 257, 4295, 30, 51168], "temperature": 0.0, "avg_logprob": -0.16268064390938236, "compression_ratio": 1.6861924686192469, "no_speech_prob": 0.00041035987669602036}, {"id": 420, "seek": 221164, "start": 2227.72, "end": 2229.24, "text": " Well, it's kind of a standard thing.", "tokens": [51168, 1042, 11, 309, 311, 733, 295, 257, 3832, 551, 13, 51244], "temperature": 0.0, "avg_logprob": -0.16268064390938236, "compression_ratio": 1.6861924686192469, "no_speech_prob": 0.00041035987669602036}, {"id": 421, "seek": 221164, "start": 2229.24, "end": 2232.6, "text": " You know, create nodes and then, you know, you're basically,", "tokens": [51244, 509, 458, 11, 1884, 13891, 293, 550, 11, 291, 458, 11, 291, 434, 1936, 11, 51412], "temperature": 0.0, "avg_logprob": -0.16268064390938236, "compression_ratio": 1.6861924686192469, "no_speech_prob": 0.00041035987669602036}, {"id": 422, "seek": 221164, "start": 2232.6, "end": 2236.2799999999997, "text": " your nodes are some representation and some using some encoder, phi.", "tokens": [51412, 428, 13891, 366, 512, 10290, 293, 512, 1228, 512, 2058, 19866, 11, 13107, 13, 51596], "temperature": 0.0, "avg_logprob": -0.16268064390938236, "compression_ratio": 1.6861924686192469, "no_speech_prob": 0.00041035987669602036}, {"id": 423, "seek": 221164, "start": 2236.2799999999997, "end": 2239.24, "text": " And really, this phi is really the only thing that you're learning.", "tokens": [51596, 400, 534, 11, 341, 13107, 307, 534, 264, 787, 551, 300, 291, 434, 2539, 13, 51744], "temperature": 0.0, "avg_logprob": -0.16268064390938236, "compression_ratio": 1.6861924686192469, "no_speech_prob": 0.00041035987669602036}, {"id": 424, "seek": 223924, "start": 2239.24, "end": 2244.6, "text": " What you're learning is you're learning the representation of each patch", "tokens": [50364, 708, 291, 434, 2539, 307, 291, 434, 2539, 264, 10290, 295, 1184, 9972, 50632], "temperature": 0.0, "avg_logprob": -0.12101883790930923, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.0011152707738801837}, {"id": 425, "seek": 223924, "start": 2244.6, "end": 2245.72, "text": " in your feature space.", "tokens": [50632, 294, 428, 4111, 1901, 13, 50688], "temperature": 0.0, "avg_logprob": -0.12101883790930923, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.0011152707738801837}, {"id": 426, "seek": 223924, "start": 2245.72, "end": 2251.72, "text": " And you're basically trying to figure out how to arrange those features", "tokens": [50688, 400, 291, 434, 1936, 1382, 281, 2573, 484, 577, 281, 9424, 729, 4122, 50988], "temperature": 0.0, "avg_logprob": -0.12101883790930923, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.0011152707738801837}, {"id": 427, "seek": 223924, "start": 2252.3599999999997, "end": 2255.72, "text": " in your representation, who's going to be close, who's going to be far, okay?", "tokens": [51020, 294, 428, 10290, 11, 567, 311, 516, 281, 312, 1998, 11, 567, 311, 516, 281, 312, 1400, 11, 1392, 30, 51188], "temperature": 0.0, "avg_logprob": -0.12101883790930923, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.0011152707738801837}, {"id": 428, "seek": 223924, "start": 2256.2799999999997, "end": 2261.08, "text": " And so, now your video is going to be a graph.", "tokens": [51216, 400, 370, 11, 586, 428, 960, 307, 516, 281, 312, 257, 4295, 13, 51456], "temperature": 0.0, "avg_logprob": -0.12101883790930923, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.0011152707738801837}, {"id": 429, "seek": 223924, "start": 2261.08, "end": 2267.7999999999997, "text": " And then from frame T to frame T plus one, you're just going to have a transition matrix", "tokens": [51456, 400, 550, 490, 3920, 314, 281, 3920, 314, 1804, 472, 11, 291, 434, 445, 516, 281, 362, 257, 6034, 8141, 51792], "temperature": 0.0, "avg_logprob": -0.12101883790930923, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.0011152707738801837}, {"id": 430, "seek": 226780, "start": 2267.8, "end": 2273.7200000000003, "text": " that's just going to say, you know, where did all the points from T go in T plus one?", "tokens": [50364, 300, 311, 445, 516, 281, 584, 11, 291, 458, 11, 689, 630, 439, 264, 2793, 490, 314, 352, 294, 314, 1804, 472, 30, 50660], "temperature": 0.0, "avg_logprob": -0.13739707177145438, "compression_ratio": 1.7327935222672064, "no_speech_prob": 0.0005526660825125873}, {"id": 431, "seek": 226780, "start": 2273.7200000000003, "end": 2278.1200000000003, "text": " And then this is just basically like a dot product in the feature space.", "tokens": [50660, 400, 550, 341, 307, 445, 1936, 411, 257, 5893, 1674, 294, 264, 4111, 1901, 13, 50880], "temperature": 0.0, "avg_logprob": -0.13739707177145438, "compression_ratio": 1.7327935222672064, "no_speech_prob": 0.0005526660825125873}, {"id": 432, "seek": 226780, "start": 2278.1200000000003, "end": 2284.28, "text": " So, the closest things are going to be to get the higher dot product, okay?", "tokens": [50880, 407, 11, 264, 13699, 721, 366, 516, 281, 312, 281, 483, 264, 2946, 5893, 1674, 11, 1392, 30, 51188], "temperature": 0.0, "avg_logprob": -0.13739707177145438, "compression_ratio": 1.7327935222672064, "no_speech_prob": 0.0005526660825125873}, {"id": 433, "seek": 226780, "start": 2284.28, "end": 2286.6000000000004, "text": " And then how are we going to do it around the work?", "tokens": [51188, 400, 550, 577, 366, 321, 516, 281, 360, 309, 926, 264, 589, 30, 51304], "temperature": 0.0, "avg_logprob": -0.13739707177145438, "compression_ratio": 1.7327935222672064, "no_speech_prob": 0.0005526660825125873}, {"id": 434, "seek": 226780, "start": 2286.6000000000004, "end": 2291.2400000000002, "text": " Well, just going to compose all of these transition matrices A,", "tokens": [51304, 1042, 11, 445, 516, 281, 35925, 439, 295, 613, 6034, 32284, 316, 11, 51536], "temperature": 0.0, "avg_logprob": -0.13739707177145438, "compression_ratio": 1.7327935222672064, "no_speech_prob": 0.0005526660825125873}, {"id": 435, "seek": 226780, "start": 2291.2400000000002, "end": 2295.0, "text": " just like, you know, standard Markov chain, you know, you're just multiplying", "tokens": [51536, 445, 411, 11, 291, 458, 11, 3832, 3934, 5179, 5021, 11, 291, 458, 11, 291, 434, 445, 30955, 51724], "temperature": 0.0, "avg_logprob": -0.13739707177145438, "compression_ratio": 1.7327935222672064, "no_speech_prob": 0.0005526660825125873}, {"id": 436, "seek": 229500, "start": 2295.0, "end": 2302.28, "text": " all of those transition matrices and you get your full work on this graph, right?", "tokens": [50364, 439, 295, 729, 6034, 32284, 293, 291, 483, 428, 1577, 589, 322, 341, 4295, 11, 558, 30, 50728], "temperature": 0.0, "avg_logprob": -0.1093280381626553, "compression_ratio": 1.7837837837837838, "no_speech_prob": 0.0005525610176846385}, {"id": 437, "seek": 229500, "start": 2302.28, "end": 2308.52, "text": " So, now kind of the nice thing is that the task of learning this representation phi", "tokens": [50728, 407, 11, 586, 733, 295, 264, 1481, 551, 307, 300, 264, 5633, 295, 2539, 341, 10290, 13107, 51040], "temperature": 0.0, "avg_logprob": -0.1093280381626553, "compression_ratio": 1.7837837837837838, "no_speech_prob": 0.0005525610176846385}, {"id": 438, "seek": 229500, "start": 2308.52, "end": 2313.64, "text": " is essentially the same as fitting these transition probabilities, okay?", "tokens": [51040, 307, 4476, 264, 912, 382, 15669, 613, 6034, 33783, 11, 1392, 30, 51296], "temperature": 0.0, "avg_logprob": -0.1093280381626553, "compression_ratio": 1.7837837837837838, "no_speech_prob": 0.0005525610176846385}, {"id": 439, "seek": 229500, "start": 2313.64, "end": 2318.44, "text": " You find the right transition probabilities and it gives you your representation phi, okay?", "tokens": [51296, 509, 915, 264, 558, 6034, 33783, 293, 309, 2709, 291, 428, 10290, 13107, 11, 1392, 30, 51536], "temperature": 0.0, "avg_logprob": -0.1093280381626553, "compression_ratio": 1.7837837837837838, "no_speech_prob": 0.0005525610176846385}, {"id": 440, "seek": 231844, "start": 2319.4, "end": 2325.64, "text": " So, again, in kind of a, if we do have the target somewhere, if we do have the supervision,", "tokens": [50412, 407, 11, 797, 11, 294, 733, 295, 257, 11, 498, 321, 360, 362, 264, 3779, 4079, 11, 498, 321, 360, 362, 264, 32675, 11, 50724], "temperature": 0.0, "avg_logprob": -0.15499531305753267, "compression_ratio": 1.8475336322869955, "no_speech_prob": 0.0004044032539241016}, {"id": 441, "seek": 231844, "start": 2325.64, "end": 2329.64, "text": " then this is just a standard contrast of learning problem.", "tokens": [50724, 550, 341, 307, 445, 257, 3832, 8712, 295, 2539, 1154, 13, 50924], "temperature": 0.0, "avg_logprob": -0.15499531305753267, "compression_ratio": 1.8475336322869955, "no_speech_prob": 0.0004044032539241016}, {"id": 442, "seek": 231844, "start": 2329.64, "end": 2337.48, "text": " You basically, you want to find a representation where this query goes directly to the target.", "tokens": [50924, 509, 1936, 11, 291, 528, 281, 915, 257, 10290, 689, 341, 14581, 1709, 3838, 281, 264, 3779, 13, 51316], "temperature": 0.0, "avg_logprob": -0.15499531305753267, "compression_ratio": 1.8475336322869955, "no_speech_prob": 0.0004044032539241016}, {"id": 443, "seek": 231844, "start": 2337.48, "end": 2339.64, "text": " It doesn't go to the red ones, right?", "tokens": [51316, 467, 1177, 380, 352, 281, 264, 2182, 2306, 11, 558, 30, 51424], "temperature": 0.0, "avg_logprob": -0.15499531305753267, "compression_ratio": 1.8475336322869955, "no_speech_prob": 0.0004044032539241016}, {"id": 444, "seek": 231844, "start": 2339.64, "end": 2342.84, "text": " And this is basically just, this is your positive, this is your negative,", "tokens": [51424, 400, 341, 307, 1936, 445, 11, 341, 307, 428, 3353, 11, 341, 307, 428, 3671, 11, 51584], "temperature": 0.0, "avg_logprob": -0.15499531305753267, "compression_ratio": 1.8475336322869955, "no_speech_prob": 0.0004044032539241016}, {"id": 445, "seek": 231844, "start": 2342.84, "end": 2345.8, "text": " this is your standard kind of static learning problem.", "tokens": [51584, 341, 307, 428, 3832, 733, 295, 13437, 2539, 1154, 13, 51732], "temperature": 0.0, "avg_logprob": -0.15499531305753267, "compression_ratio": 1.8475336322869955, "no_speech_prob": 0.0004044032539241016}, {"id": 446, "seek": 234580, "start": 2345.8, "end": 2351.7200000000003, "text": " If you have multiple frames in between, then in a sense, you have some latent views", "tokens": [50364, 759, 291, 362, 3866, 12083, 294, 1296, 11, 550, 294, 257, 2020, 11, 291, 362, 512, 48994, 6809, 50660], "temperature": 0.0, "avg_logprob": -0.14760330200195312, "compression_ratio": 1.8413461538461537, "no_speech_prob": 0.0007671317434869707}, {"id": 447, "seek": 234580, "start": 2351.7200000000003, "end": 2353.88, "text": " that you can also use, right?", "tokens": [50660, 300, 291, 393, 611, 764, 11, 558, 30, 50768], "temperature": 0.0, "avg_logprob": -0.14760330200195312, "compression_ratio": 1.8413461538461537, "no_speech_prob": 0.0007671317434869707}, {"id": 448, "seek": 234580, "start": 2353.88, "end": 2360.28, "text": " So, now we have, these are all the positives and these are the negatives if you,", "tokens": [50768, 407, 11, 586, 321, 362, 11, 613, 366, 439, 264, 35127, 293, 613, 366, 264, 40019, 498, 291, 11, 51088], "temperature": 0.0, "avg_logprob": -0.14760330200195312, "compression_ratio": 1.8413461538461537, "no_speech_prob": 0.0007671317434869707}, {"id": 449, "seek": 234580, "start": 2360.28, "end": 2361.88, "text": " if it's an obvious path.", "tokens": [51088, 498, 309, 311, 364, 6322, 3100, 13, 51168], "temperature": 0.0, "avg_logprob": -0.14760330200195312, "compression_ratio": 1.8413461538461537, "no_speech_prob": 0.0007671317434869707}, {"id": 450, "seek": 234580, "start": 2361.88, "end": 2366.84, "text": " But if you have multiple, multiple hyperability paths and these will be late, like,", "tokens": [51168, 583, 498, 291, 362, 3866, 11, 3866, 9848, 2310, 14518, 293, 613, 486, 312, 3469, 11, 411, 11, 51416], "temperature": 0.0, "avg_logprob": -0.14760330200195312, "compression_ratio": 1.8413461538461537, "no_speech_prob": 0.0007671317434869707}, {"id": 451, "seek": 234580, "start": 2368.52, "end": 2372.6800000000003, "text": " awaited positives and these will be weighted negatives and you can still do it.", "tokens": [51500, 19670, 292, 35127, 293, 613, 486, 312, 32807, 40019, 293, 291, 393, 920, 360, 309, 13, 51708], "temperature": 0.0, "avg_logprob": -0.14760330200195312, "compression_ratio": 1.8413461538461537, "no_speech_prob": 0.0007671317434869707}, {"id": 452, "seek": 237268, "start": 2372.68, "end": 2378.04, "text": " And so, again, from a single point of supervision, you get all of this data-augmented information,", "tokens": [50364, 400, 370, 11, 797, 11, 490, 257, 2167, 935, 295, 32675, 11, 291, 483, 439, 295, 341, 1412, 12, 20056, 14684, 1589, 11, 50632], "temperature": 0.0, "avg_logprob": -0.14692325794950445, "compression_ratio": 1.721698113207547, "no_speech_prob": 0.0002823113463819027}, {"id": 453, "seek": 237268, "start": 2378.04, "end": 2378.2799999999997, "text": " okay?", "tokens": [50632, 1392, 30, 50644], "temperature": 0.0, "avg_logprob": -0.14692325794950445, "compression_ratio": 1.721698113207547, "no_speech_prob": 0.0002823113463819027}, {"id": 454, "seek": 237268, "start": 2380.12, "end": 2387.72, "text": " And of course, what we can do then is we can do the palindrome trick and now we get all of these", "tokens": [50736, 400, 295, 1164, 11, 437, 321, 393, 360, 550, 307, 321, 393, 360, 264, 3984, 471, 11505, 4282, 293, 586, 321, 483, 439, 295, 613, 51116], "temperature": 0.0, "avg_logprob": -0.14692325794950445, "compression_ratio": 1.721698113207547, "no_speech_prob": 0.0002823113463819027}, {"id": 455, "seek": 237268, "start": 2387.72, "end": 2394.6, "text": " latent data-augmented positives without even providing any supervision, okay?", "tokens": [51116, 48994, 1412, 12, 20056, 14684, 35127, 1553, 754, 6530, 604, 32675, 11, 1392, 30, 51460], "temperature": 0.0, "avg_logprob": -0.14692325794950445, "compression_ratio": 1.721698113207547, "no_speech_prob": 0.0002823113463819027}, {"id": 456, "seek": 237268, "start": 2394.6, "end": 2399.64, "text": " Because this is basically by construction, the target is the same as the quick, okay?", "tokens": [51460, 1436, 341, 307, 1936, 538, 6435, 11, 264, 3779, 307, 264, 912, 382, 264, 1702, 11, 1392, 30, 51712], "temperature": 0.0, "avg_logprob": -0.14692325794950445, "compression_ratio": 1.721698113207547, "no_speech_prob": 0.0002823113463819027}, {"id": 457, "seek": 239964, "start": 2400.52, "end": 2406.2799999999997, "text": " And so, where we can just set this up at training time and you can see that it's,", "tokens": [50408, 400, 370, 11, 689, 321, 393, 445, 992, 341, 493, 412, 3097, 565, 293, 291, 393, 536, 300, 309, 311, 11, 50696], "temperature": 0.0, "avg_logprob": -0.11899002620152065, "compression_ratio": 1.7394957983193278, "no_speech_prob": 0.00035129761090502143}, {"id": 458, "seek": 239964, "start": 2407.08, "end": 2412.7599999999998, "text": " you know, if you pick a point in the query image, in the first image, you can see that", "tokens": [50736, 291, 458, 11, 498, 291, 1888, 257, 935, 294, 264, 14581, 3256, 11, 294, 264, 700, 3256, 11, 291, 393, 536, 300, 51020], "temperature": 0.0, "avg_logprob": -0.11899002620152065, "compression_ratio": 1.7394957983193278, "no_speech_prob": 0.00035129761090502143}, {"id": 459, "seek": 239964, "start": 2412.7599999999998, "end": 2417.08, "text": " over time, it kind of gives you a little probability distribution of where that image", "tokens": [51020, 670, 565, 11, 309, 733, 295, 2709, 291, 257, 707, 8482, 7316, 295, 689, 300, 3256, 51236], "temperature": 0.0, "avg_logprob": -0.11899002620152065, "compression_ratio": 1.7394957983193278, "no_speech_prob": 0.00035129761090502143}, {"id": 460, "seek": 239964, "start": 2417.08, "end": 2423.56, "text": " might have gone and you can say, well, maybe we can even do this by trying to get grouping", "tokens": [51236, 1062, 362, 2780, 293, 291, 393, 584, 11, 731, 11, 1310, 321, 393, 754, 360, 341, 538, 1382, 281, 483, 40149, 51560], "temperature": 0.0, "avg_logprob": -0.11899002620152065, "compression_ratio": 1.7394957983193278, "no_speech_prob": 0.00035129761090502143}, {"id": 461, "seek": 239964, "start": 2423.56, "end": 2428.2799999999997, "text": " happening and find out a group which corresponds to a single object.", "tokens": [51560, 2737, 293, 915, 484, 257, 1594, 597, 23249, 281, 257, 2167, 2657, 13, 51796], "temperature": 0.0, "avg_logprob": -0.11899002620152065, "compression_ratio": 1.7394957983193278, "no_speech_prob": 0.00035129761090502143}, {"id": 462, "seek": 242828, "start": 2428.84, "end": 2433.6400000000003, "text": " And to do that, we have a little extra thing that we can do which is we can do a dropout.", "tokens": [50392, 400, 281, 360, 300, 11, 321, 362, 257, 707, 2857, 551, 300, 321, 393, 360, 597, 307, 321, 393, 360, 257, 3270, 346, 13, 50632], "temperature": 0.0, "avg_logprob": -0.08626309660978096, "compression_ratio": 1.7376237623762376, "no_speech_prob": 0.0010480496566742659}, {"id": 463, "seek": 242828, "start": 2433.6400000000003, "end": 2441.88, "text": " We can cut some of the engines away and force the correspondences to go through nearby paths", "tokens": [50632, 492, 393, 1723, 512, 295, 264, 12982, 1314, 293, 3464, 264, 6805, 2667, 281, 352, 807, 11184, 14518, 51044], "temperature": 0.0, "avg_logprob": -0.08626309660978096, "compression_ratio": 1.7376237623762376, "no_speech_prob": 0.0010480496566742659}, {"id": 464, "seek": 242828, "start": 2441.88, "end": 2446.1200000000003, "text": " and that basically allows us to get a little bit more of this kind of grouping", "tokens": [51044, 293, 300, 1936, 4045, 505, 281, 483, 257, 707, 857, 544, 295, 341, 733, 295, 40149, 51256], "temperature": 0.0, "avg_logprob": -0.08626309660978096, "compression_ratio": 1.7376237623762376, "no_speech_prob": 0.0010480496566742659}, {"id": 465, "seek": 242828, "start": 2447.32, "end": 2451.88, "text": " happening where you basically kind of, you go through the paths that are also on the same", "tokens": [51316, 2737, 689, 291, 1936, 733, 295, 11, 291, 352, 807, 264, 14518, 300, 366, 611, 322, 264, 912, 51544], "temperature": 0.0, "avg_logprob": -0.08626309660978096, "compression_ratio": 1.7376237623762376, "no_speech_prob": 0.0010480496566742659}, {"id": 466, "seek": 245188, "start": 2451.88, "end": 2459.4, "text": " object, okay? And, you know, we basically violated it at runtime by essentially nearest", "tokens": [50364, 2657, 11, 1392, 30, 400, 11, 291, 458, 11, 321, 1936, 33239, 309, 412, 34474, 538, 4476, 23831, 50740], "temperature": 0.0, "avg_logprob": -0.2038514180616899, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.0009544261847622693}, {"id": 467, "seek": 245188, "start": 2459.4, "end": 2466.04, "text": " neighbor in the phi space and here are some examples. This is the kind of the state-of-the-art", "tokens": [50740, 5987, 294, 264, 13107, 1901, 293, 510, 366, 512, 5110, 13, 639, 307, 264, 733, 295, 264, 1785, 12, 2670, 12, 3322, 12, 446, 51072], "temperature": 0.0, "avg_logprob": -0.2038514180616899, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.0009544261847622693}, {"id": 468, "seek": 245188, "start": 2467.2400000000002, "end": 2472.52, "text": " label propagation results and this are the results of our methods and you can see that it's", "tokens": [51132, 7645, 38377, 3542, 293, 341, 366, 264, 3542, 295, 527, 7150, 293, 291, 393, 536, 300, 309, 311, 51396], "temperature": 0.0, "avg_logprob": -0.2038514180616899, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.0009544261847622693}, {"id": 469, "seek": 245188, "start": 2472.52, "end": 2479.08, "text": " it's basically behaving much better in terms of occlusion handling and just seems to do quite", "tokens": [51396, 309, 311, 1936, 35263, 709, 1101, 294, 2115, 295, 2678, 6485, 13175, 293, 445, 2544, 281, 360, 1596, 51724], "temperature": 0.0, "avg_logprob": -0.2038514180616899, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.0009544261847622693}, {"id": 470, "seek": 247908, "start": 2479.08, "end": 2484.92, "text": " a bit better. Here is again state-of-the-art self-supervised method and this is ours, right?", "tokens": [50364, 257, 857, 1101, 13, 1692, 307, 797, 1785, 12, 2670, 12, 3322, 12, 446, 2698, 12, 48172, 24420, 3170, 293, 341, 307, 11896, 11, 558, 30, 50656], "temperature": 0.0, "avg_logprob": -0.16846431385387073, "compression_ratio": 1.639269406392694, "no_speech_prob": 0.0008037600200623274}, {"id": 471, "seek": 247908, "start": 2486.2, "end": 2491.48, "text": " Even against supervised methods actually does pretty well even though it doesn't get any", "tokens": [50720, 2754, 1970, 46533, 7150, 767, 775, 1238, 731, 754, 1673, 309, 1177, 380, 483, 604, 50984], "temperature": 0.0, "avg_logprob": -0.16846431385387073, "compression_ratio": 1.639269406392694, "no_speech_prob": 0.0008037600200623274}, {"id": 472, "seek": 247908, "start": 2491.48, "end": 2500.2799999999997, "text": " sort of supervision. So here is kind of an example of how we do compared to some of the", "tokens": [50984, 1333, 295, 32675, 13, 407, 510, 307, 733, 295, 364, 1365, 295, 577, 321, 360, 5347, 281, 512, 295, 264, 51424], "temperature": 0.0, "avg_logprob": -0.16846431385387073, "compression_ratio": 1.639269406392694, "no_speech_prob": 0.0008037600200623274}, {"id": 473, "seek": 247908, "start": 2500.2799999999997, "end": 2505.16, "text": " self-supervised comparators and interestingly even for methods that are trained on image,", "tokens": [51424, 2698, 12, 48172, 24420, 6311, 3391, 293, 25873, 754, 337, 7150, 300, 366, 8895, 322, 3256, 11, 51668], "temperature": 0.0, "avg_logprob": -0.16846431385387073, "compression_ratio": 1.639269406392694, "no_speech_prob": 0.0008037600200623274}, {"id": 474, "seek": 250516, "start": 2505.3199999999997, "end": 2511.7999999999997, "text": " using image net representation we are actually doing better than that, okay? And here are some", "tokens": [50372, 1228, 3256, 2533, 10290, 321, 366, 767, 884, 1101, 813, 300, 11, 1392, 30, 400, 510, 366, 512, 50696], "temperature": 0.0, "avg_logprob": -0.18757721734425378, "compression_ratio": 1.5965909090909092, "no_speech_prob": 0.00023770576808601618}, {"id": 475, "seek": 250516, "start": 2511.7999999999997, "end": 2517.7999999999997, "text": " examples of kind of propagating various things like skeletons or labels or things like that, okay?", "tokens": [50696, 5110, 295, 733, 295, 12425, 990, 3683, 721, 411, 45538, 420, 16949, 420, 721, 411, 300, 11, 1392, 30, 50996], "temperature": 0.0, "avg_logprob": -0.18757721734425378, "compression_ratio": 1.5965909090909092, "no_speech_prob": 0.00023770576808601618}, {"id": 476, "seek": 250516, "start": 2520.68, "end": 2531.08, "text": " So this is one way to use this contrastive learning as without data augmentation but of", "tokens": [51140, 407, 341, 307, 472, 636, 281, 764, 341, 8712, 488, 2539, 382, 1553, 1412, 14501, 19631, 457, 295, 51660], "temperature": 0.0, "avg_logprob": -0.18757721734425378, "compression_ratio": 1.5965909090909092, "no_speech_prob": 0.00023770576808601618}, {"id": 477, "seek": 253108, "start": 2531.08, "end": 2536.52, "text": " course in my lab we also like to make pretty pictures and so I'll briefly show you another", "tokens": [50364, 1164, 294, 452, 2715, 321, 611, 411, 281, 652, 1238, 5242, 293, 370, 286, 603, 10515, 855, 291, 1071, 50636], "temperature": 0.0, "avg_logprob": -0.1203243911907237, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.0006164205260574818}, {"id": 478, "seek": 253108, "start": 2537.16, "end": 2546.12, "text": " way of using the same kind of an idea of kind of creating your own latent views for an image-to-image", "tokens": [50668, 636, 295, 1228, 264, 912, 733, 295, 364, 1558, 295, 733, 295, 4084, 428, 1065, 48994, 6809, 337, 364, 3256, 12, 1353, 12, 26624, 51116], "temperature": 0.0, "avg_logprob": -0.1203243911907237, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.0006164205260574818}, {"id": 479, "seek": 253108, "start": 2546.12, "end": 2554.68, "text": " translation setup, okay? And here the idea is of course image unfair translation. The classic", "tokens": [51116, 12853, 8657, 11, 1392, 30, 400, 510, 264, 1558, 307, 295, 1164, 3256, 17019, 12853, 13, 440, 7230, 51544], "temperature": 0.0, "avg_logprob": -0.1203243911907237, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.0006164205260574818}, {"id": 480, "seek": 253108, "start": 2554.68, "end": 2559.3199999999997, "text": " thing that we've been doing for a while we want to translate horses into zebras but we don't have", "tokens": [51544, 551, 300, 321, 600, 668, 884, 337, 257, 1339, 321, 528, 281, 13799, 13112, 666, 5277, 38182, 457, 321, 500, 380, 362, 51776], "temperature": 0.0, "avg_logprob": -0.1203243911907237, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.0006164205260574818}, {"id": 481, "seek": 255932, "start": 2559.32, "end": 2564.6800000000003, "text": " a correspondence between horses and zebras, okay? So we want to go from here to here but we don't", "tokens": [50364, 257, 38135, 1296, 13112, 293, 5277, 38182, 11, 1392, 30, 407, 321, 528, 281, 352, 490, 510, 281, 510, 457, 321, 500, 380, 50632], "temperature": 0.0, "avg_logprob": -0.07060935497283935, "compression_ratio": 1.7025862068965518, "no_speech_prob": 0.0014771927380934358}, {"id": 482, "seek": 255932, "start": 2564.6800000000003, "end": 2574.2000000000003, "text": " have a correspondence, okay? And of course the one powerful signal here is we can use a GAN loss", "tokens": [50632, 362, 257, 38135, 11, 1392, 30, 400, 295, 1164, 264, 472, 4005, 6358, 510, 307, 321, 393, 764, 257, 460, 1770, 4470, 51108], "temperature": 0.0, "avg_logprob": -0.07060935497283935, "compression_ratio": 1.7025862068965518, "no_speech_prob": 0.0014771927380934358}, {"id": 483, "seek": 255932, "start": 2574.2000000000003, "end": 2581.6400000000003, "text": " which basically says make this thing into a zebra by basically forcing it to look like other zebras", "tokens": [51108, 597, 1936, 1619, 652, 341, 551, 666, 257, 47060, 538, 1936, 19030, 309, 281, 574, 411, 661, 5277, 38182, 51480], "temperature": 0.0, "avg_logprob": -0.07060935497283935, "compression_ratio": 1.7025862068965518, "no_speech_prob": 0.0014771927380934358}, {"id": 484, "seek": 255932, "start": 2581.6400000000003, "end": 2587.0800000000004, "text": " that I have seen, okay? Using a GAN loss but that GAN loss is not enough because it can make it look", "tokens": [51480, 300, 286, 362, 1612, 11, 1392, 30, 11142, 257, 460, 1770, 4470, 457, 300, 460, 1770, 4470, 307, 406, 1547, 570, 309, 393, 652, 309, 574, 51752], "temperature": 0.0, "avg_logprob": -0.07060935497283935, "compression_ratio": 1.7025862068965518, "no_speech_prob": 0.0014771927380934358}, {"id": 485, "seek": 258708, "start": 2587.16, "end": 2593.56, "text": " like a zebra many ways, right? But we wanted to kind of be in correspondence and so this is where", "tokens": [50368, 411, 257, 47060, 867, 2098, 11, 558, 30, 583, 321, 1415, 281, 733, 295, 312, 294, 38135, 293, 370, 341, 307, 689, 50688], "temperature": 0.0, "avg_logprob": -0.09756724039713542, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.0027566966600716114}, {"id": 486, "seek": 258708, "start": 2593.56, "end": 2600.44, "text": " we also want to have another constraint and in the past in works like cycle GAN we use the cycle", "tokens": [50688, 321, 611, 528, 281, 362, 1071, 25534, 293, 294, 264, 1791, 294, 1985, 411, 6586, 460, 1770, 321, 764, 264, 6586, 51032], "temperature": 0.0, "avg_logprob": -0.09756724039713542, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.0027566966600716114}, {"id": 487, "seek": 258708, "start": 2600.44, "end": 2605.64, "text": " consistency constraint which says okay make it a zebra but also make it so that when you translate", "tokens": [51032, 14416, 25534, 597, 1619, 1392, 652, 309, 257, 47060, 457, 611, 652, 309, 370, 300, 562, 291, 13799, 51292], "temperature": 0.0, "avg_logprob": -0.09756724039713542, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.0027566966600716114}, {"id": 488, "seek": 258708, "start": 2605.64, "end": 2612.44, "text": " it back you'll get back to the original horse and that kind of forces this to be the right answer,", "tokens": [51292, 309, 646, 291, 603, 483, 646, 281, 264, 3380, 6832, 293, 300, 733, 295, 5874, 341, 281, 312, 264, 558, 1867, 11, 51632], "temperature": 0.0, "avg_logprob": -0.09756724039713542, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.0027566966600716114}, {"id": 489, "seek": 261244, "start": 2612.44, "end": 2619.16, "text": " not these, okay? But there is a problem with this cycle consistency constraint because the problem", "tokens": [50364, 406, 613, 11, 1392, 30, 583, 456, 307, 257, 1154, 365, 341, 6586, 14416, 25534, 570, 264, 1154, 50700], "temperature": 0.0, "avg_logprob": -0.09146924538187462, "compression_ratio": 1.8598130841121496, "no_speech_prob": 0.0013453311985358596}, {"id": 490, "seek": 261244, "start": 2619.16, "end": 2624.52, "text": " is that it forces it to be a bijection and forces it to be one-to-one because yes it's not going to,", "tokens": [50700, 307, 300, 309, 5874, 309, 281, 312, 257, 3228, 1020, 313, 293, 5874, 309, 281, 312, 472, 12, 1353, 12, 546, 570, 2086, 309, 311, 406, 516, 281, 11, 50968], "temperature": 0.0, "avg_logprob": -0.09146924538187462, "compression_ratio": 1.8598130841121496, "no_speech_prob": 0.0013453311985358596}, {"id": 491, "seek": 261244, "start": 2625.8, "end": 2633.64, "text": " it's not going to go back to here but it's also going to constrain us to have to go back to this", "tokens": [51032, 309, 311, 406, 516, 281, 352, 646, 281, 510, 457, 309, 311, 611, 516, 281, 1817, 7146, 505, 281, 362, 281, 352, 646, 281, 341, 51424], "temperature": 0.0, "avg_logprob": -0.09146924538187462, "compression_ratio": 1.8598130841121496, "no_speech_prob": 0.0013453311985358596}, {"id": 492, "seek": 261244, "start": 2633.64, "end": 2641.16, "text": " particular horse whereas these other horses might have been just good enough, right? So this is where", "tokens": [51424, 1729, 6832, 9735, 613, 661, 13112, 1062, 362, 668, 445, 665, 1547, 11, 558, 30, 407, 341, 307, 689, 51800], "temperature": 0.0, "avg_logprob": -0.09146924538187462, "compression_ratio": 1.8598130841121496, "no_speech_prob": 0.0013453311985358596}, {"id": 493, "seek": 264116, "start": 2641.16, "end": 2648.6, "text": " kind of a bijection is not always desirable because sometimes these cycles are not a bijection.", "tokens": [50364, 733, 295, 257, 3228, 1020, 313, 307, 406, 1009, 30533, 570, 2171, 613, 17796, 366, 406, 257, 3228, 1020, 313, 13, 50736], "temperature": 0.0, "avg_logprob": -0.11527985164097378, "compression_ratio": 1.5080213903743316, "no_speech_prob": 0.0006164805963635445}, {"id": 494, "seek": 264116, "start": 2648.6, "end": 2657.24, "text": " So how could we kind of address this problem? And here is the approach that we came up with", "tokens": [50736, 407, 577, 727, 321, 733, 295, 2985, 341, 1154, 30, 400, 510, 307, 264, 3109, 300, 321, 1361, 493, 365, 51168], "temperature": 0.0, "avg_logprob": -0.11527985164097378, "compression_ratio": 1.5080213903743316, "no_speech_prob": 0.0006164805963635445}, {"id": 495, "seek": 264116, "start": 2657.24, "end": 2666.04, "text": " which is we are going to have an image-to-image translation framework. We're starting with our", "tokens": [51168, 597, 307, 321, 366, 516, 281, 362, 364, 3256, 12, 1353, 12, 26624, 12853, 8388, 13, 492, 434, 2891, 365, 527, 51608], "temperature": 0.0, "avg_logprob": -0.11527985164097378, "compression_ratio": 1.5080213903743316, "no_speech_prob": 0.0006164805963635445}, {"id": 496, "seek": 266604, "start": 2666.52, "end": 2671.56, "text": " with our horse. We want to get a zebra so we have a GAN loss that says okay make this a zebra,", "tokens": [50388, 365, 527, 6832, 13, 492, 528, 281, 483, 257, 47060, 370, 321, 362, 257, 460, 1770, 4470, 300, 1619, 1392, 652, 341, 257, 47060, 11, 50640], "temperature": 0.0, "avg_logprob": -0.10860025882720947, "compression_ratio": 1.7788461538461537, "no_speech_prob": 0.0023958373349159956}, {"id": 497, "seek": 266604, "start": 2671.56, "end": 2678.36, "text": " okay? And then what we're going to do in addition is we want to make this zebra to be", "tokens": [50640, 1392, 30, 400, 550, 437, 321, 434, 516, 281, 360, 294, 4500, 307, 321, 528, 281, 652, 341, 47060, 281, 312, 50980], "temperature": 0.0, "avg_logprob": -0.10860025882720947, "compression_ratio": 1.7788461538461537, "no_speech_prob": 0.0023958373349159956}, {"id": 498, "seek": 266604, "start": 2679.24, "end": 2686.44, "text": " similar in structure to this horse but not in texture and what we're going to do way to do this", "tokens": [51024, 2531, 294, 3877, 281, 341, 6832, 457, 406, 294, 8091, 293, 437, 321, 434, 516, 281, 360, 636, 281, 360, 341, 51384], "temperature": 0.0, "avg_logprob": -0.10860025882720947, "compression_ratio": 1.7788461538461537, "no_speech_prob": 0.0023958373349159956}, {"id": 499, "seek": 266604, "start": 2686.44, "end": 2694.52, "text": " is we're going to enforce the structures to be the same by taking pairs of patches across the", "tokens": [51384, 307, 321, 434, 516, 281, 24825, 264, 9227, 281, 312, 264, 912, 538, 1940, 15494, 295, 26531, 2108, 264, 51788], "temperature": 0.0, "avg_logprob": -0.10860025882720947, "compression_ratio": 1.7788461538461537, "no_speech_prob": 0.0023958373349159956}, {"id": 500, "seek": 269452, "start": 2694.52, "end": 2702.6, "text": " input and the output and say that these two patches need to be close to each other in features play", "tokens": [50364, 4846, 293, 264, 5598, 293, 584, 300, 613, 732, 26531, 643, 281, 312, 1998, 281, 1184, 661, 294, 4122, 862, 50768], "temperature": 0.0, "avg_logprob": -0.0864696353673935, "compression_ratio": 1.6424581005586592, "no_speech_prob": 0.0006984315114095807}, {"id": 501, "seek": 269452, "start": 2702.6, "end": 2712.84, "text": " the space and farther away than other patches from the horse image, okay? So you can see that again", "tokens": [50768, 264, 1901, 293, 20344, 1314, 813, 661, 26531, 490, 264, 6832, 3256, 11, 1392, 30, 407, 291, 393, 536, 300, 797, 51280], "temperature": 0.0, "avg_logprob": -0.0864696353673935, "compression_ratio": 1.6424581005586592, "no_speech_prob": 0.0006984315114095807}, {"id": 502, "seek": 269452, "start": 2712.84, "end": 2719.16, "text": " we are getting this whole similarity learning story here where we are basically bringing these", "tokens": [51280, 321, 366, 1242, 341, 1379, 32194, 2539, 1657, 510, 689, 321, 366, 1936, 5062, 613, 51596], "temperature": 0.0, "avg_logprob": -0.0864696353673935, "compression_ratio": 1.6424581005586592, "no_speech_prob": 0.0006984315114095807}, {"id": 503, "seek": 271916, "start": 2719.16, "end": 2728.6, "text": " two things to be closer and farther from the other patches of horse and again just unlike other", "tokens": [50364, 732, 721, 281, 312, 4966, 293, 20344, 490, 264, 661, 26531, 295, 6832, 293, 797, 445, 8343, 661, 50836], "temperature": 0.0, "avg_logprob": -0.15008322919001343, "compression_ratio": 1.7117647058823529, "no_speech_prob": 0.0015481340233236551}, {"id": 504, "seek": 271916, "start": 2728.6, "end": 2735.64, "text": " methods where the positives are somehow automatic created by data augmentation here the the the", "tokens": [50836, 7150, 689, 264, 35127, 366, 6063, 12509, 2942, 538, 1412, 14501, 19631, 510, 264, 264, 264, 51188], "temperature": 0.0, "avg_logprob": -0.15008322919001343, "compression_ratio": 1.7117647058823529, "no_speech_prob": 0.0015481340233236551}, {"id": 505, "seek": 271916, "start": 2735.64, "end": 2743.72, "text": " positives are basically our input and our output so the output becomes our data augmentation, okay?", "tokens": [51188, 35127, 366, 1936, 527, 4846, 293, 527, 5598, 370, 264, 5598, 3643, 527, 1412, 14501, 19631, 11, 1392, 30, 51592], "temperature": 0.0, "avg_logprob": -0.15008322919001343, "compression_ratio": 1.7117647058823529, "no_speech_prob": 0.0015481340233236551}, {"id": 506, "seek": 274372, "start": 2744.2, "end": 2751.24, "text": " And now we are back into our contrastive learning land we just basically formulate this and we", "tokens": [50388, 400, 586, 321, 366, 646, 666, 527, 8712, 488, 2539, 2117, 321, 445, 1936, 47881, 341, 293, 321, 50740], "temperature": 0.0, "avg_logprob": -0.13426013325535974, "compression_ratio": 1.7417840375586855, "no_speech_prob": 0.0007791632669977844}, {"id": 507, "seek": 274372, "start": 2751.24, "end": 2756.52, "text": " basically say learn a representation such that these two guys are close so basically it kind", "tokens": [50740, 1936, 584, 1466, 257, 10290, 1270, 300, 613, 732, 1074, 366, 1998, 370, 1936, 309, 733, 51004], "temperature": 0.0, "avg_logprob": -0.13426013325535974, "compression_ratio": 1.7417840375586855, "no_speech_prob": 0.0007791632669977844}, {"id": 508, "seek": 274372, "start": 2756.52, "end": 2762.8399999999997, "text": " of ignores the texture and focuses on the structure and these things are fine, okay? And", "tokens": [51004, 295, 5335, 2706, 264, 8091, 293, 16109, 322, 264, 3877, 293, 613, 721, 366, 2489, 11, 1392, 30, 400, 51320], "temperature": 0.0, "avg_logprob": -0.13426013325535974, "compression_ratio": 1.7417840375586855, "no_speech_prob": 0.0007791632669977844}, {"id": 509, "seek": 274372, "start": 2762.8399999999997, "end": 2769.48, "text": " and and of course what we do this we don't do this on just on the pixels we do it at different", "tokens": [51320, 293, 293, 295, 1164, 437, 321, 360, 341, 321, 500, 380, 360, 341, 322, 445, 322, 264, 18668, 321, 360, 309, 412, 819, 51652], "temperature": 0.0, "avg_logprob": -0.13426013325535974, "compression_ratio": 1.7417840375586855, "no_speech_prob": 0.0007791632669977844}, {"id": 510, "seek": 276948, "start": 2770.12, "end": 2777.56, "text": " levels of of representation at at basically different menu multi-scale patch representation", "tokens": [50396, 4358, 295, 295, 10290, 412, 412, 1936, 819, 6510, 4825, 12, 20033, 9972, 10290, 50768], "temperature": 0.0, "avg_logprob": -0.171913328624907, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0010474402224645019}, {"id": 511, "seek": 276948, "start": 2777.56, "end": 2784.84, "text": " and we do this contrastive learning basically everywhere here in our decoder, okay? And of", "tokens": [50768, 293, 321, 360, 341, 8712, 488, 2539, 1936, 5315, 510, 294, 527, 979, 19866, 11, 1392, 30, 400, 295, 51132], "temperature": 0.0, "avg_logprob": -0.171913328624907, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0010474402224645019}, {"id": 512, "seek": 276948, "start": 2784.84, "end": 2794.28, "text": " course we also have our gap losses as usual, okay? One kind of interesting cute note for for those who", "tokens": [51132, 1164, 321, 611, 362, 527, 7417, 15352, 382, 7713, 11, 1392, 30, 1485, 733, 295, 1880, 4052, 3637, 337, 337, 729, 567, 51604], "temperature": 0.0, "avg_logprob": -0.171913328624907, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0010474402224645019}, {"id": 513, "seek": 279428, "start": 2795.0, "end": 2799.8, "text": " who are in this might appreciate this well we thought okay you know the positives that's", "tokens": [50400, 567, 366, 294, 341, 1062, 4449, 341, 731, 321, 1194, 1392, 291, 458, 264, 35127, 300, 311, 50640], "temperature": 0.0, "avg_logprob": -0.10387724201853682, "compression_ratio": 1.8693467336683418, "no_speech_prob": 0.004904242232441902}, {"id": 514, "seek": 279428, "start": 2799.8, "end": 2804.6800000000003, "text": " everything is clear with negatives we just take all the patches from the same image and then we", "tokens": [50640, 1203, 307, 1850, 365, 40019, 321, 445, 747, 439, 264, 26531, 490, 264, 912, 3256, 293, 550, 321, 50884], "temperature": 0.0, "avg_logprob": -0.10387724201853682, "compression_ratio": 1.8693467336683418, "no_speech_prob": 0.004904242232441902}, {"id": 515, "seek": 279428, "start": 2804.6800000000003, "end": 2810.52, "text": " thought you know maybe it will be better if we take the negatives to be not just patches from", "tokens": [50884, 1194, 291, 458, 1310, 309, 486, 312, 1101, 498, 321, 747, 264, 40019, 281, 312, 406, 445, 26531, 490, 51176], "temperature": 0.0, "avg_logprob": -0.10387724201853682, "compression_ratio": 1.8693467336683418, "no_speech_prob": 0.004904242232441902}, {"id": 516, "seek": 279428, "start": 2810.52, "end": 2816.28, "text": " the same image but also just add other patches from other images other negatives, right? Even", "tokens": [51176, 264, 912, 3256, 457, 611, 445, 909, 661, 26531, 490, 661, 5267, 661, 40019, 11, 558, 30, 2754, 51464], "temperature": 0.0, "avg_logprob": -0.10387724201853682, "compression_ratio": 1.8693467336683418, "no_speech_prob": 0.004904242232441902}, {"id": 517, "seek": 281628, "start": 2816.28, "end": 2824.76, "text": " should be even better even more negative data, right? And guess what? It turned out that this", "tokens": [50364, 820, 312, 754, 1101, 754, 544, 3671, 1412, 11, 558, 30, 400, 2041, 437, 30, 467, 3574, 484, 300, 341, 50788], "temperature": 0.0, "avg_logprob": -0.07937831656877385, "compression_ratio": 1.6784140969162995, "no_speech_prob": 0.0047546434216201305}, {"id": 518, "seek": 281628, "start": 2824.76, "end": 2831.5600000000004, "text": " did not work as well these external patches actually made performance worse than if we just", "tokens": [50788, 630, 406, 589, 382, 731, 613, 8320, 26531, 767, 1027, 3389, 5324, 813, 498, 321, 445, 51128], "temperature": 0.0, "avg_logprob": -0.07937831656877385, "compression_ratio": 1.6784140969162995, "no_speech_prob": 0.0047546434216201305}, {"id": 519, "seek": 281628, "start": 2831.5600000000004, "end": 2838.36, "text": " kept the eternal patch, okay? And this kind of goes back to some old work that that I have been", "tokens": [51128, 4305, 264, 14503, 9972, 11, 1392, 30, 400, 341, 733, 295, 1709, 646, 281, 512, 1331, 589, 300, 300, 286, 362, 668, 51468], "temperature": 0.0, "avg_logprob": -0.07937831656877385, "compression_ratio": 1.6784140969162995, "no_speech_prob": 0.0047546434216201305}, {"id": 520, "seek": 281628, "start": 2838.36, "end": 2844.44, "text": " doing on textures this is where we also seen that that patches from the same image actually provide", "tokens": [51468, 884, 322, 24501, 341, 307, 689, 321, 611, 1612, 300, 300, 26531, 490, 264, 912, 3256, 767, 2893, 51772], "temperature": 0.0, "avg_logprob": -0.07937831656877385, "compression_ratio": 1.6784140969162995, "no_speech_prob": 0.0047546434216201305}, {"id": 521, "seek": 284444, "start": 2844.44, "end": 2849.88, "text": " much more information than if you start mixing them up with patches from other image and in fact", "tokens": [50364, 709, 544, 1589, 813, 498, 291, 722, 11983, 552, 493, 365, 26531, 490, 661, 3256, 293, 294, 1186, 50636], "temperature": 0.0, "avg_logprob": -0.1304873511904762, "compression_ratio": 1.7339449541284404, "no_speech_prob": 0.0016737459227442741}, {"id": 522, "seek": 284444, "start": 2849.88, "end": 2857.2400000000002, "text": " Michala Rani has this wonderful example story of doing super resolution using a single image", "tokens": [50636, 3392, 5159, 497, 3782, 575, 341, 3715, 1365, 1657, 295, 884, 1687, 8669, 1228, 257, 2167, 3256, 51004], "temperature": 0.0, "avg_logprob": -0.1304873511904762, "compression_ratio": 1.7339449541284404, "no_speech_prob": 0.0016737459227442741}, {"id": 523, "seek": 284444, "start": 2857.2400000000002, "end": 2863.32, "text": " where she shows that you can do super resolution by learning from a single image you basically", "tokens": [51004, 689, 750, 3110, 300, 291, 393, 360, 1687, 8669, 538, 2539, 490, 257, 2167, 3256, 291, 1936, 51308], "temperature": 0.0, "avg_logprob": -0.1304873511904762, "compression_ratio": 1.7339449541284404, "no_speech_prob": 0.0016737459227442741}, {"id": 524, "seek": 284444, "start": 2863.32, "end": 2872.28, "text": " take an image down sample it train a cnn to up sample that one image, right? So you basically", "tokens": [51308, 747, 364, 3256, 760, 6889, 309, 3847, 257, 269, 26384, 281, 493, 6889, 300, 472, 3256, 11, 558, 30, 407, 291, 1936, 51756], "temperature": 0.0, "avg_logprob": -0.1304873511904762, "compression_ratio": 1.7339449541284404, "no_speech_prob": 0.0016737459227442741}, {"id": 525, "seek": 287228, "start": 2872.36, "end": 2877.1600000000003, "text": " train a single image network and then just reuse that network for the original image.", "tokens": [50368, 3847, 257, 2167, 3256, 3209, 293, 550, 445, 26225, 300, 3209, 337, 264, 3380, 3256, 13, 50608], "temperature": 0.0, "avg_logprob": -0.10643367011948388, "compression_ratio": 1.8704453441295548, "no_speech_prob": 0.0014546673046424985}, {"id": 526, "seek": 287228, "start": 2877.1600000000003, "end": 2883.7200000000003, "text": " So that works better than if you're if you're training a standard thing with many with a large", "tokens": [50608, 407, 300, 1985, 1101, 813, 498, 291, 434, 498, 291, 434, 3097, 257, 3832, 551, 365, 867, 365, 257, 2416, 50936], "temperature": 0.0, "avg_logprob": -0.10643367011948388, "compression_ratio": 1.8704453441295548, "no_speech_prob": 0.0014546673046424985}, {"id": 527, "seek": 287228, "start": 2883.7200000000003, "end": 2890.6000000000004, "text": " data set, okay? And basically we're seeing the same thing happening here that it's actually the", "tokens": [50936, 1412, 992, 11, 1392, 30, 400, 1936, 321, 434, 2577, 264, 912, 551, 2737, 510, 300, 309, 311, 767, 264, 51280], "temperature": 0.0, "avg_logprob": -0.10643367011948388, "compression_ratio": 1.8704453441295548, "no_speech_prob": 0.0014546673046424985}, {"id": 528, "seek": 287228, "start": 2890.6000000000004, "end": 2896.76, "text": " patches that are in the same image that have the same illumination the same you know camera", "tokens": [51280, 26531, 300, 366, 294, 264, 912, 3256, 300, 362, 264, 912, 30579, 2486, 264, 912, 291, 458, 2799, 51588], "temperature": 0.0, "avg_logprob": -0.10643367011948388, "compression_ratio": 1.8704453441295548, "no_speech_prob": 0.0014546673046424985}, {"id": 529, "seek": 287228, "start": 2896.76, "end": 2901.8, "text": " parameters the same setting they actually much more powerful information than if you just put", "tokens": [51588, 9834, 264, 912, 3287, 436, 767, 709, 544, 4005, 1589, 813, 498, 291, 445, 829, 51840], "temperature": 0.0, "avg_logprob": -0.10643367011948388, "compression_ratio": 1.8704453441295548, "no_speech_prob": 0.0014546673046424985}, {"id": 530, "seek": 290180, "start": 2901.8, "end": 2908.84, "text": " a whole data set. So this is kind of a cute little story and you can see here how using the", "tokens": [50364, 257, 1379, 1412, 992, 13, 407, 341, 307, 733, 295, 257, 4052, 707, 1657, 293, 291, 393, 536, 510, 577, 1228, 264, 50716], "temperature": 0.0, "avg_logprob": -0.10203149101950905, "compression_ratio": 1.6711711711711712, "no_speech_prob": 0.0003352913190610707}, {"id": 531, "seek": 290180, "start": 2908.84, "end": 2914.04, "text": " internal patches we get much better translation than if you we use external patches where you", "tokens": [50716, 6920, 26531, 321, 483, 709, 1101, 12853, 813, 498, 291, 321, 764, 8320, 26531, 689, 291, 50976], "temperature": 0.0, "avg_logprob": -0.10203149101950905, "compression_ratio": 1.6711711711711712, "no_speech_prob": 0.0003352913190610707}, {"id": 532, "seek": 290180, "start": 2914.04, "end": 2920.92, "text": " can see that there is a lot of mode collapse happening, okay? So yeah, so basically that's", "tokens": [50976, 393, 536, 300, 456, 307, 257, 688, 295, 4391, 15584, 2737, 11, 1392, 30, 407, 1338, 11, 370, 1936, 300, 311, 51320], "temperature": 0.0, "avg_logprob": -0.10203149101950905, "compression_ratio": 1.6711711711711712, "no_speech_prob": 0.0003352913190610707}, {"id": 533, "seek": 290180, "start": 2920.92, "end": 2930.04, "text": " the story and this is our method and compared to compared to something like CycleGAN and other", "tokens": [51320, 264, 1657, 293, 341, 307, 527, 3170, 293, 5347, 281, 5347, 281, 746, 411, 10295, 2160, 27699, 293, 661, 51776], "temperature": 0.0, "avg_logprob": -0.10203149101950905, "compression_ratio": 1.6711711711711712, "no_speech_prob": 0.0003352913190610707}, {"id": 534, "seek": 293004, "start": 2930.04, "end": 2937.0, "text": " methods as well and basically we can we see that we're basically getting as well performance as good", "tokens": [50364, 7150, 382, 731, 293, 1936, 321, 393, 321, 536, 300, 321, 434, 1936, 1242, 382, 731, 3389, 382, 665, 50712], "temperature": 0.0, "avg_logprob": -0.14631945087063697, "compression_ratio": 1.75, "no_speech_prob": 0.0023222784511744976}, {"id": 535, "seek": 293004, "start": 2937.0, "end": 2944.6, "text": " as CycleGAN in most cases but it's much faster and it's it's it's one sided you don't need to", "tokens": [50712, 382, 10295, 2160, 27699, 294, 881, 3331, 457, 309, 311, 709, 4663, 293, 309, 311, 309, 311, 309, 311, 472, 41651, 291, 500, 380, 643, 281, 51092], "temperature": 0.0, "avg_logprob": -0.14631945087063697, "compression_ratio": 1.75, "no_speech_prob": 0.0023222784511744976}, {"id": 536, "seek": 293004, "start": 2944.6, "end": 2951.88, "text": " train a two thing two-way thing and and it's basically a we think it's kind of a much better", "tokens": [51092, 3847, 257, 732, 551, 732, 12, 676, 551, 293, 293, 309, 311, 1936, 257, 321, 519, 309, 311, 733, 295, 257, 709, 1101, 51456], "temperature": 0.0, "avg_logprob": -0.14631945087063697, "compression_ratio": 1.75, "no_speech_prob": 0.0023222784511744976}, {"id": 537, "seek": 293004, "start": 2952.68, "end": 2956.84, "text": " a much better story and so here are some of the transformations that we have", "tokens": [51496, 257, 709, 1101, 1657, 293, 370, 510, 366, 512, 295, 264, 34852, 300, 321, 362, 51704], "temperature": 0.0, "avg_logprob": -0.14631945087063697, "compression_ratio": 1.75, "no_speech_prob": 0.0023222784511744976}, {"id": 538, "seek": 295684, "start": 2957.56, "end": 2963.0, "text": " and one cute thing that we can also do is we can basically apply this to instances so for", "tokens": [50400, 293, 472, 4052, 551, 300, 321, 393, 611, 360, 307, 321, 393, 1936, 3079, 341, 281, 14519, 370, 337, 50672], "temperature": 0.0, "avg_logprob": -0.1191685540335519, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.003025715472176671}, {"id": 539, "seek": 295684, "start": 2963.0, "end": 2967.88, "text": " example let's say that we have a single image Claude Monet's painting we want to make it into", "tokens": [50672, 1365, 718, 311, 584, 300, 321, 362, 257, 2167, 3256, 12947, 2303, 47871, 311, 5370, 321, 528, 281, 652, 309, 666, 50916], "temperature": 0.0, "avg_logprob": -0.1191685540335519, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.003025715472176671}, {"id": 540, "seek": 295684, "start": 2969.48, "end": 2975.7200000000003, "text": " photograph and maybe what we have also is a single image instead of data set we have a", "tokens": [50996, 8348, 293, 1310, 437, 321, 362, 611, 307, 257, 2167, 3256, 2602, 295, 1412, 992, 321, 362, 257, 51308], "temperature": 0.0, "avg_logprob": -0.1191685540335519, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.003025715472176671}, {"id": 541, "seek": 295684, "start": 2975.7200000000003, "end": 2982.28, "text": " single photograph that is also let's say of water lilies, okay? Well we can basically use the same kind", "tokens": [51308, 2167, 8348, 300, 307, 611, 718, 311, 584, 295, 1281, 375, 24119, 11, 1392, 30, 1042, 321, 393, 1936, 764, 264, 912, 733, 51636], "temperature": 0.0, "avg_logprob": -0.1191685540335519, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.003025715472176671}, {"id": 542, "seek": 298228, "start": 2982.28, "end": 2991.88, "text": " of contrastive learning basically just between a single reference photo and our output, okay?", "tokens": [50364, 295, 8712, 488, 2539, 1936, 445, 1296, 257, 2167, 6408, 5052, 293, 527, 5598, 11, 1392, 30, 50844], "temperature": 0.0, "avg_logprob": -0.13409985265424174, "compression_ratio": 1.763975155279503, "no_speech_prob": 0.0016474901931360364}, {"id": 543, "seek": 298228, "start": 2993.7200000000003, "end": 3001.7200000000003, "text": " and have have have one have the same thing here for the for the positives and have a instead of", "tokens": [50936, 293, 362, 362, 362, 472, 362, 264, 912, 551, 510, 337, 264, 337, 264, 35127, 293, 362, 257, 2602, 295, 51336], "temperature": 0.0, "avg_logprob": -0.13409985265424174, "compression_ratio": 1.763975155279503, "no_speech_prob": 0.0016474901931360364}, {"id": 544, "seek": 298228, "start": 3001.7200000000003, "end": 3007.0800000000004, "text": " instead of again have basically just a single discriminator here and we can get something that", "tokens": [51336, 2602, 295, 797, 362, 1936, 445, 257, 2167, 20828, 1639, 510, 293, 321, 393, 483, 746, 300, 51604], "temperature": 0.0, "avg_logprob": -0.13409985265424174, "compression_ratio": 1.763975155279503, "no_speech_prob": 0.0016474901931360364}, {"id": 545, "seek": 300708, "start": 3007.08, "end": 3014.6, "text": " actually works quite a bit better than a lot of these kind of a stylization methods, okay?", "tokens": [50364, 767, 1985, 1596, 257, 857, 1101, 813, 257, 688, 295, 613, 733, 295, 257, 23736, 2144, 7150, 11, 1392, 30, 50740], "temperature": 0.0, "avg_logprob": -0.12633904048374722, "compression_ratio": 1.5988700564971752, "no_speech_prob": 0.0005440214881673455}, {"id": 546, "seek": 300708, "start": 3014.6, "end": 3020.2799999999997, "text": " So this is this is competitors and this is ours and I think that ours actually looks quite a bit", "tokens": [50740, 407, 341, 307, 341, 307, 18333, 293, 341, 307, 11896, 293, 286, 519, 300, 11896, 767, 1542, 1596, 257, 857, 51024], "temperature": 0.0, "avg_logprob": -0.12633904048374722, "compression_ratio": 1.5988700564971752, "no_speech_prob": 0.0005440214881673455}, {"id": 547, "seek": 300708, "start": 3020.2799999999997, "end": 3032.12, "text": " more natural and also better than CycleGAN. There are some other examples, okay? Let's see what", "tokens": [51024, 544, 3303, 293, 611, 1101, 813, 10295, 2160, 27699, 13, 821, 366, 512, 661, 5110, 11, 1392, 30, 961, 311, 536, 437, 51616], "temperature": 0.0, "avg_logprob": -0.12633904048374722, "compression_ratio": 1.5988700564971752, "no_speech_prob": 0.0005440214881673455}, {"id": 548, "seek": 303212, "start": 3032.12, "end": 3042.8399999999997, "text": " timing is. Well you know I don't think I have time to go over the second point of why you sell", "tokens": [50364, 10822, 307, 13, 1042, 291, 458, 286, 500, 380, 519, 286, 362, 565, 281, 352, 670, 264, 1150, 935, 295, 983, 291, 3607, 50900], "temperature": 0.0, "avg_logprob": -0.0874344835576323, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.002433949848636985}, {"id": 549, "seek": 303212, "start": 3042.8399999999997, "end": 3047.56, "text": " supervision maybe I'll just give you a little bit of a hint of what I mean and then you can", "tokens": [50900, 32675, 1310, 286, 603, 445, 976, 291, 257, 707, 857, 295, 257, 12075, 295, 437, 286, 914, 293, 550, 291, 393, 51136], "temperature": 0.0, "avg_logprob": -0.0874344835576323, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.002433949848636985}, {"id": 550, "seek": 303212, "start": 3047.56, "end": 3054.52, "text": " you can read the paper if you're interested. So basically the idea is that it's a little bit weird", "tokens": [51136, 291, 393, 1401, 264, 3035, 498, 291, 434, 3102, 13, 407, 1936, 264, 1558, 307, 300, 309, 311, 257, 707, 857, 3657, 51484], "temperature": 0.0, "avg_logprob": -0.0874344835576323, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.002433949848636985}, {"id": 551, "seek": 303212, "start": 3055.56, "end": 3061.3199999999997, "text": " that we are in most of machine learning we are using a fixed training set. It's not very natural", "tokens": [51536, 300, 321, 366, 294, 881, 295, 3479, 2539, 321, 366, 1228, 257, 6806, 3097, 992, 13, 467, 311, 406, 588, 3303, 51824], "temperature": 0.0, "avg_logprob": -0.0874344835576323, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.002433949848636985}, {"id": 552, "seek": 306132, "start": 3061.4, "end": 3069.0800000000004, "text": " biologically because biological agents they never see the same data twice, right? So you live your", "tokens": [50368, 3228, 17157, 570, 13910, 12554, 436, 1128, 536, 264, 912, 1412, 6091, 11, 558, 30, 407, 291, 1621, 428, 50752], "temperature": 0.0, "avg_logprob": -0.1585748299308445, "compression_ratio": 1.9696969696969697, "no_speech_prob": 0.005056397523730993}, {"id": 553, "seek": 306132, "start": 3069.0800000000004, "end": 3074.6000000000004, "text": " life you never see the same thing twice. You see something first you you know you you deal with it", "tokens": [50752, 993, 291, 1128, 536, 264, 912, 551, 6091, 13, 509, 536, 746, 700, 291, 291, 458, 291, 291, 2028, 365, 309, 51028], "temperature": 0.0, "avg_logprob": -0.1585748299308445, "compression_ratio": 1.9696969696969697, "no_speech_prob": 0.005056397523730993}, {"id": 554, "seek": 306132, "start": 3076.04, "end": 3081.0800000000004, "text": " you hopefully learn from it if you you know if you didn't deal from it you're dead if you deal", "tokens": [51100, 291, 4696, 1466, 490, 309, 498, 291, 291, 458, 498, 291, 994, 380, 2028, 490, 309, 291, 434, 3116, 498, 291, 2028, 51352], "temperature": 0.0, "avg_logprob": -0.1585748299308445, "compression_ratio": 1.9696969696969697, "no_speech_prob": 0.005056397523730993}, {"id": 555, "seek": 306132, "start": 3081.0800000000004, "end": 3087.4, "text": " with it you learn from it and then and then you you can recover some information from it but then", "tokens": [51352, 365, 309, 291, 1466, 490, 309, 293, 550, 293, 550, 291, 291, 393, 8114, 512, 1589, 490, 309, 457, 550, 51668], "temperature": 0.0, "avg_logprob": -0.1585748299308445, "compression_ratio": 1.9696969696969697, "no_speech_prob": 0.005056397523730993}, {"id": 556, "seek": 308740, "start": 3087.4, "end": 3093.64, "text": " you never see that again you see maybe something similar, okay? So every new piece of data is", "tokens": [50364, 291, 1128, 536, 300, 797, 291, 536, 1310, 746, 2531, 11, 1392, 30, 407, 633, 777, 2522, 295, 1412, 307, 50676], "temperature": 0.0, "avg_logprob": -0.08309647169980136, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.0009544674539938569}, {"id": 557, "seek": 308740, "start": 3093.64, "end": 3102.76, "text": " basically first in your test set and then in your training set, okay? And it seems like using a fixed", "tokens": [50676, 1936, 700, 294, 428, 1500, 992, 293, 550, 294, 428, 3097, 992, 11, 1392, 30, 400, 309, 2544, 411, 1228, 257, 6806, 51132], "temperature": 0.0, "avg_logprob": -0.08309647169980136, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.0009544674539938569}, {"id": 558, "seek": 308740, "start": 3102.76, "end": 3108.12, "text": " data set it kind of encourages memorization because you see the same exact thing over and over and over", "tokens": [51132, 1412, 992, 309, 733, 295, 28071, 10560, 2144, 570, 291, 536, 264, 912, 1900, 551, 670, 293, 670, 293, 670, 51400], "temperature": 0.0, "avg_logprob": -0.08309647169980136, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.0009544674539938569}, {"id": 559, "seek": 308740, "start": 3108.12, "end": 3112.84, "text": " again. In fact maybe this is actually another reason why data augmentation works because", "tokens": [51400, 797, 13, 682, 1186, 1310, 341, 307, 767, 1071, 1778, 983, 1412, 14501, 19631, 1985, 570, 51636], "temperature": 0.0, "avg_logprob": -0.08309647169980136, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.0009544674539938569}, {"id": 560, "seek": 311284, "start": 3112.92, "end": 3118.6000000000004, "text": " data augmentation is kind of random you create a random thing every time so you kind of get away", "tokens": [50368, 1412, 14501, 19631, 307, 733, 295, 4974, 291, 1884, 257, 4974, 551, 633, 565, 370, 291, 733, 295, 483, 1314, 50652], "temperature": 0.0, "avg_logprob": -0.05594517534429377, "compression_ratio": 1.8371212121212122, "no_speech_prob": 0.0004372486437205225}, {"id": 561, "seek": 311284, "start": 3118.6000000000004, "end": 3125.4, "text": " a little bit from this memorization. So in fact this this might be kind of a subtle way in which", "tokens": [50652, 257, 707, 857, 490, 341, 10560, 2144, 13, 407, 294, 1186, 341, 341, 1062, 312, 733, 295, 257, 13743, 636, 294, 597, 50992], "temperature": 0.0, "avg_logprob": -0.05594517534429377, "compression_ratio": 1.8371212121212122, "no_speech_prob": 0.0004372486437205225}, {"id": 562, "seek": 311284, "start": 3125.4, "end": 3130.1200000000003, "text": " data augmentation helps that actually has nothing to do with the data augmentation just basically", "tokens": [50992, 1412, 14501, 19631, 3665, 300, 767, 575, 1825, 281, 360, 365, 264, 1412, 14501, 19631, 445, 1936, 51228], "temperature": 0.0, "avg_logprob": -0.05594517534429377, "compression_ratio": 1.8371212121212122, "no_speech_prob": 0.0004372486437205225}, {"id": 563, "seek": 311284, "start": 3130.1200000000003, "end": 3136.6800000000003, "text": " randomization of your data, okay? But the point is that if you're using self supervised learning", "tokens": [51228, 4974, 2144, 295, 428, 1412, 11, 1392, 30, 583, 264, 935, 307, 300, 498, 291, 434, 1228, 2698, 46533, 2539, 51556], "temperature": 0.0, "avg_logprob": -0.05594517534429377, "compression_ratio": 1.8371212121212122, "no_speech_prob": 0.0004372486437205225}, {"id": 564, "seek": 311284, "start": 3136.6800000000003, "end": 3141.4, "text": " like the whole point of having a fixed training set was because it was expensive to do all these", "tokens": [51556, 411, 264, 1379, 935, 295, 1419, 257, 6806, 3097, 992, 390, 570, 309, 390, 5124, 281, 360, 439, 613, 51792], "temperature": 0.0, "avg_logprob": -0.05594517534429377, "compression_ratio": 1.8371212121212122, "no_speech_prob": 0.0004372486437205225}, {"id": 565, "seek": 314140, "start": 3141.4, "end": 3147.96, "text": " labels, you know? ImageNet, poor Fei Fei spent all of her startup money in Stanford labeling this", "tokens": [50364, 16949, 11, 291, 458, 30, 29903, 31890, 11, 4716, 39587, 39587, 4418, 439, 295, 720, 18578, 1460, 294, 20374, 40244, 341, 50692], "temperature": 0.0, "avg_logprob": -0.1362870972732018, "compression_ratio": 1.6701388888888888, "no_speech_prob": 0.0018096609273925424}, {"id": 566, "seek": 314140, "start": 3147.96, "end": 3153.7200000000003, "text": " huge data set, right? So it kind of makes sense that it's it's fixed because it took so much money", "tokens": [50692, 2603, 1412, 992, 11, 558, 30, 407, 309, 733, 295, 1669, 2020, 300, 309, 311, 309, 311, 6806, 570, 309, 1890, 370, 709, 1460, 50980], "temperature": 0.0, "avg_logprob": -0.1362870972732018, "compression_ratio": 1.6701388888888888, "no_speech_prob": 0.0018096609273925424}, {"id": 567, "seek": 314140, "start": 3153.7200000000003, "end": 3159.0, "text": " to label it. But if you're using self supervised learning if you don't need the labels what's the", "tokens": [50980, 281, 7645, 309, 13, 583, 498, 291, 434, 1228, 2698, 46533, 2539, 498, 291, 500, 380, 643, 264, 16949, 437, 311, 264, 51244], "temperature": 0.0, "avg_logprob": -0.1362870972732018, "compression_ratio": 1.6701388888888888, "no_speech_prob": 0.0018096609273925424}, {"id": 568, "seek": 314140, "start": 3159.0, "end": 3164.6800000000003, "text": " point of having a fixed data set? Why can't we just keep downloading images from whatever the", "tokens": [51244, 935, 295, 1419, 257, 6806, 1412, 992, 30, 1545, 393, 380, 321, 445, 1066, 32529, 5267, 490, 2035, 264, 51528], "temperature": 0.0, "avg_logprob": -0.1362870972732018, "compression_ratio": 1.6701388888888888, "no_speech_prob": 0.0018096609273925424}, {"id": 569, "seek": 314140, "start": 3164.6800000000003, "end": 3170.92, "text": " internet the TV whatever and just keep doing it all the time because we can generate our own", "tokens": [51528, 4705, 264, 3558, 2035, 293, 445, 1066, 884, 309, 439, 264, 565, 570, 321, 393, 8460, 527, 1065, 51840], "temperature": 0.0, "avg_logprob": -0.1362870972732018, "compression_ratio": 1.6701388888888888, "no_speech_prob": 0.0018096609273925424}, {"id": 570, "seek": 317092, "start": 3170.92, "end": 3178.12, "text": " labels. Seems kind of natural and so this is where kind of I've been pushing on this idea of kind of", "tokens": [50364, 16949, 13, 22524, 733, 295, 3303, 293, 370, 341, 307, 689, 733, 295, 286, 600, 668, 7380, 322, 341, 1558, 295, 733, 295, 50724], "temperature": 0.0, "avg_logprob": -0.10481760794656318, "compression_ratio": 1.9710743801652892, "no_speech_prob": 0.0003199686761945486}, {"id": 571, "seek": 317092, "start": 3178.12, "end": 3183.32, "text": " this online continual learning. So you can you can think of it in terms of of the standard", "tokens": [50724, 341, 2950, 1421, 901, 2539, 13, 407, 291, 393, 291, 393, 519, 295, 309, 294, 2115, 295, 295, 264, 3832, 50984], "temperature": 0.0, "avg_logprob": -0.10481760794656318, "compression_ratio": 1.9710743801652892, "no_speech_prob": 0.0003199686761945486}, {"id": 572, "seek": 317092, "start": 3183.88, "end": 3188.12, "text": " a train valve separation. So you know you have your training set and kind of the standard thing", "tokens": [51012, 257, 3847, 15294, 14634, 13, 407, 291, 458, 291, 362, 428, 3097, 992, 293, 733, 295, 264, 3832, 551, 51224], "temperature": 0.0, "avg_logprob": -0.10481760794656318, "compression_ratio": 1.9710743801652892, "no_speech_prob": 0.0003199686761945486}, {"id": 573, "seek": 317092, "start": 3188.12, "end": 3192.52, "text": " in machine learning is you can separate it into a training set and a validation set, right?", "tokens": [51224, 294, 3479, 2539, 307, 291, 393, 4994, 309, 666, 257, 3097, 992, 293, 257, 24071, 992, 11, 558, 30, 51444], "temperature": 0.0, "avg_logprob": -0.10481760794656318, "compression_ratio": 1.9710743801652892, "no_speech_prob": 0.0003199686761945486}, {"id": 574, "seek": 317092, "start": 3192.52, "end": 3198.52, "text": " And we know that if you just train on a training set and then use the validation set to tune your", "tokens": [51444, 400, 321, 458, 300, 498, 291, 445, 3847, 322, 257, 3097, 992, 293, 550, 764, 264, 24071, 992, 281, 10864, 428, 51744], "temperature": 0.0, "avg_logprob": -0.10481760794656318, "compression_ratio": 1.9710743801652892, "no_speech_prob": 0.0003199686761945486}, {"id": 575, "seek": 319852, "start": 3198.52, "end": 3204.7599999999998, "text": " high parameters you usually get better performance on the eventual test data than if you just train", "tokens": [50364, 1090, 9834, 291, 2673, 483, 1101, 3389, 322, 264, 33160, 1500, 1412, 813, 498, 291, 445, 3847, 50676], "temperature": 0.0, "avg_logprob": -0.08134150909165204, "compression_ratio": 1.830827067669173, "no_speech_prob": 0.0007792253163643181}, {"id": 576, "seek": 319852, "start": 3204.7599999999998, "end": 3210.36, "text": " on all the training set all at once. Even though you're kind of you you think that it's less data", "tokens": [50676, 322, 439, 264, 3097, 992, 439, 412, 1564, 13, 2754, 1673, 291, 434, 733, 295, 291, 291, 519, 300, 309, 311, 1570, 1412, 50956], "temperature": 0.0, "avg_logprob": -0.08134150909165204, "compression_ratio": 1.830827067669173, "no_speech_prob": 0.0007792253163643181}, {"id": 577, "seek": 319852, "start": 3210.36, "end": 3215.4, "text": " that you're using for training but actually this is effect turns out to be more effective. Well we", "tokens": [50956, 300, 291, 434, 1228, 337, 3097, 457, 767, 341, 307, 1802, 4523, 484, 281, 312, 544, 4942, 13, 1042, 321, 51208], "temperature": 0.0, "avg_logprob": -0.08134150909165204, "compression_ratio": 1.830827067669173, "no_speech_prob": 0.0007792253163643181}, {"id": 578, "seek": 319852, "start": 3215.4, "end": 3221.4, "text": " can think of the same thing in a continual way. So we can think of it as you train on the data", "tokens": [51208, 393, 519, 295, 264, 912, 551, 294, 257, 1421, 901, 636, 13, 407, 321, 393, 519, 295, 309, 382, 291, 3847, 322, 264, 1412, 51508], "temperature": 0.0, "avg_logprob": -0.08134150909165204, "compression_ratio": 1.830827067669173, "no_speech_prob": 0.0007792253163643181}, {"id": 579, "seek": 319852, "start": 3221.4, "end": 3227.4, "text": " that you have seen and then you're validating on the next data that comes along, okay? And then", "tokens": [51508, 300, 291, 362, 1612, 293, 550, 291, 434, 7363, 990, 322, 264, 958, 1412, 300, 1487, 2051, 11, 1392, 30, 400, 550, 51808], "temperature": 0.0, "avg_logprob": -0.08134150909165204, "compression_ratio": 1.830827067669173, "no_speech_prob": 0.0007792253163643181}, {"id": 580, "seek": 322740, "start": 3227.4, "end": 3231.96, "text": " once you do that you just incorporate it into your training center you can keep going and they", "tokens": [50364, 1564, 291, 360, 300, 291, 445, 16091, 309, 666, 428, 3097, 3056, 291, 393, 1066, 516, 293, 436, 50592], "temperature": 0.0, "avg_logprob": -0.11048719618055555, "compression_ratio": 1.7919708029197081, "no_speech_prob": 0.0006165069062262774}, {"id": 581, "seek": 322740, "start": 3231.96, "end": 3237.0, "text": " can keep going on forever. You don't ever need to stop, okay? And this I think is a kind of a very", "tokens": [50592, 393, 1066, 516, 322, 5680, 13, 509, 500, 380, 1562, 643, 281, 1590, 11, 1392, 30, 400, 341, 286, 519, 307, 257, 733, 295, 257, 588, 50844], "temperature": 0.0, "avg_logprob": -0.11048719618055555, "compression_ratio": 1.7919708029197081, "no_speech_prob": 0.0006165069062262774}, {"id": 582, "seek": 322740, "start": 3237.0, "end": 3245.8, "text": " powerful trick that is made that we can now do because we can use self-supervision to do this", "tokens": [50844, 4005, 4282, 300, 307, 1027, 300, 321, 393, 586, 360, 570, 321, 393, 764, 2698, 12, 48172, 6763, 281, 360, 341, 51284], "temperature": 0.0, "avg_logprob": -0.11048719618055555, "compression_ratio": 1.7919708029197081, "no_speech_prob": 0.0006165069062262774}, {"id": 583, "seek": 322740, "start": 3245.8, "end": 3251.1600000000003, "text": " kind of this evaluation, this testing, okay? And so this is the idea of test time training which is", "tokens": [51284, 733, 295, 341, 13344, 11, 341, 4997, 11, 1392, 30, 400, 370, 341, 307, 264, 1558, 295, 1500, 565, 3097, 597, 307, 51552], "temperature": 0.0, "avg_logprob": -0.11048719618055555, "compression_ratio": 1.7919708029197081, "no_speech_prob": 0.0006165069062262774}, {"id": 584, "seek": 322740, "start": 3251.1600000000003, "end": 3257.32, "text": " our attempt to operationalize this on an infinite smoothly changing stream and the idea is to basically", "tokens": [51552, 527, 5217, 281, 16607, 1125, 341, 322, 364, 13785, 19565, 4473, 4309, 293, 264, 1558, 307, 281, 1936, 51860], "temperature": 0.0, "avg_logprob": -0.11048719618055555, "compression_ratio": 1.7919708029197081, "no_speech_prob": 0.0006165069062262774}, {"id": 585, "seek": 325732, "start": 3257.6400000000003, "end": 3267.0, "text": " use self-supervision to continuously adapt to new data, okay? And we did this already in the", "tokens": [50380, 764, 2698, 12, 48172, 6763, 281, 15684, 6231, 281, 777, 1412, 11, 1392, 30, 400, 321, 630, 341, 1217, 294, 264, 50848], "temperature": 0.0, "avg_logprob": -0.14733125202691377, "compression_ratio": 1.4329896907216495, "no_speech_prob": 0.0011327782412990928}, {"id": 586, "seek": 325732, "start": 3268.44, "end": 3276.04, "text": " case of reinforcement learning with our curiosity work and this new work is basically trying to do", "tokens": [50920, 1389, 295, 29280, 2539, 365, 527, 18769, 589, 293, 341, 777, 589, 307, 1936, 1382, 281, 360, 51300], "temperature": 0.0, "avg_logprob": -0.14733125202691377, "compression_ratio": 1.4329896907216495, "no_speech_prob": 0.0011327782412990928}, {"id": 587, "seek": 325732, "start": 3276.04, "end": 3286.36, "text": " it for images and this is the paper, test time training and it was in ICML 2000. Maybe", "tokens": [51300, 309, 337, 5267, 293, 341, 307, 264, 3035, 11, 1500, 565, 3097, 293, 309, 390, 294, 14360, 12683, 8132, 13, 2704, 51816], "temperature": 0.0, "avg_logprob": -0.14733125202691377, "compression_ratio": 1.4329896907216495, "no_speech_prob": 0.0011327782412990928}, {"id": 588, "seek": 328636, "start": 3286.92, "end": 3293.0, "text": " just give me, I'll give you one slide of intuition of what we're doing. Basically,", "tokens": [50392, 445, 976, 385, 11, 286, 603, 976, 291, 472, 4137, 295, 24002, 295, 437, 321, 434, 884, 13, 8537, 11, 50696], "temperature": 0.0, "avg_logprob": -0.12481967496200347, "compression_ratio": 1.6130952380952381, "no_speech_prob": 0.0006360316183418036}, {"id": 589, "seek": 328636, "start": 3293.0, "end": 3301.88, "text": " the idea is that we're, let's say we have a training set of object detection, right? And at", "tokens": [50696, 264, 1558, 307, 300, 321, 434, 11, 718, 311, 584, 321, 362, 257, 3097, 992, 295, 2657, 17784, 11, 558, 30, 400, 412, 51140], "temperature": 0.0, "avg_logprob": -0.12481967496200347, "compression_ratio": 1.6130952380952381, "no_speech_prob": 0.0006360316183418036}, {"id": 590, "seek": 328636, "start": 3301.88, "end": 3308.6800000000003, "text": " training time we have our standard thing, we have our image and we have our label so nothing new", "tokens": [51140, 3097, 565, 321, 362, 527, 3832, 551, 11, 321, 362, 527, 3256, 293, 321, 362, 527, 7645, 370, 1825, 777, 51480], "temperature": 0.0, "avg_logprob": -0.12481967496200347, "compression_ratio": 1.6130952380952381, "no_speech_prob": 0.0006360316183418036}, {"id": 591, "seek": 330868, "start": 3308.68, "end": 3318.3599999999997, "text": " here, we have input in, label out, we are training and then at the same time we also have a self-supervised", "tokens": [50364, 510, 11, 321, 362, 4846, 294, 11, 7645, 484, 11, 321, 366, 3097, 293, 550, 412, 264, 912, 565, 321, 611, 362, 257, 2698, 12, 48172, 24420, 50848], "temperature": 0.0, "avg_logprob": -0.1488964366912842, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.007458047941327095}, {"id": 592, "seek": 330868, "start": 3318.3599999999997, "end": 3325.08, "text": " head that basically given your image it does some self-supervised task. In this case we are basically", "tokens": [50848, 1378, 300, 1936, 2212, 428, 3256, 309, 775, 512, 2698, 12, 48172, 24420, 5633, 13, 682, 341, 1389, 321, 366, 1936, 51184], "temperature": 0.0, "avg_logprob": -0.1488964366912842, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.007458047941327095}, {"id": 593, "seek": 330868, "start": 3325.08, "end": 3330.7599999999998, "text": " our task here is rotation prediction. Given the rotated version of the image we want to predict", "tokens": [51184, 527, 5633, 510, 307, 12447, 17630, 13, 18600, 264, 42146, 3037, 295, 264, 3256, 321, 528, 281, 6069, 51468], "temperature": 0.0, "avg_logprob": -0.1488964366912842, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.007458047941327095}, {"id": 594, "seek": 330868, "start": 3330.7599999999998, "end": 3334.9199999999996, "text": " which rotation it is. It doesn't really matter, it could be any task at all, okay? So at training", "tokens": [51468, 597, 12447, 309, 307, 13, 467, 1177, 380, 534, 1871, 11, 309, 727, 312, 604, 5633, 412, 439, 11, 1392, 30, 407, 412, 3097, 51676], "temperature": 0.0, "avg_logprob": -0.1488964366912842, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.007458047941327095}, {"id": 595, "seek": 333492, "start": 3334.92, "end": 3341.48, "text": " time we do both of those tasks together but then at test time of course we don't have the labels", "tokens": [50364, 565, 321, 360, 1293, 295, 729, 9608, 1214, 457, 550, 412, 1500, 565, 295, 1164, 321, 500, 380, 362, 264, 16949, 50692], "temperature": 0.0, "avg_logprob": -0.1102155610626819, "compression_ratio": 1.8046511627906976, "no_speech_prob": 0.0016217873198911548}, {"id": 596, "seek": 333492, "start": 3341.48, "end": 3348.76, "text": " but we still have this task, okay? And so we can basically around this, we can evaluate this task", "tokens": [50692, 457, 321, 920, 362, 341, 5633, 11, 1392, 30, 400, 370, 321, 393, 1936, 926, 341, 11, 321, 393, 13059, 341, 5633, 51056], "temperature": 0.0, "avg_logprob": -0.1102155610626819, "compression_ratio": 1.8046511627906976, "no_speech_prob": 0.0016217873198911548}, {"id": 597, "seek": 333492, "start": 3349.4, "end": 3358.12, "text": " and if the result is not good, if it failed this self-supervised task we can do a little bit of", "tokens": [51088, 293, 498, 264, 1874, 307, 406, 665, 11, 498, 309, 7612, 341, 2698, 12, 48172, 24420, 5633, 321, 393, 360, 257, 707, 857, 295, 51524], "temperature": 0.0, "avg_logprob": -0.1102155610626819, "compression_ratio": 1.8046511627906976, "no_speech_prob": 0.0016217873198911548}, {"id": 598, "seek": 333492, "start": 3358.12, "end": 3364.6800000000003, "text": " fine-tuning, a little bit of fine-tuning training for this other task but as we're doing the fine", "tokens": [51524, 2489, 12, 83, 37726, 11, 257, 707, 857, 295, 2489, 12, 83, 37726, 3097, 337, 341, 661, 5633, 457, 382, 321, 434, 884, 264, 2489, 51852], "temperature": 0.0, "avg_logprob": -0.1102155610626819, "compression_ratio": 1.8046511627906976, "no_speech_prob": 0.0016217873198911548}, {"id": 599, "seek": 336468, "start": 3364.68, "end": 3372.7599999999998, "text": " tuning it's going to get changed representation in a way that will also impact the real task that", "tokens": [50364, 15164, 309, 311, 516, 281, 483, 3105, 10290, 294, 257, 636, 300, 486, 611, 2712, 264, 957, 5633, 300, 50768], "temperature": 0.0, "avg_logprob": -0.15157346725463866, "compression_ratio": 1.5691489361702127, "no_speech_prob": 0.0009542185580357909}, {"id": 600, "seek": 336468, "start": 3372.7599999999998, "end": 3381.8799999999997, "text": " we care about and that allows us to do better as we are changing, as we're going for the dataset.", "tokens": [50768, 321, 1127, 466, 293, 300, 4045, 505, 281, 360, 1101, 382, 321, 366, 4473, 11, 382, 321, 434, 516, 337, 264, 28872, 13, 51224], "temperature": 0.0, "avg_logprob": -0.15157346725463866, "compression_ratio": 1.5691489361702127, "no_speech_prob": 0.0009542185580357909}, {"id": 601, "seek": 336468, "start": 3381.8799999999997, "end": 3389.48, "text": " And so here is an example where you know given this image at test time basically the right label is", "tokens": [51224, 400, 370, 510, 307, 364, 1365, 689, 291, 458, 2212, 341, 3256, 412, 1500, 565, 1936, 264, 558, 7645, 307, 51604], "temperature": 0.0, "avg_logprob": -0.15157346725463866, "compression_ratio": 1.5691489361702127, "no_speech_prob": 0.0009542185580357909}, {"id": 602, "seek": 338948, "start": 3389.48, "end": 3396.76, "text": " elephant but initially it basically thinks it's a dog but then as we do this fine-tuning on our", "tokens": [50364, 19791, 457, 9105, 309, 1936, 7309, 309, 311, 257, 3000, 457, 550, 382, 321, 360, 341, 2489, 12, 83, 37726, 322, 527, 50728], "temperature": 0.0, "avg_logprob": -0.13819139297694377, "compression_ratio": 1.6494252873563218, "no_speech_prob": 0.0029337808955460787}, {"id": 603, "seek": 338948, "start": 3399.2400000000002, "end": 3405.16, "text": " self-supervised task it figures out that it's actually less of a dog and more of an elephant", "tokens": [50852, 2698, 12, 48172, 24420, 5633, 309, 9624, 484, 300, 309, 311, 767, 1570, 295, 257, 3000, 293, 544, 295, 364, 19791, 51148], "temperature": 0.0, "avg_logprob": -0.13819139297694377, "compression_ratio": 1.6494252873563218, "no_speech_prob": 0.0029337808955460787}, {"id": 604, "seek": 338948, "start": 3405.16, "end": 3410.12, "text": " and gives us the right answer and that's basically the story of the paper, sorry I had to rush but", "tokens": [51148, 293, 2709, 505, 264, 558, 1867, 293, 300, 311, 1936, 264, 1657, 295, 264, 3035, 11, 2597, 286, 632, 281, 9300, 457, 51396], "temperature": 0.0, "avg_logprob": -0.13819139297694377, "compression_ratio": 1.6494252873563218, "no_speech_prob": 0.0029337808955460787}, {"id": 605, "seek": 341012, "start": 3410.68, "end": 3419.0, "text": " you can look at the paper online. And to conclude, why use self-supervision?", "tokens": [50392, 291, 393, 574, 412, 264, 3035, 2950, 13, 400, 281, 16886, 11, 983, 764, 2698, 12, 48172, 6763, 30, 50808], "temperature": 0.0, "avg_logprob": -0.1027341743013752, "compression_ratio": 1.4943820224719102, "no_speech_prob": 0.005467480979859829}, {"id": 606, "seek": 341012, "start": 3421.3199999999997, "end": 3427.4, "text": " One reason that I like is that it allows us to get away from this top-down semantic categorization", "tokens": [50924, 1485, 1778, 300, 286, 411, 307, 300, 309, 4045, 505, 281, 483, 1314, 490, 341, 1192, 12, 5093, 47982, 19250, 2144, 51228], "temperature": 0.0, "avg_logprob": -0.1027341743013752, "compression_ratio": 1.4943820224719102, "no_speech_prob": 0.005467480979859829}, {"id": 607, "seek": 341012, "start": 3427.4, "end": 3434.7599999999998, "text": " and gets us more into this bottom-up association story and learn things from the bottom-up", "tokens": [51228, 293, 2170, 505, 544, 666, 341, 2767, 12, 1010, 14598, 1657, 293, 1466, 721, 490, 264, 2767, 12, 1010, 51596], "temperature": 0.0, "avg_logprob": -0.1027341743013752, "compression_ratio": 1.4943820224719102, "no_speech_prob": 0.005467480979859829}, {"id": 608, "seek": 343476, "start": 3434.76, "end": 3441.2400000000002, "text": " but we must be careful that the supervision doesn't leak in through things like data augmentation", "tokens": [50364, 457, 321, 1633, 312, 5026, 300, 264, 32675, 1177, 380, 17143, 294, 807, 721, 411, 1412, 14501, 19631, 50688], "temperature": 0.0, "avg_logprob": -0.1655872388817798, "compression_ratio": 1.748917748917749, "no_speech_prob": 0.0005269398097880185}, {"id": 609, "seek": 343476, "start": 3441.2400000000002, "end": 3447.7200000000003, "text": " right and we need to be careful about this and second is that eventually self-supervision should", "tokens": [50688, 558, 293, 321, 643, 281, 312, 5026, 466, 341, 293, 1150, 307, 300, 4728, 2698, 12, 48172, 6763, 820, 51012], "temperature": 0.0, "avg_logprob": -0.1655872388817798, "compression_ratio": 1.748917748917749, "no_speech_prob": 0.0005269398097880185}, {"id": 610, "seek": 343476, "start": 3447.7200000000003, "end": 3454.2000000000003, "text": " enable us to check the datasets, forget about all these fixed datasets and and learn things continuously", "tokens": [51012, 9528, 505, 281, 1520, 264, 42856, 11, 2870, 466, 439, 613, 6806, 42856, 293, 293, 1466, 721, 15684, 51336], "temperature": 0.0, "avg_logprob": -0.1655872388817798, "compression_ratio": 1.748917748917749, "no_speech_prob": 0.0005269398097880185}, {"id": 611, "seek": 343476, "start": 3455.0800000000004, "end": 3460.36, "text": " and it's you know we're still we're only starting on this direction I think it's very exciting direction", "tokens": [51380, 293, 309, 311, 291, 458, 321, 434, 920, 321, 434, 787, 2891, 322, 341, 3513, 286, 519, 309, 311, 588, 4670, 3513, 51644], "temperature": 0.0, "avg_logprob": -0.1655872388817798, "compression_ratio": 1.748917748917749, "no_speech_prob": 0.0005269398097880185}, {"id": 612, "seek": 346036, "start": 3460.44, "end": 3466.1200000000003, "text": " very exciting problem so I'm hoping people will get excited about it okay thank you very much", "tokens": [50368, 588, 4670, 1154, 370, 286, 478, 7159, 561, 486, 483, 2919, 466, 309, 1392, 1309, 291, 588, 709, 50652], "temperature": 0.0, "avg_logprob": -0.15178360658533432, "compression_ratio": 1.757936507936508, "no_speech_prob": 0.001725109526887536}, {"id": 613, "seek": 346036, "start": 3467.6400000000003, "end": 3470.92, "text": " yeah awesome fantastic talk thanks a lot for all the amazing works", "tokens": [50728, 1338, 3476, 5456, 751, 3231, 257, 688, 337, 439, 264, 2243, 1985, 50892], "temperature": 0.0, "avg_logprob": -0.15178360658533432, "compression_ratio": 1.757936507936508, "no_speech_prob": 0.001725109526887536}, {"id": 614, "seek": 346036, "start": 3472.1200000000003, "end": 3477.2400000000002, "text": " yeah self-supervision is cool and does anybody have some some some question on Zoom maybe let's", "tokens": [50952, 1338, 2698, 12, 48172, 6763, 307, 1627, 293, 775, 4472, 362, 512, 512, 512, 1168, 322, 13453, 1310, 718, 311, 51208], "temperature": 0.0, "avg_logprob": -0.15178360658533432, "compression_ratio": 1.757936507936508, "no_speech_prob": 0.001725109526887536}, {"id": 615, "seek": 346036, "start": 3477.2400000000002, "end": 3480.92, "text": " start with this we have a lot of questions on YouTube but I'm going to start to assume", "tokens": [51208, 722, 365, 341, 321, 362, 257, 688, 295, 1651, 322, 3088, 457, 286, 478, 516, 281, 722, 281, 6552, 51392], "temperature": 0.0, "avg_logprob": -0.15178360658533432, "compression_ratio": 1.757936507936508, "no_speech_prob": 0.001725109526887536}, {"id": 616, "seek": 346036, "start": 3480.92, "end": 3485.8, "text": " I have a lot of questions too but if somebody wants to ask question on Zoom just turn on your video", "tokens": [51392, 286, 362, 257, 688, 295, 1651, 886, 457, 498, 2618, 2738, 281, 1029, 1168, 322, 13453, 445, 1261, 322, 428, 960, 51636], "temperature": 0.0, "avg_logprob": -0.15178360658533432, "compression_ratio": 1.757936507936508, "no_speech_prob": 0.001725109526887536}, {"id": 617, "seek": 348580, "start": 3485.8, "end": 3487.7200000000003, "text": " and and just pick up probably", "tokens": [50364, 293, 293, 445, 1888, 493, 1391, 50460], "temperature": 0.0, "avg_logprob": -0.13609576755099825, "compression_ratio": 1.6582278481012658, "no_speech_prob": 0.00040442252065986395}, {"id": 618, "seek": 348580, "start": 3493.7200000000003, "end": 3500.6000000000004, "text": " I can start with one with a maybe a higher level question first so I mean the challenge", "tokens": [50760, 286, 393, 722, 365, 472, 365, 257, 1310, 257, 2946, 1496, 1168, 700, 370, 286, 914, 264, 3430, 51104], "temperature": 0.0, "avg_logprob": -0.13609576755099825, "compression_ratio": 1.6582278481012658, "no_speech_prob": 0.00040442252065986395}, {"id": 619, "seek": 348580, "start": 3500.6000000000004, "end": 3505.48, "text": " in self-supervision is right you basically have visual data on you let's say correlate patches", "tokens": [51104, 294, 2698, 12, 48172, 6763, 307, 558, 291, 1936, 362, 5056, 1412, 322, 291, 718, 311, 584, 48742, 26531, 51348], "temperature": 0.0, "avg_logprob": -0.13609576755099825, "compression_ratio": 1.6582278481012658, "no_speech_prob": 0.00040442252065986395}, {"id": 620, "seek": 348580, "start": 3505.48, "end": 3510.6000000000004, "text": " with whatever contrastive loss or whatever whatever people do now um I mean what do you", "tokens": [51348, 365, 2035, 8712, 488, 4470, 420, 2035, 2035, 561, 360, 586, 1105, 286, 914, 437, 360, 291, 51604], "temperature": 0.0, "avg_logprob": -0.13609576755099825, "compression_ratio": 1.6582278481012658, "no_speech_prob": 0.00040442252065986395}, {"id": 621, "seek": 348580, "start": 3510.6000000000004, "end": 3514.36, "text": " think about if you're thinking about the 3d world right you have obviously a third dimension", "tokens": [51604, 519, 466, 498, 291, 434, 1953, 466, 264, 805, 67, 1002, 558, 291, 362, 2745, 257, 2636, 10139, 51792], "temperature": 0.0, "avg_logprob": -0.13609576755099825, "compression_ratio": 1.6582278481012658, "no_speech_prob": 0.00040442252065986395}, {"id": 622, "seek": 351436, "start": 3514.92, "end": 3519.56, "text": " is it a smart idea to do this actually all on on images and videos and not think about", "tokens": [50392, 307, 309, 257, 4069, 1558, 281, 360, 341, 767, 439, 322, 322, 5267, 293, 2145, 293, 406, 519, 466, 50624], "temperature": 0.0, "avg_logprob": -0.113403673922078, "compression_ratio": 1.7417840375586855, "no_speech_prob": 0.0029339350294321775}, {"id": 623, "seek": 351436, "start": 3520.28, "end": 3526.6800000000003, "text": " I don't know like kind of project a 3d representation maybe first and then think about how to kind of", "tokens": [50660, 286, 500, 380, 458, 411, 733, 295, 1716, 257, 805, 67, 10290, 1310, 700, 293, 550, 519, 466, 577, 281, 733, 295, 50980], "temperature": 0.0, "avg_logprob": -0.113403673922078, "compression_ratio": 1.7417840375586855, "no_speech_prob": 0.0029339350294321775}, {"id": 624, "seek": 351436, "start": 3526.6800000000003, "end": 3532.2000000000003, "text": " get similarities in some 3d space learn a 3d representation and then you know try to", "tokens": [50980, 483, 24197, 294, 512, 805, 67, 1901, 1466, 257, 805, 67, 10290, 293, 550, 291, 458, 853, 281, 51256], "temperature": 0.0, "avg_logprob": -0.113403673922078, "compression_ratio": 1.7417840375586855, "no_speech_prob": 0.0029339350294321775}, {"id": 625, "seek": 351436, "start": 3532.2000000000003, "end": 3539.0, "text": " channelize with the onscreen tasks later on right right no this is absolutely and and as you know", "tokens": [51256, 2269, 1125, 365, 264, 322, 12439, 9608, 1780, 322, 558, 558, 572, 341, 307, 3122, 293, 293, 382, 291, 458, 51596], "temperature": 0.0, "avg_logprob": -0.113403673922078, "compression_ratio": 1.7417840375586855, "no_speech_prob": 0.0029339350294321775}, {"id": 626, "seek": 353900, "start": 3539.0, "end": 3545.56, "text": " you know I've been I've been angling for for going into 3d you know since since since a long", "tokens": [50364, 291, 458, 286, 600, 668, 286, 600, 668, 2562, 1688, 337, 337, 516, 666, 805, 67, 291, 458, 1670, 1670, 1670, 257, 938, 50692], "temperature": 0.0, "avg_logprob": -0.11233448287815724, "compression_ratio": 1.701834862385321, "no_speech_prob": 0.012235565111041069}, {"id": 627, "seek": 353900, "start": 3545.56, "end": 3551.4, "text": " time ago since our work with Derry Coyne on qualitative 3d I'm a I'm a big fan of 3d in", "tokens": [50692, 565, 2057, 1670, 527, 589, 365, 413, 5318, 383, 939, 716, 322, 31312, 805, 67, 286, 478, 257, 286, 478, 257, 955, 3429, 295, 805, 67, 294, 50984], "temperature": 0.0, "avg_logprob": -0.11233448287815724, "compression_ratio": 1.701834862385321, "no_speech_prob": 0.012235565111041069}, {"id": 628, "seek": 353900, "start": 3551.4, "end": 3557.56, "text": " my heart and it's kind of a little bit sad that once you know once we went to neural networks", "tokens": [50984, 452, 1917, 293, 309, 311, 733, 295, 257, 707, 857, 4227, 300, 1564, 291, 458, 1564, 321, 1437, 281, 18161, 9590, 51292], "temperature": 0.0, "avg_logprob": -0.11233448287815724, "compression_ratio": 1.701834862385321, "no_speech_prob": 0.012235565111041069}, {"id": 629, "seek": 353900, "start": 3557.56, "end": 3562.84, "text": " the kind of things dropped back to 2d plane for a while and now of course they're they're coming", "tokens": [51292, 264, 733, 295, 721, 8119, 646, 281, 568, 67, 5720, 337, 257, 1339, 293, 586, 295, 1164, 436, 434, 436, 434, 1348, 51556], "temperature": 0.0, "avg_logprob": -0.11233448287815724, "compression_ratio": 1.701834862385321, "no_speech_prob": 0.012235565111041069}, {"id": 630, "seek": 356284, "start": 3562.84, "end": 3571.0, "text": " back again um okay so there's there's two answers to this question one the final you know the the", "tokens": [50364, 646, 797, 1105, 1392, 370, 456, 311, 456, 311, 732, 6338, 281, 341, 1168, 472, 264, 2572, 291, 458, 264, 264, 50772], "temperature": 0.0, "avg_logprob": -0.09509897943752915, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.016387244686484337}, {"id": 631, "seek": 356284, "start": 3571.0, "end": 3582.1200000000003, "text": " ultimate answer is that 3d should emerge from our 2d of observation that the representation", "tokens": [50772, 9705, 1867, 307, 300, 805, 67, 820, 21511, 490, 527, 568, 67, 295, 14816, 300, 264, 10290, 51328], "temperature": 0.0, "avg_logprob": -0.09509897943752915, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.016387244686484337}, {"id": 632, "seek": 356284, "start": 3582.1200000000003, "end": 3592.6800000000003, "text": " should figure out 3d on its own okay uh just like it's done with humans right humans are only seeing", "tokens": [51328, 820, 2573, 484, 805, 67, 322, 1080, 1065, 1392, 2232, 445, 411, 309, 311, 1096, 365, 6255, 558, 6255, 366, 787, 2577, 51856], "temperature": 0.0, "avg_logprob": -0.09509897943752915, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.016387244686484337}, {"id": 633, "seek": 359284, "start": 3593.48, "end": 3599.32, "text": " 2d projections of the 3d world okay if you have stereo maybe you have a little bit of 3d but", "tokens": [50396, 568, 67, 32371, 295, 264, 805, 67, 1002, 1392, 498, 291, 362, 29029, 1310, 291, 362, 257, 707, 857, 295, 805, 67, 457, 50688], "temperature": 0.0, "avg_logprob": -0.06327676773071289, "compression_ratio": 1.7370892018779343, "no_speech_prob": 0.0025093709118664265}, {"id": 634, "seek": 359284, "start": 3599.32, "end": 3603.6400000000003, "text": " you know I don't have stereo for example 10 percent of people in the world don't have stereo", "tokens": [50688, 291, 458, 286, 500, 380, 362, 29029, 337, 1365, 1266, 3043, 295, 561, 294, 264, 1002, 500, 380, 362, 29029, 50904], "temperature": 0.0, "avg_logprob": -0.06327676773071289, "compression_ratio": 1.7370892018779343, "no_speech_prob": 0.0025093709118664265}, {"id": 635, "seek": 359284, "start": 3603.6400000000003, "end": 3611.32, "text": " and we are perfectly fine seeing 3d okay so we learn 3d from uh from from a series of 2d", "tokens": [50904, 293, 321, 366, 6239, 2489, 2577, 805, 67, 1392, 370, 321, 1466, 805, 67, 490, 2232, 490, 490, 257, 2638, 295, 568, 67, 51288], "temperature": 0.0, "avg_logprob": -0.06327676773071289, "compression_ratio": 1.7370892018779343, "no_speech_prob": 0.0025093709118664265}, {"id": 636, "seek": 359284, "start": 3611.32, "end": 3618.84, "text": " representations uh and I think if we if we go from you know collections of images like ImageNet", "tokens": [51288, 33358, 2232, 293, 286, 519, 498, 321, 498, 321, 352, 490, 291, 458, 16641, 295, 5267, 411, 29903, 31890, 51664], "temperature": 0.0, "avg_logprob": -0.06327676773071289, "compression_ratio": 1.7370892018779343, "no_speech_prob": 0.0025093709118664265}, {"id": 637, "seek": 361884, "start": 3618.84, "end": 3628.84, "text": " to videos for example hopefully and I'm very hoping that like it will encourage 3d to automatically", "tokens": [50364, 281, 2145, 337, 1365, 4696, 293, 286, 478, 588, 7159, 300, 411, 309, 486, 5373, 805, 67, 281, 6772, 50864], "temperature": 0.0, "avg_logprob": -0.0959056990487235, "compression_ratio": 1.6408839779005524, "no_speech_prob": 0.0018375312210991979}, {"id": 638, "seek": 361884, "start": 3628.84, "end": 3637.96, "text": " emerge as as the you know inside of the representation okay so that's kind of a the the the the the", "tokens": [50864, 21511, 382, 382, 264, 291, 458, 1854, 295, 264, 10290, 1392, 370, 300, 311, 733, 295, 257, 264, 264, 264, 264, 264, 51320], "temperature": 0.0, "avg_logprob": -0.0959056990487235, "compression_ratio": 1.6408839779005524, "no_speech_prob": 0.0018375312210991979}, {"id": 639, "seek": 361884, "start": 3637.96, "end": 3644.52, "text": " glorious answer at the end of the rainbow okay uh but of course this is this is very hard this is", "tokens": [51320, 24026, 1867, 412, 264, 917, 295, 264, 18526, 1392, 2232, 457, 295, 1164, 341, 307, 341, 307, 588, 1152, 341, 307, 51648], "temperature": 0.0, "avg_logprob": -0.0959056990487235, "compression_ratio": 1.6408839779005524, "no_speech_prob": 0.0018375312210991979}, {"id": 640, "seek": 364452, "start": 3644.52, "end": 3650.04, "text": " kind of a a very tall order uh you know we are seeing a little bit of this happening we are seeing", "tokens": [50364, 733, 295, 257, 257, 588, 6764, 1668, 2232, 291, 458, 321, 366, 2577, 257, 707, 857, 295, 341, 2737, 321, 366, 2577, 50640], "temperature": 0.0, "avg_logprob": -0.11283792194567228, "compression_ratio": 1.9447236180904524, "no_speech_prob": 0.004606516100466251}, {"id": 641, "seek": 364452, "start": 3650.04, "end": 3655.88, "text": " a little bit of kind of a maybe two and a half two or two point one d kind of occlusion occlusion", "tokens": [50640, 257, 707, 857, 295, 733, 295, 257, 1310, 732, 293, 257, 1922, 732, 420, 732, 935, 472, 274, 733, 295, 2678, 6485, 2678, 6485, 50932], "temperature": 0.0, "avg_logprob": -0.11283792194567228, "compression_ratio": 1.9447236180904524, "no_speech_prob": 0.004606516100466251}, {"id": 642, "seek": 364452, "start": 3655.88, "end": 3663.72, "text": " reasoning you know figure ground reasoning uh a little bit of of that but but but it we're", "tokens": [50932, 21577, 291, 458, 2573, 2727, 21577, 2232, 257, 707, 857, 295, 295, 300, 457, 457, 457, 309, 321, 434, 51324], "temperature": 0.0, "avg_logprob": -0.11283792194567228, "compression_ratio": 1.9447236180904524, "no_speech_prob": 0.004606516100466251}, {"id": 643, "seek": 364452, "start": 3663.72, "end": 3669.64, "text": " they're definitely far away from that right and so the second direction is okay can we kind of help", "tokens": [51324, 436, 434, 2138, 1400, 1314, 490, 300, 558, 293, 370, 264, 1150, 3513, 307, 1392, 393, 321, 733, 295, 854, 51620], "temperature": 0.0, "avg_logprob": -0.11283792194567228, "compression_ratio": 1.9447236180904524, "no_speech_prob": 0.004606516100466251}, {"id": 644, "seek": 366964, "start": 3669.64, "end": 3678.7599999999998, "text": " it out a little bit how can we can we provide features that are more amenable to to to three", "tokens": [50364, 309, 484, 257, 707, 857, 577, 393, 321, 393, 321, 2893, 4122, 300, 366, 544, 18497, 712, 281, 281, 281, 1045, 50820], "temperature": 0.0, "avg_logprob": -0.14339710289323834, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.007227955386042595}, {"id": 645, "seek": 366964, "start": 3678.7599999999998, "end": 3687.24, "text": " dimensional manipulation and there I think uh things like like like holo-gan or or pie-gan this", "tokens": [50820, 18795, 26475, 293, 456, 286, 519, 2232, 721, 411, 411, 411, 4091, 78, 12, 1275, 420, 420, 1730, 12, 1275, 341, 51244], "temperature": 0.0, "avg_logprob": -0.14339710289323834, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.007227955386042595}, {"id": 646, "seek": 366964, "start": 3687.24, "end": 3694.52, "text": " kind of directions are I think very exciting in in that it's kind of you you can inject some things", "tokens": [51244, 733, 295, 11095, 366, 286, 519, 588, 4670, 294, 294, 300, 309, 311, 733, 295, 291, 291, 393, 10711, 512, 721, 51608], "temperature": 0.0, "avg_logprob": -0.14339710289323834, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.007227955386042595}, {"id": 647, "seek": 369452, "start": 3694.52, "end": 3701.64, "text": " that you know are physically true like rotation for example and and uh and so I think I think in the", "tokens": [50364, 300, 291, 458, 366, 9762, 2074, 411, 12447, 337, 1365, 293, 293, 2232, 293, 370, 286, 519, 286, 519, 294, 264, 50720], "temperature": 0.0, "avg_logprob": -0.06135607738884128, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.0070051285438239574}, {"id": 648, "seek": 369452, "start": 3701.64, "end": 3709.08, "text": " short in the short uh uh uh short term all of those things are I think going to be extremely", "tokens": [50720, 2099, 294, 264, 2099, 2232, 2232, 2232, 2099, 1433, 439, 295, 729, 721, 366, 286, 519, 516, 281, 312, 4664, 51092], "temperature": 0.0, "avg_logprob": -0.06135607738884128, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.0070051285438239574}, {"id": 649, "seek": 369452, "start": 3709.08, "end": 3715.64, "text": " helpful in the long term I'm still kind of hoping that I can learn 3d from scratch okay but who knows", "tokens": [51092, 4961, 294, 264, 938, 1433, 286, 478, 920, 733, 295, 7159, 300, 286, 393, 1466, 805, 67, 490, 8459, 1392, 457, 567, 3255, 51420], "temperature": 0.0, "avg_logprob": -0.06135607738884128, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.0070051285438239574}, {"id": 650, "seek": 369452, "start": 3715.64, "end": 3721.16, "text": " maybe it's too much to ask but I'm still kind of hoping that one day I will wake up in the morning", "tokens": [51420, 1310, 309, 311, 886, 709, 281, 1029, 457, 286, 478, 920, 733, 295, 7159, 300, 472, 786, 286, 486, 6634, 493, 294, 264, 2446, 51696], "temperature": 0.0, "avg_logprob": -0.06135607738884128, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.0070051285438239574}, {"id": 651, "seek": 372116, "start": 3721.16, "end": 3727.56, "text": " and boom my computer learned 3d but we'll see do it with two cameras right we have stereo that's I", "tokens": [50364, 293, 9351, 452, 3820, 3264, 805, 67, 457, 321, 603, 536, 360, 309, 365, 732, 8622, 558, 321, 362, 29029, 300, 311, 286, 50684], "temperature": 0.0, "avg_logprob": -0.17532730102539062, "compression_ratio": 1.7396449704142012, "no_speech_prob": 0.009701655246317387}, {"id": 652, "seek": 372116, "start": 3727.56, "end": 3735.56, "text": " mean that's the thing but I don't have stereo for example right like 10 percent of people don't", "tokens": [50684, 914, 300, 311, 264, 551, 457, 286, 500, 380, 362, 29029, 337, 1365, 558, 411, 1266, 3043, 295, 561, 500, 380, 51084], "temperature": 0.0, "avg_logprob": -0.17532730102539062, "compression_ratio": 1.7396449704142012, "no_speech_prob": 0.009701655246317387}, {"id": 653, "seek": 372116, "start": 3735.56, "end": 3745.08, "text": " have stereo stereo is actually not as important as as as as we we we we think stereo is only really", "tokens": [51084, 362, 29029, 29029, 307, 767, 406, 382, 1021, 382, 382, 382, 382, 321, 321, 321, 321, 519, 29029, 307, 787, 534, 51560], "temperature": 0.0, "avg_logprob": -0.17532730102539062, "compression_ratio": 1.7396449704142012, "no_speech_prob": 0.009701655246317387}, {"id": 654, "seek": 374508, "start": 3745.96, "end": 3750.44, "text": " important for like the you know half a meter in front of you it's like it's you know what", "tokens": [50408, 1021, 337, 411, 264, 291, 458, 1922, 257, 9255, 294, 1868, 295, 291, 309, 311, 411, 309, 311, 291, 458, 437, 50632], "temperature": 0.0, "avg_logprob": -0.0940687997000558, "compression_ratio": 1.8221343873517786, "no_speech_prob": 0.05333768576383591}, {"id": 655, "seek": 374508, "start": 3750.44, "end": 3755.48, "text": " what is it that I cannot do that everybody else can do okay I cannot put you know thread through", "tokens": [50632, 437, 307, 309, 300, 286, 2644, 360, 300, 2201, 1646, 393, 360, 1392, 286, 2644, 829, 291, 458, 7207, 807, 50884], "temperature": 0.0, "avg_logprob": -0.0940687997000558, "compression_ratio": 1.8221343873517786, "no_speech_prob": 0.05333768576383591}, {"id": 656, "seek": 374508, "start": 3755.48, "end": 3761.3199999999997, "text": " the needle and I have trouble you know pouring wine right other than that I'm fine so really it", "tokens": [50884, 264, 11037, 293, 286, 362, 5253, 291, 458, 20450, 7209, 558, 661, 813, 300, 286, 478, 2489, 370, 534, 309, 51176], "temperature": 0.0, "avg_logprob": -0.0940687997000558, "compression_ratio": 1.8221343873517786, "no_speech_prob": 0.05333768576383591}, {"id": 657, "seek": 374508, "start": 3761.3199999999997, "end": 3767.56, "text": " stereo is kind of over overemphasized I think it's really parallax is much more important", "tokens": [51176, 29029, 307, 733, 295, 670, 38657, 76, 7485, 1602, 286, 519, 309, 311, 534, 8069, 2797, 307, 709, 544, 1021, 51488], "temperature": 0.0, "avg_logprob": -0.0940687997000558, "compression_ratio": 1.8221343873517786, "no_speech_prob": 0.05333768576383591}, {"id": 658, "seek": 374508, "start": 3767.56, "end": 3773.72, "text": " and parallax you can get from from video no good point I have another follow-up question", "tokens": [51488, 293, 8069, 2797, 291, 393, 483, 490, 490, 960, 572, 665, 935, 286, 362, 1071, 1524, 12, 1010, 1168, 51796], "temperature": 0.0, "avg_logprob": -0.0940687997000558, "compression_ratio": 1.8221343873517786, "no_speech_prob": 0.05333768576383591}, {"id": 659, "seek": 377372, "start": 3773.72, "end": 3779.56, "text": " um so in the similar spirit right like one argument is you can do contrastive learning", "tokens": [50364, 1105, 370, 294, 264, 2531, 3797, 558, 411, 472, 6770, 307, 291, 393, 360, 8712, 488, 2539, 50656], "temperature": 0.0, "avg_logprob": -0.11156123818703068, "compression_ratio": 1.7509578544061302, "no_speech_prob": 0.0046796659007668495}, {"id": 660, "seek": 377372, "start": 3779.56, "end": 3783.72, "text": " and mostly it's about comparing things right you're saying one versus all classifiers like", "tokens": [50656, 293, 5240, 309, 311, 466, 15763, 721, 558, 291, 434, 1566, 472, 5717, 439, 1508, 23463, 411, 50864], "temperature": 0.0, "avg_logprob": -0.11156123818703068, "compression_ratio": 1.7509578544061302, "no_speech_prob": 0.0046796659007668495}, {"id": 661, "seek": 377372, "start": 3783.72, "end": 3788.4399999999996, "text": " how similar are these things I mean what about going back to the original things when people", "tokens": [50864, 577, 2531, 366, 613, 721, 286, 914, 437, 466, 516, 646, 281, 264, 3380, 721, 562, 561, 51100], "temperature": 0.0, "avg_logprob": -0.11156123818703068, "compression_ratio": 1.7509578544061302, "no_speech_prob": 0.0046796659007668495}, {"id": 662, "seek": 377372, "start": 3788.4399999999996, "end": 3792.7599999999998, "text": " using like auto encoders for pre-training and so on for like basically using generative tasks", "tokens": [51100, 1228, 411, 8399, 2058, 378, 433, 337, 659, 12, 17227, 1760, 293, 370, 322, 337, 411, 1936, 1228, 1337, 1166, 9608, 51316], "temperature": 0.0, "avg_logprob": -0.11156123818703068, "compression_ratio": 1.7509578544061302, "no_speech_prob": 0.0046796659007668495}, {"id": 663, "seek": 377372, "start": 3792.7599999999998, "end": 3798.7599999999998, "text": " let's say oh I train my favorite game how good of a representation can I learn from learning", "tokens": [51316, 718, 311, 584, 1954, 286, 3847, 452, 2954, 1216, 577, 665, 295, 257, 10290, 393, 286, 1466, 490, 2539, 51616], "temperature": 0.0, "avg_logprob": -0.11156123818703068, "compression_ratio": 1.7509578544061302, "no_speech_prob": 0.0046796659007668495}, {"id": 664, "seek": 379876, "start": 3798.76, "end": 3803.8, "text": " the distribution basically right like how well like it's like this famous thing like you have to", "tokens": [50364, 264, 7316, 1936, 558, 411, 577, 731, 411, 309, 311, 411, 341, 4618, 551, 411, 291, 362, 281, 50616], "temperature": 0.0, "avg_logprob": -0.11399125478353846, "compression_ratio": 1.722488038277512, "no_speech_prob": 0.004680312238633633}, {"id": 665, "seek": 379876, "start": 3803.8, "end": 3809.6400000000003, "text": " be able to create in order to understand and where to see that competing or maybe going", "tokens": [50616, 312, 1075, 281, 1884, 294, 1668, 281, 1223, 293, 689, 281, 536, 300, 15439, 420, 1310, 516, 50908], "temperature": 0.0, "avg_logprob": -0.11399125478353846, "compression_ratio": 1.722488038277512, "no_speech_prob": 0.004680312238633633}, {"id": 666, "seek": 379876, "start": 3809.6400000000003, "end": 3813.1600000000003, "text": " going along the same line so what's your take channel is speaking on the lines there", "tokens": [50908, 516, 2051, 264, 912, 1622, 370, 437, 311, 428, 747, 2269, 307, 4124, 322, 264, 3876, 456, 51084], "temperature": 0.0, "avg_logprob": -0.11399125478353846, "compression_ratio": 1.722488038277512, "no_speech_prob": 0.004680312238633633}, {"id": 667, "seek": 379876, "start": 3815.0800000000004, "end": 3822.36, "text": " um I mean yeah I mean yeah we have definitely been also using out encoders as well I think", "tokens": [51180, 1105, 286, 914, 1338, 286, 914, 1338, 321, 362, 2138, 668, 611, 1228, 484, 2058, 378, 433, 382, 731, 286, 519, 51544], "temperature": 0.0, "avg_logprob": -0.11399125478353846, "compression_ratio": 1.722488038277512, "no_speech_prob": 0.004680312238633633}, {"id": 668, "seek": 382236, "start": 3822.36, "end": 3831.6400000000003, "text": " with an outer encoder it's a little bit of a it's a little bit of a of a magic box like if you", "tokens": [50364, 365, 364, 10847, 2058, 19866, 309, 311, 257, 707, 857, 295, 257, 309, 311, 257, 707, 857, 295, 257, 295, 257, 5585, 2424, 411, 498, 291, 50828], "temperature": 0.0, "avg_logprob": -0.10072763929975793, "compression_ratio": 1.9195979899497488, "no_speech_prob": 0.001926147029735148}, {"id": 669, "seek": 382236, "start": 3831.6400000000003, "end": 3836.92, "text": " know if you get really lucky your outer encoder is going to capture exactly the right things", "tokens": [50828, 458, 498, 291, 483, 534, 6356, 428, 10847, 2058, 19866, 307, 516, 281, 7983, 2293, 264, 558, 721, 51092], "temperature": 0.0, "avg_logprob": -0.10072763929975793, "compression_ratio": 1.9195979899497488, "no_speech_prob": 0.001926147029735148}, {"id": 670, "seek": 382236, "start": 3836.92, "end": 3840.84, "text": " and if you get unlikely it will capture all exactly the wrong things right it's it's kind of", "tokens": [51092, 293, 498, 291, 483, 17518, 309, 486, 7983, 439, 2293, 264, 2085, 721, 558, 309, 311, 309, 311, 733, 295, 51288], "temperature": 0.0, "avg_logprob": -0.10072763929975793, "compression_ratio": 1.9195979899497488, "no_speech_prob": 0.001926147029735148}, {"id": 671, "seek": 382236, "start": 3840.84, "end": 3847.7200000000003, "text": " it's a compression mechanism it somehow compresses your data and and it it really depends on what you", "tokens": [51288, 309, 311, 257, 19355, 7513, 309, 6063, 14778, 279, 428, 1412, 293, 293, 309, 309, 534, 5946, 322, 437, 291, 51632], "temperature": 0.0, "avg_logprob": -0.10072763929975793, "compression_ratio": 1.9195979899497488, "no_speech_prob": 0.001926147029735148}, {"id": 672, "seek": 384772, "start": 3847.72, "end": 3853.8799999999997, "text": " care about like sometimes it will compress the away the stuff that you care about or sometimes it", "tokens": [50364, 1127, 466, 411, 2171, 309, 486, 14778, 264, 1314, 264, 1507, 300, 291, 1127, 466, 420, 2171, 309, 50672], "temperature": 0.0, "avg_logprob": -0.07554186658656344, "compression_ratio": 2.0526315789473686, "no_speech_prob": 0.017434721812605858}, {"id": 673, "seek": 384772, "start": 3853.8799999999997, "end": 3859.3999999999996, "text": " will retain the stuff that you care about and it's it's a little bit hard to control what it's going", "tokens": [50672, 486, 18340, 264, 1507, 300, 291, 1127, 466, 293, 309, 311, 309, 311, 257, 707, 857, 1152, 281, 1969, 437, 309, 311, 516, 50948], "temperature": 0.0, "avg_logprob": -0.07554186658656344, "compression_ratio": 2.0526315789473686, "no_speech_prob": 0.017434721812605858}, {"id": 674, "seek": 384772, "start": 3859.3999999999996, "end": 3868.2, "text": " to do so I think I think this kind of a similarity learning is it allows you to get a little bit", "tokens": [50948, 281, 360, 370, 286, 519, 286, 519, 341, 733, 295, 257, 32194, 2539, 307, 309, 4045, 291, 281, 483, 257, 707, 857, 51388], "temperature": 0.0, "avg_logprob": -0.07554186658656344, "compression_ratio": 2.0526315789473686, "no_speech_prob": 0.017434721812605858}, {"id": 675, "seek": 384772, "start": 3868.2, "end": 3874.52, "text": " more control and a little bit of more of kind of a intuition about what is it what is it being", "tokens": [51388, 544, 1969, 293, 257, 707, 857, 295, 544, 295, 733, 295, 257, 24002, 466, 437, 307, 309, 437, 307, 309, 885, 51704], "temperature": 0.0, "avg_logprob": -0.07554186658656344, "compression_ratio": 2.0526315789473686, "no_speech_prob": 0.017434721812605858}, {"id": 676, "seek": 387452, "start": 3875.16, "end": 3879.24, "text": " what is it that's being learned it's also kind of a has a very nice connection to kind of to", "tokens": [50396, 437, 307, 309, 300, 311, 885, 3264, 309, 311, 611, 733, 295, 257, 575, 257, 588, 1481, 4984, 281, 733, 295, 281, 50600], "temperature": 0.0, "avg_logprob": -0.10810302128301602, "compression_ratio": 2.112676056338028, "no_speech_prob": 0.012031003832817078}, {"id": 677, "seek": 387452, "start": 3879.24, "end": 3883.8, "text": " graphs and graph theory that kind of think you you think about it like you have different", "tokens": [50600, 24877, 293, 4295, 5261, 300, 733, 295, 519, 291, 291, 519, 466, 309, 411, 291, 362, 819, 50828], "temperature": 0.0, "avg_logprob": -0.10810302128301602, "compression_ratio": 2.112676056338028, "no_speech_prob": 0.012031003832817078}, {"id": 678, "seek": 387452, "start": 3883.8, "end": 3888.36, "text": " entities and then you have kind of you can think of it like as a as like an as a like a network", "tokens": [50828, 16667, 293, 550, 291, 362, 733, 295, 291, 393, 519, 295, 309, 411, 382, 257, 382, 411, 364, 382, 257, 411, 257, 3209, 51056], "temperature": 0.0, "avg_logprob": -0.10810302128301602, "compression_ratio": 2.112676056338028, "no_speech_prob": 0.012031003832817078}, {"id": 679, "seek": 387452, "start": 3888.36, "end": 3895.0, "text": " right like a like a uh a social network for example where you you can think of different", "tokens": [51056, 558, 411, 257, 411, 257, 2232, 257, 2093, 3209, 337, 1365, 689, 291, 291, 393, 519, 295, 819, 51388], "temperature": 0.0, "avg_logprob": -0.10810302128301602, "compression_ratio": 2.112676056338028, "no_speech_prob": 0.012031003832817078}, {"id": 680, "seek": 387452, "start": 3895.0, "end": 3899.64, "text": " people being connected in different ways and you can think about yeah we call them", "tokens": [51388, 561, 885, 4582, 294, 819, 2098, 293, 291, 393, 519, 466, 1338, 321, 818, 552, 51620], "temperature": 0.0, "avg_logprob": -0.10810302128301602, "compression_ratio": 2.112676056338028, "no_speech_prob": 0.012031003832817078}, {"id": 681, "seek": 389964, "start": 3899.64, "end": 3906.04, "text": " senses of similarity so there's many different senses of similarity between two instances and", "tokens": [50364, 17057, 295, 32194, 370, 456, 311, 867, 819, 17057, 295, 32194, 1296, 732, 14519, 293, 50684], "temperature": 0.0, "avg_logprob": -0.10496952954460592, "compression_ratio": 1.8288973384030418, "no_speech_prob": 0.0030710555147379637}, {"id": 682, "seek": 389964, "start": 3906.04, "end": 3909.96, "text": " you know something like an out encoder is probably going to collapse them all together and here you", "tokens": [50684, 291, 458, 746, 411, 364, 484, 2058, 19866, 307, 1391, 516, 281, 15584, 552, 439, 1214, 293, 510, 291, 50880], "temperature": 0.0, "avg_logprob": -0.10496952954460592, "compression_ratio": 1.8288973384030418, "no_speech_prob": 0.0030710555147379637}, {"id": 683, "seek": 389964, "start": 3909.96, "end": 3914.44, "text": " can actually separate them you can have a similarity in color similarity in texture maybe", "tokens": [50880, 393, 767, 4994, 552, 291, 393, 362, 257, 32194, 294, 2017, 32194, 294, 8091, 1310, 51104], "temperature": 0.0, "avg_logprob": -0.10496952954460592, "compression_ratio": 1.8288973384030418, "no_speech_prob": 0.0030710555147379637}, {"id": 684, "seek": 389964, "start": 3914.44, "end": 3921.72, "text": " similarity in 3d and they're all can be kind of exposed hopefully separately now that's interesting", "tokens": [51104, 32194, 294, 805, 67, 293, 436, 434, 439, 393, 312, 733, 295, 9495, 4696, 14759, 586, 300, 311, 1880, 51468], "temperature": 0.0, "avg_logprob": -0.10496952954460592, "compression_ratio": 1.8288973384030418, "no_speech_prob": 0.0030710555147379637}, {"id": 685, "seek": 389964, "start": 3921.72, "end": 3926.2, "text": " I mean our experiences so we've done a lot of stuff on like shape completion in 3d so whenever we", "tokens": [51468, 286, 914, 527, 5235, 370, 321, 600, 1096, 257, 688, 295, 1507, 322, 411, 3909, 19372, 294, 805, 67, 370, 5699, 321, 51692], "temperature": 0.0, "avg_logprob": -0.10496952954460592, "compression_ratio": 1.8288973384030418, "no_speech_prob": 0.0030710555147379637}, {"id": 686, "seek": 392620, "start": 3926.2, "end": 3931.0, "text": " had the ability to take stuff away and predict it then we got great features this was always amazing", "tokens": [50364, 632, 264, 3485, 281, 747, 1507, 1314, 293, 6069, 309, 550, 321, 658, 869, 4122, 341, 390, 1009, 2243, 50604], "temperature": 0.0, "avg_logprob": -0.09967290370836171, "compression_ratio": 1.8150943396226416, "no_speech_prob": 0.0030722159426659346}, {"id": 687, "seek": 392620, "start": 3931.0, "end": 3936.2799999999997, "text": " in terms of using these features to help semantics and whenever we're trying to classify it to help", "tokens": [50604, 294, 2115, 295, 1228, 613, 4122, 281, 854, 4361, 45298, 293, 5699, 321, 434, 1382, 281, 33872, 309, 281, 854, 50868], "temperature": 0.0, "avg_logprob": -0.09967290370836171, "compression_ratio": 1.8150943396226416, "no_speech_prob": 0.0030722159426659346}, {"id": 688, "seek": 392620, "start": 3936.2799999999997, "end": 3940.7599999999998, "text": " the completion this is this is always a total disaster it never worked we tried really hard", "tokens": [50868, 264, 19372, 341, 307, 341, 307, 1009, 257, 3217, 11293, 309, 1128, 2732, 321, 3031, 534, 1152, 51092], "temperature": 0.0, "avg_logprob": -0.09967290370836171, "compression_ratio": 1.8150943396226416, "no_speech_prob": 0.0030722159426659346}, {"id": 689, "seek": 392620, "start": 3940.7599999999998, "end": 3948.3599999999997, "text": " actually I mean I think that that's that's been our our experience as well but but I think have", "tokens": [51092, 767, 286, 914, 286, 519, 300, 300, 311, 300, 311, 668, 527, 527, 1752, 382, 731, 457, 457, 286, 519, 362, 51472], "temperature": 0.0, "avg_logprob": -0.09967290370836171, "compression_ratio": 1.8150943396226416, "no_speech_prob": 0.0030722159426659346}, {"id": 690, "seek": 392620, "start": 3948.3599999999997, "end": 3955.16, "text": " you have you tried the latest uh contrastive learning because it's really it's to me the way", "tokens": [51472, 291, 362, 291, 3031, 264, 6792, 2232, 8712, 488, 2539, 570, 309, 311, 534, 309, 311, 281, 385, 264, 636, 51812], "temperature": 0.0, "avg_logprob": -0.09967290370836171, "compression_ratio": 1.8150943396226416, "no_speech_prob": 0.0030722159426659346}, {"id": 691, "seek": 395516, "start": 3955.16, "end": 3962.04, "text": " I think about contrastive learning is it's really just old school triplet loss you know uh Siamese", "tokens": [50364, 286, 519, 466, 8712, 488, 2539, 307, 309, 311, 534, 445, 1331, 1395, 1376, 14657, 4470, 291, 458, 2232, 318, 2918, 1130, 50708], "temperature": 0.0, "avg_logprob": -0.1255732255823472, "compression_ratio": 1.8405797101449275, "no_speech_prob": 0.0012444311287254095}, {"id": 692, "seek": 395516, "start": 3962.04, "end": 3970.92, "text": " network learning except you're switching from from from from kind of a regression to to a", "tokens": [50708, 3209, 2539, 3993, 291, 434, 16493, 490, 490, 490, 490, 733, 295, 257, 24590, 281, 281, 257, 51152], "temperature": 0.0, "avg_logprob": -0.1255732255823472, "compression_ratio": 1.8405797101449275, "no_speech_prob": 0.0012444311287254095}, {"id": 693, "seek": 395516, "start": 3970.92, "end": 3977.48, "text": " classification but it's a classification with like huge amounts of data and it's very very fine", "tokens": [51152, 21538, 457, 309, 311, 257, 21538, 365, 411, 2603, 11663, 295, 1412, 293, 309, 311, 588, 588, 2489, 51480], "temperature": 0.0, "avg_logprob": -0.1255732255823472, "compression_ratio": 1.8405797101449275, "no_speech_prob": 0.0012444311287254095}, {"id": 694, "seek": 395516, "start": 3977.48, "end": 3983.72, "text": " grain classification so it's almost it's it's really not like your your grandma's classification", "tokens": [51480, 12837, 21538, 370, 309, 311, 1920, 309, 311, 309, 311, 534, 406, 411, 428, 428, 15766, 311, 21538, 51792], "temperature": 0.0, "avg_logprob": -0.1255732255823472, "compression_ratio": 1.8405797101449275, "no_speech_prob": 0.0012444311287254095}, {"id": 695, "seek": 398372, "start": 3983.7999999999997, "end": 3990.2, "text": " it's uh I mean we we did something like this for for uh for when we did colorization so we we first", "tokens": [50368, 309, 311, 2232, 286, 914, 321, 321, 630, 746, 411, 341, 337, 337, 2232, 337, 562, 321, 630, 2017, 2144, 370, 321, 321, 700, 50688], "temperature": 0.0, "avg_logprob": -0.09348252545232358, "compression_ratio": 1.8246445497630333, "no_speech_prob": 0.003878801129758358}, {"id": 696, "seek": 398372, "start": 3990.2, "end": 3995.9599999999996, "text": " we tried to do colorization with the regression and then we we we we got better results by doing", "tokens": [50688, 321, 3031, 281, 360, 2017, 2144, 365, 264, 24590, 293, 550, 321, 321, 321, 321, 658, 1101, 3542, 538, 884, 50976], "temperature": 0.0, "avg_logprob": -0.09348252545232358, "compression_ratio": 1.8246445497630333, "no_speech_prob": 0.003878801129758358}, {"id": 697, "seek": 398372, "start": 3995.9599999999996, "end": 4002.9199999999996, "text": " classification but the classification was across like you know 500 classes of different colors", "tokens": [50976, 21538, 457, 264, 21538, 390, 2108, 411, 291, 458, 5923, 5359, 295, 819, 4577, 51324], "temperature": 0.0, "avg_logprob": -0.09348252545232358, "compression_ratio": 1.8246445497630333, "no_speech_prob": 0.003878801129758358}, {"id": 698, "seek": 398372, "start": 4002.9199999999996, "end": 4009.48, "text": " in the in the in the color gamut right so it's it's a much more kind of narrow thing and that", "tokens": [51324, 294, 264, 294, 264, 294, 264, 2017, 8019, 325, 558, 370, 309, 311, 309, 311, 257, 709, 544, 733, 295, 9432, 551, 293, 300, 51652], "temperature": 0.0, "avg_logprob": -0.09348252545232358, "compression_ratio": 1.8246445497630333, "no_speech_prob": 0.003878801129758358}, {"id": 699, "seek": 400948, "start": 4009.48, "end": 4014.28, "text": " seemed to work for us but yeah like if you have a few classes then then then it's very hard to", "tokens": [50364, 6576, 281, 589, 337, 505, 457, 1338, 411, 498, 291, 362, 257, 1326, 5359, 550, 550, 550, 309, 311, 588, 1152, 281, 50604], "temperature": 0.0, "avg_logprob": -0.10638346523046494, "compression_ratio": 1.96113074204947, "no_speech_prob": 0.002215362386777997}, {"id": 700, "seek": 400948, "start": 4014.28, "end": 4019.2400000000002, "text": " make it work but if you do something like either have lots of classes or do something like like", "tokens": [50604, 652, 309, 589, 457, 498, 291, 360, 746, 411, 2139, 362, 3195, 295, 5359, 420, 360, 746, 411, 411, 50852], "temperature": 0.0, "avg_logprob": -0.10638346523046494, "compression_ratio": 1.96113074204947, "no_speech_prob": 0.002215362386777997}, {"id": 701, "seek": 400948, "start": 4019.2400000000002, "end": 4025.08, "text": " contrastive learning where it's basically just really kind of push it with data yet it seems to", "tokens": [50852, 8712, 488, 2539, 689, 309, 311, 1936, 445, 534, 733, 295, 2944, 309, 365, 1412, 1939, 309, 2544, 281, 51144], "temperature": 0.0, "avg_logprob": -0.10638346523046494, "compression_ratio": 1.96113074204947, "no_speech_prob": 0.002215362386777997}, {"id": 702, "seek": 400948, "start": 4025.08, "end": 4029.2400000000002, "text": " to work for us now we've actually tried that so we had we had one one student project actually", "tokens": [51144, 281, 589, 337, 505, 586, 321, 600, 767, 3031, 300, 370, 321, 632, 321, 632, 472, 472, 3107, 1716, 767, 51352], "temperature": 0.0, "avg_logprob": -0.10638346523046494, "compression_ratio": 1.96113074204947, "no_speech_prob": 0.002215362386777997}, {"id": 703, "seek": 400948, "start": 4029.2400000000002, "end": 4032.92, "text": " in collaboration with fair so Chihu one of my students they've been working on basically", "tokens": [51352, 294, 9363, 365, 3143, 370, 761, 44344, 472, 295, 452, 1731, 436, 600, 668, 1364, 322, 1936, 51536], "temperature": 0.0, "avg_logprob": -0.10638346523046494, "compression_ratio": 1.96113074204947, "no_speech_prob": 0.002215362386777997}, {"id": 704, "seek": 400948, "start": 4034.68, "end": 4038.04, "text": " basically doing contrastive learning for pre-training 3d structures and in a similar", "tokens": [51624, 1936, 884, 8712, 488, 2539, 337, 659, 12, 17227, 1760, 805, 67, 9227, 293, 294, 257, 2531, 51792], "temperature": 0.0, "avg_logprob": -0.10638346523046494, "compression_ratio": 1.96113074204947, "no_speech_prob": 0.002215362386777997}, {"id": 705, "seek": 403804, "start": 4038.04, "end": 4045.0, "text": " way than you would do it in 2d it does help but the completion still seems to work a bit better", "tokens": [50364, 636, 813, 291, 576, 360, 309, 294, 568, 67, 309, 775, 854, 457, 264, 19372, 920, 2544, 281, 589, 257, 857, 1101, 50712], "temperature": 0.0, "avg_logprob": -0.09875964446806572, "compression_ratio": 1.615819209039548, "no_speech_prob": 0.00164762360509485}, {"id": 706, "seek": 403804, "start": 4045.88, "end": 4053.96, "text": " it's very interesting I think so in general yeah I mean I think if if completions if if actually", "tokens": [50756, 309, 311, 588, 1880, 286, 519, 370, 294, 2674, 1338, 286, 914, 286, 519, 498, 498, 1557, 626, 498, 498, 767, 51160], "temperature": 0.0, "avg_logprob": -0.09875964446806572, "compression_ratio": 1.615819209039548, "no_speech_prob": 0.00164762360509485}, {"id": 707, "seek": 403804, "start": 4053.96, "end": 4062.2, "text": " predicting you know pixels or predicting voxels whatever um it it has it has more data it has", "tokens": [51160, 32884, 291, 458, 18668, 420, 32884, 1650, 87, 1625, 2035, 1105, 309, 309, 575, 309, 575, 544, 1412, 309, 575, 51572], "temperature": 0.0, "avg_logprob": -0.09875964446806572, "compression_ratio": 1.615819209039548, "no_speech_prob": 0.00164762360509485}, {"id": 708, "seek": 406220, "start": 4062.2, "end": 4071.24, "text": " more information that and and we know that 3d world is actually much you know it's much more", "tokens": [50364, 544, 1589, 300, 293, 293, 321, 458, 300, 805, 67, 1002, 307, 767, 709, 291, 458, 309, 311, 709, 544, 50816], "temperature": 0.0, "avg_logprob": -0.08595424002789437, "compression_ratio": 1.8285714285714285, "no_speech_prob": 0.0034279588144272566}, {"id": 709, "seek": 406220, "start": 4071.24, "end": 4078.52, "text": " informative right so and it's also I think much more um uni model so the one thing that was hard", "tokens": [50816, 27759, 558, 370, 293, 309, 311, 611, 286, 519, 709, 544, 1105, 36435, 2316, 370, 264, 472, 551, 300, 390, 1152, 51180], "temperature": 0.0, "avg_logprob": -0.08595424002789437, "compression_ratio": 1.8285714285714285, "no_speech_prob": 0.0034279588144272566}, {"id": 710, "seek": 406220, "start": 4078.52, "end": 4083.0, "text": " for us for example when we did core colorization is what we're you know we're trying to colorize a", "tokens": [51180, 337, 505, 337, 1365, 562, 321, 630, 4965, 2017, 2144, 307, 437, 321, 434, 291, 458, 321, 434, 1382, 281, 2017, 1125, 257, 51404], "temperature": 0.0, "avg_logprob": -0.08595424002789437, "compression_ratio": 1.8285714285714285, "no_speech_prob": 0.0034279588144272566}, {"id": 711, "seek": 406220, "start": 4083.0, "end": 4088.8399999999997, "text": " bird and the birds could be yellow or the bird could be green right and so you have multi model", "tokens": [51404, 5255, 293, 264, 9009, 727, 312, 5566, 420, 264, 5255, 727, 312, 3092, 558, 293, 370, 291, 362, 4825, 2316, 51696], "temperature": 0.0, "avg_logprob": -0.08595424002789437, "compression_ratio": 1.8285714285714285, "no_speech_prob": 0.0034279588144272566}, {"id": 712, "seek": 408884, "start": 4088.84, "end": 4094.1200000000003, "text": " you have two modes and if you're doing kind of a just sort of like a regression completion", "tokens": [50364, 291, 362, 732, 14068, 293, 498, 291, 434, 884, 733, 295, 257, 445, 1333, 295, 411, 257, 24590, 19372, 50628], "temperature": 0.0, "avg_logprob": -0.06507025824652778, "compression_ratio": 1.904382470119522, "no_speech_prob": 0.014718317426741123}, {"id": 713, "seek": 408884, "start": 4094.1200000000003, "end": 4098.76, "text": " what's it going to do it's going to do the average right so it's going to be neither here nor there", "tokens": [50628, 437, 311, 309, 516, 281, 360, 309, 311, 516, 281, 360, 264, 4274, 558, 370, 309, 311, 516, 281, 312, 9662, 510, 6051, 456, 50860], "temperature": 0.0, "avg_logprob": -0.06507025824652778, "compression_ratio": 1.904382470119522, "no_speech_prob": 0.014718317426741123}, {"id": 714, "seek": 408884, "start": 4098.76, "end": 4105.32, "text": " right but if you have a single mode it works really well so it might be that in 3d you're really", "tokens": [50860, 558, 457, 498, 291, 362, 257, 2167, 4391, 309, 1985, 534, 731, 370, 309, 1062, 312, 300, 294, 805, 67, 291, 434, 534, 51188], "temperature": 0.0, "avg_logprob": -0.06507025824652778, "compression_ratio": 1.904382470119522, "no_speech_prob": 0.014718317426741123}, {"id": 715, "seek": 408884, "start": 4105.32, "end": 4112.12, "text": " in a world that's much more uni model in which you don't have like you're not trying to have an", "tokens": [51188, 294, 257, 1002, 300, 311, 709, 544, 36435, 2316, 294, 597, 291, 500, 380, 362, 411, 291, 434, 406, 1382, 281, 362, 364, 51528], "temperature": 0.0, "avg_logprob": -0.06507025824652778, "compression_ratio": 1.904382470119522, "no_speech_prob": 0.014718317426741123}, {"id": 716, "seek": 408884, "start": 4112.12, "end": 4116.4400000000005, "text": " average between two different completions and they get something that doesn't look like either", "tokens": [51528, 4274, 1296, 732, 819, 1557, 626, 293, 436, 483, 746, 300, 1177, 380, 574, 411, 2139, 51744], "temperature": 0.0, "avg_logprob": -0.06507025824652778, "compression_ratio": 1.904382470119522, "no_speech_prob": 0.014718317426741123}, {"id": 717, "seek": 411644, "start": 4116.44, "end": 4121.879999999999, "text": " but you're actually really focusing on a single mode so in that case maybe this is why you're", "tokens": [50364, 457, 291, 434, 767, 534, 8416, 322, 257, 2167, 4391, 370, 294, 300, 1389, 1310, 341, 307, 983, 291, 434, 50636], "temperature": 0.0, "avg_logprob": -0.06928412667636213, "compression_ratio": 1.7897196261682242, "no_speech_prob": 0.0039964779280126095}, {"id": 718, "seek": 411644, "start": 4121.879999999999, "end": 4128.36, "text": " getting better results but if I suspect that if you had multi model like if you have a hole that's", "tokens": [50636, 1242, 1101, 3542, 457, 498, 286, 9091, 300, 498, 291, 632, 4825, 2316, 411, 498, 291, 362, 257, 5458, 300, 311, 50960], "temperature": 0.0, "avg_logprob": -0.06928412667636213, "compression_ratio": 1.7897196261682242, "no_speech_prob": 0.0039964779280126095}, {"id": 719, "seek": 411644, "start": 4128.36, "end": 4135.799999999999, "text": " big enough that you could have many different plausible completions happen to it I suspect that", "tokens": [50960, 955, 1547, 300, 291, 727, 362, 867, 819, 39925, 1557, 626, 1051, 281, 309, 286, 9091, 300, 51332], "temperature": 0.0, "avg_logprob": -0.06928412667636213, "compression_ratio": 1.7897196261682242, "no_speech_prob": 0.0039964779280126095}, {"id": 720, "seek": 411644, "start": 4135.799999999999, "end": 4141.879999999999, "text": " that that then you're kind of uh the kind of the the prediction route might have more problems", "tokens": [51332, 300, 300, 550, 291, 434, 733, 295, 2232, 264, 733, 295, 264, 264, 17630, 7955, 1062, 362, 544, 2740, 51636], "temperature": 0.0, "avg_logprob": -0.06928412667636213, "compression_ratio": 1.7897196261682242, "no_speech_prob": 0.0039964779280126095}, {"id": 721, "seek": 414188, "start": 4141.88, "end": 4147.16, "text": " no I fully agree with you no that one is definitely true and and but most of the case right you're", "tokens": [50364, 572, 286, 4498, 3986, 365, 291, 572, 300, 472, 307, 2138, 2074, 293, 293, 457, 881, 295, 264, 1389, 558, 291, 434, 50628], "temperature": 0.0, "avg_logprob": -0.10626984985781388, "compression_ratio": 1.935593220338983, "no_speech_prob": 0.0024313507601618767}, {"id": 722, "seek": 414188, "start": 4147.16, "end": 4151.56, "text": " thinking about it's more like a dropout in a sense right so you're leaving out some stuff right and", "tokens": [50628, 1953, 466, 309, 311, 544, 411, 257, 3270, 346, 294, 257, 2020, 558, 370, 291, 434, 5012, 484, 512, 1507, 558, 293, 50848], "temperature": 0.0, "avg_logprob": -0.10626984985781388, "compression_ratio": 1.935593220338983, "no_speech_prob": 0.0024313507601618767}, {"id": 723, "seek": 414188, "start": 4151.56, "end": 4154.6, "text": " then you're trying to figure out what's missing in this case I think we've experienced that it", "tokens": [50848, 550, 291, 434, 1382, 281, 2573, 484, 437, 311, 5361, 294, 341, 1389, 286, 519, 321, 600, 6751, 300, 309, 51000], "temperature": 0.0, "avg_logprob": -0.10626984985781388, "compression_ratio": 1.935593220338983, "no_speech_prob": 0.0024313507601618767}, {"id": 724, "seek": 414188, "start": 4154.6, "end": 4158.76, "text": " works remarkably well if it's too large then you need probabilistic models again and stuff like", "tokens": [51000, 1985, 37381, 731, 498, 309, 311, 886, 2416, 550, 291, 643, 31959, 3142, 5245, 797, 293, 1507, 411, 51208], "temperature": 0.0, "avg_logprob": -0.10626984985781388, "compression_ratio": 1.935593220338983, "no_speech_prob": 0.0024313507601618767}, {"id": 725, "seek": 414188, "start": 4158.76, "end": 4164.04, "text": " that then it's a lot more difficult um yeah I agree yeah I think I think it's kind of a", "tokens": [51208, 300, 550, 309, 311, 257, 688, 544, 2252, 1105, 1338, 286, 3986, 1338, 286, 519, 286, 519, 309, 311, 733, 295, 257, 51472], "temperature": 0.0, "avg_logprob": -0.10626984985781388, "compression_ratio": 1.935593220338983, "no_speech_prob": 0.0024313507601618767}, {"id": 726, "seek": 414188, "start": 4164.04, "end": 4169.88, "text": " if it's a level of dropout and it should just work yeah I I I agree yeah yeah I think I think", "tokens": [51472, 498, 309, 311, 257, 1496, 295, 3270, 346, 293, 309, 820, 445, 589, 1338, 286, 286, 286, 3986, 1338, 1338, 286, 519, 286, 519, 51764], "temperature": 0.0, "avg_logprob": -0.10626984985781388, "compression_ratio": 1.935593220338983, "no_speech_prob": 0.0024313507601618767}, {"id": 727, "seek": 416988, "start": 4169.88, "end": 4174.92, "text": " if it works you should definitely use it absolutely um actually any other questions maybe", "tokens": [50364, 498, 309, 1985, 291, 820, 2138, 764, 309, 3122, 1105, 767, 604, 661, 1651, 1310, 50616], "temperature": 0.0, "avg_logprob": -0.09548341355672697, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.0005878702504560351}, {"id": 728, "seek": 416988, "start": 4174.92, "end": 4178.2, "text": " maybe somebody else can ask questions I don't want to dominate the discussion too much", "tokens": [50616, 1310, 2618, 1646, 393, 1029, 1651, 286, 500, 380, 528, 281, 28246, 264, 5017, 886, 709, 50780], "temperature": 0.0, "avg_logprob": -0.09548341355672697, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.0005878702504560351}, {"id": 729, "seek": 416988, "start": 4182.04, "end": 4190.76, "text": " hi yeah thanks for the talk um I have a similarly high level question so speaking along the lines of", "tokens": [50972, 4879, 1338, 3231, 337, 264, 751, 1105, 286, 362, 257, 14138, 1090, 1496, 1168, 370, 4124, 2051, 264, 3876, 295, 51408], "temperature": 0.0, "avg_logprob": -0.09548341355672697, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.0005878702504560351}, {"id": 730, "seek": 416988, "start": 4190.76, "end": 4195.96, "text": " like multi modality and and stuff like this it seems like you have a lot of inspiration in terms of", "tokens": [51408, 411, 4825, 1072, 1860, 293, 293, 1507, 411, 341, 309, 2544, 411, 291, 362, 257, 688, 295, 10249, 294, 2115, 295, 51668], "temperature": 0.0, "avg_logprob": -0.09548341355672697, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.0005878702504560351}, {"id": 731, "seek": 419596, "start": 4196.92, "end": 4205.08, "text": " how to learn perception based on how people perform perception and it seems like people do have", "tokens": [50412, 577, 281, 1466, 12860, 2361, 322, 577, 561, 2042, 12860, 293, 309, 2544, 411, 561, 360, 362, 50820], "temperature": 0.0, "avg_logprob": -0.08685965220133464, "compression_ratio": 1.7535545023696681, "no_speech_prob": 0.002115285489708185}, {"id": 732, "seek": 419596, "start": 4205.08, "end": 4211.4, "text": " naturally some kind of estimate of uncertainty multi modality and the ability to generate", "tokens": [50820, 8195, 512, 733, 295, 12539, 295, 15697, 4825, 1072, 1860, 293, 264, 3485, 281, 8460, 51136], "temperature": 0.0, "avg_logprob": -0.08685965220133464, "compression_ratio": 1.7535545023696681, "no_speech_prob": 0.002115285489708185}, {"id": 733, "seek": 419596, "start": 4211.4, "end": 4215.4800000000005, "text": " also for like these video tracking kind of applications that you showed like multiple", "tokens": [51136, 611, 337, 411, 613, 960, 11603, 733, 295, 5821, 300, 291, 4712, 411, 3866, 51340], "temperature": 0.0, "avg_logprob": -0.08685965220133464, "compression_ratio": 1.7535545023696681, "no_speech_prob": 0.002115285489708185}, {"id": 734, "seek": 419596, "start": 4215.4800000000005, "end": 4223.56, "text": " hypotheses for where um the prediction should go and how far do you think you can get without this", "tokens": [51340, 49969, 337, 689, 1105, 264, 17630, 820, 352, 293, 577, 1400, 360, 291, 519, 291, 393, 483, 1553, 341, 51744], "temperature": 0.0, "avg_logprob": -0.08685965220133464, "compression_ratio": 1.7535545023696681, "no_speech_prob": 0.002115285489708185}, {"id": 735, "seek": 422356, "start": 4223.64, "end": 4226.76, "text": " explicitly modeled or do you think it needs to be explicitly modeled", "tokens": [50368, 20803, 37140, 420, 360, 291, 519, 309, 2203, 281, 312, 20803, 37140, 50524], "temperature": 0.0, "avg_logprob": -0.09792161275105304, "compression_ratio": 1.8526315789473684, "no_speech_prob": 0.0020820568315684795}, {"id": 736, "seek": 422356, "start": 4229.0, "end": 4239.0, "text": " good question I think I think I would go with I don't know so um yes humans are very good at", "tokens": [50636, 665, 1168, 286, 519, 286, 519, 286, 576, 352, 365, 286, 500, 380, 458, 370, 1105, 2086, 6255, 366, 588, 665, 412, 51136], "temperature": 0.0, "avg_logprob": -0.09792161275105304, "compression_ratio": 1.8526315789473684, "no_speech_prob": 0.0020820568315684795}, {"id": 737, "seek": 422356, "start": 4239.0, "end": 4245.8, "text": " at modeling uncertainty but they I don't think they're doing it in the way that was the decisions", "tokens": [51136, 412, 15983, 15697, 457, 436, 286, 500, 380, 519, 436, 434, 884, 309, 294, 264, 636, 300, 390, 264, 5327, 51476], "temperature": 0.0, "avg_logprob": -0.09792161275105304, "compression_ratio": 1.8526315789473684, "no_speech_prob": 0.0020820568315684795}, {"id": 738, "seek": 422356, "start": 4245.8, "end": 4253.320000000001, "text": " to it I don't think humans are actually probabilistic I think I think they might be doing it", "tokens": [51476, 281, 309, 286, 500, 380, 519, 6255, 366, 767, 31959, 3142, 286, 519, 286, 519, 436, 1062, 312, 884, 309, 51852], "temperature": 0.0, "avg_logprob": -0.09792161275105304, "compression_ratio": 1.8526315789473684, "no_speech_prob": 0.0020820568315684795}, {"id": 739, "seek": 425356, "start": 4254.04, "end": 4258.84, "text": " almost like if you remember from a long time ago like all this particle filtering where you", "tokens": [50388, 1920, 411, 498, 291, 1604, 490, 257, 938, 565, 2057, 411, 439, 341, 12359, 30822, 689, 291, 50628], "temperature": 0.0, "avg_logprob": -0.07157999385486949, "compression_ratio": 1.951417004048583, "no_speech_prob": 0.0026300200261175632}, {"id": 740, "seek": 425356, "start": 4258.84, "end": 4263.72, "text": " can keep a whole bunch of hypotheses and then you kind of keep all of them going for a while and then", "tokens": [50628, 393, 1066, 257, 1379, 3840, 295, 49969, 293, 550, 291, 733, 295, 1066, 439, 295, 552, 516, 337, 257, 1339, 293, 550, 50872], "temperature": 0.0, "avg_logprob": -0.07157999385486949, "compression_ratio": 1.951417004048583, "no_speech_prob": 0.0026300200261175632}, {"id": 741, "seek": 425356, "start": 4263.72, "end": 4269.8, "text": " you kind of uh drop one like you know there's illusion of like young lady old woman visual", "tokens": [50872, 291, 733, 295, 2232, 3270, 472, 411, 291, 458, 456, 311, 18854, 295, 411, 2037, 7262, 1331, 3059, 5056, 51176], "temperature": 0.0, "avg_logprob": -0.07157999385486949, "compression_ratio": 1.951417004048583, "no_speech_prob": 0.0026300200261175632}, {"id": 742, "seek": 425356, "start": 4269.8, "end": 4275.4800000000005, "text": " illusion where you know one day once time you see like an old lady one time you see a young woman", "tokens": [51176, 18854, 689, 291, 458, 472, 786, 1564, 565, 291, 536, 411, 364, 1331, 7262, 472, 565, 291, 536, 257, 2037, 3059, 51460], "temperature": 0.0, "avg_logprob": -0.07157999385486949, "compression_ratio": 1.951417004048583, "no_speech_prob": 0.0026300200261175632}, {"id": 743, "seek": 425356, "start": 4275.4800000000005, "end": 4282.68, "text": " right and you never see both of them so it seems some there's some very interesting mechanism going", "tokens": [51460, 558, 293, 291, 1128, 536, 1293, 295, 552, 370, 309, 2544, 512, 456, 311, 512, 588, 1880, 7513, 516, 51820], "temperature": 0.0, "avg_logprob": -0.07157999385486949, "compression_ratio": 1.951417004048583, "no_speech_prob": 0.0026300200261175632}, {"id": 744, "seek": 428268, "start": 4282.76, "end": 4292.200000000001, "text": " on but I think it's not it's not like a standard probabilistic mechanism and so yeah so I don't", "tokens": [50368, 322, 457, 286, 519, 309, 311, 406, 309, 311, 406, 411, 257, 3832, 31959, 3142, 7513, 293, 370, 1338, 370, 286, 500, 380, 50840], "temperature": 0.0, "avg_logprob": -0.09220297907439756, "compression_ratio": 1.601123595505618, "no_speech_prob": 0.003648531623184681}, {"id": 745, "seek": 428268, "start": 4292.200000000001, "end": 4298.84, "text": " know how to deal with it and in the in the vision in the in this video paper that I showed you know", "tokens": [50840, 458, 577, 281, 2028, 365, 309, 293, 294, 264, 294, 264, 5201, 294, 264, 294, 341, 960, 3035, 300, 286, 4712, 291, 458, 51172], "temperature": 0.0, "avg_logprob": -0.09220297907439756, "compression_ratio": 1.601123595505618, "no_speech_prob": 0.003648531623184681}, {"id": 746, "seek": 428268, "start": 4298.84, "end": 4304.52, "text": " we are really just keeping a whole bunch of hypotheses as we're going through the through", "tokens": [51172, 321, 366, 534, 445, 5145, 257, 1379, 3840, 295, 49969, 382, 321, 434, 516, 807, 264, 807, 51456], "temperature": 0.0, "avg_logprob": -0.09220297907439756, "compression_ratio": 1.601123595505618, "no_speech_prob": 0.003648531623184681}, {"id": 747, "seek": 430452, "start": 4304.52, "end": 4312.84, "text": " the video at training time at test time we don't and but whether that's the right thing to do or", "tokens": [50364, 264, 960, 412, 3097, 565, 412, 1500, 565, 321, 500, 380, 293, 457, 1968, 300, 311, 264, 558, 551, 281, 360, 420, 50780], "temperature": 0.0, "avg_logprob": -0.0734481604202934, "compression_ratio": 1.7710280373831775, "no_speech_prob": 0.007934304885566235}, {"id": 748, "seek": 430452, "start": 4312.84, "end": 4318.360000000001, "text": " not I don't know I think it's a very important question I don't I don't have an answer but", "tokens": [50780, 406, 286, 500, 380, 458, 286, 519, 309, 311, 257, 588, 1021, 1168, 286, 500, 380, 286, 500, 380, 362, 364, 1867, 457, 51056], "temperature": 0.0, "avg_logprob": -0.0734481604202934, "compression_ratio": 1.7710280373831775, "no_speech_prob": 0.007934304885566235}, {"id": 749, "seek": 430452, "start": 4318.360000000001, "end": 4327.96, "text": " frankly I think that nobody else does either sounds good I think one other somewhat unrelated", "tokens": [51056, 11939, 286, 519, 300, 5079, 1646, 775, 2139, 3263, 665, 286, 519, 472, 661, 8344, 38967, 51536], "temperature": 0.0, "avg_logprob": -0.0734481604202934, "compression_ratio": 1.7710280373831775, "no_speech_prob": 0.007934304885566235}, {"id": 750, "seek": 430452, "start": 4327.96, "end": 4333.400000000001, "text": " thing I think there's a bit of a tension between people who think that we should be able to learn", "tokens": [51536, 551, 286, 519, 456, 311, 257, 857, 295, 257, 8980, 1296, 561, 567, 519, 300, 321, 820, 312, 1075, 281, 1466, 51808], "temperature": 0.0, "avg_logprob": -0.0734481604202934, "compression_ratio": 1.7710280373831775, "no_speech_prob": 0.007934304885566235}, {"id": 751, "seek": 433340, "start": 4333.4, "end": 4338.92, "text": " everything from scratch like you mentioned in terms of being able to learn 3d and whether this", "tokens": [50364, 1203, 490, 8459, 411, 291, 2835, 294, 2115, 295, 885, 1075, 281, 1466, 805, 67, 293, 1968, 341, 50640], "temperature": 0.0, "avg_logprob": -0.12076055397421627, "compression_ratio": 1.5191256830601092, "no_speech_prob": 0.0039445022121071815}, {"id": 752, "seek": 433340, "start": 4338.92, "end": 4344.92, "text": " actually possible because it's unclear I guess how many how much supervision certainly for", "tokens": [50640, 767, 1944, 570, 309, 311, 25636, 286, 2041, 577, 867, 577, 709, 32675, 3297, 337, 50940], "temperature": 0.0, "avg_logprob": -0.12076055397421627, "compression_ratio": 1.5191256830601092, "no_speech_prob": 0.0039445022121071815}, {"id": 753, "seek": 433340, "start": 4344.92, "end": 4352.12, "text": " like some rantic perception people get direct supervision and so yeah okay now we're back to", "tokens": [50940, 411, 512, 367, 7128, 12860, 561, 483, 2047, 32675, 293, 370, 1338, 1392, 586, 321, 434, 646, 281, 51300], "temperature": 0.0, "avg_logprob": -0.12076055397421627, "compression_ratio": 1.5191256830601092, "no_speech_prob": 0.0039445022121071815}, {"id": 754, "seek": 435212, "start": 4352.2, "end": 4359.4, "text": " philosophy I think it must be possible because because it already happened right", "tokens": [50368, 10675, 286, 519, 309, 1633, 312, 1944, 570, 570, 309, 1217, 2011, 558, 50728], "temperature": 0.0, "avg_logprob": -0.08696913300899037, "compression_ratio": 1.656441717791411, "no_speech_prob": 0.04882213473320007}, {"id": 755, "seek": 435212, "start": 4362.04, "end": 4369.64, "text": " supervised learning is something that happens in nature but it's it's very very rare like like", "tokens": [50860, 46533, 2539, 307, 746, 300, 2314, 294, 3687, 457, 309, 311, 309, 311, 588, 588, 5892, 411, 411, 51240], "temperature": 0.0, "avg_logprob": -0.08696913300899037, "compression_ratio": 1.656441717791411, "no_speech_prob": 0.04882213473320007}, {"id": 756, "seek": 435212, "start": 4370.5199999999995, "end": 4376.599999999999, "text": " parents teaching their children things I know that a lot of modern parents they feel like it's", "tokens": [51284, 3152, 4571, 641, 2227, 721, 286, 458, 300, 257, 688, 295, 4363, 3152, 436, 841, 411, 309, 311, 51588], "temperature": 0.0, "avg_logprob": -0.08696913300899037, "compression_ratio": 1.656441717791411, "no_speech_prob": 0.04882213473320007}, {"id": 757, "seek": 437660, "start": 4376.6, "end": 4382.120000000001, "text": " super super important but sorry you know a developmental psychologist disagree they say", "tokens": [50364, 1687, 1687, 1021, 457, 2597, 291, 458, 257, 30160, 29514, 14091, 436, 584, 50640], "temperature": 0.0, "avg_logprob": -0.09714374355241365, "compression_ratio": 1.8790322580645162, "no_speech_prob": 0.005135959945619106}, {"id": 758, "seek": 437660, "start": 4382.120000000001, "end": 4388.120000000001, "text": " that it doesn't really matter that much most of the things that a kid picks up they pick up", "tokens": [50640, 300, 309, 1177, 380, 534, 1871, 300, 709, 881, 295, 264, 721, 300, 257, 1636, 16137, 493, 436, 1888, 493, 50940], "temperature": 0.0, "avg_logprob": -0.09714374355241365, "compression_ratio": 1.8790322580645162, "no_speech_prob": 0.005135959945619106}, {"id": 759, "seek": 437660, "start": 4388.120000000001, "end": 4395.160000000001, "text": " without supervision they keep pick up on their own and and you could think about it you know", "tokens": [50940, 1553, 32675, 436, 1066, 1888, 493, 322, 641, 1065, 293, 293, 291, 727, 519, 466, 309, 291, 458, 51292], "temperature": 0.0, "avg_logprob": -0.09714374355241365, "compression_ratio": 1.8790322580645162, "no_speech_prob": 0.005135959945619106}, {"id": 760, "seek": 437660, "start": 4396.4400000000005, "end": 4400.6, "text": " from in the very beginning right in the beginning if you're you know as long as you believe in", "tokens": [51356, 490, 294, 264, 588, 2863, 558, 294, 264, 2863, 498, 291, 434, 291, 458, 382, 938, 382, 291, 1697, 294, 51564], "temperature": 0.0, "avg_logprob": -0.09714374355241365, "compression_ratio": 1.8790322580645162, "no_speech_prob": 0.005135959945619106}, {"id": 761, "seek": 437660, "start": 4400.6, "end": 4405.64, "text": " evolution you must believe in in unsupervised or self-supervised learning because in the beginning", "tokens": [51564, 9303, 291, 1633, 1697, 294, 294, 2693, 12879, 24420, 420, 2698, 12, 48172, 24420, 2539, 570, 294, 264, 2863, 51816], "temperature": 0.0, "avg_logprob": -0.09714374355241365, "compression_ratio": 1.8790322580645162, "no_speech_prob": 0.005135959945619106}, {"id": 762, "seek": 440564, "start": 4405.64, "end": 4410.200000000001, "text": " there was nothing there was no there was no teacher there was no supervision there was only", "tokens": [50364, 456, 390, 1825, 456, 390, 572, 456, 390, 572, 5027, 456, 390, 572, 32675, 456, 390, 787, 50592], "temperature": 0.0, "avg_logprob": -0.08193455864401425, "compression_ratio": 2.010928961748634, "no_speech_prob": 0.0031215364579111338}, {"id": 763, "seek": 440564, "start": 4410.200000000001, "end": 4415.72, "text": " data right and kind of the organism and its environment were co-involving and learning", "tokens": [50592, 1412, 558, 293, 733, 295, 264, 24128, 293, 1080, 2823, 645, 598, 12, 259, 9646, 798, 293, 2539, 50868], "temperature": 0.0, "avg_logprob": -0.08193455864401425, "compression_ratio": 2.010928961748634, "no_speech_prob": 0.0031215364579111338}, {"id": 764, "seek": 440564, "start": 4415.72, "end": 4423.96, "text": " from each other and and and and and and develop so I think there is there is to me there is no", "tokens": [50868, 490, 1184, 661, 293, 293, 293, 293, 293, 293, 1499, 370, 286, 519, 456, 307, 456, 307, 281, 385, 456, 307, 572, 51280], "temperature": 0.0, "avg_logprob": -0.08193455864401425, "compression_ratio": 2.010928961748634, "no_speech_prob": 0.0031215364579111338}, {"id": 765, "seek": 440564, "start": 4423.96, "end": 4431.8, "text": " question that it should be possible in theory I think that the kind of the the the interesting", "tokens": [51280, 1168, 300, 309, 820, 312, 1944, 294, 5261, 286, 519, 300, 264, 733, 295, 264, 264, 264, 1880, 51672], "temperature": 0.0, "avg_logprob": -0.08193455864401425, "compression_ratio": 2.010928961748634, "no_speech_prob": 0.0031215364579111338}, {"id": 766, "seek": 443180, "start": 4431.88, "end": 4437.08, "text": " question is is it does it make sense to do in practice right and like you could also say well", "tokens": [50368, 1168, 307, 307, 309, 775, 309, 652, 2020, 281, 360, 294, 3124, 558, 293, 411, 291, 727, 611, 584, 731, 50628], "temperature": 0.0, "avg_logprob": -0.04913705860802887, "compression_ratio": 1.7695167286245352, "no_speech_prob": 0.019986728206276894}, {"id": 767, "seek": 443180, "start": 4437.08, "end": 4442.76, "text": " why don't we just simulate evolution for for a gazillion years and then we'll get everything", "tokens": [50628, 983, 500, 380, 321, 445, 27817, 9303, 337, 337, 257, 26232, 11836, 924, 293, 550, 321, 603, 483, 1203, 50912], "temperature": 0.0, "avg_logprob": -0.04913705860802887, "compression_ratio": 1.7695167286245352, "no_speech_prob": 0.019986728206276894}, {"id": 768, "seek": 443180, "start": 4442.76, "end": 4448.12, "text": " right and that's of course not feasible with the current technology so I don't think that there is", "tokens": [50912, 558, 293, 300, 311, 295, 1164, 406, 26648, 365, 264, 2190, 2899, 370, 286, 500, 380, 519, 300, 456, 307, 51180], "temperature": 0.0, "avg_logprob": -0.04913705860802887, "compression_ratio": 1.7695167286245352, "no_speech_prob": 0.019986728206276894}, {"id": 769, "seek": 443180, "start": 4448.12, "end": 4453.400000000001, "text": " that much or maybe there shouldn't be that much tension because I think I think there are people", "tokens": [51180, 300, 709, 420, 1310, 456, 4659, 380, 312, 300, 709, 8980, 570, 286, 519, 286, 519, 456, 366, 561, 51444], "temperature": 0.0, "avg_logprob": -0.04913705860802887, "compression_ratio": 1.7695167286245352, "no_speech_prob": 0.019986728206276894}, {"id": 770, "seek": 443180, "start": 4453.400000000001, "end": 4458.04, "text": " like me who really want to try to learn things from first principles and I think this is very", "tokens": [51444, 411, 385, 567, 534, 528, 281, 853, 281, 1466, 721, 490, 700, 9156, 293, 286, 519, 341, 307, 588, 51676], "temperature": 0.0, "avg_logprob": -0.04913705860802887, "compression_ratio": 1.7695167286245352, "no_speech_prob": 0.019986728206276894}, {"id": 771, "seek": 445804, "start": 4458.04, "end": 4463.72, "text": " interesting if if if anything from you know from the biological plausibility point of view", "tokens": [50364, 1880, 498, 498, 498, 1340, 490, 291, 458, 490, 264, 13910, 34946, 2841, 935, 295, 1910, 50648], "temperature": 0.0, "avg_logprob": -0.05074011938912528, "compression_ratio": 1.8443579766536966, "no_speech_prob": 0.011151454411447048}, {"id": 772, "seek": 445804, "start": 4463.72, "end": 4469.88, "text": " okay and there are people who just want to get stuff done and and and get to a good result too", "tokens": [50648, 1392, 293, 456, 366, 561, 567, 445, 528, 281, 483, 1507, 1096, 293, 293, 293, 483, 281, 257, 665, 1874, 886, 50956], "temperature": 0.0, "avg_logprob": -0.05074011938912528, "compression_ratio": 1.8443579766536966, "no_speech_prob": 0.011151454411447048}, {"id": 773, "seek": 445804, "start": 4469.88, "end": 4475.88, "text": " fast and those people should definitely just use whatever works best at the time so I'm not sure", "tokens": [50956, 2370, 293, 729, 561, 820, 2138, 445, 764, 2035, 1985, 1151, 412, 264, 565, 370, 286, 478, 406, 988, 51256], "temperature": 0.0, "avg_logprob": -0.05074011938912528, "compression_ratio": 1.8443579766536966, "no_speech_prob": 0.011151454411447048}, {"id": 774, "seek": 445804, "start": 4475.88, "end": 4481.64, "text": " that it's either or I think both directions are are useful and I think we're learning from each", "tokens": [51256, 300, 309, 311, 2139, 420, 286, 519, 1293, 11095, 366, 366, 4420, 293, 286, 519, 321, 434, 2539, 490, 1184, 51544], "temperature": 0.0, "avg_logprob": -0.05074011938912528, "compression_ratio": 1.8443579766536966, "no_speech_prob": 0.011151454411447048}, {"id": 775, "seek": 445804, "start": 4481.64, "end": 4486.2, "text": " other I think those two direction directions are informing each other so for example for a very", "tokens": [51544, 661, 286, 519, 729, 732, 3513, 11095, 366, 43969, 1184, 661, 370, 337, 1365, 337, 257, 588, 51772], "temperature": 0.0, "avg_logprob": -0.05074011938912528, "compression_ratio": 1.8443579766536966, "no_speech_prob": 0.011151454411447048}, {"id": 776, "seek": 448620, "start": 4486.2, "end": 4493.639999999999, "text": " long time self-supervised approaches worked worse than supervised approaches and so you know", "tokens": [50364, 938, 565, 2698, 12, 48172, 24420, 11587, 2732, 5324, 813, 46533, 11587, 293, 370, 291, 458, 50736], "temperature": 0.0, "avg_logprob": -0.07867185351918045, "compression_ratio": 2.0042372881355934, "no_speech_prob": 0.004466424696147442}, {"id": 777, "seek": 448620, "start": 4494.36, "end": 4498.599999999999, "text": " if you know we could have all quit because oh my god you know our stuff doesn't work as well as", "tokens": [50772, 498, 291, 458, 321, 727, 362, 439, 10366, 570, 1954, 452, 3044, 291, 458, 527, 1507, 1177, 380, 589, 382, 731, 382, 50984], "temperature": 0.0, "avg_logprob": -0.07867185351918045, "compression_ratio": 2.0042372881355934, "no_speech_prob": 0.004466424696147442}, {"id": 778, "seek": 448620, "start": 4498.599999999999, "end": 4503.32, "text": " supervision but we persevered because we thought that you know there's something interesting that", "tokens": [50984, 32675, 457, 321, 29917, 292, 570, 321, 1194, 300, 291, 458, 456, 311, 746, 1880, 300, 51220], "temperature": 0.0, "avg_logprob": -0.07867185351918045, "compression_ratio": 2.0042372881355934, "no_speech_prob": 0.004466424696147442}, {"id": 779, "seek": 448620, "start": 4503.32, "end": 4509.96, "text": " that we could learn anyway and now what we are seeing is that for some tasks self-supervision", "tokens": [51220, 300, 321, 727, 1466, 4033, 293, 586, 437, 321, 366, 2577, 307, 300, 337, 512, 9608, 2698, 12, 48172, 6763, 51552], "temperature": 0.0, "avg_logprob": -0.07867185351918045, "compression_ratio": 2.0042372881355934, "no_speech_prob": 0.004466424696147442}, {"id": 780, "seek": 448620, "start": 4509.96, "end": 4514.84, "text": " actually works better than supervised learning not for all not for many but for some there's", "tokens": [51552, 767, 1985, 1101, 813, 46533, 2539, 406, 337, 439, 406, 337, 867, 457, 337, 512, 456, 311, 51796], "temperature": 0.0, "avg_logprob": -0.07867185351918045, "compression_ratio": 2.0042372881355934, "no_speech_prob": 0.004466424696147442}, {"id": 781, "seek": 451484, "start": 4514.84, "end": 4521.88, "text": " definitely some cases when it actually the the the learning from the data actually gives you", "tokens": [50364, 2138, 512, 3331, 562, 309, 767, 264, 264, 264, 2539, 490, 264, 1412, 767, 2709, 291, 50716], "temperature": 0.0, "avg_logprob": -0.08933574162172468, "compression_ratio": 1.9278350515463918, "no_speech_prob": 0.0011505881557241082}, {"id": 782, "seek": 451484, "start": 4521.88, "end": 4527.88, "text": " better results than learning from uh from from from from labels and so I think I think I think", "tokens": [50716, 1101, 3542, 813, 2539, 490, 2232, 490, 490, 490, 490, 16949, 293, 370, 286, 519, 286, 519, 286, 519, 51016], "temperature": 0.0, "avg_logprob": -0.08933574162172468, "compression_ratio": 1.9278350515463918, "no_speech_prob": 0.0011505881557241082}, {"id": 783, "seek": 451484, "start": 4527.88, "end": 4534.52, "text": " you know let all the flowers bloom it I think both directions are useful and I think it's", "tokens": [51016, 291, 458, 718, 439, 264, 8085, 26899, 309, 286, 519, 1293, 11095, 366, 4420, 293, 286, 519, 309, 311, 51348], "temperature": 0.0, "avg_logprob": -0.08933574162172468, "compression_ratio": 1.9278350515463918, "no_speech_prob": 0.0011505881557241082}, {"id": 784, "seek": 451484, "start": 4534.52, "end": 4541.64, "text": " it's great that people are are pushing in in in in both of them and I think we'll we'll get to a", "tokens": [51348, 309, 311, 869, 300, 561, 366, 366, 7380, 294, 294, 294, 294, 1293, 295, 552, 293, 286, 519, 321, 603, 321, 603, 483, 281, 257, 51704], "temperature": 0.0, "avg_logprob": -0.08933574162172468, "compression_ratio": 1.9278350515463918, "no_speech_prob": 0.0011505881557241082}, {"id": 785, "seek": 454164, "start": 4541.72, "end": 4548.04, "text": " better point eventually and we'll learn more so I'm actually optimistic on on on all fronts it's", "tokens": [50368, 1101, 935, 4728, 293, 321, 603, 1466, 544, 370, 286, 478, 767, 19397, 322, 322, 322, 439, 40426, 309, 311, 50684], "temperature": 0.0, "avg_logprob": -0.09379681819627265, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.0019251647172495723}, {"id": 786, "seek": 454164, "start": 4548.04, "end": 4553.240000000001, "text": " yeah it's not a competition well it is a competition but it's not like it's not one is right another", "tokens": [50684, 1338, 309, 311, 406, 257, 6211, 731, 309, 307, 257, 6211, 457, 309, 311, 406, 411, 309, 311, 406, 472, 307, 558, 1071, 50944], "temperature": 0.0, "avg_logprob": -0.09379681819627265, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.0019251647172495723}, {"id": 787, "seek": 454164, "start": 4553.240000000001, "end": 4560.280000000001, "text": " is wrong I think both are right cool all right I think that's a that's a very good um I guess", "tokens": [50944, 307, 2085, 286, 519, 1293, 366, 558, 1627, 439, 558, 286, 519, 300, 311, 257, 300, 311, 257, 588, 665, 1105, 286, 2041, 51296], "temperature": 0.0, "avg_logprob": -0.09379681819627265, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.0019251647172495723}, {"id": 788, "seek": 454164, "start": 4560.280000000001, "end": 4564.280000000001, "text": " ending of the live stream I think thanks a really lot for the amazing talk um we're a little bit", "tokens": [51296, 8121, 295, 264, 1621, 4309, 286, 519, 3231, 257, 534, 688, 337, 264, 2243, 751, 1105, 321, 434, 257, 707, 857, 51496], "temperature": 0.0, "avg_logprob": -0.09379681819627265, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.0019251647172495723}, {"id": 789, "seek": 454164, "start": 4564.280000000001, "end": 4569.0, "text": " over I have to apologize to a lot of questions on YouTube we couldn't unfortunately go into all of", "tokens": [51496, 670, 286, 362, 281, 12328, 281, 257, 688, 295, 1651, 322, 3088, 321, 2809, 380, 7015, 352, 666, 439, 295, 51732], "temperature": 0.0, "avg_logprob": -0.09379681819627265, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.0019251647172495723}, {"id": 790, "seek": 456900, "start": 4569.0, "end": 4575.48, "text": " them um but um it was really great to have you and um I hope also for everybody who is with", "tokens": [50364, 552, 1105, 457, 1105, 309, 390, 534, 869, 281, 362, 291, 293, 1105, 286, 1454, 611, 337, 2201, 567, 307, 365, 50688], "temperature": 0.0, "avg_logprob": -0.2550561819503556, "compression_ratio": 1.638036809815951, "no_speech_prob": 0.002931570867076516}, {"id": 791, "seek": 456900, "start": 4575.48, "end": 4581.08, "text": " with here right now next week we'll have another great lecture with rock help and yeah we'll see", "tokens": [50688, 365, 510, 558, 586, 958, 1243, 321, 603, 362, 1071, 869, 7991, 365, 3727, 854, 293, 1338, 321, 603, 536, 50968], "temperature": 0.0, "avg_logprob": -0.2550561819503556, "compression_ratio": 1.638036809815951, "no_speech_prob": 0.002931570867076516}, {"id": 792, "seek": 456900, "start": 4581.08, "end": 4584.2, "text": " so thanks a lot again for the for the great year I need great research", "tokens": [50968, 370, 3231, 257, 688, 797, 337, 264, 337, 264, 869, 1064, 286, 643, 869, 2132, 51124], "temperature": 0.0, "avg_logprob": -0.2550561819503556, "compression_ratio": 1.638036809815951, "no_speech_prob": 0.002931570867076516}, {"id": 793, "seek": 456900, "start": 4588.68, "end": 4589.8, "text": " okay um", "tokens": [51348, 1392, 1105, 51404], "temperature": 0.0, "avg_logprob": -0.2550561819503556, "compression_ratio": 1.638036809815951, "no_speech_prob": 0.002931570867076516}], "language": "en"}