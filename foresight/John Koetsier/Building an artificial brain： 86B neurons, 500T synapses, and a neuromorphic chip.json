{"text": " Ultimately, we see this as kind of like Lego pieces that, you know, due to their low power footprints, we'll be able to concatenate them together using things like chip lead integration, advanced packaging, and ultimately scale out these systems to be brain scale, 86 billion neurons, 500 trillion synapses, and low power enough that they can exist in autonomous devices. Can we build a computer chip that operates like the brain? We've seen neuromorphic computer chips from companies like Intel before, like the Luigi chip, which Intel claimed had a sense of smell. Rain neuromorphics, however, says it has an end-to-end analog chip, a neuromorphic processing unit that they say is the world's first end-to-end analog trainable AI circuit. It's a fully analog neural network, and it's a thousand times more energy efficient than today's best processors. Here to chat is Rain neuromorphic CEO, Gordon Wilson. Welcome, Gordon. Thanks so much for having me, John. It's good to be here. It's good to have you. When I see neuromorphics in the inbox, I got to check it out. It's a cool space. Let's start here. What the heck is an analog chip? Yeah, great question. And I think a great kicking off point because it really allows us to frame kind of what we're doing compared to what has been done for this past decade. And I think it's easiest to understand what an analog chip is in contrast to the neural networks, the AI that have defined this last decade of deep learning. So in 2012, we kind of had a big event that started this new era, this AI Renaissance, and we are seeing these massive neural networks grow in size and grow in capabilities since then. But all of those neural networks that we've seen in this deep learning world are neural simulations. They are abstractions that are written in software and the neurons and synapses that are defined in that software don't physically exist, but rather they sit on this highest layer usually written in Python and that are then translated through many layers of abstraction down until it gets to the digital circuit, most of the time a GPU graphics processing unit where it then processes that math that represents that neural network at the top. An analog chip and a neuromorphic chip is different. It's not a neural simulation, but rather it's a neural circuit. It's a physical collection of neurons and synapses as opposed to an abstraction of neurons and synapses. And this is very similar to the brain. The brain is a collection of physical neurons and synapses. It's governed by the laws of physics and it achieves all that it does with extraordinary scale and extraordinary efficiency within the bounds of the physical world. So an analog chip, as we're building it, is trying to achieve something simple, trying to find ways to learn, find ways to scale all within the physical domain. So let's dig into that just a little deeper. Great, great overview. What does that mean? Typically a chip will think in terms of or operate in terms of on or off one or zero, right? Binary logic, right? What does an analog chip, how does that work? What's that look like? So digital chips are, as you said, built on the very bottom on zeros and ones on this Boolean logic of on or off. And all of the other logic is then constructed on top of that. When you zoom down to the bottom of an analog chip, you don't have zeros or ones, you have gradients of information, you have voltages and currents and resistances, you have physical quantities that you're measuring that represents the mathematical operations that you're performing. And you're exploiting the relationship between those physical quantities to then perform these very complex neural operations. So an example of this is like matrix vector multiplication. This is the backbone of most neural network math. And GPUs do this by parallelizing these multiplications across a lot of digital cores and doing precise digital multiplication in addition. In an analog chip, as we are building it, we're not doing this with highly precise digital math, but instead we have the activations of the neurons represented by voltages. We have the weights of the synapses represented by resistances, which are held in components called memristors. And when that voltage passes across that resistance, you have a natural relationship between voltage and resistance that's multiplicative to receive a current, you read out a current and that's your output. So an analog chip works by kind of first understanding these physical relationships between electrical quantities and exploiting those to do the math, to make the physics do the math for us. That sounds super interesting and it sounds at once very, very complex and at the same time kind of simple, right? And is that one of the key reasons why your chip is so much more energy efficient? I mean, you're claiming a thousand times more energy efficient. Yeah, exactly. That really is, I think, the most fundamental reason. And I think when you consider the comparison again to the neural simulation, the neural network in that simulation exists so many layers above and requires to be translated and then performed on a circuit that is really not that well optimized for neural math. And, but in our case, the circuit is the neural network. And because it is, it exists in that very bottom layer, it is on the substrate of the chip itself, you can achieve some extraordinary gains in both speed and improvement and power reduction, which of course gives you that energy efficiency gain. So, so yeah, it's because we're building the physical thing on that bottom layer. This episode of Tech First is sponsored by Smart One. Smart One is a smart vending machine platform that transforms traditional vending hardware into smarter, better, faster, automated retail kiosks, a convenient store without the store. Learn more at smrt1.ca. That I'm fascinated. And I'm wondering with Boolean logic, old school computer chips, you kind of have to simulate reality and go through those multiple layers of translation because you're not on bare metal, you know, as the, the old timers and computing would tell us, right? Go through various layers of translation before you're actually hitting computer, machine instruction, machine language. And you're kind of modeling reality or what you're computing in reality. Is, is that an accurate way of thinking about it? Yes. That's an exact way, a really great way to put it. You know, I sometimes use the metaphor, like what would be easier, you know, to, to assess your ability to kick a soccer ball on a field, right? Would you rather, you know, reconstruct all of the physics of your body and of the soccer field and of the ball and simulate that kick and, you know, observe that in the simulated world, or would you just rather walk out of the pitch and kick the ball? You know, it's for us, it feels very obvious that, you know, the most natural way to build a neural network, uh, to make it as efficient as the brain is to build it physically, just as the brain does. Are you trying to build an artificial brain? Yes, we are. That is our goal. You know, we have kind of two missions that are very complimentary. Uh, one of them is to build a brain. And the other one is to actually understand it. You know, we really love the, and believe the notion that you can't fully understand a system until you have, have reconstructed it and built it. Uh, you know, this go back to Feynman and many others. Uh, but what we believe we've developed really are kind of the core technologies that allow us to first build just kind of unit level chips that address, you know, near term problems. But ultimately we see this as kind of like Lego pieces that, you know, due to their low power footprints, we'll be able to concatenate them together using things like chiplet integration, advanced packaging, and ultimately scale out these systems to be brain scale, 86 billion neurons, 500 trillion synapses, and low power enough that they can exist in autonomous devices. Because today, trading is so expensive that first week, we consider trading inferences, the separate problems. And I don't think they really should be considered as these separate and distinct problems, but it's so expensive that we can't even conceive of putting training of natural language in an autonomous machine. And yet humans do it all the time. So that is what we are trying to achieve to, to recapitulate the brain in hardware and ultimately give machines all of the capabilities that we recognize in ourselves. So Gordon, you're a pretty soft spoken guy and you sound like a very thoughtful guy. And in that very soft spoken way, you're saying absolutely ginormous things. We're talking Frankenstein level stuff, right? I mean, you understand the gravity of what you're talking about, right? Absolutely. No, this is the scope and impact of our work is not. I mean, this is something we've been working on for nearly five years and we recognize that if we are successful in achieving this, this, this will be historic and, and massively consequential. But, you know, what motivates us, you know, is of course the, the impact on positively improving human life, you know, and we can have personalized medicine, personalized education, we can automate all of labor. I mean, this is the world that we want to realize. I think many people are already in this consensus that artificial intelligence is going to be kind of the defining technology of the century. But most people don't, don't know that the hardware that supports it is, is the bottleneck right now. So, so yes, we recognize the scope of this and, you know, it's, it's a big mission and a big task. But, you know, I think that we're, we're approaching it the right way. And we're also very conscientious of the fact that we're, you know, conscientious of the fact that we don't want, that there, there are good ways of implementing AI and there are also not good ways. And we don't think AI should be used everywhere for every purpose, but there are guidelines and ethics that should really direct how we build and implement these systems. And it's controversial. It's also political in the AI space, right? In terms of what you're building, what you're looking at, people who claim to be working on general AI, for instance, you know, there's a lot of scrutiny there, there was a, I believe a Google engineer who last week said, I think that some of our systems are, are approaching consciousness. And, and there were a ton of people jumping all over him, probably correctly. But, you know, perhaps in a bit of a mob mentality for daring to suggest that and, and saying, no, we're, we're so far out there, maybe let's come back here, because you and your co-founder have studied the human brain significantly. What do we learn about AI from the way that our brains work? Absolutely. That's a great question, John. And I'd say that there are really kind of two categories of clues that we look at, you know, from the brain that then inform our hardware. The first is, how does the brain learn so efficiently? You know, it, the brain trains and learns with both very few examples. We, we learn with, with one example or two examples, one shot learning, two shot learning, and we can generalize extraordinarily well. So learning training happens very, very efficiently. And there are the learning rule of the brain, the algorithm the brain uses is not fully understood or identified, but we do know that there are certain requirements that, that algorithm must have. So one of those is called a local learning rule. So this, if you're, for the listeners who are familiar with back propagation, which is the industry standard algorithm for digital AI, this says what's called a global learning. So first let's say, well, what is a learning rule? A learning rule is how any given synapse in a neural network knows, should it become stronger or weaker for the whole system to become smarter, better at its assigned task. And in back propagation of the digital world, for you to calculate whether this one synapse should be stronger or weaker, you need to do a math equation that incorporates the entire network. You need to differentiate against the entire system. That's really mathematically expensive, but not only is it expensive, it's also impossible for the brain to be doing the same thing. There's no like agent sitting in our brain observing the whole system and then doing a math problem to update every synapse. It's, it's impossible. The brain has to be operating with a local learning rule. And so a local learning rule is so that that synapse can just observe what's right nearby and still know I become stronger. So that's one of the clues in the algorithm side. And that's one of the pieces that makes our learning algorithm so special, that it is as smart as back propagation, but it does so with a local learning rule. Well, you burst my bubble there. And there's no homunculus, I believe you pronounce it. I mean, there's no little guy in a little control room in my brain. Unfortunate. Yeah. And, and there's another side of the clue. So I'd say the first is on like how it learns the learning algorithm. The other is about scale. How does the brain achieve its massive scale? 86 million neurons, 500 trillion synapses, and still process and move information so quickly, so efficiently. So, and in that case, we take clues from like the topology of the brain. And in fact, and the specific thing is called sparsity. The idea that you don't have to connect every neuron to every other neuron in the system for it to be well connected. Now, again, to contrast to the status quo, digital ALI in deep learning is, was primarily built on what are called fully connected layers in neural networks where you have a layer of neurons and another layer of neurons and you connect every neuron here to every neuron in the next layer. Whoa. This was, that was the natural way to do it on GPUs because GPUs do these dense matrix multiplications, which correspond to this fully connected, densely connected systems. Now, our brain is very different. Our brain of all the possible connections that could exist between neurons, it's something like just a fraction or one percent of those connections exist. And yet at the same time, the path for information to travel from one neuron to any other neuron is very short. The average path length is about four jumps for information to traverse anywhere in the brain. It's extremely well connected. So there are these special patterns of connectivity. One of them is called a small world network. And if you've ever heard of a small world network, it's a network pattern that also mirrors human social networks that gives rise to the six degrees of separation property and human connections. And the idea is you can have lots of local connections. You want to be connected to your neighbors. You're likely to be connected to your neighbors. And that's a very short path to bridge. And then you want some long distance connections. And you can create these very well connected networks at very large scale when you implement these intelligent forms of sparsity. So sparsity is core to our scaling architecture. And really, and just to kind of summarize there. So we have these are the two core technologies we've developed. A learning algorithm that learns of the local learning rule and a scaling architecture that scales to massive sizes of neural networks using intelligent sparsity. I knew Kevin Bacon would come up some point. I mean, inevitable. Last year, I believe you sort of taped a functional chip together. Your first prototype. Where are you on the journey to shipping a fully functional chip? So we have, I'd say in the last four years, you know, we have done such expansive work that has been mostly, I would say, qualified as a research. We've been exploring different algorithms. We've been exploring different architectures. Originally, we have this concept using random nanowire meshes. Turns out it's not very manufacturable and better to build things that you can manufacture today easily. But in this last year, we kind of crystallized kind of our two core technologies. Like what is the learning algorithm and what is that scaling architecture? And then developed hardware prototypes of each. We still have a good amount of time to engineer this completely and to get to market. We we hope to get to market, you know, on the order of full scale shipping 2025. But that said, you know, building the world's first analog neural network is not easy. You know, to iterate through this and get it fully fully up at scale. And you just got some help there. You raised some funds. Yeah. Yeah. Yeah. So we just closed a 25 million series A, which is thrilling. You know, we had used eight million dollars for the last four years and honestly had gone through some challenging times where, you know, we got really close. You know, one of our first tape out prototypes didn't function precisely as designed. It was a very silly error. But in ships, it takes a long time to iterate and even and resolve. You can't just debug like software. So we went through a lot. We learned a lot. And now we have 25 million in the bank and we're hiring like crazy. Wonderful. It goes quickly, I know, from personal experience. So talk about what this will enable. You're shipping this ship. What will it enable? Yeah. So we want to not enable just like an incremental improvement in AI. You know, I think that there are a lot of folks and video included on the digital hardware roadmap and because digital hardware is so mature, it's just it's kind of incremental gains that we're getting at this point. And I think there's still more improvement to be geeked out on that roadmap. But we're trying to enable a new roadmap that is really a step change in performance improvement. And so we want to enter the market really at a thousand X energy efficiency improvement over status quo hardware. And at a thousand X comes from about a 10 X reduction in power alongside a 100 X improvement in speed. And when you can do that and importantly, not just for inference, we're talking about training and inference in the same platform. It unlocks possibilities that have just been inconceivable until until now. For one, you know, currently people consider training and inference as these kind of separate problems that we need separate platforms of hardware with. You know, we train up in a GPU cloud system, and then we might upload those weights onto a more efficient chip and deploy it out into the world. I think that would be the first step for kind of low power inference in devices. But we don't want devices just to be pre-programmed and just do what they do in the world. We want devices to learn on their own. We want devices to have an adaptive brain that's continuously learning from a changing environment and from a changing self. So imagine a robot, right? We have we're we're eventually in our lifetime. We're going to have robots for everything, you know, but maybe it's a construction robot that's helping, you know, repair our streets or build our homes. The joints on that robot are going to erode and face damage in unique ways. And it needs to learn how to adjust its own movement so it can maintain its performance based on its own kind of evolution and transition in its physical self. Also, the robots might be adjusting to new environments. And we'd like that ability to be baked in so they can continuously and adaptively learn. This also really enables personalization. It enables machines to get to know us and for us to have the assurance that that knowledge and data of ourselves is in that robot and doesn't believe that robot, I think is something we will will be very assuring. But but that's a huge piece, you know, training and inference in the same platform that is untethered. What's really interesting about that? Oh, there's a number of things, obviously. But I mean, I'm just thinking of a limping robot. For instance, you know, we limp when we injure a joint and that is our adaptation to the limitation in a knee or a hip or something like that. And we function with that. And, you know, maybe we'll repair the robot, but maybe the robot is inaccessible or maybe the robot is on Mars or Pluto or who knows where or maybe it's too expensive. So limping and getting, you know, that's interesting. The other thing that you mentioned that's super interesting is we want AI to make our lives better and we want robots to make our lives better. But that doesn't mean that we want Amazon to know our deepest thoughts. That doesn't mean that we want Google to know everything about our personal finances. You know, if we can have AI that is personal, that, you know, sure, it comes from somewhere and we've purchased it. Or, you know, if you start to get into it, if you start to look at general AI, you start thinking, do you purchase that? Do you recruit that? Do you adopt that? Lots of questions there, but it's nice if you can get a system that learns you, understands you and it stays in some sort of privacy corridor there. Really, really interesting stuff. How it's so hard to predict the future. You mentioned about speed. That's always a moving target, right? You want a hundred X speed, but you see what speed is right now. In terms of adding speed right now, we seem to not be making chips much faster per se. We're adding more chipsets on a die or we're we're creating chips that are more optimized for this task or for that task or for energy efficiency or for whatever, and that's how we're making overall devices faster. So are you are you keeping that sort of moving target in mind as you look at the performance levels that you want to hit? So we believe we can achieve that one hundred X and proven speed and beyond because we're taking a different tack entirely because we're not on that roadmap of digital hardware that is very mature chips and they're eking out performance from any number of, you know, kind of well trod playbooks. In the case of a fully analog neuromorphic chip, you know, you have a neural network where you have analog neurons and synapses that are connected in sequence. And, you know, you can compare this to to other analog mixed signal chips. So people are starting to get a lot of speed improvements by moving away from digital and doing, say, the synaptic operations either with photonic components or flash components. But in all of those cases, they still actually have to translate between their kind of physical, their either physics or optical to digital for their neurons. And so they have these analog synapses, digital neurons, they kind of go back and forth and that requires clocking that requires slowing down the system. So in a fully analog chip, when it when it's designed, well, you can have input to output and have the signal flow at wire speed from end to end. That is the full potential of an analog chip. And that's why the speed here is so extraordinary because we're no longer working in this digitally clocked world. But we're again, exploiting the physics of the system, the physical nature of the system to do that math for us. And you can perform inference as just a wave of electricity from input out. Amazing. I know that Tesla, for instance, is doing we can debate whether the term full is is an appropriate modifier there, but full self driving on atom chips, right? Not saying that all the training and learning is happening there, but that's what's actively involved in the vehicle. So just imagining what this could do for self driving, for automated machinery, for robotics, for AI. It's kind of mind blowing. Gordon, thank you for spending this time with us. I really do appreciate it. Thank you so much for the time, John. It was a pleasure.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 3.68, "text": " Ultimately, we see this as kind of like Lego pieces that, you know,", "tokens": [50364, 23921, 11, 321, 536, 341, 382, 733, 295, 411, 28761, 3755, 300, 11, 291, 458, 11, 50548], "temperature": 0.0, "avg_logprob": -0.2611372891594382, "compression_ratio": 1.5985130111524164, "no_speech_prob": 0.004902631510049105}, {"id": 1, "seek": 0, "start": 3.72, "end": 8.0, "text": " due to their low power footprints, we'll be able to concatenate them together", "tokens": [50550, 3462, 281, 641, 2295, 1347, 45715, 11, 321, 603, 312, 1075, 281, 1588, 7186, 473, 552, 1214, 50764], "temperature": 0.0, "avg_logprob": -0.2611372891594382, "compression_ratio": 1.5985130111524164, "no_speech_prob": 0.004902631510049105}, {"id": 2, "seek": 0, "start": 8.0, "end": 12.48, "text": " using things like chip lead integration, advanced packaging, and ultimately", "tokens": [50764, 1228, 721, 411, 11409, 1477, 10980, 11, 7339, 16836, 11, 293, 6284, 50988], "temperature": 0.0, "avg_logprob": -0.2611372891594382, "compression_ratio": 1.5985130111524164, "no_speech_prob": 0.004902631510049105}, {"id": 3, "seek": 0, "start": 12.52, "end": 17.240000000000002, "text": " scale out these systems to be brain scale, 86 billion neurons,", "tokens": [50990, 4373, 484, 613, 3652, 281, 312, 3567, 4373, 11, 26687, 5218, 22027, 11, 51226], "temperature": 0.0, "avg_logprob": -0.2611372891594382, "compression_ratio": 1.5985130111524164, "no_speech_prob": 0.004902631510049105}, {"id": 4, "seek": 0, "start": 17.32, "end": 23.32, "text": " 500 trillion synapses, and low power enough that they can exist in autonomous devices.", "tokens": [51230, 5923, 18723, 5451, 2382, 279, 11, 293, 2295, 1347, 1547, 300, 436, 393, 2514, 294, 23797, 5759, 13, 51530], "temperature": 0.0, "avg_logprob": -0.2611372891594382, "compression_ratio": 1.5985130111524164, "no_speech_prob": 0.004902631510049105}, {"id": 5, "seek": 0, "start": 23.88, "end": 28.080000000000002, "text": " Can we build a computer chip that operates like the brain?", "tokens": [51558, 1664, 321, 1322, 257, 3820, 11409, 300, 22577, 411, 264, 3567, 30, 51768], "temperature": 0.0, "avg_logprob": -0.2611372891594382, "compression_ratio": 1.5985130111524164, "no_speech_prob": 0.004902631510049105}, {"id": 6, "seek": 2808, "start": 28.639999999999997, "end": 32.96, "text": " We've seen neuromorphic computer chips from companies like Intel before,", "tokens": [50392, 492, 600, 1612, 12087, 32702, 299, 3820, 11583, 490, 3431, 411, 19762, 949, 11, 50608], "temperature": 0.0, "avg_logprob": -0.1727590373918122, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.0006262277020141482}, {"id": 7, "seek": 2808, "start": 32.96, "end": 37.08, "text": " like the Luigi chip, which Intel claimed had a sense of smell.", "tokens": [50608, 411, 264, 33308, 11409, 11, 597, 19762, 12941, 632, 257, 2020, 295, 4316, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1727590373918122, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.0006262277020141482}, {"id": 8, "seek": 2808, "start": 37.599999999999994, "end": 42.239999999999995, "text": " Rain neuromorphics, however, says it has an end-to-end analog chip,", "tokens": [50840, 14487, 12087, 32702, 1167, 11, 4461, 11, 1619, 309, 575, 364, 917, 12, 1353, 12, 521, 16660, 11409, 11, 51072], "temperature": 0.0, "avg_logprob": -0.1727590373918122, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.0006262277020141482}, {"id": 9, "seek": 2808, "start": 42.519999999999996, "end": 47.28, "text": " a neuromorphic processing unit that they say is the world's first end-to-end", "tokens": [51086, 257, 12087, 32702, 299, 9007, 4985, 300, 436, 584, 307, 264, 1002, 311, 700, 917, 12, 1353, 12, 521, 51324], "temperature": 0.0, "avg_logprob": -0.1727590373918122, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.0006262277020141482}, {"id": 10, "seek": 2808, "start": 47.28, "end": 49.879999999999995, "text": " analog trainable AI circuit.", "tokens": [51324, 16660, 3847, 712, 7318, 9048, 13, 51454], "temperature": 0.0, "avg_logprob": -0.1727590373918122, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.0006262277020141482}, {"id": 11, "seek": 2808, "start": 50.2, "end": 55.480000000000004, "text": " It's a fully analog neural network, and it's a thousand times more energy", "tokens": [51470, 467, 311, 257, 4498, 16660, 18161, 3209, 11, 293, 309, 311, 257, 4714, 1413, 544, 2281, 51734], "temperature": 0.0, "avg_logprob": -0.1727590373918122, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.0006262277020141482}, {"id": 12, "seek": 5548, "start": 55.48, "end": 58.279999999999994, "text": " efficient than today's best processors.", "tokens": [50364, 7148, 813, 965, 311, 1151, 27751, 13, 50504], "temperature": 0.0, "avg_logprob": -0.14892240671011117, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.006096361204981804}, {"id": 13, "seek": 5548, "start": 58.559999999999995, "end": 61.8, "text": " Here to chat is Rain neuromorphic CEO, Gordon Wilson.", "tokens": [50518, 1692, 281, 5081, 307, 14487, 12087, 32702, 299, 9282, 11, 19369, 15388, 13, 50680], "temperature": 0.0, "avg_logprob": -0.14892240671011117, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.006096361204981804}, {"id": 14, "seek": 5548, "start": 62.08, "end": 62.8, "text": " Welcome, Gordon.", "tokens": [50694, 4027, 11, 19369, 13, 50730], "temperature": 0.0, "avg_logprob": -0.14892240671011117, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.006096361204981804}, {"id": 15, "seek": 5548, "start": 63.879999999999995, "end": 65.03999999999999, "text": " Thanks so much for having me, John.", "tokens": [50784, 2561, 370, 709, 337, 1419, 385, 11, 2619, 13, 50842], "temperature": 0.0, "avg_logprob": -0.14892240671011117, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.006096361204981804}, {"id": 16, "seek": 5548, "start": 65.08, "end": 65.75999999999999, "text": " It's good to be here.", "tokens": [50844, 467, 311, 665, 281, 312, 510, 13, 50878], "temperature": 0.0, "avg_logprob": -0.14892240671011117, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.006096361204981804}, {"id": 17, "seek": 5548, "start": 66.84, "end": 67.84, "text": " It's good to have you.", "tokens": [50932, 467, 311, 665, 281, 362, 291, 13, 50982], "temperature": 0.0, "avg_logprob": -0.14892240671011117, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.006096361204981804}, {"id": 18, "seek": 5548, "start": 68.08, "end": 71.36, "text": " When I see neuromorphics in the inbox, I got to check it out.", "tokens": [50994, 1133, 286, 536, 12087, 32702, 1167, 294, 264, 35067, 11, 286, 658, 281, 1520, 309, 484, 13, 51158], "temperature": 0.0, "avg_logprob": -0.14892240671011117, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.006096361204981804}, {"id": 19, "seek": 5548, "start": 71.36, "end": 72.56, "text": " It's a cool space.", "tokens": [51158, 467, 311, 257, 1627, 1901, 13, 51218], "temperature": 0.0, "avg_logprob": -0.14892240671011117, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.006096361204981804}, {"id": 20, "seek": 5548, "start": 73.32, "end": 74.24, "text": " Let's start here.", "tokens": [51256, 961, 311, 722, 510, 13, 51302], "temperature": 0.0, "avg_logprob": -0.14892240671011117, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.006096361204981804}, {"id": 21, "seek": 5548, "start": 74.28, "end": 75.88, "text": " What the heck is an analog chip?", "tokens": [51304, 708, 264, 12872, 307, 364, 16660, 11409, 30, 51384], "temperature": 0.0, "avg_logprob": -0.14892240671011117, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.006096361204981804}, {"id": 22, "seek": 5548, "start": 77.16, "end": 78.32, "text": " Yeah, great question.", "tokens": [51448, 865, 11, 869, 1168, 13, 51506], "temperature": 0.0, "avg_logprob": -0.14892240671011117, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.006096361204981804}, {"id": 23, "seek": 5548, "start": 78.32, "end": 82.6, "text": " And I think a great kicking off point because it really allows us to frame kind", "tokens": [51506, 400, 286, 519, 257, 869, 19137, 766, 935, 570, 309, 534, 4045, 505, 281, 3920, 733, 51720], "temperature": 0.0, "avg_logprob": -0.14892240671011117, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.006096361204981804}, {"id": 24, "seek": 8260, "start": 82.6, "end": 86.6, "text": " of what we're doing compared to what has been done for this past decade.", "tokens": [50364, 295, 437, 321, 434, 884, 5347, 281, 437, 575, 668, 1096, 337, 341, 1791, 10378, 13, 50564], "temperature": 0.0, "avg_logprob": -0.11704597265824028, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.003270704997703433}, {"id": 25, "seek": 8260, "start": 87.16, "end": 92.32, "text": " And I think it's easiest to understand what an analog chip is in contrast", "tokens": [50592, 400, 286, 519, 309, 311, 12889, 281, 1223, 437, 364, 16660, 11409, 307, 294, 8712, 50850], "temperature": 0.0, "avg_logprob": -0.11704597265824028, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.003270704997703433}, {"id": 26, "seek": 8260, "start": 92.32, "end": 97.96, "text": " to the neural networks, the AI that have defined this last decade of deep learning.", "tokens": [50850, 281, 264, 18161, 9590, 11, 264, 7318, 300, 362, 7642, 341, 1036, 10378, 295, 2452, 2539, 13, 51132], "temperature": 0.0, "avg_logprob": -0.11704597265824028, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.003270704997703433}, {"id": 27, "seek": 8260, "start": 98.56, "end": 103.88, "text": " So in 2012, we kind of had a big event that started this new era, this AI", "tokens": [51162, 407, 294, 9125, 11, 321, 733, 295, 632, 257, 955, 2280, 300, 1409, 341, 777, 4249, 11, 341, 7318, 51428], "temperature": 0.0, "avg_logprob": -0.11704597265824028, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.003270704997703433}, {"id": 28, "seek": 8260, "start": 103.88, "end": 110.63999999999999, "text": " Renaissance, and we are seeing these massive neural networks grow in size", "tokens": [51428, 32642, 11, 293, 321, 366, 2577, 613, 5994, 18161, 9590, 1852, 294, 2744, 51766], "temperature": 0.0, "avg_logprob": -0.11704597265824028, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.003270704997703433}, {"id": 29, "seek": 11064, "start": 110.64, "end": 112.92, "text": " and grow in capabilities since then.", "tokens": [50364, 293, 1852, 294, 10862, 1670, 550, 13, 50478], "temperature": 0.0, "avg_logprob": -0.13155761207501912, "compression_ratio": 1.7459677419354838, "no_speech_prob": 0.002714232774451375}, {"id": 30, "seek": 11064, "start": 113.28, "end": 117.44, "text": " But all of those neural networks that we've seen in this deep learning", "tokens": [50496, 583, 439, 295, 729, 18161, 9590, 300, 321, 600, 1612, 294, 341, 2452, 2539, 50704], "temperature": 0.0, "avg_logprob": -0.13155761207501912, "compression_ratio": 1.7459677419354838, "no_speech_prob": 0.002714232774451375}, {"id": 31, "seek": 11064, "start": 117.44, "end": 120.04, "text": " world are neural simulations.", "tokens": [50704, 1002, 366, 18161, 35138, 13, 50834], "temperature": 0.0, "avg_logprob": -0.13155761207501912, "compression_ratio": 1.7459677419354838, "no_speech_prob": 0.002714232774451375}, {"id": 32, "seek": 11064, "start": 120.44, "end": 125.84, "text": " They are abstractions that are written in software and the neurons and synapses", "tokens": [50854, 814, 366, 12649, 626, 300, 366, 3720, 294, 4722, 293, 264, 22027, 293, 5451, 2382, 279, 51124], "temperature": 0.0, "avg_logprob": -0.13155761207501912, "compression_ratio": 1.7459677419354838, "no_speech_prob": 0.002714232774451375}, {"id": 33, "seek": 11064, "start": 125.84, "end": 130.48, "text": " that are defined in that software don't physically exist, but rather they", "tokens": [51124, 300, 366, 7642, 294, 300, 4722, 500, 380, 9762, 2514, 11, 457, 2831, 436, 51356], "temperature": 0.0, "avg_logprob": -0.13155761207501912, "compression_ratio": 1.7459677419354838, "no_speech_prob": 0.002714232774451375}, {"id": 34, "seek": 11064, "start": 130.48, "end": 133.64, "text": " sit on this highest layer usually written in Python and that are then", "tokens": [51356, 1394, 322, 341, 6343, 4583, 2673, 3720, 294, 15329, 293, 300, 366, 550, 51514], "temperature": 0.0, "avg_logprob": -0.13155761207501912, "compression_ratio": 1.7459677419354838, "no_speech_prob": 0.002714232774451375}, {"id": 35, "seek": 11064, "start": 133.64, "end": 137.64, "text": " translated through many layers of abstraction down until it gets to the", "tokens": [51514, 16805, 807, 867, 7914, 295, 37765, 760, 1826, 309, 2170, 281, 264, 51714], "temperature": 0.0, "avg_logprob": -0.13155761207501912, "compression_ratio": 1.7459677419354838, "no_speech_prob": 0.002714232774451375}, {"id": 36, "seek": 13764, "start": 137.64, "end": 142.6, "text": " digital circuit, most of the time a GPU graphics processing unit where it", "tokens": [50364, 4562, 9048, 11, 881, 295, 264, 565, 257, 18407, 11837, 9007, 4985, 689, 309, 50612], "temperature": 0.0, "avg_logprob": -0.11023528903138403, "compression_ratio": 1.7245762711864407, "no_speech_prob": 0.002980306511744857}, {"id": 37, "seek": 13764, "start": 142.6, "end": 146.44, "text": " then processes that math that represents that neural network at the top.", "tokens": [50612, 550, 7555, 300, 5221, 300, 8855, 300, 18161, 3209, 412, 264, 1192, 13, 50804], "temperature": 0.0, "avg_logprob": -0.11023528903138403, "compression_ratio": 1.7245762711864407, "no_speech_prob": 0.002980306511744857}, {"id": 38, "seek": 13764, "start": 148.27999999999997, "end": 151.51999999999998, "text": " An analog chip and a neuromorphic chip is different.", "tokens": [50896, 1107, 16660, 11409, 293, 257, 12087, 32702, 299, 11409, 307, 819, 13, 51058], "temperature": 0.0, "avg_logprob": -0.11023528903138403, "compression_ratio": 1.7245762711864407, "no_speech_prob": 0.002980306511744857}, {"id": 39, "seek": 13764, "start": 151.88, "end": 156.23999999999998, "text": " It's not a neural simulation, but rather it's a neural circuit.", "tokens": [51076, 467, 311, 406, 257, 18161, 16575, 11, 457, 2831, 309, 311, 257, 18161, 9048, 13, 51294], "temperature": 0.0, "avg_logprob": -0.11023528903138403, "compression_ratio": 1.7245762711864407, "no_speech_prob": 0.002980306511744857}, {"id": 40, "seek": 13764, "start": 156.64, "end": 161.35999999999999, "text": " It's a physical collection of neurons and synapses as opposed to an", "tokens": [51314, 467, 311, 257, 4001, 5765, 295, 22027, 293, 5451, 2382, 279, 382, 8851, 281, 364, 51550], "temperature": 0.0, "avg_logprob": -0.11023528903138403, "compression_ratio": 1.7245762711864407, "no_speech_prob": 0.002980306511744857}, {"id": 41, "seek": 13764, "start": 161.35999999999999, "end": 163.32, "text": " abstraction of neurons and synapses.", "tokens": [51550, 37765, 295, 22027, 293, 5451, 2382, 279, 13, 51648], "temperature": 0.0, "avg_logprob": -0.11023528903138403, "compression_ratio": 1.7245762711864407, "no_speech_prob": 0.002980306511744857}, {"id": 42, "seek": 13764, "start": 163.88, "end": 166.44, "text": " And this is very similar to the brain.", "tokens": [51676, 400, 341, 307, 588, 2531, 281, 264, 3567, 13, 51804], "temperature": 0.0, "avg_logprob": -0.11023528903138403, "compression_ratio": 1.7245762711864407, "no_speech_prob": 0.002980306511744857}, {"id": 43, "seek": 16644, "start": 166.8, "end": 169.96, "text": " The brain is a collection of physical neurons and synapses.", "tokens": [50382, 440, 3567, 307, 257, 5765, 295, 4001, 22027, 293, 5451, 2382, 279, 13, 50540], "temperature": 0.0, "avg_logprob": -0.15870586354681787, "compression_ratio": 1.75, "no_speech_prob": 0.0007548507419414818}, {"id": 44, "seek": 16644, "start": 170.0, "end": 174.52, "text": " It's governed by the laws of physics and it achieves all that it does with", "tokens": [50542, 467, 311, 35529, 538, 264, 6064, 295, 10649, 293, 309, 3538, 977, 439, 300, 309, 775, 365, 50768], "temperature": 0.0, "avg_logprob": -0.15870586354681787, "compression_ratio": 1.75, "no_speech_prob": 0.0007548507419414818}, {"id": 45, "seek": 16644, "start": 174.64, "end": 180.64, "text": " extraordinary scale and extraordinary efficiency within the bounds of the", "tokens": [50774, 10581, 4373, 293, 10581, 10493, 1951, 264, 29905, 295, 264, 51074], "temperature": 0.0, "avg_logprob": -0.15870586354681787, "compression_ratio": 1.75, "no_speech_prob": 0.0007548507419414818}, {"id": 46, "seek": 16644, "start": 180.64, "end": 181.52, "text": " physical world.", "tokens": [51074, 4001, 1002, 13, 51118], "temperature": 0.0, "avg_logprob": -0.15870586354681787, "compression_ratio": 1.75, "no_speech_prob": 0.0007548507419414818}, {"id": 47, "seek": 16644, "start": 182.0, "end": 186.44, "text": " So an analog chip, as we're building it, is trying to achieve something", "tokens": [51142, 407, 364, 16660, 11409, 11, 382, 321, 434, 2390, 309, 11, 307, 1382, 281, 4584, 746, 51364], "temperature": 0.0, "avg_logprob": -0.15870586354681787, "compression_ratio": 1.75, "no_speech_prob": 0.0007548507419414818}, {"id": 48, "seek": 16644, "start": 186.44, "end": 193.16, "text": " simple, trying to find ways to learn, find ways to scale all within the physical", "tokens": [51364, 2199, 11, 1382, 281, 915, 2098, 281, 1466, 11, 915, 2098, 281, 4373, 439, 1951, 264, 4001, 51700], "temperature": 0.0, "avg_logprob": -0.15870586354681787, "compression_ratio": 1.75, "no_speech_prob": 0.0007548507419414818}, {"id": 49, "seek": 16644, "start": 193.16, "end": 193.48, "text": " domain.", "tokens": [51700, 9274, 13, 51716], "temperature": 0.0, "avg_logprob": -0.15870586354681787, "compression_ratio": 1.75, "no_speech_prob": 0.0007548507419414818}, {"id": 50, "seek": 19348, "start": 194.48, "end": 196.92, "text": " So let's dig into that just a little deeper.", "tokens": [50414, 407, 718, 311, 2528, 666, 300, 445, 257, 707, 7731, 13, 50536], "temperature": 0.0, "avg_logprob": -0.3560876938903216, "compression_ratio": 1.6, "no_speech_prob": 0.001264247577637434}, {"id": 51, "seek": 19348, "start": 197.48, "end": 199.56, "text": " Great, great overview.", "tokens": [50564, 3769, 11, 869, 12492, 13, 50668], "temperature": 0.0, "avg_logprob": -0.3560876938903216, "compression_ratio": 1.6, "no_speech_prob": 0.001264247577637434}, {"id": 52, "seek": 19348, "start": 200.12, "end": 201.48, "text": " What does that mean?", "tokens": [50696, 708, 775, 300, 914, 30, 50764], "temperature": 0.0, "avg_logprob": -0.3560876938903216, "compression_ratio": 1.6, "no_speech_prob": 0.001264247577637434}, {"id": 53, "seek": 19348, "start": 202.04, "end": 206.44, "text": " Typically a chip will think in terms of or operate in terms of on or off one or", "tokens": [50792, 23129, 257, 11409, 486, 519, 294, 2115, 295, 420, 9651, 294, 2115, 295, 322, 420, 766, 472, 420, 51012], "temperature": 0.0, "avg_logprob": -0.3560876938903216, "compression_ratio": 1.6, "no_speech_prob": 0.001264247577637434}, {"id": 54, "seek": 19348, "start": 206.44, "end": 207.28, "text": " zero, right?", "tokens": [51012, 4018, 11, 558, 30, 51054], "temperature": 0.0, "avg_logprob": -0.3560876938903216, "compression_ratio": 1.6, "no_speech_prob": 0.001264247577637434}, {"id": 55, "seek": 19348, "start": 207.28, "end": 208.83999999999997, "text": " Binary logic, right?", "tokens": [51054, 363, 4066, 9952, 11, 558, 30, 51132], "temperature": 0.0, "avg_logprob": -0.3560876938903216, "compression_ratio": 1.6, "no_speech_prob": 0.001264247577637434}, {"id": 56, "seek": 19348, "start": 209.92, "end": 213.88, "text": " What does an analog chip, how does that work?", "tokens": [51186, 708, 775, 364, 16660, 11409, 11, 577, 775, 300, 589, 30, 51384], "temperature": 0.0, "avg_logprob": -0.3560876938903216, "compression_ratio": 1.6, "no_speech_prob": 0.001264247577637434}, {"id": 57, "seek": 19348, "start": 213.88, "end": 214.72, "text": " What's that look like?", "tokens": [51384, 708, 311, 300, 574, 411, 30, 51426], "temperature": 0.0, "avg_logprob": -0.3560876938903216, "compression_ratio": 1.6, "no_speech_prob": 0.001264247577637434}, {"id": 58, "seek": 19348, "start": 215.72, "end": 221.39999999999998, "text": " So digital chips are, as you said, built on the very bottom on zeros and", "tokens": [51476, 407, 4562, 11583, 366, 11, 382, 291, 848, 11, 3094, 322, 264, 588, 2767, 322, 35193, 293, 51760], "temperature": 0.0, "avg_logprob": -0.3560876938903216, "compression_ratio": 1.6, "no_speech_prob": 0.001264247577637434}, {"id": 59, "seek": 22140, "start": 221.96, "end": 225.48000000000002, "text": " ones on this Boolean logic of on or off.", "tokens": [50392, 2306, 322, 341, 23351, 28499, 9952, 295, 322, 420, 766, 13, 50568], "temperature": 0.0, "avg_logprob": -0.14451231020633307, "compression_ratio": 1.852, "no_speech_prob": 0.0043303207494318485}, {"id": 60, "seek": 22140, "start": 225.92000000000002, "end": 228.76000000000002, "text": " And all of the other logic is then constructed on top of that.", "tokens": [50590, 400, 439, 295, 264, 661, 9952, 307, 550, 17083, 322, 1192, 295, 300, 13, 50732], "temperature": 0.0, "avg_logprob": -0.14451231020633307, "compression_ratio": 1.852, "no_speech_prob": 0.0043303207494318485}, {"id": 61, "seek": 22140, "start": 229.24, "end": 233.36, "text": " When you zoom down to the bottom of an analog chip, you don't have zeros or", "tokens": [50756, 1133, 291, 8863, 760, 281, 264, 2767, 295, 364, 16660, 11409, 11, 291, 500, 380, 362, 35193, 420, 50962], "temperature": 0.0, "avg_logprob": -0.14451231020633307, "compression_ratio": 1.852, "no_speech_prob": 0.0043303207494318485}, {"id": 62, "seek": 22140, "start": 233.36, "end": 239.8, "text": " ones, you have gradients of information, you have voltages and currents and", "tokens": [50962, 2306, 11, 291, 362, 2771, 2448, 295, 1589, 11, 291, 362, 49614, 293, 30110, 293, 51284], "temperature": 0.0, "avg_logprob": -0.14451231020633307, "compression_ratio": 1.852, "no_speech_prob": 0.0043303207494318485}, {"id": 63, "seek": 22140, "start": 239.8, "end": 243.92000000000002, "text": " resistances, you have physical quantities that you're measuring that", "tokens": [51284, 4597, 2676, 11, 291, 362, 4001, 22927, 300, 291, 434, 13389, 300, 51490], "temperature": 0.0, "avg_logprob": -0.14451231020633307, "compression_ratio": 1.852, "no_speech_prob": 0.0043303207494318485}, {"id": 64, "seek": 22140, "start": 243.92000000000002, "end": 247.16, "text": " represents the mathematical operations that you're performing.", "tokens": [51490, 8855, 264, 18894, 7705, 300, 291, 434, 10205, 13, 51652], "temperature": 0.0, "avg_logprob": -0.14451231020633307, "compression_ratio": 1.852, "no_speech_prob": 0.0043303207494318485}, {"id": 65, "seek": 22140, "start": 247.6, "end": 251.16, "text": " And you're exploiting the relationship between those physical quantities to", "tokens": [51674, 400, 291, 434, 12382, 1748, 264, 2480, 1296, 729, 4001, 22927, 281, 51852], "temperature": 0.0, "avg_logprob": -0.14451231020633307, "compression_ratio": 1.852, "no_speech_prob": 0.0043303207494318485}, {"id": 66, "seek": 25116, "start": 251.16, "end": 255.2, "text": " then perform these very complex neural operations.", "tokens": [50364, 550, 2042, 613, 588, 3997, 18161, 7705, 13, 50566], "temperature": 0.0, "avg_logprob": -0.11659716114853368, "compression_ratio": 1.6042780748663101, "no_speech_prob": 0.0005192033713683486}, {"id": 67, "seek": 25116, "start": 255.68, "end": 259.44, "text": " So an example of this is like matrix vector multiplication.", "tokens": [50590, 407, 364, 1365, 295, 341, 307, 411, 8141, 8062, 27290, 13, 50778], "temperature": 0.0, "avg_logprob": -0.11659716114853368, "compression_ratio": 1.6042780748663101, "no_speech_prob": 0.0005192033713683486}, {"id": 68, "seek": 25116, "start": 259.44, "end": 264.6, "text": " This is the backbone of most neural network math.", "tokens": [50778, 639, 307, 264, 34889, 295, 881, 18161, 3209, 5221, 13, 51036], "temperature": 0.0, "avg_logprob": -0.11659716114853368, "compression_ratio": 1.6042780748663101, "no_speech_prob": 0.0005192033713683486}, {"id": 69, "seek": 25116, "start": 265.15999999999997, "end": 271.04, "text": " And GPUs do this by parallelizing these multiplications across a lot of", "tokens": [51064, 400, 18407, 82, 360, 341, 538, 8952, 3319, 613, 17596, 763, 2108, 257, 688, 295, 51358], "temperature": 0.0, "avg_logprob": -0.11659716114853368, "compression_ratio": 1.6042780748663101, "no_speech_prob": 0.0005192033713683486}, {"id": 70, "seek": 25116, "start": 271.04, "end": 275.36, "text": " digital cores and doing precise digital multiplication in addition.", "tokens": [51358, 4562, 24826, 293, 884, 13600, 4562, 27290, 294, 4500, 13, 51574], "temperature": 0.0, "avg_logprob": -0.11659716114853368, "compression_ratio": 1.6042780748663101, "no_speech_prob": 0.0005192033713683486}, {"id": 71, "seek": 27536, "start": 276.36, "end": 281.2, "text": " In an analog chip, as we are building it, we're not doing this with highly", "tokens": [50414, 682, 364, 16660, 11409, 11, 382, 321, 366, 2390, 309, 11, 321, 434, 406, 884, 341, 365, 5405, 50656], "temperature": 0.0, "avg_logprob": -0.16668448785338738, "compression_ratio": 1.7418032786885247, "no_speech_prob": 0.002396238036453724}, {"id": 72, "seek": 27536, "start": 281.2, "end": 285.76, "text": " precise digital math, but instead we have the activations of the neurons", "tokens": [50656, 13600, 4562, 5221, 11, 457, 2602, 321, 362, 264, 2430, 763, 295, 264, 22027, 50884], "temperature": 0.0, "avg_logprob": -0.16668448785338738, "compression_ratio": 1.7418032786885247, "no_speech_prob": 0.002396238036453724}, {"id": 73, "seek": 27536, "start": 285.76, "end": 287.12, "text": " represented by voltages.", "tokens": [50884, 10379, 538, 49614, 13, 50952], "temperature": 0.0, "avg_logprob": -0.16668448785338738, "compression_ratio": 1.7418032786885247, "no_speech_prob": 0.002396238036453724}, {"id": 74, "seek": 27536, "start": 287.52000000000004, "end": 292.92, "text": " We have the weights of the synapses represented by resistances, which are", "tokens": [50972, 492, 362, 264, 17443, 295, 264, 5451, 2382, 279, 10379, 538, 4597, 2676, 11, 597, 366, 51242], "temperature": 0.0, "avg_logprob": -0.16668448785338738, "compression_ratio": 1.7418032786885247, "no_speech_prob": 0.002396238036453724}, {"id": 75, "seek": 27536, "start": 292.92, "end": 294.96000000000004, "text": " held in components called memristors.", "tokens": [51242, 5167, 294, 6677, 1219, 1334, 12940, 830, 13, 51344], "temperature": 0.0, "avg_logprob": -0.16668448785338738, "compression_ratio": 1.7418032786885247, "no_speech_prob": 0.002396238036453724}, {"id": 76, "seek": 27536, "start": 295.48, "end": 299.32, "text": " And when that voltage passes across that resistance, you have a natural", "tokens": [51370, 400, 562, 300, 8352, 11335, 2108, 300, 7335, 11, 291, 362, 257, 3303, 51562], "temperature": 0.0, "avg_logprob": -0.16668448785338738, "compression_ratio": 1.7418032786885247, "no_speech_prob": 0.002396238036453724}, {"id": 77, "seek": 27536, "start": 299.32, "end": 303.44, "text": " relationship between voltage and resistance that's multiplicative to", "tokens": [51562, 2480, 1296, 8352, 293, 7335, 300, 311, 17596, 1166, 281, 51768], "temperature": 0.0, "avg_logprob": -0.16668448785338738, "compression_ratio": 1.7418032786885247, "no_speech_prob": 0.002396238036453724}, {"id": 78, "seek": 30344, "start": 303.6, "end": 307.0, "text": " receive a current, you read out a current and that's your output.", "tokens": [50372, 4774, 257, 2190, 11, 291, 1401, 484, 257, 2190, 293, 300, 311, 428, 5598, 13, 50542], "temperature": 0.0, "avg_logprob": -0.14659269232498973, "compression_ratio": 1.6225490196078431, "no_speech_prob": 0.0008039494277909398}, {"id": 79, "seek": 30344, "start": 307.44, "end": 312.71999999999997, "text": " So an analog chip works by kind of first understanding these physical", "tokens": [50564, 407, 364, 16660, 11409, 1985, 538, 733, 295, 700, 3701, 613, 4001, 50828], "temperature": 0.0, "avg_logprob": -0.14659269232498973, "compression_ratio": 1.6225490196078431, "no_speech_prob": 0.0008039494277909398}, {"id": 80, "seek": 30344, "start": 312.71999999999997, "end": 317.96, "text": " relationships between electrical quantities and exploiting those to do", "tokens": [50828, 6159, 1296, 12147, 22927, 293, 12382, 1748, 729, 281, 360, 51090], "temperature": 0.0, "avg_logprob": -0.14659269232498973, "compression_ratio": 1.6225490196078431, "no_speech_prob": 0.0008039494277909398}, {"id": 81, "seek": 30344, "start": 317.96, "end": 320.96, "text": " the math, to make the physics do the math for us.", "tokens": [51090, 264, 5221, 11, 281, 652, 264, 10649, 360, 264, 5221, 337, 505, 13, 51240], "temperature": 0.0, "avg_logprob": -0.14659269232498973, "compression_ratio": 1.6225490196078431, "no_speech_prob": 0.0008039494277909398}, {"id": 82, "seek": 30344, "start": 323.0, "end": 330.48, "text": " That sounds super interesting and it sounds at once very, very complex and", "tokens": [51342, 663, 3263, 1687, 1880, 293, 309, 3263, 412, 1564, 588, 11, 588, 3997, 293, 51716], "temperature": 0.0, "avg_logprob": -0.14659269232498973, "compression_ratio": 1.6225490196078431, "no_speech_prob": 0.0008039494277909398}, {"id": 83, "seek": 33048, "start": 330.48, "end": 333.76, "text": " at the same time kind of simple, right?", "tokens": [50364, 412, 264, 912, 565, 733, 295, 2199, 11, 558, 30, 50528], "temperature": 0.0, "avg_logprob": -0.12704264640808105, "compression_ratio": 1.6639676113360324, "no_speech_prob": 0.005058924667537212}, {"id": 84, "seek": 33048, "start": 334.08000000000004, "end": 339.48, "text": " And is that one of the key reasons why your chip is so much more energy efficient?", "tokens": [50544, 400, 307, 300, 472, 295, 264, 2141, 4112, 983, 428, 11409, 307, 370, 709, 544, 2281, 7148, 30, 50814], "temperature": 0.0, "avg_logprob": -0.12704264640808105, "compression_ratio": 1.6639676113360324, "no_speech_prob": 0.005058924667537212}, {"id": 85, "seek": 33048, "start": 339.48, "end": 342.76, "text": " I mean, you're claiming a thousand times more energy efficient.", "tokens": [50814, 286, 914, 11, 291, 434, 19232, 257, 4714, 1413, 544, 2281, 7148, 13, 50978], "temperature": 0.0, "avg_logprob": -0.12704264640808105, "compression_ratio": 1.6639676113360324, "no_speech_prob": 0.005058924667537212}, {"id": 86, "seek": 33048, "start": 343.44, "end": 344.76, "text": " Yeah, exactly.", "tokens": [51012, 865, 11, 2293, 13, 51078], "temperature": 0.0, "avg_logprob": -0.12704264640808105, "compression_ratio": 1.6639676113360324, "no_speech_prob": 0.005058924667537212}, {"id": 87, "seek": 33048, "start": 345.12, "end": 347.88, "text": " That really is, I think, the most fundamental reason.", "tokens": [51096, 663, 534, 307, 11, 286, 519, 11, 264, 881, 8088, 1778, 13, 51234], "temperature": 0.0, "avg_logprob": -0.12704264640808105, "compression_ratio": 1.6639676113360324, "no_speech_prob": 0.005058924667537212}, {"id": 88, "seek": 33048, "start": 347.88, "end": 352.8, "text": " And I think when you consider the comparison again to the neural simulation,", "tokens": [51234, 400, 286, 519, 562, 291, 1949, 264, 9660, 797, 281, 264, 18161, 16575, 11, 51480], "temperature": 0.0, "avg_logprob": -0.12704264640808105, "compression_ratio": 1.6639676113360324, "no_speech_prob": 0.005058924667537212}, {"id": 89, "seek": 33048, "start": 353.44, "end": 357.92, "text": " the neural network in that simulation exists so many layers above and requires", "tokens": [51512, 264, 18161, 3209, 294, 300, 16575, 8198, 370, 867, 7914, 3673, 293, 7029, 51736], "temperature": 0.0, "avg_logprob": -0.12704264640808105, "compression_ratio": 1.6639676113360324, "no_speech_prob": 0.005058924667537212}, {"id": 90, "seek": 35792, "start": 357.92, "end": 363.56, "text": " to be translated and then performed on a circuit that is really not that", "tokens": [50364, 281, 312, 16805, 293, 550, 10332, 322, 257, 9048, 300, 307, 534, 406, 300, 50646], "temperature": 0.0, "avg_logprob": -0.1317627575932717, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.001151155331172049}, {"id": 91, "seek": 35792, "start": 363.56, "end": 366.64000000000004, "text": " well optimized for neural math.", "tokens": [50646, 731, 26941, 337, 18161, 5221, 13, 50800], "temperature": 0.0, "avg_logprob": -0.1317627575932717, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.001151155331172049}, {"id": 92, "seek": 35792, "start": 367.64000000000004, "end": 371.40000000000003, "text": " And, but in our case, the circuit is the neural network.", "tokens": [50850, 400, 11, 457, 294, 527, 1389, 11, 264, 9048, 307, 264, 18161, 3209, 13, 51038], "temperature": 0.0, "avg_logprob": -0.1317627575932717, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.001151155331172049}, {"id": 93, "seek": 35792, "start": 371.76, "end": 374.92, "text": " And because it is, it exists in that very bottom layer, it is on the", "tokens": [51056, 400, 570, 309, 307, 11, 309, 8198, 294, 300, 588, 2767, 4583, 11, 309, 307, 322, 264, 51214], "temperature": 0.0, "avg_logprob": -0.1317627575932717, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.001151155331172049}, {"id": 94, "seek": 35792, "start": 374.92, "end": 380.40000000000003, "text": " substrate of the chip itself, you can achieve some extraordinary gains in", "tokens": [51214, 27585, 295, 264, 11409, 2564, 11, 291, 393, 4584, 512, 10581, 16823, 294, 51488], "temperature": 0.0, "avg_logprob": -0.1317627575932717, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.001151155331172049}, {"id": 95, "seek": 35792, "start": 380.40000000000003, "end": 384.96000000000004, "text": " both speed and improvement and power reduction, which of course gives you", "tokens": [51488, 1293, 3073, 293, 10444, 293, 1347, 11004, 11, 597, 295, 1164, 2709, 291, 51716], "temperature": 0.0, "avg_logprob": -0.1317627575932717, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.001151155331172049}, {"id": 96, "seek": 35792, "start": 384.96000000000004, "end": 386.56, "text": " that energy efficiency gain.", "tokens": [51716, 300, 2281, 10493, 6052, 13, 51796], "temperature": 0.0, "avg_logprob": -0.1317627575932717, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.001151155331172049}, {"id": 97, "seek": 38656, "start": 387.28000000000003, "end": 391.2, "text": " So, so yeah, it's because we're building the physical thing on that bottom layer.", "tokens": [50400, 407, 11, 370, 1338, 11, 309, 311, 570, 321, 434, 2390, 264, 4001, 551, 322, 300, 2767, 4583, 13, 50596], "temperature": 0.0, "avg_logprob": -0.162957120448985, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.001809970592148602}, {"id": 98, "seek": 38656, "start": 391.88, "end": 396.28000000000003, "text": " This episode of Tech First is sponsored by Smart One.", "tokens": [50630, 639, 3500, 295, 13795, 2386, 307, 16621, 538, 12923, 1485, 13, 50850], "temperature": 0.0, "avg_logprob": -0.162957120448985, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.001809970592148602}, {"id": 99, "seek": 38656, "start": 396.68, "end": 401.4, "text": " Smart One is a smart vending machine platform that transforms traditional", "tokens": [50870, 12923, 1485, 307, 257, 4069, 371, 2029, 3479, 3663, 300, 35592, 5164, 51106], "temperature": 0.0, "avg_logprob": -0.162957120448985, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.001809970592148602}, {"id": 100, "seek": 38656, "start": 401.4, "end": 407.16, "text": " vending hardware into smarter, better, faster, automated retail kiosks, a", "tokens": [51106, 371, 2029, 8837, 666, 20294, 11, 1101, 11, 4663, 11, 18473, 10800, 350, 2717, 1694, 11, 257, 51394], "temperature": 0.0, "avg_logprob": -0.162957120448985, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.001809970592148602}, {"id": 101, "seek": 38656, "start": 407.16, "end": 409.2, "text": " convenient store without the store.", "tokens": [51394, 10851, 3531, 1553, 264, 3531, 13, 51496], "temperature": 0.0, "avg_logprob": -0.162957120448985, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.001809970592148602}, {"id": 102, "seek": 38656, "start": 409.4, "end": 413.32, "text": " Learn more at smrt1.ca.", "tokens": [51506, 17216, 544, 412, 899, 17721, 16, 13, 496, 13, 51702], "temperature": 0.0, "avg_logprob": -0.162957120448985, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.001809970592148602}, {"id": 103, "seek": 38656, "start": 413.92, "end": 415.84000000000003, "text": " That I'm fascinated.", "tokens": [51732, 663, 286, 478, 24597, 13, 51828], "temperature": 0.0, "avg_logprob": -0.162957120448985, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.001809970592148602}, {"id": 104, "seek": 41656, "start": 416.56, "end": 422.72, "text": " And I'm wondering with Boolean logic, old school computer chips, you kind", "tokens": [50364, 400, 286, 478, 6359, 365, 23351, 28499, 9952, 11, 1331, 1395, 3820, 11583, 11, 291, 733, 50672], "temperature": 0.0, "avg_logprob": -0.15180884769984654, "compression_ratio": 1.8, "no_speech_prob": 0.0003568968386389315}, {"id": 105, "seek": 41656, "start": 422.72, "end": 426.92, "text": " of have to simulate reality and go through those multiple layers of", "tokens": [50672, 295, 362, 281, 27817, 4103, 293, 352, 807, 729, 3866, 7914, 295, 50882], "temperature": 0.0, "avg_logprob": -0.15180884769984654, "compression_ratio": 1.8, "no_speech_prob": 0.0003568968386389315}, {"id": 106, "seek": 41656, "start": 426.92, "end": 431.32, "text": " translation because you're not on bare metal, you know, as the, the old", "tokens": [50882, 12853, 570, 291, 434, 406, 322, 6949, 5760, 11, 291, 458, 11, 382, 264, 11, 264, 1331, 51102], "temperature": 0.0, "avg_logprob": -0.15180884769984654, "compression_ratio": 1.8, "no_speech_prob": 0.0003568968386389315}, {"id": 107, "seek": 41656, "start": 431.32, "end": 433.2, "text": " timers and computing would tell us, right?", "tokens": [51102, 524, 433, 293, 15866, 576, 980, 505, 11, 558, 30, 51196], "temperature": 0.0, "avg_logprob": -0.15180884769984654, "compression_ratio": 1.8, "no_speech_prob": 0.0003568968386389315}, {"id": 108, "seek": 41656, "start": 433.68, "end": 436.48, "text": " Go through various layers of translation before you're actually hitting", "tokens": [51220, 1037, 807, 3683, 7914, 295, 12853, 949, 291, 434, 767, 8850, 51360], "temperature": 0.0, "avg_logprob": -0.15180884769984654, "compression_ratio": 1.8, "no_speech_prob": 0.0003568968386389315}, {"id": 109, "seek": 41656, "start": 436.48, "end": 439.28, "text": " computer, machine instruction, machine language.", "tokens": [51360, 3820, 11, 3479, 10951, 11, 3479, 2856, 13, 51500], "temperature": 0.0, "avg_logprob": -0.15180884769984654, "compression_ratio": 1.8, "no_speech_prob": 0.0003568968386389315}, {"id": 110, "seek": 41656, "start": 439.76, "end": 445.88, "text": " And you're kind of modeling reality or what you're computing in reality.", "tokens": [51524, 400, 291, 434, 733, 295, 15983, 4103, 420, 437, 291, 434, 15866, 294, 4103, 13, 51830], "temperature": 0.0, "avg_logprob": -0.15180884769984654, "compression_ratio": 1.8, "no_speech_prob": 0.0003568968386389315}, {"id": 111, "seek": 44588, "start": 445.92, "end": 447.92, "text": " Is, is that an accurate way of thinking about it?", "tokens": [50366, 1119, 11, 307, 300, 364, 8559, 636, 295, 1953, 466, 309, 30, 50466], "temperature": 0.0, "avg_logprob": -0.1446969854922695, "compression_ratio": 1.7992565055762082, "no_speech_prob": 0.0009696175693534315}, {"id": 112, "seek": 44588, "start": 447.96, "end": 448.32, "text": " Yes.", "tokens": [50468, 1079, 13, 50486], "temperature": 0.0, "avg_logprob": -0.1446969854922695, "compression_ratio": 1.7992565055762082, "no_speech_prob": 0.0009696175693534315}, {"id": 113, "seek": 44588, "start": 448.76, "end": 451.08, "text": " That's an exact way, a really great way to put it.", "tokens": [50508, 663, 311, 364, 1900, 636, 11, 257, 534, 869, 636, 281, 829, 309, 13, 50624], "temperature": 0.0, "avg_logprob": -0.1446969854922695, "compression_ratio": 1.7992565055762082, "no_speech_prob": 0.0009696175693534315}, {"id": 114, "seek": 44588, "start": 451.4, "end": 455.48, "text": " You know, I sometimes use the metaphor, like what would be easier, you know,", "tokens": [50640, 509, 458, 11, 286, 2171, 764, 264, 19157, 11, 411, 437, 576, 312, 3571, 11, 291, 458, 11, 50844], "temperature": 0.0, "avg_logprob": -0.1446969854922695, "compression_ratio": 1.7992565055762082, "no_speech_prob": 0.0009696175693534315}, {"id": 115, "seek": 44588, "start": 455.48, "end": 459.68, "text": " to, to assess your ability to kick a soccer ball on a field, right?", "tokens": [50844, 281, 11, 281, 5877, 428, 3485, 281, 4437, 257, 15469, 2594, 322, 257, 2519, 11, 558, 30, 51054], "temperature": 0.0, "avg_logprob": -0.1446969854922695, "compression_ratio": 1.7992565055762082, "no_speech_prob": 0.0009696175693534315}, {"id": 116, "seek": 44588, "start": 459.68, "end": 465.52, "text": " Would you rather, you know, reconstruct all of the physics of your body and of", "tokens": [51054, 6068, 291, 2831, 11, 291, 458, 11, 31499, 439, 295, 264, 10649, 295, 428, 1772, 293, 295, 51346], "temperature": 0.0, "avg_logprob": -0.1446969854922695, "compression_ratio": 1.7992565055762082, "no_speech_prob": 0.0009696175693534315}, {"id": 117, "seek": 44588, "start": 465.52, "end": 472.04, "text": " the soccer field and of the ball and simulate that kick and, you know, observe", "tokens": [51346, 264, 15469, 2519, 293, 295, 264, 2594, 293, 27817, 300, 4437, 293, 11, 291, 458, 11, 11441, 51672], "temperature": 0.0, "avg_logprob": -0.1446969854922695, "compression_ratio": 1.7992565055762082, "no_speech_prob": 0.0009696175693534315}, {"id": 118, "seek": 44588, "start": 472.04, "end": 475.4, "text": " that in the simulated world, or would you just rather walk out of the pitch", "tokens": [51672, 300, 294, 264, 41713, 1002, 11, 420, 576, 291, 445, 2831, 1792, 484, 295, 264, 7293, 51840], "temperature": 0.0, "avg_logprob": -0.1446969854922695, "compression_ratio": 1.7992565055762082, "no_speech_prob": 0.0009696175693534315}, {"id": 119, "seek": 47540, "start": 475.76, "end": 476.47999999999996, "text": " and kick the ball?", "tokens": [50382, 293, 4437, 264, 2594, 30, 50418], "temperature": 0.0, "avg_logprob": -0.14604840036165917, "compression_ratio": 1.702127659574468, "no_speech_prob": 0.0002959097037091851}, {"id": 120, "seek": 47540, "start": 477.03999999999996, "end": 481.64, "text": " You know, it's for us, it feels very obvious that, you know, the most natural", "tokens": [50446, 509, 458, 11, 309, 311, 337, 505, 11, 309, 3417, 588, 6322, 300, 11, 291, 458, 11, 264, 881, 3303, 50676], "temperature": 0.0, "avg_logprob": -0.14604840036165917, "compression_ratio": 1.702127659574468, "no_speech_prob": 0.0002959097037091851}, {"id": 121, "seek": 47540, "start": 481.64, "end": 487.91999999999996, "text": " way to build a neural network, uh, to make it as efficient as the brain is to", "tokens": [50676, 636, 281, 1322, 257, 18161, 3209, 11, 2232, 11, 281, 652, 309, 382, 7148, 382, 264, 3567, 307, 281, 50990], "temperature": 0.0, "avg_logprob": -0.14604840036165917, "compression_ratio": 1.702127659574468, "no_speech_prob": 0.0002959097037091851}, {"id": 122, "seek": 47540, "start": 487.91999999999996, "end": 490.08, "text": " build it physically, just as the brain does.", "tokens": [50990, 1322, 309, 9762, 11, 445, 382, 264, 3567, 775, 13, 51098], "temperature": 0.0, "avg_logprob": -0.14604840036165917, "compression_ratio": 1.702127659574468, "no_speech_prob": 0.0002959097037091851}, {"id": 123, "seek": 47540, "start": 492.2, "end": 494.47999999999996, "text": " Are you trying to build an artificial brain?", "tokens": [51204, 2014, 291, 1382, 281, 1322, 364, 11677, 3567, 30, 51318], "temperature": 0.0, "avg_logprob": -0.14604840036165917, "compression_ratio": 1.702127659574468, "no_speech_prob": 0.0002959097037091851}, {"id": 124, "seek": 47540, "start": 495.64, "end": 496.59999999999997, "text": " Yes, we are.", "tokens": [51376, 1079, 11, 321, 366, 13, 51424], "temperature": 0.0, "avg_logprob": -0.14604840036165917, "compression_ratio": 1.702127659574468, "no_speech_prob": 0.0002959097037091851}, {"id": 125, "seek": 47540, "start": 497.2, "end": 498.52, "text": " That is our goal.", "tokens": [51454, 663, 307, 527, 3387, 13, 51520], "temperature": 0.0, "avg_logprob": -0.14604840036165917, "compression_ratio": 1.702127659574468, "no_speech_prob": 0.0002959097037091851}, {"id": 126, "seek": 47540, "start": 498.67999999999995, "end": 502.59999999999997, "text": " You know, we have kind of two missions that are very complimentary.", "tokens": [51528, 509, 458, 11, 321, 362, 733, 295, 732, 13744, 300, 366, 588, 47162, 13, 51724], "temperature": 0.0, "avg_logprob": -0.14604840036165917, "compression_ratio": 1.702127659574468, "no_speech_prob": 0.0002959097037091851}, {"id": 127, "seek": 47540, "start": 502.64, "end": 504.64, "text": " Uh, one of them is to build a brain.", "tokens": [51726, 4019, 11, 472, 295, 552, 307, 281, 1322, 257, 3567, 13, 51826], "temperature": 0.0, "avg_logprob": -0.14604840036165917, "compression_ratio": 1.702127659574468, "no_speech_prob": 0.0002959097037091851}, {"id": 128, "seek": 50464, "start": 504.96, "end": 507.32, "text": " And the other one is to actually understand it.", "tokens": [50380, 400, 264, 661, 472, 307, 281, 767, 1223, 309, 13, 50498], "temperature": 0.0, "avg_logprob": -0.12296863113130842, "compression_ratio": 1.7489878542510122, "no_speech_prob": 0.0009695194312371314}, {"id": 129, "seek": 50464, "start": 507.68, "end": 512.8, "text": " You know, we really love the, and believe the notion that you can't fully", "tokens": [50516, 509, 458, 11, 321, 534, 959, 264, 11, 293, 1697, 264, 10710, 300, 291, 393, 380, 4498, 50772], "temperature": 0.0, "avg_logprob": -0.12296863113130842, "compression_ratio": 1.7489878542510122, "no_speech_prob": 0.0009695194312371314}, {"id": 130, "seek": 50464, "start": 512.8, "end": 516.56, "text": " understand a system until you have, have reconstructed it and built it.", "tokens": [50772, 1223, 257, 1185, 1826, 291, 362, 11, 362, 31499, 292, 309, 293, 3094, 309, 13, 50960], "temperature": 0.0, "avg_logprob": -0.12296863113130842, "compression_ratio": 1.7489878542510122, "no_speech_prob": 0.0009695194312371314}, {"id": 131, "seek": 50464, "start": 517.0, "end": 519.8, "text": " Uh, you know, this go back to Feynman and many others.", "tokens": [50982, 4019, 11, 291, 458, 11, 341, 352, 646, 281, 46530, 77, 1601, 293, 867, 2357, 13, 51122], "temperature": 0.0, "avg_logprob": -0.12296863113130842, "compression_ratio": 1.7489878542510122, "no_speech_prob": 0.0009695194312371314}, {"id": 132, "seek": 50464, "start": 520.28, "end": 524.84, "text": " Uh, but what we believe we've developed really are kind of the core technologies", "tokens": [51146, 4019, 11, 457, 437, 321, 1697, 321, 600, 4743, 534, 366, 733, 295, 264, 4965, 7943, 51374], "temperature": 0.0, "avg_logprob": -0.12296863113130842, "compression_ratio": 1.7489878542510122, "no_speech_prob": 0.0009695194312371314}, {"id": 133, "seek": 50464, "start": 524.84, "end": 529.16, "text": " that allow us to first build just kind of unit level chips that address, you", "tokens": [51374, 300, 2089, 505, 281, 700, 1322, 445, 733, 295, 4985, 1496, 11583, 300, 2985, 11, 291, 51590], "temperature": 0.0, "avg_logprob": -0.12296863113130842, "compression_ratio": 1.7489878542510122, "no_speech_prob": 0.0009695194312371314}, {"id": 134, "seek": 50464, "start": 529.16, "end": 530.4399999999999, "text": " know, near term problems.", "tokens": [51590, 458, 11, 2651, 1433, 2740, 13, 51654], "temperature": 0.0, "avg_logprob": -0.12296863113130842, "compression_ratio": 1.7489878542510122, "no_speech_prob": 0.0009695194312371314}, {"id": 135, "seek": 53044, "start": 531.0, "end": 534.7600000000001, "text": " But ultimately we see this as kind of like Lego pieces that, you know,", "tokens": [50392, 583, 6284, 321, 536, 341, 382, 733, 295, 411, 28761, 3755, 300, 11, 291, 458, 11, 50580], "temperature": 0.0, "avg_logprob": -0.21309363726273323, "compression_ratio": 1.6058394160583942, "no_speech_prob": 0.00970692653208971}, {"id": 136, "seek": 53044, "start": 534.84, "end": 538.48, "text": " due to their low power footprints, we'll be able to concatenate them", "tokens": [50584, 3462, 281, 641, 2295, 1347, 45715, 11, 321, 603, 312, 1075, 281, 1588, 7186, 473, 552, 50766], "temperature": 0.0, "avg_logprob": -0.21309363726273323, "compression_ratio": 1.6058394160583942, "no_speech_prob": 0.00970692653208971}, {"id": 137, "seek": 53044, "start": 538.48, "end": 542.9200000000001, "text": " together using things like chiplet integration, advanced packaging, and", "tokens": [50766, 1214, 1228, 721, 411, 11409, 2631, 10980, 11, 7339, 16836, 11, 293, 50988], "temperature": 0.0, "avg_logprob": -0.21309363726273323, "compression_ratio": 1.6058394160583942, "no_speech_prob": 0.00970692653208971}, {"id": 138, "seek": 53044, "start": 542.9200000000001, "end": 548.84, "text": " ultimately scale out these systems to be brain scale, 86 billion neurons, 500", "tokens": [50988, 6284, 4373, 484, 613, 3652, 281, 312, 3567, 4373, 11, 26687, 5218, 22027, 11, 5923, 51284], "temperature": 0.0, "avg_logprob": -0.21309363726273323, "compression_ratio": 1.6058394160583942, "no_speech_prob": 0.00970692653208971}, {"id": 139, "seek": 53044, "start": 548.84, "end": 554.44, "text": " trillion synapses, and low power enough that they can exist in autonomous devices.", "tokens": [51284, 18723, 5451, 2382, 279, 11, 293, 2295, 1347, 1547, 300, 436, 393, 2514, 294, 23797, 5759, 13, 51564], "temperature": 0.0, "avg_logprob": -0.21309363726273323, "compression_ratio": 1.6058394160583942, "no_speech_prob": 0.00970692653208971}, {"id": 140, "seek": 53044, "start": 555.0, "end": 559.72, "text": " Because today, trading is so expensive that first week, we consider", "tokens": [51592, 1436, 965, 11, 9529, 307, 370, 5124, 300, 700, 1243, 11, 321, 1949, 51828], "temperature": 0.0, "avg_logprob": -0.21309363726273323, "compression_ratio": 1.6058394160583942, "no_speech_prob": 0.00970692653208971}, {"id": 141, "seek": 55972, "start": 559.72, "end": 561.84, "text": " trading inferences, the separate problems.", "tokens": [50364, 9529, 13596, 2667, 11, 264, 4994, 2740, 13, 50470], "temperature": 0.0, "avg_logprob": -0.17469065657285887, "compression_ratio": 1.6840148698884758, "no_speech_prob": 0.0015973360277712345}, {"id": 142, "seek": 55972, "start": 561.84, "end": 564.64, "text": " And I don't think they really should be considered as these separate", "tokens": [50470, 400, 286, 500, 380, 519, 436, 534, 820, 312, 4888, 382, 613, 4994, 50610], "temperature": 0.0, "avg_logprob": -0.17469065657285887, "compression_ratio": 1.6840148698884758, "no_speech_prob": 0.0015973360277712345}, {"id": 143, "seek": 55972, "start": 564.64, "end": 569.36, "text": " and distinct problems, but it's so expensive that we can't even conceive", "tokens": [50610, 293, 10644, 2740, 11, 457, 309, 311, 370, 5124, 300, 321, 393, 380, 754, 48605, 50846], "temperature": 0.0, "avg_logprob": -0.17469065657285887, "compression_ratio": 1.6840148698884758, "no_speech_prob": 0.0015973360277712345}, {"id": 144, "seek": 55972, "start": 569.44, "end": 572.84, "text": " of putting training of natural language in an autonomous machine.", "tokens": [50850, 295, 3372, 3097, 295, 3303, 2856, 294, 364, 23797, 3479, 13, 51020], "temperature": 0.0, "avg_logprob": -0.17469065657285887, "compression_ratio": 1.6840148698884758, "no_speech_prob": 0.0015973360277712345}, {"id": 145, "seek": 55972, "start": 573.44, "end": 575.5600000000001, "text": " And yet humans do it all the time.", "tokens": [51050, 400, 1939, 6255, 360, 309, 439, 264, 565, 13, 51156], "temperature": 0.0, "avg_logprob": -0.17469065657285887, "compression_ratio": 1.6840148698884758, "no_speech_prob": 0.0015973360277712345}, {"id": 146, "seek": 55972, "start": 576.0, "end": 580.1600000000001, "text": " So that is what we are trying to achieve to, to recapitulate the brain in", "tokens": [51178, 407, 300, 307, 437, 321, 366, 1382, 281, 4584, 281, 11, 281, 20928, 270, 5256, 264, 3567, 294, 51386], "temperature": 0.0, "avg_logprob": -0.17469065657285887, "compression_ratio": 1.6840148698884758, "no_speech_prob": 0.0015973360277712345}, {"id": 147, "seek": 55972, "start": 580.1600000000001, "end": 584.8000000000001, "text": " hardware and ultimately give machines all of the capabilities that we", "tokens": [51386, 8837, 293, 6284, 976, 8379, 439, 295, 264, 10862, 300, 321, 51618], "temperature": 0.0, "avg_logprob": -0.17469065657285887, "compression_ratio": 1.6840148698884758, "no_speech_prob": 0.0015973360277712345}, {"id": 148, "seek": 55972, "start": 584.84, "end": 585.96, "text": " recognize in ourselves.", "tokens": [51620, 5521, 294, 4175, 13, 51676], "temperature": 0.0, "avg_logprob": -0.17469065657285887, "compression_ratio": 1.6840148698884758, "no_speech_prob": 0.0015973360277712345}, {"id": 149, "seek": 58596, "start": 586.6, "end": 592.12, "text": " So Gordon, you're a pretty soft spoken guy and you sound like a very thoughtful", "tokens": [50396, 407, 19369, 11, 291, 434, 257, 1238, 2787, 10759, 2146, 293, 291, 1626, 411, 257, 588, 21566, 50672], "temperature": 0.0, "avg_logprob": -0.3191653956537661, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.0015974369598552585}, {"id": 150, "seek": 58596, "start": 592.12, "end": 600.36, "text": " guy. And in that very soft spoken way, you're saying absolutely ginormous things.", "tokens": [50672, 2146, 13, 400, 294, 300, 588, 2787, 10759, 636, 11, 291, 434, 1566, 3122, 36604, 687, 563, 721, 13, 51084], "temperature": 0.0, "avg_logprob": -0.3191653956537661, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.0015974369598552585}, {"id": 151, "seek": 58596, "start": 601.64, "end": 604.1600000000001, "text": " We're talking Frankenstein level stuff, right?", "tokens": [51148, 492, 434, 1417, 39678, 9089, 1496, 1507, 11, 558, 30, 51274], "temperature": 0.0, "avg_logprob": -0.3191653956537661, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.0015974369598552585}, {"id": 152, "seek": 58596, "start": 604.1600000000001, "end": 607.8000000000001, "text": " I mean, you understand the gravity of what you're talking about, right?", "tokens": [51274, 286, 914, 11, 291, 1223, 264, 12110, 295, 437, 291, 434, 1417, 466, 11, 558, 30, 51456], "temperature": 0.0, "avg_logprob": -0.3191653956537661, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.0015974369598552585}, {"id": 153, "seek": 58596, "start": 608.52, "end": 609.32, "text": " Absolutely.", "tokens": [51492, 7021, 13, 51532], "temperature": 0.0, "avg_logprob": -0.3191653956537661, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.0015974369598552585}, {"id": 154, "seek": 58596, "start": 609.32, "end": 614.72, "text": " No, this is the scope and impact of our work is not.", "tokens": [51532, 883, 11, 341, 307, 264, 11923, 293, 2712, 295, 527, 589, 307, 406, 13, 51802], "temperature": 0.0, "avg_logprob": -0.3191653956537661, "compression_ratio": 1.5898617511520738, "no_speech_prob": 0.0015974369598552585}, {"id": 155, "seek": 61472, "start": 614.84, "end": 618.28, "text": " I mean, this is something we've been working on for nearly five years and we", "tokens": [50370, 286, 914, 11, 341, 307, 746, 321, 600, 668, 1364, 322, 337, 6217, 1732, 924, 293, 321, 50542], "temperature": 0.0, "avg_logprob": -0.3456102337753564, "compression_ratio": 1.7404580152671756, "no_speech_prob": 0.010800465010106564}, {"id": 156, "seek": 61472, "start": 618.28, "end": 622.0400000000001, "text": " recognize that if we are successful in achieving this, this, this will be", "tokens": [50542, 5521, 300, 498, 321, 366, 4406, 294, 19626, 341, 11, 341, 11, 341, 486, 312, 50730], "temperature": 0.0, "avg_logprob": -0.3456102337753564, "compression_ratio": 1.7404580152671756, "no_speech_prob": 0.010800465010106564}, {"id": 157, "seek": 61472, "start": 622.0400000000001, "end": 624.48, "text": " historic and, and massively consequential.", "tokens": [50730, 13236, 293, 11, 293, 29379, 7242, 2549, 13, 50852], "temperature": 0.0, "avg_logprob": -0.3456102337753564, "compression_ratio": 1.7404580152671756, "no_speech_prob": 0.010800465010106564}, {"id": 158, "seek": 61472, "start": 625.0400000000001, "end": 629.9200000000001, "text": " But, you know, what motivates us, you know, is of course the, the impact on", "tokens": [50880, 583, 11, 291, 458, 11, 437, 42569, 505, 11, 291, 458, 11, 307, 295, 1164, 264, 11, 264, 2712, 322, 51124], "temperature": 0.0, "avg_logprob": -0.3456102337753564, "compression_ratio": 1.7404580152671756, "no_speech_prob": 0.010800465010106564}, {"id": 159, "seek": 61472, "start": 629.9200000000001, "end": 635.9200000000001, "text": " positively improving human life, you know, and we can have personalized medicine,", "tokens": [51124, 25795, 11470, 1952, 993, 11, 291, 458, 11, 293, 321, 393, 362, 28415, 7195, 11, 51424], "temperature": 0.0, "avg_logprob": -0.3456102337753564, "compression_ratio": 1.7404580152671756, "no_speech_prob": 0.010800465010106564}, {"id": 160, "seek": 61472, "start": 635.9200000000001, "end": 638.8000000000001, "text": " personalized education, we can automate all of labor.", "tokens": [51424, 28415, 3309, 11, 321, 393, 31605, 439, 295, 5938, 13, 51568], "temperature": 0.0, "avg_logprob": -0.3456102337753564, "compression_ratio": 1.7404580152671756, "no_speech_prob": 0.010800465010106564}, {"id": 161, "seek": 61472, "start": 639.48, "end": 642.08, "text": " I mean, this is the world that we want to realize.", "tokens": [51602, 286, 914, 11, 341, 307, 264, 1002, 300, 321, 528, 281, 4325, 13, 51732], "temperature": 0.0, "avg_logprob": -0.3456102337753564, "compression_ratio": 1.7404580152671756, "no_speech_prob": 0.010800465010106564}, {"id": 162, "seek": 64208, "start": 642.12, "end": 645.0, "text": " I think many people are already in this consensus that artificial", "tokens": [50366, 286, 519, 867, 561, 366, 1217, 294, 341, 19115, 300, 11677, 50510], "temperature": 0.0, "avg_logprob": -0.30408344846783264, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.002979685552418232}, {"id": 163, "seek": 64208, "start": 645.0, "end": 649.32, "text": " intelligence is going to be kind of the defining technology of the century.", "tokens": [50510, 7599, 307, 516, 281, 312, 733, 295, 264, 17827, 2899, 295, 264, 4901, 13, 50726], "temperature": 0.0, "avg_logprob": -0.30408344846783264, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.002979685552418232}, {"id": 164, "seek": 64208, "start": 649.64, "end": 653.64, "text": " But most people don't, don't know that the hardware that supports it is,", "tokens": [50742, 583, 881, 561, 500, 380, 11, 500, 380, 458, 300, 264, 8837, 300, 9346, 309, 307, 11, 50942], "temperature": 0.0, "avg_logprob": -0.30408344846783264, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.002979685552418232}, {"id": 165, "seek": 64208, "start": 653.64, "end": 654.9200000000001, "text": " is the bottleneck right now.", "tokens": [50942, 307, 264, 44641, 547, 558, 586, 13, 51006], "temperature": 0.0, "avg_logprob": -0.30408344846783264, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.002979685552418232}, {"id": 166, "seek": 64208, "start": 655.64, "end": 660.2800000000001, "text": " So, so yes, we recognize the scope of this and, you know, it's, it's a big", "tokens": [51042, 407, 11, 370, 2086, 11, 321, 5521, 264, 11923, 295, 341, 293, 11, 291, 458, 11, 309, 311, 11, 309, 311, 257, 955, 51274], "temperature": 0.0, "avg_logprob": -0.30408344846783264, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.002979685552418232}, {"id": 167, "seek": 64208, "start": 660.32, "end": 661.72, "text": " mission and a big task.", "tokens": [51276, 4447, 293, 257, 955, 5633, 13, 51346], "temperature": 0.0, "avg_logprob": -0.30408344846783264, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.002979685552418232}, {"id": 168, "seek": 64208, "start": 661.76, "end": 665.84, "text": " But, you know, I think that we're, we're approaching it the right way.", "tokens": [51348, 583, 11, 291, 458, 11, 286, 519, 300, 321, 434, 11, 321, 434, 14908, 309, 264, 558, 636, 13, 51552], "temperature": 0.0, "avg_logprob": -0.30408344846783264, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.002979685552418232}, {"id": 169, "seek": 64208, "start": 665.84, "end": 670.4000000000001, "text": " And we're also very conscientious of the fact that we're, you know,", "tokens": [51552, 400, 321, 434, 611, 588, 44507, 851, 295, 264, 1186, 300, 321, 434, 11, 291, 458, 11, 51780], "temperature": 0.0, "avg_logprob": -0.30408344846783264, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.002979685552418232}, {"id": 170, "seek": 67040, "start": 670.4, "end": 676.3199999999999, "text": " conscientious of the fact that we don't want, that there, there are good ways", "tokens": [50364, 44507, 851, 295, 264, 1186, 300, 321, 500, 380, 528, 11, 300, 456, 11, 456, 366, 665, 2098, 50660], "temperature": 0.0, "avg_logprob": -0.240875244140625, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.033559564501047134}, {"id": 171, "seek": 67040, "start": 676.3199999999999, "end": 678.4399999999999, "text": " of implementing AI and there are also not good ways.", "tokens": [50660, 295, 18114, 7318, 293, 456, 366, 611, 406, 665, 2098, 13, 50766], "temperature": 0.0, "avg_logprob": -0.240875244140625, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.033559564501047134}, {"id": 172, "seek": 67040, "start": 679.24, "end": 683.0, "text": " And we don't think AI should be used everywhere for every purpose, but there", "tokens": [50806, 400, 321, 500, 380, 519, 7318, 820, 312, 1143, 5315, 337, 633, 4334, 11, 457, 456, 50994], "temperature": 0.0, "avg_logprob": -0.240875244140625, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.033559564501047134}, {"id": 173, "seek": 67040, "start": 683.0, "end": 689.3199999999999, "text": " are guidelines and ethics that should really direct how we build and implement", "tokens": [50994, 366, 12470, 293, 19769, 300, 820, 534, 2047, 577, 321, 1322, 293, 4445, 51310], "temperature": 0.0, "avg_logprob": -0.240875244140625, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.033559564501047134}, {"id": 174, "seek": 67040, "start": 689.48, "end": 690.0799999999999, "text": " these systems.", "tokens": [51318, 613, 3652, 13, 51348], "temperature": 0.0, "avg_logprob": -0.240875244140625, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.033559564501047134}, {"id": 175, "seek": 67040, "start": 691.16, "end": 692.28, "text": " And it's controversial.", "tokens": [51402, 400, 309, 311, 17323, 13, 51458], "temperature": 0.0, "avg_logprob": -0.240875244140625, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.033559564501047134}, {"id": 176, "seek": 67040, "start": 692.28, "end": 695.24, "text": " It's also political in the AI space, right?", "tokens": [51458, 467, 311, 611, 3905, 294, 264, 7318, 1901, 11, 558, 30, 51606], "temperature": 0.0, "avg_logprob": -0.240875244140625, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.033559564501047134}, {"id": 177, "seek": 67040, "start": 695.24, "end": 699.3199999999999, "text": " In terms of what you're building, what you're looking at, people who claim", "tokens": [51606, 682, 2115, 295, 437, 291, 434, 2390, 11, 437, 291, 434, 1237, 412, 11, 561, 567, 3932, 51810], "temperature": 0.0, "avg_logprob": -0.240875244140625, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.033559564501047134}, {"id": 178, "seek": 69932, "start": 699.44, "end": 704.1600000000001, "text": " to be working on general AI, for instance, you know, there's a lot of", "tokens": [50370, 281, 312, 1364, 322, 2674, 7318, 11, 337, 5197, 11, 291, 458, 11, 456, 311, 257, 688, 295, 50606], "temperature": 0.0, "avg_logprob": -0.17375793777594045, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.011681593954563141}, {"id": 179, "seek": 69932, "start": 704.1600000000001, "end": 708.12, "text": " scrutiny there, there was a, I believe a Google engineer who last week said,", "tokens": [50606, 38615, 456, 11, 456, 390, 257, 11, 286, 1697, 257, 3329, 11403, 567, 1036, 1243, 848, 11, 50804], "temperature": 0.0, "avg_logprob": -0.17375793777594045, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.011681593954563141}, {"id": 180, "seek": 69932, "start": 708.12, "end": 711.5600000000001, "text": " I think that some of our systems are, are approaching consciousness.", "tokens": [50804, 286, 519, 300, 512, 295, 527, 3652, 366, 11, 366, 14908, 10081, 13, 50976], "temperature": 0.0, "avg_logprob": -0.17375793777594045, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.011681593954563141}, {"id": 181, "seek": 69932, "start": 711.96, "end": 717.6, "text": " And, and there were a ton of people jumping all over him, probably correctly.", "tokens": [50996, 400, 11, 293, 456, 645, 257, 2952, 295, 561, 11233, 439, 670, 796, 11, 1391, 8944, 13, 51278], "temperature": 0.0, "avg_logprob": -0.17375793777594045, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.011681593954563141}, {"id": 182, "seek": 69932, "start": 717.84, "end": 723.5200000000001, "text": " But, you know, perhaps in a bit of a mob mentality for daring to suggest", "tokens": [51290, 583, 11, 291, 458, 11, 4317, 294, 257, 857, 295, 257, 4298, 21976, 337, 43128, 281, 3402, 51574], "temperature": 0.0, "avg_logprob": -0.17375793777594045, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.011681593954563141}, {"id": 183, "seek": 69932, "start": 723.5200000000001, "end": 728.48, "text": " that and, and saying, no, we're, we're so far out there, maybe let's come back", "tokens": [51574, 300, 293, 11, 293, 1566, 11, 572, 11, 321, 434, 11, 321, 434, 370, 1400, 484, 456, 11, 1310, 718, 311, 808, 646, 51822], "temperature": 0.0, "avg_logprob": -0.17375793777594045, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.011681593954563141}, {"id": 184, "seek": 72848, "start": 728.48, "end": 736.12, "text": " here, because you and your co-founder have studied the human brain significantly.", "tokens": [50364, 510, 11, 570, 291, 293, 428, 598, 12, 33348, 362, 9454, 264, 1952, 3567, 10591, 13, 50746], "temperature": 0.0, "avg_logprob": -0.14850392061121323, "compression_ratio": 1.5211267605633803, "no_speech_prob": 0.0032711352687329054}, {"id": 185, "seek": 72848, "start": 736.64, "end": 740.12, "text": " What do we learn about AI from the way that our brains work?", "tokens": [50772, 708, 360, 321, 1466, 466, 7318, 490, 264, 636, 300, 527, 15442, 589, 30, 50946], "temperature": 0.0, "avg_logprob": -0.14850392061121323, "compression_ratio": 1.5211267605633803, "no_speech_prob": 0.0032711352687329054}, {"id": 186, "seek": 72848, "start": 741.2, "end": 741.5600000000001, "text": " Absolutely.", "tokens": [51000, 7021, 13, 51018], "temperature": 0.0, "avg_logprob": -0.14850392061121323, "compression_ratio": 1.5211267605633803, "no_speech_prob": 0.0032711352687329054}, {"id": 187, "seek": 72848, "start": 741.5600000000001, "end": 742.96, "text": " That's a great question, John.", "tokens": [51018, 663, 311, 257, 869, 1168, 11, 2619, 13, 51088], "temperature": 0.0, "avg_logprob": -0.14850392061121323, "compression_ratio": 1.5211267605633803, "no_speech_prob": 0.0032711352687329054}, {"id": 188, "seek": 72848, "start": 743.32, "end": 749.8000000000001, "text": " And I'd say that there are really kind of two categories of clues that we look", "tokens": [51106, 400, 286, 1116, 584, 300, 456, 366, 534, 733, 295, 732, 10479, 295, 20936, 300, 321, 574, 51430], "temperature": 0.0, "avg_logprob": -0.14850392061121323, "compression_ratio": 1.5211267605633803, "no_speech_prob": 0.0032711352687329054}, {"id": 189, "seek": 72848, "start": 749.8000000000001, "end": 753.48, "text": " at, you know, from the brain that then inform our hardware.", "tokens": [51430, 412, 11, 291, 458, 11, 490, 264, 3567, 300, 550, 1356, 527, 8837, 13, 51614], "temperature": 0.0, "avg_logprob": -0.14850392061121323, "compression_ratio": 1.5211267605633803, "no_speech_prob": 0.0032711352687329054}, {"id": 190, "seek": 75348, "start": 754.48, "end": 758.9200000000001, "text": " The first is, how does the brain learn so efficiently?", "tokens": [50414, 440, 700, 307, 11, 577, 775, 264, 3567, 1466, 370, 19621, 30, 50636], "temperature": 0.0, "avg_logprob": -0.16940989096959433, "compression_ratio": 1.7935779816513762, "no_speech_prob": 0.0029800909105688334}, {"id": 191, "seek": 75348, "start": 759.2, "end": 764.52, "text": " You know, it, the brain trains and learns with both very few examples.", "tokens": [50650, 509, 458, 11, 309, 11, 264, 3567, 16329, 293, 27152, 365, 1293, 588, 1326, 5110, 13, 50916], "temperature": 0.0, "avg_logprob": -0.16940989096959433, "compression_ratio": 1.7935779816513762, "no_speech_prob": 0.0029800909105688334}, {"id": 192, "seek": 75348, "start": 765.52, "end": 768.84, "text": " We, we learn with, with one example or two examples, one shot learning, two", "tokens": [50966, 492, 11, 321, 1466, 365, 11, 365, 472, 1365, 420, 732, 5110, 11, 472, 3347, 2539, 11, 732, 51132], "temperature": 0.0, "avg_logprob": -0.16940989096959433, "compression_ratio": 1.7935779816513762, "no_speech_prob": 0.0029800909105688334}, {"id": 193, "seek": 75348, "start": 768.84, "end": 771.5600000000001, "text": " shot learning, and we can generalize extraordinarily well.", "tokens": [51132, 3347, 2539, 11, 293, 321, 393, 2674, 1125, 34557, 731, 13, 51268], "temperature": 0.0, "avg_logprob": -0.16940989096959433, "compression_ratio": 1.7935779816513762, "no_speech_prob": 0.0029800909105688334}, {"id": 194, "seek": 75348, "start": 772.28, "end": 775.5600000000001, "text": " So learning training happens very, very efficiently.", "tokens": [51304, 407, 2539, 3097, 2314, 588, 11, 588, 19621, 13, 51468], "temperature": 0.0, "avg_logprob": -0.16940989096959433, "compression_ratio": 1.7935779816513762, "no_speech_prob": 0.0029800909105688334}, {"id": 195, "seek": 75348, "start": 776.0, "end": 781.0, "text": " And there are the learning rule of the brain, the algorithm the brain uses is", "tokens": [51490, 400, 456, 366, 264, 2539, 4978, 295, 264, 3567, 11, 264, 9284, 264, 3567, 4960, 307, 51740], "temperature": 0.0, "avg_logprob": -0.16940989096959433, "compression_ratio": 1.7935779816513762, "no_speech_prob": 0.0029800909105688334}, {"id": 196, "seek": 78100, "start": 781.0, "end": 786.56, "text": " not fully understood or identified, but we do know that there are certain", "tokens": [50364, 406, 4498, 7320, 420, 9234, 11, 457, 321, 360, 458, 300, 456, 366, 1629, 50642], "temperature": 0.0, "avg_logprob": -0.12560925339207504, "compression_ratio": 1.6638655462184875, "no_speech_prob": 0.002396145137026906}, {"id": 197, "seek": 78100, "start": 786.6, "end": 789.48, "text": " requirements that, that algorithm must have.", "tokens": [50644, 7728, 300, 11, 300, 9284, 1633, 362, 13, 50788], "temperature": 0.0, "avg_logprob": -0.12560925339207504, "compression_ratio": 1.6638655462184875, "no_speech_prob": 0.002396145137026906}, {"id": 198, "seek": 78100, "start": 790.32, "end": 794.44, "text": " So one of those is called a local learning rule.", "tokens": [50830, 407, 472, 295, 729, 307, 1219, 257, 2654, 2539, 4978, 13, 51036], "temperature": 0.0, "avg_logprob": -0.12560925339207504, "compression_ratio": 1.6638655462184875, "no_speech_prob": 0.002396145137026906}, {"id": 199, "seek": 78100, "start": 795.0, "end": 799.12, "text": " So this, if you're, for the listeners who are familiar with back propagation,", "tokens": [51064, 407, 341, 11, 498, 291, 434, 11, 337, 264, 23274, 567, 366, 4963, 365, 646, 38377, 11, 51270], "temperature": 0.0, "avg_logprob": -0.12560925339207504, "compression_ratio": 1.6638655462184875, "no_speech_prob": 0.002396145137026906}, {"id": 200, "seek": 78100, "start": 799.12, "end": 803.8, "text": " which is the industry standard algorithm for digital AI, this says what's", "tokens": [51270, 597, 307, 264, 3518, 3832, 9284, 337, 4562, 7318, 11, 341, 1619, 437, 311, 51504], "temperature": 0.0, "avg_logprob": -0.12560925339207504, "compression_ratio": 1.6638655462184875, "no_speech_prob": 0.002396145137026906}, {"id": 201, "seek": 78100, "start": 803.8, "end": 805.16, "text": " called a global learning.", "tokens": [51504, 1219, 257, 4338, 2539, 13, 51572], "temperature": 0.0, "avg_logprob": -0.12560925339207504, "compression_ratio": 1.6638655462184875, "no_speech_prob": 0.002396145137026906}, {"id": 202, "seek": 78100, "start": 805.84, "end": 807.64, "text": " So first let's say, well, what is a learning rule?", "tokens": [51606, 407, 700, 718, 311, 584, 11, 731, 11, 437, 307, 257, 2539, 4978, 30, 51696], "temperature": 0.0, "avg_logprob": -0.12560925339207504, "compression_ratio": 1.6638655462184875, "no_speech_prob": 0.002396145137026906}, {"id": 203, "seek": 80764, "start": 807.96, "end": 813.28, "text": " A learning rule is how any given synapse in a neural network knows, should", "tokens": [50380, 316, 2539, 4978, 307, 577, 604, 2212, 5451, 11145, 294, 257, 18161, 3209, 3255, 11, 820, 50646], "temperature": 0.0, "avg_logprob": -0.10732789625201308, "compression_ratio": 1.7661870503597121, "no_speech_prob": 0.008844109252095222}, {"id": 204, "seek": 80764, "start": 813.28, "end": 818.3199999999999, "text": " it become stronger or weaker for the whole system to become smarter, better", "tokens": [50646, 309, 1813, 7249, 420, 24286, 337, 264, 1379, 1185, 281, 1813, 20294, 11, 1101, 50898], "temperature": 0.0, "avg_logprob": -0.10732789625201308, "compression_ratio": 1.7661870503597121, "no_speech_prob": 0.008844109252095222}, {"id": 205, "seek": 80764, "start": 818.3199999999999, "end": 819.72, "text": " at its assigned task.", "tokens": [50898, 412, 1080, 13279, 5633, 13, 50968], "temperature": 0.0, "avg_logprob": -0.10732789625201308, "compression_ratio": 1.7661870503597121, "no_speech_prob": 0.008844109252095222}, {"id": 206, "seek": 80764, "start": 820.28, "end": 824.12, "text": " And in back propagation of the digital world, for you to calculate whether", "tokens": [50996, 400, 294, 646, 38377, 295, 264, 4562, 1002, 11, 337, 291, 281, 8873, 1968, 51188], "temperature": 0.0, "avg_logprob": -0.10732789625201308, "compression_ratio": 1.7661870503597121, "no_speech_prob": 0.008844109252095222}, {"id": 207, "seek": 80764, "start": 824.12, "end": 827.6, "text": " this one synapse should be stronger or weaker, you need to do a math equation", "tokens": [51188, 341, 472, 5451, 11145, 820, 312, 7249, 420, 24286, 11, 291, 643, 281, 360, 257, 5221, 5367, 51362], "temperature": 0.0, "avg_logprob": -0.10732789625201308, "compression_ratio": 1.7661870503597121, "no_speech_prob": 0.008844109252095222}, {"id": 208, "seek": 80764, "start": 827.6, "end": 829.64, "text": " that incorporates the entire network.", "tokens": [51362, 300, 50193, 264, 2302, 3209, 13, 51464], "temperature": 0.0, "avg_logprob": -0.10732789625201308, "compression_ratio": 1.7661870503597121, "no_speech_prob": 0.008844109252095222}, {"id": 209, "seek": 80764, "start": 829.96, "end": 832.28, "text": " You need to differentiate against the entire system.", "tokens": [51480, 509, 643, 281, 23203, 1970, 264, 2302, 1185, 13, 51596], "temperature": 0.0, "avg_logprob": -0.10732789625201308, "compression_ratio": 1.7661870503597121, "no_speech_prob": 0.008844109252095222}, {"id": 210, "seek": 80764, "start": 832.8, "end": 837.4399999999999, "text": " That's really mathematically expensive, but not only is it expensive, it's", "tokens": [51622, 663, 311, 534, 44003, 5124, 11, 457, 406, 787, 307, 309, 5124, 11, 309, 311, 51854], "temperature": 0.0, "avg_logprob": -0.10732789625201308, "compression_ratio": 1.7661870503597121, "no_speech_prob": 0.008844109252095222}, {"id": 211, "seek": 83744, "start": 837.44, "end": 840.9200000000001, "text": " also impossible for the brain to be doing the same thing.", "tokens": [50364, 611, 6243, 337, 264, 3567, 281, 312, 884, 264, 912, 551, 13, 50538], "temperature": 0.0, "avg_logprob": -0.12985900470188685, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.0003459378785919398}, {"id": 212, "seek": 83744, "start": 841.2, "end": 845.12, "text": " There's no like agent sitting in our brain observing the whole system and", "tokens": [50552, 821, 311, 572, 411, 9461, 3798, 294, 527, 3567, 22107, 264, 1379, 1185, 293, 50748], "temperature": 0.0, "avg_logprob": -0.12985900470188685, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.0003459378785919398}, {"id": 213, "seek": 83744, "start": 845.12, "end": 847.6800000000001, "text": " then doing a math problem to update every synapse.", "tokens": [50748, 550, 884, 257, 5221, 1154, 281, 5623, 633, 5451, 11145, 13, 50876], "temperature": 0.0, "avg_logprob": -0.12985900470188685, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.0003459378785919398}, {"id": 214, "seek": 83744, "start": 847.6800000000001, "end": 848.6400000000001, "text": " It's, it's impossible.", "tokens": [50876, 467, 311, 11, 309, 311, 6243, 13, 50924], "temperature": 0.0, "avg_logprob": -0.12985900470188685, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.0003459378785919398}, {"id": 215, "seek": 83744, "start": 848.96, "end": 852.4000000000001, "text": " The brain has to be operating with a local learning rule.", "tokens": [50940, 440, 3567, 575, 281, 312, 7447, 365, 257, 2654, 2539, 4978, 13, 51112], "temperature": 0.0, "avg_logprob": -0.12985900470188685, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.0003459378785919398}, {"id": 216, "seek": 83744, "start": 853.24, "end": 857.6, "text": " And so a local learning rule is so that that synapse can just observe what's", "tokens": [51154, 400, 370, 257, 2654, 2539, 4978, 307, 370, 300, 300, 5451, 11145, 393, 445, 11441, 437, 311, 51372], "temperature": 0.0, "avg_logprob": -0.12985900470188685, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.0003459378785919398}, {"id": 217, "seek": 83744, "start": 857.6, "end": 860.24, "text": " right nearby and still know I become stronger.", "tokens": [51372, 558, 11184, 293, 920, 458, 286, 1813, 7249, 13, 51504], "temperature": 0.0, "avg_logprob": -0.12985900470188685, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.0003459378785919398}, {"id": 218, "seek": 83744, "start": 861.2800000000001, "end": 863.84, "text": " So that's one of the clues in the algorithm side.", "tokens": [51556, 407, 300, 311, 472, 295, 264, 20936, 294, 264, 9284, 1252, 13, 51684], "temperature": 0.0, "avg_logprob": -0.12985900470188685, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.0003459378785919398}, {"id": 219, "seek": 86384, "start": 863.84, "end": 868.2, "text": " And that's one of the pieces that makes our learning algorithm so special,", "tokens": [50364, 400, 300, 311, 472, 295, 264, 3755, 300, 1669, 527, 2539, 9284, 370, 2121, 11, 50582], "temperature": 0.0, "avg_logprob": -0.17339537048339843, "compression_ratio": 1.6958174904942966, "no_speech_prob": 0.0004172777698840946}, {"id": 220, "seek": 86384, "start": 868.2, "end": 873.9200000000001, "text": " that it is as smart as back propagation, but it does so with a local learning rule.", "tokens": [50582, 300, 309, 307, 382, 4069, 382, 646, 38377, 11, 457, 309, 775, 370, 365, 257, 2654, 2539, 4978, 13, 50868], "temperature": 0.0, "avg_logprob": -0.17339537048339843, "compression_ratio": 1.6958174904942966, "no_speech_prob": 0.0004172777698840946}, {"id": 221, "seek": 86384, "start": 875.32, "end": 876.5600000000001, "text": " Well, you burst my bubble there.", "tokens": [50938, 1042, 11, 291, 12712, 452, 12212, 456, 13, 51000], "temperature": 0.0, "avg_logprob": -0.17339537048339843, "compression_ratio": 1.6958174904942966, "no_speech_prob": 0.0004172777698840946}, {"id": 222, "seek": 86384, "start": 876.5600000000001, "end": 879.32, "text": " And there's no homunculus, I believe you pronounce it.", "tokens": [51000, 400, 456, 311, 572, 3655, 409, 36002, 11, 286, 1697, 291, 19567, 309, 13, 51138], "temperature": 0.0, "avg_logprob": -0.17339537048339843, "compression_ratio": 1.6958174904942966, "no_speech_prob": 0.0004172777698840946}, {"id": 223, "seek": 86384, "start": 879.32, "end": 882.88, "text": " I mean, there's no little guy in a little control room in my brain.", "tokens": [51138, 286, 914, 11, 456, 311, 572, 707, 2146, 294, 257, 707, 1969, 1808, 294, 452, 3567, 13, 51316], "temperature": 0.0, "avg_logprob": -0.17339537048339843, "compression_ratio": 1.6958174904942966, "no_speech_prob": 0.0004172777698840946}, {"id": 224, "seek": 86384, "start": 884.64, "end": 885.4, "text": " Unfortunate.", "tokens": [51404, 8170, 17063, 13, 51442], "temperature": 0.0, "avg_logprob": -0.17339537048339843, "compression_ratio": 1.6958174904942966, "no_speech_prob": 0.0004172777698840946}, {"id": 225, "seek": 86384, "start": 886.44, "end": 886.8000000000001, "text": " Yeah.", "tokens": [51494, 865, 13, 51512], "temperature": 0.0, "avg_logprob": -0.17339537048339843, "compression_ratio": 1.6958174904942966, "no_speech_prob": 0.0004172777698840946}, {"id": 226, "seek": 86384, "start": 886.96, "end": 889.08, "text": " And, and there's another side of the clue.", "tokens": [51520, 400, 11, 293, 456, 311, 1071, 1252, 295, 264, 13602, 13, 51626], "temperature": 0.0, "avg_logprob": -0.17339537048339843, "compression_ratio": 1.6958174904942966, "no_speech_prob": 0.0004172777698840946}, {"id": 227, "seek": 86384, "start": 889.08, "end": 892.8000000000001, "text": " So I'd say the first is on like how it learns the learning algorithm.", "tokens": [51626, 407, 286, 1116, 584, 264, 700, 307, 322, 411, 577, 309, 27152, 264, 2539, 9284, 13, 51812], "temperature": 0.0, "avg_logprob": -0.17339537048339843, "compression_ratio": 1.6958174904942966, "no_speech_prob": 0.0004172777698840946}, {"id": 228, "seek": 89280, "start": 892.88, "end": 894.92, "text": " The other is about scale.", "tokens": [50368, 440, 661, 307, 466, 4373, 13, 50470], "temperature": 0.0, "avg_logprob": -0.13366365854719045, "compression_ratio": 1.6398467432950192, "no_speech_prob": 0.0006069288356229663}, {"id": 229, "seek": 89280, "start": 895.0799999999999, "end": 898.16, "text": " How does the brain achieve its massive scale?", "tokens": [50478, 1012, 775, 264, 3567, 4584, 1080, 5994, 4373, 30, 50632], "temperature": 0.0, "avg_logprob": -0.13366365854719045, "compression_ratio": 1.6398467432950192, "no_speech_prob": 0.0006069288356229663}, {"id": 230, "seek": 89280, "start": 898.1999999999999, "end": 902.28, "text": " 86 million neurons, 500 trillion synapses, and still process and move", "tokens": [50634, 26687, 2459, 22027, 11, 5923, 18723, 5451, 2382, 279, 11, 293, 920, 1399, 293, 1286, 50838], "temperature": 0.0, "avg_logprob": -0.13366365854719045, "compression_ratio": 1.6398467432950192, "no_speech_prob": 0.0006069288356229663}, {"id": 231, "seek": 89280, "start": 902.28, "end": 904.4399999999999, "text": " information so quickly, so efficiently.", "tokens": [50838, 1589, 370, 2661, 11, 370, 19621, 13, 50946], "temperature": 0.0, "avg_logprob": -0.13366365854719045, "compression_ratio": 1.6398467432950192, "no_speech_prob": 0.0006069288356229663}, {"id": 232, "seek": 89280, "start": 905.8399999999999, "end": 910.24, "text": " So, and in that case, we take clues from like the topology of the brain.", "tokens": [51016, 407, 11, 293, 294, 300, 1389, 11, 321, 747, 20936, 490, 411, 264, 1192, 1793, 295, 264, 3567, 13, 51236], "temperature": 0.0, "avg_logprob": -0.13366365854719045, "compression_ratio": 1.6398467432950192, "no_speech_prob": 0.0006069288356229663}, {"id": 233, "seek": 89280, "start": 910.52, "end": 913.92, "text": " And in fact, and the specific thing is called sparsity.", "tokens": [51250, 400, 294, 1186, 11, 293, 264, 2685, 551, 307, 1219, 637, 685, 507, 13, 51420], "temperature": 0.0, "avg_logprob": -0.13366365854719045, "compression_ratio": 1.6398467432950192, "no_speech_prob": 0.0006069288356229663}, {"id": 234, "seek": 89280, "start": 914.4799999999999, "end": 919.64, "text": " The idea that you don't have to connect every neuron to every other neuron in", "tokens": [51448, 440, 1558, 300, 291, 500, 380, 362, 281, 1745, 633, 34090, 281, 633, 661, 34090, 294, 51706], "temperature": 0.0, "avg_logprob": -0.13366365854719045, "compression_ratio": 1.6398467432950192, "no_speech_prob": 0.0006069288356229663}, {"id": 235, "seek": 89280, "start": 919.64, "end": 921.8399999999999, "text": " the system for it to be well connected.", "tokens": [51706, 264, 1185, 337, 309, 281, 312, 731, 4582, 13, 51816], "temperature": 0.0, "avg_logprob": -0.13366365854719045, "compression_ratio": 1.6398467432950192, "no_speech_prob": 0.0006069288356229663}, {"id": 236, "seek": 92184, "start": 922.44, "end": 927.96, "text": " Now, again, to contrast to the status quo, digital ALI in deep learning is,", "tokens": [50394, 823, 11, 797, 11, 281, 8712, 281, 264, 6558, 28425, 11, 4562, 7056, 40, 294, 2452, 2539, 307, 11, 50670], "temperature": 0.0, "avg_logprob": -0.2115483367652224, "compression_ratio": 1.7360594795539033, "no_speech_prob": 0.00039197553996928036}, {"id": 237, "seek": 92184, "start": 928.6, "end": 932.6, "text": " was primarily built on what are called fully connected layers in neural networks", "tokens": [50702, 390, 10029, 3094, 322, 437, 366, 1219, 4498, 4582, 7914, 294, 18161, 9590, 50902], "temperature": 0.0, "avg_logprob": -0.2115483367652224, "compression_ratio": 1.7360594795539033, "no_speech_prob": 0.00039197553996928036}, {"id": 238, "seek": 92184, "start": 932.6, "end": 935.72, "text": " where you have a layer of neurons and another layer of neurons and you", "tokens": [50902, 689, 291, 362, 257, 4583, 295, 22027, 293, 1071, 4583, 295, 22027, 293, 291, 51058], "temperature": 0.0, "avg_logprob": -0.2115483367652224, "compression_ratio": 1.7360594795539033, "no_speech_prob": 0.00039197553996928036}, {"id": 239, "seek": 92184, "start": 935.72, "end": 939.44, "text": " connect every neuron here to every neuron in the next layer.", "tokens": [51058, 1745, 633, 34090, 510, 281, 633, 34090, 294, 264, 958, 4583, 13, 51244], "temperature": 0.0, "avg_logprob": -0.2115483367652224, "compression_ratio": 1.7360594795539033, "no_speech_prob": 0.00039197553996928036}, {"id": 240, "seek": 92184, "start": 940.0, "end": 940.36, "text": " Whoa.", "tokens": [51272, 7521, 13, 51290], "temperature": 0.0, "avg_logprob": -0.2115483367652224, "compression_ratio": 1.7360594795539033, "no_speech_prob": 0.00039197553996928036}, {"id": 241, "seek": 92184, "start": 940.36, "end": 945.6, "text": " This was, that was the natural way to do it on GPUs because GPUs do these", "tokens": [51290, 639, 390, 11, 300, 390, 264, 3303, 636, 281, 360, 309, 322, 18407, 82, 570, 18407, 82, 360, 613, 51552], "temperature": 0.0, "avg_logprob": -0.2115483367652224, "compression_ratio": 1.7360594795539033, "no_speech_prob": 0.00039197553996928036}, {"id": 242, "seek": 92184, "start": 945.6, "end": 949.12, "text": " dense matrix multiplications, which correspond to this fully connected,", "tokens": [51552, 18011, 8141, 17596, 763, 11, 597, 6805, 281, 341, 4498, 4582, 11, 51728], "temperature": 0.0, "avg_logprob": -0.2115483367652224, "compression_ratio": 1.7360594795539033, "no_speech_prob": 0.00039197553996928036}, {"id": 243, "seek": 92184, "start": 949.1600000000001, "end": 950.36, "text": " densely connected systems.", "tokens": [51730, 24505, 736, 4582, 3652, 13, 51790], "temperature": 0.0, "avg_logprob": -0.2115483367652224, "compression_ratio": 1.7360594795539033, "no_speech_prob": 0.00039197553996928036}, {"id": 244, "seek": 95036, "start": 951.36, "end": 953.8000000000001, "text": " Now, our brain is very different.", "tokens": [50414, 823, 11, 527, 3567, 307, 588, 819, 13, 50536], "temperature": 0.0, "avg_logprob": -0.20169421075617225, "compression_ratio": 1.717741935483871, "no_speech_prob": 0.00030531699303537607}, {"id": 245, "seek": 95036, "start": 954.04, "end": 957.96, "text": " Our brain of all the possible connections that could exist between", "tokens": [50548, 2621, 3567, 295, 439, 264, 1944, 9271, 300, 727, 2514, 1296, 50744], "temperature": 0.0, "avg_logprob": -0.20169421075617225, "compression_ratio": 1.717741935483871, "no_speech_prob": 0.00030531699303537607}, {"id": 246, "seek": 95036, "start": 957.96, "end": 963.12, "text": " neurons, it's something like just a fraction or one percent of those", "tokens": [50744, 22027, 11, 309, 311, 746, 411, 445, 257, 14135, 420, 472, 3043, 295, 729, 51002], "temperature": 0.0, "avg_logprob": -0.20169421075617225, "compression_ratio": 1.717741935483871, "no_speech_prob": 0.00030531699303537607}, {"id": 247, "seek": 95036, "start": 963.12, "end": 964.0, "text": " connections exist.", "tokens": [51002, 9271, 2514, 13, 51046], "temperature": 0.0, "avg_logprob": -0.20169421075617225, "compression_ratio": 1.717741935483871, "no_speech_prob": 0.00030531699303537607}, {"id": 248, "seek": 95036, "start": 964.52, "end": 970.04, "text": " And yet at the same time, the path for information to travel from one neuron", "tokens": [51072, 400, 1939, 412, 264, 912, 565, 11, 264, 3100, 337, 1589, 281, 3147, 490, 472, 34090, 51348], "temperature": 0.0, "avg_logprob": -0.20169421075617225, "compression_ratio": 1.717741935483871, "no_speech_prob": 0.00030531699303537607}, {"id": 249, "seek": 95036, "start": 970.04, "end": 971.88, "text": " to any other neuron is very short.", "tokens": [51348, 281, 604, 661, 34090, 307, 588, 2099, 13, 51440], "temperature": 0.0, "avg_logprob": -0.20169421075617225, "compression_ratio": 1.717741935483871, "no_speech_prob": 0.00030531699303537607}, {"id": 250, "seek": 95036, "start": 972.2, "end": 976.44, "text": " The average path length is about four jumps for information to traverse", "tokens": [51456, 440, 4274, 3100, 4641, 307, 466, 1451, 16704, 337, 1589, 281, 45674, 51668], "temperature": 0.0, "avg_logprob": -0.20169421075617225, "compression_ratio": 1.717741935483871, "no_speech_prob": 0.00030531699303537607}, {"id": 251, "seek": 95036, "start": 976.44, "end": 977.6800000000001, "text": " anywhere in the brain.", "tokens": [51668, 4992, 294, 264, 3567, 13, 51730], "temperature": 0.0, "avg_logprob": -0.20169421075617225, "compression_ratio": 1.717741935483871, "no_speech_prob": 0.00030531699303537607}, {"id": 252, "seek": 95036, "start": 977.88, "end": 979.64, "text": " It's extremely well connected.", "tokens": [51740, 467, 311, 4664, 731, 4582, 13, 51828], "temperature": 0.0, "avg_logprob": -0.20169421075617225, "compression_ratio": 1.717741935483871, "no_speech_prob": 0.00030531699303537607}, {"id": 253, "seek": 97964, "start": 980.1999999999999, "end": 983.8, "text": " So there are these special patterns of connectivity.", "tokens": [50392, 407, 456, 366, 613, 2121, 8294, 295, 21095, 13, 50572], "temperature": 0.0, "avg_logprob": -0.10830550640821457, "compression_ratio": 1.9169675090252707, "no_speech_prob": 0.0008557079127058387}, {"id": 254, "seek": 97964, "start": 984.04, "end": 986.24, "text": " One of them is called a small world network.", "tokens": [50584, 1485, 295, 552, 307, 1219, 257, 1359, 1002, 3209, 13, 50694], "temperature": 0.0, "avg_logprob": -0.10830550640821457, "compression_ratio": 1.9169675090252707, "no_speech_prob": 0.0008557079127058387}, {"id": 255, "seek": 97964, "start": 986.72, "end": 990.36, "text": " And if you've ever heard of a small world network, it's a network pattern", "tokens": [50718, 400, 498, 291, 600, 1562, 2198, 295, 257, 1359, 1002, 3209, 11, 309, 311, 257, 3209, 5102, 50900], "temperature": 0.0, "avg_logprob": -0.10830550640821457, "compression_ratio": 1.9169675090252707, "no_speech_prob": 0.0008557079127058387}, {"id": 256, "seek": 97964, "start": 990.36, "end": 994.04, "text": " that also mirrors human social networks that gives rise to the six", "tokens": [50900, 300, 611, 24238, 1952, 2093, 9590, 300, 2709, 6272, 281, 264, 2309, 51084], "temperature": 0.0, "avg_logprob": -0.10830550640821457, "compression_ratio": 1.9169675090252707, "no_speech_prob": 0.0008557079127058387}, {"id": 257, "seek": 97964, "start": 994.04, "end": 996.8, "text": " degrees of separation property and human connections.", "tokens": [51084, 5310, 295, 14634, 4707, 293, 1952, 9271, 13, 51222], "temperature": 0.0, "avg_logprob": -0.10830550640821457, "compression_ratio": 1.9169675090252707, "no_speech_prob": 0.0008557079127058387}, {"id": 258, "seek": 97964, "start": 997.56, "end": 1000.0, "text": " And the idea is you can have lots of local connections.", "tokens": [51260, 400, 264, 1558, 307, 291, 393, 362, 3195, 295, 2654, 9271, 13, 51382], "temperature": 0.0, "avg_logprob": -0.10830550640821457, "compression_ratio": 1.9169675090252707, "no_speech_prob": 0.0008557079127058387}, {"id": 259, "seek": 97964, "start": 1000.04, "end": 1001.52, "text": " You want to be connected to your neighbors.", "tokens": [51384, 509, 528, 281, 312, 4582, 281, 428, 12512, 13, 51458], "temperature": 0.0, "avg_logprob": -0.10830550640821457, "compression_ratio": 1.9169675090252707, "no_speech_prob": 0.0008557079127058387}, {"id": 260, "seek": 97964, "start": 1001.52, "end": 1003.3199999999999, "text": " You're likely to be connected to your neighbors.", "tokens": [51458, 509, 434, 3700, 281, 312, 4582, 281, 428, 12512, 13, 51548], "temperature": 0.0, "avg_logprob": -0.10830550640821457, "compression_ratio": 1.9169675090252707, "no_speech_prob": 0.0008557079127058387}, {"id": 261, "seek": 97964, "start": 1003.3199999999999, "end": 1005.2, "text": " And that's a very short path to bridge.", "tokens": [51548, 400, 300, 311, 257, 588, 2099, 3100, 281, 7283, 13, 51642], "temperature": 0.0, "avg_logprob": -0.10830550640821457, "compression_ratio": 1.9169675090252707, "no_speech_prob": 0.0008557079127058387}, {"id": 262, "seek": 97964, "start": 1005.72, "end": 1008.88, "text": " And then you want some long distance connections.", "tokens": [51668, 400, 550, 291, 528, 512, 938, 4560, 9271, 13, 51826], "temperature": 0.0, "avg_logprob": -0.10830550640821457, "compression_ratio": 1.9169675090252707, "no_speech_prob": 0.0008557079127058387}, {"id": 263, "seek": 100888, "start": 1009.52, "end": 1015.4, "text": " And you can create these very well connected networks at very large scale", "tokens": [50396, 400, 291, 393, 1884, 613, 588, 731, 4582, 9590, 412, 588, 2416, 4373, 50690], "temperature": 0.0, "avg_logprob": -0.179254132647847, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.000791361031588167}, {"id": 264, "seek": 100888, "start": 1015.76, "end": 1019.32, "text": " when you implement these intelligent forms of sparsity.", "tokens": [50708, 562, 291, 4445, 613, 13232, 6422, 295, 637, 685, 507, 13, 50886], "temperature": 0.0, "avg_logprob": -0.179254132647847, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.000791361031588167}, {"id": 265, "seek": 100888, "start": 1019.76, "end": 1024.92, "text": " So sparsity is core to our scaling architecture.", "tokens": [50908, 407, 637, 685, 507, 307, 4965, 281, 527, 21589, 9482, 13, 51166], "temperature": 0.0, "avg_logprob": -0.179254132647847, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.000791361031588167}, {"id": 266, "seek": 100888, "start": 1025.36, "end": 1027.68, "text": " And really, and just to kind of summarize there.", "tokens": [51188, 400, 534, 11, 293, 445, 281, 733, 295, 20858, 456, 13, 51304], "temperature": 0.0, "avg_logprob": -0.179254132647847, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.000791361031588167}, {"id": 267, "seek": 100888, "start": 1027.76, "end": 1030.8, "text": " So we have these are the two core technologies we've developed.", "tokens": [51308, 407, 321, 362, 613, 366, 264, 732, 4965, 7943, 321, 600, 4743, 13, 51460], "temperature": 0.0, "avg_logprob": -0.179254132647847, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.000791361031588167}, {"id": 268, "seek": 100888, "start": 1031.0, "end": 1034.88, "text": " A learning algorithm that learns of the local learning rule and a scaling", "tokens": [51470, 316, 2539, 9284, 300, 27152, 295, 264, 2654, 2539, 4978, 293, 257, 21589, 51664], "temperature": 0.0, "avg_logprob": -0.179254132647847, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.000791361031588167}, {"id": 269, "seek": 103488, "start": 1034.88, "end": 1039.5200000000002, "text": " architecture that scales to massive sizes of neural networks using intelligent sparsity.", "tokens": [50364, 9482, 300, 17408, 281, 5994, 11602, 295, 18161, 9590, 1228, 13232, 637, 685, 507, 13, 50596], "temperature": 0.0, "avg_logprob": -0.1849784255027771, "compression_ratio": 1.5368852459016393, "no_speech_prob": 0.0005527049070224166}, {"id": 270, "seek": 103488, "start": 1041.2, "end": 1043.1200000000001, "text": " I knew Kevin Bacon would come up some point.", "tokens": [50680, 286, 2586, 9954, 42460, 576, 808, 493, 512, 935, 13, 50776], "temperature": 0.0, "avg_logprob": -0.1849784255027771, "compression_ratio": 1.5368852459016393, "no_speech_prob": 0.0005527049070224166}, {"id": 271, "seek": 103488, "start": 1043.2, "end": 1045.3200000000002, "text": " I mean, inevitable.", "tokens": [50780, 286, 914, 11, 21451, 13, 50886], "temperature": 0.0, "avg_logprob": -0.1849784255027771, "compression_ratio": 1.5368852459016393, "no_speech_prob": 0.0005527049070224166}, {"id": 272, "seek": 103488, "start": 1046.88, "end": 1052.2800000000002, "text": " Last year, I believe you sort of taped a functional chip together.", "tokens": [50964, 5264, 1064, 11, 286, 1697, 291, 1333, 295, 45673, 257, 11745, 11409, 1214, 13, 51234], "temperature": 0.0, "avg_logprob": -0.1849784255027771, "compression_ratio": 1.5368852459016393, "no_speech_prob": 0.0005527049070224166}, {"id": 273, "seek": 103488, "start": 1052.2800000000002, "end": 1053.64, "text": " Your first prototype.", "tokens": [51234, 2260, 700, 19475, 13, 51302], "temperature": 0.0, "avg_logprob": -0.1849784255027771, "compression_ratio": 1.5368852459016393, "no_speech_prob": 0.0005527049070224166}, {"id": 274, "seek": 103488, "start": 1054.0, "end": 1057.24, "text": " Where are you on the journey to shipping a fully functional chip?", "tokens": [51320, 2305, 366, 291, 322, 264, 4671, 281, 14122, 257, 4498, 11745, 11409, 30, 51482], "temperature": 0.0, "avg_logprob": -0.1849784255027771, "compression_ratio": 1.5368852459016393, "no_speech_prob": 0.0005527049070224166}, {"id": 275, "seek": 103488, "start": 1058.68, "end": 1063.7600000000002, "text": " So we have, I'd say in the last four years, you know, we have done", "tokens": [51554, 407, 321, 362, 11, 286, 1116, 584, 294, 264, 1036, 1451, 924, 11, 291, 458, 11, 321, 362, 1096, 51808], "temperature": 0.0, "avg_logprob": -0.1849784255027771, "compression_ratio": 1.5368852459016393, "no_speech_prob": 0.0005527049070224166}, {"id": 276, "seek": 106376, "start": 1064.24, "end": 1070.44, "text": " such expansive work that has been mostly, I would say, qualified as a research.", "tokens": [50388, 1270, 46949, 589, 300, 575, 668, 5240, 11, 286, 576, 584, 11, 15904, 382, 257, 2132, 13, 50698], "temperature": 0.0, "avg_logprob": -0.13400273530379586, "compression_ratio": 1.7177700348432057, "no_speech_prob": 0.0009107126970775425}, {"id": 277, "seek": 106376, "start": 1070.84, "end": 1072.64, "text": " We've been exploring different algorithms.", "tokens": [50718, 492, 600, 668, 12736, 819, 14642, 13, 50808], "temperature": 0.0, "avg_logprob": -0.13400273530379586, "compression_ratio": 1.7177700348432057, "no_speech_prob": 0.0009107126970775425}, {"id": 278, "seek": 106376, "start": 1072.64, "end": 1074.48, "text": " We've been exploring different architectures.", "tokens": [50808, 492, 600, 668, 12736, 819, 6331, 1303, 13, 50900], "temperature": 0.0, "avg_logprob": -0.13400273530379586, "compression_ratio": 1.7177700348432057, "no_speech_prob": 0.0009107126970775425}, {"id": 279, "seek": 106376, "start": 1075.28, "end": 1079.24, "text": " Originally, we have this concept using random nanowire meshes.", "tokens": [50940, 28696, 11, 321, 362, 341, 3410, 1228, 4974, 14067, 305, 621, 3813, 8076, 13, 51138], "temperature": 0.0, "avg_logprob": -0.13400273530379586, "compression_ratio": 1.7177700348432057, "no_speech_prob": 0.0009107126970775425}, {"id": 280, "seek": 106376, "start": 1079.8, "end": 1083.04, "text": " Turns out it's not very manufacturable and better to build things", "tokens": [51166, 29524, 484, 309, 311, 406, 588, 5793, 25863, 293, 1101, 281, 1322, 721, 51328], "temperature": 0.0, "avg_logprob": -0.13400273530379586, "compression_ratio": 1.7177700348432057, "no_speech_prob": 0.0009107126970775425}, {"id": 281, "seek": 106376, "start": 1083.04, "end": 1085.48, "text": " that you can manufacture today easily.", "tokens": [51328, 300, 291, 393, 27400, 965, 3612, 13, 51450], "temperature": 0.0, "avg_logprob": -0.13400273530379586, "compression_ratio": 1.7177700348432057, "no_speech_prob": 0.0009107126970775425}, {"id": 282, "seek": 106376, "start": 1085.48, "end": 1090.24, "text": " But in this last year, we kind of crystallized kind of our two core technologies.", "tokens": [51450, 583, 294, 341, 1036, 1064, 11, 321, 733, 295, 31924, 1602, 733, 295, 527, 732, 4965, 7943, 13, 51688], "temperature": 0.0, "avg_logprob": -0.13400273530379586, "compression_ratio": 1.7177700348432057, "no_speech_prob": 0.0009107126970775425}, {"id": 283, "seek": 106376, "start": 1090.24, "end": 1093.0, "text": " Like what is the learning algorithm and what is that scaling architecture?", "tokens": [51688, 1743, 437, 307, 264, 2539, 9284, 293, 437, 307, 300, 21589, 9482, 30, 51826], "temperature": 0.0, "avg_logprob": -0.13400273530379586, "compression_ratio": 1.7177700348432057, "no_speech_prob": 0.0009107126970775425}, {"id": 284, "seek": 109300, "start": 1093.28, "end": 1095.52, "text": " And then developed hardware prototypes of each.", "tokens": [50378, 400, 550, 4743, 8837, 42197, 295, 1184, 13, 50490], "temperature": 0.0, "avg_logprob": -0.1919869683005593, "compression_ratio": 1.6273764258555132, "no_speech_prob": 0.0011691893450915813}, {"id": 285, "seek": 109300, "start": 1096.24, "end": 1100.8, "text": " We still have a good amount of time to engineer this completely and to get to market.", "tokens": [50526, 492, 920, 362, 257, 665, 2372, 295, 565, 281, 11403, 341, 2584, 293, 281, 483, 281, 2142, 13, 50754], "temperature": 0.0, "avg_logprob": -0.1919869683005593, "compression_ratio": 1.6273764258555132, "no_speech_prob": 0.0011691893450915813}, {"id": 286, "seek": 109300, "start": 1100.8, "end": 1106.6, "text": " We we hope to get to market, you know, on the order of full scale shipping 2025.", "tokens": [50754, 492, 321, 1454, 281, 483, 281, 2142, 11, 291, 458, 11, 322, 264, 1668, 295, 1577, 4373, 14122, 39209, 13, 51044], "temperature": 0.0, "avg_logprob": -0.1919869683005593, "compression_ratio": 1.6273764258555132, "no_speech_prob": 0.0011691893450915813}, {"id": 287, "seek": 109300, "start": 1108.04, "end": 1113.48, "text": " But that said, you know, building the world's first analog neural network is not easy.", "tokens": [51116, 583, 300, 848, 11, 291, 458, 11, 2390, 264, 1002, 311, 700, 16660, 18161, 3209, 307, 406, 1858, 13, 51388], "temperature": 0.0, "avg_logprob": -0.1919869683005593, "compression_ratio": 1.6273764258555132, "no_speech_prob": 0.0011691893450915813}, {"id": 288, "seek": 109300, "start": 1114.76, "end": 1118.96, "text": " You know, to iterate through this and get it fully fully up at scale.", "tokens": [51452, 509, 458, 11, 281, 44497, 807, 341, 293, 483, 309, 4498, 4498, 493, 412, 4373, 13, 51662], "temperature": 0.0, "avg_logprob": -0.1919869683005593, "compression_ratio": 1.6273764258555132, "no_speech_prob": 0.0011691893450915813}, {"id": 289, "seek": 109300, "start": 1119.92, "end": 1121.28, "text": " And you just got some help there.", "tokens": [51710, 400, 291, 445, 658, 512, 854, 456, 13, 51778], "temperature": 0.0, "avg_logprob": -0.1919869683005593, "compression_ratio": 1.6273764258555132, "no_speech_prob": 0.0011691893450915813}, {"id": 290, "seek": 109300, "start": 1121.28, "end": 1122.2, "text": " You raised some funds.", "tokens": [51778, 509, 6005, 512, 8271, 13, 51824], "temperature": 0.0, "avg_logprob": -0.1919869683005593, "compression_ratio": 1.6273764258555132, "no_speech_prob": 0.0011691893450915813}, {"id": 291, "seek": 112220, "start": 1122.8, "end": 1123.52, "text": " Yeah. Yeah.", "tokens": [50394, 865, 13, 865, 13, 50430], "temperature": 0.0, "avg_logprob": -0.17086029052734375, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.00032498862128704786}, {"id": 292, "seek": 112220, "start": 1123.52, "end": 1127.88, "text": " Yeah. So we just closed a 25 million series A, which is thrilling.", "tokens": [50430, 865, 13, 407, 321, 445, 5395, 257, 3552, 2459, 2638, 316, 11, 597, 307, 39347, 13, 50648], "temperature": 0.0, "avg_logprob": -0.17086029052734375, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.00032498862128704786}, {"id": 293, "seek": 112220, "start": 1128.3600000000001, "end": 1131.92, "text": " You know, we had used eight million dollars for the last four years", "tokens": [50672, 509, 458, 11, 321, 632, 1143, 3180, 2459, 3808, 337, 264, 1036, 1451, 924, 50850], "temperature": 0.0, "avg_logprob": -0.17086029052734375, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.00032498862128704786}, {"id": 294, "seek": 112220, "start": 1131.92, "end": 1136.0, "text": " and honestly had gone through some challenging times where, you know,", "tokens": [50850, 293, 6095, 632, 2780, 807, 512, 7595, 1413, 689, 11, 291, 458, 11, 51054], "temperature": 0.0, "avg_logprob": -0.17086029052734375, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.00032498862128704786}, {"id": 295, "seek": 112220, "start": 1136.68, "end": 1138.6000000000001, "text": " we got really close.", "tokens": [51088, 321, 658, 534, 1998, 13, 51184], "temperature": 0.0, "avg_logprob": -0.17086029052734375, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.00032498862128704786}, {"id": 296, "seek": 112220, "start": 1138.6000000000001, "end": 1141.68, "text": " You know, one of our first tape out prototypes didn't function", "tokens": [51184, 509, 458, 11, 472, 295, 527, 700, 7314, 484, 42197, 994, 380, 2445, 51338], "temperature": 0.0, "avg_logprob": -0.17086029052734375, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.00032498862128704786}, {"id": 297, "seek": 112220, "start": 1141.68, "end": 1142.72, "text": " precisely as designed.", "tokens": [51338, 13402, 382, 4761, 13, 51390], "temperature": 0.0, "avg_logprob": -0.17086029052734375, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.00032498862128704786}, {"id": 298, "seek": 112220, "start": 1142.72, "end": 1144.1200000000001, "text": " It was a very silly error.", "tokens": [51390, 467, 390, 257, 588, 11774, 6713, 13, 51460], "temperature": 0.0, "avg_logprob": -0.17086029052734375, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.00032498862128704786}, {"id": 299, "seek": 112220, "start": 1144.1200000000001, "end": 1148.64, "text": " But in ships, it takes a long time to iterate and even and resolve.", "tokens": [51460, 583, 294, 11434, 11, 309, 2516, 257, 938, 565, 281, 44497, 293, 754, 293, 14151, 13, 51686], "temperature": 0.0, "avg_logprob": -0.17086029052734375, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.00032498862128704786}, {"id": 300, "seek": 112220, "start": 1148.64, "end": 1150.64, "text": " You can't just debug like software.", "tokens": [51686, 509, 393, 380, 445, 24083, 411, 4722, 13, 51786], "temperature": 0.0, "avg_logprob": -0.17086029052734375, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.00032498862128704786}, {"id": 301, "seek": 115064, "start": 1150.68, "end": 1152.0800000000002, "text": " So we went through a lot.", "tokens": [50366, 407, 321, 1437, 807, 257, 688, 13, 50436], "temperature": 0.0, "avg_logprob": -0.15674285685762446, "compression_ratio": 1.5, "no_speech_prob": 0.00017951257177628577}, {"id": 302, "seek": 115064, "start": 1152.0800000000002, "end": 1153.0, "text": " We learned a lot.", "tokens": [50436, 492, 3264, 257, 688, 13, 50482], "temperature": 0.0, "avg_logprob": -0.15674285685762446, "compression_ratio": 1.5, "no_speech_prob": 0.00017951257177628577}, {"id": 303, "seek": 115064, "start": 1153.0, "end": 1156.88, "text": " And now we have 25 million in the bank and we're hiring like crazy.", "tokens": [50482, 400, 586, 321, 362, 3552, 2459, 294, 264, 3765, 293, 321, 434, 15335, 411, 3219, 13, 50676], "temperature": 0.0, "avg_logprob": -0.15674285685762446, "compression_ratio": 1.5, "no_speech_prob": 0.00017951257177628577}, {"id": 304, "seek": 115064, "start": 1158.0, "end": 1160.72, "text": " Wonderful. It goes quickly, I know, from personal experience.", "tokens": [50732, 22768, 13, 467, 1709, 2661, 11, 286, 458, 11, 490, 2973, 1752, 13, 50868], "temperature": 0.0, "avg_logprob": -0.15674285685762446, "compression_ratio": 1.5, "no_speech_prob": 0.00017951257177628577}, {"id": 305, "seek": 115064, "start": 1163.2, "end": 1166.64, "text": " So talk about what this will enable.", "tokens": [50992, 407, 751, 466, 437, 341, 486, 9528, 13, 51164], "temperature": 0.0, "avg_logprob": -0.15674285685762446, "compression_ratio": 1.5, "no_speech_prob": 0.00017951257177628577}, {"id": 306, "seek": 115064, "start": 1167.5600000000002, "end": 1169.3200000000002, "text": " You're shipping this ship.", "tokens": [51210, 509, 434, 14122, 341, 5374, 13, 51298], "temperature": 0.0, "avg_logprob": -0.15674285685762446, "compression_ratio": 1.5, "no_speech_prob": 0.00017951257177628577}, {"id": 307, "seek": 115064, "start": 1169.3200000000002, "end": 1171.44, "text": " What will it enable?", "tokens": [51298, 708, 486, 309, 9528, 30, 51404], "temperature": 0.0, "avg_logprob": -0.15674285685762446, "compression_ratio": 1.5, "no_speech_prob": 0.00017951257177628577}, {"id": 308, "seek": 115064, "start": 1171.44, "end": 1178.76, "text": " Yeah. So we want to not enable just like an incremental improvement in AI.", "tokens": [51404, 865, 13, 407, 321, 528, 281, 406, 9528, 445, 411, 364, 35759, 10444, 294, 7318, 13, 51770], "temperature": 0.0, "avg_logprob": -0.15674285685762446, "compression_ratio": 1.5, "no_speech_prob": 0.00017951257177628577}, {"id": 309, "seek": 117876, "start": 1178.92, "end": 1183.68, "text": " You know, I think that there are a lot of folks and video included", "tokens": [50372, 509, 458, 11, 286, 519, 300, 456, 366, 257, 688, 295, 4024, 293, 960, 5556, 50610], "temperature": 0.0, "avg_logprob": -0.15364959648063592, "compression_ratio": 1.7538461538461538, "no_speech_prob": 0.008572367951273918}, {"id": 310, "seek": 117876, "start": 1183.68, "end": 1188.6, "text": " on the digital hardware roadmap and because digital hardware is so mature,", "tokens": [50610, 322, 264, 4562, 8837, 35738, 293, 570, 4562, 8837, 307, 370, 14442, 11, 50856], "temperature": 0.0, "avg_logprob": -0.15364959648063592, "compression_ratio": 1.7538461538461538, "no_speech_prob": 0.008572367951273918}, {"id": 311, "seek": 117876, "start": 1189.0, "end": 1192.48, "text": " it's just it's kind of incremental gains that we're getting at this point.", "tokens": [50876, 309, 311, 445, 309, 311, 733, 295, 35759, 16823, 300, 321, 434, 1242, 412, 341, 935, 13, 51050], "temperature": 0.0, "avg_logprob": -0.15364959648063592, "compression_ratio": 1.7538461538461538, "no_speech_prob": 0.008572367951273918}, {"id": 312, "seek": 117876, "start": 1192.48, "end": 1196.08, "text": " And I think there's still more improvement to be geeked out on that roadmap.", "tokens": [51050, 400, 286, 519, 456, 311, 920, 544, 10444, 281, 312, 36162, 292, 484, 322, 300, 35738, 13, 51230], "temperature": 0.0, "avg_logprob": -0.15364959648063592, "compression_ratio": 1.7538461538461538, "no_speech_prob": 0.008572367951273918}, {"id": 313, "seek": 117876, "start": 1196.6, "end": 1202.12, "text": " But we're trying to enable a new roadmap that is really a step change", "tokens": [51256, 583, 321, 434, 1382, 281, 9528, 257, 777, 35738, 300, 307, 534, 257, 1823, 1319, 51532], "temperature": 0.0, "avg_logprob": -0.15364959648063592, "compression_ratio": 1.7538461538461538, "no_speech_prob": 0.008572367951273918}, {"id": 314, "seek": 117876, "start": 1202.2, "end": 1204.04, "text": " in performance improvement.", "tokens": [51536, 294, 3389, 10444, 13, 51628], "temperature": 0.0, "avg_logprob": -0.15364959648063592, "compression_ratio": 1.7538461538461538, "no_speech_prob": 0.008572367951273918}, {"id": 315, "seek": 117876, "start": 1204.04, "end": 1208.6, "text": " And so we want to enter the market really at a thousand X energy", "tokens": [51628, 400, 370, 321, 528, 281, 3242, 264, 2142, 534, 412, 257, 4714, 1783, 2281, 51856], "temperature": 0.0, "avg_logprob": -0.15364959648063592, "compression_ratio": 1.7538461538461538, "no_speech_prob": 0.008572367951273918}, {"id": 316, "seek": 120860, "start": 1208.6, "end": 1211.28, "text": " efficiency improvement over status quo hardware.", "tokens": [50364, 10493, 10444, 670, 6558, 28425, 8837, 13, 50498], "temperature": 0.0, "avg_logprob": -0.15794385047185988, "compression_ratio": 1.5633187772925765, "no_speech_prob": 0.0002779994683805853}, {"id": 317, "seek": 120860, "start": 1211.56, "end": 1215.32, "text": " And at a thousand X comes from about a 10 X reduction in power", "tokens": [50512, 400, 412, 257, 4714, 1783, 1487, 490, 466, 257, 1266, 1783, 11004, 294, 1347, 50700], "temperature": 0.0, "avg_logprob": -0.15794385047185988, "compression_ratio": 1.5633187772925765, "no_speech_prob": 0.0002779994683805853}, {"id": 318, "seek": 120860, "start": 1215.7199999999998, "end": 1218.24, "text": " alongside a 100 X improvement in speed.", "tokens": [50720, 12385, 257, 2319, 1783, 10444, 294, 3073, 13, 50846], "temperature": 0.0, "avg_logprob": -0.15794385047185988, "compression_ratio": 1.5633187772925765, "no_speech_prob": 0.0002779994683805853}, {"id": 319, "seek": 120860, "start": 1219.12, "end": 1224.3999999999999, "text": " And when you can do that and importantly, not just for inference,", "tokens": [50890, 400, 562, 291, 393, 360, 300, 293, 8906, 11, 406, 445, 337, 38253, 11, 51154], "temperature": 0.0, "avg_logprob": -0.15794385047185988, "compression_ratio": 1.5633187772925765, "no_speech_prob": 0.0002779994683805853}, {"id": 320, "seek": 120860, "start": 1224.3999999999999, "end": 1228.6399999999999, "text": " we're talking about training and inference in the same platform.", "tokens": [51154, 321, 434, 1417, 466, 3097, 293, 38253, 294, 264, 912, 3663, 13, 51366], "temperature": 0.0, "avg_logprob": -0.15794385047185988, "compression_ratio": 1.5633187772925765, "no_speech_prob": 0.0002779994683805853}, {"id": 321, "seek": 120860, "start": 1229.04, "end": 1234.48, "text": " It unlocks possibilities that have just been inconceivable until until now.", "tokens": [51386, 467, 517, 34896, 12178, 300, 362, 445, 668, 20972, 384, 34376, 1826, 1826, 586, 13, 51658], "temperature": 0.0, "avg_logprob": -0.15794385047185988, "compression_ratio": 1.5633187772925765, "no_speech_prob": 0.0002779994683805853}, {"id": 322, "seek": 123448, "start": 1235.28, "end": 1239.2, "text": " For one, you know, currently people consider training and inference", "tokens": [50404, 1171, 472, 11, 291, 458, 11, 4362, 561, 1949, 3097, 293, 38253, 50600], "temperature": 0.0, "avg_logprob": -0.10845736153105386, "compression_ratio": 1.675, "no_speech_prob": 0.0006460913573391736}, {"id": 323, "seek": 123448, "start": 1239.2, "end": 1243.1200000000001, "text": " as these kind of separate problems that we need separate platforms of hardware with.", "tokens": [50600, 382, 613, 733, 295, 4994, 2740, 300, 321, 643, 4994, 9473, 295, 8837, 365, 13, 50796], "temperature": 0.0, "avg_logprob": -0.10845736153105386, "compression_ratio": 1.675, "no_speech_prob": 0.0006460913573391736}, {"id": 324, "seek": 123448, "start": 1243.6, "end": 1246.88, "text": " You know, we train up in a GPU cloud system,", "tokens": [50820, 509, 458, 11, 321, 3847, 493, 294, 257, 18407, 4588, 1185, 11, 50984], "temperature": 0.0, "avg_logprob": -0.10845736153105386, "compression_ratio": 1.675, "no_speech_prob": 0.0006460913573391736}, {"id": 325, "seek": 123448, "start": 1246.88, "end": 1250.0, "text": " and then we might upload those weights onto a more efficient chip", "tokens": [50984, 293, 550, 321, 1062, 6580, 729, 17443, 3911, 257, 544, 7148, 11409, 51140], "temperature": 0.0, "avg_logprob": -0.10845736153105386, "compression_ratio": 1.675, "no_speech_prob": 0.0006460913573391736}, {"id": 326, "seek": 123448, "start": 1250.0, "end": 1252.6, "text": " and deploy it out into the world.", "tokens": [51140, 293, 7274, 309, 484, 666, 264, 1002, 13, 51270], "temperature": 0.0, "avg_logprob": -0.10845736153105386, "compression_ratio": 1.675, "no_speech_prob": 0.0006460913573391736}, {"id": 327, "seek": 123448, "start": 1252.6, "end": 1256.92, "text": " I think that would be the first step for kind of low power inference in devices.", "tokens": [51270, 286, 519, 300, 576, 312, 264, 700, 1823, 337, 733, 295, 2295, 1347, 38253, 294, 5759, 13, 51486], "temperature": 0.0, "avg_logprob": -0.10845736153105386, "compression_ratio": 1.675, "no_speech_prob": 0.0006460913573391736}, {"id": 328, "seek": 123448, "start": 1256.92, "end": 1260.8, "text": " But we don't want devices just to be pre-programmed", "tokens": [51486, 583, 321, 500, 380, 528, 5759, 445, 281, 312, 659, 12, 32726, 1912, 51680], "temperature": 0.0, "avg_logprob": -0.10845736153105386, "compression_ratio": 1.675, "no_speech_prob": 0.0006460913573391736}, {"id": 329, "seek": 123448, "start": 1260.8, "end": 1262.84, "text": " and just do what they do in the world.", "tokens": [51680, 293, 445, 360, 437, 436, 360, 294, 264, 1002, 13, 51782], "temperature": 0.0, "avg_logprob": -0.10845736153105386, "compression_ratio": 1.675, "no_speech_prob": 0.0006460913573391736}, {"id": 330, "seek": 126284, "start": 1262.84, "end": 1265.6, "text": " We want devices to learn on their own.", "tokens": [50364, 492, 528, 5759, 281, 1466, 322, 641, 1065, 13, 50502], "temperature": 0.0, "avg_logprob": -0.1272983948389689, "compression_ratio": 1.779467680608365, "no_speech_prob": 0.0005883356789126992}, {"id": 331, "seek": 126284, "start": 1265.6, "end": 1267.9199999999998, "text": " We want devices to have an adaptive brain", "tokens": [50502, 492, 528, 5759, 281, 362, 364, 27912, 3567, 50618], "temperature": 0.0, "avg_logprob": -0.1272983948389689, "compression_ratio": 1.779467680608365, "no_speech_prob": 0.0005883356789126992}, {"id": 332, "seek": 126284, "start": 1267.9199999999998, "end": 1272.4399999999998, "text": " that's continuously learning from a changing environment and from a changing self.", "tokens": [50618, 300, 311, 15684, 2539, 490, 257, 4473, 2823, 293, 490, 257, 4473, 2698, 13, 50844], "temperature": 0.0, "avg_logprob": -0.1272983948389689, "compression_ratio": 1.779467680608365, "no_speech_prob": 0.0005883356789126992}, {"id": 333, "seek": 126284, "start": 1272.8799999999999, "end": 1274.3999999999999, "text": " So imagine a robot, right?", "tokens": [50866, 407, 3811, 257, 7881, 11, 558, 30, 50942], "temperature": 0.0, "avg_logprob": -0.1272983948389689, "compression_ratio": 1.779467680608365, "no_speech_prob": 0.0005883356789126992}, {"id": 334, "seek": 126284, "start": 1274.3999999999999, "end": 1276.56, "text": " We have we're we're eventually in our lifetime.", "tokens": [50942, 492, 362, 321, 434, 321, 434, 4728, 294, 527, 11364, 13, 51050], "temperature": 0.0, "avg_logprob": -0.1272983948389689, "compression_ratio": 1.779467680608365, "no_speech_prob": 0.0005883356789126992}, {"id": 335, "seek": 126284, "start": 1276.56, "end": 1279.0, "text": " We're going to have robots for everything, you know,", "tokens": [51050, 492, 434, 516, 281, 362, 14733, 337, 1203, 11, 291, 458, 11, 51172], "temperature": 0.0, "avg_logprob": -0.1272983948389689, "compression_ratio": 1.779467680608365, "no_speech_prob": 0.0005883356789126992}, {"id": 336, "seek": 126284, "start": 1279.0, "end": 1281.56, "text": " but maybe it's a construction robot that's helping, you know,", "tokens": [51172, 457, 1310, 309, 311, 257, 6435, 7881, 300, 311, 4315, 11, 291, 458, 11, 51300], "temperature": 0.0, "avg_logprob": -0.1272983948389689, "compression_ratio": 1.779467680608365, "no_speech_prob": 0.0005883356789126992}, {"id": 337, "seek": 126284, "start": 1281.56, "end": 1283.72, "text": " repair our streets or build our homes.", "tokens": [51300, 10535, 527, 8481, 420, 1322, 527, 7388, 13, 51408], "temperature": 0.0, "avg_logprob": -0.1272983948389689, "compression_ratio": 1.779467680608365, "no_speech_prob": 0.0005883356789126992}, {"id": 338, "seek": 126284, "start": 1283.72, "end": 1291.08, "text": " The joints on that robot are going to erode and face damage in unique ways.", "tokens": [51408, 440, 19949, 322, 300, 7881, 366, 516, 281, 1189, 1429, 293, 1851, 4344, 294, 3845, 2098, 13, 51776], "temperature": 0.0, "avg_logprob": -0.1272983948389689, "compression_ratio": 1.779467680608365, "no_speech_prob": 0.0005883356789126992}, {"id": 339, "seek": 129108, "start": 1291.4399999999998, "end": 1295.56, "text": " And it needs to learn how to adjust its own movement", "tokens": [50382, 400, 309, 2203, 281, 1466, 577, 281, 4369, 1080, 1065, 3963, 50588], "temperature": 0.0, "avg_logprob": -0.12742162954927694, "compression_ratio": 1.6456692913385826, "no_speech_prob": 0.008979067206382751}, {"id": 340, "seek": 129108, "start": 1295.56, "end": 1300.3999999999999, "text": " so it can maintain its performance based on its own kind of evolution", "tokens": [50588, 370, 309, 393, 6909, 1080, 3389, 2361, 322, 1080, 1065, 733, 295, 9303, 50830], "temperature": 0.0, "avg_logprob": -0.12742162954927694, "compression_ratio": 1.6456692913385826, "no_speech_prob": 0.008979067206382751}, {"id": 341, "seek": 129108, "start": 1300.3999999999999, "end": 1302.76, "text": " and transition in its physical self.", "tokens": [50830, 293, 6034, 294, 1080, 4001, 2698, 13, 50948], "temperature": 0.0, "avg_logprob": -0.12742162954927694, "compression_ratio": 1.6456692913385826, "no_speech_prob": 0.008979067206382751}, {"id": 342, "seek": 129108, "start": 1302.76, "end": 1306.0, "text": " Also, the robots might be adjusting to new environments.", "tokens": [50948, 2743, 11, 264, 14733, 1062, 312, 23559, 281, 777, 12388, 13, 51110], "temperature": 0.0, "avg_logprob": -0.12742162954927694, "compression_ratio": 1.6456692913385826, "no_speech_prob": 0.008979067206382751}, {"id": 343, "seek": 129108, "start": 1306.3999999999999, "end": 1310.8799999999999, "text": " And we'd like that ability to be baked in so they can continuously and adaptively learn.", "tokens": [51130, 400, 321, 1116, 411, 300, 3485, 281, 312, 19453, 294, 370, 436, 393, 15684, 293, 6231, 3413, 1466, 13, 51354], "temperature": 0.0, "avg_logprob": -0.12742162954927694, "compression_ratio": 1.6456692913385826, "no_speech_prob": 0.008979067206382751}, {"id": 344, "seek": 129108, "start": 1311.6799999999998, "end": 1314.8799999999999, "text": " This also really enables personalization.", "tokens": [51394, 639, 611, 534, 17077, 2973, 2144, 13, 51554], "temperature": 0.0, "avg_logprob": -0.12742162954927694, "compression_ratio": 1.6456692913385826, "no_speech_prob": 0.008979067206382751}, {"id": 345, "seek": 129108, "start": 1314.8799999999999, "end": 1320.32, "text": " It enables machines to get to know us and for us to have the assurance", "tokens": [51554, 467, 17077, 8379, 281, 483, 281, 458, 505, 293, 337, 505, 281, 362, 264, 32189, 51826], "temperature": 0.0, "avg_logprob": -0.12742162954927694, "compression_ratio": 1.6456692913385826, "no_speech_prob": 0.008979067206382751}, {"id": 346, "seek": 132032, "start": 1320.36, "end": 1323.9199999999998, "text": " that that knowledge and data of ourselves is in that robot", "tokens": [50366, 300, 300, 3601, 293, 1412, 295, 4175, 307, 294, 300, 7881, 50544], "temperature": 0.0, "avg_logprob": -0.12716372538421114, "compression_ratio": 1.6705426356589148, "no_speech_prob": 0.0002736655296757817}, {"id": 347, "seek": 132032, "start": 1323.9199999999998, "end": 1327.8, "text": " and doesn't believe that robot, I think is something we will will be very assuring.", "tokens": [50544, 293, 1177, 380, 1697, 300, 7881, 11, 286, 519, 307, 746, 321, 486, 486, 312, 588, 1256, 1345, 13, 50738], "temperature": 0.0, "avg_logprob": -0.12716372538421114, "compression_ratio": 1.6705426356589148, "no_speech_prob": 0.0002736655296757817}, {"id": 348, "seek": 132032, "start": 1328.6399999999999, "end": 1331.72, "text": " But but that's a huge piece, you know, training and inference", "tokens": [50780, 583, 457, 300, 311, 257, 2603, 2522, 11, 291, 458, 11, 3097, 293, 38253, 50934], "temperature": 0.0, "avg_logprob": -0.12716372538421114, "compression_ratio": 1.6705426356589148, "no_speech_prob": 0.0002736655296757817}, {"id": 349, "seek": 132032, "start": 1331.72, "end": 1335.48, "text": " in the same platform that is untethered.", "tokens": [50934, 294, 264, 912, 3663, 300, 307, 1701, 1666, 292, 13, 51122], "temperature": 0.0, "avg_logprob": -0.12716372538421114, "compression_ratio": 1.6705426356589148, "no_speech_prob": 0.0002736655296757817}, {"id": 350, "seek": 132032, "start": 1336.8, "end": 1338.76, "text": " What's really interesting about that?", "tokens": [51188, 708, 311, 534, 1880, 466, 300, 30, 51286], "temperature": 0.0, "avg_logprob": -0.12716372538421114, "compression_ratio": 1.6705426356589148, "no_speech_prob": 0.0002736655296757817}, {"id": 351, "seek": 132032, "start": 1338.76, "end": 1340.32, "text": " Oh, there's a number of things, obviously.", "tokens": [51286, 876, 11, 456, 311, 257, 1230, 295, 721, 11, 2745, 13, 51364], "temperature": 0.0, "avg_logprob": -0.12716372538421114, "compression_ratio": 1.6705426356589148, "no_speech_prob": 0.0002736655296757817}, {"id": 352, "seek": 132032, "start": 1340.32, "end": 1343.8, "text": " But I mean, I'm just thinking of a limping robot.", "tokens": [51364, 583, 286, 914, 11, 286, 478, 445, 1953, 295, 257, 2364, 3381, 7881, 13, 51538], "temperature": 0.0, "avg_logprob": -0.12716372538421114, "compression_ratio": 1.6705426356589148, "no_speech_prob": 0.0002736655296757817}, {"id": 353, "seek": 132032, "start": 1343.8, "end": 1347.24, "text": " For instance, you know, we limp when we injure a joint", "tokens": [51538, 1171, 5197, 11, 291, 458, 11, 321, 33174, 562, 321, 5580, 540, 257, 7225, 51710], "temperature": 0.0, "avg_logprob": -0.12716372538421114, "compression_ratio": 1.6705426356589148, "no_speech_prob": 0.0002736655296757817}, {"id": 354, "seek": 134724, "start": 1347.28, "end": 1354.28, "text": " and that is our adaptation to the limitation in a knee or a hip or something like that.", "tokens": [50366, 293, 300, 307, 527, 21549, 281, 264, 27432, 294, 257, 9434, 420, 257, 8103, 420, 746, 411, 300, 13, 50716], "temperature": 0.0, "avg_logprob": -0.09993310945223918, "compression_ratio": 1.7682926829268293, "no_speech_prob": 0.0014547496102750301}, {"id": 355, "seek": 134724, "start": 1354.28, "end": 1355.48, "text": " And we function with that.", "tokens": [50716, 400, 321, 2445, 365, 300, 13, 50776], "temperature": 0.0, "avg_logprob": -0.09993310945223918, "compression_ratio": 1.7682926829268293, "no_speech_prob": 0.0014547496102750301}, {"id": 356, "seek": 134724, "start": 1355.48, "end": 1360.24, "text": " And, you know, maybe we'll repair the robot, but maybe the robot is inaccessible", "tokens": [50776, 400, 11, 291, 458, 11, 1310, 321, 603, 10535, 264, 7881, 11, 457, 1310, 264, 7881, 307, 33230, 780, 964, 51014], "temperature": 0.0, "avg_logprob": -0.09993310945223918, "compression_ratio": 1.7682926829268293, "no_speech_prob": 0.0014547496102750301}, {"id": 357, "seek": 134724, "start": 1360.24, "end": 1365.08, "text": " or maybe the robot is on Mars or Pluto or who knows where or maybe it's too expensive.", "tokens": [51014, 420, 1310, 264, 7881, 307, 322, 9692, 420, 41205, 420, 567, 3255, 689, 420, 1310, 309, 311, 886, 5124, 13, 51256], "temperature": 0.0, "avg_logprob": -0.09993310945223918, "compression_ratio": 1.7682926829268293, "no_speech_prob": 0.0014547496102750301}, {"id": 358, "seek": 134724, "start": 1365.08, "end": 1368.1200000000001, "text": " So limping and getting, you know, that's interesting.", "tokens": [51256, 407, 2364, 3381, 293, 1242, 11, 291, 458, 11, 300, 311, 1880, 13, 51408], "temperature": 0.0, "avg_logprob": -0.09993310945223918, "compression_ratio": 1.7682926829268293, "no_speech_prob": 0.0014547496102750301}, {"id": 359, "seek": 134724, "start": 1368.4, "end": 1371.16, "text": " The other thing that you mentioned that's super interesting is", "tokens": [51422, 440, 661, 551, 300, 291, 2835, 300, 311, 1687, 1880, 307, 51560], "temperature": 0.0, "avg_logprob": -0.09993310945223918, "compression_ratio": 1.7682926829268293, "no_speech_prob": 0.0014547496102750301}, {"id": 360, "seek": 134724, "start": 1372.04, "end": 1374.6, "text": " we want AI to make our lives better", "tokens": [51604, 321, 528, 7318, 281, 652, 527, 2909, 1101, 51732], "temperature": 0.0, "avg_logprob": -0.09993310945223918, "compression_ratio": 1.7682926829268293, "no_speech_prob": 0.0014547496102750301}, {"id": 361, "seek": 137460, "start": 1374.8, "end": 1377.4399999999998, "text": " and we want robots to make our lives better.", "tokens": [50374, 293, 321, 528, 14733, 281, 652, 527, 2909, 1101, 13, 50506], "temperature": 0.0, "avg_logprob": -0.14523740579153746, "compression_ratio": 1.8565891472868217, "no_speech_prob": 0.0037063925992697477}, {"id": 362, "seek": 137460, "start": 1377.56, "end": 1382.1599999999999, "text": " But that doesn't mean that we want Amazon to know our deepest thoughts.", "tokens": [50512, 583, 300, 1177, 380, 914, 300, 321, 528, 6795, 281, 458, 527, 28288, 4598, 13, 50742], "temperature": 0.0, "avg_logprob": -0.14523740579153746, "compression_ratio": 1.8565891472868217, "no_speech_prob": 0.0037063925992697477}, {"id": 363, "seek": 137460, "start": 1382.28, "end": 1386.6799999999998, "text": " That doesn't mean that we want Google to know everything about our personal finances.", "tokens": [50748, 663, 1177, 380, 914, 300, 321, 528, 3329, 281, 458, 1203, 466, 527, 2973, 25123, 13, 50968], "temperature": 0.0, "avg_logprob": -0.14523740579153746, "compression_ratio": 1.8565891472868217, "no_speech_prob": 0.0037063925992697477}, {"id": 364, "seek": 137460, "start": 1387.04, "end": 1392.24, "text": " You know, if we can have AI that is personal, that, you know,", "tokens": [50986, 509, 458, 11, 498, 321, 393, 362, 7318, 300, 307, 2973, 11, 300, 11, 291, 458, 11, 51246], "temperature": 0.0, "avg_logprob": -0.14523740579153746, "compression_ratio": 1.8565891472868217, "no_speech_prob": 0.0037063925992697477}, {"id": 365, "seek": 137460, "start": 1392.24, "end": 1394.76, "text": " sure, it comes from somewhere and we've purchased it.", "tokens": [51246, 988, 11, 309, 1487, 490, 4079, 293, 321, 600, 14734, 309, 13, 51372], "temperature": 0.0, "avg_logprob": -0.14523740579153746, "compression_ratio": 1.8565891472868217, "no_speech_prob": 0.0037063925992697477}, {"id": 366, "seek": 137460, "start": 1394.76, "end": 1398.9599999999998, "text": " Or, you know, if you start to get into it, if you start to look at general AI,", "tokens": [51372, 1610, 11, 291, 458, 11, 498, 291, 722, 281, 483, 666, 309, 11, 498, 291, 722, 281, 574, 412, 2674, 7318, 11, 51582], "temperature": 0.0, "avg_logprob": -0.14523740579153746, "compression_ratio": 1.8565891472868217, "no_speech_prob": 0.0037063925992697477}, {"id": 367, "seek": 137460, "start": 1398.9599999999998, "end": 1401.0, "text": " you start thinking, do you purchase that?", "tokens": [51582, 291, 722, 1953, 11, 360, 291, 8110, 300, 30, 51684], "temperature": 0.0, "avg_logprob": -0.14523740579153746, "compression_ratio": 1.8565891472868217, "no_speech_prob": 0.0037063925992697477}, {"id": 368, "seek": 137460, "start": 1401.0, "end": 1402.1999999999998, "text": " Do you recruit that?", "tokens": [51684, 1144, 291, 15119, 300, 30, 51744], "temperature": 0.0, "avg_logprob": -0.14523740579153746, "compression_ratio": 1.8565891472868217, "no_speech_prob": 0.0037063925992697477}, {"id": 369, "seek": 137460, "start": 1402.1999999999998, "end": 1404.12, "text": " Do you adopt that?", "tokens": [51744, 1144, 291, 6878, 300, 30, 51840], "temperature": 0.0, "avg_logprob": -0.14523740579153746, "compression_ratio": 1.8565891472868217, "no_speech_prob": 0.0037063925992697477}, {"id": 370, "seek": 140412, "start": 1404.12, "end": 1407.76, "text": " Lots of questions there, but it's nice if you can get a system", "tokens": [50364, 15908, 295, 1651, 456, 11, 457, 309, 311, 1481, 498, 291, 393, 483, 257, 1185, 50546], "temperature": 0.0, "avg_logprob": -0.14904436334833368, "compression_ratio": 1.6115384615384616, "no_speech_prob": 0.0010159739758819342}, {"id": 371, "seek": 140412, "start": 1408.56, "end": 1413.28, "text": " that learns you, understands you and it stays in some sort of privacy corridor there.", "tokens": [50586, 300, 27152, 291, 11, 15146, 291, 293, 309, 10834, 294, 512, 1333, 295, 11427, 25602, 456, 13, 50822], "temperature": 0.0, "avg_logprob": -0.14904436334833368, "compression_ratio": 1.6115384615384616, "no_speech_prob": 0.0010159739758819342}, {"id": 372, "seek": 140412, "start": 1413.9599999999998, "end": 1416.28, "text": " Really, really interesting stuff.", "tokens": [50856, 4083, 11, 534, 1880, 1507, 13, 50972], "temperature": 0.0, "avg_logprob": -0.14904436334833368, "compression_ratio": 1.6115384615384616, "no_speech_prob": 0.0010159739758819342}, {"id": 373, "seek": 140412, "start": 1417.7199999999998, "end": 1421.6799999999998, "text": " How it's so hard to predict the future.", "tokens": [51044, 1012, 309, 311, 370, 1152, 281, 6069, 264, 2027, 13, 51242], "temperature": 0.0, "avg_logprob": -0.14904436334833368, "compression_ratio": 1.6115384615384616, "no_speech_prob": 0.0010159739758819342}, {"id": 374, "seek": 140412, "start": 1422.1599999999999, "end": 1424.36, "text": " You mentioned about speed.", "tokens": [51266, 509, 2835, 466, 3073, 13, 51376], "temperature": 0.0, "avg_logprob": -0.14904436334833368, "compression_ratio": 1.6115384615384616, "no_speech_prob": 0.0010159739758819342}, {"id": 375, "seek": 140412, "start": 1424.36, "end": 1425.6799999999998, "text": " That's always a moving target, right?", "tokens": [51376, 663, 311, 1009, 257, 2684, 3779, 11, 558, 30, 51442], "temperature": 0.0, "avg_logprob": -0.14904436334833368, "compression_ratio": 1.6115384615384616, "no_speech_prob": 0.0010159739758819342}, {"id": 376, "seek": 140412, "start": 1425.6799999999998, "end": 1428.3999999999999, "text": " You want a hundred X speed, but you see what speed is right now.", "tokens": [51442, 509, 528, 257, 3262, 1783, 3073, 11, 457, 291, 536, 437, 3073, 307, 558, 586, 13, 51578], "temperature": 0.0, "avg_logprob": -0.14904436334833368, "compression_ratio": 1.6115384615384616, "no_speech_prob": 0.0010159739758819342}, {"id": 377, "seek": 140412, "start": 1428.9199999999998, "end": 1432.7199999999998, "text": " In terms of adding speed right now, we seem to not be making chips", "tokens": [51604, 682, 2115, 295, 5127, 3073, 558, 586, 11, 321, 1643, 281, 406, 312, 1455, 11583, 51794], "temperature": 0.0, "avg_logprob": -0.14904436334833368, "compression_ratio": 1.6115384615384616, "no_speech_prob": 0.0010159739758819342}, {"id": 378, "seek": 143272, "start": 1432.72, "end": 1434.3600000000001, "text": " much faster per se.", "tokens": [50364, 709, 4663, 680, 369, 13, 50446], "temperature": 0.0, "avg_logprob": -0.12370650282183897, "compression_ratio": 1.6974789915966386, "no_speech_prob": 0.0006460798322223127}, {"id": 379, "seek": 143272, "start": 1434.3600000000001, "end": 1440.56, "text": " We're adding more chipsets on a die or we're we're creating chips", "tokens": [50446, 492, 434, 5127, 544, 11583, 1385, 322, 257, 978, 420, 321, 434, 321, 434, 4084, 11583, 50756], "temperature": 0.0, "avg_logprob": -0.12370650282183897, "compression_ratio": 1.6974789915966386, "no_speech_prob": 0.0006460798322223127}, {"id": 380, "seek": 143272, "start": 1440.56, "end": 1444.68, "text": " that are more optimized for this task or for that task or for energy efficiency", "tokens": [50756, 300, 366, 544, 26941, 337, 341, 5633, 420, 337, 300, 5633, 420, 337, 2281, 10493, 50962], "temperature": 0.0, "avg_logprob": -0.12370650282183897, "compression_ratio": 1.6974789915966386, "no_speech_prob": 0.0006460798322223127}, {"id": 381, "seek": 143272, "start": 1444.68, "end": 1448.88, "text": " or for whatever, and that's how we're making overall devices faster.", "tokens": [50962, 420, 337, 2035, 11, 293, 300, 311, 577, 321, 434, 1455, 4787, 5759, 4663, 13, 51172], "temperature": 0.0, "avg_logprob": -0.12370650282183897, "compression_ratio": 1.6974789915966386, "no_speech_prob": 0.0006460798322223127}, {"id": 382, "seek": 143272, "start": 1449.2, "end": 1452.48, "text": " So are you are you keeping that sort of moving target in mind", "tokens": [51188, 407, 366, 291, 366, 291, 5145, 300, 1333, 295, 2684, 3779, 294, 1575, 51352], "temperature": 0.0, "avg_logprob": -0.12370650282183897, "compression_ratio": 1.6974789915966386, "no_speech_prob": 0.0006460798322223127}, {"id": 383, "seek": 143272, "start": 1452.48, "end": 1456.24, "text": " as you look at the performance levels that you want to hit?", "tokens": [51352, 382, 291, 574, 412, 264, 3389, 4358, 300, 291, 528, 281, 2045, 30, 51540], "temperature": 0.0, "avg_logprob": -0.12370650282183897, "compression_ratio": 1.6974789915966386, "no_speech_prob": 0.0006460798322223127}, {"id": 384, "seek": 143272, "start": 1457.0, "end": 1460.64, "text": " So we believe we can achieve that one hundred X", "tokens": [51578, 407, 321, 1697, 321, 393, 4584, 300, 472, 3262, 1783, 51760], "temperature": 0.0, "avg_logprob": -0.12370650282183897, "compression_ratio": 1.6974789915966386, "no_speech_prob": 0.0006460798322223127}, {"id": 385, "seek": 146064, "start": 1460.68, "end": 1465.48, "text": " and proven speed and beyond because we're taking a different tack entirely", "tokens": [50366, 293, 12785, 3073, 293, 4399, 570, 321, 434, 1940, 257, 819, 9426, 7696, 50606], "temperature": 0.0, "avg_logprob": -0.1742256762934666, "compression_ratio": 1.6818181818181819, "no_speech_prob": 0.0179736390709877}, {"id": 386, "seek": 146064, "start": 1465.48, "end": 1468.76, "text": " because we're not on that roadmap of digital hardware", "tokens": [50606, 570, 321, 434, 406, 322, 300, 35738, 295, 4562, 8837, 50770], "temperature": 0.0, "avg_logprob": -0.1742256762934666, "compression_ratio": 1.6818181818181819, "no_speech_prob": 0.0179736390709877}, {"id": 387, "seek": 146064, "start": 1469.0800000000002, "end": 1473.24, "text": " that is very mature chips and they're eking out performance", "tokens": [50786, 300, 307, 588, 14442, 11583, 293, 436, 434, 308, 5092, 484, 3389, 50994], "temperature": 0.0, "avg_logprob": -0.1742256762934666, "compression_ratio": 1.6818181818181819, "no_speech_prob": 0.0179736390709877}, {"id": 388, "seek": 146064, "start": 1473.24, "end": 1477.68, "text": " from any number of, you know, kind of well trod playbooks.", "tokens": [50994, 490, 604, 1230, 295, 11, 291, 458, 11, 733, 295, 731, 4495, 67, 862, 15170, 13, 51216], "temperature": 0.0, "avg_logprob": -0.1742256762934666, "compression_ratio": 1.6818181818181819, "no_speech_prob": 0.0179736390709877}, {"id": 389, "seek": 146064, "start": 1478.3600000000001, "end": 1480.92, "text": " In the case of a fully analog neuromorphic chip,", "tokens": [51250, 682, 264, 1389, 295, 257, 4498, 16660, 12087, 32702, 299, 11409, 11, 51378], "temperature": 0.0, "avg_logprob": -0.1742256762934666, "compression_ratio": 1.6818181818181819, "no_speech_prob": 0.0179736390709877}, {"id": 390, "seek": 146064, "start": 1481.44, "end": 1484.5200000000002, "text": " you know, you have a neural network where you have analog neurons", "tokens": [51404, 291, 458, 11, 291, 362, 257, 18161, 3209, 689, 291, 362, 16660, 22027, 51558], "temperature": 0.0, "avg_logprob": -0.1742256762934666, "compression_ratio": 1.6818181818181819, "no_speech_prob": 0.0179736390709877}, {"id": 391, "seek": 146064, "start": 1484.5200000000002, "end": 1486.48, "text": " and synapses that are connected in sequence.", "tokens": [51558, 293, 5451, 2382, 279, 300, 366, 4582, 294, 8310, 13, 51656], "temperature": 0.0, "avg_logprob": -0.1742256762934666, "compression_ratio": 1.6818181818181819, "no_speech_prob": 0.0179736390709877}, {"id": 392, "seek": 148648, "start": 1486.96, "end": 1492.6, "text": " And, you know, you can compare this to to other analog mixed signal chips.", "tokens": [50388, 400, 11, 291, 458, 11, 291, 393, 6794, 341, 281, 281, 661, 16660, 7467, 6358, 11583, 13, 50670], "temperature": 0.0, "avg_logprob": -0.14928711677084164, "compression_ratio": 1.648, "no_speech_prob": 0.0016480545746162534}, {"id": 393, "seek": 148648, "start": 1492.6, "end": 1496.1200000000001, "text": " So people are starting to get a lot of speed improvements", "tokens": [50670, 407, 561, 366, 2891, 281, 483, 257, 688, 295, 3073, 13797, 50846], "temperature": 0.0, "avg_logprob": -0.14928711677084164, "compression_ratio": 1.648, "no_speech_prob": 0.0016480545746162534}, {"id": 394, "seek": 148648, "start": 1496.1200000000001, "end": 1499.44, "text": " by moving away from digital and doing, say, the synaptic operations", "tokens": [50846, 538, 2684, 1314, 490, 4562, 293, 884, 11, 584, 11, 264, 5451, 2796, 299, 7705, 51012], "temperature": 0.0, "avg_logprob": -0.14928711677084164, "compression_ratio": 1.648, "no_speech_prob": 0.0016480545746162534}, {"id": 395, "seek": 148648, "start": 1499.44, "end": 1502.96, "text": " either with photonic components or flash components.", "tokens": [51012, 2139, 365, 2409, 11630, 6677, 420, 7319, 6677, 13, 51188], "temperature": 0.0, "avg_logprob": -0.14928711677084164, "compression_ratio": 1.648, "no_speech_prob": 0.0016480545746162534}, {"id": 396, "seek": 148648, "start": 1503.56, "end": 1507.56, "text": " But in all of those cases, they still actually have to translate", "tokens": [51218, 583, 294, 439, 295, 729, 3331, 11, 436, 920, 767, 362, 281, 13799, 51418], "temperature": 0.0, "avg_logprob": -0.14928711677084164, "compression_ratio": 1.648, "no_speech_prob": 0.0016480545746162534}, {"id": 397, "seek": 148648, "start": 1507.56, "end": 1512.2, "text": " between their kind of physical, their either physics or optical", "tokens": [51418, 1296, 641, 733, 295, 4001, 11, 641, 2139, 10649, 420, 20674, 51650], "temperature": 0.0, "avg_logprob": -0.14928711677084164, "compression_ratio": 1.648, "no_speech_prob": 0.0016480545746162534}, {"id": 398, "seek": 148648, "start": 1512.2, "end": 1514.88, "text": " to digital for their neurons.", "tokens": [51650, 281, 4562, 337, 641, 22027, 13, 51784], "temperature": 0.0, "avg_logprob": -0.14928711677084164, "compression_ratio": 1.648, "no_speech_prob": 0.0016480545746162534}, {"id": 399, "seek": 151488, "start": 1514.92, "end": 1517.8000000000002, "text": " And so they have these analog synapses, digital neurons,", "tokens": [50366, 400, 370, 436, 362, 613, 16660, 5451, 2382, 279, 11, 4562, 22027, 11, 50510], "temperature": 0.0, "avg_logprob": -0.11532651810418992, "compression_ratio": 1.673728813559322, "no_speech_prob": 0.0040694172494113445}, {"id": 400, "seek": 151488, "start": 1517.8000000000002, "end": 1521.72, "text": " they kind of go back and forth and that requires clocking", "tokens": [50510, 436, 733, 295, 352, 646, 293, 5220, 293, 300, 7029, 7830, 278, 50706], "temperature": 0.0, "avg_logprob": -0.11532651810418992, "compression_ratio": 1.673728813559322, "no_speech_prob": 0.0040694172494113445}, {"id": 401, "seek": 151488, "start": 1521.72, "end": 1524.16, "text": " that requires slowing down the system.", "tokens": [50706, 300, 7029, 26958, 760, 264, 1185, 13, 50828], "temperature": 0.0, "avg_logprob": -0.11532651810418992, "compression_ratio": 1.673728813559322, "no_speech_prob": 0.0040694172494113445}, {"id": 402, "seek": 151488, "start": 1524.16, "end": 1527.72, "text": " So in a fully analog chip, when it when it's designed,", "tokens": [50828, 407, 294, 257, 4498, 16660, 11409, 11, 562, 309, 562, 309, 311, 4761, 11, 51006], "temperature": 0.0, "avg_logprob": -0.11532651810418992, "compression_ratio": 1.673728813559322, "no_speech_prob": 0.0040694172494113445}, {"id": 403, "seek": 151488, "start": 1527.8000000000002, "end": 1532.48, "text": " well, you can have input to output and have the signal flow", "tokens": [51010, 731, 11, 291, 393, 362, 4846, 281, 5598, 293, 362, 264, 6358, 3095, 51244], "temperature": 0.0, "avg_logprob": -0.11532651810418992, "compression_ratio": 1.673728813559322, "no_speech_prob": 0.0040694172494113445}, {"id": 404, "seek": 151488, "start": 1532.48, "end": 1535.2800000000002, "text": " at wire speed from end to end.", "tokens": [51244, 412, 6234, 3073, 490, 917, 281, 917, 13, 51384], "temperature": 0.0, "avg_logprob": -0.11532651810418992, "compression_ratio": 1.673728813559322, "no_speech_prob": 0.0040694172494113445}, {"id": 405, "seek": 151488, "start": 1535.7600000000002, "end": 1538.0, "text": " That is the full potential of an analog chip.", "tokens": [51408, 663, 307, 264, 1577, 3995, 295, 364, 16660, 11409, 13, 51520], "temperature": 0.0, "avg_logprob": -0.11532651810418992, "compression_ratio": 1.673728813559322, "no_speech_prob": 0.0040694172494113445}, {"id": 406, "seek": 151488, "start": 1538.0, "end": 1541.92, "text": " And that's why the speed here is so extraordinary", "tokens": [51520, 400, 300, 311, 983, 264, 3073, 510, 307, 370, 10581, 51716], "temperature": 0.0, "avg_logprob": -0.11532651810418992, "compression_ratio": 1.673728813559322, "no_speech_prob": 0.0040694172494113445}, {"id": 407, "seek": 154192, "start": 1542.52, "end": 1545.48, "text": " because we're no longer working in this digitally clocked world.", "tokens": [50394, 570, 321, 434, 572, 2854, 1364, 294, 341, 36938, 7830, 292, 1002, 13, 50542], "temperature": 0.0, "avg_logprob": -0.14548239160756596, "compression_ratio": 1.6452702702702702, "no_speech_prob": 0.0011511417105793953}, {"id": 408, "seek": 154192, "start": 1545.68, "end": 1548.48, "text": " But we're again, exploiting the physics of the system,", "tokens": [50552, 583, 321, 434, 797, 11, 12382, 1748, 264, 10649, 295, 264, 1185, 11, 50692], "temperature": 0.0, "avg_logprob": -0.14548239160756596, "compression_ratio": 1.6452702702702702, "no_speech_prob": 0.0011511417105793953}, {"id": 409, "seek": 154192, "start": 1548.48, "end": 1550.76, "text": " the physical nature of the system to do that math for us.", "tokens": [50692, 264, 4001, 3687, 295, 264, 1185, 281, 360, 300, 5221, 337, 505, 13, 50806], "temperature": 0.0, "avg_logprob": -0.14548239160756596, "compression_ratio": 1.6452702702702702, "no_speech_prob": 0.0011511417105793953}, {"id": 410, "seek": 154192, "start": 1551.1200000000001, "end": 1555.3200000000002, "text": " And you can perform inference as just a wave of electricity from input out.", "tokens": [50824, 400, 291, 393, 2042, 38253, 382, 445, 257, 5772, 295, 10356, 490, 4846, 484, 13, 51034], "temperature": 0.0, "avg_logprob": -0.14548239160756596, "compression_ratio": 1.6452702702702702, "no_speech_prob": 0.0011511417105793953}, {"id": 411, "seek": 154192, "start": 1556.8000000000002, "end": 1557.96, "text": " Amazing.", "tokens": [51108, 14165, 13, 51166], "temperature": 0.0, "avg_logprob": -0.14548239160756596, "compression_ratio": 1.6452702702702702, "no_speech_prob": 0.0011511417105793953}, {"id": 412, "seek": 154192, "start": 1557.96, "end": 1561.04, "text": " I know that Tesla, for instance, is doing", "tokens": [51166, 286, 458, 300, 13666, 11, 337, 5197, 11, 307, 884, 51320], "temperature": 0.0, "avg_logprob": -0.14548239160756596, "compression_ratio": 1.6452702702702702, "no_speech_prob": 0.0011511417105793953}, {"id": 413, "seek": 154192, "start": 1561.6000000000001, "end": 1565.5600000000002, "text": " we can debate whether the term full is is an appropriate modifier there,", "tokens": [51348, 321, 393, 7958, 1968, 264, 1433, 1577, 307, 307, 364, 6854, 38011, 456, 11, 51546], "temperature": 0.0, "avg_logprob": -0.14548239160756596, "compression_ratio": 1.6452702702702702, "no_speech_prob": 0.0011511417105793953}, {"id": 414, "seek": 154192, "start": 1565.5600000000002, "end": 1568.3200000000002, "text": " but full self driving on atom chips, right?", "tokens": [51546, 457, 1577, 2698, 4840, 322, 12018, 11583, 11, 558, 30, 51684], "temperature": 0.0, "avg_logprob": -0.14548239160756596, "compression_ratio": 1.6452702702702702, "no_speech_prob": 0.0011511417105793953}, {"id": 415, "seek": 154192, "start": 1568.6000000000001, "end": 1571.16, "text": " Not saying that all the training and learning is happening there,", "tokens": [51698, 1726, 1566, 300, 439, 264, 3097, 293, 2539, 307, 2737, 456, 11, 51826], "temperature": 0.0, "avg_logprob": -0.14548239160756596, "compression_ratio": 1.6452702702702702, "no_speech_prob": 0.0011511417105793953}, {"id": 416, "seek": 157116, "start": 1571.16, "end": 1574.16, "text": " but that's what's actively involved in the vehicle.", "tokens": [50364, 457, 300, 311, 437, 311, 13022, 3288, 294, 264, 5864, 13, 50514], "temperature": 0.0, "avg_logprob": -0.17320395624914833, "compression_ratio": 1.5023923444976077, "no_speech_prob": 0.0005881499964743853}, {"id": 417, "seek": 157116, "start": 1574.4, "end": 1578.64, "text": " So just imagining what this could do for self driving,", "tokens": [50526, 407, 445, 27798, 437, 341, 727, 360, 337, 2698, 4840, 11, 50738], "temperature": 0.0, "avg_logprob": -0.17320395624914833, "compression_ratio": 1.5023923444976077, "no_speech_prob": 0.0005881499964743853}, {"id": 418, "seek": 157116, "start": 1578.64, "end": 1581.5600000000002, "text": " for automated machinery, for robotics, for AI.", "tokens": [50738, 337, 18473, 27302, 11, 337, 34145, 11, 337, 7318, 13, 50884], "temperature": 0.0, "avg_logprob": -0.17320395624914833, "compression_ratio": 1.5023923444976077, "no_speech_prob": 0.0005881499964743853}, {"id": 419, "seek": 157116, "start": 1582.0, "end": 1583.4, "text": " It's kind of mind blowing.", "tokens": [50906, 467, 311, 733, 295, 1575, 15068, 13, 50976], "temperature": 0.0, "avg_logprob": -0.17320395624914833, "compression_ratio": 1.5023923444976077, "no_speech_prob": 0.0005881499964743853}, {"id": 420, "seek": 157116, "start": 1583.4, "end": 1585.3600000000001, "text": " Gordon, thank you for spending this time with us.", "tokens": [50976, 19369, 11, 1309, 291, 337, 6434, 341, 565, 365, 505, 13, 51074], "temperature": 0.0, "avg_logprob": -0.17320395624914833, "compression_ratio": 1.5023923444976077, "no_speech_prob": 0.0005881499964743853}, {"id": 421, "seek": 157116, "start": 1585.3600000000001, "end": 1587.3200000000002, "text": " I really do appreciate it.", "tokens": [51074, 286, 534, 360, 4449, 309, 13, 51172], "temperature": 0.0, "avg_logprob": -0.17320395624914833, "compression_ratio": 1.5023923444976077, "no_speech_prob": 0.0005881499964743853}, {"id": 422, "seek": 157116, "start": 1587.3200000000002, "end": 1590.3200000000002, "text": " Thank you so much for the time, John. It was a pleasure.", "tokens": [51172, 1044, 291, 370, 709, 337, 264, 565, 11, 2619, 13, 467, 390, 257, 6834, 13, 51322], "temperature": 0.0, "avg_logprob": -0.17320395624914833, "compression_ratio": 1.5023923444976077, "no_speech_prob": 0.0005881499964743853}], "language": "en"}