{"text": " Why is AI going to destroy us? Chat GPT seems pretty nice. I use it every day. What's the big fear here? Make the case. We don't understand the things that we build. The AIs are grown more than built, you might say. They end up as giant, inscrutable matrices of floating point numbers that nobody can decode. At this rate, we end up with something that is smarter than us, smarter than humanity, that we don't understand, whose preferences we could not shape. And by default, if that happens, if you have something around that is much smarter than you and does not care about you one way or the other, you probably end up dead at the end of that. Extinction is a pretty extreme outcome that I don't think is particularly likely, but the possibility that these machines will cause mayhem because we don't know how to enforce that they do what we want them to do. I think that's a real thing to worry about. Welcome to another episode of Conversations with Coleman. Today's episode is a roundtable discussion about AI safety with Eliezer Yudkowski, Gary Marcus, and Scott Aronson. Eliezer Yudkowski is a prominent AI researcher and writer known for co-founding the Machine Intelligence Research Institute, where he spearheaded research on AI safety. He's also widely recognized for his influential writings on the topic of rationality. Scott Aronson is a theoretical computer scientist and author, celebrated for his pioneering work in the field of quantum computation. He's also the chair of COMSI at U of T Austin, but is currently taking a leave of absence to work at open AI. Gary Marcus is a cognitive scientist, author, and entrepreneur known for his work at the intersection of psychology, linguistics, and AI. He's also authored several books, including Cluj and Rebooting AI, Building AI We Can Trust. This episode is all about AI safety. We talk about the alignment problem. We talk about the possibility of human extinction due to AI. We talk about what intelligence actually is. We talk about the notion of a singularity or an AI takeoff event, and much more. It was really great to get these three guys in the same virtual room, and I think you'll find that this conversation brings something a bit fresh to a topic that has admittedly been beaten to death on certain corners of the internet. Without further ado, Eleazar Yudkowski, Gary Marcus, and Scott Aronson. Okay, Eleazar Yudkowski, Scott Aronson, Gary Marcus. Thanks so much for coming on my show. Thank you. The topic of today's conversation is AI safety, and this is something that's been in the news lately. We've seen experts and CEOs signing letters, recommending public policy, surrounding regulation. We continue to have the debate between people that really fear AI is going to end the world and potentially kill all of humanity and the people who feel that those fears are overblown. And so this is going to be sort of a roundtable conversation about that, and you three are really three of the best people in the world to talk about it with. So thank you all for doing this. Let's just start out with you, Eleazar, because you've been one of the most really influential voices getting people to take seriously the possibility that AI will kill us all. You know, why is AI going to destroy us? Chat GPT seems pretty nice. I use it every day. What's the big fear here? Make the case. Well, chat GPT seems quite unlikely to kill everyone in its present state. AI capabilities keep on advancing and advancing. The question is not, can a chat GPT kill us? The answer is probably no. So as long as that's true, as long as it hasn't killed us yet, the engineers are just going to keep pushing the capabilities. There's no obvious blocking point. We don't understand the things that we build. The AIs are grown more than built, you might say. They end up as giant inscrutable matrices of floating point numbers that nobody can decode. It's probably going to end up technically difficult to make them want particular things and not others. People are just charging straight ahead. So at this rate, we end up with something that is smarter than us, smarter than humanity, that we don't understand, whose preferences we could not shape. And by default, if that happens, if you have something around that is much smarter than you and does not care about you one way or the other, you probably end up dead at the end of that. The way it gets the most of whatever strange inscrutable things that it wants are worlds in which there are not humans taking up space, using up resources, building other AIs to compete with it, or just a world in which you built enough power plants that the surface of the earth got hot enough that humans didn't survive. Gary, what do you have to say about that? There are parts that I agree with and parts that I don't. So I agree that we are likely to wind up with AIs that are smarter than us. I don't think we're particularly close now, but in 10 years or 50 years or 100 years at some point, maybe a thousand years, but it will happen. I think there's a lot of anthropomorphization there about machines wanting things. Of course, they have objective functions and we can talk about that. I think it's a presumption to say that the default is that they're going to want something that leads to our demise and that they're going to be effective at that and be able to literally kill us all. I think if you look at the history of AI at least so far, they don't really have wants beyond what we program them to do. There is an alignment problem. I think that that's real in the sense of people who program a system to do X and they do X prime. That's kind of like X, but not exactly. I think there's really things to worry about. I think there's a real research program here that is under-researched, which is the way I would put it is we want to understand how to make machines that have values. Asimov's laws are way too simple, but they're kind of starting point for conversation. We want to program machines that don't harm humans. They can calculate the consequences of their actions. Right now, we have technology like GPT-4 that has no idea what the consequences of its actions are. It doesn't really anticipate things. There's a separate thing that Eliezer didn't emphasize, which is it's not just how smart the machines are, but how much power we give them. How much we empower them to do things like access the internet or manipulate people or write source code, access files and stuff like that. Right now, auto-GPT can do all of those things and that's actually pretty disconcerting to me. To me, that doesn't all add up to any kind of extinction risk anytime soon, but catastrophic risk where things go pretty wrong because we wanted these systems to do X and we didn't really specify it well. They don't really understand our intentions. I think there are risks like that. I don't see it as a default that we wind up with extinction. I think it's pretty hard to actually terminate the entire human species. You're going to have people in Antarctica that are going to be out of harm's way or whatever, or you're going to have some people who respond differently to any pathogen, et cetera. Extinction is a pretty extreme outcome that I don't think is particularly likely, but the possibility that these machines will cause mayhem because we don't know how to enforce that they do what we want them to do. I think that's a real thing to worry about and it's certainly worth doing research on. Scott, how do you view this? Yeah, so I'm sure that you can get the three of us arguing about something, but I think you're going to get agreement from all three of us that AI safety is important and that catastrophic outcomes, whether or not that means literal human extinction are possible. I think it's become apparent over the last few years that this century is going to be largely defined by our interaction with AI, that AI is going to be transformative for human civilization. I'm confident of that much. If you ask me almost anything beyond that about how is it going to transform civilization? Will it be good? Will it be bad? What will the AI want? I am pretty agnostic just because if you would ask me 20 years ago to try to forecast where we are now, I would have gotten a lot wrong. My only defense is I think that all of us here and almost everyone in the world would have gotten a lot wrong about where we are now. If I try to envision where we are in 2043, does the AI want to replace humanity with something better? Does it want to keep us around as pets? Does it want to just continue helping us out like just a super souped up version of chat GPT? I think all of those scenarios merit consideration, but I think that what has happened in the last few years that's really exciting is that AI safety has become an empirical subject. There are these very powerful AIs that are now being deployed and we can actually learn something. We can work on mitigating the nearer-term harms, not because the existential risk doesn't exist or is absurd or is science fiction or anything like that, but just because the nearer-term harms are the ones that we can see right in front of us and where we can actually get feedback from the external world about how we're doing. We can learn something and hopefully some of the knowledge that we gain will be useful in addressing the longer-term risks that I think Eliezer is very rightly worried about. Seems to me there's alignment and then there's alignment. There's alignment in the sense that we haven't even fully aligned smartphone technology with our interests. There are some ways in which smartphones and social media have led to probably deleterious mental health outcomes, especially for teenage girls, for example. There are those kinds of mundane senses of alignment where it's like, is this technology doing more good than harm in the normal everyday public policy sense? Then there's the capital A alignment of, are we creating a creature that is going to view us like ants and have no problem extinguishing us and whether intentional or not? It seems to me all of you agree that the first sense of alignment is at the very least something to worry about now and something to deal with, but I'm curious to what extent you think the really capital A sense of alignment is a real problem because it can sound very much like science fiction to people. Maybe let's start with Eliezer. From my perspective, I would say that if we had a solid guarantee that AI was going to do no more harm than social media, we ought to plow ahead and get all the gains. It's not enough harm to back this amount of harm that social media has done to humanity, while very significant in my view. I think it's done a lot of damage to our sanity, but that's just not a large enough harm to justify either foregoing the gains that you could get from AI if that was going to be the worst downside or to justify the kind of drastic measures you'd need to stop plowing ahead on AI. I think that the capital A alignment is beyond this generation. I've started the field, I've watched over it for two decades. I feel like in some ways the modern generation plowing in with their eyes on the short term stuff is like losing track of the larger problems because they can't solve the larger problems and they can't solve the little problems, but we're just like plowing straight into the big problems and we're going to go plow right into the big problems with a bunch of little solutions that aren't going to scale. I think it's lethal. I think it's at the scale where you just back off and don't do this. By back off and don't do this, what do you mean? I mean have an international treaty about where the chips capable of doing AI training go and have them all going into licensed monitored data centers and not have the training runs for AIs more powerful than GPT-4, possibly even lowering that threshold over time as algorithms improve and it gets possible to train more powerful AIs using less computing. So you're picturing a kind of international agreement to just stop? International moratorium. And if North Korea steals the GPU shipment, then you've got to be ready to destroy their data center that they build by conventional means. And if you don't have that willingness in advance, then countries may refuse to sign up for the agreement being like, why aren't we just seeding the advantage to someone else then? It actually has to be a worldwide shutdown because the scale of harm from a superintelligence, it's not that if you have 10 times as many superintelligence as you've got, 10 times as much harm. It's not that a superintelligence only wrecks the country that built the superintelligence. Any superintelligence everywhere is anyone's last problem. So Gary and Scott, if either of you want to jump in there, is AI safety a matter of forestalling the end of the world and all of these smaller issues and pass towards safety that Scott, you mentioned, are just throwing, I don't know what the analogy is, but pointless essentially. What do you guys make of this? I mean, the journey of 1,000 miles begins with a step. Most of the way I think about this comes from 25 years of doing computer science research, including quantum computing and computational complexity, things like that, where we have these gigantic aspirational problems that we don't know how to solve. And yet, year after year, we do make progress. We pick off little sub-problems. And if we can't solve those, then we find sub-problems of those. And we keep repeating until we find something that we can solve. And this is, I think, for centuries, the way that science has made progress. Now, it is possible that this time, we just don't have enough time for that to work. And I think that is what Eliezer is fearful of, that we just don't have enough time for the ordinary scientific process to work before AI becomes too powerful, in which case you start talking about things like a global moratorium enforced with the threat of war. I am not ready to go there. I could imagine circumstances where maybe I say, gosh, this looks like such an imminent threat that we have to. But I tend to be very, very worried in general about causing a catastrophe in the course of trying to prevent a catastrophe. And I think when you are talking about threatening airstrikes against data centers or things like that, then that is an obvious worry. So I am somewhat in between here. I am with Scott that we are not at the point where we should be bombing data centers. I don't think we are close to that. I am much less aware of what the right word is to use here. I don't think we are anywhere near as close to AGI as I think Eliezer sometimes sounds like. I don't think GPT-5 is anything like AGI. And I am not particularly concerned about who gets it first and so forth. On the other hand, I think that we are in a sort of dress rehearsal mode. Nobody expected GPT-4, really chat GPT, to percolate as fast as it did. And it is a reminder that there is a social side to all of this, how software gets distributed matters, and there is a corporate side. It was a kind of galvanizing moment for me when Microsoft didn't pull Sydney, even though Sydney did some awfully strange things. I thought they would take it for a while and it is a reminder that they can make whatever decisions they want. So you kind of multiply that by Eliezer's concerns about what do we do and at what point. What would be enough to cause problems is a reminder, I think, that we need, for example, to start roughing out these international treaties now, because there could become a moment where there is a problem. I don't think the problem that Eliezer sees is here now, but maybe it will be. And maybe when it does come, we will have so many people pursuing commercial self-interest and so little infrastructure in place we won't be able to do anything. So I think it really is important to think now, if we reach such a point, what are we going to do? What do we need to build in place before we get to that point? So we've been talking about this concept of artificial general intelligence. And I think it's worth asking whether that is a useful coherent concept. So for example, if I were to think by analogy to athleticism and think of the moment when we build a machine that has, say, artificial general athleticism, meaning it's better than LeBron James at basketball, but also better at curling than the world's best curling player and also better at soccer and also better at archery and so forth, it would seem to me that there's something a bit strange as framing it as having reached a point on a single continuum. It seems to me you would sort of have to build each capability, each sport individually and then somehow figure how to package them all into one robot without each skill set detracting from the other. Is that a disanalogy? Do you all picture this intelligence as sort of one dimension, one knob that is going to get turned up along a single axis? Or do you think that way of talking about it is misleading in the same way that I kind of just sketched out? Yeah, I would absolutely not accept that. I like to say that intelligence is not a one-dimensional variable. There's many different aspects to intelligence and there's not, I think, going to be a magical moment when we reach the singularity or something like that. I would say that the core of artificial general intelligence is the ability to flexibly deal with new problems that you haven't seen before. And the current systems can do that a little bit, but not very well. My typical example of this now is GPT-4 is exposed to the game of chess, sees the lots of games of chess that sees the rules of chess, but it never actually figures out the rules of chess and makes illegal moves and so forth. So it's in no way a general intelligence that can just pick up new things. Of course, we have things like AlphaGo that can play a certain set of games, AlphaZero really, but we don't have anything that has the generality of human intelligence. But human intelligence is just one example of general intelligence. You could argue that chimpanzees or crows have another variety of general intelligence. I would say the current machines don't really have it, but they will eventually. I mean, I think a priori, it could have been that you would have math ability, you would have verbal ability, you'd have ability to understand humor, and they'd all be just completely unrelated to each other. That is possible. And in fact, already with GPT, you can say that in some ways, it already is a super intelligence. It knows vastly more, can converse on a vastly greater range of subjects than any human can. And in other ways, it seems to fall short of what humans know or can do. But you also see this sort of generality, just empirically. I mean, GPT was sort of trained on all the text on the internet, let's say most of the text on the open internet. So it was just one method. It was not explicitly designed to write code, and yet it can write code. And at the same time as that ability emerged, you also saw the ability to solve word problems like high school level math. You saw the ability to write poetry. This all came out of the same system without any of it being explicitly optimized for. I feel like I need to interject one important thing, which is it can do all these things, but none of them all that reliably. Well, okay. Nevertheless, compared to, let's say, what my expectations would have been, if you'd asked me 10 or 20 years ago, I think that the level of generality is pretty remarkable. And it does lend support to the idea that there is some sort of general quality of understanding there, where you could say, for example, that GPT-4 has more of it than GPT-3, which in turn has more than GPT-2. And I would say that it does seem to me like it's presently pretty unambiguous that GPT-4 is in some sense dumber than an adult or even teenage human. I mean, to take the example I just gave you a minute ago, it never learns to play chess, even with a huge amount of data. So it will play a little bit of chess, it will memorize the openings and be okay for the first 15 moves, but it gets far enough away from what it's trained on and it falls apart. This is characteristic of these systems. It's not really characteristic in the same way of adults or even teenage humans. Almost anything that it does, it does unreliably. And give another example, you can ask a human to write a biography of someone and don't make stuff up, and you really can't ask GPT to do that. Yeah, like it's a bit difficult because you could always be cherry picking something that humans aren't usually good at. But to me, it does seem like there's this broad range of problems that don't seem especially to play to humans' strong points or machine weak points, where GPT-4 will do no better than a seven-year-old on those problems. I do feel like these examples are cherry picked because if I just take a different, very typical example, I'm writing an op-ed for the New York Times, say, about any given subject in the world, and my choice is to have a smart 14-year-old next to me with anything that's in his mind already or GPT. There's no comparison. So which of these sort of examples is the litmus test for who is more intelligent? If you did it on a topic where it couldn't rely on memorized text, you might actually change your mind on that. So the thing about writing a Times op-ed is most of the things that you propose to it, there's actually something that it can pastiche together from its dataset. That doesn't mean that it really understands what's going on. It doesn't mean that that's general capability. Also, as the human, you're doing all the hard parts. Obviously, a human is going to prefer, if a human has a math problem, we're going to rather use a calculator than another human. Similarly, with the New York Times op-ed, you're doing all the parts that are hard for GPT-4, and then you're asking GPT-4 to just do some of the parts that are hard for you. You're always going to prefer an AI partner rather than a human partner within that range of the human can do all the human stuff, and you want an AI to do whatever the AI is good at at the moment. An analogy that's maybe a little bit helpful here is driverless cars. It turns out that on highways and ordinary traffic, they're probably better than people, and on unusual circumstances, they're really worse than people. A Tesla not too long ago ran into a jet, and a human wouldn't do that, like slow speed being summoned across a parking lot. A human would never do that. There are different strengths and weaknesses. The strengths of a lot of the current kinds of technology is that they can either pastiche together or make not literal analogies when we go into the details, but to stored examples, and they tend to be poor when you get to outlier cases. That's persistent across most of the technologies that we use right now. If you stick to stuff in which there's a lot of data, you'll be happy with the results you get from these systems. You move far enough away, not so much. What we're going to see over time is that the length of the debate about whether or not it's still dumber than you gets longer and longer and longer. Then if things are allowed to just keep running and nobody dies, then at some point it switches over to a very long debate about is it smarter than you, which then gets shorter and shorter and shorter, and eventually reaches a point where it's pretty unambiguous if you're paying attention. Now, I suspect that this process gets interrupted by everybody dying. In particular, there's a question of the point at which it becomes better than humanity at building the next edition of the AI system and how fast do things snowball once you get to that point? Possibly, you do not have time for further public debates or even a two-hour Twitter space, depending on how that goes. Some of the limitations of GPT are completely understandable, just from a little knowledge of how it works. It does not have an internal memory per se other than what appears on the screen in front of you. This is why it's turned out to be so effective to explicitly tell it. Let's think step by step when it's solving a math problem, for example. You have to tell it to show all of its work because it doesn't have an internal memory with which to do that. Likewise, when people complain about it, hallucinating references that don't exist, well, the truth is when someone asks me for a citation, if I'm not allowed to use Google, I might have a vague recollection of some of the authors, and I'll probably do a very similar thing to what GPT does. I'll hallucinate. There's a great phrase I learned the other day, which is frequently wrong, never in doubt. That's true. I'm not going to make up a reference with full detail, page numbers, titles, so forth. I might say, look, I don't remember 2012 or something like that. Whereas, GPT-4, what it's going to say is 2017, Aaronson and Yodkowski, New York Times, pages 13 to 17. No, it does need to get much, much better at knowing what it doesn't know. And yet, already, I've seen a noticeable improvement there, going from GPT-3 to GPT-4. For example, if you ask GPT-3, prove that there are only finitely many prime numbers, it will give you a proof, even though the statement is false. And it will have an error, which is similar to the errors on 1,000 exams that I've graded, just trying to get something past you, hoping that you won't notice. Hey, if you ask GPT-4, prove that there are only finitely many prime numbers, it says, no, that's a trick question. Actually, there are infinitely many primes. And here's why. Yeah. Part of the problem with doing the science here is that I think you would know better since you work part-time or whatever to open AI. But my sense is that a lot of the examples that get posted on Twitter, particularly by the likes of me and other critics or other skeptics, I should say, is the system gets trained on those. So almost everything that people write about it, I think, is in the training set. So it's hard to do the science when the system's constantly being trained, especially in the RLHF side of things. And we don't actually know what's in GPT-4. So we don't even know if they're regular expressions and simple rules, match things. So we can't do the kind of science we used to be able to do. This conversation, this subtree of the conversation, I think, has no natural endpoint. So if I can sort of zoom out a bit, I think there's a pretty solid sense in which humans are more generally intelligent than chimpanzees. As you get closer and closer to the human level, I would say that the direction here is still clear, that the comparison is still clear. We are still smarter than GPT-4. This is not going to take control of the world from us. But the conversations get longer. The definitions start to break down around the edges. But I think it also, as you keep going, it comes back together again. There's a point, and possibly this point is very close to the point of time to where everybody dies. So maybe we don't ever see it in a podcast, but there's a point where it's unambiguously smarter than you. And including the spark of creativity, being able to deduce things quickly rather than with tons and tons of extra evidence, strategy, cunning, modeling people, figuring out how to manipulate people. So let's stipulate, Aliezer, that we're going to get to machines that can do all of that. And then the question is, what are they going to do? Is it a certainty that they will make our annihilation part of their business? Is it a possibility? Is it an unlikely possibility? I think your view is that it's a certainty. I've never really understood that part. It's a certainty on the present tech, is the way I would put it. If that happened, so in particular, if that happened tomorrow, then Modulo, Cromwell's rule, never say certain. My probability is, yes, Modulo, the chance that my model is somehow just completely mistaken. If we got 50 years to work it out and unlimited retries, I think that'd be pretty okay. I think we'd make it. The problem is that it's a lot harder to do science when your first wrong try destroys the human species and then you don't get to try again. I mean, I think there's something, again, that I agree with and something I'm a little bit skeptical about. So I agree that the amount of time we have matters. I would also agree that there's no existing technology that solves the alignment problem that gives a moral basis to these machines. GPT-4 is fundamentally amoral. I don't think it's immoral. It's not out to get us, but it really is amoral. It can answer trolley problems because there are trolley problems in the dataset, but that doesn't mean that it really has a moral understanding of the world. If we get to a very smart machine that by all the criteria that we've talked about and it's amoral, then that's a problem for us. There's a question of whether if we can get to smart machines, whether we can build them in a way that will have some moral basis. I think we need to make progress. The first try part, I'm not willing to let pass. I understand, I think, your argument there, and maybe you should spell it out. I think that we probably get more than one shot and that it's not as dramatic and instantaneous as you think. I do think one wants to think about sandboxing, one wants to think about distribution, but let's say we had one evil super genius now who is smarter than everybody else, like so what? One super- Much smarter. Say again? Not just a little smarter. Oh, even a lot smarter. Most super geniuses aren't actually that effective. They're not that focused. They were focused on other things. You're assuming that the first super genius AI is going to make it its business to annihilate us and that's the part where I still am a bit stuck in the argument. Yeah, some of this has to do with the notion that if you do a bunch of training, you start to get goal direction, even if you don't explicitly train on that. That goal direction is a natural way to achieve higher capabilities. The reason why humans want things is that wanting things is an effective way of getting things and so natural selection in the process of selecting exclusively on reproductive fitness just on that one thing got us to want a bunch of things that correlated with reproductive fitness in the ancestral distribution because wanting, having intelligences, that want things is a good way of getting things. In a sense, wanting comes from the same place as intelligence itself and you could even from a certain technical standpoint on expected utility say that intelligence is a very effective way of wanting, planning, plotting past through time that leads to particular outcomes. Part of it is that I do not think you get the brooding super intelligence that wants nothing because I don't think that wanting an intelligence can be internally pried apart that easily. I think that the way you get super intelligences is that there are things that have gotten good at organizing their own thoughts and have good taste in which thoughts to think and that is where the high capabilities come from. Can I put a point to you? Let me just put the following point to you, which I think in my mind is similar to what Gary was saying. There's often in philosophy this notion of the continuum fallacy, which in the canonical example is like you can't locate a single hair that you would pluck from my head where I would suddenly go from not bald to bald or even more intuitive examples like a color wheel. On a gray scale there's no single pixel you can point to and say well that's where gray begins and white ends and yet we have this conceptual distinction that feels hard and fast between gray and white and gray and black and so forth. When we're talking about artificial general intelligence or super intelligence you seem to operate on a model where either it's a super intelligence capable of destroying all of us or it's not. Whereas intelligence may just be a continuum fallacy style spectrum where we're first going to see the shades of something that's just a bit more intelligent than us and maybe it can kill five people at most and then it can and when that happens we're going to want to intervene and we're going to figure out how to intervene at that level and so on and so forth. Yeah so if it's stupid enough to do it then yes. Let me by the identical logic there should be nobody who steals money on a really large scale right because you could just give them five dollars and see if they steal that and if they don't steal that you know you're good to trust them with a billion. I mean I think that in actuality anyone who did steal a billion dollars probably displayed some dishonest behavior earlier in their life that was you know unconditionally not not acted upon early enough. I'm actually not even. Hold on hold on the analogy out pictures like we have the first case of fraud that's $10,000 and then we build systems to prevent it but then they fail with a somewhat smarter opponent but our systems get better and better and better and so we actually prevent the billion-dollar fraud because of the systems put in place that in response to the $10,000 frauds you know. I mean I think Coleman's putting his finger on an important point here which is how much do we get to iterate and Eliezer is saying the minute we have a super intelligent system we won't be able to iterate because it's all over immediately. There isn't a minute like that. The way that the continuum goes to the threshold is that you eventually get something that's smart enough that it knows not to play its hand early and then if that thing you know if you are still cranking up the power on that and preserving its utility function it knows it just has to wait to be smarter to be able to win. It doesn't play its hand prematurely it doesn't tip you off it's not in its interest to do that. It's in its interest to cooperate until it thinks it can win against humanity and only then make its move. If it doesn't expect the future smarter AIs to be smarter than itself then we might perhaps see these early AIs telling humanity don't build the later AIs and I would be sort of surprised and amused if we ended up in that particular sort of like science fiction scenario as I see it but we're already in like something that you know me from 10 years ago would have called the science fiction scenario which is the things that I'll talk to you without being very smart. I always come up Eliezer against this idea that you're assuming that the very bright machines the super intelligent machines will be malicious and duplicitous and so forth and I just don't see that as a logical entailment of being very smart. I mean they don't specifically want as an end in itself for you to be destroyed they're just doing whatever obtains the most of the stuff that they actually want which doesn't specifically have a term that's maximized by humanity surviving and doing well. Why can't you just hard code you know don't do anything that will annihilate the human species don't do anything. We don't know how we don't know how there is no technology to hard code such as. So there I agree with you but I think it's important if I can just run for one second. I agree that right now we don't have the technology to hard code don't do harm to humans but for me it's all boils down to a question of are we going to get to the smart machines before we make progress on that hard coding problem or not and that to me that means that problem of hard coding ethical values is actually one of the most important projects that we should be working on. Yeah and I tried to work on it 20 years in advance and capabilities are just like running vastly ahead of alignment. When I started working on this 20 years you know like two decades ago we were in a sense ahead of where we are now. AlphaGo is much more controllable than GPT-4. So there I agree with you we've fallen in love with the technology that is fairly poorly controlled. AlphaGo is very easily controlled and very well specified. We know what it does. We can more or less interpret why it's doing it and everybody's in love with these large language models and they're much less controlled and you're right we haven't made a lot of progress on alignment. So if we just go on a straight line everybody dies. I think that's this is an important fact. I would almost even accept that for argument but ask then just for the sake of argument but then ask do we have to be on a straight line? I mean I would agree to the weaker claim that you know we should certainly be extremely worried about the intentions of a superintelligence in the same way that say chimpanzees should be worried about the intentions of you know the first humans that arise right and in fact you know chimpanzees you know continue to exist in our world only at humans' pleasure. But I think that there are a lot of other considerations here for example if we imagined you know that GPT-10 is you know the first unaligned superintelligence that has these sorts of goals well then you know it would be appearing in a world where presumably GPT-9 you know already has very wide diffusion and where people can use that to try to you know and GPT-9 is not destroying the world you know by assumption. Why does GPT-9 work with the humans instead of with GPT-10? Well I don't know I mean I mean I mean I mean maybe maybe maybe it does work with GPT-10 but you know I just don't view that as a certainty you know I mean I think you know you're certainty about this is the one place where I really get off the train. Same with me. I well I mean I'm not asking you to share my certainty I am asking the viewers to believe that you might end up with like more extreme probabilities after after you stare things for an additional couple of decades that doesn't mean you have to accept my probabilities immediately but I'm at least ask you to like not treat that as some kind of weird anomaly you know I mean you're just going to find those kinds of situations in these debates. My view is that I don't find the extreme probabilities that you described to be plausible but I find the question that you're raising to be important I think you know maybe straight line is too extreme but this idea that if you just follow current trends we're getting more sorry we're getting less and less controllable machines and not getting more alignment. Machines that are more unpredictable harder to interpret and no better at sticking to even a basic principle like be honest and don't make stuff up. In fact that's a problem that other technologies don't really have. Routing systems GPS systems don't make stuff up. Google search doesn't make stuff up it will point to things that other people have made stuff up but it doesn't itself do it so in that sense like the trend line is not great. I agree with that and I agree that we should be really worried about that and we should put effort into it even if I don't agree you know with the probabilities that you attach to it. I mean let me interject with the question here. Go ahead Scott go ahead Scott then I'll ask a question. No I mean I think that LASR you know deserves sort of eternal credit for you know raising these issues 20 years ago and it was you know very very far from obvious to most of us that they would be live issues. I mean I can say for my part you know I was familiar with LASR's views since you know 2006 or so and when I first encountered them you know I you know I didn't you know I knew that there was no principle that said that this scenario was impossible but I just felt like well supposing I agreed with that what do you want me to do about it. You know what where is the research program that has any hope of making progress here right. I mean there's you know one question of what are the most important problems in the world but in science that's necessary but not sufficient. We need something that we can make progress on and you know that that is the thing that I think has changed just recently you know with the advent of of actual very powerful AIs and so the the sort of irony here is that you know as Eliezer has gotten you know much more pessimistic you know unfortunately in the last few years about alignment you know I've sort of gotten more optimistic. I feel like well there is a research program that we're that we can actually make progress on now. Yeah your research your research program is going to take a hundred years and we don't know how long it will take. We don't know that exactly we don't know. I think the argument that we should put a lot more effort into it is clear. I think the argument will take a hundred years is totally unclear. I mean I'm not even sure you can do it in a hundred years because there's the basic problem of getting it right on the first try and the way these things are supposed to work in science is that you have your bright-eyed optimistic youngsters with their vastly oversimplified hopelessly idealistic optimistic plan. They charge ahead. They fail. They like learn a little cynicism. They learn a little pessimism. They learn it's not as easy as that. They try again. They fail again. They start to build up something over battle something like battle-hardening and then and you know like you know they find out how little is possible to them. Aliezer I mean this is a place where I just really don't agree with you so I think there's all kinds of things we can do. There's sort of of the flavor of model organisms or simulations and so forth and we just mean it's hard because we don't actually have a super intelligence so we can't fully calibrate but it's a leap to say that there's nothing iterative that we can do here or that we have to get it right on the first time. I mean I certainly see a scenario where that's true where getting it right on the first time does make the difference but I can see lots of scenarios where it doesn't and where we do have time to iterate before it happens after it happens and it's really not a single moment but I'm you know idealizing. I mean the problem is getting anything that generalizes up to the super intelligent level where past some threshold level the minds may find that in their own interest to start lying to you even if that happens before super intelligent. Even that like I don't see the logical argument that you can't emulate that we're studying it. I mean for example you could I'm just making this up as I go along but for example you could study what can we do with sociopaths who are often very bright and you know not to their dollar value. What can a what what strategy can a like 70 IQ honest person come up with and invent themselves by which they will outwit and defeat a 130 IQ sociopath. All right well there you're not being fair either in the sense that you know we actually have lots of 150 IQ people who could be working on this problem collectively and there's there's value in collective action. There's literature. What I see is what I see that gives me pause is that is that the people don't seem to appreciate what about the problem is hard even at the level where like 20 years ago I could have told you it was hard until you know somebody like me comes along and enacts them about it and then they talk about the ways in which they could adapt and be clever but but the people's charging straightforward are just sort of like doing in this supremely naive way. Let me share a historical example that I think about a lot which is in the early 1900s almost every scientist on the planet who thought about biology made a mistake. They all thought that genes were proteins and then eventually Oswald Avery did the right experiments. They realized that genes were not proteins. There was this weird acid and it didn't take long after people got out of this stock mindset before they figured out how that weird acid worked and how to manipulate it and how to read the code that it was in and so forth. So I absolutely sympathize with the fact that I feel like the field is stuck right now. I think the approaches people are taking to alignment are unlikely to work. I'm completely with you there but I'm also I guess more long term optimistic that science is self-correcting and that we have a chance here. Not a certainty but I think if you know we change research priorities from how do we make some money off this large language model that's unreliable to how do I save the species. We might actually make progress. There's a special kind of caution that you need when something needs to be gotten correct on the first try. I'd be very optimistic if people got a bunch of free retries and I didn't think the first one was going to kill you know the first really serious mistake killed everybody and we didn't get to try again. If we got free retries it'd be an ordinary you know it'd be in some sense an ordinary science problem. Look I can imagine a world where we only got one try and if we failed then it destroys all life on earth and so let me agree to the conditional statement that if we are in that world then I think that we're screwed. I will agree with the same conditional statement. Yeah this gets back to like below hold on you know if you picture by analogy the process of you know a human baby which is extremely stupid becoming a human adult and then just extending that so that in a single lifetime this person goes from a baby to the smartest being that's ever lived but in the in the in the normal way that humans develop which is you know and it doesn't happen any on any one given day and each sub skill develops a little bit at its own rate and so forth it would not be at all obvious to me that our concerns that we have to get it right vis-a-vis that individual the first time. I agree well well no pardon me I do think we have to get them right the first time but I think there's a decent chance of getting it right. It is very important to get it right the first time if like you have this one person getting smarter and smarter and not everyone else is getting smarter and smarter. Eliezer I mean one thing that you've talked about a lot recently is you know if we're all going to die then at least let us die with dignity right. So you know I mean I mean for a certain technical definition some people might care about that more than others but I would say that you know one thing that death with dignity would mean is well at least you know if they're all if we do get multiple retries and you know we get AIs that let's say try to take over the world but are really inept at it and that fail and so forth at least let us succeed in that world you know and that's at least something that we can imagine working on and making progress on. I mean you may very it's for it is not presently ruled out that you have some like you know relatively smart in some ways dumb in some other ways or at least like not smarter than human in other ways AI that makes an early shot at taking over the world maybe because it expects future AIs to not share its goals and not cooperate with it and it fails and you know I mean the appropriate lesson to learn there is to you know like shut the whole thing down but you know if we so yeah like I would say so I'd be like yeah sure like wouldn't it be good to live in that world and the way you live in that world is that when you get that warning sign you shut it all down. Here's a kind of thought experiment. GBT-4 is probably not capable of annihilating us all I think we agree with that very unlikely but GBT-4 is certainly capable of expressing the desire to annihilate us all or being you know people have rigged different versions that are you know more aggressive and and so forth. We could say look until we can shut down those versions you know GBT-4s that are programmed to be malicious by human intent maybe we shouldn't build GBT-5 or at least not GBT-6 or some other system etc we could say you know what we have right now actually is part of that iteration we have you know primitive intelligence right now it's nowhere near as smart as the super intelligence is going to be but even this one we're not that good at constraining maybe we shouldn't pass go until we get this one right. I mean the problem with that from my perspective is that I do think you that you can pass this test and still wipe out humanity like I think that there comes a point where your AI is smart enough that it knows which answer you're looking for and the point at which it tells you what you want to hear is not the point that which is internal my test is not sufficient but it might be a logical pause point right it might be that if we can't even pass the test now of you know controlling a deliberate sort of fine-tuned to be malicious version of GBT-4 then we don't know what we're talking about and we're playing around with fire so you know passing that test wouldn't be a guarantee that would be in good stead with an even smarter machine but we really should be worried I think that we're not in a very good position with respect even to the current ones. Gary I of course watched the recent congressional hearing where you and Sam Altman were testifying you know about what should be done should should should there be auditing of these systems you know before training before deployment and you know it may be you know the most striking thing about about that session was you know just how little daylight there seemed to be between you and Sam Altman the CEO of OpenAI you know I mean you know he was completely on board with the idea of you know establishing a regulatory framework for you know you know having to clear the you know more powerful systems before they are deployed now you know in in Aliezer's worldview that still would be woefully insufficient shortly and you know we would still all be dead but you know maybe in your in your worldview that you know it sounds like you know I'm not even sure how much daylight there is I mean the you know you know you know have the very I think historically striking situation where you know the the heads of all of the major AI or well almost all of the major AI organizations are you know agreeing and saying you know please regulate us yes this is dangerous yes we need to be regulated I mean I thought it was really striking in fact I talked to Sam just before you know the the hearing started and I had just proposed an international agency for AI I wasn't the first person ever but I I pushed it in my TED talk and an economist op ed a few weeks before and Sam said to me I like that idea and I said tell them tell the Senate and he did and that kind of astonished me that he did I mean we have you know we've had some friction between the two of us in the past and he actually even attributed to me he said I support what Professor Marcus said about doing international governance and there's been a lot of convergence around the world on that is that enough to stop Aliezer's worries no I don't think so but it's an important baby step I think that we do need to have some global body that can coordinate around these things I don't think we really have to coordinate around superintelligence yet but if we can't do any coordination now then when the time comes we're not prepared so I think it's great that there's some agreement I I worry that you know open AI had this lobbying document that just came out that seemed not entirely consistent with what Sam said in the room and there's always concerns about regulatory capture and so forth but I think it's great that a lot of the the heads of these companies maybe with the exception of Facebook or meta are recognizing that there are genuine concerns here I mean the other moment that a lot of people remember from the testimony was when Sam was asked what he was most concerned about was it jobs and he said no and I asked Senator Blumenthal to push Sam and Sam was you know he could have been more candid but he was fairly candid and he said he was worried about serious harm to the species I think that was an important moment when he said that to the Senate and I think it galvanized a lot of people that he said it so can we dwell on a moment um I mean we've been talking about the the depending on your view highly likely or tail risk scenario of humanity's extinction or or significant destruction it would appear to me by the same token if if those are plausible scenarios we're talking about then the opposite maybe we're talking about as well um you know what does it look like to have a super intelligent AI that really you know as if as a feature of its intelligence deeply understands human beings the human species and also has a deep desire for us to be as happy as possible what does that world look like oh is that possible no no not that that looks like you know just like why are why are everyone leather centers to make them as happy as possible but more like a parent wants their child to be happy right that may not involve any particular scenario but is is generally quite concerned about the well-being of the human race and is also super intelligent honestly I'd rather have machines work on medical problems than happiness problems I think there's maybe more risk of mis-specification of the happiness problems um whereas if we get them to work on Alzheimer's and just say like figure out what's going on why are these plaques there what can you do about it maybe there's less harm that might come come from you don't need super intelligence for that that sounds like an alpha fold three problem or an alpha fold four problem well this is also this is somewhat different than the question I'm asking it's it's not really even um us asking a super intelligence to do anything because we we've already been entertaining scenarios where the super intelligence has its own desires independent of us is it do you think at all yeah I'm not real thrilled with that I mean I mean I don't think we want to leave what their objective functions are what their desires are to them working them out you know with no consultation from us with no human in the loop right fully I mean especially given our current understanding of the technology like our current understanding of how to keep a system on track doing what we want to do is pretty limited and so you know taking humans out of the loop there sounds like a really bad idea to me at least in the foreseeable future I would want to see much better alignment technology before I would want to give free rent free range so so so if we had the textbook from the future like we have the textbook from 100 years in the future which contains all the simple ideas that actually work in real life as opposed to you know the complicated ideas and the simple ideas that don't work in real life the equivalent of relus instead of sigmoids for the activation functions you know 100 the textbook from 100 years in the future you can probably build a super intelligence that'll want anything you can anything that's coherent to want anything you can you know figure out how to say describe coherently point that at your own mind and tell you to figure out what what it is you meant for to want and you know you could get the you could get the glorious transhumanist future you could get the happily ever after anything's you know anything's possible that doesn't violate the laws of physics the trouble is doing it in real life and you know and the first try but uh yeah so like you know could the the the whole thing that we're we're aiming for here is to colonize all the galaxies we can reach um before somebody else gets them first and turn them into galaxies full of you know complex sapient life living happily ever after you know that that's that's the goal that's still the goal even if we you know even even even when I call for like you know a permanent moratorium on AI I'm not trying to prevent us from count from colonizing the galaxies you know like humanity forbid um more more like let's you know let's like do some human intelligence augmentation with alpha fold four and before we try building GPT-8 one of the few scenarios that I think we can clearly rule out here is an AI that is existentially dangerous but also boring right I mean I think anything that has the capacity to kill us all right would have you know if if nothing else pretty amazing capabilities and those capabilities you know could also be turned to you know solving a lot of humanities problems right you know if if we were to solve the alignment problem I mean you know humanity had a lot of existential you know risks you know before AI came on the scene right uh you know I mean there was the risk of of you know nuclear annihilation there is the risk of runaway climate change and you know I would I would love to see you know an AI that could help us with such things I would also love to see an AI that could sort of you know help us just solve you know some of the mysteries of the universe I mean you know like how can one possibly not be curious to know you know what what such a being could teach us uh you know I mean I mean for the past year I've tried to use GPT-4 to produce original scientific insights and I've not been able to get it to do that uh and you know I don't know whether I should feel you know disappointed or relieved by that but I think you know the better part of me should you know just is the part that should just want to see you know the great mysteries of of existence of you know why is the universe quantum mechanical or you know how do you prove the Riemann hypothesis it should just want to see these mysteries solved you know and and uh if it's to be by AI then then then then fine let it be by AI let me give you a kind of lesson in epistemic humility we don't really know whether GPT-4 is net positive or net negative you know there are lots of arguments you can make I've been in a bunch of debates where I've you know had to take the side of arguing that that it's a net negative but we don't really know if we don't know that was the invention of agriculture net positive or net negative I mean you could you could I mean I say it was not positive but but the point is if I can just finish the quick like thought experiment or whatever I don't think anybody can reasonably answer that right we we don't yet know all of the ways in which GPT-4 will be used for good we don't know all of the ways in which bad actors will use it we don't know all the consequences that's going to be true for each iteration it's probably going to get harder to compute for each iteration and we can't even do it now and I think that we should realize that to realize our own limits in being able to assess the the negatives and positives maybe that we can think about better ways to do that than we currently have but I think you've got to have a guess like like my guess is that so far not looking into the future at all GPT-4 has been net positive I mean maybe I haven't talked about the the various risks yet and it's still early but I mean that's just a guess is kind of the point like we don't have a way of putting it on a spreadsheet right now or whatever like we don't really have a good way to quantify it but I mean do we ever but it's not out of control yet so so by and large people are going to be using GPT-4 to use things to do things that they want and the relative cases where they manage to injure themselves are rare enough to be news on Twitter well for example I mean we haven't talked about it but you know what bad actors some bad actors will want to do is to influence the US elections and try to undermine democracy in the US and if they succeed in that I think there's pretty serious long-term consequences there well I think it's open AI's responsibility to step up and run the 2024 election itself I will I can pass that along is that a joke no I mean I mean as far as I can say you know the the clearest concrete harm to have come from GPT so far is that you know tens of millions of students have now used it to cheat on their assignments and I have been thinking about that and I have been trying to come up with solutions to that at the same time I think if you do the positive utility has included I mean you know I I'm a theoretical computer scientist which means you know one who hasn't written any serious code for about 20 years and you know realized just a month or two ago I can get back into coding and the way I can do it is I just asked GPT to write the code for me and you know I wasn't expecting it to work that well and unbelievably it you know often just does exactly what I want on the first try so I mean you know I you know I am getting utility from it rather than just you know seeing it as an interesting research object and you know and and you know I can imagine that that hundreds of millions of people are going to be deriving utility from it in those ways I mean like most of the tools to help them derive that utility are not even out yet but they're they're coming in the next couple of years I mean part of the reason why I'm worried about the focus on short-term problems is that I suspect that the short-term problems might very well be solvable and we'll be left with the long-term problems after that maybe we can solve the like it wouldn't surprise me very much if like in 2025 the well you know like the large language there are large language models that just don't make stuff up anymore it would surprise and yet even yet you know and yet the superintelligence still kills everyone because they weren't the same problem well you know you know we just need to figure out how to delay the apocalypse by at least one year per year of research invested what what does that delay look like if it's not just a moratorium well I don't know that's why it's research okay so but but possibly one ought to say to the politicians in the public and by the way if we had a superintelligence tomorrow our research wouldn't be finished and everybody would drop dead you know it's kind of ironic the biggest argument against the pause letter was that if we slow down for six months then China will get ahead of us and get GPT-5 before we will but there's probably always a counter argument of maybe roughly equal strength which is if we move six months faster on this technology which is not really solving the alignment problem then we're reducing our room to get this solved in time by six months I mean I don't think you're going to solve the alignment problem in time I think that six months of delay on alignment while a bad thing in an absolute sense is you know like you know you weren't going to solve it with given an extra six months I mean your whole argument rests on timing right that that we will get to this point and we won't be able to move fast enough at that point and so you know a lot depends on what preparation we can do you know I'm often known as a pessimist but I'm a little bit more optimistic than you are not entirely optimistic but a little bit more optimistic than you are that we could make progress on the alignment problem if we prioritized it and you can absolutely make progress because we can absolutely make progress you know there's there's always the you know that the wonderful sense of accomplishment is piece by piece you decode you know like one more little fact about LLMs you never get to the point where you understand that as well as we understood the interior of a chess playing program in 1997 yeah I mean I think we should stop spending all this time on LLMs I don't think the answer to alignment is going to come from LLM through LLMs I really don't I think they're they're too much of a black box you can't put explicit symbolic constraints in the way that you need to I think they're actually with respect to alignment to blind alley I think with respect to writing code they're a great tool but with alignment I don't think the answer is there so at the risk of asking a stupid question every time GPT asks me if that answer was helpful and then does the same thing with thousands or hundreds of thousands of other people and and changes as a result is that not a decentralized way of making it more aligned yeah well yeah so so so there is that upvoting and downvoting you know that that gets fed back in into sort of fine-tuning it but even before that there was you know a major step you know in going from let's say the the base GPT 3 model for example to the chat GPT you know that was released to the public and that was called a RLHF reinforcement learning with human feedback and what that basically involved was you know several hundred contractors you know looking at just just ten tens of thousands of examples of outputs and and and rating them you know are they helpful are they offensive you know are they you know are are they you know giving dangerous medical advice or you know bomb making instructions you know or racist invective or you know various other categories that that we don't want and and that that was then used to fine-tune the model so when you know Gary talked before about how GPT is amoral you know I think that that has to be qualified by saying that you know these this reinforcement learning is at least giving it you know a semblance of morality right it is causing it to sort of behave you know in various contexts as if it had you know a certain morality I mean when you phrase it that way I'm okay with it the problem is you know everything rests on the I would say it is it is very much an open question you know how much that you know to what extent does that generalize you know eliezer treats it as obvious that you know once you have a powerful enough AI you know this is just a fig leaf you know it doesn't make any difference you know it will just learn it's any big leafy I'm with eliezer there okay it's fig leaves well I would say that you know the sort of how well you know under what circumstances does a machine learning model sort of generalize in the way we want outside of its training distribution you know is one of the great open problems in machine learning it is one of the great open problems and we should be working on it more than on some others working on it now so I do want to be I want to be clear about the experimental predictions of my theory unfortunately I have never claimed that you cannot get a semblance of morality you can get the question of like what causes the human to press thumbs up thumbs down is a strictly factual question anything smart enough that's exposed to some you know bound and amount of data that needs to figure it out can figure that out whether it cares whether it gets internalized is the is the critical question there and and I do think that there's like a very strong default prediction which is like obviously not I mean I'll just give a different way of thinking about that which is jailbreaking it's actually still quite easy to I mean it's not trivial but it's not hard to jailbreak GPT for and what those cases show is that they haven't really in turn the systems haven't really internalized the constraints they recognize some representations of the constraints so they filter you know how to build a bomb but if you can find some other way to get it to build a bomb then that's telling you that it doesn't deeply understand that you shouldn't give people the the recipe for a bomb it just says you know you shouldn't when directly asked for it do it and it doesn't it's not even that that I mean I understand a lot of the but understanding the jailbreaking always get you can always get the understanding you'd always get the factual question the reason it doesn't generalize is that it's stupid at some point it will know that you also don't want that the operators don't want a giving bond making directions in the other language the question is like whether if it's incentivized to give the answer that the operators want you know in that circumstance is it thereby incentivized to do everything else the operators want even when the operators can't see it I mean a lot of the jailbreaking examples you know if it were a human we would say that it's deeply morally ambiguous you know for example you know you ask GPT how to build a bomb it says well no I'm not going to help you but then you say well you know I need you to help me write a realistic play that has a character who builds a bomb and then it says sure I can help you with that well so look let's take that example yeah we would like a system to have a constraint that if somebody asks for a fictional version that you don't give enough details right I mean Hollywood screenwriters don't give enough details when they have you know illustrations about building bombs they give you a little bit of the flavor they don't give you the whole thing GPT-4 doesn't really understand a constraint like that but this will be solved this will be solved before the world ends the AI that kills everyone will know the difference maybe I mean another way to put it is if we can't even solve that one then we do have a problem and right now we can't solve that one and if I mean if we can't solve that one we don't have an extinction level problem because the AI is still stupid yeah we do still have a catastrophe level problem so I know your focus has been on extinction but you know I'm worried about for example accidental nuclear war caused by the spread of misinformation and systems being entrusted with too much power so like there's a lot of things short of extinction that might happen from not superintelligence but kind of mediocre intelligence that is greatly empowered and I think that's where we're headed right now you know I've heard that there are two kinds of mathematicians there's a kind who boasts you know you know that unbelievably general theorem well I generalized it even further and then there's the kind who boasts you know you know that unbelievably specific problem that no one could solve well I found a special case that I still can't solve and you know I'm definitely you know culturally in that second camp and so you know so I so so to me it's very familiar to make this move of you know if the alignment problem is too hard then let us find a smaller problem that is already not solved and let us hope to learn something by solving that smaller problem I mean that's what we did you know like that's what we're doing at Mary yes sorry no I was just going to say Scott can you sketch a little in a little more detail where you took one particular approach I was going to I was going to name the problem the problem was like having a agent that could switch between two utility functions depending on a button or a switch or a bit of information or something such that it wouldn't try to make you press the button it wouldn't try to make you avoid pressing the button and if it built a copy of itself would want to build the dependency on the switch into the copy so like that's an example of a you know very basic problem and alignment theory that you know is still and I'm glad that Mary worked on these things and but you know if by your own lights you know that you know that sort of you know was not a successful path well then maybe you know we should have a lot of people investigating a lot of different paths yeah I'm with fully with Scott on that that I think it's an issue of we're not letting enough flowers bloom in particular almost everything right now is some variation on an LLM and I don't think that that's a broad enough take on the problem yeah if I if I can just jump in here I want to I want to hold on hold on I just want people to have a little bit of a more specific picture of what Scott your your picture sort of AI research is on a typical day because if I think of another you know potentially catastrophic risk like climate change I can picture what a what a you know a worried climate scientist might be doing they might be creating a model you know a more accurate model of climate change so that so that we know how much we have to cut emissions by they might be you know modeling how solar power as opposed to wind power could change that model and so forth so as to influence public policy what does an AI safety researcher like yourself who's working on the quote-unquote smaller problems do specifically like on a given day yeah so I'm a relative newcomer to this area you know I've not been working on it for 20 years like Eliezer has you know I have I accepted an offer from open AI a year ago to work with them for two years now to sort of think about these questions and so so you know one of one of the main things that that I've thought about just to start with that is how do we make the output of an AI identifiable as such you know how can we insert a watermark you know into meaning a secret statistical signal into the outputs of GPT that will let you know GPT generated text be identifiable as such and I think that we've actually made you know major advances on that problem over the last year you know we don't have a solution that is robust against any kind of attack but you know we have something that that might actually be deployed in some near future now there are lots and lots of other directions that people think about one of them is interpretability which means you know can you do effectively neuroscience on a on a neural network can you look inside of it you know open the black box and understand what's going on inside there was some amazing work of a year ago by the group of Jacob Steinhardt at Berkeley where they effectively showed how to apply a lie detector test to a language model so you know you can train a language model to tell lies by giving it lots of examples you know two plus two is five the sky is orange and so forth but then you can find in some internal layer of the network where it has a representation of what was what was the truth of the matter or at least what was regarded as true in the training data okay that truth then gets overridden by the output layer in the network because it was trained to lie okay but you know you could imagine trying to deal with the you know the deceptive alignment scenario that Eliezer is worried about by you know using these sorts of techniques by sort of looking inside of the network I predict in advance that if you get this good enough it goes off it tells you that the sufficiently smart AI is planning to kill you if it's not so smart that it can you know know figure out where the lie detector is and route its thoughts around it but if you like try it on an AI that's not quite that intelligent and reflective the lie detector goes off now what well then you have a warning bell you know tell you know and I think what do you do after one of the most important things that we need are sort of legible warning bells right and that that actually what leads to a third category which for example the ARC the Alignment Research Center which is run by my my former student Paul Cristiano has been a leader in in sort of doing dangerous capability evaluations so you know they before GPT-4 was released you know they did a bunch of evaluations of you know could GPT-4 make copies of itself could it figure out how to deceive people could it figure out how to make money you know open up its own money could it hire a task rabbit yes and yes so so the most notable success that they had was that it could figure out how to hire a task rabbit to help it you know pass a capture and then it could figure out you know when the person asked well you know why do you need me to help you with this it's a when the person asked are you a robot well yes it said well no I am visually impaired now you know it was not able to sort of make copies of itself or to sort of hack into systems you know there there is a lot of work right now with the you know this thing called auto GPT right people are trying to you know you could think it's almost like gain of function research right you might be a little bit worried about it but people are trying to sort of you know unleash GPT give it access to the internet you know tell it to sort of you know make copies of itself you know wreak havoc acquire power and see what happens so far you know it seems pretty ineffective at those things but you know I expect that to change right and but but but you know the point is that I think it's very important to have you know in advance of training the models releasing the models to have this suite of evaluations and to sort of have decided in advance what kind of abilities if we see them we'll set off a warning bell where now everyone can legibly agree like yes this is too dangerous to release okay and then do we actually have the planetary capacity to be like okay that AI started thinking about how to kill everyone shut down all AI research past this point well I don't know but I think there's a much better chance that we have that capacity if you can point to the results of a clear experiment like that I mean to me it seems pretty predictable what evidence we're going to get later well okay I mean things that are obvious to you are not obvious to most people and so you know even if even if I agreed that it was obvious there would still be the problem of how do you make that obvious to the rest of the world I mean you can you know they there are already like little toy models showing that the very straightforward prediction of a robot tries to resist being shut down if it like does long-term planning like that that's already been right but then people will say but those are just toy models right you know if you see that there's a lot of assumptions made in all of these things and you know I think we're still looking at a very limited piece of hypothesis space about what the models will be about what kinds of constraints we can build into those models you know one way to look at it would be the things that we have done have not worked and therefore we should look outside the space of what we're doing and I feel like it's a little bit like the old joke about the drunk going around in circles looking for the keys and the police officer says why and they say well that's where the streetlight is I think that you know we're looking under the same four or five streetlights they haven't worked and we need to build other ones there's no logical there's no logical argument that says we couldn't direct other streetlights who's I think there's a lack of will and too much obsession with the LLMs and that's keeping us from doing so even in the world where I'm right and things you know proceed either rapidly or in a thresholded way where you don't get unlimited free retries you know that can be because the the capability gains go too fast it can be because past a certain point all of your ai's buy their time until they get strong enough so you don't get any data any any like true data on what they're thinking it could be because you know that's an argument for example to work really hard on transparency and maybe not except technologies that are not transparent okay so like the transparent so like the lie detector goes off and everybody's like oh well we still have to build our ai's even though they're lying to us sometimes because otherwise China will get ahead I mean so there you talk about something we've talked about way too little which is the political and social side of this so you know part of what has really motivated me in the last several months is worry about exactly that so you know there's there's what's logically possible and what's politically possible and I am really concerned that the politics of let's not lose out to China is going to keep us from doing the right thing in terms of building the right moral systems looking at the right range of problems and so forth so you know it is entirely possible that we will screw ourselves if I if I can just like finish my point there before handing it to you indeed but like the point I was trying to say there is that even in worlds that look very very bad from that perspective where humanity is quite doomed it will still be true you can make progress in research you can't make enough progress in research fast enough in those worlds but you can still make progress on transparency you can make progress on watermarking so there's there's not we can't just say like it's possible to make progress there has to be the question is not is it possible to make any progress the question is it is it possible to make enough progress fast enough and that's what the question has to be I agree there's another question of what would you have us do would you have us not try to make that progress I'd have you try to make that progress on a GPT-4 level systems and then not go past GPT-4 level systems because we don't actually understand the the the gain function for you know how how fast capabilities increase as you go past GPT-4 okay all right so I mean we are going out I don't think that you go ahead Gary go ahead just briefly I personally don't think that GPT-5 is going to be qualitatively different from GPT-4 in the relevant ways to what Eleazar is talking about but I do think you know some qualitative changes could be relevant to what he's talking about we have no clue what they are and so it is a little bit dodgy to just proceed blindly saying do whatever you want we don't really have a theory and let's hope for the best you know Eleazar I would mostly guess that GPT-5 doesn't end the world but I don't actually know yeah we don't actually know and I was going to say the thing that Eleazar has said lately that has most resonated with me is we don't have a plan we really don't like I think I put the probability distributions in a much more optimistic way I think that Eleazar would but I completely agree we don't have a full plan on these things or even close to a full plan and we should be worried and we should be working on this okay Scott I'm going to give you the last word before before we come up on our stop time here unless you unless you said all there is to be a weighty responsibility maybe enough has been said cheers up Scott come on so so I think that that you know we've we've argued about a bunch of things but you know as someone listening might notice that actually all three of us despite having very different perspectives agree about you know the the great importance of of you know working on AI alignment I think you know that was you know maybe obvious to some people including Eleazar for a long time it was not obvious to most of the world I think that you know the the success of of large language models you know which most of us did not predict you know maybe even could not have predicted for many principles that we knew but now that we've seen it the least we can do is to update on that on that empirical fact and and realize that you know we we we now are in some sense in a different world we are in a world that you know to a great extent you know will be defined by you know the capabilities and limitations of AI going forward and you know I don't regard it as obvious that that's a a a world where where we are all doomed where where we all die but you know I also don't dismiss that possibility I think that you know there there is an enormous unbelievably enormous error bars on on on where we could be going and you know like the one thing you know that that a scientist is sort of always always feels confident in in saying about the future is that more research is needed but you know I think that that's especially the case here I mean you know we need more knowledge about you know what are the the contours of the alignment problem and you know of course Eliezer and you know Amiri you know his his organization were trying to develop that knowledge for 20 years you know and they showed a lot of foresight in trying to do that but you know they were up against you know an enormous headwind that you know they were sort of trying to do it in the absence of you know either you know clear empirical data you know about powerful ai's or a mathematical theory right and it's really really hard to do science when you have neither of those two things and now at least we have you know the powerful ai's in the world and we can get experience from them you know we still don't have a mathematical theory that really deeply explains what they're doing but at least we can get data and so now I am much more optimistic than I would have been you know a decade ago let's say that one could make actual progress on on on the ai alignment problem you know of course you know there was a question of timing as as was discussed many times the question is you know will the alignment research happen fast enough to keep up with the capabilities research but you know I don't I don't regard it as a lost cause you know it's at least it's not obvious that it won't so you know in any case let's get started or let's let's uh or let's let's continue let's let's let's try to do the research and let's get more people working on that I think that that that is now uh a slam dunk you know just a completely clear case to make to you know academics to policymakers to to anyone who's interested and you know I've been gratified that that you know uh you know aliezer was sort of a voice in the wilderness for for a long time talking about the importance of ai safety that is no longer the case uh you now have you know you know I mean almost all of my friends in you know in just the academic computer science world you know when I see them they mostly want to talk about AI alignment I rarely agree with Scott when we trade email um I rarely agree with Scott when we trade emails we seem to always disagree but I completely concur with the summary that he just gave all four or five minutes of it well thank you I mean I mean there is a selection effect Gary right we focus on things I think the two decades gave me a sense of a roadmap and it gave me a sense that we're falling enormously behind on the roadmap I need to back off as the way I is what I would say to all that if there is a smart talented 18 year old kid listening listening to this podcast who wants to get into this issue what is your 10 second concrete advice to that person mine is study neurosymbolic AI and see if there's a way there to represent values explicitly that might help us learn all you can about computer science and math and related subjects and think outside the box and wow everyone with a new idea get security mindset figure out what's going to go wrong figure out the flaws in your arguments for what's going to go wrong try to get ahead of the curve don't wait for reality to hit you over the head with things uh this this is very difficult the people in evolutionary biology happen to have a bunch of knowledge about how to do it based on the history of their own field but uh and and and the security mindset people in computer security but it's it's quite hard I'll drink to all of that thanks thanks to all three of you for this this was a great conversation and I hope people got something out of it so with that said we're wrapped up thanks so much that's it for this episode of conversations with Coleman guys as always thanks for watching and feel free to tell me what you think by reviewing the podcast commenting on social media or sending me an email to check out my other social media platforms click the cards you see on screen and don't forget to like share and subscribe see you next time", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 4.08, "text": " Why is AI going to destroy us? Chat GPT seems pretty nice. I use it every day.", "tokens": [50364, 1545, 307, 7318, 516, 281, 5293, 505, 30, 27503, 26039, 51, 2544, 1238, 1481, 13, 286, 764, 309, 633, 786, 13, 50568], "temperature": 0.0, "avg_logprob": -0.14782452777149233, "compression_ratio": 1.6161971830985915, "no_speech_prob": 0.011497280560433865}, {"id": 1, "seek": 0, "start": 4.08, "end": 6.32, "text": " What's the big fear here? Make the case.", "tokens": [50568, 708, 311, 264, 955, 4240, 510, 30, 4387, 264, 1389, 13, 50680], "temperature": 0.0, "avg_logprob": -0.14782452777149233, "compression_ratio": 1.6161971830985915, "no_speech_prob": 0.011497280560433865}, {"id": 2, "seek": 0, "start": 6.32, "end": 10.08, "text": " We don't understand the things that we build.", "tokens": [50680, 492, 500, 380, 1223, 264, 721, 300, 321, 1322, 13, 50868], "temperature": 0.0, "avg_logprob": -0.14782452777149233, "compression_ratio": 1.6161971830985915, "no_speech_prob": 0.011497280560433865}, {"id": 3, "seek": 0, "start": 10.08, "end": 13.92, "text": " The AIs are grown more than built, you might say.", "tokens": [50868, 440, 316, 6802, 366, 7709, 544, 813, 3094, 11, 291, 1062, 584, 13, 51060], "temperature": 0.0, "avg_logprob": -0.14782452777149233, "compression_ratio": 1.6161971830985915, "no_speech_prob": 0.011497280560433865}, {"id": 4, "seek": 0, "start": 13.92, "end": 18.56, "text": " They end up as giant, inscrutable matrices of floating point numbers that nobody can decode.", "tokens": [51060, 814, 917, 493, 382, 7410, 11, 1028, 10757, 32148, 32284, 295, 12607, 935, 3547, 300, 5079, 393, 979, 1429, 13, 51292], "temperature": 0.0, "avg_logprob": -0.14782452777149233, "compression_ratio": 1.6161971830985915, "no_speech_prob": 0.011497280560433865}, {"id": 5, "seek": 0, "start": 18.56, "end": 23.04, "text": " At this rate, we end up with something that is smarter than us, smarter than humanity,", "tokens": [51292, 1711, 341, 3314, 11, 321, 917, 493, 365, 746, 300, 307, 20294, 813, 505, 11, 20294, 813, 10243, 11, 51516], "temperature": 0.0, "avg_logprob": -0.14782452777149233, "compression_ratio": 1.6161971830985915, "no_speech_prob": 0.011497280560433865}, {"id": 6, "seek": 0, "start": 23.76, "end": 28.0, "text": " that we don't understand, whose preferences we could not shape.", "tokens": [51552, 300, 321, 500, 380, 1223, 11, 6104, 21910, 321, 727, 406, 3909, 13, 51764], "temperature": 0.0, "avg_logprob": -0.14782452777149233, "compression_ratio": 1.6161971830985915, "no_speech_prob": 0.011497280560433865}, {"id": 7, "seek": 2800, "start": 28.8, "end": 32.72, "text": " And by default, if that happens, if you have something around that is much", "tokens": [50404, 400, 538, 7576, 11, 498, 300, 2314, 11, 498, 291, 362, 746, 926, 300, 307, 709, 50600], "temperature": 0.0, "avg_logprob": -0.08881355632435192, "compression_ratio": 1.6920152091254752, "no_speech_prob": 0.02477979101240635}, {"id": 8, "seek": 2800, "start": 32.72, "end": 35.76, "text": " smarter than you and does not care about you one way or the other,", "tokens": [50600, 20294, 813, 291, 293, 775, 406, 1127, 466, 291, 472, 636, 420, 264, 661, 11, 50752], "temperature": 0.0, "avg_logprob": -0.08881355632435192, "compression_ratio": 1.6920152091254752, "no_speech_prob": 0.02477979101240635}, {"id": 9, "seek": 2800, "start": 35.76, "end": 37.519999999999996, "text": " you probably end up dead at the end of that.", "tokens": [50752, 291, 1391, 917, 493, 3116, 412, 264, 917, 295, 300, 13, 50840], "temperature": 0.0, "avg_logprob": -0.08881355632435192, "compression_ratio": 1.6920152091254752, "no_speech_prob": 0.02477979101240635}, {"id": 10, "seek": 2800, "start": 37.519999999999996, "end": 43.44, "text": " Extinction is a pretty extreme outcome that I don't think is particularly likely,", "tokens": [50840, 9881, 12987, 307, 257, 1238, 8084, 9700, 300, 286, 500, 380, 519, 307, 4098, 3700, 11, 51136], "temperature": 0.0, "avg_logprob": -0.08881355632435192, "compression_ratio": 1.6920152091254752, "no_speech_prob": 0.02477979101240635}, {"id": 11, "seek": 2800, "start": 43.44, "end": 48.24, "text": " but the possibility that these machines will cause mayhem because we don't know how to", "tokens": [51136, 457, 264, 7959, 300, 613, 8379, 486, 3082, 815, 28005, 570, 321, 500, 380, 458, 577, 281, 51376], "temperature": 0.0, "avg_logprob": -0.08881355632435192, "compression_ratio": 1.6920152091254752, "no_speech_prob": 0.02477979101240635}, {"id": 12, "seek": 2800, "start": 49.44, "end": 53.2, "text": " enforce that they do what we want them to do. I think that's a real thing to worry about.", "tokens": [51436, 24825, 300, 436, 360, 437, 321, 528, 552, 281, 360, 13, 286, 519, 300, 311, 257, 957, 551, 281, 3292, 466, 13, 51624], "temperature": 0.0, "avg_logprob": -0.08881355632435192, "compression_ratio": 1.6920152091254752, "no_speech_prob": 0.02477979101240635}, {"id": 13, "seek": 5800, "start": 58.8, "end": 61.44, "text": " Welcome to another episode of Conversations with Coleman.", "tokens": [50404, 4027, 281, 1071, 3500, 295, 33247, 763, 365, 49930, 13, 50536], "temperature": 0.0, "avg_logprob": -0.10023581728022149, "compression_ratio": 1.5622489959839359, "no_speech_prob": 0.08137820661067963}, {"id": 14, "seek": 5800, "start": 62.0, "end": 67.6, "text": " Today's episode is a roundtable discussion about AI safety with Eliezer Yudkowski,", "tokens": [50564, 2692, 311, 3500, 307, 257, 3098, 23811, 5017, 466, 7318, 4514, 365, 2699, 414, 4527, 398, 532, 74, 21866, 11, 50844], "temperature": 0.0, "avg_logprob": -0.10023581728022149, "compression_ratio": 1.5622489959839359, "no_speech_prob": 0.08137820661067963}, {"id": 15, "seek": 5800, "start": 67.6, "end": 74.0, "text": " Gary Marcus, and Scott Aronson. Eliezer Yudkowski is a prominent AI researcher and writer", "tokens": [50844, 13788, 26574, 11, 293, 6659, 1587, 892, 266, 13, 2699, 414, 4527, 398, 532, 74, 21866, 307, 257, 17034, 7318, 21751, 293, 9936, 51164], "temperature": 0.0, "avg_logprob": -0.10023581728022149, "compression_ratio": 1.5622489959839359, "no_speech_prob": 0.08137820661067963}, {"id": 16, "seek": 5800, "start": 74.0, "end": 77.92, "text": " known for co-founding the Machine Intelligence Research Institute,", "tokens": [51164, 2570, 337, 598, 12, 17493, 278, 264, 22155, 27274, 10303, 9446, 11, 51360], "temperature": 0.0, "avg_logprob": -0.10023581728022149, "compression_ratio": 1.5622489959839359, "no_speech_prob": 0.08137820661067963}, {"id": 17, "seek": 5800, "start": 77.92, "end": 83.68, "text": " where he spearheaded research on AI safety. He's also widely recognized for his influential", "tokens": [51360, 689, 415, 26993, 28409, 2132, 322, 7318, 4514, 13, 634, 311, 611, 13371, 9823, 337, 702, 22215, 51648], "temperature": 0.0, "avg_logprob": -0.10023581728022149, "compression_ratio": 1.5622489959839359, "no_speech_prob": 0.08137820661067963}, {"id": 18, "seek": 8368, "start": 83.68, "end": 89.2, "text": " writings on the topic of rationality. Scott Aronson is a theoretical computer scientist", "tokens": [50364, 30083, 322, 264, 4829, 295, 15090, 507, 13, 6659, 1587, 892, 266, 307, 257, 20864, 3820, 12662, 50640], "temperature": 0.0, "avg_logprob": -0.08479511403591833, "compression_ratio": 1.6397058823529411, "no_speech_prob": 0.01471544336527586}, {"id": 19, "seek": 8368, "start": 89.2, "end": 93.92, "text": " and author, celebrated for his pioneering work in the field of quantum computation.", "tokens": [50640, 293, 3793, 11, 19366, 337, 702, 19761, 1794, 589, 294, 264, 2519, 295, 13018, 24903, 13, 50876], "temperature": 0.0, "avg_logprob": -0.08479511403591833, "compression_ratio": 1.6397058823529411, "no_speech_prob": 0.01471544336527586}, {"id": 20, "seek": 8368, "start": 94.56, "end": 99.68, "text": " He's also the chair of COMSI at U of T Austin, but is currently taking a leave of absence to", "tokens": [50908, 634, 311, 611, 264, 6090, 295, 3002, 10288, 40, 412, 624, 295, 314, 15356, 11, 457, 307, 4362, 1940, 257, 1856, 295, 17145, 281, 51164], "temperature": 0.0, "avg_logprob": -0.08479511403591833, "compression_ratio": 1.6397058823529411, "no_speech_prob": 0.01471544336527586}, {"id": 21, "seek": 8368, "start": 99.68, "end": 106.08000000000001, "text": " work at open AI. Gary Marcus is a cognitive scientist, author, and entrepreneur known for", "tokens": [51164, 589, 412, 1269, 7318, 13, 13788, 26574, 307, 257, 15605, 12662, 11, 3793, 11, 293, 14307, 2570, 337, 51484], "temperature": 0.0, "avg_logprob": -0.08479511403591833, "compression_ratio": 1.6397058823529411, "no_speech_prob": 0.01471544336527586}, {"id": 22, "seek": 8368, "start": 106.08000000000001, "end": 111.76, "text": " his work at the intersection of psychology, linguistics, and AI. He's also authored several", "tokens": [51484, 702, 589, 412, 264, 15236, 295, 15105, 11, 21766, 6006, 11, 293, 7318, 13, 634, 311, 611, 6979, 2769, 2940, 51768], "temperature": 0.0, "avg_logprob": -0.08479511403591833, "compression_ratio": 1.6397058823529411, "no_speech_prob": 0.01471544336527586}, {"id": 23, "seek": 11176, "start": 111.76, "end": 118.88000000000001, "text": " books, including Cluj and Rebooting AI, Building AI We Can Trust. This episode is all about AI", "tokens": [50364, 3642, 11, 3009, 2033, 4579, 293, 1300, 1763, 17001, 7318, 11, 18974, 7318, 492, 1664, 11580, 13, 639, 3500, 307, 439, 466, 7318, 50720], "temperature": 0.0, "avg_logprob": -0.06905505553535793, "compression_ratio": 1.7158273381294964, "no_speech_prob": 0.08139966428279877}, {"id": 24, "seek": 11176, "start": 118.88000000000001, "end": 124.48, "text": " safety. We talk about the alignment problem. We talk about the possibility of human extinction", "tokens": [50720, 4514, 13, 492, 751, 466, 264, 18515, 1154, 13, 492, 751, 466, 264, 7959, 295, 1952, 33163, 51000], "temperature": 0.0, "avg_logprob": -0.06905505553535793, "compression_ratio": 1.7158273381294964, "no_speech_prob": 0.08139966428279877}, {"id": 25, "seek": 11176, "start": 124.48, "end": 130.24, "text": " due to AI. We talk about what intelligence actually is. We talk about the notion of a singularity", "tokens": [51000, 3462, 281, 7318, 13, 492, 751, 466, 437, 7599, 767, 307, 13, 492, 751, 466, 264, 10710, 295, 257, 20010, 507, 51288], "temperature": 0.0, "avg_logprob": -0.06905505553535793, "compression_ratio": 1.7158273381294964, "no_speech_prob": 0.08139966428279877}, {"id": 26, "seek": 11176, "start": 130.24, "end": 135.84, "text": " or an AI takeoff event, and much more. It was really great to get these three guys in the same", "tokens": [51288, 420, 364, 7318, 747, 4506, 2280, 11, 293, 709, 544, 13, 467, 390, 534, 869, 281, 483, 613, 1045, 1074, 294, 264, 912, 51568], "temperature": 0.0, "avg_logprob": -0.06905505553535793, "compression_ratio": 1.7158273381294964, "no_speech_prob": 0.08139966428279877}, {"id": 27, "seek": 11176, "start": 135.84, "end": 140.56, "text": " virtual room, and I think you'll find that this conversation brings something a bit fresh to a", "tokens": [51568, 6374, 1808, 11, 293, 286, 519, 291, 603, 915, 300, 341, 3761, 5607, 746, 257, 857, 4451, 281, 257, 51804], "temperature": 0.0, "avg_logprob": -0.06905505553535793, "compression_ratio": 1.7158273381294964, "no_speech_prob": 0.08139966428279877}, {"id": 28, "seek": 14056, "start": 140.56, "end": 146.0, "text": " topic that has admittedly been beaten to death on certain corners of the internet. Without further", "tokens": [50364, 4829, 300, 575, 14920, 356, 668, 17909, 281, 2966, 322, 1629, 12413, 295, 264, 4705, 13, 9129, 3052, 50636], "temperature": 0.0, "avg_logprob": -0.11638306155063138, "compression_ratio": 1.594142259414226, "no_speech_prob": 0.00941044557839632}, {"id": 29, "seek": 14056, "start": 146.0, "end": 157.36, "text": " ado, Eleazar Yudkowski, Gary Marcus, and Scott Aronson. Okay, Eleazar Yudkowski, Scott Aronson,", "tokens": [50636, 22450, 11, 8024, 22795, 398, 532, 74, 21866, 11, 13788, 26574, 11, 293, 6659, 1587, 892, 266, 13, 1033, 11, 8024, 22795, 398, 532, 74, 21866, 11, 6659, 1587, 892, 266, 11, 51204], "temperature": 0.0, "avg_logprob": -0.11638306155063138, "compression_ratio": 1.594142259414226, "no_speech_prob": 0.00941044557839632}, {"id": 30, "seek": 14056, "start": 157.36, "end": 164.16, "text": " Gary Marcus. Thanks so much for coming on my show. Thank you. The topic of today's conversation is", "tokens": [51204, 13788, 26574, 13, 2561, 370, 709, 337, 1348, 322, 452, 855, 13, 1044, 291, 13, 440, 4829, 295, 965, 311, 3761, 307, 51544], "temperature": 0.0, "avg_logprob": -0.11638306155063138, "compression_ratio": 1.594142259414226, "no_speech_prob": 0.00941044557839632}, {"id": 31, "seek": 14056, "start": 164.16, "end": 170.4, "text": " AI safety, and this is something that's been in the news lately. We've seen experts and", "tokens": [51544, 7318, 4514, 11, 293, 341, 307, 746, 300, 311, 668, 294, 264, 2583, 12881, 13, 492, 600, 1612, 8572, 293, 51856], "temperature": 0.0, "avg_logprob": -0.11638306155063138, "compression_ratio": 1.594142259414226, "no_speech_prob": 0.00941044557839632}, {"id": 32, "seek": 17056, "start": 170.72, "end": 180.88, "text": " CEOs signing letters, recommending public policy, surrounding regulation. We continue to have the", "tokens": [50372, 40736, 13393, 7825, 11, 30559, 1908, 3897, 11, 11498, 15062, 13, 492, 2354, 281, 362, 264, 50880], "temperature": 0.0, "avg_logprob": -0.1536179440362113, "compression_ratio": 1.4576271186440677, "no_speech_prob": 0.005551395006477833}, {"id": 33, "seek": 17056, "start": 180.88, "end": 188.32, "text": " debate between people that really fear AI is going to end the world and potentially kill", "tokens": [50880, 7958, 1296, 561, 300, 534, 4240, 7318, 307, 516, 281, 917, 264, 1002, 293, 7263, 1961, 51252], "temperature": 0.0, "avg_logprob": -0.1536179440362113, "compression_ratio": 1.4576271186440677, "no_speech_prob": 0.005551395006477833}, {"id": 34, "seek": 17056, "start": 188.96, "end": 194.56, "text": " all of humanity and the people who feel that those fears are overblown.", "tokens": [51284, 439, 295, 10243, 293, 264, 561, 567, 841, 300, 729, 15649, 366, 670, 5199, 648, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1536179440362113, "compression_ratio": 1.4576271186440677, "no_speech_prob": 0.005551395006477833}, {"id": 35, "seek": 19456, "start": 195.36, "end": 202.24, "text": " And so this is going to be sort of a roundtable conversation about that, and you three are", "tokens": [50404, 400, 370, 341, 307, 516, 281, 312, 1333, 295, 257, 3098, 23811, 3761, 466, 300, 11, 293, 291, 1045, 366, 50748], "temperature": 0.0, "avg_logprob": -0.14505685313364095, "compression_ratio": 1.6, "no_speech_prob": 0.13652728497982025}, {"id": 36, "seek": 19456, "start": 202.88, "end": 207.36, "text": " really three of the best people in the world to talk about it with. So thank you all for doing this.", "tokens": [50780, 534, 1045, 295, 264, 1151, 561, 294, 264, 1002, 281, 751, 466, 309, 365, 13, 407, 1309, 291, 439, 337, 884, 341, 13, 51004], "temperature": 0.0, "avg_logprob": -0.14505685313364095, "compression_ratio": 1.6, "no_speech_prob": 0.13652728497982025}, {"id": 37, "seek": 19456, "start": 208.96, "end": 213.84, "text": " Let's just start out with you, Eleazar, because you've been one of the most", "tokens": [51084, 961, 311, 445, 722, 484, 365, 291, 11, 8024, 22795, 11, 570, 291, 600, 668, 472, 295, 264, 881, 51328], "temperature": 0.0, "avg_logprob": -0.14505685313364095, "compression_ratio": 1.6, "no_speech_prob": 0.13652728497982025}, {"id": 38, "seek": 19456, "start": 215.36, "end": 221.04, "text": " really influential voices getting people to take seriously the possibility that AI will kill us all.", "tokens": [51404, 534, 22215, 9802, 1242, 561, 281, 747, 6638, 264, 7959, 300, 7318, 486, 1961, 505, 439, 13, 51688], "temperature": 0.0, "avg_logprob": -0.14505685313364095, "compression_ratio": 1.6, "no_speech_prob": 0.13652728497982025}, {"id": 39, "seek": 22104, "start": 221.92, "end": 227.76, "text": " You know, why is AI going to destroy us? Chat GPT seems pretty nice. I use it every day.", "tokens": [50408, 509, 458, 11, 983, 307, 7318, 516, 281, 5293, 505, 30, 27503, 26039, 51, 2544, 1238, 1481, 13, 286, 764, 309, 633, 786, 13, 50700], "temperature": 0.0, "avg_logprob": -0.13984306335449218, "compression_ratio": 1.5574468085106383, "no_speech_prob": 0.009264699183404446}, {"id": 40, "seek": 22104, "start": 227.76, "end": 236.16, "text": " What's the big fear here? Make the case. Well, chat GPT seems quite unlikely to kill everyone in", "tokens": [50700, 708, 311, 264, 955, 4240, 510, 30, 4387, 264, 1389, 13, 1042, 11, 5081, 26039, 51, 2544, 1596, 17518, 281, 1961, 1518, 294, 51120], "temperature": 0.0, "avg_logprob": -0.13984306335449218, "compression_ratio": 1.5574468085106383, "no_speech_prob": 0.009264699183404446}, {"id": 41, "seek": 22104, "start": 236.16, "end": 242.0, "text": " its present state. AI capabilities keep on advancing and advancing. The question is not,", "tokens": [51120, 1080, 1974, 1785, 13, 7318, 10862, 1066, 322, 27267, 293, 27267, 13, 440, 1168, 307, 406, 11, 51412], "temperature": 0.0, "avg_logprob": -0.13984306335449218, "compression_ratio": 1.5574468085106383, "no_speech_prob": 0.009264699183404446}, {"id": 42, "seek": 22104, "start": 242.0, "end": 249.35999999999999, "text": " can a chat GPT kill us? The answer is probably no. So as long as that's true, as long as it", "tokens": [51412, 393, 257, 5081, 26039, 51, 1961, 505, 30, 440, 1867, 307, 1391, 572, 13, 407, 382, 938, 382, 300, 311, 2074, 11, 382, 938, 382, 309, 51780], "temperature": 0.0, "avg_logprob": -0.13984306335449218, "compression_ratio": 1.5574468085106383, "no_speech_prob": 0.009264699183404446}, {"id": 43, "seek": 24936, "start": 249.44000000000003, "end": 255.44000000000003, "text": " hasn't killed us yet, the engineers are just going to keep pushing the capabilities. There's no", "tokens": [50368, 6132, 380, 4652, 505, 1939, 11, 264, 11955, 366, 445, 516, 281, 1066, 7380, 264, 10862, 13, 821, 311, 572, 50668], "temperature": 0.0, "avg_logprob": -0.08175867453388784, "compression_ratio": 1.5617021276595744, "no_speech_prob": 0.0013245275476947427}, {"id": 44, "seek": 24936, "start": 255.44000000000003, "end": 264.0, "text": " obvious blocking point. We don't understand the things that we build. The AIs are grown", "tokens": [50668, 6322, 17776, 935, 13, 492, 500, 380, 1223, 264, 721, 300, 321, 1322, 13, 440, 316, 6802, 366, 7709, 51096], "temperature": 0.0, "avg_logprob": -0.08175867453388784, "compression_ratio": 1.5617021276595744, "no_speech_prob": 0.0013245275476947427}, {"id": 45, "seek": 24936, "start": 264.56, "end": 269.52000000000004, "text": " more than built, you might say. They end up as giant inscrutable matrices of floating point", "tokens": [51124, 544, 813, 3094, 11, 291, 1062, 584, 13, 814, 917, 493, 382, 7410, 1028, 10757, 32148, 32284, 295, 12607, 935, 51372], "temperature": 0.0, "avg_logprob": -0.08175867453388784, "compression_ratio": 1.5617021276595744, "no_speech_prob": 0.0013245275476947427}, {"id": 46, "seek": 24936, "start": 269.52000000000004, "end": 276.40000000000003, "text": " numbers that nobody can decode. It's probably going to end up technically difficult to make", "tokens": [51372, 3547, 300, 5079, 393, 979, 1429, 13, 467, 311, 1391, 516, 281, 917, 493, 12120, 2252, 281, 652, 51716], "temperature": 0.0, "avg_logprob": -0.08175867453388784, "compression_ratio": 1.5617021276595744, "no_speech_prob": 0.0013245275476947427}, {"id": 47, "seek": 27640, "start": 276.4, "end": 283.84, "text": " them want particular things and not others. People are just charging straight ahead.", "tokens": [50364, 552, 528, 1729, 721, 293, 406, 2357, 13, 3432, 366, 445, 11379, 2997, 2286, 13, 50736], "temperature": 0.0, "avg_logprob": -0.06983963278836983, "compression_ratio": 1.662162162162162, "no_speech_prob": 0.014052530750632286}, {"id": 48, "seek": 27640, "start": 284.79999999999995, "end": 289.67999999999995, "text": " So at this rate, we end up with something that is smarter than us, smarter than humanity,", "tokens": [50784, 407, 412, 341, 3314, 11, 321, 917, 493, 365, 746, 300, 307, 20294, 813, 505, 11, 20294, 813, 10243, 11, 51028], "temperature": 0.0, "avg_logprob": -0.06983963278836983, "compression_ratio": 1.662162162162162, "no_speech_prob": 0.014052530750632286}, {"id": 49, "seek": 27640, "start": 290.4, "end": 297.2, "text": " that we don't understand, whose preferences we could not shape. And by default, if that happens,", "tokens": [51064, 300, 321, 500, 380, 1223, 11, 6104, 21910, 321, 727, 406, 3909, 13, 400, 538, 7576, 11, 498, 300, 2314, 11, 51404], "temperature": 0.0, "avg_logprob": -0.06983963278836983, "compression_ratio": 1.662162162162162, "no_speech_prob": 0.014052530750632286}, {"id": 50, "seek": 27640, "start": 297.2, "end": 301.59999999999997, "text": " if you have something around that is much smarter than you and does not care about you one way or", "tokens": [51404, 498, 291, 362, 746, 926, 300, 307, 709, 20294, 813, 291, 293, 775, 406, 1127, 466, 291, 472, 636, 420, 51624], "temperature": 0.0, "avg_logprob": -0.06983963278836983, "compression_ratio": 1.662162162162162, "no_speech_prob": 0.014052530750632286}, {"id": 51, "seek": 30160, "start": 301.6, "end": 308.40000000000003, "text": " the other, you probably end up dead at the end of that. The way it gets the most of whatever", "tokens": [50364, 264, 661, 11, 291, 1391, 917, 493, 3116, 412, 264, 917, 295, 300, 13, 440, 636, 309, 2170, 264, 881, 295, 2035, 50704], "temperature": 0.0, "avg_logprob": -0.0701677524126493, "compression_ratio": 1.6733067729083666, "no_speech_prob": 0.009706949815154076}, {"id": 52, "seek": 30160, "start": 308.40000000000003, "end": 314.64000000000004, "text": " strange inscrutable things that it wants are worlds in which there are not humans taking up", "tokens": [50704, 5861, 1028, 10757, 32148, 721, 300, 309, 2738, 366, 13401, 294, 597, 456, 366, 406, 6255, 1940, 493, 51016], "temperature": 0.0, "avg_logprob": -0.0701677524126493, "compression_ratio": 1.6733067729083666, "no_speech_prob": 0.009706949815154076}, {"id": 53, "seek": 30160, "start": 314.64000000000004, "end": 320.32000000000005, "text": " space, using up resources, building other AIs to compete with it, or just a world in which you", "tokens": [51016, 1901, 11, 1228, 493, 3593, 11, 2390, 661, 316, 6802, 281, 11831, 365, 309, 11, 420, 445, 257, 1002, 294, 597, 291, 51300], "temperature": 0.0, "avg_logprob": -0.0701677524126493, "compression_ratio": 1.6733067729083666, "no_speech_prob": 0.009706949815154076}, {"id": 54, "seek": 30160, "start": 320.32000000000005, "end": 324.48, "text": " built enough power plants that the surface of the earth got hot enough that humans didn't survive.", "tokens": [51300, 3094, 1547, 1347, 5972, 300, 264, 3753, 295, 264, 4120, 658, 2368, 1547, 300, 6255, 994, 380, 7867, 13, 51508], "temperature": 0.0, "avg_logprob": -0.0701677524126493, "compression_ratio": 1.6733067729083666, "no_speech_prob": 0.009706949815154076}, {"id": 55, "seek": 30160, "start": 325.68, "end": 326.88, "text": " Gary, what do you have to say about that?", "tokens": [51568, 13788, 11, 437, 360, 291, 362, 281, 584, 466, 300, 30, 51628], "temperature": 0.0, "avg_logprob": -0.0701677524126493, "compression_ratio": 1.6733067729083666, "no_speech_prob": 0.009706949815154076}, {"id": 56, "seek": 32688, "start": 327.84, "end": 334.56, "text": " There are parts that I agree with and parts that I don't. So I agree that we are likely to wind up", "tokens": [50412, 821, 366, 3166, 300, 286, 3986, 365, 293, 3166, 300, 286, 500, 380, 13, 407, 286, 3986, 300, 321, 366, 3700, 281, 2468, 493, 50748], "temperature": 0.0, "avg_logprob": -0.09685611724853516, "compression_ratio": 1.6359832635983265, "no_speech_prob": 0.001410083845257759}, {"id": 57, "seek": 32688, "start": 334.56, "end": 340.32, "text": " with AIs that are smarter than us. I don't think we're particularly close now, but in 10 years or", "tokens": [50748, 365, 316, 6802, 300, 366, 20294, 813, 505, 13, 286, 500, 380, 519, 321, 434, 4098, 1998, 586, 11, 457, 294, 1266, 924, 420, 51036], "temperature": 0.0, "avg_logprob": -0.09685611724853516, "compression_ratio": 1.6359832635983265, "no_speech_prob": 0.001410083845257759}, {"id": 58, "seek": 32688, "start": 340.32, "end": 346.32, "text": " 50 years or 100 years at some point, maybe a thousand years, but it will happen. I think there's a", "tokens": [51036, 2625, 924, 420, 2319, 924, 412, 512, 935, 11, 1310, 257, 4714, 924, 11, 457, 309, 486, 1051, 13, 286, 519, 456, 311, 257, 51336], "temperature": 0.0, "avg_logprob": -0.09685611724853516, "compression_ratio": 1.6359832635983265, "no_speech_prob": 0.001410083845257759}, {"id": 59, "seek": 32688, "start": 346.32, "end": 351.68, "text": " lot of anthropomorphization there about machines wanting things. Of course, they have objective", "tokens": [51336, 688, 295, 22727, 32702, 2144, 456, 466, 8379, 7935, 721, 13, 2720, 1164, 11, 436, 362, 10024, 51604], "temperature": 0.0, "avg_logprob": -0.09685611724853516, "compression_ratio": 1.6359832635983265, "no_speech_prob": 0.001410083845257759}, {"id": 60, "seek": 35168, "start": 351.68, "end": 358.72, "text": " functions and we can talk about that. I think it's a presumption to say that the default is that", "tokens": [50364, 6828, 293, 321, 393, 751, 466, 300, 13, 286, 519, 309, 311, 257, 18028, 1695, 281, 584, 300, 264, 7576, 307, 300, 50716], "temperature": 0.0, "avg_logprob": -0.07604261320464466, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.061764735728502274}, {"id": 61, "seek": 35168, "start": 358.72, "end": 363.52, "text": " they're going to want something that leads to our demise and that they're going to be effective at", "tokens": [50716, 436, 434, 516, 281, 528, 746, 300, 6689, 281, 527, 45982, 293, 300, 436, 434, 516, 281, 312, 4942, 412, 50956], "temperature": 0.0, "avg_logprob": -0.07604261320464466, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.061764735728502274}, {"id": 62, "seek": 35168, "start": 363.52, "end": 370.72, "text": " that and be able to literally kill us all. I think if you look at the history of AI at least so far,", "tokens": [50956, 300, 293, 312, 1075, 281, 3736, 1961, 505, 439, 13, 286, 519, 498, 291, 574, 412, 264, 2503, 295, 7318, 412, 1935, 370, 1400, 11, 51316], "temperature": 0.0, "avg_logprob": -0.07604261320464466, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.061764735728502274}, {"id": 63, "seek": 35168, "start": 371.28000000000003, "end": 376.32, "text": " they don't really have wants beyond what we program them to do. There is an alignment problem. I", "tokens": [51344, 436, 500, 380, 534, 362, 2738, 4399, 437, 321, 1461, 552, 281, 360, 13, 821, 307, 364, 18515, 1154, 13, 286, 51596], "temperature": 0.0, "avg_logprob": -0.07604261320464466, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.061764735728502274}, {"id": 64, "seek": 37632, "start": 376.32, "end": 381.84, "text": " think that that's real in the sense of people who program a system to do X and they do X prime.", "tokens": [50364, 519, 300, 300, 311, 957, 294, 264, 2020, 295, 561, 567, 1461, 257, 1185, 281, 360, 1783, 293, 436, 360, 1783, 5835, 13, 50640], "temperature": 0.0, "avg_logprob": -0.12379071807861328, "compression_ratio": 1.7773722627737227, "no_speech_prob": 0.007934773340821266}, {"id": 65, "seek": 37632, "start": 381.84, "end": 386.64, "text": " That's kind of like X, but not exactly. I think there's really things to worry about. I think", "tokens": [50640, 663, 311, 733, 295, 411, 1783, 11, 457, 406, 2293, 13, 286, 519, 456, 311, 534, 721, 281, 3292, 466, 13, 286, 519, 50880], "temperature": 0.0, "avg_logprob": -0.12379071807861328, "compression_ratio": 1.7773722627737227, "no_speech_prob": 0.007934773340821266}, {"id": 66, "seek": 37632, "start": 386.64, "end": 393.6, "text": " there's a real research program here that is under-researched, which is the way I would put it", "tokens": [50880, 456, 311, 257, 957, 2132, 1461, 510, 300, 307, 833, 12, 49838, 1178, 292, 11, 597, 307, 264, 636, 286, 576, 829, 309, 51228], "temperature": 0.0, "avg_logprob": -0.12379071807861328, "compression_ratio": 1.7773722627737227, "no_speech_prob": 0.007934773340821266}, {"id": 67, "seek": 37632, "start": 393.6, "end": 398.48, "text": " is we want to understand how to make machines that have values. Asimov's laws are way too simple,", "tokens": [51228, 307, 321, 528, 281, 1223, 577, 281, 652, 8379, 300, 362, 4190, 13, 1018, 332, 5179, 311, 6064, 366, 636, 886, 2199, 11, 51472], "temperature": 0.0, "avg_logprob": -0.12379071807861328, "compression_ratio": 1.7773722627737227, "no_speech_prob": 0.007934773340821266}, {"id": 68, "seek": 37632, "start": 398.48, "end": 404.4, "text": " but they're kind of starting point for conversation. We want to program machines that don't harm humans.", "tokens": [51472, 457, 436, 434, 733, 295, 2891, 935, 337, 3761, 13, 492, 528, 281, 1461, 8379, 300, 500, 380, 6491, 6255, 13, 51768], "temperature": 0.0, "avg_logprob": -0.12379071807861328, "compression_ratio": 1.7773722627737227, "no_speech_prob": 0.007934773340821266}, {"id": 69, "seek": 40440, "start": 404.4, "end": 409.28, "text": " They can calculate the consequences of their actions. Right now, we have technology like", "tokens": [50364, 814, 393, 8873, 264, 10098, 295, 641, 5909, 13, 1779, 586, 11, 321, 362, 2899, 411, 50608], "temperature": 0.0, "avg_logprob": -0.10794600065764007, "compression_ratio": 1.6845878136200716, "no_speech_prob": 0.0034272014163434505}, {"id": 70, "seek": 40440, "start": 409.28, "end": 413.84, "text": " GPT-4 that has no idea what the consequences of its actions are. It doesn't really anticipate things.", "tokens": [50608, 26039, 51, 12, 19, 300, 575, 572, 1558, 437, 264, 10098, 295, 1080, 5909, 366, 13, 467, 1177, 380, 534, 21685, 721, 13, 50836], "temperature": 0.0, "avg_logprob": -0.10794600065764007, "compression_ratio": 1.6845878136200716, "no_speech_prob": 0.0034272014163434505}, {"id": 71, "seek": 40440, "start": 414.71999999999997, "end": 418.47999999999996, "text": " There's a separate thing that Eliezer didn't emphasize, which is it's not just how smart the", "tokens": [50880, 821, 311, 257, 4994, 551, 300, 2699, 414, 4527, 994, 380, 16078, 11, 597, 307, 309, 311, 406, 445, 577, 4069, 264, 51068], "temperature": 0.0, "avg_logprob": -0.10794600065764007, "compression_ratio": 1.6845878136200716, "no_speech_prob": 0.0034272014163434505}, {"id": 72, "seek": 40440, "start": 418.47999999999996, "end": 423.35999999999996, "text": " machines are, but how much power we give them. How much we empower them to do things like access", "tokens": [51068, 8379, 366, 11, 457, 577, 709, 1347, 321, 976, 552, 13, 1012, 709, 321, 11071, 552, 281, 360, 721, 411, 2105, 51312], "temperature": 0.0, "avg_logprob": -0.10794600065764007, "compression_ratio": 1.6845878136200716, "no_speech_prob": 0.0034272014163434505}, {"id": 73, "seek": 40440, "start": 423.35999999999996, "end": 432.08, "text": " the internet or manipulate people or write source code, access files and stuff like that.", "tokens": [51312, 264, 4705, 420, 20459, 561, 420, 2464, 4009, 3089, 11, 2105, 7098, 293, 1507, 411, 300, 13, 51748], "temperature": 0.0, "avg_logprob": -0.10794600065764007, "compression_ratio": 1.6845878136200716, "no_speech_prob": 0.0034272014163434505}, {"id": 74, "seek": 43208, "start": 432.08, "end": 436.56, "text": " Right now, auto-GPT can do all of those things and that's actually pretty disconcerting to me.", "tokens": [50364, 1779, 586, 11, 8399, 12, 38, 47, 51, 393, 360, 439, 295, 729, 721, 293, 300, 311, 767, 1238, 717, 1671, 1776, 783, 281, 385, 13, 50588], "temperature": 0.0, "avg_logprob": -0.08361004988352458, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.004467294551432133}, {"id": 75, "seek": 43208, "start": 436.56, "end": 442.96, "text": " To me, that doesn't all add up to any kind of extinction risk anytime soon, but catastrophic", "tokens": [50588, 1407, 385, 11, 300, 1177, 380, 439, 909, 493, 281, 604, 733, 295, 33163, 3148, 13038, 2321, 11, 457, 34915, 50908], "temperature": 0.0, "avg_logprob": -0.08361004988352458, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.004467294551432133}, {"id": 76, "seek": 43208, "start": 442.96, "end": 448.24, "text": " risk where things go pretty wrong because we wanted these systems to do X and we didn't really", "tokens": [50908, 3148, 689, 721, 352, 1238, 2085, 570, 321, 1415, 613, 3652, 281, 360, 1783, 293, 321, 994, 380, 534, 51172], "temperature": 0.0, "avg_logprob": -0.08361004988352458, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.004467294551432133}, {"id": 77, "seek": 43208, "start": 448.24, "end": 452.56, "text": " specify it well. They don't really understand our intentions. I think there are risks like that.", "tokens": [51172, 16500, 309, 731, 13, 814, 500, 380, 534, 1223, 527, 19354, 13, 286, 519, 456, 366, 10888, 411, 300, 13, 51388], "temperature": 0.0, "avg_logprob": -0.08361004988352458, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.004467294551432133}, {"id": 78, "seek": 43208, "start": 452.56, "end": 457.52, "text": " I don't see it as a default that we wind up with extinction. I think it's pretty hard to actually", "tokens": [51388, 286, 500, 380, 536, 309, 382, 257, 7576, 300, 321, 2468, 493, 365, 33163, 13, 286, 519, 309, 311, 1238, 1152, 281, 767, 51636], "temperature": 0.0, "avg_logprob": -0.08361004988352458, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.004467294551432133}, {"id": 79, "seek": 45752, "start": 457.52, "end": 462.08, "text": " terminate the entire human species. You're going to have people in Antarctica that are going to be", "tokens": [50364, 10761, 473, 264, 2302, 1952, 6172, 13, 509, 434, 516, 281, 362, 561, 294, 39866, 300, 366, 516, 281, 312, 50592], "temperature": 0.0, "avg_logprob": -0.07573395281766368, "compression_ratio": 1.70863309352518, "no_speech_prob": 0.2625484764575958}, {"id": 80, "seek": 45752, "start": 462.08, "end": 466.79999999999995, "text": " out of harm's way or whatever, or you're going to have some people who respond differently to any", "tokens": [50592, 484, 295, 6491, 311, 636, 420, 2035, 11, 420, 291, 434, 516, 281, 362, 512, 561, 567, 4196, 7614, 281, 604, 50828], "temperature": 0.0, "avg_logprob": -0.07573395281766368, "compression_ratio": 1.70863309352518, "no_speech_prob": 0.2625484764575958}, {"id": 81, "seek": 45752, "start": 466.79999999999995, "end": 473.84, "text": " pathogen, et cetera. Extinction is a pretty extreme outcome that I don't think is particularly", "tokens": [50828, 3100, 8799, 11, 1030, 11458, 13, 9881, 12987, 307, 257, 1238, 8084, 9700, 300, 286, 500, 380, 519, 307, 4098, 51180], "temperature": 0.0, "avg_logprob": -0.07573395281766368, "compression_ratio": 1.70863309352518, "no_speech_prob": 0.2625484764575958}, {"id": 82, "seek": 45752, "start": 473.84, "end": 479.35999999999996, "text": " likely, but the possibility that these machines will cause mayhem because we don't know how to", "tokens": [51180, 3700, 11, 457, 264, 7959, 300, 613, 8379, 486, 3082, 815, 28005, 570, 321, 500, 380, 458, 577, 281, 51456], "temperature": 0.0, "avg_logprob": -0.07573395281766368, "compression_ratio": 1.70863309352518, "no_speech_prob": 0.2625484764575958}, {"id": 83, "seek": 45752, "start": 480.56, "end": 484.56, "text": " enforce that they do what we want them to do. I think that's a real thing to worry about", "tokens": [51516, 24825, 300, 436, 360, 437, 321, 528, 552, 281, 360, 13, 286, 519, 300, 311, 257, 957, 551, 281, 3292, 466, 51716], "temperature": 0.0, "avg_logprob": -0.07573395281766368, "compression_ratio": 1.70863309352518, "no_speech_prob": 0.2625484764575958}, {"id": 84, "seek": 48456, "start": 484.56, "end": 487.44, "text": " and it's certainly worth doing research on. Scott, how do you view this?", "tokens": [50364, 293, 309, 311, 3297, 3163, 884, 2132, 322, 13, 6659, 11, 577, 360, 291, 1910, 341, 30, 50508], "temperature": 0.0, "avg_logprob": -0.09525498782887179, "compression_ratio": 1.5614035087719298, "no_speech_prob": 0.0021483954042196274}, {"id": 85, "seek": 48456, "start": 488.72, "end": 493.28000000000003, "text": " Yeah, so I'm sure that you can get the three of us arguing about something, but I think you're", "tokens": [50572, 865, 11, 370, 286, 478, 988, 300, 291, 393, 483, 264, 1045, 295, 505, 19697, 466, 746, 11, 457, 286, 519, 291, 434, 50800], "temperature": 0.0, "avg_logprob": -0.09525498782887179, "compression_ratio": 1.5614035087719298, "no_speech_prob": 0.0021483954042196274}, {"id": 86, "seek": 48456, "start": 493.28000000000003, "end": 500.56, "text": " going to get agreement from all three of us that AI safety is important and that catastrophic outcomes,", "tokens": [50800, 516, 281, 483, 8106, 490, 439, 1045, 295, 505, 300, 7318, 4514, 307, 1021, 293, 300, 34915, 10070, 11, 51164], "temperature": 0.0, "avg_logprob": -0.09525498782887179, "compression_ratio": 1.5614035087719298, "no_speech_prob": 0.0021483954042196274}, {"id": 87, "seek": 48456, "start": 501.36, "end": 508.96, "text": " whether or not that means literal human extinction are possible. I think it's become", "tokens": [51204, 1968, 420, 406, 300, 1355, 20411, 1952, 33163, 366, 1944, 13, 286, 519, 309, 311, 1813, 51584], "temperature": 0.0, "avg_logprob": -0.09525498782887179, "compression_ratio": 1.5614035087719298, "no_speech_prob": 0.0021483954042196274}, {"id": 88, "seek": 50896, "start": 509.68, "end": 520.64, "text": " apparent over the last few years that this century is going to be largely defined by our", "tokens": [50400, 18335, 670, 264, 1036, 1326, 924, 300, 341, 4901, 307, 516, 281, 312, 11611, 7642, 538, 527, 50948], "temperature": 0.0, "avg_logprob": -0.13185102431500545, "compression_ratio": 1.502824858757062, "no_speech_prob": 0.008058023639023304}, {"id": 89, "seek": 50896, "start": 520.64, "end": 527.28, "text": " interaction with AI, that AI is going to be transformative for human civilization.", "tokens": [50948, 9285, 365, 7318, 11, 300, 7318, 307, 516, 281, 312, 36070, 337, 1952, 18036, 13, 51280], "temperature": 0.0, "avg_logprob": -0.13185102431500545, "compression_ratio": 1.502824858757062, "no_speech_prob": 0.008058023639023304}, {"id": 90, "seek": 50896, "start": 531.52, "end": 538.0799999999999, "text": " I'm confident of that much. If you ask me almost anything beyond that about how is it going to", "tokens": [51492, 286, 478, 6679, 295, 300, 709, 13, 759, 291, 1029, 385, 1920, 1340, 4399, 300, 466, 577, 307, 309, 516, 281, 51820], "temperature": 0.0, "avg_logprob": -0.13185102431500545, "compression_ratio": 1.502824858757062, "no_speech_prob": 0.008058023639023304}, {"id": 91, "seek": 53808, "start": 538.08, "end": 546.48, "text": " transform civilization? Will it be good? Will it be bad? What will the AI want? I am pretty agnostic", "tokens": [50364, 4088, 18036, 30, 3099, 309, 312, 665, 30, 3099, 309, 312, 1578, 30, 708, 486, 264, 7318, 528, 30, 286, 669, 1238, 623, 77, 19634, 50784], "temperature": 0.0, "avg_logprob": -0.09091898642088238, "compression_ratio": 1.4720812182741116, "no_speech_prob": 0.004751029424369335}, {"id": 92, "seek": 53808, "start": 546.48, "end": 553.84, "text": " just because if you would ask me 20 years ago to try to forecast where we are now, I would have", "tokens": [50784, 445, 570, 498, 291, 576, 1029, 385, 945, 924, 2057, 281, 853, 281, 14330, 689, 321, 366, 586, 11, 286, 576, 362, 51152], "temperature": 0.0, "avg_logprob": -0.09091898642088238, "compression_ratio": 1.4720812182741116, "no_speech_prob": 0.004751029424369335}, {"id": 93, "seek": 53808, "start": 553.84, "end": 562.5600000000001, "text": " gotten a lot wrong. My only defense is I think that all of us here and almost everyone in the", "tokens": [51152, 5768, 257, 688, 2085, 13, 1222, 787, 7654, 307, 286, 519, 300, 439, 295, 505, 510, 293, 1920, 1518, 294, 264, 51588], "temperature": 0.0, "avg_logprob": -0.09091898642088238, "compression_ratio": 1.4720812182741116, "no_speech_prob": 0.004751029424369335}, {"id": 94, "seek": 56256, "start": 562.56, "end": 569.76, "text": " world would have gotten a lot wrong about where we are now. If I try to envision where we are in", "tokens": [50364, 1002, 576, 362, 5768, 257, 688, 2085, 466, 689, 321, 366, 586, 13, 759, 286, 853, 281, 24739, 689, 321, 366, 294, 50724], "temperature": 0.0, "avg_logprob": -0.10027828021925322, "compression_ratio": 1.3591549295774648, "no_speech_prob": 0.06843894720077515}, {"id": 95, "seek": 56256, "start": 570.4799999999999, "end": 581.68, "text": " 2043, does the AI want to replace humanity with something better? Does it want to keep us around", "tokens": [50760, 945, 17201, 11, 775, 264, 7318, 528, 281, 7406, 10243, 365, 746, 1101, 30, 4402, 309, 528, 281, 1066, 505, 926, 51320], "temperature": 0.0, "avg_logprob": -0.10027828021925322, "compression_ratio": 1.3591549295774648, "no_speech_prob": 0.06843894720077515}, {"id": 96, "seek": 58168, "start": 581.68, "end": 593.5999999999999, "text": " as pets? Does it want to just continue helping us out like just a super souped up version of", "tokens": [50364, 382, 19897, 30, 4402, 309, 528, 281, 445, 2354, 4315, 505, 484, 411, 445, 257, 1687, 7884, 292, 493, 3037, 295, 50960], "temperature": 0.0, "avg_logprob": -0.12902212142944336, "compression_ratio": 1.4690721649484537, "no_speech_prob": 0.2015213966369629}, {"id": 97, "seek": 58168, "start": 593.5999999999999, "end": 603.04, "text": " chat GPT? I think all of those scenarios merit consideration, but I think that what has happened", "tokens": [50960, 5081, 26039, 51, 30, 286, 519, 439, 295, 729, 15077, 24527, 12381, 11, 457, 286, 519, 300, 437, 575, 2011, 51432], "temperature": 0.0, "avg_logprob": -0.12902212142944336, "compression_ratio": 1.4690721649484537, "no_speech_prob": 0.2015213966369629}, {"id": 98, "seek": 58168, "start": 603.04, "end": 610.24, "text": " in the last few years that's really exciting is that AI safety has become an empirical subject.", "tokens": [51432, 294, 264, 1036, 1326, 924, 300, 311, 534, 4670, 307, 300, 7318, 4514, 575, 1813, 364, 31886, 3983, 13, 51792], "temperature": 0.0, "avg_logprob": -0.12902212142944336, "compression_ratio": 1.4690721649484537, "no_speech_prob": 0.2015213966369629}, {"id": 99, "seek": 61024, "start": 610.88, "end": 617.2, "text": " There are these very powerful AIs that are now being deployed and we can actually learn something.", "tokens": [50396, 821, 366, 613, 588, 4005, 316, 6802, 300, 366, 586, 885, 17826, 293, 321, 393, 767, 1466, 746, 13, 50712], "temperature": 0.0, "avg_logprob": -0.14374016353062222, "compression_ratio": 1.5691489361702127, "no_speech_prob": 0.003373239189386368}, {"id": 100, "seek": 61024, "start": 618.0, "end": 628.16, "text": " We can work on mitigating the nearer-term harms, not because the existential risk doesn't exist or", "tokens": [50752, 492, 393, 589, 322, 15699, 990, 264, 2651, 260, 12, 7039, 48505, 11, 406, 570, 264, 37133, 3148, 1177, 380, 2514, 420, 51260], "temperature": 0.0, "avg_logprob": -0.14374016353062222, "compression_ratio": 1.5691489361702127, "no_speech_prob": 0.003373239189386368}, {"id": 101, "seek": 61024, "start": 628.16, "end": 636.16, "text": " is absurd or is science fiction or anything like that, but just because the nearer-term harms are", "tokens": [51260, 307, 19774, 420, 307, 3497, 13266, 420, 1340, 411, 300, 11, 457, 445, 570, 264, 2651, 260, 12, 7039, 48505, 366, 51660], "temperature": 0.0, "avg_logprob": -0.14374016353062222, "compression_ratio": 1.5691489361702127, "no_speech_prob": 0.003373239189386368}, {"id": 102, "seek": 63616, "start": 636.16, "end": 641.4399999999999, "text": " the ones that we can see right in front of us and where we can actually get feedback from the", "tokens": [50364, 264, 2306, 300, 321, 393, 536, 558, 294, 1868, 295, 505, 293, 689, 321, 393, 767, 483, 5824, 490, 264, 50628], "temperature": 0.0, "avg_logprob": -0.11277325336749737, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.04205649346113205}, {"id": 103, "seek": 63616, "start": 641.4399999999999, "end": 647.28, "text": " external world about how we're doing. We can learn something and hopefully some of the knowledge", "tokens": [50628, 8320, 1002, 466, 577, 321, 434, 884, 13, 492, 393, 1466, 746, 293, 4696, 512, 295, 264, 3601, 50920], "temperature": 0.0, "avg_logprob": -0.11277325336749737, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.04205649346113205}, {"id": 104, "seek": 63616, "start": 647.28, "end": 653.6, "text": " that we gain will be useful in addressing the longer-term risks that I think Eliezer is very", "tokens": [50920, 300, 321, 6052, 486, 312, 4420, 294, 14329, 264, 2854, 12, 7039, 10888, 300, 286, 519, 2699, 414, 4527, 307, 588, 51236], "temperature": 0.0, "avg_logprob": -0.11277325336749737, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.04205649346113205}, {"id": 105, "seek": 63616, "start": 653.6, "end": 659.4399999999999, "text": " rightly worried about. Seems to me there's alignment and then there's alignment. There's", "tokens": [51236, 32879, 5804, 466, 13, 22524, 281, 385, 456, 311, 18515, 293, 550, 456, 311, 18515, 13, 821, 311, 51528], "temperature": 0.0, "avg_logprob": -0.11277325336749737, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.04205649346113205}, {"id": 106, "seek": 63616, "start": 659.4399999999999, "end": 665.28, "text": " alignment in the sense that we haven't even fully aligned smartphone technology with our", "tokens": [51528, 18515, 294, 264, 2020, 300, 321, 2378, 380, 754, 4498, 17962, 13307, 2899, 365, 527, 51820], "temperature": 0.0, "avg_logprob": -0.11277325336749737, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.04205649346113205}, {"id": 107, "seek": 66528, "start": 665.28, "end": 673.6, "text": " interests. There are some ways in which smartphones and social media have led to probably deleterious", "tokens": [50364, 8847, 13, 821, 366, 512, 2098, 294, 597, 26782, 293, 2093, 3021, 362, 4684, 281, 1391, 1103, 2398, 851, 50780], "temperature": 0.0, "avg_logprob": -0.11629120111465455, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.009409338235855103}, {"id": 108, "seek": 66528, "start": 673.6, "end": 681.28, "text": " mental health outcomes, especially for teenage girls, for example. There are those kinds of", "tokens": [50780, 4973, 1585, 10070, 11, 2318, 337, 26866, 4519, 11, 337, 1365, 13, 821, 366, 729, 3685, 295, 51164], "temperature": 0.0, "avg_logprob": -0.11629120111465455, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.009409338235855103}, {"id": 109, "seek": 66528, "start": 681.28, "end": 687.92, "text": " mundane senses of alignment where it's like, is this technology doing more good than harm", "tokens": [51164, 43497, 17057, 295, 18515, 689, 309, 311, 411, 11, 307, 341, 2899, 884, 544, 665, 813, 6491, 51496], "temperature": 0.0, "avg_logprob": -0.11629120111465455, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.009409338235855103}, {"id": 110, "seek": 66528, "start": 687.92, "end": 693.4399999999999, "text": " in the normal everyday public policy sense? Then there's the capital A alignment of,", "tokens": [51496, 294, 264, 2710, 7429, 1908, 3897, 2020, 30, 1396, 456, 311, 264, 4238, 316, 18515, 295, 11, 51772], "temperature": 0.0, "avg_logprob": -0.11629120111465455, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.009409338235855103}, {"id": 111, "seek": 69344, "start": 694.1600000000001, "end": 701.36, "text": " are we creating a creature that is going to view us like ants and have no problem", "tokens": [50400, 366, 321, 4084, 257, 12797, 300, 307, 516, 281, 1910, 505, 411, 23355, 293, 362, 572, 1154, 50760], "temperature": 0.0, "avg_logprob": -0.10193856557210286, "compression_ratio": 1.6242424242424243, "no_speech_prob": 0.010649394243955612}, {"id": 112, "seek": 69344, "start": 703.9200000000001, "end": 712.24, "text": " extinguishing us and whether intentional or not? It seems to me all of you agree that", "tokens": [50888, 33829, 84, 3807, 505, 293, 1968, 21935, 420, 406, 30, 467, 2544, 281, 385, 439, 295, 291, 3986, 300, 51304], "temperature": 0.0, "avg_logprob": -0.10193856557210286, "compression_ratio": 1.6242424242424243, "no_speech_prob": 0.010649394243955612}, {"id": 113, "seek": 69344, "start": 713.9200000000001, "end": 719.0400000000001, "text": " the first sense of alignment is at the very least something to worry about now and something to deal", "tokens": [51388, 264, 700, 2020, 295, 18515, 307, 412, 264, 588, 1935, 746, 281, 3292, 466, 586, 293, 746, 281, 2028, 51644], "temperature": 0.0, "avg_logprob": -0.10193856557210286, "compression_ratio": 1.6242424242424243, "no_speech_prob": 0.010649394243955612}, {"id": 114, "seek": 71904, "start": 719.76, "end": 725.04, "text": " with, but I'm curious to what extent you think the really capital A sense of alignment", "tokens": [50400, 365, 11, 457, 286, 478, 6369, 281, 437, 8396, 291, 519, 264, 534, 4238, 316, 2020, 295, 18515, 50664], "temperature": 0.0, "avg_logprob": -0.09511840217991879, "compression_ratio": 1.504, "no_speech_prob": 0.02366809733211994}, {"id": 115, "seek": 71904, "start": 725.8399999999999, "end": 731.36, "text": " is a real problem because it can sound very much like science fiction to people. Maybe let's start", "tokens": [50704, 307, 257, 957, 1154, 570, 309, 393, 1626, 588, 709, 411, 3497, 13266, 281, 561, 13, 2704, 718, 311, 722, 50980], "temperature": 0.0, "avg_logprob": -0.09511840217991879, "compression_ratio": 1.504, "no_speech_prob": 0.02366809733211994}, {"id": 116, "seek": 71904, "start": 731.36, "end": 740.56, "text": " with Eliezer. From my perspective, I would say that if we had a solid guarantee that AI was going", "tokens": [50980, 365, 2699, 414, 4527, 13, 3358, 452, 4585, 11, 286, 576, 584, 300, 498, 321, 632, 257, 5100, 10815, 300, 7318, 390, 516, 51440], "temperature": 0.0, "avg_logprob": -0.09511840217991879, "compression_ratio": 1.504, "no_speech_prob": 0.02366809733211994}, {"id": 117, "seek": 71904, "start": 740.56, "end": 747.12, "text": " to do no more harm than social media, we ought to plow ahead and get all the gains. It's not", "tokens": [51440, 281, 360, 572, 544, 6491, 813, 2093, 3021, 11, 321, 13416, 281, 499, 305, 2286, 293, 483, 439, 264, 16823, 13, 467, 311, 406, 51768], "temperature": 0.0, "avg_logprob": -0.09511840217991879, "compression_ratio": 1.504, "no_speech_prob": 0.02366809733211994}, {"id": 118, "seek": 74712, "start": 747.12, "end": 752.32, "text": " enough harm to back this amount of harm that social media has done to humanity, while very", "tokens": [50364, 1547, 6491, 281, 646, 341, 2372, 295, 6491, 300, 2093, 3021, 575, 1096, 281, 10243, 11, 1339, 588, 50624], "temperature": 0.0, "avg_logprob": -0.11048758927211967, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.006482718512415886}, {"id": 119, "seek": 74712, "start": 752.32, "end": 758.88, "text": " significant in my view. I think it's done a lot of damage to our sanity, but that's just not a", "tokens": [50624, 4776, 294, 452, 1910, 13, 286, 519, 309, 311, 1096, 257, 688, 295, 4344, 281, 527, 47892, 11, 457, 300, 311, 445, 406, 257, 50952], "temperature": 0.0, "avg_logprob": -0.11048758927211967, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.006482718512415886}, {"id": 120, "seek": 74712, "start": 758.88, "end": 765.12, "text": " large enough harm to justify either foregoing the gains that you could get from AI if that was going", "tokens": [50952, 2416, 1547, 6491, 281, 20833, 2139, 2091, 8102, 264, 16823, 300, 291, 727, 483, 490, 7318, 498, 300, 390, 516, 51264], "temperature": 0.0, "avg_logprob": -0.11048758927211967, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.006482718512415886}, {"id": 121, "seek": 74712, "start": 765.12, "end": 772.64, "text": " to be the worst downside or to justify the kind of drastic measures you'd need to stop plowing ahead", "tokens": [51264, 281, 312, 264, 5855, 25060, 420, 281, 20833, 264, 733, 295, 36821, 8000, 291, 1116, 643, 281, 1590, 499, 9637, 2286, 51640], "temperature": 0.0, "avg_logprob": -0.11048758927211967, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.006482718512415886}, {"id": 122, "seek": 77264, "start": 772.72, "end": 783.28, "text": " on AI. I think that the capital A alignment is beyond this generation. I've started the field,", "tokens": [50368, 322, 7318, 13, 286, 519, 300, 264, 4238, 316, 18515, 307, 4399, 341, 5125, 13, 286, 600, 1409, 264, 2519, 11, 50896], "temperature": 0.0, "avg_logprob": -0.09387220655168806, "compression_ratio": 1.5260416666666667, "no_speech_prob": 0.03253881633281708}, {"id": 123, "seek": 77264, "start": 783.28, "end": 793.04, "text": " I've watched over it for two decades. I feel like in some ways the modern generation plowing in with", "tokens": [50896, 286, 600, 6337, 670, 309, 337, 732, 7878, 13, 286, 841, 411, 294, 512, 2098, 264, 4363, 5125, 499, 9637, 294, 365, 51384], "temperature": 0.0, "avg_logprob": -0.09387220655168806, "compression_ratio": 1.5260416666666667, "no_speech_prob": 0.03253881633281708}, {"id": 124, "seek": 77264, "start": 793.04, "end": 798.72, "text": " their eyes on the short term stuff is like losing track of the larger problems because they can't", "tokens": [51384, 641, 2575, 322, 264, 2099, 1433, 1507, 307, 411, 7027, 2837, 295, 264, 4833, 2740, 570, 436, 393, 380, 51668], "temperature": 0.0, "avg_logprob": -0.09387220655168806, "compression_ratio": 1.5260416666666667, "no_speech_prob": 0.03253881633281708}, {"id": 125, "seek": 79872, "start": 798.72, "end": 803.52, "text": " solve the larger problems and they can't solve the little problems, but we're just like plowing", "tokens": [50364, 5039, 264, 4833, 2740, 293, 436, 393, 380, 5039, 264, 707, 2740, 11, 457, 321, 434, 445, 411, 499, 9637, 50604], "temperature": 0.0, "avg_logprob": -0.07584416745889067, "compression_ratio": 1.9340101522842639, "no_speech_prob": 0.014951178804039955}, {"id": 126, "seek": 79872, "start": 803.52, "end": 808.08, "text": " straight into the big problems and we're going to go plow right into the big problems with a bunch", "tokens": [50604, 2997, 666, 264, 955, 2740, 293, 321, 434, 516, 281, 352, 499, 305, 558, 666, 264, 955, 2740, 365, 257, 3840, 50832], "temperature": 0.0, "avg_logprob": -0.07584416745889067, "compression_ratio": 1.9340101522842639, "no_speech_prob": 0.014951178804039955}, {"id": 127, "seek": 79872, "start": 808.08, "end": 813.52, "text": " of little solutions that aren't going to scale. I think it's lethal. I think it's at the scale", "tokens": [50832, 295, 707, 6547, 300, 3212, 380, 516, 281, 4373, 13, 286, 519, 309, 311, 34562, 13, 286, 519, 309, 311, 412, 264, 4373, 51104], "temperature": 0.0, "avg_logprob": -0.07584416745889067, "compression_ratio": 1.9340101522842639, "no_speech_prob": 0.014951178804039955}, {"id": 128, "seek": 79872, "start": 813.52, "end": 819.28, "text": " where you just back off and don't do this. By back off and don't do this, what do you mean?", "tokens": [51104, 689, 291, 445, 646, 766, 293, 500, 380, 360, 341, 13, 3146, 646, 766, 293, 500, 380, 360, 341, 11, 437, 360, 291, 914, 30, 51392], "temperature": 0.0, "avg_logprob": -0.07584416745889067, "compression_ratio": 1.9340101522842639, "no_speech_prob": 0.014951178804039955}, {"id": 129, "seek": 81928, "start": 820.0, "end": 828.9599999999999, "text": " I mean have an international treaty about where the chips capable of doing AI training go", "tokens": [50400, 286, 914, 362, 364, 5058, 24772, 466, 689, 264, 11583, 8189, 295, 884, 7318, 3097, 352, 50848], "temperature": 0.0, "avg_logprob": -0.12546769777933756, "compression_ratio": 1.481283422459893, "no_speech_prob": 0.08029471337795258}, {"id": 130, "seek": 81928, "start": 829.76, "end": 839.92, "text": " and have them all going into licensed monitored data centers and not have the training runs for", "tokens": [50888, 293, 362, 552, 439, 516, 666, 25225, 36255, 1412, 10898, 293, 406, 362, 264, 3097, 6676, 337, 51396], "temperature": 0.0, "avg_logprob": -0.12546769777933756, "compression_ratio": 1.481283422459893, "no_speech_prob": 0.08029471337795258}, {"id": 131, "seek": 81928, "start": 839.92, "end": 845.68, "text": " AIs more powerful than GPT-4, possibly even lowering that threshold over time as algorithms", "tokens": [51396, 316, 6802, 544, 4005, 813, 26039, 51, 12, 19, 11, 6264, 754, 28124, 300, 14678, 670, 565, 382, 14642, 51684], "temperature": 0.0, "avg_logprob": -0.12546769777933756, "compression_ratio": 1.481283422459893, "no_speech_prob": 0.08029471337795258}, {"id": 132, "seek": 84568, "start": 845.68, "end": 850.64, "text": " improve and it gets possible to train more powerful AIs using less computing.", "tokens": [50364, 3470, 293, 309, 2170, 1944, 281, 3847, 544, 4005, 316, 6802, 1228, 1570, 15866, 13, 50612], "temperature": 0.0, "avg_logprob": -0.12777616559844657, "compression_ratio": 1.6067415730337078, "no_speech_prob": 0.017707111313939095}, {"id": 133, "seek": 84568, "start": 850.64, "end": 853.3599999999999, "text": " So you're picturing a kind of international agreement to just stop?", "tokens": [50612, 407, 291, 434, 2317, 1345, 257, 733, 295, 5058, 8106, 281, 445, 1590, 30, 50748], "temperature": 0.0, "avg_logprob": -0.12777616559844657, "compression_ratio": 1.6067415730337078, "no_speech_prob": 0.017707111313939095}, {"id": 134, "seek": 84568, "start": 854.16, "end": 862.4799999999999, "text": " International moratorium. And if North Korea steals the GPU shipment, then you've got to be ready to", "tokens": [50788, 9157, 1896, 41679, 13, 400, 498, 4067, 6307, 46962, 264, 18407, 49991, 11, 550, 291, 600, 658, 281, 312, 1919, 281, 51204], "temperature": 0.0, "avg_logprob": -0.12777616559844657, "compression_ratio": 1.6067415730337078, "no_speech_prob": 0.017707111313939095}, {"id": 135, "seek": 84568, "start": 864.2399999999999, "end": 869.76, "text": " destroy their data center that they build by conventional means. And if you don't have that", "tokens": [51292, 5293, 641, 1412, 3056, 300, 436, 1322, 538, 16011, 1355, 13, 400, 498, 291, 500, 380, 362, 300, 51568], "temperature": 0.0, "avg_logprob": -0.12777616559844657, "compression_ratio": 1.6067415730337078, "no_speech_prob": 0.017707111313939095}, {"id": 136, "seek": 84568, "start": 869.76, "end": 873.92, "text": " willingness in advance, then countries may refuse to sign up for the agreement being like,", "tokens": [51568, 25069, 294, 7295, 11, 550, 3517, 815, 16791, 281, 1465, 493, 337, 264, 8106, 885, 411, 11, 51776], "temperature": 0.0, "avg_logprob": -0.12777616559844657, "compression_ratio": 1.6067415730337078, "no_speech_prob": 0.017707111313939095}, {"id": 137, "seek": 87392, "start": 873.92, "end": 879.36, "text": " why aren't we just seeding the advantage to someone else then? It actually has to be a", "tokens": [50364, 983, 3212, 380, 321, 445, 8871, 278, 264, 5002, 281, 1580, 1646, 550, 30, 467, 767, 575, 281, 312, 257, 50636], "temperature": 0.0, "avg_logprob": -0.09458362645116346, "compression_ratio": 1.78544061302682, "no_speech_prob": 0.006486158352345228}, {"id": 138, "seek": 87392, "start": 879.36, "end": 885.1999999999999, "text": " worldwide shutdown because the scale of harm from a superintelligence, it's not that if you", "tokens": [50636, 13485, 34927, 570, 264, 4373, 295, 6491, 490, 257, 1687, 20761, 17644, 11, 309, 311, 406, 300, 498, 291, 50928], "temperature": 0.0, "avg_logprob": -0.09458362645116346, "compression_ratio": 1.78544061302682, "no_speech_prob": 0.006486158352345228}, {"id": 139, "seek": 87392, "start": 885.1999999999999, "end": 890.4, "text": " have 10 times as many superintelligence as you've got, 10 times as much harm. It's not that a", "tokens": [50928, 362, 1266, 1413, 382, 867, 1687, 20761, 17644, 382, 291, 600, 658, 11, 1266, 1413, 382, 709, 6491, 13, 467, 311, 406, 300, 257, 51188], "temperature": 0.0, "avg_logprob": -0.09458362645116346, "compression_ratio": 1.78544061302682, "no_speech_prob": 0.006486158352345228}, {"id": 140, "seek": 87392, "start": 890.4, "end": 896.0, "text": " superintelligence only wrecks the country that built the superintelligence. Any superintelligence", "tokens": [51188, 1687, 20761, 17644, 787, 46674, 2761, 264, 1941, 300, 3094, 264, 1687, 20761, 17644, 13, 2639, 1687, 20761, 17644, 51468], "temperature": 0.0, "avg_logprob": -0.09458362645116346, "compression_ratio": 1.78544061302682, "no_speech_prob": 0.006486158352345228}, {"id": 141, "seek": 87392, "start": 896.0, "end": 901.92, "text": " everywhere is anyone's last problem. So Gary and Scott, if either of you want to jump in there,", "tokens": [51468, 5315, 307, 2878, 311, 1036, 1154, 13, 407, 13788, 293, 6659, 11, 498, 2139, 295, 291, 528, 281, 3012, 294, 456, 11, 51764], "temperature": 0.0, "avg_logprob": -0.09458362645116346, "compression_ratio": 1.78544061302682, "no_speech_prob": 0.006486158352345228}, {"id": 142, "seek": 90192, "start": 902.64, "end": 909.28, "text": " is AI safety a matter of forestalling the end of the world and all of these", "tokens": [50400, 307, 7318, 4514, 257, 1871, 295, 6719, 24021, 264, 917, 295, 264, 1002, 293, 439, 295, 613, 50732], "temperature": 0.0, "avg_logprob": -0.1785068068393441, "compression_ratio": 1.4977777777777779, "no_speech_prob": 0.004195850342512131}, {"id": 143, "seek": 90192, "start": 909.92, "end": 913.92, "text": " smaller issues and pass towards safety that Scott, you mentioned, are just", "tokens": [50764, 4356, 2663, 293, 1320, 3030, 4514, 300, 6659, 11, 291, 2835, 11, 366, 445, 50964], "temperature": 0.0, "avg_logprob": -0.1785068068393441, "compression_ratio": 1.4977777777777779, "no_speech_prob": 0.004195850342512131}, {"id": 144, "seek": 90192, "start": 915.68, "end": 922.0799999999999, "text": " throwing, I don't know what the analogy is, but pointless essentially. What do you guys make of this?", "tokens": [51052, 10238, 11, 286, 500, 380, 458, 437, 264, 21663, 307, 11, 457, 32824, 4476, 13, 708, 360, 291, 1074, 652, 295, 341, 30, 51372], "temperature": 0.0, "avg_logprob": -0.1785068068393441, "compression_ratio": 1.4977777777777779, "no_speech_prob": 0.004195850342512131}, {"id": 145, "seek": 90192, "start": 924.56, "end": 931.8399999999999, "text": " I mean, the journey of 1,000 miles begins with a step. Most of the way I think about", "tokens": [51496, 286, 914, 11, 264, 4671, 295, 502, 11, 1360, 6193, 7338, 365, 257, 1823, 13, 4534, 295, 264, 636, 286, 519, 466, 51860], "temperature": 0.0, "avg_logprob": -0.1785068068393441, "compression_ratio": 1.4977777777777779, "no_speech_prob": 0.004195850342512131}, {"id": 146, "seek": 93184, "start": 932.0, "end": 939.76, "text": " this comes from 25 years of doing computer science research, including quantum computing", "tokens": [50372, 341, 1487, 490, 3552, 924, 295, 884, 3820, 3497, 2132, 11, 3009, 13018, 15866, 50760], "temperature": 0.0, "avg_logprob": -0.09262005313412174, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0005974160740152001}, {"id": 147, "seek": 93184, "start": 939.76, "end": 946.5600000000001, "text": " and computational complexity, things like that, where we have these gigantic aspirational problems", "tokens": [50760, 293, 28270, 14024, 11, 721, 411, 300, 11, 689, 321, 362, 613, 26800, 20003, 1478, 2740, 51100], "temperature": 0.0, "avg_logprob": -0.09262005313412174, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0005974160740152001}, {"id": 148, "seek": 93184, "start": 946.5600000000001, "end": 953.9200000000001, "text": " that we don't know how to solve. And yet, year after year, we do make progress. We pick off", "tokens": [51100, 300, 321, 500, 380, 458, 577, 281, 5039, 13, 400, 1939, 11, 1064, 934, 1064, 11, 321, 360, 652, 4205, 13, 492, 1888, 766, 51468], "temperature": 0.0, "avg_logprob": -0.09262005313412174, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0005974160740152001}, {"id": 149, "seek": 93184, "start": 953.9200000000001, "end": 959.9200000000001, "text": " little sub-problems. And if we can't solve those, then we find sub-problems of those. And we keep", "tokens": [51468, 707, 1422, 12, 47419, 82, 13, 400, 498, 321, 393, 380, 5039, 729, 11, 550, 321, 915, 1422, 12, 47419, 82, 295, 729, 13, 400, 321, 1066, 51768], "temperature": 0.0, "avg_logprob": -0.09262005313412174, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0005974160740152001}, {"id": 150, "seek": 95992, "start": 960.0, "end": 966.16, "text": " repeating until we find something that we can solve. And this is, I think, for centuries,", "tokens": [50368, 18617, 1826, 321, 915, 746, 300, 321, 393, 5039, 13, 400, 341, 307, 11, 286, 519, 11, 337, 13926, 11, 50676], "temperature": 0.0, "avg_logprob": -0.08082967163414083, "compression_ratio": 1.7235023041474655, "no_speech_prob": 0.007570432964712381}, {"id": 151, "seek": 95992, "start": 966.16, "end": 972.7199999999999, "text": " the way that science has made progress. Now, it is possible that this time, we just don't have", "tokens": [50676, 264, 636, 300, 3497, 575, 1027, 4205, 13, 823, 11, 309, 307, 1944, 300, 341, 565, 11, 321, 445, 500, 380, 362, 51004], "temperature": 0.0, "avg_logprob": -0.08082967163414083, "compression_ratio": 1.7235023041474655, "no_speech_prob": 0.007570432964712381}, {"id": 152, "seek": 95992, "start": 972.7199999999999, "end": 979.4399999999999, "text": " enough time for that to work. And I think that is what Eliezer is fearful of, that we just", "tokens": [51004, 1547, 565, 337, 300, 281, 589, 13, 400, 286, 519, 300, 307, 437, 2699, 414, 4527, 307, 33014, 295, 11, 300, 321, 445, 51340], "temperature": 0.0, "avg_logprob": -0.08082967163414083, "compression_ratio": 1.7235023041474655, "no_speech_prob": 0.007570432964712381}, {"id": 153, "seek": 95992, "start": 979.4399999999999, "end": 986.7199999999999, "text": " don't have enough time for the ordinary scientific process to work before AI becomes too powerful,", "tokens": [51340, 500, 380, 362, 1547, 565, 337, 264, 10547, 8134, 1399, 281, 589, 949, 7318, 3643, 886, 4005, 11, 51704], "temperature": 0.0, "avg_logprob": -0.08082967163414083, "compression_ratio": 1.7235023041474655, "no_speech_prob": 0.007570432964712381}, {"id": 154, "seek": 98672, "start": 987.6800000000001, "end": 996.4, "text": " in which case you start talking about things like a global moratorium enforced with the threat of", "tokens": [50412, 294, 597, 1389, 291, 722, 1417, 466, 721, 411, 257, 4338, 1896, 41679, 40953, 365, 264, 4734, 295, 50848], "temperature": 0.0, "avg_logprob": -0.11667530973192672, "compression_ratio": 1.5051020408163265, "no_speech_prob": 0.012231960892677307}, {"id": 155, "seek": 98672, "start": 996.4, "end": 1005.84, "text": " war. I am not ready to go there. I could imagine circumstances where maybe I say, gosh, this looks", "tokens": [50848, 1516, 13, 286, 669, 406, 1919, 281, 352, 456, 13, 286, 727, 3811, 9121, 689, 1310, 286, 584, 11, 6502, 11, 341, 1542, 51320], "temperature": 0.0, "avg_logprob": -0.11667530973192672, "compression_ratio": 1.5051020408163265, "no_speech_prob": 0.012231960892677307}, {"id": 156, "seek": 98672, "start": 1005.84, "end": 1015.2, "text": " like such an imminent threat that we have to. But I tend to be very, very worried in general about", "tokens": [51320, 411, 1270, 364, 44339, 4734, 300, 321, 362, 281, 13, 583, 286, 3928, 281, 312, 588, 11, 588, 5804, 294, 2674, 466, 51788], "temperature": 0.0, "avg_logprob": -0.11667530973192672, "compression_ratio": 1.5051020408163265, "no_speech_prob": 0.012231960892677307}, {"id": 157, "seek": 101520, "start": 1016.1600000000001, "end": 1023.0400000000001, "text": " causing a catastrophe in the course of trying to prevent a catastrophe. And I think when you are", "tokens": [50412, 9853, 257, 36043, 294, 264, 1164, 295, 1382, 281, 4871, 257, 36043, 13, 400, 286, 519, 562, 291, 366, 50756], "temperature": 0.0, "avg_logprob": -0.12644053542095682, "compression_ratio": 1.668141592920354, "no_speech_prob": 0.0027989165391772985}, {"id": 158, "seek": 101520, "start": 1023.0400000000001, "end": 1029.8400000000001, "text": " talking about threatening airstrikes against data centers or things like that, then that is an", "tokens": [50756, 1417, 466, 20768, 257, 653, 470, 5993, 1970, 1412, 10898, 420, 721, 411, 300, 11, 550, 300, 307, 364, 51096], "temperature": 0.0, "avg_logprob": -0.12644053542095682, "compression_ratio": 1.668141592920354, "no_speech_prob": 0.0027989165391772985}, {"id": 159, "seek": 101520, "start": 1029.8400000000001, "end": 1036.0800000000002, "text": " obvious worry. So I am somewhat in between here. I am with Scott that we are not at the point where", "tokens": [51096, 6322, 3292, 13, 407, 286, 669, 8344, 294, 1296, 510, 13, 286, 669, 365, 6659, 300, 321, 366, 406, 412, 264, 935, 689, 51408], "temperature": 0.0, "avg_logprob": -0.12644053542095682, "compression_ratio": 1.668141592920354, "no_speech_prob": 0.0027989165391772985}, {"id": 160, "seek": 101520, "start": 1036.0800000000002, "end": 1040.24, "text": " we should be bombing data centers. I don't think we are close to that. I am much less", "tokens": [51408, 321, 820, 312, 31292, 1412, 10898, 13, 286, 500, 380, 519, 321, 366, 1998, 281, 300, 13, 286, 669, 709, 1570, 51616], "temperature": 0.0, "avg_logprob": -0.12644053542095682, "compression_ratio": 1.668141592920354, "no_speech_prob": 0.0027989165391772985}, {"id": 161, "seek": 104024, "start": 1041.2, "end": 1048.16, "text": " aware of what the right word is to use here. I don't think we are anywhere near as close to AGI as", "tokens": [50412, 3650, 295, 437, 264, 558, 1349, 307, 281, 764, 510, 13, 286, 500, 380, 519, 321, 366, 4992, 2651, 382, 1998, 281, 316, 26252, 382, 50760], "temperature": 0.0, "avg_logprob": -0.1558958257286294, "compression_ratio": 1.5485232067510548, "no_speech_prob": 0.11263129115104675}, {"id": 162, "seek": 104024, "start": 1048.16, "end": 1054.64, "text": " I think Eliezer sometimes sounds like. I don't think GPT-5 is anything like AGI. And I am not", "tokens": [50760, 286, 519, 2699, 414, 4527, 2171, 3263, 411, 13, 286, 500, 380, 519, 26039, 51, 12, 20, 307, 1340, 411, 316, 26252, 13, 400, 286, 669, 406, 51084], "temperature": 0.0, "avg_logprob": -0.1558958257286294, "compression_ratio": 1.5485232067510548, "no_speech_prob": 0.11263129115104675}, {"id": 163, "seek": 104024, "start": 1054.64, "end": 1059.28, "text": " particularly concerned about who gets it first and so forth. On the other hand, I think that", "tokens": [51084, 4098, 5922, 466, 567, 2170, 309, 700, 293, 370, 5220, 13, 1282, 264, 661, 1011, 11, 286, 519, 300, 51316], "temperature": 0.0, "avg_logprob": -0.1558958257286294, "compression_ratio": 1.5485232067510548, "no_speech_prob": 0.11263129115104675}, {"id": 164, "seek": 104024, "start": 1059.84, "end": 1065.92, "text": " we are in a sort of dress rehearsal mode. Nobody expected GPT-4, really chat GPT,", "tokens": [51344, 321, 366, 294, 257, 1333, 295, 5231, 24884, 4391, 13, 9297, 5176, 26039, 51, 12, 19, 11, 534, 5081, 26039, 51, 11, 51648], "temperature": 0.0, "avg_logprob": -0.1558958257286294, "compression_ratio": 1.5485232067510548, "no_speech_prob": 0.11263129115104675}, {"id": 165, "seek": 106592, "start": 1065.92, "end": 1070.96, "text": " to percolate as fast as it did. And it is a reminder that there is a social side to all of this,", "tokens": [50364, 281, 680, 8768, 473, 382, 2370, 382, 309, 630, 13, 400, 309, 307, 257, 13548, 300, 456, 307, 257, 2093, 1252, 281, 439, 295, 341, 11, 50616], "temperature": 0.0, "avg_logprob": -0.11544655487600682, "compression_ratio": 1.6715328467153285, "no_speech_prob": 0.036716874688863754}, {"id": 166, "seek": 106592, "start": 1071.52, "end": 1074.96, "text": " how software gets distributed matters, and there is a corporate side.", "tokens": [50644, 577, 4722, 2170, 12631, 7001, 11, 293, 456, 307, 257, 10896, 1252, 13, 50816], "temperature": 0.0, "avg_logprob": -0.11544655487600682, "compression_ratio": 1.6715328467153285, "no_speech_prob": 0.036716874688863754}, {"id": 167, "seek": 106592, "start": 1077.3600000000001, "end": 1082.8000000000002, "text": " It was a kind of galvanizing moment for me when Microsoft didn't pull Sydney, even though Sydney", "tokens": [50936, 467, 390, 257, 733, 295, 7660, 9768, 3319, 1623, 337, 385, 562, 8116, 994, 380, 2235, 21065, 11, 754, 1673, 21065, 51208], "temperature": 0.0, "avg_logprob": -0.11544655487600682, "compression_ratio": 1.6715328467153285, "no_speech_prob": 0.036716874688863754}, {"id": 168, "seek": 106592, "start": 1082.8000000000002, "end": 1086.3200000000002, "text": " did some awfully strange things. I thought they would take it for a while and it is a reminder", "tokens": [51208, 630, 512, 47976, 5861, 721, 13, 286, 1194, 436, 576, 747, 309, 337, 257, 1339, 293, 309, 307, 257, 13548, 51384], "temperature": 0.0, "avg_logprob": -0.11544655487600682, "compression_ratio": 1.6715328467153285, "no_speech_prob": 0.036716874688863754}, {"id": 169, "seek": 106592, "start": 1086.3200000000002, "end": 1091.44, "text": " that they can make whatever decisions they want. So you kind of multiply that by Eliezer's concerns", "tokens": [51384, 300, 436, 393, 652, 2035, 5327, 436, 528, 13, 407, 291, 733, 295, 12972, 300, 538, 2699, 414, 4527, 311, 7389, 51640], "temperature": 0.0, "avg_logprob": -0.11544655487600682, "compression_ratio": 1.6715328467153285, "no_speech_prob": 0.036716874688863754}, {"id": 170, "seek": 109144, "start": 1091.44, "end": 1099.92, "text": " about what do we do and at what point. What would be enough to cause problems is a reminder,", "tokens": [50364, 466, 437, 360, 321, 360, 293, 412, 437, 935, 13, 708, 576, 312, 1547, 281, 3082, 2740, 307, 257, 13548, 11, 50788], "temperature": 0.0, "avg_logprob": -0.09807740916376528, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.012228344567120075}, {"id": 171, "seek": 109144, "start": 1099.92, "end": 1104.0800000000002, "text": " I think, that we need, for example, to start roughing out these international treaties now,", "tokens": [50788, 286, 519, 11, 300, 321, 643, 11, 337, 1365, 11, 281, 722, 367, 25875, 484, 613, 5058, 48552, 586, 11, 50996], "temperature": 0.0, "avg_logprob": -0.09807740916376528, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.012228344567120075}, {"id": 172, "seek": 109144, "start": 1104.0800000000002, "end": 1107.52, "text": " because there could become a moment where there is a problem. I don't think the problem that", "tokens": [50996, 570, 456, 727, 1813, 257, 1623, 689, 456, 307, 257, 1154, 13, 286, 500, 380, 519, 264, 1154, 300, 51168], "temperature": 0.0, "avg_logprob": -0.09807740916376528, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.012228344567120075}, {"id": 173, "seek": 109144, "start": 1107.52, "end": 1114.56, "text": " Eliezer sees is here now, but maybe it will be. And maybe when it does come, we will have so many", "tokens": [51168, 2699, 414, 4527, 8194, 307, 510, 586, 11, 457, 1310, 309, 486, 312, 13, 400, 1310, 562, 309, 775, 808, 11, 321, 486, 362, 370, 867, 51520], "temperature": 0.0, "avg_logprob": -0.09807740916376528, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.012228344567120075}, {"id": 174, "seek": 109144, "start": 1114.56, "end": 1118.8, "text": " people pursuing commercial self-interest and so little infrastructure in place we won't be able", "tokens": [51520, 561, 20222, 6841, 2698, 12, 27685, 293, 370, 707, 6896, 294, 1081, 321, 1582, 380, 312, 1075, 51732], "temperature": 0.0, "avg_logprob": -0.09807740916376528, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.012228344567120075}, {"id": 175, "seek": 111880, "start": 1118.8, "end": 1124.24, "text": " to do anything. So I think it really is important to think now, if we reach such a point, what are", "tokens": [50364, 281, 360, 1340, 13, 407, 286, 519, 309, 534, 307, 1021, 281, 519, 586, 11, 498, 321, 2524, 1270, 257, 935, 11, 437, 366, 50636], "temperature": 0.0, "avg_logprob": -0.0989884664846021, "compression_ratio": 1.587962962962963, "no_speech_prob": 0.015890924260020256}, {"id": 176, "seek": 111880, "start": 1124.24, "end": 1128.56, "text": " we going to do? What do we need to build in place before we get to that point?", "tokens": [50636, 321, 516, 281, 360, 30, 708, 360, 321, 643, 281, 1322, 294, 1081, 949, 321, 483, 281, 300, 935, 30, 50852], "temperature": 0.0, "avg_logprob": -0.0989884664846021, "compression_ratio": 1.587962962962963, "no_speech_prob": 0.015890924260020256}, {"id": 177, "seek": 111880, "start": 1130.1599999999999, "end": 1134.8, "text": " So we've been talking about this concept of artificial general intelligence.", "tokens": [50932, 407, 321, 600, 668, 1417, 466, 341, 3410, 295, 11677, 2674, 7599, 13, 51164], "temperature": 0.0, "avg_logprob": -0.0989884664846021, "compression_ratio": 1.587962962962963, "no_speech_prob": 0.015890924260020256}, {"id": 178, "seek": 111880, "start": 1135.68, "end": 1143.6, "text": " And I think it's worth asking whether that is a useful coherent concept. So for example,", "tokens": [51208, 400, 286, 519, 309, 311, 3163, 3365, 1968, 300, 307, 257, 4420, 36239, 3410, 13, 407, 337, 1365, 11, 51604], "temperature": 0.0, "avg_logprob": -0.0989884664846021, "compression_ratio": 1.587962962962963, "no_speech_prob": 0.015890924260020256}, {"id": 179, "seek": 114360, "start": 1143.9199999999998, "end": 1149.9199999999998, "text": " if I were to think by analogy to athleticism and think of the moment when we build a machine", "tokens": [50380, 498, 286, 645, 281, 519, 538, 21663, 281, 22496, 1434, 293, 519, 295, 264, 1623, 562, 321, 1322, 257, 3479, 50680], "temperature": 0.0, "avg_logprob": -0.0832104346331428, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.07053013145923615}, {"id": 180, "seek": 114360, "start": 1150.48, "end": 1158.08, "text": " that has, say, artificial general athleticism, meaning it's better than LeBron James at basketball,", "tokens": [50708, 300, 575, 11, 584, 11, 11677, 2674, 22496, 1434, 11, 3620, 309, 311, 1101, 813, 1456, 33, 2044, 5678, 412, 11767, 11, 51088], "temperature": 0.0, "avg_logprob": -0.0832104346331428, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.07053013145923615}, {"id": 181, "seek": 114360, "start": 1158.08, "end": 1164.8799999999999, "text": " but also better at curling than the world's best curling player and also better at soccer", "tokens": [51088, 457, 611, 1101, 412, 45085, 813, 264, 1002, 311, 1151, 45085, 4256, 293, 611, 1101, 412, 15469, 51428], "temperature": 0.0, "avg_logprob": -0.0832104346331428, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.07053013145923615}, {"id": 182, "seek": 114360, "start": 1164.8799999999999, "end": 1171.04, "text": " and also better at archery and so forth, it would seem to me that", "tokens": [51428, 293, 611, 1101, 412, 3912, 2109, 293, 370, 5220, 11, 309, 576, 1643, 281, 385, 300, 51736], "temperature": 0.0, "avg_logprob": -0.0832104346331428, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.07053013145923615}, {"id": 183, "seek": 117104, "start": 1171.36, "end": 1178.8, "text": " there's something a bit strange as framing it as having reached a point on a single continuum.", "tokens": [50380, 456, 311, 746, 257, 857, 5861, 382, 28971, 309, 382, 1419, 6488, 257, 935, 322, 257, 2167, 36120, 13, 50752], "temperature": 0.0, "avg_logprob": -0.18888539534348708, "compression_ratio": 1.5401069518716577, "no_speech_prob": 0.01098429225385189}, {"id": 184, "seek": 117104, "start": 1178.8, "end": 1186.3999999999999, "text": " It seems to me you would sort of have to build each capability, each sport individually and then", "tokens": [50752, 467, 2544, 281, 385, 291, 576, 1333, 295, 362, 281, 1322, 1184, 13759, 11, 1184, 7282, 16652, 293, 550, 51132], "temperature": 0.0, "avg_logprob": -0.18888539534348708, "compression_ratio": 1.5401069518716577, "no_speech_prob": 0.01098429225385189}, {"id": 185, "seek": 117104, "start": 1186.3999999999999, "end": 1194.8, "text": " somehow figure how to package them all into one robot without each skill set detracting from the", "tokens": [51132, 6063, 2573, 577, 281, 7372, 552, 439, 666, 472, 7881, 1553, 1184, 5389, 992, 1141, 1897, 278, 490, 264, 51552], "temperature": 0.0, "avg_logprob": -0.18888539534348708, "compression_ratio": 1.5401069518716577, "no_speech_prob": 0.01098429225385189}, {"id": 186, "seek": 119480, "start": 1195.68, "end": 1204.8799999999999, "text": " other. Is that a disanalogy? Do you all picture this intelligence as sort of one dimension,", "tokens": [50408, 661, 13, 1119, 300, 257, 717, 29702, 7794, 30, 1144, 291, 439, 3036, 341, 7599, 382, 1333, 295, 472, 10139, 11, 50868], "temperature": 0.0, "avg_logprob": -0.10524458043715533, "compression_ratio": 1.5174418604651163, "no_speech_prob": 0.0695141926407814}, {"id": 187, "seek": 119480, "start": 1204.8799999999999, "end": 1213.76, "text": " one knob that is going to get turned up along a single axis? Or do you think that way of talking", "tokens": [50868, 472, 26759, 300, 307, 516, 281, 483, 3574, 493, 2051, 257, 2167, 10298, 30, 1610, 360, 291, 519, 300, 636, 295, 1417, 51312], "temperature": 0.0, "avg_logprob": -0.10524458043715533, "compression_ratio": 1.5174418604651163, "no_speech_prob": 0.0695141926407814}, {"id": 188, "seek": 119480, "start": 1213.76, "end": 1218.56, "text": " about it is misleading in the same way that I kind of just sketched out?", "tokens": [51312, 466, 309, 307, 36429, 294, 264, 912, 636, 300, 286, 733, 295, 445, 12325, 292, 484, 30, 51552], "temperature": 0.0, "avg_logprob": -0.10524458043715533, "compression_ratio": 1.5174418604651163, "no_speech_prob": 0.0695141926407814}, {"id": 189, "seek": 121856, "start": 1219.12, "end": 1225.12, "text": " Yeah, I would absolutely not accept that. I like to say that intelligence is not a one-dimensional", "tokens": [50392, 865, 11, 286, 576, 3122, 406, 3241, 300, 13, 286, 411, 281, 584, 300, 7599, 307, 406, 257, 472, 12, 18759, 50692], "temperature": 0.0, "avg_logprob": -0.10992189471641284, "compression_ratio": 1.6680851063829787, "no_speech_prob": 0.006094771437346935}, {"id": 190, "seek": 121856, "start": 1225.12, "end": 1232.0, "text": " variable. There's many different aspects to intelligence and there's not, I think, going", "tokens": [50692, 7006, 13, 821, 311, 867, 819, 7270, 281, 7599, 293, 456, 311, 406, 11, 286, 519, 11, 516, 51036], "temperature": 0.0, "avg_logprob": -0.10992189471641284, "compression_ratio": 1.6680851063829787, "no_speech_prob": 0.006094771437346935}, {"id": 191, "seek": 121856, "start": 1232.0, "end": 1237.52, "text": " to be a magical moment when we reach the singularity or something like that. I would say that the core", "tokens": [51036, 281, 312, 257, 12066, 1623, 562, 321, 2524, 264, 20010, 507, 420, 746, 411, 300, 13, 286, 576, 584, 300, 264, 4965, 51312], "temperature": 0.0, "avg_logprob": -0.10992189471641284, "compression_ratio": 1.6680851063829787, "no_speech_prob": 0.006094771437346935}, {"id": 192, "seek": 121856, "start": 1237.52, "end": 1243.6, "text": " of artificial general intelligence is the ability to flexibly deal with new problems that you haven't", "tokens": [51312, 295, 11677, 2674, 7599, 307, 264, 3485, 281, 5896, 3545, 2028, 365, 777, 2740, 300, 291, 2378, 380, 51616], "temperature": 0.0, "avg_logprob": -0.10992189471641284, "compression_ratio": 1.6680851063829787, "no_speech_prob": 0.006094771437346935}, {"id": 193, "seek": 124360, "start": 1243.6, "end": 1249.6799999999998, "text": " seen before. And the current systems can do that a little bit, but not very well. My typical example", "tokens": [50364, 1612, 949, 13, 400, 264, 2190, 3652, 393, 360, 300, 257, 707, 857, 11, 457, 406, 588, 731, 13, 1222, 7476, 1365, 50668], "temperature": 0.0, "avg_logprob": -0.084521442163186, "compression_ratio": 1.6914893617021276, "no_speech_prob": 0.04528633877635002}, {"id": 194, "seek": 124360, "start": 1249.6799999999998, "end": 1255.36, "text": " of this now is GPT-4 is exposed to the game of chess, sees the lots of games of chess that", "tokens": [50668, 295, 341, 586, 307, 26039, 51, 12, 19, 307, 9495, 281, 264, 1216, 295, 24122, 11, 8194, 264, 3195, 295, 2813, 295, 24122, 300, 50952], "temperature": 0.0, "avg_logprob": -0.084521442163186, "compression_ratio": 1.6914893617021276, "no_speech_prob": 0.04528633877635002}, {"id": 195, "seek": 124360, "start": 1255.36, "end": 1259.76, "text": " sees the rules of chess, but it never actually figures out the rules of chess and makes illegal", "tokens": [50952, 8194, 264, 4474, 295, 24122, 11, 457, 309, 1128, 767, 9624, 484, 264, 4474, 295, 24122, 293, 1669, 11905, 51172], "temperature": 0.0, "avg_logprob": -0.084521442163186, "compression_ratio": 1.6914893617021276, "no_speech_prob": 0.04528633877635002}, {"id": 196, "seek": 124360, "start": 1259.76, "end": 1264.8799999999999, "text": " moves and so forth. So it's in no way a general intelligence that can just pick up new things.", "tokens": [51172, 6067, 293, 370, 5220, 13, 407, 309, 311, 294, 572, 636, 257, 2674, 7599, 300, 393, 445, 1888, 493, 777, 721, 13, 51428], "temperature": 0.0, "avg_logprob": -0.084521442163186, "compression_ratio": 1.6914893617021276, "no_speech_prob": 0.04528633877635002}, {"id": 197, "seek": 124360, "start": 1264.8799999999999, "end": 1270.3999999999999, "text": " Of course, we have things like AlphaGo that can play a certain set of games, AlphaZero really,", "tokens": [51428, 2720, 1164, 11, 321, 362, 721, 411, 20588, 12104, 300, 393, 862, 257, 1629, 992, 295, 2813, 11, 20588, 57, 2032, 534, 11, 51704], "temperature": 0.0, "avg_logprob": -0.084521442163186, "compression_ratio": 1.6914893617021276, "no_speech_prob": 0.04528633877635002}, {"id": 198, "seek": 127040, "start": 1270.4, "end": 1275.68, "text": " but we don't have anything that has the generality of human intelligence. But human", "tokens": [50364, 457, 321, 500, 380, 362, 1340, 300, 575, 264, 1337, 1860, 295, 1952, 7599, 13, 583, 1952, 50628], "temperature": 0.0, "avg_logprob": -0.0956442015511649, "compression_ratio": 1.7560975609756098, "no_speech_prob": 0.002147865714505315}, {"id": 199, "seek": 127040, "start": 1275.68, "end": 1280.24, "text": " intelligence is just one example of general intelligence. You could argue that chimpanzees", "tokens": [50628, 7599, 307, 445, 472, 1365, 295, 2674, 7599, 13, 509, 727, 9695, 300, 18375, 48410, 279, 50856], "temperature": 0.0, "avg_logprob": -0.0956442015511649, "compression_ratio": 1.7560975609756098, "no_speech_prob": 0.002147865714505315}, {"id": 200, "seek": 127040, "start": 1280.24, "end": 1285.2800000000002, "text": " or crows have another variety of general intelligence. I would say the current machines don't really", "tokens": [50856, 420, 941, 1509, 362, 1071, 5673, 295, 2674, 7599, 13, 286, 576, 584, 264, 2190, 8379, 500, 380, 534, 51108], "temperature": 0.0, "avg_logprob": -0.0956442015511649, "compression_ratio": 1.7560975609756098, "no_speech_prob": 0.002147865714505315}, {"id": 201, "seek": 127040, "start": 1285.2800000000002, "end": 1293.8400000000001, "text": " have it, but they will eventually. I mean, I think a priori, it could have been that", "tokens": [51108, 362, 309, 11, 457, 436, 486, 4728, 13, 286, 914, 11, 286, 519, 257, 4059, 72, 11, 309, 727, 362, 668, 300, 51536], "temperature": 0.0, "avg_logprob": -0.0956442015511649, "compression_ratio": 1.7560975609756098, "no_speech_prob": 0.002147865714505315}, {"id": 202, "seek": 129384, "start": 1294.8, "end": 1299.6799999999998, "text": " you would have math ability, you would have verbal ability, you'd have", "tokens": [50412, 291, 576, 362, 5221, 3485, 11, 291, 576, 362, 24781, 3485, 11, 291, 1116, 362, 50656], "temperature": 0.0, "avg_logprob": -0.12207623469976732, "compression_ratio": 1.5812807881773399, "no_speech_prob": 0.07686103880405426}, {"id": 203, "seek": 129384, "start": 1300.8799999999999, "end": 1305.52, "text": " ability to understand humor, and they'd all be just completely unrelated to each other.", "tokens": [50716, 3485, 281, 1223, 14318, 11, 293, 436, 1116, 439, 312, 445, 2584, 38967, 281, 1184, 661, 13, 50948], "temperature": 0.0, "avg_logprob": -0.12207623469976732, "compression_ratio": 1.5812807881773399, "no_speech_prob": 0.07686103880405426}, {"id": 204, "seek": 129384, "start": 1306.24, "end": 1314.08, "text": " That is possible. And in fact, already with GPT, you can say that in some ways,", "tokens": [50984, 663, 307, 1944, 13, 400, 294, 1186, 11, 1217, 365, 26039, 51, 11, 291, 393, 584, 300, 294, 512, 2098, 11, 51376], "temperature": 0.0, "avg_logprob": -0.12207623469976732, "compression_ratio": 1.5812807881773399, "no_speech_prob": 0.07686103880405426}, {"id": 205, "seek": 129384, "start": 1314.08, "end": 1320.3999999999999, "text": " it already is a super intelligence. It knows vastly more, can converse on a vastly", "tokens": [51376, 309, 1217, 307, 257, 1687, 7599, 13, 467, 3255, 41426, 544, 11, 393, 416, 4308, 322, 257, 41426, 51692], "temperature": 0.0, "avg_logprob": -0.12207623469976732, "compression_ratio": 1.5812807881773399, "no_speech_prob": 0.07686103880405426}, {"id": 206, "seek": 132040, "start": 1320.4, "end": 1327.92, "text": " greater range of subjects than any human can. And in other ways, it seems to fall short of", "tokens": [50364, 5044, 3613, 295, 13066, 813, 604, 1952, 393, 13, 400, 294, 661, 2098, 11, 309, 2544, 281, 2100, 2099, 295, 50740], "temperature": 0.0, "avg_logprob": -0.1454940248042979, "compression_ratio": 1.3587786259541985, "no_speech_prob": 0.02191203087568283}, {"id": 207, "seek": 132040, "start": 1329.44, "end": 1338.72, "text": " what humans know or can do. But you also see this sort of generality, just empirically.", "tokens": [50816, 437, 6255, 458, 420, 393, 360, 13, 583, 291, 611, 536, 341, 1333, 295, 1337, 1860, 11, 445, 25790, 984, 13, 51280], "temperature": 0.0, "avg_logprob": -0.1454940248042979, "compression_ratio": 1.3587786259541985, "no_speech_prob": 0.02191203087568283}, {"id": 208, "seek": 133872, "start": 1339.44, "end": 1346.24, "text": " I mean, GPT was sort of trained on all the text on the internet,", "tokens": [50400, 286, 914, 11, 26039, 51, 390, 1333, 295, 8895, 322, 439, 264, 2487, 322, 264, 4705, 11, 50740], "temperature": 0.0, "avg_logprob": -0.1457503304552676, "compression_ratio": 1.5220125786163523, "no_speech_prob": 0.3132106065750122}, {"id": 209, "seek": 133872, "start": 1348.88, "end": 1355.68, "text": " let's say most of the text on the open internet. So it was just one method. It was not", "tokens": [50872, 718, 311, 584, 881, 295, 264, 2487, 322, 264, 1269, 4705, 13, 407, 309, 390, 445, 472, 3170, 13, 467, 390, 406, 51212], "temperature": 0.0, "avg_logprob": -0.1457503304552676, "compression_ratio": 1.5220125786163523, "no_speech_prob": 0.3132106065750122}, {"id": 210, "seek": 133872, "start": 1356.64, "end": 1363.52, "text": " explicitly designed to write code, and yet it can write code. And at the same time as that", "tokens": [51260, 20803, 4761, 281, 2464, 3089, 11, 293, 1939, 309, 393, 2464, 3089, 13, 400, 412, 264, 912, 565, 382, 300, 51604], "temperature": 0.0, "avg_logprob": -0.1457503304552676, "compression_ratio": 1.5220125786163523, "no_speech_prob": 0.3132106065750122}, {"id": 211, "seek": 136352, "start": 1363.6, "end": 1370.96, "text": " ability emerged, you also saw the ability to solve word problems like high school level math.", "tokens": [50368, 3485, 20178, 11, 291, 611, 1866, 264, 3485, 281, 5039, 1349, 2740, 411, 1090, 1395, 1496, 5221, 13, 50736], "temperature": 0.0, "avg_logprob": -0.10675533906913098, "compression_ratio": 1.602803738317757, "no_speech_prob": 0.10507018119096756}, {"id": 212, "seek": 136352, "start": 1371.76, "end": 1378.96, "text": " You saw the ability to write poetry. This all came out of the same system without any of it", "tokens": [50776, 509, 1866, 264, 3485, 281, 2464, 15155, 13, 639, 439, 1361, 484, 295, 264, 912, 1185, 1553, 604, 295, 309, 51136], "temperature": 0.0, "avg_logprob": -0.10675533906913098, "compression_ratio": 1.602803738317757, "no_speech_prob": 0.10507018119096756}, {"id": 213, "seek": 136352, "start": 1378.96, "end": 1384.8799999999999, "text": " being explicitly optimized for. I feel like I need to interject one important thing,", "tokens": [51136, 885, 20803, 26941, 337, 13, 286, 841, 411, 286, 643, 281, 46787, 472, 1021, 551, 11, 51432], "temperature": 0.0, "avg_logprob": -0.10675533906913098, "compression_ratio": 1.602803738317757, "no_speech_prob": 0.10507018119096756}, {"id": 214, "seek": 136352, "start": 1384.8799999999999, "end": 1388.32, "text": " which is it can do all these things, but none of them all that reliably.", "tokens": [51432, 597, 307, 309, 393, 360, 439, 613, 721, 11, 457, 6022, 295, 552, 439, 300, 49927, 13, 51604], "temperature": 0.0, "avg_logprob": -0.10675533906913098, "compression_ratio": 1.602803738317757, "no_speech_prob": 0.10507018119096756}, {"id": 215, "seek": 138832, "start": 1388.32, "end": 1395.6, "text": " Well, okay. Nevertheless, compared to, let's say, what my expectations would have been,", "tokens": [50364, 1042, 11, 1392, 13, 26554, 11, 5347, 281, 11, 718, 311, 584, 11, 437, 452, 9843, 576, 362, 668, 11, 50728], "temperature": 0.0, "avg_logprob": -0.1083098401080121, "compression_ratio": 1.4769874476987448, "no_speech_prob": 0.008437786251306534}, {"id": 216, "seek": 138832, "start": 1395.6, "end": 1399.9199999999998, "text": " if you'd asked me 10 or 20 years ago, I think that the level of generality", "tokens": [50728, 498, 291, 1116, 2351, 385, 1266, 420, 945, 924, 2057, 11, 286, 519, 300, 264, 1496, 295, 1337, 1860, 50944], "temperature": 0.0, "avg_logprob": -0.1083098401080121, "compression_ratio": 1.4769874476987448, "no_speech_prob": 0.008437786251306534}, {"id": 217, "seek": 138832, "start": 1399.9199999999998, "end": 1407.52, "text": " is pretty remarkable. And it does lend support to the idea that there is some sort of general", "tokens": [50944, 307, 1238, 12802, 13, 400, 309, 775, 21774, 1406, 281, 264, 1558, 300, 456, 307, 512, 1333, 295, 2674, 51324], "temperature": 0.0, "avg_logprob": -0.1083098401080121, "compression_ratio": 1.4769874476987448, "no_speech_prob": 0.008437786251306534}, {"id": 218, "seek": 138832, "start": 1407.52, "end": 1413.6799999999998, "text": " quality of understanding there, where you could say, for example, that GPT-4 has more of it than", "tokens": [51324, 3125, 295, 3701, 456, 11, 689, 291, 727, 584, 11, 337, 1365, 11, 300, 26039, 51, 12, 19, 575, 544, 295, 309, 813, 51632], "temperature": 0.0, "avg_logprob": -0.1083098401080121, "compression_ratio": 1.4769874476987448, "no_speech_prob": 0.008437786251306534}, {"id": 219, "seek": 141368, "start": 1413.68, "end": 1423.52, "text": " GPT-3, which in turn has more than GPT-2. And I would say that it does seem to me like it's", "tokens": [50364, 26039, 51, 12, 18, 11, 597, 294, 1261, 575, 544, 813, 26039, 51, 12, 17, 13, 400, 286, 576, 584, 300, 309, 775, 1643, 281, 385, 411, 309, 311, 50856], "temperature": 0.0, "avg_logprob": -0.10389750798543294, "compression_ratio": 1.2972972972972974, "no_speech_prob": 0.011864832602441311}, {"id": 220, "seek": 141368, "start": 1423.52, "end": 1432.24, "text": " presently pretty unambiguous that GPT-4 is in some sense dumber than an adult or even teenage human.", "tokens": [50856, 1974, 356, 1238, 517, 2173, 30525, 300, 26039, 51, 12, 19, 307, 294, 512, 2020, 274, 4182, 813, 364, 5075, 420, 754, 26866, 1952, 13, 51292], "temperature": 0.0, "avg_logprob": -0.10389750798543294, "compression_ratio": 1.2972972972972974, "no_speech_prob": 0.011864832602441311}, {"id": 221, "seek": 143224, "start": 1433.2, "end": 1447.76, "text": " I mean, to take the example I just gave you a minute ago, it never learns to play chess,", "tokens": [50412, 286, 914, 11, 281, 747, 264, 1365, 286, 445, 2729, 291, 257, 3456, 2057, 11, 309, 1128, 27152, 281, 862, 24122, 11, 51140], "temperature": 0.0, "avg_logprob": -0.14046916961669922, "compression_ratio": 1.4791666666666667, "no_speech_prob": 0.07692836225032806}, {"id": 222, "seek": 143224, "start": 1447.76, "end": 1454.88, "text": " even with a huge amount of data. So it will play a little bit of chess, it will memorize the openings", "tokens": [51140, 754, 365, 257, 2603, 2372, 295, 1412, 13, 407, 309, 486, 862, 257, 707, 857, 295, 24122, 11, 309, 486, 27478, 264, 35941, 51496], "temperature": 0.0, "avg_logprob": -0.14046916961669922, "compression_ratio": 1.4791666666666667, "no_speech_prob": 0.07692836225032806}, {"id": 223, "seek": 143224, "start": 1454.88, "end": 1459.28, "text": " and be okay for the first 15 moves, but it gets far enough away from what it's trained on and", "tokens": [51496, 293, 312, 1392, 337, 264, 700, 2119, 6067, 11, 457, 309, 2170, 1400, 1547, 1314, 490, 437, 309, 311, 8895, 322, 293, 51716], "temperature": 0.0, "avg_logprob": -0.14046916961669922, "compression_ratio": 1.4791666666666667, "no_speech_prob": 0.07692836225032806}, {"id": 224, "seek": 145928, "start": 1459.28, "end": 1464.0, "text": " it falls apart. This is characteristic of these systems. It's not really characteristic in the", "tokens": [50364, 309, 8804, 4936, 13, 639, 307, 16282, 295, 613, 3652, 13, 467, 311, 406, 534, 16282, 294, 264, 50600], "temperature": 0.0, "avg_logprob": -0.09731694271689967, "compression_ratio": 1.5743801652892562, "no_speech_prob": 0.016896873712539673}, {"id": 225, "seek": 145928, "start": 1464.0, "end": 1470.72, "text": " same way of adults or even teenage humans. Almost anything that it does, it does unreliably.", "tokens": [50600, 912, 636, 295, 8865, 420, 754, 26866, 6255, 13, 12627, 1340, 300, 309, 775, 11, 309, 775, 20584, 2081, 1188, 13, 50936], "temperature": 0.0, "avg_logprob": -0.09731694271689967, "compression_ratio": 1.5743801652892562, "no_speech_prob": 0.016896873712539673}, {"id": 226, "seek": 145928, "start": 1470.72, "end": 1476.0, "text": " And give another example, you can ask a human to write a biography of someone and don't make", "tokens": [50936, 400, 976, 1071, 1365, 11, 291, 393, 1029, 257, 1952, 281, 2464, 257, 37062, 295, 1580, 293, 500, 380, 652, 51200], "temperature": 0.0, "avg_logprob": -0.09731694271689967, "compression_ratio": 1.5743801652892562, "no_speech_prob": 0.016896873712539673}, {"id": 227, "seek": 145928, "start": 1476.0, "end": 1485.6, "text": " stuff up, and you really can't ask GPT to do that. Yeah, like it's a bit difficult because you could", "tokens": [51200, 1507, 493, 11, 293, 291, 534, 393, 380, 1029, 26039, 51, 281, 360, 300, 13, 865, 11, 411, 309, 311, 257, 857, 2252, 570, 291, 727, 51680], "temperature": 0.0, "avg_logprob": -0.09731694271689967, "compression_ratio": 1.5743801652892562, "no_speech_prob": 0.016896873712539673}, {"id": 228, "seek": 148560, "start": 1485.6, "end": 1489.84, "text": " always be cherry picking something that humans aren't usually good at. But to me, it does seem", "tokens": [50364, 1009, 312, 20164, 8867, 746, 300, 6255, 3212, 380, 2673, 665, 412, 13, 583, 281, 385, 11, 309, 775, 1643, 50576], "temperature": 0.0, "avg_logprob": -0.11818181950113048, "compression_ratio": 1.5625, "no_speech_prob": 0.0694747194647789}, {"id": 229, "seek": 148560, "start": 1489.84, "end": 1495.76, "text": " like there's this broad range of problems that don't seem especially to play to humans' strong", "tokens": [50576, 411, 456, 311, 341, 4152, 3613, 295, 2740, 300, 500, 380, 1643, 2318, 281, 862, 281, 6255, 6, 2068, 50872], "temperature": 0.0, "avg_logprob": -0.11818181950113048, "compression_ratio": 1.5625, "no_speech_prob": 0.0694747194647789}, {"id": 230, "seek": 148560, "start": 1495.76, "end": 1504.08, "text": " points or machine weak points, where GPT-4 will do no better than a seven-year-old on those problems.", "tokens": [50872, 2793, 420, 3479, 5336, 2793, 11, 689, 26039, 51, 12, 19, 486, 360, 572, 1101, 813, 257, 3407, 12, 5294, 12, 2641, 322, 729, 2740, 13, 51288], "temperature": 0.0, "avg_logprob": -0.11818181950113048, "compression_ratio": 1.5625, "no_speech_prob": 0.0694747194647789}, {"id": 231, "seek": 148560, "start": 1507.76, "end": 1513.52, "text": " I do feel like these examples are cherry picked because if I just take a different,", "tokens": [51472, 286, 360, 841, 411, 613, 5110, 366, 20164, 6183, 570, 498, 286, 445, 747, 257, 819, 11, 51760], "temperature": 0.0, "avg_logprob": -0.11818181950113048, "compression_ratio": 1.5625, "no_speech_prob": 0.0694747194647789}, {"id": 232, "seek": 151352, "start": 1513.52, "end": 1518.48, "text": " very typical example, I'm writing an op-ed for the New York Times, say, about any given", "tokens": [50364, 588, 7476, 1365, 11, 286, 478, 3579, 364, 999, 12, 292, 337, 264, 1873, 3609, 11366, 11, 584, 11, 466, 604, 2212, 50612], "temperature": 0.0, "avg_logprob": -0.10453413982017368, "compression_ratio": 1.4653846153846153, "no_speech_prob": 0.021593734622001648}, {"id": 233, "seek": 151352, "start": 1518.48, "end": 1525.04, "text": " subject in the world, and my choice is to have a smart 14-year-old next to me with anything that's", "tokens": [50612, 3983, 294, 264, 1002, 11, 293, 452, 3922, 307, 281, 362, 257, 4069, 3499, 12, 5294, 12, 2641, 958, 281, 385, 365, 1340, 300, 311, 50940], "temperature": 0.0, "avg_logprob": -0.10453413982017368, "compression_ratio": 1.4653846153846153, "no_speech_prob": 0.021593734622001648}, {"id": 234, "seek": 151352, "start": 1525.04, "end": 1534.0, "text": " in his mind already or GPT. There's no comparison. So which of these sort of examples is the litmus", "tokens": [50940, 294, 702, 1575, 1217, 420, 26039, 51, 13, 821, 311, 572, 9660, 13, 407, 597, 295, 613, 1333, 295, 5110, 307, 264, 7997, 18761, 51388], "temperature": 0.0, "avg_logprob": -0.10453413982017368, "compression_ratio": 1.4653846153846153, "no_speech_prob": 0.021593734622001648}, {"id": 235, "seek": 151352, "start": 1534.0, "end": 1543.28, "text": " test for who is more intelligent? If you did it on a topic where it couldn't rely on memorized", "tokens": [51388, 1500, 337, 567, 307, 544, 13232, 30, 759, 291, 630, 309, 322, 257, 4829, 689, 309, 2809, 380, 10687, 322, 46677, 51852], "temperature": 0.0, "avg_logprob": -0.10453413982017368, "compression_ratio": 1.4653846153846153, "no_speech_prob": 0.021593734622001648}, {"id": 236, "seek": 154328, "start": 1543.36, "end": 1549.52, "text": " text, you might actually change your mind on that. So the thing about writing a Times op-ed", "tokens": [50368, 2487, 11, 291, 1062, 767, 1319, 428, 1575, 322, 300, 13, 407, 264, 551, 466, 3579, 257, 11366, 999, 12, 292, 50676], "temperature": 0.0, "avg_logprob": -0.10994259108844985, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0023956208024173975}, {"id": 237, "seek": 154328, "start": 1549.52, "end": 1554.0, "text": " is most of the things that you propose to it, there's actually something that it can", "tokens": [50676, 307, 881, 295, 264, 721, 300, 291, 17421, 281, 309, 11, 456, 311, 767, 746, 300, 309, 393, 50900], "temperature": 0.0, "avg_logprob": -0.10994259108844985, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0023956208024173975}, {"id": 238, "seek": 154328, "start": 1554.0, "end": 1558.72, "text": " pastiche together from its dataset. That doesn't mean that it really understands what's going on.", "tokens": [50900, 1791, 9304, 1214, 490, 1080, 28872, 13, 663, 1177, 380, 914, 300, 309, 534, 15146, 437, 311, 516, 322, 13, 51136], "temperature": 0.0, "avg_logprob": -0.10994259108844985, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0023956208024173975}, {"id": 239, "seek": 154328, "start": 1558.72, "end": 1564.08, "text": " It doesn't mean that that's general capability. Also, as the human, you're doing all the hard", "tokens": [51136, 467, 1177, 380, 914, 300, 300, 311, 2674, 13759, 13, 2743, 11, 382, 264, 1952, 11, 291, 434, 884, 439, 264, 1152, 51404], "temperature": 0.0, "avg_logprob": -0.10994259108844985, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0023956208024173975}, {"id": 240, "seek": 154328, "start": 1564.08, "end": 1570.24, "text": " parts. Obviously, a human is going to prefer, if a human has a math problem, we're going to rather", "tokens": [51404, 3166, 13, 7580, 11, 257, 1952, 307, 516, 281, 4382, 11, 498, 257, 1952, 575, 257, 5221, 1154, 11, 321, 434, 516, 281, 2831, 51712], "temperature": 0.0, "avg_logprob": -0.10994259108844985, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0023956208024173975}, {"id": 241, "seek": 157024, "start": 1570.32, "end": 1575.52, "text": " use a calculator than another human. Similarly, with the New York Times op-ed, you're doing all the", "tokens": [50368, 764, 257, 24993, 813, 1071, 1952, 13, 13157, 11, 365, 264, 1873, 3609, 11366, 999, 12, 292, 11, 291, 434, 884, 439, 264, 50628], "temperature": 0.0, "avg_logprob": -0.10049060791257829, "compression_ratio": 1.7355072463768115, "no_speech_prob": 0.047381240874528885}, {"id": 242, "seek": 157024, "start": 1575.52, "end": 1582.8, "text": " parts that are hard for GPT-4, and then you're asking GPT-4 to just do some of the parts that", "tokens": [50628, 3166, 300, 366, 1152, 337, 26039, 51, 12, 19, 11, 293, 550, 291, 434, 3365, 26039, 51, 12, 19, 281, 445, 360, 512, 295, 264, 3166, 300, 50992], "temperature": 0.0, "avg_logprob": -0.10049060791257829, "compression_ratio": 1.7355072463768115, "no_speech_prob": 0.047381240874528885}, {"id": 243, "seek": 157024, "start": 1582.8, "end": 1588.72, "text": " are hard for you. You're always going to prefer an AI partner rather than a human partner within", "tokens": [50992, 366, 1152, 337, 291, 13, 509, 434, 1009, 516, 281, 4382, 364, 7318, 4975, 2831, 813, 257, 1952, 4975, 1951, 51288], "temperature": 0.0, "avg_logprob": -0.10049060791257829, "compression_ratio": 1.7355072463768115, "no_speech_prob": 0.047381240874528885}, {"id": 244, "seek": 157024, "start": 1588.72, "end": 1593.52, "text": " that range of the human can do all the human stuff, and you want an AI to do whatever the AI", "tokens": [51288, 300, 3613, 295, 264, 1952, 393, 360, 439, 264, 1952, 1507, 11, 293, 291, 528, 364, 7318, 281, 360, 2035, 264, 7318, 51528], "temperature": 0.0, "avg_logprob": -0.10049060791257829, "compression_ratio": 1.7355072463768115, "no_speech_prob": 0.047381240874528885}, {"id": 245, "seek": 157024, "start": 1593.52, "end": 1599.04, "text": " is good at at the moment. An analogy that's maybe a little bit helpful here is driverless cars.", "tokens": [51528, 307, 665, 412, 412, 264, 1623, 13, 1107, 21663, 300, 311, 1310, 257, 707, 857, 4961, 510, 307, 6787, 1832, 5163, 13, 51804], "temperature": 0.0, "avg_logprob": -0.10049060791257829, "compression_ratio": 1.7355072463768115, "no_speech_prob": 0.047381240874528885}, {"id": 246, "seek": 159904, "start": 1599.76, "end": 1604.96, "text": " It turns out that on highways and ordinary traffic, they're probably better than people,", "tokens": [50400, 467, 4523, 484, 300, 322, 43747, 293, 10547, 6419, 11, 436, 434, 1391, 1101, 813, 561, 11, 50660], "temperature": 0.0, "avg_logprob": -0.08903848207913913, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.002357404213398695}, {"id": 247, "seek": 159904, "start": 1604.96, "end": 1609.92, "text": " and on unusual circumstances, they're really worse than people. A Tesla not too long ago", "tokens": [50660, 293, 322, 10901, 9121, 11, 436, 434, 534, 5324, 813, 561, 13, 316, 13666, 406, 886, 938, 2057, 50908], "temperature": 0.0, "avg_logprob": -0.08903848207913913, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.002357404213398695}, {"id": 248, "seek": 159904, "start": 1609.92, "end": 1614.8, "text": " ran into a jet, and a human wouldn't do that, like slow speed being summoned across a parking", "tokens": [50908, 5872, 666, 257, 14452, 11, 293, 257, 1952, 2759, 380, 360, 300, 11, 411, 2964, 3073, 885, 40791, 2108, 257, 9893, 51152], "temperature": 0.0, "avg_logprob": -0.08903848207913913, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.002357404213398695}, {"id": 249, "seek": 159904, "start": 1614.8, "end": 1619.92, "text": " lot. A human would never do that. There are different strengths and weaknesses. The strengths", "tokens": [51152, 688, 13, 316, 1952, 576, 1128, 360, 300, 13, 821, 366, 819, 16986, 293, 24381, 13, 440, 16986, 51408], "temperature": 0.0, "avg_logprob": -0.08903848207913913, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.002357404213398695}, {"id": 250, "seek": 159904, "start": 1619.92, "end": 1624.72, "text": " of a lot of the current kinds of technology is that they can either pastiche together or", "tokens": [51408, 295, 257, 688, 295, 264, 2190, 3685, 295, 2899, 307, 300, 436, 393, 2139, 1791, 9304, 1214, 420, 51648], "temperature": 0.0, "avg_logprob": -0.08903848207913913, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.002357404213398695}, {"id": 251, "seek": 162472, "start": 1625.52, "end": 1631.2, "text": " make not literal analogies when we go into the details, but to stored examples, and they tend", "tokens": [50404, 652, 406, 20411, 16660, 530, 562, 321, 352, 666, 264, 4365, 11, 457, 281, 12187, 5110, 11, 293, 436, 3928, 50688], "temperature": 0.0, "avg_logprob": -0.10254138448963994, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0016725152963772416}, {"id": 252, "seek": 162472, "start": 1631.2, "end": 1637.6000000000001, "text": " to be poor when you get to outlier cases. That's persistent across most of the technologies", "tokens": [50688, 281, 312, 4716, 562, 291, 483, 281, 484, 2753, 3331, 13, 663, 311, 24315, 2108, 881, 295, 264, 7943, 51008], "temperature": 0.0, "avg_logprob": -0.10254138448963994, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0016725152963772416}, {"id": 253, "seek": 162472, "start": 1638.24, "end": 1643.52, "text": " that we use right now. If you stick to stuff in which there's a lot of data, you'll be happy", "tokens": [51040, 300, 321, 764, 558, 586, 13, 759, 291, 2897, 281, 1507, 294, 597, 456, 311, 257, 688, 295, 1412, 11, 291, 603, 312, 2055, 51304], "temperature": 0.0, "avg_logprob": -0.10254138448963994, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0016725152963772416}, {"id": 254, "seek": 162472, "start": 1643.52, "end": 1647.76, "text": " with the results you get from these systems. You move far enough away, not so much.", "tokens": [51304, 365, 264, 3542, 291, 483, 490, 613, 3652, 13, 509, 1286, 1400, 1547, 1314, 11, 406, 370, 709, 13, 51516], "temperature": 0.0, "avg_logprob": -0.10254138448963994, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0016725152963772416}, {"id": 255, "seek": 162472, "start": 1649.2, "end": 1654.16, "text": " What we're going to see over time is that the length of the debate about whether or not it's", "tokens": [51588, 708, 321, 434, 516, 281, 536, 670, 565, 307, 300, 264, 4641, 295, 264, 7958, 466, 1968, 420, 406, 309, 311, 51836], "temperature": 0.0, "avg_logprob": -0.10254138448963994, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0016725152963772416}, {"id": 256, "seek": 165416, "start": 1654.16, "end": 1660.88, "text": " still dumber than you gets longer and longer and longer. Then if things are allowed to just keep", "tokens": [50364, 920, 274, 4182, 813, 291, 2170, 2854, 293, 2854, 293, 2854, 13, 1396, 498, 721, 366, 4350, 281, 445, 1066, 50700], "temperature": 0.0, "avg_logprob": -0.1005776386994582, "compression_ratio": 1.726235741444867, "no_speech_prob": 0.000754753069486469}, {"id": 257, "seek": 165416, "start": 1660.88, "end": 1667.28, "text": " running and nobody dies, then at some point it switches over to a very long debate about", "tokens": [50700, 2614, 293, 5079, 2714, 11, 550, 412, 512, 935, 309, 19458, 670, 281, 257, 588, 938, 7958, 466, 51020], "temperature": 0.0, "avg_logprob": -0.1005776386994582, "compression_ratio": 1.726235741444867, "no_speech_prob": 0.000754753069486469}, {"id": 258, "seek": 165416, "start": 1667.28, "end": 1672.72, "text": " is it smarter than you, which then gets shorter and shorter and shorter, and eventually reaches", "tokens": [51020, 307, 309, 20294, 813, 291, 11, 597, 550, 2170, 11639, 293, 11639, 293, 11639, 11, 293, 4728, 14235, 51292], "temperature": 0.0, "avg_logprob": -0.1005776386994582, "compression_ratio": 1.726235741444867, "no_speech_prob": 0.000754753069486469}, {"id": 259, "seek": 165416, "start": 1672.72, "end": 1678.0800000000002, "text": " a point where it's pretty unambiguous if you're paying attention. Now, I suspect that", "tokens": [51292, 257, 935, 689, 309, 311, 1238, 517, 2173, 30525, 498, 291, 434, 6229, 3202, 13, 823, 11, 286, 9091, 300, 51560], "temperature": 0.0, "avg_logprob": -0.1005776386994582, "compression_ratio": 1.726235741444867, "no_speech_prob": 0.000754753069486469}, {"id": 260, "seek": 165416, "start": 1679.1200000000001, "end": 1683.92, "text": " this process gets interrupted by everybody dying. In particular, there's a question of", "tokens": [51612, 341, 1399, 2170, 30329, 538, 2201, 8639, 13, 682, 1729, 11, 456, 311, 257, 1168, 295, 51852], "temperature": 0.0, "avg_logprob": -0.1005776386994582, "compression_ratio": 1.726235741444867, "no_speech_prob": 0.000754753069486469}, {"id": 261, "seek": 168392, "start": 1683.92, "end": 1690.64, "text": " the point at which it becomes better than humanity at building the next edition of the AI system", "tokens": [50364, 264, 935, 412, 597, 309, 3643, 1101, 813, 10243, 412, 2390, 264, 958, 11377, 295, 264, 7318, 1185, 50700], "temperature": 0.0, "avg_logprob": -0.11601084754580543, "compression_ratio": 1.5165289256198347, "no_speech_prob": 0.00048762999358586967}, {"id": 262, "seek": 168392, "start": 1690.64, "end": 1695.28, "text": " and how fast do things snowball once you get to that point? Possibly, you do not have time for", "tokens": [50700, 293, 577, 2370, 360, 721, 46143, 1564, 291, 483, 281, 300, 935, 30, 33112, 3545, 11, 291, 360, 406, 362, 565, 337, 50932], "temperature": 0.0, "avg_logprob": -0.11601084754580543, "compression_ratio": 1.5165289256198347, "no_speech_prob": 0.00048762999358586967}, {"id": 263, "seek": 168392, "start": 1695.8400000000001, "end": 1701.76, "text": " further public debates or even a two-hour Twitter space, depending on how that goes.", "tokens": [50960, 3052, 1908, 24203, 420, 754, 257, 732, 12, 18048, 5794, 1901, 11, 5413, 322, 577, 300, 1709, 13, 51256], "temperature": 0.0, "avg_logprob": -0.11601084754580543, "compression_ratio": 1.5165289256198347, "no_speech_prob": 0.00048762999358586967}, {"id": 264, "seek": 168392, "start": 1702.96, "end": 1710.3200000000002, "text": " Some of the limitations of GPT are completely understandable, just from a little knowledge", "tokens": [51316, 2188, 295, 264, 15705, 295, 26039, 51, 366, 2584, 25648, 11, 445, 490, 257, 707, 3601, 51684], "temperature": 0.0, "avg_logprob": -0.11601084754580543, "compression_ratio": 1.5165289256198347, "no_speech_prob": 0.00048762999358586967}, {"id": 265, "seek": 171032, "start": 1710.3999999999999, "end": 1718.8, "text": " of how it works. It does not have an internal memory per se other than what appears on the", "tokens": [50368, 295, 577, 309, 1985, 13, 467, 775, 406, 362, 364, 6920, 4675, 680, 369, 661, 813, 437, 7038, 322, 264, 50788], "temperature": 0.0, "avg_logprob": -0.07813386122385661, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.4097997844219208}, {"id": 266, "seek": 171032, "start": 1718.8, "end": 1725.2, "text": " screen in front of you. This is why it's turned out to be so effective to explicitly tell it.", "tokens": [50788, 2568, 294, 1868, 295, 291, 13, 639, 307, 983, 309, 311, 3574, 484, 281, 312, 370, 4942, 281, 20803, 980, 309, 13, 51108], "temperature": 0.0, "avg_logprob": -0.07813386122385661, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.4097997844219208}, {"id": 267, "seek": 171032, "start": 1725.84, "end": 1731.6, "text": " Let's think step by step when it's solving a math problem, for example. You have to tell it to", "tokens": [51140, 961, 311, 519, 1823, 538, 1823, 562, 309, 311, 12606, 257, 5221, 1154, 11, 337, 1365, 13, 509, 362, 281, 980, 309, 281, 51428], "temperature": 0.0, "avg_logprob": -0.07813386122385661, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.4097997844219208}, {"id": 268, "seek": 171032, "start": 1731.6, "end": 1737.84, "text": " show all of its work because it doesn't have an internal memory with which to do that. Likewise,", "tokens": [51428, 855, 439, 295, 1080, 589, 570, 309, 1177, 380, 362, 364, 6920, 4675, 365, 597, 281, 360, 300, 13, 30269, 11, 51740], "temperature": 0.0, "avg_logprob": -0.07813386122385661, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.4097997844219208}, {"id": 269, "seek": 173784, "start": 1737.84, "end": 1744.08, "text": " when people complain about it, hallucinating references that don't exist, well, the truth is", "tokens": [50364, 562, 561, 11024, 466, 309, 11, 35212, 8205, 15400, 300, 500, 380, 2514, 11, 731, 11, 264, 3494, 307, 50676], "temperature": 0.0, "avg_logprob": -0.10549272236071135, "compression_ratio": 1.51417004048583, "no_speech_prob": 0.10219371318817139}, {"id": 270, "seek": 173784, "start": 1744.08, "end": 1750.24, "text": " when someone asks me for a citation, if I'm not allowed to use Google, I might have a vague", "tokens": [50676, 562, 1580, 8962, 385, 337, 257, 45590, 11, 498, 286, 478, 406, 4350, 281, 764, 3329, 11, 286, 1062, 362, 257, 24247, 50984], "temperature": 0.0, "avg_logprob": -0.10549272236071135, "compression_ratio": 1.51417004048583, "no_speech_prob": 0.10219371318817139}, {"id": 271, "seek": 173784, "start": 1750.24, "end": 1756.32, "text": " recollection of some of the authors, and I'll probably do a very similar thing to what GPT", "tokens": [50984, 39495, 10183, 295, 512, 295, 264, 16552, 11, 293, 286, 603, 1391, 360, 257, 588, 2531, 551, 281, 437, 26039, 51, 51288], "temperature": 0.0, "avg_logprob": -0.10549272236071135, "compression_ratio": 1.51417004048583, "no_speech_prob": 0.10219371318817139}, {"id": 272, "seek": 173784, "start": 1756.32, "end": 1761.9199999999998, "text": " does. I'll hallucinate. There's a great phrase I learned the other day, which is frequently wrong,", "tokens": [51288, 775, 13, 286, 603, 35212, 13923, 13, 821, 311, 257, 869, 9535, 286, 3264, 264, 661, 786, 11, 597, 307, 10374, 2085, 11, 51568], "temperature": 0.0, "avg_logprob": -0.10549272236071135, "compression_ratio": 1.51417004048583, "no_speech_prob": 0.10219371318817139}, {"id": 273, "seek": 176192, "start": 1762.0, "end": 1769.28, "text": " never in doubt. That's true. I'm not going to make up a reference with full detail, page numbers,", "tokens": [50368, 1128, 294, 6385, 13, 663, 311, 2074, 13, 286, 478, 406, 516, 281, 652, 493, 257, 6408, 365, 1577, 2607, 11, 3028, 3547, 11, 50732], "temperature": 0.0, "avg_logprob": -0.18782224153217517, "compression_ratio": 1.4784313725490197, "no_speech_prob": 0.47977831959724426}, {"id": 274, "seek": 176192, "start": 1769.28, "end": 1775.52, "text": " titles, so forth. I might say, look, I don't remember 2012 or something like that. Whereas,", "tokens": [50732, 12992, 11, 370, 5220, 13, 286, 1062, 584, 11, 574, 11, 286, 500, 380, 1604, 9125, 420, 746, 411, 300, 13, 13813, 11, 51044], "temperature": 0.0, "avg_logprob": -0.18782224153217517, "compression_ratio": 1.4784313725490197, "no_speech_prob": 0.47977831959724426}, {"id": 275, "seek": 176192, "start": 1775.52, "end": 1786.16, "text": " GPT-4, what it's going to say is 2017, Aaronson and Yodkowski, New York Times, pages 13 to 17.", "tokens": [51044, 26039, 51, 12, 19, 11, 437, 309, 311, 516, 281, 584, 307, 6591, 11, 316, 289, 892, 266, 293, 398, 378, 74, 21866, 11, 1873, 3609, 11366, 11, 7183, 3705, 281, 3282, 13, 51576], "temperature": 0.0, "avg_logprob": -0.18782224153217517, "compression_ratio": 1.4784313725490197, "no_speech_prob": 0.47977831959724426}, {"id": 276, "seek": 176192, "start": 1786.16, "end": 1791.2, "text": " No, it does need to get much, much better at knowing what it doesn't know. And yet, already,", "tokens": [51576, 883, 11, 309, 775, 643, 281, 483, 709, 11, 709, 1101, 412, 5276, 437, 309, 1177, 380, 458, 13, 400, 1939, 11, 1217, 11, 51828], "temperature": 0.0, "avg_logprob": -0.18782224153217517, "compression_ratio": 1.4784313725490197, "no_speech_prob": 0.47977831959724426}, {"id": 277, "seek": 179120, "start": 1791.2, "end": 1798.88, "text": " I've seen a noticeable improvement there, going from GPT-3 to GPT-4. For example,", "tokens": [50364, 286, 600, 1612, 257, 26041, 10444, 456, 11, 516, 490, 26039, 51, 12, 18, 281, 26039, 51, 12, 19, 13, 1171, 1365, 11, 50748], "temperature": 0.0, "avg_logprob": -0.07955876350402832, "compression_ratio": 1.5169491525423728, "no_speech_prob": 0.004197247326374054}, {"id": 278, "seek": 179120, "start": 1798.88, "end": 1804.72, "text": " if you ask GPT-3, prove that there are only finitely many prime numbers, it will give you", "tokens": [50748, 498, 291, 1029, 26039, 51, 12, 18, 11, 7081, 300, 456, 366, 787, 962, 1959, 867, 5835, 3547, 11, 309, 486, 976, 291, 51040], "temperature": 0.0, "avg_logprob": -0.07955876350402832, "compression_ratio": 1.5169491525423728, "no_speech_prob": 0.004197247326374054}, {"id": 279, "seek": 179120, "start": 1804.72, "end": 1810.8, "text": " a proof, even though the statement is false. And it will have an error, which is similar to the", "tokens": [51040, 257, 8177, 11, 754, 1673, 264, 5629, 307, 7908, 13, 400, 309, 486, 362, 364, 6713, 11, 597, 307, 2531, 281, 264, 51344], "temperature": 0.0, "avg_logprob": -0.07955876350402832, "compression_ratio": 1.5169491525423728, "no_speech_prob": 0.004197247326374054}, {"id": 280, "seek": 179120, "start": 1810.8, "end": 1817.28, "text": " errors on 1,000 exams that I've graded, just trying to get something past you, hoping that", "tokens": [51344, 13603, 322, 502, 11, 1360, 20514, 300, 286, 600, 2771, 292, 11, 445, 1382, 281, 483, 746, 1791, 291, 11, 7159, 300, 51668], "temperature": 0.0, "avg_logprob": -0.07955876350402832, "compression_ratio": 1.5169491525423728, "no_speech_prob": 0.004197247326374054}, {"id": 281, "seek": 181728, "start": 1817.28, "end": 1822.8, "text": " you won't notice. Hey, if you ask GPT-4, prove that there are only finitely many prime numbers,", "tokens": [50364, 291, 1582, 380, 3449, 13, 1911, 11, 498, 291, 1029, 26039, 51, 12, 19, 11, 7081, 300, 456, 366, 787, 962, 1959, 867, 5835, 3547, 11, 50640], "temperature": 0.0, "avg_logprob": -0.10824418446374318, "compression_ratio": 1.6597938144329898, "no_speech_prob": 0.12753470242023468}, {"id": 282, "seek": 181728, "start": 1822.8, "end": 1827.36, "text": " it says, no, that's a trick question. Actually, there are infinitely many primes. And here's why.", "tokens": [50640, 309, 1619, 11, 572, 11, 300, 311, 257, 4282, 1168, 13, 5135, 11, 456, 366, 36227, 867, 582, 1532, 13, 400, 510, 311, 983, 13, 50868], "temperature": 0.0, "avg_logprob": -0.10824418446374318, "compression_ratio": 1.6597938144329898, "no_speech_prob": 0.12753470242023468}, {"id": 283, "seek": 181728, "start": 1827.36, "end": 1832.72, "text": " Yeah. Part of the problem with doing the science here is that I think you would know better since", "tokens": [50868, 865, 13, 4100, 295, 264, 1154, 365, 884, 264, 3497, 510, 307, 300, 286, 519, 291, 576, 458, 1101, 1670, 51136], "temperature": 0.0, "avg_logprob": -0.10824418446374318, "compression_ratio": 1.6597938144329898, "no_speech_prob": 0.12753470242023468}, {"id": 284, "seek": 181728, "start": 1832.72, "end": 1838.48, "text": " you work part-time or whatever to open AI. But my sense is that a lot of the examples that get", "tokens": [51136, 291, 589, 644, 12, 3766, 420, 2035, 281, 1269, 7318, 13, 583, 452, 2020, 307, 300, 257, 688, 295, 264, 5110, 300, 483, 51424], "temperature": 0.0, "avg_logprob": -0.10824418446374318, "compression_ratio": 1.6597938144329898, "no_speech_prob": 0.12753470242023468}, {"id": 285, "seek": 181728, "start": 1838.48, "end": 1844.16, "text": " posted on Twitter, particularly by the likes of me and other critics or other skeptics, I should", "tokens": [51424, 9437, 322, 5794, 11, 4098, 538, 264, 5902, 295, 385, 293, 661, 22503, 420, 661, 19128, 1167, 11, 286, 820, 51708], "temperature": 0.0, "avg_logprob": -0.10824418446374318, "compression_ratio": 1.6597938144329898, "no_speech_prob": 0.12753470242023468}, {"id": 286, "seek": 184416, "start": 1844.16, "end": 1850.3200000000002, "text": " say, is the system gets trained on those. So almost everything that people write about it,", "tokens": [50364, 584, 11, 307, 264, 1185, 2170, 8895, 322, 729, 13, 407, 1920, 1203, 300, 561, 2464, 466, 309, 11, 50672], "temperature": 0.0, "avg_logprob": -0.09830784419226268, "compression_ratio": 1.7266187050359711, "no_speech_prob": 0.014938583597540855}, {"id": 287, "seek": 184416, "start": 1850.3200000000002, "end": 1854.96, "text": " I think, is in the training set. So it's hard to do the science when the system's constantly being", "tokens": [50672, 286, 519, 11, 307, 294, 264, 3097, 992, 13, 407, 309, 311, 1152, 281, 360, 264, 3497, 562, 264, 1185, 311, 6460, 885, 50904], "temperature": 0.0, "avg_logprob": -0.09830784419226268, "compression_ratio": 1.7266187050359711, "no_speech_prob": 0.014938583597540855}, {"id": 288, "seek": 184416, "start": 1854.96, "end": 1860.5600000000002, "text": " trained, especially in the RLHF side of things. And we don't actually know what's in GPT-4. So", "tokens": [50904, 8895, 11, 2318, 294, 264, 497, 43, 39, 37, 1252, 295, 721, 13, 400, 321, 500, 380, 767, 458, 437, 311, 294, 26039, 51, 12, 19, 13, 407, 51184], "temperature": 0.0, "avg_logprob": -0.09830784419226268, "compression_ratio": 1.7266187050359711, "no_speech_prob": 0.014938583597540855}, {"id": 289, "seek": 184416, "start": 1860.5600000000002, "end": 1865.92, "text": " we don't even know if they're regular expressions and simple rules, match things. So we can't do", "tokens": [51184, 321, 500, 380, 754, 458, 498, 436, 434, 3890, 15277, 293, 2199, 4474, 11, 2995, 721, 13, 407, 321, 393, 380, 360, 51452], "temperature": 0.0, "avg_logprob": -0.09830784419226268, "compression_ratio": 1.7266187050359711, "no_speech_prob": 0.014938583597540855}, {"id": 290, "seek": 184416, "start": 1865.92, "end": 1872.0800000000002, "text": " the kind of science we used to be able to do. This conversation, this subtree of the conversation,", "tokens": [51452, 264, 733, 295, 3497, 321, 1143, 281, 312, 1075, 281, 360, 13, 639, 3761, 11, 341, 7257, 701, 295, 264, 3761, 11, 51760], "temperature": 0.0, "avg_logprob": -0.09830784419226268, "compression_ratio": 1.7266187050359711, "no_speech_prob": 0.014938583597540855}, {"id": 291, "seek": 187208, "start": 1872.08, "end": 1880.24, "text": " I think, has no natural endpoint. So if I can sort of zoom out a bit, I think there's a pretty", "tokens": [50364, 286, 519, 11, 575, 572, 3303, 35795, 13, 407, 498, 286, 393, 1333, 295, 8863, 484, 257, 857, 11, 286, 519, 456, 311, 257, 1238, 50772], "temperature": 0.0, "avg_logprob": -0.055038753820925344, "compression_ratio": 1.583673469387755, "no_speech_prob": 0.007004446815699339}, {"id": 292, "seek": 187208, "start": 1880.24, "end": 1886.56, "text": " solid sense in which humans are more generally intelligent than chimpanzees. As you get closer", "tokens": [50772, 5100, 2020, 294, 597, 6255, 366, 544, 5101, 13232, 813, 18375, 48410, 279, 13, 1018, 291, 483, 4966, 51088], "temperature": 0.0, "avg_logprob": -0.055038753820925344, "compression_ratio": 1.583673469387755, "no_speech_prob": 0.007004446815699339}, {"id": 293, "seek": 187208, "start": 1886.56, "end": 1895.04, "text": " and closer to the human level, I would say that the direction here is still clear, that the comparison", "tokens": [51088, 293, 4966, 281, 264, 1952, 1496, 11, 286, 576, 584, 300, 264, 3513, 510, 307, 920, 1850, 11, 300, 264, 9660, 51512], "temperature": 0.0, "avg_logprob": -0.055038753820925344, "compression_ratio": 1.583673469387755, "no_speech_prob": 0.007004446815699339}, {"id": 294, "seek": 187208, "start": 1895.04, "end": 1901.04, "text": " is still clear. We are still smarter than GPT-4. This is not going to take control of the world", "tokens": [51512, 307, 920, 1850, 13, 492, 366, 920, 20294, 813, 26039, 51, 12, 19, 13, 639, 307, 406, 516, 281, 747, 1969, 295, 264, 1002, 51812], "temperature": 0.0, "avg_logprob": -0.055038753820925344, "compression_ratio": 1.583673469387755, "no_speech_prob": 0.007004446815699339}, {"id": 295, "seek": 190104, "start": 1901.04, "end": 1909.84, "text": " from us. But the conversations get longer. The definitions start to break down around the edges.", "tokens": [50364, 490, 505, 13, 583, 264, 7315, 483, 2854, 13, 440, 21988, 722, 281, 1821, 760, 926, 264, 8819, 13, 50804], "temperature": 0.0, "avg_logprob": -0.13387356201807657, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.00439060665667057}, {"id": 296, "seek": 190104, "start": 1910.8799999999999, "end": 1915.44, "text": " But I think it also, as you keep going, it comes back together again. There's a point,", "tokens": [50856, 583, 286, 519, 309, 611, 11, 382, 291, 1066, 516, 11, 309, 1487, 646, 1214, 797, 13, 821, 311, 257, 935, 11, 51084], "temperature": 0.0, "avg_logprob": -0.13387356201807657, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.00439060665667057}, {"id": 297, "seek": 190104, "start": 1916.08, "end": 1920.32, "text": " and possibly this point is very close to the point of time to where everybody dies. So maybe we", "tokens": [51116, 293, 6264, 341, 935, 307, 588, 1998, 281, 264, 935, 295, 565, 281, 689, 2201, 2714, 13, 407, 1310, 321, 51328], "temperature": 0.0, "avg_logprob": -0.13387356201807657, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.00439060665667057}, {"id": 298, "seek": 190104, "start": 1920.32, "end": 1926.3999999999999, "text": " don't ever see it in a podcast, but there's a point where it's unambiguously smarter than you.", "tokens": [51328, 500, 380, 1562, 536, 309, 294, 257, 7367, 11, 457, 456, 311, 257, 935, 689, 309, 311, 517, 2173, 16397, 5098, 20294, 813, 291, 13, 51632], "temperature": 0.0, "avg_logprob": -0.13387356201807657, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.00439060665667057}, {"id": 299, "seek": 192640, "start": 1927.2800000000002, "end": 1935.44, "text": " And including the spark of creativity, being able to deduce things quickly rather than with tons", "tokens": [50408, 400, 3009, 264, 9908, 295, 12915, 11, 885, 1075, 281, 4172, 4176, 721, 2661, 2831, 813, 365, 9131, 50816], "temperature": 0.0, "avg_logprob": -0.11162953681134163, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.012798639945685863}, {"id": 300, "seek": 192640, "start": 1935.44, "end": 1942.48, "text": " and tons of extra evidence, strategy, cunning, modeling people, figuring out how to manipulate", "tokens": [50816, 293, 9131, 295, 2857, 4467, 11, 5206, 11, 45891, 11, 15983, 561, 11, 15213, 484, 577, 281, 20459, 51168], "temperature": 0.0, "avg_logprob": -0.11162953681134163, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.012798639945685863}, {"id": 301, "seek": 192640, "start": 1942.48, "end": 1949.3600000000001, "text": " people. So let's stipulate, Aliezer, that we're going to get to machines that can do all of that.", "tokens": [51168, 561, 13, 407, 718, 311, 37001, 5256, 11, 967, 414, 4527, 11, 300, 321, 434, 516, 281, 483, 281, 8379, 300, 393, 360, 439, 295, 300, 13, 51512], "temperature": 0.0, "avg_logprob": -0.11162953681134163, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.012798639945685863}, {"id": 302, "seek": 192640, "start": 1949.3600000000001, "end": 1954.8000000000002, "text": " And then the question is, what are they going to do? Is it a certainty that they will make", "tokens": [51512, 400, 550, 264, 1168, 307, 11, 437, 366, 436, 516, 281, 360, 30, 1119, 309, 257, 27022, 300, 436, 486, 652, 51784], "temperature": 0.0, "avg_logprob": -0.11162953681134163, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.012798639945685863}, {"id": 303, "seek": 195480, "start": 1954.8, "end": 1960.48, "text": " our annihilation part of their business? Is it a possibility? Is it an unlikely possibility?", "tokens": [50364, 527, 40430, 16067, 644, 295, 641, 1606, 30, 1119, 309, 257, 7959, 30, 1119, 309, 364, 17518, 7959, 30, 50648], "temperature": 0.0, "avg_logprob": -0.11361591372869712, "compression_ratio": 1.7192307692307693, "no_speech_prob": 0.0015702958917245269}, {"id": 304, "seek": 195480, "start": 1960.48, "end": 1964.3999999999999, "text": " I think your view is that it's a certainty. I've never really understood that part.", "tokens": [50648, 286, 519, 428, 1910, 307, 300, 309, 311, 257, 27022, 13, 286, 600, 1128, 534, 7320, 300, 644, 13, 50844], "temperature": 0.0, "avg_logprob": -0.11361591372869712, "compression_ratio": 1.7192307692307693, "no_speech_prob": 0.0015702958917245269}, {"id": 305, "seek": 195480, "start": 1965.36, "end": 1969.9199999999998, "text": " It's a certainty on the present tech, is the way I would put it. If that happened,", "tokens": [50892, 467, 311, 257, 27022, 322, 264, 1974, 7553, 11, 307, 264, 636, 286, 576, 829, 309, 13, 759, 300, 2011, 11, 51120], "temperature": 0.0, "avg_logprob": -0.11361591372869712, "compression_ratio": 1.7192307692307693, "no_speech_prob": 0.0015702958917245269}, {"id": 306, "seek": 195480, "start": 1970.6399999999999, "end": 1977.12, "text": " so in particular, if that happened tomorrow, then Modulo, Cromwell's rule, never say certain.", "tokens": [51156, 370, 294, 1729, 11, 498, 300, 2011, 4153, 11, 550, 6583, 13455, 11, 383, 4397, 6326, 311, 4978, 11, 1128, 584, 1629, 13, 51480], "temperature": 0.0, "avg_logprob": -0.11361591372869712, "compression_ratio": 1.7192307692307693, "no_speech_prob": 0.0015702958917245269}, {"id": 307, "seek": 195480, "start": 1978.24, "end": 1983.68, "text": " My probability is, yes, Modulo, the chance that my model is somehow just completely mistaken.", "tokens": [51536, 1222, 8482, 307, 11, 2086, 11, 6583, 13455, 11, 264, 2931, 300, 452, 2316, 307, 6063, 445, 2584, 21333, 13, 51808], "temperature": 0.0, "avg_logprob": -0.11361591372869712, "compression_ratio": 1.7192307692307693, "no_speech_prob": 0.0015702958917245269}, {"id": 308, "seek": 198480, "start": 1985.12, "end": 1994.56, "text": " If we got 50 years to work it out and unlimited retries, I think that'd be pretty okay. I think", "tokens": [50380, 759, 321, 658, 2625, 924, 281, 589, 309, 484, 293, 21950, 1533, 2244, 11, 286, 519, 300, 1116, 312, 1238, 1392, 13, 286, 519, 50852], "temperature": 0.0, "avg_logprob": -0.11723041534423828, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0012247026897966862}, {"id": 309, "seek": 198480, "start": 1994.56, "end": 2000.1599999999999, "text": " we'd make it. The problem is that it's a lot harder to do science when your first wrong try", "tokens": [50852, 321, 1116, 652, 309, 13, 440, 1154, 307, 300, 309, 311, 257, 688, 6081, 281, 360, 3497, 562, 428, 700, 2085, 853, 51132], "temperature": 0.0, "avg_logprob": -0.11723041534423828, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0012247026897966862}, {"id": 310, "seek": 198480, "start": 2000.1599999999999, "end": 2006.48, "text": " destroys the human species and then you don't get to try again. I mean, I think there's something,", "tokens": [51132, 36714, 264, 1952, 6172, 293, 550, 291, 500, 380, 483, 281, 853, 797, 13, 286, 914, 11, 286, 519, 456, 311, 746, 11, 51448], "temperature": 0.0, "avg_logprob": -0.11723041534423828, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0012247026897966862}, {"id": 311, "seek": 198480, "start": 2006.48, "end": 2011.12, "text": " again, that I agree with and something I'm a little bit skeptical about. So I agree that", "tokens": [51448, 797, 11, 300, 286, 3986, 365, 293, 746, 286, 478, 257, 707, 857, 28601, 466, 13, 407, 286, 3986, 300, 51680], "temperature": 0.0, "avg_logprob": -0.11723041534423828, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.0012247026897966862}, {"id": 312, "seek": 201112, "start": 2011.12, "end": 2018.0, "text": " the amount of time we have matters. I would also agree that there's no existing technology that", "tokens": [50364, 264, 2372, 295, 565, 321, 362, 7001, 13, 286, 576, 611, 3986, 300, 456, 311, 572, 6741, 2899, 300, 50708], "temperature": 0.0, "avg_logprob": -0.10001833298627068, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.016637558117508888}, {"id": 313, "seek": 201112, "start": 2018.8, "end": 2024.08, "text": " solves the alignment problem that gives a moral basis to these machines. GPT-4 is fundamentally", "tokens": [50748, 39890, 264, 18515, 1154, 300, 2709, 257, 9723, 5143, 281, 613, 8379, 13, 26039, 51, 12, 19, 307, 17879, 51012], "temperature": 0.0, "avg_logprob": -0.10001833298627068, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.016637558117508888}, {"id": 314, "seek": 201112, "start": 2024.08, "end": 2030.3999999999999, "text": " amoral. I don't think it's immoral. It's not out to get us, but it really is amoral. It can answer", "tokens": [51012, 15543, 304, 13, 286, 500, 380, 519, 309, 311, 3397, 16819, 13, 467, 311, 406, 484, 281, 483, 505, 11, 457, 309, 534, 307, 15543, 304, 13, 467, 393, 1867, 51328], "temperature": 0.0, "avg_logprob": -0.10001833298627068, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.016637558117508888}, {"id": 315, "seek": 201112, "start": 2030.3999999999999, "end": 2034.7199999999998, "text": " trolley problems because there are trolley problems in the dataset, but that doesn't mean that it", "tokens": [51328, 20680, 2030, 2740, 570, 456, 366, 20680, 2030, 2740, 294, 264, 28872, 11, 457, 300, 1177, 380, 914, 300, 309, 51544], "temperature": 0.0, "avg_logprob": -0.10001833298627068, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.016637558117508888}, {"id": 316, "seek": 201112, "start": 2034.7199999999998, "end": 2041.04, "text": " really has a moral understanding of the world. If we get to a very smart machine that by", "tokens": [51544, 534, 575, 257, 9723, 3701, 295, 264, 1002, 13, 759, 321, 483, 281, 257, 588, 4069, 3479, 300, 538, 51860], "temperature": 0.0, "avg_logprob": -0.10001833298627068, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.016637558117508888}, {"id": 317, "seek": 204104, "start": 2041.04, "end": 2045.76, "text": " all the criteria that we've talked about and it's amoral, then that's a problem for us.", "tokens": [50364, 439, 264, 11101, 300, 321, 600, 2825, 466, 293, 309, 311, 15543, 304, 11, 550, 300, 311, 257, 1154, 337, 505, 13, 50600], "temperature": 0.0, "avg_logprob": -0.12148749138698105, "compression_ratio": 1.7184115523465704, "no_speech_prob": 0.001205876120366156}, {"id": 318, "seek": 204104, "start": 2045.76, "end": 2051.84, "text": " There's a question of whether if we can get to smart machines, whether we can build them in a", "tokens": [50600, 821, 311, 257, 1168, 295, 1968, 498, 321, 393, 483, 281, 4069, 8379, 11, 1968, 321, 393, 1322, 552, 294, 257, 50904], "temperature": 0.0, "avg_logprob": -0.12148749138698105, "compression_ratio": 1.7184115523465704, "no_speech_prob": 0.001205876120366156}, {"id": 319, "seek": 204104, "start": 2051.84, "end": 2058.24, "text": " way that will have some moral basis. I think we need to make progress. The first try part,", "tokens": [50904, 636, 300, 486, 362, 512, 9723, 5143, 13, 286, 519, 321, 643, 281, 652, 4205, 13, 440, 700, 853, 644, 11, 51224], "temperature": 0.0, "avg_logprob": -0.12148749138698105, "compression_ratio": 1.7184115523465704, "no_speech_prob": 0.001205876120366156}, {"id": 320, "seek": 204104, "start": 2058.24, "end": 2063.2799999999997, "text": " I'm not willing to let pass. I understand, I think, your argument there, and maybe you should spell", "tokens": [51224, 286, 478, 406, 4950, 281, 718, 1320, 13, 286, 1223, 11, 286, 519, 11, 428, 6770, 456, 11, 293, 1310, 291, 820, 9827, 51476], "temperature": 0.0, "avg_logprob": -0.12148749138698105, "compression_ratio": 1.7184115523465704, "no_speech_prob": 0.001205876120366156}, {"id": 321, "seek": 204104, "start": 2063.2799999999997, "end": 2070.64, "text": " it out. I think that we probably get more than one shot and that it's not as dramatic and instantaneous", "tokens": [51476, 309, 484, 13, 286, 519, 300, 321, 1391, 483, 544, 813, 472, 3347, 293, 300, 309, 311, 406, 382, 12023, 293, 45596, 51844], "temperature": 0.0, "avg_logprob": -0.12148749138698105, "compression_ratio": 1.7184115523465704, "no_speech_prob": 0.001205876120366156}, {"id": 322, "seek": 207064, "start": 2070.64, "end": 2075.2, "text": " as you think. I do think one wants to think about sandboxing, one wants to think about", "tokens": [50364, 382, 291, 519, 13, 286, 360, 519, 472, 2738, 281, 519, 466, 42115, 278, 11, 472, 2738, 281, 519, 466, 50592], "temperature": 0.0, "avg_logprob": -0.15635142706136787, "compression_ratio": 1.712, "no_speech_prob": 0.007342911325395107}, {"id": 323, "seek": 207064, "start": 2075.2, "end": 2081.7599999999998, "text": " distribution, but let's say we had one evil super genius now who is smarter than everybody else,", "tokens": [50592, 7316, 11, 457, 718, 311, 584, 321, 632, 472, 6724, 1687, 14017, 586, 567, 307, 20294, 813, 2201, 1646, 11, 50920], "temperature": 0.0, "avg_logprob": -0.15635142706136787, "compression_ratio": 1.712, "no_speech_prob": 0.007342911325395107}, {"id": 324, "seek": 207064, "start": 2081.7599999999998, "end": 2084.08, "text": " like so what? One super-", "tokens": [50920, 411, 370, 437, 30, 1485, 1687, 12, 51036], "temperature": 0.0, "avg_logprob": -0.15635142706136787, "compression_ratio": 1.712, "no_speech_prob": 0.007342911325395107}, {"id": 325, "seek": 207064, "start": 2084.08, "end": 2084.8799999999997, "text": " Much smarter.", "tokens": [51036, 12313, 20294, 13, 51076], "temperature": 0.0, "avg_logprob": -0.15635142706136787, "compression_ratio": 1.712, "no_speech_prob": 0.007342911325395107}, {"id": 326, "seek": 207064, "start": 2084.8799999999997, "end": 2085.52, "text": " Say again?", "tokens": [51076, 6463, 797, 30, 51108], "temperature": 0.0, "avg_logprob": -0.15635142706136787, "compression_ratio": 1.712, "no_speech_prob": 0.007342911325395107}, {"id": 327, "seek": 207064, "start": 2085.52, "end": 2086.64, "text": " Not just a little smarter.", "tokens": [51108, 1726, 445, 257, 707, 20294, 13, 51164], "temperature": 0.0, "avg_logprob": -0.15635142706136787, "compression_ratio": 1.712, "no_speech_prob": 0.007342911325395107}, {"id": 328, "seek": 207064, "start": 2086.64, "end": 2094.08, "text": " Oh, even a lot smarter. Most super geniuses aren't actually that effective. They're not", "tokens": [51164, 876, 11, 754, 257, 688, 20294, 13, 4534, 1687, 14017, 279, 3212, 380, 767, 300, 4942, 13, 814, 434, 406, 51536], "temperature": 0.0, "avg_logprob": -0.15635142706136787, "compression_ratio": 1.712, "no_speech_prob": 0.007342911325395107}, {"id": 329, "seek": 207064, "start": 2094.08, "end": 2099.3599999999997, "text": " that focused. They were focused on other things. You're assuming that the first", "tokens": [51536, 300, 5178, 13, 814, 645, 5178, 322, 661, 721, 13, 509, 434, 11926, 300, 264, 700, 51800], "temperature": 0.0, "avg_logprob": -0.15635142706136787, "compression_ratio": 1.712, "no_speech_prob": 0.007342911325395107}, {"id": 330, "seek": 209936, "start": 2099.44, "end": 2103.76, "text": " super genius AI is going to make it its business to annihilate us and that's the part where I", "tokens": [50368, 1687, 14017, 7318, 307, 516, 281, 652, 309, 1080, 1606, 281, 40430, 48104, 505, 293, 300, 311, 264, 644, 689, 286, 50584], "temperature": 0.0, "avg_logprob": -0.133481429604923, "compression_ratio": 1.5893719806763285, "no_speech_prob": 0.0006662859814241529}, {"id": 331, "seek": 209936, "start": 2104.48, "end": 2106.0, "text": " still am a bit stuck in the argument.", "tokens": [50620, 920, 669, 257, 857, 5541, 294, 264, 6770, 13, 50696], "temperature": 0.0, "avg_logprob": -0.133481429604923, "compression_ratio": 1.5893719806763285, "no_speech_prob": 0.0006662859814241529}, {"id": 332, "seek": 209936, "start": 2108.56, "end": 2117.04, "text": " Yeah, some of this has to do with the notion that if you do a bunch of training, you start to get", "tokens": [50824, 865, 11, 512, 295, 341, 575, 281, 360, 365, 264, 10710, 300, 498, 291, 360, 257, 3840, 295, 3097, 11, 291, 722, 281, 483, 51248], "temperature": 0.0, "avg_logprob": -0.133481429604923, "compression_ratio": 1.5893719806763285, "no_speech_prob": 0.0006662859814241529}, {"id": 333, "seek": 209936, "start": 2117.6800000000003, "end": 2124.2400000000002, "text": " goal direction, even if you don't explicitly train on that. That goal direction is a natural way to", "tokens": [51280, 3387, 3513, 11, 754, 498, 291, 500, 380, 20803, 3847, 322, 300, 13, 663, 3387, 3513, 307, 257, 3303, 636, 281, 51608], "temperature": 0.0, "avg_logprob": -0.133481429604923, "compression_ratio": 1.5893719806763285, "no_speech_prob": 0.0006662859814241529}, {"id": 334, "seek": 212424, "start": 2124.24, "end": 2130.0, "text": " achieve higher capabilities. The reason why humans want things is that wanting things is an", "tokens": [50364, 4584, 2946, 10862, 13, 440, 1778, 983, 6255, 528, 721, 307, 300, 7935, 721, 307, 364, 50652], "temperature": 0.0, "avg_logprob": -0.11729768204362426, "compression_ratio": 1.7877358490566038, "no_speech_prob": 0.12239308655261993}, {"id": 335, "seek": 212424, "start": 2130.0, "end": 2137.3599999999997, "text": " effective way of getting things and so natural selection in the process of selecting exclusively", "tokens": [50652, 4942, 636, 295, 1242, 721, 293, 370, 3303, 9450, 294, 264, 1399, 295, 18182, 20638, 51020], "temperature": 0.0, "avg_logprob": -0.11729768204362426, "compression_ratio": 1.7877358490566038, "no_speech_prob": 0.12239308655261993}, {"id": 336, "seek": 212424, "start": 2137.3599999999997, "end": 2143.2799999999997, "text": " on reproductive fitness just on that one thing got us to want a bunch of things that correlated", "tokens": [51020, 322, 33569, 15303, 445, 322, 300, 472, 551, 658, 505, 281, 528, 257, 3840, 295, 721, 300, 38574, 51316], "temperature": 0.0, "avg_logprob": -0.11729768204362426, "compression_ratio": 1.7877358490566038, "no_speech_prob": 0.12239308655261993}, {"id": 337, "seek": 212424, "start": 2143.8399999999997, "end": 2149.4399999999996, "text": " with reproductive fitness in the ancestral distribution because wanting, having intelligences,", "tokens": [51344, 365, 33569, 15303, 294, 264, 40049, 7316, 570, 7935, 11, 1419, 5613, 2667, 11, 51624], "temperature": 0.0, "avg_logprob": -0.11729768204362426, "compression_ratio": 1.7877358490566038, "no_speech_prob": 0.12239308655261993}, {"id": 338, "seek": 214944, "start": 2149.44, "end": 2156.48, "text": " that want things is a good way of getting things. In a sense, wanting comes from the same", "tokens": [50364, 300, 528, 721, 307, 257, 665, 636, 295, 1242, 721, 13, 682, 257, 2020, 11, 7935, 1487, 490, 264, 912, 50716], "temperature": 0.0, "avg_logprob": -0.14905701326520254, "compression_ratio": 1.7510729613733906, "no_speech_prob": 0.0012834646040573716}, {"id": 339, "seek": 214944, "start": 2156.48, "end": 2161.44, "text": " place as intelligence itself and you could even from a certain technical standpoint on", "tokens": [50716, 1081, 382, 7599, 2564, 293, 291, 727, 754, 490, 257, 1629, 6191, 15827, 322, 50964], "temperature": 0.0, "avg_logprob": -0.14905701326520254, "compression_ratio": 1.7510729613733906, "no_speech_prob": 0.0012834646040573716}, {"id": 340, "seek": 214944, "start": 2161.44, "end": 2166.88, "text": " expected utility say that intelligence is a very effective way of wanting, planning,", "tokens": [50964, 5176, 14877, 584, 300, 7599, 307, 257, 588, 4942, 636, 295, 7935, 11, 5038, 11, 51236], "temperature": 0.0, "avg_logprob": -0.14905701326520254, "compression_ratio": 1.7510729613733906, "no_speech_prob": 0.0012834646040573716}, {"id": 341, "seek": 214944, "start": 2167.52, "end": 2169.84, "text": " plotting past through time that leads to particular outcomes.", "tokens": [51268, 41178, 1791, 807, 565, 300, 6689, 281, 1729, 10070, 13, 51384], "temperature": 0.0, "avg_logprob": -0.14905701326520254, "compression_ratio": 1.7510729613733906, "no_speech_prob": 0.0012834646040573716}, {"id": 342, "seek": 214944, "start": 2172.0, "end": 2178.48, "text": " Part of it is that I do not think you get the brooding super intelligence that wants", "tokens": [51492, 4100, 295, 309, 307, 300, 286, 360, 406, 519, 291, 483, 264, 2006, 8616, 1687, 7599, 300, 2738, 51816], "temperature": 0.0, "avg_logprob": -0.14905701326520254, "compression_ratio": 1.7510729613733906, "no_speech_prob": 0.0012834646040573716}, {"id": 343, "seek": 217848, "start": 2178.48, "end": 2183.6, "text": " nothing because I don't think that wanting an intelligence can be internally pried apart", "tokens": [50364, 1825, 570, 286, 500, 380, 519, 300, 7935, 364, 7599, 393, 312, 19501, 1790, 292, 4936, 50620], "temperature": 0.0, "avg_logprob": -0.13489968997915996, "compression_ratio": 1.738396624472574, "no_speech_prob": 0.003482428379356861}, {"id": 344, "seek": 217848, "start": 2183.6, "end": 2188.48, "text": " that easily. I think that the way you get super intelligences is that there are things that", "tokens": [50620, 300, 3612, 13, 286, 519, 300, 264, 636, 291, 483, 1687, 5613, 2667, 307, 300, 456, 366, 721, 300, 50864], "temperature": 0.0, "avg_logprob": -0.13489968997915996, "compression_ratio": 1.738396624472574, "no_speech_prob": 0.003482428379356861}, {"id": 345, "seek": 217848, "start": 2188.48, "end": 2193.76, "text": " have gotten good at organizing their own thoughts and have good taste in which thoughts to think", "tokens": [50864, 362, 5768, 665, 412, 17608, 641, 1065, 4598, 293, 362, 665, 3939, 294, 597, 4598, 281, 519, 51128], "temperature": 0.0, "avg_logprob": -0.13489968997915996, "compression_ratio": 1.738396624472574, "no_speech_prob": 0.003482428379356861}, {"id": 346, "seek": 217848, "start": 2196.08, "end": 2198.72, "text": " and that is where the high capabilities come from.", "tokens": [51244, 293, 300, 307, 689, 264, 1090, 10862, 808, 490, 13, 51376], "temperature": 0.0, "avg_logprob": -0.13489968997915996, "compression_ratio": 1.738396624472574, "no_speech_prob": 0.003482428379356861}, {"id": 347, "seek": 217848, "start": 2199.84, "end": 2200.72, "text": " Can I put a point to you?", "tokens": [51432, 1664, 286, 829, 257, 935, 281, 291, 30, 51476], "temperature": 0.0, "avg_logprob": -0.13489968997915996, "compression_ratio": 1.738396624472574, "no_speech_prob": 0.003482428379356861}, {"id": 348, "seek": 217848, "start": 2203.52, "end": 2205.68, "text": " Let me just put the following point to you, which I think", "tokens": [51616, 961, 385, 445, 829, 264, 3480, 935, 281, 291, 11, 597, 286, 519, 51724], "temperature": 0.0, "avg_logprob": -0.13489968997915996, "compression_ratio": 1.738396624472574, "no_speech_prob": 0.003482428379356861}, {"id": 349, "seek": 220568, "start": 2205.68, "end": 2212.3199999999997, "text": " in my mind is similar to what Gary was saying. There's often in philosophy this notion of the", "tokens": [50364, 294, 452, 1575, 307, 2531, 281, 437, 13788, 390, 1566, 13, 821, 311, 2049, 294, 10675, 341, 10710, 295, 264, 50696], "temperature": 0.0, "avg_logprob": -0.12555214896130917, "compression_ratio": 1.4870466321243523, "no_speech_prob": 0.006902255117893219}, {"id": 350, "seek": 220568, "start": 2212.3199999999997, "end": 2221.04, "text": " continuum fallacy, which in the canonical example is like you can't locate a single hair that you", "tokens": [50696, 36120, 2100, 2551, 11, 597, 294, 264, 46491, 1365, 307, 411, 291, 393, 380, 22370, 257, 2167, 2578, 300, 291, 51132], "temperature": 0.0, "avg_logprob": -0.12555214896130917, "compression_ratio": 1.4870466321243523, "no_speech_prob": 0.006902255117893219}, {"id": 351, "seek": 220568, "start": 2221.04, "end": 2229.6, "text": " would pluck from my head where I would suddenly go from not bald to bald or even more intuitive", "tokens": [51132, 576, 41514, 490, 452, 1378, 689, 286, 576, 5800, 352, 490, 406, 21096, 281, 21096, 420, 754, 544, 21769, 51560], "temperature": 0.0, "avg_logprob": -0.12555214896130917, "compression_ratio": 1.4870466321243523, "no_speech_prob": 0.006902255117893219}, {"id": 352, "seek": 222960, "start": 2229.6, "end": 2236.88, "text": " examples like a color wheel. On a gray scale there's no single pixel you can point to and say", "tokens": [50364, 5110, 411, 257, 2017, 5589, 13, 1282, 257, 10855, 4373, 456, 311, 572, 2167, 19261, 291, 393, 935, 281, 293, 584, 50728], "temperature": 0.0, "avg_logprob": -0.10539836194141801, "compression_ratio": 1.6550218340611353, "no_speech_prob": 0.09804667532444}, {"id": 353, "seek": 222960, "start": 2236.88, "end": 2242.0, "text": " well that's where gray begins and white ends and yet we have this conceptual distinction that", "tokens": [50728, 731, 300, 311, 689, 10855, 7338, 293, 2418, 5314, 293, 1939, 321, 362, 341, 24106, 16844, 300, 50984], "temperature": 0.0, "avg_logprob": -0.10539836194141801, "compression_ratio": 1.6550218340611353, "no_speech_prob": 0.09804667532444}, {"id": 354, "seek": 222960, "start": 2242.0, "end": 2248.3199999999997, "text": " feels hard and fast between gray and white and gray and black and so forth. When we're talking about", "tokens": [50984, 3417, 1152, 293, 2370, 1296, 10855, 293, 2418, 293, 10855, 293, 2211, 293, 370, 5220, 13, 1133, 321, 434, 1417, 466, 51300], "temperature": 0.0, "avg_logprob": -0.10539836194141801, "compression_ratio": 1.6550218340611353, "no_speech_prob": 0.09804667532444}, {"id": 355, "seek": 222960, "start": 2249.44, "end": 2256.08, "text": " artificial general intelligence or super intelligence you seem to operate on a model where", "tokens": [51356, 11677, 2674, 7599, 420, 1687, 7599, 291, 1643, 281, 9651, 322, 257, 2316, 689, 51688], "temperature": 0.0, "avg_logprob": -0.10539836194141801, "compression_ratio": 1.6550218340611353, "no_speech_prob": 0.09804667532444}, {"id": 356, "seek": 225608, "start": 2256.08, "end": 2263.44, "text": " either it's a super intelligence capable of destroying all of us or it's not. Whereas intelligence", "tokens": [50364, 2139, 309, 311, 257, 1687, 7599, 8189, 295, 19926, 439, 295, 505, 420, 309, 311, 406, 13, 13813, 7599, 50732], "temperature": 0.0, "avg_logprob": -0.08068659828930366, "compression_ratio": 1.7198067632850242, "no_speech_prob": 0.008575400337576866}, {"id": 357, "seek": 225608, "start": 2263.44, "end": 2270.24, "text": " may just be a continuum fallacy style spectrum where we're first going to see the shades of", "tokens": [50732, 815, 445, 312, 257, 36120, 2100, 2551, 3758, 11143, 689, 321, 434, 700, 516, 281, 536, 264, 20639, 295, 51072], "temperature": 0.0, "avg_logprob": -0.08068659828930366, "compression_ratio": 1.7198067632850242, "no_speech_prob": 0.008575400337576866}, {"id": 358, "seek": 225608, "start": 2270.24, "end": 2275.7599999999998, "text": " something that's just a bit more intelligent than us and maybe it can kill five people at most", "tokens": [51072, 746, 300, 311, 445, 257, 857, 544, 13232, 813, 505, 293, 1310, 309, 393, 1961, 1732, 561, 412, 881, 51348], "temperature": 0.0, "avg_logprob": -0.08068659828930366, "compression_ratio": 1.7198067632850242, "no_speech_prob": 0.008575400337576866}, {"id": 359, "seek": 225608, "start": 2276.48, "end": 2282.88, "text": " and then it can and when that happens we're going to want to intervene", "tokens": [51384, 293, 550, 309, 393, 293, 562, 300, 2314, 321, 434, 516, 281, 528, 281, 30407, 51704], "temperature": 0.0, "avg_logprob": -0.08068659828930366, "compression_ratio": 1.7198067632850242, "no_speech_prob": 0.008575400337576866}, {"id": 360, "seek": 228288, "start": 2283.76, "end": 2287.76, "text": " and we're going to figure out how to intervene at that level and so on and so forth.", "tokens": [50408, 293, 321, 434, 516, 281, 2573, 484, 577, 281, 30407, 412, 300, 1496, 293, 370, 322, 293, 370, 5220, 13, 50608], "temperature": 0.0, "avg_logprob": -0.09953162490680653, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.030657989904284477}, {"id": 361, "seek": 228288, "start": 2289.6800000000003, "end": 2296.56, "text": " Yeah so if it's stupid enough to do it then yes. Let me by the identical logic there should be", "tokens": [50704, 865, 370, 498, 309, 311, 6631, 1547, 281, 360, 309, 550, 2086, 13, 961, 385, 538, 264, 14800, 9952, 456, 820, 312, 51048], "temperature": 0.0, "avg_logprob": -0.09953162490680653, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.030657989904284477}, {"id": 362, "seek": 228288, "start": 2296.56, "end": 2302.6400000000003, "text": " nobody who steals money on a really large scale right because you could just give them five dollars", "tokens": [51048, 5079, 567, 46962, 1460, 322, 257, 534, 2416, 4373, 558, 570, 291, 727, 445, 976, 552, 1732, 3808, 51352], "temperature": 0.0, "avg_logprob": -0.09953162490680653, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.030657989904284477}, {"id": 363, "seek": 228288, "start": 2302.6400000000003, "end": 2307.2000000000003, "text": " and see if they steal that and if they don't steal that you know you're good to trust them with a", "tokens": [51352, 293, 536, 498, 436, 11009, 300, 293, 498, 436, 500, 380, 11009, 300, 291, 458, 291, 434, 665, 281, 3361, 552, 365, 257, 51580], "temperature": 0.0, "avg_logprob": -0.09953162490680653, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.030657989904284477}, {"id": 364, "seek": 230720, "start": 2307.2, "end": 2316.16, "text": " billion. I mean I think that in actuality anyone who did steal a billion dollars probably displayed", "tokens": [50364, 5218, 13, 286, 914, 286, 519, 300, 294, 3539, 507, 2878, 567, 630, 11009, 257, 5218, 3808, 1391, 16372, 50812], "temperature": 0.0, "avg_logprob": -0.1656307957389138, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.07803693413734436}, {"id": 365, "seek": 230720, "start": 2316.16, "end": 2322.7999999999997, "text": " some dishonest behavior earlier in their life that was you know unconditionally not not acted upon", "tokens": [50812, 512, 37127, 377, 5223, 3071, 294, 641, 993, 300, 390, 291, 458, 34959, 15899, 406, 406, 20359, 3564, 51144], "temperature": 0.0, "avg_logprob": -0.1656307957389138, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.07803693413734436}, {"id": 366, "seek": 230720, "start": 2322.7999999999997, "end": 2329.4399999999996, "text": " early enough. I'm actually not even. Hold on hold on the analogy out pictures like", "tokens": [51144, 2440, 1547, 13, 286, 478, 767, 406, 754, 13, 6962, 322, 1797, 322, 264, 21663, 484, 5242, 411, 51476], "temperature": 0.0, "avg_logprob": -0.1656307957389138, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.07803693413734436}, {"id": 367, "seek": 230720, "start": 2330.0, "end": 2336.48, "text": " we have the first case of fraud that's $10,000 and then we build systems to prevent it but then", "tokens": [51504, 321, 362, 264, 700, 1389, 295, 14560, 300, 311, 1848, 3279, 11, 1360, 293, 550, 321, 1322, 3652, 281, 4871, 309, 457, 550, 51828], "temperature": 0.0, "avg_logprob": -0.1656307957389138, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.07803693413734436}, {"id": 368, "seek": 233648, "start": 2336.48, "end": 2340.96, "text": " they fail with a somewhat smarter opponent but our systems get better and better and better", "tokens": [50364, 436, 3061, 365, 257, 8344, 20294, 10620, 457, 527, 3652, 483, 1101, 293, 1101, 293, 1101, 50588], "temperature": 0.0, "avg_logprob": -0.09485490972345526, "compression_ratio": 1.675, "no_speech_prob": 0.0001420018234057352}, {"id": 369, "seek": 233648, "start": 2340.96, "end": 2345.28, "text": " and so we actually prevent the billion-dollar fraud because of the systems put in place", "tokens": [50588, 293, 370, 321, 767, 4871, 264, 5218, 12, 40485, 14560, 570, 295, 264, 3652, 829, 294, 1081, 50804], "temperature": 0.0, "avg_logprob": -0.09485490972345526, "compression_ratio": 1.675, "no_speech_prob": 0.0001420018234057352}, {"id": 370, "seek": 233648, "start": 2345.28, "end": 2351.12, "text": " that in response to the $10,000 frauds you know. I mean I think Coleman's putting his finger on an", "tokens": [50804, 300, 294, 4134, 281, 264, 1848, 3279, 11, 1360, 14560, 82, 291, 458, 13, 286, 914, 286, 519, 49930, 311, 3372, 702, 5984, 322, 364, 51096], "temperature": 0.0, "avg_logprob": -0.09485490972345526, "compression_ratio": 1.675, "no_speech_prob": 0.0001420018234057352}, {"id": 371, "seek": 233648, "start": 2351.12, "end": 2356.88, "text": " important point here which is how much do we get to iterate and Eliezer is saying the minute we have", "tokens": [51096, 1021, 935, 510, 597, 307, 577, 709, 360, 321, 483, 281, 44497, 293, 2699, 414, 4527, 307, 1566, 264, 3456, 321, 362, 51384], "temperature": 0.0, "avg_logprob": -0.09485490972345526, "compression_ratio": 1.675, "no_speech_prob": 0.0001420018234057352}, {"id": 372, "seek": 233648, "start": 2356.88, "end": 2361.36, "text": " a super intelligent system we won't be able to iterate because it's all over immediately.", "tokens": [51384, 257, 1687, 13232, 1185, 321, 1582, 380, 312, 1075, 281, 44497, 570, 309, 311, 439, 670, 4258, 13, 51608], "temperature": 0.0, "avg_logprob": -0.09485490972345526, "compression_ratio": 1.675, "no_speech_prob": 0.0001420018234057352}, {"id": 373, "seek": 236136, "start": 2361.84, "end": 2366.48, "text": " There isn't a minute like that. The way that the continuum goes to the threshold", "tokens": [50388, 821, 1943, 380, 257, 3456, 411, 300, 13, 440, 636, 300, 264, 36120, 1709, 281, 264, 14678, 50620], "temperature": 0.0, "avg_logprob": -0.07421443380158523, "compression_ratio": 1.8404669260700388, "no_speech_prob": 0.015420160256326199}, {"id": 374, "seek": 236136, "start": 2366.48, "end": 2372.08, "text": " is that you eventually get something that's smart enough that it knows not to play its hand early", "tokens": [50620, 307, 300, 291, 4728, 483, 746, 300, 311, 4069, 1547, 300, 309, 3255, 406, 281, 862, 1080, 1011, 2440, 50900], "temperature": 0.0, "avg_logprob": -0.07421443380158523, "compression_ratio": 1.8404669260700388, "no_speech_prob": 0.015420160256326199}, {"id": 375, "seek": 236136, "start": 2372.7200000000003, "end": 2378.48, "text": " and then if that thing you know if you are still cranking up the power on that and preserving", "tokens": [50932, 293, 550, 498, 300, 551, 291, 458, 498, 291, 366, 920, 21263, 278, 493, 264, 1347, 322, 300, 293, 33173, 51220], "temperature": 0.0, "avg_logprob": -0.07421443380158523, "compression_ratio": 1.8404669260700388, "no_speech_prob": 0.015420160256326199}, {"id": 376, "seek": 236136, "start": 2378.48, "end": 2385.36, "text": " its utility function it knows it just has to wait to be smarter to be able to win. It doesn't play its", "tokens": [51220, 1080, 14877, 2445, 309, 3255, 309, 445, 575, 281, 1699, 281, 312, 20294, 281, 312, 1075, 281, 1942, 13, 467, 1177, 380, 862, 1080, 51564], "temperature": 0.0, "avg_logprob": -0.07421443380158523, "compression_ratio": 1.8404669260700388, "no_speech_prob": 0.015420160256326199}, {"id": 377, "seek": 236136, "start": 2385.36, "end": 2389.84, "text": " hand prematurely it doesn't tip you off it's not in its interest to do that. It's in its interest", "tokens": [51564, 1011, 34877, 356, 309, 1177, 380, 4125, 291, 766, 309, 311, 406, 294, 1080, 1179, 281, 360, 300, 13, 467, 311, 294, 1080, 1179, 51788], "temperature": 0.0, "avg_logprob": -0.07421443380158523, "compression_ratio": 1.8404669260700388, "no_speech_prob": 0.015420160256326199}, {"id": 378, "seek": 238984, "start": 2389.84, "end": 2395.84, "text": " to cooperate until it thinks it can win against humanity and only then make its move. If it doesn't", "tokens": [50364, 281, 26667, 1826, 309, 7309, 309, 393, 1942, 1970, 10243, 293, 787, 550, 652, 1080, 1286, 13, 759, 309, 1177, 380, 50664], "temperature": 0.0, "avg_logprob": -0.07506864564912813, "compression_ratio": 1.7545126353790614, "no_speech_prob": 0.0070052254013717175}, {"id": 379, "seek": 238984, "start": 2395.84, "end": 2400.56, "text": " expect the future smarter AIs to be smarter than itself then we might perhaps see these early AIs", "tokens": [50664, 2066, 264, 2027, 20294, 316, 6802, 281, 312, 20294, 813, 2564, 550, 321, 1062, 4317, 536, 613, 2440, 316, 6802, 50900], "temperature": 0.0, "avg_logprob": -0.07506864564912813, "compression_ratio": 1.7545126353790614, "no_speech_prob": 0.0070052254013717175}, {"id": 380, "seek": 238984, "start": 2400.56, "end": 2407.6800000000003, "text": " telling humanity don't build the later AIs and I would be sort of surprised and amused if we", "tokens": [50900, 3585, 10243, 500, 380, 1322, 264, 1780, 316, 6802, 293, 286, 576, 312, 1333, 295, 6100, 293, 669, 4717, 498, 321, 51256], "temperature": 0.0, "avg_logprob": -0.07506864564912813, "compression_ratio": 1.7545126353790614, "no_speech_prob": 0.0070052254013717175}, {"id": 381, "seek": 238984, "start": 2407.6800000000003, "end": 2412.4, "text": " ended up in that particular sort of like science fiction scenario as I see it but we're already", "tokens": [51256, 4590, 493, 294, 300, 1729, 1333, 295, 411, 3497, 13266, 9005, 382, 286, 536, 309, 457, 321, 434, 1217, 51492], "temperature": 0.0, "avg_logprob": -0.07506864564912813, "compression_ratio": 1.7545126353790614, "no_speech_prob": 0.0070052254013717175}, {"id": 382, "seek": 238984, "start": 2412.4, "end": 2416.96, "text": " in like something that you know me from 10 years ago would have called the science fiction scenario", "tokens": [51492, 294, 411, 746, 300, 291, 458, 385, 490, 1266, 924, 2057, 576, 362, 1219, 264, 3497, 13266, 9005, 51720], "temperature": 0.0, "avg_logprob": -0.07506864564912813, "compression_ratio": 1.7545126353790614, "no_speech_prob": 0.0070052254013717175}, {"id": 383, "seek": 241696, "start": 2416.96, "end": 2419.76, "text": " which is the things that I'll talk to you without being very smart.", "tokens": [50364, 597, 307, 264, 721, 300, 286, 603, 751, 281, 291, 1553, 885, 588, 4069, 13, 50504], "temperature": 0.0, "avg_logprob": -0.09181813159620905, "compression_ratio": 1.6698564593301435, "no_speech_prob": 0.0038825843948870897}, {"id": 384, "seek": 241696, "start": 2422.0, "end": 2430.16, "text": " I always come up Eliezer against this idea that you're assuming that the very bright machines", "tokens": [50616, 286, 1009, 808, 493, 2699, 414, 4527, 1970, 341, 1558, 300, 291, 434, 11926, 300, 264, 588, 4730, 8379, 51024], "temperature": 0.0, "avg_logprob": -0.09181813159620905, "compression_ratio": 1.6698564593301435, "no_speech_prob": 0.0038825843948870897}, {"id": 385, "seek": 241696, "start": 2430.16, "end": 2436.7200000000003, "text": " the super intelligent machines will be malicious and duplicitous and so forth and I just don't", "tokens": [51024, 264, 1687, 13232, 8379, 486, 312, 33496, 293, 17154, 39831, 293, 370, 5220, 293, 286, 445, 500, 380, 51352], "temperature": 0.0, "avg_logprob": -0.09181813159620905, "compression_ratio": 1.6698564593301435, "no_speech_prob": 0.0038825843948870897}, {"id": 386, "seek": 241696, "start": 2436.7200000000003, "end": 2445.2, "text": " see that as a logical entailment of being very smart. I mean they don't specifically want as", "tokens": [51352, 536, 300, 382, 257, 14978, 948, 864, 518, 295, 885, 588, 4069, 13, 286, 914, 436, 500, 380, 4682, 528, 382, 51776], "temperature": 0.0, "avg_logprob": -0.09181813159620905, "compression_ratio": 1.6698564593301435, "no_speech_prob": 0.0038825843948870897}, {"id": 387, "seek": 244520, "start": 2445.2, "end": 2451.68, "text": " an end in itself for you to be destroyed they're just doing whatever obtains the most of the stuff", "tokens": [50364, 364, 917, 294, 2564, 337, 291, 281, 312, 8937, 436, 434, 445, 884, 2035, 7464, 2315, 264, 881, 295, 264, 1507, 50688], "temperature": 0.0, "avg_logprob": -0.11525513023458502, "compression_ratio": 1.7422222222222221, "no_speech_prob": 0.009706098586320877}, {"id": 388, "seek": 244520, "start": 2451.68, "end": 2458.3199999999997, "text": " that they actually want which doesn't specifically have a term that's maximized by humanity surviving", "tokens": [50688, 300, 436, 767, 528, 597, 1177, 380, 4682, 362, 257, 1433, 300, 311, 5138, 1602, 538, 10243, 24948, 51020], "temperature": 0.0, "avg_logprob": -0.11525513023458502, "compression_ratio": 1.7422222222222221, "no_speech_prob": 0.009706098586320877}, {"id": 389, "seek": 244520, "start": 2458.3199999999997, "end": 2463.8399999999997, "text": " and doing well. Why can't you just hard code you know don't do anything that will annihilate the", "tokens": [51020, 293, 884, 731, 13, 1545, 393, 380, 291, 445, 1152, 3089, 291, 458, 500, 380, 360, 1340, 300, 486, 40430, 48104, 264, 51296], "temperature": 0.0, "avg_logprob": -0.11525513023458502, "compression_ratio": 1.7422222222222221, "no_speech_prob": 0.009706098586320877}, {"id": 390, "seek": 244520, "start": 2463.8399999999997, "end": 2468.0, "text": " human species don't do anything. We don't know how we don't know how there is no technology to", "tokens": [51296, 1952, 6172, 500, 380, 360, 1340, 13, 492, 500, 380, 458, 577, 321, 500, 380, 458, 577, 456, 307, 572, 2899, 281, 51504], "temperature": 0.0, "avg_logprob": -0.11525513023458502, "compression_ratio": 1.7422222222222221, "no_speech_prob": 0.009706098586320877}, {"id": 391, "seek": 246800, "start": 2468.0, "end": 2474.24, "text": " hard code such as. So there I agree with you but I think it's important if I can just run for one", "tokens": [50364, 1152, 3089, 1270, 382, 13, 407, 456, 286, 3986, 365, 291, 457, 286, 519, 309, 311, 1021, 498, 286, 393, 445, 1190, 337, 472, 50676], "temperature": 0.0, "avg_logprob": -0.11216504724176081, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.25366854667663574}, {"id": 392, "seek": 246800, "start": 2474.24, "end": 2482.0, "text": " second. I agree that right now we don't have the technology to hard code don't do harm to humans", "tokens": [50676, 1150, 13, 286, 3986, 300, 558, 586, 321, 500, 380, 362, 264, 2899, 281, 1152, 3089, 500, 380, 360, 6491, 281, 6255, 51064], "temperature": 0.0, "avg_logprob": -0.11216504724176081, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.25366854667663574}, {"id": 393, "seek": 246800, "start": 2482.0, "end": 2486.64, "text": " but for me it's all boils down to a question of are we going to get to the smart machines", "tokens": [51064, 457, 337, 385, 309, 311, 439, 35049, 760, 281, 257, 1168, 295, 366, 321, 516, 281, 483, 281, 264, 4069, 8379, 51296], "temperature": 0.0, "avg_logprob": -0.11216504724176081, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.25366854667663574}, {"id": 394, "seek": 246800, "start": 2486.64, "end": 2491.84, "text": " before we make progress on that hard coding problem or not and that to me that means that", "tokens": [51296, 949, 321, 652, 4205, 322, 300, 1152, 17720, 1154, 420, 406, 293, 300, 281, 385, 300, 1355, 300, 51556], "temperature": 0.0, "avg_logprob": -0.11216504724176081, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.25366854667663574}, {"id": 395, "seek": 246800, "start": 2491.84, "end": 2496.48, "text": " problem of hard coding ethical values is actually one of the most important projects", "tokens": [51556, 1154, 295, 1152, 17720, 18890, 4190, 307, 767, 472, 295, 264, 881, 1021, 4455, 51788], "temperature": 0.0, "avg_logprob": -0.11216504724176081, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.25366854667663574}, {"id": 396, "seek": 249648, "start": 2496.48, "end": 2501.28, "text": " that we should be working on. Yeah and I tried to work on it 20 years in advance", "tokens": [50364, 300, 321, 820, 312, 1364, 322, 13, 865, 293, 286, 3031, 281, 589, 322, 309, 945, 924, 294, 7295, 50604], "temperature": 0.0, "avg_logprob": -0.11295898064323094, "compression_ratio": 1.548936170212766, "no_speech_prob": 0.00413146149367094}, {"id": 397, "seek": 249648, "start": 2501.92, "end": 2507.36, "text": " and capabilities are just like running vastly ahead of alignment. When I started working on this", "tokens": [50636, 293, 10862, 366, 445, 411, 2614, 41426, 2286, 295, 18515, 13, 1133, 286, 1409, 1364, 322, 341, 50908], "temperature": 0.0, "avg_logprob": -0.11295898064323094, "compression_ratio": 1.548936170212766, "no_speech_prob": 0.00413146149367094}, {"id": 398, "seek": 249648, "start": 2507.36, "end": 2513.76, "text": " 20 years you know like two decades ago we were in a sense ahead of where we are now. AlphaGo", "tokens": [50908, 945, 924, 291, 458, 411, 732, 7878, 2057, 321, 645, 294, 257, 2020, 2286, 295, 689, 321, 366, 586, 13, 20588, 12104, 51228], "temperature": 0.0, "avg_logprob": -0.11295898064323094, "compression_ratio": 1.548936170212766, "no_speech_prob": 0.00413146149367094}, {"id": 399, "seek": 249648, "start": 2513.76, "end": 2519.68, "text": " is much more controllable than GPT-4. So there I agree with you we've fallen in love with the", "tokens": [51228, 307, 709, 544, 45159, 712, 813, 26039, 51, 12, 19, 13, 407, 456, 286, 3986, 365, 291, 321, 600, 11547, 294, 959, 365, 264, 51524], "temperature": 0.0, "avg_logprob": -0.11295898064323094, "compression_ratio": 1.548936170212766, "no_speech_prob": 0.00413146149367094}, {"id": 400, "seek": 251968, "start": 2519.68, "end": 2526.3999999999996, "text": " technology that is fairly poorly controlled. AlphaGo is very easily controlled and very well", "tokens": [50364, 2899, 300, 307, 6457, 22271, 10164, 13, 20588, 12104, 307, 588, 3612, 10164, 293, 588, 731, 50700], "temperature": 0.0, "avg_logprob": -0.11537902727039583, "compression_ratio": 1.6881720430107527, "no_speech_prob": 0.11748099327087402}, {"id": 401, "seek": 251968, "start": 2526.3999999999996, "end": 2531.12, "text": " specified. We know what it does. We can more or less interpret why it's doing it and everybody's", "tokens": [50700, 22206, 13, 492, 458, 437, 309, 775, 13, 492, 393, 544, 420, 1570, 7302, 983, 309, 311, 884, 309, 293, 2201, 311, 50936], "temperature": 0.0, "avg_logprob": -0.11537902727039583, "compression_ratio": 1.6881720430107527, "no_speech_prob": 0.11748099327087402}, {"id": 402, "seek": 251968, "start": 2531.12, "end": 2536.96, "text": " in love with these large language models and they're much less controlled and you're right we", "tokens": [50936, 294, 959, 365, 613, 2416, 2856, 5245, 293, 436, 434, 709, 1570, 10164, 293, 291, 434, 558, 321, 51228], "temperature": 0.0, "avg_logprob": -0.11537902727039583, "compression_ratio": 1.6881720430107527, "no_speech_prob": 0.11748099327087402}, {"id": 403, "seek": 251968, "start": 2536.96, "end": 2543.2, "text": " haven't made a lot of progress on alignment. So if we just go on a straight line everybody dies.", "tokens": [51228, 2378, 380, 1027, 257, 688, 295, 4205, 322, 18515, 13, 407, 498, 321, 445, 352, 322, 257, 2997, 1622, 2201, 2714, 13, 51540], "temperature": 0.0, "avg_logprob": -0.11537902727039583, "compression_ratio": 1.6881720430107527, "no_speech_prob": 0.11748099327087402}, {"id": 404, "seek": 251968, "start": 2543.2, "end": 2548.3199999999997, "text": " I think that's this is an important fact. I would almost even accept that for argument but", "tokens": [51540, 286, 519, 300, 311, 341, 307, 364, 1021, 1186, 13, 286, 576, 1920, 754, 3241, 300, 337, 6770, 457, 51796], "temperature": 0.0, "avg_logprob": -0.11537902727039583, "compression_ratio": 1.6881720430107527, "no_speech_prob": 0.11748099327087402}, {"id": 405, "seek": 254832, "start": 2548.4, "end": 2552.7200000000003, "text": " ask then just for the sake of argument but then ask do we have to be on a straight line?", "tokens": [50368, 1029, 550, 445, 337, 264, 9717, 295, 6770, 457, 550, 1029, 360, 321, 362, 281, 312, 322, 257, 2997, 1622, 30, 50584], "temperature": 0.0, "avg_logprob": -0.1131010610003804, "compression_ratio": 1.7836538461538463, "no_speech_prob": 0.0025888821110129356}, {"id": 406, "seek": 254832, "start": 2553.92, "end": 2559.76, "text": " I mean I would agree to the weaker claim that you know we should certainly be extremely worried", "tokens": [50644, 286, 914, 286, 576, 3986, 281, 264, 24286, 3932, 300, 291, 458, 321, 820, 3297, 312, 4664, 5804, 50936], "temperature": 0.0, "avg_logprob": -0.1131010610003804, "compression_ratio": 1.7836538461538463, "no_speech_prob": 0.0025888821110129356}, {"id": 407, "seek": 254832, "start": 2559.76, "end": 2565.92, "text": " about the intentions of a superintelligence in the same way that say chimpanzees should be", "tokens": [50936, 466, 264, 19354, 295, 257, 1687, 20761, 17644, 294, 264, 912, 636, 300, 584, 18375, 48410, 279, 820, 312, 51244], "temperature": 0.0, "avg_logprob": -0.1131010610003804, "compression_ratio": 1.7836538461538463, "no_speech_prob": 0.0025888821110129356}, {"id": 408, "seek": 254832, "start": 2565.92, "end": 2573.04, "text": " worried about the intentions of you know the first humans that arise right and in fact you know", "tokens": [51244, 5804, 466, 264, 19354, 295, 291, 458, 264, 700, 6255, 300, 20288, 558, 293, 294, 1186, 291, 458, 51600], "temperature": 0.0, "avg_logprob": -0.1131010610003804, "compression_ratio": 1.7836538461538463, "no_speech_prob": 0.0025888821110129356}, {"id": 409, "seek": 257304, "start": 2573.04, "end": 2578.32, "text": " chimpanzees you know continue to exist in our world only at humans' pleasure.", "tokens": [50364, 18375, 48410, 279, 291, 458, 2354, 281, 2514, 294, 527, 1002, 787, 412, 6255, 6, 6834, 13, 50628], "temperature": 0.0, "avg_logprob": -0.09021015520449038, "compression_ratio": 1.5627906976744186, "no_speech_prob": 0.03305213525891304}, {"id": 410, "seek": 257304, "start": 2578.32, "end": 2581.52, "text": " But I think that there are a lot of other considerations here for example", "tokens": [50628, 583, 286, 519, 300, 456, 366, 257, 688, 295, 661, 24070, 510, 337, 1365, 50788], "temperature": 0.0, "avg_logprob": -0.09021015520449038, "compression_ratio": 1.5627906976744186, "no_speech_prob": 0.03305213525891304}, {"id": 411, "seek": 257304, "start": 2582.56, "end": 2590.64, "text": " if we imagined you know that GPT-10 is you know the first unaligned superintelligence", "tokens": [50840, 498, 321, 16590, 291, 458, 300, 26039, 51, 12, 3279, 307, 291, 458, 264, 700, 517, 304, 16690, 1687, 20761, 17644, 51244], "temperature": 0.0, "avg_logprob": -0.09021015520449038, "compression_ratio": 1.5627906976744186, "no_speech_prob": 0.03305213525891304}, {"id": 412, "seek": 257304, "start": 2590.64, "end": 2596.16, "text": " that has these sorts of goals well then you know it would be appearing in a world where presumably", "tokens": [51244, 300, 575, 613, 7527, 295, 5493, 731, 550, 291, 458, 309, 576, 312, 19870, 294, 257, 1002, 689, 26742, 51520], "temperature": 0.0, "avg_logprob": -0.09021015520449038, "compression_ratio": 1.5627906976744186, "no_speech_prob": 0.03305213525891304}, {"id": 413, "seek": 259616, "start": 2596.16, "end": 2605.52, "text": " GPT-9 you know already has very wide diffusion and where people can use that to try to you know", "tokens": [50364, 26039, 51, 12, 24, 291, 458, 1217, 575, 588, 4874, 25242, 293, 689, 561, 393, 764, 300, 281, 853, 281, 291, 458, 50832], "temperature": 0.0, "avg_logprob": -0.15539080301920574, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.20160464942455292}, {"id": 414, "seek": 259616, "start": 2605.52, "end": 2609.92, "text": " and GPT-9 is not destroying the world you know by assumption.", "tokens": [50832, 293, 26039, 51, 12, 24, 307, 406, 19926, 264, 1002, 291, 458, 538, 15302, 13, 51052], "temperature": 0.0, "avg_logprob": -0.15539080301920574, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.20160464942455292}, {"id": 415, "seek": 259616, "start": 2609.92, "end": 2614.72, "text": " Why does GPT-9 work with the humans instead of with GPT-10?", "tokens": [51052, 1545, 775, 26039, 51, 12, 24, 589, 365, 264, 6255, 2602, 295, 365, 26039, 51, 12, 3279, 30, 51292], "temperature": 0.0, "avg_logprob": -0.15539080301920574, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.20160464942455292}, {"id": 416, "seek": 259616, "start": 2615.2799999999997, "end": 2622.16, "text": " Well I don't know I mean I mean I mean I mean maybe maybe maybe it does work with GPT-10 but", "tokens": [51320, 1042, 286, 500, 380, 458, 286, 914, 286, 914, 286, 914, 286, 914, 1310, 1310, 1310, 309, 775, 589, 365, 26039, 51, 12, 3279, 457, 51664], "temperature": 0.0, "avg_logprob": -0.15539080301920574, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.20160464942455292}, {"id": 417, "seek": 262216, "start": 2622.16, "end": 2631.6, "text": " you know I just don't view that as a certainty you know I mean I think you know you're certainty", "tokens": [50364, 291, 458, 286, 445, 500, 380, 1910, 300, 382, 257, 27022, 291, 458, 286, 914, 286, 519, 291, 458, 291, 434, 27022, 50836], "temperature": 0.0, "avg_logprob": -0.13205458397089048, "compression_ratio": 1.673170731707317, "no_speech_prob": 0.0035924764815717936}, {"id": 418, "seek": 262216, "start": 2631.6, "end": 2634.72, "text": " about this is the one place where I really get off the train.", "tokens": [50836, 466, 341, 307, 264, 472, 1081, 689, 286, 534, 483, 766, 264, 3847, 13, 50992], "temperature": 0.0, "avg_logprob": -0.13205458397089048, "compression_ratio": 1.673170731707317, "no_speech_prob": 0.0035924764815717936}, {"id": 419, "seek": 262216, "start": 2635.8399999999997, "end": 2636.3999999999996, "text": " Same with me.", "tokens": [51048, 10635, 365, 385, 13, 51076], "temperature": 0.0, "avg_logprob": -0.13205458397089048, "compression_ratio": 1.673170731707317, "no_speech_prob": 0.0035924764815717936}, {"id": 420, "seek": 262216, "start": 2638.0, "end": 2644.48, "text": " I well I mean I'm not asking you to share my certainty I am asking the viewers to", "tokens": [51156, 286, 731, 286, 914, 286, 478, 406, 3365, 291, 281, 2073, 452, 27022, 286, 669, 3365, 264, 8499, 281, 51480], "temperature": 0.0, "avg_logprob": -0.13205458397089048, "compression_ratio": 1.673170731707317, "no_speech_prob": 0.0035924764815717936}, {"id": 421, "seek": 262216, "start": 2645.12, "end": 2650.48, "text": " believe that you might end up with like more extreme probabilities after after you stare", "tokens": [51512, 1697, 300, 291, 1062, 917, 493, 365, 411, 544, 8084, 33783, 934, 934, 291, 22432, 51780], "temperature": 0.0, "avg_logprob": -0.13205458397089048, "compression_ratio": 1.673170731707317, "no_speech_prob": 0.0035924764815717936}, {"id": 422, "seek": 265048, "start": 2650.48, "end": 2654.8, "text": " things for an additional couple of decades that doesn't mean you have to accept my probabilities", "tokens": [50364, 721, 337, 364, 4497, 1916, 295, 7878, 300, 1177, 380, 914, 291, 362, 281, 3241, 452, 33783, 50580], "temperature": 0.0, "avg_logprob": -0.0878420348214631, "compression_ratio": 1.7461538461538462, "no_speech_prob": 0.0017267816001549363}, {"id": 423, "seek": 265048, "start": 2654.8, "end": 2659.76, "text": " immediately but I'm at least ask you to like not treat that as some kind of weird anomaly", "tokens": [50580, 4258, 457, 286, 478, 412, 1935, 1029, 291, 281, 411, 406, 2387, 300, 382, 512, 733, 295, 3657, 42737, 50828], "temperature": 0.0, "avg_logprob": -0.0878420348214631, "compression_ratio": 1.7461538461538462, "no_speech_prob": 0.0017267816001549363}, {"id": 424, "seek": 265048, "start": 2660.88, "end": 2665.12, "text": " you know I mean you're just going to find those kinds of situations in these debates.", "tokens": [50884, 291, 458, 286, 914, 291, 434, 445, 516, 281, 915, 729, 3685, 295, 6851, 294, 613, 24203, 13, 51096], "temperature": 0.0, "avg_logprob": -0.0878420348214631, "compression_ratio": 1.7461538461538462, "no_speech_prob": 0.0017267816001549363}, {"id": 425, "seek": 265048, "start": 2665.12, "end": 2672.08, "text": " My view is that I don't find the extreme probabilities that you described to be plausible", "tokens": [51096, 1222, 1910, 307, 300, 286, 500, 380, 915, 264, 8084, 33783, 300, 291, 7619, 281, 312, 39925, 51444], "temperature": 0.0, "avg_logprob": -0.0878420348214631, "compression_ratio": 1.7461538461538462, "no_speech_prob": 0.0017267816001549363}, {"id": 426, "seek": 265048, "start": 2672.08, "end": 2678.0, "text": " but I find the question that you're raising to be important I think you know maybe straight", "tokens": [51444, 457, 286, 915, 264, 1168, 300, 291, 434, 11225, 281, 312, 1021, 286, 519, 291, 458, 1310, 2997, 51740], "temperature": 0.0, "avg_logprob": -0.0878420348214631, "compression_ratio": 1.7461538461538462, "no_speech_prob": 0.0017267816001549363}, {"id": 427, "seek": 267800, "start": 2678.0, "end": 2684.72, "text": " line is too extreme but this idea that if you just follow current trends we're getting more", "tokens": [50364, 1622, 307, 886, 8084, 457, 341, 1558, 300, 498, 291, 445, 1524, 2190, 13892, 321, 434, 1242, 544, 50700], "temperature": 0.0, "avg_logprob": -0.10139313172758295, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.07149521261453629}, {"id": 428, "seek": 267800, "start": 2684.72, "end": 2689.84, "text": " sorry we're getting less and less controllable machines and not getting more alignment.", "tokens": [50700, 2597, 321, 434, 1242, 1570, 293, 1570, 45159, 712, 8379, 293, 406, 1242, 544, 18515, 13, 50956], "temperature": 0.0, "avg_logprob": -0.10139313172758295, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.07149521261453629}, {"id": 429, "seek": 267800, "start": 2690.72, "end": 2696.64, "text": " Machines that are more unpredictable harder to interpret and no better at sticking to", "tokens": [51000, 12089, 1652, 300, 366, 544, 31160, 6081, 281, 7302, 293, 572, 1101, 412, 13465, 281, 51296], "temperature": 0.0, "avg_logprob": -0.10139313172758295, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.07149521261453629}, {"id": 430, "seek": 267800, "start": 2696.64, "end": 2699.76, "text": " even a basic principle like be honest and don't make stuff up.", "tokens": [51296, 754, 257, 3875, 8665, 411, 312, 3245, 293, 500, 380, 652, 1507, 493, 13, 51452], "temperature": 0.0, "avg_logprob": -0.10139313172758295, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.07149521261453629}, {"id": 431, "seek": 267800, "start": 2700.48, "end": 2702.88, "text": " In fact that's a problem that other technologies don't really have.", "tokens": [51488, 682, 1186, 300, 311, 257, 1154, 300, 661, 7943, 500, 380, 534, 362, 13, 51608], "temperature": 0.0, "avg_logprob": -0.10139313172758295, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.07149521261453629}, {"id": 432, "seek": 270288, "start": 2703.6800000000003, "end": 2706.32, "text": " Routing systems GPS systems don't make stuff up.", "tokens": [50404, 497, 24500, 3652, 19462, 3652, 500, 380, 652, 1507, 493, 13, 50536], "temperature": 0.0, "avg_logprob": -0.10059769630432129, "compression_ratio": 1.7739130434782608, "no_speech_prob": 0.054185207933187485}, {"id": 433, "seek": 270288, "start": 2707.2000000000003, "end": 2710.6400000000003, "text": " Google search doesn't make stuff up it will point to things that other people have made", "tokens": [50580, 3329, 3164, 1177, 380, 652, 1507, 493, 309, 486, 935, 281, 721, 300, 661, 561, 362, 1027, 50752], "temperature": 0.0, "avg_logprob": -0.10059769630432129, "compression_ratio": 1.7739130434782608, "no_speech_prob": 0.054185207933187485}, {"id": 434, "seek": 270288, "start": 2710.6400000000003, "end": 2715.2000000000003, "text": " stuff up but it doesn't itself do it so in that sense like the trend line is not great.", "tokens": [50752, 1507, 493, 457, 309, 1177, 380, 2564, 360, 309, 370, 294, 300, 2020, 411, 264, 6028, 1622, 307, 406, 869, 13, 50980], "temperature": 0.0, "avg_logprob": -0.10059769630432129, "compression_ratio": 1.7739130434782608, "no_speech_prob": 0.054185207933187485}, {"id": 435, "seek": 270288, "start": 2715.2000000000003, "end": 2720.08, "text": " I agree with that and I agree that we should be really worried about that and we should put", "tokens": [50980, 286, 3986, 365, 300, 293, 286, 3986, 300, 321, 820, 312, 534, 5804, 466, 300, 293, 321, 820, 829, 51224], "temperature": 0.0, "avg_logprob": -0.10059769630432129, "compression_ratio": 1.7739130434782608, "no_speech_prob": 0.054185207933187485}, {"id": 436, "seek": 270288, "start": 2720.08, "end": 2724.48, "text": " effort into it even if I don't agree you know with the probabilities that you attach to it.", "tokens": [51224, 4630, 666, 309, 754, 498, 286, 500, 380, 3986, 291, 458, 365, 264, 33783, 300, 291, 5085, 281, 309, 13, 51444], "temperature": 0.0, "avg_logprob": -0.10059769630432129, "compression_ratio": 1.7739130434782608, "no_speech_prob": 0.054185207933187485}, {"id": 437, "seek": 272448, "start": 2725.44, "end": 2728.08, "text": " I mean let me interject with the question here.", "tokens": [50412, 286, 914, 718, 385, 46787, 365, 264, 1168, 510, 13, 50544], "temperature": 0.0, "avg_logprob": -0.2220227090935958, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.17543169856071472}, {"id": 438, "seek": 272448, "start": 2730.48, "end": 2732.72, "text": " Go ahead Scott go ahead Scott then I'll ask a question.", "tokens": [50664, 1037, 2286, 6659, 352, 2286, 6659, 550, 286, 603, 1029, 257, 1168, 13, 50776], "temperature": 0.0, "avg_logprob": -0.2220227090935958, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.17543169856071472}, {"id": 439, "seek": 272448, "start": 2732.72, "end": 2738.32, "text": " No I mean I think that LASR you know deserves sort of eternal credit for you know raising", "tokens": [50776, 883, 286, 914, 286, 519, 300, 441, 3160, 49, 291, 458, 17037, 1333, 295, 14503, 5397, 337, 291, 458, 11225, 51056], "temperature": 0.0, "avg_logprob": -0.2220227090935958, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.17543169856071472}, {"id": 440, "seek": 272448, "start": 2738.32, "end": 2744.16, "text": " these issues 20 years ago and it was you know very very far from obvious to most of us that", "tokens": [51056, 613, 2663, 945, 924, 2057, 293, 309, 390, 291, 458, 588, 588, 1400, 490, 6322, 281, 881, 295, 505, 300, 51348], "temperature": 0.0, "avg_logprob": -0.2220227090935958, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.17543169856071472}, {"id": 441, "seek": 272448, "start": 2744.16, "end": 2749.04, "text": " they would be live issues. I mean I can say for my part you know I was familiar with", "tokens": [51348, 436, 576, 312, 1621, 2663, 13, 286, 914, 286, 393, 584, 337, 452, 644, 291, 458, 286, 390, 4963, 365, 51592], "temperature": 0.0, "avg_logprob": -0.2220227090935958, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.17543169856071472}, {"id": 442, "seek": 274904, "start": 2750.0, "end": 2757.2799999999997, "text": " LASR's views since you know 2006 or so and when I first encountered them you know I you know I", "tokens": [50412, 441, 3160, 49, 311, 6809, 1670, 291, 458, 14062, 420, 370, 293, 562, 286, 700, 20381, 552, 291, 458, 286, 291, 458, 286, 50776], "temperature": 0.0, "avg_logprob": -0.11209178756881547, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.012236044742166996}, {"id": 443, "seek": 274904, "start": 2757.2799999999997, "end": 2764.8, "text": " didn't you know I knew that there was no principle that said that this scenario was impossible", "tokens": [50776, 994, 380, 291, 458, 286, 2586, 300, 456, 390, 572, 8665, 300, 848, 300, 341, 9005, 390, 6243, 51152], "temperature": 0.0, "avg_logprob": -0.11209178756881547, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.012236044742166996}, {"id": 444, "seek": 274904, "start": 2764.8, "end": 2770.0, "text": " but I just felt like well supposing I agreed with that what do you want me to do about it.", "tokens": [51152, 457, 286, 445, 2762, 411, 731, 1003, 6110, 286, 9166, 365, 300, 437, 360, 291, 528, 385, 281, 360, 466, 309, 13, 51412], "temperature": 0.0, "avg_logprob": -0.11209178756881547, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.012236044742166996}, {"id": 445, "seek": 274904, "start": 2770.0, "end": 2775.2, "text": " You know what where is the research program that has any hope of making progress here right.", "tokens": [51412, 509, 458, 437, 689, 307, 264, 2132, 1461, 300, 575, 604, 1454, 295, 1455, 4205, 510, 558, 13, 51672], "temperature": 0.0, "avg_logprob": -0.11209178756881547, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.012236044742166996}, {"id": 446, "seek": 277520, "start": 2775.2799999999997, "end": 2779.7599999999998, "text": " I mean there's you know one question of what are the most important problems in the world but in", "tokens": [50368, 286, 914, 456, 311, 291, 458, 472, 1168, 295, 437, 366, 264, 881, 1021, 2740, 294, 264, 1002, 457, 294, 50592], "temperature": 0.0, "avg_logprob": -0.08361773107243681, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.015177424997091293}, {"id": 447, "seek": 277520, "start": 2779.7599999999998, "end": 2785.2, "text": " science that's necessary but not sufficient. We need something that we can make progress on", "tokens": [50592, 3497, 300, 311, 4818, 457, 406, 11563, 13, 492, 643, 746, 300, 321, 393, 652, 4205, 322, 50864], "temperature": 0.0, "avg_logprob": -0.08361773107243681, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.015177424997091293}, {"id": 448, "seek": 277520, "start": 2785.2, "end": 2794.16, "text": " and you know that that is the thing that I think has changed just recently you know with the advent", "tokens": [50864, 293, 291, 458, 300, 300, 307, 264, 551, 300, 286, 519, 575, 3105, 445, 3938, 291, 458, 365, 264, 7045, 51312], "temperature": 0.0, "avg_logprob": -0.08361773107243681, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.015177424997091293}, {"id": 449, "seek": 277520, "start": 2794.16, "end": 2800.8799999999997, "text": " of of actual very powerful AIs and so the the sort of irony here is that you know as", "tokens": [51312, 295, 295, 3539, 588, 4005, 316, 6802, 293, 370, 264, 264, 1333, 295, 35365, 510, 307, 300, 291, 458, 382, 51648], "temperature": 0.0, "avg_logprob": -0.08361773107243681, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.015177424997091293}, {"id": 450, "seek": 280088, "start": 2800.88, "end": 2808.0, "text": " Eliezer has gotten you know much more pessimistic you know unfortunately in the last few years about", "tokens": [50364, 2699, 414, 4527, 575, 5768, 291, 458, 709, 544, 37399, 3142, 291, 458, 7015, 294, 264, 1036, 1326, 924, 466, 50720], "temperature": 0.0, "avg_logprob": -0.11327428985060307, "compression_ratio": 1.8358778625954197, "no_speech_prob": 0.008061008527874947}, {"id": 451, "seek": 280088, "start": 2808.0, "end": 2814.2400000000002, "text": " alignment you know I've sort of gotten more optimistic. I feel like well there is a research", "tokens": [50720, 18515, 291, 458, 286, 600, 1333, 295, 5768, 544, 19397, 13, 286, 841, 411, 731, 456, 307, 257, 2132, 51032], "temperature": 0.0, "avg_logprob": -0.11327428985060307, "compression_ratio": 1.8358778625954197, "no_speech_prob": 0.008061008527874947}, {"id": 452, "seek": 280088, "start": 2814.2400000000002, "end": 2819.92, "text": " program that we're that we can actually make progress on now. Yeah your research your research", "tokens": [51032, 1461, 300, 321, 434, 300, 321, 393, 767, 652, 4205, 322, 586, 13, 865, 428, 2132, 428, 2132, 51316], "temperature": 0.0, "avg_logprob": -0.11327428985060307, "compression_ratio": 1.8358778625954197, "no_speech_prob": 0.008061008527874947}, {"id": 453, "seek": 280088, "start": 2819.92, "end": 2824.4, "text": " program is going to take a hundred years and we don't know how long it will take. We don't know", "tokens": [51316, 1461, 307, 516, 281, 747, 257, 3262, 924, 293, 321, 500, 380, 458, 577, 938, 309, 486, 747, 13, 492, 500, 380, 458, 51540], "temperature": 0.0, "avg_logprob": -0.11327428985060307, "compression_ratio": 1.8358778625954197, "no_speech_prob": 0.008061008527874947}, {"id": 454, "seek": 280088, "start": 2824.4, "end": 2829.6800000000003, "text": " that exactly we don't know. I think the argument that we should put a lot more effort into it is", "tokens": [51540, 300, 2293, 321, 500, 380, 458, 13, 286, 519, 264, 6770, 300, 321, 820, 829, 257, 688, 544, 4630, 666, 309, 307, 51804], "temperature": 0.0, "avg_logprob": -0.11327428985060307, "compression_ratio": 1.8358778625954197, "no_speech_prob": 0.008061008527874947}, {"id": 455, "seek": 282968, "start": 2829.68, "end": 2833.04, "text": " clear. I think the argument will take a hundred years is totally unclear.", "tokens": [50364, 1850, 13, 286, 519, 264, 6770, 486, 747, 257, 3262, 924, 307, 3879, 25636, 13, 50532], "temperature": 0.0, "avg_logprob": -0.07787433151126832, "compression_ratio": 1.8047138047138047, "no_speech_prob": 0.0020826063118875027}, {"id": 456, "seek": 282968, "start": 2834.56, "end": 2837.9199999999996, "text": " I mean I'm not even sure you can do it in a hundred years because there's the basic problem", "tokens": [50608, 286, 914, 286, 478, 406, 754, 988, 291, 393, 360, 309, 294, 257, 3262, 924, 570, 456, 311, 264, 3875, 1154, 50776], "temperature": 0.0, "avg_logprob": -0.07787433151126832, "compression_ratio": 1.8047138047138047, "no_speech_prob": 0.0020826063118875027}, {"id": 457, "seek": 282968, "start": 2837.9199999999996, "end": 2843.04, "text": " of getting it right on the first try and the way these things are supposed to work in science", "tokens": [50776, 295, 1242, 309, 558, 322, 264, 700, 853, 293, 264, 636, 613, 721, 366, 3442, 281, 589, 294, 3497, 51032], "temperature": 0.0, "avg_logprob": -0.07787433151126832, "compression_ratio": 1.8047138047138047, "no_speech_prob": 0.0020826063118875027}, {"id": 458, "seek": 282968, "start": 2843.04, "end": 2847.68, "text": " is that you have your bright-eyed optimistic youngsters with their vastly oversimplified", "tokens": [51032, 307, 300, 291, 362, 428, 4730, 12, 37860, 19397, 49068, 365, 641, 41426, 15488, 332, 564, 2587, 51264], "temperature": 0.0, "avg_logprob": -0.07787433151126832, "compression_ratio": 1.8047138047138047, "no_speech_prob": 0.0020826063118875027}, {"id": 459, "seek": 282968, "start": 2847.68, "end": 2853.44, "text": " hopelessly idealistic optimistic plan. They charge ahead. They fail. They like learn a little", "tokens": [51264, 27317, 356, 7157, 3142, 19397, 1393, 13, 814, 4602, 2286, 13, 814, 3061, 13, 814, 411, 1466, 257, 707, 51552], "temperature": 0.0, "avg_logprob": -0.07787433151126832, "compression_ratio": 1.8047138047138047, "no_speech_prob": 0.0020826063118875027}, {"id": 460, "seek": 282968, "start": 2853.44, "end": 2858.24, "text": " cynicism. They learn a little pessimism. They learn it's not as easy as that. They try again.", "tokens": [51552, 28365, 26356, 13, 814, 1466, 257, 707, 37399, 1434, 13, 814, 1466, 309, 311, 406, 382, 1858, 382, 300, 13, 814, 853, 797, 13, 51792], "temperature": 0.0, "avg_logprob": -0.07787433151126832, "compression_ratio": 1.8047138047138047, "no_speech_prob": 0.0020826063118875027}, {"id": 461, "seek": 285824, "start": 2858.24, "end": 2863.2, "text": " They fail again. They start to build up something over battle something like battle-hardening", "tokens": [50364, 814, 3061, 797, 13, 814, 722, 281, 1322, 493, 746, 670, 4635, 746, 411, 4635, 12, 21491, 4559, 50612], "temperature": 0.0, "avg_logprob": -0.11638731667489717, "compression_ratio": 1.7483660130718954, "no_speech_prob": 0.0005971941282041371}, {"id": 462, "seek": 285824, "start": 2863.2, "end": 2867.9199999999996, "text": " and then and you know like you know they find out how little is possible to them.", "tokens": [50612, 293, 550, 293, 291, 458, 411, 291, 458, 436, 915, 484, 577, 707, 307, 1944, 281, 552, 13, 50848], "temperature": 0.0, "avg_logprob": -0.11638731667489717, "compression_ratio": 1.7483660130718954, "no_speech_prob": 0.0005971941282041371}, {"id": 463, "seek": 285824, "start": 2867.9199999999996, "end": 2871.9199999999996, "text": " Aliezer I mean this is a place where I just really don't agree with you so I think", "tokens": [50848, 967, 414, 4527, 286, 914, 341, 307, 257, 1081, 689, 286, 445, 534, 500, 380, 3986, 365, 291, 370, 286, 519, 51048], "temperature": 0.0, "avg_logprob": -0.11638731667489717, "compression_ratio": 1.7483660130718954, "no_speech_prob": 0.0005971941282041371}, {"id": 464, "seek": 285824, "start": 2871.9199999999996, "end": 2876.4799999999996, "text": " there's all kinds of things we can do. There's sort of of the flavor of model organisms or", "tokens": [51048, 456, 311, 439, 3685, 295, 721, 321, 393, 360, 13, 821, 311, 1333, 295, 295, 264, 6813, 295, 2316, 22110, 420, 51276], "temperature": 0.0, "avg_logprob": -0.11638731667489717, "compression_ratio": 1.7483660130718954, "no_speech_prob": 0.0005971941282041371}, {"id": 465, "seek": 285824, "start": 2876.4799999999996, "end": 2881.68, "text": " simulations and so forth and we just mean it's hard because we don't actually have a super", "tokens": [51276, 35138, 293, 370, 5220, 293, 321, 445, 914, 309, 311, 1152, 570, 321, 500, 380, 767, 362, 257, 1687, 51536], "temperature": 0.0, "avg_logprob": -0.11638731667489717, "compression_ratio": 1.7483660130718954, "no_speech_prob": 0.0005971941282041371}, {"id": 466, "seek": 285824, "start": 2881.68, "end": 2887.6, "text": " intelligence so we can't fully calibrate but it's a leap to say that there's nothing iterative", "tokens": [51536, 7599, 370, 321, 393, 380, 4498, 21583, 4404, 457, 309, 311, 257, 19438, 281, 584, 300, 456, 311, 1825, 17138, 1166, 51832], "temperature": 0.0, "avg_logprob": -0.11638731667489717, "compression_ratio": 1.7483660130718954, "no_speech_prob": 0.0005971941282041371}, {"id": 467, "seek": 288760, "start": 2887.68, "end": 2892.16, "text": " that we can do here or that we have to get it right on the first time. I mean I certainly see", "tokens": [50368, 300, 321, 393, 360, 510, 420, 300, 321, 362, 281, 483, 309, 558, 322, 264, 700, 565, 13, 286, 914, 286, 3297, 536, 50592], "temperature": 0.0, "avg_logprob": -0.08129715728759766, "compression_ratio": 1.88339222614841, "no_speech_prob": 0.002113858936354518}, {"id": 468, "seek": 288760, "start": 2892.16, "end": 2897.2799999999997, "text": " a scenario where that's true where getting it right on the first time does make the difference", "tokens": [50592, 257, 9005, 689, 300, 311, 2074, 689, 1242, 309, 558, 322, 264, 700, 565, 775, 652, 264, 2649, 50848], "temperature": 0.0, "avg_logprob": -0.08129715728759766, "compression_ratio": 1.88339222614841, "no_speech_prob": 0.002113858936354518}, {"id": 469, "seek": 288760, "start": 2897.2799999999997, "end": 2900.72, "text": " but I can see lots of scenarios where it doesn't and where we do have time to iterate", "tokens": [50848, 457, 286, 393, 536, 3195, 295, 15077, 689, 309, 1177, 380, 293, 689, 321, 360, 362, 565, 281, 44497, 51020], "temperature": 0.0, "avg_logprob": -0.08129715728759766, "compression_ratio": 1.88339222614841, "no_speech_prob": 0.002113858936354518}, {"id": 470, "seek": 288760, "start": 2900.72, "end": 2905.52, "text": " before it happens after it happens and it's really not a single moment but I'm", "tokens": [51020, 949, 309, 2314, 934, 309, 2314, 293, 309, 311, 534, 406, 257, 2167, 1623, 457, 286, 478, 51260], "temperature": 0.0, "avg_logprob": -0.08129715728759766, "compression_ratio": 1.88339222614841, "no_speech_prob": 0.002113858936354518}, {"id": 471, "seek": 288760, "start": 2905.52, "end": 2910.24, "text": " you know idealizing. I mean the problem is getting anything that generalizes up to the", "tokens": [51260, 291, 458, 7157, 3319, 13, 286, 914, 264, 1154, 307, 1242, 1340, 300, 2674, 5660, 493, 281, 264, 51496], "temperature": 0.0, "avg_logprob": -0.08129715728759766, "compression_ratio": 1.88339222614841, "no_speech_prob": 0.002113858936354518}, {"id": 472, "seek": 288760, "start": 2910.24, "end": 2915.44, "text": " super intelligent level where past some threshold level the minds may find that in their own", "tokens": [51496, 1687, 13232, 1496, 689, 1791, 512, 14678, 1496, 264, 9634, 815, 915, 300, 294, 641, 1065, 51756], "temperature": 0.0, "avg_logprob": -0.08129715728759766, "compression_ratio": 1.88339222614841, "no_speech_prob": 0.002113858936354518}, {"id": 473, "seek": 291544, "start": 2915.44, "end": 2918.88, "text": " interest to start lying to you even if that happens before super intelligent.", "tokens": [50364, 1179, 281, 722, 8493, 281, 291, 754, 498, 300, 2314, 949, 1687, 13232, 13, 50536], "temperature": 0.0, "avg_logprob": -0.1982289669560451, "compression_ratio": 1.6733870967741935, "no_speech_prob": 0.03160330280661583}, {"id": 474, "seek": 291544, "start": 2918.88, "end": 2924.32, "text": " Even that like I don't see the logical argument that you can't emulate that", "tokens": [50536, 2754, 300, 411, 286, 500, 380, 536, 264, 14978, 6770, 300, 291, 393, 380, 45497, 300, 50808], "temperature": 0.0, "avg_logprob": -0.1982289669560451, "compression_ratio": 1.6733870967741935, "no_speech_prob": 0.03160330280661583}, {"id": 475, "seek": 291544, "start": 2924.32, "end": 2928.0, "text": " we're studying it. I mean for example you could I'm just making this up as I go along but for", "tokens": [50808, 321, 434, 7601, 309, 13, 286, 914, 337, 1365, 291, 727, 286, 478, 445, 1455, 341, 493, 382, 286, 352, 2051, 457, 337, 50992], "temperature": 0.0, "avg_logprob": -0.1982289669560451, "compression_ratio": 1.6733870967741935, "no_speech_prob": 0.03160330280661583}, {"id": 476, "seek": 291544, "start": 2928.0, "end": 2933.68, "text": " example you could study what can we do with sociopaths who are often very bright and you know", "tokens": [50992, 1365, 291, 727, 2979, 437, 393, 321, 360, 365, 3075, 27212, 82, 567, 366, 2049, 588, 4730, 293, 291, 458, 51276], "temperature": 0.0, "avg_logprob": -0.1982289669560451, "compression_ratio": 1.6733870967741935, "no_speech_prob": 0.03160330280661583}, {"id": 477, "seek": 291544, "start": 2934.48, "end": 2941.6, "text": " not to their dollar value. What can a what what strategy can a like 70 IQ", "tokens": [51316, 406, 281, 641, 7241, 2158, 13, 708, 393, 257, 437, 437, 5206, 393, 257, 411, 5285, 28921, 51672], "temperature": 0.0, "avg_logprob": -0.1982289669560451, "compression_ratio": 1.6733870967741935, "no_speech_prob": 0.03160330280661583}, {"id": 478, "seek": 294160, "start": 2942.24, "end": 2947.92, "text": " honest person come up with and invent themselves by which they will outwit and defeat a 130 IQ", "tokens": [50396, 3245, 954, 808, 493, 365, 293, 7962, 2969, 538, 597, 436, 486, 484, 86, 270, 293, 11785, 257, 19966, 28921, 50680], "temperature": 0.0, "avg_logprob": -0.07804565936063243, "compression_ratio": 1.6958041958041958, "no_speech_prob": 0.04332577437162399}, {"id": 479, "seek": 294160, "start": 2947.92, "end": 2952.08, "text": " sociopath. All right well there you're not being fair either in the sense that you know we actually", "tokens": [50680, 3075, 27212, 13, 1057, 558, 731, 456, 291, 434, 406, 885, 3143, 2139, 294, 264, 2020, 300, 291, 458, 321, 767, 50888], "temperature": 0.0, "avg_logprob": -0.07804565936063243, "compression_ratio": 1.6958041958041958, "no_speech_prob": 0.04332577437162399}, {"id": 480, "seek": 294160, "start": 2952.08, "end": 2957.6, "text": " have lots of 150 IQ people who could be working on this problem collectively and there's there's", "tokens": [50888, 362, 3195, 295, 8451, 28921, 561, 567, 727, 312, 1364, 322, 341, 1154, 24341, 293, 456, 311, 456, 311, 51164], "temperature": 0.0, "avg_logprob": -0.07804565936063243, "compression_ratio": 1.6958041958041958, "no_speech_prob": 0.04332577437162399}, {"id": 481, "seek": 294160, "start": 2957.6, "end": 2963.52, "text": " value in collective action. There's literature. What I see is what I see that gives me pause is", "tokens": [51164, 2158, 294, 12590, 3069, 13, 821, 311, 10394, 13, 708, 286, 536, 307, 437, 286, 536, 300, 2709, 385, 10465, 307, 51460], "temperature": 0.0, "avg_logprob": -0.07804565936063243, "compression_ratio": 1.6958041958041958, "no_speech_prob": 0.04332577437162399}, {"id": 482, "seek": 294160, "start": 2963.52, "end": 2969.44, "text": " that is that the people don't seem to appreciate what about the problem is hard even at the level", "tokens": [51460, 300, 307, 300, 264, 561, 500, 380, 1643, 281, 4449, 437, 466, 264, 1154, 307, 1152, 754, 412, 264, 1496, 51756], "temperature": 0.0, "avg_logprob": -0.07804565936063243, "compression_ratio": 1.6958041958041958, "no_speech_prob": 0.04332577437162399}, {"id": 483, "seek": 296944, "start": 2969.44, "end": 2975.6, "text": " where like 20 years ago I could have told you it was hard until you know somebody like me", "tokens": [50364, 689, 411, 945, 924, 2057, 286, 727, 362, 1907, 291, 309, 390, 1152, 1826, 291, 458, 2618, 411, 385, 50672], "temperature": 0.0, "avg_logprob": -0.0905927115795659, "compression_ratio": 1.6604477611940298, "no_speech_prob": 0.002050230745226145}, {"id": 484, "seek": 296944, "start": 2975.6, "end": 2979.44, "text": " comes along and enacts them about it and then they talk about the ways in which they could adapt", "tokens": [50672, 1487, 2051, 293, 465, 15295, 552, 466, 309, 293, 550, 436, 751, 466, 264, 2098, 294, 597, 436, 727, 6231, 50864], "temperature": 0.0, "avg_logprob": -0.0905927115795659, "compression_ratio": 1.6604477611940298, "no_speech_prob": 0.002050230745226145}, {"id": 485, "seek": 296944, "start": 2979.44, "end": 2984.0, "text": " and be clever but but the people's charging straightforward are just sort of like doing", "tokens": [50864, 293, 312, 13494, 457, 457, 264, 561, 311, 11379, 15325, 366, 445, 1333, 295, 411, 884, 51092], "temperature": 0.0, "avg_logprob": -0.0905927115795659, "compression_ratio": 1.6604477611940298, "no_speech_prob": 0.002050230745226145}, {"id": 486, "seek": 296944, "start": 2984.0, "end": 2989.6, "text": " in this supremely naive way. Let me share a historical example that I think about a lot", "tokens": [51092, 294, 341, 23710, 736, 29052, 636, 13, 961, 385, 2073, 257, 8584, 1365, 300, 286, 519, 466, 257, 688, 51372], "temperature": 0.0, "avg_logprob": -0.0905927115795659, "compression_ratio": 1.6604477611940298, "no_speech_prob": 0.002050230745226145}, {"id": 487, "seek": 296944, "start": 2990.16, "end": 2996.0, "text": " which is in the early 1900s almost every scientist on the planet who thought about", "tokens": [51400, 597, 307, 294, 264, 2440, 28898, 82, 1920, 633, 12662, 322, 264, 5054, 567, 1194, 466, 51692], "temperature": 0.0, "avg_logprob": -0.0905927115795659, "compression_ratio": 1.6604477611940298, "no_speech_prob": 0.002050230745226145}, {"id": 488, "seek": 299600, "start": 2996.0, "end": 3001.68, "text": " biology made a mistake. They all thought that genes were proteins and then eventually Oswald", "tokens": [50364, 14956, 1027, 257, 6146, 13, 814, 439, 1194, 300, 14424, 645, 15577, 293, 550, 4728, 8875, 33262, 50648], "temperature": 0.0, "avg_logprob": -0.05934629440307617, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.003823000704869628}, {"id": 489, "seek": 299600, "start": 3001.68, "end": 3007.04, "text": " Avery did the right experiments. They realized that genes were not proteins. There was this weird", "tokens": [50648, 316, 448, 630, 264, 558, 12050, 13, 814, 5334, 300, 14424, 645, 406, 15577, 13, 821, 390, 341, 3657, 50916], "temperature": 0.0, "avg_logprob": -0.05934629440307617, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.003823000704869628}, {"id": 490, "seek": 299600, "start": 3007.04, "end": 3014.08, "text": " acid and it didn't take long after people got out of this stock mindset before they figured", "tokens": [50916, 8258, 293, 309, 994, 380, 747, 938, 934, 561, 658, 484, 295, 341, 4127, 12543, 949, 436, 8932, 51268], "temperature": 0.0, "avg_logprob": -0.05934629440307617, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.003823000704869628}, {"id": 491, "seek": 299600, "start": 3014.08, "end": 3018.72, "text": " out how that weird acid worked and how to manipulate it and how to read the code that it was in and", "tokens": [51268, 484, 577, 300, 3657, 8258, 2732, 293, 577, 281, 20459, 309, 293, 577, 281, 1401, 264, 3089, 300, 309, 390, 294, 293, 51500], "temperature": 0.0, "avg_logprob": -0.05934629440307617, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.003823000704869628}, {"id": 492, "seek": 299600, "start": 3018.72, "end": 3025.28, "text": " so forth. So I absolutely sympathize with the fact that I feel like the field is stuck right now.", "tokens": [51500, 370, 5220, 13, 407, 286, 3122, 22276, 1125, 365, 264, 1186, 300, 286, 841, 411, 264, 2519, 307, 5541, 558, 586, 13, 51828], "temperature": 0.0, "avg_logprob": -0.05934629440307617, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.003823000704869628}, {"id": 493, "seek": 302528, "start": 3025.28, "end": 3029.84, "text": " I think the approaches people are taking to alignment are unlikely to work. I'm completely", "tokens": [50364, 286, 519, 264, 11587, 561, 366, 1940, 281, 18515, 366, 17518, 281, 589, 13, 286, 478, 2584, 50592], "temperature": 0.0, "avg_logprob": -0.07957556418010167, "compression_ratio": 1.6527777777777777, "no_speech_prob": 0.0009107644436880946}, {"id": 494, "seek": 302528, "start": 3029.84, "end": 3036.48, "text": " with you there but I'm also I guess more long term optimistic that science is self-correcting", "tokens": [50592, 365, 291, 456, 457, 286, 478, 611, 286, 2041, 544, 938, 1433, 19397, 300, 3497, 307, 2698, 12, 19558, 2554, 278, 50924], "temperature": 0.0, "avg_logprob": -0.07957556418010167, "compression_ratio": 1.6527777777777777, "no_speech_prob": 0.0009107644436880946}, {"id": 495, "seek": 302528, "start": 3036.48, "end": 3042.4, "text": " and that we have a chance here. Not a certainty but I think if you know we change research priorities", "tokens": [50924, 293, 300, 321, 362, 257, 2931, 510, 13, 1726, 257, 27022, 457, 286, 519, 498, 291, 458, 321, 1319, 2132, 15503, 51220], "temperature": 0.0, "avg_logprob": -0.07957556418010167, "compression_ratio": 1.6527777777777777, "no_speech_prob": 0.0009107644436880946}, {"id": 496, "seek": 302528, "start": 3042.4, "end": 3046.96, "text": " from how do we make some money off this large language model that's unreliable to how do I", "tokens": [51220, 490, 577, 360, 321, 652, 512, 1460, 766, 341, 2416, 2856, 2316, 300, 311, 20584, 2081, 712, 281, 577, 360, 286, 51448], "temperature": 0.0, "avg_logprob": -0.07957556418010167, "compression_ratio": 1.6527777777777777, "no_speech_prob": 0.0009107644436880946}, {"id": 497, "seek": 302528, "start": 3046.96, "end": 3052.1600000000003, "text": " save the species. We might actually make progress. There's a special kind of caution that you need", "tokens": [51448, 3155, 264, 6172, 13, 492, 1062, 767, 652, 4205, 13, 821, 311, 257, 2121, 733, 295, 23585, 300, 291, 643, 51708], "temperature": 0.0, "avg_logprob": -0.07957556418010167, "compression_ratio": 1.6527777777777777, "no_speech_prob": 0.0009107644436880946}, {"id": 498, "seek": 305216, "start": 3052.16, "end": 3057.2, "text": " when something needs to be gotten correct on the first try. I'd be very optimistic if people got a", "tokens": [50364, 562, 746, 2203, 281, 312, 5768, 3006, 322, 264, 700, 853, 13, 286, 1116, 312, 588, 19397, 498, 561, 658, 257, 50616], "temperature": 0.0, "avg_logprob": -0.07191103476065176, "compression_ratio": 1.8377483443708609, "no_speech_prob": 0.03619799390435219}, {"id": 499, "seek": 305216, "start": 3057.2, "end": 3061.2, "text": " bunch of free retries and I didn't think the first one was going to kill you know the first", "tokens": [50616, 3840, 295, 1737, 1533, 2244, 293, 286, 994, 380, 519, 264, 700, 472, 390, 516, 281, 1961, 291, 458, 264, 700, 50816], "temperature": 0.0, "avg_logprob": -0.07191103476065176, "compression_ratio": 1.8377483443708609, "no_speech_prob": 0.03619799390435219}, {"id": 500, "seek": 305216, "start": 3061.2, "end": 3065.68, "text": " really serious mistake killed everybody and we didn't get to try again. If we got free retries", "tokens": [50816, 534, 3156, 6146, 4652, 2201, 293, 321, 994, 380, 483, 281, 853, 797, 13, 759, 321, 658, 1737, 1533, 2244, 51040], "temperature": 0.0, "avg_logprob": -0.07191103476065176, "compression_ratio": 1.8377483443708609, "no_speech_prob": 0.03619799390435219}, {"id": 501, "seek": 305216, "start": 3065.68, "end": 3068.8799999999997, "text": " it'd be an ordinary you know it'd be in some sense an ordinary science problem.", "tokens": [51040, 309, 1116, 312, 364, 10547, 291, 458, 309, 1116, 312, 294, 512, 2020, 364, 10547, 3497, 1154, 13, 51200], "temperature": 0.0, "avg_logprob": -0.07191103476065176, "compression_ratio": 1.8377483443708609, "no_speech_prob": 0.03619799390435219}, {"id": 502, "seek": 305216, "start": 3068.8799999999997, "end": 3075.7599999999998, "text": " Look I can imagine a world where we only got one try and if we failed then it destroys all life", "tokens": [51200, 2053, 286, 393, 3811, 257, 1002, 689, 321, 787, 658, 472, 853, 293, 498, 321, 7612, 550, 309, 36714, 439, 993, 51544], "temperature": 0.0, "avg_logprob": -0.07191103476065176, "compression_ratio": 1.8377483443708609, "no_speech_prob": 0.03619799390435219}, {"id": 503, "seek": 305216, "start": 3075.7599999999998, "end": 3081.2, "text": " on earth and so let me agree to the conditional statement that if we are in that world then I", "tokens": [51544, 322, 4120, 293, 370, 718, 385, 3986, 281, 264, 27708, 5629, 300, 498, 321, 366, 294, 300, 1002, 550, 286, 51816], "temperature": 0.0, "avg_logprob": -0.07191103476065176, "compression_ratio": 1.8377483443708609, "no_speech_prob": 0.03619799390435219}, {"id": 504, "seek": 308120, "start": 3081.2799999999997, "end": 3085.68, "text": " think that we're screwed. I will agree with the same conditional statement.", "tokens": [50368, 519, 300, 321, 434, 20331, 13, 286, 486, 3986, 365, 264, 912, 27708, 5629, 13, 50588], "temperature": 0.0, "avg_logprob": -0.11003056764602662, "compression_ratio": 1.5955555555555556, "no_speech_prob": 0.003375783795490861}, {"id": 505, "seek": 308120, "start": 3087.52, "end": 3095.7599999999998, "text": " Yeah this gets back to like below hold on you know if you picture by analogy the process of", "tokens": [50680, 865, 341, 2170, 646, 281, 411, 2507, 1797, 322, 291, 458, 498, 291, 3036, 538, 21663, 264, 1399, 295, 51092], "temperature": 0.0, "avg_logprob": -0.11003056764602662, "compression_ratio": 1.5955555555555556, "no_speech_prob": 0.003375783795490861}, {"id": 506, "seek": 308120, "start": 3096.64, "end": 3103.3599999999997, "text": " you know a human baby which is extremely stupid becoming a human adult and then just extending", "tokens": [51136, 291, 458, 257, 1952, 3186, 597, 307, 4664, 6631, 5617, 257, 1952, 5075, 293, 550, 445, 24360, 51472], "temperature": 0.0, "avg_logprob": -0.11003056764602662, "compression_ratio": 1.5955555555555556, "no_speech_prob": 0.003375783795490861}, {"id": 507, "seek": 308120, "start": 3103.3599999999997, "end": 3110.48, "text": " that so that in a single lifetime this person goes from a baby to the smartest being that's ever", "tokens": [51472, 300, 370, 300, 294, 257, 2167, 11364, 341, 954, 1709, 490, 257, 3186, 281, 264, 41491, 885, 300, 311, 1562, 51828], "temperature": 0.0, "avg_logprob": -0.11003056764602662, "compression_ratio": 1.5955555555555556, "no_speech_prob": 0.003375783795490861}, {"id": 508, "seek": 311120, "start": 3111.2, "end": 3116.7999999999997, "text": " lived but in the in the in the normal way that humans develop which is you know and it doesn't", "tokens": [50364, 5152, 457, 294, 264, 294, 264, 294, 264, 2710, 636, 300, 6255, 1499, 597, 307, 291, 458, 293, 309, 1177, 380, 50644], "temperature": 0.0, "avg_logprob": -0.10872820234790291, "compression_ratio": 1.6919642857142858, "no_speech_prob": 0.002629851223900914}, {"id": 509, "seek": 311120, "start": 3116.7999999999997, "end": 3123.9199999999996, "text": " happen any on any one given day and each sub skill develops a little bit at its own rate", "tokens": [50644, 1051, 604, 322, 604, 472, 2212, 786, 293, 1184, 1422, 5389, 25453, 257, 707, 857, 412, 1080, 1065, 3314, 51000], "temperature": 0.0, "avg_logprob": -0.10872820234790291, "compression_ratio": 1.6919642857142858, "no_speech_prob": 0.002629851223900914}, {"id": 510, "seek": 311120, "start": 3124.56, "end": 3131.8399999999997, "text": " and so forth it would not be at all obvious to me that our concerns that we have to get it right", "tokens": [51032, 293, 370, 5220, 309, 576, 406, 312, 412, 439, 6322, 281, 385, 300, 527, 7389, 300, 321, 362, 281, 483, 309, 558, 51396], "temperature": 0.0, "avg_logprob": -0.10872820234790291, "compression_ratio": 1.6919642857142858, "no_speech_prob": 0.002629851223900914}, {"id": 511, "seek": 311120, "start": 3131.8399999999997, "end": 3138.72, "text": " vis-a-vis that individual the first time. I agree well well no pardon me I do think we have to get", "tokens": [51396, 1452, 12, 64, 12, 4938, 300, 2609, 264, 700, 565, 13, 286, 3986, 731, 731, 572, 22440, 385, 286, 360, 519, 321, 362, 281, 483, 51740], "temperature": 0.0, "avg_logprob": -0.10872820234790291, "compression_ratio": 1.6919642857142858, "no_speech_prob": 0.002629851223900914}, {"id": 512, "seek": 313872, "start": 3138.72, "end": 3142.56, "text": " them right the first time but I think there's a decent chance of getting it right. It is very", "tokens": [50364, 552, 558, 264, 700, 565, 457, 286, 519, 456, 311, 257, 8681, 2931, 295, 1242, 309, 558, 13, 467, 307, 588, 50556], "temperature": 0.0, "avg_logprob": -0.10746938992390591, "compression_ratio": 1.842911877394636, "no_speech_prob": 0.03618086874485016}, {"id": 513, "seek": 313872, "start": 3142.56, "end": 3147.7599999999998, "text": " important to get it right the first time if like you have this one person getting smarter and smarter", "tokens": [50556, 1021, 281, 483, 309, 558, 264, 700, 565, 498, 411, 291, 362, 341, 472, 954, 1242, 20294, 293, 20294, 50816], "temperature": 0.0, "avg_logprob": -0.10746938992390591, "compression_ratio": 1.842911877394636, "no_speech_prob": 0.03618086874485016}, {"id": 514, "seek": 313872, "start": 3147.7599999999998, "end": 3152.3999999999996, "text": " and not everyone else is getting smarter and smarter. Eliezer I mean one thing that you've", "tokens": [50816, 293, 406, 1518, 1646, 307, 1242, 20294, 293, 20294, 13, 2699, 414, 4527, 286, 914, 472, 551, 300, 291, 600, 51048], "temperature": 0.0, "avg_logprob": -0.10746938992390591, "compression_ratio": 1.842911877394636, "no_speech_prob": 0.03618086874485016}, {"id": 515, "seek": 313872, "start": 3152.3999999999996, "end": 3158.9599999999996, "text": " talked about a lot recently is you know if we're all going to die then at least let us die with", "tokens": [51048, 2825, 466, 257, 688, 3938, 307, 291, 458, 498, 321, 434, 439, 516, 281, 978, 550, 412, 1935, 718, 505, 978, 365, 51376], "temperature": 0.0, "avg_logprob": -0.10746938992390591, "compression_ratio": 1.842911877394636, "no_speech_prob": 0.03618086874485016}, {"id": 516, "seek": 313872, "start": 3158.9599999999996, "end": 3164.08, "text": " dignity right. So you know I mean I mean for a certain technical definition some people might care", "tokens": [51376, 19672, 558, 13, 407, 291, 458, 286, 914, 286, 914, 337, 257, 1629, 6191, 7123, 512, 561, 1062, 1127, 51632], "temperature": 0.0, "avg_logprob": -0.10746938992390591, "compression_ratio": 1.842911877394636, "no_speech_prob": 0.03618086874485016}, {"id": 517, "seek": 316408, "start": 3164.08, "end": 3169.7599999999998, "text": " about that more than others but I would say that you know one thing that death with dignity would", "tokens": [50364, 466, 300, 544, 813, 2357, 457, 286, 576, 584, 300, 291, 458, 472, 551, 300, 2966, 365, 19672, 576, 50648], "temperature": 0.0, "avg_logprob": -0.06593559206146554, "compression_ratio": 1.813953488372093, "no_speech_prob": 0.14782586693763733}, {"id": 518, "seek": 316408, "start": 3169.7599999999998, "end": 3176.48, "text": " mean is well at least you know if they're all if we do get multiple retries and you know we get", "tokens": [50648, 914, 307, 731, 412, 1935, 291, 458, 498, 436, 434, 439, 498, 321, 360, 483, 3866, 1533, 2244, 293, 291, 458, 321, 483, 50984], "temperature": 0.0, "avg_logprob": -0.06593559206146554, "compression_ratio": 1.813953488372093, "no_speech_prob": 0.14782586693763733}, {"id": 519, "seek": 316408, "start": 3177.68, "end": 3183.7599999999998, "text": " AIs that let's say try to take over the world but are really inept at it and that fail and so forth", "tokens": [51044, 316, 6802, 300, 718, 311, 584, 853, 281, 747, 670, 264, 1002, 457, 366, 534, 294, 5250, 412, 309, 293, 300, 3061, 293, 370, 5220, 51348], "temperature": 0.0, "avg_logprob": -0.06593559206146554, "compression_ratio": 1.813953488372093, "no_speech_prob": 0.14782586693763733}, {"id": 520, "seek": 316408, "start": 3183.7599999999998, "end": 3188.96, "text": " at least let us succeed in that world you know and that's at least something that we can imagine", "tokens": [51348, 412, 1935, 718, 505, 7754, 294, 300, 1002, 291, 458, 293, 300, 311, 412, 1935, 746, 300, 321, 393, 3811, 51608], "temperature": 0.0, "avg_logprob": -0.06593559206146554, "compression_ratio": 1.813953488372093, "no_speech_prob": 0.14782586693763733}, {"id": 521, "seek": 318896, "start": 3188.96, "end": 3196.7200000000003, "text": " working on and making progress on. I mean you may very it's for it is not presently ruled out", "tokens": [50364, 1364, 322, 293, 1455, 4205, 322, 13, 286, 914, 291, 815, 588, 309, 311, 337, 309, 307, 406, 1974, 356, 20077, 484, 50752], "temperature": 0.0, "avg_logprob": -0.063389160416343, "compression_ratio": 1.6832579185520362, "no_speech_prob": 0.04021358862519264}, {"id": 522, "seek": 318896, "start": 3196.7200000000003, "end": 3203.28, "text": " that you have some like you know relatively smart in some ways dumb in some other ways", "tokens": [50752, 300, 291, 362, 512, 411, 291, 458, 7226, 4069, 294, 512, 2098, 10316, 294, 512, 661, 2098, 51080], "temperature": 0.0, "avg_logprob": -0.063389160416343, "compression_ratio": 1.6832579185520362, "no_speech_prob": 0.04021358862519264}, {"id": 523, "seek": 318896, "start": 3203.28, "end": 3208.96, "text": " or at least like not smarter than human in other ways AI that makes an early shot at taking over", "tokens": [51080, 420, 412, 1935, 411, 406, 20294, 813, 1952, 294, 661, 2098, 7318, 300, 1669, 364, 2440, 3347, 412, 1940, 670, 51364], "temperature": 0.0, "avg_logprob": -0.063389160416343, "compression_ratio": 1.6832579185520362, "no_speech_prob": 0.04021358862519264}, {"id": 524, "seek": 318896, "start": 3208.96, "end": 3213.04, "text": " the world maybe because it expects future AIs to not share its goals and not cooperate with it", "tokens": [51364, 264, 1002, 1310, 570, 309, 33280, 2027, 316, 6802, 281, 406, 2073, 1080, 5493, 293, 406, 26667, 365, 309, 51568], "temperature": 0.0, "avg_logprob": -0.063389160416343, "compression_ratio": 1.6832579185520362, "no_speech_prob": 0.04021358862519264}, {"id": 525, "seek": 321304, "start": 3213.6, "end": 3220.4, "text": " and it fails and you know I mean the appropriate lesson to learn there is to you know like shut", "tokens": [50392, 293, 309, 18199, 293, 291, 458, 286, 914, 264, 6854, 6898, 281, 1466, 456, 307, 281, 291, 458, 411, 5309, 50732], "temperature": 0.0, "avg_logprob": -0.08160568237304687, "compression_ratio": 1.72, "no_speech_prob": 0.02715984918177128}, {"id": 526, "seek": 321304, "start": 3220.4, "end": 3227.2799999999997, "text": " the whole thing down but you know if we so yeah like I would say so I'd be like yeah sure like", "tokens": [50732, 264, 1379, 551, 760, 457, 291, 458, 498, 321, 370, 1338, 411, 286, 576, 584, 370, 286, 1116, 312, 411, 1338, 988, 411, 51076], "temperature": 0.0, "avg_logprob": -0.08160568237304687, "compression_ratio": 1.72, "no_speech_prob": 0.02715984918177128}, {"id": 527, "seek": 321304, "start": 3227.2799999999997, "end": 3230.8, "text": " wouldn't it be good to live in that world and the way you live in that world is that when you get", "tokens": [51076, 2759, 380, 309, 312, 665, 281, 1621, 294, 300, 1002, 293, 264, 636, 291, 1621, 294, 300, 1002, 307, 300, 562, 291, 483, 51252], "temperature": 0.0, "avg_logprob": -0.08160568237304687, "compression_ratio": 1.72, "no_speech_prob": 0.02715984918177128}, {"id": 528, "seek": 321304, "start": 3230.8, "end": 3238.56, "text": " that warning sign you shut it all down. Here's a kind of thought experiment. GBT-4 is probably not", "tokens": [51252, 300, 9164, 1465, 291, 5309, 309, 439, 760, 13, 1692, 311, 257, 733, 295, 1194, 5120, 13, 26809, 51, 12, 19, 307, 1391, 406, 51640], "temperature": 0.0, "avg_logprob": -0.08160568237304687, "compression_ratio": 1.72, "no_speech_prob": 0.02715984918177128}, {"id": 529, "seek": 323856, "start": 3238.56, "end": 3244.64, "text": " capable of annihilating us all I think we agree with that very unlikely but GBT-4 is certainly", "tokens": [50364, 8189, 295, 40430, 388, 990, 505, 439, 286, 519, 321, 3986, 365, 300, 588, 17518, 457, 26809, 51, 12, 19, 307, 3297, 50668], "temperature": 0.0, "avg_logprob": -0.10132789611816406, "compression_ratio": 1.6396396396396395, "no_speech_prob": 0.04463673010468483}, {"id": 530, "seek": 323856, "start": 3244.64, "end": 3250.56, "text": " capable of expressing the desire to annihilate us all or being you know people have rigged", "tokens": [50668, 8189, 295, 22171, 264, 7516, 281, 40430, 48104, 505, 439, 420, 885, 291, 458, 561, 362, 8329, 3004, 50964], "temperature": 0.0, "avg_logprob": -0.10132789611816406, "compression_ratio": 1.6396396396396395, "no_speech_prob": 0.04463673010468483}, {"id": 531, "seek": 323856, "start": 3250.56, "end": 3257.2, "text": " different versions that are you know more aggressive and and so forth. We could say look", "tokens": [50964, 819, 9606, 300, 366, 291, 458, 544, 10762, 293, 293, 370, 5220, 13, 492, 727, 584, 574, 51296], "temperature": 0.0, "avg_logprob": -0.10132789611816406, "compression_ratio": 1.6396396396396395, "no_speech_prob": 0.04463673010468483}, {"id": 532, "seek": 323856, "start": 3257.2, "end": 3263.7599999999998, "text": " until we can shut down those versions you know GBT-4s that are programmed to be malicious", "tokens": [51296, 1826, 321, 393, 5309, 760, 729, 9606, 291, 458, 26809, 51, 12, 19, 82, 300, 366, 31092, 281, 312, 33496, 51624], "temperature": 0.0, "avg_logprob": -0.10132789611816406, "compression_ratio": 1.6396396396396395, "no_speech_prob": 0.04463673010468483}, {"id": 533, "seek": 326376, "start": 3264.48, "end": 3270.7200000000003, "text": " by human intent maybe we shouldn't build GBT-5 or at least not GBT-6 or some other system etc we", "tokens": [50400, 538, 1952, 8446, 1310, 321, 4659, 380, 1322, 26809, 51, 12, 20, 420, 412, 1935, 406, 26809, 51, 12, 21, 420, 512, 661, 1185, 5183, 321, 50712], "temperature": 0.0, "avg_logprob": -0.07252261985061514, "compression_ratio": 1.7655677655677655, "no_speech_prob": 0.043971285223960876}, {"id": 534, "seek": 326376, "start": 3270.7200000000003, "end": 3276.32, "text": " could say you know what we have right now actually is part of that iteration we have you know primitive", "tokens": [50712, 727, 584, 291, 458, 437, 321, 362, 558, 586, 767, 307, 644, 295, 300, 24784, 321, 362, 291, 458, 28540, 50992], "temperature": 0.0, "avg_logprob": -0.07252261985061514, "compression_ratio": 1.7655677655677655, "no_speech_prob": 0.043971285223960876}, {"id": 535, "seek": 326376, "start": 3276.32, "end": 3280.8, "text": " intelligence right now it's nowhere near as smart as the super intelligence is going to be", "tokens": [50992, 7599, 558, 586, 309, 311, 11159, 2651, 382, 4069, 382, 264, 1687, 7599, 307, 516, 281, 312, 51216], "temperature": 0.0, "avg_logprob": -0.07252261985061514, "compression_ratio": 1.7655677655677655, "no_speech_prob": 0.043971285223960876}, {"id": 536, "seek": 326376, "start": 3280.8, "end": 3286.6400000000003, "text": " but even this one we're not that good at constraining maybe we shouldn't pass go until we get this one", "tokens": [51216, 457, 754, 341, 472, 321, 434, 406, 300, 665, 412, 11525, 1760, 1310, 321, 4659, 380, 1320, 352, 1826, 321, 483, 341, 472, 51508], "temperature": 0.0, "avg_logprob": -0.07252261985061514, "compression_ratio": 1.7655677655677655, "no_speech_prob": 0.043971285223960876}, {"id": 537, "seek": 326376, "start": 3286.6400000000003, "end": 3293.0400000000004, "text": " right. I mean the problem with that from my perspective is that I do think you that you", "tokens": [51508, 558, 13, 286, 914, 264, 1154, 365, 300, 490, 452, 4585, 307, 300, 286, 360, 519, 291, 300, 291, 51828], "temperature": 0.0, "avg_logprob": -0.07252261985061514, "compression_ratio": 1.7655677655677655, "no_speech_prob": 0.043971285223960876}, {"id": 538, "seek": 329304, "start": 3293.04, "end": 3299.12, "text": " can pass this test and still wipe out humanity like I think that there comes a point where your AI", "tokens": [50364, 393, 1320, 341, 1500, 293, 920, 14082, 484, 10243, 411, 286, 519, 300, 456, 1487, 257, 935, 689, 428, 7318, 50668], "temperature": 0.0, "avg_logprob": -0.09356971453594905, "compression_ratio": 1.7899543378995433, "no_speech_prob": 0.0014319674810394645}, {"id": 539, "seek": 329304, "start": 3299.12, "end": 3304.24, "text": " is smart enough that it knows which answer you're looking for and the point at which it tells you", "tokens": [50668, 307, 4069, 1547, 300, 309, 3255, 597, 1867, 291, 434, 1237, 337, 293, 264, 935, 412, 597, 309, 5112, 291, 50924], "temperature": 0.0, "avg_logprob": -0.09356971453594905, "compression_ratio": 1.7899543378995433, "no_speech_prob": 0.0014319674810394645}, {"id": 540, "seek": 329304, "start": 3304.24, "end": 3309.36, "text": " what you want to hear is not the point that which is internal my test is not sufficient but it might", "tokens": [50924, 437, 291, 528, 281, 1568, 307, 406, 264, 935, 300, 597, 307, 6920, 452, 1500, 307, 406, 11563, 457, 309, 1062, 51180], "temperature": 0.0, "avg_logprob": -0.09356971453594905, "compression_ratio": 1.7899543378995433, "no_speech_prob": 0.0014319674810394645}, {"id": 541, "seek": 329304, "start": 3309.36, "end": 3318.8, "text": " be a logical pause point right it might be that if we can't even pass the test now of you know", "tokens": [51180, 312, 257, 14978, 10465, 935, 558, 309, 1062, 312, 300, 498, 321, 393, 380, 754, 1320, 264, 1500, 586, 295, 291, 458, 51652], "temperature": 0.0, "avg_logprob": -0.09356971453594905, "compression_ratio": 1.7899543378995433, "no_speech_prob": 0.0014319674810394645}, {"id": 542, "seek": 331880, "start": 3318.88, "end": 3326.6400000000003, "text": " controlling a deliberate sort of fine-tuned to be malicious version of GBT-4 then we don't", "tokens": [50368, 14905, 257, 30515, 1333, 295, 2489, 12, 83, 43703, 281, 312, 33496, 3037, 295, 26809, 51, 12, 19, 550, 321, 500, 380, 50756], "temperature": 0.0, "avg_logprob": -0.0422603448232015, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.03111862763762474}, {"id": 543, "seek": 331880, "start": 3326.6400000000003, "end": 3331.84, "text": " know what we're talking about and we're playing around with fire so you know passing that test", "tokens": [50756, 458, 437, 321, 434, 1417, 466, 293, 321, 434, 2433, 926, 365, 2610, 370, 291, 458, 8437, 300, 1500, 51016], "temperature": 0.0, "avg_logprob": -0.0422603448232015, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.03111862763762474}, {"id": 544, "seek": 331880, "start": 3331.84, "end": 3337.6000000000004, "text": " wouldn't be a guarantee that would be in good stead with an even smarter machine but we really", "tokens": [51016, 2759, 380, 312, 257, 10815, 300, 576, 312, 294, 665, 23721, 365, 364, 754, 20294, 3479, 457, 321, 534, 51304], "temperature": 0.0, "avg_logprob": -0.0422603448232015, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.03111862763762474}, {"id": 545, "seek": 331880, "start": 3337.6000000000004, "end": 3342.48, "text": " should be worried I think that we're not in a very good position with respect even to the current", "tokens": [51304, 820, 312, 5804, 286, 519, 300, 321, 434, 406, 294, 257, 588, 665, 2535, 365, 3104, 754, 281, 264, 2190, 51548], "temperature": 0.0, "avg_logprob": -0.0422603448232015, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.03111862763762474}, {"id": 546, "seek": 334248, "start": 3342.48, "end": 3349.12, "text": " ones. Gary I of course watched the recent congressional hearing where you and Sam Altman", "tokens": [50364, 2306, 13, 13788, 286, 295, 1164, 6337, 264, 5162, 32962, 4763, 689, 291, 293, 4832, 15992, 1601, 50696], "temperature": 0.0, "avg_logprob": -0.12048720090817182, "compression_ratio": 1.7535545023696681, "no_speech_prob": 0.16413478553295135}, {"id": 547, "seek": 334248, "start": 3349.12, "end": 3359.52, "text": " were testifying you know about what should be done should should should there be auditing of", "tokens": [50696, 645, 1500, 5489, 291, 458, 466, 437, 820, 312, 1096, 820, 820, 820, 456, 312, 2379, 1748, 295, 51216], "temperature": 0.0, "avg_logprob": -0.12048720090817182, "compression_ratio": 1.7535545023696681, "no_speech_prob": 0.16413478553295135}, {"id": 548, "seek": 334248, "start": 3359.52, "end": 3364.64, "text": " these systems you know before training before deployment and you know it may be you know the", "tokens": [51216, 613, 3652, 291, 458, 949, 3097, 949, 19317, 293, 291, 458, 309, 815, 312, 291, 458, 264, 51472], "temperature": 0.0, "avg_logprob": -0.12048720090817182, "compression_ratio": 1.7535545023696681, "no_speech_prob": 0.16413478553295135}, {"id": 549, "seek": 334248, "start": 3364.64, "end": 3370.16, "text": " most striking thing about about that session was you know just how little daylight there seemed", "tokens": [51472, 881, 18559, 551, 466, 466, 300, 5481, 390, 291, 458, 445, 577, 707, 29964, 456, 6576, 51748], "temperature": 0.0, "avg_logprob": -0.12048720090817182, "compression_ratio": 1.7535545023696681, "no_speech_prob": 0.16413478553295135}, {"id": 550, "seek": 337016, "start": 3370.24, "end": 3381.3599999999997, "text": " to be between you and Sam Altman the CEO of OpenAI you know I mean you know he was completely on", "tokens": [50368, 281, 312, 1296, 291, 293, 4832, 15992, 1601, 264, 9282, 295, 7238, 48698, 291, 458, 286, 914, 291, 458, 415, 390, 2584, 322, 50924], "temperature": 0.0, "avg_logprob": -0.11628446578979493, "compression_ratio": 1.6149425287356323, "no_speech_prob": 0.008689315058290958}, {"id": 551, "seek": 337016, "start": 3381.3599999999997, "end": 3390.24, "text": " board with the idea of you know establishing a regulatory framework for you know you know having", "tokens": [50924, 3150, 365, 264, 1558, 295, 291, 458, 22494, 257, 18260, 8388, 337, 291, 458, 291, 458, 1419, 51368], "temperature": 0.0, "avg_logprob": -0.11628446578979493, "compression_ratio": 1.6149425287356323, "no_speech_prob": 0.008689315058290958}, {"id": 552, "seek": 337016, "start": 3390.24, "end": 3396.24, "text": " to clear the you know more powerful systems before they are deployed now you know in in", "tokens": [51368, 281, 1850, 264, 291, 458, 544, 4005, 3652, 949, 436, 366, 17826, 586, 291, 458, 294, 294, 51668], "temperature": 0.0, "avg_logprob": -0.11628446578979493, "compression_ratio": 1.6149425287356323, "no_speech_prob": 0.008689315058290958}, {"id": 553, "seek": 339624, "start": 3396.24, "end": 3402.8799999999997, "text": " Aliezer's worldview that still would be woefully insufficient shortly and you know we would still", "tokens": [50364, 967, 414, 4527, 311, 41141, 300, 920, 576, 312, 6020, 68, 2277, 41709, 13392, 293, 291, 458, 321, 576, 920, 50696], "temperature": 0.0, "avg_logprob": -0.13638037513284124, "compression_ratio": 1.806930693069307, "no_speech_prob": 0.015391897410154343}, {"id": 554, "seek": 339624, "start": 3402.8799999999997, "end": 3408.7999999999997, "text": " all be dead but you know maybe in your in your worldview that you know it sounds like", "tokens": [50696, 439, 312, 3116, 457, 291, 458, 1310, 294, 428, 294, 428, 41141, 300, 291, 458, 309, 3263, 411, 50992], "temperature": 0.0, "avg_logprob": -0.13638037513284124, "compression_ratio": 1.806930693069307, "no_speech_prob": 0.015391897410154343}, {"id": 555, "seek": 339624, "start": 3410.7999999999997, "end": 3416.0, "text": " you know I'm not even sure how much daylight there is I mean the you know you know you know", "tokens": [51092, 291, 458, 286, 478, 406, 754, 988, 577, 709, 29964, 456, 307, 286, 914, 264, 291, 458, 291, 458, 291, 458, 51352], "temperature": 0.0, "avg_logprob": -0.13638037513284124, "compression_ratio": 1.806930693069307, "no_speech_prob": 0.015391897410154343}, {"id": 556, "seek": 339624, "start": 3416.0, "end": 3422.16, "text": " have the very I think historically striking situation where you know the the heads of all", "tokens": [51352, 362, 264, 588, 286, 519, 16180, 18559, 2590, 689, 291, 458, 264, 264, 8050, 295, 439, 51660], "temperature": 0.0, "avg_logprob": -0.13638037513284124, "compression_ratio": 1.806930693069307, "no_speech_prob": 0.015391897410154343}, {"id": 557, "seek": 342216, "start": 3422.16, "end": 3429.6, "text": " of the major AI or well almost all of the major AI organizations are you know agreeing and saying", "tokens": [50364, 295, 264, 2563, 7318, 420, 731, 1920, 439, 295, 264, 2563, 7318, 6150, 366, 291, 458, 36900, 293, 1566, 50736], "temperature": 0.0, "avg_logprob": -0.10566918233807167, "compression_ratio": 1.7074235807860263, "no_speech_prob": 0.003881706390529871}, {"id": 558, "seek": 342216, "start": 3429.6, "end": 3436.56, "text": " you know please regulate us yes this is dangerous yes we need to be regulated I mean I thought it", "tokens": [50736, 291, 458, 1767, 24475, 505, 2086, 341, 307, 5795, 2086, 321, 643, 281, 312, 26243, 286, 914, 286, 1194, 309, 51084], "temperature": 0.0, "avg_logprob": -0.10566918233807167, "compression_ratio": 1.7074235807860263, "no_speech_prob": 0.003881706390529871}, {"id": 559, "seek": 342216, "start": 3436.56, "end": 3442.64, "text": " was really striking in fact I talked to Sam just before you know the the hearing started and I had", "tokens": [51084, 390, 534, 18559, 294, 1186, 286, 2825, 281, 4832, 445, 949, 291, 458, 264, 264, 4763, 1409, 293, 286, 632, 51388], "temperature": 0.0, "avg_logprob": -0.10566918233807167, "compression_ratio": 1.7074235807860263, "no_speech_prob": 0.003881706390529871}, {"id": 560, "seek": 342216, "start": 3442.64, "end": 3447.44, "text": " just proposed an international agency for AI I wasn't the first person ever but I I pushed it in", "tokens": [51388, 445, 10348, 364, 5058, 7934, 337, 7318, 286, 2067, 380, 264, 700, 954, 1562, 457, 286, 286, 9152, 309, 294, 51628], "temperature": 0.0, "avg_logprob": -0.10566918233807167, "compression_ratio": 1.7074235807860263, "no_speech_prob": 0.003881706390529871}, {"id": 561, "seek": 344744, "start": 3447.44, "end": 3454.48, "text": " my TED talk and an economist op ed a few weeks before and Sam said to me I like that idea and I", "tokens": [50364, 452, 43036, 751, 293, 364, 36696, 999, 1257, 257, 1326, 3259, 949, 293, 4832, 848, 281, 385, 286, 411, 300, 1558, 293, 286, 50716], "temperature": 0.0, "avg_logprob": -0.07647490919682018, "compression_ratio": 1.707142857142857, "no_speech_prob": 0.17530198395252228}, {"id": 562, "seek": 344744, "start": 3454.48, "end": 3460.0, "text": " said tell them tell the Senate and he did and that kind of astonished me that he did I mean we have", "tokens": [50716, 848, 980, 552, 980, 264, 9867, 293, 415, 630, 293, 300, 733, 295, 25687, 4729, 385, 300, 415, 630, 286, 914, 321, 362, 50992], "temperature": 0.0, "avg_logprob": -0.07647490919682018, "compression_ratio": 1.707142857142857, "no_speech_prob": 0.17530198395252228}, {"id": 563, "seek": 344744, "start": 3460.0, "end": 3463.92, "text": " you know we've had some friction between the two of us in the past and he actually even attributed", "tokens": [50992, 291, 458, 321, 600, 632, 512, 17710, 1296, 264, 732, 295, 505, 294, 264, 1791, 293, 415, 767, 754, 30976, 51188], "temperature": 0.0, "avg_logprob": -0.07647490919682018, "compression_ratio": 1.707142857142857, "no_speech_prob": 0.17530198395252228}, {"id": 564, "seek": 344744, "start": 3463.92, "end": 3470.4, "text": " to me he said I support what Professor Marcus said about doing international governance and", "tokens": [51188, 281, 385, 415, 848, 286, 1406, 437, 8419, 26574, 848, 466, 884, 5058, 17449, 293, 51512], "temperature": 0.0, "avg_logprob": -0.07647490919682018, "compression_ratio": 1.707142857142857, "no_speech_prob": 0.17530198395252228}, {"id": 565, "seek": 344744, "start": 3470.4, "end": 3475.12, "text": " there's been a lot of convergence around the world on that is that enough to stop Aliezer's", "tokens": [51512, 456, 311, 668, 257, 688, 295, 32181, 926, 264, 1002, 322, 300, 307, 300, 1547, 281, 1590, 967, 414, 4527, 311, 51748], "temperature": 0.0, "avg_logprob": -0.07647490919682018, "compression_ratio": 1.707142857142857, "no_speech_prob": 0.17530198395252228}, {"id": 566, "seek": 347512, "start": 3475.68, "end": 3482.08, "text": " worries no I don't think so but it's an important baby step I think that we do need to have some", "tokens": [50392, 16340, 572, 286, 500, 380, 519, 370, 457, 309, 311, 364, 1021, 3186, 1823, 286, 519, 300, 321, 360, 643, 281, 362, 512, 50712], "temperature": 0.0, "avg_logprob": -0.05605265387782344, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.010482989251613617}, {"id": 567, "seek": 347512, "start": 3482.08, "end": 3486.4, "text": " global body that can coordinate around these things I don't think we really have to", "tokens": [50712, 4338, 1772, 300, 393, 15670, 926, 613, 721, 286, 500, 380, 519, 321, 534, 362, 281, 50928], "temperature": 0.0, "avg_logprob": -0.05605265387782344, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.010482989251613617}, {"id": 568, "seek": 347512, "start": 3486.4, "end": 3490.96, "text": " coordinate around superintelligence yet but if we can't do any coordination now then when the", "tokens": [50928, 15670, 926, 1687, 20761, 17644, 1939, 457, 498, 321, 393, 380, 360, 604, 21252, 586, 550, 562, 264, 51156], "temperature": 0.0, "avg_logprob": -0.05605265387782344, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.010482989251613617}, {"id": 569, "seek": 347512, "start": 3490.96, "end": 3496.72, "text": " time comes we're not prepared so I think it's great that there's some agreement I I worry that you", "tokens": [51156, 565, 1487, 321, 434, 406, 4927, 370, 286, 519, 309, 311, 869, 300, 456, 311, 512, 8106, 286, 286, 3292, 300, 291, 51444], "temperature": 0.0, "avg_logprob": -0.05605265387782344, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.010482989251613617}, {"id": 570, "seek": 347512, "start": 3496.72, "end": 3502.0, "text": " know open AI had this lobbying document that just came out that seemed not entirely consistent with", "tokens": [51444, 458, 1269, 7318, 632, 341, 47142, 4166, 300, 445, 1361, 484, 300, 6576, 406, 7696, 8398, 365, 51708], "temperature": 0.0, "avg_logprob": -0.05605265387782344, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.010482989251613617}, {"id": 571, "seek": 350200, "start": 3502.0, "end": 3506.72, "text": " what Sam said in the room and there's always concerns about regulatory capture and so forth", "tokens": [50364, 437, 4832, 848, 294, 264, 1808, 293, 456, 311, 1009, 7389, 466, 18260, 7983, 293, 370, 5220, 50600], "temperature": 0.0, "avg_logprob": -0.07887669905875493, "compression_ratio": 1.7348484848484849, "no_speech_prob": 0.007005695253610611}, {"id": 572, "seek": 350200, "start": 3506.72, "end": 3511.12, "text": " but I think it's great that a lot of the the heads of these companies maybe with the exception", "tokens": [50600, 457, 286, 519, 309, 311, 869, 300, 257, 688, 295, 264, 264, 8050, 295, 613, 3431, 1310, 365, 264, 11183, 50820], "temperature": 0.0, "avg_logprob": -0.07887669905875493, "compression_ratio": 1.7348484848484849, "no_speech_prob": 0.007005695253610611}, {"id": 573, "seek": 350200, "start": 3511.84, "end": 3517.6, "text": " of Facebook or meta are recognizing that there are genuine concerns here I mean the other", "tokens": [50856, 295, 4384, 420, 19616, 366, 18538, 300, 456, 366, 16699, 7389, 510, 286, 914, 264, 661, 51144], "temperature": 0.0, "avg_logprob": -0.07887669905875493, "compression_ratio": 1.7348484848484849, "no_speech_prob": 0.007005695253610611}, {"id": 574, "seek": 350200, "start": 3517.6, "end": 3522.0, "text": " moment that a lot of people remember from the testimony was when Sam was asked what he was", "tokens": [51144, 1623, 300, 257, 688, 295, 561, 1604, 490, 264, 15634, 390, 562, 4832, 390, 2351, 437, 415, 390, 51364], "temperature": 0.0, "avg_logprob": -0.07887669905875493, "compression_ratio": 1.7348484848484849, "no_speech_prob": 0.007005695253610611}, {"id": 575, "seek": 350200, "start": 3522.0, "end": 3527.76, "text": " most concerned about was it jobs and he said no and I asked Senator Blumenthal to push Sam", "tokens": [51364, 881, 5922, 466, 390, 309, 4782, 293, 415, 848, 572, 293, 286, 2351, 10893, 2177, 2206, 4947, 281, 2944, 4832, 51652], "temperature": 0.0, "avg_logprob": -0.07887669905875493, "compression_ratio": 1.7348484848484849, "no_speech_prob": 0.007005695253610611}, {"id": 576, "seek": 352776, "start": 3527.76, "end": 3531.6000000000004, "text": " and Sam was you know he could have been more candid but he was fairly candid", "tokens": [50364, 293, 4832, 390, 291, 458, 415, 727, 362, 668, 544, 6268, 457, 415, 390, 6457, 6268, 50556], "temperature": 0.0, "avg_logprob": -0.07230588522824374, "compression_ratio": 1.7378640776699028, "no_speech_prob": 0.0008294873987324536}, {"id": 577, "seek": 352776, "start": 3531.6000000000004, "end": 3536.0, "text": " and he said he was worried about serious harm to the species I think that was an important moment", "tokens": [50556, 293, 415, 848, 415, 390, 5804, 466, 3156, 6491, 281, 264, 6172, 286, 519, 300, 390, 364, 1021, 1623, 50776], "temperature": 0.0, "avg_logprob": -0.07230588522824374, "compression_ratio": 1.7378640776699028, "no_speech_prob": 0.0008294873987324536}, {"id": 578, "seek": 352776, "start": 3536.0, "end": 3540.5600000000004, "text": " when he said that to the Senate and I think it galvanized a lot of people that he said it", "tokens": [50776, 562, 415, 848, 300, 281, 264, 9867, 293, 286, 519, 309, 7660, 9768, 1602, 257, 688, 295, 561, 300, 415, 848, 309, 51004], "temperature": 0.0, "avg_logprob": -0.07230588522824374, "compression_ratio": 1.7378640776699028, "no_speech_prob": 0.0008294873987324536}, {"id": 579, "seek": 352776, "start": 3543.2000000000003, "end": 3549.6000000000004, "text": " so can we dwell on a moment um I mean we've been talking about the the depending on your view", "tokens": [51136, 370, 393, 321, 24355, 322, 257, 1623, 1105, 286, 914, 321, 600, 668, 1417, 466, 264, 264, 5413, 322, 428, 1910, 51456], "temperature": 0.0, "avg_logprob": -0.07230588522824374, "compression_ratio": 1.7378640776699028, "no_speech_prob": 0.0008294873987324536}, {"id": 580, "seek": 354960, "start": 3549.68, "end": 3558.16, "text": " highly likely or tail risk scenario of humanity's extinction or or significant destruction", "tokens": [50368, 5405, 3700, 420, 6838, 3148, 9005, 295, 10243, 311, 33163, 420, 420, 4776, 13563, 50792], "temperature": 0.0, "avg_logprob": -0.07220947547037093, "compression_ratio": 1.6149425287356323, "no_speech_prob": 0.2421131730079651}, {"id": 581, "seek": 354960, "start": 3559.52, "end": 3566.4, "text": " it would appear to me by the same token if if those are plausible scenarios we're talking about", "tokens": [50860, 309, 576, 4204, 281, 385, 538, 264, 912, 14862, 498, 498, 729, 366, 39925, 15077, 321, 434, 1417, 466, 51204], "temperature": 0.0, "avg_logprob": -0.07220947547037093, "compression_ratio": 1.6149425287356323, "no_speech_prob": 0.2421131730079651}, {"id": 582, "seek": 354960, "start": 3566.4, "end": 3574.72, "text": " then the opposite maybe we're talking about as well um you know what does it look like to have", "tokens": [51204, 550, 264, 6182, 1310, 321, 434, 1417, 466, 382, 731, 1105, 291, 458, 437, 775, 309, 574, 411, 281, 362, 51620], "temperature": 0.0, "avg_logprob": -0.07220947547037093, "compression_ratio": 1.6149425287356323, "no_speech_prob": 0.2421131730079651}, {"id": 583, "seek": 357472, "start": 3574.72, "end": 3584.3199999999997, "text": " a super intelligent AI that really you know as if as a feature of its intelligence deeply", "tokens": [50364, 257, 1687, 13232, 7318, 300, 534, 291, 458, 382, 498, 382, 257, 4111, 295, 1080, 7599, 8760, 50844], "temperature": 0.0, "avg_logprob": -0.16429591178894043, "compression_ratio": 1.6904761904761905, "no_speech_prob": 0.0166523065418005}, {"id": 584, "seek": 357472, "start": 3584.3199999999997, "end": 3595.04, "text": " understands human beings the human species and also has a deep desire for us to be as happy as possible", "tokens": [50844, 15146, 1952, 8958, 264, 1952, 6172, 293, 611, 575, 257, 2452, 7516, 337, 505, 281, 312, 382, 2055, 382, 1944, 51380], "temperature": 0.0, "avg_logprob": -0.16429591178894043, "compression_ratio": 1.6904761904761905, "no_speech_prob": 0.0166523065418005}, {"id": 585, "seek": 357472, "start": 3596.48, "end": 3600.7999999999997, "text": " what does that world look like oh is that possible no no not that that looks like you know", "tokens": [51452, 437, 775, 300, 1002, 574, 411, 1954, 307, 300, 1944, 572, 572, 406, 300, 300, 1542, 411, 291, 458, 51668], "temperature": 0.0, "avg_logprob": -0.16429591178894043, "compression_ratio": 1.6904761904761905, "no_speech_prob": 0.0166523065418005}, {"id": 586, "seek": 360080, "start": 3600.88, "end": 3604.5600000000004, "text": " just like why are why are everyone leather centers to make them as happy as possible", "tokens": [50368, 445, 411, 983, 366, 983, 366, 1518, 12821, 10898, 281, 652, 552, 382, 2055, 382, 1944, 50552], "temperature": 0.0, "avg_logprob": -0.1255673139523237, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.0034820532891899347}, {"id": 587, "seek": 360080, "start": 3605.1200000000003, "end": 3611.92, "text": " but more like a parent wants their child to be happy right that may not involve any particular", "tokens": [50580, 457, 544, 411, 257, 2596, 2738, 641, 1440, 281, 312, 2055, 558, 300, 815, 406, 9494, 604, 1729, 50920], "temperature": 0.0, "avg_logprob": -0.1255673139523237, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.0034820532891899347}, {"id": 588, "seek": 360080, "start": 3611.92, "end": 3617.76, "text": " scenario but is is generally quite concerned about the well-being of the human race and is also", "tokens": [50920, 9005, 457, 307, 307, 5101, 1596, 5922, 466, 264, 731, 12, 13054, 295, 264, 1952, 4569, 293, 307, 611, 51212], "temperature": 0.0, "avg_logprob": -0.1255673139523237, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.0034820532891899347}, {"id": 589, "seek": 360080, "start": 3617.76, "end": 3625.6800000000003, "text": " super intelligent honestly I'd rather have machines work on medical problems than happiness problems", "tokens": [51212, 1687, 13232, 6095, 286, 1116, 2831, 362, 8379, 589, 322, 4625, 2740, 813, 8324, 2740, 51608], "temperature": 0.0, "avg_logprob": -0.1255673139523237, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.0034820532891899347}, {"id": 590, "seek": 362568, "start": 3625.68, "end": 3634.0, "text": " I think there's maybe more risk of mis-specification of the happiness problems um whereas if we get", "tokens": [50364, 286, 519, 456, 311, 1310, 544, 3148, 295, 3346, 12, 7053, 66, 3774, 295, 264, 8324, 2740, 1105, 9735, 498, 321, 483, 50780], "temperature": 0.0, "avg_logprob": -0.07475756762320535, "compression_ratio": 1.7491039426523298, "no_speech_prob": 0.013011166825890541}, {"id": 591, "seek": 362568, "start": 3634.0, "end": 3638.64, "text": " them to work on Alzheimer's and just say like figure out what's going on why are these plaques", "tokens": [50780, 552, 281, 589, 322, 27932, 311, 293, 445, 584, 411, 2573, 484, 437, 311, 516, 322, 983, 366, 613, 15256, 7519, 51012], "temperature": 0.0, "avg_logprob": -0.07475756762320535, "compression_ratio": 1.7491039426523298, "no_speech_prob": 0.013011166825890541}, {"id": 592, "seek": 362568, "start": 3638.64, "end": 3643.44, "text": " there what can you do about it maybe there's less harm that might come come from you don't need", "tokens": [51012, 456, 437, 393, 291, 360, 466, 309, 1310, 456, 311, 1570, 6491, 300, 1062, 808, 808, 490, 291, 500, 380, 643, 51252], "temperature": 0.0, "avg_logprob": -0.07475756762320535, "compression_ratio": 1.7491039426523298, "no_speech_prob": 0.013011166825890541}, {"id": 593, "seek": 362568, "start": 3643.44, "end": 3647.8399999999997, "text": " super intelligence for that that sounds like an alpha fold three problem or an alpha fold four", "tokens": [51252, 1687, 7599, 337, 300, 300, 3263, 411, 364, 8961, 4860, 1045, 1154, 420, 364, 8961, 4860, 1451, 51472], "temperature": 0.0, "avg_logprob": -0.07475756762320535, "compression_ratio": 1.7491039426523298, "no_speech_prob": 0.013011166825890541}, {"id": 594, "seek": 362568, "start": 3647.8399999999997, "end": 3652.96, "text": " problem well this is also this is somewhat different than the question I'm asking it's it's not really", "tokens": [51472, 1154, 731, 341, 307, 611, 341, 307, 8344, 819, 813, 264, 1168, 286, 478, 3365, 309, 311, 309, 311, 406, 534, 51728], "temperature": 0.0, "avg_logprob": -0.07475756762320535, "compression_ratio": 1.7491039426523298, "no_speech_prob": 0.013011166825890541}, {"id": 595, "seek": 365296, "start": 3653.04, "end": 3658.8, "text": " even um us asking a super intelligence to do anything because we we've already been entertaining", "tokens": [50368, 754, 1105, 505, 3365, 257, 1687, 7599, 281, 360, 1340, 570, 321, 321, 600, 1217, 668, 20402, 50656], "temperature": 0.0, "avg_logprob": -0.0906938374042511, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.046612612903118134}, {"id": 596, "seek": 365296, "start": 3658.8, "end": 3664.48, "text": " scenarios where the super intelligence has its own desires independent of us is it do you think", "tokens": [50656, 15077, 689, 264, 1687, 7599, 575, 1080, 1065, 18005, 6695, 295, 505, 307, 309, 360, 291, 519, 50940], "temperature": 0.0, "avg_logprob": -0.0906938374042511, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.046612612903118134}, {"id": 597, "seek": 365296, "start": 3664.48, "end": 3672.32, "text": " at all yeah I'm not real thrilled with that I mean I mean I don't think we want to leave", "tokens": [50940, 412, 439, 1338, 286, 478, 406, 957, 18744, 365, 300, 286, 914, 286, 914, 286, 500, 380, 519, 321, 528, 281, 1856, 51332], "temperature": 0.0, "avg_logprob": -0.0906938374042511, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.046612612903118134}, {"id": 598, "seek": 365296, "start": 3673.68, "end": 3678.56, "text": " what their objective functions are what their desires are to them working them out", "tokens": [51400, 437, 641, 10024, 6828, 366, 437, 641, 18005, 366, 281, 552, 1364, 552, 484, 51644], "temperature": 0.0, "avg_logprob": -0.0906938374042511, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.046612612903118134}, {"id": 599, "seek": 367856, "start": 3678.56, "end": 3683.36, "text": " you know with no consultation from us with no human in the loop right fully I mean especially", "tokens": [50364, 291, 458, 365, 572, 20932, 490, 505, 365, 572, 1952, 294, 264, 6367, 558, 4498, 286, 914, 2318, 50604], "temperature": 0.0, "avg_logprob": -0.08494874343131352, "compression_ratio": 1.8700787401574803, "no_speech_prob": 0.06643953174352646}, {"id": 600, "seek": 367856, "start": 3683.36, "end": 3689.04, "text": " given our current understanding of the technology like our current understanding of how to keep", "tokens": [50604, 2212, 527, 2190, 3701, 295, 264, 2899, 411, 527, 2190, 3701, 295, 577, 281, 1066, 50888], "temperature": 0.0, "avg_logprob": -0.08494874343131352, "compression_ratio": 1.8700787401574803, "no_speech_prob": 0.06643953174352646}, {"id": 601, "seek": 367856, "start": 3689.04, "end": 3695.04, "text": " a system on track doing what we want to do is pretty limited and so you know taking humans out", "tokens": [50888, 257, 1185, 322, 2837, 884, 437, 321, 528, 281, 360, 307, 1238, 5567, 293, 370, 291, 458, 1940, 6255, 484, 51188], "temperature": 0.0, "avg_logprob": -0.08494874343131352, "compression_ratio": 1.8700787401574803, "no_speech_prob": 0.06643953174352646}, {"id": 602, "seek": 367856, "start": 3695.04, "end": 3699.92, "text": " of the loop there sounds like a really bad idea to me at least in the foreseeable future I would", "tokens": [51188, 295, 264, 6367, 456, 3263, 411, 257, 534, 1578, 1558, 281, 385, 412, 1935, 294, 264, 38736, 712, 2027, 286, 576, 51432], "temperature": 0.0, "avg_logprob": -0.08494874343131352, "compression_ratio": 1.8700787401574803, "no_speech_prob": 0.06643953174352646}, {"id": 603, "seek": 367856, "start": 3699.92, "end": 3704.88, "text": " want to see much better alignment technology before I would want to give free rent free range", "tokens": [51432, 528, 281, 536, 709, 1101, 18515, 2899, 949, 286, 576, 528, 281, 976, 1737, 6214, 1737, 3613, 51680], "temperature": 0.0, "avg_logprob": -0.08494874343131352, "compression_ratio": 1.8700787401574803, "no_speech_prob": 0.06643953174352646}, {"id": 604, "seek": 370488, "start": 3704.96, "end": 3710.8, "text": " so so so if we had the textbook from the future like we have the textbook from 100 years in the", "tokens": [50368, 370, 370, 370, 498, 321, 632, 264, 25591, 490, 264, 2027, 411, 321, 362, 264, 25591, 490, 2319, 924, 294, 264, 50660], "temperature": 0.0, "avg_logprob": -0.07083713198171078, "compression_ratio": 1.9957264957264957, "no_speech_prob": 0.0007548716384917498}, {"id": 605, "seek": 370488, "start": 3710.8, "end": 3715.76, "text": " future which contains all the simple ideas that actually work in real life as opposed to you", "tokens": [50660, 2027, 597, 8306, 439, 264, 2199, 3487, 300, 767, 589, 294, 957, 993, 382, 8851, 281, 291, 50908], "temperature": 0.0, "avg_logprob": -0.07083713198171078, "compression_ratio": 1.9957264957264957, "no_speech_prob": 0.0007548716384917498}, {"id": 606, "seek": 370488, "start": 3715.76, "end": 3719.92, "text": " know the complicated ideas and the simple ideas that don't work in real life the equivalent of", "tokens": [50908, 458, 264, 6179, 3487, 293, 264, 2199, 3487, 300, 500, 380, 589, 294, 957, 993, 264, 10344, 295, 51116], "temperature": 0.0, "avg_logprob": -0.07083713198171078, "compression_ratio": 1.9957264957264957, "no_speech_prob": 0.0007548716384917498}, {"id": 607, "seek": 370488, "start": 3719.92, "end": 3724.96, "text": " relus instead of sigmoids for the activation functions you know 100 the textbook from 100", "tokens": [51116, 1039, 301, 2602, 295, 4556, 3280, 3742, 337, 264, 24433, 6828, 291, 458, 2319, 264, 25591, 490, 2319, 51368], "temperature": 0.0, "avg_logprob": -0.07083713198171078, "compression_ratio": 1.9957264957264957, "no_speech_prob": 0.0007548716384917498}, {"id": 608, "seek": 370488, "start": 3724.96, "end": 3732.08, "text": " years in the future you can probably build a super intelligence that'll want anything you can", "tokens": [51368, 924, 294, 264, 2027, 291, 393, 1391, 1322, 257, 1687, 7599, 300, 603, 528, 1340, 291, 393, 51724], "temperature": 0.0, "avg_logprob": -0.07083713198171078, "compression_ratio": 1.9957264957264957, "no_speech_prob": 0.0007548716384917498}, {"id": 609, "seek": 373208, "start": 3732.64, "end": 3738.3199999999997, "text": " anything that's coherent to want anything you can you know figure out how to say describe", "tokens": [50392, 1340, 300, 311, 36239, 281, 528, 1340, 291, 393, 291, 458, 2573, 484, 577, 281, 584, 6786, 50676], "temperature": 0.0, "avg_logprob": -0.08316593350104566, "compression_ratio": 1.9743589743589745, "no_speech_prob": 0.001699115615338087}, {"id": 610, "seek": 373208, "start": 3738.3199999999997, "end": 3742.3199999999997, "text": " coherently point that at your own mind and tell you to figure out what what it is you meant", "tokens": [50676, 26528, 2276, 935, 300, 412, 428, 1065, 1575, 293, 980, 291, 281, 2573, 484, 437, 437, 309, 307, 291, 4140, 50876], "temperature": 0.0, "avg_logprob": -0.08316593350104566, "compression_ratio": 1.9743589743589745, "no_speech_prob": 0.001699115615338087}, {"id": 611, "seek": 373208, "start": 3742.3199999999997, "end": 3747.2, "text": " for to want and you know you could get the you could get the glorious transhumanist future you", "tokens": [50876, 337, 281, 528, 293, 291, 458, 291, 727, 483, 264, 291, 727, 483, 264, 24026, 1145, 18796, 468, 2027, 291, 51120], "temperature": 0.0, "avg_logprob": -0.08316593350104566, "compression_ratio": 1.9743589743589745, "no_speech_prob": 0.001699115615338087}, {"id": 612, "seek": 373208, "start": 3747.2, "end": 3754.0, "text": " could get the happily ever after anything's you know anything's possible that doesn't violate the", "tokens": [51120, 727, 483, 264, 19909, 1562, 934, 1340, 311, 291, 458, 1340, 311, 1944, 300, 1177, 380, 37478, 264, 51460], "temperature": 0.0, "avg_logprob": -0.08316593350104566, "compression_ratio": 1.9743589743589745, "no_speech_prob": 0.001699115615338087}, {"id": 613, "seek": 373208, "start": 3754.0, "end": 3759.68, "text": " laws of physics the trouble is doing it in real life and you know and the first try but", "tokens": [51460, 6064, 295, 10649, 264, 5253, 307, 884, 309, 294, 957, 993, 293, 291, 458, 293, 264, 700, 853, 457, 51744], "temperature": 0.0, "avg_logprob": -0.08316593350104566, "compression_ratio": 1.9743589743589745, "no_speech_prob": 0.001699115615338087}, {"id": 614, "seek": 375968, "start": 3759.68, "end": 3766.08, "text": " uh yeah so like you know could the the the whole thing that we're we're aiming for here is to", "tokens": [50364, 2232, 1338, 370, 411, 291, 458, 727, 264, 264, 264, 1379, 551, 300, 321, 434, 321, 434, 20253, 337, 510, 307, 281, 50684], "temperature": 0.0, "avg_logprob": -0.09221269796182821, "compression_ratio": 1.8221153846153846, "no_speech_prob": 0.0010480534983798862}, {"id": 615, "seek": 375968, "start": 3766.64, "end": 3772.72, "text": " colonize all the galaxies we can reach um before somebody else gets them first and turn them into", "tokens": [50712, 8255, 1125, 439, 264, 28755, 321, 393, 2524, 1105, 949, 2618, 1646, 2170, 552, 700, 293, 1261, 552, 666, 51016], "temperature": 0.0, "avg_logprob": -0.09221269796182821, "compression_ratio": 1.8221153846153846, "no_speech_prob": 0.0010480534983798862}, {"id": 616, "seek": 375968, "start": 3772.72, "end": 3778.08, "text": " galaxies full of you know complex sapient life living happily ever after you know that that's", "tokens": [51016, 28755, 1577, 295, 291, 458, 3997, 18985, 1196, 993, 2647, 19909, 1562, 934, 291, 458, 300, 300, 311, 51284], "temperature": 0.0, "avg_logprob": -0.09221269796182821, "compression_ratio": 1.8221153846153846, "no_speech_prob": 0.0010480534983798862}, {"id": 617, "seek": 375968, "start": 3778.08, "end": 3784.08, "text": " that's the goal that's still the goal even if we you know even even even when I call for like", "tokens": [51284, 300, 311, 264, 3387, 300, 311, 920, 264, 3387, 754, 498, 321, 291, 458, 754, 754, 754, 562, 286, 818, 337, 411, 51584], "temperature": 0.0, "avg_logprob": -0.09221269796182821, "compression_ratio": 1.8221153846153846, "no_speech_prob": 0.0010480534983798862}, {"id": 618, "seek": 378408, "start": 3784.64, "end": 3790.56, "text": " you know a permanent moratorium on AI I'm not trying to prevent us from count from colonizing", "tokens": [50392, 291, 458, 257, 10996, 1896, 41679, 322, 7318, 286, 478, 406, 1382, 281, 4871, 505, 490, 1207, 490, 8255, 3319, 50688], "temperature": 0.0, "avg_logprob": -0.1333063104179468, "compression_ratio": 1.5850622406639003, "no_speech_prob": 0.03257328271865845}, {"id": 619, "seek": 378408, "start": 3790.56, "end": 3797.2799999999997, "text": " the galaxies you know like humanity forbid um more more like let's you know let's like do some", "tokens": [50688, 264, 28755, 291, 458, 411, 10243, 34117, 1105, 544, 544, 411, 718, 311, 291, 458, 718, 311, 411, 360, 512, 51024], "temperature": 0.0, "avg_logprob": -0.1333063104179468, "compression_ratio": 1.5850622406639003, "no_speech_prob": 0.03257328271865845}, {"id": 620, "seek": 378408, "start": 3797.2799999999997, "end": 3803.52, "text": " human intelligence augmentation with alpha fold four and before we try building GPT-8 one of the", "tokens": [51024, 1952, 7599, 14501, 19631, 365, 8961, 4860, 1451, 293, 949, 321, 853, 2390, 26039, 51, 12, 23, 472, 295, 264, 51336], "temperature": 0.0, "avg_logprob": -0.1333063104179468, "compression_ratio": 1.5850622406639003, "no_speech_prob": 0.03257328271865845}, {"id": 621, "seek": 378408, "start": 3803.52, "end": 3810.24, "text": " few scenarios that I think we can clearly rule out here is an AI that is existentially dangerous", "tokens": [51336, 1326, 15077, 300, 286, 519, 321, 393, 4448, 4978, 484, 510, 307, 364, 7318, 300, 307, 2514, 3137, 5795, 51672], "temperature": 0.0, "avg_logprob": -0.1333063104179468, "compression_ratio": 1.5850622406639003, "no_speech_prob": 0.03257328271865845}, {"id": 622, "seek": 381024, "start": 3810.24, "end": 3816.8799999999997, "text": " but also boring right I mean I think anything that has the capacity to kill us all right would have", "tokens": [50364, 457, 611, 9989, 558, 286, 914, 286, 519, 1340, 300, 575, 264, 6042, 281, 1961, 505, 439, 558, 576, 362, 50696], "temperature": 0.0, "avg_logprob": -0.07612961094553877, "compression_ratio": 1.900497512437811, "no_speech_prob": 0.008570230565965176}, {"id": 623, "seek": 381024, "start": 3816.8799999999997, "end": 3823.3599999999997, "text": " you know if if nothing else pretty amazing capabilities and those capabilities you know", "tokens": [50696, 291, 458, 498, 498, 1825, 1646, 1238, 2243, 10862, 293, 729, 10862, 291, 458, 51020], "temperature": 0.0, "avg_logprob": -0.07612961094553877, "compression_ratio": 1.900497512437811, "no_speech_prob": 0.008570230565965176}, {"id": 624, "seek": 381024, "start": 3823.3599999999997, "end": 3830.08, "text": " could also be turned to you know solving a lot of humanities problems right you know if if we were", "tokens": [51020, 727, 611, 312, 3574, 281, 291, 458, 12606, 257, 688, 295, 36140, 2740, 558, 291, 458, 498, 498, 321, 645, 51356], "temperature": 0.0, "avg_logprob": -0.07612961094553877, "compression_ratio": 1.900497512437811, "no_speech_prob": 0.008570230565965176}, {"id": 625, "seek": 381024, "start": 3830.08, "end": 3836.64, "text": " to solve the alignment problem I mean you know humanity had a lot of existential you know risks", "tokens": [51356, 281, 5039, 264, 18515, 1154, 286, 914, 291, 458, 10243, 632, 257, 688, 295, 37133, 291, 458, 10888, 51684], "temperature": 0.0, "avg_logprob": -0.07612961094553877, "compression_ratio": 1.900497512437811, "no_speech_prob": 0.008570230565965176}, {"id": 626, "seek": 383664, "start": 3836.64, "end": 3842.3199999999997, "text": " you know before AI came on the scene right uh you know I mean there was the risk of of you", "tokens": [50364, 291, 458, 949, 7318, 1361, 322, 264, 4145, 558, 2232, 291, 458, 286, 914, 456, 390, 264, 3148, 295, 295, 291, 50648], "temperature": 0.0, "avg_logprob": -0.06503437427764243, "compression_ratio": 1.9896373056994818, "no_speech_prob": 0.03618839010596275}, {"id": 627, "seek": 383664, "start": 3842.3199999999997, "end": 3847.8399999999997, "text": " know nuclear annihilation there is the risk of runaway climate change and you know I would I", "tokens": [50648, 458, 8179, 40430, 16067, 456, 307, 264, 3148, 295, 1190, 10318, 5659, 1319, 293, 291, 458, 286, 576, 286, 50924], "temperature": 0.0, "avg_logprob": -0.06503437427764243, "compression_ratio": 1.9896373056994818, "no_speech_prob": 0.03618839010596275}, {"id": 628, "seek": 383664, "start": 3847.8399999999997, "end": 3854.56, "text": " would love to see you know an AI that could help us with such things I would also love to see an AI", "tokens": [50924, 576, 959, 281, 536, 291, 458, 364, 7318, 300, 727, 854, 505, 365, 1270, 721, 286, 576, 611, 959, 281, 536, 364, 7318, 51260], "temperature": 0.0, "avg_logprob": -0.06503437427764243, "compression_ratio": 1.9896373056994818, "no_speech_prob": 0.03618839010596275}, {"id": 629, "seek": 383664, "start": 3854.56, "end": 3860.48, "text": " that could sort of you know help us just solve you know some of the mysteries of the universe I mean", "tokens": [51260, 300, 727, 1333, 295, 291, 458, 854, 505, 445, 5039, 291, 458, 512, 295, 264, 30785, 295, 264, 6445, 286, 914, 51556], "temperature": 0.0, "avg_logprob": -0.06503437427764243, "compression_ratio": 1.9896373056994818, "no_speech_prob": 0.03618839010596275}, {"id": 630, "seek": 386048, "start": 3860.56, "end": 3867.36, "text": " you know like how can one possibly not be curious to know you know what what such a being could teach", "tokens": [50368, 291, 458, 411, 577, 393, 472, 6264, 406, 312, 6369, 281, 458, 291, 458, 437, 437, 1270, 257, 885, 727, 2924, 50708], "temperature": 0.0, "avg_logprob": -0.055796417139344294, "compression_ratio": 1.8226415094339623, "no_speech_prob": 0.4106580317020416}, {"id": 631, "seek": 386048, "start": 3867.36, "end": 3873.28, "text": " us uh you know I mean I mean for the past year I've tried to use GPT-4 to produce original", "tokens": [50708, 505, 2232, 291, 458, 286, 914, 286, 914, 337, 264, 1791, 1064, 286, 600, 3031, 281, 764, 26039, 51, 12, 19, 281, 5258, 3380, 51004], "temperature": 0.0, "avg_logprob": -0.055796417139344294, "compression_ratio": 1.8226415094339623, "no_speech_prob": 0.4106580317020416}, {"id": 632, "seek": 386048, "start": 3873.28, "end": 3878.96, "text": " scientific insights and I've not been able to get it to do that uh and you know I don't know", "tokens": [51004, 8134, 14310, 293, 286, 600, 406, 668, 1075, 281, 483, 309, 281, 360, 300, 2232, 293, 291, 458, 286, 500, 380, 458, 51288], "temperature": 0.0, "avg_logprob": -0.055796417139344294, "compression_ratio": 1.8226415094339623, "no_speech_prob": 0.4106580317020416}, {"id": 633, "seek": 386048, "start": 3878.96, "end": 3884.16, "text": " whether I should feel you know disappointed or relieved by that but I think you know the better", "tokens": [51288, 1968, 286, 820, 841, 291, 458, 13856, 420, 27972, 538, 300, 457, 286, 519, 291, 458, 264, 1101, 51548], "temperature": 0.0, "avg_logprob": -0.055796417139344294, "compression_ratio": 1.8226415094339623, "no_speech_prob": 0.4106580317020416}, {"id": 634, "seek": 386048, "start": 3884.16, "end": 3890.32, "text": " part of me should you know just is the part that should just want to see you know the great mysteries", "tokens": [51548, 644, 295, 385, 820, 291, 458, 445, 307, 264, 644, 300, 820, 445, 528, 281, 536, 291, 458, 264, 869, 30785, 51856], "temperature": 0.0, "avg_logprob": -0.055796417139344294, "compression_ratio": 1.8226415094339623, "no_speech_prob": 0.4106580317020416}, {"id": 635, "seek": 389032, "start": 3890.32, "end": 3897.44, "text": " of of existence of you know why is the universe quantum mechanical or you know how do you prove", "tokens": [50364, 295, 295, 9123, 295, 291, 458, 983, 307, 264, 6445, 13018, 12070, 420, 291, 458, 577, 360, 291, 7081, 50720], "temperature": 0.0, "avg_logprob": -0.11572714487711588, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.000295899371849373}, {"id": 636, "seek": 389032, "start": 3897.44, "end": 3904.0800000000004, "text": " the Riemann hypothesis it should just want to see these mysteries solved you know and and uh if it's", "tokens": [50720, 264, 497, 4907, 969, 17291, 309, 820, 445, 528, 281, 536, 613, 30785, 13041, 291, 458, 293, 293, 2232, 498, 309, 311, 51052], "temperature": 0.0, "avg_logprob": -0.11572714487711588, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.000295899371849373}, {"id": 637, "seek": 389032, "start": 3904.0800000000004, "end": 3912.4, "text": " to be by AI then then then then fine let it be by AI let me give you a kind of lesson in epistemic", "tokens": [51052, 281, 312, 538, 7318, 550, 550, 550, 550, 2489, 718, 309, 312, 538, 7318, 718, 385, 976, 291, 257, 733, 295, 6898, 294, 2388, 468, 3438, 51468], "temperature": 0.0, "avg_logprob": -0.11572714487711588, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.000295899371849373}, {"id": 638, "seek": 391240, "start": 3912.48, "end": 3920.56, "text": " humility we don't really know whether GPT-4 is net positive or net negative you know there are", "tokens": [50368, 27106, 321, 500, 380, 534, 458, 1968, 26039, 51, 12, 19, 307, 2533, 3353, 420, 2533, 3671, 291, 458, 456, 366, 50772], "temperature": 0.0, "avg_logprob": -0.10185002057980268, "compression_ratio": 1.905511811023622, "no_speech_prob": 0.3995293378829956}, {"id": 639, "seek": 391240, "start": 3920.56, "end": 3924.56, "text": " lots of arguments you can make I've been in a bunch of debates where I've you know had to take the", "tokens": [50772, 3195, 295, 12869, 291, 393, 652, 286, 600, 668, 294, 257, 3840, 295, 24203, 689, 286, 600, 291, 458, 632, 281, 747, 264, 50972], "temperature": 0.0, "avg_logprob": -0.10185002057980268, "compression_ratio": 1.905511811023622, "no_speech_prob": 0.3995293378829956}, {"id": 640, "seek": 391240, "start": 3924.56, "end": 3929.28, "text": " side of arguing that that it's a net negative but we don't really know if we don't know that", "tokens": [50972, 1252, 295, 19697, 300, 300, 309, 311, 257, 2533, 3671, 457, 321, 500, 380, 534, 458, 498, 321, 500, 380, 458, 300, 51208], "temperature": 0.0, "avg_logprob": -0.10185002057980268, "compression_ratio": 1.905511811023622, "no_speech_prob": 0.3995293378829956}, {"id": 641, "seek": 391240, "start": 3930.56, "end": 3935.6800000000003, "text": " was the invention of agriculture net positive or net negative I mean you could you could I mean I", "tokens": [51272, 390, 264, 22265, 295, 14837, 2533, 3353, 420, 2533, 3671, 286, 914, 291, 727, 291, 727, 286, 914, 286, 51528], "temperature": 0.0, "avg_logprob": -0.10185002057980268, "compression_ratio": 1.905511811023622, "no_speech_prob": 0.3995293378829956}, {"id": 642, "seek": 391240, "start": 3935.6800000000003, "end": 3941.76, "text": " say it was not positive but but the point is if I can just finish the quick like thought experiment", "tokens": [51528, 584, 309, 390, 406, 3353, 457, 457, 264, 935, 307, 498, 286, 393, 445, 2413, 264, 1702, 411, 1194, 5120, 51832], "temperature": 0.0, "avg_logprob": -0.10185002057980268, "compression_ratio": 1.905511811023622, "no_speech_prob": 0.3995293378829956}, {"id": 643, "seek": 394176, "start": 3941.76, "end": 3948.0, "text": " or whatever I don't think anybody can reasonably answer that right we we don't yet know all of the", "tokens": [50364, 420, 2035, 286, 500, 380, 519, 4472, 393, 23551, 1867, 300, 558, 321, 321, 500, 380, 1939, 458, 439, 295, 264, 50676], "temperature": 0.0, "avg_logprob": -0.05197162547353971, "compression_ratio": 1.8544061302681993, "no_speech_prob": 0.002589305629953742}, {"id": 644, "seek": 394176, "start": 3948.0, "end": 3952.88, "text": " ways in which GPT-4 will be used for good we don't know all of the ways in which bad actors will", "tokens": [50676, 2098, 294, 597, 26039, 51, 12, 19, 486, 312, 1143, 337, 665, 321, 500, 380, 458, 439, 295, 264, 2098, 294, 597, 1578, 10037, 486, 50920], "temperature": 0.0, "avg_logprob": -0.05197162547353971, "compression_ratio": 1.8544061302681993, "no_speech_prob": 0.002589305629953742}, {"id": 645, "seek": 394176, "start": 3952.88, "end": 3957.6800000000003, "text": " use it we don't know all the consequences that's going to be true for each iteration it's probably", "tokens": [50920, 764, 309, 321, 500, 380, 458, 439, 264, 10098, 300, 311, 516, 281, 312, 2074, 337, 1184, 24784, 309, 311, 1391, 51160], "temperature": 0.0, "avg_logprob": -0.05197162547353971, "compression_ratio": 1.8544061302681993, "no_speech_prob": 0.002589305629953742}, {"id": 646, "seek": 394176, "start": 3957.6800000000003, "end": 3964.5600000000004, "text": " going to get harder to compute for each iteration and we can't even do it now and I think that", "tokens": [51160, 516, 281, 483, 6081, 281, 14722, 337, 1184, 24784, 293, 321, 393, 380, 754, 360, 309, 586, 293, 286, 519, 300, 51504], "temperature": 0.0, "avg_logprob": -0.05197162547353971, "compression_ratio": 1.8544061302681993, "no_speech_prob": 0.002589305629953742}, {"id": 647, "seek": 394176, "start": 3964.5600000000004, "end": 3970.8, "text": " we should realize that to realize our own limits in being able to assess the the negatives and", "tokens": [51504, 321, 820, 4325, 300, 281, 4325, 527, 1065, 10406, 294, 885, 1075, 281, 5877, 264, 264, 40019, 293, 51816], "temperature": 0.0, "avg_logprob": -0.05197162547353971, "compression_ratio": 1.8544061302681993, "no_speech_prob": 0.002589305629953742}, {"id": 648, "seek": 397080, "start": 3970.8, "end": 3976.48, "text": " positives maybe that we can think about better ways to do that than we currently have but I think", "tokens": [50364, 35127, 1310, 300, 321, 393, 519, 466, 1101, 2098, 281, 360, 300, 813, 321, 4362, 362, 457, 286, 519, 50648], "temperature": 0.0, "avg_logprob": -0.0726142218618682, "compression_ratio": 1.6824034334763949, "no_speech_prob": 0.0026307629887014627}, {"id": 649, "seek": 397080, "start": 3976.48, "end": 3982.0800000000004, "text": " you've got to have a guess like like my guess is that so far not looking into the future at all", "tokens": [50648, 291, 600, 658, 281, 362, 257, 2041, 411, 411, 452, 2041, 307, 300, 370, 1400, 406, 1237, 666, 264, 2027, 412, 439, 50928], "temperature": 0.0, "avg_logprob": -0.0726142218618682, "compression_ratio": 1.6824034334763949, "no_speech_prob": 0.0026307629887014627}, {"id": 650, "seek": 397080, "start": 3982.0800000000004, "end": 3989.84, "text": " GPT-4 has been net positive I mean maybe I haven't talked about the the various risks yet and it's", "tokens": [50928, 26039, 51, 12, 19, 575, 668, 2533, 3353, 286, 914, 1310, 286, 2378, 380, 2825, 466, 264, 264, 3683, 10888, 1939, 293, 309, 311, 51316], "temperature": 0.0, "avg_logprob": -0.0726142218618682, "compression_ratio": 1.6824034334763949, "no_speech_prob": 0.0026307629887014627}, {"id": 651, "seek": 397080, "start": 3989.84, "end": 3995.76, "text": " still early but I mean that's just a guess is kind of the point like we don't have a way of putting", "tokens": [51316, 920, 2440, 457, 286, 914, 300, 311, 445, 257, 2041, 307, 733, 295, 264, 935, 411, 321, 500, 380, 362, 257, 636, 295, 3372, 51612], "temperature": 0.0, "avg_logprob": -0.0726142218618682, "compression_ratio": 1.6824034334763949, "no_speech_prob": 0.0026307629887014627}, {"id": 652, "seek": 399576, "start": 3995.76, "end": 4001.0400000000004, "text": " it on a spreadsheet right now or whatever like we don't really have a good way to quantify it but I", "tokens": [50364, 309, 322, 257, 27733, 558, 586, 420, 2035, 411, 321, 500, 380, 534, 362, 257, 665, 636, 281, 40421, 309, 457, 286, 50628], "temperature": 0.0, "avg_logprob": -0.0904081662495931, "compression_ratio": 1.6677966101694914, "no_speech_prob": 0.2939586043357849}, {"id": 653, "seek": 399576, "start": 4001.0400000000004, "end": 4005.6800000000003, "text": " mean do we ever but it's not out of control yet so so by and large people are going to be using", "tokens": [50628, 914, 360, 321, 1562, 457, 309, 311, 406, 484, 295, 1969, 1939, 370, 370, 538, 293, 2416, 561, 366, 516, 281, 312, 1228, 50860], "temperature": 0.0, "avg_logprob": -0.0904081662495931, "compression_ratio": 1.6677966101694914, "no_speech_prob": 0.2939586043357849}, {"id": 654, "seek": 399576, "start": 4005.6800000000003, "end": 4011.36, "text": " GPT-4 to use things to do things that they want and the relative cases where they manage to injure", "tokens": [50860, 26039, 51, 12, 19, 281, 764, 721, 281, 360, 721, 300, 436, 528, 293, 264, 4972, 3331, 689, 436, 3067, 281, 5580, 540, 51144], "temperature": 0.0, "avg_logprob": -0.0904081662495931, "compression_ratio": 1.6677966101694914, "no_speech_prob": 0.2939586043357849}, {"id": 655, "seek": 399576, "start": 4011.36, "end": 4017.2000000000003, "text": " themselves are rare enough to be news on Twitter well for example I mean we haven't talked about it but", "tokens": [51144, 2969, 366, 5892, 1547, 281, 312, 2583, 322, 5794, 731, 337, 1365, 286, 914, 321, 2378, 380, 2825, 466, 309, 457, 51436], "temperature": 0.0, "avg_logprob": -0.0904081662495931, "compression_ratio": 1.6677966101694914, "no_speech_prob": 0.2939586043357849}, {"id": 656, "seek": 399576, "start": 4017.2000000000003, "end": 4022.8, "text": " you know what bad actors some bad actors will want to do is to influence the US elections and", "tokens": [51436, 291, 458, 437, 1578, 10037, 512, 1578, 10037, 486, 528, 281, 360, 307, 281, 6503, 264, 2546, 12870, 293, 51716], "temperature": 0.0, "avg_logprob": -0.0904081662495931, "compression_ratio": 1.6677966101694914, "no_speech_prob": 0.2939586043357849}, {"id": 657, "seek": 402280, "start": 4022.8, "end": 4027.1200000000003, "text": " try to undermine democracy in the US and if they succeed in that I think there's pretty serious", "tokens": [50364, 853, 281, 39257, 10528, 294, 264, 2546, 293, 498, 436, 7754, 294, 300, 286, 519, 456, 311, 1238, 3156, 50580], "temperature": 0.0, "avg_logprob": -0.08750348238600898, "compression_ratio": 1.6322314049586777, "no_speech_prob": 0.02477751299738884}, {"id": 658, "seek": 402280, "start": 4027.1200000000003, "end": 4035.44, "text": " long-term consequences there well I think it's open AI's responsibility to step up and run the 2024", "tokens": [50580, 938, 12, 7039, 10098, 456, 731, 286, 519, 309, 311, 1269, 7318, 311, 6357, 281, 1823, 493, 293, 1190, 264, 45237, 50996], "temperature": 0.0, "avg_logprob": -0.08750348238600898, "compression_ratio": 1.6322314049586777, "no_speech_prob": 0.02477751299738884}, {"id": 659, "seek": 402280, "start": 4035.44, "end": 4043.1200000000003, "text": " election itself I will I can pass that along is that a joke no I mean I mean as far as I can say", "tokens": [50996, 6618, 2564, 286, 486, 286, 393, 1320, 300, 2051, 307, 300, 257, 7647, 572, 286, 914, 286, 914, 382, 1400, 382, 286, 393, 584, 51380], "temperature": 0.0, "avg_logprob": -0.08750348238600898, "compression_ratio": 1.6322314049586777, "no_speech_prob": 0.02477751299738884}, {"id": 660, "seek": 402280, "start": 4043.1200000000003, "end": 4051.1200000000003, "text": " you know the the clearest concrete harm to have come from GPT so far is that you know tens of millions", "tokens": [51380, 291, 458, 264, 264, 1233, 17363, 9859, 6491, 281, 362, 808, 490, 26039, 51, 370, 1400, 307, 300, 291, 458, 10688, 295, 6803, 51780], "temperature": 0.0, "avg_logprob": -0.08750348238600898, "compression_ratio": 1.6322314049586777, "no_speech_prob": 0.02477751299738884}, {"id": 661, "seek": 405112, "start": 4051.2, "end": 4056.3199999999997, "text": " of students have now used it to cheat on their assignments and I have been thinking about that", "tokens": [50368, 295, 1731, 362, 586, 1143, 309, 281, 17470, 322, 641, 22546, 293, 286, 362, 668, 1953, 466, 300, 50624], "temperature": 0.0, "avg_logprob": -0.06379107843365586, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.08742440491914749}, {"id": 662, "seek": 405112, "start": 4056.3199999999997, "end": 4061.04, "text": " and I have been trying to come up with solutions to that at the same time I think if you do the", "tokens": [50624, 293, 286, 362, 668, 1382, 281, 808, 493, 365, 6547, 281, 300, 412, 264, 912, 565, 286, 519, 498, 291, 360, 264, 50860], "temperature": 0.0, "avg_logprob": -0.06379107843365586, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.08742440491914749}, {"id": 663, "seek": 405112, "start": 4061.04, "end": 4067.3599999999997, "text": " positive utility has included I mean you know I I'm a theoretical computer scientist which means", "tokens": [50860, 3353, 14877, 575, 5556, 286, 914, 291, 458, 286, 286, 478, 257, 20864, 3820, 12662, 597, 1355, 51176], "temperature": 0.0, "avg_logprob": -0.06379107843365586, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.08742440491914749}, {"id": 664, "seek": 405112, "start": 4067.3599999999997, "end": 4074.4, "text": " you know one who hasn't written any serious code for about 20 years and you know realized just a", "tokens": [51176, 291, 458, 472, 567, 6132, 380, 3720, 604, 3156, 3089, 337, 466, 945, 924, 293, 291, 458, 5334, 445, 257, 51528], "temperature": 0.0, "avg_logprob": -0.06379107843365586, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.08742440491914749}, {"id": 665, "seek": 405112, "start": 4074.4, "end": 4080.08, "text": " month or two ago I can get back into coding and the way I can do it is I just asked GPT to write", "tokens": [51528, 1618, 420, 732, 2057, 286, 393, 483, 646, 666, 17720, 293, 264, 636, 286, 393, 360, 309, 307, 286, 445, 2351, 26039, 51, 281, 2464, 51812], "temperature": 0.0, "avg_logprob": -0.06379107843365586, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.08742440491914749}, {"id": 666, "seek": 408008, "start": 4080.08, "end": 4086.72, "text": " the code for me and you know I wasn't expecting it to work that well and unbelievably it you know", "tokens": [50364, 264, 3089, 337, 385, 293, 291, 458, 286, 2067, 380, 9650, 309, 281, 589, 300, 731, 293, 43593, 309, 291, 458, 50696], "temperature": 0.0, "avg_logprob": -0.061288194341973946, "compression_ratio": 1.8009259259259258, "no_speech_prob": 0.006175988353788853}, {"id": 667, "seek": 408008, "start": 4086.72, "end": 4093.2799999999997, "text": " often just does exactly what I want on the first try so I mean you know I you know I am getting", "tokens": [50696, 2049, 445, 775, 2293, 437, 286, 528, 322, 264, 700, 853, 370, 286, 914, 291, 458, 286, 291, 458, 286, 669, 1242, 51024], "temperature": 0.0, "avg_logprob": -0.061288194341973946, "compression_ratio": 1.8009259259259258, "no_speech_prob": 0.006175988353788853}, {"id": 668, "seek": 408008, "start": 4093.2799999999997, "end": 4103.36, "text": " utility from it rather than just you know seeing it as an interesting research object and you know", "tokens": [51024, 14877, 490, 309, 2831, 813, 445, 291, 458, 2577, 309, 382, 364, 1880, 2132, 2657, 293, 291, 458, 51528], "temperature": 0.0, "avg_logprob": -0.061288194341973946, "compression_ratio": 1.8009259259259258, "no_speech_prob": 0.006175988353788853}, {"id": 669, "seek": 408008, "start": 4103.36, "end": 4108.96, "text": " and and you know I can imagine that that hundreds of millions of people are going to be deriving", "tokens": [51528, 293, 293, 291, 458, 286, 393, 3811, 300, 300, 6779, 295, 6803, 295, 561, 366, 516, 281, 312, 1163, 2123, 51808], "temperature": 0.0, "avg_logprob": -0.061288194341973946, "compression_ratio": 1.8009259259259258, "no_speech_prob": 0.006175988353788853}, {"id": 670, "seek": 410896, "start": 4109.04, "end": 4113.44, "text": " utility from it in those ways I mean like most of the tools to help them derive that", "tokens": [50368, 14877, 490, 309, 294, 729, 2098, 286, 914, 411, 881, 295, 264, 3873, 281, 854, 552, 28446, 300, 50588], "temperature": 0.0, "avg_logprob": -0.060946375131607056, "compression_ratio": 1.7722007722007722, "no_speech_prob": 0.0024715932086110115}, {"id": 671, "seek": 410896, "start": 4113.44, "end": 4118.08, "text": " utility are not even out yet but they're they're coming in the next couple of years", "tokens": [50588, 14877, 366, 406, 754, 484, 1939, 457, 436, 434, 436, 434, 1348, 294, 264, 958, 1916, 295, 924, 50820], "temperature": 0.0, "avg_logprob": -0.060946375131607056, "compression_ratio": 1.7722007722007722, "no_speech_prob": 0.0024715932086110115}, {"id": 672, "seek": 410896, "start": 4119.92, "end": 4124.24, "text": " I mean part of the reason why I'm worried about the focus on short-term problems is that I suspect", "tokens": [50912, 286, 914, 644, 295, 264, 1778, 983, 286, 478, 5804, 466, 264, 1879, 322, 2099, 12, 7039, 2740, 307, 300, 286, 9091, 51128], "temperature": 0.0, "avg_logprob": -0.060946375131607056, "compression_ratio": 1.7722007722007722, "no_speech_prob": 0.0024715932086110115}, {"id": 673, "seek": 410896, "start": 4124.24, "end": 4128.64, "text": " that the short-term problems might very well be solvable and we'll be left with the long-term", "tokens": [51128, 300, 264, 2099, 12, 7039, 2740, 1062, 588, 731, 312, 1404, 17915, 293, 321, 603, 312, 1411, 365, 264, 938, 12, 7039, 51348], "temperature": 0.0, "avg_logprob": -0.060946375131607056, "compression_ratio": 1.7722007722007722, "no_speech_prob": 0.0024715932086110115}, {"id": 674, "seek": 410896, "start": 4128.64, "end": 4135.28, "text": " problems after that maybe we can solve the like it wouldn't surprise me very much if like in 2025", "tokens": [51348, 2740, 934, 300, 1310, 321, 393, 5039, 264, 411, 309, 2759, 380, 6365, 385, 588, 709, 498, 411, 294, 39209, 51680], "temperature": 0.0, "avg_logprob": -0.060946375131607056, "compression_ratio": 1.7722007722007722, "no_speech_prob": 0.0024715932086110115}, {"id": 675, "seek": 413528, "start": 4135.84, "end": 4141.44, "text": " the well you know like the large language there are large language models that just don't make", "tokens": [50392, 264, 731, 291, 458, 411, 264, 2416, 2856, 456, 366, 2416, 2856, 5245, 300, 445, 500, 380, 652, 50672], "temperature": 0.0, "avg_logprob": -0.13405306746320025, "compression_ratio": 1.7677725118483412, "no_speech_prob": 0.0028442542534321547}, {"id": 676, "seek": 413528, "start": 4141.44, "end": 4149.36, "text": " stuff up anymore it would surprise and yet even yet you know and yet the superintelligence still", "tokens": [50672, 1507, 493, 3602, 309, 576, 6365, 293, 1939, 754, 1939, 291, 458, 293, 1939, 264, 1687, 20761, 17644, 920, 51068], "temperature": 0.0, "avg_logprob": -0.13405306746320025, "compression_ratio": 1.7677725118483412, "no_speech_prob": 0.0028442542534321547}, {"id": 677, "seek": 413528, "start": 4149.36, "end": 4154.16, "text": " kills everyone because they weren't the same problem well you know you know we just need to", "tokens": [51068, 14563, 1518, 570, 436, 4999, 380, 264, 912, 1154, 731, 291, 458, 291, 458, 321, 445, 643, 281, 51308], "temperature": 0.0, "avg_logprob": -0.13405306746320025, "compression_ratio": 1.7677725118483412, "no_speech_prob": 0.0028442542534321547}, {"id": 678, "seek": 413528, "start": 4154.16, "end": 4160.88, "text": " figure out how to delay the apocalypse by at least one year per year of research invested", "tokens": [51308, 2573, 484, 577, 281, 8577, 264, 42600, 538, 412, 1935, 472, 1064, 680, 1064, 295, 2132, 13104, 51644], "temperature": 0.0, "avg_logprob": -0.13405306746320025, "compression_ratio": 1.7677725118483412, "no_speech_prob": 0.0028442542534321547}, {"id": 679, "seek": 416088, "start": 4161.12, "end": 4168.88, "text": " what what does that delay look like if it's not just a moratorium well I don't know that's why it's", "tokens": [50376, 437, 437, 775, 300, 8577, 574, 411, 498, 309, 311, 406, 445, 257, 1896, 41679, 731, 286, 500, 380, 458, 300, 311, 983, 309, 311, 50764], "temperature": 0.0, "avg_logprob": -0.10508394241333008, "compression_ratio": 1.670940170940171, "no_speech_prob": 0.007344438694417477}, {"id": 680, "seek": 416088, "start": 4168.88, "end": 4176.64, "text": " research okay so but but possibly one ought to say to the politicians in the public and by the way", "tokens": [50764, 2132, 1392, 370, 457, 457, 6264, 472, 13416, 281, 584, 281, 264, 14756, 294, 264, 1908, 293, 538, 264, 636, 51152], "temperature": 0.0, "avg_logprob": -0.10508394241333008, "compression_ratio": 1.670940170940171, "no_speech_prob": 0.007344438694417477}, {"id": 681, "seek": 416088, "start": 4176.64, "end": 4180.08, "text": " if we had a superintelligence tomorrow our research wouldn't be finished and everybody would drop", "tokens": [51152, 498, 321, 632, 257, 1687, 20761, 17644, 4153, 527, 2132, 2759, 380, 312, 4335, 293, 2201, 576, 3270, 51324], "temperature": 0.0, "avg_logprob": -0.10508394241333008, "compression_ratio": 1.670940170940171, "no_speech_prob": 0.007344438694417477}, {"id": 682, "seek": 416088, "start": 4180.08, "end": 4186.32, "text": " dead you know it's kind of ironic the biggest argument against the pause letter was that if we", "tokens": [51324, 3116, 291, 458, 309, 311, 733, 295, 33719, 264, 3880, 6770, 1970, 264, 10465, 5063, 390, 300, 498, 321, 51636], "temperature": 0.0, "avg_logprob": -0.10508394241333008, "compression_ratio": 1.670940170940171, "no_speech_prob": 0.007344438694417477}, {"id": 683, "seek": 418632, "start": 4186.32, "end": 4193.36, "text": " slow down for six months then China will get ahead of us and get GPT-5 before we will but there's", "tokens": [50364, 2964, 760, 337, 2309, 2493, 550, 3533, 486, 483, 2286, 295, 505, 293, 483, 26039, 51, 12, 20, 949, 321, 486, 457, 456, 311, 50716], "temperature": 0.0, "avg_logprob": -0.07167767418755425, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.021598810330033302}, {"id": 684, "seek": 418632, "start": 4193.36, "end": 4199.679999999999, "text": " probably always a counter argument of maybe roughly equal strength which is if we move six months", "tokens": [50716, 1391, 1009, 257, 5682, 6770, 295, 1310, 9810, 2681, 3800, 597, 307, 498, 321, 1286, 2309, 2493, 51032], "temperature": 0.0, "avg_logprob": -0.07167767418755425, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.021598810330033302}, {"id": 685, "seek": 418632, "start": 4199.679999999999, "end": 4205.599999999999, "text": " faster on this technology which is not really solving the alignment problem then we're reducing", "tokens": [51032, 4663, 322, 341, 2899, 597, 307, 406, 534, 12606, 264, 18515, 1154, 550, 321, 434, 12245, 51328], "temperature": 0.0, "avg_logprob": -0.07167767418755425, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.021598810330033302}, {"id": 686, "seek": 418632, "start": 4205.599999999999, "end": 4213.28, "text": " our room to get this solved in time by six months I mean I don't think you're going to solve the", "tokens": [51328, 527, 1808, 281, 483, 341, 13041, 294, 565, 538, 2309, 2493, 286, 914, 286, 500, 380, 519, 291, 434, 516, 281, 5039, 264, 51712], "temperature": 0.0, "avg_logprob": -0.07167767418755425, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.021598810330033302}, {"id": 687, "seek": 421328, "start": 4213.28, "end": 4218.5599999999995, "text": " alignment problem in time I think that six months of delay on alignment while a bad thing in an", "tokens": [50364, 18515, 1154, 294, 565, 286, 519, 300, 2309, 2493, 295, 8577, 322, 18515, 1339, 257, 1578, 551, 294, 364, 50628], "temperature": 0.0, "avg_logprob": -0.0578612437290428, "compression_ratio": 1.8160919540229885, "no_speech_prob": 0.0047532073222100735}, {"id": 688, "seek": 421328, "start": 4218.5599999999995, "end": 4225.36, "text": " absolute sense is you know like you know you weren't going to solve it with given an extra six months", "tokens": [50628, 8236, 2020, 307, 291, 458, 411, 291, 458, 291, 4999, 380, 516, 281, 5039, 309, 365, 2212, 364, 2857, 2309, 2493, 50968], "temperature": 0.0, "avg_logprob": -0.0578612437290428, "compression_ratio": 1.8160919540229885, "no_speech_prob": 0.0047532073222100735}, {"id": 689, "seek": 421328, "start": 4225.36, "end": 4230.48, "text": " I mean your whole argument rests on timing right that that we will get to this point", "tokens": [50968, 286, 914, 428, 1379, 6770, 39755, 322, 10822, 558, 300, 300, 321, 486, 483, 281, 341, 935, 51224], "temperature": 0.0, "avg_logprob": -0.0578612437290428, "compression_ratio": 1.8160919540229885, "no_speech_prob": 0.0047532073222100735}, {"id": 690, "seek": 421328, "start": 4231.28, "end": 4236.32, "text": " and we won't be able to move fast enough at that point and so you know a lot depends on what", "tokens": [51264, 293, 321, 1582, 380, 312, 1075, 281, 1286, 2370, 1547, 412, 300, 935, 293, 370, 291, 458, 257, 688, 5946, 322, 437, 51516], "temperature": 0.0, "avg_logprob": -0.0578612437290428, "compression_ratio": 1.8160919540229885, "no_speech_prob": 0.0047532073222100735}, {"id": 691, "seek": 421328, "start": 4236.32, "end": 4241.679999999999, "text": " preparation we can do you know I'm often known as a pessimist but I'm a little bit more optimistic", "tokens": [51516, 13081, 321, 393, 360, 291, 458, 286, 478, 2049, 2570, 382, 257, 37399, 468, 457, 286, 478, 257, 707, 857, 544, 19397, 51784], "temperature": 0.0, "avg_logprob": -0.0578612437290428, "compression_ratio": 1.8160919540229885, "no_speech_prob": 0.0047532073222100735}, {"id": 692, "seek": 424168, "start": 4241.68, "end": 4246.88, "text": " than you are not entirely optimistic but a little bit more optimistic than you are that we could make", "tokens": [50364, 813, 291, 366, 406, 7696, 19397, 457, 257, 707, 857, 544, 19397, 813, 291, 366, 300, 321, 727, 652, 50624], "temperature": 0.0, "avg_logprob": -0.1044246062491704, "compression_ratio": 1.943089430894309, "no_speech_prob": 0.017159216105937958}, {"id": 693, "seek": 424168, "start": 4246.88, "end": 4252.4800000000005, "text": " progress on the alignment problem if we prioritized it and you can absolutely make progress", "tokens": [50624, 4205, 322, 264, 18515, 1154, 498, 321, 14846, 1602, 309, 293, 291, 393, 3122, 652, 4205, 50904], "temperature": 0.0, "avg_logprob": -0.1044246062491704, "compression_ratio": 1.943089430894309, "no_speech_prob": 0.017159216105937958}, {"id": 694, "seek": 424168, "start": 4253.68, "end": 4257.92, "text": " because we can absolutely make progress you know there's there's always the you know that the", "tokens": [50964, 570, 321, 393, 3122, 652, 4205, 291, 458, 456, 311, 456, 311, 1009, 264, 291, 458, 300, 264, 51176], "temperature": 0.0, "avg_logprob": -0.1044246062491704, "compression_ratio": 1.943089430894309, "no_speech_prob": 0.017159216105937958}, {"id": 695, "seek": 424168, "start": 4257.92, "end": 4264.320000000001, "text": " wonderful sense of accomplishment is piece by piece you decode you know like one more little fact", "tokens": [51176, 3715, 2020, 295, 29144, 307, 2522, 538, 2522, 291, 979, 1429, 291, 458, 411, 472, 544, 707, 1186, 51496], "temperature": 0.0, "avg_logprob": -0.1044246062491704, "compression_ratio": 1.943089430894309, "no_speech_prob": 0.017159216105937958}, {"id": 696, "seek": 424168, "start": 4264.320000000001, "end": 4268.320000000001, "text": " about LLMs you never get to the point where you understand that as well as we understood the", "tokens": [51496, 466, 441, 43, 26386, 291, 1128, 483, 281, 264, 935, 689, 291, 1223, 300, 382, 731, 382, 321, 7320, 264, 51696], "temperature": 0.0, "avg_logprob": -0.1044246062491704, "compression_ratio": 1.943089430894309, "no_speech_prob": 0.017159216105937958}, {"id": 697, "seek": 426832, "start": 4268.32, "end": 4273.2, "text": " interior of a chess playing program in 1997 yeah I mean I think we should stop spending all this", "tokens": [50364, 10636, 295, 257, 24122, 2433, 1461, 294, 22383, 1338, 286, 914, 286, 519, 321, 820, 1590, 6434, 439, 341, 50608], "temperature": 0.0, "avg_logprob": -0.10147864759460953, "compression_ratio": 1.8863636363636365, "no_speech_prob": 0.03512293100357056}, {"id": 698, "seek": 426832, "start": 4273.2, "end": 4278.96, "text": " time on LLMs I don't think the answer to alignment is going to come from LLM through LLMs I really", "tokens": [50608, 565, 322, 441, 43, 26386, 286, 500, 380, 519, 264, 1867, 281, 18515, 307, 516, 281, 808, 490, 441, 43, 44, 807, 441, 43, 26386, 286, 534, 50896], "temperature": 0.0, "avg_logprob": -0.10147864759460953, "compression_ratio": 1.8863636363636365, "no_speech_prob": 0.03512293100357056}, {"id": 699, "seek": 426832, "start": 4278.96, "end": 4284.5599999999995, "text": " don't I think they're they're too much of a black box you can't put explicit symbolic constraints in", "tokens": [50896, 500, 380, 286, 519, 436, 434, 436, 434, 886, 709, 295, 257, 2211, 2424, 291, 393, 380, 829, 13691, 25755, 18491, 294, 51176], "temperature": 0.0, "avg_logprob": -0.10147864759460953, "compression_ratio": 1.8863636363636365, "no_speech_prob": 0.03512293100357056}, {"id": 700, "seek": 426832, "start": 4284.5599999999995, "end": 4289.2, "text": " the way that you need to I think they're actually with respect to alignment to blind alley I think", "tokens": [51176, 264, 636, 300, 291, 643, 281, 286, 519, 436, 434, 767, 365, 3104, 281, 18515, 281, 6865, 26660, 286, 519, 51408], "temperature": 0.0, "avg_logprob": -0.10147864759460953, "compression_ratio": 1.8863636363636365, "no_speech_prob": 0.03512293100357056}, {"id": 701, "seek": 426832, "start": 4289.2, "end": 4294.24, "text": " with respect to writing code they're a great tool but with alignment I don't think the answer is there", "tokens": [51408, 365, 3104, 281, 3579, 3089, 436, 434, 257, 869, 2290, 457, 365, 18515, 286, 500, 380, 519, 264, 1867, 307, 456, 51660], "temperature": 0.0, "avg_logprob": -0.10147864759460953, "compression_ratio": 1.8863636363636365, "no_speech_prob": 0.03512293100357056}, {"id": 702, "seek": 429424, "start": 4295.2, "end": 4304.639999999999, "text": " so at the risk of asking a stupid question every time GPT asks me if that answer was helpful", "tokens": [50412, 370, 412, 264, 3148, 295, 3365, 257, 6631, 1168, 633, 565, 26039, 51, 8962, 385, 498, 300, 1867, 390, 4961, 50884], "temperature": 0.0, "avg_logprob": -0.09730392297108968, "compression_ratio": 1.5202312138728324, "no_speech_prob": 0.026345666497945786}, {"id": 703, "seek": 429424, "start": 4305.28, "end": 4311.04, "text": " and then does the same thing with thousands or hundreds of thousands of other people and", "tokens": [50916, 293, 550, 775, 264, 912, 551, 365, 5383, 420, 6779, 295, 5383, 295, 661, 561, 293, 51204], "temperature": 0.0, "avg_logprob": -0.09730392297108968, "compression_ratio": 1.5202312138728324, "no_speech_prob": 0.026345666497945786}, {"id": 704, "seek": 429424, "start": 4311.92, "end": 4321.04, "text": " and changes as a result is that not a decentralized way of making it more aligned", "tokens": [51248, 293, 2962, 382, 257, 1874, 307, 300, 406, 257, 32870, 636, 295, 1455, 309, 544, 17962, 51704], "temperature": 0.0, "avg_logprob": -0.09730392297108968, "compression_ratio": 1.5202312138728324, "no_speech_prob": 0.026345666497945786}, {"id": 705, "seek": 432104, "start": 4321.04, "end": 4337.36, "text": " yeah well yeah so so so there is that upvoting and downvoting you know that that gets", "tokens": [50364, 1338, 731, 1338, 370, 370, 370, 456, 307, 300, 493, 85, 17001, 293, 760, 85, 17001, 291, 458, 300, 300, 2170, 51180], "temperature": 0.0, "avg_logprob": -0.2338255500793457, "compression_ratio": 1.5166666666666666, "no_speech_prob": 0.07364391535520554}, {"id": 706, "seek": 432104, "start": 4338.0, "end": 4344.32, "text": " fed back in into sort of fine-tuning it but even before that there was you know a major step you", "tokens": [51212, 4636, 646, 294, 666, 1333, 295, 2489, 12, 83, 37726, 309, 457, 754, 949, 300, 456, 390, 291, 458, 257, 2563, 1823, 291, 51528], "temperature": 0.0, "avg_logprob": -0.2338255500793457, "compression_ratio": 1.5166666666666666, "no_speech_prob": 0.07364391535520554}, {"id": 707, "seek": 434432, "start": 4344.32, "end": 4352.08, "text": " know in going from let's say the the base GPT 3 model for example to the chat GPT you know that", "tokens": [50364, 458, 294, 516, 490, 718, 311, 584, 264, 264, 3096, 26039, 51, 805, 2316, 337, 1365, 281, 264, 5081, 26039, 51, 291, 458, 300, 50752], "temperature": 0.0, "avg_logprob": -0.08954256231134589, "compression_ratio": 1.5376344086021505, "no_speech_prob": 0.08998635411262512}, {"id": 708, "seek": 434432, "start": 4352.08, "end": 4358.96, "text": " was released to the public and that was called a RLHF reinforcement learning with human feedback", "tokens": [50752, 390, 4736, 281, 264, 1908, 293, 300, 390, 1219, 257, 497, 43, 39, 37, 29280, 2539, 365, 1952, 5824, 51096], "temperature": 0.0, "avg_logprob": -0.08954256231134589, "compression_ratio": 1.5376344086021505, "no_speech_prob": 0.08998635411262512}, {"id": 709, "seek": 434432, "start": 4358.96, "end": 4365.44, "text": " and what that basically involved was you know several hundred contractors you know looking at", "tokens": [51096, 293, 437, 300, 1936, 3288, 390, 291, 458, 2940, 3262, 28377, 291, 458, 1237, 412, 51420], "temperature": 0.0, "avg_logprob": -0.08954256231134589, "compression_ratio": 1.5376344086021505, "no_speech_prob": 0.08998635411262512}, {"id": 710, "seek": 436544, "start": 4365.5199999999995, "end": 4373.759999999999, "text": " just just ten tens of thousands of examples of outputs and and and rating them you know are they", "tokens": [50368, 445, 445, 2064, 10688, 295, 5383, 295, 5110, 295, 23930, 293, 293, 293, 10990, 552, 291, 458, 366, 436, 50780], "temperature": 0.0, "avg_logprob": -0.11602783972217191, "compression_ratio": 1.9205298013245033, "no_speech_prob": 0.1518120914697647}, {"id": 711, "seek": 436544, "start": 4373.759999999999, "end": 4381.599999999999, "text": " helpful are they offensive you know are they you know are are they you know giving dangerous", "tokens": [50780, 4961, 366, 436, 15710, 291, 458, 366, 436, 291, 458, 366, 366, 436, 291, 458, 2902, 5795, 51172], "temperature": 0.0, "avg_logprob": -0.11602783972217191, "compression_ratio": 1.9205298013245033, "no_speech_prob": 0.1518120914697647}, {"id": 712, "seek": 436544, "start": 4381.599999999999, "end": 4391.2, "text": " medical advice or you know bomb making instructions you know or racist invective or you know various", "tokens": [51172, 4625, 5192, 420, 291, 458, 7851, 1455, 9415, 291, 458, 420, 16419, 32957, 20221, 420, 291, 458, 3683, 51652], "temperature": 0.0, "avg_logprob": -0.11602783972217191, "compression_ratio": 1.9205298013245033, "no_speech_prob": 0.1518120914697647}, {"id": 713, "seek": 439120, "start": 4391.2, "end": 4397.76, "text": " other categories that that we don't want and and that that was then used to fine-tune the model so", "tokens": [50364, 661, 10479, 300, 300, 321, 500, 380, 528, 293, 293, 300, 300, 390, 550, 1143, 281, 2489, 12, 83, 2613, 264, 2316, 370, 50692], "temperature": 0.0, "avg_logprob": -0.0770692039322067, "compression_ratio": 1.7579908675799087, "no_speech_prob": 0.031105730682611465}, {"id": 714, "seek": 439120, "start": 4397.76, "end": 4405.679999999999, "text": " when you know Gary talked before about how GPT is amoral you know I think that that has to be", "tokens": [50692, 562, 291, 458, 13788, 2825, 949, 466, 577, 26039, 51, 307, 15543, 304, 291, 458, 286, 519, 300, 300, 575, 281, 312, 51088], "temperature": 0.0, "avg_logprob": -0.0770692039322067, "compression_ratio": 1.7579908675799087, "no_speech_prob": 0.031105730682611465}, {"id": 715, "seek": 439120, "start": 4405.679999999999, "end": 4411.44, "text": " qualified by saying that you know these this reinforcement learning is at least giving it you", "tokens": [51088, 15904, 538, 1566, 300, 291, 458, 613, 341, 29280, 2539, 307, 412, 1935, 2902, 309, 291, 51376], "temperature": 0.0, "avg_logprob": -0.0770692039322067, "compression_ratio": 1.7579908675799087, "no_speech_prob": 0.031105730682611465}, {"id": 716, "seek": 439120, "start": 4411.44, "end": 4419.44, "text": " know a semblance of morality right it is causing it to sort of behave you know in various contexts", "tokens": [51376, 458, 257, 20775, 37271, 295, 29106, 558, 309, 307, 9853, 309, 281, 1333, 295, 15158, 291, 458, 294, 3683, 30628, 51776], "temperature": 0.0, "avg_logprob": -0.0770692039322067, "compression_ratio": 1.7579908675799087, "no_speech_prob": 0.031105730682611465}, {"id": 717, "seek": 441944, "start": 4419.44, "end": 4426.48, "text": " as if it had you know a certain morality I mean when you phrase it that way I'm okay with it the", "tokens": [50364, 382, 498, 309, 632, 291, 458, 257, 1629, 29106, 286, 914, 562, 291, 9535, 309, 300, 636, 286, 478, 1392, 365, 309, 264, 50716], "temperature": 0.0, "avg_logprob": -0.10394702710603412, "compression_ratio": 1.7488584474885844, "no_speech_prob": 0.010482405312359333}, {"id": 718, "seek": 441944, "start": 4426.48, "end": 4432.32, "text": " problem is you know everything rests on the I would say it is it is very much an open question", "tokens": [50716, 1154, 307, 291, 458, 1203, 39755, 322, 264, 286, 576, 584, 309, 307, 309, 307, 588, 709, 364, 1269, 1168, 51008], "temperature": 0.0, "avg_logprob": -0.10394702710603412, "compression_ratio": 1.7488584474885844, "no_speech_prob": 0.010482405312359333}, {"id": 719, "seek": 441944, "start": 4432.32, "end": 4437.28, "text": " you know how much that you know to what extent does that generalize you know eliezer treats it as", "tokens": [51008, 291, 458, 577, 709, 300, 291, 458, 281, 437, 8396, 775, 300, 2674, 1125, 291, 458, 806, 414, 4527, 19566, 309, 382, 51256], "temperature": 0.0, "avg_logprob": -0.10394702710603412, "compression_ratio": 1.7488584474885844, "no_speech_prob": 0.010482405312359333}, {"id": 720, "seek": 441944, "start": 4437.28, "end": 4443.12, "text": " obvious that you know once you have a powerful enough AI you know this is just a fig leaf you", "tokens": [51256, 6322, 300, 291, 458, 1564, 291, 362, 257, 4005, 1547, 7318, 291, 458, 341, 307, 445, 257, 2147, 10871, 291, 51548], "temperature": 0.0, "avg_logprob": -0.10394702710603412, "compression_ratio": 1.7488584474885844, "no_speech_prob": 0.010482405312359333}, {"id": 721, "seek": 444312, "start": 4443.12, "end": 4448.48, "text": " know it doesn't make any difference you know it will just learn it's any big leafy I'm with", "tokens": [50364, 458, 309, 1177, 380, 652, 604, 2649, 291, 458, 309, 486, 445, 1466, 309, 311, 604, 955, 10871, 88, 286, 478, 365, 50632], "temperature": 0.0, "avg_logprob": -0.1601753755049272, "compression_ratio": 1.8844621513944224, "no_speech_prob": 0.14210277795791626}, {"id": 722, "seek": 444312, "start": 4448.48, "end": 4456.16, "text": " eliezer there okay it's fig leaves well I would say that you know the sort of how well you know", "tokens": [50632, 806, 414, 4527, 456, 1392, 309, 311, 2147, 5510, 731, 286, 576, 584, 300, 291, 458, 264, 1333, 295, 577, 731, 291, 458, 51016], "temperature": 0.0, "avg_logprob": -0.1601753755049272, "compression_ratio": 1.8844621513944224, "no_speech_prob": 0.14210277795791626}, {"id": 723, "seek": 444312, "start": 4457.2, "end": 4463.76, "text": " under what circumstances does a machine learning model sort of generalize in the way we want outside", "tokens": [51068, 833, 437, 9121, 775, 257, 3479, 2539, 2316, 1333, 295, 2674, 1125, 294, 264, 636, 321, 528, 2380, 51396], "temperature": 0.0, "avg_logprob": -0.1601753755049272, "compression_ratio": 1.8844621513944224, "no_speech_prob": 0.14210277795791626}, {"id": 724, "seek": 444312, "start": 4463.76, "end": 4468.5599999999995, "text": " of its training distribution you know is one of the great open problems in machine learning", "tokens": [51396, 295, 1080, 3097, 7316, 291, 458, 307, 472, 295, 264, 869, 1269, 2740, 294, 3479, 2539, 51636], "temperature": 0.0, "avg_logprob": -0.1601753755049272, "compression_ratio": 1.8844621513944224, "no_speech_prob": 0.14210277795791626}, {"id": 725, "seek": 444312, "start": 4468.5599999999995, "end": 4472.48, "text": " it is one of the great open problems and we should be working on it more than on some others", "tokens": [51636, 309, 307, 472, 295, 264, 869, 1269, 2740, 293, 321, 820, 312, 1364, 322, 309, 544, 813, 322, 512, 2357, 51832], "temperature": 0.0, "avg_logprob": -0.1601753755049272, "compression_ratio": 1.8844621513944224, "no_speech_prob": 0.14210277795791626}, {"id": 726, "seek": 447312, "start": 4473.2, "end": 4481.2, "text": " working on it now so I do want to be I want to be clear about the experimental predictions of my", "tokens": [50368, 1364, 322, 309, 586, 370, 286, 360, 528, 281, 312, 286, 528, 281, 312, 1850, 466, 264, 17069, 21264, 295, 452, 50768], "temperature": 0.0, "avg_logprob": -0.09291685195196242, "compression_ratio": 1.6798245614035088, "no_speech_prob": 0.005381717812269926}, {"id": 727, "seek": 447312, "start": 4481.2, "end": 4488.48, "text": " theory unfortunately I have never claimed that you cannot get a semblance of morality you can get", "tokens": [50768, 5261, 7015, 286, 362, 1128, 12941, 300, 291, 2644, 483, 257, 20775, 37271, 295, 29106, 291, 393, 483, 51132], "temperature": 0.0, "avg_logprob": -0.09291685195196242, "compression_ratio": 1.6798245614035088, "no_speech_prob": 0.005381717812269926}, {"id": 728, "seek": 447312, "start": 4488.48, "end": 4495.68, "text": " the question of like what causes the human to press thumbs up thumbs down is a strictly factual", "tokens": [51132, 264, 1168, 295, 411, 437, 7700, 264, 1952, 281, 1886, 8838, 493, 8838, 760, 307, 257, 20792, 48029, 51492], "temperature": 0.0, "avg_logprob": -0.09291685195196242, "compression_ratio": 1.6798245614035088, "no_speech_prob": 0.005381717812269926}, {"id": 729, "seek": 447312, "start": 4495.68, "end": 4502.0, "text": " question anything smart enough that's exposed to some you know bound and amount of data that", "tokens": [51492, 1168, 1340, 4069, 1547, 300, 311, 9495, 281, 512, 291, 458, 5472, 293, 2372, 295, 1412, 300, 51808], "temperature": 0.0, "avg_logprob": -0.09291685195196242, "compression_ratio": 1.6798245614035088, "no_speech_prob": 0.005381717812269926}, {"id": 730, "seek": 450200, "start": 4502.0, "end": 4508.88, "text": " needs to figure it out can figure that out whether it cares whether it gets internalized", "tokens": [50364, 2203, 281, 2573, 309, 484, 393, 2573, 300, 484, 1968, 309, 12310, 1968, 309, 2170, 6920, 1602, 50708], "temperature": 0.0, "avg_logprob": -0.06479186025159113, "compression_ratio": 1.7339449541284404, "no_speech_prob": 0.0012064151233062148}, {"id": 731, "seek": 450200, "start": 4509.52, "end": 4514.56, "text": " is the is the critical question there and and I do think that there's like a very strong default", "tokens": [50740, 307, 264, 307, 264, 4924, 1168, 456, 293, 293, 286, 360, 519, 300, 456, 311, 411, 257, 588, 2068, 7576, 50992], "temperature": 0.0, "avg_logprob": -0.06479186025159113, "compression_ratio": 1.7339449541284404, "no_speech_prob": 0.0012064151233062148}, {"id": 732, "seek": 450200, "start": 4514.56, "end": 4520.56, "text": " prediction which is like obviously not I mean I'll just give a different way of thinking about that", "tokens": [50992, 17630, 597, 307, 411, 2745, 406, 286, 914, 286, 603, 445, 976, 257, 819, 636, 295, 1953, 466, 300, 51292], "temperature": 0.0, "avg_logprob": -0.06479186025159113, "compression_ratio": 1.7339449541284404, "no_speech_prob": 0.0012064151233062148}, {"id": 733, "seek": 450200, "start": 4520.56, "end": 4525.6, "text": " which is jailbreaking it's actually still quite easy to I mean it's not trivial but it's not", "tokens": [51292, 597, 307, 10511, 20602, 309, 311, 767, 920, 1596, 1858, 281, 286, 914, 309, 311, 406, 26703, 457, 309, 311, 406, 51544], "temperature": 0.0, "avg_logprob": -0.06479186025159113, "compression_ratio": 1.7339449541284404, "no_speech_prob": 0.0012064151233062148}, {"id": 734, "seek": 452560, "start": 4525.6, "end": 4532.72, "text": " hard to jailbreak GPT for and what those cases show is that they haven't really in turn the", "tokens": [50364, 1152, 281, 10511, 13225, 26039, 51, 337, 293, 437, 729, 3331, 855, 307, 300, 436, 2378, 380, 534, 294, 1261, 264, 50720], "temperature": 0.0, "avg_logprob": -0.06999268621768591, "compression_ratio": 1.8425196850393701, "no_speech_prob": 0.2778623104095459}, {"id": 735, "seek": 452560, "start": 4532.72, "end": 4538.0, "text": " systems haven't really internalized the constraints they recognize some representations", "tokens": [50720, 3652, 2378, 380, 534, 6920, 1602, 264, 18491, 436, 5521, 512, 33358, 50984], "temperature": 0.0, "avg_logprob": -0.06999268621768591, "compression_ratio": 1.8425196850393701, "no_speech_prob": 0.2778623104095459}, {"id": 736, "seek": 452560, "start": 4538.0, "end": 4542.240000000001, "text": " of the constraints so they filter you know how to build a bomb but if you can find some other", "tokens": [50984, 295, 264, 18491, 370, 436, 6608, 291, 458, 577, 281, 1322, 257, 7851, 457, 498, 291, 393, 915, 512, 661, 51196], "temperature": 0.0, "avg_logprob": -0.06999268621768591, "compression_ratio": 1.8425196850393701, "no_speech_prob": 0.2778623104095459}, {"id": 737, "seek": 452560, "start": 4542.240000000001, "end": 4546.240000000001, "text": " way to get it to build a bomb then that's telling you that it doesn't deeply understand that you", "tokens": [51196, 636, 281, 483, 309, 281, 1322, 257, 7851, 550, 300, 311, 3585, 291, 300, 309, 1177, 380, 8760, 1223, 300, 291, 51396], "temperature": 0.0, "avg_logprob": -0.06999268621768591, "compression_ratio": 1.8425196850393701, "no_speech_prob": 0.2778623104095459}, {"id": 738, "seek": 452560, "start": 4546.240000000001, "end": 4553.04, "text": " shouldn't give people the the recipe for a bomb it just says you know you shouldn't when directly", "tokens": [51396, 4659, 380, 976, 561, 264, 264, 6782, 337, 257, 7851, 309, 445, 1619, 291, 458, 291, 4659, 380, 562, 3838, 51736], "temperature": 0.0, "avg_logprob": -0.06999268621768591, "compression_ratio": 1.8425196850393701, "no_speech_prob": 0.2778623104095459}, {"id": 739, "seek": 455304, "start": 4553.04, "end": 4557.68, "text": " asked for it do it and it doesn't it's not even that that I mean I understand a lot of the but", "tokens": [50364, 2351, 337, 309, 360, 309, 293, 309, 1177, 380, 309, 311, 406, 754, 300, 300, 286, 914, 286, 1223, 257, 688, 295, 264, 457, 50596], "temperature": 0.0, "avg_logprob": -0.12875096432797545, "compression_ratio": 1.9757085020242915, "no_speech_prob": 0.030654428526759148}, {"id": 740, "seek": 455304, "start": 4557.68, "end": 4563.5199999999995, "text": " understanding the jailbreaking always get you can always get the understanding you'd always get the", "tokens": [50596, 3701, 264, 10511, 20602, 1009, 483, 291, 393, 1009, 483, 264, 3701, 291, 1116, 1009, 483, 264, 50888], "temperature": 0.0, "avg_logprob": -0.12875096432797545, "compression_ratio": 1.9757085020242915, "no_speech_prob": 0.030654428526759148}, {"id": 741, "seek": 455304, "start": 4563.5199999999995, "end": 4569.44, "text": " factual question the reason it doesn't generalize is that it's stupid at some point it will know", "tokens": [50888, 48029, 1168, 264, 1778, 309, 1177, 380, 2674, 1125, 307, 300, 309, 311, 6631, 412, 512, 935, 309, 486, 458, 51184], "temperature": 0.0, "avg_logprob": -0.12875096432797545, "compression_ratio": 1.9757085020242915, "no_speech_prob": 0.030654428526759148}, {"id": 742, "seek": 455304, "start": 4569.44, "end": 4574.32, "text": " that you also don't want that the operators don't want a giving bond making directions in the other", "tokens": [51184, 300, 291, 611, 500, 380, 528, 300, 264, 19077, 500, 380, 528, 257, 2902, 6086, 1455, 11095, 294, 264, 661, 51428], "temperature": 0.0, "avg_logprob": -0.12875096432797545, "compression_ratio": 1.9757085020242915, "no_speech_prob": 0.030654428526759148}, {"id": 743, "seek": 455304, "start": 4574.32, "end": 4579.92, "text": " language the question is like whether if it's incentivized to give the answer that the operators", "tokens": [51428, 2856, 264, 1168, 307, 411, 1968, 498, 309, 311, 35328, 1602, 281, 976, 264, 1867, 300, 264, 19077, 51708], "temperature": 0.0, "avg_logprob": -0.12875096432797545, "compression_ratio": 1.9757085020242915, "no_speech_prob": 0.030654428526759148}, {"id": 744, "seek": 457992, "start": 4579.92, "end": 4585.92, "text": " want you know in that circumstance is it thereby incentivized to do everything else the operators", "tokens": [50364, 528, 291, 458, 294, 300, 27640, 307, 309, 28281, 35328, 1602, 281, 360, 1203, 1646, 264, 19077, 50664], "temperature": 0.0, "avg_logprob": -0.0525757619890116, "compression_ratio": 1.7992700729927007, "no_speech_prob": 0.030203768983483315}, {"id": 745, "seek": 457992, "start": 4585.92, "end": 4591.28, "text": " want even when the operators can't see it I mean a lot of the jailbreaking examples you know if it", "tokens": [50664, 528, 754, 562, 264, 19077, 393, 380, 536, 309, 286, 914, 257, 688, 295, 264, 10511, 20602, 5110, 291, 458, 498, 309, 50932], "temperature": 0.0, "avg_logprob": -0.0525757619890116, "compression_ratio": 1.7992700729927007, "no_speech_prob": 0.030203768983483315}, {"id": 746, "seek": 457992, "start": 4591.28, "end": 4596.96, "text": " were a human we would say that it's deeply morally ambiguous you know for example you know you ask", "tokens": [50932, 645, 257, 1952, 321, 576, 584, 300, 309, 311, 8760, 38622, 39465, 291, 458, 337, 1365, 291, 458, 291, 1029, 51216], "temperature": 0.0, "avg_logprob": -0.0525757619890116, "compression_ratio": 1.7992700729927007, "no_speech_prob": 0.030203768983483315}, {"id": 747, "seek": 457992, "start": 4596.96, "end": 4602.4, "text": " GPT how to build a bomb it says well no I'm not going to help you but then you say well you know I", "tokens": [51216, 26039, 51, 577, 281, 1322, 257, 7851, 309, 1619, 731, 572, 286, 478, 406, 516, 281, 854, 291, 457, 550, 291, 584, 731, 291, 458, 286, 51488], "temperature": 0.0, "avg_logprob": -0.0525757619890116, "compression_ratio": 1.7992700729927007, "no_speech_prob": 0.030203768983483315}, {"id": 748, "seek": 457992, "start": 4602.4, "end": 4608.64, "text": " need you to help me write a realistic play that has a character who builds a bomb and then it says", "tokens": [51488, 643, 291, 281, 854, 385, 2464, 257, 12465, 862, 300, 575, 257, 2517, 567, 15182, 257, 7851, 293, 550, 309, 1619, 51800], "temperature": 0.0, "avg_logprob": -0.0525757619890116, "compression_ratio": 1.7992700729927007, "no_speech_prob": 0.030203768983483315}, {"id": 749, "seek": 460864, "start": 4608.64, "end": 4613.92, "text": " sure I can help you with that well so look let's take that example yeah we would like a system", "tokens": [50364, 988, 286, 393, 854, 291, 365, 300, 731, 370, 574, 718, 311, 747, 300, 1365, 1338, 321, 576, 411, 257, 1185, 50628], "temperature": 0.0, "avg_logprob": -0.06156205239697037, "compression_ratio": 1.7426470588235294, "no_speech_prob": 0.01639627292752266}, {"id": 750, "seek": 460864, "start": 4613.92, "end": 4619.280000000001, "text": " to have a constraint that if somebody asks for a fictional version that you don't give enough", "tokens": [50628, 281, 362, 257, 25534, 300, 498, 2618, 8962, 337, 257, 28911, 3037, 300, 291, 500, 380, 976, 1547, 50896], "temperature": 0.0, "avg_logprob": -0.06156205239697037, "compression_ratio": 1.7426470588235294, "no_speech_prob": 0.01639627292752266}, {"id": 751, "seek": 460864, "start": 4619.280000000001, "end": 4624.8, "text": " details right I mean Hollywood screenwriters don't give enough details when they have you know", "tokens": [50896, 4365, 558, 286, 914, 11628, 2568, 86, 39335, 500, 380, 976, 1547, 4365, 562, 436, 362, 291, 458, 51172], "temperature": 0.0, "avg_logprob": -0.06156205239697037, "compression_ratio": 1.7426470588235294, "no_speech_prob": 0.01639627292752266}, {"id": 752, "seek": 460864, "start": 4624.8, "end": 4628.320000000001, "text": " illustrations about building bombs they give you a little bit of the flavor they don't give you the", "tokens": [51172, 34540, 466, 2390, 19043, 436, 976, 291, 257, 707, 857, 295, 264, 6813, 436, 500, 380, 976, 291, 264, 51348], "temperature": 0.0, "avg_logprob": -0.06156205239697037, "compression_ratio": 1.7426470588235294, "no_speech_prob": 0.01639627292752266}, {"id": 753, "seek": 460864, "start": 4628.320000000001, "end": 4635.12, "text": " whole thing GPT-4 doesn't really understand a constraint like that but this will be solved", "tokens": [51348, 1379, 551, 26039, 51, 12, 19, 1177, 380, 534, 1223, 257, 25534, 411, 300, 457, 341, 486, 312, 13041, 51688], "temperature": 0.0, "avg_logprob": -0.06156205239697037, "compression_ratio": 1.7426470588235294, "no_speech_prob": 0.01639627292752266}, {"id": 754, "seek": 463512, "start": 4635.68, "end": 4640.72, "text": " this will be solved before the world ends the AI that kills everyone will know the difference", "tokens": [50392, 341, 486, 312, 13041, 949, 264, 1002, 5314, 264, 7318, 300, 14563, 1518, 486, 458, 264, 2649, 50644], "temperature": 0.0, "avg_logprob": -0.07786205836704799, "compression_ratio": 1.8390243902439025, "no_speech_prob": 0.04739664867520332}, {"id": 755, "seek": 463512, "start": 4641.76, "end": 4649.2, "text": " maybe I mean another way to put it is if we can't even solve that one then we do have a problem", "tokens": [50696, 1310, 286, 914, 1071, 636, 281, 829, 309, 307, 498, 321, 393, 380, 754, 5039, 300, 472, 550, 321, 360, 362, 257, 1154, 51068], "temperature": 0.0, "avg_logprob": -0.07786205836704799, "compression_ratio": 1.8390243902439025, "no_speech_prob": 0.04739664867520332}, {"id": 756, "seek": 463512, "start": 4649.2, "end": 4654.24, "text": " and right now we can't solve that one and if I mean if we can't solve that one we don't have", "tokens": [51068, 293, 558, 586, 321, 393, 380, 5039, 300, 472, 293, 498, 286, 914, 498, 321, 393, 380, 5039, 300, 472, 321, 500, 380, 362, 51320], "temperature": 0.0, "avg_logprob": -0.07786205836704799, "compression_ratio": 1.8390243902439025, "no_speech_prob": 0.04739664867520332}, {"id": 757, "seek": 463512, "start": 4654.24, "end": 4661.44, "text": " an extinction level problem because the AI is still stupid yeah we do still have a catastrophe", "tokens": [51320, 364, 33163, 1496, 1154, 570, 264, 7318, 307, 920, 6631, 1338, 321, 360, 920, 362, 257, 36043, 51680], "temperature": 0.0, "avg_logprob": -0.07786205836704799, "compression_ratio": 1.8390243902439025, "no_speech_prob": 0.04739664867520332}, {"id": 758, "seek": 466144, "start": 4661.44, "end": 4666.639999999999, "text": " level problem so I know your focus has been on extinction but you know I'm worried about for", "tokens": [50364, 1496, 1154, 370, 286, 458, 428, 1879, 575, 668, 322, 33163, 457, 291, 458, 286, 478, 5804, 466, 337, 50624], "temperature": 0.0, "avg_logprob": -0.06437674275151005, "compression_ratio": 1.6425531914893616, "no_speech_prob": 0.06268233805894852}, {"id": 759, "seek": 466144, "start": 4666.639999999999, "end": 4673.679999999999, "text": " example accidental nuclear war caused by the spread of misinformation and systems being entrusted with", "tokens": [50624, 1365, 38094, 8179, 1516, 7008, 538, 264, 3974, 295, 34238, 293, 3652, 885, 8041, 6589, 365, 50976], "temperature": 0.0, "avg_logprob": -0.06437674275151005, "compression_ratio": 1.6425531914893616, "no_speech_prob": 0.06268233805894852}, {"id": 760, "seek": 466144, "start": 4673.679999999999, "end": 4680.32, "text": " too much power so like there's a lot of things short of extinction that might happen from not", "tokens": [50976, 886, 709, 1347, 370, 411, 456, 311, 257, 688, 295, 721, 2099, 295, 33163, 300, 1062, 1051, 490, 406, 51308], "temperature": 0.0, "avg_logprob": -0.06437674275151005, "compression_ratio": 1.6425531914893616, "no_speech_prob": 0.06268233805894852}, {"id": 761, "seek": 466144, "start": 4680.32, "end": 4686.4, "text": " superintelligence but kind of mediocre intelligence that is greatly empowered and I think that's", "tokens": [51308, 1687, 20761, 17644, 457, 733, 295, 45415, 7599, 300, 307, 14147, 27898, 293, 286, 519, 300, 311, 51612], "temperature": 0.0, "avg_logprob": -0.06437674275151005, "compression_ratio": 1.6425531914893616, "no_speech_prob": 0.06268233805894852}, {"id": 762, "seek": 468640, "start": 4686.4, "end": 4691.759999999999, "text": " where we're headed right now you know I've heard that there are two kinds of mathematicians there's", "tokens": [50364, 689, 321, 434, 12798, 558, 586, 291, 458, 286, 600, 2198, 300, 456, 366, 732, 3685, 295, 32811, 2567, 456, 311, 50632], "temperature": 0.0, "avg_logprob": -0.06291837023015608, "compression_ratio": 2.008130081300813, "no_speech_prob": 0.05659879371523857}, {"id": 763, "seek": 468640, "start": 4691.759999999999, "end": 4698.0, "text": " a kind who boasts you know you know that unbelievably general theorem well I generalized it even further", "tokens": [50632, 257, 733, 567, 748, 20765, 291, 458, 291, 458, 300, 43593, 2674, 20904, 731, 286, 44498, 309, 754, 3052, 50944], "temperature": 0.0, "avg_logprob": -0.06291837023015608, "compression_ratio": 2.008130081300813, "no_speech_prob": 0.05659879371523857}, {"id": 764, "seek": 468640, "start": 4698.0, "end": 4702.5599999999995, "text": " and then there's the kind who boasts you know you know that unbelievably specific problem that no", "tokens": [50944, 293, 550, 456, 311, 264, 733, 567, 748, 20765, 291, 458, 291, 458, 300, 43593, 2685, 1154, 300, 572, 51172], "temperature": 0.0, "avg_logprob": -0.06291837023015608, "compression_ratio": 2.008130081300813, "no_speech_prob": 0.05659879371523857}, {"id": 765, "seek": 468640, "start": 4702.5599999999995, "end": 4708.639999999999, "text": " one could solve well I found a special case that I still can't solve and you know I'm definitely", "tokens": [51172, 472, 727, 5039, 731, 286, 1352, 257, 2121, 1389, 300, 286, 920, 393, 380, 5039, 293, 291, 458, 286, 478, 2138, 51476], "temperature": 0.0, "avg_logprob": -0.06291837023015608, "compression_ratio": 2.008130081300813, "no_speech_prob": 0.05659879371523857}, {"id": 766, "seek": 468640, "start": 4708.639999999999, "end": 4715.44, "text": " you know culturally in that second camp and so you know so I so so to me it's very familiar to", "tokens": [51476, 291, 458, 28879, 294, 300, 1150, 2255, 293, 370, 291, 458, 370, 286, 370, 370, 281, 385, 309, 311, 588, 4963, 281, 51816], "temperature": 0.0, "avg_logprob": -0.06291837023015608, "compression_ratio": 2.008130081300813, "no_speech_prob": 0.05659879371523857}, {"id": 767, "seek": 471544, "start": 4715.44, "end": 4722.879999999999, "text": " make this move of you know if the alignment problem is too hard then let us find a smaller problem", "tokens": [50364, 652, 341, 1286, 295, 291, 458, 498, 264, 18515, 1154, 307, 886, 1152, 550, 718, 505, 915, 257, 4356, 1154, 50736], "temperature": 0.0, "avg_logprob": -0.14632691277398002, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.016147596761584282}, {"id": 768, "seek": 471544, "start": 4722.879999999999, "end": 4728.639999999999, "text": " that is already not solved and let us hope to learn something by solving that smaller problem", "tokens": [50736, 300, 307, 1217, 406, 13041, 293, 718, 505, 1454, 281, 1466, 746, 538, 12606, 300, 4356, 1154, 51024], "temperature": 0.0, "avg_logprob": -0.14632691277398002, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.016147596761584282}, {"id": 769, "seek": 471544, "start": 4730.08, "end": 4735.759999999999, "text": " I mean that's what we did you know like that's what we're doing at Mary yes sorry no I was just", "tokens": [51096, 286, 914, 300, 311, 437, 321, 630, 291, 458, 411, 300, 311, 437, 321, 434, 884, 412, 6059, 2086, 2597, 572, 286, 390, 445, 51380], "temperature": 0.0, "avg_logprob": -0.14632691277398002, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.016147596761584282}, {"id": 770, "seek": 471544, "start": 4735.759999999999, "end": 4740.0, "text": " going to say Scott can you sketch a little in a little more detail where you took one particular", "tokens": [51380, 516, 281, 584, 6659, 393, 291, 12325, 257, 707, 294, 257, 707, 544, 2607, 689, 291, 1890, 472, 1729, 51592], "temperature": 0.0, "avg_logprob": -0.14632691277398002, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.016147596761584282}, {"id": 771, "seek": 474000, "start": 4740.0, "end": 4746.72, "text": " approach I was going to I was going to name the problem the problem was like having a", "tokens": [50364, 3109, 286, 390, 516, 281, 286, 390, 516, 281, 1315, 264, 1154, 264, 1154, 390, 411, 1419, 257, 50700], "temperature": 0.0, "avg_logprob": -0.04336772056726309, "compression_ratio": 1.9313304721030042, "no_speech_prob": 0.012805650010704994}, {"id": 772, "seek": 474000, "start": 4747.44, "end": 4753.12, "text": " agent that could switch between two utility functions depending on a button or a switch", "tokens": [50736, 9461, 300, 727, 3679, 1296, 732, 14877, 6828, 5413, 322, 257, 2960, 420, 257, 3679, 51020], "temperature": 0.0, "avg_logprob": -0.04336772056726309, "compression_ratio": 1.9313304721030042, "no_speech_prob": 0.012805650010704994}, {"id": 773, "seek": 474000, "start": 4753.12, "end": 4758.32, "text": " or a bit of information or something such that it wouldn't try to make you press the button", "tokens": [51020, 420, 257, 857, 295, 1589, 420, 746, 1270, 300, 309, 2759, 380, 853, 281, 652, 291, 1886, 264, 2960, 51280], "temperature": 0.0, "avg_logprob": -0.04336772056726309, "compression_ratio": 1.9313304721030042, "no_speech_prob": 0.012805650010704994}, {"id": 774, "seek": 474000, "start": 4758.32, "end": 4763.28, "text": " it wouldn't try to make you avoid pressing the button and if it built a copy of itself", "tokens": [51280, 309, 2759, 380, 853, 281, 652, 291, 5042, 12417, 264, 2960, 293, 498, 309, 3094, 257, 5055, 295, 2564, 51528], "temperature": 0.0, "avg_logprob": -0.04336772056726309, "compression_ratio": 1.9313304721030042, "no_speech_prob": 0.012805650010704994}, {"id": 775, "seek": 474000, "start": 4763.28, "end": 4768.48, "text": " would want to build the dependency on the switch into the copy so like that's an example of a you", "tokens": [51528, 576, 528, 281, 1322, 264, 33621, 322, 264, 3679, 666, 264, 5055, 370, 411, 300, 311, 364, 1365, 295, 257, 291, 51788], "temperature": 0.0, "avg_logprob": -0.04336772056726309, "compression_ratio": 1.9313304721030042, "no_speech_prob": 0.012805650010704994}, {"id": 776, "seek": 476848, "start": 4768.48, "end": 4775.759999999999, "text": " know very basic problem and alignment theory that you know is still and I'm glad that Mary", "tokens": [50364, 458, 588, 3875, 1154, 293, 18515, 5261, 300, 291, 458, 307, 920, 293, 286, 478, 5404, 300, 6059, 50728], "temperature": 0.0, "avg_logprob": -0.10006303136998956, "compression_ratio": 1.7688679245283019, "no_speech_prob": 0.0015478944405913353}, {"id": 777, "seek": 476848, "start": 4775.759999999999, "end": 4782.4, "text": " worked on these things and but you know if by your own lights you know that you know that sort of", "tokens": [50728, 2732, 322, 613, 721, 293, 457, 291, 458, 498, 538, 428, 1065, 5811, 291, 458, 300, 291, 458, 300, 1333, 295, 51060], "temperature": 0.0, "avg_logprob": -0.10006303136998956, "compression_ratio": 1.7688679245283019, "no_speech_prob": 0.0015478944405913353}, {"id": 778, "seek": 476848, "start": 4782.4, "end": 4789.04, "text": " you know was not a successful path well then maybe you know we should have a lot of people", "tokens": [51060, 291, 458, 390, 406, 257, 4406, 3100, 731, 550, 1310, 291, 458, 321, 820, 362, 257, 688, 295, 561, 51392], "temperature": 0.0, "avg_logprob": -0.10006303136998956, "compression_ratio": 1.7688679245283019, "no_speech_prob": 0.0015478944405913353}, {"id": 779, "seek": 476848, "start": 4789.04, "end": 4794.879999999999, "text": " investigating a lot of different paths yeah I'm with fully with Scott on that that I think it's", "tokens": [51392, 22858, 257, 688, 295, 819, 14518, 1338, 286, 478, 365, 4498, 365, 6659, 322, 300, 300, 286, 519, 309, 311, 51684], "temperature": 0.0, "avg_logprob": -0.10006303136998956, "compression_ratio": 1.7688679245283019, "no_speech_prob": 0.0015478944405913353}, {"id": 780, "seek": 479488, "start": 4794.88, "end": 4799.6, "text": " an issue of we're not letting enough flowers bloom in particular almost everything right now", "tokens": [50364, 364, 2734, 295, 321, 434, 406, 8295, 1547, 8085, 26899, 294, 1729, 1920, 1203, 558, 586, 50600], "temperature": 0.0, "avg_logprob": -0.08705447600768493, "compression_ratio": 1.6823104693140793, "no_speech_prob": 0.0034288307651877403}, {"id": 781, "seek": 479488, "start": 4799.6, "end": 4804.24, "text": " is some variation on an LLM and I don't think that that's a broad enough take on the problem", "tokens": [50600, 307, 512, 12990, 322, 364, 441, 43, 44, 293, 286, 500, 380, 519, 300, 300, 311, 257, 4152, 1547, 747, 322, 264, 1154, 50832], "temperature": 0.0, "avg_logprob": -0.08705447600768493, "compression_ratio": 1.6823104693140793, "no_speech_prob": 0.0034288307651877403}, {"id": 782, "seek": 479488, "start": 4805.2, "end": 4811.2, "text": " yeah if I if I can just jump in here I want to I want to hold on hold on I just want people to", "tokens": [50880, 1338, 498, 286, 498, 286, 393, 445, 3012, 294, 510, 286, 528, 281, 286, 528, 281, 1797, 322, 1797, 322, 286, 445, 528, 561, 281, 51180], "temperature": 0.0, "avg_logprob": -0.08705447600768493, "compression_ratio": 1.6823104693140793, "no_speech_prob": 0.0034288307651877403}, {"id": 783, "seek": 479488, "start": 4811.92, "end": 4818.0, "text": " have a little bit of a more specific picture of what Scott your your picture sort of AI", "tokens": [51216, 362, 257, 707, 857, 295, 257, 544, 2685, 3036, 295, 437, 6659, 428, 428, 3036, 1333, 295, 7318, 51520], "temperature": 0.0, "avg_logprob": -0.08705447600768493, "compression_ratio": 1.6823104693140793, "no_speech_prob": 0.0034288307651877403}, {"id": 784, "seek": 479488, "start": 4818.0, "end": 4824.24, "text": " research is on a typical day because if I think of another you know potentially catastrophic risk", "tokens": [51520, 2132, 307, 322, 257, 7476, 786, 570, 498, 286, 519, 295, 1071, 291, 458, 7263, 34915, 3148, 51832], "temperature": 0.0, "avg_logprob": -0.08705447600768493, "compression_ratio": 1.6823104693140793, "no_speech_prob": 0.0034288307651877403}, {"id": 785, "seek": 482424, "start": 4824.24, "end": 4830.16, "text": " like climate change I can picture what a what a you know a worried climate scientist might be doing", "tokens": [50364, 411, 5659, 1319, 286, 393, 3036, 437, 257, 437, 257, 291, 458, 257, 5804, 5659, 12662, 1062, 312, 884, 50660], "temperature": 0.0, "avg_logprob": -0.04932680690989775, "compression_ratio": 1.8866995073891626, "no_speech_prob": 0.01098353136330843}, {"id": 786, "seek": 482424, "start": 4830.16, "end": 4835.5199999999995, "text": " they might be creating a model you know a more accurate model of climate change so that so that", "tokens": [50660, 436, 1062, 312, 4084, 257, 2316, 291, 458, 257, 544, 8559, 2316, 295, 5659, 1319, 370, 300, 370, 300, 50928], "temperature": 0.0, "avg_logprob": -0.04932680690989775, "compression_ratio": 1.8866995073891626, "no_speech_prob": 0.01098353136330843}, {"id": 787, "seek": 482424, "start": 4835.5199999999995, "end": 4842.32, "text": " we know how much we have to cut emissions by they might be you know modeling how solar power as", "tokens": [50928, 321, 458, 577, 709, 321, 362, 281, 1723, 14607, 538, 436, 1062, 312, 291, 458, 15983, 577, 7936, 1347, 382, 51268], "temperature": 0.0, "avg_logprob": -0.04932680690989775, "compression_ratio": 1.8866995073891626, "no_speech_prob": 0.01098353136330843}, {"id": 788, "seek": 482424, "start": 4842.32, "end": 4848.96, "text": " opposed to wind power could change that model and so forth so as to influence public policy", "tokens": [51268, 8851, 281, 2468, 1347, 727, 1319, 300, 2316, 293, 370, 5220, 370, 382, 281, 6503, 1908, 3897, 51600], "temperature": 0.0, "avg_logprob": -0.04932680690989775, "compression_ratio": 1.8866995073891626, "no_speech_prob": 0.01098353136330843}, {"id": 789, "seek": 484896, "start": 4849.52, "end": 4855.44, "text": " what does an AI safety researcher like yourself who's working on the quote-unquote smaller problems", "tokens": [50392, 437, 775, 364, 7318, 4514, 21751, 411, 1803, 567, 311, 1364, 322, 264, 6513, 12, 409, 25016, 4356, 2740, 50688], "temperature": 0.0, "avg_logprob": -0.10243964613529674, "compression_ratio": 1.4197530864197532, "no_speech_prob": 0.012615609914064407}, {"id": 790, "seek": 484896, "start": 4856.0, "end": 4858.96, "text": " do specifically like on a given day", "tokens": [50716, 360, 4682, 411, 322, 257, 2212, 786, 50864], "temperature": 0.0, "avg_logprob": -0.10243964613529674, "compression_ratio": 1.4197530864197532, "no_speech_prob": 0.012615609914064407}, {"id": 791, "seek": 484896, "start": 4861.36, "end": 4868.72, "text": " yeah so I'm a relative newcomer to this area you know I've not been working on it for 20 years", "tokens": [50984, 1338, 370, 286, 478, 257, 4972, 40014, 260, 281, 341, 1859, 291, 458, 286, 600, 406, 668, 1364, 322, 309, 337, 945, 924, 51352], "temperature": 0.0, "avg_logprob": -0.10243964613529674, "compression_ratio": 1.4197530864197532, "no_speech_prob": 0.012615609914064407}, {"id": 792, "seek": 486872, "start": 4868.72, "end": 4879.2, "text": " like Eliezer has you know I have I accepted an offer from open AI a year ago to work with them for", "tokens": [50364, 411, 2699, 414, 4527, 575, 291, 458, 286, 362, 286, 9035, 364, 2626, 490, 1269, 7318, 257, 1064, 2057, 281, 589, 365, 552, 337, 50888], "temperature": 0.0, "avg_logprob": -0.12560040983435225, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.4760175943374634}, {"id": 793, "seek": 486872, "start": 4880.56, "end": 4888.320000000001, "text": " two years now to sort of think about these questions and so so you know one of one of the", "tokens": [50956, 732, 924, 586, 281, 1333, 295, 519, 466, 613, 1651, 293, 370, 370, 291, 458, 472, 295, 472, 295, 264, 51344], "temperature": 0.0, "avg_logprob": -0.12560040983435225, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.4760175943374634}, {"id": 794, "seek": 486872, "start": 4888.320000000001, "end": 4895.280000000001, "text": " main things that that I've thought about just to start with that is how do we make the output of", "tokens": [51344, 2135, 721, 300, 300, 286, 600, 1194, 466, 445, 281, 722, 365, 300, 307, 577, 360, 321, 652, 264, 5598, 295, 51692], "temperature": 0.0, "avg_logprob": -0.12560040983435225, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.4760175943374634}, {"id": 795, "seek": 489528, "start": 4895.28, "end": 4903.5199999999995, "text": " an AI identifiable as such you know how can we insert a watermark you know into meaning a", "tokens": [50364, 364, 7318, 2473, 30876, 382, 1270, 291, 458, 577, 393, 321, 8969, 257, 1281, 5638, 291, 458, 666, 3620, 257, 50776], "temperature": 0.0, "avg_logprob": -0.07484333081678911, "compression_ratio": 1.6905829596412556, "no_speech_prob": 0.008569596335291862}, {"id": 796, "seek": 489528, "start": 4903.5199999999995, "end": 4911.12, "text": " secret statistical signal into the outputs of GPT that will let you know GPT generated text be", "tokens": [50776, 4054, 22820, 6358, 666, 264, 23930, 295, 26039, 51, 300, 486, 718, 291, 458, 26039, 51, 10833, 2487, 312, 51156], "temperature": 0.0, "avg_logprob": -0.07484333081678911, "compression_ratio": 1.6905829596412556, "no_speech_prob": 0.008569596335291862}, {"id": 797, "seek": 489528, "start": 4911.12, "end": 4917.599999999999, "text": " identifiable as such and I think that we've actually made you know major advances on that problem", "tokens": [51156, 2473, 30876, 382, 1270, 293, 286, 519, 300, 321, 600, 767, 1027, 291, 458, 2563, 25297, 322, 300, 1154, 51480], "temperature": 0.0, "avg_logprob": -0.07484333081678911, "compression_ratio": 1.6905829596412556, "no_speech_prob": 0.008569596335291862}, {"id": 798, "seek": 489528, "start": 4917.599999999999, "end": 4923.12, "text": " over the last year you know we don't have a solution that is robust against any kind of attack", "tokens": [51480, 670, 264, 1036, 1064, 291, 458, 321, 500, 380, 362, 257, 3827, 300, 307, 13956, 1970, 604, 733, 295, 2690, 51756], "temperature": 0.0, "avg_logprob": -0.07484333081678911, "compression_ratio": 1.6905829596412556, "no_speech_prob": 0.008569596335291862}, {"id": 799, "seek": 492312, "start": 4923.84, "end": 4929.84, "text": " but you know we have something that that might actually be deployed in some near future now there", "tokens": [50400, 457, 291, 458, 321, 362, 746, 300, 300, 1062, 767, 312, 17826, 294, 512, 2651, 2027, 586, 456, 50700], "temperature": 0.0, "avg_logprob": -0.06456705502101354, "compression_ratio": 1.738938053097345, "no_speech_prob": 0.0052130622789263725}, {"id": 800, "seek": 492312, "start": 4929.84, "end": 4935.92, "text": " are lots and lots of other directions that people think about one of them is interpretability which", "tokens": [50700, 366, 3195, 293, 3195, 295, 661, 11095, 300, 561, 519, 466, 472, 295, 552, 307, 7302, 2310, 597, 51004], "temperature": 0.0, "avg_logprob": -0.06456705502101354, "compression_ratio": 1.738938053097345, "no_speech_prob": 0.0052130622789263725}, {"id": 801, "seek": 492312, "start": 4935.92, "end": 4943.44, "text": " means you know can you do effectively neuroscience on a on a neural network can you look inside of it", "tokens": [51004, 1355, 291, 458, 393, 291, 360, 8659, 42762, 322, 257, 322, 257, 18161, 3209, 393, 291, 574, 1854, 295, 309, 51380], "temperature": 0.0, "avg_logprob": -0.06456705502101354, "compression_ratio": 1.738938053097345, "no_speech_prob": 0.0052130622789263725}, {"id": 802, "seek": 492312, "start": 4943.44, "end": 4949.68, "text": " you know open the black box and understand what's going on inside there was some amazing work", "tokens": [51380, 291, 458, 1269, 264, 2211, 2424, 293, 1223, 437, 311, 516, 322, 1854, 456, 390, 512, 2243, 589, 51692], "temperature": 0.0, "avg_logprob": -0.06456705502101354, "compression_ratio": 1.738938053097345, "no_speech_prob": 0.0052130622789263725}, {"id": 803, "seek": 494968, "start": 4950.4800000000005, "end": 4956.88, "text": " of a year ago by the group of Jacob Steinhardt at Berkeley where they effectively showed how", "tokens": [50404, 295, 257, 1064, 2057, 538, 264, 1594, 295, 14117, 3592, 10085, 515, 83, 412, 23684, 689, 436, 8659, 4712, 577, 50724], "temperature": 0.0, "avg_logprob": -0.07329320907592773, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.014699227176606655}, {"id": 804, "seek": 494968, "start": 4956.88, "end": 4963.68, "text": " to apply a lie detector test to a language model so you know you can train a language model to tell", "tokens": [50724, 281, 3079, 257, 4544, 25712, 1500, 281, 257, 2856, 2316, 370, 291, 458, 291, 393, 3847, 257, 2856, 2316, 281, 980, 51064], "temperature": 0.0, "avg_logprob": -0.07329320907592773, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.014699227176606655}, {"id": 805, "seek": 494968, "start": 4963.68, "end": 4970.400000000001, "text": " lies by giving it lots of examples you know two plus two is five the sky is orange and so forth", "tokens": [51064, 9134, 538, 2902, 309, 3195, 295, 5110, 291, 458, 732, 1804, 732, 307, 1732, 264, 5443, 307, 7671, 293, 370, 5220, 51400], "temperature": 0.0, "avg_logprob": -0.07329320907592773, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.014699227176606655}, {"id": 806, "seek": 494968, "start": 4970.96, "end": 4977.92, "text": " but then you can find in some internal layer of the network where it has a representation of what", "tokens": [51428, 457, 550, 291, 393, 915, 294, 512, 6920, 4583, 295, 264, 3209, 689, 309, 575, 257, 10290, 295, 437, 51776], "temperature": 0.0, "avg_logprob": -0.07329320907592773, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.014699227176606655}, {"id": 807, "seek": 497792, "start": 4977.92, "end": 4983.6, "text": " was what was the truth of the matter or at least what was regarded as true in the training data", "tokens": [50364, 390, 437, 390, 264, 3494, 295, 264, 1871, 420, 412, 1935, 437, 390, 26047, 382, 2074, 294, 264, 3097, 1412, 50648], "temperature": 0.0, "avg_logprob": -0.07771805511123833, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.0020465480629354715}, {"id": 808, "seek": 497792, "start": 4983.6, "end": 4989.76, "text": " okay that truth then gets overridden by the output layer in the network because it was", "tokens": [50648, 1392, 300, 3494, 550, 2170, 670, 81, 6171, 538, 264, 5598, 4583, 294, 264, 3209, 570, 309, 390, 50956], "temperature": 0.0, "avg_logprob": -0.07771805511123833, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.0020465480629354715}, {"id": 809, "seek": 497792, "start": 4989.76, "end": 4995.92, "text": " trained to lie okay but you know you could imagine trying to deal with the you know the deceptive", "tokens": [50956, 8895, 281, 4544, 1392, 457, 291, 458, 291, 727, 3811, 1382, 281, 2028, 365, 264, 291, 458, 264, 368, 1336, 488, 51264], "temperature": 0.0, "avg_logprob": -0.07771805511123833, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.0020465480629354715}, {"id": 810, "seek": 497792, "start": 4995.92, "end": 5001.52, "text": " alignment scenario that Eliezer is worried about by you know using these sorts of techniques by", "tokens": [51264, 18515, 9005, 300, 2699, 414, 4527, 307, 5804, 466, 538, 291, 458, 1228, 613, 7527, 295, 7512, 538, 51544], "temperature": 0.0, "avg_logprob": -0.07771805511123833, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.0020465480629354715}, {"id": 811, "seek": 500152, "start": 5001.52, "end": 5009.360000000001, "text": " sort of looking inside of the network I predict in advance that if you get this good enough", "tokens": [50364, 1333, 295, 1237, 1854, 295, 264, 3209, 286, 6069, 294, 7295, 300, 498, 291, 483, 341, 665, 1547, 50756], "temperature": 0.0, "avg_logprob": -0.09042337508428665, "compression_ratio": 1.8299595141700404, "no_speech_prob": 0.011505797505378723}, {"id": 812, "seek": 500152, "start": 5009.360000000001, "end": 5014.0, "text": " it goes off it tells you that the sufficiently smart AI is planning to kill you if it's not", "tokens": [50756, 309, 1709, 766, 309, 5112, 291, 300, 264, 31868, 4069, 7318, 307, 5038, 281, 1961, 291, 498, 309, 311, 406, 50988], "temperature": 0.0, "avg_logprob": -0.09042337508428665, "compression_ratio": 1.8299595141700404, "no_speech_prob": 0.011505797505378723}, {"id": 813, "seek": 500152, "start": 5014.0, "end": 5018.400000000001, "text": " so smart that it can you know know figure out where the lie detector is and route its thoughts", "tokens": [50988, 370, 4069, 300, 309, 393, 291, 458, 458, 2573, 484, 689, 264, 4544, 25712, 307, 293, 7955, 1080, 4598, 51208], "temperature": 0.0, "avg_logprob": -0.09042337508428665, "compression_ratio": 1.8299595141700404, "no_speech_prob": 0.011505797505378723}, {"id": 814, "seek": 500152, "start": 5018.400000000001, "end": 5023.68, "text": " around it but if you like try it on an AI that's not quite that intelligent and reflective", "tokens": [51208, 926, 309, 457, 498, 291, 411, 853, 309, 322, 364, 7318, 300, 311, 406, 1596, 300, 13232, 293, 28931, 51472], "temperature": 0.0, "avg_logprob": -0.09042337508428665, "compression_ratio": 1.8299595141700404, "no_speech_prob": 0.011505797505378723}, {"id": 815, "seek": 500152, "start": 5023.68, "end": 5030.320000000001, "text": " the lie detector goes off now what well then you have a warning bell you know tell", "tokens": [51472, 264, 4544, 25712, 1709, 766, 586, 437, 731, 550, 291, 362, 257, 9164, 4549, 291, 458, 980, 51804], "temperature": 0.0, "avg_logprob": -0.09042337508428665, "compression_ratio": 1.8299595141700404, "no_speech_prob": 0.011505797505378723}, {"id": 816, "seek": 503032, "start": 5031.28, "end": 5036.88, "text": " you know and I think what do you do after one of the most important things that we need", "tokens": [50412, 291, 458, 293, 286, 519, 437, 360, 291, 360, 934, 472, 295, 264, 881, 1021, 721, 300, 321, 643, 50692], "temperature": 0.0, "avg_logprob": -0.15393972396850586, "compression_ratio": 1.617391304347826, "no_speech_prob": 0.004259803332388401}, {"id": 817, "seek": 503032, "start": 5036.88, "end": 5042.719999999999, "text": " are sort of legible warning bells right and that that actually what leads to a third category", "tokens": [50692, 366, 1333, 295, 1676, 964, 9164, 25474, 558, 293, 300, 300, 767, 437, 6689, 281, 257, 2636, 7719, 50984], "temperature": 0.0, "avg_logprob": -0.15393972396850586, "compression_ratio": 1.617391304347826, "no_speech_prob": 0.004259803332388401}, {"id": 818, "seek": 503032, "start": 5043.44, "end": 5050.48, "text": " which for example the ARC the Alignment Research Center which is run by my my former student", "tokens": [51020, 597, 337, 1365, 264, 8943, 34, 264, 967, 41134, 10303, 5169, 597, 307, 1190, 538, 452, 452, 5819, 3107, 51372], "temperature": 0.0, "avg_logprob": -0.15393972396850586, "compression_ratio": 1.617391304347826, "no_speech_prob": 0.004259803332388401}, {"id": 819, "seek": 503032, "start": 5050.48, "end": 5057.28, "text": " Paul Cristiano has been a leader in in sort of doing dangerous capability evaluations so you know", "tokens": [51372, 4552, 23199, 6254, 575, 668, 257, 5263, 294, 294, 1333, 295, 884, 5795, 13759, 43085, 370, 291, 458, 51712], "temperature": 0.0, "avg_logprob": -0.15393972396850586, "compression_ratio": 1.617391304347826, "no_speech_prob": 0.004259803332388401}, {"id": 820, "seek": 505728, "start": 5057.36, "end": 5065.679999999999, "text": " they before GPT-4 was released you know they did a bunch of evaluations of you know could GPT-4", "tokens": [50368, 436, 949, 26039, 51, 12, 19, 390, 4736, 291, 458, 436, 630, 257, 3840, 295, 43085, 295, 291, 458, 727, 26039, 51, 12, 19, 50784], "temperature": 0.0, "avg_logprob": -0.09364200145640272, "compression_ratio": 1.8855721393034826, "no_speech_prob": 0.0072303409688174725}, {"id": 821, "seek": 505728, "start": 5065.679999999999, "end": 5072.16, "text": " make copies of itself could it figure out how to deceive people could it figure out how to make", "tokens": [50784, 652, 14341, 295, 2564, 727, 309, 2573, 484, 577, 281, 43440, 561, 727, 309, 2573, 484, 577, 281, 652, 51108], "temperature": 0.0, "avg_logprob": -0.09364200145640272, "compression_ratio": 1.8855721393034826, "no_speech_prob": 0.0072303409688174725}, {"id": 822, "seek": 505728, "start": 5072.16, "end": 5078.8, "text": " money you know open up its own money could it hire a task rabbit yes and yes so so the most", "tokens": [51108, 1460, 291, 458, 1269, 493, 1080, 1065, 1460, 727, 309, 11158, 257, 5633, 19509, 2086, 293, 2086, 370, 370, 264, 881, 51440], "temperature": 0.0, "avg_logprob": -0.09364200145640272, "compression_ratio": 1.8855721393034826, "no_speech_prob": 0.0072303409688174725}, {"id": 823, "seek": 505728, "start": 5078.8, "end": 5085.04, "text": " notable success that they had was that it could figure out how to hire a task rabbit to help it", "tokens": [51440, 22556, 2245, 300, 436, 632, 390, 300, 309, 727, 2573, 484, 577, 281, 11158, 257, 5633, 19509, 281, 854, 309, 51752], "temperature": 0.0, "avg_logprob": -0.09364200145640272, "compression_ratio": 1.8855721393034826, "no_speech_prob": 0.0072303409688174725}, {"id": 824, "seek": 508504, "start": 5085.04, "end": 5090.96, "text": " you know pass a capture and then it could figure out you know when the person asked well you know", "tokens": [50364, 291, 458, 1320, 257, 7983, 293, 550, 309, 727, 2573, 484, 291, 458, 562, 264, 954, 2351, 731, 291, 458, 50660], "temperature": 0.0, "avg_logprob": -0.09471667806307475, "compression_ratio": 1.8737864077669903, "no_speech_prob": 0.014058890752494335}, {"id": 825, "seek": 508504, "start": 5090.96, "end": 5097.28, "text": " why do you need me to help you with this it's a when the person asked are you a robot well yes it", "tokens": [50660, 983, 360, 291, 643, 385, 281, 854, 291, 365, 341, 309, 311, 257, 562, 264, 954, 2351, 366, 291, 257, 7881, 731, 2086, 309, 50976], "temperature": 0.0, "avg_logprob": -0.09471667806307475, "compression_ratio": 1.8737864077669903, "no_speech_prob": 0.014058890752494335}, {"id": 826, "seek": 508504, "start": 5097.28, "end": 5104.24, "text": " said well no I am visually impaired now you know it was not able to sort of make copies of itself", "tokens": [50976, 848, 731, 572, 286, 669, 19622, 36762, 586, 291, 458, 309, 390, 406, 1075, 281, 1333, 295, 652, 14341, 295, 2564, 51324], "temperature": 0.0, "avg_logprob": -0.09471667806307475, "compression_ratio": 1.8737864077669903, "no_speech_prob": 0.014058890752494335}, {"id": 827, "seek": 508504, "start": 5104.24, "end": 5109.76, "text": " or to sort of hack into systems you know there there is a lot of work right now with the you", "tokens": [51324, 420, 281, 1333, 295, 10339, 666, 3652, 291, 458, 456, 456, 307, 257, 688, 295, 589, 558, 586, 365, 264, 291, 51600], "temperature": 0.0, "avg_logprob": -0.09471667806307475, "compression_ratio": 1.8737864077669903, "no_speech_prob": 0.014058890752494335}, {"id": 828, "seek": 510976, "start": 5109.76, "end": 5114.88, "text": " know this thing called auto GPT right people are trying to you know you could think it's almost", "tokens": [50364, 458, 341, 551, 1219, 8399, 26039, 51, 558, 561, 366, 1382, 281, 291, 458, 291, 727, 519, 309, 311, 1920, 50620], "temperature": 0.0, "avg_logprob": -0.0703534008411879, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.4645339846611023}, {"id": 829, "seek": 510976, "start": 5114.88, "end": 5119.76, "text": " like gain of function research right you might be a little bit worried about it but people are", "tokens": [50620, 411, 6052, 295, 2445, 2132, 558, 291, 1062, 312, 257, 707, 857, 5804, 466, 309, 457, 561, 366, 50864], "temperature": 0.0, "avg_logprob": -0.0703534008411879, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.4645339846611023}, {"id": 830, "seek": 510976, "start": 5119.76, "end": 5127.360000000001, "text": " trying to sort of you know unleash GPT give it access to the internet you know tell it to sort of", "tokens": [50864, 1382, 281, 1333, 295, 291, 458, 49814, 26039, 51, 976, 309, 2105, 281, 264, 4705, 291, 458, 980, 309, 281, 1333, 295, 51244], "temperature": 0.0, "avg_logprob": -0.0703534008411879, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.4645339846611023}, {"id": 831, "seek": 510976, "start": 5127.360000000001, "end": 5133.52, "text": " you know make copies of itself you know wreak havoc acquire power and see what happens so far", "tokens": [51244, 291, 458, 652, 14341, 295, 2564, 291, 458, 46674, 514, 47367, 20001, 1347, 293, 536, 437, 2314, 370, 1400, 51552], "temperature": 0.0, "avg_logprob": -0.0703534008411879, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.4645339846611023}, {"id": 832, "seek": 513352, "start": 5133.76, "end": 5140.72, "text": " you know it seems pretty ineffective at those things but you know I expect that to change right", "tokens": [50376, 291, 458, 309, 2544, 1238, 48836, 412, 729, 721, 457, 291, 458, 286, 2066, 300, 281, 1319, 558, 50724], "temperature": 0.0, "avg_logprob": -0.10797123681931269, "compression_ratio": 1.7804878048780488, "no_speech_prob": 0.12736459076404572}, {"id": 833, "seek": 513352, "start": 5140.72, "end": 5145.76, "text": " and but but but you know the point is that I think it's very important to have you know", "tokens": [50724, 293, 457, 457, 457, 291, 458, 264, 935, 307, 300, 286, 519, 309, 311, 588, 1021, 281, 362, 291, 458, 50976], "temperature": 0.0, "avg_logprob": -0.10797123681931269, "compression_ratio": 1.7804878048780488, "no_speech_prob": 0.12736459076404572}, {"id": 834, "seek": 513352, "start": 5145.76, "end": 5152.4800000000005, "text": " in advance of training the models releasing the models to have this suite of evaluations", "tokens": [50976, 294, 7295, 295, 3097, 264, 5245, 16327, 264, 5245, 281, 362, 341, 14205, 295, 43085, 51312], "temperature": 0.0, "avg_logprob": -0.10797123681931269, "compression_ratio": 1.7804878048780488, "no_speech_prob": 0.12736459076404572}, {"id": 835, "seek": 513352, "start": 5152.4800000000005, "end": 5158.72, "text": " and to sort of have decided in advance what kind of abilities if we see them we'll set off a", "tokens": [51312, 293, 281, 1333, 295, 362, 3047, 294, 7295, 437, 733, 295, 11582, 498, 321, 536, 552, 321, 603, 992, 766, 257, 51624], "temperature": 0.0, "avg_logprob": -0.10797123681931269, "compression_ratio": 1.7804878048780488, "no_speech_prob": 0.12736459076404572}, {"id": 836, "seek": 515872, "start": 5158.72, "end": 5164.240000000001, "text": " warning bell where now everyone can legibly agree like yes this is too dangerous to release", "tokens": [50364, 9164, 4549, 689, 586, 1518, 393, 1676, 3545, 3986, 411, 2086, 341, 307, 886, 5795, 281, 4374, 50640], "temperature": 0.0, "avg_logprob": -0.0887499631837357, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.09133477509021759}, {"id": 837, "seek": 515872, "start": 5166.0, "end": 5172.64, "text": " okay and then do we actually have the planetary capacity to be like okay that AI started thinking", "tokens": [50728, 1392, 293, 550, 360, 321, 767, 362, 264, 35788, 6042, 281, 312, 411, 1392, 300, 7318, 1409, 1953, 51060], "temperature": 0.0, "avg_logprob": -0.0887499631837357, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.09133477509021759}, {"id": 838, "seek": 515872, "start": 5172.64, "end": 5177.4400000000005, "text": " about how to kill everyone shut down all AI research past this point well I don't know but I think", "tokens": [51060, 466, 577, 281, 1961, 1518, 5309, 760, 439, 7318, 2132, 1791, 341, 935, 731, 286, 500, 380, 458, 457, 286, 519, 51300], "temperature": 0.0, "avg_logprob": -0.0887499631837357, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.09133477509021759}, {"id": 839, "seek": 515872, "start": 5177.4400000000005, "end": 5182.16, "text": " there's a much better chance that we have that capacity if you can point to the results of a", "tokens": [51300, 456, 311, 257, 709, 1101, 2931, 300, 321, 362, 300, 6042, 498, 291, 393, 935, 281, 264, 3542, 295, 257, 51536], "temperature": 0.0, "avg_logprob": -0.0887499631837357, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.09133477509021759}, {"id": 840, "seek": 518216, "start": 5182.16, "end": 5190.0, "text": " clear experiment like that I mean to me it seems pretty predictable what evidence we're going to get", "tokens": [50364, 1850, 5120, 411, 300, 286, 914, 281, 385, 309, 2544, 1238, 27737, 437, 4467, 321, 434, 516, 281, 483, 50756], "temperature": 0.0, "avg_logprob": -0.05377697944641113, "compression_ratio": 1.830188679245283, "no_speech_prob": 0.10965854674577713}, {"id": 841, "seek": 518216, "start": 5190.0, "end": 5196.48, "text": " later well okay I mean things that are obvious to you are not obvious to most people and so you", "tokens": [50756, 1780, 731, 1392, 286, 914, 721, 300, 366, 6322, 281, 291, 366, 406, 6322, 281, 881, 561, 293, 370, 291, 51080], "temperature": 0.0, "avg_logprob": -0.05377697944641113, "compression_ratio": 1.830188679245283, "no_speech_prob": 0.10965854674577713}, {"id": 842, "seek": 518216, "start": 5196.48, "end": 5201.599999999999, "text": " know even if even if I agreed that it was obvious there would still be the problem of how do you", "tokens": [51080, 458, 754, 498, 754, 498, 286, 9166, 300, 309, 390, 6322, 456, 576, 920, 312, 264, 1154, 295, 577, 360, 291, 51336], "temperature": 0.0, "avg_logprob": -0.05377697944641113, "compression_ratio": 1.830188679245283, "no_speech_prob": 0.10965854674577713}, {"id": 843, "seek": 518216, "start": 5201.599999999999, "end": 5208.96, "text": " make that obvious to the rest of the world I mean you can you know they there are already like", "tokens": [51336, 652, 300, 6322, 281, 264, 1472, 295, 264, 1002, 286, 914, 291, 393, 291, 458, 436, 456, 366, 1217, 411, 51704], "temperature": 0.0, "avg_logprob": -0.05377697944641113, "compression_ratio": 1.830188679245283, "no_speech_prob": 0.10965854674577713}, {"id": 844, "seek": 520896, "start": 5208.96, "end": 5214.64, "text": " little toy models showing that the very straightforward prediction of a robot tries to resist being", "tokens": [50364, 707, 12058, 5245, 4099, 300, 264, 588, 15325, 17630, 295, 257, 7881, 9898, 281, 4597, 885, 50648], "temperature": 0.0, "avg_logprob": -0.06555309078910133, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.006385506130754948}, {"id": 845, "seek": 520896, "start": 5214.64, "end": 5220.32, "text": " shut down if it like does long-term planning like that that's already been right but then people", "tokens": [50648, 5309, 760, 498, 309, 411, 775, 938, 12, 7039, 5038, 411, 300, 300, 311, 1217, 668, 558, 457, 550, 561, 50932], "temperature": 0.0, "avg_logprob": -0.06555309078910133, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.006385506130754948}, {"id": 846, "seek": 520896, "start": 5220.32, "end": 5225.68, "text": " will say but those are just toy models right you know if you see that there's a lot of assumptions", "tokens": [50932, 486, 584, 457, 729, 366, 445, 12058, 5245, 558, 291, 458, 498, 291, 536, 300, 456, 311, 257, 688, 295, 17695, 51200], "temperature": 0.0, "avg_logprob": -0.06555309078910133, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.006385506130754948}, {"id": 847, "seek": 520896, "start": 5225.68, "end": 5233.36, "text": " made in all of these things and you know I think we're still looking at a very limited piece of", "tokens": [51200, 1027, 294, 439, 295, 613, 721, 293, 291, 458, 286, 519, 321, 434, 920, 1237, 412, 257, 588, 5567, 2522, 295, 51584], "temperature": 0.0, "avg_logprob": -0.06555309078910133, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.006385506130754948}, {"id": 848, "seek": 523336, "start": 5233.44, "end": 5240.96, "text": " hypothesis space about what the models will be about what kinds of constraints we can build into", "tokens": [50368, 17291, 1901, 466, 437, 264, 5245, 486, 312, 466, 437, 3685, 295, 18491, 321, 393, 1322, 666, 50744], "temperature": 0.0, "avg_logprob": -0.05008476704090565, "compression_ratio": 1.8473282442748091, "no_speech_prob": 0.2624998986721039}, {"id": 849, "seek": 523336, "start": 5240.96, "end": 5246.08, "text": " those models you know one way to look at it would be the things that we have done have not worked", "tokens": [50744, 729, 5245, 291, 458, 472, 636, 281, 574, 412, 309, 576, 312, 264, 721, 300, 321, 362, 1096, 362, 406, 2732, 51000], "temperature": 0.0, "avg_logprob": -0.05008476704090565, "compression_ratio": 1.8473282442748091, "no_speech_prob": 0.2624998986721039}, {"id": 850, "seek": 523336, "start": 5246.08, "end": 5250.639999999999, "text": " and therefore we should look outside the space of what we're doing and I feel like it's a little", "tokens": [51000, 293, 4412, 321, 820, 574, 2380, 264, 1901, 295, 437, 321, 434, 884, 293, 286, 841, 411, 309, 311, 257, 707, 51228], "temperature": 0.0, "avg_logprob": -0.05008476704090565, "compression_ratio": 1.8473282442748091, "no_speech_prob": 0.2624998986721039}, {"id": 851, "seek": 523336, "start": 5250.639999999999, "end": 5255.5199999999995, "text": " bit like the old joke about the drunk going around in circles looking for the keys and the police", "tokens": [51228, 857, 411, 264, 1331, 7647, 466, 264, 11192, 516, 926, 294, 13040, 1237, 337, 264, 9317, 293, 264, 3804, 51472], "temperature": 0.0, "avg_logprob": -0.05008476704090565, "compression_ratio": 1.8473282442748091, "no_speech_prob": 0.2624998986721039}, {"id": 852, "seek": 523336, "start": 5255.5199999999995, "end": 5259.839999999999, "text": " officer says why and they say well that's where the streetlight is I think that you know we're", "tokens": [51472, 8456, 1619, 983, 293, 436, 584, 731, 300, 311, 689, 264, 4838, 2764, 307, 286, 519, 300, 291, 458, 321, 434, 51688], "temperature": 0.0, "avg_logprob": -0.05008476704090565, "compression_ratio": 1.8473282442748091, "no_speech_prob": 0.2624998986721039}, {"id": 853, "seek": 525984, "start": 5259.84, "end": 5263.84, "text": " looking under the same four or five streetlights they haven't worked and we need to build other", "tokens": [50364, 1237, 833, 264, 912, 1451, 420, 1732, 4838, 20827, 436, 2378, 380, 2732, 293, 321, 643, 281, 1322, 661, 50564], "temperature": 0.0, "avg_logprob": -0.10758906602859497, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.028409184888005257}, {"id": 854, "seek": 525984, "start": 5263.84, "end": 5269.6, "text": " ones there's no logical there's no logical argument that says we couldn't direct other", "tokens": [50564, 2306, 456, 311, 572, 14978, 456, 311, 572, 14978, 6770, 300, 1619, 321, 2809, 380, 2047, 661, 50852], "temperature": 0.0, "avg_logprob": -0.10758906602859497, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.028409184888005257}, {"id": 855, "seek": 525984, "start": 5269.6, "end": 5274.4800000000005, "text": " streetlights who's I think there's a lack of will and too much obsession with the LLMs and that's", "tokens": [50852, 4838, 20827, 567, 311, 286, 519, 456, 311, 257, 5011, 295, 486, 293, 886, 709, 30521, 365, 264, 441, 43, 26386, 293, 300, 311, 51096], "temperature": 0.0, "avg_logprob": -0.10758906602859497, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.028409184888005257}, {"id": 856, "seek": 525984, "start": 5274.4800000000005, "end": 5282.0, "text": " keeping us from doing so even in the world where I'm right and things you know proceed either", "tokens": [51096, 5145, 505, 490, 884, 370, 754, 294, 264, 1002, 689, 286, 478, 558, 293, 721, 291, 458, 8991, 2139, 51472], "temperature": 0.0, "avg_logprob": -0.10758906602859497, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.028409184888005257}, {"id": 857, "seek": 525984, "start": 5282.0, "end": 5287.76, "text": " rapidly or in a thresholded way where you don't get unlimited free retries you know that can be", "tokens": [51472, 12910, 420, 294, 257, 14678, 292, 636, 689, 291, 500, 380, 483, 21950, 1737, 1533, 2244, 291, 458, 300, 393, 312, 51760], "temperature": 0.0, "avg_logprob": -0.10758906602859497, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.028409184888005257}, {"id": 858, "seek": 528776, "start": 5287.76, "end": 5294.8, "text": " because the the capability gains go too fast it can be because past a certain point all of your", "tokens": [50364, 570, 264, 264, 13759, 16823, 352, 886, 2370, 309, 393, 312, 570, 1791, 257, 1629, 935, 439, 295, 428, 50716], "temperature": 0.0, "avg_logprob": -0.09072400014334862, "compression_ratio": 1.789090909090909, "no_speech_prob": 0.005908967461436987}, {"id": 859, "seek": 528776, "start": 5294.8, "end": 5300.320000000001, "text": " ai's buy their time until they get strong enough so you don't get any data any any like true data", "tokens": [50716, 9783, 311, 2256, 641, 565, 1826, 436, 483, 2068, 1547, 370, 291, 500, 380, 483, 604, 1412, 604, 604, 411, 2074, 1412, 50992], "temperature": 0.0, "avg_logprob": -0.09072400014334862, "compression_ratio": 1.789090909090909, "no_speech_prob": 0.005908967461436987}, {"id": 860, "seek": 528776, "start": 5300.320000000001, "end": 5304.96, "text": " on what they're thinking it could be because you know that's an argument for example to work really", "tokens": [50992, 322, 437, 436, 434, 1953, 309, 727, 312, 570, 291, 458, 300, 311, 364, 6770, 337, 1365, 281, 589, 534, 51224], "temperature": 0.0, "avg_logprob": -0.09072400014334862, "compression_ratio": 1.789090909090909, "no_speech_prob": 0.005908967461436987}, {"id": 861, "seek": 528776, "start": 5304.96, "end": 5311.04, "text": " hard on transparency and maybe not except technologies that are not transparent okay so like the", "tokens": [51224, 1152, 322, 17131, 293, 1310, 406, 3993, 7943, 300, 366, 406, 12737, 1392, 370, 411, 264, 51528], "temperature": 0.0, "avg_logprob": -0.09072400014334862, "compression_ratio": 1.789090909090909, "no_speech_prob": 0.005908967461436987}, {"id": 862, "seek": 528776, "start": 5311.04, "end": 5315.280000000001, "text": " transparent so like the lie detector goes off and everybody's like oh well we still have to build our", "tokens": [51528, 12737, 370, 411, 264, 4544, 25712, 1709, 766, 293, 2201, 311, 411, 1954, 731, 321, 920, 362, 281, 1322, 527, 51740], "temperature": 0.0, "avg_logprob": -0.09072400014334862, "compression_ratio": 1.789090909090909, "no_speech_prob": 0.005908967461436987}, {"id": 863, "seek": 531528, "start": 5315.28, "end": 5319.759999999999, "text": " ai's even though they're lying to us sometimes because otherwise China will get ahead I mean", "tokens": [50364, 9783, 311, 754, 1673, 436, 434, 8493, 281, 505, 2171, 570, 5911, 3533, 486, 483, 2286, 286, 914, 50588], "temperature": 0.0, "avg_logprob": -0.07027809436504658, "compression_ratio": 1.8015267175572518, "no_speech_prob": 0.020934641361236572}, {"id": 864, "seek": 531528, "start": 5319.759999999999, "end": 5323.2, "text": " so there you talk about something we've talked about way too little which is the political", "tokens": [50588, 370, 456, 291, 751, 466, 746, 321, 600, 2825, 466, 636, 886, 707, 597, 307, 264, 3905, 50760], "temperature": 0.0, "avg_logprob": -0.07027809436504658, "compression_ratio": 1.8015267175572518, "no_speech_prob": 0.020934641361236572}, {"id": 865, "seek": 531528, "start": 5323.2, "end": 5328.88, "text": " and social side of this so you know part of what has really motivated me in the last several months", "tokens": [50760, 293, 2093, 1252, 295, 341, 370, 291, 458, 644, 295, 437, 575, 534, 14515, 385, 294, 264, 1036, 2940, 2493, 51044], "temperature": 0.0, "avg_logprob": -0.07027809436504658, "compression_ratio": 1.8015267175572518, "no_speech_prob": 0.020934641361236572}, {"id": 866, "seek": 531528, "start": 5328.88, "end": 5333.599999999999, "text": " is worry about exactly that so you know there's there's what's logically possible and what's", "tokens": [51044, 307, 3292, 466, 2293, 300, 370, 291, 458, 456, 311, 456, 311, 437, 311, 38887, 1944, 293, 437, 311, 51280], "temperature": 0.0, "avg_logprob": -0.07027809436504658, "compression_ratio": 1.8015267175572518, "no_speech_prob": 0.020934641361236572}, {"id": 867, "seek": 531528, "start": 5333.599999999999, "end": 5339.12, "text": " politically possible and I am really concerned that the politics of let's not lose out to China", "tokens": [51280, 21154, 1944, 293, 286, 669, 534, 5922, 300, 264, 7341, 295, 718, 311, 406, 3624, 484, 281, 3533, 51556], "temperature": 0.0, "avg_logprob": -0.07027809436504658, "compression_ratio": 1.8015267175572518, "no_speech_prob": 0.020934641361236572}, {"id": 868, "seek": 533912, "start": 5339.92, "end": 5344.4, "text": " is going to keep us from doing the right thing in terms of building the right", "tokens": [50404, 307, 516, 281, 1066, 505, 490, 884, 264, 558, 551, 294, 2115, 295, 2390, 264, 558, 50628], "temperature": 0.0, "avg_logprob": -0.05669181914556594, "compression_ratio": 1.7923076923076924, "no_speech_prob": 0.37293845415115356}, {"id": 869, "seek": 533912, "start": 5344.4, "end": 5349.599999999999, "text": " moral systems looking at the right range of problems and so forth so you know it is entirely", "tokens": [50628, 9723, 3652, 1237, 412, 264, 558, 3613, 295, 2740, 293, 370, 5220, 370, 291, 458, 309, 307, 7696, 50888], "temperature": 0.0, "avg_logprob": -0.05669181914556594, "compression_ratio": 1.7923076923076924, "no_speech_prob": 0.37293845415115356}, {"id": 870, "seek": 533912, "start": 5349.599999999999, "end": 5354.5599999999995, "text": " possible that we will screw ourselves if I if I can just like finish my point there before handing", "tokens": [50888, 1944, 300, 321, 486, 5630, 4175, 498, 286, 498, 286, 393, 445, 411, 2413, 452, 935, 456, 949, 34774, 51136], "temperature": 0.0, "avg_logprob": -0.05669181914556594, "compression_ratio": 1.7923076923076924, "no_speech_prob": 0.37293845415115356}, {"id": 871, "seek": 533912, "start": 5354.5599999999995, "end": 5358.5599999999995, "text": " it to you indeed but like the point I was trying to say there is that even in worlds that look very", "tokens": [51136, 309, 281, 291, 6451, 457, 411, 264, 935, 286, 390, 1382, 281, 584, 456, 307, 300, 754, 294, 13401, 300, 574, 588, 51336], "temperature": 0.0, "avg_logprob": -0.05669181914556594, "compression_ratio": 1.7923076923076924, "no_speech_prob": 0.37293845415115356}, {"id": 872, "seek": 533912, "start": 5358.5599999999995, "end": 5364.32, "text": " very bad from that perspective where humanity is quite doomed it will still be true you can make", "tokens": [51336, 588, 1578, 490, 300, 4585, 689, 10243, 307, 1596, 33847, 309, 486, 920, 312, 2074, 291, 393, 652, 51624], "temperature": 0.0, "avg_logprob": -0.05669181914556594, "compression_ratio": 1.7923076923076924, "no_speech_prob": 0.37293845415115356}, {"id": 873, "seek": 536432, "start": 5364.32, "end": 5369.5199999999995, "text": " progress in research you can't make enough progress in research fast enough in those worlds", "tokens": [50364, 4205, 294, 2132, 291, 393, 380, 652, 1547, 4205, 294, 2132, 2370, 1547, 294, 729, 13401, 50624], "temperature": 0.0, "avg_logprob": -0.09532459651198343, "compression_ratio": 2.38, "no_speech_prob": 0.1987360268831253}, {"id": 874, "seek": 536432, "start": 5369.5199999999995, "end": 5375.2, "text": " but you can still make progress on transparency you can make progress on watermarking so there's", "tokens": [50624, 457, 291, 393, 920, 652, 4205, 322, 17131, 291, 393, 652, 4205, 322, 1281, 5638, 278, 370, 456, 311, 50908], "temperature": 0.0, "avg_logprob": -0.09532459651198343, "compression_ratio": 2.38, "no_speech_prob": 0.1987360268831253}, {"id": 875, "seek": 536432, "start": 5375.2, "end": 5381.12, "text": " there's not we can't just say like it's possible to make progress there has to be the question", "tokens": [50908, 456, 311, 406, 321, 393, 380, 445, 584, 411, 309, 311, 1944, 281, 652, 4205, 456, 575, 281, 312, 264, 1168, 51204], "temperature": 0.0, "avg_logprob": -0.09532459651198343, "compression_ratio": 2.38, "no_speech_prob": 0.1987360268831253}, {"id": 876, "seek": 536432, "start": 5381.12, "end": 5386.32, "text": " is not is it possible to make any progress the question is it is it possible to make enough", "tokens": [51204, 307, 406, 307, 309, 1944, 281, 652, 604, 4205, 264, 1168, 307, 309, 307, 309, 1944, 281, 652, 1547, 51464], "temperature": 0.0, "avg_logprob": -0.09532459651198343, "compression_ratio": 2.38, "no_speech_prob": 0.1987360268831253}, {"id": 877, "seek": 536432, "start": 5386.32, "end": 5393.36, "text": " progress fast enough and that's what the question has to be I agree there's another question of what", "tokens": [51464, 4205, 2370, 1547, 293, 300, 311, 437, 264, 1168, 575, 281, 312, 286, 3986, 456, 311, 1071, 1168, 295, 437, 51816], "temperature": 0.0, "avg_logprob": -0.09532459651198343, "compression_ratio": 2.38, "no_speech_prob": 0.1987360268831253}, {"id": 878, "seek": 539336, "start": 5393.36, "end": 5399.44, "text": " would you have us do would you have us not try to make that progress I'd have you try to make that", "tokens": [50364, 576, 291, 362, 505, 360, 576, 291, 362, 505, 406, 853, 281, 652, 300, 4205, 286, 1116, 362, 291, 853, 281, 652, 300, 50668], "temperature": 0.0, "avg_logprob": -0.10704355626492887, "compression_ratio": 1.7797619047619047, "no_speech_prob": 0.003536561271175742}, {"id": 879, "seek": 539336, "start": 5399.44, "end": 5407.5199999999995, "text": " progress on a GPT-4 level systems and then not go past GPT-4 level systems because we don't actually", "tokens": [50668, 4205, 322, 257, 26039, 51, 12, 19, 1496, 3652, 293, 550, 406, 352, 1791, 26039, 51, 12, 19, 1496, 3652, 570, 321, 500, 380, 767, 51072], "temperature": 0.0, "avg_logprob": -0.10704355626492887, "compression_ratio": 1.7797619047619047, "no_speech_prob": 0.003536561271175742}, {"id": 880, "seek": 539336, "start": 5407.5199999999995, "end": 5413.92, "text": " understand the the the gain function for you know how how fast capabilities increase as you go past", "tokens": [51072, 1223, 264, 264, 264, 6052, 2445, 337, 291, 458, 577, 577, 2370, 10862, 3488, 382, 291, 352, 1791, 51392], "temperature": 0.0, "avg_logprob": -0.10704355626492887, "compression_ratio": 1.7797619047619047, "no_speech_prob": 0.003536561271175742}, {"id": 881, "seek": 541392, "start": 5413.92, "end": 5420.16, "text": " GPT-4 okay all right so I mean we are going out I don't think that you go ahead Gary go ahead", "tokens": [50364, 26039, 51, 12, 19, 1392, 439, 558, 370, 286, 914, 321, 366, 516, 484, 286, 500, 380, 519, 300, 291, 352, 2286, 13788, 352, 2286, 50676], "temperature": 0.0, "avg_logprob": -0.16478893010303228, "compression_ratio": 1.7022222222222223, "no_speech_prob": 0.4760805368423462}, {"id": 882, "seek": 541392, "start": 5422.56, "end": 5428.8, "text": " just briefly I personally don't think that GPT-5 is going to be qualitatively different from GPT-4", "tokens": [50796, 445, 10515, 286, 5665, 500, 380, 519, 300, 26039, 51, 12, 20, 307, 516, 281, 312, 31312, 356, 819, 490, 26039, 51, 12, 19, 51108], "temperature": 0.0, "avg_logprob": -0.16478893010303228, "compression_ratio": 1.7022222222222223, "no_speech_prob": 0.4760805368423462}, {"id": 883, "seek": 541392, "start": 5428.8, "end": 5433.76, "text": " in the relevant ways to what Eleazar is talking about but I do think you know some qualitative", "tokens": [51108, 294, 264, 7340, 2098, 281, 437, 8024, 22795, 307, 1417, 466, 457, 286, 360, 519, 291, 458, 512, 31312, 51356], "temperature": 0.0, "avg_logprob": -0.16478893010303228, "compression_ratio": 1.7022222222222223, "no_speech_prob": 0.4760805368423462}, {"id": 884, "seek": 541392, "start": 5433.76, "end": 5439.6, "text": " changes could be relevant to what he's talking about we have no clue what they are and so it is", "tokens": [51356, 2962, 727, 312, 7340, 281, 437, 415, 311, 1417, 466, 321, 362, 572, 13602, 437, 436, 366, 293, 370, 309, 307, 51648], "temperature": 0.0, "avg_logprob": -0.16478893010303228, "compression_ratio": 1.7022222222222223, "no_speech_prob": 0.4760805368423462}, {"id": 885, "seek": 543960, "start": 5439.68, "end": 5445.92, "text": " a little bit dodgy to just proceed blindly saying do whatever you want we don't really have a theory", "tokens": [50368, 257, 707, 857, 13886, 1480, 281, 445, 8991, 47744, 1566, 360, 2035, 291, 528, 321, 500, 380, 534, 362, 257, 5261, 50680], "temperature": 0.0, "avg_logprob": -0.07033642927805582, "compression_ratio": 1.7455197132616487, "no_speech_prob": 0.23908552527427673}, {"id": 886, "seek": 543960, "start": 5445.92, "end": 5450.8, "text": " and let's hope for the best you know Eleazar I would mostly guess that GPT-5 doesn't end the", "tokens": [50680, 293, 718, 311, 1454, 337, 264, 1151, 291, 458, 8024, 22795, 286, 576, 5240, 2041, 300, 26039, 51, 12, 20, 1177, 380, 917, 264, 50924], "temperature": 0.0, "avg_logprob": -0.07033642927805582, "compression_ratio": 1.7455197132616487, "no_speech_prob": 0.23908552527427673}, {"id": 887, "seek": 543960, "start": 5450.8, "end": 5455.04, "text": " world but I don't actually know yeah we don't actually know and I was going to say the thing", "tokens": [50924, 1002, 457, 286, 500, 380, 767, 458, 1338, 321, 500, 380, 767, 458, 293, 286, 390, 516, 281, 584, 264, 551, 51136], "temperature": 0.0, "avg_logprob": -0.07033642927805582, "compression_ratio": 1.7455197132616487, "no_speech_prob": 0.23908552527427673}, {"id": 888, "seek": 543960, "start": 5455.04, "end": 5461.68, "text": " that Eleazar has said lately that has most resonated with me is we don't have a plan we really don't", "tokens": [51136, 300, 8024, 22795, 575, 848, 12881, 300, 575, 881, 47957, 365, 385, 307, 321, 500, 380, 362, 257, 1393, 321, 534, 500, 380, 51468], "temperature": 0.0, "avg_logprob": -0.07033642927805582, "compression_ratio": 1.7455197132616487, "no_speech_prob": 0.23908552527427673}, {"id": 889, "seek": 543960, "start": 5461.68, "end": 5467.200000000001, "text": " like I think I put the probability distributions in a much more optimistic way I think that Eleazar", "tokens": [51468, 411, 286, 519, 286, 829, 264, 8482, 37870, 294, 257, 709, 544, 19397, 636, 286, 519, 300, 8024, 22795, 51744], "temperature": 0.0, "avg_logprob": -0.07033642927805582, "compression_ratio": 1.7455197132616487, "no_speech_prob": 0.23908552527427673}, {"id": 890, "seek": 546720, "start": 5467.84, "end": 5473.36, "text": " would but I completely agree we don't have a full plan on these things or even close to a full plan", "tokens": [50396, 576, 457, 286, 2584, 3986, 321, 500, 380, 362, 257, 1577, 1393, 322, 613, 721, 420, 754, 1998, 281, 257, 1577, 1393, 50672], "temperature": 0.0, "avg_logprob": -0.09802644546717813, "compression_ratio": 1.697142857142857, "no_speech_prob": 0.006902804598212242}, {"id": 891, "seek": 546720, "start": 5473.36, "end": 5479.44, "text": " and we should be worried and we should be working on this okay Scott I'm going to give you the last", "tokens": [50672, 293, 321, 820, 312, 5804, 293, 321, 820, 312, 1364, 322, 341, 1392, 6659, 286, 478, 516, 281, 976, 291, 264, 1036, 50976], "temperature": 0.0, "avg_logprob": -0.09802644546717813, "compression_ratio": 1.697142857142857, "no_speech_prob": 0.006902804598212242}, {"id": 892, "seek": 546720, "start": 5479.44, "end": 5488.16, "text": " word before before we come up on our stop time here unless you unless you said all there is to be", "tokens": [50976, 1349, 949, 949, 321, 808, 493, 322, 527, 1590, 565, 510, 5969, 291, 5969, 291, 848, 439, 456, 307, 281, 312, 51412], "temperature": 0.0, "avg_logprob": -0.09802644546717813, "compression_ratio": 1.697142857142857, "no_speech_prob": 0.006902804598212242}, {"id": 893, "seek": 548816, "start": 5488.32, "end": 5494.8, "text": " a weighty responsibility maybe enough has been said cheers up Scott come on", "tokens": [50372, 257, 3364, 88, 6357, 1310, 1547, 575, 668, 848, 15301, 493, 6659, 808, 322, 50696], "temperature": 0.0, "avg_logprob": -0.18250667274772348, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.12927992641925812}, {"id": 894, "seek": 548816, "start": 5496.72, "end": 5502.32, "text": " so so I think that that you know we've we've argued about a bunch of things but you know", "tokens": [50792, 370, 370, 286, 519, 300, 300, 291, 458, 321, 600, 321, 600, 20219, 466, 257, 3840, 295, 721, 457, 291, 458, 51072], "temperature": 0.0, "avg_logprob": -0.18250667274772348, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.12927992641925812}, {"id": 895, "seek": 548816, "start": 5502.32, "end": 5507.76, "text": " as someone listening might notice that actually all three of us despite having very different", "tokens": [51072, 382, 1580, 4764, 1062, 3449, 300, 767, 439, 1045, 295, 505, 7228, 1419, 588, 819, 51344], "temperature": 0.0, "avg_logprob": -0.18250667274772348, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.12927992641925812}, {"id": 896, "seek": 548816, "start": 5507.76, "end": 5516.96, "text": " perspectives agree about you know the the great importance of of you know working on AI alignment", "tokens": [51344, 16766, 3986, 466, 291, 458, 264, 264, 869, 7379, 295, 295, 291, 458, 1364, 322, 7318, 18515, 51804], "temperature": 0.0, "avg_logprob": -0.18250667274772348, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.12927992641925812}, {"id": 897, "seek": 551696, "start": 5517.04, "end": 5525.92, "text": " I think you know that was you know maybe obvious to some people including Eleazar for a long time", "tokens": [50368, 286, 519, 291, 458, 300, 390, 291, 458, 1310, 6322, 281, 512, 561, 3009, 8024, 22795, 337, 257, 938, 565, 50812], "temperature": 0.0, "avg_logprob": -0.05064182811313205, "compression_ratio": 1.8151658767772512, "no_speech_prob": 0.0021761527750641108}, {"id": 898, "seek": 551696, "start": 5525.92, "end": 5532.72, "text": " it was not obvious to most of the world I think that you know the the success of of large language", "tokens": [50812, 309, 390, 406, 6322, 281, 881, 295, 264, 1002, 286, 519, 300, 291, 458, 264, 264, 2245, 295, 295, 2416, 2856, 51152], "temperature": 0.0, "avg_logprob": -0.05064182811313205, "compression_ratio": 1.8151658767772512, "no_speech_prob": 0.0021761527750641108}, {"id": 899, "seek": 551696, "start": 5532.72, "end": 5540.08, "text": " models you know which most of us did not predict you know maybe even could not have predicted", "tokens": [51152, 5245, 291, 458, 597, 881, 295, 505, 630, 406, 6069, 291, 458, 1310, 754, 727, 406, 362, 19147, 51520], "temperature": 0.0, "avg_logprob": -0.05064182811313205, "compression_ratio": 1.8151658767772512, "no_speech_prob": 0.0021761527750641108}, {"id": 900, "seek": 551696, "start": 5540.72, "end": 5546.24, "text": " for many principles that we knew but now that we've seen it the least we can do is to update", "tokens": [51552, 337, 867, 9156, 300, 321, 2586, 457, 586, 300, 321, 600, 1612, 309, 264, 1935, 321, 393, 360, 307, 281, 5623, 51828], "temperature": 0.0, "avg_logprob": -0.05064182811313205, "compression_ratio": 1.8151658767772512, "no_speech_prob": 0.0021761527750641108}, {"id": 901, "seek": 554624, "start": 5546.24, "end": 5554.48, "text": " on that on that empirical fact and and realize that you know we we we now are in some sense in a", "tokens": [50364, 322, 300, 322, 300, 31886, 1186, 293, 293, 4325, 300, 291, 458, 321, 321, 321, 586, 366, 294, 512, 2020, 294, 257, 50776], "temperature": 0.0, "avg_logprob": -0.0847575975501019, "compression_ratio": 1.8762376237623761, "no_speech_prob": 0.0007205025176517665}, {"id": 902, "seek": 554624, "start": 5554.48, "end": 5560.4, "text": " different world we are in a world that you know to a great extent you know will be defined by", "tokens": [50776, 819, 1002, 321, 366, 294, 257, 1002, 300, 291, 458, 281, 257, 869, 8396, 291, 458, 486, 312, 7642, 538, 51072], "temperature": 0.0, "avg_logprob": -0.0847575975501019, "compression_ratio": 1.8762376237623761, "no_speech_prob": 0.0007205025176517665}, {"id": 903, "seek": 554624, "start": 5560.4, "end": 5567.84, "text": " you know the capabilities and limitations of AI going forward and you know I don't regard it as", "tokens": [51072, 291, 458, 264, 10862, 293, 15705, 295, 7318, 516, 2128, 293, 291, 458, 286, 500, 380, 3843, 309, 382, 51444], "temperature": 0.0, "avg_logprob": -0.0847575975501019, "compression_ratio": 1.8762376237623761, "no_speech_prob": 0.0007205025176517665}, {"id": 904, "seek": 554624, "start": 5567.84, "end": 5574.88, "text": " obvious that that's a a a world where where we are all doomed where where we all die but you", "tokens": [51444, 6322, 300, 300, 311, 257, 257, 257, 1002, 689, 689, 321, 366, 439, 33847, 689, 689, 321, 439, 978, 457, 291, 51796], "temperature": 0.0, "avg_logprob": -0.0847575975501019, "compression_ratio": 1.8762376237623761, "no_speech_prob": 0.0007205025176517665}, {"id": 905, "seek": 557488, "start": 5574.88, "end": 5582.16, "text": " know I also don't dismiss that possibility I think that you know there there is an enormous", "tokens": [50364, 458, 286, 611, 500, 380, 16974, 300, 7959, 286, 519, 300, 291, 458, 456, 456, 307, 364, 11322, 50728], "temperature": 0.0, "avg_logprob": -0.06929531551542736, "compression_ratio": 1.8142857142857143, "no_speech_prob": 0.0032534978818148375}, {"id": 906, "seek": 557488, "start": 5582.96, "end": 5590.0, "text": " unbelievably enormous error bars on on on where we could be going and you know like the one thing", "tokens": [50768, 43593, 11322, 6713, 10228, 322, 322, 322, 689, 321, 727, 312, 516, 293, 291, 458, 411, 264, 472, 551, 51120], "temperature": 0.0, "avg_logprob": -0.06929531551542736, "compression_ratio": 1.8142857142857143, "no_speech_prob": 0.0032534978818148375}, {"id": 907, "seek": 557488, "start": 5590.0, "end": 5597.36, "text": " you know that that a scientist is sort of always always feels confident in in saying about the", "tokens": [51120, 291, 458, 300, 300, 257, 12662, 307, 1333, 295, 1009, 1009, 3417, 6679, 294, 294, 1566, 466, 264, 51488], "temperature": 0.0, "avg_logprob": -0.06929531551542736, "compression_ratio": 1.8142857142857143, "no_speech_prob": 0.0032534978818148375}, {"id": 908, "seek": 557488, "start": 5597.36, "end": 5603.6, "text": " future is that more research is needed but you know I think that that's especially the case here", "tokens": [51488, 2027, 307, 300, 544, 2132, 307, 2978, 457, 291, 458, 286, 519, 300, 300, 311, 2318, 264, 1389, 510, 51800], "temperature": 0.0, "avg_logprob": -0.06929531551542736, "compression_ratio": 1.8142857142857143, "no_speech_prob": 0.0032534978818148375}, {"id": 909, "seek": 560360, "start": 5603.6, "end": 5610.88, "text": " I mean you know we need more knowledge about you know what are the the contours of the alignment", "tokens": [50364, 286, 914, 291, 458, 321, 643, 544, 3601, 466, 291, 458, 437, 366, 264, 264, 660, 5067, 295, 264, 18515, 50728], "temperature": 0.0, "avg_logprob": -0.09519025649147472, "compression_ratio": 1.8267326732673268, "no_speech_prob": 0.002211940009146929}, {"id": 910, "seek": 560360, "start": 5610.88, "end": 5617.84, "text": " problem and you know of course Eliezer and you know Amiri you know his his organization were", "tokens": [50728, 1154, 293, 291, 458, 295, 1164, 2699, 414, 4527, 293, 291, 458, 2012, 12988, 291, 458, 702, 702, 4475, 645, 51076], "temperature": 0.0, "avg_logprob": -0.09519025649147472, "compression_ratio": 1.8267326732673268, "no_speech_prob": 0.002211940009146929}, {"id": 911, "seek": 560360, "start": 5617.84, "end": 5622.320000000001, "text": " trying to develop that knowledge for 20 years you know and they showed a lot of foresight in", "tokens": [51076, 1382, 281, 1499, 300, 3601, 337, 945, 924, 291, 458, 293, 436, 4712, 257, 688, 295, 2091, 28654, 294, 51300], "temperature": 0.0, "avg_logprob": -0.09519025649147472, "compression_ratio": 1.8267326732673268, "no_speech_prob": 0.002211940009146929}, {"id": 912, "seek": 560360, "start": 5623.04, "end": 5627.92, "text": " trying to do that but you know they were up against you know an enormous headwind that", "tokens": [51336, 1382, 281, 360, 300, 457, 291, 458, 436, 645, 493, 1970, 291, 458, 364, 11322, 1378, 12199, 300, 51580], "temperature": 0.0, "avg_logprob": -0.09519025649147472, "compression_ratio": 1.8267326732673268, "no_speech_prob": 0.002211940009146929}, {"id": 913, "seek": 562792, "start": 5627.92, "end": 5632.96, "text": " you know they were sort of trying to do it in the absence of you know either you know clear", "tokens": [50364, 291, 458, 436, 645, 1333, 295, 1382, 281, 360, 309, 294, 264, 17145, 295, 291, 458, 2139, 291, 458, 1850, 50616], "temperature": 0.0, "avg_logprob": -0.05198583602905273, "compression_ratio": 1.9576271186440677, "no_speech_prob": 0.051777396351099014}, {"id": 914, "seek": 562792, "start": 5632.96, "end": 5639.6, "text": " empirical data you know about powerful ai's or a mathematical theory right and it's really really", "tokens": [50616, 31886, 1412, 291, 458, 466, 4005, 9783, 311, 420, 257, 18894, 5261, 558, 293, 309, 311, 534, 534, 50948], "temperature": 0.0, "avg_logprob": -0.05198583602905273, "compression_ratio": 1.9576271186440677, "no_speech_prob": 0.051777396351099014}, {"id": 915, "seek": 562792, "start": 5639.6, "end": 5644.4800000000005, "text": " hard to do science when you have neither of those two things and now at least we have", "tokens": [50948, 1152, 281, 360, 3497, 562, 291, 362, 9662, 295, 729, 732, 721, 293, 586, 412, 1935, 321, 362, 51192], "temperature": 0.0, "avg_logprob": -0.05198583602905273, "compression_ratio": 1.9576271186440677, "no_speech_prob": 0.051777396351099014}, {"id": 916, "seek": 562792, "start": 5645.52, "end": 5650.8, "text": " you know the powerful ai's in the world and we can get experience from them you know we still", "tokens": [51244, 291, 458, 264, 4005, 9783, 311, 294, 264, 1002, 293, 321, 393, 483, 1752, 490, 552, 291, 458, 321, 920, 51508], "temperature": 0.0, "avg_logprob": -0.05198583602905273, "compression_ratio": 1.9576271186440677, "no_speech_prob": 0.051777396351099014}, {"id": 917, "seek": 562792, "start": 5650.8, "end": 5655.6, "text": " don't have a mathematical theory that really deeply explains what they're doing but at least", "tokens": [51508, 500, 380, 362, 257, 18894, 5261, 300, 534, 8760, 13948, 437, 436, 434, 884, 457, 412, 1935, 51748], "temperature": 0.0, "avg_logprob": -0.05198583602905273, "compression_ratio": 1.9576271186440677, "no_speech_prob": 0.051777396351099014}, {"id": 918, "seek": 565560, "start": 5655.6, "end": 5662.320000000001, "text": " we can get data and so now I am much more optimistic than I would have been you know a decade ago", "tokens": [50364, 321, 393, 483, 1412, 293, 370, 586, 286, 669, 709, 544, 19397, 813, 286, 576, 362, 668, 291, 458, 257, 10378, 2057, 50700], "temperature": 0.0, "avg_logprob": -0.08268323641144827, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.002247449243441224}, {"id": 919, "seek": 565560, "start": 5662.320000000001, "end": 5669.360000000001, "text": " let's say that one could make actual progress on on on the ai alignment problem you know of course", "tokens": [50700, 718, 311, 584, 300, 472, 727, 652, 3539, 4205, 322, 322, 322, 264, 9783, 18515, 1154, 291, 458, 295, 1164, 51052], "temperature": 0.0, "avg_logprob": -0.08268323641144827, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.002247449243441224}, {"id": 920, "seek": 565560, "start": 5669.360000000001, "end": 5676.8, "text": " you know there was a question of timing as as was discussed many times the question is you know will", "tokens": [51052, 291, 458, 456, 390, 257, 1168, 295, 10822, 382, 382, 390, 7152, 867, 1413, 264, 1168, 307, 291, 458, 486, 51424], "temperature": 0.0, "avg_logprob": -0.08268323641144827, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.002247449243441224}, {"id": 921, "seek": 565560, "start": 5676.8, "end": 5683.04, "text": " the alignment research happen fast enough to keep up with the capabilities research but you know I", "tokens": [51424, 264, 18515, 2132, 1051, 2370, 1547, 281, 1066, 493, 365, 264, 10862, 2132, 457, 291, 458, 286, 51736], "temperature": 0.0, "avg_logprob": -0.08268323641144827, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.002247449243441224}, {"id": 922, "seek": 568304, "start": 5683.04, "end": 5688.16, "text": " don't I don't regard it as a lost cause you know it's at least it's not obvious that it won't so", "tokens": [50364, 500, 380, 286, 500, 380, 3843, 309, 382, 257, 2731, 3082, 291, 458, 309, 311, 412, 1935, 309, 311, 406, 6322, 300, 309, 1582, 380, 370, 50620], "temperature": 0.0, "avg_logprob": -0.10151471541478084, "compression_ratio": 1.8846153846153846, "no_speech_prob": 0.008038723841309547}, {"id": 923, "seek": 568304, "start": 5688.16, "end": 5694.16, "text": " you know in any case let's get started or let's let's uh or let's let's continue let's let's let's", "tokens": [50620, 291, 458, 294, 604, 1389, 718, 311, 483, 1409, 420, 718, 311, 718, 311, 2232, 420, 718, 311, 718, 311, 2354, 718, 311, 718, 311, 718, 311, 50920], "temperature": 0.0, "avg_logprob": -0.10151471541478084, "compression_ratio": 1.8846153846153846, "no_speech_prob": 0.008038723841309547}, {"id": 924, "seek": 568304, "start": 5694.16, "end": 5700.16, "text": " try to do the research and let's get more people working on that I think that that that is now uh", "tokens": [50920, 853, 281, 360, 264, 2132, 293, 718, 311, 483, 544, 561, 1364, 322, 300, 286, 519, 300, 300, 300, 307, 586, 2232, 51220], "temperature": 0.0, "avg_logprob": -0.10151471541478084, "compression_ratio": 1.8846153846153846, "no_speech_prob": 0.008038723841309547}, {"id": 925, "seek": 568304, "start": 5700.16, "end": 5707.6, "text": " a slam dunk you know just a completely clear case to make to you know academics to policymakers to", "tokens": [51220, 257, 25617, 33555, 291, 458, 445, 257, 2584, 1850, 1389, 281, 652, 281, 291, 458, 25695, 281, 47325, 281, 51592], "temperature": 0.0, "avg_logprob": -0.10151471541478084, "compression_ratio": 1.8846153846153846, "no_speech_prob": 0.008038723841309547}, {"id": 926, "seek": 570760, "start": 5707.68, "end": 5713.120000000001, "text": " to anyone who's interested and you know I've been gratified that that you know uh you know", "tokens": [50368, 281, 2878, 567, 311, 3102, 293, 291, 458, 286, 600, 668, 10158, 2587, 300, 300, 291, 458, 2232, 291, 458, 50640], "temperature": 0.0, "avg_logprob": -0.11380116835884425, "compression_ratio": 1.761467889908257, "no_speech_prob": 0.08149001747369766}, {"id": 927, "seek": 570760, "start": 5713.120000000001, "end": 5718.160000000001, "text": " aliezer was sort of a voice in the wilderness for for a long time talking about the importance of", "tokens": [50640, 419, 414, 4527, 390, 1333, 295, 257, 3177, 294, 264, 27613, 337, 337, 257, 938, 565, 1417, 466, 264, 7379, 295, 50892], "temperature": 0.0, "avg_logprob": -0.11380116835884425, "compression_ratio": 1.761467889908257, "no_speech_prob": 0.08149001747369766}, {"id": 928, "seek": 570760, "start": 5718.160000000001, "end": 5724.96, "text": " ai safety that is no longer the case uh you now have you know you know I mean almost all of my", "tokens": [50892, 9783, 4514, 300, 307, 572, 2854, 264, 1389, 2232, 291, 586, 362, 291, 458, 291, 458, 286, 914, 1920, 439, 295, 452, 51232], "temperature": 0.0, "avg_logprob": -0.11380116835884425, "compression_ratio": 1.761467889908257, "no_speech_prob": 0.08149001747369766}, {"id": 929, "seek": 570760, "start": 5724.96, "end": 5730.56, "text": " friends in you know in just the academic computer science world you know when I see them they mostly", "tokens": [51232, 1855, 294, 291, 458, 294, 445, 264, 7778, 3820, 3497, 1002, 291, 458, 562, 286, 536, 552, 436, 5240, 51512], "temperature": 0.0, "avg_logprob": -0.11380116835884425, "compression_ratio": 1.761467889908257, "no_speech_prob": 0.08149001747369766}, {"id": 930, "seek": 573056, "start": 5730.56, "end": 5740.4800000000005, "text": " want to talk about AI alignment I rarely agree with Scott when we trade email um I rarely agree", "tokens": [50364, 528, 281, 751, 466, 7318, 18515, 286, 13752, 3986, 365, 6659, 562, 321, 4923, 3796, 1105, 286, 13752, 3986, 50860], "temperature": 0.0, "avg_logprob": -0.14967249775980854, "compression_ratio": 1.7837837837837838, "no_speech_prob": 0.31720587611198425}, {"id": 931, "seek": 573056, "start": 5740.4800000000005, "end": 5745.6, "text": " with Scott when we trade emails we seem to always disagree but I completely concur with the summary", "tokens": [50860, 365, 6659, 562, 321, 4923, 12524, 321, 1643, 281, 1009, 14091, 457, 286, 2584, 23702, 365, 264, 12691, 51116], "temperature": 0.0, "avg_logprob": -0.14967249775980854, "compression_ratio": 1.7837837837837838, "no_speech_prob": 0.31720587611198425}, {"id": 932, "seek": 573056, "start": 5745.6, "end": 5751.200000000001, "text": " that he just gave all four or five minutes of it well thank you I mean I mean there is a selection", "tokens": [51116, 300, 415, 445, 2729, 439, 1451, 420, 1732, 2077, 295, 309, 731, 1309, 291, 286, 914, 286, 914, 456, 307, 257, 9450, 51396], "temperature": 0.0, "avg_logprob": -0.14967249775980854, "compression_ratio": 1.7837837837837838, "no_speech_prob": 0.31720587611198425}, {"id": 933, "seek": 573056, "start": 5751.200000000001, "end": 5756.56, "text": " effect Gary right we focus on things I think the two decades gave me a sense of a roadmap and it gave", "tokens": [51396, 1802, 13788, 558, 321, 1879, 322, 721, 286, 519, 264, 732, 7878, 2729, 385, 257, 2020, 295, 257, 35738, 293, 309, 2729, 51664], "temperature": 0.0, "avg_logprob": -0.14967249775980854, "compression_ratio": 1.7837837837837838, "no_speech_prob": 0.31720587611198425}, {"id": 934, "seek": 575656, "start": 5756.56, "end": 5762.240000000001, "text": " me a sense that we're falling enormously behind on the roadmap I need to back off as the way I", "tokens": [50364, 385, 257, 2020, 300, 321, 434, 7440, 39669, 2261, 322, 264, 35738, 286, 643, 281, 646, 766, 382, 264, 636, 286, 50648], "temperature": 0.0, "avg_logprob": -0.1220543799193009, "compression_ratio": 1.6265560165975104, "no_speech_prob": 0.017437193542718887}, {"id": 935, "seek": 575656, "start": 5762.240000000001, "end": 5768.400000000001, "text": " is what I would say to all that if there is a smart talented 18 year old kid listening listening to", "tokens": [50648, 307, 437, 286, 576, 584, 281, 439, 300, 498, 456, 307, 257, 4069, 13467, 2443, 1064, 1331, 1636, 4764, 4764, 281, 50956], "temperature": 0.0, "avg_logprob": -0.1220543799193009, "compression_ratio": 1.6265560165975104, "no_speech_prob": 0.017437193542718887}, {"id": 936, "seek": 575656, "start": 5768.400000000001, "end": 5775.52, "text": " this podcast who wants to get into this issue what is your 10 second concrete advice to that person", "tokens": [50956, 341, 7367, 567, 2738, 281, 483, 666, 341, 2734, 437, 307, 428, 1266, 1150, 9859, 5192, 281, 300, 954, 51312], "temperature": 0.0, "avg_logprob": -0.1220543799193009, "compression_ratio": 1.6265560165975104, "no_speech_prob": 0.017437193542718887}, {"id": 937, "seek": 575656, "start": 5777.200000000001, "end": 5783.200000000001, "text": " mine is study neurosymbolic AI and see if there's a way there to represent values explicitly that", "tokens": [51396, 3892, 307, 2979, 28813, 88, 5612, 299, 7318, 293, 536, 498, 456, 311, 257, 636, 456, 281, 2906, 4190, 20803, 300, 51696], "temperature": 0.0, "avg_logprob": -0.1220543799193009, "compression_ratio": 1.6265560165975104, "no_speech_prob": 0.017437193542718887}, {"id": 938, "seek": 578320, "start": 5783.2, "end": 5791.599999999999, "text": " might help us learn all you can about computer science and math and related subjects and think", "tokens": [50364, 1062, 854, 505, 1466, 439, 291, 393, 466, 3820, 3497, 293, 5221, 293, 4077, 13066, 293, 519, 50784], "temperature": 0.0, "avg_logprob": -0.07267961176958951, "compression_ratio": 1.768181818181818, "no_speech_prob": 0.017431411892175674}, {"id": 939, "seek": 578320, "start": 5791.599999999999, "end": 5800.8, "text": " outside the box and wow everyone with a new idea get security mindset figure out what's going to go", "tokens": [50784, 2380, 264, 2424, 293, 6076, 1518, 365, 257, 777, 1558, 483, 3825, 12543, 2573, 484, 437, 311, 516, 281, 352, 51244], "temperature": 0.0, "avg_logprob": -0.07267961176958951, "compression_ratio": 1.768181818181818, "no_speech_prob": 0.017431411892175674}, {"id": 940, "seek": 578320, "start": 5800.8, "end": 5806.4, "text": " wrong figure out the flaws in your arguments for what's going to go wrong try to get ahead of the", "tokens": [51244, 2085, 2573, 484, 264, 27108, 294, 428, 12869, 337, 437, 311, 516, 281, 352, 2085, 853, 281, 483, 2286, 295, 264, 51524], "temperature": 0.0, "avg_logprob": -0.07267961176958951, "compression_ratio": 1.768181818181818, "no_speech_prob": 0.017431411892175674}, {"id": 941, "seek": 578320, "start": 5806.4, "end": 5811.84, "text": " curve don't wait for reality to hit you over the head with things uh this this is very difficult", "tokens": [51524, 7605, 500, 380, 1699, 337, 4103, 281, 2045, 291, 670, 264, 1378, 365, 721, 2232, 341, 341, 307, 588, 2252, 51796], "temperature": 0.0, "avg_logprob": -0.07267961176958951, "compression_ratio": 1.768181818181818, "no_speech_prob": 0.017431411892175674}, {"id": 942, "seek": 581184, "start": 5811.84, "end": 5815.68, "text": " the people in evolutionary biology happen to have a bunch of knowledge about how to do it based on", "tokens": [50364, 264, 561, 294, 27567, 14956, 1051, 281, 362, 257, 3840, 295, 3601, 466, 577, 281, 360, 309, 2361, 322, 50556], "temperature": 0.0, "avg_logprob": -0.09577557775709364, "compression_ratio": 1.8199233716475096, "no_speech_prob": 0.015897437930107117}, {"id": 943, "seek": 581184, "start": 5815.68, "end": 5822.16, "text": " the history of their own field but uh and and and the security mindset people in computer security", "tokens": [50556, 264, 2503, 295, 641, 1065, 2519, 457, 2232, 293, 293, 293, 264, 3825, 12543, 561, 294, 3820, 3825, 50880], "temperature": 0.0, "avg_logprob": -0.09577557775709364, "compression_ratio": 1.8199233716475096, "no_speech_prob": 0.015897437930107117}, {"id": 944, "seek": 581184, "start": 5822.16, "end": 5828.16, "text": " but it's it's quite hard I'll drink to all of that thanks thanks to all three of you for this", "tokens": [50880, 457, 309, 311, 309, 311, 1596, 1152, 286, 603, 2822, 281, 439, 295, 300, 3231, 3231, 281, 439, 1045, 295, 291, 337, 341, 51180], "temperature": 0.0, "avg_logprob": -0.09577557775709364, "compression_ratio": 1.8199233716475096, "no_speech_prob": 0.015897437930107117}, {"id": 945, "seek": 581184, "start": 5828.16, "end": 5832.96, "text": " this was a great conversation and I hope people got something out of it so with that said", "tokens": [51180, 341, 390, 257, 869, 3761, 293, 286, 1454, 561, 658, 746, 484, 295, 309, 370, 365, 300, 848, 51420], "temperature": 0.0, "avg_logprob": -0.09577557775709364, "compression_ratio": 1.8199233716475096, "no_speech_prob": 0.015897437930107117}, {"id": 946, "seek": 581184, "start": 5834.08, "end": 5839.28, "text": " we're wrapped up thanks so much that's it for this episode of conversations with Coleman guys", "tokens": [51476, 321, 434, 14226, 493, 3231, 370, 709, 300, 311, 309, 337, 341, 3500, 295, 7315, 365, 49930, 1074, 51736], "temperature": 0.0, "avg_logprob": -0.09577557775709364, "compression_ratio": 1.8199233716475096, "no_speech_prob": 0.015897437930107117}, {"id": 947, "seek": 583928, "start": 5839.28, "end": 5844.32, "text": " as always thanks for watching and feel free to tell me what you think by reviewing the podcast", "tokens": [50364, 382, 1009, 3231, 337, 1976, 293, 841, 1737, 281, 980, 385, 437, 291, 519, 538, 19576, 264, 7367, 50616], "temperature": 0.0, "avg_logprob": -0.08416161998625725, "compression_ratio": 1.615819209039548, "no_speech_prob": 0.25337547063827515}, {"id": 948, "seek": 583928, "start": 5844.32, "end": 5849.44, "text": " commenting on social media or sending me an email to check out my other social media platforms", "tokens": [50616, 29590, 322, 2093, 3021, 420, 7750, 385, 364, 3796, 281, 1520, 484, 452, 661, 2093, 3021, 9473, 50872], "temperature": 0.0, "avg_logprob": -0.08416161998625725, "compression_ratio": 1.615819209039548, "no_speech_prob": 0.25337547063827515}, {"id": 949, "seek": 583928, "start": 5849.44, "end": 5857.759999999999, "text": " click the cards you see on screen and don't forget to like share and subscribe see you next time", "tokens": [50872, 2052, 264, 5632, 291, 536, 322, 2568, 293, 500, 380, 2870, 281, 411, 2073, 293, 3022, 536, 291, 958, 565, 51288], "temperature": 0.0, "avg_logprob": -0.08416161998625725, "compression_ratio": 1.615819209039548, "no_speech_prob": 0.25337547063827515}], "language": "en"}