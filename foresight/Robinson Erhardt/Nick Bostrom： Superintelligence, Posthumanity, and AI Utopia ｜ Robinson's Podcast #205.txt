If you sort of zoom out, you look like we are right now in the middle of this like explosion of some
sec and we don't know what it's going to end up like but but I do believe as you alluded to earlier
that scenarios in which we just remain more or less like we are now and have the current human
condition just keep going for like tens of thousands of years that just seems extremely improbable to
me relative to either like extinction slash dystopia or some radical transformation into some kind of
posthumous condition. Hello this is Robinson Earhart here with the introduction to Robinson's
podcast number 205 and this episode is with Nick Bostrom a philosopher of artificial intelligence
and many other subjects who was most recently professor of philosophy at Oxford University where
he also served as the founding director of the Future of Humanity Institute. Nick is likely best
known in the public eye for his work on the simulation argument which is the idea that we live
not in the familiar physical world that we believe we inhabit but a simulation of one but he's also
well known for his book Super Intelligence which covers the dangers of artificial intelligence
and strategies for dealing with them. In this episode though Nick and I talk about his more
recent book Deep Utopia Life and Meaning in a Solved World which just came out in March actually
and opposed to get as opposed to getting into the existential dangers of AI which Nick tackles in
super intelligence deep utopia considers the sorts of concerns that might arise if everything
actually goes right with AI. So after talking about the alignment problem and some other fundamental
issues in the philosophy of AI we talk about the problems that might come from having perfect
technology from immortality from not having to work anymore from having robots that can do all
your hobbies better than you can do and more. Likes, comments, subscribes, reviews as you know all of
these things are always extremely appreciated. There is also a patreon if you would like a link
to an ad for your rss feed or show notes and to all those of you who are patrons who are geeslings
thank you so much for your support. But now without any further ado I hope that you enjoy
this conversation as much as I enjoyed having in with Nick.
You're one of the most widely recognized philosophers in the in the public sphere
and mainly known in that capacity I think for thinking about dystopian AI scenarios scenarios
and other existential threats so right off the bat I'm wondering what motivated this shift to
thinking about utopias. Now both sides have always been present in my mind and my outlook. Back when
I was writing super intelligence this 2014 book which was in the works six years prior to that I
felt it was more urgent to focus on what could go wrong with AI figure out where the pitfalls were
so that we could avoid them. This was a time at which the whole idea of AI posing any kind of
existential risk or even just having any kind of transformative impact on society was still
far outside the mainstream. The whole idea of the alignment problem was not in the
overton window that were like maybe a handful of people scattered around the world kind of internet
type so we're trying to work on this and it just seemed hugely neglected to me so I thought writing
this book super intelligence trying to develop concepts that would make it possible for people
to start to think more constructively about this and begin to do research on developing scalable
methods for alignment was important. In the intervening years we've seen a big shift now all
the frontier AI labs have research teams specifically trying to develop scalable methods for AI
control and there are many other organizations as well where a lot of the smartest young people I
know now are like flooding into this field and in the last two years we've also seen a big shift
at the level of policy conversation where even top tier policy makers are now beginning to
recognize the transformative impact of future AI developments with statements coming out from the
White House and the UK hosted this global summit on AI. I was just the other week in Brussels for
a however meeting and so to some extent that whole thing is now widely recognized and many of
me feel a work on it. I felt the other side of what happens if things go right with AI had
not yet really been addressed or people talk about it but often in a rather superficial way
but once you start to dig in you realize there are actually quite
deep even philosophical problems that come up when you imagine like what would give human life
purpose and meaning in this condition where in a solved world as I call it like we're all practical
problems that can be solved through progress have already been solved and so that's how the book
it wasn't really so much a plan to write the book it more kind of happened as sometimes
is the way of these things like you start writing a little and then it takes on a life of its own
and you just try to hold on less the thing gradually develops. I can tell that this book
really did take on a life of its own just because of the the various formats in which you wrote it
and I mean there's there's poetry there's dialogue there's standard exposition so it was
clearly a very creative project in a way that I mean philosophical articles are still creative but
it's more of an intellectual creativity than an artistic creativity. Yeah some people maybe think
they should have been a sort of more tough minded editor hovering over me to kind of
but it actually does serve a purpose well for a start it's less a book about conclusions than
it is about questions and exploration and I think this format with multiple different characters
and voices helps you explore several different sides giving each one their due and letting them
speak for themselves different values. So that's one reason for I think the form kind of works
for the content the other is that the goal of the book is well in part to try to give the reader
various concepts and considerations and such that they can you know better think about these things
but another part is to try to put somebody in the right frame of mind for confronting these
if you imagine that will actually perhaps at some point be some group of people who will have to
form some opinions about what we want long term from these AI developments you know whether it's
a few people in some lab or a government or some more humanity-wide deliberation process
these are really difficult questions to deliberate about and I would like people who go into that to
come at it with a certain attitude so a kind of broad-minded generosity combined with some
playfulness and thoughtfulness and open-mindedness which I'm hoping that the book encourages and
I think that those creative elements are also meant to contribute to that. That it is a long
it's a long read so it is also maybe an antidote to short attention spans issue.
Well before we move on to some of the substantive issues just a couple of comments it really was
a great way of delivering a number of concepts to the reader I mean before reading this book
I just thought of utopia as kind of a blanket concept but now I realize and we'll get into it
there are various different types of utopias each of which have their own problems and considerations
to keep in mind and then you said that this book tackles very deep problems about meaning and it's
also I think very useful as a thought experiment for testing an extended thought experiment for
testing our intuitions about meaning in the present so it's not just like it's useful for these
future utopian scenarios it's very useful for thinking about our lives today for instance
there's a passage on shopping that resonated with me very much as somebody who enjoys shopping but
returning to the substance two things that you mentioned right at the outset that I think we
should pin down for our listeners who might not have read superintelligence are one what
superintelligence is since that's vital for the understanding of a deep utopia and then also
what this alignment problem is because even though we will presuppose that it has been solved for a
lot of this conversation I think it's still important to understand what it is. Yeah well so
superintelligence is kind of any intellectual system that radically outperforms all humans in
all cognitive fields and so including you know scientific creativity you know wisdom strategy
like the full range really and the the alignment problem is the technical question of how if you
were if you figured out how to make an AI that's generally capable of learning and planning and
reasoning how could you then steer it in some particular direction to make sure that even
when it becomes much smarter than you its creator it still does what it's supposed to do like what
you intended for it to do that it's kind of on our side as opposed to becoming this antagonistic
force that has different goals than we tried to give it that then works at cross purposes with ours
probably speaking and and there are different ways that different people have tried to make that
precise but that is more or less the gist of it. So yeah this book kind of just assumes our like
postulates really that all of that the alignment problem is solved and also that the like governance
problems are solved to whatever extent they can be solved so that like imagine we actually
don't use this powerful technology to wage war against each other or to oppress each other and
that like all these things that can be solved have been solved to whatever extent possible
in order then to actually get to the point where we can ask these questions about value
I have of course a lot of things to say in my other writing so about these issues of getting
from here to there but there is a risk that if one starts to write about those one never actually
gets to consider what it's all for ultimately like we are and I think this holds in general with our
existences as well we are very busy like putting one foot in front of the other and maybe don't
always take the time to reflect on where we are going or and especially at like at the
civilization level a lot of effort is being put into making progress like growing the economy
improving the technology making things more efficient but nobody really seems to have a
clear notion of you know where does this lead us to in you know in 50 years time in 500 years time
but anyway that's yeah so that that's that's all kind of now I don't know whether super
intelligence is strictly speaking like a premise or like it is certainly is one technology which
if we had that it would unlock a lot of other technological affordances and you would more
quickly approximate this condition of a solved world but you could in principle imagine getting
there just through a slower accumulation of human driven automation you could maybe imagine in the
limit just as you can create a little program that automates a specific task on your computer
or create a robot that makes one action in the car factor or something if we just kept doing that
for a hundred thousand years or a million years maybe eventually we would have software and
robots that could all the tasks and you could kind of at least get close to a similar situation
without super intelligence you said that so both the the dystopian and the utopian sides of the coin
were always on your mind from the beginning but at the time you wrote super intelligence though it
had been gestating for seven or eight years you thought it was more a more pressing problem to
deal with the the alignment problem and the pitfalls of AI but what I'm wondering is so there
was a practical element in writing super intelligence I don't want to get bogged down and how we get
from here to super intelligence because as you mentioned that can take us very far far afield
and we won't actually ever get to the utopian questions but is there also a sort of practical
dimension to writing about deep utopia because you think it is near at hand and we need to
start thinking about it or is it more at this point just a philosophical exercise it's more
the former for me actually I mean I do think we are on a seemingly fast track towards the AI
transition and so it does give the whole set of questions greater practical urgency and
that might be relevant in all sorts of ways like that might for example be points at which we may
need to make some some trade-offs between taking on risks and undergoing this transition sooner versus
delaying it in order to hopefully like make it safer although that exposes us to other
risks independent of AI but and some of this might hinge on how urgent we think it is to
improve upon or get out of the current human condition into something better if you think that
anything on the other side is like bad right then you might just want to preserve the status quo for
as long as possible if you think there is this like very wonderful utopia on the other side then
maybe you think well let's let's make sure we get there before we all just die from aging or
something and it would be worse taking some risk to make sure that we can reach that point so
these questions do I think flow back possibly to decisions that people have to make but the main
use case would be this if people are at one point having to design that trajectory forward and maybe
they with AI advice are able to anticipate where it will lead and like you know one trajectory
maybe leads to some kind of hedonism maximizing outcome another leads to some other complex
situation a third might lead to some kind of radically planetary sized brains optimized for
you know processing scientific knowledge or something and if some people need to make some
judgments about the relative desirability of these then I think it would be good if they had
thought more about it then there are their sort of decisions were not merely reflecting on the
latest thing they had happened to read on twitter or like how they happened to feel that day like
if they wake up in a good mood they think you know it's the future is great and has a lot of
opportunity if they happen to wake up depressed they kind of are a nihilist I think it would be
better if the world just disappeared and ideally whatever decision is made should reflect the
kind of broader set of considerations and values and perspectives than that and so
yeah contributing to that and I think I guess one more thing to be said about that is that
the prospect of the future gone well I think is greater if
people have this sense of there being great possibilities to realize not just one value
but many values that if the future goes well it unlocks this huge I mean would have this
super advanced technology plentiful resources a lot of time and there would be a kind of
abundance and I think that can help people approach things in a more generous way than if
there is extreme scarcity and like one person's gain is another's loss and there is not enough
for everybody then it's very hard to be generous right it's easier to be generous if you have a
lot and so thinking ahead if we could approach the future in this more cooperative and generous
way I think that also reduces the risk of various dystopian outcomes and improves the prospect so
those are some thoughts in the background yeah to speak I guess a little bit proverbially though
that abundance has its own problems because what is a pleasure without pain and when we
have everything I mean this is a big part of of the book in your project is where we find
meaning in a world where we have everything and there is no scarcity to drive purpose in right
yeah so so that's like the kind of the problem then that one confronts so much of our lives currently
are structured around the various practical necessities that we face in our life so you
have to go into work every day because you need to get the paycheck which you need to pay the rent
you have to brush your teeth because otherwise your gum will decay and you have to you have to
do this stat and you have like this like so much of our lives are just like doing something in order
for something else to be cost as a result right and that that that kind of fills our life with
sort of goal oriented activity but in this old world a very large chunk of all of that
would no longer be needed like you wouldn't have to humans wouldn't have to engage in economically
productive labor because ais and robots could do everything that needed to be done
um yeah you you you wouldn't have to like spend an hour at the gym working out in order
to be fit and healthy because you could pop a pill that would give you the same physiological
effects and you can kind of go through activity by activity and you find that for many of them
you can sort of either cross them out or at least put a question mark on top of them that
although you could still do them at technical maturity they would seem to be a kind of
pointlessness hanging over them like a dark cloud that maybe remove some of their value and so
and and this is like I think yeah part of what would make from our current vantage point
some of these scenarios at least prima facie look unattractive we kind of base our self-worth
and dignity on the sense of making some doing something useful like you're a breadwinner or
maybe you contribute to society in some other way or you like you you look after your kids or
your grandkids and you like through your efforts and strivings like you actually make the world
better in some place that it could in some way that it could not otherwise be
and if that's removed then yeah there is a void that the utopians would have to somehow
fill in I think a lot of the fun in this project comes from your imagination and
looking at all the various examples of what life might be like and the technologies that might be
available in a what you refer to as a technologically mature society and I want to talk
about those things but before we do I mentioned earlier that there were I'm not sure if it was
five or six I think five different utopias that you discuss in the book whereas I had thought that I
just only ever thought there's one kind of utopia it's just heaven and I had left that
unanalyzed heaven or something like heaven where everything's perfect but what are the
the different types of utopia that you think are relevant to this discussion and and how do they
differ and what are some of the basic problems that they confront the utopia dweller with
yeah so so this is how I like how I classify them for my purposes but you could think of
first category of sort of culture and politics utopia as many of the classical works fall into
this category where basically the author tries to imagine a better political system or a better
sort of culture so maybe you think there would be a different system of governance or like the
gender roles would be defined differently or the way that children relate to their parents
um and then it like different authors are different who is about the optimal way to
arrange this and the optimal way would that be a utopia um now a slightly more I guess radical or
like at least in one dimension more radical uh conception of utopia would be uh an abundance
utopia where you imagine that there is plenty to go around so all material needs are abundantly
supplied um and you do also find some of these um in the historical records like there was a
a kind of medieval fantasy of the the land of kokai that was a kind of peasant vision of like
the ideal life the rivers would flow with a wine and roasted turkeys would kind of drop down
on the plate and that would be music and dancing and a lot of time for relaxing and and you can see
if you were like a kind of agricultural labor like doing backbreaking work from morn to dusk
and then just to have barely enough porridge to eat like this would already be like a fantastic
conception right like you could eat as much as you want you could just stuff yourself with food
and rest all day and like that so so that would be kind of an abundance utopia um and then then
we have a kind of post-work utopia which is different from abundance utopia in that not
only is there plenty of everything but humans don't need to work to produce it um and this is
about as far as most mainstream conversation has gone in the context of AI you do find some
economists who are starting to think about um automation and whether it could cause unemployment
and if so what would happen like you know you maybe need some universal basic income etc
and um like like in in Marx's utopia he doesn't fight very much about it but it seems he imagines
that would be a sort of um certainly a culture's politics utopia according to his conception and
then that would be like less work and more abundance but that would still be people would
still be working so it's kind of but i think there are levels beyond that that you could consider
which is um much more radical and poses much more deep problems uh in terms of human values so
we have a post-instrumental utopia where it is not just the need for human economic labor
that is rendered odious by technological progress but the need for all human labor that is
instrumental in character so i mean i mentioned like you might have to labor at the gym to be fit
but that you wouldn't have to do in utopia um right now if you want to understand mathematics you
have to first study mathematics and spend hours working on exercise problems and like really
exerting yourself right but in this condition of technical maturity there would be shortcuts to
the same end you could imagine some swarm of nanobots infiltrating your brain and rewiring
your synapses into a condition where you now possess mathematical knowledge without you having to
put out any effort um so that kind of you know pulls the rug out of a wider range of human activity
and exertion not just like the job that you go and do for eight hours a day but most of what fills
the rest of your time um and then there's like a final stage beyond that which is i call a plastic
utopia which has all the attributes of a post instrumental utopia but in addition um the human
organism uh itself becomes malleable uh and subject to our wishes and desires so you could
sort of choose what emotions you want to have or what thoughts you want to have or what moral
character you want to have or what like physiology you have technologies to kind of reshape yourself
uh at will um including your psychological states and and that then results in this kind of
solve they're almost this old world where we're like all the kind of hard limitations that we
currently face like are removed it seems and and the only thing that remains are kind of our values
that i think have been shaped under this condition of scarcity which has like always been there for
for humans throughout history like and um it's almost like formed an exoskeleton these practical
needs uh and if you were to remove all of those practical necessities there is like the question
of what happens to the this soft squishy parts like do they just become a blob like a drug doubt
um a kind of pleasure blob uh or can they take some more interesting shape um and um yeah so that's
so that's like the the main that there are a couple of early chapters that talk about
some of these poor economic and technological but then the bulk of the issue is literally set in
this condition of solve it as a solved world at this plastic and post instrumental i'd like to
digress for a moment to this mathematics case that you brought up which i i find particularly
compelling myself especially because it's an example of something i i said earlier where
and you're examining what a mathematician might do in let's say a post instrumental utopia might
tell us something about what mathematicians do and value today that might not readily be apparent
so in this post instrumental world where we have extremely powerful
automated theorem provers that might enumerate all the theorems of math and all the
interesting axiomatic systems and there's no longer a role for mathematicians to be
providing new proofs do you think mathematicians would still be around because i mean this is
something that isn't this is one element of utopia that might not be that far out unlike
some other ones because we already have automated theorem provers that are doing work that mathematicians
can't do yeah so i mean people do i mean people play chess even though we have computers that can
play much better chess or solve crossword puzzles even though there is no need for
crossword puzzles to be solved and do a lot of other things currently right so the first answer
one might think is yeah yeah sure we'll just do it anyway because it's fun now i think we can't
stop at that point we need to like unpack this idea that we do it because it's fun so that could
mean we do it because it gives us pleasure like somebody who is fascinated with mathematics
probably derive pleasure from engaging in mathematical thinking and occasionally maybe
finding a solution but if that's the only reason there would be again shortcuts to attaining pleasure
in a solved world you could have more direct forms of brain manipulation that would stimulate
your pleasure centers i mean you could imagine it as some sort of a super duper drug with outside
effects and addiction potential or more likely some direct way of manipulating the relevant
neural structures you know maybe we're all digital at that point anyway and you just
and so yeah if all you wanted was to experience positive affect that there would be no need to
do mathematics for that purpose so if you do nevertheless think that it would be better to
do mathematics you then it seems value something other than just this hedonic state that you now
very imperfectly and grudgingly like maybe like some little drips of pleasure is derived every
once in a while when somebody who is enjoying mathematics does mathematics and there's probably
just a lot of sort of boring futile effort and like uncomfortable straining to get to those occasional
little drips of reward that's the stingy way our current reward systems are architected right
so you could kind of open the floodgates to that and then have a kind of more blissed out
psychological condition and so that's easy to dismiss a lot of people like immediately think
that wow that's like what a horrific view of the future that is we're all kind of like junkies
sprayed on some sort of flea-infested mattress but with like a super drug dripping into our nucleus
incumbents and you know it might well be that ultimately we want and can have more than that
but I it is actually a rather deep question whether we shouldn't dismiss too quickly the
the super bliss as an element of what we would ultimately choose and have reason to choose
perhaps nevertheless I think we can have that and have a whole bunch of other things on top of that
that may be satisfy other possible value candidates so certainly if you do think that it is good to
engage in certain types of activity you could do that as well there is no reason you could have
complex experiences pleasure plus complex experiences plus various forms of goal-directed
activity but maybe we're you know and we could talk more about why you would be adopting various
goals if if you were in this post-instrumental situation but and and then perhaps some additional
elements even beyond that that you could kind of reconstitute some of the prerequisites for
instantiating human values even in this solved world condition I think what what motivated my
asking this question was reflecting on two conversations I had in the past on the show
one was with a renowned number theorist at Columbia University named Michael Harris that
we had a couple of years ago so it's a little faint in my mind and another is with Steven Wolfram
and we were talking about math in a world in which all of math is essentially automatable and
today I think our folk view of what mathematicians are in the business of is just producing new proofs
discovering or inventing depending on your philosophical view more facts to be added to
this big book of math but what Michael Harris said and what I think Steven Wolfram agreed with
is that mathematicians aren't just in the business of producing new facts
they're in the business of understanding that's what really drives what they're doing is they
want to understand these structures and I was thinking that in this post-instrumental world
when mathematicians no longer have to produce proofs they still would be very interested in
understanding and maybe teaching mathematics but then this raises another problem that I hadn't
considered yet that you discuss in some of the later or the more advanced types of utopia where
we have a matrix like system of downloading information where there's no long into our
brains where there's no longer any real barrier to understanding you can understand anything
as soon as you just downloaded into your mind so there's no there's not really an activity of being
a mathematician anymore just if you want to understand the math then you press a button
then you understand the math yeah so this is a very like advanced level of technology and it's
like a little unclear exactly how close to this we could get but certainly if you imagine a human
upload like a digitized version of a human mind and then you have on the outside some machine super
intelligence that is able to like understand how the neural network that is you sometimes
successfully can grasp mathematical concepts and in other cases fail and what variations of your
neural network would be required like what edits to make it as similar as possible to you now but
with this extra mathematical understanding I think it possibly would be the case that the
job of working out how to adjust the various parameters in your brain to give you this mathematical
knowledge could be outsourced to this machine super intelligence that is looking at a model of
your brain and probably be able to do that without actually running a detailed simulation of your
brain which if it if that were the only way for the super intelligence to work it out you might
then think well you would actually then be instantiated in the simulation and you would have to put
in the effort although the simulated version of you would do but I think probably you would be able
to move up levels of abstraction to more or less obviate that need and so that you would then be
able to yeah in effect download skills or knowledge without having to put in time studying
and so yeah I think I mean and the teaching of mathematics is even more obvious I mean I think
we are very close now to having tutorial systems that would be much better than most
like high school mathematics I mean aside from keeping the class disciplined and making sure
everybody sits at their desk or whatever like but the actual instruction I'd imagine maybe even
chateau pt4 would like be a better explainer than than than most high school teachers because it can
keep track of exactly where you are where you get stuck on a particular problem and sort of
customize its explanation for you as opposed to doing something generic for the class of 30
just curious are you drawing the sort of distinction between chateau pt4 or gbt4 being
a good high school teacher and a good university level professor because maybe there is insufficient
training data on university level material for chateau pt4 to be able to explain it
better than a university professor could I mean I so I don't know exactly I'd imagine there need
to be some fine tuning maybe to adapt these large language models for specific use cases in the
classroom I'd imagine the standard university courses like you know first and second calculus
and like all of that stuff probably it would be able to explain Adam Madden as well as a mathematics
professor I think maybe once you get to the research level of mathematics whether it's more
matter of taste and then I'm not sure the current language models are quite yet there yet whether
it would be as good as like a decent mathematics professor in terms of figuring out whether a
research direction is is is promising or whether some proposal for say a phd is like
the right level of difficulty that the student could possibly do it in four years and
like like I think there there is like well there's obviously less training data written up
for ingestion and and also it involves the the most high level human faculties that haven't yet
perhaps quite been attained by the current generation of systems a term of art that you
introduce in the book that I referenced earlier is technological maturity and
I also mentioned that this is one of the the very fun things for me
of reading deep utopia because we get to see your imagination at work and all the possible
things that a technological mature society might have at its fingertips so to speak
so how do you define a technologically mature society and what are some of the things that
people might expect to be able to do or have on offer yeah so it's like a condition at which
all those technological affordances that are consistent with the loss of physics
and for which there is some possible trajectory from where we are now to their development exists
so yeah it might be that you can't ever strictly speaking attain perfect technological maturity
but in reality you might get some kind of close approximation to it if you have developed all
the most useful general purpose technologies is perfect technical technological maturity being
able to do anything that's physically possible well I would also have this pathway there but it
might just be that if you imagine there are kind of an unlimited number of more and more
specialized technologies for doing specific things it might be possible to develop any
like small subset of them by like investing your r&d resources but if there is like quadrillion
and quadrillion of different very specialized technologies maybe you can't develop the whole
set of them but I think that would be sort of ways of getting close to that for most practical
purposes like once you have superintelligence and nanotechnology you can sort of come up with
the superintelligence can make arbitrary designs and the nanotech can sort of put it together
and then like some other things you can I think get pretty close to that
um so and and I think we know already at least some lower bounds of what this
such a condition of technical maturity would involve that is technologies that we can already
have good reason to think are physically possible and for which there is a pathway such that we could
at least in the fullness of time under favorable condition get there so superintelligence is one
of these like I think perfect virtual reality of the sort that would be indistinguishable to the
person inside the physical like virtual reality from from ordinary basic reality would be another
affordance I think like cures for aging uploading into computers space colonization at large
intergalactic scales perfect newer technology in the sense of being able to control
precisely our hedonic and emotional states cognitive augmentations like many other things
as well but at least that already gives you a huge set of possible like things you can do right
that's technological maturity one of the so the way that for our listeners who haven't
looked at the book yet the book is organized so it's kind of like a a course you're teaching to
these imaginary students and at various points in the book there are handouts where you've
summarized some of the material and I have a handout number two some capabilities at technological
maturity on the screen before me and I was just glancing at them and one that jumped out at me
is the possibility of Dyson spheres for harvesting the energy output of stars and this comes to mind
for two reasons one is well I'll just focus on one but the reason is I've done a number of episodes
on string theory and been thinking a lot about string theory lately and one of the big barriers
to empirical confirmation of string theory is that we cannot generate enough energy to probe
sufficiently small distances to confirm the existence of strings and people have conjectured
that the sort of energy you would need is the energy of a star so it looks like we'll be able
to confirm or disconfirm string theory in a very useful technology the Dyson sphere
but yeah like you mentioned arbitrary sensory inputs reversal of aging
uploading of biological brains into computers and all of these things
engender their own host of philosophical questions to be asked and answered aligned police
bots and automatic treaty enforcement I mean and police bots are already a question being asked
today but you know reversal of aging and cures for all diseases that's one that
jumps out at me or a couple that jump out at me right now are there any particular problems
that would need to be dealt with in these later stage utopias if we just lived forever
well I mean the most obvious one would be the size of the population which is able to increase
exponentially and if nobody dies then at some point the rate of births would have to match
the rate of acquisition of new resources in order to maintain high per capita incomes
because at technological maturity there wouldn't be increases in productivity like that's one of
the things that drive technological growth now right even if the resources are the same you
could have better technologies to make more efficient use of them but that will have maxed
out and so then the only way that the economy could grow at that point is if more resources
are attained through expanding in space but that can at most happen at a polynomial rate
like you have a bubble that is growing in all directions at some significant fraction of the
speed of light and the volume of that grows as a polynomial of time whereas the population
like could grow exponentially right and so then eventually you would have a Malthusian condition
and so in the limit you would need to sort of make sure the the rate of population increase
which might be sort of digital minds making copies of themselves right but would kind of at
most match the rate at which the the resource endowment increases like another maybe more
philosophically interesting question if we eliminated aging and then I mean right now what
would happen if you eliminated aging is that people would die from accidents and wars but maybe
with a lifespan of a few thousand years if you kind of calculate the rate of death by accident
now hopefully we will bring down the rate of accidents and and war certainly in utopia you'd
imagine that to go way down and if you could upload yourself to computers then you could make backup
copies and stuff and then the rate of accidents could kind of become arbitrarily small so then
then you might have very long lifespans even astronomical and and that presents more interesting
philosophical questions for human values in that well first of all we don't know what would happen
to like if you remained a human mind of like a brain with your current size and the number of
synapses and stuff like we know you can continue to learn and develop and grow for like a hundred
years but we don't even know what would happen if a human just kept living for 400 years like would
you go stale and rigid and like so and even if that didn't happen in a sort of like neurological
way like then it might still be that and it's a hard question to sort of gauge but that the
number of different types of things that can be done with a human mind and body in a human world
is finite and is that number small enough that it would become relevant so that at some point you
would just run out of interesting new things to do and if so how long like I mean I think
given that we are finite there has to be some number of years after which you would literally
be doing the same thing you'd already done but if that is kind of 10 to the power of a hundred
or something we might not have to care very much because we'd die anyway before that from the
heat death of the universe but if the answer is like 10,000 years like after 10,000 years you'd
basically just repeat yourself then either you'd have to accept that such lives will have a diminution
of a certain kind of novelty and that may be a price to admittance and this kind of extreme
longevity in utopia or you would have to perhaps start to level up after you have spent at 10,000
years being a human maybe then you would want to become a transhuman like increase your intellectual
faculties or something and you could kind of start to tackle the next level of challenges and
keep developing that way but it is I think it is one direction in which you can kind of
take our current human values and where they start to become strained if you just imagine the
current human lifespan with our current values and our current faculties but just extended
and like prevented from physical disease like at some point I think that would
possibly become unattractive like there are still a lot of things in human life that don't
require novelty I mean like a cup of tea is like about as good like the 10,000s time as it is the
second time or first time right it they're like renewable pleasures and sometimes you could run
the argument that sometimes the best things in life are the little things that it's not like
like the big dramatic narrative climaxes but it's like you know the smell of autumn air in
the evening along a stroll along the coast or like looking into your loved one's face or a little
you know cup of tea or whatever like these little things sometimes you know you could run the argument
that that's a fairly high quality value although we give them kind of short shrift
an interesting connection to the philosophical literature going back
hundreds of years I mean is how conceptions of personal identity might shift in this world
where we live for we live indefinitely I think and you should correct me if I'm wrong but I think
it was Locke who proposed that personal identity has something to do with memory and psychological
connectedness and maybe it was Derek Parfit in his sort of ongoing discourse with David Lewis who
questioned whether somebody who lived who wasn't immortal would eventually no longer be the same
person that they started out as because they would not remember let's say their childhood
F there would no longer be any psychological connection to a person stage thousands and
thousands of years earlier and in this sort of utopia maybe we would bypass this by getting
memory implants or memory chip implants so that we could just continually
add new memories and maintain internal psychological connectedness yeah um
I mean I guess there is first of all like I would want to make retain the distinction between
long time and infinity like immortality I think you should mean not dying not not just taking
a while before you die like conceptually and it is important because immortality in that strict
sense just might be impossible in our physical universe and be the preserve of say more theological
scenarios and from the blink view of eternity like whether you live for like 80 years or 80
thousand years it's kind of in some sense the same right it's an infinitesimal short relative to
infinity either way now I do think that yes increasing I call it time time suits but the
idea that we could make some modifications tasks that make us better able to survive radical change
without having our identity eroded or our values corrupted so the most obvious thing would be to
improve our episodic memory so that you actually don't just forget what you've been through and
that could make you sort of remain relevantly the same for longer than if you just have like the
memory of a goldfish and and you could imagine some other tricks as well that would allow us to
sort of endure for longer periods of time and and upgrading our capacities in different ways could
help with that um but even if it came to a point where you would have to accept some loss of personal
continuity in in whatever relevant sense I mean it might be acceptable like if you if you were
have a five-year-old and you know that if there were a pill that would just arrest their development
that they would remain a five-year-old like in some sense maybe a year from now that would be
more similar to what they're now than if they're just allowed to freely develop uh but we might
still think it's better for them to grow up like in some sense you are the same person now as you
were when you were five but in realistically you're also quite different right in many ways uh and uh
and maybe that's not an unambiguously bad thing like and so I think the combination of these that um
a uh we can reduce the negative effects of various kinds of uh corroding uh consequences of the passage
of time through improving memory and other certain other positive attributes like also including like
maybe extending your planning horizon etc and and then also accepting some degree of of change
even if it does mean that you eventually move further away from what you once were if there's
still a difference between that and just dying because at any given point in time you might
look forward to hundreds of years of existing in some very similar things your current condition and
and you would gradually sort of you know see new ways of doing things or being or new experiences
that that feels a lot more optimistic to me than it then like a kind of you're gonna be shot
tomorrow morning right it's a um this the smoother and gentler way of losing our connection with the
past seems perhaps prudentially preferable um even to the extent that it is unavoidable relative to
yeah um the alternative okay not that a lot of this or all of it hasn't all been speculative
but i have a particularly speculative question to ask so when i
spoke with avi lobe the harvard astrophysicist this this brings us back to dyson spheres
he conjectured that umuamua this comet that passed us by in i believe 2017 might have been
part of a dyson sphere and you have made your own very uh i don't know if splashy is an adjective but
powerful uh controversial conjectures about for instance whether or not we might be in a simulation
and i'm wondering if you think it is possible or likely even that there are societies out there
that have already reached uh for instance a post scarcity utopian stage because i think the
having a dyson sphere if whoever sent uamua our way had a dyson sphere we would classify them
probably as being in a post scarcity period assuming that they still have other dyson spheres
yeah i mean so that i mean post scarcity they might not i mean it depends a lot on what their goals are
and um it might be that the dyson sphere of resources is nowhere near enough for what they
are trying to do um and so it is to some extent a human con like um it's not like a very precisely
defined concept it's like you could say like from few humans so you could say that we are already
uh somewhat close in some respects well if you're if you are like fortunate enough to live in a in a
in a rich country and you have a i don't know like you're healthy and trying to good education like
probably most of your listeners like it's probably the case that um uh if if you wanted to you wouldn't
really have to work to survive like or if you select say say you worked hard really hard for
five or ten years and saved up all the money you probably could then move to thailand or something
and buy a small hot near a beach and then have enough to eat and be physically healthy and you'd
have a computer you could eat access the internet or whatever for the rest of your life without
having to work like it's at least tantalizingly close uh but yeah people choose to continue to
strive because they want more than just the basic necessities of life right like and in particular
we want to have more than other people and so there's a lot of this kind of um zero some
status consumption going on with humans um and that could drive scarcity up to astronomical
levels right like you yeah you have your own dyson sphere but uh like i have four dyson spheres so
like you still need to try to um catch up and and and intergalactic civilization might have
practical reasons as well like maybe they fear some other intergalactic civilization that might
have a larger fleet of worships or something and so um but the difference is like um even if human
desires are insatiable it doesn't mean there will always be a need for human work like you
could reach a condition where even though like you maybe are worth a trillion dollars and you
would like to make another trillion dollars there's just nothing you can do with your own labor that
would make you any significant amount of money because all the work is better done by machine
and if the most you could make is the minimum wage then once you're a trillion year like
there is no point really working right because it's trivial compared to what you just earned from
your capital and and it might even be that by doing the work yourself you like expend more
calories that cost you more than the actual value of the labor so you could still end up in this kind
of condition of um uh unemployment or post work even if there are still needs that have or desires
that haven't been fully uh satisfied um now you asked whether I think there are already some that
have attained either poor scarcity or I guess you could generalize it into technological maturity
and I think if the universe is infinite as it seems to be like if we have the simplest topology
and an opener flat spacetime um then definitely that would be uh such civilizations in fact infinitely
many of them out there but um if I had to guess I'd say none in our in the observable universe and so
that there would be infinitely many of these but they would have low density and so um um we might
be out of causal contact forever with the nearest other one um that certainly would help explain the
Fermi paradox um but it's not the only possible explanation so we can't rule out that we could
share the observable universe with some other civilizations as well. Speaking of intergalactic
civilizations and intergalactic warfare obviously that would be a huge barrier to us reaching a
utopian state if we had to ascend off uh an alien invasion but do you see any other barriers
besides just our ability to produce a super intelligent technology or super intelligent
AI other barriers beyond that to our reaching utopian states? Uh yes I mean first of all it would
be uh crucially super intelligence is well aligned um because otherwise yeah that might
be our undoing um and second if you have scenarios uh multipolar in character like if you have many
different entities ultimately with our own AI uh assistance that then a lot of the same dynamics
that uh we see on the planet today with arms races and um oppression and warfare and exploitation of
the global commons by sort of spewing pollutants into the atmosphere overfishing the oceans all of
that could still occur and and indeed could be intensified in this kind of hyper competitive
economy that might be created um if on the other hand you don't have a multipolar but like a unipolar
or as I call like a singleton scenario where it gets all consolidated then there is the obvious
question of um who controls that uh singleton right and how uh benevolent and wise is whatever
the mechanism whether it's like a global democracy or a dictatorship or whatever it is is like so I
think we can identify several broad categories of things that need to fall in place so one is
to have this kind of uh deep utopia a you would need super advanced technology
like otherwise you just can't do all of the if you right now we can't cure the
jit with a cancer in many cases right and that means our world will fall short of what it should be
so the super advanced technology but then I think also we'd need um a fairly high level of
cooperation slash good governance to prevent sort of negative some conflict and then we'd
also need some adequately high level of wisdom in how we use these great uh technological powers
that we have um and it might be that the wisdom is it has a kind of threshold effect where if
you're above that threshold even if you're still uh unwise in many deep ways and have many
erroneous beliefs and misconceptions you might have enough wisdom to realize that you are fallible
and to start to seek out ways to fix you can reflect on your own shortcomings and gradually
develop ways of remedying it but if you're sort of below that wisdom level you might
be more likely to lock in your current prejudices uh or to shoot your foot off when you're trying to
like develop ways to fix it and it's kind of actually an open question I think where humanity
is relative to that because you could ask the same question at the collective level like are we
I think we are maybe close to the threshold level but I'm not sure whether we are just under
or just above it um and um and then we might need some bit of luck as well on top of that um but um
um I think yeah although these are kind of extreme technological postulates and you might
see them very wide wild ideas I still think um they might actually not be completely unrealistic
even within our lifetime if this whole AI transition happens um and it's if you sort of
zoom out and look at the human history like uh from from its inception like you know a few
hundred thousand years ago to today and you plot that in any possible way you you might want to
like whether it's like the amount of you know um you know the GDP let us say or like some sort of
the energy expended by human civilization or like in any it does have this you like if you
plot it on a linear scale you just see a flat line that just spikes up at the end of the graph so
then you have to go to like a log plot or to even see it bending but even then it bends up and we're
really sitting right now at this like ridiculous anomaly um where what we are currently taking
to be the normal human condition is in any which way look at it like just extreme historical anomaly
like a tiny little thin coat of paint on on like a giant uh battleship of human history right it's
like it and and then now we think it's like a radical conception to think well what if that changes
in the future whereas in fact if you sort of zoom out you look like we are right now in the middle
of this like explosion of something and we don't know what it's going to end up like but um but I
do believe as as you alluded to earlier that scenarios in which we just remain more or less
like we are now and have the current human condition just keep going for like tens of thousands of
years that just seems extremely improbable to me relative to either like extinction slash dystopia
or some radical transformation into some kind of post-human condition well Nick I I really
enjoyed deep utopia and I came out of it with so many ideas and concepts that I hadn't considered
beforehand so thanks so much for writing the book and thinking about these really interesting
pressing problems and thanks a lot for coming on the show to talk to me about it well thanks to you
and uh to the little cat there as well
