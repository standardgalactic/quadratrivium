{"text": " Okay, I'm Evan Treplicchi, I designed the Elm programming language, and what I wanted to talk about is people often wonder, they see similarities between React and Elm, both these things are about creating things in browsers, these interactive applications, and people say, well, which came first, where, who originated this idea, that idea? And so I thought I could offer a sort of unique perspective on how these things evolved in the timeline. And what's interesting is that usually it's a case of conversion evolution, where something was going on inside Facebook, I didn't know about it, and independently I was working on my thesis at college, coming up with certain ideas, and it just turns out we came to a lot of similar conclusions, and so I want to emphasize those and sort of see what that might mean. And I want to start by giving an example of conversion evolution, just from real life, which is you have these sort of very different creatures, birds and bees, that both can fly. They both somehow ended up with wings, even though millions of years ago they diverged evolutionarily. And one thing that a developer might say when they see this connection is like, well, who did it better? Who did wings best? And so one person may say, okay, well, birds, they have feathers, that's pretty cool. Whereas wings, they have chitin. And so with feathers, well, if it gets damaged, it can be replaced. Whereas with chitin, if it gets chipped, it's just chipped, it's just bad now. So like, but I think this is kind of a silly question, and in this context, like, it sort of seems ridiculous. And I prefer to ask the question, how does this design fit in with all the other features? So if we take a step back and we look at bees, well, bees have the exoskeleton, that's also made of chitin. And so the fact that the same material can be what their wings are made of, there's no extra nutrients that they need to be able to fly, it's kind of a beautiful design. They also have an open circulatory system, so instead of a heart, they just have like, they don't have blood, it's just like hemolymph seeps through their shell. Point is, they don't live a super long time because that's not an ideal system. But for the purpose of a bee, it's like, I'm going to be alive for six weeks, maybe a couple months, and if a wing gets chipped in that time, it's going to serve its purpose and do a really good job in that context. Whereas with a bird, you have hollow bones, and hey, if the bone breaks, the wing is broken too, so that thing about feathers wasn't such a nice thing. And they have a four-chamber heart, so they can be much bigger, so they can use their wings to kill bugs, so they're using the wings in very different ways. The big point here is that flying seems like a good idea. And the fact that these two creatures came to the same conclusion in these totally different ways with these totally different other feature sets, it's suggested like flying, it's pretty neat. And so when it comes to implementation details, I prefer to ask, how does this fit with other features rather than who did flying best? So with that context, we're going to try to do a similar thing with React and Elm. So one of the features that React and Elm have in common is virtual DOM. And so when I was working on Elm from the very beginning, we were having functions that would create this data structure, and then I would just, based on that data structure, we built the DOM on every frame. And I was like, that's kind of crazy, I don't know if that's going to work out. And so over time, I was like, okay, well, I can incrementally do it so it doesn't flash, and I can preserve some information. And subsequently, I saw that React did the same thing, and that sort of really validated that design that I think anyone I asked who would have said, that's obviously crazy. And so when you look into the details in virtual DOM, with React, you have a special syntax called JSX, so it's giving you this familiar HTML in your JavaScript code. Whereas in Elm, we don't have a special syntax, and this is something that people, when they come to Elm, will find weird, it's like, well, how do I set this up? So I want to show a little program here. So I'm going to take a program from the Elm guide. That's just like the very beginner thing, and we'll take a look at it. Tell me when you can see this. Okay. This is the problem of having the massive high resolution. It's quite the right size. Okay. So I'm going to build that, and we can look at how the view code works here. So rather than an HTML-style thing, we're saying, okay, I have a div, and it has three children, a button, a div, and another button. And when I actually go look at that code, we can see, okay, not the most exciting beginner program, but it does something. And when we look back at the view code, we see that exact structure. We have the button. It's got a negative sign. And what's neat about doing this all in Elm is anything you want to do, you can do it in Elm syntax. So rather than saying I want a number here, I can say maybe I want a list, and I want to view a dot for every number from one to the count. And then I can just make an Elm function of view dot that takes the number, and instead it just says, I'll show a star here. And so when I compile that, I can go and look, and oops. So now I see dots when it shows up. So it's quite a nice thing. So if I want to use any feature of Elm, it's sort of like the templating language for Elm is Elm. So I'm not here to say one way is better or not. It's better to look at it in context. And so in the React world, you're using JavaScript, you're using the C-style syntax. And this goes back to 1972 at least when C came out. And so JavaScript, if you believe the origin myths, could have had a Lisp syntax. But for the sake of familiarity, went with the C-style syntax that everyone was familiar with. So essentially, this is an ecosystem that's putting a premium or using familiarity as an onboarding tool to make people feel confident and dive into things and use that to learn. Whereas in Elm, I have an ML-style syntax. And interestingly, that goes back to 1973 at least, but it's just not as widely known. And so to say, well, which of these is better is kind of like saying, well, is Arabic script better or is Korean script better? It's like, well, which one do you know? And you probably will prefer that one, at least at first. And so I know that Elm pays a familiarity cost in making this choice. But I think it fits in with all the other Elm features that we're going to see. And so I'm willing to pay that hit in maybe where our community grows a little bit slower. But it makes this coherent whole. And so when a question comes up, should we use something like JSX? It's like, well, we've already sort of committed to not using syntax as an onboarding technique. So we'll come back to that and see how it fits in more. So another thing that React and Elm have in common is unidirectional flow. And so for me, I first sort of, this became a distinct concept for me when I was at Hacker School, now Recurse Center back in 2014. And a student there made this game called Bessel. And this student had never done like functional programming before. They had done Python, I think, with the language that they knew. And while I was there for the two weeks, they wanted to try something out. So they made this little game where you have to go through the blood vessel. And if you run into the wall, you explode. And so this is like a weak project. He's just trying functional programming for the first time. And at the end, he asked me for a code review. And what was crazy was his code was really good. And that's not to say like, it's just like when you start, I found it surprising that someone starting functional programming for the first time would end up with a program where like, that's how I would architect it. I have no concerns, like that's great. And it matched how I would structure my code as well. And I thought that was just a me thing. And so this was when I started to notice, okay, there's this pattern that sort of Elm wants us to write code in a certain way. So this is when the Elm architecture sort of got a name, even though everyone who used it, who used Elm had been doing this kind of pattern. And the idea is that you have a model that says what's going on in your application. And it creates HTML. That gets sent to the Elm runtime system. It renders it, deals with the DOM, does the diffing, all that kind of stuff. And then it'll send back messages. And that is how you update your model. You send new HTML, and the cycle just goes round and round and round. And when I first presented this kind of stuff, again, this was something that seemed like a crazy idea. And from the JavaScript world, it looked crazy. From the functional world, it looked crazy. Everyone was like, this is silly. And so when I saw that React had this thing called, they were promoting this thing called Flux, I was like, okay, that actually sort of validates this design. And it sort of arose, I think, separately. Since Flux, there's been more, it hasn't been as much independent development. So people have seen Elm architecture and things as neat. But so let's look at what the Elm architecture looked like in Elm. So we can go back to our little counter program. And we have a model. And in this case, it's just a number that we're counting up. And we have a way to update. So if we want to increment our document, we have messages like that. And when we handle them in each case, and then we can put those in here. So if I wanted to add a new feature, I could say, okay, I want a thing called reset. And it's going to be a reset button. And I need to add in that kind of message and handle that case. And if we go look at it, now I have my same thing and I can reset back. So it sort of gives structure to your program. And so this is a really simple example, but it actually shows up in every Elm program ever. So if we go look at the to do MVC code, we see the structure again. So we start with a model. In this case, it's a bit more complicated. So let's open it up. So here we can say hello in all of this. So we have a model of, we have a list of entries. We have a field that you can type in. We have what things are visible or not. We have our entries. That has a description. Is it completed? Is it being edited? We have our messages, all the things that you can do to this program. And a way to update our program. And we have a view, which again is using this Elm as the HTML syntax. So you can see, okay, I've got a div. It's got some attributes. It's got some children. And we're just using Elm functions to create the different parts. So here's where the text input is, that kind of thing. And no matter what level of crazy program you go to, so another program you could look at is Richard did this real world thing that's been sort of going around the internet in Elm. And you see the same pattern again, where there's the model, there's the update, there's a view. And one thing that's really neat about this is when you come to an Elm project, you're immediately oriented, because you're like, every Elm project starts this way, and then they're just functions out from there. So when you go and put this in context, in the react world, my understanding is that not everyone is into unidirectional flow. And I think that's because components are an important idea in the react world. And when I look at components, I see local, state, methods, like getters and setters to deal with it. Whenever I think of that, I think of an object. We've got local, state, getters and setters. It's sort of an object-oriented way of thinking. And that's one way to approach things, and this unidirectional flow is another way to approach it. Whereas in Elm, we don't have the objects, we just have functions. And if that's your only tool, you're going to end up with a unidirectional flow. So because of the feature set of Elm, it really makes sense that that's how all Elm programs work. And because the feature set of react, it makes sense that people might mix and match and use some depending on what their case is, depending on what their preferences are. Another case that people ended up at independently is immutability. So Elm is a language where every single value in the whole language is immutable. And so I think this became important in the react world because react has this thing called shouldComponentUpdate, and it looks something like this, where you have some function and you're saying, all right, did any of these properties change? If so, we should update. And I just want to do a quick poll. How many people have had a bug where they changed the component, but they forgot to change the shouldComponentUpdate, and then they were like, so how many people out there? Okay, was it a fun bug? This can be something that's super frustrating because you're like, I swear this code works, my test is fine, and you just don't think to look at this piece of code. And so ClosureScript, David Nolan came up with this idea of putting pairing shouldComponentUpdate with immutability. And so the basic realization is if you have an immutable value and you say, well, is this reference the same as that reference? No one could have changed it in the meantime, so it must be the same. And so it's a really nice way of making this reliable, even as the shape of that value changes. And so he wrote about this in this blog post, and I really want to give him credit for this idea because I think, one, it popularized, or like it made immutability palatable, like not an insane person idea in the JavaScript world, and it really made space for functional languages to have a place in front of development. So in Elm, everything's immutable. So I saw David Nolan's idea here, and I was like, great, like, what is this, how does this come to Elm in the Elmi way? And so we have this thing called lazy. So if we go look at our toDo app, I'm going to remove the lazies real quick so we can see it without. So here I have a div, it holds a section, and it has three subnodes. And so for the first one, I'm calling a function, and I'm giving it some field value, and that's what's going to show up in there. And so essentially what's happening when I add lazy is I'm saying, instead of calling this function now, building the virtual DOM, doing the diff, seeing if there's patches, and finding out yes or no, I'm going to say, okay, hold on to this function, hold on to this value, and when it's time to diff, I'll say, are these the same as last time? And if it's the same function by reference, same argument by reference, I'll just skip the whole thing because I know the results are going to be the same. And because everything in Elm is immutable, this is known to be safe. You can just trust, you can sprinkle in this lazy operator wherever you want. And so if we look around this file more, I use it in other places, so each entry in the list is lazy. This is the footer where there's some controls, so if we look at the app again, there's these kinds of things at the bottom. So that can be lazy too. And what's neat about this is it's not tied to the component itself, it's just if you have a function and you have some arguments, that can become a lazy piece of the structure. Okay, so another thing that React in Elm have in common that's maybe more, one of the more controversial things is static analysis. And so when I use that term, I mean how can computers look at your code and give you helpful timely hints that help make your code better and don't waste your time or don't give you good feedback. And so for React that may be a linter is a version of this, something like flow, something like TypeScript, giving this extra machine help to improve your code. So in Elm, static analysis has been sort of an important part from the very beginning. So in Elm, Compiler is able to give you these hints. And I want to look at a couple and try to put in context. It's something that's hard to, I feel like Elm programs have like a personal relationship with this, but it doesn't translate well, so I'm going to do my best. So we have here this little expression where I'm trying to join the strings Alice and Bob with the number four and it's saying, okay, function join is expecting the first argument to be a string, but in fact it's a number. So it's sort of giving you this very human explanation of what's going wrong in that code. And the neat thing is as your code gets bigger and bigger and bigger, the error may not be as simple as just it's the number four here, but you have some variable and through some other fact in your code base, it will be a number. It'll catch that as well. So in a little bit more complex case here, we have an if expression and in the body we're saying is the length, what is the length of this? And so Elm is saying, hey, this needs to be a Boolean value. You've given me an integer, but I need a Boolean. And what's nice about this one is it has the little hint. So I know that when people come to Elm, there's certain mistakes that are like super predictable, like lots of people are coming from Python, JavaScript. And so I try to give a hint that, hey, Elm doesn't have truthiness such that instance strings are automatically converted. You need to do that conversion explicitly. So I'm trying to give as much scaffolding as possible so that you know, okay, list length, is it equal to zero? Less than one is greater than 10, like be explicit about that kind of thing. Now I think those examples don't really show what this means in a large setting. So I work at this company called NoWriteInc, and we've been using Elm for about two years now, and we have about 200,000 lines of Elm code, and there's been zero runtime exceptions in production. And so the kinds of things that this is catching is really, really extensive, and it's doing it in a way that feels like a pair of programmers saying, hey, did you think about this case? Did you think about that case? And so one question you might ask is, how do you know it's zero, like is your URL misconfigured so you're just not getting any reports? There is legacy JavaScript code that will throw exceptions from time to time. So we know errors can be detected. So I want to show in a larger program what it means. And so I accidentally, okay, no, I think this is good, I think this is good. So let's say I want to add a new control, so rather than just having all the things, what's active, what's completed, I want to show if something's complex. So here I can say, here's my controls for which things are visible, and I'm going to add an extra case for, is it a complex task? So what's nice in Elm is you can kind of just run the compiler and see what it tells you. So in this case, it's saying, hey, this complex thing, I don't know what it is. Is it supposed to be an import? So where did the code go? Okay, so it's suggesting like, hey, you need to define complex before you use it. So one of the visibility options is, okay, I want complex stuff. So I added that, let's see if that works. And it's saying, hey, one of your cases doesn't cover that scenario, so case, visibility. So in this case, we're changing it to strings. So in the complex case, we're just going to say complex. And one question you may have here is, why turn it to strings that looks the same as the value? So your designer may say, I don't want it to be complex, I want it to be called like fancy tasks. And so you can change that without changing all your code. So I think this decoupling is important even if you're not using it at the start. So we'll stick with complex for now. So let's just ask the compiler again what's going on. Okay, this case doesn't handle all the possibilities. It's saying, hey, you need to handle complex in particular. So let's go find that. Okay, and so this is a function that's figuring out, given the visibility, is the entry visible or not? So in the complex case, we can say, is the length of the to-do description? Oh, yeah, and I want to make all sorts of typos here. So I misspell that. I'm going to misspell this thing. And the description, that was a legit typo, I didn't mean, is less than 15, let's say. So some of these errors are bound to happen eventually. So let's see what the compiler tells me about it. So it's saying, hey, I found this pattern complex. Maybe you want this other idea, okay, that is exactly what I want, in fact. And here's a naming error. You use toad, maybe you want one of these other things, and it tries to find names in scope that are close. So I want to do. So okay, I fixed all the errors. Let's see. And it's saying, hey, to-do doesn't have a thing called description, but this is close to a field that it could have, so maybe you want description. And so for each of those errors, had this been a string, it just would have been wrong. And then some point you find that error through some bug report. And then you find out that this was also misspelled. And then that would have been, I can't access a field on an undefined value. And then you would find out, okay, this thing is spelled wrong, and that's going to actually be an undefined. And what is string.length? Do you want undefined? I don't know. So it's catching all these things in a really nice way. And so as your program gets bigger, it's catching all these things still across a whole code base. So for the 200,000 lines that Norbert Inc. has, this is the kind of help they're getting along the way. And so because that's such an important part of Elm, it sort of fits in with, like, another question people have is, React uses NPM for all of its package management. Elm uses Elm package, so we actually don't use NPM. But all of the half a million packages on NPM aren't directly available. And so some people look at that and they're like, well, you're a crazy person. That's like, obviously, you need that to have something nice. And the thing is that because we have all the static analysis tools, it makes sense to use them in Elm package. So for example, if I say Elm package diff Elm laying core, which is the core library, then I'm going to take a recent release with the most recent release. It's going to tell me all the things that have changed between those two versions. And so I can do it on another package of mine, Elm tools parser. And the first release and the second release, I made a decent amount of changes. So here it can say, hey, this is a major change. You added all this stuff. You removed all this stuff. Here are the things you changed. And so for any package in the Elm ecosystem, you can ask this question and see exactly what changed. And what that means is when someone's publishing, I can say, okay, I looked at your code. You have made major changes. This is the new version number that you will be using. And so it's not a matter of like, oh, do people get semantic version? Do they like it or not? It's just like the Elm ecosystem uses semantic versioning. And if you're making a major change, everyone's going to get that major change. And so what that means for the whole ecosystem is there's no way to sneak through like, well, I know it'll break people's code, but it doesn't feel important. It doesn't feel major. And so I think, again, so this is like using the ML style syntax. I know that this means that Elm will have a smaller ecosystem and the community will grow more slowly. But I think it makes sense because of how everything fits together to make that investment and 10 years down the line, 20 years down the line, it's going to be something really, really special, even if it wasn't like as big as possible at the very beginning. So yeah, and to come back to the ML style syntax, when all your values are immutable, that syntax makes a lot of sense. So when it fits into the whole picture here, it becomes a coherent whole. And so I want to sort of end by saying, not one thing is better than the other, but these features that we arrived at independently seem like good ideas. And there are lots of ways to do it. And the thing you want to be thinking about is, how does this fit in with other features? What are the trade-offs that I need to make? What are my constraints? What are my preferences? How's that going to work for me? And if you're interested in Elm at all, you can learn more at the guide, which is trying to go through a bunch of these things, or on the subreddit or on Slack. And people are really friendly and happy to help out. And I encourage you, if you're interested, do it with a spirit of kindness and learning, because there are some people who really, really love Elm and they're really happy to be helpful. And I just want... I like them a lot, and I want them to have fun. And so ultimately, my goal with this project is I want to make web programming delightful. So even if Elm isn't for you, we're trying to do our best, and we'll hopefully get there. So I hope that spirit is how you come to these. And so ultimately, if the goal is to make web programming delightful, that will look different for different people. So if you go check out ClosureScript or Elm or TypeScript or Flow or React or whatever it is, you're going to find a place that works well for you. And it's not that someone's right, someone's wrong, it's that there are different constellations of features that work together in a particular way. And there are certain parts that overlap, and those seem like a good idea. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.64, "text": " Okay, I'm Evan Treplicchi, I designed the Elm programming language, and what I wanted", "tokens": [50364, 1033, 11, 286, 478, 22613, 8648, 4770, 8036, 11, 286, 4761, 264, 2699, 76, 9410, 2856, 11, 293, 437, 286, 1415, 50946], "temperature": 0.0, "avg_logprob": -0.29159385402028154, "compression_ratio": 1.55, "no_speech_prob": 0.0103038614615798}, {"id": 1, "seek": 0, "start": 11.64, "end": 17.28, "text": " to talk about is people often wonder, they see similarities between React and Elm, both", "tokens": [50946, 281, 751, 466, 307, 561, 2049, 2441, 11, 436, 536, 24197, 1296, 30644, 293, 2699, 76, 11, 1293, 51228], "temperature": 0.0, "avg_logprob": -0.29159385402028154, "compression_ratio": 1.55, "no_speech_prob": 0.0103038614615798}, {"id": 2, "seek": 0, "start": 17.28, "end": 21.400000000000002, "text": " these things are about creating things in browsers, these interactive applications,", "tokens": [51228, 613, 721, 366, 466, 4084, 721, 294, 36069, 11, 613, 15141, 5821, 11, 51434], "temperature": 0.0, "avg_logprob": -0.29159385402028154, "compression_ratio": 1.55, "no_speech_prob": 0.0103038614615798}, {"id": 3, "seek": 0, "start": 21.400000000000002, "end": 25.48, "text": " and people say, well, which came first, where, who originated this idea, that idea?", "tokens": [51434, 293, 561, 584, 11, 731, 11, 597, 1361, 700, 11, 689, 11, 567, 31129, 341, 1558, 11, 300, 1558, 30, 51638], "temperature": 0.0, "avg_logprob": -0.29159385402028154, "compression_ratio": 1.55, "no_speech_prob": 0.0103038614615798}, {"id": 4, "seek": 2548, "start": 25.48, "end": 30.36, "text": " And so I thought I could offer a sort of unique perspective on how these things evolved in", "tokens": [50364, 400, 370, 286, 1194, 286, 727, 2626, 257, 1333, 295, 3845, 4585, 322, 577, 613, 721, 14178, 294, 50608], "temperature": 0.0, "avg_logprob": -0.14416142513877467, "compression_ratio": 1.6411149825783973, "no_speech_prob": 0.004465957637876272}, {"id": 5, "seek": 2548, "start": 30.36, "end": 31.36, "text": " the timeline.", "tokens": [50608, 264, 12933, 13, 50658], "temperature": 0.0, "avg_logprob": -0.14416142513877467, "compression_ratio": 1.6411149825783973, "no_speech_prob": 0.004465957637876272}, {"id": 6, "seek": 2548, "start": 31.36, "end": 37.8, "text": " And what's interesting is that usually it's a case of conversion evolution, where something", "tokens": [50658, 400, 437, 311, 1880, 307, 300, 2673, 309, 311, 257, 1389, 295, 14298, 9303, 11, 689, 746, 50980], "temperature": 0.0, "avg_logprob": -0.14416142513877467, "compression_ratio": 1.6411149825783973, "no_speech_prob": 0.004465957637876272}, {"id": 7, "seek": 2548, "start": 37.8, "end": 43.04, "text": " was going on inside Facebook, I didn't know about it, and independently I was working", "tokens": [50980, 390, 516, 322, 1854, 4384, 11, 286, 994, 380, 458, 466, 309, 11, 293, 21761, 286, 390, 1364, 51242], "temperature": 0.0, "avg_logprob": -0.14416142513877467, "compression_ratio": 1.6411149825783973, "no_speech_prob": 0.004465957637876272}, {"id": 8, "seek": 2548, "start": 43.04, "end": 49.68, "text": " on my thesis at college, coming up with certain ideas, and it just turns out we came to a", "tokens": [51242, 322, 452, 22288, 412, 3859, 11, 1348, 493, 365, 1629, 3487, 11, 293, 309, 445, 4523, 484, 321, 1361, 281, 257, 51574], "temperature": 0.0, "avg_logprob": -0.14416142513877467, "compression_ratio": 1.6411149825783973, "no_speech_prob": 0.004465957637876272}, {"id": 9, "seek": 2548, "start": 49.68, "end": 53.92, "text": " lot of similar conclusions, and so I want to emphasize those and sort of see what that", "tokens": [51574, 688, 295, 2531, 22865, 11, 293, 370, 286, 528, 281, 16078, 729, 293, 1333, 295, 536, 437, 300, 51786], "temperature": 0.0, "avg_logprob": -0.14416142513877467, "compression_ratio": 1.6411149825783973, "no_speech_prob": 0.004465957637876272}, {"id": 10, "seek": 2548, "start": 53.92, "end": 55.040000000000006, "text": " might mean.", "tokens": [51786, 1062, 914, 13, 51842], "temperature": 0.0, "avg_logprob": -0.14416142513877467, "compression_ratio": 1.6411149825783973, "no_speech_prob": 0.004465957637876272}, {"id": 11, "seek": 5504, "start": 55.04, "end": 61.08, "text": " And I want to start by giving an example of conversion evolution, just from real life,", "tokens": [50364, 400, 286, 528, 281, 722, 538, 2902, 364, 1365, 295, 14298, 9303, 11, 445, 490, 957, 993, 11, 50666], "temperature": 0.0, "avg_logprob": -0.16260207101200405, "compression_ratio": 1.5630252100840336, "no_speech_prob": 0.0003916152927558869}, {"id": 12, "seek": 5504, "start": 61.08, "end": 65.96, "text": " which is you have these sort of very different creatures, birds and bees, that both can fly.", "tokens": [50666, 597, 307, 291, 362, 613, 1333, 295, 588, 819, 12281, 11, 9009, 293, 17511, 11, 300, 1293, 393, 3603, 13, 50910], "temperature": 0.0, "avg_logprob": -0.16260207101200405, "compression_ratio": 1.5630252100840336, "no_speech_prob": 0.0003916152927558869}, {"id": 13, "seek": 5504, "start": 65.96, "end": 71.44, "text": " They both somehow ended up with wings, even though millions of years ago they diverged", "tokens": [50910, 814, 1293, 6063, 4590, 493, 365, 11405, 11, 754, 1673, 6803, 295, 924, 2057, 436, 18558, 3004, 51184], "temperature": 0.0, "avg_logprob": -0.16260207101200405, "compression_ratio": 1.5630252100840336, "no_speech_prob": 0.0003916152927558869}, {"id": 14, "seek": 5504, "start": 71.44, "end": 73.03999999999999, "text": " evolutionarily.", "tokens": [51184, 9303, 3289, 13, 51264], "temperature": 0.0, "avg_logprob": -0.16260207101200405, "compression_ratio": 1.5630252100840336, "no_speech_prob": 0.0003916152927558869}, {"id": 15, "seek": 5504, "start": 73.03999999999999, "end": 79.8, "text": " And one thing that a developer might say when they see this connection is like, well, who", "tokens": [51264, 400, 472, 551, 300, 257, 10754, 1062, 584, 562, 436, 536, 341, 4984, 307, 411, 11, 731, 11, 567, 51602], "temperature": 0.0, "avg_logprob": -0.16260207101200405, "compression_ratio": 1.5630252100840336, "no_speech_prob": 0.0003916152927558869}, {"id": 16, "seek": 7980, "start": 79.8, "end": 80.8, "text": " did it better?", "tokens": [50364, 630, 309, 1101, 30, 50414], "temperature": 0.0, "avg_logprob": -0.1730422019958496, "compression_ratio": 1.7256637168141593, "no_speech_prob": 0.015898393467068672}, {"id": 17, "seek": 7980, "start": 80.8, "end": 85.64, "text": " Who did wings best?", "tokens": [50414, 2102, 630, 11405, 1151, 30, 50656], "temperature": 0.0, "avg_logprob": -0.1730422019958496, "compression_ratio": 1.7256637168141593, "no_speech_prob": 0.015898393467068672}, {"id": 18, "seek": 7980, "start": 85.64, "end": 92.44, "text": " And so one person may say, okay, well, birds, they have feathers, that's pretty cool.", "tokens": [50656, 400, 370, 472, 954, 815, 584, 11, 1392, 11, 731, 11, 9009, 11, 436, 362, 27044, 11, 300, 311, 1238, 1627, 13, 50996], "temperature": 0.0, "avg_logprob": -0.1730422019958496, "compression_ratio": 1.7256637168141593, "no_speech_prob": 0.015898393467068672}, {"id": 19, "seek": 7980, "start": 92.44, "end": 94.16, "text": " Whereas wings, they have chitin.", "tokens": [50996, 13813, 11405, 11, 436, 362, 417, 270, 259, 13, 51082], "temperature": 0.0, "avg_logprob": -0.1730422019958496, "compression_ratio": 1.7256637168141593, "no_speech_prob": 0.015898393467068672}, {"id": 20, "seek": 7980, "start": 94.16, "end": 97.96, "text": " And so with feathers, well, if it gets damaged, it can be replaced.", "tokens": [51082, 400, 370, 365, 27044, 11, 731, 11, 498, 309, 2170, 14080, 11, 309, 393, 312, 10772, 13, 51272], "temperature": 0.0, "avg_logprob": -0.1730422019958496, "compression_ratio": 1.7256637168141593, "no_speech_prob": 0.015898393467068672}, {"id": 21, "seek": 7980, "start": 97.96, "end": 101.67999999999999, "text": " Whereas with chitin, if it gets chipped, it's just chipped, it's just bad now.", "tokens": [51272, 13813, 365, 417, 270, 259, 11, 498, 309, 2170, 417, 5529, 11, 309, 311, 445, 417, 5529, 11, 309, 311, 445, 1578, 586, 13, 51458], "temperature": 0.0, "avg_logprob": -0.1730422019958496, "compression_ratio": 1.7256637168141593, "no_speech_prob": 0.015898393467068672}, {"id": 22, "seek": 7980, "start": 101.67999999999999, "end": 108.88, "text": " So like, but I think this is kind of a silly question, and in this context, like, it sort", "tokens": [51458, 407, 411, 11, 457, 286, 519, 341, 307, 733, 295, 257, 11774, 1168, 11, 293, 294, 341, 4319, 11, 411, 11, 309, 1333, 51818], "temperature": 0.0, "avg_logprob": -0.1730422019958496, "compression_ratio": 1.7256637168141593, "no_speech_prob": 0.015898393467068672}, {"id": 23, "seek": 10888, "start": 108.92, "end": 110.75999999999999, "text": " of seems ridiculous.", "tokens": [50366, 295, 2544, 11083, 13, 50458], "temperature": 0.0, "avg_logprob": -0.13977564746186932, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.0034817447885870934}, {"id": 24, "seek": 10888, "start": 110.75999999999999, "end": 115.47999999999999, "text": " And I prefer to ask the question, how does this design fit in with all the other features?", "tokens": [50458, 400, 286, 4382, 281, 1029, 264, 1168, 11, 577, 775, 341, 1715, 3318, 294, 365, 439, 264, 661, 4122, 30, 50694], "temperature": 0.0, "avg_logprob": -0.13977564746186932, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.0034817447885870934}, {"id": 25, "seek": 10888, "start": 115.47999999999999, "end": 120.44, "text": " So if we take a step back and we look at bees, well, bees have the exoskeleton, that's also", "tokens": [50694, 407, 498, 321, 747, 257, 1823, 646, 293, 321, 574, 412, 17511, 11, 731, 11, 17511, 362, 264, 454, 329, 330, 14806, 11, 300, 311, 611, 50942], "temperature": 0.0, "avg_logprob": -0.13977564746186932, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.0034817447885870934}, {"id": 26, "seek": 10888, "start": 120.44, "end": 121.6, "text": " made of chitin.", "tokens": [50942, 1027, 295, 417, 270, 259, 13, 51000], "temperature": 0.0, "avg_logprob": -0.13977564746186932, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.0034817447885870934}, {"id": 27, "seek": 10888, "start": 121.6, "end": 124.8, "text": " And so the fact that the same material can be what their wings are made of, there's no", "tokens": [51000, 400, 370, 264, 1186, 300, 264, 912, 2527, 393, 312, 437, 641, 11405, 366, 1027, 295, 11, 456, 311, 572, 51160], "temperature": 0.0, "avg_logprob": -0.13977564746186932, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.0034817447885870934}, {"id": 28, "seek": 10888, "start": 124.8, "end": 129.76, "text": " extra nutrients that they need to be able to fly, it's kind of a beautiful design.", "tokens": [51160, 2857, 17617, 300, 436, 643, 281, 312, 1075, 281, 3603, 11, 309, 311, 733, 295, 257, 2238, 1715, 13, 51408], "temperature": 0.0, "avg_logprob": -0.13977564746186932, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.0034817447885870934}, {"id": 29, "seek": 10888, "start": 129.76, "end": 133.64, "text": " They also have an open circulatory system, so instead of a heart, they just have like,", "tokens": [51408, 814, 611, 362, 364, 1269, 12515, 4745, 1185, 11, 370, 2602, 295, 257, 1917, 11, 436, 445, 362, 411, 11, 51602], "temperature": 0.0, "avg_logprob": -0.13977564746186932, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.0034817447885870934}, {"id": 30, "seek": 13364, "start": 133.64, "end": 139.27999999999997, "text": " they don't have blood, it's just like hemolymph seeps through their shell.", "tokens": [50364, 436, 500, 380, 362, 3390, 11, 309, 311, 445, 411, 415, 3280, 356, 76, 950, 536, 1878, 807, 641, 8720, 13, 50646], "temperature": 0.0, "avg_logprob": -0.13127375013045683, "compression_ratio": 1.68, "no_speech_prob": 0.0004728153580799699}, {"id": 31, "seek": 13364, "start": 139.27999999999997, "end": 145.35999999999999, "text": " Point is, they don't live a super long time because that's not an ideal system.", "tokens": [50646, 12387, 307, 11, 436, 500, 380, 1621, 257, 1687, 938, 565, 570, 300, 311, 406, 364, 7157, 1185, 13, 50950], "temperature": 0.0, "avg_logprob": -0.13127375013045683, "compression_ratio": 1.68, "no_speech_prob": 0.0004728153580799699}, {"id": 32, "seek": 13364, "start": 145.35999999999999, "end": 152.27999999999997, "text": " But for the purpose of a bee, it's like, I'm going to be alive for six weeks, maybe a couple", "tokens": [50950, 583, 337, 264, 4334, 295, 257, 17479, 11, 309, 311, 411, 11, 286, 478, 516, 281, 312, 5465, 337, 2309, 3259, 11, 1310, 257, 1916, 51296], "temperature": 0.0, "avg_logprob": -0.13127375013045683, "compression_ratio": 1.68, "no_speech_prob": 0.0004728153580799699}, {"id": 33, "seek": 13364, "start": 152.27999999999997, "end": 156.04, "text": " months, and if a wing gets chipped in that time, it's going to serve its purpose and", "tokens": [51296, 2493, 11, 293, 498, 257, 11162, 2170, 417, 5529, 294, 300, 565, 11, 309, 311, 516, 281, 4596, 1080, 4334, 293, 51484], "temperature": 0.0, "avg_logprob": -0.13127375013045683, "compression_ratio": 1.68, "no_speech_prob": 0.0004728153580799699}, {"id": 34, "seek": 13364, "start": 156.04, "end": 158.51999999999998, "text": " do a really good job in that context.", "tokens": [51484, 360, 257, 534, 665, 1691, 294, 300, 4319, 13, 51608], "temperature": 0.0, "avg_logprob": -0.13127375013045683, "compression_ratio": 1.68, "no_speech_prob": 0.0004728153580799699}, {"id": 35, "seek": 13364, "start": 158.51999999999998, "end": 163.44, "text": " Whereas with a bird, you have hollow bones, and hey, if the bone breaks, the wing is broken", "tokens": [51608, 13813, 365, 257, 5255, 11, 291, 362, 23972, 10491, 11, 293, 4177, 11, 498, 264, 9026, 9857, 11, 264, 11162, 307, 5463, 51854], "temperature": 0.0, "avg_logprob": -0.13127375013045683, "compression_ratio": 1.68, "no_speech_prob": 0.0004728153580799699}, {"id": 36, "seek": 16344, "start": 163.44, "end": 169.52, "text": " too, so that thing about feathers wasn't such a nice thing.", "tokens": [50364, 886, 11, 370, 300, 551, 466, 27044, 2067, 380, 1270, 257, 1481, 551, 13, 50668], "temperature": 0.0, "avg_logprob": -0.146642383776213, "compression_ratio": 1.8221343873517786, "no_speech_prob": 0.007571707479655743}, {"id": 37, "seek": 16344, "start": 169.52, "end": 172.8, "text": " And they have a four-chamber heart, so they can be much bigger, so they can use their", "tokens": [50668, 400, 436, 362, 257, 1451, 12, 339, 335, 607, 1917, 11, 370, 436, 393, 312, 709, 3801, 11, 370, 436, 393, 764, 641, 50832], "temperature": 0.0, "avg_logprob": -0.146642383776213, "compression_ratio": 1.8221343873517786, "no_speech_prob": 0.007571707479655743}, {"id": 38, "seek": 16344, "start": 172.8, "end": 177.48, "text": " wings to kill bugs, so they're using the wings in very different ways.", "tokens": [50832, 11405, 281, 1961, 15120, 11, 370, 436, 434, 1228, 264, 11405, 294, 588, 819, 2098, 13, 51066], "temperature": 0.0, "avg_logprob": -0.146642383776213, "compression_ratio": 1.8221343873517786, "no_speech_prob": 0.007571707479655743}, {"id": 39, "seek": 16344, "start": 177.48, "end": 181.76, "text": " The big point here is that flying seems like a good idea.", "tokens": [51066, 440, 955, 935, 510, 307, 300, 7137, 2544, 411, 257, 665, 1558, 13, 51280], "temperature": 0.0, "avg_logprob": -0.146642383776213, "compression_ratio": 1.8221343873517786, "no_speech_prob": 0.007571707479655743}, {"id": 40, "seek": 16344, "start": 181.76, "end": 185.2, "text": " And the fact that these two creatures came to the same conclusion in these totally different", "tokens": [51280, 400, 264, 1186, 300, 613, 732, 12281, 1361, 281, 264, 912, 10063, 294, 613, 3879, 819, 51452], "temperature": 0.0, "avg_logprob": -0.146642383776213, "compression_ratio": 1.8221343873517786, "no_speech_prob": 0.007571707479655743}, {"id": 41, "seek": 16344, "start": 185.2, "end": 193.24, "text": " ways with these totally different other feature sets, it's suggested like flying, it's pretty", "tokens": [51452, 2098, 365, 613, 3879, 819, 661, 4111, 6352, 11, 309, 311, 10945, 411, 7137, 11, 309, 311, 1238, 51854], "temperature": 0.0, "avg_logprob": -0.146642383776213, "compression_ratio": 1.8221343873517786, "no_speech_prob": 0.007571707479655743}, {"id": 42, "seek": 19324, "start": 193.24, "end": 195.4, "text": " neat.", "tokens": [50364, 10654, 13, 50472], "temperature": 0.0, "avg_logprob": -0.14061327217039, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.020315827801823616}, {"id": 43, "seek": 19324, "start": 195.4, "end": 199.48000000000002, "text": " And so when it comes to implementation details, I prefer to ask, how does this fit with other", "tokens": [50472, 400, 370, 562, 309, 1487, 281, 11420, 4365, 11, 286, 4382, 281, 1029, 11, 577, 775, 341, 3318, 365, 661, 50676], "temperature": 0.0, "avg_logprob": -0.14061327217039, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.020315827801823616}, {"id": 44, "seek": 19324, "start": 199.48000000000002, "end": 203.12, "text": " features rather than who did flying best?", "tokens": [50676, 4122, 2831, 813, 567, 630, 7137, 1151, 30, 50858], "temperature": 0.0, "avg_logprob": -0.14061327217039, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.020315827801823616}, {"id": 45, "seek": 19324, "start": 203.12, "end": 208.92000000000002, "text": " So with that context, we're going to try to do a similar thing with React and Elm.", "tokens": [50858, 407, 365, 300, 4319, 11, 321, 434, 516, 281, 853, 281, 360, 257, 2531, 551, 365, 30644, 293, 2699, 76, 13, 51148], "temperature": 0.0, "avg_logprob": -0.14061327217039, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.020315827801823616}, {"id": 46, "seek": 19324, "start": 208.92000000000002, "end": 212.64000000000001, "text": " So one of the features that React and Elm have in common is virtual DOM.", "tokens": [51148, 407, 472, 295, 264, 4122, 300, 30644, 293, 2699, 76, 362, 294, 2689, 307, 6374, 35727, 13, 51334], "temperature": 0.0, "avg_logprob": -0.14061327217039, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.020315827801823616}, {"id": 47, "seek": 19324, "start": 212.64000000000001, "end": 219.16000000000003, "text": " And so when I was working on Elm from the very beginning, we were having functions that", "tokens": [51334, 400, 370, 562, 286, 390, 1364, 322, 2699, 76, 490, 264, 588, 2863, 11, 321, 645, 1419, 6828, 300, 51660], "temperature": 0.0, "avg_logprob": -0.14061327217039, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.020315827801823616}, {"id": 48, "seek": 19324, "start": 219.16000000000003, "end": 222.68, "text": " would create this data structure, and then I would just, based on that data structure,", "tokens": [51660, 576, 1884, 341, 1412, 3877, 11, 293, 550, 286, 576, 445, 11, 2361, 322, 300, 1412, 3877, 11, 51836], "temperature": 0.0, "avg_logprob": -0.14061327217039, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.020315827801823616}, {"id": 49, "seek": 22268, "start": 222.68, "end": 226.0, "text": " we built the DOM on every frame.", "tokens": [50364, 321, 3094, 264, 35727, 322, 633, 3920, 13, 50530], "temperature": 0.0, "avg_logprob": -0.1335348365581141, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.017424872145056725}, {"id": 50, "seek": 22268, "start": 226.0, "end": 230.28, "text": " And I was like, that's kind of crazy, I don't know if that's going to work out.", "tokens": [50530, 400, 286, 390, 411, 11, 300, 311, 733, 295, 3219, 11, 286, 500, 380, 458, 498, 300, 311, 516, 281, 589, 484, 13, 50744], "temperature": 0.0, "avg_logprob": -0.1335348365581141, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.017424872145056725}, {"id": 51, "seek": 22268, "start": 230.28, "end": 233.8, "text": " And so over time, I was like, okay, well, I can incrementally do it so it doesn't flash,", "tokens": [50744, 400, 370, 670, 565, 11, 286, 390, 411, 11, 1392, 11, 731, 11, 286, 393, 26200, 379, 360, 309, 370, 309, 1177, 380, 7319, 11, 50920], "temperature": 0.0, "avg_logprob": -0.1335348365581141, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.017424872145056725}, {"id": 52, "seek": 22268, "start": 233.8, "end": 236.20000000000002, "text": " and I can preserve some information.", "tokens": [50920, 293, 286, 393, 15665, 512, 1589, 13, 51040], "temperature": 0.0, "avg_logprob": -0.1335348365581141, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.017424872145056725}, {"id": 53, "seek": 22268, "start": 236.20000000000002, "end": 240.96, "text": " And subsequently, I saw that React did the same thing, and that sort of really validated", "tokens": [51040, 400, 26514, 11, 286, 1866, 300, 30644, 630, 264, 912, 551, 11, 293, 300, 1333, 295, 534, 40693, 51278], "temperature": 0.0, "avg_logprob": -0.1335348365581141, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.017424872145056725}, {"id": 54, "seek": 22268, "start": 240.96, "end": 247.68, "text": " that design that I think anyone I asked who would have said, that's obviously crazy.", "tokens": [51278, 300, 1715, 300, 286, 519, 2878, 286, 2351, 567, 576, 362, 848, 11, 300, 311, 2745, 3219, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1335348365581141, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.017424872145056725}, {"id": 55, "seek": 24768, "start": 247.68, "end": 252.44, "text": " And so when you look into the details in virtual DOM, with React, you have a special", "tokens": [50364, 400, 370, 562, 291, 574, 666, 264, 4365, 294, 6374, 35727, 11, 365, 30644, 11, 291, 362, 257, 2121, 50602], "temperature": 0.0, "avg_logprob": -0.1428610514668585, "compression_ratio": 1.5311203319502074, "no_speech_prob": 0.00638343021273613}, {"id": 56, "seek": 24768, "start": 252.44, "end": 257.24, "text": " syntax called JSX, so it's giving you this familiar HTML in your JavaScript code.", "tokens": [50602, 28431, 1219, 33063, 55, 11, 370, 309, 311, 2902, 291, 341, 4963, 17995, 294, 428, 15778, 3089, 13, 50842], "temperature": 0.0, "avg_logprob": -0.1428610514668585, "compression_ratio": 1.5311203319502074, "no_speech_prob": 0.00638343021273613}, {"id": 57, "seek": 24768, "start": 257.24, "end": 260.36, "text": " Whereas in Elm, we don't have a special syntax, and this is something that people, when they", "tokens": [50842, 13813, 294, 2699, 76, 11, 321, 500, 380, 362, 257, 2121, 28431, 11, 293, 341, 307, 746, 300, 561, 11, 562, 436, 50998], "temperature": 0.0, "avg_logprob": -0.1428610514668585, "compression_ratio": 1.5311203319502074, "no_speech_prob": 0.00638343021273613}, {"id": 58, "seek": 24768, "start": 260.36, "end": 264.96000000000004, "text": " come to Elm, will find weird, it's like, well, how do I set this up?", "tokens": [50998, 808, 281, 2699, 76, 11, 486, 915, 3657, 11, 309, 311, 411, 11, 731, 11, 577, 360, 286, 992, 341, 493, 30, 51228], "temperature": 0.0, "avg_logprob": -0.1428610514668585, "compression_ratio": 1.5311203319502074, "no_speech_prob": 0.00638343021273613}, {"id": 59, "seek": 24768, "start": 264.96000000000004, "end": 271.52, "text": " So I want to show a little program here.", "tokens": [51228, 407, 286, 528, 281, 855, 257, 707, 1461, 510, 13, 51556], "temperature": 0.0, "avg_logprob": -0.1428610514668585, "compression_ratio": 1.5311203319502074, "no_speech_prob": 0.00638343021273613}, {"id": 60, "seek": 27152, "start": 271.52, "end": 280.64, "text": " So I'm going to take a program from the Elm guide.", "tokens": [50364, 407, 286, 478, 516, 281, 747, 257, 1461, 490, 264, 2699, 76, 5934, 13, 50820], "temperature": 0.0, "avg_logprob": -0.23033062861515927, "compression_ratio": 1.3647798742138364, "no_speech_prob": 0.00039807878783904016}, {"id": 61, "seek": 27152, "start": 280.64, "end": 288.4, "text": " That's just like the very beginner thing, and we'll take a look at it.", "tokens": [50820, 663, 311, 445, 411, 264, 588, 22080, 551, 11, 293, 321, 603, 747, 257, 574, 412, 309, 13, 51208], "temperature": 0.0, "avg_logprob": -0.23033062861515927, "compression_ratio": 1.3647798742138364, "no_speech_prob": 0.00039807878783904016}, {"id": 62, "seek": 27152, "start": 288.4, "end": 293.08, "text": " Tell me when you can see this.", "tokens": [51208, 5115, 385, 562, 291, 393, 536, 341, 13, 51442], "temperature": 0.0, "avg_logprob": -0.23033062861515927, "compression_ratio": 1.3647798742138364, "no_speech_prob": 0.00039807878783904016}, {"id": 63, "seek": 27152, "start": 293.08, "end": 296.08, "text": " Okay.", "tokens": [51442, 1033, 13, 51592], "temperature": 0.0, "avg_logprob": -0.23033062861515927, "compression_ratio": 1.3647798742138364, "no_speech_prob": 0.00039807878783904016}, {"id": 64, "seek": 27152, "start": 296.08, "end": 300.24, "text": " This is the problem of having the massive high resolution.", "tokens": [51592, 639, 307, 264, 1154, 295, 1419, 264, 5994, 1090, 8669, 13, 51800], "temperature": 0.0, "avg_logprob": -0.23033062861515927, "compression_ratio": 1.3647798742138364, "no_speech_prob": 0.00039807878783904016}, {"id": 65, "seek": 30024, "start": 300.24, "end": 303.04, "text": " It's quite the right size.", "tokens": [50364, 467, 311, 1596, 264, 558, 2744, 13, 50504], "temperature": 0.0, "avg_logprob": -0.15536798249690906, "compression_ratio": 1.5775862068965518, "no_speech_prob": 0.019706031307578087}, {"id": 66, "seek": 30024, "start": 303.04, "end": 304.2, "text": " Okay.", "tokens": [50504, 1033, 13, 50562], "temperature": 0.0, "avg_logprob": -0.15536798249690906, "compression_ratio": 1.5775862068965518, "no_speech_prob": 0.019706031307578087}, {"id": 67, "seek": 30024, "start": 304.2, "end": 308.68, "text": " So I'm going to build that, and we can look at how the view code works here.", "tokens": [50562, 407, 286, 478, 516, 281, 1322, 300, 11, 293, 321, 393, 574, 412, 577, 264, 1910, 3089, 1985, 510, 13, 50786], "temperature": 0.0, "avg_logprob": -0.15536798249690906, "compression_ratio": 1.5775862068965518, "no_speech_prob": 0.019706031307578087}, {"id": 68, "seek": 30024, "start": 308.68, "end": 312.48, "text": " So rather than an HTML-style thing, we're saying, okay, I have a div, and it has three", "tokens": [50786, 407, 2831, 813, 364, 17995, 12, 15014, 551, 11, 321, 434, 1566, 11, 1392, 11, 286, 362, 257, 3414, 11, 293, 309, 575, 1045, 50976], "temperature": 0.0, "avg_logprob": -0.15536798249690906, "compression_ratio": 1.5775862068965518, "no_speech_prob": 0.019706031307578087}, {"id": 69, "seek": 30024, "start": 312.48, "end": 315.84000000000003, "text": " children, a button, a div, and another button.", "tokens": [50976, 2227, 11, 257, 2960, 11, 257, 3414, 11, 293, 1071, 2960, 13, 51144], "temperature": 0.0, "avg_logprob": -0.15536798249690906, "compression_ratio": 1.5775862068965518, "no_speech_prob": 0.019706031307578087}, {"id": 70, "seek": 30024, "start": 315.84000000000003, "end": 323.96000000000004, "text": " And when I actually go look at that code, we can see, okay, not the most exciting beginner", "tokens": [51144, 400, 562, 286, 767, 352, 574, 412, 300, 3089, 11, 321, 393, 536, 11, 1392, 11, 406, 264, 881, 4670, 22080, 51550], "temperature": 0.0, "avg_logprob": -0.15536798249690906, "compression_ratio": 1.5775862068965518, "no_speech_prob": 0.019706031307578087}, {"id": 71, "seek": 30024, "start": 323.96000000000004, "end": 326.76, "text": " program, but it does something.", "tokens": [51550, 1461, 11, 457, 309, 775, 746, 13, 51690], "temperature": 0.0, "avg_logprob": -0.15536798249690906, "compression_ratio": 1.5775862068965518, "no_speech_prob": 0.019706031307578087}, {"id": 72, "seek": 32676, "start": 326.76, "end": 330.84, "text": " And when we look back at the view code, we see that exact structure.", "tokens": [50364, 400, 562, 321, 574, 646, 412, 264, 1910, 3089, 11, 321, 536, 300, 1900, 3877, 13, 50568], "temperature": 0.0, "avg_logprob": -0.09550210664857109, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.008312967605888844}, {"id": 73, "seek": 32676, "start": 330.84, "end": 331.84, "text": " We have the button.", "tokens": [50568, 492, 362, 264, 2960, 13, 50618], "temperature": 0.0, "avg_logprob": -0.09550210664857109, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.008312967605888844}, {"id": 74, "seek": 32676, "start": 331.84, "end": 333.71999999999997, "text": " It's got a negative sign.", "tokens": [50618, 467, 311, 658, 257, 3671, 1465, 13, 50712], "temperature": 0.0, "avg_logprob": -0.09550210664857109, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.008312967605888844}, {"id": 75, "seek": 32676, "start": 333.71999999999997, "end": 337.32, "text": " And what's neat about doing this all in Elm is anything you want to do, you can do it", "tokens": [50712, 400, 437, 311, 10654, 466, 884, 341, 439, 294, 2699, 76, 307, 1340, 291, 528, 281, 360, 11, 291, 393, 360, 309, 50892], "temperature": 0.0, "avg_logprob": -0.09550210664857109, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.008312967605888844}, {"id": 76, "seek": 32676, "start": 337.32, "end": 338.32, "text": " in Elm syntax.", "tokens": [50892, 294, 2699, 76, 28431, 13, 50942], "temperature": 0.0, "avg_logprob": -0.09550210664857109, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.008312967605888844}, {"id": 77, "seek": 32676, "start": 338.32, "end": 345.24, "text": " So rather than saying I want a number here, I can say maybe I want a list, and I want", "tokens": [50942, 407, 2831, 813, 1566, 286, 528, 257, 1230, 510, 11, 286, 393, 584, 1310, 286, 528, 257, 1329, 11, 293, 286, 528, 51288], "temperature": 0.0, "avg_logprob": -0.09550210664857109, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.008312967605888844}, {"id": 78, "seek": 32676, "start": 345.24, "end": 352.36, "text": " to view a dot for every number from one to the count.", "tokens": [51288, 281, 1910, 257, 5893, 337, 633, 1230, 490, 472, 281, 264, 1207, 13, 51644], "temperature": 0.0, "avg_logprob": -0.09550210664857109, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.008312967605888844}, {"id": 79, "seek": 35236, "start": 352.36, "end": 356.88, "text": " And then I can just make an Elm function of view dot that takes the number, and instead", "tokens": [50364, 400, 550, 286, 393, 445, 652, 364, 2699, 76, 2445, 295, 1910, 5893, 300, 2516, 264, 1230, 11, 293, 2602, 50590], "temperature": 0.0, "avg_logprob": -0.11861197662353516, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.02001563087105751}, {"id": 80, "seek": 35236, "start": 356.88, "end": 360.68, "text": " it just says, I'll show a star here.", "tokens": [50590, 309, 445, 1619, 11, 286, 603, 855, 257, 3543, 510, 13, 50780], "temperature": 0.0, "avg_logprob": -0.11861197662353516, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.02001563087105751}, {"id": 81, "seek": 35236, "start": 360.68, "end": 368.44, "text": " And so when I compile that, I can go and look, and oops.", "tokens": [50780, 400, 370, 562, 286, 31413, 300, 11, 286, 393, 352, 293, 574, 11, 293, 34166, 13, 51168], "temperature": 0.0, "avg_logprob": -0.11861197662353516, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.02001563087105751}, {"id": 82, "seek": 35236, "start": 368.44, "end": 371.08000000000004, "text": " So now I see dots when it shows up.", "tokens": [51168, 407, 586, 286, 536, 15026, 562, 309, 3110, 493, 13, 51300], "temperature": 0.0, "avg_logprob": -0.11861197662353516, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.02001563087105751}, {"id": 83, "seek": 35236, "start": 371.08000000000004, "end": 372.44, "text": " So it's quite a nice thing.", "tokens": [51300, 407, 309, 311, 1596, 257, 1481, 551, 13, 51368], "temperature": 0.0, "avg_logprob": -0.11861197662353516, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.02001563087105751}, {"id": 84, "seek": 35236, "start": 372.44, "end": 376.56, "text": " So if I want to use any feature of Elm, it's sort of like the templating language for Elm", "tokens": [51368, 407, 498, 286, 528, 281, 764, 604, 4111, 295, 2699, 76, 11, 309, 311, 1333, 295, 411, 264, 9100, 990, 2856, 337, 2699, 76, 51574], "temperature": 0.0, "avg_logprob": -0.11861197662353516, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.02001563087105751}, {"id": 85, "seek": 35236, "start": 376.56, "end": 378.8, "text": " is Elm.", "tokens": [51574, 307, 2699, 76, 13, 51686], "temperature": 0.0, "avg_logprob": -0.11861197662353516, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.02001563087105751}, {"id": 86, "seek": 35236, "start": 378.8, "end": 382.0, "text": " So I'm not here to say one way is better or not.", "tokens": [51686, 407, 286, 478, 406, 510, 281, 584, 472, 636, 307, 1101, 420, 406, 13, 51846], "temperature": 0.0, "avg_logprob": -0.11861197662353516, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.02001563087105751}, {"id": 87, "seek": 38200, "start": 382.0, "end": 384.04, "text": " It's better to look at it in context.", "tokens": [50364, 467, 311, 1101, 281, 574, 412, 309, 294, 4319, 13, 50466], "temperature": 0.0, "avg_logprob": -0.15756414662236753, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.006481972988694906}, {"id": 88, "seek": 38200, "start": 384.04, "end": 389.12, "text": " And so in the React world, you're using JavaScript, you're using the C-style syntax.", "tokens": [50466, 400, 370, 294, 264, 30644, 1002, 11, 291, 434, 1228, 15778, 11, 291, 434, 1228, 264, 383, 12, 15014, 28431, 13, 50720], "temperature": 0.0, "avg_logprob": -0.15756414662236753, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.006481972988694906}, {"id": 89, "seek": 38200, "start": 389.12, "end": 393.76, "text": " And this goes back to 1972 at least when C came out.", "tokens": [50720, 400, 341, 1709, 646, 281, 32952, 412, 1935, 562, 383, 1361, 484, 13, 50952], "temperature": 0.0, "avg_logprob": -0.15756414662236753, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.006481972988694906}, {"id": 90, "seek": 38200, "start": 393.76, "end": 399.56, "text": " And so JavaScript, if you believe the origin myths, could have had a Lisp syntax.", "tokens": [50952, 400, 370, 15778, 11, 498, 291, 1697, 264, 4957, 28205, 11, 727, 362, 632, 257, 441, 7631, 28431, 13, 51242], "temperature": 0.0, "avg_logprob": -0.15756414662236753, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.006481972988694906}, {"id": 91, "seek": 38200, "start": 399.56, "end": 403.72, "text": " But for the sake of familiarity, went with the C-style syntax that everyone was familiar", "tokens": [51242, 583, 337, 264, 9717, 295, 49828, 11, 1437, 365, 264, 383, 12, 15014, 28431, 300, 1518, 390, 4963, 51450], "temperature": 0.0, "avg_logprob": -0.15756414662236753, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.006481972988694906}, {"id": 92, "seek": 38200, "start": 403.72, "end": 404.72, "text": " with.", "tokens": [51450, 365, 13, 51500], "temperature": 0.0, "avg_logprob": -0.15756414662236753, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.006481972988694906}, {"id": 93, "seek": 38200, "start": 404.72, "end": 410.04, "text": " So essentially, this is an ecosystem that's putting a premium or using familiarity as", "tokens": [51500, 407, 4476, 11, 341, 307, 364, 11311, 300, 311, 3372, 257, 12049, 420, 1228, 49828, 382, 51766], "temperature": 0.0, "avg_logprob": -0.15756414662236753, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.006481972988694906}, {"id": 94, "seek": 41004, "start": 410.04, "end": 416.6, "text": " an onboarding tool to make people feel confident and dive into things and use that to learn.", "tokens": [50364, 364, 24033, 278, 2290, 281, 652, 561, 841, 6679, 293, 9192, 666, 721, 293, 764, 300, 281, 1466, 13, 50692], "temperature": 0.0, "avg_logprob": -0.15064231748503398, "compression_ratio": 1.635036496350365, "no_speech_prob": 0.005812996532768011}, {"id": 95, "seek": 41004, "start": 416.6, "end": 418.84000000000003, "text": " Whereas in Elm, I have an ML-style syntax.", "tokens": [50692, 13813, 294, 2699, 76, 11, 286, 362, 364, 21601, 12, 15014, 28431, 13, 50804], "temperature": 0.0, "avg_logprob": -0.15064231748503398, "compression_ratio": 1.635036496350365, "no_speech_prob": 0.005812996532768011}, {"id": 96, "seek": 41004, "start": 418.84000000000003, "end": 426.16, "text": " And interestingly, that goes back to 1973 at least, but it's just not as widely known.", "tokens": [50804, 400, 25873, 11, 300, 1709, 646, 281, 33530, 412, 1935, 11, 457, 309, 311, 445, 406, 382, 13371, 2570, 13, 51170], "temperature": 0.0, "avg_logprob": -0.15064231748503398, "compression_ratio": 1.635036496350365, "no_speech_prob": 0.005812996532768011}, {"id": 97, "seek": 41004, "start": 426.16, "end": 429.72, "text": " And so to say, well, which of these is better is kind of like saying, well, is Arabic script", "tokens": [51170, 400, 370, 281, 584, 11, 731, 11, 597, 295, 613, 307, 1101, 307, 733, 295, 411, 1566, 11, 731, 11, 307, 19938, 5755, 51348], "temperature": 0.0, "avg_logprob": -0.15064231748503398, "compression_ratio": 1.635036496350365, "no_speech_prob": 0.005812996532768011}, {"id": 98, "seek": 41004, "start": 429.72, "end": 431.72, "text": " better or is Korean script better?", "tokens": [51348, 1101, 420, 307, 6933, 5755, 1101, 30, 51448], "temperature": 0.0, "avg_logprob": -0.15064231748503398, "compression_ratio": 1.635036496350365, "no_speech_prob": 0.005812996532768011}, {"id": 99, "seek": 41004, "start": 431.72, "end": 433.76, "text": " It's like, well, which one do you know?", "tokens": [51448, 467, 311, 411, 11, 731, 11, 597, 472, 360, 291, 458, 30, 51550], "temperature": 0.0, "avg_logprob": -0.15064231748503398, "compression_ratio": 1.635036496350365, "no_speech_prob": 0.005812996532768011}, {"id": 100, "seek": 41004, "start": 433.76, "end": 438.64000000000004, "text": " And you probably will prefer that one, at least at first.", "tokens": [51550, 400, 291, 1391, 486, 4382, 300, 472, 11, 412, 1935, 412, 700, 13, 51794], "temperature": 0.0, "avg_logprob": -0.15064231748503398, "compression_ratio": 1.635036496350365, "no_speech_prob": 0.005812996532768011}, {"id": 101, "seek": 43864, "start": 438.64, "end": 443.84, "text": " And so I know that Elm pays a familiarity cost in making this choice.", "tokens": [50364, 400, 370, 286, 458, 300, 2699, 76, 10604, 257, 49828, 2063, 294, 1455, 341, 3922, 13, 50624], "temperature": 0.0, "avg_logprob": -0.11193255548891815, "compression_ratio": 1.6102941176470589, "no_speech_prob": 0.0011688078520819545}, {"id": 102, "seek": 43864, "start": 443.84, "end": 447.44, "text": " But I think it fits in with all the other Elm features that we're going to see.", "tokens": [50624, 583, 286, 519, 309, 9001, 294, 365, 439, 264, 661, 2699, 76, 4122, 300, 321, 434, 516, 281, 536, 13, 50804], "temperature": 0.0, "avg_logprob": -0.11193255548891815, "compression_ratio": 1.6102941176470589, "no_speech_prob": 0.0011688078520819545}, {"id": 103, "seek": 43864, "start": 447.44, "end": 453.84, "text": " And so I'm willing to pay that hit in maybe where our community grows a little bit slower.", "tokens": [50804, 400, 370, 286, 478, 4950, 281, 1689, 300, 2045, 294, 1310, 689, 527, 1768, 13156, 257, 707, 857, 14009, 13, 51124], "temperature": 0.0, "avg_logprob": -0.11193255548891815, "compression_ratio": 1.6102941176470589, "no_speech_prob": 0.0011688078520819545}, {"id": 104, "seek": 43864, "start": 453.84, "end": 455.44, "text": " But it makes this coherent whole.", "tokens": [51124, 583, 309, 1669, 341, 36239, 1379, 13, 51204], "temperature": 0.0, "avg_logprob": -0.11193255548891815, "compression_ratio": 1.6102941176470589, "no_speech_prob": 0.0011688078520819545}, {"id": 105, "seek": 43864, "start": 455.44, "end": 458.4, "text": " And so when a question comes up, should we use something like JSX?", "tokens": [51204, 400, 370, 562, 257, 1168, 1487, 493, 11, 820, 321, 764, 746, 411, 33063, 55, 30, 51352], "temperature": 0.0, "avg_logprob": -0.11193255548891815, "compression_ratio": 1.6102941176470589, "no_speech_prob": 0.0011688078520819545}, {"id": 106, "seek": 43864, "start": 458.4, "end": 466.56, "text": " It's like, well, we've already sort of committed to not using syntax as an onboarding technique.", "tokens": [51352, 467, 311, 411, 11, 731, 11, 321, 600, 1217, 1333, 295, 7784, 281, 406, 1228, 28431, 382, 364, 24033, 278, 6532, 13, 51760], "temperature": 0.0, "avg_logprob": -0.11193255548891815, "compression_ratio": 1.6102941176470589, "no_speech_prob": 0.0011688078520819545}, {"id": 107, "seek": 46656, "start": 466.56, "end": 469.88, "text": " So we'll come back to that and see how it fits in more.", "tokens": [50364, 407, 321, 603, 808, 646, 281, 300, 293, 536, 577, 309, 9001, 294, 544, 13, 50530], "temperature": 0.0, "avg_logprob": -0.14731034028877332, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.002549423836171627}, {"id": 108, "seek": 46656, "start": 469.88, "end": 474.24, "text": " So another thing that React and Elm have in common is unidirectional flow.", "tokens": [50530, 407, 1071, 551, 300, 30644, 293, 2699, 76, 362, 294, 2689, 307, 517, 327, 621, 41048, 3095, 13, 50748], "temperature": 0.0, "avg_logprob": -0.14731034028877332, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.002549423836171627}, {"id": 109, "seek": 46656, "start": 474.24, "end": 483.28, "text": " And so for me, I first sort of, this became a distinct concept for me when I was at Hacker", "tokens": [50748, 400, 370, 337, 385, 11, 286, 700, 1333, 295, 11, 341, 3062, 257, 10644, 3410, 337, 385, 562, 286, 390, 412, 389, 23599, 51200], "temperature": 0.0, "avg_logprob": -0.14731034028877332, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.002549423836171627}, {"id": 110, "seek": 46656, "start": 483.28, "end": 486.12, "text": " School, now Recurse Center back in 2014.", "tokens": [51200, 5070, 11, 586, 9647, 374, 405, 5169, 646, 294, 8227, 13, 51342], "temperature": 0.0, "avg_logprob": -0.14731034028877332, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.002549423836171627}, {"id": 111, "seek": 46656, "start": 486.12, "end": 488.8, "text": " And a student there made this game called Bessel.", "tokens": [51342, 400, 257, 3107, 456, 1027, 341, 1216, 1219, 363, 47166, 13, 51476], "temperature": 0.0, "avg_logprob": -0.14731034028877332, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.002549423836171627}, {"id": 112, "seek": 46656, "start": 488.8, "end": 494.76, "text": " And this student had never done like functional programming before.", "tokens": [51476, 400, 341, 3107, 632, 1128, 1096, 411, 11745, 9410, 949, 13, 51774], "temperature": 0.0, "avg_logprob": -0.14731034028877332, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.002549423836171627}, {"id": 113, "seek": 49476, "start": 494.76, "end": 497.84, "text": " They had done Python, I think, with the language that they knew.", "tokens": [50364, 814, 632, 1096, 15329, 11, 286, 519, 11, 365, 264, 2856, 300, 436, 2586, 13, 50518], "temperature": 0.0, "avg_logprob": -0.11719708972507054, "compression_ratio": 1.732258064516129, "no_speech_prob": 0.07152809947729111}, {"id": 114, "seek": 49476, "start": 497.84, "end": 501.12, "text": " And while I was there for the two weeks, they wanted to try something out.", "tokens": [50518, 400, 1339, 286, 390, 456, 337, 264, 732, 3259, 11, 436, 1415, 281, 853, 746, 484, 13, 50682], "temperature": 0.0, "avg_logprob": -0.11719708972507054, "compression_ratio": 1.732258064516129, "no_speech_prob": 0.07152809947729111}, {"id": 115, "seek": 49476, "start": 501.12, "end": 504.32, "text": " So they made this little game where you have to go through the blood vessel.", "tokens": [50682, 407, 436, 1027, 341, 707, 1216, 689, 291, 362, 281, 352, 807, 264, 3390, 18098, 13, 50842], "temperature": 0.0, "avg_logprob": -0.11719708972507054, "compression_ratio": 1.732258064516129, "no_speech_prob": 0.07152809947729111}, {"id": 116, "seek": 49476, "start": 504.32, "end": 507.59999999999997, "text": " And if you run into the wall, you explode.", "tokens": [50842, 400, 498, 291, 1190, 666, 264, 2929, 11, 291, 21411, 13, 51006], "temperature": 0.0, "avg_logprob": -0.11719708972507054, "compression_ratio": 1.732258064516129, "no_speech_prob": 0.07152809947729111}, {"id": 117, "seek": 49476, "start": 507.59999999999997, "end": 509.2, "text": " And so this is like a weak project.", "tokens": [51006, 400, 370, 341, 307, 411, 257, 5336, 1716, 13, 51086], "temperature": 0.0, "avg_logprob": -0.11719708972507054, "compression_ratio": 1.732258064516129, "no_speech_prob": 0.07152809947729111}, {"id": 118, "seek": 49476, "start": 509.2, "end": 512.2, "text": " He's just trying functional programming for the first time.", "tokens": [51086, 634, 311, 445, 1382, 11745, 9410, 337, 264, 700, 565, 13, 51236], "temperature": 0.0, "avg_logprob": -0.11719708972507054, "compression_ratio": 1.732258064516129, "no_speech_prob": 0.07152809947729111}, {"id": 119, "seek": 49476, "start": 512.2, "end": 514.4, "text": " And at the end, he asked me for a code review.", "tokens": [51236, 400, 412, 264, 917, 11, 415, 2351, 385, 337, 257, 3089, 3131, 13, 51346], "temperature": 0.0, "avg_logprob": -0.11719708972507054, "compression_ratio": 1.732258064516129, "no_speech_prob": 0.07152809947729111}, {"id": 120, "seek": 49476, "start": 514.4, "end": 518.64, "text": " And what was crazy was his code was really good.", "tokens": [51346, 400, 437, 390, 3219, 390, 702, 3089, 390, 534, 665, 13, 51558], "temperature": 0.0, "avg_logprob": -0.11719708972507054, "compression_ratio": 1.732258064516129, "no_speech_prob": 0.07152809947729111}, {"id": 121, "seek": 49476, "start": 518.64, "end": 523.96, "text": " And that's not to say like, it's just like when you start, I found it surprising that", "tokens": [51558, 400, 300, 311, 406, 281, 584, 411, 11, 309, 311, 445, 411, 562, 291, 722, 11, 286, 1352, 309, 8830, 300, 51824], "temperature": 0.0, "avg_logprob": -0.11719708972507054, "compression_ratio": 1.732258064516129, "no_speech_prob": 0.07152809947729111}, {"id": 122, "seek": 52396, "start": 523.96, "end": 526.36, "text": " someone starting functional programming for the first time would end up with a program", "tokens": [50364, 1580, 2891, 11745, 9410, 337, 264, 700, 565, 576, 917, 493, 365, 257, 1461, 50484], "temperature": 0.0, "avg_logprob": -0.17502391084711602, "compression_ratio": 1.7912457912457913, "no_speech_prob": 0.007117826025933027}, {"id": 123, "seek": 52396, "start": 526.36, "end": 528.4000000000001, "text": " where like, that's how I would architect it.", "tokens": [50484, 689, 411, 11, 300, 311, 577, 286, 576, 6331, 309, 13, 50586], "temperature": 0.0, "avg_logprob": -0.17502391084711602, "compression_ratio": 1.7912457912457913, "no_speech_prob": 0.007117826025933027}, {"id": 124, "seek": 52396, "start": 528.4000000000001, "end": 531.96, "text": " I have no concerns, like that's great.", "tokens": [50586, 286, 362, 572, 7389, 11, 411, 300, 311, 869, 13, 50764], "temperature": 0.0, "avg_logprob": -0.17502391084711602, "compression_ratio": 1.7912457912457913, "no_speech_prob": 0.007117826025933027}, {"id": 125, "seek": 52396, "start": 531.96, "end": 534.76, "text": " And it matched how I would structure my code as well.", "tokens": [50764, 400, 309, 21447, 577, 286, 576, 3877, 452, 3089, 382, 731, 13, 50904], "temperature": 0.0, "avg_logprob": -0.17502391084711602, "compression_ratio": 1.7912457912457913, "no_speech_prob": 0.007117826025933027}, {"id": 126, "seek": 52396, "start": 534.76, "end": 536.6800000000001, "text": " And I thought that was just a me thing.", "tokens": [50904, 400, 286, 1194, 300, 390, 445, 257, 385, 551, 13, 51000], "temperature": 0.0, "avg_logprob": -0.17502391084711602, "compression_ratio": 1.7912457912457913, "no_speech_prob": 0.007117826025933027}, {"id": 127, "seek": 52396, "start": 536.6800000000001, "end": 539.9200000000001, "text": " And so this was when I started to notice, okay, there's this pattern that sort of Elm", "tokens": [51000, 400, 370, 341, 390, 562, 286, 1409, 281, 3449, 11, 1392, 11, 456, 311, 341, 5102, 300, 1333, 295, 2699, 76, 51162], "temperature": 0.0, "avg_logprob": -0.17502391084711602, "compression_ratio": 1.7912457912457913, "no_speech_prob": 0.007117826025933027}, {"id": 128, "seek": 52396, "start": 539.9200000000001, "end": 541.9200000000001, "text": " wants us to write code in a certain way.", "tokens": [51162, 2738, 505, 281, 2464, 3089, 294, 257, 1629, 636, 13, 51262], "temperature": 0.0, "avg_logprob": -0.17502391084711602, "compression_ratio": 1.7912457912457913, "no_speech_prob": 0.007117826025933027}, {"id": 129, "seek": 52396, "start": 541.9200000000001, "end": 545.88, "text": " So this is when the Elm architecture sort of got a name, even though everyone who used", "tokens": [51262, 407, 341, 307, 562, 264, 2699, 76, 9482, 1333, 295, 658, 257, 1315, 11, 754, 1673, 1518, 567, 1143, 51460], "temperature": 0.0, "avg_logprob": -0.17502391084711602, "compression_ratio": 1.7912457912457913, "no_speech_prob": 0.007117826025933027}, {"id": 130, "seek": 52396, "start": 545.88, "end": 549.0400000000001, "text": " it, who used Elm had been doing this kind of pattern.", "tokens": [51460, 309, 11, 567, 1143, 2699, 76, 632, 668, 884, 341, 733, 295, 5102, 13, 51618], "temperature": 0.0, "avg_logprob": -0.17502391084711602, "compression_ratio": 1.7912457912457913, "no_speech_prob": 0.007117826025933027}, {"id": 131, "seek": 54904, "start": 549.04, "end": 554.4, "text": " And the idea is that you have a model that says what's going on in your application.", "tokens": [50364, 400, 264, 1558, 307, 300, 291, 362, 257, 2316, 300, 1619, 437, 311, 516, 322, 294, 428, 3861, 13, 50632], "temperature": 0.0, "avg_logprob": -0.1404686472774331, "compression_ratio": 1.7515527950310559, "no_speech_prob": 0.04882583022117615}, {"id": 132, "seek": 54904, "start": 554.4, "end": 555.8, "text": " And it creates HTML.", "tokens": [50632, 400, 309, 7829, 17995, 13, 50702], "temperature": 0.0, "avg_logprob": -0.1404686472774331, "compression_ratio": 1.7515527950310559, "no_speech_prob": 0.04882583022117615}, {"id": 133, "seek": 54904, "start": 555.8, "end": 557.68, "text": " That gets sent to the Elm runtime system.", "tokens": [50702, 663, 2170, 2279, 281, 264, 2699, 76, 34474, 1185, 13, 50796], "temperature": 0.0, "avg_logprob": -0.1404686472774331, "compression_ratio": 1.7515527950310559, "no_speech_prob": 0.04882583022117615}, {"id": 134, "seek": 54904, "start": 557.68, "end": 561.4399999999999, "text": " It renders it, deals with the DOM, does the diffing, all that kind of stuff.", "tokens": [50796, 467, 6125, 433, 309, 11, 11215, 365, 264, 35727, 11, 775, 264, 7593, 278, 11, 439, 300, 733, 295, 1507, 13, 50984], "temperature": 0.0, "avg_logprob": -0.1404686472774331, "compression_ratio": 1.7515527950310559, "no_speech_prob": 0.04882583022117615}, {"id": 135, "seek": 54904, "start": 561.4399999999999, "end": 563.64, "text": " And then it'll send back messages.", "tokens": [50984, 400, 550, 309, 603, 2845, 646, 7897, 13, 51094], "temperature": 0.0, "avg_logprob": -0.1404686472774331, "compression_ratio": 1.7515527950310559, "no_speech_prob": 0.04882583022117615}, {"id": 136, "seek": 54904, "start": 563.64, "end": 565.5999999999999, "text": " And that is how you update your model.", "tokens": [51094, 400, 300, 307, 577, 291, 5623, 428, 2316, 13, 51192], "temperature": 0.0, "avg_logprob": -0.1404686472774331, "compression_ratio": 1.7515527950310559, "no_speech_prob": 0.04882583022117615}, {"id": 137, "seek": 54904, "start": 565.5999999999999, "end": 570.0, "text": " You send new HTML, and the cycle just goes round and round and round.", "tokens": [51192, 509, 2845, 777, 17995, 11, 293, 264, 6586, 445, 1709, 3098, 293, 3098, 293, 3098, 13, 51412], "temperature": 0.0, "avg_logprob": -0.1404686472774331, "compression_ratio": 1.7515527950310559, "no_speech_prob": 0.04882583022117615}, {"id": 138, "seek": 54904, "start": 570.0, "end": 573.5999999999999, "text": " And when I first presented this kind of stuff, again, this was something that seemed like", "tokens": [51412, 400, 562, 286, 700, 8212, 341, 733, 295, 1507, 11, 797, 11, 341, 390, 746, 300, 6576, 411, 51592], "temperature": 0.0, "avg_logprob": -0.1404686472774331, "compression_ratio": 1.7515527950310559, "no_speech_prob": 0.04882583022117615}, {"id": 139, "seek": 54904, "start": 573.5999999999999, "end": 575.64, "text": " a crazy idea.", "tokens": [51592, 257, 3219, 1558, 13, 51694], "temperature": 0.0, "avg_logprob": -0.1404686472774331, "compression_ratio": 1.7515527950310559, "no_speech_prob": 0.04882583022117615}, {"id": 140, "seek": 54904, "start": 575.64, "end": 577.24, "text": " And from the JavaScript world, it looked crazy.", "tokens": [51694, 400, 490, 264, 15778, 1002, 11, 309, 2956, 3219, 13, 51774], "temperature": 0.0, "avg_logprob": -0.1404686472774331, "compression_ratio": 1.7515527950310559, "no_speech_prob": 0.04882583022117615}, {"id": 141, "seek": 54904, "start": 577.24, "end": 578.76, "text": " From the functional world, it looked crazy.", "tokens": [51774, 3358, 264, 11745, 1002, 11, 309, 2956, 3219, 13, 51850], "temperature": 0.0, "avg_logprob": -0.1404686472774331, "compression_ratio": 1.7515527950310559, "no_speech_prob": 0.04882583022117615}, {"id": 142, "seek": 57876, "start": 578.76, "end": 581.6, "text": " Everyone was like, this is silly.", "tokens": [50364, 5198, 390, 411, 11, 341, 307, 11774, 13, 50506], "temperature": 0.0, "avg_logprob": -0.1895250455297605, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.002509613521397114}, {"id": 143, "seek": 57876, "start": 581.6, "end": 587.04, "text": " And so when I saw that React had this thing called, they were promoting this thing called", "tokens": [50506, 400, 370, 562, 286, 1866, 300, 30644, 632, 341, 551, 1219, 11, 436, 645, 16383, 341, 551, 1219, 50778], "temperature": 0.0, "avg_logprob": -0.1895250455297605, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.002509613521397114}, {"id": 144, "seek": 57876, "start": 587.04, "end": 590.72, "text": " Flux, I was like, okay, that actually sort of validates this design.", "tokens": [50778, 3235, 2449, 11, 286, 390, 411, 11, 1392, 11, 300, 767, 1333, 295, 7363, 1024, 341, 1715, 13, 50962], "temperature": 0.0, "avg_logprob": -0.1895250455297605, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.002509613521397114}, {"id": 145, "seek": 57876, "start": 590.72, "end": 594.16, "text": " And it sort of arose, I think, separately.", "tokens": [50962, 400, 309, 1333, 295, 37192, 11, 286, 519, 11, 14759, 13, 51134], "temperature": 0.0, "avg_logprob": -0.1895250455297605, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.002509613521397114}, {"id": 146, "seek": 57876, "start": 594.16, "end": 602.88, "text": " Since Flux, there's been more, it hasn't been as much independent development.", "tokens": [51134, 4162, 3235, 2449, 11, 456, 311, 668, 544, 11, 309, 6132, 380, 668, 382, 709, 6695, 3250, 13, 51570], "temperature": 0.0, "avg_logprob": -0.1895250455297605, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.002509613521397114}, {"id": 147, "seek": 57876, "start": 602.88, "end": 605.3199999999999, "text": " So people have seen Elm architecture and things as neat.", "tokens": [51570, 407, 561, 362, 1612, 2699, 76, 9482, 293, 721, 382, 10654, 13, 51692], "temperature": 0.0, "avg_logprob": -0.1895250455297605, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.002509613521397114}, {"id": 148, "seek": 60532, "start": 605.32, "end": 609.0, "text": " But so let's look at what the Elm architecture looked like in Elm.", "tokens": [50364, 583, 370, 718, 311, 574, 412, 437, 264, 2699, 76, 9482, 2956, 411, 294, 2699, 76, 13, 50548], "temperature": 0.0, "avg_logprob": -0.1121075264761381, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.004262635484337807}, {"id": 149, "seek": 60532, "start": 609.0, "end": 614.6, "text": " So we can go back to our little counter program.", "tokens": [50548, 407, 321, 393, 352, 646, 281, 527, 707, 5682, 1461, 13, 50828], "temperature": 0.0, "avg_logprob": -0.1121075264761381, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.004262635484337807}, {"id": 150, "seek": 60532, "start": 614.6, "end": 617.1600000000001, "text": " And we have a model.", "tokens": [50828, 400, 321, 362, 257, 2316, 13, 50956], "temperature": 0.0, "avg_logprob": -0.1121075264761381, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.004262635484337807}, {"id": 151, "seek": 60532, "start": 617.1600000000001, "end": 620.0, "text": " And in this case, it's just a number that we're counting up.", "tokens": [50956, 400, 294, 341, 1389, 11, 309, 311, 445, 257, 1230, 300, 321, 434, 13251, 493, 13, 51098], "temperature": 0.0, "avg_logprob": -0.1121075264761381, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.004262635484337807}, {"id": 152, "seek": 60532, "start": 620.0, "end": 621.24, "text": " And we have a way to update.", "tokens": [51098, 400, 321, 362, 257, 636, 281, 5623, 13, 51160], "temperature": 0.0, "avg_logprob": -0.1121075264761381, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.004262635484337807}, {"id": 153, "seek": 60532, "start": 621.24, "end": 624.84, "text": " So if we want to increment our document, we have messages like that.", "tokens": [51160, 407, 498, 321, 528, 281, 26200, 527, 4166, 11, 321, 362, 7897, 411, 300, 13, 51340], "temperature": 0.0, "avg_logprob": -0.1121075264761381, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.004262635484337807}, {"id": 154, "seek": 60532, "start": 624.84, "end": 629.5600000000001, "text": " And when we handle them in each case, and then we can put those in here.", "tokens": [51340, 400, 562, 321, 4813, 552, 294, 1184, 1389, 11, 293, 550, 321, 393, 829, 729, 294, 510, 13, 51576], "temperature": 0.0, "avg_logprob": -0.1121075264761381, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.004262635484337807}, {"id": 155, "seek": 62956, "start": 629.56, "end": 635.76, "text": " So if I wanted to add a new feature, I could say, okay, I want a thing called reset.", "tokens": [50364, 407, 498, 286, 1415, 281, 909, 257, 777, 4111, 11, 286, 727, 584, 11, 1392, 11, 286, 528, 257, 551, 1219, 14322, 13, 50674], "temperature": 0.0, "avg_logprob": -0.12276536990434696, "compression_ratio": 1.5670731707317074, "no_speech_prob": 0.005059201270341873}, {"id": 156, "seek": 62956, "start": 635.76, "end": 639.64, "text": " And it's going to be a reset button.", "tokens": [50674, 400, 309, 311, 516, 281, 312, 257, 14322, 2960, 13, 50868], "temperature": 0.0, "avg_logprob": -0.12276536990434696, "compression_ratio": 1.5670731707317074, "no_speech_prob": 0.005059201270341873}, {"id": 157, "seek": 62956, "start": 639.64, "end": 649.0799999999999, "text": " And I need to add in that kind of message and handle that case.", "tokens": [50868, 400, 286, 643, 281, 909, 294, 300, 733, 295, 3636, 293, 4813, 300, 1389, 13, 51340], "temperature": 0.0, "avg_logprob": -0.12276536990434696, "compression_ratio": 1.5670731707317074, "no_speech_prob": 0.005059201270341873}, {"id": 158, "seek": 62956, "start": 649.0799999999999, "end": 659.52, "text": " And if we go look at it, now I have my same thing and I can reset back.", "tokens": [51340, 400, 498, 321, 352, 574, 412, 309, 11, 586, 286, 362, 452, 912, 551, 293, 286, 393, 14322, 646, 13, 51862], "temperature": 0.0, "avg_logprob": -0.12276536990434696, "compression_ratio": 1.5670731707317074, "no_speech_prob": 0.005059201270341873}, {"id": 159, "seek": 65952, "start": 659.52, "end": 662.1999999999999, "text": " So it sort of gives structure to your program.", "tokens": [50364, 407, 309, 1333, 295, 2709, 3877, 281, 428, 1461, 13, 50498], "temperature": 0.0, "avg_logprob": -0.16122249980549236, "compression_ratio": 1.494949494949495, "no_speech_prob": 0.0010640764376148582}, {"id": 160, "seek": 65952, "start": 662.1999999999999, "end": 665.48, "text": " And so this is a really simple example, but it actually shows up in every Elm program", "tokens": [50498, 400, 370, 341, 307, 257, 534, 2199, 1365, 11, 457, 309, 767, 3110, 493, 294, 633, 2699, 76, 1461, 50662], "temperature": 0.0, "avg_logprob": -0.16122249980549236, "compression_ratio": 1.494949494949495, "no_speech_prob": 0.0010640764376148582}, {"id": 161, "seek": 65952, "start": 665.48, "end": 666.48, "text": " ever.", "tokens": [50662, 1562, 13, 50712], "temperature": 0.0, "avg_logprob": -0.16122249980549236, "compression_ratio": 1.494949494949495, "no_speech_prob": 0.0010640764376148582}, {"id": 162, "seek": 65952, "start": 666.48, "end": 678.24, "text": " So if we go look at the to do MVC code, we see the structure again.", "tokens": [50712, 407, 498, 321, 352, 574, 412, 264, 281, 360, 17663, 34, 3089, 11, 321, 536, 264, 3877, 797, 13, 51300], "temperature": 0.0, "avg_logprob": -0.16122249980549236, "compression_ratio": 1.494949494949495, "no_speech_prob": 0.0010640764376148582}, {"id": 163, "seek": 65952, "start": 678.24, "end": 679.64, "text": " So we start with a model.", "tokens": [51300, 407, 321, 722, 365, 257, 2316, 13, 51370], "temperature": 0.0, "avg_logprob": -0.16122249980549236, "compression_ratio": 1.494949494949495, "no_speech_prob": 0.0010640764376148582}, {"id": 164, "seek": 65952, "start": 679.64, "end": 681.96, "text": " In this case, it's a bit more complicated.", "tokens": [51370, 682, 341, 1389, 11, 309, 311, 257, 857, 544, 6179, 13, 51486], "temperature": 0.0, "avg_logprob": -0.16122249980549236, "compression_ratio": 1.494949494949495, "no_speech_prob": 0.0010640764376148582}, {"id": 165, "seek": 65952, "start": 681.96, "end": 686.6, "text": " So let's open it up.", "tokens": [51486, 407, 718, 311, 1269, 309, 493, 13, 51718], "temperature": 0.0, "avg_logprob": -0.16122249980549236, "compression_ratio": 1.494949494949495, "no_speech_prob": 0.0010640764376148582}, {"id": 166, "seek": 68660, "start": 686.6, "end": 691.24, "text": " So here we can say hello in all of this.", "tokens": [50364, 407, 510, 321, 393, 584, 7751, 294, 439, 295, 341, 13, 50596], "temperature": 0.0, "avg_logprob": -0.12006100018819173, "compression_ratio": 1.77992277992278, "no_speech_prob": 0.0009394859080202878}, {"id": 167, "seek": 68660, "start": 691.24, "end": 694.08, "text": " So we have a model of, we have a list of entries.", "tokens": [50596, 407, 321, 362, 257, 2316, 295, 11, 321, 362, 257, 1329, 295, 23041, 13, 50738], "temperature": 0.0, "avg_logprob": -0.12006100018819173, "compression_ratio": 1.77992277992278, "no_speech_prob": 0.0009394859080202878}, {"id": 168, "seek": 68660, "start": 694.08, "end": 695.6, "text": " We have a field that you can type in.", "tokens": [50738, 492, 362, 257, 2519, 300, 291, 393, 2010, 294, 13, 50814], "temperature": 0.0, "avg_logprob": -0.12006100018819173, "compression_ratio": 1.77992277992278, "no_speech_prob": 0.0009394859080202878}, {"id": 169, "seek": 68660, "start": 695.6, "end": 697.72, "text": " We have what things are visible or not.", "tokens": [50814, 492, 362, 437, 721, 366, 8974, 420, 406, 13, 50920], "temperature": 0.0, "avg_logprob": -0.12006100018819173, "compression_ratio": 1.77992277992278, "no_speech_prob": 0.0009394859080202878}, {"id": 170, "seek": 68660, "start": 697.72, "end": 698.72, "text": " We have our entries.", "tokens": [50920, 492, 362, 527, 23041, 13, 50970], "temperature": 0.0, "avg_logprob": -0.12006100018819173, "compression_ratio": 1.77992277992278, "no_speech_prob": 0.0009394859080202878}, {"id": 171, "seek": 68660, "start": 698.72, "end": 699.72, "text": " That has a description.", "tokens": [50970, 663, 575, 257, 3855, 13, 51020], "temperature": 0.0, "avg_logprob": -0.12006100018819173, "compression_ratio": 1.77992277992278, "no_speech_prob": 0.0009394859080202878}, {"id": 172, "seek": 68660, "start": 699.72, "end": 700.72, "text": " Is it completed?", "tokens": [51020, 1119, 309, 7365, 30, 51070], "temperature": 0.0, "avg_logprob": -0.12006100018819173, "compression_ratio": 1.77992277992278, "no_speech_prob": 0.0009394859080202878}, {"id": 173, "seek": 68660, "start": 700.72, "end": 702.5600000000001, "text": " Is it being edited?", "tokens": [51070, 1119, 309, 885, 23016, 30, 51162], "temperature": 0.0, "avg_logprob": -0.12006100018819173, "compression_ratio": 1.77992277992278, "no_speech_prob": 0.0009394859080202878}, {"id": 174, "seek": 68660, "start": 702.5600000000001, "end": 706.12, "text": " We have our messages, all the things that you can do to this program.", "tokens": [51162, 492, 362, 527, 7897, 11, 439, 264, 721, 300, 291, 393, 360, 281, 341, 1461, 13, 51340], "temperature": 0.0, "avg_logprob": -0.12006100018819173, "compression_ratio": 1.77992277992278, "no_speech_prob": 0.0009394859080202878}, {"id": 175, "seek": 68660, "start": 706.12, "end": 708.82, "text": " And a way to update our program.", "tokens": [51340, 400, 257, 636, 281, 5623, 527, 1461, 13, 51475], "temperature": 0.0, "avg_logprob": -0.12006100018819173, "compression_ratio": 1.77992277992278, "no_speech_prob": 0.0009394859080202878}, {"id": 176, "seek": 68660, "start": 708.82, "end": 713.64, "text": " And we have a view, which again is using this Elm as the HTML syntax.", "tokens": [51475, 400, 321, 362, 257, 1910, 11, 597, 797, 307, 1228, 341, 2699, 76, 382, 264, 17995, 28431, 13, 51716], "temperature": 0.0, "avg_logprob": -0.12006100018819173, "compression_ratio": 1.77992277992278, "no_speech_prob": 0.0009394859080202878}, {"id": 177, "seek": 68660, "start": 713.64, "end": 716.36, "text": " So you can see, okay, I've got a div.", "tokens": [51716, 407, 291, 393, 536, 11, 1392, 11, 286, 600, 658, 257, 3414, 13, 51852], "temperature": 0.0, "avg_logprob": -0.12006100018819173, "compression_ratio": 1.77992277992278, "no_speech_prob": 0.0009394859080202878}, {"id": 178, "seek": 71636, "start": 716.36, "end": 717.36, "text": " It's got some attributes.", "tokens": [50364, 467, 311, 658, 512, 17212, 13, 50414], "temperature": 0.0, "avg_logprob": -0.13754693122759257, "compression_ratio": 1.7774086378737541, "no_speech_prob": 0.0005524380831047893}, {"id": 179, "seek": 71636, "start": 717.36, "end": 720.0, "text": " It's got some children.", "tokens": [50414, 467, 311, 658, 512, 2227, 13, 50546], "temperature": 0.0, "avg_logprob": -0.13754693122759257, "compression_ratio": 1.7774086378737541, "no_speech_prob": 0.0005524380831047893}, {"id": 180, "seek": 71636, "start": 720.0, "end": 723.28, "text": " And we're just using Elm functions to create the different parts.", "tokens": [50546, 400, 321, 434, 445, 1228, 2699, 76, 6828, 281, 1884, 264, 819, 3166, 13, 50710], "temperature": 0.0, "avg_logprob": -0.13754693122759257, "compression_ratio": 1.7774086378737541, "no_speech_prob": 0.0005524380831047893}, {"id": 181, "seek": 71636, "start": 723.28, "end": 726.2, "text": " So here's where the text input is, that kind of thing.", "tokens": [50710, 407, 510, 311, 689, 264, 2487, 4846, 307, 11, 300, 733, 295, 551, 13, 50856], "temperature": 0.0, "avg_logprob": -0.13754693122759257, "compression_ratio": 1.7774086378737541, "no_speech_prob": 0.0005524380831047893}, {"id": 182, "seek": 71636, "start": 726.2, "end": 731.2, "text": " And no matter what level of crazy program you go to, so another program you could look", "tokens": [50856, 400, 572, 1871, 437, 1496, 295, 3219, 1461, 291, 352, 281, 11, 370, 1071, 1461, 291, 727, 574, 51106], "temperature": 0.0, "avg_logprob": -0.13754693122759257, "compression_ratio": 1.7774086378737541, "no_speech_prob": 0.0005524380831047893}, {"id": 183, "seek": 71636, "start": 731.2, "end": 736.72, "text": " at is Richard did this real world thing that's been sort of going around the internet in", "tokens": [51106, 412, 307, 9809, 630, 341, 957, 1002, 551, 300, 311, 668, 1333, 295, 516, 926, 264, 4705, 294, 51382], "temperature": 0.0, "avg_logprob": -0.13754693122759257, "compression_ratio": 1.7774086378737541, "no_speech_prob": 0.0005524380831047893}, {"id": 184, "seek": 71636, "start": 736.72, "end": 737.72, "text": " Elm.", "tokens": [51382, 2699, 76, 13, 51432], "temperature": 0.0, "avg_logprob": -0.13754693122759257, "compression_ratio": 1.7774086378737541, "no_speech_prob": 0.0005524380831047893}, {"id": 185, "seek": 71636, "start": 737.72, "end": 740.96, "text": " And you see the same pattern again, where there's the model, there's the update, there's", "tokens": [51432, 400, 291, 536, 264, 912, 5102, 797, 11, 689, 456, 311, 264, 2316, 11, 456, 311, 264, 5623, 11, 456, 311, 51594], "temperature": 0.0, "avg_logprob": -0.13754693122759257, "compression_ratio": 1.7774086378737541, "no_speech_prob": 0.0005524380831047893}, {"id": 186, "seek": 71636, "start": 740.96, "end": 741.96, "text": " a view.", "tokens": [51594, 257, 1910, 13, 51644], "temperature": 0.0, "avg_logprob": -0.13754693122759257, "compression_ratio": 1.7774086378737541, "no_speech_prob": 0.0005524380831047893}, {"id": 187, "seek": 71636, "start": 741.96, "end": 744.8000000000001, "text": " And one thing that's really neat about this is when you come to an Elm project, you're", "tokens": [51644, 400, 472, 551, 300, 311, 534, 10654, 466, 341, 307, 562, 291, 808, 281, 364, 2699, 76, 1716, 11, 291, 434, 51786], "temperature": 0.0, "avg_logprob": -0.13754693122759257, "compression_ratio": 1.7774086378737541, "no_speech_prob": 0.0005524380831047893}, {"id": 188, "seek": 74480, "start": 744.8, "end": 749.04, "text": " immediately oriented, because you're like, every Elm project starts this way, and then", "tokens": [50364, 4258, 21841, 11, 570, 291, 434, 411, 11, 633, 2699, 76, 1716, 3719, 341, 636, 11, 293, 550, 50576], "temperature": 0.0, "avg_logprob": -0.1551825936916655, "compression_ratio": 1.6692307692307693, "no_speech_prob": 0.0035900799557566643}, {"id": 189, "seek": 74480, "start": 749.04, "end": 753.24, "text": " they're just functions out from there.", "tokens": [50576, 436, 434, 445, 6828, 484, 490, 456, 13, 50786], "temperature": 0.0, "avg_logprob": -0.1551825936916655, "compression_ratio": 1.6692307692307693, "no_speech_prob": 0.0035900799557566643}, {"id": 190, "seek": 74480, "start": 753.24, "end": 759.8399999999999, "text": " So when you go and put this in context, in the react world, my understanding is that", "tokens": [50786, 407, 562, 291, 352, 293, 829, 341, 294, 4319, 11, 294, 264, 4515, 1002, 11, 452, 3701, 307, 300, 51116], "temperature": 0.0, "avg_logprob": -0.1551825936916655, "compression_ratio": 1.6692307692307693, "no_speech_prob": 0.0035900799557566643}, {"id": 191, "seek": 74480, "start": 759.8399999999999, "end": 762.4399999999999, "text": " not everyone is into unidirectional flow.", "tokens": [51116, 406, 1518, 307, 666, 517, 327, 621, 41048, 3095, 13, 51246], "temperature": 0.0, "avg_logprob": -0.1551825936916655, "compression_ratio": 1.6692307692307693, "no_speech_prob": 0.0035900799557566643}, {"id": 192, "seek": 74480, "start": 762.4399999999999, "end": 767.4, "text": " And I think that's because components are an important idea in the react world.", "tokens": [51246, 400, 286, 519, 300, 311, 570, 6677, 366, 364, 1021, 1558, 294, 264, 4515, 1002, 13, 51494], "temperature": 0.0, "avg_logprob": -0.1551825936916655, "compression_ratio": 1.6692307692307693, "no_speech_prob": 0.0035900799557566643}, {"id": 193, "seek": 74480, "start": 767.4, "end": 773.0799999999999, "text": " And when I look at components, I see local, state, methods, like getters and setters to", "tokens": [51494, 400, 562, 286, 574, 412, 6677, 11, 286, 536, 2654, 11, 1785, 11, 7150, 11, 411, 483, 1559, 293, 992, 1559, 281, 51778], "temperature": 0.0, "avg_logprob": -0.1551825936916655, "compression_ratio": 1.6692307692307693, "no_speech_prob": 0.0035900799557566643}, {"id": 194, "seek": 74480, "start": 773.0799999999999, "end": 774.0799999999999, "text": " deal with it.", "tokens": [51778, 2028, 365, 309, 13, 51828], "temperature": 0.0, "avg_logprob": -0.1551825936916655, "compression_ratio": 1.6692307692307693, "no_speech_prob": 0.0035900799557566643}, {"id": 195, "seek": 77408, "start": 774.2800000000001, "end": 776.6800000000001, "text": " Whenever I think of that, I think of an object.", "tokens": [50374, 14159, 286, 519, 295, 300, 11, 286, 519, 295, 364, 2657, 13, 50494], "temperature": 0.0, "avg_logprob": -0.1623820909639684, "compression_ratio": 1.9141914191419143, "no_speech_prob": 0.00043045682832598686}, {"id": 196, "seek": 77408, "start": 776.6800000000001, "end": 778.76, "text": " We've got local, state, getters and setters.", "tokens": [50494, 492, 600, 658, 2654, 11, 1785, 11, 483, 1559, 293, 992, 1559, 13, 50598], "temperature": 0.0, "avg_logprob": -0.1623820909639684, "compression_ratio": 1.9141914191419143, "no_speech_prob": 0.00043045682832598686}, {"id": 197, "seek": 77408, "start": 778.76, "end": 781.2, "text": " It's sort of an object-oriented way of thinking.", "tokens": [50598, 467, 311, 1333, 295, 364, 2657, 12, 27414, 636, 295, 1953, 13, 50720], "temperature": 0.0, "avg_logprob": -0.1623820909639684, "compression_ratio": 1.9141914191419143, "no_speech_prob": 0.00043045682832598686}, {"id": 198, "seek": 77408, "start": 781.2, "end": 784.48, "text": " And that's one way to approach things, and this unidirectional flow is another way to", "tokens": [50720, 400, 300, 311, 472, 636, 281, 3109, 721, 11, 293, 341, 517, 327, 621, 41048, 3095, 307, 1071, 636, 281, 50884], "temperature": 0.0, "avg_logprob": -0.1623820909639684, "compression_ratio": 1.9141914191419143, "no_speech_prob": 0.00043045682832598686}, {"id": 199, "seek": 77408, "start": 784.48, "end": 785.48, "text": " approach it.", "tokens": [50884, 3109, 309, 13, 50934], "temperature": 0.0, "avg_logprob": -0.1623820909639684, "compression_ratio": 1.9141914191419143, "no_speech_prob": 0.00043045682832598686}, {"id": 200, "seek": 77408, "start": 785.48, "end": 789.5600000000001, "text": " Whereas in Elm, we don't have the objects, we just have functions.", "tokens": [50934, 13813, 294, 2699, 76, 11, 321, 500, 380, 362, 264, 6565, 11, 321, 445, 362, 6828, 13, 51138], "temperature": 0.0, "avg_logprob": -0.1623820909639684, "compression_ratio": 1.9141914191419143, "no_speech_prob": 0.00043045682832598686}, {"id": 201, "seek": 77408, "start": 789.5600000000001, "end": 793.0400000000001, "text": " And if that's your only tool, you're going to end up with a unidirectional flow.", "tokens": [51138, 400, 498, 300, 311, 428, 787, 2290, 11, 291, 434, 516, 281, 917, 493, 365, 257, 517, 327, 621, 41048, 3095, 13, 51312], "temperature": 0.0, "avg_logprob": -0.1623820909639684, "compression_ratio": 1.9141914191419143, "no_speech_prob": 0.00043045682832598686}, {"id": 202, "seek": 77408, "start": 793.0400000000001, "end": 797.24, "text": " So because of the feature set of Elm, it really makes sense that that's how all Elm programs", "tokens": [51312, 407, 570, 295, 264, 4111, 992, 295, 2699, 76, 11, 309, 534, 1669, 2020, 300, 300, 311, 577, 439, 2699, 76, 4268, 51522], "temperature": 0.0, "avg_logprob": -0.1623820909639684, "compression_ratio": 1.9141914191419143, "no_speech_prob": 0.00043045682832598686}, {"id": 203, "seek": 77408, "start": 797.24, "end": 798.24, "text": " work.", "tokens": [51522, 589, 13, 51572], "temperature": 0.0, "avg_logprob": -0.1623820909639684, "compression_ratio": 1.9141914191419143, "no_speech_prob": 0.00043045682832598686}, {"id": 204, "seek": 77408, "start": 798.24, "end": 802.32, "text": " And because the feature set of react, it makes sense that people might mix and match and use", "tokens": [51572, 400, 570, 264, 4111, 992, 295, 4515, 11, 309, 1669, 2020, 300, 561, 1062, 2890, 293, 2995, 293, 764, 51776], "temperature": 0.0, "avg_logprob": -0.1623820909639684, "compression_ratio": 1.9141914191419143, "no_speech_prob": 0.00043045682832598686}, {"id": 205, "seek": 80232, "start": 802.32, "end": 807.88, "text": " some depending on what their case is, depending on what their preferences are.", "tokens": [50364, 512, 5413, 322, 437, 641, 1389, 307, 11, 5413, 322, 437, 641, 21910, 366, 13, 50642], "temperature": 0.0, "avg_logprob": -0.14942738781236622, "compression_ratio": 1.675392670157068, "no_speech_prob": 0.0002912992495112121}, {"id": 206, "seek": 80232, "start": 807.88, "end": 813.08, "text": " Another case that people ended up at independently is immutability.", "tokens": [50642, 3996, 1389, 300, 561, 4590, 493, 412, 21761, 307, 3397, 325, 2310, 13, 50902], "temperature": 0.0, "avg_logprob": -0.14942738781236622, "compression_ratio": 1.675392670157068, "no_speech_prob": 0.0002912992495112121}, {"id": 207, "seek": 80232, "start": 813.08, "end": 818.5600000000001, "text": " So Elm is a language where every single value in the whole language is immutable.", "tokens": [50902, 407, 2699, 76, 307, 257, 2856, 689, 633, 2167, 2158, 294, 264, 1379, 2856, 307, 3397, 32148, 13, 51176], "temperature": 0.0, "avg_logprob": -0.14942738781236622, "compression_ratio": 1.675392670157068, "no_speech_prob": 0.0002912992495112121}, {"id": 208, "seek": 80232, "start": 818.5600000000001, "end": 824.88, "text": " And so I think this became important in the react world because react has this thing called", "tokens": [51176, 400, 370, 286, 519, 341, 3062, 1021, 294, 264, 4515, 1002, 570, 4515, 575, 341, 551, 1219, 51492], "temperature": 0.0, "avg_logprob": -0.14942738781236622, "compression_ratio": 1.675392670157068, "no_speech_prob": 0.0002912992495112121}, {"id": 209, "seek": 82488, "start": 824.88, "end": 832.92, "text": " shouldComponentUpdate, and it looks something like this, where you have some function and", "tokens": [50364, 820, 34, 8586, 30365, 22164, 17393, 11, 293, 309, 1542, 746, 411, 341, 11, 689, 291, 362, 512, 2445, 293, 50766], "temperature": 0.0, "avg_logprob": -0.15694586435953775, "compression_ratio": 1.6970954356846473, "no_speech_prob": 0.34819403290748596}, {"id": 210, "seek": 82488, "start": 832.92, "end": 836.08, "text": " you're saying, all right, did any of these properties change?", "tokens": [50766, 291, 434, 1566, 11, 439, 558, 11, 630, 604, 295, 613, 7221, 1319, 30, 50924], "temperature": 0.0, "avg_logprob": -0.15694586435953775, "compression_ratio": 1.6970954356846473, "no_speech_prob": 0.34819403290748596}, {"id": 211, "seek": 82488, "start": 836.08, "end": 838.6, "text": " If so, we should update.", "tokens": [50924, 759, 370, 11, 321, 820, 5623, 13, 51050], "temperature": 0.0, "avg_logprob": -0.15694586435953775, "compression_ratio": 1.6970954356846473, "no_speech_prob": 0.34819403290748596}, {"id": 212, "seek": 82488, "start": 838.6, "end": 840.28, "text": " And I just want to do a quick poll.", "tokens": [51050, 400, 286, 445, 528, 281, 360, 257, 1702, 6418, 13, 51134], "temperature": 0.0, "avg_logprob": -0.15694586435953775, "compression_ratio": 1.6970954356846473, "no_speech_prob": 0.34819403290748596}, {"id": 213, "seek": 82488, "start": 840.28, "end": 844.4399999999999, "text": " How many people have had a bug where they changed the component, but they forgot to", "tokens": [51134, 1012, 867, 561, 362, 632, 257, 7426, 689, 436, 3105, 264, 6542, 11, 457, 436, 5298, 281, 51342], "temperature": 0.0, "avg_logprob": -0.15694586435953775, "compression_ratio": 1.6970954356846473, "no_speech_prob": 0.34819403290748596}, {"id": 214, "seek": 82488, "start": 844.4399999999999, "end": 849.56, "text": " change the shouldComponentUpdate, and then they were like, so how many people out there?", "tokens": [51342, 1319, 264, 820, 34, 8586, 30365, 22164, 17393, 11, 293, 550, 436, 645, 411, 11, 370, 577, 867, 561, 484, 456, 30, 51598], "temperature": 0.0, "avg_logprob": -0.15694586435953775, "compression_ratio": 1.6970954356846473, "no_speech_prob": 0.34819403290748596}, {"id": 215, "seek": 82488, "start": 849.56, "end": 854.64, "text": " Okay, was it a fun bug?", "tokens": [51598, 1033, 11, 390, 309, 257, 1019, 7426, 30, 51852], "temperature": 0.0, "avg_logprob": -0.15694586435953775, "compression_ratio": 1.6970954356846473, "no_speech_prob": 0.34819403290748596}, {"id": 216, "seek": 85464, "start": 855.4, "end": 859.28, "text": " This can be something that's super frustrating because you're like, I swear this code works,", "tokens": [50402, 639, 393, 312, 746, 300, 311, 1687, 16522, 570, 291, 434, 411, 11, 286, 11902, 341, 3089, 1985, 11, 50596], "temperature": 0.0, "avg_logprob": -0.1577702174111018, "compression_ratio": 1.6382252559726962, "no_speech_prob": 0.0008826697594486177}, {"id": 217, "seek": 85464, "start": 859.28, "end": 865.16, "text": " my test is fine, and you just don't think to look at this piece of code.", "tokens": [50596, 452, 1500, 307, 2489, 11, 293, 291, 445, 500, 380, 519, 281, 574, 412, 341, 2522, 295, 3089, 13, 50890], "temperature": 0.0, "avg_logprob": -0.1577702174111018, "compression_ratio": 1.6382252559726962, "no_speech_prob": 0.0008826697594486177}, {"id": 218, "seek": 85464, "start": 865.16, "end": 872.3199999999999, "text": " And so ClosureScript, David Nolan came up with this idea of putting pairing shouldComponentUpdate", "tokens": [50890, 400, 370, 2033, 7641, 14237, 11, 4389, 43707, 1361, 493, 365, 341, 1558, 295, 3372, 32735, 820, 34, 8586, 30365, 22164, 17393, 51248], "temperature": 0.0, "avg_logprob": -0.1577702174111018, "compression_ratio": 1.6382252559726962, "no_speech_prob": 0.0008826697594486177}, {"id": 219, "seek": 85464, "start": 872.3199999999999, "end": 874.16, "text": " with immutability.", "tokens": [51248, 365, 3397, 325, 2310, 13, 51340], "temperature": 0.0, "avg_logprob": -0.1577702174111018, "compression_ratio": 1.6382252559726962, "no_speech_prob": 0.0008826697594486177}, {"id": 220, "seek": 85464, "start": 874.16, "end": 878.48, "text": " And so the basic realization is if you have an immutable value and you say, well, is this", "tokens": [51340, 400, 370, 264, 3875, 25138, 307, 498, 291, 362, 364, 3397, 32148, 2158, 293, 291, 584, 11, 731, 11, 307, 341, 51556], "temperature": 0.0, "avg_logprob": -0.1577702174111018, "compression_ratio": 1.6382252559726962, "no_speech_prob": 0.0008826697594486177}, {"id": 221, "seek": 85464, "start": 878.48, "end": 880.24, "text": " reference the same as that reference?", "tokens": [51556, 6408, 264, 912, 382, 300, 6408, 30, 51644], "temperature": 0.0, "avg_logprob": -0.1577702174111018, "compression_ratio": 1.6382252559726962, "no_speech_prob": 0.0008826697594486177}, {"id": 222, "seek": 85464, "start": 880.24, "end": 883.2, "text": " No one could have changed it in the meantime, so it must be the same.", "tokens": [51644, 883, 472, 727, 362, 3105, 309, 294, 264, 14991, 11, 370, 309, 1633, 312, 264, 912, 13, 51792], "temperature": 0.0, "avg_logprob": -0.1577702174111018, "compression_ratio": 1.6382252559726962, "no_speech_prob": 0.0008826697594486177}, {"id": 223, "seek": 88320, "start": 883.2, "end": 889.6800000000001, "text": " And so it's a really nice way of making this reliable, even as the shape of that value changes.", "tokens": [50364, 400, 370, 309, 311, 257, 534, 1481, 636, 295, 1455, 341, 12924, 11, 754, 382, 264, 3909, 295, 300, 2158, 2962, 13, 50688], "temperature": 0.0, "avg_logprob": -0.1373684652920427, "compression_ratio": 1.6317689530685922, "no_speech_prob": 0.0002164838369935751}, {"id": 224, "seek": 88320, "start": 889.6800000000001, "end": 893.24, "text": " And so he wrote about this in this blog post, and I really want to give him credit for this", "tokens": [50688, 400, 370, 415, 4114, 466, 341, 294, 341, 6968, 2183, 11, 293, 286, 534, 528, 281, 976, 796, 5397, 337, 341, 50866], "temperature": 0.0, "avg_logprob": -0.1373684652920427, "compression_ratio": 1.6317689530685922, "no_speech_prob": 0.0002164838369935751}, {"id": 225, "seek": 88320, "start": 893.24, "end": 898.6400000000001, "text": " idea because I think, one, it popularized, or like it made immutability palatable, like", "tokens": [50866, 1558, 570, 286, 519, 11, 472, 11, 309, 3743, 1602, 11, 420, 411, 309, 1027, 3397, 325, 2310, 3984, 31415, 11, 411, 51136], "temperature": 0.0, "avg_logprob": -0.1373684652920427, "compression_ratio": 1.6317689530685922, "no_speech_prob": 0.0002164838369935751}, {"id": 226, "seek": 88320, "start": 898.6400000000001, "end": 903.6400000000001, "text": " not an insane person idea in the JavaScript world, and it really made space for functional", "tokens": [51136, 406, 364, 10838, 954, 1558, 294, 264, 15778, 1002, 11, 293, 309, 534, 1027, 1901, 337, 11745, 51386], "temperature": 0.0, "avg_logprob": -0.1373684652920427, "compression_ratio": 1.6317689530685922, "no_speech_prob": 0.0002164838369935751}, {"id": 227, "seek": 88320, "start": 903.6400000000001, "end": 908.36, "text": " languages to have a place in front of development.", "tokens": [51386, 8650, 281, 362, 257, 1081, 294, 1868, 295, 3250, 13, 51622], "temperature": 0.0, "avg_logprob": -0.1373684652920427, "compression_ratio": 1.6317689530685922, "no_speech_prob": 0.0002164838369935751}, {"id": 228, "seek": 88320, "start": 908.36, "end": 910.5200000000001, "text": " So in Elm, everything's immutable.", "tokens": [51622, 407, 294, 2699, 76, 11, 1203, 311, 3397, 32148, 13, 51730], "temperature": 0.0, "avg_logprob": -0.1373684652920427, "compression_ratio": 1.6317689530685922, "no_speech_prob": 0.0002164838369935751}, {"id": 229, "seek": 91052, "start": 910.52, "end": 914.56, "text": " So I saw David Nolan's idea here, and I was like, great, like, what is this, how does", "tokens": [50364, 407, 286, 1866, 4389, 43707, 311, 1558, 510, 11, 293, 286, 390, 411, 11, 869, 11, 411, 11, 437, 307, 341, 11, 577, 775, 50566], "temperature": 0.0, "avg_logprob": -0.19020942472062022, "compression_ratio": 1.5231481481481481, "no_speech_prob": 0.014948987402021885}, {"id": 230, "seek": 91052, "start": 914.56, "end": 918.72, "text": " this come to Elm in the Elmi way?", "tokens": [50566, 341, 808, 281, 2699, 76, 294, 264, 2699, 3057, 636, 30, 50774], "temperature": 0.0, "avg_logprob": -0.19020942472062022, "compression_ratio": 1.5231481481481481, "no_speech_prob": 0.014948987402021885}, {"id": 231, "seek": 91052, "start": 918.72, "end": 921.4, "text": " And so we have this thing called lazy.", "tokens": [50774, 400, 370, 321, 362, 341, 551, 1219, 14847, 13, 50908], "temperature": 0.0, "avg_logprob": -0.19020942472062022, "compression_ratio": 1.5231481481481481, "no_speech_prob": 0.014948987402021885}, {"id": 232, "seek": 91052, "start": 921.4, "end": 929.88, "text": " So if we go look at our toDo app, I'm going to remove the lazies real quick so we can", "tokens": [50908, 407, 498, 321, 352, 574, 412, 527, 281, 7653, 724, 11, 286, 478, 516, 281, 4159, 264, 19320, 530, 957, 1702, 370, 321, 393, 51332], "temperature": 0.0, "avg_logprob": -0.19020942472062022, "compression_ratio": 1.5231481481481481, "no_speech_prob": 0.014948987402021885}, {"id": 233, "seek": 91052, "start": 929.88, "end": 931.3, "text": " see it without.", "tokens": [51332, 536, 309, 1553, 13, 51403], "temperature": 0.0, "avg_logprob": -0.19020942472062022, "compression_ratio": 1.5231481481481481, "no_speech_prob": 0.014948987402021885}, {"id": 234, "seek": 91052, "start": 931.3, "end": 937.3199999999999, "text": " So here I have a div, it holds a section, and it has three subnodes.", "tokens": [51403, 407, 510, 286, 362, 257, 3414, 11, 309, 9190, 257, 3541, 11, 293, 309, 575, 1045, 1422, 77, 4789, 13, 51704], "temperature": 0.0, "avg_logprob": -0.19020942472062022, "compression_ratio": 1.5231481481481481, "no_speech_prob": 0.014948987402021885}, {"id": 235, "seek": 93732, "start": 937.32, "end": 942.2, "text": " And so for the first one, I'm calling a function, and I'm giving it some field value, and that's", "tokens": [50364, 400, 370, 337, 264, 700, 472, 11, 286, 478, 5141, 257, 2445, 11, 293, 286, 478, 2902, 309, 512, 2519, 2158, 11, 293, 300, 311, 50608], "temperature": 0.0, "avg_logprob": -0.10445192365935355, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.0073430356569588184}, {"id": 236, "seek": 93732, "start": 942.2, "end": 943.96, "text": " what's going to show up in there.", "tokens": [50608, 437, 311, 516, 281, 855, 493, 294, 456, 13, 50696], "temperature": 0.0, "avg_logprob": -0.10445192365935355, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.0073430356569588184}, {"id": 237, "seek": 93732, "start": 943.96, "end": 948.1600000000001, "text": " And so essentially what's happening when I add lazy is I'm saying, instead of calling", "tokens": [50696, 400, 370, 4476, 437, 311, 2737, 562, 286, 909, 14847, 307, 286, 478, 1566, 11, 2602, 295, 5141, 50906], "temperature": 0.0, "avg_logprob": -0.10445192365935355, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.0073430356569588184}, {"id": 238, "seek": 93732, "start": 948.1600000000001, "end": 953.9200000000001, "text": " this function now, building the virtual DOM, doing the diff, seeing if there's patches,", "tokens": [50906, 341, 2445, 586, 11, 2390, 264, 6374, 35727, 11, 884, 264, 7593, 11, 2577, 498, 456, 311, 26531, 11, 51194], "temperature": 0.0, "avg_logprob": -0.10445192365935355, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.0073430356569588184}, {"id": 239, "seek": 93732, "start": 953.9200000000001, "end": 958.96, "text": " and finding out yes or no, I'm going to say, okay, hold on to this function, hold on to", "tokens": [51194, 293, 5006, 484, 2086, 420, 572, 11, 286, 478, 516, 281, 584, 11, 1392, 11, 1797, 322, 281, 341, 2445, 11, 1797, 322, 281, 51446], "temperature": 0.0, "avg_logprob": -0.10445192365935355, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.0073430356569588184}, {"id": 240, "seek": 93732, "start": 958.96, "end": 964.4000000000001, "text": " this value, and when it's time to diff, I'll say, are these the same as last time?", "tokens": [51446, 341, 2158, 11, 293, 562, 309, 311, 565, 281, 7593, 11, 286, 603, 584, 11, 366, 613, 264, 912, 382, 1036, 565, 30, 51718], "temperature": 0.0, "avg_logprob": -0.10445192365935355, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.0073430356569588184}, {"id": 241, "seek": 96440, "start": 964.4, "end": 967.92, "text": " And if it's the same function by reference, same argument by reference, I'll just skip", "tokens": [50364, 400, 498, 309, 311, 264, 912, 2445, 538, 6408, 11, 912, 6770, 538, 6408, 11, 286, 603, 445, 10023, 50540], "temperature": 0.0, "avg_logprob": -0.10740805394721753, "compression_ratio": 1.7758007117437722, "no_speech_prob": 0.02295517921447754}, {"id": 242, "seek": 96440, "start": 967.92, "end": 971.0, "text": " the whole thing because I know the results are going to be the same.", "tokens": [50540, 264, 1379, 551, 570, 286, 458, 264, 3542, 366, 516, 281, 312, 264, 912, 13, 50694], "temperature": 0.0, "avg_logprob": -0.10740805394721753, "compression_ratio": 1.7758007117437722, "no_speech_prob": 0.02295517921447754}, {"id": 243, "seek": 96440, "start": 971.0, "end": 976.6, "text": " And because everything in Elm is immutable, this is known to be safe.", "tokens": [50694, 400, 570, 1203, 294, 2699, 76, 307, 3397, 32148, 11, 341, 307, 2570, 281, 312, 3273, 13, 50974], "temperature": 0.0, "avg_logprob": -0.10740805394721753, "compression_ratio": 1.7758007117437722, "no_speech_prob": 0.02295517921447754}, {"id": 244, "seek": 96440, "start": 976.6, "end": 981.48, "text": " You can just trust, you can sprinkle in this lazy operator wherever you want.", "tokens": [50974, 509, 393, 445, 3361, 11, 291, 393, 24745, 294, 341, 14847, 12973, 8660, 291, 528, 13, 51218], "temperature": 0.0, "avg_logprob": -0.10740805394721753, "compression_ratio": 1.7758007117437722, "no_speech_prob": 0.02295517921447754}, {"id": 245, "seek": 96440, "start": 981.48, "end": 985.9599999999999, "text": " And so if we look around this file more, I use it in other places, so each entry in", "tokens": [51218, 400, 370, 498, 321, 574, 926, 341, 3991, 544, 11, 286, 764, 309, 294, 661, 3190, 11, 370, 1184, 8729, 294, 51442], "temperature": 0.0, "avg_logprob": -0.10740805394721753, "compression_ratio": 1.7758007117437722, "no_speech_prob": 0.02295517921447754}, {"id": 246, "seek": 96440, "start": 985.9599999999999, "end": 988.56, "text": " the list is lazy.", "tokens": [51442, 264, 1329, 307, 14847, 13, 51572], "temperature": 0.0, "avg_logprob": -0.10740805394721753, "compression_ratio": 1.7758007117437722, "no_speech_prob": 0.02295517921447754}, {"id": 247, "seek": 96440, "start": 988.56, "end": 993.4, "text": " This is the footer where there's some controls, so if we look at the app again, there's these", "tokens": [51572, 639, 307, 264, 2671, 260, 689, 456, 311, 512, 9003, 11, 370, 498, 321, 574, 412, 264, 724, 797, 11, 456, 311, 613, 51814], "temperature": 0.0, "avg_logprob": -0.10740805394721753, "compression_ratio": 1.7758007117437722, "no_speech_prob": 0.02295517921447754}, {"id": 248, "seek": 99340, "start": 993.4, "end": 998.72, "text": " kinds of things at the bottom.", "tokens": [50364, 3685, 295, 721, 412, 264, 2767, 13, 50630], "temperature": 0.0, "avg_logprob": -0.16018118460973105, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.0030744019895792007}, {"id": 249, "seek": 99340, "start": 998.72, "end": 1000.84, "text": " So that can be lazy too.", "tokens": [50630, 407, 300, 393, 312, 14847, 886, 13, 50736], "temperature": 0.0, "avg_logprob": -0.16018118460973105, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.0030744019895792007}, {"id": 250, "seek": 99340, "start": 1000.84, "end": 1004.1999999999999, "text": " And what's neat about this is it's not tied to the component itself, it's just if you", "tokens": [50736, 400, 437, 311, 10654, 466, 341, 307, 309, 311, 406, 9601, 281, 264, 6542, 2564, 11, 309, 311, 445, 498, 291, 50904], "temperature": 0.0, "avg_logprob": -0.16018118460973105, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.0030744019895792007}, {"id": 251, "seek": 99340, "start": 1004.1999999999999, "end": 1010.9599999999999, "text": " have a function and you have some arguments, that can become a lazy piece of the structure.", "tokens": [50904, 362, 257, 2445, 293, 291, 362, 512, 12869, 11, 300, 393, 1813, 257, 14847, 2522, 295, 264, 3877, 13, 51242], "temperature": 0.0, "avg_logprob": -0.16018118460973105, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.0030744019895792007}, {"id": 252, "seek": 99340, "start": 1010.9599999999999, "end": 1018.84, "text": " Okay, so another thing that React in Elm have in common that's maybe more, one of the more", "tokens": [51242, 1033, 11, 370, 1071, 551, 300, 30644, 294, 2699, 76, 362, 294, 2689, 300, 311, 1310, 544, 11, 472, 295, 264, 544, 51636], "temperature": 0.0, "avg_logprob": -0.16018118460973105, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.0030744019895792007}, {"id": 253, "seek": 99340, "start": 1018.84, "end": 1021.96, "text": " controversial things is static analysis.", "tokens": [51636, 17323, 721, 307, 13437, 5215, 13, 51792], "temperature": 0.0, "avg_logprob": -0.16018118460973105, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.0030744019895792007}, {"id": 254, "seek": 102196, "start": 1021.96, "end": 1028.16, "text": " And so when I use that term, I mean how can computers look at your code and give you helpful", "tokens": [50364, 400, 370, 562, 286, 764, 300, 1433, 11, 286, 914, 577, 393, 10807, 574, 412, 428, 3089, 293, 976, 291, 4961, 50674], "temperature": 0.0, "avg_logprob": -0.1514391475253635, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.0022512117866426706}, {"id": 255, "seek": 102196, "start": 1028.16, "end": 1035.76, "text": " timely hints that help make your code better and don't waste your time or don't give you", "tokens": [50674, 25150, 27271, 300, 854, 652, 428, 3089, 1101, 293, 500, 380, 5964, 428, 565, 420, 500, 380, 976, 291, 51054], "temperature": 0.0, "avg_logprob": -0.1514391475253635, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.0022512117866426706}, {"id": 256, "seek": 102196, "start": 1035.76, "end": 1037.28, "text": " good feedback.", "tokens": [51054, 665, 5824, 13, 51130], "temperature": 0.0, "avg_logprob": -0.1514391475253635, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.0022512117866426706}, {"id": 257, "seek": 102196, "start": 1037.28, "end": 1042.32, "text": " And so for React that may be a linter is a version of this, something like flow, something", "tokens": [51130, 400, 370, 337, 30644, 300, 815, 312, 257, 287, 5106, 307, 257, 3037, 295, 341, 11, 746, 411, 3095, 11, 746, 51382], "temperature": 0.0, "avg_logprob": -0.1514391475253635, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.0022512117866426706}, {"id": 258, "seek": 102196, "start": 1042.32, "end": 1048.6200000000001, "text": " like TypeScript, giving this extra machine help to improve your code.", "tokens": [51382, 411, 15576, 14237, 11, 2902, 341, 2857, 3479, 854, 281, 3470, 428, 3089, 13, 51697], "temperature": 0.0, "avg_logprob": -0.1514391475253635, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.0022512117866426706}, {"id": 259, "seek": 104862, "start": 1048.62, "end": 1052.6599999999999, "text": " So in Elm, static analysis has been sort of an important part from the very beginning.", "tokens": [50364, 407, 294, 2699, 76, 11, 13437, 5215, 575, 668, 1333, 295, 364, 1021, 644, 490, 264, 588, 2863, 13, 50566], "temperature": 0.0, "avg_logprob": -0.17657157843061488, "compression_ratio": 1.6625386996904026, "no_speech_prob": 0.0011691489489749074}, {"id": 260, "seek": 104862, "start": 1052.6599999999999, "end": 1057.1399999999999, "text": " So in Elm, Compiler is able to give you these hints.", "tokens": [50566, 407, 294, 2699, 76, 11, 6620, 5441, 307, 1075, 281, 976, 291, 613, 27271, 13, 50790], "temperature": 0.0, "avg_logprob": -0.17657157843061488, "compression_ratio": 1.6625386996904026, "no_speech_prob": 0.0011691489489749074}, {"id": 261, "seek": 104862, "start": 1057.1399999999999, "end": 1059.62, "text": " And I want to look at a couple and try to put in context.", "tokens": [50790, 400, 286, 528, 281, 574, 412, 257, 1916, 293, 853, 281, 829, 294, 4319, 13, 50914], "temperature": 0.0, "avg_logprob": -0.17657157843061488, "compression_ratio": 1.6625386996904026, "no_speech_prob": 0.0011691489489749074}, {"id": 262, "seek": 104862, "start": 1059.62, "end": 1065.02, "text": " It's something that's hard to, I feel like Elm programs have like a personal relationship", "tokens": [50914, 467, 311, 746, 300, 311, 1152, 281, 11, 286, 841, 411, 2699, 76, 4268, 362, 411, 257, 2973, 2480, 51184], "temperature": 0.0, "avg_logprob": -0.17657157843061488, "compression_ratio": 1.6625386996904026, "no_speech_prob": 0.0011691489489749074}, {"id": 263, "seek": 104862, "start": 1065.02, "end": 1069.32, "text": " with this, but it doesn't translate well, so I'm going to do my best.", "tokens": [51184, 365, 341, 11, 457, 309, 1177, 380, 13799, 731, 11, 370, 286, 478, 516, 281, 360, 452, 1151, 13, 51399], "temperature": 0.0, "avg_logprob": -0.17657157843061488, "compression_ratio": 1.6625386996904026, "no_speech_prob": 0.0011691489489749074}, {"id": 264, "seek": 104862, "start": 1069.32, "end": 1073.58, "text": " So we have here this little expression where I'm trying to join the strings Alice and Bob", "tokens": [51399, 407, 321, 362, 510, 341, 707, 6114, 689, 286, 478, 1382, 281, 3917, 264, 13985, 16004, 293, 6085, 51612], "temperature": 0.0, "avg_logprob": -0.17657157843061488, "compression_ratio": 1.6625386996904026, "no_speech_prob": 0.0011691489489749074}, {"id": 265, "seek": 104862, "start": 1073.58, "end": 1077.6599999999999, "text": " with the number four and it's saying, okay, function join is expecting the first argument", "tokens": [51612, 365, 264, 1230, 1451, 293, 309, 311, 1566, 11, 1392, 11, 2445, 3917, 307, 9650, 264, 700, 6770, 51816], "temperature": 0.0, "avg_logprob": -0.17657157843061488, "compression_ratio": 1.6625386996904026, "no_speech_prob": 0.0011691489489749074}, {"id": 266, "seek": 107766, "start": 1077.66, "end": 1079.9, "text": " to be a string, but in fact it's a number.", "tokens": [50364, 281, 312, 257, 6798, 11, 457, 294, 1186, 309, 311, 257, 1230, 13, 50476], "temperature": 0.0, "avg_logprob": -0.14079489872373382, "compression_ratio": 1.8150684931506849, "no_speech_prob": 0.0320657417178154}, {"id": 267, "seek": 107766, "start": 1079.9, "end": 1083.8600000000001, "text": " So it's sort of giving you this very human explanation of what's going wrong in that", "tokens": [50476, 407, 309, 311, 1333, 295, 2902, 291, 341, 588, 1952, 10835, 295, 437, 311, 516, 2085, 294, 300, 50674], "temperature": 0.0, "avg_logprob": -0.14079489872373382, "compression_ratio": 1.8150684931506849, "no_speech_prob": 0.0320657417178154}, {"id": 268, "seek": 107766, "start": 1083.8600000000001, "end": 1084.8600000000001, "text": " code.", "tokens": [50674, 3089, 13, 50724], "temperature": 0.0, "avg_logprob": -0.14079489872373382, "compression_ratio": 1.8150684931506849, "no_speech_prob": 0.0320657417178154}, {"id": 269, "seek": 107766, "start": 1084.8600000000001, "end": 1087.3000000000002, "text": " And the neat thing is as your code gets bigger and bigger and bigger, the error may not be", "tokens": [50724, 400, 264, 10654, 551, 307, 382, 428, 3089, 2170, 3801, 293, 3801, 293, 3801, 11, 264, 6713, 815, 406, 312, 50846], "temperature": 0.0, "avg_logprob": -0.14079489872373382, "compression_ratio": 1.8150684931506849, "no_speech_prob": 0.0320657417178154}, {"id": 270, "seek": 107766, "start": 1087.3000000000002, "end": 1091.1000000000001, "text": " as simple as just it's the number four here, but you have some variable and through some", "tokens": [50846, 382, 2199, 382, 445, 309, 311, 264, 1230, 1451, 510, 11, 457, 291, 362, 512, 7006, 293, 807, 512, 51036], "temperature": 0.0, "avg_logprob": -0.14079489872373382, "compression_ratio": 1.8150684931506849, "no_speech_prob": 0.0320657417178154}, {"id": 271, "seek": 107766, "start": 1091.1000000000001, "end": 1094.8200000000002, "text": " other fact in your code base, it will be a number.", "tokens": [51036, 661, 1186, 294, 428, 3089, 3096, 11, 309, 486, 312, 257, 1230, 13, 51222], "temperature": 0.0, "avg_logprob": -0.14079489872373382, "compression_ratio": 1.8150684931506849, "no_speech_prob": 0.0320657417178154}, {"id": 272, "seek": 107766, "start": 1094.8200000000002, "end": 1096.46, "text": " It'll catch that as well.", "tokens": [51222, 467, 603, 3745, 300, 382, 731, 13, 51304], "temperature": 0.0, "avg_logprob": -0.14079489872373382, "compression_ratio": 1.8150684931506849, "no_speech_prob": 0.0320657417178154}, {"id": 273, "seek": 107766, "start": 1096.46, "end": 1101.6200000000001, "text": " So in a little bit more complex case here, we have an if expression and in the body we're", "tokens": [51304, 407, 294, 257, 707, 857, 544, 3997, 1389, 510, 11, 321, 362, 364, 498, 6114, 293, 294, 264, 1772, 321, 434, 51562], "temperature": 0.0, "avg_logprob": -0.14079489872373382, "compression_ratio": 1.8150684931506849, "no_speech_prob": 0.0320657417178154}, {"id": 274, "seek": 107766, "start": 1101.6200000000001, "end": 1104.8600000000001, "text": " saying is the length, what is the length of this?", "tokens": [51562, 1566, 307, 264, 4641, 11, 437, 307, 264, 4641, 295, 341, 30, 51724], "temperature": 0.0, "avg_logprob": -0.14079489872373382, "compression_ratio": 1.8150684931506849, "no_speech_prob": 0.0320657417178154}, {"id": 275, "seek": 110486, "start": 1104.86, "end": 1108.3, "text": " And so Elm is saying, hey, this needs to be a Boolean value.", "tokens": [50364, 400, 370, 2699, 76, 307, 1566, 11, 4177, 11, 341, 2203, 281, 312, 257, 23351, 28499, 2158, 13, 50536], "temperature": 0.0, "avg_logprob": -0.16465191753364047, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.0017002179520204663}, {"id": 276, "seek": 110486, "start": 1108.3, "end": 1110.9399999999998, "text": " You've given me an integer, but I need a Boolean.", "tokens": [50536, 509, 600, 2212, 385, 364, 24922, 11, 457, 286, 643, 257, 23351, 28499, 13, 50668], "temperature": 0.0, "avg_logprob": -0.16465191753364047, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.0017002179520204663}, {"id": 277, "seek": 110486, "start": 1110.9399999999998, "end": 1113.5, "text": " And what's nice about this one is it has the little hint.", "tokens": [50668, 400, 437, 311, 1481, 466, 341, 472, 307, 309, 575, 264, 707, 12075, 13, 50796], "temperature": 0.0, "avg_logprob": -0.16465191753364047, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.0017002179520204663}, {"id": 278, "seek": 110486, "start": 1113.5, "end": 1118.74, "text": " So I know that when people come to Elm, there's certain mistakes that are like super predictable,", "tokens": [50796, 407, 286, 458, 300, 562, 561, 808, 281, 2699, 76, 11, 456, 311, 1629, 8038, 300, 366, 411, 1687, 27737, 11, 51058], "temperature": 0.0, "avg_logprob": -0.16465191753364047, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.0017002179520204663}, {"id": 279, "seek": 110486, "start": 1118.74, "end": 1121.1, "text": " like lots of people are coming from Python, JavaScript.", "tokens": [51058, 411, 3195, 295, 561, 366, 1348, 490, 15329, 11, 15778, 13, 51176], "temperature": 0.0, "avg_logprob": -0.16465191753364047, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.0017002179520204663}, {"id": 280, "seek": 110486, "start": 1121.1, "end": 1124.74, "text": " And so I try to give a hint that, hey, Elm doesn't have truthiness such that instance", "tokens": [51176, 400, 370, 286, 853, 281, 976, 257, 12075, 300, 11, 4177, 11, 2699, 76, 1177, 380, 362, 3494, 1324, 1270, 300, 5197, 51358], "temperature": 0.0, "avg_logprob": -0.16465191753364047, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.0017002179520204663}, {"id": 281, "seek": 110486, "start": 1124.74, "end": 1126.02, "text": " strings are automatically converted.", "tokens": [51358, 13985, 366, 6772, 16424, 13, 51422], "temperature": 0.0, "avg_logprob": -0.16465191753364047, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.0017002179520204663}, {"id": 282, "seek": 110486, "start": 1126.02, "end": 1128.3, "text": " You need to do that conversion explicitly.", "tokens": [51422, 509, 643, 281, 360, 300, 14298, 20803, 13, 51536], "temperature": 0.0, "avg_logprob": -0.16465191753364047, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.0017002179520204663}, {"id": 283, "seek": 110486, "start": 1128.3, "end": 1132.8999999999999, "text": " So I'm trying to give as much scaffolding as possible so that you know, okay, list length,", "tokens": [51536, 407, 286, 478, 1382, 281, 976, 382, 709, 44094, 278, 382, 1944, 370, 300, 291, 458, 11, 1392, 11, 1329, 4641, 11, 51766], "temperature": 0.0, "avg_logprob": -0.16465191753364047, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.0017002179520204663}, {"id": 284, "seek": 110486, "start": 1132.8999999999999, "end": 1133.8999999999999, "text": " is it equal to zero?", "tokens": [51766, 307, 309, 2681, 281, 4018, 30, 51816], "temperature": 0.0, "avg_logprob": -0.16465191753364047, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.0017002179520204663}, {"id": 285, "seek": 113390, "start": 1133.94, "end": 1138.46, "text": " Less than one is greater than 10, like be explicit about that kind of thing.", "tokens": [50366, 18649, 813, 472, 307, 5044, 813, 1266, 11, 411, 312, 13691, 466, 300, 733, 295, 551, 13, 50592], "temperature": 0.0, "avg_logprob": -0.1600545410417084, "compression_ratio": 1.651851851851852, "no_speech_prob": 0.0005355706089176238}, {"id": 286, "seek": 113390, "start": 1138.46, "end": 1143.3000000000002, "text": " Now I think those examples don't really show what this means in a large setting.", "tokens": [50592, 823, 286, 519, 729, 5110, 500, 380, 534, 855, 437, 341, 1355, 294, 257, 2416, 3287, 13, 50834], "temperature": 0.0, "avg_logprob": -0.1600545410417084, "compression_ratio": 1.651851851851852, "no_speech_prob": 0.0005355706089176238}, {"id": 287, "seek": 113390, "start": 1143.3000000000002, "end": 1147.66, "text": " So I work at this company called NoWriteInc, and we've been using Elm for about two years", "tokens": [50834, 407, 286, 589, 412, 341, 2237, 1219, 883, 54, 35002, 4575, 66, 11, 293, 321, 600, 668, 1228, 2699, 76, 337, 466, 732, 924, 51052], "temperature": 0.0, "avg_logprob": -0.1600545410417084, "compression_ratio": 1.651851851851852, "no_speech_prob": 0.0005355706089176238}, {"id": 288, "seek": 113390, "start": 1147.66, "end": 1154.98, "text": " now, and we have about 200,000 lines of Elm code, and there's been zero runtime exceptions", "tokens": [51052, 586, 11, 293, 321, 362, 466, 2331, 11, 1360, 3876, 295, 2699, 76, 3089, 11, 293, 456, 311, 668, 4018, 34474, 22847, 51418], "temperature": 0.0, "avg_logprob": -0.1600545410417084, "compression_ratio": 1.651851851851852, "no_speech_prob": 0.0005355706089176238}, {"id": 289, "seek": 113390, "start": 1154.98, "end": 1157.1000000000001, "text": " in production.", "tokens": [51418, 294, 4265, 13, 51524], "temperature": 0.0, "avg_logprob": -0.1600545410417084, "compression_ratio": 1.651851851851852, "no_speech_prob": 0.0005355706089176238}, {"id": 290, "seek": 113390, "start": 1157.1000000000001, "end": 1163.26, "text": " And so the kinds of things that this is catching is really, really extensive, and it's doing", "tokens": [51524, 400, 370, 264, 3685, 295, 721, 300, 341, 307, 16124, 307, 534, 11, 534, 13246, 11, 293, 309, 311, 884, 51832], "temperature": 0.0, "avg_logprob": -0.1600545410417084, "compression_ratio": 1.651851851851852, "no_speech_prob": 0.0005355706089176238}, {"id": 291, "seek": 116326, "start": 1163.26, "end": 1167.54, "text": " it in a way that feels like a pair of programmers saying, hey, did you think about this case?", "tokens": [50364, 309, 294, 257, 636, 300, 3417, 411, 257, 6119, 295, 41504, 1566, 11, 4177, 11, 630, 291, 519, 466, 341, 1389, 30, 50578], "temperature": 0.0, "avg_logprob": -0.16062971131991496, "compression_ratio": 1.6015037593984962, "no_speech_prob": 0.00019404737395234406}, {"id": 292, "seek": 116326, "start": 1167.54, "end": 1169.66, "text": " Did you think about that case?", "tokens": [50578, 2589, 291, 519, 466, 300, 1389, 30, 50684], "temperature": 0.0, "avg_logprob": -0.16062971131991496, "compression_ratio": 1.6015037593984962, "no_speech_prob": 0.00019404737395234406}, {"id": 293, "seek": 116326, "start": 1169.66, "end": 1174.22, "text": " And so one question you might ask is, how do you know it's zero, like is your URL misconfigured", "tokens": [50684, 400, 370, 472, 1168, 291, 1062, 1029, 307, 11, 577, 360, 291, 458, 309, 311, 4018, 11, 411, 307, 428, 12905, 27631, 20646, 3831, 50912], "temperature": 0.0, "avg_logprob": -0.16062971131991496, "compression_ratio": 1.6015037593984962, "no_speech_prob": 0.00019404737395234406}, {"id": 294, "seek": 116326, "start": 1174.22, "end": 1177.1, "text": " so you're just not getting any reports?", "tokens": [50912, 370, 291, 434, 445, 406, 1242, 604, 7122, 30, 51056], "temperature": 0.0, "avg_logprob": -0.16062971131991496, "compression_ratio": 1.6015037593984962, "no_speech_prob": 0.00019404737395234406}, {"id": 295, "seek": 116326, "start": 1177.1, "end": 1180.62, "text": " There is legacy JavaScript code that will throw exceptions from time to time.", "tokens": [51056, 821, 307, 11711, 15778, 3089, 300, 486, 3507, 22847, 490, 565, 281, 565, 13, 51232], "temperature": 0.0, "avg_logprob": -0.16062971131991496, "compression_ratio": 1.6015037593984962, "no_speech_prob": 0.00019404737395234406}, {"id": 296, "seek": 116326, "start": 1180.62, "end": 1184.06, "text": " So we know errors can be detected.", "tokens": [51232, 407, 321, 458, 13603, 393, 312, 21896, 13, 51404], "temperature": 0.0, "avg_logprob": -0.16062971131991496, "compression_ratio": 1.6015037593984962, "no_speech_prob": 0.00019404737395234406}, {"id": 297, "seek": 116326, "start": 1184.06, "end": 1192.74, "text": " So I want to show in a larger program what it means.", "tokens": [51404, 407, 286, 528, 281, 855, 294, 257, 4833, 1461, 437, 309, 1355, 13, 51838], "temperature": 0.0, "avg_logprob": -0.16062971131991496, "compression_ratio": 1.6015037593984962, "no_speech_prob": 0.00019404737395234406}, {"id": 298, "seek": 119274, "start": 1192.74, "end": 1198.6200000000001, "text": " And so I accidentally, okay, no, I think this is good, I think this is good.", "tokens": [50364, 400, 370, 286, 15715, 11, 1392, 11, 572, 11, 286, 519, 341, 307, 665, 11, 286, 519, 341, 307, 665, 13, 50658], "temperature": 0.0, "avg_logprob": -0.151160822974311, "compression_ratio": 1.6391752577319587, "no_speech_prob": 0.0022857070434838533}, {"id": 299, "seek": 119274, "start": 1198.6200000000001, "end": 1209.5, "text": " So let's say I want to add a new control, so rather than just having all the things,", "tokens": [50658, 407, 718, 311, 584, 286, 528, 281, 909, 257, 777, 1969, 11, 370, 2831, 813, 445, 1419, 439, 264, 721, 11, 51202], "temperature": 0.0, "avg_logprob": -0.151160822974311, "compression_ratio": 1.6391752577319587, "no_speech_prob": 0.0022857070434838533}, {"id": 300, "seek": 119274, "start": 1209.5, "end": 1216.38, "text": " what's active, what's completed, I want to show if something's complex.", "tokens": [51202, 437, 311, 4967, 11, 437, 311, 7365, 11, 286, 528, 281, 855, 498, 746, 311, 3997, 13, 51546], "temperature": 0.0, "avg_logprob": -0.151160822974311, "compression_ratio": 1.6391752577319587, "no_speech_prob": 0.0022857070434838533}, {"id": 301, "seek": 119274, "start": 1216.38, "end": 1221.86, "text": " So here I can say, here's my controls for which things are visible, and I'm going to", "tokens": [51546, 407, 510, 286, 393, 584, 11, 510, 311, 452, 9003, 337, 597, 721, 366, 8974, 11, 293, 286, 478, 516, 281, 51820], "temperature": 0.0, "avg_logprob": -0.151160822974311, "compression_ratio": 1.6391752577319587, "no_speech_prob": 0.0022857070434838533}, {"id": 302, "seek": 122186, "start": 1221.9799999999998, "end": 1229.62, "text": " add an extra case for, is it a complex task?", "tokens": [50370, 909, 364, 2857, 1389, 337, 11, 307, 309, 257, 3997, 5633, 30, 50752], "temperature": 0.0, "avg_logprob": -0.14479551817241468, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.010481535457074642}, {"id": 303, "seek": 122186, "start": 1229.62, "end": 1241.3799999999999, "text": " So what's nice in Elm is you can kind of just run the compiler and see what it tells you.", "tokens": [50752, 407, 437, 311, 1481, 294, 2699, 76, 307, 291, 393, 733, 295, 445, 1190, 264, 31958, 293, 536, 437, 309, 5112, 291, 13, 51340], "temperature": 0.0, "avg_logprob": -0.14479551817241468, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.010481535457074642}, {"id": 304, "seek": 122186, "start": 1241.3799999999999, "end": 1245.6999999999998, "text": " So in this case, it's saying, hey, this complex thing, I don't know what it is.", "tokens": [51340, 407, 294, 341, 1389, 11, 309, 311, 1566, 11, 4177, 11, 341, 3997, 551, 11, 286, 500, 380, 458, 437, 309, 307, 13, 51556], "temperature": 0.0, "avg_logprob": -0.14479551817241468, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.010481535457074642}, {"id": 305, "seek": 122186, "start": 1245.6999999999998, "end": 1249.02, "text": " Is it supposed to be an import?", "tokens": [51556, 1119, 309, 3442, 281, 312, 364, 974, 30, 51722], "temperature": 0.0, "avg_logprob": -0.14479551817241468, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.010481535457074642}, {"id": 306, "seek": 124902, "start": 1249.18, "end": 1253.86, "text": " So where did the code go?", "tokens": [50372, 407, 689, 630, 264, 3089, 352, 30, 50606], "temperature": 0.0, "avg_logprob": -0.16317244707527806, "compression_ratio": 1.7361702127659575, "no_speech_prob": 0.00010888589167734608}, {"id": 307, "seek": 124902, "start": 1253.86, "end": 1259.46, "text": " Okay, so it's suggesting like, hey, you need to define complex before you use it.", "tokens": [50606, 1033, 11, 370, 309, 311, 18094, 411, 11, 4177, 11, 291, 643, 281, 6964, 3997, 949, 291, 764, 309, 13, 50886], "temperature": 0.0, "avg_logprob": -0.16317244707527806, "compression_ratio": 1.7361702127659575, "no_speech_prob": 0.00010888589167734608}, {"id": 308, "seek": 124902, "start": 1259.46, "end": 1263.62, "text": " So one of the visibility options is, okay, I want complex stuff.", "tokens": [50886, 407, 472, 295, 264, 19883, 3956, 307, 11, 1392, 11, 286, 528, 3997, 1507, 13, 51094], "temperature": 0.0, "avg_logprob": -0.16317244707527806, "compression_ratio": 1.7361702127659575, "no_speech_prob": 0.00010888589167734608}, {"id": 309, "seek": 124902, "start": 1263.62, "end": 1266.46, "text": " So I added that, let's see if that works.", "tokens": [51094, 407, 286, 3869, 300, 11, 718, 311, 536, 498, 300, 1985, 13, 51236], "temperature": 0.0, "avg_logprob": -0.16317244707527806, "compression_ratio": 1.7361702127659575, "no_speech_prob": 0.00010888589167734608}, {"id": 310, "seek": 124902, "start": 1266.46, "end": 1272.18, "text": " And it's saying, hey, one of your cases doesn't cover that scenario, so case, visibility.", "tokens": [51236, 400, 309, 311, 1566, 11, 4177, 11, 472, 295, 428, 3331, 1177, 380, 2060, 300, 9005, 11, 370, 1389, 11, 19883, 13, 51522], "temperature": 0.0, "avg_logprob": -0.16317244707527806, "compression_ratio": 1.7361702127659575, "no_speech_prob": 0.00010888589167734608}, {"id": 311, "seek": 124902, "start": 1272.18, "end": 1274.78, "text": " So in this case, we're changing it to strings.", "tokens": [51522, 407, 294, 341, 1389, 11, 321, 434, 4473, 309, 281, 13985, 13, 51652], "temperature": 0.0, "avg_logprob": -0.16317244707527806, "compression_ratio": 1.7361702127659575, "no_speech_prob": 0.00010888589167734608}, {"id": 312, "seek": 124902, "start": 1274.78, "end": 1278.74, "text": " So in the complex case, we're just going to say complex.", "tokens": [51652, 407, 294, 264, 3997, 1389, 11, 321, 434, 445, 516, 281, 584, 3997, 13, 51850], "temperature": 0.0, "avg_logprob": -0.16317244707527806, "compression_ratio": 1.7361702127659575, "no_speech_prob": 0.00010888589167734608}, {"id": 313, "seek": 127874, "start": 1278.74, "end": 1283.14, "text": " And one question you may have here is, why turn it to strings that looks the same as", "tokens": [50364, 400, 472, 1168, 291, 815, 362, 510, 307, 11, 983, 1261, 309, 281, 13985, 300, 1542, 264, 912, 382, 50584], "temperature": 0.0, "avg_logprob": -0.12182425007675633, "compression_ratio": 1.6689895470383276, "no_speech_prob": 4.682963481172919e-05}, {"id": 314, "seek": 127874, "start": 1283.14, "end": 1284.14, "text": " the value?", "tokens": [50584, 264, 2158, 30, 50634], "temperature": 0.0, "avg_logprob": -0.12182425007675633, "compression_ratio": 1.6689895470383276, "no_speech_prob": 4.682963481172919e-05}, {"id": 315, "seek": 127874, "start": 1284.14, "end": 1287.7, "text": " So your designer may say, I don't want it to be complex, I want it to be called like", "tokens": [50634, 407, 428, 11795, 815, 584, 11, 286, 500, 380, 528, 309, 281, 312, 3997, 11, 286, 528, 309, 281, 312, 1219, 411, 50812], "temperature": 0.0, "avg_logprob": -0.12182425007675633, "compression_ratio": 1.6689895470383276, "no_speech_prob": 4.682963481172919e-05}, {"id": 316, "seek": 127874, "start": 1287.7, "end": 1289.9, "text": " fancy tasks.", "tokens": [50812, 10247, 9608, 13, 50922], "temperature": 0.0, "avg_logprob": -0.12182425007675633, "compression_ratio": 1.6689895470383276, "no_speech_prob": 4.682963481172919e-05}, {"id": 317, "seek": 127874, "start": 1289.9, "end": 1292.18, "text": " And so you can change that without changing all your code.", "tokens": [50922, 400, 370, 291, 393, 1319, 300, 1553, 4473, 439, 428, 3089, 13, 51036], "temperature": 0.0, "avg_logprob": -0.12182425007675633, "compression_ratio": 1.6689895470383276, "no_speech_prob": 4.682963481172919e-05}, {"id": 318, "seek": 127874, "start": 1292.18, "end": 1297.66, "text": " So I think this decoupling is important even if you're not using it at the start.", "tokens": [51036, 407, 286, 519, 341, 979, 263, 11970, 307, 1021, 754, 498, 291, 434, 406, 1228, 309, 412, 264, 722, 13, 51310], "temperature": 0.0, "avg_logprob": -0.12182425007675633, "compression_ratio": 1.6689895470383276, "no_speech_prob": 4.682963481172919e-05}, {"id": 319, "seek": 127874, "start": 1297.66, "end": 1299.82, "text": " So we'll stick with complex for now.", "tokens": [51310, 407, 321, 603, 2897, 365, 3997, 337, 586, 13, 51418], "temperature": 0.0, "avg_logprob": -0.12182425007675633, "compression_ratio": 1.6689895470383276, "no_speech_prob": 4.682963481172919e-05}, {"id": 320, "seek": 127874, "start": 1299.82, "end": 1302.14, "text": " So let's just ask the compiler again what's going on.", "tokens": [51418, 407, 718, 311, 445, 1029, 264, 31958, 797, 437, 311, 516, 322, 13, 51534], "temperature": 0.0, "avg_logprob": -0.12182425007675633, "compression_ratio": 1.6689895470383276, "no_speech_prob": 4.682963481172919e-05}, {"id": 321, "seek": 127874, "start": 1302.14, "end": 1305.74, "text": " Okay, this case doesn't handle all the possibilities.", "tokens": [51534, 1033, 11, 341, 1389, 1177, 380, 4813, 439, 264, 12178, 13, 51714], "temperature": 0.0, "avg_logprob": -0.12182425007675633, "compression_ratio": 1.6689895470383276, "no_speech_prob": 4.682963481172919e-05}, {"id": 322, "seek": 130574, "start": 1305.74, "end": 1310.34, "text": " It's saying, hey, you need to handle complex in particular.", "tokens": [50364, 467, 311, 1566, 11, 4177, 11, 291, 643, 281, 4813, 3997, 294, 1729, 13, 50594], "temperature": 0.0, "avg_logprob": -0.18364139667992452, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.0017003753455355763}, {"id": 323, "seek": 130574, "start": 1310.34, "end": 1312.7, "text": " So let's go find that.", "tokens": [50594, 407, 718, 311, 352, 915, 300, 13, 50712], "temperature": 0.0, "avg_logprob": -0.18364139667992452, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.0017003753455355763}, {"id": 324, "seek": 130574, "start": 1312.7, "end": 1318.66, "text": " Okay, and so this is a function that's figuring out, given the visibility, is the entry visible", "tokens": [50712, 1033, 11, 293, 370, 341, 307, 257, 2445, 300, 311, 15213, 484, 11, 2212, 264, 19883, 11, 307, 264, 8729, 8974, 51010], "temperature": 0.0, "avg_logprob": -0.18364139667992452, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.0017003753455355763}, {"id": 325, "seek": 130574, "start": 1318.66, "end": 1319.66, "text": " or not?", "tokens": [51010, 420, 406, 30, 51060], "temperature": 0.0, "avg_logprob": -0.18364139667992452, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.0017003753455355763}, {"id": 326, "seek": 130574, "start": 1319.66, "end": 1326.5, "text": " So in the complex case, we can say, is the length of the to-do description?", "tokens": [51060, 407, 294, 264, 3997, 1389, 11, 321, 393, 584, 11, 307, 264, 4641, 295, 264, 281, 12, 2595, 3855, 30, 51402], "temperature": 0.0, "avg_logprob": -0.18364139667992452, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.0017003753455355763}, {"id": 327, "seek": 130574, "start": 1326.5, "end": 1330.18, "text": " Oh, yeah, and I want to make all sorts of typos here.", "tokens": [51402, 876, 11, 1338, 11, 293, 286, 528, 281, 652, 439, 7527, 295, 2125, 329, 510, 13, 51586], "temperature": 0.0, "avg_logprob": -0.18364139667992452, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.0017003753455355763}, {"id": 328, "seek": 130574, "start": 1330.18, "end": 1331.7, "text": " So I misspell that.", "tokens": [51586, 407, 286, 1713, 49241, 300, 13, 51662], "temperature": 0.0, "avg_logprob": -0.18364139667992452, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.0017003753455355763}, {"id": 329, "seek": 133170, "start": 1331.7, "end": 1334.06, "text": " I'm going to misspell this thing.", "tokens": [50364, 286, 478, 516, 281, 1713, 49241, 341, 551, 13, 50482], "temperature": 0.0, "avg_logprob": -0.15832225287832866, "compression_ratio": 1.4734042553191489, "no_speech_prob": 7.96614185674116e-05}, {"id": 330, "seek": 133170, "start": 1334.06, "end": 1345.74, "text": " And the description, that was a legit typo, I didn't mean, is less than 15, let's say.", "tokens": [50482, 400, 264, 3855, 11, 300, 390, 257, 10275, 2125, 78, 11, 286, 994, 380, 914, 11, 307, 1570, 813, 2119, 11, 718, 311, 584, 13, 51066], "temperature": 0.0, "avg_logprob": -0.15832225287832866, "compression_ratio": 1.4734042553191489, "no_speech_prob": 7.96614185674116e-05}, {"id": 331, "seek": 133170, "start": 1345.74, "end": 1350.7, "text": " So some of these errors are bound to happen eventually.", "tokens": [51066, 407, 512, 295, 613, 13603, 366, 5472, 281, 1051, 4728, 13, 51314], "temperature": 0.0, "avg_logprob": -0.15832225287832866, "compression_ratio": 1.4734042553191489, "no_speech_prob": 7.96614185674116e-05}, {"id": 332, "seek": 133170, "start": 1350.7, "end": 1353.02, "text": " So let's see what the compiler tells me about it.", "tokens": [51314, 407, 718, 311, 536, 437, 264, 31958, 5112, 385, 466, 309, 13, 51430], "temperature": 0.0, "avg_logprob": -0.15832225287832866, "compression_ratio": 1.4734042553191489, "no_speech_prob": 7.96614185674116e-05}, {"id": 333, "seek": 133170, "start": 1353.02, "end": 1359.14, "text": " So it's saying, hey, I found this pattern complex.", "tokens": [51430, 407, 309, 311, 1566, 11, 4177, 11, 286, 1352, 341, 5102, 3997, 13, 51736], "temperature": 0.0, "avg_logprob": -0.15832225287832866, "compression_ratio": 1.4734042553191489, "no_speech_prob": 7.96614185674116e-05}, {"id": 334, "seek": 135914, "start": 1359.14, "end": 1364.9, "text": " Maybe you want this other idea, okay, that is exactly what I want, in fact.", "tokens": [50364, 2704, 291, 528, 341, 661, 1558, 11, 1392, 11, 300, 307, 2293, 437, 286, 528, 11, 294, 1186, 13, 50652], "temperature": 0.0, "avg_logprob": -0.1785034269798459, "compression_ratio": 1.721311475409836, "no_speech_prob": 0.007343104109168053}, {"id": 335, "seek": 135914, "start": 1364.9, "end": 1365.9, "text": " And here's a naming error.", "tokens": [50652, 400, 510, 311, 257, 25290, 6713, 13, 50702], "temperature": 0.0, "avg_logprob": -0.1785034269798459, "compression_ratio": 1.721311475409836, "no_speech_prob": 0.007343104109168053}, {"id": 336, "seek": 135914, "start": 1365.9, "end": 1370.8200000000002, "text": " You use toad, maybe you want one of these other things, and it tries to find names in", "tokens": [50702, 509, 764, 281, 345, 11, 1310, 291, 528, 472, 295, 613, 661, 721, 11, 293, 309, 9898, 281, 915, 5288, 294, 50948], "temperature": 0.0, "avg_logprob": -0.1785034269798459, "compression_ratio": 1.721311475409836, "no_speech_prob": 0.007343104109168053}, {"id": 337, "seek": 135914, "start": 1370.8200000000002, "end": 1373.18, "text": " scope that are close.", "tokens": [50948, 11923, 300, 366, 1998, 13, 51066], "temperature": 0.0, "avg_logprob": -0.1785034269798459, "compression_ratio": 1.721311475409836, "no_speech_prob": 0.007343104109168053}, {"id": 338, "seek": 135914, "start": 1373.18, "end": 1375.14, "text": " So I want to do.", "tokens": [51066, 407, 286, 528, 281, 360, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1785034269798459, "compression_ratio": 1.721311475409836, "no_speech_prob": 0.007343104109168053}, {"id": 339, "seek": 135914, "start": 1375.14, "end": 1376.8600000000001, "text": " So okay, I fixed all the errors.", "tokens": [51164, 407, 1392, 11, 286, 6806, 439, 264, 13603, 13, 51250], "temperature": 0.0, "avg_logprob": -0.1785034269798459, "compression_ratio": 1.721311475409836, "no_speech_prob": 0.007343104109168053}, {"id": 340, "seek": 135914, "start": 1376.8600000000001, "end": 1377.8600000000001, "text": " Let's see.", "tokens": [51250, 961, 311, 536, 13, 51300], "temperature": 0.0, "avg_logprob": -0.1785034269798459, "compression_ratio": 1.721311475409836, "no_speech_prob": 0.007343104109168053}, {"id": 341, "seek": 135914, "start": 1377.8600000000001, "end": 1382.8200000000002, "text": " And it's saying, hey, to-do doesn't have a thing called description, but this is close", "tokens": [51300, 400, 309, 311, 1566, 11, 4177, 11, 281, 12, 2595, 1177, 380, 362, 257, 551, 1219, 3855, 11, 457, 341, 307, 1998, 51548], "temperature": 0.0, "avg_logprob": -0.1785034269798459, "compression_ratio": 1.721311475409836, "no_speech_prob": 0.007343104109168053}, {"id": 342, "seek": 135914, "start": 1382.8200000000002, "end": 1386.42, "text": " to a field that it could have, so maybe you want description.", "tokens": [51548, 281, 257, 2519, 300, 309, 727, 362, 11, 370, 1310, 291, 528, 3855, 13, 51728], "temperature": 0.0, "avg_logprob": -0.1785034269798459, "compression_ratio": 1.721311475409836, "no_speech_prob": 0.007343104109168053}, {"id": 343, "seek": 138642, "start": 1386.42, "end": 1392.26, "text": " And so for each of those errors, had this been a string, it just would have been wrong.", "tokens": [50364, 400, 370, 337, 1184, 295, 729, 13603, 11, 632, 341, 668, 257, 6798, 11, 309, 445, 576, 362, 668, 2085, 13, 50656], "temperature": 0.0, "avg_logprob": -0.1110778505151922, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.0002611533855088055}, {"id": 344, "seek": 138642, "start": 1392.26, "end": 1396.74, "text": " And then some point you find that error through some bug report.", "tokens": [50656, 400, 550, 512, 935, 291, 915, 300, 6713, 807, 512, 7426, 2275, 13, 50880], "temperature": 0.0, "avg_logprob": -0.1110778505151922, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.0002611533855088055}, {"id": 345, "seek": 138642, "start": 1396.74, "end": 1399.5, "text": " And then you find out that this was also misspelled.", "tokens": [50880, 400, 550, 291, 915, 484, 300, 341, 390, 611, 1713, 33000, 13, 51018], "temperature": 0.0, "avg_logprob": -0.1110778505151922, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.0002611533855088055}, {"id": 346, "seek": 138642, "start": 1399.5, "end": 1403.3000000000002, "text": " And then that would have been, I can't access a field on an undefined value.", "tokens": [51018, 400, 550, 300, 576, 362, 668, 11, 286, 393, 380, 2105, 257, 2519, 322, 364, 674, 5666, 2001, 2158, 13, 51208], "temperature": 0.0, "avg_logprob": -0.1110778505151922, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.0002611533855088055}, {"id": 347, "seek": 138642, "start": 1403.3000000000002, "end": 1407.3400000000001, "text": " And then you would find out, okay, this thing is spelled wrong, and that's going to actually", "tokens": [51208, 400, 550, 291, 576, 915, 484, 11, 1392, 11, 341, 551, 307, 34388, 2085, 11, 293, 300, 311, 516, 281, 767, 51410], "temperature": 0.0, "avg_logprob": -0.1110778505151922, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.0002611533855088055}, {"id": 348, "seek": 138642, "start": 1407.3400000000001, "end": 1409.1000000000001, "text": " be an undefined.", "tokens": [51410, 312, 364, 674, 5666, 2001, 13, 51498], "temperature": 0.0, "avg_logprob": -0.1110778505151922, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.0002611533855088055}, {"id": 349, "seek": 138642, "start": 1409.1000000000001, "end": 1410.1000000000001, "text": " And what is string.length?", "tokens": [51498, 400, 437, 307, 6798, 13, 45390, 30, 51548], "temperature": 0.0, "avg_logprob": -0.1110778505151922, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.0002611533855088055}, {"id": 350, "seek": 138642, "start": 1410.1000000000001, "end": 1411.1000000000001, "text": " Do you want undefined?", "tokens": [51548, 1144, 291, 528, 674, 5666, 2001, 30, 51598], "temperature": 0.0, "avg_logprob": -0.1110778505151922, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.0002611533855088055}, {"id": 351, "seek": 138642, "start": 1411.1000000000001, "end": 1413.98, "text": " I don't know.", "tokens": [51598, 286, 500, 380, 458, 13, 51742], "temperature": 0.0, "avg_logprob": -0.1110778505151922, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.0002611533855088055}, {"id": 352, "seek": 141398, "start": 1413.98, "end": 1417.02, "text": " So it's catching all these things in a really nice way.", "tokens": [50364, 407, 309, 311, 16124, 439, 613, 721, 294, 257, 534, 1481, 636, 13, 50516], "temperature": 0.0, "avg_logprob": -0.1496871549691727, "compression_ratio": 1.6620209059233448, "no_speech_prob": 0.004606377333402634}, {"id": 353, "seek": 141398, "start": 1417.02, "end": 1421.42, "text": " And so as your program gets bigger, it's catching all these things still across a whole code", "tokens": [50516, 400, 370, 382, 428, 1461, 2170, 3801, 11, 309, 311, 16124, 439, 613, 721, 920, 2108, 257, 1379, 3089, 50736], "temperature": 0.0, "avg_logprob": -0.1496871549691727, "compression_ratio": 1.6620209059233448, "no_speech_prob": 0.004606377333402634}, {"id": 354, "seek": 141398, "start": 1421.42, "end": 1422.42, "text": " base.", "tokens": [50736, 3096, 13, 50786], "temperature": 0.0, "avg_logprob": -0.1496871549691727, "compression_ratio": 1.6620209059233448, "no_speech_prob": 0.004606377333402634}, {"id": 355, "seek": 141398, "start": 1422.42, "end": 1426.58, "text": " So for the 200,000 lines that Norbert Inc. has, this is the kind of help they're getting", "tokens": [50786, 407, 337, 264, 2331, 11, 1360, 3876, 300, 6966, 4290, 7779, 13, 575, 11, 341, 307, 264, 733, 295, 854, 436, 434, 1242, 50994], "temperature": 0.0, "avg_logprob": -0.1496871549691727, "compression_ratio": 1.6620209059233448, "no_speech_prob": 0.004606377333402634}, {"id": 356, "seek": 141398, "start": 1426.58, "end": 1428.18, "text": " along the way.", "tokens": [50994, 2051, 264, 636, 13, 51074], "temperature": 0.0, "avg_logprob": -0.1496871549691727, "compression_ratio": 1.6620209059233448, "no_speech_prob": 0.004606377333402634}, {"id": 357, "seek": 141398, "start": 1428.18, "end": 1432.78, "text": " And so because that's such an important part of Elm, it sort of fits in with, like, another", "tokens": [51074, 400, 370, 570, 300, 311, 1270, 364, 1021, 644, 295, 2699, 76, 11, 309, 1333, 295, 9001, 294, 365, 11, 411, 11, 1071, 51304], "temperature": 0.0, "avg_logprob": -0.1496871549691727, "compression_ratio": 1.6620209059233448, "no_speech_prob": 0.004606377333402634}, {"id": 358, "seek": 141398, "start": 1432.78, "end": 1437.5, "text": " question people have is, React uses NPM for all of its package management.", "tokens": [51304, 1168, 561, 362, 307, 11, 30644, 4960, 426, 18819, 337, 439, 295, 1080, 7372, 4592, 13, 51540], "temperature": 0.0, "avg_logprob": -0.1496871549691727, "compression_ratio": 1.6620209059233448, "no_speech_prob": 0.004606377333402634}, {"id": 359, "seek": 141398, "start": 1437.5, "end": 1440.9, "text": " Elm uses Elm package, so we actually don't use NPM.", "tokens": [51540, 2699, 76, 4960, 2699, 76, 7372, 11, 370, 321, 767, 500, 380, 764, 426, 18819, 13, 51710], "temperature": 0.0, "avg_logprob": -0.1496871549691727, "compression_ratio": 1.6620209059233448, "no_speech_prob": 0.004606377333402634}, {"id": 360, "seek": 144090, "start": 1440.9, "end": 1445.8200000000002, "text": " But all of the half a million packages on NPM aren't directly available.", "tokens": [50364, 583, 439, 295, 264, 1922, 257, 2459, 17401, 322, 426, 18819, 3212, 380, 3838, 2435, 13, 50610], "temperature": 0.0, "avg_logprob": -0.14367293452357385, "compression_ratio": 1.60546875, "no_speech_prob": 0.0031716665253043175}, {"id": 361, "seek": 144090, "start": 1445.8200000000002, "end": 1448.7, "text": " And so some people look at that and they're like, well, you're a crazy person.", "tokens": [50610, 400, 370, 512, 561, 574, 412, 300, 293, 436, 434, 411, 11, 731, 11, 291, 434, 257, 3219, 954, 13, 50754], "temperature": 0.0, "avg_logprob": -0.14367293452357385, "compression_ratio": 1.60546875, "no_speech_prob": 0.0031716665253043175}, {"id": 362, "seek": 144090, "start": 1448.7, "end": 1452.7800000000002, "text": " That's like, obviously, you need that to have something nice.", "tokens": [50754, 663, 311, 411, 11, 2745, 11, 291, 643, 300, 281, 362, 746, 1481, 13, 50958], "temperature": 0.0, "avg_logprob": -0.14367293452357385, "compression_ratio": 1.60546875, "no_speech_prob": 0.0031716665253043175}, {"id": 363, "seek": 144090, "start": 1452.7800000000002, "end": 1456.98, "text": " And the thing is that because we have all the static analysis tools, it makes sense to", "tokens": [50958, 400, 264, 551, 307, 300, 570, 321, 362, 439, 264, 13437, 5215, 3873, 11, 309, 1669, 2020, 281, 51168], "temperature": 0.0, "avg_logprob": -0.14367293452357385, "compression_ratio": 1.60546875, "no_speech_prob": 0.0031716665253043175}, {"id": 364, "seek": 144090, "start": 1456.98, "end": 1459.18, "text": " use them in Elm package.", "tokens": [51168, 764, 552, 294, 2699, 76, 7372, 13, 51278], "temperature": 0.0, "avg_logprob": -0.14367293452357385, "compression_ratio": 1.60546875, "no_speech_prob": 0.0031716665253043175}, {"id": 365, "seek": 144090, "start": 1459.18, "end": 1466.5800000000002, "text": " So for example, if I say Elm package diff Elm laying core, which is the core library,", "tokens": [51278, 407, 337, 1365, 11, 498, 286, 584, 2699, 76, 7372, 7593, 2699, 76, 14903, 4965, 11, 597, 307, 264, 4965, 6405, 11, 51648], "temperature": 0.0, "avg_logprob": -0.14367293452357385, "compression_ratio": 1.60546875, "no_speech_prob": 0.0031716665253043175}, {"id": 366, "seek": 146658, "start": 1466.58, "end": 1471.6599999999999, "text": " then I'm going to take a recent release with the most recent release.", "tokens": [50364, 550, 286, 478, 516, 281, 747, 257, 5162, 4374, 365, 264, 881, 5162, 4374, 13, 50618], "temperature": 0.0, "avg_logprob": -0.1314410678410934, "compression_ratio": 1.786008230452675, "no_speech_prob": 0.01971149444580078}, {"id": 367, "seek": 146658, "start": 1471.6599999999999, "end": 1476.58, "text": " It's going to tell me all the things that have changed between those two versions.", "tokens": [50618, 467, 311, 516, 281, 980, 385, 439, 264, 721, 300, 362, 3105, 1296, 729, 732, 9606, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1314410678410934, "compression_ratio": 1.786008230452675, "no_speech_prob": 0.01971149444580078}, {"id": 368, "seek": 146658, "start": 1476.58, "end": 1483.4199999999998, "text": " And so I can do it on another package of mine, Elm tools parser.", "tokens": [50864, 400, 370, 286, 393, 360, 309, 322, 1071, 7372, 295, 3892, 11, 2699, 76, 3873, 21156, 260, 13, 51206], "temperature": 0.0, "avg_logprob": -0.1314410678410934, "compression_ratio": 1.786008230452675, "no_speech_prob": 0.01971149444580078}, {"id": 369, "seek": 146658, "start": 1483.4199999999998, "end": 1488.06, "text": " And the first release and the second release, I made a decent amount of changes.", "tokens": [51206, 400, 264, 700, 4374, 293, 264, 1150, 4374, 11, 286, 1027, 257, 8681, 2372, 295, 2962, 13, 51438], "temperature": 0.0, "avg_logprob": -0.1314410678410934, "compression_ratio": 1.786008230452675, "no_speech_prob": 0.01971149444580078}, {"id": 370, "seek": 146658, "start": 1488.06, "end": 1489.96, "text": " So here it can say, hey, this is a major change.", "tokens": [51438, 407, 510, 309, 393, 584, 11, 4177, 11, 341, 307, 257, 2563, 1319, 13, 51533], "temperature": 0.0, "avg_logprob": -0.1314410678410934, "compression_ratio": 1.786008230452675, "no_speech_prob": 0.01971149444580078}, {"id": 371, "seek": 146658, "start": 1489.96, "end": 1490.96, "text": " You added all this stuff.", "tokens": [51533, 509, 3869, 439, 341, 1507, 13, 51583], "temperature": 0.0, "avg_logprob": -0.1314410678410934, "compression_ratio": 1.786008230452675, "no_speech_prob": 0.01971149444580078}, {"id": 372, "seek": 146658, "start": 1490.96, "end": 1492.46, "text": " You removed all this stuff.", "tokens": [51583, 509, 7261, 439, 341, 1507, 13, 51658], "temperature": 0.0, "avg_logprob": -0.1314410678410934, "compression_ratio": 1.786008230452675, "no_speech_prob": 0.01971149444580078}, {"id": 373, "seek": 146658, "start": 1492.46, "end": 1494.06, "text": " Here are the things you changed.", "tokens": [51658, 1692, 366, 264, 721, 291, 3105, 13, 51738], "temperature": 0.0, "avg_logprob": -0.1314410678410934, "compression_ratio": 1.786008230452675, "no_speech_prob": 0.01971149444580078}, {"id": 374, "seek": 149406, "start": 1494.06, "end": 1498.22, "text": " And so for any package in the Elm ecosystem, you can ask this question and see exactly", "tokens": [50364, 400, 370, 337, 604, 7372, 294, 264, 2699, 76, 11311, 11, 291, 393, 1029, 341, 1168, 293, 536, 2293, 50572], "temperature": 0.0, "avg_logprob": -0.10495707608651424, "compression_ratio": 1.7422680412371134, "no_speech_prob": 0.0012061863671988249}, {"id": 375, "seek": 149406, "start": 1498.22, "end": 1499.34, "text": " what changed.", "tokens": [50572, 437, 3105, 13, 50628], "temperature": 0.0, "avg_logprob": -0.10495707608651424, "compression_ratio": 1.7422680412371134, "no_speech_prob": 0.0012061863671988249}, {"id": 376, "seek": 149406, "start": 1499.34, "end": 1503.8999999999999, "text": " And what that means is when someone's publishing, I can say, okay, I looked at your code.", "tokens": [50628, 400, 437, 300, 1355, 307, 562, 1580, 311, 17832, 11, 286, 393, 584, 11, 1392, 11, 286, 2956, 412, 428, 3089, 13, 50856], "temperature": 0.0, "avg_logprob": -0.10495707608651424, "compression_ratio": 1.7422680412371134, "no_speech_prob": 0.0012061863671988249}, {"id": 377, "seek": 149406, "start": 1503.8999999999999, "end": 1505.5, "text": " You have made major changes.", "tokens": [50856, 509, 362, 1027, 2563, 2962, 13, 50936], "temperature": 0.0, "avg_logprob": -0.10495707608651424, "compression_ratio": 1.7422680412371134, "no_speech_prob": 0.0012061863671988249}, {"id": 378, "seek": 149406, "start": 1505.5, "end": 1508.1799999999998, "text": " This is the new version number that you will be using.", "tokens": [50936, 639, 307, 264, 777, 3037, 1230, 300, 291, 486, 312, 1228, 13, 51070], "temperature": 0.0, "avg_logprob": -0.10495707608651424, "compression_ratio": 1.7422680412371134, "no_speech_prob": 0.0012061863671988249}, {"id": 379, "seek": 149406, "start": 1508.1799999999998, "end": 1511.1799999999998, "text": " And so it's not a matter of like, oh, do people get semantic version?", "tokens": [51070, 400, 370, 309, 311, 406, 257, 1871, 295, 411, 11, 1954, 11, 360, 561, 483, 47982, 3037, 30, 51220], "temperature": 0.0, "avg_logprob": -0.10495707608651424, "compression_ratio": 1.7422680412371134, "no_speech_prob": 0.0012061863671988249}, {"id": 380, "seek": 149406, "start": 1511.1799999999998, "end": 1512.1799999999998, "text": " Do they like it or not?", "tokens": [51220, 1144, 436, 411, 309, 420, 406, 30, 51270], "temperature": 0.0, "avg_logprob": -0.10495707608651424, "compression_ratio": 1.7422680412371134, "no_speech_prob": 0.0012061863671988249}, {"id": 381, "seek": 149406, "start": 1512.1799999999998, "end": 1514.62, "text": " It's just like the Elm ecosystem uses semantic versioning.", "tokens": [51270, 467, 311, 445, 411, 264, 2699, 76, 11311, 4960, 47982, 3037, 278, 13, 51392], "temperature": 0.0, "avg_logprob": -0.10495707608651424, "compression_ratio": 1.7422680412371134, "no_speech_prob": 0.0012061863671988249}, {"id": 382, "seek": 149406, "start": 1514.62, "end": 1519.34, "text": " And if you're making a major change, everyone's going to get that major change.", "tokens": [51392, 400, 498, 291, 434, 1455, 257, 2563, 1319, 11, 1518, 311, 516, 281, 483, 300, 2563, 1319, 13, 51628], "temperature": 0.0, "avg_logprob": -0.10495707608651424, "compression_ratio": 1.7422680412371134, "no_speech_prob": 0.0012061863671988249}, {"id": 383, "seek": 151934, "start": 1519.34, "end": 1524.4599999999998, "text": " And so what that means for the whole ecosystem is there's no way to sneak through like, well,", "tokens": [50364, 400, 370, 437, 300, 1355, 337, 264, 1379, 11311, 307, 456, 311, 572, 636, 281, 13164, 807, 411, 11, 731, 11, 50620], "temperature": 0.0, "avg_logprob": -0.1160436938790714, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.0014547213213518262}, {"id": 384, "seek": 151934, "start": 1524.4599999999998, "end": 1528.1799999999998, "text": " I know it'll break people's code, but it doesn't feel important.", "tokens": [50620, 286, 458, 309, 603, 1821, 561, 311, 3089, 11, 457, 309, 1177, 380, 841, 1021, 13, 50806], "temperature": 0.0, "avg_logprob": -0.1160436938790714, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.0014547213213518262}, {"id": 385, "seek": 151934, "start": 1528.1799999999998, "end": 1531.1, "text": " It doesn't feel major.", "tokens": [50806, 467, 1177, 380, 841, 2563, 13, 50952], "temperature": 0.0, "avg_logprob": -0.1160436938790714, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.0014547213213518262}, {"id": 386, "seek": 151934, "start": 1531.1, "end": 1534.5, "text": " And so I think, again, so this is like using the ML style syntax.", "tokens": [50952, 400, 370, 286, 519, 11, 797, 11, 370, 341, 307, 411, 1228, 264, 21601, 3758, 28431, 13, 51122], "temperature": 0.0, "avg_logprob": -0.1160436938790714, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.0014547213213518262}, {"id": 387, "seek": 151934, "start": 1534.5, "end": 1538.78, "text": " I know that this means that Elm will have a smaller ecosystem and the community will", "tokens": [51122, 286, 458, 300, 341, 1355, 300, 2699, 76, 486, 362, 257, 4356, 11311, 293, 264, 1768, 486, 51336], "temperature": 0.0, "avg_logprob": -0.1160436938790714, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.0014547213213518262}, {"id": 388, "seek": 151934, "start": 1538.78, "end": 1540.22, "text": " grow more slowly.", "tokens": [51336, 1852, 544, 5692, 13, 51408], "temperature": 0.0, "avg_logprob": -0.1160436938790714, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.0014547213213518262}, {"id": 389, "seek": 151934, "start": 1540.22, "end": 1544.8999999999999, "text": " But I think it makes sense because of how everything fits together to make that investment", "tokens": [51408, 583, 286, 519, 309, 1669, 2020, 570, 295, 577, 1203, 9001, 1214, 281, 652, 300, 6078, 51642], "temperature": 0.0, "avg_logprob": -0.1160436938790714, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.0014547213213518262}, {"id": 390, "seek": 151934, "start": 1544.8999999999999, "end": 1548.82, "text": " and 10 years down the line, 20 years down the line, it's going to be something really,", "tokens": [51642, 293, 1266, 924, 760, 264, 1622, 11, 945, 924, 760, 264, 1622, 11, 309, 311, 516, 281, 312, 746, 534, 11, 51838], "temperature": 0.0, "avg_logprob": -0.1160436938790714, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.0014547213213518262}, {"id": 391, "seek": 154882, "start": 1548.82, "end": 1555.9399999999998, "text": " really special, even if it wasn't like as big as possible at the very beginning.", "tokens": [50364, 534, 2121, 11, 754, 498, 309, 2067, 380, 411, 382, 955, 382, 1944, 412, 264, 588, 2863, 13, 50720], "temperature": 0.0, "avg_logprob": -0.1064454425464977, "compression_ratio": 1.5970149253731343, "no_speech_prob": 0.0009106030920520425}, {"id": 392, "seek": 154882, "start": 1555.9399999999998, "end": 1561.06, "text": " So yeah, and to come back to the ML style syntax, when all your values are immutable,", "tokens": [50720, 407, 1338, 11, 293, 281, 808, 646, 281, 264, 21601, 3758, 28431, 11, 562, 439, 428, 4190, 366, 3397, 32148, 11, 50976], "temperature": 0.0, "avg_logprob": -0.1064454425464977, "compression_ratio": 1.5970149253731343, "no_speech_prob": 0.0009106030920520425}, {"id": 393, "seek": 154882, "start": 1561.06, "end": 1562.46, "text": " that syntax makes a lot of sense.", "tokens": [50976, 300, 28431, 1669, 257, 688, 295, 2020, 13, 51046], "temperature": 0.0, "avg_logprob": -0.1064454425464977, "compression_ratio": 1.5970149253731343, "no_speech_prob": 0.0009106030920520425}, {"id": 394, "seek": 154882, "start": 1562.46, "end": 1567.74, "text": " So when it fits into the whole picture here, it becomes a coherent whole.", "tokens": [51046, 407, 562, 309, 9001, 666, 264, 1379, 3036, 510, 11, 309, 3643, 257, 36239, 1379, 13, 51310], "temperature": 0.0, "avg_logprob": -0.1064454425464977, "compression_ratio": 1.5970149253731343, "no_speech_prob": 0.0009106030920520425}, {"id": 395, "seek": 154882, "start": 1567.74, "end": 1574.1799999999998, "text": " And so I want to sort of end by saying, not one thing is better than the other, but these", "tokens": [51310, 400, 370, 286, 528, 281, 1333, 295, 917, 538, 1566, 11, 406, 472, 551, 307, 1101, 813, 264, 661, 11, 457, 613, 51632], "temperature": 0.0, "avg_logprob": -0.1064454425464977, "compression_ratio": 1.5970149253731343, "no_speech_prob": 0.0009106030920520425}, {"id": 396, "seek": 154882, "start": 1574.1799999999998, "end": 1578.4199999999998, "text": " features that we arrived at independently seem like good ideas.", "tokens": [51632, 4122, 300, 321, 6678, 412, 21761, 1643, 411, 665, 3487, 13, 51844], "temperature": 0.0, "avg_logprob": -0.1064454425464977, "compression_ratio": 1.5970149253731343, "no_speech_prob": 0.0009106030920520425}, {"id": 397, "seek": 157842, "start": 1578.42, "end": 1580.02, "text": " And there are lots of ways to do it.", "tokens": [50364, 400, 456, 366, 3195, 295, 2098, 281, 360, 309, 13, 50444], "temperature": 0.0, "avg_logprob": -0.11667579650878906, "compression_ratio": 1.8505747126436782, "no_speech_prob": 0.00884079560637474}, {"id": 398, "seek": 157842, "start": 1580.02, "end": 1583.66, "text": " And the thing you want to be thinking about is, how does this fit in with other features?", "tokens": [50444, 400, 264, 551, 291, 528, 281, 312, 1953, 466, 307, 11, 577, 775, 341, 3318, 294, 365, 661, 4122, 30, 50626], "temperature": 0.0, "avg_logprob": -0.11667579650878906, "compression_ratio": 1.8505747126436782, "no_speech_prob": 0.00884079560637474}, {"id": 399, "seek": 157842, "start": 1583.66, "end": 1585.52, "text": " What are the trade-offs that I need to make?", "tokens": [50626, 708, 366, 264, 4923, 12, 19231, 300, 286, 643, 281, 652, 30, 50719], "temperature": 0.0, "avg_logprob": -0.11667579650878906, "compression_ratio": 1.8505747126436782, "no_speech_prob": 0.00884079560637474}, {"id": 400, "seek": 157842, "start": 1585.52, "end": 1586.6200000000001, "text": " What are my constraints?", "tokens": [50719, 708, 366, 452, 18491, 30, 50774], "temperature": 0.0, "avg_logprob": -0.11667579650878906, "compression_ratio": 1.8505747126436782, "no_speech_prob": 0.00884079560637474}, {"id": 401, "seek": 157842, "start": 1586.6200000000001, "end": 1587.6200000000001, "text": " What are my preferences?", "tokens": [50774, 708, 366, 452, 21910, 30, 50824], "temperature": 0.0, "avg_logprob": -0.11667579650878906, "compression_ratio": 1.8505747126436782, "no_speech_prob": 0.00884079560637474}, {"id": 402, "seek": 157842, "start": 1587.6200000000001, "end": 1589.44, "text": " How's that going to work for me?", "tokens": [50824, 1012, 311, 300, 516, 281, 589, 337, 385, 30, 50915], "temperature": 0.0, "avg_logprob": -0.11667579650878906, "compression_ratio": 1.8505747126436782, "no_speech_prob": 0.00884079560637474}, {"id": 403, "seek": 157842, "start": 1589.44, "end": 1593.7, "text": " And if you're interested in Elm at all, you can learn more at the guide, which is trying", "tokens": [50915, 400, 498, 291, 434, 3102, 294, 2699, 76, 412, 439, 11, 291, 393, 1466, 544, 412, 264, 5934, 11, 597, 307, 1382, 51128], "temperature": 0.0, "avg_logprob": -0.11667579650878906, "compression_ratio": 1.8505747126436782, "no_speech_prob": 0.00884079560637474}, {"id": 404, "seek": 157842, "start": 1593.7, "end": 1597.5, "text": " to go through a bunch of these things, or on the subreddit or on Slack.", "tokens": [51128, 281, 352, 807, 257, 3840, 295, 613, 721, 11, 420, 322, 264, 1422, 986, 17975, 420, 322, 37211, 13, 51318], "temperature": 0.0, "avg_logprob": -0.11667579650878906, "compression_ratio": 1.8505747126436782, "no_speech_prob": 0.00884079560637474}, {"id": 405, "seek": 157842, "start": 1597.5, "end": 1600.22, "text": " And people are really friendly and happy to help out.", "tokens": [51318, 400, 561, 366, 534, 9208, 293, 2055, 281, 854, 484, 13, 51454], "temperature": 0.0, "avg_logprob": -0.11667579650878906, "compression_ratio": 1.8505747126436782, "no_speech_prob": 0.00884079560637474}, {"id": 406, "seek": 157842, "start": 1600.22, "end": 1604.18, "text": " And I encourage you, if you're interested, do it with a spirit of kindness and learning,", "tokens": [51454, 400, 286, 5373, 291, 11, 498, 291, 434, 3102, 11, 360, 309, 365, 257, 3797, 295, 18171, 293, 2539, 11, 51652], "temperature": 0.0, "avg_logprob": -0.11667579650878906, "compression_ratio": 1.8505747126436782, "no_speech_prob": 0.00884079560637474}, {"id": 407, "seek": 157842, "start": 1604.18, "end": 1607.6200000000001, "text": " because there are some people who really, really love Elm and they're really happy to", "tokens": [51652, 570, 456, 366, 512, 561, 567, 534, 11, 534, 959, 2699, 76, 293, 436, 434, 534, 2055, 281, 51824], "temperature": 0.0, "avg_logprob": -0.11667579650878906, "compression_ratio": 1.8505747126436782, "no_speech_prob": 0.00884079560637474}, {"id": 408, "seek": 160762, "start": 1607.62, "end": 1608.62, "text": " be helpful.", "tokens": [50364, 312, 4961, 13, 50414], "temperature": 0.0, "avg_logprob": -0.11843101794903095, "compression_ratio": 1.7966101694915255, "no_speech_prob": 0.04951242730021477}, {"id": 409, "seek": 160762, "start": 1608.62, "end": 1609.62, "text": " And I just want...", "tokens": [50414, 400, 286, 445, 528, 485, 50464], "temperature": 0.0, "avg_logprob": -0.11843101794903095, "compression_ratio": 1.7966101694915255, "no_speech_prob": 0.04951242730021477}, {"id": 410, "seek": 160762, "start": 1609.62, "end": 1612.9799999999998, "text": " I like them a lot, and I want them to have fun.", "tokens": [50464, 286, 411, 552, 257, 688, 11, 293, 286, 528, 552, 281, 362, 1019, 13, 50632], "temperature": 0.0, "avg_logprob": -0.11843101794903095, "compression_ratio": 1.7966101694915255, "no_speech_prob": 0.04951242730021477}, {"id": 411, "seek": 160762, "start": 1612.9799999999998, "end": 1616.82, "text": " And so ultimately, my goal with this project is I want to make web programming delightful.", "tokens": [50632, 400, 370, 6284, 11, 452, 3387, 365, 341, 1716, 307, 286, 528, 281, 652, 3670, 9410, 35194, 13, 50824], "temperature": 0.0, "avg_logprob": -0.11843101794903095, "compression_ratio": 1.7966101694915255, "no_speech_prob": 0.04951242730021477}, {"id": 412, "seek": 160762, "start": 1616.82, "end": 1623.2199999999998, "text": " So even if Elm isn't for you, we're trying to do our best, and we'll hopefully get there.", "tokens": [50824, 407, 754, 498, 2699, 76, 1943, 380, 337, 291, 11, 321, 434, 1382, 281, 360, 527, 1151, 11, 293, 321, 603, 4696, 483, 456, 13, 51144], "temperature": 0.0, "avg_logprob": -0.11843101794903095, "compression_ratio": 1.7966101694915255, "no_speech_prob": 0.04951242730021477}, {"id": 413, "seek": 160762, "start": 1623.2199999999998, "end": 1628.1399999999999, "text": " So I hope that spirit is how you come to these.", "tokens": [51144, 407, 286, 1454, 300, 3797, 307, 577, 291, 808, 281, 613, 13, 51390], "temperature": 0.0, "avg_logprob": -0.11843101794903095, "compression_ratio": 1.7966101694915255, "no_speech_prob": 0.04951242730021477}, {"id": 414, "seek": 160762, "start": 1628.1399999999999, "end": 1631.7399999999998, "text": " And so ultimately, if the goal is to make web programming delightful, that will look", "tokens": [51390, 400, 370, 6284, 11, 498, 264, 3387, 307, 281, 652, 3670, 9410, 35194, 11, 300, 486, 574, 51570], "temperature": 0.0, "avg_logprob": -0.11843101794903095, "compression_ratio": 1.7966101694915255, "no_speech_prob": 0.04951242730021477}, {"id": 415, "seek": 160762, "start": 1631.7399999999998, "end": 1632.9799999999998, "text": " different for different people.", "tokens": [51570, 819, 337, 819, 561, 13, 51632], "temperature": 0.0, "avg_logprob": -0.11843101794903095, "compression_ratio": 1.7966101694915255, "no_speech_prob": 0.04951242730021477}, {"id": 416, "seek": 163298, "start": 1632.98, "end": 1638.66, "text": " So if you go check out ClosureScript or Elm or TypeScript or Flow or React or whatever", "tokens": [50364, 407, 498, 291, 352, 1520, 484, 2033, 7641, 14237, 420, 2699, 76, 420, 15576, 14237, 420, 32792, 420, 30644, 420, 2035, 50648], "temperature": 0.0, "avg_logprob": -0.16256806401923152, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.014036621898412704}, {"id": 417, "seek": 163298, "start": 1638.66, "end": 1642.1, "text": " it is, you're going to find a place that works well for you.", "tokens": [50648, 309, 307, 11, 291, 434, 516, 281, 915, 257, 1081, 300, 1985, 731, 337, 291, 13, 50820], "temperature": 0.0, "avg_logprob": -0.16256806401923152, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.014036621898412704}, {"id": 418, "seek": 163298, "start": 1642.1, "end": 1646.38, "text": " And it's not that someone's right, someone's wrong, it's that there are different constellations", "tokens": [50820, 400, 309, 311, 406, 300, 1580, 311, 558, 11, 1580, 311, 2085, 11, 309, 311, 300, 456, 366, 819, 32436, 763, 51034], "temperature": 0.0, "avg_logprob": -0.16256806401923152, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.014036621898412704}, {"id": 419, "seek": 163298, "start": 1646.38, "end": 1650.06, "text": " of features that work together in a particular way.", "tokens": [51034, 295, 4122, 300, 589, 1214, 294, 257, 1729, 636, 13, 51218], "temperature": 0.0, "avg_logprob": -0.16256806401923152, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.014036621898412704}, {"id": 420, "seek": 163298, "start": 1650.06, "end": 1654.5, "text": " And there are certain parts that overlap, and those seem like a good idea.", "tokens": [51218, 400, 456, 366, 1629, 3166, 300, 19959, 11, 293, 729, 1643, 411, 257, 665, 1558, 13, 51440], "temperature": 0.0, "avg_logprob": -0.16256806401923152, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.014036621898412704}, {"id": 421, "seek": 163298, "start": 1654.5, "end": 1655.5, "text": " Thank you.", "tokens": [51440, 1044, 291, 13, 51490], "temperature": 0.0, "avg_logprob": -0.16256806401923152, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.014036621898412704}, {"id": 422, "seek": 165550, "start": 1655.5, "end": 1656.5, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50414], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 423, "seek": 165550, "start": 1656.5, "end": 1657.5, "text": " Thank you.", "tokens": [50414, 1044, 291, 13, 50464], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 424, "seek": 165550, "start": 1657.5, "end": 1658.5, "text": " Thank you.", "tokens": [50464, 1044, 291, 13, 50514], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 425, "seek": 165550, "start": 1658.5, "end": 1659.5, "text": " Thank you.", "tokens": [50514, 1044, 291, 13, 50564], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 426, "seek": 165550, "start": 1659.5, "end": 1660.5, "text": " Thank you.", "tokens": [50564, 1044, 291, 13, 50614], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 427, "seek": 165550, "start": 1660.5, "end": 1661.5, "text": " Thank you.", "tokens": [50614, 1044, 291, 13, 50664], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 428, "seek": 165550, "start": 1661.5, "end": 1662.5, "text": " Thank you.", "tokens": [50664, 1044, 291, 13, 50714], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 429, "seek": 165550, "start": 1662.5, "end": 1663.5, "text": " Thank you.", "tokens": [50714, 1044, 291, 13, 50764], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 430, "seek": 165550, "start": 1663.5, "end": 1664.5, "text": " Thank you.", "tokens": [50764, 1044, 291, 13, 50814], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 431, "seek": 165550, "start": 1664.5, "end": 1665.5, "text": " Thank you.", "tokens": [50814, 1044, 291, 13, 50864], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 432, "seek": 165550, "start": 1665.5, "end": 1666.5, "text": " Thank you.", "tokens": [50864, 1044, 291, 13, 50914], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 433, "seek": 165550, "start": 1666.5, "end": 1667.5, "text": " Thank you.", "tokens": [50914, 1044, 291, 13, 50964], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 434, "seek": 165550, "start": 1667.5, "end": 1668.5, "text": " Thank you.", "tokens": [50964, 1044, 291, 13, 51014], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 435, "seek": 165550, "start": 1668.5, "end": 1669.5, "text": " Thank you.", "tokens": [51014, 1044, 291, 13, 51064], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 436, "seek": 165550, "start": 1669.5, "end": 1670.5, "text": " Thank you.", "tokens": [51064, 1044, 291, 13, 51114], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 437, "seek": 165550, "start": 1670.5, "end": 1671.5, "text": " Thank you.", "tokens": [51114, 1044, 291, 13, 51164], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 438, "seek": 165550, "start": 1671.5, "end": 1672.5, "text": " Thank you.", "tokens": [51164, 1044, 291, 13, 51214], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 439, "seek": 165550, "start": 1672.5, "end": 1673.5, "text": " Thank you.", "tokens": [51214, 1044, 291, 13, 51264], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 440, "seek": 165550, "start": 1673.5, "end": 1674.5, "text": " Thank you.", "tokens": [51264, 1044, 291, 13, 51314], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 441, "seek": 165550, "start": 1674.5, "end": 1675.5, "text": " Thank you.", "tokens": [51314, 1044, 291, 13, 51364], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 442, "seek": 165550, "start": 1675.5, "end": 1676.5, "text": " Thank you.", "tokens": [51364, 1044, 291, 13, 51414], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 443, "seek": 165550, "start": 1676.5, "end": 1677.5, "text": " Thank you.", "tokens": [51414, 1044, 291, 13, 51464], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 444, "seek": 165550, "start": 1677.5, "end": 1678.5, "text": " Thank you.", "tokens": [51464, 1044, 291, 13, 51514], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 445, "seek": 165550, "start": 1678.5, "end": 1679.5, "text": " Thank you.", "tokens": [51514, 1044, 291, 13, 51564], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 446, "seek": 165550, "start": 1679.5, "end": 1680.5, "text": " Thank you.", "tokens": [51564, 1044, 291, 13, 51614], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 447, "seek": 165550, "start": 1680.5, "end": 1681.5, "text": " Thank you.", "tokens": [51614, 1044, 291, 13, 51664], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}, {"id": 448, "seek": 165550, "start": 1681.5, "end": 1682.5, "text": " Thank you.", "tokens": [51664, 1044, 291, 13, 51714], "temperature": 0.0, "avg_logprob": -0.13119680864097427, "compression_ratio": 12.333333333333334, "no_speech_prob": 0.9721698760986328}], "language": "en"}