start	end	text
0	29000	I want to know how the world works.
30000	39000	I scan the hierarchy of being from fundamental physics to physical chemistry, biochemistry, biology, psychology, sociology.
39000	49000	Bottom to top, I see mathematics. And I wonder, is the math really there at the foundations making it all happen?
49000	60000	Or is the math merely our way of describing the data, curve fitting, approximating relationships, or hand waving, making simple models?
60000	72000	This distinction between math as intrinsic and fundamental versus math as extrinsic and descriptive seems especially relevant for probability.
72000	78000	Does probability have a split personality in explicating science?
78000	89000	A potential duality between probability as fundamental to the driving essence and probability as descriptive of the observational data?
89000	99000	It's this potential duality, these two pillars of probability, that I'll call the deep meaning of probability.
99000	103000	What is the deep meaning of probability?
103000	107000	I'm Robert Lawrence Kuhn and Closer to Truth is my journey to find out.
107000	123000	I'm going to follow probability's potential two pillars, pillar one.
123000	132000	Probability as the intrinsic beating heart of quantum physics, also resonating in biology from neural networks to population genetics.
132000	144000	Pillar two, applied probability, predicting the likelihood of future events and its offspring statistics, analyzing the frequency of past events.
144000	154000	But to begin, I get the basics. I go to a mathematician who specializes in probability, Columbia's Ivan Corwin.
155000	163000	Ivan, when I think about probability theory, I'm torn between two different visions of it.
163000	172000	One is as a descriptor of the world. On the other hand, probability is baked into the fundamentals of reality through quantum theory.
172000	178000	Give me your overview of what the field is and how it was founded.
178000	185000	Probability as a field was only really axiomatized in the 30s in the work of Komar Gorov in Russia.
185000	193000	Part of the reason why probability hadn't really lifted off before then was because it was seen as an offense to the gods.
193000	202000	The notion that you would try to predict the outcome of something, that wasn't very favorable because the gods were the ones who were dictating what the outcomes would be.
202000	210000	Now luckily, gambling came into the picture and some people, including Cardano, who was one of the real founders of probability in the 15th century,
210000	214000	he introduced some of the sort of fundamental ideas of probability.
214000	219000	For instance, the idea of enumerating a state space and assigning probabilities to different events.
219000	223000	So if you roll a die, there are six outcomes and you assign probabilities to each of these.
223000	230000	And so people would play games and because they didn't really have the notions of probability, they didn't know how to compute probabilities of outcomes.
230000	238000	So once somebody kind of thought about it and was willing to really enumerate and then assign probabilities, they were able to make a lot of money.
238000	241000	Let me tell you the biggest developments of probability.
241000	248000	So the first was in 1600s, 1630s or so, and it was the law of large numbers.
248000	257000	And this is the result, you've probably heard it, you flip a coin two times, you can have a head-a-head, a head-a-tail, a tail-a-tail, a tail-a-tail.
257000	265000	Not each one's a quarter, but now if you flip it a thousand times or ten thousand times and you look at the number of heads versus the number of tails,
265000	268000	you'll find that the ratio will converge to a half.
268000	276000	Now the fact that that ratio really converged to the sort of expected probabilities is what's called the law of large numbers.
276000	282000	And that result, in the case of fair coin flips, was proved about 300 years ago.
282000	287000	And then it took actually quite a while for people to show that it wasn't just for coin flips,
287000	292000	that there were kind of other types of systems that would describe this sort of scaling limit,
292000	297000	that if you do it a lot, you'll converge to some deterministic limit.
297000	303000	The next level that one goes to in probability, it's what's called the central limit theorem.
303000	310000	And the idea there is if you actually flip a coin a thousand times, you don't get 500 heads and 500 tails.
310000	315000	But you usually get within, say, plus or minus 50.
315000	318000	And where's that plus or minus 50 coming from?
318000	325000	It says that in the scale of the square root of the system size, you will see a bell curve emerge.
325000	329000	You know, you've heard of bell curves, you've heard of Gaussian distribution.
329000	334000	And it's not because it's the answer to how many coin flips you, you know, how many heads do you get in tails.
334000	339000	It's because it comes up all over the place in mathematics and in science.
339000	344000	And the third is came from insurance and it's called large deviation theory.
344000	348000	There are certain situations where you don't care about the average behavior.
348000	351000	You care about aberrant behaviors.
351000	354000	The one in a million who does something sensationally good or sensationally bad.
354000	359000	Or if you're insurance, you care about that one out of a million chance that the building burns down.
359000	367000	And so the challenge there was to understand how do you estimate the probability of extremely unlikely events occurring.
367000	370000	And you might think, you know, who cares about large deviations?
370000	376000	But every time you turn your car on, something needs to happen and you want that thing happens
376000	382000	and the probability of something bad happens is exponentially small compared to the number of times you actually turn the car on.
382000	388000	So this is a little bit of the sort of history of thematically what probability thinks about.
389000	397000	Probability's three foundational themes provide good grounding to discern probability's potential two pillars
397000	401000	and thus to probe probability's deep meaning.
401000	405000	The law of large numbers, which forces convergence.
405000	410000	The central limit theorem, which generates normal distributions.
410000	415000	The large deviation theory, which quantifies rare events.
416000	423000	To seek probability's deep meaning, I'm now prepared to observe probability in the wild,
423000	429000	how probability works in the real world of science, and I go straight to the wildest.
431000	434000	Cosmology, our vast universe.
436000	442000	I seek an astrophysicist who develops statistical tools to analyze cosmological data,
442000	448000	including large-scale galactic structure and the cosmic microwave background.
451000	455000	You have to understand that when you have some data to analyze,
455000	458000	you first start using probability as a tool.
458000	466000	And cosmology is a particular interesting example because there are several types of probability that are involved.
466000	470000	There is the probability that simply describes the measurement's errors.
470000	473000	When you make a measurement, you always make a little bit of a mistake,
473000	477000	but there is a theory of probability that tells you what the mistake you make,
477000	480000	and therefore what's the most likely correct value.
480000	484000	And more measurements you make, the smaller is the error bars,
484000	488000	and in the limit you can arrive to basically zero error if you make infinite measurement.
488000	493000	When we talk about cosmology, we are dealing with a deeper sense of probability,
493000	498000	and here it's one step of abstraction.
498000	503000	It's the probability of the model that describes the universe.
503000	508000	So instead of treating the probability like saying there is a true model,
508000	514000	and then I do the experiment and I check what the probability of the data is,
514000	519000	given the model, I want to invert that, and I want to assign a probability to the model
519000	523000	because I want to know what is the correct model that describes the universe,
523000	527000	and all I have are the observations and not the model.
527000	529000	Right, so give me some examples.
529000	532000	The microwave background is probably the simplest example.
532000	535000	In a measurement of the cosmic microwave background,
535000	541000	the experiment wants to measure the temperature or the polarization of the sky in a particular direction,
541000	543000	which in this picture will become a pixel,
543000	547000	and then in that pixel there will be an error, a measurement error,
547000	549000	that has got to do with the noise that is in your instrument,
549000	551000	and how well you can do that measurement.
551000	555000	But then there is another error associated to that,
555000	562000	because the universe we see is one possible realization of all the possible universes
562000	565000	that your model could have generated,
565000	568000	and maybe other model, other singular model could have generated
568000	572000	that are still consistent with the picture of the universe we have.
572000	578000	And what we want to infer is what is the probability of the model
578000	581000	that has generated this data that we observe.
581000	586000	And we also have to put into account the fact that we see the universe we see,
586000	589000	we don't see all the universe which is much bigger.
589000	593000	So you have to put all that into your error bars
593000	596000	and state what you are saying and what the meaning of it is,
596000	598000	I measure something.
598000	601000	The very interesting things that come in is when you ask,
601000	605000	well, if this is the primary universe, this is the baby universe,
605000	608000	and there are already in homogeneity in there,
608000	610000	who or what put them there?
610000	615000	Yeah, people have very theoretical models about quantum mechanics,
615000	616000	they're so small.
616000	620000	Exactly, but then you will know that in quantum mechanics,
620000	622000	there's probability everywhere.
622000	626000	So we go back to randomness and probability.
626000	631000	So in some sense, we are a product of uncertainty and probability,
631000	635000	because it's the quantum randomness that creates those perturbations
635000	640000	and out of those perturbations, gravity worked on them for some 14 billion years,
640000	643000	and here we are having this interesting discussion.
643000	647000	So in essence, you're talking about three kinds of probability radically,
647000	649000	each one radically different from each other.
649000	653000	Yes, and it's the same theory of probability,
653000	656000	which you can write down with the same kind of equation
656000	658000	and the same kind of machinery
658000	663000	that allows you to describe these three different types of probability,
663000	666000	and they all get rolled up into an error bar
666000	669000	about what we think the universe is made of, say.
672000	676000	Those error bars encoding probabilities
676000	679000	help reveal the composition of the cosmos.
679000	684000	Leysche distinguishes three kinds of probability in cosmology.
684000	689000	The first is how tightly measurements cluster around particular values,
689000	692000	which is a test of confidence in those values.
692000	695000	This is probabilities pillar one.
695000	699000	The second kind of probability is how the measured values
699000	702000	support a given model that claims to describe the universe.
702000	705000	This applies probabilities pillar one.
708000	712000	The third kind of probability is the inherent uncertainty
712000	715000	of quantum mechanics in the very early universe,
715000	720000	and gravity's astonishing amplification of those miniscule fluctuations
720000	723000	to construct, over aeons of time,
723000	727000	the vast galaxies and stars we see today.
727000	730000	This is probabilities pillar two.
733000	738000	But the deep meaning of probability in physics and cosmology is debated.
738000	741000	I speak with the author of Existential Physics,
741000	745000	a physicist who relishes challenging current belief,
745000	748000	Sabine Hasenfelder.
748000	753000	The reason we are not making much progress on the foundations of physics
753000	758000	is that on a really fundamental level, we do not understand probability.
758000	762000	So probability appears prominently, of course, in quantum mechanics,
762000	767000	but it also appears in the discussion about the multiverse,
767000	770000	the question of why are the constants of nature,
770000	773000	these particular constants that we observe,
773000	777000	and also in the argument that the Large Hadron Collider
777000	780000	should have seen new particles besides the Higgs boson,
780000	782000	which has not happened.
782000	785000	The whole issue with quantum mechanics is that the wave function
785000	787000	is not the probability distribution,
787000	792000	but you calculate the probability distribution from the wave function,
792000	796000	and the probability distribution is the only thing that we can observe,
796000	800000	whereas the wave function itself is not observable.
800000	804000	So the problem with the multiverse is that in the multiverse,
804000	807000	you have this infinite number of universes,
807000	809000	which brings up questions of the type,
809000	813000	why do we find ourselves in this particular universe
813000	819000	with these particular values of the constants of nature that we have measured,
819000	824000	and there are some anthropic arguments that you have to take into account here,
824000	829000	that we just cannot live in certain kinds of universes with certain constants,
829000	835000	but once you have that, you still have a distribution over universes
835000	838000	in which we could find ourselves,
838000	843000	and what you then want to argue is that in this multiverse,
843000	850000	we would be likely to find ourselves in something that looks like what we actually see.
850000	855000	The reason you want that is to argue that the multiverse actually explains something.
855000	861000	Now, the problem with that is that if you have an infinite number of universes,
861000	867000	it is very difficult to properly define some notion of probability on that.
867000	872000	So you always end up comparing infinities to infinities,
872000	876000	and that's not a mathematically well-defined procedure.
876000	882000	You have to use additional assumptions to fix that problem.
882000	885000	Then that goes into the next category that you mentioned.
885000	890000	If you look at all the constants that are in the standard model,
890000	895000	then they all look good, they all look reasonably probable,
895000	900000	except for one, which is the mass of the Higgs boson.
901000	906000	Now, physicists were arguing before the Large Hadron Collider turned on
906000	915000	that this particular constant is so improbable that the standard model cannot be the last word.
915000	919000	Instead, there has to be more to particle physics,
919000	924000	which would explain why this constant is what it is.
924000	929000	So the goal is that you amend the standard model
929000	933000	so that this constant eventually turns out to be probable.
933000	936000	This goes under the name naturalness argument,
936000	940000	and these naturalness arguments were the key reason
940000	944000	why so many theoretical physicists believed
944000	951000	that the Large Hadron Collider should see some new physics besides the Higgs boson.
951000	958000	This naturalness argument is also sometimes called an argument from fine-tuning.
958000	965000	It basically says that there are certain cancellations between numbers
965000	968000	that have to work out very, very precisely.
968000	971000	This is a notion of fine-tuning,
971000	978000	but you can also see it as an unnatural coincidence.
978000	982000	So this is where this unnaturalness comes from.
982000	986000	So if you have what looks like fine-tuning on its surface,
986000	989000	you have to search for something else to make it natural,
989000	993000	or you have to have an unnatural explanation for the fine-tuning,
993000	996000	which gives the physicists hives.
996000	999000	Yes, exactly. It's just that on a fundamental level,
999000	1004000	you can very well just accept that this constant is whatever it is.
1004000	1009000	Ultimately, this argument goes back to a specific assumption
1009000	1018000	about the probability distribution parameters in some space which we cannot observe,
1018000	1022000	because the only thing we can observe is our universe,
1022000	1026000	with this particular selection of the constants of nature.
1026000	1032000	So making any kind of assumption about the probability of the constants of nature
1032000	1036000	in a space that we cannot really observe
1036000	1041000	is for what I'm concerned not proper science.
1041000	1048000	To Sabine, probability is a lens through which physics and cosmology can be viewed.
1048000	1053000	I'm intrigued by the naturalness argument.
1053000	1057000	It seems so fine-tuned as to be unnatural,
1057000	1062000	but a natural explanation is required and must be found.
1062000	1067000	But when that natural explanation is a multiverse,
1067000	1071000	Sabine says that is not science.
1071000	1076000	But probability is not limited, of course, to physics and cosmology.
1076000	1082000	Probability pervades science, biology, psychology, sociology, medicine.
1082000	1085000	Everywhere there is data.
1085000	1090000	This burdened data science and complex systems are in class A.
1090000	1094000	Probability is a way of wrapping up things we don't understand,
1094000	1096000	a variability of randomness.
1096000	1101000	The idea of randomness being that if I were to rerun the tape of the world a second time,
1101000	1103000	slightly different things might happen,
1103000	1107000	because maybe I don't know the initial conditions of the system perfectly well.
1107000	1112000	And so as a result, the systems diverge slightly in these two different runs of the simulation, so to speak.
1112000	1117000	And in order to capture sort of the underlying mechanisms that are driving the whole system,
1117000	1120000	I need to be able to capture that variability.
1120000	1126000	And so in practice what we do with probabilistic modeling is we stuff that variability into an error term.
1126000	1131000	And we say that there is a set of deterministic rules that govern the way things work on average,
1131000	1137000	and then there's some randomness that we include to capture the variability that we're not covering with.
1137000	1143000	The size of error bars, how big it is at any point, is a very important descriptor of the system.
1143000	1147000	So if a system is very unpredictable, the error bars will be enormous,
1147000	1153000	because you are not able to capture enough of the underlying mechanisms to explain that variability.
1153000	1158000	So the role of taking these large data sets and trying to boil them down into scientific insights
1158000	1164000	is partly about starting with a model that is very poor, that puts most of the variability into the error term,
1164000	1168000	and then slowly picking apart what are the threads of causality,
1168000	1172000	and then pulling those pieces out of the error model, out of the probabilistic part,
1172000	1175000	so that you can capture that structure more readily.
1175000	1179000	And that leaves all the stuff we don't understand sort of captured by the probability.
1179000	1181000	Looking at the large data sets that we have available today,
1181000	1186000	these probabilistic models that use probability to capture the variation of things,
1186000	1192000	this is the only way that we can extract insight from these data sets about complex systems.
1192000	1197000	Because in complex systems, the ways things can interact with each other can be so complicated.
1197000	1202000	When you're thinking about the behavior of a cell, the genome is incredibly complicated,
1202000	1207000	and the environment has a role, and so in order to get a good model,
1207000	1210000	you have to be able to throw out some of the factors,
1210000	1214000	and doing that means you have to put them into the probability part.
1214000	1221000	I stand humble before the power and ubiquity of probability.
1221000	1225000	I like probability as a way of wrapping up things we don't understand,
1225000	1234000	using this information, these variables we capture to tease out underlying mechanisms driving whole systems.
1234000	1238000	What's the forefront of modern f...
1238000	1243000	I return to probability expert Ivan Corwin.
1243000	1249000	There are kind of two themes that are really coming up a lot in probability research these days.
1249000	1253000	So the first is universality, and the second is integrability.
1253000	1258000	So universality refers to the question, or the phenomena,
1258000	1262000	that despite different microscopic natures of systems,
1262000	1266000	a lot of different systems look the same when you zoom out,
1266000	1270000	or when you look at them over a long period of time in the right scale.
1270000	1275000	And integrability deals with the question of what do they look like?
1275000	1278000	It's just an example of how this works.
1278000	1285000	So universality, so you could imagine an example of particles moving on the line,
1285000	1287000	so your traffic.
1287000	1291000	So you have cars lined up in a row, and they try to move to the right,
1291000	1294000	and they do so after some random amount of time.
1294000	1300000	And so you can ask how many cars will have crossed a given location over a long period of time.
1300000	1303000	You can compute, you know, the average number of cars.
1303000	1305000	That's like a law of large numbers.
1305000	1309000	And then you can ask about the fluctuations around that.
1309000	1314000	And under this particular model, you can show that the fluctuation will grow in scale,
1314000	1317000	like the one-third power of time.
1317000	1321000	Universality holds that it's actually not just kind of within one class,
1321000	1325000	but between classes you have oftentimes the exact same distributions,
1325000	1327000	the exact same statistics arising.
1327000	1331000	So let's take the example of bacterial growth on a petri dish.
1331000	1336000	So you inculcate a little bacterial colony in the middle of a petri dish,
1336000	1339000	and you watch it grow outward, and you look at the boundary.
1339000	1343000	And you see that the boundary is roughly growing spherically or circularly,
1343000	1346000	but there are fluctuations.
1346000	1349000	And you can ask how do the fluctuations grow as a function of time?
1349000	1353000	And you do this on a thousand petri dishes, and you measure over time,
1353000	1359000	and you see that the fluctuations, it's supposed to be also the one-third power of time,
1359000	1362000	or in the sense of the radius, and the exact same distribution
1362000	1365000	that I mentioned in the context of traffic flow.
1365000	1369000	So there's something very universal about this distribution coming up.
1369000	1371000	Okay, let's go on to integrability.
1371000	1375000	Okay, so the first example of integrability is coin flipping.
1375000	1379000	You flip a coin a thousand times, you ask how many heads or tails there are.
1379000	1382000	Now you can enumerate the outcomes, and that's very complicated,
1382000	1385000	or you can use what's called the binomial formula,
1385000	1388000	which tells you that you can write it in terms of factorials.
1388000	1393000	Now once you have a formula, you can start to take asymptotics of factorials.
1393000	1397000	So you go from a microscopic formula, you perform asymptotics,
1397000	1402000	you show that kind of the formula admits large-scale limits,
1402000	1406000	and that gives you this statistic, in this case the bell curve.
1406000	1409000	There turn out to be a certain number of special systems,
1409000	1412000	systems that have some enhanced mathematical structure
1412000	1415000	that allow you to actually compute formulas,
1415000	1418000	albeit a little bit more complicated than factorials,
1418000	1423000	but formulas that don't grow in complexity as the system size grows.
1423000	1427000	This notion of integrability that informs what is universal,
1427000	1431000	and universality gives steam to integrability, it gives it power.
1431000	1434000	A lot of the world is large, and a lot of the world is too complicated
1434000	1438000	to really deterministically understand, so it's effectively random.
1438000	1444000	And the ubiquity of probability is kind of a necessary thing.
1444000	1447000	Probability gives you this sort of dimensional reduction
1447000	1451000	from this very complicated deterministic world
1451000	1457000	to a much more tangible, but random world.
1457000	1459000	So there's a little bit of a cost in that,
1459000	1463000	but you still gain a lot in terms of tractability.
1463000	1468000	To probe the deep meaning of probability,
1468000	1472000	I begin with the profound power of probability,
1472000	1477000	refining data, assessing theories, touching ultimate reality.
1477000	1481000	There are two basic kinds of probability,
1481000	1484000	inherent randomness of quantum systems,
1484000	1488000	a way of describing non-random systems.
1488000	1492000	Probability in cosmology quantifies confidence
1492000	1495000	in measurements, adjudicates competing models,
1495000	1500000	reveals how quantum fluctuations become galactic structures.
1500000	1504000	But perhaps at the foundations of physics,
1504000	1507000	we do not understand probability.
1507000	1509000	Contrarians should be appreciated
1509000	1512000	for keeping us open-minded and humble.
1512000	1515000	Probability is a way of capturing things we do not understand,
1515000	1519000	or as variable, or as random.
1519000	1523000	The deep meaning of probability reflects its duality.
1523000	1528000	The two pillars of probability split personality in science.
1528000	1533000	One, a basic operating principle of deepest quantum physics.
1533000	1537000	Two, an analytical tool that parses past events
1537000	1539000	and predicts future events
1539000	1543000	to discern how things work at deepest levels.
1543000	1547000	To understand the elements that compose our world,
1547000	1552000	and perhaps its ultimate essence, probability is key.
1552000	1559000	So, what's the probability we are closer to truth?
1578000	1582000	Copyright © 2020 All Rights Reserved
1582000	1586000	No part of this recording may be reproduced
1586000	1588000	without any permission.
1588000	1590000	All rights reserved.
1590000	1592000	All rights reserved.
1592000	1595000	All rights reserved.
1607000	1612000	© 2020 All Rights Reserved
