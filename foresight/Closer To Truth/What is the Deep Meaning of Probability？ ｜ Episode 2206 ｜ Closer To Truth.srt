1
00:00:00,000 --> 00:00:29,000
I want to know how the world works.

2
00:00:30,000 --> 00:00:39,000
I scan the hierarchy of being from fundamental physics to physical chemistry, biochemistry, biology, psychology, sociology.

3
00:00:39,000 --> 00:00:49,000
Bottom to top, I see mathematics. And I wonder, is the math really there at the foundations making it all happen?

4
00:00:49,000 --> 00:01:00,000
Or is the math merely our way of describing the data, curve fitting, approximating relationships, or hand waving, making simple models?

5
00:01:00,000 --> 00:01:12,000
This distinction between math as intrinsic and fundamental versus math as extrinsic and descriptive seems especially relevant for probability.

6
00:01:12,000 --> 00:01:18,000
Does probability have a split personality in explicating science?

7
00:01:18,000 --> 00:01:29,000
A potential duality between probability as fundamental to the driving essence and probability as descriptive of the observational data?

8
00:01:29,000 --> 00:01:39,000
It's this potential duality, these two pillars of probability, that I'll call the deep meaning of probability.

9
00:01:39,000 --> 00:01:43,000
What is the deep meaning of probability?

10
00:01:43,000 --> 00:01:47,000
I'm Robert Lawrence Kuhn and Closer to Truth is my journey to find out.

11
00:01:47,000 --> 00:02:03,000
I'm going to follow probability's potential two pillars, pillar one.

12
00:02:03,000 --> 00:02:12,000
Probability as the intrinsic beating heart of quantum physics, also resonating in biology from neural networks to population genetics.

13
00:02:12,000 --> 00:02:24,000
Pillar two, applied probability, predicting the likelihood of future events and its offspring statistics, analyzing the frequency of past events.

14
00:02:24,000 --> 00:02:34,000
But to begin, I get the basics. I go to a mathematician who specializes in probability, Columbia's Ivan Corwin.

15
00:02:35,000 --> 00:02:43,000
Ivan, when I think about probability theory, I'm torn between two different visions of it.

16
00:02:43,000 --> 00:02:52,000
One is as a descriptor of the world. On the other hand, probability is baked into the fundamentals of reality through quantum theory.

17
00:02:52,000 --> 00:02:58,000
Give me your overview of what the field is and how it was founded.

18
00:02:58,000 --> 00:03:05,000
Probability as a field was only really axiomatized in the 30s in the work of Komar Gorov in Russia.

19
00:03:05,000 --> 00:03:13,000
Part of the reason why probability hadn't really lifted off before then was because it was seen as an offense to the gods.

20
00:03:13,000 --> 00:03:22,000
The notion that you would try to predict the outcome of something, that wasn't very favorable because the gods were the ones who were dictating what the outcomes would be.

21
00:03:22,000 --> 00:03:30,000
Now luckily, gambling came into the picture and some people, including Cardano, who was one of the real founders of probability in the 15th century,

22
00:03:30,000 --> 00:03:34,000
he introduced some of the sort of fundamental ideas of probability.

23
00:03:34,000 --> 00:03:39,000
For instance, the idea of enumerating a state space and assigning probabilities to different events.

24
00:03:39,000 --> 00:03:43,000
So if you roll a die, there are six outcomes and you assign probabilities to each of these.

25
00:03:43,000 --> 00:03:50,000
And so people would play games and because they didn't really have the notions of probability, they didn't know how to compute probabilities of outcomes.

26
00:03:50,000 --> 00:03:58,000
So once somebody kind of thought about it and was willing to really enumerate and then assign probabilities, they were able to make a lot of money.

27
00:03:58,000 --> 00:04:01,000
Let me tell you the biggest developments of probability.

28
00:04:01,000 --> 00:04:08,000
So the first was in 1600s, 1630s or so, and it was the law of large numbers.

29
00:04:08,000 --> 00:04:17,000
And this is the result, you've probably heard it, you flip a coin two times, you can have a head-a-head, a head-a-tail, a tail-a-tail, a tail-a-tail.

30
00:04:17,000 --> 00:04:25,000
Not each one's a quarter, but now if you flip it a thousand times or ten thousand times and you look at the number of heads versus the number of tails,

31
00:04:25,000 --> 00:04:28,000
you'll find that the ratio will converge to a half.

32
00:04:28,000 --> 00:04:36,000
Now the fact that that ratio really converged to the sort of expected probabilities is what's called the law of large numbers.

33
00:04:36,000 --> 00:04:42,000
And that result, in the case of fair coin flips, was proved about 300 years ago.

34
00:04:42,000 --> 00:04:47,000
And then it took actually quite a while for people to show that it wasn't just for coin flips,

35
00:04:47,000 --> 00:04:52,000
that there were kind of other types of systems that would describe this sort of scaling limit,

36
00:04:52,000 --> 00:04:57,000
that if you do it a lot, you'll converge to some deterministic limit.

37
00:04:57,000 --> 00:05:03,000
The next level that one goes to in probability, it's what's called the central limit theorem.

38
00:05:03,000 --> 00:05:10,000
And the idea there is if you actually flip a coin a thousand times, you don't get 500 heads and 500 tails.

39
00:05:10,000 --> 00:05:15,000
But you usually get within, say, plus or minus 50.

40
00:05:15,000 --> 00:05:18,000
And where's that plus or minus 50 coming from?

41
00:05:18,000 --> 00:05:25,000
It says that in the scale of the square root of the system size, you will see a bell curve emerge.

42
00:05:25,000 --> 00:05:29,000
You know, you've heard of bell curves, you've heard of Gaussian distribution.

43
00:05:29,000 --> 00:05:34,000
And it's not because it's the answer to how many coin flips you, you know, how many heads do you get in tails.

44
00:05:34,000 --> 00:05:39,000
It's because it comes up all over the place in mathematics and in science.

45
00:05:39,000 --> 00:05:44,000
And the third is came from insurance and it's called large deviation theory.

46
00:05:44,000 --> 00:05:48,000
There are certain situations where you don't care about the average behavior.

47
00:05:48,000 --> 00:05:51,000
You care about aberrant behaviors.

48
00:05:51,000 --> 00:05:54,000
The one in a million who does something sensationally good or sensationally bad.

49
00:05:54,000 --> 00:05:59,000
Or if you're insurance, you care about that one out of a million chance that the building burns down.

50
00:05:59,000 --> 00:06:07,000
And so the challenge there was to understand how do you estimate the probability of extremely unlikely events occurring.

51
00:06:07,000 --> 00:06:10,000
And you might think, you know, who cares about large deviations?

52
00:06:10,000 --> 00:06:16,000
But every time you turn your car on, something needs to happen and you want that thing happens

53
00:06:16,000 --> 00:06:22,000
and the probability of something bad happens is exponentially small compared to the number of times you actually turn the car on.

54
00:06:22,000 --> 00:06:28,000
So this is a little bit of the sort of history of thematically what probability thinks about.

55
00:06:29,000 --> 00:06:37,000
Probability's three foundational themes provide good grounding to discern probability's potential two pillars

56
00:06:37,000 --> 00:06:41,000
and thus to probe probability's deep meaning.

57
00:06:41,000 --> 00:06:45,000
The law of large numbers, which forces convergence.

58
00:06:45,000 --> 00:06:50,000
The central limit theorem, which generates normal distributions.

59
00:06:50,000 --> 00:06:55,000
The large deviation theory, which quantifies rare events.

60
00:06:56,000 --> 00:07:03,000
To seek probability's deep meaning, I'm now prepared to observe probability in the wild,

61
00:07:03,000 --> 00:07:09,000
how probability works in the real world of science, and I go straight to the wildest.

62
00:07:11,000 --> 00:07:14,000
Cosmology, our vast universe.

63
00:07:16,000 --> 00:07:22,000
I seek an astrophysicist who develops statistical tools to analyze cosmological data,

64
00:07:22,000 --> 00:07:28,000
including large-scale galactic structure and the cosmic microwave background.

65
00:07:31,000 --> 00:07:35,000
You have to understand that when you have some data to analyze,

66
00:07:35,000 --> 00:07:38,000
you first start using probability as a tool.

67
00:07:38,000 --> 00:07:46,000
And cosmology is a particular interesting example because there are several types of probability that are involved.

68
00:07:46,000 --> 00:07:50,000
There is the probability that simply describes the measurement's errors.

69
00:07:50,000 --> 00:07:53,000
When you make a measurement, you always make a little bit of a mistake,

70
00:07:53,000 --> 00:07:57,000
but there is a theory of probability that tells you what the mistake you make,

71
00:07:57,000 --> 00:08:00,000
and therefore what's the most likely correct value.

72
00:08:00,000 --> 00:08:04,000
And more measurements you make, the smaller is the error bars,

73
00:08:04,000 --> 00:08:08,000
and in the limit you can arrive to basically zero error if you make infinite measurement.

74
00:08:08,000 --> 00:08:13,000
When we talk about cosmology, we are dealing with a deeper sense of probability,

75
00:08:13,000 --> 00:08:18,000
and here it's one step of abstraction.

76
00:08:18,000 --> 00:08:23,000
It's the probability of the model that describes the universe.

77
00:08:23,000 --> 00:08:28,000
So instead of treating the probability like saying there is a true model,

78
00:08:28,000 --> 00:08:34,000
and then I do the experiment and I check what the probability of the data is,

79
00:08:34,000 --> 00:08:39,000
given the model, I want to invert that, and I want to assign a probability to the model

80
00:08:39,000 --> 00:08:43,000
because I want to know what is the correct model that describes the universe,

81
00:08:43,000 --> 00:08:47,000
and all I have are the observations and not the model.

82
00:08:47,000 --> 00:08:49,000
Right, so give me some examples.

83
00:08:49,000 --> 00:08:52,000
The microwave background is probably the simplest example.

84
00:08:52,000 --> 00:08:55,000
In a measurement of the cosmic microwave background,

85
00:08:55,000 --> 00:09:01,000
the experiment wants to measure the temperature or the polarization of the sky in a particular direction,

86
00:09:01,000 --> 00:09:03,000
which in this picture will become a pixel,

87
00:09:03,000 --> 00:09:07,000
and then in that pixel there will be an error, a measurement error,

88
00:09:07,000 --> 00:09:09,000
that has got to do with the noise that is in your instrument,

89
00:09:09,000 --> 00:09:11,000
and how well you can do that measurement.

90
00:09:11,000 --> 00:09:15,000
But then there is another error associated to that,

91
00:09:15,000 --> 00:09:22,000
because the universe we see is one possible realization of all the possible universes

92
00:09:22,000 --> 00:09:25,000
that your model could have generated,

93
00:09:25,000 --> 00:09:28,000
and maybe other model, other singular model could have generated

94
00:09:28,000 --> 00:09:32,000
that are still consistent with the picture of the universe we have.

95
00:09:32,000 --> 00:09:38,000
And what we want to infer is what is the probability of the model

96
00:09:38,000 --> 00:09:41,000
that has generated this data that we observe.

97
00:09:41,000 --> 00:09:46,000
And we also have to put into account the fact that we see the universe we see,

98
00:09:46,000 --> 00:09:49,000
we don't see all the universe which is much bigger.

99
00:09:49,000 --> 00:09:53,000
So you have to put all that into your error bars

100
00:09:53,000 --> 00:09:56,000
and state what you are saying and what the meaning of it is,

101
00:09:56,000 --> 00:09:58,000
I measure something.

102
00:09:58,000 --> 00:10:01,000
The very interesting things that come in is when you ask,

103
00:10:01,000 --> 00:10:05,000
well, if this is the primary universe, this is the baby universe,

104
00:10:05,000 --> 00:10:08,000
and there are already in homogeneity in there,

105
00:10:08,000 --> 00:10:10,000
who or what put them there?

106
00:10:10,000 --> 00:10:15,000
Yeah, people have very theoretical models about quantum mechanics,

107
00:10:15,000 --> 00:10:16,000
they're so small.

108
00:10:16,000 --> 00:10:20,000
Exactly, but then you will know that in quantum mechanics,

109
00:10:20,000 --> 00:10:22,000
there's probability everywhere.

110
00:10:22,000 --> 00:10:26,000
So we go back to randomness and probability.

111
00:10:26,000 --> 00:10:31,000
So in some sense, we are a product of uncertainty and probability,

112
00:10:31,000 --> 00:10:35,000
because it's the quantum randomness that creates those perturbations

113
00:10:35,000 --> 00:10:40,000
and out of those perturbations, gravity worked on them for some 14 billion years,

114
00:10:40,000 --> 00:10:43,000
and here we are having this interesting discussion.

115
00:10:43,000 --> 00:10:47,000
So in essence, you're talking about three kinds of probability radically,

116
00:10:47,000 --> 00:10:49,000
each one radically different from each other.

117
00:10:49,000 --> 00:10:53,000
Yes, and it's the same theory of probability,

118
00:10:53,000 --> 00:10:56,000
which you can write down with the same kind of equation

119
00:10:56,000 --> 00:10:58,000
and the same kind of machinery

120
00:10:58,000 --> 00:11:03,000
that allows you to describe these three different types of probability,

121
00:11:03,000 --> 00:11:06,000
and they all get rolled up into an error bar

122
00:11:06,000 --> 00:11:09,000
about what we think the universe is made of, say.

123
00:11:12,000 --> 00:11:16,000
Those error bars encoding probabilities

124
00:11:16,000 --> 00:11:19,000
help reveal the composition of the cosmos.

125
00:11:19,000 --> 00:11:24,000
Leysche distinguishes three kinds of probability in cosmology.

126
00:11:24,000 --> 00:11:29,000
The first is how tightly measurements cluster around particular values,

127
00:11:29,000 --> 00:11:32,000
which is a test of confidence in those values.

128
00:11:32,000 --> 00:11:35,000
This is probabilities pillar one.

129
00:11:35,000 --> 00:11:39,000
The second kind of probability is how the measured values

130
00:11:39,000 --> 00:11:42,000
support a given model that claims to describe the universe.

131
00:11:42,000 --> 00:11:45,000
This applies probabilities pillar one.

132
00:11:48,000 --> 00:11:52,000
The third kind of probability is the inherent uncertainty

133
00:11:52,000 --> 00:11:55,000
of quantum mechanics in the very early universe,

134
00:11:55,000 --> 00:12:00,000
and gravity's astonishing amplification of those miniscule fluctuations

135
00:12:00,000 --> 00:12:03,000
to construct, over aeons of time,

136
00:12:03,000 --> 00:12:07,000
the vast galaxies and stars we see today.

137
00:12:07,000 --> 00:12:10,000
This is probabilities pillar two.

138
00:12:13,000 --> 00:12:18,000
But the deep meaning of probability in physics and cosmology is debated.

139
00:12:18,000 --> 00:12:21,000
I speak with the author of Existential Physics,

140
00:12:21,000 --> 00:12:25,000
a physicist who relishes challenging current belief,

141
00:12:25,000 --> 00:12:28,000
Sabine Hasenfelder.

142
00:12:28,000 --> 00:12:33,000
The reason we are not making much progress on the foundations of physics

143
00:12:33,000 --> 00:12:38,000
is that on a really fundamental level, we do not understand probability.

144
00:12:38,000 --> 00:12:42,000
So probability appears prominently, of course, in quantum mechanics,

145
00:12:42,000 --> 00:12:47,000
but it also appears in the discussion about the multiverse,

146
00:12:47,000 --> 00:12:50,000
the question of why are the constants of nature,

147
00:12:50,000 --> 00:12:53,000
these particular constants that we observe,

148
00:12:53,000 --> 00:12:57,000
and also in the argument that the Large Hadron Collider

149
00:12:57,000 --> 00:13:00,000
should have seen new particles besides the Higgs boson,

150
00:13:00,000 --> 00:13:02,000
which has not happened.

151
00:13:02,000 --> 00:13:05,000
The whole issue with quantum mechanics is that the wave function

152
00:13:05,000 --> 00:13:07,000
is not the probability distribution,

153
00:13:07,000 --> 00:13:12,000
but you calculate the probability distribution from the wave function,

154
00:13:12,000 --> 00:13:16,000
and the probability distribution is the only thing that we can observe,

155
00:13:16,000 --> 00:13:20,000
whereas the wave function itself is not observable.

156
00:13:20,000 --> 00:13:24,000
So the problem with the multiverse is that in the multiverse,

157
00:13:24,000 --> 00:13:27,000
you have this infinite number of universes,

158
00:13:27,000 --> 00:13:29,000
which brings up questions of the type,

159
00:13:29,000 --> 00:13:33,000
why do we find ourselves in this particular universe

160
00:13:33,000 --> 00:13:39,000
with these particular values of the constants of nature that we have measured,

161
00:13:39,000 --> 00:13:44,000
and there are some anthropic arguments that you have to take into account here,

162
00:13:44,000 --> 00:13:49,000
that we just cannot live in certain kinds of universes with certain constants,

163
00:13:49,000 --> 00:13:55,000
but once you have that, you still have a distribution over universes

164
00:13:55,000 --> 00:13:58,000
in which we could find ourselves,

165
00:13:58,000 --> 00:14:03,000
and what you then want to argue is that in this multiverse,

166
00:14:03,000 --> 00:14:10,000
we would be likely to find ourselves in something that looks like what we actually see.

167
00:14:10,000 --> 00:14:15,000
The reason you want that is to argue that the multiverse actually explains something.

168
00:14:15,000 --> 00:14:21,000
Now, the problem with that is that if you have an infinite number of universes,

169
00:14:21,000 --> 00:14:27,000
it is very difficult to properly define some notion of probability on that.

170
00:14:27,000 --> 00:14:32,000
So you always end up comparing infinities to infinities,

171
00:14:32,000 --> 00:14:36,000
and that's not a mathematically well-defined procedure.

172
00:14:36,000 --> 00:14:42,000
You have to use additional assumptions to fix that problem.

173
00:14:42,000 --> 00:14:45,000
Then that goes into the next category that you mentioned.

174
00:14:45,000 --> 00:14:50,000
If you look at all the constants that are in the standard model,

175
00:14:50,000 --> 00:14:55,000
then they all look good, they all look reasonably probable,

176
00:14:55,000 --> 00:15:00,000
except for one, which is the mass of the Higgs boson.

177
00:15:01,000 --> 00:15:06,000
Now, physicists were arguing before the Large Hadron Collider turned on

178
00:15:06,000 --> 00:15:15,000
that this particular constant is so improbable that the standard model cannot be the last word.

179
00:15:15,000 --> 00:15:19,000
Instead, there has to be more to particle physics,

180
00:15:19,000 --> 00:15:24,000
which would explain why this constant is what it is.

181
00:15:24,000 --> 00:15:29,000
So the goal is that you amend the standard model

182
00:15:29,000 --> 00:15:33,000
so that this constant eventually turns out to be probable.

183
00:15:33,000 --> 00:15:36,000
This goes under the name naturalness argument,

184
00:15:36,000 --> 00:15:40,000
and these naturalness arguments were the key reason

185
00:15:40,000 --> 00:15:44,000
why so many theoretical physicists believed

186
00:15:44,000 --> 00:15:51,000
that the Large Hadron Collider should see some new physics besides the Higgs boson.

187
00:15:51,000 --> 00:15:58,000
This naturalness argument is also sometimes called an argument from fine-tuning.

188
00:15:58,000 --> 00:16:05,000
It basically says that there are certain cancellations between numbers

189
00:16:05,000 --> 00:16:08,000
that have to work out very, very precisely.

190
00:16:08,000 --> 00:16:11,000
This is a notion of fine-tuning,

191
00:16:11,000 --> 00:16:18,000
but you can also see it as an unnatural coincidence.

192
00:16:18,000 --> 00:16:22,000
So this is where this unnaturalness comes from.

193
00:16:22,000 --> 00:16:26,000
So if you have what looks like fine-tuning on its surface,

194
00:16:26,000 --> 00:16:29,000
you have to search for something else to make it natural,

195
00:16:29,000 --> 00:16:33,000
or you have to have an unnatural explanation for the fine-tuning,

196
00:16:33,000 --> 00:16:36,000
which gives the physicists hives.

197
00:16:36,000 --> 00:16:39,000
Yes, exactly. It's just that on a fundamental level,

198
00:16:39,000 --> 00:16:44,000
you can very well just accept that this constant is whatever it is.

199
00:16:44,000 --> 00:16:49,000
Ultimately, this argument goes back to a specific assumption

200
00:16:49,000 --> 00:16:58,000
about the probability distribution parameters in some space which we cannot observe,

201
00:16:58,000 --> 00:17:02,000
because the only thing we can observe is our universe,

202
00:17:02,000 --> 00:17:06,000
with this particular selection of the constants of nature.

203
00:17:06,000 --> 00:17:12,000
So making any kind of assumption about the probability of the constants of nature

204
00:17:12,000 --> 00:17:16,000
in a space that we cannot really observe

205
00:17:16,000 --> 00:17:21,000
is for what I'm concerned not proper science.

206
00:17:21,000 --> 00:17:28,000
To Sabine, probability is a lens through which physics and cosmology can be viewed.

207
00:17:28,000 --> 00:17:33,000
I'm intrigued by the naturalness argument.

208
00:17:33,000 --> 00:17:37,000
It seems so fine-tuned as to be unnatural,

209
00:17:37,000 --> 00:17:42,000
but a natural explanation is required and must be found.

210
00:17:42,000 --> 00:17:47,000
But when that natural explanation is a multiverse,

211
00:17:47,000 --> 00:17:51,000
Sabine says that is not science.

212
00:17:51,000 --> 00:17:56,000
But probability is not limited, of course, to physics and cosmology.

213
00:17:56,000 --> 00:18:02,000
Probability pervades science, biology, psychology, sociology, medicine.

214
00:18:02,000 --> 00:18:05,000
Everywhere there is data.

215
00:18:05,000 --> 00:18:10,000
This burdened data science and complex systems are in class A.

216
00:18:10,000 --> 00:18:14,000
Probability is a way of wrapping up things we don't understand,

217
00:18:14,000 --> 00:18:16,000
a variability of randomness.

218
00:18:16,000 --> 00:18:21,000
The idea of randomness being that if I were to rerun the tape of the world a second time,

219
00:18:21,000 --> 00:18:23,000
slightly different things might happen,

220
00:18:23,000 --> 00:18:27,000
because maybe I don't know the initial conditions of the system perfectly well.

221
00:18:27,000 --> 00:18:32,000
And so as a result, the systems diverge slightly in these two different runs of the simulation, so to speak.

222
00:18:32,000 --> 00:18:37,000
And in order to capture sort of the underlying mechanisms that are driving the whole system,

223
00:18:37,000 --> 00:18:40,000
I need to be able to capture that variability.

224
00:18:40,000 --> 00:18:46,000
And so in practice what we do with probabilistic modeling is we stuff that variability into an error term.

225
00:18:46,000 --> 00:18:51,000
And we say that there is a set of deterministic rules that govern the way things work on average,

226
00:18:51,000 --> 00:18:57,000
and then there's some randomness that we include to capture the variability that we're not covering with.

227
00:18:57,000 --> 00:19:03,000
The size of error bars, how big it is at any point, is a very important descriptor of the system.

228
00:19:03,000 --> 00:19:07,000
So if a system is very unpredictable, the error bars will be enormous,

229
00:19:07,000 --> 00:19:13,000
because you are not able to capture enough of the underlying mechanisms to explain that variability.

230
00:19:13,000 --> 00:19:18,000
So the role of taking these large data sets and trying to boil them down into scientific insights

231
00:19:18,000 --> 00:19:24,000
is partly about starting with a model that is very poor, that puts most of the variability into the error term,

232
00:19:24,000 --> 00:19:28,000
and then slowly picking apart what are the threads of causality,

233
00:19:28,000 --> 00:19:32,000
and then pulling those pieces out of the error model, out of the probabilistic part,

234
00:19:32,000 --> 00:19:35,000
so that you can capture that structure more readily.

235
00:19:35,000 --> 00:19:39,000
And that leaves all the stuff we don't understand sort of captured by the probability.

236
00:19:39,000 --> 00:19:41,000
Looking at the large data sets that we have available today,

237
00:19:41,000 --> 00:19:46,000
these probabilistic models that use probability to capture the variation of things,

238
00:19:46,000 --> 00:19:52,000
this is the only way that we can extract insight from these data sets about complex systems.

239
00:19:52,000 --> 00:19:57,000
Because in complex systems, the ways things can interact with each other can be so complicated.

240
00:19:57,000 --> 00:20:02,000
When you're thinking about the behavior of a cell, the genome is incredibly complicated,

241
00:20:02,000 --> 00:20:07,000
and the environment has a role, and so in order to get a good model,

242
00:20:07,000 --> 00:20:10,000
you have to be able to throw out some of the factors,

243
00:20:10,000 --> 00:20:14,000
and doing that means you have to put them into the probability part.

244
00:20:14,000 --> 00:20:21,000
I stand humble before the power and ubiquity of probability.

245
00:20:21,000 --> 00:20:25,000
I like probability as a way of wrapping up things we don't understand,

246
00:20:25,000 --> 00:20:34,000
using this information, these variables we capture to tease out underlying mechanisms driving whole systems.

247
00:20:34,000 --> 00:20:38,000
What's the forefront of modern f...

248
00:20:38,000 --> 00:20:43,000
I return to probability expert Ivan Corwin.

249
00:20:43,000 --> 00:20:49,000
There are kind of two themes that are really coming up a lot in probability research these days.

250
00:20:49,000 --> 00:20:53,000
So the first is universality, and the second is integrability.

251
00:20:53,000 --> 00:20:58,000
So universality refers to the question, or the phenomena,

252
00:20:58,000 --> 00:21:02,000
that despite different microscopic natures of systems,

253
00:21:02,000 --> 00:21:06,000
a lot of different systems look the same when you zoom out,

254
00:21:06,000 --> 00:21:10,000
or when you look at them over a long period of time in the right scale.

255
00:21:10,000 --> 00:21:15,000
And integrability deals with the question of what do they look like?

256
00:21:15,000 --> 00:21:18,000
It's just an example of how this works.

257
00:21:18,000 --> 00:21:25,000
So universality, so you could imagine an example of particles moving on the line,

258
00:21:25,000 --> 00:21:27,000
so your traffic.

259
00:21:27,000 --> 00:21:31,000
So you have cars lined up in a row, and they try to move to the right,

260
00:21:31,000 --> 00:21:34,000
and they do so after some random amount of time.

261
00:21:34,000 --> 00:21:40,000
And so you can ask how many cars will have crossed a given location over a long period of time.

262
00:21:40,000 --> 00:21:43,000
You can compute, you know, the average number of cars.

263
00:21:43,000 --> 00:21:45,000
That's like a law of large numbers.

264
00:21:45,000 --> 00:21:49,000
And then you can ask about the fluctuations around that.

265
00:21:49,000 --> 00:21:54,000
And under this particular model, you can show that the fluctuation will grow in scale,

266
00:21:54,000 --> 00:21:57,000
like the one-third power of time.

267
00:21:57,000 --> 00:22:01,000
Universality holds that it's actually not just kind of within one class,

268
00:22:01,000 --> 00:22:05,000
but between classes you have oftentimes the exact same distributions,

269
00:22:05,000 --> 00:22:07,000
the exact same statistics arising.

270
00:22:07,000 --> 00:22:11,000
So let's take the example of bacterial growth on a petri dish.

271
00:22:11,000 --> 00:22:16,000
So you inculcate a little bacterial colony in the middle of a petri dish,

272
00:22:16,000 --> 00:22:19,000
and you watch it grow outward, and you look at the boundary.

273
00:22:19,000 --> 00:22:23,000
And you see that the boundary is roughly growing spherically or circularly,

274
00:22:23,000 --> 00:22:26,000
but there are fluctuations.

275
00:22:26,000 --> 00:22:29,000
And you can ask how do the fluctuations grow as a function of time?

276
00:22:29,000 --> 00:22:33,000
And you do this on a thousand petri dishes, and you measure over time,

277
00:22:33,000 --> 00:22:39,000
and you see that the fluctuations, it's supposed to be also the one-third power of time,

278
00:22:39,000 --> 00:22:42,000
or in the sense of the radius, and the exact same distribution

279
00:22:42,000 --> 00:22:45,000
that I mentioned in the context of traffic flow.

280
00:22:45,000 --> 00:22:49,000
So there's something very universal about this distribution coming up.

281
00:22:49,000 --> 00:22:51,000
Okay, let's go on to integrability.

282
00:22:51,000 --> 00:22:55,000
Okay, so the first example of integrability is coin flipping.

283
00:22:55,000 --> 00:22:59,000
You flip a coin a thousand times, you ask how many heads or tails there are.

284
00:22:59,000 --> 00:23:02,000
Now you can enumerate the outcomes, and that's very complicated,

285
00:23:02,000 --> 00:23:05,000
or you can use what's called the binomial formula,

286
00:23:05,000 --> 00:23:08,000
which tells you that you can write it in terms of factorials.

287
00:23:08,000 --> 00:23:13,000
Now once you have a formula, you can start to take asymptotics of factorials.

288
00:23:13,000 --> 00:23:17,000
So you go from a microscopic formula, you perform asymptotics,

289
00:23:17,000 --> 00:23:22,000
you show that kind of the formula admits large-scale limits,

290
00:23:22,000 --> 00:23:26,000
and that gives you this statistic, in this case the bell curve.

291
00:23:26,000 --> 00:23:29,000
There turn out to be a certain number of special systems,

292
00:23:29,000 --> 00:23:32,000
systems that have some enhanced mathematical structure

293
00:23:32,000 --> 00:23:35,000
that allow you to actually compute formulas,

294
00:23:35,000 --> 00:23:38,000
albeit a little bit more complicated than factorials,

295
00:23:38,000 --> 00:23:43,000
but formulas that don't grow in complexity as the system size grows.

296
00:23:43,000 --> 00:23:47,000
This notion of integrability that informs what is universal,

297
00:23:47,000 --> 00:23:51,000
and universality gives steam to integrability, it gives it power.

298
00:23:51,000 --> 00:23:54,000
A lot of the world is large, and a lot of the world is too complicated

299
00:23:54,000 --> 00:23:58,000
to really deterministically understand, so it's effectively random.

300
00:23:58,000 --> 00:24:04,000
And the ubiquity of probability is kind of a necessary thing.

301
00:24:04,000 --> 00:24:07,000
Probability gives you this sort of dimensional reduction

302
00:24:07,000 --> 00:24:11,000
from this very complicated deterministic world

303
00:24:11,000 --> 00:24:17,000
to a much more tangible, but random world.

304
00:24:17,000 --> 00:24:19,000
So there's a little bit of a cost in that,

305
00:24:19,000 --> 00:24:23,000
but you still gain a lot in terms of tractability.

306
00:24:23,000 --> 00:24:28,000
To probe the deep meaning of probability,

307
00:24:28,000 --> 00:24:32,000
I begin with the profound power of probability,

308
00:24:32,000 --> 00:24:37,000
refining data, assessing theories, touching ultimate reality.

309
00:24:37,000 --> 00:24:41,000
There are two basic kinds of probability,

310
00:24:41,000 --> 00:24:44,000
inherent randomness of quantum systems,

311
00:24:44,000 --> 00:24:48,000
a way of describing non-random systems.

312
00:24:48,000 --> 00:24:52,000
Probability in cosmology quantifies confidence

313
00:24:52,000 --> 00:24:55,000
in measurements, adjudicates competing models,

314
00:24:55,000 --> 00:25:00,000
reveals how quantum fluctuations become galactic structures.

315
00:25:00,000 --> 00:25:04,000
But perhaps at the foundations of physics,

316
00:25:04,000 --> 00:25:07,000
we do not understand probability.

317
00:25:07,000 --> 00:25:09,000
Contrarians should be appreciated

318
00:25:09,000 --> 00:25:12,000
for keeping us open-minded and humble.

319
00:25:12,000 --> 00:25:15,000
Probability is a way of capturing things we do not understand,

320
00:25:15,000 --> 00:25:19,000
or as variable, or as random.

321
00:25:19,000 --> 00:25:23,000
The deep meaning of probability reflects its duality.

322
00:25:23,000 --> 00:25:28,000
The two pillars of probability split personality in science.

323
00:25:28,000 --> 00:25:33,000
One, a basic operating principle of deepest quantum physics.

324
00:25:33,000 --> 00:25:37,000
Two, an analytical tool that parses past events

325
00:25:37,000 --> 00:25:39,000
and predicts future events

326
00:25:39,000 --> 00:25:43,000
to discern how things work at deepest levels.

327
00:25:43,000 --> 00:25:47,000
To understand the elements that compose our world,

328
00:25:47,000 --> 00:25:52,000
and perhaps its ultimate essence, probability is key.

329
00:25:52,000 --> 00:25:59,000
So, what's the probability we are closer to truth?

330
00:26:18,000 --> 00:26:22,000
Copyright © 2020 All Rights Reserved

331
00:26:22,000 --> 00:26:26,000
No part of this recording may be reproduced

332
00:26:26,000 --> 00:26:28,000
without any permission.

333
00:26:28,000 --> 00:26:30,000
All rights reserved.

334
00:26:30,000 --> 00:26:32,000
All rights reserved.

335
00:26:32,000 --> 00:26:35,000
All rights reserved.

336
00:26:47,000 --> 00:26:52,000
© 2020 All Rights Reserved

