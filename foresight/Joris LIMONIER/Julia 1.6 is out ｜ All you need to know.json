{"text": " Hi everyone and welcome back to Datafile. Today I'm very excited. We're gonna go through the highlights of Julia 1.6 and basically what's new in the version and how it's gonna improve our life as Julia developers. So let's check it out. Okay so let's move to the Julia website here. I'm gonna make this link available in the description so you can check it out. And this is the blog. This is Julia's blog. This is Julia's website. And you can see over here they so if I go to the blog list they have a couple blogs dating back from a while ago. This is the latest one as of today. And here are all of the new things which are brought to life in Julia 1.6. So Julia 1.6 might be the new long-term stable which is kind of a big deal. Meaning that this is the one we may be using for a while. It's not just some version that they're gonna throw away very soon. Okay so let's dive into the new features. You can read the whole thing if you're interested. I'm gonna leave the link in the description. Here they mentioned that they're not sure whether 1.6 or 1.7 is gonna be the new LTS. Okay well basically so just an overall view on Julia 1.6. What they improve the most is speed, speed, speed. And this is great especially for a first time run because we had this problem as I mentioned in previous videos that the first time you run a cell in Julia it's gonna take a while and they did their best to reduce it as much as possible. Obviously they're going to do more changes in order to make it even better but as of today there is quite a substantial difference with before this version already. Okay so parallel pre-compilation so that the whole idea of these things is that you're trying to import the packages as fast as possible because I believe differential equation is a pretty heavy package but I haven't used it myself so I can't say for sure. But basically packages which take quite some time are a problem and obviously Julia team want to reduce that time. So here what they also included this thing this new animation and we're gonna see it here. I'm gonna I'm gonna show you that video so you can see what's going on. So you see they're adding this images package and here you have the progress as you're downloading the package which is great. It's nice to see that everything is going fine and as expected. And yeah this I experienced myself when I installed Julia 1.6 you can you see the dependencies coming in and coming out and it's really nice not to just have that black box. Python for instance if you install things from Jupyter notebook with the pip install you get just a black box. You know that the cell is running hopefully it's installing but you're not sure even though you don't get an error sometimes things might happen. So it's just yeah it's really nice to get to get this animation and you see here they're using images and it loaded pretty quick and now they have access to this package. So that's great I'm all for it I'm very happy about that it's a nice cool feature obviously it's not gonna revolutionize coding but it's just a nice feature to know what's going on. Compile time percentage so here that's maybe not as important I would say they include the compilation time when you talk about the runtime so they use this time and time verbose things to measure the time that running code takes. Eliminating needless to compilation which is great basically you use some code and then you reuse the same code later and depending on when you use that code in the past Julia is gonna sometimes throw it away too much and you shouldn't throw it away as much as it does and they're trying to fix that here. They're trying to make it so that if you use code and you still need it at some point in the future Julia is not throwing it away so it's gonna be able to reuse it to gain some speed in the future in the future runs of codes for instance in Jupyter Notebooks if you have many cells and you want to run third cell but the first cell has some codes which you still need instead of Julia having to recompile and redo the run of the first cell under the hood it's gonna be way faster and it's gonna keep those codes in memory or it's gonna be able to reuse them. Compile a latency reduction so all of these are kind of achieving the same purpose I'm just gonna go quickly through those tooling to help optimize packages for latency so you see this one word which comes all the time it's latency and it's obviously related to speed loading speed ups binary loading speed ups so they understood the problem they understood that they have this community of developers and these people are used to Python they're used to all the languages or maybe they're just starting on the language but they don't want to take too much time to run their code and they just want to have things being done quick because in Python and in R and in all the languages that's how it happens so they don't want to spend one minute importing a package if Python can do it in five seconds obviously so if Julia wants to compete it's gonna have to do that and I'm very happy that they put the accent on this because the first run time being huge I mean personally I'm taking the hit because I'm all for Julia and I love language no matter what but I can understand that someone who's a new comer to the language would not be happy with with waiting one minute for the first run to happen that's if you have Python doing it in five seconds it's not acceptable anyway this is a this is a nice graph I think they're measuring whatever GTK3 whatever I don't personally know this I guess the package anyway what's important is so these are the versions version 1.3 1.4 1.5 1.6 and they're measuring the time that this this thing whatever it is takes and you can obviously see that things are going down so initially we had the blue curve with those old wrappers and they included some new wrappers which I may have missed it's part of the binary loading speed-ups I guess and they included some new JLL wrappers whatever they are anyway bottom line for for anyone using Julia and who doesn't know those things under the hood is that speed is going up so time time taken is going down and it's going down it's going down really significantly like we used to have six or seven seconds to load that package just like a couple like three versions ago and as of today it's it's almost instantaneous so this is insane I'm very happy that they made those changes and I don't personally understand all the things happening under the hood but whatever it is if if you can reduce the time taken by whatever it is like 30 30x well I am all for it so I don't know how they do that I I'm not familiar with the computer science technical things going on in the Julia repos but I'm very happy about that and I wanted to report to you so that you have an idea of of how fast things are changing because they they are talking I'm gonna maybe I'm gonna show you later but they're talking about the next version being in a month so I don't know if they had that timeline as well for the previous versions but if that's the case it's gonna it's absolutely workers yeah downloads and networking options by Stefan Karpinski by the way there's a bit of drama going on on Reddit I don't know if you if you saw that but it's on the on the subreddit of Julia there's a little bit of drama with like some guy insulting Stefan Karpinski and and yeah the whole community crushing this guy so I'm very happy about the community as well on the subreddit of Julia if you haven't seen that you should check it out it's it's a beautiful community people are helping each other it's a small community it's it's kind of the birth of Julia still even though the language wasn't created yesterday but it's still pretty new and and the community is small and still beautiful I hope we're gonna be able to keep it that way anyway that was a side story but yeah you can see that you can tell that they really understand the the problems it's loads and consistent it's inflexible they I think they're really listening to their community and you can also show that because they report github issues so github issues I don't know if you're familiar with that but basically you have people going on the Julia repository and saying okay I have this problem I would like to I would like this bug to be fixed or they could say okay I have this idea of new feature could you guys do that is it possible and basically you have the the actual people who work on the Julia project who who try to change those things which people are not happy with that's one possibility another possibility is that someone says okay I have this issue could anyone fix it and it can also be anyone from the community from the Julia community which I talked about before and just someone coming and saying hey I've got this bug this this fix I think it's it fix your bug and you ask it to be included in the new code and and so that it fixes this bug for everyone not just not just you on your machine who managed to fix it so this is the whole idea of open source it's a very beautiful thing if you're not familiar with it you can it's be careful it's addictive you just start with it and and after a while you anything not open source you start having bad thoughts about it because it's the whole idea of free and open sorry free and open source software is is really beautiful anyway talking about that they have this CI robustness so it's actually pretty related to that so basically they they had the tests so anytime someone makes this kind of changes on the code so they say I've got this code it fixes whatever they have to make it run through a couple tests to make sure that it's not breaking the whole system because you don't want to fix one bug and then break everything else right so that's what they had that's the problem they had so CI stands for continuous integration you can see here and basically they had a couple tests to make sure that everything was working fine with the new code which was included in and and some of these tests if I understood correctly some of these sets always failed so now they if I understood correctly they're trying to change the tests or make it so that the code can the review of the code in order to include it in the in the whole Julia code this review is going to be made if not easier at least at least better that's going to improve those things so yeah obviously if we can have better review of code it means we can have people including more code which maybe was not classified properly before so maybe they were saying nope sorry the code doesn't pass this this test and it should have passed the test and be included all the other way around so overall good testing is also part of the of the developing process and only with good testing can you can you have efficient contributions from the community what else we got improved stack trace of formatting so yeah this is this is ugly right I mean you don't really know what's going on I mean it's it's kind of the code you see in your in your shell in your terminal but it doesn't I mean to me you wouldn't mean much and this is the new trace so you can see here all stack trace and this is the new stack trace and I mean it's just way clearer right it's so much more beautiful for me as someone outside of this like computer science community because I'm a mathematician this is way cleaner up this I can start wondering what's going on and look into my errors and try to to fix those errors before that it was it's not as clear I mean if you've got this you're not you're not gonna dive into it right I mean personally it doesn't make me want to dive into that it's it's it's not clear it's kind of a mess and yeah this is this is way easier to dive in hopefully they I don't know if this new version of Julia is gonna improve that but hopefully they're gonna improve the errors they throw because sometimes I'm gonna say they're not great you have errors and it's just telling you this not working and and you don't really know what to fix and hopefully they're gonna change up because because it's really hard to debug your code if you don't have the proper errors being thrown so hopefully this fixes this issue as well I don't know if it goes that deep or I hope it's not just the the formatting and the prettiness of the the error thrown but yeah we shall see only only after coding only after testing out the code you can you can decide whether you think that the errors are good or bad and if they actually give you information about what the error is okay yeah so yeah it seems it seems like they're actually doing that are gonna things are in methods are now shown which is great if you don't even know which method your has an error that's impossible to debug the function name was made to be more emphasized yes yes so this is probably just some formatting things which is great obviously it's helping you through your developing process and and through your coding in general so that's that's awesome the modules were the modules where the method is defined is now shown that's great just basically just give me more information that's all I want and anything going in that direction like those things which seem to be that I'm all for it I'm all for it and please enjoy the release that's probably the most important phrase right so and yeah let us know so they're very open to to new ideas and and just people contributing and telling them what's going on and what's not working so without we're gonna we're gonna bring the video to a close thank you for for for watching it if you have any any comment anything I missed you can you can let me know in the comments if you if you haven't already you can subscribe you can like the video that would be that would be awesome and with that we'll see you next time thanks for joining you", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.84, "text": " Hi everyone and welcome back to Datafile. Today I'm very excited. We're gonna go", "tokens": [50364, 2421, 1518, 293, 2928, 646, 281, 9315, 2792, 794, 13, 2692, 286, 478, 588, 2919, 13, 492, 434, 799, 352, 50656], "temperature": 0.0, "avg_logprob": -0.3029507833813864, "compression_ratio": 1.372093023255814, "no_speech_prob": 0.057547397911548615}, {"id": 1, "seek": 0, "start": 5.84, "end": 11.28, "text": " through the highlights of Julia 1.6 and basically what's new in the version and", "tokens": [50656, 807, 264, 14254, 295, 18551, 502, 13, 21, 293, 1936, 437, 311, 777, 294, 264, 3037, 293, 50928], "temperature": 0.0, "avg_logprob": -0.3029507833813864, "compression_ratio": 1.372093023255814, "no_speech_prob": 0.057547397911548615}, {"id": 2, "seek": 0, "start": 11.28, "end": 18.68, "text": " how it's gonna improve our life as Julia developers. So let's check it out.", "tokens": [50928, 577, 309, 311, 799, 3470, 527, 993, 382, 18551, 8849, 13, 407, 718, 311, 1520, 309, 484, 13, 51298], "temperature": 0.0, "avg_logprob": -0.3029507833813864, "compression_ratio": 1.372093023255814, "no_speech_prob": 0.057547397911548615}, {"id": 3, "seek": 1868, "start": 18.68, "end": 32.2, "text": " Okay so let's move to the Julia website here. I'm gonna make this link", "tokens": [50364, 1033, 370, 718, 311, 1286, 281, 264, 18551, 3144, 510, 13, 286, 478, 799, 652, 341, 2113, 51040], "temperature": 0.0, "avg_logprob": -0.20391333103179932, "compression_ratio": 1.5570469798657718, "no_speech_prob": 0.025530872866511345}, {"id": 4, "seek": 1868, "start": 32.2, "end": 37.519999999999996, "text": " available in the description so you can check it out. And this is the blog. This", "tokens": [51040, 2435, 294, 264, 3855, 370, 291, 393, 1520, 309, 484, 13, 400, 341, 307, 264, 6968, 13, 639, 51306], "temperature": 0.0, "avg_logprob": -0.20391333103179932, "compression_ratio": 1.5570469798657718, "no_speech_prob": 0.025530872866511345}, {"id": 5, "seek": 1868, "start": 37.519999999999996, "end": 44.72, "text": " is Julia's blog. This is Julia's website. And you can see over here they so if I", "tokens": [51306, 307, 18551, 311, 6968, 13, 639, 307, 18551, 311, 3144, 13, 400, 291, 393, 536, 670, 510, 436, 370, 498, 286, 51666], "temperature": 0.0, "avg_logprob": -0.20391333103179932, "compression_ratio": 1.5570469798657718, "no_speech_prob": 0.025530872866511345}, {"id": 6, "seek": 4472, "start": 44.72, "end": 50.839999999999996, "text": " go to the blog list they have a couple blogs dating back from a while ago.", "tokens": [50364, 352, 281, 264, 6968, 1329, 436, 362, 257, 1916, 31038, 10689, 646, 490, 257, 1339, 2057, 13, 50670], "temperature": 0.0, "avg_logprob": -0.12931645358050312, "compression_ratio": 1.6131687242798354, "no_speech_prob": 0.07682459056377411}, {"id": 7, "seek": 4472, "start": 50.839999999999996, "end": 57.28, "text": " This is the latest one as of today. And here are all of the new things which are", "tokens": [50670, 639, 307, 264, 6792, 472, 382, 295, 965, 13, 400, 510, 366, 439, 295, 264, 777, 721, 597, 366, 50992], "temperature": 0.0, "avg_logprob": -0.12931645358050312, "compression_ratio": 1.6131687242798354, "no_speech_prob": 0.07682459056377411}, {"id": 8, "seek": 4472, "start": 57.28, "end": 64.92, "text": " brought to life in Julia 1.6. So Julia 1.6 might be the new long-term stable", "tokens": [50992, 3038, 281, 993, 294, 18551, 502, 13, 21, 13, 407, 18551, 502, 13, 21, 1062, 312, 264, 777, 938, 12, 7039, 8351, 51374], "temperature": 0.0, "avg_logprob": -0.12931645358050312, "compression_ratio": 1.6131687242798354, "no_speech_prob": 0.07682459056377411}, {"id": 9, "seek": 4472, "start": 64.92, "end": 69.75999999999999, "text": " which is kind of a big deal. Meaning that this is the one we may be using for a", "tokens": [51374, 597, 307, 733, 295, 257, 955, 2028, 13, 19948, 300, 341, 307, 264, 472, 321, 815, 312, 1228, 337, 257, 51616], "temperature": 0.0, "avg_logprob": -0.12931645358050312, "compression_ratio": 1.6131687242798354, "no_speech_prob": 0.07682459056377411}, {"id": 10, "seek": 4472, "start": 69.75999999999999, "end": 74.16, "text": " while. It's not just some version that they're gonna throw away very soon. Okay", "tokens": [51616, 1339, 13, 467, 311, 406, 445, 512, 3037, 300, 436, 434, 799, 3507, 1314, 588, 2321, 13, 1033, 51836], "temperature": 0.0, "avg_logprob": -0.12931645358050312, "compression_ratio": 1.6131687242798354, "no_speech_prob": 0.07682459056377411}, {"id": 11, "seek": 7416, "start": 74.2, "end": 79.16, "text": " so let's dive into the new features. You can read the whole thing if you're", "tokens": [50366, 370, 718, 311, 9192, 666, 264, 777, 4122, 13, 509, 393, 1401, 264, 1379, 551, 498, 291, 434, 50614], "temperature": 0.0, "avg_logprob": -0.14621759863460765, "compression_ratio": 1.5774058577405858, "no_speech_prob": 0.008438498713076115}, {"id": 12, "seek": 7416, "start": 79.16, "end": 83.39999999999999, "text": " interested. I'm gonna leave the link in the description. Here they mentioned that", "tokens": [50614, 3102, 13, 286, 478, 799, 1856, 264, 2113, 294, 264, 3855, 13, 1692, 436, 2835, 300, 50826], "temperature": 0.0, "avg_logprob": -0.14621759863460765, "compression_ratio": 1.5774058577405858, "no_speech_prob": 0.008438498713076115}, {"id": 13, "seek": 7416, "start": 83.39999999999999, "end": 90.12, "text": " they're not sure whether 1.6 or 1.7 is gonna be the new LTS. Okay well", "tokens": [50826, 436, 434, 406, 988, 1968, 502, 13, 21, 420, 502, 13, 22, 307, 799, 312, 264, 777, 441, 7327, 13, 1033, 731, 51162], "temperature": 0.0, "avg_logprob": -0.14621759863460765, "compression_ratio": 1.5774058577405858, "no_speech_prob": 0.008438498713076115}, {"id": 14, "seek": 7416, "start": 90.12, "end": 96.56, "text": " basically so just an overall view on Julia 1.6. What they improve the most", "tokens": [51162, 1936, 370, 445, 364, 4787, 1910, 322, 18551, 502, 13, 21, 13, 708, 436, 3470, 264, 881, 51484], "temperature": 0.0, "avg_logprob": -0.14621759863460765, "compression_ratio": 1.5774058577405858, "no_speech_prob": 0.008438498713076115}, {"id": 15, "seek": 7416, "start": 96.56, "end": 102.6, "text": " is speed, speed, speed. And this is great especially for a first time run", "tokens": [51484, 307, 3073, 11, 3073, 11, 3073, 13, 400, 341, 307, 869, 2318, 337, 257, 700, 565, 1190, 51786], "temperature": 0.0, "avg_logprob": -0.14621759863460765, "compression_ratio": 1.5774058577405858, "no_speech_prob": 0.008438498713076115}, {"id": 16, "seek": 10260, "start": 102.64, "end": 107.55999999999999, "text": " because we had this problem as I mentioned in previous videos that the", "tokens": [50366, 570, 321, 632, 341, 1154, 382, 286, 2835, 294, 3894, 2145, 300, 264, 50612], "temperature": 0.0, "avg_logprob": -0.16084339933575326, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.010006105527281761}, {"id": 17, "seek": 10260, "start": 107.55999999999999, "end": 111.75999999999999, "text": " first time you run a cell in Julia it's gonna take a while and they did their", "tokens": [50612, 700, 565, 291, 1190, 257, 2815, 294, 18551, 309, 311, 799, 747, 257, 1339, 293, 436, 630, 641, 50822], "temperature": 0.0, "avg_logprob": -0.16084339933575326, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.010006105527281761}, {"id": 18, "seek": 10260, "start": 111.75999999999999, "end": 114.96, "text": " best to reduce it as much as possible. Obviously they're going to do more", "tokens": [50822, 1151, 281, 5407, 309, 382, 709, 382, 1944, 13, 7580, 436, 434, 516, 281, 360, 544, 50982], "temperature": 0.0, "avg_logprob": -0.16084339933575326, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.010006105527281761}, {"id": 19, "seek": 10260, "start": 114.96, "end": 119.52, "text": " changes in order to make it even better but as of today there is quite a", "tokens": [50982, 2962, 294, 1668, 281, 652, 309, 754, 1101, 457, 382, 295, 965, 456, 307, 1596, 257, 51210], "temperature": 0.0, "avg_logprob": -0.16084339933575326, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.010006105527281761}, {"id": 20, "seek": 10260, "start": 119.52, "end": 124.28, "text": " substantial difference with before this version already. Okay so parallel", "tokens": [51210, 16726, 2649, 365, 949, 341, 3037, 1217, 13, 1033, 370, 8952, 51448], "temperature": 0.0, "avg_logprob": -0.16084339933575326, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.010006105527281761}, {"id": 21, "seek": 10260, "start": 124.28, "end": 129.64, "text": " pre-compilation so that the whole idea of these things is that you're trying to", "tokens": [51448, 659, 12, 21541, 16067, 370, 300, 264, 1379, 1558, 295, 613, 721, 307, 300, 291, 434, 1382, 281, 51716], "temperature": 0.0, "avg_logprob": -0.16084339933575326, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.010006105527281761}, {"id": 22, "seek": 12964, "start": 129.67999999999998, "end": 133.83999999999997, "text": " import the packages as fast as possible because I believe differential", "tokens": [50366, 974, 264, 17401, 382, 2370, 382, 1944, 570, 286, 1697, 15756, 50574], "temperature": 0.0, "avg_logprob": -0.13110476407137783, "compression_ratio": 1.6703296703296704, "no_speech_prob": 0.048832036554813385}, {"id": 23, "seek": 12964, "start": 133.83999999999997, "end": 138.35999999999999, "text": " equation is a pretty heavy package but I haven't used it myself so I can't say", "tokens": [50574, 5367, 307, 257, 1238, 4676, 7372, 457, 286, 2378, 380, 1143, 309, 2059, 370, 286, 393, 380, 584, 50800], "temperature": 0.0, "avg_logprob": -0.13110476407137783, "compression_ratio": 1.6703296703296704, "no_speech_prob": 0.048832036554813385}, {"id": 24, "seek": 12964, "start": 138.35999999999999, "end": 144.04, "text": " for sure. But basically packages which take quite some time are a problem and", "tokens": [50800, 337, 988, 13, 583, 1936, 17401, 597, 747, 1596, 512, 565, 366, 257, 1154, 293, 51084], "temperature": 0.0, "avg_logprob": -0.13110476407137783, "compression_ratio": 1.6703296703296704, "no_speech_prob": 0.048832036554813385}, {"id": 25, "seek": 12964, "start": 144.04, "end": 149.44, "text": " obviously Julia team want to reduce that time. So here what they also included", "tokens": [51084, 2745, 18551, 1469, 528, 281, 5407, 300, 565, 13, 407, 510, 437, 436, 611, 5556, 51354], "temperature": 0.0, "avg_logprob": -0.13110476407137783, "compression_ratio": 1.6703296703296704, "no_speech_prob": 0.048832036554813385}, {"id": 26, "seek": 12964, "start": 149.44, "end": 154.23999999999998, "text": " this thing this new animation and we're gonna see it here. I'm gonna I'm gonna", "tokens": [51354, 341, 551, 341, 777, 9603, 293, 321, 434, 799, 536, 309, 510, 13, 286, 478, 799, 286, 478, 799, 51594], "temperature": 0.0, "avg_logprob": -0.13110476407137783, "compression_ratio": 1.6703296703296704, "no_speech_prob": 0.048832036554813385}, {"id": 27, "seek": 12964, "start": 154.23999999999998, "end": 157.79999999999998, "text": " show you that video so you can see what's going on. So you see they're", "tokens": [51594, 855, 291, 300, 960, 370, 291, 393, 536, 437, 311, 516, 322, 13, 407, 291, 536, 436, 434, 51772], "temperature": 0.0, "avg_logprob": -0.13110476407137783, "compression_ratio": 1.6703296703296704, "no_speech_prob": 0.048832036554813385}, {"id": 28, "seek": 15780, "start": 157.84, "end": 163.72, "text": " adding this images package and here you have the progress as you're", "tokens": [50366, 5127, 341, 5267, 7372, 293, 510, 291, 362, 264, 4205, 382, 291, 434, 50660], "temperature": 0.0, "avg_logprob": -0.19073558675831762, "compression_ratio": 1.6283185840707965, "no_speech_prob": 0.007103540003299713}, {"id": 29, "seek": 15780, "start": 163.72, "end": 167.8, "text": " downloading the package which is great. It's nice to see that everything", "tokens": [50660, 32529, 264, 7372, 597, 307, 869, 13, 467, 311, 1481, 281, 536, 300, 1203, 50864], "temperature": 0.0, "avg_logprob": -0.19073558675831762, "compression_ratio": 1.6283185840707965, "no_speech_prob": 0.007103540003299713}, {"id": 30, "seek": 15780, "start": 167.8, "end": 174.12, "text": " is going fine and as expected. And yeah this I experienced myself when I", "tokens": [50864, 307, 516, 2489, 293, 382, 5176, 13, 400, 1338, 341, 286, 6751, 2059, 562, 286, 51180], "temperature": 0.0, "avg_logprob": -0.19073558675831762, "compression_ratio": 1.6283185840707965, "no_speech_prob": 0.007103540003299713}, {"id": 31, "seek": 15780, "start": 174.12, "end": 181.12, "text": " installed Julia 1.6 you can you see the dependencies coming in and coming out", "tokens": [51180, 8899, 18551, 502, 13, 21, 291, 393, 291, 536, 264, 36606, 1348, 294, 293, 1348, 484, 51530], "temperature": 0.0, "avg_logprob": -0.19073558675831762, "compression_ratio": 1.6283185840707965, "no_speech_prob": 0.007103540003299713}, {"id": 32, "seek": 15780, "start": 181.12, "end": 186.76000000000002, "text": " and it's really nice not to just have that black box. Python for instance if", "tokens": [51530, 293, 309, 311, 534, 1481, 406, 281, 445, 362, 300, 2211, 2424, 13, 15329, 337, 5197, 498, 51812], "temperature": 0.0, "avg_logprob": -0.19073558675831762, "compression_ratio": 1.6283185840707965, "no_speech_prob": 0.007103540003299713}, {"id": 33, "seek": 18676, "start": 186.79999999999998, "end": 191.72, "text": " you install things from Jupyter notebook with the pip install you get just a", "tokens": [50366, 291, 3625, 721, 490, 22125, 88, 391, 21060, 365, 264, 8489, 3625, 291, 483, 445, 257, 50612], "temperature": 0.0, "avg_logprob": -0.14011570531078893, "compression_ratio": 1.7269372693726937, "no_speech_prob": 0.013208707794547081}, {"id": 34, "seek": 18676, "start": 191.72, "end": 195.39999999999998, "text": " black box. You know that the cell is running hopefully it's installing but", "tokens": [50612, 2211, 2424, 13, 509, 458, 300, 264, 2815, 307, 2614, 4696, 309, 311, 20762, 457, 50796], "temperature": 0.0, "avg_logprob": -0.14011570531078893, "compression_ratio": 1.7269372693726937, "no_speech_prob": 0.013208707794547081}, {"id": 35, "seek": 18676, "start": 195.39999999999998, "end": 200.0, "text": " you're not sure even though you don't get an error sometimes things might happen.", "tokens": [50796, 291, 434, 406, 988, 754, 1673, 291, 500, 380, 483, 364, 6713, 2171, 721, 1062, 1051, 13, 51026], "temperature": 0.0, "avg_logprob": -0.14011570531078893, "compression_ratio": 1.7269372693726937, "no_speech_prob": 0.013208707794547081}, {"id": 36, "seek": 18676, "start": 200.0, "end": 203.92, "text": " So it's just yeah it's really nice to get to get this animation and you see", "tokens": [51026, 407, 309, 311, 445, 1338, 309, 311, 534, 1481, 281, 483, 281, 483, 341, 9603, 293, 291, 536, 51222], "temperature": 0.0, "avg_logprob": -0.14011570531078893, "compression_ratio": 1.7269372693726937, "no_speech_prob": 0.013208707794547081}, {"id": 37, "seek": 18676, "start": 203.92, "end": 208.44, "text": " here they're using images and it loaded pretty quick and now they have access to", "tokens": [51222, 510, 436, 434, 1228, 5267, 293, 309, 13210, 1238, 1702, 293, 586, 436, 362, 2105, 281, 51448], "temperature": 0.0, "avg_logprob": -0.14011570531078893, "compression_ratio": 1.7269372693726937, "no_speech_prob": 0.013208707794547081}, {"id": 38, "seek": 18676, "start": 208.44, "end": 214.76, "text": " this package. So that's great I'm all for it I'm very happy about that it's a", "tokens": [51448, 341, 7372, 13, 407, 300, 311, 869, 286, 478, 439, 337, 309, 286, 478, 588, 2055, 466, 300, 309, 311, 257, 51764], "temperature": 0.0, "avg_logprob": -0.14011570531078893, "compression_ratio": 1.7269372693726937, "no_speech_prob": 0.013208707794547081}, {"id": 39, "seek": 21476, "start": 214.76, "end": 221.48, "text": " nice cool feature obviously it's not gonna revolutionize coding but it's", "tokens": [50364, 1481, 1627, 4111, 2745, 309, 311, 406, 799, 8894, 1125, 17720, 457, 309, 311, 50700], "temperature": 0.0, "avg_logprob": -0.16335507956418124, "compression_ratio": 1.6681614349775784, "no_speech_prob": 0.012232685461640358}, {"id": 40, "seek": 21476, "start": 221.48, "end": 226.84, "text": " just a nice feature to know what's going on. Compile time percentage so here", "tokens": [50700, 445, 257, 1481, 4111, 281, 458, 437, 311, 516, 322, 13, 6620, 794, 565, 9668, 370, 510, 50968], "temperature": 0.0, "avg_logprob": -0.16335507956418124, "compression_ratio": 1.6681614349775784, "no_speech_prob": 0.012232685461640358}, {"id": 41, "seek": 21476, "start": 226.84, "end": 232.48, "text": " that's maybe not as important I would say they include the compilation time", "tokens": [50968, 300, 311, 1310, 406, 382, 1021, 286, 576, 584, 436, 4090, 264, 40261, 565, 51250], "temperature": 0.0, "avg_logprob": -0.16335507956418124, "compression_ratio": 1.6681614349775784, "no_speech_prob": 0.012232685461640358}, {"id": 42, "seek": 21476, "start": 232.48, "end": 236.88, "text": " when you talk about the runtime so they use this time and time verbose things", "tokens": [51250, 562, 291, 751, 466, 264, 34474, 370, 436, 764, 341, 565, 293, 565, 9595, 541, 721, 51470], "temperature": 0.0, "avg_logprob": -0.16335507956418124, "compression_ratio": 1.6681614349775784, "no_speech_prob": 0.012232685461640358}, {"id": 43, "seek": 21476, "start": 236.88, "end": 242.95999999999998, "text": " to measure the time that running code takes. Eliminating needless to", "tokens": [51470, 281, 3481, 264, 565, 300, 2614, 3089, 2516, 13, 2699, 4395, 990, 643, 1832, 281, 51774], "temperature": 0.0, "avg_logprob": -0.16335507956418124, "compression_ratio": 1.6681614349775784, "no_speech_prob": 0.012232685461640358}, {"id": 44, "seek": 24296, "start": 243.0, "end": 248.16, "text": " compilation which is great basically you use some code and then you reuse the", "tokens": [50366, 40261, 597, 307, 869, 1936, 291, 764, 512, 3089, 293, 550, 291, 26225, 264, 50624], "temperature": 0.0, "avg_logprob": -0.12771270586096722, "compression_ratio": 1.9621848739495797, "no_speech_prob": 0.07470060884952545}, {"id": 45, "seek": 24296, "start": 248.16, "end": 252.92000000000002, "text": " same code later and depending on when you use that code in the past Julia is", "tokens": [50624, 912, 3089, 1780, 293, 5413, 322, 562, 291, 764, 300, 3089, 294, 264, 1791, 18551, 307, 50862], "temperature": 0.0, "avg_logprob": -0.12771270586096722, "compression_ratio": 1.9621848739495797, "no_speech_prob": 0.07470060884952545}, {"id": 46, "seek": 24296, "start": 252.92000000000002, "end": 256.64, "text": " gonna sometimes throw it away too much and you shouldn't throw it away as much", "tokens": [50862, 799, 2171, 3507, 309, 1314, 886, 709, 293, 291, 4659, 380, 3507, 309, 1314, 382, 709, 51048], "temperature": 0.0, "avg_logprob": -0.12771270586096722, "compression_ratio": 1.9621848739495797, "no_speech_prob": 0.07470060884952545}, {"id": 47, "seek": 24296, "start": 256.64, "end": 263.28000000000003, "text": " as it does and they're trying to fix that here. They're trying to make it so", "tokens": [51048, 382, 309, 775, 293, 436, 434, 1382, 281, 3191, 300, 510, 13, 814, 434, 1382, 281, 652, 309, 370, 51380], "temperature": 0.0, "avg_logprob": -0.12771270586096722, "compression_ratio": 1.9621848739495797, "no_speech_prob": 0.07470060884952545}, {"id": 48, "seek": 24296, "start": 263.28000000000003, "end": 268.36, "text": " that if you use code and you still need it at some point in the future Julia is", "tokens": [51380, 300, 498, 291, 764, 3089, 293, 291, 920, 643, 309, 412, 512, 935, 294, 264, 2027, 18551, 307, 51634], "temperature": 0.0, "avg_logprob": -0.12771270586096722, "compression_ratio": 1.9621848739495797, "no_speech_prob": 0.07470060884952545}, {"id": 49, "seek": 24296, "start": 268.36, "end": 271.6, "text": " not throwing it away so it's gonna be able to reuse it to gain some speed in", "tokens": [51634, 406, 10238, 309, 1314, 370, 309, 311, 799, 312, 1075, 281, 26225, 309, 281, 6052, 512, 3073, 294, 51796], "temperature": 0.0, "avg_logprob": -0.12771270586096722, "compression_ratio": 1.9621848739495797, "no_speech_prob": 0.07470060884952545}, {"id": 50, "seek": 27160, "start": 271.64000000000004, "end": 277.24, "text": " the future in the future runs of codes for instance in Jupyter Notebooks if", "tokens": [50366, 264, 2027, 294, 264, 2027, 6676, 295, 14211, 337, 5197, 294, 22125, 88, 391, 11633, 15170, 498, 50646], "temperature": 0.0, "avg_logprob": -0.136139515748958, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.007107044104486704}, {"id": 51, "seek": 27160, "start": 277.24, "end": 283.20000000000005, "text": " you have many cells and you want to run third cell but the first cell has some", "tokens": [50646, 291, 362, 867, 5438, 293, 291, 528, 281, 1190, 2636, 2815, 457, 264, 700, 2815, 575, 512, 50944], "temperature": 0.0, "avg_logprob": -0.136139515748958, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.007107044104486704}, {"id": 52, "seek": 27160, "start": 283.20000000000005, "end": 287.96000000000004, "text": " codes which you still need instead of Julia having to recompile and redo the", "tokens": [50944, 14211, 597, 291, 920, 643, 2602, 295, 18551, 1419, 281, 48000, 794, 293, 29956, 264, 51182], "temperature": 0.0, "avg_logprob": -0.136139515748958, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.007107044104486704}, {"id": 53, "seek": 27160, "start": 287.96000000000004, "end": 293.20000000000005, "text": " run of the first cell under the hood it's gonna be way faster and it's gonna", "tokens": [51182, 1190, 295, 264, 700, 2815, 833, 264, 13376, 309, 311, 799, 312, 636, 4663, 293, 309, 311, 799, 51444], "temperature": 0.0, "avg_logprob": -0.136139515748958, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.007107044104486704}, {"id": 54, "seek": 27160, "start": 293.20000000000005, "end": 299.92, "text": " keep those codes in memory or it's gonna be able to reuse them. Compile a", "tokens": [51444, 1066, 729, 14211, 294, 4675, 420, 309, 311, 799, 312, 1075, 281, 26225, 552, 13, 6620, 794, 257, 51780], "temperature": 0.0, "avg_logprob": -0.136139515748958, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.007107044104486704}, {"id": 55, "seek": 29992, "start": 299.96000000000004, "end": 304.48, "text": " latency reduction so all of these are kind of achieving the same purpose I'm", "tokens": [50366, 27043, 11004, 370, 439, 295, 613, 366, 733, 295, 19626, 264, 912, 4334, 286, 478, 50592], "temperature": 0.0, "avg_logprob": -0.13692836272410858, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.056608736515045166}, {"id": 56, "seek": 29992, "start": 304.48, "end": 308.8, "text": " just gonna go quickly through those tooling to help optimize packages for", "tokens": [50592, 445, 799, 352, 2661, 807, 729, 46593, 281, 854, 19719, 17401, 337, 50808], "temperature": 0.0, "avg_logprob": -0.13692836272410858, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.056608736515045166}, {"id": 57, "seek": 29992, "start": 308.8, "end": 312.64000000000004, "text": " latency so you see this one word which comes all the time it's latency and it's", "tokens": [50808, 27043, 370, 291, 536, 341, 472, 1349, 597, 1487, 439, 264, 565, 309, 311, 27043, 293, 309, 311, 51000], "temperature": 0.0, "avg_logprob": -0.13692836272410858, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.056608736515045166}, {"id": 58, "seek": 29992, "start": 312.64000000000004, "end": 318.48, "text": " obviously related to speed loading speed ups binary loading speed ups so they", "tokens": [51000, 2745, 4077, 281, 3073, 15114, 3073, 15497, 17434, 15114, 3073, 15497, 370, 436, 51292], "temperature": 0.0, "avg_logprob": -0.13692836272410858, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.056608736515045166}, {"id": 59, "seek": 29992, "start": 318.48, "end": 321.08000000000004, "text": " understood the problem they understood that they have this community of", "tokens": [51292, 7320, 264, 1154, 436, 7320, 300, 436, 362, 341, 1768, 295, 51422], "temperature": 0.0, "avg_logprob": -0.13692836272410858, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.056608736515045166}, {"id": 60, "seek": 29992, "start": 321.08000000000004, "end": 325.84000000000003, "text": " developers and these people are used to Python they're used to all the languages", "tokens": [51422, 8849, 293, 613, 561, 366, 1143, 281, 15329, 436, 434, 1143, 281, 439, 264, 8650, 51660], "temperature": 0.0, "avg_logprob": -0.13692836272410858, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.056608736515045166}, {"id": 61, "seek": 29992, "start": 325.84000000000003, "end": 329.68, "text": " or maybe they're just starting on the language but they don't want to take too", "tokens": [51660, 420, 1310, 436, 434, 445, 2891, 322, 264, 2856, 457, 436, 500, 380, 528, 281, 747, 886, 51852], "temperature": 0.0, "avg_logprob": -0.13692836272410858, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.056608736515045166}, {"id": 62, "seek": 32968, "start": 329.72, "end": 333.8, "text": " much time to run their code and they just want to have things being done quick", "tokens": [50366, 709, 565, 281, 1190, 641, 3089, 293, 436, 445, 528, 281, 362, 721, 885, 1096, 1702, 50570], "temperature": 0.0, "avg_logprob": -0.10841512258073925, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.0062849451787769794}, {"id": 63, "seek": 32968, "start": 333.8, "end": 339.32, "text": " because in Python and in R and in all the languages that's how it happens so", "tokens": [50570, 570, 294, 15329, 293, 294, 497, 293, 294, 439, 264, 8650, 300, 311, 577, 309, 2314, 370, 50846], "temperature": 0.0, "avg_logprob": -0.10841512258073925, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.0062849451787769794}, {"id": 64, "seek": 32968, "start": 339.32, "end": 343.96000000000004, "text": " they don't want to spend one minute importing a package if Python can do it", "tokens": [50846, 436, 500, 380, 528, 281, 3496, 472, 3456, 43866, 257, 7372, 498, 15329, 393, 360, 309, 51078], "temperature": 0.0, "avg_logprob": -0.10841512258073925, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.0062849451787769794}, {"id": 65, "seek": 32968, "start": 343.96000000000004, "end": 347.8, "text": " in five seconds obviously so if Julia wants to compete it's gonna have to do", "tokens": [51078, 294, 1732, 3949, 2745, 370, 498, 18551, 2738, 281, 11831, 309, 311, 799, 362, 281, 360, 51270], "temperature": 0.0, "avg_logprob": -0.10841512258073925, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.0062849451787769794}, {"id": 66, "seek": 32968, "start": 347.8, "end": 352.24, "text": " that and I'm very happy that they put the accent on this because the first run", "tokens": [51270, 300, 293, 286, 478, 588, 2055, 300, 436, 829, 264, 11982, 322, 341, 570, 264, 700, 1190, 51492], "temperature": 0.0, "avg_logprob": -0.10841512258073925, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.0062849451787769794}, {"id": 67, "seek": 32968, "start": 352.24, "end": 359.2, "text": " time being huge I mean personally I'm taking the hit because I'm all for Julia", "tokens": [51492, 565, 885, 2603, 286, 914, 5665, 286, 478, 1940, 264, 2045, 570, 286, 478, 439, 337, 18551, 51840], "temperature": 0.0, "avg_logprob": -0.10841512258073925, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.0062849451787769794}, {"id": 68, "seek": 35920, "start": 359.2, "end": 364.47999999999996, "text": " and I love language no matter what but I can understand that someone who's a new", "tokens": [50364, 293, 286, 959, 2856, 572, 1871, 437, 457, 286, 393, 1223, 300, 1580, 567, 311, 257, 777, 50628], "temperature": 0.0, "avg_logprob": -0.1655980936686198, "compression_ratio": 1.6051282051282052, "no_speech_prob": 0.007116252090781927}, {"id": 69, "seek": 35920, "start": 364.47999999999996, "end": 369.32, "text": " comer to the language would not be happy with with waiting one minute for the", "tokens": [50628, 16510, 281, 264, 2856, 576, 406, 312, 2055, 365, 365, 3806, 472, 3456, 337, 264, 50870], "temperature": 0.0, "avg_logprob": -0.1655980936686198, "compression_ratio": 1.6051282051282052, "no_speech_prob": 0.007116252090781927}, {"id": 70, "seek": 35920, "start": 369.32, "end": 375.03999999999996, "text": " first run to happen that's if you have Python doing it in five seconds it's", "tokens": [50870, 700, 1190, 281, 1051, 300, 311, 498, 291, 362, 15329, 884, 309, 294, 1732, 3949, 309, 311, 51156], "temperature": 0.0, "avg_logprob": -0.1655980936686198, "compression_ratio": 1.6051282051282052, "no_speech_prob": 0.007116252090781927}, {"id": 71, "seek": 35920, "start": 375.03999999999996, "end": 380.96, "text": " not acceptable anyway this is a this is a nice graph I think they're measuring", "tokens": [51156, 406, 15513, 4033, 341, 307, 257, 341, 307, 257, 1481, 4295, 286, 519, 436, 434, 13389, 51452], "temperature": 0.0, "avg_logprob": -0.1655980936686198, "compression_ratio": 1.6051282051282052, "no_speech_prob": 0.007116252090781927}, {"id": 72, "seek": 38096, "start": 381.0, "end": 390.47999999999996, "text": " whatever GTK3 whatever I don't personally know this I guess the package anyway", "tokens": [50366, 2035, 17530, 42, 18, 2035, 286, 500, 380, 5665, 458, 341, 286, 2041, 264, 7372, 4033, 50840], "temperature": 0.0, "avg_logprob": -0.19075220059125853, "compression_ratio": 1.5863874345549738, "no_speech_prob": 0.3337838649749756}, {"id": 73, "seek": 38096, "start": 390.47999999999996, "end": 397.15999999999997, "text": " what's important is so these are the versions version 1.3 1.4 1.5 1.6 and", "tokens": [50840, 437, 311, 1021, 307, 370, 613, 366, 264, 9606, 3037, 502, 13, 18, 502, 13, 19, 502, 13, 20, 502, 13, 21, 293, 51174], "temperature": 0.0, "avg_logprob": -0.19075220059125853, "compression_ratio": 1.5863874345549738, "no_speech_prob": 0.3337838649749756}, {"id": 74, "seek": 38096, "start": 397.15999999999997, "end": 405.4, "text": " they're measuring the time that this this thing whatever it is takes and you", "tokens": [51174, 436, 434, 13389, 264, 565, 300, 341, 341, 551, 2035, 309, 307, 2516, 293, 291, 51586], "temperature": 0.0, "avg_logprob": -0.19075220059125853, "compression_ratio": 1.5863874345549738, "no_speech_prob": 0.3337838649749756}, {"id": 75, "seek": 38096, "start": 405.4, "end": 409.44, "text": " can obviously see that things are going down so initially we had the blue", "tokens": [51586, 393, 2745, 536, 300, 721, 366, 516, 760, 370, 9105, 321, 632, 264, 3344, 51788], "temperature": 0.0, "avg_logprob": -0.19075220059125853, "compression_ratio": 1.5863874345549738, "no_speech_prob": 0.3337838649749756}, {"id": 76, "seek": 40944, "start": 409.44, "end": 414.0, "text": " curve with those old wrappers and they included some new wrappers which I may", "tokens": [50364, 7605, 365, 729, 1331, 7843, 15226, 293, 436, 5556, 512, 777, 7843, 15226, 597, 286, 815, 50592], "temperature": 0.0, "avg_logprob": -0.13273573958355447, "compression_ratio": 1.7904761904761906, "no_speech_prob": 0.18635103106498718}, {"id": 77, "seek": 40944, "start": 414.0, "end": 419.92, "text": " have missed it's part of the binary loading speed-ups I guess and they", "tokens": [50592, 362, 6721, 309, 311, 644, 295, 264, 17434, 15114, 3073, 12, 7528, 286, 2041, 293, 436, 50888], "temperature": 0.0, "avg_logprob": -0.13273573958355447, "compression_ratio": 1.7904761904761906, "no_speech_prob": 0.18635103106498718}, {"id": 78, "seek": 40944, "start": 419.92, "end": 425.36, "text": " included some new JLL wrappers whatever they are anyway bottom line for for", "tokens": [50888, 5556, 512, 777, 508, 24010, 7843, 15226, 2035, 436, 366, 4033, 2767, 1622, 337, 337, 51160], "temperature": 0.0, "avg_logprob": -0.13273573958355447, "compression_ratio": 1.7904761904761906, "no_speech_prob": 0.18635103106498718}, {"id": 79, "seek": 40944, "start": 425.36, "end": 429.84, "text": " anyone using Julia and who doesn't know those things under the hood is that", "tokens": [51160, 2878, 1228, 18551, 293, 567, 1177, 380, 458, 729, 721, 833, 264, 13376, 307, 300, 51384], "temperature": 0.0, "avg_logprob": -0.13273573958355447, "compression_ratio": 1.7904761904761906, "no_speech_prob": 0.18635103106498718}, {"id": 80, "seek": 40944, "start": 429.84, "end": 435.4, "text": " speed is going up so time time taken is going down and it's going down it's", "tokens": [51384, 3073, 307, 516, 493, 370, 565, 565, 2726, 307, 516, 760, 293, 309, 311, 516, 760, 309, 311, 51662], "temperature": 0.0, "avg_logprob": -0.13273573958355447, "compression_ratio": 1.7904761904761906, "no_speech_prob": 0.18635103106498718}, {"id": 81, "seek": 43540, "start": 435.4, "end": 441.35999999999996, "text": " going down really significantly like we used to have six or seven seconds to", "tokens": [50364, 516, 760, 534, 10591, 411, 321, 1143, 281, 362, 2309, 420, 3407, 3949, 281, 50662], "temperature": 0.0, "avg_logprob": -0.12701148336583917, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.017150020226836205}, {"id": 82, "seek": 43540, "start": 441.35999999999996, "end": 446.2, "text": " load that package just like a couple like three versions ago and as of today", "tokens": [50662, 3677, 300, 7372, 445, 411, 257, 1916, 411, 1045, 9606, 2057, 293, 382, 295, 965, 50904], "temperature": 0.0, "avg_logprob": -0.12701148336583917, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.017150020226836205}, {"id": 83, "seek": 43540, "start": 446.2, "end": 453.52, "text": " it's it's almost instantaneous so this is insane I'm very happy that they made", "tokens": [50904, 309, 311, 309, 311, 1920, 45596, 370, 341, 307, 10838, 286, 478, 588, 2055, 300, 436, 1027, 51270], "temperature": 0.0, "avg_logprob": -0.12701148336583917, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.017150020226836205}, {"id": 84, "seek": 43540, "start": 453.52, "end": 458.15999999999997, "text": " those changes and I don't personally understand all the things happening under", "tokens": [51270, 729, 2962, 293, 286, 500, 380, 5665, 1223, 439, 264, 721, 2737, 833, 51502], "temperature": 0.0, "avg_logprob": -0.12701148336583917, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.017150020226836205}, {"id": 85, "seek": 43540, "start": 458.15999999999997, "end": 464.71999999999997, "text": " the hood but whatever it is if if you can reduce the time taken by whatever it", "tokens": [51502, 264, 13376, 457, 2035, 309, 307, 498, 498, 291, 393, 5407, 264, 565, 2726, 538, 2035, 309, 51830], "temperature": 0.0, "avg_logprob": -0.12701148336583917, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.017150020226836205}, {"id": 86, "seek": 46472, "start": 464.72, "end": 473.68, "text": " is like 30 30x well I am all for it so I don't know how they do that I I'm not", "tokens": [50364, 307, 411, 2217, 2217, 87, 731, 286, 669, 439, 337, 309, 370, 286, 500, 380, 458, 577, 436, 360, 300, 286, 286, 478, 406, 50812], "temperature": 0.0, "avg_logprob": -0.13801875556867146, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.032977163791656494}, {"id": 87, "seek": 46472, "start": 473.68, "end": 479.36, "text": " familiar with the computer science technical things going on in the", "tokens": [50812, 4963, 365, 264, 3820, 3497, 6191, 721, 516, 322, 294, 264, 51096], "temperature": 0.0, "avg_logprob": -0.13801875556867146, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.032977163791656494}, {"id": 88, "seek": 46472, "start": 479.36, "end": 484.12, "text": " Julia repos but I'm very happy about that and I wanted to report to you so", "tokens": [51096, 18551, 1085, 329, 457, 286, 478, 588, 2055, 466, 300, 293, 286, 1415, 281, 2275, 281, 291, 370, 51334], "temperature": 0.0, "avg_logprob": -0.13801875556867146, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.032977163791656494}, {"id": 89, "seek": 46472, "start": 484.12, "end": 488.52000000000004, "text": " that you have an idea of of how fast things are changing because they they", "tokens": [51334, 300, 291, 362, 364, 1558, 295, 295, 577, 2370, 721, 366, 4473, 570, 436, 436, 51554], "temperature": 0.0, "avg_logprob": -0.13801875556867146, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.032977163791656494}, {"id": 90, "seek": 46472, "start": 488.52000000000004, "end": 491.36, "text": " are talking I'm gonna maybe I'm gonna show you later but they're talking about", "tokens": [51554, 366, 1417, 286, 478, 799, 1310, 286, 478, 799, 855, 291, 1780, 457, 436, 434, 1417, 466, 51696], "temperature": 0.0, "avg_logprob": -0.13801875556867146, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.032977163791656494}, {"id": 91, "seek": 49136, "start": 491.68, "end": 496.0, "text": " the next version being in a month so I don't know if they had that timeline as", "tokens": [50380, 264, 958, 3037, 885, 294, 257, 1618, 370, 286, 500, 380, 458, 498, 436, 632, 300, 12933, 382, 50596], "temperature": 0.0, "avg_logprob": -0.1599194366152924, "compression_ratio": 1.7772727272727273, "no_speech_prob": 0.06425569951534271}, {"id": 92, "seek": 49136, "start": 496.0, "end": 500.0, "text": " well for the previous versions but if that's the case it's gonna it's absolutely", "tokens": [50596, 731, 337, 264, 3894, 9606, 457, 498, 300, 311, 264, 1389, 309, 311, 799, 309, 311, 3122, 50796], "temperature": 0.0, "avg_logprob": -0.1599194366152924, "compression_ratio": 1.7772727272727273, "no_speech_prob": 0.06425569951534271}, {"id": 93, "seek": 49136, "start": 500.0, "end": 507.96000000000004, "text": " workers yeah downloads and networking options by Stefan Karpinski by the way", "tokens": [50796, 5600, 1338, 36553, 293, 17985, 3956, 538, 32158, 591, 6529, 38984, 538, 264, 636, 51194], "temperature": 0.0, "avg_logprob": -0.1599194366152924, "compression_ratio": 1.7772727272727273, "no_speech_prob": 0.06425569951534271}, {"id": 94, "seek": 49136, "start": 507.96000000000004, "end": 510.72, "text": " there's a bit of drama going on on Reddit I don't know if you if you saw that", "tokens": [51194, 456, 311, 257, 857, 295, 9412, 516, 322, 322, 32210, 286, 500, 380, 458, 498, 291, 498, 291, 1866, 300, 51332], "temperature": 0.0, "avg_logprob": -0.1599194366152924, "compression_ratio": 1.7772727272727273, "no_speech_prob": 0.06425569951534271}, {"id": 95, "seek": 49136, "start": 510.72, "end": 516.08, "text": " but it's on the on the subreddit of Julia there's a little bit of drama with", "tokens": [51332, 457, 309, 311, 322, 264, 322, 264, 1422, 986, 17975, 295, 18551, 456, 311, 257, 707, 857, 295, 9412, 365, 51600], "temperature": 0.0, "avg_logprob": -0.1599194366152924, "compression_ratio": 1.7772727272727273, "no_speech_prob": 0.06425569951534271}, {"id": 96, "seek": 51608, "start": 516.24, "end": 522.2, "text": " like some guy insulting Stefan Karpinski and and yeah the whole community", "tokens": [50372, 411, 512, 2146, 44463, 32158, 591, 6529, 38984, 293, 293, 1338, 264, 1379, 1768, 50670], "temperature": 0.0, "avg_logprob": -0.1582974600135733, "compression_ratio": 1.8207171314741035, "no_speech_prob": 0.20535808801651}, {"id": 97, "seek": 51608, "start": 522.2, "end": 525.64, "text": " crushing this guy so I'm very happy about the community as well on the", "tokens": [50670, 31317, 341, 2146, 370, 286, 478, 588, 2055, 466, 264, 1768, 382, 731, 322, 264, 50842], "temperature": 0.0, "avg_logprob": -0.1582974600135733, "compression_ratio": 1.8207171314741035, "no_speech_prob": 0.20535808801651}, {"id": 98, "seek": 51608, "start": 525.64, "end": 529.5200000000001, "text": " subreddit of Julia if you haven't seen that you should check it out it's it's a", "tokens": [50842, 1422, 986, 17975, 295, 18551, 498, 291, 2378, 380, 1612, 300, 291, 820, 1520, 309, 484, 309, 311, 309, 311, 257, 51036], "temperature": 0.0, "avg_logprob": -0.1582974600135733, "compression_ratio": 1.8207171314741035, "no_speech_prob": 0.20535808801651}, {"id": 99, "seek": 51608, "start": 529.5200000000001, "end": 533.48, "text": " beautiful community people are helping each other it's a small community it's", "tokens": [51036, 2238, 1768, 561, 366, 4315, 1184, 661, 309, 311, 257, 1359, 1768, 309, 311, 51234], "temperature": 0.0, "avg_logprob": -0.1582974600135733, "compression_ratio": 1.8207171314741035, "no_speech_prob": 0.20535808801651}, {"id": 100, "seek": 51608, "start": 533.48, "end": 537.76, "text": " it's kind of the birth of Julia still even though the language wasn't created", "tokens": [51234, 309, 311, 733, 295, 264, 3965, 295, 18551, 920, 754, 1673, 264, 2856, 2067, 380, 2942, 51448], "temperature": 0.0, "avg_logprob": -0.1582974600135733, "compression_ratio": 1.8207171314741035, "no_speech_prob": 0.20535808801651}, {"id": 101, "seek": 51608, "start": 537.76, "end": 542.8000000000001, "text": " yesterday but it's still pretty new and and the community is small and still", "tokens": [51448, 5186, 457, 309, 311, 920, 1238, 777, 293, 293, 264, 1768, 307, 1359, 293, 920, 51700], "temperature": 0.0, "avg_logprob": -0.1582974600135733, "compression_ratio": 1.8207171314741035, "no_speech_prob": 0.20535808801651}, {"id": 102, "seek": 54280, "start": 542.8, "end": 546.92, "text": " beautiful I hope we're gonna be able to keep it that way anyway that was a side", "tokens": [50364, 2238, 286, 1454, 321, 434, 799, 312, 1075, 281, 1066, 309, 300, 636, 4033, 300, 390, 257, 1252, 50570], "temperature": 0.0, "avg_logprob": -0.16418388297965936, "compression_ratio": 1.7786259541984732, "no_speech_prob": 0.029700370505452156}, {"id": 103, "seek": 54280, "start": 546.92, "end": 551.52, "text": " story but yeah you can see that you can tell that they really understand the", "tokens": [50570, 1657, 457, 1338, 291, 393, 536, 300, 291, 393, 980, 300, 436, 534, 1223, 264, 50800], "temperature": 0.0, "avg_logprob": -0.16418388297965936, "compression_ratio": 1.7786259541984732, "no_speech_prob": 0.029700370505452156}, {"id": 104, "seek": 54280, "start": 551.52, "end": 556.4, "text": " the problems it's loads and consistent it's inflexible they I think they're", "tokens": [50800, 264, 2740, 309, 311, 12668, 293, 8398, 309, 311, 1536, 2021, 964, 436, 286, 519, 436, 434, 51044], "temperature": 0.0, "avg_logprob": -0.16418388297965936, "compression_ratio": 1.7786259541984732, "no_speech_prob": 0.029700370505452156}, {"id": 105, "seek": 54280, "start": 556.4, "end": 561.04, "text": " really listening to their community and you can also show that because they", "tokens": [51044, 534, 4764, 281, 641, 1768, 293, 291, 393, 611, 855, 300, 570, 436, 51276], "temperature": 0.0, "avg_logprob": -0.16418388297965936, "compression_ratio": 1.7786259541984732, "no_speech_prob": 0.029700370505452156}, {"id": 106, "seek": 54280, "start": 561.04, "end": 565.8, "text": " report github issues so github issues I don't know if you're familiar with that", "tokens": [51276, 2275, 290, 355, 836, 2663, 370, 290, 355, 836, 2663, 286, 500, 380, 458, 498, 291, 434, 4963, 365, 300, 51514], "temperature": 0.0, "avg_logprob": -0.16418388297965936, "compression_ratio": 1.7786259541984732, "no_speech_prob": 0.029700370505452156}, {"id": 107, "seek": 54280, "start": 565.8, "end": 570.8, "text": " but basically you have people going on the Julia repository and saying okay I", "tokens": [51514, 457, 1936, 291, 362, 561, 516, 322, 264, 18551, 25841, 293, 1566, 1392, 286, 51764], "temperature": 0.0, "avg_logprob": -0.16418388297965936, "compression_ratio": 1.7786259541984732, "no_speech_prob": 0.029700370505452156}, {"id": 108, "seek": 57080, "start": 570.8, "end": 575.7199999999999, "text": " have this problem I would like to I would like this bug to be fixed or they", "tokens": [50364, 362, 341, 1154, 286, 576, 411, 281, 286, 576, 411, 341, 7426, 281, 312, 6806, 420, 436, 50610], "temperature": 0.0, "avg_logprob": -0.10135030283511264, "compression_ratio": 1.865546218487395, "no_speech_prob": 0.04665273427963257}, {"id": 109, "seek": 57080, "start": 575.7199999999999, "end": 579.1999999999999, "text": " could say okay I have this idea of new feature could you guys do that is it", "tokens": [50610, 727, 584, 1392, 286, 362, 341, 1558, 295, 777, 4111, 727, 291, 1074, 360, 300, 307, 309, 50784], "temperature": 0.0, "avg_logprob": -0.10135030283511264, "compression_ratio": 1.865546218487395, "no_speech_prob": 0.04665273427963257}, {"id": 110, "seek": 57080, "start": 579.1999999999999, "end": 583.68, "text": " possible and basically you have the the actual people who work on the Julia", "tokens": [50784, 1944, 293, 1936, 291, 362, 264, 264, 3539, 561, 567, 589, 322, 264, 18551, 51008], "temperature": 0.0, "avg_logprob": -0.10135030283511264, "compression_ratio": 1.865546218487395, "no_speech_prob": 0.04665273427963257}, {"id": 111, "seek": 57080, "start": 583.68, "end": 588.7199999999999, "text": " project who who try to change those things which people are not happy with", "tokens": [51008, 1716, 567, 567, 853, 281, 1319, 729, 721, 597, 561, 366, 406, 2055, 365, 51260], "temperature": 0.0, "avg_logprob": -0.10135030283511264, "compression_ratio": 1.865546218487395, "no_speech_prob": 0.04665273427963257}, {"id": 112, "seek": 57080, "start": 588.7199999999999, "end": 595.3199999999999, "text": " that's one possibility another possibility is that someone says okay I", "tokens": [51260, 300, 311, 472, 7959, 1071, 7959, 307, 300, 1580, 1619, 1392, 286, 51590], "temperature": 0.0, "avg_logprob": -0.10135030283511264, "compression_ratio": 1.865546218487395, "no_speech_prob": 0.04665273427963257}, {"id": 113, "seek": 57080, "start": 595.3199999999999, "end": 599.64, "text": " have this issue could anyone fix it and it can also be anyone from the", "tokens": [51590, 362, 341, 2734, 727, 2878, 3191, 309, 293, 309, 393, 611, 312, 2878, 490, 264, 51806], "temperature": 0.0, "avg_logprob": -0.10135030283511264, "compression_ratio": 1.865546218487395, "no_speech_prob": 0.04665273427963257}, {"id": 114, "seek": 59964, "start": 599.64, "end": 604.08, "text": " community from the Julia community which I talked about before and just", "tokens": [50364, 1768, 490, 264, 18551, 1768, 597, 286, 2825, 466, 949, 293, 445, 50586], "temperature": 0.0, "avg_logprob": -0.12583456541362562, "compression_ratio": 1.815686274509804, "no_speech_prob": 0.02439294569194317}, {"id": 115, "seek": 59964, "start": 604.08, "end": 607.68, "text": " someone coming and saying hey I've got this bug this this fix I think it's it", "tokens": [50586, 1580, 1348, 293, 1566, 4177, 286, 600, 658, 341, 7426, 341, 341, 3191, 286, 519, 309, 311, 309, 50766], "temperature": 0.0, "avg_logprob": -0.12583456541362562, "compression_ratio": 1.815686274509804, "no_speech_prob": 0.02439294569194317}, {"id": 116, "seek": 59964, "start": 607.68, "end": 613.64, "text": " fix your bug and you ask it to be included in the new code and and so that", "tokens": [50766, 3191, 428, 7426, 293, 291, 1029, 309, 281, 312, 5556, 294, 264, 777, 3089, 293, 293, 370, 300, 51064], "temperature": 0.0, "avg_logprob": -0.12583456541362562, "compression_ratio": 1.815686274509804, "no_speech_prob": 0.02439294569194317}, {"id": 117, "seek": 59964, "start": 613.64, "end": 618.96, "text": " it fixes this bug for everyone not just not just you on your machine who managed", "tokens": [51064, 309, 32539, 341, 7426, 337, 1518, 406, 445, 406, 445, 291, 322, 428, 3479, 567, 6453, 51330], "temperature": 0.0, "avg_logprob": -0.12583456541362562, "compression_ratio": 1.815686274509804, "no_speech_prob": 0.02439294569194317}, {"id": 118, "seek": 59964, "start": 618.96, "end": 623.56, "text": " to fix it so this is the whole idea of open source it's a very beautiful thing", "tokens": [51330, 281, 3191, 309, 370, 341, 307, 264, 1379, 1558, 295, 1269, 4009, 309, 311, 257, 588, 2238, 551, 51560], "temperature": 0.0, "avg_logprob": -0.12583456541362562, "compression_ratio": 1.815686274509804, "no_speech_prob": 0.02439294569194317}, {"id": 119, "seek": 59964, "start": 623.56, "end": 628.92, "text": " if you're not familiar with it you can it's be careful it's addictive you just", "tokens": [51560, 498, 291, 434, 406, 4963, 365, 309, 291, 393, 309, 311, 312, 5026, 309, 311, 36486, 291, 445, 51828], "temperature": 0.0, "avg_logprob": -0.12583456541362562, "compression_ratio": 1.815686274509804, "no_speech_prob": 0.02439294569194317}, {"id": 120, "seek": 62892, "start": 628.92, "end": 633.7199999999999, "text": " start with it and and after a while you anything not open source you start", "tokens": [50364, 722, 365, 309, 293, 293, 934, 257, 1339, 291, 1340, 406, 1269, 4009, 291, 722, 50604], "temperature": 0.0, "avg_logprob": -0.20753760564894902, "compression_ratio": 1.7534883720930232, "no_speech_prob": 0.015821505337953568}, {"id": 121, "seek": 62892, "start": 633.7199999999999, "end": 638.24, "text": " having bad thoughts about it because it's the whole idea of free and open", "tokens": [50604, 1419, 1578, 4598, 466, 309, 570, 309, 311, 264, 1379, 1558, 295, 1737, 293, 1269, 50830], "temperature": 0.0, "avg_logprob": -0.20753760564894902, "compression_ratio": 1.7534883720930232, "no_speech_prob": 0.015821505337953568}, {"id": 122, "seek": 62892, "start": 638.24, "end": 644.8399999999999, "text": " sorry free and open source software is is really beautiful anyway talking about", "tokens": [50830, 2597, 1737, 293, 1269, 4009, 4722, 307, 307, 534, 2238, 4033, 1417, 466, 51160], "temperature": 0.0, "avg_logprob": -0.20753760564894902, "compression_ratio": 1.7534883720930232, "no_speech_prob": 0.015821505337953568}, {"id": 123, "seek": 62892, "start": 644.8399999999999, "end": 651.68, "text": " that they have this CI robustness so it's actually pretty related to that so", "tokens": [51160, 300, 436, 362, 341, 37777, 13956, 1287, 370, 309, 311, 767, 1238, 4077, 281, 300, 370, 51502], "temperature": 0.0, "avg_logprob": -0.20753760564894902, "compression_ratio": 1.7534883720930232, "no_speech_prob": 0.015821505337953568}, {"id": 124, "seek": 62892, "start": 651.68, "end": 656.1999999999999, "text": " basically they they had the tests so anytime someone makes this kind of", "tokens": [51502, 1936, 436, 436, 632, 264, 6921, 370, 13038, 1580, 1669, 341, 733, 295, 51728], "temperature": 0.0, "avg_logprob": -0.20753760564894902, "compression_ratio": 1.7534883720930232, "no_speech_prob": 0.015821505337953568}, {"id": 125, "seek": 65620, "start": 656.2, "end": 662.5600000000001, "text": " changes on the code so they say I've got this code it fixes whatever they have", "tokens": [50364, 2962, 322, 264, 3089, 370, 436, 584, 286, 600, 658, 341, 3089, 309, 32539, 2035, 436, 362, 50682], "temperature": 0.0, "avg_logprob": -0.12573260731167263, "compression_ratio": 1.8525896414342629, "no_speech_prob": 0.04081019386649132}, {"id": 126, "seek": 65620, "start": 662.5600000000001, "end": 665.5600000000001, "text": " to make it run through a couple tests to make sure that it's not breaking the", "tokens": [50682, 281, 652, 309, 1190, 807, 257, 1916, 6921, 281, 652, 988, 300, 309, 311, 406, 7697, 264, 50832], "temperature": 0.0, "avg_logprob": -0.12573260731167263, "compression_ratio": 1.8525896414342629, "no_speech_prob": 0.04081019386649132}, {"id": 127, "seek": 65620, "start": 665.5600000000001, "end": 668.5600000000001, "text": " whole system because you don't want to fix one bug and then break everything", "tokens": [50832, 1379, 1185, 570, 291, 500, 380, 528, 281, 3191, 472, 7426, 293, 550, 1821, 1203, 50982], "temperature": 0.0, "avg_logprob": -0.12573260731167263, "compression_ratio": 1.8525896414342629, "no_speech_prob": 0.04081019386649132}, {"id": 128, "seek": 65620, "start": 668.5600000000001, "end": 673.08, "text": " else right so that's what they had that's the problem they had so CI stands", "tokens": [50982, 1646, 558, 370, 300, 311, 437, 436, 632, 300, 311, 264, 1154, 436, 632, 370, 37777, 7382, 51208], "temperature": 0.0, "avg_logprob": -0.12573260731167263, "compression_ratio": 1.8525896414342629, "no_speech_prob": 0.04081019386649132}, {"id": 129, "seek": 65620, "start": 673.08, "end": 678.6800000000001, "text": " for continuous integration you can see here and basically they had a couple", "tokens": [51208, 337, 10957, 10980, 291, 393, 536, 510, 293, 1936, 436, 632, 257, 1916, 51488], "temperature": 0.0, "avg_logprob": -0.12573260731167263, "compression_ratio": 1.8525896414342629, "no_speech_prob": 0.04081019386649132}, {"id": 130, "seek": 65620, "start": 678.6800000000001, "end": 683.0, "text": " tests to make sure that everything was working fine with the new code which was", "tokens": [51488, 6921, 281, 652, 988, 300, 1203, 390, 1364, 2489, 365, 264, 777, 3089, 597, 390, 51704], "temperature": 0.0, "avg_logprob": -0.12573260731167263, "compression_ratio": 1.8525896414342629, "no_speech_prob": 0.04081019386649132}, {"id": 131, "seek": 68300, "start": 683.0, "end": 688.2, "text": " included in and and some of these tests if I understood correctly some of these", "tokens": [50364, 5556, 294, 293, 293, 512, 295, 613, 6921, 498, 286, 7320, 8944, 512, 295, 613, 50624], "temperature": 0.0, "avg_logprob": -0.17081484264797633, "compression_ratio": 1.8955223880597014, "no_speech_prob": 0.08137352764606476}, {"id": 132, "seek": 68300, "start": 688.2, "end": 693.44, "text": " sets always failed so now they if I understood correctly they're trying to", "tokens": [50624, 6352, 1009, 7612, 370, 586, 436, 498, 286, 7320, 8944, 436, 434, 1382, 281, 50886], "temperature": 0.0, "avg_logprob": -0.17081484264797633, "compression_ratio": 1.8955223880597014, "no_speech_prob": 0.08137352764606476}, {"id": 133, "seek": 68300, "start": 693.44, "end": 699.96, "text": " change the tests or make it so that the code can the review of the code in", "tokens": [50886, 1319, 264, 6921, 420, 652, 309, 370, 300, 264, 3089, 393, 264, 3131, 295, 264, 3089, 294, 51212], "temperature": 0.0, "avg_logprob": -0.17081484264797633, "compression_ratio": 1.8955223880597014, "no_speech_prob": 0.08137352764606476}, {"id": 134, "seek": 68300, "start": 699.96, "end": 707.04, "text": " order to include it in the in the whole Julia code this review is going to be", "tokens": [51212, 1668, 281, 4090, 309, 294, 264, 294, 264, 1379, 18551, 3089, 341, 3131, 307, 516, 281, 312, 51566], "temperature": 0.0, "avg_logprob": -0.17081484264797633, "compression_ratio": 1.8955223880597014, "no_speech_prob": 0.08137352764606476}, {"id": 135, "seek": 68300, "start": 707.04, "end": 711.28, "text": " made if not easier at least at least better that's going to improve those", "tokens": [51566, 1027, 498, 406, 3571, 412, 1935, 412, 1935, 1101, 300, 311, 516, 281, 3470, 729, 51778], "temperature": 0.0, "avg_logprob": -0.17081484264797633, "compression_ratio": 1.8955223880597014, "no_speech_prob": 0.08137352764606476}, {"id": 136, "seek": 71128, "start": 711.3199999999999, "end": 716.4399999999999, "text": " things so yeah obviously if we can have better review of code it means we can", "tokens": [50366, 721, 370, 1338, 2745, 498, 321, 393, 362, 1101, 3131, 295, 3089, 309, 1355, 321, 393, 50622], "temperature": 0.0, "avg_logprob": -0.15845839921818222, "compression_ratio": 1.7808219178082192, "no_speech_prob": 0.007101723924279213}, {"id": 137, "seek": 71128, "start": 716.4399999999999, "end": 722.12, "text": " have people including more code which maybe was not classified properly before", "tokens": [50622, 362, 561, 3009, 544, 3089, 597, 1310, 390, 406, 20627, 6108, 949, 50906], "temperature": 0.0, "avg_logprob": -0.15845839921818222, "compression_ratio": 1.7808219178082192, "no_speech_prob": 0.007101723924279213}, {"id": 138, "seek": 71128, "start": 722.12, "end": 726.1999999999999, "text": " so maybe they were saying nope sorry the code doesn't pass this this test and it", "tokens": [50906, 370, 1310, 436, 645, 1566, 23444, 2597, 264, 3089, 1177, 380, 1320, 341, 341, 1500, 293, 309, 51110], "temperature": 0.0, "avg_logprob": -0.15845839921818222, "compression_ratio": 1.7808219178082192, "no_speech_prob": 0.007101723924279213}, {"id": 139, "seek": 71128, "start": 726.1999999999999, "end": 729.8399999999999, "text": " should have passed the test and be included all the other way around so", "tokens": [51110, 820, 362, 4678, 264, 1500, 293, 312, 5556, 439, 264, 661, 636, 926, 370, 51292], "temperature": 0.0, "avg_logprob": -0.15845839921818222, "compression_ratio": 1.7808219178082192, "no_speech_prob": 0.007101723924279213}, {"id": 140, "seek": 71128, "start": 729.8399999999999, "end": 735.28, "text": " overall good testing is also part of the of the developing process and only with", "tokens": [51292, 4787, 665, 4997, 307, 611, 644, 295, 264, 295, 264, 6416, 1399, 293, 787, 365, 51564], "temperature": 0.0, "avg_logprob": -0.15845839921818222, "compression_ratio": 1.7808219178082192, "no_speech_prob": 0.007101723924279213}, {"id": 141, "seek": 73528, "start": 735.28, "end": 739.4, "text": " good testing can you can you have efficient contributions from the", "tokens": [50364, 665, 4997, 393, 291, 393, 291, 362, 7148, 15725, 490, 264, 50570], "temperature": 0.0, "avg_logprob": -0.18016831592846944, "compression_ratio": 1.7932692307692308, "no_speech_prob": 0.03886714577674866}, {"id": 142, "seek": 73528, "start": 739.4, "end": 746.9599999999999, "text": " community what else we got improved stack trace of formatting so yeah this is", "tokens": [50570, 1768, 437, 1646, 321, 658, 9689, 8630, 13508, 295, 39366, 370, 1338, 341, 307, 50948], "temperature": 0.0, "avg_logprob": -0.18016831592846944, "compression_ratio": 1.7932692307692308, "no_speech_prob": 0.03886714577674866}, {"id": 143, "seek": 73528, "start": 746.9599999999999, "end": 751.6, "text": " this is ugly right I mean you don't really know what's going on I mean it's", "tokens": [50948, 341, 307, 12246, 558, 286, 914, 291, 500, 380, 534, 458, 437, 311, 516, 322, 286, 914, 309, 311, 51180], "temperature": 0.0, "avg_logprob": -0.18016831592846944, "compression_ratio": 1.7932692307692308, "no_speech_prob": 0.03886714577674866}, {"id": 144, "seek": 73528, "start": 751.6, "end": 756.8, "text": " it's kind of the code you see in your in your shell in your terminal but it", "tokens": [51180, 309, 311, 733, 295, 264, 3089, 291, 536, 294, 428, 294, 428, 8720, 294, 428, 14709, 457, 309, 51440], "temperature": 0.0, "avg_logprob": -0.18016831592846944, "compression_ratio": 1.7932692307692308, "no_speech_prob": 0.03886714577674866}, {"id": 145, "seek": 73528, "start": 756.8, "end": 761.88, "text": " doesn't I mean to me you wouldn't mean much and this is the new trace so you", "tokens": [51440, 1177, 380, 286, 914, 281, 385, 291, 2759, 380, 914, 709, 293, 341, 307, 264, 777, 13508, 370, 291, 51694], "temperature": 0.0, "avg_logprob": -0.18016831592846944, "compression_ratio": 1.7932692307692308, "no_speech_prob": 0.03886714577674866}, {"id": 146, "seek": 76188, "start": 761.88, "end": 767.16, "text": " can see here all stack trace and this is the new stack trace and I mean it's", "tokens": [50364, 393, 536, 510, 439, 8630, 13508, 293, 341, 307, 264, 777, 8630, 13508, 293, 286, 914, 309, 311, 50628], "temperature": 0.0, "avg_logprob": -0.136894879133805, "compression_ratio": 1.7008928571428572, "no_speech_prob": 0.019405538216233253}, {"id": 147, "seek": 76188, "start": 767.16, "end": 774.36, "text": " just way clearer right it's so much more beautiful for me as someone outside of", "tokens": [50628, 445, 636, 26131, 558, 309, 311, 370, 709, 544, 2238, 337, 385, 382, 1580, 2380, 295, 50988], "temperature": 0.0, "avg_logprob": -0.136894879133805, "compression_ratio": 1.7008928571428572, "no_speech_prob": 0.019405538216233253}, {"id": 148, "seek": 76188, "start": 774.36, "end": 781.08, "text": " this like computer science community because I'm a mathematician this is", "tokens": [50988, 341, 411, 3820, 3497, 1768, 570, 286, 478, 257, 48281, 341, 307, 51324], "temperature": 0.0, "avg_logprob": -0.136894879133805, "compression_ratio": 1.7008928571428572, "no_speech_prob": 0.019405538216233253}, {"id": 149, "seek": 76188, "start": 781.08, "end": 785.84, "text": " way cleaner up this I can start wondering what's going on and look into my", "tokens": [51324, 636, 16532, 493, 341, 286, 393, 722, 6359, 437, 311, 516, 322, 293, 574, 666, 452, 51562], "temperature": 0.0, "avg_logprob": -0.136894879133805, "compression_ratio": 1.7008928571428572, "no_speech_prob": 0.019405538216233253}, {"id": 150, "seek": 76188, "start": 785.84, "end": 791.4, "text": " errors and try to to fix those errors before that it was it's not as clear I", "tokens": [51562, 13603, 293, 853, 281, 281, 3191, 729, 13603, 949, 300, 309, 390, 309, 311, 406, 382, 1850, 286, 51840], "temperature": 0.0, "avg_logprob": -0.136894879133805, "compression_ratio": 1.7008928571428572, "no_speech_prob": 0.019405538216233253}, {"id": 151, "seek": 79140, "start": 791.4, "end": 794.64, "text": " mean if you've got this you're not you're not gonna dive into it right I mean", "tokens": [50364, 914, 498, 291, 600, 658, 341, 291, 434, 406, 291, 434, 406, 799, 9192, 666, 309, 558, 286, 914, 50526], "temperature": 0.0, "avg_logprob": -0.13341491390960386, "compression_ratio": 1.8708133971291867, "no_speech_prob": 0.008152739144861698}, {"id": 152, "seek": 79140, "start": 794.64, "end": 800.72, "text": " personally it doesn't make me want to dive into that it's it's it's not clear", "tokens": [50526, 5665, 309, 1177, 380, 652, 385, 528, 281, 9192, 666, 300, 309, 311, 309, 311, 309, 311, 406, 1850, 50830], "temperature": 0.0, "avg_logprob": -0.13341491390960386, "compression_ratio": 1.8708133971291867, "no_speech_prob": 0.008152739144861698}, {"id": 153, "seek": 79140, "start": 800.72, "end": 806.64, "text": " it's kind of a mess and yeah this is this is way easier to dive in hopefully", "tokens": [50830, 309, 311, 733, 295, 257, 2082, 293, 1338, 341, 307, 341, 307, 636, 3571, 281, 9192, 294, 4696, 51126], "temperature": 0.0, "avg_logprob": -0.13341491390960386, "compression_ratio": 1.8708133971291867, "no_speech_prob": 0.008152739144861698}, {"id": 154, "seek": 79140, "start": 806.64, "end": 811.48, "text": " they I don't know if this new version of Julia is gonna improve that but hopefully", "tokens": [51126, 436, 286, 500, 380, 458, 498, 341, 777, 3037, 295, 18551, 307, 799, 3470, 300, 457, 4696, 51368], "temperature": 0.0, "avg_logprob": -0.13341491390960386, "compression_ratio": 1.8708133971291867, "no_speech_prob": 0.008152739144861698}, {"id": 155, "seek": 79140, "start": 811.48, "end": 817.48, "text": " they're gonna improve the errors they throw because sometimes I'm gonna say", "tokens": [51368, 436, 434, 799, 3470, 264, 13603, 436, 3507, 570, 2171, 286, 478, 799, 584, 51668], "temperature": 0.0, "avg_logprob": -0.13341491390960386, "compression_ratio": 1.8708133971291867, "no_speech_prob": 0.008152739144861698}, {"id": 156, "seek": 81748, "start": 817.48, "end": 822.5600000000001, "text": " they're not great you have errors and it's just telling you this not working", "tokens": [50364, 436, 434, 406, 869, 291, 362, 13603, 293, 309, 311, 445, 3585, 291, 341, 406, 1364, 50618], "temperature": 0.0, "avg_logprob": -0.1468681477485819, "compression_ratio": 1.7990654205607477, "no_speech_prob": 0.06356170773506165}, {"id": 157, "seek": 81748, "start": 822.5600000000001, "end": 827.52, "text": " and and you don't really know what to fix and hopefully they're gonna change up", "tokens": [50618, 293, 293, 291, 500, 380, 534, 458, 437, 281, 3191, 293, 4696, 436, 434, 799, 1319, 493, 50866], "temperature": 0.0, "avg_logprob": -0.1468681477485819, "compression_ratio": 1.7990654205607477, "no_speech_prob": 0.06356170773506165}, {"id": 158, "seek": 81748, "start": 827.52, "end": 832.08, "text": " because because it's really hard to debug your code if you don't have the", "tokens": [50866, 570, 570, 309, 311, 534, 1152, 281, 24083, 428, 3089, 498, 291, 500, 380, 362, 264, 51094], "temperature": 0.0, "avg_logprob": -0.1468681477485819, "compression_ratio": 1.7990654205607477, "no_speech_prob": 0.06356170773506165}, {"id": 159, "seek": 81748, "start": 832.08, "end": 837.6, "text": " proper errors being thrown so hopefully this fixes this issue as well I don't", "tokens": [51094, 2296, 13603, 885, 11732, 370, 4696, 341, 32539, 341, 2734, 382, 731, 286, 500, 380, 51370], "temperature": 0.0, "avg_logprob": -0.1468681477485819, "compression_ratio": 1.7990654205607477, "no_speech_prob": 0.06356170773506165}, {"id": 160, "seek": 81748, "start": 837.6, "end": 843.88, "text": " know if it goes that deep or I hope it's not just the the formatting and the", "tokens": [51370, 458, 498, 309, 1709, 300, 2452, 420, 286, 1454, 309, 311, 406, 445, 264, 264, 39366, 293, 264, 51684], "temperature": 0.0, "avg_logprob": -0.1468681477485819, "compression_ratio": 1.7990654205607477, "no_speech_prob": 0.06356170773506165}, {"id": 161, "seek": 84388, "start": 844.64, "end": 852.6, "text": " prettiness of the the error thrown but yeah we shall see only only after coding", "tokens": [50402, 45421, 1324, 295, 264, 264, 6713, 11732, 457, 1338, 321, 4393, 536, 787, 787, 934, 17720, 50800], "temperature": 0.0, "avg_logprob": -0.16535613271925184, "compression_ratio": 1.8150289017341041, "no_speech_prob": 0.013389110565185547}, {"id": 162, "seek": 84388, "start": 852.6, "end": 857.6, "text": " only after testing out the code you can you can decide whether you think that", "tokens": [50800, 787, 934, 4997, 484, 264, 3089, 291, 393, 291, 393, 4536, 1968, 291, 519, 300, 51050], "temperature": 0.0, "avg_logprob": -0.16535613271925184, "compression_ratio": 1.8150289017341041, "no_speech_prob": 0.013389110565185547}, {"id": 163, "seek": 84388, "start": 857.6, "end": 863.12, "text": " the errors are good or bad and if they actually give you information about what", "tokens": [51050, 264, 13603, 366, 665, 420, 1578, 293, 498, 436, 767, 976, 291, 1589, 466, 437, 51326], "temperature": 0.0, "avg_logprob": -0.16535613271925184, "compression_ratio": 1.8150289017341041, "no_speech_prob": 0.013389110565185547}, {"id": 164, "seek": 84388, "start": 863.12, "end": 870.64, "text": " the error is okay yeah so yeah it seems it seems like they're actually doing", "tokens": [51326, 264, 6713, 307, 1392, 1338, 370, 1338, 309, 2544, 309, 2544, 411, 436, 434, 767, 884, 51702], "temperature": 0.0, "avg_logprob": -0.16535613271925184, "compression_ratio": 1.8150289017341041, "no_speech_prob": 0.013389110565185547}, {"id": 165, "seek": 87064, "start": 870.64, "end": 874.8, "text": " that are gonna things are in methods are now shown which is great if you don't", "tokens": [50364, 300, 366, 799, 721, 366, 294, 7150, 366, 586, 4898, 597, 307, 869, 498, 291, 500, 380, 50572], "temperature": 0.0, "avg_logprob": -0.18341000245349243, "compression_ratio": 1.8658536585365855, "no_speech_prob": 0.09781985729932785}, {"id": 166, "seek": 87064, "start": 874.8, "end": 880.12, "text": " even know which method your has an error that's impossible to debug the function", "tokens": [50572, 754, 458, 597, 3170, 428, 575, 364, 6713, 300, 311, 6243, 281, 24083, 264, 2445, 50838], "temperature": 0.0, "avg_logprob": -0.18341000245349243, "compression_ratio": 1.8658536585365855, "no_speech_prob": 0.09781985729932785}, {"id": 167, "seek": 87064, "start": 880.12, "end": 884.28, "text": " name was made to be more emphasized yes yes so this is probably just some", "tokens": [50838, 1315, 390, 1027, 281, 312, 544, 34068, 2086, 2086, 370, 341, 307, 1391, 445, 512, 51046], "temperature": 0.0, "avg_logprob": -0.18341000245349243, "compression_ratio": 1.8658536585365855, "no_speech_prob": 0.09781985729932785}, {"id": 168, "seek": 87064, "start": 884.28, "end": 890.36, "text": " formatting things which is great obviously it's helping you through your", "tokens": [51046, 39366, 721, 597, 307, 869, 2745, 309, 311, 4315, 291, 807, 428, 51350], "temperature": 0.0, "avg_logprob": -0.18341000245349243, "compression_ratio": 1.8658536585365855, "no_speech_prob": 0.09781985729932785}, {"id": 169, "seek": 87064, "start": 890.36, "end": 894.4399999999999, "text": " developing process and and through your coding in general so that's that's", "tokens": [51350, 6416, 1399, 293, 293, 807, 428, 17720, 294, 2674, 370, 300, 311, 300, 311, 51554], "temperature": 0.0, "avg_logprob": -0.18341000245349243, "compression_ratio": 1.8658536585365855, "no_speech_prob": 0.09781985729932785}, {"id": 170, "seek": 87064, "start": 894.4399999999999, "end": 899.88, "text": " awesome the modules were the modules where the method is defined is now shown", "tokens": [51554, 3476, 264, 16679, 645, 264, 16679, 689, 264, 3170, 307, 7642, 307, 586, 4898, 51826], "temperature": 0.0, "avg_logprob": -0.18341000245349243, "compression_ratio": 1.8658536585365855, "no_speech_prob": 0.09781985729932785}, {"id": 171, "seek": 89988, "start": 899.92, "end": 904.36, "text": " that's great just basically just give me more information that's all I want and", "tokens": [50366, 300, 311, 869, 445, 1936, 445, 976, 385, 544, 1589, 300, 311, 439, 286, 528, 293, 50588], "temperature": 0.0, "avg_logprob": -0.16717080319865366, "compression_ratio": 1.7453703703703705, "no_speech_prob": 0.011305255815386772}, {"id": 172, "seek": 89988, "start": 904.36, "end": 909.4399999999999, "text": " anything going in that direction like those things which seem to be that I'm", "tokens": [50588, 1340, 516, 294, 300, 3513, 411, 729, 721, 597, 1643, 281, 312, 300, 286, 478, 50842], "temperature": 0.0, "avg_logprob": -0.16717080319865366, "compression_ratio": 1.7453703703703705, "no_speech_prob": 0.011305255815386772}, {"id": 173, "seek": 89988, "start": 909.4399999999999, "end": 914.08, "text": " all for it I'm all for it and please enjoy the release that's probably the", "tokens": [50842, 439, 337, 309, 286, 478, 439, 337, 309, 293, 1767, 2103, 264, 4374, 300, 311, 1391, 264, 51074], "temperature": 0.0, "avg_logprob": -0.16717080319865366, "compression_ratio": 1.7453703703703705, "no_speech_prob": 0.011305255815386772}, {"id": 174, "seek": 89988, "start": 914.08, "end": 921.52, "text": " most important phrase right so and yeah let us know so they're very open to to", "tokens": [51074, 881, 1021, 9535, 558, 370, 293, 1338, 718, 505, 458, 370, 436, 434, 588, 1269, 281, 281, 51446], "temperature": 0.0, "avg_logprob": -0.16717080319865366, "compression_ratio": 1.7453703703703705, "no_speech_prob": 0.011305255815386772}, {"id": 175, "seek": 89988, "start": 921.52, "end": 929.08, "text": " new ideas and and just people contributing and telling them what's", "tokens": [51446, 777, 3487, 293, 293, 445, 561, 19270, 293, 3585, 552, 437, 311, 51824], "temperature": 0.0, "avg_logprob": -0.16717080319865366, "compression_ratio": 1.7453703703703705, "no_speech_prob": 0.011305255815386772}, {"id": 176, "seek": 92908, "start": 929.12, "end": 932.6800000000001, "text": " going on and what's not working so without we're gonna we're gonna bring", "tokens": [50366, 516, 322, 293, 437, 311, 406, 1364, 370, 1553, 321, 434, 799, 321, 434, 799, 1565, 50544], "temperature": 0.0, "avg_logprob": -0.16068699048913043, "compression_ratio": 1.8955223880597014, "no_speech_prob": 0.04324285313487053}, {"id": 177, "seek": 92908, "start": 932.6800000000001, "end": 939.24, "text": " the video to a close thank you for for for watching it if you have any any", "tokens": [50544, 264, 960, 281, 257, 1998, 1309, 291, 337, 337, 337, 1976, 309, 498, 291, 362, 604, 604, 50872], "temperature": 0.0, "avg_logprob": -0.16068699048913043, "compression_ratio": 1.8955223880597014, "no_speech_prob": 0.04324285313487053}, {"id": 178, "seek": 92908, "start": 939.24, "end": 946.76, "text": " comment anything I missed you can you can let me know in the comments if you if", "tokens": [50872, 2871, 1340, 286, 6721, 291, 393, 291, 393, 718, 385, 458, 294, 264, 3053, 498, 291, 498, 51248], "temperature": 0.0, "avg_logprob": -0.16068699048913043, "compression_ratio": 1.8955223880597014, "no_speech_prob": 0.04324285313487053}, {"id": 179, "seek": 92908, "start": 946.76, "end": 949.64, "text": " you haven't already you can subscribe you can like the video that would be that", "tokens": [51248, 291, 2378, 380, 1217, 291, 393, 3022, 291, 393, 411, 264, 960, 300, 576, 312, 300, 51392], "temperature": 0.0, "avg_logprob": -0.16068699048913043, "compression_ratio": 1.8955223880597014, "no_speech_prob": 0.04324285313487053}, {"id": 180, "seek": 92908, "start": 949.64, "end": 956.2800000000001, "text": " would be awesome and with that we'll see you next time thanks for joining", "tokens": [51392, 576, 312, 3476, 293, 365, 300, 321, 603, 536, 291, 958, 565, 3231, 337, 5549, 51724], "temperature": 0.0, "avg_logprob": -0.16068699048913043, "compression_ratio": 1.8955223880597014, "no_speech_prob": 0.04324285313487053}, {"id": 181, "seek": 95908, "start": 959.08, "end": 962.1, "text": " you", "tokens": [50412, 291, 50515], "temperature": 0.0, "avg_logprob": -0.8398641347885132, "compression_ratio": 0.2727272727272727, "no_speech_prob": 0.6369263529777527}], "language": "en"}