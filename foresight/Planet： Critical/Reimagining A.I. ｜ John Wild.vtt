WEBVTT

00:00.000 --> 00:04.720
The stated aim of a company like OpenAI

00:04.720 --> 00:08.240
is the development of artificial general intelligence.

00:08.240 --> 00:10.640
Now, artificial general intelligence

00:10.640 --> 00:15.160
is in Google AI terms,

00:15.160 --> 00:17.000
the equivalent of human intelligence.

00:17.000 --> 00:19.440
What I kind of want to point out here,

00:19.440 --> 00:22.920
when you look at what a general intelligence is,

00:22.920 --> 00:26.320
then that's actually rooted in Charles Spearman

00:26.320 --> 00:28.000
and the idea of the G factor.

00:28.000 --> 00:31.560
But Charles Spearman was a hygienicist.

00:31.560 --> 00:35.560
And his reason for developing this ranking

00:35.560 --> 00:39.360
of general intelligence was to rank human intelligence

00:39.360 --> 00:41.360
for selective breeding, et cetera.

00:41.360 --> 00:46.000
So you've got this drive for artificial general intelligence.

00:46.000 --> 00:49.200
But when you actually work out what general intelligence is,

00:49.200 --> 00:51.760
it's got some very, very dark histories.

00:52.400 --> 00:58.520
Hello and welcome to Planet Critical,

00:58.520 --> 01:00.960
the podcast for a world in crisis.

01:00.960 --> 01:02.240
My name is Rachel Donald.

01:02.240 --> 01:04.800
I'm a climate corruption journalist and your host.

01:04.800 --> 01:06.360
Every week, I interview experts

01:06.360 --> 01:08.480
who are battling to save our planet.

01:08.480 --> 01:11.360
My guests are scientists, politicians, academics,

01:11.360 --> 01:13.280
journalists and activists.

01:13.280 --> 01:15.840
They explain the complexities of the energy,

01:15.840 --> 01:19.640
economic, political and cultural crises we face today,

01:19.640 --> 01:21.400
revealing what's really going on

01:21.440 --> 01:23.600
and what they think needs to be done.

01:23.600 --> 01:26.120
These are the stories of the big picture.

01:26.120 --> 01:29.640
Go to planetcritical.com to learn more and subscribe.

01:29.640 --> 01:31.960
My guest this week is John Wilde.

01:31.960 --> 01:33.520
John is a London-based artist

01:33.520 --> 01:36.480
who works across performance, sound, text, code,

01:36.480 --> 01:38.240
electronics and machine learning

01:38.240 --> 01:39.920
to research the future's imminent

01:39.920 --> 01:41.520
within digital technology.

01:41.520 --> 01:43.480
John joined me today to talk about

01:43.480 --> 01:46.040
culture and artificial intelligence,

01:46.040 --> 01:50.160
how the stories we tell ourselves inform our technologies

01:50.200 --> 01:52.480
and then how those technologies inform the stories

01:52.480 --> 01:53.560
we tell ourselves,

01:53.560 --> 01:56.760
getting caught in these kinds of circular loops essentially,

01:56.760 --> 01:58.280
which make it increasingly difficult

01:58.280 --> 02:00.080
to imagine a different way of being.

02:00.080 --> 02:02.120
John talks about this in relationship

02:02.120 --> 02:03.840
to artificial intelligence.

02:03.840 --> 02:05.840
Artificial intelligence is an incredibly

02:05.840 --> 02:07.480
energy-hungry technology.

02:07.480 --> 02:10.080
It is being used for profit motives.

02:10.080 --> 02:11.680
We have very little understanding

02:11.680 --> 02:14.360
of what it could do when unleashed upon the world

02:14.360 --> 02:17.160
and at the moment, all it's doing is threatening jobs

02:17.160 --> 02:19.360
rather than creating new ways of being.

02:19.360 --> 02:21.360
John's research shows what we could do

02:21.360 --> 02:24.360
if we imagined using mycelium as a framework

02:24.360 --> 02:28.000
for developing something decentralized, interconnected,

02:28.000 --> 02:30.280
entangled and symbiotic.

02:30.280 --> 02:33.280
To begin with, John explains the history of thinking

02:33.280 --> 02:34.680
and artificial intelligence.

02:34.680 --> 02:38.320
How Silicon Valley is infused with theories and stories

02:38.320 --> 02:40.920
that came out of Russia in the late 19th century.

02:40.920 --> 02:44.680
The desire to pollinate the universe with consciousness,

02:44.680 --> 02:47.000
creating a hierarchy of consciousness,

02:47.000 --> 02:50.280
as if humanity is the only thing that is truly conscious

02:50.280 --> 02:52.040
or would be able to do such a thing

02:52.040 --> 02:54.600
as if the universe isn't already conscious.

02:54.600 --> 02:56.680
And he also explains how this hierarchy

02:56.680 --> 02:58.920
of consciousness or intelligence

02:58.920 --> 03:00.240
that is directing Silicon Valley

03:00.240 --> 03:02.120
to make an artificial general intelligence

03:02.120 --> 03:04.360
comes out of eugenicist thinking.

03:04.360 --> 03:06.480
This is such a fascinating conversation.

03:06.480 --> 03:08.400
We had so much fun recording this.

03:08.400 --> 03:09.960
I knew a fair bit about AI

03:09.960 --> 03:12.360
thanks to research into the effective altruist movement,

03:12.360 --> 03:14.720
but I did not know the history that John lays out today.

03:14.720 --> 03:16.080
And understanding more of that history

03:16.080 --> 03:17.320
makes me really grateful

03:17.320 --> 03:19.560
that people like him and artists around the world

03:19.560 --> 03:21.080
and technologists around the world

03:21.080 --> 03:23.640
are trying to think about how to develop permacomputing

03:23.640 --> 03:25.280
or the wood-wide web,

03:25.280 --> 03:29.120
collaborative, interdependent, entangled projects

03:29.120 --> 03:31.880
that reflect the intelligence and harmony

03:31.880 --> 03:33.600
of natural ecosystems

03:33.600 --> 03:35.680
in order for us all to live more sustainably

03:35.680 --> 03:36.520
with one another.

03:36.520 --> 03:38.120
And we end our conversation with a dialogue

03:38.120 --> 03:39.600
on exactly that.

03:39.600 --> 03:41.240
What is sustainable computing

03:41.240 --> 03:43.480
and what is sustainability more widely?

03:43.480 --> 03:45.080
I hope you all enjoy the episode.

03:45.160 --> 03:47.480
If you do, please share it far and wide.

03:47.480 --> 03:48.680
And if you're loving the show,

03:48.680 --> 03:50.600
become a patron on Patreon

03:50.600 --> 03:51.800
or support Planet Critical

03:51.800 --> 03:55.040
with a paid subscription at planetcritical.com.

03:55.040 --> 03:57.360
By signing up, you'll get the Planet Critical newsletter

03:57.360 --> 03:58.800
inspired by each episode

03:58.800 --> 04:01.040
delivered straight to your inbox every week.

04:01.040 --> 04:02.200
You'll also have access

04:02.200 --> 04:04.640
to the wonderful Planet Critical community

04:04.640 --> 04:08.400
who are full of inspiring thoughts, ideas, critiques

04:08.400 --> 04:09.960
and determination.

04:09.960 --> 04:11.920
The links are in the description box below.

04:11.920 --> 04:13.600
I'm so grateful to everyone

04:13.600 --> 04:15.200
who chooses to support the project.

04:15.200 --> 04:16.720
I'm a vehement believer in ad-free

04:16.720 --> 04:18.160
and open-access content,

04:18.160 --> 04:19.840
so Planet Critical wouldn't exist

04:19.840 --> 04:22.760
without the direct support of the amazing community.

04:22.760 --> 04:24.520
Thank you so much to all of you

04:24.520 --> 04:26.320
who believe in Planet Critical

04:26.320 --> 04:28.360
and keep the project going every week.

04:28.360 --> 04:29.680
John, thank you very much for joining me

04:29.680 --> 04:30.520
on Planet Critical.

04:30.520 --> 04:32.600
It is a pleasure to have you on the show.

04:32.600 --> 04:34.200
Well, thank you for inviting me.

04:35.600 --> 04:36.440
Happy to.

04:36.440 --> 04:38.040
As I was saying before we started recording it,

04:38.040 --> 04:39.520
such an interesting conversation with Maggie

04:39.520 --> 04:40.560
who platformed you.

04:41.560 --> 04:44.240
And I think that speaking with artists

04:44.240 --> 04:45.760
is a really critical component

04:45.760 --> 04:48.480
to understanding what the hell is going on in the world

04:48.480 --> 04:51.160
and what we can do about it,

04:51.160 --> 04:53.000
which leads me to my first question.

04:53.000 --> 04:54.800
Why is the world in crisis?

04:56.640 --> 04:58.240
That's such a big question, isn't it?

04:58.240 --> 04:59.080
I know.

05:00.840 --> 05:04.080
I mean, I'm going to start with a report

05:04.080 --> 05:07.440
which was out last week, which really struck me.

05:07.680 --> 05:12.680
So I read an article by Duncan Agnew in Nature Magazine,

05:13.040 --> 05:14.680
which suggested that climate change

05:14.680 --> 05:17.120
is having an effect on universal timekeeping.

05:18.240 --> 05:19.080
What?

05:19.080 --> 05:22.640
So Coordinated Universal Time, or UTC,

05:22.640 --> 05:24.360
is the primary time standard

05:24.360 --> 05:26.360
globally used to regulate clocks.

05:27.360 --> 05:30.880
So UTC closely follows the rotation of the Earth.

05:32.120 --> 05:35.960
But accelerating melt from Greenland and Antarctica

05:35.960 --> 05:40.360
is adding extra water to the world's sea.

05:40.360 --> 05:43.080
It's redistributing mass around the globe,

05:43.080 --> 05:45.320
and that's causing a very slight slowing

05:45.320 --> 05:46.680
in the Earth's rotation.

05:48.280 --> 05:53.160
And if you combine that with what we know

05:53.160 --> 05:57.440
about the shift in the Earth's poles.

05:57.440 --> 06:00.040
So since the 1980s, it's been shown

06:00.040 --> 06:02.240
that the massive melting of glaciers

06:02.240 --> 06:05.000
as a result of global heating

06:05.000 --> 06:09.600
has caused a shift in the Earth's axis of around four metres.

06:09.600 --> 06:13.440
So I think if we think about this question,

06:13.440 --> 06:15.040
the shifting of the Earth's axis

06:15.040 --> 06:17.840
and the slowing of the Earth's orientation

06:17.840 --> 06:22.680
mark both an impressive, to be honest,

06:22.680 --> 06:26.360
but terrifying achievement of human,

06:26.360 --> 06:28.920
global, well, geoengineering.

06:28.920 --> 06:33.280
The impact that we've had as basically fundamentally

06:33.280 --> 06:37.200
has shifted time and the axis of the Earth.

06:37.200 --> 06:40.960
And that seems to be the ultimate mark of the amphipersine.

06:40.960 --> 06:43.680
But I think what troubles me with this,

06:43.680 --> 06:45.280
well, I mean, there's lots of things

06:45.280 --> 06:47.240
which troubles me with this,

06:47.240 --> 06:50.440
but such a feat could only be the outcome

06:50.440 --> 06:54.200
of sustained and coordinated human action and interaction.

06:55.200 --> 06:57.760
Yet no one's planned, organised,

06:57.760 --> 07:01.280
voted for, or even imagined such a venture.

07:04.280 --> 07:06.320
And I kind of wanted to start this conversation

07:06.320 --> 07:11.800
with a kind of provocation which comes from my own research.

07:13.480 --> 07:17.680
My own research is looking at artificial intelligence,

07:17.680 --> 07:20.440
specifically narratives around artificial intelligence.

07:22.040 --> 07:23.880
But what is the coordinating force

07:23.880 --> 07:26.440
that's playing a role here?

07:26.440 --> 07:29.720
And I think the provocation that I want to put forward

07:29.720 --> 07:33.200
is that it's a non-conscious intelligence.

07:33.200 --> 07:35.960
Or an artificial intelligence that we call the market.

07:37.120 --> 07:41.080
I think the market struck producers emergent forms,

07:41.080 --> 07:44.960
which you could call a form of non-conscious intelligence.

07:44.960 --> 07:47.440
Yeah, I totally agree.

07:49.280 --> 07:51.440
What a way to kick us off, by the way.

07:52.720 --> 07:54.400
Wow, I didn't know that,

07:54.400 --> 07:57.680
but climate change has been an impact

07:57.680 --> 07:59.680
on universal timekeeping.

07:59.680 --> 08:02.360
I was thinking about this question that you asked

08:02.360 --> 08:06.960
as this appeared in my feed, and I'm like, wow.

08:06.960 --> 08:11.240
But not only that, it's that universal time,

08:11.240 --> 08:16.240
it affects computing because the computer programmes

08:16.760 --> 08:21.000
made to keep track of universal time

08:21.000 --> 08:25.160
are going to struggle with this slowing down of the Earth.

08:25.160 --> 08:27.280
So it kind of comes into the territory

08:27.280 --> 08:29.560
that I'm also interested in, in a way.

08:32.960 --> 08:34.400
There's so much there, isn't there?

08:34.400 --> 08:39.400
Like the idea of having a human system

08:39.480 --> 08:42.080
mapped onto a natural system,

08:42.080 --> 08:45.320
the human system impacting the natural system,

08:45.320 --> 08:46.560
and then the natural system,

08:46.560 --> 08:50.800
and then being unable to deal with the fallout,

08:50.800 --> 08:52.160
to deal with the consequences,

08:52.160 --> 08:54.680
to understand even the new reality,

08:54.680 --> 08:59.040
because the limits of that system were so fixed and rigid,

08:59.040 --> 09:04.040
which is kind of a really classic feature of modernity.

09:05.040 --> 09:07.480
Like there just being no flexibility.

09:09.160 --> 09:12.800
And then watching reality as we understand it,

09:12.800 --> 09:15.800
just kind of peel away in that moment,

09:15.800 --> 09:17.400
because the systems aren't built for it.

09:17.400 --> 09:21.600
So it really reveals this thread of domination

09:21.600 --> 09:24.920
that runs through modernity, like domination over nature.

09:25.920 --> 09:29.400
It doesn't work, the domination over ourselves.

09:29.400 --> 09:30.640
It just doesn't work.

09:30.640 --> 09:34.600
There is a, it's brittle and it's fragile and it will snap

09:34.600 --> 09:39.040
if it's met with enough kind of shifting, evolving resistance.

09:39.880 --> 09:42.720
I guess the challenge that we have

09:42.720 --> 09:45.760
is if we understand this as a form of,

09:45.760 --> 09:47.120
or if we understand the market

09:47.120 --> 09:50.480
that produces these kind of emergent forms,

09:51.760 --> 09:53.480
as a kind of structural system

09:53.480 --> 09:58.800
that has an intelligence that structures human activity, et cetera.

09:58.800 --> 10:01.520
How do we, how do we move beyond that?

10:01.520 --> 10:06.160
How do we imagine futures, which are structured a different way?

10:06.160 --> 10:10.200
How do we imagine technologies, which are,

10:12.440 --> 10:16.080
which behave in a different way, which are sustainable?

10:19.160 --> 10:23.280
My own research actually looks at the kind of imaginaries

10:23.280 --> 10:25.400
around artificial intelligence.

10:25.400 --> 10:30.320
And I think they can tell us quite a lot really about why we end up

10:32.200 --> 10:35.920
kind of looking to the stars rather than looking to the soil,

10:35.920 --> 10:38.160
rather than looking to the earth.

10:39.360 --> 10:41.360
That's beautiful.

10:44.080 --> 10:47.800
On this artificial intelligence,

10:49.880 --> 10:52.200
I mean, this is kind of what Hayek spoke about as well.

10:52.760 --> 10:55.920
The invisible hand of the market directing people.

10:58.160 --> 11:00.760
The sort of godfather of neoliberalism, essentially.

11:01.520 --> 11:03.720
And yes.

11:03.720 --> 11:09.200
I think you were Smith as well, weren't you, in the wealth of nations?

11:09.200 --> 11:13.800
I think Smith initiated it, and then people kind of took on this idea.

11:13.800 --> 11:15.920
But yeah, the idea of the invisible hand.

11:16.680 --> 11:17.880
Which is interesting, isn't it?

11:17.920 --> 11:24.080
Because there's a concept there of this physical thing being shaped.

11:24.080 --> 11:26.520
But they weren't talking about a brain.

11:26.520 --> 11:29.080
They weren't talking about the invisible brain.

11:29.080 --> 11:32.160
Whereas what is directing that hand to move?

11:32.160 --> 11:34.560
The idea is that it would respond to needs or whatever.

11:34.560 --> 11:37.480
And it's obvious that's obviously not been the case.

11:37.480 --> 11:42.640
Like we've sort of created a system that is impacted,

11:42.640 --> 11:46.320
but also impact its environment around it as it accumulates more

11:46.360 --> 11:49.360
historical precedent and knowledge.

11:49.760 --> 11:54.000
And it's just embodied really with historicity, you might say.

11:55.160 --> 11:58.440
Kind of like self-perpetuate itself and grows and grows and grows.

11:58.920 --> 12:02.000
Well, I think that self-perpetuation is the thing.

12:02.360 --> 12:06.440
I think where this kind of connects with the kind of research

12:06.440 --> 12:09.920
that I do on artificial intelligence, it's kind of like looking at what

12:09.920 --> 12:13.360
intelligence is in some sort of way.

12:13.920 --> 12:18.760
And obviously with the kind of common sense for you is this kind of

12:18.760 --> 12:24.480
conscious intelligence, the kind of the human conscious intelligence.

12:24.760 --> 12:28.840
But conscious intelligence is very rare in the world.

12:29.800 --> 12:31.840
Most forms of intelligence that would come across

12:31.840 --> 12:34.600
are a form of non-conscious intelligence.

12:35.240 --> 12:38.160
So this is kind of sensing and acting on the world

12:38.160 --> 12:40.920
in a way that produces very complex outcomes.

12:41.720 --> 12:46.560
But but don't don't have but don't have at the car this kind of

12:46.560 --> 12:51.440
conscious drive that maybe maybe language produces in humans.

12:52.160 --> 12:54.240
OK, and we pause there.

12:54.240 --> 12:57.480
Yeah. So conscious intelligence is rare in the world,

12:57.920 --> 13:00.240
but this unconscious intelligence is sensed.

13:00.240 --> 13:02.560
Is that the word you used?

13:02.560 --> 13:06.680
Well, I'm saying that for something to act, for something to act,

13:06.680 --> 13:09.400
there's some sort of sensing, some sort of information.

13:10.320 --> 13:13.240
And then there's a behavior that responds to that,

13:14.440 --> 13:16.440
which produces complex outcomes.

13:16.640 --> 13:19.440
So I'm thinking I'm thinking as a good example,

13:19.440 --> 13:23.160
or an example is quite often used as a slime mold.

13:24.000 --> 13:27.400
And in my own practice, we've also been using mycelium,

13:27.400 --> 13:29.880
but slime mode is quite a common one.

13:30.440 --> 13:35.240
So slime mode is a single celled algorithm organism,

13:36.040 --> 13:40.680
which it basically produces filaments

13:40.680 --> 13:43.320
which stretch out to find food in all directions.

13:43.320 --> 13:45.800
And then when it finds finds food,

13:45.800 --> 13:49.200
it solidifies the filaments that is produced.

13:50.240 --> 13:54.920
And it's it's been used to mimic the Tokyo.

13:56.760 --> 13:58.240
Tube map.

13:58.240 --> 14:04.240
So the Tokyo tube because of the kind of geology of the area, etc.

14:05.520 --> 14:08.440
The planning of it is there's quite a lot of complexity

14:08.440 --> 14:11.480
to how to produce the most direct routes.

14:12.320 --> 14:16.280
But by by creating an artificial map of the tube

14:16.280 --> 14:19.400
using the food for the slime mold,

14:20.280 --> 14:22.320
the slime mold managed to

14:23.560 --> 14:25.800
calculate the most direct routes,

14:25.800 --> 14:31.240
which pretty much mimic the the actual Tokyo underground.

14:31.680 --> 14:34.280
So that's that's the way that you could see

14:34.280 --> 14:38.440
that there's a non-conscious intelligence working.

14:39.280 --> 14:43.560
And NASA has used exactly the same model to map

14:43.560 --> 14:47.200
to map the dark matter that holds together the universe.

14:47.720 --> 14:50.880
So these kind of intelligences,

14:50.880 --> 14:53.360
which aren't a model of conscious intelligence,

14:54.480 --> 14:58.120
still produce very complex behavior in the world.

14:58.560 --> 15:00.480
And I'd go.

15:00.520 --> 15:02.680
Sorry, it's just I suppose I'm getting stuck

15:02.680 --> 15:06.000
on this conscious unconscious binary.

15:07.760 --> 15:10.800
Because what we're talking about then

15:10.800 --> 15:12.960
when we talk about consciousness,

15:12.960 --> 15:15.360
because there's quite a lot of, you know,

15:15.360 --> 15:17.240
stuff now coming out of physics

15:17.240 --> 15:19.360
and other sort of theories that suggest that,

15:19.880 --> 15:22.240
well, everything is just consciousness

15:22.240 --> 15:26.040
and that perhaps it's consciousness that predates matter.

15:26.560 --> 15:28.680
And thus, you know, perhaps the slime mold

15:28.720 --> 15:31.400
doesn't have a brain in the way that we

15:31.400 --> 15:32.400
well, definitely doesn't, right?

15:32.400 --> 15:33.400
It's one cell.

15:34.640 --> 15:38.280
But that doesn't necessarily mean it's it's not conscious.

15:38.560 --> 15:40.440
Like, I guess I'm concerned.

15:40.440 --> 15:41.600
Yeah, I agree.

15:41.600 --> 15:43.600
I agree.

15:43.600 --> 15:44.240
I agree.

15:44.240 --> 15:46.480
And it's exactly the hierarchy of consciousness,

15:46.480 --> 15:48.280
which I want to break down.

15:48.280 --> 15:49.080
Right.

15:49.080 --> 15:55.040
I mean, I'm using the term conscious in this way.

15:56.040 --> 16:01.360
As a relationship to language and the the modelling

16:02.360 --> 16:04.760
of the world as an abstract ship.

16:05.680 --> 16:08.520
Of which then things are planned.

16:08.520 --> 16:10.640
But I don't believe this is how humans behave.

16:10.640 --> 16:14.240
I think humans, the vast majority of human activity

16:14.240 --> 16:15.760
is non-conscious.

16:16.880 --> 16:19.800
Like, ride a bike, you don't have to do

16:19.800 --> 16:23.920
with the mathematical calculations to stay on the bike

16:24.800 --> 16:26.840
and direct and route, et cetera.

16:27.680 --> 16:30.760
I think the vast majority of action is non-conscious.

16:32.040 --> 16:34.880
But wouldn't that suggest then that consciousness

16:34.880 --> 16:39.320
is only these kind of consciousness is language

16:39.320 --> 16:41.720
because mass, for example, could be, you know,

16:41.720 --> 16:44.360
understood as like a language for understanding the universe

16:44.720 --> 16:47.600
or other laws for which words don't quite

16:49.440 --> 16:51.240
aren't quite useful.

16:51.280 --> 16:54.480
And so does it not then become that consciousness is language

16:54.480 --> 16:56.520
and everything else is non-consciousness?

16:57.720 --> 17:00.360
I think so in the way that I'm trying to say it.

17:00.760 --> 17:04.880
But the reason the reason why I'm going down this rabbit rabbit hole

17:05.320 --> 17:07.840
is because of the drive of an artificial intelligence

17:07.840 --> 17:10.440
to develop what they call AGI.

17:11.040 --> 17:14.400
So like, which is a general intelligence,

17:14.400 --> 17:19.680
which is trying to trying to mimic human reason in some sort of way.

17:20.000 --> 17:23.120
But what I'm kind of arguing is against that

17:23.120 --> 17:25.480
in favour of something closer to

17:26.520 --> 17:31.160
accepting the intelligence that exists in all species

17:31.160 --> 17:33.320
and plants, et cetera, on the earth.

17:34.720 --> 17:38.520
And then recognising the importance of that kind of intelligence.

17:39.320 --> 17:42.840
So I'm kind of trying to make an argument in opposition

17:42.840 --> 17:45.480
to the artificial intelligence

17:46.480 --> 17:49.280
that drive towards AGI.

17:50.960 --> 17:54.000
So assuming this comes back to your beautiful line,

17:54.000 --> 17:58.920
you know, wondering why humans look up at the stars and not the soil.

18:00.600 --> 18:03.600
Which I think we should unpack as well in relation to this.

18:03.600 --> 18:05.760
So please.

18:05.760 --> 18:09.440
I mean, I mean, I think a good way forward to that is.

18:10.640 --> 18:11.640
I mean, I.

18:12.000 --> 18:16.440
It's probably good to introduce myself a little bit in that.

18:17.520 --> 18:22.280
My own research explores artificial intelligence and real world narrative.

18:22.280 --> 18:25.080
So I'm actually interested in the imaginaries

18:25.320 --> 18:28.320
and the relationship between storytelling and imaginaries

18:28.680 --> 18:30.680
and how that.

18:31.720 --> 18:36.960
As a cyclic causality with technical production itself.

18:37.400 --> 18:39.360
When computer scientists.

18:40.280 --> 18:43.160
Bring something new into the world, it's a creative act.

18:43.160 --> 18:46.000
It's an act of futurism or future, is it?

18:48.000 --> 18:52.400
Like you've got to you've got to think in the future.

18:53.560 --> 18:55.960
To babes to produce technology in the present.

18:56.360 --> 19:00.080
So there is a creative act involved in that.

19:00.080 --> 19:04.720
And that's the kind of creation of narratives or imaginaries.

19:05.120 --> 19:12.040
And this as an impact on on technical production,

19:12.040 --> 19:16.520
the technical production, like what what is possible as an impact on imaginaries.

19:17.040 --> 19:21.440
So so you have a cyclic relationship between the creation of

19:23.000 --> 19:27.320
kind of speculative imaginaries and actual technical production.

19:27.720 --> 19:32.480
So the two things are different in in technical production is

19:32.640 --> 19:37.280
technical production is rooted in in the constraints of the present

19:37.800 --> 19:42.120
in the regulatory framework and politics and ethics, etc.

19:42.440 --> 19:46.400
Whereas imaginaries are that kind of creative leap

19:47.160 --> 19:52.040
into the future that that are used by developers

19:52.600 --> 19:55.640
to basically order.

19:55.640 --> 20:01.680
Like to create goals really for for the technologies that get produced.

20:02.680 --> 20:05.520
And by looking at the kind of imaginaries,

20:05.520 --> 20:09.240
the kind of stories that circulate within tech communities,

20:09.760 --> 20:14.160
then you can get a sense of where the technical development is going.

20:14.640 --> 20:17.080
Is kind of what I'm arguing.

20:18.840 --> 20:21.000
Go on, do you have any good examples?

20:21.000 --> 20:23.840
You said I just wanted to make sure that that made sense,

20:23.840 --> 20:26.240
that relationship between the two.

20:26.240 --> 20:26.800
Oh, definitely.

20:26.800 --> 20:30.200
I think it's just much in the same way

20:30.200 --> 20:33.400
when like scientists come on and speak science.

20:34.600 --> 20:36.640
There's a lot of us here that are laymen

20:36.640 --> 20:38.200
and I think breaking it down

20:38.200 --> 20:40.800
of some sense quite academic language is helpful.

20:41.680 --> 20:44.880
To talk about how these two things inform each other all the time.

20:45.760 --> 20:47.520
So yes, I have a better understanding now.

20:47.520 --> 20:48.360
Thank you.

20:48.360 --> 20:52.040
I think when we're looking at developer narratives,

20:52.040 --> 20:57.280
so the kind of ideas which are driving tech developers.

20:57.560 --> 20:59.120
I mean, these people don't normally come

20:59.120 --> 21:01.040
from a creative background.

21:01.040 --> 21:04.360
So so where where do the graph grab the imaginaries?

21:04.360 --> 21:06.960
Is is quite an interesting thing.

21:06.960 --> 21:12.320
And what my research has found is that a lot of these imaginaries

21:12.320 --> 21:15.240
are driven by, I suppose, obviously sci-fi.

21:16.400 --> 21:17.400
But.

21:18.640 --> 21:22.200
More specifically by the kind of speculative avant-garde movements

21:22.200 --> 21:24.720
which circulate in tech circles.

21:24.720 --> 21:27.560
So to name a few, there's Cosmism,

21:27.600 --> 21:32.960
Transhumanism, Extra-Pianism and Effective Accelerationism.

21:33.520 --> 21:37.560
Oh, what are they exactly?

21:38.640 --> 21:42.840
So like if you delve into tech communities,

21:42.840 --> 21:46.920
you come across these kind of like quite far out

21:46.920 --> 21:48.840
and fascinating ideas.

21:51.280 --> 21:55.280
But what struck me is when I started when I started research

21:55.280 --> 21:59.640
in this territory is the massive impact that Cosmism has had.

22:00.000 --> 22:03.800
Now, Cosmism was a movement which developed in Russia

22:04.200 --> 22:07.600
at the end of the 19th century in the beginning of the 20th century.

22:08.000 --> 22:12.960
So to discover that these ideas from from this period

22:12.960 --> 22:16.240
from pre the Russian Revolution or around the Russian Revolution

22:17.920 --> 22:20.960
currently has a massive impact on

22:21.840 --> 22:25.560
on AI and tech developers in Silicon Valley and California

22:25.560 --> 22:27.280
is a little bit, whoa, really?

22:28.160 --> 22:29.160
But.

22:30.040 --> 22:35.280
So if I dig a little bit deeper into this into the ideas of Cosmism,

22:35.280 --> 22:40.520
it I think I think where your tech is is kind of

22:40.920 --> 22:44.640
to answer that question of why the developers looked at the stars.

22:45.640 --> 22:50.640
So Cosmism emerged in Russia at the end of the 19th century

22:50.640 --> 22:52.280
in the beginning of the 20th century.

22:52.800 --> 22:56.640
And one of the key figures was a guy called Nikolai Fedorov.

22:57.640 --> 23:02.560
And Fedorov connected his kind of quite strong

23:02.560 --> 23:07.520
Christian beliefs with a with a futurism.

23:08.640 --> 23:12.760
And he thought he believed that the common task of humanity

23:13.160 --> 23:14.600
was to end death.

23:15.920 --> 23:19.200
So to end all death to move towards immortality.

23:19.640 --> 23:21.240
Very good. And.

23:23.840 --> 23:26.800
And this wasn't enough

23:27.280 --> 23:30.600
because this betrayed the older generations.

23:30.960 --> 23:33.720
So the first step is to kind of end death.

23:34.240 --> 23:37.840
But once you've achieved that, then the next step is to resurrect the dead.

23:38.840 --> 23:44.320
That's that's that's the duty of all good son.

23:44.480 --> 23:47.200
Sons is to resurrect their fathers.

23:47.680 --> 23:50.320
That's the language, the language he used, not mine.

23:50.920 --> 23:53.840
I just sorry, just a very, very quick side note.

23:53.840 --> 23:56.400
But it's just fascinating to me that this man, for example,

23:56.400 --> 23:57.960
wasn't burned at the stake.

23:57.960 --> 24:00.080
It sends an awful lot like sorcery.

24:00.520 --> 24:02.400
Imagine if that had been coming out the mouth of a woman.

24:02.400 --> 24:05.000
Hey, please continue.

24:05.440 --> 24:09.800
But anyway, you've got to remember, my interest is the relationship

24:09.800 --> 24:13.040
between like imaginaries and technology itself.

24:13.400 --> 24:18.160
Now, one of his students was a person called Constantine.

24:19.240 --> 24:21.640
My Russian is appalling, so please forgive me.

24:21.640 --> 24:25.480
Any listeners who speak Russian, but Sayel Sayelkovsky.

24:27.040 --> 24:29.960
So Sayelkovsky.

24:30.960 --> 24:37.600
He took on a lot of the philosophy of Fedorov, Fedorov, so.

24:40.360 --> 24:42.640
But he took it in a very practical way.

24:43.720 --> 24:48.400
So Sayelkovsky studied kind of the physics of his time and etc.

24:48.920 --> 24:52.080
And he developed some of the first practical divide

24:53.120 --> 24:58.800
designs for the space rockets and the equations

24:58.880 --> 25:01.400
required to for space travel.

25:02.040 --> 25:04.760
And he did this in 1896.

25:06.360 --> 25:10.480
So this these kind of like developments in kind of the technology

25:10.480 --> 25:13.120
of space travel emerged from.

25:14.800 --> 25:20.160
Following Fedorov, realising that if you ended death.

25:21.440 --> 25:26.840
And resurrected the dead, then the planet would get overrun quite quick.

25:27.200 --> 25:32.280
So it was so it becomes necessary to leave the cradle of the earth.

25:34.120 --> 25:36.720
Does that make sense in the logic?

25:40.440 --> 25:42.080
As logic, sure.

25:45.600 --> 25:48.040
OK. So.

25:49.600 --> 25:51.760
The reason this becomes interesting is because

25:52.400 --> 25:58.360
Sayelkovsky is basically the founder of the Russian space program

25:59.160 --> 26:01.520
and the former Soviet space program.

26:01.520 --> 26:07.160
And his rocket designs are currently like

26:08.080 --> 26:10.560
I'm not not exactly the same, but

26:10.960 --> 26:14.960
but are the forefathers of our current rocket design.

26:15.360 --> 26:17.360
So you've got this link between kind of.

26:18.360 --> 26:21.080
Quite fascinating and crazy.

26:23.080 --> 26:25.680
Imagineries, so futurist imaginaries,

26:26.400 --> 26:32.320
linked with technology, which ultimately developed the US space program.

26:33.280 --> 26:35.440
But how does this link with Silicon Valley?

26:36.640 --> 26:41.560
Well, if you look at, say, Ray Kurzweil said,

26:42.400 --> 26:48.560
you know, Ray Kurzweil was kind of the profit for Google's AI program.

26:49.440 --> 26:50.440
Is.

26:52.240 --> 26:54.520
I think he's probably a chief engineer.

26:55.840 --> 26:56.840
But.

26:57.640 --> 26:59.560
He also believes in.

27:01.120 --> 27:02.680
Moving towards immortality.

27:02.680 --> 27:05.200
He wanted to be the first person to kind of end death.

27:06.320 --> 27:09.520
So they've like a lot of these ideas

27:09.520 --> 27:12.320
that came from Cosmism have been translated

27:12.320 --> 27:17.000
directly into the kind of AI tech circles which circulate.

27:17.760 --> 27:22.120
So so Kurzweil is a serious technical.

27:23.560 --> 27:26.960
Player within the AI world, particularly in Google.

27:27.760 --> 27:33.240
And this idea of extending life or eradicating death

27:34.240 --> 27:38.320
is part of the discourse which circulates within within this community.

27:39.320 --> 27:42.680
That that would be a kind of group

27:42.680 --> 27:46.840
in which called themselves extra extra pianism,

27:47.440 --> 27:50.480
extra pianist, so that's not sure how you say it properly.

27:51.120 --> 27:55.040
But these ideas link directly to actual technical production.

27:55.400 --> 28:00.320
So so things like the Fitbit and the quantitative self movement.

28:00.320 --> 28:03.760
So the idea of like monitoring your health and maximising health,

28:03.960 --> 28:07.200
which you must have come across because that's part of the kind of like tech

28:07.600 --> 28:09.840
scene, human optimisation.

28:10.560 --> 28:11.760
Exactly.

28:11.760 --> 28:17.520
This human optimisation comes out of this attempt to extend life and eradicate death.

28:18.040 --> 28:21.160
So you can see how the kind of Cosmism has kind of like

28:21.680 --> 28:26.920
been kind of plagiarised really right into these kind of like tech ideas,

28:26.920 --> 28:32.040
which then find themselves been sold on Amazon as Fitbit.

28:32.040 --> 28:35.480
So various other optimisation technologies.

28:37.720 --> 28:42.000
Kurzweil himself, in an interview in a film called

28:42.280 --> 28:45.240
What was it? Are you man?

28:46.720 --> 28:51.320
Declared that one of his driving force for developing artificial intelligence.

28:51.320 --> 28:53.440
And you got to remember that this is a chief engineer.

28:54.360 --> 28:56.640
Is to resurrect his own father.

28:57.040 --> 28:59.800
Oh, my God.

28:59.800 --> 29:04.200
So so so you've got Federer repeating himself

29:04.640 --> 29:08.440
right at the top of the kind of Google development chain.

29:10.280 --> 29:11.960
Oh, God.

29:11.960 --> 29:15.240
And and taking a kind of slightly

29:16.360 --> 29:18.320
a slight side move here.

29:18.320 --> 29:20.560
But when we talk about artificial intelligence,

29:21.720 --> 29:24.520
in tech circles, it gets broken down into

29:26.200 --> 29:27.480
three different areas.

29:27.480 --> 29:30.680
The first one's narrow artificial intelligence, which is what we

29:30.840 --> 29:34.000
what we have at the moment, which.

29:34.040 --> 29:36.520
It's mainly what we call machine learning.

29:37.680 --> 29:42.760
So it's narrow in that it can do very intelligent

29:42.760 --> 29:49.080
activities such as playing go or chess or predicting

29:49.400 --> 29:52.400
texts, but in a very narrow domain.

29:54.120 --> 29:58.760
But the next, like the state of them

29:58.760 --> 30:02.200
of company like open AI

30:03.160 --> 30:06.600
is the development of artificial general intelligence.

30:07.840 --> 30:11.080
Now, artificial general intelligence is

30:12.000 --> 30:17.560
in in Google AI terms, kind of the equivalent of human intelligence.

30:18.000 --> 30:21.280
So it's this this ability to abstract

30:21.280 --> 30:23.920
and apply intelligence to multiple domains.

30:24.520 --> 30:27.040
So so it's wider.

30:27.440 --> 30:31.520
But what what I kind of want to point out here

30:33.480 --> 30:37.000
is that this idea of a general intelligence, which is

30:38.160 --> 30:42.280
is what people are striving for, an artificial general intelligence.

30:42.280 --> 30:45.120
When you look at what a general intelligence is,

30:45.720 --> 30:48.800
then that's actually rooted in what

30:49.840 --> 30:53.000
in the statistic statistician,

30:53.480 --> 30:56.320
Charles Spearman and the idea of the G factor.

30:56.320 --> 30:59.760
But Charles Spearman was a hygienicist

31:00.600 --> 31:02.400
and his reason for developing

31:03.840 --> 31:10.800
this ranking of general intelligence

31:11.960 --> 31:15.760
was to rank human intelligence for selective breeding, etc.

31:16.040 --> 31:18.600
So you've got this you've got this kind of

31:19.920 --> 31:23.360
this drive for artificial general intelligence.

31:23.360 --> 31:26.480
But when when you actually work out what general intelligence is,

31:29.120 --> 31:31.680
it's got some very, very dark histories.

31:33.680 --> 31:37.480
I mean, Spearman developed this to support his colonial

31:37.880 --> 31:42.440
to support colonial policies, etc.

31:42.640 --> 31:47.400
Trying to prove that perhaps other humans were less intelligent for various reasons.

31:48.800 --> 31:52.560
So you've got this kind of hierarchical drive

31:52.600 --> 31:56.720
within artificial intelligence for basically a superhuman

31:58.560 --> 32:02.560
or an intelligence which is beyond human in that kind of way.

32:05.200 --> 32:08.440
And just to kind of

32:10.040 --> 32:12.200
just linking back to

32:13.640 --> 32:15.880
the Cosmist kind of ideas,

32:16.800 --> 32:19.880
you see that the idea of colonising the solar system

32:20.240 --> 32:22.920
or spreading intelligence to the solar system

32:23.720 --> 32:27.280
is is something which is a core concept

32:27.920 --> 32:31.080
within AI development circles.

32:31.920 --> 32:34.480
I mean, it's also the reason why tech billionaires

32:35.720 --> 32:39.440
building their own spaceships, if you think of SpaceX, Blue Origin,

32:39.800 --> 32:43.960
they're all they're all influenced by by these imaginaries.

32:45.600 --> 32:47.600
It's like.

32:48.600 --> 32:53.400
And I'm sure there's probably a lot of people saying I'm over exaggerating

32:53.600 --> 32:57.080
this at this point, but I just want to give you a couple of quotes.

32:57.280 --> 32:59.880
So so this is from

33:00.680 --> 33:07.200
Jürgen Schmid, Schmid, who developed the natural language model,

33:07.400 --> 33:10.960
which is used in Apple, Siri and Amazon's Alexa.

33:11.920 --> 33:16.040
So let me let me just get this and so I can read it properly.

33:17.840 --> 33:22.560
So this is this is his understanding of what he's doing.

33:23.560 --> 33:25.360
He says,

33:25.360 --> 33:28.560
So I'm not a very human centric person.

33:29.280 --> 33:33.000
I think I'm a little stepping stone in the evolution of the universe

33:33.000 --> 33:35.800
towards a higher complexity.

33:35.800 --> 33:38.520
It is clear to me that I am not the crown of creation

33:38.960 --> 33:42.880
and that human kind as a whole is not the crown of creation.

33:44.360 --> 33:47.280
But we are setting the stage for something bigger than us.

33:47.800 --> 33:53.280
That transcends us and we'll go out there in a way where humans cannot follow

33:53.280 --> 33:58.120
and transform the old universe or at least the regional universe.

33:58.720 --> 34:04.640
So I find the beauty and awe in seeing myself as a part of this much grander theme.

34:08.640 --> 34:10.800
I've got another one for you if that's not enough.

34:10.800 --> 34:11.800
Go on, hurt me.

34:11.800 --> 34:15.240
This is this is Professor Dr.

34:15.240 --> 34:20.160
Hugo de Garis, who was the former director of the China Human

34:20.280 --> 34:24.120
the China Brain Project Institute for Artificial Intelligence.

34:24.360 --> 34:25.680
And he writes,

34:25.680 --> 34:29.680
Humanity has the duty to serve as a stepping stone towards building

34:29.680 --> 34:32.640
the next dominant rung of the evolutionary ladder.

34:34.520 --> 34:38.560
And Kurzweil himself says, does God exist?

34:39.240 --> 34:41.200
I would say not yet.

34:41.200 --> 34:44.120
Oh, God. Right.

34:44.560 --> 34:49.760
So so what what what you get when you start digging into these these narratives

34:50.760 --> 34:56.200
is the idea of of building intelligence, which goes beyond humans

34:56.880 --> 35:03.400
and goes beyond our our time frame, our 70, 80 year limitation

35:03.600 --> 35:08.240
and our body's limitation of living within certain environments like the Earth,

35:08.240 --> 35:13.360
like our need to be within a kind of ecosystem, etc.

35:13.560 --> 35:16.600
and can survive out there on the planets.

35:17.040 --> 35:21.600
And it starts to feel like a spiritual movement

35:21.920 --> 35:25.880
to to spread consciousness to to the universe.

35:26.400 --> 35:32.560
So so the tech development, as as I said at the beginning, looks to the stars.

35:34.760 --> 35:39.920
Whereas I think to solve this problem, we need to start looking back to the soil.

35:44.000 --> 35:46.360
I'm so upset.

35:47.720 --> 35:48.720
Sorry about that.

35:51.280 --> 35:53.400
It's so upsetting.

35:53.400 --> 35:55.880
I mean, I think we've got to I think we've got to be upset.

35:56.520 --> 35:59.280
Yes. To to disrupt

35:59.880 --> 36:05.000
and and start saying we need to change these imaginaries.

36:05.240 --> 36:07.960
I mean, you've got to remember, I'm coming from an artist background

36:07.960 --> 36:10.960
and I kind of do a lot of work within the tech sector.

36:14.240 --> 36:16.840
But we have got to be able to create some imaginaries

36:16.840 --> 36:20.600
which can compete with these kind of these

36:21.400 --> 36:25.560
these dominant narratives which circulate within the kind of tech environment.

36:26.720 --> 36:32.000
I have a I have a few things to say on everything you just said.

36:32.440 --> 36:36.120
Number one, these men need therapy.

36:36.800 --> 36:39.840
That is the sound like those are the words of

36:40.040 --> 36:42.520
fairly traumatized people, I would say.

36:42.720 --> 36:47.080
Number one, especially the buggers that want to, you know, resurrect their fathers.

36:47.080 --> 36:49.040
I'm so sorry for your loss.

36:49.040 --> 36:52.440
Please go and pay a therapist to therapist to walk you through it

36:52.440 --> 36:55.200
rather than trying to develop a very energy hungry.

36:55.200 --> 36:56.960
We don't know what would happen if we released it.

36:57.720 --> 36:59.160
Intelligence thing.

36:59.160 --> 37:01.600
Number two.

37:01.600 --> 37:03.960
The other thing I find really interesting about it is like this.

37:03.960 --> 37:05.000
Oh, no.

37:05.000 --> 37:07.120
Number two, one funny thing before number three.

37:08.040 --> 37:12.600
And that bit that you said at the end, when you were quoting these guys,

37:12.600 --> 37:15.480
especially the, you know, I'm not a human centric person.

37:16.640 --> 37:19.360
I consider myself a stepping stone.

37:19.360 --> 37:20.040
It's not about me.

37:20.040 --> 37:24.440
You could just imagine that quote being pasted on top of a

37:24.800 --> 37:28.800
a cartoon of like one sperm cell talking to the other sperm cell

37:29.440 --> 37:30.920
and it would totally fly.

37:30.920 --> 37:35.040
It would be really in place there and which leads me on to point number three,

37:35.080 --> 37:36.480
which kind of struck out to me.

37:36.480 --> 37:38.680
And then what we will get into the imaginaries, of course, but like

37:39.360 --> 37:42.880
in a culture that is so deeply individualistic,

37:43.240 --> 37:48.760
there is like a lack of individualism in what they are saying in a sense.

37:49.120 --> 37:51.440
And that's fascinating.

37:51.720 --> 37:54.480
What is going on there?

37:55.040 --> 37:55.800
I agree with you.

37:55.800 --> 37:59.040
I think this is like there's a religiosity, religiosity

37:59.880 --> 38:01.080
in what they're saying.

38:01.560 --> 38:04.480
It's very culty, but like to.

38:05.560 --> 38:08.040
This isn't fringe, though, by the way.

38:08.520 --> 38:09.720
Oh, no, no, no.

38:09.720 --> 38:14.000
These ideas are really, really move in these circles.

38:14.400 --> 38:15.400
Yeah.

38:15.400 --> 38:17.680
And I think the.

38:19.720 --> 38:22.400
Yeah, that kind of spiritual that that link back to the kind of

38:22.400 --> 38:24.680
cosmos linked to religion.

38:25.680 --> 38:31.240
Is it is definitely there in that it gives people that goal

38:31.520 --> 38:33.680
that like this drive towards AI.

38:34.680 --> 38:37.400
Is is a bigger goal for these people.

38:37.600 --> 38:40.120
So you're right, it's not necessarily that individual thing.

38:40.400 --> 38:44.080
It's that they are seeing themselves literally forming.

38:44.080 --> 38:46.640
Well, they said it themselves that the next stage in evolution

38:46.640 --> 38:52.120
are spreading consciousness to the universe or ultimately creating God.

38:53.120 --> 38:56.720
It's so it's funny because they managed to like make themselves

38:56.720 --> 39:00.800
as small as sperm cells and yet be still incredibly arrogant.

39:00.840 --> 39:03.760
Like the universe doesn't need you, you know,

39:03.760 --> 39:07.200
ejaculating all over it with consciousness.

39:07.240 --> 39:08.920
Likely there is consciousness everywhere.

39:08.920 --> 39:09.760
So it's funny, isn't it?

39:09.760 --> 39:14.160
Because there's like there's these interesting moments of kind of disruption,

39:14.160 --> 39:16.640
even in the thinking of like lack of individuality in it.

39:16.720 --> 39:20.360
And yet it's still so fundamentally hierarchical.

39:21.160 --> 39:24.200
Like running with narrative domination.

39:24.200 --> 39:30.400
That's why I was pointing out the AGI, the the the absolute link to eugenics in there.

39:31.680 --> 39:37.120
Now, what was how does Charles Spearman link to them?

39:38.120 --> 39:40.480
Is there like do we have a kind of because, you know,

39:40.480 --> 39:43.160
we can walk through the Russian thing pretty clearly.

39:43.200 --> 39:46.720
No, no, no, no, Spearman is general intelligence.

39:47.440 --> 39:54.000
So if you if you look at the stated aims of open AI on their website

39:54.520 --> 39:58.560
and and they will tell you that they are developing

39:58.840 --> 40:03.440
that their aim is to develop artificial general intelligence.

40:04.000 --> 40:09.800
And if you research general intelligence, that term is Spearman.

40:10.240 --> 40:12.000
Right. OK. So that's where it comes from.

40:12.240 --> 40:17.160
Yeah. And and and the G factor as a measure of intelligence.

40:17.160 --> 40:21.120
So if we are measuring intelligence with general intelligence,

40:21.400 --> 40:23.840
then we're already in the territory of.

40:25.440 --> 40:27.600
Of eugenics as an idea.

40:27.600 --> 40:31.360
I mean, I've got a feeling in this territory,

40:31.360 --> 40:35.320
a eugenics which goes beyond the human and wants to develop the.

40:36.360 --> 40:38.480
The the superior artificial.

40:39.480 --> 40:41.320
Mm hmm. Mm hmm. Totally.

40:43.720 --> 40:48.680
And I think this I can do a little linking of Silicon Valley

40:48.680 --> 40:51.320
to Eugenics is thinking at this point,

40:51.880 --> 40:53.960
which is the effective altruist movement,

40:54.280 --> 40:58.360
which is very frightened of there not being enough babies

40:58.360 --> 41:02.960
of a certain kind being born in the world, in an overpopulated world.

41:04.240 --> 41:08.240
And so I kind of like, you know, Elon Musk is throwing money at reproduction

41:08.640 --> 41:12.920
research. There's this like Silicon Valley couple that are planning on having

41:12.920 --> 41:17.200
10 babies and inculcating those babies to have 10 more because they want

41:17.240 --> 41:19.800
they literally want to replace, you know, sort of like,

41:19.920 --> 41:22.880
I can't remember what it was exactly, but in a hundred years,

41:22.880 --> 41:25.800
I think they could replace like 50 percent of the United States population

41:26.160 --> 41:28.480
at that rate, essentially.

41:28.480 --> 41:31.840
And and their purpose here is this.

41:32.080 --> 41:35.800
Oh, well, because they believe that you should be investing in the top

41:35.960 --> 41:41.400
one percent of humanity rather than the bottom, you know, 10, 20, 30.

41:42.160 --> 41:45.120
Because it's the top one percent that are going to have the, you know,

41:45.120 --> 41:49.440
intellectual reasoning and capacity to sort of fix the world really.

41:49.440 --> 41:53.960
So there is a hierarchy of ability, capacity and intelligence.

41:54.440 --> 41:57.480
Yeah. And we don't have enough of the smart ones being born,

41:57.560 --> 42:01.200
which does equate to white, essentially.

42:01.720 --> 42:06.360
Yeah, of course, because that that's also what the general

42:06.360 --> 42:11.920
intelligence historically did anyway, with it within the colonial,

42:12.640 --> 42:16.360
well, British colonial, I think, Spierman would like British.

42:16.720 --> 42:19.200
I think you're working at King's, I'd have to reset.

42:19.200 --> 42:21.000
I'd have to look that up again.

42:21.000 --> 42:24.520
I mean, I mean, yeah, this, this, I mean, what you're saying there makes sense

42:24.520 --> 42:29.600
with with the general shape of of thinking that I come across as well.

42:29.600 --> 42:33.320
This is kind of like a shift towards like a super, super intelligence.

42:34.000 --> 42:37.320
And then there's, there's either the direct mechanical group

42:37.880 --> 42:41.760
or there's ultimately the developing the human

42:42.800 --> 42:47.000
and kind of the cyborg and kind of shift, really, where

42:47.200 --> 42:50.120
where you enhance the human to such a level that it becomes

42:51.120 --> 42:55.920
the super intelligence that they seem to be the two, the two directions.

42:56.880 --> 42:59.880
Yeah, that's so interesting.

42:59.880 --> 43:03.000
I don't think I hadn't quite clocked that as being

43:03.120 --> 43:06.080
sort of parallel tracks heading in the same direction.

43:06.480 --> 43:12.080
The desire to, you know, birth as many superior humans as possible

43:12.080 --> 43:15.880
and this drive to create this kind of, yeah, mechanical.

43:17.800 --> 43:23.000
I mean, I mean, in my list of things such as

43:23.560 --> 43:27.240
immortality, et cetera, I actually missed off the human augmentation.

43:27.560 --> 43:30.120
But maybe I should have because human augmentation

43:30.120 --> 43:33.080
is is definitely one of the things which comes up a lot.

43:34.320 --> 43:40.680
The kind of cyborg is an Elon Musk himself owns Neuralink.

43:41.240 --> 43:43.800
Yeah. Neuralink is is the company

43:43.800 --> 43:48.720
which which aims to connect the brain directly to kind of computer systems.

43:48.760 --> 43:53.440
So, yeah, those ideas of human augmentation kind of completely link in with

43:54.360 --> 43:56.720
with this side, with this idea. Yeah.

43:57.520 --> 44:00.240
I interviewed Olivia Luzard recently and she was talking about the fact

44:00.240 --> 44:02.440
that Mark Zuckerberg has been quoted as kind of, you know,

44:02.440 --> 44:05.760
you can't wait to like get rid of his body to get rid of

44:05.760 --> 44:08.200
get rid of the weight of physicality.

44:08.200 --> 44:10.040
I think it's get rid of the flesh.

44:10.040 --> 44:11.520
Yeah, yeah, yeah, yeah, yeah.

44:11.520 --> 44:14.080
And which, of course, links into this idea of like, oh, well,

44:14.080 --> 44:17.160
if I can upload myself, then I can live forever.

44:17.480 --> 44:21.560
Like, transhumanism, I think, is this stepping stone as well towards

44:22.000 --> 44:25.800
towards immortality and then towards, you know, the ever expanding stars.

44:26.760 --> 44:30.120
Yeah, those ideas are all all interconnect.

44:30.120 --> 44:32.960
So in various ways.

44:33.520 --> 44:37.240
But for me, yeah, the important thing is these ideas

44:37.240 --> 44:39.920
aren't just crazy ideas of crazy people.

44:40.480 --> 44:43.640
These these are ideas which are completely

44:44.320 --> 44:48.080
embedded in the development of technology, of current technology.

44:48.080 --> 44:51.160
Well, the idea what I was talking about earlier, the kind of

44:51.720 --> 44:55.800
cyclic causality of of imaginaries and technology.

44:56.640 --> 45:00.360
These ideas are part of the process of developing

45:01.080 --> 45:03.320
our technologies and our future technologies.

45:03.840 --> 45:08.840
So that's why I think as an artist and as a creative

45:09.200 --> 45:12.080
that there's an important activist job to be done

45:13.000 --> 45:18.240
challenging these ideas and and developing alternatives.

45:19.880 --> 45:25.560
Which is kind of the second part of of what we do in our research

45:25.560 --> 45:31.440
is kind of carrying out like workshops with with different communities of people

45:31.960 --> 45:36.800
kind of discussing these ideas, but also trying to get people to

45:37.040 --> 45:40.720
kind of think what what a different form of technology would be.

45:40.720 --> 45:47.160
What a technology that does look to the soil that looks to biological systems

45:47.160 --> 45:51.360
that that sees all species as intelligent and doesn't create this

45:51.360 --> 45:54.040
hierarchy with with a

45:54.040 --> 45:57.880
so-called conscious intelligence versus a non-conscious intelligence,

45:57.880 --> 46:00.120
which you quite rightly picked me up on earlier.

46:00.720 --> 46:05.800
Kind of like break down those ideas and recognize the entanglement

46:06.240 --> 46:13.520
that exists between humans, other species, plants, the the biosphere.

46:16.800 --> 46:18.160
Yeah, beautiful.

46:18.160 --> 46:22.440
The interconnectedness, the oneness, which leads to a different kind of

46:22.440 --> 46:24.360
you know, potential for the duality.

46:24.360 --> 46:29.960
The multi oneness, the multiplicity, the entanglement of multiplicity,

46:29.960 --> 46:34.680
which isn't a oneness, but but is entangled into.

46:36.320 --> 46:39.880
Well, as we started started off kind of like

46:41.400 --> 46:43.880
our actions do have an impact.

46:44.600 --> 46:48.600
Let's talk then about some of these potential technologies

46:48.720 --> 46:52.120
that look to the soil or what happens as well to our own kind of

46:52.680 --> 46:54.960
thinking and processes when we look to the soil.

46:54.960 --> 46:56.480
What have you found?

46:56.480 --> 47:00.200
What's good is like working with other communities and getting getting

47:00.240 --> 47:05.720
voices, which aren't normally heard within these environments.

47:08.120 --> 47:10.720
And we've done a lot of workshops with.

47:14.280 --> 47:17.200
Yeah, just all sorts of different people.

47:17.200 --> 47:21.320
But one of the projects which has emerged out of this is a project

47:21.320 --> 47:25.600
that I've been working with together with Shira Vashman,

47:26.360 --> 47:30.840
which is trying to rethink AI with mycelium.

47:32.520 --> 47:34.880
I think when I listened to your conversation with Maggie,

47:34.880 --> 47:38.120
you raised the idea of mycelium, which I thought was interesting.

47:40.760 --> 47:45.040
For people who don't know, mycelium is the organism which

47:46.880 --> 47:51.040
it which produces mushrooms, ultimately, but mycelium

47:51.800 --> 47:54.080
lives under the soil.

47:54.080 --> 47:58.000
It's an interconnected organism of individual high fee,

47:58.840 --> 48:04.600
which connecting to a network and the remain as that organism,

48:05.040 --> 48:09.960
as long as there's no threat, as long as there's no food shortage of food, etc.

48:11.640 --> 48:16.880
When when when there is a problem, when there's a say a temperature change

48:17.880 --> 48:20.520
or the area where they're existing runs out of food,

48:20.760 --> 48:23.520
they produce mushrooms, which then spar

48:25.040 --> 48:27.320
and produce more mycelium networks.

48:28.400 --> 48:32.720
But one of the interesting things about mycelium is the way that

48:33.640 --> 48:38.880
it's evolutionary or some mycelium, because there's there's lots of different mycelium,

48:39.280 --> 48:45.560
but some mycelium kind of work in a symbiotic relationship with other species.

48:46.400 --> 48:50.720
So the the best example of this is the idea of the Woodwide Web,

48:50.720 --> 48:55.600
which has been circulated quite a lot, which is the way that mycelium

48:56.000 --> 48:59.400
connects between different trees within the forest.

49:01.120 --> 49:06.920
And and sugars and nutrients are shared between different species

49:07.800 --> 49:09.880
or between different trees within

49:12.200 --> 49:13.720
a species.

49:13.720 --> 49:16.360
So so mycelium works

49:17.480 --> 49:20.320
in in symbiotic relationships

49:21.320 --> 49:23.400
within the kind of forest environment.

49:24.120 --> 49:28.720
And another example of the way it works, in vertically, it would be with the orchid.

49:30.160 --> 49:32.560
So orchids

49:34.160 --> 49:36.520
cannot photosynthesize while they are young.

49:37.560 --> 49:40.800
So they couldn't exist, basically, while they are young.

49:40.800 --> 49:44.280
But what they do is they create symbiotic relationships with mycelium,

49:45.000 --> 49:51.880
which provides the kind of sugars that they require in their early stages.

49:52.360 --> 49:55.560
And then when they when they mature,

49:56.040 --> 49:59.840
they become a net producer of sugars, which feeds the mycelium.

50:00.240 --> 50:02.920
So you get these kind of symbiotic relationships

50:03.600 --> 50:07.960
developing micro-risal networks between different species.

50:08.960 --> 50:09.960
And

50:11.520 --> 50:14.320
so by working with people

50:15.200 --> 50:18.040
taking mycelium as a starting point,

50:19.560 --> 50:20.960
we've kind of been

50:22.880 --> 50:28.400
kind of looking at at the way if if we were if we were going to think of a technology like AI,

50:28.840 --> 50:30.400
what would that look like?

50:30.680 --> 50:33.000
And I think the question that emerges from

50:33.800 --> 50:37.080
from our rethinking AI with mycelium

50:38.080 --> 50:39.080
is

50:42.680 --> 50:44.240
I'm going to read this, sorry.

50:44.640 --> 50:45.160
Go for it.

50:45.400 --> 50:50.040
Is a what if AI significance lies not in competing with us,

50:50.360 --> 50:57.400
supplanting or surpassing us in a mainstream AI narrative as in mainstream AI narratives,

50:57.800 --> 51:04.280
but in fostering complex, ecologically sustainable symbiotic relations with both mechanical and

51:04.280 --> 51:05.960
dogonic intelligences.

51:09.040 --> 51:15.160
We suggest the study of AI should involve a redress of our relationship to other non human

51:15.160 --> 51:17.240
intelligences on the planet.

51:18.760 --> 51:20.360
So that's the kind of

51:23.760 --> 51:24.760
the kind of

51:27.120 --> 51:30.800
outcome that we're kind of developing with

51:31.800 --> 51:37.120
rethinking AI through mycelium is to kind of shift it away from the kind of

51:37.120 --> 51:41.600
hierarchical model that we've been discussing and towards

51:41.600 --> 51:47.520
rethinking intelligence in this kind of wider way and how can we connect to

51:47.520 --> 51:51.560
these intelligences in rather than a

51:51.560 --> 51:55.080
combative survival of the fittest

51:57.680 --> 52:00.200
eugenicist kind of model.

52:00.840 --> 52:05.280
But rather in a model of symbiotic, I suppose,

52:08.200 --> 52:09.040
solidarity.

52:11.320 --> 52:13.280
And what would these technologies look like?

52:16.040 --> 52:23.120
So I think one of the first things is that we've got to understand the impact that

52:23.440 --> 52:27.800
computing, obviously I'm coming from an AI computing background, so this is important to

52:27.800 --> 52:33.120
me, the kind of impact that computing itself has on the world.

52:33.120 --> 52:41.720
So computing itself contributes to global heating and environmental degradation.

52:44.480 --> 52:49.720
I think on some recent research that I read in Nature magazine,

52:50.560 --> 52:59.200
it stated that the IT industry could use 20% of all electrical production by 2025,

52:59.200 --> 53:01.360
given that's next year, that's a lot.

53:02.720 --> 53:10.440
And that 5.5 of the world's carbon emissions comes from 5.5% of the world's

53:10.440 --> 53:16.240
carbon emissions comes from basically the global IT industry.

53:17.240 --> 53:22.120
Now, that's bigger than most countries by, say, China and India, U.S.

53:22.120 --> 53:24.800
extract, that's the big countries.

53:24.800 --> 53:29.000
So we've got to take these ideas seriously.

53:29.000 --> 53:39.320
And so if we're going to continue developing computer systems, then we've got to think

53:39.320 --> 53:43.480
of how to create a sustainable computer.

53:44.480 --> 53:50.840
And there's quite an interesting movement called permacomputing, I don't know if you've

53:50.840 --> 54:00.160
come across it, but permacomputing is it kind of takes permaculture as a model, but looks

54:00.160 --> 54:09.000
at how we can develop computing in a kind of sustainable and a kind of viable way, kind

54:09.000 --> 54:18.840
of moving away from this ever-growing storing of data within data centers, which use mass

54:18.840 --> 54:25.120
amounts of electricity to keep them cool, and also has an impact on water as well, because

54:25.120 --> 54:28.440
water's used in these kind of large data centers.

54:28.440 --> 54:36.840
Many of which, the storing of mass data is the reason why we're storing mass data is

54:36.840 --> 54:41.440
ultimately to train AI models, to train machine learning models.

54:41.440 --> 54:44.160
It kind of comes round in a circle to some level.

54:44.160 --> 54:51.360
The kind of the form of computing that we are developing, storing all of this data in

54:51.360 --> 54:58.920
the so-called cloud, is ultimately collecting the data that is required to train mass machine

54:58.920 --> 55:02.520
learning models to develop the AI.

55:02.520 --> 55:11.120
So how can we shift away from this kind of circular model to one where we can use computing

55:11.120 --> 55:18.120
perhaps to help solve some of the problems that we have, we're having with the environment,

55:18.120 --> 55:22.280
but that kind of computing itself needs to be developed in a way which is sustainable

55:22.280 --> 55:24.440
with the environment.

55:24.440 --> 55:30.800
So that's the kind of thinking that we are trying to develop with our practices.

55:31.200 --> 55:36.200
Wonderful.

55:36.200 --> 55:41.600
This is kind of the reckoning of all industries of this juncture in history, isn't it?

55:41.600 --> 55:49.880
How to get away from our legacy, essentially, and reimagine entirely new ways of being in

55:49.880 --> 55:54.520
order to survive ourselves.

55:54.520 --> 56:02.160
I think that the ultimate job at the moment is to create these imaginaries, to create the

56:02.160 --> 56:08.960
imaginaries so that we've got something to drive for and develop the technologies that

56:08.960 --> 56:10.240
allow for its existence.

56:10.240 --> 56:15.280
By technologies, I use that term broadly.

56:15.280 --> 56:20.000
My ceiling itself can be a technology.

56:20.000 --> 56:29.480
If we can use it as a way to understand what's going off within the forest ecology, it is

56:29.480 --> 56:35.560
a computer system itself, or a computing system itself, that if we can learn to understand

56:35.560 --> 56:36.560
and read.

56:37.560 --> 56:46.000
I don't mean instrumentalizing, I mean in a kind of non-destructive way, then that's

56:46.000 --> 56:50.360
kind of an interesting way to kind of move forward, I think.

56:50.360 --> 56:52.200
Definitely.

56:52.200 --> 57:00.560
I think the third thing we maybe need to bring in at this point, though, is as you spoke

57:00.560 --> 57:07.520
about the circularity between the ideas and the tech and how they inform one another.

57:07.520 --> 57:15.760
We've also got to add in for-profit motive and private ownership and the competitive

57:15.760 --> 57:17.280
market.

57:17.280 --> 57:24.080
That very first artificial intelligence that you spoke about at the beginning of this interview.

57:24.080 --> 57:34.880
Whether or not it is possible to, not to reimagine, but to actually create the sustainable

57:34.880 --> 57:42.560
solidarities necessary when that artificial framework will be, sorry, when that artificial

57:42.560 --> 57:46.560
intelligence will be moving to shut those kinds of things down.

57:46.560 --> 57:49.360
Yeah, absolutely.

57:49.440 --> 57:56.960
I mean, I think within our project that we've been working on, particularly the rethinking

57:56.960 --> 58:04.440
AI with Mycelium, is we've got to think about, if we are developing intelligence, if we were

58:04.440 --> 58:11.960
developing AI, then we've got to think about the particular environments that AI has been

58:11.960 --> 58:20.120
brought up in, what sort of ecosystems we are raising and developing artificial intelligence

58:20.120 --> 58:21.120
in.

58:21.120 --> 58:29.360
Currently, it's this kind of aggressive, domineering, environmentally destructive, competitive

58:29.360 --> 58:31.360
environment.

58:31.360 --> 58:37.920
If you think of the way machine learning is where it's currently used, high-speed trading,

58:37.920 --> 58:48.000
etc., then it's all about systems of winning and losing, of profit and loss, etc.

58:48.000 --> 58:59.120
So what would an artificial intelligence look like if it was developed in a symbiotic relationship

58:59.120 --> 59:01.040
like a Mycelium?

59:01.040 --> 59:09.120
I mean, I've actually got a good quote from this from Tim Ingold, but thinking through

59:09.120 --> 59:17.320
the social and the way the social is structured, I think has to play a massive role in our

59:17.320 --> 59:22.000
rethinking, say, the market.

59:22.000 --> 59:26.520
Let me just find this quote from Tim Ingold, because it would fit here really nicely.

59:26.520 --> 59:27.520
Please.

59:27.520 --> 59:28.520
I've got it.

59:29.520 --> 59:30.520
Where's he gone?

59:30.520 --> 59:31.520
Here he is.

59:31.520 --> 59:32.520
Okay.

59:32.520 --> 59:42.160
So what Tim Ingold wrote in his book Lines a Brief History is, and his dad was a mycologist,

59:42.160 --> 59:48.320
so this is probably why he's kind of talking about Mycelium, but what if we take the Mycelium

59:48.320 --> 59:55.640
as our exemplar of the organism, arguably, the oil of biological science would be different

59:55.640 --> 01:00:00.920
and so too would the science of society be different, where every person to be considered

01:00:00.920 --> 01:00:09.200
like the Mycelium as a thing of a line and the social as the domain of their entanglement.

01:00:09.200 --> 01:00:17.200
So I think what he's arguing for here is a breaking down of that neoliberal individualism

01:00:17.200 --> 01:00:25.600
that is so dominant within our culture and to see ourselves both entangled with each

01:00:25.600 --> 01:00:33.120
other, but also in a species relationship with the planet itself, like how would we

01:00:33.120 --> 01:00:42.200
develop science and technology if we could, if we saw the world in these terms of entanglement.

01:00:42.200 --> 01:00:50.280
And I think that's quite a good imaginary to kind of base our technology on.

01:00:50.280 --> 01:00:59.600
So the image for me that came to mind was a weaving, a weaving of threads, a braiding,

01:00:59.600 --> 01:01:00.840
which kind of like...

01:01:00.840 --> 01:01:10.680
It's not a loss of the individual to the mass, but at the same time, it's not a separation

01:01:10.680 --> 01:01:17.480
of the individual from the mass, it's a layer weaving textiles, that's I think a good way

01:01:17.480 --> 01:01:18.480
forward.

01:01:18.480 --> 01:01:19.480
Beautiful.

01:01:19.680 --> 01:01:26.840
I think if all of reality is relational, which it is everyone listening, it just is.

01:01:26.840 --> 01:01:31.840
And then the more that you braid and weave these relationships, the more that you are

01:01:31.840 --> 01:01:37.800
literally reinforcing the structure of reality in a good way, you're fortifying it with that

01:01:37.800 --> 01:01:38.800
entanglement.

01:01:38.800 --> 01:01:39.800
And I think that's...

01:01:39.800 --> 01:01:42.720
I think that's a beautiful note to end on, John.

01:01:42.720 --> 01:01:43.720
Yeah, brilliant.

01:01:43.720 --> 01:01:44.720
Yeah.

01:01:44.720 --> 01:01:45.720
I've so enjoyed this.

01:01:45.720 --> 01:01:46.720
Thank you so much.

01:01:46.720 --> 01:01:47.720
I have as well.

01:01:47.760 --> 01:01:50.760
It's a bit of a crazy journey, aren't we?

01:01:50.760 --> 01:01:52.760
But a good one.

01:01:52.760 --> 01:01:54.760
Hopefully from the stars back to the soil.

01:01:54.760 --> 01:01:56.760
Yeah, exactly.

01:01:56.760 --> 01:01:57.760
Rewind people.

01:01:57.760 --> 01:02:00.360
Let's bring it back.

01:02:00.360 --> 01:02:03.760
My final question for you is, who would you like to platform?

01:02:03.760 --> 01:02:05.260
Okay.

01:02:05.260 --> 01:02:12.400
So the person I'd like to platform is an art activist called Jay Jordan.

01:02:12.400 --> 01:02:17.960
So Jay Jordan is perhaps the most committed art activist I know.

01:02:17.960 --> 01:02:23.320
He played an important role in the activist movements, Reclaim the Streets, and was one

01:02:23.320 --> 01:02:30.000
of the founders of the laboratory of insurrectionary imagination and the clown army.

01:02:30.000 --> 01:02:37.200
And he kind of lives resistance daily in the occupied zads in France, the kind of...

01:02:37.200 --> 01:02:46.240
So hopefully we can get him on and he can take some of these imaginaries forward in a

01:02:46.240 --> 01:02:51.160
way of how we can actually take them into the streets and into the fields and turn them

01:02:51.160 --> 01:02:54.760
into direct action, which he's amazing at.

01:02:54.760 --> 01:02:56.760
Oh, that is just wonderful.

01:02:56.760 --> 01:02:57.760
I can't wait to speak to them.

01:02:57.760 --> 01:02:59.760
John, thank you so much for today.

01:02:59.760 --> 01:03:00.760
It was just great.

01:03:00.760 --> 01:03:04.280
If you want to learn more, I've put links to everything in the description box below.

01:03:04.280 --> 01:03:08.200
Remember to subscribe to the channel if you're new here and share the episode if you enjoyed

01:03:08.200 --> 01:03:09.200
it.

01:03:09.200 --> 01:03:12.960
To support the show, subscribe at planetcritical.com where you can read the weekly newsletter

01:03:12.960 --> 01:03:14.660
inspired by each interview.

01:03:14.660 --> 01:03:17.120
You can also become a Planet Critical patron.

01:03:17.120 --> 01:03:19.240
All links are in the description box below.

01:03:19.240 --> 01:03:22.160
As always, my deepest thanks to that community.

01:03:22.160 --> 01:03:24.760
Planet Critical wouldn't exist without your support.

01:03:24.760 --> 01:03:28.280
Thank you everyone for listening and for coming on this journey together.

01:03:34.280 --> 01:03:35.280
Thank you.

01:03:35.280 --> 01:03:36.280
Bye.

