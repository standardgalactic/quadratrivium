{"text": " Good, without further ado, I'd like to present our next speaker, Sebastian. Sebastian will be talking about writing faster code. Give him a big hand. APPLAUSE OK, hi, everyone. Can you hear me? OK, so I would like to talk with you about writing faster code. And last time I was giving a short talk, short lightning talk about writing faster code, I remember someone pointed out that, well, basically, you can take your Python code, rewrite it in CRC++, and it will be faster. And I mean, the guy was right. So take any piece of Python code, rewrite it in CRC++, and probably it will be automatically faster. So I was thinking, hmm, if I say just writing faster code, it might not be clear if I mean only Python or not. So I had to fix the title of my presentation. LAUGHTER And I was very happy with the new title. I mean, it makes it clear we are not going to talk about C or Java today. But then I realized the title is too long. I mean, even though it's very clear, it barely fits on the slide. So I had to change it again. So I got the version that means exactly the same thing, but it's shorter. So this is how I ended up with writing faster Python as a title for my today's talk. So let's put aside the flame war about which programming language is better. We all know the answer. That's why you're here. Python was not created to be a fast language that you would use for some computations where every nanosecond counts. And that's fine with me. Python is a great programming language that is very easy and fun to use. Python is very easy to learn. The fact that it's so easy to read and write code in Python, it's very encouraging for people new to software development. I see that it's getting more and more popular in schools or at the universities as the first programming language. And I am not surprised. I mean, imagine you're completely new to programming and someone tells you, hey, let me show you how much fun programming is and let's start with something super simple. Let's just print some text to the screen. And then he shows you those two examples. I mean, one of them is clearly not something that you want to show to a beginner to encourage him or her to start programming. But also, Python is not only useful for learning. There are many big companies that are using Python. Companies with millions of users and billions of requests per month. So your website is going to be fun using Python. So Python is usually fast enough. But what if you decide that it's not fast enough anymore? For example, your website starts giving you timeouts or maybe a faster code will bring more money to your company. So it's time for optimization. But how do we optimize the code? Well, probably you need to follow some rules. So let's try to Google for that. And if we open the first link, we see that there are only three rules. Wow, it's going to be easier than we expected. So let's take a closer look at those rules. First rule of optimization, don't. Okay, that was easy. Any questions? Well, actually, now there is more to that. So what does it mean, don't? Well, nine out of ten times when you think that you need optimization, you don't, especially in the early stage of your product's life. You might think it would be nice to optimize your code a bit, but first of all, you will waste time doing something that is probably not needed. If you want your code to run faster, you can start with getting a faster hardware in the first place. And second of all, optimization comes with a cost. Most often, the only cost is the time that you spend optimizing your code. Well, sometimes it's also the time that you need to fix what you just broke with your optimization. But also optimize it, the optimized code might not be as readable as it was in the first place. And maybe your code is running faster, but it's now using more memory. So unless you have really good reasons to optimize, don't do this. And if you know that you have reasons to optimize, then we can move to the second rule of optimization. Don't do this yet. And this is how I understand this rule. So first, make sure your code works, then make sure you have a good test suit, and only then you're ready for optimization. I love this rule. It always reminds me how many times I broke it. I mean, so many times I was working on a piece of software, and I started thinking, hmm, maybe I can change this piece of code, and it will be faster, and maybe I will save like two lines of code. Was it a good idea? No. I ended up breaking things. Most often I did end up breaking things, but also I started jumping around the code, and at some point I got confused what I was writing in the first place. Did it make my code faster? I have no idea, because I had nothing to compare it to in the first place. If I would finish writing the code and then try to improve it, I could measure both solutions and compare them. But in that scenario, I could only guess. And that brings me to the last rule of optimization. Don't guess. Always profile your code. Human are terrible in predicting the bottlenecks of your code, so if you think that your code is slow, first profile it and then see what part of it takes most of the time. Otherwise, you may end up spending time rewriting one piece of your code to just get like 1% of speed improvement, while there are other parts of your software where you can gain way more improvement with less effort. So there are plenty of profiling tools. There were already quite a few talks during EuroPython about profiling, so I will not go into the details, but if you don't know where to start, you can take a look at the C-profile module. It will show you a clear overview of how many times each function is called and where the code is spent, and if you want to have some more advanced formatting, you can have the PSTADS module. Also, if you prefer the graphic interface, you can take a look at the Run Snake Run or SnakeVis libraries. So once we're ready for optimization, we have to decide on which area we want to focus. So there are different levels of optimization. Starting from the highest level, you have the design level optimization. So depending on the constraints and priorities of your system, you can optimize it by redesigning it. It might require rewriting your software in a different programming language or changing the database type or changing the architecture to perform less database queries. So this kind of optimization will usually give you the best improvement, but it also takes most time to do this. So I don't encourage you to rewrite your software from the scratch, but if you have some critical parts of your code that are run often, you can optimize them by rewriting them in C or C++. Because C is faster, you will have some good speed improvement for free. Well, not really for free, now you will have Python and C code in the same project. So one level lower, we have algorithms and data structures. So knowing good algorithms together with their complexity definitely helps you creating a good and efficient software. For example, if you want to get the sum of numbers from 1 to n, the first idea might be to get a loop that goes through all the elements and adds them. It will work, but it won't be fast. Instead, you can use the algorithm for the arithmetic sum, which will give you the same results and it will be more efficient. So the next level is the source code optimization. And this is something that I will talk about in the second part of the presentation. Now we're moving to the build level, which involves setting up some specific build flags. So in your daily work, it's not something that you will do often. You can optimize Python for a specific architecture, but if you're a web developer like me, this is either something that you will do once per machine or you won't bother at all. Next, we have the compile level. So you can make some optimizations if your programming language has an ahead-of-time compiler. And since I'm talking about C Python today, which doesn't really have a head-of-time compiler, we're going to skip that part as well. And last but not least, we have the runtime level. So it's related with a specific compiler that you're using. Some compilers are faster than the others. So, for example, if you replace C Python with PyPy, you can get some improvements depending on the use case of your software. But it really depends on what kind of piece of code you're writing. So most of the time, once you set up on a specific language implementation, there's nothing you have to do to benefit from this kind of optimization. It's usually up to the creators of the compilers to optimize them. So simply updating to the new version of the programming language you're using can make your code run a bit faster. So when you optimize, you probably want your code to run faster. And also use less memory. And basically less of everything. The bad news is you can't have all of it. Optimization in one area will usually cause deterioration in other areas. So you always have to decide which resources are crucial and you have to optimize in that direction. So it's possible that optimization will have nothing to do with the speed because there are other resources more important than the raw speed. For example, who cares that your program is now 10 times faster when it's crashing half of the time because it's running out of memory? Also, another important resource that people are often forgetting is the sanity. A sanity of a person that will be maintaining your code. So please be nice to that person. You never know who that might be. Yeah, so unless you're really writing a throwaway code, if you're making your code harder to read and maintain, then you're probably doing it wrong. So having those things clear, let's jump straight to how you can write faster Python. Also known as source code optimization. In my examples, I'm using the version 3.5.1 of Python. Together with iPython. Although the examples should work in both Python 2 and Python 3. So for measuring the execution time of my code, I will be using the magic timing function. It has some overhead comparing to the standard timing library, but it doesn't really matter because as long as we use the same method to measure execution time of different functions, we only need to know which method is faster than and by how much. So for each of my examples, I will write different versions of code, measure the execution time, and compare them. So let's start with something simple. Let's say you want to count the number of elements in a list. You can easily write a simple loop that will increment the counter, and while this will work, it will be very slow. You can achieve the same results using the built-in LAN function. And as you can see, for only one million of results, the difference is insanely huge. So my first advice is not to reinvent the wheel, but first check if there is a function that you can use. Python 3.5 has 68 built-in functions, so it's nice to take a look at them and keep them in the back of your head because they might be handy at some point. Also, before you start writing your own version of order dictionary or a dictionary with default values, take a look at the collection module from the standard library. Even though it contains only like 10 different data types, those are probably the data types you are looking for if the standard ones are not enough. So let's say you have a list of one million elements, and you want to select only the odd numbers. So the naive version would be to use the for loop. So for each element of the list, you check if it's odd, and if it is, you add it to another list. But I already show you in the previous example that in most cases, for loops can be replaced with something better. In this case, you could use the built-in filter function instead. And in Python 2, filter was returning a list directly. In Python 3, it's returning an iterator. So I have to call the list function to get the same results as in case of the for loop. And even though the list function has some impact on the performance, it's negligible comparing to the time spent in the filter function. Yet, you can see that filter performs even slower than the for loop. Why does this happen? Well, the fact that filter is returning now an iterator is a clear sign that it's a wrong use case for this kind of function. So if you want to get the whole list as a result, it's better to use the list comprehension. It's around 75% times faster than the for loop, and at least for me, it looks more clear. When you want to execute a piece of code, but you are not sure if it will be successful. Maybe some variables are not set, like in this case, the class might be missing some attribute. So you want to protect yourself somehow. The first way you can do this is called look before you leave or ask for permissions. What it means is that you first check if the class has a specific attribute, and then you perform the operations. Usually, this checking is done with the if statement. However, there's different approach that you could use, and it's called back for forgiveness. So in this scenario, you perform the operation without checking the conditions first. But in case you expect that something might break, you wrap your code in a try except block, and you catch the exceptions that were raised. And as you can see in the simple example, begging for forgiveness is like three times faster. But it gets even better if you're checking for more conditions. So here we are checking if three attributes are present. And asking for permission is still slower, and now it's also getting more difficult to read. So following the back for forgiveness approach will result in a faster and more readable code. So we could say that asking for forgiveness instead of checking the permissions is always a better way. But we won't say that because it's not true. Exceptional handling is still quite expensive. So if the attribute is actually missing, then begging for forgiveness will be slower than asking for permissions. So as a rule of thumb, you can use the ask for permissions way if you know that it's very likely that the attribute will be missing, or there will be some other problems that you can predict. Otherwise, if you're expecting that your code will work in most of the times, try using try accept will result in a faster and quite often more readable code. So for example, if you're fetching some files from the internet, and you expect that everything will be fine unless there is no internet connection. So instead of checking if there is internet connection, if it's fast enough, if there are no timeouts, just go for the try accept. But then again, I strongly advise you to measure both solutions and see maybe in your case it will be different. So let's tackle another problem, the membership testing. So if you have a list and you want to check if it contains a specific element, you can use a for loop. But the problem is you are iterating over the whole list even though you're not really doing anything with all those elements. So you can replace the for loop with the in statement. It will check if a specific element belongs to a given set of data, and it will do this twice as fast. But there is still one big problem with this approach. The lookup time depends on where your element is located in that list. If it's at the beginning of the list, you're lucky and you will get it fast. If it's at the end of the list, you have to wait. So what would be really nice here if we had the data structure that would have a constant lookup time. And actually in Python we have, we have both sets and dictionary that have constant lookup time. So if we replace the list with a set, then the lookup time becomes faster, from just a few times faster to hundreds of thousand times faster. So where's the catch? Well, you pay some time to convert the list to a set. And in this scenario, converting this list to a set takes more time than any of the lookups in that list. So it doesn't really make sense. However, if you're checking membership of different elements, quite often it makes sense to first convert it to a set. So speaking of sets, they have another interesting feature. They don't contain duplicates. So basically if you have a list of elements and you want to remove the duplicates, the fastest way to do this is to convert this list to a set. But be aware that sets are not ordered. So if you need to preserve the order, take a look at the order dictionary from the collection module. So if you want to sort your list, you can either do this in place using the list.sort function, or you can call the sorted function that will create a new list. And unless you really need to have a new list, sorting in place will be like six times faster in this scenario. This is for one million of random numbers. If you want to perform the same operation on a large set of data, then you have two options. You can write a function that performs the operation and call this function 1,000 times. Or you can call a function that takes this set of data and performs the operation inside. And the second approach will be faster. So if you can in an easy way replace multiple calls to one function with just one function, then quite often it's a good idea. So what's the best way to check if a variable expression is true? Well, you can explicitly compare this variable to true, but in most cases you're adding additional redundancy. So you can simplify your condition to just if variable. And it will return true unless the variable is false, non-zero, empty string, empty list, or other false expression. And by doing that, your comparison gets faster by like 70%. And the same rule applies when checking for false. So the fastest way to do this is to use if not variable, unless you really need to distinguish false from, let's say, non or zero or other false values. It also applies to empty data structures. So simply doing if not a list will be almost three times faster than explicitly checking the length of a list. So let's take a look at different ways of defining functions in Python. The most common one is to create a function with def keyword. The other way is to declare an anonymous function with lambda. If you assign this lambda to a variable, it will act in the same way as the function created with a def keyword. And as you can see, they are both equally fast. Why? Because both versions do exactly the same thing. We can disassemble the code of both versions with the disk library, and we'll see that inside is the same code. So is there any difference? Well, if your function has more than one line, you can't use lambda. And you can't really put documentation inside of lambda. Also, if you have Pepeit enabled in your code editor, it will complain each time you try to assign lambda to a variable. And in his right, lambdas work really nice when you need a simple one-liner callback for your functions, especially for functions like filter, mabel, reduce. And there are also some quite few narrow use cases where it might be necessary to use lambda as a callback. So if you want to read more, you can check the link at the bottom. In any other case, I would definitely recommend to use that. It's much cleaner, you can document it properly, and the performance is exactly the same. So there are two ways how you can create an empty list. So you can either call a list function, or you can just use the list literal syntax. And as you can see, the literal syntax is faster. Why is it faster? Because if you call a function, Python first needs to resolve this function. And with the literal syntax, there is no overhead for that. And the exact same thing happens for creating a dictionary. Okay, I have two more examples that should be treated with quotient. Even though the code can run faster, I would not advise you to do this kind of optimization. So sometimes, even though you can squeeze some additional performance from your code, it doesn't mean that you should do this. So one thing is a variable assignment. If you have a bunch of variables that you need to assign, you can do this the normal sequential way, or you can go for this crazy parallel assignment. And I mean, you can gain some speed, but with this speed comes the hate of your colleagues that will be reading this code later. So in my opinion, it's not worth it. Okay, and another interesting property of Python is that the lookup for local variables is faster than the lookup for globals or buildings. So you can save some time if you store the reference to a building function or a global function in a local variable. So in this example, the only difference is on the line 3, where I'm storing the reference to the global append in a local append variable. And thanks to that, this function is like 35% faster. But then again, if you see this code for the first time, it's not very clear what it is supposed to do. It might be confusing to see this kind of append function because we are most used to see the list.append version. To sum up, there are different kind of optimizations. It's quite often about the speed, but not always. And there are also different levels of optimization. So sometimes if you cannot rewrite your whole application, maybe you can use a different approach. Even though the source code optimization is not the fastest way to optimize your code, those small improvements will add up. And the main advantage of it is cheap. So you can optimize the code at the moment of writing. You don't really need to rewrite something. And as long as you're writing idiomatic code and you don't reinvent the wheel but already use the existing functions and data structures in Python, then you're already doing it correctly. So be curious when you're coding. If you think that the different code structure can be faster, you can quickly check it with the time it, and then you can improve it. All right, my name is Sebastian Witowski, and I work at CERN. So if you guys want to talk about physics, then you're probably on the wrong conference. But if you want to talk about Python, you can catch me somewhere on the corridor. Thank you. All right, brilliant. We have about two minutes for questions. Sebastian, if you're happy to take one or two questions, shall we have them? Fantastic. Who's got a question? You, sir. Awesome talk. I have a quick question. You showed us some profilers, code profilers. Do you have any preference, any favorites? It really depends what you want to profile. Because if you care about the speed, then the basic ones are fine. But if you want to profile the memory users, then you might need to use different profilers. So it really depends what you want to profile. Any other questions? Yep. Do you have any recommendation on books or source where we can find best practices regarding this idiomatic Python? Not from the top of my head, but, well, definitely there is some guides on the official Python documentation. But also, for me, it's a lot of Googling for best practices, also reading a lot of Stack Overflow. There are some books, but I can't give you the names right now. Any more questions? Yes? Was that you sticking your hand up, sir, or just explaining something excitedly? Pretty really not a question. Any more questions? No? In that case, let's thank our speaker for a fantastic talking. Nice to ask you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 3.68, "text": " Good, without further ado, I'd like to present our next speaker, Sebastian.", "tokens": [50364, 2205, 11, 1553, 3052, 22450, 11, 286, 1116, 411, 281, 1974, 527, 958, 8145, 11, 31102, 13, 50548], "temperature": 0.0, "avg_logprob": -0.36211768702456826, "compression_ratio": 1.6555023923444976, "no_speech_prob": 0.12214812636375427}, {"id": 1, "seek": 0, "start": 3.68, "end": 6.4, "text": " Sebastian will be talking about writing faster code.", "tokens": [50548, 31102, 486, 312, 1417, 466, 3579, 4663, 3089, 13, 50684], "temperature": 0.0, "avg_logprob": -0.36211768702456826, "compression_ratio": 1.6555023923444976, "no_speech_prob": 0.12214812636375427}, {"id": 2, "seek": 0, "start": 6.4, "end": 7.88, "text": " Give him a big hand.", "tokens": [50684, 5303, 796, 257, 955, 1011, 13, 50758], "temperature": 0.0, "avg_logprob": -0.36211768702456826, "compression_ratio": 1.6555023923444976, "no_speech_prob": 0.12214812636375427}, {"id": 3, "seek": 0, "start": 7.88, "end": 9.88, "text": " APPLAUSE", "tokens": [50758, 35298, 50858], "temperature": 0.0, "avg_logprob": -0.36211768702456826, "compression_ratio": 1.6555023923444976, "no_speech_prob": 0.12214812636375427}, {"id": 4, "seek": 0, "start": 14.68, "end": 17.080000000000002, "text": " OK, hi, everyone. Can you hear me?", "tokens": [51098, 2264, 11, 4879, 11, 1518, 13, 1664, 291, 1568, 385, 30, 51218], "temperature": 0.0, "avg_logprob": -0.36211768702456826, "compression_ratio": 1.6555023923444976, "no_speech_prob": 0.12214812636375427}, {"id": 5, "seek": 0, "start": 20.080000000000002, "end": 23.68, "text": " OK, so I would like to talk with you about writing faster code.", "tokens": [51368, 2264, 11, 370, 286, 576, 411, 281, 751, 365, 291, 466, 3579, 4663, 3089, 13, 51548], "temperature": 0.0, "avg_logprob": -0.36211768702456826, "compression_ratio": 1.6555023923444976, "no_speech_prob": 0.12214812636375427}, {"id": 6, "seek": 0, "start": 23.68, "end": 26.2, "text": " And last time I was giving a short talk,", "tokens": [51548, 400, 1036, 565, 286, 390, 2902, 257, 2099, 751, 11, 51674], "temperature": 0.0, "avg_logprob": -0.36211768702456826, "compression_ratio": 1.6555023923444976, "no_speech_prob": 0.12214812636375427}, {"id": 7, "seek": 0, "start": 26.2, "end": 28.400000000000002, "text": " short lightning talk about writing faster code,", "tokens": [51674, 2099, 16589, 751, 466, 3579, 4663, 3089, 11, 51784], "temperature": 0.0, "avg_logprob": -0.36211768702456826, "compression_ratio": 1.6555023923444976, "no_speech_prob": 0.12214812636375427}, {"id": 8, "seek": 2840, "start": 28.4, "end": 31.32, "text": " I remember someone pointed out that, well, basically,", "tokens": [50364, 286, 1604, 1580, 10932, 484, 300, 11, 731, 11, 1936, 11, 50510], "temperature": 0.0, "avg_logprob": -0.18073466566742444, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.025403574109077454}, {"id": 9, "seek": 2840, "start": 31.32, "end": 34.239999999999995, "text": " you can take your Python code, rewrite it in CRC++,", "tokens": [50510, 291, 393, 747, 428, 15329, 3089, 11, 28132, 309, 294, 14123, 34, 25472, 11, 50656], "temperature": 0.0, "avg_logprob": -0.18073466566742444, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.025403574109077454}, {"id": 10, "seek": 2840, "start": 34.239999999999995, "end": 36.8, "text": " and it will be faster.", "tokens": [50656, 293, 309, 486, 312, 4663, 13, 50784], "temperature": 0.0, "avg_logprob": -0.18073466566742444, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.025403574109077454}, {"id": 11, "seek": 2840, "start": 36.8, "end": 39.4, "text": " And I mean, the guy was right.", "tokens": [50784, 400, 286, 914, 11, 264, 2146, 390, 558, 13, 50914], "temperature": 0.0, "avg_logprob": -0.18073466566742444, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.025403574109077454}, {"id": 12, "seek": 2840, "start": 39.4, "end": 42.4, "text": " So take any piece of Python code, rewrite it in CRC++,", "tokens": [50914, 407, 747, 604, 2522, 295, 15329, 3089, 11, 28132, 309, 294, 14123, 34, 25472, 11, 51064], "temperature": 0.0, "avg_logprob": -0.18073466566742444, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.025403574109077454}, {"id": 13, "seek": 2840, "start": 42.4, "end": 45.519999999999996, "text": " and probably it will be automatically faster.", "tokens": [51064, 293, 1391, 309, 486, 312, 6772, 4663, 13, 51220], "temperature": 0.0, "avg_logprob": -0.18073466566742444, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.025403574109077454}, {"id": 14, "seek": 2840, "start": 45.519999999999996, "end": 48.64, "text": " So I was thinking, hmm, if I say just writing faster code,", "tokens": [51220, 407, 286, 390, 1953, 11, 16478, 11, 498, 286, 584, 445, 3579, 4663, 3089, 11, 51376], "temperature": 0.0, "avg_logprob": -0.18073466566742444, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.025403574109077454}, {"id": 15, "seek": 2840, "start": 48.64, "end": 51.44, "text": " it might not be clear if I mean only Python or not.", "tokens": [51376, 309, 1062, 406, 312, 1850, 498, 286, 914, 787, 15329, 420, 406, 13, 51516], "temperature": 0.0, "avg_logprob": -0.18073466566742444, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.025403574109077454}, {"id": 16, "seek": 2840, "start": 51.44, "end": 53.68, "text": " So I had to fix the title of my presentation.", "tokens": [51516, 407, 286, 632, 281, 3191, 264, 4876, 295, 452, 5860, 13, 51628], "temperature": 0.0, "avg_logprob": -0.18073466566742444, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.025403574109077454}, {"id": 17, "seek": 5368, "start": 54.68, "end": 56.68, "text": " LAUGHTER", "tokens": [50414, 46760, 50514], "temperature": 0.0, "avg_logprob": -0.1691703933606045, "compression_ratio": 1.6456953642384107, "no_speech_prob": 0.005018551368266344}, {"id": 18, "seek": 5368, "start": 56.68, "end": 58.68, "text": " And I was very happy with the new title.", "tokens": [50514, 400, 286, 390, 588, 2055, 365, 264, 777, 4876, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1691703933606045, "compression_ratio": 1.6456953642384107, "no_speech_prob": 0.005018551368266344}, {"id": 19, "seek": 5368, "start": 58.68, "end": 62.68, "text": " I mean, it makes it clear we are not going to talk about C or Java today.", "tokens": [50614, 286, 914, 11, 309, 1669, 309, 1850, 321, 366, 406, 516, 281, 751, 466, 383, 420, 10745, 965, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1691703933606045, "compression_ratio": 1.6456953642384107, "no_speech_prob": 0.005018551368266344}, {"id": 20, "seek": 5368, "start": 62.68, "end": 64.68, "text": " But then I realized the title is too long.", "tokens": [50814, 583, 550, 286, 5334, 264, 4876, 307, 886, 938, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1691703933606045, "compression_ratio": 1.6456953642384107, "no_speech_prob": 0.005018551368266344}, {"id": 21, "seek": 5368, "start": 64.68, "end": 67.68, "text": " I mean, even though it's very clear, it barely fits on the slide.", "tokens": [50914, 286, 914, 11, 754, 1673, 309, 311, 588, 1850, 11, 309, 10268, 9001, 322, 264, 4137, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1691703933606045, "compression_ratio": 1.6456953642384107, "no_speech_prob": 0.005018551368266344}, {"id": 22, "seek": 5368, "start": 67.68, "end": 69.68, "text": " So I had to change it again.", "tokens": [51064, 407, 286, 632, 281, 1319, 309, 797, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1691703933606045, "compression_ratio": 1.6456953642384107, "no_speech_prob": 0.005018551368266344}, {"id": 23, "seek": 5368, "start": 69.68, "end": 73.68, "text": " So I got the version that means exactly the same thing, but it's shorter.", "tokens": [51164, 407, 286, 658, 264, 3037, 300, 1355, 2293, 264, 912, 551, 11, 457, 309, 311, 11639, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1691703933606045, "compression_ratio": 1.6456953642384107, "no_speech_prob": 0.005018551368266344}, {"id": 24, "seek": 5368, "start": 73.68, "end": 75.68, "text": " So this is how I ended up with writing faster Python", "tokens": [51364, 407, 341, 307, 577, 286, 4590, 493, 365, 3579, 4663, 15329, 51464], "temperature": 0.0, "avg_logprob": -0.1691703933606045, "compression_ratio": 1.6456953642384107, "no_speech_prob": 0.005018551368266344}, {"id": 25, "seek": 5368, "start": 75.68, "end": 77.68, "text": " as a title for my today's talk.", "tokens": [51464, 382, 257, 4876, 337, 452, 965, 311, 751, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1691703933606045, "compression_ratio": 1.6456953642384107, "no_speech_prob": 0.005018551368266344}, {"id": 26, "seek": 5368, "start": 77.68, "end": 81.68, "text": " So let's put aside the flame war about which programming language is better.", "tokens": [51564, 407, 718, 311, 829, 7359, 264, 13287, 1516, 466, 597, 9410, 2856, 307, 1101, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1691703933606045, "compression_ratio": 1.6456953642384107, "no_speech_prob": 0.005018551368266344}, {"id": 27, "seek": 8168, "start": 81.68, "end": 85.68, "text": " We all know the answer. That's why you're here.", "tokens": [50364, 492, 439, 458, 264, 1867, 13, 663, 311, 983, 291, 434, 510, 13, 50564], "temperature": 0.0, "avg_logprob": -0.05780612338672985, "compression_ratio": 1.7078189300411524, "no_speech_prob": 0.013289157301187515}, {"id": 28, "seek": 8168, "start": 85.68, "end": 87.68, "text": " Python was not created to be a fast language", "tokens": [50564, 15329, 390, 406, 2942, 281, 312, 257, 2370, 2856, 50664], "temperature": 0.0, "avg_logprob": -0.05780612338672985, "compression_ratio": 1.7078189300411524, "no_speech_prob": 0.013289157301187515}, {"id": 29, "seek": 8168, "start": 87.68, "end": 91.68, "text": " that you would use for some computations where every nanosecond counts.", "tokens": [50664, 300, 291, 576, 764, 337, 512, 2807, 763, 689, 633, 14067, 541, 18882, 14893, 13, 50864], "temperature": 0.0, "avg_logprob": -0.05780612338672985, "compression_ratio": 1.7078189300411524, "no_speech_prob": 0.013289157301187515}, {"id": 30, "seek": 8168, "start": 91.68, "end": 93.68, "text": " And that's fine with me.", "tokens": [50864, 400, 300, 311, 2489, 365, 385, 13, 50964], "temperature": 0.0, "avg_logprob": -0.05780612338672985, "compression_ratio": 1.7078189300411524, "no_speech_prob": 0.013289157301187515}, {"id": 31, "seek": 8168, "start": 93.68, "end": 97.68, "text": " Python is a great programming language that is very easy and fun to use.", "tokens": [50964, 15329, 307, 257, 869, 9410, 2856, 300, 307, 588, 1858, 293, 1019, 281, 764, 13, 51164], "temperature": 0.0, "avg_logprob": -0.05780612338672985, "compression_ratio": 1.7078189300411524, "no_speech_prob": 0.013289157301187515}, {"id": 32, "seek": 8168, "start": 97.68, "end": 99.68, "text": " Python is very easy to learn.", "tokens": [51164, 15329, 307, 588, 1858, 281, 1466, 13, 51264], "temperature": 0.0, "avg_logprob": -0.05780612338672985, "compression_ratio": 1.7078189300411524, "no_speech_prob": 0.013289157301187515}, {"id": 33, "seek": 8168, "start": 99.68, "end": 102.68, "text": " The fact that it's so easy to read and write code in Python,", "tokens": [51264, 440, 1186, 300, 309, 311, 370, 1858, 281, 1401, 293, 2464, 3089, 294, 15329, 11, 51414], "temperature": 0.0, "avg_logprob": -0.05780612338672985, "compression_ratio": 1.7078189300411524, "no_speech_prob": 0.013289157301187515}, {"id": 34, "seek": 8168, "start": 102.68, "end": 107.68, "text": " it's very encouraging for people new to software development.", "tokens": [51414, 309, 311, 588, 14580, 337, 561, 777, 281, 4722, 3250, 13, 51664], "temperature": 0.0, "avg_logprob": -0.05780612338672985, "compression_ratio": 1.7078189300411524, "no_speech_prob": 0.013289157301187515}, {"id": 35, "seek": 10768, "start": 107.68, "end": 110.68, "text": " I see that it's getting more and more popular in schools", "tokens": [50364, 286, 536, 300, 309, 311, 1242, 544, 293, 544, 3743, 294, 4656, 50514], "temperature": 0.0, "avg_logprob": -0.07121598822438818, "compression_ratio": 1.751908396946565, "no_speech_prob": 0.025985736399888992}, {"id": 36, "seek": 10768, "start": 110.68, "end": 113.68, "text": " or at the universities as the first programming language.", "tokens": [50514, 420, 412, 264, 11779, 382, 264, 700, 9410, 2856, 13, 50664], "temperature": 0.0, "avg_logprob": -0.07121598822438818, "compression_ratio": 1.751908396946565, "no_speech_prob": 0.025985736399888992}, {"id": 37, "seek": 10768, "start": 113.68, "end": 115.68, "text": " And I am not surprised.", "tokens": [50664, 400, 286, 669, 406, 6100, 13, 50764], "temperature": 0.0, "avg_logprob": -0.07121598822438818, "compression_ratio": 1.751908396946565, "no_speech_prob": 0.025985736399888992}, {"id": 38, "seek": 10768, "start": 115.68, "end": 118.68, "text": " I mean, imagine you're completely new to programming", "tokens": [50764, 286, 914, 11, 3811, 291, 434, 2584, 777, 281, 9410, 50914], "temperature": 0.0, "avg_logprob": -0.07121598822438818, "compression_ratio": 1.751908396946565, "no_speech_prob": 0.025985736399888992}, {"id": 39, "seek": 10768, "start": 118.68, "end": 123.68, "text": " and someone tells you, hey, let me show you how much fun programming is", "tokens": [50914, 293, 1580, 5112, 291, 11, 4177, 11, 718, 385, 855, 291, 577, 709, 1019, 9410, 307, 51164], "temperature": 0.0, "avg_logprob": -0.07121598822438818, "compression_ratio": 1.751908396946565, "no_speech_prob": 0.025985736399888992}, {"id": 40, "seek": 10768, "start": 123.68, "end": 125.68, "text": " and let's start with something super simple.", "tokens": [51164, 293, 718, 311, 722, 365, 746, 1687, 2199, 13, 51264], "temperature": 0.0, "avg_logprob": -0.07121598822438818, "compression_ratio": 1.751908396946565, "no_speech_prob": 0.025985736399888992}, {"id": 41, "seek": 10768, "start": 125.68, "end": 127.68, "text": " Let's just print some text to the screen.", "tokens": [51264, 961, 311, 445, 4482, 512, 2487, 281, 264, 2568, 13, 51364], "temperature": 0.0, "avg_logprob": -0.07121598822438818, "compression_ratio": 1.751908396946565, "no_speech_prob": 0.025985736399888992}, {"id": 42, "seek": 10768, "start": 127.68, "end": 130.68, "text": " And then he shows you those two examples.", "tokens": [51364, 400, 550, 415, 3110, 291, 729, 732, 5110, 13, 51514], "temperature": 0.0, "avg_logprob": -0.07121598822438818, "compression_ratio": 1.751908396946565, "no_speech_prob": 0.025985736399888992}, {"id": 43, "seek": 10768, "start": 130.68, "end": 134.68, "text": " I mean, one of them is clearly not something that you want to show", "tokens": [51514, 286, 914, 11, 472, 295, 552, 307, 4448, 406, 746, 300, 291, 528, 281, 855, 51714], "temperature": 0.0, "avg_logprob": -0.07121598822438818, "compression_ratio": 1.751908396946565, "no_speech_prob": 0.025985736399888992}, {"id": 44, "seek": 13468, "start": 134.68, "end": 138.68, "text": " to a beginner to encourage him or her to start programming.", "tokens": [50364, 281, 257, 22080, 281, 5373, 796, 420, 720, 281, 722, 9410, 13, 50564], "temperature": 0.0, "avg_logprob": -0.05255335719645524, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.007195814047008753}, {"id": 45, "seek": 13468, "start": 138.68, "end": 142.68, "text": " But also, Python is not only useful for learning.", "tokens": [50564, 583, 611, 11, 15329, 307, 406, 787, 4420, 337, 2539, 13, 50764], "temperature": 0.0, "avg_logprob": -0.05255335719645524, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.007195814047008753}, {"id": 46, "seek": 13468, "start": 142.68, "end": 144.68, "text": " There are many big companies that are using Python.", "tokens": [50764, 821, 366, 867, 955, 3431, 300, 366, 1228, 15329, 13, 50864], "temperature": 0.0, "avg_logprob": -0.05255335719645524, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.007195814047008753}, {"id": 47, "seek": 13468, "start": 144.68, "end": 147.68, "text": " Companies with millions of users and billions of requests per month.", "tokens": [50864, 44031, 365, 6803, 295, 5022, 293, 17375, 295, 12475, 680, 1618, 13, 51014], "temperature": 0.0, "avg_logprob": -0.05255335719645524, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.007195814047008753}, {"id": 48, "seek": 13468, "start": 147.68, "end": 151.68, "text": " So your website is going to be fun using Python.", "tokens": [51014, 407, 428, 3144, 307, 516, 281, 312, 1019, 1228, 15329, 13, 51214], "temperature": 0.0, "avg_logprob": -0.05255335719645524, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.007195814047008753}, {"id": 49, "seek": 13468, "start": 151.68, "end": 153.68, "text": " So Python is usually fast enough.", "tokens": [51214, 407, 15329, 307, 2673, 2370, 1547, 13, 51314], "temperature": 0.0, "avg_logprob": -0.05255335719645524, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.007195814047008753}, {"id": 50, "seek": 13468, "start": 153.68, "end": 156.68, "text": " But what if you decide that it's not fast enough anymore?", "tokens": [51314, 583, 437, 498, 291, 4536, 300, 309, 311, 406, 2370, 1547, 3602, 30, 51464], "temperature": 0.0, "avg_logprob": -0.05255335719645524, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.007195814047008753}, {"id": 51, "seek": 13468, "start": 156.68, "end": 159.68, "text": " For example, your website starts giving you timeouts", "tokens": [51464, 1171, 1365, 11, 428, 3144, 3719, 2902, 291, 565, 7711, 51614], "temperature": 0.0, "avg_logprob": -0.05255335719645524, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.007195814047008753}, {"id": 52, "seek": 13468, "start": 159.68, "end": 162.68, "text": " or maybe a faster code will bring more money to your company.", "tokens": [51614, 420, 1310, 257, 4663, 3089, 486, 1565, 544, 1460, 281, 428, 2237, 13, 51764], "temperature": 0.0, "avg_logprob": -0.05255335719645524, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.007195814047008753}, {"id": 53, "seek": 16268, "start": 162.68, "end": 164.68, "text": " So it's time for optimization.", "tokens": [50364, 407, 309, 311, 565, 337, 19618, 13, 50464], "temperature": 0.0, "avg_logprob": -0.09493574213098596, "compression_ratio": 1.7061068702290076, "no_speech_prob": 0.0060967872850596905}, {"id": 54, "seek": 16268, "start": 164.68, "end": 166.68, "text": " But how do we optimize the code?", "tokens": [50464, 583, 577, 360, 321, 19719, 264, 3089, 30, 50564], "temperature": 0.0, "avg_logprob": -0.09493574213098596, "compression_ratio": 1.7061068702290076, "no_speech_prob": 0.0060967872850596905}, {"id": 55, "seek": 16268, "start": 166.68, "end": 168.68, "text": " Well, probably you need to follow some rules.", "tokens": [50564, 1042, 11, 1391, 291, 643, 281, 1524, 512, 4474, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09493574213098596, "compression_ratio": 1.7061068702290076, "no_speech_prob": 0.0060967872850596905}, {"id": 56, "seek": 16268, "start": 168.68, "end": 170.68, "text": " So let's try to Google for that.", "tokens": [50664, 407, 718, 311, 853, 281, 3329, 337, 300, 13, 50764], "temperature": 0.0, "avg_logprob": -0.09493574213098596, "compression_ratio": 1.7061068702290076, "no_speech_prob": 0.0060967872850596905}, {"id": 57, "seek": 16268, "start": 170.68, "end": 174.68, "text": " And if we open the first link, we see that there are only three rules.", "tokens": [50764, 400, 498, 321, 1269, 264, 700, 2113, 11, 321, 536, 300, 456, 366, 787, 1045, 4474, 13, 50964], "temperature": 0.0, "avg_logprob": -0.09493574213098596, "compression_ratio": 1.7061068702290076, "no_speech_prob": 0.0060967872850596905}, {"id": 58, "seek": 16268, "start": 174.68, "end": 176.68, "text": " Wow, it's going to be easier than we expected.", "tokens": [50964, 3153, 11, 309, 311, 516, 281, 312, 3571, 813, 321, 5176, 13, 51064], "temperature": 0.0, "avg_logprob": -0.09493574213098596, "compression_ratio": 1.7061068702290076, "no_speech_prob": 0.0060967872850596905}, {"id": 59, "seek": 16268, "start": 176.68, "end": 179.68, "text": " So let's take a closer look at those rules.", "tokens": [51064, 407, 718, 311, 747, 257, 4966, 574, 412, 729, 4474, 13, 51214], "temperature": 0.0, "avg_logprob": -0.09493574213098596, "compression_ratio": 1.7061068702290076, "no_speech_prob": 0.0060967872850596905}, {"id": 60, "seek": 16268, "start": 179.68, "end": 182.68, "text": " First rule of optimization, don't.", "tokens": [51214, 2386, 4978, 295, 19618, 11, 500, 380, 13, 51364], "temperature": 0.0, "avg_logprob": -0.09493574213098596, "compression_ratio": 1.7061068702290076, "no_speech_prob": 0.0060967872850596905}, {"id": 61, "seek": 16268, "start": 182.68, "end": 184.68, "text": " Okay, that was easy. Any questions?", "tokens": [51364, 1033, 11, 300, 390, 1858, 13, 2639, 1651, 30, 51464], "temperature": 0.0, "avg_logprob": -0.09493574213098596, "compression_ratio": 1.7061068702290076, "no_speech_prob": 0.0060967872850596905}, {"id": 62, "seek": 16268, "start": 184.68, "end": 187.68, "text": " Well, actually, now there is more to that.", "tokens": [51464, 1042, 11, 767, 11, 586, 456, 307, 544, 281, 300, 13, 51614], "temperature": 0.0, "avg_logprob": -0.09493574213098596, "compression_ratio": 1.7061068702290076, "no_speech_prob": 0.0060967872850596905}, {"id": 63, "seek": 16268, "start": 187.68, "end": 189.68, "text": " So what does it mean, don't?", "tokens": [51614, 407, 437, 775, 309, 914, 11, 500, 380, 30, 51714], "temperature": 0.0, "avg_logprob": -0.09493574213098596, "compression_ratio": 1.7061068702290076, "no_speech_prob": 0.0060967872850596905}, {"id": 64, "seek": 18968, "start": 189.68, "end": 193.68, "text": " Well, nine out of ten times when you think that you need optimization,", "tokens": [50364, 1042, 11, 4949, 484, 295, 2064, 1413, 562, 291, 519, 300, 291, 643, 19618, 11, 50564], "temperature": 0.0, "avg_logprob": -0.06603965163230896, "compression_ratio": 1.801418439716312, "no_speech_prob": 0.013293649069964886}, {"id": 65, "seek": 18968, "start": 193.68, "end": 197.68, "text": " you don't, especially in the early stage of your product's life.", "tokens": [50564, 291, 500, 380, 11, 2318, 294, 264, 2440, 3233, 295, 428, 1674, 311, 993, 13, 50764], "temperature": 0.0, "avg_logprob": -0.06603965163230896, "compression_ratio": 1.801418439716312, "no_speech_prob": 0.013293649069964886}, {"id": 66, "seek": 18968, "start": 197.68, "end": 200.68, "text": " You might think it would be nice to optimize your code a bit,", "tokens": [50764, 509, 1062, 519, 309, 576, 312, 1481, 281, 19719, 428, 3089, 257, 857, 11, 50914], "temperature": 0.0, "avg_logprob": -0.06603965163230896, "compression_ratio": 1.801418439716312, "no_speech_prob": 0.013293649069964886}, {"id": 67, "seek": 18968, "start": 200.68, "end": 204.68, "text": " but first of all, you will waste time doing something that is probably not needed.", "tokens": [50914, 457, 700, 295, 439, 11, 291, 486, 5964, 565, 884, 746, 300, 307, 1391, 406, 2978, 13, 51114], "temperature": 0.0, "avg_logprob": -0.06603965163230896, "compression_ratio": 1.801418439716312, "no_speech_prob": 0.013293649069964886}, {"id": 68, "seek": 18968, "start": 204.68, "end": 207.68, "text": " If you want your code to run faster,", "tokens": [51114, 759, 291, 528, 428, 3089, 281, 1190, 4663, 11, 51264], "temperature": 0.0, "avg_logprob": -0.06603965163230896, "compression_ratio": 1.801418439716312, "no_speech_prob": 0.013293649069964886}, {"id": 69, "seek": 18968, "start": 207.68, "end": 210.68, "text": " you can start with getting a faster hardware in the first place.", "tokens": [51264, 291, 393, 722, 365, 1242, 257, 4663, 8837, 294, 264, 700, 1081, 13, 51414], "temperature": 0.0, "avg_logprob": -0.06603965163230896, "compression_ratio": 1.801418439716312, "no_speech_prob": 0.013293649069964886}, {"id": 70, "seek": 18968, "start": 210.68, "end": 213.68, "text": " And second of all, optimization comes with a cost.", "tokens": [51414, 400, 1150, 295, 439, 11, 19618, 1487, 365, 257, 2063, 13, 51564], "temperature": 0.0, "avg_logprob": -0.06603965163230896, "compression_ratio": 1.801418439716312, "no_speech_prob": 0.013293649069964886}, {"id": 71, "seek": 18968, "start": 213.68, "end": 218.68, "text": " Most often, the only cost is the time that you spend optimizing your code.", "tokens": [51564, 4534, 2049, 11, 264, 787, 2063, 307, 264, 565, 300, 291, 3496, 40425, 428, 3089, 13, 51814], "temperature": 0.0, "avg_logprob": -0.06603965163230896, "compression_ratio": 1.801418439716312, "no_speech_prob": 0.013293649069964886}, {"id": 72, "seek": 21868, "start": 218.68, "end": 221.68, "text": " Well, sometimes it's also the time that you need to fix", "tokens": [50364, 1042, 11, 2171, 309, 311, 611, 264, 565, 300, 291, 643, 281, 3191, 50514], "temperature": 0.0, "avg_logprob": -0.05564934918374726, "compression_ratio": 1.837037037037037, "no_speech_prob": 0.002114278730005026}, {"id": 73, "seek": 21868, "start": 221.68, "end": 224.68, "text": " what you just broke with your optimization.", "tokens": [50514, 437, 291, 445, 6902, 365, 428, 19618, 13, 50664], "temperature": 0.0, "avg_logprob": -0.05564934918374726, "compression_ratio": 1.837037037037037, "no_speech_prob": 0.002114278730005026}, {"id": 74, "seek": 21868, "start": 224.68, "end": 227.68, "text": " But also optimize it, the optimized code might not be as readable", "tokens": [50664, 583, 611, 19719, 309, 11, 264, 26941, 3089, 1062, 406, 312, 382, 49857, 50814], "temperature": 0.0, "avg_logprob": -0.05564934918374726, "compression_ratio": 1.837037037037037, "no_speech_prob": 0.002114278730005026}, {"id": 75, "seek": 21868, "start": 227.68, "end": 229.68, "text": " as it was in the first place.", "tokens": [50814, 382, 309, 390, 294, 264, 700, 1081, 13, 50914], "temperature": 0.0, "avg_logprob": -0.05564934918374726, "compression_ratio": 1.837037037037037, "no_speech_prob": 0.002114278730005026}, {"id": 76, "seek": 21868, "start": 229.68, "end": 232.68, "text": " And maybe your code is running faster, but it's now using more memory.", "tokens": [50914, 400, 1310, 428, 3089, 307, 2614, 4663, 11, 457, 309, 311, 586, 1228, 544, 4675, 13, 51064], "temperature": 0.0, "avg_logprob": -0.05564934918374726, "compression_ratio": 1.837037037037037, "no_speech_prob": 0.002114278730005026}, {"id": 77, "seek": 21868, "start": 232.68, "end": 236.68, "text": " So unless you have really good reasons to optimize, don't do this.", "tokens": [51064, 407, 5969, 291, 362, 534, 665, 4112, 281, 19719, 11, 500, 380, 360, 341, 13, 51264], "temperature": 0.0, "avg_logprob": -0.05564934918374726, "compression_ratio": 1.837037037037037, "no_speech_prob": 0.002114278730005026}, {"id": 78, "seek": 21868, "start": 236.68, "end": 239.68, "text": " And if you know that you have reasons to optimize,", "tokens": [51264, 400, 498, 291, 458, 300, 291, 362, 4112, 281, 19719, 11, 51414], "temperature": 0.0, "avg_logprob": -0.05564934918374726, "compression_ratio": 1.837037037037037, "no_speech_prob": 0.002114278730005026}, {"id": 79, "seek": 21868, "start": 239.68, "end": 242.68, "text": " then we can move to the second rule of optimization.", "tokens": [51414, 550, 321, 393, 1286, 281, 264, 1150, 4978, 295, 19618, 13, 51564], "temperature": 0.0, "avg_logprob": -0.05564934918374726, "compression_ratio": 1.837037037037037, "no_speech_prob": 0.002114278730005026}, {"id": 80, "seek": 21868, "start": 242.68, "end": 244.68, "text": " Don't do this yet.", "tokens": [51564, 1468, 380, 360, 341, 1939, 13, 51664], "temperature": 0.0, "avg_logprob": -0.05564934918374726, "compression_ratio": 1.837037037037037, "no_speech_prob": 0.002114278730005026}, {"id": 81, "seek": 21868, "start": 244.68, "end": 247.68, "text": " And this is how I understand this rule.", "tokens": [51664, 400, 341, 307, 577, 286, 1223, 341, 4978, 13, 51814], "temperature": 0.0, "avg_logprob": -0.05564934918374726, "compression_ratio": 1.837037037037037, "no_speech_prob": 0.002114278730005026}, {"id": 82, "seek": 24768, "start": 247.68, "end": 250.68, "text": " So first, make sure your code works,", "tokens": [50364, 407, 700, 11, 652, 988, 428, 3089, 1985, 11, 50514], "temperature": 0.0, "avg_logprob": -0.09488088853897587, "compression_ratio": 1.6872427983539096, "no_speech_prob": 0.003967027645558119}, {"id": 83, "seek": 24768, "start": 250.68, "end": 253.68, "text": " then make sure you have a good test suit,", "tokens": [50514, 550, 652, 988, 291, 362, 257, 665, 1500, 5722, 11, 50664], "temperature": 0.0, "avg_logprob": -0.09488088853897587, "compression_ratio": 1.6872427983539096, "no_speech_prob": 0.003967027645558119}, {"id": 84, "seek": 24768, "start": 253.68, "end": 255.68, "text": " and only then you're ready for optimization.", "tokens": [50664, 293, 787, 550, 291, 434, 1919, 337, 19618, 13, 50764], "temperature": 0.0, "avg_logprob": -0.09488088853897587, "compression_ratio": 1.6872427983539096, "no_speech_prob": 0.003967027645558119}, {"id": 85, "seek": 24768, "start": 255.68, "end": 257.68, "text": " I love this rule.", "tokens": [50764, 286, 959, 341, 4978, 13, 50864], "temperature": 0.0, "avg_logprob": -0.09488088853897587, "compression_ratio": 1.6872427983539096, "no_speech_prob": 0.003967027645558119}, {"id": 86, "seek": 24768, "start": 257.68, "end": 259.68, "text": " It always reminds me how many times I broke it.", "tokens": [50864, 467, 1009, 12025, 385, 577, 867, 1413, 286, 6902, 309, 13, 50964], "temperature": 0.0, "avg_logprob": -0.09488088853897587, "compression_ratio": 1.6872427983539096, "no_speech_prob": 0.003967027645558119}, {"id": 87, "seek": 24768, "start": 259.68, "end": 262.68, "text": " I mean, so many times I was working on a piece of software,", "tokens": [50964, 286, 914, 11, 370, 867, 1413, 286, 390, 1364, 322, 257, 2522, 295, 4722, 11, 51114], "temperature": 0.0, "avg_logprob": -0.09488088853897587, "compression_ratio": 1.6872427983539096, "no_speech_prob": 0.003967027645558119}, {"id": 88, "seek": 24768, "start": 262.68, "end": 266.68, "text": " and I started thinking, hmm, maybe I can change this piece of code,", "tokens": [51114, 293, 286, 1409, 1953, 11, 16478, 11, 1310, 286, 393, 1319, 341, 2522, 295, 3089, 11, 51314], "temperature": 0.0, "avg_logprob": -0.09488088853897587, "compression_ratio": 1.6872427983539096, "no_speech_prob": 0.003967027645558119}, {"id": 89, "seek": 24768, "start": 266.68, "end": 268.68, "text": " and it will be faster,", "tokens": [51314, 293, 309, 486, 312, 4663, 11, 51414], "temperature": 0.0, "avg_logprob": -0.09488088853897587, "compression_ratio": 1.6872427983539096, "no_speech_prob": 0.003967027645558119}, {"id": 90, "seek": 24768, "start": 268.68, "end": 271.68, "text": " and maybe I will save like two lines of code.", "tokens": [51414, 293, 1310, 286, 486, 3155, 411, 732, 3876, 295, 3089, 13, 51564], "temperature": 0.0, "avg_logprob": -0.09488088853897587, "compression_ratio": 1.6872427983539096, "no_speech_prob": 0.003967027645558119}, {"id": 91, "seek": 24768, "start": 271.68, "end": 273.68, "text": " Was it a good idea?", "tokens": [51564, 3027, 309, 257, 665, 1558, 30, 51664], "temperature": 0.0, "avg_logprob": -0.09488088853897587, "compression_ratio": 1.6872427983539096, "no_speech_prob": 0.003967027645558119}, {"id": 92, "seek": 24768, "start": 273.68, "end": 275.68, "text": " No.", "tokens": [51664, 883, 13, 51764], "temperature": 0.0, "avg_logprob": -0.09488088853897587, "compression_ratio": 1.6872427983539096, "no_speech_prob": 0.003967027645558119}, {"id": 93, "seek": 27568, "start": 275.68, "end": 277.68, "text": " I ended up breaking things.", "tokens": [50364, 286, 4590, 493, 7697, 721, 13, 50464], "temperature": 0.0, "avg_logprob": -0.09195582341339628, "compression_ratio": 1.7569721115537849, "no_speech_prob": 0.013526315800845623}, {"id": 94, "seek": 27568, "start": 277.68, "end": 279.68, "text": " Most often I did end up breaking things,", "tokens": [50464, 4534, 2049, 286, 630, 917, 493, 7697, 721, 11, 50564], "temperature": 0.0, "avg_logprob": -0.09195582341339628, "compression_ratio": 1.7569721115537849, "no_speech_prob": 0.013526315800845623}, {"id": 95, "seek": 27568, "start": 279.68, "end": 282.68, "text": " but also I started jumping around the code,", "tokens": [50564, 457, 611, 286, 1409, 11233, 926, 264, 3089, 11, 50714], "temperature": 0.0, "avg_logprob": -0.09195582341339628, "compression_ratio": 1.7569721115537849, "no_speech_prob": 0.013526315800845623}, {"id": 96, "seek": 27568, "start": 282.68, "end": 286.68, "text": " and at some point I got confused what I was writing in the first place.", "tokens": [50714, 293, 412, 512, 935, 286, 658, 9019, 437, 286, 390, 3579, 294, 264, 700, 1081, 13, 50914], "temperature": 0.0, "avg_logprob": -0.09195582341339628, "compression_ratio": 1.7569721115537849, "no_speech_prob": 0.013526315800845623}, {"id": 97, "seek": 27568, "start": 286.68, "end": 288.68, "text": " Did it make my code faster?", "tokens": [50914, 2589, 309, 652, 452, 3089, 4663, 30, 51014], "temperature": 0.0, "avg_logprob": -0.09195582341339628, "compression_ratio": 1.7569721115537849, "no_speech_prob": 0.013526315800845623}, {"id": 98, "seek": 27568, "start": 288.68, "end": 292.68, "text": " I have no idea, because I had nothing to compare it to in the first place.", "tokens": [51014, 286, 362, 572, 1558, 11, 570, 286, 632, 1825, 281, 6794, 309, 281, 294, 264, 700, 1081, 13, 51214], "temperature": 0.0, "avg_logprob": -0.09195582341339628, "compression_ratio": 1.7569721115537849, "no_speech_prob": 0.013526315800845623}, {"id": 99, "seek": 27568, "start": 292.68, "end": 296.68, "text": " If I would finish writing the code and then try to improve it,", "tokens": [51214, 759, 286, 576, 2413, 3579, 264, 3089, 293, 550, 853, 281, 3470, 309, 11, 51414], "temperature": 0.0, "avg_logprob": -0.09195582341339628, "compression_ratio": 1.7569721115537849, "no_speech_prob": 0.013526315800845623}, {"id": 100, "seek": 27568, "start": 296.68, "end": 299.68, "text": " I could measure both solutions and compare them.", "tokens": [51414, 286, 727, 3481, 1293, 6547, 293, 6794, 552, 13, 51564], "temperature": 0.0, "avg_logprob": -0.09195582341339628, "compression_ratio": 1.7569721115537849, "no_speech_prob": 0.013526315800845623}, {"id": 101, "seek": 27568, "start": 299.68, "end": 302.68, "text": " But in that scenario, I could only guess.", "tokens": [51564, 583, 294, 300, 9005, 11, 286, 727, 787, 2041, 13, 51714], "temperature": 0.0, "avg_logprob": -0.09195582341339628, "compression_ratio": 1.7569721115537849, "no_speech_prob": 0.013526315800845623}, {"id": 102, "seek": 30268, "start": 302.68, "end": 305.68, "text": " And that brings me to the last rule of optimization.", "tokens": [50364, 400, 300, 5607, 385, 281, 264, 1036, 4978, 295, 19618, 13, 50514], "temperature": 0.0, "avg_logprob": -0.08573951143206972, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.0029284560587257147}, {"id": 103, "seek": 30268, "start": 305.68, "end": 308.68, "text": " Don't guess. Always profile your code.", "tokens": [50514, 1468, 380, 2041, 13, 11270, 7964, 428, 3089, 13, 50664], "temperature": 0.0, "avg_logprob": -0.08573951143206972, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.0029284560587257147}, {"id": 104, "seek": 30268, "start": 308.68, "end": 311.68, "text": " Human are terrible in predicting the bottlenecks of your code,", "tokens": [50664, 10294, 366, 6237, 294, 32884, 264, 44641, 2761, 295, 428, 3089, 11, 50814], "temperature": 0.0, "avg_logprob": -0.08573951143206972, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.0029284560587257147}, {"id": 105, "seek": 30268, "start": 311.68, "end": 315.68, "text": " so if you think that your code is slow,", "tokens": [50814, 370, 498, 291, 519, 300, 428, 3089, 307, 2964, 11, 51014], "temperature": 0.0, "avg_logprob": -0.08573951143206972, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.0029284560587257147}, {"id": 106, "seek": 30268, "start": 315.68, "end": 320.68, "text": " first profile it and then see what part of it takes most of the time.", "tokens": [51014, 700, 7964, 309, 293, 550, 536, 437, 644, 295, 309, 2516, 881, 295, 264, 565, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08573951143206972, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.0029284560587257147}, {"id": 107, "seek": 30268, "start": 320.68, "end": 326.68, "text": " Otherwise, you may end up spending time rewriting one piece of your code", "tokens": [51264, 10328, 11, 291, 815, 917, 493, 6434, 565, 319, 19868, 472, 2522, 295, 428, 3089, 51564], "temperature": 0.0, "avg_logprob": -0.08573951143206972, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.0029284560587257147}, {"id": 108, "seek": 30268, "start": 326.68, "end": 329.68, "text": " to just get like 1% of speed improvement,", "tokens": [51564, 281, 445, 483, 411, 502, 4, 295, 3073, 10444, 11, 51714], "temperature": 0.0, "avg_logprob": -0.08573951143206972, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.0029284560587257147}, {"id": 109, "seek": 32968, "start": 329.68, "end": 331.68, "text": " while there are other parts of your software", "tokens": [50364, 1339, 456, 366, 661, 3166, 295, 428, 4722, 50464], "temperature": 0.0, "avg_logprob": -0.08764484316803688, "compression_ratio": 1.6677966101694914, "no_speech_prob": 0.0033964719623327255}, {"id": 110, "seek": 32968, "start": 331.68, "end": 336.68, "text": " where you can gain way more improvement with less effort.", "tokens": [50464, 689, 291, 393, 6052, 636, 544, 10444, 365, 1570, 4630, 13, 50714], "temperature": 0.0, "avg_logprob": -0.08764484316803688, "compression_ratio": 1.6677966101694914, "no_speech_prob": 0.0033964719623327255}, {"id": 111, "seek": 32968, "start": 336.68, "end": 338.68, "text": " So there are plenty of profiling tools.", "tokens": [50714, 407, 456, 366, 7140, 295, 1740, 4883, 3873, 13, 50814], "temperature": 0.0, "avg_logprob": -0.08764484316803688, "compression_ratio": 1.6677966101694914, "no_speech_prob": 0.0033964719623327255}, {"id": 112, "seek": 32968, "start": 338.68, "end": 341.68, "text": " There were already quite a few talks during EuroPython about profiling,", "tokens": [50814, 821, 645, 1217, 1596, 257, 1326, 6686, 1830, 3010, 47, 88, 11943, 466, 1740, 4883, 11, 50964], "temperature": 0.0, "avg_logprob": -0.08764484316803688, "compression_ratio": 1.6677966101694914, "no_speech_prob": 0.0033964719623327255}, {"id": 113, "seek": 32968, "start": 341.68, "end": 343.68, "text": " so I will not go into the details,", "tokens": [50964, 370, 286, 486, 406, 352, 666, 264, 4365, 11, 51064], "temperature": 0.0, "avg_logprob": -0.08764484316803688, "compression_ratio": 1.6677966101694914, "no_speech_prob": 0.0033964719623327255}, {"id": 114, "seek": 32968, "start": 343.68, "end": 347.68, "text": " but if you don't know where to start, you can take a look at the C-profile module.", "tokens": [51064, 457, 498, 291, 500, 380, 458, 689, 281, 722, 11, 291, 393, 747, 257, 574, 412, 264, 383, 12, 29175, 794, 10088, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08764484316803688, "compression_ratio": 1.6677966101694914, "no_speech_prob": 0.0033964719623327255}, {"id": 115, "seek": 32968, "start": 347.68, "end": 351.68, "text": " It will show you a clear overview of how many times each function is called", "tokens": [51264, 467, 486, 855, 291, 257, 1850, 12492, 295, 577, 867, 1413, 1184, 2445, 307, 1219, 51464], "temperature": 0.0, "avg_logprob": -0.08764484316803688, "compression_ratio": 1.6677966101694914, "no_speech_prob": 0.0033964719623327255}, {"id": 116, "seek": 32968, "start": 351.68, "end": 353.68, "text": " and where the code is spent,", "tokens": [51464, 293, 689, 264, 3089, 307, 4418, 11, 51564], "temperature": 0.0, "avg_logprob": -0.08764484316803688, "compression_ratio": 1.6677966101694914, "no_speech_prob": 0.0033964719623327255}, {"id": 117, "seek": 32968, "start": 353.68, "end": 357.68, "text": " and if you want to have some more advanced formatting,", "tokens": [51564, 293, 498, 291, 528, 281, 362, 512, 544, 7339, 39366, 11, 51764], "temperature": 0.0, "avg_logprob": -0.08764484316803688, "compression_ratio": 1.6677966101694914, "no_speech_prob": 0.0033964719623327255}, {"id": 118, "seek": 35768, "start": 357.68, "end": 359.68, "text": " you can have the PSTADS module.", "tokens": [50364, 291, 393, 362, 264, 430, 6840, 6112, 50, 10088, 13, 50464], "temperature": 0.0, "avg_logprob": -0.14086023477407603, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.00335918297059834}, {"id": 119, "seek": 35768, "start": 359.68, "end": 361.68, "text": " Also, if you prefer the graphic interface,", "tokens": [50464, 2743, 11, 498, 291, 4382, 264, 14089, 9226, 11, 50564], "temperature": 0.0, "avg_logprob": -0.14086023477407603, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.00335918297059834}, {"id": 120, "seek": 35768, "start": 361.68, "end": 365.68, "text": " you can take a look at the Run Snake Run or SnakeVis libraries.", "tokens": [50564, 291, 393, 747, 257, 574, 412, 264, 8950, 33885, 8950, 420, 33885, 53, 271, 15148, 13, 50764], "temperature": 0.0, "avg_logprob": -0.14086023477407603, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.00335918297059834}, {"id": 121, "seek": 35768, "start": 365.68, "end": 367.68, "text": " So once we're ready for optimization,", "tokens": [50764, 407, 1564, 321, 434, 1919, 337, 19618, 11, 50864], "temperature": 0.0, "avg_logprob": -0.14086023477407603, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.00335918297059834}, {"id": 122, "seek": 35768, "start": 367.68, "end": 369.68, "text": " we have to decide on which area we want to focus.", "tokens": [50864, 321, 362, 281, 4536, 322, 597, 1859, 321, 528, 281, 1879, 13, 50964], "temperature": 0.0, "avg_logprob": -0.14086023477407603, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.00335918297059834}, {"id": 123, "seek": 35768, "start": 369.68, "end": 372.68, "text": " So there are different levels of optimization.", "tokens": [50964, 407, 456, 366, 819, 4358, 295, 19618, 13, 51114], "temperature": 0.0, "avg_logprob": -0.14086023477407603, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.00335918297059834}, {"id": 124, "seek": 35768, "start": 372.68, "end": 376.68, "text": " Starting from the highest level, you have the design level optimization.", "tokens": [51114, 16217, 490, 264, 6343, 1496, 11, 291, 362, 264, 1715, 1496, 19618, 13, 51314], "temperature": 0.0, "avg_logprob": -0.14086023477407603, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.00335918297059834}, {"id": 125, "seek": 35768, "start": 376.68, "end": 379.68, "text": " So depending on the constraints and priorities of your system,", "tokens": [51314, 407, 5413, 322, 264, 18491, 293, 15503, 295, 428, 1185, 11, 51464], "temperature": 0.0, "avg_logprob": -0.14086023477407603, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.00335918297059834}, {"id": 126, "seek": 35768, "start": 379.68, "end": 381.68, "text": " you can optimize it by redesigning it.", "tokens": [51464, 291, 393, 19719, 309, 538, 16762, 9676, 309, 13, 51564], "temperature": 0.0, "avg_logprob": -0.14086023477407603, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.00335918297059834}, {"id": 127, "seek": 35768, "start": 381.68, "end": 385.68, "text": " It might require rewriting your software in a different programming language", "tokens": [51564, 467, 1062, 3651, 319, 19868, 428, 4722, 294, 257, 819, 9410, 2856, 51764], "temperature": 0.0, "avg_logprob": -0.14086023477407603, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.00335918297059834}, {"id": 128, "seek": 38568, "start": 385.68, "end": 387.68, "text": " or changing the database type", "tokens": [50364, 420, 4473, 264, 8149, 2010, 50464], "temperature": 0.0, "avg_logprob": -0.04573729163721988, "compression_ratio": 1.7269372693726937, "no_speech_prob": 0.004697502590715885}, {"id": 129, "seek": 38568, "start": 387.68, "end": 390.68, "text": " or changing the architecture to perform less database queries.", "tokens": [50464, 420, 4473, 264, 9482, 281, 2042, 1570, 8149, 24109, 13, 50614], "temperature": 0.0, "avg_logprob": -0.04573729163721988, "compression_ratio": 1.7269372693726937, "no_speech_prob": 0.004697502590715885}, {"id": 130, "seek": 38568, "start": 390.68, "end": 394.68, "text": " So this kind of optimization will usually give you the best improvement,", "tokens": [50614, 407, 341, 733, 295, 19618, 486, 2673, 976, 291, 264, 1151, 10444, 11, 50814], "temperature": 0.0, "avg_logprob": -0.04573729163721988, "compression_ratio": 1.7269372693726937, "no_speech_prob": 0.004697502590715885}, {"id": 131, "seek": 38568, "start": 394.68, "end": 397.68, "text": " but it also takes most time to do this.", "tokens": [50814, 457, 309, 611, 2516, 881, 565, 281, 360, 341, 13, 50964], "temperature": 0.0, "avg_logprob": -0.04573729163721988, "compression_ratio": 1.7269372693726937, "no_speech_prob": 0.004697502590715885}, {"id": 132, "seek": 38568, "start": 397.68, "end": 400.68, "text": " So I don't encourage you to rewrite your software from the scratch,", "tokens": [50964, 407, 286, 500, 380, 5373, 291, 281, 28132, 428, 4722, 490, 264, 8459, 11, 51114], "temperature": 0.0, "avg_logprob": -0.04573729163721988, "compression_ratio": 1.7269372693726937, "no_speech_prob": 0.004697502590715885}, {"id": 133, "seek": 38568, "start": 400.68, "end": 404.68, "text": " but if you have some critical parts of your code that are run often,", "tokens": [51114, 457, 498, 291, 362, 512, 4924, 3166, 295, 428, 3089, 300, 366, 1190, 2049, 11, 51314], "temperature": 0.0, "avg_logprob": -0.04573729163721988, "compression_ratio": 1.7269372693726937, "no_speech_prob": 0.004697502590715885}, {"id": 134, "seek": 38568, "start": 404.68, "end": 408.68, "text": " you can optimize them by rewriting them in C or C++.", "tokens": [51314, 291, 393, 19719, 552, 538, 319, 19868, 552, 294, 383, 420, 383, 25472, 13, 51514], "temperature": 0.0, "avg_logprob": -0.04573729163721988, "compression_ratio": 1.7269372693726937, "no_speech_prob": 0.004697502590715885}, {"id": 135, "seek": 38568, "start": 408.68, "end": 412.68, "text": " Because C is faster, you will have some good speed improvement for free.", "tokens": [51514, 1436, 383, 307, 4663, 11, 291, 486, 362, 512, 665, 3073, 10444, 337, 1737, 13, 51714], "temperature": 0.0, "avg_logprob": -0.04573729163721988, "compression_ratio": 1.7269372693726937, "no_speech_prob": 0.004697502590715885}, {"id": 136, "seek": 41268, "start": 412.68, "end": 416.68, "text": " Well, not really for free, now you will have Python and C code in the same project.", "tokens": [50364, 1042, 11, 406, 534, 337, 1737, 11, 586, 291, 486, 362, 15329, 293, 383, 3089, 294, 264, 912, 1716, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08886924743652344, "compression_ratio": 1.6046511627906976, "no_speech_prob": 0.0011684703640639782}, {"id": 137, "seek": 41268, "start": 420.68, "end": 424.68, "text": " So one level lower, we have algorithms and data structures.", "tokens": [50764, 407, 472, 1496, 3126, 11, 321, 362, 14642, 293, 1412, 9227, 13, 50964], "temperature": 0.0, "avg_logprob": -0.08886924743652344, "compression_ratio": 1.6046511627906976, "no_speech_prob": 0.0011684703640639782}, {"id": 138, "seek": 41268, "start": 424.68, "end": 427.68, "text": " So knowing good algorithms together with their complexity", "tokens": [50964, 407, 5276, 665, 14642, 1214, 365, 641, 14024, 51114], "temperature": 0.0, "avg_logprob": -0.08886924743652344, "compression_ratio": 1.6046511627906976, "no_speech_prob": 0.0011684703640639782}, {"id": 139, "seek": 41268, "start": 427.68, "end": 432.68, "text": " definitely helps you creating a good and efficient software.", "tokens": [51114, 2138, 3665, 291, 4084, 257, 665, 293, 7148, 4722, 13, 51364], "temperature": 0.0, "avg_logprob": -0.08886924743652344, "compression_ratio": 1.6046511627906976, "no_speech_prob": 0.0011684703640639782}, {"id": 140, "seek": 41268, "start": 432.68, "end": 436.68, "text": " For example, if you want to get the sum of numbers from 1 to n,", "tokens": [51364, 1171, 1365, 11, 498, 291, 528, 281, 483, 264, 2408, 295, 3547, 490, 502, 281, 297, 11, 51564], "temperature": 0.0, "avg_logprob": -0.08886924743652344, "compression_ratio": 1.6046511627906976, "no_speech_prob": 0.0011684703640639782}, {"id": 141, "seek": 41268, "start": 436.68, "end": 440.68, "text": " the first idea might be to get a loop that goes through all the elements and adds them.", "tokens": [51564, 264, 700, 1558, 1062, 312, 281, 483, 257, 6367, 300, 1709, 807, 439, 264, 4959, 293, 10860, 552, 13, 51764], "temperature": 0.0, "avg_logprob": -0.08886924743652344, "compression_ratio": 1.6046511627906976, "no_speech_prob": 0.0011684703640639782}, {"id": 142, "seek": 44068, "start": 440.68, "end": 443.68, "text": " It will work, but it won't be fast.", "tokens": [50364, 467, 486, 589, 11, 457, 309, 1582, 380, 312, 2370, 13, 50514], "temperature": 0.0, "avg_logprob": -0.06985383198179047, "compression_ratio": 1.6940298507462686, "no_speech_prob": 0.0035017644986510277}, {"id": 143, "seek": 44068, "start": 443.68, "end": 446.68, "text": " Instead, you can use the algorithm for the arithmetic sum,", "tokens": [50514, 7156, 11, 291, 393, 764, 264, 9284, 337, 264, 42973, 2408, 11, 50664], "temperature": 0.0, "avg_logprob": -0.06985383198179047, "compression_ratio": 1.6940298507462686, "no_speech_prob": 0.0035017644986510277}, {"id": 144, "seek": 44068, "start": 446.68, "end": 451.68, "text": " which will give you the same results and it will be more efficient.", "tokens": [50664, 597, 486, 976, 291, 264, 912, 3542, 293, 309, 486, 312, 544, 7148, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06985383198179047, "compression_ratio": 1.6940298507462686, "no_speech_prob": 0.0035017644986510277}, {"id": 145, "seek": 44068, "start": 451.68, "end": 454.68, "text": " So the next level is the source code optimization.", "tokens": [50914, 407, 264, 958, 1496, 307, 264, 4009, 3089, 19618, 13, 51064], "temperature": 0.0, "avg_logprob": -0.06985383198179047, "compression_ratio": 1.6940298507462686, "no_speech_prob": 0.0035017644986510277}, {"id": 146, "seek": 44068, "start": 454.68, "end": 458.68, "text": " And this is something that I will talk about in the second part of the presentation.", "tokens": [51064, 400, 341, 307, 746, 300, 286, 486, 751, 466, 294, 264, 1150, 644, 295, 264, 5860, 13, 51264], "temperature": 0.0, "avg_logprob": -0.06985383198179047, "compression_ratio": 1.6940298507462686, "no_speech_prob": 0.0035017644986510277}, {"id": 147, "seek": 44068, "start": 458.68, "end": 460.68, "text": " Now we're moving to the build level,", "tokens": [51264, 823, 321, 434, 2684, 281, 264, 1322, 1496, 11, 51364], "temperature": 0.0, "avg_logprob": -0.06985383198179047, "compression_ratio": 1.6940298507462686, "no_speech_prob": 0.0035017644986510277}, {"id": 148, "seek": 44068, "start": 460.68, "end": 463.68, "text": " which involves setting up some specific build flags.", "tokens": [51364, 597, 11626, 3287, 493, 512, 2685, 1322, 23265, 13, 51514], "temperature": 0.0, "avg_logprob": -0.06985383198179047, "compression_ratio": 1.6940298507462686, "no_speech_prob": 0.0035017644986510277}, {"id": 149, "seek": 44068, "start": 463.68, "end": 467.68, "text": " So in your daily work, it's not something that you will do often.", "tokens": [51514, 407, 294, 428, 5212, 589, 11, 309, 311, 406, 746, 300, 291, 486, 360, 2049, 13, 51714], "temperature": 0.0, "avg_logprob": -0.06985383198179047, "compression_ratio": 1.6940298507462686, "no_speech_prob": 0.0035017644986510277}, {"id": 150, "seek": 46768, "start": 467.68, "end": 469.68, "text": " You can optimize Python for a specific architecture,", "tokens": [50364, 509, 393, 19719, 15329, 337, 257, 2685, 9482, 11, 50464], "temperature": 0.0, "avg_logprob": -0.07846528963935107, "compression_ratio": 1.693103448275862, "no_speech_prob": 0.010702535510063171}, {"id": 151, "seek": 46768, "start": 469.68, "end": 471.68, "text": " but if you're a web developer like me,", "tokens": [50464, 457, 498, 291, 434, 257, 3670, 10754, 411, 385, 11, 50564], "temperature": 0.0, "avg_logprob": -0.07846528963935107, "compression_ratio": 1.693103448275862, "no_speech_prob": 0.010702535510063171}, {"id": 152, "seek": 46768, "start": 471.68, "end": 474.68, "text": " this is either something that you will do once per machine", "tokens": [50564, 341, 307, 2139, 746, 300, 291, 486, 360, 1564, 680, 3479, 50714], "temperature": 0.0, "avg_logprob": -0.07846528963935107, "compression_ratio": 1.693103448275862, "no_speech_prob": 0.010702535510063171}, {"id": 153, "seek": 46768, "start": 474.68, "end": 476.68, "text": " or you won't bother at all.", "tokens": [50714, 420, 291, 1582, 380, 8677, 412, 439, 13, 50814], "temperature": 0.0, "avg_logprob": -0.07846528963935107, "compression_ratio": 1.693103448275862, "no_speech_prob": 0.010702535510063171}, {"id": 154, "seek": 46768, "start": 476.68, "end": 478.68, "text": " Next, we have the compile level.", "tokens": [50814, 3087, 11, 321, 362, 264, 31413, 1496, 13, 50914], "temperature": 0.0, "avg_logprob": -0.07846528963935107, "compression_ratio": 1.693103448275862, "no_speech_prob": 0.010702535510063171}, {"id": 155, "seek": 46768, "start": 478.68, "end": 484.68, "text": " So you can make some optimizations if your programming language has an ahead-of-time compiler.", "tokens": [50914, 407, 291, 393, 652, 512, 5028, 14455, 498, 428, 9410, 2856, 575, 364, 2286, 12, 2670, 12, 3766, 31958, 13, 51214], "temperature": 0.0, "avg_logprob": -0.07846528963935107, "compression_ratio": 1.693103448275862, "no_speech_prob": 0.010702535510063171}, {"id": 156, "seek": 46768, "start": 484.68, "end": 486.68, "text": " And since I'm talking about C Python today,", "tokens": [51214, 400, 1670, 286, 478, 1417, 466, 383, 15329, 965, 11, 51314], "temperature": 0.0, "avg_logprob": -0.07846528963935107, "compression_ratio": 1.693103448275862, "no_speech_prob": 0.010702535510063171}, {"id": 157, "seek": 46768, "start": 486.68, "end": 488.68, "text": " which doesn't really have a head-of-time compiler,", "tokens": [51314, 597, 1177, 380, 534, 362, 257, 1378, 12, 2670, 12, 3766, 31958, 11, 51414], "temperature": 0.0, "avg_logprob": -0.07846528963935107, "compression_ratio": 1.693103448275862, "no_speech_prob": 0.010702535510063171}, {"id": 158, "seek": 46768, "start": 488.68, "end": 491.68, "text": " we're going to skip that part as well.", "tokens": [51414, 321, 434, 516, 281, 10023, 300, 644, 382, 731, 13, 51564], "temperature": 0.0, "avg_logprob": -0.07846528963935107, "compression_ratio": 1.693103448275862, "no_speech_prob": 0.010702535510063171}, {"id": 159, "seek": 46768, "start": 491.68, "end": 494.68, "text": " And last but not least, we have the runtime level.", "tokens": [51564, 400, 1036, 457, 406, 1935, 11, 321, 362, 264, 34474, 1496, 13, 51714], "temperature": 0.0, "avg_logprob": -0.07846528963935107, "compression_ratio": 1.693103448275862, "no_speech_prob": 0.010702535510063171}, {"id": 160, "seek": 49468, "start": 494.68, "end": 497.68, "text": " So it's related with a specific compiler that you're using.", "tokens": [50364, 407, 309, 311, 4077, 365, 257, 2685, 31958, 300, 291, 434, 1228, 13, 50514], "temperature": 0.0, "avg_logprob": -0.06536523501078288, "compression_ratio": 1.7628865979381443, "no_speech_prob": 0.0019669122993946075}, {"id": 161, "seek": 49468, "start": 497.68, "end": 499.68, "text": " Some compilers are faster than the others.", "tokens": [50514, 2188, 715, 388, 433, 366, 4663, 813, 264, 2357, 13, 50614], "temperature": 0.0, "avg_logprob": -0.06536523501078288, "compression_ratio": 1.7628865979381443, "no_speech_prob": 0.0019669122993946075}, {"id": 162, "seek": 49468, "start": 499.68, "end": 502.68, "text": " So, for example, if you replace C Python with PyPy,", "tokens": [50614, 407, 11, 337, 1365, 11, 498, 291, 7406, 383, 15329, 365, 9953, 47, 88, 11, 50764], "temperature": 0.0, "avg_logprob": -0.06536523501078288, "compression_ratio": 1.7628865979381443, "no_speech_prob": 0.0019669122993946075}, {"id": 163, "seek": 49468, "start": 502.68, "end": 506.68, "text": " you can get some improvements depending on the use case of your software.", "tokens": [50764, 291, 393, 483, 512, 13797, 5413, 322, 264, 764, 1389, 295, 428, 4722, 13, 50964], "temperature": 0.0, "avg_logprob": -0.06536523501078288, "compression_ratio": 1.7628865979381443, "no_speech_prob": 0.0019669122993946075}, {"id": 164, "seek": 49468, "start": 508.68, "end": 512.6800000000001, "text": " But it really depends on what kind of piece of code you're writing.", "tokens": [51064, 583, 309, 534, 5946, 322, 437, 733, 295, 2522, 295, 3089, 291, 434, 3579, 13, 51264], "temperature": 0.0, "avg_logprob": -0.06536523501078288, "compression_ratio": 1.7628865979381443, "no_speech_prob": 0.0019669122993946075}, {"id": 165, "seek": 49468, "start": 512.6800000000001, "end": 516.6800000000001, "text": " So most of the time, once you set up on a specific language implementation,", "tokens": [51264, 407, 881, 295, 264, 565, 11, 1564, 291, 992, 493, 322, 257, 2685, 2856, 11420, 11, 51464], "temperature": 0.0, "avg_logprob": -0.06536523501078288, "compression_ratio": 1.7628865979381443, "no_speech_prob": 0.0019669122993946075}, {"id": 166, "seek": 49468, "start": 516.6800000000001, "end": 519.6800000000001, "text": " there's nothing you have to do to benefit from this kind of optimization.", "tokens": [51464, 456, 311, 1825, 291, 362, 281, 360, 281, 5121, 490, 341, 733, 295, 19618, 13, 51614], "temperature": 0.0, "avg_logprob": -0.06536523501078288, "compression_ratio": 1.7628865979381443, "no_speech_prob": 0.0019669122993946075}, {"id": 167, "seek": 49468, "start": 519.6800000000001, "end": 522.6800000000001, "text": " It's usually up to the creators of the compilers to optimize them.", "tokens": [51614, 467, 311, 2673, 493, 281, 264, 16039, 295, 264, 715, 388, 433, 281, 19719, 552, 13, 51764], "temperature": 0.0, "avg_logprob": -0.06536523501078288, "compression_ratio": 1.7628865979381443, "no_speech_prob": 0.0019669122993946075}, {"id": 168, "seek": 52268, "start": 522.68, "end": 526.68, "text": " So simply updating to the new version of the programming language you're using", "tokens": [50364, 407, 2935, 25113, 281, 264, 777, 3037, 295, 264, 9410, 2856, 291, 434, 1228, 50564], "temperature": 0.0, "avg_logprob": -0.06989656374292466, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.002895033685490489}, {"id": 169, "seek": 52268, "start": 526.68, "end": 530.68, "text": " can make your code run a bit faster.", "tokens": [50564, 393, 652, 428, 3089, 1190, 257, 857, 4663, 13, 50764], "temperature": 0.0, "avg_logprob": -0.06989656374292466, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.002895033685490489}, {"id": 170, "seek": 52268, "start": 530.68, "end": 534.68, "text": " So when you optimize, you probably want your code to run faster.", "tokens": [50764, 407, 562, 291, 19719, 11, 291, 1391, 528, 428, 3089, 281, 1190, 4663, 13, 50964], "temperature": 0.0, "avg_logprob": -0.06989656374292466, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.002895033685490489}, {"id": 171, "seek": 52268, "start": 534.68, "end": 537.68, "text": " And also use less memory.", "tokens": [50964, 400, 611, 764, 1570, 4675, 13, 51114], "temperature": 0.0, "avg_logprob": -0.06989656374292466, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.002895033685490489}, {"id": 172, "seek": 52268, "start": 537.68, "end": 540.68, "text": " And basically less of everything.", "tokens": [51114, 400, 1936, 1570, 295, 1203, 13, 51264], "temperature": 0.0, "avg_logprob": -0.06989656374292466, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.002895033685490489}, {"id": 173, "seek": 52268, "start": 540.68, "end": 543.68, "text": " The bad news is you can't have all of it.", "tokens": [51264, 440, 1578, 2583, 307, 291, 393, 380, 362, 439, 295, 309, 13, 51414], "temperature": 0.0, "avg_logprob": -0.06989656374292466, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.002895033685490489}, {"id": 174, "seek": 52268, "start": 543.68, "end": 547.68, "text": " Optimization in one area will usually cause deterioration in other areas.", "tokens": [51414, 35013, 2144, 294, 472, 1859, 486, 2673, 3082, 26431, 399, 294, 661, 3179, 13, 51614], "temperature": 0.0, "avg_logprob": -0.06989656374292466, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.002895033685490489}, {"id": 175, "seek": 52268, "start": 547.68, "end": 551.68, "text": " So you always have to decide which resources are crucial", "tokens": [51614, 407, 291, 1009, 362, 281, 4536, 597, 3593, 366, 11462, 51814], "temperature": 0.0, "avg_logprob": -0.06989656374292466, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.002895033685490489}, {"id": 176, "seek": 55168, "start": 551.68, "end": 554.68, "text": " and you have to optimize in that direction.", "tokens": [50364, 293, 291, 362, 281, 19719, 294, 300, 3513, 13, 50514], "temperature": 0.0, "avg_logprob": -0.059765015008314604, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0014462174149230123}, {"id": 177, "seek": 55168, "start": 554.68, "end": 558.68, "text": " So it's possible that optimization will have nothing to do with the speed", "tokens": [50514, 407, 309, 311, 1944, 300, 19618, 486, 362, 1825, 281, 360, 365, 264, 3073, 50714], "temperature": 0.0, "avg_logprob": -0.059765015008314604, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0014462174149230123}, {"id": 178, "seek": 55168, "start": 558.68, "end": 561.68, "text": " because there are other resources more important than the raw speed.", "tokens": [50714, 570, 456, 366, 661, 3593, 544, 1021, 813, 264, 8936, 3073, 13, 50864], "temperature": 0.0, "avg_logprob": -0.059765015008314604, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0014462174149230123}, {"id": 179, "seek": 55168, "start": 561.68, "end": 566.68, "text": " For example, who cares that your program is now 10 times faster", "tokens": [50864, 1171, 1365, 11, 567, 12310, 300, 428, 1461, 307, 586, 1266, 1413, 4663, 51114], "temperature": 0.0, "avg_logprob": -0.059765015008314604, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0014462174149230123}, {"id": 180, "seek": 55168, "start": 566.68, "end": 570.68, "text": " when it's crashing half of the time because it's running out of memory?", "tokens": [51114, 562, 309, 311, 26900, 1922, 295, 264, 565, 570, 309, 311, 2614, 484, 295, 4675, 30, 51314], "temperature": 0.0, "avg_logprob": -0.059765015008314604, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0014462174149230123}, {"id": 181, "seek": 55168, "start": 571.68, "end": 576.68, "text": " Also, another important resource that people are often forgetting is the sanity.", "tokens": [51364, 2743, 11, 1071, 1021, 7684, 300, 561, 366, 2049, 25428, 307, 264, 47892, 13, 51614], "temperature": 0.0, "avg_logprob": -0.059765015008314604, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0014462174149230123}, {"id": 182, "seek": 55168, "start": 576.68, "end": 579.68, "text": " A sanity of a person that will be maintaining your code.", "tokens": [51614, 316, 47892, 295, 257, 954, 300, 486, 312, 14916, 428, 3089, 13, 51764], "temperature": 0.0, "avg_logprob": -0.059765015008314604, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0014462174149230123}, {"id": 183, "seek": 57968, "start": 579.68, "end": 583.68, "text": " So please be nice to that person. You never know who that might be.", "tokens": [50364, 407, 1767, 312, 1481, 281, 300, 954, 13, 509, 1128, 458, 567, 300, 1062, 312, 13, 50564], "temperature": 0.0, "avg_logprob": -0.09569614624308649, "compression_ratio": 1.5447470817120623, "no_speech_prob": 0.0020694262348115444}, {"id": 184, "seek": 57968, "start": 583.68, "end": 587.68, "text": " Yeah, so unless you're really writing a throwaway code,", "tokens": [50564, 865, 11, 370, 5969, 291, 434, 534, 3579, 257, 3507, 10318, 3089, 11, 50764], "temperature": 0.0, "avg_logprob": -0.09569614624308649, "compression_ratio": 1.5447470817120623, "no_speech_prob": 0.0020694262348115444}, {"id": 185, "seek": 57968, "start": 587.68, "end": 590.68, "text": " if you're making your code harder to read and maintain,", "tokens": [50764, 498, 291, 434, 1455, 428, 3089, 6081, 281, 1401, 293, 6909, 11, 50914], "temperature": 0.0, "avg_logprob": -0.09569614624308649, "compression_ratio": 1.5447470817120623, "no_speech_prob": 0.0020694262348115444}, {"id": 186, "seek": 57968, "start": 590.68, "end": 593.68, "text": " then you're probably doing it wrong.", "tokens": [50914, 550, 291, 434, 1391, 884, 309, 2085, 13, 51064], "temperature": 0.0, "avg_logprob": -0.09569614624308649, "compression_ratio": 1.5447470817120623, "no_speech_prob": 0.0020694262348115444}, {"id": 187, "seek": 57968, "start": 593.68, "end": 597.68, "text": " So having those things clear, let's jump straight to how you can write faster Python.", "tokens": [51064, 407, 1419, 729, 721, 1850, 11, 718, 311, 3012, 2997, 281, 577, 291, 393, 2464, 4663, 15329, 13, 51264], "temperature": 0.0, "avg_logprob": -0.09569614624308649, "compression_ratio": 1.5447470817120623, "no_speech_prob": 0.0020694262348115444}, {"id": 188, "seek": 57968, "start": 597.68, "end": 600.68, "text": " Also known as source code optimization.", "tokens": [51264, 2743, 2570, 382, 4009, 3089, 19618, 13, 51414], "temperature": 0.0, "avg_logprob": -0.09569614624308649, "compression_ratio": 1.5447470817120623, "no_speech_prob": 0.0020694262348115444}, {"id": 189, "seek": 57968, "start": 604.68, "end": 608.68, "text": " In my examples, I'm using the version 3.5.1 of Python.", "tokens": [51614, 682, 452, 5110, 11, 286, 478, 1228, 264, 3037, 805, 13, 20, 13, 16, 295, 15329, 13, 51814], "temperature": 0.0, "avg_logprob": -0.09569614624308649, "compression_ratio": 1.5447470817120623, "no_speech_prob": 0.0020694262348115444}, {"id": 190, "seek": 60868, "start": 608.68, "end": 610.68, "text": " Together with iPython.", "tokens": [50364, 15911, 365, 741, 47, 88, 11943, 13, 50464], "temperature": 0.0, "avg_logprob": -0.10657816786107009, "compression_ratio": 1.7877697841726619, "no_speech_prob": 0.0027693279553204775}, {"id": 191, "seek": 60868, "start": 610.68, "end": 613.68, "text": " Although the examples should work in both Python 2 and Python 3.", "tokens": [50464, 5780, 264, 5110, 820, 589, 294, 1293, 15329, 568, 293, 15329, 805, 13, 50614], "temperature": 0.0, "avg_logprob": -0.10657816786107009, "compression_ratio": 1.7877697841726619, "no_speech_prob": 0.0027693279553204775}, {"id": 192, "seek": 60868, "start": 613.68, "end": 616.68, "text": " So for measuring the execution time of my code,", "tokens": [50614, 407, 337, 13389, 264, 15058, 565, 295, 452, 3089, 11, 50764], "temperature": 0.0, "avg_logprob": -0.10657816786107009, "compression_ratio": 1.7877697841726619, "no_speech_prob": 0.0027693279553204775}, {"id": 193, "seek": 60868, "start": 616.68, "end": 618.68, "text": " I will be using the magic timing function.", "tokens": [50764, 286, 486, 312, 1228, 264, 5585, 10822, 2445, 13, 50864], "temperature": 0.0, "avg_logprob": -0.10657816786107009, "compression_ratio": 1.7877697841726619, "no_speech_prob": 0.0027693279553204775}, {"id": 194, "seek": 60868, "start": 618.68, "end": 621.68, "text": " It has some overhead comparing to the standard timing library,", "tokens": [50864, 467, 575, 512, 19922, 15763, 281, 264, 3832, 10822, 6405, 11, 51014], "temperature": 0.0, "avg_logprob": -0.10657816786107009, "compression_ratio": 1.7877697841726619, "no_speech_prob": 0.0027693279553204775}, {"id": 195, "seek": 60868, "start": 621.68, "end": 625.68, "text": " but it doesn't really matter because as long as we use the same method", "tokens": [51014, 457, 309, 1177, 380, 534, 1871, 570, 382, 938, 382, 321, 764, 264, 912, 3170, 51214], "temperature": 0.0, "avg_logprob": -0.10657816786107009, "compression_ratio": 1.7877697841726619, "no_speech_prob": 0.0027693279553204775}, {"id": 196, "seek": 60868, "start": 625.68, "end": 628.68, "text": " to measure execution time of different functions,", "tokens": [51214, 281, 3481, 15058, 565, 295, 819, 6828, 11, 51364], "temperature": 0.0, "avg_logprob": -0.10657816786107009, "compression_ratio": 1.7877697841726619, "no_speech_prob": 0.0027693279553204775}, {"id": 197, "seek": 60868, "start": 628.68, "end": 631.68, "text": " we only need to know which method is faster than and by how much.", "tokens": [51364, 321, 787, 643, 281, 458, 597, 3170, 307, 4663, 813, 293, 538, 577, 709, 13, 51514], "temperature": 0.0, "avg_logprob": -0.10657816786107009, "compression_ratio": 1.7877697841726619, "no_speech_prob": 0.0027693279553204775}, {"id": 198, "seek": 60868, "start": 631.68, "end": 635.68, "text": " So for each of my examples, I will write different versions of code,", "tokens": [51514, 407, 337, 1184, 295, 452, 5110, 11, 286, 486, 2464, 819, 9606, 295, 3089, 11, 51714], "temperature": 0.0, "avg_logprob": -0.10657816786107009, "compression_ratio": 1.7877697841726619, "no_speech_prob": 0.0027693279553204775}, {"id": 199, "seek": 63568, "start": 635.68, "end": 639.68, "text": " measure the execution time, and compare them.", "tokens": [50364, 3481, 264, 15058, 565, 11, 293, 6794, 552, 13, 50564], "temperature": 0.0, "avg_logprob": -0.09775668530424764, "compression_ratio": 1.667870036101083, "no_speech_prob": 0.005084081087261438}, {"id": 200, "seek": 63568, "start": 639.68, "end": 642.68, "text": " So let's start with something simple.", "tokens": [50564, 407, 718, 311, 722, 365, 746, 2199, 13, 50714], "temperature": 0.0, "avg_logprob": -0.09775668530424764, "compression_ratio": 1.667870036101083, "no_speech_prob": 0.005084081087261438}, {"id": 201, "seek": 63568, "start": 642.68, "end": 645.68, "text": " Let's say you want to count the number of elements in a list.", "tokens": [50714, 961, 311, 584, 291, 528, 281, 1207, 264, 1230, 295, 4959, 294, 257, 1329, 13, 50864], "temperature": 0.0, "avg_logprob": -0.09775668530424764, "compression_ratio": 1.667870036101083, "no_speech_prob": 0.005084081087261438}, {"id": 202, "seek": 63568, "start": 645.68, "end": 648.68, "text": " You can easily write a simple loop that will increment the counter,", "tokens": [50864, 509, 393, 3612, 2464, 257, 2199, 6367, 300, 486, 26200, 264, 5682, 11, 51014], "temperature": 0.0, "avg_logprob": -0.09775668530424764, "compression_ratio": 1.667870036101083, "no_speech_prob": 0.005084081087261438}, {"id": 203, "seek": 63568, "start": 648.68, "end": 651.68, "text": " and while this will work, it will be very slow.", "tokens": [51014, 293, 1339, 341, 486, 589, 11, 309, 486, 312, 588, 2964, 13, 51164], "temperature": 0.0, "avg_logprob": -0.09775668530424764, "compression_ratio": 1.667870036101083, "no_speech_prob": 0.005084081087261438}, {"id": 204, "seek": 63568, "start": 651.68, "end": 654.68, "text": " You can achieve the same results using the built-in LAN function.", "tokens": [51164, 509, 393, 4584, 264, 912, 3542, 1228, 264, 3094, 12, 259, 37387, 2445, 13, 51314], "temperature": 0.0, "avg_logprob": -0.09775668530424764, "compression_ratio": 1.667870036101083, "no_speech_prob": 0.005084081087261438}, {"id": 205, "seek": 63568, "start": 654.68, "end": 657.68, "text": " And as you can see, for only one million of results,", "tokens": [51314, 400, 382, 291, 393, 536, 11, 337, 787, 472, 2459, 295, 3542, 11, 51464], "temperature": 0.0, "avg_logprob": -0.09775668530424764, "compression_ratio": 1.667870036101083, "no_speech_prob": 0.005084081087261438}, {"id": 206, "seek": 63568, "start": 657.68, "end": 659.68, "text": " the difference is insanely huge.", "tokens": [51464, 264, 2649, 307, 40965, 2603, 13, 51564], "temperature": 0.0, "avg_logprob": -0.09775668530424764, "compression_ratio": 1.667870036101083, "no_speech_prob": 0.005084081087261438}, {"id": 207, "seek": 63568, "start": 659.68, "end": 662.68, "text": " So my first advice is not to reinvent the wheel,", "tokens": [51564, 407, 452, 700, 5192, 307, 406, 281, 33477, 264, 5589, 11, 51714], "temperature": 0.0, "avg_logprob": -0.09775668530424764, "compression_ratio": 1.667870036101083, "no_speech_prob": 0.005084081087261438}, {"id": 208, "seek": 66268, "start": 662.68, "end": 665.68, "text": " but first check if there is a function that you can use.", "tokens": [50364, 457, 700, 1520, 498, 456, 307, 257, 2445, 300, 291, 393, 764, 13, 50514], "temperature": 0.0, "avg_logprob": -0.044843503407069614, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.005033700726926327}, {"id": 209, "seek": 66268, "start": 665.68, "end": 668.68, "text": " Python 3.5 has 68 built-in functions,", "tokens": [50514, 15329, 805, 13, 20, 575, 23317, 3094, 12, 259, 6828, 11, 50664], "temperature": 0.0, "avg_logprob": -0.044843503407069614, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.005033700726926327}, {"id": 210, "seek": 66268, "start": 668.68, "end": 670.68, "text": " so it's nice to take a look at them", "tokens": [50664, 370, 309, 311, 1481, 281, 747, 257, 574, 412, 552, 50764], "temperature": 0.0, "avg_logprob": -0.044843503407069614, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.005033700726926327}, {"id": 211, "seek": 66268, "start": 670.68, "end": 672.68, "text": " and keep them in the back of your head", "tokens": [50764, 293, 1066, 552, 294, 264, 646, 295, 428, 1378, 50864], "temperature": 0.0, "avg_logprob": -0.044843503407069614, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.005033700726926327}, {"id": 212, "seek": 66268, "start": 672.68, "end": 674.68, "text": " because they might be handy at some point.", "tokens": [50864, 570, 436, 1062, 312, 13239, 412, 512, 935, 13, 50964], "temperature": 0.0, "avg_logprob": -0.044843503407069614, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.005033700726926327}, {"id": 213, "seek": 66268, "start": 674.68, "end": 678.68, "text": " Also, before you start writing your own version of order dictionary", "tokens": [50964, 2743, 11, 949, 291, 722, 3579, 428, 1065, 3037, 295, 1668, 25890, 51164], "temperature": 0.0, "avg_logprob": -0.044843503407069614, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.005033700726926327}, {"id": 214, "seek": 66268, "start": 678.68, "end": 680.68, "text": " or a dictionary with default values,", "tokens": [51164, 420, 257, 25890, 365, 7576, 4190, 11, 51264], "temperature": 0.0, "avg_logprob": -0.044843503407069614, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.005033700726926327}, {"id": 215, "seek": 66268, "start": 680.68, "end": 683.68, "text": " take a look at the collection module from the standard library.", "tokens": [51264, 747, 257, 574, 412, 264, 5765, 10088, 490, 264, 3832, 6405, 13, 51414], "temperature": 0.0, "avg_logprob": -0.044843503407069614, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.005033700726926327}, {"id": 216, "seek": 66268, "start": 683.68, "end": 687.68, "text": " Even though it contains only like 10 different data types,", "tokens": [51414, 2754, 1673, 309, 8306, 787, 411, 1266, 819, 1412, 3467, 11, 51614], "temperature": 0.0, "avg_logprob": -0.044843503407069614, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.005033700726926327}, {"id": 217, "seek": 66268, "start": 687.68, "end": 690.68, "text": " those are probably the data types you are looking for", "tokens": [51614, 729, 366, 1391, 264, 1412, 3467, 291, 366, 1237, 337, 51764], "temperature": 0.0, "avg_logprob": -0.044843503407069614, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.005033700726926327}, {"id": 218, "seek": 69068, "start": 690.68, "end": 692.68, "text": " if the standard ones are not enough.", "tokens": [50364, 498, 264, 3832, 2306, 366, 406, 1547, 13, 50464], "temperature": 0.0, "avg_logprob": -0.06513866037130356, "compression_ratio": 1.713235294117647, "no_speech_prob": 0.005461706779897213}, {"id": 219, "seek": 69068, "start": 694.68, "end": 697.68, "text": " So let's say you have a list of one million elements,", "tokens": [50564, 407, 718, 311, 584, 291, 362, 257, 1329, 295, 472, 2459, 4959, 11, 50714], "temperature": 0.0, "avg_logprob": -0.06513866037130356, "compression_ratio": 1.713235294117647, "no_speech_prob": 0.005461706779897213}, {"id": 220, "seek": 69068, "start": 697.68, "end": 699.68, "text": " and you want to select only the odd numbers.", "tokens": [50714, 293, 291, 528, 281, 3048, 787, 264, 7401, 3547, 13, 50814], "temperature": 0.0, "avg_logprob": -0.06513866037130356, "compression_ratio": 1.713235294117647, "no_speech_prob": 0.005461706779897213}, {"id": 221, "seek": 69068, "start": 699.68, "end": 702.68, "text": " So the naive version would be to use the for loop.", "tokens": [50814, 407, 264, 29052, 3037, 576, 312, 281, 764, 264, 337, 6367, 13, 50964], "temperature": 0.0, "avg_logprob": -0.06513866037130356, "compression_ratio": 1.713235294117647, "no_speech_prob": 0.005461706779897213}, {"id": 222, "seek": 69068, "start": 702.68, "end": 705.68, "text": " So for each element of the list, you check if it's odd,", "tokens": [50964, 407, 337, 1184, 4478, 295, 264, 1329, 11, 291, 1520, 498, 309, 311, 7401, 11, 51114], "temperature": 0.0, "avg_logprob": -0.06513866037130356, "compression_ratio": 1.713235294117647, "no_speech_prob": 0.005461706779897213}, {"id": 223, "seek": 69068, "start": 705.68, "end": 707.68, "text": " and if it is, you add it to another list.", "tokens": [51114, 293, 498, 309, 307, 11, 291, 909, 309, 281, 1071, 1329, 13, 51214], "temperature": 0.0, "avg_logprob": -0.06513866037130356, "compression_ratio": 1.713235294117647, "no_speech_prob": 0.005461706779897213}, {"id": 224, "seek": 69068, "start": 707.68, "end": 710.68, "text": " But I already show you in the previous example", "tokens": [51214, 583, 286, 1217, 855, 291, 294, 264, 3894, 1365, 51364], "temperature": 0.0, "avg_logprob": -0.06513866037130356, "compression_ratio": 1.713235294117647, "no_speech_prob": 0.005461706779897213}, {"id": 225, "seek": 69068, "start": 710.68, "end": 714.68, "text": " that in most cases, for loops can be replaced with something better.", "tokens": [51364, 300, 294, 881, 3331, 11, 337, 16121, 393, 312, 10772, 365, 746, 1101, 13, 51564], "temperature": 0.0, "avg_logprob": -0.06513866037130356, "compression_ratio": 1.713235294117647, "no_speech_prob": 0.005461706779897213}, {"id": 226, "seek": 69068, "start": 714.68, "end": 718.68, "text": " In this case, you could use the built-in filter function instead.", "tokens": [51564, 682, 341, 1389, 11, 291, 727, 764, 264, 3094, 12, 259, 6608, 2445, 2602, 13, 51764], "temperature": 0.0, "avg_logprob": -0.06513866037130356, "compression_ratio": 1.713235294117647, "no_speech_prob": 0.005461706779897213}, {"id": 227, "seek": 71868, "start": 718.68, "end": 721.68, "text": " And in Python 2, filter was returning a list directly.", "tokens": [50364, 400, 294, 15329, 568, 11, 6608, 390, 12678, 257, 1329, 3838, 13, 50514], "temperature": 0.0, "avg_logprob": -0.07620426891295891, "compression_ratio": 1.813953488372093, "no_speech_prob": 0.0031032939441502094}, {"id": 228, "seek": 71868, "start": 721.68, "end": 723.68, "text": " In Python 3, it's returning an iterator.", "tokens": [50514, 682, 15329, 805, 11, 309, 311, 12678, 364, 17138, 1639, 13, 50614], "temperature": 0.0, "avg_logprob": -0.07620426891295891, "compression_ratio": 1.813953488372093, "no_speech_prob": 0.0031032939441502094}, {"id": 229, "seek": 71868, "start": 723.68, "end": 725.68, "text": " So I have to call the list function", "tokens": [50614, 407, 286, 362, 281, 818, 264, 1329, 2445, 50714], "temperature": 0.0, "avg_logprob": -0.07620426891295891, "compression_ratio": 1.813953488372093, "no_speech_prob": 0.0031032939441502094}, {"id": 230, "seek": 71868, "start": 725.68, "end": 729.68, "text": " to get the same results as in case of the for loop.", "tokens": [50714, 281, 483, 264, 912, 3542, 382, 294, 1389, 295, 264, 337, 6367, 13, 50914], "temperature": 0.0, "avg_logprob": -0.07620426891295891, "compression_ratio": 1.813953488372093, "no_speech_prob": 0.0031032939441502094}, {"id": 231, "seek": 71868, "start": 729.68, "end": 733.68, "text": " And even though the list function has some impact on the performance,", "tokens": [50914, 400, 754, 1673, 264, 1329, 2445, 575, 512, 2712, 322, 264, 3389, 11, 51114], "temperature": 0.0, "avg_logprob": -0.07620426891295891, "compression_ratio": 1.813953488372093, "no_speech_prob": 0.0031032939441502094}, {"id": 232, "seek": 71868, "start": 733.68, "end": 736.68, "text": " it's negligible comparing to the time spent in the filter function.", "tokens": [51114, 309, 311, 32570, 964, 15763, 281, 264, 565, 4418, 294, 264, 6608, 2445, 13, 51264], "temperature": 0.0, "avg_logprob": -0.07620426891295891, "compression_ratio": 1.813953488372093, "no_speech_prob": 0.0031032939441502094}, {"id": 233, "seek": 71868, "start": 736.68, "end": 740.68, "text": " Yet, you can see that filter performs even slower than the for loop.", "tokens": [51264, 10890, 11, 291, 393, 536, 300, 6608, 26213, 754, 14009, 813, 264, 337, 6367, 13, 51464], "temperature": 0.0, "avg_logprob": -0.07620426891295891, "compression_ratio": 1.813953488372093, "no_speech_prob": 0.0031032939441502094}, {"id": 234, "seek": 71868, "start": 741.68, "end": 742.68, "text": " Why does this happen?", "tokens": [51514, 1545, 775, 341, 1051, 30, 51564], "temperature": 0.0, "avg_logprob": -0.07620426891295891, "compression_ratio": 1.813953488372093, "no_speech_prob": 0.0031032939441502094}, {"id": 235, "seek": 71868, "start": 742.68, "end": 745.68, "text": " Well, the fact that filter is returning now an iterator", "tokens": [51564, 1042, 11, 264, 1186, 300, 6608, 307, 12678, 586, 364, 17138, 1639, 51714], "temperature": 0.0, "avg_logprob": -0.07620426891295891, "compression_ratio": 1.813953488372093, "no_speech_prob": 0.0031032939441502094}, {"id": 236, "seek": 74568, "start": 745.68, "end": 749.68, "text": " is a clear sign that it's a wrong use case for this kind of function.", "tokens": [50364, 307, 257, 1850, 1465, 300, 309, 311, 257, 2085, 764, 1389, 337, 341, 733, 295, 2445, 13, 50564], "temperature": 0.0, "avg_logprob": -0.06858479976654053, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.0016228818567469716}, {"id": 237, "seek": 74568, "start": 749.68, "end": 753.68, "text": " So if you want to get the whole list as a result,", "tokens": [50564, 407, 498, 291, 528, 281, 483, 264, 1379, 1329, 382, 257, 1874, 11, 50764], "temperature": 0.0, "avg_logprob": -0.06858479976654053, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.0016228818567469716}, {"id": 238, "seek": 74568, "start": 753.68, "end": 755.68, "text": " it's better to use the list comprehension.", "tokens": [50764, 309, 311, 1101, 281, 764, 264, 1329, 44991, 13, 50864], "temperature": 0.0, "avg_logprob": -0.06858479976654053, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.0016228818567469716}, {"id": 239, "seek": 74568, "start": 755.68, "end": 759.68, "text": " It's around 75% times faster than the for loop,", "tokens": [50864, 467, 311, 926, 9562, 4, 1413, 4663, 813, 264, 337, 6367, 11, 51064], "temperature": 0.0, "avg_logprob": -0.06858479976654053, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.0016228818567469716}, {"id": 240, "seek": 74568, "start": 759.68, "end": 761.68, "text": " and at least for me, it looks more clear.", "tokens": [51064, 293, 412, 1935, 337, 385, 11, 309, 1542, 544, 1850, 13, 51164], "temperature": 0.0, "avg_logprob": -0.06858479976654053, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.0016228818567469716}, {"id": 241, "seek": 74568, "start": 766.68, "end": 768.68, "text": " When you want to execute a piece of code,", "tokens": [51414, 1133, 291, 528, 281, 14483, 257, 2522, 295, 3089, 11, 51514], "temperature": 0.0, "avg_logprob": -0.06858479976654053, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.0016228818567469716}, {"id": 242, "seek": 74568, "start": 768.68, "end": 771.68, "text": " but you are not sure if it will be successful.", "tokens": [51514, 457, 291, 366, 406, 988, 498, 309, 486, 312, 4406, 13, 51664], "temperature": 0.0, "avg_logprob": -0.06858479976654053, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.0016228818567469716}, {"id": 243, "seek": 74568, "start": 771.68, "end": 773.68, "text": " Maybe some variables are not set,", "tokens": [51664, 2704, 512, 9102, 366, 406, 992, 11, 51764], "temperature": 0.0, "avg_logprob": -0.06858479976654053, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.0016228818567469716}, {"id": 244, "seek": 77368, "start": 773.68, "end": 776.68, "text": " like in this case, the class might be missing some attribute.", "tokens": [50364, 411, 294, 341, 1389, 11, 264, 1508, 1062, 312, 5361, 512, 19667, 13, 50514], "temperature": 0.0, "avg_logprob": -0.07757471535952036, "compression_ratio": 1.8546712802768166, "no_speech_prob": 0.0040724147111177444}, {"id": 245, "seek": 77368, "start": 776.68, "end": 778.68, "text": " So you want to protect yourself somehow.", "tokens": [50514, 407, 291, 528, 281, 2371, 1803, 6063, 13, 50614], "temperature": 0.0, "avg_logprob": -0.07757471535952036, "compression_ratio": 1.8546712802768166, "no_speech_prob": 0.0040724147111177444}, {"id": 246, "seek": 77368, "start": 778.68, "end": 781.68, "text": " The first way you can do this is called look before you leave", "tokens": [50614, 440, 700, 636, 291, 393, 360, 341, 307, 1219, 574, 949, 291, 1856, 50764], "temperature": 0.0, "avg_logprob": -0.07757471535952036, "compression_ratio": 1.8546712802768166, "no_speech_prob": 0.0040724147111177444}, {"id": 247, "seek": 77368, "start": 781.68, "end": 783.68, "text": " or ask for permissions.", "tokens": [50764, 420, 1029, 337, 32723, 13, 50864], "temperature": 0.0, "avg_logprob": -0.07757471535952036, "compression_ratio": 1.8546712802768166, "no_speech_prob": 0.0040724147111177444}, {"id": 248, "seek": 77368, "start": 783.68, "end": 787.68, "text": " What it means is that you first check if the class has a specific attribute,", "tokens": [50864, 708, 309, 1355, 307, 300, 291, 700, 1520, 498, 264, 1508, 575, 257, 2685, 19667, 11, 51064], "temperature": 0.0, "avg_logprob": -0.07757471535952036, "compression_ratio": 1.8546712802768166, "no_speech_prob": 0.0040724147111177444}, {"id": 249, "seek": 77368, "start": 787.68, "end": 789.68, "text": " and then you perform the operations.", "tokens": [51064, 293, 550, 291, 2042, 264, 7705, 13, 51164], "temperature": 0.0, "avg_logprob": -0.07757471535952036, "compression_ratio": 1.8546712802768166, "no_speech_prob": 0.0040724147111177444}, {"id": 250, "seek": 77368, "start": 789.68, "end": 792.68, "text": " Usually, this checking is done with the if statement.", "tokens": [51164, 11419, 11, 341, 8568, 307, 1096, 365, 264, 498, 5629, 13, 51314], "temperature": 0.0, "avg_logprob": -0.07757471535952036, "compression_ratio": 1.8546712802768166, "no_speech_prob": 0.0040724147111177444}, {"id": 251, "seek": 77368, "start": 792.68, "end": 794.68, "text": " However, there's different approach that you could use,", "tokens": [51314, 2908, 11, 456, 311, 819, 3109, 300, 291, 727, 764, 11, 51414], "temperature": 0.0, "avg_logprob": -0.07757471535952036, "compression_ratio": 1.8546712802768166, "no_speech_prob": 0.0040724147111177444}, {"id": 252, "seek": 77368, "start": 794.68, "end": 796.68, "text": " and it's called back for forgiveness.", "tokens": [51414, 293, 309, 311, 1219, 646, 337, 18396, 13, 51514], "temperature": 0.0, "avg_logprob": -0.07757471535952036, "compression_ratio": 1.8546712802768166, "no_speech_prob": 0.0040724147111177444}, {"id": 253, "seek": 77368, "start": 796.68, "end": 799.68, "text": " So in this scenario, you perform the operation", "tokens": [51514, 407, 294, 341, 9005, 11, 291, 2042, 264, 6916, 51664], "temperature": 0.0, "avg_logprob": -0.07757471535952036, "compression_ratio": 1.8546712802768166, "no_speech_prob": 0.0040724147111177444}, {"id": 254, "seek": 77368, "start": 799.68, "end": 801.68, "text": " without checking the conditions first.", "tokens": [51664, 1553, 8568, 264, 4487, 700, 13, 51764], "temperature": 0.0, "avg_logprob": -0.07757471535952036, "compression_ratio": 1.8546712802768166, "no_speech_prob": 0.0040724147111177444}, {"id": 255, "seek": 80168, "start": 801.68, "end": 804.68, "text": " But in case you expect that something might break,", "tokens": [50364, 583, 294, 1389, 291, 2066, 300, 746, 1062, 1821, 11, 50514], "temperature": 0.0, "avg_logprob": -0.07305239908622974, "compression_ratio": 1.8066666666666666, "no_speech_prob": 0.00155036267824471}, {"id": 256, "seek": 80168, "start": 804.68, "end": 807.68, "text": " you wrap your code in a try except block,", "tokens": [50514, 291, 7019, 428, 3089, 294, 257, 853, 3993, 3461, 11, 50664], "temperature": 0.0, "avg_logprob": -0.07305239908622974, "compression_ratio": 1.8066666666666666, "no_speech_prob": 0.00155036267824471}, {"id": 257, "seek": 80168, "start": 807.68, "end": 809.68, "text": " and you catch the exceptions that were raised.", "tokens": [50664, 293, 291, 3745, 264, 22847, 300, 645, 6005, 13, 50764], "temperature": 0.0, "avg_logprob": -0.07305239908622974, "compression_ratio": 1.8066666666666666, "no_speech_prob": 0.00155036267824471}, {"id": 258, "seek": 80168, "start": 809.68, "end": 811.68, "text": " And as you can see in the simple example,", "tokens": [50764, 400, 382, 291, 393, 536, 294, 264, 2199, 1365, 11, 50864], "temperature": 0.0, "avg_logprob": -0.07305239908622974, "compression_ratio": 1.8066666666666666, "no_speech_prob": 0.00155036267824471}, {"id": 259, "seek": 80168, "start": 811.68, "end": 814.68, "text": " begging for forgiveness is like three times faster.", "tokens": [50864, 26600, 337, 18396, 307, 411, 1045, 1413, 4663, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07305239908622974, "compression_ratio": 1.8066666666666666, "no_speech_prob": 0.00155036267824471}, {"id": 260, "seek": 80168, "start": 814.68, "end": 817.68, "text": " But it gets even better if you're checking for more conditions.", "tokens": [51014, 583, 309, 2170, 754, 1101, 498, 291, 434, 8568, 337, 544, 4487, 13, 51164], "temperature": 0.0, "avg_logprob": -0.07305239908622974, "compression_ratio": 1.8066666666666666, "no_speech_prob": 0.00155036267824471}, {"id": 261, "seek": 80168, "start": 817.68, "end": 820.68, "text": " So here we are checking if three attributes are present.", "tokens": [51164, 407, 510, 321, 366, 8568, 498, 1045, 17212, 366, 1974, 13, 51314], "temperature": 0.0, "avg_logprob": -0.07305239908622974, "compression_ratio": 1.8066666666666666, "no_speech_prob": 0.00155036267824471}, {"id": 262, "seek": 80168, "start": 820.68, "end": 823.68, "text": " And asking for permission is still slower,", "tokens": [51314, 400, 3365, 337, 11226, 307, 920, 14009, 11, 51464], "temperature": 0.0, "avg_logprob": -0.07305239908622974, "compression_ratio": 1.8066666666666666, "no_speech_prob": 0.00155036267824471}, {"id": 263, "seek": 80168, "start": 823.68, "end": 826.68, "text": " and now it's also getting more difficult to read.", "tokens": [51464, 293, 586, 309, 311, 611, 1242, 544, 2252, 281, 1401, 13, 51614], "temperature": 0.0, "avg_logprob": -0.07305239908622974, "compression_ratio": 1.8066666666666666, "no_speech_prob": 0.00155036267824471}, {"id": 264, "seek": 80168, "start": 826.68, "end": 828.68, "text": " So following the back for forgiveness approach", "tokens": [51614, 407, 3480, 264, 646, 337, 18396, 3109, 51714], "temperature": 0.0, "avg_logprob": -0.07305239908622974, "compression_ratio": 1.8066666666666666, "no_speech_prob": 0.00155036267824471}, {"id": 265, "seek": 80168, "start": 828.68, "end": 830.68, "text": " will result in a faster and more readable code.", "tokens": [51714, 486, 1874, 294, 257, 4663, 293, 544, 49857, 3089, 13, 51814], "temperature": 0.0, "avg_logprob": -0.07305239908622974, "compression_ratio": 1.8066666666666666, "no_speech_prob": 0.00155036267824471}, {"id": 266, "seek": 83068, "start": 830.68, "end": 833.68, "text": " So we could say that asking for forgiveness", "tokens": [50364, 407, 321, 727, 584, 300, 3365, 337, 18396, 50514], "temperature": 0.0, "avg_logprob": -0.05932054046756965, "compression_ratio": 1.8419117647058822, "no_speech_prob": 0.002427047351375222}, {"id": 267, "seek": 83068, "start": 833.68, "end": 836.68, "text": " instead of checking the permissions is always a better way.", "tokens": [50514, 2602, 295, 8568, 264, 32723, 307, 1009, 257, 1101, 636, 13, 50664], "temperature": 0.0, "avg_logprob": -0.05932054046756965, "compression_ratio": 1.8419117647058822, "no_speech_prob": 0.002427047351375222}, {"id": 268, "seek": 83068, "start": 836.68, "end": 839.68, "text": " But we won't say that because it's not true.", "tokens": [50664, 583, 321, 1582, 380, 584, 300, 570, 309, 311, 406, 2074, 13, 50814], "temperature": 0.0, "avg_logprob": -0.05932054046756965, "compression_ratio": 1.8419117647058822, "no_speech_prob": 0.002427047351375222}, {"id": 269, "seek": 83068, "start": 839.68, "end": 841.68, "text": " Exceptional handling is still quite expensive.", "tokens": [50814, 16192, 1966, 13175, 307, 920, 1596, 5124, 13, 50914], "temperature": 0.0, "avg_logprob": -0.05932054046756965, "compression_ratio": 1.8419117647058822, "no_speech_prob": 0.002427047351375222}, {"id": 270, "seek": 83068, "start": 841.68, "end": 844.68, "text": " So if the attribute is actually missing,", "tokens": [50914, 407, 498, 264, 19667, 307, 767, 5361, 11, 51064], "temperature": 0.0, "avg_logprob": -0.05932054046756965, "compression_ratio": 1.8419117647058822, "no_speech_prob": 0.002427047351375222}, {"id": 271, "seek": 83068, "start": 844.68, "end": 848.68, "text": " then begging for forgiveness will be slower than asking for permissions.", "tokens": [51064, 550, 26600, 337, 18396, 486, 312, 14009, 813, 3365, 337, 32723, 13, 51264], "temperature": 0.0, "avg_logprob": -0.05932054046756965, "compression_ratio": 1.8419117647058822, "no_speech_prob": 0.002427047351375222}, {"id": 272, "seek": 83068, "start": 848.68, "end": 852.68, "text": " So as a rule of thumb, you can use the ask for permissions way", "tokens": [51264, 407, 382, 257, 4978, 295, 9298, 11, 291, 393, 764, 264, 1029, 337, 32723, 636, 51464], "temperature": 0.0, "avg_logprob": -0.05932054046756965, "compression_ratio": 1.8419117647058822, "no_speech_prob": 0.002427047351375222}, {"id": 273, "seek": 83068, "start": 852.68, "end": 855.68, "text": " if you know that it's very likely that the attribute will be missing,", "tokens": [51464, 498, 291, 458, 300, 309, 311, 588, 3700, 300, 264, 19667, 486, 312, 5361, 11, 51614], "temperature": 0.0, "avg_logprob": -0.05932054046756965, "compression_ratio": 1.8419117647058822, "no_speech_prob": 0.002427047351375222}, {"id": 274, "seek": 83068, "start": 855.68, "end": 858.68, "text": " or there will be some other problems that you can predict.", "tokens": [51614, 420, 456, 486, 312, 512, 661, 2740, 300, 291, 393, 6069, 13, 51764], "temperature": 0.0, "avg_logprob": -0.05932054046756965, "compression_ratio": 1.8419117647058822, "no_speech_prob": 0.002427047351375222}, {"id": 275, "seek": 85868, "start": 858.68, "end": 862.68, "text": " Otherwise, if you're expecting that your code will work in most of the times,", "tokens": [50364, 10328, 11, 498, 291, 434, 9650, 300, 428, 3089, 486, 589, 294, 881, 295, 264, 1413, 11, 50564], "temperature": 0.0, "avg_logprob": -0.09430725905146913, "compression_ratio": 1.8065573770491803, "no_speech_prob": 0.010748719796538353}, {"id": 276, "seek": 85868, "start": 862.68, "end": 868.68, "text": " try using try accept will result in a faster and quite often more readable code.", "tokens": [50564, 853, 1228, 853, 3241, 486, 1874, 294, 257, 4663, 293, 1596, 2049, 544, 49857, 3089, 13, 50864], "temperature": 0.0, "avg_logprob": -0.09430725905146913, "compression_ratio": 1.8065573770491803, "no_speech_prob": 0.010748719796538353}, {"id": 277, "seek": 85868, "start": 868.68, "end": 871.68, "text": " So for example, if you're fetching some files from the internet,", "tokens": [50864, 407, 337, 1365, 11, 498, 291, 434, 23673, 278, 512, 7098, 490, 264, 4705, 11, 51014], "temperature": 0.0, "avg_logprob": -0.09430725905146913, "compression_ratio": 1.8065573770491803, "no_speech_prob": 0.010748719796538353}, {"id": 278, "seek": 85868, "start": 871.68, "end": 873.68, "text": " and you expect that everything will be fine", "tokens": [51014, 293, 291, 2066, 300, 1203, 486, 312, 2489, 51114], "temperature": 0.0, "avg_logprob": -0.09430725905146913, "compression_ratio": 1.8065573770491803, "no_speech_prob": 0.010748719796538353}, {"id": 279, "seek": 85868, "start": 873.68, "end": 875.68, "text": " unless there is no internet connection.", "tokens": [51114, 5969, 456, 307, 572, 4705, 4984, 13, 51214], "temperature": 0.0, "avg_logprob": -0.09430725905146913, "compression_ratio": 1.8065573770491803, "no_speech_prob": 0.010748719796538353}, {"id": 280, "seek": 85868, "start": 875.68, "end": 877.68, "text": " So instead of checking if there is internet connection,", "tokens": [51214, 407, 2602, 295, 8568, 498, 456, 307, 4705, 4984, 11, 51314], "temperature": 0.0, "avg_logprob": -0.09430725905146913, "compression_ratio": 1.8065573770491803, "no_speech_prob": 0.010748719796538353}, {"id": 281, "seek": 85868, "start": 877.68, "end": 879.68, "text": " if it's fast enough, if there are no timeouts,", "tokens": [51314, 498, 309, 311, 2370, 1547, 11, 498, 456, 366, 572, 565, 7711, 11, 51414], "temperature": 0.0, "avg_logprob": -0.09430725905146913, "compression_ratio": 1.8065573770491803, "no_speech_prob": 0.010748719796538353}, {"id": 282, "seek": 85868, "start": 879.68, "end": 881.68, "text": " just go for the try accept.", "tokens": [51414, 445, 352, 337, 264, 853, 3241, 13, 51514], "temperature": 0.0, "avg_logprob": -0.09430725905146913, "compression_ratio": 1.8065573770491803, "no_speech_prob": 0.010748719796538353}, {"id": 283, "seek": 85868, "start": 881.68, "end": 884.68, "text": " But then again, I strongly advise you to measure both solutions", "tokens": [51514, 583, 550, 797, 11, 286, 10613, 18312, 291, 281, 3481, 1293, 6547, 51664], "temperature": 0.0, "avg_logprob": -0.09430725905146913, "compression_ratio": 1.8065573770491803, "no_speech_prob": 0.010748719796538353}, {"id": 284, "seek": 85868, "start": 884.68, "end": 887.68, "text": " and see maybe in your case it will be different.", "tokens": [51664, 293, 536, 1310, 294, 428, 1389, 309, 486, 312, 819, 13, 51814], "temperature": 0.0, "avg_logprob": -0.09430725905146913, "compression_ratio": 1.8065573770491803, "no_speech_prob": 0.010748719796538353}, {"id": 285, "seek": 88868, "start": 888.68, "end": 892.68, "text": " So let's tackle another problem, the membership testing.", "tokens": [50364, 407, 718, 311, 14896, 1071, 1154, 11, 264, 16560, 4997, 13, 50564], "temperature": 0.0, "avg_logprob": -0.051351387053728104, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.0019120037322863936}, {"id": 286, "seek": 88868, "start": 892.68, "end": 896.68, "text": " So if you have a list and you want to check if it contains a specific element,", "tokens": [50564, 407, 498, 291, 362, 257, 1329, 293, 291, 528, 281, 1520, 498, 309, 8306, 257, 2685, 4478, 11, 50764], "temperature": 0.0, "avg_logprob": -0.051351387053728104, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.0019120037322863936}, {"id": 287, "seek": 88868, "start": 896.68, "end": 898.68, "text": " you can use a for loop.", "tokens": [50764, 291, 393, 764, 257, 337, 6367, 13, 50864], "temperature": 0.0, "avg_logprob": -0.051351387053728104, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.0019120037322863936}, {"id": 288, "seek": 88868, "start": 898.68, "end": 901.68, "text": " But the problem is you are iterating over the whole list", "tokens": [50864, 583, 264, 1154, 307, 291, 366, 17138, 990, 670, 264, 1379, 1329, 51014], "temperature": 0.0, "avg_logprob": -0.051351387053728104, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.0019120037322863936}, {"id": 289, "seek": 88868, "start": 901.68, "end": 905.68, "text": " even though you're not really doing anything with all those elements.", "tokens": [51014, 754, 1673, 291, 434, 406, 534, 884, 1340, 365, 439, 729, 4959, 13, 51214], "temperature": 0.0, "avg_logprob": -0.051351387053728104, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.0019120037322863936}, {"id": 290, "seek": 88868, "start": 905.68, "end": 908.68, "text": " So you can replace the for loop with the in statement.", "tokens": [51214, 407, 291, 393, 7406, 264, 337, 6367, 365, 264, 294, 5629, 13, 51364], "temperature": 0.0, "avg_logprob": -0.051351387053728104, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.0019120037322863936}, {"id": 291, "seek": 88868, "start": 908.68, "end": 912.68, "text": " It will check if a specific element belongs to a given set of data,", "tokens": [51364, 467, 486, 1520, 498, 257, 2685, 4478, 12953, 281, 257, 2212, 992, 295, 1412, 11, 51564], "temperature": 0.0, "avg_logprob": -0.051351387053728104, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.0019120037322863936}, {"id": 292, "seek": 88868, "start": 912.68, "end": 915.68, "text": " and it will do this twice as fast.", "tokens": [51564, 293, 309, 486, 360, 341, 6091, 382, 2370, 13, 51714], "temperature": 0.0, "avg_logprob": -0.051351387053728104, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.0019120037322863936}, {"id": 293, "seek": 88868, "start": 915.68, "end": 917.68, "text": " But there is still one big problem with this approach.", "tokens": [51714, 583, 456, 307, 920, 472, 955, 1154, 365, 341, 3109, 13, 51814], "temperature": 0.0, "avg_logprob": -0.051351387053728104, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.0019120037322863936}, {"id": 294, "seek": 91768, "start": 917.68, "end": 921.68, "text": " The lookup time depends on where your element is located in that list.", "tokens": [50364, 440, 574, 1010, 565, 5946, 322, 689, 428, 4478, 307, 6870, 294, 300, 1329, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08030775510347807, "compression_ratio": 1.858267716535433, "no_speech_prob": 0.005363194737583399}, {"id": 295, "seek": 91768, "start": 921.68, "end": 924.68, "text": " If it's at the beginning of the list, you're lucky and you will get it fast.", "tokens": [50564, 759, 309, 311, 412, 264, 2863, 295, 264, 1329, 11, 291, 434, 6356, 293, 291, 486, 483, 309, 2370, 13, 50714], "temperature": 0.0, "avg_logprob": -0.08030775510347807, "compression_ratio": 1.858267716535433, "no_speech_prob": 0.005363194737583399}, {"id": 296, "seek": 91768, "start": 924.68, "end": 927.68, "text": " If it's at the end of the list, you have to wait.", "tokens": [50714, 759, 309, 311, 412, 264, 917, 295, 264, 1329, 11, 291, 362, 281, 1699, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08030775510347807, "compression_ratio": 1.858267716535433, "no_speech_prob": 0.005363194737583399}, {"id": 297, "seek": 91768, "start": 927.68, "end": 930.68, "text": " So what would be really nice here if we had the data structure", "tokens": [50864, 407, 437, 576, 312, 534, 1481, 510, 498, 321, 632, 264, 1412, 3877, 51014], "temperature": 0.0, "avg_logprob": -0.08030775510347807, "compression_ratio": 1.858267716535433, "no_speech_prob": 0.005363194737583399}, {"id": 298, "seek": 91768, "start": 930.68, "end": 932.68, "text": " that would have a constant lookup time.", "tokens": [51014, 300, 576, 362, 257, 5754, 574, 1010, 565, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08030775510347807, "compression_ratio": 1.858267716535433, "no_speech_prob": 0.005363194737583399}, {"id": 299, "seek": 91768, "start": 932.68, "end": 936.68, "text": " And actually in Python we have, we have both sets and dictionary", "tokens": [51114, 400, 767, 294, 15329, 321, 362, 11, 321, 362, 1293, 6352, 293, 25890, 51314], "temperature": 0.0, "avg_logprob": -0.08030775510347807, "compression_ratio": 1.858267716535433, "no_speech_prob": 0.005363194737583399}, {"id": 300, "seek": 91768, "start": 936.68, "end": 938.68, "text": " that have constant lookup time.", "tokens": [51314, 300, 362, 5754, 574, 1010, 565, 13, 51414], "temperature": 0.0, "avg_logprob": -0.08030775510347807, "compression_ratio": 1.858267716535433, "no_speech_prob": 0.005363194737583399}, {"id": 301, "seek": 91768, "start": 938.68, "end": 941.68, "text": " So if we replace the list with a set,", "tokens": [51414, 407, 498, 321, 7406, 264, 1329, 365, 257, 992, 11, 51564], "temperature": 0.0, "avg_logprob": -0.08030775510347807, "compression_ratio": 1.858267716535433, "no_speech_prob": 0.005363194737583399}, {"id": 302, "seek": 91768, "start": 941.68, "end": 943.68, "text": " then the lookup time becomes faster,", "tokens": [51564, 550, 264, 574, 1010, 565, 3643, 4663, 11, 51664], "temperature": 0.0, "avg_logprob": -0.08030775510347807, "compression_ratio": 1.858267716535433, "no_speech_prob": 0.005363194737583399}, {"id": 303, "seek": 94368, "start": 943.68, "end": 947.68, "text": " from just a few times faster to hundreds of thousand times faster.", "tokens": [50364, 490, 445, 257, 1326, 1413, 4663, 281, 6779, 295, 4714, 1413, 4663, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08019355932871501, "compression_ratio": 1.7100371747211895, "no_speech_prob": 0.003004862694069743}, {"id": 304, "seek": 94368, "start": 947.68, "end": 949.68, "text": " So where's the catch?", "tokens": [50564, 407, 689, 311, 264, 3745, 30, 50664], "temperature": 0.0, "avg_logprob": -0.08019355932871501, "compression_ratio": 1.7100371747211895, "no_speech_prob": 0.003004862694069743}, {"id": 305, "seek": 94368, "start": 949.68, "end": 952.68, "text": " Well, you pay some time to convert the list to a set.", "tokens": [50664, 1042, 11, 291, 1689, 512, 565, 281, 7620, 264, 1329, 281, 257, 992, 13, 50814], "temperature": 0.0, "avg_logprob": -0.08019355932871501, "compression_ratio": 1.7100371747211895, "no_speech_prob": 0.003004862694069743}, {"id": 306, "seek": 94368, "start": 952.68, "end": 955.68, "text": " And in this scenario, converting this list to a set", "tokens": [50814, 400, 294, 341, 9005, 11, 29942, 341, 1329, 281, 257, 992, 50964], "temperature": 0.0, "avg_logprob": -0.08019355932871501, "compression_ratio": 1.7100371747211895, "no_speech_prob": 0.003004862694069743}, {"id": 307, "seek": 94368, "start": 955.68, "end": 958.68, "text": " takes more time than any of the lookups in that list.", "tokens": [50964, 2516, 544, 565, 813, 604, 295, 264, 574, 7528, 294, 300, 1329, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08019355932871501, "compression_ratio": 1.7100371747211895, "no_speech_prob": 0.003004862694069743}, {"id": 308, "seek": 94368, "start": 958.68, "end": 960.68, "text": " So it doesn't really make sense.", "tokens": [51114, 407, 309, 1177, 380, 534, 652, 2020, 13, 51214], "temperature": 0.0, "avg_logprob": -0.08019355932871501, "compression_ratio": 1.7100371747211895, "no_speech_prob": 0.003004862694069743}, {"id": 309, "seek": 94368, "start": 960.68, "end": 964.68, "text": " However, if you're checking membership of different elements,", "tokens": [51214, 2908, 11, 498, 291, 434, 8568, 16560, 295, 819, 4959, 11, 51414], "temperature": 0.0, "avg_logprob": -0.08019355932871501, "compression_ratio": 1.7100371747211895, "no_speech_prob": 0.003004862694069743}, {"id": 310, "seek": 94368, "start": 964.68, "end": 968.68, "text": " quite often it makes sense to first convert it to a set.", "tokens": [51414, 1596, 2049, 309, 1669, 2020, 281, 700, 7620, 309, 281, 257, 992, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08019355932871501, "compression_ratio": 1.7100371747211895, "no_speech_prob": 0.003004862694069743}, {"id": 311, "seek": 94368, "start": 968.68, "end": 971.68, "text": " So speaking of sets, they have another interesting feature.", "tokens": [51614, 407, 4124, 295, 6352, 11, 436, 362, 1071, 1880, 4111, 13, 51764], "temperature": 0.0, "avg_logprob": -0.08019355932871501, "compression_ratio": 1.7100371747211895, "no_speech_prob": 0.003004862694069743}, {"id": 312, "seek": 97168, "start": 971.68, "end": 973.68, "text": " They don't contain duplicates.", "tokens": [50364, 814, 500, 380, 5304, 17154, 1024, 13, 50464], "temperature": 0.0, "avg_logprob": -0.0709415402328759, "compression_ratio": 1.791304347826087, "no_speech_prob": 0.0017358436016365886}, {"id": 313, "seek": 97168, "start": 973.68, "end": 975.68, "text": " So basically if you have a list of elements", "tokens": [50464, 407, 1936, 498, 291, 362, 257, 1329, 295, 4959, 50564], "temperature": 0.0, "avg_logprob": -0.0709415402328759, "compression_ratio": 1.791304347826087, "no_speech_prob": 0.0017358436016365886}, {"id": 314, "seek": 97168, "start": 975.68, "end": 977.68, "text": " and you want to remove the duplicates,", "tokens": [50564, 293, 291, 528, 281, 4159, 264, 17154, 1024, 11, 50664], "temperature": 0.0, "avg_logprob": -0.0709415402328759, "compression_ratio": 1.791304347826087, "no_speech_prob": 0.0017358436016365886}, {"id": 315, "seek": 97168, "start": 977.68, "end": 981.68, "text": " the fastest way to do this is to convert this list to a set.", "tokens": [50664, 264, 14573, 636, 281, 360, 341, 307, 281, 7620, 341, 1329, 281, 257, 992, 13, 50864], "temperature": 0.0, "avg_logprob": -0.0709415402328759, "compression_ratio": 1.791304347826087, "no_speech_prob": 0.0017358436016365886}, {"id": 316, "seek": 97168, "start": 981.68, "end": 984.68, "text": " But be aware that sets are not ordered.", "tokens": [50864, 583, 312, 3650, 300, 6352, 366, 406, 8866, 13, 51014], "temperature": 0.0, "avg_logprob": -0.0709415402328759, "compression_ratio": 1.791304347826087, "no_speech_prob": 0.0017358436016365886}, {"id": 317, "seek": 97168, "start": 984.68, "end": 986.68, "text": " So if you need to preserve the order,", "tokens": [51014, 407, 498, 291, 643, 281, 15665, 264, 1668, 11, 51114], "temperature": 0.0, "avg_logprob": -0.0709415402328759, "compression_ratio": 1.791304347826087, "no_speech_prob": 0.0017358436016365886}, {"id": 318, "seek": 97168, "start": 986.68, "end": 991.68, "text": " take a look at the order dictionary from the collection module.", "tokens": [51114, 747, 257, 574, 412, 264, 1668, 25890, 490, 264, 5765, 10088, 13, 51364], "temperature": 0.0, "avg_logprob": -0.0709415402328759, "compression_ratio": 1.791304347826087, "no_speech_prob": 0.0017358436016365886}, {"id": 319, "seek": 97168, "start": 991.68, "end": 993.68, "text": " So if you want to sort your list,", "tokens": [51364, 407, 498, 291, 528, 281, 1333, 428, 1329, 11, 51464], "temperature": 0.0, "avg_logprob": -0.0709415402328759, "compression_ratio": 1.791304347826087, "no_speech_prob": 0.0017358436016365886}, {"id": 320, "seek": 97168, "start": 993.68, "end": 997.68, "text": " you can either do this in place using the list.sort function,", "tokens": [51464, 291, 393, 2139, 360, 341, 294, 1081, 1228, 264, 1329, 13, 82, 477, 2445, 11, 51664], "temperature": 0.0, "avg_logprob": -0.0709415402328759, "compression_ratio": 1.791304347826087, "no_speech_prob": 0.0017358436016365886}, {"id": 321, "seek": 99768, "start": 997.68, "end": 1001.68, "text": " or you can call the sorted function that will create a new list.", "tokens": [50364, 420, 291, 393, 818, 264, 25462, 2445, 300, 486, 1884, 257, 777, 1329, 13, 50564], "temperature": 0.0, "avg_logprob": -0.05976674189934364, "compression_ratio": 1.728448275862069, "no_speech_prob": 0.0014862037496641278}, {"id": 322, "seek": 99768, "start": 1001.68, "end": 1003.68, "text": " And unless you really need to have a new list,", "tokens": [50564, 400, 5969, 291, 534, 643, 281, 362, 257, 777, 1329, 11, 50664], "temperature": 0.0, "avg_logprob": -0.05976674189934364, "compression_ratio": 1.728448275862069, "no_speech_prob": 0.0014862037496641278}, {"id": 323, "seek": 99768, "start": 1003.68, "end": 1007.68, "text": " sorting in place will be like six times faster in this scenario.", "tokens": [50664, 32411, 294, 1081, 486, 312, 411, 2309, 1413, 4663, 294, 341, 9005, 13, 50864], "temperature": 0.0, "avg_logprob": -0.05976674189934364, "compression_ratio": 1.728448275862069, "no_speech_prob": 0.0014862037496641278}, {"id": 324, "seek": 99768, "start": 1007.68, "end": 1012.68, "text": " This is for one million of random numbers.", "tokens": [50864, 639, 307, 337, 472, 2459, 295, 4974, 3547, 13, 51114], "temperature": 0.0, "avg_logprob": -0.05976674189934364, "compression_ratio": 1.728448275862069, "no_speech_prob": 0.0014862037496641278}, {"id": 325, "seek": 99768, "start": 1012.68, "end": 1016.68, "text": " If you want to perform the same operation on a large set of data,", "tokens": [51114, 759, 291, 528, 281, 2042, 264, 912, 6916, 322, 257, 2416, 992, 295, 1412, 11, 51314], "temperature": 0.0, "avg_logprob": -0.05976674189934364, "compression_ratio": 1.728448275862069, "no_speech_prob": 0.0014862037496641278}, {"id": 326, "seek": 99768, "start": 1016.68, "end": 1018.68, "text": " then you have two options.", "tokens": [51314, 550, 291, 362, 732, 3956, 13, 51414], "temperature": 0.0, "avg_logprob": -0.05976674189934364, "compression_ratio": 1.728448275862069, "no_speech_prob": 0.0014862037496641278}, {"id": 327, "seek": 99768, "start": 1018.68, "end": 1021.68, "text": " You can write a function that performs the operation", "tokens": [51414, 509, 393, 2464, 257, 2445, 300, 26213, 264, 6916, 51564], "temperature": 0.0, "avg_logprob": -0.05976674189934364, "compression_ratio": 1.728448275862069, "no_speech_prob": 0.0014862037496641278}, {"id": 328, "seek": 99768, "start": 1021.68, "end": 1024.6799999999998, "text": " and call this function 1,000 times.", "tokens": [51564, 293, 818, 341, 2445, 502, 11, 1360, 1413, 13, 51714], "temperature": 0.0, "avg_logprob": -0.05976674189934364, "compression_ratio": 1.728448275862069, "no_speech_prob": 0.0014862037496641278}, {"id": 329, "seek": 102468, "start": 1024.68, "end": 1027.68, "text": " Or you can call a function that takes this set of data", "tokens": [50364, 1610, 291, 393, 818, 257, 2445, 300, 2516, 341, 992, 295, 1412, 50514], "temperature": 0.0, "avg_logprob": -0.06185234139818664, "compression_ratio": 1.6401515151515151, "no_speech_prob": 0.0013454494765028358}, {"id": 330, "seek": 102468, "start": 1027.68, "end": 1029.68, "text": " and performs the operation inside.", "tokens": [50514, 293, 26213, 264, 6916, 1854, 13, 50614], "temperature": 0.0, "avg_logprob": -0.06185234139818664, "compression_ratio": 1.6401515151515151, "no_speech_prob": 0.0013454494765028358}, {"id": 331, "seek": 102468, "start": 1029.68, "end": 1032.68, "text": " And the second approach will be faster.", "tokens": [50614, 400, 264, 1150, 3109, 486, 312, 4663, 13, 50764], "temperature": 0.0, "avg_logprob": -0.06185234139818664, "compression_ratio": 1.6401515151515151, "no_speech_prob": 0.0013454494765028358}, {"id": 332, "seek": 102468, "start": 1032.68, "end": 1036.68, "text": " So if you can in an easy way replace multiple calls to one function", "tokens": [50764, 407, 498, 291, 393, 294, 364, 1858, 636, 7406, 3866, 5498, 281, 472, 2445, 50964], "temperature": 0.0, "avg_logprob": -0.06185234139818664, "compression_ratio": 1.6401515151515151, "no_speech_prob": 0.0013454494765028358}, {"id": 333, "seek": 102468, "start": 1036.68, "end": 1040.68, "text": " with just one function, then quite often it's a good idea.", "tokens": [50964, 365, 445, 472, 2445, 11, 550, 1596, 2049, 309, 311, 257, 665, 1558, 13, 51164], "temperature": 0.0, "avg_logprob": -0.06185234139818664, "compression_ratio": 1.6401515151515151, "no_speech_prob": 0.0013454494765028358}, {"id": 334, "seek": 102468, "start": 1042.68, "end": 1045.68, "text": " So what's the best way to check if a variable expression is true?", "tokens": [51264, 407, 437, 311, 264, 1151, 636, 281, 1520, 498, 257, 7006, 6114, 307, 2074, 30, 51414], "temperature": 0.0, "avg_logprob": -0.06185234139818664, "compression_ratio": 1.6401515151515151, "no_speech_prob": 0.0013454494765028358}, {"id": 335, "seek": 102468, "start": 1045.68, "end": 1048.68, "text": " Well, you can explicitly compare this variable to true,", "tokens": [51414, 1042, 11, 291, 393, 20803, 6794, 341, 7006, 281, 2074, 11, 51564], "temperature": 0.0, "avg_logprob": -0.06185234139818664, "compression_ratio": 1.6401515151515151, "no_speech_prob": 0.0013454494765028358}, {"id": 336, "seek": 102468, "start": 1048.68, "end": 1051.68, "text": " but in most cases you're adding additional redundancy.", "tokens": [51564, 457, 294, 881, 3331, 291, 434, 5127, 4497, 27830, 6717, 13, 51714], "temperature": 0.0, "avg_logprob": -0.06185234139818664, "compression_ratio": 1.6401515151515151, "no_speech_prob": 0.0013454494765028358}, {"id": 337, "seek": 105168, "start": 1051.68, "end": 1055.68, "text": " So you can simplify your condition to just if variable.", "tokens": [50364, 407, 291, 393, 20460, 428, 4188, 281, 445, 498, 7006, 13, 50564], "temperature": 0.0, "avg_logprob": -0.09782772619747421, "compression_ratio": 1.6434426229508197, "no_speech_prob": 0.003009781939908862}, {"id": 338, "seek": 105168, "start": 1055.68, "end": 1059.68, "text": " And it will return true unless the variable is false,", "tokens": [50564, 400, 309, 486, 2736, 2074, 5969, 264, 7006, 307, 7908, 11, 50764], "temperature": 0.0, "avg_logprob": -0.09782772619747421, "compression_ratio": 1.6434426229508197, "no_speech_prob": 0.003009781939908862}, {"id": 339, "seek": 105168, "start": 1059.68, "end": 1063.68, "text": " non-zero, empty string, empty list, or other false expression.", "tokens": [50764, 2107, 12, 32226, 11, 6707, 6798, 11, 6707, 1329, 11, 420, 661, 7908, 6114, 13, 50964], "temperature": 0.0, "avg_logprob": -0.09782772619747421, "compression_ratio": 1.6434426229508197, "no_speech_prob": 0.003009781939908862}, {"id": 340, "seek": 105168, "start": 1063.68, "end": 1067.68, "text": " And by doing that, your comparison gets faster by like 70%.", "tokens": [50964, 400, 538, 884, 300, 11, 428, 9660, 2170, 4663, 538, 411, 5285, 6856, 51164], "temperature": 0.0, "avg_logprob": -0.09782772619747421, "compression_ratio": 1.6434426229508197, "no_speech_prob": 0.003009781939908862}, {"id": 341, "seek": 105168, "start": 1067.68, "end": 1070.68, "text": " And the same rule applies when checking for false.", "tokens": [51164, 400, 264, 912, 4978, 13165, 562, 8568, 337, 7908, 13, 51314], "temperature": 0.0, "avg_logprob": -0.09782772619747421, "compression_ratio": 1.6434426229508197, "no_speech_prob": 0.003009781939908862}, {"id": 342, "seek": 105168, "start": 1070.68, "end": 1074.68, "text": " So the fastest way to do this is to use if not variable,", "tokens": [51314, 407, 264, 14573, 636, 281, 360, 341, 307, 281, 764, 498, 406, 7006, 11, 51514], "temperature": 0.0, "avg_logprob": -0.09782772619747421, "compression_ratio": 1.6434426229508197, "no_speech_prob": 0.003009781939908862}, {"id": 343, "seek": 105168, "start": 1074.68, "end": 1078.68, "text": " unless you really need to distinguish false from, let's say,", "tokens": [51514, 5969, 291, 534, 643, 281, 20206, 7908, 490, 11, 718, 311, 584, 11, 51714], "temperature": 0.0, "avg_logprob": -0.09782772619747421, "compression_ratio": 1.6434426229508197, "no_speech_prob": 0.003009781939908862}, {"id": 344, "seek": 107868, "start": 1078.68, "end": 1081.68, "text": " non or zero or other false values.", "tokens": [50364, 2107, 420, 4018, 420, 661, 7908, 4190, 13, 50514], "temperature": 0.0, "avg_logprob": -0.10986422499020894, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.0011357716284692287}, {"id": 345, "seek": 107868, "start": 1081.68, "end": 1084.68, "text": " It also applies to empty data structures.", "tokens": [50514, 467, 611, 13165, 281, 6707, 1412, 9227, 13, 50664], "temperature": 0.0, "avg_logprob": -0.10986422499020894, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.0011357716284692287}, {"id": 346, "seek": 107868, "start": 1084.68, "end": 1087.68, "text": " So simply doing if not a list", "tokens": [50664, 407, 2935, 884, 498, 406, 257, 1329, 50814], "temperature": 0.0, "avg_logprob": -0.10986422499020894, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.0011357716284692287}, {"id": 347, "seek": 107868, "start": 1087.68, "end": 1090.68, "text": " will be almost three times faster", "tokens": [50814, 486, 312, 1920, 1045, 1413, 4663, 50964], "temperature": 0.0, "avg_logprob": -0.10986422499020894, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.0011357716284692287}, {"id": 348, "seek": 107868, "start": 1090.68, "end": 1093.68, "text": " than explicitly checking the length of a list.", "tokens": [50964, 813, 20803, 8568, 264, 4641, 295, 257, 1329, 13, 51114], "temperature": 0.0, "avg_logprob": -0.10986422499020894, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.0011357716284692287}, {"id": 349, "seek": 107868, "start": 1097.68, "end": 1100.68, "text": " So let's take a look at different ways of defining functions in Python.", "tokens": [51314, 407, 718, 311, 747, 257, 574, 412, 819, 2098, 295, 17827, 6828, 294, 15329, 13, 51464], "temperature": 0.0, "avg_logprob": -0.10986422499020894, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.0011357716284692287}, {"id": 350, "seek": 107868, "start": 1100.68, "end": 1104.68, "text": " The most common one is to create a function with def keyword.", "tokens": [51464, 440, 881, 2689, 472, 307, 281, 1884, 257, 2445, 365, 1060, 20428, 13, 51664], "temperature": 0.0, "avg_logprob": -0.10986422499020894, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.0011357716284692287}, {"id": 351, "seek": 107868, "start": 1104.68, "end": 1107.68, "text": " The other way is to declare an anonymous function with lambda.", "tokens": [51664, 440, 661, 636, 307, 281, 19710, 364, 24932, 2445, 365, 13607, 13, 51814], "temperature": 0.0, "avg_logprob": -0.10986422499020894, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.0011357716284692287}, {"id": 352, "seek": 110768, "start": 1107.68, "end": 1109.68, "text": " If you assign this lambda to a variable,", "tokens": [50364, 759, 291, 6269, 341, 13607, 281, 257, 7006, 11, 50464], "temperature": 0.0, "avg_logprob": -0.06749089308611052, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.006450021639466286}, {"id": 353, "seek": 110768, "start": 1109.68, "end": 1113.68, "text": " it will act in the same way as the function created with a def keyword.", "tokens": [50464, 309, 486, 605, 294, 264, 912, 636, 382, 264, 2445, 2942, 365, 257, 1060, 20428, 13, 50664], "temperature": 0.0, "avg_logprob": -0.06749089308611052, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.006450021639466286}, {"id": 354, "seek": 110768, "start": 1113.68, "end": 1116.68, "text": " And as you can see, they are both equally fast.", "tokens": [50664, 400, 382, 291, 393, 536, 11, 436, 366, 1293, 12309, 2370, 13, 50814], "temperature": 0.0, "avg_logprob": -0.06749089308611052, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.006450021639466286}, {"id": 355, "seek": 110768, "start": 1116.68, "end": 1120.68, "text": " Why? Because both versions do exactly the same thing.", "tokens": [50814, 1545, 30, 1436, 1293, 9606, 360, 2293, 264, 912, 551, 13, 51014], "temperature": 0.0, "avg_logprob": -0.06749089308611052, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.006450021639466286}, {"id": 356, "seek": 110768, "start": 1120.68, "end": 1124.68, "text": " We can disassemble the code of both versions with the disk library,", "tokens": [51014, 492, 393, 717, 37319, 264, 3089, 295, 1293, 9606, 365, 264, 12355, 6405, 11, 51214], "temperature": 0.0, "avg_logprob": -0.06749089308611052, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.006450021639466286}, {"id": 357, "seek": 110768, "start": 1124.68, "end": 1126.68, "text": " and we'll see that inside is the same code.", "tokens": [51214, 293, 321, 603, 536, 300, 1854, 307, 264, 912, 3089, 13, 51314], "temperature": 0.0, "avg_logprob": -0.06749089308611052, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.006450021639466286}, {"id": 358, "seek": 110768, "start": 1126.68, "end": 1128.68, "text": " So is there any difference?", "tokens": [51314, 407, 307, 456, 604, 2649, 30, 51414], "temperature": 0.0, "avg_logprob": -0.06749089308611052, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.006450021639466286}, {"id": 359, "seek": 110768, "start": 1128.68, "end": 1131.68, "text": " Well, if your function has more than one line, you can't use lambda.", "tokens": [51414, 1042, 11, 498, 428, 2445, 575, 544, 813, 472, 1622, 11, 291, 393, 380, 764, 13607, 13, 51564], "temperature": 0.0, "avg_logprob": -0.06749089308611052, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.006450021639466286}, {"id": 360, "seek": 110768, "start": 1131.68, "end": 1134.68, "text": " And you can't really put documentation inside of lambda.", "tokens": [51564, 400, 291, 393, 380, 534, 829, 14333, 1854, 295, 13607, 13, 51714], "temperature": 0.0, "avg_logprob": -0.06749089308611052, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.006450021639466286}, {"id": 361, "seek": 113468, "start": 1135.68, "end": 1138.68, "text": " Also, if you have Pepeit enabled in your code editor,", "tokens": [50414, 2743, 11, 498, 291, 362, 2396, 494, 270, 15172, 294, 428, 3089, 9839, 11, 50564], "temperature": 0.0, "avg_logprob": -0.14420402148538383, "compression_ratio": 1.6777777777777778, "no_speech_prob": 0.0103755546733737}, {"id": 362, "seek": 113468, "start": 1138.68, "end": 1141.68, "text": " it will complain each time you try to assign lambda to a variable.", "tokens": [50564, 309, 486, 11024, 1184, 565, 291, 853, 281, 6269, 13607, 281, 257, 7006, 13, 50714], "temperature": 0.0, "avg_logprob": -0.14420402148538383, "compression_ratio": 1.6777777777777778, "no_speech_prob": 0.0103755546733737}, {"id": 363, "seek": 113468, "start": 1141.68, "end": 1143.68, "text": " And in his right,", "tokens": [50714, 400, 294, 702, 558, 11, 50814], "temperature": 0.0, "avg_logprob": -0.14420402148538383, "compression_ratio": 1.6777777777777778, "no_speech_prob": 0.0103755546733737}, {"id": 364, "seek": 113468, "start": 1143.68, "end": 1147.68, "text": " lambdas work really nice when you need a simple one-liner callback", "tokens": [50814, 10097, 27476, 589, 534, 1481, 562, 291, 643, 257, 2199, 472, 12, 36849, 818, 3207, 51014], "temperature": 0.0, "avg_logprob": -0.14420402148538383, "compression_ratio": 1.6777777777777778, "no_speech_prob": 0.0103755546733737}, {"id": 365, "seek": 113468, "start": 1147.68, "end": 1150.68, "text": " for your functions, especially for functions like filter, mabel, reduce.", "tokens": [51014, 337, 428, 6828, 11, 2318, 337, 6828, 411, 6608, 11, 275, 18657, 11, 5407, 13, 51164], "temperature": 0.0, "avg_logprob": -0.14420402148538383, "compression_ratio": 1.6777777777777778, "no_speech_prob": 0.0103755546733737}, {"id": 366, "seek": 113468, "start": 1150.68, "end": 1154.68, "text": " And there are also some quite few narrow use cases", "tokens": [51164, 400, 456, 366, 611, 512, 1596, 1326, 9432, 764, 3331, 51364], "temperature": 0.0, "avg_logprob": -0.14420402148538383, "compression_ratio": 1.6777777777777778, "no_speech_prob": 0.0103755546733737}, {"id": 367, "seek": 113468, "start": 1154.68, "end": 1157.68, "text": " where it might be necessary to use lambda as a callback.", "tokens": [51364, 689, 309, 1062, 312, 4818, 281, 764, 13607, 382, 257, 818, 3207, 13, 51514], "temperature": 0.0, "avg_logprob": -0.14420402148538383, "compression_ratio": 1.6777777777777778, "no_speech_prob": 0.0103755546733737}, {"id": 368, "seek": 113468, "start": 1157.68, "end": 1160.68, "text": " So if you want to read more, you can check the link at the bottom.", "tokens": [51514, 407, 498, 291, 528, 281, 1401, 544, 11, 291, 393, 1520, 264, 2113, 412, 264, 2767, 13, 51664], "temperature": 0.0, "avg_logprob": -0.14420402148538383, "compression_ratio": 1.6777777777777778, "no_speech_prob": 0.0103755546733737}, {"id": 369, "seek": 116068, "start": 1160.68, "end": 1164.68, "text": " In any other case, I would definitely recommend to use that.", "tokens": [50364, 682, 604, 661, 1389, 11, 286, 576, 2138, 2748, 281, 764, 300, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08990592956542968, "compression_ratio": 1.7906137184115523, "no_speech_prob": 0.007608748972415924}, {"id": 370, "seek": 116068, "start": 1164.68, "end": 1167.68, "text": " It's much cleaner, you can document it properly,", "tokens": [50564, 467, 311, 709, 16532, 11, 291, 393, 4166, 309, 6108, 11, 50714], "temperature": 0.0, "avg_logprob": -0.08990592956542968, "compression_ratio": 1.7906137184115523, "no_speech_prob": 0.007608748972415924}, {"id": 371, "seek": 116068, "start": 1167.68, "end": 1169.68, "text": " and the performance is exactly the same.", "tokens": [50714, 293, 264, 3389, 307, 2293, 264, 912, 13, 50814], "temperature": 0.0, "avg_logprob": -0.08990592956542968, "compression_ratio": 1.7906137184115523, "no_speech_prob": 0.007608748972415924}, {"id": 372, "seek": 116068, "start": 1171.68, "end": 1174.68, "text": " So there are two ways how you can create an empty list.", "tokens": [50914, 407, 456, 366, 732, 2098, 577, 291, 393, 1884, 364, 6707, 1329, 13, 51064], "temperature": 0.0, "avg_logprob": -0.08990592956542968, "compression_ratio": 1.7906137184115523, "no_speech_prob": 0.007608748972415924}, {"id": 373, "seek": 116068, "start": 1174.68, "end": 1176.68, "text": " So you can either call a list function,", "tokens": [51064, 407, 291, 393, 2139, 818, 257, 1329, 2445, 11, 51164], "temperature": 0.0, "avg_logprob": -0.08990592956542968, "compression_ratio": 1.7906137184115523, "no_speech_prob": 0.007608748972415924}, {"id": 374, "seek": 116068, "start": 1176.68, "end": 1178.68, "text": " or you can just use the list literal syntax.", "tokens": [51164, 420, 291, 393, 445, 764, 264, 1329, 20411, 28431, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08990592956542968, "compression_ratio": 1.7906137184115523, "no_speech_prob": 0.007608748972415924}, {"id": 375, "seek": 116068, "start": 1178.68, "end": 1181.68, "text": " And as you can see, the literal syntax is faster.", "tokens": [51264, 400, 382, 291, 393, 536, 11, 264, 20411, 28431, 307, 4663, 13, 51414], "temperature": 0.0, "avg_logprob": -0.08990592956542968, "compression_ratio": 1.7906137184115523, "no_speech_prob": 0.007608748972415924}, {"id": 376, "seek": 116068, "start": 1181.68, "end": 1183.68, "text": " Why is it faster?", "tokens": [51414, 1545, 307, 309, 4663, 30, 51514], "temperature": 0.0, "avg_logprob": -0.08990592956542968, "compression_ratio": 1.7906137184115523, "no_speech_prob": 0.007608748972415924}, {"id": 377, "seek": 116068, "start": 1183.68, "end": 1186.68, "text": " Because if you call a function, Python first needs to resolve this function.", "tokens": [51514, 1436, 498, 291, 818, 257, 2445, 11, 15329, 700, 2203, 281, 14151, 341, 2445, 13, 51664], "temperature": 0.0, "avg_logprob": -0.08990592956542968, "compression_ratio": 1.7906137184115523, "no_speech_prob": 0.007608748972415924}, {"id": 378, "seek": 116068, "start": 1186.68, "end": 1189.68, "text": " And with the literal syntax, there is no overhead for that.", "tokens": [51664, 400, 365, 264, 20411, 28431, 11, 456, 307, 572, 19922, 337, 300, 13, 51814], "temperature": 0.0, "avg_logprob": -0.08990592956542968, "compression_ratio": 1.7906137184115523, "no_speech_prob": 0.007608748972415924}, {"id": 379, "seek": 119068, "start": 1190.68, "end": 1193.68, "text": " And the exact same thing happens for creating a dictionary.", "tokens": [50364, 400, 264, 1900, 912, 551, 2314, 337, 4084, 257, 25890, 13, 50514], "temperature": 0.0, "avg_logprob": -0.09097544017590975, "compression_ratio": 1.579591836734694, "no_speech_prob": 0.0013971144799143076}, {"id": 380, "seek": 119068, "start": 1197.68, "end": 1200.68, "text": " Okay, I have two more examples that should be treated with quotient.", "tokens": [50714, 1033, 11, 286, 362, 732, 544, 5110, 300, 820, 312, 8668, 365, 9641, 1196, 13, 50864], "temperature": 0.0, "avg_logprob": -0.09097544017590975, "compression_ratio": 1.579591836734694, "no_speech_prob": 0.0013971144799143076}, {"id": 381, "seek": 119068, "start": 1200.68, "end": 1203.68, "text": " Even though the code can run faster,", "tokens": [50864, 2754, 1673, 264, 3089, 393, 1190, 4663, 11, 51014], "temperature": 0.0, "avg_logprob": -0.09097544017590975, "compression_ratio": 1.579591836734694, "no_speech_prob": 0.0013971144799143076}, {"id": 382, "seek": 119068, "start": 1203.68, "end": 1206.68, "text": " I would not advise you to do this kind of optimization.", "tokens": [51014, 286, 576, 406, 18312, 291, 281, 360, 341, 733, 295, 19618, 13, 51164], "temperature": 0.0, "avg_logprob": -0.09097544017590975, "compression_ratio": 1.579591836734694, "no_speech_prob": 0.0013971144799143076}, {"id": 383, "seek": 119068, "start": 1206.68, "end": 1210.68, "text": " So sometimes, even though you can squeeze some additional performance from your code,", "tokens": [51164, 407, 2171, 11, 754, 1673, 291, 393, 13578, 512, 4497, 3389, 490, 428, 3089, 11, 51364], "temperature": 0.0, "avg_logprob": -0.09097544017590975, "compression_ratio": 1.579591836734694, "no_speech_prob": 0.0013971144799143076}, {"id": 384, "seek": 119068, "start": 1210.68, "end": 1213.68, "text": " it doesn't mean that you should do this.", "tokens": [51364, 309, 1177, 380, 914, 300, 291, 820, 360, 341, 13, 51514], "temperature": 0.0, "avg_logprob": -0.09097544017590975, "compression_ratio": 1.579591836734694, "no_speech_prob": 0.0013971144799143076}, {"id": 385, "seek": 119068, "start": 1216.68, "end": 1218.68, "text": " So one thing is a variable assignment.", "tokens": [51664, 407, 472, 551, 307, 257, 7006, 15187, 13, 51764], "temperature": 0.0, "avg_logprob": -0.09097544017590975, "compression_ratio": 1.579591836734694, "no_speech_prob": 0.0013971144799143076}, {"id": 386, "seek": 121868, "start": 1219.68, "end": 1222.68, "text": " If you have a bunch of variables that you need to assign,", "tokens": [50414, 759, 291, 362, 257, 3840, 295, 9102, 300, 291, 643, 281, 6269, 11, 50564], "temperature": 0.0, "avg_logprob": -0.06684712339038691, "compression_ratio": 1.7014925373134329, "no_speech_prob": 0.0011597673874348402}, {"id": 387, "seek": 121868, "start": 1222.68, "end": 1224.68, "text": " you can do this the normal sequential way,", "tokens": [50564, 291, 393, 360, 341, 264, 2710, 42881, 636, 11, 50664], "temperature": 0.0, "avg_logprob": -0.06684712339038691, "compression_ratio": 1.7014925373134329, "no_speech_prob": 0.0011597673874348402}, {"id": 388, "seek": 121868, "start": 1224.68, "end": 1227.68, "text": " or you can go for this crazy parallel assignment.", "tokens": [50664, 420, 291, 393, 352, 337, 341, 3219, 8952, 15187, 13, 50814], "temperature": 0.0, "avg_logprob": -0.06684712339038691, "compression_ratio": 1.7014925373134329, "no_speech_prob": 0.0011597673874348402}, {"id": 389, "seek": 121868, "start": 1227.68, "end": 1230.68, "text": " And I mean, you can gain some speed,", "tokens": [50814, 400, 286, 914, 11, 291, 393, 6052, 512, 3073, 11, 50964], "temperature": 0.0, "avg_logprob": -0.06684712339038691, "compression_ratio": 1.7014925373134329, "no_speech_prob": 0.0011597673874348402}, {"id": 390, "seek": 121868, "start": 1230.68, "end": 1233.68, "text": " but with this speed comes the hate of your colleagues", "tokens": [50964, 457, 365, 341, 3073, 1487, 264, 4700, 295, 428, 7734, 51114], "temperature": 0.0, "avg_logprob": -0.06684712339038691, "compression_ratio": 1.7014925373134329, "no_speech_prob": 0.0011597673874348402}, {"id": 391, "seek": 121868, "start": 1233.68, "end": 1235.68, "text": " that will be reading this code later.", "tokens": [51114, 300, 486, 312, 3760, 341, 3089, 1780, 13, 51214], "temperature": 0.0, "avg_logprob": -0.06684712339038691, "compression_ratio": 1.7014925373134329, "no_speech_prob": 0.0011597673874348402}, {"id": 392, "seek": 121868, "start": 1235.68, "end": 1238.68, "text": " So in my opinion, it's not worth it.", "tokens": [51214, 407, 294, 452, 4800, 11, 309, 311, 406, 3163, 309, 13, 51364], "temperature": 0.0, "avg_logprob": -0.06684712339038691, "compression_ratio": 1.7014925373134329, "no_speech_prob": 0.0011597673874348402}, {"id": 393, "seek": 121868, "start": 1239.68, "end": 1241.68, "text": " Okay, and another interesting property of Python", "tokens": [51414, 1033, 11, 293, 1071, 1880, 4707, 295, 15329, 51514], "temperature": 0.0, "avg_logprob": -0.06684712339038691, "compression_ratio": 1.7014925373134329, "no_speech_prob": 0.0011597673874348402}, {"id": 394, "seek": 121868, "start": 1241.68, "end": 1243.68, "text": " is that the lookup for local variables", "tokens": [51514, 307, 300, 264, 574, 1010, 337, 2654, 9102, 51614], "temperature": 0.0, "avg_logprob": -0.06684712339038691, "compression_ratio": 1.7014925373134329, "no_speech_prob": 0.0011597673874348402}, {"id": 395, "seek": 121868, "start": 1243.68, "end": 1246.68, "text": " is faster than the lookup for globals or buildings.", "tokens": [51614, 307, 4663, 813, 264, 574, 1010, 337, 16125, 1124, 420, 7446, 13, 51764], "temperature": 0.0, "avg_logprob": -0.06684712339038691, "compression_ratio": 1.7014925373134329, "no_speech_prob": 0.0011597673874348402}, {"id": 396, "seek": 124668, "start": 1246.68, "end": 1250.68, "text": " So you can save some time if you store the reference to a building function", "tokens": [50364, 407, 291, 393, 3155, 512, 565, 498, 291, 3531, 264, 6408, 281, 257, 2390, 2445, 50564], "temperature": 0.0, "avg_logprob": -0.08821251353279488, "compression_ratio": 1.7946768060836502, "no_speech_prob": 0.0022661613766103983}, {"id": 397, "seek": 124668, "start": 1250.68, "end": 1253.68, "text": " or a global function in a local variable.", "tokens": [50564, 420, 257, 4338, 2445, 294, 257, 2654, 7006, 13, 50714], "temperature": 0.0, "avg_logprob": -0.08821251353279488, "compression_ratio": 1.7946768060836502, "no_speech_prob": 0.0022661613766103983}, {"id": 398, "seek": 124668, "start": 1253.68, "end": 1256.68, "text": " So in this example, the only difference is on the line 3,", "tokens": [50714, 407, 294, 341, 1365, 11, 264, 787, 2649, 307, 322, 264, 1622, 805, 11, 50864], "temperature": 0.0, "avg_logprob": -0.08821251353279488, "compression_ratio": 1.7946768060836502, "no_speech_prob": 0.0022661613766103983}, {"id": 399, "seek": 124668, "start": 1256.68, "end": 1261.68, "text": " where I'm storing the reference to the global append in a local append variable.", "tokens": [50864, 689, 286, 478, 26085, 264, 6408, 281, 264, 4338, 34116, 294, 257, 2654, 34116, 7006, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08821251353279488, "compression_ratio": 1.7946768060836502, "no_speech_prob": 0.0022661613766103983}, {"id": 400, "seek": 124668, "start": 1261.68, "end": 1265.68, "text": " And thanks to that, this function is like 35% faster.", "tokens": [51114, 400, 3231, 281, 300, 11, 341, 2445, 307, 411, 6976, 4, 4663, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08821251353279488, "compression_ratio": 1.7946768060836502, "no_speech_prob": 0.0022661613766103983}, {"id": 401, "seek": 124668, "start": 1265.68, "end": 1268.68, "text": " But then again, if you see this code for the first time,", "tokens": [51314, 583, 550, 797, 11, 498, 291, 536, 341, 3089, 337, 264, 700, 565, 11, 51464], "temperature": 0.0, "avg_logprob": -0.08821251353279488, "compression_ratio": 1.7946768060836502, "no_speech_prob": 0.0022661613766103983}, {"id": 402, "seek": 124668, "start": 1268.68, "end": 1272.68, "text": " it's not very clear what it is supposed to do.", "tokens": [51464, 309, 311, 406, 588, 1850, 437, 309, 307, 3442, 281, 360, 13, 51664], "temperature": 0.0, "avg_logprob": -0.08821251353279488, "compression_ratio": 1.7946768060836502, "no_speech_prob": 0.0022661613766103983}, {"id": 403, "seek": 124668, "start": 1272.68, "end": 1275.68, "text": " It might be confusing to see this kind of append function", "tokens": [51664, 467, 1062, 312, 13181, 281, 536, 341, 733, 295, 34116, 2445, 51814], "temperature": 0.0, "avg_logprob": -0.08821251353279488, "compression_ratio": 1.7946768060836502, "no_speech_prob": 0.0022661613766103983}, {"id": 404, "seek": 127568, "start": 1275.68, "end": 1279.68, "text": " because we are most used to see the list.append version.", "tokens": [50364, 570, 321, 366, 881, 1143, 281, 536, 264, 1329, 13, 1746, 521, 3037, 13, 50564], "temperature": 0.0, "avg_logprob": -0.07828309319236061, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0010442939819768071}, {"id": 405, "seek": 127568, "start": 1282.68, "end": 1285.68, "text": " To sum up, there are different kind of optimizations.", "tokens": [50714, 1407, 2408, 493, 11, 456, 366, 819, 733, 295, 5028, 14455, 13, 50864], "temperature": 0.0, "avg_logprob": -0.07828309319236061, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0010442939819768071}, {"id": 406, "seek": 127568, "start": 1285.68, "end": 1288.68, "text": " It's quite often about the speed, but not always.", "tokens": [50864, 467, 311, 1596, 2049, 466, 264, 3073, 11, 457, 406, 1009, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07828309319236061, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0010442939819768071}, {"id": 407, "seek": 127568, "start": 1288.68, "end": 1291.68, "text": " And there are also different levels of optimization.", "tokens": [51014, 400, 456, 366, 611, 819, 4358, 295, 19618, 13, 51164], "temperature": 0.0, "avg_logprob": -0.07828309319236061, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0010442939819768071}, {"id": 408, "seek": 127568, "start": 1291.68, "end": 1295.68, "text": " So sometimes if you cannot rewrite your whole application,", "tokens": [51164, 407, 2171, 498, 291, 2644, 28132, 428, 1379, 3861, 11, 51364], "temperature": 0.0, "avg_logprob": -0.07828309319236061, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0010442939819768071}, {"id": 409, "seek": 127568, "start": 1295.68, "end": 1298.68, "text": " maybe you can use a different approach.", "tokens": [51364, 1310, 291, 393, 764, 257, 819, 3109, 13, 51514], "temperature": 0.0, "avg_logprob": -0.07828309319236061, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0010442939819768071}, {"id": 410, "seek": 127568, "start": 1298.68, "end": 1300.68, "text": " Even though the source code optimization", "tokens": [51514, 2754, 1673, 264, 4009, 3089, 19618, 51614], "temperature": 0.0, "avg_logprob": -0.07828309319236061, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0010442939819768071}, {"id": 411, "seek": 127568, "start": 1300.68, "end": 1303.68, "text": " is not the fastest way to optimize your code,", "tokens": [51614, 307, 406, 264, 14573, 636, 281, 19719, 428, 3089, 11, 51764], "temperature": 0.0, "avg_logprob": -0.07828309319236061, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0010442939819768071}, {"id": 412, "seek": 130368, "start": 1303.68, "end": 1305.68, "text": " those small improvements will add up.", "tokens": [50364, 729, 1359, 13797, 486, 909, 493, 13, 50464], "temperature": 0.0, "avg_logprob": -0.07452991429497213, "compression_ratio": 1.6610878661087867, "no_speech_prob": 0.0029801775235682726}, {"id": 413, "seek": 130368, "start": 1305.68, "end": 1308.68, "text": " And the main advantage of it is cheap.", "tokens": [50464, 400, 264, 2135, 5002, 295, 309, 307, 7084, 13, 50614], "temperature": 0.0, "avg_logprob": -0.07452991429497213, "compression_ratio": 1.6610878661087867, "no_speech_prob": 0.0029801775235682726}, {"id": 414, "seek": 130368, "start": 1308.68, "end": 1313.68, "text": " So you can optimize the code at the moment of writing.", "tokens": [50614, 407, 291, 393, 19719, 264, 3089, 412, 264, 1623, 295, 3579, 13, 50864], "temperature": 0.0, "avg_logprob": -0.07452991429497213, "compression_ratio": 1.6610878661087867, "no_speech_prob": 0.0029801775235682726}, {"id": 415, "seek": 130368, "start": 1313.68, "end": 1316.68, "text": " You don't really need to rewrite something.", "tokens": [50864, 509, 500, 380, 534, 643, 281, 28132, 746, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07452991429497213, "compression_ratio": 1.6610878661087867, "no_speech_prob": 0.0029801775235682726}, {"id": 416, "seek": 130368, "start": 1316.68, "end": 1318.68, "text": " And as long as you're writing idiomatic code", "tokens": [51014, 400, 382, 938, 382, 291, 434, 3579, 18014, 13143, 3089, 51114], "temperature": 0.0, "avg_logprob": -0.07452991429497213, "compression_ratio": 1.6610878661087867, "no_speech_prob": 0.0029801775235682726}, {"id": 417, "seek": 130368, "start": 1318.68, "end": 1320.68, "text": " and you don't reinvent the wheel", "tokens": [51114, 293, 291, 500, 380, 33477, 264, 5589, 51214], "temperature": 0.0, "avg_logprob": -0.07452991429497213, "compression_ratio": 1.6610878661087867, "no_speech_prob": 0.0029801775235682726}, {"id": 418, "seek": 130368, "start": 1320.68, "end": 1324.68, "text": " but already use the existing functions and data structures in Python,", "tokens": [51214, 457, 1217, 764, 264, 6741, 6828, 293, 1412, 9227, 294, 15329, 11, 51414], "temperature": 0.0, "avg_logprob": -0.07452991429497213, "compression_ratio": 1.6610878661087867, "no_speech_prob": 0.0029801775235682726}, {"id": 419, "seek": 130368, "start": 1324.68, "end": 1327.68, "text": " then you're already doing it correctly.", "tokens": [51414, 550, 291, 434, 1217, 884, 309, 8944, 13, 51564], "temperature": 0.0, "avg_logprob": -0.07452991429497213, "compression_ratio": 1.6610878661087867, "no_speech_prob": 0.0029801775235682726}, {"id": 420, "seek": 130368, "start": 1327.68, "end": 1329.68, "text": " So be curious when you're coding.", "tokens": [51564, 407, 312, 6369, 562, 291, 434, 17720, 13, 51664], "temperature": 0.0, "avg_logprob": -0.07452991429497213, "compression_ratio": 1.6610878661087867, "no_speech_prob": 0.0029801775235682726}, {"id": 421, "seek": 132968, "start": 1329.68, "end": 1333.68, "text": " If you think that the different code structure can be faster,", "tokens": [50364, 759, 291, 519, 300, 264, 819, 3089, 3877, 393, 312, 4663, 11, 50564], "temperature": 0.0, "avg_logprob": -0.10534757988475194, "compression_ratio": 1.590717299578059, "no_speech_prob": 0.006905536632984877}, {"id": 422, "seek": 132968, "start": 1333.68, "end": 1335.68, "text": " you can quickly check it with the time it,", "tokens": [50564, 291, 393, 2661, 1520, 309, 365, 264, 565, 309, 11, 50664], "temperature": 0.0, "avg_logprob": -0.10534757988475194, "compression_ratio": 1.590717299578059, "no_speech_prob": 0.006905536632984877}, {"id": 423, "seek": 132968, "start": 1335.68, "end": 1338.68, "text": " and then you can improve it.", "tokens": [50664, 293, 550, 291, 393, 3470, 309, 13, 50814], "temperature": 0.0, "avg_logprob": -0.10534757988475194, "compression_ratio": 1.590717299578059, "no_speech_prob": 0.006905536632984877}, {"id": 424, "seek": 132968, "start": 1338.68, "end": 1340.68, "text": " All right, my name is Sebastian Witowski, and I work at CERN.", "tokens": [50814, 1057, 558, 11, 452, 1315, 307, 31102, 42299, 21866, 11, 293, 286, 589, 412, 383, 1598, 45, 13, 50914], "temperature": 0.0, "avg_logprob": -0.10534757988475194, "compression_ratio": 1.590717299578059, "no_speech_prob": 0.006905536632984877}, {"id": 425, "seek": 132968, "start": 1340.68, "end": 1342.68, "text": " So if you guys want to talk about physics,", "tokens": [50914, 407, 498, 291, 1074, 528, 281, 751, 466, 10649, 11, 51014], "temperature": 0.0, "avg_logprob": -0.10534757988475194, "compression_ratio": 1.590717299578059, "no_speech_prob": 0.006905536632984877}, {"id": 426, "seek": 132968, "start": 1342.68, "end": 1345.68, "text": " then you're probably on the wrong conference.", "tokens": [51014, 550, 291, 434, 1391, 322, 264, 2085, 7586, 13, 51164], "temperature": 0.0, "avg_logprob": -0.10534757988475194, "compression_ratio": 1.590717299578059, "no_speech_prob": 0.006905536632984877}, {"id": 427, "seek": 132968, "start": 1345.68, "end": 1347.68, "text": " But if you want to talk about Python,", "tokens": [51164, 583, 498, 291, 528, 281, 751, 466, 15329, 11, 51264], "temperature": 0.0, "avg_logprob": -0.10534757988475194, "compression_ratio": 1.590717299578059, "no_speech_prob": 0.006905536632984877}, {"id": 428, "seek": 132968, "start": 1347.68, "end": 1349.68, "text": " you can catch me somewhere on the corridor.", "tokens": [51264, 291, 393, 3745, 385, 4079, 322, 264, 25602, 13, 51364], "temperature": 0.0, "avg_logprob": -0.10534757988475194, "compression_ratio": 1.590717299578059, "no_speech_prob": 0.006905536632984877}, {"id": 429, "seek": 132968, "start": 1349.68, "end": 1350.68, "text": " Thank you.", "tokens": [51364, 1044, 291, 13, 51414], "temperature": 0.0, "avg_logprob": -0.10534757988475194, "compression_ratio": 1.590717299578059, "no_speech_prob": 0.006905536632984877}, {"id": 430, "seek": 135068, "start": 1350.68, "end": 1360.68, "text": " All right, brilliant.", "tokens": [50364, 1057, 558, 11, 10248, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1662750479615765, "compression_ratio": 1.4916201117318435, "no_speech_prob": 0.019370069727301598}, {"id": 431, "seek": 135068, "start": 1360.68, "end": 1363.68, "text": " We have about two minutes for questions.", "tokens": [50864, 492, 362, 466, 732, 2077, 337, 1651, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1662750479615765, "compression_ratio": 1.4916201117318435, "no_speech_prob": 0.019370069727301598}, {"id": 432, "seek": 135068, "start": 1363.68, "end": 1365.68, "text": " Sebastian, if you're happy to take one or two questions,", "tokens": [51014, 31102, 11, 498, 291, 434, 2055, 281, 747, 472, 420, 732, 1651, 11, 51114], "temperature": 0.0, "avg_logprob": -0.1662750479615765, "compression_ratio": 1.4916201117318435, "no_speech_prob": 0.019370069727301598}, {"id": 433, "seek": 135068, "start": 1365.68, "end": 1366.68, "text": " shall we have them?", "tokens": [51114, 4393, 321, 362, 552, 30, 51164], "temperature": 0.0, "avg_logprob": -0.1662750479615765, "compression_ratio": 1.4916201117318435, "no_speech_prob": 0.019370069727301598}, {"id": 434, "seek": 135068, "start": 1366.68, "end": 1371.68, "text": " Fantastic. Who's got a question? You, sir.", "tokens": [51164, 21320, 13, 2102, 311, 658, 257, 1168, 30, 509, 11, 4735, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1662750479615765, "compression_ratio": 1.4916201117318435, "no_speech_prob": 0.019370069727301598}, {"id": 435, "seek": 135068, "start": 1371.68, "end": 1373.68, "text": " Awesome talk. I have a quick question.", "tokens": [51414, 10391, 751, 13, 286, 362, 257, 1702, 1168, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1662750479615765, "compression_ratio": 1.4916201117318435, "no_speech_prob": 0.019370069727301598}, {"id": 436, "seek": 135068, "start": 1373.68, "end": 1377.68, "text": " You showed us some profilers, code profilers.", "tokens": [51514, 509, 4712, 505, 512, 1740, 388, 433, 11, 3089, 1740, 388, 433, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1662750479615765, "compression_ratio": 1.4916201117318435, "no_speech_prob": 0.019370069727301598}, {"id": 437, "seek": 137768, "start": 1377.68, "end": 1383.68, "text": " Do you have any preference, any favorites?", "tokens": [50364, 1144, 291, 362, 604, 17502, 11, 604, 16907, 30, 50664], "temperature": 0.0, "avg_logprob": -0.13992564622745957, "compression_ratio": 1.7243243243243243, "no_speech_prob": 0.021498309448361397}, {"id": 438, "seek": 137768, "start": 1383.68, "end": 1386.68, "text": " It really depends what you want to profile.", "tokens": [50664, 467, 534, 5946, 437, 291, 528, 281, 7964, 13, 50814], "temperature": 0.0, "avg_logprob": -0.13992564622745957, "compression_ratio": 1.7243243243243243, "no_speech_prob": 0.021498309448361397}, {"id": 439, "seek": 137768, "start": 1386.68, "end": 1389.68, "text": " Because if you care about the speed, then the basic ones are fine.", "tokens": [50814, 1436, 498, 291, 1127, 466, 264, 3073, 11, 550, 264, 3875, 2306, 366, 2489, 13, 50964], "temperature": 0.0, "avg_logprob": -0.13992564622745957, "compression_ratio": 1.7243243243243243, "no_speech_prob": 0.021498309448361397}, {"id": 440, "seek": 137768, "start": 1389.68, "end": 1391.68, "text": " But if you want to profile the memory users,", "tokens": [50964, 583, 498, 291, 528, 281, 7964, 264, 4675, 5022, 11, 51064], "temperature": 0.0, "avg_logprob": -0.13992564622745957, "compression_ratio": 1.7243243243243243, "no_speech_prob": 0.021498309448361397}, {"id": 441, "seek": 137768, "start": 1391.68, "end": 1393.68, "text": " then you might need to use different profilers.", "tokens": [51064, 550, 291, 1062, 643, 281, 764, 819, 1740, 388, 433, 13, 51164], "temperature": 0.0, "avg_logprob": -0.13992564622745957, "compression_ratio": 1.7243243243243243, "no_speech_prob": 0.021498309448361397}, {"id": 442, "seek": 137768, "start": 1393.68, "end": 1397.68, "text": " So it really depends what you want to profile.", "tokens": [51164, 407, 309, 534, 5946, 437, 291, 528, 281, 7964, 13, 51364], "temperature": 0.0, "avg_logprob": -0.13992564622745957, "compression_ratio": 1.7243243243243243, "no_speech_prob": 0.021498309448361397}, {"id": 443, "seek": 137768, "start": 1397.68, "end": 1403.68, "text": " Any other questions? Yep.", "tokens": [51364, 2639, 661, 1651, 30, 7010, 13, 51664], "temperature": 0.0, "avg_logprob": -0.13992564622745957, "compression_ratio": 1.7243243243243243, "no_speech_prob": 0.021498309448361397}, {"id": 444, "seek": 140368, "start": 1403.68, "end": 1405.68, "text": " Do you have any recommendation on books or source", "tokens": [50364, 1144, 291, 362, 604, 11879, 322, 3642, 420, 4009, 50464], "temperature": 0.0, "avg_logprob": -0.20535004813716096, "compression_ratio": 1.5582329317269077, "no_speech_prob": 0.4727585017681122}, {"id": 445, "seek": 140368, "start": 1405.68, "end": 1408.68, "text": " where we can find best practices regarding this", "tokens": [50464, 689, 321, 393, 915, 1151, 7525, 8595, 341, 50614], "temperature": 0.0, "avg_logprob": -0.20535004813716096, "compression_ratio": 1.5582329317269077, "no_speech_prob": 0.4727585017681122}, {"id": 446, "seek": 140368, "start": 1408.68, "end": 1411.68, "text": " idiomatic Python?", "tokens": [50614, 18014, 13143, 15329, 30, 50764], "temperature": 0.0, "avg_logprob": -0.20535004813716096, "compression_ratio": 1.5582329317269077, "no_speech_prob": 0.4727585017681122}, {"id": 447, "seek": 140368, "start": 1411.68, "end": 1414.68, "text": " Not from the top of my head,", "tokens": [50764, 1726, 490, 264, 1192, 295, 452, 1378, 11, 50914], "temperature": 0.0, "avg_logprob": -0.20535004813716096, "compression_ratio": 1.5582329317269077, "no_speech_prob": 0.4727585017681122}, {"id": 448, "seek": 140368, "start": 1414.68, "end": 1418.68, "text": " but, well, definitely there is some guides", "tokens": [50914, 457, 11, 731, 11, 2138, 456, 307, 512, 17007, 51114], "temperature": 0.0, "avg_logprob": -0.20535004813716096, "compression_ratio": 1.5582329317269077, "no_speech_prob": 0.4727585017681122}, {"id": 449, "seek": 140368, "start": 1418.68, "end": 1420.68, "text": " on the official Python documentation.", "tokens": [51114, 322, 264, 4783, 15329, 14333, 13, 51214], "temperature": 0.0, "avg_logprob": -0.20535004813716096, "compression_ratio": 1.5582329317269077, "no_speech_prob": 0.4727585017681122}, {"id": 450, "seek": 140368, "start": 1420.68, "end": 1423.68, "text": " But also, for me, it's a lot of Googling", "tokens": [51214, 583, 611, 11, 337, 385, 11, 309, 311, 257, 688, 295, 45005, 1688, 51364], "temperature": 0.0, "avg_logprob": -0.20535004813716096, "compression_ratio": 1.5582329317269077, "no_speech_prob": 0.4727585017681122}, {"id": 451, "seek": 140368, "start": 1423.68, "end": 1426.68, "text": " for best practices, also reading a lot of Stack Overflow.", "tokens": [51364, 337, 1151, 7525, 11, 611, 3760, 257, 688, 295, 37649, 4886, 10565, 13, 51514], "temperature": 0.0, "avg_logprob": -0.20535004813716096, "compression_ratio": 1.5582329317269077, "no_speech_prob": 0.4727585017681122}, {"id": 452, "seek": 140368, "start": 1426.68, "end": 1431.68, "text": " There are some books, but I can't give you the names right now.", "tokens": [51514, 821, 366, 512, 3642, 11, 457, 286, 393, 380, 976, 291, 264, 5288, 558, 586, 13, 51764], "temperature": 0.0, "avg_logprob": -0.20535004813716096, "compression_ratio": 1.5582329317269077, "no_speech_prob": 0.4727585017681122}, {"id": 453, "seek": 143168, "start": 1431.68, "end": 1433.68, "text": " Any more questions?", "tokens": [50364, 2639, 544, 1651, 30, 50464], "temperature": 0.0, "avg_logprob": -0.19924838106397172, "compression_ratio": 1.4573170731707317, "no_speech_prob": 0.03643430396914482}, {"id": 454, "seek": 143168, "start": 1433.68, "end": 1435.68, "text": " Yes?", "tokens": [50464, 1079, 30, 50564], "temperature": 0.0, "avg_logprob": -0.19924838106397172, "compression_ratio": 1.4573170731707317, "no_speech_prob": 0.03643430396914482}, {"id": 455, "seek": 143168, "start": 1435.68, "end": 1437.68, "text": " Was that you sticking your hand up, sir,", "tokens": [50564, 3027, 300, 291, 13465, 428, 1011, 493, 11, 4735, 11, 50664], "temperature": 0.0, "avg_logprob": -0.19924838106397172, "compression_ratio": 1.4573170731707317, "no_speech_prob": 0.03643430396914482}, {"id": 456, "seek": 143168, "start": 1437.68, "end": 1439.68, "text": " or just explaining something excitedly?", "tokens": [50664, 420, 445, 13468, 746, 2919, 356, 30, 50764], "temperature": 0.0, "avg_logprob": -0.19924838106397172, "compression_ratio": 1.4573170731707317, "no_speech_prob": 0.03643430396914482}, {"id": 457, "seek": 143168, "start": 1439.68, "end": 1441.68, "text": " Pretty really not a question.", "tokens": [50764, 10693, 534, 406, 257, 1168, 13, 50864], "temperature": 0.0, "avg_logprob": -0.19924838106397172, "compression_ratio": 1.4573170731707317, "no_speech_prob": 0.03643430396914482}, {"id": 458, "seek": 143168, "start": 1441.68, "end": 1443.68, "text": " Any more questions? No?", "tokens": [50864, 2639, 544, 1651, 30, 883, 30, 50964], "temperature": 0.0, "avg_logprob": -0.19924838106397172, "compression_ratio": 1.4573170731707317, "no_speech_prob": 0.03643430396914482}, {"id": 459, "seek": 143168, "start": 1443.68, "end": 1445.68, "text": " In that case, let's thank our speaker for a fantastic talking.", "tokens": [50964, 682, 300, 1389, 11, 718, 311, 1309, 527, 8145, 337, 257, 5456, 1417, 13, 51064], "temperature": 0.0, "avg_logprob": -0.19924838106397172, "compression_ratio": 1.4573170731707317, "no_speech_prob": 0.03643430396914482}, {"id": 460, "seek": 143168, "start": 1445.68, "end": 1447.68, "text": " Nice to ask you.", "tokens": [51064, 5490, 281, 1029, 291, 13, 51164], "temperature": 0.0, "avg_logprob": -0.19924838106397172, "compression_ratio": 1.4573170731707317, "no_speech_prob": 0.03643430396914482}], "language": "en"}