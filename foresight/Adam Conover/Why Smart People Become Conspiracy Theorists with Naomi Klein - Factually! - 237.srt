1
00:00:00,000 --> 00:00:04,480
Hello and welcome to Factually. I'm Adam Conover. Thank you so much for joining me on the show again.

2
00:00:04,480 --> 00:00:10,560
This week, I want to talk about an experience that is both weird and weirdly common in 2023 in

3
00:00:10,560 --> 00:00:14,720
the past couple years. You've probably seen it happen to someone around you. Maybe it was a roommate,

4
00:00:14,720 --> 00:00:19,920
a parent, a family friend, or for me, some comedians I started out with. Whoever it was,

5
00:00:19,920 --> 00:00:26,320
the story is the same. Someone who seemed sane with it and living in the same reality as you did

6
00:00:26,320 --> 00:00:33,280
suddenly lost their mind and went down some rabbit hole to emerge as a fully blown conspiracy

7
00:00:33,280 --> 00:00:39,200
theorist. Now, people have been losing their shit like this from time immemorial. As I've covered

8
00:00:39,200 --> 00:00:44,400
before on this show and on Adam ruins everything, conspiratorial thinking follows from the normal

9
00:00:44,400 --> 00:00:49,920
patterns of human thought that we use to understand the world around us. But it seems that there's

10
00:00:49,920 --> 00:00:55,520
something particular and special about the way that people fall into the trap of conspiratorial

11
00:00:55,520 --> 00:01:02,400
thinking now. Whether it starts on 4chan or Fox News, anti-vaxx or QAnon, there's a mirror world

12
00:01:02,400 --> 00:01:08,560
of socially poisonous conspiracy that people keep falling into. It is incredibly painful when it

13
00:01:08,560 --> 00:01:14,080
happens to someone who you know and love and it's often hard to know how to even understand what

14
00:01:14,080 --> 00:01:21,280
happened. What is it about our world, our media, and our politics today that makes this happen

15
00:01:21,360 --> 00:01:28,320
over and over again, the reasonable people who we love and care about? Well, today I have a truly

16
00:01:28,320 --> 00:01:34,080
brilliant guest to help dig into this issue and into the entire mirror world that our politics

17
00:01:34,080 --> 00:01:38,000
and media ecosystem has become. But before we get into it, I just want to remind you that if you

18
00:01:38,000 --> 00:01:43,200
want to support this show, you can do so on Patreon. Head to patreon.com slash Adam Conover.

19
00:01:43,200 --> 00:01:47,520
Five bucks a month gets you every episode of the show ad free. You can hear all the wonderful

20
00:01:47,520 --> 00:01:51,360
interviews we do every single week and you can support other people getting them as well.

21
00:01:51,360 --> 00:01:55,200
And by the way, if you like stand-up comedy, just want to remind you I am a touring stand-up

22
00:01:55,200 --> 00:02:00,400
comedian. I just put a whole bunch of new dates up on my website. In 2024, I am heading to New

23
00:02:00,400 --> 00:02:06,480
York, Boston, Philly, D.C., Portland, Maine, a bunch of other places, Chicago, Nashville,

24
00:02:06,480 --> 00:02:13,040
head to adamconover.net for tickets and tour dates. And now let's get to today's guest because she is

25
00:02:13,040 --> 00:02:17,520
incredible. She's one of the most respected and influential public intellectuals and

26
00:02:17,520 --> 00:02:23,680
nonfiction authors on the left of the past century. Her writings on consumerism, capitalism,

27
00:02:23,680 --> 00:02:28,320
and climate are required reading. And her most recent book is called doppelganger,

28
00:02:28,320 --> 00:02:33,280
a trip into the mirror world. I am, of course, talking about the incredible Naomi Klein and her

29
00:02:33,280 --> 00:02:38,880
new book is a fascinating and personal look into the conspiratorial ways of thinking that are thriving

30
00:02:38,880 --> 00:02:42,880
in the moment we live in today. So without further ado, please welcome Naomi Klein.

31
00:02:45,760 --> 00:02:49,760
Naomi, thank you so much for being on the show. It's a complete thrill to have you.

32
00:02:49,760 --> 00:02:54,880
I'm very happy to be with you. Your books, every time one comes out, they make waves

33
00:02:54,880 --> 00:03:00,800
every single time. This new one, I am so excited about having read the introduction of the first

34
00:03:00,800 --> 00:03:07,120
chapter. It's immediately gripping. You do something that is a form of thinking and communicating

35
00:03:07,120 --> 00:03:11,360
that is very close to my heart. Always interesting to me where you start from

36
00:03:11,360 --> 00:03:17,040
a fascinating personal story and you ladder out from that to a really wide ranging discussion of

37
00:03:17,040 --> 00:03:21,440
the world that we live in today and some really fascinating intellectual issues. It's so cool.

38
00:03:22,400 --> 00:03:26,240
Let's start from the starting point. The book's called doppelganger. Please tell us about your

39
00:03:26,240 --> 00:03:33,200
doppelganger and how it led you on this investigation. Sure. So I do have a doppelganger

40
00:03:34,000 --> 00:03:39,680
by which I mean a person who I am perennially confused and conflated with. Lots of us

41
00:03:39,680 --> 00:03:45,680
have had this experience. I would say mine is more extreme than most. There is another Naomi

42
00:03:45,680 --> 00:03:54,080
nonfiction writer of books who is close to my age and I don't know. We're both Jewish. We're both

43
00:03:54,080 --> 00:04:03,440
named Naomi and we both write books and sort of big ideas, I suppose. You're both cultural critics

44
00:04:03,440 --> 00:04:09,680
as well. Yeah. Her first book, I'm referring to Naomi Wolfe and so lots of viewers, listeners

45
00:04:09,680 --> 00:04:15,920
and viewers might not be familiar with her. She was big in the 90s. She wrote a book called

46
00:04:15,920 --> 00:04:21,440
The Beauty Myth. She worked for Al Gore when he ran for president. She was one of the most

47
00:04:21,520 --> 00:04:26,560
prominent feminists of her generation. She used to be more on the liberal left.

48
00:04:28,640 --> 00:04:32,640
This is why it became a little awkward for me to be confused with her. Now she pales around

49
00:04:32,640 --> 00:04:37,200
with Steve Bannon and Tucker Carlson and was a real vector of medical misinformation

50
00:04:37,760 --> 00:04:48,400
during the COVID-19 pandemic. I use her as a case study. We all know people who changed a lot

51
00:04:48,400 --> 00:04:52,720
during COVID. We all know people who we've scratched our heads and gone like, what happened

52
00:04:52,720 --> 00:04:58,320
to that person? Maybe it's like a public figure or maybe it's like a brother or a sister or a

53
00:04:58,320 --> 00:05:06,000
yoga instructor who suddenly is talking about QAnon. I use this experience of identity confusion

54
00:05:06,000 --> 00:05:10,080
because during the pandemic, I would go online and just there would be thousands of people

55
00:05:11,040 --> 00:05:20,960
really angry at me about things that I hadn't done. Because they saw a Naomi on TV saying

56
00:05:20,960 --> 00:05:24,800
something who looks, I mean, if you were next to each other, I could tell the difference,

57
00:05:24,800 --> 00:05:28,080
but if someone hasn't looked at you for a couple years and they see the other,

58
00:05:28,080 --> 00:05:33,600
oh, Brunette, et cetera, same age, et cetera. I always say she has much better hair than me.

59
00:05:34,160 --> 00:05:36,480
It's really important to know.

60
00:05:36,480 --> 00:05:41,120
So people are actually misattributing. Naomi Wolfe was out there saying sometimes horrible

61
00:05:41,120 --> 00:05:44,480
things and they were saying Naomi Klein said this and getting mad at you.

62
00:05:44,480 --> 00:05:49,280
Yeah. Like why is Naomi Klein saying that unvaccinated people have to stay away from

63
00:05:49,280 --> 00:05:53,920
vaccinated people because they might shed vaccine particles onto them and then not be able to have

64
00:05:53,920 --> 00:06:01,680
babies? Things like that. So in the book, I use this identity confusion, which all of us who

65
00:06:01,840 --> 00:06:07,280
have something of a public platform, I think the pandemic had a particular kind of vertigo

66
00:06:07,280 --> 00:06:13,440
because we are used to being in rooms full of other people who help tell us who we are.

67
00:06:13,440 --> 00:06:17,680
Right? Like the last thing, I canceled a book tour. I canceled all these public events.

68
00:06:18,240 --> 00:06:25,600
And so I think that, I think generally we're confused about what our social media avatars are.

69
00:06:25,600 --> 00:06:33,920
Like is that us? Is that really you? It's a sort of an approximation of you.

70
00:06:33,920 --> 00:06:38,640
Like it's a character version of you. It's a branded version of you.

71
00:06:39,840 --> 00:06:46,800
And so I think that I didn't like being confused with her because she was saying a lot of

72
00:06:46,800 --> 00:06:51,360
strange and dangerous things during COVID. But I also think that I was very confused about who

73
00:06:51,360 --> 00:06:57,280
I was during COVID because I wasn't able to do the things that tell me who I am a lot of the time.

74
00:06:57,280 --> 00:07:04,240
Right? So I used it as this kind of portal to get into the weirdness of how we are represented

75
00:07:04,240 --> 00:07:09,280
to the world through our avatars, whether we really believe that each other are real when we

76
00:07:09,280 --> 00:07:15,600
just see these avatar versions of one another. And in a way, that's like she is my doppelganger,

77
00:07:15,600 --> 00:07:22,240
but so is my Twitter avatar. Like that's not really me, whoever that person is performing me on

78
00:07:22,240 --> 00:07:28,320
Twitter. So I think we live in a doppelganger world, especially with AI, where we're not really

79
00:07:28,320 --> 00:07:36,080
sure who and what is real. And so she is a, you know, I guess a kind of a literary device to get

80
00:07:36,080 --> 00:07:40,480
at this hall of mirrors that is contemporary culture. And as soon as you start talking about

81
00:07:40,480 --> 00:07:48,000
that, the number of doppelgangers like starts multiplying in my head because you talk about,

82
00:07:48,000 --> 00:07:53,120
yeah, do you understand yourself, that Twitter avatar as part of you, there's these sort of

83
00:07:53,680 --> 00:07:58,320
strange loss of your own identity you feel when someone confuses you with another person,

84
00:07:58,320 --> 00:08:02,080
you know, when someone, whenever someone says that person looks like you, I'm like,

85
00:08:02,080 --> 00:08:06,880
that's what you think I look like. It's not what I think I look like. Like it's destabilizing just

86
00:08:06,880 --> 00:08:13,200
to be mistaken for another person. In fact, I was once told, I told, this happened to me in

87
00:08:13,200 --> 00:08:17,760
comedy 10 years ago, I told a comic I ran into that she looked like another comic and she said,

88
00:08:17,760 --> 00:08:24,320
no, I don't. And then she said, you should never tell anyone that they look like another person,

89
00:08:24,320 --> 00:08:28,160
because you don't know what the person you're talking to thinks they look like, you know,

90
00:08:28,160 --> 00:08:32,320
you don't know what their self image is and you could be violating their self image in a deep way.

91
00:08:32,320 --> 00:08:36,240
And I always took that to heart and I no longer do that. I no longer say, oh, you kind of look

92
00:08:36,240 --> 00:08:40,800
like this other person because you might be triggering some insecurity the person has or whatever.

93
00:08:41,440 --> 00:08:45,920
It can be very destabilizing to be compared to another person out there.

94
00:08:46,400 --> 00:08:51,360
But, you know, in the end, I decided to embrace it as an unconventional form of,

95
00:08:52,640 --> 00:08:58,480
you know, sort of Zen non-attachment. Because, you know, we live in a culture that is constantly

96
00:08:58,480 --> 00:09:03,520
telling us that we need to perform this perfected version of ourselves and optimize ourselves.

97
00:09:03,600 --> 00:09:08,960
And it's like, you know, it's a kind of our life raft in these extremely competitive waters.

98
00:09:08,960 --> 00:09:15,040
And there's something sort of liberating about realizing that no matter how carefully you tend

99
00:09:15,040 --> 00:09:21,120
to your personal brand and project yourself with the exact right caliber of irony and earnestness,

100
00:09:22,160 --> 00:09:27,680
if thousands of people think that you are somebody totally different, it really is just

101
00:09:27,680 --> 00:09:35,040
telling you like get over yourself, you know. And so I've decided to be grateful for my doppelganger

102
00:09:35,040 --> 00:09:44,400
and to take it as a message to just find other people, find the others, invest in community,

103
00:09:45,440 --> 00:09:49,680
not in personal perfection because people are going to think that you think wild things no

104
00:09:49,680 --> 00:09:53,280
matter what you do. I feel like you've given us the beautiful conclusion of this book at the

105
00:09:53,280 --> 00:09:57,440
beginning of the interview. So maybe we should bleep it for spoilers. I don't know. That's

106
00:09:57,440 --> 00:10:03,440
wonderful. But let's keep exploring. Something else that you said that made me think is, you know,

107
00:10:03,440 --> 00:10:08,640
when our online avatars are those us, are people seeing us when they're looking at us,

108
00:10:08,640 --> 00:10:14,000
that makes me think that when people, you know, lose that screw like Naomi Wolfe did when the

109
00:10:14,000 --> 00:10:18,080
person goes QAnon, when they go anti-vax, when our friend starts behaving in this bizarre way

110
00:10:18,880 --> 00:10:22,960
and starts accusing us of being involved in a conspiracy or seeing those around them,

111
00:10:22,960 --> 00:10:28,080
it often is. Or being a doppelganger of yourself, like stepped for people and stuff.

112
00:10:28,080 --> 00:10:34,240
Yes. Oh, you're not you anymore and they turn it away on you. Well, the pain of that is often

113
00:10:34,240 --> 00:10:40,480
that we no longer feel seen by our friend. The person somehow loses their ability to see us and

114
00:10:40,480 --> 00:10:45,280
to see, you know, when people are really going nuts on Twitter and accusing each other of being,

115
00:10:45,280 --> 00:10:49,760
you know, whatever, vaccine propagandist or whatever, they're not seeing the people they're

116
00:10:49,760 --> 00:10:54,320
talking to as people anymore. And we sort of, it seems like a very modern thing to lose our

117
00:10:54,320 --> 00:11:00,560
ability to see each other as human beings. Yeah. And I mean, it's, it's weird enough when it's

118
00:11:00,560 --> 00:11:06,800
somebody who you don't know, who clearly has you completely wrong. But what's weird as you're saying,

119
00:11:06,800 --> 00:11:11,840
and it's like, when it's somebody who does know you and is suddenly treating you like this,

120
00:11:12,480 --> 00:11:20,560
like entirely two dimensional form. Yeah. I mean, I think a lot of relationships were severed

121
00:11:20,560 --> 00:11:26,240
during during COVID because we were all really stressed out and we were confused. We were anxious.

122
00:11:26,880 --> 00:11:33,040
And so people were disinvited from family dinners and, you know, often for good reasons, you know,

123
00:11:33,040 --> 00:11:39,600
they are immunocompromised and, you know, like, like if you had immunocompromised people in your

124
00:11:39,600 --> 00:11:44,400
family, then you, and you had somebody who was not taking COVID seriously at all, you know,

125
00:11:44,400 --> 00:11:50,240
that's going to create a rift and it created rifts and countless families. But I've also heard some

126
00:11:50,240 --> 00:11:56,000
really nice stories since the book came out of people who, who said that they reached back out

127
00:11:56,000 --> 00:12:02,560
to a sister they lost touch with or, you know, another family member and realized that, you know,

128
00:12:02,560 --> 00:12:06,080
they didn't want to have all these severed connections. And maybe there, there are some

129
00:12:06,160 --> 00:12:11,520
things that they agree on. Maybe they, maybe, maybe you don't like big pharma either for different

130
00:12:11,520 --> 00:12:16,640
reasons, but you might be able to find some common ground and maybe pull them back from what I call

131
00:12:16,640 --> 00:12:24,880
the mirror world. Because, yeah, there's often a, like, you know, I write that conspiracy culture

132
00:12:24,880 --> 00:12:30,640
often gets the facts wrong, but the feelings right. And there's a, there's a way in which there's

133
00:12:30,640 --> 00:12:37,840
always a little bit of truth mixed in with the fantasy in any of the conspiracies. So,

134
00:12:38,720 --> 00:12:43,040
you know, you've got to extend some kind of a bridge where you find, maybe you find some common

135
00:12:43,040 --> 00:12:47,280
ground and give somebody an out because they might be looking for an out. There's a lot of

136
00:12:47,280 --> 00:12:52,160
grifters in there. The fact that you call it the mirror world is just, again, such an evocative

137
00:12:52,160 --> 00:13:00,160
image you found to, that really makes me think about it differently. What, so let's talk about

138
00:13:00,160 --> 00:13:05,920
what is it, do you think that pulls people into that mirror world? Because it's happened with a

139
00:13:05,920 --> 00:13:12,000
lot of events. I saw it happen a friend of mine after 2016, after the pandemic. You know, it seems

140
00:13:12,000 --> 00:13:17,520
like there are these inciting events. And what is it that, that causes this to happen to people?

141
00:13:18,240 --> 00:13:23,360
So I think human beings are creatures of narrative. We like to have stories that,

142
00:13:23,360 --> 00:13:31,680
that tell us who we are and, and where we are. And, and when you have a shock, like a major event

143
00:13:31,680 --> 00:13:38,560
that, that, that scrambles the story of who you thought you were, like 9-11, like a lot of Americans

144
00:13:39,280 --> 00:13:44,080
had no idea who these people were. And that was, that was the question like, why do they hate us?

145
00:13:44,080 --> 00:13:52,480
Like, what is this? You know, we don't do a very good job of teaching what people like geopolitics

146
00:13:52,480 --> 00:13:57,840
in high school, let alone university. So when it turns out that there's like people on the other

147
00:13:57,840 --> 00:14:03,360
side of the planet who are very angry at your country and you, you never learned why, like you

148
00:14:03,360 --> 00:14:10,560
never learned, you didn't even know they were there, right? But after 9-11, I, I wrote a piece,

149
00:14:10,560 --> 00:14:15,120
I remember, I think it was for the LA Times saying, you know, Americans woke up to realize

150
00:14:15,120 --> 00:14:20,960
they were, that they were at war only to find that they had been at war for a long time and no one

151
00:14:20,960 --> 00:14:29,920
told them, you know? So, so I think that we go looking for stories when, when, when our stories

152
00:14:29,920 --> 00:14:35,200
of self fall apart. And, and, and like, I don't know about you, but I've never lived through a

153
00:14:35,200 --> 00:14:41,440
global pandemic before. I've never been told to stay home for months before. This was new terrain.

154
00:14:41,440 --> 00:14:46,720
I've never looked up at the sky and not seen planes of Times Square empty. I mean, these were

155
00:14:46,720 --> 00:14:53,200
shocking events. And so as creatures of story, we go looking for them. And I think what really

156
00:14:53,200 --> 00:14:59,040
derailed us during COVID is that, that search for story intersected with an attention economy.

157
00:14:59,040 --> 00:15:02,240
And it's an economy that means that whoever has the most outrageous

158
00:15:02,880 --> 00:15:08,080
over-claiming story wins the clicks, wins the eyeballs. You know, science takes time.

159
00:15:08,080 --> 00:15:13,280
We were confronting a novel virus. And you had all these scientists saying like, okay, be patient.

160
00:15:13,280 --> 00:15:17,120
We have to go do our research and then we'll get back to you. And then you had a whole bunch of

161
00:15:17,120 --> 00:15:23,840
grifters just rush into that gap saying, we have the story we know come over here. And, you know,

162
00:15:23,840 --> 00:15:27,840
often they were dusting off theories that they had been using in different contexts,

163
00:15:27,840 --> 00:15:34,560
like the anti-vax movement, right? Like they had been spinning stories about childhood vaccines

164
00:15:34,560 --> 00:15:41,680
and autism, which were lies before COVID. But they just needed to kind of do a search and replace

165
00:15:42,400 --> 00:15:47,200
on the COVID vaccines. And they were good to go. Like they didn't have to, you know, so anyway,

166
00:15:47,200 --> 00:15:52,000
so that's some of it. Why do you call, how did you come up with the term the mirror world? And

167
00:15:52,000 --> 00:15:57,360
why do you think of the conspiracy theory world as being a mirror? Well, I was struck, you know,

168
00:15:57,360 --> 00:16:03,440
so I, like, I use my doppelganger as sort of my white rabbit, like in Alice in Wonderland,

169
00:16:03,440 --> 00:16:09,040
to fall down the rabbit hole and really explore the world that she is in now. Because it was either

170
00:16:09,040 --> 00:16:15,840
going to be like, just be horrified by everything she was saying, or, or actually try to understand

171
00:16:15,840 --> 00:16:21,920
like how she could have changed so much. And I'm a researcher. And this is how I understand the

172
00:16:21,920 --> 00:16:29,120
world. Like, you know, when something confounds me, I try to understand it. And so, so I started

173
00:16:29,120 --> 00:16:34,960
listening to a lot of the interviews she was doing with people like Steve Bannon. She was on

174
00:16:34,960 --> 00:16:40,320
his show almost every day for a while. So I listened to hundreds of hours of Steve Bannon's

175
00:16:40,320 --> 00:16:46,560
podcast, The War Room. Wow. And, you know, she was also on like many lesser known.

176
00:16:46,560 --> 00:16:50,240
Did you start to like the podcast after a while? Or are you like, okay, these are like my buddies

177
00:16:50,320 --> 00:16:57,920
now. You get a parasocial relationship with Steve? I admit that I got his theme song

178
00:16:57,920 --> 00:17:05,760
stuck in my head, which is like pretty catchy. It's a very weird anti-China theme song.

179
00:17:10,000 --> 00:17:16,160
But it does end with like, let's take down the CCP. And that's when I knew I was in trouble.

180
00:17:16,880 --> 00:17:21,520
When I just was like, couldn't get it out of my brain when I was doing, you know, unloading the

181
00:17:21,520 --> 00:17:29,600
dishwasher. So, so, but, but I like, I call it the mirror world because I was really struck,

182
00:17:29,600 --> 00:17:36,080
particularly listening to Bannon. One time it was, it was, I remember it was Christmas 2021.

183
00:17:36,080 --> 00:17:46,720
And he was shilling a new coin called FJB, like fuck Joe Biden. And he was just trying to

184
00:17:46,720 --> 00:17:50,800
fleece people before Christmas. He was like, get this for your relatives. And he was making

185
00:17:50,800 --> 00:17:56,160
this whole pitch about how you couldn't trust the dollar anymore. So you had to buy these coins and

186
00:17:56,160 --> 00:18:01,120
so on. Is this cryptocurrency? It wasn't exactly, it was even like, not even crypto. It was just

187
00:18:01,200 --> 00:18:06,560
like literally a coin that said fuck Joe Biden. Like just, like just we made a little, a little

188
00:18:06,560 --> 00:18:12,800
piece of metal disc that says FJB on it. Which is why I say you might be able to get some friends

189
00:18:12,800 --> 00:18:16,800
and family members back from the mirror world because there are so many drifters there, right?

190
00:18:16,800 --> 00:18:22,560
That they might be looking for some kind of help. It's so they're getting fleeced non-stop, right?

191
00:18:23,680 --> 00:18:30,720
Right. You know, send that lifeline, see what happens. But, but as he was making his pitch,

192
00:18:31,600 --> 00:18:36,480
his pre-Christmas pitch, he was saying, you know, we need to have, this is why we need to have our

193
00:18:36,480 --> 00:18:41,680
own money and we need to have our own publishing companies and we need to have our own social

194
00:18:41,680 --> 00:18:47,920
media platforms because we will never cancel you. We will never other you. You'll always be welcome

195
00:18:47,920 --> 00:18:54,960
here. And so, and he was really talking about a one to one, like, you know, get kicked off Twitter,

196
00:18:54,960 --> 00:19:00,160
you can join Getter, which they call themselves the Twitter killer. You know, get kicked off

197
00:19:00,160 --> 00:19:05,920
YouTube, you can join Rumble and so on. And there was, there was like an exact mirror of everything,

198
00:19:05,920 --> 00:19:11,520
like in the world that I lived in. And I was just really struck that most of the people who I know

199
00:19:11,520 --> 00:19:16,880
and hang out with have no idea this world like fully exists. And they actually think that when

200
00:19:16,880 --> 00:19:21,200
somebody gets kicked off the social media that site that they're on that they almost like have been

201
00:19:21,200 --> 00:19:27,040
deleted from planet Earth. And it's so strangely arrogant because actually they're really good

202
00:19:27,120 --> 00:19:33,600
at this. And they are building massive platforms and they're reaching lots of people. And, and

203
00:19:33,600 --> 00:19:37,600
that's, you know, that's why I pay attention to them. They're a major political force, you know.

204
00:19:37,600 --> 00:19:40,320
Steve Bannon is a strategist. He's trying to get back into power.

205
00:19:41,040 --> 00:19:44,640
And these are happening on the public internet. They're not, it's not the dark web. It's like,

206
00:19:44,640 --> 00:19:50,720
you can just go to these websites and look at this stuff. How do you, you know, I know you

207
00:19:50,720 --> 00:19:56,560
tracked Naomi Wolf's progress through the book. How did she fall into this? Because it's, it's a very

208
00:19:57,440 --> 00:20:01,600
even if it weren't for the connection to you, it's a very strange story.

209
00:20:01,600 --> 00:20:07,840
Yeah, it's a strange story because she was such a prominent liberal, such a prominent Democrat,

210
00:20:07,840 --> 00:20:15,120
feminist. How did she fall into it? You know, I have an, I have an equation in the book that might

211
00:20:15,120 --> 00:20:21,440
be useful because I think there's a lot of people who have, who have changed as we, as discussed,

212
00:20:22,240 --> 00:20:33,520
which is social media slash grandiosity plus social media addiction. Many of, I think pretty

213
00:20:33,520 --> 00:20:42,880
much anybody who we might be thinking of spends way too much time online. And plus midlife crisis

214
00:20:44,880 --> 00:20:50,960
divided by public shaming equals right wing meltdown. So I want to talk a bit about the

215
00:20:50,960 --> 00:20:55,680
public shaving piece of it because I, you know, I think one of the big drivers for her is that

216
00:20:55,680 --> 00:21:03,600
she's one of these people who became a spectacle for liberal left Twitter. And that's because she

217
00:21:03,600 --> 00:21:09,520
made a foundational error in a book that she published in 2019. And this error was discovered

218
00:21:09,520 --> 00:21:16,080
live on BBC radio. It's every writer's worst nightmare. I mean, I, I sort of remember this

219
00:21:16,080 --> 00:21:20,000
as a viral moment. And I didn't, I honestly did not really know who she was or really follow her

220
00:21:20,000 --> 00:21:24,000
that much, but I, I sort of remember this. What was the error that was discovered?

221
00:21:24,000 --> 00:21:29,920
So she wrote a book called Outrageous. It came out, you know, a few months before the pandemic.

222
00:21:31,040 --> 00:21:38,000
And it was a, it was a, it was a historical work. It was actually her PhD thesis. And it told,

223
00:21:40,480 --> 00:21:47,680
what she, during this interview, she, she made this claim that gay men had been executed

224
00:21:48,560 --> 00:21:55,920
for sodomy long after it was like people thought that they stopped sentencing people to death

225
00:21:55,920 --> 00:22:02,400
for being gay. And what happened in the BBC interviewer pointed out that she had misread

226
00:22:02,400 --> 00:22:07,520
the historical record. And he said, like in a very polite British way, like, it's just the

227
00:22:07,520 --> 00:22:11,520
thing is, is that I think you misunderstood. And then he explained that, and then the bottom

228
00:22:11,520 --> 00:22:17,120
falls out of her entire book. And she, and it turns out that those men had actually been released.

229
00:22:18,080 --> 00:22:25,040
She misunderstood a term called death recorded, which is what she thought was a death sentence,

230
00:22:25,040 --> 00:22:31,840
but it isn't. And so that was just a journalist doing his job. You know, he fact-checked a book

231
00:22:31,840 --> 00:22:35,440
that should have been fact-checked by the author and the publisher and found a massive error.

232
00:22:36,080 --> 00:22:43,840
But then she becomes a meme, you know, then, then people just cannot get enough of this.

233
00:22:44,800 --> 00:22:48,640
And why does she become a meme? Because the, you know, this sounds like

234
00:22:49,360 --> 00:22:52,640
an error is an error. That's embarrassing. Maybe people have a little bit of fun,

235
00:22:52,640 --> 00:22:56,080
but there has to be something deeper going on for people to really go in on that.

236
00:22:56,080 --> 00:23:04,320
You know, I think not really. I mean, I think she was, she was, she was enough of a big deal,

237
00:23:05,200 --> 00:23:07,920
you know, enough of a, you know, New York Times bestselling author

238
00:23:08,880 --> 00:23:14,720
that to watch this happen live on the air. It was just one of those moments where,

239
00:23:14,720 --> 00:23:18,560
because it would be your worst nightmare, and there's a lot of writers on Twitter,

240
00:23:18,560 --> 00:23:22,880
the idea that you could point and laugh at it happening to somebody else somehow made you feel

241
00:23:22,880 --> 00:23:30,160
safer. And, but also she had been dabbling in conspiracy culture, you know, before that,

242
00:23:30,160 --> 00:23:35,280
you know, she had made, she did things like they took pictures of clouds and speculated about

243
00:23:35,280 --> 00:23:42,000
government, you know, yeah, you know, chemtrails and things like that. You know,

244
00:23:42,000 --> 00:23:47,680
she was a bit of a cloud truther. She's, you know, just a little, just a little spot of cloud

245
00:23:47,680 --> 00:23:51,600
truth, just like you're hanging out with her and she might go, Hey, clouds are fake, you know,

246
00:23:51,600 --> 00:23:55,120
and you're like, Oh, well, that was weird that Naomi just sort of tossed that on me. But other

247
00:23:55,120 --> 00:23:58,800
than that, she's pretty nice. Just a bit of a cloud truth of truth. I mean, I think she thinks

248
00:23:58,800 --> 00:24:07,520
birds are real. I'm not sure. So, so, but because there was a little bit of a reservoir of annoyance

249
00:24:07,520 --> 00:24:11,520
with her already online, because she was dabbling in other conspiracy theories, that's why people,

250
00:24:11,520 --> 00:24:16,560
part of why people really went in, it sounds like. Yeah. And then during COVID, I think she was,

251
00:24:16,560 --> 00:24:23,120
we were all bored and at home, and she was like, just endlessly sharing wild theories, like, you

252
00:24:23,120 --> 00:24:28,320
know, like she, she'd, you'd log online and you know, she had like, you know, almost 200,000

253
00:24:28,320 --> 00:24:33,280
followers, you know, it's not like she's like, it didn't have reach. She has many more now.

254
00:24:34,320 --> 00:24:39,200
But she, you know, she'd say that she thinks that children were losing the ability to smile

255
00:24:39,200 --> 00:24:43,120
because they were wearing masks, you know, and then that would be days of entertainment,

256
00:24:43,120 --> 00:24:49,360
things like that. You know, there was a lot about vaccine shedding onto unvaccinated people.

257
00:24:49,760 --> 00:24:57,200
And I mean, but, but I call her a conspiracy influencer, not a conspiracy theorist, because

258
00:24:57,200 --> 00:25:04,160
there are often these glaring contradictions in the claims. Like, you know, for a while, she was

259
00:25:04,160 --> 00:25:14,400
talking about how COVID was a bot, maybe had been cooked up as a bio weapon. But then she was like,

260
00:25:14,480 --> 00:25:19,120
but why wear masks? You know, like, and it's just, it just seems like a bit of a contradiction

261
00:25:19,120 --> 00:25:25,840
there. Like, you know, if it's a bio weapon, surely you should try not to, not to get it, you

262
00:25:25,840 --> 00:25:32,720
know, she's like, so she's an influence. You should be worried about it. Contradicts the

263
00:25:32,720 --> 00:25:38,480
idea that it's not that big a deal. Yeah. So the, the, the story is constantly changing with whatever

264
00:25:38,480 --> 00:25:42,240
is going to get more clicks. So if everyone's supposed to get vaccinated, now the vaccines

265
00:25:42,240 --> 00:25:46,320
are a bio weapon. If everyone's supposed to get an app on their phone to see if they got

266
00:25:46,320 --> 00:25:50,000
vaccinated, well, it's not about the vaccine. It's the app. The app can listen to your phone

267
00:25:50,000 --> 00:25:55,600
conversations and things like that. But this is what I mean about how they often get the feeling

268
00:25:55,600 --> 00:26:00,720
right and the facts wrong is that, you know, that's where she really took a star turn on the right

269
00:26:00,720 --> 00:26:06,320
was when she started talking about those vaccine verification apps, being a covert surveillance

270
00:26:07,040 --> 00:26:15,680
plan. So the truth is like, like people are very anxious about surveillance. They're very anxious

271
00:26:15,680 --> 00:26:19,600
about what happens with their data. They're anxious about their cell phones. They don't really

272
00:26:19,600 --> 00:26:24,480
under, we don't really understand, you know, what is known about our movements, you know,

273
00:26:25,520 --> 00:26:32,720
and so she projected all of our collective surveillance fears onto this one app. But the

274
00:26:32,800 --> 00:26:37,200
response on liberal Twitter was, wait, oh, they hear about cell phones, which is kind of funny,

275
00:26:37,200 --> 00:26:42,240
right? But it's, but the assumption behind that joke is that we all know that our cell phones

276
00:26:42,240 --> 00:26:46,880
are listening to us and we're okay with it. But the thing is, people seem not to be okay with it,

277
00:26:46,880 --> 00:26:52,320
right? So this is part of the appeal of conspiracy culture is that, you know,

278
00:26:52,320 --> 00:26:56,080
they're telling a very simple story. Like if we can just get rid of these apps, then everything

279
00:26:56,080 --> 00:27:00,720
will be fine and nobody will be able to track you anymore, right? Or the vaccines or whatever

280
00:27:00,720 --> 00:27:06,880
is the kind of boogeyman of surveillance, whereas we actually need policy responses

281
00:27:06,880 --> 00:27:11,120
so that we can control these tech companies and they're not able to mine our data endlessly and

282
00:27:11,120 --> 00:27:16,240
create more doppelgangers like AI versions of us and so on. Right. The story with a grain of truth,

283
00:27:16,240 --> 00:27:23,680
but with a much simpler solution and you can apply it to almost anything. Now, often when someone

284
00:27:23,680 --> 00:27:29,040
is a conspiracy influencer like this, there'll be this implication that people will say, oh,

285
00:27:29,040 --> 00:27:34,240
they're a grifter and a grifter generally means someone who doesn't believe anything that they say.

286
00:27:34,240 --> 00:27:38,160
They're just trying to get the clicks. They're harvesting clicks. They're like following the

287
00:27:38,160 --> 00:27:44,160
audience. Did you feel that that was the case in her case? Was she a complete cynic about it? Or

288
00:27:44,160 --> 00:27:48,960
do you think she was believing these things and was just not able to sort of connect the dots

289
00:27:48,960 --> 00:27:55,360
that they were self contradictory? It's very hard for me to know what she believes, right? And I

290
00:27:55,360 --> 00:28:01,360
think that a lot of people who really go all in with conspiracy culture aren't completely cynical.

291
00:28:01,360 --> 00:28:09,520
They have to convince themselves of some of it on some level. But that doesn't mean that the primary

292
00:28:09,520 --> 00:28:17,200
impulse isn't grifting, isn't ego, isn't getting people to treat you like a savant or whatever.

293
00:28:18,080 --> 00:28:22,000
I think she gets a lot out of this, I guess is what I'm saying. I think she lost a lot

294
00:28:22,320 --> 00:28:29,840
in the world that she used to travel in. She could no longer get published. After that error on BBC,

295
00:28:29,840 --> 00:28:36,240
her publisher dropped her, dumped her book. So she had every reason to move to a new market

296
00:28:36,880 --> 00:28:43,920
that is very large. Tucker Carlson, when he had her on Fox, he was getting 3 million viewers a

297
00:28:43,920 --> 00:28:51,760
night. There's no show on the left that she had access to that could go near that. So there's

298
00:28:51,760 --> 00:29:00,080
every reason. So I don't know what she believes, but I do know that a lot of people who follow this

299
00:29:00,080 --> 00:29:05,760
are not just grifting, right? The only reason the grift is successful if it's a grift is because

300
00:29:05,760 --> 00:29:12,000
there are lots of customers who sincerely are listening to Steve Bannon and Naomi Wolfe and

301
00:29:12,000 --> 00:29:19,920
RFK Jr. and believe it, or else it's not a good grift. You don't have customers. So it's worrying

302
00:29:19,920 --> 00:29:28,080
because they're using such apocalyptic language. And if you really are in this battle for humanity

303
00:29:28,080 --> 00:29:34,720
against a genocide, that's the kind of language that she uses, good and evil. She's claimed that

304
00:29:34,720 --> 00:29:41,040
there is a genocide that has happened because of these vaccines. I think that it, and she also

305
00:29:41,040 --> 00:29:46,320
takes pictures of her new gun and says we're at war and post-pictures of her husband doing target

306
00:29:46,320 --> 00:29:53,200
practice. So this doesn't end well, I guess is what I'm saying. If you're telling people they are

307
00:29:53,200 --> 00:29:58,480
fighting a genocide for good and evil, I think they might take you at your word, whether you're

308
00:29:58,480 --> 00:30:03,120
grifting or not, and they might decide to do something about it. And we're seeing lots of

309
00:30:03,120 --> 00:30:08,000
examples of that actually. We absolutely are. Well, we have to take a really quick break. When we

310
00:30:08,000 --> 00:30:12,160
come back, I want to ask you more about how this has changed your own interaction with your online

311
00:30:12,480 --> 00:30:16,320
editing. We'll be right back with more Naomi Klein. You know, the year is never more hectic

312
00:30:16,320 --> 00:30:20,240
than during the holiday season with all those travel plans, work projects, wrapping up. And

313
00:30:20,240 --> 00:30:23,920
if you run a household, it's sometimes even hard to remember what's for dinner or if anyone's

314
00:30:23,920 --> 00:30:28,160
remembered to feed the dog. If this sounds like your home or the home of someone you know,

315
00:30:28,160 --> 00:30:32,480
this holiday season is the time for the gift of organization with the skylight calendar.

316
00:30:32,480 --> 00:30:36,720
The skylight calendar is a smart touchscreen calendar and organizer for all of your chores,

317
00:30:36,720 --> 00:30:41,040
groceries, and to-dos. It automatically syncs all of the different digital calendars and events

318
00:30:41,040 --> 00:30:46,160
your family uses and shows them all together on one beautiful touchscreen display. Skylight

319
00:30:46,160 --> 00:30:51,200
calendar is the best way to give your family peace of mind to enjoy the things that matter most.

320
00:30:51,200 --> 00:30:55,680
It works by syncing events from already existing calendars you have, including Google,

321
00:30:55,680 --> 00:30:59,680
Outlook, and Apple calendars. You can also add events directly using the touchscreen

322
00:30:59,680 --> 00:31:05,120
or with the free skylight mobile app. And it shows all family events together in one spot

323
00:31:05,120 --> 00:31:09,920
so you can see what everyone has going on each week. Families are more likely to actually check

324
00:31:09,920 --> 00:31:15,040
it since it's always up to date and so they don't question mom every day about schedules.

325
00:31:15,040 --> 00:31:19,840
And additional fun features include dinner planning, grocery list, daily weather display,

326
00:31:19,840 --> 00:31:24,320
and weather forecast based on the address of your events. And plus, when it's not in use,

327
00:31:24,320 --> 00:31:30,080
you can even turn it into a digital picture frame. And get this, as a special limited time offer for

328
00:31:30,080 --> 00:31:35,680
our listeners, you can get $15 off your purchase of a skylight calendar when you go to skylightcal.com

329
00:31:35,680 --> 00:31:41,360
slash factually. To get $15 off your purchase of a skylight calendar, just go to skylightcal.com

330
00:31:41,360 --> 00:31:48,080
slash factually. That's S-K-Y-L-I-G-H-T-C-A-L dot com slash factually.

331
00:31:48,080 --> 00:31:51,680
Okay, we're back with Naomi Klein talking about online conspiracy theories,

332
00:31:51,680 --> 00:31:56,720
the mirror world, doppelgangers. You had this really intriguing idea at the top of the interview

333
00:31:56,720 --> 00:32:02,320
about how it made you think about how your own online identity is in some ways a doppelganger.

334
00:32:02,320 --> 00:32:07,760
Can you please get into that for us? So, I think when we create an online

335
00:32:08,560 --> 00:32:12,640
version of ourselves, when we choose the picture that's going to be our avatar,

336
00:32:12,640 --> 00:32:19,920
when we write that sort of like kind of satirical bio, like we are creating a brand.

337
00:32:21,040 --> 00:32:30,960
And what is a brand? A brand is a thing version of you, of me. And this is actually

338
00:32:31,680 --> 00:32:37,600
the first book I wrote when I was in my 20s was a book called No Logo. And it was about the rise

339
00:32:37,600 --> 00:32:45,600
of this idea that companies should first and foremost most be selling an idea, a brand,

340
00:32:45,600 --> 00:32:50,160
not that the product was incidental, which was an idea that took root in corporate culture in

341
00:32:50,160 --> 00:32:56,240
the 90s, but also that individual celebrities like the first person who called himself,

342
00:32:56,240 --> 00:33:03,440
whose agent called him a super brand was Michael Jordan. And he was a mega corporation.

343
00:33:04,400 --> 00:33:12,000
And there were others, there was Richard Branson and Oprah, of course. But the idea that regular

344
00:33:12,000 --> 00:33:18,880
people could be brands was not possible at that stage, even though there were kind of management

345
00:33:18,880 --> 00:33:22,800
consultants saying this is the future and you're not going to get a job, you're just going to have

346
00:33:22,800 --> 00:33:28,000
a series of contracts. But if you really want to get ahead, you need to create a brand. And so

347
00:33:30,160 --> 00:33:36,800
that didn't become a reality until social media put advertising agencies into all of our back

348
00:33:36,800 --> 00:33:45,280
pockets, right? Because suddenly you two can do this for free, like for the price of your phone.

349
00:33:46,240 --> 00:33:52,000
And what I'm trying to do in the book is look at it with a little bit of

350
00:33:53,360 --> 00:34:00,800
distance, because I think people are often called out for being performative and being

351
00:34:00,800 --> 00:34:08,400
inauthentic online and so on. This is like the ultimate smear is like you're just performing,

352
00:34:08,400 --> 00:34:13,840
but we're all just performing. And the reason we're doing it is because we have all received

353
00:34:13,840 --> 00:34:21,360
this message that the perfected performed self, the brand itself, is really our only hope of

354
00:34:21,360 --> 00:34:32,000
survival in these incredibly competitive, shark-fist-laden waters. So yeah, I think we should

355
00:34:32,000 --> 00:34:36,720
treat ourselves with a little bit of compassion and thinking about why we build these doppelgangers

356
00:34:36,720 --> 00:34:43,200
of ourselves. But a brand is a thing, like humans are not meant to be brands. We've accepted the

357
00:34:43,200 --> 00:34:48,320
logic and we're all doing it. And that's why we think we all need to issue press statements

358
00:34:48,320 --> 00:34:54,800
whenever anything terrible happens in the world. Right. That is where I went as well, because

359
00:34:54,800 --> 00:35:00,480
there's a lot of that happening right now with people saying, you need to post about this. You

360
00:35:00,480 --> 00:35:05,040
need to post. You need to speak up. And it's at that moment that the distance between... You don't,

361
00:35:05,040 --> 00:35:10,320
by the way. Do you don't. Thank you. I agree. I don't think anyone can force you to post,

362
00:35:10,320 --> 00:35:14,720
and I don't think that posting is good by itself. Posting can be something, but it's not...

363
00:35:14,720 --> 00:35:19,120
And people will try to shame you into it. Your silence is its own statement and so on.

364
00:35:19,120 --> 00:35:24,880
And they're just performing themselves, like that version, whoever those people are who are

365
00:35:24,880 --> 00:35:30,080
calling you out for not having issued a press statement about the Middle East.

366
00:35:32,000 --> 00:35:37,280
Like unless you are a politician, unless you are a public person with some kind of record,

367
00:35:37,280 --> 00:35:41,280
you don't owe that to the world. I think you should read. You should become

368
00:35:43,120 --> 00:35:49,200
literate about these issues that are going to impact all of us. But if this is not your area,

369
00:35:49,200 --> 00:35:55,360
you do not owe anybody that sort of us versus them performance.

370
00:35:55,360 --> 00:36:00,480
Correct. And I felt that really strongly... Well, it made me think about the distance

371
00:36:00,480 --> 00:36:06,960
between my brand and my personal self, because I have a large social media presence.

372
00:36:06,960 --> 00:36:11,040
There are things that I post about a lot. What I don't post about international affairs,

373
00:36:11,040 --> 00:36:17,760
that's not part of my brand. Now, as a person, I have a responsibility to check in on my friends

374
00:36:17,760 --> 00:36:22,400
who are affected to learn as much as I can to try to, et cetera, et cetera. But there's a big

375
00:36:23,360 --> 00:36:27,600
gap there. And I really was really feeling the gap over those last couple of weeks.

376
00:36:27,600 --> 00:36:31,760
Yeah. And I think people feel... You start to feel like somebody's keeping track.

377
00:36:31,840 --> 00:36:36,640
Like there's some list somewhere that's keeping track of everybody who has said

378
00:36:36,640 --> 00:36:40,400
something, everyone who has said nothing, and we don't want to be on the wrong list.

379
00:36:40,400 --> 00:36:46,080
Wait it out is all I can say. Just wait it out. And certainly don't say anything if you don't

380
00:36:46,080 --> 00:36:54,400
know what you're talking about. But the point about this idea of that a brand is a thing version

381
00:36:54,400 --> 00:37:01,680
of you is a bad way to be human. I have studied what it means to be a good

382
00:37:01,840 --> 00:37:06,960
brand. And what it means to be a good brand is to repeat yourself endlessly and have

383
00:37:06,960 --> 00:37:12,640
extreme message discipline. So if you are a good brand as a human being, you are incredibly boring.

384
00:37:13,520 --> 00:37:19,360
You do not evolve. And you basically are just like a dog chasing its own tail for the rest of your

385
00:37:19,360 --> 00:37:24,240
life. You're just Nike. You say, just do it. Just do it. Just do it. Just do it over and over again.

386
00:37:24,240 --> 00:37:27,680
Yeah. Yeah. Just change the celebrity, keep the slogan.

387
00:37:28,640 --> 00:37:36,560
Yeah. Good branding is all about discipline. And that may work for Nike, but it is

388
00:37:37,360 --> 00:37:43,280
really not what one should look for in our attempts to be human, which is to actually evolve and

389
00:37:43,280 --> 00:37:52,240
learn from our experiences and reserve the right to change. And it's interesting because it relates

390
00:37:52,240 --> 00:38:00,160
to AI because I think the more formulaic we are as people, as artists, as creators of any kind,

391
00:38:00,160 --> 00:38:06,960
the easier we are to make a doppelganger of us by AI because AI studies formulas,

392
00:38:06,960 --> 00:38:13,680
as you got to keep some machines guessing. Be a bad brand. Break their own formula.

393
00:38:13,680 --> 00:38:19,680
But I also think it relates to the cruelty, you know, because a brand is not a human. A brand

394
00:38:19,680 --> 00:38:26,640
is a thing. And I think that when we're all out there performing thing versions of ourselves,

395
00:38:27,520 --> 00:38:33,600
we start to forget that each other are humans. And then we start to throw very sharp things at one

396
00:38:33,600 --> 00:38:38,640
another. And then we're surprised when we hurt each other because things don't bleed, right?

397
00:38:38,640 --> 00:38:42,720
You can just, you can hurl anything you want at Nike. That'll be fine.

398
00:38:42,720 --> 00:38:47,120
Do you feel that you've created a brand for yourself? Is that, did you say, oh, wait,

399
00:38:47,120 --> 00:38:52,640
hold on. I am a brand in a way that I'm no longer comfortable with as you were looking into this?

400
00:38:52,640 --> 00:38:56,720
Yeah. I mean, this was a question that came up for me pretty early because my first book,

401
00:38:56,720 --> 00:39:05,040
I got really, really fortunate with my first book. And NoLogo became a brand in the world. And it

402
00:39:05,040 --> 00:39:12,240
was very awkward because it was this anti-branding book that suddenly, like, there's a NoLogo craft

403
00:39:12,240 --> 00:39:18,880
beer in England. There's, there was a whole line of Italian sundries, including some very

404
00:39:18,880 --> 00:39:24,880
good olive oil in Italy called NoLogo. And then there was like a restaurant in Geneva called

405
00:39:24,880 --> 00:39:30,160
NoLogo, which I went into. I was like, wow, there's a NoLogo restaurant. And I went in and I

406
00:39:30,160 --> 00:39:35,040
introduced myself to the owner who ran away. He was so panicked that I was going to stew over

407
00:39:35,040 --> 00:39:41,760
something that I had decided not to trademark it because I thought that that compromised my ethics.

408
00:39:41,760 --> 00:39:45,280
Anyway, I was like, in my 20s, I could have gotten so rich.

409
00:39:47,920 --> 00:39:51,760
Well, yeah, it became a meme, NoLogo. It was everywhere.

410
00:39:51,760 --> 00:39:57,920
Yeah. So I, you know, I was confronted with this tension early on of like, okay, so even if I didn't

411
00:39:57,920 --> 00:40:02,640
want to be a brand, but I did sort of want to be a brand. And then I just realized it got way

412
00:40:02,640 --> 00:40:07,760
beyond my control. So I just decided to try to become a bad brand. And then the next, for me,

413
00:40:07,760 --> 00:40:13,920
what that meant was not writing that marketing for another 20 years. So I, you know, my next books,

414
00:40:13,920 --> 00:40:22,800
my next books were really not sequels to NoLogo, the shock doctrine, and this changes everything.

415
00:40:22,800 --> 00:40:28,240
They were, you know, I just, because I thought to be a good researcher, to be a good investigative

416
00:40:28,240 --> 00:40:33,440
journalist, I have to follow my, I have to follow the research and not just chase my tail.

417
00:40:33,440 --> 00:40:37,360
And it was very clear to me that some writers just write the same book over and over again

418
00:40:37,360 --> 00:40:41,680
and slightly change the title. I mean, they're franchises. It's very popular. But to me,

419
00:40:42,720 --> 00:40:47,040
it was never really an option because I don't have the discipline to write about things that

420
00:40:47,040 --> 00:40:52,640
are not interesting to me. Like, I'm too lazy for that, you know, it has to interest me.

421
00:40:53,600 --> 00:40:59,280
I have to not understand it and have this desire to understand it to keep me working.

422
00:40:59,280 --> 00:41:03,200
And the thing about being a good branded author is you've already figured out the formula and then

423
00:41:03,200 --> 00:41:08,800
you just have to repeat it. But to me, writing is too hard to do that, you know? Like, if I'm not

424
00:41:08,800 --> 00:41:15,520
in a process of discovery, I will just watch television, you know? So it wasn't so much like

425
00:41:15,520 --> 00:41:20,000
that I was so pure. It was truly not an option for me. I mean, I guess I could have,

426
00:41:20,000 --> 00:41:22,800
now I could have hired an AI to write those books for me.

427
00:41:22,800 --> 00:41:27,600
Well, it seems like you also, you had an urge to resist it, which I deal with that in my own work.

428
00:41:27,600 --> 00:41:31,920
I have my pet topics I return to again and again, anyone who listens to this show knows

429
00:41:31,920 --> 00:41:37,600
what they are. I don't need to list them. But then, you know, I have an urge to get away from

430
00:41:37,600 --> 00:41:41,680
that and do something new. But then the problem is, well, how do you sell that? Because people

431
00:41:41,680 --> 00:41:48,080
know you for the thing that you just did, right? People know you for that. And so maybe they want

432
00:41:48,080 --> 00:41:51,920
more of it. I mean, even this book seems very different that it starts from such a place of

433
00:41:51,920 --> 00:41:54,880
personal history of like, hey, this weird thing happened to me compared to...

434
00:41:54,880 --> 00:42:00,800
Yeah. Well, I think any kind of success is always going to create its own trap, right? I mean,

435
00:42:00,800 --> 00:42:06,480
that's like Dylan, you know, going electric. Like, people didn't want that from him. And

436
00:42:06,480 --> 00:42:15,920
then that's why he had to do it, you know? So, but with this book, I, it was similar in the sense

437
00:42:16,000 --> 00:42:23,280
that I couldn't bring myself to write a conventional nonfiction book again, because I had lost faith

438
00:42:23,840 --> 00:42:32,720
that argument changed minds. I had lost faith in the concept of a linear nonfiction argument

439
00:42:32,720 --> 00:42:39,520
based book. Life was just getting too weird. And so I just thought, well, maybe I can write in a

440
00:42:39,520 --> 00:42:43,760
complete, in a really different way. And, you know, this book is much straight, it's weirder,

441
00:42:43,760 --> 00:42:48,800
but we live in weirder times. And it uses my own double to, to go into a hall of mirrors. And I

442
00:42:48,800 --> 00:42:54,800
think that if I had tried to write about this, the weirdness of now, as if I was outside of it,

443
00:42:54,800 --> 00:42:58,960
and just be like, I'm now going to make an argument about doppelgangers.

444
00:42:58,960 --> 00:43:04,640
No, no, who would want to read that? Like, what's fun is to read about a hurricane from inside its

445
00:43:04,640 --> 00:43:12,320
eye, you know? Oh, I love that. I love that. And to explore, yeah, what does this, what does this

446
00:43:12,320 --> 00:43:17,520
mean? What does this word mean? And to explore the hall of mirrors from inside the hall of mirrors,

447
00:43:17,520 --> 00:43:21,920
like to join you right there and to like try to get out, try to get out, you know,

448
00:43:22,880 --> 00:43:29,520
but you got to start inside. Do you have any belief that that project can change minds more

449
00:43:29,520 --> 00:43:36,720
than the linear argumentative essay can? You know, I have found that like I've, I've, I have

450
00:43:37,600 --> 00:43:46,080
received so many really beautiful responses to this book of people who are grateful to have a kind

451
00:43:46,080 --> 00:43:54,000
of a map of, you know, this dynamic with the mirror world where we're defining ourselves against

452
00:43:54,000 --> 00:44:01,200
one another and projecting everything we can't stand about ourselves onto them, you know,

453
00:44:01,200 --> 00:44:08,960
and then feeling pure because we are not them. And, you know, I think, you know, even something,

454
00:44:08,960 --> 00:44:14,960
having a term like the mirror world, I have found like all a writer can do, I always see my role,

455
00:44:14,960 --> 00:44:22,560
it's it as helping people read the news better. I know this as a sort of a strange like a job

456
00:44:22,560 --> 00:44:29,040
I've assigned, but to myself, but like, I don't, I don't have grand ambitions about what books can

457
00:44:29,040 --> 00:44:36,320
do on their own. But I do think that that we can provide a little bit of orientation and some

458
00:44:36,320 --> 00:44:42,720
language, right? Like, like with a shock doctrine, I gave people some terms to describe what happens

459
00:44:42,720 --> 00:44:47,440
when we're in a state of shock, and people try to take advantage of it. They try to push through a

460
00:44:47,440 --> 00:44:52,160
preexisting wish list, right? And so whenever there's a disaster, people, I start hearing people say,

461
00:44:52,160 --> 00:44:56,960
well, it's, it's the shock doctrine, it's they're, they're doing disaster capitalism. And I think,

462
00:44:56,960 --> 00:45:03,520
okay, I helped people just get oriented a little more quickly. It's not nothing, you know, like,

463
00:45:03,520 --> 00:45:08,880
I, yeah, that's, that's all I can do. I think there are more, there's more that we can do

464
00:45:08,880 --> 00:45:14,640
that are not books that mostly involve organizing with one another in the real world.

465
00:45:14,640 --> 00:45:20,960
Yeah. Well, but to create a piece of language that can help people understand the world more

466
00:45:20,960 --> 00:45:25,920
quickly is a powerful thing to do. It's as you say, it's maybe a small contribution in the,

467
00:45:26,000 --> 00:45:32,240
in the overall world of language, right, or, or of our concepts, but it, it does give people

468
00:45:32,800 --> 00:45:38,960
a new verb almost a new way of, of relating. I want to return to that point of organizing,

469
00:45:38,960 --> 00:45:45,920
because I obviously believe that strongly as well. But the online world, I'm curious how you

470
00:45:46,480 --> 00:45:52,560
feel about it, because there's a, there's a, just a little aside early in the book,

471
00:45:52,560 --> 00:45:58,000
where you say something like, oh, I dismissed that as happening just online and not in the

472
00:45:58,000 --> 00:46:02,720
real world. You know, I was so naive back then we were all naive enough to still say things like

473
00:46:02,720 --> 00:46:09,760
that. And what's weird to me is I lately have found myself saying, oh, that's just happening online

474
00:46:09,760 --> 00:46:15,280
more. You know, I've, I've been on the internet my entire life, literally since I was, you know,

475
00:46:15,280 --> 00:46:21,440
very young, I was obsessed with the internet with the computer world and like dwelled there.

476
00:46:21,440 --> 00:46:26,480
And now over the last couple of years, I've been like, I want to be on the computer as little as

477
00:46:26,480 --> 00:46:31,600
possible. I want to go look at a fucking tree. I want to go like, you know, be, do comedy with

478
00:46:31,600 --> 00:46:35,760
people in a room. I want to meet people face to face. I like, I hate zoom meetings. I want to,

479
00:46:35,760 --> 00:46:41,040
like, I will go 45 minutes to meet you in person, you know, that's just been my own,

480
00:46:42,720 --> 00:46:48,160
my own orientation. And yet we do at the same time live in a world where you can't say, oh,

481
00:46:48,160 --> 00:46:52,560
that's just Twitter or you can't. I'm not sure. How do you feel about it?

482
00:46:53,760 --> 00:47:03,840
I mean, I think like you, I am drawn to the real to the embodied spaces. You know, I live in an

483
00:47:03,840 --> 00:47:10,800
incredibly beautiful part of the world in in coastal British Columbia, where there are many

484
00:47:10,800 --> 00:47:20,640
trees to spend time with. And you know, it is really literally grounding. And I don't think

485
00:47:20,640 --> 00:47:26,240
that I could do the kind of work that I do if I wasn't able to balance it out with a hike in the

486
00:47:26,240 --> 00:47:35,840
forest or some time on the water. And since this book came out, like being in rooms full of other

487
00:47:35,840 --> 00:47:42,640
people has felt incredibly nourishing after so much time away. And I think this is how we keep

488
00:47:42,640 --> 00:47:50,240
each other sane in these in these very vertiginous times. We are creatures of narrative, like I

489
00:47:50,240 --> 00:47:55,520
said, and we we do that work together, you know, we make sense of the world together. And I don't

490
00:47:55,520 --> 00:48:00,080
think we can do it just in a zoom meeting. I think there's something irreplaceable about doing it

491
00:48:00,160 --> 00:48:08,640
with one another. And so I the way I try to use social media is as a way to get people off social

492
00:48:08,640 --> 00:48:17,280
media. So like, come on over, you know, yeah, join the picket line and, you know, and, and, and go to

493
00:48:17,280 --> 00:48:23,440
the rally and come to this meeting and come to this event and go to this concert and read this

494
00:48:23,440 --> 00:48:30,160
book, you know, and, you know, get wherever the work is deeper than whatever the little box Elon

495
00:48:30,160 --> 00:48:36,560
Musk has given us, you know, whatever that little box is or Mark Zuckerberg. So when I see a lot of

496
00:48:36,560 --> 00:48:42,560
people using it in that way, right, to bring us to more to to more deeper work that more fully

497
00:48:42,560 --> 00:48:48,080
represents us whatever that is. And sometimes it'll be embodied with one another. And sometimes it'll

498
00:48:48,080 --> 00:48:58,560
be, you know, just offline. So that's the way I tend to relate to it. I really like that. I, you

499
00:48:58,560 --> 00:49:02,720
know, I became well known over the past year for posting from the Writers Guild picket line quite

500
00:49:02,720 --> 00:49:08,800
often. And I was that was to me a very beneficial use of social media because people became connected

501
00:49:08,800 --> 00:49:13,040
to our struggle and they were able to offer support and and just telling, you know, showing

502
00:49:13,040 --> 00:49:17,040
people what was happening was important. But I think it was really important that

503
00:49:17,040 --> 00:49:22,000
I was doing it from the picket line. You know, I was like, here I am surrounded by other people

504
00:49:22,000 --> 00:49:27,200
and you can see what is happening here in the real world. I'm on the street in front of Netflix.

505
00:49:27,200 --> 00:49:32,240
And here's hundreds of people around me or we're at a rally, etc. If I had been doing that from my

506
00:49:32,240 --> 00:49:37,520
bedroom, you know, if that if that was where the struggle was taking place, all of us on the internet,

507
00:49:37,520 --> 00:49:42,080
it wouldn't, first of all, he wouldn't have won. It wouldn't have been as powerful, but it also

508
00:49:42,080 --> 00:49:47,600
wouldn't have, it wouldn't have mattered like the the connecting to, you know, the real life

509
00:49:47,600 --> 00:49:53,120
physical organizing mattered so much. And when you're doing that face to face, you see how powerful

510
00:49:53,120 --> 00:49:56,960
it is to see someone who you're in, you know, struggle with and you see them face to face and

511
00:49:56,960 --> 00:50:01,920
you give them a hug and you say you need some water and you like have a connection. It's just

512
00:50:01,920 --> 00:50:07,920
funny though, because so in all this about return to work, so many people make fun of bosses for

513
00:50:07,920 --> 00:50:12,400
going, oh, the ineffable synergy of being in the office together and people would make fun of those

514
00:50:12,400 --> 00:50:15,680
bosses for requiring people to go back to the office. And part of me would go, I do kind of

515
00:50:15,680 --> 00:50:22,640
believe it though a little bit. Like I do agree face to face has something irreplaceable.

516
00:50:23,360 --> 00:50:27,120
But talking about nobody wants to go back to their workplaces, it probably means that their

517
00:50:27,120 --> 00:50:31,840
workplaces sucked in, you know, they need to change their workplace culture. And that's another

518
00:50:31,840 --> 00:50:37,280
argument for organizing, but I love that description because, you know, all of these ways,

519
00:50:37,280 --> 00:50:42,880
like ways of building doubles of ourselves, right? Like whether we're optimizing, we're

520
00:50:42,880 --> 00:50:48,640
perfecting our brand or we're, you know, I talk about the optimized body as being a kind of

521
00:50:48,640 --> 00:50:54,960
doubling, right? Like the idealized form. And this is, you know, part of what pushed a lot of people

522
00:50:54,960 --> 00:50:59,520
over the edge during COVID was this idea that they had a strong body, a strong immune system,

523
00:50:59,520 --> 00:51:03,680
so they didn't need to worry about other people. And they didn't, you know, they didn't have to

524
00:51:03,680 --> 00:51:09,680
think about being in this enmeshed, you know, world of other people. Or they see their kids as

525
00:51:09,680 --> 00:51:15,760
their little mini-mes, their little doppelgangers, but all of it is about the self as opposed to

526
00:51:15,760 --> 00:51:25,600
building collective power. And, you know, when we are trying to face huge collective problems

527
00:51:25,600 --> 00:51:31,520
as individuals, that's when we feel most powerless, right? And we feel ashamed, you know,

528
00:51:31,520 --> 00:51:35,200
because we can't seem to make ends meet, despite the fact that we're working so hard,

529
00:51:35,200 --> 00:51:40,800
or we're carrying this debt, you know, or we have this terrible boss. And the power of the

530
00:51:40,800 --> 00:51:46,720
demonstration, you know, and this is really where the book ends, quoting my friend, Keyanga Yamada

531
00:51:46,720 --> 00:51:52,480
Taylor, who teaches history at Princeton, and also quoting the late, great John Berger about

532
00:51:52,480 --> 00:52:00,720
the power of the demonstration is not just that you demonstrate to those in power at Netflix

533
00:52:00,720 --> 00:52:06,240
or wherever, that there's a lot of you. It's that you demonstrate to one another that you are not

534
00:52:06,240 --> 00:52:14,240
alone, that you are, that what felt individual, like an individual crisis for you, because you

535
00:52:14,240 --> 00:52:18,560
couldn't pay the bills, is actually a collective crisis. It's actually a crisis for your boss

536
00:52:19,200 --> 00:52:24,080
when all, when everybody gets together and withholds their labor or withholds their rent,

537
00:52:24,080 --> 00:52:31,200
you know, in a tenants union, or withholds their debt payments in a debtor's union.

538
00:52:32,080 --> 00:52:40,080
So that's why we need to get over ourselves, right? That is why I'm grateful to my doppelganger,

539
00:52:40,080 --> 00:52:45,920
because I think I care, like all of us, I care too much about my own image. I who the hell cares,

540
00:52:45,920 --> 00:52:51,360
you know? So people confuse me with somebody else. And that's that I take that as a message to just

541
00:52:51,360 --> 00:52:54,880
get over myself and reach towards other people, build collective power.

542
00:52:54,880 --> 00:53:00,240
Oh, I love that. It makes me think of this thought that I've had recurringly over the

543
00:53:00,240 --> 00:53:03,840
past couple of years, which is that when you're face to face with other people,

544
00:53:04,560 --> 00:53:09,920
they see you in a way that you can't control. I think about this as a stand-up comedian who I

545
00:53:09,920 --> 00:53:13,760
perform live in front of other people and I watch other stand-up comedians. And when I think about

546
00:53:13,760 --> 00:53:19,520
how the audience regards you on stage, they're looking right at you. You're exposed in front

547
00:53:19,520 --> 00:53:23,120
of them. You can try to put up whatever front you want. And a lot of people can put up a front

548
00:53:23,120 --> 00:53:29,280
quite well. But the audience is gay is always pierces to something that you don't control,

549
00:53:29,280 --> 00:53:33,680
you know? I feel that people are able to, you know, when we're present for each other,

550
00:53:33,680 --> 00:53:39,680
we see each other in this sort of like deeper uncontrollable way. And maybe that's why it's a

551
00:53:39,680 --> 00:53:44,560
relief to be in person, because we, you know, on the internet, it's all artifice, right? It's all

552
00:53:44,560 --> 00:53:50,080
anybody sees as what I control. And it's actually helpful to be in a situation where I'm not totally

553
00:53:50,080 --> 00:53:57,360
in control. And then I get, I get seen as a person, which is satisfying and sort of lumpy and weird,

554
00:53:57,360 --> 00:54:02,080
even though it's, I don't have control over, it's a little scary, but it is ultimately so much more,

555
00:54:02,080 --> 00:54:06,480
there's more fucking going on there. Well, and well, they will also do things you can't control,

556
00:54:06,480 --> 00:54:13,440
right? Like, and that's, that's a whole other thing. But it is, it's, I mean, this is the thing

557
00:54:13,440 --> 00:54:18,160
about, I think there's certain things about the tools of technology that are habit forming, you

558
00:54:18,160 --> 00:54:24,560
know, that when you can mute somebody, you know, and just, or just block, like, like there's something

559
00:54:24,560 --> 00:54:30,480
habit forming about the idea that you can just make inconvenient people disappear. Which, look,

560
00:54:30,480 --> 00:54:34,800
I'm a muter. I admit it. Like when someone's putting me in a bad mood, I'll mute them. I don't

561
00:54:34,800 --> 00:54:41,280
block. It's so much more than the satisfaction. You can't block, but it's so fun to follow someone

562
00:54:41,280 --> 00:54:45,920
and then mute them and be like, they don't know that they're muted. They still think I follow them.

563
00:54:46,640 --> 00:54:48,880
They're still yelling at me and they think I hear them.

564
00:54:51,520 --> 00:54:58,080
But it is, it's a sick thing to take pleasure in. Because when you are in a room with other

565
00:54:58,080 --> 00:55:02,720
people, you realize that you can't turn them off. Like they are going to be, they're all fully human

566
00:55:02,720 --> 00:55:06,480
selves, right? And this is why we need gun control.

567
00:55:17,760 --> 00:55:23,600
I love we're having this very, like, airy philosophical argument about seeing each other

568
00:55:23,600 --> 00:55:28,160
and control and identity and persona and you're like, and that's my policy argument for an assault

569
00:55:28,160 --> 00:55:31,920
weapons ban. Because I want to have a debate. I just don't want it to end that way. You know what I

570
00:55:32,000 --> 00:55:40,960
mean? I love it so much. And this again, it connects to so many things that I've been thinking about

571
00:55:40,960 --> 00:55:45,120
who I am and how I move through the world and what I do. It sounds like it's too high and I

572
00:55:45,120 --> 00:55:50,640
start wigging out about my online identity and stuff. And this is helping me giving me a framework

573
00:55:50,640 --> 00:55:59,040
to think about it, which I think is your goal. So do you have any to bring us in for a landing here?

574
00:55:59,520 --> 00:56:06,720
You know, concrete, like, steps that you take away from this journey that you went on with

575
00:56:06,720 --> 00:56:12,720
Ms. Wolfe and everything that you learned about the mirror world? Like, how do we, especially

576
00:56:13,360 --> 00:56:16,800
if we talk about those people who are really trapped within it and we want to connect back

577
00:56:16,800 --> 00:56:20,160
to them? Because I have so many friends who've experienced the pain of that. I have friends

578
00:56:20,160 --> 00:56:26,880
who've lost parents to QAnon who they can't speak to anymore. And to that mirror world, what do we

579
00:56:26,880 --> 00:56:37,600
do? Well, so all the research shows that if somebody is going to get out of that mirror world,

580
00:56:37,600 --> 00:56:44,400
you know, if they're going to get away from Steve Bannon or whoever it is that they have adopted as

581
00:56:44,400 --> 00:56:51,280
a guru, it's going to be somebody who they have a preexisting relationship with who will have reached

582
00:56:51,280 --> 00:56:55,600
them. And like I said, this world is full of grifters. They're getting fleeced all the time.

583
00:56:55,680 --> 00:57:00,000
The stories are changing all the time. They probably have questions. Some people are too

584
00:57:00,000 --> 00:57:05,280
far gone, but there may well be people who are looking for an off-ramp. And it's not going to

585
00:57:05,280 --> 00:57:10,480
be my book that's going to get them. It's going to be a friend from high school who maybe read my

586
00:57:10,480 --> 00:57:16,560
book and had some ideas for how to extend a bridge and find some common ground. Like I said,

587
00:57:17,440 --> 00:57:21,680
I don't like Bill Gates. I don't think he's implanting us with chips.

588
00:57:22,240 --> 00:57:29,280
I just think he's a fucking asshole who made his billions in a horrible way and then is bad to

589
00:57:29,280 --> 00:57:33,600
people and created a propaganda machine about how great he is, where he made his own Netflix

590
00:57:33,600 --> 00:57:38,880
documentary about how he's the smartest guy in the world. Exactly. There's so many reasons

591
00:57:38,880 --> 00:57:47,280
to hate Bill Gates without making anything up. He's mean to his wife. He's an asshole husband,

592
00:57:47,280 --> 00:57:55,120
isn't he? He hangs around with Jeffrey Epstein, if I recall. So I do think that it is worth

593
00:57:55,120 --> 00:57:59,200
extending those bridges, but I don't think we're going to solve this one uncle at a time.

594
00:58:00,080 --> 00:58:09,360
And I do think if you listen to how these right-wing populists are gaining ground,

595
00:58:09,360 --> 00:58:16,080
it's by mixing and matching some true things with some very dangerous and untrue things,

596
00:58:16,480 --> 00:58:23,280
great replacement theory. And the immigrants are coming to replace you and teachers are turning

597
00:58:23,280 --> 00:58:31,280
your kids' trends. So they'll take something like a fear of surveillance or rightful suspicion of

598
00:58:31,280 --> 00:58:38,800
Big Pharma and they'll mix and match it with this much more nefarious agenda. So what we can do is

599
00:58:38,800 --> 00:58:46,240
we can take away the true things that they're like, we can take them back and put them to work

600
00:58:46,240 --> 00:58:52,240
in a real progressive project. So I don't think we fight conspiracy culture by just like de-platforming

601
00:58:52,240 --> 00:58:58,080
and content moderation. And I'm not saying that there's no role for that. But I think that

602
00:58:58,080 --> 00:59:04,080
Sean Fain, the head of the UAW, has done more to fight conspiracy culture just being out there in

603
00:59:04,080 --> 00:59:09,520
his eat the rich t-shirt and saying, you know, record profits should mean record contracts

604
00:59:09,520 --> 00:59:17,040
and like being an actual left populist with a plan, an organizing plan for how to actually

605
00:59:17,040 --> 00:59:21,360
meet people's needs. Because what conspiracy culture is, is a distraction machine. It takes

606
00:59:21,360 --> 00:59:29,600
people's anger at elites, feeling that they're being screwed over. And it pivots it towards

607
00:59:29,600 --> 00:59:34,560
scapegoats, right? So the best way to fight it actually is to give people a real economic project

608
00:59:34,560 --> 00:59:38,800
that's going to meet their needs so they are less likely to fall for these counterfeit grifters.

609
00:59:38,800 --> 00:59:45,120
Absolutely right. To say, hey, the feeling that you have is real. There needs to be a fight,

610
00:59:45,120 --> 00:59:50,160
but to actually wage the right fight and don't just pay it lip service, but organize

611
00:59:50,160 --> 00:59:56,720
Marshall the power. I mean, Sean Fain has power in the UAW and he is winning and people can,

612
00:59:56,720 --> 01:00:00,960
hey, don't you feel like you're getting screwed? Everybody says, yes, let's fucking do something

613
01:00:00,960 --> 01:00:07,040
about it rather than selling you bullshit coins. Fuck Joe Biden coins. He's going after the bosses

614
01:00:07,040 --> 01:00:11,760
and that is what they fear most. I mean, there's a reason why some of the richest people on this

615
01:00:11,760 --> 01:00:18,400
planet love a good conspiracy theory. Like, why is Elon Musk the single, you know, greatest vector

616
01:00:18,400 --> 01:00:23,440
of misinformation right now? Like, if you were the richest man on the planet on a good day,

617
01:00:23,440 --> 01:00:29,360
you would want people distracted too. You know, you would want people not looking at systems of

618
01:00:29,360 --> 01:00:35,680
economic consolidation that allowed you to get as rich as you are. You would want them talking

619
01:00:35,680 --> 01:00:41,840
about the Jews and the CCP and, you know, Anthony Fauci and the rest of it. It's a distraction machine

620
01:00:41,840 --> 01:00:46,960
and it serves elites even though they claim to be fighting elites like Rupert Murdoch, right?

621
01:00:47,840 --> 01:00:52,160
So we just need to understand this. We need to do a little mapping. That's all. Get order.

622
01:00:52,160 --> 01:00:56,960
We need to understand it. And then we need to organize to show the alternative path.

623
01:00:56,960 --> 01:01:00,560
And then we need to win, which we are starting to do, I think.

624
01:01:00,560 --> 01:01:04,640
I think so too. I think so too. And I want to thank you for all of your organizing in

625
01:01:04,640 --> 01:01:09,040
real world action, right? Because this is, that's how, that's how, that's,

626
01:01:09,600 --> 01:01:16,000
that's the best way we fight this sort of fake world is by doing real work, real work.

627
01:01:16,000 --> 01:01:20,640
That is such a beautiful conclusion to this conversation. Naomi, I'm so thrilled that you

628
01:01:20,640 --> 01:01:25,040
came on the show. I can't wait. I'm going to get this book, an audio book, I think,

629
01:01:25,040 --> 01:01:29,200
is going to be for my next month of travel on the road. I can't wait to listen to it.

630
01:01:30,080 --> 01:01:31,840
I hope folks check it out. If you want to pick up a copy,

631
01:01:31,840 --> 01:01:36,240
you can get it at our special bookshop, factuallypod.com, slash books. Naomi,

632
01:01:36,240 --> 01:01:39,280
is there anywhere else that people can follow you or your work?

633
01:01:40,880 --> 01:01:44,080
Okay, I guess I'm on. I mean, I can't answer the question now.

634
01:01:44,080 --> 01:01:48,880
You're right. You're right. After an hour of talking about Twitter and stuff like that,

635
01:01:48,880 --> 01:01:53,040
you know what? How about this? I have a website, NaomiCline.org, and you can, you know,

636
01:01:54,160 --> 01:01:59,760
follow my articles in The Guardian, and you can sign up for my newsletter, which is free.

637
01:02:00,400 --> 01:02:04,800
How's that? That sounds beautiful. And then maybe someone can see you in person

638
01:02:04,800 --> 01:02:07,920
and talk to you about organizing or something like that. They run into you in British Columbia.

639
01:02:09,440 --> 01:02:13,040
Thank you so much. This was such a pleasure. Thank you so much for being here, Naomi.

640
01:02:14,000 --> 01:02:17,280
Well, my God, thank you so much again to Naomi Klein for coming on the show.

641
01:02:17,280 --> 01:02:21,200
I hope you loved that conversation as much as I did. If you want to pick up a copy of her book,

642
01:02:21,200 --> 01:02:26,880
you can get it once again at factuallypod.com slash books. That's factuallypod.com slash books.

643
01:02:26,880 --> 01:02:30,800
And when you do, you'll be supporting not just this show, but your local bookstore as well.

644
01:02:31,440 --> 01:02:36,160
If you want to support this show, you can do so at patreon.com slash Adam Conover.

645
01:02:36,160 --> 01:02:40,400
Five bucks a month gets you every episode of the show ad free for 15 bucks a month.

646
01:02:40,400 --> 01:02:44,400
I will thank you in the credits of the show and in all of my video monologues.

647
01:02:44,400 --> 01:02:49,200
This week, I want to thank Richard McVeigh, Celine Dragon, Blamo, Michael Frasco, Lee Dotson,

648
01:02:49,200 --> 01:02:54,880
Emily Wilson, Sekto Abedin, and God King, engineer of Beaverkind. Really like that username,

649
01:02:54,880 --> 01:02:58,400
God King, engineer of Beaverkind. Would love to know what that means. Send me a message on Patreon.

650
01:02:58,400 --> 01:03:01,920
You can message me on Patreon as well if you feel like it. I want to thank my producers,

651
01:03:01,920 --> 01:03:06,000
Tony Wilson and Sam Raubman. Everybody here at Head Gum for making the show possible.

652
01:03:06,560 --> 01:03:10,240
You can find my tickets and tour dates at adamconover.net. Once again, I'm going to New York,

653
01:03:10,240 --> 01:03:14,320
Chicago, Nashville, DC, a bunch of other cities as well. Boston, Portland, Maine,

654
01:03:14,320 --> 01:03:18,240
a bunch of places. Head to adamconover.net to get those tickets. Hope to see you there

655
01:03:18,240 --> 01:03:23,120
and see you next week on Factually. That was a Head Gum podcast.

