I don't hear as much about, like, end of the world as I do.
What is the application in the school system?
And then how is my child learning?
When you first heard the notion of existential risk,
that, like, within our lifetimes,
there could be a world where there is no life on Earth.
We are expected lifetimes, I guess.
How did that hit you?
What was your first thought?
I think I believed.
I mean, I'd sound so crazy.
I feel like I've found a little crazy to say, like,
I needed to do my research.
Like, I needed to know who was saying there.
Were those people credible?
And what's been really interesting, the camps, right,
being the dancers, versus the juniors, or there need camp.
And each camp has their expert that
went to this Ivy League institution
and worked at this, you know, this big tech firm,
or used to work at the big tech firm.
Like, both sides of the camp have their, you know,
qualified experts.
Like, human extinction, like, you know,
society has been trying to, like, eliminate me my entire life.
Nothing will be able to, like, overpower us
because of what we've been able to endure
and what we've been able to survive.
So for me, I'm like, OK, come at me, AI.
Like, you know, you know, it's just like, like, come at me.
Throwing down the, she's throwing down the bell.
Like, like, like, come at me, tech bros.
Like, I got you.
Like, there's no way that you can, like, completely, like,
you know, erase me because, like, I've been through so much.
I think it means a little brand.
I think the term AI, so to speak, is boring.
I don't think anybody gets excited about it.
I don't think they know what it means.
It sounds like a fake news moment.
Like, what?
Like, AI, fake news, snoozer.
I think the scary part for me was that the people that created it
were warning us and said, we don't know how to control it
at this point.
And so when you have a creator that doesn't understand it,
it doesn't understand what it's doing, that's very scary.
I was stunned to know that the people who make AI
have no idea why it does, what it does, or how to control it.
What did you think when you all first heard that?
Welcome to For Humanity, an AI safety podcast, episode 7,
Mom's Talk AI Extinction Risks.
I'm John Sherman, your host.
Thank you so much for joining me.
This is the AI Safety Podcast for the general public,
no tech background required.
As you know, this show is exclusively
about the threat of extinction from artificial intelligence.
Please like, subscribe, and tell a friend about this show.
And if you are on X and want to hear more
about these issues on a daily basis,
please follow at For Humanity Pod.
OK.
So the whole point of this podcast
has been to move this debate from the Silicon Valley
boardroom to the family dinner table.
I also, as a parent, have been wondering
how anyone who works in AI could do this to their children.
And that if maybe awakening the parental maternal instincts
that are so foreign to this AI safety debate
could be possible and maybe even powerful.
So I thought, what a better way to do that
than to just do that.
So I asked three moms to come on the show
and discuss AI as an immediate threat to their children.
I want to give a big thanks to Stephanie, Jen,
and Crystal, our three moms.
I asked them all to watch the first episode
of this podcast before we met.
I think this is a fascinating conversation,
and I am thrilled to share it with you.
All right.
Moms, I think we made it.
We made it for the Gauntlet Riverside Zooms
and getting on a video conference.
So nice to see you all.
Nice to see you.
Awesome.
So let's just take it from the top here a little bit, I guess.
So it's an interesting thing in your life
when you start to talk about these AI safety issues.
They resonate with certain people and not with other people.
And Stephanie has been a friend of mine for many years.
And it's an issue that resonated with her.
And we got to talking about it.
And one of the things we're talking about
is where is the parental attitude in this?
Where is the maternal attitude in this?
And so I've been trying to take this debate as much as I can
from tech people to regular people.
So why not just do it and take it right
to the most regular people of all, the moms?
I will say as a father, as a son, husband, all these things
that moms, the world go around.
And so I salute to all the moms everywhere.
I thought we could just start off right at the top.
Maybe let's just go around the horn, say who you are.
Tell me a little bit about your kids
and maybe what you do outside of kids.
And we'll just quick shoot around the horn
and then come back up to the top.
Stephanie, why don't you start us off?
So I'm Stephanie Rano.
I am a mom of 30 kiddos.
My oldest is 13.
My middle is 10 and my youngest is 8.
So kind of early, but definitely that 13-year-old has
opinions.
Two of my kids are neurodivergent.
And that is much a part of our lives.
I'm really open about talking about it
with anybody who will listen just around their gifts
and the place if they need support.
And what I do and I'm not being a mom is I do recruiting.
So I do sales for a recruiting company.
I've been doing stocking and recruiting for almost 20
years.
And I'm really excited for this conversation.
And excited to share the podcast, hopefully with my kids.
So watch your language, Jeff.
Thank you.
Thank you, Stephanie.
I did make a promise to our group here
that I would clean up my act for the show in an effort.
Maybe we can show it to the kids afterwards.
So that would be great.
Jen, please introduce yourself.
Yes.
Hello, everyone.
My name is Jen White-Johnson.
I do identify as someone who is neurodivergent.
I do have ADHD and also anxiety and also an autoimmune
disorder.
So I live along the intersections of being black
and having a disability.
And my son is also autistic.
And my husband is also neurodivergent.
So we are very neurodivergent, affirming family.
And it intersects with my teaching.
And I also teach graphic design within these past few years
since my son was diagnosed.
I do a lot of disability advocacy work specifically
under the influence of art and where
that can be used as a tool to really uplift
the conversation of disability justice.
So thank you for having me.
Awesome, awesome thrill to have you.
And Crystal, please introduce yourself.
Hi, everyone.
My name is Crystal Putman Garcia.
So I am also a mom of three, like Stephanie.
I have twins that are nine.
And then I have an almost seven-year-old, so six right now.
So they're a little bit on the younger side.
But I do have a neurodivergent son who
is obsessed with technology.
He could hack into our Amazon accounts when he was five.
I think it's one of his gifts.
And so definitely try to balance when is it OK
to give your kids technology because we live in a world
with technology.
And so we want kids that are comfortable with it.
But where do you draw the line?
And I'm not just a mom.
I also work for a tech company.
So I work for a policy and global intelligence company
in half or several years.
And I also, in the past, have worked
to make sure that there's an intersection between consumers
and internet privacy.
And so this is an area that's particularly of interest to me.
And one of the reasons why I thought this group would be
really great to get together is you all put so much work
into everything you're doing.
You are badasses professionally.
And you're also incredibly devoted to your kids, as am I.
I'll just introduce myself as well for a second.
I'm John.
I do video production.
I do a podcast that you may be watching.
And I have two kids, Boy Girl Twins, who are 18 years old.
I can't believe it.
They are seniors in high school and getting ready to leave us.
And it's a whole lot to take.
But I certainly, as we think about these AI existential
issues, I certainly make kids are always at the top of my mind.
So why don't we go around the world one more time?
And let's talk about our experience thus far with AI.
We're going to talk a lot about existential risk
and in the podcast.
But before you became aware of this existential risk
conversation, what were your impressions?
And just sort of briefly, what were your dealings with it?
I know Jen and I don't know, Stephanie, either.
You all have been doing some really interesting things
with neurodivergence and kids and AI, which
has some promise in that space.
So Jen, you want to start off and just talk maybe
a little bit about what you've been doing with AI in this area?
Sure.
I mean, just as a designer specifically using graphic design
as my trade and my weapon of choice,
it's always tech and the intersection of how we use it
to kind of emote joy has always been a part of my world.
And so I really use AI to just amplify good.
Crystal, in the marketing world, I'm in the marketing world.
I mean, you must hit every day with 65 new things AI will do
for you that are fantastic that you need to learn yesterday.
Yes, absolutely.
And there's this worry that you're
not going to need marketers anymore because genitive AI is
going to get so good.
I still believe that humans are better.
It still needs oversight.
There's a lot of pros, but a lot of cons.
It's like the smartest, stupid thing around.
Stephanie, how about you?
AI up until we had this conversation.
Yeah, it's funny.
Back this time last year, I was sent a link by a consultant
that we work with, a tech consultant that we work with
who also does some strategy with our to chat to you.
And he said, I know you're working on your presentation
for your big company retreat.
Check this out.
What I ended up doing, Rick, I used it to create the outliering,
to create the agenda, to help me come up with activities,
specific work activities.
And it was awesome.
And I was like, oh, my gosh, this is great.
But I think it's different.
The permission we're in now with generative AI
and the rames to get to general, what is it?
Generalized artificial intelligence?
Yeah, AI, artificial intelligence, yeah.
Artificial general intelligence.
That, to me, is a different story.
And that's where I start to get nervous.
And that's where my kids start to call me a ladderer.
Well, I think stuff you do to your husband, they have.
If you cut their head.
They have.
And it's the access, right?
So you've used it.
It's been embedded in the things that you've been using.
But now they have direct access to it
in a way that's different, right?
Yeah, I mean, I think when we all actually got to use it,
you know, like it was one thing to hear about this thing,
artificial intelligence.
And then chat GPT-4 came out and we all,
some friend of us talked us into logging into it
and signing up and checking it out.
And you were like, oh, my God, this is fundamentally different
from anything ever before.
So that will lead me into my next question.
And this can go to anyone.
When you first heard the notion of existential risk,
that like, within our lifetimes,
there could be a world where there is no life on Earth.
We are expected lifetimes, I guess.
How did that hit you?
What was your first thought?
I think I believed.
I mean, I sound so crazy.
I feel like I sound a little crazy to throw like,
I needed to do my research.
Like, I needed to know who was saying this.
Were those people credible?
And where it's been really interesting,
I think of the camps, right?
The advanceers versus the Jumers or their new camp.
And each camp has their expert that went to this
Ivy League institution and work at this, you know,
this big tech firm or used to work at the big tech firm.
Like, both sides of the camp have their, you know,
qualified experts.
So, you know, it's really like sitting through,
I think, for me and going like, well, in my guts,
because we all, as parents, as mom,
we all have the guts in the same thing, which says,
you don't know, something does it doing right.
And then when you start to see the onion peel away,
like with that mess with them all then,
like when you start to go like, wait a minute,
like what's it going on with good, no offense,
like bull even their toy.
That's all about the green meat and all about the money in,
oh, it used to be a non-profit, but no, it's not.
Now we're focused on profit.
Well, wait a minute, like wasn't your origin
of your company focused on the good of the Nermit?
So I guess I'm still a little bit, I'm slow with like,
I will always continue to just kind of try and pull
from various sources to make sense.
And then frankly, trust my gut to go,
I need to take this seriously.
I didn't take the pandemic seriously
when I first came out.
My husband and my boss were like, canary in the coal mine.
We were like, this is gonna be bad.
I'm like, I'm going to the conference.
You know, like, don't go to the conference in March.
I was like, I'll be fine.
I was like, don't go and then the conference back.
But this is like my canary moment, I think.
Yeah.
Yeah.
Excellent.
Crystal, Jen, what do you think?
Human extinction.
I think extinction is a strong word
and over what period of time.
So I think, you know, I think that's the hard part about,
well, there's two different things.
There's the scary part is, I think going back
to what Stephanie said, who is saying this
and based on what information,
I think the scary part for me was that the people
that created it were warning us
and said, we don't know how to control it at this point.
And so when you have a creator that doesn't understand it,
it doesn't understand what it's doing.
That's very scary to me.
That's the first thing that worried me.
The second thing that worried me is you look
at social media, et cetera, and these things were created
so that you cannot, like as humans,
like you can't win against it, right?
Like you become addicted to it.
You can't help it.
And so I think those are the two things
that concern me as you can see
how social media spreads misinformation, right?
So if you think about it, something that the people
that created it can't control and you have this,
and then the people that created it
are warning you about it.
And then you've seen just implications
from not generative AI, but a tool like social media
that does use it, that's spreading misinformation.
You can see how the risks could be there.
So I'm not fully doom and gloom
like the human race is going away,
but I think it's very concerning.
And if you don't have people stepping in
to take a stronger role in managing against it,
then it becomes scarier.
Yeah, for sure, Jen.
Yeah, I mean, I still think that it takes us as humans
to be able to make a lot of these tools
do what we want them to do.
I've watched my friends.
I've watched other artists, my husband,
use them to the fullest extent.
And there's still essences of the person,
the human that exists within the creations.
And that's what I really love the most
is how can you kind of coexist in the world
that essentially we've built sort of.
Yeah, yeah, I like it.
Even in this group of four,
we have, I think, four unique takes
on almost the same set of information, right?
Which is, and so Stephanie, to your point,
first of all, are we Flat Earthers?
Are we like Y2K people wrapping our houses in duct tape?
The answer's no.
I wish we were, honestly, I wish we were.
I hope we are.
How about this?
I hope we are.
I hope that this podcast is literally
a duct tape wrap around my house.
And I'll wake up on the January 1st morning
and I'll be like, oh, AGI happened.
And we're all fine and everything's fine.
I just, that is not my read of the academics
in the field.
I saw something on Twitter that I'm gonna send you
the other day, it's a list of 125 professors
in like a string of heads of departments
who are basically saying this same thing
that they have grave concern for existential risk
for all life on Earth if we continue to proceed
with developing artificial intelligence systems
that are not aligned with human goals and values
and that we don't know how they work.
So let's go to those two things,
alignment and interpretability.
I was stunned to know that the people who make AI
have no idea why it does, what it does,
or how to control it.
What did you think when you all first heard that?
I mean, it's not a,
anyone who wants that one.
I mean, Crystal, I'll go with you because,
if someone came to you and said,
hey, I wanna get this new product for our department,
it has tremendous power.
It could make us the best company on Earth
or kill everyone in the building.
I don't know how it works.
And I, you know.
That's the scary part that I had mentioned earlier
is that the people that created it
don't fully understand it.
And they don't know necessarily
how to necessarily stop parts of it.
And I think that that's the most concerning part.
I think that goes back to, I believe, Jen's part.
You have to have a human interaction
and you have to create rules around the use of it,
or else it's going to go into the hands of bad players.
You can't say that everyone's gonna use it for good things
because that's just not true.
And so how are we, as human beings, as companies,
as governments, as moms, as human beings,
going to all work together to make sure
it's being used for the right reasons?
Because we've all experienced the good in it.
We've also seen how it can fail, right?
You look at it, you're like, well, that's not right.
And so that's where I think the human mind
currently is different is we can differentiate
between those two things.
But I think there's a point where it's hard to do that.
And that's what concerns me.
Yeah.
Yeah, Stephanie?
Yeah, no, I agree.
Definitely, I think it's shocking, but not shocking
that people would want to run fast toward advancement
and towards being the first,
like being the first company, the first person,
the first team, you know, it's interesting, right?
I almost wish we had someone that may be described
to more of like in certain value years.
I don't know, like, and maybe you guys do, I don't, you know.
But in listening, John had recommended Mo Galdet,
who has a book called Scary Smart.
He was with, let's do the act,
but the time is only 10 years.
And she, you know, he even says,
like kind of the Western drive to make more money
and just succeed by any measure and get to the top.
And it doesn't matter if you leave in your weight.
We want to say that that's not the case,
but it's so very much the case.
And so I think as moms, too, it's hard to,
like, to parent kids when it's, you know,
when you've got the pressure,
social media or of your friends' kids
or of a man on what school, and, you know,
you're fighting that all, already, all the time.
And then you sort of, you blow that out,
you know, you miss, blow the AI.
And how else are their systems supposed to learn
other than our inputs?
And if our inputs are all for like the basis parts
of who we are as humans, then that's not great.
Like that's only setting up the system
to be based in the way that they pursue.
And so it really worries me.
You know, I also am aware that, like,
we're cognitively discriminant people as humans.
I don't know that AI systems
or maybe they'll be able to do that.
I don't know.
I feel like that might be a human, like, win.
Like, hey, I can hold two very opposing ideas
at the same time.
Like, I am a practicing Catholic.
And I also am really worried about existential crisis,
but I'm not worrying to a point
of where I can't get out of bed
or where I can't go to work or where I can't parent my kids.
So, because I think at the core,
I have this thing that, like, is my belief
and says, like, you can't, like, offer that up.
You can't worry about that.
So, I don't know if that makes sense.
I mean, like, the, I'm very concerned.
And also, I can't really, or,
day in or day out,
I'm up late 16th through another year,
or we're this way.
Yeah, no, absolutely.
Elon Musk was asked about it recently.
And he said, you know, he has existential fears of AI
and says it openly and says, in 2016,
he had spent a lot of sleepless nights worried about
what I'm worried about right now,
but that he has come to peace with it
because he's decided that there's no more interesting time
to be alive as a human.
So, he will sacrifice the potential for extinction
with the excitement of living the most exciting life
of any human generation.
I don't know that I can quite get there,
but I did find something in that,
something in that that was a little helpful.
Here's the question I have for you all,
and then I'll throw it to you, Jen.
Where are the women in this whole thing?
You know, a lot of people have seen my first podcast.
I appreciate that you all watched it.
And, you know, this is a very male-dominated thing
that is happening to the world.
Where are the women and what are your thoughts about it, Jen?
Well, I mean, there's a ton of women
that are really advocating specifically from, you know,
the black and brown perspective when it comes to ethical
and responsible AI.
Oveta Samson is a really amazing voice.
You know, Gerald Thomas,
who are specifically working to address
the conversation on representation,
because like I feel like the conversation shifts
when you're asking, you know, black and brown folks to say,
okay, well, what will you do with AI?
What will you do with these tools
and how will you make them radical?
And how will you, what will they look like
when they're kind of placed in the hands
of multi-pre-marginalized people
who have always been denied access
for these specific tools to create
and build the worlds that they specifically want to see.
You know, the tools that they want to see, you know,
that have been, you know, kind of denied.
And so I feel like making sure
that we can kind of have space,
and I have like my LinkedIn open and, you know,
being able to just, you know, like, okay, yeah,
well, who's having these conversations?
And I really love that the language specifically
has been evolved into incorporating responsibility,
you know, equity, being able to,
and I love that, you know,
black women who are in, invested in machine learning
and, you know, gen AI are like,
are leading those conversations.
So, you know, it, like I said,
like it begins to shift when, you know,
when the conversation is put in the hands
of the multi-pre-marginalized.
Sure, sure.
Thank you.
And I feel like
there's a maternal attitude missing to this whole thing.
Like it's like some 30-year-old guys are like,
hey, I got this car, it goes super fast.
I'm gonna go race it at 300 miles on the highway.
And nobody's being like, you might hurt someone.
Don't, you know, you might want to think twice about that.
Have you thought about the other people?
Crystal, Stephanie, any thoughts about the male domination
of this suicide cult?
So it's funny, John, because I, as you asked this,
last week I saw her film in Danny Herrera,
she was like, it's an AI advocate.
She posted about the New York Times article.
So I think, you know, there is complicity in,
particularly in media, that if you're not gonna cover,
if you're gonna cover like the 12 game changers
from leaders in AI, you can't find a woman
and she would like, lazy, and it's totally right.
Lazy reporting, lazy coverage.
I'm not calling you crazy, John, I promise.
But it's like, because you were like,
I didn't have any in mind.
And I was like-
I looked hard.
That really, like, yeah.
But she posted this and she had over 600 comments of people
and out of those, like, probably let's say,
let's just think of like half,
would-listing women leaders in AI.
And you know what's really interesting?
Just a couple that she mentioned.
Lee, Rana L. Touloubi, Margaret Mitchell, Tim Gibrew,
Siren Snyder, Vanilla Braga, Joy Bouladini.
All these women, the stuff they're doing
is around gender bias and around like ethics
and around same food and around all this stuff.
And you're like, yeah.
So then cover things that we're saying
and like that are coordinated with this conversation
around how do we protect our, you know,
I think there's a real issue when it comes to coverage
and people and the New York Times got flammed
and as they said, right.
You know a little hot about that one.
I need to swear words, but I got hot.
I think, I do think there are a lot of women
that are doing things.
I don't think they're getting the coverage
to Stephanie's point earlier.
I also think there's an interesting part to it
about geography.
And so you see women and men, right in the EU,
it's always more kind of risk a burst
when it comes to technology.
If you look at privacy, so I have a background in privacy.
The strongest privacy laws are in the EU.
And then in the US, it usually goes to California next
and then it might go federal at that point.
I think you're seeing that in AI.
And so you're seeing, so I think you also
have to look geographically.
In the US, we are capitalistic.
We're gonna go for whoever's gonna make
the most money quickly.
I think the EU has more of a familial kind of community sense
than the US and then you're gonna see that play out.
So I'm curious how the EU standards
are gonna impact the US in other parts of the world.
So I'm not sure, I think there's a male versus female
US coverage, but there's a really interesting work
happening geographically as well.
Yeah, that's super interesting.
I absolutely believe there are women
doing incredible things in AI.
I think they're not getting any coverage.
And I think that it's also just really hard
for those sort of stories to break through
because it's so male dominated at the top
that it's a real problem and it's a problem in bias.
And it's a problem in what I wanna talk about today
which is some 30 year old guys believing
that they have been authorized to exercise
existential risk on behalf of us.
Like they go to work today thinking that somehow
it's reasonable and appropriate for them to toy
with all of us dying.
And I just can't get over how that's possible
for people to get up then and say,
I'm gonna come back tomorrow for another day of this.
Crystal, I wanna get at one thing you talked about
a little bit earlier, cause I feel like even in this group
of four we may have some differences of opinion.
I feel like Stephanie, I feel like you can picture
human extinction a little bit.
Like we've had some conversations and I feel like
it's a what, like think about your street.
Like your literal street, what does your street look like
the morning after all life on earth is eliminated.
It is laughable, like it's so uncomfortable that,
you know, it's really hard to contemplate.
I did not think it possible in my life
that I would be contemplating these things.
And yet I find that I'm doing it on a daily basis.
So Crystal, I feel like, and Jen, I don't know
where you are on it, but I feel like Crystal,
well, I'm a black woman in America.
So like I feel like I'm at risk every single day,
like walking in the street.
I mean, that's why like I have like,
you know, if we really wanna get deep with it,
like human extinction, like, you know,
society has been trying to like eliminate me my entire life.
You know?
So it's just, to me, it doesn't take tech,
technology to do that.
It doesn't take technology to do that.
It just takes, you know, being erased
and having like my culture become erased and appropriated.
And, you know, if anything, you know,
just eliminated from the conversation,
which is why it's so important for us to kind of take up
as much space as we can within the AI space,
within, you know, ethical conversations on responsibility
and what that means within artificial intelligence.
Because, you know, I mean, at the core, like, you know,
as, you know, black people have been, we are the oracles.
I mean, we have been guiding people through the path of,
you know, of survival for centuries.
Like, you know, Harriet Tubman, I mean,
she was literally using astronomy
and her own disability to just to guide people
to make sure that they can actually survive, you know?
Yeah, it's really super interesting to think about it,
like that, Jen, to think about different people
perceiving it in different ways
based on their own personal experience.
Yeah, I'm so glad that you joined.
Bet we have these perspectives, that we are not.
You know what I mean?
Like, I'm really glad that you brought that up
because I think,
I think within, you know, wake up in fear
and fear for your study,
that's something that get within your bones.
And it's probably been, you know,
in your family and in your bones forever.
And, you know, it's a privilege that we don't have that.
And now we're thinking about it.
And I also, my next brain, you know,
brain knowing of one brain, two mouths,
maybe I have some other weird brain
fitting some plate though.
But, I don't even know, Monday.
Well, my next thought though is like,
and let's not reach the system that way.
Like, maybe we have the chance
to make the, it's a generalized AI,
we need there's a chance
that it can actually better than us
as humans in that way.
Like, we have the chance right now to teach it.
Yeah.
So, like they teach our kids,
like Murgale Devka, right?
Like, if they're in their infancy
or they're toddler famous right now,
which they are, and like,
I don't need like, all of the good people,
which is a lot more than the bad people in this world,
all the billions of really good people
who comes on all kinds,
how do we get people that don't even have internet
to be able to participate in chats
with, you know, in a generative AI
so that it had that perspective?
You know, it's glad to have those inputs.
It can have the influence of 3000 dudes
and a couple of ladies.
In San Francisco.
Yeah.
In San Francisco, to your point about John Birkin,
it needs like the input.
There's a people in my neighborhood,
friends of my kids' friends,
and they're starting to be like,
oh, you want to talk AI, talk to me.
But one of the mums, it's a lot of mums,
and soon as we're both using it,
and I do, I used it to draft content
for like, an invite for a party.
Like, that sounds silly,
but I was sitting at a basketball practice for my son,
and I was like, oh, he's trying to get us,
there's one thing, we did this two seconds, right?
So I could actually be mostly present
during the basketball practice.
And I gave it a quick prompt,
and then I revised it twice,
I gave it three, and I thought it's very great.
I feel better now, if I got it.
But I use it, and for some people,
it's like, well, you shouldn't use it
if you're worried about the end of the financial trip
with other, you got it, right?
Right, absolutely, and that's what I was talking, yes.
I firmly believe that 99% of the AI out there
is totally safe, and should be used,
and there's a lot of incredible benefits
we could get from it.
Like, a lot of the safety research experts say,
if we just pause for 20 years
and just dealt with the tech we have now,
for 20 years, we could get incredible benefits
for health and medical and scientific breakthroughs
and all these kinds of things.
But we appear to be racing towards it
much more quickly than that.
What do you all hear in your conversations
with your friends, with other moms out there
at the park, at the water cooler, whatever?
What is the tenor and tone of the conversation
at this moment here in December of 2023,
the year AI came out, and we all learned about it?
How do you feel like people are feeling?
I feel like when it comes up in my group of friends,
it's less around human extinction,
it's more like how the kids are gonna use it.
So like, are my kids going to properly learn
how to write an essay, or are they just gonna feed
the data into chat GBT?
And so where I hear it more, it's less around
are humans going to go extinct?
It's more around how is my child going to be learning
to use it or to not use it?
How am I gonna make sure that my child has the right skills
so that when they do go into the workforce,
they're able to kind of do the job.
You're seeing schools now have kids take tests
with a pen and paper again.
I'm seeing several universities doing that.
Who would have thought that because they wanna make sure
they can still write an essay?
So I think it's gonna be interesting as parents,
and then the education system as well.
So how do you make sure your kids are learning?
So I don't hear as much about like end of the world as I do.
What is the application in the school system?
And then how is my child learning?
Exactly.
Yeah, yeah.
No, I hear a lot of that.
And I'm actually gonna circle right back
actually to what Jen was talking about just a second ago
because I had something I wanna talk about,
which is, so I started this podcast seven weeks ago
was working on it for a couple of months before that.
And it was right around, it was all coming together
right around the October 7th attacks in Israel.
And kind of, you know, to what you're saying, Jen,
it's like people feel directly threatened
on a personal, emotional level in different ways
at all times.
And it's really hard for this very abstract issue
of AI safety, something inside a computer system
to emotionally resonate in the way these very personal,
very direct threats do.
And I sort of don't know the way around that.
Like I don't know the way this really amorphous thing
can compete with these other causes
that are so visceral for people.
And I don't know the answer.
I'm just putting it out there.
You know, and I don't know that there is a good answer.
Like, I think people that are focused on issues
of immediate human suffering and human condition,
I can't come in and say,
hey, everybody should drop what they're doing
and go work on AI safety and forget about
any stigmatism and racism and all the horrible things
out there, hate and all the horrible things on the planet.
Like people working on those causes have to continue,
but it's like we as a society have some sort of like limit
for cause stuff.
And I feel like we're tapped out
and AI is not gonna get, you know,
the attention that things that affect people
more directly and personally immediately do.
Well, then I also think you have to look at the inputs, right?
Going into AI as well.
So you have deeply personal things to people,
but people have very different views on things.
And you have all those disparate inputs
going into generative AI.
And so then what comes out of that,
I think is an interesting question.
I think AI can see and I'll just say it.
I think it means a new brand.
I think the term AI safety was boring.
I don't think anybody's guessing.
Life is about it.
I don't think they know what it means.
Well, it sounds like a safety poll.
Like what?
Like AI safety is sooner or later.
Let me ask this.
Show of hands, and I think I'm gonna know the show of hands.
I think it's me and Stephanie and Crystal and Jen
on two sides.
Could you actually imagine the end
of all living things on earth?
Because of AI or in general?
Yes, because of AI.
Because of AI.
No, I can't.
I mean, can't.
No, I mean, just because like I know how to use it.
Like I know how to use it for like,
I just know how to be radical with it.
And I know how.
The concern is when it starts using itself, right?
When it starts recursively improving itself,
setting its own goals, becoming its own agent.
You know, it goes off on its own
and it's no longer checking with us.
That to me is very conceivable, if not likely.
But how is it gonna do it though?
Like, and this is where we need to get very specific
about the tools.
Like, okay, so what tools are we specifically talking about?
Like what AI?
Like mid-journey, for instance.
Like mid-journey cannot create problems on its own.
Totally fine, not a problem.
And anything that's out there that consumers are using
is not a problem at all.
It's the 1% of the frontier level work
that open AI, Google, Microsoft,
DeepMind, Anthropic are doing
that is pushing the frontier boundary of the systems
where it starts to recursively improve itself.
And nobody knows what happens after that point.
So, yeah, Crystal.
The two things that I think about,
I have a hard time thinking humans become extinct.
That's like, I have a hard time there.
Where I can see is questioning,
what does it mean to be human?
And Stephanie and I had a conversation around this
because at some point, do we make generative AI so smart
or kind of robots or whatever
that they become citizens, humans, et cetera?
And then you have this,
then you have a kind of question on who makes decisions.
Because if generative AI keeps getting smarter,
then you can see over time,
humans kind of move into a different role within society.
So I can see some interesting things happening
if you look into the future of AI becoming human
or how we define human is one aspect.
But the thing I keep thinking that generative AI
can do really well more quickly is cause absolute chaos.
Because you have disinformation, lies,
and then you lose trust in society.
And once you lose trust in society,
that's where a lot of bad things happen.
That's where war happens.
You have groups of people, again,
fighting different interpretations.
And so the world I see that's more plausible more quickly
is just sheer chaos with disinformation
because of generative AI.
And I don't disagree with any of that stuff,
but I just wanna pick at it a little bit further, right?
So with Crystal and Jen,
so you guys watched the first episode of the podcast
where you know that there's this 22-word statement
that everybody in AI put out that says
that artificial intelligence is an extinction risk
along the lines of pandemic and nuclear war, right?
And so my question is if they're saying it,
if other people, if the literal people
who are making it are saying it,
why do you think you and the 99% of the public
is like, ah, yeah, but like they don't really mean it.
Like they said extinction,
but they really meant something else.
Like I just, I feel like I could be extinct without it.
Like who I am as a person,
like I could be extinct without it, you know?
Like I was like my people, my culture, you know,
without technology, I mean, you know,
literally they were using colonialism and racism
and they were using black and brown bodies
as they were harvesting like enslaved people,
in terms of, so I feel like it's gonna take more
than technology, more than technology
to like make us extinct as a people.
I still feel like, you know, black people,
multi-multiply marginalized people, like we will never,
like nothing will be able to like overpower us
because of what we've been able to endure
and what we've been able to survive.
So for me, I'm like, okay, come at me AI, like, you know,
you know, it's just like, like, come at me.
Throwing down the, she's throwing down the bell.
Like, come at me tech bros, like, I got you, like,
there's no way that you can like completely like,
you know, erase me because like I've been through
so much more than technology can, you know.
Yeah.
That's kind of like where I'm at.
Yeah.
I think it's generally hard to think
about existential problems, like,
and it's really hard then to think
about existential problems with your kids.
Like, as it relates to your kids because,
and I love your shirt, Jen, for free and human.
And it's like, maybe that could be like the,
like, is it like a combo of raising good humans
and just raising, I mean, again,
is we haven't read Mo Galback's book,
Scary Smiles Through Day to Play,
called the AI, we have malware like cobblers
and we should raise them like they raise our kids.
So we kind of, we show them what it means
to be a good person.
Like, what do we mean when we're a family person, right?
What do we mean when we're saying, I think human?
And how all the, you know, the interactions
you've had in real life, you know,
digitally living with that face.
Do you feel sorry?
Do you feel mean or do you try and do better?
Like, if that's, well, I don't know.
Like, John, even in that philosophy we talked about,
like, as humans, we can agree on what we mean
as to be a good human.
And then, you know, so if we can agree as humans
what it means to be good,
how will we going to teach a toddler?
Me do though, me do though.
If the systems are set,
and the intelligence is set to be generatory,
not to be generatory,
not to be generate, right?
I get what generative and other way it's like,
let's just break it down.
Like, if it is supposed to, like,
it's needed to create and not be destructive,
then let's have more people do that.
Well, I don't mind a real general,
but some things that just went into that,
like, you know, just more,
there's more inputs,
but more, more people
that are this one, two, kind of that.
Well, in some ways,
that's why I don't stop using AI,
like, let's get generative,
like, let's get that generative,
that I particularly worry about.
Let's get more people using it in a good way.
I'm a little bit more bullish, like, John,
I believe that you have 250 people that have signed this,
oh, who own a lot of the companies
that are working on this.
So the people that are saying it's a risk
also have the power to put guardrails
and to service leaders, and I urge you.
And I also believe that,
so if they say that's a problem
and we want to do something about it,
that's a good thing.
You've got, you know, you know,
you're always going to have the regulation come in.
Governments tend to be slower,
but I do believe you've got people that can stop it.
It's in a toddler stage.
As women, as moms, it's all of our responsibility
to make sure we have diversity of thought
in all the products that we're building,
in our marketing that we're doing,
making sure that we're hiring the right people for the roles,
and so we're not powerless if we all are raising good humans
and we're being good humans,
and we're making sure we're getting the right voices
at the table, then I believe that we can,
we're not going to stop it,
but I think we can use it for generative
and not degenerative purposes.
You're always going to have the nefarious folks
trying to do things,
but I do believe that these tech companies
know what they're doing and because they're funding.
And if they can actually start to say,
why don't we get a group together?
You can do something.
So I'm bullish.
I can see where it can go in dangerous places,
but I have to believe that humans can be better,
smarter to solve this.
Okay, so what do you think?
I've watched a ton of AI safety podcasts,
but I have never seen one quite like that before.
Real quick, I think Stephanie is right,
that AI safety is the wrong term.
It's boring and it's soft.
Let's talk about alternative terms to AI safety
in the comments, and honestly, I was surprised
and maybe even a bit disappointed
that all three moms did not fully buy my case
even after having heard it,
that human extinction from AI
is the most urgent threat we face.
I did not fully make the sale.
That was a little hard to take, but it's okay.
This takes time.
Quickly, my own mother, who I love dearly
and I think is an incredibly smart woman,
watched the first three episodes of this podcast
and was still telling me she didn't really fully get it,
but then after episode four,
she told me it started to make sense.
So that's how this is gonna go.
We, the ambassadors of this message,
let us not be discouraged
when someone is not immediately convinced
of what you're saying.
The idea of no life on earth at all
is something that is very difficult to process
for all of us, myself included,
but if we are to have a chance,
if our children are to have a chance,
we must go through the process,
we must try to save ourselves.
Thank you so much for watching.
Next week, we're gonna start pointing fingers
and naming names.
I'm ready to blame some people for all this.
Our next episode will be called
the top three doomers in AI,
and here's a hint,
they are not AI safety researchers at all.
For Humanity, I'm John Sherman.
I'll see you back here next week.
