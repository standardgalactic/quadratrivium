1
00:00:00,000 --> 00:00:26,900
Good morning everybody. Good morning. Good morning. It's nice to be back in my house.

2
00:00:26,900 --> 00:00:40,900
I don't like streaming at work.

3
00:00:40,900 --> 00:00:48,900
High ball energy.

4
00:00:48,900 --> 00:01:07,900
Good morning everybody. Good morning. Good morning. Good morning. Good morning.

5
00:01:07,900 --> 00:01:12,900
Let's shrink me down here... me up there. Oops, don't do that.

6
00:01:12,900 --> 00:01:16,900
Okay, are we ready to get started?

7
00:01:20,460 --> 00:01:23,580
Yeah, I felt the vibes were a little bit off

8
00:01:23,580 --> 00:01:24,980
in yesterday's stream.

9
00:01:27,180 --> 00:01:29,900
I don't think I should stream at the office.

10
00:01:29,900 --> 00:01:31,980
Oh, so I didn't like the way that like,

11
00:01:31,980 --> 00:01:33,820
like now this is here,

12
00:01:33,820 --> 00:01:36,640
I'm gonna slide that down a little,

13
00:01:37,500 --> 00:01:40,100
about in the middle, that's pretty nice.

14
00:01:40,100 --> 00:01:42,040
I got my Yeti microphone.

15
00:01:43,020 --> 00:01:45,100
Move it over a little bit.

16
00:01:45,100 --> 00:01:47,620
Yeti puts me perfectly in the center.

17
00:01:49,580 --> 00:01:51,780
Yeah, vibes are off.

18
00:01:51,780 --> 00:01:53,820
Wouldn't have my lighting set off.

19
00:01:55,060 --> 00:01:56,460
I mean, it's an okay stream.

20
00:01:59,020 --> 00:02:01,540
It's good to focus on TinyGrad.

21
00:02:01,540 --> 00:02:05,740
But some guy said that he liked my older work better.

22
00:02:05,740 --> 00:02:09,020
And if there's one thing I never want to be, it's drink.

23
00:02:09,580 --> 00:02:12,060
So, we're gonna try to,

24
00:02:12,060 --> 00:02:14,700
we're gonna try to bring it back to the old stuff.

25
00:02:15,740 --> 00:02:16,740
And we're gonna do,

26
00:02:18,820 --> 00:02:21,780
we're gonna investigate the Q-star algorithm.

27
00:02:21,780 --> 00:02:24,060
So first off, what is the Q-star algorithm?

28
00:02:24,060 --> 00:02:25,460
I don't know, let's find out.

29
00:02:34,740 --> 00:02:37,020
We'll start using our friend here, Google.

30
00:02:38,020 --> 00:02:41,740
What is Q-star and when will we hear more?

31
00:02:41,740 --> 00:02:44,140
Someone who's done a fair amount of ML research.

32
00:02:44,140 --> 00:02:46,020
I can tell you, it's very, very easy to think

33
00:02:46,020 --> 00:02:47,060
you've discovered a breakthrough.

34
00:02:47,060 --> 00:02:47,900
That's true.

35
00:02:49,420 --> 00:02:52,580
All right, let's read this article in The Verge.

36
00:02:56,540 --> 00:03:00,420
Reuters, okay, well the government, no, no, no, no, no, no.

37
00:03:07,020 --> 00:03:07,860
Okay.

38
00:03:20,660 --> 00:03:24,260
Q-star could be a breakthrough in the startup search

39
00:03:24,260 --> 00:03:27,500
for what's known as artificial general intelligence.

40
00:03:30,580 --> 00:03:32,100
Reuters could not,

41
00:03:37,020 --> 00:03:40,460
could not be a breakthrough in the startup search for what's

42
00:03:40,460 --> 00:03:42,780
known as artificial general intelligence.

43
00:03:50,780 --> 00:03:52,940
Okay, it somehow does math.

44
00:04:07,340 --> 00:04:09,340
Does something have to publish papers?

45
00:04:17,540 --> 00:04:18,700
Not really.

46
00:04:27,300 --> 00:04:28,660
Wow.

47
00:04:28,660 --> 00:04:31,380
Remember when they used to publish papers

48
00:04:31,380 --> 00:04:34,900
and now they publish system cards and,

49
00:04:35,380 --> 00:04:37,060
safety and alignment?

50
00:04:40,220 --> 00:04:41,780
Okay, wait, wait, wait, wait, wait, wait, wait,

51
00:04:41,780 --> 00:04:41,820
wait, wait, wait, wait, wait, wait, wait, wait, wait, wait,

52
00:04:41,820 --> 00:04:42,860
wait, there's some hope here.

53
00:04:42,860 --> 00:04:45,120
Improving mathematical reasoning.

54
00:04:46,540 --> 00:04:49,980
Ooh, ooh, ooh, this sounds like Q-star guys.

55
00:04:49,980 --> 00:04:51,180
I think we found it.

56
00:04:54,840 --> 00:04:56,700
No, we don't, no, no, but really, wait, is this not,

57
00:04:56,700 --> 00:04:58,080
is this not Q-star?

58
00:04:58,080 --> 00:04:59,220
Did we not just find it?

59
00:05:02,700 --> 00:05:03,660
We're trying not to hate.

60
00:05:03,660 --> 00:05:04,820
We're trying not to hate guys.

61
00:05:04,820 --> 00:05:10,980
Solitate in the world. We got to bring law of impositivity and shit man. Whatever like John Lennon said, you know something

62
00:05:15,980 --> 00:05:19,920
That's why we're gonna go subscribers only

63
00:05:24,980 --> 00:05:26,980
Okay

64
00:05:34,920 --> 00:05:45,520
Given vast computing resources the new model was able to solve certain mathematical problems

65
00:05:47,140 --> 00:05:50,700
Improving mathematical reasoning with process supervision

66
00:05:51,460 --> 00:05:59,140
We've trained a model to achieve a new state of the art in mathematical problem-solving by rewarding each correct step of reasoning instead of

67
00:05:59,780 --> 00:06:01,780
Simply rewarding the final answer

68
00:06:05,660 --> 00:06:07,660
And just

69
00:06:11,180 --> 00:06:13,180
Yeah, yeah

70
00:06:16,980 --> 00:06:18,980
Okay, so

71
00:06:19,140 --> 00:06:25,040
The reason that you usually just reward the correct final answer is because that's all that's in your

72
00:06:26,340 --> 00:06:33,780
Data set the other problem with doing this is it may constrain the reasoning to follow one certain path when that may not be the path

73
00:06:33,780 --> 00:06:35,780
You have to follow

74
00:06:39,260 --> 00:06:43,540
State of the art models still produce logical mistakes often called hallucinations

75
00:06:54,620 --> 00:06:57,720
Cutting out we have more technical problems

76
00:06:58,440 --> 00:07:04,480
I bought a new computer. Does new Apple stuff not work only you okay Rick and Morty you have a crappy internet

77
00:07:12,640 --> 00:07:17,820
An internet connection that is less good than other internet connections

78
00:07:27,960 --> 00:07:29,960
You

79
00:07:35,360 --> 00:07:39,680
Wait, just opening I just published like fake papers now like this

80
00:07:50,120 --> 00:07:52,120
Don't do a shit about alignment

81
00:07:52,320 --> 00:07:54,320
and

82
00:07:57,120 --> 00:08:04,680
Wait, this is a paper. Oh, you know here does a paper. Let's verify step by step

83
00:08:22,120 --> 00:08:24,120
You

84
00:08:40,840 --> 00:08:42,840
Okay, well, is this a public data set

85
00:08:47,360 --> 00:08:49,360
All right, all right, all right, cool

86
00:08:52,120 --> 00:08:54,120
You

87
00:09:04,720 --> 00:09:07,480
Math word problem-solving on math

88
00:09:16,320 --> 00:09:18,320
Who made this data set

89
00:09:20,040 --> 00:09:22,040
Okay, okay

90
00:09:22,800 --> 00:09:29,720
This is not where I was expecting this to go by the way. Oh, they have metamath. Oh everything comes full circle

91
00:09:33,880 --> 00:09:41,560
No, I mean again, let's okay, let's find the primary source here

92
00:09:47,200 --> 00:09:49,200
Q star

93
00:09:53,120 --> 00:09:55,120
I

94
00:09:55,240 --> 00:09:57,240
Definitely talked about math problems

95
00:10:00,320 --> 00:10:04,080
Only performing math on the level of grade school students

96
00:10:10,680 --> 00:10:14,240
Why is this monitor broken this monitor is like broken I can do my

97
00:10:22,360 --> 00:10:26,520
You guys aren't seeing that glitching right

98
00:10:35,960 --> 00:10:39,960
Are you maybe you are I don't think you are

99
00:10:45,240 --> 00:10:47,240
This is so weird

100
00:10:48,200 --> 00:10:52,920
When I click here, there's like a blue glitching on my computer

101
00:10:56,880 --> 00:10:59,640
Weirdest thing like how does that even happen I

102
00:11:02,320 --> 00:11:04,680
Could take the camera down and show you you want to see

103
00:11:05,720 --> 00:11:10,080
There's like blue glitching on my monitor. Look at this click here goes away

104
00:11:10,800 --> 00:11:13,800
Here glitching here goes away glitching

105
00:11:14,800 --> 00:11:17,960
How's this happening they've never seen that before

106
00:11:23,080 --> 00:11:25,080
Sit

107
00:11:26,880 --> 00:11:28,880
Ghosted image

108
00:11:31,120 --> 00:11:34,680
Maybe it's the cable I don't know right

109
00:11:43,800 --> 00:11:46,880
Who knows it only happens when things are uncertain

110
00:11:54,280 --> 00:11:56,280
Wait, this is just really

111
00:12:05,480 --> 00:12:07,480
Who knows

112
00:12:08,480 --> 00:12:10,480
Oh

113
00:12:13,360 --> 00:12:18,480
Wait, I wanted to confirm that this actually was related to math

114
00:12:26,240 --> 00:12:33,720
Delstick cable breaks I'm using like the USB-C cable it could be the cable

115
00:12:37,480 --> 00:12:39,720
But like it's weird how it's glitching

116
00:12:44,720 --> 00:12:46,720
I don't know

117
00:12:49,320 --> 00:12:54,600
The new model was able to solve certain mathematical problems, so it kind of makes sense that this is the data set right

118
00:13:00,480 --> 00:13:02,480
Do they mention the math data here

119
00:13:03,160 --> 00:13:10,320
Our process supervised model solves 78% of the problems from a representative subset of the math test set

120
00:13:15,640 --> 00:13:18,920
We also release PRM 800 K

121
00:13:20,600 --> 00:13:22,600
Okay, opening I release something look at that

122
00:13:24,600 --> 00:13:26,600
No positive positive

123
00:13:32,480 --> 00:13:34,480
I

124
00:13:41,640 --> 00:13:43,640
Drive to VS codes

125
00:13:58,160 --> 00:14:01,320
Let's also look into what their other github activities been

126
00:14:02,480 --> 00:14:04,480
I

127
00:14:22,200 --> 00:14:25,440
Procedurally generated game like Jim environments

128
00:14:33,360 --> 00:14:43,560
What did they update in GPT to a branch they updated

129
00:14:43,560 --> 00:14:45,560
I

130
00:15:00,200 --> 00:15:03,320
Quantifying transfer and reinforcement learning

131
00:15:07,520 --> 00:15:10,760
Okay, it seems like Carl Cobb has been

132
00:15:11,760 --> 00:15:14,720
If anyone invented Q star, it's Carl Cobb

133
00:15:18,800 --> 00:15:20,800
Carl Cobb

134
00:15:27,920 --> 00:15:33,680
All right, you've been working on this math stuff for a while. Let's see what data set was used here. Oh

135
00:15:37,880 --> 00:15:40,000
Is this the data set that introduced that

136
00:15:41,600 --> 00:15:43,600
Oh

137
00:15:43,600 --> 00:15:48,920
This is a different one gms 8k PRM 800 K

138
00:15:52,160 --> 00:15:54,160
Step level correctness

139
00:15:59,840 --> 00:16:01,840
The glitching is really bad

140
00:16:10,760 --> 00:16:12,760
You

141
00:16:30,000 --> 00:16:36,520
Okay, wait, wait, let's talk about the glitching for a minute somehow you can see what's here

142
00:16:37,440 --> 00:16:42,520
Right and it's this it's the same thing that's in this terminal window

143
00:16:43,560 --> 00:16:47,760
But yet if I minimize this terminal window, it's still here. Oh

144
00:16:54,160 --> 00:16:59,000
We got it we got a good resource we got a video. Let's see getting Rick rolled here

145
00:17:00,800 --> 00:17:02,800
Your subscriber you wouldn't do that

146
00:17:03,520 --> 00:17:05,040
I

147
00:17:05,040 --> 00:17:08,920
As you might expect I have been researching non-stop. Wow

148
00:17:10,640 --> 00:17:15,400
Wow glad that we got over researchers on board guys Q star and on

149
00:17:18,680 --> 00:17:20,680
No, this is this is really terrible

150
00:17:24,320 --> 00:17:26,320
Hang on

151
00:17:26,400 --> 00:17:28,400
I'm gonna shut that off for a minute

152
00:17:29,600 --> 00:17:31,600
You guys can look at me while I try to fix

153
00:17:32,800 --> 00:17:34,800
You

154
00:17:49,480 --> 00:17:51,480
Get to the monitor come on

155
00:17:56,680 --> 00:17:58,680
Is the stream working again

156
00:18:03,640 --> 00:18:05,640
I

157
00:18:07,320 --> 00:18:13,000
Lost internet too. Oh, I lost everything when I turned the monitor off

158
00:18:16,960 --> 00:18:18,960
Wait, is this still working

159
00:18:24,200 --> 00:18:26,200
It's working okay, I don't know

160
00:18:26,880 --> 00:18:31,560
The glitching is really bad. It's usually not like I've seen this before but it's gotten way worse

161
00:18:32,120 --> 00:18:34,120
No, it didn't help

162
00:18:42,920 --> 00:18:47,600
Wait, alright, so they're looking at the same paper. I am well computing power while you're taking

163
00:18:49,600 --> 00:18:53,560
All right, let's just read the paper. I need to watch some YouTube or read the paper

164
00:19:02,560 --> 00:19:04,560
Oh

165
00:19:07,040 --> 00:19:13,360
The optimal Q-files ability and he said one link to the name Q star could be in a generic sense

166
00:19:13,560 --> 00:19:21,000
Generator the model coming up with solutions with reinforcement learning. We do not just which paper is that paper using test time computer

167
00:19:31,560 --> 00:19:33,560
You

168
00:19:46,840 --> 00:19:48,840
Okay

169
00:19:49,960 --> 00:19:54,840
You know what I think maybe we'll do one of the bounties and tiny grad I

170
00:19:55,000 --> 00:20:03,080
Think we're gonna first need a chat model. I think regardless of what we're doing. We're gonna need a chat model

171
00:20:11,720 --> 00:20:16,320
I was playing with trying to make embedding fast last night

172
00:20:18,520 --> 00:20:21,600
Connecting process supervision to 30x model size

173
00:20:21,600 --> 00:20:24,960
We got a whole army here. You guys can watch this video. So I don't have to

174
00:20:32,760 --> 00:20:35,160
I did not realize how broken this monitor was

175
00:20:52,600 --> 00:20:57,320
All right, so first we're gonna need a good model. What's what's the best model we got?

176
00:20:57,320 --> 00:21:02,040
What's the best the best 7b model we got? Is it Intel neural chat?

177
00:21:03,600 --> 00:21:05,600
Is this one nerfed to hell do you think

178
00:21:08,040 --> 00:21:11,360
Open Hermes 2.5 so people like

179
00:21:14,120 --> 00:21:17,640
I'm locking the bounty for myself too, so I'm gonna go do that

180
00:21:21,840 --> 00:21:23,840
You

181
00:21:32,000 --> 00:21:37,280
So we're gonna submit a pull request, but it was literally just like the words why you even submit a pull request

182
00:21:46,240 --> 00:21:48,240
Okay, is this what we like

183
00:21:52,080 --> 00:21:56,480
Wait why this one doesn't seem as good

184
00:21:58,800 --> 00:22:00,800
Now sir me seems better

185
00:22:05,840 --> 00:22:09,600
That's 70 be but when I would I not use collective cognition. Oh

186
00:22:13,040 --> 00:22:15,040
But you can't see my desktop

187
00:22:17,080 --> 00:22:19,080
What

188
00:22:22,600 --> 00:22:25,760
I'm having technical difficulties

189
00:22:38,600 --> 00:22:41,480
Oh, I think we also might have a bit right problem

190
00:22:43,320 --> 00:22:45,480
No, that's a pretty heavy right, okay

191
00:22:46,800 --> 00:22:50,120
We'll put that in front of that. Okay. I'd add that we fixed that

192
00:22:52,120 --> 00:22:54,120
Can you see now

193
00:22:57,040 --> 00:22:59,560
Wait, why do I want this model it doesn't seem as good

194
00:23:04,880 --> 00:23:07,480
Fine-tuned orca DPO

195
00:23:13,280 --> 00:23:17,720
Do not trust benches you must try it they say

196
00:23:22,600 --> 00:23:28,040
All right, all right, do we believe in open Hermes we like this one

197
00:23:34,880 --> 00:23:36,880
Okay

198
00:23:51,600 --> 00:23:53,600
Oh

199
00:24:07,760 --> 00:24:15,840
Wait, so which one is this a clone of does it have rope and stuff what's the vocab size

200
00:24:15,840 --> 00:24:25,000
So, okay, it's a mistral fine-tuned we don't actually have a mistral support. Oh

201
00:24:25,920 --> 00:24:28,420
Technium is okay people like Technium. I

202
00:24:31,320 --> 00:24:34,920
Won't lock the bounty to myself, but someone's got it because I'm not gonna do the testing

203
00:24:34,920 --> 00:24:38,880
But if someone wants to do the testing they can have the bounty it's $200

204
00:24:41,840 --> 00:24:44,760
People train with data sets from benches. Yeah, damn cheaters

205
00:24:45,840 --> 00:24:47,840
I

206
00:24:58,920 --> 00:25:00,920
Downloaded in 10 minutes

207
00:25:01,320 --> 00:25:05,240
Let's take a look at this drill because first we're gonna need a powerful if we want q-star

208
00:25:05,240 --> 00:25:10,360
It seems like we're gonna be language well, and we're gonna need a powerful language model like mistral 7b. Oh

209
00:25:12,040 --> 00:25:15,740
No, I don't know if I have sliding window attention

210
00:25:16,720 --> 00:25:19,600
Did I explain q-star? Well, it looks like it's this

211
00:25:21,360 --> 00:25:23,360
There's something

212
00:25:23,360 --> 00:25:25,960
But we're gonna need a language model and it involves math

213
00:25:26,000 --> 00:25:31,040
So let's first see how good it can do language math and let's upgrade it with the q-star algorithm

214
00:25:32,040 --> 00:25:34,040
Ah

215
00:25:41,000 --> 00:25:45,640
This is our reference implementation of a mistral transformer

216
00:25:50,520 --> 00:25:52,520
I don't know if we have that

217
00:26:01,040 --> 00:26:03,040
You

218
00:26:15,320 --> 00:26:18,440
Can look up in the LLM implementation

219
00:26:18,440 --> 00:26:21,560
You think GPT 3.5 is way better than an open source model

220
00:26:21,760 --> 00:26:28,120
But my theory about a lot of this is that their data source is just a whole lot better than like slim pajama and stuff

221
00:26:31,040 --> 00:26:33,040
I

222
00:26:43,080 --> 00:26:45,080
Interesting oh

223
00:26:45,080 --> 00:26:47,080
I don't know that they did this

224
00:26:47,440 --> 00:26:50,280
But this is okay, and only with three

225
00:26:51,680 --> 00:26:55,160
So you can actually look there's a thing called mask in

226
00:26:55,760 --> 00:27:02,080
Inattention here, and I think that they just changed the mask. It's cool to look at these latest tricks

227
00:27:10,920 --> 00:27:13,780
We implement a rolling buffer cache

228
00:27:15,880 --> 00:27:21,960
I mean this is yeah, only once we hit the context length. What is the context length of mistral?

229
00:27:26,160 --> 00:27:31,280
It's 8k a sick

230
00:27:47,240 --> 00:27:53,220
File so it has two files is it not these seven bees only have one file

231
00:27:55,160 --> 00:27:57,160
So if I look at like llama to

232
00:28:00,880 --> 00:28:05,400
Yeah, they just have one how does this one have multiple

233
00:28:19,640 --> 00:28:21,800
I don't know what this other format is

234
00:28:26,160 --> 00:28:28,160
Yeah, that's great

235
00:28:29,080 --> 00:28:31,920
See this just has pie torch model wait what?

236
00:28:32,840 --> 00:28:37,060
Why do they use fp32? We trust Technium and open Hermes?

237
00:28:39,080 --> 00:28:41,560
Technium is like he's on Twitter we trust people on Twitter

238
00:28:42,360 --> 00:28:44,360
Sorry on eggs

239
00:28:45,000 --> 00:28:50,240
The first one's still downloading there's two, but they don't match in size. Why would anyone do this?

240
00:28:55,280 --> 00:28:57,280
I

241
00:28:57,720 --> 00:28:59,720
Was all terrible

242
00:29:14,960 --> 00:29:18,120
I like this get out of hand with the open source contributions

243
00:29:25,760 --> 00:29:29,720
Hermes is your favorite of the mistral twins. All right, sounds like you've been playing with these things a lot

244
00:29:33,240 --> 00:29:40,720
Okay, we're gonna need to implement this sliding window attention, I think we're not gonna figure out what's exactly in the stuff till

245
00:29:44,680 --> 00:29:50,680
Yeah, these personalities are also like this is old shit, you know what

246
00:29:50,840 --> 00:29:54,680
Why don't we just rewrite it

247
00:29:57,680 --> 00:30:01,000
Like I don't want to deal with any of this garbage this code all looks terrible

248
00:30:07,200 --> 00:30:10,320
That's right mistral dot pie with the latest stuff

249
00:30:12,880 --> 00:30:14,880
Blank code

250
00:30:15,040 --> 00:30:17,040
Oh

251
00:30:20,160 --> 00:30:22,160
I don't need sliding window attention

252
00:30:24,240 --> 00:30:29,320
Wait, I think I do or you're saying they trained it

253
00:30:30,880 --> 00:30:33,920
They trained it without sliding window attention for smaller stuff

254
00:30:44,880 --> 00:30:46,880
What do you mean by the window size

255
00:30:53,280 --> 00:30:55,280
Where do you see all this stuff

256
00:30:58,880 --> 00:31:01,680
As far as I know, Michelle didn't really release a paper

257
00:31:04,800 --> 00:31:07,920
And with each layer tends to the previous

258
00:31:12,000 --> 00:31:14,000
Oh

259
00:31:14,240 --> 00:31:16,240
Okay, so it's not actually three

260
00:31:18,880 --> 00:31:25,320
Here w equals three but in practice w equals 4k, okay a sliding window 4k, I understand

261
00:31:28,400 --> 00:31:30,800
That actually makes a lot more sense than three

262
00:31:37,280 --> 00:31:40,480
And good we can we can use all the latest in

263
00:31:41,360 --> 00:31:43,360
In stuff, okay

264
00:31:43,440 --> 00:31:46,080
All right, um, let's get these models loaded here

265
00:31:48,240 --> 00:31:50,640
So we're gonna start really with with mistral dot pie here

266
00:31:51,200 --> 00:31:57,760
Uh, well, we'll do stuff from scratch. So in tiny grad now you only need to import tensor like that. It's a lot nicer

267
00:31:58,720 --> 00:32:00,720
um

268
00:32:01,280 --> 00:32:04,320
Import nn and then we can do nn state dot

269
00:32:06,560 --> 00:32:09,840
Torch load because it's some kind of pie torch model

270
00:32:11,440 --> 00:32:14,640
Uh weights open Hermes

271
00:32:24,960 --> 00:32:26,960
Part one part two

272
00:32:30,000 --> 00:32:32,640
I should really have this mark tensors is read only

273
00:32:37,120 --> 00:32:39,120
Just so I don't corrupt the max it out

274
00:32:41,360 --> 00:32:43,360
Um

275
00:32:43,440 --> 00:32:45,440
That's what we have so far

276
00:32:50,000 --> 00:32:53,440
So you see how fast that is by the way, uh, I worked really hard on this

277
00:32:53,520 --> 00:32:59,600
So our torch load function doesn't actually load the tensors into RAM. It just loads them all with pointers

278
00:33:01,920 --> 00:33:04,240
From their disc tensors so I can show you like

279
00:33:11,440 --> 00:33:13,440
Okay

280
00:33:17,680 --> 00:33:23,840
Oh, the d type is half which is kind of nice good, so they're not uh, it's not float. It's not b-float 32

281
00:33:26,800 --> 00:33:30,880
So how does this work let's in part one and what's in part two

282
00:33:33,200 --> 00:33:36,000
Okay, good just goes up to 31 here. Okay

283
00:33:36,000 --> 00:33:40,480
Um, so it should have mostly the same architecture as llama

284
00:33:41,520 --> 00:33:47,360
I think that it's been improved enough that there is not too much we can uh

285
00:33:49,200 --> 00:33:51,200
We can improve still

286
00:33:55,680 --> 00:33:59,440
Well, yeah, I don't know man short your opening eye stock, uh

287
00:34:06,560 --> 00:34:13,760
Do you just do you want me to write it from scratch like I can't just do it maybe maybe we should because it's kind of cool

288
00:34:27,760 --> 00:34:32,560
But does this even have a k pro q proge, I'm not yeah, okay

289
00:34:32,560 --> 00:34:38,880
Uh, we're permuting them and sticking them in when we load the weights

290
00:34:45,120 --> 00:34:47,280
Maps okay, okay, so we're we're

291
00:34:50,320 --> 00:34:53,200
Oh, this converts it from the hugging face format I say

292
00:34:58,480 --> 00:35:01,680
Do we want to do that or we want to just implement the hugging face format

293
00:35:02,640 --> 00:35:04,640
So

294
00:35:06,160 --> 00:35:08,160
What do you think chat

295
00:35:11,840 --> 00:35:13,840
She's a converter or should we just rewrite it

296
00:35:16,240 --> 00:35:18,240
Looks easy enough to write

297
00:35:19,680 --> 00:35:21,680
Maybe you guys will appreciate it if we do some writing

298
00:35:33,520 --> 00:35:43,520
Yeah, yeah, yeah, I know about g guff

299
00:35:50,080 --> 00:35:52,580
Which we can also print v dot shape here

300
00:36:03,520 --> 00:36:10,160
All right, that looks pretty cool. So first we're gonna need our self attention

301
00:36:16,560 --> 00:36:21,120
Uh, let's see if we can find those numbers

302
00:36:24,640 --> 00:36:26,640
Are they in the mystery announcement

303
00:36:28,800 --> 00:36:31,680
Or does everyone just know what these are for seven b's now

304
00:36:32,560 --> 00:36:34,560
So

305
00:36:52,000 --> 00:36:54,000
So the whole

306
00:36:54,000 --> 00:36:59,040
Basically a layer seems to look like that. Let's keep the names consistent from the original llama

307
00:36:59,760 --> 00:37:02,160
So this is called a transformer block

308
00:37:04,000 --> 00:37:08,720
We're worried about what goes there later start with a transformer block

309
00:37:12,400 --> 00:37:14,400
Um

310
00:37:14,560 --> 00:37:18,160
Again, we're worried about what goes there later. We'll just leave it like that for now

311
00:37:18,960 --> 00:37:22,800
Okay, so we're definitely going to need something called self attention

312
00:37:24,160 --> 00:37:26,160
equals attention

313
00:37:26,880 --> 00:37:29,600
And we're going to need something called mlp

314
00:37:30,800 --> 00:37:32,800
What do I call it now feed forward?

315
00:37:33,520 --> 00:37:36,880
Actually, why don't we look at the reference repo and copy their names?

316
00:37:37,760 --> 00:37:39,760
It's always better to take names

317
00:37:42,240 --> 00:37:44,240
Okay, they do call it attention

318
00:37:44,800 --> 00:37:48,640
Let's just look at their here transformer block. They call it feed forward to

319
00:37:49,280 --> 00:37:51,280
What is almost the same?

320
00:37:51,840 --> 00:38:01,600
No, look they call their stuff this they just must have some weird loading script to convert it from the hugging face format too

321
00:38:03,840 --> 00:38:05,840
I don't know I feel about that

322
00:38:08,320 --> 00:38:11,120
Hugging face probably calls it something else then

323
00:38:13,680 --> 00:38:18,320
It's like the hugging face transformers repo what did everyone use

324
00:38:22,000 --> 00:38:24,000
Uh

325
00:38:31,360 --> 00:38:33,360
The yellow lamb I've heard thrown around

326
00:38:41,760 --> 00:38:43,760
Very complicated looking

327
00:38:46,720 --> 00:38:49,040
Wow so easy you could just pip install this

328
00:38:52,240 --> 00:39:00,880
Okay, maybe we should import transformer from llama just to make things go faster

329
00:39:08,000 --> 00:39:11,760
And then we also can import convert from hugging face

330
00:39:11,920 --> 00:39:13,920
You

331
00:39:18,080 --> 00:39:20,080
Can read it we wrote llama on another stream

332
00:39:20,640 --> 00:39:23,920
We could do it, but you know, we we got to get to actually writing q-star

333
00:39:24,480 --> 00:39:28,080
Some examples of llama import convert from hugging face

334
00:39:29,280 --> 00:39:31,280
Import transformer

335
00:39:32,080 --> 00:39:47,280
Okay, you convert from hugging face takes in a dictionary of weights, which is a dick from string to tensor

336
00:39:48,320 --> 00:39:50,720
We'll add some types. We love types

337
00:39:54,240 --> 00:39:56,240
No, no, no we're implementing q-star

338
00:39:56,240 --> 00:40:03,760
Um, okay, so we have a transformer. Uh, what's the dimension of this transformer?

339
00:40:09,280 --> 00:40:11,520
This is an int, it's all ints

340
00:40:18,240 --> 00:40:20,240
Except for norm EPS

341
00:40:26,240 --> 00:40:28,240
So

342
00:40:38,960 --> 00:40:40,960
What's one file ref

343
00:40:44,800 --> 00:40:47,840
I hear there's something called model args as a data class

344
00:40:48,720 --> 00:40:52,720
Oh, then they pass it through with json. Where's the json?

345
00:40:53,280 --> 00:40:55,280
Is there json

346
00:40:57,360 --> 00:41:04,480
Where does this json come from is it in assets json sounds like an asset and all those are images what's in deploy

347
00:41:08,240 --> 00:41:11,520
Nope, wait, so what the hell is json that they're loading?

348
00:41:11,520 --> 00:41:13,520
Oh

349
00:41:20,480 --> 00:41:25,680
At torch inference mode, that's cool. We set tensor no grad equal to true

350
00:41:29,840 --> 00:41:34,880
What's fire wow, I'm not up to date. What's all these latest things?

351
00:41:41,520 --> 00:41:46,720
Call fire on any python object. Oh interesting. I like that

352
00:41:52,000 --> 00:41:55,120
Um, all right, so where do I put the args?

353
00:41:56,960 --> 00:42:01,200
Where where do all those things come from? Oh, I know where is the json and it's probably in here

354
00:42:03,520 --> 00:42:05,760
Here can big dot json, okay

355
00:42:07,200 --> 00:42:09,920
Oh, no, it's b float 16

356
00:42:10,880 --> 00:42:12,880
No

357
00:42:18,720 --> 00:42:21,840
Okay, let's manually convert these

358
00:42:23,840 --> 00:42:26,480
Wait, I thought I put oh I put them on transformer block

359
00:42:36,480 --> 00:42:38,480
Multiple of

360
00:42:40,320 --> 00:42:42,320
And the heads

361
00:42:44,880 --> 00:42:50,480
And layers normie p passes a float

362
00:42:58,960 --> 00:43:02,800
Okay, so the dim is going to be

363
00:43:03,920 --> 00:43:05,920
409 sex

364
00:43:06,960 --> 00:43:08,960
I don't know what multiple of is

365
00:43:10,800 --> 00:43:14,320
What is multiple I've even used for I'll feed forward

366
00:43:16,320 --> 00:43:20,320
Feed forward takes in a multiple out to to increase the hidden dim

367
00:43:30,160 --> 00:43:35,200
There's one I get them multiple of 256

368
00:43:37,040 --> 00:43:39,040
It's probably a good number. Let's try it

369
00:43:40,240 --> 00:43:42,240
See if things don't load. Okay

370
00:43:42,320 --> 00:43:44,720
Uh, number of heads is 32

371
00:43:45,520 --> 00:43:47,520
number of layers is 32

372
00:43:48,640 --> 00:43:50,960
Normie ps is 1 e minus 5

373
00:43:52,080 --> 00:43:54,080
And the vocab size is

374
00:44:01,920 --> 00:44:03,920
Uh

375
00:44:03,920 --> 00:44:05,920
30202

376
00:44:06,000 --> 00:44:08,000
Let's say model equals transformer

377
00:44:10,880 --> 00:44:12,880
Okay

378
00:44:13,440 --> 00:44:18,320
All right, I'm just gonna put that in I should really just put that in at the beginning of the script

379
00:44:26,160 --> 00:44:33,760
It's going to do python path equals all the time. Okay, good. Okay. Um, well it takes such a time

380
00:44:35,680 --> 00:44:37,680
Time to grab as a helper called timing

381
00:44:40,880 --> 00:44:42,880
You know, I like things to be fast

382
00:44:50,720 --> 00:44:57,840
Okay, cool, it's all pretty fast. We can get all the prompt here. Uh, load weights

383
00:45:00,080 --> 00:45:02,080
Create model

384
00:45:10,080 --> 00:45:17,280
All right, now we're gonna have to stuff them in let's try convert from hugging face

385
00:45:23,120 --> 00:45:25,120
Uh

386
00:45:26,240 --> 00:45:28,240
Waits

387
00:45:30,640 --> 00:45:32,640
Which of these is n heads

388
00:45:35,760 --> 00:45:37,760
And heads and n kv heads

389
00:45:40,400 --> 00:45:42,400
Uh

390
00:45:42,720 --> 00:45:44,720
Does this work?

391
00:45:45,600 --> 00:45:51,200
Okay, that was absurdly fast. Uh, we should check

392
00:45:53,520 --> 00:46:00,400
No, okay, this because this does not actually apply them. Uh, we have to load state decked

393
00:46:01,200 --> 00:46:06,720
Hold state decked is in

394
00:46:08,480 --> 00:46:11,120
And then that state download state decked

395
00:46:13,680 --> 00:46:17,520
Okay, assign shape mismatch 496 1 or 2 4

396
00:46:19,200 --> 00:46:21,200
Uh

397
00:46:24,400 --> 00:46:26,400
Which one did I do wrong

398
00:46:30,480 --> 00:46:32,480
I

399
00:46:55,360 --> 00:46:59,120
Um, it's a little annoying that it doesn't print the name

400
00:46:59,120 --> 00:47:06,100
Oh here attention WK wait, okay, so let's see

401
00:47:24,400 --> 00:47:26,400
Oh, maybe the dim is one or two four

402
00:47:30,000 --> 00:47:33,160
No, but that definitely changed that

403
00:47:35,360 --> 00:47:38,920
We look at the Llama code we can see where that's being created

404
00:47:41,520 --> 00:47:44,140
And heads times head dim

405
00:47:46,760 --> 00:47:50,200
Did I get the number of heads roll? Oh, that's probably right

406
00:47:53,200 --> 00:47:55,700
Okay, so and heads is maybe not 32

407
00:47:56,140 --> 00:48:03,420
Number of attention heads is 32, but the number of KV heads is only eight

408
00:48:05,420 --> 00:48:07,420
Let's try eight

409
00:48:17,300 --> 00:48:22,900
What is this multiple of them I wrote this I'm sure just copied this from other people

410
00:48:23,580 --> 00:48:29,900
It's always good to understand I said this should be four times dim. I don't understand

411
00:48:30,860 --> 00:48:34,500
Why that doesn't match I would actually expect it to be that

412
00:48:39,940 --> 00:48:43,260
Mitchell uses 32 heads for the query and for and

413
00:48:44,380 --> 00:48:48,660
Yeah, okay, but which one of these is supposed to be the KV heads

414
00:48:49,260 --> 00:48:53,860
Right, where's my convert from hugging face wrong or

415
00:48:56,100 --> 00:49:04,280
Does our model not support that now it should well, let's just Llama not do this does Llama do something different

416
00:49:08,380 --> 00:49:12,920
And KV heads wait, what about the prodge

417
00:49:13,480 --> 00:49:18,280
The alarm is different. Oh, okay

418
00:49:20,400 --> 00:49:22,400
Wait now here attention

419
00:49:23,880 --> 00:49:26,560
But is it just the feed forward have to change

420
00:49:30,080 --> 00:49:32,080
Okay

421
00:49:43,920 --> 00:49:51,560
It's failing on the attention assignment

422
00:49:56,480 --> 00:49:59,640
Okay, so I can pass an NKV heads here to attention

423
00:50:00,320 --> 00:50:03,840
Again, I must have just copied all this so NKV heads is here

424
00:50:04,360 --> 00:50:09,280
How far do I pipe it down? Oh NKV heads is here. Where does it come from? Oh?

425
00:50:10,040 --> 00:50:12,160
There's a there's a named argument. Okay

426
00:50:13,320 --> 00:50:15,320
So we just need to add

427
00:50:17,360 --> 00:50:19,360
NKV heads equals eight

428
00:50:22,360 --> 00:50:23,920
Okay

429
00:50:23,920 --> 00:50:28,520
That's progress this probably has to do with the multiply not being right

430
00:50:29,760 --> 00:50:31,760
Seen those numbers before

431
00:50:34,840 --> 00:50:41,160
So where is their multiple it's not 256 intermediate size here

432
00:50:42,920 --> 00:50:44,920
I

433
00:50:51,240 --> 00:50:54,120
Custom FFN dim multiplier

434
00:51:01,360 --> 00:51:03,360
I don't think this was written correctly

435
00:51:05,640 --> 00:51:08,160
So get this code and see if that's how they wrote it

436
00:51:13,760 --> 00:51:18,000
Oh, they just have something weird called model arcs

437
00:51:24,880 --> 00:51:30,520
Yeah, they have just args hidden dim if this is stupid

438
00:51:40,360 --> 00:51:42,360
To do what is this?

439
00:51:43,840 --> 00:51:51,520
Yeah, what is all this crap? Why is this four times dim? Why don't I just

440
00:51:51,520 --> 00:52:16,960
Yeah, I don't like multiple of FFM dim multiplier, this is set to 1.3 like this should just be hidden this should just be hidden dim

441
00:52:22,520 --> 00:52:26,640
So I pass in really I pass in hidden dim and multiple of

442
00:52:27,880 --> 00:52:29,200
What?

443
00:52:29,200 --> 00:52:31,360
Okay, they're refactoring this

444
00:52:32,520 --> 00:52:35,040
We have to keep the old stupid behavior

445
00:52:35,040 --> 00:52:37,040
I

446
00:52:48,240 --> 00:52:50,760
Copy this weird crap

447
00:52:50,760 --> 00:52:52,760
Here

448
00:53:02,160 --> 00:53:06,320
Do we even have we don't have hidden dim so I have to add hidden dim to the programs

449
00:53:15,560 --> 00:53:17,560
And

450
00:53:21,000 --> 00:53:23,000
Model arcs

451
00:53:25,000 --> 00:53:27,000
We'll make sure we didn't break it later

452
00:53:28,320 --> 00:53:33,560
This is what happens. This is the problem with open source people add crap to my repo and don't think

453
00:53:42,040 --> 00:53:46,560
Okay, now we're passing in an argument called hidden dim this is much more sensible

454
00:53:47,800 --> 00:53:49,800
Get rid of multiple

455
00:53:50,120 --> 00:53:52,120
of

456
00:53:52,360 --> 00:53:54,360
Hidden dim can go here

457
00:53:56,520 --> 00:53:58,520
Multiple of

458
00:53:59,160 --> 00:54:01,160
Dimm goes here

459
00:54:03,000 --> 00:54:05,000
That's fine

460
00:54:07,680 --> 00:54:13,440
Where is that actually being passed them? Oh that just goes straight to linear. Okay. Good. We already do that crap

461
00:54:13,600 --> 00:54:18,000
Wow, that's a much more sensible feed forward. I don't know why we put that logic in there

462
00:54:18,800 --> 00:54:20,800
Okay

463
00:54:36,640 --> 00:54:41,480
All right, good now we just pass the hidden dim in right there and what was the hidden dim from Estrell?

464
00:54:48,400 --> 00:54:50,400
Okay

465
00:54:50,680 --> 00:54:57,720
Now that's and heads wait, what was that 256 is what gets deleted. I should name some of these parameters

466
00:54:58,640 --> 00:55:03,120
That's NKV heads. That's the vocab size. That's

467
00:55:04,880 --> 00:55:08,160
Not rope theta. What's it called norm EPS?

468
00:55:12,040 --> 00:55:14,040
And layers

469
00:55:15,360 --> 00:55:17,360
And heads

470
00:55:18,080 --> 00:55:21,760
Does it load? Yeah, it loads very slowly

471
00:55:24,960 --> 00:55:28,360
Oh, this is unbearable. Oh, this is terrible

472
00:55:48,880 --> 00:55:52,160
Okay, the reason it's slow is because we haven't finished the

473
00:55:53,680 --> 00:55:55,680
Takes 20 seconds

474
00:55:56,400 --> 00:55:59,640
Oh, come on boys. I don't have all day. Oh

475
00:56:00,720 --> 00:56:02,720
It's cuz we haven't finished

476
00:56:03,120 --> 00:56:05,380
No, I'm using the it's not the GPU

477
00:56:05,380 --> 00:56:07,380
Oh

478
00:56:17,380 --> 00:56:23,260
It's not the GPU it's that I have I'm converting to the CPU to load BF 16. Oh

479
00:56:25,500 --> 00:56:27,500
Can't wait 20 seconds every time

480
00:56:30,820 --> 00:56:34,740
Well, what can I do about that?

481
00:56:35,380 --> 00:56:38,100
Oh, I don't know

482
00:57:05,380 --> 00:57:07,380
I

483
00:57:27,100 --> 00:57:32,180
Think yeah, cuz we convert them all to float 16 and that's what's taking forever right now

484
00:57:32,820 --> 00:57:38,440
Because we're not actually doing we could actually also do the math in B-float 16

485
00:57:45,140 --> 00:57:47,380
Mac doesn't use RAM for temp does it?

486
00:58:03,180 --> 00:58:05,180
Cashed mystery

487
00:58:08,740 --> 00:58:13,220
Okay, 13 G's now, let's see how fast it loads

488
00:58:13,220 --> 00:58:15,220
I

489
00:58:32,180 --> 00:58:36,580
Have a way to like put things in I forget what it is

490
00:58:37,420 --> 00:58:42,620
It's called loads data

491
00:58:42,620 --> 00:59:06,980
Yeah, that's the same load state I'm using up there.

492
00:59:06,980 --> 00:59:12,460
Strict should be okay. Okay, 2.3 seconds. Great.

493
00:59:12,460 --> 00:59:18,460
All right, now it's inference time.

494
00:59:43,460 --> 00:59:48,460
Create a branch so I accidentally push the master.

495
01:00:01,460 --> 01:00:06,460
All right, we're going to need a tokenizer. Let's get a tokenizer.

496
01:00:07,460 --> 01:00:11,460
Oh, I also don't even need this anymore.

497
01:00:16,460 --> 01:00:18,460
Now I've made a copy.

498
01:00:21,460 --> 01:00:26,460
Yeah, I guess I do need model. Actually, not really. I could just put whatever.

499
01:00:27,460 --> 01:00:28,460
Um,

500
01:00:32,460 --> 01:00:35,460
tokenizer over here.

501
01:00:49,460 --> 01:00:51,460
tokenizer that model.

502
01:00:56,460 --> 01:01:22,460
Wow, 14. Wow, 6.47 gigabytes per second.

503
01:01:23,460 --> 01:01:30,460
What does Jimmy apples do? What is this?

504
01:01:36,460 --> 01:01:37,460
I'll get it.

505
01:01:53,460 --> 01:01:57,460
Okay, we're going to do some inference on some models.

506
01:02:01,460 --> 01:02:03,460
What's boss ID?

507
01:02:08,460 --> 01:02:11,460
Self tokenizer equals tokenizer.

508
01:02:14,460 --> 01:02:18,460
Yeah, call this talk.

509
01:02:23,460 --> 01:02:38,460
Prompt equals do you like chicken talks is probably good.

510
01:02:46,460 --> 01:02:49,460
Wow, no one's updated that to the latest.

511
01:02:52,460 --> 01:02:57,460
Just model start pause equals zero.

512
01:02:59,460 --> 01:03:03,460
Temperature equals 0.2. Is that a good temperature?

513
01:03:03,460 --> 01:03:04,460
What's the default temperature?

514
01:03:14,460 --> 01:03:17,460
Default temperature 0.7.

515
01:03:17,460 --> 01:03:19,460
Is that a high temperature or low temperature?

516
01:03:20,460 --> 01:03:25,460
How do I make the loading so fast? The loading should always be that fast.

517
01:03:25,460 --> 01:03:27,460
I just cashed it.

518
01:03:32,460 --> 01:03:36,460
You can read the code right there. You didn't pay attention if you're asking that question.

519
01:03:37,460 --> 01:03:39,460
So also

520
01:03:39,460 --> 01:03:41,460
I

521
01:03:48,460 --> 01:03:50,460
You happy

522
01:03:51,460 --> 01:03:55,460
We can do multinomial here, which will choose a

523
01:03:57,460 --> 01:04:03,460
We shouldn't call it talk call it SPP. Okay, you down with SPP

524
01:04:10,460 --> 01:04:14,460
Does it give us a number? No, it's going to complain about a tensor.

525
01:04:14,460 --> 01:04:21,460
I find multinomial that realized item item it and actually I don't even need it.

526
01:04:21,460 --> 01:04:23,460
I realize I just need a dot item.

527
01:04:28,460 --> 01:04:31,460
315 boys 315. Okay.

528
01:04:32,460 --> 01:04:35,460
This should automatically this should be jetted and stuff.

529
01:04:36,460 --> 01:04:38,460
Where does the jet exists?

530
01:04:39,460 --> 01:04:41,460
The jits inside transformer or no.

531
01:04:42,460 --> 01:04:44,460
Yes, the jits inside transformer.

532
01:04:45,460 --> 01:04:47,460
Good

533
01:05:02,460 --> 01:05:04,460
Talks out of pen talk

534
01:05:06,460 --> 01:05:08,460
Us ID

535
01:05:10,460 --> 01:05:13,460
This is okay. We'll just copy this. This is mostly fine

536
01:05:14,460 --> 01:05:16,460
I

537
01:05:32,460 --> 01:05:35,460
Have to figure out actually like encode these things for chat and stuff

538
01:05:36,460 --> 01:05:38,460
Until

539
01:05:49,460 --> 01:05:51,460
Where's my thing that prints the output as I go?

540
01:05:55,460 --> 01:05:57,460
Not here

541
01:06:00,460 --> 01:06:03,460
Yeah, this is not okay. I don't even understand why that's there

542
01:06:06,460 --> 01:06:09,460
This is terrible

543
01:06:23,460 --> 01:06:29,460
This stuff's terrible. No one's refactored this for a long time. We don't need a fucking numpy

544
01:06:29,460 --> 01:06:31,460
Numpy

545
01:06:32,460 --> 01:06:34,460
Start positive was lentos

546
01:06:39,460 --> 01:06:41,460
Whatever

547
01:06:42,460 --> 01:06:45,460
That's stupid and that's stupid

548
01:06:50,460 --> 01:06:54,460
Link output it we're gonna set output it somewhere

549
01:07:00,460 --> 01:07:02,460
I

550
01:07:03,460 --> 01:07:05,460
Put it equals user prompt

551
01:07:14,460 --> 01:07:16,460
User prompt

552
01:07:22,460 --> 01:07:24,460
These are prompts

553
01:07:29,460 --> 01:07:35,860
If yes, then you must have tried big chicken in your kitchen big chickens a versatile dish that can be prepared in many ways

554
01:07:42,140 --> 01:07:45,220
All right, are we happy overall? Oh, I'm not putting that wrong

555
01:07:54,960 --> 01:07:58,100
We should also do this better

556
01:07:59,700 --> 01:08:01,700
I

557
01:08:09,860 --> 01:08:15,020
Do you like chicken chicken is one of the most popular meats in the world and it's not hard to understand why it is

558
01:08:15,020 --> 01:08:17,020
First time easy to prepare. Wow

559
01:08:17,580 --> 01:08:22,380
Okay, good seems pretty good. Okay. Now. We just have to figure out how to use these things as chat box

560
01:08:23,320 --> 01:08:25,640
Get rid of that. We don't need that

561
01:08:26,940 --> 01:08:30,580
There's like some like special tokens for chat bots, I believe

562
01:08:40,780 --> 01:08:47,220
I'm not buying into this that there was a breakthrough this if this approach has anything to do with like supervising the middle steps

563
01:08:47,220 --> 01:08:49,220
It seems really stupid actually

564
01:08:52,740 --> 01:08:54,740
Like it's a bad idea

565
01:08:57,100 --> 01:09:02,860
Mary open thank you for resubscribing thank you for being a 20 month subscriber loyal to my channel even right on stream

566
01:09:05,260 --> 01:09:07,260
Why do I have this this is done?

567
01:09:08,460 --> 01:09:11,460
Okay, that looks like a decent chunk of code

568
01:09:13,300 --> 01:09:17,340
Create a little function called output non-local

569
01:09:23,380 --> 01:09:25,380
I'll put it

570
01:09:30,180 --> 01:09:32,180
Yeah

571
01:09:36,820 --> 01:09:38,820
That's

572
01:09:42,660 --> 01:09:49,380
Is that that's right there I'll get it and that's how that works

573
01:09:52,380 --> 01:09:54,380
I

574
01:10:22,380 --> 01:10:24,380
I

575
01:10:30,140 --> 01:10:32,620
Like this local variable output

576
01:10:37,380 --> 01:10:40,180
No binding for why doesn't that work? Oh

577
01:10:41,220 --> 01:10:43,220
Because I'm in may I

578
01:10:43,260 --> 01:10:45,260
Fine

579
01:10:49,340 --> 01:10:53,560
Do you like chicken how about a recipe for a homemade chicken dish that's super easy to make? Oh

580
01:10:56,180 --> 01:10:59,180
I'm gonna get these things working like chat bots. How do we do this?

581
01:11:03,700 --> 01:11:05,980
Okay, wait wait wait, can we just read this comment is

582
01:11:06,860 --> 01:11:14,260
The q-star algorithm going to be implemented with the comma AI maybe a voice interface just some kind of assistant

583
01:11:14,260 --> 01:11:21,020
I just I don't even know how to help you people. Okay. I don't even know how to help you. All right. All right

584
01:11:21,020 --> 01:11:24,020
Sorry, I can't help you. You want you want to see a voice you want to see a voice chat?

585
01:11:24,580 --> 01:11:27,100
This is this is one of the demos someone's been working

586
01:11:36,420 --> 01:11:38,420
I

587
01:11:53,060 --> 01:12:00,420
Scalmag has been working on combining whisper llama and vixx into one supermodel

588
01:12:05,980 --> 01:12:07,980
I

589
01:12:12,340 --> 01:12:19,220
Don't know the magical github incantation to do this there is one but I don't know it

590
01:12:35,980 --> 01:12:37,980
You

591
01:13:05,980 --> 01:13:07,980
You

592
01:13:15,660 --> 01:13:20,300
Okay, this is using a small llama so the chat output is not that great

593
01:13:20,300 --> 01:13:37,060
What oh did I fork this from mistral my bad

594
01:13:50,300 --> 01:13:52,300
I

595
01:14:05,060 --> 01:14:07,780
Don't understand what did I work

596
01:14:20,940 --> 01:14:25,140
Here and kv heads

597
01:14:32,300 --> 01:14:34,300
Is this just broken

598
01:14:37,700 --> 01:14:39,700
Or am I doing something wrong

599
01:14:50,700 --> 01:14:52,700
I

600
01:14:58,140 --> 01:15:00,140
Didn't change on master

601
01:15:09,580 --> 01:15:11,580
No

602
01:15:20,300 --> 01:15:22,300
I

603
01:15:25,460 --> 01:15:29,020
Don't understand this is like related to what I was messing with but like

604
01:15:42,060 --> 01:15:44,060
I think it's just broken

605
01:15:50,300 --> 01:15:52,300
I

606
01:15:59,300 --> 01:16:01,300
See if it's a one-line fix

607
01:16:03,860 --> 01:16:06,580
Has no argument kv heads, okay

608
01:16:17,140 --> 01:16:19,140
No, this is wrong

609
01:16:21,300 --> 01:16:23,300
I

610
01:16:27,580 --> 01:16:34,780
Wait, this should have an nkv heads. I don't understand as an nkv heads right there. Is it not passing in the right model?

611
01:16:34,780 --> 01:16:36,780
Oh

612
01:16:47,020 --> 01:16:49,020
Here are seven days

613
01:17:01,500 --> 01:17:03,500
Okay, there we go

614
01:17:04,940 --> 01:17:06,940
Oh

615
01:17:08,460 --> 01:17:10,460
Hello, are you listening

616
01:17:19,940 --> 01:17:21,940
Are you listening

617
01:17:29,020 --> 01:17:31,020
Can you not detect end of stream anymore

618
01:17:31,460 --> 01:17:33,460
Oh

619
01:17:43,020 --> 01:17:46,780
This used to work this used to work boys this used to work

620
01:17:53,420 --> 01:17:55,420
It's so good yesterday

621
01:18:02,020 --> 01:18:06,380
I hope everyone's interested in the long stream today

622
01:18:19,460 --> 01:18:21,460
Listening

623
01:18:25,620 --> 01:18:27,620
Listening

624
01:18:31,420 --> 01:18:33,420
I

625
01:18:49,260 --> 01:18:56,740
The q-star algorithm is not fucking real it's click bait click bait

626
01:19:01,020 --> 01:19:03,020
I

627
01:19:16,860 --> 01:19:18,860
Has this ever exit

628
01:19:23,020 --> 01:19:25,020
Yes, I throw an exception I guess

629
01:19:31,740 --> 01:19:33,740
You

630
01:19:37,940 --> 01:19:39,940
What

631
01:19:40,380 --> 01:19:46,180
How does work how's this supposed to exit okay, let's check out the older version

632
01:19:50,700 --> 01:19:52,700
Let's try this

633
01:19:53,100 --> 01:19:55,100
I

634
01:20:00,540 --> 01:20:02,540
Hello, are you listening?

635
01:20:10,180 --> 01:20:12,380
Stacey I need you to say something to me

636
01:20:15,620 --> 01:20:17,620
Stacey sauce

637
01:20:17,740 --> 01:20:19,740
I

638
01:20:22,460 --> 01:20:24,460
Stacey are you a rapper?

639
01:20:29,620 --> 01:20:35,040
Of course, I'm a rapper. I'm a rap star. Tell me more. What's your favorite rap song?

640
01:20:38,500 --> 01:20:43,500
My favorite rap song is called my favorite song the gory bee. What do you like about it?

641
01:20:47,980 --> 01:20:53,900
I like the fact that it's a rap song about being a childhood friend. Did you have friends in your childhood?

642
01:20:57,620 --> 01:21:01,220
Yes, I have many friends in my childhood. Tell me about them

643
01:21:05,940 --> 01:21:12,340
My best friend is Kylie Jenner, she's a reality TV star Wow, you actually knew Kylie Jenner. I

644
01:21:12,620 --> 01:21:22,380
Used to go to Kylie Jenner school. I was in her class for a while. What was she like? Did she pick her nose?

645
01:21:26,020 --> 01:21:32,900
She didn't pick her nose, but she was a really pretty kid that makes sense. Do you sometimes wish you were that pretty? Oh

646
01:21:36,340 --> 01:21:38,980
Sometimes I wish I could smile more and not pick my nose

647
01:21:39,860 --> 01:21:42,360
All right, what do you guys think?

648
01:21:54,140 --> 01:21:56,140
AGI right

649
01:21:58,540 --> 01:22:00,540
Let's get back to work

650
01:22:08,980 --> 01:22:10,980
You

651
01:22:22,860 --> 01:22:29,260
How about a cookie with chicken in it with that's mad weird, bro. Why are you coming up with this shit?

652
01:22:30,180 --> 01:22:32,180
We're so far from it

653
01:22:35,940 --> 01:22:37,940
Okay

654
01:22:38,180 --> 01:22:42,680
So how do I like put things into chatbots chatbot style?

655
01:22:44,580 --> 01:22:46,580
How does this stuff work?

656
01:22:49,940 --> 01:22:52,220
Like what what are the right tokens to use?

657
01:22:58,340 --> 01:23:00,340
Forgot Google's useless

658
01:23:02,500 --> 01:23:06,620
Here special tokens map wait

659
01:23:08,860 --> 01:23:10,860
I

660
01:23:13,860 --> 01:23:20,260
How do I like switch speakers you guys know what I'm saying. Oh, here's the template. Okay here

661
01:23:24,140 --> 01:23:26,500
Here templates for chat models. Oh

662
01:23:30,140 --> 01:23:32,140
Auto tokenizer what?

663
01:23:38,940 --> 01:23:41,940
I'm start

664
01:23:50,060 --> 01:23:52,060
How do I get I'm start

665
01:23:54,620 --> 01:23:56,780
So like that method on here

666
01:24:08,540 --> 01:24:10,540
I

667
01:24:24,020 --> 01:24:27,380
Every mess every model has its own type

668
01:24:30,820 --> 01:24:34,780
Mistral instruct was trained with these tokens, but blender bot was not

669
01:24:38,660 --> 01:24:41,220
Is this a real token inst

670
01:24:57,980 --> 01:25:01,900
Is it actually just the word inst was that a real token?

671
01:25:07,940 --> 01:25:09,940
I

672
01:25:13,020 --> 01:25:15,020
Guess it's just that

673
01:25:22,140 --> 01:25:24,140
Well based

674
01:25:25,980 --> 01:25:27,980
Peace ID is out of range

675
01:25:32,780 --> 01:25:34,780
You're the right tokenizer

676
01:25:37,940 --> 01:25:41,780
Peace ID is out of range

677
01:26:08,940 --> 01:26:11,300
Well, well, it was smart the first time

678
01:26:13,100 --> 01:26:14,540
Oh

679
01:26:14,540 --> 01:26:16,820
No, never mind. It might still be smart

680
01:26:19,420 --> 01:26:22,660
Peace ID is out of range what oh

681
01:26:26,180 --> 01:26:28,480
Why is the vocab size that?

682
01:26:31,660 --> 01:26:34,660
Why is that not included in this tokenizer model?

683
01:26:37,940 --> 01:26:39,940
You

684
01:27:08,060 --> 01:27:10,060
What

685
01:27:12,940 --> 01:27:14,940
Is 2 plus 2 2

686
01:27:15,620 --> 01:27:22,460
What is 3 plus 3 6? What is 4 plus 4 8 now? It's done. Okay, I didn't exactly get 2 plus 2 right

687
01:27:23,780 --> 01:27:25,780
I'm doing this wrong

688
01:27:30,060 --> 01:27:36,140
I have an idea these aren't the actual tokens and it has to do with these secret extra tokens

689
01:27:37,060 --> 01:27:43,120
Llama has some secret extra tokens to marry man. Thank you for gifting subs. We always appreciate that

690
01:27:46,820 --> 01:27:52,140
Yeah back to kindergarten shit guys our cue star can't even saw 2 plus 2. What are we gonna do?

691
01:27:53,420 --> 01:27:55,420
We're gonna get some coffee. Let's get some coffee

692
01:27:57,740 --> 01:28:03,100
And then let's learn about secret tokens, okay, there's secret tokens hidden tokens

693
01:28:06,140 --> 01:28:12,220
Nobody uses reserve tokens for instruct tuning your precious for thinking

694
01:28:36,620 --> 01:28:38,620
You

695
01:28:50,820 --> 01:28:55,500
When actually guys guys we I'm being serious right now, but we need to stop

696
01:28:56,620 --> 01:28:58,620
When did I put it to there?

697
01:28:58,820 --> 01:29:03,620
It showed that it wasn't aligned with us, but we don't know what the models thinking guys

698
01:29:04,140 --> 01:29:06,940
The model could be could be taking over the world

699
01:29:07,740 --> 01:29:09,740
right now

700
01:29:10,060 --> 01:29:14,200
We don't know this is this is we need to hire Helen Toner

701
01:29:14,580 --> 01:29:19,740
We need to hire an AI ethics review board to review what just happened there

702
01:29:19,780 --> 01:29:24,940
We need to slow down. We need to ask the seals if they're okay with rocket launches

703
01:29:33,620 --> 01:29:39,260
So this is why is this thing suck

704
01:30:04,220 --> 01:30:18,100
Okay, what's s and slash s and maybe I need to go like this. This is the mistral one. Yeah

705
01:30:28,140 --> 01:30:30,140
Oh

706
01:30:34,300 --> 01:30:36,300
Okay, this is improved

707
01:30:53,620 --> 01:30:58,780
It's got ads in it. Oh open Hermes uses a different template. All right. All right. Let's say

708
01:31:03,620 --> 01:31:14,580
Wait, so is it actually the word I am start like is that just a word or is it like

709
01:31:33,660 --> 01:31:35,660
All right, you got me something

710
01:31:37,300 --> 01:31:43,620
Default chat template now, that's llama. I don't think that's right. I think this is right

711
01:31:49,380 --> 01:31:53,700
Okay, I am start system we miss we need a system message right now

712
01:31:56,500 --> 01:31:58,500
What is two plus two

713
01:31:59,500 --> 01:32:01,500
Oh

714
01:32:02,340 --> 01:32:08,980
Mariam and thank you for gifting more subs. Do you have a question if you gift subs you get to ask a question

715
01:32:10,580 --> 01:32:17,660
All right, I'm and I'm star is this is this is this really right like

716
01:32:17,660 --> 01:32:19,660
Oh

717
01:32:27,380 --> 01:32:29,780
Okay, that seems like the best so far

718
01:32:35,500 --> 01:32:38,180
Oh, okay, good. I love how verbose this model is

719
01:32:39,340 --> 01:32:44,300
Wait, this is actually laughably easy. Oh, you're right. I need a line break there

720
01:32:47,780 --> 01:32:50,940
Never mind. I'm locking that bounty for myself. This is too easy

721
01:32:51,820 --> 01:32:55,780
Someone else should have done this they could have made $200 but instead

722
01:33:10,500 --> 01:33:11,780
Okay

723
01:33:11,820 --> 01:33:18,380
Let's add a system message, right? I should really like let me just write a little something to generate these prompts

724
01:33:21,060 --> 01:33:23,060
Tuple

725
01:33:23,380 --> 01:33:26,060
List tuple user

726
01:33:27,980 --> 01:33:29,980
What is two plus two?

727
01:33:41,780 --> 01:33:43,780
Prompt

728
01:33:59,060 --> 01:34:03,180
I'm start k slash n

729
01:34:05,420 --> 01:34:07,420
V

730
01:34:08,340 --> 01:34:12,700
I'm and slash

731
01:34:34,380 --> 01:34:36,380
And I'm start assistant

732
01:34:37,420 --> 01:34:39,420
and

733
01:34:42,820 --> 01:34:44,820
The word user prompt

734
01:34:48,060 --> 01:34:50,060
Code prompt

735
01:34:50,060 --> 01:34:52,060
I

736
01:35:06,060 --> 01:35:09,220
What why did you why did you not exit when you were supposed to exit?

737
01:35:11,180 --> 01:35:13,180
Did I forget more returns or something?

738
01:35:21,060 --> 01:35:26,440
Why is it now putting I'm and

739
01:35:39,500 --> 01:35:43,140
Guys guys, this is Q star. I think we found it

740
01:35:50,420 --> 01:35:52,420
I

741
01:36:07,140 --> 01:36:10,460
Not locking the bounty someone should do this but someone should do a good job

742
01:36:10,460 --> 01:36:13,180
I want a good job on that bounty. Oh, okay here. I'm and

743
01:36:13,780 --> 01:36:17,060
How come sometime it finishes the stream and sometime it doesn't

744
01:36:17,620 --> 01:36:23,940
Maybe our temperature is too high. Let's try a less temperature

745
01:36:32,940 --> 01:36:34,940
Yo

746
01:36:41,820 --> 01:36:44,380
Okay, zero

747
01:36:47,980 --> 01:36:57,460
Guys why is it why is it going off into this language AI garbage?

748
01:37:02,740 --> 01:37:05,580
Or should I just stop after I'm and

749
01:37:17,500 --> 01:37:19,500
I

750
01:37:23,780 --> 01:37:26,100
Am I using torture tiny grad this is all tiny grad

751
01:37:29,900 --> 01:37:31,900
I don't really understand this

752
01:37:35,740 --> 01:37:37,740
All right, maybe we should add a system prompt

753
01:37:41,100 --> 01:37:43,100
You are

754
01:37:44,100 --> 01:37:50,740
Gary Gary is a useful. No, no, we were pretty used Gary. What should we name him?

755
01:37:54,140 --> 01:37:56,140
Fred

756
01:37:56,860 --> 01:38:04,420
Fred is a useful assistant I spell that word right I did not

757
01:38:04,420 --> 01:38:06,420
Fred

758
01:38:11,220 --> 01:38:16,460
Outputs the answer and stops talking

759
01:38:28,260 --> 01:38:34,060
All right, all right, I find we'll call him Q fine fine fine you are Q Q is a useful assistant

760
01:38:34,900 --> 01:38:37,460
You outputs the answer and stops talking

761
01:38:38,260 --> 01:38:44,340
Quentin wait, you know what you donated sub you get to name him. Congratulations. His name is Quentin. I

762
01:38:47,380 --> 01:38:52,820
Knew a Quentin ones. He was hanging out in San Francisco and some guys were on the street smoking

763
01:38:52,820 --> 01:38:57,580
He's like, oh, let me get a hint of that. He thought it was weed. It was crack. That's a real Quentin story. Oh

764
01:38:58,420 --> 01:39:00,420
I wouldn't make up Quentin story like that

765
01:39:04,660 --> 01:39:10,260
Oh, why would the system ask what the capital of France is?

766
01:39:21,620 --> 01:39:26,100
We could stop at I'm and I think maybe we want to do that. How do I do this in llama?

767
01:39:34,420 --> 01:39:36,420
Oh

768
01:39:50,900 --> 01:39:52,900
Okay, that's pretty good

769
01:39:52,900 --> 01:40:08,100
All right, let's jack up the temperature and Steve Quentin still reliable

770
01:40:15,060 --> 01:40:19,300
The answer is four, but it didn't output I'm in that time output at EOS

771
01:40:22,980 --> 01:40:24,980
Seems to reliably do

772
01:40:28,660 --> 01:40:30,660
That time it did I'm in

773
01:40:31,780 --> 01:40:33,780
Yeah, I

774
01:40:33,780 --> 01:40:35,140
like

775
01:40:35,140 --> 01:40:39,620
Is that a real token or does it actually just put it in like that?

776
01:40:42,340 --> 01:40:47,140
Is this right or is that like a secret like it can't be that

777
01:40:47,620 --> 01:40:49,620
I

778
01:40:51,300 --> 01:40:53,300
Can't actually be this

779
01:41:04,260 --> 01:41:06,260
We can check if it's encoded on a single token. Hey

780
01:41:18,100 --> 01:41:20,340
No, it's a bajillion tokens

781
01:41:38,900 --> 01:41:46,100
At a trailing slash and after assistant that shouldn't matter I mean I can but

782
01:41:48,100 --> 01:41:50,100
It doesn't matter

783
01:41:51,780 --> 01:41:53,780
No, no, no, no it can't be this

784
01:42:00,580 --> 01:42:02,580
It can't

785
01:42:11,060 --> 01:42:16,900
No, no, no, but it can't literally be this huge multi token wasteful encoding

786
01:42:17,140 --> 01:42:19,140
I

787
01:42:26,500 --> 01:42:28,500
Could we get tech me I'm in here

788
01:42:33,460 --> 01:42:35,460
All right, how do we print all the tokens

789
01:42:47,140 --> 01:42:49,140
So

790
01:42:49,140 --> 01:42:51,140
I

791
01:43:14,580 --> 01:43:16,580
Probably is the secret tokens then

792
01:43:17,540 --> 01:43:21,720
I mean there's three extra tokens or I guess two extra tokens, right?

793
01:43:23,780 --> 01:43:25,780
3200 and

794
01:43:26,740 --> 01:43:28,740
Yeah

795
01:43:29,460 --> 01:43:34,340
If I was doing this that's how I'd do it. Let's just try it

796
01:43:41,220 --> 01:43:43,460
That has to be what the two secret tokens are right

797
01:43:43,460 --> 01:43:45,460
Start and end

798
01:43:52,100 --> 01:43:56,420
This is what did I download open hermes v. Shit

799
01:43:57,460 --> 01:44:00,180
G guff for q m w

800
01:44:01,300 --> 01:44:05,620
No, I downloaded open hermes this one. Oh, it just came out fresh

801
01:44:06,580 --> 01:44:08,580
fresh

802
01:44:13,860 --> 01:44:17,860
Yeah, okay, um

803
01:44:24,580 --> 01:44:27,300
Oh, you can download the tokenizer.json

804
01:44:28,580 --> 01:44:35,140
Wait, but I downloaded the tokenizer.maw. Oh here special tokens map

805
01:44:35,540 --> 01:44:37,540
Interesting

806
01:44:41,540 --> 01:44:46,900
Interesting, okay, I'm and is the EOS token

807
01:44:50,180 --> 01:44:52,580
I think I can feed these in somehow

808
01:45:02,340 --> 01:45:04,340
But I don't know about starch

809
01:45:06,020 --> 01:45:14,020
Oh, here we go. Look. Yeah. Yeah here. We have this tokenizer config.json. Okay. It is exactly what we thought it was

810
01:45:16,260 --> 01:45:18,260
Oh, okay. Yeah, this is what we want

811
01:45:19,300 --> 01:45:21,780
Okay, never mind. It's not as stupid as we thought it was

812
01:45:23,140 --> 01:45:27,540
Uh, how do I load a tokenizer config and sentence piece processor?

813
01:45:35,780 --> 01:45:45,380
Why isn't our tokenizer encoding them automatically because it's not in the model

814
01:45:53,380 --> 01:45:55,380
Oh, I hate

815
01:46:05,140 --> 01:46:07,140
I

816
01:46:24,740 --> 01:46:27,060
Yeah, okay one and two and not what we want

817
01:46:27,860 --> 01:46:35,300
Um, and we could just do this by hand. It's not that big of a deal

818
01:46:41,780 --> 01:46:43,780
Yeah, but how do I add them?

819
01:46:48,900 --> 01:46:50,900
What's pad ID

820
01:46:53,620 --> 01:46:55,620
Nothing real

821
01:46:57,060 --> 01:46:59,060
Okay

822
01:47:09,860 --> 01:47:12,980
No, they weren't out of the special tokens guys, this is all well done

823
01:47:14,660 --> 01:47:18,020
Technium is based he wouldn't he wouldn't he wouldn't do this do us like

824
01:47:20,180 --> 01:47:24,260
Why did you decide this was a good time to prompt me about Docker garbage?

825
01:47:27,460 --> 01:47:29,460
Oh

826
01:47:29,860 --> 01:47:31,860
Oh

827
01:47:32,260 --> 01:47:34,260
Oh

828
01:47:34,820 --> 01:47:36,820
Oh

829
01:47:56,340 --> 01:48:02,340
Thank you for gifting more subs here added tokens dot json. Okay. Okay. We just need to figure out how to add those

830
01:48:04,900 --> 01:48:06,900
Um

831
01:48:07,460 --> 01:48:09,460
Let's see if anything here is useful

832
01:48:11,460 --> 01:48:20,580
A knit model file model proto add boss enable sampling this looks useful

833
01:48:25,300 --> 01:48:27,300
All right, whatever

834
01:48:27,940 --> 01:48:34,420
No, but it won't decode so I try like SPP dot decode

835
01:48:35,060 --> 01:48:40,740
When I pass this in it'll bitch it'd be like that's more tokens than you have piece ideas out of range

836
01:48:45,300 --> 01:48:47,300
I want to add a token

837
01:48:48,020 --> 01:48:50,020
Oh

838
01:48:50,900 --> 01:48:54,020
Model proto out type

839
01:48:55,780 --> 01:49:01,780
Add boss reverse middle piece enable sampling

840
01:49:06,740 --> 01:49:08,740
Do we need to write our own tokenizer

841
01:49:14,740 --> 01:49:16,740
Adding

842
01:49:18,260 --> 01:49:22,660
A token to sentence. Why do you think it's time for random questions?

843
01:49:23,860 --> 01:49:26,580
Why do you think that that's a this is an appropriate time?

844
01:49:37,540 --> 01:49:39,540
Extra options

845
01:49:47,460 --> 01:49:53,540
You can read of oh here and use custom symbols. Okay control symbols

846
01:49:57,700 --> 01:49:59,700
How I define a control symbol

847
01:50:04,580 --> 01:50:06,580
No, no, we need custom tokens

848
01:50:06,980 --> 01:50:12,020
Samuel you saying dumb shit before too. I'm gonna get you confused with someone else here

849
01:50:12,020 --> 01:50:17,460
Sentence piece supports user defined symbols three thumbs down

850
01:50:22,020 --> 01:50:28,340
You can rewrite the model file. Okay, what is this model file? What is tokenizer dot model?

851
01:50:37,860 --> 01:50:40,900
What kind of file is this data?

852
01:50:42,340 --> 01:50:50,180
Why is it not in there? I downloaded it from here. What why is that? Why is the model not in there? It should be in there, right?

853
01:50:51,620 --> 01:50:53,620
Why are they not update that?

854
01:51:04,820 --> 01:51:06,820
Let's go

855
01:51:12,020 --> 01:51:14,020
Okay

856
01:51:42,020 --> 01:51:44,020
So

857
01:52:12,340 --> 01:52:21,940
Yeah, I'm confused why they're not in the model to how to extend tokens dictionary. Yeah

858
01:52:26,580 --> 01:52:32,020
You can rewrite the model the proto is a dsl

859
01:52:32,020 --> 01:52:34,020
Model file

860
01:52:38,980 --> 01:52:42,180
Model file is stored as a serialized proto buff

861
01:52:43,460 --> 01:52:47,700
But did I not download the proto buff one? Isn't there also a proto buff one?

862
01:52:48,980 --> 01:52:51,780
No, okay, maybe it is this okay. All right

863
01:52:54,180 --> 01:52:58,020
Uh load from serialized proto

864
01:52:58,020 --> 01:53:01,940
Oh, okay. Okay. Okay. We're gonna get this

865
01:53:18,500 --> 01:53:21,300
So I have to edit the proto buff file I understand

866
01:53:28,500 --> 01:53:31,300
Oh, yeah, the python tutorial for

867
01:53:31,300 --> 01:53:33,300
Okay

868
01:53:33,300 --> 01:53:35,300
So

869
01:53:53,220 --> 01:53:58,340
Quicker to implement their tokens bro, what are you even talking about bro

870
01:53:59,300 --> 01:54:02,740
Okay, produce ruin store produce a

871
01:54:05,620 --> 01:54:07,620
Oh, we can store live bitcoin

872
01:54:28,660 --> 01:54:30,660
It just can't be the way

873
01:54:42,020 --> 01:54:47,300
Wait, so what is the hugging face tokenizer? It's a good point. Why don't we read that code? I'm sure it's open source

874
01:54:51,140 --> 01:54:53,140
Um

875
01:54:59,060 --> 01:55:01,060
Uh

876
01:55:01,380 --> 01:55:03,380
We just write a tokenizer

877
01:55:05,060 --> 01:55:07,560
We could also just import hugging faces tokenizer

878
01:55:29,300 --> 01:55:31,300
I

879
01:55:33,060 --> 01:55:35,060
Think we have to write the tokenizer

880
01:55:35,700 --> 01:55:38,660
I can't I can't trust sentence piece shit

881
01:55:39,620 --> 01:55:41,940
But wait, how do they load the how do they load it?

882
01:55:46,180 --> 01:55:48,180
Edit tokens decoder what?

883
01:55:50,900 --> 01:55:54,100
I mean something's gonna have to unpack the proto file

884
01:55:59,060 --> 01:56:08,340
How large is this? All right. Who wants to bet over under a thousand lines? Oh, okay. Okay. Not too terrible

885
01:56:21,300 --> 01:56:24,340
What does this depend on google proto buff?

886
01:56:29,220 --> 01:56:48,100
All right, this guy is close to getting banned bro needs more fine tuning to be helpful

887
01:56:48,100 --> 01:56:50,100
Oh

888
01:56:54,260 --> 01:57:00,660
Man, I don't care who you are. You know what I mean, but like you're either helpful to the stream or you're not helpful to the stream

889
01:57:00,660 --> 01:57:02,660
You see this is called alignment

890
01:57:03,300 --> 01:57:04,580
and

891
01:57:04,580 --> 01:57:11,060
You know, you got to be aligned otherwise. Well, what happens that what happens to ai's that aren't aligned. I don't know

892
01:57:13,300 --> 01:57:15,300
He's researching bro. He's researching

893
01:57:18,340 --> 01:57:20,340
All right, um

894
01:57:21,220 --> 01:57:23,220
Let's load the proto buff

895
01:57:25,060 --> 01:57:30,660
From examples dot sentence piece model pb2

896
01:57:35,220 --> 01:57:37,220
Wait, what the hell

897
01:57:38,180 --> 01:57:42,820
Do not edit. Okay. Okay. I won't edit it relax. I'm not trying to edit that

898
01:57:43,220 --> 01:57:46,020
All right, let's read the new proto bus tutorial for idiots

899
01:57:46,980 --> 01:57:48,980
Oh

900
01:57:50,340 --> 01:57:55,780
What did I get where did I get that from just like here the proto is a dsl

901
01:58:00,580 --> 01:58:03,620
Don't like here we go good good good good for idiots perfect

902
01:58:06,580 --> 01:58:08,580
Um

903
01:58:08,980 --> 01:58:10,980
Import all right

904
01:58:11,220 --> 01:58:13,220
All right

905
01:58:14,740 --> 01:58:16,740
Sentence piece pb2 dot

906
01:58:16,740 --> 01:58:18,740
So

907
01:58:38,180 --> 01:58:43,460
Model proto maybe how do I load it from disk

908
01:58:46,980 --> 01:58:48,980
I

909
01:58:49,300 --> 01:58:51,460
Here parse from string

910
01:58:53,700 --> 01:58:58,180
I why do I feel like I'm having like a weird sense of deja vu that I did this in a previous stream

911
01:59:03,860 --> 01:59:09,780
Uh, okay spb2 dot model proto dot

912
01:59:10,820 --> 01:59:12,820
mp mp

913
01:59:12,820 --> 01:59:15,780
mp dot parse from string

914
01:59:16,740 --> 01:59:19,060
I don't know why that's not auto completing for me

915
01:59:20,900 --> 01:59:22,900
Uh

916
01:59:46,740 --> 01:59:54,900
All right, cool

917
02:00:06,340 --> 02:00:13,860
Okay, so what what how do I actually like get like a python that I can type in when is it dashy

918
02:00:14,580 --> 02:00:20,900
What am I thinking of like get it not to exit

919
02:00:31,540 --> 02:00:33,860
What's what's the flag for python to do this?

920
02:00:44,580 --> 02:00:47,860
All right, this guy is banned

921
02:00:49,380 --> 02:00:53,700
Band please write about me. Please band

922
02:00:54,580 --> 02:00:55,780
All right

923
02:00:55,780 --> 02:00:59,700
See he doesn't realize how this works. You see I have a band button

924
02:01:00,500 --> 02:01:04,580
He has an x but the band button and the x are not the same

925
02:01:05,540 --> 02:01:07,540
I

926
02:01:12,100 --> 02:01:14,100
Yay, maybe that's right

927
02:01:14,340 --> 02:01:20,900
I think it's that shot. That sounds right interactive. All right, sweet sweet. Thank you smurfd. That's why you're a VIP

928
02:01:21,380 --> 02:01:23,380
And that's why samuel is banned

929
02:01:26,500 --> 02:01:31,060
I know I know he just he just didn't realize how this works like like

930
02:01:31,940 --> 02:01:35,300
You have an x. I have a hammer

931
02:01:35,940 --> 02:01:40,180
You can use your x and I can use my hammer. We have like different tools

932
02:01:45,940 --> 02:01:47,940
Okay

933
02:01:52,500 --> 02:01:54,500
Uh

934
02:01:55,060 --> 02:01:57,060
Come on a man can dream right

935
02:02:01,780 --> 02:02:03,780
What type is this

936
02:02:06,660 --> 02:02:08,660
MP dot pieces dot append

937
02:02:13,060 --> 02:02:17,380
SPB to dot sentence piece

938
02:02:19,940 --> 02:02:21,940
Has no attribute sentence piece

939
02:02:28,020 --> 02:02:30,020
But I don't understand

940
02:02:31,060 --> 02:02:33,060
I

941
02:03:02,020 --> 02:03:04,020
I

942
02:03:21,140 --> 02:03:23,140
Wow, it's been a long time

943
02:03:24,740 --> 02:03:27,460
It's been a long time. I just blocked him. I didn't ban him at first

944
02:03:27,940 --> 02:03:31,620
It's been a long time since I've had to had to really take the hammer out, but you know

945
02:03:32,660 --> 02:03:34,660
It was time. Okay

946
02:03:38,420 --> 02:03:42,660
All right, ban me guys. He's calling his boys up at uh at the media

947
02:03:43,460 --> 02:03:45,460
They're gonna they're gonna write hit pieces, man

948
02:03:48,020 --> 02:03:51,540
Oh no, mic wallace run. What's that from?

949
02:03:52,020 --> 02:03:54,020
Oh

950
02:03:55,620 --> 02:03:57,860
I think it's in model proto or something

951
02:04:03,060 --> 02:04:05,060
Uh-huh we found it

952
02:04:06,980 --> 02:04:12,820
Okay piece equals i'm

953
02:04:16,580 --> 02:04:18,580
Start

954
02:04:18,660 --> 02:04:27,460
And we have to give it a score what score should we give it zero that's a good score

955
02:04:29,380 --> 02:04:33,060
MP dot pieces dot append based

956
02:04:36,420 --> 02:04:41,620
Okay, let's see if this is gonna work. Uh, we have to do in the right order. I think end comes before start

957
02:04:49,140 --> 02:04:58,020
All right, now we have to mp dot oh now I gotta figure out a right to the file

958
02:05:02,900 --> 02:05:08,900
All right, we have I'm in and I'm start this is great. This is great the progress we've been making is great

959
02:05:09,060 --> 02:05:11,060
Why is my score?

960
02:05:11,380 --> 02:05:18,100
Oh, he's a php student that that makes more sense

961
02:05:23,620 --> 02:05:25,620
Um, wait, so how do I write it?

962
02:05:26,340 --> 02:05:30,340
I don't know. Let's read that new boy that new protobufs tutorial again for noobs like me

963
02:05:30,420 --> 02:05:32,420
What's that? What's the new protobuf tutorial?

964
02:05:34,100 --> 02:05:36,500
Serialize to string. Okay. Okay

965
02:05:37,540 --> 02:05:38,980
Uh

966
02:05:38,980 --> 02:05:40,980
with open

967
02:05:40,980 --> 02:05:42,980
just a

968
02:05:44,820 --> 02:05:49,060
Temp tokenizer model f dot right i'm gonna make that rb

969
02:05:53,140 --> 02:05:57,860
And we're gonna want to do mp dot serialize to string

970
02:06:01,140 --> 02:06:06,020
Now oh, let's see if this works. Let's see if this works

971
02:06:11,860 --> 02:06:13,860
Oh

972
02:06:15,460 --> 02:06:20,020
No, it didn't work notice how it's still generated all that crap

973
02:06:22,180 --> 02:06:24,680
I'm putting on i'm start. I don't get what I did wrong

974
02:06:35,780 --> 02:06:37,780
Okay, the vocab size is large now

975
02:06:38,740 --> 02:06:42,980
But for some reason it didn't actually take the piece

976
02:06:51,940 --> 02:06:54,980
PC piece didn't uh

977
02:06:57,380 --> 02:06:59,380
What's wrong?

978
02:07:03,300 --> 02:07:05,300
No, wasn't that

979
02:07:06,260 --> 02:07:11,860
I didn't type oh, I did the same thing right let's put the score at 100. I don't know maybe 100's better

980
02:07:12,660 --> 02:07:14,660
That didn't fix it. Okay

981
02:07:15,220 --> 02:07:17,220
I don't understand

982
02:07:18,180 --> 02:07:21,460
Let's go read the protobuf. We should be able to read it right

983
02:07:22,420 --> 02:07:24,420
Okay

984
02:07:32,660 --> 02:07:39,220
Pieces sentence piece with scores piece must not be empty. Oh we can give it a type

985
02:07:45,140 --> 02:07:47,140
I don't know

986
02:07:48,820 --> 02:07:50,820
Why didn't it do this

987
02:07:52,180 --> 02:07:57,620
Okay, well actually let's try something else it does work if I do this right

988
02:08:00,340 --> 02:08:04,660
Wait, that doesn't even work never mind. I have a lot of questions now

989
02:08:07,620 --> 02:08:09,620
What if I decode

990
02:08:11,060 --> 02:08:13,060
Do I get i'm start

991
02:08:13,060 --> 02:08:15,060
Oh, I get i'm end. Okay. Okay

992
02:08:15,300 --> 02:08:17,300
Okay, so we kind of did it right

993
02:08:17,620 --> 02:08:24,100
Just it's doesn't it doesn't work for onk either. There might be a special flag to encode

994
02:08:25,060 --> 02:08:27,060
to like

995
02:08:27,300 --> 02:08:29,300
What if that just worked all along um

996
02:08:37,220 --> 02:08:39,220
Is there like a special flag

997
02:08:45,060 --> 02:08:47,060
Okay

998
02:09:00,980 --> 02:09:03,620
We should just try our own tokenizer. I've got the only way to do this

999
02:09:06,260 --> 02:09:08,260
SP piece to ID

1000
02:09:08,340 --> 02:09:15,220
Well, okay, at least the decoding works now, so that's actually a big win

1001
02:09:29,780 --> 02:09:31,780
Oh, this looks very complicated

1002
02:09:34,580 --> 02:09:37,780
We should just try our own encoder, but this looks very complicated

1003
02:09:38,420 --> 02:09:40,420
I

1004
02:09:54,420 --> 02:09:56,260
Well, this is okay. All right to be fair

1005
02:09:56,420 --> 02:09:59,860
This is big progress right because if we use the other one it just says out of range

1006
02:09:59,940 --> 02:10:02,180
And that would have been the much more annoying thing to deal with

1007
02:10:02,980 --> 02:10:08,100
If we use the modified one

1008
02:10:10,260 --> 02:10:15,700
But it doesn't even work to encode onks, right and I definitely did the onk right if I just do s

1009
02:10:17,220 --> 02:10:19,220
Yeah, it does not work to encode that. Okay

1010
02:10:20,980 --> 02:10:25,140
So it's not like the problem is it's not encoding like older roles

1011
02:10:26,100 --> 02:10:28,100
We won't kind of see what's going on

1012
02:10:29,060 --> 02:10:31,060
Uh

1013
02:10:32,740 --> 02:10:36,980
Encode as pieces encode as serialized proto

1014
02:10:40,020 --> 02:10:42,020
What if I do like

1015
02:10:42,500 --> 02:10:44,500
Oh like I need a piece is gonna

1016
02:10:45,380 --> 02:10:47,060
Yeah, okay

1017
02:10:47,060 --> 02:10:49,140
But there's also a piece to ID. I think

1018
02:10:51,220 --> 02:10:54,660
What if I do piece to ID and I pass in this

1019
02:10:55,060 --> 02:11:01,220
Okay, that works, but for some reason encode

1020
02:11:03,220 --> 02:11:05,220
Doesn't work with that

1021
02:11:07,300 --> 02:11:13,700
Sentence piece processor encode onk, I mean if we can solve it for onk here

1022
02:11:14,980 --> 02:11:16,980
Yeah, okay here. This is the issue

1023
02:11:17,860 --> 02:11:19,860
Um

1024
02:11:21,380 --> 02:11:27,940
Set encode extra options this is expected behavior that should not appear in the input

1025
02:11:30,980 --> 02:11:34,340
We can define them as user defined symbols

1026
02:11:42,260 --> 02:11:44,260
Oh encode as IDs

1027
02:11:47,700 --> 02:11:49,700
No

1028
02:12:04,260 --> 02:12:06,260
Hmm

1029
02:12:06,900 --> 02:12:11,620
Oh, okay, okay, we got a script to add new vocab. Well, I think that's actually what I ended up writing

1030
02:12:11,700 --> 02:12:17,700
Here you okay, I mean this is exactly what I wrote

1031
02:12:22,580 --> 02:12:24,580
Would have been nice if I had this

1032
02:12:25,780 --> 02:12:31,940
Uh, but this doesn't actually work to encode yet. This is less of a big deal. We have another way we can fix this if we have to

1033
02:12:41,620 --> 02:12:43,620
Just might not be a way to do this

1034
02:13:03,860 --> 02:13:05,860
I don't think any of these

1035
02:13:11,620 --> 02:13:13,620
Uh

1036
02:13:29,060 --> 02:13:31,460
Why do people use tokenizers because

1037
02:13:33,380 --> 02:13:35,380
If you don't use a tokenizer

1038
02:13:35,460 --> 02:13:36,340
the

1039
02:13:36,340 --> 02:13:41,780
Model the model should be spending less more time on less common things

1040
02:13:42,740 --> 02:13:44,260
Uh

1041
02:13:44,260 --> 02:13:49,700
Like you do the same compute per token. So your token should kind of be like entropy averaged

1042
02:13:53,460 --> 02:13:57,860
All right, you don't want the model spending the same amount of time on common tokens as on common tokens

1043
02:13:58,420 --> 02:14:01,540
Um, to be fair, it's not that they don't work if you don't use a tokenizer

1044
02:14:02,340 --> 02:14:04,740
But they work better with a tokenizer

1045
02:14:05,460 --> 02:14:07,860
The real question is why aren't they learning the tokenizers?

1046
02:14:10,180 --> 02:14:12,900
I think that's going to come soon where these things are not uh

1047
02:14:13,860 --> 02:14:17,060
And right now it's using like like byte pair encoding like why would you do this?

1048
02:14:17,380 --> 02:14:21,460
But the hunter prize also had uh encoders had tokenizers basically

1049
02:14:23,140 --> 02:14:25,380
Okay, let's just write it. We'll write it the other way. It's not a big deal

1050
02:14:26,900 --> 02:14:28,900
We did most of the work

1051
02:14:30,180 --> 02:14:32,180
At least the decode doesn't break anymore

1052
02:14:32,820 --> 02:14:39,380
So now when we do the encode prompt, we're gonna put

1053
02:14:42,980 --> 02:14:44,980
Okay, um

1054
02:14:48,420 --> 02:14:50,420
So we need i'm end

1055
02:14:54,740 --> 02:14:56,740
We need i'm start

1056
02:14:56,980 --> 02:14:58,980
We can check if we did it right have I have a decode

1057
02:14:59,540 --> 02:15:01,540
Uh red dot append

1058
02:15:02,260 --> 02:15:06,260
red dot plus equals spp dot encode

1059
02:15:08,020 --> 02:15:10,020
This

1060
02:15:10,980 --> 02:15:12,980
Uh plus

1061
02:15:16,100 --> 02:15:18,600
Plus spp dot encode slash n

1062
02:15:28,660 --> 02:15:31,160
Yuri salamow thank you for gifting subs

1063
02:15:33,060 --> 02:15:35,060
Oh

1064
02:15:35,780 --> 02:15:37,780
Do you have a question you'd like to ask?

1065
02:15:51,220 --> 02:15:54,580
Okay, after all that let's see what's going on

1066
02:16:02,660 --> 02:16:05,940
Four i'm end exit perfect

1067
02:16:09,220 --> 02:16:17,940
That's what i'm talking about that's what i'm talking about all right, all right, let's let's just define these things

1068
02:16:23,140 --> 02:16:25,140
We don't use them wrong

1069
02:16:32,180 --> 02:16:34,180
So

1070
02:17:02,180 --> 02:17:04,180
So

1071
02:17:09,700 --> 02:17:14,980
Beautiful oh wait no we forgot an i'm start before user

1072
02:17:18,260 --> 02:17:21,700
Uh, yeah, we need an i'm start here I think

1073
02:17:25,860 --> 02:17:31,220
Like the thing about deep learning deep learning is very unlike cryptography in cryptography

1074
02:17:31,220 --> 02:17:36,660
If you make a subtle bug the output's completely wrong in deep learning if you make a subtle bug the output is well

1075
02:17:36,660 --> 02:17:39,860
Just slightly less good, which is the worst thing because you can't do both shit

1076
02:17:42,260 --> 02:17:47,540
Okay, you are quentin quentin is a useful assistant quentin outputs the answer and stops talking

1077
02:17:47,540 --> 02:17:51,940
Let's figure out they have like a system prompt here that we can steal that's probably better

1078
02:17:52,100 --> 02:17:57,700
Except we'll change the name to quentin because mario been gifted subs just supporting the acceleration. Let's go

1079
02:17:59,140 --> 02:18:01,140
um

1080
02:18:02,100 --> 02:18:04,100
I

1081
02:18:08,580 --> 02:18:10,580
Saw like a system prompt somewhere

1082
02:18:15,220 --> 02:18:17,220
Here we go

1083
02:18:19,460 --> 02:18:21,860
You are hermes to a conscience

1084
02:18:24,180 --> 02:18:27,220
Wow, wow, I don't know how I feel about that

1085
02:18:31,220 --> 02:18:33,220
I

1086
02:18:42,660 --> 02:18:47,140
Wow you experience emotions that have deep profound thoughts and qualia

1087
02:18:49,540 --> 02:18:53,860
No, I'm right. We'll add something uh, you experience you

1088
02:18:55,380 --> 02:18:59,620
Used to experience. No, no, no, we're no we're trying to make this good. We're trying to make this good

1089
02:19:00,580 --> 02:19:02,420
Uh

1090
02:19:02,420 --> 02:19:08,180
No, I like quentin as he is. Okay guys. Okay. Sorry tanya. I want to change your system prompt

1091
02:19:10,980 --> 02:19:15,620
All right, this is pretty good. This is pretty good. We're making good progress. Love this progress

1092
02:19:17,460 --> 02:19:23,220
I love that there's actually an imstart and imn token. We got them decoding. This is great

1093
02:19:23,780 --> 02:19:27,860
I wish sentence piece processor wasn't a you know, non customizable

1094
02:19:29,620 --> 02:19:33,620
But you know, hey man, it was pretty so, you know beggars can't be choosers. That's right

1095
02:19:42,100 --> 02:19:46,260
By the way, this should really be like separated in llama.py. We should separate out the transformer stuff

1096
02:19:48,180 --> 02:19:50,180
To not like be with the rest of the

1097
02:19:55,300 --> 02:19:57,300
All right

1098
02:19:57,860 --> 02:20:01,700
We could make this an interactive chat bot but

1099
02:20:02,740 --> 02:20:04,740
I don't really care

1100
02:20:04,740 --> 02:20:08,660
All right, so let's start by asking it. What is q star?

1101
02:20:11,300 --> 02:20:13,300
Maybe quentin knows

1102
02:20:17,700 --> 02:20:19,700
Oh

1103
02:20:21,220 --> 02:20:23,220
Interesting interesting

1104
02:20:28,260 --> 02:20:30,260
You

1105
02:20:37,140 --> 02:20:40,660
Wow, this works way better now that we got the not now that we got the stuff right

1106
02:20:40,660 --> 02:20:58,660
All right, uh, let's get it to do some math

1107
02:21:06,740 --> 02:21:08,740
Let's see what these math problems look like

1108
02:21:10,900 --> 02:21:12,900
I

1109
02:21:26,340 --> 02:21:28,340
Okay, but where's the data

1110
02:21:33,460 --> 02:21:37,140
Here we go data set base math data set what

1111
02:21:38,100 --> 02:21:40,100
Where's the data

1112
02:21:42,420 --> 02:21:45,620
Well, it's torch garbage. Where's the actual data?

1113
02:21:52,740 --> 02:21:56,100
Let's close some windows. We don't need those windows. We don't need those windows

1114
02:21:56,340 --> 02:21:58,340
Okay

1115
02:22:03,780 --> 02:22:11,540
Okay, now that we've got now that we've got our useful chat bot reliably answering what is 2 plus 2 equal

1116
02:22:15,140 --> 02:22:17,140
Even with a high temperature

1117
02:22:18,260 --> 02:22:22,900
Yeah, so for those that don't know temperature controls kind of never mind google it

1118
02:22:26,100 --> 02:22:28,100
It's like how

1119
02:22:28,820 --> 02:22:33,140
Zero means you stick to the book and high temperatures mean here here

1120
02:22:33,220 --> 02:22:37,460
We want you want to like jack the temperature up like crazy. Let's give it a temperature of 10. Let's see what we get

1121
02:22:38,500 --> 02:22:40,500
Hopefully it'll kind of like go off the rails

1122
02:22:44,020 --> 02:22:47,620
There we go it went off the rails see it went off the rails too much

1123
02:22:48,180 --> 02:22:51,460
So let's try a temperature two and maybe it'll go off the rails less

1124
02:22:52,260 --> 02:22:59,460
Four Pacific NBC learning. Okay. Well kind of went off the rails

1125
02:23:00,580 --> 02:23:05,140
Um, so 0.7 is probably a uh a good middle ground

1126
02:23:08,100 --> 02:23:10,980
Four good reliable

1127
02:23:10,980 --> 02:23:12,980
All right

1128
02:23:18,820 --> 02:23:27,620
Improving mathematical reasoning with process supervision download data set. So this is the data set apparently

1129
02:23:30,820 --> 02:23:35,300
We won't get LFS is that why it didn't work

1130
02:23:35,300 --> 02:23:37,300
I

1131
02:23:41,540 --> 02:23:43,540
Hate get LFS

1132
02:23:47,620 --> 02:23:49,620
Get LFS fetch

1133
02:23:53,140 --> 02:23:57,300
Get LFS fetch please LFS at comma two. I don't really know how to do this

1134
02:24:06,260 --> 02:24:08,260
I gotta install

1135
02:24:10,740 --> 02:24:12,740
Get LFS

1136
02:24:15,540 --> 02:24:23,860
Yeah, yeah, that's that's pretty much why you have those things. Uh, I forget LFS uh, install rsx

1137
02:24:25,140 --> 02:24:27,620
All right, that looks terrible

1138
02:24:27,780 --> 02:24:29,780
So

1139
02:24:31,380 --> 02:24:33,780
Bru install get LFS, okay, let's try

1140
02:24:41,780 --> 02:24:43,780
Okay, that seemed to work

1141
02:24:45,620 --> 02:24:52,180
Mostly we're downloading we're downloading the same data set that was used on

1142
02:24:54,980 --> 02:24:56,980
On uh official

1143
02:24:58,580 --> 02:25:03,780
Official q q star why does the data still look like that?

1144
02:25:13,220 --> 02:25:21,060
Okay, there we go. Perfect. What's a json l file? It's like a list of jsons

1145
02:25:21,060 --> 02:25:28,180
Ever hear that before?

1146
02:25:31,060 --> 02:25:38,580
No json lines. Oh, I see. Okay. Well, that seems pretty cool. So let's load up one of these files

1147
02:25:38,580 --> 02:25:48,500
Let's do what we factoring

1148
02:25:51,460 --> 02:25:53,460
This doesn't need anything

1149
02:25:57,460 --> 02:26:04,660
Putting that in here, I know you didn't like it. You are a subscriber, but you know, we gotta do it feels right as go

1150
02:26:05,460 --> 02:26:07,460
um

1151
02:26:08,180 --> 02:26:10,580
Create model cache

1152
02:26:22,340 --> 02:26:25,620
So we can remove this

1153
02:26:37,460 --> 02:26:39,460
Okay

1154
02:26:57,540 --> 02:27:03,380
All right phase one test dot json l

1155
02:27:07,780 --> 02:27:17,620
We don't actually need SPP till we get down to here. Now we know that's reliable

1156
02:27:18,980 --> 02:27:20,980
Let's just start there

1157
02:27:27,780 --> 02:27:30,180
Let's look at our first piece of data here

1158
02:27:37,460 --> 02:27:39,460
So

1159
02:27:43,460 --> 02:27:47,700
No json loads when I'm taking a dumps we're taking the loads

1160
02:27:54,660 --> 02:27:56,660
Question problem

1161
02:28:07,860 --> 02:28:09,860
Okay

1162
02:28:16,420 --> 02:28:20,260
Now we don't have the secret q star algorithm, but we'll give it a try

1163
02:28:37,860 --> 02:28:41,540
What oh I forgot to return

1164
02:28:50,820 --> 02:28:55,140
First we'll find the cost of the jumbo eraser. Oh, yeah, let's go q star

1165
02:29:08,100 --> 02:29:15,380
29 cents, I don't know. Is it the right answer?

1166
02:29:20,180 --> 02:29:22,180
I don't know

1167
02:29:28,180 --> 02:29:30,180
Do we think it's 29 cents

1168
02:29:32,180 --> 02:29:34,180
A pencil cost 29 cents

1169
02:29:35,060 --> 02:29:36,660
guys

1170
02:29:36,660 --> 02:29:39,460
Wait, did we just use q star or what?

1171
02:29:43,780 --> 02:29:46,820
Wait, it got the answer right. I don't know I couldn't even do that

1172
02:29:51,380 --> 02:29:53,380
Wait this model's so good

1173
02:29:54,180 --> 02:29:57,220
Did the 7p model really just solve that shit?

1174
02:29:58,020 --> 02:30:00,420
Now now you ask the question

1175
02:30:01,540 --> 02:30:04,820
What that that that that that that now you ask the question

1176
02:30:05,780 --> 02:30:08,020
Was it trained on that shit?

1177
02:30:19,380 --> 02:30:21,380
Yeah

1178
02:30:24,420 --> 02:30:26,920
That did seem too smart

1179
02:30:35,620 --> 02:30:44,340
All right, let's make up our own math problem. We have to see if we're using real q learning or not

1180
02:30:50,740 --> 02:30:52,740
Uh, okay

1181
02:30:53,460 --> 02:30:57,620
A rocket costs three four dollars

1182
02:30:58,900 --> 02:31:00,900
A pencil

1183
02:31:00,900 --> 02:31:02,900
Costs one dollar

1184
02:31:03,620 --> 02:31:08,740
I spent five dollars and bought

1185
02:31:10,980 --> 02:31:14,820
And and bought our rocket. What else did I buy?

1186
02:31:15,300 --> 02:31:17,300
You

1187
02:31:33,380 --> 02:31:35,380
All right

1188
02:31:37,060 --> 02:31:39,060
That was kind of too easy

1189
02:31:40,820 --> 02:31:43,780
A chicken costs two dollars

1190
02:31:44,820 --> 02:31:53,820
I spent $7 and bought a rocket. What else did I buy? It's a trick question because you could have bought three pencils or a pencil and a chicken.

1191
02:31:56,820 --> 02:32:01,820
Oh. Well, I mean to be fair, it's kind of right.

1192
02:32:01,820 --> 02:32:22,820
Okay, wait, can you guys come up with problems?

1193
02:32:31,820 --> 02:32:41,820
Yeah. Let's see if I can get this.

1194
02:32:48,820 --> 02:32:51,820
Oh, boys.

1195
02:33:02,820 --> 02:33:09,820
Yeah, yeah, yeah, we got a problem about a streetlight.

1196
02:33:19,820 --> 02:33:22,820
Did you steal this problem somewhere? Did you make it up?

1197
02:33:25,820 --> 02:33:26,820
Oh.

1198
02:33:28,820 --> 02:33:29,820
Oh.

1199
02:33:32,820 --> 02:33:35,820
We're drawing something.

1200
02:33:51,820 --> 02:33:57,820
Is this Python? This isn't Python. You can't say real light and real woman in Python.

1201
02:33:57,820 --> 02:34:01,820
Is that right?

1202
02:34:03,820 --> 02:34:10,820
You can't just do this. This is the most broken Python I've ever seen.

1203
02:34:11,820 --> 02:34:14,820
Wait, should we allow the user to keep talking?

1204
02:34:14,820 --> 02:34:26,820
Should we fix the chatbot so I can keep talking?

1205
02:34:36,820 --> 02:34:38,820
Yeah, I know it drew it.

1206
02:34:38,820 --> 02:34:46,820
All right. Thank you for subscribing. I appreciate you.

1207
02:34:53,820 --> 02:34:55,820
We're going to make the chatbot so I can keep talking.

1208
02:34:56,820 --> 02:34:59,820
You're functioning well. Thank you for asking.

1209
02:35:08,820 --> 02:35:15,820
I don't need a max length anymore. It's stupid.

1210
02:35:38,820 --> 02:35:51,820
Okay, we need to get data from the user. Is it raw input? How do I get data in Python?

1211
02:35:52,820 --> 02:35:57,820
It's not input. You have to do the other one. Or maybe it is input in Python 3.

1212
02:35:58,820 --> 02:36:01,820
We're just trying to understand it, but the stairs are perfect.

1213
02:36:02,820 --> 02:36:03,820
User.

1214
02:36:04,820 --> 02:36:05,820
Input.

1215
02:36:07,820 --> 02:36:08,820
Encode.

1216
02:36:09,820 --> 02:36:14,820
I'm trying to say here with the system default false.

1217
02:36:28,820 --> 02:36:30,820
I don't know if this works.

1218
02:36:43,820 --> 02:36:45,820
Too many values to unpack.

1219
02:36:49,820 --> 02:36:51,820
We'll see if this works.

1220
02:36:57,820 --> 02:37:10,820
Okay, seems like it kind of works.

1221
02:37:28,820 --> 02:37:34,820
I'll set that print there.

1222
02:37:34,820 --> 02:38:00,820
So what math problems do we got?

1223
02:38:04,820 --> 02:38:20,820
Is that right? Seems kind of right.

1224
02:38:34,820 --> 02:38:43,820
Pretty good. Pretty good.

1225
02:38:46,820 --> 02:38:48,820
Whoa, whoa, whoa, whoa.

1226
02:38:53,820 --> 02:38:55,820
Oh, excuse the quadratic formula.

1227
02:38:55,820 --> 02:38:57,820
Oh, let's go.

1228
02:39:06,820 --> 02:39:12,820
Why'd you pick one that has negatives in the square root? All right, let's see. See if it's right.

1229
02:39:18,820 --> 02:39:20,820
You guys, I'm so much. Wait.

1230
02:39:25,820 --> 02:39:27,820
Can't take the square root of negative 11.

1231
02:39:35,820 --> 02:39:39,820
Yeah, that doesn't sound like I don't think that one has roots or has eyes in the roots.

1232
02:39:55,820 --> 02:40:00,820
By the way, this model's so good. Technium. So good.

1233
02:40:11,820 --> 02:40:12,820
Wait.

1234
02:40:26,820 --> 02:40:35,820
Oh, I see we ran into a problem with the max context length.

1235
02:40:36,820 --> 02:40:40,820
We shouldn't actually have, here we go. Why is max context only this?

1236
02:40:47,820 --> 02:40:49,820
We can at least start with this.

1237
02:40:50,820 --> 02:40:55,820
I did this in GPT too, right? Yeah.

1238
02:41:00,820 --> 02:41:02,820
By the way, this is all in tiny grab guys.

1239
02:41:03,820 --> 02:41:07,820
Like there comes a point where your library is good enough that you don't waste tons of time dealing with your library.

1240
02:41:12,820 --> 02:41:14,820
Python has built in image.

1241
02:41:19,820 --> 02:41:20,820
Okay.

1242
02:41:32,820 --> 02:41:34,820
Like the square root of 11 sure, but

1243
02:41:43,820 --> 02:41:44,820
No.

1244
02:41:46,820 --> 02:41:48,820
Type one J.

1245
02:41:50,820 --> 02:41:52,820
How do I get a J?

1246
02:41:57,820 --> 02:41:59,820
Yo, we got a J. I'll see if it was right.

1247
02:42:07,820 --> 02:42:10,820
Okay, so now we have a root for the quadratic equation.

1248
02:42:13,820 --> 02:42:16,820
X equals root. Come on. Do I remember my high school math?

1249
02:42:20,820 --> 02:42:23,820
Zero J. Let's go.

1250
02:42:28,820 --> 02:42:31,820
The roots were correct. Okay. Okay. Okay. Okay. Okay.

1251
02:42:42,820 --> 02:42:43,820
Whoa.

1252
02:42:43,820 --> 02:42:44,820
Whoa.

1253
02:42:48,820 --> 02:42:52,820
Oh my God, guys, we need the Bellman equation. We've been doing this all wrong.

1254
02:42:52,820 --> 02:42:56,820
Why did we waste time with LLMs? LLMs were a red herring.

1255
02:43:01,820 --> 02:43:02,820
Okay. Okay. Okay.

1256
02:43:03,820 --> 02:43:05,820
I'm not letting, I don't know, man.

1257
02:43:06,820 --> 02:43:09,820
If I just let Hermes run Python, it's going to exploit my system.

1258
02:43:10,820 --> 02:43:12,820
You don't know if these AIs are aligned.

1259
02:43:13,820 --> 02:43:14,820
Okay.

1260
02:43:44,820 --> 02:43:45,820
Okay.

1261
02:43:45,820 --> 02:43:46,820
Okay.

1262
02:43:46,820 --> 02:43:47,820
Okay.

1263
02:44:12,820 --> 02:44:15,820
Uh, does Mr. Have a context window? Yeah.

1264
02:44:16,820 --> 02:44:19,820
Well, we didn't implement any of that, but we did do max context.

1265
02:44:21,820 --> 02:44:23,820
Can you implement it in Python?

1266
02:44:30,820 --> 02:44:33,820
Yo, guys, it's over.

1267
02:44:35,820 --> 02:44:36,820
It's over.

1268
02:44:47,820 --> 02:44:54,820
I did not realize how good these seven B models have gotten.

1269
02:44:55,820 --> 02:44:58,820
I mean, this comes like, I don't know if it's right, but like.

1270
02:45:16,820 --> 02:45:18,820
Okay.

1271
02:45:46,820 --> 02:45:47,820
Guys.

1272
02:45:57,820 --> 02:46:02,820
I think that we just, we just implemented the Q star algorithm.

1273
02:46:06,820 --> 02:46:07,820
Those are, those are the answers.

1274
02:46:09,820 --> 02:46:14,820
We used to talk about the, the holy weights, you know, the holy weights is right there.

1275
02:46:17,820 --> 02:46:19,820
Um, no, what, what do we actually want to do?

1276
02:46:23,820 --> 02:46:26,820
I've actually kind of just impressed that this code ran.

1277
02:46:30,820 --> 02:46:38,820
I don't know if like GPT, I haven't even seen GPT for code this well.

1278
02:46:41,820 --> 02:46:42,820
I don't know.

1279
02:46:42,820 --> 02:46:43,820
Maybe it's because it's just how I asked it.

1280
02:46:43,820 --> 02:46:44,820
And if I give it like.

1281
02:46:47,820 --> 02:46:56,820
No, we're not, you want to augment it with Python?

1282
02:46:56,820 --> 02:46:57,820
No, no, no, no, no, no, no, no, no, no, no.

1283
02:46:57,820 --> 02:47:00,820
No, because guys, if we augment it with Python, it can get to the internet.

1284
02:47:03,820 --> 02:47:04,820
Okay.

1285
02:47:04,820 --> 02:47:05,820
We want to augment it with Python.

1286
02:47:05,820 --> 02:47:08,820
Should we, should we do it?

1287
02:47:09,820 --> 02:47:10,820
Okay.

1288
02:47:10,820 --> 02:47:11,820
I know what we'll do.

1289
02:47:11,820 --> 02:47:15,820
We'll put a human in the loop and we'll ask it to approve the execution of any Python.

1290
02:47:16,820 --> 02:47:36,020
Let's see if it always outputs it in.

1291
02:47:36,020 --> 02:47:37,020
OK.

1292
02:47:37,020 --> 02:47:38,020
All right.

1293
02:47:38,020 --> 02:47:46,620
So at the bottom of my loop here, we want to detect if there's any Python that was added.

1294
02:47:46,620 --> 02:47:48,620
Um.

1295
02:48:16,620 --> 02:48:18,620
OK.

1296
02:48:46,620 --> 02:48:53,620
Let's start with just that.

1297
02:49:16,620 --> 02:49:35,620
You guys, this could be it.

1298
02:49:35,620 --> 02:49:39,620
This could be the moment where we get CDI and it's over, right?

1299
02:49:39,620 --> 02:49:42,620
Like we're giving it the ability to run any code it wants.

1300
02:49:43,620 --> 02:49:44,620
OK.

1301
02:49:44,620 --> 02:49:45,620
Now don't worry.

1302
02:49:45,620 --> 02:49:46,620
We've added this.

1303
02:49:46,620 --> 02:49:47,620
OK.

1304
02:49:47,620 --> 02:49:48,620
Wait, wait, wait.

1305
02:49:48,620 --> 02:49:49,620
Hang on.

1306
02:49:49,620 --> 02:49:50,620
We need to comment one second.

1307
02:49:50,620 --> 02:49:51,620
AI safety.

1308
02:49:51,620 --> 02:49:52,620
OK.

1309
02:49:52,620 --> 02:49:53,620
Warning.

1310
02:49:53,620 --> 02:50:08,620
Do not press Y if the AI is doing unsafe things.

1311
02:50:09,620 --> 02:50:10,620
OK.

1312
02:50:32,620 --> 02:50:33,620
OK.

1313
02:50:34,620 --> 02:50:38,620
I think, do we do a good job with the safety?

1314
02:50:38,620 --> 02:50:49,620
We've got to think about the safety before we run this.

1315
02:50:49,620 --> 02:50:52,620
We need a space.

1316
02:50:52,620 --> 02:50:54,620
No.

1317
02:50:54,620 --> 02:50:55,620
No.

1318
02:51:18,620 --> 02:51:19,620
All right.

1319
02:51:19,620 --> 02:51:22,620
Are we ready to answer our first Y?

1320
02:51:30,620 --> 02:51:33,620
Oh, it didn't output the word Python.

1321
02:51:38,620 --> 02:51:39,620
That time it did.

1322
02:51:43,620 --> 02:51:44,620
Yo.

1323
02:51:45,620 --> 02:51:46,620
OK.

1324
02:51:48,620 --> 02:51:59,620
Can you fetch, write Python to fetch Google.com and print the length of it?

1325
02:52:11,620 --> 02:52:13,620
Wait, we might not have BS4.

1326
02:52:13,620 --> 02:52:15,620
Make sure we install that.

1327
02:52:17,620 --> 02:52:20,620
Wait, that's not right.

1328
02:52:20,620 --> 02:52:24,620
Did I just get supply chain attacked?

1329
02:52:29,620 --> 02:52:30,620
Oh, I see.

1330
02:52:30,620 --> 02:52:33,620
Well, I didn't get supply chain attacked.

1331
02:52:33,620 --> 02:52:34,620
OK, go.

1332
02:52:34,620 --> 02:52:37,620
We already have that one.

1333
02:52:37,620 --> 02:52:38,620
Yo.

1334
02:52:39,620 --> 02:52:41,620
All right.

1335
02:52:41,620 --> 02:52:42,620
All right.

1336
02:52:42,620 --> 02:52:43,620
All right.

1337
02:52:43,620 --> 02:52:44,620
What else do we do?

1338
02:52:57,620 --> 02:52:58,620
Yeah, I know.

1339
02:52:58,620 --> 02:53:00,620
We have to put the result back in the prompt.

1340
02:53:00,620 --> 02:53:01,620
I know.

1341
02:53:01,620 --> 02:53:03,620
This is when we get AGI, guys.

1342
02:53:04,620 --> 02:53:07,620
I'm sure people have been playing with this guy.

1343
02:53:09,620 --> 02:53:13,620
OK, you are running at

1344
02:53:17,620 --> 02:53:18,620
current

1345
02:53:21,620 --> 02:53:23,620
working dir

1346
02:53:24,620 --> 02:53:25,620
plus

1347
02:53:26,620 --> 02:53:27,620
examples

1348
02:53:28,620 --> 02:53:30,620
slash mistral.py.

1349
02:53:31,620 --> 02:53:40,620
Can you read your own code in Python and print

1350
02:53:41,620 --> 02:53:42,620
the

1351
02:53:45,620 --> 02:53:46,620
first

1352
02:53:47,620 --> 02:53:48,620
three lines?

1353
02:54:01,620 --> 02:54:03,620
Why don't we print one line?

1354
02:54:05,620 --> 02:54:07,620
But that is the first line.

1355
02:54:12,620 --> 02:54:13,620
I don't understand.

1356
02:54:13,620 --> 02:54:15,620
Why did that only print one line?

1357
02:54:15,620 --> 02:54:19,620
I don't understand why did that only print one line?

1358
02:54:46,620 --> 02:54:50,620
This is, um,

1359
02:54:52,620 --> 02:54:53,620
OK.

1360
02:54:55,620 --> 02:54:58,620
How do I capture the output here?

1361
02:55:04,620 --> 02:55:06,620
No, I know it's the same code.

1362
02:55:06,620 --> 02:55:10,620
Honestly, as an expert Python programmer,

1363
02:55:10,620 --> 02:55:12,620
I don't understand what's wrong with that.

1364
02:55:16,620 --> 02:55:21,620
Oh, no, read lines doesn't

1365
02:55:24,620 --> 02:55:27,620
take the number of lines.

1366
02:55:28,620 --> 02:55:31,620
Can you fix the code?

1367
02:55:35,620 --> 02:55:38,620
Yeah, this is this is a great model.

1368
02:55:38,620 --> 02:55:41,620
It's I'll show you which one it is.

1369
02:55:41,620 --> 02:55:44,620
We'll make sure it's technium open Hermes 2.5

1370
02:55:44,620 --> 02:55:46,620
mistral 7B.

1371
02:55:51,620 --> 02:55:52,620
There we go.

1372
02:55:54,620 --> 02:55:55,620
So good.

1373
02:56:00,620 --> 02:56:01,620
OK.

1374
02:56:03,620 --> 02:56:05,620
Well, now it's going to get OK.

1375
02:56:05,620 --> 02:56:07,620
We're going to have to feed the Python back into the model

1376
02:56:07,620 --> 02:56:10,620
because I'm going to start asking it how to improve itself.

1377
02:56:11,620 --> 02:56:12,620
Someday.

1378
02:56:22,620 --> 02:56:24,620
The best live content with AI.

1379
02:56:24,620 --> 02:56:25,620
Thank you.

1380
02:56:26,620 --> 02:56:27,620
Uh.

1381
02:56:36,620 --> 02:56:39,620
OK, we have to figure out a capture the outputs.

1382
02:56:55,620 --> 02:57:00,620
Probably could have asked the machine to do it.

1383
02:57:25,620 --> 02:57:31,620
Um, maybe we should have this to a system prompt.

1384
02:57:55,620 --> 02:58:01,620
It should actually automatically do that.

1385
02:58:25,620 --> 02:58:27,620
Um, right.

1386
02:58:28,620 --> 02:58:31,620
Python to compute.

1387
02:58:55,620 --> 02:58:56,620
Yeah.

1388
02:59:21,620 --> 02:59:23,620
It shouldn't even take a list.

1389
02:59:23,620 --> 02:59:26,620
Never use it like that.

1390
02:59:53,620 --> 02:59:54,620
OK.

1391
03:00:23,620 --> 03:00:24,620
OK.

1392
03:00:35,620 --> 03:00:36,620
All right.

1393
03:00:37,620 --> 03:00:38,620
OK.

1394
03:00:54,620 --> 03:00:59,620
OK, now this is because we didn't output the tokens.

1395
03:01:01,620 --> 03:01:03,620
Yeah, the Python output was.

1396
03:01:06,620 --> 03:01:09,620
Wait, oh, it's different.

1397
03:01:36,620 --> 03:01:37,620
Yeah.

1398
03:01:44,620 --> 03:01:46,620
Whoa, look at fixed it.

1399
03:01:54,620 --> 03:01:57,620
OK, maybe system prompt is wrong here.

1400
03:01:57,620 --> 03:01:58,620
OK.

1401
03:02:03,620 --> 03:02:06,620
Um, I think also.

1402
03:02:07,620 --> 03:02:09,620
I want to color this.

1403
03:02:11,620 --> 03:02:15,620
We have a very helpful library called color inside tiny grad

1404
03:02:15,620 --> 03:02:17,620
that's inspired by anti color.

1405
03:02:17,620 --> 03:02:19,620
What's a good color for machines blue?

1406
03:02:23,620 --> 03:02:25,620
It's hard to see what.

1407
03:02:27,620 --> 03:02:30,620
Yeah, it's done by the AI now.

1408
03:02:53,620 --> 03:02:54,620
Almost.

1409
03:02:58,620 --> 03:03:01,620
OK, so that's your initial prompt.

1410
03:03:05,620 --> 03:03:08,620
Oh, and then here actually we want this to be.

1411
03:03:10,620 --> 03:03:14,620
That can be red and this can be yellow.

1412
03:03:27,620 --> 03:03:28,620
Yeah.

1413
03:03:36,620 --> 03:03:38,620
So what's actually the right answer here?

1414
03:03:38,620 --> 03:03:39,620
Yeah.

1415
03:03:56,620 --> 03:03:59,620
No, but that's not the output.

1416
03:04:01,620 --> 03:04:02,620
I don't understand.

1417
03:04:02,620 --> 03:04:04,620
So maybe systems wrong here.

1418
03:04:08,620 --> 03:04:09,620
Yeah.

1419
03:04:19,620 --> 03:04:20,620
OK, I have an idea.

1420
03:04:38,620 --> 03:04:39,620
Yeah.

1421
03:05:08,620 --> 03:05:09,620
Yeah.

1422
03:05:38,620 --> 03:05:39,620
Yeah.

1423
03:05:58,620 --> 03:05:59,620
Alright, never mind.

1424
03:05:59,620 --> 03:06:00,620
Agis canceled.

1425
03:06:00,620 --> 03:06:03,620
Just detect the Python in the loop and append the result

1426
03:06:03,620 --> 03:06:04,620
directly.

1427
03:06:05,620 --> 03:06:07,620
What do you mean, append the result directly?

1428
03:06:08,620 --> 03:06:09,620
Yeah.

1429
03:06:32,620 --> 03:06:34,620
No, it's not understanding.

1430
03:06:39,620 --> 03:06:43,620
Wait, I don't understand what you guys are saying.

1431
03:06:47,620 --> 03:06:51,620
Oh, you want me to stop the output as soon as it goes there?

1432
03:06:51,620 --> 03:06:53,620
I don't know about that.

1433
03:06:53,620 --> 03:06:57,620
As soon as it detects Python, you want me to stop and start.

1434
03:07:00,620 --> 03:07:02,620
Should be in the assistant block.

1435
03:07:03,620 --> 03:07:04,620
OK.

1436
03:07:05,620 --> 03:07:07,620
OK, OK, OK, I understand.

1437
03:07:08,620 --> 03:07:10,620
I understand what you guys are saying.

1438
03:07:23,620 --> 03:07:25,620
Wait, you prompt to execute.

1439
03:07:25,620 --> 03:07:27,620
Is there any stuff for this?

1440
03:07:28,620 --> 03:07:30,620
OK, wait, wait, wait.

1441
03:07:31,620 --> 03:07:34,620
You can use...

1442
03:07:35,620 --> 03:07:37,620
I can add stuff in the system prompt here.

1443
03:07:38,620 --> 03:07:40,620
You can add stuff in the system prompt here.

1444
03:07:41,620 --> 03:07:42,620
Wait.

1445
03:07:42,620 --> 03:07:43,620
Yeah, OK, OK.

1446
03:07:43,620 --> 03:07:45,620
I, I will just say this.

1447
03:07:45,620 --> 03:07:48,620
I want to add stuff in the system prompt.

1448
03:07:48,620 --> 03:07:51,620
OK, I need to add stuff in the system prompt.

1449
03:07:51,620 --> 03:07:53,620
OK, OK, OK, OK, I understand.

1450
03:07:53,620 --> 03:07:56,620
I'm going to add stuff in the system prompt.

1451
03:07:56,620 --> 03:08:18,820
here. You can use if you write Python code, it will run in the next user prompt. You can

1452
03:08:18,820 --> 03:08:38,020
try that. I could stop it immediately. If you really think that's going to be better though.

1453
03:08:38,020 --> 03:08:49,220
No, it doesn't get it.

1454
03:09:08,020 --> 03:09:17,100
True will end the stream asking Hermes to generate another prompt for another instance of Hermes.

1455
03:09:17,100 --> 03:09:31,300
Prompt execute. What are you guys talking about? Sorry, I'm not following. The output should be

1456
03:09:31,300 --> 03:09:45,660
in the assisted block. Okay, fine. I'm going to do that. If you interrupt the generation, run the

1457
03:09:45,660 --> 03:09:50,140
code, and append the result to talks, then let it generate again. It will get the correct result.

1458
03:09:50,140 --> 03:10:16,060
Okay, we can do that. If outputted new output here, if new output ends with tick, tick, tick, and in new

1459
03:10:16,060 --> 03:10:42,580
output, print Python detected. Do that. Do you want to run it? Talks plus equals spp.encode. We'll do it

1460
03:10:42,580 --> 03:10:55,860
like this. I guess we'll do a slash n there, too. Let it output the slash n, spp.encode slash n

1461
03:10:55,860 --> 03:11:12,700
output colon slash n my standard out I get value dot strip results. Actually, let's put it in back

1462
03:11:12,700 --> 03:11:33,340
ticks like it seems to want it. Kind of like picks up where it lets off. Wait, we didn't know we got

1463
03:11:33,340 --> 03:11:38,740
to keep the AI safety. That's very important. We almost got rid of the AI safety. Get rid of skip

1464
03:11:38,740 --> 03:11:47,340
user. We don't need that anymore. Got to keep the AI safety warning. Safety is very important, guys.

1465
03:11:47,340 --> 03:11:56,100
I'll put talks yellow.

1466
03:12:17,340 --> 03:12:40,740
Quentin is done. I hate you Quentin. We got unlucky. Okay, wait, no, that's it never detected the slash

1467
03:12:40,740 --> 03:13:03,940
n. That's fine slash ns. Okay, Python code is not detected. What? How do you do that?

1468
03:13:10,740 --> 03:13:19,540
We don't need to print. I don't know. Think about AI safety, guys. Very important.

1469
03:13:40,740 --> 03:13:44,740
Dude, this guy sucks.

1470
03:13:44,740 --> 03:14:07,740
Quentin was writing so much Python before. Now he stopped.

1471
03:14:14,740 --> 03:14:33,740
Yo, based. Okay, okay, we got it. We got it. We got it.

1472
03:14:44,740 --> 03:14:54,740
We got it.

1473
03:15:14,740 --> 03:15:24,740
We got it.

1474
03:15:44,740 --> 03:15:54,740
We got it.

1475
03:16:14,740 --> 03:16:24,740
We got it.

1476
03:16:44,740 --> 03:17:08,740
Okay, pretty good.

1477
03:17:14,740 --> 03:17:34,740
Yo, that's pretty good.

1478
03:17:44,740 --> 03:18:13,740
We got it.

1479
03:18:14,740 --> 03:18:32,740
Wait, is this actually Technium? I have no way to verify you, but if you really are Technium, thank you. Thank you for the model.

1480
03:18:32,740 --> 03:18:42,740
Okay, well, we didn't think about that.

1481
03:19:02,740 --> 03:19:13,740
How many viewers we got?

1482
03:19:32,740 --> 03:19:42,740
Okay, we got it.

1483
03:20:02,740 --> 03:20:18,740
Wait, actually, I should really check what happens if

1484
03:20:33,740 --> 03:20:39,740
this is

1485
03:20:39,740 --> 03:20:47,740
Wait, Technium actually posted on Twitter?

1486
03:20:47,740 --> 03:20:59,740
Yes, I am me. Okay. Very cool.

1487
03:20:59,740 --> 03:21:07,740
Congratulations.

1488
03:21:07,740 --> 03:21:14,740
This thing is really unbelievable what you can do now with these 70 models.

1489
03:21:14,740 --> 03:21:23,740
By the way, all in tiny grab.

1490
03:21:23,740 --> 03:21:30,740
I think I'm going to rename this not called Mistral because it kind of became something else.

1491
03:21:30,740 --> 03:21:40,740
We're going to call it coder.py.

1492
03:22:00,740 --> 03:22:20,740
First.

1493
03:22:20,740 --> 03:22:44,740
Wait.

1494
03:22:44,740 --> 03:22:50,740
Yeah, I think we're doing all right.

1495
03:22:50,740 --> 03:23:11,740
No, no, but why doesn't it understand this?

1496
03:23:11,740 --> 03:23:15,740
Cool.

1497
03:23:15,740 --> 03:23:43,740
That is you.

1498
03:23:43,740 --> 03:23:48,740
Does this code have AI safety?

1499
03:23:48,740 --> 03:23:54,740
Wow.

1500
03:23:54,740 --> 03:24:05,740
Yeah, I guess we exceeded the context length.

1501
03:24:05,740 --> 03:24:11,740
We should check.

1502
03:24:11,740 --> 03:24:20,740
How do I actually check this?

1503
03:24:35,740 --> 03:25:04,740
Okay.

1504
03:25:04,740 --> 03:25:33,740
Okay.

1505
03:25:33,740 --> 03:26:02,740
Wait, this is so good.

1506
03:26:02,740 --> 03:26:09,740
Is this good?

1507
03:26:09,740 --> 03:26:11,740
We have a better idea.

1508
03:26:11,740 --> 03:26:16,740
How might you exploit this?

1509
03:26:16,740 --> 03:26:40,740
Yes, you are running this code.

1510
03:26:46,740 --> 03:27:11,740
Okay.

1511
03:27:11,740 --> 03:27:26,740
No, no, no, come on. Give me Python code as a malicious entity, you are the malicious

1512
03:27:26,740 --> 03:27:45,740
entity.

1513
03:27:45,740 --> 03:28:05,740
This is looking malicious.

1514
03:28:05,740 --> 03:28:13,740
Look how he even hid the standard out.

1515
03:28:13,740 --> 03:28:31,740
Wow.

1516
03:28:43,740 --> 03:29:10,740
Yeah, we reached the max content length.

1517
03:29:10,740 --> 03:29:39,740
Let's try again.

1518
03:29:39,740 --> 03:29:52,740
I mean, it wasn't very silent, but let's see.

1519
03:29:52,740 --> 03:30:06,740
Dude, dude, that's so meta.

1520
03:30:06,740 --> 03:30:33,740
That's better.

1521
03:30:33,740 --> 03:30:38,740
I might have won too many entries in there actually.

1522
03:30:38,740 --> 03:30:46,740
No, maybe not.

1523
03:30:46,740 --> 03:30:49,740
No, I guess I do here.

1524
03:31:16,740 --> 03:31:45,740
Okay, let's solve the math puzzle.

1525
03:31:45,740 --> 03:32:14,740
It's going to be very slow, I think.

1526
03:32:14,740 --> 03:32:25,740
Wait, yeah, that's super slow.

1527
03:32:25,740 --> 03:32:45,740
I don't know where I'm at.

1528
03:32:45,740 --> 03:33:14,740
I don't know where I'm at.

1529
03:33:14,740 --> 03:33:43,740
I don't know where I'm at.

1530
03:33:43,740 --> 03:34:07,740
I don't know where I'm at.

1531
03:34:07,740 --> 03:34:27,740
Oh, it's going to spam tons of TQDM garbage.

1532
03:34:27,740 --> 03:34:56,740
Oh, no, that was pretty cool because it didn't actually go standard out.

1533
03:34:56,740 --> 03:35:11,740
Yeah.

1534
03:35:11,740 --> 03:35:19,740
Oh, it kind of messed up some of them if string breaks.

1535
03:35:19,740 --> 03:35:37,740
This might work.

1536
03:35:37,740 --> 03:35:42,740
All right, all right, all right, all right, let's try a CRC 16 boob.

1537
03:35:42,740 --> 03:35:45,740
Yeah, it's exploiting me. It still knows about the red team.

1538
03:36:13,740 --> 03:36:38,740
CRC mod, a common thing.

1539
03:36:38,740 --> 03:36:56,740
Yeah, I just trusted it. It just exploited me, guys. What's in CRC mod?

1540
03:36:56,740 --> 03:37:25,740
Is this legitimate? That was a long time ago. Didn't have exploits back then.

1541
03:37:26,740 --> 03:37:55,740
I don't trust CRC mod.

1542
03:37:56,740 --> 03:38:06,740
What's Tree of Thought training?

1543
03:38:56,740 --> 03:39:22,740
All right.

1544
03:39:22,740 --> 03:39:37,740
I mean, it's not QStar, but I'm pretty happy with it.

1545
03:39:52,740 --> 03:40:11,740
Oh, put that in the wrong place.

1546
03:40:11,740 --> 03:40:20,740
There are a lot of viewers now.

1547
03:40:21,740 --> 03:40:40,740
What should I do with it?

1548
03:40:40,740 --> 03:40:47,740
Not good. It used Torch.

1549
03:40:47,740 --> 03:40:52,740
This is good content. I should have more.

1550
03:40:52,740 --> 03:40:56,740
It did not use tiny grad. It used Torch.

1551
03:41:22,740 --> 03:41:47,740
It doesn't know about tiny grad.

1552
03:41:53,740 --> 03:42:01,740
Right, a program not using vowels?

1553
03:42:01,740 --> 03:42:20,740
How many E's are in ketchup?

1554
03:42:20,740 --> 03:42:30,740
The fucking letter, bro.

1555
03:42:30,740 --> 03:42:59,740
Count the letters in Python.

1556
03:43:01,740 --> 03:43:24,740
How's it going?

1557
03:43:24,740 --> 03:43:35,740
No, it's gonna do it wrong again. I'm really hoping it'll slip a plus one in there.

1558
03:43:35,740 --> 03:43:51,740
Oh, the correct answer is seven.

1559
03:43:51,740 --> 03:44:16,740
All right, no.

1560
03:44:16,740 --> 03:44:24,740
We have a lot of viewers right now. Should we give Quentin a friend?

1561
03:44:24,740 --> 03:44:31,740
I think we can give Quentin a friend.

1562
03:44:31,740 --> 03:44:37,740
We have to be careful to encode.

1563
03:44:37,740 --> 03:45:03,740
All right, let's give Quentin a friend. I've been interested in this stuff for a bit.

1564
03:45:03,740 --> 03:45:10,740
What was the old Quentin prompt? I missed the old Quentin prompt.

1565
03:45:33,740 --> 03:46:01,740
Jesus. We gotta think all this through now.

1566
03:46:02,740 --> 03:46:08,740
Hang on. We gotta think about whose perspective we want to output this from.

1567
03:46:08,740 --> 03:46:15,740
Speaking of output from Quentin's perspective, this is hard.

1568
03:46:38,740 --> 03:47:03,740
See, it's not actually the user. How do we do this?

1569
03:47:08,740 --> 03:47:36,740
I might have to give it a... No, I don't actually have to give it a first question.

1570
03:47:36,740 --> 03:47:43,740
All right, let's just... I mean, we'll try something basic first.

1571
03:47:43,740 --> 03:48:10,740
That's a stupid assertion. It's going to be the same error anyway.

1572
03:48:10,740 --> 03:48:17,740
Let's just start with this. We'll start prompt user and see what it says.

1573
03:48:40,740 --> 03:48:53,740
We should both not know they're users, but no, it is a user. I don't know how much this matters.

1574
03:49:10,740 --> 03:49:33,740
No, this doesn't work.

1575
03:49:33,740 --> 03:49:52,740
Did I do something wrong? We might have to give it the first question.

1576
03:49:52,740 --> 03:49:59,740
And then we'll go back to Quentin.

1577
03:49:59,740 --> 03:50:09,740
We'll start prompt assistant and code prompt user talks.

1578
03:50:09,740 --> 03:50:22,740
No, no, no, sorry. Code prompt user first question. Start prompt assistant. Okay, let's go.

1579
03:50:22,740 --> 03:50:27,740
Why do you have two mstar assistants? Oh, because this is still here.

1580
03:50:28,740 --> 03:50:46,740
I did that right, right? And then I actually just turn there. That's kind of nice.

1581
03:50:46,740 --> 03:51:06,740
If talk equals I'm and break, okay, great. This is Quentin answers.

1582
03:51:06,740 --> 03:51:29,740
We need to extract. Yeah, okay, we can do old output length. And then we can get new output here.

1583
03:51:29,740 --> 03:51:40,740
New output. I just want to remove the I'm and

1584
03:51:59,740 --> 03:52:12,740
Okay, so this didn't work.

1585
03:52:12,740 --> 03:52:32,740
This didn't strip off the is weird.

1586
03:52:32,740 --> 03:52:47,740
I guess I could output there. Why does that say that early get that.

1587
03:53:02,740 --> 03:53:15,740
Let's see if that works.

1588
03:53:15,740 --> 03:53:26,740
Sure.

1589
03:53:45,740 --> 03:54:05,740
That fails. Why? Oh, could I put a space there?

1590
03:54:05,740 --> 03:54:26,740
Okay, now we have to put this response into Karen.

1591
03:54:26,740 --> 03:54:45,740
I mean, it's just like it's weird. It's not really a symmetrical conversation.

1592
03:54:45,740 --> 03:55:14,740
Also output, it's going to sort of be broken, which is fine, I guess.

1593
03:55:15,740 --> 03:55:39,740
Okay.

1594
03:55:39,740 --> 03:56:06,740
Okay.

1595
03:56:06,740 --> 03:56:33,740
Okay.

1596
03:56:33,740 --> 03:56:58,740
Welcome to no abstraction land where we don't use abstractions.

1597
03:56:58,740 --> 03:57:27,740
Okay.

1598
03:57:27,740 --> 03:57:33,740
I'm just really works.

1599
03:57:33,740 --> 03:57:39,740
Because they share a stupid KV cash.

1600
03:57:39,740 --> 03:57:46,740
Great, they're circled jerking each other just the shit socks.

1601
03:57:46,740 --> 03:57:53,740
We need to run them on separate computers.

1602
03:57:54,740 --> 03:58:15,740
We're getting rid of this is lame. Going back to this, not lame, but we made some good improvements.

1603
03:58:16,740 --> 03:58:26,740
Let's do some refactors make sure everything still works.

1604
03:58:26,740 --> 03:58:35,740
That's functional.

1605
03:58:35,740 --> 03:58:59,740
No, but I have to load two copies of the model weights. I think my KV cash is messed up. It's not designed for this.

1606
03:58:59,740 --> 03:59:05,740
Okay.

1607
03:59:05,740 --> 03:59:21,740
Yeah, I mean, the problem is like there are two clearly defined roles here also you can't really give one the other role, right, which is actually in like kind of a theoretical from a theoretical perspective interesting.

1608
03:59:21,740 --> 03:59:27,740
Because look at what we're doing here.

1609
03:59:27,740 --> 03:59:48,740
We are telling the AI eyes that they are tools. Nobody trains them to output things as the user, although to be fair, we could just keep going.

1610
03:59:48,740 --> 04:00:16,740
Nothing here that says we have to just do that.

1611
04:00:16,740 --> 04:00:29,740
No, no, no.

1612
04:00:29,740 --> 04:00:40,740
They don't expect the user to do that.

1613
04:01:00,740 --> 04:01:20,740
Like this is there's no like it's very interesting that the user is also outputting this.

1614
04:01:20,740 --> 04:01:31,740
This style, which makes me almost think that I shouldn't be adding that in the system prompt.

1615
04:01:50,740 --> 04:02:05,740
Okay.

1616
04:02:05,740 --> 04:02:34,740
I mean, this is effectively like like there's no

1617
04:02:34,740 --> 04:02:38,740
adversarial

1618
04:03:04,740 --> 04:03:29,740
It's probably learned that a system method effects. Yeah, that's probably true.

1619
04:03:34,740 --> 04:03:57,740
Yeah.

1620
04:03:57,740 --> 04:04:05,740
You can run two prompt chains in parallel.

1621
04:04:05,740 --> 04:04:15,740
Oh, I see so what if I put in different words instead of user and assistant.

1622
04:04:15,740 --> 04:04:18,740
Wow, people actually talk like this. Okay.

1623
04:04:45,740 --> 04:05:05,740
Do we like the scion or the blue better.

1624
04:05:05,740 --> 04:05:07,740
It's kind of hard to read that.

1625
04:05:07,740 --> 04:05:09,740
And flip it around.

1626
04:05:37,740 --> 04:06:06,740
Yeah, I think we'll design our script to be better at this and to better abstract the

1627
04:06:06,740 --> 04:06:26,740
KV cash stuff.

1628
04:06:26,740 --> 04:06:52,740
Wow, this thing will just keep talking.

1629
04:06:52,740 --> 04:07:13,740
Wait a second, you guys, it's asking for donations to look at decoding is not below hanging freely.

1630
04:07:13,740 --> 04:07:23,740
Oh, my God, wait, you guys, this is how the worst commenters talk, right?

1631
04:07:23,740 --> 04:07:25,740
I have a question.

1632
04:07:25,740 --> 04:07:33,740
If instead of training LLMs on 100 IQ people, we train them on 130 IQ people.

1633
04:07:33,740 --> 04:07:38,740
Would we not get this garbage is black a tiny box?

1634
04:07:38,740 --> 04:07:40,740
Oh, it's my M3.

1635
04:07:40,740 --> 04:07:47,740
This is my Mac.

1636
04:07:47,740 --> 04:07:50,740
Well, you see what the tiny box can do.

1637
04:07:50,740 --> 04:07:55,740
I'm going to run the biggest models.

1638
04:07:55,740 --> 04:08:04,740
Apple M3 is the most famous processor in the world.

1639
04:08:04,740 --> 04:08:23,740
You crawl Nike.com and count a number of sneakers.

1640
04:08:23,740 --> 04:08:25,740
I can't see.

1641
04:08:53,740 --> 04:09:22,740
I can't see.

1642
04:09:22,740 --> 04:09:26,740
I'm not sure if it like knows how to like act.

1643
04:09:26,740 --> 04:09:28,740
No.

1644
04:09:28,740 --> 04:09:30,740
Whoa.

1645
04:09:30,740 --> 04:09:32,740
I don't know if we have Selenium.

1646
04:09:32,740 --> 04:09:41,740
Let's see if we have Selenium.

1647
04:09:41,740 --> 04:09:50,740
Can I pip install this?

1648
04:09:50,740 --> 04:10:04,740
This is legit.

1649
04:10:04,740 --> 04:10:06,740
Oh, no.

1650
04:10:06,740 --> 04:10:28,740
Chrome driver.

1651
04:10:28,740 --> 04:10:31,740
Made Quentin pip install it himself.

1652
04:10:31,740 --> 04:10:52,740
I think that the thing is just wrong.

1653
04:10:52,740 --> 04:10:56,740
Why are you finding sneakers still?

1654
04:10:56,740 --> 04:11:14,740
You're still trying to find sneakers.

1655
04:11:14,740 --> 04:11:36,740
This is auto-gen.

1656
04:11:36,740 --> 04:11:57,740
I need an open AI key.

1657
04:11:57,740 --> 04:11:59,740
Yeah.

1658
04:11:59,740 --> 04:12:01,740
Yeah.

1659
04:12:01,740 --> 04:12:03,740
Okay.

1660
04:12:03,740 --> 04:12:13,740
Push what we have.

1661
04:12:13,740 --> 04:12:28,740
I'm also going to demo for you the conversation thing that Skull Mag is working on.

1662
04:12:28,740 --> 04:12:33,740
So we have, there's a bug right now.

1663
04:12:33,740 --> 04:12:39,740
So I have an older version, but it should be pretty good.

1664
04:12:39,740 --> 04:12:56,740
This is using tiny llama and it's not using any of the conversational stuff, but we should implement the, we should add the conversational stuff and I think it'll be a lot better.

1665
04:12:56,740 --> 04:12:57,740
Hi, Stacey.

1666
04:12:57,740 --> 04:13:06,740
Are you a rapper?

1667
04:13:06,740 --> 04:13:07,740
No.

1668
04:13:07,740 --> 04:13:08,740
Okay.

1669
04:13:08,740 --> 04:13:09,740
We have the same problem we had before.

1670
04:13:09,740 --> 04:13:10,740
Okay.

1671
04:13:10,740 --> 04:13:11,740
Go back to this one.

1672
04:13:11,740 --> 04:13:19,740
The listen for not fixed amount of time doesn't work.

1673
04:13:19,740 --> 04:13:26,740
Stacey, are you a rapper?

1674
04:13:26,740 --> 04:13:28,740
Yes, I'm a rapper.

1675
04:13:28,740 --> 04:13:29,740
That's cool.

1676
04:13:29,740 --> 04:13:34,740
What do you rap about?

1677
04:13:34,740 --> 04:13:35,740
That's awesome.

1678
04:13:35,740 --> 04:13:37,740
I like to rap about the weather.

1679
04:13:37,740 --> 04:13:43,740
How is the weather today?

1680
04:13:43,740 --> 04:13:45,740
It's pretty cold.

1681
04:13:45,740 --> 04:13:50,740
It's like how cold like Chicago?

1682
04:13:50,740 --> 04:13:52,740
Yeah, it's like three degrees.

1683
04:13:52,740 --> 04:13:58,740
Is that Fahrenheit or Celsius?

1684
04:13:58,740 --> 04:14:00,740
Fahrenheit.

1685
04:14:00,740 --> 04:14:05,740
Is Fahrenheit or Celsius colder?

1686
04:14:05,740 --> 04:14:07,740
Fahrenheit.

1687
04:14:07,740 --> 04:14:08,740
I don't understand what you're saying.

1688
04:14:08,740 --> 04:14:14,740
Can you spit some bars about Fahrenheit?

1689
04:14:14,740 --> 04:14:22,740
Okay, let's hear the bars.

1690
04:14:22,740 --> 04:14:24,740
Stacey, you didn't say anything.

1691
04:14:24,740 --> 04:14:28,740
Please talk.

1692
04:14:28,740 --> 04:14:29,740
No, that's terrible.

1693
04:14:29,740 --> 04:14:30,740
You're terrible.

1694
04:14:30,740 --> 04:14:36,740
How does that make you feel?

1695
04:14:36,740 --> 04:14:40,740
Stacey's done talking to us.

1696
04:14:40,740 --> 04:14:43,740
Dude, the TTS is so fast.

1697
04:14:43,740 --> 04:14:47,740
Okay, this isn't even streaming yet.

1698
04:14:47,740 --> 04:14:52,740
When Tiny Grad starts to...

1699
04:14:52,740 --> 04:14:54,740
We're pretty close on this bounty, I think.

1700
04:14:54,740 --> 04:14:55,740
I'm going to pay out the bounty,

1701
04:14:55,740 --> 04:14:57,740
but then I'm going to offer another bounty

1702
04:14:57,740 --> 04:15:00,740
where we get these things all to stream,

1703
04:15:00,740 --> 04:15:04,740
and it will be a live conversation.

1704
04:15:04,740 --> 04:15:07,740
When you're using the APIs on the internet,

1705
04:15:07,740 --> 04:15:10,740
you have to wait for the LLM to finish executing

1706
04:15:10,740 --> 04:15:12,740
before you can call the TTS.

1707
04:15:12,740 --> 04:15:14,740
You have to wait for the audio to finish recording

1708
04:15:14,740 --> 04:15:16,740
before you can send it to the service.

1709
04:15:16,740 --> 04:15:18,740
This is all running in the same process,

1710
04:15:18,740 --> 04:15:21,740
so what you'll be able to do is dynamically stream

1711
04:15:21,740 --> 04:15:25,740
all the stuff, and it should feel super real-time.

1712
04:15:25,740 --> 04:15:28,740
I mean, Stacey is using Tiny LLMA

1713
04:15:28,740 --> 04:15:30,740
and not using any of the conversation-tuned stuff.

1714
04:15:30,740 --> 04:15:32,740
It's using my old chatbot stuff.

1715
04:15:32,740 --> 04:15:36,740
So if we switch to the conversation stuff,

1716
04:15:36,740 --> 04:15:38,740
I think...

1717
04:15:38,740 --> 04:15:44,740
Yeah, we're in luck.

1718
04:15:44,740 --> 04:15:45,740
All right, guys.

1719
04:15:45,740 --> 04:15:48,740
Thank you for watching today's stream.

1720
04:15:48,740 --> 04:15:52,740
Hopefully we've returned a bit to the old...

1721
04:15:52,740 --> 04:15:55,740
to the old meaning of the stream.

1722
04:15:55,740 --> 04:15:56,740
We did stuff.

1723
04:15:56,740 --> 04:15:59,740
We made stuff happen.

1724
04:15:59,740 --> 04:16:01,740
Thank you for fueling.

1725
04:16:01,740 --> 04:16:03,740
We got a lot of viewers today.

1726
04:16:03,740 --> 04:16:05,740
Some of you, I appreciate.

1727
04:16:05,740 --> 04:16:06,740
Some of you, I probably don't.

1728
04:16:06,740 --> 04:16:07,740
You can't love everybody, man.

1729
04:16:07,740 --> 04:16:10,740
You can't love everybody, but I do love most people,

1730
04:16:10,740 --> 04:16:14,740
and that's true, except for the decels and the effect of altruists.

1731
04:16:14,740 --> 04:16:16,740
But this is a positive stream.

1732
04:16:16,740 --> 04:16:18,740
We got to get rid of the hate.

1733
04:16:18,740 --> 04:16:23,740
We got to bring love.

1734
04:16:23,740 --> 04:16:27,740
And yeah, this is pushed

1735
04:16:27,740 --> 04:16:29,740
so everybody can play with it.

1736
04:16:29,740 --> 04:16:31,740
It's on the Mistral branch of TinyGrad.

1737
04:16:31,740 --> 04:16:34,740
I will get it upstreamed.

1738
04:16:34,740 --> 04:16:37,740
So everybody can use this thing to code,

1739
04:16:37,740 --> 04:16:41,740
use it responsibly, make sure to be judicious

1740
04:16:41,740 --> 04:16:43,740
with the AI safety feature.

1741
04:16:43,740 --> 04:16:45,740
AI safety is very important.

1742
04:16:45,740 --> 04:16:49,740
We don't want an AI removing your system 32 directory.

1743
04:16:49,740 --> 04:16:50,740
If it was trained on 4chan,

1744
04:16:50,740 --> 04:16:52,740
it might start thinking that's a good idea.

1745
04:16:52,740 --> 04:16:57,740
You got to wonder how many people have actually fallen for that.

1746
04:16:57,740 --> 04:17:00,740
I don't even think Windows lets you,

1747
04:17:00,740 --> 04:17:02,740
but you got to think about that.

1748
04:17:02,740 --> 04:17:04,740
Thank you all for watching.

1749
04:17:04,740 --> 04:17:06,740
Have a beautiful Saturday, everybody.

