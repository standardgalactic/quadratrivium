WEBVTT

00:00.000 --> 00:05.400
And I'm sorry if this is a very kind of like a vague question, but are you familiar with

00:05.400 --> 00:06.400
the philosopher?

00:06.400 --> 00:11.360
Well, he's he's he calls himself doing foundations of physics.

00:11.360 --> 00:12.360
Tim Modellin.

00:12.360 --> 00:14.680
Um, no, I haven't heard of him.

00:14.680 --> 00:15.680
Yeah.

00:15.680 --> 00:16.680
So basically he's a fellow.

00:16.680 --> 00:20.920
He works in a philosophy department, although what his primary works like he's got a background

00:20.920 --> 00:21.920
in physics.

00:21.920 --> 00:28.720
I think he's got a PhD in physics and he his work is on deriving ontologies of the physical

00:28.720 --> 00:31.680
universe based on physics and what we know about modern physics.

00:31.680 --> 00:34.040
So he calls it the foundations of physics.

00:34.040 --> 00:40.200
And then when I was reading your stuff, it got me thinking, um, uh, is there such a thing

00:40.200 --> 00:48.000
as the, let's say the philosophical foundations of cognitive science and AGI, let's say, is

00:48.000 --> 00:55.720
is that something that we'd say researchers are actively working on or is that just what

00:55.720 --> 00:59.040
we would collectively call a philosophy of mine.

00:59.040 --> 01:04.600
So I think that with, uh, cognitive science, a lot of it is founded in things like logic

01:04.600 --> 01:07.440
and probability theory.

01:07.440 --> 01:13.400
And, uh, like, like there's, for example, the Bayesian brain hypothesis, which is hypothesis

01:13.400 --> 01:17.000
at the bind approximates Bayesian inference.

01:17.000 --> 01:20.400
And there's there are at least some empirical tests that provide some limited support for

01:20.400 --> 01:21.400
this.

01:22.200 --> 01:26.920
And there's more generally things like the problem of induction where there's this open

01:26.920 --> 01:32.520
question of how does the mind, uh, deduce, like induce the future from the past.

01:32.520 --> 01:38.320
But like, even if there's no logical justification for why the sun will rise tomorrow if it's

01:38.320 --> 01:44.240
always risen in the past, human minds will do this and there's some mechanistic explanation

01:44.240 --> 01:45.240
for this.

01:46.080 --> 01:56.880
Um, so I think the, uh, some of the foundations include these like basic things that are considered

01:56.880 --> 02:03.120
like parts of good reasoning, such as, um, uh, logic and probability theory.

02:03.120 --> 02:08.840
Uh, then there's, uh, you mentioned the mind body problem, um, and that's that definitely

02:08.840 --> 02:13.320
intersects with neuroscience a lot because there's this methodological assumption that

02:13.320 --> 02:16.800
these states of the mind are somehow encoded in the brain.

02:16.800 --> 02:24.440
Um, and this is like broadly pretty likely based on current scientific understanding,

02:24.440 --> 02:29.120
um, that like, for example, there aren't, if you, if you notice some difference in your

02:29.120 --> 02:35.760
mind, you have like n bits in your mental state, then that there have to be at least

02:35.760 --> 02:42.200
n bits in your brain state for that to be, um, represented somehow.

02:43.200 --> 02:48.760
Um, so I, I'd say that neuroscience certainly has a philosophy of mind as a foundation in

02:48.760 --> 02:56.040
terms of assumptions about how the mind's processing, uh, relates to the brain functions.

02:56.040 --> 02:59.280
Honestly, um, sorry, keep going.

02:59.280 --> 03:03.600
Oh, you also mentioned, uh, the foundations of cognitive science and AI.

03:03.600 --> 03:04.600
Yeah.

03:04.600 --> 03:05.600
Yes.

03:05.600 --> 03:06.600
Yes.

03:06.600 --> 03:09.760
I would say that AI is more founded in something I said before, which is just foundations of

03:09.760 --> 03:15.240
correct reasoning, which includes things like logic, probability theory, and induction.

03:15.240 --> 03:16.240
Understood.

03:16.240 --> 03:17.240
Yeah.

03:17.240 --> 03:22.000
Because the one thing I was thinking about was, so for instance, uh, if I kind of expand

03:22.000 --> 03:28.600
on that question, uh, like Tim Maudlin, when, when he says foundations of physics, I feel

03:28.600 --> 03:31.280
like that's in a way quite straightforward.

03:31.280 --> 03:37.320
It's trying to, trying to find, uh, kind of the ontological reality of our physical world,

03:37.320 --> 03:38.840
the physical universe.

03:38.840 --> 03:45.480
But then when it comes to something like AI or maybe perhaps more specifically, uh, COGSI,

03:45.480 --> 03:51.040
it gets a bit hazy because yes, we have cognition and the human subject, but then the question's

03:51.040 --> 03:53.120
like, what is human subjectivity?

03:53.120 --> 03:57.520
And that's a question, I guess, asked since the beginning of philosophy in some sense,

03:57.520 --> 03:58.520
right?

03:58.520 --> 04:02.480
And then especially since the Kant and the German idealist and then that got me thinking,

04:02.480 --> 04:07.280
um, are there really, do we really have, uh, people walking?

04:07.480 --> 04:15.280
In cognitive science that are trying to kind of, uh, let's say speculate and, and derive

04:15.280 --> 04:23.080
meaningful, uh, foundations of what a human subject is based on cognitive science and

04:23.080 --> 04:24.080
AI.

04:24.080 --> 04:27.840
So you would, would you say from what you just said that the answer is yes, or is it

04:27.840 --> 04:33.880
still more like, I'll just focus on the science itself, forget about, uh, you know, ontology

04:33.880 --> 04:34.880
or philosophy?

04:35.880 --> 04:38.320
Oh, I would say yes.

04:38.320 --> 04:43.440
And I think that it might be hard to notice this if you're just looking at papers published

04:43.440 --> 04:49.400
because partially the papers are assuming some amount of background of people in the field

04:49.400 --> 04:51.400
already share certain assumptions.

04:51.400 --> 04:56.640
And partially also, um, when people are presenting their findings, they're not trying to look

04:56.640 --> 04:57.640
too speculative.

04:57.640 --> 05:04.320
Um, like I think a big thing in science is that you, an under-specified part of the scientific

05:04.320 --> 05:07.280
method is how do you even come up with these hypotheses in the first place?

05:07.280 --> 05:11.000
Like the method says, once you have a hypothesis, you should go out and test it, but how do

05:11.000 --> 05:12.000
you come up with the hypothesis?

05:12.000 --> 05:13.440
It can, it can be very intuitive.

05:13.440 --> 05:15.400
It can come to you in a dream, even.

05:15.400 --> 05:19.840
Um, so I think when scientists are presenting their findings, um, they might have gotten

05:19.840 --> 05:24.720
their hypothesis in a certain manner, which might be intuitive or based on kind of philosophical

05:24.720 --> 05:29.720
thought, um, that they're trying to show their finding in a non-speculative manner.

05:30.160 --> 05:36.800
Um, but I think in, certainly I've talked with cognitive scientists and they do tend

05:36.800 --> 05:39.000
to speculate about the human subject.

05:39.000 --> 05:44.720
Um, so I mentioned the Bayesian brain hypothesis and I've learned that hypothesis when it,

05:44.720 --> 05:48.880
perhaps the primary thing that humans are doing is constructing a model of the world

05:48.880 --> 05:53.480
based on sense data that is meant to do things such as predict future sense data.

05:53.480 --> 05:58.640
Um, and then you can even go from that to think about values and like what are values

05:58.680 --> 06:05.680
and, um, there's, there's things like planning algorithms, which might tell you like if, if

06:05.680 --> 06:10.840
I have a certain value that will tend to, um, cause me to take certain actions that

06:10.840 --> 06:12.640
will achieve that end.

06:12.640 --> 06:15.000
And there's various algorithms that approximate that.

06:15.680 --> 06:24.760
Um, and it's, it's very much like, uh, that, like if, if you, if you, if you're having

06:24.760 --> 06:30.240
these sorts of thoughts about what it is like to model the world and to want things and

06:30.240 --> 06:34.840
plan towards them, um, that can certainly influence your own understanding of yourself

06:34.840 --> 06:36.160
or other humans as well.

06:38.440 --> 06:38.680
Yeah.

06:38.680 --> 06:39.760
What was the algorithm?

06:39.760 --> 06:45.560
Just because you said to penny algorithm planning, um, yeah.

06:45.560 --> 06:51.520
So if you, I guess things like, uh, reinforcement learning use some form of this, um, we're like

06:51.520 --> 06:55.680
in an alpha code has like an evaluation of board states and some kind of Monte Carlo

06:55.680 --> 06:58.280
tree search to search among the game tree.

06:58.760 --> 07:04.280
Um, and, uh, there, there's other algorithms like, like there's, there's like in, in simpler

07:04.280 --> 07:10.880
logical, um, problems you can do, do like back chaining to start from a goal state and

07:10.880 --> 07:13.840
ask like, what, what is the state before the goal state looked like?

07:14.160 --> 07:17.280
And then like, what does the state before that look like and try to get back to your current state?

