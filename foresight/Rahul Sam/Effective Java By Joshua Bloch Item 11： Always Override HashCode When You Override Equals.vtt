WEBVTT

00:00.000 --> 00:06.960
Hey everyone, welcome to yet another episode of my video series on Joshua Bloch's effective Java

00:06.960 --> 00:14.640
and today we're going to cover item number 11, always override hash code when you override equals.

00:15.280 --> 00:20.320
But of course, before I get to the item as I usually do in the series, I want to go through

00:20.320 --> 00:26.480
this proviso and make a few points. Starting off, this is not a tutorial. I'm not a teacher.

00:27.040 --> 00:34.560
Nor am I certainly an expert in Java or object oriented programming in general. So please don't

00:34.560 --> 00:43.040
take what I say as gospel truth, always double check, do your own research. This is simply me

00:43.040 --> 00:49.520
sharing my learning experience. That's purely it. So don't treat this video series like a tutorial.

00:49.520 --> 00:56.720
I may spew or give out false information, unfortunately, though I will try not to.

00:57.760 --> 01:04.240
Think of it more as the blind, leading the blind, that's an analogy that I've been using for a while

01:04.240 --> 01:12.560
now. I am as blind or perhaps even more blind than you are. So this is merely a exploratory

01:12.560 --> 01:17.680
disquisition. I'm just figuring this thing out and hopefully we can learn together. In fact,

01:17.680 --> 01:22.560
I've already been corrected in a few of my other videos and I've been trying to rectify those errors.

01:23.680 --> 01:31.520
Therefore, again, not to repeat the same point, I will inevitably make mistakes. So please do

01:31.520 --> 01:36.560
point them out more for the benefit of the videos and myself. But yes, of course, for the benefit

01:36.560 --> 01:44.640
of myself too, selfish speaking. And given this is a, in fact, programming video series,

01:44.640 --> 01:49.920
all the code that I use that I've been using for all the previous items that you can see here,

01:49.920 --> 01:57.040
it's all available on my GitHub repo. I'll leave a link to the code for today's item, item number 11

01:57.040 --> 02:05.280
to my repo, but also to Joshua Block's sort of official repo that he has for this book.

02:05.280 --> 02:09.360
Saying that without further ado, let's get started. So yeah, as I said, item number 11,

02:10.080 --> 02:17.280
which is always override hash code when you override equals and the item starts off like this.

02:19.200 --> 02:25.280
Joshua Block states, you must override hash code in every class that overrides equals.

02:25.280 --> 02:31.920
If you fail to do so, your class will violate the general contract for hash code, which will

02:31.920 --> 02:38.240
prevent it from functioning properly in collections such as hash map and hash set. But before we

02:38.240 --> 02:43.920
continue on with the item, let's get some key phrases or key terms out of the way, get some

02:43.920 --> 02:50.640
definitions out of the way. So what is hash code? And who better to ask than chat GPT? And oh,

02:50.640 --> 02:57.040
I forgot to mention, this item is a part of chapter three methods common to all objects.

02:57.040 --> 03:04.160
So back to it. What is hash code? Chat GPT states, and I think it's accurate here because I did

03:04.160 --> 03:11.840
double check with a few other resources or definitions online. In computing, a hash code

03:11.840 --> 03:20.640
also called a hash value, check sum or simply a hash is a fixed array, sorry, is a fixed size

03:20.640 --> 03:27.360
string of characters that is generated by a one way mathematical function called a hash function.

03:28.080 --> 03:35.120
From an input of any size, often call the message. The resulting hash code is typically

03:35.680 --> 03:42.160
a hexadecimal number that is a unique representation of the input. The main purpose of a hash code

03:42.160 --> 03:48.640
is to take an input and produce a fixed size string of characters that can be used to identify

03:48.640 --> 03:54.880
or verify the input. Hash codes are commonly used in data structures such as hash tables,

03:54.960 --> 04:01.680
OS, just look at stated hash maps and hash sets. And in various algorithms, such as message,

04:02.640 --> 04:08.560
sorry, such as message authentication codes, digital signatures and check sums. Oh,

04:08.560 --> 04:14.400
this is an important point regarding hash functions. Hash functions are designed to be one way and

04:14.400 --> 04:21.120
deterministic, meaning that the same input will always produce, let me zoom in a bit actually,

04:22.080 --> 04:27.280
meaning that the same input will always produce the same output, but it is computationally

04:27.280 --> 04:33.120
infeasible to determine the original input from the output. And then more in the context of Java,

04:33.120 --> 04:38.400
I got this definition from educative.io, when the hash code, which is the hash code method,

04:38.400 --> 04:44.720
is called on two separate objects which are equal according to the equals method. So by the way,

04:44.720 --> 04:50.080
we discussed the equals method in the previous items. If you want to understand, get a, in fact,

04:50.080 --> 04:54.320
a really deep understanding of the equals method, I suggest or recommend you watch

04:55.200 --> 05:01.440
all four parts for item number 10 because it was such a big item. I had to break it down into four

05:01.440 --> 05:07.600
different videos, but in that, I dealt deeply into the equals method. In that case, getting back to

05:07.600 --> 05:15.200
this, which is called on two separate objects, it returns the same hash code value. However,

05:15.280 --> 05:20.800
if it is called on two unequal objects, it will not necessarily return different integer values.

05:20.800 --> 05:26.800
So that's the definition in the context of Java. So to get started, here's a really simple,

05:26.800 --> 05:33.840
straightforward class as to how the hash code is used, example, courtesy of educative.io, of course.

05:34.640 --> 05:41.280
So there's a class called hash, declared two strings, and keep in mind that these strings

05:41.280 --> 05:49.680
are immutable. And if equals b, this function will indicate that object a is equal to object b.

05:50.640 --> 05:57.120
And it's important to keep in mind, if there is logical equality between two objects, if the hash

05:57.120 --> 06:05.280
code wasn't overridden, then unfortunately, we would get two different hash codes for these two

06:05.280 --> 06:10.960
objects that have logical equality. And that, in fact, is a anti-pattern or a violation of the

06:10.960 --> 06:16.480
hash code contract. And that's what we're trying to demonstrate here. So also, if it's not equal,

06:16.480 --> 06:22.800
here, it'll say that it's not equal. So if I run this, you'll see that a is equal to b, and c is

06:22.800 --> 06:28.560
not equal to d. So we have the equal variables. And then we have, let me zoom in a bit.

06:29.280 --> 06:35.280
We have the equal variables and the unequal variables. And you can clearly see, in the equal

06:35.280 --> 06:42.560
variables, because the string class follows the hash code contract, the hash code is the same.

06:42.560 --> 06:46.800
And for unequal variables, there are different hash codes. So that's good. That means the string

06:46.800 --> 06:52.000
class has overridden the hash code method. Speaking of the hash code contract, what does that mean?

06:52.000 --> 06:57.200
What is the hash code contract? As we saw from the demo, if two objects have logical equality,

06:57.920 --> 07:02.400
if there's an invocation of the hash code method, it should always consistently return the same

07:02.400 --> 07:08.240
value, whatever it may be. Although a caveat is it can differ depending on the application state,

07:08.240 --> 07:13.840
but that too should be considered when designing the hash code method. Or to put in a bit more

07:13.840 --> 07:21.520
clear way, let's say, using chargeGPT. For example, if you have an object that has a unique ID

07:21.760 --> 07:29.200
that is generated when the object is created, the hash code method could use this ID as a part

07:29.200 --> 07:35.040
of its calculation. Because the ID is unique to each instance of the object, the hash code method

07:35.040 --> 07:40.560
would return a unique value for each object. However, if the application is run again,

07:40.560 --> 07:45.920
the ID may not be the same. And thus, the hash code method would return a different value.

07:46.880 --> 07:52.720
This is the example that chargeGPT gave me when I asked to give an example, let's say, in the real

07:52.720 --> 07:58.960
world of how the hash code would differ depending on the application state. So that kind of makes

07:58.960 --> 08:05.520
sense because it's kind of depending on this external resource, which is the unique ID in this

08:05.520 --> 08:11.360
case. And of course, this seems like an obvious point, but it has to be stated. If they don't have

08:11.440 --> 08:19.040
logical equality, then it would probably give different hash codes when the hash code method

08:19.040 --> 08:24.800
is indicated. However, that also does not mean or there's no requirement that it should produce

08:24.800 --> 08:33.440
distinct results. Despite two objects not having logical equality, it's possible for it to return

08:33.440 --> 08:38.960
the same hash code. Though the vice versa, the opposite of that would be if they do have logical

08:38.960 --> 08:42.880
equality, then most certainly the hash code should be the same. Or put more succinctly,

08:42.880 --> 08:48.640
logical inequality doesn't necessarily mean objects will have different hash codes. However,

08:48.640 --> 08:55.360
as I've said here, if hash code, the implication of the method hash code, does return distinct

08:55.360 --> 09:01.840
integers for objects, this will improve performance in hash based collections as this will reduce

09:01.840 --> 09:08.720
collisions. Because there could be collisions if while they don't have logical equality,

09:09.280 --> 09:15.520
it still returns the same hash code. So if we can design a good quality hash code method,

09:15.520 --> 09:22.880
that will even try and prevent this, where we know for sure that two logically

09:22.880 --> 09:27.760
unequal objects will always have distinct hash codes, it will reduce these collisions.

09:27.760 --> 09:33.680
And the collection, and so whatever the collection that's using a hash based collection,

09:33.680 --> 09:38.320
won't have to look for logical equality prior to putting an object in a location

09:38.320 --> 09:42.320
or a hash bucket to be more specific. Now what I mean by this latter point,

09:42.320 --> 09:47.200
putting it into a location in a hash based data structure, it'll make more sense as we go through

09:47.200 --> 09:56.320
the demos. But the idea is, in a hash map or hash table or whatever, hash based data structure,

09:56.320 --> 10:02.800
when you give it objects, it'll look for, it will do the calculation and get the hash code,

10:02.800 --> 10:06.640
and then it'll put it in a specific hash bucket depending on the hash code, but also

10:07.760 --> 10:13.520
it'll look for logical equality. It'll look for logical equality because if there is logical

10:13.520 --> 10:17.520
equality, then without doing any more calculations, it could straight away put it in the specific

10:18.560 --> 10:24.800
hash bucket. The thing though is, I believe, and I think it works this way,

10:25.600 --> 10:35.200
it'll also create a kind of a link list if these objects have the same hash bucket. So it'll compare

10:38.640 --> 10:43.840
actually on second thought, I may be talking out of my ass here. So I'm just going to shut up

10:43.840 --> 10:50.000
and keep going and not try and make that point with such certainty. The point being,

10:50.640 --> 10:58.080
generally, considering both logical equality and inequality, it's perhaps a good idea to reduce

10:58.080 --> 11:06.240
collisions. Just take that as a general rule of thumb, let's say. Sorry, man. I've been thinking

11:06.240 --> 11:11.840
out loud here, and I don't know. Sometimes when you think out loud, you clearly do say bullshit,

11:11.840 --> 11:16.400
and I apologize if I did say something false there. Okay, so to clean up my mess and to not

11:16.400 --> 11:23.440
keep digging myself into this hole, I'm just going to go read off the book as that, in fact, is a

11:23.440 --> 11:28.560
good source of truth. On the point that I was trying to articulate here, here's what Joshua

11:28.560 --> 11:36.000
Block states. The key provision that is violated when you fail to override hash code is the second

11:36.000 --> 11:43.040
one. Equal objects must have equal hash codes. That's a really important point. Two distinct

11:43.040 --> 11:49.040
instances may be logically equal, according to a class's equals method, but two objects

11:49.040 --> 11:55.440
hash code method, they're just two objects with nothing much in common. And of course,

11:55.440 --> 12:01.920
therefore, objects hash code method returns to seemingly random numbers instead of two equal

12:01.920 --> 12:08.080
numbers as required by the hash code contract, which we discussed just here. So the idea of

12:08.080 --> 12:15.680
logical equality, giving the same hash code for hash code method invocation can be simply

12:15.680 --> 12:20.720
demoed with this phone number class that Joshua Block, in fact, has used. And this class was also

12:20.720 --> 12:26.880
used in item 10, I believe. We have a class called phone number that represents a phone number with an

12:26.880 --> 12:34.400
area code prefix and a line number. So if we go to the main method in this class,

12:34.800 --> 12:44.080
I've created an instance of, well, I've got a hash map here, sorry. And this hash map has

12:45.280 --> 12:52.160
key values of phone number and then a string, which is a phone number. If I put a new phone number

12:52.160 --> 13:00.320
object with the name Jenny into this hash map, what I'd expect is, as you can see here,

13:00.320 --> 13:07.120
I'm creating a new phone number object and I'm putting it in. Now, this hash map, because it's a

13:07.120 --> 13:13.840
hash based data structure, it's going to use the hash code of this object where to find the

13:13.840 --> 13:19.600
location in the map to put this object, the key and the value. So there's going to be the key

13:19.600 --> 13:27.360
with the hash code and the value is going to be Jenny. And it'll do that based on the hash code

13:27.360 --> 13:34.960
of this object, as I said, like 10 times already. Then in the next line, I'm trying to get that

13:34.960 --> 13:42.480
same value, Jenny, from the hash map. So what I'm doing is I'm saying m.get, so that's the hash map

13:42.480 --> 13:48.480
and I'm saying, hey, here's the key, give me that value. But unfortunately, because we haven't

13:48.480 --> 13:55.440
overwritten the hash code method, when this code is run, it returns a null. Because what happens is

13:55.440 --> 14:01.200
in the get, it'll create a different hash code, a new hash code, and it'll look for it in the

14:01.200 --> 14:09.760
hash map and it can't find it, so it'll return null. Despite both of these objects, this one here

14:09.760 --> 14:15.040
and this one here clearly having logical equality because they've got the same area code, prefix

14:15.040 --> 14:21.360
and line number. Now, simply the way to fix it is to override the hash code, which we've done here.

14:21.360 --> 14:26.480
I'll go through all of this stuff a bit later, much more punctiliously. But at the moment, just

14:26.480 --> 14:32.320
assume it has been overwritten to reflect logical equality. And now what will happen is the same

14:32.320 --> 14:38.640
bit of code that I'm going to run, it'll return Jenny. There you go. Which is good, because that's

14:38.640 --> 14:44.800
what we want. Because that means the hash base collection identified that we're in fact looking

14:44.800 --> 14:50.240
for this the same object. Or as Joshua block states, the phone number classes failure to override

14:50.240 --> 14:56.720
hash code courses the two equal instances to have unequal hash codes, which is why initially

14:56.720 --> 15:02.480
before the overwritten in the retrieval, we got a null in violation of the hash code contract.

15:03.520 --> 15:08.640
Therefore, the get method is likely. So I'll leave it in the code because it makes more sense

15:08.640 --> 15:14.160
than that. That's the get method. The therefore the get method is likely to look for the phone

15:14.160 --> 15:18.800
number in a different hash bracket from the one in which it was stored by the put method.

15:19.520 --> 15:25.120
Even if the two instances happen to hash to the same bucket, the get method will almost

15:25.120 --> 15:31.760
certainly return null because hash map has an optimization that caches the hash code associated

15:31.760 --> 15:38.480
with each entry and doesn't bother checking for object equality if the hash codes don't match.

15:38.480 --> 15:42.880
This kind of relates to the previous point that I tried to terribly articulate using

15:43.440 --> 15:48.240
bloody length list and all that. But the idea is that the idea is that if they do have

15:49.680 --> 15:54.240
hash codes that don't match, it's because the value is cash, it'll just return the cash value

15:54.240 --> 15:58.400
in this case a null. Now fixing the problem would be overriding the hash code method. The

15:58.400 --> 16:03.360
example I showed here is in fact, this is a good way of overriding it. But the worst way,

16:03.360 --> 16:08.960
despite it being legal, would be to simply return the same value returning 42 here.

16:09.440 --> 16:13.760
One should never do this because in this case for every single value, it's going to return

16:14.400 --> 16:19.760
the same hash code and that is that is hell. Or instead of invoking biblical references to

16:19.760 --> 16:26.400
put it the way Josh of Lockwood, it's legal because it ensures that equal objects have the

16:26.400 --> 16:33.760
same hash code. It's atrocious because it ensures that every object in fact has the same hash code

16:34.320 --> 16:39.280
and that shouldn't be the case. Therefore, every object hashes to the same bucket

16:39.280 --> 16:44.080
and hash tables degenerate to link lists. This was the point I was trying to make before

16:44.720 --> 16:51.680
and I kind of confused the two. And then he said it's programs that should run in linear time

16:51.680 --> 16:56.960
instead of running quadratic time. So just to get a bit of that computer science out of the way,

16:56.960 --> 17:01.440
I wouldn't say out of the way, it's in fact quite interesting. This is quite important to

17:01.440 --> 17:06.000
understand when it comes to designing algorithms, the difference between linear time and quadratic

17:06.000 --> 17:13.200
time. In linear time, the number of steps required is directly related one to one. So big O of n.

17:13.200 --> 17:18.000
So it's a number of elements, let's say in a data structure. So if it's in an array,

17:18.000 --> 17:23.360
it's the number of elements in that array. If the array is of size five, it would be big O of five

17:23.360 --> 17:30.640
here. In quadratic time, the number of steps is taken to accomplish a task is n squared because

17:30.640 --> 17:37.120
each item has to be compared with with each other. Now, because I'm partially retarded,

17:38.400 --> 17:45.920
I had to tell Judge GPT to explain this to me like I was Michael Scott from the office,

17:45.920 --> 17:50.480
because in many ways I embody that archetype. Yes, Michael Scott is an archetype in fact.

17:51.440 --> 18:00.240
And I ask from, sorry about that, a bit of background noise, let the plane pass. It's passing.

18:01.760 --> 18:09.360
And it's passed. Excellent. So I told Judge GPT, explain linear time versus quadratic time in

18:09.360 --> 18:15.280
computing like Michael Scott from the office. And here's what Judge GPT told me. And in fact,

18:15.360 --> 18:20.800
this is really good. This is really good explanation. Sure. Let's imagine you're trying to find a

18:20.800 --> 18:26.800
specific paperclip, haha, office reference, because you know, it's a paper company, find a specific

18:26.800 --> 18:34.160
paperclip in a huge pile of paperclips. If you use a linear time algorithm, it's like you're checking

18:34.160 --> 18:41.440
each paperclip one by one in a line, which is why it's called linear, I guess, until you find the

18:41.520 --> 18:47.120
one you're looking for. It takes a little longer with more paperclips, but the time it takes to

18:47.120 --> 18:52.720
search for the paperclips grow at a steady pace, just like a straight line. So it's,

18:53.920 --> 19:00.240
would it be called exponential? No, it's correlated to the amount of paperclips or simply put big

19:00.240 --> 19:08.480
O of N. But if you use quadratic time algorithm or a quadratic time algorithm, it's like you're

19:08.480 --> 19:15.440
checking each paperclip against every other paperclip in the pile over and over again,

19:15.440 --> 19:20.480
as the number of paperclips grows. The amount of time it takes to search for one,

19:20.480 --> 19:25.120
you're looking for grows at an exponential rate. So sorry, just to keep in mind, quadratic time

19:25.120 --> 19:30.880
is exponential, like a big square. So linear time is like searching through a line of paperclips,

19:30.880 --> 19:36.720
while quadratic time is like searching through a pile of paperclips. The former is faster and

19:36.720 --> 19:42.800
more efficient as the number of paperclips grows. So it's because of that reason, a good hash function,

19:42.800 --> 19:49.040
leaving aside the legality, so to speak, should produce distinct hash codes for unequal instances

19:49.040 --> 19:55.200
to prevent this, this mess of linear time and quadratic quadratic time when putting into a

19:55.200 --> 20:01.360
hash based data structure. Or as put in the book, this is exactly what is meant by the third part

20:01.360 --> 20:08.000
of the hash code contract. Ideally, a hash function should distribute any reasonable collection

20:08.000 --> 20:12.800
of unequal instances uniformly across all int values. And I kind of wanted to

20:13.520 --> 20:18.560
a more elaborated definition of this. So of course, I once again asked Judge CPT,

20:19.520 --> 20:24.720
and it said, for example, if the hash function returns integers, it should distribute the hash

20:24.720 --> 20:30.240
values evenly across the possible integer value. So if the hash function is applied to 10 unequal

20:30.240 --> 20:37.520
objects, the hash values produced for those objects should be spread across all the possible

20:37.520 --> 20:45.680
integer values, not just a small range of values. This helps to ensure efficient hash based data

20:45.680 --> 20:51.920
structures, such as hash tables, where hash collision should be kept to a minimum. Now,

20:51.920 --> 20:57.200
all of this explained here, this is, I think it kind of seems not self evident, but after this

20:57.200 --> 21:03.360
explanation, it seems to make sense. It's about uniformity. It should be spread across uniformly,

21:03.360 --> 21:08.640
depending on the int number of values you give it. But how do we achieve this? Because that's

21:08.640 --> 21:13.840
the ideal, and it can be a bit tricky at first glance. But fortunately, Joshua Block has stated

21:15.040 --> 21:20.240
there is a recipe for a high quality hash function. So to understand this hash function,

21:20.240 --> 21:27.120
firstly, let's go through the theory step by step, and then I'll jump into the demo and it'll

21:27.200 --> 21:31.760
obviously make a lot more sense when you see the actual code. Step number one is to declare an

21:31.760 --> 21:39.040
int variable called result and simply assign the value of the first significant field into this

21:39.040 --> 21:44.960
result variable. And keep in mind, as Joshua Block has stated here, recall from item 10 that a

21:44.960 --> 21:50.480
significant field is a field that affects equals comparisons. So whatever it may be, assign that

21:50.480 --> 22:00.960
to this variable value. Obviously, I screwed that up. I reread that a couple of times, and I

22:00.960 --> 22:07.040
made a blunder, I made a huge error there. It's you don't assign the value of the first significant

22:07.040 --> 22:17.520
field, you assign the hash code value of the first significant field. That is a bad mistake,

22:17.520 --> 22:22.800
because that can truly scrub the whole recipe. So keep in mind, you whatever the first significant

22:22.800 --> 22:28.720
field is, you calculate the hash code and you assign that to the result here. And then step

22:28.720 --> 22:36.240
number two, for every other remaining significant field F in your object, do the following compute

22:36.240 --> 22:42.480
int the int value hash code C. So all the other fields, if the field is a primitive type, so that

22:42.480 --> 22:49.760
could be an int, a char, whatever, use a box primitive and then use that and sort of like

22:49.760 --> 22:55.040
what I described here. So there's a primitive field 42 here, primitive int, use the box in

22:55.040 --> 23:00.880
and use value off and then use the box primitive hash code method to calculate the hash code value

23:00.880 --> 23:06.480
because the primitive type won't have a way to calculate the hash code method. So obviously,

23:06.480 --> 23:12.160
each primitive type in Java will have a corresponding box primitive, like here where int has

23:12.160 --> 23:18.320
integer. So the second part of that is that it's important to consider how the equals method compares

23:18.320 --> 23:24.400
field values. What I mean by that is, if the equals method recursively invokes equals on the

23:24.400 --> 23:30.880
object reference fields, then the hash code method should recursively invoke hash code on those fields.

23:30.880 --> 23:40.240
So in an object, whatever the fields that the equals method invokes equals to the hash code

23:40.240 --> 23:45.360
method should do the same. I will put this way, what I realized when I was going through this

23:46.480 --> 23:53.440
item, or more specifically, this recipe for the hash function is that a lot of the things that the

23:53.440 --> 23:59.200
equals method does, the hash code method should do too. A lot of the patterns that it follows,

24:00.160 --> 24:05.440
that the equals method does or follows, the hash code method should follow too. So the second part

24:05.440 --> 24:11.200
of that is, if the equals method requires a more complex comparison for the object reference field,

24:11.200 --> 24:17.760
the hash code method should compute a canonical representation for the field and invoke hash

24:17.760 --> 24:23.520
code on that representation. So what does this mean? We discussed canonical representation in item 10.

24:24.480 --> 24:31.760
As the name suggests, it's a canonical value. So if there's a certain field value in the

24:31.760 --> 24:39.520
object that's pro to change, that is rather dynamic, for the sake of comparison, or in this

24:39.520 --> 24:49.840
case, for the sake of calculating the hash code, we could assign a sort of static variable value

24:49.840 --> 24:57.120
that we consider to be the canonical representation of that field. And that can be used for all the

24:57.200 --> 25:01.600
computation and all the calculations of the equals method calculations, but also in the

25:01.600 --> 25:12.480
hash code method. That makes it gives our methods a bit more structure for object fields that have

25:12.480 --> 25:17.760
rather dynamic and volatile, and I don't mean volatile in the Java sense, I mean volatile just

25:17.760 --> 25:24.400
conceptually speaking, significant fields in an object. And the third part is, if the value of

25:24.400 --> 25:29.280
the field is null, obviously, the hash code method should use a constant value such as zero

25:29.280 --> 25:34.560
to represent the hash code for the field. That seems pretty self-explanatory because given that

25:34.560 --> 25:40.880
this result variable that we're using is an integer is of type int, we need something to

25:40.880 --> 25:47.920
correspond to a null where zero probably would be the apt value to use. And if the field is an array,

25:47.920 --> 25:52.400
with all fields of the array being significant, use arrays or hash code. So we can use this

25:53.040 --> 25:59.440
method from the arrays class in the library. Or as Joshua Booker said it here, if the field is an

25:59.440 --> 26:06.240
array, compute a hash code for each significant element by applying these rules recursively

26:06.240 --> 26:12.480
and combine the values per step to be. So per step to be is the next step.

26:13.840 --> 26:19.520
We'll get to that too. If the array has no significant elements, use a constant, preferably

26:19.520 --> 26:24.160
not zero. That makes sense because zero would normally be used for something like a null.

26:24.160 --> 26:27.920
We don't want to have that kind of conflict or confusion. And then step two be, of course, is

26:28.480 --> 26:34.560
to, all the values that we used here, that we computed here, sorry, combine them to get the

26:34.560 --> 26:43.600
hash code where we have the result value multiplied by 31 plus C. And what's C? It is the computed

26:43.600 --> 26:48.320
hash code value. And then you return result in the hash code function. This will all make sense

26:48.320 --> 26:54.160
once we look at the demo. In this demo, I've got a class called person. And this person class

26:54.160 --> 27:01.920
has some significant fields, their first name, type string, last name, type string, and address.

27:01.920 --> 27:08.640
And the address is a class that I've defined in this file, in fact. And the address essentially

27:08.640 --> 27:15.840
has a street, city, state, and zip code. So the addresses of address, as you can see clearly.

27:15.840 --> 27:23.760
And then we've got the age, which is of primitive type int. And also we have a string array,

27:25.440 --> 27:30.720
which I've called language is spoken. So the language this person speaks. And then we've

27:30.720 --> 27:35.760
got the constructor and the equals method also I've overridden. I'm not going to go through that

27:35.760 --> 27:39.520
because it's kind of on a scope. And I kind of went through this already in the previous item.

27:40.080 --> 27:48.240
And then we've overridden the hash code. So this hash code theoretically should be a high quality

27:49.040 --> 27:52.320
hash function or a hash code method, because I've followed the recipe

27:52.960 --> 28:01.520
delineated in just a blog's book or in effective Java. Initially, the result as we saw in step one

28:01.520 --> 28:06.240
has been arbitrary number 17 has been picked as a constant. This will reduce

28:07.040 --> 28:12.720
collisions. Keep in mind, don't pick a number like zero, start off with something like this.

28:12.720 --> 28:21.280
And then we've used the significant fields to calculate the result using the hash codes and

28:21.280 --> 28:26.800
then adding that to the result value. And again, multiplying by 31, this again is to give it

28:27.440 --> 28:33.040
give it more uniqueness or more more distinctiveness and preventing collisions.

28:34.160 --> 28:40.720
And then in the address, we've done it a bit differently where we're in fact looking for

28:40.720 --> 28:47.600
the hash value of the address object. And if it has been cached, or pardon me, if it's null,

28:48.160 --> 28:54.480
then we get economical address value. And if it is null, then we're going to return zero.

28:55.120 --> 28:59.680
So we're going to want to make sure that the address is not null and that this person has

28:59.680 --> 29:07.440
an object. And so we get canonical, the canonical address, which by the way, this method is defined

29:07.440 --> 29:15.760
in the address class. So back to this. And then we are also given that the age is of type int,

29:15.760 --> 29:22.560
it's a primitive type, we're using the box primitives. Sorry, yeah, box primitives and using

29:22.560 --> 29:28.080
the value often getting the hash code. And then for languages spoken, because the string array,

29:28.080 --> 29:35.360
we're using arrays or hash code, again, as stated in the hash function recipe,

29:35.360 --> 29:41.760
and then simply we return that result. So here's an example, the client using that class,

29:42.400 --> 29:48.240
we use Alha Camus, my one of my favorite essentialist authors, highly recommend you read him,

29:48.240 --> 29:52.400
start off probably with the stranger. And then if you're more philosophically inclined,

29:52.400 --> 30:00.160
perhaps the myth of Sisyphus, I love the stranger so much that I, in fact, I'm trying to learn French,

30:00.160 --> 30:06.240
just because of Camus. It's a beautiful book. So the languages Camus speaks, I found out,

30:06.240 --> 30:11.120
in fact, he speaks Arabic too. So it's English, French and Arabic. And then

30:12.160 --> 30:16.080
they're giving his address, I just randomly found this online, I'm not even sure if this is accurate,

30:16.080 --> 30:21.840
but this is probably where he lived. And unfortunately, he only lived to an age of 46 years

30:21.840 --> 30:26.880
because he died in a car crash, which is quite a tragedy, given I would have loved to

30:28.080 --> 30:33.520
read more of his work if he did live up to old age. And then when you run this function,

30:33.520 --> 30:39.520
it calculates the hash code for the Albert Camus, Albert Camus object. And then Joshua

30:39.520 --> 30:45.520
Book states, when you are finished writing the hash code method, ask yourself whether equal

30:45.520 --> 30:53.680
instances have equal hash codes, and many states do use unit tests and whatnot to figure that out.

30:53.680 --> 30:58.720
Now I haven't written unit tests for this, but clearly the way this client has used it, this

30:58.720 --> 31:04.640
can be converted to unit tests and used in a variety of ways. And then obviously, if equal

31:04.640 --> 31:11.120
instances have unequal hash codes, figure out why and fix the damn problem. He doesn't say damn,

31:11.120 --> 31:14.720
I just put it in there because why not? He's a nice guy.

31:17.840 --> 31:21.600
So that makes a question, or perhaps it doesn't, but at least it begs the question for me,

31:22.160 --> 31:28.080
what to exclude from the hash code computation? That's the typo that's on hash code, hash code

31:28.160 --> 31:35.680
computation. And he states you could in fact exclude so-called derived fields. And let's

31:35.680 --> 31:41.360
understand what they are before we get to the demo. Those are values that can be computed from

31:41.360 --> 31:46.320
other field values already in the hash code computation. So we did go through this idea

31:46.320 --> 31:56.240
of derived fields before in the, in item 10, I believe using a pentagon or some mathematical

31:56.240 --> 32:02.720
structure. But let's take a look at another demo. I think it was a polygon we used in item 10. And

32:02.720 --> 32:08.000
I didn't want to use that example here because, you know, firstly, my math is shit. I'm quite

32:08.000 --> 32:13.920
embarrassed about that. Therefore, I found it a bit hard to explain using the polygon class example.

32:14.720 --> 32:18.480
That's something I should work towards. And in fact, teach myself some mathematics,

32:18.480 --> 32:24.640
some basic mathematics at least. But this is way more straightforward. So what's the derived field?

32:24.640 --> 32:29.760
We have a full name. And obviously a full name can be derived off the first name and the last name.

32:30.960 --> 32:39.120
And in the hash code, we don't have to, when calculating the hash code, we don't have to use

32:40.560 --> 32:48.560
the full name in the hash code calculation, given that it's already derived from first name and last

32:48.560 --> 32:53.920
name. That's it. That's what a derived field is. And that could be excluded in a hash code method.

32:53.920 --> 32:59.760
Okay, so this next part, the order of the fields. And the point is the quality of the hash code

32:59.760 --> 33:06.880
method is contingent on the order of the fields if a given class has similar fields. Now, to be

33:06.880 --> 33:12.480
totally upfront, I found this part quite difficult to understand. So I'm going to try my best to

33:12.480 --> 33:17.520
try and explain this. I think I got it, but I think I'm going to struggle a bit to articulate it

33:17.520 --> 33:24.080
because it's not, intuitively, it's hard to get it on first glance. It requires a bit of thinking.

33:24.080 --> 33:31.360
So the reason for this is because of 2B. That is this calculation we make here. It's this is the

33:31.360 --> 33:40.800
reason that makes the ordering contingent for the hash code method. So Joshua book states,

33:40.800 --> 33:45.360
for example, if the multiplication were emitted from a string hash function,

33:46.400 --> 33:54.560
all anagrams would have identical hash codes. The value 31 was chosen because it is an odd prime.

33:55.280 --> 34:00.640
If it were even and the multiplication overflowed, information would be lost because modification

34:00.640 --> 34:07.920
by two is equivalent to shifting. Another way to think about that is that this multiplication here,

34:07.920 --> 34:16.560
31 times i, that can be replaced by this the shifting of the of the sum or the left shift

34:16.560 --> 34:26.560
operator in Java. As far as Java is concerned, that and sorry, that and that are mathematically

34:26.560 --> 34:31.920
equivalent. Now we'll get to the definition a bit before a bit later, sorry. But firstly,

34:31.920 --> 34:38.320
let's take a look at some demos. So in this example, and this is a bad example where the

34:38.320 --> 34:47.520
order hasn't been considered. If you run this, there's a possibility that these two hash codes,

34:47.520 --> 34:53.600
so for object A and object B, which are two anagrams, that the hash code could be the same,

34:53.600 --> 34:57.760
because all they're doing in the hash code method, if you can see here is we're simply

34:58.720 --> 35:03.680
returning the hash code of word of the string value. So we're just using the

35:03.680 --> 35:08.560
hash code method in the class string. We aren't really considering anything else apart from that.

35:08.560 --> 35:15.600
In fact, I don't even know why they'll be written as second place here. It's like this is a superfluous

35:15.600 --> 35:21.840
or unnecessary method. And even though I ran this a couple of times, and this is why I said it

35:21.840 --> 35:26.800
depends on the application state, it is possible theoretically for this to return the same hash

35:26.880 --> 35:33.440
code despite these two being different. And then here, we are in fact multiplying by 31,

35:33.440 --> 35:40.240
and we are even having this arbitrary value initially. The chance of these hash code values

35:40.240 --> 35:45.600
being the same is a lot more different in comparison to the previous example that I showed

35:46.720 --> 35:49.920
in the other class. Both classes are called anagrams, it's a bit confusing,

35:50.880 --> 35:55.840
but they're in different directories, or yeah, the packages are different. So that's because we

35:56.000 --> 36:02.240
modified that a bit in hash code. This is a bad example. I only put this in here because it kind

36:02.240 --> 36:08.000
of goes along with what Joshua Block had stated in the book. I in fact thought using a separate

36:08.000 --> 36:13.040
class called person would be better to understand this. The reason I use anagram is because that's

36:13.040 --> 36:18.800
the example that he's used, but frankly, is equally so. I didn't really get it much. So

36:18.800 --> 36:24.000
maybe we'll try to understand it with the person class. I put that other part in there just to

36:24.080 --> 36:31.760
stick with what's in the book. And I thought that'll help in some way. Given he said if the

36:31.760 --> 36:37.680
multiplication were emitted from a string hash function, all anagrams would have identical

36:37.680 --> 36:45.440
hash codes. Ah, I now seek my confusion. He did say if the multiplication were emitted from a

36:45.440 --> 36:49.920
string hash function. So the reason we're getting different ones here is because in fact in the

36:50.000 --> 36:56.320
string hash function, it wasn't emitted. If it wasn't, it was kind of like this,

36:56.320 --> 37:01.840
just simply returning it. It could have been the same. But in the string hash function, if you look

37:01.840 --> 37:10.640
at the hash function, there is some multiplication being done. There's some work being done here.

37:10.640 --> 37:15.600
I'm not going to take a look at it. It's a bit too complicated for me, but it's not just simply

37:16.560 --> 37:21.280
taking that value in and passing the hash code. So anagrams themselves would have different

37:21.280 --> 37:26.800
hash codes, which is great. Apologies about that. I should have gone through that a bit more carefully

37:26.800 --> 37:30.080
beforehand, but it kind of makes sense now what he's trying to say here.

37:32.080 --> 37:36.480
And then the part I was trying to explain before about these two statements being

37:36.480 --> 37:43.520
mathematically equivalent. Joshua Bock states, a nice property of 31 is that the multiplication

37:43.520 --> 37:50.000
can be replaced by a shift and a subtraction for better performance on some architectures,

37:50.000 --> 37:56.960
because as I said, these two are equal, mathematically speaking. And modern VMs do

37:56.960 --> 38:01.360
this sort of optimization automatically. I perhaps did a terrible job at explaining that,

38:01.360 --> 38:06.640
because I too am trying to understand this idea of the shifting operator and all that.

38:07.600 --> 38:12.400
So I asked Judge GPT, and I think this is much more clearer than what I could ever say.

38:13.200 --> 38:20.640
Here's what Judge GPT states regarding this. The double listed operator is the left shift

38:20.640 --> 38:27.360
operator in Java, which shifts the bits of an integer to the left by a specified number of

38:27.360 --> 38:33.600
positions, effectively multiplying by 2 to the power n, where n is the number of positions shifted.

38:34.800 --> 38:40.480
That's why it's shifting. The minus operator is the subtraction operator, which subtracts the

38:40.480 --> 38:49.200
second operand from the first. So the expression i double less than 5 minus i shifts the bits of i

38:49.200 --> 38:55.200
to the left by 5 positions, effectively multiplying it by 2 to the power 5 or 32,

38:55.200 --> 39:03.440
and then subtracts i from the result. Since 32 minus 1 equals 31, the expression is equivalent

39:03.440 --> 39:12.560
to 31 times i. That's what it's this bit that gives this equality that Joshua Bloch speaks of.

39:13.520 --> 39:18.400
By using the optimization, the hash function implementation can take advantage of the

39:18.400 --> 39:24.160
efficient left shift operation on some architectures potentially leading to improved performance,

39:24.160 --> 39:29.360
and also Judge GPT repeats what he stated. Modern virtual machines are designed to automatically

39:29.360 --> 39:34.400
perform this kind of optimization, so the hash function implementation can remain unchanged

39:34.400 --> 39:40.640
and still benefit from the performance improvement. So a simple example of this would be if I ran this

39:40.640 --> 39:48.640
code, j would be equal to k. It'll print true because both these are equal. They both will be 310.

39:49.440 --> 39:53.920
And then let's take a look at another demo. I think we already kind of took a look at this.

39:53.920 --> 39:57.920
Sorry, by the way, not related to this is separate because Joshua Bloch states,

39:58.640 --> 40:03.760
say all that, let's apply this previous recipe to the phone number class. Now I already did apply it

40:03.760 --> 40:10.480
and show the demo in my own way, but it's important to take a look at what Joshua Bloch has done too.

40:10.480 --> 40:18.960
Here's the demo. As we saw, it returns the hash code of the initial value area code that he set,

40:18.960 --> 40:23.840
says he said to take the first significant field and assign the hash code value to result,

40:23.840 --> 40:28.800
and then do the calculation accordingly. And that returns the result. And on this method,

40:28.800 --> 40:36.000
he states, because this method returns the result of a simple deterministic computation,

40:36.560 --> 40:43.280
whose only inputs are the three significant fields in a phone number instance, that is area code,

40:43.280 --> 40:51.920
prefix and line number, is clear that that equal phone number instances have equal hash codes.

40:52.480 --> 40:58.800
It is simple, is reasonably fast, and does a reasonable job of dispersing unequal numbers

40:58.800 --> 41:05.280
into different hash buckets. And of course, a bit of a caveat here, as we saw in item 10,

41:05.280 --> 41:12.560
when it comes to equals comparison, even in the hash codes, he stated, if you have a bona fide

41:12.560 --> 41:20.960
need for hash functions, less likely to produce collisions, see Guava's co Java library, which

41:20.960 --> 41:26.800
is Google's co libraries for Java, and the hashing there does it much better than you and I ever

41:26.800 --> 41:32.480
could. And he's continued by giving a much more simpler one line hash function, which you'll see

41:32.480 --> 41:39.360
here. Comment out the other one. So these are all hash functions. There's different ways of

41:39.360 --> 41:43.120
implementing them. He's given three separate examples. The third one will go through soon.

41:43.760 --> 41:49.840
This is a one line hash function using the objects dot hash. The caveat here, despite it being a

41:49.840 --> 41:56.800
one line hash function, is that it should only be used if performance isn't critical, because it

41:56.800 --> 42:04.080
does return an array. And every time it's invoked, it returns an array and also involves auto boxing

42:04.080 --> 42:09.920
if we do pass a primitive type. And that takes us to an interesting part in these

42:10.560 --> 42:20.240
hash code implementations, which which is threat safe lazy initialization. So lazy initialization

42:20.240 --> 42:27.200
can be used if you believe your class is immutable. And if it considers or not considers it involves

42:27.760 --> 42:32.240
the invocation of the hash code involves recalculating the hash code every every time it's

42:32.240 --> 42:39.280
requested. And he says if you believe that most objects of this type will be used as hash keys,

42:40.080 --> 42:47.120
then you should calculate the hash code when the instance is created. Otherwise, you might

42:47.120 --> 42:52.320
choose to lazily initialize the hash code the first time hash code is invoked.

42:53.440 --> 42:58.640
Some care is required to ensure that the class remains threat safe in the presence of a

42:58.640 --> 43:04.240
lazily initialized field. Now we shall look into that because creating it to be threat safe is in

43:04.320 --> 43:11.280
fact an important not even an acillary point here, but it's in fact very much related to this idea of

43:11.280 --> 43:16.720
lazy initialization. But before we look at the threat safety example, let's firstly look at the

43:16.720 --> 43:21.680
phone number example. And the phone number class doesn't require this kind of threat safety. He's

43:21.680 --> 43:27.600
even stated that in the book. And what is lazy initialization? It's quite simple, really. We

43:27.600 --> 43:36.240
have a private in hash code method, and we check if the result is zero. If there's no

43:36.240 --> 43:43.680
cash result, we directly return that result. So that means every time the hash code method is

43:43.680 --> 43:49.200
invoked, it doesn't have to go through this bit and do the computation slash calculation. If it's

43:49.200 --> 43:55.360
cached, it could just be it could just be returned. And that's what lazy initialization is. And this

43:55.360 --> 44:02.320
is automatically initialized to zero initially. So as I've stated here in the comment, apt for

44:02.320 --> 44:08.640
immutable classes with expensive hash code calculation. Okay, now let's get to the threat

44:08.640 --> 44:14.480
safety bit, which is in fact, despite it being a bit complicated at first, I found most interesting

44:15.200 --> 44:20.640
in this item. I kind of enjoyed it, especially because I kind of do enjoy that part of Java,

44:20.640 --> 44:28.000
the whole multi threading bit in shelf. So here's an example of lazy initialization

44:29.120 --> 44:35.680
with threat safety. So we have this class called canna. And canna holds it's a it's an

44:36.320 --> 44:42.400
this class is atomic as we're using the atomic integer method. So atomic means and competing

44:42.400 --> 44:48.880
atomic means the either the change happens, or it doesn't happen. I always understood

44:48.880 --> 44:54.240
atomic operations in the context of a database. So a good example is something like a bank

44:54.240 --> 44:59.440
transaction. You either want the money to go go through, or you don't want it to go through at all.

44:59.440 --> 45:06.640
It's very binary in that sense, no pun intended. And that's what an atomic computation is. There's no

45:06.640 --> 45:13.440
there's no murky territory. There's no half of the computation happening. So we're using the count

45:13.440 --> 45:17.600
of type atomic integer. And then we have we have another hash code value here,

45:18.800 --> 45:24.640
a field value of also atomic integer. We have the constructors whatnot, we're setting the count

45:24.640 --> 45:28.800
getting the count forget about all that, not forget about all that ignore all that for this context.

45:30.400 --> 45:36.400
And then we have the hash code method. And the hash code method. Remember, all of this is still

45:36.400 --> 45:44.640
using the atomic integer. And here, though the hash code is computed lazily, it's still the same

45:44.640 --> 45:49.840
thing that we saw in the phone number class, where we're checking if the value is there checking if

45:49.840 --> 45:57.440
the value is equal to zero, only if it's equal to zero, where we're setting the value and and passing

45:57.440 --> 46:03.680
it, we're setting the value and then returning it. If not, if it's not equal to zero, that means

46:03.680 --> 46:08.320
the value has been cached. So we just return that value straight away. So that's the lazy

46:08.320 --> 46:15.280
initialization bit. But now we get to the thread safety bit, the multi threading bit. So I've started

46:15.280 --> 46:22.480
two threads here, t1, t2. And they're both they both got two counters. So firstly, I've got an

46:22.480 --> 46:28.800
instance of counter called count counter, of course, of the constructs, I've initialized that with 10.

46:29.760 --> 46:37.600
And then I've created two threads that sets the count that that changes the count concurrently.

46:38.160 --> 46:44.640
So two threads are started. So here, since we've used t1 dot join and t2 dot join,

46:44.640 --> 46:50.080
because of the use of this join method, only the final state of the counter, that's this one here,

46:50.080 --> 46:55.040
this object will be used, in this case, for get count, but for anything else, because the main

46:55.120 --> 47:02.800
thread waits for both child threads to finish, finish execution. So there are two threads spun

47:02.800 --> 47:08.640
up and there's a main thread, of course, that'll wait until both threads finish execution by using

47:08.640 --> 47:15.440
join. And since the atomic integer has been used, the value will either be 15 or 20. It's atomic,

47:16.080 --> 47:22.800
because the type for the hash code is atomic. And 15 and 20, of course, comes from this set

47:22.800 --> 47:29.360
count that we used here. So depending on which thread finishes first, it'll always be the final

47:29.360 --> 47:34.960
state will be reflected. So if I maybe write it a couple of times, this is how it came. Final count

47:34.960 --> 47:44.160
and so the final count is, so the final count is 20. And the hash code also comes as 20. But I think

47:44.160 --> 47:52.240
that's because the value is cached here. So if I run that a couple of times, let's see if at one

47:52.320 --> 47:59.040
point, it's always the second thread that finishes last. So it's passing that value. But

47:59.760 --> 48:07.520
let's say I change this, I don't know, I multiply this by 21, for some reason, and I run it again.

48:07.520 --> 48:11.840
In this case, the hash code value will change. And then if I run it again, now it's going to keep

48:11.840 --> 48:16.640
returning that because that value is cached. And the point being, because we're using

48:17.520 --> 48:21.600
type atomic integer, these operations will be atomic. And this is what

48:22.240 --> 48:28.800
Joshua Block means by creating lazy initialization to work with thread safety. So

48:28.800 --> 48:33.520
in this case, really, this bit doesn't matter too much. What matters is when we declare the

48:33.520 --> 48:42.800
hash code value, we use a type of atomic integer that ensures it's thread safe. So a few caveats

48:42.800 --> 48:49.440
here, the hash code initialization field value should not be the hash code of a commonly created

48:49.440 --> 48:56.960
instance. So that initial value we set for the hash code calculation, this is not a good example.

48:56.960 --> 49:03.280
If we go back to the phone number class, this initial value we set, it shouldn't be the hash

49:03.280 --> 49:08.640
code of a value that's commonly created, pardon me, not a commonly created value, a commonly

49:08.640 --> 49:13.440
created instance or some kind of object that's used quite a lot. So that initialization value,

49:13.440 --> 49:18.320
because that would obviously defeat the purpose of caching as it'll constantly be changing.

49:18.880 --> 49:24.160
And the other thing, and this is really important, like what Don Knuth stated, oh, it wasn't Don

49:24.160 --> 49:29.600
Knuth, wasn't it? It's apocryphally attributed to Don Knuth, but the root of optimization,

49:30.480 --> 49:38.960
sorry, I'd push it back. The root of all evil is premature optimization. So always choose

49:38.960 --> 49:47.040
accuracy over optimization. And the point is poor quality hash functions that are inaccurate

49:47.040 --> 49:51.440
will degrade hash tables to the point of being unusable. It's kind of connected to that previous

49:52.160 --> 49:56.880
point where we just set one constant value that legally makes sense, but would make a

49:56.880 --> 50:04.480
terrible hash function. So Joshua Bock states, do not be tempted to exclude significant fields

50:04.480 --> 50:11.360
from the hash code computation to improve performance. So always pick accuracy of optimization,

50:11.360 --> 50:18.000
especially with modern CPUs these days. Like why would you? Well, why would you? It makes more

50:18.000 --> 50:24.320
sense to focus on accuracy because there's pretty much infinite compute in the modern world.

50:24.880 --> 50:30.160
Or as he's put it here, in particular, the hash function may be confronted with a

50:30.880 --> 50:37.280
large collection of instances that differ mainly in regions that you've chosen to ignore. If this

50:37.280 --> 50:43.680
happens, the hash function will map all these instances to a few hash codes and programs that

50:43.920 --> 50:55.600
run in linear time. Sorry, I'd push it back. If this happens, the hash function will map all

50:55.600 --> 51:03.120
these instances to a few hash codes and programs that should run in linear time will instead run

51:03.120 --> 51:09.920
in quadratic time. So if we take this class example, this is an example of a poor implementation

51:09.920 --> 51:17.360
of the hash code. Last name in this person class, did I say class example? If we take this person

51:17.360 --> 51:22.720
class example, last name of this class is a significant field, obviously. But in the hash

51:22.720 --> 51:29.680
code, we've ignored it. Now, what that would do is to put it more clearly, I use strategy PD,

51:29.680 --> 51:35.680
because I struggled to articulate that. If we create a large collection of person objects,

51:35.680 --> 51:42.080
so from this class, that differ mainly in their last name field, so this field that we've ignored.

51:44.320 --> 51:49.840
The hash function implemented in the person class will be of poor quality and the hash

51:49.840 --> 51:56.000
based data structure, so like a hash map, that use it will experience many collisions. This can

51:56.000 --> 52:01.040
lead to poor performance and even course programs that should run in linear time to run in quadratic

52:01.040 --> 52:06.720
time as the book suggests. So I'll propose ignoring significant fields like what we've seen here.

52:07.280 --> 52:14.560
One example, just like a real world implementation is prior to Java 2, the string hash function

52:14.560 --> 52:23.360
in fact used at most 16 evenly spread characters to calculate the hash code. However, unfortunately,

52:24.000 --> 52:30.800
any string with more than 16 characters, as he said he has things such as URLs, would give

52:31.040 --> 52:37.920
a low quality hash function or a poor hash function essentially, as the name suggests.

52:38.880 --> 52:44.880
And that would be bad, that's the point I'm trying to make here. So keep the hash function

52:44.880 --> 52:49.840
flexible and open for future change, which is kind of, isn't that one pattern in the

52:49.840 --> 52:56.480
solid principles in object oriented programming. So make sure that's flexible and not static in

52:56.480 --> 53:03.200
like the string hash function prior to Java 2. And then the other important point is don't provide

53:03.200 --> 53:09.520
a detailed specification for the value returned by hash code, so clients can't reasonably depend on

53:09.520 --> 53:16.000
it. This gives you the flexibility to change it. Because if you do have a detailed specification,

53:16.800 --> 53:24.960
then people might rely on the hashing algorithm when clients use your class and also make it hard

53:24.960 --> 53:30.160
to do this open for future change bit, because the hash function isn't flexible. And so an example

53:30.160 --> 53:37.120
here is in fact the string class where if you can see here, people will rely on this formula for

53:37.120 --> 53:43.120
calculating the hash function. And that makes this hash code method less flexible. So a good example

53:43.120 --> 53:48.480
would be to keep the hashing algorithm hidden, like what we've seen here where all you see here is

53:48.480 --> 53:53.760
return objects dot hash name and age, we don't know what the hashing algorithm is in the object

53:53.760 --> 54:02.720
dot hash. So that's what he means by not not being explicit or specifying how the the hash

54:02.720 --> 54:09.680
code is calculated. Because as he states, if you leave the details unspecified, and a flow is found

54:09.680 --> 54:15.680
in the hash function, or a better hash function is discovered, you can change it in subsequent in a

54:15.680 --> 54:22.960
subsequent release. And then to end, he states, in summary, you must override hash code every time

54:23.040 --> 54:30.240
you override equals, or your program will not run correctly. Your hash code method must obey

54:30.240 --> 54:36.480
the general contract specified an object, that's the object class, and must do a reasonably,

54:37.520 --> 54:42.800
and must do a reasonable job assigning unequal hash codes to unequal instances.

54:44.160 --> 54:50.320
That was also a bit of a long item. And I did feel like I can't mess up a few parts in that

54:50.320 --> 54:56.720
item. Got feeling. I don't know what I'm probably see when I'm editing the video. If I did, I

54:56.720 --> 55:02.480
apologize. Please double check everything I've stated here. And if I made some significant

55:02.480 --> 55:07.600
blunders, I'll try and correct them in some way, either in the description or in the video itself.

55:08.960 --> 55:16.320
Nonetheless, I'm going to try my best. Because that's all one could do. Appreciate it. I shall see

55:16.320 --> 55:20.640
you in the next one. Item number 12, which I've already started on. I don't know why I'm doing

55:20.640 --> 55:25.280
this if you can see the book. Okay, there's the evidence that I've started on item number 12,

55:25.280 --> 55:32.240
which states always override to string. So in that one, cheers.

