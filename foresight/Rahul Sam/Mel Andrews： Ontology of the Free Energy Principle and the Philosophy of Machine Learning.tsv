start	end	text
0	1000	in this episode.
1000	9720	So there's a long history in 20th century philosophy of science of investigating the
9720	23000	possibility of something like an automated science or a formalized science or a algorithmically
23000	34640	implemented science, all aspects of science, including sort of uncovering theory.
34640	44320	And this has been a rich tradition, but it's been strictly abstract about about hypothetical
44320	52360	machines and hypothetical algorithms and hypothetical forms of automation of scientific labor rights.
52360	61880	And all of a sudden sort of perhaps largely unanticipated by philosophers, we reach a
61880	71160	point where boom, deep learning revolution, and suddenly there is a kind of massive shift
71160	83720	towards taking aspects of scientific discovery and passing them off to a intelligent computational
83720	89920	system.
89920	97200	And I think there's been kind of a tendency to continue to view that within the lens of
97200	108520	this automation of scientific discovery debates as it's existed without really attending to
108520	116640	the details of how these technologies are in fact being implemented in scientific practice.
116640	124280	And by the way, I think when, when what we are doing is collecting data from some system
124280	133760	in the world and using some machine learning model to extract statistical patterns from
133760	137720	that system in order to learn about that system, what we're doing is is effectively science.
137720	139520	It follows the model of science.
139520	144880	So in fact, most applications of machine learning ought to be considered a kind of science
144880	146920	adjacent activity.
146920	151160	And in my opinion, it held to the standards of good science.
151480	155640	Hey, everyone, welcome to my conversation with the philosopher of science, Mel Andrews,
155640	160240	who's doing work in machine learning and other adjacent fields such as the philosophy of
160240	164360	mathematics, epistemology, and of course, ethics.
164360	168960	It was a fantastic, cordial and riveting conversation for me.
168960	171000	And I should first say it's good to be back.
171000	176680	It's good to be back after my short holiday back doing podcasts, having these fascinating
176680	181080	conversations with these superlative guests.
181080	185200	And I couldn't think of a better person to start off with other than Mel.
185200	187520	They is fascinating.
187520	194440	They also has this way of kind of, you know, elucidating certain points that for a while
194440	196880	I did struggle to understand.
196880	202760	And of course, probably the best example would be this paper, the math is not the territory
202760	206120	navigating the free energy principle.
206120	213000	As someone who's deeply interested in the kind of philosophy of FEP, this paper really
213000	218800	helped me understand what the ontology of the free energy principle is and what really
218800	225080	is the proper way to view it as a kind of a mathematical, formalistic, conceptual framework
225080	230080	that can be applied in many areas such as machine learning and of course cognitive science.
230080	234880	But we did start the podcast discussing Mel's recent paper regarding the epistemic status
234880	241260	of machine learning and they provocatively claimed that machine learning has a pseudo
241260	247200	science problem which I vehemently agree with and even kind of brought up this resurgence
247200	252600	of physiognomy kind of provocatively to make this point.
252600	257840	It's a preprint, in fact, and we discussed a bit of that paper and kind of extrapolated
257840	265240	some of those ideas into the broader socio-political discussion around AI ethics, which again is
265240	266960	very interesting.
266960	273720	And I do really appreciate that Mel is a very critical almost focodian analysis of these
273720	278440	different disciplines that are getting a lot of attention these days such as AI and machine
278440	279600	learning of course.
279600	286960	I also mentioned to Mel that this credit feed is a place that I visit quite often online.
286960	292160	I hate Twitter, I think Twitter is a hellscape, however there are a few accounts that I've
292160	299240	bookmarked and I do frequently visit simply for entertainment but also to learn and Mel's
299240	303600	Twitter feed is certainly one of those that are bookmarked.
303600	308280	Having said that, before I get carried away talking about Twitter and all of that, a bit
308280	315240	of a formal introduction to Mel Andrews is a philosopher of science working on the role
315240	320080	of mathematical and computational methods in science and particular machine learning
320080	321880	based methods.
321880	327040	Mel is currently a predoctoral research associate at the department of machine learning at the
327040	331680	Carnegie Mellon University and doing a PhD in philosophy of science at the University
331680	332680	of Cincinnati.
332680	338560	They are also a visiting scholar at the Australian National University and the University of
338560	340040	Pittsburgh.
340040	343480	Having said that, here's my conversation with Mel Andrews.
343480	347000	So on housekeeping note I should mention that I'll leave links to everything we've discussed
347000	348000	in the show notes.
348000	349000	Okay, now to the podcast.
349000	350000	Mel Andrews
350000	356960	The sort of conclusion I reached eventually was, it just, I mean, in academia there's
356960	367360	a certain portion of what you do that feels like running on a wheel, like it's not, it's
367360	371000	a performance, it's not actually to accomplish anything but it just feels like such a high
371040	379280	percentage of that in industry is just sort of, there's so many levels of removal.
379280	385640	The person who's passing down the orders is so many levels removed from the people actually
385640	392560	implementing solutions that you're almost not accomplishing anything.
392560	393560	Mel Andrews
393560	399200	Yeah, also like, I mean, look, it's, I think, Franz Kafka, he captured it best in his novel,
399200	403360	you know, it's Kafka-esque in the sense that it seems like people are just doing things
403360	409120	for the sake of doing things without really going anywhere and you're having all these,
409120	411840	you know, wonky meetings.
411840	417480	But to be fair though, like, I agree with you because, because I'm still outside of academia,
417480	422720	I've kind of idealized academia, but after talking to a lot of people like yourself on
422720	427920	the podcast, I'm getting a more realistic picture of what it is because at the end of
427920	433800	the day, the university is still in our society, it's a part of our culture within them.
433800	434800	Mel Andrews
434800	439160	And it's beholden to a capitalist economic system.
439160	440160	Mel Andrews
440160	441160	Exactly, exactly.
441160	442160	Yeah, yeah.
442160	447360	And it kind of shows how much the, let's call it the capitalist tentacles reach into every
447360	449880	corner of our social existence.
449880	455320	I mean, although I even go a step further and I say, I mean, I'm a big fan of Jacques,
455320	461480	it even changes our psyche, our subjective state in this world and, and like fundamentally
461480	467640	who we are, as let's say beings in this world, you know, and then that of course affects academics
467640	472360	and, and quote unquote, lay people and everyone really, but I see what you mean.
472360	473360	Yeah, yeah.
473360	475360	So I've got to ask now though.
475360	476360	Mel Andrews
476360	477360	Sorry.
477360	483880	In terms of even like the AI ethics communities, you have like the AI risk, AI safety people,
484880	489960	like existential risk, kind of the effective altruist oriented community.
489960	496400	And you've got then, you know, academic, fairness, safety, regulation communities.
496400	500280	And they're both sort of pointing at each other and accusing each other of like corporate
500280	501280	capture.
501280	506840	But of course, the irony is, is that these communities are both about as corporately
506840	508840	captured as you can.
508840	509840	Yeah.
509840	510840	Yeah.
510840	515440	And every entity really, you know, neoliberal society is corporate captured in some sense,
515440	519800	you know, after the 70s and 80s, it fundamentally changed.
519800	522480	I completely agree with you.
522480	524480	No ethical work, no ethical consumption.
524480	529880	I mean, there's only really a handful of, I'd say at this point, as in some sense I'm
529880	536840	like, well, I am in your fight, but I'd say there's only a handful of researchers who
536840	539960	I follow quite closely, you certainly being one of them.
539960	546800	And then in S and a few others, because as in for me, there's this whole question about
546800	556200	AI ethics and yeah, AI safety, I only find it to be useful when we kind of got it more
556200	561920	from the, let's call it the ontological level of like, what is AI, what is machine learning
561920	568480	as we have it now, and kind of starting at like that very fundamental level ontological
568480	572960	level as you've done, you know, in some of your papers.
572960	578760	Because for me, that gives a lot more hate use to stone because it's kind of cheap, but
578760	583320	like realistic view of where we are with machine learning and AI and where we can go.
583320	594240	Or even sticking to, you know, sticking to the realm of not what is conceivable.
594240	597560	I mean, I think there's a lot of discourse happening at the level of what is conceivable,
597560	602920	what sorts of technologies are conceivable, or what sorts of technologies are metaphysically
602920	604320	possible or what haven't you.
604320	615840	And it's like, well, let's think about what might come into being in the reality we occupy,
615840	623200	because what comes into being in the reality we occupy is governed by market forces.
623200	631440	And we should think about technologies that some person might conceivably be incentivized
631440	634360	and capacitated to build.
634360	640200	If there are technologies that no one would ever be incentivized and capacitated to build,
640200	645160	realistically speaking, I don't think there's much point in debating what their capabilities
645160	649040	are or what the danger is emerging from these technologies would be.
649040	653280	And I think there's a lot of debate that's happening at the level without considering,
653280	656360	you know, incentives.
657000	670920	Truthfully, I think this is, again, the primary sort of access of opposition in the AI ethics
670920	677560	communities or community is between the risk safety people and the sort of fairness responsible
677560	681960	AI people, fact community, et cetera.
681960	690720	And maybe the failing point of both of these communities is, in their scholarship, a total
690720	697200	failure, at least in the major part of the work, to really, really consider incentive
697200	699560	structures.
699560	705080	So the interventions we're suggesting have to be able to work within incentive structures
705120	708280	as they exist or they might conceivably exist.
708280	715680	They have to consider how we might, if the point is to manipulate incentive structures,
715680	718080	we have to have that conversation explicitly.
718080	725400	How are we intending that the intervention we suggest would nudge incentive structures
725400	726400	as they exist?
726400	733360	And I think there's just sort of a failure to consider that in large part in a lot of
733360	740360	the work falling under the age of AI ethics, writ as largely and abstractly as we possibly
740360	741880	can, right?
741880	743080	Undoubtedly, undoubtedly.
743080	744080	Yeah.
744080	750320	I mean, it sounds like a very straightforward thing, but, you know, AI doesn't sit in a silo.
750320	754280	It's always within a, it sits within a psychosocial reality.
754280	756320	I couldn't agree more.
756320	764520	Which is deeply, deeply complex to the point that it, having to think through incentive
764520	770160	structures feels like it makes any problem in this realm completely intractable.
770160	771160	Yeah.
771160	772160	So I get exploits.
772160	777040	Although I want to add, which is where I again like what you're doing, and we'll certainly
777040	782400	get to this in a bit, kind of trying to understand, which is why for me, I think only a philosopher
782400	789080	of science and perhaps even someone with a bit of a background in sociology can kind
789080	797360	of explore the kind of epistemic status of what is machine learning or what is AI in
797360	802000	contemporary times and then maybe speculate and theorize on where it could go and develop
802000	803000	in the future.
803000	806800	Because I'm going to be honest, as more of an outsider, some of this sounds a lot like
806800	812280	science fiction to me and I'm kind of like, are we really even discussing as to what
812920	818080	the current models are, what are large language models, what do they really do without all
818080	824080	of this speculation, which again, the speculation seems just like it's just a bunch of blokes
824080	831200	having fun without considering all the factors that you mentioned, our psychosocial reality,
831200	838400	ways, AI, incentive structure, kind of symbolic network that all comes together, which seems
838400	840520	like an intractable problem, I agree.
840520	841520	Yeah.
841600	850200	But I mean, I think a lot of philosophy is self-gratifying, in a sense.
850200	851200	Oh, for sure.
851200	853120	I mean, I would say a lot of thinking in general.
853120	854120	Yeah.
854120	855120	Yeah.
855120	859960	I'd say a big part of it is for that, because it's self-gratifying, not for any ethical.
859960	860960	Yeah.
860960	869160	I mean, I think I have a very sort of pragmatic embodied view of thinking and it's sort of
869200	876720	a very, I think that goes into sort of pragmatic ethical or political stance as well, where
876720	881320	I think, I mean, I think we think in order to affect action in the world.
881320	887000	Thinking, I don't think thought takes place.
887000	893480	I don't think we can say cognition has really taken place unless we see the hallmarks of
893480	896840	it's in behavior.
896840	904920	So I mean, I actually think I'm a sort of weird behaviorist in the sense that I think
904920	913200	that consciousness and sentience and agency and cognition and a lot of sort of what's
913200	923840	been considered unobservable mental characteristics are actually readable from behavioral dynamics.
923840	934200	And I think that we should not be thinking of philosophy as an eye will pursue.
934200	940920	It impacts the way we go about the world or it ought to be approached as though it's
940920	949320	going to have immediate impact on how we interact with the phenomena it treats as its subject
949320	950320	matter.
950320	951320	Yeah.
952320	957280	I'm just saying I'm fully a pragmatist with respect.
957280	958280	Yeah.
958280	959280	I get you.
959280	961440	But also, I mean, not only as a pragmatist, but I would even say, you know, I've been
961440	967520	deeply interested in psychoanalysis and I've spoken to heaps of psychoanalysts and one misunderstanding
967520	972120	I think a lot of people have coming from like the Carl Jung type is like the idea of depth
972120	978960	psychology where they think the truth of a person's desires and motives are somewhere
978960	982120	deep within and you need like a psychoanalyst to find it.
982120	987440	But the flip is the Freudian more Lacanian idea is no, no, no, that the truth lies in
987440	988640	your actions.
988640	995080	The truth is never like deep within rather it's it's it's very it's very conspicuous.
995080	996080	It's out there.
996080	1000800	Hey, you know, and you can see it in in how people act and how people engage in their
1000800	1001800	social world.
1001800	1004680	So I can say nothing is really hidden with that.
1004680	1005680	Yeah.
1005680	1008200	That's the ultimately come to realize nothing is really hidden.
1008560	1015880	So you wrote, you've been working on a few papers, kind of working on the epistemic status
1015880	1021440	of machine learning, which I've thoroughly enjoyed reading and learned a lot.
1021440	1026080	One of them was this paper I read, this was I read this a while back, which is the machine
1026080	1028880	learning and the theory free ideal.
1028880	1031760	I'll leave a link to that in the in the show notes.
1031760	1036360	But also the recent preprint you shared with me, which I thought was a very good provocative
1036360	1043600	piece, in fact, titled ghosts in the machine learning, the reanimation of pseudoscience
1043600	1046240	and its ethical repercussions.
1046240	1052080	So to perhaps to orient the listeners, if you could kind of give us an introduction as to
1052080	1057720	yeah, what is what is this work you're doing, researching the epistemic status of machine
1057720	1064720	learning, apropos philosophy of science, and then perhaps, you know, you know, as a as
1064760	1074040	carrying on from our ethics conversation or chat, how that how those two ideas are connected,
1074040	1078400	you know, the epistemic status of machine learning, and then what's its relationship
1078400	1079960	to ethics.
1081680	1082680	Yeah.
1082680	1091800	So there's a long history in 20th century philosophy of science of investigating the
1091800	1104960	possibility of something like an automated science, or a formalized science, or a algorithmically
1104960	1111680	implemented science, all aspects of science, including sort of uncovering theory.
1112680	1126360	And this has been a rich tradition, but it's been strictly abstract about about hypothetical
1126360	1134360	machines and hypothetical algorithms and hypothetical forms of automation of scientific labor rights.
1134360	1143920	And all of a sudden, sort of, perhaps largely unanticipated by philosophers, we reach a
1143920	1147960	point where boom, deep learning revolution.
1147960	1159240	And suddenly, there is a kind of massive shift towards taking aspects of scientific discovery
1159280	1166720	and passing them off to a intelligent computational system, right.
1171800	1179840	And I think there's been kind of a tendency to continue to view that within the lens of of this
1180120	1190720	automation of scientific discovery debate as it's existed, without really attending to the
1190720	1198440	details of how these technologies are, in fact, being implemented in scientific practice.
1198440	1206280	And by the way, I think I think when when what we are doing is collecting data from some system
1206280	1215920	in the world, and using some machine learning model to extract statistical patterns from that
1215920	1220200	system in order to learn about that system, what we're doing is effectively science, it follows
1220200	1226360	the model of science. So in fact, most applications of machine learning ought to be considered a
1226360	1233280	kind of science adjacent activity. And in my opinion, held to the standards of good science.
1233920	1242280	Now, I think that there's a lot of good work being done with machine learning and science.
1242280	1249320	There's a lot of really epistendically careful work. And I think there's also, like with most
1249320	1262720	things, a glut of garbage, pick a genre of anything. I don't care if it's films or psychological
1262720	1272880	studies, or books on the history of hip hop, or like whatever it is, or perhaps even people for
1272880	1280160	that matter. Yeah, yeah, most most of it's crap. Yeah. And there's a very small percentage of it
1280160	1289120	that's quite good. Machine learning is no different. There's a lot of good work being done, and 1000
1289120	1297680	fold more bad work being done. The issue is that it's being adopted so rapidly, these methods are
1297680	1303560	being adopted so rapidly, in so many contexts, across society, most people don't understand how
1303560	1312840	the technology works. There's a lot of AI hype, as long as there has been AI, there has been AI
1312920	1321080	hype. And what hype is, I think it should be made explicit that what hype is, is it's a targeted
1321080	1327280	disinformation campaign. Yeah, perhaps you could elaborate on what you mean by that.
1327280	1340040	Yeah, so AI hype refers to people, when Sam Altman says, we'll have AGI by X, or when Sam
1340040	1348680	Altman says, well, GPT three could take a 20 minute activity and reduce it to five minute
1348680	1356840	activity, but GPT next will reduce a week long activity to five minutes or something like that.
1356840	1358360	You know, that's AI hype.
1359960	1366760	Now, I saw I saw a recent statement by, I believe, anyway, I want to mention any names that the next
1366760	1374800	GPT model will will be able to replace PhD researchers and we won't need any PhD researchers
1374800	1378200	anymore. So yeah, I'm in shock.
1378200	1385840	That's AI hype. Scientists and science popularizers saying the theorist will be replaced, the
1385840	1393960	physicist will be replaced, the doctor will be replaced, you know, in medical context saying,
1393960	1397640	oh, we won't need, you know, we won't need secretaries or we won't need nurses anymore.
1401080	1408120	Any of that drama, but it also includes the doomerism about AI, like soon AI will surpass
1408120	1412680	human intelligence and it will, you know, hurt us somehow.
1412680	1417480	That's the part which I, for me, at least feels a lot like science fiction, if I'm being honest,
1417480	1422200	the doomer. Yeah. Yeah. There's something even it's interesting to even science fiction.
1422280	1428120	I mean, yeah. And I have nothing, nothing against I love science fiction, but it's got his own
1428120	1431720	status in our dialogue, right? I mean, science fiction, it's called fiction.
1431720	1438360	But saying that's, that's some particular tech breakthrough is going to replace
1441080	1450760	cardiologists even is absolutely, will it, you know, have some impact on the role of
1450760	1459160	cardiologists in specifically how they approach analyzing the results of imaging,
1460680	1466200	right? Totally. Is it going to replace cardiologists? No, that's science fiction, right?
1466200	1471320	And it should, given all technology affects how we do our jobs, how we live our lives,
1471320	1475880	and that's completely fine. It probably should affect how they do their job.
1476680	1481640	If it works, it should. That's, that's true. It doesn't work if it can, but if it works,
1481640	1485240	it should have an impact. It's just that there's, there's,
1488680	1494520	in anything that's, you know, marketable, there's an incentive to misrepresent
1495480	1504440	what it does. This is true of, you can pull out a magazine from 1952 and how it's
1505080	1515080	advertises some cooking implement to stay at home moms. And it misrepresent, you know, it's like,
1515080	1519160	this is a life changing, it's going to lie to you about what the thing does, right? But
1521640	1527320	with AI specifically, you know, I think, I think there's just to some extent,
1527880	1535480	even the, the average housewife in the 1950s was like, yeah, probably, probably not all of this
1535480	1543160	about the oven is actually the ground truth, you know, whereas with AI, people seem to be willing
1543160	1550520	to believe really radically untrue things, you know, just things that are actually
1551480	1556520	to anyone in the know, blatant lies. But there's a culture of
1558520	1570520	really leaning into highly fabulous lies, propagating them to no end. And no one seems to be doing
1570520	1577320	fact checking. And the worst part to me is, is, I would think that's in, so I'm, I'm coming from
1578040	1585320	this position of history and philosophy of science, where it's like, we've studied hundreds and
1585320	1591720	hundreds of years of science and technology, and how people misrepresent what it does and what it
1591720	1602120	actually does, right? So we would, I would hope that we would have a critical lens on this. And
1602120	1605800	it strikes me that there's a lot of philosophy that's simply
1607560	1612920	parroting or, or lending kind of philosophical justification to these hype narratives that,
1614360	1619960	you know, deep learning will radically change the face of particle physics or something like
1619960	1626360	that. It's like, really, really though. Okay, perhaps just, well, this is, this is a good,
1626360	1631880	good place to go to. So one, one term, which I really liked in the paper, which you use with
1631880	1637480	this idea of global, the theory free ideal, I really liked that, that, that term. Because I
1637480	1643400	think for me that captures what apropos philosophy of science or let's, let's say apropos the,
1643400	1651800	the scientific method, what the hope or the dream with ML models are. So if you could melt, just,
1651800	1658200	just to like, again, to flesh this out a bit more as, as to where we are right now with the
1658200	1665080	current paradigm of machine learning, what is the epistemic status of machine learning?
1665880	1672920	And then could you then probably connect that to what, what, what, what is this theory free ideal?
1672920	1677800	And then as you point out in your papers, what are the mistakes that people make with, with,
1677880	1683480	to, you know, by having this ideal of science being theory free when done with a,
1684200	1690920	let's say an ML model, for instance. Yeah. Yeah. So I think machine learning models are statistical
1690920	1697880	models that are computationally instantiated. There's, there's nothing that would in principle
1699560	1704360	make the epistemic status of these technologies any different from
1705080	1713320	any kind of other statistical model. Now, you're pushing yourself into really high
1713320	1723480	dimensional spaces in which data is transposed. And so there's intrinsically,
1725320	1732760	the, the dimensionality of the patterns you're finding is much higher than what you're doing
1732760	1743960	with classical statistics. But I guess I doubt that when people are doing multiple regression,
1744840	1754120	they are kind of holding all the dimensions in their head in the way that they would have to be
1754120	1760600	in order for the contrast that's typically drawn between deep learning and classical statistics
1760680	1767000	to make sense. Like there's, there's meant to be a kind of opacity, a kind of intrinsic deep
1768360	1773640	unknowability of the kinds of patterns that these statistical methods that is deep learning methods
1773640	1779320	are finding relative to classical statistical methods. And I just don't see that distinction being
1781960	1787480	substantive and absolute in the way that it's proposed to be. I think these are at their heart
1787480	1792200	statistical methods like other statistical methods. And if there's a difference,
1793960	1801000	it's a sociological difference. Okay, I think I've followed you all the way except the last bit,
1801000	1806520	the sociological, but if you could probably touch that up. Yeah, so it's, it's the corporatization
1806520	1812280	of these technologies. I see. Okay. It's the hype narrative. So even in a research context,
1812360	1814440	there's because, because machine learning, I mean,
1819000	1826440	because machine learning is this place where stats met up with AI and AI is something that's
1826440	1832280	always, AI refers to a lot of different research traditions that have had historically very little
1832280	1836200	to do with each other in terms of their, their substance in terms of their subject matter in
1836200	1845800	terms of the methods, they mostly have to do with where funding is being targeted and the kinds of
1846760	1851400	narratives spun around these research methods. So there's very little substantive that holds
1851400	1855560	everything that's historically been called AI to going back to cybernetics, going back to McCarthy,
1855560	1863080	going back to, you know, all the tips and, you know, like going back all through the history of
1863080	1869640	things being called artificial intelligence. There's very little that connects all of these, but
1871960	1876280	who they're targeting for funding and the kinds of narratives they're using in
1876280	1884440	convincing the public and funding bodies of what they're doing. So there are methods and statistics
1884440	1892920	that have been, you know, approaching something like machine learning, going, going back 80s, 90s,
1892920	1902920	whatever, right? But where that meets up with the AI narrative, you get this hype and disinformation
1902920	1918760	and overselling of competence, right? And so there's, there's an attitude and a meta narrative
1918760	1926440	surrounding machine learning that is, I think, more what sets it apart from classical statistics
1926440	1935880	than anything else. This is, this is a spicy take, you know, kind of with a grain of salt. But
1935880	1944040	this is my, my challenge is really like, tell me what is so radically epistemically different
1944040	1950680	about these technologies that they should be placed in some category that's discrete from
1950680	1956840	classical statistics. I have not seen it, you know. And you point this out. Yeah. And also,
1956840	1964280	I guess it's this meta narrative that, that drives its impetus behind this theory free ideal
1964920	1970920	when it comes to science. Yeah. And, and there's been so philosophers, natural philosophers,
1970920	1978360	scientists have debated what theory is and what its proper role in science is since the, the
1978360	1983480	incipients of what we call modern science, right, since Bacon and Newton and Galilea, you know,
1983480	1993000	modern science, right? Even going back to Bacon, there's, there's, there's a kind of push for a
1993000	2002120	kind of radical empiricism that pushes away as much as possible the role of theory about just,
2002120	2006600	just tabulating as much data as possible and sifting through it for patterns and, and not
2006680	2010280	bringing our kind of conceptual infrastructure to bear on it. But then since Hume,
2012120	2017080	since Hume brought his sort of problem of induction to the table in epistemology,
2019000	2025080	there's this widespread recognition that, well, all, all knowledge of the natural world
2025080	2029640	is knowledge by induction. You do not get deductive certainty about empirical
2029640	2037960	matters. Yeah. So the typical example is the sunrising just because it rose
2037960	2043800	yesterday. We can't say necessarily it'll every day of our lives, the sun has risen in the morning.
2043800	2049400	It's risen. Yeah. Yeah. And yet give me a deductive proof, give me logical certainty
2049400	2053720	that it will rise tomorrow. There is none. There's only the, the
2054120	2062280	you know, the remit of our experience to tell us that it will rise tomorrow. There's no
2063400	2065960	logical necessity that it will rise again tomorrow.
2068520	2075480	So knowledge of nature, scientific knowledge is, and all our kind of day to day practical
2075480	2079640	knowledge, like I can eat this bread and it won't poison me because the bread I ate yesterday that
2079720	2085080	I got from the same baker didn't poison me. You know, this is inductive knowledge, which means
2085080	2093800	we don't get deductive certainty. And it also means that to get that kind of knowledge, you need to
2095080	2101960	start off with rich conceptual infrastructure, which I'm calling theory. I think, I think when,
2101960	2105240	so I think there are lots of ways that philosophers have traditionally
2105240	2110440	cashed out what we mean by theory, I think that when we talk about theory free science, we mean
2112520	2119400	a powerful influence at the beginning of inquiry, at the beginning of the investigatory
2119400	2125720	procedure of our prior conceptual resources, our prior conceptual
2126920	2132360	acquaintance with the target phenomena, right? We do not get, we do not get inductive
2132360	2138280	inference off the ground without bringing to bear prior theory or conceptual.
2139720	2143160	The philosopher and historian of science, John Norton calls it
2143880	2149880	bringing to bear material facts, right? But there are lots of ways of putting it, but
2151880	2158040	you need theory to get empirical knowledge off the ground. And so in this sense,
2158760	2165320	you cannot have theory free knowledge of natural systems. And I think that
2168200	2172120	you can look back for hundreds of years, and there's always this dialogue between, no, we should get rid
2172120	2179800	of as much, as much as we can push away the influence of prior conceptualization, we should do that,
2179800	2185800	and that's scientific objectivity. This is, I think, one notion of scientific objectivity.
2186200	2193640	Right? That has been kind of implicitly in the background of a lot of discourse in philosophy,
2193640	2199160	natural philosophy science for hundreds of years. And then another stream that says,
2200680	2205800	well, you can't actually have knowledge of nature without bringing conceptual resources to bear.
2205800	2211960	So it's about documenting them. It's about recognizing them. It's about, to some extent,
2211960	2217240	those assumptions and saying which of those assumptions are, in fact, substantiated by
2217240	2223400	what we've then been able to observe and deduce from what we've measured or observed in nature,
2223400	2229880	right? And what is, in fact, just arbitrary or unknown, right?
2232280	2238120	And I think since the rise of domain generic statistical methods in the 20th century,
2238200	2242840	in particular, stats really gets off the ground after the axiomatization of probability theory
2242840	2251960	with Komagorov. Statistical reasoning, probabilistic reasoning is, to the extent that's so widespread
2251960	2256840	in science, it's relatively new. It's really a kind of 20th century, like statistical reasoning
2256840	2261960	is kind of a 20th century thing. I mean, it sort of got off the ground with gambling and stuff in
2261960	2272040	the 17th century. But as a scientific method, it's new. And really, I think since the mid-20th
2272040	2283800	century, you get a lot of this, what I call a theory free ideal. And it's in the kind of
2287080	2291320	fundamental, I don't know if I believe in this destination, but in the more fundamental sciences
2291960	2298680	who know how to theorize because they've been doing it for hundreds of years and know how to
2299240	2303640	mathematically represent their phenomena, because they've been doing it for hundreds of years,
2305560	2314120	you get less of this. But in the younger sciences, like the quantitative social sciences, like
2314120	2328840	social psychology, like population genetics, what have you, economics, there's this belief that
2331160	2337720	the more theory free, the more data driven the methods are, the more objective they are and
2337720	2343640	the more sciencey. Yeah, so when you mean the more fundamental, you mean like physics, for instance,
2343640	2351320	right? Yeah, areas of, areas of, but not all areas of physics, right? The areas of physics
2351320	2356040	that are really established. Yeah, although, although, you know, this beautifully connects
2356040	2361160	with your sociological point, because I'm sure you're aware of the whole Bohr-Einstein debate and
2361160	2365000	that, you know, shut up and calculate. There's like a lot of, in the history of 20th century
2365000	2371000	physics, is his idea that even within physics, you shouldn't ask, but given that physics is the,
2371080	2376200	it's a foundational discipline, the ontology of the physical world, you know, there was a time,
2376200	2383400	especially because of, you know, World War II and the nukes and all that, just don't ask the,
2384440	2388600	don't ask the ontological questions, just shut up and calculate, just that there's a
2388600	2395480	ruthless pragmatism, ruthless, just create. And so physics kind of sometimes, and again, I again
2395480	2401160	say this as a bit of an outsider, it becomes a bit more like engineering or a foundational
2401800	2405320	discipline where you're asking, well, what exists, what is reality?
2405320	2407160	That's sort of the Los Alamos attitude, right?
2407160	2409080	As in the idea that physics is engineering?
2410680	2412760	Does that happen and calculate attitudes?
2413560	2418680	Yeah, yeah, I mean, I know more from the Copenhagen school, I mean, I followed that, I think Tim
2418680	2425080	Modellin, he speaks quite well about that. And just, it's like a, you know, interesting
2425080	2430600	peculiarity in the history of physics, especially because if you look at the big figures, like,
2430600	2437880	like the Einstein's, or like the Maxwell's, they were deeply interested in these philosophical
2437880	2443000	questions, it's like, what exists, you know, it's not Einstein was a philosopher, he certainly was,
2443000	2448200	he certainly was, you know, without a doubt. Yeah. I mean, probably after Newton is probably the
2448200	2454360	quintessential natural philosopher, I couldn't agree more. And yeah, so I mean, just on this note,
2455240	2461080	I couldn't read the paper too carefully, but I do love the, perhaps it's worth mentioning,
2461080	2466840	because it's rather provocative and I like that a bit, where you say, yeah, machine learning has
2466840	2472760	a pseudoscience problem. And then you bring up the, well, you and the other other writers, Andrew
2472760	2481880	and Bieber, is it? Yeah, bring up. Yeah, yeah, they bring up the idea of how there's a resurgence
2481880	2489800	of physiognomy in kind of these ML communities. So just, if you could just humor me with that for
2489800	2495480	a bit, just kind of what all that, that's about why you claim, you know, machine learning has a
2495480	2500600	pseudoscience problem, which I think you already kind of did outline quite, quite in detail. But
2500600	2506840	then this little, little example you use on, on physiognomy. Yeah, well, part of it is this sort,
2506840	2513000	this sort of runaway idea that we can do science without theory that picks up steam in the mid
2513000	2518920	century. And then with the rise of machine learning techniques, and these being adopted
2518920	2524520	widely, it just becomes, it becomes, it gets bundled into this hype narrative about how these
2524600	2532840	technologies work. And then everyone sort of believes that these technologies are capable of
2534360	2544120	extracting true knowledge of some natural system in virtue of having achieved high
2544120	2557720	classifier accuracy on some natural data set, right? And what's actually happening is, is researchers
2557720	2564040	are interpreting that pattern as having discovered precisely whatever their intuitive idea of what
2564040	2568120	they were going to discover was beforehand. Because if they're not explicitly doing the
2568120	2573640	theory, if they're not, if they're not explicitly theorizing, then they're implicitly theorizing,
2573640	2578760	which means that they're effectively trying to con you into believing whatever their intuitions
2578760	2585480	were at the start of the research procedure, without effectively having furnished evidence of
2585480	2592600	that, besides having told you that they train some model, and there's some pattern in the data that
2592600	2601240	satisfied some criteria, right, for success. But I think because of all these hype narratives
2601240	2610920	surrounding machine learning, and again, not for substantive epistemic differences in how these
2610920	2618520	statistical methods work, but rather for sociological reasons, you get a lot of bad, bad,
2619240	2630760	bad science. So if I want to do a quantitative social science study, and I'm in a sociology
2630760	2640760	department, or an economics department, my advisors won't let me do that until I've
2640760	2647320	read up on the hundred years long history of scientists in my field having studied that
2647320	2653160	exact problem, right. Machine learners on the other hand, machine learners don't even read the
2653160	2660760	history of their own work. Machine, like, it is not typical for someone in machine learning to have
2662280	2670200	even a five years deep understanding of the history of their own field, right,
2671400	2675960	which is there are of course exceptions, but the general rule is people in machine learning do not
2675960	2682040	read. Yeah. And so by you're talking, are you talking about more on the scientific side, or do
2682040	2688600	you just mean general, you know, commercial ML engineering? Practitioners, but also in academics.
2688600	2698360	Academics, okay. That's unfortunate. And so when you go to apply ML, you know, everything that's
2698440	2702600	submitted to Art Tripoli, or, or NeurIPS, or what have you.
2705720	2714680	ACM, you get just this glut of work of people applying the methods of ML, especially DL, to
2715560	2721400	some problem that scientists have spent maybe hundreds of years working on. And there's no
2721400	2727400	acknowledgement that what they're tackling, what they're attempting to tackle is a scientific problem
2727400	2736360	that some very specific field of, you know, molecular biomechanicists or whatever the field is,
2736360	2742920	right, have been working on for hundreds of years. And then there's this attitude that
2743640	2748920	while deep learning will solve the problem, and I don't have to pay my dues and read about the
2748920	2755800	methods in this field. And then the reviewing practices at, well, you know, part of it's like
2755800	2761800	we got rid of, we got rid of traditional peer review and machine learning, which is like, was
2761800	2769800	traditional peer review hopelessly broken? Yes. Did we introduce new problems by getting rid of it
2769800	2776120	wholesale? Also, yes. Right. And so then you've got, you know, so there aren't standard journals in
2776120	2786600	machine learning the way they are in biomechanics or biochemistry or socioeconomics or whatever,
2786600	2799240	right? You are submitting to the big name machine learning conferences, but peer review there is
2799560	2811160	I mean, I have to say it's pretty radically incumbent. I don't know that I don't think anyone
2812280	2825640	who reviews for or submits to machine learning venues would try to fight me on that. I mean,
2825640	2834360	I think the consensus is that the peer review process for these venues is wildly inadequate.
2834360	2839320	Inadequate, yeah. So and it's because it's because when you apply machine learning,
2840840	2846520	right, you're applying it to some domain, you're applying it to some domain where there is a vast
2846520	2853080	history of people trying to solve some problem. And when you submit your little deep learning thing
2853080	2859320	to IEEE and you're trying to tackle some problem in social science, they're not asking social
2859320	2866920	scientists to review that. God, no. Right. They're asking other people who trained a, you know,
2867960	2875560	transformer to with data of that shape, right? But they're not asking people who have the
2875560	2883480	disciplinary knowledge to review the methods for what actually matters to doing science, right?
2886200	2892680	Yeah. Yeah. And when do you think this changed? Well, was this, is this imminent to the
2893800	2899640	practice itself? Or when do you think this change took place where the peer reviewing
2899640	2904360	method became a bit lax or inadequate as you pointed out?
2906680	2906920	Well,
2913960	2917560	it was just sort of an organic thing, right? You have
2920040	2926520	on the one hand, I mean, it was never the case that it was never the case that there were
2927160	2931960	people applying machine learning, as far as I know, where it was never the case that people were
2931960	2936680	applying machine learning to some problem in biology, and then submitting that to a biojournal.
2936680	2941240	That's not the, I mean, occasionally that happens, right? But that's not standard practice. And I
2941240	2950040	don't think it ever was. It was also not the case that there were kind of standard journals for,
2950040	2954600	there were standard journals for stats, right? But there were never kind of standardized deep
2954840	2962520	learning journals, right? There were, there were computing or stats
2965000	2973320	conferences that got kind of evolved into ML specific conferences or new ML specific conferences
2973320	2979720	emerged. And like, you know, a lot of the main ones are actually, they didn't start out as ML
2979880	2986920	conferences, and they evolved to be ML conferences. But also you have at the same time the emergence
2986920	2998360	of pre-printing servers. And so you get, you get the emergence of a new kind of, like machine
2998360	3004440	learning has been machine learning, the methods we call machine learning have been around since
3005400	3011800	like the 80s, right? You could trace it back earlier to kind of proto machine learning methods.
3013000	3018200	Those go back much, I mean, again, like, it was out of World War II, it was out of the research
3018200	3024920	at Los Alamos, that you got like MCMC sampling, right? Like Mark O'Chain Monte Carlo sampling,
3024920	3033000	like Metropolis Hastings sampling. I didn't know that. Yeah. Yeah, it goes back to like the early
3033080	3039080	50s, late 40s, early 50s. So even before that's kind of machine learning, right? Yeah.
3042040	3047320	But, but, you know, machine learning as it's the early 2000s that machine learning kind of
3048120	3051880	goes like, hey, we're a scientific field, or hey, we're an engineering discipline, like we're a
3051880	3058360	discipline now, right? And it's at the same time that you're getting pre-printing servers as the
3058360	3062600	sort of way that that stuff is disseminated. So there's, there's, effectively, there's no
3063560	3068920	incentive to start journals, and there's incentive against starting journals, I would say. This is
3068920	3073800	my, I'm making this up on the spot, but that's kind of how I would reconstruct that history.
3073800	3078360	No, that makes sense. Yeah. I mean, it's partially contingent. It's just historically how things have
3078360	3081880	been. Yeah. And also, there's this widespread recognition that there's something deeply broken
3081880	3088280	about traditional peer review, which is true. Yeah. Which virtually, I believe all every academic
3088360	3093000	I've spoken to has said that. So unequivocally, I think it's just a general consensus. Yeah. Yeah.
3093000	3097800	Excellent. Excellent. Now, that's, that's, that's great, Mel. I want to be cognizant of the time,
3097800	3102760	which is, which is why I want to get to this. And I'm sorry if this sounds like I'm flattering you,
3102760	3108840	but your paper on the free energy principle, it is, I've probably read it like three or four
3108840	3115080	times. And I think I can probably parrot out certain parts of it verbatim, because I've read it so
3115080	3119480	many times, especially because I hate it. It's actually, it's a really good paper. It's a fantastic
3119480	3123480	paper. It's a fantastic. And so now I'm trying to like, I'm like, okay, what, you know, I'm trying
3123480	3129480	to write a subsequent paper. And it's like, it's not that good. I mean, because like it's, it's
3129480	3134440	probably your most cited paper, right? I mean, I found you through this. In fact, like, I didn't
3134440	3140040	even know who you are until I came across this work. Yeah. So just for the listener, it's called
3140120	3145800	the math is not the territory navigating the free energy principle. Yeah, I mean, it's just,
3145800	3150680	it's philosophically interesting. It's got so much into like the history of science. And then,
3151400	3156760	you know, like, what is formalization? You speak about the structure like, yeah, he keeps a lot
3156760	3161960	to discuss here. Although, although before we get to the, let's say the nitty-gritty, and one thing
3161960	3166680	I want to mention is, so I've been trying to get through this, this book on active inference. And
3166680	3173960	I've got to say, because when I'm reading this, every page, I'm kind of reading it in a way through
3173960	3179720	the kind of the lens of what you put in, in me through this paper, you know, it's like, I've
3179720	3187000	got a bias now, I've got the, I've got the, the math is not the territory bias. Because it really
3187000	3192120	helped me understand. Yeah, it really did help me understand the ontology of what really is the
3192200	3197000	free energy principle, because it's got so much interest. So many people talk about it. And,
3197000	3203400	you know, Carl Friston, he's fantastic. I've learned so much, but he sometimes isn't the
3203400	3209080	best elucidator, you know, like he, when it comes to, you know, he's not a philosopher. Correct. I
3209080	3216520	think that could be the reason Einstein was a philosopher. Carl Friston is like Isaac Newton,
3216520	3224920	in that he's kind of like, I don't care what's like, he'll ascent to any metaphysics,
3224920	3229400	Newton would ascent to any Newton was like, I'm not doing metaphysics. I'm associating
3231560	3238440	relationships I see in data. Right. But don't tell me about the physical seat of gravity. I'm
3238440	3242120	not talking about that. Yeah. Oh, yeah. I mean, that certainly wasn't wasn't a dig at
3243080	3247400	Professor Friston, because he he himself says, he says, yeah, I'm not a philosopher, I'm a
3247400	3252520	scientist. And I don't really, when he doesn't even really take a philosophical position or
3252520	3260280	metaphysical position pertaining to the FEP. But but having said that, Mel, so, oh, sorry,
3260280	3267160	be that as it may, I mean, what, what, why, yeah, why do you think there's such deep philosophical
3267160	3273400	interest in the free energy principle of every any philosopher who works in the philosophy of
3273400	3279560	biology or the cognitive scientist or ML, but it's such deep philosophical interest. So, yeah,
3280440	3285800	why do you think the reason for that is, I think there are a lot of reasons one of them is, okay,
3285800	3293080	so I think, I think of all math, all applied mathematics, or scientific math or models,
3293080	3297880	as a kind of thinking tool, math is a thinking tool for science, right. But
3299720	3305400	the free energy principles are thinking tool in a different way in that it's not actually meant to
3306200	3313640	be placed in contact with empirical data, right, it's just about enabling us to conceptualize
3313640	3321800	of target phenomena and new ways. And it happens to be new ways that are actually really
3324040	3333480	a philosophically generative and novel to suck to agree. Not exactly novel, but overlooked. I mean,
3333480	3341320	you get some of like, some of what's being said about life. It's if you look hard enough, it's
3341320	3350280	really in Schrodinger's, Schrodinger's what is life. You look at that text, there's a lot of the
3350360	3355560	ideas that are being brought out in the FEP in that text originally.
3357880	3363560	Yeah, he brings up new ideas go back, but largely ignore, because they're very much
3364680	3371080	opposed to the kind of neo Darwinian canon that we have now in biology, where we're really looking
3371080	3380520	at population level analysis. And you're not looking at physical exigencies or structural
3380520	3386840	exigencies of biology at the physical systems involved in biology and what kinds of necessities
3386840	3395800	need to be there for life to exist. And then connecting that up to a view of cognition as
3395800	3401720	fundamentally oriented towards action and interaction with the environment too. I mean,
3401720	3411720	that's also there. So there's a lot that's philosophically rich that is associated with the FEP
3411720	3417880	in how the FEP is discussed. It's not necessitated by the FEP, the FEP is just math, but it's math
3417880	3424200	that allows us to conceptualize of things that we're taking away. It's also cool math, it's fun
3424200	3428840	math. Part of it is there's a lot of flourished that math that doesn't need to be there. That's
3428840	3438440	just it just if you like math, it's it's cool. And you can keep pushing it new cooler. It's
3438440	3446280	kind of it's it's like this magpied. It's like a bunch of shiny math taken from 18 difference
3446840	3452520	distinct. You know, you've got you've got some of its machine learning math.
3453480	3459000	Like some of it just is it just is elbow, right, to minimize free energy, the quantity known as
3459000	3464040	free energy as a kind of information theoretic construct to minimize free energy is is to just
3464920	3469080	optimize the evidence lower bound, which is elbow, which is machine learning technique, right?
3469640	3476280	Um, it's also Fokker Planck, or the master equation, or the Kolmogorov forward equation,
3476280	3485480	which is, you know, a principle of stat mech. It's also, I connected up to Max Ent,
3485480	3490680	maximum entropy principle, which is a sort of, James,
3491320	3502680	put forward this idea that we can view. Basically, the core principles of thermodynamics,
3502680	3511400	expressed statistically, can also be reoriented as a kind of
3512280	3525800	epistemic principle for like keeping your priors flat, basically, except for when the evidence.
3526920	3532520	Does that make sense? No, I think I got the latter bit of it regarding the epistemic principles.
3532600	3538920	Yeah. Yeah. So, James in the, is this 50s? Max Ent, James.
3541240	3542920	When's the first Max Ent paper?
3545240	3550520	50s, right? Yeah, it's a 50. It's 57. It's 57.
3553560	3557240	Yeah. So, the idea is that. Yeah.
3557960	3562120	Yeah. 57. That's right. Yeah. Yeah. BT James. Two papers.
3563960	3570200	So, it's like a closed thermodynamic system. The principles of thermodynamics tell us that
3570200	3577640	a closed thermodynamic system will max out its entropy, right? Like, that's,
3580600	3583960	this is what thermodynamics tells us. At a certain point, yeah, of course. Right.
3584680	3590760	Ultimately, in the limit. You can give this
3592920	3602600	a gloss as a principle for best inference. Like, it's already probabilistically formulated,
3602600	3616520	but then view that as a rule for governing the probability distribution over some belief.
3618200	3626840	And it's, again, Max Ent, because your priors need to be as flat as,
3626840	3632120	as the probability distribution is as flat as it can be, given the evidence, right?
3633240	3637480	So, there's.
3640440	3646600	And you're saying the FAP does bring this into its, it's theorizing too, like.
3647320	3652600	But they did. I don't think they did. I think I pointed it out, and then they started to,
3654280	3658680	so there's, their recent work is actually explicitly incorporating the James stuff.
3658760	3663800	Okay. Fascinating. Yeah. I think it was actually because I was like, so James, right?
3665480	3669000	That's fascinating. I didn't know that, because I mean, I mostly view it through,
3669000	3673560	you know, predictive coding and Bayesian reasoning. I mean, really, that's.
3673560	3680200	I actually doubted that lineage. I doubted that lineage, but I thought that they've
3680200	3685800	made that connection explicitly beforehand. But the people who are now explicitly doing the
3685800	3691640	Max Ent incorporating with FEP are attributing it to me. So I'm like, you know, it's if he wants.
3692440	3697720	Okay. Yeah. Are there any, because like, I mean, I'd love to read up on this. Are there any papers?
3697720	3700520	Because I mean, I've only just started on the book. This is the.
3700520	3703800	I think the best. Okay. So, so the, Tom Parr is fucking excellent, but.
3704360	3708040	And all of those people who wrote that book are excellent, but I think.
3708040	3709720	They're very good writers too. Yeah.
3710680	3711960	I think the most competent.
3714520	3719960	Mathematician who's working within the free energy framework is Dalton.
3721960	3725400	Okay. I got a, who I spell that.
3726360	3728440	Do you know how to spell Tamil names? Yeah.
3729880	3734280	The first name is very Scottish, which is a little well. Okay. There we go. Yeah.
3735160	3744040	Um, so actually they, they took it from, so they took the Max Ent. I, so I proposed like, hey,
3744040	3750040	you know, well, what the FEP is kind of is you're, you're, you're taking principles of statistical
3750040	3757000	mechanics and you're epistemic sizing them. You're giving them an inferential reading.
3757640	3761080	You're taking laws, laws of stats. Yeah. Yeah.
3761080	3766360	And you're reading them as principles, as principles for.
3768920	3775000	Cognition. Yeah. Yeah. I mean, I mean, I, I, I, I, I'd say for me initially when I came
3775000	3778200	across FEP, that's what I found quite interesting where, you know,
3778200	3782680	Carthus and his background is even in physics and like you take from statistical mechanics,
3782680	3787480	which is in physics. I think, I think he did a bachelor's in physics in like the 60s.
3787480	3791160	Yeah. I shouldn't say background. You're right. I think he studied physics. He certainly is a
3791160	3797400	neuroscientist, but, but like, I think he does like the physics he's getting is largely outdated.
3798920	3802840	Well, I think he's just drawing from a lot of areas of, of physics.
3805400	3811320	And really it's like, he's in clinical neuro, right? He's, he's spent a career in clinical
3811400	3816920	neuroscience. Well, I mean, generally what interested me was that the fact that you take these
3817480	3821320	theories and principles from physics, like, you know, all from statistical mechanics or,
3821320	3827960	as you point out, like, you know, max and, and then apply them to move to like cognition,
3827960	3834200	reasoning, Bayesian inference and the likes. I just, I don't know. I find that fascinating.
3834200	3839640	And I don't know. I just feel like I, again, as a neophyte, just, it just excites me to see where
3840360	3846120	the, the developments that goes on the FEP and the, you know, the concomitant, more engineering
3846120	3854280	work that comes along with it. Having, having said that, Mel, one thing is this, in your paper,
3854280	3859160	you say the math is not the territory. And I think here's where we get to the, really, the,
3859720	3863640	the crux of the argument, the philosophy of this paper. And I'm just going to read out a bit of
3863640	3868680	an excerpt. I think it's valuable for the, for the listener in case they haven't read it already,
3868680	3874520	which I, I, if you're interested in the FEP or ML, for that matter, I highly recommend reading
3874520	3879000	this. So you just, you claim here, I think this is from the abstract. I'm not sure. Anyway, I've
3879000	3884600	got this excerpt here. Conceptual verification is a common ailment of scientific modeling.
3885160	3892520	It is particularly likely to occur in cases in which models have somewhat convoluted histories.
3893160	3895960	Rification involves, and here's the important bit, in fact,
3896600	3903240	verification involves mistaking an aspect of a model, its structure, its construal, or the union
3903240	3911720	of both, for an aspect of the empirical of the natural world, mistaking the math for the territory,
3911720	3919480	so to speak. So yeah, could you please elaborate on that little statement and then, you know,
3919480	3928200	kind of connect that to the FEP? Yeah, so I think, I think there's a tendency to
3932120	3939800	conflate scientific realism with realism about the conceptual tools that we use in science.
3939800	3945560	So I'm, I'm a full-blooded scientific realist. I think, albeit a pragmatic realist.
3946520	3951080	I'm somewhat of a content. I think I'm more of a real, I think I'm more of a realist-realist
3951080	3954680	than most people who call themselves pragmatic realists. I think people who call themselves
3954680	3957320	pragmatic realists, I'm like, you're not really a realist. I'm actually a realist,
3957320	3963240	just pragmatically so. No, I mean, I would say science without a doubt, it does give us
3963240	3973560	truths about reality. I mean, I, in the content sense, let's say. Yeah, whatever the truth knowledge,
3973560	3979480	whatever the epistemic goods of science are, I want to say it's truth sub-pragmatic or knowledge
3979480	3987160	sub-pragmatic, right? I think, I think there's, it's not absolute, all-encompassing, omniscient
3988840	3996840	truth about nature. It's, it's pragmatic truth. It has its limits and it's oriented towards us
3996840	4001560	as the kinds of beings that we are having to occupy the world and navigate it the way that we do,
4001560	4006440	right? But I think it is truth. I mean, if anything is truth or knowledge, that's, that's
4006440	4012440	what that is. Exactly, with all those caveats, it gives us truths, let's say. Yeah, yeah, yeah.
4012440	4021400	But then we introduce all this conceptual machinery into science to be able to do science,
4022440	4030440	like the idea of a Hamiltonian or the idea of a gravitational field or the idea of a fermion
4030440	4039000	or the idea of, you know, a force function. And that includes all the, you know, the
4039000	4042600	Fokker-Planck equation that includes all the sort of mathematical infrastructure too.
4042600	4056760	These are all the conceptual tools of science. And I think that there's a lot of slippage that's,
4057560	4064920	that's like, well, science delivers truth. Therefore, all the conceptual tools we introduce
4064920	4070840	in the process of doing science and getting to that truth are also true and real, in some sense.
4070840	4079000	And I'm like, no, that requires a lot of careful work at the end of the day. At the final kind of
4079000	4084920	interpretive stage of a scientific procedure, you ask yourself, do we think strings are real?
4084920	4091800	Do we think that quantum fields are real? Do we think that Hamiltonians are real? Or was this
4091800	4095720	just sort of a calculational device? And I think there's a lot of, in between, between it's real
4095720	4101640	and it's a calculational device. But I don't think at the end of the day that's a distinction that
4101640	4114200	can be fully upheld. But there's a tendency, and I think it's true, even among careful philosophers
4114200	4128200	to attribute realism or truth to, to try to make the conceptual tools of science truth out
4128200	4130840	when they ought not to be read as truth out.
4130840	4134840	Yeah, when it's a thing itself. I mean, it depends, right? For instance,
4134840	4139800	I've spoken to a few mathematicians on this podcast, one person who I, as I came that comes to
4140280	4147160	shoulder with Hamkins, he's a Platonist. So for him, of course, yes, FEP, if it's a mathematical
4147160	4153000	structure, it could really exist in like a platonic sense. But in your paper, you're talking
4153640	4159720	more in regards to our physical world, what science studies, you know, you're not talking
4159720	4164200	about like a platonic realm. I don't know what your views are on Platonism.
4164200	4173240	So with math, I think there's a lot of accounts of how math works in science that are, whether
4173240	4179320	explicitly or not, deeply committed to Platonism, or something akin to it. And
4182360	4190600	for me, I'm like, if your account of how natural science works, depends on assuming
4191400	4197160	the most kind of industrial strength metaphysics possible. It's not a good account of natural
4197160	4203080	science. Like I'm an, I believe in naturalism. I'm a naturalist. And a lot of naturalists,
4203720	4208520	a lot of proclaimed naturalists happen to also be Platonists. And I'm like, that's not real
4208520	4214760	naturalism, right? You need an account of science that assumes as little in the way of metaphysics
4214760	4221160	as possible. And is cognizant of what metaphysics it does assume to the extent that you can't get
4221160	4229240	away from that. Yeah, that's why you mentioned all the, all the presuppositions that your
4229240	4237560	realism is based on, right? Right? Yeah. For me, it's like the word, the word dog or the word
4237720	4246600	mitochondrion, right? Do we think the word dog exists? It's like,
4249560	4257240	I think dogs exist. Yeah, yeah. I think that there's a class of natural entities that is well
4257240	4263320	carved out by our best science. And we refer to it via this concept that has this label attached
4263320	4269480	called dog. Yeah. But I don't think, I think the word exists as a cultural mental artifact.
4269480	4273800	But I don't think it exists mine independently. And I feel the same about math and science. It's
4273800	4279720	like. Yeah, sort of interrupt, but I think, I think I agree with you. I mean, I'm, I'm still,
4279720	4284200	I hate to use this like cheap like agnosticism, but I'm kind of agnostic as to mathematical
4284200	4289320	Platonism. Although, because I kind of view it in the way I think John Peer Jay said that,
4289880	4294600	and if you think about it all of mathematics, it's just, it's semiotics and linguistics.
4295800	4301320	The thing though is it kind of does, it has to blow our minds as to how consistently it's worked.
4301320	4308760	I mean, at a pure pragmatic level, it is rather bizarre that there is this internal consistency
4308760	4314440	in mathematics. So I'm still unreasonable efficacy. Exactly. Yeah. Yeah. I mean, you can't
4315000	4320440	necessarily say that therefore that can be true in some fundamental metaphysical sense,
4320440	4329880	but it does make one wonder. Yeah. So back to the idea, you know, in the, in the paper,
4329880	4336280	I kind of want to also discuss in this paper, also you do. Oh, I think I'm, I made a mistake
4336280	4342520	there. I'm confusing papers. Do you, in this, in the math, it's not the territory. Do you discuss
4343480	4351240	the, the natural selection, like you kind of contrast or juxtapose the FEP with natural selection,
4351240	4354760	or could it be the other paper you wrote, which was more like an introduction to
4355800	4359720	the paper, the free-range principle and accessible introduction to its derivations,
4359720	4367240	implications and applications? I don't know. Good question. Yeah. Yeah. Because regardless,
4367240	4373240	what I, what I also liked was, and this probably connects to my previous, my initial question,
4373240	4380200	why a lot of philosophical interest in the FEP, it's just, yeah. So like the FEP, is it like,
4380200	4385800	is it like, is it like a meta narrative or like a meta theory, or it's called a super theory,
4385800	4394600	not a meta theory, a super theory, something like natural selection. Yeah, or like almost an intuition
4394600	4399160	pump? Yeah, I think I prefer that. Because you can't really, it doesn't really fall into the
4399160	4403800	Hopperian falsifiability and, you know, in that rigorous sense, right? I should say maybe in it,
4403800	4411480	that, that was sort of a, I'm sort of adapting the Dennett concept. That's, that's not exactly,
4412280	4418040	that's not how he uses it. But, but one could say it's an intuition pump in a stretch of that
4418040	4428680	terminology. I see. In that. It's, it's a kind of conceptual framework
4430760	4439800	that enables us to think about things very differently in science. But it's not actually,
4439800	4448920	it's not a method. It's not a formal model. It's not a theory or a hypothesis or a, you know,
4448920	4452200	there are all these sorts of concepts, there are all these conceptual tools in science and it's,
4453080	4458680	it's not any of the kind of lower order conceptual tools of science in the same way that natural
4458680	4464680	selection is not, I don't view it as a theory. Natural selection isn't a theory or a hypothesis
4464680	4473400	or a model or a, I mean, it's really sort of a meta conceptual framework, I would say.
4473400	4477480	Yeah. Yeah. Yeah. And I think in that sense, it's very far removed from the actual
4479080	4484920	day-to-day work of science. Of scientists. Yeah. Yeah. Experimental work, for instance. Yeah.
4484920	4492200	And I think in, you know, part 1.5, you essentially say, I propose here that we reserve the free
4492200	4500360	energy principle to denote only the maths of which the FEP is composed of models utilizing this
4500360	4506760	formalism to study natural systems, bear also an interpretation, lending a means of interpreting
4506760	4513800	the maths as about the systems in nature. So, I mean, that idea of, yeah, it's kind of a formalistic
4513800	4522040	conceptual structure. I like thinking of it that way. Excellent. So, okay, let's see.
4522200	4526040	In terms of time, yeah, we've got a few more. Is it okay if you go for about 10 more minutes?
4526040	4529320	Yeah, yeah, totally. All right. All right. Fantastic. Thanks. Thank you, Mel.
4529320	4533160	I kind of... I'm happy to chat again at some point if that's...
4533880	4539240	Yes. Yes. I mean, in fact... I just have to run at like, you know, I have to run in 15 minutes, but...
4539240	4543560	Yeah. Just 10 more minutes off your time, only because one thing I really try to do with this
4543560	4547560	podcast is, I don't want to say a bridge, but I try to bring into dialogue
4548280	4554440	a so-called continental philosophy and more of the analytic philosophy that kind of you work through.
4554440	4561960	I should say, I studied with Dennett in my undergraduate and it was forbidden to me to touch
4561960	4568360	continental philosophy. Yeah. You see, this is, you know, kiss and point. And I don't like that,
4568360	4571960	to be honest. I don't even like creating this demarcation, really. It's just philosophy. It's
4572200	4575160	thinking of a philosopher as a philosopher as far as I'm concerned.
4575160	4583720	See, he knew my mind and he knew what reading Foucault would have done to me and it was nothing good.
4584520	4589880	Yeah. There you go. You know, you start talking about the epistemes and all of that. Yeah. Yeah.
4589880	4596840	But what's fascinating is like, look at how much of, you know, fruitful, productive output you've had,
4597640	4605880	if I may, because you do take in the sociological aspects that Foucault, perhaps above all,
4605880	4613640	point out very carefully when it pertains to our knowledge and epistemology. But yeah,
4613640	4620600	on that note, let me just ask a very, very broad general question, Amel. As a philosopher of AI,
4620680	4627240	as a philosopher of science, what insights do you think us in the, let's say, Anglo-American,
4627240	4633080	you know, I'm in Australia. Are you Canadian or are you in the U.S.? U.S. Right. So yeah,
4633080	4640680	the Anglo-American kind of. Yeah, there you go. The more analytic, you know, oriented philosophy,
4641560	4648520	which, when I spoke to this philosopher called Simon Critchley, he said it's more for just a
4648600	4655800	historical phenomena. It's got, it has nothing to do with really with ideas per se. It was just,
4656440	4663800	you know, how things changed with the world, with World War II and how that, you know,
4663800	4668920	certain analytic philosophers, it's in political, it was more of a political phenomena, more than a
4668920	4676200	philosophical phenomena in history. But, you know, be that as it may, yeah, as a, as a philosopher of AI
4676200	4683240	and a philosopher of ML, what insights do you think we can gain from kind of discourse within
4684120	4687880	continental philosophy with thinkers all the way from thinkers like Heidegger
4688600	4694200	or to people like Zizek and to, you know, sociologists like Foucault?
4694920	4705000	Um, I don't delve into that work very much, but I know people who do and they,
4706920	4714120	I think, make very interesting work of it. Elmer Feiden is doing, is more,
4715320	4720840	he's a philosophy of AI, is more, is more, is more continentally influenced.
4721640	4726120	I haven't heard of that person. Fantastic. Okay, thanks for that.
4728520	4732040	Um, he will know other people.
4734600	4741880	Yeah, yeah. There's also some, I think, I mean, I think there's a way in which sort of STS scholarship
4741880	4752920	on technology, AI, ML is also more continentally leaning.
4754600	4760120	Well, this is a book that I've just started on called The Critical Theory and AI,
4761000	4770440	which I'm hoping to speak to, it's by Simon, Simon Lindegren. I just started on the books. I
4770440	4776200	can't really say much on it. It was just published last year. Yeah, we just put out this, this,
4778520	4785800	the pseudoscience paper. And a lot of the reviewers were suggesting some sort of like
4785800	4791400	critical theory. Oh, you mean the one that goes in the machine learning paper? Yeah, our reviewers
4791400	4796840	were suggesting some of that stuff. Fascinating. Yeah, yeah. I mean, yeah, which is like for me and,
4796840	4801880	you know, leaving aside the names, like just generally for you, as you pointed out, you know,
4801880	4808040	Dennett said, you know, no touching, Corneal Philosophers, but just, I'm curious, well,
4808040	4815560	why did you rebel against, I'm joking, of course, but your master's commands and kind of get interested
4815560	4820440	in, because I've seen through your Twitter feed, for instance, that you do, you do retweet stuff by
4821080	4828280	some Corneal Philosopher, by Zizek, or you do, you aren't totally a verse to it or a post to it.
4829240	4838920	Yeah, I mean, I think the divide is, sorry. I think, again, the divide is pretty superficial,
4839880	4844680	as you said. And I think,
4848600	4853480	as I said, like with everything, most of everything is, this is again,
4859160	4867160	a Dennettism, but 99% of everything is crap was his life. And I think that's true of both
4867160	4872840	analytic and continental philosophy. There's a dominant tradition. There are aspects of, like,
4872840	4879640	if we think of analytic philosophy and continental philosophy as methods, I think there are really
4881800	4887000	problematic features of both of those methodologies as methodologies for philosophy.
4887000	4892520	I think there are really sort of stultifying features of both of those methodologies. And
4893080	4901400	there's brilliant work. There's brilliant ideas coming out of both traditions. But in a way,
4902520	4908280	it's working against some of the kind of primary tendencies of those traditions, in a sense.
4911480	4917080	And so in my work, I'm just trying to say something
4917160	4925800	interesting that matters for the reality we live in. And I'm trying as much as possible not to be
4928680	4937240	operating within a particular conception of what good thought is. I mean, I think
4938120	4940920	I think thinking according to some
4943080	4951320	conception of what is the right way to think is not a right way to think. I think it
4953640	4958040	keeps us short of discovering truths.
4959000	4963160	So I try to not
4967240	4974440	adhere as much as possible to principles of particular genres of philosophy,
4974440	4979720	in so much as I can do that and still get published enough in philosophy venues to get a job.
4980840	4985240	That's a whole other conversation. Just on a side note, Mel, are you familiar with
4986200	4994200	the thinker, Bianchel Hahn? No. Yeah, so he wrote this book, Psychopolitics. Where is it?
4995320	5001960	He's quite big in Germany. He's a German philosopher. In fact, no, he's originally from
5001960	5009800	South Korea, but now he works in Germany. And I was, when I read your paper, in fact, when I read
5010760	5020440	the theory free ideal paper, and then also the recent one, the pseudoscience one,
5020440	5027480	he has one chapter in this book, Psychopolitics, on big data. And he wrote this in like the early
5027480	5035080	2000s. A lot of this, I'd love to, in fact, as you said, you'll be open to another conversation,
5035080	5041640	I'd love to kind of discuss. It's just like 15 pages, that chapter, that just his ideas on it,
5041640	5046760	because I think you'd be the perfect person to comment on it with your kind of analytic background
5048680	5054600	with the work you've done, because it really did remind me of his ideas when I read that,
5054600	5061480	when I read your work, in any case. But yeah, again, I want to be cognizant of your time. So
5061480	5067800	just one last question, Mel. What would you say, currently, I just like asking this,
5067800	5074440	because it kind of excites me as to what kind of work I should do. In this space of philosophy of
5074440	5082440	ML and philosophy of AI, apart from what we've discussed so far, what other avenues for research
5082440	5087720	do you think people should look into and take into consideration and start thinking about?
5088520	5095240	Oh, God, there are a million. I think there are a million avenues that are
5096360	5103240	pursued or could be pursued that I think are kind of fruitless. But there are a million avenues that
5103240	5114200	are really fascinating. So I mean, I think the way machine learning technologies are being adopted
5114200	5125960	and changing labor and changing the way these technologies are changing our relationship to
5129000	5135800	the sort of resource consumption to the means of production, to the output of labor, to the
5135800	5142840	output of intellectual labor, or epistemic labor, one might say, which are, I think,
5142840	5156920	much more subtle than we've given credit to so far. There's a problem of opacity or
5156920	5162200	explainability or what have you. I think it's clear that the sort of research avenues that
5162200	5172040	we've been on with that are deeply flawed, and the kind of technologies we've invented to tackle
5172040	5179880	those problems in so much as they are problems are deeply flawed. But figuring that out is usually
5179880	5193640	important. How these technologies are bringing about harms in the real world is a tremendous issue.
5193640	5203240	And tackling that in a way that is deeply cognizant of incentive structures.
5208680	5218440	And investing in interventions that those in the positions of power to create and deploy these
5218520	5226440	technologies would actually be incentivized to adopt and working on that incentivization.
5228600	5233880	So this requires a vastly interdisciplinary perspective. This requires having whatever
5233880	5242520	the domain of application is, if that's a hospital, if that is in biological science,
5242520	5249880	if that is in building cell phone applications, if that is it, whatever the application is,
5249880	5256440	having deep domain knowledge of that application, having knowledge of the regulatory structures
5256440	5263240	or lack thereof, having knowledge of the incentives of those who are creating these
5263240	5268120	technologies and deploying them, and having knowledge of the knowledge level of those
5268120	5271000	who are creating these technologies and deploying them, et cetera, et cetera, et cetera.
5271720	5279160	And so I think there's, it's like now is the time when we need to stop messing around and start
5279160	5284840	doing really, really good, really dialed in interdisciplinary work and supporting that,
5284840	5288520	because you cannot effectively
5292360	5300040	prevent or remediate the ill usage of these technologies from a single disciplinary background.
5300040	5305640	You need teams of people with expertise in a lot of different domains who know how to talk to each
5305640	5311560	other. Yeah, oh, that's for sure. Yeah. Yeah. So I think, sorry, I lied. That was the penultimate
5311560	5316760	question. This is the last question. And then I'll let you go, I promise, because you spoke about
5316760	5322200	kind of social harms. One other question I wanted to ask from you was, we spoke about
5322840	5331480	science fiction and kind of the dooms kind of mentality. But would you compare, would you
5331480	5337880	like, would you say the current paradigm of AI, the current technologies we have, that it can be
5337880	5343560	compared to something like the nuclear bomb in the nukes in the 20th century, or do you think
5343560	5349000	that's an exaggeration or I'm just being dramatic? Like we aren't there yet. It's not that grave.
5351080	5360120	Well, the impact of nuclear bombs, the impact of nuclear technology
5360360	5367720	was in one part the reality of this groundbreaking technology that made
5370680	5377800	killing and destruction possible at only levels. On another part, it was a psychological phenomenon.
5378760	5379240	It was
5382120	5393000	almost more radically a psychological shift, right? I think the thing with machine learning
5393000	5399880	technologies and any possible future development of these technologies, in fact, not just what we
5399960	5408920	have right now in front of us, is almost that level of psychological reaction to what these
5408920	5421640	technologies mean. But the disruptive force is not owing to a really radical scientific or technological
5421640	5428440	breakthrough. It's more the psychological and social time.
5433800	5440200	I mean, it has the potential to really radically disrupt labor markets, and it already is. But
5440200	5446520	that was something that was already happening. Workers were already being pushed out. I mean,
5446600	5450440	that was happening since the Industrial Revolution. Yeah, and that's capitalism. Yeah,
5450440	5456520	that's just capitalism. Yeah. It's just that now there's an even more, it's perpetually a more
5456520	5464280	and more urgent need to shift away from a mode of production in which if you don't work, you die.
5467160	5473560	The world in which if you do not labor, you starve to death, is not one that works in which
5473560	5480040	most people are being automated out of their jobs. Yeah, regardless of the technology. Yeah.
5483480	5488120	On that grim note, thank you very much for your time, Mel. I've thoroughly enjoyed,
5488840	5493880	I've learned a lot from you, but also just your Twitter feed is fantastic. I visited,
5493880	5499560	I frequent it often. I hate Twitter, I think it's a terrible place, but I go to like yours,
5499560	5504280	and I've got like five people bookmarked. I just visited their feeds. But yeah, thank you.
5504280	5507880	Thank you very much for your time, Mel. And I hope we can chat again soon.
5507880	5511160	Yeah, thanks, Lucas. Yeah, I'm happy to follow up. And send me the thing, the
5513800	5520440	Korean-German author. Yes, the one by Byung-Shul Han. Yeah, I'll send you, I've got a PDF,
5520440	5525000	I'll send you the PDF and all that, because I'd love to kind of, you know, follow up on that and
5525000	5530280	see what ideas you have. But yeah, thank you, Mel. Yeah, thanks.
