{"text": " Hey everyone, welcome to part two of item 13 in Joshua Block's effective Java, which states override clone judiciously. And if it's not obvious already, since item 13 is a pretty big item, I've broken it down into two parts. And if you've missed part one, I'll leave a link down below in the description for you to go check it out. Saying all that, let's get started without further ado. So as we continue on from part one, item 13, when it comes to cloning, we have to keep in mind that recursively calling the clone method may not be sufficient at all times. So in part one, we kind of covered how when the clone takes place between a class, when we create a new object or a clone of that class, we should recursively copy all the fields to properly clone the class when using a cloneable, although that might not always suffice. So firstly, let's take a look at a demo using a hash table, and indeed show a broken clone, which will give us a shared medieval state, especially a hash table is a good example, because at least a hash table we're going to use uses an array and an array that can happen quite often. So let's take a look at this class. Obviously, let me zoom in a bit. Hash table implements cloneable. This is a hash table we are designing. I'm not saying this is how a good hash table to start should look like. It's just a rough design we have just for the purpose of the demo. And this is where the carpet is. I wouldn't call it the carpet, but here's where the problem lies. It's this array, the buckets array that creates a shared a medieval state. So I'm going to skip over all the other implementations of a hash table, things like the constructor, or well, actually, I should probably mention this, there is a inner class called entry, the buckets array is of type entry, that's kind of important for the purpose of the hash table. But still, it's kind of out of scope to one for a demo here. But as I said, I'm going to skip over the puts, the gets, all of that, that's a part of the hash table mechanism. Although if you look at the clone method, now this is a broken clone method, because it results in a shared medieval state. And here's where the issue lies. When we do the clone, and we simply clone the buck across, so the buckets array, the elements in the buckets array are not copied, rather, they're shared between two hash table objects. And that can obviously create corrupt state, ergo, this clone method being broken. As Joshua Block states, though the clone has its own bucket array, this array references the same length lists as the original, which can easily cause non-deterministic behavior in both the clone and the original. Now this issue can be resolved using the concept of a deep copy, which we've covered in previous items, but essentially what a deep copy does is, well, as the name suggests, recursively goes through the array and copies each element into the new object. It does a deep copy. So I didn't mention before, when I was showing the broken clone method, that we have this inner class called entry. So in this inner class, we've defined a new method called a deep copy to do this deep copy, which, as I said, does the recursive copying. And then what can be done is, when the recursive copying is done using the deep copy method, the client, or other client, the outer class, can use this deep copy method in its clone method. So if you can see here, it does the cloning. And then in line number 90, it's doing a deep copy of the bucket's array. This ensures that all the elements are copied to ergo, not not just resulting in, I keep saying ergo, because I've been reading a lot of philosophy. Ergo is a Latin term, I should probably say, therefore, therefore not resulting in a non deterministic state or a shared mutable state. A deep copy will solve that problem. Although, although we've got a small issue here, you can probably see we're doing a recursive copy here. And I'm going to admit, I find it a bit hard to get this concept that Joshua Bloch has outlined in the book. But he states, when it comes to recursive copying, while this technique is cute and works fine, if the buckets aren't too long, so he's referring to the buckets array, it is not a good way to clone a linkless because it consumes one stack frame for each element in the list. If the list is long, this could easily cause a stack overflow error. So the problem is that it every time the deep copy takes place, it for per per element, it creates a new stack frame. And that can obviously not a memory leak, but it can cause a stack overflow error, because this happens runtime. Now, I found this good article on a digital ocean, which kind of explains the difference between the heap and the stack. We had a we had there's one item I forget which one way we covered quite deeply Java, Java, memory management, garage collection, allocation, all of that. But but I had to put this in charge of PD to get a bit more, let's say, elaborated definition. And here's what charge of PD states, pertaining to this point that Joshua Bloch makes to choose. Oh, I didn't mention that he says, because recursion can cause this stack overflow error, it's better choosing iteration over recursion. And here's why. And I'm quoting charge of PD verbatim here. Using iteration instead of recursion helps prevent a stack overflow error by avoiding excessive stack frame allocation. When a method is invoked recursively, each recursive call creates a new stack frame, as he stated, which consumes additional memory on a call on the call stack. If the recursion goes too deep, or if the data structure being processed is large, it can result in the stack running out of memory, causing a stack overflow error. So we need a mechanism or an algorithm that doesn't create a new stack frame every time an element is created in the data structure. And that's where iteration can be much more handy. So let's take a look at how the iteration method works. Let's comment out the deep copy. And take a look at the deep copy that uses iteration. So in iteration, because we're not calling the deep copy method within the function, it's not happening recursively, it doesn't require a new frame on the call stack every single time the loop runs. And therefore, for larger data structures or large array, using iteration probably is a bad idea. Overusing recursion, even though, obviously, as you can see here, the recursive method is much simpler. And it kind of makes a lot more sense compared to this where you got p.next and your parsing generics and whatnot can be a bit more complicated. So depending on the use case, you can use whatever method or we can implement the method however may you think it'll suffice or it'll be apt. Okay, saying all that, let's move to the wrong side. Saying all that, let's move to the next point, which is how in cloning, how we can utilize the super dot clone method in your class. So you can use the clone method in your superclass. Firstly, here's what Joshua book states, a final approach to cloning complex mutable objects is to clone this to call super dot clone, set all the fields in the resulting object to their initial state, and then call high level methods to regenerate the state of the original object. So at first glance, this looks quite straightforward, because all we're doing here is we're creating a new instance of hash table clone table object, and we're setting it to its as special book states initial state, and then simply invoking the clone method of the super class, which in this case would be the object class, and repopulating this new object with whatever the super dot clone method or superclass, superclasses clone method returns. But but here we have an issue. And the issue is that this type of cloning, because we're doing a deep copy, especially with the buckets array, it doesn't abide by the the clonable architecture contract, because we're implementing the clonable interface here, which is a contract that the class is supposed to follow. But by doing it this way, by doing the deep copy, it is taking place without a field by field copy of the object. And that is anatomical to the clonable architecture. I just realized as I was rereading this, sorry, I wrote this script for this a while back, that I made a mistake here. In fact, this is correct. The problem would have been if we did a shallow copy, similar to what I've coded here, without doing a deep copy, which which is a part of the field by field copy, that's a part of the architecture. I mean, this is correct, because even though we're invoking super dot clone, and copying the state into the new object, and then create creating the buckets array, we're still doing a field by field copy. So I should probably really rewrite this into saying deep copy taking place with a field by field copy of the object. Now this is correct, as it should be, because because a clone method should act very much like a constructor in a class. And that's the point Joshua Block makes the I'm so sorry for the misunderstanding that even I got confused, but I realized I was written that in the wrong way. And this is correct, we need a deep copy to take place in the clone method. And it can happen, even when invoking the super dot clone method just to clarify. It's a bad mistake. Okay, so here's what Joshua Block states, pertaining to the clone method and how it should behave. Like a constructor, a clone method must never invoke an overriding method on the clone under construction. If okay, so that is this can be a problem because of that. Because in the clone method, we are invoking another overriding method. Now this can be an issue. So the issue isn't with the deep copy, the issue really is with line number 65, just to clarify. If clone invokes a method that is overridden in a subclass, this method will execute before the subclass has had a chance to fix its state in the clone, quite possibly leading to corruption in the clone and the original. So what does that mean? If clone invokes a method that is overridden in a subclass, this method will execute before the subclass has had a chance to fix its state in the clone. An example of that could potentially be this. We have this put method, which is extended from hash table. But because it's public, it can be overridden. Now let's say in the subclass, an extended hash table, we define another clone method, which should be allowed to be overridden. But we've overridden the put method too. And what that will do is it'll increase the size by an additional one. For instance, let's say we're in the super dark put, we're doing the key and value. And then in the array, where we're changing it, I haven't implemented that bit, but let's say the put changes it where the array will also increase the size. This put will also increase the size by one. And then what will happen is in the clone method, it'll create an inconsistent state because this put, which should have been either private or final, has been invoked again in the subclass's clone method, which you will see here in line number 22. So roughly, this is what the block means. Obviously, I haven't implemented the whole code, but the idea being in the clone method, we shouldn't be invoking methods of the superclass that can create corrupt state or non-deterministic behavior between objects. Okay, now let's discuss the objects clone method. And sorry about the background noise, it just started raining. When it comes to the objects clone method, so when I mean object, I mean the superclass and Java of all other classes, the Java object class, Drusher book states this, objects clone method is declared to throw clone not support exception, but overriding methods need not public clone methods should admit the throws close as methods that don't throw check exceptions are easy to use. So here's how the objects clone method is defined, which throws a clone not support exception. And then if you have this class here, which overrides this code method from the object class, as for the contract of the colonial architecture, it's a contract that the JVM makes, or it's a contract with the JVM, that the clone will take place properly. Therefore, this bit isn't required. So we can get rid of it really. But it's not that simple. Drusher book states that there are two ways to do this when designing a class of inheritance. Firstly, on what you should not do. If you have a superclass that is designed for being inherited, this shouldn't happen. We shouldn't implement cloneable, because then it'll create corrupt state. As you can see, this resource area here would be shared between these two objects creating a medieval not available state, sorry, corrupt state. But given that though, we can still have a clone method in a class designed for inheritance without implementing cloneable. There are two choices that just show gives us the first one is implement a properly functioning clone method mimicking that in the object class. So not a clone method like this, this is wrong. We should mimic what's being done in the object class, despite not implementing the cloneable architecture, or prevent the subclasses from implementing a clone method completely by making the clone method protected final. And then that can't be any overriding taking place. Okay, a small caveat. The caveat is what to do when writing, not a caveat really, but more of an axillary point, what to do when writing a class for threat safety for an object to work with multiple threads. So firstly, the objects clone method is not synchronized. Therefore, it is not thread safe. So we have to keep that in mind when writing a class. And let's take a look at a demo as to how we can potentially write a thread safe class. And again, this code isn't complete, they can certainly improve it's simply a blueprint on writing a thread safe class. Really like, that was a mistake, like writing other threads, thread safe, thread safe classes, what we can do is define the fields as being synchronized. So now it's atomic. And then in that class, so have a class called safe kind of which implements cloneable, this class here is not thread safe. And we can make it thread safe by giving it the synchronized keyword, which will make this clone is synchronized. And in that in that way, two objects won't be able to invoke this method at the same time. Sorry, not two objects, two threads will not be able to invoke this method at the same time. So to recap, what we've discussed in both part one and part two of item 13, Joshua book states, to recap, as I said, all classes that implement cloneable should override clone with a public method whose return type is the class itself. This method should first call super dark clone, as we went through a bit before, then fix any fields that need fixing. Typically, this means copying any mutable objects that compromise internal deep structure of the object and replacing the clone's references to these objects with references to their copies. So that's kind of what we discussed before in using either recursion or iteration by doing a deep copy. And then just another point he makes, if the class contains only primitive fields or references to mutable objects, then it is likely the case that no fields need to be fixed. So then he asks, is all this complexity really necessary when designing a clone method, or when overriding the clone method of the object class? When he means all this complexity, we're talking about what we discussed in part one and now in part two. So a better approach is using a technique called a copy constructor or a copy factory method. But before we get to that, before we look at the demos, I'll read out what he said. In regards to the complexity, he said, really, it's not needed. If you extend a class that already implements cloneable, you have a little choice but to implement a well-behaved clone method. That's the advantage of using an interface like cloneable, which kind of forces us to abide by the contract. Otherwise, if we don't use cloneable, you're usually better off providing an alternative means of object copying. Here's where we get to what I said before. A better approach to object copying is to provide a copy constructor or copy factory. A copy constructor is simply a constructor that takes a single argument whose type is the class containing the constructor, for example. Now, this was really interesting. I don't think I've actually worked with a copy constructor before. So I found this part quite interesting, despite it coming towards the end of the item to kind of finalize and conclude on what he was trying to outline in this item. So firstly, again, this is what the implementation or the signature of a copy constructor would look like and then the copy factory. Similar kind of signature, but obviously the way it's implemented is different. So the right, in fact, many advantages to using a copy constructor over a clone method. Firstly, something that I think I touched on in part one, a clone method can be extra linguistic. And what I mean by that is that generally a good rule of thumb in Java or OOP programming is only a constructor should create a new method. Sorry, one of my sign. Only a constructor should create a new object. But obviously the clone method creates a new object, making it extra linguistic. And since it is doing it in a kind of a unforeseeable adherence to purely documented conventions, it's doing it in a way that's not conventional to how an object would be created. It can create issues. And the documentation isn't that good. At least that's where Joshua Block states. Now with the copy construct, the constructor, it is in fact creating a new object. You create a new object. So when the copy construct is being implemented, you probably see here, we pass a new object into the copy constructor, and it's that that that does the copying to the new object from the current object. So the construct or the constructor itself in this case, doesn't do any work of creating new objects and whatnot. All it's doing is taking in the past object and then doing the copy. And the other advantage of using a copy constructor would be that when it comes to final classes or immutable classes, if you have this immutable point class, so the first class I was showing you was point, but now we have another variant of it that is immutable. We've used the final keyword. When using the clone method, there can be issues when copying across final fields. Now this again wouldn't happen with the copy constructor because again, we're creating a new object outside the constructor and passing it into the method and then doing the copy. And another advantage is that a copy constructor doesn't require casting because what we're doing is, as I said a couple of times already, the new object we create is already of type whatever the class is, and that's what we pass into the copy constructor. So if you use a clone method, for instance, you need to do this kind of casting, which can be a bit of a pain. Oh, and as I said before, the copy constructor doesn't have the issue with throwing unnecessary checked exceptions and whatnot, which is again a part of the clone architecture. So this is an example. I was showing you the copy constructor and I'm going through this code quite, quite quickly today. I'm sorry about that. I'm in a bit of a hurry. But obviously, all of it will be available on GitHub. You could go take a look at it and go through it carefully. Here we have an example of how the copy factory would work. It's quite similar to, it's just a static factory method. So it's similar to the copy constructor. It still does the copying and returns a new point by doing the copy fields in the new object. Another advantage is that a copy constructor factory allows you to take in an argument as a type, as type argument, when implementing the method or when using the method as a client, you can pass in the type and that will return you an object of that type. So an example that just should look as highlighted is between hash and entry sets of assume you have hash set defined like this of type string and you have an hash set. And then if you want to, so hash, hash set S. And if you want to copy that across to, let's say a tree set, simply all we got to do is to go new instance of tree set and then pass in that object with the type tree set and let it do the conversion automatically. And this is allowed as to how the copy constructors implemented in hash set. So this won't be possible with the clone object. Oh, sorry, with the clone method. I'm gonna get a bit tired clearly. Alrighty, that's it. That was part two. I hope all of that makes sense. If I wasn't clear on certain parts, I apologize. I wrote the script a while back and I got really busy so I couldn't record the video. But all the codes available on GitHub and I've kind of commented what I've done so that it kind of makes sense, despite some of it not being complete code rather being blueprints. But to conclude, Joshua Block states, given all the problems associated with cloneable new interfaces should not extend it and new extendable classes should not implement it. While it's less harmful for final classes to implement cloneable, this should be viewed as a performance optimization reserved for the rare cases where it is justified. As a rule, copy functionality is best provided by constructors or factories, which we saw with the copy constructing the copy factory and all the advantages they have for us. A notable exception to this rule is areas which are best copied with the clone method. Alrighty, that was item 13 and I hope you found that useful and I'll see you in the next one, item 14, which is consider implementing comparable. Cheers.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 7.44, "text": " Hey everyone, welcome to part two of item 13 in Joshua Block's effective Java, which states", "tokens": [50364, 1911, 1518, 11, 2928, 281, 644, 732, 295, 3174, 3705, 294, 24005, 17500, 311, 4942, 10745, 11, 597, 4368, 50736], "temperature": 0.0, "avg_logprob": -0.13858823274311266, "compression_ratio": 1.5186721991701244, "no_speech_prob": 0.06428767740726471}, {"id": 1, "seek": 0, "start": 7.44, "end": 15.36, "text": " override clone judiciously. And if it's not obvious already, since item 13 is a pretty big item,", "tokens": [50736, 42321, 26506, 3747, 3784, 356, 13, 400, 498, 309, 311, 406, 6322, 1217, 11, 1670, 3174, 3705, 307, 257, 1238, 955, 3174, 11, 51132], "temperature": 0.0, "avg_logprob": -0.13858823274311266, "compression_ratio": 1.5186721991701244, "no_speech_prob": 0.06428767740726471}, {"id": 2, "seek": 0, "start": 15.36, "end": 20.72, "text": " I've broken it down into two parts. And if you've missed part one, I'll leave a link down", "tokens": [51132, 286, 600, 5463, 309, 760, 666, 732, 3166, 13, 400, 498, 291, 600, 6721, 644, 472, 11, 286, 603, 1856, 257, 2113, 760, 51400], "temperature": 0.0, "avg_logprob": -0.13858823274311266, "compression_ratio": 1.5186721991701244, "no_speech_prob": 0.06428767740726471}, {"id": 3, "seek": 0, "start": 20.72, "end": 25.44, "text": " below in the description for you to go check it out. Saying all that, let's get started", "tokens": [51400, 2507, 294, 264, 3855, 337, 291, 281, 352, 1520, 309, 484, 13, 34087, 439, 300, 11, 718, 311, 483, 1409, 51636], "temperature": 0.0, "avg_logprob": -0.13858823274311266, "compression_ratio": 1.5186721991701244, "no_speech_prob": 0.06428767740726471}, {"id": 4, "seek": 2544, "start": 25.44, "end": 32.88, "text": " without further ado. So as we continue on from part one, item 13, when it comes to cloning,", "tokens": [50364, 1553, 3052, 22450, 13, 407, 382, 321, 2354, 322, 490, 644, 472, 11, 3174, 3705, 11, 562, 309, 1487, 281, 596, 16638, 11, 50736], "temperature": 0.0, "avg_logprob": -0.11034012855367457, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.3658689260482788}, {"id": 5, "seek": 2544, "start": 33.44, "end": 39.52, "text": " we have to keep in mind that recursively calling the clone method may not be sufficient at all", "tokens": [50764, 321, 362, 281, 1066, 294, 1575, 300, 20560, 3413, 5141, 264, 26506, 3170, 815, 406, 312, 11563, 412, 439, 51068], "temperature": 0.0, "avg_logprob": -0.11034012855367457, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.3658689260482788}, {"id": 6, "seek": 2544, "start": 39.52, "end": 46.8, "text": " times. So in part one, we kind of covered how when the clone takes place between a class,", "tokens": [51068, 1413, 13, 407, 294, 644, 472, 11, 321, 733, 295, 5343, 577, 562, 264, 26506, 2516, 1081, 1296, 257, 1508, 11, 51432], "temperature": 0.0, "avg_logprob": -0.11034012855367457, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.3658689260482788}, {"id": 7, "seek": 2544, "start": 46.8, "end": 54.64, "text": " when we create a new object or a clone of that class, we should recursively copy all the fields", "tokens": [51432, 562, 321, 1884, 257, 777, 2657, 420, 257, 26506, 295, 300, 1508, 11, 321, 820, 20560, 3413, 5055, 439, 264, 7909, 51824], "temperature": 0.0, "avg_logprob": -0.11034012855367457, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.3658689260482788}, {"id": 8, "seek": 5464, "start": 54.64, "end": 64.08, "text": " to properly clone the class when using a cloneable, although that might not always suffice. So", "tokens": [50364, 281, 6108, 26506, 264, 1508, 562, 1228, 257, 26506, 712, 11, 4878, 300, 1062, 406, 1009, 3889, 573, 13, 407, 50836], "temperature": 0.0, "avg_logprob": -0.13790573793299057, "compression_ratio": 1.5083798882681565, "no_speech_prob": 0.0025106079410761595}, {"id": 9, "seek": 5464, "start": 65.36, "end": 73.92, "text": " firstly, let's take a look at a demo using a hash table, and indeed show a broken clone,", "tokens": [50900, 27376, 11, 718, 311, 747, 257, 574, 412, 257, 10723, 1228, 257, 22019, 3199, 11, 293, 6451, 855, 257, 5463, 26506, 11, 51328], "temperature": 0.0, "avg_logprob": -0.13790573793299057, "compression_ratio": 1.5083798882681565, "no_speech_prob": 0.0025106079410761595}, {"id": 10, "seek": 5464, "start": 73.92, "end": 78.96000000000001, "text": " which will give us a shared medieval state, especially a hash table is a good example,", "tokens": [51328, 597, 486, 976, 505, 257, 5507, 24078, 1785, 11, 2318, 257, 22019, 3199, 307, 257, 665, 1365, 11, 51580], "temperature": 0.0, "avg_logprob": -0.13790573793299057, "compression_ratio": 1.5083798882681565, "no_speech_prob": 0.0025106079410761595}, {"id": 11, "seek": 7896, "start": 78.96, "end": 85.19999999999999, "text": " because at least a hash table we're going to use uses an array and an array that can happen", "tokens": [50364, 570, 412, 1935, 257, 22019, 3199, 321, 434, 516, 281, 764, 4960, 364, 10225, 293, 364, 10225, 300, 393, 1051, 50676], "temperature": 0.0, "avg_logprob": -0.15481917732640316, "compression_ratio": 1.6244343891402715, "no_speech_prob": 0.012818634510040283}, {"id": 12, "seek": 7896, "start": 85.83999999999999, "end": 91.75999999999999, "text": " quite often. So let's take a look at this class. Obviously, let me zoom in a bit.", "tokens": [50708, 1596, 2049, 13, 407, 718, 311, 747, 257, 574, 412, 341, 1508, 13, 7580, 11, 718, 385, 8863, 294, 257, 857, 13, 51004], "temperature": 0.0, "avg_logprob": -0.15481917732640316, "compression_ratio": 1.6244343891402715, "no_speech_prob": 0.012818634510040283}, {"id": 13, "seek": 7896, "start": 94.08, "end": 100.56, "text": " Hash table implements cloneable. This is a hash table we are designing. I'm not saying this is how", "tokens": [51120, 30775, 3199, 704, 17988, 26506, 712, 13, 639, 307, 257, 22019, 3199, 321, 366, 14685, 13, 286, 478, 406, 1566, 341, 307, 577, 51444], "temperature": 0.0, "avg_logprob": -0.15481917732640316, "compression_ratio": 1.6244343891402715, "no_speech_prob": 0.012818634510040283}, {"id": 14, "seek": 7896, "start": 101.75999999999999, "end": 106.63999999999999, "text": " a good hash table to start should look like. It's just a rough design we have just for", "tokens": [51504, 257, 665, 22019, 3199, 281, 722, 820, 574, 411, 13, 467, 311, 445, 257, 5903, 1715, 321, 362, 445, 337, 51748], "temperature": 0.0, "avg_logprob": -0.15481917732640316, "compression_ratio": 1.6244343891402715, "no_speech_prob": 0.012818634510040283}, {"id": 15, "seek": 10664, "start": 107.28, "end": 112.08, "text": " the purpose of the demo. And this is where the carpet is. I wouldn't call it the carpet,", "tokens": [50396, 264, 4334, 295, 264, 10723, 13, 400, 341, 307, 689, 264, 18119, 307, 13, 286, 2759, 380, 818, 309, 264, 18119, 11, 50636], "temperature": 0.0, "avg_logprob": -0.13641562378197386, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.00572937959805131}, {"id": 16, "seek": 10664, "start": 112.08, "end": 118.96000000000001, "text": " but here's where the problem lies. It's this array, the buckets array that creates a shared", "tokens": [50636, 457, 510, 311, 689, 264, 1154, 9134, 13, 467, 311, 341, 10225, 11, 264, 32191, 10225, 300, 7829, 257, 5507, 50980], "temperature": 0.0, "avg_logprob": -0.13641562378197386, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.00572937959805131}, {"id": 17, "seek": 10664, "start": 120.0, "end": 124.16, "text": " a medieval state. So I'm going to skip over all the other implementations of a hash table,", "tokens": [51032, 257, 24078, 1785, 13, 407, 286, 478, 516, 281, 10023, 670, 439, 264, 661, 4445, 763, 295, 257, 22019, 3199, 11, 51240], "temperature": 0.0, "avg_logprob": -0.13641562378197386, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.00572937959805131}, {"id": 18, "seek": 10664, "start": 124.16, "end": 128.32, "text": " things like the constructor, or well, actually, I should probably mention this, there is a", "tokens": [51240, 721, 411, 264, 47479, 11, 420, 731, 11, 767, 11, 286, 820, 1391, 2152, 341, 11, 456, 307, 257, 51448], "temperature": 0.0, "avg_logprob": -0.13641562378197386, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.00572937959805131}, {"id": 19, "seek": 10664, "start": 128.32, "end": 135.2, "text": " inner class called entry, the buckets array is of type entry, that's kind of important for the", "tokens": [51448, 7284, 1508, 1219, 8729, 11, 264, 32191, 10225, 307, 295, 2010, 8729, 11, 300, 311, 733, 295, 1021, 337, 264, 51792], "temperature": 0.0, "avg_logprob": -0.13641562378197386, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.00572937959805131}, {"id": 20, "seek": 13520, "start": 135.2, "end": 139.67999999999998, "text": " purpose of the hash table. But still, it's kind of out of scope to one for a demo here.", "tokens": [50364, 4334, 295, 264, 22019, 3199, 13, 583, 920, 11, 309, 311, 733, 295, 484, 295, 11923, 281, 472, 337, 257, 10723, 510, 13, 50588], "temperature": 0.0, "avg_logprob": -0.14346499345740493, "compression_ratio": 1.634703196347032, "no_speech_prob": 0.002322945510968566}, {"id": 21, "seek": 13520, "start": 140.48, "end": 144.56, "text": " But as I said, I'm going to skip over the puts, the gets, all of that, that's a part of the", "tokens": [50628, 583, 382, 286, 848, 11, 286, 478, 516, 281, 10023, 670, 264, 8137, 11, 264, 2170, 11, 439, 295, 300, 11, 300, 311, 257, 644, 295, 264, 50832], "temperature": 0.0, "avg_logprob": -0.14346499345740493, "compression_ratio": 1.634703196347032, "no_speech_prob": 0.002322945510968566}, {"id": 22, "seek": 13520, "start": 144.56, "end": 152.0, "text": " hash table mechanism. Although if you look at the clone method, now this is a broken clone method,", "tokens": [50832, 22019, 3199, 7513, 13, 5780, 498, 291, 574, 412, 264, 26506, 3170, 11, 586, 341, 307, 257, 5463, 26506, 3170, 11, 51204], "temperature": 0.0, "avg_logprob": -0.14346499345740493, "compression_ratio": 1.634703196347032, "no_speech_prob": 0.002322945510968566}, {"id": 23, "seek": 13520, "start": 152.0, "end": 156.88, "text": " because it results in a shared medieval state. And here's where the issue lies.", "tokens": [51204, 570, 309, 3542, 294, 257, 5507, 24078, 1785, 13, 400, 510, 311, 689, 264, 2734, 9134, 13, 51448], "temperature": 0.0, "avg_logprob": -0.14346499345740493, "compression_ratio": 1.634703196347032, "no_speech_prob": 0.002322945510968566}, {"id": 24, "seek": 15688, "start": 157.2, "end": 165.2, "text": " When we do the clone, and we simply clone the buck across, so the buckets array,", "tokens": [50380, 1133, 321, 360, 264, 26506, 11, 293, 321, 2935, 26506, 264, 14894, 2108, 11, 370, 264, 32191, 10225, 11, 50780], "temperature": 0.0, "avg_logprob": -0.19260858354114352, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.015905026346445084}, {"id": 25, "seek": 15688, "start": 165.2, "end": 170.72, "text": " the elements in the buckets array are not copied, rather, they're shared between two", "tokens": [50780, 264, 4959, 294, 264, 32191, 10225, 366, 406, 25365, 11, 2831, 11, 436, 434, 5507, 1296, 732, 51056], "temperature": 0.0, "avg_logprob": -0.19260858354114352, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.015905026346445084}, {"id": 26, "seek": 15688, "start": 170.72, "end": 177.84, "text": " hash table objects. And that can obviously create corrupt state, ergo, this clone method being", "tokens": [51056, 22019, 3199, 6565, 13, 400, 300, 393, 2745, 1884, 17366, 1785, 11, 1189, 1571, 11, 341, 26506, 3170, 885, 51412], "temperature": 0.0, "avg_logprob": -0.19260858354114352, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.015905026346445084}, {"id": 27, "seek": 15688, "start": 177.84, "end": 185.2, "text": " broken. As Joshua Block states, though the clone has its own bucket array, this array references", "tokens": [51412, 5463, 13, 1018, 24005, 17500, 4368, 11, 1673, 264, 26506, 575, 1080, 1065, 13058, 10225, 11, 341, 10225, 15400, 51780], "temperature": 0.0, "avg_logprob": -0.19260858354114352, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.015905026346445084}, {"id": 28, "seek": 18520, "start": 185.2, "end": 192.72, "text": " the same length lists as the original, which can easily cause non-deterministic behavior", "tokens": [50364, 264, 912, 4641, 14511, 382, 264, 3380, 11, 597, 393, 3612, 3082, 2107, 12, 49136, 259, 3142, 5223, 50740], "temperature": 0.0, "avg_logprob": -0.11405531565348308, "compression_ratio": 1.6591928251121075, "no_speech_prob": 0.0035378369502723217}, {"id": 29, "seek": 18520, "start": 193.35999999999999, "end": 199.28, "text": " in both the clone and the original. Now this issue can be resolved using the concept of a", "tokens": [50772, 294, 1293, 264, 26506, 293, 264, 3380, 13, 823, 341, 2734, 393, 312, 20772, 1228, 264, 3410, 295, 257, 51068], "temperature": 0.0, "avg_logprob": -0.11405531565348308, "compression_ratio": 1.6591928251121075, "no_speech_prob": 0.0035378369502723217}, {"id": 30, "seek": 18520, "start": 199.28, "end": 205.83999999999997, "text": " deep copy, which we've covered in previous items, but essentially what a deep copy does is, well,", "tokens": [51068, 2452, 5055, 11, 597, 321, 600, 5343, 294, 3894, 4754, 11, 457, 4476, 437, 257, 2452, 5055, 775, 307, 11, 731, 11, 51396], "temperature": 0.0, "avg_logprob": -0.11405531565348308, "compression_ratio": 1.6591928251121075, "no_speech_prob": 0.0035378369502723217}, {"id": 31, "seek": 18520, "start": 205.83999999999997, "end": 212.48, "text": " as the name suggests, recursively goes through the array and copies each element into the new", "tokens": [51396, 382, 264, 1315, 13409, 11, 20560, 3413, 1709, 807, 264, 10225, 293, 14341, 1184, 4478, 666, 264, 777, 51728], "temperature": 0.0, "avg_logprob": -0.11405531565348308, "compression_ratio": 1.6591928251121075, "no_speech_prob": 0.0035378369502723217}, {"id": 32, "seek": 21248, "start": 212.48, "end": 217.28, "text": " object. It does a deep copy. So I didn't mention before, when I was showing the broken clone method,", "tokens": [50364, 2657, 13, 467, 775, 257, 2452, 5055, 13, 407, 286, 994, 380, 2152, 949, 11, 562, 286, 390, 4099, 264, 5463, 26506, 3170, 11, 50604], "temperature": 0.0, "avg_logprob": -0.10477382357757871, "compression_ratio": 1.8428571428571427, "no_speech_prob": 0.017439143732190132}, {"id": 33, "seek": 21248, "start": 217.84, "end": 224.56, "text": " that we have this inner class called entry. So in this inner class, we've defined a new method", "tokens": [50632, 300, 321, 362, 341, 7284, 1508, 1219, 8729, 13, 407, 294, 341, 7284, 1508, 11, 321, 600, 7642, 257, 777, 3170, 50968], "temperature": 0.0, "avg_logprob": -0.10477382357757871, "compression_ratio": 1.8428571428571427, "no_speech_prob": 0.017439143732190132}, {"id": 34, "seek": 21248, "start": 224.56, "end": 230.39999999999998, "text": " called a deep copy to do this deep copy, which, as I said, does the recursive copying. And then", "tokens": [50968, 1219, 257, 2452, 5055, 281, 360, 341, 2452, 5055, 11, 597, 11, 382, 286, 848, 11, 775, 264, 20560, 488, 27976, 13, 400, 550, 51260], "temperature": 0.0, "avg_logprob": -0.10477382357757871, "compression_ratio": 1.8428571428571427, "no_speech_prob": 0.017439143732190132}, {"id": 35, "seek": 21248, "start": 230.39999999999998, "end": 236.95999999999998, "text": " what can be done is, when the recursive copying is done using the deep copy method, the client,", "tokens": [51260, 437, 393, 312, 1096, 307, 11, 562, 264, 20560, 488, 27976, 307, 1096, 1228, 264, 2452, 5055, 3170, 11, 264, 6423, 11, 51588], "temperature": 0.0, "avg_logprob": -0.10477382357757871, "compression_ratio": 1.8428571428571427, "no_speech_prob": 0.017439143732190132}, {"id": 36, "seek": 23696, "start": 237.44, "end": 246.56, "text": " or other client, the outer class, can use this deep copy method in its clone method. So if you", "tokens": [50388, 420, 661, 6423, 11, 264, 10847, 1508, 11, 393, 764, 341, 2452, 5055, 3170, 294, 1080, 26506, 3170, 13, 407, 498, 291, 50844], "temperature": 0.0, "avg_logprob": -0.13056077406956598, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.01854274794459343}, {"id": 37, "seek": 23696, "start": 246.56, "end": 252.48000000000002, "text": " can see here, it does the cloning. And then in line number 90, it's doing a deep copy of the", "tokens": [50844, 393, 536, 510, 11, 309, 775, 264, 596, 16638, 13, 400, 550, 294, 1622, 1230, 4289, 11, 309, 311, 884, 257, 2452, 5055, 295, 264, 51140], "temperature": 0.0, "avg_logprob": -0.13056077406956598, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.01854274794459343}, {"id": 38, "seek": 23696, "start": 252.48000000000002, "end": 260.08, "text": " bucket's array. This ensures that all the elements are copied to ergo, not not just resulting in,", "tokens": [51140, 13058, 311, 10225, 13, 639, 28111, 300, 439, 264, 4959, 366, 25365, 281, 1189, 1571, 11, 406, 406, 445, 16505, 294, 11, 51520], "temperature": 0.0, "avg_logprob": -0.13056077406956598, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.01854274794459343}, {"id": 39, "seek": 23696, "start": 260.08, "end": 265.36, "text": " I keep saying ergo, because I've been reading a lot of philosophy. Ergo is a Latin term, I should", "tokens": [51520, 286, 1066, 1566, 1189, 1571, 11, 570, 286, 600, 668, 3760, 257, 688, 295, 10675, 13, 3300, 1571, 307, 257, 10803, 1433, 11, 286, 820, 51784], "temperature": 0.0, "avg_logprob": -0.13056077406956598, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.01854274794459343}, {"id": 40, "seek": 26536, "start": 265.36, "end": 272.16, "text": " probably say, therefore, therefore not resulting in a non deterministic state or a shared mutable", "tokens": [50364, 1391, 584, 11, 4412, 11, 4412, 406, 16505, 294, 257, 2107, 15957, 3142, 1785, 420, 257, 5507, 5839, 712, 50704], "temperature": 0.0, "avg_logprob": -0.1447267434031693, "compression_ratio": 1.606694560669456, "no_speech_prob": 0.013424585573375225}, {"id": 41, "seek": 26536, "start": 272.16, "end": 276.8, "text": " state. A deep copy will solve that problem. Although, although we've got a small issue here,", "tokens": [50704, 1785, 13, 316, 2452, 5055, 486, 5039, 300, 1154, 13, 5780, 11, 4878, 321, 600, 658, 257, 1359, 2734, 510, 11, 50936], "temperature": 0.0, "avg_logprob": -0.1447267434031693, "compression_ratio": 1.606694560669456, "no_speech_prob": 0.013424585573375225}, {"id": 42, "seek": 26536, "start": 277.44, "end": 284.40000000000003, "text": " you can probably see we're doing a recursive copy here. And I'm going to admit, I find it a bit", "tokens": [50968, 291, 393, 1391, 536, 321, 434, 884, 257, 20560, 488, 5055, 510, 13, 400, 286, 478, 516, 281, 9796, 11, 286, 915, 309, 257, 857, 51316], "temperature": 0.0, "avg_logprob": -0.1447267434031693, "compression_ratio": 1.606694560669456, "no_speech_prob": 0.013424585573375225}, {"id": 43, "seek": 26536, "start": 284.40000000000003, "end": 292.24, "text": " hard to get this concept that Joshua Bloch has outlined in the book. But he states, when it comes", "tokens": [51316, 1152, 281, 483, 341, 3410, 300, 24005, 9865, 339, 575, 27412, 294, 264, 1446, 13, 583, 415, 4368, 11, 562, 309, 1487, 51708], "temperature": 0.0, "avg_logprob": -0.1447267434031693, "compression_ratio": 1.606694560669456, "no_speech_prob": 0.013424585573375225}, {"id": 44, "seek": 29224, "start": 292.24, "end": 299.92, "text": " to recursive copying, while this technique is cute and works fine, if the buckets aren't too long,", "tokens": [50364, 281, 20560, 488, 27976, 11, 1339, 341, 6532, 307, 4052, 293, 1985, 2489, 11, 498, 264, 32191, 3212, 380, 886, 938, 11, 50748], "temperature": 0.0, "avg_logprob": -0.09290842758981806, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.013845742680132389}, {"id": 45, "seek": 29224, "start": 299.92, "end": 306.56, "text": " so he's referring to the buckets array, it is not a good way to clone a linkless because it consumes", "tokens": [50748, 370, 415, 311, 13761, 281, 264, 32191, 10225, 11, 309, 307, 406, 257, 665, 636, 281, 26506, 257, 2113, 1832, 570, 309, 48823, 51080], "temperature": 0.0, "avg_logprob": -0.09290842758981806, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.013845742680132389}, {"id": 46, "seek": 29224, "start": 306.56, "end": 313.52, "text": " one stack frame for each element in the list. If the list is long, this could easily cause", "tokens": [51080, 472, 8630, 3920, 337, 1184, 4478, 294, 264, 1329, 13, 759, 264, 1329, 307, 938, 11, 341, 727, 3612, 3082, 51428], "temperature": 0.0, "avg_logprob": -0.09290842758981806, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.013845742680132389}, {"id": 47, "seek": 29224, "start": 313.52, "end": 320.0, "text": " a stack overflow error. So the problem is that it every time the deep copy takes place, it", "tokens": [51428, 257, 8630, 37772, 6713, 13, 407, 264, 1154, 307, 300, 309, 633, 565, 264, 2452, 5055, 2516, 1081, 11, 309, 51752], "temperature": 0.0, "avg_logprob": -0.09290842758981806, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.013845742680132389}, {"id": 48, "seek": 32000, "start": 320.72, "end": 325.52, "text": " for per per element, it creates a new stack frame. And that can obviously not a memory", "tokens": [50400, 337, 680, 680, 4478, 11, 309, 7829, 257, 777, 8630, 3920, 13, 400, 300, 393, 2745, 406, 257, 4675, 50640], "temperature": 0.0, "avg_logprob": -0.20980940694394318, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.013845783658325672}, {"id": 49, "seek": 32000, "start": 325.52, "end": 331.76, "text": " leak, but it can cause a stack overflow error, because this happens runtime. Now, I found this", "tokens": [50640, 17143, 11, 457, 309, 393, 3082, 257, 8630, 37772, 6713, 11, 570, 341, 2314, 34474, 13, 823, 11, 286, 1352, 341, 50952], "temperature": 0.0, "avg_logprob": -0.20980940694394318, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.013845783658325672}, {"id": 50, "seek": 32000, "start": 331.76, "end": 336.8, "text": " good article on a digital ocean, which kind of explains the difference between the heap and the", "tokens": [50952, 665, 7222, 322, 257, 4562, 7810, 11, 597, 733, 295, 13948, 264, 2649, 1296, 264, 33591, 293, 264, 51204], "temperature": 0.0, "avg_logprob": -0.20980940694394318, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.013845783658325672}, {"id": 51, "seek": 32000, "start": 336.8, "end": 343.84, "text": " stack. We had a we had there's one item I forget which one way we covered quite deeply Java, Java,", "tokens": [51204, 8630, 13, 492, 632, 257, 321, 632, 456, 311, 472, 3174, 286, 2870, 597, 472, 636, 321, 5343, 1596, 8760, 10745, 11, 10745, 11, 51556], "temperature": 0.0, "avg_logprob": -0.20980940694394318, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.013845783658325672}, {"id": 52, "seek": 34384, "start": 344.56, "end": 350.96, "text": " memory management, garage collection, allocation, all of that. But but I had to put this in", "tokens": [50400, 4675, 4592, 11, 14400, 5765, 11, 27599, 11, 439, 295, 300, 13, 583, 457, 286, 632, 281, 829, 341, 294, 50720], "temperature": 0.0, "avg_logprob": -0.21788406372070312, "compression_ratio": 1.5665236051502145, "no_speech_prob": 0.006486902013421059}, {"id": 53, "seek": 34384, "start": 350.96, "end": 355.59999999999997, "text": " charge of PD to get a bit more, let's say, elaborated definition. And here's what", "tokens": [50720, 4602, 295, 10464, 281, 483, 257, 857, 544, 11, 718, 311, 584, 11, 16298, 770, 7123, 13, 400, 510, 311, 437, 50952], "temperature": 0.0, "avg_logprob": -0.21788406372070312, "compression_ratio": 1.5665236051502145, "no_speech_prob": 0.006486902013421059}, {"id": 54, "seek": 34384, "start": 356.47999999999996, "end": 361.76, "text": " charge of PD states, pertaining to this point that Joshua Bloch makes to choose. Oh, I didn't", "tokens": [50996, 4602, 295, 10464, 4368, 11, 49582, 281, 341, 935, 300, 24005, 9865, 339, 1669, 281, 2826, 13, 876, 11, 286, 994, 380, 51260], "temperature": 0.0, "avg_logprob": -0.21788406372070312, "compression_ratio": 1.5665236051502145, "no_speech_prob": 0.006486902013421059}, {"id": 55, "seek": 34384, "start": 361.76, "end": 368.32, "text": " mention that he says, because recursion can cause this stack overflow error, it's better choosing", "tokens": [51260, 2152, 300, 415, 1619, 11, 570, 20560, 313, 393, 3082, 341, 8630, 37772, 6713, 11, 309, 311, 1101, 10875, 51588], "temperature": 0.0, "avg_logprob": -0.21788406372070312, "compression_ratio": 1.5665236051502145, "no_speech_prob": 0.006486902013421059}, {"id": 56, "seek": 36832, "start": 368.32, "end": 375.68, "text": " iteration over recursion. And here's why. And I'm quoting charge of PD verbatim here. Using", "tokens": [50364, 24784, 670, 20560, 313, 13, 400, 510, 311, 983, 13, 400, 286, 478, 41552, 4602, 295, 10464, 9595, 267, 332, 510, 13, 11142, 50732], "temperature": 0.0, "avg_logprob": -0.14645659248783904, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.014060987159609795}, {"id": 57, "seek": 36832, "start": 375.68, "end": 381.2, "text": " iteration instead of recursion helps prevent a stack overflow error by avoiding excessive", "tokens": [50732, 24784, 2602, 295, 20560, 313, 3665, 4871, 257, 8630, 37772, 6713, 538, 20220, 22704, 51008], "temperature": 0.0, "avg_logprob": -0.14645659248783904, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.014060987159609795}, {"id": 58, "seek": 36832, "start": 381.2, "end": 387.03999999999996, "text": " stack frame allocation. When a method is invoked recursively, each recursive call creates a new", "tokens": [51008, 8630, 3920, 27599, 13, 1133, 257, 3170, 307, 1048, 9511, 20560, 3413, 11, 1184, 20560, 488, 818, 7829, 257, 777, 51300], "temperature": 0.0, "avg_logprob": -0.14645659248783904, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.014060987159609795}, {"id": 59, "seek": 36832, "start": 387.03999999999996, "end": 392.15999999999997, "text": " stack frame, as he stated, which consumes additional memory on a call on the call stack.", "tokens": [51300, 8630, 3920, 11, 382, 415, 11323, 11, 597, 48823, 4497, 4675, 322, 257, 818, 322, 264, 818, 8630, 13, 51556], "temperature": 0.0, "avg_logprob": -0.14645659248783904, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.014060987159609795}, {"id": 60, "seek": 36832, "start": 392.71999999999997, "end": 397.52, "text": " If the recursion goes too deep, or if the data structure being processed is large,", "tokens": [51584, 759, 264, 20560, 313, 1709, 886, 2452, 11, 420, 498, 264, 1412, 3877, 885, 18846, 307, 2416, 11, 51824], "temperature": 0.0, "avg_logprob": -0.14645659248783904, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.014060987159609795}, {"id": 61, "seek": 39752, "start": 397.52, "end": 403.12, "text": " it can result in the stack running out of memory, causing a stack overflow error. So we need a", "tokens": [50364, 309, 393, 1874, 294, 264, 8630, 2614, 484, 295, 4675, 11, 9853, 257, 8630, 37772, 6713, 13, 407, 321, 643, 257, 50644], "temperature": 0.0, "avg_logprob": -0.07728778279345969, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.0013044505612924695}, {"id": 62, "seek": 39752, "start": 403.91999999999996, "end": 410.56, "text": " mechanism or an algorithm that doesn't create a new stack frame every time an element is created", "tokens": [50684, 7513, 420, 364, 9284, 300, 1177, 380, 1884, 257, 777, 8630, 3920, 633, 565, 364, 4478, 307, 2942, 51016], "temperature": 0.0, "avg_logprob": -0.07728778279345969, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.0013044505612924695}, {"id": 63, "seek": 39752, "start": 411.28, "end": 417.52, "text": " in the data structure. And that's where iteration can be much more handy. So let's take a look at", "tokens": [51052, 294, 264, 1412, 3877, 13, 400, 300, 311, 689, 24784, 393, 312, 709, 544, 13239, 13, 407, 718, 311, 747, 257, 574, 412, 51364], "temperature": 0.0, "avg_logprob": -0.07728778279345969, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.0013044505612924695}, {"id": 64, "seek": 39752, "start": 417.52, "end": 423.91999999999996, "text": " how the iteration method works. Let's comment out the deep copy. And take a look at the", "tokens": [51364, 577, 264, 24784, 3170, 1985, 13, 961, 311, 2871, 484, 264, 2452, 5055, 13, 400, 747, 257, 574, 412, 264, 51684], "temperature": 0.0, "avg_logprob": -0.07728778279345969, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.0013044505612924695}, {"id": 65, "seek": 42392, "start": 424.8, "end": 431.36, "text": " deep copy that uses iteration. So in iteration, because we're not calling the deep copy method", "tokens": [50408, 2452, 5055, 300, 4960, 24784, 13, 407, 294, 24784, 11, 570, 321, 434, 406, 5141, 264, 2452, 5055, 3170, 50736], "temperature": 0.0, "avg_logprob": -0.11022108704296511, "compression_ratio": 1.543010752688172, "no_speech_prob": 0.0053009348921477795}, {"id": 66, "seek": 42392, "start": 431.36, "end": 438.96000000000004, "text": " within the function, it's not happening recursively, it doesn't require a new frame on the call stack", "tokens": [50736, 1951, 264, 2445, 11, 309, 311, 406, 2737, 20560, 3413, 11, 309, 1177, 380, 3651, 257, 777, 3920, 322, 264, 818, 8630, 51116], "temperature": 0.0, "avg_logprob": -0.11022108704296511, "compression_ratio": 1.543010752688172, "no_speech_prob": 0.0053009348921477795}, {"id": 67, "seek": 42392, "start": 438.96000000000004, "end": 446.72, "text": " every single time the loop runs. And therefore, for larger data structures or large array,", "tokens": [51116, 633, 2167, 565, 264, 6367, 6676, 13, 400, 4412, 11, 337, 4833, 1412, 9227, 420, 2416, 10225, 11, 51504], "temperature": 0.0, "avg_logprob": -0.11022108704296511, "compression_ratio": 1.543010752688172, "no_speech_prob": 0.0053009348921477795}, {"id": 68, "seek": 44672, "start": 447.6, "end": 454.56, "text": " using iteration probably is a bad idea. Overusing recursion, even though, obviously,", "tokens": [50408, 1228, 24784, 1391, 307, 257, 1578, 1558, 13, 4886, 7981, 20560, 313, 11, 754, 1673, 11, 2745, 11, 50756], "temperature": 0.0, "avg_logprob": -0.13171154519786005, "compression_ratio": 1.6194690265486726, "no_speech_prob": 0.0726131722331047}, {"id": 69, "seek": 44672, "start": 454.56, "end": 460.32000000000005, "text": " as you can see here, the recursive method is much simpler. And it kind of makes a lot more", "tokens": [50756, 382, 291, 393, 536, 510, 11, 264, 20560, 488, 3170, 307, 709, 18587, 13, 400, 309, 733, 295, 1669, 257, 688, 544, 51044], "temperature": 0.0, "avg_logprob": -0.13171154519786005, "compression_ratio": 1.6194690265486726, "no_speech_prob": 0.0726131722331047}, {"id": 70, "seek": 44672, "start": 460.32000000000005, "end": 465.28000000000003, "text": " sense compared to this where you got p.next and your parsing generics and whatnot can be a bit", "tokens": [51044, 2020, 5347, 281, 341, 689, 291, 658, 280, 13, 716, 734, 293, 428, 21156, 278, 1337, 1167, 293, 25882, 393, 312, 257, 857, 51292], "temperature": 0.0, "avg_logprob": -0.13171154519786005, "compression_ratio": 1.6194690265486726, "no_speech_prob": 0.0726131722331047}, {"id": 71, "seek": 44672, "start": 465.28000000000003, "end": 471.92, "text": " more complicated. So depending on the use case, you can use whatever method or we can implement", "tokens": [51292, 544, 6179, 13, 407, 5413, 322, 264, 764, 1389, 11, 291, 393, 764, 2035, 3170, 420, 321, 393, 4445, 51624], "temperature": 0.0, "avg_logprob": -0.13171154519786005, "compression_ratio": 1.6194690265486726, "no_speech_prob": 0.0726131722331047}, {"id": 72, "seek": 47192, "start": 471.92, "end": 478.88, "text": " the method however may you think it'll suffice or it'll be apt. Okay, saying all that, let's move", "tokens": [50364, 264, 3170, 4461, 815, 291, 519, 309, 603, 3889, 573, 420, 309, 603, 312, 29427, 13, 1033, 11, 1566, 439, 300, 11, 718, 311, 1286, 50712], "temperature": 0.0, "avg_logprob": -0.15413304823863355, "compression_ratio": 1.7409638554216869, "no_speech_prob": 0.013634292408823967}, {"id": 73, "seek": 47192, "start": 478.88, "end": 485.92, "text": " to the wrong side. Saying all that, let's move to the next point, which is how in cloning, how we", "tokens": [50712, 281, 264, 2085, 1252, 13, 34087, 439, 300, 11, 718, 311, 1286, 281, 264, 958, 935, 11, 597, 307, 577, 294, 596, 16638, 11, 577, 321, 51064], "temperature": 0.0, "avg_logprob": -0.15413304823863355, "compression_ratio": 1.7409638554216869, "no_speech_prob": 0.013634292408823967}, {"id": 74, "seek": 47192, "start": 485.92, "end": 494.32, "text": " can utilize the super dot clone method in your class. So you can use the clone method in your", "tokens": [51064, 393, 16117, 264, 1687, 5893, 26506, 3170, 294, 428, 1508, 13, 407, 291, 393, 764, 264, 26506, 3170, 294, 428, 51484], "temperature": 0.0, "avg_logprob": -0.15413304823863355, "compression_ratio": 1.7409638554216869, "no_speech_prob": 0.013634292408823967}, {"id": 75, "seek": 49432, "start": 494.32, "end": 502.0, "text": " superclass. Firstly, here's what Joshua book states, a final approach to cloning complex", "tokens": [50364, 1687, 11665, 13, 20042, 11, 510, 311, 437, 24005, 1446, 4368, 11, 257, 2572, 3109, 281, 596, 16638, 3997, 50748], "temperature": 0.0, "avg_logprob": -0.11321529300733545, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.05580763518810272}, {"id": 76, "seek": 49432, "start": 502.0, "end": 508.4, "text": " mutable objects is to clone this to call super dot clone, set all the fields in the resulting", "tokens": [50748, 5839, 712, 6565, 307, 281, 26506, 341, 281, 818, 1687, 5893, 26506, 11, 992, 439, 264, 7909, 294, 264, 16505, 51068], "temperature": 0.0, "avg_logprob": -0.11321529300733545, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.05580763518810272}, {"id": 77, "seek": 49432, "start": 508.4, "end": 514.8, "text": " object to their initial state, and then call high level methods to regenerate the state of the", "tokens": [51068, 2657, 281, 641, 5883, 1785, 11, 293, 550, 818, 1090, 1496, 7150, 281, 26358, 473, 264, 1785, 295, 264, 51388], "temperature": 0.0, "avg_logprob": -0.11321529300733545, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.05580763518810272}, {"id": 78, "seek": 49432, "start": 514.8, "end": 519.36, "text": " original object. So at first glance, this looks quite straightforward, because all we're doing here", "tokens": [51388, 3380, 2657, 13, 407, 412, 700, 21094, 11, 341, 1542, 1596, 15325, 11, 570, 439, 321, 434, 884, 510, 51616], "temperature": 0.0, "avg_logprob": -0.11321529300733545, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.05580763518810272}, {"id": 79, "seek": 51936, "start": 519.36, "end": 525.6800000000001, "text": " is we're creating a new instance of hash table clone table object, and we're setting it to its", "tokens": [50364, 307, 321, 434, 4084, 257, 777, 5197, 295, 22019, 3199, 26506, 3199, 2657, 11, 293, 321, 434, 3287, 309, 281, 1080, 50680], "temperature": 0.0, "avg_logprob": -0.16187817117442255, "compression_ratio": 1.8215962441314555, "no_speech_prob": 0.06558021157979965}, {"id": 80, "seek": 51936, "start": 525.6800000000001, "end": 532.0, "text": " as special book states initial state, and then simply invoking the clone method of the super", "tokens": [50680, 382, 2121, 1446, 4368, 5883, 1785, 11, 293, 550, 2935, 1048, 5953, 264, 26506, 3170, 295, 264, 1687, 50996], "temperature": 0.0, "avg_logprob": -0.16187817117442255, "compression_ratio": 1.8215962441314555, "no_speech_prob": 0.06558021157979965}, {"id": 81, "seek": 51936, "start": 532.0, "end": 540.48, "text": " class, which in this case would be the object class, and repopulating this new object with whatever", "tokens": [50996, 1508, 11, 597, 294, 341, 1389, 576, 312, 264, 2657, 1508, 11, 293, 1085, 404, 12162, 341, 777, 2657, 365, 2035, 51420], "temperature": 0.0, "avg_logprob": -0.16187817117442255, "compression_ratio": 1.8215962441314555, "no_speech_prob": 0.06558021157979965}, {"id": 82, "seek": 51936, "start": 540.48, "end": 548.0, "text": " the super dot clone method or superclass, superclasses clone method returns. But but here we have an", "tokens": [51420, 264, 1687, 5893, 26506, 3170, 420, 1687, 11665, 11, 1687, 11665, 279, 26506, 3170, 11247, 13, 583, 457, 510, 321, 362, 364, 51796], "temperature": 0.0, "avg_logprob": -0.16187817117442255, "compression_ratio": 1.8215962441314555, "no_speech_prob": 0.06558021157979965}, {"id": 83, "seek": 54800, "start": 548.0, "end": 556.24, "text": " issue. And the issue is that this type of cloning, because we're doing a deep copy, especially with", "tokens": [50364, 2734, 13, 400, 264, 2734, 307, 300, 341, 2010, 295, 596, 16638, 11, 570, 321, 434, 884, 257, 2452, 5055, 11, 2318, 365, 50776], "temperature": 0.0, "avg_logprob": -0.09424251905629333, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.020639238879084587}, {"id": 84, "seek": 54800, "start": 556.24, "end": 564.96, "text": " the buckets array, it doesn't abide by the the clonable architecture contract, because we're", "tokens": [50776, 264, 32191, 10225, 11, 309, 1177, 380, 39663, 538, 264, 264, 596, 266, 712, 9482, 4364, 11, 570, 321, 434, 51212], "temperature": 0.0, "avg_logprob": -0.09424251905629333, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.020639238879084587}, {"id": 85, "seek": 54800, "start": 564.96, "end": 571.6, "text": " implementing the clonable interface here, which is a contract that the class is supposed to follow.", "tokens": [51212, 18114, 264, 596, 266, 712, 9226, 510, 11, 597, 307, 257, 4364, 300, 264, 1508, 307, 3442, 281, 1524, 13, 51544], "temperature": 0.0, "avg_logprob": -0.09424251905629333, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.020639238879084587}, {"id": 86, "seek": 57160, "start": 572.48, "end": 579.0400000000001, "text": " But by doing it this way, by doing the deep copy, it is taking place without a field by field copy", "tokens": [50408, 583, 538, 884, 309, 341, 636, 11, 538, 884, 264, 2452, 5055, 11, 309, 307, 1940, 1081, 1553, 257, 2519, 538, 2519, 5055, 50736], "temperature": 0.0, "avg_logprob": -0.10920414415378014, "compression_ratio": 1.6150627615062763, "no_speech_prob": 0.024793658405542374}, {"id": 87, "seek": 57160, "start": 579.0400000000001, "end": 584.72, "text": " of the object. And that is anatomical to the clonable architecture. I just realized as I was", "tokens": [50736, 295, 264, 2657, 13, 400, 300, 307, 21618, 298, 804, 281, 264, 596, 266, 712, 9482, 13, 286, 445, 5334, 382, 286, 390, 51020], "temperature": 0.0, "avg_logprob": -0.10920414415378014, "compression_ratio": 1.6150627615062763, "no_speech_prob": 0.024793658405542374}, {"id": 88, "seek": 57160, "start": 584.72, "end": 591.0400000000001, "text": " rereading this, sorry, I wrote this script for this a while back, that I made a mistake here.", "tokens": [51020, 46453, 8166, 341, 11, 2597, 11, 286, 4114, 341, 5755, 337, 341, 257, 1339, 646, 11, 300, 286, 1027, 257, 6146, 510, 13, 51336], "temperature": 0.0, "avg_logprob": -0.10920414415378014, "compression_ratio": 1.6150627615062763, "no_speech_prob": 0.024793658405542374}, {"id": 89, "seek": 57160, "start": 591.0400000000001, "end": 597.76, "text": " In fact, this is correct. The problem would have been if we did a shallow copy, similar to what I've", "tokens": [51336, 682, 1186, 11, 341, 307, 3006, 13, 440, 1154, 576, 362, 668, 498, 321, 630, 257, 20488, 5055, 11, 2531, 281, 437, 286, 600, 51672], "temperature": 0.0, "avg_logprob": -0.10920414415378014, "compression_ratio": 1.6150627615062763, "no_speech_prob": 0.024793658405542374}, {"id": 90, "seek": 59776, "start": 598.56, "end": 607.28, "text": " coded here, without doing a deep copy, which which is a part of the field by field copy,", "tokens": [50404, 34874, 510, 11, 1553, 884, 257, 2452, 5055, 11, 597, 597, 307, 257, 644, 295, 264, 2519, 538, 2519, 5055, 11, 50840], "temperature": 0.0, "avg_logprob": -0.14726356838060461, "compression_ratio": 1.7476635514018692, "no_speech_prob": 0.0034830921795219183}, {"id": 91, "seek": 59776, "start": 607.28, "end": 612.48, "text": " that's a part of the architecture. I mean, this is correct, because even though we're invoking", "tokens": [50840, 300, 311, 257, 644, 295, 264, 9482, 13, 286, 914, 11, 341, 307, 3006, 11, 570, 754, 1673, 321, 434, 1048, 5953, 51100], "temperature": 0.0, "avg_logprob": -0.14726356838060461, "compression_ratio": 1.7476635514018692, "no_speech_prob": 0.0034830921795219183}, {"id": 92, "seek": 59776, "start": 612.48, "end": 618.3199999999999, "text": " super dot clone, and copying the state into the new object, and then create creating the buckets", "tokens": [51100, 1687, 5893, 26506, 11, 293, 27976, 264, 1785, 666, 264, 777, 2657, 11, 293, 550, 1884, 4084, 264, 32191, 51392], "temperature": 0.0, "avg_logprob": -0.14726356838060461, "compression_ratio": 1.7476635514018692, "no_speech_prob": 0.0034830921795219183}, {"id": 93, "seek": 59776, "start": 618.3199999999999, "end": 624.88, "text": " array, we're still doing a field by field copy. So I should probably really rewrite this into", "tokens": [51392, 10225, 11, 321, 434, 920, 884, 257, 2519, 538, 2519, 5055, 13, 407, 286, 820, 1391, 534, 28132, 341, 666, 51720], "temperature": 0.0, "avg_logprob": -0.14726356838060461, "compression_ratio": 1.7476635514018692, "no_speech_prob": 0.0034830921795219183}, {"id": 94, "seek": 62488, "start": 624.88, "end": 632.08, "text": " saying deep copy taking place with a field by field copy of the object. Now this is correct,", "tokens": [50364, 1566, 2452, 5055, 1940, 1081, 365, 257, 2519, 538, 2519, 5055, 295, 264, 2657, 13, 823, 341, 307, 3006, 11, 50724], "temperature": 0.0, "avg_logprob": -0.13899656052285053, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.005641635041683912}, {"id": 95, "seek": 62488, "start": 632.08, "end": 638.4, "text": " as it should be, because because a clone method should act very much like a constructor in a class.", "tokens": [50724, 382, 309, 820, 312, 11, 570, 570, 257, 26506, 3170, 820, 605, 588, 709, 411, 257, 47479, 294, 257, 1508, 13, 51040], "temperature": 0.0, "avg_logprob": -0.13899656052285053, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.005641635041683912}, {"id": 96, "seek": 62488, "start": 638.4, "end": 643.4399999999999, "text": " And that's the point Joshua Block makes the I'm so sorry for the misunderstanding that even I got", "tokens": [51040, 400, 300, 311, 264, 935, 24005, 17500, 1669, 264, 286, 478, 370, 2597, 337, 264, 29227, 300, 754, 286, 658, 51292], "temperature": 0.0, "avg_logprob": -0.13899656052285053, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.005641635041683912}, {"id": 97, "seek": 62488, "start": 643.4399999999999, "end": 649.04, "text": " confused, but I realized I was written that in the wrong way. And this is correct, we need a deep", "tokens": [51292, 9019, 11, 457, 286, 5334, 286, 390, 3720, 300, 294, 264, 2085, 636, 13, 400, 341, 307, 3006, 11, 321, 643, 257, 2452, 51572], "temperature": 0.0, "avg_logprob": -0.13899656052285053, "compression_ratio": 1.6371308016877637, "no_speech_prob": 0.005641635041683912}, {"id": 98, "seek": 64904, "start": 649.04, "end": 655.52, "text": " copy to take place in the clone method. And it can happen, even when invoking the super dot clone", "tokens": [50364, 5055, 281, 747, 1081, 294, 264, 26506, 3170, 13, 400, 309, 393, 1051, 11, 754, 562, 1048, 5953, 264, 1687, 5893, 26506, 50688], "temperature": 0.0, "avg_logprob": -0.13514713574481266, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.01854364015161991}, {"id": 99, "seek": 64904, "start": 655.52, "end": 662.16, "text": " method just to clarify. It's a bad mistake. Okay, so here's what Joshua Block states,", "tokens": [50688, 3170, 445, 281, 17594, 13, 467, 311, 257, 1578, 6146, 13, 1033, 11, 370, 510, 311, 437, 24005, 17500, 4368, 11, 51020], "temperature": 0.0, "avg_logprob": -0.13514713574481266, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.01854364015161991}, {"id": 100, "seek": 64904, "start": 662.16, "end": 667.1999999999999, "text": " pertaining to the clone method and how it should behave. Like a constructor, a clone method must", "tokens": [51020, 49582, 281, 264, 26506, 3170, 293, 577, 309, 820, 15158, 13, 1743, 257, 47479, 11, 257, 26506, 3170, 1633, 51272], "temperature": 0.0, "avg_logprob": -0.13514713574481266, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.01854364015161991}, {"id": 101, "seek": 64904, "start": 667.1999999999999, "end": 676.48, "text": " never invoke an overriding method on the clone under construction. If okay, so that is this can", "tokens": [51272, 1128, 41117, 364, 670, 81, 2819, 3170, 322, 264, 26506, 833, 6435, 13, 759, 1392, 11, 370, 300, 307, 341, 393, 51736], "temperature": 0.0, "avg_logprob": -0.13514713574481266, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.01854364015161991}, {"id": 102, "seek": 67648, "start": 676.48, "end": 682.64, "text": " be a problem because of that. Because in the clone method, we are invoking another overriding", "tokens": [50364, 312, 257, 1154, 570, 295, 300, 13, 1436, 294, 264, 26506, 3170, 11, 321, 366, 1048, 5953, 1071, 670, 81, 2819, 50672], "temperature": 0.0, "avg_logprob": -0.10771308282409052, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.007345198187977076}, {"id": 103, "seek": 67648, "start": 682.64, "end": 687.2, "text": " method. Now this can be an issue. So the issue isn't with the deep copy, the issue really is", "tokens": [50672, 3170, 13, 823, 341, 393, 312, 364, 2734, 13, 407, 264, 2734, 1943, 380, 365, 264, 2452, 5055, 11, 264, 2734, 534, 307, 50900], "temperature": 0.0, "avg_logprob": -0.10771308282409052, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.007345198187977076}, {"id": 104, "seek": 67648, "start": 687.2, "end": 696.96, "text": " with line number 65, just to clarify. If clone invokes a method that is overridden in a subclass,", "tokens": [50900, 365, 1622, 1230, 11624, 11, 445, 281, 17594, 13, 759, 26506, 1048, 8606, 257, 3170, 300, 307, 670, 81, 6171, 294, 257, 1422, 11665, 11, 51388], "temperature": 0.0, "avg_logprob": -0.10771308282409052, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.007345198187977076}, {"id": 105, "seek": 67648, "start": 696.96, "end": 704.0, "text": " this method will execute before the subclass has had a chance to fix its state in the clone,", "tokens": [51388, 341, 3170, 486, 14483, 949, 264, 1422, 11665, 575, 632, 257, 2931, 281, 3191, 1080, 1785, 294, 264, 26506, 11, 51740], "temperature": 0.0, "avg_logprob": -0.10771308282409052, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.007345198187977076}, {"id": 106, "seek": 70400, "start": 704.0, "end": 709.44, "text": " quite possibly leading to corruption in the clone and the original. So what does that mean? If clone", "tokens": [50364, 1596, 6264, 5775, 281, 17959, 294, 264, 26506, 293, 264, 3380, 13, 407, 437, 775, 300, 914, 30, 759, 26506, 50636], "temperature": 0.0, "avg_logprob": -0.07788670183432223, "compression_ratio": 1.620408163265306, "no_speech_prob": 0.006487686187028885}, {"id": 107, "seek": 70400, "start": 709.44, "end": 714.96, "text": " invokes a method that is overridden in a subclass, this method will execute before the subclass has", "tokens": [50636, 1048, 8606, 257, 3170, 300, 307, 670, 81, 6171, 294, 257, 1422, 11665, 11, 341, 3170, 486, 14483, 949, 264, 1422, 11665, 575, 50912], "temperature": 0.0, "avg_logprob": -0.07788670183432223, "compression_ratio": 1.620408163265306, "no_speech_prob": 0.006487686187028885}, {"id": 108, "seek": 70400, "start": 714.96, "end": 720.8, "text": " had a chance to fix its state in the clone. An example of that could potentially be this. We", "tokens": [50912, 632, 257, 2931, 281, 3191, 1080, 1785, 294, 264, 26506, 13, 1107, 1365, 295, 300, 727, 7263, 312, 341, 13, 492, 51204], "temperature": 0.0, "avg_logprob": -0.07788670183432223, "compression_ratio": 1.620408163265306, "no_speech_prob": 0.006487686187028885}, {"id": 109, "seek": 70400, "start": 720.8, "end": 728.24, "text": " have this put method, which is extended from hash table. But because it's public, it can be overridden.", "tokens": [51204, 362, 341, 829, 3170, 11, 597, 307, 10913, 490, 22019, 3199, 13, 583, 570, 309, 311, 1908, 11, 309, 393, 312, 670, 81, 6171, 13, 51576], "temperature": 0.0, "avg_logprob": -0.07788670183432223, "compression_ratio": 1.620408163265306, "no_speech_prob": 0.006487686187028885}, {"id": 110, "seek": 72824, "start": 728.24, "end": 734.64, "text": " Now let's say in the subclass, an extended hash table, we define another clone method,", "tokens": [50364, 823, 718, 311, 584, 294, 264, 1422, 11665, 11, 364, 10913, 22019, 3199, 11, 321, 6964, 1071, 26506, 3170, 11, 50684], "temperature": 0.0, "avg_logprob": -0.14806603577177405, "compression_ratio": 1.7170542635658914, "no_speech_prob": 0.0023964489810168743}, {"id": 111, "seek": 72824, "start": 734.64, "end": 741.36, "text": " which should be allowed to be overridden. But we've overridden the put method too. And what that", "tokens": [50684, 597, 820, 312, 4350, 281, 312, 670, 81, 6171, 13, 583, 321, 600, 670, 81, 6171, 264, 829, 3170, 886, 13, 400, 437, 300, 51020], "temperature": 0.0, "avg_logprob": -0.14806603577177405, "compression_ratio": 1.7170542635658914, "no_speech_prob": 0.0023964489810168743}, {"id": 112, "seek": 72824, "start": 741.36, "end": 748.16, "text": " will do is it'll increase the size by an additional one. For instance, let's say we're", "tokens": [51020, 486, 360, 307, 309, 603, 3488, 264, 2744, 538, 364, 4497, 472, 13, 1171, 5197, 11, 718, 311, 584, 321, 434, 51360], "temperature": 0.0, "avg_logprob": -0.14806603577177405, "compression_ratio": 1.7170542635658914, "no_speech_prob": 0.0023964489810168743}, {"id": 113, "seek": 72824, "start": 748.96, "end": 752.48, "text": " in the super dark put, we're doing the key and value. And then in the array,", "tokens": [51400, 294, 264, 1687, 2877, 829, 11, 321, 434, 884, 264, 2141, 293, 2158, 13, 400, 550, 294, 264, 10225, 11, 51576], "temperature": 0.0, "avg_logprob": -0.14806603577177405, "compression_ratio": 1.7170542635658914, "no_speech_prob": 0.0023964489810168743}, {"id": 114, "seek": 72824, "start": 753.04, "end": 757.44, "text": " where we're changing it, I haven't implemented that bit, but let's say the put changes it where", "tokens": [51604, 689, 321, 434, 4473, 309, 11, 286, 2378, 380, 12270, 300, 857, 11, 457, 718, 311, 584, 264, 829, 2962, 309, 689, 51824], "temperature": 0.0, "avg_logprob": -0.14806603577177405, "compression_ratio": 1.7170542635658914, "no_speech_prob": 0.0023964489810168743}, {"id": 115, "seek": 75824, "start": 758.24, "end": 765.6, "text": " the array will also increase the size. This put will also increase the size by one. And then what", "tokens": [50364, 264, 10225, 486, 611, 3488, 264, 2744, 13, 639, 829, 486, 611, 3488, 264, 2744, 538, 472, 13, 400, 550, 437, 50732], "temperature": 0.0, "avg_logprob": -0.13365323056456863, "compression_ratio": 1.7035398230088497, "no_speech_prob": 0.0002737116883508861}, {"id": 116, "seek": 75824, "start": 765.6, "end": 771.84, "text": " will happen is in the clone method, it'll create an inconsistent state because this put, which", "tokens": [50732, 486, 1051, 307, 294, 264, 26506, 3170, 11, 309, 603, 1884, 364, 36891, 1785, 570, 341, 829, 11, 597, 51044], "temperature": 0.0, "avg_logprob": -0.13365323056456863, "compression_ratio": 1.7035398230088497, "no_speech_prob": 0.0002737116883508861}, {"id": 117, "seek": 75824, "start": 771.84, "end": 778.0, "text": " should have been either private or final, has been invoked again in the subclass's clone method,", "tokens": [51044, 820, 362, 668, 2139, 4551, 420, 2572, 11, 575, 668, 1048, 9511, 797, 294, 264, 1422, 11665, 311, 26506, 3170, 11, 51352], "temperature": 0.0, "avg_logprob": -0.13365323056456863, "compression_ratio": 1.7035398230088497, "no_speech_prob": 0.0002737116883508861}, {"id": 118, "seek": 75824, "start": 778.72, "end": 784.24, "text": " which you will see here in line number 22. So roughly, this is what the block means. Obviously,", "tokens": [51388, 597, 291, 486, 536, 510, 294, 1622, 1230, 5853, 13, 407, 9810, 11, 341, 307, 437, 264, 3461, 1355, 13, 7580, 11, 51664], "temperature": 0.0, "avg_logprob": -0.13365323056456863, "compression_ratio": 1.7035398230088497, "no_speech_prob": 0.0002737116883508861}, {"id": 119, "seek": 78424, "start": 784.24, "end": 789.6800000000001, "text": " I haven't implemented the whole code, but the idea being in the clone method, we shouldn't be", "tokens": [50364, 286, 2378, 380, 12270, 264, 1379, 3089, 11, 457, 264, 1558, 885, 294, 264, 26506, 3170, 11, 321, 4659, 380, 312, 50636], "temperature": 0.0, "avg_logprob": -0.10247622479449262, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.004330911207944155}, {"id": 120, "seek": 78424, "start": 789.6800000000001, "end": 798.8, "text": " invoking methods of the superclass that can create corrupt state or non-deterministic behavior between", "tokens": [50636, 1048, 5953, 7150, 295, 264, 1687, 11665, 300, 393, 1884, 17366, 1785, 420, 2107, 12, 49136, 259, 3142, 5223, 1296, 51092], "temperature": 0.0, "avg_logprob": -0.10247622479449262, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.004330911207944155}, {"id": 121, "seek": 78424, "start": 798.8, "end": 803.44, "text": " objects. Okay, now let's discuss the objects clone method. And sorry about the background noise,", "tokens": [51092, 6565, 13, 1033, 11, 586, 718, 311, 2248, 264, 6565, 26506, 3170, 13, 400, 2597, 466, 264, 3678, 5658, 11, 51324], "temperature": 0.0, "avg_logprob": -0.10247622479449262, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.004330911207944155}, {"id": 122, "seek": 78424, "start": 803.44, "end": 808.16, "text": " it just started raining. When it comes to the objects clone method, so when I mean object,", "tokens": [51324, 309, 445, 1409, 18441, 13, 1133, 309, 1487, 281, 264, 6565, 26506, 3170, 11, 370, 562, 286, 914, 2657, 11, 51560], "temperature": 0.0, "avg_logprob": -0.10247622479449262, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.004330911207944155}, {"id": 123, "seek": 80816, "start": 808.16, "end": 814.64, "text": " I mean the superclass and Java of all other classes, the Java object class, Drusher book", "tokens": [50364, 286, 914, 264, 1687, 11665, 293, 10745, 295, 439, 661, 5359, 11, 264, 10745, 2657, 1508, 11, 2491, 301, 511, 1446, 50688], "temperature": 0.0, "avg_logprob": -0.18357983502474698, "compression_ratio": 1.7897196261682242, "no_speech_prob": 0.002844706643372774}, {"id": 124, "seek": 80816, "start": 814.64, "end": 822.0799999999999, "text": " states this, objects clone method is declared to throw clone not support exception, but overriding", "tokens": [50688, 4368, 341, 11, 6565, 26506, 3170, 307, 15489, 281, 3507, 26506, 406, 1406, 11183, 11, 457, 670, 81, 2819, 51060], "temperature": 0.0, "avg_logprob": -0.18357983502474698, "compression_ratio": 1.7897196261682242, "no_speech_prob": 0.002844706643372774}, {"id": 125, "seek": 80816, "start": 822.0799999999999, "end": 829.28, "text": " methods need not public clone methods should admit the throws close as methods that don't throw", "tokens": [51060, 7150, 643, 406, 1908, 26506, 7150, 820, 9796, 264, 19251, 1998, 382, 7150, 300, 500, 380, 3507, 51420], "temperature": 0.0, "avg_logprob": -0.18357983502474698, "compression_ratio": 1.7897196261682242, "no_speech_prob": 0.002844706643372774}, {"id": 126, "seek": 80816, "start": 829.28, "end": 837.8399999999999, "text": " check exceptions are easy to use. So here's how the objects clone method is defined, which throws a", "tokens": [51420, 1520, 22847, 366, 1858, 281, 764, 13, 407, 510, 311, 577, 264, 6565, 26506, 3170, 307, 7642, 11, 597, 19251, 257, 51848], "temperature": 0.0, "avg_logprob": -0.18357983502474698, "compression_ratio": 1.7897196261682242, "no_speech_prob": 0.002844706643372774}, {"id": 127, "seek": 83784, "start": 837.84, "end": 843.0400000000001, "text": " clone not support exception. And then if you have this class here, which overrides this code", "tokens": [50364, 26506, 406, 1406, 11183, 13, 400, 550, 498, 291, 362, 341, 1508, 510, 11, 597, 670, 81, 1875, 341, 3089, 50624], "temperature": 0.0, "avg_logprob": -0.13615051599649283, "compression_ratio": 1.6431535269709543, "no_speech_prob": 0.0042638396844267845}, {"id": 128, "seek": 83784, "start": 843.0400000000001, "end": 850.48, "text": " method from the object class, as for the contract of the colonial architecture, it's a contract that", "tokens": [50624, 3170, 490, 264, 2657, 1508, 11, 382, 337, 264, 4364, 295, 264, 19066, 9482, 11, 309, 311, 257, 4364, 300, 50996], "temperature": 0.0, "avg_logprob": -0.13615051599649283, "compression_ratio": 1.6431535269709543, "no_speech_prob": 0.0042638396844267845}, {"id": 129, "seek": 83784, "start": 851.2, "end": 857.2800000000001, "text": " the JVM makes, or it's a contract with the JVM, that the clone will take place properly. Therefore,", "tokens": [51032, 264, 508, 53, 44, 1669, 11, 420, 309, 311, 257, 4364, 365, 264, 508, 53, 44, 11, 300, 264, 26506, 486, 747, 1081, 6108, 13, 7504, 11, 51336], "temperature": 0.0, "avg_logprob": -0.13615051599649283, "compression_ratio": 1.6431535269709543, "no_speech_prob": 0.0042638396844267845}, {"id": 130, "seek": 83784, "start": 857.2800000000001, "end": 864.24, "text": " this bit isn't required. So we can get rid of it really. But it's not that simple. Drusher book states", "tokens": [51336, 341, 857, 1943, 380, 4739, 13, 407, 321, 393, 483, 3973, 295, 309, 534, 13, 583, 309, 311, 406, 300, 2199, 13, 2491, 301, 511, 1446, 4368, 51684], "temperature": 0.0, "avg_logprob": -0.13615051599649283, "compression_ratio": 1.6431535269709543, "no_speech_prob": 0.0042638396844267845}, {"id": 131, "seek": 86424, "start": 864.24, "end": 870.16, "text": " that there are two ways to do this when designing a class of inheritance. Firstly, on what you should", "tokens": [50364, 300, 456, 366, 732, 2098, 281, 360, 341, 562, 14685, 257, 1508, 295, 32122, 13, 20042, 11, 322, 437, 291, 820, 50660], "temperature": 0.0, "avg_logprob": -0.18166544126427692, "compression_ratio": 1.6528925619834711, "no_speech_prob": 0.007120661437511444}, {"id": 132, "seek": 86424, "start": 870.16, "end": 876.72, "text": " not do. If you have a superclass that is designed for being inherited, this shouldn't happen. We", "tokens": [50660, 406, 360, 13, 759, 291, 362, 257, 1687, 11665, 300, 307, 4761, 337, 885, 27091, 11, 341, 4659, 380, 1051, 13, 492, 50988], "temperature": 0.0, "avg_logprob": -0.18166544126427692, "compression_ratio": 1.6528925619834711, "no_speech_prob": 0.007120661437511444}, {"id": 133, "seek": 86424, "start": 876.72, "end": 882.16, "text": " shouldn't implement cloneable, because then it'll create corrupt state. As you can see, this resource", "tokens": [50988, 4659, 380, 4445, 26506, 712, 11, 570, 550, 309, 603, 1884, 17366, 1785, 13, 1018, 291, 393, 536, 11, 341, 7684, 51260], "temperature": 0.0, "avg_logprob": -0.18166544126427692, "compression_ratio": 1.6528925619834711, "no_speech_prob": 0.007120661437511444}, {"id": 134, "seek": 86424, "start": 882.16, "end": 889.52, "text": " area here would be shared between these two objects creating a medieval not available state, sorry,", "tokens": [51260, 1859, 510, 576, 312, 5507, 1296, 613, 732, 6565, 4084, 257, 24078, 406, 2435, 1785, 11, 2597, 11, 51628], "temperature": 0.0, "avg_logprob": -0.18166544126427692, "compression_ratio": 1.6528925619834711, "no_speech_prob": 0.007120661437511444}, {"id": 135, "seek": 88952, "start": 890.16, "end": 895.36, "text": " corrupt state. But given that though, we can still have a clone method in a class designed for", "tokens": [50396, 17366, 1785, 13, 583, 2212, 300, 1673, 11, 321, 393, 920, 362, 257, 26506, 3170, 294, 257, 1508, 4761, 337, 50656], "temperature": 0.0, "avg_logprob": -0.13282452179835394, "compression_ratio": 1.8007662835249043, "no_speech_prob": 0.005910083651542664}, {"id": 136, "seek": 88952, "start": 895.36, "end": 900.8, "text": " inheritance without implementing cloneable. There are two choices that just show gives us the first", "tokens": [50656, 32122, 1553, 18114, 26506, 712, 13, 821, 366, 732, 7994, 300, 445, 855, 2709, 505, 264, 700, 50928], "temperature": 0.0, "avg_logprob": -0.13282452179835394, "compression_ratio": 1.8007662835249043, "no_speech_prob": 0.005910083651542664}, {"id": 137, "seek": 88952, "start": 900.8, "end": 905.92, "text": " one is implement a properly functioning clone method mimicking that in the object class. So not", "tokens": [50928, 472, 307, 4445, 257, 6108, 18483, 26506, 3170, 12247, 10401, 300, 294, 264, 2657, 1508, 13, 407, 406, 51184], "temperature": 0.0, "avg_logprob": -0.13282452179835394, "compression_ratio": 1.8007662835249043, "no_speech_prob": 0.005910083651542664}, {"id": 138, "seek": 88952, "start": 905.92, "end": 911.4399999999999, "text": " a clone method like this, this is wrong. We should mimic what's being done in the object class,", "tokens": [51184, 257, 26506, 3170, 411, 341, 11, 341, 307, 2085, 13, 492, 820, 31075, 437, 311, 885, 1096, 294, 264, 2657, 1508, 11, 51460], "temperature": 0.0, "avg_logprob": -0.13282452179835394, "compression_ratio": 1.8007662835249043, "no_speech_prob": 0.005910083651542664}, {"id": 139, "seek": 88952, "start": 911.4399999999999, "end": 916.0799999999999, "text": " despite not implementing the cloneable architecture, or prevent the subclasses from", "tokens": [51460, 7228, 406, 18114, 264, 26506, 712, 9482, 11, 420, 4871, 264, 1422, 11665, 279, 490, 51692], "temperature": 0.0, "avg_logprob": -0.13282452179835394, "compression_ratio": 1.8007662835249043, "no_speech_prob": 0.005910083651542664}, {"id": 140, "seek": 91608, "start": 916.08, "end": 923.36, "text": " implementing a clone method completely by making the clone method protected final. And then that", "tokens": [50364, 18114, 257, 26506, 3170, 2584, 538, 1455, 264, 26506, 3170, 10594, 2572, 13, 400, 550, 300, 50728], "temperature": 0.0, "avg_logprob": -0.10228808029838231, "compression_ratio": 1.7079646017699115, "no_speech_prob": 0.002082799794152379}, {"id": 141, "seek": 91608, "start": 923.36, "end": 932.08, "text": " can't be any overriding taking place. Okay, a small caveat. The caveat is what to do when writing,", "tokens": [50728, 393, 380, 312, 604, 670, 81, 2819, 1940, 1081, 13, 1033, 11, 257, 1359, 43012, 13, 440, 43012, 307, 437, 281, 360, 562, 3579, 11, 51164], "temperature": 0.0, "avg_logprob": -0.10228808029838231, "compression_ratio": 1.7079646017699115, "no_speech_prob": 0.002082799794152379}, {"id": 142, "seek": 91608, "start": 932.08, "end": 940.0, "text": " not a caveat really, but more of an axillary point, what to do when writing a class for threat safety", "tokens": [51164, 406, 257, 43012, 534, 11, 457, 544, 295, 364, 6360, 46367, 935, 11, 437, 281, 360, 562, 3579, 257, 1508, 337, 4734, 4514, 51560], "temperature": 0.0, "avg_logprob": -0.10228808029838231, "compression_ratio": 1.7079646017699115, "no_speech_prob": 0.002082799794152379}, {"id": 143, "seek": 91608, "start": 940.0, "end": 945.44, "text": " for an object to work with multiple threads. So firstly, the objects clone method is not", "tokens": [51560, 337, 364, 2657, 281, 589, 365, 3866, 19314, 13, 407, 27376, 11, 264, 6565, 26506, 3170, 307, 406, 51832], "temperature": 0.0, "avg_logprob": -0.10228808029838231, "compression_ratio": 1.7079646017699115, "no_speech_prob": 0.002082799794152379}, {"id": 144, "seek": 94544, "start": 945.44, "end": 950.0, "text": " synchronized. Therefore, it is not thread safe. So we have to keep that in mind when writing a", "tokens": [50364, 19331, 1602, 13, 7504, 11, 309, 307, 406, 7207, 3273, 13, 407, 321, 362, 281, 1066, 300, 294, 1575, 562, 3579, 257, 50592], "temperature": 0.0, "avg_logprob": -0.12766217672696678, "compression_ratio": 1.6972477064220184, "no_speech_prob": 0.013846484944224358}, {"id": 145, "seek": 94544, "start": 950.0, "end": 956.32, "text": " class. And let's take a look at a demo as to how we can potentially write a thread safe class.", "tokens": [50592, 1508, 13, 400, 718, 311, 747, 257, 574, 412, 257, 10723, 382, 281, 577, 321, 393, 7263, 2464, 257, 7207, 3273, 1508, 13, 50908], "temperature": 0.0, "avg_logprob": -0.12766217672696678, "compression_ratio": 1.6972477064220184, "no_speech_prob": 0.013846484944224358}, {"id": 146, "seek": 94544, "start": 956.32, "end": 961.12, "text": " And again, this code isn't complete, they can certainly improve it's simply a blueprint on", "tokens": [50908, 400, 797, 11, 341, 3089, 1943, 380, 3566, 11, 436, 393, 3297, 3470, 309, 311, 2935, 257, 35868, 322, 51148], "temperature": 0.0, "avg_logprob": -0.12766217672696678, "compression_ratio": 1.6972477064220184, "no_speech_prob": 0.013846484944224358}, {"id": 147, "seek": 94544, "start": 961.12, "end": 968.72, "text": " writing a thread safe class. Really like, that was a mistake, like writing other threads,", "tokens": [51148, 3579, 257, 7207, 3273, 1508, 13, 4083, 411, 11, 300, 390, 257, 6146, 11, 411, 3579, 661, 19314, 11, 51528], "temperature": 0.0, "avg_logprob": -0.12766217672696678, "compression_ratio": 1.6972477064220184, "no_speech_prob": 0.013846484944224358}, {"id": 148, "seek": 96872, "start": 968.72, "end": 976.24, "text": " thread safe, thread safe classes, what we can do is define the fields as being synchronized. So", "tokens": [50364, 7207, 3273, 11, 7207, 3273, 5359, 11, 437, 321, 393, 360, 307, 6964, 264, 7909, 382, 885, 19331, 1602, 13, 407, 50740], "temperature": 0.0, "avg_logprob": -0.17283845198781866, "compression_ratio": 1.829268292682927, "no_speech_prob": 0.07806319743394852}, {"id": 149, "seek": 96872, "start": 976.24, "end": 981.44, "text": " now it's atomic. And then in that class, so have a class called safe kind of which implements cloneable,", "tokens": [50740, 586, 309, 311, 22275, 13, 400, 550, 294, 300, 1508, 11, 370, 362, 257, 1508, 1219, 3273, 733, 295, 597, 704, 17988, 26506, 712, 11, 51000], "temperature": 0.0, "avg_logprob": -0.17283845198781866, "compression_ratio": 1.829268292682927, "no_speech_prob": 0.07806319743394852}, {"id": 150, "seek": 96872, "start": 982.0, "end": 988.64, "text": " this class here is not thread safe. And we can make it thread safe by giving it the", "tokens": [51028, 341, 1508, 510, 307, 406, 7207, 3273, 13, 400, 321, 393, 652, 309, 7207, 3273, 538, 2902, 309, 264, 51360], "temperature": 0.0, "avg_logprob": -0.17283845198781866, "compression_ratio": 1.829268292682927, "no_speech_prob": 0.07806319743394852}, {"id": 151, "seek": 96872, "start": 988.64, "end": 994.5600000000001, "text": " synchronized keyword, which will make this clone is synchronized. And in that in that way,", "tokens": [51360, 19331, 1602, 20428, 11, 597, 486, 652, 341, 26506, 307, 19331, 1602, 13, 400, 294, 300, 294, 300, 636, 11, 51656], "temperature": 0.0, "avg_logprob": -0.17283845198781866, "compression_ratio": 1.829268292682927, "no_speech_prob": 0.07806319743394852}, {"id": 152, "seek": 99456, "start": 995.1999999999999, "end": 1000.64, "text": " two objects won't be able to invoke this method at the same time. Sorry, not two objects, two", "tokens": [50396, 732, 6565, 1582, 380, 312, 1075, 281, 41117, 341, 3170, 412, 264, 912, 565, 13, 4919, 11, 406, 732, 6565, 11, 732, 50668], "temperature": 0.0, "avg_logprob": -0.12907591271907726, "compression_ratio": 1.7674418604651163, "no_speech_prob": 0.021946387365460396}, {"id": 153, "seek": 99456, "start": 1000.64, "end": 1006.56, "text": " threads will not be able to invoke this method at the same time. So to recap, what we've discussed", "tokens": [50668, 19314, 486, 406, 312, 1075, 281, 41117, 341, 3170, 412, 264, 912, 565, 13, 407, 281, 20928, 11, 437, 321, 600, 7152, 50964], "temperature": 0.0, "avg_logprob": -0.12907591271907726, "compression_ratio": 1.7674418604651163, "no_speech_prob": 0.021946387365460396}, {"id": 154, "seek": 99456, "start": 1006.56, "end": 1015.04, "text": " in both part one and part two of item 13, Joshua book states, to recap, as I said, all classes", "tokens": [50964, 294, 1293, 644, 472, 293, 644, 732, 295, 3174, 3705, 11, 24005, 1446, 4368, 11, 281, 20928, 11, 382, 286, 848, 11, 439, 5359, 51388], "temperature": 0.0, "avg_logprob": -0.12907591271907726, "compression_ratio": 1.7674418604651163, "no_speech_prob": 0.021946387365460396}, {"id": 155, "seek": 99456, "start": 1015.04, "end": 1021.52, "text": " that implement cloneable should override clone with a public method whose return type is the", "tokens": [51388, 300, 4445, 26506, 712, 820, 42321, 26506, 365, 257, 1908, 3170, 6104, 2736, 2010, 307, 264, 51712], "temperature": 0.0, "avg_logprob": -0.12907591271907726, "compression_ratio": 1.7674418604651163, "no_speech_prob": 0.021946387365460396}, {"id": 156, "seek": 102152, "start": 1021.6, "end": 1029.12, "text": " class itself. This method should first call super dark clone, as we went through a bit before,", "tokens": [50368, 1508, 2564, 13, 639, 3170, 820, 700, 818, 1687, 2877, 26506, 11, 382, 321, 1437, 807, 257, 857, 949, 11, 50744], "temperature": 0.0, "avg_logprob": -0.08124376535415649, "compression_ratio": 1.6327433628318584, "no_speech_prob": 0.00490452628582716}, {"id": 157, "seek": 102152, "start": 1029.12, "end": 1036.24, "text": " then fix any fields that need fixing. Typically, this means copying any mutable objects that", "tokens": [50744, 550, 3191, 604, 7909, 300, 643, 19442, 13, 23129, 11, 341, 1355, 27976, 604, 5839, 712, 6565, 300, 51100], "temperature": 0.0, "avg_logprob": -0.08124376535415649, "compression_ratio": 1.6327433628318584, "no_speech_prob": 0.00490452628582716}, {"id": 158, "seek": 102152, "start": 1036.24, "end": 1041.84, "text": " compromise internal deep structure of the object and replacing the clone's references", "tokens": [51100, 18577, 6920, 2452, 3877, 295, 264, 2657, 293, 19139, 264, 26506, 311, 15400, 51380], "temperature": 0.0, "avg_logprob": -0.08124376535415649, "compression_ratio": 1.6327433628318584, "no_speech_prob": 0.00490452628582716}, {"id": 159, "seek": 102152, "start": 1042.48, "end": 1047.6, "text": " to these objects with references to their copies. So that's kind of what we discussed before in", "tokens": [51412, 281, 613, 6565, 365, 15400, 281, 641, 14341, 13, 407, 300, 311, 733, 295, 437, 321, 7152, 949, 294, 51668], "temperature": 0.0, "avg_logprob": -0.08124376535415649, "compression_ratio": 1.6327433628318584, "no_speech_prob": 0.00490452628582716}, {"id": 160, "seek": 104760, "start": 1047.6, "end": 1053.4399999999998, "text": " using either recursion or iteration by doing a deep copy. And then just another point he makes,", "tokens": [50364, 1228, 2139, 20560, 313, 420, 24784, 538, 884, 257, 2452, 5055, 13, 400, 550, 445, 1071, 935, 415, 1669, 11, 50656], "temperature": 0.0, "avg_logprob": -0.08845384176387343, "compression_ratio": 1.6488888888888888, "no_speech_prob": 0.003027654252946377}, {"id": 161, "seek": 104760, "start": 1053.4399999999998, "end": 1058.32, "text": " if the class contains only primitive fields or references to mutable objects,", "tokens": [50656, 498, 264, 1508, 8306, 787, 28540, 7909, 420, 15400, 281, 5839, 712, 6565, 11, 50900], "temperature": 0.0, "avg_logprob": -0.08845384176387343, "compression_ratio": 1.6488888888888888, "no_speech_prob": 0.003027654252946377}, {"id": 162, "seek": 104760, "start": 1059.4399999999998, "end": 1067.4399999999998, "text": " then it is likely the case that no fields need to be fixed. So then he asks, is all this complexity", "tokens": [50956, 550, 309, 307, 3700, 264, 1389, 300, 572, 7909, 643, 281, 312, 6806, 13, 407, 550, 415, 8962, 11, 307, 439, 341, 14024, 51356], "temperature": 0.0, "avg_logprob": -0.08845384176387343, "compression_ratio": 1.6488888888888888, "no_speech_prob": 0.003027654252946377}, {"id": 163, "seek": 104760, "start": 1067.4399999999998, "end": 1073.28, "text": " really necessary when designing a clone method, or when overriding the clone method of the object", "tokens": [51356, 534, 4818, 562, 14685, 257, 26506, 3170, 11, 420, 562, 670, 81, 2819, 264, 26506, 3170, 295, 264, 2657, 51648], "temperature": 0.0, "avg_logprob": -0.08845384176387343, "compression_ratio": 1.6488888888888888, "no_speech_prob": 0.003027654252946377}, {"id": 164, "seek": 107328, "start": 1073.28, "end": 1077.92, "text": " class? When he means all this complexity, we're talking about what we discussed in part one and", "tokens": [50364, 1508, 30, 1133, 415, 1355, 439, 341, 14024, 11, 321, 434, 1417, 466, 437, 321, 7152, 294, 644, 472, 293, 50596], "temperature": 0.0, "avg_logprob": -0.0899817602975028, "compression_ratio": 1.6141078838174274, "no_speech_prob": 0.00793624110519886}, {"id": 165, "seek": 107328, "start": 1077.92, "end": 1085.92, "text": " now in part two. So a better approach is using a technique called a copy constructor or a copy", "tokens": [50596, 586, 294, 644, 732, 13, 407, 257, 1101, 3109, 307, 1228, 257, 6532, 1219, 257, 5055, 47479, 420, 257, 5055, 50996], "temperature": 0.0, "avg_logprob": -0.0899817602975028, "compression_ratio": 1.6141078838174274, "no_speech_prob": 0.00793624110519886}, {"id": 166, "seek": 107328, "start": 1085.92, "end": 1091.12, "text": " factory method. But before we get to that, before we look at the demos, I'll read out what he said.", "tokens": [50996, 9265, 3170, 13, 583, 949, 321, 483, 281, 300, 11, 949, 321, 574, 412, 264, 33788, 11, 286, 603, 1401, 484, 437, 415, 848, 13, 51256], "temperature": 0.0, "avg_logprob": -0.0899817602975028, "compression_ratio": 1.6141078838174274, "no_speech_prob": 0.00793624110519886}, {"id": 167, "seek": 107328, "start": 1092.3999999999999, "end": 1099.2, "text": " In regards to the complexity, he said, really, it's not needed. If you extend a class that already", "tokens": [51320, 682, 14258, 281, 264, 14024, 11, 415, 848, 11, 534, 11, 309, 311, 406, 2978, 13, 759, 291, 10101, 257, 1508, 300, 1217, 51660], "temperature": 0.0, "avg_logprob": -0.0899817602975028, "compression_ratio": 1.6141078838174274, "no_speech_prob": 0.00793624110519886}, {"id": 168, "seek": 109920, "start": 1099.2, "end": 1103.6000000000001, "text": " implements cloneable, you have a little choice but to implement a well-behaved clone method.", "tokens": [50364, 704, 17988, 26506, 712, 11, 291, 362, 257, 707, 3922, 457, 281, 4445, 257, 731, 12, 29437, 12865, 26506, 3170, 13, 50584], "temperature": 0.0, "avg_logprob": -0.0799687411806999, "compression_ratio": 1.753787878787879, "no_speech_prob": 0.016149481758475304}, {"id": 169, "seek": 109920, "start": 1103.6000000000001, "end": 1109.3600000000001, "text": " That's the advantage of using an interface like cloneable, which kind of forces us to", "tokens": [50584, 663, 311, 264, 5002, 295, 1228, 364, 9226, 411, 26506, 712, 11, 597, 733, 295, 5874, 505, 281, 50872], "temperature": 0.0, "avg_logprob": -0.0799687411806999, "compression_ratio": 1.753787878787879, "no_speech_prob": 0.016149481758475304}, {"id": 170, "seek": 109920, "start": 1109.3600000000001, "end": 1116.56, "text": " abide by the contract. Otherwise, if we don't use cloneable, you're usually better off providing", "tokens": [50872, 39663, 538, 264, 4364, 13, 10328, 11, 498, 321, 500, 380, 764, 26506, 712, 11, 291, 434, 2673, 1101, 766, 6530, 51232], "temperature": 0.0, "avg_logprob": -0.0799687411806999, "compression_ratio": 1.753787878787879, "no_speech_prob": 0.016149481758475304}, {"id": 171, "seek": 109920, "start": 1116.56, "end": 1121.6000000000001, "text": " an alternative means of object copying. Here's where we get to what I said before. A better", "tokens": [51232, 364, 8535, 1355, 295, 2657, 27976, 13, 1692, 311, 689, 321, 483, 281, 437, 286, 848, 949, 13, 316, 1101, 51484], "temperature": 0.0, "avg_logprob": -0.0799687411806999, "compression_ratio": 1.753787878787879, "no_speech_prob": 0.016149481758475304}, {"id": 172, "seek": 109920, "start": 1121.6000000000001, "end": 1128.8, "text": " approach to object copying is to provide a copy constructor or copy factory. A copy constructor", "tokens": [51484, 3109, 281, 2657, 27976, 307, 281, 2893, 257, 5055, 47479, 420, 5055, 9265, 13, 316, 5055, 47479, 51844], "temperature": 0.0, "avg_logprob": -0.0799687411806999, "compression_ratio": 1.753787878787879, "no_speech_prob": 0.016149481758475304}, {"id": 173, "seek": 112880, "start": 1128.8799999999999, "end": 1134.48, "text": " is simply a constructor that takes a single argument whose type is the class containing the", "tokens": [50368, 307, 2935, 257, 47479, 300, 2516, 257, 2167, 6770, 6104, 2010, 307, 264, 1508, 19273, 264, 50648], "temperature": 0.0, "avg_logprob": -0.08988740709092882, "compression_ratio": 1.7572463768115942, "no_speech_prob": 0.002148806117475033}, {"id": 174, "seek": 112880, "start": 1134.48, "end": 1139.12, "text": " constructor, for example. Now, this was really interesting. I don't think I've actually worked", "tokens": [50648, 47479, 11, 337, 1365, 13, 823, 11, 341, 390, 534, 1880, 13, 286, 500, 380, 519, 286, 600, 767, 2732, 50880], "temperature": 0.0, "avg_logprob": -0.08988740709092882, "compression_ratio": 1.7572463768115942, "no_speech_prob": 0.002148806117475033}, {"id": 175, "seek": 112880, "start": 1139.12, "end": 1143.36, "text": " with a copy constructor before. So I found this part quite interesting, despite it coming towards the", "tokens": [50880, 365, 257, 5055, 47479, 949, 13, 407, 286, 1352, 341, 644, 1596, 1880, 11, 7228, 309, 1348, 3030, 264, 51092], "temperature": 0.0, "avg_logprob": -0.08988740709092882, "compression_ratio": 1.7572463768115942, "no_speech_prob": 0.002148806117475033}, {"id": 176, "seek": 112880, "start": 1143.36, "end": 1148.96, "text": " end of the item to kind of finalize and conclude on what he was trying to outline in this item.", "tokens": [51092, 917, 295, 264, 3174, 281, 733, 295, 2572, 1125, 293, 16886, 322, 437, 415, 390, 1382, 281, 16387, 294, 341, 3174, 13, 51372], "temperature": 0.0, "avg_logprob": -0.08988740709092882, "compression_ratio": 1.7572463768115942, "no_speech_prob": 0.002148806117475033}, {"id": 177, "seek": 112880, "start": 1149.9199999999998, "end": 1156.24, "text": " So firstly, again, this is what the implementation or the signature of a copy constructor would look", "tokens": [51420, 407, 27376, 11, 797, 11, 341, 307, 437, 264, 11420, 420, 264, 13397, 295, 257, 5055, 47479, 576, 574, 51736], "temperature": 0.0, "avg_logprob": -0.08988740709092882, "compression_ratio": 1.7572463768115942, "no_speech_prob": 0.002148806117475033}, {"id": 178, "seek": 115624, "start": 1156.24, "end": 1162.96, "text": " like and then the copy factory. Similar kind of signature, but obviously the way it's implemented", "tokens": [50364, 411, 293, 550, 264, 5055, 9265, 13, 10905, 733, 295, 13397, 11, 457, 2745, 264, 636, 309, 311, 12270, 50700], "temperature": 0.0, "avg_logprob": -0.1431251238751155, "compression_ratio": 1.5662650602409638, "no_speech_prob": 0.0034830900840461254}, {"id": 179, "seek": 115624, "start": 1162.96, "end": 1169.2, "text": " is different. So the right, in fact, many advantages to using a copy constructor over a clone method.", "tokens": [50700, 307, 819, 13, 407, 264, 558, 11, 294, 1186, 11, 867, 14906, 281, 1228, 257, 5055, 47479, 670, 257, 26506, 3170, 13, 51012], "temperature": 0.0, "avg_logprob": -0.1431251238751155, "compression_ratio": 1.5662650602409638, "no_speech_prob": 0.0034830900840461254}, {"id": 180, "seek": 115624, "start": 1169.92, "end": 1177.1200000000001, "text": " Firstly, something that I think I touched on in part one, a clone method can be extra linguistic.", "tokens": [51048, 20042, 11, 746, 300, 286, 519, 286, 9828, 322, 294, 644, 472, 11, 257, 26506, 3170, 393, 312, 2857, 43002, 13, 51408], "temperature": 0.0, "avg_logprob": -0.1431251238751155, "compression_ratio": 1.5662650602409638, "no_speech_prob": 0.0034830900840461254}, {"id": 181, "seek": 115624, "start": 1177.1200000000001, "end": 1183.6, "text": " And what I mean by that is that generally a good rule of thumb in Java or OOP programming is", "tokens": [51408, 400, 437, 286, 914, 538, 300, 307, 300, 5101, 257, 665, 4978, 295, 9298, 294, 10745, 420, 422, 12059, 9410, 307, 51732], "temperature": 0.0, "avg_logprob": -0.1431251238751155, "compression_ratio": 1.5662650602409638, "no_speech_prob": 0.0034830900840461254}, {"id": 182, "seek": 118360, "start": 1184.48, "end": 1189.1999999999998, "text": " only a constructor should create a new method. Sorry, one of my sign. Only a constructor should", "tokens": [50408, 787, 257, 47479, 820, 1884, 257, 777, 3170, 13, 4919, 11, 472, 295, 452, 1465, 13, 5686, 257, 47479, 820, 50644], "temperature": 0.0, "avg_logprob": -0.13780482032082297, "compression_ratio": 1.853061224489796, "no_speech_prob": 0.0016224910505115986}, {"id": 183, "seek": 118360, "start": 1189.1999999999998, "end": 1193.76, "text": " create a new object. But obviously the clone method creates a new object, making it extra", "tokens": [50644, 1884, 257, 777, 2657, 13, 583, 2745, 264, 26506, 3170, 7829, 257, 777, 2657, 11, 1455, 309, 2857, 50872], "temperature": 0.0, "avg_logprob": -0.13780482032082297, "compression_ratio": 1.853061224489796, "no_speech_prob": 0.0016224910505115986}, {"id": 184, "seek": 118360, "start": 1193.76, "end": 1200.7199999999998, "text": " linguistic. And since it is doing it in a kind of a unforeseeable adherence to", "tokens": [50872, 43002, 13, 400, 1670, 309, 307, 884, 309, 294, 257, 733, 295, 257, 517, 845, 17109, 712, 30106, 655, 281, 51220], "temperature": 0.0, "avg_logprob": -0.13780482032082297, "compression_ratio": 1.853061224489796, "no_speech_prob": 0.0016224910505115986}, {"id": 185, "seek": 118360, "start": 1201.84, "end": 1207.52, "text": " purely documented conventions, it's doing it in a way that's not conventional to how an object", "tokens": [51276, 17491, 23007, 33520, 11, 309, 311, 884, 309, 294, 257, 636, 300, 311, 406, 16011, 281, 577, 364, 2657, 51560], "temperature": 0.0, "avg_logprob": -0.13780482032082297, "compression_ratio": 1.853061224489796, "no_speech_prob": 0.0016224910505115986}, {"id": 186, "seek": 118360, "start": 1207.52, "end": 1212.8, "text": " would be created. It can create issues. And the documentation isn't that good. At least that's", "tokens": [51560, 576, 312, 2942, 13, 467, 393, 1884, 2663, 13, 400, 264, 14333, 1943, 380, 300, 665, 13, 1711, 1935, 300, 311, 51824], "temperature": 0.0, "avg_logprob": -0.13780482032082297, "compression_ratio": 1.853061224489796, "no_speech_prob": 0.0016224910505115986}, {"id": 187, "seek": 121280, "start": 1212.8, "end": 1218.1599999999999, "text": " where Joshua Block states. Now with the copy construct, the constructor, it is in fact creating", "tokens": [50364, 689, 24005, 17500, 4368, 13, 823, 365, 264, 5055, 7690, 11, 264, 47479, 11, 309, 307, 294, 1186, 4084, 50632], "temperature": 0.0, "avg_logprob": -0.1706567197232633, "compression_ratio": 1.9915254237288136, "no_speech_prob": 0.0016227373853325844}, {"id": 188, "seek": 121280, "start": 1218.1599999999999, "end": 1223.2, "text": " a new object. You create a new object. So when the copy construct is being implemented, you", "tokens": [50632, 257, 777, 2657, 13, 509, 1884, 257, 777, 2657, 13, 407, 562, 264, 5055, 7690, 307, 885, 12270, 11, 291, 50884], "temperature": 0.0, "avg_logprob": -0.1706567197232633, "compression_ratio": 1.9915254237288136, "no_speech_prob": 0.0016227373853325844}, {"id": 189, "seek": 121280, "start": 1223.2, "end": 1230.1599999999999, "text": " probably see here, we pass a new object into the copy constructor, and it's that that that", "tokens": [50884, 1391, 536, 510, 11, 321, 1320, 257, 777, 2657, 666, 264, 5055, 47479, 11, 293, 309, 311, 300, 300, 300, 51232], "temperature": 0.0, "avg_logprob": -0.1706567197232633, "compression_ratio": 1.9915254237288136, "no_speech_prob": 0.0016227373853325844}, {"id": 190, "seek": 121280, "start": 1230.1599999999999, "end": 1235.9199999999998, "text": " does the copying to the new object from the current object. So the construct or the constructor itself", "tokens": [51232, 775, 264, 27976, 281, 264, 777, 2657, 490, 264, 2190, 2657, 13, 407, 264, 7690, 420, 264, 47479, 2564, 51520], "temperature": 0.0, "avg_logprob": -0.1706567197232633, "compression_ratio": 1.9915254237288136, "no_speech_prob": 0.0016227373853325844}, {"id": 191, "seek": 121280, "start": 1235.9199999999998, "end": 1242.08, "text": " in this case, doesn't do any work of creating new objects and whatnot. All it's doing is", "tokens": [51520, 294, 341, 1389, 11, 1177, 380, 360, 604, 589, 295, 4084, 777, 6565, 293, 25882, 13, 1057, 309, 311, 884, 307, 51828], "temperature": 0.0, "avg_logprob": -0.1706567197232633, "compression_ratio": 1.9915254237288136, "no_speech_prob": 0.0016227373853325844}, {"id": 192, "seek": 124208, "start": 1242.08, "end": 1246.32, "text": " taking in the past object and then doing the copy. And the other advantage of using a copy", "tokens": [50364, 1940, 294, 264, 1791, 2657, 293, 550, 884, 264, 5055, 13, 400, 264, 661, 5002, 295, 1228, 257, 5055, 50576], "temperature": 0.0, "avg_logprob": -0.11511730714277787, "compression_ratio": 1.749063670411985, "no_speech_prob": 0.0019265450537204742}, {"id": 193, "seek": 124208, "start": 1246.32, "end": 1252.8, "text": " constructor would be that when it comes to final classes or immutable classes, if you have this", "tokens": [50576, 47479, 576, 312, 300, 562, 309, 1487, 281, 2572, 5359, 420, 3397, 32148, 5359, 11, 498, 291, 362, 341, 50900], "temperature": 0.0, "avg_logprob": -0.11511730714277787, "compression_ratio": 1.749063670411985, "no_speech_prob": 0.0019265450537204742}, {"id": 194, "seek": 124208, "start": 1252.8, "end": 1257.28, "text": " immutable point class, so the first class I was showing you was point, but now we have another", "tokens": [50900, 3397, 32148, 935, 1508, 11, 370, 264, 700, 1508, 286, 390, 4099, 291, 390, 935, 11, 457, 586, 321, 362, 1071, 51124], "temperature": 0.0, "avg_logprob": -0.11511730714277787, "compression_ratio": 1.749063670411985, "no_speech_prob": 0.0019265450537204742}, {"id": 195, "seek": 124208, "start": 1257.28, "end": 1264.6399999999999, "text": " variant of it that is immutable. We've used the final keyword. When using the clone method,", "tokens": [51124, 17501, 295, 309, 300, 307, 3397, 32148, 13, 492, 600, 1143, 264, 2572, 20428, 13, 1133, 1228, 264, 26506, 3170, 11, 51492], "temperature": 0.0, "avg_logprob": -0.11511730714277787, "compression_ratio": 1.749063670411985, "no_speech_prob": 0.0019265450537204742}, {"id": 196, "seek": 124208, "start": 1264.6399999999999, "end": 1270.96, "text": " there can be issues when copying across final fields. Now this again wouldn't happen with the", "tokens": [51492, 456, 393, 312, 2663, 562, 27976, 2108, 2572, 7909, 13, 823, 341, 797, 2759, 380, 1051, 365, 264, 51808], "temperature": 0.0, "avg_logprob": -0.11511730714277787, "compression_ratio": 1.749063670411985, "no_speech_prob": 0.0019265450537204742}, {"id": 197, "seek": 127096, "start": 1270.96, "end": 1276.0, "text": " copy constructor because again, we're creating a new object outside the constructor and passing it", "tokens": [50364, 5055, 47479, 570, 797, 11, 321, 434, 4084, 257, 777, 2657, 2380, 264, 47479, 293, 8437, 309, 50616], "temperature": 0.0, "avg_logprob": -0.10389047577267602, "compression_ratio": 1.7912621359223302, "no_speech_prob": 0.0007792905671522021}, {"id": 198, "seek": 127096, "start": 1276.0, "end": 1281.8400000000001, "text": " into the method and then doing the copy. And another advantage is that a copy constructor", "tokens": [50616, 666, 264, 3170, 293, 550, 884, 264, 5055, 13, 400, 1071, 5002, 307, 300, 257, 5055, 47479, 50908], "temperature": 0.0, "avg_logprob": -0.10389047577267602, "compression_ratio": 1.7912621359223302, "no_speech_prob": 0.0007792905671522021}, {"id": 199, "seek": 127096, "start": 1281.8400000000001, "end": 1288.64, "text": " doesn't require casting because what we're doing is, as I said a couple of times already,", "tokens": [50908, 1177, 380, 3651, 17301, 570, 437, 321, 434, 884, 307, 11, 382, 286, 848, 257, 1916, 295, 1413, 1217, 11, 51248], "temperature": 0.0, "avg_logprob": -0.10389047577267602, "compression_ratio": 1.7912621359223302, "no_speech_prob": 0.0007792905671522021}, {"id": 200, "seek": 127096, "start": 1289.6000000000001, "end": 1295.76, "text": " the new object we create is already of type whatever the class is, and that's what we pass", "tokens": [51296, 264, 777, 2657, 321, 1884, 307, 1217, 295, 2010, 2035, 264, 1508, 307, 11, 293, 300, 311, 437, 321, 1320, 51604], "temperature": 0.0, "avg_logprob": -0.10389047577267602, "compression_ratio": 1.7912621359223302, "no_speech_prob": 0.0007792905671522021}, {"id": 201, "seek": 129576, "start": 1295.84, "end": 1300.32, "text": " into the copy constructor. So if you use a clone method, for instance, you need to", "tokens": [50368, 666, 264, 5055, 47479, 13, 407, 498, 291, 764, 257, 26506, 3170, 11, 337, 5197, 11, 291, 643, 281, 50592], "temperature": 0.0, "avg_logprob": -0.09233381067003522, "compression_ratio": 1.741444866920152, "no_speech_prob": 0.08150305598974228}, {"id": 202, "seek": 129576, "start": 1300.32, "end": 1305.2, "text": " do this kind of casting, which can be a bit of a pain. Oh, and as I said before, the copy", "tokens": [50592, 360, 341, 733, 295, 17301, 11, 597, 393, 312, 257, 857, 295, 257, 1822, 13, 876, 11, 293, 382, 286, 848, 949, 11, 264, 5055, 50836], "temperature": 0.0, "avg_logprob": -0.09233381067003522, "compression_ratio": 1.741444866920152, "no_speech_prob": 0.08150305598974228}, {"id": 203, "seek": 129576, "start": 1305.2, "end": 1309.84, "text": " constructor doesn't have the issue with throwing unnecessary checked exceptions and whatnot,", "tokens": [50836, 47479, 1177, 380, 362, 264, 2734, 365, 10238, 19350, 10033, 22847, 293, 25882, 11, 51068], "temperature": 0.0, "avg_logprob": -0.09233381067003522, "compression_ratio": 1.741444866920152, "no_speech_prob": 0.08150305598974228}, {"id": 204, "seek": 129576, "start": 1309.84, "end": 1316.64, "text": " which is again a part of the clone architecture. So this is an example. I was showing you the", "tokens": [51068, 597, 307, 797, 257, 644, 295, 264, 26506, 9482, 13, 407, 341, 307, 364, 1365, 13, 286, 390, 4099, 291, 264, 51408], "temperature": 0.0, "avg_logprob": -0.09233381067003522, "compression_ratio": 1.741444866920152, "no_speech_prob": 0.08150305598974228}, {"id": 205, "seek": 129576, "start": 1317.28, "end": 1320.72, "text": " copy constructor and I'm going through this code quite, quite quickly today. I'm sorry about that.", "tokens": [51440, 5055, 47479, 293, 286, 478, 516, 807, 341, 3089, 1596, 11, 1596, 2661, 965, 13, 286, 478, 2597, 466, 300, 13, 51612], "temperature": 0.0, "avg_logprob": -0.09233381067003522, "compression_ratio": 1.741444866920152, "no_speech_prob": 0.08150305598974228}, {"id": 206, "seek": 132072, "start": 1320.72, "end": 1326.48, "text": " I'm in a bit of a hurry. But obviously, all of it will be available on GitHub. You could go take", "tokens": [50364, 286, 478, 294, 257, 857, 295, 257, 11025, 13, 583, 2745, 11, 439, 295, 309, 486, 312, 2435, 322, 23331, 13, 509, 727, 352, 747, 50652], "temperature": 0.0, "avg_logprob": -0.13356097057612257, "compression_ratio": 1.6160337552742616, "no_speech_prob": 0.009266863577067852}, {"id": 207, "seek": 132072, "start": 1326.48, "end": 1332.8, "text": " a look at it and go through it carefully. Here we have an example of how the copy factory would", "tokens": [50652, 257, 574, 412, 309, 293, 352, 807, 309, 7500, 13, 1692, 321, 362, 364, 1365, 295, 577, 264, 5055, 9265, 576, 50968], "temperature": 0.0, "avg_logprob": -0.13356097057612257, "compression_ratio": 1.6160337552742616, "no_speech_prob": 0.009266863577067852}, {"id": 208, "seek": 132072, "start": 1332.8, "end": 1337.84, "text": " work. It's quite similar to, it's just a static factory method. So it's similar to the copy", "tokens": [50968, 589, 13, 467, 311, 1596, 2531, 281, 11, 309, 311, 445, 257, 13437, 9265, 3170, 13, 407, 309, 311, 2531, 281, 264, 5055, 51220], "temperature": 0.0, "avg_logprob": -0.13356097057612257, "compression_ratio": 1.6160337552742616, "no_speech_prob": 0.009266863577067852}, {"id": 209, "seek": 132072, "start": 1337.84, "end": 1345.28, "text": " constructor. It still does the copying and returns a new point by doing the copy fields in the new", "tokens": [51220, 47479, 13, 467, 920, 775, 264, 27976, 293, 11247, 257, 777, 935, 538, 884, 264, 5055, 7909, 294, 264, 777, 51592], "temperature": 0.0, "avg_logprob": -0.13356097057612257, "compression_ratio": 1.6160337552742616, "no_speech_prob": 0.009266863577067852}, {"id": 210, "seek": 134528, "start": 1345.28, "end": 1351.28, "text": " object. Another advantage is that a copy constructor factory allows you to take in", "tokens": [50364, 2657, 13, 3996, 5002, 307, 300, 257, 5055, 47479, 9265, 4045, 291, 281, 747, 294, 50664], "temperature": 0.0, "avg_logprob": -0.18209766206287203, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.014279496856033802}, {"id": 211, "seek": 134528, "start": 1351.92, "end": 1362.32, "text": " an argument as a type, as type argument, when implementing the method or when using the method", "tokens": [50696, 364, 6770, 382, 257, 2010, 11, 382, 2010, 6770, 11, 562, 18114, 264, 3170, 420, 562, 1228, 264, 3170, 51216], "temperature": 0.0, "avg_logprob": -0.18209766206287203, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.014279496856033802}, {"id": 212, "seek": 134528, "start": 1362.32, "end": 1366.56, "text": " as a client, you can pass in the type and that will return you an object of that type. So an", "tokens": [51216, 382, 257, 6423, 11, 291, 393, 1320, 294, 264, 2010, 293, 300, 486, 2736, 291, 364, 2657, 295, 300, 2010, 13, 407, 364, 51428], "temperature": 0.0, "avg_logprob": -0.18209766206287203, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.014279496856033802}, {"id": 213, "seek": 134528, "start": 1366.56, "end": 1371.2, "text": " example that just should look as highlighted is between hash and entry sets of assume you have", "tokens": [51428, 1365, 300, 445, 820, 574, 382, 17173, 307, 1296, 22019, 293, 8729, 6352, 295, 6552, 291, 362, 51660], "temperature": 0.0, "avg_logprob": -0.18209766206287203, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.014279496856033802}, {"id": 214, "seek": 137120, "start": 1371.68, "end": 1378.56, "text": " hash set defined like this of type string and you have an hash set. And then if you want to, so", "tokens": [50388, 22019, 992, 7642, 411, 341, 295, 2010, 6798, 293, 291, 362, 364, 22019, 992, 13, 400, 550, 498, 291, 528, 281, 11, 370, 50732], "temperature": 0.0, "avg_logprob": -0.17130199432373047, "compression_ratio": 1.7557603686635945, "no_speech_prob": 0.00818593055009842}, {"id": 215, "seek": 137120, "start": 1378.56, "end": 1385.04, "text": " hash, hash set S. And if you want to copy that across to, let's say a tree set, simply all we", "tokens": [50732, 22019, 11, 22019, 992, 318, 13, 400, 498, 291, 528, 281, 5055, 300, 2108, 281, 11, 718, 311, 584, 257, 4230, 992, 11, 2935, 439, 321, 51056], "temperature": 0.0, "avg_logprob": -0.17130199432373047, "compression_ratio": 1.7557603686635945, "no_speech_prob": 0.00818593055009842}, {"id": 216, "seek": 137120, "start": 1385.04, "end": 1394.0800000000002, "text": " got to do is to go new instance of tree set and then pass in that object with the type tree set", "tokens": [51056, 658, 281, 360, 307, 281, 352, 777, 5197, 295, 4230, 992, 293, 550, 1320, 294, 300, 2657, 365, 264, 2010, 4230, 992, 51508], "temperature": 0.0, "avg_logprob": -0.17130199432373047, "compression_ratio": 1.7557603686635945, "no_speech_prob": 0.00818593055009842}, {"id": 217, "seek": 137120, "start": 1394.0800000000002, "end": 1400.24, "text": " and let it do the conversion automatically. And this is allowed as to how the copy constructors", "tokens": [51508, 293, 718, 309, 360, 264, 14298, 6772, 13, 400, 341, 307, 4350, 382, 281, 577, 264, 5055, 7690, 830, 51816], "temperature": 0.0, "avg_logprob": -0.17130199432373047, "compression_ratio": 1.7557603686635945, "no_speech_prob": 0.00818593055009842}, {"id": 218, "seek": 140024, "start": 1400.8, "end": 1408.0, "text": " implemented in hash set. So this won't be possible with the clone object. Oh, sorry,", "tokens": [50392, 12270, 294, 22019, 992, 13, 407, 341, 1582, 380, 312, 1944, 365, 264, 26506, 2657, 13, 876, 11, 2597, 11, 50752], "temperature": 0.0, "avg_logprob": -0.11766864314223781, "compression_ratio": 1.5420168067226891, "no_speech_prob": 0.008983872830867767}, {"id": 219, "seek": 140024, "start": 1408.0, "end": 1413.76, "text": " with the clone method. I'm gonna get a bit tired clearly. Alrighty, that's it. That was part two.", "tokens": [50752, 365, 264, 26506, 3170, 13, 286, 478, 799, 483, 257, 857, 5868, 4448, 13, 43301, 11, 300, 311, 309, 13, 663, 390, 644, 732, 13, 51040], "temperature": 0.0, "avg_logprob": -0.11766864314223781, "compression_ratio": 1.5420168067226891, "no_speech_prob": 0.008983872830867767}, {"id": 220, "seek": 140024, "start": 1413.76, "end": 1421.52, "text": " I hope all of that makes sense. If I wasn't clear on certain parts, I apologize. I wrote the", "tokens": [51040, 286, 1454, 439, 295, 300, 1669, 2020, 13, 759, 286, 2067, 380, 1850, 322, 1629, 3166, 11, 286, 12328, 13, 286, 4114, 264, 51428], "temperature": 0.0, "avg_logprob": -0.11766864314223781, "compression_ratio": 1.5420168067226891, "no_speech_prob": 0.008983872830867767}, {"id": 221, "seek": 140024, "start": 1421.52, "end": 1426.24, "text": " script a while back and I got really busy so I couldn't record the video. But all the codes", "tokens": [51428, 5755, 257, 1339, 646, 293, 286, 658, 534, 5856, 370, 286, 2809, 380, 2136, 264, 960, 13, 583, 439, 264, 14211, 51664], "temperature": 0.0, "avg_logprob": -0.11766864314223781, "compression_ratio": 1.5420168067226891, "no_speech_prob": 0.008983872830867767}, {"id": 222, "seek": 142624, "start": 1426.24, "end": 1433.04, "text": " available on GitHub and I've kind of commented what I've done so that it kind of makes sense,", "tokens": [50364, 2435, 322, 23331, 293, 286, 600, 733, 295, 26940, 437, 286, 600, 1096, 370, 300, 309, 733, 295, 1669, 2020, 11, 50704], "temperature": 0.0, "avg_logprob": -0.10916410333970014, "compression_ratio": 1.6085106382978724, "no_speech_prob": 0.007344513200223446}, {"id": 223, "seek": 142624, "start": 1433.04, "end": 1438.32, "text": " despite some of it not being complete code rather being blueprints. But to conclude, Joshua Block", "tokens": [50704, 7228, 512, 295, 309, 406, 885, 3566, 3089, 2831, 885, 888, 23547, 47523, 13, 583, 281, 16886, 11, 24005, 17500, 50968], "temperature": 0.0, "avg_logprob": -0.10916410333970014, "compression_ratio": 1.6085106382978724, "no_speech_prob": 0.007344513200223446}, {"id": 224, "seek": 142624, "start": 1438.32, "end": 1445.92, "text": " states, given all the problems associated with cloneable new interfaces should not extend it", "tokens": [50968, 4368, 11, 2212, 439, 264, 2740, 6615, 365, 26506, 712, 777, 28416, 820, 406, 10101, 309, 51348], "temperature": 0.0, "avg_logprob": -0.10916410333970014, "compression_ratio": 1.6085106382978724, "no_speech_prob": 0.007344513200223446}, {"id": 225, "seek": 142624, "start": 1445.92, "end": 1454.08, "text": " and new extendable classes should not implement it. While it's less harmful for final classes", "tokens": [51348, 293, 777, 10101, 712, 5359, 820, 406, 4445, 309, 13, 3987, 309, 311, 1570, 19727, 337, 2572, 5359, 51756], "temperature": 0.0, "avg_logprob": -0.10916410333970014, "compression_ratio": 1.6085106382978724, "no_speech_prob": 0.007344513200223446}, {"id": 226, "seek": 145408, "start": 1454.08, "end": 1459.6799999999998, "text": " to implement cloneable, this should be viewed as a performance optimization reserved for the rare", "tokens": [50364, 281, 4445, 26506, 712, 11, 341, 820, 312, 19174, 382, 257, 3389, 19618, 24819, 337, 264, 5892, 50644], "temperature": 0.0, "avg_logprob": -0.10729051771618071, "compression_ratio": 1.6652360515021458, "no_speech_prob": 0.009266417473554611}, {"id": 227, "seek": 145408, "start": 1459.6799999999998, "end": 1466.08, "text": " cases where it is justified. As a rule, copy functionality is best provided by constructors", "tokens": [50644, 3331, 689, 309, 307, 27808, 13, 1018, 257, 4978, 11, 5055, 14980, 307, 1151, 5649, 538, 7690, 830, 50964], "temperature": 0.0, "avg_logprob": -0.10729051771618071, "compression_ratio": 1.6652360515021458, "no_speech_prob": 0.009266417473554611}, {"id": 228, "seek": 145408, "start": 1466.08, "end": 1471.4399999999998, "text": " or factories, which we saw with the copy constructing the copy factory and all the advantages they have", "tokens": [50964, 420, 24813, 11, 597, 321, 1866, 365, 264, 5055, 39969, 264, 5055, 9265, 293, 439, 264, 14906, 436, 362, 51232], "temperature": 0.0, "avg_logprob": -0.10729051771618071, "compression_ratio": 1.6652360515021458, "no_speech_prob": 0.009266417473554611}, {"id": 229, "seek": 145408, "start": 1471.4399999999998, "end": 1477.52, "text": " for us. A notable exception to this rule is areas which are best copied with the clone method.", "tokens": [51232, 337, 505, 13, 316, 22556, 11183, 281, 341, 4978, 307, 3179, 597, 366, 1151, 25365, 365, 264, 26506, 3170, 13, 51536], "temperature": 0.0, "avg_logprob": -0.10729051771618071, "compression_ratio": 1.6652360515021458, "no_speech_prob": 0.009266417473554611}, {"id": 230, "seek": 147752, "start": 1477.52, "end": 1483.04, "text": " Alrighty, that was item 13 and I hope you found that useful and I'll see you in the next one,", "tokens": [50364, 43301, 11, 300, 390, 3174, 3705, 293, 286, 1454, 291, 1352, 300, 4420, 293, 286, 603, 536, 291, 294, 264, 958, 472, 11, 50640], "temperature": 0.0, "avg_logprob": -0.247591312115009, "compression_ratio": 1.2540983606557377, "no_speech_prob": 0.006094549782574177}, {"id": 231, "seek": 147752, "start": 1483.04, "end": 1488.72, "text": " item 14, which is consider implementing comparable. Cheers.", "tokens": [50640, 3174, 3499, 11, 597, 307, 1949, 18114, 25323, 13, 13006, 13, 50924], "temperature": 0.0, "avg_logprob": -0.247591312115009, "compression_ratio": 1.2540983606557377, "no_speech_prob": 0.006094549782574177}], "language": "en"}