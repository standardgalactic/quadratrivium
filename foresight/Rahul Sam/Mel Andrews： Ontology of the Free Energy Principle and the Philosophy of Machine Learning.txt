in this episode.
So there's a long history in 20th century philosophy of science of investigating the
possibility of something like an automated science or a formalized science or a algorithmically
implemented science, all aspects of science, including sort of uncovering theory.
And this has been a rich tradition, but it's been strictly abstract about about hypothetical
machines and hypothetical algorithms and hypothetical forms of automation of scientific labor rights.
And all of a sudden sort of perhaps largely unanticipated by philosophers, we reach a
point where boom, deep learning revolution, and suddenly there is a kind of massive shift
towards taking aspects of scientific discovery and passing them off to a intelligent computational
system.
And I think there's been kind of a tendency to continue to view that within the lens of
this automation of scientific discovery debates as it's existed without really attending to
the details of how these technologies are in fact being implemented in scientific practice.
And by the way, I think when, when what we are doing is collecting data from some system
in the world and using some machine learning model to extract statistical patterns from
that system in order to learn about that system, what we're doing is is effectively science.
It follows the model of science.
So in fact, most applications of machine learning ought to be considered a kind of science
adjacent activity.
And in my opinion, it held to the standards of good science.
Hey, everyone, welcome to my conversation with the philosopher of science, Mel Andrews,
who's doing work in machine learning and other adjacent fields such as the philosophy of
mathematics, epistemology, and of course, ethics.
It was a fantastic, cordial and riveting conversation for me.
And I should first say it's good to be back.
It's good to be back after my short holiday back doing podcasts, having these fascinating
conversations with these superlative guests.
And I couldn't think of a better person to start off with other than Mel.
They is fascinating.
They also has this way of kind of, you know, elucidating certain points that for a while
I did struggle to understand.
And of course, probably the best example would be this paper, the math is not the territory
navigating the free energy principle.
As someone who's deeply interested in the kind of philosophy of FEP, this paper really
helped me understand what the ontology of the free energy principle is and what really
is the proper way to view it as a kind of a mathematical, formalistic, conceptual framework
that can be applied in many areas such as machine learning and of course cognitive science.
But we did start the podcast discussing Mel's recent paper regarding the epistemic status
of machine learning and they provocatively claimed that machine learning has a pseudo
science problem which I vehemently agree with and even kind of brought up this resurgence
of physiognomy kind of provocatively to make this point.
It's a preprint, in fact, and we discussed a bit of that paper and kind of extrapolated
some of those ideas into the broader socio-political discussion around AI ethics, which again is
very interesting.
And I do really appreciate that Mel is a very critical almost focodian analysis of these
different disciplines that are getting a lot of attention these days such as AI and machine
learning of course.
I also mentioned to Mel that this credit feed is a place that I visit quite often online.
I hate Twitter, I think Twitter is a hellscape, however there are a few accounts that I've
bookmarked and I do frequently visit simply for entertainment but also to learn and Mel's
Twitter feed is certainly one of those that are bookmarked.
Having said that, before I get carried away talking about Twitter and all of that, a bit
of a formal introduction to Mel Andrews is a philosopher of science working on the role
of mathematical and computational methods in science and particular machine learning
based methods.
Mel is currently a predoctoral research associate at the department of machine learning at the
Carnegie Mellon University and doing a PhD in philosophy of science at the University
of Cincinnati.
They are also a visiting scholar at the Australian National University and the University of
Pittsburgh.
Having said that, here's my conversation with Mel Andrews.
So on housekeeping note I should mention that I'll leave links to everything we've discussed
in the show notes.
Okay, now to the podcast.
Mel Andrews
The sort of conclusion I reached eventually was, it just, I mean, in academia there's
a certain portion of what you do that feels like running on a wheel, like it's not, it's
a performance, it's not actually to accomplish anything but it just feels like such a high
percentage of that in industry is just sort of, there's so many levels of removal.
The person who's passing down the orders is so many levels removed from the people actually
implementing solutions that you're almost not accomplishing anything.
Mel Andrews
Yeah, also like, I mean, look, it's, I think, Franz Kafka, he captured it best in his novel,
you know, it's Kafka-esque in the sense that it seems like people are just doing things
for the sake of doing things without really going anywhere and you're having all these,
you know, wonky meetings.
But to be fair though, like, I agree with you because, because I'm still outside of academia,
I've kind of idealized academia, but after talking to a lot of people like yourself on
the podcast, I'm getting a more realistic picture of what it is because at the end of
the day, the university is still in our society, it's a part of our culture within them.
Mel Andrews
And it's beholden to a capitalist economic system.
Mel Andrews
Exactly, exactly.
Yeah, yeah.
And it kind of shows how much the, let's call it the capitalist tentacles reach into every
corner of our social existence.
I mean, although I even go a step further and I say, I mean, I'm a big fan of Jacques,
it even changes our psyche, our subjective state in this world and, and like fundamentally
who we are, as let's say beings in this world, you know, and then that of course affects academics
and, and quote unquote, lay people and everyone really, but I see what you mean.
Yeah, yeah.
So I've got to ask now though.
Mel Andrews
Sorry.
In terms of even like the AI ethics communities, you have like the AI risk, AI safety people,
like existential risk, kind of the effective altruist oriented community.
And you've got then, you know, academic, fairness, safety, regulation communities.
And they're both sort of pointing at each other and accusing each other of like corporate
capture.
But of course, the irony is, is that these communities are both about as corporately
captured as you can.
Yeah.
Yeah.
And every entity really, you know, neoliberal society is corporate captured in some sense,
you know, after the 70s and 80s, it fundamentally changed.
I completely agree with you.
No ethical work, no ethical consumption.
I mean, there's only really a handful of, I'd say at this point, as in some sense I'm
like, well, I am in your fight, but I'd say there's only a handful of researchers who
I follow quite closely, you certainly being one of them.
And then in S and a few others, because as in for me, there's this whole question about
AI ethics and yeah, AI safety, I only find it to be useful when we kind of got it more
from the, let's call it the ontological level of like, what is AI, what is machine learning
as we have it now, and kind of starting at like that very fundamental level ontological
level as you've done, you know, in some of your papers.
Because for me, that gives a lot more hate use to stone because it's kind of cheap, but
like realistic view of where we are with machine learning and AI and where we can go.
Or even sticking to, you know, sticking to the realm of not what is conceivable.
I mean, I think there's a lot of discourse happening at the level of what is conceivable,
what sorts of technologies are conceivable, or what sorts of technologies are metaphysically
possible or what haven't you.
And it's like, well, let's think about what might come into being in the reality we occupy,
because what comes into being in the reality we occupy is governed by market forces.
And we should think about technologies that some person might conceivably be incentivized
and capacitated to build.
If there are technologies that no one would ever be incentivized and capacitated to build,
realistically speaking, I don't think there's much point in debating what their capabilities
are or what the danger is emerging from these technologies would be.
And I think there's a lot of debate that's happening at the level without considering,
you know, incentives.
Truthfully, I think this is, again, the primary sort of access of opposition in the AI ethics
communities or community is between the risk safety people and the sort of fairness responsible
AI people, fact community, et cetera.
And maybe the failing point of both of these communities is, in their scholarship, a total
failure, at least in the major part of the work, to really, really consider incentive
structures.
So the interventions we're suggesting have to be able to work within incentive structures
as they exist or they might conceivably exist.
They have to consider how we might, if the point is to manipulate incentive structures,
we have to have that conversation explicitly.
How are we intending that the intervention we suggest would nudge incentive structures
as they exist?
And I think there's just sort of a failure to consider that in large part in a lot of
the work falling under the age of AI ethics, writ as largely and abstractly as we possibly
can, right?
Undoubtedly, undoubtedly.
Yeah.
I mean, it sounds like a very straightforward thing, but, you know, AI doesn't sit in a silo.
It's always within a, it sits within a psychosocial reality.
I couldn't agree more.
Which is deeply, deeply complex to the point that it, having to think through incentive
structures feels like it makes any problem in this realm completely intractable.
Yeah.
So I get exploits.
Although I want to add, which is where I again like what you're doing, and we'll certainly
get to this in a bit, kind of trying to understand, which is why for me, I think only a philosopher
of science and perhaps even someone with a bit of a background in sociology can kind
of explore the kind of epistemic status of what is machine learning or what is AI in
contemporary times and then maybe speculate and theorize on where it could go and develop
in the future.
Because I'm going to be honest, as more of an outsider, some of this sounds a lot like
science fiction to me and I'm kind of like, are we really even discussing as to what
the current models are, what are large language models, what do they really do without all
of this speculation, which again, the speculation seems just like it's just a bunch of blokes
having fun without considering all the factors that you mentioned, our psychosocial reality,
ways, AI, incentive structure, kind of symbolic network that all comes together, which seems
like an intractable problem, I agree.
Yeah.
But I mean, I think a lot of philosophy is self-gratifying, in a sense.
Oh, for sure.
I mean, I would say a lot of thinking in general.
Yeah.
Yeah.
I'd say a big part of it is for that, because it's self-gratifying, not for any ethical.
Yeah.
I mean, I think I have a very sort of pragmatic embodied view of thinking and it's sort of
a very, I think that goes into sort of pragmatic ethical or political stance as well, where
I think, I mean, I think we think in order to affect action in the world.
Thinking, I don't think thought takes place.
I don't think we can say cognition has really taken place unless we see the hallmarks of
it's in behavior.
So I mean, I actually think I'm a sort of weird behaviorist in the sense that I think
that consciousness and sentience and agency and cognition and a lot of sort of what's
been considered unobservable mental characteristics are actually readable from behavioral dynamics.
And I think that we should not be thinking of philosophy as an eye will pursue.
It impacts the way we go about the world or it ought to be approached as though it's
going to have immediate impact on how we interact with the phenomena it treats as its subject
matter.
Yeah.
I'm just saying I'm fully a pragmatist with respect.
Yeah.
I get you.
But also, I mean, not only as a pragmatist, but I would even say, you know, I've been
deeply interested in psychoanalysis and I've spoken to heaps of psychoanalysts and one misunderstanding
I think a lot of people have coming from like the Carl Jung type is like the idea of depth
psychology where they think the truth of a person's desires and motives are somewhere
deep within and you need like a psychoanalyst to find it.
But the flip is the Freudian more Lacanian idea is no, no, no, that the truth lies in
your actions.
The truth is never like deep within rather it's it's it's very it's very conspicuous.
It's out there.
Hey, you know, and you can see it in in how people act and how people engage in their
social world.
So I can say nothing is really hidden with that.
Yeah.
That's the ultimately come to realize nothing is really hidden.
So you wrote, you've been working on a few papers, kind of working on the epistemic status
of machine learning, which I've thoroughly enjoyed reading and learned a lot.
One of them was this paper I read, this was I read this a while back, which is the machine
learning and the theory free ideal.
I'll leave a link to that in the in the show notes.
But also the recent preprint you shared with me, which I thought was a very good provocative
piece, in fact, titled ghosts in the machine learning, the reanimation of pseudoscience
and its ethical repercussions.
So to perhaps to orient the listeners, if you could kind of give us an introduction as to
yeah, what is what is this work you're doing, researching the epistemic status of machine
learning, apropos philosophy of science, and then perhaps, you know, you know, as a as
carrying on from our ethics conversation or chat, how that how those two ideas are connected,
you know, the epistemic status of machine learning, and then what's its relationship
to ethics.
Yeah.
So there's a long history in 20th century philosophy of science of investigating the
possibility of something like an automated science, or a formalized science, or a algorithmically
implemented science, all aspects of science, including sort of uncovering theory.
And this has been a rich tradition, but it's been strictly abstract about about hypothetical
machines and hypothetical algorithms and hypothetical forms of automation of scientific labor rights.
And all of a sudden, sort of, perhaps largely unanticipated by philosophers, we reach a
point where boom, deep learning revolution.
And suddenly, there is a kind of massive shift towards taking aspects of scientific discovery
and passing them off to a intelligent computational system, right.
And I think there's been kind of a tendency to continue to view that within the lens of of this
automation of scientific discovery debate as it's existed, without really attending to the
details of how these technologies are, in fact, being implemented in scientific practice.
And by the way, I think I think when when what we are doing is collecting data from some system
in the world, and using some machine learning model to extract statistical patterns from that
system in order to learn about that system, what we're doing is effectively science, it follows
the model of science. So in fact, most applications of machine learning ought to be considered a
kind of science adjacent activity. And in my opinion, held to the standards of good science.
Now, I think that there's a lot of good work being done with machine learning and science.
There's a lot of really epistendically careful work. And I think there's also, like with most
things, a glut of garbage, pick a genre of anything. I don't care if it's films or psychological
studies, or books on the history of hip hop, or like whatever it is, or perhaps even people for
that matter. Yeah, yeah, most most of it's crap. Yeah. And there's a very small percentage of it
that's quite good. Machine learning is no different. There's a lot of good work being done, and 1000
fold more bad work being done. The issue is that it's being adopted so rapidly, these methods are
being adopted so rapidly, in so many contexts, across society, most people don't understand how
the technology works. There's a lot of AI hype, as long as there has been AI, there has been AI
hype. And what hype is, I think it should be made explicit that what hype is, is it's a targeted
disinformation campaign. Yeah, perhaps you could elaborate on what you mean by that.
Yeah, so AI hype refers to people, when Sam Altman says, we'll have AGI by X, or when Sam
Altman says, well, GPT three could take a 20 minute activity and reduce it to five minute
activity, but GPT next will reduce a week long activity to five minutes or something like that.
You know, that's AI hype.
Now, I saw I saw a recent statement by, I believe, anyway, I want to mention any names that the next
GPT model will will be able to replace PhD researchers and we won't need any PhD researchers
anymore. So yeah, I'm in shock.
That's AI hype. Scientists and science popularizers saying the theorist will be replaced, the
physicist will be replaced, the doctor will be replaced, you know, in medical context saying,
oh, we won't need, you know, we won't need secretaries or we won't need nurses anymore.
Any of that drama, but it also includes the doomerism about AI, like soon AI will surpass
human intelligence and it will, you know, hurt us somehow.
That's the part which I, for me, at least feels a lot like science fiction, if I'm being honest,
the doomer. Yeah. Yeah. There's something even it's interesting to even science fiction.
I mean, yeah. And I have nothing, nothing against I love science fiction, but it's got his own
status in our dialogue, right? I mean, science fiction, it's called fiction.
But saying that's, that's some particular tech breakthrough is going to replace
cardiologists even is absolutely, will it, you know, have some impact on the role of
cardiologists in specifically how they approach analyzing the results of imaging,
right? Totally. Is it going to replace cardiologists? No, that's science fiction, right?
And it should, given all technology affects how we do our jobs, how we live our lives,
and that's completely fine. It probably should affect how they do their job.
If it works, it should. That's, that's true. It doesn't work if it can, but if it works,
it should have an impact. It's just that there's, there's,
in anything that's, you know, marketable, there's an incentive to misrepresent
what it does. This is true of, you can pull out a magazine from 1952 and how it's
advertises some cooking implement to stay at home moms. And it misrepresent, you know, it's like,
this is a life changing, it's going to lie to you about what the thing does, right? But
with AI specifically, you know, I think, I think there's just to some extent,
even the, the average housewife in the 1950s was like, yeah, probably, probably not all of this
about the oven is actually the ground truth, you know, whereas with AI, people seem to be willing
to believe really radically untrue things, you know, just things that are actually
to anyone in the know, blatant lies. But there's a culture of
really leaning into highly fabulous lies, propagating them to no end. And no one seems to be doing
fact checking. And the worst part to me is, is, I would think that's in, so I'm, I'm coming from
this position of history and philosophy of science, where it's like, we've studied hundreds and
hundreds of years of science and technology, and how people misrepresent what it does and what it
actually does, right? So we would, I would hope that we would have a critical lens on this. And
it strikes me that there's a lot of philosophy that's simply
parroting or, or lending kind of philosophical justification to these hype narratives that,
you know, deep learning will radically change the face of particle physics or something like
that. It's like, really, really though. Okay, perhaps just, well, this is, this is a good,
good place to go to. So one, one term, which I really liked in the paper, which you use with
this idea of global, the theory free ideal, I really liked that, that, that term. Because I
think for me that captures what apropos philosophy of science or let's, let's say apropos the,
the scientific method, what the hope or the dream with ML models are. So if you could melt, just,
just to like, again, to flesh this out a bit more as, as to where we are right now with the
current paradigm of machine learning, what is the epistemic status of machine learning?
And then could you then probably connect that to what, what, what, what is this theory free ideal?
And then as you point out in your papers, what are the mistakes that people make with, with,
to, you know, by having this ideal of science being theory free when done with a,
let's say an ML model, for instance. Yeah. Yeah. So I think machine learning models are statistical
models that are computationally instantiated. There's, there's nothing that would in principle
make the epistemic status of these technologies any different from
any kind of other statistical model. Now, you're pushing yourself into really high
dimensional spaces in which data is transposed. And so there's intrinsically,
the, the dimensionality of the patterns you're finding is much higher than what you're doing
with classical statistics. But I guess I doubt that when people are doing multiple regression,
they are kind of holding all the dimensions in their head in the way that they would have to be
in order for the contrast that's typically drawn between deep learning and classical statistics
to make sense. Like there's, there's meant to be a kind of opacity, a kind of intrinsic deep
unknowability of the kinds of patterns that these statistical methods that is deep learning methods
are finding relative to classical statistical methods. And I just don't see that distinction being
substantive and absolute in the way that it's proposed to be. I think these are at their heart
statistical methods like other statistical methods. And if there's a difference,
it's a sociological difference. Okay, I think I've followed you all the way except the last bit,
the sociological, but if you could probably touch that up. Yeah, so it's, it's the corporatization
of these technologies. I see. Okay. It's the hype narrative. So even in a research context,
there's because, because machine learning, I mean,
because machine learning is this place where stats met up with AI and AI is something that's
always, AI refers to a lot of different research traditions that have had historically very little
to do with each other in terms of their, their substance in terms of their subject matter in
terms of the methods, they mostly have to do with where funding is being targeted and the kinds of
narratives spun around these research methods. So there's very little substantive that holds
everything that's historically been called AI to going back to cybernetics, going back to McCarthy,
going back to, you know, all the tips and, you know, like going back all through the history of
things being called artificial intelligence. There's very little that connects all of these, but
who they're targeting for funding and the kinds of narratives they're using in
convincing the public and funding bodies of what they're doing. So there are methods and statistics
that have been, you know, approaching something like machine learning, going, going back 80s, 90s,
whatever, right? But where that meets up with the AI narrative, you get this hype and disinformation
and overselling of competence, right? And so there's, there's an attitude and a meta narrative
surrounding machine learning that is, I think, more what sets it apart from classical statistics
than anything else. This is, this is a spicy take, you know, kind of with a grain of salt. But
this is my, my challenge is really like, tell me what is so radically epistemically different
about these technologies that they should be placed in some category that's discrete from
classical statistics. I have not seen it, you know. And you point this out. Yeah. And also,
I guess it's this meta narrative that, that drives its impetus behind this theory free ideal
when it comes to science. Yeah. And, and there's been so philosophers, natural philosophers,
scientists have debated what theory is and what its proper role in science is since the, the
incipients of what we call modern science, right, since Bacon and Newton and Galilea, you know,
modern science, right? Even going back to Bacon, there's, there's, there's a kind of push for a
kind of radical empiricism that pushes away as much as possible the role of theory about just,
just tabulating as much data as possible and sifting through it for patterns and, and not
bringing our kind of conceptual infrastructure to bear on it. But then since Hume,
since Hume brought his sort of problem of induction to the table in epistemology,
there's this widespread recognition that, well, all, all knowledge of the natural world
is knowledge by induction. You do not get deductive certainty about empirical
matters. Yeah. So the typical example is the sunrising just because it rose
yesterday. We can't say necessarily it'll every day of our lives, the sun has risen in the morning.
It's risen. Yeah. Yeah. And yet give me a deductive proof, give me logical certainty
that it will rise tomorrow. There is none. There's only the, the
you know, the remit of our experience to tell us that it will rise tomorrow. There's no
logical necessity that it will rise again tomorrow.
So knowledge of nature, scientific knowledge is, and all our kind of day to day practical
knowledge, like I can eat this bread and it won't poison me because the bread I ate yesterday that
I got from the same baker didn't poison me. You know, this is inductive knowledge, which means
we don't get deductive certainty. And it also means that to get that kind of knowledge, you need to
start off with rich conceptual infrastructure, which I'm calling theory. I think, I think when,
so I think there are lots of ways that philosophers have traditionally
cashed out what we mean by theory, I think that when we talk about theory free science, we mean
a powerful influence at the beginning of inquiry, at the beginning of the investigatory
procedure of our prior conceptual resources, our prior conceptual
acquaintance with the target phenomena, right? We do not get, we do not get inductive
inference off the ground without bringing to bear prior theory or conceptual.
The philosopher and historian of science, John Norton calls it
bringing to bear material facts, right? But there are lots of ways of putting it, but
you need theory to get empirical knowledge off the ground. And so in this sense,
you cannot have theory free knowledge of natural systems. And I think that
you can look back for hundreds of years, and there's always this dialogue between, no, we should get rid
of as much, as much as we can push away the influence of prior conceptualization, we should do that,
and that's scientific objectivity. This is, I think, one notion of scientific objectivity.
Right? That has been kind of implicitly in the background of a lot of discourse in philosophy,
natural philosophy science for hundreds of years. And then another stream that says,
well, you can't actually have knowledge of nature without bringing conceptual resources to bear.
So it's about documenting them. It's about recognizing them. It's about, to some extent,
those assumptions and saying which of those assumptions are, in fact, substantiated by
what we've then been able to observe and deduce from what we've measured or observed in nature,
right? And what is, in fact, just arbitrary or unknown, right?
And I think since the rise of domain generic statistical methods in the 20th century,
in particular, stats really gets off the ground after the axiomatization of probability theory
with Komagorov. Statistical reasoning, probabilistic reasoning is, to the extent that's so widespread
in science, it's relatively new. It's really a kind of 20th century, like statistical reasoning
is kind of a 20th century thing. I mean, it sort of got off the ground with gambling and stuff in
the 17th century. But as a scientific method, it's new. And really, I think since the mid-20th
century, you get a lot of this, what I call a theory free ideal. And it's in the kind of
fundamental, I don't know if I believe in this destination, but in the more fundamental sciences
who know how to theorize because they've been doing it for hundreds of years and know how to
mathematically represent their phenomena, because they've been doing it for hundreds of years,
you get less of this. But in the younger sciences, like the quantitative social sciences, like
social psychology, like population genetics, what have you, economics, there's this belief that
the more theory free, the more data driven the methods are, the more objective they are and
the more sciencey. Yeah, so when you mean the more fundamental, you mean like physics, for instance,
right? Yeah, areas of, areas of, but not all areas of physics, right? The areas of physics
that are really established. Yeah, although, although, you know, this beautifully connects
with your sociological point, because I'm sure you're aware of the whole Bohr-Einstein debate and
that, you know, shut up and calculate. There's like a lot of, in the history of 20th century
physics, is his idea that even within physics, you shouldn't ask, but given that physics is the,
it's a foundational discipline, the ontology of the physical world, you know, there was a time,
especially because of, you know, World War II and the nukes and all that, just don't ask the,
don't ask the ontological questions, just shut up and calculate, just that there's a
ruthless pragmatism, ruthless, just create. And so physics kind of sometimes, and again, I again
say this as a bit of an outsider, it becomes a bit more like engineering or a foundational
discipline where you're asking, well, what exists, what is reality?
That's sort of the Los Alamos attitude, right?
As in the idea that physics is engineering?
Does that happen and calculate attitudes?
Yeah, yeah, I mean, I know more from the Copenhagen school, I mean, I followed that, I think Tim
Modellin, he speaks quite well about that. And just, it's like a, you know, interesting
peculiarity in the history of physics, especially because if you look at the big figures, like,
like the Einstein's, or like the Maxwell's, they were deeply interested in these philosophical
questions, it's like, what exists, you know, it's not Einstein was a philosopher, he certainly was,
he certainly was, you know, without a doubt. Yeah. I mean, probably after Newton is probably the
quintessential natural philosopher, I couldn't agree more. And yeah, so I mean, just on this note,
I couldn't read the paper too carefully, but I do love the, perhaps it's worth mentioning,
because it's rather provocative and I like that a bit, where you say, yeah, machine learning has
a pseudoscience problem. And then you bring up the, well, you and the other other writers, Andrew
and Bieber, is it? Yeah, bring up. Yeah, yeah, they bring up the idea of how there's a resurgence
of physiognomy in kind of these ML communities. So just, if you could just humor me with that for
a bit, just kind of what all that, that's about why you claim, you know, machine learning has a
pseudoscience problem, which I think you already kind of did outline quite, quite in detail. But
then this little, little example you use on, on physiognomy. Yeah, well, part of it is this sort,
this sort of runaway idea that we can do science without theory that picks up steam in the mid
century. And then with the rise of machine learning techniques, and these being adopted
widely, it just becomes, it becomes, it gets bundled into this hype narrative about how these
technologies work. And then everyone sort of believes that these technologies are capable of
extracting true knowledge of some natural system in virtue of having achieved high
classifier accuracy on some natural data set, right? And what's actually happening is, is researchers
are interpreting that pattern as having discovered precisely whatever their intuitive idea of what
they were going to discover was beforehand. Because if they're not explicitly doing the
theory, if they're not, if they're not explicitly theorizing, then they're implicitly theorizing,
which means that they're effectively trying to con you into believing whatever their intuitions
were at the start of the research procedure, without effectively having furnished evidence of
that, besides having told you that they train some model, and there's some pattern in the data that
satisfied some criteria, right, for success. But I think because of all these hype narratives
surrounding machine learning, and again, not for substantive epistemic differences in how these
statistical methods work, but rather for sociological reasons, you get a lot of bad, bad,
bad science. So if I want to do a quantitative social science study, and I'm in a sociology
department, or an economics department, my advisors won't let me do that until I've
read up on the hundred years long history of scientists in my field having studied that
exact problem, right. Machine learners on the other hand, machine learners don't even read the
history of their own work. Machine, like, it is not typical for someone in machine learning to have
even a five years deep understanding of the history of their own field, right,
which is there are of course exceptions, but the general rule is people in machine learning do not
read. Yeah. And so by you're talking, are you talking about more on the scientific side, or do
you just mean general, you know, commercial ML engineering? Practitioners, but also in academics.
Academics, okay. That's unfortunate. And so when you go to apply ML, you know, everything that's
submitted to Art Tripoli, or, or NeurIPS, or what have you.
ACM, you get just this glut of work of people applying the methods of ML, especially DL, to
some problem that scientists have spent maybe hundreds of years working on. And there's no
acknowledgement that what they're tackling, what they're attempting to tackle is a scientific problem
that some very specific field of, you know, molecular biomechanicists or whatever the field is,
right, have been working on for hundreds of years. And then there's this attitude that
while deep learning will solve the problem, and I don't have to pay my dues and read about the
methods in this field. And then the reviewing practices at, well, you know, part of it's like
we got rid of, we got rid of traditional peer review and machine learning, which is like, was
traditional peer review hopelessly broken? Yes. Did we introduce new problems by getting rid of it
wholesale? Also, yes. Right. And so then you've got, you know, so there aren't standard journals in
machine learning the way they are in biomechanics or biochemistry or socioeconomics or whatever,
right? You are submitting to the big name machine learning conferences, but peer review there is
I mean, I have to say it's pretty radically incumbent. I don't know that I don't think anyone
who reviews for or submits to machine learning venues would try to fight me on that. I mean,
I think the consensus is that the peer review process for these venues is wildly inadequate.
Inadequate, yeah. So and it's because it's because when you apply machine learning,
right, you're applying it to some domain, you're applying it to some domain where there is a vast
history of people trying to solve some problem. And when you submit your little deep learning thing
to IEEE and you're trying to tackle some problem in social science, they're not asking social
scientists to review that. God, no. Right. They're asking other people who trained a, you know,
transformer to with data of that shape, right? But they're not asking people who have the
disciplinary knowledge to review the methods for what actually matters to doing science, right?
Yeah. Yeah. And when do you think this changed? Well, was this, is this imminent to the
practice itself? Or when do you think this change took place where the peer reviewing
method became a bit lax or inadequate as you pointed out?
Well,
it was just sort of an organic thing, right? You have
on the one hand, I mean, it was never the case that it was never the case that there were
people applying machine learning, as far as I know, where it was never the case that people were
applying machine learning to some problem in biology, and then submitting that to a biojournal.
That's not the, I mean, occasionally that happens, right? But that's not standard practice. And I
don't think it ever was. It was also not the case that there were kind of standard journals for,
there were standard journals for stats, right? But there were never kind of standardized deep
learning journals, right? There were, there were computing or stats
conferences that got kind of evolved into ML specific conferences or new ML specific conferences
emerged. And like, you know, a lot of the main ones are actually, they didn't start out as ML
conferences, and they evolved to be ML conferences. But also you have at the same time the emergence
of pre-printing servers. And so you get, you get the emergence of a new kind of, like machine
learning has been machine learning, the methods we call machine learning have been around since
like the 80s, right? You could trace it back earlier to kind of proto machine learning methods.
Those go back much, I mean, again, like, it was out of World War II, it was out of the research
at Los Alamos, that you got like MCMC sampling, right? Like Mark O'Chain Monte Carlo sampling,
like Metropolis Hastings sampling. I didn't know that. Yeah. Yeah, it goes back to like the early
50s, late 40s, early 50s. So even before that's kind of machine learning, right? Yeah.
But, but, you know, machine learning as it's the early 2000s that machine learning kind of
goes like, hey, we're a scientific field, or hey, we're an engineering discipline, like we're a
discipline now, right? And it's at the same time that you're getting pre-printing servers as the
sort of way that that stuff is disseminated. So there's, there's, effectively, there's no
incentive to start journals, and there's incentive against starting journals, I would say. This is
my, I'm making this up on the spot, but that's kind of how I would reconstruct that history.
No, that makes sense. Yeah. I mean, it's partially contingent. It's just historically how things have
been. Yeah. And also, there's this widespread recognition that there's something deeply broken
about traditional peer review, which is true. Yeah. Which virtually, I believe all every academic
I've spoken to has said that. So unequivocally, I think it's just a general consensus. Yeah. Yeah.
Excellent. Excellent. Now, that's, that's, that's great, Mel. I want to be cognizant of the time,
which is, which is why I want to get to this. And I'm sorry if this sounds like I'm flattering you,
but your paper on the free energy principle, it is, I've probably read it like three or four
times. And I think I can probably parrot out certain parts of it verbatim, because I've read it so
many times, especially because I hate it. It's actually, it's a really good paper. It's a fantastic
paper. It's a fantastic. And so now I'm trying to like, I'm like, okay, what, you know, I'm trying
to write a subsequent paper. And it's like, it's not that good. I mean, because like it's, it's
probably your most cited paper, right? I mean, I found you through this. In fact, like, I didn't
even know who you are until I came across this work. Yeah. So just for the listener, it's called
the math is not the territory navigating the free energy principle. Yeah, I mean, it's just,
it's philosophically interesting. It's got so much into like the history of science. And then,
you know, like, what is formalization? You speak about the structure like, yeah, he keeps a lot
to discuss here. Although, although before we get to the, let's say the nitty-gritty, and one thing
I want to mention is, so I've been trying to get through this, this book on active inference. And
I've got to say, because when I'm reading this, every page, I'm kind of reading it in a way through
the kind of the lens of what you put in, in me through this paper, you know, it's like, I've
got a bias now, I've got the, I've got the, the math is not the territory bias. Because it really
helped me understand. Yeah, it really did help me understand the ontology of what really is the
free energy principle, because it's got so much interest. So many people talk about it. And,
you know, Carl Friston, he's fantastic. I've learned so much, but he sometimes isn't the
best elucidator, you know, like he, when it comes to, you know, he's not a philosopher. Correct. I
think that could be the reason Einstein was a philosopher. Carl Friston is like Isaac Newton,
in that he's kind of like, I don't care what's like, he'll ascent to any metaphysics,
Newton would ascent to any Newton was like, I'm not doing metaphysics. I'm associating
relationships I see in data. Right. But don't tell me about the physical seat of gravity. I'm
not talking about that. Yeah. Oh, yeah. I mean, that certainly wasn't wasn't a dig at
Professor Friston, because he he himself says, he says, yeah, I'm not a philosopher, I'm a
scientist. And I don't really, when he doesn't even really take a philosophical position or
metaphysical position pertaining to the FEP. But but having said that, Mel, so, oh, sorry,
be that as it may, I mean, what, what, why, yeah, why do you think there's such deep philosophical
interest in the free energy principle of every any philosopher who works in the philosophy of
biology or the cognitive scientist or ML, but it's such deep philosophical interest. So, yeah,
why do you think the reason for that is, I think there are a lot of reasons one of them is, okay,
so I think, I think of all math, all applied mathematics, or scientific math or models,
as a kind of thinking tool, math is a thinking tool for science, right. But
the free energy principles are thinking tool in a different way in that it's not actually meant to
be placed in contact with empirical data, right, it's just about enabling us to conceptualize
of target phenomena and new ways. And it happens to be new ways that are actually really
a philosophically generative and novel to suck to agree. Not exactly novel, but overlooked. I mean,
you get some of like, some of what's being said about life. It's if you look hard enough, it's
really in Schrodinger's, Schrodinger's what is life. You look at that text, there's a lot of the
ideas that are being brought out in the FEP in that text originally.
Yeah, he brings up new ideas go back, but largely ignore, because they're very much
opposed to the kind of neo Darwinian canon that we have now in biology, where we're really looking
at population level analysis. And you're not looking at physical exigencies or structural
exigencies of biology at the physical systems involved in biology and what kinds of necessities
need to be there for life to exist. And then connecting that up to a view of cognition as
fundamentally oriented towards action and interaction with the environment too. I mean,
that's also there. So there's a lot that's philosophically rich that is associated with the FEP
in how the FEP is discussed. It's not necessitated by the FEP, the FEP is just math, but it's math
that allows us to conceptualize of things that we're taking away. It's also cool math, it's fun
math. Part of it is there's a lot of flourished that math that doesn't need to be there. That's
just it just if you like math, it's it's cool. And you can keep pushing it new cooler. It's
kind of it's it's like this magpied. It's like a bunch of shiny math taken from 18 difference
distinct. You know, you've got you've got some of its machine learning math.
Like some of it just is it just is elbow, right, to minimize free energy, the quantity known as
free energy as a kind of information theoretic construct to minimize free energy is is to just
optimize the evidence lower bound, which is elbow, which is machine learning technique, right?
Um, it's also Fokker Planck, or the master equation, or the Kolmogorov forward equation,
which is, you know, a principle of stat mech. It's also, I connected up to Max Ent,
maximum entropy principle, which is a sort of, James,
put forward this idea that we can view. Basically, the core principles of thermodynamics,
expressed statistically, can also be reoriented as a kind of
epistemic principle for like keeping your priors flat, basically, except for when the evidence.
Does that make sense? No, I think I got the latter bit of it regarding the epistemic principles.
Yeah. Yeah. So, James in the, is this 50s? Max Ent, James.
When's the first Max Ent paper?
50s, right? Yeah, it's a 50. It's 57. It's 57.
Yeah. So, the idea is that. Yeah.
Yeah. 57. That's right. Yeah. Yeah. BT James. Two papers.
So, it's like a closed thermodynamic system. The principles of thermodynamics tell us that
a closed thermodynamic system will max out its entropy, right? Like, that's,
this is what thermodynamics tells us. At a certain point, yeah, of course. Right.
Ultimately, in the limit. You can give this
a gloss as a principle for best inference. Like, it's already probabilistically formulated,
but then view that as a rule for governing the probability distribution over some belief.
And it's, again, Max Ent, because your priors need to be as flat as,
as the probability distribution is as flat as it can be, given the evidence, right?
So, there's.
And you're saying the FAP does bring this into its, it's theorizing too, like.
But they did. I don't think they did. I think I pointed it out, and then they started to,
so there's, their recent work is actually explicitly incorporating the James stuff.
Okay. Fascinating. Yeah. I think it was actually because I was like, so James, right?
That's fascinating. I didn't know that, because I mean, I mostly view it through,
you know, predictive coding and Bayesian reasoning. I mean, really, that's.
I actually doubted that lineage. I doubted that lineage, but I thought that they've
made that connection explicitly beforehand. But the people who are now explicitly doing the
Max Ent incorporating with FEP are attributing it to me. So I'm like, you know, it's if he wants.
Okay. Yeah. Are there any, because like, I mean, I'd love to read up on this. Are there any papers?
Because I mean, I've only just started on the book. This is the.
I think the best. Okay. So, so the, Tom Parr is fucking excellent, but.
And all of those people who wrote that book are excellent, but I think.
They're very good writers too. Yeah.
I think the most competent.
Mathematician who's working within the free energy framework is Dalton.
Okay. I got a, who I spell that.
Do you know how to spell Tamil names? Yeah.
The first name is very Scottish, which is a little well. Okay. There we go. Yeah.
Um, so actually they, they took it from, so they took the Max Ent. I, so I proposed like, hey,
you know, well, what the FEP is kind of is you're, you're, you're taking principles of statistical
mechanics and you're epistemic sizing them. You're giving them an inferential reading.
You're taking laws, laws of stats. Yeah. Yeah.
And you're reading them as principles, as principles for.
Cognition. Yeah. Yeah. I mean, I mean, I, I, I, I, I'd say for me initially when I came
across FEP, that's what I found quite interesting where, you know,
Carthus and his background is even in physics and like you take from statistical mechanics,
which is in physics. I think, I think he did a bachelor's in physics in like the 60s.
Yeah. I shouldn't say background. You're right. I think he studied physics. He certainly is a
neuroscientist, but, but like, I think he does like the physics he's getting is largely outdated.
Well, I think he's just drawing from a lot of areas of, of physics.
And really it's like, he's in clinical neuro, right? He's, he's spent a career in clinical
neuroscience. Well, I mean, generally what interested me was that the fact that you take these
theories and principles from physics, like, you know, all from statistical mechanics or,
as you point out, like, you know, max and, and then apply them to move to like cognition,
reasoning, Bayesian inference and the likes. I just, I don't know. I find that fascinating.
And I don't know. I just feel like I, again, as a neophyte, just, it just excites me to see where
the, the developments that goes on the FEP and the, you know, the concomitant, more engineering
work that comes along with it. Having, having said that, Mel, one thing is this, in your paper,
you say the math is not the territory. And I think here's where we get to the, really, the,
the crux of the argument, the philosophy of this paper. And I'm just going to read out a bit of
an excerpt. I think it's valuable for the, for the listener in case they haven't read it already,
which I, I, if you're interested in the FEP or ML, for that matter, I highly recommend reading
this. So you just, you claim here, I think this is from the abstract. I'm not sure. Anyway, I've
got this excerpt here. Conceptual verification is a common ailment of scientific modeling.
It is particularly likely to occur in cases in which models have somewhat convoluted histories.
Rification involves, and here's the important bit, in fact,
verification involves mistaking an aspect of a model, its structure, its construal, or the union
of both, for an aspect of the empirical of the natural world, mistaking the math for the territory,
so to speak. So yeah, could you please elaborate on that little statement and then, you know,
kind of connect that to the FEP? Yeah, so I think, I think there's a tendency to
conflate scientific realism with realism about the conceptual tools that we use in science.
So I'm, I'm a full-blooded scientific realist. I think, albeit a pragmatic realist.
I'm somewhat of a content. I think I'm more of a real, I think I'm more of a realist-realist
than most people who call themselves pragmatic realists. I think people who call themselves
pragmatic realists, I'm like, you're not really a realist. I'm actually a realist,
just pragmatically so. No, I mean, I would say science without a doubt, it does give us
truths about reality. I mean, I, in the content sense, let's say. Yeah, whatever the truth knowledge,
whatever the epistemic goods of science are, I want to say it's truth sub-pragmatic or knowledge
sub-pragmatic, right? I think, I think there's, it's not absolute, all-encompassing, omniscient
truth about nature. It's, it's pragmatic truth. It has its limits and it's oriented towards us
as the kinds of beings that we are having to occupy the world and navigate it the way that we do,
right? But I think it is truth. I mean, if anything is truth or knowledge, that's, that's
what that is. Exactly, with all those caveats, it gives us truths, let's say. Yeah, yeah, yeah.
But then we introduce all this conceptual machinery into science to be able to do science,
like the idea of a Hamiltonian or the idea of a gravitational field or the idea of a fermion
or the idea of, you know, a force function. And that includes all the, you know, the
Fokker-Planck equation that includes all the sort of mathematical infrastructure too.
These are all the conceptual tools of science. And I think that there's a lot of slippage that's,
that's like, well, science delivers truth. Therefore, all the conceptual tools we introduce
in the process of doing science and getting to that truth are also true and real, in some sense.
And I'm like, no, that requires a lot of careful work at the end of the day. At the final kind of
interpretive stage of a scientific procedure, you ask yourself, do we think strings are real?
Do we think that quantum fields are real? Do we think that Hamiltonians are real? Or was this
just sort of a calculational device? And I think there's a lot of, in between, between it's real
and it's a calculational device. But I don't think at the end of the day that's a distinction that
can be fully upheld. But there's a tendency, and I think it's true, even among careful philosophers
to attribute realism or truth to, to try to make the conceptual tools of science truth out
when they ought not to be read as truth out.
Yeah, when it's a thing itself. I mean, it depends, right? For instance,
I've spoken to a few mathematicians on this podcast, one person who I, as I came that comes to
shoulder with Hamkins, he's a Platonist. So for him, of course, yes, FEP, if it's a mathematical
structure, it could really exist in like a platonic sense. But in your paper, you're talking
more in regards to our physical world, what science studies, you know, you're not talking
about like a platonic realm. I don't know what your views are on Platonism.
So with math, I think there's a lot of accounts of how math works in science that are, whether
explicitly or not, deeply committed to Platonism, or something akin to it. And
for me, I'm like, if your account of how natural science works, depends on assuming
the most kind of industrial strength metaphysics possible. It's not a good account of natural
science. Like I'm an, I believe in naturalism. I'm a naturalist. And a lot of naturalists,
a lot of proclaimed naturalists happen to also be Platonists. And I'm like, that's not real
naturalism, right? You need an account of science that assumes as little in the way of metaphysics
as possible. And is cognizant of what metaphysics it does assume to the extent that you can't get
away from that. Yeah, that's why you mentioned all the, all the presuppositions that your
realism is based on, right? Right? Yeah. For me, it's like the word, the word dog or the word
mitochondrion, right? Do we think the word dog exists? It's like,
I think dogs exist. Yeah, yeah. I think that there's a class of natural entities that is well
carved out by our best science. And we refer to it via this concept that has this label attached
called dog. Yeah. But I don't think, I think the word exists as a cultural mental artifact.
But I don't think it exists mine independently. And I feel the same about math and science. It's
like. Yeah, sort of interrupt, but I think, I think I agree with you. I mean, I'm, I'm still,
I hate to use this like cheap like agnosticism, but I'm kind of agnostic as to mathematical
Platonism. Although, because I kind of view it in the way I think John Peer Jay said that,
and if you think about it all of mathematics, it's just, it's semiotics and linguistics.
The thing though is it kind of does, it has to blow our minds as to how consistently it's worked.
I mean, at a pure pragmatic level, it is rather bizarre that there is this internal consistency
in mathematics. So I'm still unreasonable efficacy. Exactly. Yeah. Yeah. I mean, you can't
necessarily say that therefore that can be true in some fundamental metaphysical sense,
but it does make one wonder. Yeah. So back to the idea, you know, in the, in the paper,
I kind of want to also discuss in this paper, also you do. Oh, I think I'm, I made a mistake
there. I'm confusing papers. Do you, in this, in the math, it's not the territory. Do you discuss
the, the natural selection, like you kind of contrast or juxtapose the FEP with natural selection,
or could it be the other paper you wrote, which was more like an introduction to
the paper, the free-range principle and accessible introduction to its derivations,
implications and applications? I don't know. Good question. Yeah. Yeah. Because regardless,
what I, what I also liked was, and this probably connects to my previous, my initial question,
why a lot of philosophical interest in the FEP, it's just, yeah. So like the FEP, is it like,
is it like, is it like a meta narrative or like a meta theory, or it's called a super theory,
not a meta theory, a super theory, something like natural selection. Yeah, or like almost an intuition
pump? Yeah, I think I prefer that. Because you can't really, it doesn't really fall into the
Hopperian falsifiability and, you know, in that rigorous sense, right? I should say maybe in it,
that, that was sort of a, I'm sort of adapting the Dennett concept. That's, that's not exactly,
that's not how he uses it. But, but one could say it's an intuition pump in a stretch of that
terminology. I see. In that. It's, it's a kind of conceptual framework
that enables us to think about things very differently in science. But it's not actually,
it's not a method. It's not a formal model. It's not a theory or a hypothesis or a, you know,
there are all these sorts of concepts, there are all these conceptual tools in science and it's,
it's not any of the kind of lower order conceptual tools of science in the same way that natural
selection is not, I don't view it as a theory. Natural selection isn't a theory or a hypothesis
or a model or a, I mean, it's really sort of a meta conceptual framework, I would say.
Yeah. Yeah. Yeah. And I think in that sense, it's very far removed from the actual
day-to-day work of science. Of scientists. Yeah. Yeah. Experimental work, for instance. Yeah.
And I think in, you know, part 1.5, you essentially say, I propose here that we reserve the free
energy principle to denote only the maths of which the FEP is composed of models utilizing this
formalism to study natural systems, bear also an interpretation, lending a means of interpreting
the maths as about the systems in nature. So, I mean, that idea of, yeah, it's kind of a formalistic
conceptual structure. I like thinking of it that way. Excellent. So, okay, let's see.
In terms of time, yeah, we've got a few more. Is it okay if you go for about 10 more minutes?
Yeah, yeah, totally. All right. All right. Fantastic. Thanks. Thank you, Mel.
I kind of... I'm happy to chat again at some point if that's...
Yes. Yes. I mean, in fact... I just have to run at like, you know, I have to run in 15 minutes, but...
Yeah. Just 10 more minutes off your time, only because one thing I really try to do with this
podcast is, I don't want to say a bridge, but I try to bring into dialogue
a so-called continental philosophy and more of the analytic philosophy that kind of you work through.
I should say, I studied with Dennett in my undergraduate and it was forbidden to me to touch
continental philosophy. Yeah. You see, this is, you know, kiss and point. And I don't like that,
to be honest. I don't even like creating this demarcation, really. It's just philosophy. It's
thinking of a philosopher as a philosopher as far as I'm concerned.
See, he knew my mind and he knew what reading Foucault would have done to me and it was nothing good.
Yeah. There you go. You know, you start talking about the epistemes and all of that. Yeah. Yeah.
But what's fascinating is like, look at how much of, you know, fruitful, productive output you've had,
if I may, because you do take in the sociological aspects that Foucault, perhaps above all,
point out very carefully when it pertains to our knowledge and epistemology. But yeah,
on that note, let me just ask a very, very broad general question, Amel. As a philosopher of AI,
as a philosopher of science, what insights do you think us in the, let's say, Anglo-American,
you know, I'm in Australia. Are you Canadian or are you in the U.S.? U.S. Right. So yeah,
the Anglo-American kind of. Yeah, there you go. The more analytic, you know, oriented philosophy,
which, when I spoke to this philosopher called Simon Critchley, he said it's more for just a
historical phenomena. It's got, it has nothing to do with really with ideas per se. It was just,
you know, how things changed with the world, with World War II and how that, you know,
certain analytic philosophers, it's in political, it was more of a political phenomena, more than a
philosophical phenomena in history. But, you know, be that as it may, yeah, as a, as a philosopher of AI
and a philosopher of ML, what insights do you think we can gain from kind of discourse within
continental philosophy with thinkers all the way from thinkers like Heidegger
or to people like Zizek and to, you know, sociologists like Foucault?
Um, I don't delve into that work very much, but I know people who do and they,
I think, make very interesting work of it. Elmer Feiden is doing, is more,
he's a philosophy of AI, is more, is more, is more continentally influenced.
I haven't heard of that person. Fantastic. Okay, thanks for that.
Um, he will know other people.
Yeah, yeah. There's also some, I think, I mean, I think there's a way in which sort of STS scholarship
on technology, AI, ML is also more continentally leaning.
Well, this is a book that I've just started on called The Critical Theory and AI,
which I'm hoping to speak to, it's by Simon, Simon Lindegren. I just started on the books. I
can't really say much on it. It was just published last year. Yeah, we just put out this, this,
the pseudoscience paper. And a lot of the reviewers were suggesting some sort of like
critical theory. Oh, you mean the one that goes in the machine learning paper? Yeah, our reviewers
were suggesting some of that stuff. Fascinating. Yeah, yeah. I mean, yeah, which is like for me and,
you know, leaving aside the names, like just generally for you, as you pointed out, you know,
Dennett said, you know, no touching, Corneal Philosophers, but just, I'm curious, well,
why did you rebel against, I'm joking, of course, but your master's commands and kind of get interested
in, because I've seen through your Twitter feed, for instance, that you do, you do retweet stuff by
some Corneal Philosopher, by Zizek, or you do, you aren't totally a verse to it or a post to it.
Yeah, I mean, I think the divide is, sorry. I think, again, the divide is pretty superficial,
as you said. And I think,
as I said, like with everything, most of everything is, this is again,
a Dennettism, but 99% of everything is crap was his life. And I think that's true of both
analytic and continental philosophy. There's a dominant tradition. There are aspects of, like,
if we think of analytic philosophy and continental philosophy as methods, I think there are really
problematic features of both of those methodologies as methodologies for philosophy.
I think there are really sort of stultifying features of both of those methodologies. And
there's brilliant work. There's brilliant ideas coming out of both traditions. But in a way,
it's working against some of the kind of primary tendencies of those traditions, in a sense.
And so in my work, I'm just trying to say something
interesting that matters for the reality we live in. And I'm trying as much as possible not to be
operating within a particular conception of what good thought is. I mean, I think
I think thinking according to some
conception of what is the right way to think is not a right way to think. I think it
keeps us short of discovering truths.
So I try to not
adhere as much as possible to principles of particular genres of philosophy,
in so much as I can do that and still get published enough in philosophy venues to get a job.
That's a whole other conversation. Just on a side note, Mel, are you familiar with
the thinker, Bianchel Hahn? No. Yeah, so he wrote this book, Psychopolitics. Where is it?
He's quite big in Germany. He's a German philosopher. In fact, no, he's originally from
South Korea, but now he works in Germany. And I was, when I read your paper, in fact, when I read
the theory free ideal paper, and then also the recent one, the pseudoscience one,
he has one chapter in this book, Psychopolitics, on big data. And he wrote this in like the early
2000s. A lot of this, I'd love to, in fact, as you said, you'll be open to another conversation,
I'd love to kind of discuss. It's just like 15 pages, that chapter, that just his ideas on it,
because I think you'd be the perfect person to comment on it with your kind of analytic background
with the work you've done, because it really did remind me of his ideas when I read that,
when I read your work, in any case. But yeah, again, I want to be cognizant of your time. So
just one last question, Mel. What would you say, currently, I just like asking this,
because it kind of excites me as to what kind of work I should do. In this space of philosophy of
ML and philosophy of AI, apart from what we've discussed so far, what other avenues for research
do you think people should look into and take into consideration and start thinking about?
Oh, God, there are a million. I think there are a million avenues that are
pursued or could be pursued that I think are kind of fruitless. But there are a million avenues that
are really fascinating. So I mean, I think the way machine learning technologies are being adopted
and changing labor and changing the way these technologies are changing our relationship to
the sort of resource consumption to the means of production, to the output of labor, to the
output of intellectual labor, or epistemic labor, one might say, which are, I think,
much more subtle than we've given credit to so far. There's a problem of opacity or
explainability or what have you. I think it's clear that the sort of research avenues that
we've been on with that are deeply flawed, and the kind of technologies we've invented to tackle
those problems in so much as they are problems are deeply flawed. But figuring that out is usually
important. How these technologies are bringing about harms in the real world is a tremendous issue.
And tackling that in a way that is deeply cognizant of incentive structures.
And investing in interventions that those in the positions of power to create and deploy these
technologies would actually be incentivized to adopt and working on that incentivization.
So this requires a vastly interdisciplinary perspective. This requires having whatever
the domain of application is, if that's a hospital, if that is in biological science,
if that is in building cell phone applications, if that is it, whatever the application is,
having deep domain knowledge of that application, having knowledge of the regulatory structures
or lack thereof, having knowledge of the incentives of those who are creating these
technologies and deploying them, and having knowledge of the knowledge level of those
who are creating these technologies and deploying them, et cetera, et cetera, et cetera.
And so I think there's, it's like now is the time when we need to stop messing around and start
doing really, really good, really dialed in interdisciplinary work and supporting that,
because you cannot effectively
prevent or remediate the ill usage of these technologies from a single disciplinary background.
You need teams of people with expertise in a lot of different domains who know how to talk to each
other. Yeah, oh, that's for sure. Yeah. Yeah. So I think, sorry, I lied. That was the penultimate
question. This is the last question. And then I'll let you go, I promise, because you spoke about
kind of social harms. One other question I wanted to ask from you was, we spoke about
science fiction and kind of the dooms kind of mentality. But would you compare, would you
like, would you say the current paradigm of AI, the current technologies we have, that it can be
compared to something like the nuclear bomb in the nukes in the 20th century, or do you think
that's an exaggeration or I'm just being dramatic? Like we aren't there yet. It's not that grave.
Well, the impact of nuclear bombs, the impact of nuclear technology
was in one part the reality of this groundbreaking technology that made
killing and destruction possible at only levels. On another part, it was a psychological phenomenon.
It was
almost more radically a psychological shift, right? I think the thing with machine learning
technologies and any possible future development of these technologies, in fact, not just what we
have right now in front of us, is almost that level of psychological reaction to what these
technologies mean. But the disruptive force is not owing to a really radical scientific or technological
breakthrough. It's more the psychological and social time.
I mean, it has the potential to really radically disrupt labor markets, and it already is. But
that was something that was already happening. Workers were already being pushed out. I mean,
that was happening since the Industrial Revolution. Yeah, and that's capitalism. Yeah,
that's just capitalism. Yeah. It's just that now there's an even more, it's perpetually a more
and more urgent need to shift away from a mode of production in which if you don't work, you die.
The world in which if you do not labor, you starve to death, is not one that works in which
most people are being automated out of their jobs. Yeah, regardless of the technology. Yeah.
On that grim note, thank you very much for your time, Mel. I've thoroughly enjoyed,
I've learned a lot from you, but also just your Twitter feed is fantastic. I visited,
I frequent it often. I hate Twitter, I think it's a terrible place, but I go to like yours,
and I've got like five people bookmarked. I just visited their feeds. But yeah, thank you.
Thank you very much for your time, Mel. And I hope we can chat again soon.
Yeah, thanks, Lucas. Yeah, I'm happy to follow up. And send me the thing, the
Korean-German author. Yes, the one by Byung-Shul Han. Yeah, I'll send you, I've got a PDF,
I'll send you the PDF and all that, because I'd love to kind of, you know, follow up on that and
see what ideas you have. But yeah, thank you, Mel. Yeah, thanks.
