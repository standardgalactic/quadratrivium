1
00:00:00,000 --> 00:00:04,400
Okay, so to get the ball rolling, as they say, I'm going to read off

2
00:00:06,400 --> 00:00:13,200
Adiga's, uh, the question concerning technology, although, although it's very important, a caveat,

3
00:00:13,200 --> 00:00:18,560
Adiga was a serious Nazi. So whenever you read him, you need to have that in the back of your mind.

4
00:00:18,560 --> 00:00:24,160
He wasn't some kind of peripheral Nazi. No, no, no, he was deeply involved with the Nazi party.

5
00:00:24,160 --> 00:00:30,400
He was an ideological Nazi. And, you know, I even read this good analysis of Adiga that in many

6
00:00:30,400 --> 00:00:38,640
ways he was a metaphysical and SMI, not just the kind of the, you know, run-of-the-mill and SMI

7
00:00:38,640 --> 00:00:43,520
in Germany during World War II. He was a legit and SMI. So it was a Nazi. So whenever we read him,

8
00:00:44,160 --> 00:00:51,200
we need to keep that in mind. Regardless, I personally think one of his best essays I've ever

9
00:00:51,200 --> 00:00:59,120
read is the question concerning technology, which he does an analysis, a metaphysical analysis of

10
00:00:59,120 --> 00:01:07,440
technology. So I'm going to read really two tiny excerpts from that essay, and then we'll go from

11
00:01:07,440 --> 00:01:16,960
there. So here's what he says. Everywhere we remain unfree and chained to technology.

12
00:01:17,920 --> 00:01:25,440
Whether we passionately affirm or deny it, but we are delivered over to it in the worst possible way

13
00:01:25,440 --> 00:01:32,000
when we regard it as something neutral. So that's a really important point. For this conception of it,

14
00:01:32,000 --> 00:01:38,720
to which today we are particularly like to pay homage, make us utterly blind to the essence of

15
00:01:38,720 --> 00:01:43,280
technology. This is essentially in the second paragraph of the essay. So he starts off like

16
00:01:43,440 --> 00:01:47,600
that. And then this is the important bit for me, at least, which I thought was really

17
00:01:48,000 --> 00:01:56,080
perspicacious. He says, yeah, we're questioning concerning technology, and we have arrived now

18
00:01:56,080 --> 00:02:01,600
at alater, which is a Greek term, which means, well, it translates to add revealing.

19
00:02:03,040 --> 00:02:09,520
What has the essence of technology to do with revealing? The answer, everything. For every

20
00:02:09,600 --> 00:02:17,760
bringing forth is grounded in revealing. Bringing forth indeed gathers within itself

21
00:02:18,480 --> 00:02:24,800
the four modes of occasioning, causality, and the rules, and rules them through throughout.

22
00:02:24,800 --> 00:02:28,400
So the four modes he discusses as in his essay, we don't know how to get to that,

23
00:02:28,400 --> 00:02:30,320
but the important bit is about revealing.

24
00:02:31,040 --> 00:02:41,360
What's that? He writes in such a weird way, man. It's so hard to read how to go.

25
00:02:41,360 --> 00:02:49,840
Within its domain, belong and means as well as instrumentality. Okay. I don't know what the

26
00:02:49,840 --> 00:02:55,600
sentence means. Ignore that. Instrumentality is considered to be the fundamental characteristic

27
00:02:55,600 --> 00:03:03,600
of technology. If we inquire step by step what technology represented as means actually is,

28
00:03:04,800 --> 00:03:11,280
then we shall arrive at revealing. The possibility of all productive manufacturing

29
00:03:11,280 --> 00:03:15,600
lies in revealing. And now this is perhaps the most important little excerpt.

30
00:03:16,800 --> 00:03:24,800
Technology is therefore no mere means. Technology is a way of revealing. If we give heat to this,

31
00:03:24,880 --> 00:03:29,520
then another whole realm for the essence of technology will open itself up to us.

32
00:03:30,320 --> 00:03:37,360
It is in the realm of revealing, i.e. of truth. So after reading this a couple of times, my first

33
00:03:37,360 --> 00:03:44,160
insight and the way I connected this to kind of techno-optimism and tech bros of our time is,

34
00:03:46,000 --> 00:03:52,320
I feel like a lot of us, at least tacitly, view technology as a means to an end. A lot of tech

35
00:03:52,320 --> 00:03:57,120
bros think of it as some kind of, as Heidegger says, instrumentality. It's a way to get things

36
00:03:57,120 --> 00:04:04,560
done purely pragmatic, utilitarian kind of way of viewing. However, actually I have some notes here

37
00:04:04,560 --> 00:04:11,760
which I took down. That bit about instrument, sorry, that bit about revealing shows that

38
00:04:11,760 --> 00:04:19,280
technology is not a mere instrument. It's rather a way that truth reveals itself to us. And when I

39
00:04:19,280 --> 00:04:24,320
mean truth, I don't mean truth in like a scientific empirical sense, like facts of, let's say, the

40
00:04:24,320 --> 00:04:31,440
physical world, but rather truths of being as such. So the brilliant insight Heidegger had

41
00:04:31,440 --> 00:04:36,720
in the 20th century, which I think revolutionized philosophy afterwards, at least so-called

42
00:04:36,720 --> 00:04:41,360
colonial philosophy, is that he showed that, you know, truth isn't something that just

43
00:04:42,560 --> 00:04:47,520
kind of prima facie just presents itself to us. It's always something that's revealed through

44
00:04:47,520 --> 00:04:54,560
us, a subject, or as he calls it, a design. And then he used that kind of concept that truth is always

45
00:04:55,760 --> 00:05:00,880
something that's filtered through a framework or framework, again, reduces it to some kind of like

46
00:05:00,880 --> 00:05:05,920
algorithm. It's not in that sense. Rather, it's a, through a mode of being, through an orientation,

47
00:05:05,920 --> 00:05:12,880
let's say. He extrapolated that idea to every other part of being. So technology, art,

48
00:05:13,840 --> 00:05:19,280
obviously history and whatnot. This essays our technology. So the first thing is,

49
00:05:20,560 --> 00:05:26,400
technology is not a means to an end. It is much more deep and much more profound. It's essence,

50
00:05:26,400 --> 00:05:33,520
it makes metaphysical claims, which means technology deeply profoundly changes who we

51
00:05:33,520 --> 00:05:38,000
as human beings. And that's not an eye-opener, especially with social media. People just accept

52
00:05:38,080 --> 00:05:44,000
that kind of, now it's like, it's a given, right? Although it's not just in the sense of our social

53
00:05:44,000 --> 00:05:50,720
reality, but our metaphysics, our values itself changes with technology. And then the other critique

54
00:05:50,720 --> 00:05:56,000
of, let's say, tech bros or tech broism is that, you know, there's this kind of naive optimism,

55
00:05:56,000 --> 00:06:00,640
which I'm going to talk about, where there's like this assumption we have that, oh,

56
00:06:01,440 --> 00:06:06,880
technology is good just for the sake of technology. So it's just kind of, if we keep

57
00:06:08,080 --> 00:06:12,400
advancing and developing our technologies, that's just good for its sake. It's not so simple.

58
00:06:13,440 --> 00:06:19,760
What Heidegger talks about this thing called, yeah, so he has technology as revealing,

59
00:06:19,760 --> 00:06:24,800
but then he also has this thing called enframing, which, okay, I hate to be the

60
00:06:24,800 --> 00:06:29,200
annoying leftist that blames everything on capitalism, but I'm going to be that annoying leftist.

61
00:06:29,200 --> 00:06:38,240
And framing us, we start viewing other human beings also as technical objects, as resources to

62
00:06:38,240 --> 00:06:46,400
be exploited, case in point, human resources. So in that sense, the technological metaphysics

63
00:06:46,400 --> 00:06:52,800
have become our metaphysics. We view other human beings as means to an ends, as things

64
00:06:52,800 --> 00:07:00,400
to be optimized, utilized, to be used, to be technically exploited, certainly in capitalism.

65
00:07:00,400 --> 00:07:06,880
And, you know, a good example is when the whole, as we are going through the current AI revolution,

66
00:07:06,880 --> 00:07:11,680
when the whole, you know, with open AI, a judge if anything came off, the first question, a lot of

67
00:07:12,720 --> 00:07:19,600
the first kind of spontaneous reaction most people have is, oh, what's it going to do to this job,

68
00:07:19,600 --> 00:07:24,160
to marketing that job? What's it going to do to the economy? But rarely did we ask,

69
00:07:24,800 --> 00:07:30,240
what is it going to do to the human subject as such? And I think the reason we asked that

70
00:07:30,240 --> 00:07:34,720
previous question, not the latter one, the reason we asked, oh, what's it going to do to our economy?

71
00:07:34,720 --> 00:07:41,360
What's it going to do to, I don't know, different kinds of jobs is because again, we human beings,

72
00:07:41,360 --> 00:07:47,760
because we have this kind of technical metaphysics, we view human beings as agents of capital.

73
00:07:47,760 --> 00:07:54,400
Simply, that's all we have. We just, you know, we trade and we pretty much move around capital.

74
00:07:54,960 --> 00:08:00,560
So the most important thing isn't the human being, but what the human being is useful.

75
00:08:01,840 --> 00:08:07,520
And that's my critique of tech bros, who kind of, they have this kind of like

76
00:08:07,520 --> 00:08:12,640
massive optimism where technology will liberate us. It's typically on a tower of

77
00:08:12,640 --> 00:08:16,880
Babel from the Bible, right? Typically, it'll liberate us. It'll be a saving grace.

78
00:08:17,600 --> 00:08:22,960
And it's good just for its sake. And in many ways, the human being doesn't even matter what

79
00:08:22,960 --> 00:08:29,120
matters is the technology as such. And that is something. So by the way, Heidegger was not

80
00:08:29,120 --> 00:08:33,280
a Luddite. He was not saying technology is bad. I think the best way to read Heidegger is through

81
00:08:33,280 --> 00:08:39,760
the Hegelian lens and be like, okay, we need to see technology for what it is with its

82
00:08:39,760 --> 00:08:44,560
contradictions. And I'm not saying that's, oh, you see the good and bad and you kind of weigh

83
00:08:44,560 --> 00:08:49,040
out the pros and cons and get the pros. It doesn't work like that. Heidegger's point is more,

84
00:08:49,920 --> 00:08:56,480
more, I'd say more solemn even, that we, with the good, the bad comes,

85
00:08:58,240 --> 00:09:02,960
the bad comes along. It's concomitant to the good. We can't have our cake and eat it too.

86
00:09:02,960 --> 00:09:07,120
That's the point Heidegger makes, in my opinion. And I think that's the best way to read his essay

87
00:09:07,120 --> 00:09:15,200
on technology. Yeah, saying all that, Yun, right? I said a lot there, but the flow's yours.

88
00:09:16,560 --> 00:09:21,840
Yeah. Well, you know, I agree. And I have the same kind of orientation or like

89
00:09:23,920 --> 00:09:29,920
views on technology. And so I think what I can do is kind of build on what you've said.

90
00:09:32,560 --> 00:09:36,240
But first of all, yeah, like Heidegger's take on technology, I think is a really,

91
00:09:36,240 --> 00:09:42,080
really important one, right? Like, I think he sees very deeply, you could call him a prophet

92
00:09:42,080 --> 00:09:47,200
in his sense, because he wrote the book in like 1950. Was it 1950, 1900, something like that?

93
00:09:47,200 --> 00:09:52,320
The essay? No, 1950. I don't know when the essay was published. In fact, you keep going. I'll find

94
00:09:52,320 --> 00:09:56,240
out when it was published. Yeah, it was early enough. But he saw through these things that,

95
00:09:57,120 --> 00:10:03,360
that like he basically saw through how much of an impact to use a simple word, you know, like

96
00:10:03,680 --> 00:10:09,760
exactly, exactly 1950. He hit the nail on the head. Yeah, that's, that's great. But he, he saw all

97
00:10:09,760 --> 00:10:14,240
of this before any of it happened, right? Like in 1950, the world doesn't look like how it did

98
00:10:14,240 --> 00:10:19,520
today, but he saw all of this coming. But I think one of the main points again, I want to

99
00:10:19,520 --> 00:10:26,800
reiterate is like, an interesting thing here, I think is, I think, Raul, you made a few

100
00:10:28,240 --> 00:10:33,040
points around like tech bros and like techno optimism. I think in this context on what,

101
00:10:33,280 --> 00:10:36,560
what everything Heidegger is writing about, you can kind of extrapolate that to kind of

102
00:10:37,840 --> 00:10:41,920
the whole generation, at least the whole new generation, because they're all brought up within

103
00:10:41,920 --> 00:10:47,360
this setting, right? Like technology is inherently a part of the new generation. So in a way like

104
00:10:47,360 --> 00:10:52,160
tech bros have this kind of techno optimism view. But I think it's inherent in everyone who

105
00:10:52,160 --> 00:10:57,840
grows up, everyone who grew up in this kind of way of being, right? Which is times our religion.

106
00:10:58,640 --> 00:11:04,800
Yeah. So I think the important point to make is that it's one of those things now technology is

107
00:11:04,800 --> 00:11:12,240
one of those things now where it's, it's so deeply, it's so deeply encapsulated our ways of thinking.

108
00:11:12,880 --> 00:11:17,520
And I think here it's probably more accurate to say the Western way of thinking that you don't

109
00:11:17,520 --> 00:11:25,520
even notice it. Like no, like people on the street wouldn't be conscious, nearly conscious of like

110
00:11:25,520 --> 00:11:29,840
what sort of effect technology is happening to them. And I think that's kind of the real baseline

111
00:11:29,840 --> 00:11:37,840
idea we kind of trying to, trying to like expound on as well, right? Because as you mentioned,

112
00:11:37,840 --> 00:11:43,600
and like from Heidegger, it's technology is not morally neutral, right? And this is what most people

113
00:11:43,600 --> 00:11:49,600
think. It's not just tech bros, it's kind of most Gen Zs, even most parents, I'd say, although they

114
00:11:49,600 --> 00:11:54,000
have more like more of a conscious idea of like what life was like before technology. I think most

115
00:11:54,000 --> 00:11:59,920
people will, I think it's most, it's rather acceptable for lots of people nowadays to say

116
00:11:59,920 --> 00:12:06,560
technology is neutral and it's just a means to an end. But as you mentioned, like that's kind of

117
00:12:06,560 --> 00:12:10,320
missing like a lot of the point, right? Technology has a fundamental essence to it. There's a

118
00:12:10,320 --> 00:12:17,280
fundamental, fundamental metaphysics to technology. And when you pause it, when you think technology

119
00:12:17,280 --> 00:12:24,880
is just a means to kind of missing the deeper picture. And like, as you mentioned, one of the

120
00:12:24,880 --> 00:12:31,600
ways in which, in which it's affecting us, like the essence is in terms of how we view people,

121
00:12:31,600 --> 00:12:36,320
right? Like we view people as resources, we view nature as resources. And in a sense, it's kind

122
00:12:36,320 --> 00:12:41,760
of like the critique of technology is somewhat similar to a critique of capitalism, right?

123
00:12:41,760 --> 00:12:46,560
As more people might be familiar with. And I think that's fine, because like, if you think about it,

124
00:12:46,560 --> 00:12:52,800
I think like capitalism thrives on technology, right? Like, in a capitalist society, what are

125
00:12:52,800 --> 00:13:00,560
you looking for? Like, efficiency of production, something like that, right? Like, if you want to

126
00:13:00,560 --> 00:13:05,920
excel as a company, as a producer, as a whatever, like what you're trying to do, you're trying to

127
00:13:05,920 --> 00:13:12,880
produce more, more efficiently. And basically, technology, technological innovation is kind

128
00:13:12,880 --> 00:13:16,960
of what drives it. And so I think you can't really divorce technology, a critique of technology and

129
00:13:16,960 --> 00:13:20,160
a critique of capitalism. So you can kind of treat everything we're discussing as kind of

130
00:13:20,160 --> 00:13:26,560
interchangeable in this respect. But that's it, right? It's this very deep and trench thing that

131
00:13:26,560 --> 00:13:31,760
we're trying to kind of expound on. And like, we're trying to discuss the revelation that it's had

132
00:13:31,760 --> 00:13:41,440
that everyone like kind of sees past nowadays. And I suppose the biggest, the biggest

133
00:13:43,600 --> 00:13:48,160
threat or the biggest, the biggest kind of effect I see these days is

134
00:13:50,640 --> 00:13:53,520
from my point of view, and then we can kind of launch into kind of a couple of different

135
00:13:53,520 --> 00:13:58,800
points, because there's a lot out here as well. The biggest point of view, I think, is that people

136
00:13:58,880 --> 00:14:05,440
are, there is like the fundamental metaphysical idea behind technology is also a form of

137
00:14:06,640 --> 00:14:11,280
self-worship. It's a form of, it's a form of like,

138
00:14:13,840 --> 00:14:18,160
from a Nietzschean point of view, like the Nietzschean idea is like a revaluation of values,

139
00:14:18,800 --> 00:14:27,760
right? And so what technology is, is basically an attempt to create like a new order. It's an attempt

140
00:14:27,760 --> 00:14:33,600
to create a new order in which, you know, human nature or man is mechanized in different ways,

141
00:14:33,600 --> 00:14:37,280
let's say, like you can impose a rational order on the way we do things and make it more efficient.

142
00:14:38,960 --> 00:14:46,640
And I think you could then kind of interpret like the whole movement of technology

143
00:14:46,640 --> 00:14:51,600
being techno-optimism, kind of somewhat similar to scientism, right? It's this idea that, you know,

144
00:14:52,320 --> 00:14:56,480
we are our own gods and we can decide whatever the world should look like, we can do whatever we want.

145
00:14:57,360 --> 00:15:05,360
And our goal here is to kind of overcome nature, but then in doing so, like there are a couple of,

146
00:15:05,360 --> 00:15:09,840
there are lots of risks, right? Like we kind of overcome nature, then we overcome ourselves,

147
00:15:09,840 --> 00:15:15,280
we overcome ourselves, right? Like, and that's the point you raise with human resources as well,

148
00:15:15,280 --> 00:15:22,400
right? Because once you see nature as something to be overcome or something to be used as a

149
00:15:22,400 --> 00:15:27,760
resource, what's stopping you from seeing a human, right? As something to be like something to use

150
00:15:27,760 --> 00:15:32,560
as a resource and something to like kind of have power over, it's all, it kind of all exists within

151
00:15:32,560 --> 00:15:42,640
the same framework. And so I think the two things that kind of comes to mind firstly is

152
00:15:43,280 --> 00:15:48,400
where this is all taking us, because there is a kind of development, there's a development to

153
00:15:48,480 --> 00:15:55,440
technology, right? Like it doesn't just end with us having, being in a utopia, it's never that simple,

154
00:15:55,440 --> 00:16:01,600
right? And here if I want to bring it down to kind of the ground level of practical, on a more

155
00:16:01,600 --> 00:16:09,520
practical level, right? I think there's a lot of simple kind of simple ways, like you don't even

156
00:16:09,520 --> 00:16:12,960
have to talk about philosophy. There's lots of simple ways now where people are beginning to

157
00:16:12,960 --> 00:16:20,560
detect like certain faults or effects in which technology is putting us all at risk, right?

158
00:16:21,280 --> 00:16:27,600
And a simple example is like Jonathan Hyde, he's a sociologist. He talks a lot about the risk of

159
00:16:27,600 --> 00:16:32,960
social media and what it's doing to humanity. It's not morally neutral in that sense. And if we're

160
00:16:32,960 --> 00:16:37,600
going to go down the road, the route of social media, it's not a morally neutral route where it's

161
00:16:38,320 --> 00:16:44,960
a pure means in which we are just doing whatever, like we're just using technology for our own sake,

162
00:16:44,960 --> 00:16:51,120
right? Like it's doing something to us as well. And I like what CS Lewis said, I think it was in

163
00:16:51,120 --> 00:16:57,120
the abolishment of man. Let me try and find a quote. He said this, each new power won by man

164
00:16:57,120 --> 00:17:03,120
is a power over man as well. In every victory, besides being the general who triumphs, he is

165
00:17:03,120 --> 00:17:09,840
also the prisoner who follows the triumphal cup. Beautiful quote. And so you're being, you're kind of

166
00:17:11,600 --> 00:17:18,000
the more you kind of overpower nature, you overpower kind of everything, right? You're not,

167
00:17:18,000 --> 00:17:21,440
you're also being taken along for the right. You're in a way a prisoner of what's being done.

168
00:17:21,440 --> 00:17:25,120
Yeah, yeah. Actually, can we revisit that quote because that was a really good quote. I think,

169
00:17:25,840 --> 00:17:29,920
you know, CS Lewis and I, for me, he's a bit too conservative, but I think he's a brilliant thinker.

170
00:17:30,160 --> 00:17:35,920
Isn't it really interesting that you brought up Jonathan Hyde and social media and then you

171
00:17:35,920 --> 00:17:44,240
quoted CS Lewis because social media perhaps is the quintessential example to exemplify that quote.

172
00:17:44,240 --> 00:17:48,480
It shows the inherent contradiction in social media because think about social media.

173
00:17:48,480 --> 00:17:54,000
Its promise was we're going to be global citizens. We're all going to be connected. We're all going

174
00:17:54,080 --> 00:18:00,720
to be knowing what's going on. And it's just this beautiful utopian liberal dream, isn't it?

175
00:18:00,720 --> 00:18:07,040
But then CS Lewis would be laughing at that and saying, oh, look, now we've become slaves and then

176
00:18:07,040 --> 00:18:14,720
slave to social media. And this thing that was supposed to liberate us ended up enslaving us.

177
00:18:14,720 --> 00:18:19,840
And I think that's where he points out that, I don't know, I know he's coming from a very kind

178
00:18:20,160 --> 00:18:27,280
of Christian perspective and that's completely fine. So am I in many ways, but I think what's

179
00:18:27,280 --> 00:18:31,920
more perspicacious is that him pointing out the contradiction in what social media is.

180
00:18:31,920 --> 00:18:37,680
It's what it promised and what it became. No, 100%. And yeah, that's where that's what I was going to.

181
00:18:37,680 --> 00:18:44,240
So like to finish my point, it's where we're at now. Technology has done something to us. It's not

182
00:18:44,240 --> 00:18:50,240
morally neutral by any means. And one of the ways that this is reviewed is there are lots of

183
00:18:50,240 --> 00:18:56,080
simple practical ways in which people are becoming more conscious. But also, I think it's quite clear

184
00:18:56,080 --> 00:19:03,120
that going more and more further and more deeply down this path, it's not a utopia we're kind of

185
00:19:03,120 --> 00:19:09,120
ending up with. It's something weird. And there are lots of words that people use that are quite

186
00:19:09,120 --> 00:19:16,160
interesting. I like the word, I think Paul King's north as well. He used this word, like we're all

187
00:19:16,160 --> 00:19:23,440
kind of entering into a hyper reality. Yeah. Oh, John Baudrillard hyper reality. Yeah. Yeah. Yeah.

188
00:19:23,440 --> 00:19:26,880
Like I really like that word, right? We're not, it's not like when you talk about utopia, that's

189
00:19:26,880 --> 00:19:32,400
kind of the thing that techno optimists look at, right? They romanticize the idea of technology,

190
00:19:32,400 --> 00:19:38,400
really they romanticize the idea of innovation and like overcoming nature and overcoming like

191
00:19:38,400 --> 00:19:42,640
human nature even, right? Like when I see human nature, I mean, like the limitations, supposedly.

192
00:19:42,640 --> 00:19:46,400
But what that doesn't include is this whole, you know,

193
00:19:50,000 --> 00:19:56,880
what's the way to put it? Yeah. Yeah. I'm getting inklings of what I was going to mention. Oh,

194
00:19:56,880 --> 00:20:02,560
it's so weird to like juggle many thoughts. If I'll just finish it, wherever I'm going to take

195
00:20:02,560 --> 00:20:08,640
it now, right? But it's like, basically, the fault of techno optimism is this whole idea of you,

196
00:20:08,640 --> 00:20:15,520
you romanticizing the whole idea of changing the way people do things without seeing,

197
00:20:15,520 --> 00:20:20,800
and this was in the CS Lewis quote, right, that you become a prisoner of what is, what becomes

198
00:20:20,800 --> 00:20:29,760
as well. It's like, it kind of goes both ways. And I also had a couple more. So I think, so

199
00:20:29,760 --> 00:20:37,280
social media is a pretty common way in which the common person can easily detect like thoughts,

200
00:20:37,280 --> 00:20:42,160
right? Where in where this is all taking us, it's not a perfect thing by any means. And it might be

201
00:20:42,160 --> 00:20:47,520
even like immoral in many senses, right? And that's the, that's, I think, like a lot of

202
00:20:47,520 --> 00:20:52,240
heights research around social media is like social media is affecting us badly in many ways,

203
00:20:52,240 --> 00:20:59,120
which we never expected. Yeah, it's already a pretty simple. That's a good example, I think.

204
00:20:59,120 --> 00:21:04,000
And also this morning, I read a newsletter by a tech person, so a technologist,

205
00:21:04,640 --> 00:21:10,080
and I saw a few interesting like things on here, which is also like what people can easily perceive

206
00:21:11,360 --> 00:21:16,800
like to be dangerous or risks, right? And firstly, this relates to what Heidegger mentioned,

207
00:21:16,800 --> 00:21:20,480
but what she wrote here, and there's much more simple language as opposed to what Heidegger

208
00:21:20,480 --> 00:21:25,360
would have written, but part of the problem with the lean startup mindset, lean startup

209
00:21:25,360 --> 00:21:30,240
meaning basically kind of the methodology around startups and tech, right? Is that it sees live

210
00:21:30,240 --> 00:21:34,720
and work as an optimization problem. The point is to help people live a good life, not just an

211
00:21:34,720 --> 00:21:39,600
efficient life. The goal is human flourishing, not convenience. The goal is a good future, not a

212
00:21:39,600 --> 00:21:45,920
technically advanced future. And so it's pretty like technologists and kind of everyday people

213
00:21:45,920 --> 00:21:50,720
are perceiving this. And this was written by, sorry, I think I'm not sure you pronounce her name,

214
00:21:50,720 --> 00:21:56,560
but she's a technologist. And I'll put up her. Is it a substack or what is it? Yeah, yeah,

215
00:21:56,560 --> 00:22:00,960
substack. Put up the substack. Yeah. And the second thing she wrote, also kind of in more

216
00:22:00,960 --> 00:22:06,080
simple words, it's like, I've lost a lot of faith in tech solutionism, the idea that most

217
00:22:06,080 --> 00:22:10,400
problems can be solved by technology. Why? Because most problems are people problems,

218
00:22:10,400 --> 00:22:14,960
not technology problems. I don't believe. Very important point. We need to touch on that. That's

219
00:22:14,960 --> 00:22:18,800
a very important point. Yeah, I don't believe we are about to surrender to a robotic new dawn,

220
00:22:18,800 --> 00:22:23,440
where an AI will replace McKinsey or your therapist. Why? Because a company doesn't hire

221
00:22:23,440 --> 00:22:28,080
McKinsey because they're better than the AI. They hire McKinsey because if something goes wrong,

222
00:22:28,080 --> 00:22:34,080
nobody will blame you for hiring McKinsey. Humans are complicated. And so on this level,

223
00:22:34,080 --> 00:22:39,040
you can kind of see as well, like lots of kind of tech solutionism, that's an interesting word,

224
00:22:39,040 --> 00:22:46,560
is this is the point that kind of that most problems are people problems. And even on this

225
00:22:46,560 --> 00:22:57,040
level, right, kind of the applied technological level, there are already gaps. You could say

226
00:22:57,040 --> 00:23:02,240
problems, right? For me, the word I've been using recently, thanks to Tom McGavin,

227
00:23:02,240 --> 00:23:08,160
is contradictions. Human existence is, ontologically, there's like this,

228
00:23:08,800 --> 00:23:15,520
we have built in contradictions that we can't get away with or jettison out of our existence.

229
00:23:16,640 --> 00:23:20,320
Okay, I took down a lot of notes here, we know what you were saying. I want to get back

230
00:23:20,320 --> 00:23:24,320
to the self-worship point, because that is something that I hadn't thought about much.

231
00:23:24,320 --> 00:23:29,600
And because pretty much everything you said, I've kind of thought about written on and obviously

232
00:23:29,600 --> 00:23:35,280
I resonate with. But the self-worship bit isn't something I have, I have, I have thought about.

233
00:23:35,280 --> 00:23:40,160
And the reason I want to talk about that is I realized in my initial long monologue, I kind of

234
00:23:40,160 --> 00:23:45,680
missed a certain point I was going to make, which was that technology is not neutral as we

235
00:23:45,680 --> 00:23:56,560
discussed, but also another misconception tech bros have is they think that all technology will do

236
00:23:56,560 --> 00:24:02,640
is that it'll just amplify who we already are. And that comes with a lot of assumptions and

237
00:24:02,640 --> 00:24:07,600
ideological presuppositions that we already know who we are, that yes, human beings are static and

238
00:24:07,600 --> 00:24:13,120
that we have a specific nature of some kind. And secondly, that technology will just make

239
00:24:13,120 --> 00:24:21,200
kind of better versions of what human beings are. Whereas I would say if a lot of, well,

240
00:24:21,200 --> 00:24:29,600
I would certainly religion, but also philosophy, 20th century philosophy history, and now more

241
00:24:29,600 --> 00:24:38,080
recent sociological and psychological research is showing us that no human beings are malleable,

242
00:24:38,080 --> 00:24:44,800
not in a bad sense, nor in a good sense. We are malleable as such. And therefore, it's a mistake

243
00:24:44,800 --> 00:24:51,680
to assume that the human subject, even at an individual level, can, can just, we can amplify

244
00:24:51,680 --> 00:24:58,400
who we are. That, that, that doesn't happen. Our social environment deeply affects us. But,

245
00:24:58,400 --> 00:25:04,000
but saying all that though, is it because I don't get it, because for me, my whole,

246
00:25:04,000 --> 00:25:08,960
my whole view with technology is we're moving towards a, thanks to capitalism. And I mean

247
00:25:08,960 --> 00:25:14,080
that obviously, sadonically, a post humanist society where human beings simply become agents

248
00:25:14,080 --> 00:25:19,440
of capital, they become technical agents in society. But when you talk about self worship,

249
00:25:19,440 --> 00:25:24,160
that kind of gives it a bit of a different thrust. So perhaps you could expand on that a bit.

250
00:25:24,160 --> 00:25:27,280
Yeah, yeah. But yes, also, so what you're mentioning around

251
00:25:27,680 --> 00:25:34,080
the technology having kind of its own essence, right, that whole thing. I

252
00:25:36,720 --> 00:25:42,880
think, and so most people now they see it as neutral, but that misses the point. It's like,

253
00:25:42,880 --> 00:25:47,920
when, because I think when you say all technology is self augmenting, you kind of assume that it's

254
00:25:47,920 --> 00:25:53,440
neutral, right, like it just augments. But no, it has its own essence, it has its own metaphysics,

255
00:25:53,520 --> 00:25:56,560
as we were discussing, right? Yes, its own reality in some sense, which

256
00:25:58,400 --> 00:26:01,680
yeah, it's a hyper reality as well, as you mentioned. And I think the last thing I read

257
00:26:01,680 --> 00:26:05,840
is from Jack, Jack's, I'm not sure you pronounce his name, but he he's also written quite a bit

258
00:26:05,840 --> 00:26:16,240
of on technology. And he recognized it as a self augmenting force, but one that kind of

259
00:26:16,240 --> 00:26:21,600
engineers the world on its own terms. And so I guess that's the way that's how that's how

260
00:26:21,680 --> 00:26:26,400
Heidegger ends his essay in fact. Heidegger makes the point towards the end of his essay,

261
00:26:27,120 --> 00:26:32,320
that technology has a being of its own, that that does change and augment the world. Yes.

262
00:26:32,320 --> 00:26:36,000
Yeah, because it is self augmenting in its application, right? And so in that sense,

263
00:26:36,000 --> 00:26:40,320
it's like it's neutral because it just augments the human subject. But no, it kind of does it

264
00:26:40,320 --> 00:26:44,320
on its own terms because then you create something, you create a being, almost a mode of being,

265
00:26:44,320 --> 00:26:48,000
right? And that has its own essence, its own metaphysics, that's what we've been repeating.

266
00:26:48,000 --> 00:26:52,720
And I want to give an example on that. I think kissing point would be the stock market.

267
00:26:52,720 --> 00:26:58,000
Majority of the stock market, it's not human beings, the actors in the stock market aren't

268
00:26:58,000 --> 00:27:03,600
human beings anymore. It's virtually robots. It's program machine softwares that are doing

269
00:27:04,160 --> 00:27:10,720
stock trading and whatnot. And yes, you could argue that the capitalist by by workers and by

270
00:27:10,720 --> 00:27:18,320
human beings. But regardless, the stock market now is a system with with its own metaphysics,

271
00:27:18,320 --> 00:27:26,560
with its own reality. And human beings are becoming unnecessary for it. We're becoming

272
00:27:28,560 --> 00:27:33,440
so before before we get into the self worship bit, I think it's important to kind of get into

273
00:27:34,480 --> 00:27:38,080
what we mean really when we think about the essence of metaphysics

274
00:27:39,040 --> 00:27:42,560
of technology, right? Because I think we've said this many times, but it's not I think it's not

275
00:27:42,560 --> 00:27:47,040
we can make it clearer like what that actually means. And so kind of self worship, if I was to

276
00:27:47,040 --> 00:27:52,160
talk about the art, I would kind of think about it more to like towards the end, like self worship

277
00:27:52,160 --> 00:27:56,720
is kind of where we're leading ourselves ourselves to. But even right now, what we're participating

278
00:27:56,720 --> 00:28:05,360
is in like this whole met like this whole hyper reality that we live in is it's got a it's got

279
00:28:05,440 --> 00:28:10,880
its own metaphysics, it's got its own essence. And what that means, right? I think the example

280
00:28:10,880 --> 00:28:18,480
we mentioned earlier was that we start to see people as resources. That's kind of one way to

281
00:28:18,480 --> 00:28:23,120
look at it. Well, okay, to really, really break this down, because I know that you and I tend to

282
00:28:23,120 --> 00:28:30,320
get very abstract without thinking is metaphysics in a very pragmatic way of putting it is it's

283
00:28:30,400 --> 00:28:37,200
simply telling us an art. That means what are we supposed to do? Now, of course, if you go to

284
00:28:37,200 --> 00:28:42,160
Aristotelian metaphysics, you could you could look for the metaphysics or the essence of a tree.

285
00:28:42,160 --> 00:28:46,720
What's a tree? Is there a platonic tree somewhere? Well, let's let's forget about all of that for a

286
00:28:46,720 --> 00:28:52,960
moment. Let's just simply think at a at a social level, metaphysics is an art. So what are we

287
00:28:52,960 --> 00:28:59,200
supposed to do with a without given reality? And connecting that in my view, connecting that to

288
00:28:59,200 --> 00:29:07,040
human resources would be okay, the metaphysical sort of injunction or what they're told to do

289
00:29:07,040 --> 00:29:16,640
is to take these human agents and use them to, I don't know, maximize profit or maximize

290
00:29:16,640 --> 00:29:23,120
productivity, optimize or be more efficient. So that is kind of the metaphysical injunction or

291
00:29:23,840 --> 00:29:28,880
ideological injunction that is metaphysical after all. And that's the kind of the way I view

292
00:29:29,760 --> 00:29:33,680
the the metaphysics of technology, although, although, and I want to kind of put this caveat

293
00:29:33,680 --> 00:29:38,640
here. So because we started off with Heidegger, look, this port isn't on Heidegger, but we started

294
00:29:38,640 --> 00:29:42,240
off with Heidegger. So it doesn't have to be about Heidegger, but for Heidegger, it's not just

295
00:29:42,240 --> 00:29:47,920
that it's also he's looking for an essence of technology and what that entails. But sorry,

296
00:29:47,920 --> 00:29:50,960
did my kind of point about the, you know, that's good. That's good. So it's kind of

297
00:29:52,320 --> 00:29:55,840
and I think there's one more layer to it as well. Like, I think, you know, we see each other's,

298
00:29:55,840 --> 00:29:59,920
we see each other as as capital resources, essentially, and that's a danger to her, obviously,

299
00:29:59,920 --> 00:30:06,560
right? But I think there's one, like, another layer of art as well is I think

300
00:30:07,920 --> 00:30:13,360
we kind of blend on this idea, like this intrinsic idea that we don't talk about that.

301
00:30:14,800 --> 00:30:22,400
If we, if we liberate ourselves from everything, we would be happier. It's that kind of,

302
00:30:23,280 --> 00:30:26,960
like it's just the classic capitalist kind of ideology, right? And that's something very

303
00:30:26,960 --> 00:30:33,360
inherent in technology, right? It's like the thing that causes us unhappiness is like systems

304
00:30:33,360 --> 00:30:39,600
or structures that we have to be liberated from. And that's, that's sometimes true. But I think now

305
00:30:39,600 --> 00:30:44,800
we're getting to the point where we, we're trying to liberate ourselves from reality itself.

306
00:30:46,080 --> 00:30:50,960
Right. And so, but then the thing is that in a far more fundamental way, it's just making

307
00:30:50,960 --> 00:30:56,960
far more people more unhappy, which is, which is, which is a contradiction, almost ironic

308
00:30:56,960 --> 00:31:01,760
contradiction you pointed out before. And you know, you would, you, you in fact hit the nail on

309
00:31:01,760 --> 00:31:07,520
the head because this guy Ray Kurzweil, who is kind of like a futurist, he, I remember reading,

310
00:31:07,520 --> 00:31:11,920
I haven't read any of his books, but he is kind of known as well. He, he perhaps is like before

311
00:31:11,920 --> 00:31:18,640
Balaji and Elon Musk and all these types. He was kind of the OG tech bro. And he was writing about

312
00:31:18,640 --> 00:31:25,600
these things, you know, in like the nineties. And he has this really interesting essay, which I read,

313
00:31:25,600 --> 00:31:34,160
I forget where, but he talks about how you could just live in a simulation and you won't be limited

314
00:31:34,160 --> 00:31:39,280
by your physical reality. So you could live kind of the mind in a back machine. So if you, one day,

315
00:31:39,280 --> 00:31:44,640
if you feel like a woman, you are a woman. And not to go to the whole gender, you know,

316
00:31:44,720 --> 00:31:47,440
debate about that, like forget about it. But no, I think it's true.

317
00:31:47,440 --> 00:31:53,600
Like if you feel like, look, let's say a biological female, right? You just all you got to do is

318
00:31:54,480 --> 00:32:01,040
kind of cognize that in your, in your, in your brain. And then you become that thing. So

319
00:32:01,760 --> 00:32:08,400
we kind of completely let go of our physical embodied reality, which for Heidegger, Maurice

320
00:32:08,400 --> 00:32:15,760
Molleponti or modern Cogsci, a cognitive science would be an, and complete abomination,

321
00:32:15,760 --> 00:32:18,560
given that we are deeply embodied creatures to be human.

322
00:32:18,560 --> 00:32:25,840
Yeah. Well, at the end of the day, we try and liberate ourselves from reality. So precisely,

323
00:32:25,840 --> 00:32:34,800
that's what we're doing. Yes. Because also that Heidegger is kind of metaphysics, right? It's

324
00:32:34,880 --> 00:32:40,480
not just about you, but it's about, it's not just about subject and object. That's kind of

325
00:32:40,480 --> 00:32:44,000
his metaphysics. He breaks it. Yeah. No differentiation there. It's kind of the

326
00:32:44,000 --> 00:32:48,880
subject participating, subject and object are one. Yeah. Yeah. I mean, look, he has got many,

327
00:32:48,880 --> 00:32:54,160
like he calls it that's man, he calls it life. Well, the idea being that you can't just, yeah,

328
00:32:54,160 --> 00:32:59,920
you can't isolate the subject from their life world as such. Yeah. Yeah. So to put it simply,

329
00:33:00,160 --> 00:33:06,000
it's like kind of man has a certain relation to nature, right? Man has a certain relation to

330
00:33:06,000 --> 00:33:11,440
others, like the other, right? And there's a certain kind of,

331
00:33:14,160 --> 00:33:17,920
without going into what that should look like, I think what technology does is it comes in

332
00:33:17,920 --> 00:33:23,760
and imposes a certain view on that, right? Like, because traditionally, like pre-modernity,

333
00:33:24,400 --> 00:33:30,880
like man so nature as something to be worked with. Correct. Like man so fellow man as like

334
00:33:30,880 --> 00:33:35,920
something to be treasured as friends. In fact, the kind of what technology does,

335
00:33:35,920 --> 00:33:41,680
what the whole technological worldview does, this is, again, talking of discussing its essence,

336
00:33:42,800 --> 00:33:49,280
is firstly, kind of nature is seen as something to be used as a resource, right? Slash is to be

337
00:33:50,240 --> 00:33:56,320
overpowered, right? And overpowered means used, right? It's kind of the same thing. And the danger

338
00:33:56,320 --> 00:34:00,160
is that the same thing is applied to man, right? Like man becomes human resources, as you say,

339
00:34:00,160 --> 00:34:04,960
it's something to be used. And so in that sense, you can kind of see how technology is not neutral,

340
00:34:04,960 --> 00:34:09,600
it imposes a worldview, that's the essence. I mean, also, on your point on pre-modernity,

341
00:34:09,600 --> 00:34:15,040
the Hegelian point there would be in pre-modern society, and obviously I'm not a historian,

342
00:34:15,120 --> 00:34:22,560
but from what I've read, it's not even that we, that individuals, so other individuals as,

343
00:34:23,200 --> 00:34:29,680
as, oh, that's someone that I'm related to. No, no, no, they saw their subjectivity in them. As in,

344
00:34:30,400 --> 00:34:34,640
I am you as much as you are me. Yeah. Oh, no, no. Oh, yeah. No, but I'll give you the

345
00:34:34,640 --> 00:34:39,120
technological spin, right? It's not like, because nowadays, what's the phenomenon we call the social

346
00:34:39,120 --> 00:34:43,280
phenomenon? Everything is kind of networking, right? Yes. Oh my god, dude, you read my mind again.

347
00:34:44,240 --> 00:34:48,480
But like, when you speak to other people, you are like, what's the career gain here?

348
00:34:48,480 --> 00:34:54,560
Correct. I hate the term networking. It's a total term. It's just even something as

349
00:34:54,560 --> 00:34:58,640
intimate as friendship becomes something where I need to get something from that person

350
00:34:58,640 --> 00:35:05,360
for me to rise in the social hierarchy or whatnot. Exactly. So that's the imposition of

351
00:35:05,360 --> 00:35:10,800
technology, right? Sorry, sorry, sorry. I interrupt you. Can you say that, make that point again,

352
00:35:10,800 --> 00:35:14,080
a bit more, like fresher out a bit more, because I feel like you were getting out,

353
00:35:14,080 --> 00:35:20,720
making a really good point and I got excited. So again, clearly, so people get what you're

354
00:35:20,720 --> 00:35:24,720
saying is really, really, it happens between us. But yeah, so technology has an essence, right?

355
00:35:24,720 --> 00:35:28,880
And two clear examples where I can see it playing out. And I think which Heidegger touched on in

356
00:35:28,880 --> 00:35:37,680
book as well is like nature and fellow men, right? So you, we used to see nature as something to

357
00:35:37,760 --> 00:35:43,040
work with. We used to see men and women as friends, right? Friendships would be cultivated.

358
00:35:43,760 --> 00:35:47,840
We kind of saw everything on equal ground. But then when the capitalistic slash technological

359
00:35:48,800 --> 00:35:55,840
ideals, ideas started playing in the picture, then we, that started twisting our worldview, right?

360
00:35:55,840 --> 00:36:02,400
It started twisting our relation to the things around us. And as Heidegger's metaphysics goes,

361
00:36:02,400 --> 00:36:09,440
and which I actually, I personally agree with, like man is not just an individual, right? That

362
00:36:09,440 --> 00:36:14,960
uses things. No, like it's not just a subject and a relation to the object, like being separate in

363
00:36:14,960 --> 00:36:19,200
any way, right? In the subject very much participates in the object in a very,

364
00:36:20,880 --> 00:36:28,240
like you can't, you can't separate them in a very inseparable way. And so when technology comes in

365
00:36:28,240 --> 00:36:35,600
and twists certain views, you know, it's, it affects the human, it affects the mind to an

366
00:36:35,600 --> 00:36:40,480
understated degree. And that's why I think these days, right? It's something that's so heavily

367
00:36:40,480 --> 00:36:44,560
encapsulates everyone's thinking that they kind of not, you're not even conscious of it.

368
00:36:45,600 --> 00:36:49,200
I mean, it changes you. It makes you something human.

369
00:36:50,000 --> 00:36:55,840
Yeah. Yes. Like nowadays, like meeting someone purely for career gains normal,

370
00:36:55,920 --> 00:37:01,440
whereas it wasn't 50 years ago. And that's what technology does to us. And like using nature

371
00:37:02,320 --> 00:37:08,240
is normal to us, right? Yeah. I mean, we can't use it. We can't exploit. We can't exploit. We

372
00:37:08,240 --> 00:37:14,000
commoditize nature. But if you tell that to like an indigenous, you know, someone in, in this,

373
00:37:14,000 --> 00:37:18,400
I don't know, 1400s, 1300s, that would sound absolutely. Even our own Aboriginal people in

374
00:37:18,400 --> 00:37:22,160
Australia, like, I mean, I'm sure, obviously, don't get me wrong. I'm not making, I hate to

375
00:37:22,160 --> 00:37:26,720
make the racist argument or their primitive native one with nature. None of that nonsense.

376
00:37:26,720 --> 00:37:33,840
But if you, if you speak to, let's say, it doesn't have to be, leave aside the Aboriginal people,

377
00:37:33,840 --> 00:37:40,640
because I hate that argument, you know, noble savage, it's very racist. But if you study, if you

378
00:37:40,640 --> 00:37:47,840
do like, listen, anthropological study, anthropological study and explore these communities,

379
00:37:48,400 --> 00:37:55,520
certainly they don't have this concept of exploiting nature or using seeing nature as a resource.

380
00:37:55,520 --> 00:38:03,840
For them, nature was very much alive. And it was, it was a part of them as much as they were part of

381
00:38:04,720 --> 00:38:09,920
it. Yeah, yeah, yeah, precisely. And that's, and that's one of the things, right? Because now the

382
00:38:09,920 --> 00:38:16,080
danger, I think, is the kind of metaphysical problem. Like it's a, it's a kind of a spiritual crisis,

383
00:38:16,080 --> 00:38:22,480
right? As you will call it. That is, we're losing our relation to everything around us, right?

384
00:38:22,480 --> 00:38:26,320
We start to see nature as something to be used. We start to see humans as something to be used.

385
00:38:27,280 --> 00:38:30,880
And there's something that you lose there. There's something that you lose there. And I think

386
00:38:30,880 --> 00:38:34,880
that's where kind of my whole idea around self worship comes in, because that's a position of

387
00:38:34,880 --> 00:38:41,520
pride, right? That's to say that, you know, kind of my imperative here is to have power over

388
00:38:41,840 --> 00:38:47,040
everything. It's to kind of reinvent, like impose a new order and everything.

389
00:38:47,040 --> 00:38:49,600
It becomes a Hobbesian nightmare, you know, it's just.

390
00:38:49,600 --> 00:38:53,440
Yeah, yeah, yeah, yeah. And I think like, and that's probably the Christian worldview in me

391
00:38:53,440 --> 00:38:58,320
speaking as opposed to the Nietzschean, because the Nietzschean ideals will be like, no, let's reinvent

392
00:38:58,320 --> 00:39:02,880
the way things are done. But I don't think that's possible in many ways. And that's why I kind of

393
00:39:02,880 --> 00:39:10,320
refer to C.S. Lewis, because like in the abolishment of man, abolishment of, abolishment of man.

394
00:39:11,280 --> 00:39:16,640
My favorite Lewis book by myself, right? He basically writes precisely about this subject,

395
00:39:16,640 --> 00:39:21,360
right? Which is like the Nietzschean ideal kind of falls on its own head, because you can't

396
00:39:22,480 --> 00:39:29,520
revalue values using the values, using the values themselves, right? And so there's,

397
00:39:29,520 --> 00:39:33,360
there's a lot to be. I have a slight disagreement there, but we don't have to get to that. I have

398
00:39:33,360 --> 00:39:39,520
a slight philosophical debate there. We can do it another time. But the whole danger there is one

399
00:39:39,520 --> 00:39:44,560
of pride, right? And I think putting aside the Nietzschean idea, which I think there's some problems

400
00:39:44,560 --> 00:39:49,440
there. I think if you look at it from a Christian point of view, it's like pride goes before a fall

401
00:39:49,440 --> 00:39:57,600
to put it more simply. And also to cover a bit of what Lewis prophesied in the abortion of

402
00:39:57,600 --> 00:40:06,080
ban book is if we keep on trying to go down this path of like gaining power over everything,

403
00:40:06,080 --> 00:40:13,120
we gain power over nature, we can use, we can extract everything as resources, we start doing

404
00:40:13,120 --> 00:40:18,640
the same to other people. And eventually we start doing the thing to human nature itself, right?

405
00:40:18,640 --> 00:40:27,200
And there's the whole kind of thing around the whole he prophesies this endpoint to be kind of

406
00:40:27,200 --> 00:40:35,360
the eugenic event, right? The event at which basically man takes on the position of God as a

407
00:40:35,360 --> 00:40:40,640
creator. Yeah, yeah. And you know, connecting that to a bit of what Heidegger is talking about here,

408
00:40:40,640 --> 00:40:46,000
that's sort of what he means by enframing. And the grand irony of all of that was Heidegger was a

409
00:40:46,000 --> 00:40:51,920
big old Nazi. And the Jews were exactly, they were enframed, they were just used things to be

410
00:40:53,040 --> 00:41:01,680
powered to exploit and used upon. And certainly, you know, even the Nazi ideal has an element of

411
00:41:01,760 --> 00:41:08,080
self-worship. But for them, it's more that they worship a system, they worship the organic unity

412
00:41:08,080 --> 00:41:15,840
or the whole of being, which for me is a fascistic idea. So as you were, as you were

413
00:41:15,840 --> 00:41:22,640
expounding on the self-worship, but I was trying to figure out, how can I juxtapose this with kind

414
00:41:22,640 --> 00:41:28,240
of my thesis, which is the post-humanist idea that we are becoming, we're becoming something that is

415
00:41:29,200 --> 00:41:34,800
not human. The future of humanity is going to be without human beings, so to speak.

416
00:41:36,880 --> 00:41:42,320
I'm going to try to make a point here, but you were going to say something. You go first?

417
00:41:42,320 --> 00:41:48,000
Yeah, yeah. I think that's the hyper-reality element to it. Yeah, yeah. So I don't think

418
00:41:48,000 --> 00:41:52,640
Louis saw it from that lens, right? So says Louis specifically saw it from the lens of eugenics. And

419
00:41:52,720 --> 00:41:58,800
I think there's something to that point as well, which is the final stage of man's conquest over

420
00:41:58,800 --> 00:42:08,000
nature is basically when, you know, in the course of reality, when someone, like when one age,

421
00:42:08,560 --> 00:42:14,480
one age really attains, you know, by eugenics, the power to make its descendants as whatever it

422
00:42:14,480 --> 00:42:19,360
pleases. Yeah. I mean, for me now, I would still say that's post-humanist, because the post-humanist

423
00:42:19,360 --> 00:42:25,360
idea is that there's no, there's no human being per se. We're just, again, we're biological entities

424
00:42:25,360 --> 00:42:31,680
and we can be optimized, we're used. And so, and so what Louis points out is that in a way,

425
00:42:31,680 --> 00:42:39,680
all men who live after this age are patients of that power. So then they are weaker, not stronger.

426
00:42:39,680 --> 00:42:43,200
Yeah. So like, no matter what kind of power. That's a supreme irony. Yeah.

427
00:42:43,200 --> 00:42:47,840
The things we put in their hands, it's this people in this age which has preordained how

428
00:42:47,840 --> 00:42:52,400
they are to use them. So in a very interesting way, Louis prophesied this endpoint, this event

429
00:42:52,400 --> 00:42:58,960
at which we are bringing ourselves to this route, which is we, our conquest becomes over human nature

430
00:42:58,960 --> 00:43:05,120
itself. And I think a very vivid image of this is in Huxley's Brave New World, right? This human

431
00:43:05,120 --> 00:43:10,480
nature is the last part of nature to surrender to men, right? And in Brave New World, in Huxley's

432
00:43:10,480 --> 00:43:14,880
Brave New World, there's eugenics, there's like prenatal conditioning, I believe, right? Yeah.

433
00:43:15,520 --> 00:43:20,320
And of course, happiness drop, yeah. Perfected the human species, right?

434
00:43:21,280 --> 00:43:25,360
And there's like a perfect, I don't know, applied psychology, whatever, and man has

435
00:43:25,360 --> 00:43:29,600
perfect control over it. Behaviorism, BF skin and behaviorism, man, it's a monastic, yeah.

436
00:43:29,600 --> 00:43:33,120
Yeah. Yeah. And basically, Louis points out that that's the point at which

437
00:43:34,240 --> 00:43:37,200
man reaches the pinnacle of the power and everyone else is kind of,

438
00:43:38,880 --> 00:43:44,400
you know, a prisoner of that. Yeah. So that's something I find interesting. But the artificial

439
00:43:44,400 --> 00:43:49,920
piece, artificial intelligence is something else. It might be something else or it might not be.

440
00:43:49,920 --> 00:43:53,520
I'm also wondering how we can kind of dive into this. Well, in fact, when I was going to bring

441
00:43:53,520 --> 00:43:59,280
this up to you at the end of the part, but I think we, this whole conversation, we can end on a

442
00:43:59,280 --> 00:44:03,920
positive note. And I'll tell you why. And as you know, I'm very cynical. I don't really end things

443
00:44:03,920 --> 00:44:12,320
on positive notes generally. But this, this topic of technology, there is in the typical

444
00:44:12,320 --> 00:44:18,240
Hegelian move in the failure, there can, there can be something good that comes out of it, I believe.

445
00:44:20,560 --> 00:44:25,920
So firstly, the reason, you know, I was a bit initially a bit confused about the

446
00:44:25,920 --> 00:44:30,960
self-worship point was the way I, the way I view the kind of post-humanist idea is that

447
00:44:32,080 --> 00:44:40,560
human subjects, they, they, they stop viewing themselves as human beings. Whatever this deep

448
00:44:40,640 --> 00:44:45,440
down identity we have as human beings, it's just, it's jenisin. But then I realized, in fact,

449
00:44:45,440 --> 00:44:50,800
no, the self-worship point is perhaps more perspicacious because in post-modern society,

450
00:44:50,800 --> 00:44:57,920
we live in this kind of ruthless pragmatism. So being a self-worshipping, egoistic,

451
00:44:57,920 --> 00:45:04,400
narcissist is one of the best ways to get around post-modern capitalist society if you are a bit

452
00:45:04,400 --> 00:45:10,400
Machiavellian, because then, you know, as we were discussing, if we view other human beings as not

453
00:45:10,400 --> 00:45:17,600
really human, but rather some other biological agents to be used and exploited, then pretty much

454
00:45:17,600 --> 00:45:23,680
the best way is to play the game, play the game and get to the top, whatever the top and, and the,

455
00:45:23,680 --> 00:45:27,680
and the funny thing is in post-modernism, the top doesn't even matter, it's just climb the hierarchy

456
00:45:27,760 --> 00:45:33,920
for the sake of climbing the hierarchy. There, there's no, there's no, there aren't the, let's say

457
00:45:33,920 --> 00:45:40,160
the, the, the, the typical values of, of beauty, love, truth or God, none of that. It's just climb

458
00:45:40,160 --> 00:45:44,960
the hierarchy. We discussed this in the previous pods, isn't it? So, and then in that self-worship

459
00:45:44,960 --> 00:45:50,880
kind of works because it's not self-worship in the sense that you think, I don't know, at least

460
00:45:50,880 --> 00:45:55,280
this is my interpretation of it, but there's something special about me that I'm unique,

461
00:45:55,280 --> 00:46:01,280
I'm divine and none of that, it's just, I am, I am who I am. It doesn't even matter, but what matters

462
00:46:01,280 --> 00:46:07,440
is the, is the game, is the, is the task, it's the, it's the, it's partaking in, in, in the, in the

463
00:46:07,440 --> 00:46:17,920
social game, so to speak. Um, yeah, yeah. Well, I think there are two ways to look at it, right? And

464
00:46:17,920 --> 00:46:21,600
earlier, as I mentioned, like there's kind of a Nietzsche approach, which is to lean into it,

465
00:46:22,240 --> 00:46:26,960
because if you are going to think about, like, because Nietzsche's idea is like,

466
00:46:26,960 --> 00:46:31,040
the Ubermanches, like the Superman, that's the ideal you want to, you want to be, right? You

467
00:46:31,040 --> 00:46:38,800
want to be the person to kind of revalue valuations, right? Yeah. Rebuild and kind of, I mean, you want

468
00:46:38,800 --> 00:46:43,920
to even, you want to rebuild the, the meta values itself, not just values, but reevaluate what values

469
00:46:44,000 --> 00:46:53,520
are itself. Yeah. Yeah. Yeah. Yeah. And so kind of, as we discussed, technology is a major imposition

470
00:46:53,520 --> 00:46:59,040
on like the way things are done and how like worldviews, like, like to do the modern worldviews,

471
00:46:59,040 --> 00:47:03,760
right? If you were to work and build within that space, you kind of have the opportunity to do

472
00:47:03,760 --> 00:47:10,160
something like that, right? Well, I mean, actually, I was like, sorry, like, I guess the

473
00:47:10,640 --> 00:47:18,560
easiest way to say how much of an impact technology is, is if we were to boil down the ages

474
00:47:19,600 --> 00:47:27,360
into one word, like you wouldn't call this current age we're in and, you know, a post-modern age,

475
00:47:27,360 --> 00:47:31,680
like that does some, that's mean something. If you call it an atheistic age, like, yeah,

476
00:47:31,680 --> 00:47:35,280
that's something, I think people usually call you a technological age. Correct. Because I mean,

477
00:47:35,280 --> 00:47:39,760
post-modern age, you could even call it the last century, but our specific age is perhaps

478
00:47:39,760 --> 00:47:45,280
the technological age. So I think you can conclude from that. Say to say, technology has been like

479
00:47:45,280 --> 00:47:50,640
the genre, like the era defining thing, right? And so if you were to pursue the Nietzsche ideal,

480
00:47:50,640 --> 00:47:54,720
you have the opportunity to redefine the way everything starts, right, in that lens. I think,

481
00:47:55,280 --> 00:48:01,040
although on the Christian kind of religious path, I think there's a, there's quite something to the

482
00:48:01,040 --> 00:48:07,520
whole idea of, I think I saw this coin somewhere, but it's like technological acesis, I think, like,

483
00:48:08,320 --> 00:48:13,760
like acicism, like being a technological aesthetic, right? Basically, distancing yourself from

484
00:48:13,760 --> 00:48:21,520
technology and its metaphysics. And the whole imperative there is like, be aware that, you know,

485
00:48:21,520 --> 00:48:26,080
technology in everything, there is a trade-off, right? Like, no technology is perfect,

486
00:48:26,080 --> 00:48:32,400
everything comes at a price, and prices that we're not aware of. And more importantly,

487
00:48:32,400 --> 00:48:37,120
that you can't have your cake and eat it too. Exactly. Because the trade-off argument for

488
00:48:37,120 --> 00:48:40,400
me, that's too pragmatic. Because that kind of makes the assumption that, oh, you can have the

489
00:48:40,400 --> 00:48:44,400
good without the bad. I don't think that's how the reality works. I agree. But I think, firstly,

490
00:48:44,400 --> 00:48:49,760
you'll become aware of it, right? You'll be aware of it. Certainly. The whole imperative there from

491
00:48:49,760 --> 00:48:53,680
the Christian point of view is to kind of keep the means, the means, and keep the ends, the ends,

492
00:48:53,680 --> 00:49:00,400
right? Yes. I actually made a note earlier, but I think Ivan Illich, I think that's his name,

493
00:49:00,400 --> 00:49:05,200
he's also written quite a bit on technology. You may have to send me all these things because

494
00:49:05,280 --> 00:49:10,880
I need to put them in the show. But he argues for what he calls a convivial use of technology.

495
00:49:10,880 --> 00:49:14,480
Sorry, what was that word? Convivial. Right. I don't actually don't know what it means.

496
00:49:16,320 --> 00:49:22,000
That's what he called it. But what that entails basically is firstly, technology

497
00:49:22,800 --> 00:49:28,880
exists to fulfill man's existing needs and desires, instead of generating new needs and desires.

498
00:49:29,600 --> 00:49:35,920
And so, technology, capitalism, you can kind of, that's when you place the means as means and

499
00:49:35,920 --> 00:49:40,160
ends as ends, I think. The other point is quite simple. Increases man's freedom,

500
00:49:40,160 --> 00:49:46,400
independence, enhances welfare, physical man. Okay, okay. Now here's where my cynical side is

501
00:49:46,400 --> 00:49:53,040
coming out. As a Zhezhekian lecanian, I don't know if that's possible. This is the way I become

502
00:49:53,040 --> 00:50:00,720
very cynical. I don't know if it's possible for us to purely use technology as something that,

503
00:50:01,440 --> 00:50:07,840
as a tool, which is how most of us think it was used. As a pure tool that fulfills our desires.

504
00:50:07,840 --> 00:50:13,200
Because firstly, I don't think human desire can ever be fulfilled. We are desiring beings. And

505
00:50:13,200 --> 00:50:20,720
for me here, lecan is, he is a prophet, he gets it, he gets it precisely. Which again,

506
00:50:20,720 --> 00:50:27,600
is the problem. Which the problem is that our desires are unfulfillable. Therefore, the technological

507
00:50:27,600 --> 00:50:33,360
metaphysics or whatever you may call it, can exploit those desires. And for me though, for me

508
00:50:33,360 --> 00:50:40,320
though, I don't know, as far as I can say, my only way to approach this is to take on that

509
00:50:40,320 --> 00:50:48,160
contradiction. It's not to, it's not to try and take the good without the bad. Because that,

510
00:50:48,240 --> 00:50:53,200
as C.S. Loews points out, would make things worse, is to take on the contradiction. And of

511
00:50:53,200 --> 00:50:57,360
course, that doesn't mean succumbing and giving into the bad. I'm not saying, oh, go and become a

512
00:50:57,360 --> 00:51:02,960
porn addict in, I don't know, Mark Zuckerberg's meta word and just like that. I don't mean that.

513
00:51:02,960 --> 00:51:08,960
I mean, as you said, first be aware of it. And then the only solution I see is through critique,

514
00:51:08,960 --> 00:51:16,240
through perpetual critique, through working through the contradictions and doing all these

515
00:51:16,240 --> 00:51:20,000
things which some people who are a bit more intellectual might find silly. Things like,

516
00:51:20,000 --> 00:51:25,680
you know, social media detoxes, digital minimalism. Those are good things. We should not sneer at them

517
00:51:25,680 --> 00:51:30,960
and kind of look down upon them. Because that's the, again, that's our life world. We can't,

518
00:51:32,160 --> 00:51:36,880
don't play the Buddhist game or the quasi-Buddhist game where you, oh, everything's a cosmic

519
00:51:36,880 --> 00:51:42,000
phenomenon. Detach us. No, no, no. For me, it's partaking the contradictions and work through them.

520
00:51:42,240 --> 00:51:44,960
Which is hard, which is difficult work.

521
00:51:44,960 --> 00:51:48,800
Right. You know, that's a good point. But also, yeah, I guess from a psycho and analytical

522
00:51:48,800 --> 00:51:52,960
point of view, it's like desire is everything. Yeah. Desire is fundamental because we are

523
00:51:52,960 --> 00:52:00,240
lacking beings. That's an interesting one. But I think very much there are kind of different

524
00:52:00,240 --> 00:52:06,560
levels to it. And where my mind goes with that is like to go back to kind of the whole essence

525
00:52:06,560 --> 00:52:14,080
of technology, right? I think one of the major, like one, I'd say even it's, it's driving force

526
00:52:14,880 --> 00:52:20,560
is that within technology itself, it's essence. It's not just that you're engineering tools,

527
00:52:20,560 --> 00:52:27,440
but you're engineering desires. Certainly. Because it reveals. It reveals. Yeah, you're kind of,

528
00:52:27,440 --> 00:52:32,560
and it's, that's a very deliberate thing, right? And that's the whole, that's the whole concept of,

529
00:52:32,560 --> 00:52:41,520
that's not concept. The whole driving force of capitalism and social engineering or propaganda,

530
00:52:41,520 --> 00:52:47,760
right? I mean, I mean, social engineering, ideology, it's also kind of how like people

531
00:52:47,760 --> 00:52:51,680
like Balaji, they talk about the network state where in the network state, we can create it,

532
00:52:51,680 --> 00:52:56,400
where it's not top down planning, but it's bottom up planning. But nonetheless, there still is an

533
00:52:56,400 --> 00:53:01,360
ideology that tells people what to do, which, which communities. But it's like, that's, like,

534
00:53:01,360 --> 00:53:08,000
that's, that's technology. Oh, yeah, certainly. Yeah, he, I mean, he is like technology. It's

535
00:53:08,000 --> 00:53:12,240
like that to me, that is technology. And you know something interesting as, as, I mean, I'm kind

536
00:53:12,240 --> 00:53:16,480
of braver, you know, your, your, your line of thought that I'm sorry for like interrupting

537
00:53:17,360 --> 00:53:22,080
or breaking a lot of thought. So Techne, here's where I really like Heidegger because he placed

538
00:53:22,560 --> 00:53:29,920
his, he's brilliant. Like he's his knowledge on language is unbelievable. Techne in ancient Greek

539
00:53:29,920 --> 00:53:36,320
was also used for art. So art was referred to as Techne and art is perhaps one of the,

540
00:53:37,040 --> 00:53:42,560
you know, perhaps the typical example of something that reveals, right? Art reveals to it. It reveals

541
00:53:42,560 --> 00:53:47,840
new realities, reveals truths. So what's really interesting is that word Techne that was used

542
00:53:47,840 --> 00:53:54,720
for art historically, especially in ancient Greece, is now used for, for technical tools,

543
00:53:54,720 --> 00:54:00,560
for technology. And I don't, I don't know what to make of it, but Heidegger thinks, oh, what,

544
00:54:00,560 --> 00:54:03,760
he's like, okay, why is that? Just got a question why that is. That's really,

545
00:54:03,760 --> 00:54:08,400
Yeah, no, that's just a really good point. But then, yeah, though it becomes clear, right? It's

546
00:54:08,400 --> 00:54:15,040
like, kind of propaganda is, is not part of it. It's like propaganda is almost like,

547
00:54:15,840 --> 00:54:19,520
breathing air. It's like the breathing air for technology itself, right? Yeah, it's not like

548
00:54:19,520 --> 00:54:25,040
a byproduct. No, no, no, it is it. It is the ideology is it? Yeah. Yeah. There's, there's

549
00:54:25,040 --> 00:54:29,920
obviously this very interesting layer as well, where to the whole worldview or essence of technology,

550
00:54:29,920 --> 00:54:34,800
where it's like, engineer, the engineering of desires. And obviously that's kind of

551
00:54:36,080 --> 00:54:41,840
its own, like we can run a whole separate discussion on. Well, yeah, I mean, one thing I

552
00:54:41,840 --> 00:54:45,440
want to do, in fact, one thing I want to do is, because I know we're going to do some book

553
00:54:45,440 --> 00:54:50,640
discussions in the future is to discuss, because I think, you know, this book here by Todd MacGowden,

554
00:54:52,080 --> 00:54:54,960
capitalism and desire, you know, I've spoken about this a couple of times.

555
00:54:56,960 --> 00:55:01,840
I mean, this, this book could easily be technology and desire and the message of the book would

556
00:55:01,840 --> 00:55:08,960
still stand. If we could just, because they did the two things go hand in hand that tightly

557
00:55:08,960 --> 00:55:16,320
related. Yeah, well, is there any insights from that book that relate to what? Well, I mean,

558
00:55:16,320 --> 00:55:22,800
it's the idea of, the idea of desire is metanomic that it desire, desires for the sake of desiring.

559
00:55:23,440 --> 00:55:27,520
And, and then the idea of object, we don't desire something that exists, it's a virtual

560
00:55:27,520 --> 00:55:32,400
category. And then he connects that to our capitalism functions. But like, I haven't,

561
00:55:32,560 --> 00:55:38,880
I need to like prepare properly if I'm gonna do like, I might do a pod that kind of it's on the book.

562
00:55:40,640 --> 00:55:44,960
Yeah, well, because I guess like the, you know, the accompanying idea there is like,

563
00:55:44,960 --> 00:55:50,880
it's ruling by desires, right? Like it's, it's to bring back the brave new world, right? Like,

564
00:55:50,880 --> 00:55:58,880
because what that contrast is, in a few centuries ago, Orwell wrote 1984. And that was basically

565
00:55:58,880 --> 00:56:06,400
the ruling of a nation, whatever you call it, the ruling of people via control and power, right?

566
00:56:06,400 --> 00:56:13,360
Totalitarian top down, basically. But then Huxley, I think Huxley wrote Brave New World before,

567
00:56:14,320 --> 00:56:18,160
Orwell actually wrote 1984. Oh, is that right? I think Huxley, I think Huxley was right.

568
00:56:20,880 --> 00:56:24,880
Huxley was actually Orwell's lecturer, I think I got the order right. And the very

569
00:56:24,880 --> 00:56:28,320
interesting thing is they had some correspondence between each other, where basically Huxley

570
00:56:28,320 --> 00:56:35,440
disagreed with Orwell. So it was like great writing and whatnot. But he thinks that, you know,

571
00:56:35,440 --> 00:56:42,960
at some point, the totalitarians of the 1984 idea will realize that it's a lot more efficient to

572
00:56:42,960 --> 00:56:52,720
control people by means of desire alone, right? I mean, we live more in and Huxley in reality than

573
00:56:52,880 --> 00:56:57,680
Orwellian. Yeah, yeah. Well, it's like, it's power by giving us what we want, basically.

574
00:56:58,960 --> 00:57:05,520
Or by creating false needs. But giving us what we want, just enough. And that's the point

575
00:57:05,520 --> 00:57:10,480
Tottenham government makes. Capitalism works in the contradiction of it works by not working.

576
00:57:11,120 --> 00:57:18,720
It gives us just enough. Yeah, even like, I think probably like Stalin and Mao even would be impressed.

577
00:57:19,440 --> 00:57:25,680
Yeah. So much control can be. Yeah, yeah. I mean, what's interesting is, you know,

578
00:57:25,680 --> 00:57:28,960
Rijek talks about having a Soviet Union. They always

579
00:57:29,680 --> 00:57:35,280
allowed people a certain level of freedom. They always gave people so you could make jokes

580
00:57:35,920 --> 00:57:41,680
against the state against the party. There was a certain level of, you know, kind of

581
00:57:41,680 --> 00:57:48,880
unsaid humor and that that allowed people to that that this that's exactly how control works.

582
00:57:49,440 --> 00:57:54,480
It's not this kind of the way Orwell imagine. I think personally, Orwell is a bit overrated.

583
00:57:54,480 --> 00:58:01,280
This kind of where it's just tight. You can't say anything. You can't can't utter a word. It's

584
00:58:01,280 --> 00:58:05,840
complete censorship. No, no. It's like, it's kind of like teasing us with a bit of freedom.

585
00:58:05,840 --> 00:58:11,200
We're kept in control, which is why I think we live more in a Huxley in reality than

586
00:58:11,600 --> 00:58:18,000
or within reality. Hey, look, I don't know. Pretty much what I've kind of wanted to discuss,

587
00:58:18,000 --> 00:58:23,280
I think I've made the points, although I did say that I have, I'm a bit optimistic about all of

588
00:58:23,280 --> 00:58:28,720
this, right, regardless of my cynicism. So shall we shall we get there? Or are there any more points

589
00:58:28,720 --> 00:58:33,280
you want to make? Yeah, yeah. Well, yeah, we can talk about optimism, because I think

590
00:58:33,760 --> 00:58:43,120
even though that's the kind of ruling the ideology, happiness ideology, technology is going to save

591
00:58:43,120 --> 00:58:48,000
the world, you know, but what Dostoevsky wrote, beauty will save the world. I think the modern

592
00:58:48,000 --> 00:58:55,520
consensus is something more like technology, which obviously for me, I side with beauty over

593
00:58:55,520 --> 00:59:01,280
technology. But okay, my okay, I don't even know if this is optimistic. All I'm saying is this,

594
00:59:01,920 --> 00:59:08,160
the way I view in the failure, there'll be something good that comes out of it is, in fact,

595
00:59:08,160 --> 00:59:14,000
this is interestingly, the part I did with Dr. Grace Tapie, the Lacanian psychoanalyst,

596
00:59:15,040 --> 00:59:18,960
she kind of put this thought in my head. But before that, I've also been thinking about this a bit.

597
00:59:19,760 --> 00:59:27,680
I think given the fact that technology is doing what it's doing to us, it's kind of

598
00:59:28,640 --> 00:59:33,680
taking us towards this hyper-reality or post-humans' reality, people are starting to have these kinds

599
00:59:33,680 --> 00:59:38,720
of conversations. And I know this is like a very cliche thing to say, but people are starting to

600
00:59:38,720 --> 00:59:45,680
question what is the human subject. People are delving more into metaphysics and philosophy.

601
00:59:45,680 --> 00:59:54,000
And if you think about it, Stephen Hawking, he said that philosophy is dead. For me, now philosophy

602
00:59:54,400 --> 00:59:57,680
is revuifying, because first of all, we are seeing the drawbacks in science

603
00:59:57,680 --> 01:00:01,200
with quantum theory or the interpretation. Artificial intelligence, people are questioning.

604
01:00:02,240 --> 01:00:08,080
And AI is, for me, the ultimate, the epitome of where it concludes, where with AI now is where

605
01:00:08,880 --> 01:00:14,480
philosophy, religion, or certainly religion, philosophy, religion, and religion not at this

606
01:00:14,480 --> 01:00:21,120
kind of fundamentalist naive, but the platonic, neoplatonic, that sense of religion,

607
01:00:21,840 --> 01:00:26,720
or mysticism, whatnot. Because we're starting to ask questions about what is the human subject,

608
01:00:26,720 --> 01:00:32,720
what's our relationship to reality, what is reality as such. And therefore, that's why,

609
01:00:32,720 --> 01:00:44,080
you know, I believe with the failures of our society, it creates way for potential successes,

610
01:00:44,080 --> 01:00:51,200
but not, again, not successes or not good in the techno-optimist sense, where it's going to

611
01:00:51,200 --> 01:00:54,560
move towards some kind of synthesis and everything's going to work out. No, no.

612
01:00:56,000 --> 01:01:00,480
The best way to approach this is to take the contradictions on and critique them and work

613
01:01:00,480 --> 01:01:05,360
through them individually, do the hard work. It's certainly true, because we're critiquing

614
01:01:05,360 --> 01:01:10,080
technology while using technology. Yeah, I mean, look at, this is the ultimate irony, right? This

615
01:01:10,080 --> 01:01:14,800
is the ultimate irony, isn't it? Yeah. And, you know, we'll go one step further. You and I both

616
01:01:14,800 --> 01:01:21,360
are tech bros. We work in tech. You work for a Web3 accelerator, which is the full

617
01:01:21,360 --> 01:01:27,520
front of technology. I'm a software engineer. So this is the example of that.

618
01:01:28,000 --> 01:01:35,520
Yeah, no, but we're actually full on tech bros. Yeah, I mean, the problem with tech bros is,

619
01:01:35,520 --> 01:01:40,480
I would say tech bro-ism. It's, again, it's the ideology. And it's, again, it's not that you

620
01:01:40,480 --> 01:01:47,520
can step outside of ideology, but the problem is this kind of, yeah. Yeah, look, I'm going to say

621
01:01:47,520 --> 01:01:54,400
despite this is going to sound very arrogant, but naive and rather an infantile way of viewing

622
01:01:54,400 --> 01:02:00,240
technology without any depth. And again, the point I made before, Heidegger wasn't a Luddite.

623
01:02:00,240 --> 01:02:05,040
He was full of science and technology. He makes the point, in fact, to his end of the essay that,

624
01:02:05,840 --> 01:02:11,120
but we need to start asking these questions about what is technology and what's, what's

625
01:02:11,120 --> 01:02:16,560
its relationship to us as human subjects. And then again, what are human subjects? And I think AI

626
01:02:17,520 --> 01:02:23,760
is allowing us to really have those conversations, which is why AI is an interdisciplinary field,

627
01:02:23,760 --> 01:02:28,160
you know? So for me, that's kind of where the bit of the optimism comes in, although I'm very

628
01:02:28,160 --> 01:02:34,400
careful when it comes to optimism, because again, it's the prevalent ideology of our day. So I'd

629
01:02:34,400 --> 01:02:39,760
rather be cynical and pessimistic. I think you're right. And that's, yeah, that's a very important

630
01:02:39,760 --> 01:02:43,040
thing to make clear, right? It's like Heidegger wasn't against technology, right? It's like,

631
01:02:43,040 --> 01:02:47,200
Heidegger, I think you could say Heidegger was against the mode of being that kind of

632
01:02:47,200 --> 01:02:52,800
encompassed technology, like kind of, let's be aware of that. But it's, what Heidegger is not

633
01:02:52,800 --> 01:02:57,200
saying is like, do away with technology, become an aesthetic, right? And just, yeah, although he

634
01:02:57,200 --> 01:03:01,520
kind of was like an aesthetic, he lived in a heart most of his life. Oh, right. I didn't know that.

635
01:03:01,520 --> 01:03:07,680
Yeah, look, he's a Nazi weird guy. Honestly, Heidegger personally wouldn't want to be him,

636
01:03:07,680 --> 01:03:12,560
but take his take his philosophy, you know, yeah, but yeah, obviously, I think there is

637
01:03:12,560 --> 01:03:18,240
reason to be optimistic, right? Like as you say, and even from our like, what we're doing now,

638
01:03:18,240 --> 01:03:22,240
this is enabled by technology, right? Like the fact that I can have this conversation,

639
01:03:22,320 --> 01:03:27,440
like remotely, and that we can put it up and we can, like it's scalable, right? Like people can

640
01:03:27,440 --> 01:03:32,400
watch it from wherever they want. And whenever, right, that's something, right? That's not

641
01:03:32,400 --> 01:03:37,040
something that we could do. We talk a lot, we might, we might romanticize pre-modernity and like

642
01:03:37,040 --> 01:03:42,640
this and that. Yeah, yeah, yeah. I romanticize certain parts of it, but if you ask from me,

643
01:03:42,640 --> 01:03:48,960
what's the best time to be alive? It's now. Yeah, yeah, yeah. I agree, I agree. And so like right

644
01:03:48,960 --> 01:03:53,120
now we're a lot more technologically able, like enable than we were before. We have like

645
01:03:53,120 --> 01:03:57,440
extract, we have machines everywhere we look, right? We can do a lot more than we once did.

646
01:03:57,440 --> 01:04:04,160
And that gives a lot of like power in terms of ideas such as this, right? Like it means that we

647
01:04:04,160 --> 01:04:09,680
can discuss ideas such as this and like have much more reach and other people can discuss ideas like

648
01:04:09,680 --> 01:04:15,600
this and have much more reach. And so like that's the reason to be optimistic within the information

649
01:04:15,600 --> 01:04:20,080
age, I suppose. Okay, you and I think you misunderstood me there. My point wasn't even the

650
01:04:20,080 --> 01:04:25,440
functionalist pragmatic point. That is true, that I agree with you certainly. But mine was more,

651
01:04:25,440 --> 01:04:31,840
I was still working on the level of the metaphysics of technology. So given we're doing this

652
01:04:31,840 --> 01:04:38,320
metaphysical analysis and we've, technologies reveal these things to us about being as such,

653
01:04:38,400 --> 01:04:46,880
what I'm saying is, because technology does that, that allows us to, okay, I'll put it this way.

654
01:04:46,880 --> 01:04:53,040
Let's say all of these tools, modern technology, whatever, the zoom, all these things weren't

655
01:04:53,040 --> 01:04:57,520
there, they didn't exist. But technology, the metaphysics of technology was still there.

656
01:04:59,760 --> 01:05:04,320
That's a bad view of putting it. What I'm trying to say is it's not the, I'm not trying to make

657
01:05:04,320 --> 01:05:09,920
and it's not the instances or it's not this mic or zoom or the internet or what not. What I'm

658
01:05:09,920 --> 01:05:19,600
saying is what, what technology reveals metaphysically, that itself allows us to have a conversation

659
01:05:19,600 --> 01:05:24,560
about what the human subject is. If you could say it's kind of like, like Christianity technology

660
01:05:24,560 --> 01:05:32,320
allows itself to be questioned and doubted. Yes, yes. In fact, yes, the Nietzschean point about

661
01:05:32,320 --> 01:05:37,520
Christianity. Yeah. Yeah. So that's kind of the point I'm trying to make. I mean, of course,

662
01:05:37,520 --> 01:05:43,440
these things are great, but by what technology reveals, we start having these questions on being

663
01:05:43,440 --> 01:05:51,600
as such ontologically, ontological questions. But not man. Yeah. And that's, I think I kind of

664
01:05:51,600 --> 01:05:57,520
exhausted everything I had to say. Anything else you want to add? I think I got the main points too.

665
01:05:57,520 --> 01:06:03,920
But like, I always find it interesting, like even a line of thought that my mind's heading to right

666
01:06:03,920 --> 01:06:10,640
now is, you know, even though we're so much more technologically enable now, we can do a lot more.

667
01:06:10,640 --> 01:06:17,040
We've got power. It's all, you know, an interesting questionable sort of power, right? Perhaps it's

668
01:06:17,040 --> 01:06:23,680
a good way to kind of conclude. And I think there's a certain element. There's a certain element to

669
01:06:23,680 --> 01:06:30,640
human existence that's, I haven't quite figured this out, but it's the element of purity, right?

670
01:06:30,640 --> 01:06:36,080
Like with, with the purity of being human, the purity of engaging with nature, there's a purity

671
01:06:36,080 --> 01:06:41,200
of engaging with fellow humans, and somehow technology defiles that. And if we already discussed,

672
01:06:43,120 --> 01:06:48,960
we've already discussed how that looks like, right? But I do wonder if there's a kind of, you know,

673
01:06:49,040 --> 01:07:01,120
ideal state between, an ideal relation between man, nature, and, you know, other people in which

674
01:07:01,120 --> 01:07:05,040
technology can be a part of the picture. That's probably a crucial, one of the crucial questions

675
01:07:05,040 --> 01:07:10,560
that we have to ask, right, these days. But not one, it's not one that I have, you know, a proper

676
01:07:10,560 --> 01:07:14,880
answer to. It's like, there are many different ways to approach it. And it's kind of like, I don't

677
01:07:14,880 --> 01:07:18,960
know, do you want to lean into it? You know, do you want to become a techno futurist and like

678
01:07:18,960 --> 01:07:22,480
reinvent how everyone does things? There's something there. Do you want to become, you know,

679
01:07:22,480 --> 01:07:27,600
a primitive, you know, like, like, go and retreat into nature and like, you know, like,

680
01:07:27,600 --> 01:07:34,320
like, yeah, like, yeah, like, there's also something there. So, yeah, they are not

681
01:07:34,320 --> 01:07:38,960
co-primitivists. I'm not a fan of that. Yeah. Well, I mean, I guess we both want to conclude

682
01:07:38,960 --> 01:07:42,800
where do what Heidegger did and ask the question concerning technology.

683
01:07:44,160 --> 01:07:50,560
Yeah. And let the answer be, you know, let your answer be a truth for you, as Kierkegaard would

684
01:07:50,560 --> 01:07:57,280
say. Yes. And make it a truth that shakes you, because the Kierkegaardian truths are always

685
01:07:57,280 --> 01:08:00,400
the kind of truths that uproot you. And that's important.

