1
00:00:00,000 --> 00:00:05,400
And I'm sorry if this is a very kind of like a vague question, but are you familiar with

2
00:00:05,400 --> 00:00:06,400
the philosopher?

3
00:00:06,400 --> 00:00:11,360
Well, he's he's he calls himself doing foundations of physics.

4
00:00:11,360 --> 00:00:12,360
Tim Modellin.

5
00:00:12,360 --> 00:00:14,680
Um, no, I haven't heard of him.

6
00:00:14,680 --> 00:00:15,680
Yeah.

7
00:00:15,680 --> 00:00:16,680
So basically he's a fellow.

8
00:00:16,680 --> 00:00:20,920
He works in a philosophy department, although what his primary works like he's got a background

9
00:00:20,920 --> 00:00:21,920
in physics.

10
00:00:21,920 --> 00:00:28,720
I think he's got a PhD in physics and he his work is on deriving ontologies of the physical

11
00:00:28,720 --> 00:00:31,680
universe based on physics and what we know about modern physics.

12
00:00:31,680 --> 00:00:34,040
So he calls it the foundations of physics.

13
00:00:34,040 --> 00:00:40,200
And then when I was reading your stuff, it got me thinking, um, uh, is there such a thing

14
00:00:40,200 --> 00:00:48,000
as the, let's say the philosophical foundations of cognitive science and AGI, let's say, is

15
00:00:48,000 --> 00:00:55,720
is that something that we'd say researchers are actively working on or is that just what

16
00:00:55,720 --> 00:00:59,040
we would collectively call a philosophy of mine.

17
00:00:59,040 --> 00:01:04,600
So I think that with, uh, cognitive science, a lot of it is founded in things like logic

18
00:01:04,600 --> 00:01:07,440
and probability theory.

19
00:01:07,440 --> 00:01:13,400
And, uh, like, like there's, for example, the Bayesian brain hypothesis, which is hypothesis

20
00:01:13,400 --> 00:01:17,000
at the bind approximates Bayesian inference.

21
00:01:17,000 --> 00:01:20,400
And there's there are at least some empirical tests that provide some limited support for

22
00:01:20,400 --> 00:01:21,400
this.

23
00:01:22,200 --> 00:01:26,920
And there's more generally things like the problem of induction where there's this open

24
00:01:26,920 --> 00:01:32,520
question of how does the mind, uh, deduce, like induce the future from the past.

25
00:01:32,520 --> 00:01:38,320
But like, even if there's no logical justification for why the sun will rise tomorrow if it's

26
00:01:38,320 --> 00:01:44,240
always risen in the past, human minds will do this and there's some mechanistic explanation

27
00:01:44,240 --> 00:01:45,240
for this.

28
00:01:46,080 --> 00:01:56,880
Um, so I think the, uh, some of the foundations include these like basic things that are considered

29
00:01:56,880 --> 00:02:03,120
like parts of good reasoning, such as, um, uh, logic and probability theory.

30
00:02:03,120 --> 00:02:08,840
Uh, then there's, uh, you mentioned the mind body problem, um, and that's that definitely

31
00:02:08,840 --> 00:02:13,320
intersects with neuroscience a lot because there's this methodological assumption that

32
00:02:13,320 --> 00:02:16,800
these states of the mind are somehow encoded in the brain.

33
00:02:16,800 --> 00:02:24,440
Um, and this is like broadly pretty likely based on current scientific understanding,

34
00:02:24,440 --> 00:02:29,120
um, that like, for example, there aren't, if you, if you notice some difference in your

35
00:02:29,120 --> 00:02:35,760
mind, you have like n bits in your mental state, then that there have to be at least

36
00:02:35,760 --> 00:02:42,200
n bits in your brain state for that to be, um, represented somehow.

37
00:02:43,200 --> 00:02:48,760
Um, so I, I'd say that neuroscience certainly has a philosophy of mind as a foundation in

38
00:02:48,760 --> 00:02:56,040
terms of assumptions about how the mind's processing, uh, relates to the brain functions.

39
00:02:56,040 --> 00:02:59,280
Honestly, um, sorry, keep going.

40
00:02:59,280 --> 00:03:03,600
Oh, you also mentioned, uh, the foundations of cognitive science and AI.

41
00:03:03,600 --> 00:03:04,600
Yeah.

42
00:03:04,600 --> 00:03:05,600
Yes.

43
00:03:05,600 --> 00:03:06,600
Yes.

44
00:03:06,600 --> 00:03:09,760
I would say that AI is more founded in something I said before, which is just foundations of

45
00:03:09,760 --> 00:03:15,240
correct reasoning, which includes things like logic, probability theory, and induction.

46
00:03:15,240 --> 00:03:16,240
Understood.

47
00:03:16,240 --> 00:03:17,240
Yeah.

48
00:03:17,240 --> 00:03:22,000
Because the one thing I was thinking about was, so for instance, uh, if I kind of expand

49
00:03:22,000 --> 00:03:28,600
on that question, uh, like Tim Maudlin, when, when he says foundations of physics, I feel

50
00:03:28,600 --> 00:03:31,280
like that's in a way quite straightforward.

51
00:03:31,280 --> 00:03:37,320
It's trying to, trying to find, uh, kind of the ontological reality of our physical world,

52
00:03:37,320 --> 00:03:38,840
the physical universe.

53
00:03:38,840 --> 00:03:45,480
But then when it comes to something like AI or maybe perhaps more specifically, uh, COGSI,

54
00:03:45,480 --> 00:03:51,040
it gets a bit hazy because yes, we have cognition and the human subject, but then the question's

55
00:03:51,040 --> 00:03:53,120
like, what is human subjectivity?

56
00:03:53,120 --> 00:03:57,520
And that's a question, I guess, asked since the beginning of philosophy in some sense,

57
00:03:57,520 --> 00:03:58,520
right?

58
00:03:58,520 --> 00:04:02,480
And then especially since the Kant and the German idealist and then that got me thinking,

59
00:04:02,480 --> 00:04:07,280
um, are there really, do we really have, uh, people walking?

60
00:04:07,480 --> 00:04:15,280
In cognitive science that are trying to kind of, uh, let's say speculate and, and derive

61
00:04:15,280 --> 00:04:23,080
meaningful, uh, foundations of what a human subject is based on cognitive science and

62
00:04:23,080 --> 00:04:24,080
AI.

63
00:04:24,080 --> 00:04:27,840
So you would, would you say from what you just said that the answer is yes, or is it

64
00:04:27,840 --> 00:04:33,880
still more like, I'll just focus on the science itself, forget about, uh, you know, ontology

65
00:04:33,880 --> 00:04:34,880
or philosophy?

66
00:04:35,880 --> 00:04:38,320
Oh, I would say yes.

67
00:04:38,320 --> 00:04:43,440
And I think that it might be hard to notice this if you're just looking at papers published

68
00:04:43,440 --> 00:04:49,400
because partially the papers are assuming some amount of background of people in the field

69
00:04:49,400 --> 00:04:51,400
already share certain assumptions.

70
00:04:51,400 --> 00:04:56,640
And partially also, um, when people are presenting their findings, they're not trying to look

71
00:04:56,640 --> 00:04:57,640
too speculative.

72
00:04:57,640 --> 00:05:04,320
Um, like I think a big thing in science is that you, an under-specified part of the scientific

73
00:05:04,320 --> 00:05:07,280
method is how do you even come up with these hypotheses in the first place?

74
00:05:07,280 --> 00:05:11,000
Like the method says, once you have a hypothesis, you should go out and test it, but how do

75
00:05:11,000 --> 00:05:12,000
you come up with the hypothesis?

76
00:05:12,000 --> 00:05:13,440
It can, it can be very intuitive.

77
00:05:13,440 --> 00:05:15,400
It can come to you in a dream, even.

78
00:05:15,400 --> 00:05:19,840
Um, so I think when scientists are presenting their findings, um, they might have gotten

79
00:05:19,840 --> 00:05:24,720
their hypothesis in a certain manner, which might be intuitive or based on kind of philosophical

80
00:05:24,720 --> 00:05:29,720
thought, um, that they're trying to show their finding in a non-speculative manner.

81
00:05:30,160 --> 00:05:36,800
Um, but I think in, certainly I've talked with cognitive scientists and they do tend

82
00:05:36,800 --> 00:05:39,000
to speculate about the human subject.

83
00:05:39,000 --> 00:05:44,720
Um, so I mentioned the Bayesian brain hypothesis and I've learned that hypothesis when it,

84
00:05:44,720 --> 00:05:48,880
perhaps the primary thing that humans are doing is constructing a model of the world

85
00:05:48,880 --> 00:05:53,480
based on sense data that is meant to do things such as predict future sense data.

86
00:05:53,480 --> 00:05:58,640
Um, and then you can even go from that to think about values and like what are values

87
00:05:58,680 --> 00:06:05,680
and, um, there's, there's things like planning algorithms, which might tell you like if, if

88
00:06:05,680 --> 00:06:10,840
I have a certain value that will tend to, um, cause me to take certain actions that

89
00:06:10,840 --> 00:06:12,640
will achieve that end.

90
00:06:12,640 --> 00:06:15,000
And there's various algorithms that approximate that.

91
00:06:15,680 --> 00:06:24,760
Um, and it's, it's very much like, uh, that, like if, if you, if you, if you're having

92
00:06:24,760 --> 00:06:30,240
these sorts of thoughts about what it is like to model the world and to want things and

93
00:06:30,240 --> 00:06:34,840
plan towards them, um, that can certainly influence your own understanding of yourself

94
00:06:34,840 --> 00:06:36,160
or other humans as well.

95
00:06:38,440 --> 00:06:38,680
Yeah.

96
00:06:38,680 --> 00:06:39,760
What was the algorithm?

97
00:06:39,760 --> 00:06:45,560
Just because you said to penny algorithm planning, um, yeah.

98
00:06:45,560 --> 00:06:51,520
So if you, I guess things like, uh, reinforcement learning use some form of this, um, we're like

99
00:06:51,520 --> 00:06:55,680
in an alpha code has like an evaluation of board states and some kind of Monte Carlo

100
00:06:55,680 --> 00:06:58,280
tree search to search among the game tree.

101
00:06:58,760 --> 00:07:04,280
Um, and, uh, there, there's other algorithms like, like there's, there's like in, in simpler

102
00:07:04,280 --> 00:07:10,880
logical, um, problems you can do, do like back chaining to start from a goal state and

103
00:07:10,880 --> 00:07:13,840
ask like, what, what is the state before the goal state looked like?

104
00:07:14,160 --> 00:07:17,280
And then like, what does the state before that look like and try to get back to your current state?

