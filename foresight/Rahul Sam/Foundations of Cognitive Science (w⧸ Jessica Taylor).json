{"text": " And I'm sorry if this is a very kind of like a vague question, but are you familiar with the philosopher? Well, he's he's he calls himself doing foundations of physics. Tim Modellin. Um, no, I haven't heard of him. Yeah. So basically he's a fellow. He works in a philosophy department, although what his primary works like he's got a background in physics. I think he's got a PhD in physics and he his work is on deriving ontologies of the physical universe based on physics and what we know about modern physics. So he calls it the foundations of physics. And then when I was reading your stuff, it got me thinking, um, uh, is there such a thing as the, let's say the philosophical foundations of cognitive science and AGI, let's say, is is that something that we'd say researchers are actively working on or is that just what we would collectively call a philosophy of mine. So I think that with, uh, cognitive science, a lot of it is founded in things like logic and probability theory. And, uh, like, like there's, for example, the Bayesian brain hypothesis, which is hypothesis at the bind approximates Bayesian inference. And there's there are at least some empirical tests that provide some limited support for this. And there's more generally things like the problem of induction where there's this open question of how does the mind, uh, deduce, like induce the future from the past. But like, even if there's no logical justification for why the sun will rise tomorrow if it's always risen in the past, human minds will do this and there's some mechanistic explanation for this. Um, so I think the, uh, some of the foundations include these like basic things that are considered like parts of good reasoning, such as, um, uh, logic and probability theory. Uh, then there's, uh, you mentioned the mind body problem, um, and that's that definitely intersects with neuroscience a lot because there's this methodological assumption that these states of the mind are somehow encoded in the brain. Um, and this is like broadly pretty likely based on current scientific understanding, um, that like, for example, there aren't, if you, if you notice some difference in your mind, you have like n bits in your mental state, then that there have to be at least n bits in your brain state for that to be, um, represented somehow. Um, so I, I'd say that neuroscience certainly has a philosophy of mind as a foundation in terms of assumptions about how the mind's processing, uh, relates to the brain functions. Honestly, um, sorry, keep going. Oh, you also mentioned, uh, the foundations of cognitive science and AI. Yeah. Yes. Yes. I would say that AI is more founded in something I said before, which is just foundations of correct reasoning, which includes things like logic, probability theory, and induction. Understood. Yeah. Because the one thing I was thinking about was, so for instance, uh, if I kind of expand on that question, uh, like Tim Maudlin, when, when he says foundations of physics, I feel like that's in a way quite straightforward. It's trying to, trying to find, uh, kind of the ontological reality of our physical world, the physical universe. But then when it comes to something like AI or maybe perhaps more specifically, uh, COGSI, it gets a bit hazy because yes, we have cognition and the human subject, but then the question's like, what is human subjectivity? And that's a question, I guess, asked since the beginning of philosophy in some sense, right? And then especially since the Kant and the German idealist and then that got me thinking, um, are there really, do we really have, uh, people walking? In cognitive science that are trying to kind of, uh, let's say speculate and, and derive meaningful, uh, foundations of what a human subject is based on cognitive science and AI. So you would, would you say from what you just said that the answer is yes, or is it still more like, I'll just focus on the science itself, forget about, uh, you know, ontology or philosophy? Oh, I would say yes. And I think that it might be hard to notice this if you're just looking at papers published because partially the papers are assuming some amount of background of people in the field already share certain assumptions. And partially also, um, when people are presenting their findings, they're not trying to look too speculative. Um, like I think a big thing in science is that you, an under-specified part of the scientific method is how do you even come up with these hypotheses in the first place? Like the method says, once you have a hypothesis, you should go out and test it, but how do you come up with the hypothesis? It can, it can be very intuitive. It can come to you in a dream, even. Um, so I think when scientists are presenting their findings, um, they might have gotten their hypothesis in a certain manner, which might be intuitive or based on kind of philosophical thought, um, that they're trying to show their finding in a non-speculative manner. Um, but I think in, certainly I've talked with cognitive scientists and they do tend to speculate about the human subject. Um, so I mentioned the Bayesian brain hypothesis and I've learned that hypothesis when it, perhaps the primary thing that humans are doing is constructing a model of the world based on sense data that is meant to do things such as predict future sense data. Um, and then you can even go from that to think about values and like what are values and, um, there's, there's things like planning algorithms, which might tell you like if, if I have a certain value that will tend to, um, cause me to take certain actions that will achieve that end. And there's various algorithms that approximate that. Um, and it's, it's very much like, uh, that, like if, if you, if you, if you're having these sorts of thoughts about what it is like to model the world and to want things and plan towards them, um, that can certainly influence your own understanding of yourself or other humans as well. Yeah. What was the algorithm? Just because you said to penny algorithm planning, um, yeah. So if you, I guess things like, uh, reinforcement learning use some form of this, um, we're like in an alpha code has like an evaluation of board states and some kind of Monte Carlo tree search to search among the game tree. Um, and, uh, there, there's other algorithms like, like there's, there's like in, in simpler logical, um, problems you can do, do like back chaining to start from a goal state and ask like, what, what is the state before the goal state looked like? And then like, what does the state before that look like and try to get back to your current state?", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.4, "text": " And I'm sorry if this is a very kind of like a vague question, but are you familiar with", "tokens": [50364, 400, 286, 478, 2597, 498, 341, 307, 257, 588, 733, 295, 411, 257, 24247, 1168, 11, 457, 366, 291, 4963, 365, 50634], "temperature": 0.0, "avg_logprob": -0.2654772102832794, "compression_ratio": 1.6, "no_speech_prob": 0.0786437913775444}, {"id": 1, "seek": 0, "start": 5.4, "end": 6.4, "text": " the philosopher?", "tokens": [50634, 264, 29805, 30, 50684], "temperature": 0.0, "avg_logprob": -0.2654772102832794, "compression_ratio": 1.6, "no_speech_prob": 0.0786437913775444}, {"id": 2, "seek": 0, "start": 6.4, "end": 11.36, "text": " Well, he's he's he calls himself doing foundations of physics.", "tokens": [50684, 1042, 11, 415, 311, 415, 311, 415, 5498, 3647, 884, 22467, 295, 10649, 13, 50932], "temperature": 0.0, "avg_logprob": -0.2654772102832794, "compression_ratio": 1.6, "no_speech_prob": 0.0786437913775444}, {"id": 3, "seek": 0, "start": 11.36, "end": 12.36, "text": " Tim Modellin.", "tokens": [50932, 7172, 6583, 898, 259, 13, 50982], "temperature": 0.0, "avg_logprob": -0.2654772102832794, "compression_ratio": 1.6, "no_speech_prob": 0.0786437913775444}, {"id": 4, "seek": 0, "start": 12.36, "end": 14.68, "text": " Um, no, I haven't heard of him.", "tokens": [50982, 3301, 11, 572, 11, 286, 2378, 380, 2198, 295, 796, 13, 51098], "temperature": 0.0, "avg_logprob": -0.2654772102832794, "compression_ratio": 1.6, "no_speech_prob": 0.0786437913775444}, {"id": 5, "seek": 0, "start": 14.68, "end": 15.68, "text": " Yeah.", "tokens": [51098, 865, 13, 51148], "temperature": 0.0, "avg_logprob": -0.2654772102832794, "compression_ratio": 1.6, "no_speech_prob": 0.0786437913775444}, {"id": 6, "seek": 0, "start": 15.68, "end": 16.68, "text": " So basically he's a fellow.", "tokens": [51148, 407, 1936, 415, 311, 257, 7177, 13, 51198], "temperature": 0.0, "avg_logprob": -0.2654772102832794, "compression_ratio": 1.6, "no_speech_prob": 0.0786437913775444}, {"id": 7, "seek": 0, "start": 16.68, "end": 20.92, "text": " He works in a philosophy department, although what his primary works like he's got a background", "tokens": [51198, 634, 1985, 294, 257, 10675, 5882, 11, 4878, 437, 702, 6194, 1985, 411, 415, 311, 658, 257, 3678, 51410], "temperature": 0.0, "avg_logprob": -0.2654772102832794, "compression_ratio": 1.6, "no_speech_prob": 0.0786437913775444}, {"id": 8, "seek": 0, "start": 20.92, "end": 21.92, "text": " in physics.", "tokens": [51410, 294, 10649, 13, 51460], "temperature": 0.0, "avg_logprob": -0.2654772102832794, "compression_ratio": 1.6, "no_speech_prob": 0.0786437913775444}, {"id": 9, "seek": 0, "start": 21.92, "end": 28.72, "text": " I think he's got a PhD in physics and he his work is on deriving ontologies of the physical", "tokens": [51460, 286, 519, 415, 311, 658, 257, 14476, 294, 10649, 293, 415, 702, 589, 307, 322, 1163, 2123, 6592, 6204, 295, 264, 4001, 51800], "temperature": 0.0, "avg_logprob": -0.2654772102832794, "compression_ratio": 1.6, "no_speech_prob": 0.0786437913775444}, {"id": 10, "seek": 2872, "start": 28.72, "end": 31.68, "text": " universe based on physics and what we know about modern physics.", "tokens": [50364, 6445, 2361, 322, 10649, 293, 437, 321, 458, 466, 4363, 10649, 13, 50512], "temperature": 0.0, "avg_logprob": -0.25516848868512093, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.006895741913467646}, {"id": 11, "seek": 2872, "start": 31.68, "end": 34.04, "text": " So he calls it the foundations of physics.", "tokens": [50512, 407, 415, 5498, 309, 264, 22467, 295, 10649, 13, 50630], "temperature": 0.0, "avg_logprob": -0.25516848868512093, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.006895741913467646}, {"id": 12, "seek": 2872, "start": 34.04, "end": 40.2, "text": " And then when I was reading your stuff, it got me thinking, um, uh, is there such a thing", "tokens": [50630, 400, 550, 562, 286, 390, 3760, 428, 1507, 11, 309, 658, 385, 1953, 11, 1105, 11, 2232, 11, 307, 456, 1270, 257, 551, 50938], "temperature": 0.0, "avg_logprob": -0.25516848868512093, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.006895741913467646}, {"id": 13, "seek": 2872, "start": 40.2, "end": 48.0, "text": " as the, let's say the philosophical foundations of cognitive science and AGI, let's say, is", "tokens": [50938, 382, 264, 11, 718, 311, 584, 264, 25066, 22467, 295, 15605, 3497, 293, 316, 26252, 11, 718, 311, 584, 11, 307, 51328], "temperature": 0.0, "avg_logprob": -0.25516848868512093, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.006895741913467646}, {"id": 14, "seek": 2872, "start": 48.0, "end": 55.72, "text": " is that something that we'd say researchers are actively working on or is that just what", "tokens": [51328, 307, 300, 746, 300, 321, 1116, 584, 10309, 366, 13022, 1364, 322, 420, 307, 300, 445, 437, 51714], "temperature": 0.0, "avg_logprob": -0.25516848868512093, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.006895741913467646}, {"id": 15, "seek": 5572, "start": 55.72, "end": 59.04, "text": " we would collectively call a philosophy of mine.", "tokens": [50364, 321, 576, 24341, 818, 257, 10675, 295, 3892, 13, 50530], "temperature": 0.0, "avg_logprob": -0.24110932783647018, "compression_ratio": 1.625514403292181, "no_speech_prob": 0.004464083816856146}, {"id": 16, "seek": 5572, "start": 59.04, "end": 64.6, "text": " So I think that with, uh, cognitive science, a lot of it is founded in things like logic", "tokens": [50530, 407, 286, 519, 300, 365, 11, 2232, 11, 15605, 3497, 11, 257, 688, 295, 309, 307, 13234, 294, 721, 411, 9952, 50808], "temperature": 0.0, "avg_logprob": -0.24110932783647018, "compression_ratio": 1.625514403292181, "no_speech_prob": 0.004464083816856146}, {"id": 17, "seek": 5572, "start": 64.6, "end": 67.44, "text": " and probability theory.", "tokens": [50808, 293, 8482, 5261, 13, 50950], "temperature": 0.0, "avg_logprob": -0.24110932783647018, "compression_ratio": 1.625514403292181, "no_speech_prob": 0.004464083816856146}, {"id": 18, "seek": 5572, "start": 67.44, "end": 73.4, "text": " And, uh, like, like there's, for example, the Bayesian brain hypothesis, which is hypothesis", "tokens": [50950, 400, 11, 2232, 11, 411, 11, 411, 456, 311, 11, 337, 1365, 11, 264, 7840, 42434, 3567, 17291, 11, 597, 307, 17291, 51248], "temperature": 0.0, "avg_logprob": -0.24110932783647018, "compression_ratio": 1.625514403292181, "no_speech_prob": 0.004464083816856146}, {"id": 19, "seek": 5572, "start": 73.4, "end": 77.0, "text": " at the bind approximates Bayesian inference.", "tokens": [51248, 412, 264, 14786, 8542, 1024, 7840, 42434, 38253, 13, 51428], "temperature": 0.0, "avg_logprob": -0.24110932783647018, "compression_ratio": 1.625514403292181, "no_speech_prob": 0.004464083816856146}, {"id": 20, "seek": 5572, "start": 77.0, "end": 80.4, "text": " And there's there are at least some empirical tests that provide some limited support for", "tokens": [51428, 400, 456, 311, 456, 366, 412, 1935, 512, 31886, 6921, 300, 2893, 512, 5567, 1406, 337, 51598], "temperature": 0.0, "avg_logprob": -0.24110932783647018, "compression_ratio": 1.625514403292181, "no_speech_prob": 0.004464083816856146}, {"id": 21, "seek": 5572, "start": 80.4, "end": 81.4, "text": " this.", "tokens": [51598, 341, 13, 51648], "temperature": 0.0, "avg_logprob": -0.24110932783647018, "compression_ratio": 1.625514403292181, "no_speech_prob": 0.004464083816856146}, {"id": 22, "seek": 8140, "start": 82.2, "end": 86.92, "text": " And there's more generally things like the problem of induction where there's this open", "tokens": [50404, 400, 456, 311, 544, 5101, 721, 411, 264, 1154, 295, 33371, 689, 456, 311, 341, 1269, 50640], "temperature": 0.0, "avg_logprob": -0.2625901725854767, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.0016990622971206903}, {"id": 23, "seek": 8140, "start": 86.92, "end": 92.52000000000001, "text": " question of how does the mind, uh, deduce, like induce the future from the past.", "tokens": [50640, 1168, 295, 577, 775, 264, 1575, 11, 2232, 11, 4172, 4176, 11, 411, 41263, 264, 2027, 490, 264, 1791, 13, 50920], "temperature": 0.0, "avg_logprob": -0.2625901725854767, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.0016990622971206903}, {"id": 24, "seek": 8140, "start": 92.52000000000001, "end": 98.32000000000001, "text": " But like, even if there's no logical justification for why the sun will rise tomorrow if it's", "tokens": [50920, 583, 411, 11, 754, 498, 456, 311, 572, 14978, 31591, 337, 983, 264, 3295, 486, 6272, 4153, 498, 309, 311, 51210], "temperature": 0.0, "avg_logprob": -0.2625901725854767, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.0016990622971206903}, {"id": 25, "seek": 8140, "start": 98.32000000000001, "end": 104.24000000000001, "text": " always risen in the past, human minds will do this and there's some mechanistic explanation", "tokens": [51210, 1009, 28614, 294, 264, 1791, 11, 1952, 9634, 486, 360, 341, 293, 456, 311, 512, 4236, 3142, 10835, 51506], "temperature": 0.0, "avg_logprob": -0.2625901725854767, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.0016990622971206903}, {"id": 26, "seek": 8140, "start": 104.24000000000001, "end": 105.24000000000001, "text": " for this.", "tokens": [51506, 337, 341, 13, 51556], "temperature": 0.0, "avg_logprob": -0.2625901725854767, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.0016990622971206903}, {"id": 27, "seek": 10524, "start": 106.08, "end": 116.88, "text": " Um, so I think the, uh, some of the foundations include these like basic things that are considered", "tokens": [50406, 3301, 11, 370, 286, 519, 264, 11, 2232, 11, 512, 295, 264, 22467, 4090, 613, 411, 3875, 721, 300, 366, 4888, 50946], "temperature": 0.0, "avg_logprob": -0.21913286096909468, "compression_ratio": 1.6267281105990783, "no_speech_prob": 0.0013666084269061685}, {"id": 28, "seek": 10524, "start": 116.88, "end": 123.11999999999999, "text": " like parts of good reasoning, such as, um, uh, logic and probability theory.", "tokens": [50946, 411, 3166, 295, 665, 21577, 11, 1270, 382, 11, 1105, 11, 2232, 11, 9952, 293, 8482, 5261, 13, 51258], "temperature": 0.0, "avg_logprob": -0.21913286096909468, "compression_ratio": 1.6267281105990783, "no_speech_prob": 0.0013666084269061685}, {"id": 29, "seek": 10524, "start": 123.11999999999999, "end": 128.84, "text": " Uh, then there's, uh, you mentioned the mind body problem, um, and that's that definitely", "tokens": [51258, 4019, 11, 550, 456, 311, 11, 2232, 11, 291, 2835, 264, 1575, 1772, 1154, 11, 1105, 11, 293, 300, 311, 300, 2138, 51544], "temperature": 0.0, "avg_logprob": -0.21913286096909468, "compression_ratio": 1.6267281105990783, "no_speech_prob": 0.0013666084269061685}, {"id": 30, "seek": 10524, "start": 128.84, "end": 133.32, "text": " intersects with neuroscience a lot because there's this methodological assumption that", "tokens": [51544, 27815, 82, 365, 42762, 257, 688, 570, 456, 311, 341, 3170, 4383, 15302, 300, 51768], "temperature": 0.0, "avg_logprob": -0.21913286096909468, "compression_ratio": 1.6267281105990783, "no_speech_prob": 0.0013666084269061685}, {"id": 31, "seek": 13332, "start": 133.32, "end": 136.79999999999998, "text": " these states of the mind are somehow encoded in the brain.", "tokens": [50364, 613, 4368, 295, 264, 1575, 366, 6063, 2058, 12340, 294, 264, 3567, 13, 50538], "temperature": 0.0, "avg_logprob": -0.19093139804139428, "compression_ratio": 1.7741935483870968, "no_speech_prob": 0.005058586597442627}, {"id": 32, "seek": 13332, "start": 136.79999999999998, "end": 144.44, "text": " Um, and this is like broadly pretty likely based on current scientific understanding,", "tokens": [50538, 3301, 11, 293, 341, 307, 411, 19511, 1238, 3700, 2361, 322, 2190, 8134, 3701, 11, 50920], "temperature": 0.0, "avg_logprob": -0.19093139804139428, "compression_ratio": 1.7741935483870968, "no_speech_prob": 0.005058586597442627}, {"id": 33, "seek": 13332, "start": 144.44, "end": 149.12, "text": " um, that like, for example, there aren't, if you, if you notice some difference in your", "tokens": [50920, 1105, 11, 300, 411, 11, 337, 1365, 11, 456, 3212, 380, 11, 498, 291, 11, 498, 291, 3449, 512, 2649, 294, 428, 51154], "temperature": 0.0, "avg_logprob": -0.19093139804139428, "compression_ratio": 1.7741935483870968, "no_speech_prob": 0.005058586597442627}, {"id": 34, "seek": 13332, "start": 149.12, "end": 155.76, "text": " mind, you have like n bits in your mental state, then that there have to be at least", "tokens": [51154, 1575, 11, 291, 362, 411, 297, 9239, 294, 428, 4973, 1785, 11, 550, 300, 456, 362, 281, 312, 412, 1935, 51486], "temperature": 0.0, "avg_logprob": -0.19093139804139428, "compression_ratio": 1.7741935483870968, "no_speech_prob": 0.005058586597442627}, {"id": 35, "seek": 13332, "start": 155.76, "end": 162.2, "text": " n bits in your brain state for that to be, um, represented somehow.", "tokens": [51486, 297, 9239, 294, 428, 3567, 1785, 337, 300, 281, 312, 11, 1105, 11, 10379, 6063, 13, 51808], "temperature": 0.0, "avg_logprob": -0.19093139804139428, "compression_ratio": 1.7741935483870968, "no_speech_prob": 0.005058586597442627}, {"id": 36, "seek": 16220, "start": 163.2, "end": 168.76, "text": " Um, so I, I'd say that neuroscience certainly has a philosophy of mind as a foundation in", "tokens": [50414, 3301, 11, 370, 286, 11, 286, 1116, 584, 300, 42762, 3297, 575, 257, 10675, 295, 1575, 382, 257, 7030, 294, 50692], "temperature": 0.0, "avg_logprob": -0.25190839227640405, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.0026703381445258856}, {"id": 37, "seek": 16220, "start": 168.76, "end": 176.04, "text": " terms of assumptions about how the mind's processing, uh, relates to the brain functions.", "tokens": [50692, 2115, 295, 17695, 466, 577, 264, 1575, 311, 9007, 11, 2232, 11, 16155, 281, 264, 3567, 6828, 13, 51056], "temperature": 0.0, "avg_logprob": -0.25190839227640405, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.0026703381445258856}, {"id": 38, "seek": 16220, "start": 176.04, "end": 179.28, "text": " Honestly, um, sorry, keep going.", "tokens": [51056, 12348, 11, 1105, 11, 2597, 11, 1066, 516, 13, 51218], "temperature": 0.0, "avg_logprob": -0.25190839227640405, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.0026703381445258856}, {"id": 39, "seek": 16220, "start": 179.28, "end": 183.6, "text": " Oh, you also mentioned, uh, the foundations of cognitive science and AI.", "tokens": [51218, 876, 11, 291, 611, 2835, 11, 2232, 11, 264, 22467, 295, 15605, 3497, 293, 7318, 13, 51434], "temperature": 0.0, "avg_logprob": -0.25190839227640405, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.0026703381445258856}, {"id": 40, "seek": 16220, "start": 183.6, "end": 184.6, "text": " Yeah.", "tokens": [51434, 865, 13, 51484], "temperature": 0.0, "avg_logprob": -0.25190839227640405, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.0026703381445258856}, {"id": 41, "seek": 16220, "start": 184.6, "end": 185.6, "text": " Yes.", "tokens": [51484, 1079, 13, 51534], "temperature": 0.0, "avg_logprob": -0.25190839227640405, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.0026703381445258856}, {"id": 42, "seek": 16220, "start": 185.6, "end": 186.6, "text": " Yes.", "tokens": [51534, 1079, 13, 51584], "temperature": 0.0, "avg_logprob": -0.25190839227640405, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.0026703381445258856}, {"id": 43, "seek": 16220, "start": 186.6, "end": 189.76, "text": " I would say that AI is more founded in something I said before, which is just foundations of", "tokens": [51584, 286, 576, 584, 300, 7318, 307, 544, 13234, 294, 746, 286, 848, 949, 11, 597, 307, 445, 22467, 295, 51742], "temperature": 0.0, "avg_logprob": -0.25190839227640405, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.0026703381445258856}, {"id": 44, "seek": 18976, "start": 189.76, "end": 195.23999999999998, "text": " correct reasoning, which includes things like logic, probability theory, and induction.", "tokens": [50364, 3006, 21577, 11, 597, 5974, 721, 411, 9952, 11, 8482, 5261, 11, 293, 33371, 13, 50638], "temperature": 0.0, "avg_logprob": -0.20695771304043856, "compression_ratio": 1.624031007751938, "no_speech_prob": 0.01242270227521658}, {"id": 45, "seek": 18976, "start": 195.23999999999998, "end": 196.23999999999998, "text": " Understood.", "tokens": [50638, 42832, 13, 50688], "temperature": 0.0, "avg_logprob": -0.20695771304043856, "compression_ratio": 1.624031007751938, "no_speech_prob": 0.01242270227521658}, {"id": 46, "seek": 18976, "start": 196.23999999999998, "end": 197.23999999999998, "text": " Yeah.", "tokens": [50688, 865, 13, 50738], "temperature": 0.0, "avg_logprob": -0.20695771304043856, "compression_ratio": 1.624031007751938, "no_speech_prob": 0.01242270227521658}, {"id": 47, "seek": 18976, "start": 197.23999999999998, "end": 202.0, "text": " Because the one thing I was thinking about was, so for instance, uh, if I kind of expand", "tokens": [50738, 1436, 264, 472, 551, 286, 390, 1953, 466, 390, 11, 370, 337, 5197, 11, 2232, 11, 498, 286, 733, 295, 5268, 50976], "temperature": 0.0, "avg_logprob": -0.20695771304043856, "compression_ratio": 1.624031007751938, "no_speech_prob": 0.01242270227521658}, {"id": 48, "seek": 18976, "start": 202.0, "end": 208.6, "text": " on that question, uh, like Tim Maudlin, when, when he says foundations of physics, I feel", "tokens": [50976, 322, 300, 1168, 11, 2232, 11, 411, 7172, 376, 3751, 5045, 11, 562, 11, 562, 415, 1619, 22467, 295, 10649, 11, 286, 841, 51306], "temperature": 0.0, "avg_logprob": -0.20695771304043856, "compression_ratio": 1.624031007751938, "no_speech_prob": 0.01242270227521658}, {"id": 49, "seek": 18976, "start": 208.6, "end": 211.28, "text": " like that's in a way quite straightforward.", "tokens": [51306, 411, 300, 311, 294, 257, 636, 1596, 15325, 13, 51440], "temperature": 0.0, "avg_logprob": -0.20695771304043856, "compression_ratio": 1.624031007751938, "no_speech_prob": 0.01242270227521658}, {"id": 50, "seek": 18976, "start": 211.28, "end": 217.32, "text": " It's trying to, trying to find, uh, kind of the ontological reality of our physical world,", "tokens": [51440, 467, 311, 1382, 281, 11, 1382, 281, 915, 11, 2232, 11, 733, 295, 264, 6592, 4383, 4103, 295, 527, 4001, 1002, 11, 51742], "temperature": 0.0, "avg_logprob": -0.20695771304043856, "compression_ratio": 1.624031007751938, "no_speech_prob": 0.01242270227521658}, {"id": 51, "seek": 21732, "start": 217.32, "end": 218.84, "text": " the physical universe.", "tokens": [50364, 264, 4001, 6445, 13, 50440], "temperature": 0.0, "avg_logprob": -0.21140412986278534, "compression_ratio": 1.686206896551724, "no_speech_prob": 0.008845087140798569}, {"id": 52, "seek": 21732, "start": 218.84, "end": 225.48, "text": " But then when it comes to something like AI or maybe perhaps more specifically, uh, COGSI,", "tokens": [50440, 583, 550, 562, 309, 1487, 281, 746, 411, 7318, 420, 1310, 4317, 544, 4682, 11, 2232, 11, 3002, 24446, 40, 11, 50772], "temperature": 0.0, "avg_logprob": -0.21140412986278534, "compression_ratio": 1.686206896551724, "no_speech_prob": 0.008845087140798569}, {"id": 53, "seek": 21732, "start": 225.48, "end": 231.04, "text": " it gets a bit hazy because yes, we have cognition and the human subject, but then the question's", "tokens": [50772, 309, 2170, 257, 857, 324, 1229, 570, 2086, 11, 321, 362, 46905, 293, 264, 1952, 3983, 11, 457, 550, 264, 1168, 311, 51050], "temperature": 0.0, "avg_logprob": -0.21140412986278534, "compression_ratio": 1.686206896551724, "no_speech_prob": 0.008845087140798569}, {"id": 54, "seek": 21732, "start": 231.04, "end": 233.12, "text": " like, what is human subjectivity?", "tokens": [51050, 411, 11, 437, 307, 1952, 3983, 4253, 30, 51154], "temperature": 0.0, "avg_logprob": -0.21140412986278534, "compression_ratio": 1.686206896551724, "no_speech_prob": 0.008845087140798569}, {"id": 55, "seek": 21732, "start": 233.12, "end": 237.51999999999998, "text": " And that's a question, I guess, asked since the beginning of philosophy in some sense,", "tokens": [51154, 400, 300, 311, 257, 1168, 11, 286, 2041, 11, 2351, 1670, 264, 2863, 295, 10675, 294, 512, 2020, 11, 51374], "temperature": 0.0, "avg_logprob": -0.21140412986278534, "compression_ratio": 1.686206896551724, "no_speech_prob": 0.008845087140798569}, {"id": 56, "seek": 21732, "start": 237.51999999999998, "end": 238.51999999999998, "text": " right?", "tokens": [51374, 558, 30, 51424], "temperature": 0.0, "avg_logprob": -0.21140412986278534, "compression_ratio": 1.686206896551724, "no_speech_prob": 0.008845087140798569}, {"id": 57, "seek": 21732, "start": 238.51999999999998, "end": 242.48, "text": " And then especially since the Kant and the German idealist and then that got me thinking,", "tokens": [51424, 400, 550, 2318, 1670, 264, 40927, 293, 264, 6521, 7157, 468, 293, 550, 300, 658, 385, 1953, 11, 51622], "temperature": 0.0, "avg_logprob": -0.21140412986278534, "compression_ratio": 1.686206896551724, "no_speech_prob": 0.008845087140798569}, {"id": 58, "seek": 21732, "start": 242.48, "end": 247.28, "text": " um, are there really, do we really have, uh, people walking?", "tokens": [51622, 1105, 11, 366, 456, 534, 11, 360, 321, 534, 362, 11, 2232, 11, 561, 4494, 30, 51862], "temperature": 0.0, "avg_logprob": -0.21140412986278534, "compression_ratio": 1.686206896551724, "no_speech_prob": 0.008845087140798569}, {"id": 59, "seek": 24728, "start": 247.48, "end": 255.28, "text": " In cognitive science that are trying to kind of, uh, let's say speculate and, and derive", "tokens": [50374, 682, 15605, 3497, 300, 366, 1382, 281, 733, 295, 11, 2232, 11, 718, 311, 584, 40775, 293, 11, 293, 28446, 50764], "temperature": 0.0, "avg_logprob": -0.19800049367577138, "compression_ratio": 1.6343612334801763, "no_speech_prob": 0.014943727292120457}, {"id": 60, "seek": 24728, "start": 255.28, "end": 263.08, "text": " meaningful, uh, foundations of what a human subject is based on cognitive science and", "tokens": [50764, 10995, 11, 2232, 11, 22467, 295, 437, 257, 1952, 3983, 307, 2361, 322, 15605, 3497, 293, 51154], "temperature": 0.0, "avg_logprob": -0.19800049367577138, "compression_ratio": 1.6343612334801763, "no_speech_prob": 0.014943727292120457}, {"id": 61, "seek": 24728, "start": 263.08, "end": 264.08, "text": " AI.", "tokens": [51154, 7318, 13, 51204], "temperature": 0.0, "avg_logprob": -0.19800049367577138, "compression_ratio": 1.6343612334801763, "no_speech_prob": 0.014943727292120457}, {"id": 62, "seek": 24728, "start": 264.08, "end": 267.84, "text": " So you would, would you say from what you just said that the answer is yes, or is it", "tokens": [51204, 407, 291, 576, 11, 576, 291, 584, 490, 437, 291, 445, 848, 300, 264, 1867, 307, 2086, 11, 420, 307, 309, 51392], "temperature": 0.0, "avg_logprob": -0.19800049367577138, "compression_ratio": 1.6343612334801763, "no_speech_prob": 0.014943727292120457}, {"id": 63, "seek": 24728, "start": 267.84, "end": 273.88, "text": " still more like, I'll just focus on the science itself, forget about, uh, you know, ontology", "tokens": [51392, 920, 544, 411, 11, 286, 603, 445, 1879, 322, 264, 3497, 2564, 11, 2870, 466, 11, 2232, 11, 291, 458, 11, 6592, 1793, 51694], "temperature": 0.0, "avg_logprob": -0.19800049367577138, "compression_ratio": 1.6343612334801763, "no_speech_prob": 0.014943727292120457}, {"id": 64, "seek": 24728, "start": 273.88, "end": 274.88, "text": " or philosophy?", "tokens": [51694, 420, 10675, 30, 51744], "temperature": 0.0, "avg_logprob": -0.19800049367577138, "compression_ratio": 1.6343612334801763, "no_speech_prob": 0.014943727292120457}, {"id": 65, "seek": 27488, "start": 275.88, "end": 278.32, "text": " Oh, I would say yes.", "tokens": [50414, 876, 11, 286, 576, 584, 2086, 13, 50536], "temperature": 0.0, "avg_logprob": -0.17245064841376412, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0014096040977165103}, {"id": 66, "seek": 27488, "start": 278.32, "end": 283.44, "text": " And I think that it might be hard to notice this if you're just looking at papers published", "tokens": [50536, 400, 286, 519, 300, 309, 1062, 312, 1152, 281, 3449, 341, 498, 291, 434, 445, 1237, 412, 10577, 6572, 50792], "temperature": 0.0, "avg_logprob": -0.17245064841376412, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0014096040977165103}, {"id": 67, "seek": 27488, "start": 283.44, "end": 289.4, "text": " because partially the papers are assuming some amount of background of people in the field", "tokens": [50792, 570, 18886, 264, 10577, 366, 11926, 512, 2372, 295, 3678, 295, 561, 294, 264, 2519, 51090], "temperature": 0.0, "avg_logprob": -0.17245064841376412, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0014096040977165103}, {"id": 68, "seek": 27488, "start": 289.4, "end": 291.4, "text": " already share certain assumptions.", "tokens": [51090, 1217, 2073, 1629, 17695, 13, 51190], "temperature": 0.0, "avg_logprob": -0.17245064841376412, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0014096040977165103}, {"id": 69, "seek": 27488, "start": 291.4, "end": 296.64, "text": " And partially also, um, when people are presenting their findings, they're not trying to look", "tokens": [51190, 400, 18886, 611, 11, 1105, 11, 562, 561, 366, 15578, 641, 16483, 11, 436, 434, 406, 1382, 281, 574, 51452], "temperature": 0.0, "avg_logprob": -0.17245064841376412, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0014096040977165103}, {"id": 70, "seek": 27488, "start": 296.64, "end": 297.64, "text": " too speculative.", "tokens": [51452, 886, 49415, 13, 51502], "temperature": 0.0, "avg_logprob": -0.17245064841376412, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0014096040977165103}, {"id": 71, "seek": 27488, "start": 297.64, "end": 304.32, "text": " Um, like I think a big thing in science is that you, an under-specified part of the scientific", "tokens": [51502, 3301, 11, 411, 286, 519, 257, 955, 551, 294, 3497, 307, 300, 291, 11, 364, 833, 12, 7053, 66, 2587, 644, 295, 264, 8134, 51836], "temperature": 0.0, "avg_logprob": -0.17245064841376412, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0014096040977165103}, {"id": 72, "seek": 30432, "start": 304.32, "end": 307.28, "text": " method is how do you even come up with these hypotheses in the first place?", "tokens": [50364, 3170, 307, 577, 360, 291, 754, 808, 493, 365, 613, 49969, 294, 264, 700, 1081, 30, 50512], "temperature": 0.0, "avg_logprob": -0.1971747309183903, "compression_ratio": 1.8464163822525597, "no_speech_prob": 0.0020498433150351048}, {"id": 73, "seek": 30432, "start": 307.28, "end": 311.0, "text": " Like the method says, once you have a hypothesis, you should go out and test it, but how do", "tokens": [50512, 1743, 264, 3170, 1619, 11, 1564, 291, 362, 257, 17291, 11, 291, 820, 352, 484, 293, 1500, 309, 11, 457, 577, 360, 50698], "temperature": 0.0, "avg_logprob": -0.1971747309183903, "compression_ratio": 1.8464163822525597, "no_speech_prob": 0.0020498433150351048}, {"id": 74, "seek": 30432, "start": 311.0, "end": 312.0, "text": " you come up with the hypothesis?", "tokens": [50698, 291, 808, 493, 365, 264, 17291, 30, 50748], "temperature": 0.0, "avg_logprob": -0.1971747309183903, "compression_ratio": 1.8464163822525597, "no_speech_prob": 0.0020498433150351048}, {"id": 75, "seek": 30432, "start": 312.0, "end": 313.44, "text": " It can, it can be very intuitive.", "tokens": [50748, 467, 393, 11, 309, 393, 312, 588, 21769, 13, 50820], "temperature": 0.0, "avg_logprob": -0.1971747309183903, "compression_ratio": 1.8464163822525597, "no_speech_prob": 0.0020498433150351048}, {"id": 76, "seek": 30432, "start": 313.44, "end": 315.4, "text": " It can come to you in a dream, even.", "tokens": [50820, 467, 393, 808, 281, 291, 294, 257, 3055, 11, 754, 13, 50918], "temperature": 0.0, "avg_logprob": -0.1971747309183903, "compression_ratio": 1.8464163822525597, "no_speech_prob": 0.0020498433150351048}, {"id": 77, "seek": 30432, "start": 315.4, "end": 319.84, "text": " Um, so I think when scientists are presenting their findings, um, they might have gotten", "tokens": [50918, 3301, 11, 370, 286, 519, 562, 7708, 366, 15578, 641, 16483, 11, 1105, 11, 436, 1062, 362, 5768, 51140], "temperature": 0.0, "avg_logprob": -0.1971747309183903, "compression_ratio": 1.8464163822525597, "no_speech_prob": 0.0020498433150351048}, {"id": 78, "seek": 30432, "start": 319.84, "end": 324.71999999999997, "text": " their hypothesis in a certain manner, which might be intuitive or based on kind of philosophical", "tokens": [51140, 641, 17291, 294, 257, 1629, 9060, 11, 597, 1062, 312, 21769, 420, 2361, 322, 733, 295, 25066, 51384], "temperature": 0.0, "avg_logprob": -0.1971747309183903, "compression_ratio": 1.8464163822525597, "no_speech_prob": 0.0020498433150351048}, {"id": 79, "seek": 30432, "start": 324.71999999999997, "end": 329.71999999999997, "text": " thought, um, that they're trying to show their finding in a non-speculative manner.", "tokens": [51384, 1194, 11, 1105, 11, 300, 436, 434, 1382, 281, 855, 641, 5006, 294, 257, 2107, 12, 7053, 2444, 1166, 9060, 13, 51634], "temperature": 0.0, "avg_logprob": -0.1971747309183903, "compression_ratio": 1.8464163822525597, "no_speech_prob": 0.0020498433150351048}, {"id": 80, "seek": 32972, "start": 330.16, "end": 336.8, "text": " Um, but I think in, certainly I've talked with cognitive scientists and they do tend", "tokens": [50386, 3301, 11, 457, 286, 519, 294, 11, 3297, 286, 600, 2825, 365, 15605, 7708, 293, 436, 360, 3928, 50718], "temperature": 0.0, "avg_logprob": -0.20898343007498926, "compression_ratio": 1.7259259259259259, "no_speech_prob": 0.006689778994768858}, {"id": 81, "seek": 32972, "start": 336.8, "end": 339.0, "text": " to speculate about the human subject.", "tokens": [50718, 281, 40775, 466, 264, 1952, 3983, 13, 50828], "temperature": 0.0, "avg_logprob": -0.20898343007498926, "compression_ratio": 1.7259259259259259, "no_speech_prob": 0.006689778994768858}, {"id": 82, "seek": 32972, "start": 339.0, "end": 344.72, "text": " Um, so I mentioned the Bayesian brain hypothesis and I've learned that hypothesis when it,", "tokens": [50828, 3301, 11, 370, 286, 2835, 264, 7840, 42434, 3567, 17291, 293, 286, 600, 3264, 300, 17291, 562, 309, 11, 51114], "temperature": 0.0, "avg_logprob": -0.20898343007498926, "compression_ratio": 1.7259259259259259, "no_speech_prob": 0.006689778994768858}, {"id": 83, "seek": 32972, "start": 344.72, "end": 348.88000000000005, "text": " perhaps the primary thing that humans are doing is constructing a model of the world", "tokens": [51114, 4317, 264, 6194, 551, 300, 6255, 366, 884, 307, 39969, 257, 2316, 295, 264, 1002, 51322], "temperature": 0.0, "avg_logprob": -0.20898343007498926, "compression_ratio": 1.7259259259259259, "no_speech_prob": 0.006689778994768858}, {"id": 84, "seek": 32972, "start": 348.88000000000005, "end": 353.48, "text": " based on sense data that is meant to do things such as predict future sense data.", "tokens": [51322, 2361, 322, 2020, 1412, 300, 307, 4140, 281, 360, 721, 1270, 382, 6069, 2027, 2020, 1412, 13, 51552], "temperature": 0.0, "avg_logprob": -0.20898343007498926, "compression_ratio": 1.7259259259259259, "no_speech_prob": 0.006689778994768858}, {"id": 85, "seek": 32972, "start": 353.48, "end": 358.64000000000004, "text": " Um, and then you can even go from that to think about values and like what are values", "tokens": [51552, 3301, 11, 293, 550, 291, 393, 754, 352, 490, 300, 281, 519, 466, 4190, 293, 411, 437, 366, 4190, 51810], "temperature": 0.0, "avg_logprob": -0.20898343007498926, "compression_ratio": 1.7259259259259259, "no_speech_prob": 0.006689778994768858}, {"id": 86, "seek": 35864, "start": 358.68, "end": 365.68, "text": " and, um, there's, there's things like planning algorithms, which might tell you like if, if", "tokens": [50366, 293, 11, 1105, 11, 456, 311, 11, 456, 311, 721, 411, 5038, 14642, 11, 597, 1062, 980, 291, 411, 498, 11, 498, 50716], "temperature": 0.0, "avg_logprob": -0.17292757829030356, "compression_ratio": 1.7384615384615385, "no_speech_prob": 0.000345880922395736}, {"id": 87, "seek": 35864, "start": 365.68, "end": 370.84, "text": " I have a certain value that will tend to, um, cause me to take certain actions that", "tokens": [50716, 286, 362, 257, 1629, 2158, 300, 486, 3928, 281, 11, 1105, 11, 3082, 385, 281, 747, 1629, 5909, 300, 50974], "temperature": 0.0, "avg_logprob": -0.17292757829030356, "compression_ratio": 1.7384615384615385, "no_speech_prob": 0.000345880922395736}, {"id": 88, "seek": 35864, "start": 370.84, "end": 372.64, "text": " will achieve that end.", "tokens": [50974, 486, 4584, 300, 917, 13, 51064], "temperature": 0.0, "avg_logprob": -0.17292757829030356, "compression_ratio": 1.7384615384615385, "no_speech_prob": 0.000345880922395736}, {"id": 89, "seek": 35864, "start": 372.64, "end": 375.0, "text": " And there's various algorithms that approximate that.", "tokens": [51064, 400, 456, 311, 3683, 14642, 300, 30874, 300, 13, 51182], "temperature": 0.0, "avg_logprob": -0.17292757829030356, "compression_ratio": 1.7384615384615385, "no_speech_prob": 0.000345880922395736}, {"id": 90, "seek": 35864, "start": 375.68, "end": 384.76, "text": " Um, and it's, it's very much like, uh, that, like if, if you, if you, if you're having", "tokens": [51216, 3301, 11, 293, 309, 311, 11, 309, 311, 588, 709, 411, 11, 2232, 11, 300, 11, 411, 498, 11, 498, 291, 11, 498, 291, 11, 498, 291, 434, 1419, 51670], "temperature": 0.0, "avg_logprob": -0.17292757829030356, "compression_ratio": 1.7384615384615385, "no_speech_prob": 0.000345880922395736}, {"id": 91, "seek": 38476, "start": 384.76, "end": 390.24, "text": " these sorts of thoughts about what it is like to model the world and to want things and", "tokens": [50364, 613, 7527, 295, 4598, 466, 437, 309, 307, 411, 281, 2316, 264, 1002, 293, 281, 528, 721, 293, 50638], "temperature": 0.0, "avg_logprob": -0.25068564366812657, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.026312366127967834}, {"id": 92, "seek": 38476, "start": 390.24, "end": 394.84, "text": " plan towards them, um, that can certainly influence your own understanding of yourself", "tokens": [50638, 1393, 3030, 552, 11, 1105, 11, 300, 393, 3297, 6503, 428, 1065, 3701, 295, 1803, 50868], "temperature": 0.0, "avg_logprob": -0.25068564366812657, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.026312366127967834}, {"id": 93, "seek": 38476, "start": 394.84, "end": 396.15999999999997, "text": " or other humans as well.", "tokens": [50868, 420, 661, 6255, 382, 731, 13, 50934], "temperature": 0.0, "avg_logprob": -0.25068564366812657, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.026312366127967834}, {"id": 94, "seek": 38476, "start": 398.44, "end": 398.68, "text": " Yeah.", "tokens": [51048, 865, 13, 51060], "temperature": 0.0, "avg_logprob": -0.25068564366812657, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.026312366127967834}, {"id": 95, "seek": 38476, "start": 398.68, "end": 399.76, "text": " What was the algorithm?", "tokens": [51060, 708, 390, 264, 9284, 30, 51114], "temperature": 0.0, "avg_logprob": -0.25068564366812657, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.026312366127967834}, {"id": 96, "seek": 38476, "start": 399.76, "end": 405.56, "text": " Just because you said to penny algorithm planning, um, yeah.", "tokens": [51114, 1449, 570, 291, 848, 281, 24178, 9284, 5038, 11, 1105, 11, 1338, 13, 51404], "temperature": 0.0, "avg_logprob": -0.25068564366812657, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.026312366127967834}, {"id": 97, "seek": 38476, "start": 405.56, "end": 411.52, "text": " So if you, I guess things like, uh, reinforcement learning use some form of this, um, we're like", "tokens": [51404, 407, 498, 291, 11, 286, 2041, 721, 411, 11, 2232, 11, 29280, 2539, 764, 512, 1254, 295, 341, 11, 1105, 11, 321, 434, 411, 51702], "temperature": 0.0, "avg_logprob": -0.25068564366812657, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.026312366127967834}, {"id": 98, "seek": 41152, "start": 411.52, "end": 415.68, "text": " in an alpha code has like an evaluation of board states and some kind of Monte Carlo", "tokens": [50364, 294, 364, 8961, 3089, 575, 411, 364, 13344, 295, 3150, 4368, 293, 512, 733, 295, 38105, 45112, 50572], "temperature": 0.0, "avg_logprob": -0.2018787415047002, "compression_ratio": 1.8521400778210118, "no_speech_prob": 0.008842568844556808}, {"id": 99, "seek": 41152, "start": 415.68, "end": 418.28, "text": " tree search to search among the game tree.", "tokens": [50572, 4230, 3164, 281, 3164, 3654, 264, 1216, 4230, 13, 50702], "temperature": 0.0, "avg_logprob": -0.2018787415047002, "compression_ratio": 1.8521400778210118, "no_speech_prob": 0.008842568844556808}, {"id": 100, "seek": 41152, "start": 418.76, "end": 424.28, "text": " Um, and, uh, there, there's other algorithms like, like there's, there's like in, in simpler", "tokens": [50726, 3301, 11, 293, 11, 2232, 11, 456, 11, 456, 311, 661, 14642, 411, 11, 411, 456, 311, 11, 456, 311, 411, 294, 11, 294, 18587, 51002], "temperature": 0.0, "avg_logprob": -0.2018787415047002, "compression_ratio": 1.8521400778210118, "no_speech_prob": 0.008842568844556808}, {"id": 101, "seek": 41152, "start": 424.28, "end": 430.88, "text": " logical, um, problems you can do, do like back chaining to start from a goal state and", "tokens": [51002, 14978, 11, 1105, 11, 2740, 291, 393, 360, 11, 360, 411, 646, 417, 3686, 281, 722, 490, 257, 3387, 1785, 293, 51332], "temperature": 0.0, "avg_logprob": -0.2018787415047002, "compression_ratio": 1.8521400778210118, "no_speech_prob": 0.008842568844556808}, {"id": 102, "seek": 41152, "start": 430.88, "end": 433.84, "text": " ask like, what, what is the state before the goal state looked like?", "tokens": [51332, 1029, 411, 11, 437, 11, 437, 307, 264, 1785, 949, 264, 3387, 1785, 2956, 411, 30, 51480], "temperature": 0.0, "avg_logprob": -0.2018787415047002, "compression_ratio": 1.8521400778210118, "no_speech_prob": 0.008842568844556808}, {"id": 103, "seek": 41152, "start": 434.15999999999997, "end": 437.28, "text": " And then like, what does the state before that look like and try to get back to your current state?", "tokens": [51496, 400, 550, 411, 11, 437, 775, 264, 1785, 949, 300, 574, 411, 293, 853, 281, 483, 646, 281, 428, 2190, 1785, 30, 51652], "temperature": 0.0, "avg_logprob": -0.2018787415047002, "compression_ratio": 1.8521400778210118, "no_speech_prob": 0.008842568844556808}], "language": "en"}