{"text": " I want to discuss, uh, explanatory coherence. Uh, you've done a lot of work on that. And I'm wondering if you could kind of give a brief introduction to what, uh, explanatory coherence is to a lay audience. What at the same time, uh, why you think, uh, it's, uh, what, what are the, what are the implications in fields such as AI and psychology? Oh, that's a big question, but it's a really interesting one. So let's go back to Darwin. So I mentioned one of my favorite books of all time is the origin of species. And so what was he doing in that? Uh, well, in my view, what he was trying to do is to give a coherent explanation of all sorts of things that he observed. So he went on this voyage around the world and he collected all sorts of other kinds of biological information. And he gradually seemed to him that it seemed in fact that the species had evolved. I mean, now everybody knows that kids get that probably in grade four, but it was a, um, a very controversial idea. Some people had maintained it, but it went up against religious doctrines. And so he gradually started to amass more and more evidence that species had evolved. But then from reading a crazy economist named Malthus, he suddenly got the idea of how they evolved. And that's how he came up with the idea of, of, of the natural selection. So now we had not only a bunch of observations and the idea that evolution probably had occurred that would explain it, but an idea of how, how evolution had occurred. That is that natural selection was the mechanism behind evolution. So what he did in that book was an incredibly beautiful argument for his view, as opposed to the view that was dominant at the time, which was divine creation. So what he was trying to show is that his view was a better explanation, but then divine creation, because it was more coherent with the evidence. So this is an account that philosophers call inference to the best explanation. You can argue that something's the best explanation because it's more coherent with the evidence, but now you have to say what coherence is. So I had these early ideas coming out of my philosophy of science background, but then in 1987, I got one of the best ideas I've ever had, which was how to turn coherence from a sort of vague philosophical idea into a precise computational one. That is, how can you compute coherence? So I've been working on neural networks in collaboration with my colleague Keith Holyoke. And he came up with an idea that you could use neural networks to explain analogy. These neural networks, of course, are now absolutely central to artificial intelligence. It's, it's really taken off. That's a whole fascinating topic in itself. But he figured out a way of doing that. And by that time, I'd done my master's in computer science, so I was a pretty good programmer. And so I programmed up a program to use neural networks to do analogies. So that, that was nice. And then I thought, what else could apply to, and then I thought back to the problem that was part of my doctoral dissertation, which was inference to the best explanation. How do you pick up the best theory? And so then I realized that that kind of coherence can be understood using the same kind of neural network technique that Keith and I had done for, for analogy. So it was a really powerful method, both computationally, but also psychologically, because there have now since then been lots of psychological experiments that back up this idea of coherence. So I think of the mind, the brain as essentially a coherence engine. There's some people who think that it's primarily a predictive engine, but I don't think that's true. I think it's primarily a coherence engine. We're trying to make sense of things, whether we're making sense of the past, which is what explanations do, or making sense of the future, we're making coherent predictions, or we're trying to identify things. Is that a rabbit or a squirrel? Those are, are different kinds of thought. Everything we do can be understood as having coherence behind it. But coherence now isn't just a sort of vague metaphor that it was for philosophers. It's not just a matter of consistency. It's rather of taking a whole bunch of different things and putting them into a good package. But what's a good package? Well, here there's an idea that came out of the neural network world called constraint satisfaction. So we're trying to satisfy a bunch of constraints. What constraints did Darwin face? Well, he was trying to explain as much as possible about what he'd seen in the biological world. That's the positive constraints, but he also had a negative constraint. And so he had to show that he could do that better than the theory that was the computer at the top competitor at the time, which is divine creation. So that's a negative constraint. So what you're doing in all of these things, whether it's decision making or pattern recognition, or even emotion, you're putting together different sorts of constraints to evaluate what's the most coherent view. So that's how I came to see coherence, not just as a vague philosophical idea, but as a quite precise computational one that can be used to explain the mechanisms that underlie a vast amount of human thinking. So that's why I think coherence is really a fundamental idea to psychology and cognitive science and to these philosophical projects as well. Yeah, excellent, excellent. I'm glad he brought up predictive coding or predictive processing, because I'll be talking to a cognitive scientist next month, in fact, based here in Melbourne. And I want to ask her about your theory of explanatory coherence, because I believe you do have certain critiques of predictive processing, but also in your book, you are critical of, in fact, no, I think you wrote an article on this, a paper on this, pardon me, you also critical of functionalism, kind of what Hilary Putnam and the likes put forward. So from your kind of theory of mind, what would you say are your critiques of one predictive processing, and then functionalism? Those are two different views, I don't think they have anything to do with each other. I'm just curious, I quote them independently, what would be your critiques? Okay, let's do one at a time. Predictive processing definitely is an influential view right now, but I think it's just not right. It says that the mind is the brain is a predictive engine, as if everything is prediction. But the mind doesn't just do prediction, it does at least five other things that are just as important. It does explanation, which involves explaining the past, that's not prediction, that's the past prediction is about the future, or even pattern recognition. I mentioned, I see an animal in my backyard, what is it? Is that a squirrel or a rabbit? Well, that's pattern recognition, that's not necessarily a prediction, I want to know what it is. We also want to do, and this is really important, evaluation. Is this good or bad for me? Is this a threat to me? Or is this something I can eat? How do we do evaluation? Well, in humans, that comes from emotion. The predictive processing approach has said nothing interesting to say about emotion at all, but that's absolutely fundamental to many areas of human thinking. I've got a whole theory of emotion, of which coherence is part of it, but it's only part of it. So you have to have evaluation going on. Communication, we sometimes predict in order to communicate with other people, but there's lots of other things going on where we want to be able to get our ideas across to others. So that's just at least five things that are part of the human mind other than predictive processing. So that's my first critique. My second critique is the way that people in that world think that predictive processing work doesn't correspond to how the brain works very well. They're Bayesians. They say that the brain uses probability theory in accord with Bayes' theorem to predict the next thing. Well, this is crazy computationally. Bayesian processing is well known in artificial intelligence to be extremely inefficient. You can prove that it's computationally intractable. You can show that it causes all sorts of problems. Bayesians have to jump through all sorts of hoops to try to deal with anything larger than that. I've done a little bit of Bayesian modeling because I wanted to, I drew a couple of papers where I compared a Bayesian model of legal reasoning to my explanatory coherence one. But the Bayesian models are crazy because you have to generate all sorts of conditional probabilities that nobody has an idea what they are. So if you actually do Bayesian modeling seriously, you'll find first of all, you don't know any of the probabilities. You don't know any of the conditional probabilities. You don't have the computational or neural resources to actually commute the probabilities. So the way that predictive processing with its too narrow view of how the brain works fills it out is by making brains Bayesian when they're not. A really good contrast here is with the new generative AI models, which are actually incredibly good at predicting. Have you used chat GPT or any of the others? They're astonishing. They're astonishing at how good they are at predicting the next word to say. And they end up producing really coherent stuff. And they get things really bad, badly wrong sometimes, but often they're really good, but they don't use Bayesian predictions. It's they've got all different kinds of algorithms that they use tension mechanism and sorts of things. So they realize that that the Bayesian approach is not going to work for them. So those are my two major criticisms of the predictive processing. The brain is a multi fast, it's a coherence engine doing six things as well as prediction. And it's not doing it using Bayesian probability calculations. Okay, so is that good enough for predictive processing? No, I think that's perfect. I want to ask you about the free energy principle, but probably we'll get to the functionalism and then maybe come back to the principle. Yeah, okay. So functionalism is a view in the philosophy of mind. It's actually a really bad term because functionalism is a term that operates in about six different fields or six different meetings. So we need to pin it down a bit. Let's call it computational functionalism. Because it came in the 60s when computers started to become aware and Hillary Putnam knew about the advances in computing. When computers were really primitive, then I've got a watch now that was better than all the computers, way better than anything that came along for decades. But but still, people were starting to think that with computers and the possibility of artificial intelligence, we've got this abstract way of thinking of thinking as a kind of computation. Now, one thing that's really true or seems to be true about computation is that it doesn't really matter what you run it on. So here I'm using a Macintosh. I don't know what kind of computer you've got. It could be a PC or running a different kind of hardware altogether. It doesn't matter. We can all run the same software. And so the analogy that Putnam hit on was mind is software rather than hardware. You can take the same software and run it on a bunch of people or hardware. All that matters is it has the appropriate computational functions. That's where the word functionalism comes from. So if you have inputs and outputs, and you have the functions in between, you want to be able to make thinking work. And so forget about the hardware. Forget about the brain, for example. The psychologist had been studying the brain at that point for, I guess, 60 or 70 years seriously. The functionalist in the 60s said, let's forget about the brain. It's all computation. It's just like AI. Anything that runs in the mind can run on a computer. Okay. And actually in the 1960s and 70s, that was a pretty reasonable idea. And this is why a lot of philosophers consider themselves functionalists. It became the dominant view in the philosophy of mind. So I think that was a pretty good idea in the 60s and 70s because AI had become a real field. Computers had become at least rudimentarily powerful. And so not a bad idea then. But things changed in the 80s. In the 80s, a bunch of things changed. First of all, brain scanning came along. It had been really hard to study the brain before because you had to do things like poke electrodes into brains that had been exposed. And so it was really hard to study the brain. But in the 80s, brain scans came along. First of all, I forget what they were called, and then eventually fMRI. But suddenly you could actually study the brain in a much more detailed way. And then you could start to test some of the claims that had been made. So when people started doing fMRI studies, they thought, oh, we're going to be able to show that the mind really is module, that is modular, that is different parts of the brain are doing very specific things. And so we should be able to find that this part of the brain does high level thinking, this part of the brain does emotion, and that part of the brain does vision, and we could localize it. But once people had this new tool, they started to realize, hey, it's not like that at all. Lots of what goes on the brain involves interactions of lots of different areas. So suddenly the brain became much more interesting. It didn't look like just some other kind of hardware you might run thoughts on. It looked like you could study on its own. So there were these empirical findings coming out of the new tools available for studying the brain that suggested that, well, maybe the structure of the brain really does matter. So that was an incredibly important empirical basis for starting to question functionalism. But there was also a really interesting theoretical basis coming out of the ideas about neural networks. So the ideas of neural networks have been around really back since the 50s, but it didn't work very well. And people like Marvin Minsky had argued that, no, those these ideas about neural networks are not going to work very well. They're just, they're just, they're just simply not theoretically strong enough. But in the 1980s, people greatly expanded the possibilities of what neural networks could do. They invented a new algorithm called back propagation that does learning. A whole movement got started called connectionism, which said that knowledge isn't a matter of the words you've got or the symbols, which is what artificial intelligence, but it's rather it's the connections, it's the neural connections. So suddenly, people were modeling their computer models, because these are being done with computerized neural networks, they were modeling on ideas about the brain, how you can have different neurons working in parallel with simple connections with them, and nevertheless doing that. So in the 1980s, suddenly, I functionalism was in trouble. Not many people noticed because they weren't tracking what was happening in neuroscience and in neural network theory, but it wasn't. And by the 1990s, I think it really had completely turned around. I think by the 1990s, functionalism was no longer plausible. You needed to take the brain seriously if you wanted to understand. And the whole field of cognitive psychology changed. It went from being completely abstract and computational to doing almost everything it did in relation to what happened in the brain. So cognitive psychology is now completely connected with neuroscience in the field of cognitive neuroscience. Other areas of psychology, developmental social also became intensely tied in with the brain. So the idea that the hardware doesn't matter, which was what was behind Putnam's functionalism, just by the 90s, didn't seem plausible at all. So that's why I think functionalism is a defunct view in the philosophy of mind, even though there are people who seem to assume that it's right. Sometimes it goes under other names. There's another name that people use, it's called substrate independence. The idea is the substrate is the physical, and so that doesn't matter. And there are people who use that because it suits some of their views, such as the idea that we're all living in a simulation, which I think is a really dumb view. But in order to believe that, you have to believe that substrate independence is true, which is another word for functionalism, which says the hardware doesn't matter, because the idea of where a simulation is some computer in the future is basically simulating our thoughts now. Well, that assumes that a computer can simulate all our thoughts, which assumes functionalism or some straight independence, independence, which I think is wrong. And I've actually just published a paper in Philosophy of Science two years ago that gives a whole bunch of arguments based on energy about why it's wrong. But there are other reasons as well for thinking that functionalism or substrate independence is wrong. Okay, that's enough. That's really fun. But go ahead. I didn't mean to interrupt you there, but please. I just wanted to summarize. So it was a great idea in the Philosophy of Mind that no longer should be taken very seriously, given what we know about brains and energy. So even look at the way AI is going right now. So the generative AI models, the large language models are incredible, but they're really energy pigs. It takes vast amounts of energy to train these things and answer questions. Our brains are astonishing. Our brains work on basically 40 watts, like a small light bulb, very small amounts of energy, very efficient, and yet we're still smarter than any computer with all these resources. So there's a full field called neuromorphic AI, which is trying to make computers more like the brain to get these advantages of energy and efficiency and working in real time. So I think these are really interesting research areas that show that functionalism just wasn't it is no longer a plausible view in the Philosophy of Mind. Now that's an astute point, Professor, because I was, well, two points on there. Firstly, I always found functionalists to be good old Cartesian's where they had the mind, the mind matter. They think mind is independent to matter, which for me never made any sense, given we have physical embodied beings. And secondly, you are 100% right that I was listened to a talk by Scott Aronson, the American computer scientist, and he is now a researcher at Open AI. And Open AI is heavily investing in quantum computing and even in nuclear energy, because they've understood that if they are to grow their LLMs, they need infinite amounts of energy, because the compute power for LLMs are so, they're so high compared to like our puny little brains, which is a fascinating conversation.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.68, "text": " I want to discuss, uh, explanatory coherence. Uh, you've done a lot of work on that. And I'm", "tokens": [50364, 286, 528, 281, 2248, 11, 2232, 11, 9045, 4745, 26528, 655, 13, 4019, 11, 291, 600, 1096, 257, 688, 295, 589, 322, 300, 13, 400, 286, 478, 50648], "temperature": 0.0, "avg_logprob": -0.11646158599853515, "compression_ratio": 1.6415094339622642, "no_speech_prob": 0.057321697473526}, {"id": 1, "seek": 0, "start": 5.68, "end": 11.28, "text": " wondering if you could kind of give a brief introduction to what, uh, explanatory coherence", "tokens": [50648, 6359, 498, 291, 727, 733, 295, 976, 257, 5353, 9339, 281, 437, 11, 2232, 11, 9045, 4745, 26528, 655, 50928], "temperature": 0.0, "avg_logprob": -0.11646158599853515, "compression_ratio": 1.6415094339622642, "no_speech_prob": 0.057321697473526}, {"id": 2, "seek": 0, "start": 11.28, "end": 18.16, "text": " is to a lay audience. What at the same time, uh, why you think, uh, it's, uh, what, what are the,", "tokens": [50928, 307, 281, 257, 2360, 4034, 13, 708, 412, 264, 912, 565, 11, 2232, 11, 983, 291, 519, 11, 2232, 11, 309, 311, 11, 2232, 11, 437, 11, 437, 366, 264, 11, 51272], "temperature": 0.0, "avg_logprob": -0.11646158599853515, "compression_ratio": 1.6415094339622642, "no_speech_prob": 0.057321697473526}, {"id": 3, "seek": 0, "start": 18.16, "end": 21.2, "text": " what are the implications in fields such as AI and psychology?", "tokens": [51272, 437, 366, 264, 16602, 294, 7909, 1270, 382, 7318, 293, 15105, 30, 51424], "temperature": 0.0, "avg_logprob": -0.11646158599853515, "compression_ratio": 1.6415094339622642, "no_speech_prob": 0.057321697473526}, {"id": 4, "seek": 0, "start": 22.64, "end": 26.72, "text": " Oh, that's a big question, but it's a really interesting one. So let's go back to Darwin.", "tokens": [51496, 876, 11, 300, 311, 257, 955, 1168, 11, 457, 309, 311, 257, 534, 1880, 472, 13, 407, 718, 311, 352, 646, 281, 30233, 13, 51700], "temperature": 0.0, "avg_logprob": -0.11646158599853515, "compression_ratio": 1.6415094339622642, "no_speech_prob": 0.057321697473526}, {"id": 5, "seek": 2672, "start": 26.72, "end": 30.32, "text": " So I mentioned one of my favorite books of all time is the origin of species.", "tokens": [50364, 407, 286, 2835, 472, 295, 452, 2954, 3642, 295, 439, 565, 307, 264, 4957, 295, 6172, 13, 50544], "temperature": 0.0, "avg_logprob": -0.08925836736505682, "compression_ratio": 1.7275641025641026, "no_speech_prob": 0.0017543761059641838}, {"id": 6, "seek": 2672, "start": 30.32, "end": 34.56, "text": " And so what was he doing in that? Uh, well, in my view, what he was trying to do is to", "tokens": [50544, 400, 370, 437, 390, 415, 884, 294, 300, 30, 4019, 11, 731, 11, 294, 452, 1910, 11, 437, 415, 390, 1382, 281, 360, 307, 281, 50756], "temperature": 0.0, "avg_logprob": -0.08925836736505682, "compression_ratio": 1.7275641025641026, "no_speech_prob": 0.0017543761059641838}, {"id": 7, "seek": 2672, "start": 34.56, "end": 38.32, "text": " give a coherent explanation of all sorts of things that he observed. So he went on this", "tokens": [50756, 976, 257, 36239, 10835, 295, 439, 7527, 295, 721, 300, 415, 13095, 13, 407, 415, 1437, 322, 341, 50944], "temperature": 0.0, "avg_logprob": -0.08925836736505682, "compression_ratio": 1.7275641025641026, "no_speech_prob": 0.0017543761059641838}, {"id": 8, "seek": 2672, "start": 38.32, "end": 43.44, "text": " voyage around the world and he collected all sorts of other kinds of biological information.", "tokens": [50944, 30729, 926, 264, 1002, 293, 415, 11087, 439, 7527, 295, 661, 3685, 295, 13910, 1589, 13, 51200], "temperature": 0.0, "avg_logprob": -0.08925836736505682, "compression_ratio": 1.7275641025641026, "no_speech_prob": 0.0017543761059641838}, {"id": 9, "seek": 2672, "start": 43.44, "end": 48.72, "text": " And he gradually seemed to him that it seemed in fact that the species had evolved. I mean,", "tokens": [51200, 400, 415, 13145, 6576, 281, 796, 300, 309, 6576, 294, 1186, 300, 264, 6172, 632, 14178, 13, 286, 914, 11, 51464], "temperature": 0.0, "avg_logprob": -0.08925836736505682, "compression_ratio": 1.7275641025641026, "no_speech_prob": 0.0017543761059641838}, {"id": 10, "seek": 2672, "start": 48.72, "end": 54.72, "text": " now everybody knows that kids get that probably in grade four, but it was a, um, a very controversial", "tokens": [51464, 586, 2201, 3255, 300, 2301, 483, 300, 1391, 294, 7204, 1451, 11, 457, 309, 390, 257, 11, 1105, 11, 257, 588, 17323, 51764], "temperature": 0.0, "avg_logprob": -0.08925836736505682, "compression_ratio": 1.7275641025641026, "no_speech_prob": 0.0017543761059641838}, {"id": 11, "seek": 5472, "start": 54.72, "end": 60.16, "text": " idea. Some people had maintained it, but it went up against religious doctrines. And so he", "tokens": [50364, 1558, 13, 2188, 561, 632, 17578, 309, 11, 457, 309, 1437, 493, 1970, 7185, 46040, 1652, 13, 400, 370, 415, 50636], "temperature": 0.0, "avg_logprob": -0.07816066741943359, "compression_ratio": 1.6642599277978338, "no_speech_prob": 0.008846323937177658}, {"id": 12, "seek": 5472, "start": 60.16, "end": 67.6, "text": " gradually started to amass more and more evidence that species had evolved. But then from reading a", "tokens": [50636, 13145, 1409, 281, 669, 640, 544, 293, 544, 4467, 300, 6172, 632, 14178, 13, 583, 550, 490, 3760, 257, 51008], "temperature": 0.0, "avg_logprob": -0.07816066741943359, "compression_ratio": 1.6642599277978338, "no_speech_prob": 0.008846323937177658}, {"id": 13, "seek": 5472, "start": 67.6, "end": 72.08, "text": " crazy economist named Malthus, he suddenly got the idea of how they evolved. And that's how he", "tokens": [51008, 3219, 36696, 4926, 376, 1302, 301, 11, 415, 5800, 658, 264, 1558, 295, 577, 436, 14178, 13, 400, 300, 311, 577, 415, 51232], "temperature": 0.0, "avg_logprob": -0.07816066741943359, "compression_ratio": 1.6642599277978338, "no_speech_prob": 0.008846323937177658}, {"id": 14, "seek": 5472, "start": 72.08, "end": 76.8, "text": " came up with the idea of, of, of the natural selection. So now we had not only a bunch of", "tokens": [51232, 1361, 493, 365, 264, 1558, 295, 11, 295, 11, 295, 264, 3303, 9450, 13, 407, 586, 321, 632, 406, 787, 257, 3840, 295, 51468], "temperature": 0.0, "avg_logprob": -0.07816066741943359, "compression_ratio": 1.6642599277978338, "no_speech_prob": 0.008846323937177658}, {"id": 15, "seek": 5472, "start": 76.8, "end": 81.6, "text": " observations and the idea that evolution probably had occurred that would explain it,", "tokens": [51468, 18163, 293, 264, 1558, 300, 9303, 1391, 632, 11068, 300, 576, 2903, 309, 11, 51708], "temperature": 0.0, "avg_logprob": -0.07816066741943359, "compression_ratio": 1.6642599277978338, "no_speech_prob": 0.008846323937177658}, {"id": 16, "seek": 8160, "start": 81.6, "end": 87.52, "text": " but an idea of how, how evolution had occurred. That is that natural selection was the mechanism", "tokens": [50364, 457, 364, 1558, 295, 577, 11, 577, 9303, 632, 11068, 13, 663, 307, 300, 3303, 9450, 390, 264, 7513, 50660], "temperature": 0.0, "avg_logprob": -0.0628224131704747, "compression_ratio": 1.7720930232558139, "no_speech_prob": 0.0008040181128308177}, {"id": 17, "seek": 8160, "start": 87.52, "end": 94.96, "text": " behind evolution. So what he did in that book was an incredibly beautiful argument for his view,", "tokens": [50660, 2261, 9303, 13, 407, 437, 415, 630, 294, 300, 1446, 390, 364, 6252, 2238, 6770, 337, 702, 1910, 11, 51032], "temperature": 0.0, "avg_logprob": -0.0628224131704747, "compression_ratio": 1.7720930232558139, "no_speech_prob": 0.0008040181128308177}, {"id": 18, "seek": 8160, "start": 94.96, "end": 100.16, "text": " as opposed to the view that was dominant at the time, which was divine creation. So what he was", "tokens": [51032, 382, 8851, 281, 264, 1910, 300, 390, 15657, 412, 264, 565, 11, 597, 390, 13678, 8016, 13, 407, 437, 415, 390, 51292], "temperature": 0.0, "avg_logprob": -0.0628224131704747, "compression_ratio": 1.7720930232558139, "no_speech_prob": 0.0008040181128308177}, {"id": 19, "seek": 8160, "start": 100.16, "end": 106.88, "text": " trying to show is that his view was a better explanation, but then divine creation, because", "tokens": [51292, 1382, 281, 855, 307, 300, 702, 1910, 390, 257, 1101, 10835, 11, 457, 550, 13678, 8016, 11, 570, 51628], "temperature": 0.0, "avg_logprob": -0.0628224131704747, "compression_ratio": 1.7720930232558139, "no_speech_prob": 0.0008040181128308177}, {"id": 20, "seek": 10688, "start": 106.88, "end": 113.52, "text": " it was more coherent with the evidence. So this is an account that philosophers call inference to", "tokens": [50364, 309, 390, 544, 36239, 365, 264, 4467, 13, 407, 341, 307, 364, 2696, 300, 36839, 818, 38253, 281, 50696], "temperature": 0.0, "avg_logprob": -0.07519624498155382, "compression_ratio": 1.7366071428571428, "no_speech_prob": 0.0027146115899086}, {"id": 21, "seek": 10688, "start": 113.52, "end": 119.19999999999999, "text": " the best explanation. You can argue that something's the best explanation because it's more coherent", "tokens": [50696, 264, 1151, 10835, 13, 509, 393, 9695, 300, 746, 311, 264, 1151, 10835, 570, 309, 311, 544, 36239, 50980], "temperature": 0.0, "avg_logprob": -0.07519624498155382, "compression_ratio": 1.7366071428571428, "no_speech_prob": 0.0027146115899086}, {"id": 22, "seek": 10688, "start": 119.19999999999999, "end": 124.0, "text": " with the evidence, but now you have to say what coherence is. So I had these early ideas coming", "tokens": [50980, 365, 264, 4467, 11, 457, 586, 291, 362, 281, 584, 437, 26528, 655, 307, 13, 407, 286, 632, 613, 2440, 3487, 1348, 51220], "temperature": 0.0, "avg_logprob": -0.07519624498155382, "compression_ratio": 1.7366071428571428, "no_speech_prob": 0.0027146115899086}, {"id": 23, "seek": 10688, "start": 124.0, "end": 132.07999999999998, "text": " out of my philosophy of science background, but then in 1987, I got one of the best ideas I've", "tokens": [51220, 484, 295, 452, 10675, 295, 3497, 3678, 11, 457, 550, 294, 29008, 11, 286, 658, 472, 295, 264, 1151, 3487, 286, 600, 51624], "temperature": 0.0, "avg_logprob": -0.07519624498155382, "compression_ratio": 1.7366071428571428, "no_speech_prob": 0.0027146115899086}, {"id": 24, "seek": 13208, "start": 132.08, "end": 137.52, "text": " ever had, which was how to turn coherence from a sort of vague philosophical idea into a precise", "tokens": [50364, 1562, 632, 11, 597, 390, 577, 281, 1261, 26528, 655, 490, 257, 1333, 295, 24247, 25066, 1558, 666, 257, 13600, 50636], "temperature": 0.0, "avg_logprob": -0.06092577414079146, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.028424140065908432}, {"id": 25, "seek": 13208, "start": 137.52, "end": 144.0, "text": " computational one. That is, how can you compute coherence? So I've been working on neural networks", "tokens": [50636, 28270, 472, 13, 663, 307, 11, 577, 393, 291, 14722, 26528, 655, 30, 407, 286, 600, 668, 1364, 322, 18161, 9590, 50960], "temperature": 0.0, "avg_logprob": -0.06092577414079146, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.028424140065908432}, {"id": 26, "seek": 13208, "start": 144.0, "end": 151.04000000000002, "text": " in collaboration with my colleague Keith Holyoke. And he came up with an idea that you could use", "tokens": [50960, 294, 9363, 365, 452, 13532, 20613, 6295, 2949, 13, 400, 415, 1361, 493, 365, 364, 1558, 300, 291, 727, 764, 51312], "temperature": 0.0, "avg_logprob": -0.06092577414079146, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.028424140065908432}, {"id": 27, "seek": 13208, "start": 151.04000000000002, "end": 156.8, "text": " neural networks to explain analogy. These neural networks, of course, are now absolutely central", "tokens": [51312, 18161, 9590, 281, 2903, 21663, 13, 1981, 18161, 9590, 11, 295, 1164, 11, 366, 586, 3122, 5777, 51600], "temperature": 0.0, "avg_logprob": -0.06092577414079146, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.028424140065908432}, {"id": 28, "seek": 13208, "start": 156.8, "end": 161.36, "text": " to artificial intelligence. It's, it's really taken off. That's a whole fascinating topic in", "tokens": [51600, 281, 11677, 7599, 13, 467, 311, 11, 309, 311, 534, 2726, 766, 13, 663, 311, 257, 1379, 10343, 4829, 294, 51828], "temperature": 0.0, "avg_logprob": -0.06092577414079146, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.028424140065908432}, {"id": 29, "seek": 16136, "start": 161.36, "end": 166.48000000000002, "text": " itself. But he figured out a way of doing that. And by that time, I'd done my master's in computer", "tokens": [50364, 2564, 13, 583, 415, 8932, 484, 257, 636, 295, 884, 300, 13, 400, 538, 300, 565, 11, 286, 1116, 1096, 452, 4505, 311, 294, 3820, 50620], "temperature": 0.0, "avg_logprob": -0.09699357604980469, "compression_ratio": 1.726643598615917, "no_speech_prob": 0.0010648503666743636}, {"id": 30, "seek": 16136, "start": 166.48000000000002, "end": 171.44000000000003, "text": " science, so I was a pretty good programmer. And so I programmed up a program to use neural networks", "tokens": [50620, 3497, 11, 370, 286, 390, 257, 1238, 665, 32116, 13, 400, 370, 286, 31092, 493, 257, 1461, 281, 764, 18161, 9590, 50868], "temperature": 0.0, "avg_logprob": -0.09699357604980469, "compression_ratio": 1.726643598615917, "no_speech_prob": 0.0010648503666743636}, {"id": 31, "seek": 16136, "start": 171.44000000000003, "end": 177.36, "text": " to do analogies. So that, that was nice. And then I thought, what else could apply to, and then I", "tokens": [50868, 281, 360, 16660, 530, 13, 407, 300, 11, 300, 390, 1481, 13, 400, 550, 286, 1194, 11, 437, 1646, 727, 3079, 281, 11, 293, 550, 286, 51164], "temperature": 0.0, "avg_logprob": -0.09699357604980469, "compression_ratio": 1.726643598615917, "no_speech_prob": 0.0010648503666743636}, {"id": 32, "seek": 16136, "start": 177.36, "end": 181.28000000000003, "text": " thought back to the problem that was part of my doctoral dissertation, which was inference to the", "tokens": [51164, 1194, 646, 281, 264, 1154, 300, 390, 644, 295, 452, 41419, 39555, 11, 597, 390, 38253, 281, 264, 51360], "temperature": 0.0, "avg_logprob": -0.09699357604980469, "compression_ratio": 1.726643598615917, "no_speech_prob": 0.0010648503666743636}, {"id": 33, "seek": 16136, "start": 181.28000000000003, "end": 186.8, "text": " best explanation. How do you pick up the best theory? And so then I realized that that kind of coherence", "tokens": [51360, 1151, 10835, 13, 1012, 360, 291, 1888, 493, 264, 1151, 5261, 30, 400, 370, 550, 286, 5334, 300, 300, 733, 295, 26528, 655, 51636], "temperature": 0.0, "avg_logprob": -0.09699357604980469, "compression_ratio": 1.726643598615917, "no_speech_prob": 0.0010648503666743636}, {"id": 34, "seek": 18680, "start": 186.8, "end": 192.32000000000002, "text": " can be understood using the same kind of neural network technique that Keith and I had done for,", "tokens": [50364, 393, 312, 7320, 1228, 264, 912, 733, 295, 18161, 3209, 6532, 300, 20613, 293, 286, 632, 1096, 337, 11, 50640], "temperature": 0.0, "avg_logprob": -0.0766570986682222, "compression_ratio": 1.8044871794871795, "no_speech_prob": 0.022277550771832466}, {"id": 35, "seek": 18680, "start": 192.32000000000002, "end": 198.72, "text": " for analogy. So it was a really powerful method, both computationally, but also psychologically,", "tokens": [50640, 337, 21663, 13, 407, 309, 390, 257, 534, 4005, 3170, 11, 1293, 24903, 379, 11, 457, 611, 41387, 11, 50960], "temperature": 0.0, "avg_logprob": -0.0766570986682222, "compression_ratio": 1.8044871794871795, "no_speech_prob": 0.022277550771832466}, {"id": 36, "seek": 18680, "start": 198.72, "end": 202.48000000000002, "text": " because there have now since then been lots of psychological experiments that back up this", "tokens": [50960, 570, 456, 362, 586, 1670, 550, 668, 3195, 295, 14346, 12050, 300, 646, 493, 341, 51148], "temperature": 0.0, "avg_logprob": -0.0766570986682222, "compression_ratio": 1.8044871794871795, "no_speech_prob": 0.022277550771832466}, {"id": 37, "seek": 18680, "start": 202.48000000000002, "end": 207.44, "text": " idea of coherence. So I think of the mind, the brain as essentially a coherence engine.", "tokens": [51148, 1558, 295, 26528, 655, 13, 407, 286, 519, 295, 264, 1575, 11, 264, 3567, 382, 4476, 257, 26528, 655, 2848, 13, 51396], "temperature": 0.0, "avg_logprob": -0.0766570986682222, "compression_ratio": 1.8044871794871795, "no_speech_prob": 0.022277550771832466}, {"id": 38, "seek": 18680, "start": 207.44, "end": 211.28, "text": " There's some people who think that it's primarily a predictive engine, but I don't think that's", "tokens": [51396, 821, 311, 512, 561, 567, 519, 300, 309, 311, 10029, 257, 35521, 2848, 11, 457, 286, 500, 380, 519, 300, 311, 51588], "temperature": 0.0, "avg_logprob": -0.0766570986682222, "compression_ratio": 1.8044871794871795, "no_speech_prob": 0.022277550771832466}, {"id": 39, "seek": 18680, "start": 211.28, "end": 215.76000000000002, "text": " true. I think it's primarily a coherence engine. We're trying to make sense of things, whether", "tokens": [51588, 2074, 13, 286, 519, 309, 311, 10029, 257, 26528, 655, 2848, 13, 492, 434, 1382, 281, 652, 2020, 295, 721, 11, 1968, 51812], "temperature": 0.0, "avg_logprob": -0.0766570986682222, "compression_ratio": 1.8044871794871795, "no_speech_prob": 0.022277550771832466}, {"id": 40, "seek": 21576, "start": 215.76, "end": 220.88, "text": " we're making sense of the past, which is what explanations do, or making sense of the future,", "tokens": [50364, 321, 434, 1455, 2020, 295, 264, 1791, 11, 597, 307, 437, 28708, 360, 11, 420, 1455, 2020, 295, 264, 2027, 11, 50620], "temperature": 0.0, "avg_logprob": -0.09126780325906318, "compression_ratio": 1.7408759124087592, "no_speech_prob": 0.0005702656926587224}, {"id": 41, "seek": 21576, "start": 220.88, "end": 227.51999999999998, "text": " we're making coherent predictions, or we're trying to identify things. Is that a rabbit or a squirrel?", "tokens": [50620, 321, 434, 1455, 36239, 21264, 11, 420, 321, 434, 1382, 281, 5876, 721, 13, 1119, 300, 257, 19509, 420, 257, 28565, 30, 50952], "temperature": 0.0, "avg_logprob": -0.09126780325906318, "compression_ratio": 1.7408759124087592, "no_speech_prob": 0.0005702656926587224}, {"id": 42, "seek": 21576, "start": 227.51999999999998, "end": 232.07999999999998, "text": " Those are, are different kinds of thought. Everything we do can be understood as having", "tokens": [50952, 3950, 366, 11, 366, 819, 3685, 295, 1194, 13, 5471, 321, 360, 393, 312, 7320, 382, 1419, 51180], "temperature": 0.0, "avg_logprob": -0.09126780325906318, "compression_ratio": 1.7408759124087592, "no_speech_prob": 0.0005702656926587224}, {"id": 43, "seek": 21576, "start": 232.07999999999998, "end": 236.95999999999998, "text": " coherence behind it. But coherence now isn't just a sort of vague metaphor that it was for", "tokens": [51180, 26528, 655, 2261, 309, 13, 583, 26528, 655, 586, 1943, 380, 445, 257, 1333, 295, 24247, 19157, 300, 309, 390, 337, 51424], "temperature": 0.0, "avg_logprob": -0.09126780325906318, "compression_ratio": 1.7408759124087592, "no_speech_prob": 0.0005702656926587224}, {"id": 44, "seek": 21576, "start": 236.95999999999998, "end": 241.92, "text": " philosophers. It's not just a matter of consistency. It's rather of taking a whole bunch of different", "tokens": [51424, 36839, 13, 467, 311, 406, 445, 257, 1871, 295, 14416, 13, 467, 311, 2831, 295, 1940, 257, 1379, 3840, 295, 819, 51672], "temperature": 0.0, "avg_logprob": -0.09126780325906318, "compression_ratio": 1.7408759124087592, "no_speech_prob": 0.0005702656926587224}, {"id": 45, "seek": 24192, "start": 241.92, "end": 248.0, "text": " things and putting them into a good package. But what's a good package? Well, here there's an idea", "tokens": [50364, 721, 293, 3372, 552, 666, 257, 665, 7372, 13, 583, 437, 311, 257, 665, 7372, 30, 1042, 11, 510, 456, 311, 364, 1558, 50668], "temperature": 0.0, "avg_logprob": -0.08598499967340838, "compression_ratio": 1.8125, "no_speech_prob": 0.008572528138756752}, {"id": 46, "seek": 24192, "start": 248.0, "end": 254.32, "text": " that came out of the neural network world called constraint satisfaction. So we're trying to satisfy", "tokens": [50668, 300, 1361, 484, 295, 264, 18161, 3209, 1002, 1219, 25534, 18715, 13, 407, 321, 434, 1382, 281, 19319, 50984], "temperature": 0.0, "avg_logprob": -0.08598499967340838, "compression_ratio": 1.8125, "no_speech_prob": 0.008572528138756752}, {"id": 47, "seek": 24192, "start": 254.32, "end": 259.2, "text": " a bunch of constraints. What constraints did Darwin face? Well, he was trying to explain as much as", "tokens": [50984, 257, 3840, 295, 18491, 13, 708, 18491, 630, 30233, 1851, 30, 1042, 11, 415, 390, 1382, 281, 2903, 382, 709, 382, 51228], "temperature": 0.0, "avg_logprob": -0.08598499967340838, "compression_ratio": 1.8125, "no_speech_prob": 0.008572528138756752}, {"id": 48, "seek": 24192, "start": 259.2, "end": 265.2, "text": " possible about what he'd seen in the biological world. That's the positive constraints, but he", "tokens": [51228, 1944, 466, 437, 415, 1116, 1612, 294, 264, 13910, 1002, 13, 663, 311, 264, 3353, 18491, 11, 457, 415, 51528], "temperature": 0.0, "avg_logprob": -0.08598499967340838, "compression_ratio": 1.8125, "no_speech_prob": 0.008572528138756752}, {"id": 49, "seek": 24192, "start": 265.2, "end": 269.44, "text": " also had a negative constraint. And so he had to show that he could do that better than the theory", "tokens": [51528, 611, 632, 257, 3671, 25534, 13, 400, 370, 415, 632, 281, 855, 300, 415, 727, 360, 300, 1101, 813, 264, 5261, 51740], "temperature": 0.0, "avg_logprob": -0.08598499967340838, "compression_ratio": 1.8125, "no_speech_prob": 0.008572528138756752}, {"id": 50, "seek": 26944, "start": 269.44, "end": 273.92, "text": " that was the computer at the top competitor at the time, which is divine creation. So that's a", "tokens": [50364, 300, 390, 264, 3820, 412, 264, 1192, 27266, 412, 264, 565, 11, 597, 307, 13678, 8016, 13, 407, 300, 311, 257, 50588], "temperature": 0.0, "avg_logprob": -0.07225230855679293, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.0020502936094999313}, {"id": 51, "seek": 26944, "start": 273.92, "end": 278.8, "text": " negative constraint. So what you're doing in all of these things, whether it's decision making or", "tokens": [50588, 3671, 25534, 13, 407, 437, 291, 434, 884, 294, 439, 295, 613, 721, 11, 1968, 309, 311, 3537, 1455, 420, 50832], "temperature": 0.0, "avg_logprob": -0.07225230855679293, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.0020502936094999313}, {"id": 52, "seek": 26944, "start": 278.8, "end": 284.4, "text": " pattern recognition, or even emotion, you're putting together different sorts of constraints to", "tokens": [50832, 5102, 11150, 11, 420, 754, 8913, 11, 291, 434, 3372, 1214, 819, 7527, 295, 18491, 281, 51112], "temperature": 0.0, "avg_logprob": -0.07225230855679293, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.0020502936094999313}, {"id": 53, "seek": 26944, "start": 284.4, "end": 290.24, "text": " evaluate what's the most coherent view. So that's how I came to see coherence, not just as a vague", "tokens": [51112, 13059, 437, 311, 264, 881, 36239, 1910, 13, 407, 300, 311, 577, 286, 1361, 281, 536, 26528, 655, 11, 406, 445, 382, 257, 24247, 51404], "temperature": 0.0, "avg_logprob": -0.07225230855679293, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.0020502936094999313}, {"id": 54, "seek": 26944, "start": 290.24, "end": 296.08, "text": " philosophical idea, but as a quite precise computational one that can be used to explain", "tokens": [51404, 25066, 1558, 11, 457, 382, 257, 1596, 13600, 28270, 472, 300, 393, 312, 1143, 281, 2903, 51696], "temperature": 0.0, "avg_logprob": -0.07225230855679293, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.0020502936094999313}, {"id": 55, "seek": 29608, "start": 296.64, "end": 302.24, "text": " the mechanisms that underlie a vast amount of human thinking. So that's why I think coherence", "tokens": [50392, 264, 15902, 300, 833, 6302, 257, 8369, 2372, 295, 1952, 1953, 13, 407, 300, 311, 983, 286, 519, 26528, 655, 50672], "temperature": 0.0, "avg_logprob": -0.09054221047295465, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.0046797096729278564}, {"id": 56, "seek": 29608, "start": 302.24, "end": 310.0, "text": " is really a fundamental idea to psychology and cognitive science and to these philosophical", "tokens": [50672, 307, 534, 257, 8088, 1558, 281, 15105, 293, 15605, 3497, 293, 281, 613, 25066, 51060], "temperature": 0.0, "avg_logprob": -0.09054221047295465, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.0046797096729278564}, {"id": 57, "seek": 29608, "start": 310.0, "end": 315.44, "text": " projects as well. Yeah, excellent, excellent. I'm glad he brought up predictive coding or", "tokens": [51060, 4455, 382, 731, 13, 865, 11, 7103, 11, 7103, 13, 286, 478, 5404, 415, 3038, 493, 35521, 17720, 420, 51332], "temperature": 0.0, "avg_logprob": -0.09054221047295465, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.0046797096729278564}, {"id": 58, "seek": 29608, "start": 315.44, "end": 321.03999999999996, "text": " predictive processing, because I'll be talking to a cognitive scientist next month, in fact,", "tokens": [51332, 35521, 9007, 11, 570, 286, 603, 312, 1417, 281, 257, 15605, 12662, 958, 1618, 11, 294, 1186, 11, 51612], "temperature": 0.0, "avg_logprob": -0.09054221047295465, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.0046797096729278564}, {"id": 59, "seek": 32104, "start": 321.04, "end": 327.76000000000005, "text": " based here in Melbourne. And I want to ask her about your theory of explanatory coherence, because", "tokens": [50364, 2361, 510, 294, 27496, 13, 400, 286, 528, 281, 1029, 720, 466, 428, 5261, 295, 9045, 4745, 26528, 655, 11, 570, 50700], "temperature": 0.0, "avg_logprob": -0.135933340812216, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.11421734094619751}, {"id": 60, "seek": 32104, "start": 327.76000000000005, "end": 334.0, "text": " I believe you do have certain critiques of predictive processing, but also in your book,", "tokens": [50700, 286, 1697, 291, 360, 362, 1629, 3113, 4911, 295, 35521, 9007, 11, 457, 611, 294, 428, 1446, 11, 51012], "temperature": 0.0, "avg_logprob": -0.135933340812216, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.11421734094619751}, {"id": 61, "seek": 32104, "start": 334.0, "end": 340.16, "text": " you are critical of, in fact, no, I think you wrote an article on this, a paper on this, pardon me,", "tokens": [51012, 291, 366, 4924, 295, 11, 294, 1186, 11, 572, 11, 286, 519, 291, 4114, 364, 7222, 322, 341, 11, 257, 3035, 322, 341, 11, 22440, 385, 11, 51320], "temperature": 0.0, "avg_logprob": -0.135933340812216, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.11421734094619751}, {"id": 62, "seek": 32104, "start": 340.16, "end": 346.40000000000003, "text": " you also critical of functionalism, kind of what Hilary Putnam and the likes put forward. So from", "tokens": [51320, 291, 611, 4924, 295, 11745, 1434, 11, 733, 295, 437, 19914, 822, 4935, 5378, 293, 264, 5902, 829, 2128, 13, 407, 490, 51632], "temperature": 0.0, "avg_logprob": -0.135933340812216, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.11421734094619751}, {"id": 63, "seek": 34640, "start": 346.4, "end": 353.59999999999997, "text": " your kind of theory of mind, what would you say are your critiques of one predictive processing,", "tokens": [50364, 428, 733, 295, 5261, 295, 1575, 11, 437, 576, 291, 584, 366, 428, 3113, 4911, 295, 472, 35521, 9007, 11, 50724], "temperature": 0.0, "avg_logprob": -0.16516809381990352, "compression_ratio": 1.7163636363636363, "no_speech_prob": 0.0005353170563466847}, {"id": 64, "seek": 34640, "start": 353.59999999999997, "end": 358.56, "text": " and then functionalism? Those are two different views, I don't think they have anything to do with", "tokens": [50724, 293, 550, 11745, 1434, 30, 3950, 366, 732, 819, 6809, 11, 286, 500, 380, 519, 436, 362, 1340, 281, 360, 365, 50972], "temperature": 0.0, "avg_logprob": -0.16516809381990352, "compression_ratio": 1.7163636363636363, "no_speech_prob": 0.0005353170563466847}, {"id": 65, "seek": 34640, "start": 358.56, "end": 363.52, "text": " each other. I'm just curious, I quote them independently, what would be your critiques?", "tokens": [50972, 1184, 661, 13, 286, 478, 445, 6369, 11, 286, 6513, 552, 21761, 11, 437, 576, 312, 428, 3113, 4911, 30, 51220], "temperature": 0.0, "avg_logprob": -0.16516809381990352, "compression_ratio": 1.7163636363636363, "no_speech_prob": 0.0005353170563466847}, {"id": 66, "seek": 34640, "start": 363.52, "end": 368.0, "text": " Okay, let's do one at a time. Predictive processing definitely is an influential view right now,", "tokens": [51220, 1033, 11, 718, 311, 360, 472, 412, 257, 565, 13, 430, 24945, 488, 9007, 2138, 307, 364, 22215, 1910, 558, 586, 11, 51444], "temperature": 0.0, "avg_logprob": -0.16516809381990352, "compression_ratio": 1.7163636363636363, "no_speech_prob": 0.0005353170563466847}, {"id": 67, "seek": 34640, "start": 368.0, "end": 373.52, "text": " but I think it's just not right. It says that the mind is the brain is a predictive engine,", "tokens": [51444, 457, 286, 519, 309, 311, 445, 406, 558, 13, 467, 1619, 300, 264, 1575, 307, 264, 3567, 307, 257, 35521, 2848, 11, 51720], "temperature": 0.0, "avg_logprob": -0.16516809381990352, "compression_ratio": 1.7163636363636363, "no_speech_prob": 0.0005353170563466847}, {"id": 68, "seek": 37352, "start": 374.24, "end": 378.88, "text": " as if everything is prediction. But the mind doesn't just do prediction, it does at least", "tokens": [50400, 382, 498, 1203, 307, 17630, 13, 583, 264, 1575, 1177, 380, 445, 360, 17630, 11, 309, 775, 412, 1935, 50632], "temperature": 0.0, "avg_logprob": -0.08668566172101856, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.020952563732862473}, {"id": 69, "seek": 37352, "start": 378.88, "end": 384.4, "text": " five other things that are just as important. It does explanation, which involves explaining the", "tokens": [50632, 1732, 661, 721, 300, 366, 445, 382, 1021, 13, 467, 775, 10835, 11, 597, 11626, 13468, 264, 50908], "temperature": 0.0, "avg_logprob": -0.08668566172101856, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.020952563732862473}, {"id": 70, "seek": 37352, "start": 384.4, "end": 388.79999999999995, "text": " past, that's not prediction, that's the past prediction is about the future, or even pattern", "tokens": [50908, 1791, 11, 300, 311, 406, 17630, 11, 300, 311, 264, 1791, 17630, 307, 466, 264, 2027, 11, 420, 754, 5102, 51128], "temperature": 0.0, "avg_logprob": -0.08668566172101856, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.020952563732862473}, {"id": 71, "seek": 37352, "start": 388.79999999999995, "end": 394.88, "text": " recognition. I mentioned, I see an animal in my backyard, what is it? Is that a squirrel or a rabbit?", "tokens": [51128, 11150, 13, 286, 2835, 11, 286, 536, 364, 5496, 294, 452, 20036, 11, 437, 307, 309, 30, 1119, 300, 257, 28565, 420, 257, 19509, 30, 51432], "temperature": 0.0, "avg_logprob": -0.08668566172101856, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.020952563732862473}, {"id": 72, "seek": 37352, "start": 394.88, "end": 398.4, "text": " Well, that's pattern recognition, that's not necessarily a prediction, I want to know what it", "tokens": [51432, 1042, 11, 300, 311, 5102, 11150, 11, 300, 311, 406, 4725, 257, 17630, 11, 286, 528, 281, 458, 437, 309, 51608], "temperature": 0.0, "avg_logprob": -0.08668566172101856, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.020952563732862473}, {"id": 73, "seek": 39840, "start": 398.4, "end": 405.76, "text": " is. We also want to do, and this is really important, evaluation. Is this good or bad for me?", "tokens": [50364, 307, 13, 492, 611, 528, 281, 360, 11, 293, 341, 307, 534, 1021, 11, 13344, 13, 1119, 341, 665, 420, 1578, 337, 385, 30, 50732], "temperature": 0.0, "avg_logprob": -0.09196705971994708, "compression_ratio": 1.685121107266436, "no_speech_prob": 0.061823002994060516}, {"id": 74, "seek": 39840, "start": 405.76, "end": 410.23999999999995, "text": " Is this a threat to me? Or is this something I can eat? How do we do evaluation? Well, in humans,", "tokens": [50732, 1119, 341, 257, 4734, 281, 385, 30, 1610, 307, 341, 746, 286, 393, 1862, 30, 1012, 360, 321, 360, 13344, 30, 1042, 11, 294, 6255, 11, 50956], "temperature": 0.0, "avg_logprob": -0.09196705971994708, "compression_ratio": 1.685121107266436, "no_speech_prob": 0.061823002994060516}, {"id": 75, "seek": 39840, "start": 410.23999999999995, "end": 414.71999999999997, "text": " that comes from emotion. The predictive processing approach has said nothing interesting to say about", "tokens": [50956, 300, 1487, 490, 8913, 13, 440, 35521, 9007, 3109, 575, 848, 1825, 1880, 281, 584, 466, 51180], "temperature": 0.0, "avg_logprob": -0.09196705971994708, "compression_ratio": 1.685121107266436, "no_speech_prob": 0.061823002994060516}, {"id": 76, "seek": 39840, "start": 414.71999999999997, "end": 420.56, "text": " emotion at all, but that's absolutely fundamental to many areas of human thinking. I've got a whole", "tokens": [51180, 8913, 412, 439, 11, 457, 300, 311, 3122, 8088, 281, 867, 3179, 295, 1952, 1953, 13, 286, 600, 658, 257, 1379, 51472], "temperature": 0.0, "avg_logprob": -0.09196705971994708, "compression_ratio": 1.685121107266436, "no_speech_prob": 0.061823002994060516}, {"id": 77, "seek": 39840, "start": 420.56, "end": 428.32, "text": " theory of emotion, of which coherence is part of it, but it's only part of it. So you have to", "tokens": [51472, 5261, 295, 8913, 11, 295, 597, 26528, 655, 307, 644, 295, 309, 11, 457, 309, 311, 787, 644, 295, 309, 13, 407, 291, 362, 281, 51860], "temperature": 0.0, "avg_logprob": -0.09196705971994708, "compression_ratio": 1.685121107266436, "no_speech_prob": 0.061823002994060516}, {"id": 78, "seek": 42832, "start": 428.32, "end": 434.56, "text": " have evaluation going on. Communication, we sometimes predict in order to communicate with", "tokens": [50364, 362, 13344, 516, 322, 13, 34930, 11, 321, 2171, 6069, 294, 1668, 281, 7890, 365, 50676], "temperature": 0.0, "avg_logprob": -0.07527447681800992, "compression_ratio": 1.807843137254902, "no_speech_prob": 0.00045819306978955865}, {"id": 79, "seek": 42832, "start": 434.56, "end": 439.84, "text": " other people, but there's lots of other things going on where we want to be able to get our ideas", "tokens": [50676, 661, 561, 11, 457, 456, 311, 3195, 295, 661, 721, 516, 322, 689, 321, 528, 281, 312, 1075, 281, 483, 527, 3487, 50940], "temperature": 0.0, "avg_logprob": -0.07527447681800992, "compression_ratio": 1.807843137254902, "no_speech_prob": 0.00045819306978955865}, {"id": 80, "seek": 42832, "start": 439.84, "end": 445.28, "text": " across to others. So that's just at least five things that are part of the human mind other", "tokens": [50940, 2108, 281, 2357, 13, 407, 300, 311, 445, 412, 1935, 1732, 721, 300, 366, 644, 295, 264, 1952, 1575, 661, 51212], "temperature": 0.0, "avg_logprob": -0.07527447681800992, "compression_ratio": 1.807843137254902, "no_speech_prob": 0.00045819306978955865}, {"id": 81, "seek": 42832, "start": 445.28, "end": 451.44, "text": " than predictive processing. So that's my first critique. My second critique is the way that", "tokens": [51212, 813, 35521, 9007, 13, 407, 300, 311, 452, 700, 25673, 13, 1222, 1150, 25673, 307, 264, 636, 300, 51520], "temperature": 0.0, "avg_logprob": -0.07527447681800992, "compression_ratio": 1.807843137254902, "no_speech_prob": 0.00045819306978955865}, {"id": 82, "seek": 42832, "start": 451.44, "end": 455.44, "text": " people in that world think that predictive processing work doesn't correspond to how the", "tokens": [51520, 561, 294, 300, 1002, 519, 300, 35521, 9007, 589, 1177, 380, 6805, 281, 577, 264, 51720], "temperature": 0.0, "avg_logprob": -0.07527447681800992, "compression_ratio": 1.807843137254902, "no_speech_prob": 0.00045819306978955865}, {"id": 83, "seek": 45544, "start": 455.44, "end": 460.88, "text": " brain works very well. They're Bayesians. They say that the brain uses probability theory in", "tokens": [50364, 3567, 1985, 588, 731, 13, 814, 434, 7840, 279, 2567, 13, 814, 584, 300, 264, 3567, 4960, 8482, 5261, 294, 50636], "temperature": 0.0, "avg_logprob": -0.07245310362394866, "compression_ratio": 1.7752808988764044, "no_speech_prob": 0.003482743864879012}, {"id": 84, "seek": 45544, "start": 460.88, "end": 467.76, "text": " accord with Bayes' theorem to predict the next thing. Well, this is crazy computationally.", "tokens": [50636, 18640, 365, 7840, 279, 6, 20904, 281, 6069, 264, 958, 551, 13, 1042, 11, 341, 307, 3219, 24903, 379, 13, 50980], "temperature": 0.0, "avg_logprob": -0.07245310362394866, "compression_ratio": 1.7752808988764044, "no_speech_prob": 0.003482743864879012}, {"id": 85, "seek": 45544, "start": 467.76, "end": 473.68, "text": " Bayesian processing is well known in artificial intelligence to be extremely inefficient. You", "tokens": [50980, 7840, 42434, 9007, 307, 731, 2570, 294, 11677, 7599, 281, 312, 4664, 43495, 13, 509, 51276], "temperature": 0.0, "avg_logprob": -0.07245310362394866, "compression_ratio": 1.7752808988764044, "no_speech_prob": 0.003482743864879012}, {"id": 86, "seek": 45544, "start": 473.68, "end": 479.28, "text": " can prove that it's computationally intractable. You can show that it causes all sorts of problems.", "tokens": [51276, 393, 7081, 300, 309, 311, 24903, 379, 560, 1897, 712, 13, 509, 393, 855, 300, 309, 7700, 439, 7527, 295, 2740, 13, 51556], "temperature": 0.0, "avg_logprob": -0.07245310362394866, "compression_ratio": 1.7752808988764044, "no_speech_prob": 0.003482743864879012}, {"id": 87, "seek": 45544, "start": 479.28, "end": 483.76, "text": " Bayesians have to jump through all sorts of hoops to try to deal with anything larger than that.", "tokens": [51556, 7840, 279, 2567, 362, 281, 3012, 807, 439, 7527, 295, 1106, 3370, 281, 853, 281, 2028, 365, 1340, 4833, 813, 300, 13, 51780], "temperature": 0.0, "avg_logprob": -0.07245310362394866, "compression_ratio": 1.7752808988764044, "no_speech_prob": 0.003482743864879012}, {"id": 88, "seek": 48376, "start": 483.84, "end": 487.92, "text": " I've done a little bit of Bayesian modeling because I wanted to, I drew a couple of papers", "tokens": [50368, 286, 600, 1096, 257, 707, 857, 295, 7840, 42434, 15983, 570, 286, 1415, 281, 11, 286, 12804, 257, 1916, 295, 10577, 50572], "temperature": 0.0, "avg_logprob": -0.08936938785371326, "compression_ratio": 1.9403508771929825, "no_speech_prob": 0.001244465121999383}, {"id": 89, "seek": 48376, "start": 487.92, "end": 492.88, "text": " where I compared a Bayesian model of legal reasoning to my explanatory coherence one.", "tokens": [50572, 689, 286, 5347, 257, 7840, 42434, 2316, 295, 5089, 21577, 281, 452, 9045, 4745, 26528, 655, 472, 13, 50820], "temperature": 0.0, "avg_logprob": -0.08936938785371326, "compression_ratio": 1.9403508771929825, "no_speech_prob": 0.001244465121999383}, {"id": 90, "seek": 48376, "start": 492.88, "end": 498.15999999999997, "text": " But the Bayesian models are crazy because you have to generate all sorts of conditional probabilities", "tokens": [50820, 583, 264, 7840, 42434, 5245, 366, 3219, 570, 291, 362, 281, 8460, 439, 7527, 295, 27708, 33783, 51084], "temperature": 0.0, "avg_logprob": -0.08936938785371326, "compression_ratio": 1.9403508771929825, "no_speech_prob": 0.001244465121999383}, {"id": 91, "seek": 48376, "start": 498.15999999999997, "end": 502.24, "text": " that nobody has an idea what they are. So if you actually do Bayesian modeling seriously,", "tokens": [51084, 300, 5079, 575, 364, 1558, 437, 436, 366, 13, 407, 498, 291, 767, 360, 7840, 42434, 15983, 6638, 11, 51288], "temperature": 0.0, "avg_logprob": -0.08936938785371326, "compression_ratio": 1.9403508771929825, "no_speech_prob": 0.001244465121999383}, {"id": 92, "seek": 48376, "start": 502.24, "end": 505.92, "text": " you'll find first of all, you don't know any of the probabilities. You don't know any of the", "tokens": [51288, 291, 603, 915, 700, 295, 439, 11, 291, 500, 380, 458, 604, 295, 264, 33783, 13, 509, 500, 380, 458, 604, 295, 264, 51472], "temperature": 0.0, "avg_logprob": -0.08936938785371326, "compression_ratio": 1.9403508771929825, "no_speech_prob": 0.001244465121999383}, {"id": 93, "seek": 48376, "start": 505.92, "end": 510.4, "text": " conditional probabilities. You don't have the computational or neural resources to actually", "tokens": [51472, 27708, 33783, 13, 509, 500, 380, 362, 264, 28270, 420, 18161, 3593, 281, 767, 51696], "temperature": 0.0, "avg_logprob": -0.08936938785371326, "compression_ratio": 1.9403508771929825, "no_speech_prob": 0.001244465121999383}, {"id": 94, "seek": 51040, "start": 510.4, "end": 515.84, "text": " commute the probabilities. So the way that predictive processing with its too narrow view", "tokens": [50364, 36750, 264, 33783, 13, 407, 264, 636, 300, 35521, 9007, 365, 1080, 886, 9432, 1910, 50636], "temperature": 0.0, "avg_logprob": -0.09570139930361793, "compression_ratio": 1.705223880597015, "no_speech_prob": 0.004904146306216717}, {"id": 95, "seek": 51040, "start": 515.84, "end": 520.24, "text": " of how the brain works fills it out is by making brains Bayesian when they're not.", "tokens": [50636, 295, 577, 264, 3567, 1985, 22498, 309, 484, 307, 538, 1455, 15442, 7840, 42434, 562, 436, 434, 406, 13, 50856], "temperature": 0.0, "avg_logprob": -0.09570139930361793, "compression_ratio": 1.705223880597015, "no_speech_prob": 0.004904146306216717}, {"id": 96, "seek": 51040, "start": 520.24, "end": 526.64, "text": " A really good contrast here is with the new generative AI models, which are actually incredibly", "tokens": [50856, 316, 534, 665, 8712, 510, 307, 365, 264, 777, 1337, 1166, 7318, 5245, 11, 597, 366, 767, 6252, 51176], "temperature": 0.0, "avg_logprob": -0.09570139930361793, "compression_ratio": 1.705223880597015, "no_speech_prob": 0.004904146306216717}, {"id": 97, "seek": 51040, "start": 526.64, "end": 533.68, "text": " good at predicting. Have you used chat GPT or any of the others? They're astonishing. They're", "tokens": [51176, 665, 412, 32884, 13, 3560, 291, 1143, 5081, 26039, 51, 420, 604, 295, 264, 2357, 30, 814, 434, 35264, 13, 814, 434, 51528], "temperature": 0.0, "avg_logprob": -0.09570139930361793, "compression_ratio": 1.705223880597015, "no_speech_prob": 0.004904146306216717}, {"id": 98, "seek": 51040, "start": 533.68, "end": 538.48, "text": " astonishing at how good they are at predicting the next word to say. And they end up producing", "tokens": [51528, 35264, 412, 577, 665, 436, 366, 412, 32884, 264, 958, 1349, 281, 584, 13, 400, 436, 917, 493, 10501, 51768], "temperature": 0.0, "avg_logprob": -0.09570139930361793, "compression_ratio": 1.705223880597015, "no_speech_prob": 0.004904146306216717}, {"id": 99, "seek": 53848, "start": 538.48, "end": 543.12, "text": " really coherent stuff. And they get things really bad, badly wrong sometimes, but often", "tokens": [50364, 534, 36239, 1507, 13, 400, 436, 483, 721, 534, 1578, 11, 13425, 2085, 2171, 11, 457, 2049, 50596], "temperature": 0.0, "avg_logprob": -0.13348756896124947, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.007571208756417036}, {"id": 100, "seek": 53848, "start": 543.12, "end": 548.08, "text": " they're really good, but they don't use Bayesian predictions. It's they've got all different kinds", "tokens": [50596, 436, 434, 534, 665, 11, 457, 436, 500, 380, 764, 7840, 42434, 21264, 13, 467, 311, 436, 600, 658, 439, 819, 3685, 50844], "temperature": 0.0, "avg_logprob": -0.13348756896124947, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.007571208756417036}, {"id": 101, "seek": 53848, "start": 548.08, "end": 553.9200000000001, "text": " of algorithms that they use tension mechanism and sorts of things. So they realize that that the", "tokens": [50844, 295, 14642, 300, 436, 764, 8980, 7513, 293, 7527, 295, 721, 13, 407, 436, 4325, 300, 300, 264, 51136], "temperature": 0.0, "avg_logprob": -0.13348756896124947, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.007571208756417036}, {"id": 102, "seek": 53848, "start": 553.9200000000001, "end": 559.12, "text": " Bayesian approach is not going to work for them. So those are my two major criticisms of the", "tokens": [51136, 7840, 42434, 3109, 307, 406, 516, 281, 589, 337, 552, 13, 407, 729, 366, 452, 732, 2563, 48519, 295, 264, 51396], "temperature": 0.0, "avg_logprob": -0.13348756896124947, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.007571208756417036}, {"id": 103, "seek": 53848, "start": 559.12, "end": 564.16, "text": " predictive processing. The brain is a multi fast, it's a coherence engine doing six things", "tokens": [51396, 35521, 9007, 13, 440, 3567, 307, 257, 4825, 2370, 11, 309, 311, 257, 26528, 655, 2848, 884, 2309, 721, 51648], "temperature": 0.0, "avg_logprob": -0.13348756896124947, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.007571208756417036}, {"id": 104, "seek": 56416, "start": 564.56, "end": 570.3199999999999, "text": " as well as prediction. And it's not doing it using Bayesian probability calculations.", "tokens": [50384, 382, 731, 382, 17630, 13, 400, 309, 311, 406, 884, 309, 1228, 7840, 42434, 8482, 20448, 13, 50672], "temperature": 0.0, "avg_logprob": -0.13687290251255035, "compression_ratio": 1.729032258064516, "no_speech_prob": 0.004753573331981897}, {"id": 105, "seek": 56416, "start": 571.36, "end": 573.28, "text": " Okay, so is that good enough for predictive processing?", "tokens": [50724, 1033, 11, 370, 307, 300, 665, 1547, 337, 35521, 9007, 30, 50820], "temperature": 0.0, "avg_logprob": -0.13687290251255035, "compression_ratio": 1.729032258064516, "no_speech_prob": 0.004753573331981897}, {"id": 106, "seek": 56416, "start": 574.88, "end": 578.3199999999999, "text": " No, I think that's perfect. I want to ask you about the free energy principle, but probably we'll", "tokens": [50900, 883, 11, 286, 519, 300, 311, 2176, 13, 286, 528, 281, 1029, 291, 466, 264, 1737, 2281, 8665, 11, 457, 1391, 321, 603, 51072], "temperature": 0.0, "avg_logprob": -0.13687290251255035, "compression_ratio": 1.729032258064516, "no_speech_prob": 0.004753573331981897}, {"id": 107, "seek": 56416, "start": 578.3199999999999, "end": 584.7199999999999, "text": " get to the functionalism and then maybe come back to the principle. Yeah, okay. So functionalism", "tokens": [51072, 483, 281, 264, 11745, 1434, 293, 550, 1310, 808, 646, 281, 264, 8665, 13, 865, 11, 1392, 13, 407, 11745, 1434, 51392], "temperature": 0.0, "avg_logprob": -0.13687290251255035, "compression_ratio": 1.729032258064516, "no_speech_prob": 0.004753573331981897}, {"id": 108, "seek": 56416, "start": 584.7199999999999, "end": 589.4399999999999, "text": " is a view in the philosophy of mind. It's actually a really bad term because functionalism is a term", "tokens": [51392, 307, 257, 1910, 294, 264, 10675, 295, 1575, 13, 467, 311, 767, 257, 534, 1578, 1433, 570, 11745, 1434, 307, 257, 1433, 51628], "temperature": 0.0, "avg_logprob": -0.13687290251255035, "compression_ratio": 1.729032258064516, "no_speech_prob": 0.004753573331981897}, {"id": 109, "seek": 56416, "start": 589.4399999999999, "end": 593.28, "text": " that operates in about six different fields or six different meetings. So we need to pin it down a", "tokens": [51628, 300, 22577, 294, 466, 2309, 819, 7909, 420, 2309, 819, 8410, 13, 407, 321, 643, 281, 5447, 309, 760, 257, 51820], "temperature": 0.0, "avg_logprob": -0.13687290251255035, "compression_ratio": 1.729032258064516, "no_speech_prob": 0.004753573331981897}, {"id": 110, "seek": 59328, "start": 593.28, "end": 599.12, "text": " bit. Let's call it computational functionalism. Because it came in the 60s when computers started", "tokens": [50364, 857, 13, 961, 311, 818, 309, 28270, 11745, 1434, 13, 1436, 309, 1361, 294, 264, 4060, 82, 562, 10807, 1409, 50656], "temperature": 0.0, "avg_logprob": -0.13440266396235495, "compression_ratio": 1.6978417266187051, "no_speech_prob": 0.0005356692709028721}, {"id": 111, "seek": 59328, "start": 599.12, "end": 604.0799999999999, "text": " to become aware and Hillary Putnam knew about the advances in computing. When computers were", "tokens": [50656, 281, 1813, 3650, 293, 23284, 4935, 5378, 2586, 466, 264, 25297, 294, 15866, 13, 1133, 10807, 645, 50904], "temperature": 0.0, "avg_logprob": -0.13440266396235495, "compression_ratio": 1.6978417266187051, "no_speech_prob": 0.0005356692709028721}, {"id": 112, "seek": 59328, "start": 604.0799999999999, "end": 608.56, "text": " really primitive, then I've got a watch now that was better than all the computers, way better than", "tokens": [50904, 534, 28540, 11, 550, 286, 600, 658, 257, 1159, 586, 300, 390, 1101, 813, 439, 264, 10807, 11, 636, 1101, 813, 51128], "temperature": 0.0, "avg_logprob": -0.13440266396235495, "compression_ratio": 1.6978417266187051, "no_speech_prob": 0.0005356692709028721}, {"id": 113, "seek": 59328, "start": 608.56, "end": 615.6, "text": " anything that came along for decades. But but still, people were starting to think that with", "tokens": [51128, 1340, 300, 1361, 2051, 337, 7878, 13, 583, 457, 920, 11, 561, 645, 2891, 281, 519, 300, 365, 51480], "temperature": 0.0, "avg_logprob": -0.13440266396235495, "compression_ratio": 1.6978417266187051, "no_speech_prob": 0.0005356692709028721}, {"id": 114, "seek": 59328, "start": 615.6, "end": 621.68, "text": " computers and the possibility of artificial intelligence, we've got this abstract way of", "tokens": [51480, 10807, 293, 264, 7959, 295, 11677, 7599, 11, 321, 600, 658, 341, 12649, 636, 295, 51784], "temperature": 0.0, "avg_logprob": -0.13440266396235495, "compression_ratio": 1.6978417266187051, "no_speech_prob": 0.0005356692709028721}, {"id": 115, "seek": 62168, "start": 621.68, "end": 628.16, "text": " thinking of thinking as a kind of computation. Now, one thing that's really true or seems to be", "tokens": [50364, 1953, 295, 1953, 382, 257, 733, 295, 24903, 13, 823, 11, 472, 551, 300, 311, 534, 2074, 420, 2544, 281, 312, 50688], "temperature": 0.0, "avg_logprob": -0.09519681851725934, "compression_ratio": 1.8089887640449438, "no_speech_prob": 0.0010003834031522274}, {"id": 116, "seek": 62168, "start": 628.16, "end": 633.8399999999999, "text": " true about computation is that it doesn't really matter what you run it on. So here I'm using a", "tokens": [50688, 2074, 466, 24903, 307, 300, 309, 1177, 380, 534, 1871, 437, 291, 1190, 309, 322, 13, 407, 510, 286, 478, 1228, 257, 50972], "temperature": 0.0, "avg_logprob": -0.09519681851725934, "compression_ratio": 1.8089887640449438, "no_speech_prob": 0.0010003834031522274}, {"id": 117, "seek": 62168, "start": 633.8399999999999, "end": 639.68, "text": " Macintosh. I don't know what kind of computer you've got. It could be a PC or running a different", "tokens": [50972, 5707, 686, 3019, 13, 286, 500, 380, 458, 437, 733, 295, 3820, 291, 600, 658, 13, 467, 727, 312, 257, 6465, 420, 2614, 257, 819, 51264], "temperature": 0.0, "avg_logprob": -0.09519681851725934, "compression_ratio": 1.8089887640449438, "no_speech_prob": 0.0010003834031522274}, {"id": 118, "seek": 62168, "start": 639.68, "end": 644.0799999999999, "text": " kind of hardware altogether. It doesn't matter. We can all run the same software. And so the", "tokens": [51264, 733, 295, 8837, 19051, 13, 467, 1177, 380, 1871, 13, 492, 393, 439, 1190, 264, 912, 4722, 13, 400, 370, 264, 51484], "temperature": 0.0, "avg_logprob": -0.09519681851725934, "compression_ratio": 1.8089887640449438, "no_speech_prob": 0.0010003834031522274}, {"id": 119, "seek": 62168, "start": 644.0799999999999, "end": 650.88, "text": " analogy that Putnam hit on was mind is software rather than hardware. You can take the same software", "tokens": [51484, 21663, 300, 4935, 5378, 2045, 322, 390, 1575, 307, 4722, 2831, 813, 8837, 13, 509, 393, 747, 264, 912, 4722, 51824], "temperature": 0.0, "avg_logprob": -0.09519681851725934, "compression_ratio": 1.8089887640449438, "no_speech_prob": 0.0010003834031522274}, {"id": 120, "seek": 65088, "start": 650.88, "end": 654.32, "text": " and run it on a bunch of people or hardware. All that matters is it has the appropriate", "tokens": [50364, 293, 1190, 309, 322, 257, 3840, 295, 561, 420, 8837, 13, 1057, 300, 7001, 307, 309, 575, 264, 6854, 50536], "temperature": 0.0, "avg_logprob": -0.15150844739831013, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.0012446241453289986}, {"id": 121, "seek": 65088, "start": 654.32, "end": 658.96, "text": " computational functions. That's where the word functionalism comes from. So if you have inputs", "tokens": [50536, 28270, 6828, 13, 663, 311, 689, 264, 1349, 11745, 1434, 1487, 490, 13, 407, 498, 291, 362, 15743, 50768], "temperature": 0.0, "avg_logprob": -0.15150844739831013, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.0012446241453289986}, {"id": 122, "seek": 65088, "start": 658.96, "end": 665.76, "text": " and outputs, and you have the functions in between, you want to be able to make thinking work. And so", "tokens": [50768, 293, 23930, 11, 293, 291, 362, 264, 6828, 294, 1296, 11, 291, 528, 281, 312, 1075, 281, 652, 1953, 589, 13, 400, 370, 51108], "temperature": 0.0, "avg_logprob": -0.15150844739831013, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.0012446241453289986}, {"id": 123, "seek": 65088, "start": 665.76, "end": 672.24, "text": " forget about the hardware. Forget about the brain, for example. The psychologist had been studying", "tokens": [51108, 2870, 466, 264, 8837, 13, 18675, 466, 264, 3567, 11, 337, 1365, 13, 440, 29514, 632, 668, 7601, 51432], "temperature": 0.0, "avg_logprob": -0.15150844739831013, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.0012446241453289986}, {"id": 124, "seek": 65088, "start": 672.24, "end": 678.56, "text": " the brain at that point for, I guess, 60 or 70 years seriously. The functionalist in the 60s said,", "tokens": [51432, 264, 3567, 412, 300, 935, 337, 11, 286, 2041, 11, 4060, 420, 5285, 924, 6638, 13, 440, 11745, 468, 294, 264, 4060, 82, 848, 11, 51748], "temperature": 0.0, "avg_logprob": -0.15150844739831013, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.0012446241453289986}, {"id": 125, "seek": 67856, "start": 678.56, "end": 683.68, "text": " let's forget about the brain. It's all computation. It's just like AI. Anything that runs in the mind", "tokens": [50364, 718, 311, 2870, 466, 264, 3567, 13, 467, 311, 439, 24903, 13, 467, 311, 445, 411, 7318, 13, 11998, 300, 6676, 294, 264, 1575, 50620], "temperature": 0.0, "avg_logprob": -0.10453790233981225, "compression_ratio": 1.7132867132867133, "no_speech_prob": 0.0006262647802941501}, {"id": 126, "seek": 67856, "start": 683.68, "end": 689.1999999999999, "text": " can run on a computer. Okay. And actually in the 1960s and 70s, that was a pretty reasonable idea.", "tokens": [50620, 393, 1190, 322, 257, 3820, 13, 1033, 13, 400, 767, 294, 264, 16157, 82, 293, 5285, 82, 11, 300, 390, 257, 1238, 10585, 1558, 13, 50896], "temperature": 0.0, "avg_logprob": -0.10453790233981225, "compression_ratio": 1.7132867132867133, "no_speech_prob": 0.0006262647802941501}, {"id": 127, "seek": 67856, "start": 689.1999999999999, "end": 693.68, "text": " And this is why a lot of philosophers consider themselves functionalists. It became the dominant", "tokens": [50896, 400, 341, 307, 983, 257, 688, 295, 36839, 1949, 2969, 11745, 1751, 13, 467, 3062, 264, 15657, 51120], "temperature": 0.0, "avg_logprob": -0.10453790233981225, "compression_ratio": 1.7132867132867133, "no_speech_prob": 0.0006262647802941501}, {"id": 128, "seek": 67856, "start": 693.68, "end": 699.3599999999999, "text": " view in the philosophy of mind. So I think that was a pretty good idea in the 60s and 70s because", "tokens": [51120, 1910, 294, 264, 10675, 295, 1575, 13, 407, 286, 519, 300, 390, 257, 1238, 665, 1558, 294, 264, 4060, 82, 293, 5285, 82, 570, 51404], "temperature": 0.0, "avg_logprob": -0.10453790233981225, "compression_ratio": 1.7132867132867133, "no_speech_prob": 0.0006262647802941501}, {"id": 129, "seek": 67856, "start": 699.3599999999999, "end": 706.0, "text": " AI had become a real field. Computers had become at least rudimentarily powerful. And so not a", "tokens": [51404, 7318, 632, 1813, 257, 957, 2519, 13, 37804, 433, 632, 1813, 412, 1935, 32109, 2328, 3289, 4005, 13, 400, 370, 406, 257, 51736], "temperature": 0.0, "avg_logprob": -0.10453790233981225, "compression_ratio": 1.7132867132867133, "no_speech_prob": 0.0006262647802941501}, {"id": 130, "seek": 70600, "start": 706.0, "end": 712.48, "text": " bad idea then. But things changed in the 80s. In the 80s, a bunch of things changed. First of all,", "tokens": [50364, 1578, 1558, 550, 13, 583, 721, 3105, 294, 264, 4688, 82, 13, 682, 264, 4688, 82, 11, 257, 3840, 295, 721, 3105, 13, 2386, 295, 439, 11, 50688], "temperature": 0.0, "avg_logprob": -0.0605815174133797, "compression_ratio": 1.8992248062015504, "no_speech_prob": 0.009706811048090458}, {"id": 131, "seek": 70600, "start": 713.44, "end": 717.76, "text": " brain scanning came along. It had been really hard to study the brain before because you had to do", "tokens": [50736, 3567, 27019, 1361, 2051, 13, 467, 632, 668, 534, 1152, 281, 2979, 264, 3567, 949, 570, 291, 632, 281, 360, 50952], "temperature": 0.0, "avg_logprob": -0.0605815174133797, "compression_ratio": 1.8992248062015504, "no_speech_prob": 0.009706811048090458}, {"id": 132, "seek": 70600, "start": 717.76, "end": 722.0, "text": " things like poke electrodes into brains that had been exposed. And so it was really hard to study", "tokens": [50952, 721, 411, 19712, 47824, 666, 15442, 300, 632, 668, 9495, 13, 400, 370, 309, 390, 534, 1152, 281, 2979, 51164], "temperature": 0.0, "avg_logprob": -0.0605815174133797, "compression_ratio": 1.8992248062015504, "no_speech_prob": 0.009706811048090458}, {"id": 133, "seek": 70600, "start": 722.0, "end": 727.44, "text": " the brain. But in the 80s, brain scans came along. First of all, I forget what they were called,", "tokens": [51164, 264, 3567, 13, 583, 294, 264, 4688, 82, 11, 3567, 35116, 1361, 2051, 13, 2386, 295, 439, 11, 286, 2870, 437, 436, 645, 1219, 11, 51436], "temperature": 0.0, "avg_logprob": -0.0605815174133797, "compression_ratio": 1.8992248062015504, "no_speech_prob": 0.009706811048090458}, {"id": 134, "seek": 70600, "start": 727.44, "end": 731.92, "text": " and then eventually fMRI. But suddenly you could actually study the brain in a much more detailed", "tokens": [51436, 293, 550, 4728, 283, 44, 5577, 13, 583, 5800, 291, 727, 767, 2979, 264, 3567, 294, 257, 709, 544, 9942, 51660], "temperature": 0.0, "avg_logprob": -0.0605815174133797, "compression_ratio": 1.8992248062015504, "no_speech_prob": 0.009706811048090458}, {"id": 135, "seek": 73192, "start": 731.92, "end": 736.88, "text": " way. And then you could start to test some of the claims that had been made. So when people started", "tokens": [50364, 636, 13, 400, 550, 291, 727, 722, 281, 1500, 512, 295, 264, 9441, 300, 632, 668, 1027, 13, 407, 562, 561, 1409, 50612], "temperature": 0.0, "avg_logprob": -0.05868746902768975, "compression_ratio": 1.919093851132686, "no_speech_prob": 0.00609630485996604}, {"id": 136, "seek": 73192, "start": 736.88, "end": 742.56, "text": " doing fMRI studies, they thought, oh, we're going to be able to show that the mind really is module,", "tokens": [50612, 884, 283, 44, 5577, 5313, 11, 436, 1194, 11, 1954, 11, 321, 434, 516, 281, 312, 1075, 281, 855, 300, 264, 1575, 534, 307, 10088, 11, 50896], "temperature": 0.0, "avg_logprob": -0.05868746902768975, "compression_ratio": 1.919093851132686, "no_speech_prob": 0.00609630485996604}, {"id": 137, "seek": 73192, "start": 742.56, "end": 747.36, "text": " that is modular, that is different parts of the brain are doing very specific things. And so we", "tokens": [50896, 300, 307, 31111, 11, 300, 307, 819, 3166, 295, 264, 3567, 366, 884, 588, 2685, 721, 13, 400, 370, 321, 51136], "temperature": 0.0, "avg_logprob": -0.05868746902768975, "compression_ratio": 1.919093851132686, "no_speech_prob": 0.00609630485996604}, {"id": 138, "seek": 73192, "start": 747.36, "end": 751.36, "text": " should be able to find that this part of the brain does high level thinking, this part of the brain", "tokens": [51136, 820, 312, 1075, 281, 915, 300, 341, 644, 295, 264, 3567, 775, 1090, 1496, 1953, 11, 341, 644, 295, 264, 3567, 51336], "temperature": 0.0, "avg_logprob": -0.05868746902768975, "compression_ratio": 1.919093851132686, "no_speech_prob": 0.00609630485996604}, {"id": 139, "seek": 73192, "start": 751.36, "end": 756.56, "text": " does emotion, and that part of the brain does vision, and we could localize it. But once people had", "tokens": [51336, 775, 8913, 11, 293, 300, 644, 295, 264, 3567, 775, 5201, 11, 293, 321, 727, 2654, 1125, 309, 13, 583, 1564, 561, 632, 51596], "temperature": 0.0, "avg_logprob": -0.05868746902768975, "compression_ratio": 1.919093851132686, "no_speech_prob": 0.00609630485996604}, {"id": 140, "seek": 73192, "start": 756.56, "end": 761.36, "text": " this new tool, they started to realize, hey, it's not like that at all. Lots of what goes on the", "tokens": [51596, 341, 777, 2290, 11, 436, 1409, 281, 4325, 11, 4177, 11, 309, 311, 406, 411, 300, 412, 439, 13, 15908, 295, 437, 1709, 322, 264, 51836], "temperature": 0.0, "avg_logprob": -0.05868746902768975, "compression_ratio": 1.919093851132686, "no_speech_prob": 0.00609630485996604}, {"id": 141, "seek": 76136, "start": 761.36, "end": 767.12, "text": " brain involves interactions of lots of different areas. So suddenly the brain became much more", "tokens": [50364, 3567, 11626, 13280, 295, 3195, 295, 819, 3179, 13, 407, 5800, 264, 3567, 3062, 709, 544, 50652], "temperature": 0.0, "avg_logprob": -0.0637503652011647, "compression_ratio": 1.6968641114982579, "no_speech_prob": 0.00018521971651352942}, {"id": 142, "seek": 76136, "start": 767.12, "end": 771.6, "text": " interesting. It didn't look like just some other kind of hardware you might run thoughts on. It", "tokens": [50652, 1880, 13, 467, 994, 380, 574, 411, 445, 512, 661, 733, 295, 8837, 291, 1062, 1190, 4598, 322, 13, 467, 50876], "temperature": 0.0, "avg_logprob": -0.0637503652011647, "compression_ratio": 1.6968641114982579, "no_speech_prob": 0.00018521971651352942}, {"id": 143, "seek": 76136, "start": 771.6, "end": 777.12, "text": " looked like you could study on its own. So there were these empirical findings coming out of the", "tokens": [50876, 2956, 411, 291, 727, 2979, 322, 1080, 1065, 13, 407, 456, 645, 613, 31886, 16483, 1348, 484, 295, 264, 51152], "temperature": 0.0, "avg_logprob": -0.0637503652011647, "compression_ratio": 1.6968641114982579, "no_speech_prob": 0.00018521971651352942}, {"id": 144, "seek": 76136, "start": 777.12, "end": 781.36, "text": " new tools available for studying the brain that suggested that, well, maybe the structure of the", "tokens": [51152, 777, 3873, 2435, 337, 7601, 264, 3567, 300, 10945, 300, 11, 731, 11, 1310, 264, 3877, 295, 264, 51364], "temperature": 0.0, "avg_logprob": -0.0637503652011647, "compression_ratio": 1.6968641114982579, "no_speech_prob": 0.00018521971651352942}, {"id": 145, "seek": 76136, "start": 781.36, "end": 788.5600000000001, "text": " brain really does matter. So that was an incredibly important empirical basis for starting to question", "tokens": [51364, 3567, 534, 775, 1871, 13, 407, 300, 390, 364, 6252, 1021, 31886, 5143, 337, 2891, 281, 1168, 51724], "temperature": 0.0, "avg_logprob": -0.0637503652011647, "compression_ratio": 1.6968641114982579, "no_speech_prob": 0.00018521971651352942}, {"id": 146, "seek": 78856, "start": 788.56, "end": 793.92, "text": " functionalism. But there was also a really interesting theoretical basis coming out of", "tokens": [50364, 11745, 1434, 13, 583, 456, 390, 611, 257, 534, 1880, 20864, 5143, 1348, 484, 295, 50632], "temperature": 0.0, "avg_logprob": -0.12099946219966097, "compression_ratio": 1.7991967871485943, "no_speech_prob": 0.0023229222279042006}, {"id": 147, "seek": 78856, "start": 793.92, "end": 798.7199999999999, "text": " the ideas about neural networks. So the ideas of neural networks have been around really back", "tokens": [50632, 264, 3487, 466, 18161, 9590, 13, 407, 264, 3487, 295, 18161, 9590, 362, 668, 926, 534, 646, 50872], "temperature": 0.0, "avg_logprob": -0.12099946219966097, "compression_ratio": 1.7991967871485943, "no_speech_prob": 0.0023229222279042006}, {"id": 148, "seek": 78856, "start": 798.7199999999999, "end": 804.16, "text": " since the 50s, but it didn't work very well. And people like Marvin Minsky had argued that, no,", "tokens": [50872, 1670, 264, 2625, 82, 11, 457, 309, 994, 380, 589, 588, 731, 13, 400, 561, 411, 48722, 376, 44153, 632, 20219, 300, 11, 572, 11, 51144], "temperature": 0.0, "avg_logprob": -0.12099946219966097, "compression_ratio": 1.7991967871485943, "no_speech_prob": 0.0023229222279042006}, {"id": 149, "seek": 78856, "start": 804.16, "end": 808.0, "text": " those these ideas about neural networks are not going to work very well. They're just,", "tokens": [51144, 729, 613, 3487, 466, 18161, 9590, 366, 406, 516, 281, 589, 588, 731, 13, 814, 434, 445, 11, 51336], "temperature": 0.0, "avg_logprob": -0.12099946219966097, "compression_ratio": 1.7991967871485943, "no_speech_prob": 0.0023229222279042006}, {"id": 150, "seek": 78856, "start": 808.0, "end": 813.28, "text": " they're just, they're just simply not theoretically strong enough. But in the 1980s,", "tokens": [51336, 436, 434, 445, 11, 436, 434, 445, 2935, 406, 29400, 2068, 1547, 13, 583, 294, 264, 13626, 82, 11, 51600], "temperature": 0.0, "avg_logprob": -0.12099946219966097, "compression_ratio": 1.7991967871485943, "no_speech_prob": 0.0023229222279042006}, {"id": 151, "seek": 81328, "start": 814.0, "end": 820.0, "text": " people greatly expanded the possibilities of what neural networks could do. They invented a new", "tokens": [50400, 561, 14147, 14342, 264, 12178, 295, 437, 18161, 9590, 727, 360, 13, 814, 14479, 257, 777, 50700], "temperature": 0.0, "avg_logprob": -0.10951064331362946, "compression_ratio": 1.677304964539007, "no_speech_prob": 0.001987618627026677}, {"id": 152, "seek": 81328, "start": 820.0, "end": 825.04, "text": " algorithm called back propagation that does learning. A whole movement got started called", "tokens": [50700, 9284, 1219, 646, 38377, 300, 775, 2539, 13, 316, 1379, 3963, 658, 1409, 1219, 50952], "temperature": 0.0, "avg_logprob": -0.10951064331362946, "compression_ratio": 1.677304964539007, "no_speech_prob": 0.001987618627026677}, {"id": 153, "seek": 81328, "start": 825.04, "end": 830.3199999999999, "text": " connectionism, which said that knowledge isn't a matter of the words you've got or the symbols,", "tokens": [50952, 4984, 1434, 11, 597, 848, 300, 3601, 1943, 380, 257, 1871, 295, 264, 2283, 291, 600, 658, 420, 264, 16944, 11, 51216], "temperature": 0.0, "avg_logprob": -0.10951064331362946, "compression_ratio": 1.677304964539007, "no_speech_prob": 0.001987618627026677}, {"id": 154, "seek": 81328, "start": 830.3199999999999, "end": 834.56, "text": " which is what artificial intelligence, but it's rather it's the connections, it's the neural", "tokens": [51216, 597, 307, 437, 11677, 7599, 11, 457, 309, 311, 2831, 309, 311, 264, 9271, 11, 309, 311, 264, 18161, 51428], "temperature": 0.0, "avg_logprob": -0.10951064331362946, "compression_ratio": 1.677304964539007, "no_speech_prob": 0.001987618627026677}, {"id": 155, "seek": 81328, "start": 834.56, "end": 839.4399999999999, "text": " connections. So suddenly, people were modeling their computer models, because these are being done", "tokens": [51428, 9271, 13, 407, 5800, 11, 561, 645, 15983, 641, 3820, 5245, 11, 570, 613, 366, 885, 1096, 51672], "temperature": 0.0, "avg_logprob": -0.10951064331362946, "compression_ratio": 1.677304964539007, "no_speech_prob": 0.001987618627026677}, {"id": 156, "seek": 83944, "start": 839.44, "end": 844.32, "text": " with computerized neural networks, they were modeling on ideas about the brain, how you can", "tokens": [50364, 365, 3820, 1602, 18161, 9590, 11, 436, 645, 15983, 322, 3487, 466, 264, 3567, 11, 577, 291, 393, 50608], "temperature": 0.0, "avg_logprob": -0.09758945780062894, "compression_ratio": 1.6748251748251748, "no_speech_prob": 0.00884605199098587}, {"id": 157, "seek": 83944, "start": 844.32, "end": 849.6800000000001, "text": " have different neurons working in parallel with simple connections with them, and nevertheless", "tokens": [50608, 362, 819, 22027, 1364, 294, 8952, 365, 2199, 9271, 365, 552, 11, 293, 26924, 50876], "temperature": 0.0, "avg_logprob": -0.09758945780062894, "compression_ratio": 1.6748251748251748, "no_speech_prob": 0.00884605199098587}, {"id": 158, "seek": 83944, "start": 849.6800000000001, "end": 857.0400000000001, "text": " doing that. So in the 1980s, suddenly, I functionalism was in trouble. Not many people noticed because", "tokens": [50876, 884, 300, 13, 407, 294, 264, 13626, 82, 11, 5800, 11, 286, 11745, 1434, 390, 294, 5253, 13, 1726, 867, 561, 5694, 570, 51244], "temperature": 0.0, "avg_logprob": -0.09758945780062894, "compression_ratio": 1.6748251748251748, "no_speech_prob": 0.00884605199098587}, {"id": 159, "seek": 83944, "start": 857.0400000000001, "end": 861.6800000000001, "text": " they weren't tracking what was happening in neuroscience and in neural network theory,", "tokens": [51244, 436, 4999, 380, 11603, 437, 390, 2737, 294, 42762, 293, 294, 18161, 3209, 5261, 11, 51476], "temperature": 0.0, "avg_logprob": -0.09758945780062894, "compression_ratio": 1.6748251748251748, "no_speech_prob": 0.00884605199098587}, {"id": 160, "seek": 83944, "start": 861.6800000000001, "end": 867.44, "text": " but it wasn't. And by the 1990s, I think it really had completely turned around. I think by the 1990s,", "tokens": [51476, 457, 309, 2067, 380, 13, 400, 538, 264, 13384, 82, 11, 286, 519, 309, 534, 632, 2584, 3574, 926, 13, 286, 519, 538, 264, 13384, 82, 11, 51764], "temperature": 0.0, "avg_logprob": -0.09758945780062894, "compression_ratio": 1.6748251748251748, "no_speech_prob": 0.00884605199098587}, {"id": 161, "seek": 86744, "start": 867.44, "end": 871.84, "text": " functionalism was no longer plausible. You needed to take the brain seriously if you wanted to", "tokens": [50364, 11745, 1434, 390, 572, 2854, 39925, 13, 509, 2978, 281, 747, 264, 3567, 6638, 498, 291, 1415, 281, 50584], "temperature": 0.0, "avg_logprob": -0.07949067021275426, "compression_ratio": 1.8116883116883118, "no_speech_prob": 0.0028891100082546473}, {"id": 162, "seek": 86744, "start": 871.84, "end": 877.2800000000001, "text": " understand. And the whole field of cognitive psychology changed. It went from being completely", "tokens": [50584, 1223, 13, 400, 264, 1379, 2519, 295, 15605, 15105, 3105, 13, 467, 1437, 490, 885, 2584, 50856], "temperature": 0.0, "avg_logprob": -0.07949067021275426, "compression_ratio": 1.8116883116883118, "no_speech_prob": 0.0028891100082546473}, {"id": 163, "seek": 86744, "start": 877.2800000000001, "end": 883.0400000000001, "text": " abstract and computational to doing almost everything it did in relation to what happened", "tokens": [50856, 12649, 293, 28270, 281, 884, 1920, 1203, 309, 630, 294, 9721, 281, 437, 2011, 51144], "temperature": 0.0, "avg_logprob": -0.07949067021275426, "compression_ratio": 1.8116883116883118, "no_speech_prob": 0.0028891100082546473}, {"id": 164, "seek": 86744, "start": 883.0400000000001, "end": 886.5600000000001, "text": " in the brain. So cognitive psychology is now completely connected with neuroscience in the", "tokens": [51144, 294, 264, 3567, 13, 407, 15605, 15105, 307, 586, 2584, 4582, 365, 42762, 294, 264, 51320], "temperature": 0.0, "avg_logprob": -0.07949067021275426, "compression_ratio": 1.8116883116883118, "no_speech_prob": 0.0028891100082546473}, {"id": 165, "seek": 86744, "start": 886.5600000000001, "end": 891.6800000000001, "text": " field of cognitive neuroscience. Other areas of psychology, developmental social also became", "tokens": [51320, 2519, 295, 15605, 42762, 13, 5358, 3179, 295, 15105, 11, 30160, 2093, 611, 3062, 51576], "temperature": 0.0, "avg_logprob": -0.07949067021275426, "compression_ratio": 1.8116883116883118, "no_speech_prob": 0.0028891100082546473}, {"id": 166, "seek": 86744, "start": 891.6800000000001, "end": 896.8800000000001, "text": " intensely tied in with the brain. So the idea that the hardware doesn't matter, which was what", "tokens": [51576, 43235, 9601, 294, 365, 264, 3567, 13, 407, 264, 1558, 300, 264, 8837, 1177, 380, 1871, 11, 597, 390, 437, 51836], "temperature": 0.0, "avg_logprob": -0.07949067021275426, "compression_ratio": 1.8116883116883118, "no_speech_prob": 0.0028891100082546473}, {"id": 167, "seek": 89688, "start": 896.88, "end": 902.16, "text": " was behind Putnam's functionalism, just by the 90s, didn't seem plausible at all. So that's why I", "tokens": [50364, 390, 2261, 4935, 5378, 311, 11745, 1434, 11, 445, 538, 264, 4289, 82, 11, 994, 380, 1643, 39925, 412, 439, 13, 407, 300, 311, 983, 286, 50628], "temperature": 0.0, "avg_logprob": -0.0939153142336036, "compression_ratio": 1.736462093862816, "no_speech_prob": 0.0008828753489069641}, {"id": 168, "seek": 89688, "start": 902.16, "end": 906.08, "text": " think functionalism is a defunct view in the philosophy of mind, even though there are people", "tokens": [50628, 519, 11745, 1434, 307, 257, 1060, 409, 349, 1910, 294, 264, 10675, 295, 1575, 11, 754, 1673, 456, 366, 561, 50824], "temperature": 0.0, "avg_logprob": -0.0939153142336036, "compression_ratio": 1.736462093862816, "no_speech_prob": 0.0008828753489069641}, {"id": 169, "seek": 89688, "start": 906.08, "end": 910.56, "text": " who seem to assume that it's right. Sometimes it goes under other names. There's another name that", "tokens": [50824, 567, 1643, 281, 6552, 300, 309, 311, 558, 13, 4803, 309, 1709, 833, 661, 5288, 13, 821, 311, 1071, 1315, 300, 51048], "temperature": 0.0, "avg_logprob": -0.0939153142336036, "compression_ratio": 1.736462093862816, "no_speech_prob": 0.0008828753489069641}, {"id": 170, "seek": 89688, "start": 910.56, "end": 918.96, "text": " people use, it's called substrate independence. The idea is the substrate is the physical,", "tokens": [51048, 561, 764, 11, 309, 311, 1219, 27585, 14640, 13, 440, 1558, 307, 264, 27585, 307, 264, 4001, 11, 51468], "temperature": 0.0, "avg_logprob": -0.0939153142336036, "compression_ratio": 1.736462093862816, "no_speech_prob": 0.0008828753489069641}, {"id": 171, "seek": 89688, "start": 919.84, "end": 924.16, "text": " and so that doesn't matter. And there are people who use that because it suits some of their views,", "tokens": [51512, 293, 370, 300, 1177, 380, 1871, 13, 400, 456, 366, 561, 567, 764, 300, 570, 309, 15278, 512, 295, 641, 6809, 11, 51728], "temperature": 0.0, "avg_logprob": -0.0939153142336036, "compression_ratio": 1.736462093862816, "no_speech_prob": 0.0008828753489069641}, {"id": 172, "seek": 92416, "start": 924.24, "end": 929.28, "text": " such as the idea that we're all living in a simulation, which I think is a really dumb view.", "tokens": [50368, 1270, 382, 264, 1558, 300, 321, 434, 439, 2647, 294, 257, 16575, 11, 597, 286, 519, 307, 257, 534, 10316, 1910, 13, 50620], "temperature": 0.0, "avg_logprob": -0.08792317267691735, "compression_ratio": 1.7804878048780488, "no_speech_prob": 0.0034829771611839533}, {"id": 173, "seek": 92416, "start": 929.28, "end": 934.3199999999999, "text": " But in order to believe that, you have to believe that substrate independence is true,", "tokens": [50620, 583, 294, 1668, 281, 1697, 300, 11, 291, 362, 281, 1697, 300, 27585, 14640, 307, 2074, 11, 50872], "temperature": 0.0, "avg_logprob": -0.08792317267691735, "compression_ratio": 1.7804878048780488, "no_speech_prob": 0.0034829771611839533}, {"id": 174, "seek": 92416, "start": 934.3199999999999, "end": 937.36, "text": " which is another word for functionalism, which says the hardware doesn't matter,", "tokens": [50872, 597, 307, 1071, 1349, 337, 11745, 1434, 11, 597, 1619, 264, 8837, 1177, 380, 1871, 11, 51024], "temperature": 0.0, "avg_logprob": -0.08792317267691735, "compression_ratio": 1.7804878048780488, "no_speech_prob": 0.0034829771611839533}, {"id": 175, "seek": 92416, "start": 937.92, "end": 943.12, "text": " because the idea of where a simulation is some computer in the future is basically", "tokens": [51052, 570, 264, 1558, 295, 689, 257, 16575, 307, 512, 3820, 294, 264, 2027, 307, 1936, 51312], "temperature": 0.0, "avg_logprob": -0.08792317267691735, "compression_ratio": 1.7804878048780488, "no_speech_prob": 0.0034829771611839533}, {"id": 176, "seek": 92416, "start": 943.12, "end": 947.92, "text": " simulating our thoughts now. Well, that assumes that a computer can simulate all our thoughts,", "tokens": [51312, 1034, 12162, 527, 4598, 586, 13, 1042, 11, 300, 37808, 300, 257, 3820, 393, 27817, 439, 527, 4598, 11, 51552], "temperature": 0.0, "avg_logprob": -0.08792317267691735, "compression_ratio": 1.7804878048780488, "no_speech_prob": 0.0034829771611839533}, {"id": 177, "seek": 94792, "start": 947.92, "end": 953.8399999999999, "text": " which assumes functionalism or some straight independence, independence, which I think is", "tokens": [50364, 597, 37808, 11745, 1434, 420, 512, 2997, 14640, 11, 14640, 11, 597, 286, 519, 307, 50660], "temperature": 0.0, "avg_logprob": -0.15281188601539247, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.1007966548204422}, {"id": 178, "seek": 94792, "start": 953.8399999999999, "end": 959.12, "text": " wrong. And I've actually just published a paper in Philosophy of Science two years ago that gives", "tokens": [50660, 2085, 13, 400, 286, 600, 767, 445, 6572, 257, 3035, 294, 43655, 295, 8976, 732, 924, 2057, 300, 2709, 50924], "temperature": 0.0, "avg_logprob": -0.15281188601539247, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.1007966548204422}, {"id": 179, "seek": 94792, "start": 959.12, "end": 963.28, "text": " a whole bunch of arguments based on energy about why it's wrong. But there are other reasons as", "tokens": [50924, 257, 1379, 3840, 295, 12869, 2361, 322, 2281, 466, 983, 309, 311, 2085, 13, 583, 456, 366, 661, 4112, 382, 51132], "temperature": 0.0, "avg_logprob": -0.15281188601539247, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.1007966548204422}, {"id": 180, "seek": 94792, "start": 963.28, "end": 970.4799999999999, "text": " well for thinking that functionalism or substrate independence is wrong. Okay, that's enough.", "tokens": [51132, 731, 337, 1953, 300, 11745, 1434, 420, 27585, 14640, 307, 2085, 13, 1033, 11, 300, 311, 1547, 13, 51492], "temperature": 0.0, "avg_logprob": -0.15281188601539247, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.1007966548204422}, {"id": 181, "seek": 94792, "start": 971.4399999999999, "end": 975.1999999999999, "text": " That's really fun. But go ahead. I didn't mean to interrupt you there, but please.", "tokens": [51540, 663, 311, 534, 1019, 13, 583, 352, 2286, 13, 286, 994, 380, 914, 281, 12729, 291, 456, 11, 457, 1767, 13, 51728], "temperature": 0.0, "avg_logprob": -0.15281188601539247, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.1007966548204422}, {"id": 182, "seek": 97520, "start": 975.2, "end": 979.6800000000001, "text": " I just wanted to summarize. So it was a great idea in the Philosophy of Mind", "tokens": [50364, 286, 445, 1415, 281, 20858, 13, 407, 309, 390, 257, 869, 1558, 294, 264, 43655, 295, 13719, 50588], "temperature": 0.0, "avg_logprob": -0.10688657306489491, "compression_ratio": 1.6178571428571429, "no_speech_prob": 0.03620611131191254}, {"id": 183, "seek": 97520, "start": 979.6800000000001, "end": 984.08, "text": " that no longer should be taken very seriously, given what we know about brains and energy.", "tokens": [50588, 300, 572, 2854, 820, 312, 2726, 588, 6638, 11, 2212, 437, 321, 458, 466, 15442, 293, 2281, 13, 50808], "temperature": 0.0, "avg_logprob": -0.10688657306489491, "compression_ratio": 1.6178571428571429, "no_speech_prob": 0.03620611131191254}, {"id": 184, "seek": 97520, "start": 985.5200000000001, "end": 992.72, "text": " So even look at the way AI is going right now. So the generative AI models, the large language", "tokens": [50880, 407, 754, 574, 412, 264, 636, 7318, 307, 516, 558, 586, 13, 407, 264, 1337, 1166, 7318, 5245, 11, 264, 2416, 2856, 51240], "temperature": 0.0, "avg_logprob": -0.10688657306489491, "compression_ratio": 1.6178571428571429, "no_speech_prob": 0.03620611131191254}, {"id": 185, "seek": 97520, "start": 992.72, "end": 997.76, "text": " models are incredible, but they're really energy pigs. It takes vast amounts of energy to train", "tokens": [51240, 5245, 366, 4651, 11, 457, 436, 434, 534, 2281, 24380, 13, 467, 2516, 8369, 11663, 295, 2281, 281, 3847, 51492], "temperature": 0.0, "avg_logprob": -0.10688657306489491, "compression_ratio": 1.6178571428571429, "no_speech_prob": 0.03620611131191254}, {"id": 186, "seek": 97520, "start": 997.76, "end": 1004.08, "text": " these things and answer questions. Our brains are astonishing. Our brains work on basically 40", "tokens": [51492, 613, 721, 293, 1867, 1651, 13, 2621, 15442, 366, 35264, 13, 2621, 15442, 589, 322, 1936, 3356, 51808], "temperature": 0.0, "avg_logprob": -0.10688657306489491, "compression_ratio": 1.6178571428571429, "no_speech_prob": 0.03620611131191254}, {"id": 187, "seek": 100408, "start": 1004.1600000000001, "end": 1009.5200000000001, "text": " watts, like a small light bulb, very small amounts of energy, very efficient, and yet we're still", "tokens": [50368, 31247, 11, 411, 257, 1359, 1442, 21122, 11, 588, 1359, 11663, 295, 2281, 11, 588, 7148, 11, 293, 1939, 321, 434, 920, 50636], "temperature": 0.0, "avg_logprob": -0.11033904110943829, "compression_ratio": 1.6506849315068493, "no_speech_prob": 0.0006262839888222516}, {"id": 188, "seek": 100408, "start": 1009.5200000000001, "end": 1016.0, "text": " smarter than any computer with all these resources. So there's a full field called neuromorphic AI,", "tokens": [50636, 20294, 813, 604, 3820, 365, 439, 613, 3593, 13, 407, 456, 311, 257, 1577, 2519, 1219, 12087, 32702, 299, 7318, 11, 50960], "temperature": 0.0, "avg_logprob": -0.11033904110943829, "compression_ratio": 1.6506849315068493, "no_speech_prob": 0.0006262839888222516}, {"id": 189, "seek": 100408, "start": 1016.0, "end": 1020.4000000000001, "text": " which is trying to make computers more like the brain to get these advantages of energy and", "tokens": [50960, 597, 307, 1382, 281, 652, 10807, 544, 411, 264, 3567, 281, 483, 613, 14906, 295, 2281, 293, 51180], "temperature": 0.0, "avg_logprob": -0.11033904110943829, "compression_ratio": 1.6506849315068493, "no_speech_prob": 0.0006262839888222516}, {"id": 190, "seek": 100408, "start": 1020.4000000000001, "end": 1027.52, "text": " efficiency and working in real time. So I think these are really interesting research areas that", "tokens": [51180, 10493, 293, 1364, 294, 957, 565, 13, 407, 286, 519, 613, 366, 534, 1880, 2132, 3179, 300, 51536], "temperature": 0.0, "avg_logprob": -0.11033904110943829, "compression_ratio": 1.6506849315068493, "no_speech_prob": 0.0006262839888222516}, {"id": 191, "seek": 100408, "start": 1027.52, "end": 1033.68, "text": " show that functionalism just wasn't it is no longer a plausible view in the Philosophy of Mind.", "tokens": [51536, 855, 300, 11745, 1434, 445, 2067, 380, 309, 307, 572, 2854, 257, 39925, 1910, 294, 264, 43655, 295, 13719, 13, 51844], "temperature": 0.0, "avg_logprob": -0.11033904110943829, "compression_ratio": 1.6506849315068493, "no_speech_prob": 0.0006262839888222516}, {"id": 192, "seek": 103408, "start": 1034.56, "end": 1038.56, "text": " Now that's an astute point, Professor, because I was, well, two points on there. Firstly, I always", "tokens": [50388, 823, 300, 311, 364, 5357, 1169, 935, 11, 8419, 11, 570, 286, 390, 11, 731, 11, 732, 2793, 322, 456, 13, 20042, 11, 286, 1009, 50588], "temperature": 0.0, "avg_logprob": -0.16925118764241537, "compression_ratio": 1.5662251655629138, "no_speech_prob": 0.0009395350352860987}, {"id": 193, "seek": 103408, "start": 1038.56, "end": 1044.24, "text": " found functionalists to be good old Cartesian's where they had the mind, the mind matter. They", "tokens": [50588, 1352, 11745, 1751, 281, 312, 665, 1331, 22478, 42434, 311, 689, 436, 632, 264, 1575, 11, 264, 1575, 1871, 13, 814, 50872], "temperature": 0.0, "avg_logprob": -0.16925118764241537, "compression_ratio": 1.5662251655629138, "no_speech_prob": 0.0009395350352860987}, {"id": 194, "seek": 103408, "start": 1044.24, "end": 1048.8799999999999, "text": " think mind is independent to matter, which for me never made any sense, given we have physical", "tokens": [50872, 519, 1575, 307, 6695, 281, 1871, 11, 597, 337, 385, 1128, 1027, 604, 2020, 11, 2212, 321, 362, 4001, 51104], "temperature": 0.0, "avg_logprob": -0.16925118764241537, "compression_ratio": 1.5662251655629138, "no_speech_prob": 0.0009395350352860987}, {"id": 195, "seek": 103408, "start": 1048.8799999999999, "end": 1055.9199999999998, "text": " embodied beings. And secondly, you are 100% right that I was listened to a talk by Scott", "tokens": [51104, 42046, 8958, 13, 400, 26246, 11, 291, 366, 2319, 4, 558, 300, 286, 390, 13207, 281, 257, 751, 538, 6659, 51456], "temperature": 0.0, "avg_logprob": -0.16925118764241537, "compression_ratio": 1.5662251655629138, "no_speech_prob": 0.0009395350352860987}, {"id": 196, "seek": 103408, "start": 1055.9199999999998, "end": 1061.52, "text": " Aronson, the American computer scientist, and he is now a researcher at Open AI. And Open AI is", "tokens": [51456, 1587, 892, 266, 11, 264, 2665, 3820, 12662, 11, 293, 415, 307, 586, 257, 21751, 412, 7238, 7318, 13, 400, 7238, 7318, 307, 51736], "temperature": 0.0, "avg_logprob": -0.16925118764241537, "compression_ratio": 1.5662251655629138, "no_speech_prob": 0.0009395350352860987}, {"id": 197, "seek": 106152, "start": 1061.52, "end": 1068.48, "text": " heavily investing in quantum computing and even in nuclear energy, because they've understood", "tokens": [50364, 10950, 10978, 294, 13018, 15866, 293, 754, 294, 8179, 2281, 11, 570, 436, 600, 7320, 50712], "temperature": 0.0, "avg_logprob": -0.13666031326072803, "compression_ratio": 1.6166666666666667, "no_speech_prob": 0.03724789246916771}, {"id": 198, "seek": 106152, "start": 1068.48, "end": 1075.28, "text": " that if they are to grow their LLMs, they need infinite amounts of energy, because the compute", "tokens": [50712, 300, 498, 436, 366, 281, 1852, 641, 441, 43, 26386, 11, 436, 643, 13785, 11663, 295, 2281, 11, 570, 264, 14722, 51052], "temperature": 0.0, "avg_logprob": -0.13666031326072803, "compression_ratio": 1.6166666666666667, "no_speech_prob": 0.03724789246916771}, {"id": 199, "seek": 106152, "start": 1075.28, "end": 1082.8799999999999, "text": " power for LLMs are so, they're so high compared to like our puny little brains, which is a fascinating", "tokens": [51052, 1347, 337, 441, 43, 26386, 366, 370, 11, 436, 434, 370, 1090, 5347, 281, 411, 527, 4468, 88, 707, 15442, 11, 597, 307, 257, 10343, 51432], "temperature": 0.0, "avg_logprob": -0.13666031326072803, "compression_ratio": 1.6166666666666667, "no_speech_prob": 0.03724789246916771}, {"id": 200, "seek": 108288, "start": 1082.88, "end": 1084.88, "text": " conversation.", "tokens": [50364, 3761, 13, 50464], "temperature": 0.0, "avg_logprob": -0.7702869892120361, "compression_ratio": 0.6190476190476191, "no_speech_prob": 0.7771480083465576}], "language": "en"}