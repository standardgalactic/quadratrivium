start	end	text
0	8120	All right. Hello everyone. Welcome to AME HQ. For those who I haven't met, my name is
8120	12480	Cam Linky. I'm the CEO here at AME and we're pleased to welcome everybody today,
12480	17680	both to our office here and to our friends who've tuned in online on the
17680	22680	live stream. Many of you probably know about AME, but for those who don't, AME is one
22680	26800	of Canada's three national standards of artificial intelligence. We're tasked
27120	31600	with advancing Canada's AI potential and we're proud to collaborate with the
31600	38160	University of Alberta on driving AME's AI research excellence forward. We're
38160	41840	really, really excited to have everyone here today for this special
41840	46200	announcement from our Chief Scientific Advisor, Rich Sutton. Before we get
46200	50480	started, we'd like to respectfully acknowledge that we're on Treaty Six
50480	54640	Territory, a traditional gathering place for the diverse Indigenous peoples,
55040	62320	including the Cree, Blackfoot, MÃ©tis, Nakoda Sioux, Haudenosaunee, Dene, Ojibwe,
62320	68560	Sotu, Anishinaabe, Inuit, and many other peoples whose histories, languages, and
68560	74480	cultures continue to influence our vibrant community. And it's in the spirit of
74480	78880	that exchange of knowledge and of that gathering that we're excited to welcome
78880	83840	everyone here today. AME, we're really excited to support our friend and mentor,
83840	87680	Rich Sutton. There's so much that could be said about Rich and the pioneering
87680	92000	work that he's done in reinforcement learning and AI. The span of Rich's
92000	96560	impact is almost hard to enumerate from his dedication to fundamental research
96560	101680	and the advancement of the science of AI to his efforts to train the next
101680	106720	generation of AI researchers. His book, Reinforcement Learning and Introduction,
106720	112000	has both educated and inspired scores of graduate students and beyond, and is one
112000	118160	of the most approachable people in the field, always having time for researchers,
118160	124240	for curious observers, and for everyone in between to sit down, have a discussion,
124240	128320	discuss reinforcement learning, discuss artificial intelligence. He's one of the
128320	133600	people that, while many people have already left either the party or the conference,
133600	136800	Rich will be in the corner somewhere having a conversation with someone about
137520	143280	reinforcement learning, about some nuance of the field, and one of the things we talk
143280	149040	about here a lot at AME is approachability, and that approachability is something that we've
149040	155280	really been inspired by Rich from. Speaking of pioneers, the guest I'd like to invite up with
155280	160080	Rich has trailblazed multiple fields. Among his list of pioneering accomplishments are
160080	166480	co-founding id software, and his leading work there in computer graphics and computer gaming created
166480	171600	an entire genre of gaming. Since then, John's also known for his work in rocketry,
171600	177600	and ushering in a modern era of virtual reality with Oculus Rift. So we're so excited to have
177600	183600	them both here at AME HQ, and everyone please join me in welcoming John Carmack and Rich Sutton to the
183600	205760	stage. Thank you so much, Cam. It's a delight to speak to you all this afternoon. Today I am
205760	211840	pleased to announce the formation of a partnership between John Carmack and myself to work directly
211840	216000	towards the challenge of understanding and creating an artificial general intelligence
217040	221760	based on reinforcement learning and neural networks. The partnership will be embodied
221760	228320	within Keen Technologies, which is a startup that John created about a year ago. And as of today,
228320	233680	I am an employee of that company. Of course, I will continue as Professor at the University of Alberta,
233680	240080	and as the Chief Scientific Advisor at AME, the Alberta Machine Intelligence Institute that you're
241040	248160	all here at. So I'm very excited to be partnering with John. John is the world's preeminent developer
248160	253680	of complex high-performance real-time systems. His skill and brilliance was first demonstrated
254320	260880	in technical innovations in 2D and 3D graphics in computer games such as Doom and Quake. His
260880	267920	engineering skills were honed on rockets at Armadillo Aerospace and by his work on immersive
267920	276240	virtual reality at Oculus. Roughly five years ago, John became, you know, he turned to the
276240	283120	challenge of artificial general intelligence and that eventually led to Keen. Now, when I first
283120	289840	learned about John and Keen earlier this year, I was struck by how aligned we were, I was with him,
290480	296960	despite, you know, my having done this all my life and John just turning to it a few years ago,
297920	302960	there are many aspects to the way we are so strongly aligned, but let me identify just four of them.
303600	308960	We both strongly felt that the field of artificial general intelligence was dominated by
308960	314880	too narrow a set of ideas. This was groupthink and this groupthink was to be avoided. We both
315520	322400	strongly felt that trying to make money too soon was like an off-ramp on the road to AGI,
322400	327760	and we need to keep our eyes on the long-term prize of full AGI, eyes on the prize.
329360	335440	And number three, artificial general intelligence is not too complex for one person to understand
335440	343120	the principles of it or even to write the code for it. That's that as an important part of our
343120	352320	alignment. And finally, 2030 is a good target to have a success, to have a prototype AGI,
352960	360480	to show signs of life. We're a toddler, as John likes to say. So John and I are really well aligned,
361360	370960	and, but there's a sort of an elephant in the room and it's become clear. Keen is a small team,
370960	381360	the entire technical team of Keen Technologies is here today, and it's John and me and Gloria and
381360	387920	Lucas, if you could stand up, and also Joseph, who's we expect to join us by the end of the year,
388880	397840	and now they're all these Keen people are now part of our community. And could you all give
397840	416400	them a good Alberta applause? Thank you for that. So the elephant in the room is it this is a small
416400	425680	team and other companies have thousands of technical staff and are spending billions of dollars on
425680	431040	AGI. It's truly audacious of us to think that we can make a contribution.
433920	441440	But there are actually it's audacious of us to think we can compete with them. And we think we
441440	447120	can or at least we can make a contribution. There's much to say about why that might be
447120	452160	reasonable to think and I'm going to refrain from trying to explain it. But I will only remind you
452160	458960	of what Margaret Mead said. She said, never doubt that a small group of thoughtful committed people
458960	463200	can change the world. Indeed, it is the only thing that ever has.
465440	469760	Now I'd like to turn the floor over to John to say a few words. The legendary John Karnack.
469760	484320	So a couple months ago, I got an email from Richard Sutton. I'm like, well, this is cool.
484320	490480	So I am relatively new to the artificial intelligence field. And when I started kind of my larval
490480	495440	phases, I like to call it where I just inhale all of the relevant information in kind of the first
495440	501200	year. One of the very important references for me was Richard's book on reinforcement learning.
501200	506160	And in fact, I later went through the first half of it again with my son doing exercises
506160	511840	just a couple years ago. And of course, I reference the bitter lesson all the time as one of the
511840	516240	deep fundamental insights to the kind of broader effort of everything that goes on here.
516800	522800	So I'm Richard was trying to figure out I'm kind of like how he should be pursuing his efforts
522800	527360	towards research across different options in commercial, academic and nonprofit.
527360	532880	And I wanted to be super helpful. I hooked him up with a few other people and I tried to kind of
532880	538480	give him whatever help that I could. But I did very tentatively kind of broach the subject that,
538480	542800	all right, you're the godfather of reinforcement learning, you can write your own ticket anywhere
542800	548480	you want to go work. But there are some downsides to especially larger established organizations.
549040	554960	And you may get access to lots of resources and still have the freedom to do whatever you want.
554960	562000	But there are problems with culture and direction, kind of strategic direction in other areas.
562000	568240	It's why as fired as I was when OpenAI tried to recruit me, I respect all that they do,
568240	572640	but they've got their plan, they've got their directions, it's not really what I'm doing.
573360	579200	And there began a little process of kind of feeling out, well, exactly how do you feel about
579200	583760	certain of these directions? Like, what are the odds of technologies going this way? How
583760	590240	important is this? How important is that? And it turned out that we really did have a remarkable
590240	595280	amount of overlap in what we think is possible, what we think the remaining challenges are.
596000	603280	And to be clear, nobody has line of sight on the solution to this today, but we feel,
603280	610000	and I am a number of other people, that it's not that much left. There are things we don't know,
610000	614800	we don't know how to get there, but they all feel like the same scope of things that mattered in
614800	619920	this last decade. They're relatively simple things in the way that you set up your architectures,
619920	625200	the way you do your training, the way you query it in different ways. And I certainly think that
625280	630080	in 30 years, when the textbook of artificial general intelligence is written, it's going
630080	635040	to get digested down to a chapter that people are going to be able to understand. We just need
635040	642480	to figure out what those sort of core ideas are. So it was really still to my great surprise,
642480	647840	but immense pleasure, that we have decided to go ahead and work on this together. So
647840	653920	Richard is working at Keen Technologies now, he's in our workplace, and we spent all day today
653920	658640	basically talking about the plan of research, how we want to start figuring out what we're going
658640	664640	to be doing. So this is incredibly exciting for me. And would you like to say anything else Richard?
675600	679600	Thank you, John. I think now we'd like to take questions from the media.
684400	691120	So we're going to open up the floor for any media questions. For the media in the room,
691120	697360	if you have a question, please come over here. And for media on the line. So operator, please open
697360	713040	up the line for the first question. Oh, there's no media on the phone.
713680	723040	Any media questions from the room? Oh, hi, I'm Renali Unchin with CBC Edmonton.
723040	727680	So following this partnership, I'm wondering if you could talk about some of the tangible steps
727680	735120	that are going to be taken to kind of develop AGI more. So one of the big points that we do have
735120	740480	alignment on is that there's not a near term offer answer where there's not going to be a chat
740480	746320	gbt like deliverable that goes out and allows the world where there are fundamental research
746320	752240	questions that need to be answered. And this is me learning how to be a researcher and hopefully
752240	759120	learning from Richard a lot about that process. But we have internal projects and angles of attack
759120	765040	on things, but they probably will not have a lot of publicly visible effects for likely years.
765360	771520	We are fairly aligned on this sort of we are seven ish six seven eight years out from something
771520	779360	really big and important being publicly visible. Anything? That's perfect. Next question.
780880	784560	Yeah, I have a follow up. So for the average person, obviously, there was a lot of terminology
784560	789760	thrown around. Why should the average person care about this if you can describe in the most simple
789760	794560	terms? Well, I would say the average person probably shouldn't care a whole lot about this,
794640	799200	you know, I mean, this is something this is inside baseball work for people that are
799200	804000	in the field. I am, you know, a lot of people are going to be geeking out about this where,
804000	809520	you know, rich is a big, big name, big percentage, and I'm a big name in a very different field.
809520	813840	And we're kind of coming together. And I do think there's synergistic benefits for that.
813840	818800	And it's kind of exciting just as a, you know, two great taste, taste great together sort of
818800	824800	mix things up. I am between the, you know, different backgrounds, but I know, I mean,
824800	829040	I don't want us to try to make this out to be something that the man in the street should
829040	834880	actually care about. It may yet lead to one of the most important things in the world or in history,
834880	840480	but I there's very little guarantees about any of that. And that's the benefit of the way we're
840480	845200	financed in the way we're structured right now. We don't have to have a rush to a product. We don't
845200	850160	have to have a rush to make sure that there's an investor return in a very short amount of time.
850160	854000	We can concentrate on just trying to answer these critical important questions.
855120	859280	Okay. Cool. Great. Any other questions?
862480	870080	Fantastic. That concludes the Q&A portion of the program. Oh, yes, Rich. If we're done,
870080	878400	I have a few things I want to say. Please. Before we close, I want to thank Amy and the
878400	882800	University of Alberta for their help today, particularly Stephanie Enders and Laura Carter
882800	890560	and Cam and Linda Vang, express my appreciation for the entire Edmonton and Alberta community
890560	896000	for all they do in creating the rich intellectual environment in which I and this part of Keen
896000	902160	can thrive. The community has supported fundamental research in AI for 30 years
903360	909760	before I came here. And this is bearing fruit now in Amy and in industry and startup companies and
909760	915200	more fundamental research results. Please join me in a huge round of applause for Amy and for
915200	930800	yourselves, the entire AI community. And with that, I want to turn the floor over to someone else.
932960	938640	Cam, there you are. All right. Well, thanks everyone. How about one big round of applause
938720	951040	for Rich and John again. So thank you everyone for joining us today. That concludes the program
951040	956160	for the announcement. We're going to reset the room for the fireside chat. So if everyone can do
956160	961440	us a favor, I know this is a pain, but we need you to all leave the room, continue the conversation.
961440	967440	Everybody can have their favorite conversation about what took place here today. Head over to
967440	971920	the co-working space in the cafe. We have food and drinks and caffeine to really amp you up for
971920	977600	this next portion. If you've RSVP'd for the fireside chat, we'll we'll readmit you shortly.
977600	982320	So please do us a favor, move over there to our beautiful space and we'll see you back here shortly.
982320	995600	Thanks. All right. Okay, we're going. Welcome to the second half of the show. If you can do us a
995600	1001120	favor, if you're on the edge of the roll, please squeeze into the middle. That will help as stragglers
1001120	1006080	come in, not doing this, excuse me, pardon me, excuse me, pardon me, and distracting the speakers,
1006080	1011280	so or just me. So do me a favor, squeeze into the middle, help us out. Thank you very much.
1012000	1018720	Get close, get to know your neighbor. Welcome back for those who missed the earlier part of this.
1018720	1024880	I'm Cam Linky, I'm the CEO here at Amy. We're excited to welcome back to the second part of our
1024880	1032000	doubleheader with a special fireside chat. So our host for the night is well known for his hate of
1032000	1039200	love of games, love of games. Yes, loves games. An Amy fellow, Canada CIFAR AI chair and full
1039200	1044880	professor at the University of Alberta. Mike is best known for his work in poker, most notably
1044880	1052080	solving the game of heads up, no limit, Texas hold them in 2015. And for deep stack in 2016,
1052080	1057280	the first AI to be human professionals at heads up, no limit, Texas hold them. I think I made an
1057280	1064320	error in there that Mike's going to correct. He's glaring at me. We're so excited for Mike to be our
1064320	1069280	host and to host our special guests tonight. And so I don't make any more errors. Please welcome
1069280	1077200	Mike Bowling to the stage. Thank you very much, Cam. I'm sorry, I do have to correct you. So we
1077280	1082960	did essentially solve heads up limit. And we beat the first to be professional players,
1082960	1088480	heads up no limit. Okay, but you're not here for that. I get to have the great honor of introducing
1088480	1093200	John Carmack. Many people have already said wonderful words about him, but maybe you weren't
1093200	1100480	here for that. I'll just say that he's a pretty big deal, maybe a BFD, if you will. But I'll just say
1100480	1108560	my first connection to John was probably my first memory of seeing something really innovative
1108560	1112560	was thanks to John. Because if you're really young, you can't see innovation. Everything is new.
1112560	1117680	So you didn't know what came before. So you don't know this change things. And when I was 17, I went
1117680	1121920	to a gaming convention and they're sitting was a rows of computers. This wasn't even a video game
1121920	1126320	convention. It was board games and real playing games. And they're sitting was a rows of computers
1126320	1132320	with Wolfenstein 3D running on them in the summer of 1992. And my mind was blown. So thank you,
1132320	1143840	John Carmack, and welcome to stage. Welcome, John. Thank you.
1143840	1153360	Oh, I'm supposed to push the button.
1155280	1161760	Okay. Yeah, when I was asked to do this, I was trying to think through. I felt like I had a lot
1161760	1166880	of pressure on me to ask you really insightful questions for the audience. But I decided I'm
1166880	1170640	going to kind of almost ignore the audience. I'm just going to ask you questions. I feel like I
1170640	1175360	want to ask you totally selfishly. And I'm going to hope because I have a love of games,
1176480	1180960	you know, I have a love of innovation, and I have a love for AI that maybe these are the
1180960	1186240	questions that the audience wants to hear too. But so I want to walk you back to the beginnings
1186240	1193520	of id and Wolfenstein 3D. And maybe you can say some words about how did you even end up
1194080	1197280	at that place? And then I want to turn around and talk a bit more about innovation from there.
1198240	1203840	Yeah, so it did. Games were super important for me in my childhood. You know, I love the
1203840	1209840	arcade games. I love the early 8-bit video games and the tabletop games, all of that. And so it
1209840	1215280	did seem obvious to me that this love of computers that I had that the best way to express it was
1215280	1220320	through games. Now, it is important to kind of differentiate a little bit there where there
1220320	1225200	are a lot of people that go into gaming and they learn about computers so they can make games.
1225280	1231120	And it was a little more fortuitous for me because I had this intrinsic love of computers as well.
1231120	1236560	And I probably could have been happy and found interest in doing more mundane things. But the
1236560	1241520	games were there. They were the obvious place and it turned out to work, you know, really well for
1241520	1245840	me. And so I had been, you know, for the first time I could do anything on a computer. I was
1245840	1250080	trying to write games. I was trying to, you know, at first mimic some of the other games that I
1250080	1255440	would see. The first, the early text adventure games, writing my dungeon crawlers, you know,
1255440	1261040	kind of inspired by wizardry and Ultima and the early things like that. But as I got to be a teenager
1261040	1266000	and I built the assembly language skills and started figuring out how to do the sort of the
1266000	1272400	real world things and I had a talent for it. I got good at it and I had decided that I wanted to
1272400	1277280	actually try to make a living making games. And there was, you know, there was a lean year there
1277280	1282880	of barely scraping by doing contract programming work before I accepted the position to come down
1282880	1289120	and work at soft disk publishing where I met the other founders of id software. And we started out
1289120	1294320	making our initial side scroller games, which was Commander Keen, which I have kind of harkened
1294320	1300720	back to with the name of my latest company with Keen Technologies. But then we, you know, we really
1300720	1307200	broke out and kind of made our name with the 3D games. And I always did kind of look at that as
1307520	1312800	it wasn't the games were the same things that you could do in 2D, but the change in perspective
1312800	1320000	of going to 3D, it made a qualitative difference, even if sort of symbolically it was the same game,
1320000	1324880	but it made a great difference in the impact it had on people. Tell me more about that that jump
1324880	1328720	to 3D. Was that was that intentional where you like I could think of so many ways this could
1328720	1332080	have gone where you could have just been like that seems like a hard challenging computer's
1332080	1336880	problem. And so I'm going to solve that versus feeling like this is the future of games. So we
1336880	1340800	need to innovate in that front versus not even realizing maybe that you were being innovative.
1340800	1346240	Like how did that work? No, I knew I was heading for that from the early 80s. I am, you know, as a
1346240	1351360	you know, even as a young teenager, you would see the representations of 3D graphics or in the movie
1351360	1357520	and you think about you see Tron or you see 3D animated logos. I can remember making a little
1357520	1363360	wireframe MTV logo spin around on my Apple to kind of figuring out these basics and looking back,
1363360	1366800	like I didn't know how to do clipping at the time so nothing can get close to the edge of the
1366880	1372560	screen. It just has to stay in the center and rotate around. But that idea of wanting to be
1372560	1377760	inside the video game, I mean, everybody that's a gamer kind of got that sense of you want,
1377760	1382000	you look at the game, you play the game, you appreciate it, but how amazing would it be to
1382000	1386960	put yourself inside it and then, you know, see the enemies coming at you rather than looking
1386960	1393600	down at it as that 16 by 16 block of pixels. And that was magical. And you could take exactly the
1393600	1399760	same game and put the user inside it and that really followed on even more with virtual reality
1399760	1404320	later on where getting the sense of presence where you kind of believe that you're in this
1404320	1410400	other environment. So that was always a big issue for me, but I do, you know, it is important to
1410400	1415520	say that that's kind of the obvious visible thing that stands out that there was a time period where
1415520	1421280	there was nothing else like that, but there are a thousand good decisions that go into making a game
1421280	1427920	and it was never about just the technology. It was about doing those thousand things right.
1427920	1433600	All the subtleties about how you feel, how you move, how the guns react, what the sound effect is,
1433600	1438800	there's 10 things you layer on top of every action that happens in a game to wind up giving
1438800	1443440	it this really good feel. And most of them will be things that people don't even notice. I mean,
1443440	1449040	everybody points to Oh my God, this 3d black magic that was going on that that left people,
1449600	1453040	you know, just wondering how they could compete with something like that until
1453040	1458480	you know, engine technologies got out there. But there were plenty of other now forgotten games
1458480	1463600	that wound up having flashy 3d graphics, but people don't remember them because they didn't
1463600	1468160	do all the other things, right? I mean, I definitely remember the just smoothness of the
1468160	1472000	original it games were just, I think just blew people away. Like it felt like you could play them
1472000	1476640	as opposed to being pulled out of the immersion from the clunkiness. But that's also innovative
1476640	1481520	technology too, right? That's some of the things that were actually subtle that were really important
1481520	1486960	to me. And nobody actually called these out. But in terms of the graphics, the way they were
1486960	1493360	rendered, there were a lot of 3d games that had this kind of non solid feel to it, where there
1493360	1498720	are these subtle things that happen to do with pixel centers and avoiding cracks between polygons.
1498720	1503360	And you can still make great games for that. Like the entire PlayStation one, I am, you know,
1503360	1509440	set of titles was all done with this integer snapped affine interpolated rendering technology.
1509440	1514640	You can do good things with that. But I always took pride in the solidity, the kind of sense that
1514640	1519760	everything was really rock solid there, where some games felt fragile, like, you know, you bump the
1519760	1523840	wrong way and you're going to slide through the wall, get caught and see a flickering mess of
1523840	1529520	stuff. And for the most part, I, we took great pains to make that not happen in ours.
1529520	1532960	That's awesome. Is there anything else that like you think like this was the innovative part,
1533040	1537280	but in the, you know, decades later, no one remembers that being the innovation?
1537280	1543120	Well, what was great is we had this period of like this five year period during the development
1543120	1549440	going from Wolfenstein 3d to doom to quake. And there were so many things that wound up setting
1549440	1556080	the tone for gaming for the following 30 something years. And things like the multiplayer gaming,
1556080	1561600	the modding, these were not the flashy 3d graphics technology. But they, you know, they were things
1561600	1566800	that were super valuable. And it was happy to see people, you know, follow up on it, even little
1566800	1571600	things like having a console, you know, having the, you know, the override ability for the different
1571600	1576720	data sets. There were a lot of decisions like that, that, you know, that worked out pretty well.
1576720	1582000	And I could imagine a world where 3d graphics was inevitable. It was being done on higher end
1582000	1588880	systems, offline rendering. But it is possible to imagine a contingent set of history where
1588880	1594400	you didn't wind up with this action oriented things because the dominant vision was you do sims,
1594400	1600880	you do flight sims, driving sims, tank sims, you know, destroyer sims. And this idea of this run
1600880	1606240	and gun really fast paced action, twitch reaction that, you know, whipping around the mouse directly
1606240	1611920	at inhuman speeds and all of these things, that might not have happened without id software in
1611920	1617680	the early days. I wonder just like how much that affected the development even get to where we are
1617680	1623440	today in terms of would, you know, we've seen gaming drive technology a lot, right? So would we
1623440	1628160	have GPUs today? Would we be sitting on top of AI on top of Dean learning sitting on top of GPUs
1628160	1632400	today? If we didn't have those initial games saying we could have action oriented, broader,
1632400	1637120	open games. Do you think that's a possibility? So the GPU side of laddering you, but yeah,
1637120	1643120	I mean, I do, you know, it's one of those things where I smile and I'll talk about it a little bit.
1644080	1650800	I do take some satisfaction in the fact that the GPUs were largely built to play the Quake series
1650800	1657040	of games at the beginning. And then you had this great insight from like Jensen at Nvidia saying
1657040	1661840	it's like, well, all these pixel processing things that we're doing, we can do other things with them.
1661840	1667600	And they had a lot of foresight to do the long game investment in CUDA and give us the kind of
1667680	1673680	generalized processing. Because people were doing general processing before that in this horrible
1673680	1678800	way. You'd paint, you'd encode your values into pixels, you draw a giant triangle that covers
1678800	1684400	the screen to do an array processing action on there. And it was, you know, it was effective a
1684400	1690960	little bit, but it was awful. But the evolution of GPUs to where they are today as this quite
1690960	1696080	general purpose device that does underpin all of the modern era of artificial intelligence.
1696720	1702000	It's nice to, even if I wound up not working in artificial intelligence, it would be something
1702000	1706880	that I'm proud of that I at least contributed at some point to that evolution. I have one more
1706880	1711360	question of curiosity from this time that relates to Wolfenstein itself. So I played
1711360	1717520	the original Wolfenstein games and Beyond Wolfenstein and love them. How did it, how did this,
1717520	1722080	like, did you have that IP in mind and then we're designing a game for it? Did you, did you,
1722720	1727120	you know, have the game first? Like, what was the order of events and, and how did that come
1727120	1732320	back? So all of us at Id, I am, you know, John, Tom, Jay and I, I, we were all Apple II background
1732320	1738240	people. So we all had this background with the original Escape from Castle Wolfenstein. And it
1738240	1742480	was a game that had these, it was more what you today would think of as a stealth game. You would
1742480	1748000	sneak around, you'd wear guards uniforms, you'd drag the bodies out of the way. But it still did
1748000	1754640	have that sense of shooting Nazis. And I, we had originally thought we were going to do some alien
1754640	1759520	based game, you're calling it it's green and pissed, just kind of a generic alien shooter. I, this
1759520	1765520	was following up off of our kind of fantasy themed Catacombs 3D. But when the idea came up that's
1765520	1770880	like, well, what if we did Wolfenstein 3D? I am, you know, all the good memories for us. It was
1770880	1776640	playing the nostalgia card even for us at that time, some 15 years after the that was initially
1776640	1784560	released. And back at that time, I look back and kind of cringe at, like our business practices at
1784560	1790160	the time, we did not sort this out very well. We kind of just charged ahead and looked around a
1790160	1795920	little bit thinking, well, maybe the rights are clear, these companies seem bankrupt. We eventually
1795920	1802080	ran into Silas Warner, the original author at an Apple II convention. And he was, you know, he
1802080	1806160	was delighted to see Wolfenstein something. Of course, he didn't own the rights. His blessing
1806160	1811760	didn't actually mean anything from a legal term. But to us, it felt good to have the original creator
1811760	1817120	kind of bless our effort and what we were doing there. And in the end, we got out of it unscathed.
1817120	1824480	But that was luck involved, I think. Awesome. Also, in the early times, I feel like it formed
1824480	1828400	another aspect of your career, which is your proponent for open source software,
1829200	1832800	both in distribution models of how software is distributed. We're pretty original in those
1832800	1837760	early games. I'm wondering what, well, yeah, what's your trajectory through that? What's your
1837760	1843840	thoughts about open source, say, then and now, and what connections are between them?
1843840	1848640	So probably the most formative book of my teenage years was Stephen Levy's book,
1848640	1854880	Hackers, Heroes of the Computer Revolution. And, you know, I read it dog-eared and it had
1854880	1860160	these major themes about the hacker ethic and the kind of sharing of information and
1860160	1865680	communal use of code in different ways. And this was before, you know, open source became what it
1865680	1870960	is today or even before the Free Software Foundation kind of had their mission. And I, you know,
1870960	1877760	coined the term. So that was, you know, that was pretty deeply in me early on. And it was fortunate
1877760	1884400	that John Romero, my kind of co-programmer, had similar feelings about it, that this idea that
1884400	1889520	it's just amazingly cool to be able to share the program to make it possible, where we had these
1889520	1893600	memories of hacking the games, like you'd get Ultima, you'd get your Sector Editor out, you'd
1893600	1901520	find out, oh, that's my gold, I want 9999 in there. And I always, I mean, I remember fervently wishing
1901520	1905840	that I could look at the source code for these things to be able to go, these games that I
1905840	1912080	adored that I spent a lot of time on, I wanted to see exactly how they were made. And to get into
1912080	1918320	a position as a small private company, you know, where we owned all of our own IP, the ability to
1918320	1923680	kind of make that earlier childhood wish that I had had come true for a whole new generation of
1923680	1930160	programmers was, you know, it was very motivating for me. And it was a drawn out process inside the
1930160	1934720	company, because there's a huge divide generally between the technical and the creative people
1934720	1940720	here, where, I mean, it's not a judgmental side of things, but just the technical people tend to
1940720	1947120	get this sharing more than most of the artists and designers do, where there's a lot more worry
1947120	1953920	about chain of credit and, you know, where the work builds upon other people's work. So it was
1953920	1960480	not fully understood by everyone in the company, but, you know, a little bit of it was, I was able
1960480	1964560	to throw a little bit of my weight around in my position. And I know there was a little bit of
1964560	1968960	hard feelings for a while that I did something that there was thinking was bad for the business.
1968960	1972720	Is this related to the leak of the Quake source code? Or do you think you have a different,
1972880	1978160	no, just the open source in general, where there was this point early on where we had released
1978160	1984320	the tools for Doom and the ability to do all of this. And a product came out called Dezone,
1984320	1990080	which was a CD-ROM just full of hundreds and hundreds of maps. And the people that did that
1990080	1996880	actually made more money than we made on Doom 2, because we did not have a great royalty deal at
1996880	2002400	the time. And, you know, they shoveled that out. And there was some genuine bitterness that that
2002400	2008080	was possible and that to some point, degree, I had enabled that by sharing the tools. But I did
2008080	2013760	feel very good that a decade or more goes on, a couple decades now. And the people,
2014800	2020400	like Kevin Cloud, who is one of the artists on there, had later told me that, no, that really
2020400	2025920	was all for the best, looking back on it. And we are in this almost unique position where Doom
2025920	2029360	will never die. As long as there are processors, Doom will run on them.
2030320	2035040	Right. Do you think there's lessons to take now? And then, like, I feel like the open source
2035040	2040160	community has played a role in the last 10-year development of AI. What do you see the lessons
2040160	2044080	that we should learn in thinking about how that connects to the current innovation?
2044080	2049280	Yeah, I'm still surprised that it doesn't play more of a role in the game industry, where I
2051680	2058080	I'm genuinely surprised that there is not more like full open source development. You see bits
2058080	2063600	of it in the Minecraft mod scene where you have projects up on GitHub. But people that are generally
2063600	2069680	making games, they still feel very protective of their source. And then you had the commercial
2069680	2077440	companies with Unity coming in and making a very powerful product that gets the job done that was
2077440	2083200	better than open source alternatives in many cases. I think Epic does a really grand thing by
2083200	2087040	they have strict licensing terms, but the fact that the source code is all available,
2087040	2092960	that's half the battle. I am pragmatic. I'm not a purist. I'm not going to license snipe somebody
2092960	2099200	about what they're using. Just having the source code available for view is a large chunk of the
2099200	2105360	value. So there's good stuff there. But in the AI space, it's much more open. And I think in the
2105360	2112320	broader sense of where academia has gone, where comparing, I go back and I do read a lot of papers
2112320	2118880	from the 90s and stuff. And it's papers without code, without data, unreproducible. There's a whole
2118880	2125520	lot of things that are just probably are not right. And the path to having the norm, it's still not
2125520	2131520	fully established and there's still pushback about it. But the world is a far, far better place now
2131520	2137120	for the openness that we do have on the pace of artificial intelligence and most other science
2137200	2142880	that I don't even have windows into the fact that code available on GitHub. I ideally data there.
2142880	2147520	We still have too many cases of data available upon request and there's still norms that need
2147520	2152080	to be pushed there because you do still have sensitive people. It's like, oh, if I release this,
2152080	2156400	people will find mistakes. They'll critique my code. They'll, you know, they'll have all of this.
2156400	2161440	And that's still a problem being worked through. But I have no complaints about the state that we're
2161440	2165120	at now and the trajectory that we're on. I think it really is one of the great things for the world
2165120	2170640	today. Cool. I want to have an AI, but before that, let me take your detour through VR for a minute.
2172160	2175600	Tell me what would, did that just feel like a natural extension for you for games or were
2175600	2180240	you thinking something bigger? What was, what was motivating you to move? Yeah, so I had actually
2180240	2186240	tried some VR stuff back in the nineties. We had one of the really old headsets that cost $10,000
2186240	2192480	and was like 320 by 240 resolution screens and pixels the size of small footballs in your peripheral
2192480	2199120	vision. And it was clearly not the right time for something there. And it was interesting where
2199120	2203440	I went and I said, I'm just going to go look at the state of VR because it's been two decades.
2203440	2210880	Surely it's all fixed by now. And I was really surprised to find that even though technically
2210880	2217520	we had good screens, good accelerometers, we had all the things that were seem to be necessary to
2217520	2222640	make this work. But there were still just this handful of government contractors making headsets.
2222640	2228080	They, there were $50,000 headsets in some cases and they still weren't even all that great.
2228720	2234320	And that was one of those points where, you know, you can say that opportunity is the difference
2234320	2238720	between what's possible and what people are actually doing. And it did seem there. It's like
2238720	2244400	from a technical level, these things were now possible. And the early experiments that I did
2244400	2250560	there showed that it can also be really quite compelling. Now there's, there's the obvious
2250560	2254560	play there about, well, you, you make games, it's more immersive. There's the step from
2254560	2259760	looking at a 2D game to looking at a 3D game to being inside a 3D game. And that is, you know,
2259760	2266400	absolutely true. But I do think there's the even more powerful case about once you have a virtual
2266400	2273360	interface, you know, everything that you do on screens can at least in theory be done better
2273360	2280080	in a more flexible way with a virtual in virtual reality headset. So I do think there is that
2280640	2286400	many billion dollar value there. You know, I spent eight years involved with it. And,
2287040	2291120	you know, there's things that I'm very proud of the quest to the quest three being announced
2291120	2297520	officially and coming out real soon now are great pieces of hardware. And there's an interview that
2297520	2305040	I did 10 years ago in 2012 or 2013 where I'm saying this is the way I want things to go. I want
2305040	2310800	this self contained device that has inside out position tracking not cabled anything no external
2310800	2317760	tracking aids that can run lightweight applications internally all by itself and can connect wirelessly
2317760	2323840	to PCs to go ahead and have higher performance things. And that turned out just the way I wanted.
2323840	2329280	But there was a lot of things that I had friction at meta with trying to get the rest of the way.
2329280	2334240	Right. I was going to I was going to ask you. I started thinking about the transition into AI.
2334240	2338160	I don't know how much of that was somewhat being disillusioned by the impact that you want to see
2338160	2343840	in VR. No, it really wasn't. I was still fighting the good fight as much as I could from my position
2343840	2351680	in VR. But it is funny how my origin story for the AI really does go back to Sam Altman and open AI
2351680	2356720	trying to recruit me when I knew nothing about the state of AI. And I was very flattered by that,
2356720	2362240	that they just thought that I you know that my skill set in background could play a useful part
2362240	2366560	in the company that they were building and putting together. Now, we were talking about that just
2366560	2372000	before we got on before we got on stage. But had you already started to look at that point that
2372000	2377680	raised your profile? No, no, just like they went after you as purely you are a brilliant engineer.
2377680	2383200	You will help get us the rest of the way there. Yeah, the only I had some vague relationship to
2383200	2388080	it for like there were hand tracking models and eye tracking and face tracking neural nets were used
2388080	2395600	a little bit in the VR side of things. But I hadn't I I had barely touched it. I had done sort of my
2395600	2400640	neural nets in C. I just spent a week just kind of writing that by myself. But that was about it.
2401280	2406080	Yeah. So then so that was so they reached out to you. And then that made you think I should
2406080	2412160	look into this AI stuff. Yeah, exactly. And then I looked into it. And, you know, and I was very
2412160	2416480	happy they they helped me kind of get my feet under me. And like, here's roughly what you need to
2416480	2422560	learn. And when I started looking into it, it, I carefully thought about it. And I reached this
2422560	2427760	conclusion that this is probably the highest leverage time for someone like me, you know,
2427760	2433440	an individual engineer in the history of ever, you know, that there are so many important things
2433440	2439280	that require huge teams of people that require lots of management. But the gap between where we
2439280	2445040	are now standing on the shoulders of all those giants, and this really transformative thing with
2445040	2450160	general intelligences, applying to almost everything that we do intellectually in the world,
2450960	2455760	that feels like this small modest number of things. And when I look back at what
2455760	2460320	mattered in the last decade, they all feel like things that I would come up with. So
2460960	2467040	it was exciting. Yeah. So I think it's kind of funny that if you look at what Edmonton's
2467040	2471760	innovative scenes are, there's one on the side of games, and there's one on the side of AI.
2471760	2478080	Do you think that that's you've you're traveling a similar set of spaces? Do you think that that's
2478080	2481120	coincidence? Or do you think that they're related? It's interesting, because of course,
2481120	2486240	famously, like Demis Hussabis at Deep Mind was also a gaming background person. I'm
2487200	2493600	Yeah, it's hard to say there are certainly some aspects of being all about virtual worlds and
2493600	2499200	simulations that plays a little bit into it, but it's a little bit of a stretch. I think it might
2499200	2505680	be more fundamental that the people that are overjoyed at the technology of games, it's this
2505680	2511040	general sort of optimism about what you can do with technology. And you've had you've gone through
2511040	2515920	the feedback cycle of getting this huge reward and joy from solving a wonderful technical
2515920	2521280	problem, and it causes you to delve deeper into it and push harder on it. And it does, you know,
2521280	2525200	in some degree give you confidence or maybe even hubris to think that you can make a difference
2525200	2534240	in some of the other areas. Cool. So this this partnership with Rich, I'm kind of curious.
2534240	2539040	All disclosures. I was part of, I was also a co-author on the paper of the Alberta Plan with
2539040	2544000	Rich and Patrick. But I want to ask you, have you read the Alberta Plan? So I hadn't before I
2544000	2548880	started talking with Rich. So I was familiar with, you know, I had gone through his textbook,
2548880	2555600	I'm, you know, twice actually, and I loved his bitter lesson paper and I had caught like a couple
2555600	2561840	of his presentations. But I was several years behind on sort of the research work that he was doing.
2561840	2568160	And I had it, you know, I had my, my mental model of Richard Sutton had a few things that I had
2568160	2573040	some concerns about from my view of reinforcement learning from several, you know, several years
2573040	2577920	back. And when I started talking with him and started going on, like all of his more recent
2577920	2583520	work, I got most of my concerns there were pretty much elate. And it was kind of surprising how
2583520	2589040	aligned we were on a lot of things. Okay, if you could pick one thing that you think the Alberta
2589040	2596160	Plan gets right and one thing that you think the Alberta Plan gets totally wrong. So yeah,
2597120	2604720	I'm setting you guys up for success. So I have concerns that the monolithic nature of the models
2604720	2610720	that are talked about there may not capture some important aspects of the way human brains work
2610720	2617680	as a much more distributed semi-consensus finding system. I mean, we draw these neat boxes about
2617680	2623200	your state, your policy and implemented with monolithic models. You know, these are,
2623200	2627840	we have Turing equivalents on a lot of these things. I won't say anything can't get across
2627840	2633680	the finish line, but I do like to at least gesture in the direction of our one existence
2633680	2639520	proof of in general intelligence with biology and say that there, there is much less of a central
2639520	2645440	driving force behind these things that I believe they operate more at these somewhat lower levels.
2645440	2650800	And I, you know, I don't have this resolved, but that's always a concern for me when something,
2650800	2655360	I mean, we've, we've all stepped back away from anything smelling of symbolism, but
2655360	2661440	there's still monolithic tendencies that I think may yet prove to be a little bit of a retarded
2661440	2667840	for it. But the, you know, the important things about what an AI does is digest its experience
2667840	2672560	into a state representing, you know, its view of the world and how it predicts things going forward
2672560	2677440	and how it needs to have motivations both internally and externally imposed. These are
2677440	2682880	core that, that are completely unaddressed by the, you know, the current, the current sensation
2682880	2687600	with the large language models, you know, these take a very, very wide context and they throw
2687600	2691760	something at it and you get an answer out the end. And there's enormous value. I don't want to
2691760	2696560	take anything away from everything that's being done with that, but that's not how our brains are
2696560	2701920	working. And I think that there are important things that, that it doesn't, that it doesn't
2702000	2707040	encompass. And yet every lab in the world is throwing so much of the dominant share of
2707040	2712640	their resources at that. So being a little bit contrarian, both of us, I think is, is a positive
2712640	2717760	thing. Yeah, I'm glad you used that word. That seems like a word when I first thought of, of, of
2717760	2721360	you and Rich, I was like, well, those two things I know you're aligned on being contrarian, but I
2721360	2727360	don't know if you can be aligned on being contrarian. I'm going to ask you one more question, but I'll,
2727360	2731200	I'll say that I'm going to open this up to the audience for questions after this last question
2731200	2738800	and the microphone I believe is over here. So if you want to rush to get in line to ask a question,
2738800	2742720	I'll let you do that while I ask my last question to John, which is, you know, what's,
2742720	2748800	what's your future? You talked a little bit about 2030 as being a goal of, we might see some AGI,
2748800	2753840	but maybe you could describe what, when you say there's a 60, 50 to 60% chance that it happens
2753840	2760240	by 2030, paint me a picture of what happens, looks like. So it does appear that I, you know,
2760240	2766240	I'm a person of decade-long efforts where I, there's a spectrum of useful there. There's a lot
2766240	2770960	of people that have 18-month kind of passions and cycle through and you get more breadth with that,
2770960	2775680	but I've been a fairly in-depth person, you know, overlapping with, you know, gaming and
2775680	2781680	rocketry and virtual reality and now AI, and I fully expect this to consume a decade of my life
2781680	2787920	or more. So I certainly wouldn't give up in less than a decade, and if things are going well,
2787920	2795040	it'll carry on longer than that. I do intend us to stay intentionally away from anything
2795040	2801200	smacking a commercial product. I think that it is important. So this is one of the things I do
2801200	2805200	struggle with a lot though. I mean, there's, there are all of these things. I'm far from having this,
2805200	2811520	I, you know, surety of direction or anything. One of the problems that I had a lot at META
2811520	2816480	was a lot of the research I thought was actually not particularly valuable, that it was building
2816480	2820960	for things, and I wanted everyone to concentrate just on product. You know, with, you have product,
2820960	2825280	there's a million things you can do, just do those million things, don't look too far ahead,
2825840	2831440	and yet here I am doing exactly the opposite, and I, you know, I have the arguments with myself,
2831440	2835760	do I have a legitimate reason why this is different, or should I just be doing some data
2835760	2839840	generation startup, you know, the, the 10 companies that want me to help them do game
2839840	2845120	generation with generative AI, there's, you know, there's tens of millions of dollars just to be
2845120	2850960	had at the drop of a hat to go do something like that, and I can't say with surety that
2850960	2854960	that's not true, that you don't learn as much along the way building those skills there,
2855760	2861680	but I, my hunch, my bet that I'm making with this company and putting my effort into it is
2861680	2866560	that there are a number of things that are very important, that are not immediately commercially
2866560	2873600	valuable, that contribute to the big brass ring of the big deal there, so we have,
2874640	2879360	just today we spent most of the day at white rooms, at conference rooms, kind of talking about
2880400	2884480	finding out what areas we're aligned on, what areas we think need to be explored,
2884480	2889360	I, hashing out a little bit of differences in understanding on some of the air, the questions,
2889360	2894640	but I have a, you know, a series of things that I'm building up that I hope will demonstrate to me
2894640	2899600	that we're at least on the right track, but in the end, you want to get something that winds up
2899600	2906160	being sort of a virtual being that you can delegate tasks to, that's not just a chat bot,
2906160	2912240	it's not just a tool that you use, but it starts winding up being options in remote
2912240	2917840	employees for, for companies where you have the option of like, oh, I liked working with AI Tom
2917840	2922640	before I'll take five more, you know, of him, put them on the different tasks here, and that's,
2922720	2928560	I, you know, at the end result, so many of the things that humans do now are mediated by
2928560	2933040	computer interactions, and the pandemic really did put quite a point on that where
2933040	2937360	more things than people would have thought possible five years ago really are capable of
2937360	2942720	being done just through the computer intermediation. And I think that, you know, that is the opportunity
2942720	2947440	to have this golden age of creative power and ability with magnifying all of that.
2948400	2954320	Awesome, thanks. I didn't see anyone walk over to the microphone, which I told you,
2954320	2959680	there's no hand raising just to be clear. There's no hand raising, you have to walk to the microphone.
2965120	2971600	Take it away. Hello. Thank you so much. So I have a question about kind of this path
2971600	2977120	towards artificial general intelligence, and I'll kind of frame it in terms of quake. So
2977200	2983040	in quake, you have fast inverse square root, which was a method that no one would have thought of
2983040	2987120	to do this process much more efficiently. So I'm wondering when you think towards the path of
2987120	2992320	artificial general intelligence, how much of it do you think is these ideas that no one was thinking
2992320	2996480	of that are just a little bit more efficient than before? And how much of it is kind of a combination
2996480	3000320	of ideas that we already have and that are floating around our circles? Yeah, so there's
3000320	3005200	some interesting aspects to the question of efficiency, where I have to guard my time to
3005200	3010720	not spend too much time on optimization, because I love that work. It's like a vacation for me to
3010720	3018320	have something so clear, just make this number go down. That's fun for me, but it's not the most
3018320	3024080	important thing, because in so many ways, making something two times faster, four times faster,
3024080	3029920	even 10 times faster, if it's not on the critical path, that's probably not the right thing to do
3029920	3035520	now. Now, where it does matter, you get into factors of 100 and 1000, and there are architectural
3035520	3041520	choices that you make that have these three plus orders of magnitude importance. And those are
3041520	3046160	important that you not mess those up, that you not do something. And there are architectures that
3046160	3050720	you could make that are just going to be like involve pointer chasing or something that are just
3050720	3056320	not going to be good enough, because three orders of magnitude matters. You can't run your experiments
3056320	3061920	in time, you can't deploy it and all that. But on the other hand, there are some architectures that
3062960	3068720	may be important that just because they're not easily expressed as tensors in PyTorch or Jax
3068720	3074560	or whatever, that people shy away from, because you only build the things that the tools you're
3074560	3080720	familiar with are capable of building. And I do think there is potentially some value there for
3080720	3086800	architectures that as a low-level programmer that's comfortable writing just raw CUDA and managing
3086800	3095040	my own network communications for things, there are things that I may do that others wouldn't
3095040	3100720	consider. And one of the aspects is the boundaries that we put on the things that we're going to do,
3100720	3106000	one of my boundaries is it has to be able to run in real time. Maybe not from my very first experiment,
3106080	3113200	but if I can't manage a 30 hertz, 33 millisecond sort of training update for a continuous online
3113200	3120400	learned algorithm, then I probably won't consider it, because I do consider that necessary for
3120960	3125280	even while you might grow in a simulated world, at some point people aren't going to really buy it
3125280	3131440	until they're having a Zoom call with the AI and poking it in various ways and having conversations.
3131520	3137760	That ability to run in real time goes against the current grain, because things are moving up to
3137760	3142240	you use a warehouse full of computers, but your step time might be a second and a half or something.
3142960	3147680	There are alternate ways of structuring your systems such that you use a warehouse full of
3147680	3153040	computers and you get a 30 millisecond time, but you can't do that with the tools that most people
3153040	3158080	are using today. So I hope that it does have some benefit, but that's one of those speculative things.
3158080	3162320	My background may let me do something that might be important, but I can't say with any
3162320	3166320	confidence that it actually is critical. That's awesome. Thank you very much.
3169360	3174880	All right, next question. Hey there, John. So I'm a huge fan boy. I just wanted to say thank
3174880	3180960	you for everything and you've done for this industry and specifically thank you for building Quake.
3181280	3183280	Excellent.
3186480	3191200	Quake was a very important game for me for both my social and professional life. Thank you.
3192320	3198160	But my question is about who in this world has the ability to build the next great thing?
3198960	3205600	In my mind, throughout history of computers, there's always been like a sole person or a small team
3206080	3212720	and not some giant corporation that's really pushed things forward. Every programming language
3212720	3219600	was created by like one or two people. There's Linux. Google was famously started by two dudes in
3219600	3226640	a garage. Your former employer, Facebook, was created by one guy or one set of twins, depending
3226640	3232000	on who you ask. And I basically believe you created a lot of these technologies on your own.
3232960	3239280	But when we look towards AI and VR, there seems to be like these huge requirements for enormous
3239280	3246880	amounts of data, big training sets, multi-million dollar compute time. So I ask like can a small
3246880	3254160	team still build the next great thing? So there are, I would say most projects in the world of
3254160	3261600	importance actually do need larger teams and resources. Building commercial infrastructure,
3261600	3265680	building highways, these take large teams. And even in the software side of things, building
3265680	3270960	Chrome takes a large team, building Android takes a large team. And these are super important things
3270960	3277120	that the world runs on to some degree. So the default state is it probably needs a lot of people
3277120	3284560	for these big things. But my point about AI or AGI right now being this potentially unique
3284560	3292400	point of high leverage comes from my belief that I have this whole set of spiel about how
3292400	3296960	the data is not that large, the compute is probably not that large in the larger scheme of
3296960	3302720	things. Like a point I make, a year of life is a billion frames at 30 frames per second.
3302720	3308080	And that fits on a thumb drive. And you can tell that a one-year-old is a conscious intelligent
3308080	3313520	being. So it does not require all the data on the internet to demonstrate artificial general
3313520	3319440	intelligence if your algorithm is correct. The arguments about how much compute you may need
3319440	3325360	are, I don't have as ironclad positions about that, but I have plenty of reason to believe
3325360	3330000	based on the capabilities of what the networks are doing today and the size of the brain and the
3330000	3335760	parts that we think we understand what's going on, that it is not a warehouse full of computers.
3335760	3342240	I mean, I don't think it's one node or even one rack, but in that scale over the course of the
3342240	3348640	coming decade, we will factor that by, it will be another order of magnitude less. And I do think
3348640	3356320	it's inevitable, but there is this period where well-healed individuals right now can potentially
3356320	3360400	take a crack at this. If none of us make it, then eventually it's going to get to the point where
3360400	3366320	every grad student has the resources to take a stab at these problems and the problem will fall
3366320	3370960	shortly after that point if it hasn't fallen before that. But I think we're in this magical time
3370960	3376640	right now where it is a golden opportunity. And I'm honestly surprised that there aren't
3376640	3381840	more people. I mean, there are hundreds of people like me that were technical people that
3383040	3388400	succeeded, sold companies, have the resources to go and apply this. I'm kind of surprised that
3388400	3393280	there aren't more of them taking small stabs at it because even if you think you've got one tenth
3393280	3399200	of one percent chance of kind of making it and getting all the way, it's kind of a Pascal's
3399200	3405440	wager sort of thing where the expected value from that, if you have no fear of ruin, is still quite
3405440	3414960	significant. Great answer. Thank you so much. Hello, John. So I understand that the AGI Gold,
3414960	3420960	my team, a little bit abstract. So my question goes towards, if you're taking steps towards this
3420960	3426640	goal, how are you making sure your, how are you measuring your progress? Are you decomposing it
3426640	3432800	into some problems? Like what are the proofs for the steps? Or maybe abstractly, are you sure
3432800	3438800	you're going to be making progress towards this 2030 goal? Yeah, so I'm not at all sure about it.
3438800	3445920	And it is almost one of the key questions. How do you gauge whether your child is growing properly?
3445920	3450640	Do you have things that are crude like the basic responsiveness tests about things? You track
3450720	3456960	pupil movement, but how do you tell at the earliest level before a billion steps have gone by what
3456960	3462960	level of cognitive processing is going on there? And I have like my angles on this involve, you
3462960	3467920	know, like moving foveas and centers of attention. And there's low level things that I can look at
3467920	3472960	and say, I believe in intelligence should be following these patterns. And I have these indirect
3472960	3478640	measures that I can make of it. But I dearly wish that I had better objective measures because
3479600	3485680	it's undervalued how critical benchmarks were to the pace of this last decade of terrific AI
3485680	3492080	progress where turning things from a discussion section into numeric values. And yes, there's
3492080	3496720	downsides and people talk about grad student descent of the problems with leader boards and
3496720	3502400	different things like that. But overall, it's been enormously valuable. And I, you know, I do worry
3502400	3507520	a little bit even with the LLMs that I don't really buy a lot of the measures of how they're
3507520	3512960	benchmarked against each other. And it's an even harder problem for AGI. So I wish I had
3512960	3517600	a better answer to that because I think it's important. But I think that there's at least
3517600	3523040	directions that we could be following that we feel pretty good about. But it's entirely possible.
3523040	3527600	Years could go by and it turns out it was the wrong direction, but it's still worth the try.
3528400	3529040	Okay, thank you.
3532240	3537120	Yeah, I had a question about the kind of AGI you visualize building at Keen. So when I think
3537120	3541200	about AGI, I think there's an embodiment, there's an actual robot functioning in the real world.
3541200	3544880	So are you thinking about something which is animal like or human like, or is it come
3544880	3550560	completely virtual? Alright, so I'm not a fan of robots, which puts me at odds with Joseph here.
3551920	3557280	And, you know, it comes from, of course, I'm the virtual reality guy. So I believe in simulation
3557280	3563680	and the general ability to, you know, to do valuable things in simulation. While robotics puts
3564080	3569360	much of the value of working with robots is this discipline of saying you're going to be real time,
3569360	3574160	you're working with reality, you can't just get slower and slower and make your model better by,
3574160	3579440	you know, by scaling it in a way contrary to time. So I think that that discipline can still
3579440	3584160	be maintained in a virtual environment. I am. And I think that's the primary benefit. And there's a
3584160	3590880	lot of downsides to robots where I did spend over a decade building rocket ships and that drives home
3590880	3596320	sort of that, you know, the cussedness of physical things. And the less you can be forced to work
3596320	3606000	with physical objects, the better in most cases. So I think in general, I don't expect us to be
3606000	3611200	doing anything robot based. Now the question of exactly what simulated environment you have,
3611200	3616800	there's a broad range there where like right now I'm working with sort of this 2d infinite movie
3616800	3620960	wall of like moving around looking at different things. And there's a degree of agency there.
3620960	3626000	And you could learn about 3d environments and you can put 3d games inside there. But to me,
3626000	3630400	like it's an open question, should it be a virtual reality environment of instead of a
3630400	3635200	virtual 2d wall? Should it be a physical space where they have to like walk around essentially
3635200	3639600	to look at different things? And I don't know, I'm leaning towards the simpler salute, the simpler
3639600	3644720	possibilities right now. But if it turns out that I wind up making a full fledged, I am, you know,
3644720	3649280	game engine rendered virtual world, I wouldn't be at all surprised if that's where we wind
3649280	3659920	up in a year or two. Thank you. Thanks John. So it's very special to have you joining our community
3659920	3667360	here in Edmonton. And when Rich emailed you, you must have thought to yourself whether you wanted
3667360	3675440	to start this partnership. And obviously you did. So I was wondering about what were the behaviors
3675440	3681920	that you saw in this community that wanted to make you join our community? And more broadly,
3681920	3686640	like what should we hold on to? Because we might have taken it for granted because we've been
3686640	3692160	fostering for so long. Yeah. So the, you know, initially I did not get my hopes up. I was just
3692160	3697120	like, Hey, it's cool to be having a communication with Richard Sutton. And I was going to try to
3697520	3703680	my helpful self as much as I could be. And the fact that we did wind up hitting it off well enough
3704320	3710880	that it's almost remarkable how many areas of overlap that we've got in terms of the way we
3710880	3720320	look at this. And, you know, in some ways, both me and Dallas and Rich up here in Alberta,
3720320	3725520	it is, this is not the center of gravity of artificial intelligence research. I, you know,
3725520	3731200	we are in our own way in the wilderness. And I think there's some commonality that came from that
3731840	3739600	where there is, you know, there is this kind of fashion in research and especially in the
3739600	3746800	commercial side of it. And the current looking at things like the reinforcement learning and the
3746800	3752160	real time online continuous learning, these are not the current fashion for things. I, you know,
3752160	3758240	great strides are being made with large language models, large batch training, slow steps, inference
3758240	3764240	only. And, you know, and that's all great. But everybody should be aware that this is not the
3764240	3769680	be all end all, it doesn't solve all of the problems. So somebody's still got to be looking for
3769680	3775360	the remaining answers, you know, we don't have them all. So being willing to go against the grain
3775360	3781280	and to, to step a little bit outside and have a lot of people say, Why are you working on that?
3781280	3786960	You know, that's not the, you know, the mainstream. That's not where you can go impress the VCs or
3786960	3793200	whatever. But at some point, somebody has to solve some of these problems. And, you know, the willingness
3793200	3798960	to go ahead and do that, because you think that it's the right long term solution. It's I, you
3798960	3804080	know, I do tip my hat to the kind of the academic virtues of you are trying to find truth, you're
3804080	3808160	trying to find, you know, the knowledge and the way to solve these problems in the hopes that
3808160	3812560	then they will be applied into the world to produce great value across the different areas.
3814560	3818800	But yeah, the biggest thing right now is we're both outside the mainstream, but we both have
3819360	3825520	conviction and we have, you know, reason to believe that it's a profitable direction to be
3825520	3830880	pursuing. And this is far from the only direction. Again, I'm surprised that there aren't more efforts
3830880	3835760	like this going on, rather than having the 10th company training their own large language model
3835760	3840560	to compete with something. There are other interesting problems that may wind up being
3840560	3847360	even more important. And being excited about the general technology while kind of picking a path
3847360	3854080	that's not just following somebody else's trail in the specifics, I think is important. You know,
3854080	3862560	the world needs more people like that. Thanks. Hello. I'm very excited to hear about this
3862560	3868720	partnership that you have here. And so one of the things that I like about it is that there's a
3868720	3874400	lot of blue sky research that you sort of have in mind, right, that for the next seven, 10 years,
3874400	3881760	whatever, there's going to be a lot of focus on these fundamental things, some maybe online,
3882320	3890000	real time algorithms to do certain things. But you also emphasize that there is no need for a
3890000	3895280	tangible product in, let's say, in this timeframe, right? So all this sounds very much like an
3895280	3902240	academic lab. And while this is certainly not one, right? And perhaps, so my question is out of
3902240	3907040	curiosity that, is this something you are specifically guarding against? Because like deep
3907040	3912640	mind and companies like this also started with a similar perhaps intention, right, that lots of
3912640	3918640	blue sky research, solve intelligence, use that to solve everything else. But now, maybe it's not
3918640	3923120	exactly the same anymore, right? So are you specifically guarding against that? Or is that
3923120	3928960	something you don't really think about? So I am unashamedly a capitalist. I, you know, I do,
3928960	3933840	I think that this could make me a trillionaire if everything goes well, it's worth, I, you know,
3933840	3938320	it's worth kind of aiming for some things that I, you know, producing value, I think it's good for
3938320	3943760	the world. I mean, I deeply believe that building commercial enterprises is most of what has made
3943760	3949760	the world what it is today in a very positive sense. So, you know, and I don't have the academic
3949760	3955360	background, I am, you know, I respect, I recognize I'm standing on the shoulders of all of the academic
3955360	3959760	work that's been done before. And it was funny because I talked to, I'm, you know, ahead of a
3959760	3963520	university one time, and I was kind of mentioning how I feel a little guilty being a commercial
3963520	3968240	company that is built on lots of this research. And he said, you know, your tax dollars have paid
3968240	3972720	for a whole lot of this research, don't feel bad at all. You know, this is the point of all of this
3972720	3979600	is to let people try to build on it. So, yeah, it's, it is a commercial effort. And part of that
3979600	3985760	was a focusing tool for myself, where I spent kind of the prior few years in what I call Victorian
3985760	3990720	gentleman scientist mode. I was kind of styled like Darwin or Babbage, where I'm a rich guy that
3990720	3995840	can buy all the scientific tools that he needs and can kind of have my backyard laboratory for
3995840	4001520	things. And, you know, and I learned a whole lot. I spent the time kind of going through this
4001520	4005920	extended larval stage about finding out what everybody is up to and getting myself
4005920	4011120	up to the modern standards there. But it always gave me an out, you know, just at that level,
4011120	4015520	I could think of it as like, well, it's almost a hobby. I could just quit at any time. I could
4015520	4021280	divert my time any way that I want. And I had had several, several different organizations
4021280	4026640	pestering me about form a company, take our investment money. And I didn't need it for the
4026720	4032640	money. But I looked at it as a focusing tool, where I have in many ways an overactive sense
4032640	4039280	of responsibility to, you know, to investors, you know, it, it killed me at, at meta, just seeing
4039280	4044240	all that money going out, I went and like, no, turn it into profitable businesses earlier.
4044240	4049600	So that is an aspect of it. And then hiring employees means it's like, okay, now I've got
4049600	4055520	people's paychecks that I am responsible for. So it makes me focus better on the, you know,
4055520	4061440	on the tasks at hand as well as actually bringing the resources to bear. So yeah, in some ways,
4061440	4068000	it's a pure research play. And, but at some point it turns into if it works products that
4068000	4077440	really literally reshape the world. Thank you. Yeah, so I think you touched on this a bit earlier,
4077440	4085200	but I'm sure many people have tried to hire Dr. Sutton before and failed. And so, yeah,
4085200	4090080	like, could you talk a bit more about like, why you succeeded where no one else could and was it
4090080	4094800	like fully attributed to being aligned or? Yeah, so I still, you know, I still wind up
4094800	4099840	being happily surprised that I'm here today with this because I, you know, a couple of times I
4099840	4104000	just said, I know you can write your own ticket anywhere, you can go to any of these companies
4104000	4107680	and everybody would be happy to have the father of modern reinforcement learning just
4108560	4112400	in their collection. And for some big companies, it is almost like a Pokemon collection,
4112400	4116880	you know, collect your favorite researchers and, you know, make sure they're on your team and your
4116880	4123120	deck. But I, you know, I think, you know, part of it is that we want to actually do these things.
4123120	4128560	It's not about prestige and being out there and kind of staking a claim. We want it to exist.
4128560	4134880	We want to build it. I am, and I think that there is a sense that a smaller team, there's, I mean,
4134880	4140160	there's all sorts of drags and friction that you get in big teams. It is wonderful to have a 10,000
4140160	4145360	GPU cluster that you could go ahead and just kind of get time on whenever you feel like it.
4145360	4150560	But I am, again, I've got enough options for, you know, for doing things like that,
4151440	4156880	that I don't think that's going to hold us back. And the ability to have a purity of focus, I think
4156880	4163680	is important. But I'm, yeah, I'm, I'm still, you know, really very happy that it all worked out this
4163680	4173200	way. Thank you. Hello. Thank you so much for the talk, John. It was fantastic. So my question
4173200	4181520	goes back to the discussion about game development and open source. And I would like just to hear
4181520	4188400	your opinion about what is, what do you see as the future of open source software in the video game
4188400	4196480	industry, especially since it's a world full of full of IPs and proprietary platforms?
4197440	4203040	So there is, you know, right now is an interesting inflection point because Unity had their whole
4203040	4208240	change their terms of services. And this is making a lot of people reevaluate what they're doing.
4208800	4214000	And it's been a long time since I was really close to the work being done on the open source engines.
4214560	4220560	But, you know, I believe it's fair to say that Unity with all their employees, they do a lot to
4220560	4226000	make it a comfortable, cozy development experience. They do provide a lot of value. And you do get a
4226000	4231120	lot of open source crusaders that just don't acknowledge the value that the commercial companies
4231120	4235600	bring to the table when they build their software. Because there are a lot of blind spots that the
4235600	4240240	open source teams, it's, it's weird how the DNA of the people that are willing to work on open
4240240	4244880	source wind up with certain important blind spots in the kind of applicability of their
4244880	4250000	software and usability. You make super powerful tools, but, you know, they're not very comfortable
4250000	4256080	and it winds up making them not the right call for a lot of people. But like I said, I very much
4256080	4260720	respect EPICS in between position where even if you don't pay them a cent, you can read every line
4260720	4266560	of code and learn from it and understand how things work. You can pay reasonable license fees.
4266560	4271280	Having competition there is great, you know, letting people choose. And I always thought that
4271280	4276720	the trade-offs between Unity and Unreal was a nice market balance to have. And like in virtual
4276720	4282400	reality, 95% of the developers wound up with Unity because of just the crowd that was attracted.
4282400	4287520	But it was always expected that if you need serious control, you'd then go with Unreal and
4288080	4293360	you could write things at a lower level. So there's an opportunity now, I think there will
4293360	4298800	inevitably be some larger move after Unity stumble here to open source projects.
4299840	4306240	I don't expect it to be a tsunami that like accelerates and takes over everything because
4306240	4311120	there are just so many of these grubby business things that are just not fun to do on the open
4311120	4318240	source projects that I, you know, I could imagine a scenario where somebody like, you know, Meta
4318240	4323680	gets behind open source things and winds up helping do some of the unpopular, unfun things
4324880	4331840	for their own kind of self-interested reasons that could be positive. But I think I'm resigned to
4331840	4339360	a slow pace of migration towards more open source tools. Again, at this point, 30 years back,
4339360	4344400	I'm disappointed that we aren't further along there relative to like compiler tool chains and
4344400	4349440	things where the world is a better place for having those be almost universally open source.
4349440	4354000	And we probably could have been there on some game engine type things, but I don't think the
4354720	4359520	fundamental reasons why we're not have changed. So I think it's going to be modest changes going
4359520	4365280	forward still. Thank you so much. I'm being told we're almost out of time and we have a line of
4365280	4369360	six people. So I'm going to go in a lightning round mode and you get 10 seconds to ask your
4369360	4374320	question. I can actually hang around a little bit after the actual official end.
4375840	4379840	Okay. Well, so I worked with Mike and Rich at DeepMind and actually some friends and I left
4379840	4384720	DeepMind to create a startup here in town using AI to make AI in video games. So first of all,
4384720	4388640	thank you for not shooting to make a commercial product in the next couple years in the AI and
4388640	4393920	game space. But my question is more like, I know Rich has a really strong commitment to open research
4393920	4396960	and it sounds like you embraced that as well with the hacker mentality. So
4397760	4401440	what are the plans for Keen to like share your insights, your breakthroughs, maybe even your
4401440	4408800	code? So this was one of the significant conversations that we had. And Rich does
4408800	4413600	understand the importance of commercial businesses and that there's reasons why these are
4413600	4420320	fundamentally important and the incentives matter. And there's a talk about like, yes,
4420320	4425920	I did champion a lot of releases of different things and I would, there's certain technologies
4425920	4430960	that I'm happy to have us publish. There's other things more like around experiment design and
4430960	4436960	architectures that I probably don't want us talking about. And it's going to be in a situation like
4436960	4442320	if, if somebody wants to write a paper about something, we'll have a conversation about it.
4442320	4446640	And if it's, you know, if it's something at the very tactical level, like, hey, this is an
4446640	4451440	interesting way to do an optimizer. This is, you know, another way to calculate your, your,
4451440	4457200	your TD assignments, whatever, that's, that's probably fine. But here is the architecture
4457200	4463520	of what our proto AI, AGI looks like that's probably not going to be talked about. Because
4464320	4468560	all of these are going to be things that we see it today where all of the major laboratories,
4468560	4474480	they can reproduce anybody else's work with a couple sentences of direction and a couple weeks of
4474480	4479600	time. And I think that's going to be the case for AGI as well. When, you know, when it does all
4479600	4484320	get solved, the textbook from the future is going to have a relatively thin chapter about this is
4484320	4491600	actually all that's really required built on the baseline to make it happen. So yeah, there's some
4491600	4495200	sense of secrecy. And then there's real concerns about any real company is going to have employee
4495200	4499120	turnover, they're going to walk out the door, you know, NDA or not, they're going to know what the
4499120	4505760	things are. So there is a large part of this gamble on even if all of this value gets developed,
4505760	4510720	much of it may dissipate into the broader world, which is great for the world, not so great for
4510720	4516800	my investors, but we're all still collectively willing to take that risk. Thank you. Okay,
4516800	4522080	it looked like lightning round didn't work. So I'm going to call it here because we're out of time,
4522080	4527040	but John has very generously offered to answer some questions. If you have some, we'll make
4527040	4532320	sure we start with this line first. Yeah. But let's first thank John for telling us so much
4532320	4547680	insight about his past, present and future. All right, thanks. Do I have to vacate the stage?
4547680	4559040	Yeah, I don't know what we do next. Thank you. Bye.
