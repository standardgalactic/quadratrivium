All right. Hello everyone. Welcome to AME HQ. For those who I haven't met, my name is
Cam Linky. I'm the CEO here at AME and we're pleased to welcome everybody today,
both to our office here and to our friends who've tuned in online on the
live stream. Many of you probably know about AME, but for those who don't, AME is one
of Canada's three national standards of artificial intelligence. We're tasked
with advancing Canada's AI potential and we're proud to collaborate with the
University of Alberta on driving AME's AI research excellence forward. We're
really, really excited to have everyone here today for this special
announcement from our Chief Scientific Advisor, Rich Sutton. Before we get
started, we'd like to respectfully acknowledge that we're on Treaty Six
Territory, a traditional gathering place for the diverse Indigenous peoples,
including the Cree, Blackfoot, MÃ©tis, Nakoda Sioux, Haudenosaunee, Dene, Ojibwe,
Sotu, Anishinaabe, Inuit, and many other peoples whose histories, languages, and
cultures continue to influence our vibrant community. And it's in the spirit of
that exchange of knowledge and of that gathering that we're excited to welcome
everyone here today. AME, we're really excited to support our friend and mentor,
Rich Sutton. There's so much that could be said about Rich and the pioneering
work that he's done in reinforcement learning and AI. The span of Rich's
impact is almost hard to enumerate from his dedication to fundamental research
and the advancement of the science of AI to his efforts to train the next
generation of AI researchers. His book, Reinforcement Learning and Introduction,
has both educated and inspired scores of graduate students and beyond, and is one
of the most approachable people in the field, always having time for researchers,
for curious observers, and for everyone in between to sit down, have a discussion,
discuss reinforcement learning, discuss artificial intelligence. He's one of the
people that, while many people have already left either the party or the conference,
Rich will be in the corner somewhere having a conversation with someone about
reinforcement learning, about some nuance of the field, and one of the things we talk
about here a lot at AME is approachability, and that approachability is something that we've
really been inspired by Rich from. Speaking of pioneers, the guest I'd like to invite up with
Rich has trailblazed multiple fields. Among his list of pioneering accomplishments are
co-founding id software, and his leading work there in computer graphics and computer gaming created
an entire genre of gaming. Since then, John's also known for his work in rocketry,
and ushering in a modern era of virtual reality with Oculus Rift. So we're so excited to have
them both here at AME HQ, and everyone please join me in welcoming John Carmack and Rich Sutton to the
stage. Thank you so much, Cam. It's a delight to speak to you all this afternoon. Today I am
pleased to announce the formation of a partnership between John Carmack and myself to work directly
towards the challenge of understanding and creating an artificial general intelligence
based on reinforcement learning and neural networks. The partnership will be embodied
within Keen Technologies, which is a startup that John created about a year ago. And as of today,
I am an employee of that company. Of course, I will continue as Professor at the University of Alberta,
and as the Chief Scientific Advisor at AME, the Alberta Machine Intelligence Institute that you're
all here at. So I'm very excited to be partnering with John. John is the world's preeminent developer
of complex high-performance real-time systems. His skill and brilliance was first demonstrated
in technical innovations in 2D and 3D graphics in computer games such as Doom and Quake. His
engineering skills were honed on rockets at Armadillo Aerospace and by his work on immersive
virtual reality at Oculus. Roughly five years ago, John became, you know, he turned to the
challenge of artificial general intelligence and that eventually led to Keen. Now, when I first
learned about John and Keen earlier this year, I was struck by how aligned we were, I was with him,
despite, you know, my having done this all my life and John just turning to it a few years ago,
there are many aspects to the way we are so strongly aligned, but let me identify just four of them.
We both strongly felt that the field of artificial general intelligence was dominated by
too narrow a set of ideas. This was groupthink and this groupthink was to be avoided. We both
strongly felt that trying to make money too soon was like an off-ramp on the road to AGI,
and we need to keep our eyes on the long-term prize of full AGI, eyes on the prize.
And number three, artificial general intelligence is not too complex for one person to understand
the principles of it or even to write the code for it. That's that as an important part of our
alignment. And finally, 2030 is a good target to have a success, to have a prototype AGI,
to show signs of life. We're a toddler, as John likes to say. So John and I are really well aligned,
and, but there's a sort of an elephant in the room and it's become clear. Keen is a small team,
the entire technical team of Keen Technologies is here today, and it's John and me and Gloria and
Lucas, if you could stand up, and also Joseph, who's we expect to join us by the end of the year,
and now they're all these Keen people are now part of our community. And could you all give
them a good Alberta applause? Thank you for that. So the elephant in the room is it this is a small
team and other companies have thousands of technical staff and are spending billions of dollars on
AGI. It's truly audacious of us to think that we can make a contribution.
But there are actually it's audacious of us to think we can compete with them. And we think we
can or at least we can make a contribution. There's much to say about why that might be
reasonable to think and I'm going to refrain from trying to explain it. But I will only remind you
of what Margaret Mead said. She said, never doubt that a small group of thoughtful committed people
can change the world. Indeed, it is the only thing that ever has.
Now I'd like to turn the floor over to John to say a few words. The legendary John Karnack.
So a couple months ago, I got an email from Richard Sutton. I'm like, well, this is cool.
So I am relatively new to the artificial intelligence field. And when I started kind of my larval
phases, I like to call it where I just inhale all of the relevant information in kind of the first
year. One of the very important references for me was Richard's book on reinforcement learning.
And in fact, I later went through the first half of it again with my son doing exercises
just a couple years ago. And of course, I reference the bitter lesson all the time as one of the
deep fundamental insights to the kind of broader effort of everything that goes on here.
So I'm Richard was trying to figure out I'm kind of like how he should be pursuing his efforts
towards research across different options in commercial, academic and nonprofit.
And I wanted to be super helpful. I hooked him up with a few other people and I tried to kind of
give him whatever help that I could. But I did very tentatively kind of broach the subject that,
all right, you're the godfather of reinforcement learning, you can write your own ticket anywhere
you want to go work. But there are some downsides to especially larger established organizations.
And you may get access to lots of resources and still have the freedom to do whatever you want.
But there are problems with culture and direction, kind of strategic direction in other areas.
It's why as fired as I was when OpenAI tried to recruit me, I respect all that they do,
but they've got their plan, they've got their directions, it's not really what I'm doing.
And there began a little process of kind of feeling out, well, exactly how do you feel about
certain of these directions? Like, what are the odds of technologies going this way? How
important is this? How important is that? And it turned out that we really did have a remarkable
amount of overlap in what we think is possible, what we think the remaining challenges are.
And to be clear, nobody has line of sight on the solution to this today, but we feel,
and I am a number of other people, that it's not that much left. There are things we don't know,
we don't know how to get there, but they all feel like the same scope of things that mattered in
this last decade. They're relatively simple things in the way that you set up your architectures,
the way you do your training, the way you query it in different ways. And I certainly think that
in 30 years, when the textbook of artificial general intelligence is written, it's going
to get digested down to a chapter that people are going to be able to understand. We just need
to figure out what those sort of core ideas are. So it was really still to my great surprise,
but immense pleasure, that we have decided to go ahead and work on this together. So
Richard is working at Keen Technologies now, he's in our workplace, and we spent all day today
basically talking about the plan of research, how we want to start figuring out what we're going
to be doing. So this is incredibly exciting for me. And would you like to say anything else Richard?
Thank you, John. I think now we'd like to take questions from the media.
So we're going to open up the floor for any media questions. For the media in the room,
if you have a question, please come over here. And for media on the line. So operator, please open
up the line for the first question. Oh, there's no media on the phone.
Any media questions from the room? Oh, hi, I'm Renali Unchin with CBC Edmonton.
So following this partnership, I'm wondering if you could talk about some of the tangible steps
that are going to be taken to kind of develop AGI more. So one of the big points that we do have
alignment on is that there's not a near term offer answer where there's not going to be a chat
gbt like deliverable that goes out and allows the world where there are fundamental research
questions that need to be answered. And this is me learning how to be a researcher and hopefully
learning from Richard a lot about that process. But we have internal projects and angles of attack
on things, but they probably will not have a lot of publicly visible effects for likely years.
We are fairly aligned on this sort of we are seven ish six seven eight years out from something
really big and important being publicly visible. Anything? That's perfect. Next question.
Yeah, I have a follow up. So for the average person, obviously, there was a lot of terminology
thrown around. Why should the average person care about this if you can describe in the most simple
terms? Well, I would say the average person probably shouldn't care a whole lot about this,
you know, I mean, this is something this is inside baseball work for people that are
in the field. I am, you know, a lot of people are going to be geeking out about this where,
you know, rich is a big, big name, big percentage, and I'm a big name in a very different field.
And we're kind of coming together. And I do think there's synergistic benefits for that.
And it's kind of exciting just as a, you know, two great taste, taste great together sort of
mix things up. I am between the, you know, different backgrounds, but I know, I mean,
I don't want us to try to make this out to be something that the man in the street should
actually care about. It may yet lead to one of the most important things in the world or in history,
but I there's very little guarantees about any of that. And that's the benefit of the way we're
financed in the way we're structured right now. We don't have to have a rush to a product. We don't
have to have a rush to make sure that there's an investor return in a very short amount of time.
We can concentrate on just trying to answer these critical important questions.
Okay. Cool. Great. Any other questions?
Fantastic. That concludes the Q&A portion of the program. Oh, yes, Rich. If we're done,
I have a few things I want to say. Please. Before we close, I want to thank Amy and the
University of Alberta for their help today, particularly Stephanie Enders and Laura Carter
and Cam and Linda Vang, express my appreciation for the entire Edmonton and Alberta community
for all they do in creating the rich intellectual environment in which I and this part of Keen
can thrive. The community has supported fundamental research in AI for 30 years
before I came here. And this is bearing fruit now in Amy and in industry and startup companies and
more fundamental research results. Please join me in a huge round of applause for Amy and for
yourselves, the entire AI community. And with that, I want to turn the floor over to someone else.
Cam, there you are. All right. Well, thanks everyone. How about one big round of applause
for Rich and John again. So thank you everyone for joining us today. That concludes the program
for the announcement. We're going to reset the room for the fireside chat. So if everyone can do
us a favor, I know this is a pain, but we need you to all leave the room, continue the conversation.
Everybody can have their favorite conversation about what took place here today. Head over to
the co-working space in the cafe. We have food and drinks and caffeine to really amp you up for
this next portion. If you've RSVP'd for the fireside chat, we'll we'll readmit you shortly.
So please do us a favor, move over there to our beautiful space and we'll see you back here shortly.
Thanks. All right. Okay, we're going. Welcome to the second half of the show. If you can do us a
favor, if you're on the edge of the roll, please squeeze into the middle. That will help as stragglers
come in, not doing this, excuse me, pardon me, excuse me, pardon me, and distracting the speakers,
so or just me. So do me a favor, squeeze into the middle, help us out. Thank you very much.
Get close, get to know your neighbor. Welcome back for those who missed the earlier part of this.
I'm Cam Linky, I'm the CEO here at Amy. We're excited to welcome back to the second part of our
doubleheader with a special fireside chat. So our host for the night is well known for his hate of
love of games, love of games. Yes, loves games. An Amy fellow, Canada CIFAR AI chair and full
professor at the University of Alberta. Mike is best known for his work in poker, most notably
solving the game of heads up, no limit, Texas hold them in 2015. And for deep stack in 2016,
the first AI to be human professionals at heads up, no limit, Texas hold them. I think I made an
error in there that Mike's going to correct. He's glaring at me. We're so excited for Mike to be our
host and to host our special guests tonight. And so I don't make any more errors. Please welcome
Mike Bowling to the stage. Thank you very much, Cam. I'm sorry, I do have to correct you. So we
did essentially solve heads up limit. And we beat the first to be professional players,
heads up no limit. Okay, but you're not here for that. I get to have the great honor of introducing
John Carmack. Many people have already said wonderful words about him, but maybe you weren't
here for that. I'll just say that he's a pretty big deal, maybe a BFD, if you will. But I'll just say
my first connection to John was probably my first memory of seeing something really innovative
was thanks to John. Because if you're really young, you can't see innovation. Everything is new.
So you didn't know what came before. So you don't know this change things. And when I was 17, I went
to a gaming convention and they're sitting was a rows of computers. This wasn't even a video game
convention. It was board games and real playing games. And they're sitting was a rows of computers
with Wolfenstein 3D running on them in the summer of 1992. And my mind was blown. So thank you,
John Carmack, and welcome to stage. Welcome, John. Thank you.
Oh, I'm supposed to push the button.
Okay. Yeah, when I was asked to do this, I was trying to think through. I felt like I had a lot
of pressure on me to ask you really insightful questions for the audience. But I decided I'm
going to kind of almost ignore the audience. I'm just going to ask you questions. I feel like I
want to ask you totally selfishly. And I'm going to hope because I have a love of games,
you know, I have a love of innovation, and I have a love for AI that maybe these are the
questions that the audience wants to hear too. But so I want to walk you back to the beginnings
of id and Wolfenstein 3D. And maybe you can say some words about how did you even end up
at that place? And then I want to turn around and talk a bit more about innovation from there.
Yeah, so it did. Games were super important for me in my childhood. You know, I love the
arcade games. I love the early 8-bit video games and the tabletop games, all of that. And so it
did seem obvious to me that this love of computers that I had that the best way to express it was
through games. Now, it is important to kind of differentiate a little bit there where there
are a lot of people that go into gaming and they learn about computers so they can make games.
And it was a little more fortuitous for me because I had this intrinsic love of computers as well.
And I probably could have been happy and found interest in doing more mundane things. But the
games were there. They were the obvious place and it turned out to work, you know, really well for
me. And so I had been, you know, for the first time I could do anything on a computer. I was
trying to write games. I was trying to, you know, at first mimic some of the other games that I
would see. The first, the early text adventure games, writing my dungeon crawlers, you know,
kind of inspired by wizardry and Ultima and the early things like that. But as I got to be a teenager
and I built the assembly language skills and started figuring out how to do the sort of the
real world things and I had a talent for it. I got good at it and I had decided that I wanted to
actually try to make a living making games. And there was, you know, there was a lean year there
of barely scraping by doing contract programming work before I accepted the position to come down
and work at soft disk publishing where I met the other founders of id software. And we started out
making our initial side scroller games, which was Commander Keen, which I have kind of harkened
back to with the name of my latest company with Keen Technologies. But then we, you know, we really
broke out and kind of made our name with the 3D games. And I always did kind of look at that as
it wasn't the games were the same things that you could do in 2D, but the change in perspective
of going to 3D, it made a qualitative difference, even if sort of symbolically it was the same game,
but it made a great difference in the impact it had on people. Tell me more about that that jump
to 3D. Was that was that intentional where you like I could think of so many ways this could
have gone where you could have just been like that seems like a hard challenging computer's
problem. And so I'm going to solve that versus feeling like this is the future of games. So we
need to innovate in that front versus not even realizing maybe that you were being innovative.
Like how did that work? No, I knew I was heading for that from the early 80s. I am, you know, as a
you know, even as a young teenager, you would see the representations of 3D graphics or in the movie
and you think about you see Tron or you see 3D animated logos. I can remember making a little
wireframe MTV logo spin around on my Apple to kind of figuring out these basics and looking back,
like I didn't know how to do clipping at the time so nothing can get close to the edge of the
screen. It just has to stay in the center and rotate around. But that idea of wanting to be
inside the video game, I mean, everybody that's a gamer kind of got that sense of you want,
you look at the game, you play the game, you appreciate it, but how amazing would it be to
put yourself inside it and then, you know, see the enemies coming at you rather than looking
down at it as that 16 by 16 block of pixels. And that was magical. And you could take exactly the
same game and put the user inside it and that really followed on even more with virtual reality
later on where getting the sense of presence where you kind of believe that you're in this
other environment. So that was always a big issue for me, but I do, you know, it is important to
say that that's kind of the obvious visible thing that stands out that there was a time period where
there was nothing else like that, but there are a thousand good decisions that go into making a game
and it was never about just the technology. It was about doing those thousand things right.
All the subtleties about how you feel, how you move, how the guns react, what the sound effect is,
there's 10 things you layer on top of every action that happens in a game to wind up giving
it this really good feel. And most of them will be things that people don't even notice. I mean,
everybody points to Oh my God, this 3d black magic that was going on that that left people,
you know, just wondering how they could compete with something like that until
you know, engine technologies got out there. But there were plenty of other now forgotten games
that wound up having flashy 3d graphics, but people don't remember them because they didn't
do all the other things, right? I mean, I definitely remember the just smoothness of the
original it games were just, I think just blew people away. Like it felt like you could play them
as opposed to being pulled out of the immersion from the clunkiness. But that's also innovative
technology too, right? That's some of the things that were actually subtle that were really important
to me. And nobody actually called these out. But in terms of the graphics, the way they were
rendered, there were a lot of 3d games that had this kind of non solid feel to it, where there
are these subtle things that happen to do with pixel centers and avoiding cracks between polygons.
And you can still make great games for that. Like the entire PlayStation one, I am, you know,
set of titles was all done with this integer snapped affine interpolated rendering technology.
You can do good things with that. But I always took pride in the solidity, the kind of sense that
everything was really rock solid there, where some games felt fragile, like, you know, you bump the
wrong way and you're going to slide through the wall, get caught and see a flickering mess of
stuff. And for the most part, I, we took great pains to make that not happen in ours.
That's awesome. Is there anything else that like you think like this was the innovative part,
but in the, you know, decades later, no one remembers that being the innovation?
Well, what was great is we had this period of like this five year period during the development
going from Wolfenstein 3d to doom to quake. And there were so many things that wound up setting
the tone for gaming for the following 30 something years. And things like the multiplayer gaming,
the modding, these were not the flashy 3d graphics technology. But they, you know, they were things
that were super valuable. And it was happy to see people, you know, follow up on it, even little
things like having a console, you know, having the, you know, the override ability for the different
data sets. There were a lot of decisions like that, that, you know, that worked out pretty well.
And I could imagine a world where 3d graphics was inevitable. It was being done on higher end
systems, offline rendering. But it is possible to imagine a contingent set of history where
you didn't wind up with this action oriented things because the dominant vision was you do sims,
you do flight sims, driving sims, tank sims, you know, destroyer sims. And this idea of this run
and gun really fast paced action, twitch reaction that, you know, whipping around the mouse directly
at inhuman speeds and all of these things, that might not have happened without id software in
the early days. I wonder just like how much that affected the development even get to where we are
today in terms of would, you know, we've seen gaming drive technology a lot, right? So would we
have GPUs today? Would we be sitting on top of AI on top of Dean learning sitting on top of GPUs
today? If we didn't have those initial games saying we could have action oriented, broader,
open games. Do you think that's a possibility? So the GPU side of laddering you, but yeah,
I mean, I do, you know, it's one of those things where I smile and I'll talk about it a little bit.
I do take some satisfaction in the fact that the GPUs were largely built to play the Quake series
of games at the beginning. And then you had this great insight from like Jensen at Nvidia saying
it's like, well, all these pixel processing things that we're doing, we can do other things with them.
And they had a lot of foresight to do the long game investment in CUDA and give us the kind of
generalized processing. Because people were doing general processing before that in this horrible
way. You'd paint, you'd encode your values into pixels, you draw a giant triangle that covers
the screen to do an array processing action on there. And it was, you know, it was effective a
little bit, but it was awful. But the evolution of GPUs to where they are today as this quite
general purpose device that does underpin all of the modern era of artificial intelligence.
It's nice to, even if I wound up not working in artificial intelligence, it would be something
that I'm proud of that I at least contributed at some point to that evolution. I have one more
question of curiosity from this time that relates to Wolfenstein itself. So I played
the original Wolfenstein games and Beyond Wolfenstein and love them. How did it, how did this,
like, did you have that IP in mind and then we're designing a game for it? Did you, did you,
you know, have the game first? Like, what was the order of events and, and how did that come
back? So all of us at Id, I am, you know, John, Tom, Jay and I, I, we were all Apple II background
people. So we all had this background with the original Escape from Castle Wolfenstein. And it
was a game that had these, it was more what you today would think of as a stealth game. You would
sneak around, you'd wear guards uniforms, you'd drag the bodies out of the way. But it still did
have that sense of shooting Nazis. And I, we had originally thought we were going to do some alien
based game, you're calling it it's green and pissed, just kind of a generic alien shooter. I, this
was following up off of our kind of fantasy themed Catacombs 3D. But when the idea came up that's
like, well, what if we did Wolfenstein 3D? I am, you know, all the good memories for us. It was
playing the nostalgia card even for us at that time, some 15 years after the that was initially
released. And back at that time, I look back and kind of cringe at, like our business practices at
the time, we did not sort this out very well. We kind of just charged ahead and looked around a
little bit thinking, well, maybe the rights are clear, these companies seem bankrupt. We eventually
ran into Silas Warner, the original author at an Apple II convention. And he was, you know, he
was delighted to see Wolfenstein something. Of course, he didn't own the rights. His blessing
didn't actually mean anything from a legal term. But to us, it felt good to have the original creator
kind of bless our effort and what we were doing there. And in the end, we got out of it unscathed.
But that was luck involved, I think. Awesome. Also, in the early times, I feel like it formed
another aspect of your career, which is your proponent for open source software,
both in distribution models of how software is distributed. We're pretty original in those
early games. I'm wondering what, well, yeah, what's your trajectory through that? What's your
thoughts about open source, say, then and now, and what connections are between them?
So probably the most formative book of my teenage years was Stephen Levy's book,
Hackers, Heroes of the Computer Revolution. And, you know, I read it dog-eared and it had
these major themes about the hacker ethic and the kind of sharing of information and
communal use of code in different ways. And this was before, you know, open source became what it
is today or even before the Free Software Foundation kind of had their mission. And I, you know,
coined the term. So that was, you know, that was pretty deeply in me early on. And it was fortunate
that John Romero, my kind of co-programmer, had similar feelings about it, that this idea that
it's just amazingly cool to be able to share the program to make it possible, where we had these
memories of hacking the games, like you'd get Ultima, you'd get your Sector Editor out, you'd
find out, oh, that's my gold, I want 9999 in there. And I always, I mean, I remember fervently wishing
that I could look at the source code for these things to be able to go, these games that I
adored that I spent a lot of time on, I wanted to see exactly how they were made. And to get into
a position as a small private company, you know, where we owned all of our own IP, the ability to
kind of make that earlier childhood wish that I had had come true for a whole new generation of
programmers was, you know, it was very motivating for me. And it was a drawn out process inside the
company, because there's a huge divide generally between the technical and the creative people
here, where, I mean, it's not a judgmental side of things, but just the technical people tend to
get this sharing more than most of the artists and designers do, where there's a lot more worry
about chain of credit and, you know, where the work builds upon other people's work. So it was
not fully understood by everyone in the company, but, you know, a little bit of it was, I was able
to throw a little bit of my weight around in my position. And I know there was a little bit of
hard feelings for a while that I did something that there was thinking was bad for the business.
Is this related to the leak of the Quake source code? Or do you think you have a different,
no, just the open source in general, where there was this point early on where we had released
the tools for Doom and the ability to do all of this. And a product came out called Dezone,
which was a CD-ROM just full of hundreds and hundreds of maps. And the people that did that
actually made more money than we made on Doom 2, because we did not have a great royalty deal at
the time. And, you know, they shoveled that out. And there was some genuine bitterness that that
was possible and that to some point, degree, I had enabled that by sharing the tools. But I did
feel very good that a decade or more goes on, a couple decades now. And the people,
like Kevin Cloud, who is one of the artists on there, had later told me that, no, that really
was all for the best, looking back on it. And we are in this almost unique position where Doom
will never die. As long as there are processors, Doom will run on them.
Right. Do you think there's lessons to take now? And then, like, I feel like the open source
community has played a role in the last 10-year development of AI. What do you see the lessons
that we should learn in thinking about how that connects to the current innovation?
Yeah, I'm still surprised that it doesn't play more of a role in the game industry, where I
I'm genuinely surprised that there is not more like full open source development. You see bits
of it in the Minecraft mod scene where you have projects up on GitHub. But people that are generally
making games, they still feel very protective of their source. And then you had the commercial
companies with Unity coming in and making a very powerful product that gets the job done that was
better than open source alternatives in many cases. I think Epic does a really grand thing by
they have strict licensing terms, but the fact that the source code is all available,
that's half the battle. I am pragmatic. I'm not a purist. I'm not going to license snipe somebody
about what they're using. Just having the source code available for view is a large chunk of the
value. So there's good stuff there. But in the AI space, it's much more open. And I think in the
broader sense of where academia has gone, where comparing, I go back and I do read a lot of papers
from the 90s and stuff. And it's papers without code, without data, unreproducible. There's a whole
lot of things that are just probably are not right. And the path to having the norm, it's still not
fully established and there's still pushback about it. But the world is a far, far better place now
for the openness that we do have on the pace of artificial intelligence and most other science
that I don't even have windows into the fact that code available on GitHub. I ideally data there.
We still have too many cases of data available upon request and there's still norms that need
to be pushed there because you do still have sensitive people. It's like, oh, if I release this,
people will find mistakes. They'll critique my code. They'll, you know, they'll have all of this.
And that's still a problem being worked through. But I have no complaints about the state that we're
at now and the trajectory that we're on. I think it really is one of the great things for the world
today. Cool. I want to have an AI, but before that, let me take your detour through VR for a minute.
Tell me what would, did that just feel like a natural extension for you for games or were
you thinking something bigger? What was, what was motivating you to move? Yeah, so I had actually
tried some VR stuff back in the nineties. We had one of the really old headsets that cost $10,000
and was like 320 by 240 resolution screens and pixels the size of small footballs in your peripheral
vision. And it was clearly not the right time for something there. And it was interesting where
I went and I said, I'm just going to go look at the state of VR because it's been two decades.
Surely it's all fixed by now. And I was really surprised to find that even though technically
we had good screens, good accelerometers, we had all the things that were seem to be necessary to
make this work. But there were still just this handful of government contractors making headsets.
They, there were $50,000 headsets in some cases and they still weren't even all that great.
And that was one of those points where, you know, you can say that opportunity is the difference
between what's possible and what people are actually doing. And it did seem there. It's like
from a technical level, these things were now possible. And the early experiments that I did
there showed that it can also be really quite compelling. Now there's, there's the obvious
play there about, well, you, you make games, it's more immersive. There's the step from
looking at a 2D game to looking at a 3D game to being inside a 3D game. And that is, you know,
absolutely true. But I do think there's the even more powerful case about once you have a virtual
interface, you know, everything that you do on screens can at least in theory be done better
in a more flexible way with a virtual in virtual reality headset. So I do think there is that
many billion dollar value there. You know, I spent eight years involved with it. And,
you know, there's things that I'm very proud of the quest to the quest three being announced
officially and coming out real soon now are great pieces of hardware. And there's an interview that
I did 10 years ago in 2012 or 2013 where I'm saying this is the way I want things to go. I want
this self contained device that has inside out position tracking not cabled anything no external
tracking aids that can run lightweight applications internally all by itself and can connect wirelessly
to PCs to go ahead and have higher performance things. And that turned out just the way I wanted.
But there was a lot of things that I had friction at meta with trying to get the rest of the way.
Right. I was going to I was going to ask you. I started thinking about the transition into AI.
I don't know how much of that was somewhat being disillusioned by the impact that you want to see
in VR. No, it really wasn't. I was still fighting the good fight as much as I could from my position
in VR. But it is funny how my origin story for the AI really does go back to Sam Altman and open AI
trying to recruit me when I knew nothing about the state of AI. And I was very flattered by that,
that they just thought that I you know that my skill set in background could play a useful part
in the company that they were building and putting together. Now, we were talking about that just
before we got on before we got on stage. But had you already started to look at that point that
raised your profile? No, no, just like they went after you as purely you are a brilliant engineer.
You will help get us the rest of the way there. Yeah, the only I had some vague relationship to
it for like there were hand tracking models and eye tracking and face tracking neural nets were used
a little bit in the VR side of things. But I hadn't I I had barely touched it. I had done sort of my
neural nets in C. I just spent a week just kind of writing that by myself. But that was about it.
Yeah. So then so that was so they reached out to you. And then that made you think I should
look into this AI stuff. Yeah, exactly. And then I looked into it. And, you know, and I was very
happy they they helped me kind of get my feet under me. And like, here's roughly what you need to
learn. And when I started looking into it, it, I carefully thought about it. And I reached this
conclusion that this is probably the highest leverage time for someone like me, you know,
an individual engineer in the history of ever, you know, that there are so many important things
that require huge teams of people that require lots of management. But the gap between where we
are now standing on the shoulders of all those giants, and this really transformative thing with
general intelligences, applying to almost everything that we do intellectually in the world,
that feels like this small modest number of things. And when I look back at what
mattered in the last decade, they all feel like things that I would come up with. So
it was exciting. Yeah. So I think it's kind of funny that if you look at what Edmonton's
innovative scenes are, there's one on the side of games, and there's one on the side of AI.
Do you think that that's you've you're traveling a similar set of spaces? Do you think that that's
coincidence? Or do you think that they're related? It's interesting, because of course,
famously, like Demis Hussabis at Deep Mind was also a gaming background person. I'm
Yeah, it's hard to say there are certainly some aspects of being all about virtual worlds and
simulations that plays a little bit into it, but it's a little bit of a stretch. I think it might
be more fundamental that the people that are overjoyed at the technology of games, it's this
general sort of optimism about what you can do with technology. And you've had you've gone through
the feedback cycle of getting this huge reward and joy from solving a wonderful technical
problem, and it causes you to delve deeper into it and push harder on it. And it does, you know,
in some degree give you confidence or maybe even hubris to think that you can make a difference
in some of the other areas. Cool. So this this partnership with Rich, I'm kind of curious.
All disclosures. I was part of, I was also a co-author on the paper of the Alberta Plan with
Rich and Patrick. But I want to ask you, have you read the Alberta Plan? So I hadn't before I
started talking with Rich. So I was familiar with, you know, I had gone through his textbook,
I'm, you know, twice actually, and I loved his bitter lesson paper and I had caught like a couple
of his presentations. But I was several years behind on sort of the research work that he was doing.
And I had it, you know, I had my, my mental model of Richard Sutton had a few things that I had
some concerns about from my view of reinforcement learning from several, you know, several years
back. And when I started talking with him and started going on, like all of his more recent
work, I got most of my concerns there were pretty much elate. And it was kind of surprising how
aligned we were on a lot of things. Okay, if you could pick one thing that you think the Alberta
Plan gets right and one thing that you think the Alberta Plan gets totally wrong. So yeah,
I'm setting you guys up for success. So I have concerns that the monolithic nature of the models
that are talked about there may not capture some important aspects of the way human brains work
as a much more distributed semi-consensus finding system. I mean, we draw these neat boxes about
your state, your policy and implemented with monolithic models. You know, these are,
we have Turing equivalents on a lot of these things. I won't say anything can't get across
the finish line, but I do like to at least gesture in the direction of our one existence
proof of in general intelligence with biology and say that there, there is much less of a central
driving force behind these things that I believe they operate more at these somewhat lower levels.
And I, you know, I don't have this resolved, but that's always a concern for me when something,
I mean, we've, we've all stepped back away from anything smelling of symbolism, but
there's still monolithic tendencies that I think may yet prove to be a little bit of a retarded
for it. But the, you know, the important things about what an AI does is digest its experience
into a state representing, you know, its view of the world and how it predicts things going forward
and how it needs to have motivations both internally and externally imposed. These are
core that, that are completely unaddressed by the, you know, the current, the current sensation
with the large language models, you know, these take a very, very wide context and they throw
something at it and you get an answer out the end. And there's enormous value. I don't want to
take anything away from everything that's being done with that, but that's not how our brains are
working. And I think that there are important things that, that it doesn't, that it doesn't
encompass. And yet every lab in the world is throwing so much of the dominant share of
their resources at that. So being a little bit contrarian, both of us, I think is, is a positive
thing. Yeah, I'm glad you used that word. That seems like a word when I first thought of, of, of
you and Rich, I was like, well, those two things I know you're aligned on being contrarian, but I
don't know if you can be aligned on being contrarian. I'm going to ask you one more question, but I'll,
I'll say that I'm going to open this up to the audience for questions after this last question
and the microphone I believe is over here. So if you want to rush to get in line to ask a question,
I'll let you do that while I ask my last question to John, which is, you know, what's,
what's your future? You talked a little bit about 2030 as being a goal of, we might see some AGI,
but maybe you could describe what, when you say there's a 60, 50 to 60% chance that it happens
by 2030, paint me a picture of what happens, looks like. So it does appear that I, you know,
I'm a person of decade-long efforts where I, there's a spectrum of useful there. There's a lot
of people that have 18-month kind of passions and cycle through and you get more breadth with that,
but I've been a fairly in-depth person, you know, overlapping with, you know, gaming and
rocketry and virtual reality and now AI, and I fully expect this to consume a decade of my life
or more. So I certainly wouldn't give up in less than a decade, and if things are going well,
it'll carry on longer than that. I do intend us to stay intentionally away from anything
smacking a commercial product. I think that it is important. So this is one of the things I do
struggle with a lot though. I mean, there's, there are all of these things. I'm far from having this,
I, you know, surety of direction or anything. One of the problems that I had a lot at META
was a lot of the research I thought was actually not particularly valuable, that it was building
for things, and I wanted everyone to concentrate just on product. You know, with, you have product,
there's a million things you can do, just do those million things, don't look too far ahead,
and yet here I am doing exactly the opposite, and I, you know, I have the arguments with myself,
do I have a legitimate reason why this is different, or should I just be doing some data
generation startup, you know, the, the 10 companies that want me to help them do game
generation with generative AI, there's, you know, there's tens of millions of dollars just to be
had at the drop of a hat to go do something like that, and I can't say with surety that
that's not true, that you don't learn as much along the way building those skills there,
but I, my hunch, my bet that I'm making with this company and putting my effort into it is
that there are a number of things that are very important, that are not immediately commercially
valuable, that contribute to the big brass ring of the big deal there, so we have,
just today we spent most of the day at white rooms, at conference rooms, kind of talking about
finding out what areas we're aligned on, what areas we think need to be explored,
I, hashing out a little bit of differences in understanding on some of the air, the questions,
but I have a, you know, a series of things that I'm building up that I hope will demonstrate to me
that we're at least on the right track, but in the end, you want to get something that winds up
being sort of a virtual being that you can delegate tasks to, that's not just a chat bot,
it's not just a tool that you use, but it starts winding up being options in remote
employees for, for companies where you have the option of like, oh, I liked working with AI Tom
before I'll take five more, you know, of him, put them on the different tasks here, and that's,
I, you know, at the end result, so many of the things that humans do now are mediated by
computer interactions, and the pandemic really did put quite a point on that where
more things than people would have thought possible five years ago really are capable of
being done just through the computer intermediation. And I think that, you know, that is the opportunity
to have this golden age of creative power and ability with magnifying all of that.
Awesome, thanks. I didn't see anyone walk over to the microphone, which I told you,
there's no hand raising just to be clear. There's no hand raising, you have to walk to the microphone.
Take it away. Hello. Thank you so much. So I have a question about kind of this path
towards artificial general intelligence, and I'll kind of frame it in terms of quake. So
in quake, you have fast inverse square root, which was a method that no one would have thought of
to do this process much more efficiently. So I'm wondering when you think towards the path of
artificial general intelligence, how much of it do you think is these ideas that no one was thinking
of that are just a little bit more efficient than before? And how much of it is kind of a combination
of ideas that we already have and that are floating around our circles? Yeah, so there's
some interesting aspects to the question of efficiency, where I have to guard my time to
not spend too much time on optimization, because I love that work. It's like a vacation for me to
have something so clear, just make this number go down. That's fun for me, but it's not the most
important thing, because in so many ways, making something two times faster, four times faster,
even 10 times faster, if it's not on the critical path, that's probably not the right thing to do
now. Now, where it does matter, you get into factors of 100 and 1000, and there are architectural
choices that you make that have these three plus orders of magnitude importance. And those are
important that you not mess those up, that you not do something. And there are architectures that
you could make that are just going to be like involve pointer chasing or something that are just
not going to be good enough, because three orders of magnitude matters. You can't run your experiments
in time, you can't deploy it and all that. But on the other hand, there are some architectures that
may be important that just because they're not easily expressed as tensors in PyTorch or Jax
or whatever, that people shy away from, because you only build the things that the tools you're
familiar with are capable of building. And I do think there is potentially some value there for
architectures that as a low-level programmer that's comfortable writing just raw CUDA and managing
my own network communications for things, there are things that I may do that others wouldn't
consider. And one of the aspects is the boundaries that we put on the things that we're going to do,
one of my boundaries is it has to be able to run in real time. Maybe not from my very first experiment,
but if I can't manage a 30 hertz, 33 millisecond sort of training update for a continuous online
learned algorithm, then I probably won't consider it, because I do consider that necessary for
even while you might grow in a simulated world, at some point people aren't going to really buy it
until they're having a Zoom call with the AI and poking it in various ways and having conversations.
That ability to run in real time goes against the current grain, because things are moving up to
you use a warehouse full of computers, but your step time might be a second and a half or something.
There are alternate ways of structuring your systems such that you use a warehouse full of
computers and you get a 30 millisecond time, but you can't do that with the tools that most people
are using today. So I hope that it does have some benefit, but that's one of those speculative things.
My background may let me do something that might be important, but I can't say with any
confidence that it actually is critical. That's awesome. Thank you very much.
All right, next question. Hey there, John. So I'm a huge fan boy. I just wanted to say thank
you for everything and you've done for this industry and specifically thank you for building Quake.
Excellent.
Quake was a very important game for me for both my social and professional life. Thank you.
But my question is about who in this world has the ability to build the next great thing?
In my mind, throughout history of computers, there's always been like a sole person or a small team
and not some giant corporation that's really pushed things forward. Every programming language
was created by like one or two people. There's Linux. Google was famously started by two dudes in
a garage. Your former employer, Facebook, was created by one guy or one set of twins, depending
on who you ask. And I basically believe you created a lot of these technologies on your own.
But when we look towards AI and VR, there seems to be like these huge requirements for enormous
amounts of data, big training sets, multi-million dollar compute time. So I ask like can a small
team still build the next great thing? So there are, I would say most projects in the world of
importance actually do need larger teams and resources. Building commercial infrastructure,
building highways, these take large teams. And even in the software side of things, building
Chrome takes a large team, building Android takes a large team. And these are super important things
that the world runs on to some degree. So the default state is it probably needs a lot of people
for these big things. But my point about AI or AGI right now being this potentially unique
point of high leverage comes from my belief that I have this whole set of spiel about how
the data is not that large, the compute is probably not that large in the larger scheme of
things. Like a point I make, a year of life is a billion frames at 30 frames per second.
And that fits on a thumb drive. And you can tell that a one-year-old is a conscious intelligent
being. So it does not require all the data on the internet to demonstrate artificial general
intelligence if your algorithm is correct. The arguments about how much compute you may need
are, I don't have as ironclad positions about that, but I have plenty of reason to believe
based on the capabilities of what the networks are doing today and the size of the brain and the
parts that we think we understand what's going on, that it is not a warehouse full of computers.
I mean, I don't think it's one node or even one rack, but in that scale over the course of the
coming decade, we will factor that by, it will be another order of magnitude less. And I do think
it's inevitable, but there is this period where well-healed individuals right now can potentially
take a crack at this. If none of us make it, then eventually it's going to get to the point where
every grad student has the resources to take a stab at these problems and the problem will fall
shortly after that point if it hasn't fallen before that. But I think we're in this magical time
right now where it is a golden opportunity. And I'm honestly surprised that there aren't
more people. I mean, there are hundreds of people like me that were technical people that
succeeded, sold companies, have the resources to go and apply this. I'm kind of surprised that
there aren't more of them taking small stabs at it because even if you think you've got one tenth
of one percent chance of kind of making it and getting all the way, it's kind of a Pascal's
wager sort of thing where the expected value from that, if you have no fear of ruin, is still quite
significant. Great answer. Thank you so much. Hello, John. So I understand that the AGI Gold,
my team, a little bit abstract. So my question goes towards, if you're taking steps towards this
goal, how are you making sure your, how are you measuring your progress? Are you decomposing it
into some problems? Like what are the proofs for the steps? Or maybe abstractly, are you sure
you're going to be making progress towards this 2030 goal? Yeah, so I'm not at all sure about it.
And it is almost one of the key questions. How do you gauge whether your child is growing properly?
Do you have things that are crude like the basic responsiveness tests about things? You track
pupil movement, but how do you tell at the earliest level before a billion steps have gone by what
level of cognitive processing is going on there? And I have like my angles on this involve, you
know, like moving foveas and centers of attention. And there's low level things that I can look at
and say, I believe in intelligence should be following these patterns. And I have these indirect
measures that I can make of it. But I dearly wish that I had better objective measures because
it's undervalued how critical benchmarks were to the pace of this last decade of terrific AI
progress where turning things from a discussion section into numeric values. And yes, there's
downsides and people talk about grad student descent of the problems with leader boards and
different things like that. But overall, it's been enormously valuable. And I, you know, I do worry
a little bit even with the LLMs that I don't really buy a lot of the measures of how they're
benchmarked against each other. And it's an even harder problem for AGI. So I wish I had
a better answer to that because I think it's important. But I think that there's at least
directions that we could be following that we feel pretty good about. But it's entirely possible.
Years could go by and it turns out it was the wrong direction, but it's still worth the try.
Okay, thank you.
Yeah, I had a question about the kind of AGI you visualize building at Keen. So when I think
about AGI, I think there's an embodiment, there's an actual robot functioning in the real world.
So are you thinking about something which is animal like or human like, or is it come
completely virtual? Alright, so I'm not a fan of robots, which puts me at odds with Joseph here.
And, you know, it comes from, of course, I'm the virtual reality guy. So I believe in simulation
and the general ability to, you know, to do valuable things in simulation. While robotics puts
much of the value of working with robots is this discipline of saying you're going to be real time,
you're working with reality, you can't just get slower and slower and make your model better by,
you know, by scaling it in a way contrary to time. So I think that that discipline can still
be maintained in a virtual environment. I am. And I think that's the primary benefit. And there's a
lot of downsides to robots where I did spend over a decade building rocket ships and that drives home
sort of that, you know, the cussedness of physical things. And the less you can be forced to work
with physical objects, the better in most cases. So I think in general, I don't expect us to be
doing anything robot based. Now the question of exactly what simulated environment you have,
there's a broad range there where like right now I'm working with sort of this 2d infinite movie
wall of like moving around looking at different things. And there's a degree of agency there.
And you could learn about 3d environments and you can put 3d games inside there. But to me,
like it's an open question, should it be a virtual reality environment of instead of a
virtual 2d wall? Should it be a physical space where they have to like walk around essentially
to look at different things? And I don't know, I'm leaning towards the simpler salute, the simpler
possibilities right now. But if it turns out that I wind up making a full fledged, I am, you know,
game engine rendered virtual world, I wouldn't be at all surprised if that's where we wind
up in a year or two. Thank you. Thanks John. So it's very special to have you joining our community
here in Edmonton. And when Rich emailed you, you must have thought to yourself whether you wanted
to start this partnership. And obviously you did. So I was wondering about what were the behaviors
that you saw in this community that wanted to make you join our community? And more broadly,
like what should we hold on to? Because we might have taken it for granted because we've been
fostering for so long. Yeah. So the, you know, initially I did not get my hopes up. I was just
like, Hey, it's cool to be having a communication with Richard Sutton. And I was going to try to
my helpful self as much as I could be. And the fact that we did wind up hitting it off well enough
that it's almost remarkable how many areas of overlap that we've got in terms of the way we
look at this. And, you know, in some ways, both me and Dallas and Rich up here in Alberta,
it is, this is not the center of gravity of artificial intelligence research. I, you know,
we are in our own way in the wilderness. And I think there's some commonality that came from that
where there is, you know, there is this kind of fashion in research and especially in the
commercial side of it. And the current looking at things like the reinforcement learning and the
real time online continuous learning, these are not the current fashion for things. I, you know,
great strides are being made with large language models, large batch training, slow steps, inference
only. And, you know, and that's all great. But everybody should be aware that this is not the
be all end all, it doesn't solve all of the problems. So somebody's still got to be looking for
the remaining answers, you know, we don't have them all. So being willing to go against the grain
and to, to step a little bit outside and have a lot of people say, Why are you working on that?
You know, that's not the, you know, the mainstream. That's not where you can go impress the VCs or
whatever. But at some point, somebody has to solve some of these problems. And, you know, the willingness
to go ahead and do that, because you think that it's the right long term solution. It's I, you
know, I do tip my hat to the kind of the academic virtues of you are trying to find truth, you're
trying to find, you know, the knowledge and the way to solve these problems in the hopes that
then they will be applied into the world to produce great value across the different areas.
But yeah, the biggest thing right now is we're both outside the mainstream, but we both have
conviction and we have, you know, reason to believe that it's a profitable direction to be
pursuing. And this is far from the only direction. Again, I'm surprised that there aren't more efforts
like this going on, rather than having the 10th company training their own large language model
to compete with something. There are other interesting problems that may wind up being
even more important. And being excited about the general technology while kind of picking a path
that's not just following somebody else's trail in the specifics, I think is important. You know,
the world needs more people like that. Thanks. Hello. I'm very excited to hear about this
partnership that you have here. And so one of the things that I like about it is that there's a
lot of blue sky research that you sort of have in mind, right, that for the next seven, 10 years,
whatever, there's going to be a lot of focus on these fundamental things, some maybe online,
real time algorithms to do certain things. But you also emphasize that there is no need for a
tangible product in, let's say, in this timeframe, right? So all this sounds very much like an
academic lab. And while this is certainly not one, right? And perhaps, so my question is out of
curiosity that, is this something you are specifically guarding against? Because like deep
mind and companies like this also started with a similar perhaps intention, right, that lots of
blue sky research, solve intelligence, use that to solve everything else. But now, maybe it's not
exactly the same anymore, right? So are you specifically guarding against that? Or is that
something you don't really think about? So I am unashamedly a capitalist. I, you know, I do,
I think that this could make me a trillionaire if everything goes well, it's worth, I, you know,
it's worth kind of aiming for some things that I, you know, producing value, I think it's good for
the world. I mean, I deeply believe that building commercial enterprises is most of what has made
the world what it is today in a very positive sense. So, you know, and I don't have the academic
background, I am, you know, I respect, I recognize I'm standing on the shoulders of all of the academic
work that's been done before. And it was funny because I talked to, I'm, you know, ahead of a
university one time, and I was kind of mentioning how I feel a little guilty being a commercial
company that is built on lots of this research. And he said, you know, your tax dollars have paid
for a whole lot of this research, don't feel bad at all. You know, this is the point of all of this
is to let people try to build on it. So, yeah, it's, it is a commercial effort. And part of that
was a focusing tool for myself, where I spent kind of the prior few years in what I call Victorian
gentleman scientist mode. I was kind of styled like Darwin or Babbage, where I'm a rich guy that
can buy all the scientific tools that he needs and can kind of have my backyard laboratory for
things. And, you know, and I learned a whole lot. I spent the time kind of going through this
extended larval stage about finding out what everybody is up to and getting myself
up to the modern standards there. But it always gave me an out, you know, just at that level,
I could think of it as like, well, it's almost a hobby. I could just quit at any time. I could
divert my time any way that I want. And I had had several, several different organizations
pestering me about form a company, take our investment money. And I didn't need it for the
money. But I looked at it as a focusing tool, where I have in many ways an overactive sense
of responsibility to, you know, to investors, you know, it, it killed me at, at meta, just seeing
all that money going out, I went and like, no, turn it into profitable businesses earlier.
So that is an aspect of it. And then hiring employees means it's like, okay, now I've got
people's paychecks that I am responsible for. So it makes me focus better on the, you know,
on the tasks at hand as well as actually bringing the resources to bear. So yeah, in some ways,
it's a pure research play. And, but at some point it turns into if it works products that
really literally reshape the world. Thank you. Yeah, so I think you touched on this a bit earlier,
but I'm sure many people have tried to hire Dr. Sutton before and failed. And so, yeah,
like, could you talk a bit more about like, why you succeeded where no one else could and was it
like fully attributed to being aligned or? Yeah, so I still, you know, I still wind up
being happily surprised that I'm here today with this because I, you know, a couple of times I
just said, I know you can write your own ticket anywhere, you can go to any of these companies
and everybody would be happy to have the father of modern reinforcement learning just
in their collection. And for some big companies, it is almost like a Pokemon collection,
you know, collect your favorite researchers and, you know, make sure they're on your team and your
deck. But I, you know, I think, you know, part of it is that we want to actually do these things.
It's not about prestige and being out there and kind of staking a claim. We want it to exist.
We want to build it. I am, and I think that there is a sense that a smaller team, there's, I mean,
there's all sorts of drags and friction that you get in big teams. It is wonderful to have a 10,000
GPU cluster that you could go ahead and just kind of get time on whenever you feel like it.
But I am, again, I've got enough options for, you know, for doing things like that,
that I don't think that's going to hold us back. And the ability to have a purity of focus, I think
is important. But I'm, yeah, I'm, I'm still, you know, really very happy that it all worked out this
way. Thank you. Hello. Thank you so much for the talk, John. It was fantastic. So my question
goes back to the discussion about game development and open source. And I would like just to hear
your opinion about what is, what do you see as the future of open source software in the video game
industry, especially since it's a world full of full of IPs and proprietary platforms?
So there is, you know, right now is an interesting inflection point because Unity had their whole
change their terms of services. And this is making a lot of people reevaluate what they're doing.
And it's been a long time since I was really close to the work being done on the open source engines.
But, you know, I believe it's fair to say that Unity with all their employees, they do a lot to
make it a comfortable, cozy development experience. They do provide a lot of value. And you do get a
lot of open source crusaders that just don't acknowledge the value that the commercial companies
bring to the table when they build their software. Because there are a lot of blind spots that the
open source teams, it's, it's weird how the DNA of the people that are willing to work on open
source wind up with certain important blind spots in the kind of applicability of their
software and usability. You make super powerful tools, but, you know, they're not very comfortable
and it winds up making them not the right call for a lot of people. But like I said, I very much
respect EPICS in between position where even if you don't pay them a cent, you can read every line
of code and learn from it and understand how things work. You can pay reasonable license fees.
Having competition there is great, you know, letting people choose. And I always thought that
the trade-offs between Unity and Unreal was a nice market balance to have. And like in virtual
reality, 95% of the developers wound up with Unity because of just the crowd that was attracted.
But it was always expected that if you need serious control, you'd then go with Unreal and
you could write things at a lower level. So there's an opportunity now, I think there will
inevitably be some larger move after Unity stumble here to open source projects.
I don't expect it to be a tsunami that like accelerates and takes over everything because
there are just so many of these grubby business things that are just not fun to do on the open
source projects that I, you know, I could imagine a scenario where somebody like, you know, Meta
gets behind open source things and winds up helping do some of the unpopular, unfun things
for their own kind of self-interested reasons that could be positive. But I think I'm resigned to
a slow pace of migration towards more open source tools. Again, at this point, 30 years back,
I'm disappointed that we aren't further along there relative to like compiler tool chains and
things where the world is a better place for having those be almost universally open source.
And we probably could have been there on some game engine type things, but I don't think the
fundamental reasons why we're not have changed. So I think it's going to be modest changes going
forward still. Thank you so much. I'm being told we're almost out of time and we have a line of
six people. So I'm going to go in a lightning round mode and you get 10 seconds to ask your
question. I can actually hang around a little bit after the actual official end.
Okay. Well, so I worked with Mike and Rich at DeepMind and actually some friends and I left
DeepMind to create a startup here in town using AI to make AI in video games. So first of all,
thank you for not shooting to make a commercial product in the next couple years in the AI and
game space. But my question is more like, I know Rich has a really strong commitment to open research
and it sounds like you embraced that as well with the hacker mentality. So
what are the plans for Keen to like share your insights, your breakthroughs, maybe even your
code? So this was one of the significant conversations that we had. And Rich does
understand the importance of commercial businesses and that there's reasons why these are
fundamentally important and the incentives matter. And there's a talk about like, yes,
I did champion a lot of releases of different things and I would, there's certain technologies
that I'm happy to have us publish. There's other things more like around experiment design and
architectures that I probably don't want us talking about. And it's going to be in a situation like
if, if somebody wants to write a paper about something, we'll have a conversation about it.
And if it's, you know, if it's something at the very tactical level, like, hey, this is an
interesting way to do an optimizer. This is, you know, another way to calculate your, your,
your TD assignments, whatever, that's, that's probably fine. But here is the architecture
of what our proto AI, AGI looks like that's probably not going to be talked about. Because
all of these are going to be things that we see it today where all of the major laboratories,
they can reproduce anybody else's work with a couple sentences of direction and a couple weeks of
time. And I think that's going to be the case for AGI as well. When, you know, when it does all
get solved, the textbook from the future is going to have a relatively thin chapter about this is
actually all that's really required built on the baseline to make it happen. So yeah, there's some
sense of secrecy. And then there's real concerns about any real company is going to have employee
turnover, they're going to walk out the door, you know, NDA or not, they're going to know what the
things are. So there is a large part of this gamble on even if all of this value gets developed,
much of it may dissipate into the broader world, which is great for the world, not so great for
my investors, but we're all still collectively willing to take that risk. Thank you. Okay,
it looked like lightning round didn't work. So I'm going to call it here because we're out of time,
but John has very generously offered to answer some questions. If you have some, we'll make
sure we start with this line first. Yeah. But let's first thank John for telling us so much
insight about his past, present and future. All right, thanks. Do I have to vacate the stage?
Yeah, I don't know what we do next. Thank you. Bye.
