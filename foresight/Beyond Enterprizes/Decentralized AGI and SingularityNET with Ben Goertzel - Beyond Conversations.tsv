start	end	text
0	2000	You
30000	32000	You
60440	62440	You
74600	76720	Welcome to beyond conversations
77520	80720	Today's episode is very exciting
81240	84480	it has to do with a hot topic that
84680	91800	Has been brewing for years or decades even but it is now
92560	94560	on the minds of
96000	99160	Much more numerous group of people
100280	104200	Really orders of magnitude potentially more than before
104920	111680	Thanks to recent developments and it is the topic of artificial intelligence
112240	117320	My name is David or Ben and our guest today is Ben Gertzel
117680	119680	Ben is a cognitive scientist
120200	124760	Artificial intelligence researcher. He's the cof and founder of
125520	127440	singularity net a
127440	131920	project that aims to democratize access to artificial intelligence and
132720	136120	He actually helped popularize the term
136840	142920	Artificial general intelligence which refers to the goal of creating machines that can perform
143360	146400	Any intellectual task that humans can?
147240	150040	Welcome Ben to beyond conversations
152320	155520	Hey David, thank you. It's a pleasure to
156240	162440	Go over these topics with you for what is a not the first time right you and I have been
163160	169200	Digging into these issues. I mean presumably since way before we met each other
169200	173600	I've been thinking about these things since the early 1970s, but we we must have been
174520	176360	talking among
176360	181400	Ourselves about this for 15 20 years or something quite quite quite a long time
182840	188560	That's correct. I am I am proud to be your your friend and full disclosure
188760	192960	I'm also the chairman of the singularity net
193760	194880	supervisory
194880	197960	Board we will have an event
198520	201200	in just a couple of days
202120	207720	talking about the next phase of the singularity net decentralization and
209040	212320	That will be also an interesting opportunity to talk about
213040	218120	Governance that is the reason why we are not going to maybe touch that
218560	220560	as much today
220720	222000	but
222000	224200	Why don't you highlight maybe
225320	230400	Some aspects and recent developments of the singularity net
231160	232280	ecosystem
232280	234520	Which is developing so
235400	237400	rapidly and so broadly
237760	239440	that I'm sure
239440	245360	Just you know mentioning a few of the most recent components would be would be helpful
246040	248040	Yeah, so I've
249960	254400	Been thinking about the singularity and the the future and
255840	262160	AGI before the term singularity or AGI became became became current right and and
263120	265120	I've been
265160	267160	working on trying to build
267400	271240	Thinking machines or build toward the building of thinking machines
272160	279200	Actively since the mid 1990s now as soon as the internet came about in
279920	286600	The in the in the mid 90s and the dot-com boom in the late 90s. It was it was clear to me, you know a
287560	289560	In one way or another
289600	293920	the birth of the singularity and AGI and all this was likely to be
295160	300640	Distributed widely across a bunch of different machines rather than being in just one
301680	307640	Super computer sitting in some secret lab or in in somebody's basement. I mean not not that this
308480	310480	physically centralized approach
310760	314280	Was impossible, but it just didn't seem to be the way
315120	321440	Things were going right like I mean, I'd known Danny Hillis. It was building the connection machine this massively parallel
322080	325840	AI supercomputer and it was brilliant and fascinating
326600	334400	But the tech world was obviously evolving in a in it in a different direction both in the physical infrastructure being distributed and
334880	338000	the emergence of collaborative networks of people in
339320	345200	Far-flung places working working together to bring things into being so actually I
346840	352240	Started thinking in 99 2000 about how do you use strong encryption and
352400	354400	and
354680	360400	Distributed processing and how do you bring these together to create?
363680	368520	Distribute decentralized AI networks without a single owner or controller almost some
369080	375560	Emergent aspect to the intelligence in the in the network, you know, I ran into serious
376560	382360	Practical obstacles at that time. I mean I was working with Java 1.1. It was just really
383080	387080	Really slow machines didn't have the ram they do now networks fees weren't what they are now
387080	391120	I I didn't hit upon the idea of starting with decentralized money
391560	397640	Instead of decentralized AI if I had I would have been Satoshi, which unfortunately
397640	401760	I'm not and my AI projects would be tremendously better
402120	409760	Founded although we're not doing incredibly badly, but you know, it was clear then as soon as the internet came about it was really clear
410720	418840	You needed decentralized control and then when if you fast-forward to 2015 I saw Ethereum came out and
420120	423440	You had the notion of a smart contract which was clear to me immediately
424200	430000	Was neither smart nor a contract. It's really sort of a persistent script sort of involved in a
430800	437400	Decentralized validation and consensus mechanism and I hated the Solidity language from from the get-go just as a
438040	444920	Computer scientist and from up from a programming language perspective, but it was clearly the beginning of something incredible, right?
444920	448960	Like you were you were able to write these relatively simple
448960	454360	I'll be ugly looking scripts that were sort of nodes in this global world's computer
454360	458040	Which it would seem by putting the right thing in those scripts
458040	462320	You could then make them nodes in the in the global brain, right? And this this was super exciting
463200	466000	This led in 2017 to me founding
467320	469320	Singularity net which was
470440	472440	basically an attempt to make a
473360	475080	platform for
475080	477560	allowing multiple AI agents to
478400	481040	cooperate and collaborate in in
482040	484040	Flexible ways so from an AI view
485040	490840	The idea is somewhat like what pioneer Marvin Minsky called the Society of Mind
490840	494560	and I don't I'm not actually quite as far in that direction as Minsky, but
495240	497240	His thinking was inspirational here
497240	502280	He was Minsky was looking at a human mind or any mind in his view as a
502880	505720	Society of smaller agents each carrying out particular
506720	514860	Fragmentarily intelligent functions and then all cooperating together to achieve sort of emergent dynamics of intelligence now minceki
515720	522880	means he didn't like nonlinear dynamics and complexity and chaos which perplexed me because there's a strong emergence aspect to the
523480	528680	multi-agent systems that he himself was was putting forward he was a complex and
529680	535400	Fascinating character unfortunately isn't with us anymore. I'd love to bring him back if post-singularity
536360	538360	Techno technology
538400	543760	Allows, but anyway with singularity net we basically created a decentralized blockchain based platform
544600	549560	for multi-agent systems anyone in the world can put put an agent online they can
550080	556920	Have that agent announced by the singularity net protocol. Hey, I'm here to all the other agents running the SNP protocol
556920	562840	Then they can they can pay other agents and that work for services. They can outsource work for them
562840	566280	They can cooperate together doing tasks. They can rate read each other's
567640	574440	Reputations and we we rolled out a version of this platform a few years ago. It's still getting better and better. So I
575280	582680	Mean we're pretty close to rolling out what we're calling the AI DSL domain specific language for a eyes, which is a special
583680	590360	Programming language for the AIs to describe their properties and capabilities and preferences to each other
590360	596520	Which is a key ingredient to allow automated assembly of different agents into into
597480	599480	Collectives in
599520	602720	In building this though, we realized there was a lot of other
603960	606400	Missing pieces you need to get a whole decentralized
607400	610400	Text stack which leads to some of the other
610960	613320	Interesting things going on in singularity net
614280	616560	Ecosystem right because sing singularity net
617040	623240	We have we have the core protocol and platform built by singularity net foundation and an open source community
623800	625800	Then we have a number of different
626960	631560	Entities which are part of the ecosystem that are building stuff using this platform or
632400	634400	building sort of foundational tools
635360	643280	Complementary to the core singularity net platform forming part of sort of decentralized tool stack and that that gets into new net which allows
643800	645320	decentralization of
645320	650280	Processing power and tokenization of processing power in a flexible way suitable for AI
651040	653040	then the open cog
653800	655800	hyperon toolkit which is our
657560	662480	Probably main thrust in terms of how to actually build a GI on this decentralized
663360	667880	Platform and you can build a GI in any way you want on singularity that platform
668240	672320	Hyperon is our particular sort of neural symbolic evolutionary approach
672320	678920	Which we'll talk about more in a few minutes when we get into a lot of lans and stuff and then then there's hypercycle
679400	681400	which is a
681880	685520	collaboration with two fee saliva and dense toliver and folks from the
686240	688240	Tota ecosystem and
688680	689760	hypercycle
689760	695360	Like new net and hypercycle both live in a way below singularity net in the tech stack
695360	698000	Right new net tokenizes the processing power itself
698280	705760	So if you can contribute processing power for tokens and receive tokens for processing power and that process power can then run singularity
705760	707280	agents or other things
707280	710000	hypercycle is a layer one blockchain
710880	712880	customized for AI and
713120	715120	You can run singular on
715680	721800	Ethereum we can we're most of the way there to making able to run it on Cardano as an alternative and Cardano
721800	726320	We found more efficient and scalable than Ethereum for AI purposes hypercycle
727320	735560	Customized blockchain just for for AI will let singularity net decentralized AI agents run in a much faster and and more scalable way
735560	737560	And I mean hypercycle is designed
738760	742360	To work very closely with Cardano in particular
742760	744920	But it's a different design we get rid of the ledger
745080	749560	So that's probably more than we can go into in depth in this in this call
749560	757320	But if you look at Ethereum Bitcoin and so on they're all based on this replicated ledger that stores all transactions have ever happened in the blockchain
757320	759320	Right so in in hypercycle
759760	767680	We get rid of this ledger and store transactions sort of fractionated all throughout the network in a more localized way
767720	773680	And this this lets you have a much more efficient blockchain underpinning for for
774640	780880	Decentralized AI so we we've been working hard on all these aspects of a decentralized infrastructure
781120	788120	And now we're feeling a need to like move way way way faster even than we then we've been doing because we see like the
788640	790640	Centralized tech be a moths
790880	797400	Well, I don't think they have the golden key to a GI the centralized tech be a moths are certainly getting
798160	800160	extremely interesting AI
800440	802440	functionalities
806760	814400	Thank you for that that introduction to the singularity net ecosystem and let's now as you mentioned jump over to LLM's
815040	818920	large language models a lot of people in
820080	821600	like
821600	823600	moving goal posts and
824600	828760	Always defining AI by the things it cannot do
830440	833640	When it couldn't play chess very well
834760	836760	People would say oh AI is
837600	842440	Playing chess and then when it could beat every human
843440	847660	Suddenly it it wasn't chess anymore. Now. It seems to be
848600	850600	natural language processing
850880	853380	and chat GPT which
853760	858320	Now everyone knows I am sure everyone following this
859360	861360	video stream
862440	866480	Is able to manage text in a manner
867320	869320	that I would say
869440	873400	many humans cannot do it creates a
874080	876080	text that is
876760	878080	competent
878080	881560	in many many different fields now a
881840	883000	a
883000	888000	That was sufficiently surprising including two experts
889000	890680	to
890680	892680	generate a
893360	895360	Particular alarm
895560	898800	Not about what it can do now, but it
899520	905200	What may be able to do in in the near future and there was this open letter
906200	907600	A
907600	909600	Formulated by the future of life
910160	917840	Institute at MIT and signed by a bunch of people and not signed by another bunch of people and by the way
918200	923400	We belong to those two different camps. I did sign the letter and you didn't and
924440	929640	I feel that these these agreements are very very healthy
930640	938880	Especially in a decentralized and distributed world if we were in complete agreement and alignment about everything
939320	941320	Then there would be no reason
942000	947560	To experiment with different approaches and we would just be in a single
948240	950240	hierarchical centralized field
950560	952560	so a
952920	959440	The open letter has been interpreted and in misinterpreted in many ways
960040	961440	but
961440	963440	very simply it says
964600	967040	Let's in my opinion it says
968200	972360	Let's give a little breeding space
973680	974840	for
974840	977280	everyone to understand what is going on
978800	980800	especially
981200	988880	To those who are in charge at these large tech companies and the regulators
989680	991000	who
991000	998000	Should be moving faster and should be looking at what these tech companies are doing
998640	1004200	Six months, which is the pause of the open letter is not going to be sufficient for sure
1005440	1011440	But at least it raised the conversation about this need so
1012640	1014640	Two questions to you
1014920	1016920	one
1017240	1019240	What
1019800	1021800	Makes you feel that
1022760	1024760	This is
1024920	1026920	Not necessary or not useful
1027800	1029000	and
1029000	1030680	to
1030680	1036240	What are the things in your opinion that are missing from the large language models?
1037200	1039200	that
1039320	1040960	would
1040960	1042960	require the kind of
1043760	1045760	careful
1046760	1049720	Steps that the open letter advocates
1055680	1060440	So I think as the singularity approaches
1062440	1064800	And I think it is approaching I
1066160	1072520	Still see Ray Kurzweil's prediction of human level AI in 2029 as a reasonable stab
1072520	1076760	I mean, I think we may get there a few years in advance of that
1077400	1081800	I'm pushing for that. It may take a few years longer, but I don't think it's going to be
1083280	1084760	Many decades longer
1084760	1089680	I mean if it turns out somehow human level intelligence requires
1090200	1096560	You know advanced quantum computing or quantum gravity super computing maybe that could make it take a few decades longer
1096560	1100440	I give that a not zero but very low percentage
1100680	1105600	Chance based on everything we know about the brain and everything we can do with with computers now
1105880	1110000	so if that's true that the singularity is coming in
1111120	1115160	Five to ten years three to ten years. Whatever at least
1115760	1121960	Human level AI coming then which will certainly accelerate the next stages of progress towards super superhuman AI
1122360	1124360	there's going to be a lot of
1124360	1126360	crazy things going down a
1126640	1127800	lot
1127800	1132960	More impressive and a lot more disturbing to some people then then chat GBT which in the end is a
1133760	1137800	Rather banal and only half useful chatbot
1137840	1146600	Although very very very impressive in in many ways compared to what what came before right and I think in in dealing with these sorts of
1147560	1148840	unprecedented
1148840	1150840	crazy seeming situations
1152760	1154760	Some basic
1155760	1163000	Principled thinking is is helpful. Otherwise when we just swung around like crazy by the wild weird things that are
1163400	1170480	That that that are happening and so max more who we both know who's been one of the leading philosophers of transhumanism
1171680	1173680	Articulate some time ago what he called the
1174720	1182040	Proactionary principle which was intended as a contrast to the precautionary principle that others had talked about and the
1182680	1184680	precautionary principle is basically
1184760	1188080	Better safe than sorry hold off on new developments
1188520	1193280	You know until you know for sure they're not going to cause harm and this
1193760	1199120	This was the principle of Australian indigenous society for which allowed them to be
1200000	1201440	fairly
1201440	1208240	constant and stable for 60,000 years and they had they developed many things of great beauty in this in this stable
1208960	1214360	Society and develop their consciousness and dimensions that are not that common in our modern world
1214760	1220680	It's been a principle in Chinese history. Certainly. I mean if you look in the 12th 13th century China had
1221120	1226200	quite advanced technology all sorts of machinery and so forth and then they they sent
1226480	1228880	sailing ships all over the world and then they decided to
1229560	1234000	Stop that because it was being disruptive and they didn't know where it was going to leave right now
1235800	1242120	Modern Western society has generally not proceeded on on this sort of basis, which is really
1242640	1251280	Why we've developed computers and AI and the internet and modern medicine and gone to the moon and all this stuff, right? We have
1252400	1254400	Implicitly and with a lot of argumentation
1256440	1261520	Along the way, we've largely followed what max called the
1263440	1266320	Proactionary principle which basically means
1267320	1274720	You know get have a bias toward doing stuff and not making prohibitions and a buy bias toward letting processes
1275800	1279840	Unfold in a in a natural way without trying to blockade them
1279840	1285840	It doesn't mean there's nothing that you should ever prohibit and and and try to stop
1285840	1293840	I mean, I'm not advocating selling briefcase nuclear weapons in Walmart, right? But it it means that when when there is
1294840	1305440	Complex technologies complex situations with you know richly nuanced and balanced pluses and and and minuses and
1306320	1311480	It's hard to understand the implications for good or for bad in a situation like that
1312280	1314920	the proactionary principle would argue
1316800	1319920	Just do it and you know keep an eye out
1320480	1326280	Watch watch to be sure. You're not doing anything extraordinarily dangerous, but don't don't be
1327280	1333560	Paranoid don't be a wimp and you know look at look at the the cost of not doing something along with the costs of
1334680	1338080	Doing that thing and so justifying
1339040	1341040	Proaction versus precaution
1341280	1345520	on a sort of historical societal and philosophical level is
1346000	1349840	Very interesting and important would be would be a long long and deep
1351200	1359280	Conversation which gets into epistemology and metaphysics and all sorts of things, but I wanted to mention that because
1360160	1363840	In general, that's where I'm coming from and I think that attitude
1364560	1368160	Is why we have advanced technology. That's why we have
1369040	1374320	Modern dentistry and and vaccines and then computers and so forth
1374400	1376560	I mean this is why this is why we have
1377200	1379200	developed weird new technologies
1379760	1384800	Which in every case we didn't know what would be the good or bad aspects and how they would be
1385360	1388240	They would be balanced, right? So I do think they're
1389760	1391760	They're cases
1392080	1394480	Where you don't want to be proactive no matter how
1395280	1401040	Gonzo for the for the the future you are. I mean briefcase nukes is one
1401840	1403840	gain of function research on
1404960	1411920	Viruses it can infect humans is certainly an interesting borderline case which society chose to proceed with
1412880	1414800	anyway in spite of
1414800	1420720	Some pretty obvious risks to do to do with the leakage from from from labs and so forth
1421120	1423440	But the thing is with with these technologies
1424400	1426400	nuclear weapons
1426720	1430640	Have very few uses besides blowing people on their possessions up
1430640	1434240	I mean you can use them to blast starships as as freeman dyson
1434720	1441760	Suggested but by and large they're considered a weapons technology. I'm you know taking animal viruses and
1442320	1447840	Uplifting them so they can kill humans better again. There's not a lot of immediate
1449280	1457120	Humanitarian uses for that. I mean the the the the purpose is to better understand them in case they develop later in
1457600	1462720	In nature or something, but I mean AI is different than that, right? There's tremendous
1463760	1468160	obvious positive benefit of these technologies and so then
1469040	1475280	Bouncing the cost of not building the attack against the cost of doing it is complex. But what this also means is that
1476480	1478480	If you try a prohibition
1478880	1484480	Many many actors who are not particularly bad actors are going to wangle the way around the prohibition
1485200	1490880	Anyway, I mean the only reason to what to wangle around a prohibition on briefcase nukes
1491360	1497520	Is pretty much if you want to blow people up or you're a really really really ethics free conniving business person who
1497760	1502560	Wants to make a living selling briefcase nukes to other jerks who do want to blow people up, right? But
1503200	1506160	reasons to keep developing AI are just
1507280	1514240	Extremely numerous beyond wanting to do any anything bad. So I think there there are two things that are sort of mixed up here
1514480	1519040	And they're mixed up in a very natural way. So what what what what one one thing is
1520240	1522720	I think this sort of prohibition is
1523280	1528640	Ethically very very dubious because balancing the good and the bad of this sort of technology is very very hard
1529280	1530880	The other thing is
1530880	1534400	This sort of prohibition will never work and is completely
1535040	1542000	Impossible in practice and I think these are tied together because when the good and bad are all tangled up and complex and hard to assess
1542960	1547280	You know this kind of prohibition is going to be way way hard to put into place because
1548480	1551920	So many parties won't won't go along
1552640	1557360	Along with it any anyway, right and you can you can see both the aspects with this proposed
1558400	1562880	Six-month pause. I mean, I think chat gpt l lm's and so forth are not
1564080	1566080	general intelligences
1566480	1568480	they're not going to be sort of
1569200	1574240	Incrementally morphable into general intelligences just by tweaking the architecture a little bit
1574800	1578640	I do think they could serve as components of general intelligences
1579120	1581120	And whether the llm component
1581440	1585280	Is 60 percent or 20 percent of the final general intelligence
1586000	1590720	I'm I'm more toward the 20 percent side, but I think I think there's still a very interesting
1591360	1597280	Ingredient in in agi systems that that that are going to be built, but they're not agis yet
1597360	1600560	They're software systems. They're very interesting software systems
1601280	1608960	I'm engaged with a few people building amazing commercial applications on top of llm's. I'm also engaged with some research
1609920	1615760	Trying to couple llm's with logical reasoning systems to make them make more sense and carry out multi-step reasoning
1616880	1619680	So that can they be used for unpleasant things?
1620320	1624560	Of of course they can be used for unpleasant things. I mean they can generate a lot of
1625200	1628320	Nonsense so people can be tricked to believe it's not nonsense
1629600	1632160	I mean if we're going to ban things that people can use
1632800	1637600	To fool people and spread bullshit. We're going to ban the whole internet and mobile phones very
1638240	1642480	Very rapidly and these also have complex pluses and minuses that we don't we don't know
1643200	1648080	We don't know how to balance. So I just think there there's clear potential for tremendous good from these
1648400	1652320	There's potential that they serve an ingredient of agis that they can do even more good
1652640	1654640	There's also ways people can do
1654800	1657120	Harm with them. I see this is not different than
1657680	1664080	So many other technologies out there and the the practicality of a pause is a whole other thing because if you if you
1665200	1670480	If such a pause were really adopted on paper, which is obviously not going to happen anyway
1670560	1676320	So I think signing the petition is mostly virtue signaling rather than anyone thinking the pause was really going to happen
1676400	1680240	But I mean if if such a pause really did happen
1681040	1685120	I mean what would happen first of all Putin and Xi Jinping aren't going to do that pause
1685440	1691200	Even if they said they were they're not going to china can't even debate the world trade organization sort of basic
1691680	1699440	Ethics about not stealing other people's ip right so on the other hand big tech companies like at google and microsoft and so on
1699440	1703120	They're not really going to pause either. They're just going to develop a i
1703760	1709280	Internally and use it inside the products in the in a quieter way rather than making it available to the consumer
1709280	1715040	So if such a pause were adopted, which it won't be that would result in a combination of
1715520	1717520	nasty dictators
1717600	1719600	gaining in ai over the
1720080	1723120	Democratic world and it would result in greater
1723680	1732560	Centralization of ai within the developed world as big big tech companies take their lm projects black and don't open them up to the
1732640	1734880	to the consumer so I think
1735840	1742320	But I think almost everyone can see this and they just want to sign it so they could look like they're ethical and
1743200	1745200	Concerned right because because that
1745200	1747200	well
1747680	1749680	We have a lot of questions from
1750560	1752320	the people following
1752320	1754320	The live and I want to
1754320	1756640	Tackle some of them and they are
1757520	1763280	Touching these these topics, but let's start with a different question from Rohit
1764240	1766240	What is the picture behind the wall?
1767360	1769360	On the wall behind you
1770480	1773840	Oh that that orange picture. I think that's yes
1774240	1780560	That is the that is the album cover of access oldest love by by jimmy hendrix. So go
1781120	1783120	All right
1783600	1787200	Listen to access boldest love one of the great great albums in music history
1788400	1790720	All right, Rohit. So you can check it out
1791440	1792720	and
1792800	1794960	David is asking
1794960	1798880	Why is the mainstream pushing the ai is going to kill us all narrative?
1799920	1801920	And then he proposes
1802160	1806640	a benign answer saying maybe to create a common alien enemy
1807520	1808480	to
1808480	1813040	unite us and the and the wars between nations
1813520	1814400	so
1814400	1815520	to to
1815520	1817520	answer david in pot
1817520	1818800	in
1818800	1822400	ai deserves a lot of conversations and
1823280	1825040	I hope
1825040	1827440	more would happen especially
1829280	1835200	Illustrating the benefits of of ai like ben said in a in a pro-actionary
1836160	1838160	attitude
1838400	1845440	And the mainstream media is driven by fear is driven by the the the worst possible narrative
1845840	1850000	That attracts attention. So it is natural that they would
1850720	1852560	um
1852560	1854320	Push push that
1854320	1856320	in on on the other hand
1857120	1858400	it is
1858400	1860400	definitely the case
1860560	1862320	that
1862320	1864320	There are
1864320	1868000	Approaches that we have taken to iteratively
1869200	1871680	Develop solutions. For example
1873280	1879120	The the SpaceX rockets that are now landing regularly
1880160	1882160	Belonged to science fiction
1882560	1884880	And nasa or the russians
1885440	1887600	Or the chinese or the europeans
1888160	1890160	Would have never developed them
1890800	1891520	if
1891520	1897920	Crazial and musk didn't come around and said i don't care that everyone says it's impossible
1898320	1901200	I will just blow them up until we don't succeed
1902320	1905040	And so that is where the alignment
1906000	1907920	issue comes up
1907920	1909920	because
1910080	1912640	There are people who believe that
1913840	1916640	Not current agi, but future agi
1917760	1919760	can
1920320	1922320	Become agente
1922640	1926720	It can design and then execute goals of its own
1927840	1930080	And it can slowly
1930800	1932640	Diverge
1932640	1939360	And then the side effects of whatever it does can have very big effects on us
1940640	1942640	and both
1942800	1945440	The speed of its divergence and
1946960	1954320	The size of these effects can be such to represent an existential threat to human civilization
1955520	1959600	Without us being able to say after the fact
1960240	1967120	Oh, sorry, we destroyed the current one. Let's bring a new human civilization in its place and iteratively
1968080	1970080	Find what works?
1970400	1971600	so
1971600	1973600	Again two questions
1974640	1978320	Do you believe this framing of the alignment problem?
1979200	1980240	is
1980240	1982240	Worth considering now
1982880	1985120	Given that by your own assessment
1986960	1988960	The singularity
1988960	1992640	May be as close as five years from now
1993440	1995440	and the second question is
1996240	1997360	If
1997360	2001360	We don't have a current solution to the alignment problem
2001840	2009440	What are the paths that we need to take in order to find those solutions so that we have them when we need them?
2011680	2016960	Good good questions. Yeah, I want to I forgot to say one thing about the pause
2017040	2021440	Which I want to address briefly then I'll go to this more bigger and deeper more interesting question
2021520	2027680	I think another strange thing about the pause petition is it focused on training larger and larger language models
2027840	2031280	so so one one thing that was ironic when I saw that is well actually
2033040	2039040	If people really stopped training larger language models and started working on more productive approaches to agi
2039520	2047440	Then that might actually have the opposite impact of what people signed the petition thought that might accelerate the path toward agi
2047840	2051760	Sam Altman actually made the same point in recent remarks at mit. He's like well
2052480	2059760	This lacks technical nuance because what we're doing at open ai now is not so much just obsessing on bigger models
2060320	2064480	Anyway, I mean they're integrating gbd forward with microsoft knowledge graph
2064560	2066560	They're working on a lot of other
2066640	2072240	Other things besides just bigger and bigger models. So this is a difficulty of prohibitions on complex things
2072240	2076960	Like you you're going to say no no language model with more than you know
2077920	2083600	One trillion parameters. What if someone makes a complex valued parameter which equals two real valued
2084160	2091200	Parameters, right? I mean what what if you have five different models with half a trillion parameters living in different places that that that
2091840	2095600	Co-operate with with with each other. I mean it's these things are too
2096480	2097600	slippery
2097600	2103760	Inter the same reason the software patents are much harder than biotech or nuclear energy patents or something, right?
2104080	2106800	There's slippery in there in their definition
2107360	2113840	As well as slippery and balancing good and bad aspects in the in in the short term and I think
2116080	2119360	Yeah going to the align alignment question now
2121280	2123280	I I don't
2123280	2125280	really like
2125680	2130160	The word alignment that that's used in in discussing the
2131440	2133120	future
2133120	2135680	coordination of ai mines and
2136800	2137920	and
2137920	2140400	human minds, I mean I understand what people are
2141280	2147680	Getting at when they talk about ai alignment. I don't want to nitpick on on word choice in too much of a
2148960	2150960	Ridiculous way, but to me
2151440	2156400	There's nothing to align with because human
2158880	2161760	Morals human ethics human ideals human ideas
2162800	2164160	are
2164160	2167840	Intercontradictory and kind of scattered all over the place and they're also
2168880	2170240	rapidly
2170240	2175120	Devolving right so I mean if you look if you look in at, you know, indigenous
2176400	2178400	Australians at
2179360	2181360	You know
2181920	2187440	Asians at at the average Ugandan subsistence farmer at
2188240	2189680	you know
2189680	2196720	Islamic people in in rural Saudi Arabia and then look at people in the tech hubs in the US today
2197760	2200080	Right now. There's tremendously different views on
2200880	2202880	so many things and
2202880	2204880	if you roll back
2205120	2206880	50 100 years
2206880	2212960	There were divergent views among these different groups, but also each of those groups have a different view than they then they have now
2213040	2215440	where like, I mean when I when I was growing up
2216320	2217760	in
2217760	2220560	New Jersey in the 1970s in part of my childhood
2220960	2225760	I mean you would get the crap beaten out of you for being publicly gay or even being suspected of it
2226320	2231920	Now that's not true in New Jersey anymore, but you can get killed for being gay in many parts of sub Saharan Africa, right?
2231920	2234960	So there there's there's not a coherent thing
2236640	2243520	To align with at any level of precision and the way humanity thinks about what's good and right
2244240	2246240	50 years from now post-singularity
2247120	2250080	Is going to bear only a loose resemblance to how we feel
2251840	2257440	Now, I mean, I think some things that we take very much for granted now or like a
2258320	2262160	Focus on our biological family, right? I mean, that's a big thing for me
2262480	2269040	Five children and a granddaughter. I live near my mother who's almost 80. That's a big thing if you're
2269920	2273360	We're post-singularity people aging and death is is gone
2273840	2280640	Reproduction doesn't happen to happen have to happen in the traditional biological way, although it may still sometimes
2280720	2282720	I mean the the whole role that
2283200	2284800	family has
2284880	2293120	In psychology may be quite different 50 years from now than then then now and this may sound very disturbing
2294160	2296480	To some people now. I mean just as
2297120	2302320	You know gay people were very disturbing to the people I knew in New Jersey in the in the in the 70s, right?
2302400	2306560	So I mean things evolve. So then we're not saying take
2307680	2309680	you know the world view of
2310560	2311840	San Francisco
2311920	2313920	Silicon Valley tech bros in
2314400	2321840	2023 and make future agis always aligned with a world view of 2023 silicon valley tech bros, right like that
2322240	2325920	That's not what we want any more than we want to forever be aligned with
2326240	2330480	You know the the elite in Rome in 1521 or something, right?
2330480	2337840	So what what you want is somehow for the the chaotic self contradictory evolving system of human values to
2338480	2339680	be
2339680	2344160	Coordinated and co-evolving somehow with the evolving set of of
2344960	2349840	AI and transhuman and synthetic organism values and that that's
2350400	2356080	That's that's an interesting thing to think about. It doesn't seem like the kind of thing that can be
2357200	2363920	Guaranteed in any way nor the kind of thing that you can pre figure and and design in a in a detailed way
2364000	2368960	We're talking about the coupling of two pieces
2369520	2374160	Two subsystems of a complex self-organizing system, which by its nature is
2375200	2377200	Going to be evolving in ways we cannot now
2378480	2385760	Understand so I mean you have people talking about we want an AI that will provably never deviate from its initial goals
2385760	2389600	I'm like shit. What if what if the pope had created an AI in 1400?
2389840	2394880	That would provably never deviate from the goals the pope gave it and it was super powerful
2394960	2396960	And it would we'd all be forced to be
2396960	2401360	Catholics at risk of being blown up by AI drones coming out of the Vatican or something, right?
2401600	2402800	I mean
2402800	2407200	That that would be a tremendously horrible thing to do to a superhuman mind
2407680	2414400	If you could somehow wire its brain to never deviate from the goals of 2023 silicon valley tech bros
2415600	2417600	Fortunately, there's no way to really do that anyway
2418400	2420400	So
2422720	2424720	I
2424720	2426720	cherish our diversity
2427360	2429360	and we have
2429360	2431360	the ability to
2431440	2434880	Aggregate and we have built societies that
2435920	2438960	either accept develop or impose
2439840	2443520	a certain set of consistent views and behaviors
2444240	2448800	And and today as a human civilization we brought this at
2450160	2453760	Roughly speaking continental level, right?
2455440	2457840	There are different kinds of
2460560	2464000	Expectations of of behavior from humans
2465360	2467860	within societies and across
2468480	2473040	societies as well, but we more or less subscribe to
2474240	2476240	certain sets
2476400	2481040	of behaviors and expectations around those behaviors
2482560	2483840	So
2483840	2486720	The opportunity I think is huge
2487920	2489440	for
2489440	2491440	singularity net
2491760	2493760	to find
2493760	2496000	a way for the decentralized
2497120	2499120	AI and agi systems
2500080	2502080	to
2502640	2504320	navigate
2504320	2507200	The complex sets of behaviors
2508160	2509680	across
2509680	2511520	a parameter
2511520	2517520	space that is vastly larger than not what humanity has been able to explore
2518320	2519840	today
2519840	2521840	to find
2521840	2523840	consistent and coherent
2524480	2525840	a
2525840	2527520	niches
2527520	2529680	that can build
2530560	2532560	desirable futures
2533200	2536800	Both for them as well as as well as for
2537360	2538720	ourselves
2538720	2540720	current and future humans
2541440	2548000	Under an admittedly broader definition of what it means to be human and what it means to be
2548640	2551920	Living a dignified life than not what medieval
2553600	2555600	Expectations would would support
2556880	2558880	so
2560480	2562480	Ashley is actually asking
2563440	2565440	how far is
2566000	2568000	Singularity net from agi
2568720	2573200	Considering that open cog is very robust, but not there yet
2577280	2582880	Well, so from a singularity net new net hypercycle view the technology is
2583760	2586960	somewhat agnostic to what approach you
2587040	2593440	Take to to building toward agi on top of it and we have a project called
2594080	2596720	Zarko as the ARQ a which we're spinning out now
2597040	2603920	Which is pretty much building LLMs to run decentralized on on singularity net new net hypercycle platform, right?
2603920	2610320	And we will enhance those LLMs with open cog or whatever other interesting tools come up come up certainly
2610400	2615600	but I mean you you can you can do LLMs you can you can do other sorts of of
2616320	2618320	neural nets you could build
2618480	2624640	Totally different sort of of AI system. You could build paywangs non axiomatic reasoning system, right?
2624640	2626640	You could do anything that can be
2627600	2631520	Implement modern software languages and we can we can we can decentralize it
2632160	2634400	and that that I think that's it's
2635520	2637520	important both as a modular
2638320	2640320	software design
2640720	2642720	and in terms of
2643040	2650000	Building a community I want to attract people developing weird new AI ideas on onto the platform that that that said
2651520	2653360	my own
2653360	2656560	agi research effort is still oriented on
2657440	2661520	on the new version of open cog, which is called hyperon and
2662400	2664400	I I think
2664560	2666560	in the next
2667040	2669040	One to two years
2669040	2670720	We're going to get to a
2670720	2672400	massively
2672400	2682000	Scalable version of open cog hyperon and I mean we're we're making quite good progress. I mean we have we have a distributed version of open cogs
2682960	2684160	metagare
2684160	2689120	base the adams space which is built on top of mongo db and and and couch base and we're
2690080	2692080	We're working on a massively
2693600	2695600	accelerated
2696240	2701840	Compiler and execution engine for open cog hyperons agi programming language meta
2702160	2704160	which which basically works by
2704880	2706880	Compiling open cog meta code
2707120	2712720	Into roland code that runs on the on the roland interpreter that was developed in the r chain blockchain
2712720	2717280	So we we've got a bunch of interesting stuff going on the infrastructure side
2717920	2723680	There's a collaboration with simulai rachel st. Clairs company out of florida on building an optimized
2724480	2729680	Chip for open cog pattern matching and then an ag agi board as well. So I think we we
2730640	2732480	Have a lot of
2732480	2734480	different thrusts going on to make
2735200	2737200	massively scalable
2737760	2744080	Infrastructure for open cog hyperon as well as as well as ongoing r&d on the mathematical
2745200	2747040	Foundations of how to get
2747040	2753840	large language models and other deep neural nets logical reasoning and then evolutionary learning to work together and I think this is key because
2754800	2760240	You know llm's and other other generative neural networks are great at recognizing and synthesizing patterns
2761440	2769360	Logical reasoning engines are better at telling truth from false. So then carrying out, you know, multi chain logical inferences
2769920	2771680	evolutionary learning
2771680	2776320	Simulating natural selection and the computer is good at creativity, which is how evolution created us
2776320	2782240	So I think getting these three ai paradigms working together in this distributed network is
2783040	2784320	is going to be
2784320	2786320	big and I think I think that
2787280	2789280	If we didn't exist in open cog
2790160	2795040	The mainstream of big tech ai would get to a similar place eventually you can already see
2795520	2801440	They're taking llm's and they're glomming microsoft knowledge graph onto it and google they're glomming google's knowledge graph onto it
2801440	2807840	Why because they want to ground it in reality and eventually they'll want to so solving the
2809120	2811760	hallucination and bullshit problem is
2812400	2817040	High on the list and integrating with knowledge graphs that can do reasoning is an obvious route there
2817280	2820560	Their knowledge graphs are not as advanced as the one we have in open cog
2820640	2823360	But then once the bullshitting problem is solved
2824000	2829280	Then there's the banality problem of just yes, it's amazing chat gbd can write poetry
2829360	2834080	But on the other hand, it's all really bad poetry, right? So then how do you how do you get it to be?
2834720	2836400	creative and and
2836480	2842240	Inspired like people are and I think then then you're going to inevitably move towards some sort of evolutionary
2842880	2848320	Algorithm approach. So I think I think big tech will get there to the ingredients that we have already
2848880	2855760	in the open cog design, but if we can get there faster by deploying open cog hyper on its scale on a
2856480	2858480	decentralized infrastructure
2858640	2861920	I mean, then we're doing a couple different things, right? What one is
2863520	2865280	you know, we're
2866000	2870240	Past where big tech will get because they're fixated on the particular
2870880	2877680	Techniques that will best leverage their their advantage in in data rather than on on techniques or not as as
2878240	2880240	As data training data set bound
2880880	2884880	But the other thing we're doing is we're making it so that hey lo and behold
2885760	2888240	the next big breakthrough the breakthrough from
2889600	2891600	To agi happened
2892080	2897520	In the decentralized ecosystem rather than the centralized ecosystem, right now if you're if if you're
2898320	2905120	Nick Bostrom or Elias or Yadkowski, that's going to seem far worse than having it happen within a centralized company because
2905760	2908640	from the mindset that some of these ai ethics
2910080	2915280	Buffins have right they they would rather have a small group of people controlling the agi
2915760	2919280	So so so so then the small group people could be convinced to shut it down
2919840	2927840	Whereas if you have an agi rolled out in a decentralized way where it's running on millions of different machines in every country on the planet, then
2928960	2930960	nobody can
2931120	2933840	Turn it off in such a simple way now
2933840	2937440	It's not to say humanity couldn't shut it off if humanity is a whole one or two
2937440	2942480	I mean, that's like think about bitcoin or ethereum. I mean, how would you shut down those networks?
2943280	2949120	It's not easy for a government to shut down those networks if bitcoin or ethereum. We're going to kill everyone
2949440	2951840	Well, yeah, people could just start running their nodes, right?
2951840	2958480	I mean, I mean so and if you have a majority of people who will refuse to confirm transactions
2958480	2960960	It won't get confirmed, right? So being I mean being
2961920	2963920	Decentralized in a blockchain based mechanism
2964320	2970000	Doesn't mean like this will run them up and if all humans wanted to stop it. They couldn't they couldn't stop it
2970000	2975920	I mean eventually things could get there, but that's not implied in the in the use of a decentralized fabric
2976000	2980240	But it but it it does mean that it started to shut down in the same way that
2981040	2987600	Bit bitcoin or bit torn or something are hard to shut down as long as long as there's a substantial group of people
2988400	2994480	With a bunch of hardware who who want to keep the thing going that then it will keep going and
2995920	2997360	personally
2997360	3001360	I see risks either way like having having a centralized entity
3001920	3006640	Could be the best if the people running that centralized entity are open-minded open-hearted
3007280	3012880	Compassionate normal individuals who don't don't fall prey to the pathologies that have befallen
3013600	3019040	Almost every group of humans in an elite power position in human history, but it's possible. It could go well
3020080	3022880	That decentralized approach has the downside that
3023520	3026560	You know nasty groups of people could try to take over the network
3026560	3031200	They can form the open source code. They can try to do do their own unpleasant thing
3031280	3034640	Right, so we are placing a bet on the vast chaotic
3035280	3038800	team of unwashed masses of humanity over
3039280	3046080	self-appointed elites with huge amounts of of money and close military intelligence connections, right? So you I mean
3046720	3048720	neither neither one is
3048960	3050560	an
3050560	3051600	incredibly
3051680	3053200	safe and certain
3053200	3055120	path forward
3055120	3056320	my
3056320	3058080	view is that
3058080	3060080	a fundamentally
3060080	3061280	compassionate
3061280	3063680	and human benefit oriented agi
3064320	3068240	Is a bit more likely to emerge from the the decentralized
3069120	3070160	approach
3070160	3078720	I don't think this is the thing you can have a completely solid like mathematical proof of right because we're we're not just talking about the algorithms and structures
3078720	3080720	we're talking about how the human systems
3081520	3083520	in interact with the
3084480	3086240	with the compute
3086240	3089840	fabric and the ai ai algorithms, but I think there's
3090720	3092320	lots of reasons to be
3092320	3094320	optimistic. I mean, I
3094800	3096800	I think
3097120	3099280	You know with the advanced technology we have right now
3099760	3105040	You could have so much more destruction in the world that then then what we have but
3105920	3112720	In fact, there's remarkably few groups of highly competent technically trained individuals out there
3113040	3118640	Who are massing together to put their energy toward killing a lot of people are causing that causing mass destruction
3118640	3121520	like you I mean you you don't have a situation like the
3122240	3124240	you know the amount of people behind
3124480	3130960	Say a strong tech startup say Anthropod or stable diffusion just not to hover my own company
3130960	3133040	so the amount of money and energy behind
3134000	3138480	A startup tech company and the brilliant people going into it and the money going into that hardware
3138800	3142560	You don't have initiatives like that focus on blowing up a lot of people or or
3143040	3148800	Reaching great mayhem in the world right you could you could theoretically right but in in fact
3149440	3151600	In fact the mass of technical innovation
3152160	3154160	It's going toward making people money
3154480	3159600	Some bits of it are going toward doing doing doing good for people some things may may may may go awry
3160080	3162560	but what what what we what we see is
3164080	3166080	On on the whole most
3167440	3169440	humans who are
3169920	3173760	banding together in groups to advance technology are
3174640	3178400	Are actually not trying to do horrible nasty shit with it right and then I think
3179200	3181200	I think that's going to continue
3181520	3186240	It's going to continue as we move toward agi in an open and decentralized manner
3186960	3188960	There are a lot of people following the
3189840	3191840	the the stream asking questions
3192400	3194400	evidently very
3194400	3196400	passionate about these
3196480	3201280	Let's let's let's try to do a few quick questions and if I can I can try to give some short answers
3202000	3204640	one of them one of them is quite
3206000	3207520	general, but
3207520	3209520	But I think important
3210480	3213200	If they want to get involved with
3214000	3218080	the project what kind of talent what kind of skills
3219600	3225360	Both in the core as well as in the ecosystem projects are most valuable
3226080	3234080	In order to further the missions of of singularity net and of the single ecosystem projects as well
3236720	3238880	There's a great variety of skills that are
3240480	3242480	Are useful for advancing
3243360	3248560	Singularity net ecosystem projects and other projects out out there which are which are
3249600	3250640	advancing
3250640	3252640	you know singularity
3253040	3257440	Oriented technology in in in beneficial ways. So I wouldn't want to
3258160	3263440	Be rigid about it. I mean because I mean we're working with lawyers. We're working with social media people were
3264080	3269120	We're working with all people from all different walks of life as well as
3269520	3273280	The more obvious things like AI developers software engineers
3274640	3279840	Blockchain developers, but biologists cognitive scientists and whatnot, but as a generalization
3280880	3282880	I would I would I would say
3286160	3292240	People who can spit so I mean if you have the mentality and interest to be a core agi developer
3293760	3296000	That's great. We can always use more people who know
3296640	3301760	Chit loads of math computer science engineering and so forth right if if that's not your thing
3302480	3305440	I would say there's always a need for people who have
3306800	3312640	mastery of some other some other domain area and a decent knowledge of AI because when you're trying to
3313840	3316080	Apply AI and say biology or
3316800	3319040	Supply chain or media or whatever it is
3319680	3323280	It still comes down to some small group of humans who understand that domain
3323680	3326720	And have a decent sense of the AI to make to make that bridge
3327360	3331040	AI is not yet figuring out how to apply itself in one after another
3331680	3334720	Critical area. So I I think we're entering an era where
3335360	3337360	cross-disciplinarity is
3337520	3339120	is
3339120	3342080	Going to be key and and highly valued
3343600	3346960	The day after tomorrow there will be the decentralized governance
3347680	3349120	summit
3349120	3351120	What can people expect?
3351920	3359440	To to find there. What are the the kind of contributions that you will also provide as well as the other speakers?
3361600	3363600	Yeah, good question. So
3364000	3365440	you know making
3365440	3372000	A decentralized AI network has a number of aspects and I've tended to focus on the technical aspects
3372080	3377040	Just of how do you get large-scale compute processes of the sort you need in AI
3377600	3382640	To actually run across a huge number of machines without a central controller because there's
3383200	3387040	There's a huge load of hard technical problems you have to solve to make this
3387680	3394960	Happen which we're working on in Singularity that new net hypercycle open cog to agi zarka, blah, blah, blah, but I mean the
3395920	3397920	the other aspect to
3398400	3400240	making AI
3400240	3402240	fundamentally decentralized
3402320	3403680	is
3403680	3405680	governance of this
3406400	3410160	Network right because it's not all about the computing yet
3410880	3413760	All the all these compute nodes in your decentralized network
3414320	3419440	Are run by people they have to they have to decide to run run this software on their machine
3419520	3421840	They have to decide one to one to upgrade
3422480	3426240	upgrade to a new version of software there will be decisions about the
3426960	3432480	Parameters of the software and the network that have to be made for now by the people who are running the software nodes and
3432800	3437200	And the people who are using using using the software running on the nodes, right? So there's
3437840	3441200	There's a significant governance aspect to decentralized
3442080	3444000	AI networks
3444000	3447600	as well when we founded Singularity Net in 2017
3448560	3451440	one of our goals was to gradually
3452080	3457680	Transform the governance of the whole Singularity Net network into a a DAO of some form a decentralized
3458400	3465840	Autonomous organization not meaning initially would just be the AI nodes making the decisions, but but meaning meaning that it would be a
3467520	3470800	democratically governed network of humans and and
3471440	3477120	and AIs with the whole collective of participants in the network playing a meaning meaningful role
3477600	3479600	in in in the ongoing
3480000	3483680	Decisions of evolving the the network over over time
3484240	3486000	So we've we've had
3486000	3491120	Some measure of that so far. I mean we've had some pretty big decisions in the history of Singularity Net
3492640	3496400	Made by community vote and and community discussion
3497040	3499040	But we haven't gone as far in that direction
3499680	3503040	as I would I would like to have and so that basically
3504560	3506400	the governance
3506400	3511200	powwow that summit that we're having on on the Friday is
3511840	3513840	oriented toward pulling together
3514560	3519120	you know various people involved in different aspects of Singularity Net ecosystem and
3519840	3521840	gathering energy toward
3522080	3523440	in the next
3523440	3526560	two years, how can we transform Singularity Net
3527360	3529360	into a radically more
3530080	3533680	decentralized organization where the breadth of participants
3534320	3535680	in the in the
3535920	3543040	Network are playing a greater role in making the important decisions about the evolution of what happens in the network and
3544080	3547760	I mean I picked the timing of two years in my head
3548320	3550320	with a couple things in mind one is
3550880	3556480	I don't want to rush things to an insane degree because we're doing very valuable stuff and I don't want to
3557200	3563440	Disrupt it in some stupid way and there are many pathologies that that that we've seen in the blockchain world from from
3564240	3570960	From Dow governance on the other hand, you know if if we could get to human level AGI in three years
3572480	3574080	Then I want to have
3574080	3576320	Fundamentally and fully decentralized governance
3577040	3583360	Before that because I think it's going to be key in the transition from their AI to to AGI
3584080	3590000	In all sorts of ways. We can't prefigure now right like I'm I'm a big optimist about what happened after the Singularity
3590960	3598160	More based on my heart and and soul and feeling the based on rational analysis because I think based on rational analysis
3598640	3600640	the confidence intervals just
3600960	3604960	Very wide and there's a lot that we can't rationally know but I I have a strong
3606000	3613600	Faith that things are going to come out pretty amazingly once we have superhuman AGI that we've raised up in a compassionate and democratic way
3614400	3616720	but I can see a lot of risk of
3617680	3625120	Chaos unfolding en route to this utopic future and I think that having the
3626160	3628160	network in which AGI emerges
3629200	3633040	Fully decentralized and very richly democratically governed
3633920	3635920	that gives a lot of
3636320	3639440	important degrees of freedom for how the emerging
3640080	3642080	AI network
3642080	3648480	Sort of deals with any chaos that happens between here and the singularity. So I think this is it's both
3649440	3652880	It's both the direction we committed to when we founded Singularity Net and
3653600	3655600	potentially could be really really
3656160	3659120	important to humanity if the breakthrough to AGI
3659760	3663600	Happens within the Singularity Net network, which is obviously what we're pushing for
3663600	3665600	And
3668960	3670960	I know that you are
3671760	3672960	also
3672960	3676480	Going to be at a couple of events that you wanted to you to mention
3677360	3678720	in
3678720	3680720	the consensus
3680720	3682720	in Austin and
3685520	3689760	Yeah, events are coming back right so spending a couple years sitting. Yes, and
3690080	3692080	And
3692320	3694320	Web Summit go ahead
3694640	3696640	Yeah, yeah, yeah, I think
3697120	3700560	Events have come back right during the pandemic. I was mostly sitting home
3701520	3705840	working on AI on blockchain and playing with my kids and now
3706640	3707840	Now
3707840	3713280	Conferences are back. I'm trying to keep it under control so I can keep getting work done, but I'm going going to
3714400	3716640	Consensus event in Austin
3717360	3719360	Next week I'll I'll be doing a
3721360	3726560	Conversation or interview with Edward Snowden on AI and the security where we'll
3727360	3729360	Hit on a bunch a bunch of these same points
3729920	3731360	also doing a
3731360	3737360	Concert at the Speak Easy Club where I'm playing keyboards with the jam galaxy band with our robot lead vocalist
3738240	3740240	Desna Mona the Sophia robots
3741680	3744800	Little sister there'll be a bunch of Singularity Net people
3745520	3747920	around around the consensus so definitely
3748640	3750800	Come come and hang out with us then
3751440	3753200	following that I'll be at
3753200	3756480	web summit Rio and also doing an AI meet-up in
3757120	3764640	In Rio on one of the evenings of web summit and I was I was born in brazil way back in 1966. So I'm a
3765360	3769520	The world's worst brazilian citizen because my portuguese is is horrible
3769520	3773440	But I'm I'm a dual citizen us in brazil always always feels good to
3774000	3780320	To go go go back to the to the motherland. So there's a yeah, if you're if you're gonna be in australia real then
3781280	3787920	You know, there's a bunch of singularity people people around in the next next few weeks, but of of course
3789520	3795280	The core work we're doing is distributed around the globe and you can you can get get involved on the
3796240	3798960	On the interwebs if you go to Singularity Net
3799680	3804720	I owe you can join that join mailing list and find various get however repose and
3805520	3810640	Telegram linked in and and ever everything else. We encourage people to get involved these will be
3812000	3817920	The next few years maybe the last few years that you have a chance to help bring about a beneficial singularity unless you're
3818320	3821040	Be doing it in some post-singularity video game or something
3821920	3829280	Uh, Ben, uh, this was wonderful. Thank you very much for covering so many of the topics and
3830400	3834160	I'm sure that there will be a lot more to talk about and
3835440	3838640	Congratulations for everything that you have been able to
3839280	3840560	accomplish
3840560	3841520	with
3841520	3843280	Singularity Net
3843280	3845280	everyone in the teams
3845840	3847040	and
3847040	3854960	Good luck with further developing all the projects and I will see you at the decentralization summit
3856080	3858560	Just in a in a couple of days
3859600	3861120	We will both
3861120	3863120	be speaking there to talk about
3863840	3865840	governance and how to
3866720	3868560	ride the tiger
3868560	3872000	Really in the next period of time. Thank you again
3873600	3875600	Thanks a lot. David. It's been a pleasure
3878000	3884400	Thank you, uh, everyone for being here with us today at beyond conversations
3885280	3890320	I am sure that there will be a lot more opportunities to
3892240	3895440	Ask questions and to really
3896240	3901200	Find out how technology is impacting and benefiting
3901840	3903840	Society around us
3903920	3905920	Goodbye
3907040	3909200	You
