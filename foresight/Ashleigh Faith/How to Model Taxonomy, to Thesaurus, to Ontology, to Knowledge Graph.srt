1
00:00:00,000 --> 00:00:05,440
Hey everybody, so today we are going to be walking through the evolution and how do you

2
00:00:05,440 --> 00:00:14,080
model the evolution of a taxonomy to a thesaurus, to an ontology, to a knowledge graph.

3
00:00:14,080 --> 00:00:19,220
And just like with any modeling project, your end use case is your guiding light.

4
00:00:19,220 --> 00:00:23,680
So the decisions I make in this video may not be the same decisions that you make.

5
00:00:23,680 --> 00:00:28,120
And I'm going to walk through why I am making some of those decisions so you can think about

6
00:00:28,120 --> 00:00:32,000
what you need to do when you are going through this same process.

7
00:00:32,000 --> 00:00:36,200
And just like your end use case, you don't necessarily have to get to the end of this

8
00:00:36,200 --> 00:00:37,440
evolutionary stage.

9
00:00:37,440 --> 00:00:41,800
If you don't need to make a knowledge graph, you're perfectly fine with just an ontology

10
00:00:41,800 --> 00:00:46,680
or maybe you're just wanting to make your taxonomy a little bit more robust so that you have

11
00:00:46,680 --> 00:00:48,640
a thesaurus instead.

12
00:00:48,640 --> 00:00:50,200
And why is that useful?

13
00:00:50,200 --> 00:00:52,800
All of those things I am also going to cover in this video.

14
00:00:52,800 --> 00:00:55,640
So if this sounds interesting to you, keep on watching.

15
00:00:55,680 --> 00:01:01,960
All right, so starting out, we need to look at what is the use case, and then we need

16
00:01:01,960 --> 00:01:06,520
to go and look at what data do we need to supply for this use case.

17
00:01:06,520 --> 00:01:13,160
Now you could jump to any one of the models we're going to talk about today in order to

18
00:01:13,160 --> 00:01:14,920
answer this question.

19
00:01:14,920 --> 00:01:19,720
Some are going to be able to answer this question a lot easier than others.

20
00:01:19,720 --> 00:01:23,400
But for the sake of this video, I'm going to be starting with a taxonomy.

21
00:01:23,400 --> 00:01:30,120
So in our scenario, this manufacturer does not have a taxonomy and they really need to

22
00:01:30,120 --> 00:01:37,160
understand which pieces and parts and components go into any one of their vehicles.

23
00:01:37,160 --> 00:01:38,720
So let's start there.

24
00:01:38,720 --> 00:01:42,880
Now each of these models can have a much deeper dive associated with them.

25
00:01:42,880 --> 00:01:46,160
I cannot do all of those in one whole video.

26
00:01:46,160 --> 00:01:51,720
So I have linked every model and corresponding videos that I've done in the past for a deeper

27
00:01:51,720 --> 00:01:54,880
dive in each of them if you want to go and check those out.

28
00:01:54,880 --> 00:02:02,840
In our scenario, we already have tags, let's assume, on the content and or processes or

29
00:02:02,840 --> 00:02:10,240
whatever it is in our, our plants, our manufacturing plants that we can then identify what's going

30
00:02:10,240 --> 00:02:12,080
on in each of those plants.

31
00:02:12,080 --> 00:02:13,720
The problem is those are just tags.

32
00:02:13,720 --> 00:02:15,880
They have no organization to them.

33
00:02:15,880 --> 00:02:21,440
So the very first thing we're going to do is we're thinking about how like-minded things

34
00:02:21,440 --> 00:02:22,880
go together.

35
00:02:22,880 --> 00:02:33,040
Now normally a taxonomy is looking at broader and narrower parent, child or whole part relations.

36
00:02:33,040 --> 00:02:39,200
And so you can see here that passenger vehicles have narrower types, right?

37
00:02:39,200 --> 00:02:44,560
So another relationship here is type of, and these are not explicit relations.

38
00:02:44,560 --> 00:02:47,560
We'll get into that later in other models.

39
00:02:47,560 --> 00:02:53,240
Right now these are more inherent by the hierarchy the taxonomy takes on.

40
00:02:53,240 --> 00:03:01,040
So here passenger vehicles is the broader or parent of a sport vehicle.

41
00:03:01,040 --> 00:03:06,600
And then if we look at the different sports vehicles, there are Mustangs and Raptors because

42
00:03:06,600 --> 00:03:10,400
we're looking at all Ford vehicles in this example.

43
00:03:10,400 --> 00:03:17,200
You can also see in parts how parts is kind of generic, but it is a container of all of

44
00:03:17,200 --> 00:03:21,600
the different parts that would be components in a vehicle.

45
00:03:21,600 --> 00:03:25,680
And you can break this up into whatever makes sense for your organization.

46
00:03:25,680 --> 00:03:31,480
So for instance, if you want mechanical parts versus nuts and bolts, which are not mechanical

47
00:03:31,480 --> 00:03:34,640
in nature, then you can divide them up that way.

48
00:03:34,640 --> 00:03:38,240
You really have to keep your end use in mind while you're doing this.

49
00:03:38,240 --> 00:03:43,920
For us, we really just need to understand which of these vehicles have specific electric

50
00:03:43,920 --> 00:03:45,000
motors in them.

51
00:03:45,000 --> 00:03:52,600
Now you are going to notice there is a heavy emphasis in every model on the metadata and

52
00:03:52,600 --> 00:03:56,560
the relationships that the model is representing.

53
00:03:56,560 --> 00:04:01,380
So these are going to come in handy as we evolve this model into something else.

54
00:04:01,380 --> 00:04:05,880
So right now we do not have additional attributes.

55
00:04:05,880 --> 00:04:12,720
These taxonomy terms may have unique IDs, but other than the hierarchical look to them,

56
00:04:12,720 --> 00:04:13,880
they don't have anything else.

57
00:04:13,880 --> 00:04:19,880
This is just adding context by the placement that they have in the tree structure of a

58
00:04:19,880 --> 00:04:27,120
taxonomy, as well as how these tags are then connected to the end assets, whether it's

59
00:04:27,120 --> 00:04:29,680
a document or an actual component.

60
00:04:29,680 --> 00:04:30,680
All right.

61
00:04:30,680 --> 00:04:35,360
So now we're building on top of stage one.

62
00:04:35,360 --> 00:04:40,640
So everything that we've developed with our taxonomy, the hierarchy, the types of relations

63
00:04:40,640 --> 00:04:46,880
that are inherent from that hierarchy are also going to be helpful with the thesaurus.

64
00:04:46,880 --> 00:04:49,960
So here we're adding more connective tissue.

65
00:04:49,960 --> 00:04:56,720
Every single step in these stages is adding more context, more relations, more of that

66
00:04:56,720 --> 00:05:02,500
metadata to help humans and machines make better decisions based on this data.

67
00:05:02,500 --> 00:05:08,200
So here we are now adding things like use for those are synonyms and those can be synonyms

68
00:05:08,200 --> 00:05:13,040
from different catalogs, different pieces of metadata you're bringing in from different

69
00:05:13,040 --> 00:05:14,040
databases.

70
00:05:14,040 --> 00:05:17,000
It can be the natural language of your end user.

71
00:05:17,000 --> 00:05:23,480
If you're using this taxonomy and thesaurus for search enhancements, you also get things

72
00:05:23,480 --> 00:05:25,040
with see also.

73
00:05:25,040 --> 00:05:29,640
Now that's going to be really important for ontology and knowledge graph building because

74
00:05:29,640 --> 00:05:35,680
see also is a generic form of, oh, hey, there's other things that go along with this that

75
00:05:35,680 --> 00:05:40,120
are not pure hierarchical in nature.

76
00:05:40,120 --> 00:05:45,480
And so those see also are going to be really helpful in later stages in in all of this.

77
00:05:45,480 --> 00:05:55,000
See also is basically looking at how certain clusters of things or branches in your taxonomy

78
00:05:55,000 --> 00:05:57,960
are starting to play with others.

79
00:05:57,960 --> 00:06:04,120
So for instance, if you are looking at a vehicle, well, a logical representation of a vehicle

80
00:06:04,120 --> 00:06:11,880
is all of the different things that go into how that vehicle is constructed, how it goes.

81
00:06:11,880 --> 00:06:16,320
So that could be the motor, it could be the fuel, it could be, you know, how those things

82
00:06:16,320 --> 00:06:22,440
are supplied as in a pumping station or a charging station, if it's an electric vehicle,

83
00:06:22,440 --> 00:06:25,440
think of it almost as composition.

84
00:06:25,440 --> 00:06:34,520
If you are composing a room, what things go into any specific room?

85
00:06:34,520 --> 00:06:39,600
So if you're looking at a living room, it could be a television, it could be a couch,

86
00:06:39,600 --> 00:06:43,440
it could be, you know, wall hangings, it could be speakers.

87
00:06:43,440 --> 00:06:49,320
What are all the things that go together to define a living room?

88
00:06:49,320 --> 00:06:50,320
Same with a vehicle.

89
00:06:50,320 --> 00:06:55,400
What are all of the things that go into defining all of the different aspects of a vehicle?

90
00:06:55,400 --> 00:06:59,160
These are going to be incredibly important when we get to the next stage.

91
00:06:59,160 --> 00:07:04,520
Other things that are represented in a Thesaurus are looking at definitions.

92
00:07:04,520 --> 00:07:10,400
Sometimes you will see things also like scope notes, and that's for human and or computer

93
00:07:10,400 --> 00:07:18,120
automated tagging of specific assets or behaviors, if you're looking at a manufacturing plant.

94
00:07:18,120 --> 00:07:24,640
It's understanding how these things are contextualized in your specific use case and your specific

95
00:07:24,640 --> 00:07:26,200
company.

96
00:07:26,200 --> 00:07:33,320
So the jump from a taxonomy to a Thesaurus is not as large as a Thesaurus to an ontology

97
00:07:33,320 --> 00:07:36,720
or a Thesaurus to an oligarch for that matter.

98
00:07:36,720 --> 00:07:43,400
And a big reason for that is they are representing the world in different ways, where the first

99
00:07:43,400 --> 00:07:51,760
two are points, they are tags on specific assets, and the relation between things is

100
00:07:51,760 --> 00:07:57,840
a little fuzzy if you're talking about a Thesaurus or implicit, which is more on the

101
00:07:57,840 --> 00:07:59,880
hierarchy of a taxonomy.

102
00:07:59,880 --> 00:08:06,560
And ontology is starting to make the connective tissue, the contextualization of how two things

103
00:08:06,560 --> 00:08:11,560
are related and the network of those things way more explicit.

104
00:08:11,560 --> 00:08:16,080
So the very first thing that you're going to want to think about here is what is the

105
00:08:16,080 --> 00:08:18,560
focal point of your model?

106
00:08:18,560 --> 00:08:21,920
So here you can see that I have done this in three different ways.

107
00:08:21,920 --> 00:08:29,120
So our use case today is a catalog of products for the Ford Motor Company.

108
00:08:29,120 --> 00:08:35,620
And so therefore the center of a catalog is the product itself, in this case a vehicle.

109
00:08:35,620 --> 00:08:42,040
But if I am doing an ontology that is focused on the transactional, the purchasing or the

110
00:08:42,040 --> 00:08:49,160
selling or the manufacturing of something, then maybe the VIN number is the center of

111
00:08:49,160 --> 00:08:55,080
my transaction, because that is the thing that is the individual specific thing being

112
00:08:55,080 --> 00:09:00,480
manufactured or sold connected to the customer, because that's the actual transaction that

113
00:09:00,480 --> 00:09:02,360
I am trying to track.

114
00:09:02,360 --> 00:09:09,280
Or if I'm looking at a supply chain, maybe where something is manufactured and what

115
00:09:09,280 --> 00:09:14,080
they are manufacturing is the center of my model.

116
00:09:14,080 --> 00:09:19,900
And identifying this early is really crucial to understand how your model is going to shape

117
00:09:19,900 --> 00:09:23,640
up to answer the questions that you are interested in.

118
00:09:23,640 --> 00:09:28,400
So once you've identified that, you want to look at the universal containers.

119
00:09:28,400 --> 00:09:30,200
That's what ontology is.

120
00:09:30,200 --> 00:09:35,640
It's a framework to house things and how those things are related to one another.

121
00:09:35,640 --> 00:09:45,320
Now a taxonomy is identifying a universal topic or thing that could be an engine.

122
00:09:45,320 --> 00:09:48,360
There is a universal understanding of engine.

123
00:09:48,360 --> 00:09:51,920
But once you get into the lower levels of the taxonomy and thesaurus, where it's talking

124
00:09:51,920 --> 00:09:58,040
about very specific engines, that might not be part of the ontology.

125
00:09:58,040 --> 00:10:02,480
That actually might be an indicator that's part of the knowledge graph portion.

126
00:10:02,480 --> 00:10:06,960
It's talking about a very specific instance of an engine.

127
00:10:06,960 --> 00:10:15,160
So the way that I like to think about this process is the first to third levels of your

128
00:10:15,160 --> 00:10:24,560
taxonomy are usually more of the categorical universal containers of things in your asset

129
00:10:24,560 --> 00:10:26,320
or your catalog.

130
00:10:26,320 --> 00:10:31,040
And so that's a good indicator that maybe start with those first while you're doing

131
00:10:31,040 --> 00:10:32,040
your modeling.

132
00:10:32,120 --> 00:10:37,480
As you go, you're going to refine your understanding and you're going to refine what you had from

133
00:10:37,480 --> 00:10:43,680
the taxonomy at thesaurus stages because honestly, you might not need all of those nodes from

134
00:10:43,680 --> 00:10:45,320
the previous stages.

135
00:10:45,320 --> 00:10:48,480
That's part of this modeling process.

136
00:10:48,480 --> 00:10:54,640
So when you are looking at those universal categories, there's a really great thing in

137
00:10:54,640 --> 00:10:55,640
there.

138
00:10:55,640 --> 00:11:03,920
Your instance data, maybe your sub-sub-subclasses in your taxonomy, are going to be mapped.

139
00:11:03,920 --> 00:11:07,960
They roll up to those broader level categories.

140
00:11:07,960 --> 00:11:15,200
So in a way, you're pre-mapping a ton of your catalog to your ontology, which is a beautiful

141
00:11:15,200 --> 00:11:22,280
thing and that's why doing this as an evolution is a really powerful thing if you can do it.

142
00:11:22,280 --> 00:11:27,280
The next thing you need to think about is the lowest level of universal data that you

143
00:11:27,280 --> 00:11:29,120
need for your use case.

144
00:11:29,120 --> 00:11:36,480
So that could be in our use case, we're trying to identify specific electric motors.

145
00:11:36,480 --> 00:11:40,640
So maybe I only need to go as low as an electric motor.

146
00:11:40,640 --> 00:11:45,960
And by the way, you don't want to create your entire ontology based on only one very unique

147
00:11:45,960 --> 00:11:52,240
specific problem statement, but it is a good place to start, but just don't stop there.

148
00:11:52,240 --> 00:12:00,120
And with an electric vehicle, that is connected to the electric motor.

149
00:12:00,120 --> 00:12:05,200
Maybe that's all the farther I need to go, but if I do need to go even lower and look

150
00:12:05,200 --> 00:12:10,880
at specific types of electric motors, let's say there are different brand names, then

151
00:12:10,880 --> 00:12:15,720
maybe that's the lowest level of data I need to have for the ontology.

152
00:12:15,720 --> 00:12:20,240
So I have a whole nother video going into a deep dive on how to determine something

153
00:12:20,240 --> 00:12:23,400
as a class or an instance, and I will leave that down below.

154
00:12:23,400 --> 00:12:27,600
But a good rule of thumb is to think about it from this perspective.

155
00:12:27,600 --> 00:12:30,400
There is a universal understanding of cat.

156
00:12:30,400 --> 00:12:38,360
It is furry, it has whiskers, it meows, it sits in your lap and it lives in your home.

157
00:12:38,360 --> 00:12:46,440
But my cat Garfield is a different instance of cat than your cat named Otis.

158
00:12:46,440 --> 00:12:49,800
They're both cats, but those are instances of cats.

159
00:12:49,800 --> 00:12:51,480
So think of it from that perspective.

160
00:12:51,480 --> 00:12:59,520
Anything that has to be very unique and is to the cellular level unique, that's probably

161
00:12:59,520 --> 00:13:04,120
an instance and you don't necessarily want that in your ontology.

162
00:13:04,120 --> 00:13:10,640
So once you've determined that, you want to then start to look at those broader and narrower

163
00:13:10,640 --> 00:13:16,880
relationships that you had from previous steps and you want to make them more explicit.

164
00:13:16,880 --> 00:13:24,120
Now you saw that in those previous steps, we did have things like whole part, has part,

165
00:13:24,120 --> 00:13:28,960
that sort of thing, that you can just transfer back over into the ontology.

166
00:13:28,960 --> 00:13:30,760
Those work really well.

167
00:13:30,760 --> 00:13:34,760
But when you're talking about things that are just broader and narrower, you have no

168
00:13:34,760 --> 00:13:38,720
idea what the relationship is between those two things.

169
00:13:38,720 --> 00:13:44,720
So in that case, here you can see that with parts and engines.

170
00:13:44,720 --> 00:13:49,960
In our taxonomy and our thesaurus, they were just nested, right?

171
00:13:49,960 --> 00:13:52,700
The engine was nested underneath parts.

172
00:13:52,700 --> 00:13:56,080
We didn't really know why they related to each other.

173
00:13:56,080 --> 00:13:57,760
Now we're being very explicit.

174
00:13:57,760 --> 00:14:00,920
We're saying it is has part, part of.

175
00:14:00,920 --> 00:14:08,400
And that also allows us to use that specific relation with any other parts that are in

176
00:14:08,400 --> 00:14:12,200
our asset and our catalog data.

177
00:14:12,200 --> 00:14:17,880
This is also your opportunity to craft unique relations.

178
00:14:17,880 --> 00:14:27,160
And those are like manufactured in these are oftentimes business specific, or these also

179
00:14:27,160 --> 00:14:31,800
can be mined from your thesaurus definitions or the assets themselves.

180
00:14:31,800 --> 00:14:38,680
So for instance, if you're looking at a description of a product, what other things in your catalog

181
00:14:38,680 --> 00:14:40,840
are being mentioned in that description?

182
00:14:40,840 --> 00:14:44,800
It's probably a good indicator that they're related in some way.

183
00:14:44,800 --> 00:14:48,160
Now the last thing you're going to be looking at are is twofold.

184
00:14:48,160 --> 00:14:53,840
So first, you are going to add in additional nodes to flesh out that network.

185
00:14:53,840 --> 00:14:57,840
And these are things that are not always found in one table.

186
00:14:57,840 --> 00:15:00,240
So this might be something that you'd have to join together.

187
00:15:00,240 --> 00:15:04,880
So this could be customer data or transactional data in general.

188
00:15:04,880 --> 00:15:09,920
Adding those in fleshes out your network so you don't have to do as many joins, right?

189
00:15:09,920 --> 00:15:12,360
This is the beauty of an ontology.

190
00:15:12,360 --> 00:15:18,760
It makes those relations inherent rather than having you have to depend on others and your

191
00:15:18,760 --> 00:15:22,800
specialized knowledge to make those kinds of relations.

192
00:15:22,800 --> 00:15:27,840
Also which is pretty critical for making sure your machine learning and mapping and matching

193
00:15:27,840 --> 00:15:34,840
projects go smoother is making sure those used for incentives are added in as attributes.

194
00:15:34,840 --> 00:15:40,880
I also just want to note here that some of the nodes that I have in my model, for instance,

195
00:15:40,880 --> 00:15:47,320
the class of vehicle, that could be an attribute on the vehicle node.

196
00:15:47,320 --> 00:15:50,480
I decided to break it out, but that's part of the modeling process.

197
00:15:50,480 --> 00:15:56,480
You have to decide which pieces of information can be descriptors of a node or things that

198
00:15:56,480 --> 00:15:59,200
need to be standalone nodes on their own.

199
00:15:59,200 --> 00:16:04,080
So one thing I want to just point out is you don't necessarily have to have an ontology

200
00:16:04,080 --> 00:16:05,280
to have a knowledge graph.

201
00:16:05,280 --> 00:16:12,080
There are other ways to get to knowledge graph outside of an ontology, but think of the ontology

202
00:16:12,080 --> 00:16:16,240
stage as you are creating that, again, that framework.

203
00:16:16,240 --> 00:16:23,440
It doesn't necessarily have to be a true ontology like an RDF ontology, but it is a representation

204
00:16:23,440 --> 00:16:28,720
of the global entities so that you can then get to the knowledge graph stage where you

205
00:16:28,720 --> 00:16:35,160
are populating the instance or the very specifics of your graph.

206
00:16:35,160 --> 00:16:38,800
Populating your graph can come in a few different forms.

207
00:16:38,800 --> 00:16:45,480
In this situation, we are going to be taking all of the things that we identified as instance

208
00:16:45,480 --> 00:16:51,200
data from our taxonomy and thesaurus, remember it rolled up into the universal classes that

209
00:16:51,200 --> 00:16:58,640
we identified, we are going to be able to populate those as instance very quickly.

210
00:16:58,640 --> 00:17:03,760
Sometimes you are going to realize that your model is not quite right and that's because

211
00:17:03,760 --> 00:17:11,120
the things that in a taxonomy and thesaurus generally rolled up to the same category don't

212
00:17:11,120 --> 00:17:15,600
necessarily work the way you want them to work when you get to the knowledge graph space

213
00:17:15,600 --> 00:17:21,080
because now when you start to look at the individual entities, there are some exceptions

214
00:17:21,080 --> 00:17:25,400
to the rule and sometimes that means you are going to have to split classes and make a

215
00:17:25,400 --> 00:17:29,080
subclass, this is part of that refinement stage.

216
00:17:29,080 --> 00:17:33,400
So dovetailing into that, you do want to check a subset of the instance data to verify the

217
00:17:33,400 --> 00:17:35,920
logic is sound.

218
00:17:35,920 --> 00:17:39,760
This is something I like to use a visual for because then you can see if there is some

219
00:17:39,760 --> 00:17:46,840
weird circular logic which by the way happens constantly when you take a taxonomy or a thesaurus

220
00:17:46,840 --> 00:17:50,360
and you turn it into an ontology or a knowledge graph.

221
00:17:50,360 --> 00:17:58,320
Another thing to watch out for sort of in that same vein is looking at the actual definition

222
00:17:58,320 --> 00:18:05,000
of these nodes versus how it is applied to the actual assets or behaviors in your systems

223
00:18:05,000 --> 00:18:09,440
just making sure that that logic all checks out and that they align with your business

224
00:18:09,440 --> 00:18:17,360
needs because I've seen that taxonomies and thesaurus are not necessarily structured to

225
00:18:17,360 --> 00:18:22,720
be used in machine learning or knowledge graphs and therefore some of that logic doesn't always

226
00:18:22,720 --> 00:18:27,200
check out once you start to morph these and involve these into other forms.

227
00:18:27,200 --> 00:18:29,360
So just be aware of that.

228
00:18:29,360 --> 00:18:35,200
You also want to add in some inferred hidden relations.

229
00:18:35,200 --> 00:18:38,560
You can identify some of these with things like shortest path.

230
00:18:38,560 --> 00:18:46,160
It's basically showing how once you really identify a network of things and how they're

231
00:18:47,000 --> 00:18:52,120
you can see the dotted line to additional nodes that you did not even know existed and

232
00:18:52,120 --> 00:18:56,240
that's a really powerful piece of knowledge graph and you definitely want to add that

233
00:18:56,240 --> 00:18:57,920
in if you can.

234
00:18:57,920 --> 00:19:03,760
You also want to identify those exceptions and add cardinality and when you're talking

235
00:19:03,760 --> 00:19:08,680
about exceptions you do want to watch out for things like adding orphan nodes you want

236
00:19:08,680 --> 00:19:15,360
to avoid orphans as much as possible because after a while orphan nodes will start to accumulate

237
00:19:15,360 --> 00:19:20,880
and if you're not going back and trying to merge and dedupe because that's normally why

238
00:19:20,880 --> 00:19:25,840
those show up is because they're an accidental whoops that's the same thing but we didn't

239
00:19:25,840 --> 00:19:28,560
really identify it as such.

240
00:19:28,560 --> 00:19:32,760
It will create that storm cloud of data above you that you just do not want.

241
00:19:32,760 --> 00:19:34,760
It'll add technical debt.

242
00:19:34,760 --> 00:19:41,040
It will add so much more process to any mapping and matching projects that you have.

243
00:19:42,000 --> 00:19:47,920
Just definitely try to avoid any of the orphan nodes if possible.

244
00:19:47,920 --> 00:19:52,520
Also checking the shape of your knowledge graph.

245
00:19:52,520 --> 00:19:59,680
Some of those hidden relations might have to be explicitly defined in order to do certain

246
00:19:59,680 --> 00:20:01,880
graph ML.

247
00:20:01,880 --> 00:20:08,440
This would be like if you needed a bipartite graph to do certain network analysis that

248
00:20:08,440 --> 00:20:09,960
sort of thing.

249
00:20:09,960 --> 00:20:17,440
Once you have even a small portion of your graph you can start to predict missing nodes

250
00:20:17,440 --> 00:20:24,720
which is interesting because you might have dropped nodes along this evolutionary path.

251
00:20:24,720 --> 00:20:29,400
Remember there was the part node that we may or may not have needed that came from the

252
00:20:29,400 --> 00:20:33,440
taxonomy and we dropped it maybe in the ontology stage.

253
00:20:33,440 --> 00:20:37,560
Well maybe we actually do need that for doing some of the machine learning or maybe you

254
00:20:37,560 --> 00:20:42,840
are starting to identify some of the attributes that you made a decision on in the ontology

255
00:20:42,840 --> 00:20:43,840
stage.

256
00:20:43,840 --> 00:20:45,120
Maybe they actually do need to be nodes.

257
00:20:45,120 --> 00:20:47,920
This is a great place to start to identify that.

258
00:20:47,920 --> 00:20:52,840
You're also going to start to identify dense clusters of really like-minded things.

259
00:20:52,840 --> 00:20:57,280
Things that are highly, highly connected and things that are more on the peripheral.

260
00:20:57,280 --> 00:21:03,360
These are really good to also identify gaps or where your catalog is stronger or weaker.

261
00:21:03,360 --> 00:21:05,440
You can also identify things like bottlenecks.

262
00:21:05,440 --> 00:21:10,760
If you are doing things in the supply chain space where is everything going?

263
00:21:10,760 --> 00:21:14,960
If there's one node that's connecting a lot of other nodes that might be a bottleneck.

264
00:21:14,960 --> 00:21:17,360
You need to maybe look at that.

265
00:21:17,360 --> 00:21:21,960
There's a lot of other data intelligence that you can start to derive once you have this

266
00:21:21,960 --> 00:21:26,000
graph in a true network like state.

267
00:21:26,000 --> 00:21:28,120
So that is this in summary.

268
00:21:28,440 --> 00:21:30,520
It has been a long video.

269
00:21:30,520 --> 00:21:32,880
I am sorry for the length.

270
00:21:32,880 --> 00:21:36,920
But to get through each of these, I know I even glossed over a lot of things in this.

271
00:21:36,920 --> 00:21:41,400
So again, make sure you check down below for some of the links to additional videos to

272
00:21:41,400 --> 00:21:43,480
kind of flesh out more of this.

273
00:21:43,480 --> 00:21:46,120
But this has been a highly requested video.

274
00:21:46,120 --> 00:21:48,040
I really hope that you've enjoyed this.

275
00:21:48,040 --> 00:21:52,400
And if there's anything that you have a question about in any of this, please make sure to reach

276
00:21:52,400 --> 00:21:57,280
out to me on LinkedIn in my email, which is listed in the description box below, or leave

277
00:21:57,280 --> 00:21:59,320
a comment on this video.

278
00:21:59,320 --> 00:22:02,560
And so with that, I want to thank you very much and I'll catch you next time.

