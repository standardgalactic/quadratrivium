{"text": " Hey everybody, so today we are going to be walking through the evolution and how do you model the evolution of a taxonomy to a thesaurus, to an ontology, to a knowledge graph. And just like with any modeling project, your end use case is your guiding light. So the decisions I make in this video may not be the same decisions that you make. And I'm going to walk through why I am making some of those decisions so you can think about what you need to do when you are going through this same process. And just like your end use case, you don't necessarily have to get to the end of this evolutionary stage. If you don't need to make a knowledge graph, you're perfectly fine with just an ontology or maybe you're just wanting to make your taxonomy a little bit more robust so that you have a thesaurus instead. And why is that useful? All of those things I am also going to cover in this video. So if this sounds interesting to you, keep on watching. All right, so starting out, we need to look at what is the use case, and then we need to go and look at what data do we need to supply for this use case. Now you could jump to any one of the models we're going to talk about today in order to answer this question. Some are going to be able to answer this question a lot easier than others. But for the sake of this video, I'm going to be starting with a taxonomy. So in our scenario, this manufacturer does not have a taxonomy and they really need to understand which pieces and parts and components go into any one of their vehicles. So let's start there. Now each of these models can have a much deeper dive associated with them. I cannot do all of those in one whole video. So I have linked every model and corresponding videos that I've done in the past for a deeper dive in each of them if you want to go and check those out. In our scenario, we already have tags, let's assume, on the content and or processes or whatever it is in our, our plants, our manufacturing plants that we can then identify what's going on in each of those plants. The problem is those are just tags. They have no organization to them. So the very first thing we're going to do is we're thinking about how like-minded things go together. Now normally a taxonomy is looking at broader and narrower parent, child or whole part relations. And so you can see here that passenger vehicles have narrower types, right? So another relationship here is type of, and these are not explicit relations. We'll get into that later in other models. Right now these are more inherent by the hierarchy the taxonomy takes on. So here passenger vehicles is the broader or parent of a sport vehicle. And then if we look at the different sports vehicles, there are Mustangs and Raptors because we're looking at all Ford vehicles in this example. You can also see in parts how parts is kind of generic, but it is a container of all of the different parts that would be components in a vehicle. And you can break this up into whatever makes sense for your organization. So for instance, if you want mechanical parts versus nuts and bolts, which are not mechanical in nature, then you can divide them up that way. You really have to keep your end use in mind while you're doing this. For us, we really just need to understand which of these vehicles have specific electric motors in them. Now you are going to notice there is a heavy emphasis in every model on the metadata and the relationships that the model is representing. So these are going to come in handy as we evolve this model into something else. So right now we do not have additional attributes. These taxonomy terms may have unique IDs, but other than the hierarchical look to them, they don't have anything else. This is just adding context by the placement that they have in the tree structure of a taxonomy, as well as how these tags are then connected to the end assets, whether it's a document or an actual component. All right. So now we're building on top of stage one. So everything that we've developed with our taxonomy, the hierarchy, the types of relations that are inherent from that hierarchy are also going to be helpful with the thesaurus. So here we're adding more connective tissue. Every single step in these stages is adding more context, more relations, more of that metadata to help humans and machines make better decisions based on this data. So here we are now adding things like use for those are synonyms and those can be synonyms from different catalogs, different pieces of metadata you're bringing in from different databases. It can be the natural language of your end user. If you're using this taxonomy and thesaurus for search enhancements, you also get things with see also. Now that's going to be really important for ontology and knowledge graph building because see also is a generic form of, oh, hey, there's other things that go along with this that are not pure hierarchical in nature. And so those see also are going to be really helpful in later stages in in all of this. See also is basically looking at how certain clusters of things or branches in your taxonomy are starting to play with others. So for instance, if you are looking at a vehicle, well, a logical representation of a vehicle is all of the different things that go into how that vehicle is constructed, how it goes. So that could be the motor, it could be the fuel, it could be, you know, how those things are supplied as in a pumping station or a charging station, if it's an electric vehicle, think of it almost as composition. If you are composing a room, what things go into any specific room? So if you're looking at a living room, it could be a television, it could be a couch, it could be, you know, wall hangings, it could be speakers. What are all the things that go together to define a living room? Same with a vehicle. What are all of the things that go into defining all of the different aspects of a vehicle? These are going to be incredibly important when we get to the next stage. Other things that are represented in a Thesaurus are looking at definitions. Sometimes you will see things also like scope notes, and that's for human and or computer automated tagging of specific assets or behaviors, if you're looking at a manufacturing plant. It's understanding how these things are contextualized in your specific use case and your specific company. So the jump from a taxonomy to a Thesaurus is not as large as a Thesaurus to an ontology or a Thesaurus to an oligarch for that matter. And a big reason for that is they are representing the world in different ways, where the first two are points, they are tags on specific assets, and the relation between things is a little fuzzy if you're talking about a Thesaurus or implicit, which is more on the hierarchy of a taxonomy. And ontology is starting to make the connective tissue, the contextualization of how two things are related and the network of those things way more explicit. So the very first thing that you're going to want to think about here is what is the focal point of your model? So here you can see that I have done this in three different ways. So our use case today is a catalog of products for the Ford Motor Company. And so therefore the center of a catalog is the product itself, in this case a vehicle. But if I am doing an ontology that is focused on the transactional, the purchasing or the selling or the manufacturing of something, then maybe the VIN number is the center of my transaction, because that is the thing that is the individual specific thing being manufactured or sold connected to the customer, because that's the actual transaction that I am trying to track. Or if I'm looking at a supply chain, maybe where something is manufactured and what they are manufacturing is the center of my model. And identifying this early is really crucial to understand how your model is going to shape up to answer the questions that you are interested in. So once you've identified that, you want to look at the universal containers. That's what ontology is. It's a framework to house things and how those things are related to one another. Now a taxonomy is identifying a universal topic or thing that could be an engine. There is a universal understanding of engine. But once you get into the lower levels of the taxonomy and thesaurus, where it's talking about very specific engines, that might not be part of the ontology. That actually might be an indicator that's part of the knowledge graph portion. It's talking about a very specific instance of an engine. So the way that I like to think about this process is the first to third levels of your taxonomy are usually more of the categorical universal containers of things in your asset or your catalog. And so that's a good indicator that maybe start with those first while you're doing your modeling. As you go, you're going to refine your understanding and you're going to refine what you had from the taxonomy at thesaurus stages because honestly, you might not need all of those nodes from the previous stages. That's part of this modeling process. So when you are looking at those universal categories, there's a really great thing in there. Your instance data, maybe your sub-sub-subclasses in your taxonomy, are going to be mapped. They roll up to those broader level categories. So in a way, you're pre-mapping a ton of your catalog to your ontology, which is a beautiful thing and that's why doing this as an evolution is a really powerful thing if you can do it. The next thing you need to think about is the lowest level of universal data that you need for your use case. So that could be in our use case, we're trying to identify specific electric motors. So maybe I only need to go as low as an electric motor. And by the way, you don't want to create your entire ontology based on only one very unique specific problem statement, but it is a good place to start, but just don't stop there. And with an electric vehicle, that is connected to the electric motor. Maybe that's all the farther I need to go, but if I do need to go even lower and look at specific types of electric motors, let's say there are different brand names, then maybe that's the lowest level of data I need to have for the ontology. So I have a whole nother video going into a deep dive on how to determine something as a class or an instance, and I will leave that down below. But a good rule of thumb is to think about it from this perspective. There is a universal understanding of cat. It is furry, it has whiskers, it meows, it sits in your lap and it lives in your home. But my cat Garfield is a different instance of cat than your cat named Otis. They're both cats, but those are instances of cats. So think of it from that perspective. Anything that has to be very unique and is to the cellular level unique, that's probably an instance and you don't necessarily want that in your ontology. So once you've determined that, you want to then start to look at those broader and narrower relationships that you had from previous steps and you want to make them more explicit. Now you saw that in those previous steps, we did have things like whole part, has part, that sort of thing, that you can just transfer back over into the ontology. Those work really well. But when you're talking about things that are just broader and narrower, you have no idea what the relationship is between those two things. So in that case, here you can see that with parts and engines. In our taxonomy and our thesaurus, they were just nested, right? The engine was nested underneath parts. We didn't really know why they related to each other. Now we're being very explicit. We're saying it is has part, part of. And that also allows us to use that specific relation with any other parts that are in our asset and our catalog data. This is also your opportunity to craft unique relations. And those are like manufactured in these are oftentimes business specific, or these also can be mined from your thesaurus definitions or the assets themselves. So for instance, if you're looking at a description of a product, what other things in your catalog are being mentioned in that description? It's probably a good indicator that they're related in some way. Now the last thing you're going to be looking at are is twofold. So first, you are going to add in additional nodes to flesh out that network. And these are things that are not always found in one table. So this might be something that you'd have to join together. So this could be customer data or transactional data in general. Adding those in fleshes out your network so you don't have to do as many joins, right? This is the beauty of an ontology. It makes those relations inherent rather than having you have to depend on others and your specialized knowledge to make those kinds of relations. Also which is pretty critical for making sure your machine learning and mapping and matching projects go smoother is making sure those used for incentives are added in as attributes. I also just want to note here that some of the nodes that I have in my model, for instance, the class of vehicle, that could be an attribute on the vehicle node. I decided to break it out, but that's part of the modeling process. You have to decide which pieces of information can be descriptors of a node or things that need to be standalone nodes on their own. So one thing I want to just point out is you don't necessarily have to have an ontology to have a knowledge graph. There are other ways to get to knowledge graph outside of an ontology, but think of the ontology stage as you are creating that, again, that framework. It doesn't necessarily have to be a true ontology like an RDF ontology, but it is a representation of the global entities so that you can then get to the knowledge graph stage where you are populating the instance or the very specifics of your graph. Populating your graph can come in a few different forms. In this situation, we are going to be taking all of the things that we identified as instance data from our taxonomy and thesaurus, remember it rolled up into the universal classes that we identified, we are going to be able to populate those as instance very quickly. Sometimes you are going to realize that your model is not quite right and that's because the things that in a taxonomy and thesaurus generally rolled up to the same category don't necessarily work the way you want them to work when you get to the knowledge graph space because now when you start to look at the individual entities, there are some exceptions to the rule and sometimes that means you are going to have to split classes and make a subclass, this is part of that refinement stage. So dovetailing into that, you do want to check a subset of the instance data to verify the logic is sound. This is something I like to use a visual for because then you can see if there is some weird circular logic which by the way happens constantly when you take a taxonomy or a thesaurus and you turn it into an ontology or a knowledge graph. Another thing to watch out for sort of in that same vein is looking at the actual definition of these nodes versus how it is applied to the actual assets or behaviors in your systems just making sure that that logic all checks out and that they align with your business needs because I've seen that taxonomies and thesaurus are not necessarily structured to be used in machine learning or knowledge graphs and therefore some of that logic doesn't always check out once you start to morph these and involve these into other forms. So just be aware of that. You also want to add in some inferred hidden relations. You can identify some of these with things like shortest path. It's basically showing how once you really identify a network of things and how they're you can see the dotted line to additional nodes that you did not even know existed and that's a really powerful piece of knowledge graph and you definitely want to add that in if you can. You also want to identify those exceptions and add cardinality and when you're talking about exceptions you do want to watch out for things like adding orphan nodes you want to avoid orphans as much as possible because after a while orphan nodes will start to accumulate and if you're not going back and trying to merge and dedupe because that's normally why those show up is because they're an accidental whoops that's the same thing but we didn't really identify it as such. It will create that storm cloud of data above you that you just do not want. It'll add technical debt. It will add so much more process to any mapping and matching projects that you have. Just definitely try to avoid any of the orphan nodes if possible. Also checking the shape of your knowledge graph. Some of those hidden relations might have to be explicitly defined in order to do certain graph ML. This would be like if you needed a bipartite graph to do certain network analysis that sort of thing. Once you have even a small portion of your graph you can start to predict missing nodes which is interesting because you might have dropped nodes along this evolutionary path. Remember there was the part node that we may or may not have needed that came from the taxonomy and we dropped it maybe in the ontology stage. Well maybe we actually do need that for doing some of the machine learning or maybe you are starting to identify some of the attributes that you made a decision on in the ontology stage. Maybe they actually do need to be nodes. This is a great place to start to identify that. You're also going to start to identify dense clusters of really like-minded things. Things that are highly, highly connected and things that are more on the peripheral. These are really good to also identify gaps or where your catalog is stronger or weaker. You can also identify things like bottlenecks. If you are doing things in the supply chain space where is everything going? If there's one node that's connecting a lot of other nodes that might be a bottleneck. You need to maybe look at that. There's a lot of other data intelligence that you can start to derive once you have this graph in a true network like state. So that is this in summary. It has been a long video. I am sorry for the length. But to get through each of these, I know I even glossed over a lot of things in this. So again, make sure you check down below for some of the links to additional videos to kind of flesh out more of this. But this has been a highly requested video. I really hope that you've enjoyed this. And if there's anything that you have a question about in any of this, please make sure to reach out to me on LinkedIn in my email, which is listed in the description box below, or leave a comment on this video. And so with that, I want to thank you very much and I'll catch you next time.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.44, "text": " Hey everybody, so today we are going to be walking through the evolution and how do you", "tokens": [50364, 1911, 2201, 11, 370, 965, 321, 366, 516, 281, 312, 4494, 807, 264, 9303, 293, 577, 360, 291, 50636], "temperature": 0.0, "avg_logprob": -0.11363677625302915, "compression_ratio": 1.732, "no_speech_prob": 0.018808115273714066}, {"id": 1, "seek": 0, "start": 5.44, "end": 14.08, "text": " model the evolution of a taxonomy to a thesaurus, to an ontology, to a knowledge graph.", "tokens": [50636, 2316, 264, 9303, 295, 257, 3366, 23423, 281, 257, 264, 82, 40913, 11, 281, 364, 6592, 1793, 11, 281, 257, 3601, 4295, 13, 51068], "temperature": 0.0, "avg_logprob": -0.11363677625302915, "compression_ratio": 1.732, "no_speech_prob": 0.018808115273714066}, {"id": 2, "seek": 0, "start": 14.08, "end": 19.22, "text": " And just like with any modeling project, your end use case is your guiding light.", "tokens": [51068, 400, 445, 411, 365, 604, 15983, 1716, 11, 428, 917, 764, 1389, 307, 428, 25061, 1442, 13, 51325], "temperature": 0.0, "avg_logprob": -0.11363677625302915, "compression_ratio": 1.732, "no_speech_prob": 0.018808115273714066}, {"id": 3, "seek": 0, "start": 19.22, "end": 23.68, "text": " So the decisions I make in this video may not be the same decisions that you make.", "tokens": [51325, 407, 264, 5327, 286, 652, 294, 341, 960, 815, 406, 312, 264, 912, 5327, 300, 291, 652, 13, 51548], "temperature": 0.0, "avg_logprob": -0.11363677625302915, "compression_ratio": 1.732, "no_speech_prob": 0.018808115273714066}, {"id": 4, "seek": 0, "start": 23.68, "end": 28.12, "text": " And I'm going to walk through why I am making some of those decisions so you can think about", "tokens": [51548, 400, 286, 478, 516, 281, 1792, 807, 983, 286, 669, 1455, 512, 295, 729, 5327, 370, 291, 393, 519, 466, 51770], "temperature": 0.0, "avg_logprob": -0.11363677625302915, "compression_ratio": 1.732, "no_speech_prob": 0.018808115273714066}, {"id": 5, "seek": 2812, "start": 28.12, "end": 32.0, "text": " what you need to do when you are going through this same process.", "tokens": [50364, 437, 291, 643, 281, 360, 562, 291, 366, 516, 807, 341, 912, 1399, 13, 50558], "temperature": 0.0, "avg_logprob": -0.1437442073115596, "compression_ratio": 1.7190635451505016, "no_speech_prob": 0.025171203538775444}, {"id": 6, "seek": 2812, "start": 32.0, "end": 36.2, "text": " And just like your end use case, you don't necessarily have to get to the end of this", "tokens": [50558, 400, 445, 411, 428, 917, 764, 1389, 11, 291, 500, 380, 4725, 362, 281, 483, 281, 264, 917, 295, 341, 50768], "temperature": 0.0, "avg_logprob": -0.1437442073115596, "compression_ratio": 1.7190635451505016, "no_speech_prob": 0.025171203538775444}, {"id": 7, "seek": 2812, "start": 36.2, "end": 37.44, "text": " evolutionary stage.", "tokens": [50768, 27567, 3233, 13, 50830], "temperature": 0.0, "avg_logprob": -0.1437442073115596, "compression_ratio": 1.7190635451505016, "no_speech_prob": 0.025171203538775444}, {"id": 8, "seek": 2812, "start": 37.44, "end": 41.8, "text": " If you don't need to make a knowledge graph, you're perfectly fine with just an ontology", "tokens": [50830, 759, 291, 500, 380, 643, 281, 652, 257, 3601, 4295, 11, 291, 434, 6239, 2489, 365, 445, 364, 6592, 1793, 51048], "temperature": 0.0, "avg_logprob": -0.1437442073115596, "compression_ratio": 1.7190635451505016, "no_speech_prob": 0.025171203538775444}, {"id": 9, "seek": 2812, "start": 41.8, "end": 46.68, "text": " or maybe you're just wanting to make your taxonomy a little bit more robust so that you have", "tokens": [51048, 420, 1310, 291, 434, 445, 7935, 281, 652, 428, 3366, 23423, 257, 707, 857, 544, 13956, 370, 300, 291, 362, 51292], "temperature": 0.0, "avg_logprob": -0.1437442073115596, "compression_ratio": 1.7190635451505016, "no_speech_prob": 0.025171203538775444}, {"id": 10, "seek": 2812, "start": 46.68, "end": 48.64, "text": " a thesaurus instead.", "tokens": [51292, 257, 264, 82, 40913, 2602, 13, 51390], "temperature": 0.0, "avg_logprob": -0.1437442073115596, "compression_ratio": 1.7190635451505016, "no_speech_prob": 0.025171203538775444}, {"id": 11, "seek": 2812, "start": 48.64, "end": 50.2, "text": " And why is that useful?", "tokens": [51390, 400, 983, 307, 300, 4420, 30, 51468], "temperature": 0.0, "avg_logprob": -0.1437442073115596, "compression_ratio": 1.7190635451505016, "no_speech_prob": 0.025171203538775444}, {"id": 12, "seek": 2812, "start": 50.2, "end": 52.8, "text": " All of those things I am also going to cover in this video.", "tokens": [51468, 1057, 295, 729, 721, 286, 669, 611, 516, 281, 2060, 294, 341, 960, 13, 51598], "temperature": 0.0, "avg_logprob": -0.1437442073115596, "compression_ratio": 1.7190635451505016, "no_speech_prob": 0.025171203538775444}, {"id": 13, "seek": 2812, "start": 52.8, "end": 55.64, "text": " So if this sounds interesting to you, keep on watching.", "tokens": [51598, 407, 498, 341, 3263, 1880, 281, 291, 11, 1066, 322, 1976, 13, 51740], "temperature": 0.0, "avg_logprob": -0.1437442073115596, "compression_ratio": 1.7190635451505016, "no_speech_prob": 0.025171203538775444}, {"id": 14, "seek": 5564, "start": 55.68, "end": 61.96, "text": " All right, so starting out, we need to look at what is the use case, and then we need", "tokens": [50366, 1057, 558, 11, 370, 2891, 484, 11, 321, 643, 281, 574, 412, 437, 307, 264, 764, 1389, 11, 293, 550, 321, 643, 50680], "temperature": 0.0, "avg_logprob": -0.11280839783804757, "compression_ratio": 1.8034934497816595, "no_speech_prob": 0.021610502153635025}, {"id": 15, "seek": 5564, "start": 61.96, "end": 66.52, "text": " to go and look at what data do we need to supply for this use case.", "tokens": [50680, 281, 352, 293, 574, 412, 437, 1412, 360, 321, 643, 281, 5847, 337, 341, 764, 1389, 13, 50908], "temperature": 0.0, "avg_logprob": -0.11280839783804757, "compression_ratio": 1.8034934497816595, "no_speech_prob": 0.021610502153635025}, {"id": 16, "seek": 5564, "start": 66.52, "end": 73.16, "text": " Now you could jump to any one of the models we're going to talk about today in order to", "tokens": [50908, 823, 291, 727, 3012, 281, 604, 472, 295, 264, 5245, 321, 434, 516, 281, 751, 466, 965, 294, 1668, 281, 51240], "temperature": 0.0, "avg_logprob": -0.11280839783804757, "compression_ratio": 1.8034934497816595, "no_speech_prob": 0.021610502153635025}, {"id": 17, "seek": 5564, "start": 73.16, "end": 74.92, "text": " answer this question.", "tokens": [51240, 1867, 341, 1168, 13, 51328], "temperature": 0.0, "avg_logprob": -0.11280839783804757, "compression_ratio": 1.8034934497816595, "no_speech_prob": 0.021610502153635025}, {"id": 18, "seek": 5564, "start": 74.92, "end": 79.72, "text": " Some are going to be able to answer this question a lot easier than others.", "tokens": [51328, 2188, 366, 516, 281, 312, 1075, 281, 1867, 341, 1168, 257, 688, 3571, 813, 2357, 13, 51568], "temperature": 0.0, "avg_logprob": -0.11280839783804757, "compression_ratio": 1.8034934497816595, "no_speech_prob": 0.021610502153635025}, {"id": 19, "seek": 5564, "start": 79.72, "end": 83.4, "text": " But for the sake of this video, I'm going to be starting with a taxonomy.", "tokens": [51568, 583, 337, 264, 9717, 295, 341, 960, 11, 286, 478, 516, 281, 312, 2891, 365, 257, 3366, 23423, 13, 51752], "temperature": 0.0, "avg_logprob": -0.11280839783804757, "compression_ratio": 1.8034934497816595, "no_speech_prob": 0.021610502153635025}, {"id": 20, "seek": 8340, "start": 83.4, "end": 90.12, "text": " So in our scenario, this manufacturer does not have a taxonomy and they really need to", "tokens": [50364, 407, 294, 527, 9005, 11, 341, 18022, 775, 406, 362, 257, 3366, 23423, 293, 436, 534, 643, 281, 50700], "temperature": 0.0, "avg_logprob": -0.07496347232740752, "compression_ratio": 1.6504065040650406, "no_speech_prob": 0.0023230789229273796}, {"id": 21, "seek": 8340, "start": 90.12, "end": 97.16000000000001, "text": " understand which pieces and parts and components go into any one of their vehicles.", "tokens": [50700, 1223, 597, 3755, 293, 3166, 293, 6677, 352, 666, 604, 472, 295, 641, 8948, 13, 51052], "temperature": 0.0, "avg_logprob": -0.07496347232740752, "compression_ratio": 1.6504065040650406, "no_speech_prob": 0.0023230789229273796}, {"id": 22, "seek": 8340, "start": 97.16000000000001, "end": 98.72, "text": " So let's start there.", "tokens": [51052, 407, 718, 311, 722, 456, 13, 51130], "temperature": 0.0, "avg_logprob": -0.07496347232740752, "compression_ratio": 1.6504065040650406, "no_speech_prob": 0.0023230789229273796}, {"id": 23, "seek": 8340, "start": 98.72, "end": 102.88000000000001, "text": " Now each of these models can have a much deeper dive associated with them.", "tokens": [51130, 823, 1184, 295, 613, 5245, 393, 362, 257, 709, 7731, 9192, 6615, 365, 552, 13, 51338], "temperature": 0.0, "avg_logprob": -0.07496347232740752, "compression_ratio": 1.6504065040650406, "no_speech_prob": 0.0023230789229273796}, {"id": 24, "seek": 8340, "start": 102.88000000000001, "end": 106.16000000000001, "text": " I cannot do all of those in one whole video.", "tokens": [51338, 286, 2644, 360, 439, 295, 729, 294, 472, 1379, 960, 13, 51502], "temperature": 0.0, "avg_logprob": -0.07496347232740752, "compression_ratio": 1.6504065040650406, "no_speech_prob": 0.0023230789229273796}, {"id": 25, "seek": 8340, "start": 106.16000000000001, "end": 111.72, "text": " So I have linked every model and corresponding videos that I've done in the past for a deeper", "tokens": [51502, 407, 286, 362, 9408, 633, 2316, 293, 11760, 2145, 300, 286, 600, 1096, 294, 264, 1791, 337, 257, 7731, 51780], "temperature": 0.0, "avg_logprob": -0.07496347232740752, "compression_ratio": 1.6504065040650406, "no_speech_prob": 0.0023230789229273796}, {"id": 26, "seek": 11172, "start": 111.72, "end": 114.88, "text": " dive in each of them if you want to go and check those out.", "tokens": [50364, 9192, 294, 1184, 295, 552, 498, 291, 528, 281, 352, 293, 1520, 729, 484, 13, 50522], "temperature": 0.0, "avg_logprob": -0.10973444238173223, "compression_ratio": 1.6953125, "no_speech_prob": 0.006096877623349428}, {"id": 27, "seek": 11172, "start": 114.88, "end": 122.84, "text": " In our scenario, we already have tags, let's assume, on the content and or processes or", "tokens": [50522, 682, 527, 9005, 11, 321, 1217, 362, 18632, 11, 718, 311, 6552, 11, 322, 264, 2701, 293, 420, 7555, 420, 50920], "temperature": 0.0, "avg_logprob": -0.10973444238173223, "compression_ratio": 1.6953125, "no_speech_prob": 0.006096877623349428}, {"id": 28, "seek": 11172, "start": 122.84, "end": 130.24, "text": " whatever it is in our, our plants, our manufacturing plants that we can then identify what's going", "tokens": [50920, 2035, 309, 307, 294, 527, 11, 527, 5972, 11, 527, 11096, 5972, 300, 321, 393, 550, 5876, 437, 311, 516, 51290], "temperature": 0.0, "avg_logprob": -0.10973444238173223, "compression_ratio": 1.6953125, "no_speech_prob": 0.006096877623349428}, {"id": 29, "seek": 11172, "start": 130.24, "end": 132.07999999999998, "text": " on in each of those plants.", "tokens": [51290, 322, 294, 1184, 295, 729, 5972, 13, 51382], "temperature": 0.0, "avg_logprob": -0.10973444238173223, "compression_ratio": 1.6953125, "no_speech_prob": 0.006096877623349428}, {"id": 30, "seek": 11172, "start": 132.07999999999998, "end": 133.72, "text": " The problem is those are just tags.", "tokens": [51382, 440, 1154, 307, 729, 366, 445, 18632, 13, 51464], "temperature": 0.0, "avg_logprob": -0.10973444238173223, "compression_ratio": 1.6953125, "no_speech_prob": 0.006096877623349428}, {"id": 31, "seek": 11172, "start": 133.72, "end": 135.88, "text": " They have no organization to them.", "tokens": [51464, 814, 362, 572, 4475, 281, 552, 13, 51572], "temperature": 0.0, "avg_logprob": -0.10973444238173223, "compression_ratio": 1.6953125, "no_speech_prob": 0.006096877623349428}, {"id": 32, "seek": 11172, "start": 135.88, "end": 141.44, "text": " So the very first thing we're going to do is we're thinking about how like-minded things", "tokens": [51572, 407, 264, 588, 700, 551, 321, 434, 516, 281, 360, 307, 321, 434, 1953, 466, 577, 411, 12, 23310, 721, 51850], "temperature": 0.0, "avg_logprob": -0.10973444238173223, "compression_ratio": 1.6953125, "no_speech_prob": 0.006096877623349428}, {"id": 33, "seek": 14144, "start": 141.44, "end": 142.88, "text": " go together.", "tokens": [50364, 352, 1214, 13, 50436], "temperature": 0.0, "avg_logprob": -0.14715763040491053, "compression_ratio": 1.5477386934673367, "no_speech_prob": 0.02930252067744732}, {"id": 34, "seek": 14144, "start": 142.88, "end": 153.04, "text": " Now normally a taxonomy is looking at broader and narrower parent, child or whole part relations.", "tokens": [50436, 823, 5646, 257, 3366, 23423, 307, 1237, 412, 13227, 293, 46751, 2596, 11, 1440, 420, 1379, 644, 2299, 13, 50944], "temperature": 0.0, "avg_logprob": -0.14715763040491053, "compression_ratio": 1.5477386934673367, "no_speech_prob": 0.02930252067744732}, {"id": 35, "seek": 14144, "start": 153.04, "end": 159.2, "text": " And so you can see here that passenger vehicles have narrower types, right?", "tokens": [50944, 400, 370, 291, 393, 536, 510, 300, 18707, 8948, 362, 46751, 3467, 11, 558, 30, 51252], "temperature": 0.0, "avg_logprob": -0.14715763040491053, "compression_ratio": 1.5477386934673367, "no_speech_prob": 0.02930252067744732}, {"id": 36, "seek": 14144, "start": 159.2, "end": 164.56, "text": " So another relationship here is type of, and these are not explicit relations.", "tokens": [51252, 407, 1071, 2480, 510, 307, 2010, 295, 11, 293, 613, 366, 406, 13691, 2299, 13, 51520], "temperature": 0.0, "avg_logprob": -0.14715763040491053, "compression_ratio": 1.5477386934673367, "no_speech_prob": 0.02930252067744732}, {"id": 37, "seek": 14144, "start": 164.56, "end": 167.56, "text": " We'll get into that later in other models.", "tokens": [51520, 492, 603, 483, 666, 300, 1780, 294, 661, 5245, 13, 51670], "temperature": 0.0, "avg_logprob": -0.14715763040491053, "compression_ratio": 1.5477386934673367, "no_speech_prob": 0.02930252067744732}, {"id": 38, "seek": 16756, "start": 167.56, "end": 173.24, "text": " Right now these are more inherent by the hierarchy the taxonomy takes on.", "tokens": [50364, 1779, 586, 613, 366, 544, 26387, 538, 264, 22333, 264, 3366, 23423, 2516, 322, 13, 50648], "temperature": 0.0, "avg_logprob": -0.09972564033840013, "compression_ratio": 1.6223175965665235, "no_speech_prob": 0.19675394892692566}, {"id": 39, "seek": 16756, "start": 173.24, "end": 181.04, "text": " So here passenger vehicles is the broader or parent of a sport vehicle.", "tokens": [50648, 407, 510, 18707, 8948, 307, 264, 13227, 420, 2596, 295, 257, 7282, 5864, 13, 51038], "temperature": 0.0, "avg_logprob": -0.09972564033840013, "compression_ratio": 1.6223175965665235, "no_speech_prob": 0.19675394892692566}, {"id": 40, "seek": 16756, "start": 181.04, "end": 186.6, "text": " And then if we look at the different sports vehicles, there are Mustangs and Raptors because", "tokens": [51038, 400, 550, 498, 321, 574, 412, 264, 819, 6573, 8948, 11, 456, 366, 13252, 28686, 293, 38115, 830, 570, 51316], "temperature": 0.0, "avg_logprob": -0.09972564033840013, "compression_ratio": 1.6223175965665235, "no_speech_prob": 0.19675394892692566}, {"id": 41, "seek": 16756, "start": 186.6, "end": 190.4, "text": " we're looking at all Ford vehicles in this example.", "tokens": [51316, 321, 434, 1237, 412, 439, 11961, 8948, 294, 341, 1365, 13, 51506], "temperature": 0.0, "avg_logprob": -0.09972564033840013, "compression_ratio": 1.6223175965665235, "no_speech_prob": 0.19675394892692566}, {"id": 42, "seek": 16756, "start": 190.4, "end": 197.2, "text": " You can also see in parts how parts is kind of generic, but it is a container of all of", "tokens": [51506, 509, 393, 611, 536, 294, 3166, 577, 3166, 307, 733, 295, 19577, 11, 457, 309, 307, 257, 10129, 295, 439, 295, 51846], "temperature": 0.0, "avg_logprob": -0.09972564033840013, "compression_ratio": 1.6223175965665235, "no_speech_prob": 0.19675394892692566}, {"id": 43, "seek": 19720, "start": 197.2, "end": 201.6, "text": " the different parts that would be components in a vehicle.", "tokens": [50364, 264, 819, 3166, 300, 576, 312, 6677, 294, 257, 5864, 13, 50584], "temperature": 0.0, "avg_logprob": -0.10767602474890023, "compression_ratio": 1.652014652014652, "no_speech_prob": 0.11590857803821564}, {"id": 44, "seek": 19720, "start": 201.6, "end": 205.67999999999998, "text": " And you can break this up into whatever makes sense for your organization.", "tokens": [50584, 400, 291, 393, 1821, 341, 493, 666, 2035, 1669, 2020, 337, 428, 4475, 13, 50788], "temperature": 0.0, "avg_logprob": -0.10767602474890023, "compression_ratio": 1.652014652014652, "no_speech_prob": 0.11590857803821564}, {"id": 45, "seek": 19720, "start": 205.67999999999998, "end": 211.48, "text": " So for instance, if you want mechanical parts versus nuts and bolts, which are not mechanical", "tokens": [50788, 407, 337, 5197, 11, 498, 291, 528, 12070, 3166, 5717, 10483, 293, 18127, 11, 597, 366, 406, 12070, 51078], "temperature": 0.0, "avg_logprob": -0.10767602474890023, "compression_ratio": 1.652014652014652, "no_speech_prob": 0.11590857803821564}, {"id": 46, "seek": 19720, "start": 211.48, "end": 214.64, "text": " in nature, then you can divide them up that way.", "tokens": [51078, 294, 3687, 11, 550, 291, 393, 9845, 552, 493, 300, 636, 13, 51236], "temperature": 0.0, "avg_logprob": -0.10767602474890023, "compression_ratio": 1.652014652014652, "no_speech_prob": 0.11590857803821564}, {"id": 47, "seek": 19720, "start": 214.64, "end": 218.23999999999998, "text": " You really have to keep your end use in mind while you're doing this.", "tokens": [51236, 509, 534, 362, 281, 1066, 428, 917, 764, 294, 1575, 1339, 291, 434, 884, 341, 13, 51416], "temperature": 0.0, "avg_logprob": -0.10767602474890023, "compression_ratio": 1.652014652014652, "no_speech_prob": 0.11590857803821564}, {"id": 48, "seek": 19720, "start": 218.23999999999998, "end": 223.92, "text": " For us, we really just need to understand which of these vehicles have specific electric", "tokens": [51416, 1171, 505, 11, 321, 534, 445, 643, 281, 1223, 597, 295, 613, 8948, 362, 2685, 5210, 51700], "temperature": 0.0, "avg_logprob": -0.10767602474890023, "compression_ratio": 1.652014652014652, "no_speech_prob": 0.11590857803821564}, {"id": 49, "seek": 19720, "start": 223.92, "end": 225.0, "text": " motors in them.", "tokens": [51700, 25035, 294, 552, 13, 51754], "temperature": 0.0, "avg_logprob": -0.10767602474890023, "compression_ratio": 1.652014652014652, "no_speech_prob": 0.11590857803821564}, {"id": 50, "seek": 22500, "start": 225.0, "end": 232.6, "text": " Now you are going to notice there is a heavy emphasis in every model on the metadata and", "tokens": [50364, 823, 291, 366, 516, 281, 3449, 456, 307, 257, 4676, 16271, 294, 633, 2316, 322, 264, 26603, 293, 50744], "temperature": 0.0, "avg_logprob": -0.09263820032919606, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.0018674306338652968}, {"id": 51, "seek": 22500, "start": 232.6, "end": 236.56, "text": " the relationships that the model is representing.", "tokens": [50744, 264, 6159, 300, 264, 2316, 307, 13460, 13, 50942], "temperature": 0.0, "avg_logprob": -0.09263820032919606, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.0018674306338652968}, {"id": 52, "seek": 22500, "start": 236.56, "end": 241.38, "text": " So these are going to come in handy as we evolve this model into something else.", "tokens": [50942, 407, 613, 366, 516, 281, 808, 294, 13239, 382, 321, 16693, 341, 2316, 666, 746, 1646, 13, 51183], "temperature": 0.0, "avg_logprob": -0.09263820032919606, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.0018674306338652968}, {"id": 53, "seek": 22500, "start": 241.38, "end": 245.88, "text": " So right now we do not have additional attributes.", "tokens": [51183, 407, 558, 586, 321, 360, 406, 362, 4497, 17212, 13, 51408], "temperature": 0.0, "avg_logprob": -0.09263820032919606, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.0018674306338652968}, {"id": 54, "seek": 22500, "start": 245.88, "end": 252.72, "text": " These taxonomy terms may have unique IDs, but other than the hierarchical look to them,", "tokens": [51408, 1981, 3366, 23423, 2115, 815, 362, 3845, 48212, 11, 457, 661, 813, 264, 35250, 804, 574, 281, 552, 11, 51750], "temperature": 0.0, "avg_logprob": -0.09263820032919606, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.0018674306338652968}, {"id": 55, "seek": 22500, "start": 252.72, "end": 253.88, "text": " they don't have anything else.", "tokens": [51750, 436, 500, 380, 362, 1340, 1646, 13, 51808], "temperature": 0.0, "avg_logprob": -0.09263820032919606, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.0018674306338652968}, {"id": 56, "seek": 25388, "start": 253.88, "end": 259.88, "text": " This is just adding context by the placement that they have in the tree structure of a", "tokens": [50364, 639, 307, 445, 5127, 4319, 538, 264, 17257, 300, 436, 362, 294, 264, 4230, 3877, 295, 257, 50664], "temperature": 0.0, "avg_logprob": -0.13275636037190755, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.00317243835888803}, {"id": 57, "seek": 25388, "start": 259.88, "end": 267.12, "text": " taxonomy, as well as how these tags are then connected to the end assets, whether it's", "tokens": [50664, 3366, 23423, 11, 382, 731, 382, 577, 613, 18632, 366, 550, 4582, 281, 264, 917, 9769, 11, 1968, 309, 311, 51026], "temperature": 0.0, "avg_logprob": -0.13275636037190755, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.00317243835888803}, {"id": 58, "seek": 25388, "start": 267.12, "end": 269.68, "text": " a document or an actual component.", "tokens": [51026, 257, 4166, 420, 364, 3539, 6542, 13, 51154], "temperature": 0.0, "avg_logprob": -0.13275636037190755, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.00317243835888803}, {"id": 59, "seek": 25388, "start": 269.68, "end": 270.68, "text": " All right.", "tokens": [51154, 1057, 558, 13, 51204], "temperature": 0.0, "avg_logprob": -0.13275636037190755, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.00317243835888803}, {"id": 60, "seek": 25388, "start": 270.68, "end": 275.36, "text": " So now we're building on top of stage one.", "tokens": [51204, 407, 586, 321, 434, 2390, 322, 1192, 295, 3233, 472, 13, 51438], "temperature": 0.0, "avg_logprob": -0.13275636037190755, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.00317243835888803}, {"id": 61, "seek": 25388, "start": 275.36, "end": 280.64, "text": " So everything that we've developed with our taxonomy, the hierarchy, the types of relations", "tokens": [51438, 407, 1203, 300, 321, 600, 4743, 365, 527, 3366, 23423, 11, 264, 22333, 11, 264, 3467, 295, 2299, 51702], "temperature": 0.0, "avg_logprob": -0.13275636037190755, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.00317243835888803}, {"id": 62, "seek": 28064, "start": 280.64, "end": 286.88, "text": " that are inherent from that hierarchy are also going to be helpful with the thesaurus.", "tokens": [50364, 300, 366, 26387, 490, 300, 22333, 366, 611, 516, 281, 312, 4961, 365, 264, 264, 82, 40913, 13, 50676], "temperature": 0.0, "avg_logprob": -0.09052393513341103, "compression_ratio": 1.7168141592920354, "no_speech_prob": 0.009411205537617207}, {"id": 63, "seek": 28064, "start": 286.88, "end": 289.96, "text": " So here we're adding more connective tissue.", "tokens": [50676, 407, 510, 321, 434, 5127, 544, 1745, 488, 12404, 13, 50830], "temperature": 0.0, "avg_logprob": -0.09052393513341103, "compression_ratio": 1.7168141592920354, "no_speech_prob": 0.009411205537617207}, {"id": 64, "seek": 28064, "start": 289.96, "end": 296.71999999999997, "text": " Every single step in these stages is adding more context, more relations, more of that", "tokens": [50830, 2048, 2167, 1823, 294, 613, 10232, 307, 5127, 544, 4319, 11, 544, 2299, 11, 544, 295, 300, 51168], "temperature": 0.0, "avg_logprob": -0.09052393513341103, "compression_ratio": 1.7168141592920354, "no_speech_prob": 0.009411205537617207}, {"id": 65, "seek": 28064, "start": 296.71999999999997, "end": 302.5, "text": " metadata to help humans and machines make better decisions based on this data.", "tokens": [51168, 26603, 281, 854, 6255, 293, 8379, 652, 1101, 5327, 2361, 322, 341, 1412, 13, 51457], "temperature": 0.0, "avg_logprob": -0.09052393513341103, "compression_ratio": 1.7168141592920354, "no_speech_prob": 0.009411205537617207}, {"id": 66, "seek": 28064, "start": 302.5, "end": 308.2, "text": " So here we are now adding things like use for those are synonyms and those can be synonyms", "tokens": [51457, 407, 510, 321, 366, 586, 5127, 721, 411, 764, 337, 729, 366, 5451, 2526, 2592, 293, 729, 393, 312, 5451, 2526, 2592, 51742], "temperature": 0.0, "avg_logprob": -0.09052393513341103, "compression_ratio": 1.7168141592920354, "no_speech_prob": 0.009411205537617207}, {"id": 67, "seek": 30820, "start": 308.2, "end": 313.03999999999996, "text": " from different catalogs, different pieces of metadata you're bringing in from different", "tokens": [50364, 490, 819, 19746, 82, 11, 819, 3755, 295, 26603, 291, 434, 5062, 294, 490, 819, 50606], "temperature": 0.0, "avg_logprob": -0.12494644129051352, "compression_ratio": 1.6901960784313725, "no_speech_prob": 0.07584206014871597}, {"id": 68, "seek": 30820, "start": 313.03999999999996, "end": 314.03999999999996, "text": " databases.", "tokens": [50606, 22380, 13, 50656], "temperature": 0.0, "avg_logprob": -0.12494644129051352, "compression_ratio": 1.6901960784313725, "no_speech_prob": 0.07584206014871597}, {"id": 69, "seek": 30820, "start": 314.03999999999996, "end": 317.0, "text": " It can be the natural language of your end user.", "tokens": [50656, 467, 393, 312, 264, 3303, 2856, 295, 428, 917, 4195, 13, 50804], "temperature": 0.0, "avg_logprob": -0.12494644129051352, "compression_ratio": 1.6901960784313725, "no_speech_prob": 0.07584206014871597}, {"id": 70, "seek": 30820, "start": 317.0, "end": 323.48, "text": " If you're using this taxonomy and thesaurus for search enhancements, you also get things", "tokens": [50804, 759, 291, 434, 1228, 341, 3366, 23423, 293, 264, 82, 40913, 337, 3164, 11985, 1117, 11, 291, 611, 483, 721, 51128], "temperature": 0.0, "avg_logprob": -0.12494644129051352, "compression_ratio": 1.6901960784313725, "no_speech_prob": 0.07584206014871597}, {"id": 71, "seek": 30820, "start": 323.48, "end": 325.03999999999996, "text": " with see also.", "tokens": [51128, 365, 536, 611, 13, 51206], "temperature": 0.0, "avg_logprob": -0.12494644129051352, "compression_ratio": 1.6901960784313725, "no_speech_prob": 0.07584206014871597}, {"id": 72, "seek": 30820, "start": 325.03999999999996, "end": 329.64, "text": " Now that's going to be really important for ontology and knowledge graph building because", "tokens": [51206, 823, 300, 311, 516, 281, 312, 534, 1021, 337, 6592, 1793, 293, 3601, 4295, 2390, 570, 51436], "temperature": 0.0, "avg_logprob": -0.12494644129051352, "compression_ratio": 1.6901960784313725, "no_speech_prob": 0.07584206014871597}, {"id": 73, "seek": 30820, "start": 329.64, "end": 335.68, "text": " see also is a generic form of, oh, hey, there's other things that go along with this that", "tokens": [51436, 536, 611, 307, 257, 19577, 1254, 295, 11, 1954, 11, 4177, 11, 456, 311, 661, 721, 300, 352, 2051, 365, 341, 300, 51738], "temperature": 0.0, "avg_logprob": -0.12494644129051352, "compression_ratio": 1.6901960784313725, "no_speech_prob": 0.07584206014871597}, {"id": 74, "seek": 33568, "start": 335.68, "end": 340.12, "text": " are not pure hierarchical in nature.", "tokens": [50364, 366, 406, 6075, 35250, 804, 294, 3687, 13, 50586], "temperature": 0.0, "avg_logprob": -0.11295256160554432, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.04741532355546951}, {"id": 75, "seek": 33568, "start": 340.12, "end": 345.48, "text": " And so those see also are going to be really helpful in later stages in in all of this.", "tokens": [50586, 400, 370, 729, 536, 611, 366, 516, 281, 312, 534, 4961, 294, 1780, 10232, 294, 294, 439, 295, 341, 13, 50854], "temperature": 0.0, "avg_logprob": -0.11295256160554432, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.04741532355546951}, {"id": 76, "seek": 33568, "start": 345.48, "end": 355.0, "text": " See also is basically looking at how certain clusters of things or branches in your taxonomy", "tokens": [50854, 3008, 611, 307, 1936, 1237, 412, 577, 1629, 23313, 295, 721, 420, 14770, 294, 428, 3366, 23423, 51330], "temperature": 0.0, "avg_logprob": -0.11295256160554432, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.04741532355546951}, {"id": 77, "seek": 33568, "start": 355.0, "end": 357.96000000000004, "text": " are starting to play with others.", "tokens": [51330, 366, 2891, 281, 862, 365, 2357, 13, 51478], "temperature": 0.0, "avg_logprob": -0.11295256160554432, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.04741532355546951}, {"id": 78, "seek": 33568, "start": 357.96000000000004, "end": 364.12, "text": " So for instance, if you are looking at a vehicle, well, a logical representation of a vehicle", "tokens": [51478, 407, 337, 5197, 11, 498, 291, 366, 1237, 412, 257, 5864, 11, 731, 11, 257, 14978, 10290, 295, 257, 5864, 51786], "temperature": 0.0, "avg_logprob": -0.11295256160554432, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.04741532355546951}, {"id": 79, "seek": 36412, "start": 364.12, "end": 371.88, "text": " is all of the different things that go into how that vehicle is constructed, how it goes.", "tokens": [50364, 307, 439, 295, 264, 819, 721, 300, 352, 666, 577, 300, 5864, 307, 17083, 11, 577, 309, 1709, 13, 50752], "temperature": 0.0, "avg_logprob": -0.1320511377774752, "compression_ratio": 1.6833333333333333, "no_speech_prob": 0.27487748861312866}, {"id": 80, "seek": 36412, "start": 371.88, "end": 376.32, "text": " So that could be the motor, it could be the fuel, it could be, you know, how those things", "tokens": [50752, 407, 300, 727, 312, 264, 5932, 11, 309, 727, 312, 264, 6616, 11, 309, 727, 312, 11, 291, 458, 11, 577, 729, 721, 50974], "temperature": 0.0, "avg_logprob": -0.1320511377774752, "compression_ratio": 1.6833333333333333, "no_speech_prob": 0.27487748861312866}, {"id": 81, "seek": 36412, "start": 376.32, "end": 382.44, "text": " are supplied as in a pumping station or a charging station, if it's an electric vehicle,", "tokens": [50974, 366, 27625, 382, 294, 257, 27131, 5214, 420, 257, 11379, 5214, 11, 498, 309, 311, 364, 5210, 5864, 11, 51280], "temperature": 0.0, "avg_logprob": -0.1320511377774752, "compression_ratio": 1.6833333333333333, "no_speech_prob": 0.27487748861312866}, {"id": 82, "seek": 36412, "start": 382.44, "end": 385.44, "text": " think of it almost as composition.", "tokens": [51280, 519, 295, 309, 1920, 382, 12686, 13, 51430], "temperature": 0.0, "avg_logprob": -0.1320511377774752, "compression_ratio": 1.6833333333333333, "no_speech_prob": 0.27487748861312866}, {"id": 83, "seek": 38544, "start": 385.44, "end": 394.52, "text": " If you are composing a room, what things go into any specific room?", "tokens": [50364, 759, 291, 366, 715, 6110, 257, 1808, 11, 437, 721, 352, 666, 604, 2685, 1808, 30, 50818], "temperature": 0.0, "avg_logprob": -0.07507985942768601, "compression_ratio": 1.9310344827586208, "no_speech_prob": 0.6582211852073669}, {"id": 84, "seek": 38544, "start": 394.52, "end": 399.6, "text": " So if you're looking at a living room, it could be a television, it could be a couch,", "tokens": [50818, 407, 498, 291, 434, 1237, 412, 257, 2647, 1808, 11, 309, 727, 312, 257, 8815, 11, 309, 727, 312, 257, 16511, 11, 51072], "temperature": 0.0, "avg_logprob": -0.07507985942768601, "compression_ratio": 1.9310344827586208, "no_speech_prob": 0.6582211852073669}, {"id": 85, "seek": 38544, "start": 399.6, "end": 403.44, "text": " it could be, you know, wall hangings, it could be speakers.", "tokens": [51072, 309, 727, 312, 11, 291, 458, 11, 2929, 3967, 1109, 11, 309, 727, 312, 9518, 13, 51264], "temperature": 0.0, "avg_logprob": -0.07507985942768601, "compression_ratio": 1.9310344827586208, "no_speech_prob": 0.6582211852073669}, {"id": 86, "seek": 38544, "start": 403.44, "end": 409.32, "text": " What are all the things that go together to define a living room?", "tokens": [51264, 708, 366, 439, 264, 721, 300, 352, 1214, 281, 6964, 257, 2647, 1808, 30, 51558], "temperature": 0.0, "avg_logprob": -0.07507985942768601, "compression_ratio": 1.9310344827586208, "no_speech_prob": 0.6582211852073669}, {"id": 87, "seek": 38544, "start": 409.32, "end": 410.32, "text": " Same with a vehicle.", "tokens": [51558, 10635, 365, 257, 5864, 13, 51608], "temperature": 0.0, "avg_logprob": -0.07507985942768601, "compression_ratio": 1.9310344827586208, "no_speech_prob": 0.6582211852073669}, {"id": 88, "seek": 38544, "start": 410.32, "end": 415.4, "text": " What are all of the things that go into defining all of the different aspects of a vehicle?", "tokens": [51608, 708, 366, 439, 295, 264, 721, 300, 352, 666, 17827, 439, 295, 264, 819, 7270, 295, 257, 5864, 30, 51862], "temperature": 0.0, "avg_logprob": -0.07507985942768601, "compression_ratio": 1.9310344827586208, "no_speech_prob": 0.6582211852073669}, {"id": 89, "seek": 41540, "start": 415.4, "end": 419.15999999999997, "text": " These are going to be incredibly important when we get to the next stage.", "tokens": [50364, 1981, 366, 516, 281, 312, 6252, 1021, 562, 321, 483, 281, 264, 958, 3233, 13, 50552], "temperature": 0.0, "avg_logprob": -0.15198632290488795, "compression_ratio": 1.6692307692307693, "no_speech_prob": 0.03307086229324341}, {"id": 90, "seek": 41540, "start": 419.15999999999997, "end": 424.52, "text": " Other things that are represented in a Thesaurus are looking at definitions.", "tokens": [50552, 5358, 721, 300, 366, 10379, 294, 257, 334, 279, 40913, 366, 1237, 412, 21988, 13, 50820], "temperature": 0.0, "avg_logprob": -0.15198632290488795, "compression_ratio": 1.6692307692307693, "no_speech_prob": 0.03307086229324341}, {"id": 91, "seek": 41540, "start": 424.52, "end": 430.4, "text": " Sometimes you will see things also like scope notes, and that's for human and or computer", "tokens": [50820, 4803, 291, 486, 536, 721, 611, 411, 11923, 5570, 11, 293, 300, 311, 337, 1952, 293, 420, 3820, 51114], "temperature": 0.0, "avg_logprob": -0.15198632290488795, "compression_ratio": 1.6692307692307693, "no_speech_prob": 0.03307086229324341}, {"id": 92, "seek": 41540, "start": 430.4, "end": 438.12, "text": " automated tagging of specific assets or behaviors, if you're looking at a manufacturing plant.", "tokens": [51114, 18473, 6162, 3249, 295, 2685, 9769, 420, 15501, 11, 498, 291, 434, 1237, 412, 257, 11096, 3709, 13, 51500], "temperature": 0.0, "avg_logprob": -0.15198632290488795, "compression_ratio": 1.6692307692307693, "no_speech_prob": 0.03307086229324341}, {"id": 93, "seek": 41540, "start": 438.12, "end": 444.64, "text": " It's understanding how these things are contextualized in your specific use case and your specific", "tokens": [51500, 467, 311, 3701, 577, 613, 721, 366, 35526, 1602, 294, 428, 2685, 764, 1389, 293, 428, 2685, 51826], "temperature": 0.0, "avg_logprob": -0.15198632290488795, "compression_ratio": 1.6692307692307693, "no_speech_prob": 0.03307086229324341}, {"id": 94, "seek": 44464, "start": 444.64, "end": 446.2, "text": " company.", "tokens": [50364, 2237, 13, 50442], "temperature": 0.0, "avg_logprob": -0.16024244501349633, "compression_ratio": 1.649746192893401, "no_speech_prob": 0.024417979642748833}, {"id": 95, "seek": 44464, "start": 446.2, "end": 453.32, "text": " So the jump from a taxonomy to a Thesaurus is not as large as a Thesaurus to an ontology", "tokens": [50442, 407, 264, 3012, 490, 257, 3366, 23423, 281, 257, 334, 279, 40913, 307, 406, 382, 2416, 382, 257, 334, 279, 40913, 281, 364, 6592, 1793, 50798], "temperature": 0.0, "avg_logprob": -0.16024244501349633, "compression_ratio": 1.649746192893401, "no_speech_prob": 0.024417979642748833}, {"id": 96, "seek": 44464, "start": 453.32, "end": 456.71999999999997, "text": " or a Thesaurus to an oligarch for that matter.", "tokens": [50798, 420, 257, 334, 279, 40913, 281, 364, 2545, 328, 1178, 337, 300, 1871, 13, 50968], "temperature": 0.0, "avg_logprob": -0.16024244501349633, "compression_ratio": 1.649746192893401, "no_speech_prob": 0.024417979642748833}, {"id": 97, "seek": 44464, "start": 456.71999999999997, "end": 463.4, "text": " And a big reason for that is they are representing the world in different ways, where the first", "tokens": [50968, 400, 257, 955, 1778, 337, 300, 307, 436, 366, 13460, 264, 1002, 294, 819, 2098, 11, 689, 264, 700, 51302], "temperature": 0.0, "avg_logprob": -0.16024244501349633, "compression_ratio": 1.649746192893401, "no_speech_prob": 0.024417979642748833}, {"id": 98, "seek": 44464, "start": 463.4, "end": 471.76, "text": " two are points, they are tags on specific assets, and the relation between things is", "tokens": [51302, 732, 366, 2793, 11, 436, 366, 18632, 322, 2685, 9769, 11, 293, 264, 9721, 1296, 721, 307, 51720], "temperature": 0.0, "avg_logprob": -0.16024244501349633, "compression_ratio": 1.649746192893401, "no_speech_prob": 0.024417979642748833}, {"id": 99, "seek": 47176, "start": 471.76, "end": 477.84, "text": " a little fuzzy if you're talking about a Thesaurus or implicit, which is more on the", "tokens": [50364, 257, 707, 34710, 498, 291, 434, 1417, 466, 257, 334, 279, 40913, 420, 26947, 11, 597, 307, 544, 322, 264, 50668], "temperature": 0.0, "avg_logprob": -0.1078430712223053, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.15600177645683289}, {"id": 100, "seek": 47176, "start": 477.84, "end": 479.88, "text": " hierarchy of a taxonomy.", "tokens": [50668, 22333, 295, 257, 3366, 23423, 13, 50770], "temperature": 0.0, "avg_logprob": -0.1078430712223053, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.15600177645683289}, {"id": 101, "seek": 47176, "start": 479.88, "end": 486.56, "text": " And ontology is starting to make the connective tissue, the contextualization of how two things", "tokens": [50770, 400, 6592, 1793, 307, 2891, 281, 652, 264, 1745, 488, 12404, 11, 264, 35526, 2144, 295, 577, 732, 721, 51104], "temperature": 0.0, "avg_logprob": -0.1078430712223053, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.15600177645683289}, {"id": 102, "seek": 47176, "start": 486.56, "end": 491.56, "text": " are related and the network of those things way more explicit.", "tokens": [51104, 366, 4077, 293, 264, 3209, 295, 729, 721, 636, 544, 13691, 13, 51354], "temperature": 0.0, "avg_logprob": -0.1078430712223053, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.15600177645683289}, {"id": 103, "seek": 47176, "start": 491.56, "end": 496.08, "text": " So the very first thing that you're going to want to think about here is what is the", "tokens": [51354, 407, 264, 588, 700, 551, 300, 291, 434, 516, 281, 528, 281, 519, 466, 510, 307, 437, 307, 264, 51580], "temperature": 0.0, "avg_logprob": -0.1078430712223053, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.15600177645683289}, {"id": 104, "seek": 47176, "start": 496.08, "end": 498.56, "text": " focal point of your model?", "tokens": [51580, 26592, 935, 295, 428, 2316, 30, 51704], "temperature": 0.0, "avg_logprob": -0.1078430712223053, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.15600177645683289}, {"id": 105, "seek": 49856, "start": 498.56, "end": 501.92, "text": " So here you can see that I have done this in three different ways.", "tokens": [50364, 407, 510, 291, 393, 536, 300, 286, 362, 1096, 341, 294, 1045, 819, 2098, 13, 50532], "temperature": 0.0, "avg_logprob": -0.10965065956115723, "compression_ratio": 1.5637254901960784, "no_speech_prob": 0.14408452808856964}, {"id": 106, "seek": 49856, "start": 501.92, "end": 509.12, "text": " So our use case today is a catalog of products for the Ford Motor Company.", "tokens": [50532, 407, 527, 764, 1389, 965, 307, 257, 19746, 295, 3383, 337, 264, 11961, 18495, 13918, 13, 50892], "temperature": 0.0, "avg_logprob": -0.10965065956115723, "compression_ratio": 1.5637254901960784, "no_speech_prob": 0.14408452808856964}, {"id": 107, "seek": 49856, "start": 509.12, "end": 515.62, "text": " And so therefore the center of a catalog is the product itself, in this case a vehicle.", "tokens": [50892, 400, 370, 4412, 264, 3056, 295, 257, 19746, 307, 264, 1674, 2564, 11, 294, 341, 1389, 257, 5864, 13, 51217], "temperature": 0.0, "avg_logprob": -0.10965065956115723, "compression_ratio": 1.5637254901960784, "no_speech_prob": 0.14408452808856964}, {"id": 108, "seek": 49856, "start": 515.62, "end": 522.04, "text": " But if I am doing an ontology that is focused on the transactional, the purchasing or the", "tokens": [51217, 583, 498, 286, 669, 884, 364, 6592, 1793, 300, 307, 5178, 322, 264, 46688, 1966, 11, 264, 20906, 420, 264, 51538], "temperature": 0.0, "avg_logprob": -0.10965065956115723, "compression_ratio": 1.5637254901960784, "no_speech_prob": 0.14408452808856964}, {"id": 109, "seek": 52204, "start": 522.04, "end": 529.16, "text": " selling or the manufacturing of something, then maybe the VIN number is the center of", "tokens": [50364, 6511, 420, 264, 11096, 295, 746, 11, 550, 1310, 264, 691, 1464, 1230, 307, 264, 3056, 295, 50720], "temperature": 0.0, "avg_logprob": -0.129057163145484, "compression_ratio": 1.7864077669902914, "no_speech_prob": 0.3847605586051941}, {"id": 110, "seek": 52204, "start": 529.16, "end": 535.0799999999999, "text": " my transaction, because that is the thing that is the individual specific thing being", "tokens": [50720, 452, 14425, 11, 570, 300, 307, 264, 551, 300, 307, 264, 2609, 2685, 551, 885, 51016], "temperature": 0.0, "avg_logprob": -0.129057163145484, "compression_ratio": 1.7864077669902914, "no_speech_prob": 0.3847605586051941}, {"id": 111, "seek": 52204, "start": 535.0799999999999, "end": 540.48, "text": " manufactured or sold connected to the customer, because that's the actual transaction that", "tokens": [51016, 25738, 420, 3718, 4582, 281, 264, 5474, 11, 570, 300, 311, 264, 3539, 14425, 300, 51286], "temperature": 0.0, "avg_logprob": -0.129057163145484, "compression_ratio": 1.7864077669902914, "no_speech_prob": 0.3847605586051941}, {"id": 112, "seek": 52204, "start": 540.48, "end": 542.36, "text": " I am trying to track.", "tokens": [51286, 286, 669, 1382, 281, 2837, 13, 51380], "temperature": 0.0, "avg_logprob": -0.129057163145484, "compression_ratio": 1.7864077669902914, "no_speech_prob": 0.3847605586051941}, {"id": 113, "seek": 52204, "start": 542.36, "end": 549.28, "text": " Or if I'm looking at a supply chain, maybe where something is manufactured and what", "tokens": [51380, 1610, 498, 286, 478, 1237, 412, 257, 5847, 5021, 11, 1310, 689, 746, 307, 25738, 293, 437, 51726], "temperature": 0.0, "avg_logprob": -0.129057163145484, "compression_ratio": 1.7864077669902914, "no_speech_prob": 0.3847605586051941}, {"id": 114, "seek": 54928, "start": 549.28, "end": 554.0799999999999, "text": " they are manufacturing is the center of my model.", "tokens": [50364, 436, 366, 11096, 307, 264, 3056, 295, 452, 2316, 13, 50604], "temperature": 0.0, "avg_logprob": -0.09801373114952674, "compression_ratio": 1.6351931330472103, "no_speech_prob": 0.05498708039522171}, {"id": 115, "seek": 54928, "start": 554.0799999999999, "end": 559.9, "text": " And identifying this early is really crucial to understand how your model is going to shape", "tokens": [50604, 400, 16696, 341, 2440, 307, 534, 11462, 281, 1223, 577, 428, 2316, 307, 516, 281, 3909, 50895], "temperature": 0.0, "avg_logprob": -0.09801373114952674, "compression_ratio": 1.6351931330472103, "no_speech_prob": 0.05498708039522171}, {"id": 116, "seek": 54928, "start": 559.9, "end": 563.64, "text": " up to answer the questions that you are interested in.", "tokens": [50895, 493, 281, 1867, 264, 1651, 300, 291, 366, 3102, 294, 13, 51082], "temperature": 0.0, "avg_logprob": -0.09801373114952674, "compression_ratio": 1.6351931330472103, "no_speech_prob": 0.05498708039522171}, {"id": 117, "seek": 54928, "start": 563.64, "end": 568.4, "text": " So once you've identified that, you want to look at the universal containers.", "tokens": [51082, 407, 1564, 291, 600, 9234, 300, 11, 291, 528, 281, 574, 412, 264, 11455, 17089, 13, 51320], "temperature": 0.0, "avg_logprob": -0.09801373114952674, "compression_ratio": 1.6351931330472103, "no_speech_prob": 0.05498708039522171}, {"id": 118, "seek": 54928, "start": 568.4, "end": 570.1999999999999, "text": " That's what ontology is.", "tokens": [51320, 663, 311, 437, 6592, 1793, 307, 13, 51410], "temperature": 0.0, "avg_logprob": -0.09801373114952674, "compression_ratio": 1.6351931330472103, "no_speech_prob": 0.05498708039522171}, {"id": 119, "seek": 54928, "start": 570.1999999999999, "end": 575.64, "text": " It's a framework to house things and how those things are related to one another.", "tokens": [51410, 467, 311, 257, 8388, 281, 1782, 721, 293, 577, 729, 721, 366, 4077, 281, 472, 1071, 13, 51682], "temperature": 0.0, "avg_logprob": -0.09801373114952674, "compression_ratio": 1.6351931330472103, "no_speech_prob": 0.05498708039522171}, {"id": 120, "seek": 57564, "start": 575.64, "end": 585.3199999999999, "text": " Now a taxonomy is identifying a universal topic or thing that could be an engine.", "tokens": [50364, 823, 257, 3366, 23423, 307, 16696, 257, 11455, 4829, 420, 551, 300, 727, 312, 364, 2848, 13, 50848], "temperature": 0.0, "avg_logprob": -0.11715891144492409, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.0041983891278505325}, {"id": 121, "seek": 57564, "start": 585.3199999999999, "end": 588.36, "text": " There is a universal understanding of engine.", "tokens": [50848, 821, 307, 257, 11455, 3701, 295, 2848, 13, 51000], "temperature": 0.0, "avg_logprob": -0.11715891144492409, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.0041983891278505325}, {"id": 122, "seek": 57564, "start": 588.36, "end": 591.92, "text": " But once you get into the lower levels of the taxonomy and thesaurus, where it's talking", "tokens": [51000, 583, 1564, 291, 483, 666, 264, 3126, 4358, 295, 264, 3366, 23423, 293, 264, 82, 40913, 11, 689, 309, 311, 1417, 51178], "temperature": 0.0, "avg_logprob": -0.11715891144492409, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.0041983891278505325}, {"id": 123, "seek": 57564, "start": 591.92, "end": 598.04, "text": " about very specific engines, that might not be part of the ontology.", "tokens": [51178, 466, 588, 2685, 12982, 11, 300, 1062, 406, 312, 644, 295, 264, 6592, 1793, 13, 51484], "temperature": 0.0, "avg_logprob": -0.11715891144492409, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.0041983891278505325}, {"id": 124, "seek": 57564, "start": 598.04, "end": 602.48, "text": " That actually might be an indicator that's part of the knowledge graph portion.", "tokens": [51484, 663, 767, 1062, 312, 364, 16961, 300, 311, 644, 295, 264, 3601, 4295, 8044, 13, 51706], "temperature": 0.0, "avg_logprob": -0.11715891144492409, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.0041983891278505325}, {"id": 125, "seek": 60248, "start": 602.48, "end": 606.96, "text": " It's talking about a very specific instance of an engine.", "tokens": [50364, 467, 311, 1417, 466, 257, 588, 2685, 5197, 295, 364, 2848, 13, 50588], "temperature": 0.0, "avg_logprob": -0.08483432320987477, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.027578629553318024}, {"id": 126, "seek": 60248, "start": 606.96, "end": 615.16, "text": " So the way that I like to think about this process is the first to third levels of your", "tokens": [50588, 407, 264, 636, 300, 286, 411, 281, 519, 466, 341, 1399, 307, 264, 700, 281, 2636, 4358, 295, 428, 50998], "temperature": 0.0, "avg_logprob": -0.08483432320987477, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.027578629553318024}, {"id": 127, "seek": 60248, "start": 615.16, "end": 624.5600000000001, "text": " taxonomy are usually more of the categorical universal containers of things in your asset", "tokens": [50998, 3366, 23423, 366, 2673, 544, 295, 264, 19250, 804, 11455, 17089, 295, 721, 294, 428, 11999, 51468], "temperature": 0.0, "avg_logprob": -0.08483432320987477, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.027578629553318024}, {"id": 128, "seek": 60248, "start": 624.5600000000001, "end": 626.32, "text": " or your catalog.", "tokens": [51468, 420, 428, 19746, 13, 51556], "temperature": 0.0, "avg_logprob": -0.08483432320987477, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.027578629553318024}, {"id": 129, "seek": 60248, "start": 626.32, "end": 631.04, "text": " And so that's a good indicator that maybe start with those first while you're doing", "tokens": [51556, 400, 370, 300, 311, 257, 665, 16961, 300, 1310, 722, 365, 729, 700, 1339, 291, 434, 884, 51792], "temperature": 0.0, "avg_logprob": -0.08483432320987477, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.027578629553318024}, {"id": 130, "seek": 60248, "start": 631.04, "end": 632.04, "text": " your modeling.", "tokens": [51792, 428, 15983, 13, 51842], "temperature": 0.0, "avg_logprob": -0.08483432320987477, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.027578629553318024}, {"id": 131, "seek": 63204, "start": 632.12, "end": 637.48, "text": " As you go, you're going to refine your understanding and you're going to refine what you had from", "tokens": [50368, 1018, 291, 352, 11, 291, 434, 516, 281, 33906, 428, 3701, 293, 291, 434, 516, 281, 33906, 437, 291, 632, 490, 50636], "temperature": 0.0, "avg_logprob": -0.15759204154790835, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.02367209643125534}, {"id": 132, "seek": 63204, "start": 637.48, "end": 643.68, "text": " the taxonomy at thesaurus stages because honestly, you might not need all of those nodes from", "tokens": [50636, 264, 3366, 23423, 412, 264, 82, 40913, 10232, 570, 6095, 11, 291, 1062, 406, 643, 439, 295, 729, 13891, 490, 50946], "temperature": 0.0, "avg_logprob": -0.15759204154790835, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.02367209643125534}, {"id": 133, "seek": 63204, "start": 643.68, "end": 645.3199999999999, "text": " the previous stages.", "tokens": [50946, 264, 3894, 10232, 13, 51028], "temperature": 0.0, "avg_logprob": -0.15759204154790835, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.02367209643125534}, {"id": 134, "seek": 63204, "start": 645.3199999999999, "end": 648.48, "text": " That's part of this modeling process.", "tokens": [51028, 663, 311, 644, 295, 341, 15983, 1399, 13, 51186], "temperature": 0.0, "avg_logprob": -0.15759204154790835, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.02367209643125534}, {"id": 135, "seek": 63204, "start": 648.48, "end": 654.64, "text": " So when you are looking at those universal categories, there's a really great thing in", "tokens": [51186, 407, 562, 291, 366, 1237, 412, 729, 11455, 10479, 11, 456, 311, 257, 534, 869, 551, 294, 51494], "temperature": 0.0, "avg_logprob": -0.15759204154790835, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.02367209643125534}, {"id": 136, "seek": 63204, "start": 654.64, "end": 655.64, "text": " there.", "tokens": [51494, 456, 13, 51544], "temperature": 0.0, "avg_logprob": -0.15759204154790835, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.02367209643125534}, {"id": 137, "seek": 65564, "start": 655.64, "end": 663.92, "text": " Your instance data, maybe your sub-sub-subclasses in your taxonomy, are going to be mapped.", "tokens": [50364, 2260, 5197, 1412, 11, 1310, 428, 1422, 12, 30131, 12, 30131, 11665, 279, 294, 428, 3366, 23423, 11, 366, 516, 281, 312, 33318, 13, 50778], "temperature": 0.0, "avg_logprob": -0.16207291035169966, "compression_ratio": 1.5853658536585367, "no_speech_prob": 0.060071852058172226}, {"id": 138, "seek": 65564, "start": 663.92, "end": 667.96, "text": " They roll up to those broader level categories.", "tokens": [50778, 814, 3373, 493, 281, 729, 13227, 1496, 10479, 13, 50980], "temperature": 0.0, "avg_logprob": -0.16207291035169966, "compression_ratio": 1.5853658536585367, "no_speech_prob": 0.060071852058172226}, {"id": 139, "seek": 65564, "start": 667.96, "end": 675.1999999999999, "text": " So in a way, you're pre-mapping a ton of your catalog to your ontology, which is a beautiful", "tokens": [50980, 407, 294, 257, 636, 11, 291, 434, 659, 12, 1696, 3759, 257, 2952, 295, 428, 19746, 281, 428, 6592, 1793, 11, 597, 307, 257, 2238, 51342], "temperature": 0.0, "avg_logprob": -0.16207291035169966, "compression_ratio": 1.5853658536585367, "no_speech_prob": 0.060071852058172226}, {"id": 140, "seek": 65564, "start": 675.1999999999999, "end": 682.28, "text": " thing and that's why doing this as an evolution is a really powerful thing if you can do it.", "tokens": [51342, 551, 293, 300, 311, 983, 884, 341, 382, 364, 9303, 307, 257, 534, 4005, 551, 498, 291, 393, 360, 309, 13, 51696], "temperature": 0.0, "avg_logprob": -0.16207291035169966, "compression_ratio": 1.5853658536585367, "no_speech_prob": 0.060071852058172226}, {"id": 141, "seek": 68228, "start": 682.28, "end": 687.28, "text": " The next thing you need to think about is the lowest level of universal data that you", "tokens": [50364, 440, 958, 551, 291, 643, 281, 519, 466, 307, 264, 12437, 1496, 295, 11455, 1412, 300, 291, 50614], "temperature": 0.0, "avg_logprob": -0.09774223674427379, "compression_ratio": 1.7269076305220883, "no_speech_prob": 0.026753032580018044}, {"id": 142, "seek": 68228, "start": 687.28, "end": 689.12, "text": " need for your use case.", "tokens": [50614, 643, 337, 428, 764, 1389, 13, 50706], "temperature": 0.0, "avg_logprob": -0.09774223674427379, "compression_ratio": 1.7269076305220883, "no_speech_prob": 0.026753032580018044}, {"id": 143, "seek": 68228, "start": 689.12, "end": 696.48, "text": " So that could be in our use case, we're trying to identify specific electric motors.", "tokens": [50706, 407, 300, 727, 312, 294, 527, 764, 1389, 11, 321, 434, 1382, 281, 5876, 2685, 5210, 25035, 13, 51074], "temperature": 0.0, "avg_logprob": -0.09774223674427379, "compression_ratio": 1.7269076305220883, "no_speech_prob": 0.026753032580018044}, {"id": 144, "seek": 68228, "start": 696.48, "end": 700.64, "text": " So maybe I only need to go as low as an electric motor.", "tokens": [51074, 407, 1310, 286, 787, 643, 281, 352, 382, 2295, 382, 364, 5210, 5932, 13, 51282], "temperature": 0.0, "avg_logprob": -0.09774223674427379, "compression_ratio": 1.7269076305220883, "no_speech_prob": 0.026753032580018044}, {"id": 145, "seek": 68228, "start": 700.64, "end": 705.9599999999999, "text": " And by the way, you don't want to create your entire ontology based on only one very unique", "tokens": [51282, 400, 538, 264, 636, 11, 291, 500, 380, 528, 281, 1884, 428, 2302, 6592, 1793, 2361, 322, 787, 472, 588, 3845, 51548], "temperature": 0.0, "avg_logprob": -0.09774223674427379, "compression_ratio": 1.7269076305220883, "no_speech_prob": 0.026753032580018044}, {"id": 146, "seek": 68228, "start": 705.9599999999999, "end": 712.24, "text": " specific problem statement, but it is a good place to start, but just don't stop there.", "tokens": [51548, 2685, 1154, 5629, 11, 457, 309, 307, 257, 665, 1081, 281, 722, 11, 457, 445, 500, 380, 1590, 456, 13, 51862], "temperature": 0.0, "avg_logprob": -0.09774223674427379, "compression_ratio": 1.7269076305220883, "no_speech_prob": 0.026753032580018044}, {"id": 147, "seek": 71224, "start": 712.24, "end": 720.12, "text": " And with an electric vehicle, that is connected to the electric motor.", "tokens": [50364, 400, 365, 364, 5210, 5864, 11, 300, 307, 4582, 281, 264, 5210, 5932, 13, 50758], "temperature": 0.0, "avg_logprob": -0.09120259284973145, "compression_ratio": 1.7112068965517242, "no_speech_prob": 0.005383982788771391}, {"id": 148, "seek": 71224, "start": 720.12, "end": 725.2, "text": " Maybe that's all the farther I need to go, but if I do need to go even lower and look", "tokens": [50758, 2704, 300, 311, 439, 264, 20344, 286, 643, 281, 352, 11, 457, 498, 286, 360, 643, 281, 352, 754, 3126, 293, 574, 51012], "temperature": 0.0, "avg_logprob": -0.09120259284973145, "compression_ratio": 1.7112068965517242, "no_speech_prob": 0.005383982788771391}, {"id": 149, "seek": 71224, "start": 725.2, "end": 730.88, "text": " at specific types of electric motors, let's say there are different brand names, then", "tokens": [51012, 412, 2685, 3467, 295, 5210, 25035, 11, 718, 311, 584, 456, 366, 819, 3360, 5288, 11, 550, 51296], "temperature": 0.0, "avg_logprob": -0.09120259284973145, "compression_ratio": 1.7112068965517242, "no_speech_prob": 0.005383982788771391}, {"id": 150, "seek": 71224, "start": 730.88, "end": 735.72, "text": " maybe that's the lowest level of data I need to have for the ontology.", "tokens": [51296, 1310, 300, 311, 264, 12437, 1496, 295, 1412, 286, 643, 281, 362, 337, 264, 6592, 1793, 13, 51538], "temperature": 0.0, "avg_logprob": -0.09120259284973145, "compression_ratio": 1.7112068965517242, "no_speech_prob": 0.005383982788771391}, {"id": 151, "seek": 71224, "start": 735.72, "end": 740.24, "text": " So I have a whole nother video going into a deep dive on how to determine something", "tokens": [51538, 407, 286, 362, 257, 1379, 406, 511, 960, 516, 666, 257, 2452, 9192, 322, 577, 281, 6997, 746, 51764], "temperature": 0.0, "avg_logprob": -0.09120259284973145, "compression_ratio": 1.7112068965517242, "no_speech_prob": 0.005383982788771391}, {"id": 152, "seek": 74024, "start": 740.24, "end": 743.4, "text": " as a class or an instance, and I will leave that down below.", "tokens": [50364, 382, 257, 1508, 420, 364, 5197, 11, 293, 286, 486, 1856, 300, 760, 2507, 13, 50522], "temperature": 0.0, "avg_logprob": -0.11581623219998083, "compression_ratio": 1.6440677966101696, "no_speech_prob": 0.3003753125667572}, {"id": 153, "seek": 74024, "start": 743.4, "end": 747.6, "text": " But a good rule of thumb is to think about it from this perspective.", "tokens": [50522, 583, 257, 665, 4978, 295, 9298, 307, 281, 519, 466, 309, 490, 341, 4585, 13, 50732], "temperature": 0.0, "avg_logprob": -0.11581623219998083, "compression_ratio": 1.6440677966101696, "no_speech_prob": 0.3003753125667572}, {"id": 154, "seek": 74024, "start": 747.6, "end": 750.4, "text": " There is a universal understanding of cat.", "tokens": [50732, 821, 307, 257, 11455, 3701, 295, 3857, 13, 50872], "temperature": 0.0, "avg_logprob": -0.11581623219998083, "compression_ratio": 1.6440677966101696, "no_speech_prob": 0.3003753125667572}, {"id": 155, "seek": 74024, "start": 750.4, "end": 758.36, "text": " It is furry, it has whiskers, it meows, it sits in your lap and it lives in your home.", "tokens": [50872, 467, 307, 47073, 11, 309, 575, 24485, 433, 11, 309, 385, 1509, 11, 309, 12696, 294, 428, 13214, 293, 309, 2909, 294, 428, 1280, 13, 51270], "temperature": 0.0, "avg_logprob": -0.11581623219998083, "compression_ratio": 1.6440677966101696, "no_speech_prob": 0.3003753125667572}, {"id": 156, "seek": 74024, "start": 758.36, "end": 766.44, "text": " But my cat Garfield is a different instance of cat than your cat named Otis.", "tokens": [51270, 583, 452, 3857, 7995, 7610, 307, 257, 819, 5197, 295, 3857, 813, 428, 3857, 4926, 12936, 271, 13, 51674], "temperature": 0.0, "avg_logprob": -0.11581623219998083, "compression_ratio": 1.6440677966101696, "no_speech_prob": 0.3003753125667572}, {"id": 157, "seek": 74024, "start": 766.44, "end": 769.8, "text": " They're both cats, but those are instances of cats.", "tokens": [51674, 814, 434, 1293, 11111, 11, 457, 729, 366, 14519, 295, 11111, 13, 51842], "temperature": 0.0, "avg_logprob": -0.11581623219998083, "compression_ratio": 1.6440677966101696, "no_speech_prob": 0.3003753125667572}, {"id": 158, "seek": 76980, "start": 769.8, "end": 771.4799999999999, "text": " So think of it from that perspective.", "tokens": [50364, 407, 519, 295, 309, 490, 300, 4585, 13, 50448], "temperature": 0.0, "avg_logprob": -0.12259193946575296, "compression_ratio": 1.6651785714285714, "no_speech_prob": 0.005218464881181717}, {"id": 159, "seek": 76980, "start": 771.4799999999999, "end": 779.52, "text": " Anything that has to be very unique and is to the cellular level unique, that's probably", "tokens": [50448, 11998, 300, 575, 281, 312, 588, 3845, 293, 307, 281, 264, 29267, 1496, 3845, 11, 300, 311, 1391, 50850], "temperature": 0.0, "avg_logprob": -0.12259193946575296, "compression_ratio": 1.6651785714285714, "no_speech_prob": 0.005218464881181717}, {"id": 160, "seek": 76980, "start": 779.52, "end": 784.12, "text": " an instance and you don't necessarily want that in your ontology.", "tokens": [50850, 364, 5197, 293, 291, 500, 380, 4725, 528, 300, 294, 428, 6592, 1793, 13, 51080], "temperature": 0.0, "avg_logprob": -0.12259193946575296, "compression_ratio": 1.6651785714285714, "no_speech_prob": 0.005218464881181717}, {"id": 161, "seek": 76980, "start": 784.12, "end": 790.64, "text": " So once you've determined that, you want to then start to look at those broader and narrower", "tokens": [51080, 407, 1564, 291, 600, 9540, 300, 11, 291, 528, 281, 550, 722, 281, 574, 412, 729, 13227, 293, 46751, 51406], "temperature": 0.0, "avg_logprob": -0.12259193946575296, "compression_ratio": 1.6651785714285714, "no_speech_prob": 0.005218464881181717}, {"id": 162, "seek": 76980, "start": 790.64, "end": 796.88, "text": " relationships that you had from previous steps and you want to make them more explicit.", "tokens": [51406, 6159, 300, 291, 632, 490, 3894, 4439, 293, 291, 528, 281, 652, 552, 544, 13691, 13, 51718], "temperature": 0.0, "avg_logprob": -0.12259193946575296, "compression_ratio": 1.6651785714285714, "no_speech_prob": 0.005218464881181717}, {"id": 163, "seek": 79688, "start": 796.88, "end": 804.12, "text": " Now you saw that in those previous steps, we did have things like whole part, has part,", "tokens": [50364, 823, 291, 1866, 300, 294, 729, 3894, 4439, 11, 321, 630, 362, 721, 411, 1379, 644, 11, 575, 644, 11, 50726], "temperature": 0.0, "avg_logprob": -0.12569136522254165, "compression_ratio": 1.6638297872340426, "no_speech_prob": 0.006288910750299692}, {"id": 164, "seek": 79688, "start": 804.12, "end": 808.96, "text": " that sort of thing, that you can just transfer back over into the ontology.", "tokens": [50726, 300, 1333, 295, 551, 11, 300, 291, 393, 445, 5003, 646, 670, 666, 264, 6592, 1793, 13, 50968], "temperature": 0.0, "avg_logprob": -0.12569136522254165, "compression_ratio": 1.6638297872340426, "no_speech_prob": 0.006288910750299692}, {"id": 165, "seek": 79688, "start": 808.96, "end": 810.76, "text": " Those work really well.", "tokens": [50968, 3950, 589, 534, 731, 13, 51058], "temperature": 0.0, "avg_logprob": -0.12569136522254165, "compression_ratio": 1.6638297872340426, "no_speech_prob": 0.006288910750299692}, {"id": 166, "seek": 79688, "start": 810.76, "end": 814.76, "text": " But when you're talking about things that are just broader and narrower, you have no", "tokens": [51058, 583, 562, 291, 434, 1417, 466, 721, 300, 366, 445, 13227, 293, 46751, 11, 291, 362, 572, 51258], "temperature": 0.0, "avg_logprob": -0.12569136522254165, "compression_ratio": 1.6638297872340426, "no_speech_prob": 0.006288910750299692}, {"id": 167, "seek": 79688, "start": 814.76, "end": 818.72, "text": " idea what the relationship is between those two things.", "tokens": [51258, 1558, 437, 264, 2480, 307, 1296, 729, 732, 721, 13, 51456], "temperature": 0.0, "avg_logprob": -0.12569136522254165, "compression_ratio": 1.6638297872340426, "no_speech_prob": 0.006288910750299692}, {"id": 168, "seek": 79688, "start": 818.72, "end": 824.72, "text": " So in that case, here you can see that with parts and engines.", "tokens": [51456, 407, 294, 300, 1389, 11, 510, 291, 393, 536, 300, 365, 3166, 293, 12982, 13, 51756], "temperature": 0.0, "avg_logprob": -0.12569136522254165, "compression_ratio": 1.6638297872340426, "no_speech_prob": 0.006288910750299692}, {"id": 169, "seek": 82472, "start": 824.72, "end": 829.96, "text": " In our taxonomy and our thesaurus, they were just nested, right?", "tokens": [50364, 682, 527, 3366, 23423, 293, 527, 264, 82, 40913, 11, 436, 645, 445, 15646, 292, 11, 558, 30, 50626], "temperature": 0.0, "avg_logprob": -0.15936904152234396, "compression_ratio": 1.5871559633027523, "no_speech_prob": 0.1258367896080017}, {"id": 170, "seek": 82472, "start": 829.96, "end": 832.7, "text": " The engine was nested underneath parts.", "tokens": [50626, 440, 2848, 390, 15646, 292, 7223, 3166, 13, 50763], "temperature": 0.0, "avg_logprob": -0.15936904152234396, "compression_ratio": 1.5871559633027523, "no_speech_prob": 0.1258367896080017}, {"id": 171, "seek": 82472, "start": 832.7, "end": 836.08, "text": " We didn't really know why they related to each other.", "tokens": [50763, 492, 994, 380, 534, 458, 983, 436, 4077, 281, 1184, 661, 13, 50932], "temperature": 0.0, "avg_logprob": -0.15936904152234396, "compression_ratio": 1.5871559633027523, "no_speech_prob": 0.1258367896080017}, {"id": 172, "seek": 82472, "start": 836.08, "end": 837.76, "text": " Now we're being very explicit.", "tokens": [50932, 823, 321, 434, 885, 588, 13691, 13, 51016], "temperature": 0.0, "avg_logprob": -0.15936904152234396, "compression_ratio": 1.5871559633027523, "no_speech_prob": 0.1258367896080017}, {"id": 173, "seek": 82472, "start": 837.76, "end": 840.9200000000001, "text": " We're saying it is has part, part of.", "tokens": [51016, 492, 434, 1566, 309, 307, 575, 644, 11, 644, 295, 13, 51174], "temperature": 0.0, "avg_logprob": -0.15936904152234396, "compression_ratio": 1.5871559633027523, "no_speech_prob": 0.1258367896080017}, {"id": 174, "seek": 82472, "start": 840.9200000000001, "end": 848.4, "text": " And that also allows us to use that specific relation with any other parts that are in", "tokens": [51174, 400, 300, 611, 4045, 505, 281, 764, 300, 2685, 9721, 365, 604, 661, 3166, 300, 366, 294, 51548], "temperature": 0.0, "avg_logprob": -0.15936904152234396, "compression_ratio": 1.5871559633027523, "no_speech_prob": 0.1258367896080017}, {"id": 175, "seek": 82472, "start": 848.4, "end": 852.2, "text": " our asset and our catalog data.", "tokens": [51548, 527, 11999, 293, 527, 19746, 1412, 13, 51738], "temperature": 0.0, "avg_logprob": -0.15936904152234396, "compression_ratio": 1.5871559633027523, "no_speech_prob": 0.1258367896080017}, {"id": 176, "seek": 85220, "start": 852.2, "end": 857.88, "text": " This is also your opportunity to craft unique relations.", "tokens": [50364, 639, 307, 611, 428, 2650, 281, 8448, 3845, 2299, 13, 50648], "temperature": 0.0, "avg_logprob": -0.15016249418258668, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.03731934726238251}, {"id": 177, "seek": 85220, "start": 857.88, "end": 867.1600000000001, "text": " And those are like manufactured in these are oftentimes business specific, or these also", "tokens": [50648, 400, 729, 366, 411, 25738, 294, 613, 366, 18349, 1606, 2685, 11, 420, 613, 611, 51112], "temperature": 0.0, "avg_logprob": -0.15016249418258668, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.03731934726238251}, {"id": 178, "seek": 85220, "start": 867.1600000000001, "end": 871.8000000000001, "text": " can be mined from your thesaurus definitions or the assets themselves.", "tokens": [51112, 393, 312, 923, 292, 490, 428, 264, 82, 40913, 21988, 420, 264, 9769, 2969, 13, 51344], "temperature": 0.0, "avg_logprob": -0.15016249418258668, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.03731934726238251}, {"id": 179, "seek": 85220, "start": 871.8000000000001, "end": 878.6800000000001, "text": " So for instance, if you're looking at a description of a product, what other things in your catalog", "tokens": [51344, 407, 337, 5197, 11, 498, 291, 434, 1237, 412, 257, 3855, 295, 257, 1674, 11, 437, 661, 721, 294, 428, 19746, 51688], "temperature": 0.0, "avg_logprob": -0.15016249418258668, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.03731934726238251}, {"id": 180, "seek": 85220, "start": 878.6800000000001, "end": 880.84, "text": " are being mentioned in that description?", "tokens": [51688, 366, 885, 2835, 294, 300, 3855, 30, 51796], "temperature": 0.0, "avg_logprob": -0.15016249418258668, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.03731934726238251}, {"id": 181, "seek": 88084, "start": 880.84, "end": 884.8000000000001, "text": " It's probably a good indicator that they're related in some way.", "tokens": [50364, 467, 311, 1391, 257, 665, 16961, 300, 436, 434, 4077, 294, 512, 636, 13, 50562], "temperature": 0.0, "avg_logprob": -0.12445811139858835, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.11272130161523819}, {"id": 182, "seek": 88084, "start": 884.8000000000001, "end": 888.1600000000001, "text": " Now the last thing you're going to be looking at are is twofold.", "tokens": [50562, 823, 264, 1036, 551, 291, 434, 516, 281, 312, 1237, 412, 366, 307, 732, 18353, 13, 50730], "temperature": 0.0, "avg_logprob": -0.12445811139858835, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.11272130161523819}, {"id": 183, "seek": 88084, "start": 888.1600000000001, "end": 893.84, "text": " So first, you are going to add in additional nodes to flesh out that network.", "tokens": [50730, 407, 700, 11, 291, 366, 516, 281, 909, 294, 4497, 13891, 281, 12497, 484, 300, 3209, 13, 51014], "temperature": 0.0, "avg_logprob": -0.12445811139858835, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.11272130161523819}, {"id": 184, "seek": 88084, "start": 893.84, "end": 897.84, "text": " And these are things that are not always found in one table.", "tokens": [51014, 400, 613, 366, 721, 300, 366, 406, 1009, 1352, 294, 472, 3199, 13, 51214], "temperature": 0.0, "avg_logprob": -0.12445811139858835, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.11272130161523819}, {"id": 185, "seek": 88084, "start": 897.84, "end": 900.24, "text": " So this might be something that you'd have to join together.", "tokens": [51214, 407, 341, 1062, 312, 746, 300, 291, 1116, 362, 281, 3917, 1214, 13, 51334], "temperature": 0.0, "avg_logprob": -0.12445811139858835, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.11272130161523819}, {"id": 186, "seek": 88084, "start": 900.24, "end": 904.88, "text": " So this could be customer data or transactional data in general.", "tokens": [51334, 407, 341, 727, 312, 5474, 1412, 420, 46688, 1966, 1412, 294, 2674, 13, 51566], "temperature": 0.0, "avg_logprob": -0.12445811139858835, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.11272130161523819}, {"id": 187, "seek": 88084, "start": 904.88, "end": 909.9200000000001, "text": " Adding those in fleshes out your network so you don't have to do as many joins, right?", "tokens": [51566, 31204, 729, 294, 12497, 279, 484, 428, 3209, 370, 291, 500, 380, 362, 281, 360, 382, 867, 24397, 11, 558, 30, 51818], "temperature": 0.0, "avg_logprob": -0.12445811139858835, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.11272130161523819}, {"id": 188, "seek": 90992, "start": 909.92, "end": 912.36, "text": " This is the beauty of an ontology.", "tokens": [50364, 639, 307, 264, 6643, 295, 364, 6592, 1793, 13, 50486], "temperature": 0.0, "avg_logprob": -0.16681876739898285, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.009704708121716976}, {"id": 189, "seek": 90992, "start": 912.36, "end": 918.76, "text": " It makes those relations inherent rather than having you have to depend on others and your", "tokens": [50486, 467, 1669, 729, 2299, 26387, 2831, 813, 1419, 291, 362, 281, 5672, 322, 2357, 293, 428, 50806], "temperature": 0.0, "avg_logprob": -0.16681876739898285, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.009704708121716976}, {"id": 190, "seek": 90992, "start": 918.76, "end": 922.8, "text": " specialized knowledge to make those kinds of relations.", "tokens": [50806, 19813, 3601, 281, 652, 729, 3685, 295, 2299, 13, 51008], "temperature": 0.0, "avg_logprob": -0.16681876739898285, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.009704708121716976}, {"id": 191, "seek": 90992, "start": 922.8, "end": 927.8399999999999, "text": " Also which is pretty critical for making sure your machine learning and mapping and matching", "tokens": [51008, 2743, 597, 307, 1238, 4924, 337, 1455, 988, 428, 3479, 2539, 293, 18350, 293, 14324, 51260], "temperature": 0.0, "avg_logprob": -0.16681876739898285, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.009704708121716976}, {"id": 192, "seek": 90992, "start": 927.8399999999999, "end": 934.8399999999999, "text": " projects go smoother is making sure those used for incentives are added in as attributes.", "tokens": [51260, 4455, 352, 28640, 307, 1455, 988, 729, 1143, 337, 23374, 366, 3869, 294, 382, 17212, 13, 51610], "temperature": 0.0, "avg_logprob": -0.16681876739898285, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.009704708121716976}, {"id": 193, "seek": 93484, "start": 934.84, "end": 940.88, "text": " I also just want to note here that some of the nodes that I have in my model, for instance,", "tokens": [50364, 286, 611, 445, 528, 281, 3637, 510, 300, 512, 295, 264, 13891, 300, 286, 362, 294, 452, 2316, 11, 337, 5197, 11, 50666], "temperature": 0.0, "avg_logprob": -0.09098416044000994, "compression_ratio": 1.7578125, "no_speech_prob": 0.07806392014026642}, {"id": 194, "seek": 93484, "start": 940.88, "end": 947.32, "text": " the class of vehicle, that could be an attribute on the vehicle node.", "tokens": [50666, 264, 1508, 295, 5864, 11, 300, 727, 312, 364, 19667, 322, 264, 5864, 9984, 13, 50988], "temperature": 0.0, "avg_logprob": -0.09098416044000994, "compression_ratio": 1.7578125, "no_speech_prob": 0.07806392014026642}, {"id": 195, "seek": 93484, "start": 947.32, "end": 950.48, "text": " I decided to break it out, but that's part of the modeling process.", "tokens": [50988, 286, 3047, 281, 1821, 309, 484, 11, 457, 300, 311, 644, 295, 264, 15983, 1399, 13, 51146], "temperature": 0.0, "avg_logprob": -0.09098416044000994, "compression_ratio": 1.7578125, "no_speech_prob": 0.07806392014026642}, {"id": 196, "seek": 93484, "start": 950.48, "end": 956.48, "text": " You have to decide which pieces of information can be descriptors of a node or things that", "tokens": [51146, 509, 362, 281, 4536, 597, 3755, 295, 1589, 393, 312, 31280, 830, 295, 257, 9984, 420, 721, 300, 51446], "temperature": 0.0, "avg_logprob": -0.09098416044000994, "compression_ratio": 1.7578125, "no_speech_prob": 0.07806392014026642}, {"id": 197, "seek": 93484, "start": 956.48, "end": 959.2, "text": " need to be standalone nodes on their own.", "tokens": [51446, 643, 281, 312, 37454, 13891, 322, 641, 1065, 13, 51582], "temperature": 0.0, "avg_logprob": -0.09098416044000994, "compression_ratio": 1.7578125, "no_speech_prob": 0.07806392014026642}, {"id": 198, "seek": 93484, "start": 959.2, "end": 964.08, "text": " So one thing I want to just point out is you don't necessarily have to have an ontology", "tokens": [51582, 407, 472, 551, 286, 528, 281, 445, 935, 484, 307, 291, 500, 380, 4725, 362, 281, 362, 364, 6592, 1793, 51826], "temperature": 0.0, "avg_logprob": -0.09098416044000994, "compression_ratio": 1.7578125, "no_speech_prob": 0.07806392014026642}, {"id": 199, "seek": 96408, "start": 964.08, "end": 965.2800000000001, "text": " to have a knowledge graph.", "tokens": [50364, 281, 362, 257, 3601, 4295, 13, 50424], "temperature": 0.0, "avg_logprob": -0.13819342393141526, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.16442357003688812}, {"id": 200, "seek": 96408, "start": 965.2800000000001, "end": 972.08, "text": " There are other ways to get to knowledge graph outside of an ontology, but think of the ontology", "tokens": [50424, 821, 366, 661, 2098, 281, 483, 281, 3601, 4295, 2380, 295, 364, 6592, 1793, 11, 457, 519, 295, 264, 6592, 1793, 50764], "temperature": 0.0, "avg_logprob": -0.13819342393141526, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.16442357003688812}, {"id": 201, "seek": 96408, "start": 972.08, "end": 976.24, "text": " stage as you are creating that, again, that framework.", "tokens": [50764, 3233, 382, 291, 366, 4084, 300, 11, 797, 11, 300, 8388, 13, 50972], "temperature": 0.0, "avg_logprob": -0.13819342393141526, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.16442357003688812}, {"id": 202, "seek": 96408, "start": 976.24, "end": 983.44, "text": " It doesn't necessarily have to be a true ontology like an RDF ontology, but it is a representation", "tokens": [50972, 467, 1177, 380, 4725, 362, 281, 312, 257, 2074, 6592, 1793, 411, 364, 49488, 37, 6592, 1793, 11, 457, 309, 307, 257, 10290, 51332], "temperature": 0.0, "avg_logprob": -0.13819342393141526, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.16442357003688812}, {"id": 203, "seek": 96408, "start": 983.44, "end": 988.72, "text": " of the global entities so that you can then get to the knowledge graph stage where you", "tokens": [51332, 295, 264, 4338, 16667, 370, 300, 291, 393, 550, 483, 281, 264, 3601, 4295, 3233, 689, 291, 51596], "temperature": 0.0, "avg_logprob": -0.13819342393141526, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.16442357003688812}, {"id": 204, "seek": 98872, "start": 988.72, "end": 995.1600000000001, "text": " are populating the instance or the very specifics of your graph.", "tokens": [50364, 366, 1665, 12162, 264, 5197, 420, 264, 588, 28454, 295, 428, 4295, 13, 50686], "temperature": 0.0, "avg_logprob": -0.1430643553374916, "compression_ratio": 1.7889908256880733, "no_speech_prob": 0.46081921458244324}, {"id": 205, "seek": 98872, "start": 995.1600000000001, "end": 998.8000000000001, "text": " Populating your graph can come in a few different forms.", "tokens": [50686, 10215, 12162, 428, 4295, 393, 808, 294, 257, 1326, 819, 6422, 13, 50868], "temperature": 0.0, "avg_logprob": -0.1430643553374916, "compression_ratio": 1.7889908256880733, "no_speech_prob": 0.46081921458244324}, {"id": 206, "seek": 98872, "start": 998.8000000000001, "end": 1005.48, "text": " In this situation, we are going to be taking all of the things that we identified as instance", "tokens": [50868, 682, 341, 2590, 11, 321, 366, 516, 281, 312, 1940, 439, 295, 264, 721, 300, 321, 9234, 382, 5197, 51202], "temperature": 0.0, "avg_logprob": -0.1430643553374916, "compression_ratio": 1.7889908256880733, "no_speech_prob": 0.46081921458244324}, {"id": 207, "seek": 98872, "start": 1005.48, "end": 1011.2, "text": " data from our taxonomy and thesaurus, remember it rolled up into the universal classes that", "tokens": [51202, 1412, 490, 527, 3366, 23423, 293, 264, 82, 40913, 11, 1604, 309, 14306, 493, 666, 264, 11455, 5359, 300, 51488], "temperature": 0.0, "avg_logprob": -0.1430643553374916, "compression_ratio": 1.7889908256880733, "no_speech_prob": 0.46081921458244324}, {"id": 208, "seek": 98872, "start": 1011.2, "end": 1018.64, "text": " we identified, we are going to be able to populate those as instance very quickly.", "tokens": [51488, 321, 9234, 11, 321, 366, 516, 281, 312, 1075, 281, 1665, 5256, 729, 382, 5197, 588, 2661, 13, 51860], "temperature": 0.0, "avg_logprob": -0.1430643553374916, "compression_ratio": 1.7889908256880733, "no_speech_prob": 0.46081921458244324}, {"id": 209, "seek": 101864, "start": 1018.64, "end": 1023.76, "text": " Sometimes you are going to realize that your model is not quite right and that's because", "tokens": [50364, 4803, 291, 366, 516, 281, 4325, 300, 428, 2316, 307, 406, 1596, 558, 293, 300, 311, 570, 50620], "temperature": 0.0, "avg_logprob": -0.11986985206604003, "compression_ratio": 1.7689243027888446, "no_speech_prob": 0.06952230632305145}, {"id": 210, "seek": 101864, "start": 1023.76, "end": 1031.12, "text": " the things that in a taxonomy and thesaurus generally rolled up to the same category don't", "tokens": [50620, 264, 721, 300, 294, 257, 3366, 23423, 293, 264, 82, 40913, 5101, 14306, 493, 281, 264, 912, 7719, 500, 380, 50988], "temperature": 0.0, "avg_logprob": -0.11986985206604003, "compression_ratio": 1.7689243027888446, "no_speech_prob": 0.06952230632305145}, {"id": 211, "seek": 101864, "start": 1031.12, "end": 1035.6, "text": " necessarily work the way you want them to work when you get to the knowledge graph space", "tokens": [50988, 4725, 589, 264, 636, 291, 528, 552, 281, 589, 562, 291, 483, 281, 264, 3601, 4295, 1901, 51212], "temperature": 0.0, "avg_logprob": -0.11986985206604003, "compression_ratio": 1.7689243027888446, "no_speech_prob": 0.06952230632305145}, {"id": 212, "seek": 101864, "start": 1035.6, "end": 1041.08, "text": " because now when you start to look at the individual entities, there are some exceptions", "tokens": [51212, 570, 586, 562, 291, 722, 281, 574, 412, 264, 2609, 16667, 11, 456, 366, 512, 22847, 51486], "temperature": 0.0, "avg_logprob": -0.11986985206604003, "compression_ratio": 1.7689243027888446, "no_speech_prob": 0.06952230632305145}, {"id": 213, "seek": 101864, "start": 1041.08, "end": 1045.4, "text": " to the rule and sometimes that means you are going to have to split classes and make a", "tokens": [51486, 281, 264, 4978, 293, 2171, 300, 1355, 291, 366, 516, 281, 362, 281, 7472, 5359, 293, 652, 257, 51702], "temperature": 0.0, "avg_logprob": -0.11986985206604003, "compression_ratio": 1.7689243027888446, "no_speech_prob": 0.06952230632305145}, {"id": 214, "seek": 104540, "start": 1045.4, "end": 1049.0800000000002, "text": " subclass, this is part of that refinement stage.", "tokens": [50364, 1422, 11665, 11, 341, 307, 644, 295, 300, 1895, 30229, 3233, 13, 50548], "temperature": 0.0, "avg_logprob": -0.1337562579553104, "compression_ratio": 1.6554621848739495, "no_speech_prob": 0.27483847737312317}, {"id": 215, "seek": 104540, "start": 1049.0800000000002, "end": 1053.4, "text": " So dovetailing into that, you do want to check a subset of the instance data to verify the", "tokens": [50548, 407, 360, 9771, 23315, 666, 300, 11, 291, 360, 528, 281, 1520, 257, 25993, 295, 264, 5197, 1412, 281, 16888, 264, 50764], "temperature": 0.0, "avg_logprob": -0.1337562579553104, "compression_ratio": 1.6554621848739495, "no_speech_prob": 0.27483847737312317}, {"id": 216, "seek": 104540, "start": 1053.4, "end": 1055.92, "text": " logic is sound.", "tokens": [50764, 9952, 307, 1626, 13, 50890], "temperature": 0.0, "avg_logprob": -0.1337562579553104, "compression_ratio": 1.6554621848739495, "no_speech_prob": 0.27483847737312317}, {"id": 217, "seek": 104540, "start": 1055.92, "end": 1059.76, "text": " This is something I like to use a visual for because then you can see if there is some", "tokens": [50890, 639, 307, 746, 286, 411, 281, 764, 257, 5056, 337, 570, 550, 291, 393, 536, 498, 456, 307, 512, 51082], "temperature": 0.0, "avg_logprob": -0.1337562579553104, "compression_ratio": 1.6554621848739495, "no_speech_prob": 0.27483847737312317}, {"id": 218, "seek": 104540, "start": 1059.76, "end": 1066.8400000000001, "text": " weird circular logic which by the way happens constantly when you take a taxonomy or a thesaurus", "tokens": [51082, 3657, 16476, 9952, 597, 538, 264, 636, 2314, 6460, 562, 291, 747, 257, 3366, 23423, 420, 257, 264, 82, 40913, 51436], "temperature": 0.0, "avg_logprob": -0.1337562579553104, "compression_ratio": 1.6554621848739495, "no_speech_prob": 0.27483847737312317}, {"id": 219, "seek": 104540, "start": 1066.8400000000001, "end": 1070.3600000000001, "text": " and you turn it into an ontology or a knowledge graph.", "tokens": [51436, 293, 291, 1261, 309, 666, 364, 6592, 1793, 420, 257, 3601, 4295, 13, 51612], "temperature": 0.0, "avg_logprob": -0.1337562579553104, "compression_ratio": 1.6554621848739495, "no_speech_prob": 0.27483847737312317}, {"id": 220, "seek": 107036, "start": 1070.36, "end": 1078.32, "text": " Another thing to watch out for sort of in that same vein is looking at the actual definition", "tokens": [50364, 3996, 551, 281, 1159, 484, 337, 1333, 295, 294, 300, 912, 30669, 307, 1237, 412, 264, 3539, 7123, 50762], "temperature": 0.0, "avg_logprob": -0.12735966791080522, "compression_ratio": 1.6376146788990826, "no_speech_prob": 0.5922876596450806}, {"id": 221, "seek": 107036, "start": 1078.32, "end": 1085.0, "text": " of these nodes versus how it is applied to the actual assets or behaviors in your systems", "tokens": [50762, 295, 613, 13891, 5717, 577, 309, 307, 6456, 281, 264, 3539, 9769, 420, 15501, 294, 428, 3652, 51096], "temperature": 0.0, "avg_logprob": -0.12735966791080522, "compression_ratio": 1.6376146788990826, "no_speech_prob": 0.5922876596450806}, {"id": 222, "seek": 107036, "start": 1085.0, "end": 1089.4399999999998, "text": " just making sure that that logic all checks out and that they align with your business", "tokens": [51096, 445, 1455, 988, 300, 300, 9952, 439, 13834, 484, 293, 300, 436, 7975, 365, 428, 1606, 51318], "temperature": 0.0, "avg_logprob": -0.12735966791080522, "compression_ratio": 1.6376146788990826, "no_speech_prob": 0.5922876596450806}, {"id": 223, "seek": 107036, "start": 1089.4399999999998, "end": 1097.36, "text": " needs because I've seen that taxonomies and thesaurus are not necessarily structured to", "tokens": [51318, 2203, 570, 286, 600, 1612, 300, 3366, 12481, 530, 293, 264, 82, 40913, 366, 406, 4725, 18519, 281, 51714], "temperature": 0.0, "avg_logprob": -0.12735966791080522, "compression_ratio": 1.6376146788990826, "no_speech_prob": 0.5922876596450806}, {"id": 224, "seek": 109736, "start": 1097.36, "end": 1102.7199999999998, "text": " be used in machine learning or knowledge graphs and therefore some of that logic doesn't always", "tokens": [50364, 312, 1143, 294, 3479, 2539, 420, 3601, 24877, 293, 4412, 512, 295, 300, 9952, 1177, 380, 1009, 50632], "temperature": 0.0, "avg_logprob": -0.12898168158023915, "compression_ratio": 1.662551440329218, "no_speech_prob": 0.4451887905597687}, {"id": 225, "seek": 109736, "start": 1102.7199999999998, "end": 1107.1999999999998, "text": " check out once you start to morph these and involve these into other forms.", "tokens": [50632, 1520, 484, 1564, 291, 722, 281, 25778, 613, 293, 9494, 613, 666, 661, 6422, 13, 50856], "temperature": 0.0, "avg_logprob": -0.12898168158023915, "compression_ratio": 1.662551440329218, "no_speech_prob": 0.4451887905597687}, {"id": 226, "seek": 109736, "start": 1107.1999999999998, "end": 1109.36, "text": " So just be aware of that.", "tokens": [50856, 407, 445, 312, 3650, 295, 300, 13, 50964], "temperature": 0.0, "avg_logprob": -0.12898168158023915, "compression_ratio": 1.662551440329218, "no_speech_prob": 0.4451887905597687}, {"id": 227, "seek": 109736, "start": 1109.36, "end": 1115.1999999999998, "text": " You also want to add in some inferred hidden relations.", "tokens": [50964, 509, 611, 528, 281, 909, 294, 512, 13596, 986, 7633, 2299, 13, 51256], "temperature": 0.0, "avg_logprob": -0.12898168158023915, "compression_ratio": 1.662551440329218, "no_speech_prob": 0.4451887905597687}, {"id": 228, "seek": 109736, "start": 1115.1999999999998, "end": 1118.56, "text": " You can identify some of these with things like shortest path.", "tokens": [51256, 509, 393, 5876, 512, 295, 613, 365, 721, 411, 31875, 3100, 13, 51424], "temperature": 0.0, "avg_logprob": -0.12898168158023915, "compression_ratio": 1.662551440329218, "no_speech_prob": 0.4451887905597687}, {"id": 229, "seek": 109736, "start": 1118.56, "end": 1126.1599999999999, "text": " It's basically showing how once you really identify a network of things and how they're", "tokens": [51424, 467, 311, 1936, 4099, 577, 1564, 291, 534, 5876, 257, 3209, 295, 721, 293, 577, 436, 434, 51804], "temperature": 0.0, "avg_logprob": -0.12898168158023915, "compression_ratio": 1.662551440329218, "no_speech_prob": 0.4451887905597687}, {"id": 230, "seek": 112616, "start": 1127.0, "end": 1132.1200000000001, "text": " you can see the dotted line to additional nodes that you did not even know existed and", "tokens": [50406, 291, 393, 536, 264, 37459, 1622, 281, 4497, 13891, 300, 291, 630, 406, 754, 458, 13135, 293, 50662], "temperature": 0.0, "avg_logprob": -0.14302775003377674, "compression_ratio": 1.7751937984496124, "no_speech_prob": 0.45284104347229004}, {"id": 231, "seek": 112616, "start": 1132.1200000000001, "end": 1136.24, "text": " that's a really powerful piece of knowledge graph and you definitely want to add that", "tokens": [50662, 300, 311, 257, 534, 4005, 2522, 295, 3601, 4295, 293, 291, 2138, 528, 281, 909, 300, 50868], "temperature": 0.0, "avg_logprob": -0.14302775003377674, "compression_ratio": 1.7751937984496124, "no_speech_prob": 0.45284104347229004}, {"id": 232, "seek": 112616, "start": 1136.24, "end": 1137.92, "text": " in if you can.", "tokens": [50868, 294, 498, 291, 393, 13, 50952], "temperature": 0.0, "avg_logprob": -0.14302775003377674, "compression_ratio": 1.7751937984496124, "no_speech_prob": 0.45284104347229004}, {"id": 233, "seek": 112616, "start": 1137.92, "end": 1143.76, "text": " You also want to identify those exceptions and add cardinality and when you're talking", "tokens": [50952, 509, 611, 528, 281, 5876, 729, 22847, 293, 909, 2920, 259, 1860, 293, 562, 291, 434, 1417, 51244], "temperature": 0.0, "avg_logprob": -0.14302775003377674, "compression_ratio": 1.7751937984496124, "no_speech_prob": 0.45284104347229004}, {"id": 234, "seek": 112616, "start": 1143.76, "end": 1148.68, "text": " about exceptions you do want to watch out for things like adding orphan nodes you want", "tokens": [51244, 466, 22847, 291, 360, 528, 281, 1159, 484, 337, 721, 411, 5127, 28711, 13891, 291, 528, 51490], "temperature": 0.0, "avg_logprob": -0.14302775003377674, "compression_ratio": 1.7751937984496124, "no_speech_prob": 0.45284104347229004}, {"id": 235, "seek": 112616, "start": 1148.68, "end": 1155.3600000000001, "text": " to avoid orphans as much as possible because after a while orphan nodes will start to accumulate", "tokens": [51490, 281, 5042, 23896, 599, 382, 709, 382, 1944, 570, 934, 257, 1339, 28711, 13891, 486, 722, 281, 33384, 51824], "temperature": 0.0, "avg_logprob": -0.14302775003377674, "compression_ratio": 1.7751937984496124, "no_speech_prob": 0.45284104347229004}, {"id": 236, "seek": 115536, "start": 1155.36, "end": 1160.8799999999999, "text": " and if you're not going back and trying to merge and dedupe because that's normally why", "tokens": [50364, 293, 498, 291, 434, 406, 516, 646, 293, 1382, 281, 22183, 293, 4172, 84, 494, 570, 300, 311, 5646, 983, 50640], "temperature": 0.0, "avg_logprob": -0.13332221984863282, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.015420269221067429}, {"id": 237, "seek": 115536, "start": 1160.8799999999999, "end": 1165.84, "text": " those show up is because they're an accidental whoops that's the same thing but we didn't", "tokens": [50640, 729, 855, 493, 307, 570, 436, 434, 364, 38094, 567, 3370, 300, 311, 264, 912, 551, 457, 321, 994, 380, 50888], "temperature": 0.0, "avg_logprob": -0.13332221984863282, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.015420269221067429}, {"id": 238, "seek": 115536, "start": 1165.84, "end": 1168.56, "text": " really identify it as such.", "tokens": [50888, 534, 5876, 309, 382, 1270, 13, 51024], "temperature": 0.0, "avg_logprob": -0.13332221984863282, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.015420269221067429}, {"id": 239, "seek": 115536, "start": 1168.56, "end": 1172.76, "text": " It will create that storm cloud of data above you that you just do not want.", "tokens": [51024, 467, 486, 1884, 300, 7679, 4588, 295, 1412, 3673, 291, 300, 291, 445, 360, 406, 528, 13, 51234], "temperature": 0.0, "avg_logprob": -0.13332221984863282, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.015420269221067429}, {"id": 240, "seek": 115536, "start": 1172.76, "end": 1174.76, "text": " It'll add technical debt.", "tokens": [51234, 467, 603, 909, 6191, 7831, 13, 51334], "temperature": 0.0, "avg_logprob": -0.13332221984863282, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.015420269221067429}, {"id": 241, "seek": 115536, "start": 1174.76, "end": 1181.04, "text": " It will add so much more process to any mapping and matching projects that you have.", "tokens": [51334, 467, 486, 909, 370, 709, 544, 1399, 281, 604, 18350, 293, 14324, 4455, 300, 291, 362, 13, 51648], "temperature": 0.0, "avg_logprob": -0.13332221984863282, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.015420269221067429}, {"id": 242, "seek": 118104, "start": 1182.0, "end": 1187.92, "text": " Just definitely try to avoid any of the orphan nodes if possible.", "tokens": [50412, 1449, 2138, 853, 281, 5042, 604, 295, 264, 28711, 13891, 498, 1944, 13, 50708], "temperature": 0.0, "avg_logprob": -0.18292957858035439, "compression_ratio": 1.5265700483091786, "no_speech_prob": 0.04741284251213074}, {"id": 243, "seek": 118104, "start": 1187.92, "end": 1192.52, "text": " Also checking the shape of your knowledge graph.", "tokens": [50708, 2743, 8568, 264, 3909, 295, 428, 3601, 4295, 13, 50938], "temperature": 0.0, "avg_logprob": -0.18292957858035439, "compression_ratio": 1.5265700483091786, "no_speech_prob": 0.04741284251213074}, {"id": 244, "seek": 118104, "start": 1192.52, "end": 1199.68, "text": " Some of those hidden relations might have to be explicitly defined in order to do certain", "tokens": [50938, 2188, 295, 729, 7633, 2299, 1062, 362, 281, 312, 20803, 7642, 294, 1668, 281, 360, 1629, 51296], "temperature": 0.0, "avg_logprob": -0.18292957858035439, "compression_ratio": 1.5265700483091786, "no_speech_prob": 0.04741284251213074}, {"id": 245, "seek": 118104, "start": 1199.68, "end": 1201.8799999999999, "text": " graph ML.", "tokens": [51296, 4295, 21601, 13, 51406], "temperature": 0.0, "avg_logprob": -0.18292957858035439, "compression_ratio": 1.5265700483091786, "no_speech_prob": 0.04741284251213074}, {"id": 246, "seek": 118104, "start": 1201.8799999999999, "end": 1208.44, "text": " This would be like if you needed a bipartite graph to do certain network analysis that", "tokens": [51406, 639, 576, 312, 411, 498, 291, 2978, 257, 28741, 642, 4295, 281, 360, 1629, 3209, 5215, 300, 51734], "temperature": 0.0, "avg_logprob": -0.18292957858035439, "compression_ratio": 1.5265700483091786, "no_speech_prob": 0.04741284251213074}, {"id": 247, "seek": 118104, "start": 1208.44, "end": 1209.96, "text": " sort of thing.", "tokens": [51734, 1333, 295, 551, 13, 51810], "temperature": 0.0, "avg_logprob": -0.18292957858035439, "compression_ratio": 1.5265700483091786, "no_speech_prob": 0.04741284251213074}, {"id": 248, "seek": 120996, "start": 1209.96, "end": 1217.44, "text": " Once you have even a small portion of your graph you can start to predict missing nodes", "tokens": [50364, 3443, 291, 362, 754, 257, 1359, 8044, 295, 428, 4295, 291, 393, 722, 281, 6069, 5361, 13891, 50738], "temperature": 0.0, "avg_logprob": -0.13174966665414664, "compression_ratio": 1.6916666666666667, "no_speech_prob": 0.021609853953123093}, {"id": 249, "seek": 120996, "start": 1217.44, "end": 1224.72, "text": " which is interesting because you might have dropped nodes along this evolutionary path.", "tokens": [50738, 597, 307, 1880, 570, 291, 1062, 362, 8119, 13891, 2051, 341, 27567, 3100, 13, 51102], "temperature": 0.0, "avg_logprob": -0.13174966665414664, "compression_ratio": 1.6916666666666667, "no_speech_prob": 0.021609853953123093}, {"id": 250, "seek": 120996, "start": 1224.72, "end": 1229.4, "text": " Remember there was the part node that we may or may not have needed that came from the", "tokens": [51102, 5459, 456, 390, 264, 644, 9984, 300, 321, 815, 420, 815, 406, 362, 2978, 300, 1361, 490, 264, 51336], "temperature": 0.0, "avg_logprob": -0.13174966665414664, "compression_ratio": 1.6916666666666667, "no_speech_prob": 0.021609853953123093}, {"id": 251, "seek": 120996, "start": 1229.4, "end": 1233.44, "text": " taxonomy and we dropped it maybe in the ontology stage.", "tokens": [51336, 3366, 23423, 293, 321, 8119, 309, 1310, 294, 264, 6592, 1793, 3233, 13, 51538], "temperature": 0.0, "avg_logprob": -0.13174966665414664, "compression_ratio": 1.6916666666666667, "no_speech_prob": 0.021609853953123093}, {"id": 252, "seek": 120996, "start": 1233.44, "end": 1237.56, "text": " Well maybe we actually do need that for doing some of the machine learning or maybe you", "tokens": [51538, 1042, 1310, 321, 767, 360, 643, 300, 337, 884, 512, 295, 264, 3479, 2539, 420, 1310, 291, 51744], "temperature": 0.0, "avg_logprob": -0.13174966665414664, "compression_ratio": 1.6916666666666667, "no_speech_prob": 0.021609853953123093}, {"id": 253, "seek": 123756, "start": 1237.56, "end": 1242.84, "text": " are starting to identify some of the attributes that you made a decision on in the ontology", "tokens": [50364, 366, 2891, 281, 5876, 512, 295, 264, 17212, 300, 291, 1027, 257, 3537, 322, 294, 264, 6592, 1793, 50628], "temperature": 0.0, "avg_logprob": -0.11182089571682911, "compression_ratio": 1.7768924302788844, "no_speech_prob": 0.08033162355422974}, {"id": 254, "seek": 123756, "start": 1242.84, "end": 1243.84, "text": " stage.", "tokens": [50628, 3233, 13, 50678], "temperature": 0.0, "avg_logprob": -0.11182089571682911, "compression_ratio": 1.7768924302788844, "no_speech_prob": 0.08033162355422974}, {"id": 255, "seek": 123756, "start": 1243.84, "end": 1245.12, "text": " Maybe they actually do need to be nodes.", "tokens": [50678, 2704, 436, 767, 360, 643, 281, 312, 13891, 13, 50742], "temperature": 0.0, "avg_logprob": -0.11182089571682911, "compression_ratio": 1.7768924302788844, "no_speech_prob": 0.08033162355422974}, {"id": 256, "seek": 123756, "start": 1245.12, "end": 1247.9199999999998, "text": " This is a great place to start to identify that.", "tokens": [50742, 639, 307, 257, 869, 1081, 281, 722, 281, 5876, 300, 13, 50882], "temperature": 0.0, "avg_logprob": -0.11182089571682911, "compression_ratio": 1.7768924302788844, "no_speech_prob": 0.08033162355422974}, {"id": 257, "seek": 123756, "start": 1247.9199999999998, "end": 1252.84, "text": " You're also going to start to identify dense clusters of really like-minded things.", "tokens": [50882, 509, 434, 611, 516, 281, 722, 281, 5876, 18011, 23313, 295, 534, 411, 12, 23310, 721, 13, 51128], "temperature": 0.0, "avg_logprob": -0.11182089571682911, "compression_ratio": 1.7768924302788844, "no_speech_prob": 0.08033162355422974}, {"id": 258, "seek": 123756, "start": 1252.84, "end": 1257.28, "text": " Things that are highly, highly connected and things that are more on the peripheral.", "tokens": [51128, 9514, 300, 366, 5405, 11, 5405, 4582, 293, 721, 300, 366, 544, 322, 264, 40235, 13, 51350], "temperature": 0.0, "avg_logprob": -0.11182089571682911, "compression_ratio": 1.7768924302788844, "no_speech_prob": 0.08033162355422974}, {"id": 259, "seek": 123756, "start": 1257.28, "end": 1263.36, "text": " These are really good to also identify gaps or where your catalog is stronger or weaker.", "tokens": [51350, 1981, 366, 534, 665, 281, 611, 5876, 15031, 420, 689, 428, 19746, 307, 7249, 420, 24286, 13, 51654], "temperature": 0.0, "avg_logprob": -0.11182089571682911, "compression_ratio": 1.7768924302788844, "no_speech_prob": 0.08033162355422974}, {"id": 260, "seek": 126336, "start": 1263.36, "end": 1265.4399999999998, "text": " You can also identify things like bottlenecks.", "tokens": [50364, 509, 393, 611, 5876, 721, 411, 44641, 2761, 13, 50468], "temperature": 0.0, "avg_logprob": -0.16452283198290532, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.15200528502464294}, {"id": 261, "seek": 126336, "start": 1265.4399999999998, "end": 1270.76, "text": " If you are doing things in the supply chain space where is everything going?", "tokens": [50468, 759, 291, 366, 884, 721, 294, 264, 5847, 5021, 1901, 689, 307, 1203, 516, 30, 50734], "temperature": 0.0, "avg_logprob": -0.16452283198290532, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.15200528502464294}, {"id": 262, "seek": 126336, "start": 1270.76, "end": 1274.9599999999998, "text": " If there's one node that's connecting a lot of other nodes that might be a bottleneck.", "tokens": [50734, 759, 456, 311, 472, 9984, 300, 311, 11015, 257, 688, 295, 661, 13891, 300, 1062, 312, 257, 44641, 547, 13, 50944], "temperature": 0.0, "avg_logprob": -0.16452283198290532, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.15200528502464294}, {"id": 263, "seek": 126336, "start": 1274.9599999999998, "end": 1277.36, "text": " You need to maybe look at that.", "tokens": [50944, 509, 643, 281, 1310, 574, 412, 300, 13, 51064], "temperature": 0.0, "avg_logprob": -0.16452283198290532, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.15200528502464294}, {"id": 264, "seek": 126336, "start": 1277.36, "end": 1281.9599999999998, "text": " There's a lot of other data intelligence that you can start to derive once you have this", "tokens": [51064, 821, 311, 257, 688, 295, 661, 1412, 7599, 300, 291, 393, 722, 281, 28446, 1564, 291, 362, 341, 51294], "temperature": 0.0, "avg_logprob": -0.16452283198290532, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.15200528502464294}, {"id": 265, "seek": 126336, "start": 1281.9599999999998, "end": 1286.0, "text": " graph in a true network like state.", "tokens": [51294, 4295, 294, 257, 2074, 3209, 411, 1785, 13, 51496], "temperature": 0.0, "avg_logprob": -0.16452283198290532, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.15200528502464294}, {"id": 266, "seek": 126336, "start": 1286.0, "end": 1288.12, "text": " So that is this in summary.", "tokens": [51496, 407, 300, 307, 341, 294, 12691, 13, 51602], "temperature": 0.0, "avg_logprob": -0.16452283198290532, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.15200528502464294}, {"id": 267, "seek": 128812, "start": 1288.4399999999998, "end": 1290.52, "text": " It has been a long video.", "tokens": [50380, 467, 575, 668, 257, 938, 960, 13, 50484], "temperature": 0.0, "avg_logprob": -0.1348403903609472, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.8074981570243835}, {"id": 268, "seek": 128812, "start": 1290.52, "end": 1292.8799999999999, "text": " I am sorry for the length.", "tokens": [50484, 286, 669, 2597, 337, 264, 4641, 13, 50602], "temperature": 0.0, "avg_logprob": -0.1348403903609472, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.8074981570243835}, {"id": 269, "seek": 128812, "start": 1292.8799999999999, "end": 1296.9199999999998, "text": " But to get through each of these, I know I even glossed over a lot of things in this.", "tokens": [50602, 583, 281, 483, 807, 1184, 295, 613, 11, 286, 458, 286, 754, 19574, 292, 670, 257, 688, 295, 721, 294, 341, 13, 50804], "temperature": 0.0, "avg_logprob": -0.1348403903609472, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.8074981570243835}, {"id": 270, "seek": 128812, "start": 1296.9199999999998, "end": 1301.3999999999999, "text": " So again, make sure you check down below for some of the links to additional videos to", "tokens": [50804, 407, 797, 11, 652, 988, 291, 1520, 760, 2507, 337, 512, 295, 264, 6123, 281, 4497, 2145, 281, 51028], "temperature": 0.0, "avg_logprob": -0.1348403903609472, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.8074981570243835}, {"id": 271, "seek": 128812, "start": 1301.3999999999999, "end": 1303.4799999999998, "text": " kind of flesh out more of this.", "tokens": [51028, 733, 295, 12497, 484, 544, 295, 341, 13, 51132], "temperature": 0.0, "avg_logprob": -0.1348403903609472, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.8074981570243835}, {"id": 272, "seek": 128812, "start": 1303.4799999999998, "end": 1306.12, "text": " But this has been a highly requested video.", "tokens": [51132, 583, 341, 575, 668, 257, 5405, 16436, 960, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1348403903609472, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.8074981570243835}, {"id": 273, "seek": 128812, "start": 1306.12, "end": 1308.04, "text": " I really hope that you've enjoyed this.", "tokens": [51264, 286, 534, 1454, 300, 291, 600, 4626, 341, 13, 51360], "temperature": 0.0, "avg_logprob": -0.1348403903609472, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.8074981570243835}, {"id": 274, "seek": 128812, "start": 1308.04, "end": 1312.3999999999999, "text": " And if there's anything that you have a question about in any of this, please make sure to reach", "tokens": [51360, 400, 498, 456, 311, 1340, 300, 291, 362, 257, 1168, 466, 294, 604, 295, 341, 11, 1767, 652, 988, 281, 2524, 51578], "temperature": 0.0, "avg_logprob": -0.1348403903609472, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.8074981570243835}, {"id": 275, "seek": 128812, "start": 1312.3999999999999, "end": 1317.28, "text": " out to me on LinkedIn in my email, which is listed in the description box below, or leave", "tokens": [51578, 484, 281, 385, 322, 20657, 294, 452, 3796, 11, 597, 307, 10052, 294, 264, 3855, 2424, 2507, 11, 420, 1856, 51822], "temperature": 0.0, "avg_logprob": -0.1348403903609472, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.8074981570243835}, {"id": 276, "seek": 131728, "start": 1317.28, "end": 1319.32, "text": " a comment on this video.", "tokens": [50364, 257, 2871, 322, 341, 960, 13, 50466], "temperature": 0.0, "avg_logprob": -0.14634081625169323, "compression_ratio": 1.1333333333333333, "no_speech_prob": 0.28111523389816284}, {"id": 277, "seek": 131728, "start": 1319.32, "end": 1322.56, "text": " And so with that, I want to thank you very much and I'll catch you next time.", "tokens": [50466, 400, 370, 365, 300, 11, 286, 528, 281, 1309, 291, 588, 709, 293, 286, 603, 3745, 291, 958, 565, 13, 50628], "temperature": 0.0, "avg_logprob": -0.14634081625169323, "compression_ratio": 1.1333333333333333, "no_speech_prob": 0.28111523389816284}], "language": "en"}