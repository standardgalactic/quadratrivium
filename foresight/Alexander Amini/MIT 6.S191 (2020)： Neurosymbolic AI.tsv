start	end	text
0	10280	Thanks so much for inviting me.
10280	15440	This is a great, this is a great class and a great program and I'm really excited to
15440	20000	see deep learning front and center as part of IAP.
20000	24040	I understand you've covered kind of the basics of deep learning and I'm going to tell you
24040	30080	today about something that's a little bit of a mashup on top of sort of standard deep
30080	33080	learning kind of going beyond deep learning.
33080	36960	But before I start, I just want to say something about this word artificial intelligence because
36960	39480	you know I had artificial intelligence in the last slide.
39480	42320	If you look at my business card, it actually says artificial intelligence in two separate
42320	45520	places on that card and I'll have a confession.
45520	50480	I'm a recovering academic so I was a professor at Harvard for ten years.
50480	52560	I just joined IBM about two years ago.
52560	53760	This is my first real job.
53760	58280	My mom's very proud of me that I finally got out of school.
58280	64320	But I will say as an academic researcher working on AI, we hated this term.
64320	69360	2017 and before, we would do anything we could not to say these words.
69360	73440	We'd say machine learning or we'd say deep learning, be more specific.
73440	77520	But 2018 and beyond, for whatever reason, we've all given up and we're all calling it
77520	78520	AI.
78520	82840	We're calling it AI, Google's calling it AI, academics are calling it AI.
82840	87400	But when I got to IBM, they had done something that I really appreciated and it helps kind
87400	88400	of frame the discussion.
88400	91320	It will frame the discussion about what I'm going to tell you about research-wise in a
91320	92320	minute.
92320	93320	And that's just to do something very simple.
93320	96760	This is part of something that IBM does called the global technology outlook, which is like
96760	101440	an annual process where we envision for the company, for the corporation what the future
101440	103480	lies holds ahead.
103480	107160	And they did something very simple just to put adjectives in front of AI, just to distinguish
107160	109400	what we're talking about when we're talking about different things.
109400	114040	So this will be relevant to where we want to push relative to where we are today with
114040	116400	deep learning to where we want to go.
116400	119960	And that's to distinguish what we have today as narrow AI.
119960	124600	So it's not to say it's not powerful or disruptive, but just to say that it's limited in important
124600	125800	ways.
125800	129720	And also to kind of distinguish it from general AI, which is the stuff that the public and
129720	131400	the press likes to talk about sometimes.
131400	135720	When IBM Research, which if you don't know, we're a 4,300-person global research organization,
135720	141200	we have six Nobel Prizes, we've been around for 75 years, when IBM Research tried to decide
141200	145080	when this was going to happen, when general AI was going to happen, we said 2050 and beyond.
145080	148840	And basically when you ask scientists something and they tell you 2050 and beyond when it's
148840	152400	coming, that means we have no idea, but it's no time soon.
152400	154120	But in the middle is this notion of broad AI.
154120	159760	And that's really what we're here today about and what the lab I run is about.
159760	165920	And just to unpack this one level deeper, on one hand, we have general AI.
165920	171880	This is this idea of broadly autonomous systems that can decide what they do on their own.
171880	175840	This is the kind of thing that Elon Musk described as summoning the demon.
175840	177360	So congratulations, everyone.
177360	182160	You're helping to summon the demon, according to Elon Musk, or slightly more level-headed
182160	186280	people like Stephen Hawking, warning that artificial intelligence could end mankind.
186320	189840	This is kind of, you know, maybe we need to worry about this in the future, but actually
189840	193360	what I'll argue in just a minute is that we're actually in quite a bit more limited space
193360	194360	right now.
194360	199120	And really it's this broad AI that we really need to focus on.
199120	202680	So how do we build systems that are multitasking, multi-domain, that can take knowledge from
202680	207000	one place, supply it in another, that can incorporate lots of different kinds of data,
207000	211800	not just images or video, but images, video, text, structure data, unstructured data, it's
211800	215480	distributed, it runs in the cloud, it also runs in edge devices, and it's explainable.
215480	217440	So we can understand what these systems do.
217440	221320	And this is basically then the roadmap for everything that my lab does.
221320	226640	So we're asking, what are the barriers we need to break down to bring in this era where
226640	229720	we can apply AI to all the different kinds of problems that we need to apply to?
229720	231920	So things like explainability.
231920	235360	We need to have systems that aren't just black boxes, but we can look inside and understand
235360	237640	why they make decisions, when they make a right decision.
237640	240880	We know why it made that decision, when they make a wrong decision.
240880	245000	We have the ability to reach in and figure out how we would debug that system.
245000	250400	One interesting thing about the AI revolution, back in the day, people said that software
250400	252200	was going to eat the world.
252200	258560	And these days, Jensen Wang, the CEO of NVIDIA, is on record saying that AI is going to eat
258560	259560	software.
259560	261040	And I think increasingly that's true.
261040	266720	We're going to have data-driven software systems that are based on technology like deep learning.
266720	269040	But the terrifying thing about that is we don't really yet have debuggers.
269040	272640	And it's very hard in many cases to figure out why systems aren't working.
272640	276320	So this is something that's really holding back AI today.
276320	279720	Security, I'll tell you a little bit about the kind of weird world of security we live
279720	283120	in now with AI, where AI systems can be hacked in interesting ways.
283120	287480	We can close those gaps to be able to really realize the full potential of AI.
287480	290440	Systems need to be fair and unbiased.
290440	293720	That's both the thing that's good for the world, but it's also the case that in many
293720	299160	regulated industries, like the kinds of companies that IBM serves, like banks, they're regulated
299160	302440	such that the government insists that their systems be provably fair.
302440	306400	We need to be able to look inside, see, and understand that the decisions the system will
306400	307920	make will be fair and unbiased.
307920	313400	And then on a practical level, I think the real battleground going forward for deep learning
313400	318600	and for AI in general, as much as people talk about big data, actually the most interesting
318600	323400	battlegrounds that we see across many different industries all have to do with small data.
323400	327040	So how do we work with very small amounts of data?
327040	331320	It turns out if you look across all the businesses that make the world run, heavy industries,
331320	337360	healthcare, financial services, most of the problems that those companies faced and that
337360	342520	we face in the world in general don't have enormous, annotated, carefully curated data
342520	343960	sets to go with them.
343960	349280	So if we're going to be able to use AI broadly and tackle all of these hard problems that
349280	353160	we want to solve, we need to be able to learn how to do more with less data.
353160	357320	So part of that has to do with things like transfer learning, learning to transfer from
357320	361960	one domain to another, so learning one domain and then use that knowledge somewhere else.
361960	365320	But increasingly, and this is what I'm going to tell you about today, there's this notion
365320	366640	of reasoning.
366640	370880	So how do we not only extract the structure of the data we're looking at, the data domain
370880	376360	we're interested in, but then also be able to logically and fluidly reason about that
376360	377860	data?
377860	380560	And then finally, just to close it out, just to give you a little bit of a pitch about
380560	384600	what the lab is and what we do, there's also a piece about infrastructure that we think
384600	385760	is really important.
385760	392200	So if you track energy usage from computing year over year, by some estimates by the year
392200	397640	2040, if we keep increasing our energy usage due to computing, we'll exceed the power budget
397640	399360	of the planet Earth.
399360	402760	There won't be enough solar radiation from the sun, not enough stuff we can dig up out
402760	406120	of the Earth and burn to fuel our computing habit.
406120	411960	And AI isn't helping, deep learning is not helping, so many models that we train will
411960	418120	take the equivalent energy of running a whole city for several days, just for one model.
418120	421040	And that's obviously not going to last for a long time.
421040	426320	So we also do work both at the algorithmic level, some of which I'll tell you about today,
426320	430320	but also at the physics level to ask, can we build different kinds of computers?
430320	435360	So this is a diagram of a memristive device, this is an analog computer, which we think
435360	439720	we can get power consumption for deep learning workloads down by maybe a factor of 100 or
439720	440720	even a thousand.
441360	442920	And we're also working in quantum computing.
442920	445320	IBM, as you may know, is one of the leaders in quantum.
445320	448640	We have some of the biggest quantum computers that are available today, and we're asking
448640	451440	how that all interacts with AI.
451440	457160	So when IBM, when we set out to do this challenge of how do we make AI broadly applicable to
457160	461960	all the kinds of problems that we'd like to apply AI to, just as a small plug for the
461960	466080	lab since we're here, we decided we didn't want to do it alone, and we chose a partner.
466080	468640	And in particular, we chose MIT.
468640	474560	And actually, the idea being that this is one of the last standing industrial research
474560	479160	labs of the Bell Lab era, IBM Research, together with MIT, which obviously needs no introduction
479160	481920	because we're here right now, and we're partnering around AI.
481920	485600	And just to give you a little bit of historical context, it actually turns out that IBM and
485600	489960	MIT have been together since the beginning of AI, literally since the term artificial
489960	496200	intelligence was coined, way back in 1956, so right when the very first computers were
496200	497200	being developed.
497200	503120	Nathaniel Rochester, who's the gentleman right there, who developed the IBM 701, which is
503120	509080	one of the first practical computers, got together with MIT professors like John McCarthy,
509080	511760	and dreamed up this future of AI.
511760	512760	And it's actually really fascinating.
512760	518640	I encourage you all to go and find the proposal for this workshop, because a lot of the language,
518640	523400	including neural network language, is all here, like they got a lot of the words right.
523400	529800	They were just a little bit off on the time scale, maybe like seven decades off.
529800	531280	But really interesting.
531280	535600	And the partnership here, the idea here is that we're combining the long horizon, time
535600	542360	horizon that MIT brings to the creation of knowledge, maybe 100-year time horizons, departments
542360	545960	of everything in chemistry, biology, economics, and physics, together with IBM, where we have
545960	550080	a lot of those same departments because we're such a big research organization.
550080	553800	But to bring those together with industry problems, to bring data to the table, so we
553800	557680	can do the kind of research we want to do, and to bring the compute resources along as
557680	558680	well.
558680	561520	So this is what the lab is, and what we do.
561520	566480	We were founded with a quarter-billion-dollar investment over 10 years from IBM.
566480	572960	And we have 50 projects currently, more than 50 projects currently running, over 150 researchers
572960	578600	across MIT and IBM, and their opportunities for undergraduates, for graduate students
578800	580200	to be involved in these projects.
580200	585080	So if you're interested in the things I show you today, we'd love to have you join our
585080	588520	team, either on the MIT side or on the IBM side.
588520	592440	And we're basically drawing from all of the different departments of MIT, and even though
592440	596840	we've only been running for about a year and a half, we have over 100 publications in
596840	598760	top academic conferences and journals.
598760	604560	We had 17 papers in NeurIPS just a few months ago, just to give you a sense of that everything's
604560	606280	up and running.
606280	611200	So this is the evolution, this is where we're going.
611200	614880	So why do I say that today's AI is narrow?
614880	615880	Why would I say that?
615880	626880	Because clearly, AI is powerful, in particular, in 2015 Forbes said that deep learning and
626880	630080	machine intelligence would eat the world.
630080	637720	And I think it's safe to say that progress since 2012 or so has been incredibly rapid.
637720	644240	So this was a paper that really, for me, as a researcher who was working in computer vision,
644240	647560	really convinced me that something dramatic was happening.
647560	653040	So this was a paper from Andre Carpathi, who now leads Tesla's AI program, together with
653040	655760	Fei-Fei Li, who created the ImageNet dataset.
655760	659800	And they built a system which you probably have studied a little bit in this course,
659800	664640	where they can take an image and produce a beautiful natural language caption.
664640	669200	So it takes an input like this, and it produces a caption like, a man in a black shirt is
669200	670800	playing a guitar.
670800	675760	Or you take in this image and you get a construction worker in an orange safety vest is working
675760	677720	on the road.
677720	682720	When I started studying computer vision and AI and machine learning, I wasn't sure we
682720	688280	were going to actually achieve this even in my career or perhaps even in my lifetime.
688280	691640	It seems like such science fiction, it's so commonplace now that we have systems that
691640	692720	can do that.
692720	700960	So it's hard to overstate how important deep learning has been in the progress of AI and
700960	701960	machine learning.
701960	707600	You know, meanwhile, there are very few games left that humans are better than machines
707600	708600	at.
708600	715800	Everything from Jeopardy, which IBM did way back in 2011, to Go with AlphaGo from DeepMind.
715800	721560	I think Carnegie Mellon created a system that could beat the world champion in poker.
721560	725560	And recently, my own company created a system called Project Debater that can actually carry
725560	730320	on a pretty credible natural language debate with a debate champion.
730320	735720	So if you like your computers to argue with you, we can do that for you now.
735720	740440	And even domains like art, which we would have thought maybe would have been privileged
740440	745360	domains for humanity, like surely machines can't create art, right?
746000	747000	That's not the case.
747000	752120	So even way back in 2015, which now feels like a long time ago, Matias Bekka's group
752120	756840	at the Max Planck in Tubingen created the system with Style Transfer, where you could
756840	761880	go from a photograph of your own and then re-render it in the style of any artist you
761880	762880	like.
762880	767280	So this is a very simple Style Transfer model that leveraged the internal representation
767280	772880	of a convolutional neural network up to what we have today, which is, again, just astonishing
772880	774960	how fast progress is moving.
775560	780240	These are the outputs from a system called BigGAN, which came from DeepMind.
780240	785040	And all four of these images are all of things that don't exist in the real world.
785040	787280	So this dog, not a real dog.
787280	793800	You put it in a random vector into the bigGAN, and it generates full cloth, this beautiful
793800	797440	high-resolution dog, or this bubble, or this cup.
797440	800640	And this is actually going to be a problem now, because now we have this notion of deepfakes.
800640	805920	We're getting so good at creating fake images that now we're having to come up with actual
805920	806920	countermeasures.
806920	811880	And that's actually one thing we're working on in the laboratory I run at IBM, where we're
811880	817280	trying to find ganttodotes, like, antidotes, countermeasures against GANs as we move forward.
817280	821760	So clearly, the progress is impressive.
821760	826320	So why am I saying that AI is still narrow today?
827280	830360	Well, does anyone know what this is?
830360	832440	Anyone have any ideas?
832440	833440	Yeah.
833440	836440	Good job, but you're wrong.
836440	838560	It turns out it's a teddy bear.
838560	845600	So if you ask a state-of-the-art ImageNet-trained CNN, and you often see these CNNs described
845600	848880	as being superhuman in their accuracy, has anyone heard that before?
848880	852720	Like, they'll say, object recognition is a solved problem.
852720	855200	These ImageNet-trained CNNs can do better than humans.
856080	859720	And if you've ever actually looked at the ImageNet carefully, the reason that's true
859720	864800	is because ImageNet has huge numbers of categories of dogs, so you basically need to be a dog
864800	868480	show judge to be able to outperform a human at ImageNet.
868480	872160	But this is starting to illustrate a problem.
872160	873160	This image is real.
873160	878600	So this is a piece of art in the Museum of Modern Art in New York by Merit Oppenheim,
878600	886800	called Le Dijonnet en Fereur, a luncheon in Fereur, a little bit unsettling image.
886800	890360	But we, like, who thought it was a teddy bear?
890360	891360	Right?
891360	898680	Like, the most unteddy bear-like image ever, right?
898680	902360	Why did the CNN think this was a teddy bear?
902360	904840	Soft and fluffy.
904840	905840	Soft and fluffy.
905840	906840	It's round.
906840	907840	It's got fur.
907840	911120	So one of the things in the training set would be round and furry teddy bears.
911120	914040	You know, it's a little bit of a garbage-in-garbage-out kind of scenario.
914040	918800	This is, in many ways, you know, people talk about corner cases or edge cases, those rare
918800	924560	things that happen, but are different from the distribution you've trained on previously.
924560	927560	And this is a great example of such a thing.
927560	931400	So this is starting to show that even though deep learning systems we have today are amazing,
931400	935720	and they are amazing, there's, you know, there's room for improvement, there's something missing
935720	936720	here.
936880	941000	Actually, if we dig a little bit deeper, which, you know, a variety of researchers have done,
941000	948120	so this is from Alan Yule's group at Johns Hopkins, even in cases where, you know, the
948120	952440	objects are the standard objects that the system knows how to detect its supposedly
952440	957160	superhuman, you know, sort of levels, if we take this guitar and we put it on top of
957160	961320	this monkey in the jungle, a couple of funny things happen.
961320	963720	One is it thinks the guitar is a bird.
964320	966240	Anyone have an idea why that is?
966240	969080	I hear pieces of the answer all around.
969080	971040	So it's colorful, right?
971040	973080	It's a color that you would expect a tropical bird.
973080	977720	Things that are in the jungle in distribution would tend to be colorful tropical birds.
977720	980960	Interestingly, because you put the guitar in front of the monkey, now the monkey's a
980960	981960	person.
981960	988120	And, you know, again, you know, monkeys don't play guitars in the training set, and that's
988120	989440	clearly messing with the results.
989440	996920	So even though we have no trouble at all telling that these objects are a guitar and a monkey,
996920	1000080	the state-of-the-art systems are falling down.
1000080	1005840	And then even this captioning example, which I highlighted as being, you know, an amazing
1005840	1010120	success for deep learning, and it is an amazing success for deep learning, when you poke a
1010120	1015560	little bit harder, which, you know, Josh Tenenbaum and Sam Gershman and Brendan Lake and Tomer
1015560	1017960	Oman did, you find things like this.
1017960	1024840	So this image is captioned as a man riding a motorcycle on a beach.
1024840	1031160	This next one is an airplane is parked on the tarmac at an airport.
1031160	1037320	And this one, next one, is a group of people standing on top of a beach, which is correct.
1037320	1041200	So score one for the AI.
1041200	1047360	But what you can see is there's a strong sense in which the system doesn't really understand
1047360	1052760	what it's looking at, and that leads to mistakes, and that leads to sort of, you know, missing
1052760	1055760	the point, you know, in many cases.
1055760	1061560	And again, this has to do with the fact that the systems are trained on the data, and largely
1061560	1064680	they're constrained by what data they've seen before, and things that are out of sample,
1064680	1069320	these edge cases, these corner cases, tend to perform poorly.
1069320	1074120	Now the success of deep learning, you know, I think it's safe to say it's, you know, two
1074120	1075120	things happened.
1075120	1080360	So deep learning, as you already know, is a rebrand of a technology called artificial
1080360	1081360	neural networks.
1081360	1085600	It dates all the way back to that Dartmouth conference, at least to the 80s.
1085600	1091360	You know, a lot of the fundamental map of backprop was worked out in the 80s.
1091360	1096200	We went through decades of time where it was disreputable to study neural networks, and
1096200	1099920	I lived through that era where you would try and publish a paper about neural networks,
1099920	1103080	and people would tell you that everyone knows that neural networks don't work.
1103080	1109320	So what happened was the amount of data that was available grew enormously, so we digitalized
1109320	1110320	the world.
1110320	1111320	We got digital cameras.
1111320	1114800	Now we're all carrying, I'm carrying like four cameras on me right now.
1114800	1116240	And we took a lot of images.
1116240	1120040	And then the compute caught up as well, and particularly graphics processing units, graphics
1120040	1123360	processing units, GPUs became available, and it turned out they were even better for doing
1123360	1125720	deep learning than they were for doing graphics.
1125720	1130200	And really the seminal moment that really flipped the switch and made deep learning take off
1130200	1134760	was the collection of this data set called ImageNet, which Fei-Fei Li collected, and
1134760	1141840	it's basically millions of carefully curated images with categories associated with them.
1141840	1146560	Now you need to have data sets of this scale to make deep learning work.
1146560	1150880	So if you're working on projects now and you're training neural networks, you'll know that
1150880	1155800	you need to have thousands to millions of images to be able to train a network and have
1155800	1157800	it perform well.
1157800	1160200	That's in stark contrast to how we work.
1160200	1162720	So does anyone know what this object is?
1162720	1164560	Just a quick raise of your hands.
1164560	1167560	Okay, a few people, not so many.
1167560	1171200	But even though you've never seen this object before, a single training example, you're
1171200	1173440	now all experts in this object.
1173440	1174880	Just one training example.
1174880	1179240	So I can show you to you and ask, is that object present in this image?
1179240	1181240	I think we all agree, yes.
1181240	1185440	I can ask you questions like how many are in this image, and I think we'd all agree there
1185440	1187400	are two.
1187400	1190520	And I can even ask you, is it present in this image?
1190520	1196660	And I think you'd all agree, yeah, but it's weird, right?
1196660	1202880	So not only can you recognize the object from a single training example, not thousands,
1202880	1208400	not millions, one, you can reason about it now in context where it's just weird, right?
1208400	1212440	And that's why you can tell that it's a fur-covered saucer cup and spoon and not a teddy bear
1212440	1214440	because you have this ability to reason out a sample.
1214440	1219560	And that's really a remarkable ability that we'd love to have because when you get past
1219560	1224680	imagery, you get past digital images, there are very few data sets that have this kind
1224680	1228340	of scale that ImageNet has.
1228340	1233040	But even ImageNet turns out, you know, there's something else wrong with it.
1233040	1237520	So does anyone notice anything about these chairs in the image, these were all taken
1237520	1239720	from ImageNet, from the chairs category?
1239720	1242520	Does anyone notice anything unusual about these?
1242880	1246640	They're all facing the camera, they're in canonical views, they're all more or less centered.
1246640	1250040	In the case where there's multiple chairs, they're kind of like almost like a texture
1250040	1251200	of chairs, right?
1251200	1254280	So these are very unusual images, actually.
1254280	1257480	I mean, we look at them and we think these are normal images of chairs, but these are
1257480	1261720	actually very carefully posed and crafted images.
1261720	1266480	And one of the projects that we've been working on together with MIT across the MIT IBM Lab
1266480	1272480	was, this is a project that was led by Boris Katz and Andre Barbou together with our own
1272600	1277800	Dan Gutfreund, they asked, okay, well, what if we collected a data set where that wasn't
1277800	1282400	true, so where we didn't have carefully, perfectly centered objects?
1282400	1286080	And what they did is they enlisted a whole bunch of mechanical turkers on Amazon Mechanical
1286080	1291880	Turk and they told them, take a hammer, take it into your bedroom, put it on your bed,
1291880	1296360	and here's a smartphone app and please put it in this bounding box.
1296360	1300960	So basically you'd have to go and the people get instructions, you know, take your chair,
1300960	1304280	we want you to put it in the living room, and we want you to put it on its side and
1304280	1305840	put it in that bounding box.
1305840	1309360	Or we want you to take a knife out of your kitchen, put it in the bathroom, and make
1309360	1312800	it fit in that bounding box, or, you know, take that bottle and put it on a chair in
1312800	1313800	this orientation.
1313800	1317400	So they went through and they just collected a huge amount of this data, so they collected
1317400	1322720	50,000 of these images from 300 object classes that overlap with ImageNet, and then they
1322720	1326960	asked the mechanical turkers to go into four different rooms with those things.
1326960	1332840	So remember, everyone talks about how ImageNet is state-of-the-art in object categorization
1332840	1337120	and that's a solved problem, but it turns out when you take these images of these objects
1337120	1342520	that are not in the right place, humans can perform it well over 95 percent accuracy on
1342520	1348280	this task, but the AIs, the CNNs that were previously performing, you know, at state-of-the-art
1348280	1353560	levels, drop all the way down 40 to 45 percent down in their performance.
1353560	1358240	So there's a very real sense in which, as amazing as deep learning is, and I'm going
1358240	1365760	to keep saying this, deep learning is amazing, but some of the gains in the, you know, the
1365760	1369920	sort of declarations of victory are a little bit overstated, and they all circle around
1369920	1376680	this idea of small data, of corner cases, edge cases, and being able to reason about
1376680	1379760	situations that are a little bit out of the ordinary.
1379760	1381680	All right?
1381680	1387320	And of course, the last piece, you know, that's concerning for anyone who's trying to deploy
1387320	1392560	neural networks in the real world is that they're weirdly vulnerable to hacking.
1392560	1398800	So I don't know if you guys covered adversarial examples in this class yet, but here's an
1398800	1405400	example targeting that same captioning system, so where, you know, the captioning system
1405400	1409120	can see this picture of a stop sign and produce this beautiful natural language caption, a
1409120	1412000	red stop sign sitting on the side of a road.
1412000	1417160	Our own Pinyu Chen, who's an expert in this area at IBM, created this image, which is
1417160	1421800	a very subtle perturbation of the original, and you can get that to now say a brown teddy
1421800	1424960	bear lying on top of the bed with high confidence.
1424960	1430360	So this is a case, again, where there's something divergent between how we perceive images and
1430360	1436280	understand what the content of an image is and how these end-to-end trained neural networks
1436280	1437720	do the same.
1437720	1443120	Like, you know, this kind of, you know, this image, the perturbations of the pixels in
1443120	1446800	this image were done in such a way that they'd be small so that you couldn't see them, so
1446800	1450400	they're specifically hidden from us.
1450400	1454360	But it turns out that you don't have to actually have access to the digital image.
1454360	1458480	You can also do real-world in-the-wild adversarial attacks.
1458480	1465000	And this is one that was kind of fun, some folks in my lab and my group decided it'd
1465000	1467760	be fun to have a t-shirt that was adversarial.
1467760	1473520	So you took a person detector, and so this is like, you know, it'll detect a person.
1473520	1476160	You can imagine, like, an AI-powered surveillance system.
1476160	1478520	If you were to intrude in the building, you might want to have a person detector that could
1478520	1483880	detect a person and warn somebody, hey, there's a person in your building that doesn't belong.
1483880	1486720	But what they did is they created this shirt.
1486720	1488360	So this shirt's very carefully crafted.
1488360	1491560	It's a very loud, ugly shirt.
1491560	1492560	We have it in the lab.
1492560	1496320	If you want to come over any time and try it on, you're welcome to.
1496320	1498960	But this shirt basically makes you invisible to AI.
1498960	1504560	So this is Sija, who's our wizard adversarial example.
1504560	1507520	He's not wearing the shirt, so you can see the person detector is detecting him just
1507520	1508520	fine.
1508520	1509880	Tron Fu is wearing the shirt.
1509880	1510880	Therefore he is invisible.
1510880	1511880	He is camouflaged.
1511880	1517480	And you can see, even as you walk around, even if the shirt is folded and bent and wrinkled,
1517480	1519360	it makes you invisible.
1519360	1523040	So weird, right?
1523040	1527880	If anything for us, this ugly-looking shirt makes you even more visible.
1527880	1532560	So there's something weird about how deep learning seems to work relative to how weird
1532560	1534400	we work.
1534400	1540680	But there are also problems where, even under the best of conditions, no adversarial perturbation,
1540680	1545000	you can have as much training data as you like, where deep learning still struggles.
1545000	1549080	And these are really interesting for us, because these are cases where, no matter how much
1549080	1553320	data you have, deep learning just doesn't cut it for some reason.
1553320	1554320	And we want to know why.
1554320	1559560	So problems like this, if you ask the question, so I give you a picture, and I ask the question,
1559560	1562960	how many blocks are on the right of the three-level tower?
1562960	1566240	Or will the block tower fall if the top block is removed?
1566240	1568440	Or are there more animals than trees?
1568440	1572520	Or what is the shape of the object closest to the large cylinder?
1572520	1576440	These are all questions that even a child could answer, I mean, provided they understand
1576440	1582880	language and can read and stuff, it's very easy for us to work on these things.
1582880	1585840	But it turns out that deep learning systems, irrespective of how much training data you
1585840	1588200	give, struggle.
1588200	1593000	So that's a case where they're smoking, you kind of want to know where's the fire.
1593000	1596920	Actually the answer we think, or one of the things we're exploring, is the idea that maybe
1596920	1599880	the answer lies all the way back in 1956.
1599880	1606320	So this is a picture of that Dartmouth workshop back in 1956.
1606320	1611840	And back in this time period, neural networks were already, you know, had already been sort
1611840	1612840	of born.
1612840	1616400	We were thinking about neural networks, but we were also thinking about another kind of
1616400	1617400	AI back then.
1617400	1620680	And that kind of AI is interesting and different.
1620680	1624560	It hasn't really enjoyed a resurgence the way that neural networks have.
1624560	1627680	But just to step back for a moment, this is what you've been studying.
1627680	1630600	Neural network basically is a nonlinear function approximator.
1630600	1635960	You take an input in, and you get some output that you want out, and it learns the weights
1635960	1638440	of the network through training with data.
1638440	1641400	So this is what an apple looks like to a neural network.
1641400	1646560	You know, you put an apple picture in, and you light up, you know, a unit that says there's
1646560	1649360	probably an apple in that scene.
1649360	1653960	There's another kind of AI that's been around since the beginning called symbolic AI.
1653960	1659800	And this is from a book by Marvin Minsky in 1991 that was created here.
1659800	1662800	And this is what an apple looks like to symbolic AI.
1662800	1664760	So we know things about an apple.
1664760	1666800	We know that an apple has an origin.
1666800	1667880	It comes from an apple tree.
1667880	1670120	We know that an apple is a kind of fruit.
1670120	1671120	You know, that apple has parts.
1671120	1672800	It has a body, and it has a stem.
1672800	1674360	The body has a shape.
1674360	1675360	It's round.
1675360	1676360	It has a size.
1676360	1677360	It can fit in your hand.
1677360	1678360	It's got a color.
1678360	1679720	It could be red or green.
1679720	1683480	We know lots of knowledge about what an apple is.
1683480	1687880	And that's a very different take on AI.
1687880	1692920	And you know, basically this field of what we call good old fashioned AI or symbolic
1692920	1699280	AI has been around since the very beginning, and it just hasn't yet enjoyed that resurgence
1699280	1701280	that neural networks did.
1701280	1705320	And one of the central theses that we're exploring is that just the same way that neural
1705320	1709960	networks have been waiting, they were waiting for compute and data to come along to make
1709960	1711480	them really work.
1711480	1717200	We think that symbolic AI has also been waiting, but what it's been waiting for is neural networks.
1717200	1722280	So now that neural networks work, can we go back to some of these ideas from symbolic
1722280	1725960	AI and do something different?
1725960	1731400	And the work I'm going to tell you about is a collaboration as part of the MIT IBM Lab.
1731400	1735440	Chuangon is one of the researchers in my group together with Josh Tenenbaum, in particular
1735440	1740560	Jojen Wu, who's now an assistant professor at Stanford, along with some others.
1740560	1745280	And what they're asking is, can we mix together the ideas of neural networks together with
1745280	1750080	the ideas from symbolic AI and do something that's more than the sum of its parts?
1750080	1754920	And this picture that I showed you here, I showed you this earlier, this is actually
1754920	1761080	a data set called Clever that was basically created to illustrate this problem, where
1761080	1764720	irrespective of how much training data you have, this very simple kind of question answering
1764720	1767400	task where you have to answer questions like, are there an equal number of large things
1767400	1770280	in metal spheres seems to be hard.
1770280	1772520	So the data set was created to illustrate the problem.
1772520	1777760	And if you tackle this the way you're supposed to with neural networks and deep learning,
1777760	1783280	and perhaps you've learned over the course of this IEP course that the best way to train
1783280	1785480	a system is end to end.
1785480	1790080	The best way to get what you want is to start from what you have and end with what you need
1790080	1794280	and don't get in the way in the middle, just let the neural network do its thing.
1794280	1798080	The problem is that when you build end to end neural networks and try and train them
1798080	1804280	to go from these inputs to these outputs, for data sets like this it just doesn't work
1804280	1805400	well at all.
1805400	1808880	And the reason for that is that the concepts, things like colors and shapes and objects and
1808880	1813320	things like that, and then the portions of reasoning, like counting the number of objects
1813320	1817640	or reasoning about the relationships between objects are fundamentally entangled inside
1817640	1820120	the representation of the neural network.
1820120	1824040	And then not only does that cause problems where it's very difficult to cover the entire
1824040	1828760	distribution and not get caught by corner cases, but it also means it's hard to transfer
1828760	1832960	to other kinds of tasks like image captioning or instance retrieval or other kinds of things.
1832960	1837080	So fundamentally this end to end approach just doesn't seem to work very well.
1837080	1839680	So I'm already telling you something that's sort of probably against the advice you've
1839680	1842360	gotten thus far.
1842360	1846000	But when you step back and look at well how do we solve this problem of visual reasoning,
1846000	1849760	you have a question like this, are there an equal number of large things in metal spheres?
1850400	1854320	When we tackle this problem, well first we read the question and we see there's something
1854320	1855840	about large things.
1855840	1859960	We use our visual system to sort of find the large things.
1859960	1863000	Then we read the question, we see there's something about metal spheres and we use our
1863000	1866000	visual system to find the metal spheres.
1866000	1871480	And then critically we do an operation, a symbolic operation, an equality operation
1871480	1875200	where we decide are these an equal number and we say yes.
1875200	1876200	So that's what we do.
1876240	1881080	And if you unpack that, yeah it's got visual perception and CNNs are a great candidate
1881080	1882400	for doing that.
1882400	1885960	And yeah it's got question understanding, natural language processing and yeah RNNs are
1885960	1888280	a great tool for doing that.
1888280	1893720	But critically it also has this component of logical reasoning where you can very flexibly
1893720	1897920	apply operations in a compositional way.
1897920	1903920	So what the team did then was to basically this is kind of like the neurosymbolic hello
1903920	1904920	world.
1905160	1908160	It's the first program you write in most programming languages.
1908160	1912200	This is kind of the simplest example that we could tackle.
1912200	1915120	And this is the sort of diagram of the flow system and don't worry I'm going to unpack
1915120	1921680	all this where because neural networks are good at vision we use a CNN to do the vision
1921680	1929000	part but instead of going straight to an answer it's used to basically de-render the scene.
1929000	1933280	So rendering goes from a symbolic representation to an image, de-rendering goes from the image
1933320	1937560	back to some kind of symbolic structure representation so we're going to take apart the image using
1937560	1939040	the neural network.
1939040	1944600	And then the question, you'd be crazy not to use something like an LSTM to parse the
1944600	1948880	language but instead of going from the language straight to an answer or going from the language
1948880	1954640	to a label or something, the language is going to be parsed into a program, into a symbolic
1954640	1958560	program which is then going to be executed on the structure representation.
1958560	1962920	So just to walk you through that, we have a vision part, we have a language part.
1962920	1968240	You parse the scene using a CNN so you turn, you know, you find the objects in the scene
1968240	1971920	and you basically create a table that says what are the objects, what are their properties
1971920	1976920	and where are they and then you do semantic parsing on the language part and again the
1976920	1981400	goal here is to go from natural language with all of its, you know, sort of vagaries and
1981400	1988520	messiness to a program, a program that we're going to run in a minute and so you need to
1988520	1993680	learn how to take this language and turn it into a series of symbolic operations and
1993680	1999840	then you're going to run that symbolic program on the structured symbolic information and
1999840	2001960	get an answer.
2001960	2005640	So you would start by filtering and saying I want to look, the question is asking about
2005640	2009080	something red so I need to filter on red and then I need to query the shape of that object
2009080	2010560	that I've just filtered.
2010560	2015680	So this is basic, you know, sort of program execution.
2015680	2021600	And critically the system is trained jointly with reinforcement learning so the neural
2021600	2026400	network that does vision and the neural network that translates from language to a program
2026400	2030480	fundamentally learns something different by virtue of being part of a hybrid symbolic
2030480	2032000	system, right?
2032000	2036280	So it gets reward, it doesn't get reward and you propagate gradients and all that based
2036280	2039640	on whether or not the symbolic system got the right answer and we use reinforcement
2039640	2045440	learning of course because you can't differentiate through the symbolic part but, you know, fundamentally
2045480	2049900	this isn't just a matter of bolting neural networks onto a symbolic reasoner but rather
2049900	2054240	training them jointly so that the symbolic, so the neural networks learn, extract the
2054240	2059160	symbols, learn to give the right symbolic representations through experience and learning
2059160	2060160	on the data.
2060160	2063240	So this does a couple of really interesting things.
2063240	2066800	So one of the first things you'll notice, this data set was created, this clever data
2066800	2071000	set was created because it illustrated a problem with end-to-end learning but it turns out
2071000	2076800	that with just a dash of symbolic execution now you can be effectively perfect on the
2076800	2081120	clever data set so clever is now solved and this was actually an oral spotlight paper
2081120	2087240	at NURBS because this is a big deal, previously unsolved problem now solved, that's good.
2087240	2090960	But interestingly, more than that, remember I said the biggest problem with deploying
2090960	2094920	neural networks in the real world is that we rarely have big data, we usually have pretty
2094920	2095920	small data.
2095920	2101400	So anything that reduces the sample, improves the sample efficiency of these methods is
2101400	2107280	really valuable and so here's the number of training examples that the system is given,
2107280	2112880	this is the accuracy of the system, the neural symbolic system is up here in blue, I'll just
2112880	2119280	point out several things, one is it's always better and but if you look at, you know, down
2119280	2126440	here the end-to-end train systems require close to a million examples, they're kind
2126440	2132040	of, you know, okay results, not perfect but okay, the neural symbolic system again with
2132040	2136920	just a dash of symbolic mixed in with just one percent of the data can do better than
2136920	2140200	most of the end-to-end train systems and with just ten percent of the data, one tenth of
2140200	2144040	the data can perform at effectively perfect performance.
2144040	2151280	So drastically lower, you know, requirement for data, drastically higher sample efficiency.
2151280	2154880	And then the last piece, remember I said explainability was super important, you know, people are actually
2154880	2158600	going to really use AI systems, they need to be able to look inside and understand why
2158600	2163400	the decision is made, otherwise they won't trust the AI system, they won't use it.
2163400	2168240	Because the system has a symbolic choke point in the middle where you parse the question
2168240	2173600	into a series of symbolic operations, we can debug the system the same way you would debug
2173600	2178640	a traditional coded system, so you can see, okay well what did it do, it filtered on cyan,
2178640	2182360	it filtered on metal, was that the right thing, you can just, you can understand why it made
2182360	2185960	the decision it made, and if it made the wrong decision now you have some guidance on what
2185960	2187720	you'd want to do next.
2187720	2194160	So that was a paper from this team in 2018, Neurosymbolic BQA, actually since then there's
2194160	2199960	basically been a parade of papers that have made this more and more sophisticated.
2199960	2205880	So there was a paper in iClear in 2019 called the Neurosymbolic Concept Learner that relaxed
2205880	2210360	the requirement that the concepts be pre-coded, there's another paper that just came out in
2210360	2214400	Europe just a few months ago or last month called the Neurosymbolic Meta Concept Learner
2214400	2219760	that autonomously learns new concepts, it can sort of use meta concepts to do better,
2219760	2223960	and we're even now getting this to work in not just these toy images but also in real
2223960	2226840	world images, which is obviously important.
2226840	2229680	And we think this is actually a really interesting and profitable direction to go forward.
2229680	2233880	So here's the Neurosymbolic Concept Learning, basically what's happened is we're relaxing
2233880	2240480	now these concepts into concept embeddings, so when you look at an object with a CNN you
2240480	2247000	can now embed into a space of color and then compare that color to stored concept embeddings,
2247000	2252840	which means you can now learn new concepts dynamically and you can learn them from context.
2252840	2256560	So you don't need to know that green is a color, you can figure that out and learn that,
2256560	2262120	this is important because the world's full of new concepts that we're constantly encountering,
2262120	2265120	so that was the sort of next innovation on the system.
2265120	2269080	Also remember I said that one of the things that's magical about symbolic AI is that we
2269080	2274280	can leverage lots of different kinds of knowledge, and in fact we can leverage these sort of
2274280	2281000	meta relationships between different concepts, we know there are synonyms for instance, which
2281000	2285800	led to this paper which was just presented last month called the Neurosymbolic Meta Concept
2285800	2291920	Learner, where you can have a notion of is red the same kind of concept as green or is
2291920	2299760	cube a synonym of block, which then of course lets you do things like if I go through in
2299760	2306120	the regular mode here and I'm creating a representation of the object and I'm creating a symbolic program,
2306120	2311920	I can do the regular thing, but then also critically I can now use relationships I know
2311920	2318120	about synonyms and concept equivalencies to meta verify these things, and then I can
2318120	2321480	take advantage of the fact that if I know that there's an airplane then I also know
2321480	2324920	there's a plane because a plane and an airplane are synonyms.
2324920	2329000	I can know that if there's any kind of kid and the answer is yes, that is there any kind
2329000	2333000	of child, I know that's also yes because child and kid are synonyms.
2333000	2337280	So we can start to see how we can get more and more complex and more and more sophisticated
2337280	2340680	with our symbolic reasoning and do more and more and more.
2340680	2342760	Of course it works well.
2342760	2347520	We're also now extending since clever is now beaten, we're now looking also at, we're
2347520	2353400	releasing a new data set called video clever, it's called cleverer, which is a very tortured
2353400	2358720	acronym, looking at the relationships between objects and counterfactuals, what would happen
2358720	2362560	if this block weren't there, so you can see that we can kind of expand to more and more
2362560	2365560	sophisticated environments as we go.
2365640	2372960	I'll just also say that this notion of symbolic program execution isn't the only idea from
2372960	2375960	symbolic AI that we can bring together with neural networks.
2375960	2380040	We're also looking at the field of planning, so there's a field of symbolic AI called planning
2380040	2384680	where you try and start from an initial state and then use an action plan to arrive at some
2384680	2388960	target state, which is really good for solving problems like the tower of Hanoi which you
2388960	2392680	may have encountered or these kinds of slider puzzles where you need to produce a series
2392720	2398600	of operations to achieve a certain end state, like make the picture into the right shape.
2398600	2402960	Another area of projects that we're working on is mixing these together with neural networks
2402960	2406920	so that we don't just have to rely on sort of static symbolic representations, but we
2406920	2410040	can actually work in the latent space of an autoencoder.
2410040	2414800	We have binary discrete autoencoders and we can actually plan in the latent space of an
2414800	2415800	autoencoder.
2415800	2420240	Obviously these are topics that would be a whole talk unto themselves, but I just want
2420280	2424400	to give you a little bit of a flavor that this idea of mashing up neural networks and
2424400	2432480	symbolic AI has a lot of range and there's a lot of room to grow and explore and lots
2432480	2436520	of ideas in symbolic AI now that we can bring together and every time we do we seem to find
2436520	2439520	that good things happen.
2439520	2445960	So with that I'll stop just to give you one picture in your mind, these sort of two venerable
2446000	2447000	traditions of AI.
2447000	2453160	I think we're coming to a place where we can bring the symbolic stuff out of the closet
2453160	2458400	dusted off and in many ways the power of neural networks solves many of the problems and they
2458400	2461760	complement each other's strengths and weaknesses in really important and useful ways.
2461760	2465520	So with that I'll stop and thank you all for your attention and if you have any questions
2465520	2466520	I'm very happy to answer them.
2466520	2467520	Thank you.
2467520	2468520	Thank you.
2468520	2469520	Thank you.
2469520	2470520	Thank you.
2470520	2471520	Thank you.
2471520	2472520	Thank you.
2472520	2473520	Thank you.
2473520	2474520	Thank you.
2474520	2475520	Thank you.
