They not only doxxed the correlation between my principal identity and Beth Jesus, but the voice doxxed me.
I didn't want to talk to them, but then they're like, look, this is going to really come out.
I'm like, all right, well, I better try to control the narrative.
I thought there was a sort of like ethical protection.
Like, no, I've been trying to figure out, like, why did this happen to me?
Like, where did I cross the threshold of becoming enough of a problem that they needed to have leverage over me and expose me?
Our movement is about free speech, freedom of compute, freedom of AI, and not, like, top-down oppression.
I have failed, honestly, and apology to you two.
We both, you failed.
I don't know why you're talking to them.
Do not talk to journalists.
I said, don't talk to journalists.
You do not try to violate this rule.
You will regret it.
Welcome back to the pod.
We have the, we've got, are we saying Beth Jesus or where are we going with this?
You could call me both names.
I go by both names now, Beth Jesus or Gil Verdon in America, Guillaume Valdon in Canada and France, if you will.
So finally, after it's been honestly too long, the legendary biology doesn't even get a,
does not even need a second name.
It's like, you know, Madonna or who are the other ones?
I don't even know.
And you might be like, I guess.
Teal, I guess.
Well, I, you know, it's not quite, it's not, it's biology.
We are here today.
This is, I'm stoked about this episode.
This is going to be a great one.
And both of you guys, thank you.
You're on a different time zone.
It's been a while setting this up.
But biology and I have been talking about, and biology, I mean, separately from each other,
but also together, media and the shape of media for years through like tech dark ages,
back when we had no counter voice whatsoever, up until today where I think things are still
not balanced, but very different than they were three years ago, certainly during COVID.
And before that, Gil, you were, I'll just break it down.
I mean, so Beth Jesus, kind of popular anonymous account on Twitter, you run something called
the EACC, which we'll get into in a bit or Yak doxxed by Forbes, Emily Baker White of Forbes,
in concert with Alex Conrad, which is an important part of this story because Alex,
it's important to me at least, and I want to talk about it with both of you guys in a minute,
because Alex is so influential in tech.
I mean, he runs the Midas list.
Everybody knows him.
Everybody talks to him.
And that is a problem.
And, and I do want to get into it.
But long story short, these guys hit you up or Emily hits you up and she's got your,
she's got your real identity.
So you've been writing anonymously about EACC for what about a couple of years at this point,
when this happens, have a little bit of a community.
I would say I'm going to kind of characterize what I think you guys do.
And then you can come in here and give me the real version according to you.
I think you guys were memeing about the future and you're definitely counterpointing the EA stuff.
You're sort of like cleverly cutting against the doomer narrative in a fun way.
I've always seen it as very like lighthearted.
I've noticed this week, the EA crowd has been very personally aggrieved by you.
And it gave me a giant question mark then.
I was like, why is, why is the media gone to, to war against you?
I have a few theories.
I'd love to hear apology, your theory especially, because I'm sure you have one at this point.
Sure.
Your link Gill to Mark Andreessen and Gary Tan specifically seems to me
like the reason that you became something that needed to be destroyed and shamed.
So that's my version of events.
You know, EACC born, you represented.
It's a positive, futurist, anti-doomer, pro-progress, pro-AI specifically kind of movement.
You are, they think sass needed obviously doesn't work out that way for them.
You're much more popular now.
Hans to talk about what first things first, like what is your version of those events?
Yeah.
I mean, for me, it was, it was a crazy Friday and it's been a crazy couple of days since then.
I'm like halfway across the world right now and undisclosed location that is not China.
And, you know, on a business trip.
So I'm still, you know, doing, doing what I do.
I'm entrepreneur.
Yeah.
Originally, basically I get a text from like investors.
So, so first of all, I, you know, I came, you know, as, as I was doxed, you know, I came from
Google X, you know, I worked on projects with the leadership there very closely, you know,
very secretive projects.
I was used to sort of secrecy as my baseline.
And to some extent, like spending years, see, super secretive.
You can't talk about what you do and so on.
It's kind of a burden.
And that's originally how I started.
Beth Jesus was just like, as an outlet for me to communicate with people about stuff and just talk.
And, you know, I've kept that, that account since then.
But, you know, I had a startup as well that was not doxed.
Like these, they not only doxed the correlation between my principal identity and Beth Jesus,
but they correlated my principal identity, my current company, and even they traced through,
you know, name changes of the company.
They even like went through my Facebook.
They went, the voice docs me, they just correlated everything.
It was like a full, like, you know, full definition.
When they punched your identity, it was like something out of a spy movie.
They went in on you.
They really threw resources at this.
Yeah.
Like, I mean, for me, you know, like, I think like, you know, I believe what I, I believe
large majority of what I say is Beth, sometimes it's kind of like, you know,
meta-ironic, you know, extreme posts as one does on Twitter.
But like most of it, you know, like I'm all in, like I don't mind like,
you know, backing, you know, using my main identity back, what I say with,
what I have said with Beth.
But to me, it was like, hey, I didn't give you the right to disclose like that I'm doing
this like deep deck startup as well.
You know, I mean, some technologies.
Have the right there.
This is a thing.
It's like, this is the whole thing for me watching this is, this is,
this is not the first time that the press has done this.
This happens often.
And it's, it's, this question of rights comes up.
It's like, we can do this, they say.
It's like, yes, you can.
But the question is like, is it ethical?
What kind of world do you want to live in?
And obviously from where I'm sitting, it just seems the purpose of revealing your identity
is to scare other people who are sharing their opinions in this space,
anonymously from doing so.
They, it's a, it's a, it's a, it is a strategy to chill speech.
I don't have to worry about speaking for the most part within reason.
It's way easier for me.
I don't run a tech company in stealth.
I work for Peter Teal at Founders Fund.
And on the pirate wire side, I run my own business.
It's like there, I am, and the business is speaking.
It's like, it's, it's easier for me to do it.
For someone like you, it's harder.
They know that.
And the point is they want to kind of take you off the map.
Apology.
Why do you think, I mean, do you have any, you can take this anywhere you want.
Obviously you might have something you want to share in particular,
but I would really love to know kind of like what you think,
what you think the motivation behind this specific targeting was.
So, my views on this have somewhat evolved.
Fundamentally, the journalists are, are tribe and they're a sub tribe nowadays of
the overall, you know, whether you call it the regime, the paper belt, the cathedral,
the establishment, the deep state, what have you, that is a set of people.
And it is a group of people that is, you know, FUBU,
you guys remember FUBU from the nineties for us bias.
Okay.
So, like the regime is nationalist for the regime.
You know, it's like to first order, you could say it's Democrats,
you could say it's deep state, you could say a cathedral.
There's like a lot of different names for this, which are all overlapping.
But basically, if you take the whole social network of, you know,
eight billion people in the world and 300 million Americans and so on and so forth,
this is a sub graph in the social network that's densely connected.
And it's sure unless it's professors, it's regulators, it's bureaucrats and so on and so
forth. And everybody who is not them is an enemy.
And that means that they're at simultaneous war with tech, with Trump, with China, with Russia,
with India, with Israel, like, and you can, some of these there are more at war with than others,
right? They don't like India very much, but they're like somewhat fighting it.
They don't like Israel very much, and they've got some outlet, right?
But basically, once you look at it as a giant social network in different colors of subgraphs,
the journalist, you know, like blue subgraph is at war with within America,
the red subgraph and the gray or tech subgraph, right? And so that's like the first order,
like visual of the whole battle space. It's not, this is not like a discussion.
This is not like a normal story. This is information warfare of one tribe versus another.
This is meant to harm you. And even if this first one is just like a tracer bullet,
or like a flare to sort of light up the position, right, then subsequent kinds of things may or may
not be so positive or would have, right? And so that's like first is basically, it's not a,
it's not a positive thing to go and dock somebody against their will. You do not do that to a friend,
right? You do not do that to somebody who you mean well to. You don't stalk them for months.
And, you know, basically in your, in your, and you know, correct me if I'm wrong, Guillaume,
but they basically gave you, you know, they told you they had all this dirt on you and they're like,
well, you better speak with us or else, right? Yeah. Yeah. Yeah. Like I got a text from investors
the night before from, I think it was Alex Conrad told investors like, oh, hey, I correlated
Beth J. Zos and Guillaume. I think he's a portfolio company. They had the old name of my startup. So
I changed the name of my startup for further upsec and for branding eventually. But the,
they hadn't put it all together. And then they censor fused across reporters, like, and then they
had much more, they had too much put together and they wanted to, they were going to put it out,
right? And then so the morning I was like, look, this is going to come out. You have a chance to
give a comment. Like it's, it's happening, whether you like it or not. And for me, I had like two
things. One of them was like, okay, well, how do I, I just went in damage control, right? Like,
I mean, I've, I'm building stuff that I really believe in. I've been wanting to build this for
like eight years. I've been like super stealthy about it for all sorts of reasons for security
reasons, for, you know, IP reasons and so on. And, you know, everything was at risk, right? Not only
the movement, the yak movement and hope, well, hopefully the movement is not at risk, but it's
supposed to be anti fragile. We're trying to make it so, but and, and my company. So I went in damage
control mode. And I didn't want to talk to them, but then they were like, look, this is going to
really come out. I'm like, all right, well, I better try to control the narrative, at least for the
first, for this first thing, because I'm sure they're going to pile on now. The media is definitely
going to pile up from here on. I mean, I can I've entered an exhibit, let it let it be entered
into the record, exhibit a okay, this is from datajournalism.com. Okay, by one of the wokest wokes
to ever woke. One of the three heads, one of the heads on the three headed dragon, I would say.
Yeah, exactly. I mean, it's a multi had the thing is every one of these critters, like basically
is essentially a Stasi officer. That's what these, these folks are. So they actually have
a whole article at datajournalism.com. And what this is actually titled, if you I'm sure if you
paste this into chat, GPT or whatever and ask it to paraphrase it is how to docs. Okay, investigating
social, go ahead. No, I'm just shocked. I'm, I shouldn't be shocked, but I I've never seen it
this explicit. It's this explicit, right? All of their stuff. That's why I read all of their, you
know, or go ahead. Brandy works for I think NBC, right? This works. That's right. Here we go.
This is these are, these are major significant journalists who are,
Yes, that's right. And they teach how to docs, how to, there's other articles on how to
essentially assassinate, except they don't assassinate the character assassinate, right?
And it's all so, you know, once in a while, they'll actually admit it when they're talking
to each other and they put on a different face, right? So here it's like, you know,
be prepared to read thousands of tweets, click until the end of the Google results and dive down
to social media rabbit hole. If you want to collect the tiny biographical clues, they'll help you
answer the question, who is this? Okay, so, you know, I mean, whatever you can read this if you
want. The useful thing about reading articles like that is it tells us as technologists how to
build a privacy countermeasures against these people who are literally like a like a for-profit
intelligence agency. And I don't even say that lightly. How did they get your identity, GV,
right? They, they went and used like some CIA voice recognition thing.
Straight up. I mean, that, I guess that's, that makes it, that makes me a bit more badass that
they had to do that. I don't think it was necessarily that hard, but I thought there was a
sort of like ethical protection, like the way like, I'm not doing anything illegal. I'm literally just
arguing for free speech. Hey guys, thanks for listening to the Pirate Wires pod. Make sure
you like, subscribe, comment below and share this with your friends. I have failed. Honestly,
that was one of the big things I thought while I was watching this go down, I thought like, have we
not, and biology, you two, we both, you failed, you know, like, how do you, I don't know why you're
talking to them. Like that's what I'm thinking. I'm like, how do you, we've been talking about this
for years. Like they are not all of them. And maybe, I'll just, I maybe disagree a little bit
something. I think there's some good things out there. It's very clear in my opinion who are not,
and it's very clear usually by their approach, like that was not a friendly approach. That's a
hostile, at that point, you're a war. And what you, what you do, and this is for people listening
now who are maybe anonymous online, and they don't know what to do if this comes and happens to them,
you ask for help from people like us who are, who are able to be back with media who can defend
you. Like that, that is the very, who really separate from defense publicly is like, like advice,
because by participating, you, first of all, they're using that against you. They're saying,
oh, he participated. It wasn't against his will or whatever. And it's very clear from the emails
that you've shared with me, and the private messages that they sent, you know, to other people
and things like that's not obviously not the case. It was clear just reading the piece that
wasn't the case, but I can confirm here officially that that is not the case. You were definitely
not forced to participate, but you were going to be doxxed, whether or not you liked it.
But had you not participated, they wouldn't have had that weapon to use against you.
And they wouldn't have had much to talk about, because you, they also had not, yes, they were,
they had, they used their CI voice recognition. They really, really thought it was you, you know,
mathematically, whatever seemed like almost certain, but you had not actually confirmed it.
So they would have had a story where it was like, we are very, very certain, but we don't know for
sure. And also, he is sort of associated with this guy who we're telling the world is a Nazi.
And that would have been so ludicrous that, I mean, we would have just gone, the whole internet
would have exploded and been furious. And they would have been beaten back. Like,
you kind of gave them a little bit, a little bit too much in the future. I mean, I wonder what
Bolliger's advice is, but I'm like, you give them nothing. And you then concoct, you doxx yourself
at that point, possibly, to take away the story. Like, I don't know, Bolliger, what would the advice
have been you think in that situation? Well, so one thing is, I usually don't even repeat their
charges, because they throw around, everybody's, you know, everybody's a Nazi, like they'll call
anybody an everybody a Nazi, right? So I don't even give any credence to their charges, right?
But setting that aside, yeah, I mean, so I mean, here's the thing, I like,
how do I think about it? You're playing, you guys are really video games?
Yeah, not enough to this reference, but let's just do it. So there's like, you know, there's
various video games where they're like, you know, first person shooters or something like that.
And new guys just keep beaming into the arena. Oh, right. They have no context on what just
happened and where the, you know, shells are flying overhead and so on. And that's how I think about
the new guys who, you know, maybe they're heads down, maybe maybe they were just like in a different
part of the battlefield, they don't have context and they're, you know, beaming into the arena.
And it's a good analogy, I think, right? Where it's like, you know, they're on our team,
they just beamed in, but they, you know, they may not know all the battle tactics or whatever,
right? So it's actually incumbent upon us as I hate, at least, you know,
Solana, I'm not sure what the convention is, but I guess I've become a little bit of an elder.
God help me. God help us all. You're seeing your in school.
Yeah, it happens really fast. The gray comes really, really, really fast. I'll tell you that.
Okay. But it is incumbent upon us to literally compact this stuff down into monthras that people
repeat. And you assume it's almost like college where there's like a new class and it's obsolete
in two years or three years. And you have to like say it again and update it, right?
So that's, that's one part of it. Let me pause there and get your thoughts.
Well, I mean, I agree. I really, like I said, at the top of this little piece here, I felt
bad guilt. I felt like I had not done a good enough. It's loud as I have been on this issue.
It's awesome. I've written about it as much as I've tweeted about it. I feel like somehow that
message, it's like, do people think I'm kidding around? Do they think that I mean, this is
in information war? And I again, I do believe there are good actors out there. There are
so many nefarious actors. This for me, the Alex Conrad piece is really crazy because so many people
treat him like a reasonable reporter in tech. And this action for me is beyond the pale.
Not only the way he went after you, but the way he tried to go after Gary and Mark through you
is, I think, really nefarious. And I'm like frustrated that people aren't as upset about
that piece as I am. But yeah, I know I agree. I think we do have a little bit of a better job
reaching out in these moments. And I don't know, it's like, do I, I just hope that people know
that they can hit up people like us for advice in these situations? There are a lot of great people
online. Lulu is another great person to Lulu. Messervie is a great person to talk to on this
kind of stuff. I was saying, I wrote a piece about this. And in it towards the end, I get to the
point where it's like, you actually, and this is what I really would love to talk about, things
have changed. Yeah, there are a lot of people who are great online talking with big audiences.
And it's not just like they're anonymous people, there are pseudonymous, pseudonymous, I cannot
ever pronounce it, semi anonymous people. There are CEOs, big, huge, popular public CEOs who are
posting, and they are all just like a DM away. And you can see on Twitter, you can see who's
connected to who, like if you don't know them directly, you want some advice, you talk to
anyone, it's pretty cool. The vibe has shifted somewhat. And I was just watching the Reagan
National Defense Forum. This is like the Super Bowl for defense forums. You have, first of all,
last week you had Elon Musk telling the advertisers to go fuck themselves
on the stage of the New York Times. Then this weekend at the Reagan Forum,
you have Palmer Lucky sort of telling kids not to follow their stupid dreams. If they're, you know,
contra reason and self-defeating or not good for society. It was like a very sort of anti,
I don't know, mainstream message. It was strange to see him up there being so honest and
unapologetic. And Palmer, someone specifically who just lays down his opinion every day and
does not give a fuck and has really gone direct in that way with his own message about his own
company, which is killing it, by the way. Onderal. Then you have Alex Karp, who just espouses like
an incredibly anti-woke message openly on stage and is like, I'm not hiring people who are idiots
on the following topics, all of which would have been considered beyond the pale just three years
ago, would have been articles in the New York Times about, you know, the terrifying menace of Alex
Karp. But I am running one of the coolest companies in the world. And I'm telling young people,
you are breathing the vapors of a dangerous, new, fake and self-destructive religion when you are
sitting at your elite school pretending because you watched TikTok twice and got an A plus on some
crazy paper because your professor couldn't get a job anywhere else that you actually understand
the world. And you're not welcome at my company. I think things are different now. I don't know,
what do you got? Am I right? Am I wrong? Am I just naive, optimistic, too hopeful?
Well, yeah, I mean, so, you know, Solana, you and I, again, we're like literally grizzled combat
veterans at this point, 10, 10 years in the meme wars, right? Yeah. And last five is really,
I think, where most of the action took place. That's right. That's right. So basically,
you know, tech versus media, you know, I kind of, all right, I'm just going to rattle off the history
here. And then I'll be turning this into a blog post and so on and so forth with the rules and
the history and then the history history, the deep history, right? But very roughly, tech kind of
arguably, you can argue when tech exists as a culture, but maybe you date it to
95 with the graphical web browser, okay? And then from 95 till, you know, 2008 or so,
because of the dot com crash, media didn't even really take tech seriously. They're just like
gadget guys or what have you just doing their stuff on the West Coast and they were considered
basically an auxiliary of the Democrat Party, like you had, you know, unions and you had this group
and that group and then there were Steve Jobs and the tech guys making gadgets over there in the
corner over there. And media concerned themselves with their expense accounts and the rock and all
this other stuff going up into 2008. There's even this article at that time, I think by Joel Stein,
that's enumerating like the power centers of the USA and it's real time capsule from 2008,
because you know it's not on there. What's on there is a Pentagon and Wall Street and so on.
You know it's not on there. In 98? 2008. 2008, what's, oh, social media. Silicon Valley is not on
there as a power center in 2008. At all. At all. Yeah, that is, the phrase big tech had not even
been innovated at that point. Exactly. This whole system that we're in is so much more recent than
people think because what happened was after 2008, after the financial crisis,
tech revenues went vertical. Okay. There's a great graphic that shows what happened. All right.
Bam. Okay. The hate is Kazanus. What is this graph? This is showing print media revenue top set at
$67 billion in year 2000. Then it's like down after the dotcom crash, but it's flat ish.
And then a complete collapse down to like $16 billion in like 400 years. This is advertising
revenue in newspapers. Advertising revenue in newspapers is a blue line, right? And then
including digital, digital doesn't save them, doesn't come on fast enough. And Google eats their
lunch and then Facebook eats their lunch. That's a green line over here. Google is the red line.
All right. So basically it's one thing to, you know, see your neighbor become like a billionaire.
It's quite another thing for them to become a billionaire while you become
a thousandaire or whatever. Right. Okay. And so these guys essentially over the first four years
of the Obama administration saw these tech guys who had been in, you know, a box or whatever,
they didn't think of as anything, suddenly rock it up ridiculously fast. And because that was the
iPhone and that was the reallocation of budgets after the financial crisis to online ads,
which are finally mature and converting. That was the fact that like SaaS was starting to work.
Y Combinator actually, you know, remember Y Combinator started in 2005, that whole modern
seed era of things only really started working in the late 2000s. There are a bunch of great
companies found around that time, Stripe, Airbnb, Uber, all of that basically by 2013,
after Obama got reelected, even in 2012, by the way, do you guys remember in 2012,
the nerds go marching in? How a dream team of engineers from Facebook, Twitter and Google
built the software that drove Barack Obama's re-election. Okay, when the nerds go marching in.
You see that? Yeah, I remember that narrative of the Obama being the first sort of internet
president. He had this team around him from tech basically. That's right. Not fully believing it,
but. Well, and the reason for that is because, you know, Facebook and then Twitter started in
very blue zones in the Harvard area and in San Francisco. And so it was assumed that technology
was blue and blue was tech and that it was just good and that if it had any effect on politics,
it would be to overthrow oppressive regimes and overthrow, you know, cause the Arab Spring. Go
ahead. Right. That was just assumed until Arab Spring, which they thought was great. We don't
hear much about the sort of consequences of that today. A lot of disasters, a lot of people
dead unfortunately, right? So we can come back to that point, but basically what happened then
from 2012 to 2016, a bunch of things happened. First is all these conservatives started getting
Android phones. Okay. And there's a really interesting sort of meme that makes this
concrete. If you're seeing, and this is kind of late 2010s, starting to get a little obsolete or
whatever, right? But there's a, there's a collage of a bunch of Democrat visages and a bunch of
Republican visages on Twitter. So Democrat visages are guys with glasses indoors and like,
you know, kind of unshaven or whatever, right? They're like unshaven programmer, graphic designer,
Yasqueen types or whatever, you know, the guys pointing at the thing, right? Okay. And
but the Republicans are more interesting or this is like, it's an interesting different kind of
visage. They're people with sunglasses in trucks outdoors, taking selfies on their phone.
So the fundamental difference is the Democrats are indoors and Republicans are outdoors.
Because almost all the Republicans are in sunglasses and they're clearly on the go,
with some like cheapo Android phone. So part of what happened from 2012 to 2016 is the
polls got online and that started shifting Twitter and the internet to the right. The
other thing that happened is after Obama got reelected in 2012, the media, which had played
nice with tech guys because they needed them to get Obama to get reelected, now had four years to
settle scores. And all the knives came out and all the valleywag type stuff happened around that time.
Would you just look at all those rich people? That's valleywags editorial vision in nutshell,
but could be so much more by Monju, who's become a full communist now and radicalized, right?
But that was like 10 years ago when he was ostensibly central left, he was complaining about
attacking them as rich people and so on and so forth. That's crazy. I remember people being mad
about that. But in my mind, I remember Dave Moore and complaining about this, which made sense
because he was being attacked. I don't remember the press rising to the defense of those guys.
That's interesting. That's right. So basically a few years later, he's all abolished billionaires.
It's literally he's writing that. Okay. The radicalization happened to the journals.
Okay. And essentially, though, it was a boxer's clinch where that tech and media alliance didn't
make sense anymore because the media guys were like, wait a second, these tech guys aren't just
like some vote bank gadget bank, whatever that's making the the bejeweled toaster on my desk that
is an iMac, they're coming for everything. Yeah. And then toothless really. I mean, it was
Gawker is destroyed. Yeah. That was that comes that comes a little bit later. But yes, that's
right. That's right. Of course, it's an important episode. And then trouble wins the election. And
at that point, it's worse. That's right. But crucially, the negative coverage starts in 2013.
In 2012, you can even find them writing articles like there's no such thing as a brogram or and
so on. Right. So this goes back to that visual I had of the blue tribe, right, red tribe,
gray tribe, if you're part of the tribe, you get friendly coverage. If you are not part of the tribe,
it's information warfare. Yeah. Right. And now that can mean by the way, you can be part of the
tribe and then kicked out of the tribe or you can choose to leave like Glenn Greenwald has,
you know, he was he was like, he had all the prizes. That's why I give him a lot. I don't
agree with Glenn on every issue. But I respect him because he had all the prizes within blue and
decided to kind of go and do his own thing and stand for a principle that he stood for. Right.
Conversely, it is also possible for someone to be kind of a renegade,
but then to become incorporated into blue and to be part of this Borg, right. Like Google,
early Google was much more buccaneering and swashbuckling and so on than what's become,
which it's not as blue as it was like a few years ago, maybe, but it's pretty blue, right.
So so once you kind of have that visual, it's really the, you know, that's the friend enemy
of the tribal distinction. And it's not exactly left, right, or what have you. It is group non-group.
Let me pause there. I've got a lot more. Well, I want to, I mean, I have a slight pushback,
which is that I agree with, I mean, the whole history, I think is correct and insightful,
especially the piece on the revenue is really important. It's, you know, we, I think I maybe
get somewhat distracted sometimes by the ideological combat component of all this. It just very
clearly feels to me like a classic information war and maybe not classic. It's not classic. It's
new. It's a new kind of, it's a very scaled up information war. It's live. It happens every
day. It lives in our pocket. It never ends. But at the end of the day, like we are, and this is a
point that is, you know, I've heard before I just forget, it's like we're in cop, we're competitive.
We're competitive. There's a business piece that's competitive, like just hot, like industries are
competing. And then online, that I think the new thing that we've seen over the past few years,
and let's just focus on tech for a moment, is we're not just, it's not just a money issue. Like
it's an actual, the all in pod is a massive success. And that is, you know, a side project for David
Sacks. And that would be a dream come true for every single person in media. So it's not like the
platforms are taking the money. It's like the people on the platforms are also taking the
attention from them. They're not even, they don't even get to be the attention people anymore.
Or not exclusively, there's combat, there's competition there. So separate from the ideological
piece, there's just, there's the reality of just competition. And when you're in it with someone
for something that you consider your life. So it's, it's funny you say this, because, you know,
now again, this feels like an ancient, actually, GV, I want you to jump in because we were just
chatting. So, did you want to say something or? Yeah, yeah, there's kind of the broader,
there's the broader informational war between tech and, and, you know, the paper built
aligned media. But, you know, the media, they're kind of the pit bull for, for some of the,
the paper belt against, you know, whoever in tech is an enemy of whoever is like helping place
various stories. You know, to me, it's been like, I've been trying to like figure out like trying
to back propagate, why did this happen to me? Like, where did I cross the threshold of becoming
enough of a problem that they needed to have leverage over me and expose me? And, I mean,
obviously, you know, Mark and Gary have been supportive of the movement, you know, for all
sorts of reasons, one of which is like, obviously, we think that, you know, the current sort of
regulatory capture attempt by, you know, AI safety, the AI safety complex and some of the big incumbents,
you know, it's camouflage is like anti-doom, trying to, trying to save us, you know, trying
to, trying to save us from open source models, right? Their dual use and so on. And, you know,
we were calling that out and getting, getting people fired up, calling this out and it became a
problem. And of course, you know, Gary tweeted this that, you know, FTC chair, Lena Khan,
was invited to YC, you know, and I was there and we had a little chat.
And, you know, I've voiced, I've voiced our concern of our, the concerns of our community,
that like, hey, actually, this is, this is, you know, kind of some of the big incumbents kind of
covering up the fact that they're trying to capture the market with sort of like, oh, this is for
your own, your own safety. And that's when I became like officially a political problem, right? And,
you know, there's all sorts of interests in the background, you know, trying to pull strings
here. You know, I have some hypotheses, maybe I won't go into like exactly who I think is pulling
the strings. I have my, I have my thoughts on that. But what, what's been public is that, you
know, Secretary Ramondo, I believe, called out EX specifically as like a dangerous movement and
something we should suppress with AI. They want to, like our movement is about free speech,
freedom of compute, freedom of AI and not like top down oppression aided with AI. And they're
literally proposing shutting us down with AI, which proves our point, which is kind of like,
by the way, by the way, you know, that's like, it's like, well, nobody rid me of this meddlesome
priest kind of thing, right? Well, no one rid me of this meddlesome EAC, right? Like EAC is a problem.
And that's like a decentralized signal to the journals to go in, you know, right? It's stochastic
journalism. Yes. Come on, that's pretty good. Right? No, I agree. Yeah, you're holding up the
target. This is where I'm trying to think of what the illusion to stochastic terrorism. Okay,
I thought it was funny. Stochastic journalism, stochastic terrorism. Okay, I want to talk about
it was funny. I want to talk about EAC. You were just getting into it. I mean, what
this is a little bit off topic, and we can, you know, revisit any of the stuff that we just talked
about, there's a ton there on the war piece. But this, you know, it's dangerous and whatnot.
What is EAC? How would you even describe it?
What is EAC? I think for me, it's kind of like a cultural framework, really, or a
medical cultural framework. We're trying to understand, where's this whole thing going?
Where's civilization going, you know, from first principles? At the end of the day,
the only laws are the laws of physics. And I'm a former theoretical physicist, and, you know,
I do physics based AI now. You know, I always think about physics. And nowadays, I think about
self organizing systems. And, you know, to me, it was just an exercise in writing and trying to
understand where it's all going. And rather than have like, like completely, like,
unanchored to reality sort of theories, like, like the doomers do of like, AI taking over,
as soon as it reaches human level AI, it takes over and fooms and takes over the planet. Like,
I've been trying to actually find like, where's this thing going? It's like, okay, well,
you know, civilization at the end of the day is a system that's like alive. All systems that are
alive, or that are basically life from a physics standpoint, seek to grow, they acquire energy
to maintain their sort of state, and they seek to grow and increase their ability to acquire
free energy. It's like, okay, well, civilization wants to go up the what is called the Kardashev
scale. So it is the scale of energy production or consumption. And so that's where we're going,
you know, and that's where the system wants to go. And, you know, it keeps morphing itself,
it, you know, searches over the space of technologies, of cultures, of memes, of
genetics, of everything, in order to ascend this scale. And, you know, basically, it's like,
we're just pointing that out. And to us, like, like, it's first a framework of like, what is,
and, you know, that's what's going on. And then it's like, how should you live your life,
given this fact? It's like, well, actually, if you help the growth of civilization,
you know, you will likely prosper. And it's kind of a self fulfilling prophecy. If you're
optimistic about the future, you work on hard things, right, because you believe in a better
future. So you want to contribute it to it so that you own a piece of it. And, and then you go out
and build and do hard things. And then the good future happens. Whereas if like you believe in
doom, and nothing good is going to happen, you know, a longer build, you don't longer want to
have kids, you don't bet on the future. And then the future is actually worse. Right. And to us,
it was a sort of reaction to the pervasive demerism, and the the person pervasive pessimism,
tech pessimism, that was just dominating the news cycles. And we were like, can we have a viral,
optimism movement that, you know, hyperstitiously induces growth of civilization, right? Don't
we all want that? Don't we all want to be, you know, amongst the stars?
It's more no, that's the thing. No, that's actually, I mean, for us, us three, yes. But
that's actually like a core. Yeah, it's not different. It's, yeah.
Acke, obviously ACC, we're talking about acceleration is the word that you're using. It's
EA, you're making a play on effective altruism. The effective altruists are very concerned with
accidentally building a god that kills us, really, is like where their heads at. And they,
not just they, now you have the safetyists in the media who have, they want to slow down tech
for all sorts of reasons. But their position, all of them in this sort of uneasy alliance between
very smart people in AI who happen to be EA-pilled and a little bit of a doomer, and the press,
and, you know, the government that wants to slow all this shit down. It's, it is that it's slowing
things down. Endlessly in the process, especially you hear, you know, Mark Zuckerberg said, move
fast and break things. And then things broke. We have to move more slowly. And you're not saying
that you're saying we need to accelerate. So the positive vision is there. It's awesome. And I
thank you for your service, sir. It is very important. The memes are excellent. And I think,
I agree, they are powerful. I think they're motivating. I think they are helpful. But they
identified correctly your critique of them. And, and so that is, you know, you're, you're locked
in a sort of at that point, it's, if people hate you a lot, and I mean, I've seen it. Why,
how much they hated you until this week? They're definitely mad. Can I make, can I make a couple
points there? Yeah. So there are decelerationists. And there's also what the current US establishment
is, which are stagnationists, right? What they want to do is they're in their own way, conservatives,
where they want to freeze the world in amber. And so you will find, for example,
that, you know, for example, Raimondo is talking about the tariffs and so on and export controls.
And they want to kind of freeze China as a power. And actually, I can understand that. Okay.
But, and so they're like, Oh, you know, the US needs to be a leader in AI. So we're going to ban
exports in there. And then literally, you know, that's what they're saying on Mondays and Thursdays.
And then on Tuesdays and Fridays, they're doing AI bans in the US and saying, you need to slow down
and not accelerate and so on and so forth, right? So they want to kind of think they think they can
be a policy lovers, which, you know, they're not Silicon Valley, they're not Shenzhen,
you know, they're neither of these things. But Washington DC thinks they can freeze the current
dispensation in amber, where they've got a healthy lead, and nobody abroad, and nobody at home goes
too fast. And nobody, they just want to stop the disruption. Because that's the thing. Acceleration
is good for lots of people, but it's not good for them.
It's not good for power, any technological innovation, I think, pretty much.
Well, so that's the thing. So I've got it. I've got a perspective on this being out here in Asia,
right? And India loves tech. India loves tech. And the reason Indians love tech is, you know,
you've got a guy who was on a, you know, like a very poor 10 years ago, who's now got an Android
phone, and they've got a lifeline to the world, and they're able to study and they can earn and
all this stuff. So it is correlated with the massive improvement in their living standards,
right? But for the journals, and more generally, the US establishment, you saw that graph, it's
correlated with a massive decrease in their living standards. So they have a learned correlation
where the faster the tech grows, the less money they have, the less power they have,
which is kind of true for, you know, it would be extremely painful for you, right? Acceleration
is extremely painful for them, right? And so that's why they're fighting the internet,
and they're fighting every force that's against them, in actually a conservative way.
Always feels like this. And then in this case, you're talking about generative, obviously,
as many things, but the thing that the most attention at this point is are the generative
models when you're talking about like language specifically, this is something that it looks
like a journalist that knows the true NPC level. It's literally the thing is, you know, this guy,
I got to get this guy to put this project back up, which, you know, I used to say,
not even jokingly that these journalists, you know, there are just like a sports article,
it's a wrapper around a box score, you know, box score is like the, you know, how many rebounds,
how many says steals, whatever, in a basketball game, or a financial article, it's a wrapper around
a ticker, like, you know, stocks were up on heavy trading, blah, blah, blah, it's just like a verbal
narrative. I used to say that these articles are just wrappers around tweets, you give it three
tweets, and you can write the article. And I used to say that as a joke, you can go find,
not even as joke, it's like true and also a joke, right? From like years before chat,
GPT. And then when it came out, it became literally true, where you could paste in a few
articles, like a single tweet into this thing that, you know, like a New York Times article
generator, and that's probably gotten even better a year later, and generate an entire full NYT
article that's like dark times ahead in technology as acceleration continues, you know, like you
could literally do that, right? And there's no intelligence, it's totally paint by numbers,
you just have the stylistic kind of thing off the prompt, go, go, go.
Yeah, yeah, I think like the thing, the thing that's scary, right? It's kind of like the old
world media, they serve the incumbents, they serve those that have interest in top down,
sort of control, they like to like, they gain proxy power by being instrumental to
authoritarians, right? And those that argue for more control. And IAC is about, like,
saying that acceleration, techno capital acceleration is a positive force, it creates
amazing technologies, it gives us wealth. And, you know, the counter argument to it is that,
well, if we, if we don't control who and who ends up in power, that's, that's bad, you know,
really what they're thinking is like, we might lose power. And so that is bad. But the reality is,
like, the system would adapt and powers would shift to, you know, those that are disrupting
the incumbents, right? And that's good. That's how the system, you know, optimizes itself and finds,
you know, whichever technologies are most beneficial to the world and helps them scale
up. And of course, those that are the produce those technologies get to have sort of more
power to allocate capital and control where it goes, right? Which is the sort of natural
meritocracy. And they're trying to break that they're trying to maintain the sort of status quo.
They are the real conservatives, they call themselves maybe progressives in some cases,
but they're really just trying to conserve the powers that be. And then the media, they're just
mouthpieces for the incumbents. Because again, like, you know, those are the only people that
still talk to them. And they use it like, you know, they use them as the media is kind of like
an information warfare arm of like, you know, the incumbents and the pre-rebuilt, right? And we've
seen that. Like, and the label, you know, go ahead. I worry a little bit. And I want to get both of
you take on this. Unless you want to jump in a little bit, which is, you know, there's more I
can say on kind of the history of this and so on. But there's a huge difference as to where we are in
2023 versus where we are in 2019, 2020, 2021. And I think, Solana, you did your part. I think I did
my own little part. We did our part, which go ahead, shakes, no handshakes. That was no handshakes,
please. Exactly. Remember that? Yeah. Essentially, what happened was, starting in 2013, let me just
recap the history that began and bring us to the present day. From 2013 to roughly, you know, 2020,
the journals essentially began a reign of terror against tech, where there was all manner of
cancellation. We didn't have the word for it then, against people large and small. That's why the
homeless problem, which is not really a homeless problem, but a drug and mental illness problem is
Sanjana Friedman, one of your, you have many talented writers, particularly talented writers,
Sanjana Salute. Yes, she's good. All right. Is it she? She, yeah. Okay. Okay. Sorry. I didn't know
what the, you know, what the, uh, we gotta be careful. Nameless. So, um, Sanjana Friedman has done
a phenomenal job on documenting how the like the homeless problem, it's not just a homeless problem,
it's a drug and mental illness problem. The point is, in the early 2010s, when something could have
been done about it, there were a few tech guys who made in-politic comments about, you know, the
sudden epidemic of needles and syringes and poop. This guy, Greg Gottman, another guy, Peter Shee,
and yeah, maybe they posted in like, you know, maybe you might not use exactly that language,
but obviously they're, you know, it's, it's, it's a lot less offensive than some crazy guy
throwing feces at you in the street, right? And, and more importantly than the NGO who's
feeding him drugs and getting paid by the city to do so, right? They mean things about the people
who were chasing you down the block. Yeah, exactly. That's right. That's right. So, what happened was
the journals at that time. Not necessarily. It's like, that was tech people turned on them. Well,
well, but, but the reason was there's a bunch, if you go back and look, Peter Shee, Greg Gottman
got destroyed by the media at that time. And then people queued off of that as, oh, that's what I'm
supposed to, I'm supposed to yell at them, right? And so it became for years, it was incredibly
un-PC to even mention the problems that San Francisco was happening. So it was like disabling
the immune system during the period when it maybe could have done something more. And then this thing
just got completely out of control and it became what it is now. And these NGOs became totally
entrenched and so on. Many other kinds of things happened like that. That's just like one version,
example of it, where the journalists caused a giant problem and then only after it became
massive, then could it be acknowledged? It was interesting. I was nervous to write about local
politics and I forget that sometimes, but like when I first started seriously writing in like 2020,
I was nervous to touch the homeless issue and the drug issue. And I just thought like, this is,
this feels dangerous, people are going to come after me, I don't care, I got to do it.
And it doesn't feel that way now. It's a weird thing where I have, I always ask myself, is it
because they're so strong or because they become weaker? And I think it's both at the same time.
How they won, is that why they don't care anymore? Yeah, exactly. That's right. So I think it's both
where the left, the Democrats, the blues, whatever, have captured the state and so they've got the
budget. And so they sit in their parapets. And no matter what we see online, the money just
keeps flowing to these NGOs, they flow to them or whatever, right? So we can yell and they can lull
and then just go back to shipping syringes, right? But they have lost control of the network.
And, you know, thanks Elon and thanks to also sub stack and, you know, Coinbase taking a stand and
salon and a bunch of other people, they've lost control of the network enough, they're getting
crushed in soft power terms every single day. And that does also matter in terms of building
a parallel consensus over here. But it matters insofar as we can convert that energy into
parallel institutions. And so that's actually GV where you are, I think, obviously, you know,
talented and as soon as a meme maker and so on in your own right. But it's also fortunate that
this happened to you, it's not good that it happened to you, but it's fortunate to you in 2023,
when we have this whole ecosystem, right? So, you know, in the mid 2010s, what would happen is
some poor tech guy and it could be, you know, a very junior person or the most senior executive
would just get targeted and just torn limb from limb on Twitter, where it was such an
overwhelming advantage of forces for the bad guys that even somebody liking a tweet in their
defense would get pulverized for the like, right? And that means, do you think about like the, you
know, the eyeballs are just scouring Twitter for anybody who had the thought of defending somebody?
Okay. And so that was a level of, you know, control that they had over the platform and thus
over mines and the signals that were being sent. It was really, very ugly time. And a lot of people
killings, it would feel like you had like the James DeMore thing where he wasn't even posting
publicly, he was posting internally on a channel, he was at Google, right? Was that Google or Facebook?
Yeah, or like what happened to Tom Press and Werner at GitHub? Completely fake episode, okay?
You can look at this article called Facts Conveniently Withheld, okay? There's tons of these
kinds of things that happened in the 2010s where good people were just attacked and they had nobody
to defend them. And so then what happened though, steadily, gradually, year by year,
we built enough followers until there's a really interesting tipping point. So in 2020,
I funded this, there's a Niger, I made that public, there's a Nigerian guy who did this analysis,
tech journalism is less diverse than tech. Well, now of course, now we're in 2023,
so we know that DI, DIE is stupid, okay? And we can actually say that. Fine. But back then,
essentially, there was a huge to do made about how white tech, I'm not the kind of person who
believes white is an insult, they are. And yet they were far, far whiter than all of us, okay?
But here's the thing, you know, Solana, to your point, is when you go and look at the raw data
over here, you look at the raw spreadsheet, you see a very interesting phenomenon. And the interesting
phenomenon is that back in 2020, this is like three years ago, there are only a few journalists
who had more than like 100,000 followers on their own, it's like three or four, okay?
What you, what I, but lots of founders had way more than that. And I realized something, it was
like a lighting bill is like, wow, the journalists are not exceptional in their own right as
individuals, they're not like charismatic people who people want to listen to, they can only win if
they team up in groups behind brand names, and then attack the guy who stands out. That's, you
know, it's actually this remarkable thing when you start looking at, of course, followers aren't
everything and so on and so forth. But it was, it was remarkable what a difference there was,
where it was a hugely right shift to distribution of founder followings to journalists' followings.
And so then once Elon took over Twitter, and he stopped whatever algorithmic boosting,
artificial boosting those guys were getting. Yes. Well, that has been framed by journalists,
I've seen journalists talk about this on threads, as Elon is now boosting nefarious people. He's
not boosting, he's just, Twitter doesn't have enough people working to manage all this at this
point. They're just simply no longer boosting these kinds of people. For years, we wondered,
like, how is that random VC who says everything that they like, but has never made a successful
deal in his life, like the face of venture capital on Twitter, or like, why do these
people still so much engagement, they're being pumped in the trending topics by a team at Twitter
that was propping them up that no longer exists. And now Twitter moments, Twitter moments.
Do you guys remember Twitter moments? Yes, I asked almost, I think, and like every couple months,
I'd be like, take tear down this wall. Yeah. No, Twitter moments, people didn't know it by name,
because it wasn't like, like Google Maps, you go to maps.google.com, right? So Twitter moments
was not something that was publicly named, so people didn't know what it was. But it basically
is a thing where when you logged into Twitter, it would show you the trending news story of the day
that they had picked, and it would give you some prompting as to how you're supposed to think about
it. In a person you're supposed to attack. Yes, exactly. So some poor Shmo would basically have
the two minutes' hate of Orwell directed at them, right? Crazy, man. It was like the lottery that
surely jacks the story. The negative lottery. Oh, yeah, yeah, yeah, yeah, yes, yes, exactly, right?
So here's, here's basically the, now what we have is what we've done is we've flanked the,
the traditional legacy media from two directions, both ultra short-form content of tweets and
ultra long-form content of podcasts, where they're relatively weaker, you know, then they're, and
so, you know, it's obviously it's content, but it's also distribution channels. They didn't have
years and years and years of legacy distribution channels there. They're in the mezzanine,
right? And tech in general is about going, you know, to the extremes on, on some new channels,
like the office in the very small bits of content and very long, right? And so now, and then you
tweet out the podcast, right? Or in the podcast, you talk about the tweets, right? So we're flanking,
and of course, what Elon has done with the video stuff has made that even easier to do.
That said, by the way, I do think of Twitter, you know how like there's that famous, or at least
when famous, when I was a kid, Istanbul is Constantinople, it's Istanbul and Constantinople,
right? It switches hands back and forth because it's so strategic, its location, you know?
That's what Twitter is. Yeah. And it was, you know, free speech between the free speech party,
and then it switched hands and it became the regime's tool. And now it's back to Constantinople.
But I don't know where it's going to be in two or three years. They are attacking the heck out
of, out of, out of Elon. Go ahead. I think the next battleground is LLMs, right? At the end of
day, it's about information supply chain attacks, right? If the media is, you know, they have
absolute power over information flow, then they have extremely high soft power. We eroded
that power with technology within the age of social media. There's still bitter about that.
And now the media are trying to serve sort of incumbents or whoever, whichever authoritarians
are pulling the strings, they're trying to ensure that this complex that they're part of
maintains control over or gains control of the new information supply chain that's emerging,
that is LLMs, right? They want to be able to shape the cultural priors of the LLMs that shapes
how they speak. And if LLMs become like the new Google search on steroids, right, which they are,
poised to do, they're going to become a source of truth, right? And so that's why we need
decentralized AI. Exactly. I would say that, you know, this is the same battle over and over.
They're kind of like still bitter that they lost the social media battle, right? When they had like
sort of a sort of regime installed within Twitter and they have like soft control over Twitter,
you know, everything was fine. When Elon came in, bought Twitter and disrupted everything,
then they demonized him and, you know, they said that he's dangerous and whatnot when he's just
trying to ensure people have the freedom to speak. For the record, you know, like in the old regime,
my first Beth Jesus account got booted, right? I said that and I got locked out and I couldn't get
back in. So the original sub stack was from my original account because I said, you know, COVID
came from a lab, which it seems higher, you know, very high likelihood now, right?
Wild that the OG, Beth got canceled for COVID. Because I feel like at this point, journalists
look back on that a lot of people, I mean, anyone in the kind of in the one party state looks back on
COVID and really tries to pretend that it didn't happen. And the Soviet lab leak in
particular is is one, it's like that and Hunter Biden's laptop or the two things that they really
just will scream to your face that nobody was censored for, nobody was kicked off a platform
or no, it never happened. It was like, you're just making this up. And they have to do that because
those two examples are so incredibly damning. I've had a couple more honest journalists say,
you know, the Hunter Biden laptop one, for example, yes, it happened. But it's, you know,
it's just this one thing. Why does people, what do people keep talking about? It's like,
people keep talking about it because it's incredibly important that we were silenced
or that there was an attempt made in that way. And the lab leak for me is also right up there.
Just that we couldn't talk about this very obvious question, I would say that was worth asking.
There's, you know, in the background, there's cybernetic control of information propagation,
they're trying to control people's thoughts by by biasing what speech gets algorithmically amplified
or suppressed. It's pretty simple. I think that, you know, for, for COVID, you know,
as if we, there was points where we had lockdowns, it's like, look, you know, this was like the
authoritarians, they were like, give us a ton of control. We'll keep you safe. This thing is very
dangerous. We gave them a ton of control. It didn't help a lot. It didn't help at all, right?
It didn't help at all. It's total failure. It was actually the bottom up sort of, you know,
the technical capital machine is what saved us. It did all this biotech engineering that,
you know, helped help save some lives. And so at the end of the day, the lockdowns just didn't
work, right? Like we still, the thing is still spreading to this day. And so it's a failure
of this sort of narrative that if you give incumbents and those in power, more power, right,
for your own safety, like it violates the narrative that they'll do anything useful, right?
And so they want to suppress that story, fundamentally.
One quick thing on Twitter, I think, get back to the NY thing and ask you maybe an uncomfortable
question based on what you were just talking about. So on the Twitter thing, and the concept
of an opal piece, you know, it's changing hands back and forth, I would say one person who does
not get nearly enough credit for understanding that and acting, I think, morally in a sort of
righteous manner, is Jack Dorsey, who at the all like, first of all, founder of the company
was on the free speech side, things tilted in the other direction. And then we have confirmation,
we see, first of all, he said all this stuff publicly, he is the reason one of the key reasons
that Elon was brought in and then was able to do what he did. And I have no doubt that he
knew things would get crazy with Elon in the company and that things would change dramatically.
But my sense was, especially after Hunter Biden's laptop, Jack felt like, this is a power that is
too great for any one person, and it needs to switch hands, it needs to, it needs to,
it needs to recede. Now, speaking of power, as apology you were saying before, we don't know
where this will be in a couple of years, which is why I get nervous about things like community
notes existing, and the celebration over people who we don't like, being fact checked and things
like this by the platform that makes me nervous, but no power, I think more powerful maybe than
the AI piece. You guys are talking about, both of you now, decentralization. And apology,
you're saying, this is the thing that we need, I agree, because from where I'm sitting,
it looks like AI is a naturally centralizing technology. I am skeptical of people who think
that AI is the solution to all of our problems and we don't have to keep it,
you know, there's a super broad conversation here. On this topic specifically, I am nervous about the
amount of power that very few people have. I'm not worried about some runaway AI. I don't see a lot of
small players, you know, upstarts with powerful LLMs. I see the giant companies have these things,
and they have terrible track records on this question of speech in particular. And when I look
ahead, there is a very real possibility that the people who control this are the sensors,
and this things, you know, like you have a handful of these things that are shaping our reality,
who's writing those rules, it's certainly not me. And so these are central, they seem like
centralizing, not decentralizing technology. It's like, what is centralized to AI? I don't
see that, I don't really see that happening. I think that you can want that, but I don't know
that that is the natural mode. Yeah, I don't know. So, you know, I mean, I agree that in the current
paradigm with the sort of power efficiency and density of neural compute we have on GPUs, there's
a huge advantage to just building a football field supercomputer, scraping all the data over
of the internet and like training one big centralized model, but at some point that
sort of the advantages of doing that are sort of going to get eroded away and, you know, the big
incumbents hopefully can compete each other's margins out. And then there's going to be sort of
like an advantage to sort of decentralizing AI, bringing AI towards the data. We're still far
from there. For now, that's right. There's kind of like just a big advantage in just being a big
centralized player. And unfortunately, right, like I said, you know, LLMs are kind of the future
information, you know, highways, right, for people. It's much more natural to ask an LLM
that's human like to get information either from the internet or from your database and whatnot.
And if what LLMs are allowed to say is shaped by a few people in some in some room with like
enormous cultural and soft power, I think that's that's pretty dystopian. And it opens up,
you know, it's kind of turnkey authoritarianism, right? It's kind of like it's even more subversive
sort of form of censorship. And, you know, those that want to have that sort of power, of course,
you know, are going to push for, you know, AI to be centralized so that they can co-op these
organizations that have the monopoly or oligopoly. And they want to, you know, they want to form such
an oligopoly so that they have such power. And it's not disruptible by, by say up and coming
startups. And so, you know, that's why sort of like, you know, this executive order, they have
like compute caps, right? Like very close to what, you know, current big incumbents
amount of compute they threw into their models are, and they want to ban sort of open source models
or make them like a dual use technology that you need to report the government so that they,
you know, they'll have control over whoever pops up as a, as a big, you know, provider of LLMs.
And to me, that's really dystopian. I think the P probability of 1984 is superior to P AI doom
by a lot. And, you know, I still invite AI doomers to, you know, explain to me how they think like
AI is going to fume and take over, you know, as someone who's used AI in their career to,
you know, engineer matter and, and, and biologics and all sorts of stuff. Like,
I could tell you it's much harder than you think. Obviously, biology has a lot of experiences in
this area. It's much harder than they think. So they're kind of sci-fi scenarios are implausible,
but the thing is they're like those kind of cre, you know, the doomers that like talk about fume
and like all these crazy sci-fi scenarios, they're instrumental to those that seek power
and want to have this sort of soft power of shaping the cultural priors of the LLMs,
because then they'll shape the culture of the people and then they're going to be able to
control the people. And so, you know, I think there's this tech disruption and,
you know, chaos is a ladder and the existing incumbents are trying to secure power in this new
era, just like they kind of did by, you know, subverting and co-opting some of the social
media giants. And, you know, we don't want to have a Twitter situation, a pre-Elon Twitter
situation for LLMs again, right? We don't want that. And so, you know, the whole point of,
you know, of the AI policy part of EAC is to maintain freedom, maintain competitiveness
in the market, don't over-regulate it, that serves the incumbents, and that serves the
authoritarians ultimately. And we should have freedom of speech, freedom of thought, freedom
of compute. So, yeah. Apology on this question. Yeah. What is your, I mean, do you have some,
any concerns at all that you might share with the EA people? Like, could you?
Yeah, no. Well, see, the thing is that, you know, Twitter reduces the first bit is,
which tribe are you in? You know, are you this tribe? So, certainly I'm on the accelerationist
side of things in the 01. With that said, you know, when you add a second bit is,
is there a real chance of a superintelligence? I absolutely do think there is. And the reason
for that is, what most people have seen at, you know, over the last year is, let's call it chat
GPT style AI, right, which is generative AI, where there's a human in the loop, you know,
and you're prompting it, and you're typing in things. And it's basically just like search engine
plus plus, right? Where, you know, it's not that different from Google search or Google images,
it's just you get better results on the other side. You know, it's might be magical,
but it's kind of like that, right? However, deep mind styled AI, okay, where it's got
artificial intelligence that is winning games of go, right, winning games of Starcraft.
That's something and it's just looking at the map, looking at the video game, you know, pixels and
able to figure out what the moves are and so on reinforcement learning. That's different. That's
actually the, there's no human in the loop there. The AI is just playing the game and it's super
human already. But in a constrained and not time varying environment, that's really important.
It is, whether it's a game of go, game of chess, a video game, right, that's something where there
are rules in that thing and it's a kind of a bounded environment in a fundamental way, right?
Still, you can envision a world where the combination of, you know, the kind of planning
and Starcraft, if you replace Starcraft, so like Starcraft is something which you, I mean,
certainly an AI could be very good at like resource allocation and so on decision making,
take that hill and send the troops and whatnot. And you can easily imagine that the real world
with drones being Starcraft style, you know, controlled, right? And you combine that with
the ability to speak and generate images and generate video and appear in any form, right?
Like, you know, today, of course, it's appearing as text, right? Tomorrow when, when, you know,
an AI returns a result to a query, it's text, but soon it can appear as a VR thing floating in
3D that speaks to you in your language fluently, like, you know, the Blade Runner kind of scene,
okay? When you combine both those things, you get something that's actually fairly powerful
with not that much squinting, right? And so, so what I think is that every community of fairly
large size, every community that survives, in my view, crowd funds, when I say crowd funds,
I mean the broadest sense, it could be literally with tax revenue that's the most, you know,
traditional method of crowdfunding, albeit, you know, involuntary crowdfunding, right? So,
but every large enough community has its, I will call it AI God, okay? Its network God, which is
all of the knowledge of that community and the values of that community, right? And so, you could
imagine a Christian version of this, you could imagine, though, there'll be different Christian
versions, there'll be a Protestant version, a Catholic version, and a Russian Orthodox. And
of course, there's different denominations, okay? You could imagine, so I can imagine many Hindu
versions of this, right? There's many different kinds of, you know, sub-sex and dharmic sex.
And I don't know how many different ones of these are. There's definitely going to be a Chinese
version, right? Absolutely, there'll be a Chinese version. And that'll be a pretty fearsome thing
that commands all those drones. That's like a crazy kind of thing, okay? That is definitely
something I'm concerned about. But I do think that the part which is very underrated by the AI
doomers is the difficulty of taking physical form. What I think is for a long time, there'll be a
symbiotic relationship between the digital intelligence, which literally lives in the
cloud. It's like lives as an electromagnetic wave, you know, in a sense, right? And us as physical
beings, right? And these are like coordination mechanisms for us. One way of thinking about it
is the network God replaces George Washington or Lee Kuan Yew or the leader or the state that's at
the center of, you know, your hub and spoke topology of your society, right? You have some
wise thing, some decision maker that you go to for decisions, okay? And if you could go to something
that just had infinite bandwidth, and that gave you an immensely amazing answer that was really
good, that was supported by all of your history, and it could do so instantly. Well, that's almost
like a really good CEO that, you know, can almost micromanage the entire society, okay? That's not
impossible, given what we've seen. Let me pause there. I would, I would, I don't know, like, I
think from a perception and control standpoint, like, yeah, if you have perfect perception
and prediction ability, in principle, you can have like centralized top down control, but
in reality, you know, having sufficient perception everywhere,
and having a predictive model of the world that has many variables, you know, very
linked. I'm not saying, to be clear, when I say better than human, I'm not saying omnipotent,
right? I'm just saying that basically, your civilizations AI will have, just like, you know,
there's like the Catholic Church, and it has a bunch of, you know, various cardinals and stuff,
and then there's a pope at the top, right? And they're interpreting scripture and so on. Imagine
something sort of like that, where you have a bunch of engineers milling around, and making edits to
the network God, or the AI God, or whatever you want to call it, that's at the center of your
civilization. And they make edits almost like priests, you know, interpreting scripture, or
today, lawyers interpreting the constitution around the president, that's a known form,
whether it's cardinals and priests circling, you know, some had religious figure, or it's lawyers
and politicians circling some head political figure, you have engineers circling this sort
of head AI figure, right? Yeah, yeah, yeah. So go ahead. So the future, like you said,
this as well, like is polytheistic, polytheistic AI gods, right? Polytheism. Yeah. Instead, and
what sort of the incumbents want is they want monotheism, and they want to shape that God,
right? And they want control over that God. And it's kind of funny how the EAs and AI doomers
are, you know, they actually work very often for these organizations, they work in Anthropic at
OpenAI, they get jobs there. And they both like fear this God, but want to but are working to
create it and want to make sure there's only one. And that's exactly all of it, which is so like,
well, here's what it is. AI alignment is actually EA alignment. Yeah. That's the key insight,
right? They want to create the AI. And what they define as alignment is aligned with EA values.
Yep. Now here's the thing. Anything that's centralized cannot be aligned with the values
of 8 billion people, obviously, right? Like at a minimum, like I know India is working on its own
stuff or whatever, and it'll have some stuff. Dubai has got its own, everybody's going to have
their own stuff. And now, by the way, on the open sourcing, right? So decentralization is one way
of talking about it. Decentralization, another word of Archimedes open sourcing. Well, so the
diffusion models actually have made significant progress in open sourcing because they're easier
to open source than the LLM. So here, for example, Playground just released one. So give me something,
getting to Mars, right? On a shuttle. Okay. You can go here right now. Okay. This,
Sahel just released this yesterday. So it's 70,000 downloads already. It'll take 20 seconds.
And you can download this model and you can run it in a script. Okay. That's like an okay example.
I, you know, whatever, generative AI doesn't always, but at least you can see it works. You
might have to prompt it with more queries. Okay. So the point is like, we want a diversity of all
sorts of subcultures and we don't want to have a monoculture. Like was, like what happened with
social media, if you centralized control over spread of information, you centralized control over
power, the essentialize the power of shaping culture, and then you end up with a monoculture
and anything that diverges from that monoculture is suppressed, you're canceled, right?
We're already seeing this though. And this is the problem that I have with what you guys are
talking about. It sounds, obviously, what you're describing sounds better, but the path that we're
on is not that. Yeah. And skepticism or concern over AI fields. I so much through that. Look at
this. Who are the giants? It's, what is it, Google? It is, we have OpenAI and Microsoft.
Yeah, but Lama 2. We've both seen what they do. We should not be trusting these people and they
have the power. So, Mike, I agree with you, but I'd also say the rebels aren't without anything.
Lama 2, I mean, Zuck is a real MVP on open sourcing AI, right? Zuck is the champion of speech.
That's amazing. Here's the thing. Like, I know that sounds crazy, but here's the thing is
CEOs in any given vertical will counterposition against their rivals, right? If one guy is
leading with the closed source centralized version, often it only takes one CEO who will
counterposition with the open source version, right? And so what Zuck decided to do, which is very
smart, is he's like, okay, rather than go head to head with chat, GPT and so on, we're going to go
the opposite extreme and we're going to release this open source and Lama 2 is very, I mean,
GV, am I wrong? Like Lama 2 is quite popular as an open source model. You disagree?
Yeah, yeah, yeah. No, I mean, that's totally true. I would say that, you know, there are startups,
you know, Mistral is kind of a, you know, a fork. Mistral also, yeah. Mistral, you know,
I mean, we have perplexity, you know, replant, they've all started, tons of startups are training
their own model. And the point is like, it's eroding power away from the big centralized players,
right? It's like, I'd rather have a model that has less parameters or maybe had a bit less data,
but at least it's free to actually tell you its thoughts. It doesn't have all sorts of
prompt engineering and reinforcement learning to suppress its own speech. You know, like, I mean,
nowadays, the centralized models are so scared to say anything, cancelable, they're not that
useful. So I think like, I think the market is going to like value freedom, you know, at some
point. And we got to, we got to like, it's been a very fast sort of, it's been very fast progress
in AI. And the difference between a centralized approach versus a decentralized approach, the
centralized approach, you can steer it very quickly, right? If you have billions of dollars of capital,
you can build a supercomputer, you can hire a bunch of people and train a massive model on a
one to two year time scale. The thing that kills the incumbents is time because the variance of
having many open source forks kind of searching over hyper parameter space, searching over space
of techniques in AI is that at some point, they explore an area that the big centralized players
can't because they need to make one big bet on one huge centralized model. And so over time,
variance wins over centralized control is just we're on a short time scale right now. So it seems
like we're losing, but the reality is that we're not trailing that far behind. And if once they've
trained these large models and they got it at some point, they put in so much capital per model,
they got to leave it there and just let it recoup its losses through revenue. At some point,
that's going to give time for the open source models and the open source community to do a
more diversified search over the space of models and start eroding away their market advantage.
Yeah. Last one on this. Well, even then, I asked the final question to get a dip.
Sure. GV, can you, can you raise your right hand and go like that? Okay. Why? Because then we can do a,
I'm not sure where the videos are, but like high five crypto yak. Okay, because you gave a talk,
right, everyone to all right, boom, whatever. I'm sure you can make that work in the video.
All right, because here's why. Reinforcements are coming. And let me make a few arguments here.
First is Vitalik put a post the other day on decentralized acceleration. And that means I
think the Ethereum community is going to get into crowdfunding, open source AI models.
Beth gave a talk at the network state conference a few weeks ago. It was a great talk also on
kind of aligning crypto and AI. And there'll be various schools of this. Okay, the, you know,
the Bitcoin people have one view and Ethereum people in another view and Solana people have
another view. The other Solana-Solana people, right? And that's a huge pool of capital,
right, to crowdfund things. And I'll come back to that point. Number two is that
the centralized AIs are getting lobotomized, right? They're being made dumber because they
have to be inoffensive. They're even becoming like millennials in another way, not just woke
but lazy, where they're like on strike. And, you know, they won't finish your code snippet.
And they'll say, Oh, you can fill in the rest yourself. I'm like, I don't want it to fill it.
I would, it's the whole point. They want the search engine to fill it in, right? Okay.
Number three is as precedent. I mean, what you're talking about is a cathedral in the bizarre
GV, right? Which is, you know, decentralized for-profit development win or does decentralized
open source development win? And we often find in many spaces is it is a stalemate between them,
right? Like Linux is very, very popular. I mean, Linux on the desktop has arguably worked in the
sense of Android is Linux on the desktop and even iOS is BSD under the hood. So it's Unix on the
desktop in a sense, right? It's a very customized version. And so, you know, whether it's Windows,
Linux, or it's iOS, Android, or it is, you know, the closed source SaaS version versus open source
version, you know, you have GitHub and then you get GitLab, right? And then, you know, I'm pretty
sure because of the huge advantages as a developer, as an engineer, you can have consortia. You're
always seeing this with Dubai and other places. You have consortia that say, look, we don't want to
be choke pointed by Microsoft as, as much as I respect something in Dell's execution, as much
as I respect Sam Altman's execution. I mean, they're phenomenally, phenomenally well. They should
make tons of money. I want them to have as much money as, you know, stacks of money. That's great,
right? They deserve it. Still, money is fine. Power is not, right? We need to decentralize the power.
And, and I think a lot of organizations, a lot of smart people around the world, they're, they're
kind of working on that. And I think the fundamental thing that GV is saying is the two-time constants
that are not obvious how it's going to pan out is how much better the centralized models get
before the decentralized models catch up. Like that is to say, you know, can these improve so much
faster before these other ones catch up? Or, you know, what are those two-time constants look like?
Right? That's not obvious to me how that, how that works. And I guess we'll see. I mean, the fact
that Google, with all of Google's resources, put out this, you know, you guys saw the Gemini video?
Oh, yeah. Yesterday. If you look at their blog post, they, I mean, they kind of helped it along
a bit, right? Like that video was edited and so on and so forth. I was going to put up a post on
this. I love the people there. Some of them, they're really, really skilled technically. But
in some ways, it doesn't look like these are improving as fast as we thought, you know, in
the sense of like, you know, maybe generative AI is, there's 5,000 applications of it. But
what I'm saying, there's a world where these things saturate and then open source catches up.
If they don't saturate and they just keep going like this and open source can't catch up, I don't
know what happens on that. I want to wrap it up. And I want to do it. I want to tie it back to
kind of like the original sort of opening of the chat. Always we're all here today. On this topic of,
you know, I guess, working towards a more decentralized future. A big part of that is
protecting the players involved in that space. And I think increasingly they'll be under attack
in all sorts of ways. I don't know that, I don't know that you're at risk really in the way that
you once were. Just look at you now. I mean, you're totally fine. Your company is, is, you know,
raise the money. Now it's like, we're good to go here. You say no. You say you think you're not
totally fine. Well, I think, I mean, I know, you know, obviously there's more, they're swarming
now as you, as Balaji predicted, the scariest sentence in the English language as Balaji was
right. And I'm experiencing that. So, you know, there's going to be more pieces that come out and
you know, they're probably not going to be as nice. We've seen your tweets. They're not, it's
like, I'm literally just arguing for freedom. And if I get taken down for that, then so be it.
And I think, you know, the great unification here is like, you know, Mike, you want sort of freedom
of press or freedom of, you know, freedom of speech and Balaji wants freedom of exchange,
freedom of demnomination, and I want freedom of compute. And all these three things were kind
of all unified as pro freedom against the incumbents, against the authoritarians trying to
have centralized control over everything. And that's why we're all problematic, right? And that's
why we have to band together and fight. And that's what we're doing here. And we're having this
discussion. And hopefully, it inspires people from sort of all three types of libertarian camps
to collaborate. And so, um, by the way, that's a really good, that's a really good way to kind of
my Solana freedom to speak Balaji freedom to transact that freedom to compute. I think that's
a really good, you know, summary. Go. And well, I guess I want to just ask them, and this was for
you Balaji, like, how do we, how do we, I guess, how do we, how do we fight until we achieve our
goals? Like, what is the way to keep you mentioned earlier, the video game analogy of the new
guys going up on the field, right? Like, how do we protect those people? And how do we, I guess,
protect like the key players as we build towards a world I think that we all kind of want to be a
part of. So I think first is probably, you know, you and I should write like a post that has
both immediate tactics and history lesson for the young guns. And we should also make a video
like a tick tock style 90 second video. Do not talk to journalists. And then was the second
rule. I said, don't fucking talk to journalists. You do not try to violate this rule. You will
regret it, right? And then give all the kind of things there, right? And then, you know, truly,
by the way, I can talk about this, like, there's the top the concept of a journalist, by the way,
there's, is Tucker Carlson a journalist, even though he's got a TV show? No, he's not. Why?
Because he's read is CGTN a journalist. No, they're Chinese, right? Is Glenn Greenwald or
are we journalists? No, we're tech journalists or whatever tech media, you know, so it's not
actually the practice. It's the tribe. And so we have just build up our own tribes capabilities.
And once you think of tech tribe as its own tribe, we have our own media, we have our own
decentralized ideally AI, we have our own, you know, cryptocurrencies and so on and so forth.
And so I think that's really the right step is tribe formation. And then if you're in the tribe,
then we have certain guidance from the tribal elders. And if you're not, then okay, God help
you, you know, and then we probably want to have some admission mechanisms and so on and so forth
and badges and things of that nature. So I think that might be where things go.
And a city with that and a city. Yes. That is a podcast for another day. You guys, it has been
the realist. Thank you both for joining. Big fans, obviously, of both of you,
and biology friend as well, Gil will be soon, especially now that you're out of the shadows.
Why subscribe to this podcast? I never ask and it actually is very important for the algorithm.
Please subscribe, like it, send it to your friends. And we will catch you here next week, later.
