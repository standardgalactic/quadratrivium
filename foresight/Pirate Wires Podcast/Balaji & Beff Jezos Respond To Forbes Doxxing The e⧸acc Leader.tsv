start	end	text
0	7280	They not only doxxed the correlation between my principal identity and Beth Jesus, but the voice doxxed me.
7280	10800	I didn't want to talk to them, but then they're like, look, this is going to really come out.
10800	13600	I'm like, all right, well, I better try to control the narrative.
13600	16480	I thought there was a sort of like ethical protection.
16480	20880	Like, no, I've been trying to figure out, like, why did this happen to me?
20880	28880	Like, where did I cross the threshold of becoming enough of a problem that they needed to have leverage over me and expose me?
29680	36880	Our movement is about free speech, freedom of compute, freedom of AI, and not, like, top-down oppression.
36880	39120	I have failed, honestly, and apology to you two.
39120	40400	We both, you failed.
40400	42240	I don't know why you're talking to them.
42240	43520	Do not talk to journalists.
44960	47200	I said, don't talk to journalists.
47920	49840	You do not try to violate this rule.
50400	51520	You will regret it.
59760	61360	Welcome back to the pod.
61360	67760	We have the, we've got, are we saying Beth Jesus or where are we going with this?
68480	70240	You could call me both names.
70240	78080	I go by both names now, Beth Jesus or Gil Verdon in America, Guillaume Valdon in Canada and France, if you will.
78080	87040	So finally, after it's been honestly too long, the legendary biology doesn't even get a,
87120	88960	does not even need a second name.
88960	91600	It's like, you know, Madonna or who are the other ones?
91600	92160	I don't even know.
92160	93760	And you might be like, I guess.
93760	94160	Teal, I guess.
94160	99360	Well, I, you know, it's not quite, it's not, it's biology.
100400	101440	We are here today.
101440	103200	This is, I'm stoked about this episode.
103200	104080	This is going to be a great one.
104080	104880	And both of you guys, thank you.
104880	106080	You're on a different time zone.
106080	107760	It's been a while setting this up.
109200	112960	But biology and I have been talking about, and biology, I mean, separately from each other,
112960	119680	but also together, media and the shape of media for years through like tech dark ages,
119680	125120	back when we had no counter voice whatsoever, up until today where I think things are still
125120	128640	not balanced, but very different than they were three years ago, certainly during COVID.
128640	133920	And before that, Gil, you were, I'll just break it down.
133920	141520	I mean, so Beth Jesus, kind of popular anonymous account on Twitter, you run something called
141520	150640	the EACC, which we'll get into in a bit or Yak doxxed by Forbes, Emily Baker White of Forbes,
150640	156400	in concert with Alex Conrad, which is an important part of this story because Alex,
157040	160000	it's important to me at least, and I want to talk about it with both of you guys in a minute,
160000	161920	because Alex is so influential in tech.
161920	163440	I mean, he runs the Midas list.
163440	164160	Everybody knows him.
164160	165360	Everybody talks to him.
165360	167200	And that is a problem.
167200	169120	And, and I do want to get into it.
169120	175120	But long story short, these guys hit you up or Emily hits you up and she's got your,
175120	176400	she's got your real identity.
176400	181120	So you've been writing anonymously about EACC for what about a couple of years at this point,
181120	185200	when this happens, have a little bit of a community.
185200	188720	I would say I'm going to kind of characterize what I think you guys do.
188720	191600	And then you can come in here and give me the real version according to you.
192240	197200	I think you guys were memeing about the future and you're definitely counterpointing the EA stuff.
197200	203200	You're sort of like cleverly cutting against the doomer narrative in a fun way.
203200	205600	I've always seen it as very like lighthearted.
205600	211440	I've noticed this week, the EA crowd has been very personally aggrieved by you.
212000	213520	And it gave me a giant question mark then.
213520	219040	I was like, why is, why is the media gone to, to war against you?
219040	220000	I have a few theories.
220000	225680	I'd love to hear apology, your theory especially, because I'm sure you have one at this point.
225680	226320	Sure.
226320	232080	Your link Gill to Mark Andreessen and Gary Tan specifically seems to me
232080	236000	like the reason that you became something that needed to be destroyed and shamed.
237680	238960	So that's my version of events.
238960	242080	You know, EACC born, you represented.
242080	249360	It's a positive, futurist, anti-doomer, pro-progress, pro-AI specifically kind of movement.
250400	253920	You are, they think sass needed obviously doesn't work out that way for them.
253920	255120	You're much more popular now.
256560	260320	Hans to talk about what first things first, like what is your version of those events?
262000	262320	Yeah.
262320	268880	I mean, for me, it was, it was a crazy Friday and it's been a crazy couple of days since then.
268880	273280	I'm like halfway across the world right now and undisclosed location that is not China.
274640	276880	And, you know, on a business trip.
276880	279680	So I'm still, you know, doing, doing what I do.
279680	280400	I'm entrepreneur.
281440	281760	Yeah.
281760	285680	Originally, basically I get a text from like investors.
285680	291360	So, so first of all, I, you know, I came, you know, as, as I was doxed, you know, I came from
291360	296480	Google X, you know, I worked on projects with the leadership there very closely, you know,
296480	297600	very secretive projects.
297600	300080	I was used to sort of secrecy as my baseline.
301280	305840	And to some extent, like spending years, see, super secretive.
305840	307920	You can't talk about what you do and so on.
307920	308960	It's kind of a burden.
308960	311120	And that's originally how I started.
311120	316080	Beth Jesus was just like, as an outlet for me to communicate with people about stuff and just talk.
317360	320080	And, you know, I've kept that, that account since then.
321280	324400	But, you know, I had a startup as well that was not doxed.
324400	333040	Like these, they not only doxed the correlation between my principal identity and Beth Jesus,
333040	339680	but they correlated my principal identity, my current company, and even they traced through,
339680	341040	you know, name changes of the company.
341760	343920	They even like went through my Facebook.
343920	347520	They went, the voice docs me, they just correlated everything.
347520	352400	It was like a full, like, you know, full definition.
352400	355680	When they punched your identity, it was like something out of a spy movie.
355680	357120	They went in on you.
358320	360480	They really threw resources at this.
360480	360800	Yeah.
360800	364960	Like, I mean, for me, you know, like, I think like, you know, I believe what I, I believe
365760	369120	large majority of what I say is Beth, sometimes it's kind of like, you know,
369120	372960	meta-ironic, you know, extreme posts as one does on Twitter.
372960	376560	But like most of it, you know, like I'm all in, like I don't mind like,
377840	381200	you know, backing, you know, using my main identity back, what I say with,
381200	383520	what I have said with Beth.
383520	388800	But to me, it was like, hey, I didn't give you the right to disclose like that I'm doing
388800	390560	this like deep deck startup as well.
391200	393200	You know, I mean, some technologies.
393200	394080	Have the right there.
394080	394640	This is a thing.
394640	398400	It's like, this is the whole thing for me watching this is, this is,
399040	401360	this is not the first time that the press has done this.
402320	403840	This happens often.
404400	408240	And it's, it's, this question of rights comes up.
408240	410240	It's like, we can do this, they say.
410240	411200	It's like, yes, you can.
411200	413120	But the question is like, is it ethical?
413120	414480	What kind of world do you want to live in?
415600	421200	And obviously from where I'm sitting, it just seems the purpose of revealing your identity
421200	426480	is to scare other people who are sharing their opinions in this space,
426480	428240	anonymously from doing so.
428240	432160	They, it's a, it's a, it's a, it is a strategy to chill speech.
432160	434960	I don't have to worry about speaking for the most part within reason.
434960	435840	It's way easier for me.
435840	438400	I don't run a tech company in stealth.
438400	440880	I work for Peter Teal at Founders Fund.
440880	443040	And on the pirate wire side, I run my own business.
443040	446480	It's like there, I am, and the business is speaking.
446480	448880	It's like, it's, it's easier for me to do it.
448880	450000	For someone like you, it's harder.
450000	450640	They know that.
450640	453360	And the point is they want to kind of take you off the map.
453360	453760	Apology.
453760	457680	Why do you think, I mean, do you have any, you can take this anywhere you want.
457680	459840	Obviously you might have something you want to share in particular,
459840	461920	but I would really love to know kind of like what you think,
462720	466800	what you think the motivation behind this specific targeting was.
468400	472880	So, my views on this have somewhat evolved.
473280	481200	Fundamentally, the journalists are, are tribe and they're a sub tribe nowadays of
482080	486800	the overall, you know, whether you call it the regime, the paper belt, the cathedral,
486800	491760	the establishment, the deep state, what have you, that is a set of people.
492480	495520	And it is a group of people that is, you know, FUBU,
495520	498880	you guys remember FUBU from the nineties for us bias.
498880	499600	Okay.
499600	504320	So, like the regime is nationalist for the regime.
504320	507040	You know, it's like to first order, you could say it's Democrats,
507040	509280	you could say it's deep state, you could say a cathedral.
509280	511840	There's like a lot of different names for this, which are all overlapping.
512400	515840	But basically, if you take the whole social network of, you know,
516400	520320	eight billion people in the world and 300 million Americans and so on and so forth,
520320	523360	this is a sub graph in the social network that's densely connected.
524000	527920	And it's sure unless it's professors, it's regulators, it's bureaucrats and so on and so
527920	533040	forth. And everybody who is not them is an enemy.
534640	543120	And that means that they're at simultaneous war with tech, with Trump, with China, with Russia,
543120	548400	with India, with Israel, like, and you can, some of these there are more at war with than others,
548400	551840	right? They don't like India very much, but they're like somewhat fighting it.
551840	554880	They don't like Israel very much, and they've got some outlet, right?
554880	559840	But basically, once you look at it as a giant social network in different colors of subgraphs,
560880	568000	the journalist, you know, like blue subgraph is at war with within America,
568000	573200	the red subgraph and the gray or tech subgraph, right? And so that's like the first order,
573200	579680	like visual of the whole battle space. It's not, this is not like a discussion.
579680	584480	This is not like a normal story. This is information warfare of one tribe versus another.
584560	591600	This is meant to harm you. And even if this first one is just like a tracer bullet,
592400	598640	or like a flare to sort of light up the position, right, then subsequent kinds of things may or may
598640	607040	not be so positive or would have, right? And so that's like first is basically, it's not a,
607040	612080	it's not a positive thing to go and dock somebody against their will. You do not do that to a friend,
612080	617200	right? You do not do that to somebody who you mean well to. You don't stalk them for months.
617200	622560	And, you know, basically in your, in your, and you know, correct me if I'm wrong, Guillaume,
622560	628000	but they basically gave you, you know, they told you they had all this dirt on you and they're like,
628000	632960	well, you better speak with us or else, right? Yeah. Yeah. Yeah. Like I got a text from investors
632960	638640	the night before from, I think it was Alex Conrad told investors like, oh, hey, I correlated
638640	643680	Beth J. Zos and Guillaume. I think he's a portfolio company. They had the old name of my startup. So
643680	650720	I changed the name of my startup for further upsec and for branding eventually. But the,
650720	656960	they hadn't put it all together. And then they censor fused across reporters, like, and then they
656960	661760	had much more, they had too much put together and they wanted to, they were going to put it out,
661760	665680	right? And then so the morning I was like, look, this is going to come out. You have a chance to
665680	672080	give a comment. Like it's, it's happening, whether you like it or not. And for me, I had like two
672080	677760	things. One of them was like, okay, well, how do I, I just went in damage control, right? Like,
677760	682720	I mean, I've, I'm building stuff that I really believe in. I've been wanting to build this for
682720	687520	like eight years. I've been like super stealthy about it for all sorts of reasons for security
687520	694240	reasons, for, you know, IP reasons and so on. And, you know, everything was at risk, right? Not only
694240	698640	the movement, the yak movement and hope, well, hopefully the movement is not at risk, but it's
698640	703280	supposed to be anti fragile. We're trying to make it so, but and, and my company. So I went in damage
703280	708720	control mode. And I didn't want to talk to them, but then they were like, look, this is going to
708720	713120	really come out. I'm like, all right, well, I better try to control the narrative, at least for the
713120	717440	first, for this first thing, because I'm sure they're going to pile on now. The media is definitely
717440	722320	going to pile up from here on. I mean, I can I've entered an exhibit, let it let it be entered
722320	733280	into the record, exhibit a okay, this is from datajournalism.com. Okay, by one of the wokest wokes
733280	738320	to ever woke. One of the three heads, one of the heads on the three headed dragon, I would say.
738320	743600	Yeah, exactly. I mean, it's a multi had the thing is every one of these critters, like basically
744320	751360	is essentially a Stasi officer. That's what these, these folks are. So they actually have
751920	757600	a whole article at datajournalism.com. And what this is actually titled, if you I'm sure if you
757600	764080	paste this into chat, GPT or whatever and ask it to paraphrase it is how to docs. Okay, investigating
764080	770000	social, go ahead. No, I'm just shocked. I'm, I shouldn't be shocked, but I I've never seen it
770000	775280	this explicit. It's this explicit, right? All of their stuff. That's why I read all of their, you
775280	780240	know, or go ahead. Brandy works for I think NBC, right? This works. That's right. Here we go.
780800	784000	This is these are, these are major significant journalists who are,
784000	789760	Yes, that's right. And they teach how to docs, how to, there's other articles on how to
789760	794560	essentially assassinate, except they don't assassinate the character assassinate, right?
794560	799280	And it's all so, you know, once in a while, they'll actually admit it when they're talking
799280	805440	to each other and they put on a different face, right? So here it's like, you know,
806400	811120	be prepared to read thousands of tweets, click until the end of the Google results and dive down
811120	814960	to social media rabbit hole. If you want to collect the tiny biographical clues, they'll help you
814960	821120	answer the question, who is this? Okay, so, you know, I mean, whatever you can read this if you
821120	826720	want. The useful thing about reading articles like that is it tells us as technologists how to
826720	835120	build a privacy countermeasures against these people who are literally like a like a for-profit
835120	840400	intelligence agency. And I don't even say that lightly. How did they get your identity, GV,
840400	844560	right? They, they went and used like some CIA voice recognition thing.
845760	850240	Straight up. I mean, that, I guess that's, that makes it, that makes me a bit more badass that
850240	854880	they had to do that. I don't think it was necessarily that hard, but I thought there was a
854880	861600	sort of like ethical protection, like the way like, I'm not doing anything illegal. I'm literally just
862160	868240	arguing for free speech. Hey guys, thanks for listening to the Pirate Wires pod. Make sure
868240	873440	you like, subscribe, comment below and share this with your friends. I have failed. Honestly,
873440	877280	that was one of the big things I thought while I was watching this go down, I thought like, have we
877280	881920	not, and biology, you two, we both, you failed, you know, like, how do you, I don't know why you're
882000	885760	talking to them. Like that's what I'm thinking. I'm like, how do you, we've been talking about this
885760	892480	for years. Like they are not all of them. And maybe, I'll just, I maybe disagree a little bit
892480	897440	something. I think there's some good things out there. It's very clear in my opinion who are not,
897440	901040	and it's very clear usually by their approach, like that was not a friendly approach. That's a
901040	905680	hostile, at that point, you're a war. And what you, what you do, and this is for people listening
905680	910320	now who are maybe anonymous online, and they don't know what to do if this comes and happens to them,
911040	918080	you ask for help from people like us who are, who are able to be back with media who can defend
918080	924400	you. Like that, that is the very, who really separate from defense publicly is like, like advice,
924400	931840	because by participating, you, first of all, they're using that against you. They're saying,
931840	935760	oh, he participated. It wasn't against his will or whatever. And it's very clear from the emails
935760	940240	that you've shared with me, and the private messages that they sent, you know, to other people
940240	943440	and things like that's not obviously not the case. It was clear just reading the piece that
943440	947680	wasn't the case, but I can confirm here officially that that is not the case. You were definitely
948560	952400	not forced to participate, but you were going to be doxxed, whether or not you liked it.
953200	956960	But had you not participated, they wouldn't have had that weapon to use against you.
956960	963760	And they wouldn't have had much to talk about, because you, they also had not, yes, they were,
963760	967680	they had, they used their CI voice recognition. They really, really thought it was you, you know,
967680	972560	mathematically, whatever seemed like almost certain, but you had not actually confirmed it.
972560	976560	So they would have had a story where it was like, we are very, very certain, but we don't know for
976560	984320	sure. And also, he is sort of associated with this guy who we're telling the world is a Nazi.
984320	990240	And that would have been so ludicrous that, I mean, we would have just gone, the whole internet
990240	993520	would have exploded and been furious. And they would have been beaten back. Like,
994720	998800	you kind of gave them a little bit, a little bit too much in the future. I mean, I wonder what
998800	1004560	Bolliger's advice is, but I'm like, you give them nothing. And you then concoct, you doxx yourself
1004560	1009760	at that point, possibly, to take away the story. Like, I don't know, Bolliger, what would the advice
1009760	1016240	have been you think in that situation? Well, so one thing is, I usually don't even repeat their
1016240	1021360	charges, because they throw around, everybody's, you know, everybody's a Nazi, like they'll call
1021360	1024800	anybody an everybody a Nazi, right? So I don't even give any credence to their charges, right?
1025840	1030000	But setting that aside, yeah, I mean, so I mean, here's the thing, I like,
1032400	1036240	how do I think about it? You're playing, you guys are really video games?
1037280	1042560	Yeah, not enough to this reference, but let's just do it. So there's like, you know, there's
1042640	1046880	various video games where they're like, you know, first person shooters or something like that.
1046880	1053440	And new guys just keep beaming into the arena. Oh, right. They have no context on what just
1053440	1059360	happened and where the, you know, shells are flying overhead and so on. And that's how I think about
1059360	1064400	the new guys who, you know, maybe they're heads down, maybe maybe they were just like in a different
1064400	1067680	part of the battlefield, they don't have context and they're, you know, beaming into the arena.
1068320	1073040	And it's a good analogy, I think, right? Where it's like, you know, they're on our team,
1073040	1077840	they just beamed in, but they, you know, they may not know all the battle tactics or whatever,
1077840	1083120	right? So it's actually incumbent upon us as I hate, at least, you know,
1083120	1088320	Solana, I'm not sure what the convention is, but I guess I've become a little bit of an elder.
1088320	1091680	God help me. God help us all. You're seeing your in school.
1092400	1096960	Yeah, it happens really fast. The gray comes really, really, really fast. I'll tell you that.
1096960	1104880	Okay. But it is incumbent upon us to literally compact this stuff down into monthras that people
1104880	1110960	repeat. And you assume it's almost like college where there's like a new class and it's obsolete
1110960	1114880	in two years or three years. And you have to like say it again and update it, right?
1115440	1118400	So that's, that's one part of it. Let me pause there and get your thoughts.
1119920	1124560	Well, I mean, I agree. I really, like I said, at the top of this little piece here, I felt
1124560	1128880	bad guilt. I felt like I had not done a good enough. It's loud as I have been on this issue.
1128880	1132720	It's awesome. I've written about it as much as I've tweeted about it. I feel like somehow that
1132720	1136400	message, it's like, do people think I'm kidding around? Do they think that I mean, this is
1137040	1143680	in information war? And I again, I do believe there are good actors out there. There are
1143680	1149120	so many nefarious actors. This for me, the Alex Conrad piece is really crazy because so many people
1149120	1157440	treat him like a reasonable reporter in tech. And this action for me is beyond the pale.
1158000	1161840	Not only the way he went after you, but the way he tried to go after Gary and Mark through you
1163600	1170560	is, I think, really nefarious. And I'm like frustrated that people aren't as upset about
1170560	1174720	that piece as I am. But yeah, I know I agree. I think we do have a little bit of a better job
1174720	1182480	reaching out in these moments. And I don't know, it's like, do I, I just hope that people know
1182480	1190240	that they can hit up people like us for advice in these situations? There are a lot of great people
1190240	1196160	online. Lulu is another great person to Lulu. Messervie is a great person to talk to on this
1196160	1203040	kind of stuff. I was saying, I wrote a piece about this. And in it towards the end, I get to the
1203040	1208640	point where it's like, you actually, and this is what I really would love to talk about, things
1208640	1215440	have changed. Yeah, there are a lot of people who are great online talking with big audiences.
1215440	1221360	And it's not just like they're anonymous people, there are pseudonymous, pseudonymous, I cannot
1221360	1228560	ever pronounce it, semi anonymous people. There are CEOs, big, huge, popular public CEOs who are
1228560	1233680	posting, and they are all just like a DM away. And you can see on Twitter, you can see who's
1233680	1237040	connected to who, like if you don't know them directly, you want some advice, you talk to
1237040	1245600	anyone, it's pretty cool. The vibe has shifted somewhat. And I was just watching the Reagan
1245600	1251920	National Defense Forum. This is like the Super Bowl for defense forums. You have, first of all,
1252320	1256960	last week you had Elon Musk telling the advertisers to go fuck themselves
1258400	1261920	on the stage of the New York Times. Then this weekend at the Reagan Forum,
1262560	1268720	you have Palmer Lucky sort of telling kids not to follow their stupid dreams. If they're, you know,
1269760	1277200	contra reason and self-defeating or not good for society. It was like a very sort of anti,
1277200	1281520	I don't know, mainstream message. It was strange to see him up there being so honest and
1281520	1286160	unapologetic. And Palmer, someone specifically who just lays down his opinion every day and
1286160	1290320	does not give a fuck and has really gone direct in that way with his own message about his own
1290320	1299280	company, which is killing it, by the way. Onderal. Then you have Alex Karp, who just espouses like
1299280	1304320	an incredibly anti-woke message openly on stage and is like, I'm not hiring people who are idiots
1304320	1308880	on the following topics, all of which would have been considered beyond the pale just three years
1308880	1313440	ago, would have been articles in the New York Times about, you know, the terrifying menace of Alex
1313440	1318400	Karp. But I am running one of the coolest companies in the world. And I'm telling young people,
1318400	1326000	you are breathing the vapors of a dangerous, new, fake and self-destructive religion when you are
1326000	1331360	sitting at your elite school pretending because you watched TikTok twice and got an A plus on some
1331360	1335920	crazy paper because your professor couldn't get a job anywhere else that you actually understand
1335920	1344960	the world. And you're not welcome at my company. I think things are different now. I don't know,
1344960	1348640	what do you got? Am I right? Am I wrong? Am I just naive, optimistic, too hopeful?
1349760	1355600	Well, yeah, I mean, so, you know, Solana, you and I, again, we're like literally grizzled combat
1355600	1362000	veterans at this point, 10, 10 years in the meme wars, right? Yeah. And last five is really,
1362000	1365280	I think, where most of the action took place. That's right. That's right. So basically,
1366960	1372880	you know, tech versus media, you know, I kind of, all right, I'm just going to rattle off the history
1372880	1378720	here. And then I'll be turning this into a blog post and so on and so forth with the rules and
1378720	1384880	the history and then the history history, the deep history, right? But very roughly, tech kind of
1384960	1389040	arguably, you can argue when tech exists as a culture, but maybe you date it to
1389680	1398880	95 with the graphical web browser, okay? And then from 95 till, you know, 2008 or so,
1399760	1405120	because of the dot com crash, media didn't even really take tech seriously. They're just like
1405120	1410080	gadget guys or what have you just doing their stuff on the West Coast and they were considered
1410080	1416400	basically an auxiliary of the Democrat Party, like you had, you know, unions and you had this group
1416400	1420560	and that group and then there were Steve Jobs and the tech guys making gadgets over there in the
1420560	1425840	corner over there. And media concerned themselves with their expense accounts and the rock and all
1425840	1431760	this other stuff going up into 2008. There's even this article at that time, I think by Joel Stein,
1431760	1436320	that's enumerating like the power centers of the USA and it's real time capsule from 2008,
1436320	1440400	because you know it's not on there. What's on there is a Pentagon and Wall Street and so on.
1440400	1448080	You know it's not on there. In 98? 2008. 2008, what's, oh, social media. Silicon Valley is not on
1448080	1457200	there as a power center in 2008. At all. At all. Yeah, that is, the phrase big tech had not even
1457200	1463280	been innovated at that point. Exactly. This whole system that we're in is so much more recent than
1463280	1467840	people think because what happened was after 2008, after the financial crisis,
1469920	1478080	tech revenues went vertical. Okay. There's a great graphic that shows what happened. All right.
1478080	1484800	Bam. Okay. The hate is Kazanus. What is this graph? This is showing print media revenue top set at
1484800	1490400	$67 billion in year 2000. Then it's like down after the dotcom crash, but it's flat ish.
1490400	1497440	And then a complete collapse down to like $16 billion in like 400 years. This is advertising
1497440	1501200	revenue in newspapers. Advertising revenue in newspapers is a blue line, right? And then
1501200	1505520	including digital, digital doesn't save them, doesn't come on fast enough. And Google eats their
1505520	1509280	lunch and then Facebook eats their lunch. That's a green line over here. Google is the red line.
1509280	1516240	All right. So basically it's one thing to, you know, see your neighbor become like a billionaire.
1516240	1519440	It's quite another thing for them to become a billionaire while you become
1520720	1526960	a thousandaire or whatever. Right. Okay. And so these guys essentially over the first four years
1526960	1532000	of the Obama administration saw these tech guys who had been in, you know, a box or whatever,
1532000	1538160	they didn't think of as anything, suddenly rock it up ridiculously fast. And because that was the
1538960	1543360	iPhone and that was the reallocation of budgets after the financial crisis to online ads,
1543440	1549120	which are finally mature and converting. That was the fact that like SaaS was starting to work.
1549120	1554000	Y Combinator actually, you know, remember Y Combinator started in 2005, that whole modern
1554000	1558000	seed era of things only really started working in the late 2000s. There are a bunch of great
1558000	1563840	companies found around that time, Stripe, Airbnb, Uber, all of that basically by 2013,
1564640	1569920	after Obama got reelected, even in 2012, by the way, do you guys remember in 2012,
1569920	1574320	the nerds go marching in? How a dream team of engineers from Facebook, Twitter and Google
1574320	1579760	built the software that drove Barack Obama's re-election. Okay, when the nerds go marching in.
1579760	1583840	You see that? Yeah, I remember that narrative of the Obama being the first sort of internet
1583840	1589600	president. He had this team around him from tech basically. That's right. Not fully believing it,
1589600	1596800	but. Well, and the reason for that is because, you know, Facebook and then Twitter started in
1596800	1603520	very blue zones in the Harvard area and in San Francisco. And so it was assumed that technology
1604080	1609280	was blue and blue was tech and that it was just good and that if it had any effect on politics,
1609280	1613600	it would be to overthrow oppressive regimes and overthrow, you know, cause the Arab Spring. Go
1613600	1618080	ahead. Right. That was just assumed until Arab Spring, which they thought was great. We don't
1618080	1622720	hear much about the sort of consequences of that today. A lot of disasters, a lot of people
1622800	1627760	dead unfortunately, right? So we can come back to that point, but basically what happened then
1627760	1633840	from 2012 to 2016, a bunch of things happened. First is all these conservatives started getting
1633840	1638720	Android phones. Okay. And there's a really interesting sort of meme that makes this
1638720	1643200	concrete. If you're seeing, and this is kind of late 2010s, starting to get a little obsolete or
1643200	1650160	whatever, right? But there's a, there's a collage of a bunch of Democrat visages and a bunch of
1650160	1658080	Republican visages on Twitter. So Democrat visages are guys with glasses indoors and like,
1658080	1663040	you know, kind of unshaven or whatever, right? They're like unshaven programmer, graphic designer,
1663040	1667920	Yasqueen types or whatever, you know, the guys pointing at the thing, right? Okay. And
1669760	1673600	but the Republicans are more interesting or this is like, it's an interesting different kind of
1673600	1680080	visage. They're people with sunglasses in trucks outdoors, taking selfies on their phone.
1681680	1685920	So the fundamental difference is the Democrats are indoors and Republicans are outdoors.
1687120	1691200	Because almost all the Republicans are in sunglasses and they're clearly on the go,
1691200	1695840	with some like cheapo Android phone. So part of what happened from 2012 to 2016 is the
1695840	1699760	polls got online and that started shifting Twitter and the internet to the right. The
1699760	1705360	other thing that happened is after Obama got reelected in 2012, the media, which had played
1705360	1709440	nice with tech guys because they needed them to get Obama to get reelected, now had four years to
1709440	1715280	settle scores. And all the knives came out and all the valleywag type stuff happened around that time.
1715280	1718880	Would you just look at all those rich people? That's valleywags editorial vision in nutshell,
1718880	1723840	but could be so much more by Monju, who's become a full communist now and radicalized, right?
1723840	1728320	But that was like 10 years ago when he was ostensibly central left, he was complaining about
1728320	1734080	attacking them as rich people and so on and so forth. That's crazy. I remember people being mad
1734080	1738240	about that. But in my mind, I remember Dave Moore and complaining about this, which made sense
1738240	1743760	because he was being attacked. I don't remember the press rising to the defense of those guys.
1743760	1748240	That's interesting. That's right. So basically a few years later, he's all abolished billionaires.
1748240	1752480	It's literally he's writing that. Okay. The radicalization happened to the journals.
1752960	1762400	Okay. And essentially, though, it was a boxer's clinch where that tech and media alliance didn't
1762400	1767360	make sense anymore because the media guys were like, wait a second, these tech guys aren't just
1767360	1773120	like some vote bank gadget bank, whatever that's making the the bejeweled toaster on my desk that
1773120	1779040	is an iMac, they're coming for everything. Yeah. And then toothless really. I mean, it was
1779840	1785200	Gawker is destroyed. Yeah. That was that comes that comes a little bit later. But yes, that's
1785200	1789280	right. That's right. Of course, it's an important episode. And then trouble wins the election. And
1789280	1796400	at that point, it's worse. That's right. But crucially, the negative coverage starts in 2013.
1796400	1801200	In 2012, you can even find them writing articles like there's no such thing as a brogram or and
1801200	1806800	so on. Right. So this goes back to that visual I had of the blue tribe, right, red tribe,
1806800	1811680	gray tribe, if you're part of the tribe, you get friendly coverage. If you are not part of the tribe,
1811680	1816960	it's information warfare. Yeah. Right. And now that can mean by the way, you can be part of the
1816960	1820960	tribe and then kicked out of the tribe or you can choose to leave like Glenn Greenwald has,
1821680	1826240	you know, he was he was like, he had all the prizes. That's why I give him a lot. I don't
1826240	1831360	agree with Glenn on every issue. But I respect him because he had all the prizes within blue and
1831360	1835840	decided to kind of go and do his own thing and stand for a principle that he stood for. Right.
1835920	1840320	Conversely, it is also possible for someone to be kind of a renegade,
1840320	1847280	but then to become incorporated into blue and to be part of this Borg, right. Like Google,
1847280	1853840	early Google was much more buccaneering and swashbuckling and so on than what's become,
1853840	1859760	which it's not as blue as it was like a few years ago, maybe, but it's pretty blue, right.
1859760	1865520	So so once you kind of have that visual, it's really the, you know, that's the friend enemy
1865520	1871600	of the tribal distinction. And it's not exactly left, right, or what have you. It is group non-group.
1872240	1876480	Let me pause there. I've got a lot more. Well, I want to, I mean, I have a slight pushback,
1876480	1882000	which is that I agree with, I mean, the whole history, I think is correct and insightful,
1882000	1888560	especially the piece on the revenue is really important. It's, you know, we, I think I maybe
1888560	1895040	get somewhat distracted sometimes by the ideological combat component of all this. It just very
1895040	1899520	clearly feels to me like a classic information war and maybe not classic. It's not classic. It's
1899520	1903920	new. It's a new kind of, it's a very scaled up information war. It's live. It happens every
1903920	1909840	day. It lives in our pocket. It never ends. But at the end of the day, like we are, and this is a
1909840	1915440	point that is, you know, I've heard before I just forget, it's like we're in cop, we're competitive.
1915440	1919040	We're competitive. There's a business piece that's competitive, like just hot, like industries are
1919040	1924240	competing. And then online, that I think the new thing that we've seen over the past few years,
1924240	1930480	and let's just focus on tech for a moment, is we're not just, it's not just a money issue. Like
1930480	1939680	it's an actual, the all in pod is a massive success. And that is, you know, a side project for David
1939680	1946160	Sacks. And that would be a dream come true for every single person in media. So it's not like the
1946160	1950000	platforms are taking the money. It's like the people on the platforms are also taking the
1950000	1954080	attention from them. They're not even, they don't even get to be the attention people anymore.
1954080	1958720	Or not exclusively, there's combat, there's competition there. So separate from the ideological
1958720	1963440	piece, there's just, there's the reality of just competition. And when you're in it with someone
1963440	1968160	for something that you consider your life. So it's, it's funny you say this, because, you know,
1968160	1973040	now again, this feels like an ancient, actually, GV, I want you to jump in because we were just
1973040	1978880	chatting. So, did you want to say something or? Yeah, yeah, there's kind of the broader,
1979600	1984880	there's the broader informational war between tech and, and, you know, the paper built
1984880	1989600	aligned media. But, you know, the media, they're kind of the pit bull for, for some of the,
1990560	1996720	the paper belt against, you know, whoever in tech is an enemy of whoever is like helping place
1996720	2002320	various stories. You know, to me, it's been like, I've been trying to like figure out like trying
2002320	2008480	to back propagate, why did this happen to me? Like, where did I cross the threshold of becoming
2008480	2015200	enough of a problem that they needed to have leverage over me and expose me? And, I mean,
2015200	2021360	obviously, you know, Mark and Gary have been supportive of the movement, you know, for all
2021360	2026480	sorts of reasons, one of which is like, obviously, we think that, you know, the current sort of
2026480	2034000	regulatory capture attempt by, you know, AI safety, the AI safety complex and some of the big incumbents,
2034720	2040400	you know, it's camouflage is like anti-doom, trying to, trying to save us, you know, trying
2040400	2045040	to, trying to save us from open source models, right? Their dual use and so on. And, you know,
2045040	2049600	we were calling that out and getting, getting people fired up, calling this out and it became a
2049600	2056240	problem. And of course, you know, Gary tweeted this that, you know, FTC chair, Lena Khan,
2057200	2060720	was invited to YC, you know, and I was there and we had a little chat.
2060800	2065680	And, you know, I've voiced, I've voiced our concern of our, the concerns of our community,
2065680	2070480	that like, hey, actually, this is, this is, you know, kind of some of the big incumbents kind of
2070480	2076240	covering up the fact that they're trying to capture the market with sort of like, oh, this is for
2076240	2081920	your own, your own safety. And that's when I became like officially a political problem, right? And,
2081920	2086480	you know, there's all sorts of interests in the background, you know, trying to pull strings
2086480	2092000	here. You know, I have some hypotheses, maybe I won't go into like exactly who I think is pulling
2092000	2096560	the strings. I have my, I have my thoughts on that. But what, what's been public is that, you
2096560	2104800	know, Secretary Ramondo, I believe, called out EX specifically as like a dangerous movement and
2104800	2112560	something we should suppress with AI. They want to, like our movement is about free speech,
2112640	2117760	freedom of compute, freedom of AI and not like top down oppression aided with AI. And they're
2117760	2122880	literally proposing shutting us down with AI, which proves our point, which is kind of like,
2122880	2127040	by the way, by the way, you know, that's like, it's like, well, nobody rid me of this meddlesome
2127040	2133680	priest kind of thing, right? Well, no one rid me of this meddlesome EAC, right? Like EAC is a problem.
2133680	2138480	And that's like a decentralized signal to the journals to go in, you know, right? It's stochastic
2138480	2145360	journalism. Yes. Come on, that's pretty good. Right? No, I agree. Yeah, you're holding up the
2145360	2149680	target. This is where I'm trying to think of what the illusion to stochastic terrorism. Okay,
2149680	2154400	I thought it was funny. Stochastic journalism, stochastic terrorism. Okay, I want to talk about
2155120	2160960	it was funny. I want to talk about EAC. You were just getting into it. I mean, what
2162800	2165440	this is a little bit off topic, and we can, you know, revisit any of the stuff that we just talked
2165440	2174640	about, there's a ton there on the war piece. But this, you know, it's dangerous and whatnot.
2176240	2179360	What is EAC? How would you even describe it?
2180960	2189200	What is EAC? I think for me, it's kind of like a cultural framework, really, or a
2189200	2193520	medical cultural framework. We're trying to understand, where's this whole thing going?
2193600	2197440	Where's civilization going, you know, from first principles? At the end of the day,
2197440	2203680	the only laws are the laws of physics. And I'm a former theoretical physicist, and, you know,
2203680	2210160	I do physics based AI now. You know, I always think about physics. And nowadays, I think about
2210160	2215760	self organizing systems. And, you know, to me, it was just an exercise in writing and trying to
2215760	2221760	understand where it's all going. And rather than have like, like completely, like,
2223680	2228400	unanchored to reality sort of theories, like, like the doomers do of like, AI taking over,
2228400	2232320	as soon as it reaches human level AI, it takes over and fooms and takes over the planet. Like,
2232320	2236480	I've been trying to actually find like, where's this thing going? It's like, okay, well,
2238080	2244240	you know, civilization at the end of the day is a system that's like alive. All systems that are
2244320	2250560	alive, or that are basically life from a physics standpoint, seek to grow, they acquire energy
2250560	2255440	to maintain their sort of state, and they seek to grow and increase their ability to acquire
2255440	2259600	free energy. It's like, okay, well, civilization wants to go up the what is called the Kardashev
2259600	2265600	scale. So it is the scale of energy production or consumption. And so that's where we're going,
2265600	2271600	you know, and that's where the system wants to go. And, you know, it keeps morphing itself,
2271600	2276000	it, you know, searches over the space of technologies, of cultures, of memes, of
2276000	2284960	genetics, of everything, in order to ascend this scale. And, you know, basically, it's like,
2284960	2291120	we're just pointing that out. And to us, like, like, it's first a framework of like, what is,
2291120	2295200	and, you know, that's what's going on. And then it's like, how should you live your life,
2295200	2299920	given this fact? It's like, well, actually, if you help the growth of civilization,
2300640	2307600	you know, you will likely prosper. And it's kind of a self fulfilling prophecy. If you're
2307600	2312640	optimistic about the future, you work on hard things, right, because you believe in a better
2312640	2319040	future. So you want to contribute it to it so that you own a piece of it. And, and then you go out
2319040	2323920	and build and do hard things. And then the good future happens. Whereas if like you believe in
2323920	2328800	doom, and nothing good is going to happen, you know, a longer build, you don't longer want to
2328800	2333280	have kids, you don't bet on the future. And then the future is actually worse. Right. And to us,
2333280	2340320	it was a sort of reaction to the pervasive demerism, and the the person pervasive pessimism,
2340320	2347200	tech pessimism, that was just dominating the news cycles. And we were like, can we have a viral,
2347200	2354960	optimism movement that, you know, hyperstitiously induces growth of civilization, right? Don't
2354960	2358560	we all want that? Don't we all want to be, you know, amongst the stars?
2359360	2365120	It's more no, that's the thing. No, that's actually, I mean, for us, us three, yes. But
2365120	2369040	that's actually like a core. Yeah, it's not different. It's, yeah.
2369680	2373440	Acke, obviously ACC, we're talking about acceleration is the word that you're using. It's
2373440	2380720	EA, you're making a play on effective altruism. The effective altruists are very concerned with
2380960	2387040	accidentally building a god that kills us, really, is like where their heads at. And they,
2387920	2391360	not just they, now you have the safetyists in the media who have, they want to slow down tech
2391360	2396480	for all sorts of reasons. But their position, all of them in this sort of uneasy alliance between
2396480	2402640	very smart people in AI who happen to be EA-pilled and a little bit of a doomer, and the press,
2402640	2407120	and, you know, the government that wants to slow all this shit down. It's, it is that it's slowing
2407120	2411840	things down. Endlessly in the process, especially you hear, you know, Mark Zuckerberg said, move
2411840	2416240	fast and break things. And then things broke. We have to move more slowly. And you're not saying
2416240	2420960	that you're saying we need to accelerate. So the positive vision is there. It's awesome. And I
2420960	2424720	thank you for your service, sir. It is very important. The memes are excellent. And I think,
2424720	2428640	I agree, they are powerful. I think they're motivating. I think they are helpful. But they
2429440	2437120	identified correctly your critique of them. And, and so that is, you know, you're, you're locked
2437120	2441840	in a sort of at that point, it's, if people hate you a lot, and I mean, I've seen it. Why,
2441840	2446880	how much they hated you until this week? They're definitely mad. Can I make, can I make a couple
2446880	2453680	points there? Yeah. So there are decelerationists. And there's also what the current US establishment
2453680	2460320	is, which are stagnationists, right? What they want to do is they're in their own way, conservatives,
2460320	2466560	where they want to freeze the world in amber. And so you will find, for example,
2468480	2475440	that, you know, for example, Raimondo is talking about the tariffs and so on and export controls.
2475440	2480000	And they want to kind of freeze China as a power. And actually, I can understand that. Okay.
2480800	2485280	But, and so they're like, Oh, you know, the US needs to be a leader in AI. So we're going to ban
2485280	2491040	exports in there. And then literally, you know, that's what they're saying on Mondays and Thursdays.
2491040	2496880	And then on Tuesdays and Fridays, they're doing AI bans in the US and saying, you need to slow down
2496880	2501840	and not accelerate and so on and so forth, right? So they want to kind of think they think they can
2501840	2507200	be a policy lovers, which, you know, they're not Silicon Valley, they're not Shenzhen,
2507280	2511760	you know, they're neither of these things. But Washington DC thinks they can freeze the current
2511760	2516960	dispensation in amber, where they've got a healthy lead, and nobody abroad, and nobody at home goes
2516960	2522800	too fast. And nobody, they just want to stop the disruption. Because that's the thing. Acceleration
2524320	2526960	is good for lots of people, but it's not good for them.
2526960	2530720	It's not good for power, any technological innovation, I think, pretty much.
2530720	2535280	Well, so that's the thing. So I've got it. I've got a perspective on this being out here in Asia,
2535280	2542560	right? And India loves tech. India loves tech. And the reason Indians love tech is, you know,
2542560	2548480	you've got a guy who was on a, you know, like a very poor 10 years ago, who's now got an Android
2548480	2552080	phone, and they've got a lifeline to the world, and they're able to study and they can earn and
2552080	2556720	all this stuff. So it is correlated with the massive improvement in their living standards,
2556720	2561360	right? But for the journals, and more generally, the US establishment, you saw that graph, it's
2561360	2566000	correlated with a massive decrease in their living standards. So they have a learned correlation
2566000	2571200	where the faster the tech grows, the less money they have, the less power they have,
2571200	2576800	which is kind of true for, you know, it would be extremely painful for you, right? Acceleration
2576800	2582720	is extremely painful for them, right? And so that's why they're fighting the internet,
2582720	2587520	and they're fighting every force that's against them, in actually a conservative way.
2587840	2591440	Always feels like this. And then in this case, you're talking about generative, obviously,
2591440	2596800	as many things, but the thing that the most attention at this point is are the generative
2596800	2601200	models when you're talking about like language specifically, this is something that it looks
2601200	2606480	like a journalist that knows the true NPC level. It's literally the thing is, you know, this guy,
2606480	2610800	I got to get this guy to put this project back up, which, you know, I used to say,
2611520	2617040	not even jokingly that these journalists, you know, there are just like a sports article,
2617040	2621280	it's a wrapper around a box score, you know, box score is like the, you know, how many rebounds,
2621280	2626320	how many says steals, whatever, in a basketball game, or a financial article, it's a wrapper around
2626320	2630240	a ticker, like, you know, stocks were up on heavy trading, blah, blah, blah, it's just like a verbal
2630240	2635120	narrative. I used to say that these articles are just wrappers around tweets, you give it three
2635120	2639600	tweets, and you can write the article. And I used to say that as a joke, you can go find,
2639600	2645040	not even as joke, it's like true and also a joke, right? From like years before chat,
2645120	2651120	GPT. And then when it came out, it became literally true, where you could paste in a few
2651120	2656480	articles, like a single tweet into this thing that, you know, like a New York Times article
2656480	2661360	generator, and that's probably gotten even better a year later, and generate an entire full NYT
2661360	2668160	article that's like dark times ahead in technology as acceleration continues, you know, like you
2668160	2672800	could literally do that, right? And there's no intelligence, it's totally paint by numbers,
2672800	2675440	you just have the stylistic kind of thing off the prompt, go, go, go.
2676160	2681440	Yeah, yeah, I think like the thing, the thing that's scary, right? It's kind of like the old
2681440	2686160	world media, they serve the incumbents, they serve those that have interest in top down,
2686160	2691920	sort of control, they like to like, they gain proxy power by being instrumental to
2691920	2697760	authoritarians, right? And those that argue for more control. And IAC is about, like,
2698480	2703280	saying that acceleration, techno capital acceleration is a positive force, it creates
2703280	2709280	amazing technologies, it gives us wealth. And, you know, the counter argument to it is that,
2709280	2714400	well, if we, if we don't control who and who ends up in power, that's, that's bad, you know,
2714400	2719600	really what they're thinking is like, we might lose power. And so that is bad. But the reality is,
2719600	2725600	like, the system would adapt and powers would shift to, you know, those that are disrupting
2725600	2731440	the incumbents, right? And that's good. That's how the system, you know, optimizes itself and finds,
2731440	2736560	you know, whichever technologies are most beneficial to the world and helps them scale
2736560	2741680	up. And of course, those that are the produce those technologies get to have sort of more
2741680	2745520	power to allocate capital and control where it goes, right? Which is the sort of natural
2745520	2750080	meritocracy. And they're trying to break that they're trying to maintain the sort of status quo.
2750080	2753600	They are the real conservatives, they call themselves maybe progressives in some cases,
2753600	2757760	but they're really just trying to conserve the powers that be. And then the media, they're just
2757760	2763280	mouthpieces for the incumbents. Because again, like, you know, those are the only people that
2763280	2769360	still talk to them. And they use it like, you know, they use them as the media is kind of like
2769360	2775600	an information warfare arm of like, you know, the incumbents and the pre-rebuilt, right? And we've
2775600	2780240	seen that. Like, and the label, you know, go ahead. I worry a little bit. And I want to get both of
2780240	2788400	you take on this. Unless you want to jump in a little bit, which is, you know, there's more I
2788400	2793760	can say on kind of the history of this and so on. But there's a huge difference as to where we are in
2793760	2802000	2023 versus where we are in 2019, 2020, 2021. And I think, Solana, you did your part. I think I did
2802000	2807600	my own little part. We did our part, which go ahead, shakes, no handshakes. That was no handshakes,
2807600	2815680	please. Exactly. Remember that? Yeah. Essentially, what happened was, starting in 2013, let me just
2815680	2823040	recap the history that began and bring us to the present day. From 2013 to roughly, you know, 2020,
2824000	2830000	the journals essentially began a reign of terror against tech, where there was all manner of
2830000	2835360	cancellation. We didn't have the word for it then, against people large and small. That's why the
2835360	2838640	homeless problem, which is not really a homeless problem, but a drug and mental illness problem is
2838640	2842960	Sanjana Friedman, one of your, you have many talented writers, particularly talented writers,
2842960	2848560	Sanjana Salute. Yes, she's good. All right. Is it she? She, yeah. Okay. Okay. Sorry. I didn't know
2848560	2855280	what the, you know, what the, uh, we gotta be careful. Nameless. So, um, Sanjana Friedman has done
2855280	2859920	a phenomenal job on documenting how the like the homeless problem, it's not just a homeless problem,
2859920	2865840	it's a drug and mental illness problem. The point is, in the early 2010s, when something could have
2865840	2872320	been done about it, there were a few tech guys who made in-politic comments about, you know, the
2872320	2878800	sudden epidemic of needles and syringes and poop. This guy, Greg Gottman, another guy, Peter Shee,
2878800	2884160	and yeah, maybe they posted in like, you know, maybe you might not use exactly that language,
2884240	2891440	but obviously they're, you know, it's, it's, it's a lot less offensive than some crazy guy
2891440	2896800	throwing feces at you in the street, right? And, and more importantly than the NGO who's
2896800	2902400	feeding him drugs and getting paid by the city to do so, right? They mean things about the people
2902400	2908320	who were chasing you down the block. Yeah, exactly. That's right. That's right. So, what happened was
2908320	2913040	the journals at that time. Not necessarily. It's like, that was tech people turned on them. Well,
2913040	2917200	well, but, but the reason was there's a bunch, if you go back and look, Peter Shee, Greg Gottman
2917200	2922960	got destroyed by the media at that time. And then people queued off of that as, oh, that's what I'm
2922960	2928160	supposed to, I'm supposed to yell at them, right? And so it became for years, it was incredibly
2928160	2933360	un-PC to even mention the problems that San Francisco was happening. So it was like disabling
2933360	2938480	the immune system during the period when it maybe could have done something more. And then this thing
2938480	2942400	just got completely out of control and it became what it is now. And these NGOs became totally
2942400	2947040	entrenched and so on. Many other kinds of things happened like that. That's just like one version,
2947040	2952480	example of it, where the journalists caused a giant problem and then only after it became
2952480	2957600	massive, then could it be acknowledged? It was interesting. I was nervous to write about local
2957600	2962960	politics and I forget that sometimes, but like when I first started seriously writing in like 2020,
2964560	2969280	I was nervous to touch the homeless issue and the drug issue. And I just thought like, this is,
2969280	2972800	this feels dangerous, people are going to come after me, I don't care, I got to do it.
2972800	2979760	And it doesn't feel that way now. It's a weird thing where I have, I always ask myself, is it
2979760	2983680	because they're so strong or because they become weaker? And I think it's both at the same time.
2983680	2989440	How they won, is that why they don't care anymore? Yeah, exactly. That's right. So I think it's both
2989440	2997440	where the left, the Democrats, the blues, whatever, have captured the state and so they've got the
2997440	3002560	budget. And so they sit in their parapets. And no matter what we see online, the money just
3002560	3007520	keeps flowing to these NGOs, they flow to them or whatever, right? So we can yell and they can lull
3007520	3012960	and then just go back to shipping syringes, right? But they have lost control of the network.
3013520	3019680	And, you know, thanks Elon and thanks to also sub stack and, you know, Coinbase taking a stand and
3019680	3024080	salon and a bunch of other people, they've lost control of the network enough, they're getting
3024160	3029280	crushed in soft power terms every single day. And that does also matter in terms of building
3029280	3034400	a parallel consensus over here. But it matters insofar as we can convert that energy into
3034400	3040240	parallel institutions. And so that's actually GV where you are, I think, obviously, you know,
3040240	3046000	talented and as soon as a meme maker and so on in your own right. But it's also fortunate that
3046000	3050560	this happened to you, it's not good that it happened to you, but it's fortunate to you in 2023,
3051200	3057440	when we have this whole ecosystem, right? So, you know, in the mid 2010s, what would happen is
3057440	3062720	some poor tech guy and it could be, you know, a very junior person or the most senior executive
3062720	3068720	would just get targeted and just torn limb from limb on Twitter, where it was such an
3068720	3074240	overwhelming advantage of forces for the bad guys that even somebody liking a tweet in their
3074240	3080800	defense would get pulverized for the like, right? And that means, do you think about like the, you
3080800	3088480	know, the eyeballs are just scouring Twitter for anybody who had the thought of defending somebody?
3088480	3093360	Okay. And so that was a level of, you know, control that they had over the platform and thus
3093360	3098560	over mines and the signals that were being sent. It was really, very ugly time. And a lot of people
3099600	3102800	killings, it would feel like you had like the James DeMore thing where he wasn't even posting
3102800	3108800	publicly, he was posting internally on a channel, he was at Google, right? Was that Google or Facebook?
3108800	3113760	Yeah, or like what happened to Tom Press and Werner at GitHub? Completely fake episode, okay?
3114560	3119360	You can look at this article called Facts Conveniently Withheld, okay? There's tons of these
3119360	3125200	kinds of things that happened in the 2010s where good people were just attacked and they had nobody
3125200	3130480	to defend them. And so then what happened though, steadily, gradually, year by year,
3131120	3137680	we built enough followers until there's a really interesting tipping point. So in 2020,
3137680	3142080	I funded this, there's a Niger, I made that public, there's a Nigerian guy who did this analysis,
3142080	3146480	tech journalism is less diverse than tech. Well, now of course, now we're in 2023,
3146480	3153280	so we know that DI, DIE is stupid, okay? And we can actually say that. Fine. But back then,
3153280	3157760	essentially, there was a huge to do made about how white tech, I'm not the kind of person who
3157760	3162640	believes white is an insult, they are. And yet they were far, far whiter than all of us, okay?
3163680	3168080	But here's the thing, you know, Solana, to your point, is when you go and look at the raw data
3168080	3173280	over here, you look at the raw spreadsheet, you see a very interesting phenomenon. And the interesting
3173280	3180160	phenomenon is that back in 2020, this is like three years ago, there are only a few journalists
3180160	3186640	who had more than like 100,000 followers on their own, it's like three or four, okay?
3187760	3193040	What you, what I, but lots of founders had way more than that. And I realized something, it was
3193040	3199120	like a lighting bill is like, wow, the journalists are not exceptional in their own right as
3199120	3205120	individuals, they're not like charismatic people who people want to listen to, they can only win if
3205120	3214000	they team up in groups behind brand names, and then attack the guy who stands out. That's, you
3214000	3218640	know, it's actually this remarkable thing when you start looking at, of course, followers aren't
3218640	3222400	everything and so on and so forth. But it was, it was remarkable what a difference there was,
3222960	3228480	where it was a hugely right shift to distribution of founder followings to journalists' followings.
3229200	3234480	And so then once Elon took over Twitter, and he stopped whatever algorithmic boosting,
3234480	3242560	artificial boosting those guys were getting. Yes. Well, that has been framed by journalists,
3242560	3250640	I've seen journalists talk about this on threads, as Elon is now boosting nefarious people. He's
3250640	3257280	not boosting, he's just, Twitter doesn't have enough people working to manage all this at this
3257280	3262400	point. They're just simply no longer boosting these kinds of people. For years, we wondered,
3262480	3266640	like, how is that random VC who says everything that they like, but has never made a successful
3266640	3270880	deal in his life, like the face of venture capital on Twitter, or like, why do these
3270880	3276000	people still so much engagement, they're being pumped in the trending topics by a team at Twitter
3276000	3281040	that was propping them up that no longer exists. And now Twitter moments, Twitter moments.
3281040	3286960	Do you guys remember Twitter moments? Yes, I asked almost, I think, and like every couple months,
3286960	3293360	I'd be like, take tear down this wall. Yeah. No, Twitter moments, people didn't know it by name,
3293360	3298240	because it wasn't like, like Google Maps, you go to maps.google.com, right? So Twitter moments
3299040	3302880	was not something that was publicly named, so people didn't know what it was. But it basically
3302880	3308160	is a thing where when you logged into Twitter, it would show you the trending news story of the day
3308160	3312640	that they had picked, and it would give you some prompting as to how you're supposed to think about
3312640	3319520	it. In a person you're supposed to attack. Yes, exactly. So some poor Shmo would basically have
3319520	3324560	the two minutes' hate of Orwell directed at them, right? Crazy, man. It was like the lottery that
3324560	3329280	surely jacks the story. The negative lottery. Oh, yeah, yeah, yeah, yeah, yes, yes, exactly, right?
3329280	3335360	So here's, here's basically the, now what we have is what we've done is we've flanked the,
3336240	3342880	the traditional legacy media from two directions, both ultra short-form content of tweets and
3342880	3349280	ultra long-form content of podcasts, where they're relatively weaker, you know, then they're, and
3349280	3354000	so, you know, it's obviously it's content, but it's also distribution channels. They didn't have
3354000	3357280	years and years and years of legacy distribution channels there. They're in the mezzanine,
3357280	3363120	right? And tech in general is about going, you know, to the extremes on, on some new channels,
3363120	3370560	like the office in the very small bits of content and very long, right? And so now, and then you
3370560	3374560	tweet out the podcast, right? Or in the podcast, you talk about the tweets, right? So we're flanking,
3374560	3377920	and of course, what Elon has done with the video stuff has made that even easier to do.
3379280	3383920	That said, by the way, I do think of Twitter, you know how like there's that famous, or at least
3383920	3388080	when famous, when I was a kid, Istanbul is Constantinople, it's Istanbul and Constantinople,
3388080	3392480	right? It switches hands back and forth because it's so strategic, its location, you know?
3393120	3399200	That's what Twitter is. Yeah. And it was, you know, free speech between the free speech party,
3399200	3405440	and then it switched hands and it became the regime's tool. And now it's back to Constantinople.
3406720	3410320	But I don't know where it's going to be in two or three years. They are attacking the heck out
3410320	3415360	of, out of, out of Elon. Go ahead. I think the next battleground is LLMs, right? At the end of
3415360	3422240	day, it's about information supply chain attacks, right? If the media is, you know, they have
3422240	3428400	absolute power over information flow, then they have extremely high soft power. We eroded
3429040	3434000	that power with technology within the age of social media. There's still bitter about that.
3434560	3442080	And now the media are trying to serve sort of incumbents or whoever, whichever authoritarians
3442080	3448160	are pulling the strings, they're trying to ensure that this complex that they're part of
3448160	3454000	maintains control over or gains control of the new information supply chain that's emerging,
3454000	3459520	that is LLMs, right? They want to be able to shape the cultural priors of the LLMs that shapes
3460160	3466720	how they speak. And if LLMs become like the new Google search on steroids, right, which they are,
3466720	3471920	poised to do, they're going to become a source of truth, right? And so that's why we need
3471920	3479040	decentralized AI. Exactly. I would say that, you know, this is the same battle over and over.
3479040	3484720	They're kind of like still bitter that they lost the social media battle, right? When they had like
3484720	3490480	sort of a sort of regime installed within Twitter and they have like soft control over Twitter,
3490480	3497200	you know, everything was fine. When Elon came in, bought Twitter and disrupted everything,
3497200	3502880	then they demonized him and, you know, they said that he's dangerous and whatnot when he's just
3502880	3508000	trying to ensure people have the freedom to speak. For the record, you know, like in the old regime,
3508560	3514400	my first Beth Jesus account got booted, right? I said that and I got locked out and I couldn't get
3514400	3521200	back in. So the original sub stack was from my original account because I said, you know, COVID
3521200	3526560	came from a lab, which it seems higher, you know, very high likelihood now, right?
3526560	3532720	Wild that the OG, Beth got canceled for COVID. Because I feel like at this point, journalists
3532720	3536880	look back on that a lot of people, I mean, anyone in the kind of in the one party state looks back on
3537680	3542560	COVID and really tries to pretend that it didn't happen. And the Soviet lab leak in
3542560	3547760	particular is is one, it's like that and Hunter Biden's laptop or the two things that they really
3547840	3552720	just will scream to your face that nobody was censored for, nobody was kicked off a platform
3552720	3558080	or no, it never happened. It was like, you're just making this up. And they have to do that because
3558080	3563120	those two examples are so incredibly damning. I've had a couple more honest journalists say,
3563120	3567840	you know, the Hunter Biden laptop one, for example, yes, it happened. But it's, you know,
3567840	3570720	it's just this one thing. Why does people, what do people keep talking about? It's like,
3570720	3574400	people keep talking about it because it's incredibly important that we were silenced
3574400	3579120	or that there was an attempt made in that way. And the lab leak for me is also right up there.
3579760	3585120	Just that we couldn't talk about this very obvious question, I would say that was worth asking.
3585920	3591680	There's, you know, in the background, there's cybernetic control of information propagation,
3591680	3600080	they're trying to control people's thoughts by by biasing what speech gets algorithmically amplified
3600080	3605840	or suppressed. It's pretty simple. I think that, you know, for, for COVID, you know,
3605840	3611520	as if we, there was points where we had lockdowns, it's like, look, you know, this was like the
3612400	3616560	authoritarians, they were like, give us a ton of control. We'll keep you safe. This thing is very
3616560	3620320	dangerous. We gave them a ton of control. It didn't help a lot. It didn't help at all, right?
3620320	3625600	It didn't help at all. It's total failure. It was actually the bottom up sort of, you know,
3625600	3630000	the technical capital machine is what saved us. It did all this biotech engineering that,
3630000	3636240	you know, helped help save some lives. And so at the end of the day, the lockdowns just didn't
3636240	3641920	work, right? Like we still, the thing is still spreading to this day. And so it's a failure
3641920	3648000	of this sort of narrative that if you give incumbents and those in power, more power, right,
3648000	3652720	for your own safety, like it violates the narrative that they'll do anything useful, right?
3652800	3656640	And so they want to suppress that story, fundamentally.
3656640	3662320	One quick thing on Twitter, I think, get back to the NY thing and ask you maybe an uncomfortable
3662320	3667680	question based on what you were just talking about. So on the Twitter thing, and the concept
3667680	3672160	of an opal piece, you know, it's changing hands back and forth, I would say one person who does
3672160	3681040	not get nearly enough credit for understanding that and acting, I think, morally in a sort of
3681040	3690000	righteous manner, is Jack Dorsey, who at the all like, first of all, founder of the company
3690000	3694320	was on the free speech side, things tilted in the other direction. And then we have confirmation,
3694320	3699200	we see, first of all, he said all this stuff publicly, he is the reason one of the key reasons
3699200	3706080	that Elon was brought in and then was able to do what he did. And I have no doubt that he
3706800	3712480	knew things would get crazy with Elon in the company and that things would change dramatically.
3712480	3719680	But my sense was, especially after Hunter Biden's laptop, Jack felt like, this is a power that is
3719680	3724400	too great for any one person, and it needs to switch hands, it needs to, it needs to,
3724400	3730480	it needs to recede. Now, speaking of power, as apology you were saying before, we don't know
3730480	3733920	where this will be in a couple of years, which is why I get nervous about things like community
3733920	3740640	notes existing, and the celebration over people who we don't like, being fact checked and things
3740640	3745120	like this by the platform that makes me nervous, but no power, I think more powerful maybe than
3745120	3751200	the AI piece. You guys are talking about, both of you now, decentralization. And apology,
3751200	3755440	you're saying, this is the thing that we need, I agree, because from where I'm sitting,
3756000	3766560	it looks like AI is a naturally centralizing technology. I am skeptical of people who think
3766560	3771360	that AI is the solution to all of our problems and we don't have to keep it,
3771360	3777440	you know, there's a super broad conversation here. On this topic specifically, I am nervous about the
3777440	3783280	amount of power that very few people have. I'm not worried about some runaway AI. I don't see a lot of
3786080	3794320	small players, you know, upstarts with powerful LLMs. I see the giant companies have these things,
3794320	3800400	and they have terrible track records on this question of speech in particular. And when I look
3800400	3806960	ahead, there is a very real possibility that the people who control this are the sensors,
3806960	3811760	and this things, you know, like you have a handful of these things that are shaping our reality,
3811760	3818880	who's writing those rules, it's certainly not me. And so these are central, they seem like
3818880	3823360	centralizing, not decentralizing technology. It's like, what is centralized to AI? I don't
3823360	3828160	see that, I don't really see that happening. I think that you can want that, but I don't know
3828160	3834720	that that is the natural mode. Yeah, I don't know. So, you know, I mean, I agree that in the current
3834720	3841200	paradigm with the sort of power efficiency and density of neural compute we have on GPUs, there's
3841200	3847600	a huge advantage to just building a football field supercomputer, scraping all the data over
3847600	3851760	of the internet and like training one big centralized model, but at some point that
3852480	3857440	sort of the advantages of doing that are sort of going to get eroded away and, you know, the big
3857440	3863840	incumbents hopefully can compete each other's margins out. And then there's going to be sort of
3863840	3870000	like an advantage to sort of decentralizing AI, bringing AI towards the data. We're still far
3870000	3875760	from there. For now, that's right. There's kind of like just a big advantage in just being a big
3875760	3882560	centralized player. And unfortunately, right, like I said, you know, LLMs are kind of the future
3883600	3889840	information, you know, highways, right, for people. It's much more natural to ask an LLM
3889840	3896160	that's human like to get information either from the internet or from your database and whatnot.
3896160	3902720	And if what LLMs are allowed to say is shaped by a few people in some in some room with like
3903680	3910800	enormous cultural and soft power, I think that's that's pretty dystopian. And it opens up,
3911600	3916240	you know, it's kind of turnkey authoritarianism, right? It's kind of like it's even more subversive
3917680	3924640	sort of form of censorship. And, you know, those that want to have that sort of power, of course,
3925200	3931920	you know, are going to push for, you know, AI to be centralized so that they can co-op these
3931920	3938720	organizations that have the monopoly or oligopoly. And they want to, you know, they want to form such
3938720	3945360	an oligopoly so that they have such power. And it's not disruptible by, by say up and coming
3945360	3951920	startups. And so, you know, that's why sort of like, you know, this executive order, they have
3951920	3957200	like compute caps, right? Like very close to what, you know, current big incumbents
3958240	3964080	amount of compute they threw into their models are, and they want to ban sort of open source models
3964880	3969520	or make them like a dual use technology that you need to report the government so that they,
3969520	3978080	you know, they'll have control over whoever pops up as a, as a big, you know, provider of LLMs.
3978080	3985440	And to me, that's really dystopian. I think the P probability of 1984 is superior to P AI doom
3986160	3993120	by a lot. And, you know, I still invite AI doomers to, you know, explain to me how they think like
3993120	3998560	AI is going to fume and take over, you know, as someone who's used AI in their career to,
3998560	4003040	you know, engineer matter and, and, and biologics and all sorts of stuff. Like,
4003040	4006160	I could tell you it's much harder than you think. Obviously, biology has a lot of experiences in
4006160	4012080	this area. It's much harder than they think. So they're kind of sci-fi scenarios are implausible,
4012080	4017200	but the thing is they're like those kind of cre, you know, the doomers that like talk about fume
4017200	4021760	and like all these crazy sci-fi scenarios, they're instrumental to those that seek power
4022640	4027120	and want to have this sort of soft power of shaping the cultural priors of the LLMs,
4027120	4030800	because then they'll shape the culture of the people and then they're going to be able to
4030800	4036000	control the people. And so, you know, I think there's this tech disruption and,
4036000	4042880	you know, chaos is a ladder and the existing incumbents are trying to secure power in this new
4042880	4049440	era, just like they kind of did by, you know, subverting and co-opting some of the social
4049440	4055040	media giants. And, you know, we don't want to have a Twitter situation, a pre-Elon Twitter
4055040	4062400	situation for LLMs again, right? We don't want that. And so, you know, the whole point of,
4062400	4067200	you know, of the AI policy part of EAC is to maintain freedom, maintain competitiveness
4067200	4071440	in the market, don't over-regulate it, that serves the incumbents, and that serves the
4071440	4075520	authoritarians ultimately. And we should have freedom of speech, freedom of thought, freedom
4075520	4082320	of compute. So, yeah. Apology on this question. Yeah. What is your, I mean, do you have some,
4083040	4087840	any concerns at all that you might share with the EA people? Like, could you?
4088720	4097280	Yeah, no. Well, see, the thing is that, you know, Twitter reduces the first bit is,
4097280	4102960	which tribe are you in? You know, are you this tribe? So, certainly I'm on the accelerationist
4102960	4110880	side of things in the 01. With that said, you know, when you add a second bit is,
4112080	4117680	is there a real chance of a superintelligence? I absolutely do think there is. And the reason
4117680	4124720	for that is, what most people have seen at, you know, over the last year is, let's call it chat
4124720	4130000	GPT style AI, right, which is generative AI, where there's a human in the loop, you know,
4130000	4133840	and you're prompting it, and you're typing in things. And it's basically just like search engine
4133840	4139600	plus plus, right? Where, you know, it's not that different from Google search or Google images,
4139600	4143200	it's just you get better results on the other side. You know, it's might be magical,
4143200	4149440	but it's kind of like that, right? However, deep mind styled AI, okay, where it's got
4150160	4155520	artificial intelligence that is winning games of go, right, winning games of Starcraft.
4155920	4159680	That's something and it's just looking at the map, looking at the video game, you know, pixels and
4159680	4163840	able to figure out what the moves are and so on reinforcement learning. That's different. That's
4163840	4169440	actually the, there's no human in the loop there. The AI is just playing the game and it's super
4169440	4175360	human already. But in a constrained and not time varying environment, that's really important.
4175360	4181760	It is, whether it's a game of go, game of chess, a video game, right, that's something where there
4182080	4186960	are rules in that thing and it's a kind of a bounded environment in a fundamental way, right?
4187680	4193440	Still, you can envision a world where the combination of, you know, the kind of planning
4193440	4198720	and Starcraft, if you replace Starcraft, so like Starcraft is something which you, I mean,
4198720	4202800	certainly an AI could be very good at like resource allocation and so on decision making,
4202800	4206720	take that hill and send the troops and whatnot. And you can easily imagine that the real world
4206720	4213600	with drones being Starcraft style, you know, controlled, right? And you combine that with
4213600	4220400	the ability to speak and generate images and generate video and appear in any form, right?
4220400	4225760	Like, you know, today, of course, it's appearing as text, right? Tomorrow when, when, you know,
4226560	4235920	an AI returns a result to a query, it's text, but soon it can appear as a VR thing floating in
4235920	4242000	3D that speaks to you in your language fluently, like, you know, the Blade Runner kind of scene,
4242000	4247120	okay? When you combine both those things, you get something that's actually fairly powerful
4247120	4256160	with not that much squinting, right? And so, so what I think is that every community of fairly
4256160	4262560	large size, every community that survives, in my view, crowd funds, when I say crowd funds,
4262560	4265680	I mean the broadest sense, it could be literally with tax revenue that's the most, you know,
4265680	4271120	traditional method of crowdfunding, albeit, you know, involuntary crowdfunding, right? So,
4271120	4279920	but every large enough community has its, I will call it AI God, okay? Its network God, which is
4280720	4287520	all of the knowledge of that community and the values of that community, right? And so, you could
4287520	4291040	imagine a Christian version of this, you could imagine, though, there'll be different Christian
4291040	4294640	versions, there'll be a Protestant version, a Catholic version, and a Russian Orthodox. And
4294640	4301200	of course, there's different denominations, okay? You could imagine, so I can imagine many Hindu
4301200	4306160	versions of this, right? There's many different kinds of, you know, sub-sex and dharmic sex.
4306160	4310080	And I don't know how many different ones of these are. There's definitely going to be a Chinese
4310080	4313920	version, right? Absolutely, there'll be a Chinese version. And that'll be a pretty fearsome thing
4313920	4317600	that commands all those drones. That's like a crazy kind of thing, okay? That is definitely
4317600	4327840	something I'm concerned about. But I do think that the part which is very underrated by the AI
4327840	4334800	doomers is the difficulty of taking physical form. What I think is for a long time, there'll be a
4334800	4339680	symbiotic relationship between the digital intelligence, which literally lives in the
4339680	4344880	cloud. It's like lives as an electromagnetic wave, you know, in a sense, right? And us as physical
4344880	4351040	beings, right? And these are like coordination mechanisms for us. One way of thinking about it
4351040	4360480	is the network God replaces George Washington or Lee Kuan Yew or the leader or the state that's at
4360480	4366000	the center of, you know, your hub and spoke topology of your society, right? You have some
4366000	4372400	wise thing, some decision maker that you go to for decisions, okay? And if you could go to something
4372400	4378160	that just had infinite bandwidth, and that gave you an immensely amazing answer that was really
4378160	4383040	good, that was supported by all of your history, and it could do so instantly. Well, that's almost
4383040	4391600	like a really good CEO that, you know, can almost micromanage the entire society, okay? That's not
4391600	4398480	impossible, given what we've seen. Let me pause there. I would, I would, I don't know, like, I
4398480	4405680	think from a perception and control standpoint, like, yeah, if you have perfect perception
4406320	4411440	and prediction ability, in principle, you can have like centralized top down control, but
4412160	4415760	in reality, you know, having sufficient perception everywhere,
4417280	4421680	and having a predictive model of the world that has many variables, you know, very
4422640	4427920	linked. I'm not saying, to be clear, when I say better than human, I'm not saying omnipotent,
4428800	4436800	right? I'm just saying that basically, your civilizations AI will have, just like, you know,
4436800	4443920	there's like the Catholic Church, and it has a bunch of, you know, various cardinals and stuff,
4443920	4448080	and then there's a pope at the top, right? And they're interpreting scripture and so on. Imagine
4448080	4453040	something sort of like that, where you have a bunch of engineers milling around, and making edits to
4453040	4457280	the network God, or the AI God, or whatever you want to call it, that's at the center of your
4457280	4462560	civilization. And they make edits almost like priests, you know, interpreting scripture, or
4462560	4466640	today, lawyers interpreting the constitution around the president, that's a known form,
4466640	4471840	whether it's cardinals and priests circling, you know, some had religious figure, or it's lawyers
4471840	4478320	and politicians circling some head political figure, you have engineers circling this sort
4478320	4484000	of head AI figure, right? Yeah, yeah, yeah. So go ahead. So the future, like you said,
4484000	4492800	this as well, like is polytheistic, polytheistic AI gods, right? Polytheism. Yeah. Instead, and
4492800	4498000	what sort of the incumbents want is they want monotheism, and they want to shape that God,
4498000	4503920	right? And they want control over that God. And it's kind of funny how the EAs and AI doomers
4504880	4511360	are, you know, they actually work very often for these organizations, they work in Anthropic at
4511360	4518160	OpenAI, they get jobs there. And they both like fear this God, but want to but are working to
4518160	4523040	create it and want to make sure there's only one. And that's exactly all of it, which is so like,
4523840	4531440	well, here's what it is. AI alignment is actually EA alignment. Yeah. That's the key insight,
4531440	4537920	right? They want to create the AI. And what they define as alignment is aligned with EA values.
4537920	4542720	Yep. Now here's the thing. Anything that's centralized cannot be aligned with the values
4542720	4549680	of 8 billion people, obviously, right? Like at a minimum, like I know India is working on its own
4549680	4553360	stuff or whatever, and it'll have some stuff. Dubai has got its own, everybody's going to have
4553360	4558080	their own stuff. And now, by the way, on the open sourcing, right? So decentralization is one way
4558080	4562160	of talking about it. Decentralization, another word of Archimedes open sourcing. Well, so the
4562160	4566800	diffusion models actually have made significant progress in open sourcing because they're easier
4566800	4573360	to open source than the LLM. So here, for example, Playground just released one. So give me something,
4573360	4580080	getting to Mars, right? On a shuttle. Okay. You can go here right now. Okay. This,
4580080	4585040	Sahel just released this yesterday. So it's 70,000 downloads already. It'll take 20 seconds.
4585040	4590240	And you can download this model and you can run it in a script. Okay. That's like an okay example.
4590240	4593360	I, you know, whatever, generative AI doesn't always, but at least you can see it works. You
4593360	4599040	might have to prompt it with more queries. Okay. So the point is like, we want a diversity of all
4599120	4604400	sorts of subcultures and we don't want to have a monoculture. Like was, like what happened with
4604400	4609440	social media, if you centralized control over spread of information, you centralized control over
4609440	4614000	power, the essentialize the power of shaping culture, and then you end up with a monoculture
4614000	4618160	and anything that diverges from that monoculture is suppressed, you're canceled, right?
4618160	4620960	We're already seeing this though. And this is the problem that I have with what you guys are
4620960	4625920	talking about. It sounds, obviously, what you're describing sounds better, but the path that we're
4625920	4631600	on is not that. Yeah. And skepticism or concern over AI fields. I so much through that. Look at
4631600	4638080	this. Who are the giants? It's, what is it, Google? It is, we have OpenAI and Microsoft.
4638080	4644160	Yeah, but Lama 2. We've both seen what they do. We should not be trusting these people and they
4644160	4651360	have the power. So, Mike, I agree with you, but I'd also say the rebels aren't without anything.
4651360	4660000	Lama 2, I mean, Zuck is a real MVP on open sourcing AI, right? Zuck is the champion of speech.
4660000	4664960	That's amazing. Here's the thing. Like, I know that sounds crazy, but here's the thing is
4667520	4673440	CEOs in any given vertical will counterposition against their rivals, right? If one guy is
4673440	4678320	leading with the closed source centralized version, often it only takes one CEO who will
4678320	4684240	counterposition with the open source version, right? And so what Zuck decided to do, which is very
4684240	4689840	smart, is he's like, okay, rather than go head to head with chat, GPT and so on, we're going to go
4689840	4693760	the opposite extreme and we're going to release this open source and Lama 2 is very, I mean,
4693760	4697920	GV, am I wrong? Like Lama 2 is quite popular as an open source model. You disagree?
4697920	4702960	Yeah, yeah, yeah. No, I mean, that's totally true. I would say that, you know, there are startups,
4703040	4707520	you know, Mistral is kind of a, you know, a fork. Mistral also, yeah. Mistral, you know,
4707520	4712800	I mean, we have perplexity, you know, replant, they've all started, tons of startups are training
4712800	4717840	their own model. And the point is like, it's eroding power away from the big centralized players,
4717840	4723920	right? It's like, I'd rather have a model that has less parameters or maybe had a bit less data,
4723920	4729120	but at least it's free to actually tell you its thoughts. It doesn't have all sorts of
4729120	4736480	prompt engineering and reinforcement learning to suppress its own speech. You know, like, I mean,
4736480	4741600	nowadays, the centralized models are so scared to say anything, cancelable, they're not that
4741600	4748960	useful. So I think like, I think the market is going to like value freedom, you know, at some
4748960	4758000	point. And we got to, we got to like, it's been a very fast sort of, it's been very fast progress
4758000	4763600	in AI. And the difference between a centralized approach versus a decentralized approach, the
4763600	4768960	centralized approach, you can steer it very quickly, right? If you have billions of dollars of capital,
4768960	4774720	you can build a supercomputer, you can hire a bunch of people and train a massive model on a
4774720	4780800	one to two year time scale. The thing that kills the incumbents is time because the variance of
4780800	4785760	having many open source forks kind of searching over hyper parameter space, searching over space
4785760	4792480	of techniques in AI is that at some point, they explore an area that the big centralized players
4792480	4798080	can't because they need to make one big bet on one huge centralized model. And so over time,
4798080	4803840	variance wins over centralized control is just we're on a short time scale right now. So it seems
4803840	4810640	like we're losing, but the reality is that we're not trailing that far behind. And if once they've
4810640	4815520	trained these large models and they got it at some point, they put in so much capital per model,
4815520	4823760	they got to leave it there and just let it recoup its losses through revenue. At some point,
4824960	4830240	that's going to give time for the open source models and the open source community to do a
4830240	4836000	more diversified search over the space of models and start eroding away their market advantage.
4836000	4840080	Yeah. Last one on this. Well, even then, I asked the final question to get a dip.
4840080	4850400	Sure. GV, can you, can you raise your right hand and go like that? Okay. Why? Because then we can do a,
4850400	4857760	I'm not sure where the videos are, but like high five crypto yak. Okay, because you gave a talk,
4857760	4863440	right, everyone to all right, boom, whatever. I'm sure you can make that work in the video.
4863440	4868160	All right, because here's why. Reinforcements are coming. And let me make a few arguments here.
4868160	4874320	First is Vitalik put a post the other day on decentralized acceleration. And that means I
4874320	4880160	think the Ethereum community is going to get into crowdfunding, open source AI models.
4881680	4886560	Beth gave a talk at the network state conference a few weeks ago. It was a great talk also on
4886560	4890880	kind of aligning crypto and AI. And there'll be various schools of this. Okay, the, you know,
4890880	4894640	the Bitcoin people have one view and Ethereum people in another view and Solana people have
4894640	4901760	another view. The other Solana-Solana people, right? And that's a huge pool of capital,
4902320	4907200	right, to crowdfund things. And I'll come back to that point. Number two is that
4909520	4916640	the centralized AIs are getting lobotomized, right? They're being made dumber because they
4916640	4921680	have to be inoffensive. They're even becoming like millennials in another way, not just woke
4921680	4928560	but lazy, where they're like on strike. And, you know, they won't finish your code snippet.
4928560	4931760	And they'll say, Oh, you can fill in the rest yourself. I'm like, I don't want it to fill it.
4931760	4936160	I would, it's the whole point. They want the search engine to fill it in, right? Okay.
4936160	4943040	Number three is as precedent. I mean, what you're talking about is a cathedral in the bizarre
4943040	4950160	GV, right? Which is, you know, decentralized for-profit development win or does decentralized
4950160	4956000	open source development win? And we often find in many spaces is it is a stalemate between them,
4956000	4962800	right? Like Linux is very, very popular. I mean, Linux on the desktop has arguably worked in the
4962800	4968640	sense of Android is Linux on the desktop and even iOS is BSD under the hood. So it's Unix on the
4968640	4976640	desktop in a sense, right? It's a very customized version. And so, you know, whether it's Windows,
4976640	4984000	Linux, or it's iOS, Android, or it is, you know, the closed source SaaS version versus open source
4984000	4990560	version, you know, you have GitHub and then you get GitLab, right? And then, you know, I'm pretty
4990560	4996800	sure because of the huge advantages as a developer, as an engineer, you can have consortia. You're
4996800	5000800	always seeing this with Dubai and other places. You have consortia that say, look, we don't want to
5000800	5005520	be choke pointed by Microsoft as, as much as I respect something in Dell's execution, as much
5005520	5009040	as I respect Sam Altman's execution. I mean, they're phenomenally, phenomenally well. They should
5009040	5015040	make tons of money. I want them to have as much money as, you know, stacks of money. That's great,
5015040	5021040	right? They deserve it. Still, money is fine. Power is not, right? We need to decentralize the power.
5021600	5025360	And, and I think a lot of organizations, a lot of smart people around the world, they're, they're
5025360	5030480	kind of working on that. And I think the fundamental thing that GV is saying is the two-time constants
5030480	5035200	that are not obvious how it's going to pan out is how much better the centralized models get
5036160	5042800	before the decentralized models catch up. Like that is to say, you know, can these improve so much
5042800	5047280	faster before these other ones catch up? Or, you know, what are those two-time constants look like?
5047280	5054080	Right? That's not obvious to me how that, how that works. And I guess we'll see. I mean, the fact
5054160	5060960	that Google, with all of Google's resources, put out this, you know, you guys saw the Gemini video?
5061840	5069200	Oh, yeah. Yesterday. If you look at their blog post, they, I mean, they kind of helped it along
5069200	5073760	a bit, right? Like that video was edited and so on and so forth. I was going to put up a post on
5073760	5078000	this. I love the people there. Some of them, they're really, really skilled technically. But
5078880	5083440	in some ways, it doesn't look like these are improving as fast as we thought, you know, in
5083440	5092640	the sense of like, you know, maybe generative AI is, there's 5,000 applications of it. But
5095520	5102240	what I'm saying, there's a world where these things saturate and then open source catches up.
5102880	5106560	If they don't saturate and they just keep going like this and open source can't catch up, I don't
5106560	5113280	know what happens on that. I want to wrap it up. And I want to do it. I want to tie it back to
5113280	5120640	kind of like the original sort of opening of the chat. Always we're all here today. On this topic of,
5122240	5127920	you know, I guess, working towards a more decentralized future. A big part of that is
5127920	5132720	protecting the players involved in that space. And I think increasingly they'll be under attack
5132720	5137920	in all sorts of ways. I don't know that, I don't know that you're at risk really in the way that
5137920	5142320	you once were. Just look at you now. I mean, you're totally fine. Your company is, is, you know,
5142320	5146400	raise the money. Now it's like, we're good to go here. You say no. You say you think you're not
5146400	5151360	totally fine. Well, I think, I mean, I know, you know, obviously there's more, they're swarming
5151360	5156000	now as you, as Balaji predicted, the scariest sentence in the English language as Balaji was
5156000	5161760	right. And I'm experiencing that. So, you know, there's going to be more pieces that come out and
5162640	5169120	you know, they're probably not going to be as nice. We've seen your tweets. They're not, it's
5169120	5174960	like, I'm literally just arguing for freedom. And if I get taken down for that, then so be it.
5176400	5182720	And I think, you know, the great unification here is like, you know, Mike, you want sort of freedom
5182720	5188080	of press or freedom of, you know, freedom of speech and Balaji wants freedom of exchange,
5188080	5193040	freedom of demnomination, and I want freedom of compute. And all these three things were kind
5193040	5197920	of all unified as pro freedom against the incumbents, against the authoritarians trying to
5197920	5203040	have centralized control over everything. And that's why we're all problematic, right? And that's
5203040	5208000	why we have to band together and fight. And that's what we're doing here. And we're having this
5208000	5214240	discussion. And hopefully, it inspires people from sort of all three types of libertarian camps
5214240	5221920	to collaborate. And so, um, by the way, that's a really good, that's a really good way to kind of
5222880	5227520	my Solana freedom to speak Balaji freedom to transact that freedom to compute. I think that's
5227520	5233440	a really good, you know, summary. Go. And well, I guess I want to just ask them, and this was for
5233440	5244960	you Balaji, like, how do we, how do we, I guess, how do we, how do we fight until we achieve our
5244960	5250720	goals? Like, what is the way to keep you mentioned earlier, the video game analogy of the new
5250720	5256480	guys going up on the field, right? Like, how do we protect those people? And how do we, I guess,
5257440	5264720	protect like the key players as we build towards a world I think that we all kind of want to be a
5264720	5271840	part of. So I think first is probably, you know, you and I should write like a post that has
5272880	5278400	both immediate tactics and history lesson for the young guns. And we should also make a video
5278400	5284480	like a tick tock style 90 second video. Do not talk to journalists. And then was the second
5284480	5291200	rule. I said, don't fucking talk to journalists. You do not try to violate this rule. You will
5291200	5296560	regret it, right? And then give all the kind of things there, right? And then, you know, truly,
5296560	5302720	by the way, I can talk about this, like, there's the top the concept of a journalist, by the way,
5302720	5306960	there's, is Tucker Carlson a journalist, even though he's got a TV show? No, he's not. Why?
5306960	5311920	Because he's read is CGTN a journalist. No, they're Chinese, right? Is Glenn Greenwald or
5311920	5316800	are we journalists? No, we're tech journalists or whatever tech media, you know, so it's not
5316800	5323440	actually the practice. It's the tribe. And so we have just build up our own tribes capabilities.
5323440	5328640	And once you think of tech tribe as its own tribe, we have our own media, we have our own
5328640	5333360	decentralized ideally AI, we have our own, you know, cryptocurrencies and so on and so forth.
5334320	5340320	And so I think that's really the right step is tribe formation. And then if you're in the tribe,
5340320	5345280	then we have certain guidance from the tribal elders. And if you're not, then okay, God help
5345280	5350080	you, you know, and then we probably want to have some admission mechanisms and so on and so forth
5350080	5353920	and badges and things of that nature. So I think that might be where things go.
5353920	5362320	And a city with that and a city. Yes. That is a podcast for another day. You guys, it has been
5362400	5367440	the realist. Thank you both for joining. Big fans, obviously, of both of you,
5367440	5373680	and biology friend as well, Gil will be soon, especially now that you're out of the shadows.
5374640	5380080	Why subscribe to this podcast? I never ask and it actually is very important for the algorithm.
5380080	5392160	Please subscribe, like it, send it to your friends. And we will catch you here next week, later.
