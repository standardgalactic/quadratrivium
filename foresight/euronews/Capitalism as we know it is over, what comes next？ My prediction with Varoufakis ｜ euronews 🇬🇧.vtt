WEBVTT

00:00.000 --> 00:01.000
Are we good?

00:01.000 --> 00:03.000
One, two, three.

00:03.000 --> 00:04.000
Welcome to the show.

00:04.000 --> 00:05.000
Giannis.

00:05.000 --> 00:06.000
Thank you, Tom.

00:06.000 --> 00:07.000
Very good to be here.

00:07.000 --> 00:08.000
Let's start there, shall we?

00:08.000 --> 00:11.000
What is your wildest prediction for the future?

00:11.000 --> 00:14.000
It's not a prediction, it is a diagnosis.

00:14.000 --> 00:23.000
My name is Tom Goodwin and this is my wildest prediction.

00:23.000 --> 00:33.000
His name is shot to fame in 2015 when he was anointed minister of finance in Greece at the height of the European debt crisis.

00:33.000 --> 00:41.000
This is Giannis Varoufakis, an author, academic, perhaps activist, a politician,

00:41.000 --> 00:47.000
and we're here to discuss the future of capitalism and how technology is changing the world.

00:47.000 --> 00:53.000
I want to talk about his latest book, techno feudalism, the end of capitalism.

00:53.000 --> 00:56.000
This book is not about what will happen in the future.

00:56.000 --> 01:03.000
It is a highly controversial notion of what has already gone down.

01:03.000 --> 01:14.000
I'm not writing about what AI would do to the labour market, what will happen to us with big brother and surveillance and any of that.

01:15.000 --> 01:25.000
It is my estimation, and this is a controversial hypothesis, that capitalism has already entered, which is very strange.

01:25.000 --> 01:26.000
Yes.

01:26.000 --> 01:29.000
I don't remember this feeling like something that happened.

01:29.000 --> 01:32.000
Tom, the way I see it is this.

01:32.000 --> 01:39.000
Suppose this was 1776 and we were in London and we were having a discussion about the state of the world.

01:39.000 --> 01:43.000
Now, everywhere we looked in 1776, we would see feudalism.

01:43.000 --> 01:52.000
We would see feudalism in the House of Lords, in the House of Commons, in government, in every local council, around the world, on the land.

01:52.000 --> 01:56.000
We would see peasants, we would see aristocrats.

01:56.000 --> 01:59.000
And yet, we do know that, don't we?

01:59.000 --> 02:08.000
Already, feudalism had died and was being gradually but fast being replaced by something called capitalism.

02:08.000 --> 02:18.000
The magnificent shift of power from the owners of land to the owners of machinery, of steamships, of electrical grids later on.

02:18.000 --> 02:24.000
And the shift of wealth creation from rent accumulation to profit making.

02:24.000 --> 02:28.000
My view is that we are already experiencing a similar transformation.

02:28.000 --> 02:31.000
Wherever we look, we see capital.

02:31.000 --> 02:32.000
We see markets.

02:32.000 --> 02:35.000
We see capitalists doing extremely well.

02:35.000 --> 02:45.000
And yet, I think that already we have undergone a transformation to something like feudalism, but a very technologically advanced version of it.

02:45.000 --> 02:48.000
Markets have been replaced by platforms.

02:48.000 --> 02:51.000
So Amazon.com is not a market.

02:51.000 --> 03:02.000
It looks like a market, but it's more like a digital fiefdom, a cloud fiefdom, belonging to one man whose accumulation of wealth is based not on profit,

03:02.000 --> 03:04.000
but on a form of rent.

03:04.000 --> 03:10.000
Every time you buy something on Amazon, 30-40% of the price goes to Mr Bezos, not to the maker.

03:10.000 --> 03:15.000
And how are you defining assets in this world of technofedalism?

03:15.000 --> 03:17.000
What is it that they are owning?

03:17.000 --> 03:18.000
What is it that they are renting?

03:18.000 --> 03:21.000
Is it our data, our attention, our relationship?

03:21.000 --> 03:24.000
No, all that is part of the story, but it's not the story.

03:24.000 --> 03:30.000
The story is that a new form of capital began to emerge about 10 years ago.

03:30.000 --> 03:34.000
Capital was always a produced means of production.

03:34.000 --> 03:43.000
So whether you have Robinson Cruser's fishing rod, a steam engine, or an industrial, a very advanced industrial robot today.

03:43.000 --> 03:47.000
It's a produced means of production, something we produced in order to produce other stuff.

03:47.000 --> 03:54.000
But this new mutation of capital, which I call cloud capital, it's what lives in your phone.

03:54.000 --> 03:58.000
And by cloud you mean it's sort of a ethereal asset?

03:58.000 --> 03:59.000
No, I'm talking about cloud capital.

03:59.000 --> 04:05.000
So take Alexa or Siri or Google Assistant.

04:05.000 --> 04:11.000
That sits there either on your phone or on your desk and you order it to do things.

04:11.000 --> 04:15.000
Well, yes, but that's only a tiny part of the story.

04:15.000 --> 04:25.000
What it is, it's an interface between you and the whole agglomeration of capital goods, including optic fiber cables that are laid on the ocean floors.

04:25.000 --> 04:35.000
Huge, gigantic server farms that hum like a factory, like a dark satanic mill to quote Edmund Burke, sell towers.

04:35.000 --> 04:39.000
This is capital, it doesn't live in the cloud, but it's what we call the cloud.

04:39.000 --> 04:42.000
When you upload stuff, you know, photographs on the cloud, right?

04:42.000 --> 04:45.000
Or you save stuff on the cloud.

04:45.000 --> 04:52.000
So you interface with this thing, which is a kind of capital, but it's not exactly produced means of production.

04:52.000 --> 04:56.000
What does Amazon Alexa, what does it do?

04:56.000 --> 05:01.000
You are training it essentially through your commands.

05:01.000 --> 05:03.000
It's just speaking in the house.

05:03.000 --> 05:07.000
It gets from you data, but data on what?

05:07.000 --> 05:09.000
On you, on your preferences.

05:09.000 --> 05:15.000
So you are training it to learn how to give you good recommendations.

05:15.000 --> 05:20.000
So I don't know about you, but when Amazon recommends a book, I always want to read it because it knows me.

05:20.000 --> 05:28.000
When Spotify gives me a recommendation for music, invariably I like it, invariably, because it understands me really very well.

05:28.000 --> 05:38.000
So I'm training it to train me, to train it, to train me, to train it, to train me, so that at some point it can actually make a recommendation and then I can say, OK, I want that.

05:38.000 --> 05:49.000
And the fundamental thing, Tom, here is that this is not like standard advertising, where you see a poster, you buy Mercedes Benz, then you go to Mercedes Benz dealership

05:49.000 --> 05:58.000
and you get one. No. Alexa convinces you to buy something, exercise bike, whatever, a pair of binoculars.

05:58.000 --> 06:04.000
And then sells it to you, bypassing every marketplace in the world.

06:04.000 --> 06:07.000
Now that is a fiefdom, that is a market.

06:07.000 --> 06:22.000
And you see, and most income now that is accumulated is accumulating the form of rents that basis charges capitalists for access to this digital fiefdom.

06:22.000 --> 06:28.000
So we're going back to a system where access to the land, only this time it is digital land.

06:28.000 --> 06:43.000
It's what I call cloud capital, is restricted, crucial, outside the marketplace, outside capitalism, and procure a magnificent rent for the new cloud lords.

06:43.000 --> 06:44.000
That's a new system.

06:44.000 --> 06:47.000
And how are you defining these new cloud lords?

06:47.000 --> 06:50.000
Is it a question of the service space that they own?

06:50.000 --> 06:52.000
Is it how many customers they have?

06:52.000 --> 06:55.000
At what point does Walmart become Amazon?

06:55.000 --> 06:57.000
At what point does a taxi company become Amazon?

06:57.000 --> 07:00.000
Walmart has already become, Walmart is already a cloud fief.

07:00.000 --> 07:07.000
Because Walmart, very smartly, has developed its own competitor to Amazon.

07:07.000 --> 07:13.000
It is using its stores in order to build up its cloud fief.

07:13.000 --> 07:25.000
And now increasingly the profits, the net returns of Walmart come from the cloud, not from the analog buildings that it still has,

07:25.000 --> 07:29.000
which it uses in order to lure people effectively into the cloud.

07:29.000 --> 07:32.000
And you talk about this in a very sort of sinister way, almost.

07:32.000 --> 07:34.000
I mean, your book is quite gloomy.

07:34.000 --> 07:40.000
You know, some people would look at this and they would say they have decided to enter in with the relationship with Amazon.

07:40.000 --> 07:43.000
They have decided to upload their pictures to Instagram.

07:43.000 --> 07:46.000
They have decided to use WhatsApp as a way to...

07:46.000 --> 07:48.000
I don't think my book is at all gloomy.

07:48.000 --> 07:52.000
I try to write my book, you know, in a very jovial way.

07:52.000 --> 07:54.000
You could argue that people have...

07:54.000 --> 07:56.000
By the way, as a letter to my dad.

07:56.000 --> 07:57.000
Yes, yes.

07:57.000 --> 07:59.000
So I constantly have a little tiff with my dad.

07:59.000 --> 08:04.000
Because I try to imagine what he would have said to me and I try to answer to what I imagine he would have said to me.

08:04.000 --> 08:06.000
I think my book is a very pleasant read.

08:06.000 --> 08:11.000
It didn't feel that way to me, but I mean, I'm very optimistic about the future and what technology means.

08:11.000 --> 08:13.000
And I think there's something interesting...

08:13.000 --> 08:18.000
But that takes an incredible degree of naivety to be optimistic about the future.

08:18.000 --> 08:19.000
Doesn't it?

08:19.000 --> 08:22.000
There's no empirical evidence to support that anything good will happen.

08:22.000 --> 08:24.000
But where I agree with you...

08:24.000 --> 08:26.000
We have a lot of evidence that things have got better every year.

08:26.000 --> 08:28.000
Oh, no, no, no, no, we don't.

08:28.000 --> 08:32.000
Everything is getting far, far worse for the majority of the people on this earth, including climate catastrophe.

08:32.000 --> 08:33.000
Come on, Tom.

08:33.000 --> 08:35.000
But I'll tell you, I'll give you this.

08:35.000 --> 08:39.000
I'll give you this and let's see if we can converge.

08:39.000 --> 08:41.000
I'm hopeful.

08:41.000 --> 08:43.000
I'm not optimistic.

08:43.000 --> 08:50.000
I make it a very great distinction between optimism, which is the poor cousin of hope and hope.

08:50.000 --> 08:52.000
Hope we need to have.

08:52.000 --> 08:54.000
I love those technologies.

08:54.000 --> 08:56.000
Don't get me wrong.

08:56.000 --> 08:57.000
I'm not a Luddite.

08:57.000 --> 08:59.000
I mind you, Luddites are very misunderstood.

08:59.000 --> 09:02.000
They didn't, like, completely misunderstood.

09:02.000 --> 09:05.000
I love the Luddites, but you know what I mean.

09:05.000 --> 09:07.000
I'm not against machinery.

09:07.000 --> 09:12.000
I am absolutely enthusiastic, completely addicted to all those apps.

09:12.000 --> 09:18.000
For instance, I think the world of AI, I think AI may very well destroy us, but I love it.

09:18.000 --> 09:25.000
I absolutely adore the idea that there is AI today designing antibiotics that can kill superbugs

09:25.000 --> 09:29.000
that human minds cannot design and antibiotic against.

09:29.000 --> 09:30.000
That's brilliant.

09:30.000 --> 09:33.000
That's a triumph of the human spirit.

09:33.000 --> 09:44.000
But not to see that we have exponential concentrations of incomes

09:44.000 --> 09:52.000
in the hands of people who produce nothing except for the right and the opportunity to extract incomes from others

09:52.000 --> 09:57.000
while the world is going to the rocks in terms of the climate catastrophe.

09:57.000 --> 10:00.000
That we need to recognize if we are going to remain hopeful.

10:00.000 --> 10:09.000
I mean, you are a big study of history and you, in your books, talk a lot about technology,

10:09.000 --> 10:15.000
especially when it comes to capital, and you would look at most forms of technology

10:15.000 --> 10:18.000
and see them as levers to human potential.

10:18.000 --> 10:25.000
The loom obviously had big threatening impacts on the Luddites, hence their fight for fairness.

10:25.000 --> 10:30.000
But generally speaking, technology is a lever to allow us to create more wealth.

10:30.000 --> 10:38.000
Its distribution has not always been fair, but over a long period of time, the trend lines are fairly consistent.

10:38.000 --> 10:43.000
And especially since about 1910, global inequality has remained about the same.

10:43.000 --> 10:45.000
Since 1910.

10:45.000 --> 10:48.000
Since around about 1910, 1930 on a global scale.

10:48.000 --> 10:49.000
They remain the same.

10:49.000 --> 10:50.000
That is not true.

10:50.000 --> 10:51.000
That is not true.

10:51.000 --> 10:52.000
Broadly similar.

10:52.000 --> 10:55.000
It depends on whether you look at the top 0.1%.

10:55.000 --> 10:56.000
It depends on what you measure.

10:56.000 --> 10:57.000
I'm sorry.

10:57.000 --> 11:03.000
But my question is, I'm afflicted by an economic mind that refuses to see things.

11:03.000 --> 11:06.000
It's the 2022 World Inequality Report.

11:06.000 --> 11:07.000
It's roasted glasses.

11:07.000 --> 11:10.000
It's the 2022 World Inequality Report.

11:10.000 --> 11:12.000
And it's looked at things globally.

11:12.000 --> 11:14.000
And obviously no one lives in a global world.

11:14.000 --> 11:16.000
We all live in our own reality.

11:16.000 --> 11:21.000
To some extent, we have to wonder if it's about relative income or whether it's about absolute income.

11:21.000 --> 11:27.000
But at what point in the last few years, do you think we switched over to sort of techno feudalism?

11:27.000 --> 11:31.000
Is there a defining moment where you think we sort of reached this tipping point?

11:31.000 --> 11:34.000
Well, it's between 2008 and today.

11:34.000 --> 11:39.000
It's impossible to, it's like saying, you know, when did you become bald?

11:39.000 --> 11:45.000
Which hair did you lose so that you switched from being a person with hair to a bald person?

11:45.000 --> 11:48.000
There's no such hair that defines your transition.

11:48.000 --> 11:51.000
But I can tell you that it was around the night when I was in my forties.

11:51.000 --> 11:54.000
Similarly, the switch happened after 2008.

11:54.000 --> 11:57.000
And it happened because of 2008 to a very large extent.

11:57.000 --> 12:04.000
Because the way in which the G7 government and central banks responded to the great financial catastrophe

12:04.000 --> 12:11.000
by a combination of socialism for the bankers, you know, trillions pumped out of our central banks

12:11.000 --> 12:15.000
to go to the financial sector with huge austerity for everybody else.

12:15.000 --> 12:20.000
That starved, so you know, you create lots of money.

12:20.000 --> 12:27.000
You have liquidity that we never had in the history of the world, which never went into investment

12:27.000 --> 12:29.000
because of low levels of demand.

12:29.000 --> 12:35.000
So the companies that got this money from the central banks bought back their own shares that created asset price inflation.

12:35.000 --> 12:42.000
The only ones who invested were the cloud elists, the people who owned cloud capital, you know, the techno feudal lords.

12:42.000 --> 12:45.000
And, you know, wonderful machinery and all that.

12:45.000 --> 12:53.000
But that investment went into creating the cloud capital, which then replaced markets with platforms

12:53.000 --> 13:02.000
and shifted a very significant percentage of the circular flow of income from profits to rents.

13:02.000 --> 13:05.000
And that is destabilizing for the global system.

13:05.000 --> 13:11.000
What do you think the relationship between the rise of these tech companies and zero interest rates almost has been?

13:11.000 --> 13:12.000
It's what I said.

13:12.000 --> 13:13.000
Yeah.

13:13.000 --> 13:20.000
I mean, zero interest rates is what happens when you're trying to reflow the financial sector by printing huge amounts of money, right?

13:20.000 --> 13:24.000
I mean, the price of money is related to its supply.

13:24.000 --> 13:33.000
So when you boost supply, as if they do now tomorrow, then the price of money, which is related to interest, will go to zero and below zero, which is what happened.

13:33.000 --> 13:34.000
It's just interesting.

13:34.000 --> 13:42.000
When you try and find the sort of defining feature of what a tech company is versus what a tech company isn't, you can look at many things like network effects.

13:42.000 --> 13:44.000
You can look at the use of data.

13:44.000 --> 13:50.000
But one sort of interesting element, I guess, is to look at capital return and the degree to which they need to make a profit.

13:50.000 --> 13:51.000
That's all irrelevant.

13:51.000 --> 13:55.000
That is just mumbo jumbo, just trying to sound as if you're financially intelligent.

13:55.000 --> 13:56.000
I'm sorry.

13:56.000 --> 13:58.000
I'm intelligent about technology.

13:58.000 --> 13:59.000
Yeah, I'm sure.

13:59.000 --> 14:00.000
I'm sure.

14:00.000 --> 14:05.000
But from a socioeconomic point of view, what really matters is none of that.

14:05.000 --> 14:07.000
I don't care how you define a tech company.

14:07.000 --> 14:12.000
You can have a tech company that makes fantastic industrial robots.

14:12.000 --> 14:14.000
That's not cloud capital.

14:14.000 --> 14:15.000
It's beautiful.

14:15.000 --> 14:16.000
I love it.

14:16.000 --> 14:19.000
I see industrial robot assemble cars and microchips.

14:19.000 --> 14:20.000
Beautiful.

14:20.000 --> 14:22.000
It's like poetry in motion.

14:22.000 --> 14:23.000
A little bit of a body.

14:23.000 --> 14:24.000
Now, that's a tech company.

14:24.000 --> 14:25.000
Yeah.

14:25.000 --> 14:26.000
It's not what I'm talking about.

14:26.000 --> 14:37.000
I'm talking about companies that are investing in the creation of my definition of cloud capital, which is a produced means of behavioral modification.

14:37.000 --> 14:40.000
The difference between an industrial robot.

14:40.000 --> 14:43.000
Fantastic, technologically snazzy and so on.

14:43.000 --> 14:54.000
And Amazon, or for that matter, Facebook, is that the latter is not a produced means of production.

14:54.000 --> 14:58.000
It is a produced means of behavioral modification.

14:58.000 --> 15:09.000
So that cloud capital gives the owner an immense exorbitant power and privilege to alter people's behavior.

15:09.000 --> 15:24.000
In order to create alternatives to markets in which we are all caught up as buyers and sellers, but not within a market in which you can choose a partner and choose.

15:24.000 --> 15:26.000
The algorithms does the choice for us.

15:26.000 --> 15:31.000
And the algorithm chooses in a manner that maximizes cloud rents of the owners of that cloud capital.

15:31.000 --> 15:46.000
And you're sort of concerned that this becomes somewhat monopolistic because of the information they have on us making it hard to leave that ecosystem or because of their market share or because that's impossible for other people to enter the market.

15:46.000 --> 15:48.000
Or this isn't a sort of monopoly concern.

15:48.000 --> 15:52.000
Well, you see, I avoid the word monopoly.

15:52.000 --> 15:55.000
And I avoid it because a monopoly is a market.

15:55.000 --> 15:57.000
It's a monopolized market.

15:57.000 --> 16:05.000
My point about Alibaba, so I was not to talk only about, you know, Amazon, is that it is not a market.

16:05.000 --> 16:08.000
You see, and I tried to explain this in the book.

16:08.000 --> 16:20.000
Imagine you and I are entering a town in the United States of America, you know, back in the 19th century, let's make it a bit, you know, of a western movie, right?

16:20.000 --> 16:25.000
And we discovered that every shop in the town belongs to one man.

16:25.000 --> 16:27.000
You've seen westerns like that, right?

16:27.000 --> 16:28.000
And there's a showdown.

16:28.000 --> 16:31.000
It would be more that one person owns the land.

16:31.000 --> 16:32.000
No, no, no.

16:32.000 --> 16:42.000
Suppose that this person owns the bar, the saloon, the, you know, the shops, the hotel, everything, everything, the post office, the sheriff.

16:42.000 --> 16:43.000
Okay.

16:43.000 --> 16:45.000
You've seen these movies with John Wayne and so on.

16:45.000 --> 16:46.000
Right.

16:46.000 --> 16:48.000
Now that's a monopolized market.

16:48.000 --> 16:49.000
A monopolized town.

16:49.000 --> 16:51.000
You and I walked down the store.

16:51.000 --> 16:53.000
We know it belongs to that one person who owns everything.

16:53.000 --> 16:56.000
He has immense monopoly power over everyone in that town.

16:56.000 --> 17:00.000
But in Alibaba, for example, 100% their revenues from third parties.

17:00.000 --> 17:02.000
Wait, wait, wait, wait, wait, wait, wait.

17:02.000 --> 17:04.000
In Amazon, 45% of their revenues.

17:04.000 --> 17:06.000
You're missing the point of my allegory here.

17:06.000 --> 17:08.000
I have a western movie allegory.

17:08.000 --> 17:09.000
Let's not lose it.

17:09.000 --> 17:10.000
Okay.

17:10.000 --> 17:13.000
The point I'm trying to make is this is a monopolized market, right?

17:13.000 --> 17:22.000
But Alibaba and Amazon are not because in that town, in the western movie, you and I, Tom, we're walking down the street, right?

17:22.000 --> 17:24.000
And we look at the shop window.

17:24.000 --> 17:26.000
You and I see the same thing.

17:26.000 --> 17:28.000
We may not buy it.

17:28.000 --> 17:33.000
We may say, you know, let's not give our money to this terrible man who owns everything, right?

17:33.000 --> 17:34.000
But we converse.

17:34.000 --> 17:35.000
We see the same thing.

17:35.000 --> 17:44.000
If you and I had our laptops here and we went to Alibaba or Amazon and we typed extravagant binoculars.

17:44.000 --> 17:47.000
You see different things to what I'm going to see.

17:47.000 --> 17:53.000
The algorithm knows you, knows me and calibrates what we see and it does not select the same thing.

17:53.000 --> 17:55.000
So we don't even see the same things.

17:55.000 --> 17:56.000
That's not a marketplace.

17:56.000 --> 17:57.000
It's not a monopolized market.

17:57.000 --> 17:59.000
It is not a market.

17:59.000 --> 18:15.000
It is an algorithm like a Soviet economic system which decides who does what with whom, without any consultation, without any way that you and I can communicate as buyers or you as a seller and me as a buyer.

18:15.000 --> 18:20.000
No way that we can communicate unless the algorithm chooses for us to communicate.

18:20.000 --> 18:23.000
I mean, some people would call that personalization.

18:23.000 --> 18:24.000
That's all rubbish.

18:24.000 --> 18:26.000
It is not a market.

18:26.000 --> 18:27.000
You can call it whatever.

18:27.000 --> 18:29.000
You can call it Snoopy Do.

18:29.000 --> 18:31.000
It is not the point I'm making.

18:31.000 --> 18:33.000
It's not the market, right?

18:33.000 --> 18:42.000
And it is an algorithm which matches the people who are selling with the people who are buying in the interest, not of the seller even.

18:42.000 --> 18:44.000
That could be monopoly.

18:44.000 --> 18:50.000
But of the rentier or the landlord of that cloud capital.

18:50.000 --> 18:52.000
That's the point I'm making.

18:52.000 --> 18:54.000
What do you think is the solution to all this?

18:54.000 --> 18:56.000
How are things going to progress from here?

18:56.000 --> 18:59.000
Can technology be the fix as well as the problem?

18:59.000 --> 19:01.000
Technology has never been the fix.

19:01.000 --> 19:05.000
To the problems we create with the technology, the problem is political.

19:05.000 --> 19:06.000
It's social.

19:06.000 --> 19:16.000
So, you know, steam engines were not responsible for the awful conditions of the working class in Manchester when the first dark satanic meals were put together, right?

19:16.000 --> 19:18.000
And the solution was not technology.

19:18.000 --> 19:24.000
The solution was, you know, social, political interventions.

19:24.000 --> 19:26.000
That will always be the case.

19:26.000 --> 19:30.000
So, I don't blame the technology and therefore I do not expect the technology to solve the problem.

19:30.000 --> 19:32.000
The question is who owns what?

19:32.000 --> 19:38.000
You see, some people are very worried about surveillance.

19:38.000 --> 19:41.000
That, you know, these companies know so much about us.

19:41.000 --> 19:43.000
I'm not that bothered personally.

19:43.000 --> 19:45.000
I mean, I understand why people are worried.

19:45.000 --> 19:52.000
I'm slightly worried, but I'm far more worried by what they own.

19:52.000 --> 20:07.000
They own this capital, which is a capacity to separate us, to fragment us as markets, as communities, as societies, to influence us in ways we don't understand.

20:07.000 --> 20:10.000
In ways that the people who wrote the algorithms do not understand.

20:10.000 --> 20:13.000
This is even more worrying, right?

20:13.000 --> 20:16.000
You hear that from coders, from AI and so on.

20:16.000 --> 20:18.000
It becomes ever more true, like AI is a good example.

20:18.000 --> 20:19.000
People are surprised.

20:19.000 --> 20:26.000
So, for me, as an old lefty, the answer must always be the socialization of the means of production.

20:26.000 --> 20:32.000
In some ways, technology has been a force to kind of democratize access to wealth creation.

20:32.000 --> 20:33.000
So, now it's...

20:33.000 --> 20:35.000
You live in a different universe, right?

20:35.000 --> 20:37.000
There are plenty of...

20:37.000 --> 20:38.000
Democratization.

20:38.000 --> 20:39.000
What democratization?

20:39.000 --> 20:40.000
We have exactly the opposite.

20:40.000 --> 20:48.000
We live in a world where three companies, BlackRock, State Street and Vanguard, own 90% of all the companies in the New York Stock Exchange.

20:48.000 --> 20:49.000
We're talking about democratization.

20:49.000 --> 20:50.000
They don't own 90%.

20:50.000 --> 20:55.000
They all have a majority shareholding together in 90%.

20:55.000 --> 20:57.000
Again, nitpicking.

20:57.000 --> 20:59.000
This is...

20:59.000 --> 21:03.000
Adam Smith is the patron saint of the factory market.

21:03.000 --> 21:10.000
He would be a gust hearing you talk about the democratization of capitalism.

21:10.000 --> 21:14.000
For him, what we now have would be a nightmare.

21:14.000 --> 21:21.000
But you could argue that a platform like Shopify makes it easy for people without many means to set up a store.

21:21.000 --> 21:28.000
You could argue that YouTube gives an opportunity for anyone in the world to make a world-class documentary and they can make money from advertising.

21:28.000 --> 21:37.000
You could argue that Facebook has democratized access to advertising tools that allow people to buy media at the same rate as bigger companies.

21:37.000 --> 21:40.000
I got my line with almost all of your thinking.

21:40.000 --> 21:48.000
I just think it's a little bit unfair to look at some of the dynamics that provide access to people in a more level way.

21:48.000 --> 22:00.000
And to some extent, the data that allows a marketplace to personalize what they offer actually works in favor in some cases of smaller companies that use these...

22:00.000 --> 22:02.000
That last sentence is absurd.

22:02.000 --> 22:04.000
Everything else you said before was fine.

22:04.000 --> 22:06.000
The conclusion was absolutely absurd.

22:06.000 --> 22:08.000
You will allow me to say, right?

22:08.000 --> 22:18.000
Now, listen, there is no doubt that Amazon gives every day fantastic opportunities to producers to reach customers.

22:18.000 --> 22:20.000
There's no doubt about that.

22:20.000 --> 22:22.000
Shopify does the same thing.

22:22.000 --> 22:30.000
Not this is ancient, but all the paraphernalia of podcasting and so on allows all of us to be broadcasters.

22:30.000 --> 22:33.000
That is all perfectly true.

22:33.000 --> 22:35.000
And it's great.

22:35.000 --> 22:45.000
However, the point I'm making is that the techno feudal forces at work, which are based on the money in which cloud capital operates,

22:45.000 --> 22:56.000
are ensuring that all those people who create businesses and sell stuff through Amazon or Shopify and so on in the end become vassals.

22:56.000 --> 23:02.000
Because landlords under feudalism did allow people to actually do things.

23:02.000 --> 23:04.000
They gave them land, they gave them the opportunity to produce stuff.

23:04.000 --> 23:08.000
They were called vassals in the sense that they were complete, dependent on the landlord,

23:08.000 --> 23:15.000
who actually grabbed rent out of them until he squeezed the living wits out of them.

23:15.000 --> 23:17.000
This is precisely what we're having.

23:17.000 --> 23:23.000
We're having machinery and cloud capital that allows us to do a lot of stuff, right?

23:23.000 --> 23:25.000
Podcasts and so on.

23:25.000 --> 23:32.000
That said, if you look at the concentration of the capacity to influence public opinion,

23:32.000 --> 23:45.000
we've never had less of a free press than we have today within the context of each one of us being able to be a small BBC or Euro news or whatever.

23:45.000 --> 23:51.000
I guess when I hear a lot of what you say, the sentiment that you have is something that I agree with entirely.

23:51.000 --> 24:01.000
I'm personally by no means a fan of Amazon or any of these tech giants and I hate the level of influence they have over our lives.

24:01.000 --> 24:04.000
But I think of it more in terms of algorithmic persuasion.

24:04.000 --> 24:15.000
I think of it more in terms of slightly sociopathic tendencies to monetize our attention in ways that leads us to be more angry with each other than we should be.

24:15.000 --> 24:23.000
So I wonder sometimes if maybe the real brunt of your concern is not more about algorithms and the way that they're used.

24:23.000 --> 24:28.000
I love algorithms. The question is who owns the bloody thing, right?

24:28.000 --> 24:35.000
If one person owns the algorithm that controls billions of people, then we have something worse than 1984.

24:35.000 --> 24:38.000
We're shifting towards Brave New World.

24:38.000 --> 24:40.000
There's sort of opening up access to algorithms.

24:40.000 --> 24:43.000
You see, 1984 was a problem of surveillance.

24:43.000 --> 24:49.000
Brave New World is a problem where we are all happy little slaves who love slavery, right?

24:49.000 --> 24:54.000
And that is a problem. If you are a liberal, if you believe in freedom, if you believe...

24:54.000 --> 24:58.000
But also there's something else that really worries me.

24:58.000 --> 25:06.000
You talked about algorithms that are primed to maximize rage and outrage and intolerance.

25:06.000 --> 25:13.000
We all know that, right? You only need to go on ex-formerly Twitter to five minutes of that.

25:13.000 --> 25:17.000
Who said that? I think it was Stephen Fry who said something brilliant.

25:17.000 --> 25:19.000
He said this quite a long time ago before Musk.

25:19.000 --> 25:27.000
It's a bit like taking everything which is written on the walls of mail toilets around the world and posting it online.

25:27.000 --> 25:30.000
So yeah, I agree with you. But think of this.

25:30.000 --> 25:34.000
If my macroeconomic analysis in the book is right,

25:34.000 --> 25:42.000
we have a situation where, as David Ricardo in 1809 wonders,

25:42.000 --> 25:54.000
if you have an economic system where increasing percentages of income are siphoned off the cycle of investment by renteers.

25:54.000 --> 25:59.000
He was talking about the corn laws back then, due to the Napoleonic Wars.

25:59.000 --> 26:11.000
The war in Europe then, the Napoleonic Wars, were a boon to landlords because they didn't have to compete with imported corn.

26:11.000 --> 26:18.000
And therefore they managed to charge higher and higher rents on the producers of corn who used their land.

26:18.000 --> 26:25.000
But because they just simply got rich in their sleep because it was rent, it was not capitalist profit.

26:25.000 --> 26:31.000
It was as if this money, this economic energy was taken out of the circular flow.

26:31.000 --> 26:35.000
There was less investment and the whole system was becoming degenerate.

26:35.000 --> 26:37.000
So I'm telling a similar story.

26:37.000 --> 26:47.000
If increasing quantities of economic energy are being siphoned off as rents by the owners of those cloud thieves, these platforms,

26:47.000 --> 26:53.000
then that explains to a very large extent why we have inflation.

26:53.000 --> 26:56.000
Central banks continue to print money.

26:56.000 --> 26:57.000
Why?

26:57.000 --> 26:59.000
Even though you have inflation?

26:59.000 --> 27:09.000
Well, because aggregate demand is shrinking as a result of the fact that a lot of wealth is being siphoned off the circular flow of income in the form of cloud rents.

27:09.000 --> 27:18.000
So you have inflation, you have bullshit jobs, as David Greber scientifically put it.

27:18.000 --> 27:26.000
You have discontent building up with our central banks, with our governments, with markets, with inflation.

27:26.000 --> 27:33.000
And then you have those algorithms that make a lot more money out of priming the outrage.

27:33.000 --> 27:39.000
And then the more they prime the outrage, the more they extract money from the circular flow of income and the more outrage there is.

27:39.000 --> 27:41.000
That spins out of control.

27:41.000 --> 27:43.000
And what becomes the endpoint for this?

27:43.000 --> 27:45.000
The end of civilization.

27:45.000 --> 27:46.000
Okay.

27:46.000 --> 27:49.000
This is not going to be good.

27:49.000 --> 27:52.000
I don't think anything good is going to come out of it.

27:52.000 --> 27:59.000
I'm not one of those left-wing revolutionists who think, like Lenin once said, that the worst things get the better it is.

27:59.000 --> 28:00.000
I don't believe that.

28:00.000 --> 28:07.000
I've seen, in this country, in Greece, I've seen the deterioration of living standards year after year after year.

28:07.000 --> 28:09.000
And that only produces Nazis.

28:09.000 --> 28:10.000
Nothing good.

28:10.000 --> 28:20.000
And when you look towards a tool like AI, can you see that as being something to bring us out of that spiral?

28:20.000 --> 28:22.000
No technology will bring us out.

28:22.000 --> 28:26.000
I mean, in a good society, we will be using AI all the time.

28:26.000 --> 28:28.000
All the time.

28:28.000 --> 28:33.000
We no longer need, for instance, teachers training us to do things.

28:33.000 --> 28:35.000
We need teachers to educate us.

28:35.000 --> 28:39.000
But the training can be subcontracted to AI beautifully already.

28:39.000 --> 28:41.000
So I love it.

28:41.000 --> 28:48.000
But it will not solve the problem of the cloudelists, as I call them, exorbitant power of the rest of society.

28:48.000 --> 28:53.000
If anything, it will make it worse because AI makes the algorithms faster and better.

28:53.000 --> 29:08.000
How do you sort of reconcile in your mind these sort of cloud owners with forces for absolute evil versus companies that have elements to what they do, which is beneficial to society?

29:08.000 --> 29:14.000
One could look at YouTube and see how that could educate people across the world who otherwise wouldn't have access to books.

29:14.000 --> 29:20.000
Is it possible in your head to sort of reconcile what's a good use of server-based technology and what's bad?

29:20.000 --> 29:21.000
Of course, absolutely.

29:21.000 --> 29:29.000
There are a lot of fantastic and fully humanist uses of technology today.

29:29.000 --> 29:37.000
The question is, where is humanity as a whole being led by the more powerful forces to work within it?

29:37.000 --> 29:39.000
That is the question.

29:39.000 --> 29:51.000
And we have to constantly be on the lookout for good uses of technology, which are all over us, for ideas of how society should be functioning, designed.

29:51.000 --> 29:54.000
What its architecture should be.

29:54.000 --> 30:02.000
How do you see these conversations progressing in the context of global climate change and move towards net zero?

30:02.000 --> 30:07.000
Do you think of that as being again a sort of catalyst to bring the end closer?

30:07.000 --> 30:15.000
Do you think of it as an environment which changes people's motivations away from consumption in a way that helps decelerate this change?

30:15.000 --> 30:16.000
No, that's the opposite.

30:16.000 --> 30:28.000
Because in the same way that the algorithms are primed to excite intolerance in our souls, they are primed to make us buy things that we neither need nor want,

30:28.000 --> 30:35.000
and to forget about difficult things like the climate crisis.

30:35.000 --> 30:41.000
Of course, these algorithms are essential in fighting the climate crisis.

30:41.000 --> 30:53.000
So if we as a society, as a community, as a League of Nations or societies, if we could agree to stop drilling for oil and, you know,

30:53.000 --> 30:59.000
force influence more generally, if we agree to end the wars, that would be very helpful.

30:59.000 --> 31:03.000
War doesn't help the climate in the slightest.

31:03.000 --> 31:08.000
Then we would design our new green energy grids.

31:08.000 --> 31:18.000
And you can only design it if you have very strong use of fantastic algorithms that are necessary in order to ensure that the peak load is always used properly,

31:18.000 --> 31:26.000
that, you know, wind, solar and other renewables are combined in the optimal manner.

31:26.000 --> 31:37.000
So, like the beginning of time, our technologies are a force for good and for a force of evil.

31:37.000 --> 31:39.000
And if evil prevails, it is our fault.

31:39.000 --> 31:44.000
I think I want you to leave on some action that we can take.

31:44.000 --> 31:50.000
You know, like, I love what you say makes me feel like we're at this sort of liminal point.

31:50.000 --> 31:51.000
Okay, I will.

31:51.000 --> 31:55.000
If things work out well or badly, what can we do to ensure that we get to a better place together?

31:55.000 --> 31:58.000
Well, I think that we should concentrate on two things.

31:58.000 --> 32:04.000
Firstly, we must end free services, because you don't need me to explain that.

32:04.000 --> 32:11.000
When you have free services affected, if you've got the complete tyranny of the cloud capitalist or the cloudless,

32:11.000 --> 32:16.000
it would be fantastic if we had subscript micropayments, a micropayment system.

32:16.000 --> 32:21.000
And if some people can't afford it, they should get social security payments in order to make for these micropayments.

32:21.000 --> 32:23.000
So you're creating an app, right?

32:23.000 --> 32:29.000
You get paid directly by the person who is using the app, not indirectly through advertising,

32:29.000 --> 32:35.000
because that way you do not have this complete takeover of our souls.

32:35.000 --> 32:37.000
That's one thing.

32:37.000 --> 32:44.000
The second thing is fantastic if we started thinking in terms of changing corporate law.

32:44.000 --> 32:46.000
Imagine, just imagine.

32:46.000 --> 32:49.000
I know it sounds like science fiction, but technically it's really very simple.

32:49.000 --> 33:01.000
Imagine that you and I, if we were to form a company or 30 of us, 40 of us, we form a cooperative and we have one share each.

33:01.000 --> 33:12.000
Imagine if every company, especially large companies, had a share structure whereby every employee had one share which could not be traded.

33:12.000 --> 33:20.000
In the same way as a university student gets a library card or a student union card when they enroll,

33:20.000 --> 33:26.000
and then they have to hand it over or it becomes invalid when they leave, when they graduate.

33:26.000 --> 33:31.000
They cannot sell it, they cannot buy it, but they can use it to vote, they can use it to take books out,

33:31.000 --> 33:34.000
they can use it to use the internet and so on.

33:34.000 --> 33:39.000
Imagine if that's how shares were and they gave you one vote in the company and you worked.

33:39.000 --> 33:42.000
It didn't mean equality because we could vote.

33:42.000 --> 33:50.000
The person who actually creates the really good stuff which allows our company to do well, we should give more money to him or her.

33:50.000 --> 33:52.000
Imagine that.

33:52.000 --> 33:55.000
That would be a magnificent revolution.

33:55.000 --> 33:58.000
It would end share markets and labour markets in one go.

33:58.000 --> 34:00.000
And then you would have no state.

34:00.000 --> 34:07.000
You had market-based cooperatives owning the algorithm but in a way that is not predatory.

34:07.000 --> 34:15.000
And if they had to receive micropayments from those who actually use them, the algorithms,

34:15.000 --> 34:22.000
then we would be talking about technology in the interest of a combination of freedom and justice.

34:22.000 --> 34:23.000
Okay.

34:23.000 --> 34:29.000
So something kind of rooted in philosophy almost as like a DAO or something sort of based on blockchain

34:29.000 --> 34:31.000
or does the technology not matter?

34:31.000 --> 34:33.000
The technology doesn't matter.

34:33.000 --> 34:36.000
So what I described, you could do it with pieces of paper really.

34:36.000 --> 34:40.000
It helps to have an algorithm.

34:40.000 --> 34:46.000
Blockchain might be useful but the problem with blockchain is that it has become a religion.

34:46.000 --> 34:52.000
And you have people who religiously hate it and people who religiously adopt it.

34:52.000 --> 34:55.000
And I'm just not a religious person when it comes to these things.

34:55.000 --> 34:57.000
I think horses for courses.

34:57.000 --> 34:59.000
Blockchain can be very useful.

34:59.000 --> 35:01.000
I mean, J.B. Morgan uses it internally.

35:01.000 --> 35:03.000
If they use it internally, we should use it internally.

35:03.000 --> 35:07.000
But we must not think that blockchain is the answer.

35:07.000 --> 35:08.000
Blockchain is a tool.

35:08.000 --> 35:09.000
That makes sense.

35:09.000 --> 35:18.000
So when it does come to your wildest prediction, in some ways you're thinking that perhaps this could be the start of the downfall of civilization

35:18.000 --> 35:21.000
or you're also open-minded to there being other ways.

35:21.000 --> 35:23.000
I maintain hope.

35:23.000 --> 35:28.000
Hope is my duty and I cling on to it against all empirical evidence.

35:28.000 --> 35:30.000
That makes absolutely sense.

35:30.000 --> 35:32.000
Janne is very flacky. Thanks very much.

35:32.000 --> 35:33.000
Thank you, Tom.

35:33.000 --> 35:34.000
Thank you.

35:34.000 --> 35:35.000
Very good.

35:35.000 --> 35:37.000
Have a good time.

35:37.000 --> 35:38.000
That was good.

35:38.000 --> 35:39.000
It was fun.

