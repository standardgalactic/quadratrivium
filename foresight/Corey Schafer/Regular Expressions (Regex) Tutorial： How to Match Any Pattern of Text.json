{"text": " Hey there, how's it going everybody? In this video we're going to be learning how to use regular expressions. So we're actually going to look at regular expressions as a standalone topic because they aren't specific to any one programming language. Now there are some slightly different flavors here and there, but for the most part, whether you're programming in Python or JavaScript or Java or whatever, if you learn how to use general regular expressions, then it should mostly carry over into your language of choice. And it will also allow you to use them in text editors and the command line and things like that. Now I am going to do a follow up video where I show how to use regular expressions specifically in Python since that's a language that I cover most on this channel. But for this video, we're going to be learning how to use regular expressions by themselves so that you can apply these to other areas. So with that said, let's go ahead and get started. So regular expressions basically allow us to search for specific patterns of text. And they can look extremely complicated. But that's mainly because there's just so much that you can do with them. You can create a regular expression for just about any pattern of text that you can think of. So let's see what some of these look like. So I have a test file open here that we're going to use to search for specific patterns. And I'm going to be using the regular expression tool in the atom text editor to write these regular expressions and find what text matches our patterns. Now in order to open up this regular expression search tool, I'm just going to go to find and then find in buffer. Now you could have also opened this up with command F on a Mac. And I believe that's control F on Windows. Now within the options here, make sure that you have the dot asterisk selected over here because that's going to tell our search tool to use regular expressions. And also select this match case option here as well. That's just going to give us behavior that is more common to how regular expressions usually behave. Okay, so let's start writing some regular expressions. And first we'll start off kind of simple. So first of all, we can just search for literal characters. So if I was to search for ABC, then we can see here at the top that it highlighted ABC because it matched the ABC and our lowercase alphabet. Now it didn't match the capital ABC here because it's case sensitive. Now this search right now is looking specifically for A, B, and C. But if I was to type in something like BCA, then we can see that there were no results found because the order does matter. Now if we look at this meta character section here, I have some examples of characters that I say need to be escaped. So for example, if you wanted to search for a literal period, now if I was to just type in a period here and hit enter for my search, then we can see that it does this weird thing where it matches everything. And that is because the dot is a special character in regular expressions. And we'll see more of this in just a second. But for now, if we just wanted to actually search for a period or a dot, then we have to escape it. And to escape characters, we can use the backslash. So if I do a backslash and search, then now we can see that it only matches the actual literal dot or period within our document here. And that goes for any of these meta characters that I've listed here. So for example, we can see that the backslash is a special character also. So if you wanted to search specifically for a backslash, then you have to escape itself. So a backslash to escape, and then a backslash for the search. And if I search for that, then we can see that we matched a literal backslash. So a practical example of this might be trying to match this URL right here. So if we wanted to match that literal URL, exactly, then we could just say corey Ms. And then for the dot on the dot com, we have to escape that with a backslash and then a period, and then a com. And we can see that it matches our URL. Okay, so that's how you match literal characters. But a literal search isn't too exciting, because we're used to that already. Really, we want to use regular expressions to search for patterns. And to do this, we're going to be using some of these meta characters that we were just escaping. So I have a snippets file open here. So I'm going to switch over to this. And in here, I have a list of values where we can see the types of characters that we can match. Now just for now, I'm going to try to make this into a split screen here, as we're walking down this list. So the first one I have listed here is this dot or period. And we can see that this matches any character except a new line. Now we've already seen this, but let's take a look again. If we just do a dot and search for that, then we can see that it matches any character except it does not match the new lines. Okay, so next on the list is backslash D. And that matches any digit zero through nine. So if I was to do a backslash D here and search for that, then you can see that this matches all of our digits. So anything zero through nine, it matches. Now we also have an uppercase D here. And that matches anything that is not a digit. So if I search for an uppercase D, then we can see that our digits are not matched. But everything else is highlighted. So it matched everything except for the digit. Now you'll notice that this is a common theme here that the uppercase versions of all of these are the ones that kind of negate the search. So moving on down here, we have backslash w that searches for any word character and a word character is lowercase a through z uppercase a through z zero through nine and an underscore. So let's search for the word character. And we can see that it matches, you know, all these lowercase uppercase numbers and things like that. It doesn't match these special meta characters here. And just like with the digit, the uppercase w will match anything that is not a word character. So anything that is not in this list here. So let's go ahead and search for that uppercase w. And we can see that, you know, it picks up the spaces and these special punctuations and things like that. But it does not match the word characters that we saw before. Now, if you're not quite getting this just yet, we are going to look at a lot of examples to where it'll start to sink in. So moving down the list here, we have backslash s, which will match any white space. And white space is a space tab or a new line. So if we search for backslash s, then we can see that it matches our new lines here and our spaces, but it doesn't match any of these characters in here. So it's mainly white space. And just like with the others, the capital s will search for anything that is not white space. So now you can see that we have, you know, all these lowercase uppercase digits and then also this punctuation, anything that isn't a new line or a space or anything like that. Now these bottom ones over here, the backslash b, the carrot and the dollar sign, these ones are a little bit different. So these are called anchors. And they don't actually match any characters, but rather they match invisible positions before or after characters. So let's see what I mean by this. So for a word boundary, if I search for a word boundary here. So now let's search for where we have this ha ha ha here. Let's search for a word boundary and then ha and match that. So we can see that that matched because there is a word boundary here at the start of this line before this first one here. And this space here is also word boundary. So this one gets matched as well. But this last one does not get matched because there's no word boundary between these two ha's here. Now just to show what this would look like without the word boundary. If I was to search for that, then you can see that it highlights all three of those. Now just like with the other ones, if I do a an uppercase b, then that matches anything that is not a word boundary. So if I do an uppercase b, then we can see that we match the one that it didn't match before, because there is no word boundary between these two here. So it doesn't match these first two. Now if I was to put word boundaries on both sides of these, then it should only match this first one, because this is the only one that has a word boundary at the beginning, which we're matching here, and at the end. So this one has a word boundary at the beginning, but not at the end because it's in the middle of this word. And this one has a word boundary at the end, but not at the beginning. Okay, so our other two anchors here are pretty similar. So the carrot matches the position at the beginning of a string, and the dollar sign matches the position at the end of a string. So let's say for example, that we only wanted to match a ha if it was at the beginning of a string. So for example, if I was to do a carrot and then a ha and match that, then we can see that it only matched this one, because it's the only one that is at the beginning of a line. Now if we wanted to only match it if it was at the end, then we could put that dollar sign at the end. And what we're saying here is that we only want to match this if the end of the string is the is in the following position. So we can see that it not only matches this last one, because the end of the string is the next position in line. Okay, so now that we've seen what we can match with these special characters here, now let's go ahead and take a look at some practical examples. So I'm going to move my snippets file back here, and we will keep referencing that later on. But for now, let's go ahead and say that we wanted to match a couple of phone numbers. And let's write some regular expressions to do this. Now with a phone number, we can't just type in a literal search like we did before, because all of these are different. So they have a similar pattern, but they're not all the same digits. So in this case, we need to use the meta characters instead of literal characters. So we just have a pattern here of three digits, and then a dash or a period, and then three more digits, and then a dash or a period, and then four digits at the end. So we saw before that we can match a digit with a backslash d. And that is going to match all of the digits in our file. So we want to match this phone number here. So we want to match first three digits in a row. So we can just put in three backslash d's, and that will match any three digits in a row. So now that we're matching those first three digits, now we're getting to where we can see that we're either going to match a dash or a dot in our phone number. So for now, let's just match any character that's in this position. So from our snippets file, we saw that if we want to match any character that we can use a dot. So we can see that for now, our pattern is still matching some other stuff as well. But let's just continue on. So now that we're matching this hyphen or this dot, now let's go ahead and add in the next three digits. So we want to search for three more digits. So I'll do three backslash d's. And now we're going to want a dot to match any character, which should match that dash or that dot. And now we want four digits. So we can just do four backslash d's. So now we can see that this regular expression highlights both of our phone numbers and matches both of those. So now we're starting to see how this could be pretty useful. So for example, I have a data file here. Now if I pull this up, then I have a bunch of fake names and numbers and addresses and emails. But if I wanted to match all of the phone numbers in this file, then you can see that the regular expression that we just wrote matches all of the phone numbers here. So now we're starting to kind of get a sense of how this could be more useful than just a literal search, because now we're actually searching for a specific pattern. So now let me go back to our simple text file here. So now let's get a little bit more specific. So let's say that we only wanted to match a phone number if it had a dash or a dot. Now right now, this pattern will match any separator, because we're using the period down here, which will match any character. So if I was to put in a another number here that doesn't have a regular separator, let's just say it's an asterisk, then we can see that it matches this number as well, even though the asterisk isn't really a phone number separator. So to only match the dash or the dot, we're going to have to use a character set. And a character set uses square brackets with the characters that we want to match. So to create a character set, I'm going to replace our first dot here. And this is going to be square brackets. Now this is a character set. Now within this character set, we want to put the characters that we want to match. So we want to match either a dash or a dot. And I will just copy that and we'll replace this second dot here, which was matching any character. And we will put that in for that as well. And now you can see that it only matches our phone numbers here that have a dash or a dot separator. And it does not match this one with the weird asterisk there. Now you probably also notice that we didn't need to escape our dot character within our character set. And that's because character sets have some slightly different rules. Now you can escape these characters if you'd like. But it just makes it a lot more difficult to read if you do that. Now even though the character set has multiple characters here in the set, it's still only matching one character in our text. It's matching one character that is either a dash or a period. But if I was to put in, let's say two dashes here into one of these numbers, then you can see now it doesn't match that number because it's only matching the first dash or a dot. And then it moves right on to looking for a digit. So it's looking for a digit in this position. So that's something that can kind of throw people off when they first start working with regular expressions. So even though, you know, we have four characters total here in this character set with these square brackets, and all of the characters in this set, it's still only searching for one literal character up here, which is either a dash or a dot. Now to show another example of this, let's say that we only wanted to match 800 and 900 numbers. So I'm going to create two different numbers here. I'll do an 800 number and a 900 number here. So if we only wanted to match 800 and 900 numbers, then our first three digits here, we have to do something different. So first, we want the first digit that we're going to match to either be an eight or a nine. So we can do a character set. And we can say that we're looking to either start with an eight or a nine. Now the following two numbers are going to be zero zero. And that's just a literal search. So now you can see that we're finding the 800 and 900 numbers here. Now within our character set, the dash is actually a special character as well. So when it's put at the beginning or the end of the character set, then it will just match the literal dash. But when it's placed between values that can actually specify a range of values. So for example, we know that the backslash D matches any digit. But what if we only wanted to match digits between let's say one and seven. So to do that, we can use a character set. And we can just say instead of typing out 1234567, if we wanted to specify a range of those values, then we can just say one dash seven. So now we can see that we're matching all of the digits between one and seven, but the eight, nine and the zero aren't getting matched up here. Now you can do this with letters as well. So if we only wanted to match the lowercase letters a through Z, then we could just do a character set of a through Z. Now you can see all of the capital letters aren't getting matched, but the lowercase ones are. Now if we wanted to match the uppercase and lowercase numbers, then we could just put our ranges back to back. So I could say a through Z and then just add on to this character set and say capital A through capital Z. And now we're matching all letters, regardless of whether they are uppercase or lowercase. And you could keep adding to those ranges. If you wanted to, you could do a zero through nine there as well, to add in all digits. Now another special character in our character set is the carrot. Now we saw before that outside of the character set, it matches the beginning of a string, but within the character set, it negates the set and matches everything that is not in the set. So for example, if we wanted to match every character that is not a lowercase letter, then we could say this carrot and then A through Z. So we can see that it matches everything on our screen that isn't a lowercase letter. It's not matching these lowercase letters here. So it's even matching these new lines and the spaces and everything. So just to show another example of this, let's say that we had some words here, cat, mat, pat, and bat. So let's say that we wanted to match every word that ends in A-T, except bat. We don't want to match bat. So to do this, we can just say that we want a character set of everything that is not B, followed by A-T. So now we can see that it matches all of these three letter words that end in A-T, except for bat, because our character set here negated that B. So everything that we've looked at so far has involved single characters. So in this example right here, we're matching any single character that is not a B, then followed by an A, and then followed by a T. But we can actually use these things called quantifiers to match more than one character at a time. So let's go back to our original phone number example from earlier, and we'll just match any character like we did before. So I will do three digits and then a period for any character, and then three digits again, and a period for any character, and then four digits at the end. And I'm just going to remove what we had there for an example and scroll those back up. So to see what quantifiers we have available, I'm going to make my snippets half of my screen here again, and then scroll down to my quantifiers section. So the asterisk will match zero or more of what we're searching for. The plus sign will match one or more. The question mark will match zero or one. And to match exact numbers, we can use these curly braces with a number on the inside. So in this example, this would match exactly three of what it is we're looking for. And we can also specify a range of numbers as well, with the first number being the minimum, and the last number being the max. So this would search for whatever our pattern is. It would look for three or four of those. So let's take a look at an example of this to see how this works. So you can see that with our phone number, we are searching for one digit at a time. But we could change this. If I erase my digits here, then we could say that I'm searching for a digit. And then we could put in our quantifier for exactly three digits. And we could do this after our separator as well. So we're searching for three digits, and then any character. And then here at the end, we want to match four digits. So instead of writing out the same characters over and over, we can see how these quantifiers allow us to specify exactly how much we want. Now here we're matching exact numbers. But sometimes we don't know the exact number. And we'll need to use one of these other quantifiers. So for example, here at the bottom of this test file here, we have some lines where each starts with a prefix of mister, or miss, or misses. So let's say that we wanted to match these prefixes, as well as the names after. So just to start, let's start by matching the names that start with mister. Now we can see that some of these have a period after the prefix, and some do not. Some of them just have a space. So let's start our regular expression by searching for lines that start with mister. And then we're going to put a backslash period to search for that literal period. And right now it isn't matching this mister Smith, which doesn't have a period after the prefix. Now to match that also, we can use this question mark quantifier, which tells our pattern that we want to match zero or one of that character. So if I put a question mark after that literal period, then it's saying that there can be zero periods there, or there can be one. So we can see that now it's matching the ones with one period there, and it's also matching the one with no period. So now to continue and match the entire line. Now we want to match a space after that. And after the space, we want to match any uppercase letter. And to do that, we can use our character class, and we can match any uppercase letter by doing a range of uppercase letters there. So at this point, after that first uppercase letter that we match, we've completely matched the name for Mr. T down here at the bottom. But we still need to match the rest of our other names. So we could say that we will match any word character after that uppercase. So let's put in a backslash w to match any word character. And now we don't know how many more characters are going to be in our name. So we'll have to use a quantifier here. Now if we look over here, we could use the asterisk or the plus sign. And the plus sign will match one or more of these word characters. And the asterisk will match zero or more. So if we used the plus sign, then we can see that it matches our two top names here. But now it's not matching this Mr. T because after our word character, it's searching for one or more word characters after our uppercase character. So a better solution in this case, maybe to use the asterisk, which matches zero or more word characters. And if we use that asterisk, then we can see that it matches all three of our names that begin with Mr. Now I know that we've covered a lot so far, but we've got a couple of more concepts to go. And then we'll look at some examples that wrap everything together. So we still haven't matched our miss or misses names here. So how would we do that? So you might think that we could use a character set that matches either an r or an s. And there are maybe some ways that we could get that to work. But it probably would be a bit ugly, since we'd have to match either an r or an s as the second character and then the optional s after that. So that could get kind of ugly. But I think a better solution here would be to use a group. Now we haven't looked at groups yet. But groups allow us to match several different patterns. And to create a group, we use parentheses. So after the m here, instead of just searching for Mr, I'm going to create a group with open and closed parentheses here. And now within our group, we can specify different matches. So I can say that we want to match either an r and then or and we use this character here to specify an or. And that is just the vertical bar character to specify an or. So we can say that we want to match an r or an s. And whenever we add that in, we can see that now we're matching the miss name here. But we're still not matching this misses. So to match the misses, we can put in another or and say that we want to match an RS. Okay, so now we can see that we are matching all of our names here. So let's do a quick walkthrough of this one more time to make sure we know what's going on. So we have a capital M to start. And then that capital M is followed by either an r and s or an RS. And then we are looking for a literal period. And this question mark says that we can have zero or one of those. So that is optional. So it's matching the ones that do have that period and the ones that don't. And then after that, we are matching a space. Then after that space, we the first letter of the last name, we're looking for any capital letter. So we have a character set here that is a through Z of capital letters. And then for the rest of the last name, we are matching zero or more word characters. Now these groups can actually be used to capture sections of your matched regular expression. And that's something that we'll look at in just a minute. But for now, let's do a quick recap of everything that we've learned so far. And look at some examples that incorporates all of these things together. So I have a file here and I'm going to move my snippets back into the group here and open up this file emails.txt. So I've got a file here with three fairly different email addresses. So let's try to write a regular expression that will match all of these emails. So let's just match the first email address first and see what that looks like. So the first email address, we have a mix of upper and lowercase letters here before we hit this at symbol. So let's go ahead and match those first. So to match any upper or lowercase letters, we can do a character set. And we can do a lowercase a through Z or an uppercase a through uppercase Z. Now right now, this is only matching those single characters. So we can use the plus quantifier to say that we want one or more of these upper or lowercase letters. So we're still working on the first email address here, we have our upper and lowercase letters here. And now we want to match that at symbol. So I'll just put in a literal at symbol. And now for the domain name here, I'll just do a another search for any upper or lowercase letters. So I'll do the same as we did before. And then I will do a plus sign for a quantifier to match any upper lowercase letters after that at symbol. And then that's when we hit the end with the dot com. So to match the dot com, we can do a backslash period for the dot. And then we can just fill in a literal com. So now we've successfully matched that first address. Now it looks like it's not matching the second address. So let's see why and see if we can mold this to match the second address as well. So we can see that the second address has a dot in the first part of the name here. So let's add a dot to our first character set, so that dots are included in that character set. So now it's still not matching that second address. And it's because at the end here, we don't have a dot com but a dot edu. So in order to search for both, we can use a group like we saw before using open and close parentheses. And we can search for either com or edu. Okay, so now we are building this up a little bit at a time. And we can see that we are now matching our second email address. Okay, so now let's see if we can change this to match our third email address here. So in our third email address, it looks like before the at symbol, we also have some hyphens and some numbers in the first part here. So let's add those to the character set as well. So back here after our capital letters, I'm also going to add in digits by doing zero through nine. And we also want to add a dash in there as well. So that should match everything before the at symbol. Now it looks like we also have a dash in our domain here. So we'll have to add that in as well. So after the at symbol, we're matching any characters right now, it's just lowercase and uppercase, but we can put a dash in there as well. And lastly, it's still not matching because just like the other two instead, we have a dot net here instead. So we can just add in a second or at the end and also include dot net. So we can see that we built that up a little bit at a time to match all three of our email addresses. Now with something like email addresses, it can be pretty tough writing your own regular expressions from scratch. But there are a lot of these available online. And once we learn how to write regular expressions, then we should be able to read them and figure out how they're matching as well. Now, I've always found that reading other people's regular expressions to be a lot harder than writing them. But let's take a look at one and see if we can do this. So I have an expression here that I pulled offline that matches email addresses. And let's paste this in here and see if we can read through and see what this is matching. So we can see that the one that I got offline does match all three of my email addresses here. Now let's look through this. So we can see that it's somewhat similar to what we had before. But first we have a character set here and it's a pretty large character set. And it matches lowercase, uppercase, any number, an underscore, a period, a plus sign, or a hyphen. And then the plus sign here says that we want to match one or more of any of those characters. And we match one or more of those characters all the way up until we hit an at sign. And then after the at sign, we have another character set here. And in this character set, we have lowercase letters, uppercase letters, any digits, and also a hyphen. Now I don't know a lot about email addresses, but I'm assuming that since they left out the underscore, the period, and the plus sign that were in the first part of the email address, I'm assuming that those aren't allowed in the domain. So then we have a plus sign after that character set, which means that we're matching one or more of any of those characters all the way up until we reach this literal dot. And that literal dot is escaped with a backslash. And then after the dot, we have another character set here. And this character set is any lowercase letter, any uppercase letter, any digits, any hyphen, or a period. And then that is followed by a plus sign, which matches one or more of anything in that character set. So just like I did with the phone numbers, if we open up our data file here, with this regular expression that we've typed in, then we can see that it does match all of the email addresses in this data file as well. So we've got an expression that will match email addresses fairly well. So doing what we just did and reading through a regular expression written by other people is probably the hardest part of all this. But if you walk through it bit by bit, then you should be able to break down just about any pattern. Okay, so the last thing that I'd like to look at in this video is how to capture information from groups. Now, we've already seen how to match groups, but we can actually use the information captured from those groups. So to show an example of this, I'm going to open up a file here with some URLs. Okay, so we can see here that some of the URLs are HTTP, some are HTTPS. Also, some of these have WWW before the domain name, and some do not. So let's say that you had a list of a lot of different URLs within your document, and you only wanted to grab the domain name and the top level domain, which is .com or .gov. So for example, out of all these domains, you only wanted to grab google.com or coreyms.com or youtube.com or nasa.gov. And you just wanted to ignore everything else. So let's see how we can do this. So first, let's write an expression that actually matches these URLs. So let me get rid of the one that we currently have. Now, first, to match this, we can say all of these start with with HTTP. And then the s is optional. So we can say s and then put in a question mark to say that we want to match zero or one for the s. And then after that optional s, we want a colon forward slash forward slash. So at this point, some of these domains have a WWW dot before the domain name and some do not. So that WWW dot is optional. So since this isn't one character, we're actually going to create a group here and say this group of WWW and then a literal dot, which is a backslash dot. Now, all of that group is optional. So now you can see on all of our URLs, we've matched up to the domain name. So now to complete this, I'm just going to say any word character, so backslash w, and I will put in a plus sign to say one or more of those word characters. And then we get here to the top level domain. So we want to match a literal dot. So we'll do a backslash dot. And then for the rest of that top level domain, I will just do any word character one or more times so we can do a word character with a plus sign to do one or more. Okay, so we can see that this matches all of our URLs. But the point here was to use our groups to capture some information from our URLs. So let's capture the domain name and the top level domain, which is the dot com or the dot gov and things like that. So to capture these sections, we can just put them in a group by surrounding them in parentheses. So what we want to group here is our domain name. And the domain name is this part right here, this string of one or more word characters. So I'm just going to wrap those in parentheses and create a group. And we've seen that before. And now we also want to put the top level domain in a group as well. That is the dot com or the dot gov. So we can put a parentheses around that dot, and then also around the ending there that is the string of one or more word characters. Okay, so we can see that we're still matching all of our URLs here. But now we have three different groups. So our first group is just that optional www dot. Our second group is the word characters that make up our domain name. And the third group is that top level domain. Now there's also an implicit group zero. And group zero is everything that we captured. So in this case, it's the entire URL. So now let's get to the cool part about this. So let me show you what we can do now that we've captured these. So we can use something called a back reference to reference our captured group. So for example, here in Adam, we have the ability to replace our matches, we can see down here that we can replace. So let's replace all of our matches with just the literal text group one, and then a colon, and then a dollar sign one. Now this dollar sign one is a reference to our first group. Now sometimes this is a backslash. But for some reason in Adam, they use a dollar sign. So if I do a replace all here, then we can see that it replaced our matches with this literal text group one. But then it also replaced the dollar sign one with our first captured group. And the first capture group is that optional www dot. So for the ones for the domains that had that www, we can see that it shows up. And for ones that didn't, it doesn't have anything. So let me undo this. And now let's replace our matches with the second group. And now the second group should be the domain name. So now if I do a replace all now, then we can see that now it says group two is Google, CoreMS, YouTube, and NASA. And if I undo that, and replace this with the group three, then the group three should give us our top level domain. So our group three is the dot com dot com dot gov things like that. So let me undo this one more time. So now that we know how to use those back references, then we can actually take our regular URLs and clean them up like we meant to from before. So we could convert these to a cleaned up version without the HTTP or the www just by replacing our matches with the domain name, which is group two, followed by the top level domain, which is group three. So now if I replace all of our selections with those two, then we can see that replaced all of our URLs with just the domain name and the top level domain. So you can imagine if you had a lot of information like this that you needed to clean up or modify in some way, then knowing how to match these groups with regular expressions could save you a ton of time with doing things like this. Okay, so I think that's going to do it for this video. Now there's a lot of advanced features that we could go over with regular expressions as well. So if anyone is interested in learning more, then I could put together an advanced video covering those topics in the near future. But hopefully now you feel comfortable with being able to read and write these regular expressions that we went over in this video. But if anyone does have any questions about what we covered in this video, then feel free to ask in the comment section below and I'll do my best to answer those. And if you enjoy these tutorials and would like to support them, then there are several ways you can do that. The easiest ways to simply like the video and give it a thumbs up. And also it's a huge help to share these videos with anyone who you think would find them useful. And if you have the means you can contribute your Patreon and there's a link to that page in the description section below. Be sure to subscribe for future videos and thank you all for watching.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 3.04, "text": " Hey there, how's it going everybody? In this video we're going to be learning how to use", "tokens": [50364, 1911, 456, 11, 577, 311, 309, 516, 2201, 30, 682, 341, 960, 321, 434, 516, 281, 312, 2539, 577, 281, 764, 50516], "temperature": 0.0, "avg_logprob": -0.09605197300986638, "compression_ratio": 1.7917981072555205, "no_speech_prob": 0.08996120095252991}, {"id": 1, "seek": 0, "start": 3.04, "end": 7.28, "text": " regular expressions. So we're actually going to look at regular expressions as a standalone", "tokens": [50516, 3890, 15277, 13, 407, 321, 434, 767, 516, 281, 574, 412, 3890, 15277, 382, 257, 37454, 50728], "temperature": 0.0, "avg_logprob": -0.09605197300986638, "compression_ratio": 1.7917981072555205, "no_speech_prob": 0.08996120095252991}, {"id": 2, "seek": 0, "start": 7.28, "end": 11.36, "text": " topic because they aren't specific to any one programming language. Now there are some slightly", "tokens": [50728, 4829, 570, 436, 3212, 380, 2685, 281, 604, 472, 9410, 2856, 13, 823, 456, 366, 512, 4748, 50932], "temperature": 0.0, "avg_logprob": -0.09605197300986638, "compression_ratio": 1.7917981072555205, "no_speech_prob": 0.08996120095252991}, {"id": 3, "seek": 0, "start": 11.36, "end": 15.76, "text": " different flavors here and there, but for the most part, whether you're programming in Python or", "tokens": [50932, 819, 16303, 510, 293, 456, 11, 457, 337, 264, 881, 644, 11, 1968, 291, 434, 9410, 294, 15329, 420, 51152], "temperature": 0.0, "avg_logprob": -0.09605197300986638, "compression_ratio": 1.7917981072555205, "no_speech_prob": 0.08996120095252991}, {"id": 4, "seek": 0, "start": 15.76, "end": 21.2, "text": " JavaScript or Java or whatever, if you learn how to use general regular expressions, then it should", "tokens": [51152, 15778, 420, 10745, 420, 2035, 11, 498, 291, 1466, 577, 281, 764, 2674, 3890, 15277, 11, 550, 309, 820, 51424], "temperature": 0.0, "avg_logprob": -0.09605197300986638, "compression_ratio": 1.7917981072555205, "no_speech_prob": 0.08996120095252991}, {"id": 5, "seek": 0, "start": 21.2, "end": 25.84, "text": " mostly carry over into your language of choice. And it will also allow you to use them in text", "tokens": [51424, 5240, 3985, 670, 666, 428, 2856, 295, 3922, 13, 400, 309, 486, 611, 2089, 291, 281, 764, 552, 294, 2487, 51656], "temperature": 0.0, "avg_logprob": -0.09605197300986638, "compression_ratio": 1.7917981072555205, "no_speech_prob": 0.08996120095252991}, {"id": 6, "seek": 2584, "start": 25.84, "end": 30.32, "text": " editors and the command line and things like that. Now I am going to do a follow up video where I", "tokens": [50364, 31446, 293, 264, 5622, 1622, 293, 721, 411, 300, 13, 823, 286, 669, 516, 281, 360, 257, 1524, 493, 960, 689, 286, 50588], "temperature": 0.0, "avg_logprob": -0.06634398662682736, "compression_ratio": 1.81875, "no_speech_prob": 0.10371237248182297}, {"id": 7, "seek": 2584, "start": 30.32, "end": 34.64, "text": " show how to use regular expressions specifically in Python since that's a language that I cover", "tokens": [50588, 855, 577, 281, 764, 3890, 15277, 4682, 294, 15329, 1670, 300, 311, 257, 2856, 300, 286, 2060, 50804], "temperature": 0.0, "avg_logprob": -0.06634398662682736, "compression_ratio": 1.81875, "no_speech_prob": 0.10371237248182297}, {"id": 8, "seek": 2584, "start": 34.64, "end": 39.36, "text": " most on this channel. But for this video, we're going to be learning how to use regular expressions", "tokens": [50804, 881, 322, 341, 2269, 13, 583, 337, 341, 960, 11, 321, 434, 516, 281, 312, 2539, 577, 281, 764, 3890, 15277, 51040], "temperature": 0.0, "avg_logprob": -0.06634398662682736, "compression_ratio": 1.81875, "no_speech_prob": 0.10371237248182297}, {"id": 9, "seek": 2584, "start": 39.36, "end": 43.92, "text": " by themselves so that you can apply these to other areas. So with that said, let's go ahead and get", "tokens": [51040, 538, 2969, 370, 300, 291, 393, 3079, 613, 281, 661, 3179, 13, 407, 365, 300, 848, 11, 718, 311, 352, 2286, 293, 483, 51268], "temperature": 0.0, "avg_logprob": -0.06634398662682736, "compression_ratio": 1.81875, "no_speech_prob": 0.10371237248182297}, {"id": 10, "seek": 2584, "start": 43.92, "end": 49.2, "text": " started. So regular expressions basically allow us to search for specific patterns of text. And", "tokens": [51268, 1409, 13, 407, 3890, 15277, 1936, 2089, 505, 281, 3164, 337, 2685, 8294, 295, 2487, 13, 400, 51532], "temperature": 0.0, "avg_logprob": -0.06634398662682736, "compression_ratio": 1.81875, "no_speech_prob": 0.10371237248182297}, {"id": 11, "seek": 2584, "start": 49.2, "end": 53.6, "text": " they can look extremely complicated. But that's mainly because there's just so much that you", "tokens": [51532, 436, 393, 574, 4664, 6179, 13, 583, 300, 311, 8704, 570, 456, 311, 445, 370, 709, 300, 291, 51752], "temperature": 0.0, "avg_logprob": -0.06634398662682736, "compression_ratio": 1.81875, "no_speech_prob": 0.10371237248182297}, {"id": 12, "seek": 5360, "start": 53.6, "end": 57.68, "text": " can do with them. You can create a regular expression for just about any pattern of text that", "tokens": [50364, 393, 360, 365, 552, 13, 509, 393, 1884, 257, 3890, 6114, 337, 445, 466, 604, 5102, 295, 2487, 300, 50568], "temperature": 0.0, "avg_logprob": -0.06370716363611356, "compression_ratio": 1.903225806451613, "no_speech_prob": 0.028432665392756462}, {"id": 13, "seek": 5360, "start": 57.68, "end": 62.56, "text": " you can think of. So let's see what some of these look like. So I have a test file open here that", "tokens": [50568, 291, 393, 519, 295, 13, 407, 718, 311, 536, 437, 512, 295, 613, 574, 411, 13, 407, 286, 362, 257, 1500, 3991, 1269, 510, 300, 50812], "temperature": 0.0, "avg_logprob": -0.06370716363611356, "compression_ratio": 1.903225806451613, "no_speech_prob": 0.028432665392756462}, {"id": 14, "seek": 5360, "start": 62.56, "end": 67.68, "text": " we're going to use to search for specific patterns. And I'm going to be using the regular expression", "tokens": [50812, 321, 434, 516, 281, 764, 281, 3164, 337, 2685, 8294, 13, 400, 286, 478, 516, 281, 312, 1228, 264, 3890, 6114, 51068], "temperature": 0.0, "avg_logprob": -0.06370716363611356, "compression_ratio": 1.903225806451613, "no_speech_prob": 0.028432665392756462}, {"id": 15, "seek": 5360, "start": 67.68, "end": 73.28, "text": " tool in the atom text editor to write these regular expressions and find what text matches our patterns.", "tokens": [51068, 2290, 294, 264, 12018, 2487, 9839, 281, 2464, 613, 3890, 15277, 293, 915, 437, 2487, 10676, 527, 8294, 13, 51348], "temperature": 0.0, "avg_logprob": -0.06370716363611356, "compression_ratio": 1.903225806451613, "no_speech_prob": 0.028432665392756462}, {"id": 16, "seek": 5360, "start": 73.28, "end": 78.0, "text": " Now in order to open up this regular expression search tool, I'm just going to go to find and", "tokens": [51348, 823, 294, 1668, 281, 1269, 493, 341, 3890, 6114, 3164, 2290, 11, 286, 478, 445, 516, 281, 352, 281, 915, 293, 51584], "temperature": 0.0, "avg_logprob": -0.06370716363611356, "compression_ratio": 1.903225806451613, "no_speech_prob": 0.028432665392756462}, {"id": 17, "seek": 5360, "start": 78.0, "end": 83.28, "text": " then find in buffer. Now you could have also opened this up with command F on a Mac. And I believe", "tokens": [51584, 550, 915, 294, 21762, 13, 823, 291, 727, 362, 611, 5625, 341, 493, 365, 5622, 479, 322, 257, 5707, 13, 400, 286, 1697, 51848], "temperature": 0.0, "avg_logprob": -0.06370716363611356, "compression_ratio": 1.903225806451613, "no_speech_prob": 0.028432665392756462}, {"id": 18, "seek": 8328, "start": 83.28, "end": 90.32000000000001, "text": " that's control F on Windows. Now within the options here, make sure that you have the dot", "tokens": [50364, 300, 311, 1969, 479, 322, 8591, 13, 823, 1951, 264, 3956, 510, 11, 652, 988, 300, 291, 362, 264, 5893, 50716], "temperature": 0.0, "avg_logprob": -0.06758306722725387, "compression_ratio": 1.7683823529411764, "no_speech_prob": 0.002800679998472333}, {"id": 19, "seek": 8328, "start": 90.32000000000001, "end": 95.68, "text": " asterisk selected over here because that's going to tell our search tool to use regular expressions.", "tokens": [50716, 257, 3120, 7797, 8209, 670, 510, 570, 300, 311, 516, 281, 980, 527, 3164, 2290, 281, 764, 3890, 15277, 13, 50984], "temperature": 0.0, "avg_logprob": -0.06758306722725387, "compression_ratio": 1.7683823529411764, "no_speech_prob": 0.002800679998472333}, {"id": 20, "seek": 8328, "start": 95.68, "end": 101.2, "text": " And also select this match case option here as well. That's just going to give us behavior that", "tokens": [50984, 400, 611, 3048, 341, 2995, 1389, 3614, 510, 382, 731, 13, 663, 311, 445, 516, 281, 976, 505, 5223, 300, 51260], "temperature": 0.0, "avg_logprob": -0.06758306722725387, "compression_ratio": 1.7683823529411764, "no_speech_prob": 0.002800679998472333}, {"id": 21, "seek": 8328, "start": 101.2, "end": 106.0, "text": " is more common to how regular expressions usually behave. Okay, so let's start writing some regular", "tokens": [51260, 307, 544, 2689, 281, 577, 3890, 15277, 2673, 15158, 13, 1033, 11, 370, 718, 311, 722, 3579, 512, 3890, 51500], "temperature": 0.0, "avg_logprob": -0.06758306722725387, "compression_ratio": 1.7683823529411764, "no_speech_prob": 0.002800679998472333}, {"id": 22, "seek": 8328, "start": 106.0, "end": 111.04, "text": " expressions. And first we'll start off kind of simple. So first of all, we can just search for", "tokens": [51500, 15277, 13, 400, 700, 321, 603, 722, 766, 733, 295, 2199, 13, 407, 700, 295, 439, 11, 321, 393, 445, 3164, 337, 51752], "temperature": 0.0, "avg_logprob": -0.06758306722725387, "compression_ratio": 1.7683823529411764, "no_speech_prob": 0.002800679998472333}, {"id": 23, "seek": 11104, "start": 111.04, "end": 117.12, "text": " literal characters. So if I was to search for ABC, then we can see here at the top that it", "tokens": [50364, 20411, 4342, 13, 407, 498, 286, 390, 281, 3164, 337, 22342, 11, 550, 321, 393, 536, 510, 412, 264, 1192, 300, 309, 50668], "temperature": 0.0, "avg_logprob": -0.07588184873263042, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.010651783086359501}, {"id": 24, "seek": 11104, "start": 117.12, "end": 123.92, "text": " highlighted ABC because it matched the ABC and our lowercase alphabet. Now it didn't match the", "tokens": [50668, 17173, 22342, 570, 309, 21447, 264, 22342, 293, 527, 3126, 9765, 23339, 13, 823, 309, 994, 380, 2995, 264, 51008], "temperature": 0.0, "avg_logprob": -0.07588184873263042, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.010651783086359501}, {"id": 25, "seek": 11104, "start": 123.92, "end": 130.32, "text": " capital ABC here because it's case sensitive. Now this search right now is looking specifically", "tokens": [51008, 4238, 22342, 510, 570, 309, 311, 1389, 9477, 13, 823, 341, 3164, 558, 586, 307, 1237, 4682, 51328], "temperature": 0.0, "avg_logprob": -0.07588184873263042, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.010651783086359501}, {"id": 26, "seek": 11104, "start": 130.32, "end": 136.72, "text": " for A, B, and C. But if I was to type in something like BCA, then we can see that there were no", "tokens": [51328, 337, 316, 11, 363, 11, 293, 383, 13, 583, 498, 286, 390, 281, 2010, 294, 746, 411, 14359, 32, 11, 550, 321, 393, 536, 300, 456, 645, 572, 51648], "temperature": 0.0, "avg_logprob": -0.07588184873263042, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.010651783086359501}, {"id": 27, "seek": 13672, "start": 136.72, "end": 143.28, "text": " results found because the order does matter. Now if we look at this meta character section here,", "tokens": [50364, 3542, 1352, 570, 264, 1668, 775, 1871, 13, 823, 498, 321, 574, 412, 341, 19616, 2517, 3541, 510, 11, 50692], "temperature": 0.0, "avg_logprob": -0.05152850446447862, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.01590549945831299}, {"id": 28, "seek": 13672, "start": 143.28, "end": 148.56, "text": " I have some examples of characters that I say need to be escaped. So for example,", "tokens": [50692, 286, 362, 512, 5110, 295, 4342, 300, 286, 584, 643, 281, 312, 20397, 13, 407, 337, 1365, 11, 50956], "temperature": 0.0, "avg_logprob": -0.05152850446447862, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.01590549945831299}, {"id": 29, "seek": 13672, "start": 148.56, "end": 155.92, "text": " if you wanted to search for a literal period, now if I was to just type in a period here and", "tokens": [50956, 498, 291, 1415, 281, 3164, 337, 257, 20411, 2896, 11, 586, 498, 286, 390, 281, 445, 2010, 294, 257, 2896, 510, 293, 51324], "temperature": 0.0, "avg_logprob": -0.05152850446447862, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.01590549945831299}, {"id": 30, "seek": 13672, "start": 155.92, "end": 160.72, "text": " hit enter for my search, then we can see that it does this weird thing where it matches everything.", "tokens": [51324, 2045, 3242, 337, 452, 3164, 11, 550, 321, 393, 536, 300, 309, 775, 341, 3657, 551, 689, 309, 10676, 1203, 13, 51564], "temperature": 0.0, "avg_logprob": -0.05152850446447862, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.01590549945831299}, {"id": 31, "seek": 13672, "start": 160.72, "end": 166.32, "text": " And that is because the dot is a special character in regular expressions. And we'll see more of this", "tokens": [51564, 400, 300, 307, 570, 264, 5893, 307, 257, 2121, 2517, 294, 3890, 15277, 13, 400, 321, 603, 536, 544, 295, 341, 51844], "temperature": 0.0, "avg_logprob": -0.05152850446447862, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.01590549945831299}, {"id": 32, "seek": 16632, "start": 166.32, "end": 172.16, "text": " in just a second. But for now, if we just wanted to actually search for a period or a dot, then we", "tokens": [50364, 294, 445, 257, 1150, 13, 583, 337, 586, 11, 498, 321, 445, 1415, 281, 767, 3164, 337, 257, 2896, 420, 257, 5893, 11, 550, 321, 50656], "temperature": 0.0, "avg_logprob": -0.04115303802490235, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0026315583381801844}, {"id": 33, "seek": 16632, "start": 172.16, "end": 178.48, "text": " have to escape it. And to escape characters, we can use the backslash. So if I do a backslash and", "tokens": [50656, 362, 281, 7615, 309, 13, 400, 281, 7615, 4342, 11, 321, 393, 764, 264, 646, 10418, 1299, 13, 407, 498, 286, 360, 257, 646, 10418, 1299, 293, 50972], "temperature": 0.0, "avg_logprob": -0.04115303802490235, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0026315583381801844}, {"id": 34, "seek": 16632, "start": 178.48, "end": 185.04, "text": " search, then now we can see that it only matches the actual literal dot or period within our document", "tokens": [50972, 3164, 11, 550, 586, 321, 393, 536, 300, 309, 787, 10676, 264, 3539, 20411, 5893, 420, 2896, 1951, 527, 4166, 51300], "temperature": 0.0, "avg_logprob": -0.04115303802490235, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0026315583381801844}, {"id": 35, "seek": 16632, "start": 185.04, "end": 189.76, "text": " here. And that goes for any of these meta characters that I've listed here. So for example,", "tokens": [51300, 510, 13, 400, 300, 1709, 337, 604, 295, 613, 19616, 4342, 300, 286, 600, 10052, 510, 13, 407, 337, 1365, 11, 51536], "temperature": 0.0, "avg_logprob": -0.04115303802490235, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0026315583381801844}, {"id": 36, "seek": 16632, "start": 189.76, "end": 194.56, "text": " we can see that the backslash is a special character also. So if you wanted to search", "tokens": [51536, 321, 393, 536, 300, 264, 646, 10418, 1299, 307, 257, 2121, 2517, 611, 13, 407, 498, 291, 1415, 281, 3164, 51776], "temperature": 0.0, "avg_logprob": -0.04115303802490235, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0026315583381801844}, {"id": 37, "seek": 19456, "start": 194.56, "end": 200.24, "text": " specifically for a backslash, then you have to escape itself. So a backslash to escape,", "tokens": [50364, 4682, 337, 257, 646, 10418, 1299, 11, 550, 291, 362, 281, 7615, 2564, 13, 407, 257, 646, 10418, 1299, 281, 7615, 11, 50648], "temperature": 0.0, "avg_logprob": -0.08359745570591517, "compression_ratio": 1.9369747899159664, "no_speech_prob": 0.0019265480805188417}, {"id": 38, "seek": 19456, "start": 200.24, "end": 204.56, "text": " and then a backslash for the search. And if I search for that, then we can see that we matched", "tokens": [50648, 293, 550, 257, 646, 10418, 1299, 337, 264, 3164, 13, 400, 498, 286, 3164, 337, 300, 11, 550, 321, 393, 536, 300, 321, 21447, 50864], "temperature": 0.0, "avg_logprob": -0.08359745570591517, "compression_ratio": 1.9369747899159664, "no_speech_prob": 0.0019265480805188417}, {"id": 39, "seek": 19456, "start": 204.56, "end": 210.24, "text": " a literal backslash. So a practical example of this might be trying to match this URL right here.", "tokens": [50864, 257, 20411, 646, 10418, 1299, 13, 407, 257, 8496, 1365, 295, 341, 1062, 312, 1382, 281, 2995, 341, 12905, 558, 510, 13, 51148], "temperature": 0.0, "avg_logprob": -0.08359745570591517, "compression_ratio": 1.9369747899159664, "no_speech_prob": 0.0019265480805188417}, {"id": 40, "seek": 19456, "start": 210.24, "end": 216.0, "text": " So if we wanted to match that literal URL, exactly, then we could just say corey Ms.", "tokens": [51148, 407, 498, 321, 1415, 281, 2995, 300, 20411, 12905, 11, 2293, 11, 550, 321, 727, 445, 584, 4965, 88, 7741, 13, 51436], "temperature": 0.0, "avg_logprob": -0.08359745570591517, "compression_ratio": 1.9369747899159664, "no_speech_prob": 0.0019265480805188417}, {"id": 41, "seek": 19456, "start": 216.0, "end": 221.68, "text": " And then for the dot on the dot com, we have to escape that with a backslash and then a period,", "tokens": [51436, 400, 550, 337, 264, 5893, 322, 264, 5893, 395, 11, 321, 362, 281, 7615, 300, 365, 257, 646, 10418, 1299, 293, 550, 257, 2896, 11, 51720], "temperature": 0.0, "avg_logprob": -0.08359745570591517, "compression_ratio": 1.9369747899159664, "no_speech_prob": 0.0019265480805188417}, {"id": 42, "seek": 22168, "start": 221.68, "end": 226.32, "text": " and then a com. And we can see that it matches our URL. Okay, so that's how you match literal", "tokens": [50364, 293, 550, 257, 395, 13, 400, 321, 393, 536, 300, 309, 10676, 527, 12905, 13, 1033, 11, 370, 300, 311, 577, 291, 2995, 20411, 50596], "temperature": 0.0, "avg_logprob": -0.0473763878281052, "compression_ratio": 1.8083067092651757, "no_speech_prob": 0.0018101346213370562}, {"id": 43, "seek": 22168, "start": 226.32, "end": 230.8, "text": " characters. But a literal search isn't too exciting, because we're used to that already.", "tokens": [50596, 4342, 13, 583, 257, 20411, 3164, 1943, 380, 886, 4670, 11, 570, 321, 434, 1143, 281, 300, 1217, 13, 50820], "temperature": 0.0, "avg_logprob": -0.0473763878281052, "compression_ratio": 1.8083067092651757, "no_speech_prob": 0.0018101346213370562}, {"id": 44, "seek": 22168, "start": 230.8, "end": 235.04000000000002, "text": " Really, we want to use regular expressions to search for patterns. And to do this, we're going", "tokens": [50820, 4083, 11, 321, 528, 281, 764, 3890, 15277, 281, 3164, 337, 8294, 13, 400, 281, 360, 341, 11, 321, 434, 516, 51032], "temperature": 0.0, "avg_logprob": -0.0473763878281052, "compression_ratio": 1.8083067092651757, "no_speech_prob": 0.0018101346213370562}, {"id": 45, "seek": 22168, "start": 235.04000000000002, "end": 240.48000000000002, "text": " to be using some of these meta characters that we were just escaping. So I have a snippets file", "tokens": [51032, 281, 312, 1228, 512, 295, 613, 19616, 4342, 300, 321, 645, 445, 32554, 13, 407, 286, 362, 257, 35623, 1385, 3991, 51304], "temperature": 0.0, "avg_logprob": -0.0473763878281052, "compression_ratio": 1.8083067092651757, "no_speech_prob": 0.0018101346213370562}, {"id": 46, "seek": 22168, "start": 240.48000000000002, "end": 245.92000000000002, "text": " open here. So I'm going to switch over to this. And in here, I have a list of values where we can", "tokens": [51304, 1269, 510, 13, 407, 286, 478, 516, 281, 3679, 670, 281, 341, 13, 400, 294, 510, 11, 286, 362, 257, 1329, 295, 4190, 689, 321, 393, 51576], "temperature": 0.0, "avg_logprob": -0.0473763878281052, "compression_ratio": 1.8083067092651757, "no_speech_prob": 0.0018101346213370562}, {"id": 47, "seek": 22168, "start": 245.92000000000002, "end": 250.64000000000001, "text": " see the types of characters that we can match. Now just for now, I'm going to try to make this", "tokens": [51576, 536, 264, 3467, 295, 4342, 300, 321, 393, 2995, 13, 823, 445, 337, 586, 11, 286, 478, 516, 281, 853, 281, 652, 341, 51812], "temperature": 0.0, "avg_logprob": -0.0473763878281052, "compression_ratio": 1.8083067092651757, "no_speech_prob": 0.0018101346213370562}, {"id": 48, "seek": 25064, "start": 250.64, "end": 257.36, "text": " into a split screen here, as we're walking down this list. So the first one I have listed here", "tokens": [50364, 666, 257, 7472, 2568, 510, 11, 382, 321, 434, 4494, 760, 341, 1329, 13, 407, 264, 700, 472, 286, 362, 10052, 510, 50700], "temperature": 0.0, "avg_logprob": -0.05215718958637502, "compression_ratio": 1.696035242290749, "no_speech_prob": 0.0012065492337569594}, {"id": 49, "seek": 25064, "start": 257.36, "end": 263.44, "text": " is this dot or period. And we can see that this matches any character except a new line. Now we've", "tokens": [50700, 307, 341, 5893, 420, 2896, 13, 400, 321, 393, 536, 300, 341, 10676, 604, 2517, 3993, 257, 777, 1622, 13, 823, 321, 600, 51004], "temperature": 0.0, "avg_logprob": -0.05215718958637502, "compression_ratio": 1.696035242290749, "no_speech_prob": 0.0012065492337569594}, {"id": 50, "seek": 25064, "start": 263.44, "end": 268.88, "text": " already seen this, but let's take a look again. If we just do a dot and search for that, then we", "tokens": [51004, 1217, 1612, 341, 11, 457, 718, 311, 747, 257, 574, 797, 13, 759, 321, 445, 360, 257, 5893, 293, 3164, 337, 300, 11, 550, 321, 51276], "temperature": 0.0, "avg_logprob": -0.05215718958637502, "compression_ratio": 1.696035242290749, "no_speech_prob": 0.0012065492337569594}, {"id": 51, "seek": 25064, "start": 268.88, "end": 273.91999999999996, "text": " can see that it matches any character except it does not match the new lines. Okay, so next on", "tokens": [51276, 393, 536, 300, 309, 10676, 604, 2517, 3993, 309, 775, 406, 2995, 264, 777, 3876, 13, 1033, 11, 370, 958, 322, 51528], "temperature": 0.0, "avg_logprob": -0.05215718958637502, "compression_ratio": 1.696035242290749, "no_speech_prob": 0.0012065492337569594}, {"id": 52, "seek": 27392, "start": 273.92, "end": 281.52000000000004, "text": " the list is backslash D. And that matches any digit zero through nine. So if I was to do a backslash", "tokens": [50364, 264, 1329, 307, 646, 10418, 1299, 413, 13, 400, 300, 10676, 604, 14293, 4018, 807, 4949, 13, 407, 498, 286, 390, 281, 360, 257, 646, 10418, 1299, 50744], "temperature": 0.0, "avg_logprob": -0.06864421329801045, "compression_ratio": 2.029535864978903, "no_speech_prob": 0.1096927598118782}, {"id": 53, "seek": 27392, "start": 281.52000000000004, "end": 286.64000000000004, "text": " D here and search for that, then you can see that this matches all of our digits. So anything", "tokens": [50744, 413, 510, 293, 3164, 337, 300, 11, 550, 291, 393, 536, 300, 341, 10676, 439, 295, 527, 27011, 13, 407, 1340, 51000], "temperature": 0.0, "avg_logprob": -0.06864421329801045, "compression_ratio": 2.029535864978903, "no_speech_prob": 0.1096927598118782}, {"id": 54, "seek": 27392, "start": 286.64000000000004, "end": 291.76, "text": " zero through nine, it matches. Now we also have an uppercase D here. And that matches anything", "tokens": [51000, 4018, 807, 4949, 11, 309, 10676, 13, 823, 321, 611, 362, 364, 11775, 2869, 651, 413, 510, 13, 400, 300, 10676, 1340, 51256], "temperature": 0.0, "avg_logprob": -0.06864421329801045, "compression_ratio": 2.029535864978903, "no_speech_prob": 0.1096927598118782}, {"id": 55, "seek": 27392, "start": 291.76, "end": 297.84000000000003, "text": " that is not a digit. So if I search for an uppercase D, then we can see that our digits are not", "tokens": [51256, 300, 307, 406, 257, 14293, 13, 407, 498, 286, 3164, 337, 364, 11775, 2869, 651, 413, 11, 550, 321, 393, 536, 300, 527, 27011, 366, 406, 51560], "temperature": 0.0, "avg_logprob": -0.06864421329801045, "compression_ratio": 2.029535864978903, "no_speech_prob": 0.1096927598118782}, {"id": 56, "seek": 27392, "start": 297.84000000000003, "end": 303.12, "text": " matched. But everything else is highlighted. So it matched everything except for the digit. Now", "tokens": [51560, 21447, 13, 583, 1203, 1646, 307, 17173, 13, 407, 309, 21447, 1203, 3993, 337, 264, 14293, 13, 823, 51824], "temperature": 0.0, "avg_logprob": -0.06864421329801045, "compression_ratio": 2.029535864978903, "no_speech_prob": 0.1096927598118782}, {"id": 57, "seek": 30312, "start": 303.12, "end": 308.4, "text": " you'll notice that this is a common theme here that the uppercase versions of all of these are the", "tokens": [50364, 291, 603, 3449, 300, 341, 307, 257, 2689, 6314, 510, 300, 264, 11775, 2869, 651, 9606, 295, 439, 295, 613, 366, 264, 50628], "temperature": 0.0, "avg_logprob": -0.07875952955152167, "compression_ratio": 1.8837209302325582, "no_speech_prob": 0.0001488353154854849}, {"id": 58, "seek": 30312, "start": 308.4, "end": 315.2, "text": " ones that kind of negate the search. So moving on down here, we have backslash w that searches for", "tokens": [50628, 2306, 300, 733, 295, 2485, 473, 264, 3164, 13, 407, 2684, 322, 760, 510, 11, 321, 362, 646, 10418, 1299, 261, 300, 26701, 337, 50968], "temperature": 0.0, "avg_logprob": -0.07875952955152167, "compression_ratio": 1.8837209302325582, "no_speech_prob": 0.0001488353154854849}, {"id": 59, "seek": 30312, "start": 315.2, "end": 321.84000000000003, "text": " any word character and a word character is lowercase a through z uppercase a through z zero through", "tokens": [50968, 604, 1349, 2517, 293, 257, 1349, 2517, 307, 3126, 9765, 257, 807, 710, 11775, 2869, 651, 257, 807, 710, 4018, 807, 51300], "temperature": 0.0, "avg_logprob": -0.07875952955152167, "compression_ratio": 1.8837209302325582, "no_speech_prob": 0.0001488353154854849}, {"id": 60, "seek": 30312, "start": 321.84000000000003, "end": 328.08, "text": " nine and an underscore. So let's search for the word character. And we can see that it matches,", "tokens": [51300, 4949, 293, 364, 37556, 13, 407, 718, 311, 3164, 337, 264, 1349, 2517, 13, 400, 321, 393, 536, 300, 309, 10676, 11, 51612], "temperature": 0.0, "avg_logprob": -0.07875952955152167, "compression_ratio": 1.8837209302325582, "no_speech_prob": 0.0001488353154854849}, {"id": 61, "seek": 30312, "start": 328.08, "end": 332.48, "text": " you know, all these lowercase uppercase numbers and things like that. It doesn't match these", "tokens": [51612, 291, 458, 11, 439, 613, 3126, 9765, 11775, 2869, 651, 3547, 293, 721, 411, 300, 13, 467, 1177, 380, 2995, 613, 51832], "temperature": 0.0, "avg_logprob": -0.07875952955152167, "compression_ratio": 1.8837209302325582, "no_speech_prob": 0.0001488353154854849}, {"id": 62, "seek": 33248, "start": 332.48, "end": 338.72, "text": " special meta characters here. And just like with the digit, the uppercase w will match anything that", "tokens": [50364, 2121, 19616, 4342, 510, 13, 400, 445, 411, 365, 264, 14293, 11, 264, 11775, 2869, 651, 261, 486, 2995, 1340, 300, 50676], "temperature": 0.0, "avg_logprob": -0.0502275574591852, "compression_ratio": 1.8104089219330854, "no_speech_prob": 0.0002959489938803017}, {"id": 63, "seek": 33248, "start": 338.72, "end": 344.72, "text": " is not a word character. So anything that is not in this list here. So let's go ahead and search", "tokens": [50676, 307, 406, 257, 1349, 2517, 13, 407, 1340, 300, 307, 406, 294, 341, 1329, 510, 13, 407, 718, 311, 352, 2286, 293, 3164, 50976], "temperature": 0.0, "avg_logprob": -0.0502275574591852, "compression_ratio": 1.8104089219330854, "no_speech_prob": 0.0002959489938803017}, {"id": 64, "seek": 33248, "start": 344.72, "end": 350.16, "text": " for that uppercase w. And we can see that, you know, it picks up the spaces and these special", "tokens": [50976, 337, 300, 11775, 2869, 651, 261, 13, 400, 321, 393, 536, 300, 11, 291, 458, 11, 309, 16137, 493, 264, 7673, 293, 613, 2121, 51248], "temperature": 0.0, "avg_logprob": -0.0502275574591852, "compression_ratio": 1.8104089219330854, "no_speech_prob": 0.0002959489938803017}, {"id": 65, "seek": 33248, "start": 350.16, "end": 355.52000000000004, "text": " punctuations and things like that. But it does not match the word characters that we saw before.", "tokens": [51248, 27006, 37570, 293, 721, 411, 300, 13, 583, 309, 775, 406, 2995, 264, 1349, 4342, 300, 321, 1866, 949, 13, 51516], "temperature": 0.0, "avg_logprob": -0.0502275574591852, "compression_ratio": 1.8104089219330854, "no_speech_prob": 0.0002959489938803017}, {"id": 66, "seek": 33248, "start": 355.52000000000004, "end": 359.20000000000005, "text": " Now, if you're not quite getting this just yet, we are going to look at a lot of examples to where", "tokens": [51516, 823, 11, 498, 291, 434, 406, 1596, 1242, 341, 445, 1939, 11, 321, 366, 516, 281, 574, 412, 257, 688, 295, 5110, 281, 689, 51700], "temperature": 0.0, "avg_logprob": -0.0502275574591852, "compression_ratio": 1.8104089219330854, "no_speech_prob": 0.0002959489938803017}, {"id": 67, "seek": 35920, "start": 359.2, "end": 364.71999999999997, "text": " it'll start to sink in. So moving down the list here, we have backslash s, which will match any", "tokens": [50364, 309, 603, 722, 281, 9500, 294, 13, 407, 2684, 760, 264, 1329, 510, 11, 321, 362, 646, 10418, 1299, 262, 11, 597, 486, 2995, 604, 50640], "temperature": 0.0, "avg_logprob": -0.061520761297654734, "compression_ratio": 1.904382470119522, "no_speech_prob": 0.01065161544829607}, {"id": 68, "seek": 35920, "start": 364.71999999999997, "end": 372.08, "text": " white space. And white space is a space tab or a new line. So if we search for backslash s,", "tokens": [50640, 2418, 1901, 13, 400, 2418, 1901, 307, 257, 1901, 4421, 420, 257, 777, 1622, 13, 407, 498, 321, 3164, 337, 646, 10418, 1299, 262, 11, 51008], "temperature": 0.0, "avg_logprob": -0.061520761297654734, "compression_ratio": 1.904382470119522, "no_speech_prob": 0.01065161544829607}, {"id": 69, "seek": 35920, "start": 372.08, "end": 377.28, "text": " then we can see that it matches our new lines here and our spaces, but it doesn't match any of these", "tokens": [51008, 550, 321, 393, 536, 300, 309, 10676, 527, 777, 3876, 510, 293, 527, 7673, 11, 457, 309, 1177, 380, 2995, 604, 295, 613, 51268], "temperature": 0.0, "avg_logprob": -0.061520761297654734, "compression_ratio": 1.904382470119522, "no_speech_prob": 0.01065161544829607}, {"id": 70, "seek": 35920, "start": 377.28, "end": 382.8, "text": " characters in here. So it's mainly white space. And just like with the others, the capital s", "tokens": [51268, 4342, 294, 510, 13, 407, 309, 311, 8704, 2418, 1901, 13, 400, 445, 411, 365, 264, 2357, 11, 264, 4238, 262, 51544], "temperature": 0.0, "avg_logprob": -0.061520761297654734, "compression_ratio": 1.904382470119522, "no_speech_prob": 0.01065161544829607}, {"id": 71, "seek": 35920, "start": 382.8, "end": 387.59999999999997, "text": " will search for anything that is not white space. So now you can see that we have, you know, all", "tokens": [51544, 486, 3164, 337, 1340, 300, 307, 406, 2418, 1901, 13, 407, 586, 291, 393, 536, 300, 321, 362, 11, 291, 458, 11, 439, 51784], "temperature": 0.0, "avg_logprob": -0.061520761297654734, "compression_ratio": 1.904382470119522, "no_speech_prob": 0.01065161544829607}, {"id": 72, "seek": 38760, "start": 387.6, "end": 393.20000000000005, "text": " these lowercase uppercase digits and then also this punctuation, anything that isn't a new line", "tokens": [50364, 613, 3126, 9765, 11775, 2869, 651, 27011, 293, 550, 611, 341, 27006, 16073, 11, 1340, 300, 1943, 380, 257, 777, 1622, 50644], "temperature": 0.0, "avg_logprob": -0.06275285411084819, "compression_ratio": 1.718978102189781, "no_speech_prob": 0.0011694785207509995}, {"id": 73, "seek": 38760, "start": 393.20000000000005, "end": 398.64000000000004, "text": " or a space or anything like that. Now these bottom ones over here, the backslash b, the", "tokens": [50644, 420, 257, 1901, 420, 1340, 411, 300, 13, 823, 613, 2767, 2306, 670, 510, 11, 264, 646, 10418, 1299, 272, 11, 264, 50916], "temperature": 0.0, "avg_logprob": -0.06275285411084819, "compression_ratio": 1.718978102189781, "no_speech_prob": 0.0011694785207509995}, {"id": 74, "seek": 38760, "start": 398.64000000000004, "end": 403.76000000000005, "text": " carrot and the dollar sign, these ones are a little bit different. So these are called anchors.", "tokens": [50916, 22767, 293, 264, 7241, 1465, 11, 613, 2306, 366, 257, 707, 857, 819, 13, 407, 613, 366, 1219, 12723, 830, 13, 51172], "temperature": 0.0, "avg_logprob": -0.06275285411084819, "compression_ratio": 1.718978102189781, "no_speech_prob": 0.0011694785207509995}, {"id": 75, "seek": 38760, "start": 403.76000000000005, "end": 410.88, "text": " And they don't actually match any characters, but rather they match invisible positions before or", "tokens": [51172, 400, 436, 500, 380, 767, 2995, 604, 4342, 11, 457, 2831, 436, 2995, 14603, 8432, 949, 420, 51528], "temperature": 0.0, "avg_logprob": -0.06275285411084819, "compression_ratio": 1.718978102189781, "no_speech_prob": 0.0011694785207509995}, {"id": 76, "seek": 38760, "start": 410.88, "end": 417.20000000000005, "text": " after characters. So let's see what I mean by this. So for a word boundary, if I search for a", "tokens": [51528, 934, 4342, 13, 407, 718, 311, 536, 437, 286, 914, 538, 341, 13, 407, 337, 257, 1349, 12866, 11, 498, 286, 3164, 337, 257, 51844], "temperature": 0.0, "avg_logprob": -0.06275285411084819, "compression_ratio": 1.718978102189781, "no_speech_prob": 0.0011694785207509995}, {"id": 77, "seek": 41720, "start": 417.2, "end": 424.24, "text": " word boundary here. So now let's search for where we have this ha ha ha here. Let's search for a", "tokens": [50364, 1349, 12866, 510, 13, 407, 586, 718, 311, 3164, 337, 689, 321, 362, 341, 324, 324, 324, 510, 13, 961, 311, 3164, 337, 257, 50716], "temperature": 0.0, "avg_logprob": -0.06421077627884714, "compression_ratio": 2.0104166666666665, "no_speech_prob": 0.0023230197839438915}, {"id": 78, "seek": 41720, "start": 424.24, "end": 431.12, "text": " word boundary and then ha and match that. So we can see that that matched because there is a word", "tokens": [50716, 1349, 12866, 293, 550, 324, 293, 2995, 300, 13, 407, 321, 393, 536, 300, 300, 21447, 570, 456, 307, 257, 1349, 51060], "temperature": 0.0, "avg_logprob": -0.06421077627884714, "compression_ratio": 2.0104166666666665, "no_speech_prob": 0.0023230197839438915}, {"id": 79, "seek": 41720, "start": 431.12, "end": 437.76, "text": " boundary here at the start of this line before this first one here. And this space here is also", "tokens": [51060, 12866, 510, 412, 264, 722, 295, 341, 1622, 949, 341, 700, 472, 510, 13, 400, 341, 1901, 510, 307, 611, 51392], "temperature": 0.0, "avg_logprob": -0.06421077627884714, "compression_ratio": 2.0104166666666665, "no_speech_prob": 0.0023230197839438915}, {"id": 80, "seek": 41720, "start": 437.76, "end": 443.91999999999996, "text": " word boundary. So this one gets matched as well. But this last one does not get matched because", "tokens": [51392, 1349, 12866, 13, 407, 341, 472, 2170, 21447, 382, 731, 13, 583, 341, 1036, 472, 775, 406, 483, 21447, 570, 51700], "temperature": 0.0, "avg_logprob": -0.06421077627884714, "compression_ratio": 2.0104166666666665, "no_speech_prob": 0.0023230197839438915}, {"id": 81, "seek": 44392, "start": 443.92, "end": 449.52000000000004, "text": " there's no word boundary between these two ha's here. Now just to show what this would look like", "tokens": [50364, 456, 311, 572, 1349, 12866, 1296, 613, 732, 324, 311, 510, 13, 823, 445, 281, 855, 437, 341, 576, 574, 411, 50644], "temperature": 0.0, "avg_logprob": -0.06253699958324432, "compression_ratio": 2.0040816326530613, "no_speech_prob": 0.0033764897380024195}, {"id": 82, "seek": 44392, "start": 449.52000000000004, "end": 453.92, "text": " without the word boundary. If I was to search for that, then you can see that it highlights all three", "tokens": [50644, 1553, 264, 1349, 12866, 13, 759, 286, 390, 281, 3164, 337, 300, 11, 550, 291, 393, 536, 300, 309, 14254, 439, 1045, 50864], "temperature": 0.0, "avg_logprob": -0.06253699958324432, "compression_ratio": 2.0040816326530613, "no_speech_prob": 0.0033764897380024195}, {"id": 83, "seek": 44392, "start": 453.92, "end": 460.0, "text": " of those. Now just like with the other ones, if I do a an uppercase b, then that matches anything", "tokens": [50864, 295, 729, 13, 823, 445, 411, 365, 264, 661, 2306, 11, 498, 286, 360, 257, 364, 11775, 2869, 651, 272, 11, 550, 300, 10676, 1340, 51168], "temperature": 0.0, "avg_logprob": -0.06253699958324432, "compression_ratio": 2.0040816326530613, "no_speech_prob": 0.0033764897380024195}, {"id": 84, "seek": 44392, "start": 460.0, "end": 465.76, "text": " that is not a word boundary. So if I do an uppercase b, then we can see that we match the one that it", "tokens": [51168, 300, 307, 406, 257, 1349, 12866, 13, 407, 498, 286, 360, 364, 11775, 2869, 651, 272, 11, 550, 321, 393, 536, 300, 321, 2995, 264, 472, 300, 309, 51456], "temperature": 0.0, "avg_logprob": -0.06253699958324432, "compression_ratio": 2.0040816326530613, "no_speech_prob": 0.0033764897380024195}, {"id": 85, "seek": 44392, "start": 465.76, "end": 471.04, "text": " didn't match before, because there is no word boundary between these two here. So it doesn't", "tokens": [51456, 994, 380, 2995, 949, 11, 570, 456, 307, 572, 1349, 12866, 1296, 613, 732, 510, 13, 407, 309, 1177, 380, 51720], "temperature": 0.0, "avg_logprob": -0.06253699958324432, "compression_ratio": 2.0040816326530613, "no_speech_prob": 0.0033764897380024195}, {"id": 86, "seek": 47104, "start": 471.04, "end": 477.84000000000003, "text": " match these first two. Now if I was to put word boundaries on both sides of these, then it should", "tokens": [50364, 2995, 613, 700, 732, 13, 823, 498, 286, 390, 281, 829, 1349, 13180, 322, 1293, 4881, 295, 613, 11, 550, 309, 820, 50704], "temperature": 0.0, "avg_logprob": -0.04328494169274155, "compression_ratio": 1.9845360824742269, "no_speech_prob": 0.004331357777118683}, {"id": 87, "seek": 47104, "start": 477.84000000000003, "end": 484.64000000000004, "text": " only match this first one, because this is the only one that has a word boundary at the beginning,", "tokens": [50704, 787, 2995, 341, 700, 472, 11, 570, 341, 307, 264, 787, 472, 300, 575, 257, 1349, 12866, 412, 264, 2863, 11, 51044], "temperature": 0.0, "avg_logprob": -0.04328494169274155, "compression_ratio": 1.9845360824742269, "no_speech_prob": 0.004331357777118683}, {"id": 88, "seek": 47104, "start": 484.64000000000004, "end": 491.04, "text": " which we're matching here, and at the end. So this one has a word boundary at the beginning,", "tokens": [51044, 597, 321, 434, 14324, 510, 11, 293, 412, 264, 917, 13, 407, 341, 472, 575, 257, 1349, 12866, 412, 264, 2863, 11, 51364], "temperature": 0.0, "avg_logprob": -0.04328494169274155, "compression_ratio": 1.9845360824742269, "no_speech_prob": 0.004331357777118683}, {"id": 89, "seek": 47104, "start": 491.04, "end": 496.72, "text": " but not at the end because it's in the middle of this word. And this one has a word boundary at", "tokens": [51364, 457, 406, 412, 264, 917, 570, 309, 311, 294, 264, 2808, 295, 341, 1349, 13, 400, 341, 472, 575, 257, 1349, 12866, 412, 51648], "temperature": 0.0, "avg_logprob": -0.04328494169274155, "compression_ratio": 1.9845360824742269, "no_speech_prob": 0.004331357777118683}, {"id": 90, "seek": 49672, "start": 496.72, "end": 502.0, "text": " the end, but not at the beginning. Okay, so our other two anchors here are pretty similar. So the", "tokens": [50364, 264, 917, 11, 457, 406, 412, 264, 2863, 13, 1033, 11, 370, 527, 661, 732, 12723, 830, 510, 366, 1238, 2531, 13, 407, 264, 50628], "temperature": 0.0, "avg_logprob": -0.061281708837712855, "compression_ratio": 1.9306930693069306, "no_speech_prob": 0.008061510510742664}, {"id": 91, "seek": 49672, "start": 502.0, "end": 508.08000000000004, "text": " carrot matches the position at the beginning of a string, and the dollar sign matches the position", "tokens": [50628, 22767, 10676, 264, 2535, 412, 264, 2863, 295, 257, 6798, 11, 293, 264, 7241, 1465, 10676, 264, 2535, 50932], "temperature": 0.0, "avg_logprob": -0.061281708837712855, "compression_ratio": 1.9306930693069306, "no_speech_prob": 0.008061510510742664}, {"id": 92, "seek": 49672, "start": 508.08000000000004, "end": 514.88, "text": " at the end of a string. So let's say for example, that we only wanted to match a ha if it was at", "tokens": [50932, 412, 264, 917, 295, 257, 6798, 13, 407, 718, 311, 584, 337, 1365, 11, 300, 321, 787, 1415, 281, 2995, 257, 324, 498, 309, 390, 412, 51272], "temperature": 0.0, "avg_logprob": -0.061281708837712855, "compression_ratio": 1.9306930693069306, "no_speech_prob": 0.008061510510742664}, {"id": 93, "seek": 49672, "start": 514.88, "end": 522.1600000000001, "text": " the beginning of a string. So for example, if I was to do a carrot and then a ha and match that,", "tokens": [51272, 264, 2863, 295, 257, 6798, 13, 407, 337, 1365, 11, 498, 286, 390, 281, 360, 257, 22767, 293, 550, 257, 324, 293, 2995, 300, 11, 51636], "temperature": 0.0, "avg_logprob": -0.061281708837712855, "compression_ratio": 1.9306930693069306, "no_speech_prob": 0.008061510510742664}, {"id": 94, "seek": 52216, "start": 522.16, "end": 525.76, "text": " then we can see that it only matched this one, because it's the only one", "tokens": [50364, 550, 321, 393, 536, 300, 309, 787, 21447, 341, 472, 11, 570, 309, 311, 264, 787, 472, 50544], "temperature": 0.0, "avg_logprob": -0.061882412433624266, "compression_ratio": 2.03125, "no_speech_prob": 0.004331349860876799}, {"id": 95, "seek": 52216, "start": 525.76, "end": 531.4399999999999, "text": " that is at the beginning of a line. Now if we wanted to only match it if it was at the end,", "tokens": [50544, 300, 307, 412, 264, 2863, 295, 257, 1622, 13, 823, 498, 321, 1415, 281, 787, 2995, 309, 498, 309, 390, 412, 264, 917, 11, 50828], "temperature": 0.0, "avg_logprob": -0.061882412433624266, "compression_ratio": 2.03125, "no_speech_prob": 0.004331349860876799}, {"id": 96, "seek": 52216, "start": 531.4399999999999, "end": 537.12, "text": " then we could put that dollar sign at the end. And what we're saying here is that we only want", "tokens": [50828, 550, 321, 727, 829, 300, 7241, 1465, 412, 264, 917, 13, 400, 437, 321, 434, 1566, 510, 307, 300, 321, 787, 528, 51112], "temperature": 0.0, "avg_logprob": -0.061882412433624266, "compression_ratio": 2.03125, "no_speech_prob": 0.004331349860876799}, {"id": 97, "seek": 52216, "start": 537.12, "end": 543.6, "text": " to match this if the end of the string is the is in the following position. So we can see that it", "tokens": [51112, 281, 2995, 341, 498, 264, 917, 295, 264, 6798, 307, 264, 307, 294, 264, 3480, 2535, 13, 407, 321, 393, 536, 300, 309, 51436], "temperature": 0.0, "avg_logprob": -0.061882412433624266, "compression_ratio": 2.03125, "no_speech_prob": 0.004331349860876799}, {"id": 98, "seek": 52216, "start": 543.6, "end": 548.9599999999999, "text": " not only matches this last one, because the end of the string is the next position in line. Okay,", "tokens": [51436, 406, 787, 10676, 341, 1036, 472, 11, 570, 264, 917, 295, 264, 6798, 307, 264, 958, 2535, 294, 1622, 13, 1033, 11, 51704], "temperature": 0.0, "avg_logprob": -0.061882412433624266, "compression_ratio": 2.03125, "no_speech_prob": 0.004331349860876799}, {"id": 99, "seek": 54896, "start": 548.96, "end": 554.32, "text": " so now that we've seen what we can match with these special characters here, now let's go ahead", "tokens": [50364, 370, 586, 300, 321, 600, 1612, 437, 321, 393, 2995, 365, 613, 2121, 4342, 510, 11, 586, 718, 311, 352, 2286, 50632], "temperature": 0.0, "avg_logprob": -0.044603975613911946, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.015423271805047989}, {"id": 100, "seek": 54896, "start": 554.32, "end": 559.52, "text": " and take a look at some practical examples. So I'm going to move my snippets file back here,", "tokens": [50632, 293, 747, 257, 574, 412, 512, 8496, 5110, 13, 407, 286, 478, 516, 281, 1286, 452, 35623, 1385, 3991, 646, 510, 11, 50892], "temperature": 0.0, "avg_logprob": -0.044603975613911946, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.015423271805047989}, {"id": 101, "seek": 54896, "start": 559.52, "end": 564.96, "text": " and we will keep referencing that later on. But for now, let's go ahead and say that we wanted", "tokens": [50892, 293, 321, 486, 1066, 40582, 300, 1780, 322, 13, 583, 337, 586, 11, 718, 311, 352, 2286, 293, 584, 300, 321, 1415, 51164], "temperature": 0.0, "avg_logprob": -0.044603975613911946, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.015423271805047989}, {"id": 102, "seek": 54896, "start": 564.96, "end": 569.12, "text": " to match a couple of phone numbers. And let's write some regular expressions to do this. Now", "tokens": [51164, 281, 2995, 257, 1916, 295, 2593, 3547, 13, 400, 718, 311, 2464, 512, 3890, 15277, 281, 360, 341, 13, 823, 51372], "temperature": 0.0, "avg_logprob": -0.044603975613911946, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.015423271805047989}, {"id": 103, "seek": 54896, "start": 569.12, "end": 574.1600000000001, "text": " with a phone number, we can't just type in a literal search like we did before, because all of these", "tokens": [51372, 365, 257, 2593, 1230, 11, 321, 393, 380, 445, 2010, 294, 257, 20411, 3164, 411, 321, 630, 949, 11, 570, 439, 295, 613, 51624], "temperature": 0.0, "avg_logprob": -0.044603975613911946, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.015423271805047989}, {"id": 104, "seek": 57416, "start": 574.16, "end": 580.4, "text": " are different. So they have a similar pattern, but they're not all the same digits. So in this case,", "tokens": [50364, 366, 819, 13, 407, 436, 362, 257, 2531, 5102, 11, 457, 436, 434, 406, 439, 264, 912, 27011, 13, 407, 294, 341, 1389, 11, 50676], "temperature": 0.0, "avg_logprob": -0.05102212501294685, "compression_ratio": 1.9540816326530612, "no_speech_prob": 0.035141222178936005}, {"id": 105, "seek": 57416, "start": 580.4, "end": 586.8, "text": " we need to use the meta characters instead of literal characters. So we just have a pattern here", "tokens": [50676, 321, 643, 281, 764, 264, 19616, 4342, 2602, 295, 20411, 4342, 13, 407, 321, 445, 362, 257, 5102, 510, 50996], "temperature": 0.0, "avg_logprob": -0.05102212501294685, "compression_ratio": 1.9540816326530612, "no_speech_prob": 0.035141222178936005}, {"id": 106, "seek": 57416, "start": 586.8, "end": 593.4399999999999, "text": " of three digits, and then a dash or a period, and then three more digits, and then a dash", "tokens": [50996, 295, 1045, 27011, 11, 293, 550, 257, 8240, 420, 257, 2896, 11, 293, 550, 1045, 544, 27011, 11, 293, 550, 257, 8240, 51328], "temperature": 0.0, "avg_logprob": -0.05102212501294685, "compression_ratio": 1.9540816326530612, "no_speech_prob": 0.035141222178936005}, {"id": 107, "seek": 57416, "start": 593.4399999999999, "end": 599.92, "text": " or a period, and then four digits at the end. So we saw before that we can match a digit with a", "tokens": [51328, 420, 257, 2896, 11, 293, 550, 1451, 27011, 412, 264, 917, 13, 407, 321, 1866, 949, 300, 321, 393, 2995, 257, 14293, 365, 257, 51652], "temperature": 0.0, "avg_logprob": -0.05102212501294685, "compression_ratio": 1.9540816326530612, "no_speech_prob": 0.035141222178936005}, {"id": 108, "seek": 59992, "start": 600.0, "end": 606.4799999999999, "text": " backslash d. And that is going to match all of the digits in our file. So we want to match", "tokens": [50368, 646, 10418, 1299, 274, 13, 400, 300, 307, 516, 281, 2995, 439, 295, 264, 27011, 294, 527, 3991, 13, 407, 321, 528, 281, 2995, 50692], "temperature": 0.0, "avg_logprob": -0.05396955460309982, "compression_ratio": 2.1454545454545455, "no_speech_prob": 0.010986044071614742}, {"id": 109, "seek": 59992, "start": 606.4799999999999, "end": 612.4, "text": " this phone number here. So we want to match first three digits in a row. So we can just put in", "tokens": [50692, 341, 2593, 1230, 510, 13, 407, 321, 528, 281, 2995, 700, 1045, 27011, 294, 257, 5386, 13, 407, 321, 393, 445, 829, 294, 50988], "temperature": 0.0, "avg_logprob": -0.05396955460309982, "compression_ratio": 2.1454545454545455, "no_speech_prob": 0.010986044071614742}, {"id": 110, "seek": 59992, "start": 612.4, "end": 617.92, "text": " three backslash d's, and that will match any three digits in a row. So now that we're matching", "tokens": [50988, 1045, 646, 10418, 1299, 274, 311, 11, 293, 300, 486, 2995, 604, 1045, 27011, 294, 257, 5386, 13, 407, 586, 300, 321, 434, 14324, 51264], "temperature": 0.0, "avg_logprob": -0.05396955460309982, "compression_ratio": 2.1454545454545455, "no_speech_prob": 0.010986044071614742}, {"id": 111, "seek": 59992, "start": 617.92, "end": 622.4, "text": " those first three digits, now we're getting to where we can see that we're either going to match", "tokens": [51264, 729, 700, 1045, 27011, 11, 586, 321, 434, 1242, 281, 689, 321, 393, 536, 300, 321, 434, 2139, 516, 281, 2995, 51488], "temperature": 0.0, "avg_logprob": -0.05396955460309982, "compression_ratio": 2.1454545454545455, "no_speech_prob": 0.010986044071614742}, {"id": 112, "seek": 59992, "start": 622.4, "end": 628.9599999999999, "text": " a dash or a dot in our phone number. So for now, let's just match any character that's in this", "tokens": [51488, 257, 8240, 420, 257, 5893, 294, 527, 2593, 1230, 13, 407, 337, 586, 11, 718, 311, 445, 2995, 604, 2517, 300, 311, 294, 341, 51816], "temperature": 0.0, "avg_logprob": -0.05396955460309982, "compression_ratio": 2.1454545454545455, "no_speech_prob": 0.010986044071614742}, {"id": 113, "seek": 62896, "start": 628.96, "end": 634.64, "text": " position. So from our snippets file, we saw that if we want to match any character that we can use", "tokens": [50364, 2535, 13, 407, 490, 527, 35623, 1385, 3991, 11, 321, 1866, 300, 498, 321, 528, 281, 2995, 604, 2517, 300, 321, 393, 764, 50648], "temperature": 0.0, "avg_logprob": -0.04640497801438818, "compression_ratio": 1.708695652173913, "no_speech_prob": 0.0011335383169353008}, {"id": 114, "seek": 62896, "start": 634.64, "end": 640.08, "text": " a dot. So we can see that for now, our pattern is still matching some other stuff as well. But", "tokens": [50648, 257, 5893, 13, 407, 321, 393, 536, 300, 337, 586, 11, 527, 5102, 307, 920, 14324, 512, 661, 1507, 382, 731, 13, 583, 50920], "temperature": 0.0, "avg_logprob": -0.04640497801438818, "compression_ratio": 1.708695652173913, "no_speech_prob": 0.0011335383169353008}, {"id": 115, "seek": 62896, "start": 640.08, "end": 646.32, "text": " let's just continue on. So now that we're matching this hyphen or this dot, now let's go ahead and", "tokens": [50920, 718, 311, 445, 2354, 322, 13, 407, 586, 300, 321, 434, 14324, 341, 2477, 47059, 420, 341, 5893, 11, 586, 718, 311, 352, 2286, 293, 51232], "temperature": 0.0, "avg_logprob": -0.04640497801438818, "compression_ratio": 1.708695652173913, "no_speech_prob": 0.0011335383169353008}, {"id": 116, "seek": 62896, "start": 646.32, "end": 652.88, "text": " add in the next three digits. So we want to search for three more digits. So I'll do three backslash", "tokens": [51232, 909, 294, 264, 958, 1045, 27011, 13, 407, 321, 528, 281, 3164, 337, 1045, 544, 27011, 13, 407, 286, 603, 360, 1045, 646, 10418, 1299, 51560], "temperature": 0.0, "avg_logprob": -0.04640497801438818, "compression_ratio": 1.708695652173913, "no_speech_prob": 0.0011335383169353008}, {"id": 117, "seek": 65288, "start": 652.88, "end": 658.8, "text": " d's. And now we're going to want a dot to match any character, which should match that dash or", "tokens": [50364, 274, 311, 13, 400, 586, 321, 434, 516, 281, 528, 257, 5893, 281, 2995, 604, 2517, 11, 597, 820, 2995, 300, 8240, 420, 50660], "temperature": 0.0, "avg_logprob": -0.05010666275024414, "compression_ratio": 1.797752808988764, "no_speech_prob": 0.10816802084445953}, {"id": 118, "seek": 65288, "start": 658.8, "end": 665.4399999999999, "text": " that dot. And now we want four digits. So we can just do four backslash d's. So now we can see that", "tokens": [50660, 300, 5893, 13, 400, 586, 321, 528, 1451, 27011, 13, 407, 321, 393, 445, 360, 1451, 646, 10418, 1299, 274, 311, 13, 407, 586, 321, 393, 536, 300, 50992], "temperature": 0.0, "avg_logprob": -0.05010666275024414, "compression_ratio": 1.797752808988764, "no_speech_prob": 0.10816802084445953}, {"id": 119, "seek": 65288, "start": 665.4399999999999, "end": 670.32, "text": " this regular expression highlights both of our phone numbers and matches both of those. So now", "tokens": [50992, 341, 3890, 6114, 14254, 1293, 295, 527, 2593, 3547, 293, 10676, 1293, 295, 729, 13, 407, 586, 51236], "temperature": 0.0, "avg_logprob": -0.05010666275024414, "compression_ratio": 1.797752808988764, "no_speech_prob": 0.10816802084445953}, {"id": 120, "seek": 65288, "start": 670.32, "end": 676.08, "text": " we're starting to see how this could be pretty useful. So for example, I have a data file here.", "tokens": [51236, 321, 434, 2891, 281, 536, 577, 341, 727, 312, 1238, 4420, 13, 407, 337, 1365, 11, 286, 362, 257, 1412, 3991, 510, 13, 51524], "temperature": 0.0, "avg_logprob": -0.05010666275024414, "compression_ratio": 1.797752808988764, "no_speech_prob": 0.10816802084445953}, {"id": 121, "seek": 65288, "start": 676.08, "end": 681.92, "text": " Now if I pull this up, then I have a bunch of fake names and numbers and addresses and emails.", "tokens": [51524, 823, 498, 286, 2235, 341, 493, 11, 550, 286, 362, 257, 3840, 295, 7592, 5288, 293, 3547, 293, 16862, 293, 12524, 13, 51816], "temperature": 0.0, "avg_logprob": -0.05010666275024414, "compression_ratio": 1.797752808988764, "no_speech_prob": 0.10816802084445953}, {"id": 122, "seek": 68192, "start": 681.92, "end": 686.3199999999999, "text": " But if I wanted to match all of the phone numbers in this file, then you can see that the regular", "tokens": [50364, 583, 498, 286, 1415, 281, 2995, 439, 295, 264, 2593, 3547, 294, 341, 3991, 11, 550, 291, 393, 536, 300, 264, 3890, 50584], "temperature": 0.0, "avg_logprob": -0.034402564420538434, "compression_ratio": 1.8532818532818534, "no_speech_prob": 0.00014883646508678794}, {"id": 123, "seek": 68192, "start": 686.3199999999999, "end": 692.0799999999999, "text": " expression that we just wrote matches all of the phone numbers here. So now we're starting to kind", "tokens": [50584, 6114, 300, 321, 445, 4114, 10676, 439, 295, 264, 2593, 3547, 510, 13, 407, 586, 321, 434, 2891, 281, 733, 50872], "temperature": 0.0, "avg_logprob": -0.034402564420538434, "compression_ratio": 1.8532818532818534, "no_speech_prob": 0.00014883646508678794}, {"id": 124, "seek": 68192, "start": 692.0799999999999, "end": 696.88, "text": " of get a sense of how this could be more useful than just a literal search, because now we're", "tokens": [50872, 295, 483, 257, 2020, 295, 577, 341, 727, 312, 544, 4420, 813, 445, 257, 20411, 3164, 11, 570, 586, 321, 434, 51112], "temperature": 0.0, "avg_logprob": -0.034402564420538434, "compression_ratio": 1.8532818532818534, "no_speech_prob": 0.00014883646508678794}, {"id": 125, "seek": 68192, "start": 696.88, "end": 703.36, "text": " actually searching for a specific pattern. So now let me go back to our simple text file here.", "tokens": [51112, 767, 10808, 337, 257, 2685, 5102, 13, 407, 586, 718, 385, 352, 646, 281, 527, 2199, 2487, 3991, 510, 13, 51436], "temperature": 0.0, "avg_logprob": -0.034402564420538434, "compression_ratio": 1.8532818532818534, "no_speech_prob": 0.00014883646508678794}, {"id": 126, "seek": 68192, "start": 703.36, "end": 707.5999999999999, "text": " So now let's get a little bit more specific. So let's say that we only wanted to match a phone", "tokens": [51436, 407, 586, 718, 311, 483, 257, 707, 857, 544, 2685, 13, 407, 718, 311, 584, 300, 321, 787, 1415, 281, 2995, 257, 2593, 51648], "temperature": 0.0, "avg_logprob": -0.034402564420538434, "compression_ratio": 1.8532818532818534, "no_speech_prob": 0.00014883646508678794}, {"id": 127, "seek": 70760, "start": 707.6, "end": 713.84, "text": " number if it had a dash or a dot. Now right now, this pattern will match any separator,", "tokens": [50364, 1230, 498, 309, 632, 257, 8240, 420, 257, 5893, 13, 823, 558, 586, 11, 341, 5102, 486, 2995, 604, 3128, 1639, 11, 50676], "temperature": 0.0, "avg_logprob": -0.05777360901000008, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.03514116629958153}, {"id": 128, "seek": 70760, "start": 713.84, "end": 719.28, "text": " because we're using the period down here, which will match any character. So if I was to put in", "tokens": [50676, 570, 321, 434, 1228, 264, 2896, 760, 510, 11, 597, 486, 2995, 604, 2517, 13, 407, 498, 286, 390, 281, 829, 294, 50948], "temperature": 0.0, "avg_logprob": -0.05777360901000008, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.03514116629958153}, {"id": 129, "seek": 70760, "start": 719.28, "end": 726.5600000000001, "text": " a another number here that doesn't have a regular separator, let's just say it's an asterisk,", "tokens": [50948, 257, 1071, 1230, 510, 300, 1177, 380, 362, 257, 3890, 3128, 1639, 11, 718, 311, 445, 584, 309, 311, 364, 257, 3120, 7797, 11, 51312], "temperature": 0.0, "avg_logprob": -0.05777360901000008, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.03514116629958153}, {"id": 130, "seek": 70760, "start": 726.5600000000001, "end": 731.12, "text": " then we can see that it matches this number as well, even though the asterisk isn't really a", "tokens": [51312, 550, 321, 393, 536, 300, 309, 10676, 341, 1230, 382, 731, 11, 754, 1673, 264, 257, 3120, 7797, 1943, 380, 534, 257, 51540], "temperature": 0.0, "avg_logprob": -0.05777360901000008, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.03514116629958153}, {"id": 131, "seek": 70760, "start": 731.12, "end": 737.36, "text": " phone number separator. So to only match the dash or the dot, we're going to have to use a character", "tokens": [51540, 2593, 1230, 3128, 1639, 13, 407, 281, 787, 2995, 264, 8240, 420, 264, 5893, 11, 321, 434, 516, 281, 362, 281, 764, 257, 2517, 51852], "temperature": 0.0, "avg_logprob": -0.05777360901000008, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.03514116629958153}, {"id": 132, "seek": 73736, "start": 737.36, "end": 743.6800000000001, "text": " set. And a character set uses square brackets with the characters that we want to match. So to", "tokens": [50364, 992, 13, 400, 257, 2517, 992, 4960, 3732, 26179, 365, 264, 4342, 300, 321, 528, 281, 2995, 13, 407, 281, 50680], "temperature": 0.0, "avg_logprob": -0.05560485197573292, "compression_ratio": 2.1032608695652173, "no_speech_prob": 0.0010004392825067043}, {"id": 133, "seek": 73736, "start": 743.6800000000001, "end": 748.64, "text": " create a character set, I'm going to replace our first dot here. And this is going to be square", "tokens": [50680, 1884, 257, 2517, 992, 11, 286, 478, 516, 281, 7406, 527, 700, 5893, 510, 13, 400, 341, 307, 516, 281, 312, 3732, 50928], "temperature": 0.0, "avg_logprob": -0.05560485197573292, "compression_ratio": 2.1032608695652173, "no_speech_prob": 0.0010004392825067043}, {"id": 134, "seek": 73736, "start": 748.64, "end": 754.24, "text": " brackets. Now this is a character set. Now within this character set, we want to put the characters", "tokens": [50928, 26179, 13, 823, 341, 307, 257, 2517, 992, 13, 823, 1951, 341, 2517, 992, 11, 321, 528, 281, 829, 264, 4342, 51208], "temperature": 0.0, "avg_logprob": -0.05560485197573292, "compression_ratio": 2.1032608695652173, "no_speech_prob": 0.0010004392825067043}, {"id": 135, "seek": 73736, "start": 754.24, "end": 761.04, "text": " that we want to match. So we want to match either a dash or a dot. And I will just copy that and", "tokens": [51208, 300, 321, 528, 281, 2995, 13, 407, 321, 528, 281, 2995, 2139, 257, 8240, 420, 257, 5893, 13, 400, 286, 486, 445, 5055, 300, 293, 51548], "temperature": 0.0, "avg_logprob": -0.05560485197573292, "compression_ratio": 2.1032608695652173, "no_speech_prob": 0.0010004392825067043}, {"id": 136, "seek": 76104, "start": 761.04, "end": 766.88, "text": " we'll replace this second dot here, which was matching any character. And we will put that", "tokens": [50364, 321, 603, 7406, 341, 1150, 5893, 510, 11, 597, 390, 14324, 604, 2517, 13, 400, 321, 486, 829, 300, 50656], "temperature": 0.0, "avg_logprob": -0.05075357656563278, "compression_ratio": 1.8295454545454546, "no_speech_prob": 0.002182658528909087}, {"id": 137, "seek": 76104, "start": 766.88, "end": 772.88, "text": " in for that as well. And now you can see that it only matches our phone numbers here that have a", "tokens": [50656, 294, 337, 300, 382, 731, 13, 400, 586, 291, 393, 536, 300, 309, 787, 10676, 527, 2593, 3547, 510, 300, 362, 257, 50956], "temperature": 0.0, "avg_logprob": -0.05075357656563278, "compression_ratio": 1.8295454545454546, "no_speech_prob": 0.002182658528909087}, {"id": 138, "seek": 76104, "start": 772.88, "end": 778.48, "text": " dash or a dot separator. And it does not match this one with the weird asterisk there. Now you", "tokens": [50956, 8240, 420, 257, 5893, 3128, 1639, 13, 400, 309, 775, 406, 2995, 341, 472, 365, 264, 3657, 257, 3120, 7797, 456, 13, 823, 291, 51236], "temperature": 0.0, "avg_logprob": -0.05075357656563278, "compression_ratio": 1.8295454545454546, "no_speech_prob": 0.002182658528909087}, {"id": 139, "seek": 76104, "start": 778.48, "end": 784.0, "text": " probably also notice that we didn't need to escape our dot character within our character set. And", "tokens": [51236, 1391, 611, 3449, 300, 321, 994, 380, 643, 281, 7615, 527, 5893, 2517, 1951, 527, 2517, 992, 13, 400, 51512], "temperature": 0.0, "avg_logprob": -0.05075357656563278, "compression_ratio": 1.8295454545454546, "no_speech_prob": 0.002182658528909087}, {"id": 140, "seek": 76104, "start": 784.0, "end": 788.88, "text": " that's because character sets have some slightly different rules. Now you can escape these characters", "tokens": [51512, 300, 311, 570, 2517, 6352, 362, 512, 4748, 819, 4474, 13, 823, 291, 393, 7615, 613, 4342, 51756], "temperature": 0.0, "avg_logprob": -0.05075357656563278, "compression_ratio": 1.8295454545454546, "no_speech_prob": 0.002182658528909087}, {"id": 141, "seek": 78888, "start": 788.88, "end": 793.6, "text": " if you'd like. But it just makes it a lot more difficult to read if you do that. Now even though", "tokens": [50364, 498, 291, 1116, 411, 13, 583, 309, 445, 1669, 309, 257, 688, 544, 2252, 281, 1401, 498, 291, 360, 300, 13, 823, 754, 1673, 50600], "temperature": 0.0, "avg_logprob": -0.04355060108124264, "compression_ratio": 1.8058608058608059, "no_speech_prob": 0.0005703081842511892}, {"id": 142, "seek": 78888, "start": 793.6, "end": 799.76, "text": " the character set has multiple characters here in the set, it's still only matching one character", "tokens": [50600, 264, 2517, 992, 575, 3866, 4342, 510, 294, 264, 992, 11, 309, 311, 920, 787, 14324, 472, 2517, 50908], "temperature": 0.0, "avg_logprob": -0.04355060108124264, "compression_ratio": 1.8058608058608059, "no_speech_prob": 0.0005703081842511892}, {"id": 143, "seek": 78888, "start": 799.76, "end": 806.08, "text": " in our text. It's matching one character that is either a dash or a period. But if I was to put in,", "tokens": [50908, 294, 527, 2487, 13, 467, 311, 14324, 472, 2517, 300, 307, 2139, 257, 8240, 420, 257, 2896, 13, 583, 498, 286, 390, 281, 829, 294, 11, 51224], "temperature": 0.0, "avg_logprob": -0.04355060108124264, "compression_ratio": 1.8058608058608059, "no_speech_prob": 0.0005703081842511892}, {"id": 144, "seek": 78888, "start": 806.08, "end": 811.6, "text": " let's say two dashes here into one of these numbers, then you can see now it doesn't match that number", "tokens": [51224, 718, 311, 584, 732, 8240, 279, 510, 666, 472, 295, 613, 3547, 11, 550, 291, 393, 536, 586, 309, 1177, 380, 2995, 300, 1230, 51500], "temperature": 0.0, "avg_logprob": -0.04355060108124264, "compression_ratio": 1.8058608058608059, "no_speech_prob": 0.0005703081842511892}, {"id": 145, "seek": 78888, "start": 811.6, "end": 818.08, "text": " because it's only matching the first dash or a dot. And then it moves right on to looking for a", "tokens": [51500, 570, 309, 311, 787, 14324, 264, 700, 8240, 420, 257, 5893, 13, 400, 550, 309, 6067, 558, 322, 281, 1237, 337, 257, 51824], "temperature": 0.0, "avg_logprob": -0.04355060108124264, "compression_ratio": 1.8058608058608059, "no_speech_prob": 0.0005703081842511892}, {"id": 146, "seek": 81808, "start": 818.08, "end": 822.48, "text": " digit. So it's looking for a digit in this position. So that's something that can kind of throw", "tokens": [50364, 14293, 13, 407, 309, 311, 1237, 337, 257, 14293, 294, 341, 2535, 13, 407, 300, 311, 746, 300, 393, 733, 295, 3507, 50584], "temperature": 0.0, "avg_logprob": -0.04716629165786881, "compression_ratio": 1.7718631178707225, "no_speech_prob": 0.001648406032472849}, {"id": 147, "seek": 81808, "start": 822.48, "end": 826.5600000000001, "text": " people off when they first start working with regular expressions. So even though, you know,", "tokens": [50584, 561, 766, 562, 436, 700, 722, 1364, 365, 3890, 15277, 13, 407, 754, 1673, 11, 291, 458, 11, 50788], "temperature": 0.0, "avg_logprob": -0.04716629165786881, "compression_ratio": 1.7718631178707225, "no_speech_prob": 0.001648406032472849}, {"id": 148, "seek": 81808, "start": 826.5600000000001, "end": 830.88, "text": " we have four characters total here in this character set with these square brackets,", "tokens": [50788, 321, 362, 1451, 4342, 3217, 510, 294, 341, 2517, 992, 365, 613, 3732, 26179, 11, 51004], "temperature": 0.0, "avg_logprob": -0.04716629165786881, "compression_ratio": 1.7718631178707225, "no_speech_prob": 0.001648406032472849}, {"id": 149, "seek": 81808, "start": 830.88, "end": 836.72, "text": " and all of the characters in this set, it's still only searching for one literal character up here,", "tokens": [51004, 293, 439, 295, 264, 4342, 294, 341, 992, 11, 309, 311, 920, 787, 10808, 337, 472, 20411, 2517, 493, 510, 11, 51296], "temperature": 0.0, "avg_logprob": -0.04716629165786881, "compression_ratio": 1.7718631178707225, "no_speech_prob": 0.001648406032472849}, {"id": 150, "seek": 81808, "start": 836.72, "end": 842.08, "text": " which is either a dash or a dot. Now to show another example of this, let's say that we only", "tokens": [51296, 597, 307, 2139, 257, 8240, 420, 257, 5893, 13, 823, 281, 855, 1071, 1365, 295, 341, 11, 718, 311, 584, 300, 321, 787, 51564], "temperature": 0.0, "avg_logprob": -0.04716629165786881, "compression_ratio": 1.7718631178707225, "no_speech_prob": 0.001648406032472849}, {"id": 151, "seek": 84208, "start": 842.08, "end": 848.64, "text": " wanted to match 800 and 900 numbers. So I'm going to create two different numbers here. I'll do an", "tokens": [50364, 1415, 281, 2995, 13083, 293, 22016, 3547, 13, 407, 286, 478, 516, 281, 1884, 732, 819, 3547, 510, 13, 286, 603, 360, 364, 50692], "temperature": 0.0, "avg_logprob": -0.05665495789166793, "compression_ratio": 1.8457943925233644, "no_speech_prob": 0.04742107540369034}, {"id": 152, "seek": 84208, "start": 848.64, "end": 856.72, "text": " 800 number and a 900 number here. So if we only wanted to match 800 and 900 numbers, then our first", "tokens": [50692, 13083, 1230, 293, 257, 22016, 1230, 510, 13, 407, 498, 321, 787, 1415, 281, 2995, 13083, 293, 22016, 3547, 11, 550, 527, 700, 51096], "temperature": 0.0, "avg_logprob": -0.05665495789166793, "compression_ratio": 1.8457943925233644, "no_speech_prob": 0.04742107540369034}, {"id": 153, "seek": 84208, "start": 856.72, "end": 862.1600000000001, "text": " three digits here, we have to do something different. So first, we want the first digit that we're", "tokens": [51096, 1045, 27011, 510, 11, 321, 362, 281, 360, 746, 819, 13, 407, 700, 11, 321, 528, 264, 700, 14293, 300, 321, 434, 51368], "temperature": 0.0, "avg_logprob": -0.05665495789166793, "compression_ratio": 1.8457943925233644, "no_speech_prob": 0.04742107540369034}, {"id": 154, "seek": 84208, "start": 862.1600000000001, "end": 867.6800000000001, "text": " going to match to either be an eight or a nine. So we can do a character set. And we can say that", "tokens": [51368, 516, 281, 2995, 281, 2139, 312, 364, 3180, 420, 257, 4949, 13, 407, 321, 393, 360, 257, 2517, 992, 13, 400, 321, 393, 584, 300, 51644], "temperature": 0.0, "avg_logprob": -0.05665495789166793, "compression_ratio": 1.8457943925233644, "no_speech_prob": 0.04742107540369034}, {"id": 155, "seek": 86768, "start": 867.68, "end": 874.4799999999999, "text": " we're looking to either start with an eight or a nine. Now the following two numbers are going to be", "tokens": [50364, 321, 434, 1237, 281, 2139, 722, 365, 364, 3180, 420, 257, 4949, 13, 823, 264, 3480, 732, 3547, 366, 516, 281, 312, 50704], "temperature": 0.0, "avg_logprob": -0.06322355368702683, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.0004044751403853297}, {"id": 156, "seek": 86768, "start": 874.4799999999999, "end": 880.4799999999999, "text": " zero zero. And that's just a literal search. So now you can see that we're finding the 800 and 900", "tokens": [50704, 4018, 4018, 13, 400, 300, 311, 445, 257, 20411, 3164, 13, 407, 586, 291, 393, 536, 300, 321, 434, 5006, 264, 13083, 293, 22016, 51004], "temperature": 0.0, "avg_logprob": -0.06322355368702683, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.0004044751403853297}, {"id": 157, "seek": 86768, "start": 880.4799999999999, "end": 886.9599999999999, "text": " numbers here. Now within our character set, the dash is actually a special character as well.", "tokens": [51004, 3547, 510, 13, 823, 1951, 527, 2517, 992, 11, 264, 8240, 307, 767, 257, 2121, 2517, 382, 731, 13, 51328], "temperature": 0.0, "avg_logprob": -0.06322355368702683, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.0004044751403853297}, {"id": 158, "seek": 86768, "start": 886.9599999999999, "end": 892.4, "text": " So when it's put at the beginning or the end of the character set, then it will just match the", "tokens": [51328, 407, 562, 309, 311, 829, 412, 264, 2863, 420, 264, 917, 295, 264, 2517, 992, 11, 550, 309, 486, 445, 2995, 264, 51600], "temperature": 0.0, "avg_logprob": -0.06322355368702683, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.0004044751403853297}, {"id": 159, "seek": 89240, "start": 892.48, "end": 898.9599999999999, "text": " literal dash. But when it's placed between values that can actually specify a range of values. So", "tokens": [50368, 20411, 8240, 13, 583, 562, 309, 311, 7074, 1296, 4190, 300, 393, 767, 16500, 257, 3613, 295, 4190, 13, 407, 50692], "temperature": 0.0, "avg_logprob": -0.08052657854439009, "compression_ratio": 1.6623931623931625, "no_speech_prob": 0.07583699375391006}, {"id": 160, "seek": 89240, "start": 898.9599999999999, "end": 905.52, "text": " for example, we know that the backslash D matches any digit. But what if we only wanted to match", "tokens": [50692, 337, 1365, 11, 321, 458, 300, 264, 646, 10418, 1299, 413, 10676, 604, 14293, 13, 583, 437, 498, 321, 787, 1415, 281, 2995, 51020], "temperature": 0.0, "avg_logprob": -0.08052657854439009, "compression_ratio": 1.6623931623931625, "no_speech_prob": 0.07583699375391006}, {"id": 161, "seek": 89240, "start": 905.52, "end": 911.84, "text": " digits between let's say one and seven. So to do that, we can use a character set. And we can just", "tokens": [51020, 27011, 1296, 718, 311, 584, 472, 293, 3407, 13, 407, 281, 360, 300, 11, 321, 393, 764, 257, 2517, 992, 13, 400, 321, 393, 445, 51336], "temperature": 0.0, "avg_logprob": -0.08052657854439009, "compression_ratio": 1.6623931623931625, "no_speech_prob": 0.07583699375391006}, {"id": 162, "seek": 89240, "start": 911.84, "end": 919.04, "text": " say instead of typing out 1234567, if we wanted to specify a range of those values, then we can", "tokens": [51336, 584, 2602, 295, 18444, 484, 34466, 8465, 22452, 11, 498, 321, 1415, 281, 16500, 257, 3613, 295, 729, 4190, 11, 550, 321, 393, 51696], "temperature": 0.0, "avg_logprob": -0.08052657854439009, "compression_ratio": 1.6623931623931625, "no_speech_prob": 0.07583699375391006}, {"id": 163, "seek": 91904, "start": 919.12, "end": 924.88, "text": " just say one dash seven. So now we can see that we're matching all of the digits between one and", "tokens": [50368, 445, 584, 472, 8240, 3407, 13, 407, 586, 321, 393, 536, 300, 321, 434, 14324, 439, 295, 264, 27011, 1296, 472, 293, 50656], "temperature": 0.0, "avg_logprob": -0.09090728759765625, "compression_ratio": 1.9959016393442623, "no_speech_prob": 0.0034832896199077368}, {"id": 164, "seek": 91904, "start": 924.88, "end": 930.8, "text": " seven, but the eight, nine and the zero aren't getting matched up here. Now you can do this with", "tokens": [50656, 3407, 11, 457, 264, 3180, 11, 4949, 293, 264, 4018, 3212, 380, 1242, 21447, 493, 510, 13, 823, 291, 393, 360, 341, 365, 50952], "temperature": 0.0, "avg_logprob": -0.09090728759765625, "compression_ratio": 1.9959016393442623, "no_speech_prob": 0.0034832896199077368}, {"id": 165, "seek": 91904, "start": 930.8, "end": 936.88, "text": " letters as well. So if we only wanted to match the lowercase letters a through Z, then we could just", "tokens": [50952, 7825, 382, 731, 13, 407, 498, 321, 787, 1415, 281, 2995, 264, 3126, 9765, 7825, 257, 807, 1176, 11, 550, 321, 727, 445, 51256], "temperature": 0.0, "avg_logprob": -0.09090728759765625, "compression_ratio": 1.9959016393442623, "no_speech_prob": 0.0034832896199077368}, {"id": 166, "seek": 91904, "start": 936.88, "end": 942.56, "text": " do a character set of a through Z. Now you can see all of the capital letters aren't getting matched,", "tokens": [51256, 360, 257, 2517, 992, 295, 257, 807, 1176, 13, 823, 291, 393, 536, 439, 295, 264, 4238, 7825, 3212, 380, 1242, 21447, 11, 51540], "temperature": 0.0, "avg_logprob": -0.09090728759765625, "compression_ratio": 1.9959016393442623, "no_speech_prob": 0.0034832896199077368}, {"id": 167, "seek": 91904, "start": 942.56, "end": 947.92, "text": " but the lowercase ones are. Now if we wanted to match the uppercase and lowercase numbers,", "tokens": [51540, 457, 264, 3126, 9765, 2306, 366, 13, 823, 498, 321, 1415, 281, 2995, 264, 11775, 2869, 651, 293, 3126, 9765, 3547, 11, 51808], "temperature": 0.0, "avg_logprob": -0.09090728759765625, "compression_ratio": 1.9959016393442623, "no_speech_prob": 0.0034832896199077368}, {"id": 168, "seek": 94792, "start": 947.92, "end": 954.4, "text": " then we could just put our ranges back to back. So I could say a through Z and then just add on", "tokens": [50364, 550, 321, 727, 445, 829, 527, 22526, 646, 281, 646, 13, 407, 286, 727, 584, 257, 807, 1176, 293, 550, 445, 909, 322, 50688], "temperature": 0.0, "avg_logprob": -0.0702797033018985, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.0005883827107027173}, {"id": 169, "seek": 94792, "start": 954.4, "end": 960.9599999999999, "text": " to this character set and say capital A through capital Z. And now we're matching all letters,", "tokens": [50688, 281, 341, 2517, 992, 293, 584, 4238, 316, 807, 4238, 1176, 13, 400, 586, 321, 434, 14324, 439, 7825, 11, 51016], "temperature": 0.0, "avg_logprob": -0.0702797033018985, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.0005883827107027173}, {"id": 170, "seek": 94792, "start": 960.9599999999999, "end": 965.8399999999999, "text": " regardless of whether they are uppercase or lowercase. And you could keep adding to those ranges.", "tokens": [51016, 10060, 295, 1968, 436, 366, 11775, 2869, 651, 420, 3126, 9765, 13, 400, 291, 727, 1066, 5127, 281, 729, 22526, 13, 51260], "temperature": 0.0, "avg_logprob": -0.0702797033018985, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.0005883827107027173}, {"id": 171, "seek": 94792, "start": 965.8399999999999, "end": 970.9599999999999, "text": " If you wanted to, you could do a zero through nine there as well, to add in all digits. Now", "tokens": [51260, 759, 291, 1415, 281, 11, 291, 727, 360, 257, 4018, 807, 4949, 456, 382, 731, 11, 281, 909, 294, 439, 27011, 13, 823, 51516], "temperature": 0.0, "avg_logprob": -0.0702797033018985, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.0005883827107027173}, {"id": 172, "seek": 94792, "start": 970.9599999999999, "end": 977.4399999999999, "text": " another special character in our character set is the carrot. Now we saw before that outside of the", "tokens": [51516, 1071, 2121, 2517, 294, 527, 2517, 992, 307, 264, 22767, 13, 823, 321, 1866, 949, 300, 2380, 295, 264, 51840], "temperature": 0.0, "avg_logprob": -0.0702797033018985, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.0005883827107027173}, {"id": 173, "seek": 97744, "start": 977.44, "end": 982.8800000000001, "text": " character set, it matches the beginning of a string, but within the character set, it negates", "tokens": [50364, 2517, 992, 11, 309, 10676, 264, 2863, 295, 257, 6798, 11, 457, 1951, 264, 2517, 992, 11, 309, 2485, 1024, 50636], "temperature": 0.0, "avg_logprob": -0.060429778592339875, "compression_ratio": 2.0384615384615383, "no_speech_prob": 0.000732148764654994}, {"id": 174, "seek": 97744, "start": 982.8800000000001, "end": 988.72, "text": " the set and matches everything that is not in the set. So for example, if we wanted to match every", "tokens": [50636, 264, 992, 293, 10676, 1203, 300, 307, 406, 294, 264, 992, 13, 407, 337, 1365, 11, 498, 321, 1415, 281, 2995, 633, 50928], "temperature": 0.0, "avg_logprob": -0.060429778592339875, "compression_ratio": 2.0384615384615383, "no_speech_prob": 0.000732148764654994}, {"id": 175, "seek": 97744, "start": 989.5200000000001, "end": 996.72, "text": " character that is not a lowercase letter, then we could say this carrot and then A through Z.", "tokens": [50968, 2517, 300, 307, 406, 257, 3126, 9765, 5063, 11, 550, 321, 727, 584, 341, 22767, 293, 550, 316, 807, 1176, 13, 51328], "temperature": 0.0, "avg_logprob": -0.060429778592339875, "compression_ratio": 2.0384615384615383, "no_speech_prob": 0.000732148764654994}, {"id": 176, "seek": 97744, "start": 996.72, "end": 1001.36, "text": " So we can see that it matches everything on our screen that isn't a lowercase letter. It's not", "tokens": [51328, 407, 321, 393, 536, 300, 309, 10676, 1203, 322, 527, 2568, 300, 1943, 380, 257, 3126, 9765, 5063, 13, 467, 311, 406, 51560], "temperature": 0.0, "avg_logprob": -0.060429778592339875, "compression_ratio": 2.0384615384615383, "no_speech_prob": 0.000732148764654994}, {"id": 177, "seek": 97744, "start": 1001.36, "end": 1006.72, "text": " matching these lowercase letters here. So it's even matching these new lines and the spaces and", "tokens": [51560, 14324, 613, 3126, 9765, 7825, 510, 13, 407, 309, 311, 754, 14324, 613, 777, 3876, 293, 264, 7673, 293, 51828], "temperature": 0.0, "avg_logprob": -0.060429778592339875, "compression_ratio": 2.0384615384615383, "no_speech_prob": 0.000732148764654994}, {"id": 178, "seek": 100672, "start": 1006.8000000000001, "end": 1013.52, "text": " everything. So just to show another example of this, let's say that we had some words here,", "tokens": [50368, 1203, 13, 407, 445, 281, 855, 1071, 1365, 295, 341, 11, 718, 311, 584, 300, 321, 632, 512, 2283, 510, 11, 50704], "temperature": 0.0, "avg_logprob": -0.08827595357541684, "compression_ratio": 1.7809523809523808, "no_speech_prob": 0.001098688691854477}, {"id": 179, "seek": 100672, "start": 1013.52, "end": 1021.28, "text": " cat, mat, pat, and bat. So let's say that we wanted to match every word that ends in A-T,", "tokens": [50704, 3857, 11, 3803, 11, 1947, 11, 293, 7362, 13, 407, 718, 311, 584, 300, 321, 1415, 281, 2995, 633, 1349, 300, 5314, 294, 316, 12, 51, 11, 51092], "temperature": 0.0, "avg_logprob": -0.08827595357541684, "compression_ratio": 1.7809523809523808, "no_speech_prob": 0.001098688691854477}, {"id": 180, "seek": 100672, "start": 1021.28, "end": 1028.4, "text": " except bat. We don't want to match bat. So to do this, we can just say that we want a character", "tokens": [51092, 3993, 7362, 13, 492, 500, 380, 528, 281, 2995, 7362, 13, 407, 281, 360, 341, 11, 321, 393, 445, 584, 300, 321, 528, 257, 2517, 51448], "temperature": 0.0, "avg_logprob": -0.08827595357541684, "compression_ratio": 1.7809523809523808, "no_speech_prob": 0.001098688691854477}, {"id": 181, "seek": 100672, "start": 1028.4, "end": 1035.68, "text": " set of everything that is not B, followed by A-T. So now we can see that it matches all of these", "tokens": [51448, 992, 295, 1203, 300, 307, 406, 363, 11, 6263, 538, 316, 12, 51, 13, 407, 586, 321, 393, 536, 300, 309, 10676, 439, 295, 613, 51812], "temperature": 0.0, "avg_logprob": -0.08827595357541684, "compression_ratio": 1.7809523809523808, "no_speech_prob": 0.001098688691854477}, {"id": 182, "seek": 103568, "start": 1035.68, "end": 1042.48, "text": " three letter words that end in A-T, except for bat, because our character set here negated that B.", "tokens": [50364, 1045, 5063, 2283, 300, 917, 294, 316, 12, 51, 11, 3993, 337, 7362, 11, 570, 527, 2517, 992, 510, 2485, 770, 300, 363, 13, 50704], "temperature": 0.0, "avg_logprob": -0.06230498364097194, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.0014102886198088527}, {"id": 183, "seek": 103568, "start": 1042.48, "end": 1048.16, "text": " So everything that we've looked at so far has involved single characters. So in this example", "tokens": [50704, 407, 1203, 300, 321, 600, 2956, 412, 370, 1400, 575, 3288, 2167, 4342, 13, 407, 294, 341, 1365, 50988], "temperature": 0.0, "avg_logprob": -0.06230498364097194, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.0014102886198088527}, {"id": 184, "seek": 103568, "start": 1048.16, "end": 1055.2, "text": " right here, we're matching any single character that is not a B, then followed by an A, and then", "tokens": [50988, 558, 510, 11, 321, 434, 14324, 604, 2167, 2517, 300, 307, 406, 257, 363, 11, 550, 6263, 538, 364, 316, 11, 293, 550, 51340], "temperature": 0.0, "avg_logprob": -0.06230498364097194, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.0014102886198088527}, {"id": 185, "seek": 103568, "start": 1055.2, "end": 1060.64, "text": " followed by a T. But we can actually use these things called quantifiers to match more than one", "tokens": [51340, 6263, 538, 257, 314, 13, 583, 321, 393, 767, 764, 613, 721, 1219, 4426, 23463, 281, 2995, 544, 813, 472, 51612], "temperature": 0.0, "avg_logprob": -0.06230498364097194, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.0014102886198088527}, {"id": 186, "seek": 106064, "start": 1060.64, "end": 1066.72, "text": " character at a time. So let's go back to our original phone number example from earlier,", "tokens": [50364, 2517, 412, 257, 565, 13, 407, 718, 311, 352, 646, 281, 527, 3380, 2593, 1230, 1365, 490, 3071, 11, 50668], "temperature": 0.0, "avg_logprob": -0.0586997311690758, "compression_ratio": 1.886178861788618, "no_speech_prob": 0.04741932079195976}, {"id": 187, "seek": 106064, "start": 1066.72, "end": 1073.0400000000002, "text": " and we'll just match any character like we did before. So I will do three digits and then a", "tokens": [50668, 293, 321, 603, 445, 2995, 604, 2517, 411, 321, 630, 949, 13, 407, 286, 486, 360, 1045, 27011, 293, 550, 257, 50984], "temperature": 0.0, "avg_logprob": -0.0586997311690758, "compression_ratio": 1.886178861788618, "no_speech_prob": 0.04741932079195976}, {"id": 188, "seek": 106064, "start": 1073.0400000000002, "end": 1079.1200000000001, "text": " period for any character, and then three digits again, and a period for any character, and then", "tokens": [50984, 2896, 337, 604, 2517, 11, 293, 550, 1045, 27011, 797, 11, 293, 257, 2896, 337, 604, 2517, 11, 293, 550, 51288], "temperature": 0.0, "avg_logprob": -0.0586997311690758, "compression_ratio": 1.886178861788618, "no_speech_prob": 0.04741932079195976}, {"id": 189, "seek": 106064, "start": 1079.1200000000001, "end": 1084.16, "text": " four digits at the end. And I'm just going to remove what we had there for an example", "tokens": [51288, 1451, 27011, 412, 264, 917, 13, 400, 286, 478, 445, 516, 281, 4159, 437, 321, 632, 456, 337, 364, 1365, 51540], "temperature": 0.0, "avg_logprob": -0.0586997311690758, "compression_ratio": 1.886178861788618, "no_speech_prob": 0.04741932079195976}, {"id": 190, "seek": 106064, "start": 1084.16, "end": 1090.3200000000002, "text": " and scroll those back up. So to see what quantifiers we have available, I'm going to make my snippets", "tokens": [51540, 293, 11369, 729, 646, 493, 13, 407, 281, 536, 437, 4426, 23463, 321, 362, 2435, 11, 286, 478, 516, 281, 652, 452, 35623, 1385, 51848], "temperature": 0.0, "avg_logprob": -0.0586997311690758, "compression_ratio": 1.886178861788618, "no_speech_prob": 0.04741932079195976}, {"id": 191, "seek": 109032, "start": 1090.3999999999999, "end": 1096.3999999999999, "text": " half of my screen here again, and then scroll down to my quantifiers section. So the asterisk will", "tokens": [50368, 1922, 295, 452, 2568, 510, 797, 11, 293, 550, 11369, 760, 281, 452, 4426, 23463, 3541, 13, 407, 264, 257, 3120, 7797, 486, 50668], "temperature": 0.0, "avg_logprob": -0.04966291938860392, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.0003920313611160964}, {"id": 192, "seek": 109032, "start": 1096.3999999999999, "end": 1103.4399999999998, "text": " match zero or more of what we're searching for. The plus sign will match one or more. The question", "tokens": [50668, 2995, 4018, 420, 544, 295, 437, 321, 434, 10808, 337, 13, 440, 1804, 1465, 486, 2995, 472, 420, 544, 13, 440, 1168, 51020], "temperature": 0.0, "avg_logprob": -0.04966291938860392, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.0003920313611160964}, {"id": 193, "seek": 109032, "start": 1103.4399999999998, "end": 1109.6, "text": " mark will match zero or one. And to match exact numbers, we can use these curly braces with a", "tokens": [51020, 1491, 486, 2995, 4018, 420, 472, 13, 400, 281, 2995, 1900, 3547, 11, 321, 393, 764, 613, 32066, 41537, 365, 257, 51328], "temperature": 0.0, "avg_logprob": -0.04966291938860392, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.0003920313611160964}, {"id": 194, "seek": 109032, "start": 1109.6, "end": 1114.56, "text": " number on the inside. So in this example, this would match exactly three of what it is we're", "tokens": [51328, 1230, 322, 264, 1854, 13, 407, 294, 341, 1365, 11, 341, 576, 2995, 2293, 1045, 295, 437, 309, 307, 321, 434, 51576], "temperature": 0.0, "avg_logprob": -0.04966291938860392, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.0003920313611160964}, {"id": 195, "seek": 111456, "start": 1114.56, "end": 1120.56, "text": " looking for. And we can also specify a range of numbers as well, with the first number being the", "tokens": [50364, 1237, 337, 13, 400, 321, 393, 611, 16500, 257, 3613, 295, 3547, 382, 731, 11, 365, 264, 700, 1230, 885, 264, 50664], "temperature": 0.0, "avg_logprob": -0.04972587585449219, "compression_ratio": 1.703056768558952, "no_speech_prob": 0.017441188916563988}, {"id": 196, "seek": 111456, "start": 1120.56, "end": 1126.72, "text": " minimum, and the last number being the max. So this would search for whatever our pattern is. It", "tokens": [50664, 7285, 11, 293, 264, 1036, 1230, 885, 264, 11469, 13, 407, 341, 576, 3164, 337, 2035, 527, 5102, 307, 13, 467, 50972], "temperature": 0.0, "avg_logprob": -0.04972587585449219, "compression_ratio": 1.703056768558952, "no_speech_prob": 0.017441188916563988}, {"id": 197, "seek": 111456, "start": 1126.72, "end": 1131.9199999999998, "text": " would look for three or four of those. So let's take a look at an example of this to see how this", "tokens": [50972, 576, 574, 337, 1045, 420, 1451, 295, 729, 13, 407, 718, 311, 747, 257, 574, 412, 364, 1365, 295, 341, 281, 536, 577, 341, 51232], "temperature": 0.0, "avg_logprob": -0.04972587585449219, "compression_ratio": 1.703056768558952, "no_speech_prob": 0.017441188916563988}, {"id": 198, "seek": 111456, "start": 1131.9199999999998, "end": 1137.9199999999998, "text": " works. So you can see that with our phone number, we are searching for one digit at a time. But we", "tokens": [51232, 1985, 13, 407, 291, 393, 536, 300, 365, 527, 2593, 1230, 11, 321, 366, 10808, 337, 472, 14293, 412, 257, 565, 13, 583, 321, 51532], "temperature": 0.0, "avg_logprob": -0.04972587585449219, "compression_ratio": 1.703056768558952, "no_speech_prob": 0.017441188916563988}, {"id": 199, "seek": 113792, "start": 1137.92, "end": 1145.1200000000001, "text": " could change this. If I erase my digits here, then we could say that I'm searching for a digit.", "tokens": [50364, 727, 1319, 341, 13, 759, 286, 23525, 452, 27011, 510, 11, 550, 321, 727, 584, 300, 286, 478, 10808, 337, 257, 14293, 13, 50724], "temperature": 0.0, "avg_logprob": -0.0733987055326763, "compression_ratio": 1.7962085308056872, "no_speech_prob": 0.010986162349581718}, {"id": 200, "seek": 113792, "start": 1145.1200000000001, "end": 1152.0800000000002, "text": " And then we could put in our quantifier for exactly three digits. And we could do this", "tokens": [50724, 400, 550, 321, 727, 829, 294, 527, 4426, 9902, 337, 2293, 1045, 27011, 13, 400, 321, 727, 360, 341, 51072], "temperature": 0.0, "avg_logprob": -0.0733987055326763, "compression_ratio": 1.7962085308056872, "no_speech_prob": 0.010986162349581718}, {"id": 201, "seek": 113792, "start": 1152.0800000000002, "end": 1158.72, "text": " after our separator as well. So we're searching for three digits, and then any character. And then", "tokens": [51072, 934, 527, 3128, 1639, 382, 731, 13, 407, 321, 434, 10808, 337, 1045, 27011, 11, 293, 550, 604, 2517, 13, 400, 550, 51404], "temperature": 0.0, "avg_logprob": -0.0733987055326763, "compression_ratio": 1.7962085308056872, "no_speech_prob": 0.010986162349581718}, {"id": 202, "seek": 113792, "start": 1158.72, "end": 1164.8000000000002, "text": " here at the end, we want to match four digits. So instead of writing out the same characters over", "tokens": [51404, 510, 412, 264, 917, 11, 321, 528, 281, 2995, 1451, 27011, 13, 407, 2602, 295, 3579, 484, 264, 912, 4342, 670, 51708], "temperature": 0.0, "avg_logprob": -0.0733987055326763, "compression_ratio": 1.7962085308056872, "no_speech_prob": 0.010986162349581718}, {"id": 203, "seek": 116480, "start": 1164.8, "end": 1171.04, "text": " and over, we can see how these quantifiers allow us to specify exactly how much we want. Now here", "tokens": [50364, 293, 670, 11, 321, 393, 536, 577, 613, 4426, 23463, 2089, 505, 281, 16500, 2293, 577, 709, 321, 528, 13, 823, 510, 50676], "temperature": 0.0, "avg_logprob": -0.06423026440190334, "compression_ratio": 1.6835443037974684, "no_speech_prob": 0.02228303626179695}, {"id": 204, "seek": 116480, "start": 1171.04, "end": 1176.48, "text": " we're matching exact numbers. But sometimes we don't know the exact number. And we'll need to use one", "tokens": [50676, 321, 434, 14324, 1900, 3547, 13, 583, 2171, 321, 500, 380, 458, 264, 1900, 1230, 13, 400, 321, 603, 643, 281, 764, 472, 50948], "temperature": 0.0, "avg_logprob": -0.06423026440190334, "compression_ratio": 1.6835443037974684, "no_speech_prob": 0.02228303626179695}, {"id": 205, "seek": 116480, "start": 1176.48, "end": 1182.56, "text": " of these other quantifiers. So for example, here at the bottom of this test file here, we have some", "tokens": [50948, 295, 613, 661, 4426, 23463, 13, 407, 337, 1365, 11, 510, 412, 264, 2767, 295, 341, 1500, 3991, 510, 11, 321, 362, 512, 51252], "temperature": 0.0, "avg_logprob": -0.06423026440190334, "compression_ratio": 1.6835443037974684, "no_speech_prob": 0.02228303626179695}, {"id": 206, "seek": 116480, "start": 1182.56, "end": 1189.68, "text": " lines where each starts with a prefix of mister, or miss, or misses. So let's say that we wanted to", "tokens": [51252, 3876, 689, 1184, 3719, 365, 257, 46969, 295, 26562, 11, 420, 1713, 11, 420, 29394, 13, 407, 718, 311, 584, 300, 321, 1415, 281, 51608], "temperature": 0.0, "avg_logprob": -0.06423026440190334, "compression_ratio": 1.6835443037974684, "no_speech_prob": 0.02228303626179695}, {"id": 207, "seek": 118968, "start": 1189.76, "end": 1197.28, "text": " match these prefixes, as well as the names after. So just to start, let's start by matching the names", "tokens": [50368, 2995, 613, 18417, 36005, 11, 382, 731, 382, 264, 5288, 934, 13, 407, 445, 281, 722, 11, 718, 311, 722, 538, 14324, 264, 5288, 50744], "temperature": 0.0, "avg_logprob": -0.06314062831377742, "compression_ratio": 1.835680751173709, "no_speech_prob": 0.07584241777658463}, {"id": 208, "seek": 118968, "start": 1197.28, "end": 1204.0, "text": " that start with mister. Now we can see that some of these have a period after the prefix, and some", "tokens": [50744, 300, 722, 365, 26562, 13, 823, 321, 393, 536, 300, 512, 295, 613, 362, 257, 2896, 934, 264, 46969, 11, 293, 512, 51080], "temperature": 0.0, "avg_logprob": -0.06314062831377742, "compression_ratio": 1.835680751173709, "no_speech_prob": 0.07584241777658463}, {"id": 209, "seek": 118968, "start": 1204.0, "end": 1211.44, "text": " do not. Some of them just have a space. So let's start our regular expression by searching for", "tokens": [51080, 360, 406, 13, 2188, 295, 552, 445, 362, 257, 1901, 13, 407, 718, 311, 722, 527, 3890, 6114, 538, 10808, 337, 51452], "temperature": 0.0, "avg_logprob": -0.06314062831377742, "compression_ratio": 1.835680751173709, "no_speech_prob": 0.07584241777658463}, {"id": 210, "seek": 118968, "start": 1211.44, "end": 1216.5600000000002, "text": " lines that start with mister. And then we're going to put a backslash period to search for that", "tokens": [51452, 3876, 300, 722, 365, 26562, 13, 400, 550, 321, 434, 516, 281, 829, 257, 646, 10418, 1299, 2896, 281, 3164, 337, 300, 51708], "temperature": 0.0, "avg_logprob": -0.06314062831377742, "compression_ratio": 1.835680751173709, "no_speech_prob": 0.07584241777658463}, {"id": 211, "seek": 121656, "start": 1217.44, "end": 1223.84, "text": " literal period. And right now it isn't matching this mister Smith, which doesn't have a period", "tokens": [50408, 20411, 2896, 13, 400, 558, 586, 309, 1943, 380, 14324, 341, 26562, 8538, 11, 597, 1177, 380, 362, 257, 2896, 50728], "temperature": 0.0, "avg_logprob": -0.06999357951056097, "compression_ratio": 1.7657657657657657, "no_speech_prob": 0.004754764959216118}, {"id": 212, "seek": 121656, "start": 1223.84, "end": 1231.28, "text": " after the prefix. Now to match that also, we can use this question mark quantifier, which tells our", "tokens": [50728, 934, 264, 46969, 13, 823, 281, 2995, 300, 611, 11, 321, 393, 764, 341, 1168, 1491, 4426, 9902, 11, 597, 5112, 527, 51100], "temperature": 0.0, "avg_logprob": -0.06999357951056097, "compression_ratio": 1.7657657657657657, "no_speech_prob": 0.004754764959216118}, {"id": 213, "seek": 121656, "start": 1231.28, "end": 1238.0, "text": " pattern that we want to match zero or one of that character. So if I put a question mark after that", "tokens": [51100, 5102, 300, 321, 528, 281, 2995, 4018, 420, 472, 295, 300, 2517, 13, 407, 498, 286, 829, 257, 1168, 1491, 934, 300, 51436], "temperature": 0.0, "avg_logprob": -0.06999357951056097, "compression_ratio": 1.7657657657657657, "no_speech_prob": 0.004754764959216118}, {"id": 214, "seek": 121656, "start": 1238.0, "end": 1244.48, "text": " literal period, then it's saying that there can be zero periods there, or there can be one. So we", "tokens": [51436, 20411, 2896, 11, 550, 309, 311, 1566, 300, 456, 393, 312, 4018, 13804, 456, 11, 420, 456, 393, 312, 472, 13, 407, 321, 51760], "temperature": 0.0, "avg_logprob": -0.06999357951056097, "compression_ratio": 1.7657657657657657, "no_speech_prob": 0.004754764959216118}, {"id": 215, "seek": 124448, "start": 1244.48, "end": 1249.68, "text": " can see that now it's matching the ones with one period there, and it's also matching the one with", "tokens": [50364, 393, 536, 300, 586, 309, 311, 14324, 264, 2306, 365, 472, 2896, 456, 11, 293, 309, 311, 611, 14324, 264, 472, 365, 50624], "temperature": 0.0, "avg_logprob": -0.05596704006195068, "compression_ratio": 1.9895287958115184, "no_speech_prob": 0.0015487242490053177}, {"id": 216, "seek": 124448, "start": 1249.68, "end": 1258.16, "text": " no period. So now to continue and match the entire line. Now we want to match a space after that.", "tokens": [50624, 572, 2896, 13, 407, 586, 281, 2354, 293, 2995, 264, 2302, 1622, 13, 823, 321, 528, 281, 2995, 257, 1901, 934, 300, 13, 51048], "temperature": 0.0, "avg_logprob": -0.05596704006195068, "compression_ratio": 1.9895287958115184, "no_speech_prob": 0.0015487242490053177}, {"id": 217, "seek": 124448, "start": 1258.16, "end": 1264.96, "text": " And after the space, we want to match any uppercase letter. And to do that, we can use", "tokens": [51048, 400, 934, 264, 1901, 11, 321, 528, 281, 2995, 604, 11775, 2869, 651, 5063, 13, 400, 281, 360, 300, 11, 321, 393, 764, 51388], "temperature": 0.0, "avg_logprob": -0.05596704006195068, "compression_ratio": 1.9895287958115184, "no_speech_prob": 0.0015487242490053177}, {"id": 218, "seek": 124448, "start": 1264.96, "end": 1270.88, "text": " our character class, and we can match any uppercase letter by doing a range of uppercase letters", "tokens": [51388, 527, 2517, 1508, 11, 293, 321, 393, 2995, 604, 11775, 2869, 651, 5063, 538, 884, 257, 3613, 295, 11775, 2869, 651, 7825, 51684], "temperature": 0.0, "avg_logprob": -0.05596704006195068, "compression_ratio": 1.9895287958115184, "no_speech_prob": 0.0015487242490053177}, {"id": 219, "seek": 127088, "start": 1270.88, "end": 1276.4, "text": " there. So at this point, after that first uppercase letter that we match, we've completely matched the", "tokens": [50364, 456, 13, 407, 412, 341, 935, 11, 934, 300, 700, 11775, 2869, 651, 5063, 300, 321, 2995, 11, 321, 600, 2584, 21447, 264, 50640], "temperature": 0.0, "avg_logprob": -0.05111798644065857, "compression_ratio": 1.7790262172284643, "no_speech_prob": 0.010986181907355785}, {"id": 220, "seek": 127088, "start": 1276.4, "end": 1282.16, "text": " name for Mr. T down here at the bottom. But we still need to match the rest of our other names.", "tokens": [50640, 1315, 337, 2221, 13, 314, 760, 510, 412, 264, 2767, 13, 583, 321, 920, 643, 281, 2995, 264, 1472, 295, 527, 661, 5288, 13, 50928], "temperature": 0.0, "avg_logprob": -0.05111798644065857, "compression_ratio": 1.7790262172284643, "no_speech_prob": 0.010986181907355785}, {"id": 221, "seek": 127088, "start": 1282.16, "end": 1289.6000000000001, "text": " So we could say that we will match any word character after that uppercase. So let's put in", "tokens": [50928, 407, 321, 727, 584, 300, 321, 486, 2995, 604, 1349, 2517, 934, 300, 11775, 2869, 651, 13, 407, 718, 311, 829, 294, 51300], "temperature": 0.0, "avg_logprob": -0.05111798644065857, "compression_ratio": 1.7790262172284643, "no_speech_prob": 0.010986181907355785}, {"id": 222, "seek": 127088, "start": 1289.6000000000001, "end": 1294.48, "text": " a backslash w to match any word character. And now we don't know how many more characters are", "tokens": [51300, 257, 646, 10418, 1299, 261, 281, 2995, 604, 1349, 2517, 13, 400, 586, 321, 500, 380, 458, 577, 867, 544, 4342, 366, 51544], "temperature": 0.0, "avg_logprob": -0.05111798644065857, "compression_ratio": 1.7790262172284643, "no_speech_prob": 0.010986181907355785}, {"id": 223, "seek": 127088, "start": 1294.48, "end": 1300.24, "text": " going to be in our name. So we'll have to use a quantifier here. Now if we look over here,", "tokens": [51544, 516, 281, 312, 294, 527, 1315, 13, 407, 321, 603, 362, 281, 764, 257, 4426, 9902, 510, 13, 823, 498, 321, 574, 670, 510, 11, 51832], "temperature": 0.0, "avg_logprob": -0.05111798644065857, "compression_ratio": 1.7790262172284643, "no_speech_prob": 0.010986181907355785}, {"id": 224, "seek": 130024, "start": 1300.24, "end": 1305.76, "text": " we could use the asterisk or the plus sign. And the plus sign will match one or more of", "tokens": [50364, 321, 727, 764, 264, 257, 3120, 7797, 420, 264, 1804, 1465, 13, 400, 264, 1804, 1465, 486, 2995, 472, 420, 544, 295, 50640], "temperature": 0.0, "avg_logprob": -0.05380384776057029, "compression_ratio": 1.893939393939394, "no_speech_prob": 0.0024724379181861877}, {"id": 225, "seek": 130024, "start": 1305.76, "end": 1312.4, "text": " these word characters. And the asterisk will match zero or more. So if we used the plus sign,", "tokens": [50640, 613, 1349, 4342, 13, 400, 264, 257, 3120, 7797, 486, 2995, 4018, 420, 544, 13, 407, 498, 321, 1143, 264, 1804, 1465, 11, 50972], "temperature": 0.0, "avg_logprob": -0.05380384776057029, "compression_ratio": 1.893939393939394, "no_speech_prob": 0.0024724379181861877}, {"id": 226, "seek": 130024, "start": 1312.4, "end": 1319.04, "text": " then we can see that it matches our two top names here. But now it's not matching this Mr. T because", "tokens": [50972, 550, 321, 393, 536, 300, 309, 10676, 527, 732, 1192, 5288, 510, 13, 583, 586, 309, 311, 406, 14324, 341, 2221, 13, 314, 570, 51304], "temperature": 0.0, "avg_logprob": -0.05380384776057029, "compression_ratio": 1.893939393939394, "no_speech_prob": 0.0024724379181861877}, {"id": 227, "seek": 130024, "start": 1319.04, "end": 1324.88, "text": " after our word character, it's searching for one or more word characters after our uppercase", "tokens": [51304, 934, 527, 1349, 2517, 11, 309, 311, 10808, 337, 472, 420, 544, 1349, 4342, 934, 527, 11775, 2869, 651, 51596], "temperature": 0.0, "avg_logprob": -0.05380384776057029, "compression_ratio": 1.893939393939394, "no_speech_prob": 0.0024724379181861877}, {"id": 228, "seek": 132488, "start": 1324.88, "end": 1330.8000000000002, "text": " character. So a better solution in this case, maybe to use the asterisk, which matches zero or", "tokens": [50364, 2517, 13, 407, 257, 1101, 3827, 294, 341, 1389, 11, 1310, 281, 764, 264, 257, 3120, 7797, 11, 597, 10676, 4018, 420, 50660], "temperature": 0.0, "avg_logprob": -0.058687667692861246, "compression_ratio": 1.7060931899641576, "no_speech_prob": 0.021613260731101036}, {"id": 229, "seek": 132488, "start": 1330.8000000000002, "end": 1337.1200000000001, "text": " more word characters. And if we use that asterisk, then we can see that it matches all three of our", "tokens": [50660, 544, 1349, 4342, 13, 400, 498, 321, 764, 300, 257, 3120, 7797, 11, 550, 321, 393, 536, 300, 309, 10676, 439, 1045, 295, 527, 50976], "temperature": 0.0, "avg_logprob": -0.058687667692861246, "compression_ratio": 1.7060931899641576, "no_speech_prob": 0.021613260731101036}, {"id": 230, "seek": 132488, "start": 1337.1200000000001, "end": 1342.3200000000002, "text": " names that begin with Mr. Now I know that we've covered a lot so far, but we've got a couple", "tokens": [50976, 5288, 300, 1841, 365, 2221, 13, 823, 286, 458, 300, 321, 600, 5343, 257, 688, 370, 1400, 11, 457, 321, 600, 658, 257, 1916, 51236], "temperature": 0.0, "avg_logprob": -0.058687667692861246, "compression_ratio": 1.7060931899641576, "no_speech_prob": 0.021613260731101036}, {"id": 231, "seek": 132488, "start": 1342.3200000000002, "end": 1347.2, "text": " of more concepts to go. And then we'll look at some examples that wrap everything together.", "tokens": [51236, 295, 544, 10392, 281, 352, 13, 400, 550, 321, 603, 574, 412, 512, 5110, 300, 7019, 1203, 1214, 13, 51480], "temperature": 0.0, "avg_logprob": -0.058687667692861246, "compression_ratio": 1.7060931899641576, "no_speech_prob": 0.021613260731101036}, {"id": 232, "seek": 132488, "start": 1347.2, "end": 1354.16, "text": " So we still haven't matched our miss or misses names here. So how would we do that? So you might", "tokens": [51480, 407, 321, 920, 2378, 380, 21447, 527, 1713, 420, 29394, 5288, 510, 13, 407, 577, 576, 321, 360, 300, 30, 407, 291, 1062, 51828], "temperature": 0.0, "avg_logprob": -0.058687667692861246, "compression_ratio": 1.7060931899641576, "no_speech_prob": 0.021613260731101036}, {"id": 233, "seek": 135416, "start": 1354.16, "end": 1361.28, "text": " think that we could use a character set that matches either an r or an s. And there are maybe", "tokens": [50364, 519, 300, 321, 727, 764, 257, 2517, 992, 300, 10676, 2139, 364, 367, 420, 364, 262, 13, 400, 456, 366, 1310, 50720], "temperature": 0.0, "avg_logprob": -0.0658035419955112, "compression_ratio": 1.7612612612612613, "no_speech_prob": 0.006902878172695637}, {"id": 234, "seek": 135416, "start": 1361.28, "end": 1366.4, "text": " some ways that we could get that to work. But it probably would be a bit ugly, since we'd have to", "tokens": [50720, 512, 2098, 300, 321, 727, 483, 300, 281, 589, 13, 583, 309, 1391, 576, 312, 257, 857, 12246, 11, 1670, 321, 1116, 362, 281, 50976], "temperature": 0.0, "avg_logprob": -0.0658035419955112, "compression_ratio": 1.7612612612612613, "no_speech_prob": 0.006902878172695637}, {"id": 235, "seek": 135416, "start": 1366.4, "end": 1373.3600000000001, "text": " match either an r or an s as the second character and then the optional s after that. So that could", "tokens": [50976, 2995, 2139, 364, 367, 420, 364, 262, 382, 264, 1150, 2517, 293, 550, 264, 17312, 262, 934, 300, 13, 407, 300, 727, 51324], "temperature": 0.0, "avg_logprob": -0.0658035419955112, "compression_ratio": 1.7612612612612613, "no_speech_prob": 0.006902878172695637}, {"id": 236, "seek": 135416, "start": 1373.3600000000001, "end": 1378.16, "text": " get kind of ugly. But I think a better solution here would be to use a group. Now we haven't looked", "tokens": [51324, 483, 733, 295, 12246, 13, 583, 286, 519, 257, 1101, 3827, 510, 576, 312, 281, 764, 257, 1594, 13, 823, 321, 2378, 380, 2956, 51564], "temperature": 0.0, "avg_logprob": -0.0658035419955112, "compression_ratio": 1.7612612612612613, "no_speech_prob": 0.006902878172695637}, {"id": 237, "seek": 137816, "start": 1378.24, "end": 1384.48, "text": " at groups yet. But groups allow us to match several different patterns. And to create a group, we use", "tokens": [50368, 412, 3935, 1939, 13, 583, 3935, 2089, 505, 281, 2995, 2940, 819, 8294, 13, 400, 281, 1884, 257, 1594, 11, 321, 764, 50680], "temperature": 0.0, "avg_logprob": -0.07737558446031936, "compression_ratio": 1.7625570776255708, "no_speech_prob": 0.1258922517299652}, {"id": 238, "seek": 137816, "start": 1384.48, "end": 1391.8400000000001, "text": " parentheses. So after the m here, instead of just searching for Mr, I'm going to create a group", "tokens": [50680, 34153, 13, 407, 934, 264, 275, 510, 11, 2602, 295, 445, 10808, 337, 2221, 11, 286, 478, 516, 281, 1884, 257, 1594, 51048], "temperature": 0.0, "avg_logprob": -0.07737558446031936, "compression_ratio": 1.7625570776255708, "no_speech_prob": 0.1258922517299652}, {"id": 239, "seek": 137816, "start": 1391.8400000000001, "end": 1398.5600000000002, "text": " with open and closed parentheses here. And now within our group, we can specify different", "tokens": [51048, 365, 1269, 293, 5395, 34153, 510, 13, 400, 586, 1951, 527, 1594, 11, 321, 393, 16500, 819, 51384], "temperature": 0.0, "avg_logprob": -0.07737558446031936, "compression_ratio": 1.7625570776255708, "no_speech_prob": 0.1258922517299652}, {"id": 240, "seek": 137816, "start": 1398.5600000000002, "end": 1404.96, "text": " matches. So I can say that we want to match either an r and then or and we use this character here", "tokens": [51384, 10676, 13, 407, 286, 393, 584, 300, 321, 528, 281, 2995, 2139, 364, 367, 293, 550, 420, 293, 321, 764, 341, 2517, 510, 51704], "temperature": 0.0, "avg_logprob": -0.07737558446031936, "compression_ratio": 1.7625570776255708, "no_speech_prob": 0.1258922517299652}, {"id": 241, "seek": 140496, "start": 1404.96, "end": 1411.3600000000001, "text": " to specify an or. And that is just the vertical bar character to specify an or. So we can say that", "tokens": [50364, 281, 16500, 364, 420, 13, 400, 300, 307, 445, 264, 9429, 2159, 2517, 281, 16500, 364, 420, 13, 407, 321, 393, 584, 300, 50684], "temperature": 0.0, "avg_logprob": -0.0609339714050293, "compression_ratio": 2.0104166666666665, "no_speech_prob": 0.007576668635010719}, {"id": 242, "seek": 140496, "start": 1411.3600000000001, "end": 1417.8400000000001, "text": " we want to match an r or an s. And whenever we add that in, we can see that now we're matching the", "tokens": [50684, 321, 528, 281, 2995, 364, 367, 420, 364, 262, 13, 400, 5699, 321, 909, 300, 294, 11, 321, 393, 536, 300, 586, 321, 434, 14324, 264, 51008], "temperature": 0.0, "avg_logprob": -0.0609339714050293, "compression_ratio": 2.0104166666666665, "no_speech_prob": 0.007576668635010719}, {"id": 243, "seek": 140496, "start": 1417.8400000000001, "end": 1424.64, "text": " miss name here. But we're still not matching this misses. So to match the misses, we can put in", "tokens": [51008, 1713, 1315, 510, 13, 583, 321, 434, 920, 406, 14324, 341, 29394, 13, 407, 281, 2995, 264, 29394, 11, 321, 393, 829, 294, 51348], "temperature": 0.0, "avg_logprob": -0.0609339714050293, "compression_ratio": 2.0104166666666665, "no_speech_prob": 0.007576668635010719}, {"id": 244, "seek": 140496, "start": 1424.64, "end": 1430.56, "text": " another or and say that we want to match an RS. Okay, so now we can see that we are matching", "tokens": [51348, 1071, 420, 293, 584, 300, 321, 528, 281, 2995, 364, 25855, 13, 1033, 11, 370, 586, 321, 393, 536, 300, 321, 366, 14324, 51644], "temperature": 0.0, "avg_logprob": -0.0609339714050293, "compression_ratio": 2.0104166666666665, "no_speech_prob": 0.007576668635010719}, {"id": 245, "seek": 143056, "start": 1430.56, "end": 1434.96, "text": " all of our names here. So let's do a quick walkthrough of this one more time to make sure", "tokens": [50364, 439, 295, 527, 5288, 510, 13, 407, 718, 311, 360, 257, 1702, 1792, 11529, 295, 341, 472, 544, 565, 281, 652, 988, 50584], "temperature": 0.0, "avg_logprob": -0.06048268538254958, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.02096252515912056}, {"id": 246, "seek": 143056, "start": 1434.96, "end": 1441.6799999999998, "text": " we know what's going on. So we have a capital M to start. And then that capital M is followed by", "tokens": [50584, 321, 458, 437, 311, 516, 322, 13, 407, 321, 362, 257, 4238, 376, 281, 722, 13, 400, 550, 300, 4238, 376, 307, 6263, 538, 50920], "temperature": 0.0, "avg_logprob": -0.06048268538254958, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.02096252515912056}, {"id": 247, "seek": 143056, "start": 1441.6799999999998, "end": 1451.52, "text": " either an r and s or an RS. And then we are looking for a literal period. And this question mark says", "tokens": [50920, 2139, 364, 367, 293, 262, 420, 364, 25855, 13, 400, 550, 321, 366, 1237, 337, 257, 20411, 2896, 13, 400, 341, 1168, 1491, 1619, 51412], "temperature": 0.0, "avg_logprob": -0.06048268538254958, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.02096252515912056}, {"id": 248, "seek": 143056, "start": 1451.52, "end": 1457.04, "text": " that we can have zero or one of those. So that is optional. So it's matching the ones that do have", "tokens": [51412, 300, 321, 393, 362, 4018, 420, 472, 295, 729, 13, 407, 300, 307, 17312, 13, 407, 309, 311, 14324, 264, 2306, 300, 360, 362, 51688], "temperature": 0.0, "avg_logprob": -0.06048268538254958, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.02096252515912056}, {"id": 249, "seek": 145704, "start": 1457.04, "end": 1462.8, "text": " that period and the ones that don't. And then after that, we are matching a space. Then after", "tokens": [50364, 300, 2896, 293, 264, 2306, 300, 500, 380, 13, 400, 550, 934, 300, 11, 321, 366, 14324, 257, 1901, 13, 1396, 934, 50652], "temperature": 0.0, "avg_logprob": -0.05275187940679045, "compression_ratio": 1.8505747126436782, "no_speech_prob": 0.014955544844269753}, {"id": 250, "seek": 145704, "start": 1462.8, "end": 1468.72, "text": " that space, we the first letter of the last name, we're looking for any capital letter. So we have", "tokens": [50652, 300, 1901, 11, 321, 264, 700, 5063, 295, 264, 1036, 1315, 11, 321, 434, 1237, 337, 604, 4238, 5063, 13, 407, 321, 362, 50948], "temperature": 0.0, "avg_logprob": -0.05275187940679045, "compression_ratio": 1.8505747126436782, "no_speech_prob": 0.014955544844269753}, {"id": 251, "seek": 145704, "start": 1468.72, "end": 1474.8, "text": " a character set here that is a through Z of capital letters. And then for the rest of the last name,", "tokens": [50948, 257, 2517, 992, 510, 300, 307, 257, 807, 1176, 295, 4238, 7825, 13, 400, 550, 337, 264, 1472, 295, 264, 1036, 1315, 11, 51252], "temperature": 0.0, "avg_logprob": -0.05275187940679045, "compression_ratio": 1.8505747126436782, "no_speech_prob": 0.014955544844269753}, {"id": 252, "seek": 145704, "start": 1474.8, "end": 1481.92, "text": " we are matching zero or more word characters. Now these groups can actually be used to capture", "tokens": [51252, 321, 366, 14324, 4018, 420, 544, 1349, 4342, 13, 823, 613, 3935, 393, 767, 312, 1143, 281, 7983, 51608], "temperature": 0.0, "avg_logprob": -0.05275187940679045, "compression_ratio": 1.8505747126436782, "no_speech_prob": 0.014955544844269753}, {"id": 253, "seek": 145704, "start": 1481.92, "end": 1486.32, "text": " sections of your matched regular expression. And that's something that we'll look at in just a", "tokens": [51608, 10863, 295, 428, 21447, 3890, 6114, 13, 400, 300, 311, 746, 300, 321, 603, 574, 412, 294, 445, 257, 51828], "temperature": 0.0, "avg_logprob": -0.05275187940679045, "compression_ratio": 1.8505747126436782, "no_speech_prob": 0.014955544844269753}, {"id": 254, "seek": 148632, "start": 1486.32, "end": 1491.6, "text": " minute. But for now, let's do a quick recap of everything that we've learned so far. And look", "tokens": [50364, 3456, 13, 583, 337, 586, 11, 718, 311, 360, 257, 1702, 20928, 295, 1203, 300, 321, 600, 3264, 370, 1400, 13, 400, 574, 50628], "temperature": 0.0, "avg_logprob": -0.048411768725794606, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.00521951075643301}, {"id": 255, "seek": 148632, "start": 1491.6, "end": 1496.72, "text": " at some examples that incorporates all of these things together. So I have a file here and I'm", "tokens": [50628, 412, 512, 5110, 300, 50193, 439, 295, 613, 721, 1214, 13, 407, 286, 362, 257, 3991, 510, 293, 286, 478, 50884], "temperature": 0.0, "avg_logprob": -0.048411768725794606, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.00521951075643301}, {"id": 256, "seek": 148632, "start": 1496.72, "end": 1503.84, "text": " going to move my snippets back into the group here and open up this file emails.txt. So I've got a", "tokens": [50884, 516, 281, 1286, 452, 35623, 1385, 646, 666, 264, 1594, 510, 293, 1269, 493, 341, 3991, 12524, 13, 83, 734, 13, 407, 286, 600, 658, 257, 51240], "temperature": 0.0, "avg_logprob": -0.048411768725794606, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.00521951075643301}, {"id": 257, "seek": 148632, "start": 1503.84, "end": 1508.56, "text": " file here with three fairly different email addresses. So let's try to write a regular", "tokens": [51240, 3991, 510, 365, 1045, 6457, 819, 3796, 16862, 13, 407, 718, 311, 853, 281, 2464, 257, 3890, 51476], "temperature": 0.0, "avg_logprob": -0.048411768725794606, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.00521951075643301}, {"id": 258, "seek": 148632, "start": 1508.56, "end": 1514.6399999999999, "text": " expression that will match all of these emails. So let's just match the first email address first", "tokens": [51476, 6114, 300, 486, 2995, 439, 295, 613, 12524, 13, 407, 718, 311, 445, 2995, 264, 700, 3796, 2985, 700, 51780], "temperature": 0.0, "avg_logprob": -0.048411768725794606, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.00521951075643301}, {"id": 259, "seek": 151464, "start": 1514.64, "end": 1520.24, "text": " and see what that looks like. So the first email address, we have a mix of upper and lowercase", "tokens": [50364, 293, 536, 437, 300, 1542, 411, 13, 407, 264, 700, 3796, 2985, 11, 321, 362, 257, 2890, 295, 6597, 293, 3126, 9765, 50644], "temperature": 0.0, "avg_logprob": -0.09089320182800292, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.0010986699489876628}, {"id": 260, "seek": 151464, "start": 1520.24, "end": 1526.96, "text": " letters here before we hit this at symbol. So let's go ahead and match those first. So to match", "tokens": [50644, 7825, 510, 949, 321, 2045, 341, 412, 5986, 13, 407, 718, 311, 352, 2286, 293, 2995, 729, 700, 13, 407, 281, 2995, 50980], "temperature": 0.0, "avg_logprob": -0.09089320182800292, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.0010986699489876628}, {"id": 261, "seek": 151464, "start": 1526.96, "end": 1533.5200000000002, "text": " any upper or lowercase letters, we can do a character set. And we can do a lowercase a through", "tokens": [50980, 604, 6597, 420, 3126, 9765, 7825, 11, 321, 393, 360, 257, 2517, 992, 13, 400, 321, 393, 360, 257, 3126, 9765, 257, 807, 51308], "temperature": 0.0, "avg_logprob": -0.09089320182800292, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.0010986699489876628}, {"id": 262, "seek": 151464, "start": 1533.5200000000002, "end": 1540.0, "text": " Z or an uppercase a through uppercase Z. Now right now, this is only matching those single", "tokens": [51308, 1176, 420, 364, 11775, 2869, 651, 257, 807, 11775, 2869, 651, 1176, 13, 823, 558, 586, 11, 341, 307, 787, 14324, 729, 2167, 51632], "temperature": 0.0, "avg_logprob": -0.09089320182800292, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.0010986699489876628}, {"id": 263, "seek": 154000, "start": 1540.0, "end": 1546.72, "text": " characters. So we can use the plus quantifier to say that we want one or more of these upper or", "tokens": [50364, 4342, 13, 407, 321, 393, 764, 264, 1804, 4426, 9902, 281, 584, 300, 321, 528, 472, 420, 544, 295, 613, 6597, 420, 50700], "temperature": 0.0, "avg_logprob": -0.059649419784545896, "compression_ratio": 1.768181818181818, "no_speech_prob": 0.01282014511525631}, {"id": 264, "seek": 154000, "start": 1546.72, "end": 1551.76, "text": " lowercase letters. So we're still working on the first email address here, we have our upper and", "tokens": [50700, 3126, 9765, 7825, 13, 407, 321, 434, 920, 1364, 322, 264, 700, 3796, 2985, 510, 11, 321, 362, 527, 6597, 293, 50952], "temperature": 0.0, "avg_logprob": -0.059649419784545896, "compression_ratio": 1.768181818181818, "no_speech_prob": 0.01282014511525631}, {"id": 265, "seek": 154000, "start": 1551.76, "end": 1556.56, "text": " lowercase letters here. And now we want to match that at symbol. So I'll just put in a literal", "tokens": [50952, 3126, 9765, 7825, 510, 13, 400, 586, 321, 528, 281, 2995, 300, 412, 5986, 13, 407, 286, 603, 445, 829, 294, 257, 20411, 51192], "temperature": 0.0, "avg_logprob": -0.059649419784545896, "compression_ratio": 1.768181818181818, "no_speech_prob": 0.01282014511525631}, {"id": 266, "seek": 154000, "start": 1556.56, "end": 1563.12, "text": " at symbol. And now for the domain name here, I'll just do a another search for any upper or lowercase", "tokens": [51192, 412, 5986, 13, 400, 586, 337, 264, 9274, 1315, 510, 11, 286, 603, 445, 360, 257, 1071, 3164, 337, 604, 6597, 420, 3126, 9765, 51520], "temperature": 0.0, "avg_logprob": -0.059649419784545896, "compression_ratio": 1.768181818181818, "no_speech_prob": 0.01282014511525631}, {"id": 267, "seek": 156312, "start": 1563.12, "end": 1569.9199999999998, "text": " letters. So I'll do the same as we did before. And then I will do a plus sign for a quantifier to", "tokens": [50364, 7825, 13, 407, 286, 603, 360, 264, 912, 382, 321, 630, 949, 13, 400, 550, 286, 486, 360, 257, 1804, 1465, 337, 257, 4426, 9902, 281, 50704], "temperature": 0.0, "avg_logprob": -0.06222533271426246, "compression_ratio": 1.703056768558952, "no_speech_prob": 0.09267354011535645}, {"id": 268, "seek": 156312, "start": 1569.9199999999998, "end": 1576.0, "text": " match any upper lowercase letters after that at symbol. And then that's when we hit the end with", "tokens": [50704, 2995, 604, 6597, 3126, 9765, 7825, 934, 300, 412, 5986, 13, 400, 550, 300, 311, 562, 321, 2045, 264, 917, 365, 51008], "temperature": 0.0, "avg_logprob": -0.06222533271426246, "compression_ratio": 1.703056768558952, "no_speech_prob": 0.09267354011535645}, {"id": 269, "seek": 156312, "start": 1576.0, "end": 1582.6399999999999, "text": " the dot com. So to match the dot com, we can do a backslash period for the dot. And then we can", "tokens": [51008, 264, 5893, 395, 13, 407, 281, 2995, 264, 5893, 395, 11, 321, 393, 360, 257, 646, 10418, 1299, 2896, 337, 264, 5893, 13, 400, 550, 321, 393, 51340], "temperature": 0.0, "avg_logprob": -0.06222533271426246, "compression_ratio": 1.703056768558952, "no_speech_prob": 0.09267354011535645}, {"id": 270, "seek": 156312, "start": 1582.6399999999999, "end": 1588.32, "text": " just fill in a literal com. So now we've successfully matched that first address. Now it looks like", "tokens": [51340, 445, 2836, 294, 257, 20411, 395, 13, 407, 586, 321, 600, 10727, 21447, 300, 700, 2985, 13, 823, 309, 1542, 411, 51624], "temperature": 0.0, "avg_logprob": -0.06222533271426246, "compression_ratio": 1.703056768558952, "no_speech_prob": 0.09267354011535645}, {"id": 271, "seek": 158832, "start": 1588.32, "end": 1594.24, "text": " it's not matching the second address. So let's see why and see if we can mold this to match the", "tokens": [50364, 309, 311, 406, 14324, 264, 1150, 2985, 13, 407, 718, 311, 536, 983, 293, 536, 498, 321, 393, 11102, 341, 281, 2995, 264, 50660], "temperature": 0.0, "avg_logprob": -0.03944321067965761, "compression_ratio": 1.9947368421052631, "no_speech_prob": 0.05833469331264496}, {"id": 272, "seek": 158832, "start": 1594.24, "end": 1600.24, "text": " second address as well. So we can see that the second address has a dot in the first part of", "tokens": [50660, 1150, 2985, 382, 731, 13, 407, 321, 393, 536, 300, 264, 1150, 2985, 575, 257, 5893, 294, 264, 700, 644, 295, 50960], "temperature": 0.0, "avg_logprob": -0.03944321067965761, "compression_ratio": 1.9947368421052631, "no_speech_prob": 0.05833469331264496}, {"id": 273, "seek": 158832, "start": 1600.24, "end": 1607.6799999999998, "text": " the name here. So let's add a dot to our first character set, so that dots are included in", "tokens": [50960, 264, 1315, 510, 13, 407, 718, 311, 909, 257, 5893, 281, 527, 700, 2517, 992, 11, 370, 300, 15026, 366, 5556, 294, 51332], "temperature": 0.0, "avg_logprob": -0.03944321067965761, "compression_ratio": 1.9947368421052631, "no_speech_prob": 0.05833469331264496}, {"id": 274, "seek": 158832, "start": 1607.6799999999998, "end": 1614.08, "text": " that character set. So now it's still not matching that second address. And it's because at the end", "tokens": [51332, 300, 2517, 992, 13, 407, 586, 309, 311, 920, 406, 14324, 300, 1150, 2985, 13, 400, 309, 311, 570, 412, 264, 917, 51652], "temperature": 0.0, "avg_logprob": -0.03944321067965761, "compression_ratio": 1.9947368421052631, "no_speech_prob": 0.05833469331264496}, {"id": 275, "seek": 161408, "start": 1614.08, "end": 1621.1999999999998, "text": " here, we don't have a dot com but a dot edu. So in order to search for both, we can use a group", "tokens": [50364, 510, 11, 321, 500, 380, 362, 257, 5893, 395, 457, 257, 5893, 1257, 84, 13, 407, 294, 1668, 281, 3164, 337, 1293, 11, 321, 393, 764, 257, 1594, 50720], "temperature": 0.0, "avg_logprob": -0.05737000313874717, "compression_ratio": 1.790909090909091, "no_speech_prob": 0.010488311760127544}, {"id": 276, "seek": 161408, "start": 1621.1999999999998, "end": 1629.36, "text": " like we saw before using open and close parentheses. And we can search for either com or edu. Okay, so", "tokens": [50720, 411, 321, 1866, 949, 1228, 1269, 293, 1998, 34153, 13, 400, 321, 393, 3164, 337, 2139, 395, 420, 1257, 84, 13, 1033, 11, 370, 51128], "temperature": 0.0, "avg_logprob": -0.05737000313874717, "compression_ratio": 1.790909090909091, "no_speech_prob": 0.010488311760127544}, {"id": 277, "seek": 161408, "start": 1629.36, "end": 1634.6399999999999, "text": " now we are building this up a little bit at a time. And we can see that we are now matching our", "tokens": [51128, 586, 321, 366, 2390, 341, 493, 257, 707, 857, 412, 257, 565, 13, 400, 321, 393, 536, 300, 321, 366, 586, 14324, 527, 51392], "temperature": 0.0, "avg_logprob": -0.05737000313874717, "compression_ratio": 1.790909090909091, "no_speech_prob": 0.010488311760127544}, {"id": 278, "seek": 161408, "start": 1634.6399999999999, "end": 1639.6799999999998, "text": " second email address. Okay, so now let's see if we can change this to match our third email address", "tokens": [51392, 1150, 3796, 2985, 13, 1033, 11, 370, 586, 718, 311, 536, 498, 321, 393, 1319, 341, 281, 2995, 527, 2636, 3796, 2985, 51644], "temperature": 0.0, "avg_logprob": -0.05737000313874717, "compression_ratio": 1.790909090909091, "no_speech_prob": 0.010488311760127544}, {"id": 279, "seek": 163968, "start": 1639.68, "end": 1647.44, "text": " here. So in our third email address, it looks like before the at symbol, we also have some hyphens", "tokens": [50364, 510, 13, 407, 294, 527, 2636, 3796, 2985, 11, 309, 1542, 411, 949, 264, 412, 5986, 11, 321, 611, 362, 512, 2477, 950, 694, 50752], "temperature": 0.0, "avg_logprob": -0.050419883728027345, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.010651621967554092}, {"id": 280, "seek": 163968, "start": 1647.44, "end": 1653.28, "text": " and some numbers in the first part here. So let's add those to the character set as well.", "tokens": [50752, 293, 512, 3547, 294, 264, 700, 644, 510, 13, 407, 718, 311, 909, 729, 281, 264, 2517, 992, 382, 731, 13, 51044], "temperature": 0.0, "avg_logprob": -0.050419883728027345, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.010651621967554092}, {"id": 281, "seek": 163968, "start": 1653.28, "end": 1661.52, "text": " So back here after our capital letters, I'm also going to add in digits by doing zero through nine.", "tokens": [51044, 407, 646, 510, 934, 527, 4238, 7825, 11, 286, 478, 611, 516, 281, 909, 294, 27011, 538, 884, 4018, 807, 4949, 13, 51456], "temperature": 0.0, "avg_logprob": -0.050419883728027345, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.010651621967554092}, {"id": 282, "seek": 163968, "start": 1661.52, "end": 1668.8, "text": " And we also want to add a dash in there as well. So that should match everything before the at symbol.", "tokens": [51456, 400, 321, 611, 528, 281, 909, 257, 8240, 294, 456, 382, 731, 13, 407, 300, 820, 2995, 1203, 949, 264, 412, 5986, 13, 51820], "temperature": 0.0, "avg_logprob": -0.050419883728027345, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.010651621967554092}, {"id": 283, "seek": 166880, "start": 1668.8, "end": 1674.3999999999999, "text": " Now it looks like we also have a dash in our domain here. So we'll have to add that in as well.", "tokens": [50364, 823, 309, 1542, 411, 321, 611, 362, 257, 8240, 294, 527, 9274, 510, 13, 407, 321, 603, 362, 281, 909, 300, 294, 382, 731, 13, 50644], "temperature": 0.0, "avg_logprob": -0.07078307142881589, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.0007553722243756056}, {"id": 284, "seek": 166880, "start": 1674.3999999999999, "end": 1680.3999999999999, "text": " So after the at symbol, we're matching any characters right now, it's just lowercase and uppercase,", "tokens": [50644, 407, 934, 264, 412, 5986, 11, 321, 434, 14324, 604, 4342, 558, 586, 11, 309, 311, 445, 3126, 9765, 293, 11775, 2869, 651, 11, 50944], "temperature": 0.0, "avg_logprob": -0.07078307142881589, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.0007553722243756056}, {"id": 285, "seek": 166880, "start": 1680.3999999999999, "end": 1686.56, "text": " but we can put a dash in there as well. And lastly, it's still not matching because just like the", "tokens": [50944, 457, 321, 393, 829, 257, 8240, 294, 456, 382, 731, 13, 400, 16386, 11, 309, 311, 920, 406, 14324, 570, 445, 411, 264, 51252], "temperature": 0.0, "avg_logprob": -0.07078307142881589, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.0007553722243756056}, {"id": 286, "seek": 166880, "start": 1686.56, "end": 1693.6, "text": " other two instead, we have a dot net here instead. So we can just add in a second or at the end and", "tokens": [51252, 661, 732, 2602, 11, 321, 362, 257, 5893, 2533, 510, 2602, 13, 407, 321, 393, 445, 909, 294, 257, 1150, 420, 412, 264, 917, 293, 51604], "temperature": 0.0, "avg_logprob": -0.07078307142881589, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.0007553722243756056}, {"id": 287, "seek": 169360, "start": 1693.6, "end": 1699.76, "text": " also include dot net. So we can see that we built that up a little bit at a time to match all three", "tokens": [50364, 611, 4090, 5893, 2533, 13, 407, 321, 393, 536, 300, 321, 3094, 300, 493, 257, 707, 857, 412, 257, 565, 281, 2995, 439, 1045, 50672], "temperature": 0.0, "avg_logprob": -0.04084167310169765, "compression_ratio": 1.7526881720430108, "no_speech_prob": 0.10968174785375595}, {"id": 288, "seek": 169360, "start": 1699.76, "end": 1704.7199999999998, "text": " of our email addresses. Now with something like email addresses, it can be pretty tough writing", "tokens": [50672, 295, 527, 3796, 16862, 13, 823, 365, 746, 411, 3796, 16862, 11, 309, 393, 312, 1238, 4930, 3579, 50920], "temperature": 0.0, "avg_logprob": -0.04084167310169765, "compression_ratio": 1.7526881720430108, "no_speech_prob": 0.10968174785375595}, {"id": 289, "seek": 169360, "start": 1704.7199999999998, "end": 1709.9199999999998, "text": " your own regular expressions from scratch. But there are a lot of these available online. And", "tokens": [50920, 428, 1065, 3890, 15277, 490, 8459, 13, 583, 456, 366, 257, 688, 295, 613, 2435, 2950, 13, 400, 51180], "temperature": 0.0, "avg_logprob": -0.04084167310169765, "compression_ratio": 1.7526881720430108, "no_speech_prob": 0.10968174785375595}, {"id": 290, "seek": 169360, "start": 1709.9199999999998, "end": 1714.9599999999998, "text": " once we learn how to write regular expressions, then we should be able to read them and figure out", "tokens": [51180, 1564, 321, 1466, 577, 281, 2464, 3890, 15277, 11, 550, 321, 820, 312, 1075, 281, 1401, 552, 293, 2573, 484, 51432], "temperature": 0.0, "avg_logprob": -0.04084167310169765, "compression_ratio": 1.7526881720430108, "no_speech_prob": 0.10968174785375595}, {"id": 291, "seek": 169360, "start": 1714.9599999999998, "end": 1720.32, "text": " how they're matching as well. Now, I've always found that reading other people's regular expressions", "tokens": [51432, 577, 436, 434, 14324, 382, 731, 13, 823, 11, 286, 600, 1009, 1352, 300, 3760, 661, 561, 311, 3890, 15277, 51700], "temperature": 0.0, "avg_logprob": -0.04084167310169765, "compression_ratio": 1.7526881720430108, "no_speech_prob": 0.10968174785375595}, {"id": 292, "seek": 172032, "start": 1720.32, "end": 1725.6799999999998, "text": " to be a lot harder than writing them. But let's take a look at one and see if we can do this.", "tokens": [50364, 281, 312, 257, 688, 6081, 813, 3579, 552, 13, 583, 718, 311, 747, 257, 574, 412, 472, 293, 536, 498, 321, 393, 360, 341, 13, 50632], "temperature": 0.0, "avg_logprob": -0.041753210005213, "compression_ratio": 1.9397590361445782, "no_speech_prob": 0.018544603139162064}, {"id": 293, "seek": 172032, "start": 1725.6799999999998, "end": 1731.6799999999998, "text": " So I have an expression here that I pulled offline that matches email addresses. And let's", "tokens": [50632, 407, 286, 362, 364, 6114, 510, 300, 286, 7373, 21857, 300, 10676, 3796, 16862, 13, 400, 718, 311, 50932], "temperature": 0.0, "avg_logprob": -0.041753210005213, "compression_ratio": 1.9397590361445782, "no_speech_prob": 0.018544603139162064}, {"id": 294, "seek": 172032, "start": 1731.6799999999998, "end": 1737.52, "text": " paste this in here and see if we can read through and see what this is matching. So we can see that", "tokens": [50932, 9163, 341, 294, 510, 293, 536, 498, 321, 393, 1401, 807, 293, 536, 437, 341, 307, 14324, 13, 407, 321, 393, 536, 300, 51224], "temperature": 0.0, "avg_logprob": -0.041753210005213, "compression_ratio": 1.9397590361445782, "no_speech_prob": 0.018544603139162064}, {"id": 295, "seek": 172032, "start": 1737.52, "end": 1742.8799999999999, "text": " the one that I got offline does match all three of my email addresses here. Now let's look through", "tokens": [51224, 264, 472, 300, 286, 658, 21857, 775, 2995, 439, 1045, 295, 452, 3796, 16862, 510, 13, 823, 718, 311, 574, 807, 51492], "temperature": 0.0, "avg_logprob": -0.041753210005213, "compression_ratio": 1.9397590361445782, "no_speech_prob": 0.018544603139162064}, {"id": 296, "seek": 172032, "start": 1742.8799999999999, "end": 1748.6399999999999, "text": " this. So we can see that it's somewhat similar to what we had before. But first we have a character", "tokens": [51492, 341, 13, 407, 321, 393, 536, 300, 309, 311, 8344, 2531, 281, 437, 321, 632, 949, 13, 583, 700, 321, 362, 257, 2517, 51780], "temperature": 0.0, "avg_logprob": -0.041753210005213, "compression_ratio": 1.9397590361445782, "no_speech_prob": 0.018544603139162064}, {"id": 297, "seek": 174864, "start": 1748.64, "end": 1756.4, "text": " set here and it's a pretty large character set. And it matches lowercase, uppercase, any number,", "tokens": [50364, 992, 510, 293, 309, 311, 257, 1238, 2416, 2517, 992, 13, 400, 309, 10676, 3126, 9765, 11, 11775, 2869, 651, 11, 604, 1230, 11, 50752], "temperature": 0.0, "avg_logprob": -0.06170946009018842, "compression_ratio": 1.9059405940594059, "no_speech_prob": 0.019714951515197754}, {"id": 298, "seek": 174864, "start": 1757.1200000000001, "end": 1764.24, "text": " an underscore, a period, a plus sign, or a hyphen. And then the plus sign here says that we want to", "tokens": [50788, 364, 37556, 11, 257, 2896, 11, 257, 1804, 1465, 11, 420, 257, 2477, 47059, 13, 400, 550, 264, 1804, 1465, 510, 1619, 300, 321, 528, 281, 51144], "temperature": 0.0, "avg_logprob": -0.06170946009018842, "compression_ratio": 1.9059405940594059, "no_speech_prob": 0.019714951515197754}, {"id": 299, "seek": 174864, "start": 1764.24, "end": 1770.0, "text": " match one or more of any of those characters. And we match one or more of those characters", "tokens": [51144, 2995, 472, 420, 544, 295, 604, 295, 729, 4342, 13, 400, 321, 2995, 472, 420, 544, 295, 729, 4342, 51432], "temperature": 0.0, "avg_logprob": -0.06170946009018842, "compression_ratio": 1.9059405940594059, "no_speech_prob": 0.019714951515197754}, {"id": 300, "seek": 174864, "start": 1770.0, "end": 1775.68, "text": " all the way up until we hit an at sign. And then after the at sign, we have another character set", "tokens": [51432, 439, 264, 636, 493, 1826, 321, 2045, 364, 412, 1465, 13, 400, 550, 934, 264, 412, 1465, 11, 321, 362, 1071, 2517, 992, 51716], "temperature": 0.0, "avg_logprob": -0.06170946009018842, "compression_ratio": 1.9059405940594059, "no_speech_prob": 0.019714951515197754}, {"id": 301, "seek": 177568, "start": 1775.68, "end": 1783.1200000000001, "text": " here. And in this character set, we have lowercase letters, uppercase letters, any digits, and also", "tokens": [50364, 510, 13, 400, 294, 341, 2517, 992, 11, 321, 362, 3126, 9765, 7825, 11, 11775, 2869, 651, 7825, 11, 604, 27011, 11, 293, 611, 50736], "temperature": 0.0, "avg_logprob": -0.05240338356768499, "compression_ratio": 1.8615384615384616, "no_speech_prob": 0.01640086993575096}, {"id": 302, "seek": 177568, "start": 1783.1200000000001, "end": 1788.72, "text": " a hyphen. Now I don't know a lot about email addresses, but I'm assuming that since they left out the", "tokens": [50736, 257, 2477, 47059, 13, 823, 286, 500, 380, 458, 257, 688, 466, 3796, 16862, 11, 457, 286, 478, 11926, 300, 1670, 436, 1411, 484, 264, 51016], "temperature": 0.0, "avg_logprob": -0.05240338356768499, "compression_ratio": 1.8615384615384616, "no_speech_prob": 0.01640086993575096}, {"id": 303, "seek": 177568, "start": 1788.72, "end": 1793.92, "text": " underscore, the period, and the plus sign that were in the first part of the email address,", "tokens": [51016, 37556, 11, 264, 2896, 11, 293, 264, 1804, 1465, 300, 645, 294, 264, 700, 644, 295, 264, 3796, 2985, 11, 51276], "temperature": 0.0, "avg_logprob": -0.05240338356768499, "compression_ratio": 1.8615384615384616, "no_speech_prob": 0.01640086993575096}, {"id": 304, "seek": 177568, "start": 1793.92, "end": 1798.5600000000002, "text": " I'm assuming that those aren't allowed in the domain. So then we have a plus sign after that", "tokens": [51276, 286, 478, 11926, 300, 729, 3212, 380, 4350, 294, 264, 9274, 13, 407, 550, 321, 362, 257, 1804, 1465, 934, 300, 51508], "temperature": 0.0, "avg_logprob": -0.05240338356768499, "compression_ratio": 1.8615384615384616, "no_speech_prob": 0.01640086993575096}, {"id": 305, "seek": 177568, "start": 1798.5600000000002, "end": 1803.68, "text": " character set, which means that we're matching one or more of any of those characters all the way", "tokens": [51508, 2517, 992, 11, 597, 1355, 300, 321, 434, 14324, 472, 420, 544, 295, 604, 295, 729, 4342, 439, 264, 636, 51764], "temperature": 0.0, "avg_logprob": -0.05240338356768499, "compression_ratio": 1.8615384615384616, "no_speech_prob": 0.01640086993575096}, {"id": 306, "seek": 180368, "start": 1803.68, "end": 1810.24, "text": " up until we reach this literal dot. And that literal dot is escaped with a backslash. And then", "tokens": [50364, 493, 1826, 321, 2524, 341, 20411, 5893, 13, 400, 300, 20411, 5893, 307, 20397, 365, 257, 646, 10418, 1299, 13, 400, 550, 50692], "temperature": 0.0, "avg_logprob": -0.05873937129974365, "compression_ratio": 1.8009259259259258, "no_speech_prob": 0.00757658202201128}, {"id": 307, "seek": 180368, "start": 1810.24, "end": 1815.76, "text": " after the dot, we have another character set here. And this character set is any lowercase letter,", "tokens": [50692, 934, 264, 5893, 11, 321, 362, 1071, 2517, 992, 510, 13, 400, 341, 2517, 992, 307, 604, 3126, 9765, 5063, 11, 50968], "temperature": 0.0, "avg_logprob": -0.05873937129974365, "compression_ratio": 1.8009259259259258, "no_speech_prob": 0.00757658202201128}, {"id": 308, "seek": 180368, "start": 1815.76, "end": 1823.28, "text": " any uppercase letter, any digits, any hyphen, or a period. And then that is followed by a plus sign,", "tokens": [50968, 604, 11775, 2869, 651, 5063, 11, 604, 27011, 11, 604, 2477, 47059, 11, 420, 257, 2896, 13, 400, 550, 300, 307, 6263, 538, 257, 1804, 1465, 11, 51344], "temperature": 0.0, "avg_logprob": -0.05873937129974365, "compression_ratio": 1.8009259259259258, "no_speech_prob": 0.00757658202201128}, {"id": 309, "seek": 180368, "start": 1823.28, "end": 1828.3200000000002, "text": " which matches one or more of anything in that character set. So just like I did with the phone", "tokens": [51344, 597, 10676, 472, 420, 544, 295, 1340, 294, 300, 2517, 992, 13, 407, 445, 411, 286, 630, 365, 264, 2593, 51596], "temperature": 0.0, "avg_logprob": -0.05873937129974365, "compression_ratio": 1.8009259259259258, "no_speech_prob": 0.00757658202201128}, {"id": 310, "seek": 182832, "start": 1828.32, "end": 1834.08, "text": " numbers, if we open up our data file here, with this regular expression that we've typed in,", "tokens": [50364, 3547, 11, 498, 321, 1269, 493, 527, 1412, 3991, 510, 11, 365, 341, 3890, 6114, 300, 321, 600, 33941, 294, 11, 50652], "temperature": 0.0, "avg_logprob": -0.0432578418565833, "compression_ratio": 1.8104089219330854, "no_speech_prob": 0.15199336409568787}, {"id": 311, "seek": 182832, "start": 1834.08, "end": 1840.3999999999999, "text": " then we can see that it does match all of the email addresses in this data file as well. So we've", "tokens": [50652, 550, 321, 393, 536, 300, 309, 775, 2995, 439, 295, 264, 3796, 16862, 294, 341, 1412, 3991, 382, 731, 13, 407, 321, 600, 50968], "temperature": 0.0, "avg_logprob": -0.0432578418565833, "compression_ratio": 1.8104089219330854, "no_speech_prob": 0.15199336409568787}, {"id": 312, "seek": 182832, "start": 1841.2, "end": 1846.48, "text": " got an expression that will match email addresses fairly well. So doing what we just did and reading", "tokens": [51008, 658, 364, 6114, 300, 486, 2995, 3796, 16862, 6457, 731, 13, 407, 884, 437, 321, 445, 630, 293, 3760, 51272], "temperature": 0.0, "avg_logprob": -0.0432578418565833, "compression_ratio": 1.8104089219330854, "no_speech_prob": 0.15199336409568787}, {"id": 313, "seek": 182832, "start": 1846.48, "end": 1851.9199999999998, "text": " through a regular expression written by other people is probably the hardest part of all this.", "tokens": [51272, 807, 257, 3890, 6114, 3720, 538, 661, 561, 307, 1391, 264, 13158, 644, 295, 439, 341, 13, 51544], "temperature": 0.0, "avg_logprob": -0.0432578418565833, "compression_ratio": 1.8104089219330854, "no_speech_prob": 0.15199336409568787}, {"id": 314, "seek": 182832, "start": 1851.9199999999998, "end": 1857.12, "text": " But if you walk through it bit by bit, then you should be able to break down just about any pattern.", "tokens": [51544, 583, 498, 291, 1792, 807, 309, 857, 538, 857, 11, 550, 291, 820, 312, 1075, 281, 1821, 760, 445, 466, 604, 5102, 13, 51804], "temperature": 0.0, "avg_logprob": -0.0432578418565833, "compression_ratio": 1.8104089219330854, "no_speech_prob": 0.15199336409568787}, {"id": 315, "seek": 185712, "start": 1857.12, "end": 1861.9199999999998, "text": " Okay, so the last thing that I'd like to look at in this video is how to capture information", "tokens": [50364, 1033, 11, 370, 264, 1036, 551, 300, 286, 1116, 411, 281, 574, 412, 294, 341, 960, 307, 577, 281, 7983, 1589, 50604], "temperature": 0.0, "avg_logprob": -0.05358614504915997, "compression_ratio": 1.6594827586206897, "no_speech_prob": 0.0020505955908447504}, {"id": 316, "seek": 185712, "start": 1861.9199999999998, "end": 1868.08, "text": " from groups. Now, we've already seen how to match groups, but we can actually use the information", "tokens": [50604, 490, 3935, 13, 823, 11, 321, 600, 1217, 1612, 577, 281, 2995, 3935, 11, 457, 321, 393, 767, 764, 264, 1589, 50912], "temperature": 0.0, "avg_logprob": -0.05358614504915997, "compression_ratio": 1.6594827586206897, "no_speech_prob": 0.0020505955908447504}, {"id": 317, "seek": 185712, "start": 1868.08, "end": 1873.76, "text": " captured from those groups. So to show an example of this, I'm going to open up a file here with", "tokens": [50912, 11828, 490, 729, 3935, 13, 407, 281, 855, 364, 1365, 295, 341, 11, 286, 478, 516, 281, 1269, 493, 257, 3991, 510, 365, 51196], "temperature": 0.0, "avg_logprob": -0.05358614504915997, "compression_ratio": 1.6594827586206897, "no_speech_prob": 0.0020505955908447504}, {"id": 318, "seek": 185712, "start": 1873.76, "end": 1882.6399999999999, "text": " some URLs. Okay, so we can see here that some of the URLs are HTTP, some are HTTPS. Also, some of", "tokens": [51196, 512, 43267, 13, 1033, 11, 370, 321, 393, 536, 510, 300, 512, 295, 264, 43267, 366, 33283, 11, 512, 366, 11751, 51, 6273, 13, 2743, 11, 512, 295, 51640], "temperature": 0.0, "avg_logprob": -0.05358614504915997, "compression_ratio": 1.6594827586206897, "no_speech_prob": 0.0020505955908447504}, {"id": 319, "seek": 188264, "start": 1882.64, "end": 1888.96, "text": " these have WWW before the domain name, and some do not. So let's say that you had a list of a lot", "tokens": [50364, 613, 362, 12040, 54, 949, 264, 9274, 1315, 11, 293, 512, 360, 406, 13, 407, 718, 311, 584, 300, 291, 632, 257, 1329, 295, 257, 688, 50680], "temperature": 0.0, "avg_logprob": -0.09949234428755734, "compression_ratio": 1.7566371681415929, "no_speech_prob": 0.04741734266281128}, {"id": 320, "seek": 188264, "start": 1888.96, "end": 1895.2, "text": " of different URLs within your document, and you only wanted to grab the domain name and the top", "tokens": [50680, 295, 819, 43267, 1951, 428, 4166, 11, 293, 291, 787, 1415, 281, 4444, 264, 9274, 1315, 293, 264, 1192, 50992], "temperature": 0.0, "avg_logprob": -0.09949234428755734, "compression_ratio": 1.7566371681415929, "no_speech_prob": 0.04741734266281128}, {"id": 321, "seek": 188264, "start": 1895.2, "end": 1901.2, "text": " level domain, which is .com or .gov. So for example, out of all these domains, you only wanted to grab", "tokens": [50992, 1496, 9274, 11, 597, 307, 2411, 1112, 420, 2411, 16089, 13, 407, 337, 1365, 11, 484, 295, 439, 613, 25514, 11, 291, 787, 1415, 281, 4444, 51292], "temperature": 0.0, "avg_logprob": -0.09949234428755734, "compression_ratio": 1.7566371681415929, "no_speech_prob": 0.04741734266281128}, {"id": 322, "seek": 188264, "start": 1901.2, "end": 1908.8000000000002, "text": " google.com or coreyms.com or youtube.com or nasa.gov. And you just wanted to ignore everything else.", "tokens": [51292, 20742, 13, 1112, 420, 4965, 88, 2592, 13, 1112, 420, 12487, 13, 1112, 420, 5382, 64, 13, 16089, 13, 400, 291, 445, 1415, 281, 11200, 1203, 1646, 13, 51672], "temperature": 0.0, "avg_logprob": -0.09949234428755734, "compression_ratio": 1.7566371681415929, "no_speech_prob": 0.04741734266281128}, {"id": 323, "seek": 190880, "start": 1908.8, "end": 1914.08, "text": " So let's see how we can do this. So first, let's write an expression that actually matches these", "tokens": [50364, 407, 718, 311, 536, 577, 321, 393, 360, 341, 13, 407, 700, 11, 718, 311, 2464, 364, 6114, 300, 767, 10676, 613, 50628], "temperature": 0.0, "avg_logprob": -0.07565233842381891, "compression_ratio": 1.7399103139013452, "no_speech_prob": 0.008576824329793453}, {"id": 324, "seek": 190880, "start": 1914.08, "end": 1921.84, "text": " URLs. So let me get rid of the one that we currently have. Now, first, to match this, we can say", "tokens": [50628, 43267, 13, 407, 718, 385, 483, 3973, 295, 264, 472, 300, 321, 4362, 362, 13, 823, 11, 700, 11, 281, 2995, 341, 11, 321, 393, 584, 51016], "temperature": 0.0, "avg_logprob": -0.07565233842381891, "compression_ratio": 1.7399103139013452, "no_speech_prob": 0.008576824329793453}, {"id": 325, "seek": 190880, "start": 1921.84, "end": 1929.36, "text": " all of these start with with HTTP. And then the s is optional. So we can say s and then put in a", "tokens": [51016, 439, 295, 613, 722, 365, 365, 33283, 13, 400, 550, 264, 262, 307, 17312, 13, 407, 321, 393, 584, 262, 293, 550, 829, 294, 257, 51392], "temperature": 0.0, "avg_logprob": -0.07565233842381891, "compression_ratio": 1.7399103139013452, "no_speech_prob": 0.008576824329793453}, {"id": 326, "seek": 190880, "start": 1929.36, "end": 1935.52, "text": " question mark to say that we want to match zero or one for the s. And then after that optional s,", "tokens": [51392, 1168, 1491, 281, 584, 300, 321, 528, 281, 2995, 4018, 420, 472, 337, 264, 262, 13, 400, 550, 934, 300, 17312, 262, 11, 51700], "temperature": 0.0, "avg_logprob": -0.07565233842381891, "compression_ratio": 1.7399103139013452, "no_speech_prob": 0.008576824329793453}, {"id": 327, "seek": 193552, "start": 1935.52, "end": 1940.96, "text": " we want a colon forward slash forward slash. So at this point, some of these domains have a", "tokens": [50364, 321, 528, 257, 8255, 2128, 17330, 2128, 17330, 13, 407, 412, 341, 935, 11, 512, 295, 613, 25514, 362, 257, 50636], "temperature": 0.0, "avg_logprob": -0.07925564108543026, "compression_ratio": 1.731818181818182, "no_speech_prob": 0.012052297592163086}, {"id": 328, "seek": 193552, "start": 1940.96, "end": 1950.24, "text": " WWW dot before the domain name and some do not. So that WWW dot is optional. So since this isn't", "tokens": [50636, 12040, 54, 5893, 949, 264, 9274, 1315, 293, 512, 360, 406, 13, 407, 300, 12040, 54, 5893, 307, 17312, 13, 407, 1670, 341, 1943, 380, 51100], "temperature": 0.0, "avg_logprob": -0.07925564108543026, "compression_ratio": 1.731818181818182, "no_speech_prob": 0.012052297592163086}, {"id": 329, "seek": 193552, "start": 1950.24, "end": 1958.16, "text": " one character, we're actually going to create a group here and say this group of WWW and then a", "tokens": [51100, 472, 2517, 11, 321, 434, 767, 516, 281, 1884, 257, 1594, 510, 293, 584, 341, 1594, 295, 12040, 54, 293, 550, 257, 51496], "temperature": 0.0, "avg_logprob": -0.07925564108543026, "compression_ratio": 1.731818181818182, "no_speech_prob": 0.012052297592163086}, {"id": 330, "seek": 193552, "start": 1958.16, "end": 1964.56, "text": " literal dot, which is a backslash dot. Now, all of that group is optional. So now you can see on", "tokens": [51496, 20411, 5893, 11, 597, 307, 257, 646, 10418, 1299, 5893, 13, 823, 11, 439, 295, 300, 1594, 307, 17312, 13, 407, 586, 291, 393, 536, 322, 51816], "temperature": 0.0, "avg_logprob": -0.07925564108543026, "compression_ratio": 1.731818181818182, "no_speech_prob": 0.012052297592163086}, {"id": 331, "seek": 196456, "start": 1964.56, "end": 1969.9199999999998, "text": " all of our URLs, we've matched up to the domain name. So now to complete this, I'm just going to say", "tokens": [50364, 439, 295, 527, 43267, 11, 321, 600, 21447, 493, 281, 264, 9274, 1315, 13, 407, 586, 281, 3566, 341, 11, 286, 478, 445, 516, 281, 584, 50632], "temperature": 0.0, "avg_logprob": -0.06576698749989003, "compression_ratio": 1.7312775330396475, "no_speech_prob": 0.0022516660392284393}, {"id": 332, "seek": 196456, "start": 1970.72, "end": 1978.6399999999999, "text": " any word character, so backslash w, and I will put in a plus sign to say one or more of those word", "tokens": [50672, 604, 1349, 2517, 11, 370, 646, 10418, 1299, 261, 11, 293, 286, 486, 829, 294, 257, 1804, 1465, 281, 584, 472, 420, 544, 295, 729, 1349, 51068], "temperature": 0.0, "avg_logprob": -0.06576698749989003, "compression_ratio": 1.7312775330396475, "no_speech_prob": 0.0022516660392284393}, {"id": 333, "seek": 196456, "start": 1978.6399999999999, "end": 1984.96, "text": " characters. And then we get here to the top level domain. So we want to match a literal dot. So we'll", "tokens": [51068, 4342, 13, 400, 550, 321, 483, 510, 281, 264, 1192, 1496, 9274, 13, 407, 321, 528, 281, 2995, 257, 20411, 5893, 13, 407, 321, 603, 51384], "temperature": 0.0, "avg_logprob": -0.06576698749989003, "compression_ratio": 1.7312775330396475, "no_speech_prob": 0.0022516660392284393}, {"id": 334, "seek": 196456, "start": 1984.96, "end": 1990.3999999999999, "text": " do a backslash dot. And then for the rest of that top level domain, I will just do any word", "tokens": [51384, 360, 257, 646, 10418, 1299, 5893, 13, 400, 550, 337, 264, 1472, 295, 300, 1192, 1496, 9274, 11, 286, 486, 445, 360, 604, 1349, 51656], "temperature": 0.0, "avg_logprob": -0.06576698749989003, "compression_ratio": 1.7312775330396475, "no_speech_prob": 0.0022516660392284393}, {"id": 335, "seek": 199040, "start": 1990.4, "end": 1996.96, "text": " character one or more times so we can do a word character with a plus sign to do one or more.", "tokens": [50364, 2517, 472, 420, 544, 1413, 370, 321, 393, 360, 257, 1349, 2517, 365, 257, 1804, 1465, 281, 360, 472, 420, 544, 13, 50692], "temperature": 0.0, "avg_logprob": -0.043088219829441346, "compression_ratio": 1.738532110091743, "no_speech_prob": 0.0013669432373717427}, {"id": 336, "seek": 199040, "start": 1996.96, "end": 2003.6000000000001, "text": " Okay, so we can see that this matches all of our URLs. But the point here was to use our groups", "tokens": [50692, 1033, 11, 370, 321, 393, 536, 300, 341, 10676, 439, 295, 527, 43267, 13, 583, 264, 935, 510, 390, 281, 764, 527, 3935, 51024], "temperature": 0.0, "avg_logprob": -0.043088219829441346, "compression_ratio": 1.738532110091743, "no_speech_prob": 0.0013669432373717427}, {"id": 337, "seek": 199040, "start": 2003.6000000000001, "end": 2010.64, "text": " to capture some information from our URLs. So let's capture the domain name and the top level", "tokens": [51024, 281, 7983, 512, 1589, 490, 527, 43267, 13, 407, 718, 311, 7983, 264, 9274, 1315, 293, 264, 1192, 1496, 51376], "temperature": 0.0, "avg_logprob": -0.043088219829441346, "compression_ratio": 1.738532110091743, "no_speech_prob": 0.0013669432373717427}, {"id": 338, "seek": 199040, "start": 2010.64, "end": 2016.5600000000002, "text": " domain, which is the dot com or the dot gov and things like that. So to capture these sections,", "tokens": [51376, 9274, 11, 597, 307, 264, 5893, 395, 420, 264, 5893, 352, 85, 293, 721, 411, 300, 13, 407, 281, 7983, 613, 10863, 11, 51672], "temperature": 0.0, "avg_logprob": -0.043088219829441346, "compression_ratio": 1.738532110091743, "no_speech_prob": 0.0013669432373717427}, {"id": 339, "seek": 201656, "start": 2016.6399999999999, "end": 2023.44, "text": " we can just put them in a group by surrounding them in parentheses. So what we want to group here", "tokens": [50368, 321, 393, 445, 829, 552, 294, 257, 1594, 538, 11498, 552, 294, 34153, 13, 407, 437, 321, 528, 281, 1594, 510, 50708], "temperature": 0.0, "avg_logprob": -0.052152132501407544, "compression_ratio": 1.7545454545454546, "no_speech_prob": 0.003272866364568472}, {"id": 340, "seek": 201656, "start": 2023.44, "end": 2030.3999999999999, "text": " is our domain name. And the domain name is this part right here, this string of one or more word", "tokens": [50708, 307, 527, 9274, 1315, 13, 400, 264, 9274, 1315, 307, 341, 644, 558, 510, 11, 341, 6798, 295, 472, 420, 544, 1349, 51056], "temperature": 0.0, "avg_logprob": -0.052152132501407544, "compression_ratio": 1.7545454545454546, "no_speech_prob": 0.003272866364568472}, {"id": 341, "seek": 201656, "start": 2030.3999999999999, "end": 2035.36, "text": " characters. So I'm just going to wrap those in parentheses and create a group. And we've seen", "tokens": [51056, 4342, 13, 407, 286, 478, 445, 516, 281, 7019, 729, 294, 34153, 293, 1884, 257, 1594, 13, 400, 321, 600, 1612, 51304], "temperature": 0.0, "avg_logprob": -0.052152132501407544, "compression_ratio": 1.7545454545454546, "no_speech_prob": 0.003272866364568472}, {"id": 342, "seek": 201656, "start": 2035.36, "end": 2040.3999999999999, "text": " that before. And now we also want to put the top level domain in a group as well. That is the dot", "tokens": [51304, 300, 949, 13, 400, 586, 321, 611, 528, 281, 829, 264, 1192, 1496, 9274, 294, 257, 1594, 382, 731, 13, 663, 307, 264, 5893, 51556], "temperature": 0.0, "avg_logprob": -0.052152132501407544, "compression_ratio": 1.7545454545454546, "no_speech_prob": 0.003272866364568472}, {"id": 343, "seek": 204040, "start": 2040.72, "end": 2047.92, "text": " com or the dot gov. So we can put a parentheses around that dot, and then also around the ending", "tokens": [50380, 395, 420, 264, 5893, 352, 85, 13, 407, 321, 393, 829, 257, 34153, 926, 300, 5893, 11, 293, 550, 611, 926, 264, 8121, 50740], "temperature": 0.0, "avg_logprob": -0.07542014372976202, "compression_ratio": 1.7239819004524888, "no_speech_prob": 0.0106516657397151}, {"id": 344, "seek": 204040, "start": 2047.92, "end": 2052.4, "text": " there that is the string of one or more word characters. Okay, so we can see that we're", "tokens": [50740, 456, 300, 307, 264, 6798, 295, 472, 420, 544, 1349, 4342, 13, 1033, 11, 370, 321, 393, 536, 300, 321, 434, 50964], "temperature": 0.0, "avg_logprob": -0.07542014372976202, "compression_ratio": 1.7239819004524888, "no_speech_prob": 0.0106516657397151}, {"id": 345, "seek": 204040, "start": 2052.4, "end": 2057.84, "text": " still matching all of our URLs here. But now we have three different groups. So our first group", "tokens": [50964, 920, 14324, 439, 295, 527, 43267, 510, 13, 583, 586, 321, 362, 1045, 819, 3935, 13, 407, 527, 700, 1594, 51236], "temperature": 0.0, "avg_logprob": -0.07542014372976202, "compression_ratio": 1.7239819004524888, "no_speech_prob": 0.0106516657397151}, {"id": 346, "seek": 204040, "start": 2057.84, "end": 2065.12, "text": " is just that optional www dot. Our second group is the word characters that make up our domain name.", "tokens": [51236, 307, 445, 300, 17312, 12520, 5893, 13, 2621, 1150, 1594, 307, 264, 1349, 4342, 300, 652, 493, 527, 9274, 1315, 13, 51600], "temperature": 0.0, "avg_logprob": -0.07542014372976202, "compression_ratio": 1.7239819004524888, "no_speech_prob": 0.0106516657397151}, {"id": 347, "seek": 206512, "start": 2065.12, "end": 2071.2, "text": " And the third group is that top level domain. Now there's also an implicit group zero. And", "tokens": [50364, 400, 264, 2636, 1594, 307, 300, 1192, 1496, 9274, 13, 823, 456, 311, 611, 364, 26947, 1594, 4018, 13, 400, 50668], "temperature": 0.0, "avg_logprob": -0.0563298926865759, "compression_ratio": 1.8143939393939394, "no_speech_prob": 0.0023966592270880938}, {"id": 348, "seek": 206512, "start": 2071.2, "end": 2077.92, "text": " group zero is everything that we captured. So in this case, it's the entire URL. So now let's get", "tokens": [50668, 1594, 4018, 307, 1203, 300, 321, 11828, 13, 407, 294, 341, 1389, 11, 309, 311, 264, 2302, 12905, 13, 407, 586, 718, 311, 483, 51004], "temperature": 0.0, "avg_logprob": -0.0563298926865759, "compression_ratio": 1.8143939393939394, "no_speech_prob": 0.0023966592270880938}, {"id": 349, "seek": 206512, "start": 2077.92, "end": 2082.56, "text": " to the cool part about this. So let me show you what we can do now that we've captured these.", "tokens": [51004, 281, 264, 1627, 644, 466, 341, 13, 407, 718, 385, 855, 291, 437, 321, 393, 360, 586, 300, 321, 600, 11828, 613, 13, 51236], "temperature": 0.0, "avg_logprob": -0.0563298926865759, "compression_ratio": 1.8143939393939394, "no_speech_prob": 0.0023966592270880938}, {"id": 350, "seek": 206512, "start": 2082.56, "end": 2088.56, "text": " So we can use something called a back reference to reference our captured group. So for example,", "tokens": [51236, 407, 321, 393, 764, 746, 1219, 257, 646, 6408, 281, 6408, 527, 11828, 1594, 13, 407, 337, 1365, 11, 51536], "temperature": 0.0, "avg_logprob": -0.0563298926865759, "compression_ratio": 1.8143939393939394, "no_speech_prob": 0.0023966592270880938}, {"id": 351, "seek": 206512, "start": 2088.56, "end": 2094.72, "text": " here in Adam, we have the ability to replace our matches, we can see down here that we can replace.", "tokens": [51536, 510, 294, 7938, 11, 321, 362, 264, 3485, 281, 7406, 527, 10676, 11, 321, 393, 536, 760, 510, 300, 321, 393, 7406, 13, 51844], "temperature": 0.0, "avg_logprob": -0.0563298926865759, "compression_ratio": 1.8143939393939394, "no_speech_prob": 0.0023966592270880938}, {"id": 352, "seek": 209472, "start": 2094.72, "end": 2102.3199999999997, "text": " So let's replace all of our matches with just the literal text group one, and then a colon,", "tokens": [50364, 407, 718, 311, 7406, 439, 295, 527, 10676, 365, 445, 264, 20411, 2487, 1594, 472, 11, 293, 550, 257, 8255, 11, 50744], "temperature": 0.0, "avg_logprob": -0.0567556891110864, "compression_ratio": 1.861244019138756, "no_speech_prob": 0.0001634601503610611}, {"id": 353, "seek": 209472, "start": 2102.3199999999997, "end": 2109.2799999999997, "text": " and then a dollar sign one. Now this dollar sign one is a reference to our first group. Now sometimes", "tokens": [50744, 293, 550, 257, 7241, 1465, 472, 13, 823, 341, 7241, 1465, 472, 307, 257, 6408, 281, 527, 700, 1594, 13, 823, 2171, 51092], "temperature": 0.0, "avg_logprob": -0.0567556891110864, "compression_ratio": 1.861244019138756, "no_speech_prob": 0.0001634601503610611}, {"id": 354, "seek": 209472, "start": 2109.2799999999997, "end": 2116.08, "text": " this is a backslash. But for some reason in Adam, they use a dollar sign. So if I do a replace all", "tokens": [51092, 341, 307, 257, 646, 10418, 1299, 13, 583, 337, 512, 1778, 294, 7938, 11, 436, 764, 257, 7241, 1465, 13, 407, 498, 286, 360, 257, 7406, 439, 51432], "temperature": 0.0, "avg_logprob": -0.0567556891110864, "compression_ratio": 1.861244019138756, "no_speech_prob": 0.0001634601503610611}, {"id": 355, "seek": 209472, "start": 2116.08, "end": 2122.7999999999997, "text": " here, then we can see that it replaced our matches with this literal text group one. But then it", "tokens": [51432, 510, 11, 550, 321, 393, 536, 300, 309, 10772, 527, 10676, 365, 341, 20411, 2487, 1594, 472, 13, 583, 550, 309, 51768], "temperature": 0.0, "avg_logprob": -0.0567556891110864, "compression_ratio": 1.861244019138756, "no_speech_prob": 0.0001634601503610611}, {"id": 356, "seek": 212280, "start": 2122.8, "end": 2128.88, "text": " also replaced the dollar sign one with our first captured group. And the first capture group is that", "tokens": [50364, 611, 10772, 264, 7241, 1465, 472, 365, 527, 700, 11828, 1594, 13, 400, 264, 700, 7983, 1594, 307, 300, 50668], "temperature": 0.0, "avg_logprob": -0.06247406959533691, "compression_ratio": 1.8372093023255813, "no_speech_prob": 0.0012448097113519907}, {"id": 357, "seek": 212280, "start": 2128.88, "end": 2136.0800000000004, "text": " optional www dot. So for the ones for the domains that had that www, we can see that it shows up.", "tokens": [50668, 17312, 12520, 5893, 13, 407, 337, 264, 2306, 337, 264, 25514, 300, 632, 300, 12520, 11, 321, 393, 536, 300, 309, 3110, 493, 13, 51028], "temperature": 0.0, "avg_logprob": -0.06247406959533691, "compression_ratio": 1.8372093023255813, "no_speech_prob": 0.0012448097113519907}, {"id": 358, "seek": 212280, "start": 2136.0800000000004, "end": 2142.32, "text": " And for ones that didn't, it doesn't have anything. So let me undo this. And now let's replace our", "tokens": [51028, 400, 337, 2306, 300, 994, 380, 11, 309, 1177, 380, 362, 1340, 13, 407, 718, 385, 23779, 341, 13, 400, 586, 718, 311, 7406, 527, 51340], "temperature": 0.0, "avg_logprob": -0.06247406959533691, "compression_ratio": 1.8372093023255813, "no_speech_prob": 0.0012448097113519907}, {"id": 359, "seek": 212280, "start": 2142.32, "end": 2148.7200000000003, "text": " matches with the second group. And now the second group should be the domain name. So now if I do", "tokens": [51340, 10676, 365, 264, 1150, 1594, 13, 400, 586, 264, 1150, 1594, 820, 312, 264, 9274, 1315, 13, 407, 586, 498, 286, 360, 51660], "temperature": 0.0, "avg_logprob": -0.06247406959533691, "compression_ratio": 1.8372093023255813, "no_speech_prob": 0.0012448097113519907}, {"id": 360, "seek": 214872, "start": 2148.72, "end": 2155.68, "text": " a replace all now, then we can see that now it says group two is Google, CoreMS, YouTube,", "tokens": [50364, 257, 7406, 439, 586, 11, 550, 321, 393, 536, 300, 586, 309, 1619, 1594, 732, 307, 3329, 11, 14798, 10288, 11, 3088, 11, 50712], "temperature": 0.0, "avg_logprob": -0.09901906967163086, "compression_ratio": 1.6651785714285714, "no_speech_prob": 0.02096235565841198}, {"id": 361, "seek": 214872, "start": 2155.68, "end": 2162.9599999999996, "text": " and NASA. And if I undo that, and replace this with the group three, then the group three should", "tokens": [50712, 293, 12077, 13, 400, 498, 286, 23779, 300, 11, 293, 7406, 341, 365, 264, 1594, 1045, 11, 550, 264, 1594, 1045, 820, 51076], "temperature": 0.0, "avg_logprob": -0.09901906967163086, "compression_ratio": 1.6651785714285714, "no_speech_prob": 0.02096235565841198}, {"id": 362, "seek": 214872, "start": 2162.9599999999996, "end": 2169.2, "text": " give us our top level domain. So our group three is the dot com dot com dot gov things like that.", "tokens": [51076, 976, 505, 527, 1192, 1496, 9274, 13, 407, 527, 1594, 1045, 307, 264, 5893, 395, 5893, 395, 5893, 352, 85, 721, 411, 300, 13, 51388], "temperature": 0.0, "avg_logprob": -0.09901906967163086, "compression_ratio": 1.6651785714285714, "no_speech_prob": 0.02096235565841198}, {"id": 363, "seek": 214872, "start": 2169.2, "end": 2173.7599999999998, "text": " So let me undo this one more time. So now that we know how to use those back references,", "tokens": [51388, 407, 718, 385, 23779, 341, 472, 544, 565, 13, 407, 586, 300, 321, 458, 577, 281, 764, 729, 646, 15400, 11, 51616], "temperature": 0.0, "avg_logprob": -0.09901906967163086, "compression_ratio": 1.6651785714285714, "no_speech_prob": 0.02096235565841198}, {"id": 364, "seek": 217376, "start": 2173.76, "end": 2179.5200000000004, "text": " then we can actually take our regular URLs and clean them up like we meant to from before.", "tokens": [50364, 550, 321, 393, 767, 747, 527, 3890, 43267, 293, 2541, 552, 493, 411, 321, 4140, 281, 490, 949, 13, 50652], "temperature": 0.0, "avg_logprob": -0.06158501681159524, "compression_ratio": 1.6238532110091743, "no_speech_prob": 0.009411975741386414}, {"id": 365, "seek": 217376, "start": 2180.32, "end": 2187.6800000000003, "text": " So we could convert these to a cleaned up version without the HTTP or the www just by replacing", "tokens": [50692, 407, 321, 727, 7620, 613, 281, 257, 16146, 493, 3037, 1553, 264, 33283, 420, 264, 12520, 445, 538, 19139, 51060], "temperature": 0.0, "avg_logprob": -0.06158501681159524, "compression_ratio": 1.6238532110091743, "no_speech_prob": 0.009411975741386414}, {"id": 366, "seek": 217376, "start": 2187.6800000000003, "end": 2194.4, "text": " our matches with the domain name, which is group two, followed by the top level domain,", "tokens": [51060, 527, 10676, 365, 264, 9274, 1315, 11, 597, 307, 1594, 732, 11, 6263, 538, 264, 1192, 1496, 9274, 11, 51396], "temperature": 0.0, "avg_logprob": -0.06158501681159524, "compression_ratio": 1.6238532110091743, "no_speech_prob": 0.009411975741386414}, {"id": 367, "seek": 217376, "start": 2194.4, "end": 2199.84, "text": " which is group three. So now if I replace all of our selections with those two,", "tokens": [51396, 597, 307, 1594, 1045, 13, 407, 586, 498, 286, 7406, 439, 295, 527, 47829, 365, 729, 732, 11, 51668], "temperature": 0.0, "avg_logprob": -0.06158501681159524, "compression_ratio": 1.6238532110091743, "no_speech_prob": 0.009411975741386414}, {"id": 368, "seek": 219984, "start": 2199.84, "end": 2204.88, "text": " then we can see that replaced all of our URLs with just the domain name and the top level domain.", "tokens": [50364, 550, 321, 393, 536, 300, 10772, 439, 295, 527, 43267, 365, 445, 264, 9274, 1315, 293, 264, 1192, 1496, 9274, 13, 50616], "temperature": 0.0, "avg_logprob": -0.04144302766714523, "compression_ratio": 1.8037974683544304, "no_speech_prob": 0.00669243885204196}, {"id": 369, "seek": 219984, "start": 2204.88, "end": 2209.76, "text": " So you can imagine if you had a lot of information like this that you needed to clean up or modify", "tokens": [50616, 407, 291, 393, 3811, 498, 291, 632, 257, 688, 295, 1589, 411, 341, 300, 291, 2978, 281, 2541, 493, 420, 16927, 50860], "temperature": 0.0, "avg_logprob": -0.04144302766714523, "compression_ratio": 1.8037974683544304, "no_speech_prob": 0.00669243885204196}, {"id": 370, "seek": 219984, "start": 2209.76, "end": 2214.8, "text": " in some way, then knowing how to match these groups with regular expressions could save you", "tokens": [50860, 294, 512, 636, 11, 550, 5276, 577, 281, 2995, 613, 3935, 365, 3890, 15277, 727, 3155, 291, 51112], "temperature": 0.0, "avg_logprob": -0.04144302766714523, "compression_ratio": 1.8037974683544304, "no_speech_prob": 0.00669243885204196}, {"id": 371, "seek": 219984, "start": 2214.8, "end": 2219.1200000000003, "text": " a ton of time with doing things like this. Okay, so I think that's going to do it for this video.", "tokens": [51112, 257, 2952, 295, 565, 365, 884, 721, 411, 341, 13, 1033, 11, 370, 286, 519, 300, 311, 516, 281, 360, 309, 337, 341, 960, 13, 51328], "temperature": 0.0, "avg_logprob": -0.04144302766714523, "compression_ratio": 1.8037974683544304, "no_speech_prob": 0.00669243885204196}, {"id": 372, "seek": 219984, "start": 2219.1200000000003, "end": 2223.36, "text": " Now there's a lot of advanced features that we could go over with regular expressions as well.", "tokens": [51328, 823, 456, 311, 257, 688, 295, 7339, 4122, 300, 321, 727, 352, 670, 365, 3890, 15277, 382, 731, 13, 51540], "temperature": 0.0, "avg_logprob": -0.04144302766714523, "compression_ratio": 1.8037974683544304, "no_speech_prob": 0.00669243885204196}, {"id": 373, "seek": 219984, "start": 2223.36, "end": 2227.92, "text": " So if anyone is interested in learning more, then I could put together an advanced video", "tokens": [51540, 407, 498, 2878, 307, 3102, 294, 2539, 544, 11, 550, 286, 727, 829, 1214, 364, 7339, 960, 51768], "temperature": 0.0, "avg_logprob": -0.04144302766714523, "compression_ratio": 1.8037974683544304, "no_speech_prob": 0.00669243885204196}, {"id": 374, "seek": 222792, "start": 2227.92, "end": 2232.4, "text": " covering those topics in the near future. But hopefully now you feel comfortable with being", "tokens": [50364, 10322, 729, 8378, 294, 264, 2651, 2027, 13, 583, 4696, 586, 291, 841, 4619, 365, 885, 50588], "temperature": 0.0, "avg_logprob": -0.05820706524426424, "compression_ratio": 1.8297872340425532, "no_speech_prob": 0.039631519466638565}, {"id": 375, "seek": 222792, "start": 2232.4, "end": 2237.28, "text": " able to read and write these regular expressions that we went over in this video. But if anyone", "tokens": [50588, 1075, 281, 1401, 293, 2464, 613, 3890, 15277, 300, 321, 1437, 670, 294, 341, 960, 13, 583, 498, 2878, 50832], "temperature": 0.0, "avg_logprob": -0.05820706524426424, "compression_ratio": 1.8297872340425532, "no_speech_prob": 0.039631519466638565}, {"id": 376, "seek": 222792, "start": 2237.28, "end": 2241.36, "text": " does have any questions about what we covered in this video, then feel free to ask in the comment", "tokens": [50832, 775, 362, 604, 1651, 466, 437, 321, 5343, 294, 341, 960, 11, 550, 841, 1737, 281, 1029, 294, 264, 2871, 51036], "temperature": 0.0, "avg_logprob": -0.05820706524426424, "compression_ratio": 1.8297872340425532, "no_speech_prob": 0.039631519466638565}, {"id": 377, "seek": 222792, "start": 2241.36, "end": 2245.52, "text": " section below and I'll do my best to answer those. And if you enjoy these tutorials and would like to", "tokens": [51036, 3541, 2507, 293, 286, 603, 360, 452, 1151, 281, 1867, 729, 13, 400, 498, 291, 2103, 613, 17616, 293, 576, 411, 281, 51244], "temperature": 0.0, "avg_logprob": -0.05820706524426424, "compression_ratio": 1.8297872340425532, "no_speech_prob": 0.039631519466638565}, {"id": 378, "seek": 222792, "start": 2245.52, "end": 2249.6, "text": " support them, then there are several ways you can do that. The easiest ways to simply like the video", "tokens": [51244, 1406, 552, 11, 550, 456, 366, 2940, 2098, 291, 393, 360, 300, 13, 440, 12889, 2098, 281, 2935, 411, 264, 960, 51448], "temperature": 0.0, "avg_logprob": -0.05820706524426424, "compression_ratio": 1.8297872340425532, "no_speech_prob": 0.039631519466638565}, {"id": 379, "seek": 222792, "start": 2249.6, "end": 2253.44, "text": " and give it a thumbs up. And also it's a huge help to share these videos with anyone who you think", "tokens": [51448, 293, 976, 309, 257, 8838, 493, 13, 400, 611, 309, 311, 257, 2603, 854, 281, 2073, 613, 2145, 365, 2878, 567, 291, 519, 51640], "temperature": 0.0, "avg_logprob": -0.05820706524426424, "compression_ratio": 1.8297872340425532, "no_speech_prob": 0.039631519466638565}, {"id": 380, "seek": 222792, "start": 2253.44, "end": 2257.28, "text": " would find them useful. And if you have the means you can contribute your Patreon and there's a link", "tokens": [51640, 576, 915, 552, 4420, 13, 400, 498, 291, 362, 264, 1355, 291, 393, 10586, 428, 15692, 293, 456, 311, 257, 2113, 51832], "temperature": 0.0, "avg_logprob": -0.05820706524426424, "compression_ratio": 1.8297872340425532, "no_speech_prob": 0.039631519466638565}, {"id": 381, "seek": 225728, "start": 2257.28, "end": 2261.28, "text": " to that page in the description section below. Be sure to subscribe for future videos and thank", "tokens": [50364, 281, 300, 3028, 294, 264, 3855, 3541, 2507, 13, 879, 988, 281, 3022, 337, 2027, 2145, 293, 1309, 50564], "temperature": 0.0, "avg_logprob": -0.14305857094851407, "compression_ratio": 1.1585365853658536, "no_speech_prob": 0.18436619639396667}, {"id": 382, "seek": 226128, "start": 2261.28, "end": 2265.28, "text": " you all for watching.", "tokens": [50364, 291, 439, 337, 1976, 13, 50564], "temperature": 0.0, "avg_logprob": -0.45304033160209656, "compression_ratio": 0.7241379310344828, "no_speech_prob": 0.09346986562013626}], "language": "en"}