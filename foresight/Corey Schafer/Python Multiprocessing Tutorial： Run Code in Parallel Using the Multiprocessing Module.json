{"text": " Hey there, how's it going everybody? In this video, we're going to be learning how to run code in parallel using the multi-processing module. Now, if you'd also like to learn about running code concurrently using the threading module, then I did recently put out a video on that as well, so I'll be sure to leave a link to that video in the description section below. Now, if you don't know the difference between threading and multi-processing, then you should have a grasp on the difference between those once we're finished. Now, I would like to mention that we do have a sponsor for this video, and that is Brilliant.org. So, I really want to thank Brilliant for sponsoring the video, and it would be great if you all could go and check them out using the link in the description section below and support the sponsors, and I'll talk more about their services in just a bit. So, with that said, let's go ahead and get started. Okay, so first, why would we want to use multi-processing? So, basically, we want to use multi-processing whenever it's going to significantly speed up our program. Now, the speed up comes from different tasks running in parallel. Now, in this video, we're going to start off with a basic example of where we learn how to run some simple sleep methods in parallel, but then we'll finish up with a real-world example where we do some image processing on a directory of high-resolution images. I want to show that real-world example because, personally, when I watch tutorials that only show how it works on basic examples, then I always feel like I don't really walk away with any useful knowledge. So, we'll use the sleep method to get a good idea of how to use multi-processing, and then we'll be sure to go over the more complicated real-world example of image processing. So, let's go ahead and get started. So, I have a starting script open here, and if you'd like to follow along, then I'll be sure to have a link to this code in the description section below. And, like I said, we'll start with a very simple example to see how this works and then build up with more realistic examples. So, let me go over the script that I currently have open here. So, first, I'm importing time, and I'm just using time to measure how long it takes the script to run. That's also what this is here. This is just a start time for our script, and then we have a function here called doSomething, and all this is doing is printing that we are sleeping for one second, then we actually sleep a second using that time module, and then we are printing out that we are done sleeping, and then we are actually executing that function. So, it should do all of this, and then we are calculating the finish time and printing out that our script is finished. Okay, so, if I run the code that we have right now, we can see that it said that it was sleeping for one second, done sleeping, and that we finished in about one second. And that sounds about right since we were running our doSomething function one time, and that sleeps for one second. And if we were to run that function twice, then our program will likely take two seconds. So, let's go ahead and see that. So, right below doSomething here, I'm going to run this again, and if I run that, then we can see that now that it printed out that it was sleeping for one second twice, and that it took about two seconds. So, we can see that each time we run this doSomething function, it's adding about one second to our script. So, our script is just waiting around sleeping for a second, and once that's done, it moves on to run that next function, and sits around waiting for another second. And then at that point, we're basically done, and our script finishes. Now, I created a quick graphic to try to represent what this looks like. So, let me bring that up here in my browser real quick. And this is actually the second graphic. We'll go over that in just a second. Okay. So, this is basically what it looks like for our script to be executed right now. So, we are running a function. In this case, it's that doSomething function. And then this is just coming up here and waiting and executing for one second. And once that one second is over, then we come back and we execute this another function, and it's that same function again. So, then it comes up here and executes this sleep for one second again. And when that one second is done, then we can come down here and print that our script is done. And running everything in order like this is called running it synchronously. Now, if you have some tasks that don't need to be run synchronously, then we can use the multi-processing module to split these tasks up onto other CPUs and run them at the same time. Now, if you watched my last video on threading, then I mentioned that tasks were going to either be IO bound or CPU bound. So, CPU bound tasks are things that are crunching a lot of numbers and using the CPU. And IO bound tasks are things that are waiting for input and output operations to be completed. And they're not really using the CPU all that much. So, some other examples of IO bound tasks include file system operations and network operations like downloading stuff online. Now, in that threading video, I mentioned that we wouldn't get much of a speed up when using threading on CPU bound tasks because those threads are still only running one process. But with multi-processing, we're going to actually spread the work out onto multiple processors on our machine and run those tasks at the same time. So, we can use this with both IO bound tasks and CPU bound tasks. So, it really just depends on what we're doing and your computer's hardware that will determine if it's better to use threading or multi-processing. But with that said, let's look at what it looks like to run something in parallel using multi-processing. And I've got another graphic put together of what this would look like. So, in this example, we can see that we still have our two tasks. But now we're just breaking these up onto two different processes. And unlike with threading, where we were running these concurrently, and I said that running concurrently doesn't necessarily mean that they're running at the same time, with multi-processes, these actually are running at the same time on different processes. So, we can see here that once we kick off our multiple processes and we spread out our tasks onto those processes, then we can just run each of these functions one time. And then both of these will sleep for a second. And then once they're both done, we'll come down here and print that they're done. Okay, so now that we've talked about multi-processing and what it looks like to run code in parallel, now let's see how to actually do this with our current script. So, first, let's import the multi-processing module. So, this is in the standard library, so we don't need to install anything. So, up here at the top, I'm just going to say import multi-processing. Now, I'm going to show an older way of how to do multi-processing first so that we can get a good idea of what's going on. But if it seems confusing at first, then definitely stick around, because I'm also going to show some newer ways of doing multi-processing using pools that allow us to add this to our program with just a few lines of code. Okay, so first, instead of running the do something function twice in a row like we have here, let's instead turn both of these into processes. So, to do this, I'm just going to create two processes. And for both of these, we can just say p1 is equal to multi-processing.process. And now, we are going to pass in a target. And the target is the function that we want to run. So, if I want to run this do something function, then I can pass in do something. Now, we want to pass in the actual function and not the return value of the function. So, we don't want to execute the function with parentheses like this. We just want to pass it in with no parentheses. Okay, so now that will be one process. And now, if I do a p2 is equal to multi-processing.process with a target of do something, then that will be our second process. Okay, so at this point, we've created two process objects, but we're not actually running that code. So, if I run this right now, then we can see that it says that it finished immediately, but nothing from our function printed out. So, our functions didn't actually run. So, in order to get our processes to run, we need to use the start method on each one. So, down here below our p2, I'm going to say p1.start to start that first process, and p2.start to start that second process. Okay, so now that will actually run our processes, but it might not do exactly what we think it'll do. So, if we run this, then we can see that now it runs the functions, but it said that our script was finished in zero seconds, and then it said that we were sleeping for one second twice because we ran that function twice, and then it said that it was done sleeping. Now, our entire script didn't actually complete in zero seconds. It actually took around one second, but the reason that it says that it completed in zero seconds is because after it started both of these processes here, while those processes were sleeping, our script continued running and came down here and calculated out the finish time and printed out that our script was finished in zero seconds, and then it kicked off these processes. Now, actually, I think that I just said that it started sleeping first before it printed out that we were finished, but these processes take a little bit longer to spin up than threads, so it actually didn't even start our processes first. It actually came down here and printed that we were finished before these sleep statements even first got executed. So, it printed that before it said we were sleeping, and then after a second we were done. So, basically what this is doing is it's kicking off our processes, but then it's going down here and running the rest of our script before our process is finished. Now, what if we wanted our processes to finish before we calculated the finish time and before we printed out that our script is finished? So, in order to do this, we can use the join method. So, to do this right below start, I'm going to say p1.join and p2.join. So, when we run that join method, it means that the process will finish before moving on in the script. So, now, if we run this, then we can see that both processes started at almost the same time, and then they both printed that they were done sleeping after one second, and then our script continued on to print that our script had finished in about one second. Now, if using multi-processing seems a bit complicated right now, then definitely stick around until the end of the video, because we're going to see an easier way of how to do what we're doing here, but I think it's important to understand what this is doing so far, even if we use other methods where we don't actually manually call these start methods and join methods. Okay, so, right now, we're not really getting that big of a speedup. Now, so, our code ran in two seconds before, and now it's running in one second, but that's because our function doesn't take too long, and we're only running it twice, but what if we wanted to run our function 10 times? Well, if we were to run our code synchronously, then we can take a guess that it would take 10 seconds since one would have to finish before the other, and we'd be running 10 in a row. But if we ran this with multiple processes, then it should be significantly faster. So, let's see an example of this. Now, instead of manually creating 10 different processes, let's instead create and start these in a loop. So, to do this, I can come up here, and I'm going to copy this whole part here, and now I'm just going to overwrite all the code that we have here so far, and I'm going to say 4 underscore in range of 10, and we'll say p is equal to multi-processing dot process with a target set to the do something function. And now, let's also start that process here within our loop. Now, if you're unfamiliar with the underscore in Python, basically, that's just a throwaway variable name. It's just saying that we're not actually using the integer from this range in the loop. So, we just have something as a throwaway variable there. So, we're starting all these processes here within our loop, but we can't do a p dot join within the loop, because it would run join on the process before looping through and creating and starting the next process in the loop. So, it would basically be the same as running it synchronously. So, we need a way that we can start all of these processes in one loop, and then loop through those processes again, and run the join method on them so that they all finish before the end of our script. So, to do this, let's just append each process to a list. So, above our for loop here, I'm just going to create a list called processes and set that to an empty list. And then below p dot start, I'm going to say processes dot append, and I will append each process to our processes list. And now, here below our for loop, I'm going to say for process in processes, let's do a process dot join. Okay, so just one more time here. We are looping over a range of 10. So, we're going to do this loop 10 times here. And each time through the loop, we are creating a new process with this target of do something. And we are starting that process. And then we are appending that process to a processes list. So, then after that loop is complete, and all of our processes have been started, we're coming through and looping over all those processes, and we are joining them. And again, when we join a process, when we run the join method, it means that it is going to wait until that finishes before continuing on to the rest of the script. So, it'll finish before it comes down here and calculates the finish time and prints that our script is finished. So, we're running this do something function 10 times, and it sleeps for one second every time. But since we're using multiple processes, it'll just run all of these in parallel at the same time. So, instead of it taking 10 seconds, let's save this and run this and see how long it actually takes. So, we can see that even running the function 10 times, we're still finishing this in about one second. Now, that might seem a little strange, because I don't actually have 10 cores on this machine. But your computer has ways of switching off between cores when one of them isn't too busy. So, even though we had more processes than we do cores, it's still finished in about a second. So, that's pretty good. Okay, so now let's look at how we can pass in arguments into our function. So, right now, we're running a function that doesn't accept any arguments. But let's add a couple of arguments real quick. So, right now, we're just sleeping for one second. So, let's add an argument that specifies how long to sleep. So, up here, we will accept an argument. And I'm just going to pass in an argument of seconds. And let's also change that we are going to sleep for that number of seconds. And let me also put a parentheses s there as well. Now, this needs to be an f string, since we're now using this variable here within our string. Now, I want to sleep for that number of seconds. Okay, so with that small change, our do something function now accepts an argument of seconds. And then it'll print out that we're sleeping for that number of seconds. And then it will actually sleep for that number of seconds. So, let's pass in seconds as an argument to this function. And we need to pass that in as a list of arguments to our process. So, I'll say, down here, where we are saying that our target is that do something function, we can also pass in an argument of arcs. And we'll pass that in as a list of arguments. So, I'll do 1.5. So, now, instead of sleeping for one second for 10 different times, now it's going to sleep for 1.5 seconds for 10 different times. Now, unlike with threads, in order to pass arguments to a multi processing process, the arguments must be able to be serialized using pickle. Now, if you don't know what that means, basically serializing something with pickle means that we're converting Python objects into a format that can be deconstructed and reconstructed in another Python script. So, now we should expect our function to take 1.5 seconds instead. So, if I save this and run it, then we can see that now our script is finishing in about 1.5 seconds. Okay, so, I said before that I was going to show you the older way of doing multi processing, and then I'd show you what I believe is a faster, easier way of doing this. And I still wanted to show you the manual way of creating these processes, because I think this can still be useful depending on what you're doing. And also, I think it's better to learn this manual first to understand a bit better what's going on in the background. But in Python 3.2, they added something called a process pull executor. And in a lot of cases, this will be an easier and more efficient way to run multiple processes. And it also allows us to easily switch over to using multiple threads instead of processes as well, depending on the problem that we're trying to solve. So, let's replace what we currently have and instead use this process pull executor. Now, this actually isn't in the multi processing module. It's in the concurrent futures module instead. So, up here at the top, let's instead import concurrent futures. And I actually don't think I need multi processing anymore. So, I'm just going to say import concurrent futures. Now, I'm going to leave everything else that I have here for now, so that we can see the difference between these. Now, when we use this process pull executor, it's usually best to use this with a context manager. So, above our processes list here, I'm going to do the same thing that we already have. But just with our concurrent futures module instead. So, I'm going to say with concurrent dot futures dot process pull executor, and make sure you get those capitalizations in the right place. And then, we will say, whoops, we'll say as executor. And now, within our or with our executor here, there are a couple of different methods that we can use. Now, if we want to execute the function once at a time, then we can use the submit method. So, the submit method schedules a function to be executed and returns a future object. So, let's add this in and then I'll explain this a bit more. So, I'm going to say f one is equal to executor dot submit. And I will submit that do something function. And let's also pass in an argument of one. So, again, the submit method schedules a function to be executed and returns a future object. So, a future object basically encapsulates the execution of our function and allows us to check on it after it's been scheduled. So, we can check that it's running or if it's done, and also check the result. So, if we grab the result, then it'll give us the return value of the function. Now, right now, we're just printing out values. But let me add in a return value so that we can grab that. So, instead of just printing that we are done sleeping up here, instead, I'm going to return that string. So, I'm going to say return done sleeping instead of just printing that out. Okay, so now that's returning that string. So, if we still want to print that out, then we'll need to print that return value. So, let's grab that by using the result method on that future object. So, I'm going to say print and we will print out F1 dot result. Now, if we run the return method, then this will wait until the function completes. Okay, so let's comment out what we had before and run our code. So, I'm going to comment out this processes list here and our previous starts and joins. And instead, we're just going to use this process pull executor. Okay, so if I run this, then we can see that that still works. And that's a lot less code than we had down here that's commented out. But we're still not running this multiple times yet like we were down here. So, if we wanted to run this multiple times, then we could just run submit multiple times. So, I could say let me go above our result here. I'm going to add in another execution of this do something function. So, I'm going to call this F2 is equal to executor dot submit do something with one second. And then, I will also print out the F2 result. So, if I run this, then we can see that it's the same thing. It kicks both of these off at the same time. And we finished in about one second. And if we wanted to run this 10 times like we did below, then we likely wouldn't want to run submit 10 different times. So, we could use a loop like we did before. So, instead of running one at a time, I'm going to use a loop. And we could use a regular loop like we did below. But I'm going to go ahead and use a list comprehension to create these instead. So, we could say, I'm just going to copy this executor dot submit part. And I'm just going to overwrite all of this other stuff right now. And I'm going to say results are equal to, then I will start a list comprehension here and say executor dot submit do something for one second for underscore range 10. Now, if you're not familiar with list comprehensions like we have here, then I do have a separate video on that as well. So, I'll put a link to that in the description section below if you've never seen this type of code before. And if you're not comfortable using list comprehensions, then you can always use a regular loop like we did down here below. Okay, so now we've created a list comprehension that's running our submit method with this do something function, and an argument of one second, 10 different times. Now, in order to get these results, we can actually use another function from the concurrent futures module called as completed. And this will give us an iterator that we can loop over that will yield the results of our processes as they're completed. So, I think this is really useful. And it's one of the good things about using these processing pull executors. So to use this, we can say just for f in concurrent, oops, sorry about my typing there, concurrent dot futures dot as underscore completed. And now we want to pass in this list of results, which is a list of futures objects. And now within this list, let's print out f dot result. So if we run this, oops, and it looks like I have some invalid syntax here. Oh, I forgot to say, I should have said for underscore in range of 10. Some of you probably saw that as I was typing it out. Okay, so now if I run this, then we can see that we slept for one second. Now it's still ran 10 different times. But if we scroll down to the bottom, then we can see how much time it took. So we can see here that it actually took three seconds this time. Now, the reason behind that is that our poll may have made a decision based on our hardware, not to a lot as many processes. So that's why it might take longer. But even though it took longer in our simple little example here, I still you like to use these processing pull executors most of the time, because I trust it to a lot the processes a lot more than I trust myself. So I passed that off to the process pull executor to do and to make that decision for me. Now to prove that these results are actually coming in as they're completed, let me actually pass in a different range of seconds for our processes to sleep. And those should print out in the order that they complete. So I'm going to create a list of seconds to sleep. And I'll make that sleep from five seconds all the way down to one second. So above our results here, I'm going to make a list of seconds. And I will just make a list of five, four, three, two, one. And I'll also print out the seconds in the return statement of our do something function, so that we can tell which ones are finishing and in what order. So again, I'm going to make this an f string by putting an f right there. And I'm just going to pass that in to so we can see which seconds is actually done sleeping. So now, let me also change our list comprehension here, so that we are running our do something function with each of these seconds in this seconds list. So I'm going to say executor dot submit, do something. And I want to do that for whatever second. So four sec in our seconds list. Okay, so now if I run this, then we can see that it actually started our five second process first, and then our four, then our three, then our two, then our one. But it finished these in the order that they came in. And the lower number seconds are towards the top. Now I'm not sure why the one second process took so much longer than the two and the three second processes. I guess it just got hung up on something. But the four and the five second processes were down here at the bottom. Actually, let me run that one more time. And Oh, okay, so that's why it's because our one second process was down here. And since I have four cores on my machine, it started these four processes here first. And it didn't start the one second process until this two was finished right here. So that's why that took a little bit longer. But since we are using this as completed method, this actually did print our result out our results in the order that they completed. So this two second one finished first, and then this three, then one, then four, then five. And we can see here down at the bottom that our script is still finishing in about five seconds. So that's pretty good. Okay, so with this submit method right now, it's submitting each function once at a time. But in order to run submit on an entire list, then we need to do a loop or a comprehension like we did here. But if you're familiar with the built in map method, then there is actually something similar that we can do with processes, where we can use the map method to run our function over a list of values. So if you're familiar with the built in map method, then this is very similar, except it uses processes instead. So it runs the function every time or with every item of the interval that we pass in. So let's say that I want to map our function to our list of seconds. So to do this, I am just going to overwrite our list comprehension here. And I'm not going to be using this as completed anymore either. So I'm also going to get rid of that. So now in order to do this, we can simply say executor dot map. And now we will map our do something function. And we will map our list of seconds. So again, what this map method does, if you're not familiar with the built in Python map method and what it does, basically map will run this do something function with every item of this list with every item of whatever iterable you pass in. So that is what map does. Now, when we were using the submit method, it returned future objects. But when we use map, it just returns the results. Now, it is going to run those processes in parallel. But instead of returning the results as they're completed, like we saw before, map is going to return the results in the in the order that they were started. So to loop over these results, we can simply just do a for loop. So I'm going to say for result in results. And then I will just print out our result, whoop, make sure that I'm printing out the result and not that results list. Okay, so now if I run this, then we can see that all of our processes kicked off at pretty much the same time, except for that one second when it looked like it got outside of the pool like it did before. But they actually didn't all complete at the same time. But when you loop over your results using map like we did here, then it returns the results in the order that they were started. So since we slept for five seconds first, then we waited for that one to finish before printing out the other results. But it still didn't slow us down, we can see that our entire script still finished in five seconds here. But it looks like our five seconds was done sleeping first, and then our four, then three, then two, then one, it actually didn't finish in that order. But it printed out in that order, because again, it prints out the ones that in the order that they were started and not in the order that they were finished. Now another thing to point out here is that if our function raises an exception, it won't actually raise that exception while running the process. The exception will be raised when its value is retrieved from the results iterator. So if you need to handle any exceptions, then you can do that here within the iterator if you'd like. And if you'd like to learn more about handling exceptions, then I do have a more in depth video. If you'd like to learn more about that. So I'll be sure to leave a link to that video in the description section below for anyone who's interested. Now even if we don't grab our results within the context manager, it's still going to automatically join all of those processes and let them finish after the context manager ends. So if I comment out where we are printing out our results, let me also get rid of our old way of doing this here so that we can see our code below our processes here. So now I'm commenting out where we're printing those results. And if I run this, then we can see that it still didn't move on to our finish time here until it returned the results from our processes. So anytime you're using a context manager like this, it's going to automatically join those processes. And they're going to complete before that context manager finishes. Okay, so now that we've looked at a basic example of using sleep, now let's take a look at a more real world example of where using multiple processes would be useful. So I've got another script open here where I'm not using multiple processes at the moment. So let me open this up and let's go over what this is doing. And again, I'll have a link to this code in the description section below for anyone who wants to follow along. So in our last video on threading, I showed how we could use threads to go out and download some high resolution photos from unsplash. Now if you don't know what unsplash is, it's a website that has some really nice photos available for anyone to use. Now downloading images is something that is IO bound since we're waiting for the images to download. So for this multi processing example, we want something that is more CPU bound. So in this script, I'm doing some image processing on the images that we downloaded in the threading video. And I'll have these images available in the description section below as well, in case anyone didn't follow along with that threading video. So let me go over the script to show you how someone might do this image processing normally. So I'm using the pillow library here, which if you don't know what the pillow library is, it's a image library for Python that makes it makes image processing easy. I also have a video on pillow if you'd like to learn more about image processing. But I have a list here of image names. And these are all of the images or all of the image names that we downloaded in the last video using threading. So I am starting a counter here so that we can measure how long our script took. I am setting a size of 1200 pixels. And that is what we are going to resize these high resolution photos to. Okay, and now what I am doing is I am looping over all of those image names. So with one image at a time, I am opening that image. And then I am running running this image filter. And we're just doing a Gaussian blur on that image. And then I am doing an image thumbnail and setting it to this 1200 pixel size. And then we are saving that image into a processed folder with that the image name. And then we are printing out that that image was processed. Now I do have a processed folder here within my directory. If you don't, you'll probably get an error. And I also have all of these photos here within my directory. If you don't have those, then you're also going to get an error. So you want to have all of those photos in order for this code to work. Then after that's done, I am printing out the time that it took. And then I am printing out that our script is finished. Okay, so this is processing 15 high resolution photos. So if I run this now, then let's see how long this takes. So I'm running this, we can see that it is just going through synchronously and running these one at a time. And then we will print out the final time once this is done. Now, I think that my processing here, I think that this still might be more IO bound than CPU bound. Because opening the image and saving this here is going to be more of an IO bound thing. I don't know how much is actually getting CPU bound here using this filter. But if we were doing some more computations, then this would be more CPU bound. And we can even test this in a second. But anyways, we can see that our script finished in 22 seconds. So that's how long it took to do this image processing here on 15 of these high resolution photos. Now, when we're processing a lot of items like this, this is actually a great candidate to use multi processing, because this can be one of those CPU bound operations that's spending a lot of time processing each image. And it's not moving on to the next image until the previous one finishes. And if we use multiple processes, then it can actually go ahead and move on to the to process another image while the previous one is finishing. And even if this is IO bound, unlike threading, CP or multi processing is actually going to be beneficial for IO bound processes as well. So now let's see how we can change this code so that it's using multiple processes instead. So first, let's think about what we're doing here. So we're looping over our list of images and processing each one at a time. So if we remember from our previous examples, then this would probably be a good candidate for the processing pull map method, where we can pass in a function and a list and have that function run with every value in that list. But first we'll have to create a function that will process a single image. So to do that, if we think about this, we can basically just replace our for loop, because our for loop is processing a single image from our images list. So instead, we can just change this one line here and just turn this into a process image function. And we will just accept this image name as the argument. And now that we have that function, that process is a single image, then we can create a process pull and map our list of images using that function. So first let's import the concurrent futures module so that we can use that. So up here at the top, I'm going to import concurrent dot futures. And now down here below our function, we can do this by saying with concurrent dot futures dot process pull executor as executor. And now within our context manager, we can just say executor dot map. And we want to map this process image function. And we want to pass in the list of these image names. Now, just in case that was confusing, let me go over exactly what we did again, in order to change our previous script in order to use multiprocessing. So we were using a for loop here. But instead, we changed this to a function that processes one image at a time. And now we're using our processing pull executor like we saw before within a context manager, we're running executor dot map. And we are passing in that function that we created. And then we're passing in our list of image names. And again, what map does is it runs this process image function with every item in this image names list. And just with those small changes, this will actually use multiple processes to process those images and run these in parallel, instead of running these synchronously. So if I run this, whoops, and I made another mistake here, you guys probably saw that one also. But I needed to put a colon there. Okay, hopefully that's my only mistake. Okay, so if I run this, then we can see now these are processing faster. And I'm going to open up my activity monitor here, and scroll down to the P's. And we can see here that we have multiple Python processes running here. So we can actually see these in our activity monitor. And now that this script is finished, then we can see most of those go away. The only one that's still here is probably just one that is open here in my sublime text. So we could see all of those kick off in our activity monitor. And we could see that they were all returning faster. That's because they were running in parallel. And now instead of taking 22 seconds, like it did before, now it finished in seven seconds, so more than a third of the time. So that's a pretty significant speed up there. And this would be even more significant if we were processing even more images. So the speed ups can be pretty drastic, depending on what you're doing. Now, again, you might want to experiment when using multiple threads or processes for specific tasks, depending on what you're doing and what kind of hardware you're running. One might be drastically different than the other. And it's hard to tell exactly what you should be using without some benchmarks. But again, a good rule of thumb is that you want to use threads for things that are IO bound. And you'll want to use processes for things that are CPU bound. But you may actually see significant speed ups using threads with this example, since this is reading and writing to disk, which is an IO bound operation. Now, one nice thing about using the concurrent futures library like this is that switching between threads and processes is just as simple as changing this process pull executor, and just using a thread pull executor instead. And you can do that vice versa to change from threads to processes with your programs. So if I change this to a thread pull executor, let me see if I'm right about a lot of this being IO bound here. If I run this, then we'll see how long this takes us to finish this script using threads instead of multiple processes. And that was actually faster. So that was 7.2 seconds. So even though I tried to put together an example that was doing a lot of processing on the CPU, it looks like most of this is IO bound from opening and saving these files and not CPU bound, but from doing some image processing here with these Gaussian blurs and these resizes and things like that. But that's okay. That's why you want to always experiment. And, you know, if you try it with a process pulled, and maybe try it once with threads and see if you get a better execution. And also, whenever you add in even more items, maybe processes will start to become more performant than threads. So it really just depends on what you're doing. Now, before we finish up here, I'd like to mention the sponsor of this video. And that is brilliant.org. So when we're talking about threading and multi processing, these topics are especially useful in the field of data science. And the data science field is growing at a very rapid pace. If you'd like to learn more about programming and data science, then I would definitely recommend checking out brilliant.org. So brilliant is a problem solving website that helps you understand underlying concepts by actively working through guided lessons. And they've recently added some brand new interactive content that makes solving puzzles and challenges even more fun and hands on. And if you'd like to learn more about data science and programming with Python, then I would recommend checking out their new probability course that covers everything from the basics to real world applications and also fun things like casino games. They even use Python in their statistics courses and will quiz you on how to correctly analyze the data within the language. So their guided lessons will challenge you, but you also have the ability to get hints or even solutions if you need them. It's really tailored towards understanding the material. They even have a coding environment built into their website so that you can run code directly in the browser. And that is a great compliment to watching my tutorials, because you can apply what you've learned in their active problem solving environment. And that helps to solidify that knowledge. So to support my channel and learn more about brilliant, you can go to brilliant.org forward slash CMS to sign up for free. And also the first 200 people that go to that link will get 20% off the annual premium subscription. And you can find that link in the description section below. And again, that is brilliant.org forward slash CMS. Okay, so I think that's going to do it for this video. I hope you feel like you got a good idea of how to use the multiprocessing module and how we can use these to speed up our scripts. Now, I hope you also feel like you got a good overview of threads and processes. And when you should use those. But like I said, if you're unsure, then there's no hurt in simply trying both on a subset of your data to see what gives you the most speed up. Now, there are some more advanced topics that we could cover in future videos, such as race conditions, locks and things like that. But we'll save that for a future video if anyone is interested. But if anyone has any questions about what we covered in this video, then feel free to ask in the comment section below and I'll do my best to answer those. And if you enjoy these tutorials and would like to support them, then there are several ways you can do that. The easiest way is to simply like the video and give it a thumbs up. And also it's a huge help to share these videos with anyone who you think would find them useful. And if you have the means you can contribute to Patreon and there's a link to that page in the description section below. Be sure to subscribe for future videos and thank you all for watching.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 3.2, "text": " Hey there, how's it going everybody? In this video, we're going to be learning how to run", "tokens": [50364, 1911, 456, 11, 577, 311, 309, 516, 2201, 30, 682, 341, 960, 11, 321, 434, 516, 281, 312, 2539, 577, 281, 1190, 50524], "temperature": 0.0, "avg_logprob": -0.08106969350791839, "compression_ratio": 1.9300291545189505, "no_speech_prob": 0.11901045590639114}, {"id": 1, "seek": 0, "start": 3.2, "end": 7.76, "text": " code in parallel using the multi-processing module. Now, if you'd also like to learn about", "tokens": [50524, 3089, 294, 8952, 1228, 264, 4825, 12, 41075, 278, 10088, 13, 823, 11, 498, 291, 1116, 611, 411, 281, 1466, 466, 50752], "temperature": 0.0, "avg_logprob": -0.08106969350791839, "compression_ratio": 1.9300291545189505, "no_speech_prob": 0.11901045590639114}, {"id": 2, "seek": 0, "start": 7.76, "end": 12.32, "text": " running code concurrently using the threading module, then I did recently put out a video on", "tokens": [50752, 2614, 3089, 37702, 356, 1228, 264, 7207, 278, 10088, 11, 550, 286, 630, 3938, 829, 484, 257, 960, 322, 50980], "temperature": 0.0, "avg_logprob": -0.08106969350791839, "compression_ratio": 1.9300291545189505, "no_speech_prob": 0.11901045590639114}, {"id": 3, "seek": 0, "start": 12.32, "end": 16.64, "text": " that as well, so I'll be sure to leave a link to that video in the description section below. Now,", "tokens": [50980, 300, 382, 731, 11, 370, 286, 603, 312, 988, 281, 1856, 257, 2113, 281, 300, 960, 294, 264, 3855, 3541, 2507, 13, 823, 11, 51196], "temperature": 0.0, "avg_logprob": -0.08106969350791839, "compression_ratio": 1.9300291545189505, "no_speech_prob": 0.11901045590639114}, {"id": 4, "seek": 0, "start": 16.64, "end": 20.64, "text": " if you don't know the difference between threading and multi-processing, then you should have a grasp", "tokens": [51196, 498, 291, 500, 380, 458, 264, 2649, 1296, 7207, 278, 293, 4825, 12, 41075, 278, 11, 550, 291, 820, 362, 257, 21743, 51396], "temperature": 0.0, "avg_logprob": -0.08106969350791839, "compression_ratio": 1.9300291545189505, "no_speech_prob": 0.11901045590639114}, {"id": 5, "seek": 0, "start": 20.64, "end": 24.16, "text": " on the difference between those once we're finished. Now, I would like to mention that we", "tokens": [51396, 322, 264, 2649, 1296, 729, 1564, 321, 434, 4335, 13, 823, 11, 286, 576, 411, 281, 2152, 300, 321, 51572], "temperature": 0.0, "avg_logprob": -0.08106969350791839, "compression_ratio": 1.9300291545189505, "no_speech_prob": 0.11901045590639114}, {"id": 6, "seek": 0, "start": 24.16, "end": 28.96, "text": " do have a sponsor for this video, and that is Brilliant.org. So, I really want to thank Brilliant", "tokens": [51572, 360, 362, 257, 16198, 337, 341, 960, 11, 293, 300, 307, 34007, 13, 4646, 13, 407, 11, 286, 534, 528, 281, 1309, 34007, 51812], "temperature": 0.0, "avg_logprob": -0.08106969350791839, "compression_ratio": 1.9300291545189505, "no_speech_prob": 0.11901045590639114}, {"id": 7, "seek": 2896, "start": 28.96, "end": 32.56, "text": " for sponsoring the video, and it would be great if you all could go and check them out using the", "tokens": [50364, 337, 30311, 264, 960, 11, 293, 309, 576, 312, 869, 498, 291, 439, 727, 352, 293, 1520, 552, 484, 1228, 264, 50544], "temperature": 0.0, "avg_logprob": -0.05447043204794125, "compression_ratio": 1.7740963855421688, "no_speech_prob": 0.043997861444950104}, {"id": 8, "seek": 2896, "start": 32.56, "end": 36.72, "text": " link in the description section below and support the sponsors, and I'll talk more about their", "tokens": [50544, 2113, 294, 264, 3855, 3541, 2507, 293, 1406, 264, 22593, 11, 293, 286, 603, 751, 544, 466, 641, 50752], "temperature": 0.0, "avg_logprob": -0.05447043204794125, "compression_ratio": 1.7740963855421688, "no_speech_prob": 0.043997861444950104}, {"id": 9, "seek": 2896, "start": 36.72, "end": 42.24, "text": " services in just a bit. So, with that said, let's go ahead and get started. Okay, so first, why would", "tokens": [50752, 3328, 294, 445, 257, 857, 13, 407, 11, 365, 300, 848, 11, 718, 311, 352, 2286, 293, 483, 1409, 13, 1033, 11, 370, 700, 11, 983, 576, 51028], "temperature": 0.0, "avg_logprob": -0.05447043204794125, "compression_ratio": 1.7740963855421688, "no_speech_prob": 0.043997861444950104}, {"id": 10, "seek": 2896, "start": 42.24, "end": 47.760000000000005, "text": " we want to use multi-processing? So, basically, we want to use multi-processing whenever it's going", "tokens": [51028, 321, 528, 281, 764, 4825, 12, 41075, 278, 30, 407, 11, 1936, 11, 321, 528, 281, 764, 4825, 12, 41075, 278, 5699, 309, 311, 516, 51304], "temperature": 0.0, "avg_logprob": -0.05447043204794125, "compression_ratio": 1.7740963855421688, "no_speech_prob": 0.043997861444950104}, {"id": 11, "seek": 2896, "start": 47.760000000000005, "end": 53.52, "text": " to significantly speed up our program. Now, the speed up comes from different tasks running in", "tokens": [51304, 281, 10591, 3073, 493, 527, 1461, 13, 823, 11, 264, 3073, 493, 1487, 490, 819, 9608, 2614, 294, 51592], "temperature": 0.0, "avg_logprob": -0.05447043204794125, "compression_ratio": 1.7740963855421688, "no_speech_prob": 0.043997861444950104}, {"id": 12, "seek": 2896, "start": 53.52, "end": 58.480000000000004, "text": " parallel. Now, in this video, we're going to start off with a basic example of where we learn how to", "tokens": [51592, 8952, 13, 823, 11, 294, 341, 960, 11, 321, 434, 516, 281, 722, 766, 365, 257, 3875, 1365, 295, 689, 321, 1466, 577, 281, 51840], "temperature": 0.0, "avg_logprob": -0.05447043204794125, "compression_ratio": 1.7740963855421688, "no_speech_prob": 0.043997861444950104}, {"id": 13, "seek": 5848, "start": 58.48, "end": 63.919999999999995, "text": " run some simple sleep methods in parallel, but then we'll finish up with a real-world example", "tokens": [50364, 1190, 512, 2199, 2817, 7150, 294, 8952, 11, 457, 550, 321, 603, 2413, 493, 365, 257, 957, 12, 13217, 1365, 50636], "temperature": 0.0, "avg_logprob": -0.047245685090409946, "compression_ratio": 1.8478964401294498, "no_speech_prob": 0.0020504514686763287}, {"id": 14, "seek": 5848, "start": 63.919999999999995, "end": 68.96, "text": " where we do some image processing on a directory of high-resolution images. I want to show that", "tokens": [50636, 689, 321, 360, 512, 3256, 9007, 322, 257, 21120, 295, 1090, 12, 495, 3386, 5267, 13, 286, 528, 281, 855, 300, 50888], "temperature": 0.0, "avg_logprob": -0.047245685090409946, "compression_ratio": 1.8478964401294498, "no_speech_prob": 0.0020504514686763287}, {"id": 15, "seek": 5848, "start": 68.96, "end": 73.84, "text": " real-world example because, personally, when I watch tutorials that only show how it works on", "tokens": [50888, 957, 12, 13217, 1365, 570, 11, 5665, 11, 562, 286, 1159, 17616, 300, 787, 855, 577, 309, 1985, 322, 51132], "temperature": 0.0, "avg_logprob": -0.047245685090409946, "compression_ratio": 1.8478964401294498, "no_speech_prob": 0.0020504514686763287}, {"id": 16, "seek": 5848, "start": 73.84, "end": 78.47999999999999, "text": " basic examples, then I always feel like I don't really walk away with any useful knowledge. So,", "tokens": [51132, 3875, 5110, 11, 550, 286, 1009, 841, 411, 286, 500, 380, 534, 1792, 1314, 365, 604, 4420, 3601, 13, 407, 11, 51364], "temperature": 0.0, "avg_logprob": -0.047245685090409946, "compression_ratio": 1.8478964401294498, "no_speech_prob": 0.0020504514686763287}, {"id": 17, "seek": 5848, "start": 78.47999999999999, "end": 83.12, "text": " we'll use the sleep method to get a good idea of how to use multi-processing, and then we'll", "tokens": [51364, 321, 603, 764, 264, 2817, 3170, 281, 483, 257, 665, 1558, 295, 577, 281, 764, 4825, 12, 41075, 278, 11, 293, 550, 321, 603, 51596], "temperature": 0.0, "avg_logprob": -0.047245685090409946, "compression_ratio": 1.8478964401294498, "no_speech_prob": 0.0020504514686763287}, {"id": 18, "seek": 5848, "start": 83.12, "end": 88.16, "text": " be sure to go over the more complicated real-world example of image processing. So, let's go ahead", "tokens": [51596, 312, 988, 281, 352, 670, 264, 544, 6179, 957, 12, 13217, 1365, 295, 3256, 9007, 13, 407, 11, 718, 311, 352, 2286, 51848], "temperature": 0.0, "avg_logprob": -0.047245685090409946, "compression_ratio": 1.8478964401294498, "no_speech_prob": 0.0020504514686763287}, {"id": 19, "seek": 8816, "start": 88.16, "end": 93.2, "text": " and get started. So, I have a starting script open here, and if you'd like to follow along, then", "tokens": [50364, 293, 483, 1409, 13, 407, 11, 286, 362, 257, 2891, 5755, 1269, 510, 11, 293, 498, 291, 1116, 411, 281, 1524, 2051, 11, 550, 50616], "temperature": 0.0, "avg_logprob": -0.04585656218641386, "compression_ratio": 1.7482014388489209, "no_speech_prob": 0.0020504395943135023}, {"id": 20, "seek": 8816, "start": 93.2, "end": 98.56, "text": " I'll be sure to have a link to this code in the description section below. And, like I said, we'll", "tokens": [50616, 286, 603, 312, 988, 281, 362, 257, 2113, 281, 341, 3089, 294, 264, 3855, 3541, 2507, 13, 400, 11, 411, 286, 848, 11, 321, 603, 50884], "temperature": 0.0, "avg_logprob": -0.04585656218641386, "compression_ratio": 1.7482014388489209, "no_speech_prob": 0.0020504395943135023}, {"id": 21, "seek": 8816, "start": 98.56, "end": 104.4, "text": " start with a very simple example to see how this works and then build up with more realistic examples.", "tokens": [50884, 722, 365, 257, 588, 2199, 1365, 281, 536, 577, 341, 1985, 293, 550, 1322, 493, 365, 544, 12465, 5110, 13, 51176], "temperature": 0.0, "avg_logprob": -0.04585656218641386, "compression_ratio": 1.7482014388489209, "no_speech_prob": 0.0020504395943135023}, {"id": 22, "seek": 8816, "start": 104.4, "end": 109.92, "text": " So, let me go over the script that I currently have open here. So, first, I'm importing time,", "tokens": [51176, 407, 11, 718, 385, 352, 670, 264, 5755, 300, 286, 4362, 362, 1269, 510, 13, 407, 11, 700, 11, 286, 478, 43866, 565, 11, 51452], "temperature": 0.0, "avg_logprob": -0.04585656218641386, "compression_ratio": 1.7482014388489209, "no_speech_prob": 0.0020504395943135023}, {"id": 23, "seek": 8816, "start": 109.92, "end": 115.19999999999999, "text": " and I'm just using time to measure how long it takes the script to run. That's also what this", "tokens": [51452, 293, 286, 478, 445, 1228, 565, 281, 3481, 577, 938, 309, 2516, 264, 5755, 281, 1190, 13, 663, 311, 611, 437, 341, 51716], "temperature": 0.0, "avg_logprob": -0.04585656218641386, "compression_ratio": 1.7482014388489209, "no_speech_prob": 0.0020504395943135023}, {"id": 24, "seek": 11520, "start": 115.2, "end": 120.88, "text": " is here. This is just a start time for our script, and then we have a function here called", "tokens": [50364, 307, 510, 13, 639, 307, 445, 257, 722, 565, 337, 527, 5755, 11, 293, 550, 321, 362, 257, 2445, 510, 1219, 50648], "temperature": 0.0, "avg_logprob": -0.06394476049086627, "compression_ratio": 2.1106870229007635, "no_speech_prob": 0.001700685708783567}, {"id": 25, "seek": 11520, "start": 120.88, "end": 126.08, "text": " doSomething, and all this is doing is printing that we are sleeping for one second, then we actually", "tokens": [50648, 360, 45431, 11, 293, 439, 341, 307, 884, 307, 14699, 300, 321, 366, 8296, 337, 472, 1150, 11, 550, 321, 767, 50908], "temperature": 0.0, "avg_logprob": -0.06394476049086627, "compression_ratio": 2.1106870229007635, "no_speech_prob": 0.001700685708783567}, {"id": 26, "seek": 11520, "start": 126.08, "end": 131.36, "text": " sleep a second using that time module, and then we are printing out that we are done sleeping,", "tokens": [50908, 2817, 257, 1150, 1228, 300, 565, 10088, 11, 293, 550, 321, 366, 14699, 484, 300, 321, 366, 1096, 8296, 11, 51172], "temperature": 0.0, "avg_logprob": -0.06394476049086627, "compression_ratio": 2.1106870229007635, "no_speech_prob": 0.001700685708783567}, {"id": 27, "seek": 11520, "start": 131.36, "end": 135.2, "text": " and then we are actually executing that function. So, it should do all of this,", "tokens": [51172, 293, 550, 321, 366, 767, 32368, 300, 2445, 13, 407, 11, 309, 820, 360, 439, 295, 341, 11, 51364], "temperature": 0.0, "avg_logprob": -0.06394476049086627, "compression_ratio": 2.1106870229007635, "no_speech_prob": 0.001700685708783567}, {"id": 28, "seek": 11520, "start": 135.2, "end": 140.32, "text": " and then we are calculating the finish time and printing out that our script is finished.", "tokens": [51364, 293, 550, 321, 366, 28258, 264, 2413, 565, 293, 14699, 484, 300, 527, 5755, 307, 4335, 13, 51620], "temperature": 0.0, "avg_logprob": -0.06394476049086627, "compression_ratio": 2.1106870229007635, "no_speech_prob": 0.001700685708783567}, {"id": 29, "seek": 11520, "start": 140.32, "end": 144.72, "text": " Okay, so, if I run the code that we have right now, we can see that it said that it was sleeping", "tokens": [51620, 1033, 11, 370, 11, 498, 286, 1190, 264, 3089, 300, 321, 362, 558, 586, 11, 321, 393, 536, 300, 309, 848, 300, 309, 390, 8296, 51840], "temperature": 0.0, "avg_logprob": -0.06394476049086627, "compression_ratio": 2.1106870229007635, "no_speech_prob": 0.001700685708783567}, {"id": 30, "seek": 14472, "start": 144.72, "end": 149.28, "text": " for one second, done sleeping, and that we finished in about one second. And that sounds", "tokens": [50364, 337, 472, 1150, 11, 1096, 8296, 11, 293, 300, 321, 4335, 294, 466, 472, 1150, 13, 400, 300, 3263, 50592], "temperature": 0.0, "avg_logprob": -0.07271610388234884, "compression_ratio": 1.962809917355372, "no_speech_prob": 0.0011335293529555202}, {"id": 31, "seek": 14472, "start": 149.28, "end": 154.4, "text": " about right since we were running our doSomething function one time, and that sleeps for one second.", "tokens": [50592, 466, 558, 1670, 321, 645, 2614, 527, 360, 45431, 2445, 472, 565, 11, 293, 300, 37991, 337, 472, 1150, 13, 50848], "temperature": 0.0, "avg_logprob": -0.07271610388234884, "compression_ratio": 1.962809917355372, "no_speech_prob": 0.0011335293529555202}, {"id": 32, "seek": 14472, "start": 154.4, "end": 159.2, "text": " And if we were to run that function twice, then our program will likely take two seconds. So,", "tokens": [50848, 400, 498, 321, 645, 281, 1190, 300, 2445, 6091, 11, 550, 527, 1461, 486, 3700, 747, 732, 3949, 13, 407, 11, 51088], "temperature": 0.0, "avg_logprob": -0.07271610388234884, "compression_ratio": 1.962809917355372, "no_speech_prob": 0.0011335293529555202}, {"id": 33, "seek": 14472, "start": 159.2, "end": 166.0, "text": " let's go ahead and see that. So, right below doSomething here, I'm going to run this again,", "tokens": [51088, 718, 311, 352, 2286, 293, 536, 300, 13, 407, 11, 558, 2507, 360, 45431, 510, 11, 286, 478, 516, 281, 1190, 341, 797, 11, 51428], "temperature": 0.0, "avg_logprob": -0.07271610388234884, "compression_ratio": 1.962809917355372, "no_speech_prob": 0.0011335293529555202}, {"id": 34, "seek": 14472, "start": 166.0, "end": 172.07999999999998, "text": " and if I run that, then we can see that now that it printed out that it was sleeping for one second", "tokens": [51428, 293, 498, 286, 1190, 300, 11, 550, 321, 393, 536, 300, 586, 300, 309, 13567, 484, 300, 309, 390, 8296, 337, 472, 1150, 51732], "temperature": 0.0, "avg_logprob": -0.07271610388234884, "compression_ratio": 1.962809917355372, "no_speech_prob": 0.0011335293529555202}, {"id": 35, "seek": 17208, "start": 172.16000000000003, "end": 177.60000000000002, "text": " twice, and that it took about two seconds. So, we can see that each time we run this doSomething", "tokens": [50368, 6091, 11, 293, 300, 309, 1890, 466, 732, 3949, 13, 407, 11, 321, 393, 536, 300, 1184, 565, 321, 1190, 341, 360, 45431, 50640], "temperature": 0.0, "avg_logprob": -0.06955444087152896, "compression_ratio": 1.7557251908396947, "no_speech_prob": 0.004331146366894245}, {"id": 36, "seek": 17208, "start": 177.60000000000002, "end": 182.56, "text": " function, it's adding about one second to our script. So, our script is just waiting around", "tokens": [50640, 2445, 11, 309, 311, 5127, 466, 472, 1150, 281, 527, 5755, 13, 407, 11, 527, 5755, 307, 445, 3806, 926, 50888], "temperature": 0.0, "avg_logprob": -0.06955444087152896, "compression_ratio": 1.7557251908396947, "no_speech_prob": 0.004331146366894245}, {"id": 37, "seek": 17208, "start": 182.56, "end": 188.32000000000002, "text": " sleeping for a second, and once that's done, it moves on to run that next function,", "tokens": [50888, 8296, 337, 257, 1150, 11, 293, 1564, 300, 311, 1096, 11, 309, 6067, 322, 281, 1190, 300, 958, 2445, 11, 51176], "temperature": 0.0, "avg_logprob": -0.06955444087152896, "compression_ratio": 1.7557251908396947, "no_speech_prob": 0.004331146366894245}, {"id": 38, "seek": 17208, "start": 188.32000000000002, "end": 192.72000000000003, "text": " and sits around waiting for another second. And then at that point, we're basically done,", "tokens": [51176, 293, 12696, 926, 3806, 337, 1071, 1150, 13, 400, 550, 412, 300, 935, 11, 321, 434, 1936, 1096, 11, 51396], "temperature": 0.0, "avg_logprob": -0.06955444087152896, "compression_ratio": 1.7557251908396947, "no_speech_prob": 0.004331146366894245}, {"id": 39, "seek": 17208, "start": 192.72000000000003, "end": 197.84, "text": " and our script finishes. Now, I created a quick graphic to try to represent what this looks like.", "tokens": [51396, 293, 527, 5755, 23615, 13, 823, 11, 286, 2942, 257, 1702, 14089, 281, 853, 281, 2906, 437, 341, 1542, 411, 13, 51652], "temperature": 0.0, "avg_logprob": -0.06955444087152896, "compression_ratio": 1.7557251908396947, "no_speech_prob": 0.004331146366894245}, {"id": 40, "seek": 19784, "start": 197.84, "end": 202.16, "text": " So, let me bring that up here in my browser real quick. And this is actually the second", "tokens": [50364, 407, 11, 718, 385, 1565, 300, 493, 510, 294, 452, 11185, 957, 1702, 13, 400, 341, 307, 767, 264, 1150, 50580], "temperature": 0.0, "avg_logprob": -0.07281532125957942, "compression_ratio": 1.782442748091603, "no_speech_prob": 0.00031503013451583683}, {"id": 41, "seek": 19784, "start": 202.16, "end": 206.96, "text": " graphic. We'll go over that in just a second. Okay. So, this is basically what it looks like", "tokens": [50580, 14089, 13, 492, 603, 352, 670, 300, 294, 445, 257, 1150, 13, 1033, 13, 407, 11, 341, 307, 1936, 437, 309, 1542, 411, 50820], "temperature": 0.0, "avg_logprob": -0.07281532125957942, "compression_ratio": 1.782442748091603, "no_speech_prob": 0.00031503013451583683}, {"id": 42, "seek": 19784, "start": 207.6, "end": 213.36, "text": " for our script to be executed right now. So, we are running a function. In this case, it's that", "tokens": [50852, 337, 527, 5755, 281, 312, 17577, 558, 586, 13, 407, 11, 321, 366, 2614, 257, 2445, 13, 682, 341, 1389, 11, 309, 311, 300, 51140], "temperature": 0.0, "avg_logprob": -0.07281532125957942, "compression_ratio": 1.782442748091603, "no_speech_prob": 0.00031503013451583683}, {"id": 43, "seek": 19784, "start": 213.36, "end": 218.96, "text": " doSomething function. And then this is just coming up here and waiting and executing for one second.", "tokens": [51140, 360, 45431, 2445, 13, 400, 550, 341, 307, 445, 1348, 493, 510, 293, 3806, 293, 32368, 337, 472, 1150, 13, 51420], "temperature": 0.0, "avg_logprob": -0.07281532125957942, "compression_ratio": 1.782442748091603, "no_speech_prob": 0.00031503013451583683}, {"id": 44, "seek": 19784, "start": 218.96, "end": 224.0, "text": " And once that one second is over, then we come back and we execute this another function,", "tokens": [51420, 400, 1564, 300, 472, 1150, 307, 670, 11, 550, 321, 808, 646, 293, 321, 14483, 341, 1071, 2445, 11, 51672], "temperature": 0.0, "avg_logprob": -0.07281532125957942, "compression_ratio": 1.782442748091603, "no_speech_prob": 0.00031503013451583683}, {"id": 45, "seek": 22400, "start": 224.08, "end": 229.12, "text": " and it's that same function again. So, then it comes up here and executes this sleep for one", "tokens": [50368, 293, 309, 311, 300, 912, 2445, 797, 13, 407, 11, 550, 309, 1487, 493, 510, 293, 4454, 1819, 341, 2817, 337, 472, 50620], "temperature": 0.0, "avg_logprob": -0.051856615604498446, "compression_ratio": 1.7709923664122138, "no_speech_prob": 0.0011335116578266025}, {"id": 46, "seek": 22400, "start": 229.12, "end": 233.68, "text": " second again. And when that one second is done, then we can come down here and print that our", "tokens": [50620, 1150, 797, 13, 400, 562, 300, 472, 1150, 307, 1096, 11, 550, 321, 393, 808, 760, 510, 293, 4482, 300, 527, 50848], "temperature": 0.0, "avg_logprob": -0.051856615604498446, "compression_ratio": 1.7709923664122138, "no_speech_prob": 0.0011335116578266025}, {"id": 47, "seek": 22400, "start": 233.68, "end": 238.88, "text": " script is done. And running everything in order like this is called running it synchronously.", "tokens": [50848, 5755, 307, 1096, 13, 400, 2614, 1203, 294, 1668, 411, 341, 307, 1219, 2614, 309, 19331, 5098, 13, 51108], "temperature": 0.0, "avg_logprob": -0.051856615604498446, "compression_ratio": 1.7709923664122138, "no_speech_prob": 0.0011335116578266025}, {"id": 48, "seek": 22400, "start": 238.88, "end": 242.88, "text": " Now, if you have some tasks that don't need to be run synchronously, then we can use the", "tokens": [51108, 823, 11, 498, 291, 362, 512, 9608, 300, 500, 380, 643, 281, 312, 1190, 19331, 5098, 11, 550, 321, 393, 764, 264, 51308], "temperature": 0.0, "avg_logprob": -0.051856615604498446, "compression_ratio": 1.7709923664122138, "no_speech_prob": 0.0011335116578266025}, {"id": 49, "seek": 22400, "start": 242.88, "end": 249.2, "text": " multi-processing module to split these tasks up onto other CPUs and run them at the same time.", "tokens": [51308, 4825, 12, 41075, 278, 10088, 281, 7472, 613, 9608, 493, 3911, 661, 13199, 82, 293, 1190, 552, 412, 264, 912, 565, 13, 51624], "temperature": 0.0, "avg_logprob": -0.051856615604498446, "compression_ratio": 1.7709923664122138, "no_speech_prob": 0.0011335116578266025}, {"id": 50, "seek": 24920, "start": 249.2, "end": 254.39999999999998, "text": " Now, if you watched my last video on threading, then I mentioned that tasks were going to either", "tokens": [50364, 823, 11, 498, 291, 6337, 452, 1036, 960, 322, 7207, 278, 11, 550, 286, 2835, 300, 9608, 645, 516, 281, 2139, 50624], "temperature": 0.0, "avg_logprob": -0.05883583721813855, "compression_ratio": 1.8157894736842106, "no_speech_prob": 0.02595175802707672}, {"id": 51, "seek": 24920, "start": 254.39999999999998, "end": 261.2, "text": " be IO bound or CPU bound. So, CPU bound tasks are things that are crunching a lot of numbers and", "tokens": [50624, 312, 39839, 5472, 420, 13199, 5472, 13, 407, 11, 13199, 5472, 9608, 366, 721, 300, 366, 13386, 278, 257, 688, 295, 3547, 293, 50964], "temperature": 0.0, "avg_logprob": -0.05883583721813855, "compression_ratio": 1.8157894736842106, "no_speech_prob": 0.02595175802707672}, {"id": 52, "seek": 24920, "start": 261.2, "end": 266.96, "text": " using the CPU. And IO bound tasks are things that are waiting for input and output operations", "tokens": [50964, 1228, 264, 13199, 13, 400, 39839, 5472, 9608, 366, 721, 300, 366, 3806, 337, 4846, 293, 5598, 7705, 51252], "temperature": 0.0, "avg_logprob": -0.05883583721813855, "compression_ratio": 1.8157894736842106, "no_speech_prob": 0.02595175802707672}, {"id": 53, "seek": 24920, "start": 266.96, "end": 272.32, "text": " to be completed. And they're not really using the CPU all that much. So, some other examples of", "tokens": [51252, 281, 312, 7365, 13, 400, 436, 434, 406, 534, 1228, 264, 13199, 439, 300, 709, 13, 407, 11, 512, 661, 5110, 295, 51520], "temperature": 0.0, "avg_logprob": -0.05883583721813855, "compression_ratio": 1.8157894736842106, "no_speech_prob": 0.02595175802707672}, {"id": 54, "seek": 24920, "start": 272.32, "end": 278.96, "text": " IO bound tasks include file system operations and network operations like downloading stuff online.", "tokens": [51520, 39839, 5472, 9608, 4090, 3991, 1185, 7705, 293, 3209, 7705, 411, 32529, 1507, 2950, 13, 51852], "temperature": 0.0, "avg_logprob": -0.05883583721813855, "compression_ratio": 1.8157894736842106, "no_speech_prob": 0.02595175802707672}, {"id": 55, "seek": 27896, "start": 278.96, "end": 283.03999999999996, "text": " Now, in that threading video, I mentioned that we wouldn't get much of a speed up when using", "tokens": [50364, 823, 11, 294, 300, 7207, 278, 960, 11, 286, 2835, 300, 321, 2759, 380, 483, 709, 295, 257, 3073, 493, 562, 1228, 50568], "temperature": 0.0, "avg_logprob": -0.06232364074043606, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.00019715998496394604}, {"id": 56, "seek": 27896, "start": 283.03999999999996, "end": 289.12, "text": " threading on CPU bound tasks because those threads are still only running one process. But with", "tokens": [50568, 7207, 278, 322, 13199, 5472, 9608, 570, 729, 19314, 366, 920, 787, 2614, 472, 1399, 13, 583, 365, 50872], "temperature": 0.0, "avg_logprob": -0.06232364074043606, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.00019715998496394604}, {"id": 57, "seek": 27896, "start": 289.12, "end": 294.4, "text": " multi-processing, we're going to actually spread the work out onto multiple processors on our machine", "tokens": [50872, 4825, 12, 41075, 278, 11, 321, 434, 516, 281, 767, 3974, 264, 589, 484, 3911, 3866, 27751, 322, 527, 3479, 51136], "temperature": 0.0, "avg_logprob": -0.06232364074043606, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.00019715998496394604}, {"id": 58, "seek": 27896, "start": 294.4, "end": 300.56, "text": " and run those tasks at the same time. So, we can use this with both IO bound tasks and CPU bound", "tokens": [51136, 293, 1190, 729, 9608, 412, 264, 912, 565, 13, 407, 11, 321, 393, 764, 341, 365, 1293, 39839, 5472, 9608, 293, 13199, 5472, 51444], "temperature": 0.0, "avg_logprob": -0.06232364074043606, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.00019715998496394604}, {"id": 59, "seek": 27896, "start": 300.56, "end": 305.35999999999996, "text": " tasks. So, it really just depends on what we're doing and your computer's hardware that will", "tokens": [51444, 9608, 13, 407, 11, 309, 534, 445, 5946, 322, 437, 321, 434, 884, 293, 428, 3820, 311, 8837, 300, 486, 51684], "temperature": 0.0, "avg_logprob": -0.06232364074043606, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.00019715998496394604}, {"id": 60, "seek": 30536, "start": 305.44, "end": 309.84000000000003, "text": " determine if it's better to use threading or multi-processing. But with that said,", "tokens": [50368, 6997, 498, 309, 311, 1101, 281, 764, 7207, 278, 420, 4825, 12, 41075, 278, 13, 583, 365, 300, 848, 11, 50588], "temperature": 0.0, "avg_logprob": -0.059679663542545204, "compression_ratio": 1.7980132450331126, "no_speech_prob": 0.019121849909424782}, {"id": 61, "seek": 30536, "start": 309.84000000000003, "end": 314.56, "text": " let's look at what it looks like to run something in parallel using multi-processing.", "tokens": [50588, 718, 311, 574, 412, 437, 309, 1542, 411, 281, 1190, 746, 294, 8952, 1228, 4825, 12, 41075, 278, 13, 50824], "temperature": 0.0, "avg_logprob": -0.059679663542545204, "compression_ratio": 1.7980132450331126, "no_speech_prob": 0.019121849909424782}, {"id": 62, "seek": 30536, "start": 314.56, "end": 319.36, "text": " And I've got another graphic put together of what this would look like. So, in this example,", "tokens": [50824, 400, 286, 600, 658, 1071, 14089, 829, 1214, 295, 437, 341, 576, 574, 411, 13, 407, 11, 294, 341, 1365, 11, 51064], "temperature": 0.0, "avg_logprob": -0.059679663542545204, "compression_ratio": 1.7980132450331126, "no_speech_prob": 0.019121849909424782}, {"id": 63, "seek": 30536, "start": 319.36, "end": 324.08000000000004, "text": " we can see that we still have our two tasks. But now we're just breaking these up onto two", "tokens": [51064, 321, 393, 536, 300, 321, 920, 362, 527, 732, 9608, 13, 583, 586, 321, 434, 445, 7697, 613, 493, 3911, 732, 51300], "temperature": 0.0, "avg_logprob": -0.059679663542545204, "compression_ratio": 1.7980132450331126, "no_speech_prob": 0.019121849909424782}, {"id": 64, "seek": 30536, "start": 324.08000000000004, "end": 329.84000000000003, "text": " different processes. And unlike with threading, where we were running these concurrently, and I", "tokens": [51300, 819, 7555, 13, 400, 8343, 365, 7207, 278, 11, 689, 321, 645, 2614, 613, 37702, 356, 11, 293, 286, 51588], "temperature": 0.0, "avg_logprob": -0.059679663542545204, "compression_ratio": 1.7980132450331126, "no_speech_prob": 0.019121849909424782}, {"id": 65, "seek": 30536, "start": 329.84000000000003, "end": 333.76, "text": " said that running concurrently doesn't necessarily mean that they're running at the same time,", "tokens": [51588, 848, 300, 2614, 37702, 356, 1177, 380, 4725, 914, 300, 436, 434, 2614, 412, 264, 912, 565, 11, 51784], "temperature": 0.0, "avg_logprob": -0.059679663542545204, "compression_ratio": 1.7980132450331126, "no_speech_prob": 0.019121849909424782}, {"id": 66, "seek": 33376, "start": 334.48, "end": 339.84, "text": " with multi-processes, these actually are running at the same time on different processes. So,", "tokens": [50400, 365, 4825, 12, 41075, 279, 11, 613, 767, 366, 2614, 412, 264, 912, 565, 322, 819, 7555, 13, 407, 11, 50668], "temperature": 0.0, "avg_logprob": -0.06003419827606719, "compression_ratio": 1.8075471698113208, "no_speech_prob": 0.0008558523841202259}, {"id": 67, "seek": 33376, "start": 339.84, "end": 346.24, "text": " we can see here that once we kick off our multiple processes and we spread out our tasks onto those", "tokens": [50668, 321, 393, 536, 510, 300, 1564, 321, 4437, 766, 527, 3866, 7555, 293, 321, 3974, 484, 527, 9608, 3911, 729, 50988], "temperature": 0.0, "avg_logprob": -0.06003419827606719, "compression_ratio": 1.8075471698113208, "no_speech_prob": 0.0008558523841202259}, {"id": 68, "seek": 33376, "start": 346.24, "end": 352.56, "text": " processes, then we can just run each of these functions one time. And then both of these will", "tokens": [50988, 7555, 11, 550, 321, 393, 445, 1190, 1184, 295, 613, 6828, 472, 565, 13, 400, 550, 1293, 295, 613, 486, 51304], "temperature": 0.0, "avg_logprob": -0.06003419827606719, "compression_ratio": 1.8075471698113208, "no_speech_prob": 0.0008558523841202259}, {"id": 69, "seek": 33376, "start": 352.56, "end": 357.44, "text": " sleep for a second. And then once they're both done, we'll come down here and print that they're", "tokens": [51304, 2817, 337, 257, 1150, 13, 400, 550, 1564, 436, 434, 1293, 1096, 11, 321, 603, 808, 760, 510, 293, 4482, 300, 436, 434, 51548], "temperature": 0.0, "avg_logprob": -0.06003419827606719, "compression_ratio": 1.8075471698113208, "no_speech_prob": 0.0008558523841202259}, {"id": 70, "seek": 33376, "start": 357.44, "end": 361.76, "text": " done. Okay, so now that we've talked about multi-processing and what it looks like to run code", "tokens": [51548, 1096, 13, 1033, 11, 370, 586, 300, 321, 600, 2825, 466, 4825, 12, 41075, 278, 293, 437, 309, 1542, 411, 281, 1190, 3089, 51764], "temperature": 0.0, "avg_logprob": -0.06003419827606719, "compression_ratio": 1.8075471698113208, "no_speech_prob": 0.0008558523841202259}, {"id": 71, "seek": 36176, "start": 361.76, "end": 368.15999999999997, "text": " in parallel, now let's see how to actually do this with our current script. So, first,", "tokens": [50364, 294, 8952, 11, 586, 718, 311, 536, 577, 281, 767, 360, 341, 365, 527, 2190, 5755, 13, 407, 11, 700, 11, 50684], "temperature": 0.0, "avg_logprob": -0.06027710810303688, "compression_ratio": 1.7252747252747254, "no_speech_prob": 0.001324969227425754}, {"id": 72, "seek": 36176, "start": 368.15999999999997, "end": 373.59999999999997, "text": " let's import the multi-processing module. So, this is in the standard library, so we don't need to", "tokens": [50684, 718, 311, 974, 264, 4825, 12, 41075, 278, 10088, 13, 407, 11, 341, 307, 294, 264, 3832, 6405, 11, 370, 321, 500, 380, 643, 281, 50956], "temperature": 0.0, "avg_logprob": -0.06027710810303688, "compression_ratio": 1.7252747252747254, "no_speech_prob": 0.001324969227425754}, {"id": 73, "seek": 36176, "start": 373.59999999999997, "end": 381.12, "text": " install anything. So, up here at the top, I'm just going to say import multi-processing. Now,", "tokens": [50956, 3625, 1340, 13, 407, 11, 493, 510, 412, 264, 1192, 11, 286, 478, 445, 516, 281, 584, 974, 4825, 12, 41075, 278, 13, 823, 11, 51332], "temperature": 0.0, "avg_logprob": -0.06027710810303688, "compression_ratio": 1.7252747252747254, "no_speech_prob": 0.001324969227425754}, {"id": 74, "seek": 36176, "start": 381.12, "end": 385.03999999999996, "text": " I'm going to show an older way of how to do multi-processing first so that we can get a good", "tokens": [51332, 286, 478, 516, 281, 855, 364, 4906, 636, 295, 577, 281, 360, 4825, 12, 41075, 278, 700, 370, 300, 321, 393, 483, 257, 665, 51528], "temperature": 0.0, "avg_logprob": -0.06027710810303688, "compression_ratio": 1.7252747252747254, "no_speech_prob": 0.001324969227425754}, {"id": 75, "seek": 36176, "start": 385.03999999999996, "end": 389.68, "text": " idea of what's going on. But if it seems confusing at first, then definitely stick around, because", "tokens": [51528, 1558, 295, 437, 311, 516, 322, 13, 583, 498, 309, 2544, 13181, 412, 700, 11, 550, 2138, 2897, 926, 11, 570, 51760], "temperature": 0.0, "avg_logprob": -0.06027710810303688, "compression_ratio": 1.7252747252747254, "no_speech_prob": 0.001324969227425754}, {"id": 76, "seek": 38968, "start": 389.68, "end": 394.88, "text": " I'm also going to show some newer ways of doing multi-processing using pools that allow us to", "tokens": [50364, 286, 478, 611, 516, 281, 855, 512, 17628, 2098, 295, 884, 4825, 12, 41075, 278, 1228, 28688, 300, 2089, 505, 281, 50624], "temperature": 0.0, "avg_logprob": -0.04637463390827179, "compression_ratio": 1.6415929203539823, "no_speech_prob": 0.0009399242699146271}, {"id": 77, "seek": 38968, "start": 394.88, "end": 401.36, "text": " add this to our program with just a few lines of code. Okay, so first, instead of running the", "tokens": [50624, 909, 341, 281, 527, 1461, 365, 445, 257, 1326, 3876, 295, 3089, 13, 1033, 11, 370, 700, 11, 2602, 295, 2614, 264, 50948], "temperature": 0.0, "avg_logprob": -0.04637463390827179, "compression_ratio": 1.6415929203539823, "no_speech_prob": 0.0009399242699146271}, {"id": 78, "seek": 38968, "start": 401.36, "end": 406.96000000000004, "text": " do something function twice in a row like we have here, let's instead turn both of these into", "tokens": [50948, 360, 746, 2445, 6091, 294, 257, 5386, 411, 321, 362, 510, 11, 718, 311, 2602, 1261, 1293, 295, 613, 666, 51228], "temperature": 0.0, "avg_logprob": -0.04637463390827179, "compression_ratio": 1.6415929203539823, "no_speech_prob": 0.0009399242699146271}, {"id": 79, "seek": 38968, "start": 406.96000000000004, "end": 412.64, "text": " processes. So, to do this, I'm just going to create two processes. And for both of these,", "tokens": [51228, 7555, 13, 407, 11, 281, 360, 341, 11, 286, 478, 445, 516, 281, 1884, 732, 7555, 13, 400, 337, 1293, 295, 613, 11, 51512], "temperature": 0.0, "avg_logprob": -0.04637463390827179, "compression_ratio": 1.6415929203539823, "no_speech_prob": 0.0009399242699146271}, {"id": 80, "seek": 41264, "start": 412.64, "end": 421.2, "text": " we can just say p1 is equal to multi-processing.process. And now, we are going to pass in a", "tokens": [50364, 321, 393, 445, 584, 280, 16, 307, 2681, 281, 4825, 12, 41075, 278, 13, 41075, 13, 400, 586, 11, 321, 366, 516, 281, 1320, 294, 257, 50792], "temperature": 0.0, "avg_logprob": -0.06651901962733504, "compression_ratio": 1.8349514563106797, "no_speech_prob": 0.0017545334994792938}, {"id": 81, "seek": 41264, "start": 421.2, "end": 427.2, "text": " target. And the target is the function that we want to run. So, if I want to run this do something", "tokens": [50792, 3779, 13, 400, 264, 3779, 307, 264, 2445, 300, 321, 528, 281, 1190, 13, 407, 11, 498, 286, 528, 281, 1190, 341, 360, 746, 51092], "temperature": 0.0, "avg_logprob": -0.06651901962733504, "compression_ratio": 1.8349514563106797, "no_speech_prob": 0.0017545334994792938}, {"id": 82, "seek": 41264, "start": 427.2, "end": 433.59999999999997, "text": " function, then I can pass in do something. Now, we want to pass in the actual function and not", "tokens": [51092, 2445, 11, 550, 286, 393, 1320, 294, 360, 746, 13, 823, 11, 321, 528, 281, 1320, 294, 264, 3539, 2445, 293, 406, 51412], "temperature": 0.0, "avg_logprob": -0.06651901962733504, "compression_ratio": 1.8349514563106797, "no_speech_prob": 0.0017545334994792938}, {"id": 83, "seek": 41264, "start": 433.59999999999997, "end": 437.76, "text": " the return value of the function. So, we don't want to execute the function with parentheses", "tokens": [51412, 264, 2736, 2158, 295, 264, 2445, 13, 407, 11, 321, 500, 380, 528, 281, 14483, 264, 2445, 365, 34153, 51620], "temperature": 0.0, "avg_logprob": -0.06651901962733504, "compression_ratio": 1.8349514563106797, "no_speech_prob": 0.0017545334994792938}, {"id": 84, "seek": 43776, "start": 437.76, "end": 445.2, "text": " like this. We just want to pass it in with no parentheses. Okay, so now that will be one process.", "tokens": [50364, 411, 341, 13, 492, 445, 528, 281, 1320, 309, 294, 365, 572, 34153, 13, 1033, 11, 370, 586, 300, 486, 312, 472, 1399, 13, 50736], "temperature": 0.0, "avg_logprob": -0.059383711724911095, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.004905130248516798}, {"id": 85, "seek": 43776, "start": 445.2, "end": 452.8, "text": " And now, if I do a p2 is equal to multi-processing.process with a target of do something, then", "tokens": [50736, 400, 586, 11, 498, 286, 360, 257, 280, 17, 307, 2681, 281, 4825, 12, 41075, 278, 13, 41075, 365, 257, 3779, 295, 360, 746, 11, 550, 51116], "temperature": 0.0, "avg_logprob": -0.059383711724911095, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.004905130248516798}, {"id": 86, "seek": 43776, "start": 452.8, "end": 459.12, "text": " that will be our second process. Okay, so at this point, we've created two process objects,", "tokens": [51116, 300, 486, 312, 527, 1150, 1399, 13, 1033, 11, 370, 412, 341, 935, 11, 321, 600, 2942, 732, 1399, 6565, 11, 51432], "temperature": 0.0, "avg_logprob": -0.059383711724911095, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.004905130248516798}, {"id": 87, "seek": 43776, "start": 459.12, "end": 465.59999999999997, "text": " but we're not actually running that code. So, if I run this right now, then we can see that it says", "tokens": [51432, 457, 321, 434, 406, 767, 2614, 300, 3089, 13, 407, 11, 498, 286, 1190, 341, 558, 586, 11, 550, 321, 393, 536, 300, 309, 1619, 51756], "temperature": 0.0, "avg_logprob": -0.059383711724911095, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.004905130248516798}, {"id": 88, "seek": 46560, "start": 465.6, "end": 471.20000000000005, "text": " that it finished immediately, but nothing from our function printed out. So, our functions didn't", "tokens": [50364, 300, 309, 4335, 4258, 11, 457, 1825, 490, 527, 2445, 13567, 484, 13, 407, 11, 527, 6828, 994, 380, 50644], "temperature": 0.0, "avg_logprob": -0.05211147785186768, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.006289564073085785}, {"id": 89, "seek": 46560, "start": 471.20000000000005, "end": 477.6, "text": " actually run. So, in order to get our processes to run, we need to use the start method on each one.", "tokens": [50644, 767, 1190, 13, 407, 11, 294, 1668, 281, 483, 527, 7555, 281, 1190, 11, 321, 643, 281, 764, 264, 722, 3170, 322, 1184, 472, 13, 50964], "temperature": 0.0, "avg_logprob": -0.05211147785186768, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.006289564073085785}, {"id": 90, "seek": 46560, "start": 477.6, "end": 484.56, "text": " So, down here below our p2, I'm going to say p1.start to start that first process,", "tokens": [50964, 407, 11, 760, 510, 2507, 527, 280, 17, 11, 286, 478, 516, 281, 584, 280, 16, 13, 24419, 281, 722, 300, 700, 1399, 11, 51312], "temperature": 0.0, "avg_logprob": -0.05211147785186768, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.006289564073085785}, {"id": 91, "seek": 46560, "start": 484.56, "end": 492.88, "text": " and p2.start to start that second process. Okay, so now that will actually run our processes,", "tokens": [51312, 293, 280, 17, 13, 24419, 281, 722, 300, 1150, 1399, 13, 1033, 11, 370, 586, 300, 486, 767, 1190, 527, 7555, 11, 51728], "temperature": 0.0, "avg_logprob": -0.05211147785186768, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.006289564073085785}, {"id": 92, "seek": 49288, "start": 492.88, "end": 500.24, "text": " but it might not do exactly what we think it'll do. So, if we run this, then we can see that now", "tokens": [50364, 457, 309, 1062, 406, 360, 2293, 437, 321, 519, 309, 603, 360, 13, 407, 11, 498, 321, 1190, 341, 11, 550, 321, 393, 536, 300, 586, 50732], "temperature": 0.0, "avg_logprob": -0.06432169491482764, "compression_ratio": 1.8240740740740742, "no_speech_prob": 0.0018101563910022378}, {"id": 93, "seek": 49288, "start": 500.24, "end": 507.2, "text": " it runs the functions, but it said that our script was finished in zero seconds, and then it said", "tokens": [50732, 309, 6676, 264, 6828, 11, 457, 309, 848, 300, 527, 5755, 390, 4335, 294, 4018, 3949, 11, 293, 550, 309, 848, 51080], "temperature": 0.0, "avg_logprob": -0.06432169491482764, "compression_ratio": 1.8240740740740742, "no_speech_prob": 0.0018101563910022378}, {"id": 94, "seek": 49288, "start": 507.2, "end": 512.72, "text": " that we were sleeping for one second twice because we ran that function twice, and then it said that", "tokens": [51080, 300, 321, 645, 8296, 337, 472, 1150, 6091, 570, 321, 5872, 300, 2445, 6091, 11, 293, 550, 309, 848, 300, 51356], "temperature": 0.0, "avg_logprob": -0.06432169491482764, "compression_ratio": 1.8240740740740742, "no_speech_prob": 0.0018101563910022378}, {"id": 95, "seek": 49288, "start": 512.72, "end": 518.48, "text": " it was done sleeping. Now, our entire script didn't actually complete in zero seconds. It actually", "tokens": [51356, 309, 390, 1096, 8296, 13, 823, 11, 527, 2302, 5755, 994, 380, 767, 3566, 294, 4018, 3949, 13, 467, 767, 51644], "temperature": 0.0, "avg_logprob": -0.06432169491482764, "compression_ratio": 1.8240740740740742, "no_speech_prob": 0.0018101563910022378}, {"id": 96, "seek": 51848, "start": 518.48, "end": 524.16, "text": " took around one second, but the reason that it says that it completed in zero seconds is because", "tokens": [50364, 1890, 926, 472, 1150, 11, 457, 264, 1778, 300, 309, 1619, 300, 309, 7365, 294, 4018, 3949, 307, 570, 50648], "temperature": 0.0, "avg_logprob": -0.05854682127634684, "compression_ratio": 1.830188679245283, "no_speech_prob": 0.030210202559828758}, {"id": 97, "seek": 51848, "start": 524.16, "end": 530.96, "text": " after it started both of these processes here, while those processes were sleeping, our script", "tokens": [50648, 934, 309, 1409, 1293, 295, 613, 7555, 510, 11, 1339, 729, 7555, 645, 8296, 11, 527, 5755, 50988], "temperature": 0.0, "avg_logprob": -0.05854682127634684, "compression_ratio": 1.830188679245283, "no_speech_prob": 0.030210202559828758}, {"id": 98, "seek": 51848, "start": 530.96, "end": 537.28, "text": " continued running and came down here and calculated out the finish time and printed out that our", "tokens": [50988, 7014, 2614, 293, 1361, 760, 510, 293, 15598, 484, 264, 2413, 565, 293, 13567, 484, 300, 527, 51304], "temperature": 0.0, "avg_logprob": -0.05854682127634684, "compression_ratio": 1.830188679245283, "no_speech_prob": 0.030210202559828758}, {"id": 99, "seek": 51848, "start": 537.28, "end": 544.0, "text": " script was finished in zero seconds, and then it kicked off these processes. Now, actually, I think", "tokens": [51304, 5755, 390, 4335, 294, 4018, 3949, 11, 293, 550, 309, 14609, 766, 613, 7555, 13, 823, 11, 767, 11, 286, 519, 51640], "temperature": 0.0, "avg_logprob": -0.05854682127634684, "compression_ratio": 1.830188679245283, "no_speech_prob": 0.030210202559828758}, {"id": 100, "seek": 54400, "start": 544.08, "end": 549.12, "text": " that I just said that it started sleeping first before it printed out that we were finished,", "tokens": [50368, 300, 286, 445, 848, 300, 309, 1409, 8296, 700, 949, 309, 13567, 484, 300, 321, 645, 4335, 11, 50620], "temperature": 0.0, "avg_logprob": -0.05560354284338049, "compression_ratio": 1.91796875, "no_speech_prob": 0.004904930014163256}, {"id": 101, "seek": 54400, "start": 549.12, "end": 554.24, "text": " but these processes take a little bit longer to spin up than threads, so it actually didn't even", "tokens": [50620, 457, 613, 7555, 747, 257, 707, 857, 2854, 281, 6060, 493, 813, 19314, 11, 370, 309, 767, 994, 380, 754, 50876], "temperature": 0.0, "avg_logprob": -0.05560354284338049, "compression_ratio": 1.91796875, "no_speech_prob": 0.004904930014163256}, {"id": 102, "seek": 54400, "start": 554.24, "end": 559.12, "text": " start our processes first. It actually came down here and printed that we were finished before", "tokens": [50876, 722, 527, 7555, 700, 13, 467, 767, 1361, 760, 510, 293, 13567, 300, 321, 645, 4335, 949, 51120], "temperature": 0.0, "avg_logprob": -0.05560354284338049, "compression_ratio": 1.91796875, "no_speech_prob": 0.004904930014163256}, {"id": 103, "seek": 54400, "start": 559.12, "end": 565.2, "text": " these sleep statements even first got executed. So, it printed that before it said we were sleeping,", "tokens": [51120, 613, 2817, 12363, 754, 700, 658, 17577, 13, 407, 11, 309, 13567, 300, 949, 309, 848, 321, 645, 8296, 11, 51424], "temperature": 0.0, "avg_logprob": -0.05560354284338049, "compression_ratio": 1.91796875, "no_speech_prob": 0.004904930014163256}, {"id": 104, "seek": 54400, "start": 565.2, "end": 571.44, "text": " and then after a second we were done. So, basically what this is doing is it's kicking off our processes,", "tokens": [51424, 293, 550, 934, 257, 1150, 321, 645, 1096, 13, 407, 11, 1936, 437, 341, 307, 884, 307, 309, 311, 19137, 766, 527, 7555, 11, 51736], "temperature": 0.0, "avg_logprob": -0.05560354284338049, "compression_ratio": 1.91796875, "no_speech_prob": 0.004904930014163256}, {"id": 105, "seek": 57144, "start": 571.44, "end": 576.8000000000001, "text": " but then it's going down here and running the rest of our script before our process is finished.", "tokens": [50364, 457, 550, 309, 311, 516, 760, 510, 293, 2614, 264, 1472, 295, 527, 5755, 949, 527, 1399, 307, 4335, 13, 50632], "temperature": 0.0, "avg_logprob": -0.062030524299258274, "compression_ratio": 1.7625570776255708, "no_speech_prob": 0.0006666810950264335}, {"id": 106, "seek": 57144, "start": 576.8000000000001, "end": 581.44, "text": " Now, what if we wanted our processes to finish before we calculated the finish time and before", "tokens": [50632, 823, 11, 437, 498, 321, 1415, 527, 7555, 281, 2413, 949, 321, 15598, 264, 2413, 565, 293, 949, 50864], "temperature": 0.0, "avg_logprob": -0.062030524299258274, "compression_ratio": 1.7625570776255708, "no_speech_prob": 0.0006666810950264335}, {"id": 107, "seek": 57144, "start": 581.44, "end": 586.96, "text": " we printed out that our script is finished? So, in order to do this, we can use the join method.", "tokens": [50864, 321, 13567, 484, 300, 527, 5755, 307, 4335, 30, 407, 11, 294, 1668, 281, 360, 341, 11, 321, 393, 764, 264, 3917, 3170, 13, 51140], "temperature": 0.0, "avg_logprob": -0.062030524299258274, "compression_ratio": 1.7625570776255708, "no_speech_prob": 0.0006666810950264335}, {"id": 108, "seek": 57144, "start": 586.96, "end": 596.4000000000001, "text": " So, to do this right below start, I'm going to say p1.join and p2.join. So, when we run that join", "tokens": [51140, 407, 11, 281, 360, 341, 558, 2507, 722, 11, 286, 478, 516, 281, 584, 280, 16, 13, 5134, 259, 293, 280, 17, 13, 5134, 259, 13, 407, 11, 562, 321, 1190, 300, 3917, 51612], "temperature": 0.0, "avg_logprob": -0.062030524299258274, "compression_ratio": 1.7625570776255708, "no_speech_prob": 0.0006666810950264335}, {"id": 109, "seek": 59640, "start": 596.4, "end": 602.8, "text": " method, it means that the process will finish before moving on in the script. So, now, if we", "tokens": [50364, 3170, 11, 309, 1355, 300, 264, 1399, 486, 2413, 949, 2684, 322, 294, 264, 5755, 13, 407, 11, 586, 11, 498, 321, 50684], "temperature": 0.0, "avg_logprob": -0.054179221391677856, "compression_ratio": 1.8091603053435115, "no_speech_prob": 0.11592711508274078}, {"id": 110, "seek": 59640, "start": 602.8, "end": 609.52, "text": " run this, then we can see that both processes started at almost the same time, and then they", "tokens": [50684, 1190, 341, 11, 550, 321, 393, 536, 300, 1293, 7555, 1409, 412, 1920, 264, 912, 565, 11, 293, 550, 436, 51020], "temperature": 0.0, "avg_logprob": -0.054179221391677856, "compression_ratio": 1.8091603053435115, "no_speech_prob": 0.11592711508274078}, {"id": 111, "seek": 59640, "start": 609.52, "end": 614.88, "text": " both printed that they were done sleeping after one second, and then our script continued on to", "tokens": [51020, 1293, 13567, 300, 436, 645, 1096, 8296, 934, 472, 1150, 11, 293, 550, 527, 5755, 7014, 322, 281, 51288], "temperature": 0.0, "avg_logprob": -0.054179221391677856, "compression_ratio": 1.8091603053435115, "no_speech_prob": 0.11592711508274078}, {"id": 112, "seek": 59640, "start": 614.88, "end": 620.8, "text": " print that our script had finished in about one second. Now, if using multi-processing seems a", "tokens": [51288, 4482, 300, 527, 5755, 632, 4335, 294, 466, 472, 1150, 13, 823, 11, 498, 1228, 4825, 12, 41075, 278, 2544, 257, 51584], "temperature": 0.0, "avg_logprob": -0.054179221391677856, "compression_ratio": 1.8091603053435115, "no_speech_prob": 0.11592711508274078}, {"id": 113, "seek": 59640, "start": 620.8, "end": 625.76, "text": " bit complicated right now, then definitely stick around until the end of the video, because we're", "tokens": [51584, 857, 6179, 558, 586, 11, 550, 2138, 2897, 926, 1826, 264, 917, 295, 264, 960, 11, 570, 321, 434, 51832], "temperature": 0.0, "avg_logprob": -0.054179221391677856, "compression_ratio": 1.8091603053435115, "no_speech_prob": 0.11592711508274078}, {"id": 114, "seek": 62576, "start": 625.76, "end": 631.28, "text": " going to see an easier way of how to do what we're doing here, but I think it's important to understand", "tokens": [50364, 516, 281, 536, 364, 3571, 636, 295, 577, 281, 360, 437, 321, 434, 884, 510, 11, 457, 286, 519, 309, 311, 1021, 281, 1223, 50640], "temperature": 0.0, "avg_logprob": -0.06061138370172764, "compression_ratio": 1.7326007326007327, "no_speech_prob": 0.0006666774861514568}, {"id": 115, "seek": 62576, "start": 631.28, "end": 637.28, "text": " what this is doing so far, even if we use other methods where we don't actually manually call", "tokens": [50640, 437, 341, 307, 884, 370, 1400, 11, 754, 498, 321, 764, 661, 7150, 689, 321, 500, 380, 767, 16945, 818, 50940], "temperature": 0.0, "avg_logprob": -0.06061138370172764, "compression_ratio": 1.7326007326007327, "no_speech_prob": 0.0006666774861514568}, {"id": 116, "seek": 62576, "start": 637.28, "end": 642.3199999999999, "text": " these start methods and join methods. Okay, so, right now, we're not really getting that big of a", "tokens": [50940, 613, 722, 7150, 293, 3917, 7150, 13, 1033, 11, 370, 11, 558, 586, 11, 321, 434, 406, 534, 1242, 300, 955, 295, 257, 51192], "temperature": 0.0, "avg_logprob": -0.06061138370172764, "compression_ratio": 1.7326007326007327, "no_speech_prob": 0.0006666774861514568}, {"id": 117, "seek": 62576, "start": 642.3199999999999, "end": 648.24, "text": " speedup. Now, so, our code ran in two seconds before, and now it's running in one second,", "tokens": [51192, 3073, 1010, 13, 823, 11, 370, 11, 527, 3089, 5872, 294, 732, 3949, 949, 11, 293, 586, 309, 311, 2614, 294, 472, 1150, 11, 51488], "temperature": 0.0, "avg_logprob": -0.06061138370172764, "compression_ratio": 1.7326007326007327, "no_speech_prob": 0.0006666774861514568}, {"id": 118, "seek": 62576, "start": 648.24, "end": 652.88, "text": " but that's because our function doesn't take too long, and we're only running it twice,", "tokens": [51488, 457, 300, 311, 570, 527, 2445, 1177, 380, 747, 886, 938, 11, 293, 321, 434, 787, 2614, 309, 6091, 11, 51720], "temperature": 0.0, "avg_logprob": -0.06061138370172764, "compression_ratio": 1.7326007326007327, "no_speech_prob": 0.0006666774861514568}, {"id": 119, "seek": 65288, "start": 652.88, "end": 658.4, "text": " but what if we wanted to run our function 10 times? Well, if we were to run our code synchronously,", "tokens": [50364, 457, 437, 498, 321, 1415, 281, 1190, 527, 2445, 1266, 1413, 30, 1042, 11, 498, 321, 645, 281, 1190, 527, 3089, 19331, 5098, 11, 50640], "temperature": 0.0, "avg_logprob": -0.05780481701054849, "compression_ratio": 1.7, "no_speech_prob": 0.0013249662006273866}, {"id": 120, "seek": 65288, "start": 658.4, "end": 664.64, "text": " then we can take a guess that it would take 10 seconds since one would have to finish before", "tokens": [50640, 550, 321, 393, 747, 257, 2041, 300, 309, 576, 747, 1266, 3949, 1670, 472, 576, 362, 281, 2413, 949, 50952], "temperature": 0.0, "avg_logprob": -0.05780481701054849, "compression_ratio": 1.7, "no_speech_prob": 0.0013249662006273866}, {"id": 121, "seek": 65288, "start": 664.64, "end": 669.4399999999999, "text": " the other, and we'd be running 10 in a row. But if we ran this with multiple processes,", "tokens": [50952, 264, 661, 11, 293, 321, 1116, 312, 2614, 1266, 294, 257, 5386, 13, 583, 498, 321, 5872, 341, 365, 3866, 7555, 11, 51192], "temperature": 0.0, "avg_logprob": -0.05780481701054849, "compression_ratio": 1.7, "no_speech_prob": 0.0013249662006273866}, {"id": 122, "seek": 65288, "start": 669.4399999999999, "end": 675.68, "text": " then it should be significantly faster. So, let's see an example of this. Now, instead of manually", "tokens": [51192, 550, 309, 820, 312, 10591, 4663, 13, 407, 11, 718, 311, 536, 364, 1365, 295, 341, 13, 823, 11, 2602, 295, 16945, 51504], "temperature": 0.0, "avg_logprob": -0.05780481701054849, "compression_ratio": 1.7, "no_speech_prob": 0.0013249662006273866}, {"id": 123, "seek": 65288, "start": 675.68, "end": 681.52, "text": " creating 10 different processes, let's instead create and start these in a loop. So, to do this,", "tokens": [51504, 4084, 1266, 819, 7555, 11, 718, 311, 2602, 1884, 293, 722, 613, 294, 257, 6367, 13, 407, 11, 281, 360, 341, 11, 51796], "temperature": 0.0, "avg_logprob": -0.05780481701054849, "compression_ratio": 1.7, "no_speech_prob": 0.0013249662006273866}, {"id": 124, "seek": 68152, "start": 682.3199999999999, "end": 688.56, "text": " I can come up here, and I'm going to copy this whole part here, and now I'm just going to", "tokens": [50404, 286, 393, 808, 493, 510, 11, 293, 286, 478, 516, 281, 5055, 341, 1379, 644, 510, 11, 293, 586, 286, 478, 445, 516, 281, 50716], "temperature": 0.0, "avg_logprob": -0.10363590717315674, "compression_ratio": 1.6382978723404256, "no_speech_prob": 0.0012065240880474448}, {"id": 125, "seek": 68152, "start": 688.56, "end": 696.56, "text": " overwrite all the code that we have here so far, and I'm going to say 4 underscore in range of 10,", "tokens": [50716, 670, 21561, 439, 264, 3089, 300, 321, 362, 510, 370, 1400, 11, 293, 286, 478, 516, 281, 584, 1017, 37556, 294, 3613, 295, 1266, 11, 51116], "temperature": 0.0, "avg_logprob": -0.10363590717315674, "compression_ratio": 1.6382978723404256, "no_speech_prob": 0.0012065240880474448}, {"id": 126, "seek": 68152, "start": 697.4399999999999, "end": 704.24, "text": " and we'll say p is equal to multi-processing dot process with a target set to the do something", "tokens": [51160, 293, 321, 603, 584, 280, 307, 2681, 281, 4825, 12, 41075, 278, 5893, 1399, 365, 257, 3779, 992, 281, 264, 360, 746, 51500], "temperature": 0.0, "avg_logprob": -0.10363590717315674, "compression_ratio": 1.6382978723404256, "no_speech_prob": 0.0012065240880474448}, {"id": 127, "seek": 68152, "start": 704.24, "end": 711.12, "text": " function. And now, let's also start that process here within our loop. Now, if you're unfamiliar with", "tokens": [51500, 2445, 13, 400, 586, 11, 718, 311, 611, 722, 300, 1399, 510, 1951, 527, 6367, 13, 823, 11, 498, 291, 434, 29415, 365, 51844], "temperature": 0.0, "avg_logprob": -0.10363590717315674, "compression_ratio": 1.6382978723404256, "no_speech_prob": 0.0012065240880474448}, {"id": 128, "seek": 71112, "start": 711.12, "end": 716.72, "text": " the underscore in Python, basically, that's just a throwaway variable name. It's just saying that", "tokens": [50364, 264, 37556, 294, 15329, 11, 1936, 11, 300, 311, 445, 257, 3507, 10318, 7006, 1315, 13, 467, 311, 445, 1566, 300, 50644], "temperature": 0.0, "avg_logprob": -0.07384298245112102, "compression_ratio": 1.75, "no_speech_prob": 0.000755359826143831}, {"id": 129, "seek": 71112, "start": 716.72, "end": 722.8, "text": " we're not actually using the integer from this range in the loop. So, we just have something as", "tokens": [50644, 321, 434, 406, 767, 1228, 264, 24922, 490, 341, 3613, 294, 264, 6367, 13, 407, 11, 321, 445, 362, 746, 382, 50948], "temperature": 0.0, "avg_logprob": -0.07384298245112102, "compression_ratio": 1.75, "no_speech_prob": 0.000755359826143831}, {"id": 130, "seek": 71112, "start": 722.8, "end": 728.48, "text": " a throwaway variable there. So, we're starting all these processes here within our loop, but we can't", "tokens": [50948, 257, 3507, 10318, 7006, 456, 13, 407, 11, 321, 434, 2891, 439, 613, 7555, 510, 1951, 527, 6367, 11, 457, 321, 393, 380, 51232], "temperature": 0.0, "avg_logprob": -0.07384298245112102, "compression_ratio": 1.75, "no_speech_prob": 0.000755359826143831}, {"id": 131, "seek": 71112, "start": 728.48, "end": 736.08, "text": " do a p dot join within the loop, because it would run join on the process before looping through", "tokens": [51232, 360, 257, 280, 5893, 3917, 1951, 264, 6367, 11, 570, 309, 576, 1190, 3917, 322, 264, 1399, 949, 6367, 278, 807, 51612], "temperature": 0.0, "avg_logprob": -0.07384298245112102, "compression_ratio": 1.75, "no_speech_prob": 0.000755359826143831}, {"id": 132, "seek": 73608, "start": 736.1600000000001, "end": 741.12, "text": " and creating and starting the next process in the loop. So, it would basically be the same", "tokens": [50368, 293, 4084, 293, 2891, 264, 958, 1399, 294, 264, 6367, 13, 407, 11, 309, 576, 1936, 312, 264, 912, 50616], "temperature": 0.0, "avg_logprob": -0.05179267401223654, "compression_ratio": 1.7190476190476192, "no_speech_prob": 0.010012555867433548}, {"id": 133, "seek": 73608, "start": 741.12, "end": 747.2, "text": " as running it synchronously. So, we need a way that we can start all of these processes in one loop,", "tokens": [50616, 382, 2614, 309, 19331, 5098, 13, 407, 11, 321, 643, 257, 636, 300, 321, 393, 722, 439, 295, 613, 7555, 294, 472, 6367, 11, 50920], "temperature": 0.0, "avg_logprob": -0.05179267401223654, "compression_ratio": 1.7190476190476192, "no_speech_prob": 0.010012555867433548}, {"id": 134, "seek": 73608, "start": 747.2, "end": 751.5200000000001, "text": " and then loop through those processes again, and run the join method on them", "tokens": [50920, 293, 550, 6367, 807, 729, 7555, 797, 11, 293, 1190, 264, 3917, 3170, 322, 552, 51136], "temperature": 0.0, "avg_logprob": -0.05179267401223654, "compression_ratio": 1.7190476190476192, "no_speech_prob": 0.010012555867433548}, {"id": 135, "seek": 73608, "start": 751.5200000000001, "end": 756.88, "text": " so that they all finish before the end of our script. So, to do this, let's just append each", "tokens": [51136, 370, 300, 436, 439, 2413, 949, 264, 917, 295, 527, 5755, 13, 407, 11, 281, 360, 341, 11, 718, 311, 445, 34116, 1184, 51404], "temperature": 0.0, "avg_logprob": -0.05179267401223654, "compression_ratio": 1.7190476190476192, "no_speech_prob": 0.010012555867433548}, {"id": 136, "seek": 75688, "start": 756.88, "end": 765.84, "text": " process to a list. So, above our for loop here, I'm just going to create a list called processes", "tokens": [50364, 1399, 281, 257, 1329, 13, 407, 11, 3673, 527, 337, 6367, 510, 11, 286, 478, 445, 516, 281, 1884, 257, 1329, 1219, 7555, 50812], "temperature": 0.0, "avg_logprob": -0.05486396031501966, "compression_ratio": 1.8024691358024691, "no_speech_prob": 0.047419339418411255}, {"id": 137, "seek": 75688, "start": 765.84, "end": 773.6, "text": " and set that to an empty list. And then below p dot start, I'm going to say processes dot append,", "tokens": [50812, 293, 992, 300, 281, 364, 6707, 1329, 13, 400, 550, 2507, 280, 5893, 722, 11, 286, 478, 516, 281, 584, 7555, 5893, 34116, 11, 51200], "temperature": 0.0, "avg_logprob": -0.05486396031501966, "compression_ratio": 1.8024691358024691, "no_speech_prob": 0.047419339418411255}, {"id": 138, "seek": 75688, "start": 773.6, "end": 782.32, "text": " and I will append each process to our processes list. And now, here below our for loop, I'm going", "tokens": [51200, 293, 286, 486, 34116, 1184, 1399, 281, 527, 7555, 1329, 13, 400, 586, 11, 510, 2507, 527, 337, 6367, 11, 286, 478, 516, 51636], "temperature": 0.0, "avg_logprob": -0.05486396031501966, "compression_ratio": 1.8024691358024691, "no_speech_prob": 0.047419339418411255}, {"id": 139, "seek": 78232, "start": 782.32, "end": 793.44, "text": " to say for process in processes, let's do a process dot join. Okay, so just one more time here. We are", "tokens": [50364, 281, 584, 337, 1399, 294, 7555, 11, 718, 311, 360, 257, 1399, 5893, 3917, 13, 1033, 11, 370, 445, 472, 544, 565, 510, 13, 492, 366, 50920], "temperature": 0.0, "avg_logprob": -0.08896358013153076, "compression_ratio": 1.6108108108108108, "no_speech_prob": 0.0033763356041163206}, {"id": 140, "seek": 78232, "start": 794.24, "end": 800.32, "text": " looping over a range of 10. So, we're going to do this loop 10 times here. And each time through", "tokens": [50960, 6367, 278, 670, 257, 3613, 295, 1266, 13, 407, 11, 321, 434, 516, 281, 360, 341, 6367, 1266, 1413, 510, 13, 400, 1184, 565, 807, 51264], "temperature": 0.0, "avg_logprob": -0.08896358013153076, "compression_ratio": 1.6108108108108108, "no_speech_prob": 0.0033763356041163206}, {"id": 141, "seek": 78232, "start": 800.32, "end": 806.32, "text": " the loop, we are creating a new process with this target of do something. And we are starting that", "tokens": [51264, 264, 6367, 11, 321, 366, 4084, 257, 777, 1399, 365, 341, 3779, 295, 360, 746, 13, 400, 321, 366, 2891, 300, 51564], "temperature": 0.0, "avg_logprob": -0.08896358013153076, "compression_ratio": 1.6108108108108108, "no_speech_prob": 0.0033763356041163206}, {"id": 142, "seek": 80632, "start": 806.32, "end": 813.36, "text": " process. And then we are appending that process to a processes list. So, then after that loop is", "tokens": [50364, 1399, 13, 400, 550, 321, 366, 724, 2029, 300, 1399, 281, 257, 7555, 1329, 13, 407, 11, 550, 934, 300, 6367, 307, 50716], "temperature": 0.0, "avg_logprob": -0.05049629700489533, "compression_ratio": 1.8968253968253967, "no_speech_prob": 0.04083889722824097}, {"id": 143, "seek": 80632, "start": 813.36, "end": 817.5200000000001, "text": " complete, and all of our processes have been started, we're coming through and looping over all", "tokens": [50716, 3566, 11, 293, 439, 295, 527, 7555, 362, 668, 1409, 11, 321, 434, 1348, 807, 293, 6367, 278, 670, 439, 50924], "temperature": 0.0, "avg_logprob": -0.05049629700489533, "compression_ratio": 1.8968253968253967, "no_speech_prob": 0.04083889722824097}, {"id": 144, "seek": 80632, "start": 817.5200000000001, "end": 823.0400000000001, "text": " those processes, and we are joining them. And again, when we join a process, when we run the join", "tokens": [50924, 729, 7555, 11, 293, 321, 366, 5549, 552, 13, 400, 797, 11, 562, 321, 3917, 257, 1399, 11, 562, 321, 1190, 264, 3917, 51200], "temperature": 0.0, "avg_logprob": -0.05049629700489533, "compression_ratio": 1.8968253968253967, "no_speech_prob": 0.04083889722824097}, {"id": 145, "seek": 80632, "start": 823.0400000000001, "end": 828.5600000000001, "text": " method, it means that it is going to wait until that finishes before continuing on to the rest", "tokens": [51200, 3170, 11, 309, 1355, 300, 309, 307, 516, 281, 1699, 1826, 300, 23615, 949, 9289, 322, 281, 264, 1472, 51476], "temperature": 0.0, "avg_logprob": -0.05049629700489533, "compression_ratio": 1.8968253968253967, "no_speech_prob": 0.04083889722824097}, {"id": 146, "seek": 80632, "start": 828.5600000000001, "end": 833.36, "text": " of the script. So, it'll finish before it comes down here and calculates the finish time and", "tokens": [51476, 295, 264, 5755, 13, 407, 11, 309, 603, 2413, 949, 309, 1487, 760, 510, 293, 4322, 1024, 264, 2413, 565, 293, 51716], "temperature": 0.0, "avg_logprob": -0.05049629700489533, "compression_ratio": 1.8968253968253967, "no_speech_prob": 0.04083889722824097}, {"id": 147, "seek": 83336, "start": 833.36, "end": 838.24, "text": " prints that our script is finished. So, we're running this do something function 10 times,", "tokens": [50364, 22305, 300, 527, 5755, 307, 4335, 13, 407, 11, 321, 434, 2614, 341, 360, 746, 2445, 1266, 1413, 11, 50608], "temperature": 0.0, "avg_logprob": -0.04555005542302536, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.011685934849083424}, {"id": 148, "seek": 83336, "start": 838.24, "end": 843.36, "text": " and it sleeps for one second every time. But since we're using multiple processes, it'll just run", "tokens": [50608, 293, 309, 37991, 337, 472, 1150, 633, 565, 13, 583, 1670, 321, 434, 1228, 3866, 7555, 11, 309, 603, 445, 1190, 50864], "temperature": 0.0, "avg_logprob": -0.04555005542302536, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.011685934849083424}, {"id": 149, "seek": 83336, "start": 843.36, "end": 848.88, "text": " all of these in parallel at the same time. So, instead of it taking 10 seconds, let's save this", "tokens": [50864, 439, 295, 613, 294, 8952, 412, 264, 912, 565, 13, 407, 11, 2602, 295, 309, 1940, 1266, 3949, 11, 718, 311, 3155, 341, 51140], "temperature": 0.0, "avg_logprob": -0.04555005542302536, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.011685934849083424}, {"id": 150, "seek": 83336, "start": 848.88, "end": 855.52, "text": " and run this and see how long it actually takes. So, we can see that even running the function 10", "tokens": [51140, 293, 1190, 341, 293, 536, 577, 938, 309, 767, 2516, 13, 407, 11, 321, 393, 536, 300, 754, 2614, 264, 2445, 1266, 51472], "temperature": 0.0, "avg_logprob": -0.04555005542302536, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.011685934849083424}, {"id": 151, "seek": 83336, "start": 855.52, "end": 861.12, "text": " times, we're still finishing this in about one second. Now, that might seem a little strange,", "tokens": [51472, 1413, 11, 321, 434, 920, 12693, 341, 294, 466, 472, 1150, 13, 823, 11, 300, 1062, 1643, 257, 707, 5861, 11, 51752], "temperature": 0.0, "avg_logprob": -0.04555005542302536, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.011685934849083424}, {"id": 152, "seek": 86112, "start": 861.12, "end": 867.12, "text": " because I don't actually have 10 cores on this machine. But your computer has ways of switching", "tokens": [50364, 570, 286, 500, 380, 767, 362, 1266, 24826, 322, 341, 3479, 13, 583, 428, 3820, 575, 2098, 295, 16493, 50664], "temperature": 0.0, "avg_logprob": -0.0577715044099141, "compression_ratio": 1.701067615658363, "no_speech_prob": 0.0004728407657239586}, {"id": 153, "seek": 86112, "start": 867.12, "end": 873.36, "text": " off between cores when one of them isn't too busy. So, even though we had more processes than we do", "tokens": [50664, 766, 1296, 24826, 562, 472, 295, 552, 1943, 380, 886, 5856, 13, 407, 11, 754, 1673, 321, 632, 544, 7555, 813, 321, 360, 50976], "temperature": 0.0, "avg_logprob": -0.0577715044099141, "compression_ratio": 1.701067615658363, "no_speech_prob": 0.0004728407657239586}, {"id": 154, "seek": 86112, "start": 873.36, "end": 878.32, "text": " cores, it's still finished in about a second. So, that's pretty good. Okay, so now let's look at", "tokens": [50976, 24826, 11, 309, 311, 920, 4335, 294, 466, 257, 1150, 13, 407, 11, 300, 311, 1238, 665, 13, 1033, 11, 370, 586, 718, 311, 574, 412, 51224], "temperature": 0.0, "avg_logprob": -0.0577715044099141, "compression_ratio": 1.701067615658363, "no_speech_prob": 0.0004728407657239586}, {"id": 155, "seek": 86112, "start": 878.32, "end": 883.12, "text": " how we can pass in arguments into our function. So, right now, we're running a function that", "tokens": [51224, 577, 321, 393, 1320, 294, 12869, 666, 527, 2445, 13, 407, 11, 558, 586, 11, 321, 434, 2614, 257, 2445, 300, 51464], "temperature": 0.0, "avg_logprob": -0.0577715044099141, "compression_ratio": 1.701067615658363, "no_speech_prob": 0.0004728407657239586}, {"id": 156, "seek": 86112, "start": 883.12, "end": 888.64, "text": " doesn't accept any arguments. But let's add a couple of arguments real quick. So, right now,", "tokens": [51464, 1177, 380, 3241, 604, 12869, 13, 583, 718, 311, 909, 257, 1916, 295, 12869, 957, 1702, 13, 407, 11, 558, 586, 11, 51740], "temperature": 0.0, "avg_logprob": -0.0577715044099141, "compression_ratio": 1.701067615658363, "no_speech_prob": 0.0004728407657239586}, {"id": 157, "seek": 88864, "start": 888.64, "end": 894.56, "text": " we're just sleeping for one second. So, let's add an argument that specifies how long to sleep.", "tokens": [50364, 321, 434, 445, 8296, 337, 472, 1150, 13, 407, 11, 718, 311, 909, 364, 6770, 300, 1608, 11221, 577, 938, 281, 2817, 13, 50660], "temperature": 0.0, "avg_logprob": -0.06253549631904154, "compression_ratio": 1.7674418604651163, "no_speech_prob": 0.0006666671833954751}, {"id": 158, "seek": 88864, "start": 894.56, "end": 900.48, "text": " So, up here, we will accept an argument. And I'm just going to pass in an argument of seconds.", "tokens": [50660, 407, 11, 493, 510, 11, 321, 486, 3241, 364, 6770, 13, 400, 286, 478, 445, 516, 281, 1320, 294, 364, 6770, 295, 3949, 13, 50956], "temperature": 0.0, "avg_logprob": -0.06253549631904154, "compression_ratio": 1.7674418604651163, "no_speech_prob": 0.0006666671833954751}, {"id": 159, "seek": 88864, "start": 900.48, "end": 909.84, "text": " And let's also change that we are going to sleep for that number of seconds. And let me also put", "tokens": [50956, 400, 718, 311, 611, 1319, 300, 321, 366, 516, 281, 2817, 337, 300, 1230, 295, 3949, 13, 400, 718, 385, 611, 829, 51424], "temperature": 0.0, "avg_logprob": -0.06253549631904154, "compression_ratio": 1.7674418604651163, "no_speech_prob": 0.0006666671833954751}, {"id": 160, "seek": 88864, "start": 910.88, "end": 916.56, "text": " a parentheses s there as well. Now, this needs to be an f string, since we're now using this", "tokens": [51476, 257, 34153, 262, 456, 382, 731, 13, 823, 11, 341, 2203, 281, 312, 364, 283, 6798, 11, 1670, 321, 434, 586, 1228, 341, 51760], "temperature": 0.0, "avg_logprob": -0.06253549631904154, "compression_ratio": 1.7674418604651163, "no_speech_prob": 0.0006666671833954751}, {"id": 161, "seek": 91656, "start": 916.56, "end": 923.5999999999999, "text": " variable here within our string. Now, I want to sleep for that number of seconds. Okay, so with", "tokens": [50364, 7006, 510, 1951, 527, 6798, 13, 823, 11, 286, 528, 281, 2817, 337, 300, 1230, 295, 3949, 13, 1033, 11, 370, 365, 50716], "temperature": 0.0, "avg_logprob": -0.0631606528099547, "compression_ratio": 1.8743961352657006, "no_speech_prob": 0.00020987846073694527}, {"id": 162, "seek": 91656, "start": 923.5999999999999, "end": 929.1199999999999, "text": " that small change, our do something function now accepts an argument of seconds. And then it'll", "tokens": [50716, 300, 1359, 1319, 11, 527, 360, 746, 2445, 586, 33538, 364, 6770, 295, 3949, 13, 400, 550, 309, 603, 50992], "temperature": 0.0, "avg_logprob": -0.0631606528099547, "compression_ratio": 1.8743961352657006, "no_speech_prob": 0.00020987846073694527}, {"id": 163, "seek": 91656, "start": 929.1199999999999, "end": 933.3599999999999, "text": " print out that we're sleeping for that number of seconds. And then it will actually sleep for that", "tokens": [50992, 4482, 484, 300, 321, 434, 8296, 337, 300, 1230, 295, 3949, 13, 400, 550, 309, 486, 767, 2817, 337, 300, 51204], "temperature": 0.0, "avg_logprob": -0.0631606528099547, "compression_ratio": 1.8743961352657006, "no_speech_prob": 0.00020987846073694527}, {"id": 164, "seek": 91656, "start": 933.3599999999999, "end": 940.4799999999999, "text": " number of seconds. So, let's pass in seconds as an argument to this function. And we need to pass", "tokens": [51204, 1230, 295, 3949, 13, 407, 11, 718, 311, 1320, 294, 3949, 382, 364, 6770, 281, 341, 2445, 13, 400, 321, 643, 281, 1320, 51560], "temperature": 0.0, "avg_logprob": -0.0631606528099547, "compression_ratio": 1.8743961352657006, "no_speech_prob": 0.00020987846073694527}, {"id": 165, "seek": 94048, "start": 940.48, "end": 947.28, "text": " that in as a list of arguments to our process. So, I'll say, down here, where we are saying that", "tokens": [50364, 300, 294, 382, 257, 1329, 295, 12869, 281, 527, 1399, 13, 407, 11, 286, 603, 584, 11, 760, 510, 11, 689, 321, 366, 1566, 300, 50704], "temperature": 0.0, "avg_logprob": -0.07495390927350079, "compression_ratio": 1.8009478672985781, "no_speech_prob": 0.034096140414476395}, {"id": 166, "seek": 94048, "start": 947.28, "end": 953.76, "text": " our target is that do something function, we can also pass in an argument of arcs. And we'll pass", "tokens": [50704, 527, 3779, 307, 300, 360, 746, 2445, 11, 321, 393, 611, 1320, 294, 364, 6770, 295, 10346, 82, 13, 400, 321, 603, 1320, 51028], "temperature": 0.0, "avg_logprob": -0.07495390927350079, "compression_ratio": 1.8009478672985781, "no_speech_prob": 0.034096140414476395}, {"id": 167, "seek": 94048, "start": 953.76, "end": 961.2, "text": " that in as a list of arguments. So, I'll do 1.5. So, now, instead of sleeping for one second", "tokens": [51028, 300, 294, 382, 257, 1329, 295, 12869, 13, 407, 11, 286, 603, 360, 502, 13, 20, 13, 407, 11, 586, 11, 2602, 295, 8296, 337, 472, 1150, 51400], "temperature": 0.0, "avg_logprob": -0.07495390927350079, "compression_ratio": 1.8009478672985781, "no_speech_prob": 0.034096140414476395}, {"id": 168, "seek": 94048, "start": 961.9200000000001, "end": 967.6800000000001, "text": " for 10 different times, now it's going to sleep for 1.5 seconds for 10 different times. Now,", "tokens": [51436, 337, 1266, 819, 1413, 11, 586, 309, 311, 516, 281, 2817, 337, 502, 13, 20, 3949, 337, 1266, 819, 1413, 13, 823, 11, 51724], "temperature": 0.0, "avg_logprob": -0.07495390927350079, "compression_ratio": 1.8009478672985781, "no_speech_prob": 0.034096140414476395}, {"id": 169, "seek": 96768, "start": 967.68, "end": 973.76, "text": " unlike with threads, in order to pass arguments to a multi processing process, the arguments must", "tokens": [50364, 8343, 365, 19314, 11, 294, 1668, 281, 1320, 12869, 281, 257, 4825, 9007, 1399, 11, 264, 12869, 1633, 50668], "temperature": 0.0, "avg_logprob": -0.04712648825211958, "compression_ratio": 1.672340425531915, "no_speech_prob": 0.0003569653781596571}, {"id": 170, "seek": 96768, "start": 973.76, "end": 980.0, "text": " be able to be serialized using pickle. Now, if you don't know what that means, basically serializing", "tokens": [50668, 312, 1075, 281, 312, 17436, 1602, 1228, 31433, 13, 823, 11, 498, 291, 500, 380, 458, 437, 300, 1355, 11, 1936, 17436, 3319, 50980], "temperature": 0.0, "avg_logprob": -0.04712648825211958, "compression_ratio": 1.672340425531915, "no_speech_prob": 0.0003569653781596571}, {"id": 171, "seek": 96768, "start": 980.0, "end": 986.56, "text": " something with pickle means that we're converting Python objects into a format that can be deconstructed", "tokens": [50980, 746, 365, 31433, 1355, 300, 321, 434, 29942, 15329, 6565, 666, 257, 7877, 300, 393, 312, 49473, 1757, 292, 51308], "temperature": 0.0, "avg_logprob": -0.04712648825211958, "compression_ratio": 1.672340425531915, "no_speech_prob": 0.0003569653781596571}, {"id": 172, "seek": 96768, "start": 986.56, "end": 992.88, "text": " and reconstructed in another Python script. So, now we should expect our function to take", "tokens": [51308, 293, 31499, 292, 294, 1071, 15329, 5755, 13, 407, 11, 586, 321, 820, 2066, 527, 2445, 281, 747, 51624], "temperature": 0.0, "avg_logprob": -0.04712648825211958, "compression_ratio": 1.672340425531915, "no_speech_prob": 0.0003569653781596571}, {"id": 173, "seek": 99288, "start": 992.88, "end": 1000.4, "text": " 1.5 seconds instead. So, if I save this and run it, then we can see that now our script is finishing", "tokens": [50364, 502, 13, 20, 3949, 2602, 13, 407, 11, 498, 286, 3155, 341, 293, 1190, 309, 11, 550, 321, 393, 536, 300, 586, 527, 5755, 307, 12693, 50740], "temperature": 0.0, "avg_logprob": -0.057273391634225845, "compression_ratio": 1.7985347985347986, "no_speech_prob": 0.015904292464256287}, {"id": 174, "seek": 99288, "start": 1000.4, "end": 1006.8, "text": " in about 1.5 seconds. Okay, so, I said before that I was going to show you the older way of doing", "tokens": [50740, 294, 466, 502, 13, 20, 3949, 13, 1033, 11, 370, 11, 286, 848, 949, 300, 286, 390, 516, 281, 855, 291, 264, 4906, 636, 295, 884, 51060], "temperature": 0.0, "avg_logprob": -0.057273391634225845, "compression_ratio": 1.7985347985347986, "no_speech_prob": 0.015904292464256287}, {"id": 175, "seek": 99288, "start": 1006.8, "end": 1012.32, "text": " multi processing, and then I'd show you what I believe is a faster, easier way of doing this.", "tokens": [51060, 4825, 9007, 11, 293, 550, 286, 1116, 855, 291, 437, 286, 1697, 307, 257, 4663, 11, 3571, 636, 295, 884, 341, 13, 51336], "temperature": 0.0, "avg_logprob": -0.057273391634225845, "compression_ratio": 1.7985347985347986, "no_speech_prob": 0.015904292464256287}, {"id": 176, "seek": 99288, "start": 1012.32, "end": 1017.52, "text": " And I still wanted to show you the manual way of creating these processes, because I think this can", "tokens": [51336, 400, 286, 920, 1415, 281, 855, 291, 264, 9688, 636, 295, 4084, 613, 7555, 11, 570, 286, 519, 341, 393, 51596], "temperature": 0.0, "avg_logprob": -0.057273391634225845, "compression_ratio": 1.7985347985347986, "no_speech_prob": 0.015904292464256287}, {"id": 177, "seek": 99288, "start": 1017.52, "end": 1022.16, "text": " still be useful depending on what you're doing. And also, I think it's better to learn this manual", "tokens": [51596, 920, 312, 4420, 5413, 322, 437, 291, 434, 884, 13, 400, 611, 11, 286, 519, 309, 311, 1101, 281, 1466, 341, 9688, 51828], "temperature": 0.0, "avg_logprob": -0.057273391634225845, "compression_ratio": 1.7985347985347986, "no_speech_prob": 0.015904292464256287}, {"id": 178, "seek": 102216, "start": 1022.48, "end": 1028.96, "text": " first to understand a bit better what's going on in the background. But in Python 3.2, they added", "tokens": [50380, 700, 281, 1223, 257, 857, 1101, 437, 311, 516, 322, 294, 264, 3678, 13, 583, 294, 15329, 805, 13, 17, 11, 436, 3869, 50704], "temperature": 0.0, "avg_logprob": -0.05722554954322609, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0031723123975098133}, {"id": 179, "seek": 102216, "start": 1028.96, "end": 1034.6399999999999, "text": " something called a process pull executor. And in a lot of cases, this will be an easier and more", "tokens": [50704, 746, 1219, 257, 1399, 2235, 7568, 284, 13, 400, 294, 257, 688, 295, 3331, 11, 341, 486, 312, 364, 3571, 293, 544, 50988], "temperature": 0.0, "avg_logprob": -0.05722554954322609, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0031723123975098133}, {"id": 180, "seek": 102216, "start": 1034.6399999999999, "end": 1040.0, "text": " efficient way to run multiple processes. And it also allows us to easily switch over to using", "tokens": [50988, 7148, 636, 281, 1190, 3866, 7555, 13, 400, 309, 611, 4045, 505, 281, 3612, 3679, 670, 281, 1228, 51256], "temperature": 0.0, "avg_logprob": -0.05722554954322609, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0031723123975098133}, {"id": 181, "seek": 102216, "start": 1040.0, "end": 1045.04, "text": " multiple threads instead of processes as well, depending on the problem that we're trying to", "tokens": [51256, 3866, 19314, 2602, 295, 7555, 382, 731, 11, 5413, 322, 264, 1154, 300, 321, 434, 1382, 281, 51508], "temperature": 0.0, "avg_logprob": -0.05722554954322609, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0031723123975098133}, {"id": 182, "seek": 102216, "start": 1045.04, "end": 1051.84, "text": " solve. So, let's replace what we currently have and instead use this process pull executor.", "tokens": [51508, 5039, 13, 407, 11, 718, 311, 7406, 437, 321, 4362, 362, 293, 2602, 764, 341, 1399, 2235, 7568, 284, 13, 51848], "temperature": 0.0, "avg_logprob": -0.05722554954322609, "compression_ratio": 1.6953405017921146, "no_speech_prob": 0.0031723123975098133}, {"id": 183, "seek": 105216, "start": 1052.24, "end": 1057.52, "text": " Now, this actually isn't in the multi processing module. It's in the concurrent futures module", "tokens": [50368, 823, 11, 341, 767, 1943, 380, 294, 264, 4825, 9007, 10088, 13, 467, 311, 294, 264, 37702, 26071, 10088, 50632], "temperature": 0.0, "avg_logprob": -0.06474684010381283, "compression_ratio": 1.8492063492063493, "no_speech_prob": 0.0002868396695703268}, {"id": 184, "seek": 105216, "start": 1057.52, "end": 1064.72, "text": " instead. So, up here at the top, let's instead import concurrent futures. And I actually don't", "tokens": [50632, 2602, 13, 407, 11, 493, 510, 412, 264, 1192, 11, 718, 311, 2602, 974, 37702, 26071, 13, 400, 286, 767, 500, 380, 50992], "temperature": 0.0, "avg_logprob": -0.06474684010381283, "compression_ratio": 1.8492063492063493, "no_speech_prob": 0.0002868396695703268}, {"id": 185, "seek": 105216, "start": 1064.72, "end": 1071.44, "text": " think I need multi processing anymore. So, I'm just going to say import concurrent futures.", "tokens": [50992, 519, 286, 643, 4825, 9007, 3602, 13, 407, 11, 286, 478, 445, 516, 281, 584, 974, 37702, 26071, 13, 51328], "temperature": 0.0, "avg_logprob": -0.06474684010381283, "compression_ratio": 1.8492063492063493, "no_speech_prob": 0.0002868396695703268}, {"id": 186, "seek": 105216, "start": 1071.44, "end": 1075.6000000000001, "text": " Now, I'm going to leave everything else that I have here for now, so that we can see the", "tokens": [51328, 823, 11, 286, 478, 516, 281, 1856, 1203, 1646, 300, 286, 362, 510, 337, 586, 11, 370, 300, 321, 393, 536, 264, 51536], "temperature": 0.0, "avg_logprob": -0.06474684010381283, "compression_ratio": 1.8492063492063493, "no_speech_prob": 0.0002868396695703268}, {"id": 187, "seek": 105216, "start": 1075.6000000000001, "end": 1081.68, "text": " difference between these. Now, when we use this process pull executor, it's usually best to use", "tokens": [51536, 2649, 1296, 613, 13, 823, 11, 562, 321, 764, 341, 1399, 2235, 7568, 284, 11, 309, 311, 2673, 1151, 281, 764, 51840], "temperature": 0.0, "avg_logprob": -0.06474684010381283, "compression_ratio": 1.8492063492063493, "no_speech_prob": 0.0002868396695703268}, {"id": 188, "seek": 108168, "start": 1081.68, "end": 1087.6000000000001, "text": " this with a context manager. So, above our processes list here, I'm going to do the same thing that", "tokens": [50364, 341, 365, 257, 4319, 6598, 13, 407, 11, 3673, 527, 7555, 1329, 510, 11, 286, 478, 516, 281, 360, 264, 912, 551, 300, 50660], "temperature": 0.0, "avg_logprob": -0.08133521080017089, "compression_ratio": 1.553191489361702, "no_speech_prob": 0.00037995853926986456}, {"id": 189, "seek": 108168, "start": 1087.6000000000001, "end": 1094.3200000000002, "text": " we already have. But just with our concurrent futures module instead. So, I'm going to say with", "tokens": [50660, 321, 1217, 362, 13, 583, 445, 365, 527, 37702, 26071, 10088, 2602, 13, 407, 11, 286, 478, 516, 281, 584, 365, 50996], "temperature": 0.0, "avg_logprob": -0.08133521080017089, "compression_ratio": 1.553191489361702, "no_speech_prob": 0.00037995853926986456}, {"id": 190, "seek": 108168, "start": 1094.3200000000002, "end": 1103.2, "text": " concurrent dot futures dot process pull executor, and make sure you get those capitalizations in", "tokens": [50996, 37702, 5893, 26071, 5893, 1399, 2235, 7568, 284, 11, 293, 652, 988, 291, 483, 729, 4238, 14455, 294, 51440], "temperature": 0.0, "avg_logprob": -0.08133521080017089, "compression_ratio": 1.553191489361702, "no_speech_prob": 0.00037995853926986456}, {"id": 191, "seek": 110320, "start": 1103.2, "end": 1112.8, "text": " the right place. And then, we will say, whoops, we'll say as executor. And now, within our or", "tokens": [50364, 264, 558, 1081, 13, 400, 550, 11, 321, 486, 584, 11, 567, 3370, 11, 321, 603, 584, 382, 7568, 284, 13, 400, 586, 11, 1951, 527, 420, 50844], "temperature": 0.0, "avg_logprob": -0.07121471756870307, "compression_ratio": 1.7488584474885844, "no_speech_prob": 0.03514174371957779}, {"id": 192, "seek": 110320, "start": 1112.8, "end": 1117.6000000000001, "text": " with our executor here, there are a couple of different methods that we can use. Now, if we", "tokens": [50844, 365, 527, 7568, 284, 510, 11, 456, 366, 257, 1916, 295, 819, 7150, 300, 321, 393, 764, 13, 823, 11, 498, 321, 51084], "temperature": 0.0, "avg_logprob": -0.07121471756870307, "compression_ratio": 1.7488584474885844, "no_speech_prob": 0.03514174371957779}, {"id": 193, "seek": 110320, "start": 1117.6000000000001, "end": 1123.68, "text": " want to execute the function once at a time, then we can use the submit method. So, the submit method", "tokens": [51084, 528, 281, 14483, 264, 2445, 1564, 412, 257, 565, 11, 550, 321, 393, 764, 264, 10315, 3170, 13, 407, 11, 264, 10315, 3170, 51388], "temperature": 0.0, "avg_logprob": -0.07121471756870307, "compression_ratio": 1.7488584474885844, "no_speech_prob": 0.03514174371957779}, {"id": 194, "seek": 110320, "start": 1123.68, "end": 1129.52, "text": " schedules a function to be executed and returns a future object. So, let's add this in and then", "tokens": [51388, 28078, 257, 2445, 281, 312, 17577, 293, 11247, 257, 2027, 2657, 13, 407, 11, 718, 311, 909, 341, 294, 293, 550, 51680], "temperature": 0.0, "avg_logprob": -0.07121471756870307, "compression_ratio": 1.7488584474885844, "no_speech_prob": 0.03514174371957779}, {"id": 195, "seek": 112952, "start": 1129.6, "end": 1137.92, "text": " I'll explain this a bit more. So, I'm going to say f one is equal to executor dot submit. And I will", "tokens": [50368, 286, 603, 2903, 341, 257, 857, 544, 13, 407, 11, 286, 478, 516, 281, 584, 283, 472, 307, 2681, 281, 7568, 284, 5893, 10315, 13, 400, 286, 486, 50784], "temperature": 0.0, "avg_logprob": -0.07483764128251509, "compression_ratio": 1.6043956043956045, "no_speech_prob": 0.0007553822360932827}, {"id": 196, "seek": 112952, "start": 1137.92, "end": 1146.0, "text": " submit that do something function. And let's also pass in an argument of one. So, again, the submit", "tokens": [50784, 10315, 300, 360, 746, 2445, 13, 400, 718, 311, 611, 1320, 294, 364, 6770, 295, 472, 13, 407, 11, 797, 11, 264, 10315, 51188], "temperature": 0.0, "avg_logprob": -0.07483764128251509, "compression_ratio": 1.6043956043956045, "no_speech_prob": 0.0007553822360932827}, {"id": 197, "seek": 112952, "start": 1146.0, "end": 1154.0, "text": " method schedules a function to be executed and returns a future object. So, a future object", "tokens": [51188, 3170, 28078, 257, 2445, 281, 312, 17577, 293, 11247, 257, 2027, 2657, 13, 407, 11, 257, 2027, 2657, 51588], "temperature": 0.0, "avg_logprob": -0.07483764128251509, "compression_ratio": 1.6043956043956045, "no_speech_prob": 0.0007553822360932827}, {"id": 198, "seek": 115400, "start": 1154.0, "end": 1160.0, "text": " basically encapsulates the execution of our function and allows us to check on it after it's", "tokens": [50364, 1936, 38745, 26192, 264, 15058, 295, 527, 2445, 293, 4045, 505, 281, 1520, 322, 309, 934, 309, 311, 50664], "temperature": 0.0, "avg_logprob": -0.055309451452576285, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.04022848978638649}, {"id": 199, "seek": 115400, "start": 1160.0, "end": 1166.72, "text": " been scheduled. So, we can check that it's running or if it's done, and also check the result. So,", "tokens": [50664, 668, 15678, 13, 407, 11, 321, 393, 1520, 300, 309, 311, 2614, 420, 498, 309, 311, 1096, 11, 293, 611, 1520, 264, 1874, 13, 407, 11, 51000], "temperature": 0.0, "avg_logprob": -0.055309451452576285, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.04022848978638649}, {"id": 200, "seek": 115400, "start": 1166.72, "end": 1172.16, "text": " if we grab the result, then it'll give us the return value of the function. Now, right now,", "tokens": [51000, 498, 321, 4444, 264, 1874, 11, 550, 309, 603, 976, 505, 264, 2736, 2158, 295, 264, 2445, 13, 823, 11, 558, 586, 11, 51272], "temperature": 0.0, "avg_logprob": -0.055309451452576285, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.04022848978638649}, {"id": 201, "seek": 115400, "start": 1172.16, "end": 1177.92, "text": " we're just printing out values. But let me add in a return value so that we can grab that. So,", "tokens": [51272, 321, 434, 445, 14699, 484, 4190, 13, 583, 718, 385, 909, 294, 257, 2736, 2158, 370, 300, 321, 393, 4444, 300, 13, 407, 11, 51560], "temperature": 0.0, "avg_logprob": -0.055309451452576285, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.04022848978638649}, {"id": 202, "seek": 117792, "start": 1177.92, "end": 1184.8000000000002, "text": " instead of just printing that we are done sleeping up here, instead, I'm going to return that string.", "tokens": [50364, 2602, 295, 445, 14699, 300, 321, 366, 1096, 8296, 493, 510, 11, 2602, 11, 286, 478, 516, 281, 2736, 300, 6798, 13, 50708], "temperature": 0.0, "avg_logprob": -0.055850218800665104, "compression_ratio": 2.020408163265306, "no_speech_prob": 0.0022518024779856205}, {"id": 203, "seek": 117792, "start": 1184.8000000000002, "end": 1190.72, "text": " So, I'm going to say return done sleeping instead of just printing that out. Okay, so now that's", "tokens": [50708, 407, 11, 286, 478, 516, 281, 584, 2736, 1096, 8296, 2602, 295, 445, 14699, 300, 484, 13, 1033, 11, 370, 586, 300, 311, 51004], "temperature": 0.0, "avg_logprob": -0.055850218800665104, "compression_ratio": 2.020408163265306, "no_speech_prob": 0.0022518024779856205}, {"id": 204, "seek": 117792, "start": 1190.72, "end": 1196.64, "text": " returning that string. So, if we still want to print that out, then we'll need to print that return", "tokens": [51004, 12678, 300, 6798, 13, 407, 11, 498, 321, 920, 528, 281, 4482, 300, 484, 11, 550, 321, 603, 643, 281, 4482, 300, 2736, 51300], "temperature": 0.0, "avg_logprob": -0.055850218800665104, "compression_ratio": 2.020408163265306, "no_speech_prob": 0.0022518024779856205}, {"id": 205, "seek": 117792, "start": 1196.64, "end": 1203.44, "text": " value. So, let's grab that by using the result method on that future object. So, I'm going to say", "tokens": [51300, 2158, 13, 407, 11, 718, 311, 4444, 300, 538, 1228, 264, 1874, 3170, 322, 300, 2027, 2657, 13, 407, 11, 286, 478, 516, 281, 584, 51640], "temperature": 0.0, "avg_logprob": -0.055850218800665104, "compression_ratio": 2.020408163265306, "no_speech_prob": 0.0022518024779856205}, {"id": 206, "seek": 120344, "start": 1203.44, "end": 1212.0800000000002, "text": " print and we will print out F1 dot result. Now, if we run the return method, then this will wait", "tokens": [50364, 4482, 293, 321, 486, 4482, 484, 479, 16, 5893, 1874, 13, 823, 11, 498, 321, 1190, 264, 2736, 3170, 11, 550, 341, 486, 1699, 50796], "temperature": 0.0, "avg_logprob": -0.08910239911546894, "compression_ratio": 1.6695278969957081, "no_speech_prob": 0.0006070536910556257}, {"id": 207, "seek": 120344, "start": 1212.0800000000002, "end": 1218.72, "text": " until the function completes. Okay, so let's comment out what we had before and run our code. So,", "tokens": [50796, 1826, 264, 2445, 36362, 13, 1033, 11, 370, 718, 311, 2871, 484, 437, 321, 632, 949, 293, 1190, 527, 3089, 13, 407, 11, 51128], "temperature": 0.0, "avg_logprob": -0.08910239911546894, "compression_ratio": 1.6695278969957081, "no_speech_prob": 0.0006070536910556257}, {"id": 208, "seek": 120344, "start": 1218.72, "end": 1226.4, "text": " I'm going to comment out this processes list here and our previous starts and joins. And instead,", "tokens": [51128, 286, 478, 516, 281, 2871, 484, 341, 7555, 1329, 510, 293, 527, 3894, 3719, 293, 24397, 13, 400, 2602, 11, 51512], "temperature": 0.0, "avg_logprob": -0.08910239911546894, "compression_ratio": 1.6695278969957081, "no_speech_prob": 0.0006070536910556257}, {"id": 209, "seek": 120344, "start": 1226.4, "end": 1232.64, "text": " we're just going to use this process pull executor. Okay, so if I run this, then we can see that", "tokens": [51512, 321, 434, 445, 516, 281, 764, 341, 1399, 2235, 7568, 284, 13, 1033, 11, 370, 498, 286, 1190, 341, 11, 550, 321, 393, 536, 300, 51824], "temperature": 0.0, "avg_logprob": -0.08910239911546894, "compression_ratio": 1.6695278969957081, "no_speech_prob": 0.0006070536910556257}, {"id": 210, "seek": 123264, "start": 1232.64, "end": 1238.24, "text": " that still works. And that's a lot less code than we had down here that's commented out. But we're", "tokens": [50364, 300, 920, 1985, 13, 400, 300, 311, 257, 688, 1570, 3089, 813, 321, 632, 760, 510, 300, 311, 26940, 484, 13, 583, 321, 434, 50644], "temperature": 0.0, "avg_logprob": -0.055418387055397034, "compression_ratio": 1.7534883720930232, "no_speech_prob": 0.00040447356877848506}, {"id": 211, "seek": 123264, "start": 1238.24, "end": 1243.1200000000001, "text": " still not running this multiple times yet like we were down here. So, if we wanted to run this", "tokens": [50644, 920, 406, 2614, 341, 3866, 1413, 1939, 411, 321, 645, 760, 510, 13, 407, 11, 498, 321, 1415, 281, 1190, 341, 50888], "temperature": 0.0, "avg_logprob": -0.055418387055397034, "compression_ratio": 1.7534883720930232, "no_speech_prob": 0.00040447356877848506}, {"id": 212, "seek": 123264, "start": 1243.1200000000001, "end": 1250.48, "text": " multiple times, then we could just run submit multiple times. So, I could say let me go above", "tokens": [50888, 3866, 1413, 11, 550, 321, 727, 445, 1190, 10315, 3866, 1413, 13, 407, 11, 286, 727, 584, 718, 385, 352, 3673, 51256], "temperature": 0.0, "avg_logprob": -0.055418387055397034, "compression_ratio": 1.7534883720930232, "no_speech_prob": 0.00040447356877848506}, {"id": 213, "seek": 123264, "start": 1250.48, "end": 1256.3200000000002, "text": " our result here. I'm going to add in another execution of this do something function. So,", "tokens": [51256, 527, 1874, 510, 13, 286, 478, 516, 281, 909, 294, 1071, 15058, 295, 341, 360, 746, 2445, 13, 407, 11, 51548], "temperature": 0.0, "avg_logprob": -0.055418387055397034, "compression_ratio": 1.7534883720930232, "no_speech_prob": 0.00040447356877848506}, {"id": 214, "seek": 125632, "start": 1256.32, "end": 1264.0, "text": " I'm going to call this F2 is equal to executor dot submit do something with one second. And then,", "tokens": [50364, 286, 478, 516, 281, 818, 341, 479, 17, 307, 2681, 281, 7568, 284, 5893, 10315, 360, 746, 365, 472, 1150, 13, 400, 550, 11, 50748], "temperature": 0.0, "avg_logprob": -0.05476290774795244, "compression_ratio": 1.6666666666666667, "no_speech_prob": 9.915189002640545e-05}, {"id": 215, "seek": 125632, "start": 1264.0, "end": 1272.56, "text": " I will also print out the F2 result. So, if I run this, then we can see that it's the same thing.", "tokens": [50748, 286, 486, 611, 4482, 484, 264, 479, 17, 1874, 13, 407, 11, 498, 286, 1190, 341, 11, 550, 321, 393, 536, 300, 309, 311, 264, 912, 551, 13, 51176], "temperature": 0.0, "avg_logprob": -0.05476290774795244, "compression_ratio": 1.6666666666666667, "no_speech_prob": 9.915189002640545e-05}, {"id": 216, "seek": 125632, "start": 1272.56, "end": 1277.4399999999998, "text": " It kicks both of these off at the same time. And we finished in about one second. And if we wanted", "tokens": [51176, 467, 21293, 1293, 295, 613, 766, 412, 264, 912, 565, 13, 400, 321, 4335, 294, 466, 472, 1150, 13, 400, 498, 321, 1415, 51420], "temperature": 0.0, "avg_logprob": -0.05476290774795244, "compression_ratio": 1.6666666666666667, "no_speech_prob": 9.915189002640545e-05}, {"id": 217, "seek": 125632, "start": 1277.4399999999998, "end": 1282.32, "text": " to run this 10 times like we did below, then we likely wouldn't want to run submit 10 different", "tokens": [51420, 281, 1190, 341, 1266, 1413, 411, 321, 630, 2507, 11, 550, 321, 3700, 2759, 380, 528, 281, 1190, 10315, 1266, 819, 51664], "temperature": 0.0, "avg_logprob": -0.05476290774795244, "compression_ratio": 1.6666666666666667, "no_speech_prob": 9.915189002640545e-05}, {"id": 218, "seek": 128232, "start": 1282.32, "end": 1287.76, "text": " times. So, we could use a loop like we did before. So, instead of running one at a time,", "tokens": [50364, 1413, 13, 407, 11, 321, 727, 764, 257, 6367, 411, 321, 630, 949, 13, 407, 11, 2602, 295, 2614, 472, 412, 257, 565, 11, 50636], "temperature": 0.0, "avg_logprob": -0.0529048273882528, "compression_ratio": 1.9747899159663866, "no_speech_prob": 0.00263158674351871}, {"id": 219, "seek": 128232, "start": 1287.76, "end": 1292.48, "text": " I'm going to use a loop. And we could use a regular loop like we did below. But I'm going", "tokens": [50636, 286, 478, 516, 281, 764, 257, 6367, 13, 400, 321, 727, 764, 257, 3890, 6367, 411, 321, 630, 2507, 13, 583, 286, 478, 516, 50872], "temperature": 0.0, "avg_logprob": -0.0529048273882528, "compression_ratio": 1.9747899159663866, "no_speech_prob": 0.00263158674351871}, {"id": 220, "seek": 128232, "start": 1292.48, "end": 1298.0, "text": " to go ahead and use a list comprehension to create these instead. So, we could say, I'm just going", "tokens": [50872, 281, 352, 2286, 293, 764, 257, 1329, 44991, 281, 1884, 613, 2602, 13, 407, 11, 321, 727, 584, 11, 286, 478, 445, 516, 51148], "temperature": 0.0, "avg_logprob": -0.0529048273882528, "compression_ratio": 1.9747899159663866, "no_speech_prob": 0.00263158674351871}, {"id": 221, "seek": 128232, "start": 1298.0, "end": 1304.6399999999999, "text": " to copy this executor dot submit part. And I'm just going to overwrite all of this other stuff", "tokens": [51148, 281, 5055, 341, 7568, 284, 5893, 10315, 644, 13, 400, 286, 478, 445, 516, 281, 670, 21561, 439, 295, 341, 661, 1507, 51480], "temperature": 0.0, "avg_logprob": -0.0529048273882528, "compression_ratio": 1.9747899159663866, "no_speech_prob": 0.00263158674351871}, {"id": 222, "seek": 128232, "start": 1304.6399999999999, "end": 1311.2, "text": " right now. And I'm going to say results are equal to, then I will start a list comprehension here", "tokens": [51480, 558, 586, 13, 400, 286, 478, 516, 281, 584, 3542, 366, 2681, 281, 11, 550, 286, 486, 722, 257, 1329, 44991, 510, 51808], "temperature": 0.0, "avg_logprob": -0.0529048273882528, "compression_ratio": 1.9747899159663866, "no_speech_prob": 0.00263158674351871}, {"id": 223, "seek": 131120, "start": 1311.2, "end": 1320.64, "text": " and say executor dot submit do something for one second for underscore range 10. Now, if you're", "tokens": [50364, 293, 584, 7568, 284, 5893, 10315, 360, 746, 337, 472, 1150, 337, 37556, 3613, 1266, 13, 823, 11, 498, 291, 434, 50836], "temperature": 0.0, "avg_logprob": -0.061097145080566406, "compression_ratio": 1.6537102473498233, "no_speech_prob": 0.0020506279543042183}, {"id": 224, "seek": 131120, "start": 1320.64, "end": 1325.44, "text": " not familiar with list comprehensions like we have here, then I do have a separate video on that", "tokens": [50836, 406, 4963, 365, 1329, 10753, 8302, 411, 321, 362, 510, 11, 550, 286, 360, 362, 257, 4994, 960, 322, 300, 51076], "temperature": 0.0, "avg_logprob": -0.061097145080566406, "compression_ratio": 1.6537102473498233, "no_speech_prob": 0.0020506279543042183}, {"id": 225, "seek": 131120, "start": 1325.44, "end": 1329.92, "text": " as well. So, I'll put a link to that in the description section below if you've never seen", "tokens": [51076, 382, 731, 13, 407, 11, 286, 603, 829, 257, 2113, 281, 300, 294, 264, 3855, 3541, 2507, 498, 291, 600, 1128, 1612, 51300], "temperature": 0.0, "avg_logprob": -0.061097145080566406, "compression_ratio": 1.6537102473498233, "no_speech_prob": 0.0020506279543042183}, {"id": 226, "seek": 131120, "start": 1329.92, "end": 1334.0, "text": " this type of code before. And if you're not comfortable using list comprehensions, then", "tokens": [51300, 341, 2010, 295, 3089, 949, 13, 400, 498, 291, 434, 406, 4619, 1228, 1329, 10753, 8302, 11, 550, 51504], "temperature": 0.0, "avg_logprob": -0.061097145080566406, "compression_ratio": 1.6537102473498233, "no_speech_prob": 0.0020506279543042183}, {"id": 227, "seek": 131120, "start": 1334.0, "end": 1339.3600000000001, "text": " you can always use a regular loop like we did down here below. Okay, so now we've created a list", "tokens": [51504, 291, 393, 1009, 764, 257, 3890, 6367, 411, 321, 630, 760, 510, 2507, 13, 1033, 11, 370, 586, 321, 600, 2942, 257, 1329, 51772], "temperature": 0.0, "avg_logprob": -0.061097145080566406, "compression_ratio": 1.6537102473498233, "no_speech_prob": 0.0020506279543042183}, {"id": 228, "seek": 133936, "start": 1339.36, "end": 1345.6, "text": " comprehension that's running our submit method with this do something function, and an argument of", "tokens": [50364, 44991, 300, 311, 2614, 527, 10315, 3170, 365, 341, 360, 746, 2445, 11, 293, 364, 6770, 295, 50676], "temperature": 0.0, "avg_logprob": -0.06061209028012285, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.0005192894604988396}, {"id": 229, "seek": 133936, "start": 1345.6, "end": 1351.52, "text": " one second, 10 different times. Now, in order to get these results, we can actually use another", "tokens": [50676, 472, 1150, 11, 1266, 819, 1413, 13, 823, 11, 294, 1668, 281, 483, 613, 3542, 11, 321, 393, 767, 764, 1071, 50972], "temperature": 0.0, "avg_logprob": -0.06061209028012285, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.0005192894604988396}, {"id": 230, "seek": 133936, "start": 1351.52, "end": 1356.8, "text": " function from the concurrent futures module called as completed. And this will give us an", "tokens": [50972, 2445, 490, 264, 37702, 26071, 10088, 1219, 382, 7365, 13, 400, 341, 486, 976, 505, 364, 51236], "temperature": 0.0, "avg_logprob": -0.06061209028012285, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.0005192894604988396}, {"id": 231, "seek": 133936, "start": 1356.8, "end": 1362.24, "text": " iterator that we can loop over that will yield the results of our processes as they're completed.", "tokens": [51236, 17138, 1639, 300, 321, 393, 6367, 670, 300, 486, 11257, 264, 3542, 295, 527, 7555, 382, 436, 434, 7365, 13, 51508], "temperature": 0.0, "avg_logprob": -0.06061209028012285, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.0005192894604988396}, {"id": 232, "seek": 133936, "start": 1362.24, "end": 1367.52, "text": " So, I think this is really useful. And it's one of the good things about using these processing", "tokens": [51508, 407, 11, 286, 519, 341, 307, 534, 4420, 13, 400, 309, 311, 472, 295, 264, 665, 721, 466, 1228, 613, 9007, 51772], "temperature": 0.0, "avg_logprob": -0.06061209028012285, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.0005192894604988396}, {"id": 233, "seek": 136752, "start": 1367.52, "end": 1376.8, "text": " pull executors. So to use this, we can say just for f in concurrent, oops, sorry about my typing", "tokens": [50364, 2235, 7568, 830, 13, 407, 281, 764, 341, 11, 321, 393, 584, 445, 337, 283, 294, 37702, 11, 34166, 11, 2597, 466, 452, 18444, 50828], "temperature": 0.0, "avg_logprob": -0.1096104029062632, "compression_ratio": 1.6089385474860336, "no_speech_prob": 0.004609151277691126}, {"id": 234, "seek": 136752, "start": 1376.8, "end": 1385.44, "text": " there, concurrent dot futures dot as underscore completed. And now we want to pass in this list", "tokens": [50828, 456, 11, 37702, 5893, 26071, 5893, 382, 37556, 7365, 13, 400, 586, 321, 528, 281, 1320, 294, 341, 1329, 51260], "temperature": 0.0, "avg_logprob": -0.1096104029062632, "compression_ratio": 1.6089385474860336, "no_speech_prob": 0.004609151277691126}, {"id": 235, "seek": 136752, "start": 1385.44, "end": 1393.68, "text": " of results, which is a list of futures objects. And now within this list, let's print out f dot", "tokens": [51260, 295, 3542, 11, 597, 307, 257, 1329, 295, 26071, 6565, 13, 400, 586, 1951, 341, 1329, 11, 718, 311, 4482, 484, 283, 5893, 51672], "temperature": 0.0, "avg_logprob": -0.1096104029062632, "compression_ratio": 1.6089385474860336, "no_speech_prob": 0.004609151277691126}, {"id": 236, "seek": 139368, "start": 1394.5600000000002, "end": 1401.92, "text": " result. So if we run this, oops, and it looks like I have some invalid syntax here. Oh,", "tokens": [50408, 1874, 13, 407, 498, 321, 1190, 341, 11, 34166, 11, 293, 309, 1542, 411, 286, 362, 512, 34702, 28431, 510, 13, 876, 11, 50776], "temperature": 0.0, "avg_logprob": -0.06620549238645114, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0015011165523901582}, {"id": 237, "seek": 139368, "start": 1401.92, "end": 1408.0, "text": " I forgot to say, I should have said for underscore in range of 10. Some of you probably saw that", "tokens": [50776, 286, 5298, 281, 584, 11, 286, 820, 362, 848, 337, 37556, 294, 3613, 295, 1266, 13, 2188, 295, 291, 1391, 1866, 300, 51080], "temperature": 0.0, "avg_logprob": -0.06620549238645114, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0015011165523901582}, {"id": 238, "seek": 139368, "start": 1408.0, "end": 1416.24, "text": " as I was typing it out. Okay, so now if I run this, then we can see that we slept for one second.", "tokens": [51080, 382, 286, 390, 18444, 309, 484, 13, 1033, 11, 370, 586, 498, 286, 1190, 341, 11, 550, 321, 393, 536, 300, 321, 17400, 337, 472, 1150, 13, 51492], "temperature": 0.0, "avg_logprob": -0.06620549238645114, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0015011165523901582}, {"id": 239, "seek": 139368, "start": 1416.24, "end": 1421.1200000000001, "text": " Now it's still ran 10 different times. But if we scroll down to the bottom, then we can see", "tokens": [51492, 823, 309, 311, 920, 5872, 1266, 819, 1413, 13, 583, 498, 321, 11369, 760, 281, 264, 2767, 11, 550, 321, 393, 536, 51736], "temperature": 0.0, "avg_logprob": -0.06620549238645114, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0015011165523901582}, {"id": 240, "seek": 142112, "start": 1421.12, "end": 1427.36, "text": " how much time it took. So we can see here that it actually took three seconds this time. Now,", "tokens": [50364, 577, 709, 565, 309, 1890, 13, 407, 321, 393, 536, 510, 300, 309, 767, 1890, 1045, 3949, 341, 565, 13, 823, 11, 50676], "temperature": 0.0, "avg_logprob": -0.06503082358318826, "compression_ratio": 1.613733905579399, "no_speech_prob": 0.022281724959611893}, {"id": 241, "seek": 142112, "start": 1427.36, "end": 1432.6399999999999, "text": " the reason behind that is that our poll may have made a decision based on our hardware,", "tokens": [50676, 264, 1778, 2261, 300, 307, 300, 527, 6418, 815, 362, 1027, 257, 3537, 2361, 322, 527, 8837, 11, 50940], "temperature": 0.0, "avg_logprob": -0.06503082358318826, "compression_ratio": 1.613733905579399, "no_speech_prob": 0.022281724959611893}, {"id": 242, "seek": 142112, "start": 1432.6399999999999, "end": 1439.4399999999998, "text": " not to a lot as many processes. So that's why it might take longer. But even though it took longer", "tokens": [50940, 406, 281, 257, 688, 382, 867, 7555, 13, 407, 300, 311, 983, 309, 1062, 747, 2854, 13, 583, 754, 1673, 309, 1890, 2854, 51280], "temperature": 0.0, "avg_logprob": -0.06503082358318826, "compression_ratio": 1.613733905579399, "no_speech_prob": 0.022281724959611893}, {"id": 243, "seek": 142112, "start": 1439.4399999999998, "end": 1445.04, "text": " in our simple little example here, I still you like to use these processing pull executors most", "tokens": [51280, 294, 527, 2199, 707, 1365, 510, 11, 286, 920, 291, 411, 281, 764, 613, 9007, 2235, 7568, 830, 881, 51560], "temperature": 0.0, "avg_logprob": -0.06503082358318826, "compression_ratio": 1.613733905579399, "no_speech_prob": 0.022281724959611893}, {"id": 244, "seek": 144504, "start": 1445.04, "end": 1451.68, "text": " of the time, because I trust it to a lot the processes a lot more than I trust myself. So", "tokens": [50364, 295, 264, 565, 11, 570, 286, 3361, 309, 281, 257, 688, 264, 7555, 257, 688, 544, 813, 286, 3361, 2059, 13, 407, 50696], "temperature": 0.0, "avg_logprob": -0.06087815761566162, "compression_ratio": 1.828793774319066, "no_speech_prob": 0.030671516433358192}, {"id": 245, "seek": 144504, "start": 1451.68, "end": 1457.2, "text": " I passed that off to the process pull executor to do and to make that decision for me. Now to", "tokens": [50696, 286, 4678, 300, 766, 281, 264, 1399, 2235, 7568, 284, 281, 360, 293, 281, 652, 300, 3537, 337, 385, 13, 823, 281, 50972], "temperature": 0.0, "avg_logprob": -0.06087815761566162, "compression_ratio": 1.828793774319066, "no_speech_prob": 0.030671516433358192}, {"id": 246, "seek": 144504, "start": 1457.2, "end": 1462.24, "text": " prove that these results are actually coming in as they're completed, let me actually pass in a", "tokens": [50972, 7081, 300, 613, 3542, 366, 767, 1348, 294, 382, 436, 434, 7365, 11, 718, 385, 767, 1320, 294, 257, 51224], "temperature": 0.0, "avg_logprob": -0.06087815761566162, "compression_ratio": 1.828793774319066, "no_speech_prob": 0.030671516433358192}, {"id": 247, "seek": 144504, "start": 1462.24, "end": 1468.0, "text": " different range of seconds for our processes to sleep. And those should print out in the order", "tokens": [51224, 819, 3613, 295, 3949, 337, 527, 7555, 281, 2817, 13, 400, 729, 820, 4482, 484, 294, 264, 1668, 51512], "temperature": 0.0, "avg_logprob": -0.06087815761566162, "compression_ratio": 1.828793774319066, "no_speech_prob": 0.030671516433358192}, {"id": 248, "seek": 144504, "start": 1468.0, "end": 1473.76, "text": " that they complete. So I'm going to create a list of seconds to sleep. And I'll make that sleep", "tokens": [51512, 300, 436, 3566, 13, 407, 286, 478, 516, 281, 1884, 257, 1329, 295, 3949, 281, 2817, 13, 400, 286, 603, 652, 300, 2817, 51800], "temperature": 0.0, "avg_logprob": -0.06087815761566162, "compression_ratio": 1.828793774319066, "no_speech_prob": 0.030671516433358192}, {"id": 249, "seek": 147376, "start": 1473.76, "end": 1480.48, "text": " from five seconds all the way down to one second. So above our results here, I'm going to make a list", "tokens": [50364, 490, 1732, 3949, 439, 264, 636, 760, 281, 472, 1150, 13, 407, 3673, 527, 3542, 510, 11, 286, 478, 516, 281, 652, 257, 1329, 50700], "temperature": 0.0, "avg_logprob": -0.0540856898409649, "compression_ratio": 1.7244444444444444, "no_speech_prob": 0.0004044622473884374}, {"id": 250, "seek": 147376, "start": 1480.48, "end": 1487.68, "text": " of seconds. And I will just make a list of five, four, three, two, one. And I'll also print out", "tokens": [50700, 295, 3949, 13, 400, 286, 486, 445, 652, 257, 1329, 295, 1732, 11, 1451, 11, 1045, 11, 732, 11, 472, 13, 400, 286, 603, 611, 4482, 484, 51060], "temperature": 0.0, "avg_logprob": -0.0540856898409649, "compression_ratio": 1.7244444444444444, "no_speech_prob": 0.0004044622473884374}, {"id": 251, "seek": 147376, "start": 1487.68, "end": 1494.4, "text": " the seconds in the return statement of our do something function, so that we can tell which", "tokens": [51060, 264, 3949, 294, 264, 2736, 5629, 295, 527, 360, 746, 2445, 11, 370, 300, 321, 393, 980, 597, 51396], "temperature": 0.0, "avg_logprob": -0.0540856898409649, "compression_ratio": 1.7244444444444444, "no_speech_prob": 0.0004044622473884374}, {"id": 252, "seek": 147376, "start": 1494.4, "end": 1500.24, "text": " ones are finishing and in what order. So again, I'm going to make this an f string by putting an f", "tokens": [51396, 2306, 366, 12693, 293, 294, 437, 1668, 13, 407, 797, 11, 286, 478, 516, 281, 652, 341, 364, 283, 6798, 538, 3372, 364, 283, 51688], "temperature": 0.0, "avg_logprob": -0.0540856898409649, "compression_ratio": 1.7244444444444444, "no_speech_prob": 0.0004044622473884374}, {"id": 253, "seek": 150024, "start": 1500.24, "end": 1508.72, "text": " right there. And I'm just going to pass that in to so we can see which seconds is actually done", "tokens": [50364, 558, 456, 13, 400, 286, 478, 445, 516, 281, 1320, 300, 294, 281, 370, 321, 393, 536, 597, 3949, 307, 767, 1096, 50788], "temperature": 0.0, "avg_logprob": -0.06262192927615744, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.0011335203889757395}, {"id": 254, "seek": 150024, "start": 1508.72, "end": 1515.44, "text": " sleeping. So now, let me also change our list comprehension here, so that we are running our", "tokens": [50788, 8296, 13, 407, 586, 11, 718, 385, 611, 1319, 527, 1329, 44991, 510, 11, 370, 300, 321, 366, 2614, 527, 51124], "temperature": 0.0, "avg_logprob": -0.06262192927615744, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.0011335203889757395}, {"id": 255, "seek": 150024, "start": 1515.44, "end": 1522.16, "text": " do something function with each of these seconds in this seconds list. So I'm going to say executor", "tokens": [51124, 360, 746, 2445, 365, 1184, 295, 613, 3949, 294, 341, 3949, 1329, 13, 407, 286, 478, 516, 281, 584, 7568, 284, 51460], "temperature": 0.0, "avg_logprob": -0.06262192927615744, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.0011335203889757395}, {"id": 256, "seek": 152216, "start": 1522.24, "end": 1533.28, "text": " dot submit, do something. And I want to do that for whatever second. So four sec in our seconds", "tokens": [50368, 5893, 10315, 11, 360, 746, 13, 400, 286, 528, 281, 360, 300, 337, 2035, 1150, 13, 407, 1451, 907, 294, 527, 3949, 50920], "temperature": 0.0, "avg_logprob": -0.10665026463960346, "compression_ratio": 1.6342857142857143, "no_speech_prob": 0.024421365931630135}, {"id": 257, "seek": 152216, "start": 1533.28, "end": 1540.8000000000002, "text": " list. Okay, so now if I run this, then we can see that it actually started our five second", "tokens": [50920, 1329, 13, 1033, 11, 370, 586, 498, 286, 1190, 341, 11, 550, 321, 393, 536, 300, 309, 767, 1409, 527, 1732, 1150, 51296], "temperature": 0.0, "avg_logprob": -0.10665026463960346, "compression_ratio": 1.6342857142857143, "no_speech_prob": 0.024421365931630135}, {"id": 258, "seek": 152216, "start": 1540.8000000000002, "end": 1546.88, "text": " process first, and then our four, then our three, then our two, then our one. But it finished these", "tokens": [51296, 1399, 700, 11, 293, 550, 527, 1451, 11, 550, 527, 1045, 11, 550, 527, 732, 11, 550, 527, 472, 13, 583, 309, 4335, 613, 51600], "temperature": 0.0, "avg_logprob": -0.10665026463960346, "compression_ratio": 1.6342857142857143, "no_speech_prob": 0.024421365931630135}, {"id": 259, "seek": 154688, "start": 1546.88, "end": 1552.48, "text": " in the order that they came in. And the lower number seconds are towards the top. Now I'm not", "tokens": [50364, 294, 264, 1668, 300, 436, 1361, 294, 13, 400, 264, 3126, 1230, 3949, 366, 3030, 264, 1192, 13, 823, 286, 478, 406, 50644], "temperature": 0.0, "avg_logprob": -0.06647457881849639, "compression_ratio": 1.7048458149779735, "no_speech_prob": 0.006692336406558752}, {"id": 260, "seek": 154688, "start": 1552.48, "end": 1559.1200000000001, "text": " sure why the one second process took so much longer than the two and the three second processes. I", "tokens": [50644, 988, 983, 264, 472, 1150, 1399, 1890, 370, 709, 2854, 813, 264, 732, 293, 264, 1045, 1150, 7555, 13, 286, 50976], "temperature": 0.0, "avg_logprob": -0.06647457881849639, "compression_ratio": 1.7048458149779735, "no_speech_prob": 0.006692336406558752}, {"id": 261, "seek": 154688, "start": 1559.1200000000001, "end": 1563.92, "text": " guess it just got hung up on something. But the four and the five second processes were down here", "tokens": [50976, 2041, 309, 445, 658, 5753, 493, 322, 746, 13, 583, 264, 1451, 293, 264, 1732, 1150, 7555, 645, 760, 510, 51216], "temperature": 0.0, "avg_logprob": -0.06647457881849639, "compression_ratio": 1.7048458149779735, "no_speech_prob": 0.006692336406558752}, {"id": 262, "seek": 154688, "start": 1563.92, "end": 1570.24, "text": " at the bottom. Actually, let me run that one more time. And Oh, okay, so that's why it's because", "tokens": [51216, 412, 264, 2767, 13, 5135, 11, 718, 385, 1190, 300, 472, 544, 565, 13, 400, 876, 11, 1392, 11, 370, 300, 311, 983, 309, 311, 570, 51532], "temperature": 0.0, "avg_logprob": -0.06647457881849639, "compression_ratio": 1.7048458149779735, "no_speech_prob": 0.006692336406558752}, {"id": 263, "seek": 157024, "start": 1570.24, "end": 1576.88, "text": " our one second process was down here. And since I have four cores on my machine,", "tokens": [50364, 527, 472, 1150, 1399, 390, 760, 510, 13, 400, 1670, 286, 362, 1451, 24826, 322, 452, 3479, 11, 50696], "temperature": 0.0, "avg_logprob": -0.05595107965691145, "compression_ratio": 1.721698113207547, "no_speech_prob": 0.00419863173738122}, {"id": 264, "seek": 157024, "start": 1577.44, "end": 1583.76, "text": " it started these four processes here first. And it didn't start the one second process until", "tokens": [50724, 309, 1409, 613, 1451, 7555, 510, 700, 13, 400, 309, 994, 380, 722, 264, 472, 1150, 1399, 1826, 51040], "temperature": 0.0, "avg_logprob": -0.05595107965691145, "compression_ratio": 1.721698113207547, "no_speech_prob": 0.00419863173738122}, {"id": 265, "seek": 157024, "start": 1584.56, "end": 1589.84, "text": " this two was finished right here. So that's why that took a little bit longer. But since we are", "tokens": [51080, 341, 732, 390, 4335, 558, 510, 13, 407, 300, 311, 983, 300, 1890, 257, 707, 857, 2854, 13, 583, 1670, 321, 366, 51344], "temperature": 0.0, "avg_logprob": -0.05595107965691145, "compression_ratio": 1.721698113207547, "no_speech_prob": 0.00419863173738122}, {"id": 266, "seek": 157024, "start": 1589.84, "end": 1595.92, "text": " using this as completed method, this actually did print our result out our results in the order", "tokens": [51344, 1228, 341, 382, 7365, 3170, 11, 341, 767, 630, 4482, 527, 1874, 484, 527, 3542, 294, 264, 1668, 51648], "temperature": 0.0, "avg_logprob": -0.05595107965691145, "compression_ratio": 1.721698113207547, "no_speech_prob": 0.00419863173738122}, {"id": 267, "seek": 159592, "start": 1595.92, "end": 1601.04, "text": " that they completed. So this two second one finished first, and then this three, then one,", "tokens": [50364, 300, 436, 7365, 13, 407, 341, 732, 1150, 472, 4335, 700, 11, 293, 550, 341, 1045, 11, 550, 472, 11, 50620], "temperature": 0.0, "avg_logprob": -0.0354741549087783, "compression_ratio": 1.724264705882353, "no_speech_prob": 0.001098681939765811}, {"id": 268, "seek": 159592, "start": 1601.04, "end": 1606.0, "text": " then four, then five. And we can see here down at the bottom that our script is still finishing", "tokens": [50620, 550, 1451, 11, 550, 1732, 13, 400, 321, 393, 536, 510, 760, 412, 264, 2767, 300, 527, 5755, 307, 920, 12693, 50868], "temperature": 0.0, "avg_logprob": -0.0354741549087783, "compression_ratio": 1.724264705882353, "no_speech_prob": 0.001098681939765811}, {"id": 269, "seek": 159592, "start": 1606.0, "end": 1611.3600000000001, "text": " in about five seconds. So that's pretty good. Okay, so with this submit method right now,", "tokens": [50868, 294, 466, 1732, 3949, 13, 407, 300, 311, 1238, 665, 13, 1033, 11, 370, 365, 341, 10315, 3170, 558, 586, 11, 51136], "temperature": 0.0, "avg_logprob": -0.0354741549087783, "compression_ratio": 1.724264705882353, "no_speech_prob": 0.001098681939765811}, {"id": 270, "seek": 159592, "start": 1612.16, "end": 1619.28, "text": " it's submitting each function once at a time. But in order to run submit on an entire list,", "tokens": [51176, 309, 311, 31836, 1184, 2445, 1564, 412, 257, 565, 13, 583, 294, 1668, 281, 1190, 10315, 322, 364, 2302, 1329, 11, 51532], "temperature": 0.0, "avg_logprob": -0.0354741549087783, "compression_ratio": 1.724264705882353, "no_speech_prob": 0.001098681939765811}, {"id": 271, "seek": 159592, "start": 1619.28, "end": 1624.5600000000002, "text": " then we need to do a loop or a comprehension like we did here. But if you're familiar with the built", "tokens": [51532, 550, 321, 643, 281, 360, 257, 6367, 420, 257, 44991, 411, 321, 630, 510, 13, 583, 498, 291, 434, 4963, 365, 264, 3094, 51796], "temperature": 0.0, "avg_logprob": -0.0354741549087783, "compression_ratio": 1.724264705882353, "no_speech_prob": 0.001098681939765811}, {"id": 272, "seek": 162456, "start": 1624.56, "end": 1629.76, "text": " in map method, then there is actually something similar that we can do with processes, where we", "tokens": [50364, 294, 4471, 3170, 11, 550, 456, 307, 767, 746, 2531, 300, 321, 393, 360, 365, 7555, 11, 689, 321, 50624], "temperature": 0.0, "avg_logprob": -0.062410667378415344, "compression_ratio": 1.7971698113207548, "no_speech_prob": 0.003172326134517789}, {"id": 273, "seek": 162456, "start": 1629.76, "end": 1635.28, "text": " can use the map method to run our function over a list of values. So if you're familiar with the", "tokens": [50624, 393, 764, 264, 4471, 3170, 281, 1190, 527, 2445, 670, 257, 1329, 295, 4190, 13, 407, 498, 291, 434, 4963, 365, 264, 50900], "temperature": 0.0, "avg_logprob": -0.062410667378415344, "compression_ratio": 1.7971698113207548, "no_speech_prob": 0.003172326134517789}, {"id": 274, "seek": 162456, "start": 1635.28, "end": 1641.6, "text": " built in map method, then this is very similar, except it uses processes instead. So it runs the", "tokens": [50900, 3094, 294, 4471, 3170, 11, 550, 341, 307, 588, 2531, 11, 3993, 309, 4960, 7555, 2602, 13, 407, 309, 6676, 264, 51216], "temperature": 0.0, "avg_logprob": -0.062410667378415344, "compression_ratio": 1.7971698113207548, "no_speech_prob": 0.003172326134517789}, {"id": 275, "seek": 162456, "start": 1641.6, "end": 1647.44, "text": " function every time or with every item of the interval that we pass in. So let's say that I", "tokens": [51216, 2445, 633, 565, 420, 365, 633, 3174, 295, 264, 15035, 300, 321, 1320, 294, 13, 407, 718, 311, 584, 300, 286, 51508], "temperature": 0.0, "avg_logprob": -0.062410667378415344, "compression_ratio": 1.7971698113207548, "no_speech_prob": 0.003172326134517789}, {"id": 276, "seek": 164744, "start": 1647.44, "end": 1656.16, "text": " want to map our function to our list of seconds. So to do this, I am just going to overwrite our", "tokens": [50364, 528, 281, 4471, 527, 2445, 281, 527, 1329, 295, 3949, 13, 407, 281, 360, 341, 11, 286, 669, 445, 516, 281, 670, 21561, 527, 50800], "temperature": 0.0, "avg_logprob": -0.05604756184113331, "compression_ratio": 1.5944444444444446, "no_speech_prob": 0.017984440550208092}, {"id": 277, "seek": 164744, "start": 1656.16, "end": 1661.52, "text": " list comprehension here. And I'm not going to be using this as completed anymore either. So I'm", "tokens": [50800, 1329, 44991, 510, 13, 400, 286, 478, 406, 516, 281, 312, 1228, 341, 382, 7365, 3602, 2139, 13, 407, 286, 478, 51068], "temperature": 0.0, "avg_logprob": -0.05604756184113331, "compression_ratio": 1.5944444444444446, "no_speech_prob": 0.017984440550208092}, {"id": 278, "seek": 164744, "start": 1661.52, "end": 1671.04, "text": " also going to get rid of that. So now in order to do this, we can simply say executor dot map.", "tokens": [51068, 611, 516, 281, 483, 3973, 295, 300, 13, 407, 586, 294, 1668, 281, 360, 341, 11, 321, 393, 2935, 584, 7568, 284, 5893, 4471, 13, 51544], "temperature": 0.0, "avg_logprob": -0.05604756184113331, "compression_ratio": 1.5944444444444446, "no_speech_prob": 0.017984440550208092}, {"id": 279, "seek": 167104, "start": 1671.76, "end": 1682.3999999999999, "text": " And now we will map our do something function. And we will map our list of seconds. So again,", "tokens": [50400, 400, 586, 321, 486, 4471, 527, 360, 746, 2445, 13, 400, 321, 486, 4471, 527, 1329, 295, 3949, 13, 407, 797, 11, 50932], "temperature": 0.0, "avg_logprob": -0.06655283941738847, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.006903488654643297}, {"id": 280, "seek": 167104, "start": 1682.3999999999999, "end": 1687.04, "text": " what this map method does, if you're not familiar with the built in Python map method and what it", "tokens": [50932, 437, 341, 4471, 3170, 775, 11, 498, 291, 434, 406, 4963, 365, 264, 3094, 294, 15329, 4471, 3170, 293, 437, 309, 51164], "temperature": 0.0, "avg_logprob": -0.06655283941738847, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.006903488654643297}, {"id": 281, "seek": 167104, "start": 1687.04, "end": 1696.08, "text": " does, basically map will run this do something function with every item of this list with every", "tokens": [51164, 775, 11, 1936, 4471, 486, 1190, 341, 360, 746, 2445, 365, 633, 3174, 295, 341, 1329, 365, 633, 51616], "temperature": 0.0, "avg_logprob": -0.06655283941738847, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.006903488654643297}, {"id": 282, "seek": 169608, "start": 1696.08, "end": 1702.24, "text": " item of whatever iterable you pass in. So that is what map does. Now, when we were using the submit", "tokens": [50364, 3174, 295, 2035, 17138, 712, 291, 1320, 294, 13, 407, 300, 307, 437, 4471, 775, 13, 823, 11, 562, 321, 645, 1228, 264, 10315, 50672], "temperature": 0.0, "avg_logprob": -0.07377311648154745, "compression_ratio": 1.76, "no_speech_prob": 0.004468078725039959}, {"id": 283, "seek": 169608, "start": 1702.24, "end": 1709.04, "text": " method, it returned future objects. But when we use map, it just returns the results. Now, it is", "tokens": [50672, 3170, 11, 309, 8752, 2027, 6565, 13, 583, 562, 321, 764, 4471, 11, 309, 445, 11247, 264, 3542, 13, 823, 11, 309, 307, 51012], "temperature": 0.0, "avg_logprob": -0.07377311648154745, "compression_ratio": 1.76, "no_speech_prob": 0.004468078725039959}, {"id": 284, "seek": 169608, "start": 1709.04, "end": 1714.32, "text": " going to run those processes in parallel. But instead of returning the results as they're completed,", "tokens": [51012, 516, 281, 1190, 729, 7555, 294, 8952, 13, 583, 2602, 295, 12678, 264, 3542, 382, 436, 434, 7365, 11, 51276], "temperature": 0.0, "avg_logprob": -0.07377311648154745, "compression_ratio": 1.76, "no_speech_prob": 0.004468078725039959}, {"id": 285, "seek": 169608, "start": 1714.32, "end": 1720.24, "text": " like we saw before, map is going to return the results in the in the order that they were started.", "tokens": [51276, 411, 321, 1866, 949, 11, 4471, 307, 516, 281, 2736, 264, 3542, 294, 264, 294, 264, 1668, 300, 436, 645, 1409, 13, 51572], "temperature": 0.0, "avg_logprob": -0.07377311648154745, "compression_ratio": 1.76, "no_speech_prob": 0.004468078725039959}, {"id": 286, "seek": 172024, "start": 1720.24, "end": 1726.0, "text": " So to loop over these results, we can simply just do a for loop. So I'm going to say for", "tokens": [50364, 407, 281, 6367, 670, 613, 3542, 11, 321, 393, 2935, 445, 360, 257, 337, 6367, 13, 407, 286, 478, 516, 281, 584, 337, 50652], "temperature": 0.0, "avg_logprob": -0.07017003536224366, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.001501134131103754}, {"id": 287, "seek": 172024, "start": 1726.0, "end": 1734.16, "text": " result in results. And then I will just print out our result, whoop, make sure that I'm printing", "tokens": [50652, 1874, 294, 3542, 13, 400, 550, 286, 486, 445, 4482, 484, 527, 1874, 11, 567, 404, 11, 652, 988, 300, 286, 478, 14699, 51060], "temperature": 0.0, "avg_logprob": -0.07017003536224366, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.001501134131103754}, {"id": 288, "seek": 172024, "start": 1734.16, "end": 1740.72, "text": " out the result and not that results list. Okay, so now if I run this, then we can see that all of", "tokens": [51060, 484, 264, 1874, 293, 406, 300, 3542, 1329, 13, 1033, 11, 370, 586, 498, 286, 1190, 341, 11, 550, 321, 393, 536, 300, 439, 295, 51388], "temperature": 0.0, "avg_logprob": -0.07017003536224366, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.001501134131103754}, {"id": 289, "seek": 172024, "start": 1740.72, "end": 1746.56, "text": " our processes kicked off at pretty much the same time, except for that one second when it looked", "tokens": [51388, 527, 7555, 14609, 766, 412, 1238, 709, 264, 912, 565, 11, 3993, 337, 300, 472, 1150, 562, 309, 2956, 51680], "temperature": 0.0, "avg_logprob": -0.07017003536224366, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.001501134131103754}, {"id": 290, "seek": 174656, "start": 1746.56, "end": 1753.2, "text": " like it got outside of the pool like it did before. But they actually didn't all complete at the same", "tokens": [50364, 411, 309, 658, 2380, 295, 264, 7005, 411, 309, 630, 949, 13, 583, 436, 767, 994, 380, 439, 3566, 412, 264, 912, 50696], "temperature": 0.0, "avg_logprob": -0.05242741604646047, "compression_ratio": 1.7292576419213974, "no_speech_prob": 0.0031723189167678356}, {"id": 291, "seek": 174656, "start": 1753.2, "end": 1759.84, "text": " time. But when you loop over your results using map like we did here, then it returns the results", "tokens": [50696, 565, 13, 583, 562, 291, 6367, 670, 428, 3542, 1228, 4471, 411, 321, 630, 510, 11, 550, 309, 11247, 264, 3542, 51028], "temperature": 0.0, "avg_logprob": -0.05242741604646047, "compression_ratio": 1.7292576419213974, "no_speech_prob": 0.0031723189167678356}, {"id": 292, "seek": 174656, "start": 1759.84, "end": 1766.08, "text": " in the order that they were started. So since we slept for five seconds first, then we waited for", "tokens": [51028, 294, 264, 1668, 300, 436, 645, 1409, 13, 407, 1670, 321, 17400, 337, 1732, 3949, 700, 11, 550, 321, 15240, 337, 51340], "temperature": 0.0, "avg_logprob": -0.05242741604646047, "compression_ratio": 1.7292576419213974, "no_speech_prob": 0.0031723189167678356}, {"id": 293, "seek": 174656, "start": 1766.08, "end": 1771.36, "text": " that one to finish before printing out the other results. But it still didn't slow us down, we can", "tokens": [51340, 300, 472, 281, 2413, 949, 14699, 484, 264, 661, 3542, 13, 583, 309, 920, 994, 380, 2964, 505, 760, 11, 321, 393, 51604], "temperature": 0.0, "avg_logprob": -0.05242741604646047, "compression_ratio": 1.7292576419213974, "no_speech_prob": 0.0031723189167678356}, {"id": 294, "seek": 177136, "start": 1771.36, "end": 1777.52, "text": " see that our entire script still finished in five seconds here. But it looks like our five", "tokens": [50364, 536, 300, 527, 2302, 5755, 920, 4335, 294, 1732, 3949, 510, 13, 583, 309, 1542, 411, 527, 1732, 50672], "temperature": 0.0, "avg_logprob": -0.06586438054623811, "compression_ratio": 1.9836065573770492, "no_speech_prob": 0.012430569157004356}, {"id": 295, "seek": 177136, "start": 1777.52, "end": 1782.32, "text": " seconds was done sleeping first, and then our four, then three, then two, then one, it actually didn't", "tokens": [50672, 3949, 390, 1096, 8296, 700, 11, 293, 550, 527, 1451, 11, 550, 1045, 11, 550, 732, 11, 550, 472, 11, 309, 767, 994, 380, 50912], "temperature": 0.0, "avg_logprob": -0.06586438054623811, "compression_ratio": 1.9836065573770492, "no_speech_prob": 0.012430569157004356}, {"id": 296, "seek": 177136, "start": 1782.32, "end": 1790.24, "text": " finish in that order. But it printed out in that order, because again, it prints out the ones that", "tokens": [50912, 2413, 294, 300, 1668, 13, 583, 309, 13567, 484, 294, 300, 1668, 11, 570, 797, 11, 309, 22305, 484, 264, 2306, 300, 51308], "temperature": 0.0, "avg_logprob": -0.06586438054623811, "compression_ratio": 1.9836065573770492, "no_speech_prob": 0.012430569157004356}, {"id": 297, "seek": 177136, "start": 1790.24, "end": 1794.4799999999998, "text": " in the order that they were started and not in the order that they were finished. Now another", "tokens": [51308, 294, 264, 1668, 300, 436, 645, 1409, 293, 406, 294, 264, 1668, 300, 436, 645, 4335, 13, 823, 1071, 51520], "temperature": 0.0, "avg_logprob": -0.06586438054623811, "compression_ratio": 1.9836065573770492, "no_speech_prob": 0.012430569157004356}, {"id": 298, "seek": 177136, "start": 1794.4799999999998, "end": 1799.52, "text": " thing to point out here is that if our function raises an exception, it won't actually raise that", "tokens": [51520, 551, 281, 935, 484, 510, 307, 300, 498, 527, 2445, 19658, 364, 11183, 11, 309, 1582, 380, 767, 5300, 300, 51772], "temperature": 0.0, "avg_logprob": -0.06586438054623811, "compression_ratio": 1.9836065573770492, "no_speech_prob": 0.012430569157004356}, {"id": 299, "seek": 179952, "start": 1799.52, "end": 1805.76, "text": " exception while running the process. The exception will be raised when its value is retrieved from", "tokens": [50364, 11183, 1339, 2614, 264, 1399, 13, 440, 11183, 486, 312, 6005, 562, 1080, 2158, 307, 19817, 937, 490, 50676], "temperature": 0.0, "avg_logprob": -0.04634896914164225, "compression_ratio": 1.8697318007662835, "no_speech_prob": 0.01743907667696476}, {"id": 300, "seek": 179952, "start": 1805.76, "end": 1811.92, "text": " the results iterator. So if you need to handle any exceptions, then you can do that here within the", "tokens": [50676, 264, 3542, 17138, 1639, 13, 407, 498, 291, 643, 281, 4813, 604, 22847, 11, 550, 291, 393, 360, 300, 510, 1951, 264, 50984], "temperature": 0.0, "avg_logprob": -0.04634896914164225, "compression_ratio": 1.8697318007662835, "no_speech_prob": 0.01743907667696476}, {"id": 301, "seek": 179952, "start": 1811.92, "end": 1816.72, "text": " iterator if you'd like. And if you'd like to learn more about handling exceptions, then I do have a", "tokens": [50984, 17138, 1639, 498, 291, 1116, 411, 13, 400, 498, 291, 1116, 411, 281, 1466, 544, 466, 13175, 22847, 11, 550, 286, 360, 362, 257, 51224], "temperature": 0.0, "avg_logprob": -0.04634896914164225, "compression_ratio": 1.8697318007662835, "no_speech_prob": 0.01743907667696476}, {"id": 302, "seek": 179952, "start": 1816.72, "end": 1821.36, "text": " more in depth video. If you'd like to learn more about that. So I'll be sure to leave a link to", "tokens": [51224, 544, 294, 7161, 960, 13, 759, 291, 1116, 411, 281, 1466, 544, 466, 300, 13, 407, 286, 603, 312, 988, 281, 1856, 257, 2113, 281, 51456], "temperature": 0.0, "avg_logprob": -0.04634896914164225, "compression_ratio": 1.8697318007662835, "no_speech_prob": 0.01743907667696476}, {"id": 303, "seek": 179952, "start": 1821.36, "end": 1825.6, "text": " that video in the description section below for anyone who's interested. Now even if we don't", "tokens": [51456, 300, 960, 294, 264, 3855, 3541, 2507, 337, 2878, 567, 311, 3102, 13, 823, 754, 498, 321, 500, 380, 51668], "temperature": 0.0, "avg_logprob": -0.04634896914164225, "compression_ratio": 1.8697318007662835, "no_speech_prob": 0.01743907667696476}, {"id": 304, "seek": 182560, "start": 1825.6, "end": 1830.9599999999998, "text": " grab our results within the context manager, it's still going to automatically join all of those", "tokens": [50364, 4444, 527, 3542, 1951, 264, 4319, 6598, 11, 309, 311, 920, 516, 281, 6772, 3917, 439, 295, 729, 50632], "temperature": 0.0, "avg_logprob": -0.04512930446200901, "compression_ratio": 1.7834101382488479, "no_speech_prob": 0.03844922035932541}, {"id": 305, "seek": 182560, "start": 1831.84, "end": 1838.32, "text": " processes and let them finish after the context manager ends. So if I comment out where we are", "tokens": [50676, 7555, 293, 718, 552, 2413, 934, 264, 4319, 6598, 5314, 13, 407, 498, 286, 2871, 484, 689, 321, 366, 51000], "temperature": 0.0, "avg_logprob": -0.04512930446200901, "compression_ratio": 1.7834101382488479, "no_speech_prob": 0.03844922035932541}, {"id": 306, "seek": 182560, "start": 1838.32, "end": 1844.8, "text": " printing out our results, let me also get rid of our old way of doing this here so that we can", "tokens": [51000, 14699, 484, 527, 3542, 11, 718, 385, 611, 483, 3973, 295, 527, 1331, 636, 295, 884, 341, 510, 370, 300, 321, 393, 51324], "temperature": 0.0, "avg_logprob": -0.04512930446200901, "compression_ratio": 1.7834101382488479, "no_speech_prob": 0.03844922035932541}, {"id": 307, "seek": 182560, "start": 1844.8, "end": 1850.8799999999999, "text": " see our code below our processes here. So now I'm commenting out where we're printing those results.", "tokens": [51324, 536, 527, 3089, 2507, 527, 7555, 510, 13, 407, 586, 286, 478, 29590, 484, 689, 321, 434, 14699, 729, 3542, 13, 51628], "temperature": 0.0, "avg_logprob": -0.04512930446200901, "compression_ratio": 1.7834101382488479, "no_speech_prob": 0.03844922035932541}, {"id": 308, "seek": 185088, "start": 1850.96, "end": 1857.2800000000002, "text": " And if I run this, then we can see that it still didn't move on to our finish time here", "tokens": [50368, 400, 498, 286, 1190, 341, 11, 550, 321, 393, 536, 300, 309, 920, 994, 380, 1286, 322, 281, 527, 2413, 565, 510, 50684], "temperature": 0.0, "avg_logprob": -0.05334185670923303, "compression_ratio": 1.7722007722007722, "no_speech_prob": 0.002714838134124875}, {"id": 309, "seek": 185088, "start": 1858.0800000000002, "end": 1864.48, "text": " until it returned the results from our processes. So anytime you're using a context manager like", "tokens": [50724, 1826, 309, 8752, 264, 3542, 490, 527, 7555, 13, 407, 13038, 291, 434, 1228, 257, 4319, 6598, 411, 51044], "temperature": 0.0, "avg_logprob": -0.05334185670923303, "compression_ratio": 1.7722007722007722, "no_speech_prob": 0.002714838134124875}, {"id": 310, "seek": 185088, "start": 1864.48, "end": 1870.0800000000002, "text": " this, it's going to automatically join those processes. And they're going to complete before", "tokens": [51044, 341, 11, 309, 311, 516, 281, 6772, 3917, 729, 7555, 13, 400, 436, 434, 516, 281, 3566, 949, 51324], "temperature": 0.0, "avg_logprob": -0.05334185670923303, "compression_ratio": 1.7722007722007722, "no_speech_prob": 0.002714838134124875}, {"id": 311, "seek": 185088, "start": 1870.0800000000002, "end": 1875.7600000000002, "text": " that context manager finishes. Okay, so now that we've looked at a basic example of using sleep,", "tokens": [51324, 300, 4319, 6598, 23615, 13, 1033, 11, 370, 586, 300, 321, 600, 2956, 412, 257, 3875, 1365, 295, 1228, 2817, 11, 51608], "temperature": 0.0, "avg_logprob": -0.05334185670923303, "compression_ratio": 1.7722007722007722, "no_speech_prob": 0.002714838134124875}, {"id": 312, "seek": 185088, "start": 1875.7600000000002, "end": 1880.0, "text": " now let's take a look at a more real world example of where using multiple processes", "tokens": [51608, 586, 718, 311, 747, 257, 574, 412, 257, 544, 957, 1002, 1365, 295, 689, 1228, 3866, 7555, 51820], "temperature": 0.0, "avg_logprob": -0.05334185670923303, "compression_ratio": 1.7722007722007722, "no_speech_prob": 0.002714838134124875}, {"id": 313, "seek": 188000, "start": 1880.0, "end": 1886.08, "text": " would be useful. So I've got another script open here where I'm not using multiple processes at", "tokens": [50364, 576, 312, 4420, 13, 407, 286, 600, 658, 1071, 5755, 1269, 510, 689, 286, 478, 406, 1228, 3866, 7555, 412, 50668], "temperature": 0.0, "avg_logprob": -0.03655616760253906, "compression_ratio": 1.664406779661017, "no_speech_prob": 0.00818672589957714}, {"id": 314, "seek": 188000, "start": 1886.08, "end": 1892.0, "text": " the moment. So let me open this up and let's go over what this is doing. And again, I'll have a", "tokens": [50668, 264, 1623, 13, 407, 718, 385, 1269, 341, 493, 293, 718, 311, 352, 670, 437, 341, 307, 884, 13, 400, 797, 11, 286, 603, 362, 257, 50964], "temperature": 0.0, "avg_logprob": -0.03655616760253906, "compression_ratio": 1.664406779661017, "no_speech_prob": 0.00818672589957714}, {"id": 315, "seek": 188000, "start": 1892.0, "end": 1896.96, "text": " link to this code in the description section below for anyone who wants to follow along. So in our", "tokens": [50964, 2113, 281, 341, 3089, 294, 264, 3855, 3541, 2507, 337, 2878, 567, 2738, 281, 1524, 2051, 13, 407, 294, 527, 51212], "temperature": 0.0, "avg_logprob": -0.03655616760253906, "compression_ratio": 1.664406779661017, "no_speech_prob": 0.00818672589957714}, {"id": 316, "seek": 188000, "start": 1896.96, "end": 1902.64, "text": " last video on threading, I showed how we could use threads to go out and download some high resolution", "tokens": [51212, 1036, 960, 322, 7207, 278, 11, 286, 4712, 577, 321, 727, 764, 19314, 281, 352, 484, 293, 5484, 512, 1090, 8669, 51496], "temperature": 0.0, "avg_logprob": -0.03655616760253906, "compression_ratio": 1.664406779661017, "no_speech_prob": 0.00818672589957714}, {"id": 317, "seek": 188000, "start": 1902.64, "end": 1908.08, "text": " photos from unsplash. Now if you don't know what unsplash is, it's a website that has some really", "tokens": [51496, 5787, 490, 2693, 564, 1299, 13, 823, 498, 291, 500, 380, 458, 437, 2693, 564, 1299, 307, 11, 309, 311, 257, 3144, 300, 575, 512, 534, 51768], "temperature": 0.0, "avg_logprob": -0.03655616760253906, "compression_ratio": 1.664406779661017, "no_speech_prob": 0.00818672589957714}, {"id": 318, "seek": 190808, "start": 1908.08, "end": 1914.56, "text": " nice photos available for anyone to use. Now downloading images is something that is IO bound", "tokens": [50364, 1481, 5787, 2435, 337, 2878, 281, 764, 13, 823, 32529, 5267, 307, 746, 300, 307, 39839, 5472, 50688], "temperature": 0.0, "avg_logprob": -0.038242313097108085, "compression_ratio": 1.8577075098814229, "no_speech_prob": 0.013219637796282768}, {"id": 319, "seek": 190808, "start": 1914.56, "end": 1920.1599999999999, "text": " since we're waiting for the images to download. So for this multi processing example, we want", "tokens": [50688, 1670, 321, 434, 3806, 337, 264, 5267, 281, 5484, 13, 407, 337, 341, 4825, 9007, 1365, 11, 321, 528, 50968], "temperature": 0.0, "avg_logprob": -0.038242313097108085, "compression_ratio": 1.8577075098814229, "no_speech_prob": 0.013219637796282768}, {"id": 320, "seek": 190808, "start": 1920.1599999999999, "end": 1925.28, "text": " something that is more CPU bound. So in this script, I'm doing some image processing on the", "tokens": [50968, 746, 300, 307, 544, 13199, 5472, 13, 407, 294, 341, 5755, 11, 286, 478, 884, 512, 3256, 9007, 322, 264, 51224], "temperature": 0.0, "avg_logprob": -0.038242313097108085, "compression_ratio": 1.8577075098814229, "no_speech_prob": 0.013219637796282768}, {"id": 321, "seek": 190808, "start": 1925.28, "end": 1929.9199999999998, "text": " images that we downloaded in the threading video. And I'll have these images available in the", "tokens": [51224, 5267, 300, 321, 21748, 294, 264, 7207, 278, 960, 13, 400, 286, 603, 362, 613, 5267, 2435, 294, 264, 51456], "temperature": 0.0, "avg_logprob": -0.038242313097108085, "compression_ratio": 1.8577075098814229, "no_speech_prob": 0.013219637796282768}, {"id": 322, "seek": 190808, "start": 1929.9199999999998, "end": 1934.8799999999999, "text": " description section below as well, in case anyone didn't follow along with that threading video.", "tokens": [51456, 3855, 3541, 2507, 382, 731, 11, 294, 1389, 2878, 994, 380, 1524, 2051, 365, 300, 7207, 278, 960, 13, 51704], "temperature": 0.0, "avg_logprob": -0.038242313097108085, "compression_ratio": 1.8577075098814229, "no_speech_prob": 0.013219637796282768}, {"id": 323, "seek": 193488, "start": 1934.88, "end": 1940.4, "text": " So let me go over the script to show you how someone might do this image processing normally.", "tokens": [50364, 407, 718, 385, 352, 670, 264, 5755, 281, 855, 291, 577, 1580, 1062, 360, 341, 3256, 9007, 5646, 13, 50640], "temperature": 0.0, "avg_logprob": -0.0653052380210475, "compression_ratio": 1.7443946188340806, "no_speech_prob": 0.00034597303601913154}, {"id": 324, "seek": 193488, "start": 1940.4, "end": 1947.3600000000001, "text": " So I'm using the pillow library here, which if you don't know what the pillow library is, it's a", "tokens": [50640, 407, 286, 478, 1228, 264, 18581, 6405, 510, 11, 597, 498, 291, 500, 380, 458, 437, 264, 18581, 6405, 307, 11, 309, 311, 257, 50988], "temperature": 0.0, "avg_logprob": -0.0653052380210475, "compression_ratio": 1.7443946188340806, "no_speech_prob": 0.00034597303601913154}, {"id": 325, "seek": 193488, "start": 1947.3600000000001, "end": 1953.6000000000001, "text": " image library for Python that makes it makes image processing easy. I also have a video on pillow if", "tokens": [50988, 3256, 6405, 337, 15329, 300, 1669, 309, 1669, 3256, 9007, 1858, 13, 286, 611, 362, 257, 960, 322, 18581, 498, 51300], "temperature": 0.0, "avg_logprob": -0.0653052380210475, "compression_ratio": 1.7443946188340806, "no_speech_prob": 0.00034597303601913154}, {"id": 326, "seek": 193488, "start": 1953.6000000000001, "end": 1959.3600000000001, "text": " you'd like to learn more about image processing. But I have a list here of image names. And these", "tokens": [51300, 291, 1116, 411, 281, 1466, 544, 466, 3256, 9007, 13, 583, 286, 362, 257, 1329, 510, 295, 3256, 5288, 13, 400, 613, 51588], "temperature": 0.0, "avg_logprob": -0.0653052380210475, "compression_ratio": 1.7443946188340806, "no_speech_prob": 0.00034597303601913154}, {"id": 327, "seek": 195936, "start": 1959.36, "end": 1965.1999999999998, "text": " are all of the images or all of the image names that we downloaded in the last video using threading.", "tokens": [50364, 366, 439, 295, 264, 5267, 420, 439, 295, 264, 3256, 5288, 300, 321, 21748, 294, 264, 1036, 960, 1228, 7207, 278, 13, 50656], "temperature": 0.0, "avg_logprob": -0.059735440193338596, "compression_ratio": 1.695852534562212, "no_speech_prob": 0.015422428026795387}, {"id": 328, "seek": 195936, "start": 1965.76, "end": 1971.4399999999998, "text": " So I am starting a counter here so that we can measure how long our script took.", "tokens": [50684, 407, 286, 669, 2891, 257, 5682, 510, 370, 300, 321, 393, 3481, 577, 938, 527, 5755, 1890, 13, 50968], "temperature": 0.0, "avg_logprob": -0.059735440193338596, "compression_ratio": 1.695852534562212, "no_speech_prob": 0.015422428026795387}, {"id": 329, "seek": 195936, "start": 1971.4399999999998, "end": 1978.0, "text": " I am setting a size of 1200 pixels. And that is what we are going to resize these high resolution", "tokens": [50968, 286, 669, 3287, 257, 2744, 295, 29139, 18668, 13, 400, 300, 307, 437, 321, 366, 516, 281, 50069, 613, 1090, 8669, 51296], "temperature": 0.0, "avg_logprob": -0.059735440193338596, "compression_ratio": 1.695852534562212, "no_speech_prob": 0.015422428026795387}, {"id": 330, "seek": 195936, "start": 1978.0, "end": 1984.6399999999999, "text": " photos to. Okay, and now what I am doing is I am looping over all of those image names.", "tokens": [51296, 5787, 281, 13, 1033, 11, 293, 586, 437, 286, 669, 884, 307, 286, 669, 6367, 278, 670, 439, 295, 729, 3256, 5288, 13, 51628], "temperature": 0.0, "avg_logprob": -0.059735440193338596, "compression_ratio": 1.695852534562212, "no_speech_prob": 0.015422428026795387}, {"id": 331, "seek": 198464, "start": 1984.64, "end": 1992.0, "text": " So with one image at a time, I am opening that image. And then I am running running this image", "tokens": [50364, 407, 365, 472, 3256, 412, 257, 565, 11, 286, 669, 5193, 300, 3256, 13, 400, 550, 286, 669, 2614, 2614, 341, 3256, 50732], "temperature": 0.0, "avg_logprob": -0.0634985177413277, "compression_ratio": 1.885, "no_speech_prob": 0.0017543942667543888}, {"id": 332, "seek": 198464, "start": 1992.0, "end": 1999.2, "text": " filter. And we're just doing a Gaussian blur on that image. And then I am doing an image thumbnail", "tokens": [50732, 6608, 13, 400, 321, 434, 445, 884, 257, 39148, 14257, 322, 300, 3256, 13, 400, 550, 286, 669, 884, 364, 3256, 26746, 51092], "temperature": 0.0, "avg_logprob": -0.0634985177413277, "compression_ratio": 1.885, "no_speech_prob": 0.0017543942667543888}, {"id": 333, "seek": 198464, "start": 1999.2, "end": 2007.5200000000002, "text": " and setting it to this 1200 pixel size. And then we are saving that image into a processed folder", "tokens": [51092, 293, 3287, 309, 281, 341, 29139, 19261, 2744, 13, 400, 550, 321, 366, 6816, 300, 3256, 666, 257, 18846, 10820, 51508], "temperature": 0.0, "avg_logprob": -0.0634985177413277, "compression_ratio": 1.885, "no_speech_prob": 0.0017543942667543888}, {"id": 334, "seek": 198464, "start": 2008.3200000000002, "end": 2014.0, "text": " with that the image name. And then we are printing out that that image was processed.", "tokens": [51548, 365, 300, 264, 3256, 1315, 13, 400, 550, 321, 366, 14699, 484, 300, 300, 3256, 390, 18846, 13, 51832], "temperature": 0.0, "avg_logprob": -0.0634985177413277, "compression_ratio": 1.885, "no_speech_prob": 0.0017543942667543888}, {"id": 335, "seek": 201400, "start": 2014.0, "end": 2019.6, "text": " Now I do have a processed folder here within my directory. If you don't, you'll probably get an", "tokens": [50364, 823, 286, 360, 362, 257, 18846, 10820, 510, 1951, 452, 21120, 13, 759, 291, 500, 380, 11, 291, 603, 1391, 483, 364, 50644], "temperature": 0.0, "avg_logprob": -0.0424601640857634, "compression_ratio": 1.8560311284046693, "no_speech_prob": 0.00023781439813319594}, {"id": 336, "seek": 201400, "start": 2019.6, "end": 2025.2, "text": " error. And I also have all of these photos here within my directory. If you don't have those,", "tokens": [50644, 6713, 13, 400, 286, 611, 362, 439, 295, 613, 5787, 510, 1951, 452, 21120, 13, 759, 291, 500, 380, 362, 729, 11, 50924], "temperature": 0.0, "avg_logprob": -0.0424601640857634, "compression_ratio": 1.8560311284046693, "no_speech_prob": 0.00023781439813319594}, {"id": 337, "seek": 201400, "start": 2025.2, "end": 2030.4, "text": " then you're also going to get an error. So you want to have all of those photos in order for", "tokens": [50924, 550, 291, 434, 611, 516, 281, 483, 364, 6713, 13, 407, 291, 528, 281, 362, 439, 295, 729, 5787, 294, 1668, 337, 51184], "temperature": 0.0, "avg_logprob": -0.0424601640857634, "compression_ratio": 1.8560311284046693, "no_speech_prob": 0.00023781439813319594}, {"id": 338, "seek": 201400, "start": 2030.4, "end": 2036.64, "text": " this code to work. Then after that's done, I am printing out the time that it took. And then", "tokens": [51184, 341, 3089, 281, 589, 13, 1396, 934, 300, 311, 1096, 11, 286, 669, 14699, 484, 264, 565, 300, 309, 1890, 13, 400, 550, 51496], "temperature": 0.0, "avg_logprob": -0.0424601640857634, "compression_ratio": 1.8560311284046693, "no_speech_prob": 0.00023781439813319594}, {"id": 339, "seek": 201400, "start": 2036.64, "end": 2043.28, "text": " I am printing out that our script is finished. Okay, so this is processing 15 high resolution photos.", "tokens": [51496, 286, 669, 14699, 484, 300, 527, 5755, 307, 4335, 13, 1033, 11, 370, 341, 307, 9007, 2119, 1090, 8669, 5787, 13, 51828], "temperature": 0.0, "avg_logprob": -0.0424601640857634, "compression_ratio": 1.8560311284046693, "no_speech_prob": 0.00023781439813319594}, {"id": 340, "seek": 204328, "start": 2043.28, "end": 2049.2799999999997, "text": " So if I run this now, then let's see how long this takes. So I'm running this, we can see that", "tokens": [50364, 407, 498, 286, 1190, 341, 586, 11, 550, 718, 311, 536, 577, 938, 341, 2516, 13, 407, 286, 478, 2614, 341, 11, 321, 393, 536, 300, 50664], "temperature": 0.0, "avg_logprob": -0.06904319354466029, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.0004441552155185491}, {"id": 341, "seek": 204328, "start": 2049.2799999999997, "end": 2056.16, "text": " it is just going through synchronously and running these one at a time. And then we will print out", "tokens": [50664, 309, 307, 445, 516, 807, 19331, 5098, 293, 2614, 613, 472, 412, 257, 565, 13, 400, 550, 321, 486, 4482, 484, 51008], "temperature": 0.0, "avg_logprob": -0.06904319354466029, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.0004441552155185491}, {"id": 342, "seek": 204328, "start": 2056.16, "end": 2063.04, "text": " the final time once this is done. Now, I think that my processing here, I think that this still", "tokens": [51008, 264, 2572, 565, 1564, 341, 307, 1096, 13, 823, 11, 286, 519, 300, 452, 9007, 510, 11, 286, 519, 300, 341, 920, 51352], "temperature": 0.0, "avg_logprob": -0.06904319354466029, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.0004441552155185491}, {"id": 343, "seek": 204328, "start": 2063.04, "end": 2069.44, "text": " might be more IO bound than CPU bound. Because opening the image and saving this here is going", "tokens": [51352, 1062, 312, 544, 39839, 5472, 813, 13199, 5472, 13, 1436, 5193, 264, 3256, 293, 6816, 341, 510, 307, 516, 51672], "temperature": 0.0, "avg_logprob": -0.06904319354466029, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.0004441552155185491}, {"id": 344, "seek": 206944, "start": 2069.52, "end": 2077.92, "text": " to be more of an IO bound thing. I don't know how much is actually getting CPU bound here using", "tokens": [50368, 281, 312, 544, 295, 364, 39839, 5472, 551, 13, 286, 500, 380, 458, 577, 709, 307, 767, 1242, 13199, 5472, 510, 1228, 50788], "temperature": 0.0, "avg_logprob": -0.05944683154424032, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.0006263128598220646}, {"id": 345, "seek": 206944, "start": 2077.92, "end": 2083.52, "text": " this filter. But if we were doing some more computations, then this would be more CPU bound.", "tokens": [50788, 341, 6608, 13, 583, 498, 321, 645, 884, 512, 544, 2807, 763, 11, 550, 341, 576, 312, 544, 13199, 5472, 13, 51068], "temperature": 0.0, "avg_logprob": -0.05944683154424032, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.0006263128598220646}, {"id": 346, "seek": 206944, "start": 2083.52, "end": 2089.44, "text": " And we can even test this in a second. But anyways, we can see that our script finished in 22", "tokens": [51068, 400, 321, 393, 754, 1500, 341, 294, 257, 1150, 13, 583, 13448, 11, 321, 393, 536, 300, 527, 5755, 4335, 294, 5853, 51364], "temperature": 0.0, "avg_logprob": -0.05944683154424032, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.0006263128598220646}, {"id": 347, "seek": 206944, "start": 2089.44, "end": 2096.88, "text": " seconds. So that's how long it took to do this image processing here on 15 of these high resolution", "tokens": [51364, 3949, 13, 407, 300, 311, 577, 938, 309, 1890, 281, 360, 341, 3256, 9007, 510, 322, 2119, 295, 613, 1090, 8669, 51736], "temperature": 0.0, "avg_logprob": -0.05944683154424032, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.0006263128598220646}, {"id": 348, "seek": 209688, "start": 2096.88, "end": 2101.92, "text": " photos. Now, when we're processing a lot of items like this, this is actually a great candidate to", "tokens": [50364, 5787, 13, 823, 11, 562, 321, 434, 9007, 257, 688, 295, 4754, 411, 341, 11, 341, 307, 767, 257, 869, 11532, 281, 50616], "temperature": 0.0, "avg_logprob": -0.06405472966422023, "compression_ratio": 1.8365019011406845, "no_speech_prob": 0.009124196134507656}, {"id": 349, "seek": 209688, "start": 2101.92, "end": 2108.4, "text": " use multi processing, because this can be one of those CPU bound operations that's spending a lot", "tokens": [50616, 764, 4825, 9007, 11, 570, 341, 393, 312, 472, 295, 729, 13199, 5472, 7705, 300, 311, 6434, 257, 688, 50940], "temperature": 0.0, "avg_logprob": -0.06405472966422023, "compression_ratio": 1.8365019011406845, "no_speech_prob": 0.009124196134507656}, {"id": 350, "seek": 209688, "start": 2108.4, "end": 2113.52, "text": " of time processing each image. And it's not moving on to the next image until the previous one", "tokens": [50940, 295, 565, 9007, 1184, 3256, 13, 400, 309, 311, 406, 2684, 322, 281, 264, 958, 3256, 1826, 264, 3894, 472, 51196], "temperature": 0.0, "avg_logprob": -0.06405472966422023, "compression_ratio": 1.8365019011406845, "no_speech_prob": 0.009124196134507656}, {"id": 351, "seek": 209688, "start": 2113.52, "end": 2119.28, "text": " finishes. And if we use multiple processes, then it can actually go ahead and move on to the to", "tokens": [51196, 23615, 13, 400, 498, 321, 764, 3866, 7555, 11, 550, 309, 393, 767, 352, 2286, 293, 1286, 322, 281, 264, 281, 51484], "temperature": 0.0, "avg_logprob": -0.06405472966422023, "compression_ratio": 1.8365019011406845, "no_speech_prob": 0.009124196134507656}, {"id": 352, "seek": 209688, "start": 2119.28, "end": 2125.04, "text": " process another image while the previous one is finishing. And even if this is IO bound, unlike", "tokens": [51484, 1399, 1071, 3256, 1339, 264, 3894, 472, 307, 12693, 13, 400, 754, 498, 341, 307, 39839, 5472, 11, 8343, 51772], "temperature": 0.0, "avg_logprob": -0.06405472966422023, "compression_ratio": 1.8365019011406845, "no_speech_prob": 0.009124196134507656}, {"id": 353, "seek": 212504, "start": 2125.04, "end": 2130.8, "text": " threading, CP or multi processing is actually going to be beneficial for IO bound processes as", "tokens": [50364, 7207, 278, 11, 22431, 420, 4825, 9007, 307, 767, 516, 281, 312, 14072, 337, 39839, 5472, 7555, 382, 50652], "temperature": 0.0, "avg_logprob": -0.059487073317818016, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.0026314910501241684}, {"id": 354, "seek": 212504, "start": 2130.8, "end": 2136.88, "text": " well. So now let's see how we can change this code so that it's using multiple processes instead.", "tokens": [50652, 731, 13, 407, 586, 718, 311, 536, 577, 321, 393, 1319, 341, 3089, 370, 300, 309, 311, 1228, 3866, 7555, 2602, 13, 50956], "temperature": 0.0, "avg_logprob": -0.059487073317818016, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.0026314910501241684}, {"id": 355, "seek": 212504, "start": 2136.88, "end": 2143.2799999999997, "text": " So first, let's think about what we're doing here. So we're looping over our list of images", "tokens": [50956, 407, 700, 11, 718, 311, 519, 466, 437, 321, 434, 884, 510, 13, 407, 321, 434, 6367, 278, 670, 527, 1329, 295, 5267, 51276], "temperature": 0.0, "avg_logprob": -0.059487073317818016, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.0026314910501241684}, {"id": 356, "seek": 212504, "start": 2143.2799999999997, "end": 2149.2799999999997, "text": " and processing each one at a time. So if we remember from our previous examples, then this", "tokens": [51276, 293, 9007, 1184, 472, 412, 257, 565, 13, 407, 498, 321, 1604, 490, 527, 3894, 5110, 11, 550, 341, 51576], "temperature": 0.0, "avg_logprob": -0.059487073317818016, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.0026314910501241684}, {"id": 357, "seek": 214928, "start": 2149.28, "end": 2156.1600000000003, "text": " would probably be a good candidate for the processing pull map method, where we can pass in a function", "tokens": [50364, 576, 1391, 312, 257, 665, 11532, 337, 264, 9007, 2235, 4471, 3170, 11, 689, 321, 393, 1320, 294, 257, 2445, 50708], "temperature": 0.0, "avg_logprob": -0.06100552709479081, "compression_ratio": 1.7709251101321586, "no_speech_prob": 0.01590488664805889}, {"id": 358, "seek": 214928, "start": 2156.1600000000003, "end": 2163.2000000000003, "text": " and a list and have that function run with every value in that list. But first we'll have to create", "tokens": [50708, 293, 257, 1329, 293, 362, 300, 2445, 1190, 365, 633, 2158, 294, 300, 1329, 13, 583, 700, 321, 603, 362, 281, 1884, 51060], "temperature": 0.0, "avg_logprob": -0.06100552709479081, "compression_ratio": 1.7709251101321586, "no_speech_prob": 0.01590488664805889}, {"id": 359, "seek": 214928, "start": 2163.2000000000003, "end": 2170.0, "text": " a function that will process a single image. So to do that, if we think about this, we can basically", "tokens": [51060, 257, 2445, 300, 486, 1399, 257, 2167, 3256, 13, 407, 281, 360, 300, 11, 498, 321, 519, 466, 341, 11, 321, 393, 1936, 51400], "temperature": 0.0, "avg_logprob": -0.06100552709479081, "compression_ratio": 1.7709251101321586, "no_speech_prob": 0.01590488664805889}, {"id": 360, "seek": 214928, "start": 2170.0, "end": 2177.28, "text": " just replace our for loop, because our for loop is processing a single image from our images list.", "tokens": [51400, 445, 7406, 527, 337, 6367, 11, 570, 527, 337, 6367, 307, 9007, 257, 2167, 3256, 490, 527, 5267, 1329, 13, 51764], "temperature": 0.0, "avg_logprob": -0.06100552709479081, "compression_ratio": 1.7709251101321586, "no_speech_prob": 0.01590488664805889}, {"id": 361, "seek": 217728, "start": 2177.28, "end": 2184.4, "text": " So instead, we can just change this one line here and just turn this into a process image function.", "tokens": [50364, 407, 2602, 11, 321, 393, 445, 1319, 341, 472, 1622, 510, 293, 445, 1261, 341, 666, 257, 1399, 3256, 2445, 13, 50720], "temperature": 0.0, "avg_logprob": -0.07571433960123265, "compression_ratio": 1.8073394495412844, "no_speech_prob": 0.00028684522840194404}, {"id": 362, "seek": 217728, "start": 2185.1200000000003, "end": 2190.8, "text": " And we will just accept this image name as the argument. And now that we have that function,", "tokens": [50756, 400, 321, 486, 445, 3241, 341, 3256, 1315, 382, 264, 6770, 13, 400, 586, 300, 321, 362, 300, 2445, 11, 51040], "temperature": 0.0, "avg_logprob": -0.07571433960123265, "compression_ratio": 1.8073394495412844, "no_speech_prob": 0.00028684522840194404}, {"id": 363, "seek": 217728, "start": 2190.8, "end": 2198.1600000000003, "text": " that process is a single image, then we can create a process pull and map our list of images using", "tokens": [51040, 300, 1399, 307, 257, 2167, 3256, 11, 550, 321, 393, 1884, 257, 1399, 2235, 293, 4471, 527, 1329, 295, 5267, 1228, 51408], "temperature": 0.0, "avg_logprob": -0.07571433960123265, "compression_ratio": 1.8073394495412844, "no_speech_prob": 0.00028684522840194404}, {"id": 364, "seek": 217728, "start": 2198.1600000000003, "end": 2204.96, "text": " that function. So first let's import the concurrent futures module so that we can use that. So up here", "tokens": [51408, 300, 2445, 13, 407, 700, 718, 311, 974, 264, 37702, 26071, 10088, 370, 300, 321, 393, 764, 300, 13, 407, 493, 510, 51748], "temperature": 0.0, "avg_logprob": -0.07571433960123265, "compression_ratio": 1.8073394495412844, "no_speech_prob": 0.00028684522840194404}, {"id": 365, "seek": 220496, "start": 2204.96, "end": 2215.76, "text": " at the top, I'm going to import concurrent dot futures. And now down here below our function,", "tokens": [50364, 412, 264, 1192, 11, 286, 478, 516, 281, 974, 37702, 5893, 26071, 13, 400, 586, 760, 510, 2507, 527, 2445, 11, 50904], "temperature": 0.0, "avg_logprob": -0.0898525507553764, "compression_ratio": 1.4566929133858268, "no_speech_prob": 0.003945102449506521}, {"id": 366, "seek": 220496, "start": 2216.48, "end": 2229.76, "text": " we can do this by saying with concurrent dot futures dot process pull executor as executor.", "tokens": [50940, 321, 393, 360, 341, 538, 1566, 365, 37702, 5893, 26071, 5893, 1399, 2235, 7568, 284, 382, 7568, 284, 13, 51604], "temperature": 0.0, "avg_logprob": -0.0898525507553764, "compression_ratio": 1.4566929133858268, "no_speech_prob": 0.003945102449506521}, {"id": 367, "seek": 222976, "start": 2230.5600000000004, "end": 2240.96, "text": " And now within our context manager, we can just say executor dot map. And we want to map this", "tokens": [50404, 400, 586, 1951, 527, 4319, 6598, 11, 321, 393, 445, 584, 7568, 284, 5893, 4471, 13, 400, 321, 528, 281, 4471, 341, 50924], "temperature": 0.0, "avg_logprob": -0.08002301057179768, "compression_ratio": 1.554945054945055, "no_speech_prob": 0.002115598414093256}, {"id": 368, "seek": 222976, "start": 2240.96, "end": 2251.84, "text": " process image function. And we want to pass in the list of these image names. Now, just in case", "tokens": [50924, 1399, 3256, 2445, 13, 400, 321, 528, 281, 1320, 294, 264, 1329, 295, 613, 3256, 5288, 13, 823, 11, 445, 294, 1389, 51468], "temperature": 0.0, "avg_logprob": -0.08002301057179768, "compression_ratio": 1.554945054945055, "no_speech_prob": 0.002115598414093256}, {"id": 369, "seek": 222976, "start": 2251.84, "end": 2259.0400000000004, "text": " that was confusing, let me go over exactly what we did again, in order to change our previous", "tokens": [51468, 300, 390, 13181, 11, 718, 385, 352, 670, 2293, 437, 321, 630, 797, 11, 294, 1668, 281, 1319, 527, 3894, 51828], "temperature": 0.0, "avg_logprob": -0.08002301057179768, "compression_ratio": 1.554945054945055, "no_speech_prob": 0.002115598414093256}, {"id": 370, "seek": 225904, "start": 2259.04, "end": 2264.64, "text": " script in order to use multiprocessing. So we were using a for loop here. But instead,", "tokens": [50364, 5755, 294, 1668, 281, 764, 3311, 340, 780, 278, 13, 407, 321, 645, 1228, 257, 337, 6367, 510, 13, 583, 2602, 11, 50644], "temperature": 0.0, "avg_logprob": -0.08450903943789903, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.0005357535555958748}, {"id": 371, "seek": 225904, "start": 2264.64, "end": 2269.7599999999998, "text": " we changed this to a function that processes one image at a time. And now we're using our", "tokens": [50644, 321, 3105, 341, 281, 257, 2445, 300, 7555, 472, 3256, 412, 257, 565, 13, 400, 586, 321, 434, 1228, 527, 50900], "temperature": 0.0, "avg_logprob": -0.08450903943789903, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.0005357535555958748}, {"id": 372, "seek": 225904, "start": 2269.7599999999998, "end": 2276.56, "text": " processing pull executor like we saw before within a context manager, we're running executor dot map.", "tokens": [50900, 9007, 2235, 7568, 284, 411, 321, 1866, 949, 1951, 257, 4319, 6598, 11, 321, 434, 2614, 7568, 284, 5893, 4471, 13, 51240], "temperature": 0.0, "avg_logprob": -0.08450903943789903, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.0005357535555958748}, {"id": 373, "seek": 225904, "start": 2276.56, "end": 2282.64, "text": " And we are passing in that function that we created. And then we're passing in our list of", "tokens": [51240, 400, 321, 366, 8437, 294, 300, 2445, 300, 321, 2942, 13, 400, 550, 321, 434, 8437, 294, 527, 1329, 295, 51544], "temperature": 0.0, "avg_logprob": -0.08450903943789903, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.0005357535555958748}, {"id": 374, "seek": 228264, "start": 2282.64, "end": 2290.7999999999997, "text": " image names. And again, what map does is it runs this process image function with every item in", "tokens": [50364, 3256, 5288, 13, 400, 797, 11, 437, 4471, 775, 307, 309, 6676, 341, 1399, 3256, 2445, 365, 633, 3174, 294, 50772], "temperature": 0.0, "avg_logprob": -0.0552658516427745, "compression_ratio": 1.6596638655462186, "no_speech_prob": 0.06753790378570557}, {"id": 375, "seek": 228264, "start": 2290.7999999999997, "end": 2296.64, "text": " this image names list. And just with those small changes, this will actually use multiple processes", "tokens": [50772, 341, 3256, 5288, 1329, 13, 400, 445, 365, 729, 1359, 2962, 11, 341, 486, 767, 764, 3866, 7555, 51064], "temperature": 0.0, "avg_logprob": -0.0552658516427745, "compression_ratio": 1.6596638655462186, "no_speech_prob": 0.06753790378570557}, {"id": 376, "seek": 228264, "start": 2296.64, "end": 2303.8399999999997, "text": " to process those images and run these in parallel, instead of running these synchronously. So if I", "tokens": [51064, 281, 1399, 729, 5267, 293, 1190, 613, 294, 8952, 11, 2602, 295, 2614, 613, 19331, 5098, 13, 407, 498, 286, 51424], "temperature": 0.0, "avg_logprob": -0.0552658516427745, "compression_ratio": 1.6596638655462186, "no_speech_prob": 0.06753790378570557}, {"id": 377, "seek": 228264, "start": 2303.8399999999997, "end": 2310.8799999999997, "text": " run this, whoops, and I made another mistake here, you guys probably saw that one also. But I needed", "tokens": [51424, 1190, 341, 11, 567, 3370, 11, 293, 286, 1027, 1071, 6146, 510, 11, 291, 1074, 1391, 1866, 300, 472, 611, 13, 583, 286, 2978, 51776], "temperature": 0.0, "avg_logprob": -0.0552658516427745, "compression_ratio": 1.6596638655462186, "no_speech_prob": 0.06753790378570557}, {"id": 378, "seek": 231088, "start": 2310.88, "end": 2316.48, "text": " to put a colon there. Okay, hopefully that's my only mistake. Okay, so if I run this, then we can", "tokens": [50364, 281, 829, 257, 8255, 456, 13, 1033, 11, 4696, 300, 311, 452, 787, 6146, 13, 1033, 11, 370, 498, 286, 1190, 341, 11, 550, 321, 393, 50644], "temperature": 0.0, "avg_logprob": -0.05299209779308688, "compression_ratio": 1.8148148148148149, "no_speech_prob": 0.00712081091478467}, {"id": 379, "seek": 231088, "start": 2316.48, "end": 2321.76, "text": " see now these are processing faster. And I'm going to open up my activity monitor here, and scroll", "tokens": [50644, 536, 586, 613, 366, 9007, 4663, 13, 400, 286, 478, 516, 281, 1269, 493, 452, 5191, 6002, 510, 11, 293, 11369, 50908], "temperature": 0.0, "avg_logprob": -0.05299209779308688, "compression_ratio": 1.8148148148148149, "no_speech_prob": 0.00712081091478467}, {"id": 380, "seek": 231088, "start": 2321.76, "end": 2328.4, "text": " down to the P's. And we can see here that we have multiple Python processes running here. So we can", "tokens": [50908, 760, 281, 264, 430, 311, 13, 400, 321, 393, 536, 510, 300, 321, 362, 3866, 15329, 7555, 2614, 510, 13, 407, 321, 393, 51240], "temperature": 0.0, "avg_logprob": -0.05299209779308688, "compression_ratio": 1.8148148148148149, "no_speech_prob": 0.00712081091478467}, {"id": 381, "seek": 231088, "start": 2328.4, "end": 2334.32, "text": " actually see these in our activity monitor. And now that this script is finished, then we can see", "tokens": [51240, 767, 536, 613, 294, 527, 5191, 6002, 13, 400, 586, 300, 341, 5755, 307, 4335, 11, 550, 321, 393, 536, 51536], "temperature": 0.0, "avg_logprob": -0.05299209779308688, "compression_ratio": 1.8148148148148149, "no_speech_prob": 0.00712081091478467}, {"id": 382, "seek": 231088, "start": 2334.32, "end": 2339.6, "text": " most of those go away. The only one that's still here is probably just one that is open here in", "tokens": [51536, 881, 295, 729, 352, 1314, 13, 440, 787, 472, 300, 311, 920, 510, 307, 1391, 445, 472, 300, 307, 1269, 510, 294, 51800], "temperature": 0.0, "avg_logprob": -0.05299209779308688, "compression_ratio": 1.8148148148148149, "no_speech_prob": 0.00712081091478467}, {"id": 383, "seek": 233960, "start": 2339.6, "end": 2345.68, "text": " my sublime text. So we could see all of those kick off in our activity monitor. And we could see that", "tokens": [50364, 452, 1422, 40941, 2487, 13, 407, 321, 727, 536, 439, 295, 729, 4437, 766, 294, 527, 5191, 6002, 13, 400, 321, 727, 536, 300, 50668], "temperature": 0.0, "avg_logprob": -0.060563455548202784, "compression_ratio": 1.8084291187739463, "no_speech_prob": 0.001454993151128292}, {"id": 384, "seek": 233960, "start": 2345.68, "end": 2350.4, "text": " they were all returning faster. That's because they were running in parallel. And now instead of", "tokens": [50668, 436, 645, 439, 12678, 4663, 13, 663, 311, 570, 436, 645, 2614, 294, 8952, 13, 400, 586, 2602, 295, 50904], "temperature": 0.0, "avg_logprob": -0.060563455548202784, "compression_ratio": 1.8084291187739463, "no_speech_prob": 0.001454993151128292}, {"id": 385, "seek": 233960, "start": 2350.4, "end": 2356.72, "text": " taking 22 seconds, like it did before, now it finished in seven seconds, so more than a third", "tokens": [50904, 1940, 5853, 3949, 11, 411, 309, 630, 949, 11, 586, 309, 4335, 294, 3407, 3949, 11, 370, 544, 813, 257, 2636, 51220], "temperature": 0.0, "avg_logprob": -0.060563455548202784, "compression_ratio": 1.8084291187739463, "no_speech_prob": 0.001454993151128292}, {"id": 386, "seek": 233960, "start": 2356.72, "end": 2361.68, "text": " of the time. So that's a pretty significant speed up there. And this would be even more", "tokens": [51220, 295, 264, 565, 13, 407, 300, 311, 257, 1238, 4776, 3073, 493, 456, 13, 400, 341, 576, 312, 754, 544, 51468], "temperature": 0.0, "avg_logprob": -0.060563455548202784, "compression_ratio": 1.8084291187739463, "no_speech_prob": 0.001454993151128292}, {"id": 387, "seek": 233960, "start": 2361.68, "end": 2366.88, "text": " significant if we were processing even more images. So the speed ups can be pretty drastic,", "tokens": [51468, 4776, 498, 321, 645, 9007, 754, 544, 5267, 13, 407, 264, 3073, 15497, 393, 312, 1238, 36821, 11, 51728], "temperature": 0.0, "avg_logprob": -0.060563455548202784, "compression_ratio": 1.8084291187739463, "no_speech_prob": 0.001454993151128292}, {"id": 388, "seek": 236688, "start": 2366.96, "end": 2372.1600000000003, "text": " depending on what you're doing. Now, again, you might want to experiment when using multiple", "tokens": [50368, 5413, 322, 437, 291, 434, 884, 13, 823, 11, 797, 11, 291, 1062, 528, 281, 5120, 562, 1228, 3866, 50628], "temperature": 0.0, "avg_logprob": -0.05742974866900528, "compression_ratio": 1.8265682656826567, "no_speech_prob": 0.05260559171438217}, {"id": 389, "seek": 236688, "start": 2372.1600000000003, "end": 2377.36, "text": " threads or processes for specific tasks, depending on what you're doing and what kind of hardware", "tokens": [50628, 19314, 420, 7555, 337, 2685, 9608, 11, 5413, 322, 437, 291, 434, 884, 293, 437, 733, 295, 8837, 50888], "temperature": 0.0, "avg_logprob": -0.05742974866900528, "compression_ratio": 1.8265682656826567, "no_speech_prob": 0.05260559171438217}, {"id": 390, "seek": 236688, "start": 2377.36, "end": 2382.4, "text": " you're running. One might be drastically different than the other. And it's hard to tell exactly what", "tokens": [50888, 291, 434, 2614, 13, 1485, 1062, 312, 29673, 819, 813, 264, 661, 13, 400, 309, 311, 1152, 281, 980, 2293, 437, 51140], "temperature": 0.0, "avg_logprob": -0.05742974866900528, "compression_ratio": 1.8265682656826567, "no_speech_prob": 0.05260559171438217}, {"id": 391, "seek": 236688, "start": 2382.4, "end": 2387.44, "text": " you should be using without some benchmarks. But again, a good rule of thumb is that you want to use", "tokens": [51140, 291, 820, 312, 1228, 1553, 512, 43751, 13, 583, 797, 11, 257, 665, 4978, 295, 9298, 307, 300, 291, 528, 281, 764, 51392], "temperature": 0.0, "avg_logprob": -0.05742974866900528, "compression_ratio": 1.8265682656826567, "no_speech_prob": 0.05260559171438217}, {"id": 392, "seek": 236688, "start": 2387.44, "end": 2393.52, "text": " threads for things that are IO bound. And you'll want to use processes for things that are CPU bound.", "tokens": [51392, 19314, 337, 721, 300, 366, 39839, 5472, 13, 400, 291, 603, 528, 281, 764, 7555, 337, 721, 300, 366, 13199, 5472, 13, 51696], "temperature": 0.0, "avg_logprob": -0.05742974866900528, "compression_ratio": 1.8265682656826567, "no_speech_prob": 0.05260559171438217}, {"id": 393, "seek": 239352, "start": 2393.52, "end": 2400.0, "text": " But you may actually see significant speed ups using threads with this example, since this is", "tokens": [50364, 583, 291, 815, 767, 536, 4776, 3073, 15497, 1228, 19314, 365, 341, 1365, 11, 1670, 341, 307, 50688], "temperature": 0.0, "avg_logprob": -0.06583693550854194, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.00044419063488021493}, {"id": 394, "seek": 239352, "start": 2400.0, "end": 2405.7599999999998, "text": " reading and writing to disk, which is an IO bound operation. Now, one nice thing about using the", "tokens": [50688, 3760, 293, 3579, 281, 12355, 11, 597, 307, 364, 39839, 5472, 6916, 13, 823, 11, 472, 1481, 551, 466, 1228, 264, 50976], "temperature": 0.0, "avg_logprob": -0.06583693550854194, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.00044419063488021493}, {"id": 395, "seek": 239352, "start": 2405.7599999999998, "end": 2410.72, "text": " concurrent futures library like this is that switching between threads and processes is just", "tokens": [50976, 37702, 26071, 6405, 411, 341, 307, 300, 16493, 1296, 19314, 293, 7555, 307, 445, 51224], "temperature": 0.0, "avg_logprob": -0.06583693550854194, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.00044419063488021493}, {"id": 396, "seek": 239352, "start": 2410.72, "end": 2417.6, "text": " as simple as changing this process pull executor, and just using a thread pull executor instead.", "tokens": [51224, 382, 2199, 382, 4473, 341, 1399, 2235, 7568, 284, 11, 293, 445, 1228, 257, 7207, 2235, 7568, 284, 2602, 13, 51568], "temperature": 0.0, "avg_logprob": -0.06583693550854194, "compression_ratio": 1.6888888888888889, "no_speech_prob": 0.00044419063488021493}, {"id": 397, "seek": 241760, "start": 2417.6, "end": 2424.72, "text": " And you can do that vice versa to change from threads to processes with your programs. So", "tokens": [50364, 400, 291, 393, 360, 300, 11964, 25650, 281, 1319, 490, 19314, 281, 7555, 365, 428, 4268, 13, 407, 50720], "temperature": 0.0, "avg_logprob": -0.05128728465030068, "compression_ratio": 1.6008583690987124, "no_speech_prob": 0.005060022696852684}, {"id": 398, "seek": 241760, "start": 2424.72, "end": 2430.24, "text": " if I change this to a thread pull executor, let me see if I'm right about a lot of this", "tokens": [50720, 498, 286, 1319, 341, 281, 257, 7207, 2235, 7568, 284, 11, 718, 385, 536, 498, 286, 478, 558, 466, 257, 688, 295, 341, 50996], "temperature": 0.0, "avg_logprob": -0.05128728465030068, "compression_ratio": 1.6008583690987124, "no_speech_prob": 0.005060022696852684}, {"id": 399, "seek": 241760, "start": 2430.24, "end": 2437.12, "text": " being IO bound here. If I run this, then we'll see how long this takes us to finish this script", "tokens": [50996, 885, 39839, 5472, 510, 13, 759, 286, 1190, 341, 11, 550, 321, 603, 536, 577, 938, 341, 2516, 505, 281, 2413, 341, 5755, 51340], "temperature": 0.0, "avg_logprob": -0.05128728465030068, "compression_ratio": 1.6008583690987124, "no_speech_prob": 0.005060022696852684}, {"id": 400, "seek": 241760, "start": 2437.12, "end": 2443.2, "text": " using threads instead of multiple processes. And that was actually faster. So that was 7.2 seconds.", "tokens": [51340, 1228, 19314, 2602, 295, 3866, 7555, 13, 400, 300, 390, 767, 4663, 13, 407, 300, 390, 1614, 13, 17, 3949, 13, 51644], "temperature": 0.0, "avg_logprob": -0.05128728465030068, "compression_ratio": 1.6008583690987124, "no_speech_prob": 0.005060022696852684}, {"id": 401, "seek": 244320, "start": 2443.2, "end": 2449.04, "text": " So even though I tried to put together an example that was doing a lot of processing on the CPU,", "tokens": [50364, 407, 754, 1673, 286, 3031, 281, 829, 1214, 364, 1365, 300, 390, 884, 257, 688, 295, 9007, 322, 264, 13199, 11, 50656], "temperature": 0.0, "avg_logprob": -0.08238993572587726, "compression_ratio": 1.6968641114982579, "no_speech_prob": 0.0008558527333661914}, {"id": 402, "seek": 244320, "start": 2449.04, "end": 2455.9199999999996, "text": " it looks like most of this is IO bound from opening and saving these files and not CPU bound, but from", "tokens": [50656, 309, 1542, 411, 881, 295, 341, 307, 39839, 5472, 490, 5193, 293, 6816, 613, 7098, 293, 406, 13199, 5472, 11, 457, 490, 51000], "temperature": 0.0, "avg_logprob": -0.08238993572587726, "compression_ratio": 1.6968641114982579, "no_speech_prob": 0.0008558527333661914}, {"id": 403, "seek": 244320, "start": 2455.9199999999996, "end": 2460.64, "text": " doing some image processing here with these Gaussian blurs and these resizes and things like that.", "tokens": [51000, 884, 512, 3256, 9007, 510, 365, 613, 39148, 888, 2156, 293, 613, 725, 5660, 293, 721, 411, 300, 13, 51236], "temperature": 0.0, "avg_logprob": -0.08238993572587726, "compression_ratio": 1.6968641114982579, "no_speech_prob": 0.0008558527333661914}, {"id": 404, "seek": 244320, "start": 2460.64, "end": 2466.72, "text": " But that's okay. That's why you want to always experiment. And, you know, if you try it with", "tokens": [51236, 583, 300, 311, 1392, 13, 663, 311, 983, 291, 528, 281, 1009, 5120, 13, 400, 11, 291, 458, 11, 498, 291, 853, 309, 365, 51540], "temperature": 0.0, "avg_logprob": -0.08238993572587726, "compression_ratio": 1.6968641114982579, "no_speech_prob": 0.0008558527333661914}, {"id": 405, "seek": 244320, "start": 2466.72, "end": 2471.9199999999996, "text": " a process pulled, and maybe try it once with threads and see if you get a better execution. And", "tokens": [51540, 257, 1399, 7373, 11, 293, 1310, 853, 309, 1564, 365, 19314, 293, 536, 498, 291, 483, 257, 1101, 15058, 13, 400, 51800], "temperature": 0.0, "avg_logprob": -0.08238993572587726, "compression_ratio": 1.6968641114982579, "no_speech_prob": 0.0008558527333661914}, {"id": 406, "seek": 247192, "start": 2472.0, "end": 2478.4, "text": " also, whenever you add in even more items, maybe processes will start to become", "tokens": [50368, 611, 11, 5699, 291, 909, 294, 754, 544, 4754, 11, 1310, 7555, 486, 722, 281, 1813, 50688], "temperature": 0.0, "avg_logprob": -0.06578372142933032, "compression_ratio": 1.6373626373626373, "no_speech_prob": 0.001098678563721478}, {"id": 407, "seek": 247192, "start": 2478.4, "end": 2482.88, "text": " more performant than threads. So it really just depends on what you're doing. Now,", "tokens": [50688, 544, 2042, 394, 813, 19314, 13, 407, 309, 534, 445, 5946, 322, 437, 291, 434, 884, 13, 823, 11, 50912], "temperature": 0.0, "avg_logprob": -0.06578372142933032, "compression_ratio": 1.6373626373626373, "no_speech_prob": 0.001098678563721478}, {"id": 408, "seek": 247192, "start": 2482.88, "end": 2488.16, "text": " before we finish up here, I'd like to mention the sponsor of this video. And that is brilliant.org.", "tokens": [50912, 949, 321, 2413, 493, 510, 11, 286, 1116, 411, 281, 2152, 264, 16198, 295, 341, 960, 13, 400, 300, 307, 10248, 13, 4646, 13, 51176], "temperature": 0.0, "avg_logprob": -0.06578372142933032, "compression_ratio": 1.6373626373626373, "no_speech_prob": 0.001098678563721478}, {"id": 409, "seek": 247192, "start": 2488.16, "end": 2493.44, "text": " So when we're talking about threading and multi processing, these topics are especially useful", "tokens": [51176, 407, 562, 321, 434, 1417, 466, 7207, 278, 293, 4825, 9007, 11, 613, 8378, 366, 2318, 4420, 51440], "temperature": 0.0, "avg_logprob": -0.06578372142933032, "compression_ratio": 1.6373626373626373, "no_speech_prob": 0.001098678563721478}, {"id": 410, "seek": 247192, "start": 2493.44, "end": 2498.56, "text": " in the field of data science. And the data science field is growing at a very rapid pace.", "tokens": [51440, 294, 264, 2519, 295, 1412, 3497, 13, 400, 264, 1412, 3497, 2519, 307, 4194, 412, 257, 588, 7558, 11638, 13, 51696], "temperature": 0.0, "avg_logprob": -0.06578372142933032, "compression_ratio": 1.6373626373626373, "no_speech_prob": 0.001098678563721478}, {"id": 411, "seek": 249856, "start": 2498.56, "end": 2502.4, "text": " If you'd like to learn more about programming and data science, then I would definitely recommend", "tokens": [50364, 759, 291, 1116, 411, 281, 1466, 544, 466, 9410, 293, 1412, 3497, 11, 550, 286, 576, 2138, 2748, 50556], "temperature": 0.0, "avg_logprob": -0.042224018974641786, "compression_ratio": 1.8664495114006514, "no_speech_prob": 0.0038239520508795977}, {"id": 412, "seek": 249856, "start": 2502.4, "end": 2507.68, "text": " checking out brilliant.org. So brilliant is a problem solving website that helps you understand", "tokens": [50556, 8568, 484, 10248, 13, 4646, 13, 407, 10248, 307, 257, 1154, 12606, 3144, 300, 3665, 291, 1223, 50820], "temperature": 0.0, "avg_logprob": -0.042224018974641786, "compression_ratio": 1.8664495114006514, "no_speech_prob": 0.0038239520508795977}, {"id": 413, "seek": 249856, "start": 2507.68, "end": 2513.12, "text": " underlying concepts by actively working through guided lessons. And they've recently added some", "tokens": [50820, 14217, 10392, 538, 13022, 1364, 807, 19663, 8820, 13, 400, 436, 600, 3938, 3869, 512, 51092], "temperature": 0.0, "avg_logprob": -0.042224018974641786, "compression_ratio": 1.8664495114006514, "no_speech_prob": 0.0038239520508795977}, {"id": 414, "seek": 249856, "start": 2513.12, "end": 2518.7999999999997, "text": " brand new interactive content that makes solving puzzles and challenges even more fun and hands", "tokens": [51092, 3360, 777, 15141, 2701, 300, 1669, 12606, 24138, 293, 4759, 754, 544, 1019, 293, 2377, 51376], "temperature": 0.0, "avg_logprob": -0.042224018974641786, "compression_ratio": 1.8664495114006514, "no_speech_prob": 0.0038239520508795977}, {"id": 415, "seek": 249856, "start": 2518.7999999999997, "end": 2523.44, "text": " on. And if you'd like to learn more about data science and programming with Python, then I would", "tokens": [51376, 322, 13, 400, 498, 291, 1116, 411, 281, 1466, 544, 466, 1412, 3497, 293, 9410, 365, 15329, 11, 550, 286, 576, 51608], "temperature": 0.0, "avg_logprob": -0.042224018974641786, "compression_ratio": 1.8664495114006514, "no_speech_prob": 0.0038239520508795977}, {"id": 416, "seek": 249856, "start": 2523.44, "end": 2528.08, "text": " recommend checking out their new probability course that covers everything from the basics", "tokens": [51608, 2748, 8568, 484, 641, 777, 8482, 1164, 300, 10538, 1203, 490, 264, 14688, 51840], "temperature": 0.0, "avg_logprob": -0.042224018974641786, "compression_ratio": 1.8664495114006514, "no_speech_prob": 0.0038239520508795977}, {"id": 417, "seek": 252808, "start": 2528.08, "end": 2533.92, "text": " to real world applications and also fun things like casino games. They even use Python in their", "tokens": [50364, 281, 957, 1002, 5821, 293, 611, 1019, 721, 411, 36278, 2813, 13, 814, 754, 764, 15329, 294, 641, 50656], "temperature": 0.0, "avg_logprob": -0.05553840809181088, "compression_ratio": 1.7280966767371602, "no_speech_prob": 0.0013453328283503652}, {"id": 418, "seek": 252808, "start": 2533.92, "end": 2539.2799999999997, "text": " statistics courses and will quiz you on how to correctly analyze the data within the language.", "tokens": [50656, 12523, 7712, 293, 486, 15450, 291, 322, 577, 281, 8944, 12477, 264, 1412, 1951, 264, 2856, 13, 50924], "temperature": 0.0, "avg_logprob": -0.05553840809181088, "compression_ratio": 1.7280966767371602, "no_speech_prob": 0.0013453328283503652}, {"id": 419, "seek": 252808, "start": 2539.2799999999997, "end": 2543.6, "text": " So their guided lessons will challenge you, but you also have the ability to get hints or even", "tokens": [50924, 407, 641, 19663, 8820, 486, 3430, 291, 11, 457, 291, 611, 362, 264, 3485, 281, 483, 27271, 420, 754, 51140], "temperature": 0.0, "avg_logprob": -0.05553840809181088, "compression_ratio": 1.7280966767371602, "no_speech_prob": 0.0013453328283503652}, {"id": 420, "seek": 252808, "start": 2543.6, "end": 2548.16, "text": " solutions if you need them. It's really tailored towards understanding the material. They even", "tokens": [51140, 6547, 498, 291, 643, 552, 13, 467, 311, 534, 34858, 3030, 3701, 264, 2527, 13, 814, 754, 51368], "temperature": 0.0, "avg_logprob": -0.05553840809181088, "compression_ratio": 1.7280966767371602, "no_speech_prob": 0.0013453328283503652}, {"id": 421, "seek": 252808, "start": 2548.16, "end": 2553.2, "text": " have a coding environment built into their website so that you can run code directly in the browser.", "tokens": [51368, 362, 257, 17720, 2823, 3094, 666, 641, 3144, 370, 300, 291, 393, 1190, 3089, 3838, 294, 264, 11185, 13, 51620], "temperature": 0.0, "avg_logprob": -0.05553840809181088, "compression_ratio": 1.7280966767371602, "no_speech_prob": 0.0013453328283503652}, {"id": 422, "seek": 252808, "start": 2553.2, "end": 2557.2, "text": " And that is a great compliment to watching my tutorials, because you can apply what you've", "tokens": [51620, 400, 300, 307, 257, 869, 16250, 281, 1976, 452, 17616, 11, 570, 291, 393, 3079, 437, 291, 600, 51820], "temperature": 0.0, "avg_logprob": -0.05553840809181088, "compression_ratio": 1.7280966767371602, "no_speech_prob": 0.0013453328283503652}, {"id": 423, "seek": 255720, "start": 2557.2, "end": 2561.9199999999996, "text": " learned in their active problem solving environment. And that helps to solidify that knowledge.", "tokens": [50364, 3264, 294, 641, 4967, 1154, 12606, 2823, 13, 400, 300, 3665, 281, 5100, 2505, 300, 3601, 13, 50600], "temperature": 0.0, "avg_logprob": -0.08204795603166547, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.054976630955934525}, {"id": 424, "seek": 255720, "start": 2561.9199999999996, "end": 2567.9199999999996, "text": " So to support my channel and learn more about brilliant, you can go to brilliant.org forward slash", "tokens": [50600, 407, 281, 1406, 452, 2269, 293, 1466, 544, 466, 10248, 11, 291, 393, 352, 281, 10248, 13, 4646, 2128, 17330, 50900], "temperature": 0.0, "avg_logprob": -0.08204795603166547, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.054976630955934525}, {"id": 425, "seek": 255720, "start": 2567.9199999999996, "end": 2574.08, "text": " CMS to sign up for free. And also the first 200 people that go to that link will get 20% off the", "tokens": [50900, 33124, 281, 1465, 493, 337, 1737, 13, 400, 611, 264, 700, 2331, 561, 300, 352, 281, 300, 2113, 486, 483, 945, 4, 766, 264, 51208], "temperature": 0.0, "avg_logprob": -0.08204795603166547, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.054976630955934525}, {"id": 426, "seek": 255720, "start": 2574.08, "end": 2578.3999999999996, "text": " annual premium subscription. And you can find that link in the description section below. And", "tokens": [51208, 9784, 12049, 17231, 13, 400, 291, 393, 915, 300, 2113, 294, 264, 3855, 3541, 2507, 13, 400, 51424], "temperature": 0.0, "avg_logprob": -0.08204795603166547, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.054976630955934525}, {"id": 427, "seek": 255720, "start": 2578.3999999999996, "end": 2584.7999999999997, "text": " again, that is brilliant.org forward slash CMS. Okay, so I think that's going to do it for this", "tokens": [51424, 797, 11, 300, 307, 10248, 13, 4646, 2128, 17330, 33124, 13, 1033, 11, 370, 286, 519, 300, 311, 516, 281, 360, 309, 337, 341, 51744], "temperature": 0.0, "avg_logprob": -0.08204795603166547, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.054976630955934525}, {"id": 428, "seek": 258480, "start": 2584.8, "end": 2589.76, "text": " video. I hope you feel like you got a good idea of how to use the multiprocessing module and how", "tokens": [50364, 960, 13, 286, 1454, 291, 841, 411, 291, 658, 257, 665, 1558, 295, 577, 281, 764, 264, 3311, 340, 780, 278, 10088, 293, 577, 50612], "temperature": 0.0, "avg_logprob": -0.05736004329118572, "compression_ratio": 1.7715355805243447, "no_speech_prob": 0.15198245644569397}, {"id": 429, "seek": 258480, "start": 2589.76, "end": 2594.88, "text": " we can use these to speed up our scripts. Now, I hope you also feel like you got a good overview", "tokens": [50612, 321, 393, 764, 613, 281, 3073, 493, 527, 23294, 13, 823, 11, 286, 1454, 291, 611, 841, 411, 291, 658, 257, 665, 12492, 50868], "temperature": 0.0, "avg_logprob": -0.05736004329118572, "compression_ratio": 1.7715355805243447, "no_speech_prob": 0.15198245644569397}, {"id": 430, "seek": 258480, "start": 2594.88, "end": 2600.0800000000004, "text": " of threads and processes. And when you should use those. But like I said, if you're unsure,", "tokens": [50868, 295, 19314, 293, 7555, 13, 400, 562, 291, 820, 764, 729, 13, 583, 411, 286, 848, 11, 498, 291, 434, 32486, 11, 51128], "temperature": 0.0, "avg_logprob": -0.05736004329118572, "compression_ratio": 1.7715355805243447, "no_speech_prob": 0.15198245644569397}, {"id": 431, "seek": 258480, "start": 2600.0800000000004, "end": 2605.36, "text": " then there's no hurt in simply trying both on a subset of your data to see what gives you the", "tokens": [51128, 550, 456, 311, 572, 4607, 294, 2935, 1382, 1293, 322, 257, 25993, 295, 428, 1412, 281, 536, 437, 2709, 291, 264, 51392], "temperature": 0.0, "avg_logprob": -0.05736004329118572, "compression_ratio": 1.7715355805243447, "no_speech_prob": 0.15198245644569397}, {"id": 432, "seek": 258480, "start": 2605.36, "end": 2610.48, "text": " most speed up. Now, there are some more advanced topics that we could cover in future videos,", "tokens": [51392, 881, 3073, 493, 13, 823, 11, 456, 366, 512, 544, 7339, 8378, 300, 321, 727, 2060, 294, 2027, 2145, 11, 51648], "temperature": 0.0, "avg_logprob": -0.05736004329118572, "compression_ratio": 1.7715355805243447, "no_speech_prob": 0.15198245644569397}, {"id": 433, "seek": 261048, "start": 2610.48, "end": 2616.0, "text": " such as race conditions, locks and things like that. But we'll save that for a future video if", "tokens": [50364, 1270, 382, 4569, 4487, 11, 20703, 293, 721, 411, 300, 13, 583, 321, 603, 3155, 300, 337, 257, 2027, 960, 498, 50640], "temperature": 0.0, "avg_logprob": -0.06957703828811646, "compression_ratio": 1.8360655737704918, "no_speech_prob": 0.04884885996580124}, {"id": 434, "seek": 261048, "start": 2616.0, "end": 2620.08, "text": " anyone is interested. But if anyone has any questions about what we covered in this video,", "tokens": [50640, 2878, 307, 3102, 13, 583, 498, 2878, 575, 604, 1651, 466, 437, 321, 5343, 294, 341, 960, 11, 50844], "temperature": 0.0, "avg_logprob": -0.06957703828811646, "compression_ratio": 1.8360655737704918, "no_speech_prob": 0.04884885996580124}, {"id": 435, "seek": 261048, "start": 2620.08, "end": 2624.0, "text": " then feel free to ask in the comment section below and I'll do my best to answer those. And if you", "tokens": [50844, 550, 841, 1737, 281, 1029, 294, 264, 2871, 3541, 2507, 293, 286, 603, 360, 452, 1151, 281, 1867, 729, 13, 400, 498, 291, 51040], "temperature": 0.0, "avg_logprob": -0.06957703828811646, "compression_ratio": 1.8360655737704918, "no_speech_prob": 0.04884885996580124}, {"id": 436, "seek": 261048, "start": 2624.0, "end": 2627.92, "text": " enjoy these tutorials and would like to support them, then there are several ways you can do that.", "tokens": [51040, 2103, 613, 17616, 293, 576, 411, 281, 1406, 552, 11, 550, 456, 366, 2940, 2098, 291, 393, 360, 300, 13, 51236], "temperature": 0.0, "avg_logprob": -0.06957703828811646, "compression_ratio": 1.8360655737704918, "no_speech_prob": 0.04884885996580124}, {"id": 437, "seek": 261048, "start": 2627.92, "end": 2631.84, "text": " The easiest way is to simply like the video and give it a thumbs up. And also it's a huge help", "tokens": [51236, 440, 12889, 636, 307, 281, 2935, 411, 264, 960, 293, 976, 309, 257, 8838, 493, 13, 400, 611, 309, 311, 257, 2603, 854, 51432], "temperature": 0.0, "avg_logprob": -0.06957703828811646, "compression_ratio": 1.8360655737704918, "no_speech_prob": 0.04884885996580124}, {"id": 438, "seek": 261048, "start": 2631.84, "end": 2635.52, "text": " to share these videos with anyone who you think would find them useful. And if you have the means", "tokens": [51432, 281, 2073, 613, 2145, 365, 2878, 567, 291, 519, 576, 915, 552, 4420, 13, 400, 498, 291, 362, 264, 1355, 51616], "temperature": 0.0, "avg_logprob": -0.06957703828811646, "compression_ratio": 1.8360655737704918, "no_speech_prob": 0.04884885996580124}, {"id": 439, "seek": 261048, "start": 2635.52, "end": 2639.52, "text": " you can contribute to Patreon and there's a link to that page in the description section below.", "tokens": [51616, 291, 393, 10586, 281, 15692, 293, 456, 311, 257, 2113, 281, 300, 3028, 294, 264, 3855, 3541, 2507, 13, 51816], "temperature": 0.0, "avg_logprob": -0.06957703828811646, "compression_ratio": 1.8360655737704918, "no_speech_prob": 0.04884885996580124}, {"id": 440, "seek": 263952, "start": 2639.52, "end": 2642.56, "text": " Be sure to subscribe for future videos and thank you all for watching.", "tokens": [50364, 879, 988, 281, 3022, 337, 2027, 2145, 293, 1309, 291, 439, 337, 1976, 13, 50516], "temperature": 0.0, "avg_logprob": -0.2662467956542969, "compression_ratio": 0.9859154929577465, "no_speech_prob": 0.07355883717536926}], "language": "en"}