WEBVTT

00:00.000 --> 00:03.200
Hey there, how's it going everybody? In this video, we're going to be learning how to run

00:03.200 --> 00:07.760
code in parallel using the multi-processing module. Now, if you'd also like to learn about

00:07.760 --> 00:12.320
running code concurrently using the threading module, then I did recently put out a video on

00:12.320 --> 00:16.640
that as well, so I'll be sure to leave a link to that video in the description section below. Now,

00:16.640 --> 00:20.640
if you don't know the difference between threading and multi-processing, then you should have a grasp

00:20.640 --> 00:24.160
on the difference between those once we're finished. Now, I would like to mention that we

00:24.160 --> 00:28.960
do have a sponsor for this video, and that is Brilliant.org. So, I really want to thank Brilliant

00:28.960 --> 00:32.560
for sponsoring the video, and it would be great if you all could go and check them out using the

00:32.560 --> 00:36.720
link in the description section below and support the sponsors, and I'll talk more about their

00:36.720 --> 00:42.240
services in just a bit. So, with that said, let's go ahead and get started. Okay, so first, why would

00:42.240 --> 00:47.760
we want to use multi-processing? So, basically, we want to use multi-processing whenever it's going

00:47.760 --> 00:53.520
to significantly speed up our program. Now, the speed up comes from different tasks running in

00:53.520 --> 00:58.480
parallel. Now, in this video, we're going to start off with a basic example of where we learn how to

00:58.480 --> 01:03.920
run some simple sleep methods in parallel, but then we'll finish up with a real-world example

01:03.920 --> 01:08.960
where we do some image processing on a directory of high-resolution images. I want to show that

01:08.960 --> 01:13.840
real-world example because, personally, when I watch tutorials that only show how it works on

01:13.840 --> 01:18.480
basic examples, then I always feel like I don't really walk away with any useful knowledge. So,

01:18.480 --> 01:23.120
we'll use the sleep method to get a good idea of how to use multi-processing, and then we'll

01:23.120 --> 01:28.160
be sure to go over the more complicated real-world example of image processing. So, let's go ahead

01:28.160 --> 01:33.200
and get started. So, I have a starting script open here, and if you'd like to follow along, then

01:33.200 --> 01:38.560
I'll be sure to have a link to this code in the description section below. And, like I said, we'll

01:38.560 --> 01:44.400
start with a very simple example to see how this works and then build up with more realistic examples.

01:44.400 --> 01:49.920
So, let me go over the script that I currently have open here. So, first, I'm importing time,

01:49.920 --> 01:55.200
and I'm just using time to measure how long it takes the script to run. That's also what this

01:55.200 --> 02:00.880
is here. This is just a start time for our script, and then we have a function here called

02:00.880 --> 02:06.080
doSomething, and all this is doing is printing that we are sleeping for one second, then we actually

02:06.080 --> 02:11.360
sleep a second using that time module, and then we are printing out that we are done sleeping,

02:11.360 --> 02:15.200
and then we are actually executing that function. So, it should do all of this,

02:15.200 --> 02:20.320
and then we are calculating the finish time and printing out that our script is finished.

02:20.320 --> 02:24.720
Okay, so, if I run the code that we have right now, we can see that it said that it was sleeping

02:24.720 --> 02:29.280
for one second, done sleeping, and that we finished in about one second. And that sounds

02:29.280 --> 02:34.400
about right since we were running our doSomething function one time, and that sleeps for one second.

02:34.400 --> 02:39.200
And if we were to run that function twice, then our program will likely take two seconds. So,

02:39.200 --> 02:46.000
let's go ahead and see that. So, right below doSomething here, I'm going to run this again,

02:46.000 --> 02:52.080
and if I run that, then we can see that now that it printed out that it was sleeping for one second

02:52.160 --> 02:57.600
twice, and that it took about two seconds. So, we can see that each time we run this doSomething

02:57.600 --> 03:02.560
function, it's adding about one second to our script. So, our script is just waiting around

03:02.560 --> 03:08.320
sleeping for a second, and once that's done, it moves on to run that next function,

03:08.320 --> 03:12.720
and sits around waiting for another second. And then at that point, we're basically done,

03:12.720 --> 03:17.840
and our script finishes. Now, I created a quick graphic to try to represent what this looks like.

03:17.840 --> 03:22.160
So, let me bring that up here in my browser real quick. And this is actually the second

03:22.160 --> 03:26.960
graphic. We'll go over that in just a second. Okay. So, this is basically what it looks like

03:27.600 --> 03:33.360
for our script to be executed right now. So, we are running a function. In this case, it's that

03:33.360 --> 03:38.960
doSomething function. And then this is just coming up here and waiting and executing for one second.

03:38.960 --> 03:44.000
And once that one second is over, then we come back and we execute this another function,

03:44.080 --> 03:49.120
and it's that same function again. So, then it comes up here and executes this sleep for one

03:49.120 --> 03:53.680
second again. And when that one second is done, then we can come down here and print that our

03:53.680 --> 03:58.880
script is done. And running everything in order like this is called running it synchronously.

03:58.880 --> 04:02.880
Now, if you have some tasks that don't need to be run synchronously, then we can use the

04:02.880 --> 04:09.200
multi-processing module to split these tasks up onto other CPUs and run them at the same time.

04:09.200 --> 04:14.400
Now, if you watched my last video on threading, then I mentioned that tasks were going to either

04:14.400 --> 04:21.200
be IO bound or CPU bound. So, CPU bound tasks are things that are crunching a lot of numbers and

04:21.200 --> 04:26.960
using the CPU. And IO bound tasks are things that are waiting for input and output operations

04:26.960 --> 04:32.320
to be completed. And they're not really using the CPU all that much. So, some other examples of

04:32.320 --> 04:38.960
IO bound tasks include file system operations and network operations like downloading stuff online.

04:38.960 --> 04:43.040
Now, in that threading video, I mentioned that we wouldn't get much of a speed up when using

04:43.040 --> 04:49.120
threading on CPU bound tasks because those threads are still only running one process. But with

04:49.120 --> 04:54.400
multi-processing, we're going to actually spread the work out onto multiple processors on our machine

04:54.400 --> 05:00.560
and run those tasks at the same time. So, we can use this with both IO bound tasks and CPU bound

05:00.560 --> 05:05.360
tasks. So, it really just depends on what we're doing and your computer's hardware that will

05:05.440 --> 05:09.840
determine if it's better to use threading or multi-processing. But with that said,

05:09.840 --> 05:14.560
let's look at what it looks like to run something in parallel using multi-processing.

05:14.560 --> 05:19.360
And I've got another graphic put together of what this would look like. So, in this example,

05:19.360 --> 05:24.080
we can see that we still have our two tasks. But now we're just breaking these up onto two

05:24.080 --> 05:29.840
different processes. And unlike with threading, where we were running these concurrently, and I

05:29.840 --> 05:33.760
said that running concurrently doesn't necessarily mean that they're running at the same time,

05:34.480 --> 05:39.840
with multi-processes, these actually are running at the same time on different processes. So,

05:39.840 --> 05:46.240
we can see here that once we kick off our multiple processes and we spread out our tasks onto those

05:46.240 --> 05:52.560
processes, then we can just run each of these functions one time. And then both of these will

05:52.560 --> 05:57.440
sleep for a second. And then once they're both done, we'll come down here and print that they're

05:57.440 --> 06:01.760
done. Okay, so now that we've talked about multi-processing and what it looks like to run code

06:01.760 --> 06:08.160
in parallel, now let's see how to actually do this with our current script. So, first,

06:08.160 --> 06:13.600
let's import the multi-processing module. So, this is in the standard library, so we don't need to

06:13.600 --> 06:21.120
install anything. So, up here at the top, I'm just going to say import multi-processing. Now,

06:21.120 --> 06:25.040
I'm going to show an older way of how to do multi-processing first so that we can get a good

06:25.040 --> 06:29.680
idea of what's going on. But if it seems confusing at first, then definitely stick around, because

06:29.680 --> 06:34.880
I'm also going to show some newer ways of doing multi-processing using pools that allow us to

06:34.880 --> 06:41.360
add this to our program with just a few lines of code. Okay, so first, instead of running the

06:41.360 --> 06:46.960
do something function twice in a row like we have here, let's instead turn both of these into

06:46.960 --> 06:52.640
processes. So, to do this, I'm just going to create two processes. And for both of these,

06:52.640 --> 07:01.200
we can just say p1 is equal to multi-processing.process. And now, we are going to pass in a

07:01.200 --> 07:07.200
target. And the target is the function that we want to run. So, if I want to run this do something

07:07.200 --> 07:13.600
function, then I can pass in do something. Now, we want to pass in the actual function and not

07:13.600 --> 07:17.760
the return value of the function. So, we don't want to execute the function with parentheses

07:17.760 --> 07:25.200
like this. We just want to pass it in with no parentheses. Okay, so now that will be one process.

07:25.200 --> 07:32.800
And now, if I do a p2 is equal to multi-processing.process with a target of do something, then

07:32.800 --> 07:39.120
that will be our second process. Okay, so at this point, we've created two process objects,

07:39.120 --> 07:45.600
but we're not actually running that code. So, if I run this right now, then we can see that it says

07:45.600 --> 07:51.200
that it finished immediately, but nothing from our function printed out. So, our functions didn't

07:51.200 --> 07:57.600
actually run. So, in order to get our processes to run, we need to use the start method on each one.

07:57.600 --> 08:04.560
So, down here below our p2, I'm going to say p1.start to start that first process,

08:04.560 --> 08:12.880
and p2.start to start that second process. Okay, so now that will actually run our processes,

08:12.880 --> 08:20.240
but it might not do exactly what we think it'll do. So, if we run this, then we can see that now

08:20.240 --> 08:27.200
it runs the functions, but it said that our script was finished in zero seconds, and then it said

08:27.200 --> 08:32.720
that we were sleeping for one second twice because we ran that function twice, and then it said that

08:32.720 --> 08:38.480
it was done sleeping. Now, our entire script didn't actually complete in zero seconds. It actually

08:38.480 --> 08:44.160
took around one second, but the reason that it says that it completed in zero seconds is because

08:44.160 --> 08:50.960
after it started both of these processes here, while those processes were sleeping, our script

08:50.960 --> 08:57.280
continued running and came down here and calculated out the finish time and printed out that our

08:57.280 --> 09:04.000
script was finished in zero seconds, and then it kicked off these processes. Now, actually, I think

09:04.080 --> 09:09.120
that I just said that it started sleeping first before it printed out that we were finished,

09:09.120 --> 09:14.240
but these processes take a little bit longer to spin up than threads, so it actually didn't even

09:14.240 --> 09:19.120
start our processes first. It actually came down here and printed that we were finished before

09:19.120 --> 09:25.200
these sleep statements even first got executed. So, it printed that before it said we were sleeping,

09:25.200 --> 09:31.440
and then after a second we were done. So, basically what this is doing is it's kicking off our processes,

09:31.440 --> 09:36.800
but then it's going down here and running the rest of our script before our process is finished.

09:36.800 --> 09:41.440
Now, what if we wanted our processes to finish before we calculated the finish time and before

09:41.440 --> 09:46.960
we printed out that our script is finished? So, in order to do this, we can use the join method.

09:46.960 --> 09:56.400
So, to do this right below start, I'm going to say p1.join and p2.join. So, when we run that join

09:56.400 --> 10:02.800
method, it means that the process will finish before moving on in the script. So, now, if we

10:02.800 --> 10:09.520
run this, then we can see that both processes started at almost the same time, and then they

10:09.520 --> 10:14.880
both printed that they were done sleeping after one second, and then our script continued on to

10:14.880 --> 10:20.800
print that our script had finished in about one second. Now, if using multi-processing seems a

10:20.800 --> 10:25.760
bit complicated right now, then definitely stick around until the end of the video, because we're

10:25.760 --> 10:31.280
going to see an easier way of how to do what we're doing here, but I think it's important to understand

10:31.280 --> 10:37.280
what this is doing so far, even if we use other methods where we don't actually manually call

10:37.280 --> 10:42.320
these start methods and join methods. Okay, so, right now, we're not really getting that big of a

10:42.320 --> 10:48.240
speedup. Now, so, our code ran in two seconds before, and now it's running in one second,

10:48.240 --> 10:52.880
but that's because our function doesn't take too long, and we're only running it twice,

10:52.880 --> 10:58.400
but what if we wanted to run our function 10 times? Well, if we were to run our code synchronously,

10:58.400 --> 11:04.640
then we can take a guess that it would take 10 seconds since one would have to finish before

11:04.640 --> 11:09.440
the other, and we'd be running 10 in a row. But if we ran this with multiple processes,

11:09.440 --> 11:15.680
then it should be significantly faster. So, let's see an example of this. Now, instead of manually

11:15.680 --> 11:21.520
creating 10 different processes, let's instead create and start these in a loop. So, to do this,

11:22.320 --> 11:28.560
I can come up here, and I'm going to copy this whole part here, and now I'm just going to

11:28.560 --> 11:36.560
overwrite all the code that we have here so far, and I'm going to say 4 underscore in range of 10,

11:37.440 --> 11:44.240
and we'll say p is equal to multi-processing dot process with a target set to the do something

11:44.240 --> 11:51.120
function. And now, let's also start that process here within our loop. Now, if you're unfamiliar with

11:51.120 --> 11:56.720
the underscore in Python, basically, that's just a throwaway variable name. It's just saying that

11:56.720 --> 12:02.800
we're not actually using the integer from this range in the loop. So, we just have something as

12:02.800 --> 12:08.480
a throwaway variable there. So, we're starting all these processes here within our loop, but we can't

12:08.480 --> 12:16.080
do a p dot join within the loop, because it would run join on the process before looping through

12:16.160 --> 12:21.120
and creating and starting the next process in the loop. So, it would basically be the same

12:21.120 --> 12:27.200
as running it synchronously. So, we need a way that we can start all of these processes in one loop,

12:27.200 --> 12:31.520
and then loop through those processes again, and run the join method on them

12:31.520 --> 12:36.880
so that they all finish before the end of our script. So, to do this, let's just append each

12:36.880 --> 12:45.840
process to a list. So, above our for loop here, I'm just going to create a list called processes

12:45.840 --> 12:53.600
and set that to an empty list. And then below p dot start, I'm going to say processes dot append,

12:53.600 --> 13:02.320
and I will append each process to our processes list. And now, here below our for loop, I'm going

13:02.320 --> 13:13.440
to say for process in processes, let's do a process dot join. Okay, so just one more time here. We are

13:14.240 --> 13:20.320
looping over a range of 10. So, we're going to do this loop 10 times here. And each time through

13:20.320 --> 13:26.320
the loop, we are creating a new process with this target of do something. And we are starting that

13:26.320 --> 13:33.360
process. And then we are appending that process to a processes list. So, then after that loop is

13:33.360 --> 13:37.520
complete, and all of our processes have been started, we're coming through and looping over all

13:37.520 --> 13:43.040
those processes, and we are joining them. And again, when we join a process, when we run the join

13:43.040 --> 13:48.560
method, it means that it is going to wait until that finishes before continuing on to the rest

13:48.560 --> 13:53.360
of the script. So, it'll finish before it comes down here and calculates the finish time and

13:53.360 --> 13:58.240
prints that our script is finished. So, we're running this do something function 10 times,

13:58.240 --> 14:03.360
and it sleeps for one second every time. But since we're using multiple processes, it'll just run

14:03.360 --> 14:08.880
all of these in parallel at the same time. So, instead of it taking 10 seconds, let's save this

14:08.880 --> 14:15.520
and run this and see how long it actually takes. So, we can see that even running the function 10

14:15.520 --> 14:21.120
times, we're still finishing this in about one second. Now, that might seem a little strange,

14:21.120 --> 14:27.120
because I don't actually have 10 cores on this machine. But your computer has ways of switching

14:27.120 --> 14:33.360
off between cores when one of them isn't too busy. So, even though we had more processes than we do

14:33.360 --> 14:38.320
cores, it's still finished in about a second. So, that's pretty good. Okay, so now let's look at

14:38.320 --> 14:43.120
how we can pass in arguments into our function. So, right now, we're running a function that

14:43.120 --> 14:48.640
doesn't accept any arguments. But let's add a couple of arguments real quick. So, right now,

14:48.640 --> 14:54.560
we're just sleeping for one second. So, let's add an argument that specifies how long to sleep.

14:54.560 --> 15:00.480
So, up here, we will accept an argument. And I'm just going to pass in an argument of seconds.

15:00.480 --> 15:09.840
And let's also change that we are going to sleep for that number of seconds. And let me also put

15:10.880 --> 15:16.560
a parentheses s there as well. Now, this needs to be an f string, since we're now using this

15:16.560 --> 15:23.600
variable here within our string. Now, I want to sleep for that number of seconds. Okay, so with

15:23.600 --> 15:29.120
that small change, our do something function now accepts an argument of seconds. And then it'll

15:29.120 --> 15:33.360
print out that we're sleeping for that number of seconds. And then it will actually sleep for that

15:33.360 --> 15:40.480
number of seconds. So, let's pass in seconds as an argument to this function. And we need to pass

15:40.480 --> 15:47.280
that in as a list of arguments to our process. So, I'll say, down here, where we are saying that

15:47.280 --> 15:53.760
our target is that do something function, we can also pass in an argument of arcs. And we'll pass

15:53.760 --> 16:01.200
that in as a list of arguments. So, I'll do 1.5. So, now, instead of sleeping for one second

16:01.920 --> 16:07.680
for 10 different times, now it's going to sleep for 1.5 seconds for 10 different times. Now,

16:07.680 --> 16:13.760
unlike with threads, in order to pass arguments to a multi processing process, the arguments must

16:13.760 --> 16:20.000
be able to be serialized using pickle. Now, if you don't know what that means, basically serializing

16:20.000 --> 16:26.560
something with pickle means that we're converting Python objects into a format that can be deconstructed

16:26.560 --> 16:32.880
and reconstructed in another Python script. So, now we should expect our function to take

16:32.880 --> 16:40.400
1.5 seconds instead. So, if I save this and run it, then we can see that now our script is finishing

16:40.400 --> 16:46.800
in about 1.5 seconds. Okay, so, I said before that I was going to show you the older way of doing

16:46.800 --> 16:52.320
multi processing, and then I'd show you what I believe is a faster, easier way of doing this.

16:52.320 --> 16:57.520
And I still wanted to show you the manual way of creating these processes, because I think this can

16:57.520 --> 17:02.160
still be useful depending on what you're doing. And also, I think it's better to learn this manual

17:02.480 --> 17:08.960
first to understand a bit better what's going on in the background. But in Python 3.2, they added

17:08.960 --> 17:14.640
something called a process pull executor. And in a lot of cases, this will be an easier and more

17:14.640 --> 17:20.000
efficient way to run multiple processes. And it also allows us to easily switch over to using

17:20.000 --> 17:25.040
multiple threads instead of processes as well, depending on the problem that we're trying to

17:25.040 --> 17:31.840
solve. So, let's replace what we currently have and instead use this process pull executor.

17:32.240 --> 17:37.520
Now, this actually isn't in the multi processing module. It's in the concurrent futures module

17:37.520 --> 17:44.720
instead. So, up here at the top, let's instead import concurrent futures. And I actually don't

17:44.720 --> 17:51.440
think I need multi processing anymore. So, I'm just going to say import concurrent futures.

17:51.440 --> 17:55.600
Now, I'm going to leave everything else that I have here for now, so that we can see the

17:55.600 --> 18:01.680
difference between these. Now, when we use this process pull executor, it's usually best to use

18:01.680 --> 18:07.600
this with a context manager. So, above our processes list here, I'm going to do the same thing that

18:07.600 --> 18:14.320
we already have. But just with our concurrent futures module instead. So, I'm going to say with

18:14.320 --> 18:23.200
concurrent dot futures dot process pull executor, and make sure you get those capitalizations in

18:23.200 --> 18:32.800
the right place. And then, we will say, whoops, we'll say as executor. And now, within our or

18:32.800 --> 18:37.600
with our executor here, there are a couple of different methods that we can use. Now, if we

18:37.600 --> 18:43.680
want to execute the function once at a time, then we can use the submit method. So, the submit method

18:43.680 --> 18:49.520
schedules a function to be executed and returns a future object. So, let's add this in and then

18:49.600 --> 18:57.920
I'll explain this a bit more. So, I'm going to say f one is equal to executor dot submit. And I will

18:57.920 --> 19:06.000
submit that do something function. And let's also pass in an argument of one. So, again, the submit

19:06.000 --> 19:14.000
method schedules a function to be executed and returns a future object. So, a future object

19:14.000 --> 19:20.000
basically encapsulates the execution of our function and allows us to check on it after it's

19:20.000 --> 19:26.720
been scheduled. So, we can check that it's running or if it's done, and also check the result. So,

19:26.720 --> 19:32.160
if we grab the result, then it'll give us the return value of the function. Now, right now,

19:32.160 --> 19:37.920
we're just printing out values. But let me add in a return value so that we can grab that. So,

19:37.920 --> 19:44.800
instead of just printing that we are done sleeping up here, instead, I'm going to return that string.

19:44.800 --> 19:50.720
So, I'm going to say return done sleeping instead of just printing that out. Okay, so now that's

19:50.720 --> 19:56.640
returning that string. So, if we still want to print that out, then we'll need to print that return

19:56.640 --> 20:03.440
value. So, let's grab that by using the result method on that future object. So, I'm going to say

20:03.440 --> 20:12.080
print and we will print out F1 dot result. Now, if we run the return method, then this will wait

20:12.080 --> 20:18.720
until the function completes. Okay, so let's comment out what we had before and run our code. So,

20:18.720 --> 20:26.400
I'm going to comment out this processes list here and our previous starts and joins. And instead,

20:26.400 --> 20:32.640
we're just going to use this process pull executor. Okay, so if I run this, then we can see that

20:32.640 --> 20:38.240
that still works. And that's a lot less code than we had down here that's commented out. But we're

20:38.240 --> 20:43.120
still not running this multiple times yet like we were down here. So, if we wanted to run this

20:43.120 --> 20:50.480
multiple times, then we could just run submit multiple times. So, I could say let me go above

20:50.480 --> 20:56.320
our result here. I'm going to add in another execution of this do something function. So,

20:56.320 --> 21:04.000
I'm going to call this F2 is equal to executor dot submit do something with one second. And then,

21:04.000 --> 21:12.560
I will also print out the F2 result. So, if I run this, then we can see that it's the same thing.

21:12.560 --> 21:17.440
It kicks both of these off at the same time. And we finished in about one second. And if we wanted

21:17.440 --> 21:22.320
to run this 10 times like we did below, then we likely wouldn't want to run submit 10 different

21:22.320 --> 21:27.760
times. So, we could use a loop like we did before. So, instead of running one at a time,

21:27.760 --> 21:32.480
I'm going to use a loop. And we could use a regular loop like we did below. But I'm going

21:32.480 --> 21:38.000
to go ahead and use a list comprehension to create these instead. So, we could say, I'm just going

21:38.000 --> 21:44.640
to copy this executor dot submit part. And I'm just going to overwrite all of this other stuff

21:44.640 --> 21:51.200
right now. And I'm going to say results are equal to, then I will start a list comprehension here

21:51.200 --> 22:00.640
and say executor dot submit do something for one second for underscore range 10. Now, if you're

22:00.640 --> 22:05.440
not familiar with list comprehensions like we have here, then I do have a separate video on that

22:05.440 --> 22:09.920
as well. So, I'll put a link to that in the description section below if you've never seen

22:09.920 --> 22:14.000
this type of code before. And if you're not comfortable using list comprehensions, then

22:14.000 --> 22:19.360
you can always use a regular loop like we did down here below. Okay, so now we've created a list

22:19.360 --> 22:25.600
comprehension that's running our submit method with this do something function, and an argument of

22:25.600 --> 22:31.520
one second, 10 different times. Now, in order to get these results, we can actually use another

22:31.520 --> 22:36.800
function from the concurrent futures module called as completed. And this will give us an

22:36.800 --> 22:42.240
iterator that we can loop over that will yield the results of our processes as they're completed.

22:42.240 --> 22:47.520
So, I think this is really useful. And it's one of the good things about using these processing

22:47.520 --> 22:56.800
pull executors. So to use this, we can say just for f in concurrent, oops, sorry about my typing

22:56.800 --> 23:05.440
there, concurrent dot futures dot as underscore completed. And now we want to pass in this list

23:05.440 --> 23:13.680
of results, which is a list of futures objects. And now within this list, let's print out f dot

23:14.560 --> 23:21.920
result. So if we run this, oops, and it looks like I have some invalid syntax here. Oh,

23:21.920 --> 23:28.000
I forgot to say, I should have said for underscore in range of 10. Some of you probably saw that

23:28.000 --> 23:36.240
as I was typing it out. Okay, so now if I run this, then we can see that we slept for one second.

23:36.240 --> 23:41.120
Now it's still ran 10 different times. But if we scroll down to the bottom, then we can see

23:41.120 --> 23:47.360
how much time it took. So we can see here that it actually took three seconds this time. Now,

23:47.360 --> 23:52.640
the reason behind that is that our poll may have made a decision based on our hardware,

23:52.640 --> 23:59.440
not to a lot as many processes. So that's why it might take longer. But even though it took longer

23:59.440 --> 24:05.040
in our simple little example here, I still you like to use these processing pull executors most

24:05.040 --> 24:11.680
of the time, because I trust it to a lot the processes a lot more than I trust myself. So

24:11.680 --> 24:17.200
I passed that off to the process pull executor to do and to make that decision for me. Now to

24:17.200 --> 24:22.240
prove that these results are actually coming in as they're completed, let me actually pass in a

24:22.240 --> 24:28.000
different range of seconds for our processes to sleep. And those should print out in the order

24:28.000 --> 24:33.760
that they complete. So I'm going to create a list of seconds to sleep. And I'll make that sleep

24:33.760 --> 24:40.480
from five seconds all the way down to one second. So above our results here, I'm going to make a list

24:40.480 --> 24:47.680
of seconds. And I will just make a list of five, four, three, two, one. And I'll also print out

24:47.680 --> 24:54.400
the seconds in the return statement of our do something function, so that we can tell which

24:54.400 --> 25:00.240
ones are finishing and in what order. So again, I'm going to make this an f string by putting an f

25:00.240 --> 25:08.720
right there. And I'm just going to pass that in to so we can see which seconds is actually done

25:08.720 --> 25:15.440
sleeping. So now, let me also change our list comprehension here, so that we are running our

25:15.440 --> 25:22.160
do something function with each of these seconds in this seconds list. So I'm going to say executor

25:22.240 --> 25:33.280
dot submit, do something. And I want to do that for whatever second. So four sec in our seconds

25:33.280 --> 25:40.800
list. Okay, so now if I run this, then we can see that it actually started our five second

25:40.800 --> 25:46.880
process first, and then our four, then our three, then our two, then our one. But it finished these

25:46.880 --> 25:52.480
in the order that they came in. And the lower number seconds are towards the top. Now I'm not

25:52.480 --> 25:59.120
sure why the one second process took so much longer than the two and the three second processes. I

25:59.120 --> 26:03.920
guess it just got hung up on something. But the four and the five second processes were down here

26:03.920 --> 26:10.240
at the bottom. Actually, let me run that one more time. And Oh, okay, so that's why it's because

26:10.240 --> 26:16.880
our one second process was down here. And since I have four cores on my machine,

26:17.440 --> 26:23.760
it started these four processes here first. And it didn't start the one second process until

26:24.560 --> 26:29.840
this two was finished right here. So that's why that took a little bit longer. But since we are

26:29.840 --> 26:35.920
using this as completed method, this actually did print our result out our results in the order

26:35.920 --> 26:41.040
that they completed. So this two second one finished first, and then this three, then one,

26:41.040 --> 26:46.000
then four, then five. And we can see here down at the bottom that our script is still finishing

26:46.000 --> 26:51.360
in about five seconds. So that's pretty good. Okay, so with this submit method right now,

26:52.160 --> 26:59.280
it's submitting each function once at a time. But in order to run submit on an entire list,

26:59.280 --> 27:04.560
then we need to do a loop or a comprehension like we did here. But if you're familiar with the built

27:04.560 --> 27:09.760
in map method, then there is actually something similar that we can do with processes, where we

27:09.760 --> 27:15.280
can use the map method to run our function over a list of values. So if you're familiar with the

27:15.280 --> 27:21.600
built in map method, then this is very similar, except it uses processes instead. So it runs the

27:21.600 --> 27:27.440
function every time or with every item of the interval that we pass in. So let's say that I

27:27.440 --> 27:36.160
want to map our function to our list of seconds. So to do this, I am just going to overwrite our

27:36.160 --> 27:41.520
list comprehension here. And I'm not going to be using this as completed anymore either. So I'm

27:41.520 --> 27:51.040
also going to get rid of that. So now in order to do this, we can simply say executor dot map.

27:51.760 --> 28:02.400
And now we will map our do something function. And we will map our list of seconds. So again,

28:02.400 --> 28:07.040
what this map method does, if you're not familiar with the built in Python map method and what it

28:07.040 --> 28:16.080
does, basically map will run this do something function with every item of this list with every

28:16.080 --> 28:22.240
item of whatever iterable you pass in. So that is what map does. Now, when we were using the submit

28:22.240 --> 28:29.040
method, it returned future objects. But when we use map, it just returns the results. Now, it is

28:29.040 --> 28:34.320
going to run those processes in parallel. But instead of returning the results as they're completed,

28:34.320 --> 28:40.240
like we saw before, map is going to return the results in the in the order that they were started.

28:40.240 --> 28:46.000
So to loop over these results, we can simply just do a for loop. So I'm going to say for

28:46.000 --> 28:54.160
result in results. And then I will just print out our result, whoop, make sure that I'm printing

28:54.160 --> 29:00.720
out the result and not that results list. Okay, so now if I run this, then we can see that all of

29:00.720 --> 29:06.560
our processes kicked off at pretty much the same time, except for that one second when it looked

29:06.560 --> 29:13.200
like it got outside of the pool like it did before. But they actually didn't all complete at the same

29:13.200 --> 29:19.840
time. But when you loop over your results using map like we did here, then it returns the results

29:19.840 --> 29:26.080
in the order that they were started. So since we slept for five seconds first, then we waited for

29:26.080 --> 29:31.360
that one to finish before printing out the other results. But it still didn't slow us down, we can

29:31.360 --> 29:37.520
see that our entire script still finished in five seconds here. But it looks like our five

29:37.520 --> 29:42.320
seconds was done sleeping first, and then our four, then three, then two, then one, it actually didn't

29:42.320 --> 29:50.240
finish in that order. But it printed out in that order, because again, it prints out the ones that

29:50.240 --> 29:54.480
in the order that they were started and not in the order that they were finished. Now another

29:54.480 --> 29:59.520
thing to point out here is that if our function raises an exception, it won't actually raise that

29:59.520 --> 30:05.760
exception while running the process. The exception will be raised when its value is retrieved from

30:05.760 --> 30:11.920
the results iterator. So if you need to handle any exceptions, then you can do that here within the

30:11.920 --> 30:16.720
iterator if you'd like. And if you'd like to learn more about handling exceptions, then I do have a

30:16.720 --> 30:21.360
more in depth video. If you'd like to learn more about that. So I'll be sure to leave a link to

30:21.360 --> 30:25.600
that video in the description section below for anyone who's interested. Now even if we don't

30:25.600 --> 30:30.960
grab our results within the context manager, it's still going to automatically join all of those

30:31.840 --> 30:38.320
processes and let them finish after the context manager ends. So if I comment out where we are

30:38.320 --> 30:44.800
printing out our results, let me also get rid of our old way of doing this here so that we can

30:44.800 --> 30:50.880
see our code below our processes here. So now I'm commenting out where we're printing those results.

30:50.960 --> 30:57.280
And if I run this, then we can see that it still didn't move on to our finish time here

30:58.080 --> 31:04.480
until it returned the results from our processes. So anytime you're using a context manager like

31:04.480 --> 31:10.080
this, it's going to automatically join those processes. And they're going to complete before

31:10.080 --> 31:15.760
that context manager finishes. Okay, so now that we've looked at a basic example of using sleep,

31:15.760 --> 31:20.000
now let's take a look at a more real world example of where using multiple processes

31:20.000 --> 31:26.080
would be useful. So I've got another script open here where I'm not using multiple processes at

31:26.080 --> 31:32.000
the moment. So let me open this up and let's go over what this is doing. And again, I'll have a

31:32.000 --> 31:36.960
link to this code in the description section below for anyone who wants to follow along. So in our

31:36.960 --> 31:42.640
last video on threading, I showed how we could use threads to go out and download some high resolution

31:42.640 --> 31:48.080
photos from unsplash. Now if you don't know what unsplash is, it's a website that has some really

31:48.080 --> 31:54.560
nice photos available for anyone to use. Now downloading images is something that is IO bound

31:54.560 --> 32:00.160
since we're waiting for the images to download. So for this multi processing example, we want

32:00.160 --> 32:05.280
something that is more CPU bound. So in this script, I'm doing some image processing on the

32:05.280 --> 32:09.920
images that we downloaded in the threading video. And I'll have these images available in the

32:09.920 --> 32:14.880
description section below as well, in case anyone didn't follow along with that threading video.

32:14.880 --> 32:20.400
So let me go over the script to show you how someone might do this image processing normally.

32:20.400 --> 32:27.360
So I'm using the pillow library here, which if you don't know what the pillow library is, it's a

32:27.360 --> 32:33.600
image library for Python that makes it makes image processing easy. I also have a video on pillow if

32:33.600 --> 32:39.360
you'd like to learn more about image processing. But I have a list here of image names. And these

32:39.360 --> 32:45.200
are all of the images or all of the image names that we downloaded in the last video using threading.

32:45.760 --> 32:51.440
So I am starting a counter here so that we can measure how long our script took.

32:51.440 --> 32:58.000
I am setting a size of 1200 pixels. And that is what we are going to resize these high resolution

32:58.000 --> 33:04.640
photos to. Okay, and now what I am doing is I am looping over all of those image names.

33:04.640 --> 33:12.000
So with one image at a time, I am opening that image. And then I am running running this image

33:12.000 --> 33:19.200
filter. And we're just doing a Gaussian blur on that image. And then I am doing an image thumbnail

33:19.200 --> 33:27.520
and setting it to this 1200 pixel size. And then we are saving that image into a processed folder

33:28.320 --> 33:34.000
with that the image name. And then we are printing out that that image was processed.

33:34.000 --> 33:39.600
Now I do have a processed folder here within my directory. If you don't, you'll probably get an

33:39.600 --> 33:45.200
error. And I also have all of these photos here within my directory. If you don't have those,

33:45.200 --> 33:50.400
then you're also going to get an error. So you want to have all of those photos in order for

33:50.400 --> 33:56.640
this code to work. Then after that's done, I am printing out the time that it took. And then

33:56.640 --> 34:03.280
I am printing out that our script is finished. Okay, so this is processing 15 high resolution photos.

34:03.280 --> 34:09.280
So if I run this now, then let's see how long this takes. So I'm running this, we can see that

34:09.280 --> 34:16.160
it is just going through synchronously and running these one at a time. And then we will print out

34:16.160 --> 34:23.040
the final time once this is done. Now, I think that my processing here, I think that this still

34:23.040 --> 34:29.440
might be more IO bound than CPU bound. Because opening the image and saving this here is going

34:29.520 --> 34:37.920
to be more of an IO bound thing. I don't know how much is actually getting CPU bound here using

34:37.920 --> 34:43.520
this filter. But if we were doing some more computations, then this would be more CPU bound.

34:43.520 --> 34:49.440
And we can even test this in a second. But anyways, we can see that our script finished in 22

34:49.440 --> 34:56.880
seconds. So that's how long it took to do this image processing here on 15 of these high resolution

34:56.880 --> 35:01.920
photos. Now, when we're processing a lot of items like this, this is actually a great candidate to

35:01.920 --> 35:08.400
use multi processing, because this can be one of those CPU bound operations that's spending a lot

35:08.400 --> 35:13.520
of time processing each image. And it's not moving on to the next image until the previous one

35:13.520 --> 35:19.280
finishes. And if we use multiple processes, then it can actually go ahead and move on to the to

35:19.280 --> 35:25.040
process another image while the previous one is finishing. And even if this is IO bound, unlike

35:25.040 --> 35:30.800
threading, CP or multi processing is actually going to be beneficial for IO bound processes as

35:30.800 --> 35:36.880
well. So now let's see how we can change this code so that it's using multiple processes instead.

35:36.880 --> 35:43.280
So first, let's think about what we're doing here. So we're looping over our list of images

35:43.280 --> 35:49.280
and processing each one at a time. So if we remember from our previous examples, then this

35:49.280 --> 35:56.160
would probably be a good candidate for the processing pull map method, where we can pass in a function

35:56.160 --> 36:03.200
and a list and have that function run with every value in that list. But first we'll have to create

36:03.200 --> 36:10.000
a function that will process a single image. So to do that, if we think about this, we can basically

36:10.000 --> 36:17.280
just replace our for loop, because our for loop is processing a single image from our images list.

36:17.280 --> 36:24.400
So instead, we can just change this one line here and just turn this into a process image function.

36:25.120 --> 36:30.800
And we will just accept this image name as the argument. And now that we have that function,

36:30.800 --> 36:38.160
that process is a single image, then we can create a process pull and map our list of images using

36:38.160 --> 36:44.960
that function. So first let's import the concurrent futures module so that we can use that. So up here

36:44.960 --> 36:55.760
at the top, I'm going to import concurrent dot futures. And now down here below our function,

36:56.480 --> 37:09.760
we can do this by saying with concurrent dot futures dot process pull executor as executor.

37:10.560 --> 37:20.960
And now within our context manager, we can just say executor dot map. And we want to map this

37:20.960 --> 37:31.840
process image function. And we want to pass in the list of these image names. Now, just in case

37:31.840 --> 37:39.040
that was confusing, let me go over exactly what we did again, in order to change our previous

37:39.040 --> 37:44.640
script in order to use multiprocessing. So we were using a for loop here. But instead,

37:44.640 --> 37:49.760
we changed this to a function that processes one image at a time. And now we're using our

37:49.760 --> 37:56.560
processing pull executor like we saw before within a context manager, we're running executor dot map.

37:56.560 --> 38:02.640
And we are passing in that function that we created. And then we're passing in our list of

38:02.640 --> 38:10.800
image names. And again, what map does is it runs this process image function with every item in

38:10.800 --> 38:16.640
this image names list. And just with those small changes, this will actually use multiple processes

38:16.640 --> 38:23.840
to process those images and run these in parallel, instead of running these synchronously. So if I

38:23.840 --> 38:30.880
run this, whoops, and I made another mistake here, you guys probably saw that one also. But I needed

38:30.880 --> 38:36.480
to put a colon there. Okay, hopefully that's my only mistake. Okay, so if I run this, then we can

38:36.480 --> 38:41.760
see now these are processing faster. And I'm going to open up my activity monitor here, and scroll

38:41.760 --> 38:48.400
down to the P's. And we can see here that we have multiple Python processes running here. So we can

38:48.400 --> 38:54.320
actually see these in our activity monitor. And now that this script is finished, then we can see

38:54.320 --> 38:59.600
most of those go away. The only one that's still here is probably just one that is open here in

38:59.600 --> 39:05.680
my sublime text. So we could see all of those kick off in our activity monitor. And we could see that

39:05.680 --> 39:10.400
they were all returning faster. That's because they were running in parallel. And now instead of

39:10.400 --> 39:16.720
taking 22 seconds, like it did before, now it finished in seven seconds, so more than a third

39:16.720 --> 39:21.680
of the time. So that's a pretty significant speed up there. And this would be even more

39:21.680 --> 39:26.880
significant if we were processing even more images. So the speed ups can be pretty drastic,

39:26.960 --> 39:32.160
depending on what you're doing. Now, again, you might want to experiment when using multiple

39:32.160 --> 39:37.360
threads or processes for specific tasks, depending on what you're doing and what kind of hardware

39:37.360 --> 39:42.400
you're running. One might be drastically different than the other. And it's hard to tell exactly what

39:42.400 --> 39:47.440
you should be using without some benchmarks. But again, a good rule of thumb is that you want to use

39:47.440 --> 39:53.520
threads for things that are IO bound. And you'll want to use processes for things that are CPU bound.

39:53.520 --> 40:00.000
But you may actually see significant speed ups using threads with this example, since this is

40:00.000 --> 40:05.760
reading and writing to disk, which is an IO bound operation. Now, one nice thing about using the

40:05.760 --> 40:10.720
concurrent futures library like this is that switching between threads and processes is just

40:10.720 --> 40:17.600
as simple as changing this process pull executor, and just using a thread pull executor instead.

40:17.600 --> 40:24.720
And you can do that vice versa to change from threads to processes with your programs. So

40:24.720 --> 40:30.240
if I change this to a thread pull executor, let me see if I'm right about a lot of this

40:30.240 --> 40:37.120
being IO bound here. If I run this, then we'll see how long this takes us to finish this script

40:37.120 --> 40:43.200
using threads instead of multiple processes. And that was actually faster. So that was 7.2 seconds.

40:43.200 --> 40:49.040
So even though I tried to put together an example that was doing a lot of processing on the CPU,

40:49.040 --> 40:55.920
it looks like most of this is IO bound from opening and saving these files and not CPU bound, but from

40:55.920 --> 41:00.640
doing some image processing here with these Gaussian blurs and these resizes and things like that.

41:00.640 --> 41:06.720
But that's okay. That's why you want to always experiment. And, you know, if you try it with

41:06.720 --> 41:11.920
a process pulled, and maybe try it once with threads and see if you get a better execution. And

41:12.000 --> 41:18.400
also, whenever you add in even more items, maybe processes will start to become

41:18.400 --> 41:22.880
more performant than threads. So it really just depends on what you're doing. Now,

41:22.880 --> 41:28.160
before we finish up here, I'd like to mention the sponsor of this video. And that is brilliant.org.

41:28.160 --> 41:33.440
So when we're talking about threading and multi processing, these topics are especially useful

41:33.440 --> 41:38.560
in the field of data science. And the data science field is growing at a very rapid pace.

41:38.560 --> 41:42.400
If you'd like to learn more about programming and data science, then I would definitely recommend

41:42.400 --> 41:47.680
checking out brilliant.org. So brilliant is a problem solving website that helps you understand

41:47.680 --> 41:53.120
underlying concepts by actively working through guided lessons. And they've recently added some

41:53.120 --> 41:58.800
brand new interactive content that makes solving puzzles and challenges even more fun and hands

41:58.800 --> 42:03.440
on. And if you'd like to learn more about data science and programming with Python, then I would

42:03.440 --> 42:08.080
recommend checking out their new probability course that covers everything from the basics

42:08.080 --> 42:13.920
to real world applications and also fun things like casino games. They even use Python in their

42:13.920 --> 42:19.280
statistics courses and will quiz you on how to correctly analyze the data within the language.

42:19.280 --> 42:23.600
So their guided lessons will challenge you, but you also have the ability to get hints or even

42:23.600 --> 42:28.160
solutions if you need them. It's really tailored towards understanding the material. They even

42:28.160 --> 42:33.200
have a coding environment built into their website so that you can run code directly in the browser.

42:33.200 --> 42:37.200
And that is a great compliment to watching my tutorials, because you can apply what you've

42:37.200 --> 42:41.920
learned in their active problem solving environment. And that helps to solidify that knowledge.

42:41.920 --> 42:47.920
So to support my channel and learn more about brilliant, you can go to brilliant.org forward slash

42:47.920 --> 42:54.080
CMS to sign up for free. And also the first 200 people that go to that link will get 20% off the

42:54.080 --> 42:58.400
annual premium subscription. And you can find that link in the description section below. And

42:58.400 --> 43:04.800
again, that is brilliant.org forward slash CMS. Okay, so I think that's going to do it for this

43:04.800 --> 43:09.760
video. I hope you feel like you got a good idea of how to use the multiprocessing module and how

43:09.760 --> 43:14.880
we can use these to speed up our scripts. Now, I hope you also feel like you got a good overview

43:14.880 --> 43:20.080
of threads and processes. And when you should use those. But like I said, if you're unsure,

43:20.080 --> 43:25.360
then there's no hurt in simply trying both on a subset of your data to see what gives you the

43:25.360 --> 43:30.480
most speed up. Now, there are some more advanced topics that we could cover in future videos,

43:30.480 --> 43:36.000
such as race conditions, locks and things like that. But we'll save that for a future video if

43:36.000 --> 43:40.080
anyone is interested. But if anyone has any questions about what we covered in this video,

43:40.080 --> 43:44.000
then feel free to ask in the comment section below and I'll do my best to answer those. And if you

43:44.000 --> 43:47.920
enjoy these tutorials and would like to support them, then there are several ways you can do that.

43:47.920 --> 43:51.840
The easiest way is to simply like the video and give it a thumbs up. And also it's a huge help

43:51.840 --> 43:55.520
to share these videos with anyone who you think would find them useful. And if you have the means

43:55.520 --> 43:59.520
you can contribute to Patreon and there's a link to that page in the description section below.

43:59.520 --> 44:02.560
Be sure to subscribe for future videos and thank you all for watching.

