{"text": " Welcome back. Today we're talking with Dr Simon Cornblith, a research scientist in the Google Brain team. Simon is most famous for being one of the authors on Simclear, the computer vision paper that used self-supervised learning and the contrastive loss with loads of cool image augmentations. Simon also used to be a neuroscientist. When I was pretty young, I was interested in consciousness and how we create this kind of impression of the external world inside our heads. And so I guess it's pretty obvious how that translates into an interest in brains and how the brain works. Turns out the neuroscience is really difficult. Progress is really slow and tedious. Simon's goal is to understand the inner workings of neural networks, both in meat space and in silicon. He initially thought that the artificial variety might be easier to understand. He was in for a rude awakening. So in a neural network, we can record all the neurons, which is extremely challenging in a biological organism. And we can also manipulate the system in any kind of way that we can imagine. But it still seems really hard to understand neural networks. I think there are a lot of ideas from machine learning that will ultimately help us understand brains. Maybe we could make some headway that might eventually translate back to brains. And so that's how I ended up in machine learning. People often try and anthropomorphise neural networks. People try to relate whatever neural network they've built back to a brain and they say that it works like the brain, but it doesn't work like the brain. So Simon was involved in this paper, do wide and deep networks learn the same things, uncovering how neural network representations vary with width and depth. Simon pioneered this really fascinating way of comparing representations by comparing features. And what this essentially amounts to is we need to have a similarity function so that we can compare the representations in layers to themselves in different parts of the network or indeed to other networks. And so for this similarity measure to work well, the first thing Simon did was take two architecturally identical networks, A and B, trained from different random initialisations and just ensure that the third convolution layer is more self-similar to its counterpart than any of the other layers. If that works, then you're onto something. Turns out that's not super simple to do, but Simon came up with this concept called the centred kernel alignment, which we'll talk about on the call. But this is actually super fascinating. We're talking about this idea here of using self-similarity to reason about the evolution of representations throughout successive layers in the neural network. And what Simon found is that you get this kind of characteristic blockiness. So when you see these large blocks, what it means is that the representations are no longer evolving in respect of time. So it's showing here the representational similarity of all of the layers against themselves and against all of the other layers. So clearly there's this characteristic diagonal down the matrix, as you would see with any self-similarity matrix. And because this blockiness appears, it means that nothing is happening. And what Simon realised is you can actually delete these layers from the neural network and it wouldn't make any difference because it hasn't learned anything new. But it's also a really interesting way of reasoning about a kind of pathology, a weird thing that happens when you saturate a neural network. So he said that this presence of this block structure is an indicator of the halting of evolution and a strong indicator of over-parameterisation. And he actually shows that this blockiness appears on deeper networks and wider networks. But this concept of self-similarity analysis is not new to me. On my PhD, I was fascinated in segmenting DJ-mixed music shows and I actually used the same techniques for learning regimes in financial datasets later on. This is an example of a DJ-mix which I segmented. I came up with a dynamic programming algorithm which would essentially sum up all of the tiles along this diagonal and compute the lowest costs contiguous segmentation. And it's super interesting. So here are two music tracks and you can see that they are more self-similar to each other than they are any of the other tracks just because of the tone of the colour here. And if you zoom into a track, you can even see that there are symmetries. This part of the track here is a repetition from this part of the track here. And you can tell that from this kind of symmetry pattern on the diagonal. And you can see that there's a little bit in the track in the middle here which is not similar to any other part of the track. You see some really interesting stuff here and essentially I'm a huge fan of anyone using self-similarity matrices for reasoning about the evolution of representations. I think it's a fascinating idea. So how did Simon come up with this measure of similarity? The centred kernel alignment. Jeff Hinton had another idea and I tried the idea that it worked but then we wondered is there a simpler thing that worked. And that's how we ended up with centred kernel alignment. The blockiness in these matrices is absolutely fascinating but how much can we read into it? It's not clear what we should really expect in terms of how a neural network representation evolves through the layers. I think there's kind of some theory on what we should expect if all the layers are linear. But like obviously the neural networks that we train are nonlinear and it's really important to have a nonlinearity in between the layers. If we see that nothing is changing from one layer to the next that's a really bad sign. If the neural network representation isn't changing then obviously nothing's happening. We couldn't have predicted this ahead of time based on what we know about neural network theory and we couldn't have predicted it ahead of time based on the accuracy of the network. Does this apply to ResNets though? I thought that they could learn their own capacity. You can either look at networks without residual connections where you do actually find that at some depth the accuracy will start going down and in networks without residual connections we find that the depth where accuracy starts to go down is like around the same depth where you begin seeing this kind of block structure where many successive layers have similar representations and it looks like the representation is no longer getting refined through the network. Once you start getting these blocks making the network deeper, making the network wider no longer really gives you any improvement in accuracy. So it seems like this is basically telling you that the network has fit the data as much as it can and there's no real advantage to using something bigger. Next we move on to Simon's paper about using different loss functions on image classifiers and he made some really interesting findings actually so the loss functions only really seem to affect the penultimate layers in the neural network. This also gives us some pretty useful insight into transfer learning. The last third of the network is setting up the penultimate layer representation in a way that is good for your loss function but the first two thirds of the network are somehow just learning general features. I think this also corresponds with the success of transfer learning where we can take features that we've learned on one task and transfer them to some other task. What's the implication though? It seems, is the implication that the loss function is not having any impact on the representations early on in the network? That seems like quite a big implication. Ultimately we're asking the network to do the same thing just in a slightly different way. Like some inverse correlation between the gains you get from a loss function and how good it is for transfer learning. If you use loss functions that give you higher accuracy on ImageNet, you tend to learn representations that transfer substantially worse in that setting. The loss functions that perform better lead classes to become more separated in the penultimate layers. To standard softmax loss, actually the classes are not that separated from each other in the penultimate layer representation. Right now on whatever TensorFlow Hub or Hugging Face repositories and so on, we have these pre-trend models and the pre-trend models, they're like full stack models and people usually take some sort of last or next to last hidden layer but maybe we should much more focus on actually providing like half of a network to share, like determining which are actually the best, good or general representations from a data set and so on. It's a really interesting question. If we just want to turn an image into a vector that we could then train a linear classifier on top of, what is the best way of doing that? Self-supervised pre-training, just like word vectors, gives us a really great starting point to vectorize an image into a semantically relevant geometric space. It's been a real game changer in the computer vision world since about 2018. We want that neural network to learn a representation such that when we then just train a linear classifier on top of that representation to classify image net, it's going to do well. But we want to learn the initial representation without using any kind of labels. So what is self-supervised pre-training for vision? People came up with these kinds of tasks that you could try to train a neural network to do so that it would learn some kind of good representation. You're trying to learn some kind of representation space where you've got different patches from an image or different augmentations from an image, just different representations of the same image and you want to learn a representation space where these representations of the same image are all close together in that representation space and they're far apart from the representations of other images. This surprisingly seems to lead to very good representations. I was very fascinated by all of these different tricks that you apparently have to get and so big kudos to figuring all of this out for the rest of us. Data augmentation is absolutely key to making this work. The important part of the recipe is data augmentation. There are really only two super important data augmentations that we need. So we have to take two different crops from the same image and then we have to do some kind of color distortion. Turns out though the architecture isn't that important. You don't have to worry about architecture, engineering specifically or contrastive learning. What was new in the CIM CLR paper? We introduced the idea of this projection head in CIM Clear and we also spend a lot of time studying the augmentation. And what about the bring your own latent paper? I don't really have any insight into how either BYOL or the more recent papers actually are learning a representation that doesn't end up collapsing. Why it doesn't happen relates to some mysteries about neural network training dynamics that we still don't entirely understand. We dive deep into data augmentation in general. The data augmentation that you need for contrastive learning is different from the data augmentation that you need for supervised learning because the task is different. When you have contrastive learning, you have this problem that if there's just one feature in your data that can be used to do the contrastive task to get images of the same example or views of the same example close together and far apart from views of all the other examples. If you could do that with one feature, that would be the only feature the network would ever learn or it might be the only feature the network would ever learn. And so with the augmentation, you're making the task harder so that the network actually has to learn many different kinds of features. We find that this color distortion actually is very important for self-supervised learning, for contrastive learning, or as it doesn't really matter for supervised learning. There seems to be this fascinating universality of representations, especially in vision. I'm not trying to be flippant when I say this because practitioners have used ImageNet on a variety of downstream tasks. For example, they might use it for classifying circuit boards or something. And the miraculous thing is it just seems to work quite well. So do you think in your opinion that there is some kind of universality? I'm very skeptical about universality of ImageNet for different tasks. Even though there are lots of cars in ImageNet, if you pre-train on ImageNet and you fine tune on that data set, you will learn to classify it faster and fewer steps than if you had trained from scratch on the Stanford cars data set. But you won't actually perform any better at the end. Representations of images are not that universal. And at least what works for natural images like those in ImageNet may not work on other data sets. Taking a bit from the universality of representations to the universality of augmentations, since this is such a crucial part, do you think that there is a systematic way how we can discover augmentations? Right now, it seems to be kind of a whack-a-mole, right? It's okay. We just feed images and say, no, that's too easy. We crop them. Oh, no, it's the color histogram. So we like whack on the color and then it works better. Maybe someone finds out, oh, there is still this easy feature that the network, every noun, then pays attention to, so we design a method to whack on that a bit. Do you think there is a systematic way or will this kind of philosophically always rely on us humans having a higher level inside of what we want to do with the data set? So what comes next after data augmentation? So would the next step be some simulation? Do you know what I mean? Where we impute physics and we impute some world knowledge and then, I don't know, whether we train a machine learning model from that? Yeah, I think there are definitely shortcomings in our current machine learning models, understandings of the world. There are probably things that we can't just solve by throwing more static images at them. I think maybe the next step, rather than trying to immediately situate the machine learning model in a simulated world, we could just think about video. I think probably representation learning from video is going to be a big thing next year or the year after, something sometime in the near future. Finally, we talk about Simon's paper. Big self-supervised models are strong semi-supervised learners. What is a practical problem is the situation where you have a lot of unlabeled data and then a very small amount of labeled data. What I find fascinating is how many ideas come together in this paper. You probably didn't sit down after a SimClear one and be like, all right, what do we do for SimClear two? Okay, let's do this. So it tells me there was this process. Could you, if you can, maybe elaborate a bit on how did you going to build up the system towards the final output? We also tried the approach of first fine-tuning the big network and then distilling it. It turned out that worked a lot better. What we found was this approach of pre-training, then fine-tuning, then distilling works a lot better than pre-training, then distilling, then fine-tuning. We probably shouldn't expect distillation of the kind that we do in SimClear v2 to work substantially better than supervised distillation, which has been around for quite a while now. I think what's impressive is that in the self-supervised case, in the contrastive case, distillation basically allows you to recover the same accuracy that you would get from training supervised from scratch, whereas without it, the accuracy is a lot worse. So it seems like it maybe matters more in this contrastive case. But I think generally when you do distillation in the supervised case, you can get maybe a percentage point gain, maybe a couple of percentage points. And I think that's probably about the limit in terms of the improvement that you could get from any kind of distillation-based approach over supervised training from scratch. Can you use GANs, Generative Adversarial Neural Networks, to do data augmentation? Or is that just a myth? Simon certainly seems to think so. Using a GAN to do data augmentation, you have this problem that you still don't actually have more data. You have a GAN that's trained on the same data. And so it might help you because your way of encoding inductive bias into the GAN is different from your way of encoding inductive bias into the neural network. And maybe by having more inductive bias, you can learn a better function. You still don't have more data, and it seems like without having more data, there's no reason to expect a priority that you will be able to learn a better function. Ironically, when you do the simple data augmentation, you do have more data because you put all the knowledge in there as a human of what makes two images dissimilar visually, but still equivalent semantically, which, again, is exactly the opposite. It gives you images that are visually similar, but it has no intuition of what the semantic similarity is. We round off the show by talking about Simon's love of the Julia language. Julia is a much better programming language than Python in many ways. Julia is designed for these situations where maybe beyond just matrices, you have these funny types of structured matrices, you have sparse matrices, and you can define special methods for the product of a sparse matrix in a vector, or all sorts of things where you might want different methods depending on the types. I really hope you've enjoyed the show today. We've had so much fun making it. Remember to like, comment, and subscribe. We love reading your comments, every single one of them, and we'll see you back next week. Welcome back to the Machine Learning Street Talk YouTube channel and podcast with my two compadre, Syac, the neural network pruner, Paul, and Yannick, the Lightspeed protein folder, Kiltcher. Today we have an incredibly special guest, Simon Cornblith, and Simon got his PhD in brain and cognitive sciences from MIT. His undergrad was from Caltech, and he's a research scientist at Google Brain. He's been there since about 2017. He's been cited nearly 2,000 times, which for someone quite early in career is seriously impressive. He's got a keen interest in the digital humanities, in philosophy, computer science, machine learning, computer vision, and neuroscience. He used to be a neuroscientist before we started doing machine learning, and he tells us that he's got some very strong opinions about neuroscience and machine learning, which we certainly will be getting on to later. He's a huge lover of the Julia language, so if you Google Simon's name, you'll see him talking at about a million Julia conferences, so definitely check that out as well. Simon pioneered the use of centered kernel alignment as a way of analyzing the evolution of representations in layers, in network, and between networks of different architectures. Now Simon, like me, is a lover of similarity matrices, and what can be gleaned from them? On my own PhD, I worked with them a lot for music segmentation, and also for detecting regimes in financial data sets. When a block in a ResNet is no longer self-similar to previous layers early on, you might intuit that it's moving into a new representational regime, or maybe it's just started hallucinating. All of this stuff was covered in his paper, Do Wide and Deep Neural Networks Learn the Same Things, and I find it fascinating that representation of self-similarity can reveal network pathology. Now in his paper, What's in a Loss Function for Image Classification, he noted that different losses and regularizers have similar accuracies on several data sets, but using the same representational evolution analysis, Simon gleaned that these losses and regularizers only affected the penultimate layers in the neural network, revealing inherent limitations in what can be achieved in manipulating the loss on a network. Now next in the session today, we're going to talk about the Simclear paper, and this was an incredibly exciting paper for unsupervised contrastive image learning with augmentations. It introduced a learnable nonlinear transformation between the representations and the contrastive loss, which massively improved the representations. The composition of augmentations is super important, and whenever anyone asks me about what are the different data augmentations in computer vision, I always point them to the SimCLR paper because it's got this wonderful matrix, and in that matrix it was shown that the crop and the color I think were the most effective augmentations, but Simon also noted that the batch sizes were super important, and the paper improved over the state of the art on the ImageNet top one, and actually matched unsupervised methods for the first time, albeit with many more parameters. But the final paper we're going to talk about today is Big Self-Supervised Models, a strong semi-supervised learners, and this is where you can learn from fewer labeled examples while making use of a large amount of unlabeled data, and with unsupervised pre-training on SimCLR v2, supervised fine-tuning on a few labeled examples, and then distillation with unlabeled examples, this approach improved the label efficiency over previous state-of-the-art methods. I remember Yannick Lightspeed Kilcher made a video on this one, which I watched a few months ago, so Yannick will have all of that completely fresh in his mind. Anyway, Simon, it's an absolute pleasure to welcome you to the show. Thank you so much for coming. It's great to be here. Amazing. How did you get into machine learning? So I guess first I got into neuroscience, and then I got disillusioned with neuroscience. When I was pretty young, I was interested in consciousness and how we create this kind of impression of the external world inside our heads. And so I guess it's pretty obvious how that translates into an interest in brains and how the brain works. So I spent both four years as an undergraduate doing neuroscience research, and then seven years working with monkeys at MIT trying to figure out how monkey brains work. And then after that, I felt like we weren't getting very far by trying to record from neurons in monkeys' brains and figure out how those neurons work. So I thought about what other ways are there approaching this problem? How could we think about how to understand how the brain is doing tasks? And it seemed like maybe by building systems that can do those tasks well that are not biological, we could learn more. So that's how I got into machine learning. I joined the Google AI residency program, which is like this great program that Google has to take people who have extensive background in some field that is not machine learning and train them to do machine learning. And I ended up at Google, and initially I thought I'm going to spend a year here learning about machine learning related stuff, and then maybe I'll go back to neuroscience and I'll decide the tools for machine learning could be applied back to brains, and maybe we can learn more about brains by applying the tools of machine learning there. But ultimately I decided I was more interested in just looking at how the neural networks work and also in the engineering challenges of building better neural networks, which I actually think are fun. One of the thoughts that came to my mind is it's fascinating looking at the kind of introspective analysis that you've been conducting with neural networks, but could you contrast that with neuroscience? Because as I understand, you have MRI scans and you have different ways of trying to visualize and reason about the behavior of a brain, but you can't really tweak the architecture and tweak all of the knobs and the levers in quite the same way you do in machine learning. Yeah, so like in neuroscience people also use this analysis across different individuals or different organisms or whatever. It is a tool that people use in neuroscience as well, but I guess they're limited in the ways in which they could manipulate the systems that are providing these representations. So in neuroscience, you're always constrained by data, so you can compare representations of images across individuals by doing MRI scans. But first of all, you might not get a very good idea of how the brain is representing those images because there's a lot of noise in the MRI scan and there's a limit to how long you can scan each person, whereas I guess in a neural network, noise is not a problem. The entire system's deterministic, we just pass in the image and we get the representation vector. And you also have these kinds of limits of, like, we can't see what happens if people have bigger brains, like we can't manipulate the architecture in those kinds of ways. So even though we can look at how intact brains are working, we can't see how representations change when we manipulate them all that easily. And I guess, again, in machine learning, like we can do all of those things. We can look at what happens when we change the loss function. We can look at what happens when we make the network deeper or wider. So I think there are, like, some really cool ways that even the same techniques can be applied in machine learning that they couldn't be applied in neuroscience. I felt like we weren't getting very far by trying to record from neurons in monkey's brains and figure out how those neurons work. Like it didn't really seem like a very effective way of figuring out how the brain constructs this kind of internal representation of the world. So from there, I thought about what could we actually do to understand this? And it seemed like the most promising thing to do was to look at what happens in simpler systems that we can construct ourselves and where we can analyze the behavior of everything inside the system. So in a neural network, we can record all the neurons, which is extremely challenging in a biological organism. And we can also manipulate the system in any kind of way that we can imagine. But it still seems like really hard to understand neural networks. So it seemed like maybe this was a more tractable challenge and a challenge where maybe we could make some headway that might eventually translate back to brains. And so that's how I ended up in machine learning. I guess there are, like, other great things about machine learning. I guess the pay is much better than in, like, academic neuroscience. But really, I think, like, it's a logical progression based on the ideas that I was interested in. And I am still interested in the same sorts of ideas. Do you still think now that you're in machine learning and have made some progress here that there is a good chance that we're going to map our knowledge that we gain back to the brain? Or do you think there is a bit of a disconnect? I think that's a really good question. I think there is definitely some knowledge that we're going to get from machine learning that will map back to the brain. I think, like, in terms of general principles and ways of looking at how, like, information processing systems work, I think there are a lot of ideas from machine learning that will ultimately help us understand brains. I'm a little less sure whether we're going to build, like, a machine learning system that is a brain. I think there's a disconnect between the way that the systems that we build work and the way that biology works. And I think that's insurmountable just because there's differences between what you can build efficiently with cells and what you can build efficiently in silicon. But in terms of approaches to understanding, in terms of building tools to understand things, the tools that we build in machine learning, I think will eventually be useful in neuroscience. So people make a lot of analogies and they make a lot of claims about neuroscience in connections with neural networks. Is there a statement or a bunch of statements that you hear over and over again where you just cringe because they're so wrong? Is that something that happens to you? I can imagine it would. Yeah. Yeah. So I think there's this, like, kind of basic fact that neural networks are inspired by brains, which is true. Then there's all this other stuff where people try to relate whatever neural network they've built back to a brain and they say that it works like the brain, but it doesn't work like the brain. There's still this huge kind of disconnect in how the system is actually operating. The brain is not literally doing back prop. It might be doing something that's like back prop. We still don't really know, but it's not literally computing gradients by automatic differentiation. And I'm fascinated to talk about this line of reasoning that you have because you're clearly the kind of guy that you want to reason about the behavior of models and in particular the evolution of representations. And I watched one of your presentations on YouTube where you were talking about how you can compare the representations by comparing features. And of course, the naive way of doing is the dot product or some variations of that. Turns out that doesn't work very well. And you came up with this wonderful metric called the centered kernel alignment. So how did that all come about? The way we came up with that idea was that Jeff Hinton had another idea and I tried the idea and it worked, but then we wondered, is there a simpler thing that worked? And that's how we ended up with centered kernel alignment. I guess the problem that we had in trying to come up with a way of comparing similarity of neural network representations is that it's really hard to know what is a good way. Like it's not something where you can really develop a good benchmark. So like in the paper, we came up with this simple sanity check where the idea is basically we've got two architecturally identical neural networks and we just train them from different random initializations. And so we want it to be the case that if you measure like the similarity between a layer from network A and all the layers from network B, that the most similar layer in network B is going to be the architecturally corresponding layer. So if we have layer two from network A, it should be more similar to layer two from network B than layer three or layer four. And so like basically we found that what people had been doing before didn't always pass that sanity check. And we basically tried to come up with the simplest way of building a similarity index that did actually pass that sanity check. And that's how we ended up with centered kernel alignment. Yeah, because I think you showed that the canonical correlation analysis only worked about, I think at an accuracy of about 1.4%. So it's complete apples and oranges. But this absolutely fascinates me though, because when you plot this thing in this kind of self similarity matrix, you can glean so much about the evolution as a function of time. And because you talk about this in one of your other papers as well, that there's this characteristic blockiness. And when you see blockiness, that successive layers are similar to versions of themselves in the past. And that kind of means that they're not evolving anymore. And you then made the intuition in your paper that, well, essentially it's redundant information. If it's not learning anything new, I can just delete that block. I can just delete those layers from the neural network and it won't make any difference. And indeed it didn't. Yeah. Could you, for people listening, explain the similarity measure you came up with in principle, just so we can imagine something, how that should even work? Yeah. So I guess the idea is you've got a neural network and you feed some set of examples, like multiple examples through the neural network. And now you've got some matrix where the rows of the matrix are different examples and the columns are different neurons. So yeah, you can imagine this as if you have vectors of activations for each example, you've stacked them real wise. So now what do we do with that to compare two neural networks trained from different random initializations? The problem is if we were to just take the square difference between those matrices, we have this problem that the neurons between these two different networks aren't necessarily aligned in any way if they're trained from different random initializations. Even if we had exactly the same neurons, we shouldn't expect that neuron one would be the same, representing the same thing in both networks. So we need some way to get around that problem. One way around this problem is instead of comparing these original matrices, we're going to make matrices that measure the similarity of each example to each other example for one particular network. So if we've got example A and example B, we can measure their similarity very simply just by taking the dot product between those two vectors. And now because we're measuring similarity from the same network, we don't have to worry about this alignment problem. And we get some idea of how similar different examples are to each other according to the representation in network A. So if we do that for all the examples, we get some examples by examples matrix. And then we can do that both for our first network and for our second network. So after we've done that, we've got these two examples by examples matrices. And then the easy way to compare those matrices is we just reshape them to vectors and we take the dot product again between those vectors. So now we've measured the similarities between the similarities of the examples. And this doesn't have this problem of aligning the neurons because instead of measuring similarities of neurons, we're measuring similarities of examples and then we're comparing those similarities. So ultimately, we do that, we take that dot product and then we normalize it in a way that makes it invariant to scaling. So if you just took the dot product, you'd have this problem that scaling all of the features by some number, if you scale everything by a factor of two, the dot product will go up by a factor of two. And so we just apply some normalization so that kind of scaling will not affect the similarity index and we get centered kernel alignment, which gives us a similarity score between zero and one. The fascinating thing is that you can replace that dot product with a kernel because it's a gram matrix. Yeah. So did you find that it made a difference if you use, let's say, the RBF kernel? Yeah. Yeah. So, yeah, basically when we're measuring the similarities between examples, we can just instead of taking the dot product between the representations of the different examples, we can take the kernel between one example and another example because the kernel is also a way of measuring similarity. And so we tried that. It turns out that like for CNNs, it didn't really make a difference. Like the RBF kernel worked, but sort of just taking a regular dot product. But we did find in the appendix of that paper that if you instead use an RBF kernel with a transformer, it actually does work better than taking a normal dot product. And I think like part of what's going on is that sometimes you want it to be the case that when you're measuring similarity, you care more about the distances between the examples that you're close to than the distances to the examples that you're far away from. Like once you're really far away from something, maybe it doesn't matter so much if you're 10 times as far away because like you're already so far, you're already not going to... You don't really care how far away something is once you're far enough. And the RBF kernel takes that into account in a way that a linear dot product wouldn't. The linear dot product is like very sensitive to the global distances in the space. What I find fascinating is that you can glean so much from the blockiness, right? So you are saying that as it becomes blockier, it might be an indication that it's become saturated in some sense. And I'm also interested in a way, we already know that the representations in neural networks are increasingly abstract, so they don't necessarily bear any resemblance to the beginning. So when we're looking at the cell similarity matrix, we don't necessarily want the representations on the final penultimate layers to be similar to the ones at the beginning. We want there to be a continuous evolution. We don't want to have a stalled evolution because that would correspond to this blockiness. But is it when you've stalled for a long time, is that when it becomes pathological? Because we want it to evolve in stops and starts, don't we? Yeah. I think it's not clear what we should really expect in terms of how a neural network representation evolves through the layers. I think there's kind of some theory on what we should expect if all the layers are linear. But obviously, the neural networks that we train are nonlinear, and it's really important to have a nonlinearity in between the layers. And so at that point, it's really hard to reason about what the optimal thing for a neural network to do actually is. I think it's something that we can really only study empirically. On the other hand, I do think if we see that nothing is changing from one layer to the next, that's a really bad sign. If the neural network representation isn't changing, then obviously nothing's happening. But I guess it's unclear whether we should expect abrupt shifts or we want things to happen slowly between the layers. I'm not sure whether we really have the theoretical knowledge to say what is best. Yeah. I'd love to see this as a kind of tool in our toolbox that we could use on different network architectures. But you said that the other learn features are shared across different initializations and architectures, particularly across the depths of the network. So it almost seems as if this blockiness is separate to your work in wide and deep neural networks because you showed that the width and the depth have got different effects on network predictions at the example level or at the class level. But the blockiness almost seems to be an orthogonal thing. That's just when you have this kind of saturation of the network, you see the blockiness. Yeah. Yeah. So initially we had hoped that we could look at other similarities between wide networks and deep networks in their representations. But like when we did those experiments, we actually just found that if you make the network really wide, you get this kind of blockiness in the representations and those blocks are like dissimilar across different initializations. And then the same thing happens if you make the network really deep. We see these like big blocks in the representations. So that made it hard to study these very wide and very deep networks from the representational similarity perspective. But at the same time, I think it's like a really interesting observation. Like it's something where we couldn't have predicted this ahead of time based on what we know about neural network theory and we couldn't have predicted it ahead of time based on the accuracy of the network. It's something where we really needed like these techniques for looking at the internal representations of neural networks to see what was happening inside of them. There's this whole literature that takes a look at a network's expressibility with regards to its depth and width. So could you just explain it to us whether or not we should be able to meaningfully quantify or formulate the expressibility of a neural network with regards to your analysis made on that? Yeah. So there's this work that looks at like kind of the functions that can be expressed by wide networks and the functions that can be expressed by deep networks. And I guess like the neural networks seem to become exponentially more expressive as you make them deeper. So it seems like in that sense depth is more important than width. But on the other hand, like the neural networks that we actually train in this paper, like both the wide networks and the deep networks are big enough that they can overfit the entire training set. So in this case, like the expressibility of the network is not really important. Important is the function that the network actually ends up learning. So I guess even though networks could express more functions when they're deep, what we're really studying is the function that you actually get when you train the neural network by gradient descent on some data, what the optimization process actually finds. One thing as well in that paper, you talked about the network pathology, right? You said that two times depth accuracy 95%, four times 93.2, eight times 91.9. So because this is this runs counter to what a lot of us would intuit. We think that you can have as much depth as you want. And architectures like ResNet in some sense, they learn their own capacity. There is a pathology there happening clearly. And how would you determine that from this visualization? Yeah, so I guess there are two kind of results. So like you can either look at networks without residual connections, where you do actually find that at some depth, the accuracy will start going down. And in networks without residual connections, we find that like that the depth where accuracy starts to go down is like around the same depth where you begin seeing this kind of block structure where many successive layers have similar representations. And it looks like the representation is no longer getting refined through the network. Yeah, I mean, with ResNets, you can make them much deeper. And it seems like it doesn't hurt accuracy as much even once you start getting these blocks. But it also seems once you start getting these blocks, making the network deeper, making that work wider, no longer really gives you any improvement in accuracy. So it seems like this is basically telling you that the network has fit the data as much as it can. And and there's no real advantage to using something bigger. Fascinating. Let's move on to another paper that you've done, which is quite related in terms of you've used the same analysis to reason about it. But you had a paper called What's in a Loss Function for Image Classification. And you looked at a whole bunch of different label smoothing and regularizers, which are things that you do on the end of the network. And you identified differences in accuracy and calibration and out of domain distribution. And you made some really interesting observations. So by the way, we're talking about things like do we use the softmax or the squared area or dropout or label smoothing or logic penalty. But you noticed using the same analysis technique that only affected the representations on the penultimate layers of the neural network. What's going on there? Yeah, so it's not just the penultimate layer. It's like the the last maybe third of the network is affected by the loss function. But then the first two thirds of the network, it seems like you learn the same representation no matter what loss function you use. So it doesn't change if you use label smoothing. It doesn't even change if you use mean squared error instead of using softmax cross entropy. You still basically learn the same representation for the first two thirds of the network. And I think it's still it's a bit of a puzzle to us why this happens. Clearly, it matters that you're training the network with the loss function. There's those layers in the first two thirds of the network do change from the initialization. But I guess it seems that the last third of the network is setting up the penultimate layer representation in a way that is good for your loss function. But the first two thirds of the network are somehow just learning general features. I think this also like corresponds with the success of transfer learning, where we can take features that we've learned on one task and transfer them to some other task. What's the implication that it seems is the implication that the loss function is not having any impact on the representations early on in the network? That seems like quite a big implication. Yeah, I think the loss function must have some impact because if you don't train the network, if you don't have any loss function at all, then the representation in that first two thirds of the network is actually quite different. I think what's really happening is there are these differences among the loss functions, which don't really matter except later in the network. Although they will give you a slight change in accuracy and slight changes in robustness, they don't matter for this general feature learning process. I guess maybe it's what we should expect because ultimately we're asking the network to do the same thing just in a slightly different way. We're still asking the network to classify images. We're just asking it to provide slightly different outputs to produce a slightly different representation at the penultimate layer. Maybe we should expect that those earlier features that are just trying to represent general things about images, those will be the same no matter what loss function we pick. In your experiments, did you find whether or not model capacity has anything to do with it? Yeah, so we didn't really investigate different model capacities in that paper. I would expect that the same thing holds for a wide range of model capacities. There's no indication from the experiments that if you use a bigger network or a slightly smaller network that things would change all that much. Yeah, I think it's still an open question how model capacity changes things. I guess in the Sinclair paper, we found that model capacity can matter quite a bit. Yeah, so the general hypothesis there should also hold, even though your model is bigger or smaller, no matter how big or smaller your network is, the general feature learning regime or paradigm should still hold no matter what loss function you would end up using. Yeah, that would be my guess. I think if you're in a regime where it's really hard for you to fit the training data, if you have a very small network, it might be the case that you see more differences in the earlier layers because it might be that the loss function really affects what features are best there in a way that it wouldn't if the network is a bit bigger and if it's more capable of fitting your training data. But I don't really know. I think this is something that is probably worth looking at in some follow-up work. And you found also there's implications for transfer learning with respect to the loss function. There seems to be some inverse correlation between the gains you get from a loss function and how good it is for transfer learning. Or is there a connection between loss functions and regularizers and all of that? Yeah, we look at just linear transfer in the paper. So if we take the features from the penultimate layer and we try to use them directly for some other task, how good are those features going to be? And what we found was that if you use loss functions that give you higher accuracy on ImageNet, you tend to learn representations that transfer substantially worse in that setting. And our intuition is you could learn many different kinds of representations in that penultimate layer and still do a reasonable job of classifying ImageNet. But what seems to happen is that the loss functions that perform better lead classes to become more separated in the penultimate layer. So like class A and class B will be farther apart relative to the variability within the class. And when you have a situation like that, you have this penultimate layer representation that's specialized for the classes in ImageNet. Like you've got a thousand clusters corresponding to the thousand classes in ImageNet. And so then if you want to use like those kinds of representations for some other task, it will only really work well if you have exactly the same classes that are in ImageNet because they're already organized by the ImageNet classes. On the other hand, what we found is if you just use standard softmax loss, actually the classes are not that separated from each other in the penultimate layer representation. And because they're not that separated, there are these features that you could use to classify things that are not ImageNet that still convey some kind of useful information about the images that are not just their ImageNet class labels. It hints at a bit of a future where, you know, like right now on whatever TensorFlow Hub or HuggingFace repositories and so on, we have these pre-trend models. And the pre-trend models, they're like full stack models and people usually take some sort of last or next to last hidden layer. But maybe we should much more focus on actually providing like half of a network to share. Like determining which are actually the best good or general representations from a data set and so on. Do you have any of this in mind when you do work like this? Yeah, at Google, what is generally best for us to do is just to fine-tune the whole network. And if you fine-tune the whole network, it eliminates some of these issues with the actual form of the representation in the penultimate layer. Because even if you have this kind of highly specialized penultimate layer, when if you're allowed to change all the other weights in the network, you can fix that and you can specialize the rest of the network for some other task. But yeah, I think like it's a really interesting question. If we just want to turn an image into a vector that we could then train a linear classifier on top of, what is the best way of doing that? How should we approach that problem? And how should we approach that problem if we want this very like general universal vector representation of an image that would work well for a lot of different tasks? And I think we don't really have good ways of doing that because basically this is all empirical, right? Like, we don't know what makes a good universal representation of an image. We've just got to try a bunch of things and figure out what works best. And I guess, yeah, the insight from this paper is like actually the loss function that you use to train the network can make a huge difference there. Fascinating. I guess without any further ado, we should move on to SIMCLEAR, a simple framework for contrastive learning of visual representations. We've been absolutely fascinated by this concept of unsupervised contrastive image representation learning algorithms. We've seen such a huge kind of step forward, haven't we, over the last couple of years in this area? Yeah, it's pretty amazing to me. Could you just go back to real basics? Imagine that people out there have been living in a cave. They don't know what contrastive learning is. They don't know about image augmentation. How would you frame the whole thing up? The self-supervised learning setup is we've got a bunch of images and at least the initial like historical self-supervised learning setup is we've got a bunch of images. We want to train some kind of neural network on it. And we want that neural network to learn a representation such that when we then just train a linear classifier on top of that representation to classify ImageNet, it's going to do well. But we want to learn the initial representation without using any kind of labels. And yeah, I guess there are a lot of different approaches that people tried for this problem. Like people tried things like let's train a neural network so that we can cut up the image into just a grid and shuffle the grid. And then the neural network has to figure out how to assemble these puzzle pieces back into the original image. And maybe that'll give us a good representation. Or let's try just rotating the images so we can have images that are rotated 90, 180, 270 degrees. And then we'll have the neural network try to classify what rotation we fed into it. And so people came up with these kinds of tasks that you could try to train a neural network to do so that it would learn some kind of good representation. They were defined in this ad hoc way. Let's come up with some kind of funny thing where you don't need a label. You can have the neural network trained to do this kind of thing. And maybe it'll learn something about images. Starting in around 2018, there are a few papers that basically suggested this alternative approach where you're trying to learn some kind of representation space where you've got different patches from an image or different augmentations from an image, just different representations of the same image. And you want to learn a representation space where these representations of the same image are all close together in that representation space. And they're far apart from the representations of other images. This surprisingly seems to lead to very good representations. But it turns out there are a lot of very important details to get this to work well. So it's really like a situation where the basic idea is very simple. Let's create multiple views of an image and try to get them close to each other and far away from everything else. But things like augmentation and things like the exact way we set up the network end up being very important to learning a good representation with this kind of technique. How does the negative sampling work? People have done this in different ways. So in Simclear, our way of doing negative sampling is very simple. So basically, we are attracting two views of the same image. And then we have a mini batch that has 4,096 images in it and two augmentations of each image. And so we are repelling using a softmax from all of the other 8,190 views in that mini batch. Basically, we want our two augmentations of the same image close and we want them to be far from the other 8,190 images. Yeah, it's a bit of a throwback to work to VEC. I think it's pretty cool how these ideas just come up through the eras and through the different models and so on. And there is seemingly always another layer on top of these ideas. Pretty cool. Yeah. So if you only consider, you know, two views that are coming out of the same image as the positive pair, so to speak, and all the other views are coming out of the different images located in the same mini batch, wouldn't this hurt the representation space to some extent? Let's say you have multiple images of dogs in a mini batch of 4,096 samples. We would essentially want the representations of different dogs to map together as closer as possible in the representation space while representations of cats from dogs would get further away. Wouldn't we expect this? But how does Simclear ensure this rigorously? I guess it's because of the larger batch sizes you use, but I still wanted to know from you. Yeah, one thing is, even if we've got other kinds of images that we want to be close together in the mini batch, even if we've got like a dog image and then another dog image and ultimately we want to learn a representation space where maybe they're not so far apart, like on average, most of the images in the mini batch are things that we want to be really far apart from. So maybe it doesn't hurt that much if we're repelling from everything as opposed to just repelling from images that are part of other classes. I think this actually is something that hurts current self-supervised learning techniques and hurts contrastive techniques because we also know when you do the contrastive loss, if you don't contrast against examples that are very close to you, that actually improves things a little bit. So if you don't contrast against the very hard negatives, we've found that gives you slightly higher accuracy when you do this linear evaluation. That kind of suggests that this really is a problem with these techniques that maybe sometimes you don't want to be as far apart from other images as the losses encouraging you to be. Now there's one other aspect which is that in Simclear, we don't actually use the representation that's feeding into the loss function. Like we have this projection head, an MLP on top of the network, and instead of using that representation at the end of the network, we use a representation that's two layers back. And so by using a representation that's two layers back, even if in the final layer we're pushing things apart, we kind of figure that this earlier representation might not have pushed apart the things that really are semantically similar. And indeed, we find that using this earlier representation in the network leads to higher linear evaluation accuracy. So it works better. I was very fascinated by all of these different tricks that you apparently have to get. And so big kudos to figuring all of this out for the rest of us. There has been a lot of follow-up work on this idea. A lot of modifications. There is this bootstrap your own latent where they completely leave out the negative sampling. Then I think just like one or two weeks ago, there was a paper saying if you build in a stop gradient into the contrastive loss, you also apparently don't need a negative and so on. Do you have maybe from your own work or from work of others, do you have any sort of current? If I were to build a self-supervised contrastive representation learner today, what is the top things I should do? What is my recipe? How do I go about it? The most important part of the recipe is data augmentation. So we're going to use two views from the same image and it's very important how those two views are constructed. But they're really only two super important data augmentations that we need. So we have to take two different crops from the same image and then we have to do some kind of color distortion. So in SimClear we use very aggressive color distortion. So that is probably the most important part of the recipe. Then I guess we feed that representation into a neural network and fortunately we found that you can just use a regular ResNet 50 for this part. You don't have to worry about architecture, engineering, specifically for contrastive learning. Then I think all of the work since SimClear also uses this idea of putting an MLP on top of the end of the network and then using that to get whatever representation goes into the loss function, but then discarding part of the MLP when we later just want the representation for a downstream task. All of those pieces are pieces that are shared by all of these modern self-supervised learning techniques. So like we introduced the idea of this projection head in SimClear and we also spend a lot of time studying the augmentation although we were not the first people to come up with the idea that the augmentation was important. Yeah, in terms of what the loss function is, I guess it's surprising that there are so many things that work that we use this contrastive loss in SimClear because it was what previous work had done and it's like intuitive that you might want to learn a space where you're explicitly pushing away representations of other examples, but I guess like in BYOL they aren't explicitly contrasting against representations of other examples. So instead they have a network where they're taking a moving average of the weights that they've been learning and they try to match the representation that's coming out of the network that they're training to this representation of this moving average network and somehow magically that works and I guess it doesn't even have to be a moving average. I think you were referring to earlier like you can just match the representation of one network to stop gradient of the same network as long as you're matching the representation in an earlier layer and I think like it's still like mysterious why that should work. I don't really have any insight into how either BYOL or the more recent papers actually are learning a representation that doesn't end up collapsing. The problem is if you're trying to match some earlier representation you could just collapse to the point where all of your representations are the same and then like you would trivially be matching the earlier representation, but this doesn't happen and I think why it doesn't happen relates to some mysteries about neural network training dynamics that we still don't entirely understand. I'm absolutely fascinated by this concept of data augmentation. Early on in my neural network career I just imagined it as being a way of increasing the size of your training set, but in a sense you're not really adding new information. You are creating semantically equivalent noise perturbations or examples similar to how BERT works the NLP model it's like a denoising autoencoder and you're creating noise diversions of the same thing and pushing the examples off the manifold. So there seems to be a dichotomy between on the one hand augmenting your data and it's almost like you're stopping the neural network from overfitting on things like the color or some specific feature you don't want to. You want to have a bit of generalization, but at the same time you are saying those things over there it's definitely nothing like that. The data augmentation that you need for contrastive learning is different from the data augmentation that you need for supervised learning because the task is different. When you have contrastive learning you have this problem that if there's just one feature in your data that can be used to do the contrastive task to get images of the same example or views of the same example close together and far apart from views of all the other examples. If you could do that with one feature that would be the only feature the network would ever learn or it might be the only feature the network would ever learn. And so with the augmentation you're making the task harder so that the network actually has to learn many different kinds of features. So I guess we find that this color distortion actually is very important for self-supervised learning, for contrastive learning, whereas it doesn't really matter for supervised learning. And what we think is going on is that if you have two crops from the same image, generally their color histograms are surprisingly similar. If you just plot out the intensity histogram of the image you can see that the crops came from the same image. And that's a trick that the network is very good at doing because I guess if you have ReLU activations they're very good at computing histograms. And so by doing the color distortion we basically we don't let the network just learn the color histograms in order to do the contrastive task. We force the network to actually use other sorts of information and that ends up being like critical to the performance of these contrastive methods. Like it basically doesn't work unless you do that kind of aggressive color distortion. Because that seems to be the key thing then. So you're not telling it to learn things, you're telling it not to learn things. We're telling it to learn one thing. We're telling it to learn figure out which views came from the same image. But then, yeah, we have to make sure that it learns to do that with a diverse set of features instead of just doing it in one way. Because I guess it's like a task that's actually pretty easy to do if you don't have this kind of aggressive augmentation. Yeah, I think in a way it helps the network to also differentiate what actually what is the thing that differentiates two images. I think it helps the network to learn, you know, pick up on that signal. To that end, I also wanted to ask for a custom dataset, if I wanted to, you know, apply a sim clear, what pointers should I take into consideration while designing my augmentation policy? I'm sure you have been asked about this question quite a few times. But yeah, I think it's a good question. Like I think like we actually still don't really know how generalizable these contrastive learning techniques are beyond image net. Like we know they work super well on image net. But like image net is like a boring dataset to apply contrastive learning to because we actually already have all the labels and we could just be doing supervised learning. But I think starting with the crop and color augmentation is definitely a good idea, at least like for datasets that have color, I guess if you don't have color, then maybe think about distorting intensities instead of colors. But beyond that, I think it depends on the specific task and what you really want the neural network to pick up out of the dataset. I feel like there are probably some sorts of data where I wouldn't really expect contrastive learning to work well. So for example, like if you try to do contrastive learning on a dataset of medical images where you've just got healthy patients, and then you want to translate that to like some sort of dataset of people with some kind of pathology, you might never pick up the features that are important for detecting the pathology. But yeah, I think this question of how do you design the augmentation, what augmentation works well for datasets that maybe aren't natural images like these kinds of medical images or maybe like satellite images. That's an important question that we haven't addressed yet. There seems to be this fascinating universality of representations, especially in vision. This is exactly the kind of thing you can test with your wonderful similarity matrix idea. I'm not trying to be flippant when I say this because practitioners have used ImageNet on a variety of downstream tasks. For example, they might use it for classifying circuit boards or something. And the miraculous thing is it just seems to work quite well. So do you think in your opinion that there is some kind of universality? I'm very skeptical about like universality of ImageNet for different tasks. Like in the past, we did some work where we looked at how well ImageNet networks transfer to other tasks. And it seems like there are actually some tasks which are just like datasets of natural images where pre-training an ImageNet doesn't really help at all. And those datasets just seem to be too different from ImageNet. They're things like this Stanford cars dataset where you have to like classify different cars according to their make, model, and year. It turns out even though there are lots of cars in ImageNet, if you pre-train on ImageNet and you fine-tune on that dataset, you will learn to classify it faster in fewer steps than if you had trained from scratch on the Stanford cars dataset. But you won't actually perform any better at the end. And that's true even though the Stanford cars dataset has 10,000 images. So it's tiny compared to ImageNet. So I think like actually representations of images are not that universal. And at least what works for natural images for images like those in ImageNet may not work on other datasets. I think there's also like limited evidence for transfer from ImageNet to medical datasets. It seems if you don't like work really hard at tuning hyperparameters or if you don't train for long enough, you will get better accuracy by starting with an ImageNet pre-trained network. But if you do very thorough experiments and you train for long enough, you try different learning rates and weight decay parameters, like actually it seems like training from scratch on most medical datasets will give you the same accuracy as if you started from a network that's pre-trained on some other giant dataset. Maybe this makes sense because if you think about radiologists, like it's not like a radiologist can just like at the beginning of their education, they can't just look at an MRI or an X-ray image and say this is where the tumor is. It's something that takes them years of training to learn how to do. And so maybe it also makes sense that like our neural networks can't just immediately easily without lots of training pick up on very different image distributions. It does seem to make sense, going a bit from the universality of representations to the universality of augmentation, since this is such a crucial part. Do you think that there is a systematic way how we can discover augmentations? Because it seems right now, it seems to be kind of a whack-a-mole, right? It's okay, we just feed images and it's no, that's too easy. We crop them. Oh no, it's the color histogram. So we like whack on the color and then it works better. But maybe someone finds out oh, there is still this easy feature that the network every now and then pays attention to. So we design a method to whack on that a bit. Do you think there is a systematic way or will this kind of philosophically always rely on us humans having a higher level inside of what we want to do with the dataset? Yeah, so I think actually I'm hopeful that at least for natural images, just like crops and color distortions are enough, because I guess like what we found is you combine those two augmentations and if you do that, like that gets you most of the way to supervised accuracy. So maybe we shouldn't expect huge gains from adding additional augmentations on top of that, even though there are like in the Sinclair paper, we add like Gaussian blur, which gives slight gains on top of that. I guess in the BYL paper, they add even more augmentations on top of that. So you can get small gains, but it seems like the gains are much smaller once you've got the crops and the color distortions there. In terms of systematic ways of discovering what set of augmentations we should be using, I guess there's a paper that I saw where they basically use linear evaluation on the rotation prediction task to see whether the augmentations are good and they claim that actually works for evaluating the augmentations. So maybe that's one way, I don't know. There are all sorts of ways of designing augmentations for supervised learning that could conceivably be applied to the self-supervised learning setting, to the contrastive setting. There are these meta-learning based approaches for learning data augmentation. I'm not sure, those techniques tend to be pretty complicated. I'm not sure whether it's actually easier to deal with those techniques than just like trying a bunch of things, but I think that maybe it doesn't matter that much. Maybe like just, at least if you're dealing with natural images, maybe crop and color distortion is enough. I guess if you think about other images, I don't really have any idea. I guess it depends on what the images look like. There are lots of things that you could be expressing as images like a spectrogram or like some kind of chart or whatever, where you could be applying a neural network to it, but the further you get from natural images, the less clear it is what kind of augmentations you should be working with. It is a fascinating thought though, this universality of augmentations. When you said cropping and color, that made me think it seems to be related to the inductive priors in the CNN architecture that we use and also to things like its regularly sampled, gridded, discrete image data, because we're speaking with Max Welling the other week and as he's created lots of other interesting inductive priors for computer vision models. It does set my mind racing a little bit because presumably there's a continuum. On the one hand, we don't do any augmentation and we just learn from examples. In the middle, we do the augmentation and then maybe in the future, because some people have said that computer vision systems don't have seen understanding. They don't understand physics. The ball might be on the table, but we don't know that it's not falling and so on. There's a lot of missing information. Would the next step be some simulation? Do you know what I mean? Where we impute physics and we impute some world knowledge and then I don't know whether we train a machine learning model from that? Yeah, I think there are definitely shortcomings in our current machine learning models, understandings of the world. There are probably things that we can't just solve by throwing more static images at them. I think maybe the next step, rather than trying to immediately situate the machine learning model in a simulated world, we could just think about video. I think there's already a lot of additional information in video that a neural network could use to learn interesting representations. It seems like if you just see static images, it's hard to learn how to segment objects. It's hard to learn where the object's boundaries are, but once you have video, it's like the stuff that's moving together is an object and you can tell that because it's moving together. I think there's a lot of potential for learning better visual representations and maybe eventually from these kinds of interactions in simulated environments. I think ultimately it becomes a computational headache. Even video is a computational headache because suddenly you've got all of these frames that you have to deal with. You probably want to be thinking about how representations change over time and video data is just huge. It's especially huge if you have to process many frames at once on your accelerators. I think that's why this hasn't taken off yet, but I think probably representation learning from video is going to be a big thing next year or the year after or sometime in the near future. We would love to talk about your big self-supervised models, our strong semi-supervised learners. This is super interesting because you're combining the unsupervised stuff that we've been talking about in Simclear, but now we're in the semi-supervised domain where the label efficiency becomes super important. What's the deal there? Yeah. I guess in Simclear we focus on this question of linear evaluation accuracy. We're just learning a representation without any labels and then training a linear classifier on top of that representation on the same data, but now with all the labels. It turns out that's not really a very practical problem if you have all the labels. There's not necessarily any reason in practice that you would want to first learn this representation and then train the classifier versus just doing standard supervised end-to-end training. What is a practical problem is the situation where you have a lot of unlabeled data and then a very small amount of labeled data. That's the situation that we look at in Simclear v2 in that paper. What we find there is that you can train this network fully unsupervised without using the labels on all the data and then you can fine-tune it on just the subset where you've got the labels. If you do that, it's possible to get very high accuracy, especially if the network is very big. Basically, we find if you have a really big ResNet, if you have ResNet 152 and then you make the layers three times wider, when you do that, you can get accuracy when you fine-tune on 10% of the labels that's substantially better than if you trained ResNet 50 from scratch with all the labels. Once you have that really big network, it turns out you don't have to put the really big network into production. You can take the really big network and you can then distill it back into a standard ResNet 50 and you can retain almost all of the accuracy when you do that. I guess what's important about this distillation process is we're not just going to distill on the labeled dataset. We're going to also use the labels that this giant network, which we fine-tuned on a small subset of the data, we're going to use the labels that it gives on all of our unlabeled data. We're going to use it to generate labels and then we're just going to use those labels to train a much smaller network. If we do that, we get accuracy that's similar to or maybe even slightly better than standard supervised training from scratch. This becomes a highly practically relatable approach toward doing computer vision related things. We see all the times that folks have a huge corpus of unlabeled images, but they only have maybe 5% or 10% labeled images. This immediately becomes a practically applicable recipe for them. I definitely am looking forward to seeing this thing implemented at scale at different companies. That's there. If I understood it correctly, just for the viewers, you folks used a variant of distillation here, which is more popularly referred to as self-training. I don't think there's really a difference between what we call distillation and what other people call self-training. I guess the idea is basically we will pass information into the network. We get its output probabilities and then we train another neural network with those output probabilities as the targets. What I find fascinating is how many ideas come together in this paper. There's first, there's this, let's do representation learning and then we have these just small labels. We find tune and then there's big networks, small networks. Then you label, but you also apply some noise, if I understand correctly, in the process of transferring. Maybe I'm misremembering that, but there's a lot of ideas that come together. Yannick, you probably confused it with noisy student training, where they impose noise during the student training. Sorry, maybe not, but there is a lot of ideas that come together. Something tells me that there was a process behind going, you probably didn't sit down after SimClear1 and be like, all right, what do we do for SimClear2? Okay, let's do this. It tells me there was this process. If you can maybe elaborate a bit on how did you going to build up the system towards the final output? Was there dead ends or was it like, let's build up until we can no longer make it better? How was that? Yeah, I guess there was a bit of a process. After the original SimClear paper, I guess it's clear from the SimClear paper that when we have this bigger network, we get much higher linear evaluation accuracy than we do if we just train SimClear with a ResNet50. Then the question was, is there some way that we can somehow eliminate this dependence on this giant network? Because the giant network is annoying to work with, it's computationally expensive, it's big. We first tried what happens if you distill the unsupervised network. We basically have this task that is set up as a form of cross entropy loss when we're doing the contrast of learning. You can also think about distilling on that task where you have a probability distribution that corresponds to the similarity between an image and all the other images. You could use those kinds of targets to distill. We tried that and that kind of worked. Then we also tried the approach of first fine-tuning the big network and then distilling it. It turned out that worked a lot better. I guess we jumped straight to distillation because we knew that we could get much better results by using a giant network with SimClear. Then once you realize that distillation is going to be important, the only thing you've got to figure out is what kind of distillation should you be doing. What we found was this approach of pre-training, then fine-tuning, then distilling works a lot better than pre-training, then distilling, then fine-tuning. How far down do you think one can go with this final distillation step? Is this something that is conceivably going to be available on, let's say, edge devices at some point, like that our glasses or something run with similar accuracies to these giant networks? Or is it more a factor of four, a factor of 10 kind of stuff? I think there are clearly some limits to distillation. I guess we probably shouldn't expect distillation of the kind that we do in SimClear v2 to work substantially better than supervised distillation, which has been around for quite a while now. I think what's impressive is that in the self-supervised case, in the contrastive case, distillation basically allows you to recover the same accuracy that you would get from training supervised from scratch, whereas without it, the accuracy is a lot worse. It seems like it maybe matters more in this contrastive case, but I think generally when you do distillation in the supervised case, you can get maybe a percentage point gain, maybe a couple of percentage points. I think that's probably about the limit in terms of the improvement that you could get from any kind of distillation-based approach over supervised training from scratch. Fascinating. I don't know if you know that we've been playing with GPT-3 and you said something quite interesting just now. You said that they're deterministic, but in GPT-3, that's not really the case. If you sample from it deterministically, it gets stuck in cycles. You have to do some kind of trickery, some kind of random sampling from this distribution. It might be the case in future computer vision models as well, that we have to randomly sample from them in some way, because otherwise it would get into some pathological behavior. Maybe to do that, we need to have some kind of controller on the top. I suppose my question is in the future, maybe we will be in the stochastic regime. What do you think about that? With GPT-3, you're trying to generate data. When you generate data, there has to be some kind of noise that's coming from somewhere. The process of generating data is like turning noise into data. For image classification, we have the data and we just want to turn it into a label. Maybe there's this implicit notion of stochasticity in that the network gives some output distribution. I think we still want everything to be deterministic if it can be deterministic. We basically want the network to say, this is a dog with probability x. If there's some way to improve it with stochasticity, I don't know. I guess dropout used to be very popular, but it seems like it's not so popular anymore and it doesn't really help us very much with vision models. Also, even dropout is generally only used when we train the neural networks. On the other hand, the brain is very stochastic. The brain has lots of noise. I guess that suggests that maybe there's some way to leverage noise to learn better representations in neural networks as well and we just don't quite know the right way yet. That's right. Max Welling said to us that he thinks that the future of AI will have a generative component. He thinks that we have the matrix in our minds. We have these simulations going on all the time and we're generating new scenarios. It's related to the data augmentation thing as well. Some people have said to me in the past that using a GAN might be a way of doing data augmentation. Presumably, that would require some kind of stochastic sampling as well. I suppose it's just quite interesting to see where these two things might meet in the middle at some point. Max Yeah. I don't know. I guess like with a GAN, using a GAN to do data augmentation, you have this problem that you still don't actually have more data. You have a GAN that's trained on the same data. It might help you because your way of encoding inductive bias into the GAN is different from your way of encoding inductive bias into the neural network. Maybe by having more inductive bias, you can learn a better function. You still don't have more data at it. Without having more data, there's no reason to expect a priority that you will be able to learn a better function. Paul I'm so glad you said that. It was always my intuition. The amount of people that have said to me that you should use a GAN for data augmentation. Anyway. Max What's the first thing you think about if you're like, oh, what could I use a GAN for? And then you learn about data, and they're like, wait, this is so much more data. Yeah, but conceptually, yes, you don't have more data. And ironically, when you do the simple data augmentation, you do have more data because you put all the knowledge in there as a human of what makes two images dissimilar visually, but still equivalent semantically, which again, is exactly the opposite. It gives you images that are visually similar, but it has no intuition of what the semantic similarity is. For my last question, I actually want to switch topics just a little bit to what Tim said at the beginning, namely your love of Julia. So I have seen a number of especially data scientists be strong advocates for Julia as a language and so on. Do you want to give anyone sort of the pitch? Why should we even consider this? Yeah, so I think Julia is a much better programming language than Python in many ways. I guess one thing and I guess the thing that first attracted me to Julia is that it's really fast, like you can write Julia code and with very little work, you will end up running as fast as equivalent C code. So that's something that you can't get out of standard Python code. If you're just writing a for loop in Python, it's going to be super slow. But in Julia, you don't have to worry about all of that. And you don't have to worry about like Cython or number all of this other stuff that people have hacked on top of Python. Julia is just designed to be fast and it works. I think there are other advantages to Julia as a language beyond that. I guess it's built on this idea of generic functions where you have a function that can take multiple types and you can define the function differently for the different types. And this is something that we do all the time when we're doing like machine learning, like we have matrix multiplication, which is a different form of multiplication that takes matrices and produces something. And I guess like in Python, it's so it used to be that you had to type dot dot to multiply things, but now it's like they have this add symbol that does matrix multiplication. But Julia is designed for these situations where maybe beyond just matrices, you have these funny types of structured matrices, you have sparse matrices, and you can define special methods for the product of a sparse matrix and a vector or all sorts of things where you might want different methods depending on the types. And even though it seems like this is complicated and you might have some trouble picking which version of the function is going to be called at runtime, because Julia is ultimately compiling everything when you call it. And because it has this kind of strong type system, it can ultimately pick which method is going to be used and compile that method call in and you don't have to worry about picking which one. And so it still ends up being fast. I also think like there's this question of whether like the object oriented Python or the object oriented paradigm and Python is really like the best paradigm for machine learning. Because I guess like it's like we have data and then we have functions that operate on the data. But in the object oriented paradigm, you want the functions that operate on the data to be attached to the data, which is like a weird way of setting things up. And that Julia is not set up that way. You have these data structures. And then because you are able to create functions that specialize on the data structures, you don't have to worry about attaching those functions to the data structures themselves. Amazing. Dr. Simon Cornblith. Thank you very much for joining us this evening. It's been an absolute pleasure. Thanks for having me. Thank you. I really hope you've enjoyed the show today. We've had so much fun making it. Remember to like, comment, and subscribe. We love reading your comments, every single one of them. And we'll see you back next week.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 14.6, "text": " Welcome back. Today we're talking with Dr Simon Cornblith, a research scientist in the", "tokens": [50364, 4027, 646, 13, 2692, 321, 434, 1417, 365, 2491, 13193, 21590, 5199, 355, 11, 257, 2132, 12662, 294, 264, 51094], "temperature": 0.0, "avg_logprob": -0.18494682312011718, "compression_ratio": 1.4756756756756757, "no_speech_prob": 0.021231576800346375}, {"id": 1, "seek": 0, "start": 14.6, "end": 20.64, "text": " Google Brain team. Simon is most famous for being one of the authors on Simclear, the computer", "tokens": [51094, 3329, 29783, 1469, 13, 13193, 307, 881, 4618, 337, 885, 472, 295, 264, 16552, 322, 3998, 43679, 11, 264, 3820, 51396], "temperature": 0.0, "avg_logprob": -0.18494682312011718, "compression_ratio": 1.4756756756756757, "no_speech_prob": 0.021231576800346375}, {"id": 2, "seek": 0, "start": 20.64, "end": 25.36, "text": " vision paper that used self-supervised learning and the contrastive loss with loads of cool", "tokens": [51396, 5201, 3035, 300, 1143, 2698, 12, 48172, 24420, 2539, 293, 264, 8712, 488, 4470, 365, 12668, 295, 1627, 51632], "temperature": 0.0, "avg_logprob": -0.18494682312011718, "compression_ratio": 1.4756756756756757, "no_speech_prob": 0.021231576800346375}, {"id": 3, "seek": 2536, "start": 25.36, "end": 30.759999999999998, "text": " image augmentations. Simon also used to be a neuroscientist.", "tokens": [50364, 3256, 29919, 763, 13, 13193, 611, 1143, 281, 312, 257, 28813, 5412, 468, 13, 50634], "temperature": 0.0, "avg_logprob": -0.145089460455853, "compression_ratio": 1.6639004149377594, "no_speech_prob": 0.048809126019477844}, {"id": 4, "seek": 2536, "start": 30.759999999999998, "end": 35.92, "text": " When I was pretty young, I was interested in consciousness and how we create this kind", "tokens": [50634, 1133, 286, 390, 1238, 2037, 11, 286, 390, 3102, 294, 10081, 293, 577, 321, 1884, 341, 733, 50892], "temperature": 0.0, "avg_logprob": -0.145089460455853, "compression_ratio": 1.6639004149377594, "no_speech_prob": 0.048809126019477844}, {"id": 5, "seek": 2536, "start": 35.92, "end": 41.64, "text": " of impression of the external world inside our heads. And so I guess it's pretty obvious", "tokens": [50892, 295, 9995, 295, 264, 8320, 1002, 1854, 527, 8050, 13, 400, 370, 286, 2041, 309, 311, 1238, 6322, 51178], "temperature": 0.0, "avg_logprob": -0.145089460455853, "compression_ratio": 1.6639004149377594, "no_speech_prob": 0.048809126019477844}, {"id": 6, "seek": 2536, "start": 41.64, "end": 46.56, "text": " how that translates into an interest in brains and how the brain works.", "tokens": [51178, 577, 300, 28468, 666, 364, 1179, 294, 15442, 293, 577, 264, 3567, 1985, 13, 51424], "temperature": 0.0, "avg_logprob": -0.145089460455853, "compression_ratio": 1.6639004149377594, "no_speech_prob": 0.048809126019477844}, {"id": 7, "seek": 2536, "start": 46.56, "end": 52.239999999999995, "text": " Turns out the neuroscience is really difficult. Progress is really slow and tedious. Simon's", "tokens": [51424, 29524, 484, 264, 42762, 307, 534, 2252, 13, 32587, 307, 534, 2964, 293, 38284, 13, 13193, 311, 51708], "temperature": 0.0, "avg_logprob": -0.145089460455853, "compression_ratio": 1.6639004149377594, "no_speech_prob": 0.048809126019477844}, {"id": 8, "seek": 5224, "start": 52.32, "end": 58.160000000000004, "text": " goal is to understand the inner workings of neural networks, both in meat space and", "tokens": [50368, 3387, 307, 281, 1223, 264, 7284, 589, 1109, 295, 18161, 9590, 11, 1293, 294, 4615, 1901, 293, 50660], "temperature": 0.0, "avg_logprob": -0.14594297938876682, "compression_ratio": 1.7453874538745386, "no_speech_prob": 0.011668931692838669}, {"id": 9, "seek": 5224, "start": 58.160000000000004, "end": 65.64, "text": " in silicon. He initially thought that the artificial variety might be easier to understand.", "tokens": [50660, 294, 22848, 13, 634, 9105, 1194, 300, 264, 11677, 5673, 1062, 312, 3571, 281, 1223, 13, 51034], "temperature": 0.0, "avg_logprob": -0.14594297938876682, "compression_ratio": 1.7453874538745386, "no_speech_prob": 0.011668931692838669}, {"id": 10, "seek": 5224, "start": 65.64, "end": 67.36, "text": " He was in for a rude awakening.", "tokens": [51034, 634, 390, 294, 337, 257, 18895, 31550, 13, 51120], "temperature": 0.0, "avg_logprob": -0.14594297938876682, "compression_ratio": 1.7453874538745386, "no_speech_prob": 0.011668931692838669}, {"id": 11, "seek": 5224, "start": 67.36, "end": 71.2, "text": " So in a neural network, we can record all the neurons, which is extremely challenging", "tokens": [51120, 407, 294, 257, 18161, 3209, 11, 321, 393, 2136, 439, 264, 22027, 11, 597, 307, 4664, 7595, 51312], "temperature": 0.0, "avg_logprob": -0.14594297938876682, "compression_ratio": 1.7453874538745386, "no_speech_prob": 0.011668931692838669}, {"id": 12, "seek": 5224, "start": 71.2, "end": 77.16, "text": " in a biological organism. And we can also manipulate the system in any kind of way that", "tokens": [51312, 294, 257, 13910, 24128, 13, 400, 321, 393, 611, 20459, 264, 1185, 294, 604, 733, 295, 636, 300, 51610], "temperature": 0.0, "avg_logprob": -0.14594297938876682, "compression_ratio": 1.7453874538745386, "no_speech_prob": 0.011668931692838669}, {"id": 13, "seek": 5224, "start": 77.16, "end": 82.08, "text": " we can imagine. But it still seems really hard to understand neural networks. I think there", "tokens": [51610, 321, 393, 3811, 13, 583, 309, 920, 2544, 534, 1152, 281, 1223, 18161, 9590, 13, 286, 519, 456, 51856], "temperature": 0.0, "avg_logprob": -0.14594297938876682, "compression_ratio": 1.7453874538745386, "no_speech_prob": 0.011668931692838669}, {"id": 14, "seek": 8208, "start": 82.08, "end": 88.8, "text": " are a lot of ideas from machine learning that will ultimately help us understand brains.", "tokens": [50364, 366, 257, 688, 295, 3487, 490, 3479, 2539, 300, 486, 6284, 854, 505, 1223, 15442, 13, 50700], "temperature": 0.0, "avg_logprob": -0.12075234241172915, "compression_ratio": 1.7796610169491525, "no_speech_prob": 0.00034593231976032257}, {"id": 15, "seek": 8208, "start": 88.8, "end": 93.92, "text": " Maybe we could make some headway that might eventually translate back to brains. And so", "tokens": [50700, 2704, 321, 727, 652, 512, 1378, 676, 300, 1062, 4728, 13799, 646, 281, 15442, 13, 400, 370, 50956], "temperature": 0.0, "avg_logprob": -0.12075234241172915, "compression_ratio": 1.7796610169491525, "no_speech_prob": 0.00034593231976032257}, {"id": 16, "seek": 8208, "start": 93.92, "end": 95.8, "text": " that's how I ended up in machine learning.", "tokens": [50956, 300, 311, 577, 286, 4590, 493, 294, 3479, 2539, 13, 51050], "temperature": 0.0, "avg_logprob": -0.12075234241172915, "compression_ratio": 1.7796610169491525, "no_speech_prob": 0.00034593231976032257}, {"id": 17, "seek": 8208, "start": 95.8, "end": 99.36, "text": " People often try and anthropomorphise neural networks.", "tokens": [51050, 3432, 2049, 853, 293, 22727, 32702, 908, 18161, 9590, 13, 51228], "temperature": 0.0, "avg_logprob": -0.12075234241172915, "compression_ratio": 1.7796610169491525, "no_speech_prob": 0.00034593231976032257}, {"id": 18, "seek": 8208, "start": 99.36, "end": 103.72, "text": " People try to relate whatever neural network they've built back to a brain and they say", "tokens": [51228, 3432, 853, 281, 10961, 2035, 18161, 3209, 436, 600, 3094, 646, 281, 257, 3567, 293, 436, 584, 51446], "temperature": 0.0, "avg_logprob": -0.12075234241172915, "compression_ratio": 1.7796610169491525, "no_speech_prob": 0.00034593231976032257}, {"id": 19, "seek": 8208, "start": 103.72, "end": 106.8, "text": " that it works like the brain, but it doesn't work like the brain.", "tokens": [51446, 300, 309, 1985, 411, 264, 3567, 11, 457, 309, 1177, 380, 589, 411, 264, 3567, 13, 51600], "temperature": 0.0, "avg_logprob": -0.12075234241172915, "compression_ratio": 1.7796610169491525, "no_speech_prob": 0.00034593231976032257}, {"id": 20, "seek": 8208, "start": 106.8, "end": 111.78, "text": " So Simon was involved in this paper, do wide and deep networks learn the same things, uncovering", "tokens": [51600, 407, 13193, 390, 3288, 294, 341, 3035, 11, 360, 4874, 293, 2452, 9590, 1466, 264, 912, 721, 11, 21694, 278, 51849], "temperature": 0.0, "avg_logprob": -0.12075234241172915, "compression_ratio": 1.7796610169491525, "no_speech_prob": 0.00034593231976032257}, {"id": 21, "seek": 11178, "start": 111.78, "end": 115.46000000000001, "text": " how neural network representations vary with width and depth.", "tokens": [50364, 577, 18161, 3209, 33358, 10559, 365, 11402, 293, 7161, 13, 50548], "temperature": 0.0, "avg_logprob": -0.13714405798142956, "compression_ratio": 1.8266129032258065, "no_speech_prob": 0.0039062323048710823}, {"id": 22, "seek": 11178, "start": 115.46000000000001, "end": 121.3, "text": " Simon pioneered this really fascinating way of comparing representations by comparing", "tokens": [50548, 13193, 19761, 4073, 341, 534, 10343, 636, 295, 15763, 33358, 538, 15763, 50840], "temperature": 0.0, "avg_logprob": -0.13714405798142956, "compression_ratio": 1.8266129032258065, "no_speech_prob": 0.0039062323048710823}, {"id": 23, "seek": 11178, "start": 121.3, "end": 126.82000000000001, "text": " features. And what this essentially amounts to is we need to have a similarity function", "tokens": [50840, 4122, 13, 400, 437, 341, 4476, 11663, 281, 307, 321, 643, 281, 362, 257, 32194, 2445, 51116], "temperature": 0.0, "avg_logprob": -0.13714405798142956, "compression_ratio": 1.8266129032258065, "no_speech_prob": 0.0039062323048710823}, {"id": 24, "seek": 11178, "start": 126.82000000000001, "end": 133.42000000000002, "text": " so that we can compare the representations in layers to themselves in different parts", "tokens": [51116, 370, 300, 321, 393, 6794, 264, 33358, 294, 7914, 281, 2969, 294, 819, 3166, 51446], "temperature": 0.0, "avg_logprob": -0.13714405798142956, "compression_ratio": 1.8266129032258065, "no_speech_prob": 0.0039062323048710823}, {"id": 25, "seek": 11178, "start": 133.42000000000002, "end": 135.78, "text": " of the network or indeed to other networks.", "tokens": [51446, 295, 264, 3209, 420, 6451, 281, 661, 9590, 13, 51564], "temperature": 0.0, "avg_logprob": -0.13714405798142956, "compression_ratio": 1.8266129032258065, "no_speech_prob": 0.0039062323048710823}, {"id": 26, "seek": 11178, "start": 135.78, "end": 139.54, "text": " And so for this similarity measure to work well, the first thing Simon did was take two", "tokens": [51564, 400, 370, 337, 341, 32194, 3481, 281, 589, 731, 11, 264, 700, 551, 13193, 630, 390, 747, 732, 51752], "temperature": 0.0, "avg_logprob": -0.13714405798142956, "compression_ratio": 1.8266129032258065, "no_speech_prob": 0.0039062323048710823}, {"id": 27, "seek": 13954, "start": 139.54, "end": 144.57999999999998, "text": " architecturally identical networks, A and B, trained from different random initialisations", "tokens": [50364, 6331, 6512, 14800, 9590, 11, 316, 293, 363, 11, 8895, 490, 819, 4974, 5883, 47791, 50616], "temperature": 0.0, "avg_logprob": -0.15145785868668757, "compression_ratio": 1.6513157894736843, "no_speech_prob": 0.01575998216867447}, {"id": 28, "seek": 13954, "start": 144.57999999999998, "end": 152.18, "text": " and just ensure that the third convolution layer is more self-similar to its counterpart", "tokens": [50616, 293, 445, 5586, 300, 264, 2636, 45216, 4583, 307, 544, 2698, 12, 30937, 2202, 281, 1080, 22335, 50996], "temperature": 0.0, "avg_logprob": -0.15145785868668757, "compression_ratio": 1.6513157894736843, "no_speech_prob": 0.01575998216867447}, {"id": 29, "seek": 13954, "start": 152.18, "end": 154.45999999999998, "text": " than any of the other layers.", "tokens": [50996, 813, 604, 295, 264, 661, 7914, 13, 51110], "temperature": 0.0, "avg_logprob": -0.15145785868668757, "compression_ratio": 1.6513157894736843, "no_speech_prob": 0.01575998216867447}, {"id": 30, "seek": 13954, "start": 154.45999999999998, "end": 158.42, "text": " If that works, then you're onto something. Turns out that's not super simple to do, but", "tokens": [51110, 759, 300, 1985, 11, 550, 291, 434, 3911, 746, 13, 29524, 484, 300, 311, 406, 1687, 2199, 281, 360, 11, 457, 51308], "temperature": 0.0, "avg_logprob": -0.15145785868668757, "compression_ratio": 1.6513157894736843, "no_speech_prob": 0.01575998216867447}, {"id": 31, "seek": 13954, "start": 158.42, "end": 161.73999999999998, "text": " Simon came up with this concept called the centred kernel alignment, which we'll talk", "tokens": [51308, 13193, 1361, 493, 365, 341, 3410, 1219, 264, 1489, 986, 28256, 18515, 11, 597, 321, 603, 751, 51474], "temperature": 0.0, "avg_logprob": -0.15145785868668757, "compression_ratio": 1.6513157894736843, "no_speech_prob": 0.01575998216867447}, {"id": 32, "seek": 13954, "start": 161.73999999999998, "end": 163.18, "text": " about on the call.", "tokens": [51474, 466, 322, 264, 818, 13, 51546], "temperature": 0.0, "avg_logprob": -0.15145785868668757, "compression_ratio": 1.6513157894736843, "no_speech_prob": 0.01575998216867447}, {"id": 33, "seek": 13954, "start": 163.18, "end": 169.29999999999998, "text": " But this is actually super fascinating. We're talking about this idea here of using self-similarity", "tokens": [51546, 583, 341, 307, 767, 1687, 10343, 13, 492, 434, 1417, 466, 341, 1558, 510, 295, 1228, 2698, 12, 30937, 2202, 507, 51852], "temperature": 0.0, "avg_logprob": -0.15145785868668757, "compression_ratio": 1.6513157894736843, "no_speech_prob": 0.01575998216867447}, {"id": 34, "seek": 16930, "start": 169.3, "end": 175.02, "text": " to reason about the evolution of representations throughout successive layers in the neural", "tokens": [50364, 281, 1778, 466, 264, 9303, 295, 33358, 3710, 48043, 7914, 294, 264, 18161, 50650], "temperature": 0.0, "avg_logprob": -0.13157565697379733, "compression_ratio": 1.8059071729957805, "no_speech_prob": 0.007790988776832819}, {"id": 35, "seek": 16930, "start": 175.02, "end": 180.94, "text": " network. And what Simon found is that you get this kind of characteristic blockiness.", "tokens": [50650, 3209, 13, 400, 437, 13193, 1352, 307, 300, 291, 483, 341, 733, 295, 16282, 3461, 1324, 13, 50946], "temperature": 0.0, "avg_logprob": -0.13157565697379733, "compression_ratio": 1.8059071729957805, "no_speech_prob": 0.007790988776832819}, {"id": 36, "seek": 16930, "start": 180.94, "end": 186.38000000000002, "text": " So when you see these large blocks, what it means is that the representations are no longer", "tokens": [50946, 407, 562, 291, 536, 613, 2416, 8474, 11, 437, 309, 1355, 307, 300, 264, 33358, 366, 572, 2854, 51218], "temperature": 0.0, "avg_logprob": -0.13157565697379733, "compression_ratio": 1.8059071729957805, "no_speech_prob": 0.007790988776832819}, {"id": 37, "seek": 16930, "start": 186.38000000000002, "end": 188.46, "text": " evolving in respect of time.", "tokens": [51218, 21085, 294, 3104, 295, 565, 13, 51322], "temperature": 0.0, "avg_logprob": -0.13157565697379733, "compression_ratio": 1.8059071729957805, "no_speech_prob": 0.007790988776832819}, {"id": 38, "seek": 16930, "start": 188.46, "end": 193.94, "text": " So it's showing here the representational similarity of all of the layers against themselves", "tokens": [51322, 407, 309, 311, 4099, 510, 264, 2906, 1478, 32194, 295, 439, 295, 264, 7914, 1970, 2969, 51596], "temperature": 0.0, "avg_logprob": -0.13157565697379733, "compression_ratio": 1.8059071729957805, "no_speech_prob": 0.007790988776832819}, {"id": 39, "seek": 16930, "start": 193.94, "end": 196.14000000000001, "text": " and against all of the other layers.", "tokens": [51596, 293, 1970, 439, 295, 264, 661, 7914, 13, 51706], "temperature": 0.0, "avg_logprob": -0.13157565697379733, "compression_ratio": 1.8059071729957805, "no_speech_prob": 0.007790988776832819}, {"id": 40, "seek": 19614, "start": 196.14, "end": 200.26, "text": " So clearly there's this characteristic diagonal down the matrix, as you would see with any", "tokens": [50364, 407, 4448, 456, 311, 341, 16282, 21539, 760, 264, 8141, 11, 382, 291, 576, 536, 365, 604, 50570], "temperature": 0.0, "avg_logprob": -0.10220269989549068, "compression_ratio": 1.7, "no_speech_prob": 0.001519087702035904}, {"id": 41, "seek": 19614, "start": 200.26, "end": 202.26, "text": " self-similarity matrix.", "tokens": [50570, 2698, 12, 30937, 2202, 507, 8141, 13, 50670], "temperature": 0.0, "avg_logprob": -0.10220269989549068, "compression_ratio": 1.7, "no_speech_prob": 0.001519087702035904}, {"id": 42, "seek": 19614, "start": 202.26, "end": 207.7, "text": " And because this blockiness appears, it means that nothing is happening.", "tokens": [50670, 400, 570, 341, 3461, 1324, 7038, 11, 309, 1355, 300, 1825, 307, 2737, 13, 50942], "temperature": 0.0, "avg_logprob": -0.10220269989549068, "compression_ratio": 1.7, "no_speech_prob": 0.001519087702035904}, {"id": 43, "seek": 19614, "start": 207.7, "end": 211.61999999999998, "text": " And what Simon realised is you can actually delete these layers from the neural network", "tokens": [50942, 400, 437, 13193, 21337, 307, 291, 393, 767, 12097, 613, 7914, 490, 264, 18161, 3209, 51138], "temperature": 0.0, "avg_logprob": -0.10220269989549068, "compression_ratio": 1.7, "no_speech_prob": 0.001519087702035904}, {"id": 44, "seek": 19614, "start": 211.61999999999998, "end": 215.1, "text": " and it wouldn't make any difference because it hasn't learned anything new.", "tokens": [51138, 293, 309, 2759, 380, 652, 604, 2649, 570, 309, 6132, 380, 3264, 1340, 777, 13, 51312], "temperature": 0.0, "avg_logprob": -0.10220269989549068, "compression_ratio": 1.7, "no_speech_prob": 0.001519087702035904}, {"id": 45, "seek": 19614, "start": 215.1, "end": 219.89999999999998, "text": " But it's also a really interesting way of reasoning about a kind of pathology, a weird", "tokens": [51312, 583, 309, 311, 611, 257, 534, 1880, 636, 295, 21577, 466, 257, 733, 295, 3100, 1793, 11, 257, 3657, 51552], "temperature": 0.0, "avg_logprob": -0.10220269989549068, "compression_ratio": 1.7, "no_speech_prob": 0.001519087702035904}, {"id": 46, "seek": 19614, "start": 219.89999999999998, "end": 223.06, "text": " thing that happens when you saturate a neural network.", "tokens": [51552, 551, 300, 2314, 562, 291, 21160, 473, 257, 18161, 3209, 13, 51710], "temperature": 0.0, "avg_logprob": -0.10220269989549068, "compression_ratio": 1.7, "no_speech_prob": 0.001519087702035904}, {"id": 47, "seek": 22306, "start": 223.06, "end": 227.1, "text": " So he said that this presence of this block structure is an indicator of the halting of", "tokens": [50364, 407, 415, 848, 300, 341, 6814, 295, 341, 3461, 3877, 307, 364, 16961, 295, 264, 7523, 783, 295, 50566], "temperature": 0.0, "avg_logprob": -0.12492187744980558, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.011135652661323547}, {"id": 48, "seek": 22306, "start": 227.1, "end": 231.42000000000002, "text": " evolution and a strong indicator of over-parameterisation.", "tokens": [50566, 9303, 293, 257, 2068, 16961, 295, 670, 12, 2181, 335, 2398, 7623, 13, 50782], "temperature": 0.0, "avg_logprob": -0.12492187744980558, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.011135652661323547}, {"id": 49, "seek": 22306, "start": 231.42000000000002, "end": 236.02, "text": " And he actually shows that this blockiness appears on deeper networks and wider networks.", "tokens": [50782, 400, 415, 767, 3110, 300, 341, 3461, 1324, 7038, 322, 7731, 9590, 293, 11842, 9590, 13, 51012], "temperature": 0.0, "avg_logprob": -0.12492187744980558, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.011135652661323547}, {"id": 50, "seek": 22306, "start": 236.02, "end": 239.22, "text": " But this concept of self-similarity analysis is not new to me.", "tokens": [51012, 583, 341, 3410, 295, 2698, 12, 30937, 2202, 507, 5215, 307, 406, 777, 281, 385, 13, 51172], "temperature": 0.0, "avg_logprob": -0.12492187744980558, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.011135652661323547}, {"id": 51, "seek": 22306, "start": 239.22, "end": 246.06, "text": " On my PhD, I was fascinated in segmenting DJ-mixed music shows and I actually used the same techniques", "tokens": [51172, 1282, 452, 14476, 11, 286, 390, 24597, 294, 9469, 278, 13078, 12, 76, 40303, 1318, 3110, 293, 286, 767, 1143, 264, 912, 7512, 51514], "temperature": 0.0, "avg_logprob": -0.12492187744980558, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.011135652661323547}, {"id": 52, "seek": 22306, "start": 246.06, "end": 250.26, "text": " for learning regimes in financial datasets later on.", "tokens": [51514, 337, 2539, 45738, 294, 4669, 42856, 1780, 322, 13, 51724], "temperature": 0.0, "avg_logprob": -0.12492187744980558, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.011135652661323547}, {"id": 53, "seek": 25026, "start": 250.62, "end": 253.89999999999998, "text": " This is an example of a DJ-mix which I segmented.", "tokens": [50382, 639, 307, 364, 1365, 295, 257, 13078, 12, 76, 970, 597, 286, 9469, 292, 13, 50546], "temperature": 0.0, "avg_logprob": -0.1383593292236328, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.2599563002586365}, {"id": 54, "seek": 25026, "start": 253.89999999999998, "end": 259.26, "text": " I came up with a dynamic programming algorithm which would essentially sum up all of the", "tokens": [50546, 286, 1361, 493, 365, 257, 8546, 9410, 9284, 597, 576, 4476, 2408, 493, 439, 295, 264, 50814], "temperature": 0.0, "avg_logprob": -0.1383593292236328, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.2599563002586365}, {"id": 55, "seek": 25026, "start": 259.26, "end": 265.26, "text": " tiles along this diagonal and compute the lowest costs contiguous segmentation.", "tokens": [50814, 21982, 2051, 341, 21539, 293, 14722, 264, 12437, 5497, 660, 30525, 9469, 399, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1383593292236328, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.2599563002586365}, {"id": 56, "seek": 25026, "start": 265.26, "end": 266.58, "text": " And it's super interesting.", "tokens": [51114, 400, 309, 311, 1687, 1880, 13, 51180], "temperature": 0.0, "avg_logprob": -0.1383593292236328, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.2599563002586365}, {"id": 57, "seek": 25026, "start": 266.58, "end": 271.26, "text": " So here are two music tracks and you can see that they are more self-similar to each other", "tokens": [51180, 407, 510, 366, 732, 1318, 10218, 293, 291, 393, 536, 300, 436, 366, 544, 2698, 12, 30937, 2202, 281, 1184, 661, 51414], "temperature": 0.0, "avg_logprob": -0.1383593292236328, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.2599563002586365}, {"id": 58, "seek": 25026, "start": 271.26, "end": 275.82, "text": " than they are any of the other tracks just because of the tone of the colour here.", "tokens": [51414, 813, 436, 366, 604, 295, 264, 661, 10218, 445, 570, 295, 264, 8027, 295, 264, 8267, 510, 13, 51642], "temperature": 0.0, "avg_logprob": -0.1383593292236328, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.2599563002586365}, {"id": 59, "seek": 25026, "start": 275.82, "end": 279.7, "text": " And if you zoom into a track, you can even see that there are symmetries.", "tokens": [51642, 400, 498, 291, 8863, 666, 257, 2837, 11, 291, 393, 754, 536, 300, 456, 366, 14232, 302, 2244, 13, 51836], "temperature": 0.0, "avg_logprob": -0.1383593292236328, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.2599563002586365}, {"id": 60, "seek": 27970, "start": 279.7, "end": 284.42, "text": " This part of the track here is a repetition from this part of the track here.", "tokens": [50364, 639, 644, 295, 264, 2837, 510, 307, 257, 30432, 490, 341, 644, 295, 264, 2837, 510, 13, 50600], "temperature": 0.0, "avg_logprob": -0.10880773642967487, "compression_ratio": 1.8250950570342206, "no_speech_prob": 0.006158623844385147}, {"id": 61, "seek": 27970, "start": 284.42, "end": 289.42, "text": " And you can tell that from this kind of symmetry pattern on the diagonal.", "tokens": [50600, 400, 291, 393, 980, 300, 490, 341, 733, 295, 25440, 5102, 322, 264, 21539, 13, 50850], "temperature": 0.0, "avg_logprob": -0.10880773642967487, "compression_ratio": 1.8250950570342206, "no_speech_prob": 0.006158623844385147}, {"id": 62, "seek": 27970, "start": 289.42, "end": 292.78, "text": " And you can see that there's a little bit in the track in the middle here which is not", "tokens": [50850, 400, 291, 393, 536, 300, 456, 311, 257, 707, 857, 294, 264, 2837, 294, 264, 2808, 510, 597, 307, 406, 51018], "temperature": 0.0, "avg_logprob": -0.10880773642967487, "compression_ratio": 1.8250950570342206, "no_speech_prob": 0.006158623844385147}, {"id": 63, "seek": 27970, "start": 292.78, "end": 295.74, "text": " similar to any other part of the track.", "tokens": [51018, 2531, 281, 604, 661, 644, 295, 264, 2837, 13, 51166], "temperature": 0.0, "avg_logprob": -0.10880773642967487, "compression_ratio": 1.8250950570342206, "no_speech_prob": 0.006158623844385147}, {"id": 64, "seek": 27970, "start": 295.74, "end": 300.65999999999997, "text": " You see some really interesting stuff here and essentially I'm a huge fan of anyone using", "tokens": [51166, 509, 536, 512, 534, 1880, 1507, 510, 293, 4476, 286, 478, 257, 2603, 3429, 295, 2878, 1228, 51412], "temperature": 0.0, "avg_logprob": -0.10880773642967487, "compression_ratio": 1.8250950570342206, "no_speech_prob": 0.006158623844385147}, {"id": 65, "seek": 27970, "start": 300.65999999999997, "end": 305.41999999999996, "text": " self-similarity matrices for reasoning about the evolution of representations.", "tokens": [51412, 2698, 12, 30937, 2202, 507, 32284, 337, 21577, 466, 264, 9303, 295, 33358, 13, 51650], "temperature": 0.0, "avg_logprob": -0.10880773642967487, "compression_ratio": 1.8250950570342206, "no_speech_prob": 0.006158623844385147}, {"id": 66, "seek": 27970, "start": 305.41999999999996, "end": 307.14, "text": " I think it's a fascinating idea.", "tokens": [51650, 286, 519, 309, 311, 257, 10343, 1558, 13, 51736], "temperature": 0.0, "avg_logprob": -0.10880773642967487, "compression_ratio": 1.8250950570342206, "no_speech_prob": 0.006158623844385147}, {"id": 67, "seek": 30714, "start": 307.14, "end": 309.97999999999996, "text": " So how did Simon come up with this measure of similarity?", "tokens": [50364, 407, 577, 630, 13193, 808, 493, 365, 341, 3481, 295, 32194, 30, 50506], "temperature": 0.0, "avg_logprob": -0.16048398792234242, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0008557505789212883}, {"id": 68, "seek": 30714, "start": 309.97999999999996, "end": 312.58, "text": " The centred kernel alignment.", "tokens": [50506, 440, 1489, 986, 28256, 18515, 13, 50636], "temperature": 0.0, "avg_logprob": -0.16048398792234242, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0008557505789212883}, {"id": 69, "seek": 30714, "start": 312.58, "end": 317.9, "text": " Jeff Hinton had another idea and I tried the idea that it worked but then we wondered is", "tokens": [50636, 7506, 389, 12442, 632, 1071, 1558, 293, 286, 3031, 264, 1558, 300, 309, 2732, 457, 550, 321, 17055, 307, 50902], "temperature": 0.0, "avg_logprob": -0.16048398792234242, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0008557505789212883}, {"id": 70, "seek": 30714, "start": 317.9, "end": 320.53999999999996, "text": " there a simpler thing that worked.", "tokens": [50902, 456, 257, 18587, 551, 300, 2732, 13, 51034], "temperature": 0.0, "avg_logprob": -0.16048398792234242, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0008557505789212883}, {"id": 71, "seek": 30714, "start": 320.53999999999996, "end": 323.14, "text": " And that's how we ended up with centred kernel alignment.", "tokens": [51034, 400, 300, 311, 577, 321, 4590, 493, 365, 1489, 986, 28256, 18515, 13, 51164], "temperature": 0.0, "avg_logprob": -0.16048398792234242, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0008557505789212883}, {"id": 72, "seek": 30714, "start": 323.14, "end": 327.94, "text": " The blockiness in these matrices is absolutely fascinating but how much can we read into", "tokens": [51164, 440, 3461, 1324, 294, 613, 32284, 307, 3122, 10343, 457, 577, 709, 393, 321, 1401, 666, 51404], "temperature": 0.0, "avg_logprob": -0.16048398792234242, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0008557505789212883}, {"id": 73, "seek": 30714, "start": 327.94, "end": 328.94, "text": " it?", "tokens": [51404, 309, 30, 51454], "temperature": 0.0, "avg_logprob": -0.16048398792234242, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0008557505789212883}, {"id": 74, "seek": 30714, "start": 328.94, "end": 333.46, "text": " It's not clear what we should really expect in terms of how a neural network representation", "tokens": [51454, 467, 311, 406, 1850, 437, 321, 820, 534, 2066, 294, 2115, 295, 577, 257, 18161, 3209, 10290, 51680], "temperature": 0.0, "avg_logprob": -0.16048398792234242, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0008557505789212883}, {"id": 75, "seek": 30714, "start": 333.46, "end": 335.06, "text": " evolves through the layers.", "tokens": [51680, 43737, 807, 264, 7914, 13, 51760], "temperature": 0.0, "avg_logprob": -0.16048398792234242, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0008557505789212883}, {"id": 76, "seek": 33506, "start": 335.06, "end": 340.26, "text": " I think there's kind of some theory on what we should expect if all the layers are linear.", "tokens": [50364, 286, 519, 456, 311, 733, 295, 512, 5261, 322, 437, 321, 820, 2066, 498, 439, 264, 7914, 366, 8213, 13, 50624], "temperature": 0.0, "avg_logprob": -0.1054703619627826, "compression_ratio": 1.850187265917603, "no_speech_prob": 0.0023222854360938072}, {"id": 77, "seek": 33506, "start": 340.26, "end": 344.74, "text": " But like obviously the neural networks that we train are nonlinear and it's really important", "tokens": [50624, 583, 411, 2745, 264, 18161, 9590, 300, 321, 3847, 366, 2107, 28263, 293, 309, 311, 534, 1021, 50848], "temperature": 0.0, "avg_logprob": -0.1054703619627826, "compression_ratio": 1.850187265917603, "no_speech_prob": 0.0023222854360938072}, {"id": 78, "seek": 33506, "start": 344.74, "end": 347.34000000000003, "text": " to have a nonlinearity in between the layers.", "tokens": [50848, 281, 362, 257, 2107, 1889, 17409, 294, 1296, 264, 7914, 13, 50978], "temperature": 0.0, "avg_logprob": -0.1054703619627826, "compression_ratio": 1.850187265917603, "no_speech_prob": 0.0023222854360938072}, {"id": 79, "seek": 33506, "start": 347.34000000000003, "end": 352.78, "text": " If we see that nothing is changing from one layer to the next that's a really bad sign.", "tokens": [50978, 759, 321, 536, 300, 1825, 307, 4473, 490, 472, 4583, 281, 264, 958, 300, 311, 257, 534, 1578, 1465, 13, 51250], "temperature": 0.0, "avg_logprob": -0.1054703619627826, "compression_ratio": 1.850187265917603, "no_speech_prob": 0.0023222854360938072}, {"id": 80, "seek": 33506, "start": 352.78, "end": 356.86, "text": " If the neural network representation isn't changing then obviously nothing's happening.", "tokens": [51250, 759, 264, 18161, 3209, 10290, 1943, 380, 4473, 550, 2745, 1825, 311, 2737, 13, 51454], "temperature": 0.0, "avg_logprob": -0.1054703619627826, "compression_ratio": 1.850187265917603, "no_speech_prob": 0.0023222854360938072}, {"id": 81, "seek": 33506, "start": 356.86, "end": 361.54, "text": " We couldn't have predicted this ahead of time based on what we know about neural network", "tokens": [51454, 492, 2809, 380, 362, 19147, 341, 2286, 295, 565, 2361, 322, 437, 321, 458, 466, 18161, 3209, 51688], "temperature": 0.0, "avg_logprob": -0.1054703619627826, "compression_ratio": 1.850187265917603, "no_speech_prob": 0.0023222854360938072}, {"id": 82, "seek": 36154, "start": 361.62, "end": 366.94, "text": " theory and we couldn't have predicted it ahead of time based on the accuracy of the network.", "tokens": [50368, 5261, 293, 321, 2809, 380, 362, 19147, 309, 2286, 295, 565, 2361, 322, 264, 14170, 295, 264, 3209, 13, 50634], "temperature": 0.0, "avg_logprob": -0.13124312400817872, "compression_ratio": 1.854251012145749, "no_speech_prob": 0.02756580151617527}, {"id": 83, "seek": 36154, "start": 366.94, "end": 368.74, "text": " Does this apply to ResNets though?", "tokens": [50634, 4402, 341, 3079, 281, 5015, 45, 1385, 1673, 30, 50724], "temperature": 0.0, "avg_logprob": -0.13124312400817872, "compression_ratio": 1.854251012145749, "no_speech_prob": 0.02756580151617527}, {"id": 84, "seek": 36154, "start": 368.74, "end": 371.46000000000004, "text": " I thought that they could learn their own capacity.", "tokens": [50724, 286, 1194, 300, 436, 727, 1466, 641, 1065, 6042, 13, 50860], "temperature": 0.0, "avg_logprob": -0.13124312400817872, "compression_ratio": 1.854251012145749, "no_speech_prob": 0.02756580151617527}, {"id": 85, "seek": 36154, "start": 371.46000000000004, "end": 375.78000000000003, "text": " You can either look at networks without residual connections where you do actually find that", "tokens": [50860, 509, 393, 2139, 574, 412, 9590, 1553, 27980, 9271, 689, 291, 360, 767, 915, 300, 51076], "temperature": 0.0, "avg_logprob": -0.13124312400817872, "compression_ratio": 1.854251012145749, "no_speech_prob": 0.02756580151617527}, {"id": 86, "seek": 36154, "start": 375.78000000000003, "end": 381.58000000000004, "text": " at some depth the accuracy will start going down and in networks without residual connections", "tokens": [51076, 412, 512, 7161, 264, 14170, 486, 722, 516, 760, 293, 294, 9590, 1553, 27980, 9271, 51366], "temperature": 0.0, "avg_logprob": -0.13124312400817872, "compression_ratio": 1.854251012145749, "no_speech_prob": 0.02756580151617527}, {"id": 87, "seek": 36154, "start": 381.58000000000004, "end": 388.14000000000004, "text": " we find that the depth where accuracy starts to go down is like around the same depth where", "tokens": [51366, 321, 915, 300, 264, 7161, 689, 14170, 3719, 281, 352, 760, 307, 411, 926, 264, 912, 7161, 689, 51694], "temperature": 0.0, "avg_logprob": -0.13124312400817872, "compression_ratio": 1.854251012145749, "no_speech_prob": 0.02756580151617527}, {"id": 88, "seek": 38814, "start": 388.18, "end": 393.02, "text": " you begin seeing this kind of block structure where many successive layers have similar", "tokens": [50366, 291, 1841, 2577, 341, 733, 295, 3461, 3877, 689, 867, 48043, 7914, 362, 2531, 50608], "temperature": 0.0, "avg_logprob": -0.13146729044394917, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.11267711967229843}, {"id": 89, "seek": 38814, "start": 393.02, "end": 397.78, "text": " representations and it looks like the representation is no longer getting refined through the network.", "tokens": [50608, 33358, 293, 309, 1542, 411, 264, 10290, 307, 572, 2854, 1242, 26201, 807, 264, 3209, 13, 50846], "temperature": 0.0, "avg_logprob": -0.13146729044394917, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.11267711967229843}, {"id": 90, "seek": 38814, "start": 397.78, "end": 402.41999999999996, "text": " Once you start getting these blocks making the network deeper, making the network wider", "tokens": [50846, 3443, 291, 722, 1242, 613, 8474, 1455, 264, 3209, 7731, 11, 1455, 264, 3209, 11842, 51078], "temperature": 0.0, "avg_logprob": -0.13146729044394917, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.11267711967229843}, {"id": 91, "seek": 38814, "start": 402.41999999999996, "end": 405.65999999999997, "text": " no longer really gives you any improvement in accuracy.", "tokens": [51078, 572, 2854, 534, 2709, 291, 604, 10444, 294, 14170, 13, 51240], "temperature": 0.0, "avg_logprob": -0.13146729044394917, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.11267711967229843}, {"id": 92, "seek": 38814, "start": 405.65999999999997, "end": 410.21999999999997, "text": " So it seems like this is basically telling you that the network has fit the data as much", "tokens": [51240, 407, 309, 2544, 411, 341, 307, 1936, 3585, 291, 300, 264, 3209, 575, 3318, 264, 1412, 382, 709, 51468], "temperature": 0.0, "avg_logprob": -0.13146729044394917, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.11267711967229843}, {"id": 93, "seek": 38814, "start": 410.21999999999997, "end": 416.82, "text": " as it can and there's no real advantage to using something bigger.", "tokens": [51468, 382, 309, 393, 293, 456, 311, 572, 957, 5002, 281, 1228, 746, 3801, 13, 51798], "temperature": 0.0, "avg_logprob": -0.13146729044394917, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.11267711967229843}, {"id": 94, "seek": 41682, "start": 416.82, "end": 422.02, "text": " Next we move on to Simon's paper about using different loss functions on image classifiers", "tokens": [50364, 3087, 321, 1286, 322, 281, 13193, 311, 3035, 466, 1228, 819, 4470, 6828, 322, 3256, 1508, 23463, 50624], "temperature": 0.0, "avg_logprob": -0.111263184320359, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.000882440188433975}, {"id": 95, "seek": 41682, "start": 422.02, "end": 425.98, "text": " and he made some really interesting findings actually so the loss functions only really", "tokens": [50624, 293, 415, 1027, 512, 534, 1880, 16483, 767, 370, 264, 4470, 6828, 787, 534, 50822], "temperature": 0.0, "avg_logprob": -0.111263184320359, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.000882440188433975}, {"id": 96, "seek": 41682, "start": 425.98, "end": 430.78, "text": " seem to affect the penultimate layers in the neural network.", "tokens": [50822, 1643, 281, 3345, 264, 3435, 723, 2905, 7914, 294, 264, 18161, 3209, 13, 51062], "temperature": 0.0, "avg_logprob": -0.111263184320359, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.000882440188433975}, {"id": 97, "seek": 41682, "start": 430.78, "end": 434.58, "text": " This also gives us some pretty useful insight into transfer learning.", "tokens": [51062, 639, 611, 2709, 505, 512, 1238, 4420, 11269, 666, 5003, 2539, 13, 51252], "temperature": 0.0, "avg_logprob": -0.111263184320359, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.000882440188433975}, {"id": 98, "seek": 41682, "start": 434.58, "end": 439.5, "text": " The last third of the network is setting up the penultimate layer representation in a", "tokens": [51252, 440, 1036, 2636, 295, 264, 3209, 307, 3287, 493, 264, 3435, 723, 2905, 4583, 10290, 294, 257, 51498], "temperature": 0.0, "avg_logprob": -0.111263184320359, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.000882440188433975}, {"id": 99, "seek": 41682, "start": 439.5, "end": 444.7, "text": " way that is good for your loss function but the first two thirds of the network are somehow", "tokens": [51498, 636, 300, 307, 665, 337, 428, 4470, 2445, 457, 264, 700, 732, 34552, 295, 264, 3209, 366, 6063, 51758], "temperature": 0.0, "avg_logprob": -0.111263184320359, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.000882440188433975}, {"id": 100, "seek": 44470, "start": 444.86, "end": 447.42, "text": " just learning general features.", "tokens": [50372, 445, 2539, 2674, 4122, 13, 50500], "temperature": 0.0, "avg_logprob": -0.17178310666765487, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.03620012104511261}, {"id": 101, "seek": 44470, "start": 447.42, "end": 452.18, "text": " I think this also corresponds with the success of transfer learning where we can take features", "tokens": [50500, 286, 519, 341, 611, 23249, 365, 264, 2245, 295, 5003, 2539, 689, 321, 393, 747, 4122, 50738], "temperature": 0.0, "avg_logprob": -0.17178310666765487, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.03620012104511261}, {"id": 102, "seek": 44470, "start": 452.18, "end": 456.26, "text": " that we've learned on one task and transfer them to some other task.", "tokens": [50738, 300, 321, 600, 3264, 322, 472, 5633, 293, 5003, 552, 281, 512, 661, 5633, 13, 50942], "temperature": 0.0, "avg_logprob": -0.17178310666765487, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.03620012104511261}, {"id": 103, "seek": 44470, "start": 456.26, "end": 457.98, "text": " What's the implication though?", "tokens": [50942, 708, 311, 264, 37814, 1673, 30, 51028], "temperature": 0.0, "avg_logprob": -0.17178310666765487, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.03620012104511261}, {"id": 104, "seek": 44470, "start": 457.98, "end": 464.46, "text": " It seems, is the implication that the loss function is not having any impact on the representations", "tokens": [51028, 467, 2544, 11, 307, 264, 37814, 300, 264, 4470, 2445, 307, 406, 1419, 604, 2712, 322, 264, 33358, 51352], "temperature": 0.0, "avg_logprob": -0.17178310666765487, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.03620012104511261}, {"id": 105, "seek": 44470, "start": 464.46, "end": 465.65999999999997, "text": " early on in the network?", "tokens": [51352, 2440, 322, 294, 264, 3209, 30, 51412], "temperature": 0.0, "avg_logprob": -0.17178310666765487, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.03620012104511261}, {"id": 106, "seek": 44470, "start": 465.65999999999997, "end": 469.34, "text": " That seems like quite a big implication.", "tokens": [51412, 663, 2544, 411, 1596, 257, 955, 37814, 13, 51596], "temperature": 0.0, "avg_logprob": -0.17178310666765487, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.03620012104511261}, {"id": 107, "seek": 44470, "start": 469.34, "end": 472.46, "text": " Ultimately we're asking the network to do the same thing just in a slightly different", "tokens": [51596, 23921, 321, 434, 3365, 264, 3209, 281, 360, 264, 912, 551, 445, 294, 257, 4748, 819, 51752], "temperature": 0.0, "avg_logprob": -0.17178310666765487, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.03620012104511261}, {"id": 108, "seek": 44470, "start": 472.46, "end": 473.46, "text": " way.", "tokens": [51752, 636, 13, 51802], "temperature": 0.0, "avg_logprob": -0.17178310666765487, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.03620012104511261}, {"id": 109, "seek": 47346, "start": 473.5, "end": 479.94, "text": " Like some inverse correlation between the gains you get from a loss function and how", "tokens": [50366, 1743, 512, 17340, 20009, 1296, 264, 16823, 291, 483, 490, 257, 4470, 2445, 293, 577, 50688], "temperature": 0.0, "avg_logprob": -0.11965556261016101, "compression_ratio": 1.7013574660633484, "no_speech_prob": 0.0009695725748315454}, {"id": 110, "seek": 47346, "start": 479.94, "end": 481.9, "text": " good it is for transfer learning.", "tokens": [50688, 665, 309, 307, 337, 5003, 2539, 13, 50786], "temperature": 0.0, "avg_logprob": -0.11965556261016101, "compression_ratio": 1.7013574660633484, "no_speech_prob": 0.0009695725748315454}, {"id": 111, "seek": 47346, "start": 481.9, "end": 489.9, "text": " If you use loss functions that give you higher accuracy on ImageNet, you tend to learn representations", "tokens": [50786, 759, 291, 764, 4470, 6828, 300, 976, 291, 2946, 14170, 322, 29903, 31890, 11, 291, 3928, 281, 1466, 33358, 51186], "temperature": 0.0, "avg_logprob": -0.11965556261016101, "compression_ratio": 1.7013574660633484, "no_speech_prob": 0.0009695725748315454}, {"id": 112, "seek": 47346, "start": 489.9, "end": 494.06, "text": " that transfer substantially worse in that setting.", "tokens": [51186, 300, 5003, 30797, 5324, 294, 300, 3287, 13, 51394], "temperature": 0.0, "avg_logprob": -0.11965556261016101, "compression_ratio": 1.7013574660633484, "no_speech_prob": 0.0009695725748315454}, {"id": 113, "seek": 47346, "start": 494.06, "end": 499.09999999999997, "text": " The loss functions that perform better lead classes to become more separated in the penultimate", "tokens": [51394, 440, 4470, 6828, 300, 2042, 1101, 1477, 5359, 281, 1813, 544, 12005, 294, 264, 3435, 723, 2905, 51646], "temperature": 0.0, "avg_logprob": -0.11965556261016101, "compression_ratio": 1.7013574660633484, "no_speech_prob": 0.0009695725748315454}, {"id": 114, "seek": 47346, "start": 499.09999999999997, "end": 500.09999999999997, "text": " layers.", "tokens": [51646, 7914, 13, 51696], "temperature": 0.0, "avg_logprob": -0.11965556261016101, "compression_ratio": 1.7013574660633484, "no_speech_prob": 0.0009695725748315454}, {"id": 115, "seek": 50010, "start": 500.14000000000004, "end": 505.34000000000003, "text": " To standard softmax loss, actually the classes are not that separated from each other in", "tokens": [50366, 1407, 3832, 2787, 41167, 4470, 11, 767, 264, 5359, 366, 406, 300, 12005, 490, 1184, 661, 294, 50626], "temperature": 0.0, "avg_logprob": -0.19360154674899194, "compression_ratio": 1.6125, "no_speech_prob": 0.006190769374370575}, {"id": 116, "seek": 50010, "start": 505.34000000000003, "end": 508.18, "text": " the penultimate layer representation.", "tokens": [50626, 264, 3435, 723, 2905, 4583, 10290, 13, 50768], "temperature": 0.0, "avg_logprob": -0.19360154674899194, "compression_ratio": 1.6125, "no_speech_prob": 0.006190769374370575}, {"id": 117, "seek": 50010, "start": 508.18, "end": 513.78, "text": " Right now on whatever TensorFlow Hub or Hugging Face repositories and so on, we have these", "tokens": [50768, 1779, 586, 322, 2035, 37624, 18986, 420, 46892, 3249, 4047, 22283, 2083, 293, 370, 322, 11, 321, 362, 613, 51048], "temperature": 0.0, "avg_logprob": -0.19360154674899194, "compression_ratio": 1.6125, "no_speech_prob": 0.006190769374370575}, {"id": 118, "seek": 50010, "start": 513.78, "end": 518.66, "text": " pre-trend models and the pre-trend models, they're like full stack models and people", "tokens": [51048, 659, 12, 3599, 273, 5245, 293, 264, 659, 12, 3599, 273, 5245, 11, 436, 434, 411, 1577, 8630, 5245, 293, 561, 51292], "temperature": 0.0, "avg_logprob": -0.19360154674899194, "compression_ratio": 1.6125, "no_speech_prob": 0.006190769374370575}, {"id": 119, "seek": 50010, "start": 518.66, "end": 526.82, "text": " usually take some sort of last or next to last hidden layer but maybe we should much", "tokens": [51292, 2673, 747, 512, 1333, 295, 1036, 420, 958, 281, 1036, 7633, 4583, 457, 1310, 321, 820, 709, 51700], "temperature": 0.0, "avg_logprob": -0.19360154674899194, "compression_ratio": 1.6125, "no_speech_prob": 0.006190769374370575}, {"id": 120, "seek": 52682, "start": 526.9000000000001, "end": 532.82, "text": " more focus on actually providing like half of a network to share, like determining which", "tokens": [50368, 544, 1879, 322, 767, 6530, 411, 1922, 295, 257, 3209, 281, 2073, 11, 411, 23751, 597, 50664], "temperature": 0.0, "avg_logprob": -0.16049071338689216, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.011503232643008232}, {"id": 121, "seek": 52682, "start": 532.82, "end": 538.22, "text": " are actually the best, good or general representations from a data set and so on.", "tokens": [50664, 366, 767, 264, 1151, 11, 665, 420, 2674, 33358, 490, 257, 1412, 992, 293, 370, 322, 13, 50934], "temperature": 0.0, "avg_logprob": -0.16049071338689216, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.011503232643008232}, {"id": 122, "seek": 52682, "start": 538.22, "end": 540.0600000000001, "text": " It's a really interesting question.", "tokens": [50934, 467, 311, 257, 534, 1880, 1168, 13, 51026], "temperature": 0.0, "avg_logprob": -0.16049071338689216, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.011503232643008232}, {"id": 123, "seek": 52682, "start": 540.0600000000001, "end": 544.74, "text": " If we just want to turn an image into a vector that we could then train a linear classifier", "tokens": [51026, 759, 321, 445, 528, 281, 1261, 364, 3256, 666, 257, 8062, 300, 321, 727, 550, 3847, 257, 8213, 1508, 9902, 51260], "temperature": 0.0, "avg_logprob": -0.16049071338689216, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.011503232643008232}, {"id": 124, "seek": 52682, "start": 544.74, "end": 547.9000000000001, "text": " on top of, what is the best way of doing that?", "tokens": [51260, 322, 1192, 295, 11, 437, 307, 264, 1151, 636, 295, 884, 300, 30, 51418], "temperature": 0.0, "avg_logprob": -0.16049071338689216, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.011503232643008232}, {"id": 125, "seek": 52682, "start": 547.9000000000001, "end": 552.34, "text": " Self-supervised pre-training, just like word vectors, gives us a really great starting", "tokens": [51418, 16348, 12, 48172, 24420, 659, 12, 17227, 1760, 11, 445, 411, 1349, 18875, 11, 2709, 505, 257, 534, 869, 2891, 51640], "temperature": 0.0, "avg_logprob": -0.16049071338689216, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.011503232643008232}, {"id": 126, "seek": 55234, "start": 552.34, "end": 557.7800000000001, "text": " point to vectorize an image into a semantically relevant geometric space.", "tokens": [50364, 935, 281, 8062, 1125, 364, 3256, 666, 257, 4361, 49505, 7340, 33246, 1901, 13, 50636], "temperature": 0.0, "avg_logprob": -0.11477381966330788, "compression_ratio": 1.6714285714285715, "no_speech_prob": 0.0037067157682031393}, {"id": 127, "seek": 55234, "start": 557.7800000000001, "end": 561.82, "text": " It's been a real game changer in the computer vision world since about 2018.", "tokens": [50636, 467, 311, 668, 257, 957, 1216, 22822, 294, 264, 3820, 5201, 1002, 1670, 466, 6096, 13, 50838], "temperature": 0.0, "avg_logprob": -0.11477381966330788, "compression_ratio": 1.6714285714285715, "no_speech_prob": 0.0037067157682031393}, {"id": 128, "seek": 55234, "start": 561.82, "end": 565.9, "text": " We want that neural network to learn a representation such that when we then just train a linear", "tokens": [50838, 492, 528, 300, 18161, 3209, 281, 1466, 257, 10290, 1270, 300, 562, 321, 550, 445, 3847, 257, 8213, 51042], "temperature": 0.0, "avg_logprob": -0.11477381966330788, "compression_ratio": 1.6714285714285715, "no_speech_prob": 0.0037067157682031393}, {"id": 129, "seek": 55234, "start": 565.9, "end": 570.86, "text": " classifier on top of that representation to classify image net, it's going to do well.", "tokens": [51042, 1508, 9902, 322, 1192, 295, 300, 10290, 281, 33872, 3256, 2533, 11, 309, 311, 516, 281, 360, 731, 13, 51290], "temperature": 0.0, "avg_logprob": -0.11477381966330788, "compression_ratio": 1.6714285714285715, "no_speech_prob": 0.0037067157682031393}, {"id": 130, "seek": 55234, "start": 570.86, "end": 575.7800000000001, "text": " But we want to learn the initial representation without using any kind of labels.", "tokens": [51290, 583, 321, 528, 281, 1466, 264, 5883, 10290, 1553, 1228, 604, 733, 295, 16949, 13, 51536], "temperature": 0.0, "avg_logprob": -0.11477381966330788, "compression_ratio": 1.6714285714285715, "no_speech_prob": 0.0037067157682031393}, {"id": 131, "seek": 55234, "start": 575.7800000000001, "end": 578.7800000000001, "text": " So what is self-supervised pre-training for vision?", "tokens": [51536, 407, 437, 307, 2698, 12, 48172, 24420, 659, 12, 17227, 1760, 337, 5201, 30, 51686], "temperature": 0.0, "avg_logprob": -0.11477381966330788, "compression_ratio": 1.6714285714285715, "no_speech_prob": 0.0037067157682031393}, {"id": 132, "seek": 57878, "start": 578.78, "end": 582.4599999999999, "text": " People came up with these kinds of tasks that you could try to train a neural network to", "tokens": [50364, 3432, 1361, 493, 365, 613, 3685, 295, 9608, 300, 291, 727, 853, 281, 3847, 257, 18161, 3209, 281, 50548], "temperature": 0.0, "avg_logprob": -0.13991816984404118, "compression_ratio": 2.2016460905349793, "no_speech_prob": 0.37307536602020264}, {"id": 133, "seek": 57878, "start": 582.4599999999999, "end": 586.26, "text": " do so that it would learn some kind of good representation.", "tokens": [50548, 360, 370, 300, 309, 576, 1466, 512, 733, 295, 665, 10290, 13, 50738], "temperature": 0.0, "avg_logprob": -0.13991816984404118, "compression_ratio": 2.2016460905349793, "no_speech_prob": 0.37307536602020264}, {"id": 134, "seek": 57878, "start": 586.26, "end": 593.14, "text": " You're trying to learn some kind of representation space where you've got different patches from", "tokens": [50738, 509, 434, 1382, 281, 1466, 512, 733, 295, 10290, 1901, 689, 291, 600, 658, 819, 26531, 490, 51082], "temperature": 0.0, "avg_logprob": -0.13991816984404118, "compression_ratio": 2.2016460905349793, "no_speech_prob": 0.37307536602020264}, {"id": 135, "seek": 57878, "start": 593.14, "end": 597.3399999999999, "text": " an image or different augmentations from an image, just different representations of the", "tokens": [51082, 364, 3256, 420, 819, 29919, 763, 490, 364, 3256, 11, 445, 819, 33358, 295, 264, 51292], "temperature": 0.0, "avg_logprob": -0.13991816984404118, "compression_ratio": 2.2016460905349793, "no_speech_prob": 0.37307536602020264}, {"id": 136, "seek": 57878, "start": 597.3399999999999, "end": 602.9399999999999, "text": " same image and you want to learn a representation space where these representations of the same", "tokens": [51292, 912, 3256, 293, 291, 528, 281, 1466, 257, 10290, 1901, 689, 613, 33358, 295, 264, 912, 51572], "temperature": 0.0, "avg_logprob": -0.13991816984404118, "compression_ratio": 2.2016460905349793, "no_speech_prob": 0.37307536602020264}, {"id": 137, "seek": 57878, "start": 602.9399999999999, "end": 608.74, "text": " image are all close together in that representation space and they're far apart from the representations", "tokens": [51572, 3256, 366, 439, 1998, 1214, 294, 300, 10290, 1901, 293, 436, 434, 1400, 4936, 490, 264, 33358, 51862], "temperature": 0.0, "avg_logprob": -0.13991816984404118, "compression_ratio": 2.2016460905349793, "no_speech_prob": 0.37307536602020264}, {"id": 138, "seek": 60874, "start": 609.38, "end": 611.34, "text": " of other images.", "tokens": [50396, 295, 661, 5267, 13, 50494], "temperature": 0.0, "avg_logprob": -0.17497096004256282, "compression_ratio": 1.6208530805687205, "no_speech_prob": 0.004197301808744669}, {"id": 139, "seek": 60874, "start": 611.34, "end": 616.22, "text": " This surprisingly seems to lead to very good representations.", "tokens": [50494, 639, 17600, 2544, 281, 1477, 281, 588, 665, 33358, 13, 50738], "temperature": 0.0, "avg_logprob": -0.17497096004256282, "compression_ratio": 1.6208530805687205, "no_speech_prob": 0.004197301808744669}, {"id": 140, "seek": 60874, "start": 616.22, "end": 623.0600000000001, "text": " I was very fascinated by all of these different tricks that you apparently have to get and", "tokens": [50738, 286, 390, 588, 24597, 538, 439, 295, 613, 819, 11733, 300, 291, 7970, 362, 281, 483, 293, 51080], "temperature": 0.0, "avg_logprob": -0.17497096004256282, "compression_ratio": 1.6208530805687205, "no_speech_prob": 0.004197301808744669}, {"id": 141, "seek": 60874, "start": 623.0600000000001, "end": 628.14, "text": " so big kudos to figuring all of this out for the rest of us.", "tokens": [51080, 370, 955, 350, 35063, 281, 15213, 439, 295, 341, 484, 337, 264, 1472, 295, 505, 13, 51334], "temperature": 0.0, "avg_logprob": -0.17497096004256282, "compression_ratio": 1.6208530805687205, "no_speech_prob": 0.004197301808744669}, {"id": 142, "seek": 60874, "start": 628.14, "end": 631.5, "text": " Data augmentation is absolutely key to making this work.", "tokens": [51334, 11888, 14501, 19631, 307, 3122, 2141, 281, 1455, 341, 589, 13, 51502], "temperature": 0.0, "avg_logprob": -0.17497096004256282, "compression_ratio": 1.6208530805687205, "no_speech_prob": 0.004197301808744669}, {"id": 143, "seek": 60874, "start": 631.5, "end": 635.3, "text": " The important part of the recipe is data augmentation.", "tokens": [51502, 440, 1021, 644, 295, 264, 6782, 307, 1412, 14501, 19631, 13, 51692], "temperature": 0.0, "avg_logprob": -0.17497096004256282, "compression_ratio": 1.6208530805687205, "no_speech_prob": 0.004197301808744669}, {"id": 144, "seek": 63530, "start": 635.3, "end": 640.38, "text": " There are really only two super important data augmentations that we need.", "tokens": [50364, 821, 366, 534, 787, 732, 1687, 1021, 1412, 29919, 763, 300, 321, 643, 13, 50618], "temperature": 0.0, "avg_logprob": -0.16618639394777632, "compression_ratio": 1.6285714285714286, "no_speech_prob": 0.00023779856564942747}, {"id": 145, "seek": 63530, "start": 640.38, "end": 645.8599999999999, "text": " So we have to take two different crops from the same image and then we have to do some", "tokens": [50618, 407, 321, 362, 281, 747, 732, 819, 16829, 490, 264, 912, 3256, 293, 550, 321, 362, 281, 360, 512, 50892], "temperature": 0.0, "avg_logprob": -0.16618639394777632, "compression_ratio": 1.6285714285714286, "no_speech_prob": 0.00023779856564942747}, {"id": 146, "seek": 63530, "start": 645.8599999999999, "end": 648.02, "text": " kind of color distortion.", "tokens": [50892, 733, 295, 2017, 28426, 13, 51000], "temperature": 0.0, "avg_logprob": -0.16618639394777632, "compression_ratio": 1.6285714285714286, "no_speech_prob": 0.00023779856564942747}, {"id": 147, "seek": 63530, "start": 648.02, "end": 650.38, "text": " Turns out though the architecture isn't that important.", "tokens": [51000, 29524, 484, 1673, 264, 9482, 1943, 380, 300, 1021, 13, 51118], "temperature": 0.0, "avg_logprob": -0.16618639394777632, "compression_ratio": 1.6285714285714286, "no_speech_prob": 0.00023779856564942747}, {"id": 148, "seek": 63530, "start": 650.38, "end": 656.78, "text": " You don't have to worry about architecture, engineering specifically or contrastive learning.", "tokens": [51118, 509, 500, 380, 362, 281, 3292, 466, 9482, 11, 7043, 4682, 420, 8712, 488, 2539, 13, 51438], "temperature": 0.0, "avg_logprob": -0.16618639394777632, "compression_ratio": 1.6285714285714286, "no_speech_prob": 0.00023779856564942747}, {"id": 149, "seek": 63530, "start": 656.78, "end": 658.66, "text": " What was new in the CIM CLR paper?", "tokens": [51438, 708, 390, 777, 294, 264, 383, 6324, 12855, 49, 3035, 30, 51532], "temperature": 0.0, "avg_logprob": -0.16618639394777632, "compression_ratio": 1.6285714285714286, "no_speech_prob": 0.00023779856564942747}, {"id": 150, "seek": 63530, "start": 658.66, "end": 664.06, "text": " We introduced the idea of this projection head in CIM Clear and we also spend a lot", "tokens": [51532, 492, 7268, 264, 1558, 295, 341, 22743, 1378, 294, 383, 6324, 14993, 293, 321, 611, 3496, 257, 688, 51802], "temperature": 0.0, "avg_logprob": -0.16618639394777632, "compression_ratio": 1.6285714285714286, "no_speech_prob": 0.00023779856564942747}, {"id": 151, "seek": 66406, "start": 664.06, "end": 666.2199999999999, "text": " of time studying the augmentation.", "tokens": [50364, 295, 565, 7601, 264, 14501, 19631, 13, 50472], "temperature": 0.0, "avg_logprob": -0.12476920066995824, "compression_ratio": 1.632, "no_speech_prob": 0.0005032548797316849}, {"id": 152, "seek": 66406, "start": 666.2199999999999, "end": 668.3399999999999, "text": " And what about the bring your own latent paper?", "tokens": [50472, 400, 437, 466, 264, 1565, 428, 1065, 48994, 3035, 30, 50578], "temperature": 0.0, "avg_logprob": -0.12476920066995824, "compression_ratio": 1.632, "no_speech_prob": 0.0005032548797316849}, {"id": 153, "seek": 66406, "start": 668.3399999999999, "end": 678.38, "text": " I don't really have any insight into how either BYOL or the more recent papers actually", "tokens": [50578, 286, 500, 380, 534, 362, 604, 11269, 666, 577, 2139, 26930, 5046, 420, 264, 544, 5162, 10577, 767, 51080], "temperature": 0.0, "avg_logprob": -0.12476920066995824, "compression_ratio": 1.632, "no_speech_prob": 0.0005032548797316849}, {"id": 154, "seek": 66406, "start": 678.38, "end": 681.8599999999999, "text": " are learning a representation that doesn't end up collapsing.", "tokens": [51080, 366, 2539, 257, 10290, 300, 1177, 380, 917, 493, 45339, 13, 51254], "temperature": 0.0, "avg_logprob": -0.12476920066995824, "compression_ratio": 1.632, "no_speech_prob": 0.0005032548797316849}, {"id": 155, "seek": 66406, "start": 681.8599999999999, "end": 686.6999999999999, "text": " Why it doesn't happen relates to some mysteries about neural network training dynamics that", "tokens": [51254, 1545, 309, 1177, 380, 1051, 16155, 281, 512, 30785, 466, 18161, 3209, 3097, 15679, 300, 51496], "temperature": 0.0, "avg_logprob": -0.12476920066995824, "compression_ratio": 1.632, "no_speech_prob": 0.0005032548797316849}, {"id": 156, "seek": 66406, "start": 686.6999999999999, "end": 688.9399999999999, "text": " we still don't entirely understand.", "tokens": [51496, 321, 920, 500, 380, 7696, 1223, 13, 51608], "temperature": 0.0, "avg_logprob": -0.12476920066995824, "compression_ratio": 1.632, "no_speech_prob": 0.0005032548797316849}, {"id": 157, "seek": 66406, "start": 688.9399999999999, "end": 691.6199999999999, "text": " We dive deep into data augmentation in general.", "tokens": [51608, 492, 9192, 2452, 666, 1412, 14501, 19631, 294, 2674, 13, 51742], "temperature": 0.0, "avg_logprob": -0.12476920066995824, "compression_ratio": 1.632, "no_speech_prob": 0.0005032548797316849}, {"id": 158, "seek": 69162, "start": 691.62, "end": 695.94, "text": " The data augmentation that you need for contrastive learning is different from the data augmentation", "tokens": [50364, 440, 1412, 14501, 19631, 300, 291, 643, 337, 8712, 488, 2539, 307, 819, 490, 264, 1412, 14501, 19631, 50580], "temperature": 0.0, "avg_logprob": -0.12087063028031036, "compression_ratio": 2.0817120622568095, "no_speech_prob": 0.013214784674346447}, {"id": 159, "seek": 69162, "start": 695.94, "end": 698.98, "text": " that you need for supervised learning because the task is different.", "tokens": [50580, 300, 291, 643, 337, 46533, 2539, 570, 264, 5633, 307, 819, 13, 50732], "temperature": 0.0, "avg_logprob": -0.12087063028031036, "compression_ratio": 2.0817120622568095, "no_speech_prob": 0.013214784674346447}, {"id": 160, "seek": 69162, "start": 698.98, "end": 704.22, "text": " When you have contrastive learning, you have this problem that if there's just one feature", "tokens": [50732, 1133, 291, 362, 8712, 488, 2539, 11, 291, 362, 341, 1154, 300, 498, 456, 311, 445, 472, 4111, 50994], "temperature": 0.0, "avg_logprob": -0.12087063028031036, "compression_ratio": 2.0817120622568095, "no_speech_prob": 0.013214784674346447}, {"id": 161, "seek": 69162, "start": 704.22, "end": 710.58, "text": " in your data that can be used to do the contrastive task to get images of the same example or", "tokens": [50994, 294, 428, 1412, 300, 393, 312, 1143, 281, 360, 264, 8712, 488, 5633, 281, 483, 5267, 295, 264, 912, 1365, 420, 51312], "temperature": 0.0, "avg_logprob": -0.12087063028031036, "compression_ratio": 2.0817120622568095, "no_speech_prob": 0.013214784674346447}, {"id": 162, "seek": 69162, "start": 710.58, "end": 715.02, "text": " views of the same example close together and far apart from views of all the other examples.", "tokens": [51312, 6809, 295, 264, 912, 1365, 1998, 1214, 293, 1400, 4936, 490, 6809, 295, 439, 264, 661, 5110, 13, 51534], "temperature": 0.0, "avg_logprob": -0.12087063028031036, "compression_ratio": 2.0817120622568095, "no_speech_prob": 0.013214784674346447}, {"id": 163, "seek": 69162, "start": 715.02, "end": 718.98, "text": " If you could do that with one feature, that would be the only feature the network would", "tokens": [51534, 759, 291, 727, 360, 300, 365, 472, 4111, 11, 300, 576, 312, 264, 787, 4111, 264, 3209, 576, 51732], "temperature": 0.0, "avg_logprob": -0.12087063028031036, "compression_ratio": 2.0817120622568095, "no_speech_prob": 0.013214784674346447}, {"id": 164, "seek": 71898, "start": 718.98, "end": 722.66, "text": " ever learn or it might be the only feature the network would ever learn.", "tokens": [50364, 1562, 1466, 420, 309, 1062, 312, 264, 787, 4111, 264, 3209, 576, 1562, 1466, 13, 50548], "temperature": 0.0, "avg_logprob": -0.1593009325174185, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.01320878230035305}, {"id": 165, "seek": 71898, "start": 722.66, "end": 726.78, "text": " And so with the augmentation, you're making the task harder so that the network actually", "tokens": [50548, 400, 370, 365, 264, 14501, 19631, 11, 291, 434, 1455, 264, 5633, 6081, 370, 300, 264, 3209, 767, 50754], "temperature": 0.0, "avg_logprob": -0.1593009325174185, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.01320878230035305}, {"id": 166, "seek": 71898, "start": 726.78, "end": 730.4200000000001, "text": " has to learn many different kinds of features.", "tokens": [50754, 575, 281, 1466, 867, 819, 3685, 295, 4122, 13, 50936], "temperature": 0.0, "avg_logprob": -0.1593009325174185, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.01320878230035305}, {"id": 167, "seek": 71898, "start": 730.4200000000001, "end": 736.58, "text": " We find that this color distortion actually is very important for self-supervised learning,", "tokens": [50936, 492, 915, 300, 341, 2017, 28426, 767, 307, 588, 1021, 337, 2698, 12, 48172, 24420, 2539, 11, 51244], "temperature": 0.0, "avg_logprob": -0.1593009325174185, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.01320878230035305}, {"id": 168, "seek": 71898, "start": 736.58, "end": 741.3000000000001, "text": " for contrastive learning, or as it doesn't really matter for supervised learning.", "tokens": [51244, 337, 8712, 488, 2539, 11, 420, 382, 309, 1177, 380, 534, 1871, 337, 46533, 2539, 13, 51480], "temperature": 0.0, "avg_logprob": -0.1593009325174185, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.01320878230035305}, {"id": 169, "seek": 71898, "start": 741.3000000000001, "end": 746.4200000000001, "text": " There seems to be this fascinating universality of representations, especially in vision.", "tokens": [51480, 821, 2544, 281, 312, 341, 10343, 5950, 1860, 295, 33358, 11, 2318, 294, 5201, 13, 51736], "temperature": 0.0, "avg_logprob": -0.1593009325174185, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.01320878230035305}, {"id": 170, "seek": 74642, "start": 746.42, "end": 750.74, "text": " I'm not trying to be flippant when I say this because practitioners have used ImageNet", "tokens": [50364, 286, 478, 406, 1382, 281, 312, 932, 2488, 394, 562, 286, 584, 341, 570, 25742, 362, 1143, 29903, 31890, 50580], "temperature": 0.0, "avg_logprob": -0.14352736434316246, "compression_ratio": 1.64, "no_speech_prob": 0.0025493218563497066}, {"id": 171, "seek": 74642, "start": 750.74, "end": 752.74, "text": " on a variety of downstream tasks.", "tokens": [50580, 322, 257, 5673, 295, 30621, 9608, 13, 50680], "temperature": 0.0, "avg_logprob": -0.14352736434316246, "compression_ratio": 1.64, "no_speech_prob": 0.0025493218563497066}, {"id": 172, "seek": 74642, "start": 752.74, "end": 756.5799999999999, "text": " For example, they might use it for classifying circuit boards or something.", "tokens": [50680, 1171, 1365, 11, 436, 1062, 764, 309, 337, 1508, 5489, 9048, 13293, 420, 746, 13, 50872], "temperature": 0.0, "avg_logprob": -0.14352736434316246, "compression_ratio": 1.64, "no_speech_prob": 0.0025493218563497066}, {"id": 173, "seek": 74642, "start": 756.5799999999999, "end": 759.3, "text": " And the miraculous thing is it just seems to work quite well.", "tokens": [50872, 400, 264, 41101, 551, 307, 309, 445, 2544, 281, 589, 1596, 731, 13, 51008], "temperature": 0.0, "avg_logprob": -0.14352736434316246, "compression_ratio": 1.64, "no_speech_prob": 0.0025493218563497066}, {"id": 174, "seek": 74642, "start": 759.3, "end": 763.5, "text": " So do you think in your opinion that there is some kind of universality?", "tokens": [51008, 407, 360, 291, 519, 294, 428, 4800, 300, 456, 307, 512, 733, 295, 5950, 1860, 30, 51218], "temperature": 0.0, "avg_logprob": -0.14352736434316246, "compression_ratio": 1.64, "no_speech_prob": 0.0025493218563497066}, {"id": 175, "seek": 74642, "start": 763.5, "end": 769.0999999999999, "text": " I'm very skeptical about universality of ImageNet for different tasks.", "tokens": [51218, 286, 478, 588, 28601, 466, 5950, 1860, 295, 29903, 31890, 337, 819, 9608, 13, 51498], "temperature": 0.0, "avg_logprob": -0.14352736434316246, "compression_ratio": 1.64, "no_speech_prob": 0.0025493218563497066}, {"id": 176, "seek": 74642, "start": 769.0999999999999, "end": 772.98, "text": " Even though there are lots of cars in ImageNet, if you pre-train on ImageNet and you fine", "tokens": [51498, 2754, 1673, 456, 366, 3195, 295, 5163, 294, 29903, 31890, 11, 498, 291, 659, 12, 83, 7146, 322, 29903, 31890, 293, 291, 2489, 51692], "temperature": 0.0, "avg_logprob": -0.14352736434316246, "compression_ratio": 1.64, "no_speech_prob": 0.0025493218563497066}, {"id": 177, "seek": 77298, "start": 772.98, "end": 778.5, "text": " tune on that data set, you will learn to classify it faster and fewer steps than if you had", "tokens": [50364, 10864, 322, 300, 1412, 992, 11, 291, 486, 1466, 281, 33872, 309, 4663, 293, 13366, 4439, 813, 498, 291, 632, 50640], "temperature": 0.0, "avg_logprob": -0.18165123739907907, "compression_ratio": 1.5944700460829493, "no_speech_prob": 0.024040935561060905}, {"id": 178, "seek": 77298, "start": 778.5, "end": 783.1, "text": " trained from scratch on the Stanford cars data set.", "tokens": [50640, 8895, 490, 8459, 322, 264, 20374, 5163, 1412, 992, 13, 50870], "temperature": 0.0, "avg_logprob": -0.18165123739907907, "compression_ratio": 1.5944700460829493, "no_speech_prob": 0.024040935561060905}, {"id": 179, "seek": 77298, "start": 783.1, "end": 786.94, "text": " But you won't actually perform any better at the end.", "tokens": [50870, 583, 291, 1582, 380, 767, 2042, 604, 1101, 412, 264, 917, 13, 51062], "temperature": 0.0, "avg_logprob": -0.18165123739907907, "compression_ratio": 1.5944700460829493, "no_speech_prob": 0.024040935561060905}, {"id": 180, "seek": 77298, "start": 786.94, "end": 789.86, "text": " Representations of images are not that universal.", "tokens": [51062, 19945, 763, 295, 5267, 366, 406, 300, 11455, 13, 51208], "temperature": 0.0, "avg_logprob": -0.18165123739907907, "compression_ratio": 1.5944700460829493, "no_speech_prob": 0.024040935561060905}, {"id": 181, "seek": 77298, "start": 789.86, "end": 796.14, "text": " And at least what works for natural images like those in ImageNet may not work on other", "tokens": [51208, 400, 412, 1935, 437, 1985, 337, 3303, 5267, 411, 729, 294, 29903, 31890, 815, 406, 589, 322, 661, 51522], "temperature": 0.0, "avg_logprob": -0.18165123739907907, "compression_ratio": 1.5944700460829493, "no_speech_prob": 0.024040935561060905}, {"id": 182, "seek": 77298, "start": 796.14, "end": 797.78, "text": " data sets.", "tokens": [51522, 1412, 6352, 13, 51604], "temperature": 0.0, "avg_logprob": -0.18165123739907907, "compression_ratio": 1.5944700460829493, "no_speech_prob": 0.024040935561060905}, {"id": 183, "seek": 79778, "start": 797.78, "end": 805.86, "text": " Taking a bit from the universality of representations to the universality of augmentations, since", "tokens": [50364, 17837, 257, 857, 490, 264, 5950, 1860, 295, 33358, 281, 264, 5950, 1860, 295, 29919, 763, 11, 1670, 50768], "temperature": 0.0, "avg_logprob": -0.17817657470703124, "compression_ratio": 1.66147859922179, "no_speech_prob": 0.6236708164215088}, {"id": 184, "seek": 79778, "start": 805.86, "end": 812.62, "text": " this is such a crucial part, do you think that there is a systematic way how we can", "tokens": [50768, 341, 307, 1270, 257, 11462, 644, 11, 360, 291, 519, 300, 456, 307, 257, 27249, 636, 577, 321, 393, 51106], "temperature": 0.0, "avg_logprob": -0.17817657470703124, "compression_ratio": 1.66147859922179, "no_speech_prob": 0.6236708164215088}, {"id": 185, "seek": 79778, "start": 812.62, "end": 815.06, "text": " discover augmentations?", "tokens": [51106, 4411, 29919, 763, 30, 51228], "temperature": 0.0, "avg_logprob": -0.17817657470703124, "compression_ratio": 1.66147859922179, "no_speech_prob": 0.6236708164215088}, {"id": 186, "seek": 79778, "start": 815.06, "end": 817.3399999999999, "text": " Right now, it seems to be kind of a whack-a-mole, right?", "tokens": [51228, 1779, 586, 11, 309, 2544, 281, 312, 733, 295, 257, 42877, 12, 64, 12, 3280, 306, 11, 558, 30, 51342], "temperature": 0.0, "avg_logprob": -0.17817657470703124, "compression_ratio": 1.66147859922179, "no_speech_prob": 0.6236708164215088}, {"id": 187, "seek": 79778, "start": 817.3399999999999, "end": 818.3399999999999, "text": " It's okay.", "tokens": [51342, 467, 311, 1392, 13, 51392], "temperature": 0.0, "avg_logprob": -0.17817657470703124, "compression_ratio": 1.66147859922179, "no_speech_prob": 0.6236708164215088}, {"id": 188, "seek": 79778, "start": 818.3399999999999, "end": 820.3, "text": " We just feed images and say, no, that's too easy.", "tokens": [51392, 492, 445, 3154, 5267, 293, 584, 11, 572, 11, 300, 311, 886, 1858, 13, 51490], "temperature": 0.0, "avg_logprob": -0.17817657470703124, "compression_ratio": 1.66147859922179, "no_speech_prob": 0.6236708164215088}, {"id": 189, "seek": 79778, "start": 820.3, "end": 821.3, "text": " We crop them.", "tokens": [51490, 492, 9086, 552, 13, 51540], "temperature": 0.0, "avg_logprob": -0.17817657470703124, "compression_ratio": 1.66147859922179, "no_speech_prob": 0.6236708164215088}, {"id": 190, "seek": 79778, "start": 821.3, "end": 822.5799999999999, "text": " Oh, no, it's the color histogram.", "tokens": [51540, 876, 11, 572, 11, 309, 311, 264, 2017, 49816, 13, 51604], "temperature": 0.0, "avg_logprob": -0.17817657470703124, "compression_ratio": 1.66147859922179, "no_speech_prob": 0.6236708164215088}, {"id": 191, "seek": 79778, "start": 822.5799999999999, "end": 825.42, "text": " So we like whack on the color and then it works better.", "tokens": [51604, 407, 321, 411, 42877, 322, 264, 2017, 293, 550, 309, 1985, 1101, 13, 51746], "temperature": 0.0, "avg_logprob": -0.17817657470703124, "compression_ratio": 1.66147859922179, "no_speech_prob": 0.6236708164215088}, {"id": 192, "seek": 82542, "start": 825.5, "end": 830.74, "text": " Maybe someone finds out, oh, there is still this easy feature that the network, every", "tokens": [50368, 2704, 1580, 10704, 484, 11, 1954, 11, 456, 307, 920, 341, 1858, 4111, 300, 264, 3209, 11, 633, 50630], "temperature": 0.0, "avg_logprob": -0.1812174842471168, "compression_ratio": 1.63671875, "no_speech_prob": 0.005634502973407507}, {"id": 193, "seek": 82542, "start": 830.74, "end": 836.3399999999999, "text": " noun, then pays attention to, so we design a method to whack on that a bit.", "tokens": [50630, 23307, 11, 550, 10604, 3202, 281, 11, 370, 321, 1715, 257, 3170, 281, 42877, 322, 300, 257, 857, 13, 50910], "temperature": 0.0, "avg_logprob": -0.1812174842471168, "compression_ratio": 1.63671875, "no_speech_prob": 0.005634502973407507}, {"id": 194, "seek": 82542, "start": 836.3399999999999, "end": 841.6999999999999, "text": " Do you think there is a systematic way or will this kind of philosophically always rely", "tokens": [50910, 1144, 291, 519, 456, 307, 257, 27249, 636, 420, 486, 341, 733, 295, 14529, 984, 1009, 10687, 51178], "temperature": 0.0, "avg_logprob": -0.1812174842471168, "compression_ratio": 1.63671875, "no_speech_prob": 0.005634502973407507}, {"id": 195, "seek": 82542, "start": 841.6999999999999, "end": 847.5799999999999, "text": " on us humans having a higher level inside of what we want to do with the data set?", "tokens": [51178, 322, 505, 6255, 1419, 257, 2946, 1496, 1854, 295, 437, 321, 528, 281, 360, 365, 264, 1412, 992, 30, 51472], "temperature": 0.0, "avg_logprob": -0.1812174842471168, "compression_ratio": 1.63671875, "no_speech_prob": 0.005634502973407507}, {"id": 196, "seek": 82542, "start": 847.5799999999999, "end": 850.4599999999999, "text": " So what comes next after data augmentation?", "tokens": [51472, 407, 437, 1487, 958, 934, 1412, 14501, 19631, 30, 51616], "temperature": 0.0, "avg_logprob": -0.1812174842471168, "compression_ratio": 1.63671875, "no_speech_prob": 0.005634502973407507}, {"id": 197, "seek": 82542, "start": 850.4599999999999, "end": 852.4599999999999, "text": " So would the next step be some simulation?", "tokens": [51616, 407, 576, 264, 958, 1823, 312, 512, 16575, 30, 51716], "temperature": 0.0, "avg_logprob": -0.1812174842471168, "compression_ratio": 1.63671875, "no_speech_prob": 0.005634502973407507}, {"id": 198, "seek": 85246, "start": 853.1800000000001, "end": 854.1800000000001, "text": " Do you know what I mean?", "tokens": [50400, 1144, 291, 458, 437, 286, 914, 30, 50450], "temperature": 0.0, "avg_logprob": -0.19183669833961978, "compression_ratio": 1.7018867924528303, "no_speech_prob": 0.00896349735558033}, {"id": 199, "seek": 85246, "start": 854.1800000000001, "end": 857.58, "text": " Where we impute physics and we impute some world knowledge and then, I don't know, whether", "tokens": [50450, 2305, 321, 704, 1169, 10649, 293, 321, 704, 1169, 512, 1002, 3601, 293, 550, 11, 286, 500, 380, 458, 11, 1968, 50620], "temperature": 0.0, "avg_logprob": -0.19183669833961978, "compression_ratio": 1.7018867924528303, "no_speech_prob": 0.00896349735558033}, {"id": 200, "seek": 85246, "start": 857.58, "end": 859.6600000000001, "text": " we train a machine learning model from that?", "tokens": [50620, 321, 3847, 257, 3479, 2539, 2316, 490, 300, 30, 50724], "temperature": 0.0, "avg_logprob": -0.19183669833961978, "compression_ratio": 1.7018867924528303, "no_speech_prob": 0.00896349735558033}, {"id": 201, "seek": 85246, "start": 859.6600000000001, "end": 866.1, "text": " Yeah, I think there are definitely shortcomings in our current machine learning models, understandings", "tokens": [50724, 865, 11, 286, 519, 456, 366, 2138, 2099, 49886, 294, 527, 2190, 3479, 2539, 5245, 11, 1223, 1109, 51046], "temperature": 0.0, "avg_logprob": -0.19183669833961978, "compression_ratio": 1.7018867924528303, "no_speech_prob": 0.00896349735558033}, {"id": 202, "seek": 85246, "start": 866.1, "end": 867.1, "text": " of the world.", "tokens": [51046, 295, 264, 1002, 13, 51096], "temperature": 0.0, "avg_logprob": -0.19183669833961978, "compression_ratio": 1.7018867924528303, "no_speech_prob": 0.00896349735558033}, {"id": 203, "seek": 85246, "start": 867.1, "end": 872.34, "text": " There are probably things that we can't just solve by throwing more static images at them.", "tokens": [51096, 821, 366, 1391, 721, 300, 321, 393, 380, 445, 5039, 538, 10238, 544, 13437, 5267, 412, 552, 13, 51358], "temperature": 0.0, "avg_logprob": -0.19183669833961978, "compression_ratio": 1.7018867924528303, "no_speech_prob": 0.00896349735558033}, {"id": 204, "seek": 85246, "start": 872.34, "end": 878.1, "text": " I think maybe the next step, rather than trying to immediately situate the machine", "tokens": [51358, 286, 519, 1310, 264, 958, 1823, 11, 2831, 813, 1382, 281, 4258, 2054, 473, 264, 3479, 51646], "temperature": 0.0, "avg_logprob": -0.19183669833961978, "compression_ratio": 1.7018867924528303, "no_speech_prob": 0.00896349735558033}, {"id": 205, "seek": 87810, "start": 878.1, "end": 883.4200000000001, "text": " learning model in a simulated world, we could just think about video.", "tokens": [50364, 2539, 2316, 294, 257, 41713, 1002, 11, 321, 727, 445, 519, 466, 960, 13, 50630], "temperature": 0.0, "avg_logprob": -0.15423801967075892, "compression_ratio": 1.6370967741935485, "no_speech_prob": 0.015896612778306007}, {"id": 206, "seek": 87810, "start": 883.4200000000001, "end": 889.1800000000001, "text": " I think probably representation learning from video is going to be a big thing next year", "tokens": [50630, 286, 519, 1391, 10290, 2539, 490, 960, 307, 516, 281, 312, 257, 955, 551, 958, 1064, 50918], "temperature": 0.0, "avg_logprob": -0.15423801967075892, "compression_ratio": 1.6370967741935485, "no_speech_prob": 0.015896612778306007}, {"id": 207, "seek": 87810, "start": 889.1800000000001, "end": 893.4200000000001, "text": " or the year after, something sometime in the near future.", "tokens": [50918, 420, 264, 1064, 934, 11, 746, 15053, 294, 264, 2651, 2027, 13, 51130], "temperature": 0.0, "avg_logprob": -0.15423801967075892, "compression_ratio": 1.6370967741935485, "no_speech_prob": 0.015896612778306007}, {"id": 208, "seek": 87810, "start": 893.4200000000001, "end": 895.74, "text": " Finally, we talk about Simon's paper.", "tokens": [51130, 6288, 11, 321, 751, 466, 13193, 311, 3035, 13, 51246], "temperature": 0.0, "avg_logprob": -0.15423801967075892, "compression_ratio": 1.6370967741935485, "no_speech_prob": 0.015896612778306007}, {"id": 209, "seek": 87810, "start": 895.74, "end": 900.46, "text": " Big self-supervised models are strong semi-supervised learners.", "tokens": [51246, 5429, 2698, 12, 48172, 24420, 5245, 366, 2068, 12909, 12, 48172, 24420, 23655, 13, 51482], "temperature": 0.0, "avg_logprob": -0.15423801967075892, "compression_ratio": 1.6370967741935485, "no_speech_prob": 0.015896612778306007}, {"id": 210, "seek": 87810, "start": 900.46, "end": 905.98, "text": " What is a practical problem is the situation where you have a lot of unlabeled data and", "tokens": [51482, 708, 307, 257, 8496, 1154, 307, 264, 2590, 689, 291, 362, 257, 688, 295, 32118, 18657, 292, 1412, 293, 51758], "temperature": 0.0, "avg_logprob": -0.15423801967075892, "compression_ratio": 1.6370967741935485, "no_speech_prob": 0.015896612778306007}, {"id": 211, "seek": 90598, "start": 905.98, "end": 909.34, "text": " then a very small amount of labeled data.", "tokens": [50364, 550, 257, 588, 1359, 2372, 295, 21335, 1412, 13, 50532], "temperature": 0.0, "avg_logprob": -0.17875816140856063, "compression_ratio": 1.5173745173745175, "no_speech_prob": 0.34753480553627014}, {"id": 212, "seek": 90598, "start": 909.34, "end": 915.1800000000001, "text": " What I find fascinating is how many ideas come together in this paper.", "tokens": [50532, 708, 286, 915, 10343, 307, 577, 867, 3487, 808, 1214, 294, 341, 3035, 13, 50824], "temperature": 0.0, "avg_logprob": -0.17875816140856063, "compression_ratio": 1.5173745173745175, "no_speech_prob": 0.34753480553627014}, {"id": 213, "seek": 90598, "start": 915.1800000000001, "end": 920.58, "text": " You probably didn't sit down after a SimClear one and be like, all right, what do we do", "tokens": [50824, 509, 1391, 994, 380, 1394, 760, 934, 257, 3998, 34, 5797, 472, 293, 312, 411, 11, 439, 558, 11, 437, 360, 321, 360, 51094], "temperature": 0.0, "avg_logprob": -0.17875816140856063, "compression_ratio": 1.5173745173745175, "no_speech_prob": 0.34753480553627014}, {"id": 214, "seek": 90598, "start": 920.58, "end": 921.58, "text": " for SimClear two?", "tokens": [51094, 337, 3998, 34, 5797, 732, 30, 51144], "temperature": 0.0, "avg_logprob": -0.17875816140856063, "compression_ratio": 1.5173745173745175, "no_speech_prob": 0.34753480553627014}, {"id": 215, "seek": 90598, "start": 921.58, "end": 922.58, "text": " Okay, let's do this.", "tokens": [51144, 1033, 11, 718, 311, 360, 341, 13, 51194], "temperature": 0.0, "avg_logprob": -0.17875816140856063, "compression_ratio": 1.5173745173745175, "no_speech_prob": 0.34753480553627014}, {"id": 216, "seek": 90598, "start": 922.58, "end": 924.22, "text": " So it tells me there was this process.", "tokens": [51194, 407, 309, 5112, 385, 456, 390, 341, 1399, 13, 51276], "temperature": 0.0, "avg_logprob": -0.17875816140856063, "compression_ratio": 1.5173745173745175, "no_speech_prob": 0.34753480553627014}, {"id": 217, "seek": 90598, "start": 924.22, "end": 930.34, "text": " Could you, if you can, maybe elaborate a bit on how did you going to build up the system", "tokens": [51276, 7497, 291, 11, 498, 291, 393, 11, 1310, 20945, 257, 857, 322, 577, 630, 291, 516, 281, 1322, 493, 264, 1185, 51582], "temperature": 0.0, "avg_logprob": -0.17875816140856063, "compression_ratio": 1.5173745173745175, "no_speech_prob": 0.34753480553627014}, {"id": 218, "seek": 90598, "start": 930.34, "end": 932.82, "text": " towards the final output?", "tokens": [51582, 3030, 264, 2572, 5598, 30, 51706], "temperature": 0.0, "avg_logprob": -0.17875816140856063, "compression_ratio": 1.5173745173745175, "no_speech_prob": 0.34753480553627014}, {"id": 219, "seek": 93282, "start": 932.82, "end": 937.5400000000001, "text": " We also tried the approach of first fine-tuning the big network and then distilling it.", "tokens": [50364, 492, 611, 3031, 264, 3109, 295, 700, 2489, 12, 83, 37726, 264, 955, 3209, 293, 550, 1483, 7345, 309, 13, 50600], "temperature": 0.0, "avg_logprob": -0.1182962245628482, "compression_ratio": 1.9061224489795918, "no_speech_prob": 0.0320759192109108}, {"id": 220, "seek": 93282, "start": 937.5400000000001, "end": 940.9000000000001, "text": " It turned out that worked a lot better.", "tokens": [50600, 467, 3574, 484, 300, 2732, 257, 688, 1101, 13, 50768], "temperature": 0.0, "avg_logprob": -0.1182962245628482, "compression_ratio": 1.9061224489795918, "no_speech_prob": 0.0320759192109108}, {"id": 221, "seek": 93282, "start": 940.9000000000001, "end": 946.5400000000001, "text": " What we found was this approach of pre-training, then fine-tuning, then distilling works a", "tokens": [50768, 708, 321, 1352, 390, 341, 3109, 295, 659, 12, 17227, 1760, 11, 550, 2489, 12, 83, 37726, 11, 550, 1483, 7345, 1985, 257, 51050], "temperature": 0.0, "avg_logprob": -0.1182962245628482, "compression_ratio": 1.9061224489795918, "no_speech_prob": 0.0320759192109108}, {"id": 222, "seek": 93282, "start": 946.5400000000001, "end": 950.6600000000001, "text": " lot better than pre-training, then distilling, then fine-tuning.", "tokens": [51050, 688, 1101, 813, 659, 12, 17227, 1760, 11, 550, 1483, 7345, 11, 550, 2489, 12, 83, 37726, 13, 51256], "temperature": 0.0, "avg_logprob": -0.1182962245628482, "compression_ratio": 1.9061224489795918, "no_speech_prob": 0.0320759192109108}, {"id": 223, "seek": 93282, "start": 950.6600000000001, "end": 956.1, "text": " We probably shouldn't expect distillation of the kind that we do in SimClear v2 to work", "tokens": [51256, 492, 1391, 4659, 380, 2066, 42923, 399, 295, 264, 733, 300, 321, 360, 294, 3998, 34, 5797, 371, 17, 281, 589, 51528], "temperature": 0.0, "avg_logprob": -0.1182962245628482, "compression_ratio": 1.9061224489795918, "no_speech_prob": 0.0320759192109108}, {"id": 224, "seek": 93282, "start": 956.1, "end": 962.6600000000001, "text": " substantially better than supervised distillation, which has been around for quite a while now.", "tokens": [51528, 30797, 1101, 813, 46533, 42923, 399, 11, 597, 575, 668, 926, 337, 1596, 257, 1339, 586, 13, 51856], "temperature": 0.0, "avg_logprob": -0.1182962245628482, "compression_ratio": 1.9061224489795918, "no_speech_prob": 0.0320759192109108}, {"id": 225, "seek": 96266, "start": 962.66, "end": 969.8199999999999, "text": " I think what's impressive is that in the self-supervised case, in the contrastive case, distillation", "tokens": [50364, 286, 519, 437, 311, 8992, 307, 300, 294, 264, 2698, 12, 48172, 24420, 1389, 11, 294, 264, 8712, 488, 1389, 11, 42923, 399, 50722], "temperature": 0.0, "avg_logprob": -0.12164460619290669, "compression_ratio": 1.7869565217391303, "no_speech_prob": 0.0027998914010822773}, {"id": 226, "seek": 96266, "start": 969.8199999999999, "end": 974.4599999999999, "text": " basically allows you to recover the same accuracy that you would get from training supervised", "tokens": [50722, 1936, 4045, 291, 281, 8114, 264, 912, 14170, 300, 291, 576, 483, 490, 3097, 46533, 50954], "temperature": 0.0, "avg_logprob": -0.12164460619290669, "compression_ratio": 1.7869565217391303, "no_speech_prob": 0.0027998914010822773}, {"id": 227, "seek": 96266, "start": 974.4599999999999, "end": 978.98, "text": " from scratch, whereas without it, the accuracy is a lot worse.", "tokens": [50954, 490, 8459, 11, 9735, 1553, 309, 11, 264, 14170, 307, 257, 688, 5324, 13, 51180], "temperature": 0.0, "avg_logprob": -0.12164460619290669, "compression_ratio": 1.7869565217391303, "no_speech_prob": 0.0027998914010822773}, {"id": 228, "seek": 96266, "start": 978.98, "end": 983.9399999999999, "text": " So it seems like it maybe matters more in this contrastive case.", "tokens": [51180, 407, 309, 2544, 411, 309, 1310, 7001, 544, 294, 341, 8712, 488, 1389, 13, 51428], "temperature": 0.0, "avg_logprob": -0.12164460619290669, "compression_ratio": 1.7869565217391303, "no_speech_prob": 0.0027998914010822773}, {"id": 229, "seek": 96266, "start": 983.9399999999999, "end": 989.3, "text": " But I think generally when you do distillation in the supervised case, you can get maybe", "tokens": [51428, 583, 286, 519, 5101, 562, 291, 360, 42923, 399, 294, 264, 46533, 1389, 11, 291, 393, 483, 1310, 51696], "temperature": 0.0, "avg_logprob": -0.12164460619290669, "compression_ratio": 1.7869565217391303, "no_speech_prob": 0.0027998914010822773}, {"id": 230, "seek": 98930, "start": 989.3, "end": 993.5799999999999, "text": " a percentage point gain, maybe a couple of percentage points.", "tokens": [50364, 257, 9668, 935, 6052, 11, 1310, 257, 1916, 295, 9668, 2793, 13, 50578], "temperature": 0.0, "avg_logprob": -0.15031680414232157, "compression_ratio": 1.6501766784452296, "no_speech_prob": 0.0026311150286346674}, {"id": 231, "seek": 98930, "start": 993.5799999999999, "end": 998.18, "text": " And I think that's probably about the limit in terms of the improvement that you could", "tokens": [50578, 400, 286, 519, 300, 311, 1391, 466, 264, 4948, 294, 2115, 295, 264, 10444, 300, 291, 727, 50808], "temperature": 0.0, "avg_logprob": -0.15031680414232157, "compression_ratio": 1.6501766784452296, "no_speech_prob": 0.0026311150286346674}, {"id": 232, "seek": 98930, "start": 998.18, "end": 1004.8199999999999, "text": " get from any kind of distillation-based approach over supervised training from scratch.", "tokens": [50808, 483, 490, 604, 733, 295, 42923, 399, 12, 6032, 3109, 670, 46533, 3097, 490, 8459, 13, 51140], "temperature": 0.0, "avg_logprob": -0.15031680414232157, "compression_ratio": 1.6501766784452296, "no_speech_prob": 0.0026311150286346674}, {"id": 233, "seek": 98930, "start": 1004.8199999999999, "end": 1010.5799999999999, "text": " Can you use GANs, Generative Adversarial Neural Networks, to do data augmentation?", "tokens": [51140, 1664, 291, 764, 460, 1770, 82, 11, 15409, 1166, 1999, 840, 44745, 1734, 1807, 12640, 82, 11, 281, 360, 1412, 14501, 19631, 30, 51428], "temperature": 0.0, "avg_logprob": -0.15031680414232157, "compression_ratio": 1.6501766784452296, "no_speech_prob": 0.0026311150286346674}, {"id": 234, "seek": 98930, "start": 1010.5799999999999, "end": 1012.78, "text": " Or is that just a myth?", "tokens": [51428, 1610, 307, 300, 445, 257, 9474, 30, 51538], "temperature": 0.0, "avg_logprob": -0.15031680414232157, "compression_ratio": 1.6501766784452296, "no_speech_prob": 0.0026311150286346674}, {"id": 235, "seek": 98930, "start": 1012.78, "end": 1015.0999999999999, "text": " Simon certainly seems to think so.", "tokens": [51538, 13193, 3297, 2544, 281, 519, 370, 13, 51654], "temperature": 0.0, "avg_logprob": -0.15031680414232157, "compression_ratio": 1.6501766784452296, "no_speech_prob": 0.0026311150286346674}, {"id": 236, "seek": 98930, "start": 1015.0999999999999, "end": 1019.26, "text": " Using a GAN to do data augmentation, you have this problem that you still don't actually", "tokens": [51654, 11142, 257, 460, 1770, 281, 360, 1412, 14501, 19631, 11, 291, 362, 341, 1154, 300, 291, 920, 500, 380, 767, 51862], "temperature": 0.0, "avg_logprob": -0.15031680414232157, "compression_ratio": 1.6501766784452296, "no_speech_prob": 0.0026311150286346674}, {"id": 237, "seek": 101926, "start": 1019.26, "end": 1021.14, "text": " have more data.", "tokens": [50364, 362, 544, 1412, 13, 50458], "temperature": 0.0, "avg_logprob": -0.1275759309025134, "compression_ratio": 1.889795918367347, "no_speech_prob": 0.018525905907154083}, {"id": 238, "seek": 101926, "start": 1021.14, "end": 1023.62, "text": " You have a GAN that's trained on the same data.", "tokens": [50458, 509, 362, 257, 460, 1770, 300, 311, 8895, 322, 264, 912, 1412, 13, 50582], "temperature": 0.0, "avg_logprob": -0.1275759309025134, "compression_ratio": 1.889795918367347, "no_speech_prob": 0.018525905907154083}, {"id": 239, "seek": 101926, "start": 1023.62, "end": 1028.46, "text": " And so it might help you because your way of encoding inductive bias into the GAN is", "tokens": [50582, 400, 370, 309, 1062, 854, 291, 570, 428, 636, 295, 43430, 31612, 488, 12577, 666, 264, 460, 1770, 307, 50824], "temperature": 0.0, "avg_logprob": -0.1275759309025134, "compression_ratio": 1.889795918367347, "no_speech_prob": 0.018525905907154083}, {"id": 240, "seek": 101926, "start": 1028.46, "end": 1032.5, "text": " different from your way of encoding inductive bias into the neural network.", "tokens": [50824, 819, 490, 428, 636, 295, 43430, 31612, 488, 12577, 666, 264, 18161, 3209, 13, 51026], "temperature": 0.0, "avg_logprob": -0.1275759309025134, "compression_ratio": 1.889795918367347, "no_speech_prob": 0.018525905907154083}, {"id": 241, "seek": 101926, "start": 1032.5, "end": 1037.54, "text": " And maybe by having more inductive bias, you can learn a better function.", "tokens": [51026, 400, 1310, 538, 1419, 544, 31612, 488, 12577, 11, 291, 393, 1466, 257, 1101, 2445, 13, 51278], "temperature": 0.0, "avg_logprob": -0.1275759309025134, "compression_ratio": 1.889795918367347, "no_speech_prob": 0.018525905907154083}, {"id": 242, "seek": 101926, "start": 1037.54, "end": 1041.66, "text": " You still don't have more data, and it seems like without having more data, there's no", "tokens": [51278, 509, 920, 500, 380, 362, 544, 1412, 11, 293, 309, 2544, 411, 1553, 1419, 544, 1412, 11, 456, 311, 572, 51484], "temperature": 0.0, "avg_logprob": -0.1275759309025134, "compression_ratio": 1.889795918367347, "no_speech_prob": 0.018525905907154083}, {"id": 243, "seek": 101926, "start": 1041.66, "end": 1046.46, "text": " reason to expect a priority that you will be able to learn a better function.", "tokens": [51484, 1778, 281, 2066, 257, 9365, 300, 291, 486, 312, 1075, 281, 1466, 257, 1101, 2445, 13, 51724], "temperature": 0.0, "avg_logprob": -0.1275759309025134, "compression_ratio": 1.889795918367347, "no_speech_prob": 0.018525905907154083}, {"id": 244, "seek": 104646, "start": 1046.46, "end": 1052.82, "text": " Ironically, when you do the simple data augmentation, you do have more data because you put all", "tokens": [50364, 13720, 984, 11, 562, 291, 360, 264, 2199, 1412, 14501, 19631, 11, 291, 360, 362, 544, 1412, 570, 291, 829, 439, 50682], "temperature": 0.0, "avg_logprob": -0.12403115560842115, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.020320231094956398}, {"id": 245, "seek": 104646, "start": 1052.82, "end": 1058.6200000000001, "text": " the knowledge in there as a human of what makes two images dissimilar visually, but", "tokens": [50682, 264, 3601, 294, 456, 382, 257, 1952, 295, 437, 1669, 732, 5267, 7802, 332, 2202, 19622, 11, 457, 50972], "temperature": 0.0, "avg_logprob": -0.12403115560842115, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.020320231094956398}, {"id": 246, "seek": 104646, "start": 1058.6200000000001, "end": 1064.5, "text": " still equivalent semantically, which, again, is exactly the opposite.", "tokens": [50972, 920, 10344, 4361, 49505, 11, 597, 11, 797, 11, 307, 2293, 264, 6182, 13, 51266], "temperature": 0.0, "avg_logprob": -0.12403115560842115, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.020320231094956398}, {"id": 247, "seek": 104646, "start": 1064.5, "end": 1071.18, "text": " It gives you images that are visually similar, but it has no intuition of what the semantic", "tokens": [51266, 467, 2709, 291, 5267, 300, 366, 19622, 2531, 11, 457, 309, 575, 572, 24002, 295, 437, 264, 47982, 51600], "temperature": 0.0, "avg_logprob": -0.12403115560842115, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.020320231094956398}, {"id": 248, "seek": 104646, "start": 1071.18, "end": 1072.98, "text": " similarity is.", "tokens": [51600, 32194, 307, 13, 51690], "temperature": 0.0, "avg_logprob": -0.12403115560842115, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.020320231094956398}, {"id": 249, "seek": 107298, "start": 1072.98, "end": 1077.18, "text": " We round off the show by talking about Simon's love of the Julia language.", "tokens": [50364, 492, 3098, 766, 264, 855, 538, 1417, 466, 13193, 311, 959, 295, 264, 18551, 2856, 13, 50574], "temperature": 0.0, "avg_logprob": -0.14664311244569975, "compression_ratio": 1.7517241379310344, "no_speech_prob": 0.02928830124437809}, {"id": 250, "seek": 107298, "start": 1077.18, "end": 1082.38, "text": " Julia is a much better programming language than Python in many ways.", "tokens": [50574, 18551, 307, 257, 709, 1101, 9410, 2856, 813, 15329, 294, 867, 2098, 13, 50834], "temperature": 0.0, "avg_logprob": -0.14664311244569975, "compression_ratio": 1.7517241379310344, "no_speech_prob": 0.02928830124437809}, {"id": 251, "seek": 107298, "start": 1082.38, "end": 1087.18, "text": " Julia is designed for these situations where maybe beyond just matrices, you have these", "tokens": [50834, 18551, 307, 4761, 337, 613, 6851, 689, 1310, 4399, 445, 32284, 11, 291, 362, 613, 51074], "temperature": 0.0, "avg_logprob": -0.14664311244569975, "compression_ratio": 1.7517241379310344, "no_speech_prob": 0.02928830124437809}, {"id": 252, "seek": 107298, "start": 1087.18, "end": 1091.5, "text": " funny types of structured matrices, you have sparse matrices, and you can define special", "tokens": [51074, 4074, 3467, 295, 18519, 32284, 11, 291, 362, 637, 11668, 32284, 11, 293, 291, 393, 6964, 2121, 51290], "temperature": 0.0, "avg_logprob": -0.14664311244569975, "compression_ratio": 1.7517241379310344, "no_speech_prob": 0.02928830124437809}, {"id": 253, "seek": 107298, "start": 1091.5, "end": 1096.7, "text": " methods for the product of a sparse matrix in a vector, or all sorts of things where", "tokens": [51290, 7150, 337, 264, 1674, 295, 257, 637, 11668, 8141, 294, 257, 8062, 11, 420, 439, 7527, 295, 721, 689, 51550], "temperature": 0.0, "avg_logprob": -0.14664311244569975, "compression_ratio": 1.7517241379310344, "no_speech_prob": 0.02928830124437809}, {"id": 254, "seek": 107298, "start": 1096.7, "end": 1100.5, "text": " you might want different methods depending on the types.", "tokens": [51550, 291, 1062, 528, 819, 7150, 5413, 322, 264, 3467, 13, 51740], "temperature": 0.0, "avg_logprob": -0.14664311244569975, "compression_ratio": 1.7517241379310344, "no_speech_prob": 0.02928830124437809}, {"id": 255, "seek": 107298, "start": 1100.5, "end": 1102.3, "text": " I really hope you've enjoyed the show today.", "tokens": [51740, 286, 534, 1454, 291, 600, 4626, 264, 855, 965, 13, 51830], "temperature": 0.0, "avg_logprob": -0.14664311244569975, "compression_ratio": 1.7517241379310344, "no_speech_prob": 0.02928830124437809}, {"id": 256, "seek": 110230, "start": 1102.3, "end": 1104.3799999999999, "text": " We've had so much fun making it.", "tokens": [50364, 492, 600, 632, 370, 709, 1019, 1455, 309, 13, 50468], "temperature": 0.0, "avg_logprob": -0.229398951810949, "compression_ratio": 1.5, "no_speech_prob": 0.47867098450660706}, {"id": 257, "seek": 110230, "start": 1104.3799999999999, "end": 1107.94, "text": " Remember to like, comment, and subscribe.", "tokens": [50468, 5459, 281, 411, 11, 2871, 11, 293, 3022, 13, 50646], "temperature": 0.0, "avg_logprob": -0.229398951810949, "compression_ratio": 1.5, "no_speech_prob": 0.47867098450660706}, {"id": 258, "seek": 110230, "start": 1107.94, "end": 1113.82, "text": " We love reading your comments, every single one of them, and we'll see you back next", "tokens": [50646, 492, 959, 3760, 428, 3053, 11, 633, 2167, 472, 295, 552, 11, 293, 321, 603, 536, 291, 646, 958, 50940], "temperature": 0.0, "avg_logprob": -0.229398951810949, "compression_ratio": 1.5, "no_speech_prob": 0.47867098450660706}, {"id": 259, "seek": 110230, "start": 1113.82, "end": 1114.82, "text": " week.", "tokens": [50940, 1243, 13, 50990], "temperature": 0.0, "avg_logprob": -0.229398951810949, "compression_ratio": 1.5, "no_speech_prob": 0.47867098450660706}, {"id": 260, "seek": 110230, "start": 1114.82, "end": 1119.82, "text": " Welcome back to the Machine Learning Street Talk YouTube channel and podcast with my", "tokens": [50990, 4027, 646, 281, 264, 22155, 15205, 7638, 8780, 3088, 2269, 293, 7367, 365, 452, 51240], "temperature": 0.0, "avg_logprob": -0.229398951810949, "compression_ratio": 1.5, "no_speech_prob": 0.47867098450660706}, {"id": 261, "seek": 110230, "start": 1119.82, "end": 1126.1, "text": " two compadre, Syac, the neural network pruner, Paul, and Yannick, the Lightspeed protein", "tokens": [51240, 732, 715, 345, 265, 11, 3902, 326, 11, 264, 18161, 3209, 582, 409, 260, 11, 4552, 11, 293, 398, 969, 618, 11, 264, 38226, 494, 292, 7944, 51554], "temperature": 0.0, "avg_logprob": -0.229398951810949, "compression_ratio": 1.5, "no_speech_prob": 0.47867098450660706}, {"id": 262, "seek": 110230, "start": 1126.1, "end": 1129.18, "text": " folder, Kiltcher.", "tokens": [51554, 10820, 11, 591, 2352, 6759, 13, 51708], "temperature": 0.0, "avg_logprob": -0.229398951810949, "compression_ratio": 1.5, "no_speech_prob": 0.47867098450660706}, {"id": 263, "seek": 112918, "start": 1129.18, "end": 1133.78, "text": " Today we have an incredibly special guest, Simon Cornblith, and Simon got his PhD in", "tokens": [50364, 2692, 321, 362, 364, 6252, 2121, 8341, 11, 13193, 21590, 5199, 355, 11, 293, 13193, 658, 702, 14476, 294, 50594], "temperature": 0.0, "avg_logprob": -0.19529341007101125, "compression_ratio": 1.6101694915254237, "no_speech_prob": 0.4413753151893616}, {"id": 264, "seek": 112918, "start": 1133.78, "end": 1136.98, "text": " brain and cognitive sciences from MIT.", "tokens": [50594, 3567, 293, 15605, 17677, 490, 13100, 13, 50754], "temperature": 0.0, "avg_logprob": -0.19529341007101125, "compression_ratio": 1.6101694915254237, "no_speech_prob": 0.4413753151893616}, {"id": 265, "seek": 112918, "start": 1136.98, "end": 1140.74, "text": " His undergrad was from Caltech, and he's a research scientist at Google Brain.", "tokens": [50754, 2812, 14295, 390, 490, 3511, 25970, 11, 293, 415, 311, 257, 2132, 12662, 412, 3329, 29783, 13, 50942], "temperature": 0.0, "avg_logprob": -0.19529341007101125, "compression_ratio": 1.6101694915254237, "no_speech_prob": 0.4413753151893616}, {"id": 266, "seek": 112918, "start": 1140.74, "end": 1143.66, "text": " He's been there since about 2017.", "tokens": [50942, 634, 311, 668, 456, 1670, 466, 6591, 13, 51088], "temperature": 0.0, "avg_logprob": -0.19529341007101125, "compression_ratio": 1.6101694915254237, "no_speech_prob": 0.4413753151893616}, {"id": 267, "seek": 112918, "start": 1143.66, "end": 1148.9, "text": " He's been cited nearly 2,000 times, which for someone quite early in career is seriously", "tokens": [51088, 634, 311, 668, 30134, 6217, 568, 11, 1360, 1413, 11, 597, 337, 1580, 1596, 2440, 294, 3988, 307, 6638, 51350], "temperature": 0.0, "avg_logprob": -0.19529341007101125, "compression_ratio": 1.6101694915254237, "no_speech_prob": 0.4413753151893616}, {"id": 268, "seek": 112918, "start": 1148.9, "end": 1149.9, "text": " impressive.", "tokens": [51350, 8992, 13, 51400], "temperature": 0.0, "avg_logprob": -0.19529341007101125, "compression_ratio": 1.6101694915254237, "no_speech_prob": 0.4413753151893616}, {"id": 269, "seek": 112918, "start": 1149.9, "end": 1156.5, "text": " He's got a keen interest in the digital humanities, in philosophy, computer science, machine learning,", "tokens": [51400, 634, 311, 658, 257, 20297, 1179, 294, 264, 4562, 36140, 11, 294, 10675, 11, 3820, 3497, 11, 3479, 2539, 11, 51730], "temperature": 0.0, "avg_logprob": -0.19529341007101125, "compression_ratio": 1.6101694915254237, "no_speech_prob": 0.4413753151893616}, {"id": 270, "seek": 112918, "start": 1156.5, "end": 1159.14, "text": " computer vision, and neuroscience.", "tokens": [51730, 3820, 5201, 11, 293, 42762, 13, 51862], "temperature": 0.0, "avg_logprob": -0.19529341007101125, "compression_ratio": 1.6101694915254237, "no_speech_prob": 0.4413753151893616}, {"id": 271, "seek": 115914, "start": 1159.14, "end": 1162.9, "text": " He used to be a neuroscientist before we started doing machine learning, and he tells us that", "tokens": [50364, 634, 1143, 281, 312, 257, 28813, 5412, 468, 949, 321, 1409, 884, 3479, 2539, 11, 293, 415, 5112, 505, 300, 50552], "temperature": 0.0, "avg_logprob": -0.14856080751161319, "compression_ratio": 1.6795774647887325, "no_speech_prob": 0.012398331426084042}, {"id": 272, "seek": 115914, "start": 1162.9, "end": 1167.18, "text": " he's got some very strong opinions about neuroscience and machine learning, which we certainly will", "tokens": [50552, 415, 311, 658, 512, 588, 2068, 11819, 466, 42762, 293, 3479, 2539, 11, 597, 321, 3297, 486, 50766], "temperature": 0.0, "avg_logprob": -0.14856080751161319, "compression_ratio": 1.6795774647887325, "no_speech_prob": 0.012398331426084042}, {"id": 273, "seek": 115914, "start": 1167.18, "end": 1168.8600000000001, "text": " be getting on to later.", "tokens": [50766, 312, 1242, 322, 281, 1780, 13, 50850], "temperature": 0.0, "avg_logprob": -0.14856080751161319, "compression_ratio": 1.6795774647887325, "no_speech_prob": 0.012398331426084042}, {"id": 274, "seek": 115914, "start": 1168.8600000000001, "end": 1173.3000000000002, "text": " He's a huge lover of the Julia language, so if you Google Simon's name, you'll see him", "tokens": [50850, 634, 311, 257, 2603, 18009, 295, 264, 18551, 2856, 11, 370, 498, 291, 3329, 13193, 311, 1315, 11, 291, 603, 536, 796, 51072], "temperature": 0.0, "avg_logprob": -0.14856080751161319, "compression_ratio": 1.6795774647887325, "no_speech_prob": 0.012398331426084042}, {"id": 275, "seek": 115914, "start": 1173.3000000000002, "end": 1178.8200000000002, "text": " talking at about a million Julia conferences, so definitely check that out as well.", "tokens": [51072, 1417, 412, 466, 257, 2459, 18551, 22032, 11, 370, 2138, 1520, 300, 484, 382, 731, 13, 51348], "temperature": 0.0, "avg_logprob": -0.14856080751161319, "compression_ratio": 1.6795774647887325, "no_speech_prob": 0.012398331426084042}, {"id": 276, "seek": 115914, "start": 1178.8200000000002, "end": 1183.74, "text": " Simon pioneered the use of centered kernel alignment as a way of analyzing the evolution", "tokens": [51348, 13193, 19761, 4073, 264, 764, 295, 18988, 28256, 18515, 382, 257, 636, 295, 23663, 264, 9303, 51594], "temperature": 0.0, "avg_logprob": -0.14856080751161319, "compression_ratio": 1.6795774647887325, "no_speech_prob": 0.012398331426084042}, {"id": 277, "seek": 118374, "start": 1183.74, "end": 1189.18, "text": " of representations in layers, in network, and between networks of different architectures.", "tokens": [50364, 295, 33358, 294, 7914, 11, 294, 3209, 11, 293, 1296, 9590, 295, 819, 6331, 1303, 13, 50636], "temperature": 0.0, "avg_logprob": -0.14953775874903943, "compression_ratio": 1.6366666666666667, "no_speech_prob": 0.6733371019363403}, {"id": 278, "seek": 118374, "start": 1189.18, "end": 1193.98, "text": " Now Simon, like me, is a lover of similarity matrices, and what can be gleaned from them?", "tokens": [50636, 823, 13193, 11, 411, 385, 11, 307, 257, 18009, 295, 32194, 32284, 11, 293, 437, 393, 312, 290, 28499, 292, 490, 552, 30, 50876], "temperature": 0.0, "avg_logprob": -0.14953775874903943, "compression_ratio": 1.6366666666666667, "no_speech_prob": 0.6733371019363403}, {"id": 279, "seek": 118374, "start": 1193.98, "end": 1199.22, "text": " On my own PhD, I worked with them a lot for music segmentation, and also for detecting", "tokens": [50876, 1282, 452, 1065, 14476, 11, 286, 2732, 365, 552, 257, 688, 337, 1318, 9469, 399, 11, 293, 611, 337, 40237, 51138], "temperature": 0.0, "avg_logprob": -0.14953775874903943, "compression_ratio": 1.6366666666666667, "no_speech_prob": 0.6733371019363403}, {"id": 280, "seek": 118374, "start": 1199.22, "end": 1201.78, "text": " regimes in financial data sets.", "tokens": [51138, 45738, 294, 4669, 1412, 6352, 13, 51266], "temperature": 0.0, "avg_logprob": -0.14953775874903943, "compression_ratio": 1.6366666666666667, "no_speech_prob": 0.6733371019363403}, {"id": 281, "seek": 118374, "start": 1201.78, "end": 1207.22, "text": " When a block in a ResNet is no longer self-similar to previous layers early on, you might intuit", "tokens": [51266, 1133, 257, 3461, 294, 257, 5015, 31890, 307, 572, 2854, 2698, 12, 30937, 2202, 281, 3894, 7914, 2440, 322, 11, 291, 1062, 16224, 51538], "temperature": 0.0, "avg_logprob": -0.14953775874903943, "compression_ratio": 1.6366666666666667, "no_speech_prob": 0.6733371019363403}, {"id": 282, "seek": 118374, "start": 1207.22, "end": 1212.7, "text": " that it's moving into a new representational regime, or maybe it's just started hallucinating.", "tokens": [51538, 300, 309, 311, 2684, 666, 257, 777, 2906, 1478, 13120, 11, 420, 1310, 309, 311, 445, 1409, 35212, 8205, 13, 51812], "temperature": 0.0, "avg_logprob": -0.14953775874903943, "compression_ratio": 1.6366666666666667, "no_speech_prob": 0.6733371019363403}, {"id": 283, "seek": 121270, "start": 1212.78, "end": 1216.54, "text": " All of this stuff was covered in his paper, Do Wide and Deep Neural Networks Learn the", "tokens": [50368, 1057, 295, 341, 1507, 390, 5343, 294, 702, 3035, 11, 1144, 42543, 293, 14895, 1734, 1807, 12640, 82, 17216, 264, 50556], "temperature": 0.0, "avg_logprob": -0.14417886312029002, "compression_ratio": 1.687719298245614, "no_speech_prob": 0.048886410892009735}, {"id": 284, "seek": 121270, "start": 1216.54, "end": 1221.9, "text": " Same Things, and I find it fascinating that representation of self-similarity can reveal", "tokens": [50556, 10635, 9514, 11, 293, 286, 915, 309, 10343, 300, 10290, 295, 2698, 12, 30937, 2202, 507, 393, 10658, 50824], "temperature": 0.0, "avg_logprob": -0.14417886312029002, "compression_ratio": 1.687719298245614, "no_speech_prob": 0.048886410892009735}, {"id": 285, "seek": 121270, "start": 1221.9, "end": 1223.54, "text": " network pathology.", "tokens": [50824, 3209, 3100, 1793, 13, 50906], "temperature": 0.0, "avg_logprob": -0.14417886312029002, "compression_ratio": 1.687719298245614, "no_speech_prob": 0.048886410892009735}, {"id": 286, "seek": 121270, "start": 1223.54, "end": 1227.5800000000002, "text": " Now in his paper, What's in a Loss Function for Image Classification, he noted that different", "tokens": [50906, 823, 294, 702, 3035, 11, 708, 311, 294, 257, 441, 772, 11166, 882, 337, 29903, 9471, 3774, 11, 415, 12964, 300, 819, 51108], "temperature": 0.0, "avg_logprob": -0.14417886312029002, "compression_ratio": 1.687719298245614, "no_speech_prob": 0.048886410892009735}, {"id": 287, "seek": 121270, "start": 1227.5800000000002, "end": 1233.5, "text": " losses and regularizers have similar accuracies on several data sets, but using the same representational", "tokens": [51108, 15352, 293, 3890, 22525, 362, 2531, 5771, 20330, 322, 2940, 1412, 6352, 11, 457, 1228, 264, 912, 2906, 1478, 51404], "temperature": 0.0, "avg_logprob": -0.14417886312029002, "compression_ratio": 1.687719298245614, "no_speech_prob": 0.048886410892009735}, {"id": 288, "seek": 121270, "start": 1233.5, "end": 1239.5, "text": " evolution analysis, Simon gleaned that these losses and regularizers only affected the", "tokens": [51404, 9303, 5215, 11, 13193, 290, 28499, 292, 300, 613, 15352, 293, 3890, 22525, 787, 8028, 264, 51704], "temperature": 0.0, "avg_logprob": -0.14417886312029002, "compression_ratio": 1.687719298245614, "no_speech_prob": 0.048886410892009735}, {"id": 289, "seek": 123950, "start": 1239.5, "end": 1243.34, "text": " penultimate layers in the neural network, revealing inherent limitations in what can", "tokens": [50364, 3435, 723, 2905, 7914, 294, 264, 18161, 3209, 11, 23983, 26387, 15705, 294, 437, 393, 50556], "temperature": 0.0, "avg_logprob": -0.1405034558526401, "compression_ratio": 1.7763578274760383, "no_speech_prob": 0.009542696177959442}, {"id": 290, "seek": 123950, "start": 1243.34, "end": 1246.5, "text": " be achieved in manipulating the loss on a network.", "tokens": [50556, 312, 11042, 294, 40805, 264, 4470, 322, 257, 3209, 13, 50714], "temperature": 0.0, "avg_logprob": -0.1405034558526401, "compression_ratio": 1.7763578274760383, "no_speech_prob": 0.009542696177959442}, {"id": 291, "seek": 123950, "start": 1246.5, "end": 1250.14, "text": " Now next in the session today, we're going to talk about the Simclear paper, and this", "tokens": [50714, 823, 958, 294, 264, 5481, 965, 11, 321, 434, 516, 281, 751, 466, 264, 3998, 43679, 3035, 11, 293, 341, 50896], "temperature": 0.0, "avg_logprob": -0.1405034558526401, "compression_ratio": 1.7763578274760383, "no_speech_prob": 0.009542696177959442}, {"id": 292, "seek": 123950, "start": 1250.14, "end": 1255.94, "text": " was an incredibly exciting paper for unsupervised contrastive image learning with augmentations.", "tokens": [50896, 390, 364, 6252, 4670, 3035, 337, 2693, 12879, 24420, 8712, 488, 3256, 2539, 365, 29919, 763, 13, 51186], "temperature": 0.0, "avg_logprob": -0.1405034558526401, "compression_ratio": 1.7763578274760383, "no_speech_prob": 0.009542696177959442}, {"id": 293, "seek": 123950, "start": 1255.94, "end": 1260.74, "text": " It introduced a learnable nonlinear transformation between the representations and the contrastive", "tokens": [51186, 467, 7268, 257, 1466, 712, 2107, 28263, 9887, 1296, 264, 33358, 293, 264, 8712, 488, 51426], "temperature": 0.0, "avg_logprob": -0.1405034558526401, "compression_ratio": 1.7763578274760383, "no_speech_prob": 0.009542696177959442}, {"id": 294, "seek": 123950, "start": 1260.74, "end": 1264.1, "text": " loss, which massively improved the representations.", "tokens": [51426, 4470, 11, 597, 29379, 9689, 264, 33358, 13, 51594], "temperature": 0.0, "avg_logprob": -0.1405034558526401, "compression_ratio": 1.7763578274760383, "no_speech_prob": 0.009542696177959442}, {"id": 295, "seek": 123950, "start": 1264.1, "end": 1268.74, "text": " The composition of augmentations is super important, and whenever anyone asks me about", "tokens": [51594, 440, 12686, 295, 29919, 763, 307, 1687, 1021, 11, 293, 5699, 2878, 8962, 385, 466, 51826], "temperature": 0.0, "avg_logprob": -0.1405034558526401, "compression_ratio": 1.7763578274760383, "no_speech_prob": 0.009542696177959442}, {"id": 296, "seek": 126874, "start": 1268.98, "end": 1272.1, "text": " what are the different data augmentations in computer vision, I always point them to", "tokens": [50376, 437, 366, 264, 819, 1412, 29919, 763, 294, 3820, 5201, 11, 286, 1009, 935, 552, 281, 50532], "temperature": 0.0, "avg_logprob": -0.17280894167283, "compression_ratio": 1.7289156626506024, "no_speech_prob": 0.09554287046194077}, {"id": 297, "seek": 126874, "start": 1272.1, "end": 1276.94, "text": " the SimCLR paper because it's got this wonderful matrix, and in that matrix it was shown that", "tokens": [50532, 264, 3998, 34, 31722, 3035, 570, 309, 311, 658, 341, 3715, 8141, 11, 293, 294, 300, 8141, 309, 390, 4898, 300, 50774], "temperature": 0.0, "avg_logprob": -0.17280894167283, "compression_ratio": 1.7289156626506024, "no_speech_prob": 0.09554287046194077}, {"id": 298, "seek": 126874, "start": 1276.94, "end": 1281.74, "text": " the crop and the color I think were the most effective augmentations, but Simon also noted", "tokens": [50774, 264, 9086, 293, 264, 2017, 286, 519, 645, 264, 881, 4942, 29919, 763, 11, 457, 13193, 611, 12964, 51014], "temperature": 0.0, "avg_logprob": -0.17280894167283, "compression_ratio": 1.7289156626506024, "no_speech_prob": 0.09554287046194077}, {"id": 299, "seek": 126874, "start": 1281.74, "end": 1285.58, "text": " that the batch sizes were super important, and the paper improved over the state of the", "tokens": [51014, 300, 264, 15245, 11602, 645, 1687, 1021, 11, 293, 264, 3035, 9689, 670, 264, 1785, 295, 264, 51206], "temperature": 0.0, "avg_logprob": -0.17280894167283, "compression_ratio": 1.7289156626506024, "no_speech_prob": 0.09554287046194077}, {"id": 300, "seek": 126874, "start": 1285.58, "end": 1290.02, "text": " art on the ImageNet top one, and actually matched unsupervised methods for the first", "tokens": [51206, 1523, 322, 264, 29903, 31890, 1192, 472, 11, 293, 767, 21447, 2693, 12879, 24420, 7150, 337, 264, 700, 51428], "temperature": 0.0, "avg_logprob": -0.17280894167283, "compression_ratio": 1.7289156626506024, "no_speech_prob": 0.09554287046194077}, {"id": 301, "seek": 126874, "start": 1290.02, "end": 1292.42, "text": " time, albeit with many more parameters.", "tokens": [51428, 565, 11, 43654, 365, 867, 544, 9834, 13, 51548], "temperature": 0.0, "avg_logprob": -0.17280894167283, "compression_ratio": 1.7289156626506024, "no_speech_prob": 0.09554287046194077}, {"id": 302, "seek": 126874, "start": 1292.42, "end": 1295.82, "text": " But the final paper we're going to talk about today is Big Self-Supervised Models, a strong", "tokens": [51548, 583, 264, 2572, 3035, 321, 434, 516, 281, 751, 466, 965, 307, 5429, 16348, 12, 30152, 24420, 6583, 1625, 11, 257, 2068, 51718], "temperature": 0.0, "avg_logprob": -0.17280894167283, "compression_ratio": 1.7289156626506024, "no_speech_prob": 0.09554287046194077}, {"id": 303, "seek": 129582, "start": 1295.8999999999999, "end": 1300.06, "text": " semi-supervised learners, and this is where you can learn from fewer labeled examples while", "tokens": [50368, 12909, 12, 48172, 24420, 23655, 11, 293, 341, 307, 689, 291, 393, 1466, 490, 13366, 21335, 5110, 1339, 50576], "temperature": 0.0, "avg_logprob": -0.13846729823521206, "compression_ratio": 1.743421052631579, "no_speech_prob": 0.09198381751775742}, {"id": 304, "seek": 129582, "start": 1300.06, "end": 1304.9399999999998, "text": " making use of a large amount of unlabeled data, and with unsupervised pre-training", "tokens": [50576, 1455, 764, 295, 257, 2416, 2372, 295, 32118, 18657, 292, 1412, 11, 293, 365, 2693, 12879, 24420, 659, 12, 17227, 1760, 50820], "temperature": 0.0, "avg_logprob": -0.13846729823521206, "compression_ratio": 1.743421052631579, "no_speech_prob": 0.09198381751775742}, {"id": 305, "seek": 129582, "start": 1304.9399999999998, "end": 1310.3799999999999, "text": " on SimCLR v2, supervised fine-tuning on a few labeled examples, and then distillation", "tokens": [50820, 322, 3998, 34, 31722, 371, 17, 11, 46533, 2489, 12, 83, 37726, 322, 257, 1326, 21335, 5110, 11, 293, 550, 42923, 399, 51092], "temperature": 0.0, "avg_logprob": -0.13846729823521206, "compression_ratio": 1.743421052631579, "no_speech_prob": 0.09198381751775742}, {"id": 306, "seek": 129582, "start": 1310.3799999999999, "end": 1314.8999999999999, "text": " with unlabeled examples, this approach improved the label efficiency over previous state-of-the-art", "tokens": [51092, 365, 32118, 18657, 292, 5110, 11, 341, 3109, 9689, 264, 7645, 10493, 670, 3894, 1785, 12, 2670, 12, 3322, 12, 446, 51318], "temperature": 0.0, "avg_logprob": -0.13846729823521206, "compression_ratio": 1.743421052631579, "no_speech_prob": 0.09198381751775742}, {"id": 307, "seek": 129582, "start": 1314.8999999999999, "end": 1315.8999999999999, "text": " methods.", "tokens": [51318, 7150, 13, 51368], "temperature": 0.0, "avg_logprob": -0.13846729823521206, "compression_ratio": 1.743421052631579, "no_speech_prob": 0.09198381751775742}, {"id": 308, "seek": 129582, "start": 1315.8999999999999, "end": 1320.1399999999999, "text": " I remember Yannick Lightspeed Kilcher made a video on this one, which I watched a few", "tokens": [51368, 286, 1604, 398, 969, 618, 38226, 494, 292, 23912, 6759, 1027, 257, 960, 322, 341, 472, 11, 597, 286, 6337, 257, 1326, 51580], "temperature": 0.0, "avg_logprob": -0.13846729823521206, "compression_ratio": 1.743421052631579, "no_speech_prob": 0.09198381751775742}, {"id": 309, "seek": 129582, "start": 1320.1399999999999, "end": 1323.8999999999999, "text": " months ago, so Yannick will have all of that completely fresh in his mind.", "tokens": [51580, 2493, 2057, 11, 370, 398, 969, 618, 486, 362, 439, 295, 300, 2584, 4451, 294, 702, 1575, 13, 51768], "temperature": 0.0, "avg_logprob": -0.13846729823521206, "compression_ratio": 1.743421052631579, "no_speech_prob": 0.09198381751775742}, {"id": 310, "seek": 132390, "start": 1323.98, "end": 1326.98, "text": " Anyway, Simon, it's an absolute pleasure to welcome you to the show.", "tokens": [50368, 5684, 11, 13193, 11, 309, 311, 364, 8236, 6834, 281, 2928, 291, 281, 264, 855, 13, 50518], "temperature": 0.0, "avg_logprob": -0.1328237287459835, "compression_ratio": 1.6875, "no_speech_prob": 0.36057671904563904}, {"id": 311, "seek": 132390, "start": 1326.98, "end": 1327.98, "text": " Thank you so much for coming.", "tokens": [50518, 1044, 291, 370, 709, 337, 1348, 13, 50568], "temperature": 0.0, "avg_logprob": -0.1328237287459835, "compression_ratio": 1.6875, "no_speech_prob": 0.36057671904563904}, {"id": 312, "seek": 132390, "start": 1327.98, "end": 1328.98, "text": " It's great to be here.", "tokens": [50568, 467, 311, 869, 281, 312, 510, 13, 50618], "temperature": 0.0, "avg_logprob": -0.1328237287459835, "compression_ratio": 1.6875, "no_speech_prob": 0.36057671904563904}, {"id": 313, "seek": 132390, "start": 1328.98, "end": 1329.98, "text": " Amazing.", "tokens": [50618, 14165, 13, 50668], "temperature": 0.0, "avg_logprob": -0.1328237287459835, "compression_ratio": 1.6875, "no_speech_prob": 0.36057671904563904}, {"id": 314, "seek": 132390, "start": 1329.98, "end": 1331.7800000000002, "text": " How did you get into machine learning?", "tokens": [50668, 1012, 630, 291, 483, 666, 3479, 2539, 30, 50758], "temperature": 0.0, "avg_logprob": -0.1328237287459835, "compression_ratio": 1.6875, "no_speech_prob": 0.36057671904563904}, {"id": 315, "seek": 132390, "start": 1331.7800000000002, "end": 1338.5400000000002, "text": " So I guess first I got into neuroscience, and then I got disillusioned with neuroscience.", "tokens": [50758, 407, 286, 2041, 700, 286, 658, 666, 42762, 11, 293, 550, 286, 658, 717, 373, 5704, 292, 365, 42762, 13, 51096], "temperature": 0.0, "avg_logprob": -0.1328237287459835, "compression_ratio": 1.6875, "no_speech_prob": 0.36057671904563904}, {"id": 316, "seek": 132390, "start": 1338.5400000000002, "end": 1343.7, "text": " When I was pretty young, I was interested in consciousness and how we create this kind", "tokens": [51096, 1133, 286, 390, 1238, 2037, 11, 286, 390, 3102, 294, 10081, 293, 577, 321, 1884, 341, 733, 51354], "temperature": 0.0, "avg_logprob": -0.1328237287459835, "compression_ratio": 1.6875, "no_speech_prob": 0.36057671904563904}, {"id": 317, "seek": 132390, "start": 1343.7, "end": 1348.0600000000002, "text": " of impression of the external world inside our heads.", "tokens": [51354, 295, 9995, 295, 264, 8320, 1002, 1854, 527, 8050, 13, 51572], "temperature": 0.0, "avg_logprob": -0.1328237287459835, "compression_ratio": 1.6875, "no_speech_prob": 0.36057671904563904}, {"id": 318, "seek": 132390, "start": 1348.0600000000002, "end": 1352.5, "text": " And so I guess it's pretty obvious how that translates into an interest in brains and", "tokens": [51572, 400, 370, 286, 2041, 309, 311, 1238, 6322, 577, 300, 28468, 666, 364, 1179, 294, 15442, 293, 51794], "temperature": 0.0, "avg_logprob": -0.1328237287459835, "compression_ratio": 1.6875, "no_speech_prob": 0.36057671904563904}, {"id": 319, "seek": 135250, "start": 1352.5, "end": 1354.3, "text": " how the brain works.", "tokens": [50364, 577, 264, 3567, 1985, 13, 50454], "temperature": 0.0, "avg_logprob": -0.09414930939674378, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.08483652770519257}, {"id": 320, "seek": 135250, "start": 1354.3, "end": 1360.46, "text": " So I spent both four years as an undergraduate doing neuroscience research, and then seven", "tokens": [50454, 407, 286, 4418, 1293, 1451, 924, 382, 364, 19113, 884, 42762, 2132, 11, 293, 550, 3407, 50762], "temperature": 0.0, "avg_logprob": -0.09414930939674378, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.08483652770519257}, {"id": 321, "seek": 135250, "start": 1360.46, "end": 1366.9, "text": " years working with monkeys at MIT trying to figure out how monkey brains work.", "tokens": [50762, 924, 1364, 365, 29534, 412, 13100, 1382, 281, 2573, 484, 577, 17847, 15442, 589, 13, 51084], "temperature": 0.0, "avg_logprob": -0.09414930939674378, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.08483652770519257}, {"id": 322, "seek": 135250, "start": 1366.9, "end": 1373.46, "text": " And then after that, I felt like we weren't getting very far by trying to record from", "tokens": [51084, 400, 550, 934, 300, 11, 286, 2762, 411, 321, 4999, 380, 1242, 588, 1400, 538, 1382, 281, 2136, 490, 51412], "temperature": 0.0, "avg_logprob": -0.09414930939674378, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.08483652770519257}, {"id": 323, "seek": 135250, "start": 1373.46, "end": 1378.1, "text": " neurons in monkeys' brains and figure out how those neurons work.", "tokens": [51412, 22027, 294, 29534, 6, 15442, 293, 2573, 484, 577, 729, 22027, 589, 13, 51644], "temperature": 0.0, "avg_logprob": -0.09414930939674378, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.08483652770519257}, {"id": 324, "seek": 137810, "start": 1378.1, "end": 1383.78, "text": " So I thought about what other ways are there approaching this problem?", "tokens": [50364, 407, 286, 1194, 466, 437, 661, 2098, 366, 456, 14908, 341, 1154, 30, 50648], "temperature": 0.0, "avg_logprob": -0.10878308959629225, "compression_ratio": 1.6307053941908713, "no_speech_prob": 0.002713603898882866}, {"id": 325, "seek": 137810, "start": 1383.78, "end": 1390.3799999999999, "text": " How could we think about how to understand how the brain is doing tasks?", "tokens": [50648, 1012, 727, 321, 519, 466, 577, 281, 1223, 577, 264, 3567, 307, 884, 9608, 30, 50978], "temperature": 0.0, "avg_logprob": -0.10878308959629225, "compression_ratio": 1.6307053941908713, "no_speech_prob": 0.002713603898882866}, {"id": 326, "seek": 137810, "start": 1390.3799999999999, "end": 1396.5, "text": " And it seemed like maybe by building systems that can do those tasks well that are not", "tokens": [50978, 400, 309, 6576, 411, 1310, 538, 2390, 3652, 300, 393, 360, 729, 9608, 731, 300, 366, 406, 51284], "temperature": 0.0, "avg_logprob": -0.10878308959629225, "compression_ratio": 1.6307053941908713, "no_speech_prob": 0.002713603898882866}, {"id": 327, "seek": 137810, "start": 1396.5, "end": 1398.74, "text": " biological, we could learn more.", "tokens": [51284, 13910, 11, 321, 727, 1466, 544, 13, 51396], "temperature": 0.0, "avg_logprob": -0.10878308959629225, "compression_ratio": 1.6307053941908713, "no_speech_prob": 0.002713603898882866}, {"id": 328, "seek": 137810, "start": 1398.74, "end": 1401.06, "text": " So that's how I got into machine learning.", "tokens": [51396, 407, 300, 311, 577, 286, 658, 666, 3479, 2539, 13, 51512], "temperature": 0.0, "avg_logprob": -0.10878308959629225, "compression_ratio": 1.6307053941908713, "no_speech_prob": 0.002713603898882866}, {"id": 329, "seek": 137810, "start": 1401.06, "end": 1405.82, "text": " I joined the Google AI residency program, which is like this great program that Google", "tokens": [51512, 286, 6869, 264, 3329, 7318, 34014, 1461, 11, 597, 307, 411, 341, 869, 1461, 300, 3329, 51750], "temperature": 0.0, "avg_logprob": -0.10878308959629225, "compression_ratio": 1.6307053941908713, "no_speech_prob": 0.002713603898882866}, {"id": 330, "seek": 140582, "start": 1405.82, "end": 1412.6599999999999, "text": " has to take people who have extensive background in some field that is not machine learning", "tokens": [50364, 575, 281, 747, 561, 567, 362, 13246, 3678, 294, 512, 2519, 300, 307, 406, 3479, 2539, 50706], "temperature": 0.0, "avg_logprob": -0.12651829449635632, "compression_ratio": 1.895582329317269, "no_speech_prob": 0.09250039607286453}, {"id": 331, "seek": 140582, "start": 1412.6599999999999, "end": 1415.58, "text": " and train them to do machine learning.", "tokens": [50706, 293, 3847, 552, 281, 360, 3479, 2539, 13, 50852], "temperature": 0.0, "avg_logprob": -0.12651829449635632, "compression_ratio": 1.895582329317269, "no_speech_prob": 0.09250039607286453}, {"id": 332, "seek": 140582, "start": 1415.58, "end": 1420.6599999999999, "text": " And I ended up at Google, and initially I thought I'm going to spend a year here learning", "tokens": [50852, 400, 286, 4590, 493, 412, 3329, 11, 293, 9105, 286, 1194, 286, 478, 516, 281, 3496, 257, 1064, 510, 2539, 51106], "temperature": 0.0, "avg_logprob": -0.12651829449635632, "compression_ratio": 1.895582329317269, "no_speech_prob": 0.09250039607286453}, {"id": 333, "seek": 140582, "start": 1420.6599999999999, "end": 1425.1399999999999, "text": " about machine learning related stuff, and then maybe I'll go back to neuroscience and", "tokens": [51106, 466, 3479, 2539, 4077, 1507, 11, 293, 550, 1310, 286, 603, 352, 646, 281, 42762, 293, 51330], "temperature": 0.0, "avg_logprob": -0.12651829449635632, "compression_ratio": 1.895582329317269, "no_speech_prob": 0.09250039607286453}, {"id": 334, "seek": 140582, "start": 1425.1399999999999, "end": 1429.82, "text": " I'll decide the tools for machine learning could be applied back to brains, and maybe", "tokens": [51330, 286, 603, 4536, 264, 3873, 337, 3479, 2539, 727, 312, 6456, 646, 281, 15442, 11, 293, 1310, 51564], "temperature": 0.0, "avg_logprob": -0.12651829449635632, "compression_ratio": 1.895582329317269, "no_speech_prob": 0.09250039607286453}, {"id": 335, "seek": 140582, "start": 1429.82, "end": 1434.58, "text": " we can learn more about brains by applying the tools of machine learning there.", "tokens": [51564, 321, 393, 1466, 544, 466, 15442, 538, 9275, 264, 3873, 295, 3479, 2539, 456, 13, 51802], "temperature": 0.0, "avg_logprob": -0.12651829449635632, "compression_ratio": 1.895582329317269, "no_speech_prob": 0.09250039607286453}, {"id": 336, "seek": 143458, "start": 1434.58, "end": 1439.26, "text": " But ultimately I decided I was more interested in just looking at how the neural networks", "tokens": [50364, 583, 6284, 286, 3047, 286, 390, 544, 3102, 294, 445, 1237, 412, 577, 264, 18161, 9590, 50598], "temperature": 0.0, "avg_logprob": -0.13901224923790048, "compression_ratio": 1.7064846416382253, "no_speech_prob": 0.10011729598045349}, {"id": 337, "seek": 143458, "start": 1439.26, "end": 1444.5, "text": " work and also in the engineering challenges of building better neural networks, which", "tokens": [50598, 589, 293, 611, 294, 264, 7043, 4759, 295, 2390, 1101, 18161, 9590, 11, 597, 50860], "temperature": 0.0, "avg_logprob": -0.13901224923790048, "compression_ratio": 1.7064846416382253, "no_speech_prob": 0.10011729598045349}, {"id": 338, "seek": 143458, "start": 1444.5, "end": 1446.5, "text": " I actually think are fun.", "tokens": [50860, 286, 767, 519, 366, 1019, 13, 50960], "temperature": 0.0, "avg_logprob": -0.13901224923790048, "compression_ratio": 1.7064846416382253, "no_speech_prob": 0.10011729598045349}, {"id": 339, "seek": 143458, "start": 1446.5, "end": 1451.02, "text": " One of the thoughts that came to my mind is it's fascinating looking at the kind of introspective", "tokens": [50960, 1485, 295, 264, 4598, 300, 1361, 281, 452, 1575, 307, 309, 311, 10343, 1237, 412, 264, 733, 295, 560, 28713, 488, 51186], "temperature": 0.0, "avg_logprob": -0.13901224923790048, "compression_ratio": 1.7064846416382253, "no_speech_prob": 0.10011729598045349}, {"id": 340, "seek": 143458, "start": 1451.02, "end": 1455.3799999999999, "text": " analysis that you've been conducting with neural networks, but could you contrast that", "tokens": [51186, 5215, 300, 291, 600, 668, 21749, 365, 18161, 9590, 11, 457, 727, 291, 8712, 300, 51404], "temperature": 0.0, "avg_logprob": -0.13901224923790048, "compression_ratio": 1.7064846416382253, "no_speech_prob": 0.10011729598045349}, {"id": 341, "seek": 143458, "start": 1455.3799999999999, "end": 1456.3799999999999, "text": " with neuroscience?", "tokens": [51404, 365, 42762, 30, 51454], "temperature": 0.0, "avg_logprob": -0.13901224923790048, "compression_ratio": 1.7064846416382253, "no_speech_prob": 0.10011729598045349}, {"id": 342, "seek": 143458, "start": 1456.3799999999999, "end": 1462.3, "text": " Because as I understand, you have MRI scans and you have different ways of trying to visualize", "tokens": [51454, 1436, 382, 286, 1223, 11, 291, 362, 32812, 35116, 293, 291, 362, 819, 2098, 295, 1382, 281, 23273, 51750], "temperature": 0.0, "avg_logprob": -0.13901224923790048, "compression_ratio": 1.7064846416382253, "no_speech_prob": 0.10011729598045349}, {"id": 343, "seek": 146230, "start": 1462.3, "end": 1466.62, "text": " and reason about the behavior of a brain, but you can't really tweak the architecture", "tokens": [50364, 293, 1778, 466, 264, 5223, 295, 257, 3567, 11, 457, 291, 393, 380, 534, 29879, 264, 9482, 50580], "temperature": 0.0, "avg_logprob": -0.13864092145647322, "compression_ratio": 1.7240143369175627, "no_speech_prob": 0.012772741727530956}, {"id": 344, "seek": 146230, "start": 1466.62, "end": 1470.78, "text": " and tweak all of the knobs and the levers in quite the same way you do in machine learning.", "tokens": [50580, 293, 29879, 439, 295, 264, 46999, 293, 264, 45571, 294, 1596, 264, 912, 636, 291, 360, 294, 3479, 2539, 13, 50788], "temperature": 0.0, "avg_logprob": -0.13864092145647322, "compression_ratio": 1.7240143369175627, "no_speech_prob": 0.012772741727530956}, {"id": 345, "seek": 146230, "start": 1470.78, "end": 1477.02, "text": " Yeah, so like in neuroscience people also use this analysis across different individuals", "tokens": [50788, 865, 11, 370, 411, 294, 42762, 561, 611, 764, 341, 5215, 2108, 819, 5346, 51100], "temperature": 0.0, "avg_logprob": -0.13864092145647322, "compression_ratio": 1.7240143369175627, "no_speech_prob": 0.012772741727530956}, {"id": 346, "seek": 146230, "start": 1477.02, "end": 1479.74, "text": " or different organisms or whatever.", "tokens": [51100, 420, 819, 22110, 420, 2035, 13, 51236], "temperature": 0.0, "avg_logprob": -0.13864092145647322, "compression_ratio": 1.7240143369175627, "no_speech_prob": 0.012772741727530956}, {"id": 347, "seek": 146230, "start": 1479.74, "end": 1484.62, "text": " It is a tool that people use in neuroscience as well, but I guess they're limited in the", "tokens": [51236, 467, 307, 257, 2290, 300, 561, 764, 294, 42762, 382, 731, 11, 457, 286, 2041, 436, 434, 5567, 294, 264, 51480], "temperature": 0.0, "avg_logprob": -0.13864092145647322, "compression_ratio": 1.7240143369175627, "no_speech_prob": 0.012772741727530956}, {"id": 348, "seek": 146230, "start": 1484.62, "end": 1490.06, "text": " ways in which they could manipulate the systems that are providing these representations.", "tokens": [51480, 2098, 294, 597, 436, 727, 20459, 264, 3652, 300, 366, 6530, 613, 33358, 13, 51752], "temperature": 0.0, "avg_logprob": -0.13864092145647322, "compression_ratio": 1.7240143369175627, "no_speech_prob": 0.012772741727530956}, {"id": 349, "seek": 149006, "start": 1490.06, "end": 1495.8999999999999, "text": " So in neuroscience, you're always constrained by data, so you can compare representations", "tokens": [50364, 407, 294, 42762, 11, 291, 434, 1009, 38901, 538, 1412, 11, 370, 291, 393, 6794, 33358, 50656], "temperature": 0.0, "avg_logprob": -0.14119739374838586, "compression_ratio": 1.7310344827586206, "no_speech_prob": 0.00043044559424743056}, {"id": 350, "seek": 149006, "start": 1495.8999999999999, "end": 1500.34, "text": " of images across individuals by doing MRI scans.", "tokens": [50656, 295, 5267, 2108, 5346, 538, 884, 32812, 35116, 13, 50878], "temperature": 0.0, "avg_logprob": -0.14119739374838586, "compression_ratio": 1.7310344827586206, "no_speech_prob": 0.00043044559424743056}, {"id": 351, "seek": 149006, "start": 1500.34, "end": 1505.02, "text": " But first of all, you might not get a very good idea of how the brain is representing", "tokens": [50878, 583, 700, 295, 439, 11, 291, 1062, 406, 483, 257, 588, 665, 1558, 295, 577, 264, 3567, 307, 13460, 51112], "temperature": 0.0, "avg_logprob": -0.14119739374838586, "compression_ratio": 1.7310344827586206, "no_speech_prob": 0.00043044559424743056}, {"id": 352, "seek": 149006, "start": 1505.02, "end": 1508.58, "text": " those images because there's a lot of noise in the MRI scan and there's a limit to how", "tokens": [51112, 729, 5267, 570, 456, 311, 257, 688, 295, 5658, 294, 264, 32812, 11049, 293, 456, 311, 257, 4948, 281, 577, 51290], "temperature": 0.0, "avg_logprob": -0.14119739374838586, "compression_ratio": 1.7310344827586206, "no_speech_prob": 0.00043044559424743056}, {"id": 353, "seek": 149006, "start": 1508.58, "end": 1513.98, "text": " long you can scan each person, whereas I guess in a neural network, noise is not a problem.", "tokens": [51290, 938, 291, 393, 11049, 1184, 954, 11, 9735, 286, 2041, 294, 257, 18161, 3209, 11, 5658, 307, 406, 257, 1154, 13, 51560], "temperature": 0.0, "avg_logprob": -0.14119739374838586, "compression_ratio": 1.7310344827586206, "no_speech_prob": 0.00043044559424743056}, {"id": 354, "seek": 149006, "start": 1513.98, "end": 1518.34, "text": " The entire system's deterministic, we just pass in the image and we get the representation", "tokens": [51560, 440, 2302, 1185, 311, 15957, 3142, 11, 321, 445, 1320, 294, 264, 3256, 293, 321, 483, 264, 10290, 51778], "temperature": 0.0, "avg_logprob": -0.14119739374838586, "compression_ratio": 1.7310344827586206, "no_speech_prob": 0.00043044559424743056}, {"id": 355, "seek": 149006, "start": 1518.34, "end": 1519.34, "text": " vector.", "tokens": [51778, 8062, 13, 51828], "temperature": 0.0, "avg_logprob": -0.14119739374838586, "compression_ratio": 1.7310344827586206, "no_speech_prob": 0.00043044559424743056}, {"id": 356, "seek": 151934, "start": 1519.4599999999998, "end": 1524.02, "text": " And you also have these kinds of limits of, like, we can't see what happens if people", "tokens": [50370, 400, 291, 611, 362, 613, 3685, 295, 10406, 295, 11, 411, 11, 321, 393, 380, 536, 437, 2314, 498, 561, 50598], "temperature": 0.0, "avg_logprob": -0.12701424956321716, "compression_ratio": 1.9772727272727273, "no_speech_prob": 0.0027124977204948664}, {"id": 357, "seek": 151934, "start": 1524.02, "end": 1529.5, "text": " have bigger brains, like we can't manipulate the architecture in those kinds of ways.", "tokens": [50598, 362, 3801, 15442, 11, 411, 321, 393, 380, 20459, 264, 9482, 294, 729, 3685, 295, 2098, 13, 50872], "temperature": 0.0, "avg_logprob": -0.12701424956321716, "compression_ratio": 1.9772727272727273, "no_speech_prob": 0.0027124977204948664}, {"id": 358, "seek": 151934, "start": 1529.5, "end": 1534.6599999999999, "text": " So even though we can look at how intact brains are working, we can't see how representations", "tokens": [50872, 407, 754, 1673, 321, 393, 574, 412, 577, 23493, 15442, 366, 1364, 11, 321, 393, 380, 536, 577, 33358, 51130], "temperature": 0.0, "avg_logprob": -0.12701424956321716, "compression_ratio": 1.9772727272727273, "no_speech_prob": 0.0027124977204948664}, {"id": 359, "seek": 151934, "start": 1534.6599999999999, "end": 1538.3799999999999, "text": " change when we manipulate them all that easily.", "tokens": [51130, 1319, 562, 321, 20459, 552, 439, 300, 3612, 13, 51316], "temperature": 0.0, "avg_logprob": -0.12701424956321716, "compression_ratio": 1.9772727272727273, "no_speech_prob": 0.0027124977204948664}, {"id": 360, "seek": 151934, "start": 1538.3799999999999, "end": 1542.34, "text": " And I guess, again, in machine learning, like we can do all of those things.", "tokens": [51316, 400, 286, 2041, 11, 797, 11, 294, 3479, 2539, 11, 411, 321, 393, 360, 439, 295, 729, 721, 13, 51514], "temperature": 0.0, "avg_logprob": -0.12701424956321716, "compression_ratio": 1.9772727272727273, "no_speech_prob": 0.0027124977204948664}, {"id": 361, "seek": 151934, "start": 1542.34, "end": 1545.22, "text": " We can look at what happens when we change the loss function.", "tokens": [51514, 492, 393, 574, 412, 437, 2314, 562, 321, 1319, 264, 4470, 2445, 13, 51658], "temperature": 0.0, "avg_logprob": -0.12701424956321716, "compression_ratio": 1.9772727272727273, "no_speech_prob": 0.0027124977204948664}, {"id": 362, "seek": 151934, "start": 1545.22, "end": 1548.6999999999998, "text": " We can look at what happens when we make the network deeper or wider.", "tokens": [51658, 492, 393, 574, 412, 437, 2314, 562, 321, 652, 264, 3209, 7731, 420, 11842, 13, 51832], "temperature": 0.0, "avg_logprob": -0.12701424956321716, "compression_ratio": 1.9772727272727273, "no_speech_prob": 0.0027124977204948664}, {"id": 363, "seek": 154870, "start": 1548.7, "end": 1554.14, "text": " So I think there are, like, some really cool ways that even the same techniques can be", "tokens": [50364, 407, 286, 519, 456, 366, 11, 411, 11, 512, 534, 1627, 2098, 300, 754, 264, 912, 7512, 393, 312, 50636], "temperature": 0.0, "avg_logprob": -0.15231289333767362, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.00015834438090678304}, {"id": 364, "seek": 154870, "start": 1554.14, "end": 1559.42, "text": " applied in machine learning that they couldn't be applied in neuroscience.", "tokens": [50636, 6456, 294, 3479, 2539, 300, 436, 2809, 380, 312, 6456, 294, 42762, 13, 50900], "temperature": 0.0, "avg_logprob": -0.15231289333767362, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.00015834438090678304}, {"id": 365, "seek": 154870, "start": 1559.42, "end": 1565.7, "text": " I felt like we weren't getting very far by trying to record from neurons in monkey's", "tokens": [50900, 286, 2762, 411, 321, 4999, 380, 1242, 588, 1400, 538, 1382, 281, 2136, 490, 22027, 294, 17847, 311, 51214], "temperature": 0.0, "avg_logprob": -0.15231289333767362, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.00015834438090678304}, {"id": 366, "seek": 154870, "start": 1565.7, "end": 1569.14, "text": " brains and figure out how those neurons work.", "tokens": [51214, 15442, 293, 2573, 484, 577, 729, 22027, 589, 13, 51386], "temperature": 0.0, "avg_logprob": -0.15231289333767362, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.00015834438090678304}, {"id": 367, "seek": 154870, "start": 1569.14, "end": 1575.02, "text": " Like it didn't really seem like a very effective way of figuring out how the brain constructs", "tokens": [51386, 1743, 309, 994, 380, 534, 1643, 411, 257, 588, 4942, 636, 295, 15213, 484, 577, 264, 3567, 7690, 82, 51680], "temperature": 0.0, "avg_logprob": -0.15231289333767362, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.00015834438090678304}, {"id": 368, "seek": 157502, "start": 1575.22, "end": 1578.9, "text": " this kind of internal representation of the world.", "tokens": [50374, 341, 733, 295, 6920, 10290, 295, 264, 1002, 13, 50558], "temperature": 0.0, "avg_logprob": -0.11282612800598145, "compression_ratio": 1.6319702602230484, "no_speech_prob": 0.0028874597046524286}, {"id": 369, "seek": 157502, "start": 1578.9, "end": 1584.46, "text": " So from there, I thought about what could we actually do to understand this?", "tokens": [50558, 407, 490, 456, 11, 286, 1194, 466, 437, 727, 321, 767, 360, 281, 1223, 341, 30, 50836], "temperature": 0.0, "avg_logprob": -0.11282612800598145, "compression_ratio": 1.6319702602230484, "no_speech_prob": 0.0028874597046524286}, {"id": 370, "seek": 157502, "start": 1584.46, "end": 1589.94, "text": " And it seemed like the most promising thing to do was to look at what happens in simpler", "tokens": [50836, 400, 309, 6576, 411, 264, 881, 20257, 551, 281, 360, 390, 281, 574, 412, 437, 2314, 294, 18587, 51110], "temperature": 0.0, "avg_logprob": -0.11282612800598145, "compression_ratio": 1.6319702602230484, "no_speech_prob": 0.0028874597046524286}, {"id": 371, "seek": 157502, "start": 1589.94, "end": 1595.54, "text": " systems that we can construct ourselves and where we can analyze the behavior of everything", "tokens": [51110, 3652, 300, 321, 393, 7690, 4175, 293, 689, 321, 393, 12477, 264, 5223, 295, 1203, 51390], "temperature": 0.0, "avg_logprob": -0.11282612800598145, "compression_ratio": 1.6319702602230484, "no_speech_prob": 0.0028874597046524286}, {"id": 372, "seek": 157502, "start": 1595.54, "end": 1596.98, "text": " inside the system.", "tokens": [51390, 1854, 264, 1185, 13, 51462], "temperature": 0.0, "avg_logprob": -0.11282612800598145, "compression_ratio": 1.6319702602230484, "no_speech_prob": 0.0028874597046524286}, {"id": 373, "seek": 157502, "start": 1596.98, "end": 1601.02, "text": " So in a neural network, we can record all the neurons, which is extremely challenging", "tokens": [51462, 407, 294, 257, 18161, 3209, 11, 321, 393, 2136, 439, 264, 22027, 11, 597, 307, 4664, 7595, 51664], "temperature": 0.0, "avg_logprob": -0.11282612800598145, "compression_ratio": 1.6319702602230484, "no_speech_prob": 0.0028874597046524286}, {"id": 374, "seek": 157502, "start": 1601.02, "end": 1602.9, "text": " in a biological organism.", "tokens": [51664, 294, 257, 13910, 24128, 13, 51758], "temperature": 0.0, "avg_logprob": -0.11282612800598145, "compression_ratio": 1.6319702602230484, "no_speech_prob": 0.0028874597046524286}, {"id": 375, "seek": 160290, "start": 1602.94, "end": 1608.1000000000001, "text": " And we can also manipulate the system in any kind of way that we can imagine.", "tokens": [50366, 400, 321, 393, 611, 20459, 264, 1185, 294, 604, 733, 295, 636, 300, 321, 393, 3811, 13, 50624], "temperature": 0.0, "avg_logprob": -0.0821943853655432, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0002779139031190425}, {"id": 376, "seek": 160290, "start": 1608.1000000000001, "end": 1611.7, "text": " But it still seems like really hard to understand neural networks.", "tokens": [50624, 583, 309, 920, 2544, 411, 534, 1152, 281, 1223, 18161, 9590, 13, 50804], "temperature": 0.0, "avg_logprob": -0.0821943853655432, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0002779139031190425}, {"id": 377, "seek": 160290, "start": 1611.7, "end": 1617.5, "text": " So it seemed like maybe this was a more tractable challenge and a challenge where maybe we could", "tokens": [50804, 407, 309, 6576, 411, 1310, 341, 390, 257, 544, 24207, 712, 3430, 293, 257, 3430, 689, 1310, 321, 727, 51094], "temperature": 0.0, "avg_logprob": -0.0821943853655432, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0002779139031190425}, {"id": 378, "seek": 160290, "start": 1617.5, "end": 1621.74, "text": " make some headway that might eventually translate back to brains.", "tokens": [51094, 652, 512, 1378, 676, 300, 1062, 4728, 13799, 646, 281, 15442, 13, 51306], "temperature": 0.0, "avg_logprob": -0.0821943853655432, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0002779139031190425}, {"id": 379, "seek": 160290, "start": 1621.74, "end": 1623.7800000000002, "text": " And so that's how I ended up in machine learning.", "tokens": [51306, 400, 370, 300, 311, 577, 286, 4590, 493, 294, 3479, 2539, 13, 51408], "temperature": 0.0, "avg_logprob": -0.0821943853655432, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0002779139031190425}, {"id": 380, "seek": 160290, "start": 1623.7800000000002, "end": 1626.74, "text": " I guess there are, like, other great things about machine learning.", "tokens": [51408, 286, 2041, 456, 366, 11, 411, 11, 661, 869, 721, 466, 3479, 2539, 13, 51556], "temperature": 0.0, "avg_logprob": -0.0821943853655432, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0002779139031190425}, {"id": 381, "seek": 160290, "start": 1626.74, "end": 1630.94, "text": " I guess the pay is much better than in, like, academic neuroscience.", "tokens": [51556, 286, 2041, 264, 1689, 307, 709, 1101, 813, 294, 11, 411, 11, 7778, 42762, 13, 51766], "temperature": 0.0, "avg_logprob": -0.0821943853655432, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0002779139031190425}, {"id": 382, "seek": 163094, "start": 1630.98, "end": 1636.18, "text": " But really, I think, like, it's a logical progression based on the ideas that I was", "tokens": [50366, 583, 534, 11, 286, 519, 11, 411, 11, 309, 311, 257, 14978, 18733, 2361, 322, 264, 3487, 300, 286, 390, 50626], "temperature": 0.0, "avg_logprob": -0.14342411144359693, "compression_ratio": 1.7276422764227641, "no_speech_prob": 0.0007665292359888554}, {"id": 383, "seek": 163094, "start": 1636.18, "end": 1637.02, "text": " interested in.", "tokens": [50626, 3102, 294, 13, 50668], "temperature": 0.0, "avg_logprob": -0.14342411144359693, "compression_ratio": 1.7276422764227641, "no_speech_prob": 0.0007665292359888554}, {"id": 384, "seek": 163094, "start": 1637.02, "end": 1641.54, "text": " And I am still interested in the same sorts of ideas.", "tokens": [50668, 400, 286, 669, 920, 3102, 294, 264, 912, 7527, 295, 3487, 13, 50894], "temperature": 0.0, "avg_logprob": -0.14342411144359693, "compression_ratio": 1.7276422764227641, "no_speech_prob": 0.0007665292359888554}, {"id": 385, "seek": 163094, "start": 1641.54, "end": 1647.7, "text": " Do you still think now that you're in machine learning and have made some progress here that", "tokens": [50894, 1144, 291, 920, 519, 586, 300, 291, 434, 294, 3479, 2539, 293, 362, 1027, 512, 4205, 510, 300, 51202], "temperature": 0.0, "avg_logprob": -0.14342411144359693, "compression_ratio": 1.7276422764227641, "no_speech_prob": 0.0007665292359888554}, {"id": 386, "seek": 163094, "start": 1647.7, "end": 1653.66, "text": " there is a good chance that we're going to map our knowledge that we gain back to the brain?", "tokens": [51202, 456, 307, 257, 665, 2931, 300, 321, 434, 516, 281, 4471, 527, 3601, 300, 321, 6052, 646, 281, 264, 3567, 30, 51500], "temperature": 0.0, "avg_logprob": -0.14342411144359693, "compression_ratio": 1.7276422764227641, "no_speech_prob": 0.0007665292359888554}, {"id": 387, "seek": 163094, "start": 1653.66, "end": 1658.38, "text": " Or do you think there is a bit of a disconnect?", "tokens": [51500, 1610, 360, 291, 519, 456, 307, 257, 857, 295, 257, 14299, 30, 51736], "temperature": 0.0, "avg_logprob": -0.14342411144359693, "compression_ratio": 1.7276422764227641, "no_speech_prob": 0.0007665292359888554}, {"id": 388, "seek": 163094, "start": 1658.38, "end": 1660.74, "text": " I think that's a really good question.", "tokens": [51736, 286, 519, 300, 311, 257, 534, 665, 1168, 13, 51854], "temperature": 0.0, "avg_logprob": -0.14342411144359693, "compression_ratio": 1.7276422764227641, "no_speech_prob": 0.0007665292359888554}, {"id": 389, "seek": 166074, "start": 1660.74, "end": 1665.38, "text": " I think there is definitely some knowledge that we're going to get from machine learning", "tokens": [50364, 286, 519, 456, 307, 2138, 512, 3601, 300, 321, 434, 516, 281, 483, 490, 3479, 2539, 50596], "temperature": 0.0, "avg_logprob": -0.09469650838976708, "compression_ratio": 1.8851063829787233, "no_speech_prob": 0.00018803743296302855}, {"id": 390, "seek": 166074, "start": 1665.38, "end": 1667.02, "text": " that will map back to the brain.", "tokens": [50596, 300, 486, 4471, 646, 281, 264, 3567, 13, 50678], "temperature": 0.0, "avg_logprob": -0.09469650838976708, "compression_ratio": 1.8851063829787233, "no_speech_prob": 0.00018803743296302855}, {"id": 391, "seek": 166074, "start": 1667.02, "end": 1672.38, "text": " I think, like, in terms of general principles and ways of looking at how, like, information", "tokens": [50678, 286, 519, 11, 411, 11, 294, 2115, 295, 2674, 9156, 293, 2098, 295, 1237, 412, 577, 11, 411, 11, 1589, 50946], "temperature": 0.0, "avg_logprob": -0.09469650838976708, "compression_ratio": 1.8851063829787233, "no_speech_prob": 0.00018803743296302855}, {"id": 392, "seek": 166074, "start": 1672.38, "end": 1678.22, "text": " processing systems work, I think there are a lot of ideas from machine learning that", "tokens": [50946, 9007, 3652, 589, 11, 286, 519, 456, 366, 257, 688, 295, 3487, 490, 3479, 2539, 300, 51238], "temperature": 0.0, "avg_logprob": -0.09469650838976708, "compression_ratio": 1.8851063829787233, "no_speech_prob": 0.00018803743296302855}, {"id": 393, "seek": 166074, "start": 1678.22, "end": 1681.42, "text": " will ultimately help us understand brains.", "tokens": [51238, 486, 6284, 854, 505, 1223, 15442, 13, 51398], "temperature": 0.0, "avg_logprob": -0.09469650838976708, "compression_ratio": 1.8851063829787233, "no_speech_prob": 0.00018803743296302855}, {"id": 394, "seek": 166074, "start": 1681.42, "end": 1686.78, "text": " I'm a little less sure whether we're going to build, like, a machine learning system", "tokens": [51398, 286, 478, 257, 707, 1570, 988, 1968, 321, 434, 516, 281, 1322, 11, 411, 11, 257, 3479, 2539, 1185, 51666], "temperature": 0.0, "avg_logprob": -0.09469650838976708, "compression_ratio": 1.8851063829787233, "no_speech_prob": 0.00018803743296302855}, {"id": 395, "seek": 166074, "start": 1686.78, "end": 1687.78, "text": " that is a brain.", "tokens": [51666, 300, 307, 257, 3567, 13, 51716], "temperature": 0.0, "avg_logprob": -0.09469650838976708, "compression_ratio": 1.8851063829787233, "no_speech_prob": 0.00018803743296302855}, {"id": 396, "seek": 168778, "start": 1687.78, "end": 1692.3799999999999, "text": " I think there's a disconnect between the way that the systems that we build work and", "tokens": [50364, 286, 519, 456, 311, 257, 14299, 1296, 264, 636, 300, 264, 3652, 300, 321, 1322, 589, 293, 50594], "temperature": 0.0, "avg_logprob": -0.10129879516305275, "compression_ratio": 1.9176954732510287, "no_speech_prob": 0.00029103236738592386}, {"id": 397, "seek": 168778, "start": 1692.3799999999999, "end": 1693.82, "text": " the way that biology works.", "tokens": [50594, 264, 636, 300, 14956, 1985, 13, 50666], "temperature": 0.0, "avg_logprob": -0.10129879516305275, "compression_ratio": 1.9176954732510287, "no_speech_prob": 0.00029103236738592386}, {"id": 398, "seek": 168778, "start": 1693.82, "end": 1697.98, "text": " And I think that's insurmountable just because there's differences between what you can", "tokens": [50666, 400, 286, 519, 300, 311, 1028, 26717, 792, 712, 445, 570, 456, 311, 7300, 1296, 437, 291, 393, 50874], "temperature": 0.0, "avg_logprob": -0.10129879516305275, "compression_ratio": 1.9176954732510287, "no_speech_prob": 0.00029103236738592386}, {"id": 399, "seek": 168778, "start": 1697.98, "end": 1703.22, "text": " build efficiently with cells and what you can build efficiently in silicon.", "tokens": [50874, 1322, 19621, 365, 5438, 293, 437, 291, 393, 1322, 19621, 294, 22848, 13, 51136], "temperature": 0.0, "avg_logprob": -0.10129879516305275, "compression_ratio": 1.9176954732510287, "no_speech_prob": 0.00029103236738592386}, {"id": 400, "seek": 168778, "start": 1703.22, "end": 1708.86, "text": " But in terms of approaches to understanding, in terms of building tools to understand things,", "tokens": [51136, 583, 294, 2115, 295, 11587, 281, 3701, 11, 294, 2115, 295, 2390, 3873, 281, 1223, 721, 11, 51418], "temperature": 0.0, "avg_logprob": -0.10129879516305275, "compression_ratio": 1.9176954732510287, "no_speech_prob": 0.00029103236738592386}, {"id": 401, "seek": 168778, "start": 1708.86, "end": 1714.66, "text": " the tools that we build in machine learning, I think will eventually be useful in neuroscience.", "tokens": [51418, 264, 3873, 300, 321, 1322, 294, 3479, 2539, 11, 286, 519, 486, 4728, 312, 4420, 294, 42762, 13, 51708], "temperature": 0.0, "avg_logprob": -0.10129879516305275, "compression_ratio": 1.9176954732510287, "no_speech_prob": 0.00029103236738592386}, {"id": 402, "seek": 171466, "start": 1714.66, "end": 1720.46, "text": " So people make a lot of analogies and they make a lot of claims about neuroscience in", "tokens": [50364, 407, 561, 652, 257, 688, 295, 16660, 530, 293, 436, 652, 257, 688, 295, 9441, 466, 42762, 294, 50654], "temperature": 0.0, "avg_logprob": -0.1449156309428968, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.058259982615709305}, {"id": 403, "seek": 171466, "start": 1720.46, "end": 1723.5400000000002, "text": " connections with neural networks.", "tokens": [50654, 9271, 365, 18161, 9590, 13, 50808], "temperature": 0.0, "avg_logprob": -0.1449156309428968, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.058259982615709305}, {"id": 404, "seek": 171466, "start": 1723.5400000000002, "end": 1728.1000000000001, "text": " Is there a statement or a bunch of statements that you hear over and over again where you", "tokens": [50808, 1119, 456, 257, 5629, 420, 257, 3840, 295, 12363, 300, 291, 1568, 670, 293, 670, 797, 689, 291, 51036], "temperature": 0.0, "avg_logprob": -0.1449156309428968, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.058259982615709305}, {"id": 405, "seek": 171466, "start": 1728.1000000000001, "end": 1731.5800000000002, "text": " just cringe because they're so wrong?", "tokens": [51036, 445, 47081, 570, 436, 434, 370, 2085, 30, 51210], "temperature": 0.0, "avg_logprob": -0.1449156309428968, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.058259982615709305}, {"id": 406, "seek": 171466, "start": 1731.5800000000002, "end": 1733.38, "text": " Is that something that happens to you?", "tokens": [51210, 1119, 300, 746, 300, 2314, 281, 291, 30, 51300], "temperature": 0.0, "avg_logprob": -0.1449156309428968, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.058259982615709305}, {"id": 407, "seek": 171466, "start": 1733.38, "end": 1735.3000000000002, "text": " I can imagine it would.", "tokens": [51300, 286, 393, 3811, 309, 576, 13, 51396], "temperature": 0.0, "avg_logprob": -0.1449156309428968, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.058259982615709305}, {"id": 408, "seek": 171466, "start": 1735.3000000000002, "end": 1736.3000000000002, "text": " Yeah.", "tokens": [51396, 865, 13, 51446], "temperature": 0.0, "avg_logprob": -0.1449156309428968, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.058259982615709305}, {"id": 409, "seek": 171466, "start": 1736.3000000000002, "end": 1737.3000000000002, "text": " Yeah.", "tokens": [51446, 865, 13, 51496], "temperature": 0.0, "avg_logprob": -0.1449156309428968, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.058259982615709305}, {"id": 410, "seek": 171466, "start": 1737.3000000000002, "end": 1741.14, "text": " So I think there's this, like, kind of basic fact that neural networks are inspired by", "tokens": [51496, 407, 286, 519, 456, 311, 341, 11, 411, 11, 733, 295, 3875, 1186, 300, 18161, 9590, 366, 7547, 538, 51688], "temperature": 0.0, "avg_logprob": -0.1449156309428968, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.058259982615709305}, {"id": 411, "seek": 171466, "start": 1741.14, "end": 1743.0600000000002, "text": " brains, which is true.", "tokens": [51688, 15442, 11, 597, 307, 2074, 13, 51784], "temperature": 0.0, "avg_logprob": -0.1449156309428968, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.058259982615709305}, {"id": 412, "seek": 174306, "start": 1743.06, "end": 1747.94, "text": " Then there's all this other stuff where people try to relate whatever neural network they've", "tokens": [50364, 1396, 456, 311, 439, 341, 661, 1507, 689, 561, 853, 281, 10961, 2035, 18161, 3209, 436, 600, 50608], "temperature": 0.0, "avg_logprob": -0.13773665257862636, "compression_ratio": 1.7984790874524714, "no_speech_prob": 0.0015967418439686298}, {"id": 413, "seek": 174306, "start": 1747.94, "end": 1751.7, "text": " built back to a brain and they say that it works like the brain, but it doesn't work", "tokens": [50608, 3094, 646, 281, 257, 3567, 293, 436, 584, 300, 309, 1985, 411, 264, 3567, 11, 457, 309, 1177, 380, 589, 50796], "temperature": 0.0, "avg_logprob": -0.13773665257862636, "compression_ratio": 1.7984790874524714, "no_speech_prob": 0.0015967418439686298}, {"id": 414, "seek": 174306, "start": 1751.7, "end": 1752.7, "text": " like the brain.", "tokens": [50796, 411, 264, 3567, 13, 50846], "temperature": 0.0, "avg_logprob": -0.13773665257862636, "compression_ratio": 1.7984790874524714, "no_speech_prob": 0.0015967418439686298}, {"id": 415, "seek": 174306, "start": 1752.7, "end": 1757.94, "text": " There's still this huge kind of disconnect in how the system is actually operating.", "tokens": [50846, 821, 311, 920, 341, 2603, 733, 295, 14299, 294, 577, 264, 1185, 307, 767, 7447, 13, 51108], "temperature": 0.0, "avg_logprob": -0.13773665257862636, "compression_ratio": 1.7984790874524714, "no_speech_prob": 0.0015967418439686298}, {"id": 416, "seek": 174306, "start": 1757.94, "end": 1760.5, "text": " The brain is not literally doing back prop.", "tokens": [51108, 440, 3567, 307, 406, 3736, 884, 646, 2365, 13, 51236], "temperature": 0.0, "avg_logprob": -0.13773665257862636, "compression_ratio": 1.7984790874524714, "no_speech_prob": 0.0015967418439686298}, {"id": 417, "seek": 174306, "start": 1760.5, "end": 1762.82, "text": " It might be doing something that's like back prop.", "tokens": [51236, 467, 1062, 312, 884, 746, 300, 311, 411, 646, 2365, 13, 51352], "temperature": 0.0, "avg_logprob": -0.13773665257862636, "compression_ratio": 1.7984790874524714, "no_speech_prob": 0.0015967418439686298}, {"id": 418, "seek": 174306, "start": 1762.82, "end": 1769.1, "text": " We still don't really know, but it's not literally computing gradients by automatic differentiation.", "tokens": [51352, 492, 920, 500, 380, 534, 458, 11, 457, 309, 311, 406, 3736, 15866, 2771, 2448, 538, 12509, 38902, 13, 51666], "temperature": 0.0, "avg_logprob": -0.13773665257862636, "compression_ratio": 1.7984790874524714, "no_speech_prob": 0.0015967418439686298}, {"id": 419, "seek": 176910, "start": 1769.1, "end": 1773.34, "text": " And I'm fascinated to talk about this line of reasoning that you have because you're", "tokens": [50364, 400, 286, 478, 24597, 281, 751, 466, 341, 1622, 295, 21577, 300, 291, 362, 570, 291, 434, 50576], "temperature": 0.0, "avg_logprob": -0.15050828072332567, "compression_ratio": 1.7753164556962024, "no_speech_prob": 0.46434614062309265}, {"id": 420, "seek": 176910, "start": 1773.34, "end": 1778.02, "text": " clearly the kind of guy that you want to reason about the behavior of models and in particular", "tokens": [50576, 4448, 264, 733, 295, 2146, 300, 291, 528, 281, 1778, 466, 264, 5223, 295, 5245, 293, 294, 1729, 50810], "temperature": 0.0, "avg_logprob": -0.15050828072332567, "compression_ratio": 1.7753164556962024, "no_speech_prob": 0.46434614062309265}, {"id": 421, "seek": 176910, "start": 1778.02, "end": 1780.2199999999998, "text": " the evolution of representations.", "tokens": [50810, 264, 9303, 295, 33358, 13, 50920], "temperature": 0.0, "avg_logprob": -0.15050828072332567, "compression_ratio": 1.7753164556962024, "no_speech_prob": 0.46434614062309265}, {"id": 422, "seek": 176910, "start": 1780.2199999999998, "end": 1783.3799999999999, "text": " And I watched one of your presentations on YouTube where you were talking about how you", "tokens": [50920, 400, 286, 6337, 472, 295, 428, 18964, 322, 3088, 689, 291, 645, 1417, 466, 577, 291, 51078], "temperature": 0.0, "avg_logprob": -0.15050828072332567, "compression_ratio": 1.7753164556962024, "no_speech_prob": 0.46434614062309265}, {"id": 423, "seek": 176910, "start": 1783.3799999999999, "end": 1786.62, "text": " can compare the representations by comparing features.", "tokens": [51078, 393, 6794, 264, 33358, 538, 15763, 4122, 13, 51240], "temperature": 0.0, "avg_logprob": -0.15050828072332567, "compression_ratio": 1.7753164556962024, "no_speech_prob": 0.46434614062309265}, {"id": 424, "seek": 176910, "start": 1786.62, "end": 1790.62, "text": " And of course, the naive way of doing is the dot product or some variations of that.", "tokens": [51240, 400, 295, 1164, 11, 264, 29052, 636, 295, 884, 307, 264, 5893, 1674, 420, 512, 17840, 295, 300, 13, 51440], "temperature": 0.0, "avg_logprob": -0.15050828072332567, "compression_ratio": 1.7753164556962024, "no_speech_prob": 0.46434614062309265}, {"id": 425, "seek": 176910, "start": 1790.62, "end": 1792.1, "text": " Turns out that doesn't work very well.", "tokens": [51440, 29524, 484, 300, 1177, 380, 589, 588, 731, 13, 51514], "temperature": 0.0, "avg_logprob": -0.15050828072332567, "compression_ratio": 1.7753164556962024, "no_speech_prob": 0.46434614062309265}, {"id": 426, "seek": 176910, "start": 1792.1, "end": 1797.4199999999998, "text": " And you came up with this wonderful metric called the centered kernel alignment.", "tokens": [51514, 400, 291, 1361, 493, 365, 341, 3715, 20678, 1219, 264, 18988, 28256, 18515, 13, 51780], "temperature": 0.0, "avg_logprob": -0.15050828072332567, "compression_ratio": 1.7753164556962024, "no_speech_prob": 0.46434614062309265}, {"id": 427, "seek": 179742, "start": 1797.42, "end": 1800.02, "text": " So how did that all come about?", "tokens": [50364, 407, 577, 630, 300, 439, 808, 466, 30, 50494], "temperature": 0.0, "avg_logprob": -0.12908579685069896, "compression_ratio": 1.7182539682539681, "no_speech_prob": 0.09248942136764526}, {"id": 428, "seek": 179742, "start": 1800.02, "end": 1806.42, "text": " The way we came up with that idea was that Jeff Hinton had another idea and I tried the", "tokens": [50494, 440, 636, 321, 1361, 493, 365, 300, 1558, 390, 300, 7506, 389, 12442, 632, 1071, 1558, 293, 286, 3031, 264, 50814], "temperature": 0.0, "avg_logprob": -0.12908579685069896, "compression_ratio": 1.7182539682539681, "no_speech_prob": 0.09248942136764526}, {"id": 429, "seek": 179742, "start": 1806.42, "end": 1811.8600000000001, "text": " idea and it worked, but then we wondered, is there a simpler thing that worked?", "tokens": [50814, 1558, 293, 309, 2732, 11, 457, 550, 321, 17055, 11, 307, 456, 257, 18587, 551, 300, 2732, 30, 51086], "temperature": 0.0, "avg_logprob": -0.12908579685069896, "compression_ratio": 1.7182539682539681, "no_speech_prob": 0.09248942136764526}, {"id": 430, "seek": 179742, "start": 1811.8600000000001, "end": 1814.3000000000002, "text": " And that's how we ended up with centered kernel alignment.", "tokens": [51086, 400, 300, 311, 577, 321, 4590, 493, 365, 18988, 28256, 18515, 13, 51208], "temperature": 0.0, "avg_logprob": -0.12908579685069896, "compression_ratio": 1.7182539682539681, "no_speech_prob": 0.09248942136764526}, {"id": 431, "seek": 179742, "start": 1814.3000000000002, "end": 1819.6200000000001, "text": " I guess the problem that we had in trying to come up with a way of comparing similarity", "tokens": [51208, 286, 2041, 264, 1154, 300, 321, 632, 294, 1382, 281, 808, 493, 365, 257, 636, 295, 15763, 32194, 51474], "temperature": 0.0, "avg_logprob": -0.12908579685069896, "compression_ratio": 1.7182539682539681, "no_speech_prob": 0.09248942136764526}, {"id": 432, "seek": 179742, "start": 1819.6200000000001, "end": 1824.8200000000002, "text": " of neural network representations is that it's really hard to know what is a good way.", "tokens": [51474, 295, 18161, 3209, 33358, 307, 300, 309, 311, 534, 1152, 281, 458, 437, 307, 257, 665, 636, 13, 51734], "temperature": 0.0, "avg_logprob": -0.12908579685069896, "compression_ratio": 1.7182539682539681, "no_speech_prob": 0.09248942136764526}, {"id": 433, "seek": 182482, "start": 1824.82, "end": 1828.78, "text": " Like it's not something where you can really develop a good benchmark.", "tokens": [50364, 1743, 309, 311, 406, 746, 689, 291, 393, 534, 1499, 257, 665, 18927, 13, 50562], "temperature": 0.0, "avg_logprob": -0.1413186228173411, "compression_ratio": 1.782006920415225, "no_speech_prob": 0.06178831681609154}, {"id": 434, "seek": 182482, "start": 1828.78, "end": 1834.3, "text": " So like in the paper, we came up with this simple sanity check where the idea is basically", "tokens": [50562, 407, 411, 294, 264, 3035, 11, 321, 1361, 493, 365, 341, 2199, 47892, 1520, 689, 264, 1558, 307, 1936, 50838], "temperature": 0.0, "avg_logprob": -0.1413186228173411, "compression_ratio": 1.782006920415225, "no_speech_prob": 0.06178831681609154}, {"id": 435, "seek": 182482, "start": 1834.3, "end": 1839.46, "text": " we've got two architecturally identical neural networks and we just train them from different", "tokens": [50838, 321, 600, 658, 732, 6331, 6512, 14800, 18161, 9590, 293, 321, 445, 3847, 552, 490, 819, 51096], "temperature": 0.0, "avg_logprob": -0.1413186228173411, "compression_ratio": 1.782006920415225, "no_speech_prob": 0.06178831681609154}, {"id": 436, "seek": 182482, "start": 1839.46, "end": 1841.26, "text": " random initializations.", "tokens": [51096, 4974, 5883, 14455, 13, 51186], "temperature": 0.0, "avg_logprob": -0.1413186228173411, "compression_ratio": 1.782006920415225, "no_speech_prob": 0.06178831681609154}, {"id": 437, "seek": 182482, "start": 1841.26, "end": 1845.7, "text": " And so we want it to be the case that if you measure like the similarity between a layer", "tokens": [51186, 400, 370, 321, 528, 309, 281, 312, 264, 1389, 300, 498, 291, 3481, 411, 264, 32194, 1296, 257, 4583, 51408], "temperature": 0.0, "avg_logprob": -0.1413186228173411, "compression_ratio": 1.782006920415225, "no_speech_prob": 0.06178831681609154}, {"id": 438, "seek": 182482, "start": 1845.7, "end": 1851.1, "text": " from network A and all the layers from network B, that the most similar layer in network", "tokens": [51408, 490, 3209, 316, 293, 439, 264, 7914, 490, 3209, 363, 11, 300, 264, 881, 2531, 4583, 294, 3209, 51678], "temperature": 0.0, "avg_logprob": -0.1413186228173411, "compression_ratio": 1.782006920415225, "no_speech_prob": 0.06178831681609154}, {"id": 439, "seek": 182482, "start": 1851.1, "end": 1853.82, "text": " B is going to be the architecturally corresponding layer.", "tokens": [51678, 363, 307, 516, 281, 312, 264, 6331, 6512, 11760, 4583, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1413186228173411, "compression_ratio": 1.782006920415225, "no_speech_prob": 0.06178831681609154}, {"id": 440, "seek": 185382, "start": 1853.82, "end": 1859.54, "text": " So if we have layer two from network A, it should be more similar to layer two from network", "tokens": [50364, 407, 498, 321, 362, 4583, 732, 490, 3209, 316, 11, 309, 820, 312, 544, 2531, 281, 4583, 732, 490, 3209, 50650], "temperature": 0.0, "avg_logprob": -0.1525363072310344, "compression_ratio": 1.8146551724137931, "no_speech_prob": 0.002547699958086014}, {"id": 441, "seek": 185382, "start": 1859.54, "end": 1862.4199999999998, "text": " B than layer three or layer four.", "tokens": [50650, 363, 813, 4583, 1045, 420, 4583, 1451, 13, 50794], "temperature": 0.0, "avg_logprob": -0.1525363072310344, "compression_ratio": 1.8146551724137931, "no_speech_prob": 0.002547699958086014}, {"id": 442, "seek": 185382, "start": 1862.4199999999998, "end": 1868.86, "text": " And so like basically we found that what people had been doing before didn't always pass that", "tokens": [50794, 400, 370, 411, 1936, 321, 1352, 300, 437, 561, 632, 668, 884, 949, 994, 380, 1009, 1320, 300, 51116], "temperature": 0.0, "avg_logprob": -0.1525363072310344, "compression_ratio": 1.8146551724137931, "no_speech_prob": 0.002547699958086014}, {"id": 443, "seek": 185382, "start": 1868.86, "end": 1870.3799999999999, "text": " sanity check.", "tokens": [51116, 47892, 1520, 13, 51192], "temperature": 0.0, "avg_logprob": -0.1525363072310344, "compression_ratio": 1.8146551724137931, "no_speech_prob": 0.002547699958086014}, {"id": 444, "seek": 185382, "start": 1870.3799999999999, "end": 1874.62, "text": " And we basically tried to come up with the simplest way of building a similarity index", "tokens": [51192, 400, 321, 1936, 3031, 281, 808, 493, 365, 264, 22811, 636, 295, 2390, 257, 32194, 8186, 51404], "temperature": 0.0, "avg_logprob": -0.1525363072310344, "compression_ratio": 1.8146551724137931, "no_speech_prob": 0.002547699958086014}, {"id": 445, "seek": 185382, "start": 1874.62, "end": 1877.58, "text": " that did actually pass that sanity check.", "tokens": [51404, 300, 630, 767, 1320, 300, 47892, 1520, 13, 51552], "temperature": 0.0, "avg_logprob": -0.1525363072310344, "compression_ratio": 1.8146551724137931, "no_speech_prob": 0.002547699958086014}, {"id": 446, "seek": 185382, "start": 1877.58, "end": 1880.02, "text": " And that's how we ended up with centered kernel alignment.", "tokens": [51552, 400, 300, 311, 577, 321, 4590, 493, 365, 18988, 28256, 18515, 13, 51674], "temperature": 0.0, "avg_logprob": -0.1525363072310344, "compression_ratio": 1.8146551724137931, "no_speech_prob": 0.002547699958086014}, {"id": 447, "seek": 188002, "start": 1881.02, "end": 1885.26, "text": " Yeah, because I think you showed that the canonical correlation analysis only worked", "tokens": [50414, 865, 11, 570, 286, 519, 291, 4712, 300, 264, 46491, 20009, 5215, 787, 2732, 50626], "temperature": 0.0, "avg_logprob": -0.19937928517659506, "compression_ratio": 1.6546762589928057, "no_speech_prob": 0.07930199801921844}, {"id": 448, "seek": 188002, "start": 1885.26, "end": 1887.94, "text": " about, I think at an accuracy of about 1.4%.", "tokens": [50626, 466, 11, 286, 519, 412, 364, 14170, 295, 466, 502, 13, 19, 6856, 50760], "temperature": 0.0, "avg_logprob": -0.19937928517659506, "compression_ratio": 1.6546762589928057, "no_speech_prob": 0.07930199801921844}, {"id": 449, "seek": 188002, "start": 1887.94, "end": 1890.22, "text": " So it's complete apples and oranges.", "tokens": [50760, 407, 309, 311, 3566, 16814, 293, 35474, 13, 50874], "temperature": 0.0, "avg_logprob": -0.19937928517659506, "compression_ratio": 1.6546762589928057, "no_speech_prob": 0.07930199801921844}, {"id": 450, "seek": 188002, "start": 1890.22, "end": 1894.18, "text": " But this absolutely fascinates me though, because when you plot this thing in this kind", "tokens": [50874, 583, 341, 3122, 7184, 259, 1024, 385, 1673, 11, 570, 562, 291, 7542, 341, 551, 294, 341, 733, 51072], "temperature": 0.0, "avg_logprob": -0.19937928517659506, "compression_ratio": 1.6546762589928057, "no_speech_prob": 0.07930199801921844}, {"id": 451, "seek": 188002, "start": 1894.18, "end": 1900.1, "text": " of self similarity matrix, you can glean so much about the evolution as a function of", "tokens": [51072, 295, 2698, 32194, 8141, 11, 291, 393, 290, 28499, 370, 709, 466, 264, 9303, 382, 257, 2445, 295, 51368], "temperature": 0.0, "avg_logprob": -0.19937928517659506, "compression_ratio": 1.6546762589928057, "no_speech_prob": 0.07930199801921844}, {"id": 452, "seek": 188002, "start": 1900.1, "end": 1901.1, "text": " time.", "tokens": [51368, 565, 13, 51418], "temperature": 0.0, "avg_logprob": -0.19937928517659506, "compression_ratio": 1.6546762589928057, "no_speech_prob": 0.07930199801921844}, {"id": 453, "seek": 188002, "start": 1901.1, "end": 1904.26, "text": " And because you talk about this in one of your other papers as well, that there's this", "tokens": [51418, 400, 570, 291, 751, 466, 341, 294, 472, 295, 428, 661, 10577, 382, 731, 11, 300, 456, 311, 341, 51576], "temperature": 0.0, "avg_logprob": -0.19937928517659506, "compression_ratio": 1.6546762589928057, "no_speech_prob": 0.07930199801921844}, {"id": 454, "seek": 188002, "start": 1904.26, "end": 1906.7, "text": " characteristic blockiness.", "tokens": [51576, 16282, 3461, 1324, 13, 51698], "temperature": 0.0, "avg_logprob": -0.19937928517659506, "compression_ratio": 1.6546762589928057, "no_speech_prob": 0.07930199801921844}, {"id": 455, "seek": 190670, "start": 1906.7, "end": 1912.78, "text": " And when you see blockiness, that successive layers are similar to versions of themselves", "tokens": [50364, 400, 562, 291, 536, 3461, 1324, 11, 300, 48043, 7914, 366, 2531, 281, 9606, 295, 2969, 50668], "temperature": 0.0, "avg_logprob": -0.13948901783336293, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.044416628777980804}, {"id": 456, "seek": 190670, "start": 1912.78, "end": 1914.14, "text": " in the past.", "tokens": [50668, 294, 264, 1791, 13, 50736], "temperature": 0.0, "avg_logprob": -0.13948901783336293, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.044416628777980804}, {"id": 457, "seek": 190670, "start": 1914.14, "end": 1917.7, "text": " And that kind of means that they're not evolving anymore.", "tokens": [50736, 400, 300, 733, 295, 1355, 300, 436, 434, 406, 21085, 3602, 13, 50914], "temperature": 0.0, "avg_logprob": -0.13948901783336293, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.044416628777980804}, {"id": 458, "seek": 190670, "start": 1917.7, "end": 1922.26, "text": " And you then made the intuition in your paper that, well, essentially it's redundant information.", "tokens": [50914, 400, 291, 550, 1027, 264, 24002, 294, 428, 3035, 300, 11, 731, 11, 4476, 309, 311, 40997, 1589, 13, 51142], "temperature": 0.0, "avg_logprob": -0.13948901783336293, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.044416628777980804}, {"id": 459, "seek": 190670, "start": 1922.26, "end": 1925.38, "text": " If it's not learning anything new, I can just delete that block.", "tokens": [51142, 759, 309, 311, 406, 2539, 1340, 777, 11, 286, 393, 445, 12097, 300, 3461, 13, 51298], "temperature": 0.0, "avg_logprob": -0.13948901783336293, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.044416628777980804}, {"id": 460, "seek": 190670, "start": 1925.38, "end": 1928.74, "text": " I can just delete those layers from the neural network and it won't make any difference.", "tokens": [51298, 286, 393, 445, 12097, 729, 7914, 490, 264, 18161, 3209, 293, 309, 1582, 380, 652, 604, 2649, 13, 51466], "temperature": 0.0, "avg_logprob": -0.13948901783336293, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.044416628777980804}, {"id": 461, "seek": 190670, "start": 1928.74, "end": 1930.54, "text": " And indeed it didn't.", "tokens": [51466, 400, 6451, 309, 994, 380, 13, 51556], "temperature": 0.0, "avg_logprob": -0.13948901783336293, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.044416628777980804}, {"id": 462, "seek": 190670, "start": 1930.54, "end": 1933.54, "text": " Yeah.", "tokens": [51556, 865, 13, 51706], "temperature": 0.0, "avg_logprob": -0.13948901783336293, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.044416628777980804}, {"id": 463, "seek": 193354, "start": 1933.54, "end": 1941.1, "text": " Could you, for people listening, explain the similarity measure you came up with in principle,", "tokens": [50364, 7497, 291, 11, 337, 561, 4764, 11, 2903, 264, 32194, 3481, 291, 1361, 493, 365, 294, 8665, 11, 50742], "temperature": 0.0, "avg_logprob": -0.19686792373657228, "compression_ratio": 1.6935483870967742, "no_speech_prob": 0.03562277927994728}, {"id": 464, "seek": 193354, "start": 1941.1, "end": 1945.18, "text": " just so we can imagine something, how that should even work?", "tokens": [50742, 445, 370, 321, 393, 3811, 746, 11, 577, 300, 820, 754, 589, 30, 50946], "temperature": 0.0, "avg_logprob": -0.19686792373657228, "compression_ratio": 1.6935483870967742, "no_speech_prob": 0.03562277927994728}, {"id": 465, "seek": 193354, "start": 1945.18, "end": 1946.18, "text": " Yeah.", "tokens": [50946, 865, 13, 50996], "temperature": 0.0, "avg_logprob": -0.19686792373657228, "compression_ratio": 1.6935483870967742, "no_speech_prob": 0.03562277927994728}, {"id": 466, "seek": 193354, "start": 1946.18, "end": 1951.62, "text": " So I guess the idea is you've got a neural network and you feed some set of examples,", "tokens": [50996, 407, 286, 2041, 264, 1558, 307, 291, 600, 658, 257, 18161, 3209, 293, 291, 3154, 512, 992, 295, 5110, 11, 51268], "temperature": 0.0, "avg_logprob": -0.19686792373657228, "compression_ratio": 1.6935483870967742, "no_speech_prob": 0.03562277927994728}, {"id": 467, "seek": 193354, "start": 1951.62, "end": 1953.8999999999999, "text": " like multiple examples through the neural network.", "tokens": [51268, 411, 3866, 5110, 807, 264, 18161, 3209, 13, 51382], "temperature": 0.0, "avg_logprob": -0.19686792373657228, "compression_ratio": 1.6935483870967742, "no_speech_prob": 0.03562277927994728}, {"id": 468, "seek": 193354, "start": 1953.8999999999999, "end": 1960.1, "text": " And now you've got some matrix where the rows of the matrix are different examples and the", "tokens": [51382, 400, 586, 291, 600, 658, 512, 8141, 689, 264, 13241, 295, 264, 8141, 366, 819, 5110, 293, 264, 51692], "temperature": 0.0, "avg_logprob": -0.19686792373657228, "compression_ratio": 1.6935483870967742, "no_speech_prob": 0.03562277927994728}, {"id": 469, "seek": 193354, "start": 1960.1, "end": 1962.82, "text": " columns are different neurons.", "tokens": [51692, 13766, 366, 819, 22027, 13, 51828], "temperature": 0.0, "avg_logprob": -0.19686792373657228, "compression_ratio": 1.6935483870967742, "no_speech_prob": 0.03562277927994728}, {"id": 470, "seek": 196282, "start": 1962.82, "end": 1967.9399999999998, "text": " So yeah, you can imagine this as if you have vectors of activations for each example, you've", "tokens": [50364, 407, 1338, 11, 291, 393, 3811, 341, 382, 498, 291, 362, 18875, 295, 2430, 763, 337, 1184, 1365, 11, 291, 600, 50620], "temperature": 0.0, "avg_logprob": -0.13772110627076337, "compression_ratio": 1.8150943396226416, "no_speech_prob": 0.0012838785769417882}, {"id": 471, "seek": 196282, "start": 1967.9399999999998, "end": 1970.46, "text": " stacked them real wise.", "tokens": [50620, 28867, 552, 957, 10829, 13, 50746], "temperature": 0.0, "avg_logprob": -0.13772110627076337, "compression_ratio": 1.8150943396226416, "no_speech_prob": 0.0012838785769417882}, {"id": 472, "seek": 196282, "start": 1970.46, "end": 1974.8999999999999, "text": " So now what do we do with that to compare two neural networks trained from different", "tokens": [50746, 407, 586, 437, 360, 321, 360, 365, 300, 281, 6794, 732, 18161, 9590, 8895, 490, 819, 50968], "temperature": 0.0, "avg_logprob": -0.13772110627076337, "compression_ratio": 1.8150943396226416, "no_speech_prob": 0.0012838785769417882}, {"id": 473, "seek": 196282, "start": 1974.8999999999999, "end": 1976.5, "text": " random initializations?", "tokens": [50968, 4974, 5883, 14455, 30, 51048], "temperature": 0.0, "avg_logprob": -0.13772110627076337, "compression_ratio": 1.8150943396226416, "no_speech_prob": 0.0012838785769417882}, {"id": 474, "seek": 196282, "start": 1976.5, "end": 1981.1399999999999, "text": " The problem is if we were to just take the square difference between those matrices,", "tokens": [51048, 440, 1154, 307, 498, 321, 645, 281, 445, 747, 264, 3732, 2649, 1296, 729, 32284, 11, 51280], "temperature": 0.0, "avg_logprob": -0.13772110627076337, "compression_ratio": 1.8150943396226416, "no_speech_prob": 0.0012838785769417882}, {"id": 475, "seek": 196282, "start": 1981.1399999999999, "end": 1986.78, "text": " we have this problem that the neurons between these two different networks aren't necessarily", "tokens": [51280, 321, 362, 341, 1154, 300, 264, 22027, 1296, 613, 732, 819, 9590, 3212, 380, 4725, 51562], "temperature": 0.0, "avg_logprob": -0.13772110627076337, "compression_ratio": 1.8150943396226416, "no_speech_prob": 0.0012838785769417882}, {"id": 476, "seek": 196282, "start": 1986.78, "end": 1990.5, "text": " aligned in any way if they're trained from different random initializations.", "tokens": [51562, 17962, 294, 604, 636, 498, 436, 434, 8895, 490, 819, 4974, 5883, 14455, 13, 51748], "temperature": 0.0, "avg_logprob": -0.13772110627076337, "compression_ratio": 1.8150943396226416, "no_speech_prob": 0.0012838785769417882}, {"id": 477, "seek": 199050, "start": 1990.5, "end": 1994.66, "text": " Even if we had exactly the same neurons, we shouldn't expect that neuron one would be", "tokens": [50364, 2754, 498, 321, 632, 2293, 264, 912, 22027, 11, 321, 4659, 380, 2066, 300, 34090, 472, 576, 312, 50572], "temperature": 0.0, "avg_logprob": -0.10899500900440001, "compression_ratio": 1.7443946188340806, "no_speech_prob": 0.0012063675094395876}, {"id": 478, "seek": 199050, "start": 1994.66, "end": 1998.42, "text": " the same, representing the same thing in both networks.", "tokens": [50572, 264, 912, 11, 13460, 264, 912, 551, 294, 1293, 9590, 13, 50760], "temperature": 0.0, "avg_logprob": -0.10899500900440001, "compression_ratio": 1.7443946188340806, "no_speech_prob": 0.0012063675094395876}, {"id": 479, "seek": 199050, "start": 1998.42, "end": 2001.18, "text": " So we need some way to get around that problem.", "tokens": [50760, 407, 321, 643, 512, 636, 281, 483, 926, 300, 1154, 13, 50898], "temperature": 0.0, "avg_logprob": -0.10899500900440001, "compression_ratio": 1.7443946188340806, "no_speech_prob": 0.0012063675094395876}, {"id": 480, "seek": 199050, "start": 2001.18, "end": 2008.86, "text": " One way around this problem is instead of comparing these original matrices, we're going", "tokens": [50898, 1485, 636, 926, 341, 1154, 307, 2602, 295, 15763, 613, 3380, 32284, 11, 321, 434, 516, 51282], "temperature": 0.0, "avg_logprob": -0.10899500900440001, "compression_ratio": 1.7443946188340806, "no_speech_prob": 0.0012063675094395876}, {"id": 481, "seek": 199050, "start": 2008.86, "end": 2014.82, "text": " to make matrices that measure the similarity of each example to each other example for", "tokens": [51282, 281, 652, 32284, 300, 3481, 264, 32194, 295, 1184, 1365, 281, 1184, 661, 1365, 337, 51580], "temperature": 0.0, "avg_logprob": -0.10899500900440001, "compression_ratio": 1.7443946188340806, "no_speech_prob": 0.0012063675094395876}, {"id": 482, "seek": 199050, "start": 2014.82, "end": 2017.42, "text": " one particular network.", "tokens": [51580, 472, 1729, 3209, 13, 51710], "temperature": 0.0, "avg_logprob": -0.10899500900440001, "compression_ratio": 1.7443946188340806, "no_speech_prob": 0.0012063675094395876}, {"id": 483, "seek": 201742, "start": 2017.42, "end": 2022.74, "text": " So if we've got example A and example B, we can measure their similarity very simply", "tokens": [50364, 407, 498, 321, 600, 658, 1365, 316, 293, 1365, 363, 11, 321, 393, 3481, 641, 32194, 588, 2935, 50630], "temperature": 0.0, "avg_logprob": -0.10115807664160635, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.00337517773732543}, {"id": 484, "seek": 201742, "start": 2022.74, "end": 2026.26, "text": " just by taking the dot product between those two vectors.", "tokens": [50630, 445, 538, 1940, 264, 5893, 1674, 1296, 729, 732, 18875, 13, 50806], "temperature": 0.0, "avg_logprob": -0.10115807664160635, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.00337517773732543}, {"id": 485, "seek": 201742, "start": 2026.26, "end": 2030.0600000000002, "text": " And now because we're measuring similarity from the same network, we don't have to worry", "tokens": [50806, 400, 586, 570, 321, 434, 13389, 32194, 490, 264, 912, 3209, 11, 321, 500, 380, 362, 281, 3292, 50996], "temperature": 0.0, "avg_logprob": -0.10115807664160635, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.00337517773732543}, {"id": 486, "seek": 201742, "start": 2030.0600000000002, "end": 2032.18, "text": " about this alignment problem.", "tokens": [50996, 466, 341, 18515, 1154, 13, 51102], "temperature": 0.0, "avg_logprob": -0.10115807664160635, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.00337517773732543}, {"id": 487, "seek": 201742, "start": 2032.18, "end": 2037.8600000000001, "text": " And we get some idea of how similar different examples are to each other according to the", "tokens": [51102, 400, 321, 483, 512, 1558, 295, 577, 2531, 819, 5110, 366, 281, 1184, 661, 4650, 281, 264, 51386], "temperature": 0.0, "avg_logprob": -0.10115807664160635, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.00337517773732543}, {"id": 488, "seek": 201742, "start": 2037.8600000000001, "end": 2043.1000000000001, "text": " representation in network A. So if we do that for all the examples, we get some examples", "tokens": [51386, 10290, 294, 3209, 316, 13, 407, 498, 321, 360, 300, 337, 439, 264, 5110, 11, 321, 483, 512, 5110, 51648], "temperature": 0.0, "avg_logprob": -0.10115807664160635, "compression_ratio": 1.7391304347826086, "no_speech_prob": 0.00337517773732543}, {"id": 489, "seek": 204310, "start": 2043.1, "end": 2045.3, "text": " by examples matrix.", "tokens": [50364, 538, 5110, 8141, 13, 50474], "temperature": 0.0, "avg_logprob": -0.08792582978593542, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.014498009346425533}, {"id": 490, "seek": 204310, "start": 2045.3, "end": 2049.66, "text": " And then we can do that both for our first network and for our second network.", "tokens": [50474, 400, 550, 321, 393, 360, 300, 1293, 337, 527, 700, 3209, 293, 337, 527, 1150, 3209, 13, 50692], "temperature": 0.0, "avg_logprob": -0.08792582978593542, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.014498009346425533}, {"id": 491, "seek": 204310, "start": 2049.66, "end": 2054.62, "text": " So after we've done that, we've got these two examples by examples matrices.", "tokens": [50692, 407, 934, 321, 600, 1096, 300, 11, 321, 600, 658, 613, 732, 5110, 538, 5110, 32284, 13, 50940], "temperature": 0.0, "avg_logprob": -0.08792582978593542, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.014498009346425533}, {"id": 492, "seek": 204310, "start": 2054.62, "end": 2059.7799999999997, "text": " And then the easy way to compare those matrices is we just reshape them to vectors and we", "tokens": [50940, 400, 550, 264, 1858, 636, 281, 6794, 729, 32284, 307, 321, 445, 725, 42406, 552, 281, 18875, 293, 321, 51198], "temperature": 0.0, "avg_logprob": -0.08792582978593542, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.014498009346425533}, {"id": 493, "seek": 204310, "start": 2059.7799999999997, "end": 2062.62, "text": " take the dot product again between those vectors.", "tokens": [51198, 747, 264, 5893, 1674, 797, 1296, 729, 18875, 13, 51340], "temperature": 0.0, "avg_logprob": -0.08792582978593542, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.014498009346425533}, {"id": 494, "seek": 204310, "start": 2062.62, "end": 2068.66, "text": " So now we've measured the similarities between the similarities of the examples.", "tokens": [51340, 407, 586, 321, 600, 12690, 264, 24197, 1296, 264, 24197, 295, 264, 5110, 13, 51642], "temperature": 0.0, "avg_logprob": -0.08792582978593542, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.014498009346425533}, {"id": 495, "seek": 206866, "start": 2068.66, "end": 2073.66, "text": " And this doesn't have this problem of aligning the neurons because instead of measuring similarities", "tokens": [50364, 400, 341, 1177, 380, 362, 341, 1154, 295, 419, 9676, 264, 22027, 570, 2602, 295, 13389, 24197, 50614], "temperature": 0.0, "avg_logprob": -0.11581034172238328, "compression_ratio": 1.9734848484848484, "no_speech_prob": 0.11107237637042999}, {"id": 496, "seek": 206866, "start": 2073.66, "end": 2077.7799999999997, "text": " of neurons, we're measuring similarities of examples and then we're comparing those", "tokens": [50614, 295, 22027, 11, 321, 434, 13389, 24197, 295, 5110, 293, 550, 321, 434, 15763, 729, 50820], "temperature": 0.0, "avg_logprob": -0.11581034172238328, "compression_ratio": 1.9734848484848484, "no_speech_prob": 0.11107237637042999}, {"id": 497, "seek": 206866, "start": 2077.7799999999997, "end": 2078.7799999999997, "text": " similarities.", "tokens": [50820, 24197, 13, 50870], "temperature": 0.0, "avg_logprob": -0.11581034172238328, "compression_ratio": 1.9734848484848484, "no_speech_prob": 0.11107237637042999}, {"id": 498, "seek": 206866, "start": 2078.7799999999997, "end": 2082.62, "text": " So ultimately, we do that, we take that dot product and then we normalize it in a way", "tokens": [50870, 407, 6284, 11, 321, 360, 300, 11, 321, 747, 300, 5893, 1674, 293, 550, 321, 2710, 1125, 309, 294, 257, 636, 51062], "temperature": 0.0, "avg_logprob": -0.11581034172238328, "compression_ratio": 1.9734848484848484, "no_speech_prob": 0.11107237637042999}, {"id": 499, "seek": 206866, "start": 2082.62, "end": 2085.02, "text": " that makes it invariant to scaling.", "tokens": [51062, 300, 1669, 309, 33270, 394, 281, 21589, 13, 51182], "temperature": 0.0, "avg_logprob": -0.11581034172238328, "compression_ratio": 1.9734848484848484, "no_speech_prob": 0.11107237637042999}, {"id": 500, "seek": 206866, "start": 2085.02, "end": 2090.42, "text": " So if you just took the dot product, you'd have this problem that scaling all of the", "tokens": [51182, 407, 498, 291, 445, 1890, 264, 5893, 1674, 11, 291, 1116, 362, 341, 1154, 300, 21589, 439, 295, 264, 51452], "temperature": 0.0, "avg_logprob": -0.11581034172238328, "compression_ratio": 1.9734848484848484, "no_speech_prob": 0.11107237637042999}, {"id": 501, "seek": 206866, "start": 2090.42, "end": 2095.42, "text": " features by some number, if you scale everything by a factor of two, the dot product will go", "tokens": [51452, 4122, 538, 512, 1230, 11, 498, 291, 4373, 1203, 538, 257, 5952, 295, 732, 11, 264, 5893, 1674, 486, 352, 51702], "temperature": 0.0, "avg_logprob": -0.11581034172238328, "compression_ratio": 1.9734848484848484, "no_speech_prob": 0.11107237637042999}, {"id": 502, "seek": 206866, "start": 2095.42, "end": 2097.3799999999997, "text": " up by a factor of two.", "tokens": [51702, 493, 538, 257, 5952, 295, 732, 13, 51800], "temperature": 0.0, "avg_logprob": -0.11581034172238328, "compression_ratio": 1.9734848484848484, "no_speech_prob": 0.11107237637042999}, {"id": 503, "seek": 209738, "start": 2097.38, "end": 2101.86, "text": " And so we just apply some normalization so that kind of scaling will not affect the similarity", "tokens": [50364, 400, 370, 321, 445, 3079, 512, 2710, 2144, 370, 300, 733, 295, 21589, 486, 406, 3345, 264, 32194, 50588], "temperature": 0.0, "avg_logprob": -0.1773768768310547, "compression_ratio": 1.647457627118644, "no_speech_prob": 0.0008820806979201734}, {"id": 504, "seek": 209738, "start": 2101.86, "end": 2108.42, "text": " index and we get centered kernel alignment, which gives us a similarity score between", "tokens": [50588, 8186, 293, 321, 483, 18988, 28256, 18515, 11, 597, 2709, 505, 257, 32194, 6175, 1296, 50916], "temperature": 0.0, "avg_logprob": -0.1773768768310547, "compression_ratio": 1.647457627118644, "no_speech_prob": 0.0008820806979201734}, {"id": 505, "seek": 209738, "start": 2108.42, "end": 2110.06, "text": " zero and one.", "tokens": [50916, 4018, 293, 472, 13, 50998], "temperature": 0.0, "avg_logprob": -0.1773768768310547, "compression_ratio": 1.647457627118644, "no_speech_prob": 0.0008820806979201734}, {"id": 506, "seek": 209738, "start": 2110.06, "end": 2113.46, "text": " The fascinating thing is that you can replace that dot product with a kernel because it's", "tokens": [50998, 440, 10343, 551, 307, 300, 291, 393, 7406, 300, 5893, 1674, 365, 257, 28256, 570, 309, 311, 51168], "temperature": 0.0, "avg_logprob": -0.1773768768310547, "compression_ratio": 1.647457627118644, "no_speech_prob": 0.0008820806979201734}, {"id": 507, "seek": 209738, "start": 2113.46, "end": 2114.58, "text": " a gram matrix.", "tokens": [51168, 257, 21353, 8141, 13, 51224], "temperature": 0.0, "avg_logprob": -0.1773768768310547, "compression_ratio": 1.647457627118644, "no_speech_prob": 0.0008820806979201734}, {"id": 508, "seek": 209738, "start": 2114.58, "end": 2115.58, "text": " Yeah.", "tokens": [51224, 865, 13, 51274], "temperature": 0.0, "avg_logprob": -0.1773768768310547, "compression_ratio": 1.647457627118644, "no_speech_prob": 0.0008820806979201734}, {"id": 509, "seek": 209738, "start": 2115.58, "end": 2119.9, "text": " So did you find that it made a difference if you use, let's say, the RBF kernel?", "tokens": [51274, 407, 630, 291, 915, 300, 309, 1027, 257, 2649, 498, 291, 764, 11, 718, 311, 584, 11, 264, 40302, 37, 28256, 30, 51490], "temperature": 0.0, "avg_logprob": -0.1773768768310547, "compression_ratio": 1.647457627118644, "no_speech_prob": 0.0008820806979201734}, {"id": 510, "seek": 209738, "start": 2119.9, "end": 2120.9, "text": " Yeah.", "tokens": [51490, 865, 13, 51540], "temperature": 0.0, "avg_logprob": -0.1773768768310547, "compression_ratio": 1.647457627118644, "no_speech_prob": 0.0008820806979201734}, {"id": 511, "seek": 209738, "start": 2120.9, "end": 2121.9, "text": " Yeah.", "tokens": [51540, 865, 13, 51590], "temperature": 0.0, "avg_logprob": -0.1773768768310547, "compression_ratio": 1.647457627118644, "no_speech_prob": 0.0008820806979201734}, {"id": 512, "seek": 209738, "start": 2121.9, "end": 2125.7000000000003, "text": " So, yeah, basically when we're measuring the similarities between examples, we can just", "tokens": [51590, 407, 11, 1338, 11, 1936, 562, 321, 434, 13389, 264, 24197, 1296, 5110, 11, 321, 393, 445, 51780], "temperature": 0.0, "avg_logprob": -0.1773768768310547, "compression_ratio": 1.647457627118644, "no_speech_prob": 0.0008820806979201734}, {"id": 513, "seek": 212570, "start": 2125.7, "end": 2129.18, "text": " instead of taking the dot product between the representations of the different examples,", "tokens": [50364, 2602, 295, 1940, 264, 5893, 1674, 1296, 264, 33358, 295, 264, 819, 5110, 11, 50538], "temperature": 0.0, "avg_logprob": -0.13351971280258312, "compression_ratio": 1.724907063197026, "no_speech_prob": 0.007340196054428816}, {"id": 514, "seek": 212570, "start": 2129.18, "end": 2133.8999999999996, "text": " we can take the kernel between one example and another example because the kernel is", "tokens": [50538, 321, 393, 747, 264, 28256, 1296, 472, 1365, 293, 1071, 1365, 570, 264, 28256, 307, 50774], "temperature": 0.0, "avg_logprob": -0.13351971280258312, "compression_ratio": 1.724907063197026, "no_speech_prob": 0.007340196054428816}, {"id": 515, "seek": 212570, "start": 2133.8999999999996, "end": 2136.46, "text": " also a way of measuring similarity.", "tokens": [50774, 611, 257, 636, 295, 13389, 32194, 13, 50902], "temperature": 0.0, "avg_logprob": -0.13351971280258312, "compression_ratio": 1.724907063197026, "no_speech_prob": 0.007340196054428816}, {"id": 516, "seek": 212570, "start": 2136.46, "end": 2138.62, "text": " And so we tried that.", "tokens": [50902, 400, 370, 321, 3031, 300, 13, 51010], "temperature": 0.0, "avg_logprob": -0.13351971280258312, "compression_ratio": 1.724907063197026, "no_speech_prob": 0.007340196054428816}, {"id": 517, "seek": 212570, "start": 2138.62, "end": 2141.9399999999996, "text": " It turns out that like for CNNs, it didn't really make a difference.", "tokens": [51010, 467, 4523, 484, 300, 411, 337, 24859, 82, 11, 309, 994, 380, 534, 652, 257, 2649, 13, 51176], "temperature": 0.0, "avg_logprob": -0.13351971280258312, "compression_ratio": 1.724907063197026, "no_speech_prob": 0.007340196054428816}, {"id": 518, "seek": 212570, "start": 2141.9399999999996, "end": 2146.3399999999997, "text": " Like the RBF kernel worked, but sort of just taking a regular dot product.", "tokens": [51176, 1743, 264, 40302, 37, 28256, 2732, 11, 457, 1333, 295, 445, 1940, 257, 3890, 5893, 1674, 13, 51396], "temperature": 0.0, "avg_logprob": -0.13351971280258312, "compression_ratio": 1.724907063197026, "no_speech_prob": 0.007340196054428816}, {"id": 519, "seek": 212570, "start": 2146.3399999999997, "end": 2152.2599999999998, "text": " But we did find in the appendix of that paper that if you instead use an RBF kernel with", "tokens": [51396, 583, 321, 630, 915, 294, 264, 34116, 970, 295, 300, 3035, 300, 498, 291, 2602, 764, 364, 40302, 37, 28256, 365, 51692], "temperature": 0.0, "avg_logprob": -0.13351971280258312, "compression_ratio": 1.724907063197026, "no_speech_prob": 0.007340196054428816}, {"id": 520, "seek": 215226, "start": 2152.26, "end": 2157.26, "text": " a transformer, it actually does work better than taking a normal dot product.", "tokens": [50364, 257, 31782, 11, 309, 767, 775, 589, 1101, 813, 1940, 257, 2710, 5893, 1674, 13, 50614], "temperature": 0.0, "avg_logprob": -0.11171957525876489, "compression_ratio": 1.78099173553719, "no_speech_prob": 0.005382641218602657}, {"id": 521, "seek": 215226, "start": 2157.26, "end": 2162.3, "text": " And I think like part of what's going on is that sometimes you want it to be the case", "tokens": [50614, 400, 286, 519, 411, 644, 295, 437, 311, 516, 322, 307, 300, 2171, 291, 528, 309, 281, 312, 264, 1389, 50866], "temperature": 0.0, "avg_logprob": -0.11171957525876489, "compression_ratio": 1.78099173553719, "no_speech_prob": 0.005382641218602657}, {"id": 522, "seek": 215226, "start": 2162.3, "end": 2168.3, "text": " that when you're measuring similarity, you care more about the distances between the", "tokens": [50866, 300, 562, 291, 434, 13389, 32194, 11, 291, 1127, 544, 466, 264, 22182, 1296, 264, 51166], "temperature": 0.0, "avg_logprob": -0.11171957525876489, "compression_ratio": 1.78099173553719, "no_speech_prob": 0.005382641218602657}, {"id": 523, "seek": 215226, "start": 2168.3, "end": 2173.5400000000004, "text": " examples that you're close to than the distances to the examples that you're far away from.", "tokens": [51166, 5110, 300, 291, 434, 1998, 281, 813, 264, 22182, 281, 264, 5110, 300, 291, 434, 1400, 1314, 490, 13, 51428], "temperature": 0.0, "avg_logprob": -0.11171957525876489, "compression_ratio": 1.78099173553719, "no_speech_prob": 0.005382641218602657}, {"id": 524, "seek": 215226, "start": 2173.5400000000004, "end": 2178.26, "text": " Like once you're really far away from something, maybe it doesn't matter so much if you're", "tokens": [51428, 1743, 1564, 291, 434, 534, 1400, 1314, 490, 746, 11, 1310, 309, 1177, 380, 1871, 370, 709, 498, 291, 434, 51664], "temperature": 0.0, "avg_logprob": -0.11171957525876489, "compression_ratio": 1.78099173553719, "no_speech_prob": 0.005382641218602657}, {"id": 525, "seek": 217826, "start": 2178.26, "end": 2184.9, "text": " 10 times as far away because like you're already so far, you're already not going to...", "tokens": [50364, 1266, 1413, 382, 1400, 1314, 570, 411, 291, 434, 1217, 370, 1400, 11, 291, 434, 1217, 406, 516, 281, 485, 50696], "temperature": 0.0, "avg_logprob": -0.11812669328115519, "compression_ratio": 1.619607843137255, "no_speech_prob": 0.058231648057699203}, {"id": 526, "seek": 217826, "start": 2184.9, "end": 2190.38, "text": " You don't really care how far away something is once you're far enough.", "tokens": [50696, 509, 500, 380, 534, 1127, 577, 1400, 1314, 746, 307, 1564, 291, 434, 1400, 1547, 13, 50970], "temperature": 0.0, "avg_logprob": -0.11812669328115519, "compression_ratio": 1.619607843137255, "no_speech_prob": 0.058231648057699203}, {"id": 527, "seek": 217826, "start": 2190.38, "end": 2194.98, "text": " And the RBF kernel takes that into account in a way that a linear dot product wouldn't.", "tokens": [50970, 400, 264, 40302, 37, 28256, 2516, 300, 666, 2696, 294, 257, 636, 300, 257, 8213, 5893, 1674, 2759, 380, 13, 51200], "temperature": 0.0, "avg_logprob": -0.11812669328115519, "compression_ratio": 1.619607843137255, "no_speech_prob": 0.058231648057699203}, {"id": 528, "seek": 217826, "start": 2194.98, "end": 2203.6600000000003, "text": " The linear dot product is like very sensitive to the global distances in the space.", "tokens": [51200, 440, 8213, 5893, 1674, 307, 411, 588, 9477, 281, 264, 4338, 22182, 294, 264, 1901, 13, 51634], "temperature": 0.0, "avg_logprob": -0.11812669328115519, "compression_ratio": 1.619607843137255, "no_speech_prob": 0.058231648057699203}, {"id": 529, "seek": 217826, "start": 2203.6600000000003, "end": 2207.0200000000004, "text": " What I find fascinating is that you can glean so much from the blockiness, right?", "tokens": [51634, 708, 286, 915, 10343, 307, 300, 291, 393, 290, 28499, 370, 709, 490, 264, 3461, 1324, 11, 558, 30, 51802], "temperature": 0.0, "avg_logprob": -0.11812669328115519, "compression_ratio": 1.619607843137255, "no_speech_prob": 0.058231648057699203}, {"id": 530, "seek": 220702, "start": 2207.02, "end": 2211.38, "text": " So you are saying that as it becomes blockier, it might be an indication that it's become", "tokens": [50364, 407, 291, 366, 1566, 300, 382, 309, 3643, 3461, 811, 11, 309, 1062, 312, 364, 18877, 300, 309, 311, 1813, 50582], "temperature": 0.0, "avg_logprob": -0.13829348882039388, "compression_ratio": 1.8274647887323943, "no_speech_prob": 0.29331228137016296}, {"id": 531, "seek": 220702, "start": 2211.38, "end": 2213.7, "text": " saturated in some sense.", "tokens": [50582, 25408, 294, 512, 2020, 13, 50698], "temperature": 0.0, "avg_logprob": -0.13829348882039388, "compression_ratio": 1.8274647887323943, "no_speech_prob": 0.29331228137016296}, {"id": 532, "seek": 220702, "start": 2213.7, "end": 2219.94, "text": " And I'm also interested in a way, we already know that the representations in neural networks", "tokens": [50698, 400, 286, 478, 611, 3102, 294, 257, 636, 11, 321, 1217, 458, 300, 264, 33358, 294, 18161, 9590, 51010], "temperature": 0.0, "avg_logprob": -0.13829348882039388, "compression_ratio": 1.8274647887323943, "no_speech_prob": 0.29331228137016296}, {"id": 533, "seek": 220702, "start": 2219.94, "end": 2223.5, "text": " are increasingly abstract, so they don't necessarily bear any resemblance to the beginning.", "tokens": [51010, 366, 12980, 12649, 11, 370, 436, 500, 380, 4725, 6155, 604, 20695, 37271, 281, 264, 2863, 13, 51188], "temperature": 0.0, "avg_logprob": -0.13829348882039388, "compression_ratio": 1.8274647887323943, "no_speech_prob": 0.29331228137016296}, {"id": 534, "seek": 220702, "start": 2223.5, "end": 2228.2599999999998, "text": " So when we're looking at the cell similarity matrix, we don't necessarily want the representations", "tokens": [51188, 407, 562, 321, 434, 1237, 412, 264, 2815, 32194, 8141, 11, 321, 500, 380, 4725, 528, 264, 33358, 51426], "temperature": 0.0, "avg_logprob": -0.13829348882039388, "compression_ratio": 1.8274647887323943, "no_speech_prob": 0.29331228137016296}, {"id": 535, "seek": 220702, "start": 2228.2599999999998, "end": 2232.34, "text": " on the final penultimate layers to be similar to the ones at the beginning.", "tokens": [51426, 322, 264, 2572, 3435, 723, 2905, 7914, 281, 312, 2531, 281, 264, 2306, 412, 264, 2863, 13, 51630], "temperature": 0.0, "avg_logprob": -0.13829348882039388, "compression_ratio": 1.8274647887323943, "no_speech_prob": 0.29331228137016296}, {"id": 536, "seek": 220702, "start": 2232.34, "end": 2235.2599999999998, "text": " We want there to be a continuous evolution.", "tokens": [51630, 492, 528, 456, 281, 312, 257, 10957, 9303, 13, 51776], "temperature": 0.0, "avg_logprob": -0.13829348882039388, "compression_ratio": 1.8274647887323943, "no_speech_prob": 0.29331228137016296}, {"id": 537, "seek": 223526, "start": 2235.26, "end": 2240.1800000000003, "text": " We don't want to have a stalled evolution because that would correspond to this blockiness.", "tokens": [50364, 492, 500, 380, 528, 281, 362, 257, 342, 8907, 9303, 570, 300, 576, 6805, 281, 341, 3461, 1324, 13, 50610], "temperature": 0.0, "avg_logprob": -0.14234802050468248, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.006368521600961685}, {"id": 538, "seek": 223526, "start": 2240.1800000000003, "end": 2245.94, "text": " But is it when you've stalled for a long time, is that when it becomes pathological?", "tokens": [50610, 583, 307, 309, 562, 291, 600, 342, 8907, 337, 257, 938, 565, 11, 307, 300, 562, 309, 3643, 3100, 4383, 30, 50898], "temperature": 0.0, "avg_logprob": -0.14234802050468248, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.006368521600961685}, {"id": 539, "seek": 223526, "start": 2245.94, "end": 2249.38, "text": " Because we want it to evolve in stops and starts, don't we?", "tokens": [50898, 1436, 321, 528, 309, 281, 16693, 294, 10094, 293, 3719, 11, 500, 380, 321, 30, 51070], "temperature": 0.0, "avg_logprob": -0.14234802050468248, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.006368521600961685}, {"id": 540, "seek": 223526, "start": 2249.38, "end": 2250.38, "text": " Yeah.", "tokens": [51070, 865, 13, 51120], "temperature": 0.0, "avg_logprob": -0.14234802050468248, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.006368521600961685}, {"id": 541, "seek": 223526, "start": 2250.38, "end": 2255.5, "text": " I think it's not clear what we should really expect in terms of how a neural network representation", "tokens": [51120, 286, 519, 309, 311, 406, 1850, 437, 321, 820, 534, 2066, 294, 2115, 295, 577, 257, 18161, 3209, 10290, 51376], "temperature": 0.0, "avg_logprob": -0.14234802050468248, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.006368521600961685}, {"id": 542, "seek": 223526, "start": 2255.5, "end": 2257.0600000000004, "text": " evolves through the layers.", "tokens": [51376, 43737, 807, 264, 7914, 13, 51454], "temperature": 0.0, "avg_logprob": -0.14234802050468248, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.006368521600961685}, {"id": 543, "seek": 223526, "start": 2257.0600000000004, "end": 2262.34, "text": " I think there's kind of some theory on what we should expect if all the layers are linear.", "tokens": [51454, 286, 519, 456, 311, 733, 295, 512, 5261, 322, 437, 321, 820, 2066, 498, 439, 264, 7914, 366, 8213, 13, 51718], "temperature": 0.0, "avg_logprob": -0.14234802050468248, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.006368521600961685}, {"id": 544, "seek": 226234, "start": 2262.34, "end": 2266.78, "text": " But obviously, the neural networks that we train are nonlinear, and it's really important", "tokens": [50364, 583, 2745, 11, 264, 18161, 9590, 300, 321, 3847, 366, 2107, 28263, 11, 293, 309, 311, 534, 1021, 50586], "temperature": 0.0, "avg_logprob": -0.12918939663253667, "compression_ratio": 1.8687943262411348, "no_speech_prob": 0.0033746855333447456}, {"id": 545, "seek": 226234, "start": 2266.78, "end": 2269.38, "text": " to have a nonlinearity in between the layers.", "tokens": [50586, 281, 362, 257, 2107, 1889, 17409, 294, 1296, 264, 7914, 13, 50716], "temperature": 0.0, "avg_logprob": -0.12918939663253667, "compression_ratio": 1.8687943262411348, "no_speech_prob": 0.0033746855333447456}, {"id": 546, "seek": 226234, "start": 2269.38, "end": 2274.1800000000003, "text": " And so at that point, it's really hard to reason about what the optimal thing for a", "tokens": [50716, 400, 370, 412, 300, 935, 11, 309, 311, 534, 1152, 281, 1778, 466, 437, 264, 16252, 551, 337, 257, 50956], "temperature": 0.0, "avg_logprob": -0.12918939663253667, "compression_ratio": 1.8687943262411348, "no_speech_prob": 0.0033746855333447456}, {"id": 547, "seek": 226234, "start": 2274.1800000000003, "end": 2276.7000000000003, "text": " neural network to do actually is.", "tokens": [50956, 18161, 3209, 281, 360, 767, 307, 13, 51082], "temperature": 0.0, "avg_logprob": -0.12918939663253667, "compression_ratio": 1.8687943262411348, "no_speech_prob": 0.0033746855333447456}, {"id": 548, "seek": 226234, "start": 2276.7000000000003, "end": 2280.1800000000003, "text": " I think it's something that we can really only study empirically.", "tokens": [51082, 286, 519, 309, 311, 746, 300, 321, 393, 534, 787, 2979, 25790, 984, 13, 51256], "temperature": 0.0, "avg_logprob": -0.12918939663253667, "compression_ratio": 1.8687943262411348, "no_speech_prob": 0.0033746855333447456}, {"id": 549, "seek": 226234, "start": 2280.1800000000003, "end": 2284.2200000000003, "text": " On the other hand, I do think if we see that nothing is changing from one layer to the", "tokens": [51256, 1282, 264, 661, 1011, 11, 286, 360, 519, 498, 321, 536, 300, 1825, 307, 4473, 490, 472, 4583, 281, 264, 51458], "temperature": 0.0, "avg_logprob": -0.12918939663253667, "compression_ratio": 1.8687943262411348, "no_speech_prob": 0.0033746855333447456}, {"id": 550, "seek": 226234, "start": 2284.2200000000003, "end": 2286.82, "text": " next, that's a really bad sign.", "tokens": [51458, 958, 11, 300, 311, 257, 534, 1578, 1465, 13, 51588], "temperature": 0.0, "avg_logprob": -0.12918939663253667, "compression_ratio": 1.8687943262411348, "no_speech_prob": 0.0033746855333447456}, {"id": 551, "seek": 226234, "start": 2286.82, "end": 2290.7000000000003, "text": " If the neural network representation isn't changing, then obviously nothing's happening.", "tokens": [51588, 759, 264, 18161, 3209, 10290, 1943, 380, 4473, 11, 550, 2745, 1825, 311, 2737, 13, 51782], "temperature": 0.0, "avg_logprob": -0.12918939663253667, "compression_ratio": 1.8687943262411348, "no_speech_prob": 0.0033746855333447456}, {"id": 552, "seek": 229070, "start": 2290.7, "end": 2295.54, "text": " But I guess it's unclear whether we should expect abrupt shifts or we want things to", "tokens": [50364, 583, 286, 2041, 309, 311, 25636, 1968, 321, 820, 2066, 33401, 19201, 420, 321, 528, 721, 281, 50606], "temperature": 0.0, "avg_logprob": -0.12375136288729581, "compression_ratio": 1.6895306859205776, "no_speech_prob": 0.009678106755018234}, {"id": 553, "seek": 229070, "start": 2295.54, "end": 2297.3799999999997, "text": " happen slowly between the layers.", "tokens": [50606, 1051, 5692, 1296, 264, 7914, 13, 50698], "temperature": 0.0, "avg_logprob": -0.12375136288729581, "compression_ratio": 1.6895306859205776, "no_speech_prob": 0.009678106755018234}, {"id": 554, "seek": 229070, "start": 2297.3799999999997, "end": 2302.7, "text": " I'm not sure whether we really have the theoretical knowledge to say what is best.", "tokens": [50698, 286, 478, 406, 988, 1968, 321, 534, 362, 264, 20864, 3601, 281, 584, 437, 307, 1151, 13, 50964], "temperature": 0.0, "avg_logprob": -0.12375136288729581, "compression_ratio": 1.6895306859205776, "no_speech_prob": 0.009678106755018234}, {"id": 555, "seek": 229070, "start": 2302.7, "end": 2303.7, "text": " Yeah.", "tokens": [50964, 865, 13, 51014], "temperature": 0.0, "avg_logprob": -0.12375136288729581, "compression_ratio": 1.6895306859205776, "no_speech_prob": 0.009678106755018234}, {"id": 556, "seek": 229070, "start": 2303.7, "end": 2307.9399999999996, "text": " I'd love to see this as a kind of tool in our toolbox that we could use on different network", "tokens": [51014, 286, 1116, 959, 281, 536, 341, 382, 257, 733, 295, 2290, 294, 527, 44593, 300, 321, 727, 764, 322, 819, 3209, 51226], "temperature": 0.0, "avg_logprob": -0.12375136288729581, "compression_ratio": 1.6895306859205776, "no_speech_prob": 0.009678106755018234}, {"id": 557, "seek": 229070, "start": 2307.9399999999996, "end": 2308.9399999999996, "text": " architectures.", "tokens": [51226, 6331, 1303, 13, 51276], "temperature": 0.0, "avg_logprob": -0.12375136288729581, "compression_ratio": 1.6895306859205776, "no_speech_prob": 0.009678106755018234}, {"id": 558, "seek": 229070, "start": 2308.9399999999996, "end": 2312.7799999999997, "text": " But you said that the other learn features are shared across different initializations", "tokens": [51276, 583, 291, 848, 300, 264, 661, 1466, 4122, 366, 5507, 2108, 819, 5883, 14455, 51468], "temperature": 0.0, "avg_logprob": -0.12375136288729581, "compression_ratio": 1.6895306859205776, "no_speech_prob": 0.009678106755018234}, {"id": 559, "seek": 229070, "start": 2312.7799999999997, "end": 2316.2999999999997, "text": " and architectures, particularly across the depths of the network.", "tokens": [51468, 293, 6331, 1303, 11, 4098, 2108, 264, 28439, 295, 264, 3209, 13, 51644], "temperature": 0.0, "avg_logprob": -0.12375136288729581, "compression_ratio": 1.6895306859205776, "no_speech_prob": 0.009678106755018234}, {"id": 560, "seek": 231630, "start": 2316.3, "end": 2322.38, "text": " So it almost seems as if this blockiness is separate to your work in wide and deep neural", "tokens": [50364, 407, 309, 1920, 2544, 382, 498, 341, 3461, 1324, 307, 4994, 281, 428, 589, 294, 4874, 293, 2452, 18161, 50668], "temperature": 0.0, "avg_logprob": -0.135070742731509, "compression_ratio": 1.7883211678832116, "no_speech_prob": 0.016889750957489014}, {"id": 561, "seek": 231630, "start": 2322.38, "end": 2325.9, "text": " networks because you showed that the width and the depth have got different effects on", "tokens": [50668, 9590, 570, 291, 4712, 300, 264, 11402, 293, 264, 7161, 362, 658, 819, 5065, 322, 50844], "temperature": 0.0, "avg_logprob": -0.135070742731509, "compression_ratio": 1.7883211678832116, "no_speech_prob": 0.016889750957489014}, {"id": 562, "seek": 231630, "start": 2325.9, "end": 2329.6200000000003, "text": " network predictions at the example level or at the class level.", "tokens": [50844, 3209, 21264, 412, 264, 1365, 1496, 420, 412, 264, 1508, 1496, 13, 51030], "temperature": 0.0, "avg_logprob": -0.135070742731509, "compression_ratio": 1.7883211678832116, "no_speech_prob": 0.016889750957489014}, {"id": 563, "seek": 231630, "start": 2329.6200000000003, "end": 2332.1400000000003, "text": " But the blockiness almost seems to be an orthogonal thing.", "tokens": [51030, 583, 264, 3461, 1324, 1920, 2544, 281, 312, 364, 41488, 551, 13, 51156], "temperature": 0.0, "avg_logprob": -0.135070742731509, "compression_ratio": 1.7883211678832116, "no_speech_prob": 0.016889750957489014}, {"id": 564, "seek": 231630, "start": 2332.1400000000003, "end": 2336.42, "text": " That's just when you have this kind of saturation of the network, you see the blockiness.", "tokens": [51156, 663, 311, 445, 562, 291, 362, 341, 733, 295, 27090, 295, 264, 3209, 11, 291, 536, 264, 3461, 1324, 13, 51370], "temperature": 0.0, "avg_logprob": -0.135070742731509, "compression_ratio": 1.7883211678832116, "no_speech_prob": 0.016889750957489014}, {"id": 565, "seek": 231630, "start": 2336.42, "end": 2337.42, "text": " Yeah.", "tokens": [51370, 865, 13, 51420], "temperature": 0.0, "avg_logprob": -0.135070742731509, "compression_ratio": 1.7883211678832116, "no_speech_prob": 0.016889750957489014}, {"id": 566, "seek": 231630, "start": 2337.42, "end": 2338.42, "text": " Yeah.", "tokens": [51420, 865, 13, 51470], "temperature": 0.0, "avg_logprob": -0.135070742731509, "compression_ratio": 1.7883211678832116, "no_speech_prob": 0.016889750957489014}, {"id": 567, "seek": 231630, "start": 2338.42, "end": 2342.98, "text": " So initially we had hoped that we could look at other similarities between wide networks", "tokens": [51470, 407, 9105, 321, 632, 19737, 300, 321, 727, 574, 412, 661, 24197, 1296, 4874, 9590, 51698], "temperature": 0.0, "avg_logprob": -0.135070742731509, "compression_ratio": 1.7883211678832116, "no_speech_prob": 0.016889750957489014}, {"id": 568, "seek": 234298, "start": 2342.98, "end": 2346.18, "text": " and deep networks in their representations.", "tokens": [50364, 293, 2452, 9590, 294, 641, 33358, 13, 50524], "temperature": 0.0, "avg_logprob": -0.13786021450109648, "compression_ratio": 1.9884169884169884, "no_speech_prob": 0.024397803470492363}, {"id": 569, "seek": 234298, "start": 2346.18, "end": 2349.62, "text": " But like when we did those experiments, we actually just found that if you make the network", "tokens": [50524, 583, 411, 562, 321, 630, 729, 12050, 11, 321, 767, 445, 1352, 300, 498, 291, 652, 264, 3209, 50696], "temperature": 0.0, "avg_logprob": -0.13786021450109648, "compression_ratio": 1.9884169884169884, "no_speech_prob": 0.024397803470492363}, {"id": 570, "seek": 234298, "start": 2349.62, "end": 2354.14, "text": " really wide, you get this kind of blockiness in the representations and those blocks are", "tokens": [50696, 534, 4874, 11, 291, 483, 341, 733, 295, 3461, 1324, 294, 264, 33358, 293, 729, 8474, 366, 50922], "temperature": 0.0, "avg_logprob": -0.13786021450109648, "compression_ratio": 1.9884169884169884, "no_speech_prob": 0.024397803470492363}, {"id": 571, "seek": 234298, "start": 2354.14, "end": 2357.22, "text": " like dissimilar across different initializations.", "tokens": [50922, 411, 7802, 332, 2202, 2108, 819, 5883, 14455, 13, 51076], "temperature": 0.0, "avg_logprob": -0.13786021450109648, "compression_ratio": 1.9884169884169884, "no_speech_prob": 0.024397803470492363}, {"id": 572, "seek": 234298, "start": 2357.22, "end": 2359.7, "text": " And then the same thing happens if you make the network really deep.", "tokens": [51076, 400, 550, 264, 912, 551, 2314, 498, 291, 652, 264, 3209, 534, 2452, 13, 51200], "temperature": 0.0, "avg_logprob": -0.13786021450109648, "compression_ratio": 1.9884169884169884, "no_speech_prob": 0.024397803470492363}, {"id": 573, "seek": 234298, "start": 2359.7, "end": 2363.2, "text": " We see these like big blocks in the representations.", "tokens": [51200, 492, 536, 613, 411, 955, 8474, 294, 264, 33358, 13, 51375], "temperature": 0.0, "avg_logprob": -0.13786021450109648, "compression_ratio": 1.9884169884169884, "no_speech_prob": 0.024397803470492363}, {"id": 574, "seek": 234298, "start": 2363.2, "end": 2369.38, "text": " So that made it hard to study these very wide and very deep networks from the representational", "tokens": [51375, 407, 300, 1027, 309, 1152, 281, 2979, 613, 588, 4874, 293, 588, 2452, 9590, 490, 264, 2906, 1478, 51684], "temperature": 0.0, "avg_logprob": -0.13786021450109648, "compression_ratio": 1.9884169884169884, "no_speech_prob": 0.024397803470492363}, {"id": 575, "seek": 234298, "start": 2369.38, "end": 2371.02, "text": " similarity perspective.", "tokens": [51684, 32194, 4585, 13, 51766], "temperature": 0.0, "avg_logprob": -0.13786021450109648, "compression_ratio": 1.9884169884169884, "no_speech_prob": 0.024397803470492363}, {"id": 576, "seek": 237102, "start": 2371.06, "end": 2374.38, "text": " But at the same time, I think it's like a really interesting observation.", "tokens": [50366, 583, 412, 264, 912, 565, 11, 286, 519, 309, 311, 411, 257, 534, 1880, 14816, 13, 50532], "temperature": 0.0, "avg_logprob": -0.13452883441038807, "compression_ratio": 1.9059829059829059, "no_speech_prob": 0.007342984434217215}, {"id": 577, "seek": 237102, "start": 2374.38, "end": 2379.2599999999998, "text": " Like it's something where we couldn't have predicted this ahead of time based on what", "tokens": [50532, 1743, 309, 311, 746, 689, 321, 2809, 380, 362, 19147, 341, 2286, 295, 565, 2361, 322, 437, 50776], "temperature": 0.0, "avg_logprob": -0.13452883441038807, "compression_ratio": 1.9059829059829059, "no_speech_prob": 0.007342984434217215}, {"id": 578, "seek": 237102, "start": 2379.2599999999998, "end": 2383.98, "text": " we know about neural network theory and we couldn't have predicted it ahead of time based", "tokens": [50776, 321, 458, 466, 18161, 3209, 5261, 293, 321, 2809, 380, 362, 19147, 309, 2286, 295, 565, 2361, 51012], "temperature": 0.0, "avg_logprob": -0.13452883441038807, "compression_ratio": 1.9059829059829059, "no_speech_prob": 0.007342984434217215}, {"id": 579, "seek": 237102, "start": 2383.98, "end": 2386.1, "text": " on the accuracy of the network.", "tokens": [51012, 322, 264, 14170, 295, 264, 3209, 13, 51118], "temperature": 0.0, "avg_logprob": -0.13452883441038807, "compression_ratio": 1.9059829059829059, "no_speech_prob": 0.007342984434217215}, {"id": 580, "seek": 237102, "start": 2386.1, "end": 2390.86, "text": " It's something where we really needed like these techniques for looking at the internal", "tokens": [51118, 467, 311, 746, 689, 321, 534, 2978, 411, 613, 7512, 337, 1237, 412, 264, 6920, 51356], "temperature": 0.0, "avg_logprob": -0.13452883441038807, "compression_ratio": 1.9059829059829059, "no_speech_prob": 0.007342984434217215}, {"id": 581, "seek": 237102, "start": 2390.86, "end": 2395.62, "text": " representations of neural networks to see what was happening inside of them.", "tokens": [51356, 33358, 295, 18161, 9590, 281, 536, 437, 390, 2737, 1854, 295, 552, 13, 51594], "temperature": 0.0, "avg_logprob": -0.13452883441038807, "compression_ratio": 1.9059829059829059, "no_speech_prob": 0.007342984434217215}, {"id": 582, "seek": 239562, "start": 2395.7, "end": 2400.8199999999997, "text": " There's this whole literature that takes a look at a network's expressibility with", "tokens": [50368, 821, 311, 341, 1379, 10394, 300, 2516, 257, 574, 412, 257, 3209, 311, 5109, 2841, 365, 50624], "temperature": 0.0, "avg_logprob": -0.15872785207387563, "compression_ratio": 1.8795180722891567, "no_speech_prob": 0.04334542900323868}, {"id": 583, "seek": 239562, "start": 2400.8199999999997, "end": 2403.1, "text": " regards to its depth and width.", "tokens": [50624, 14258, 281, 1080, 7161, 293, 11402, 13, 50738], "temperature": 0.0, "avg_logprob": -0.15872785207387563, "compression_ratio": 1.8795180722891567, "no_speech_prob": 0.04334542900323868}, {"id": 584, "seek": 239562, "start": 2403.1, "end": 2407.98, "text": " So could you just explain it to us whether or not we should be able to meaningfully quantify", "tokens": [50738, 407, 727, 291, 445, 2903, 309, 281, 505, 1968, 420, 406, 321, 820, 312, 1075, 281, 3620, 2277, 40421, 50982], "temperature": 0.0, "avg_logprob": -0.15872785207387563, "compression_ratio": 1.8795180722891567, "no_speech_prob": 0.04334542900323868}, {"id": 585, "seek": 239562, "start": 2407.98, "end": 2413.22, "text": " or formulate the expressibility of a neural network with regards to your analysis made", "tokens": [50982, 420, 47881, 264, 5109, 2841, 295, 257, 18161, 3209, 365, 14258, 281, 428, 5215, 1027, 51244], "temperature": 0.0, "avg_logprob": -0.15872785207387563, "compression_ratio": 1.8795180722891567, "no_speech_prob": 0.04334542900323868}, {"id": 586, "seek": 239562, "start": 2413.22, "end": 2414.22, "text": " on that?", "tokens": [51244, 322, 300, 30, 51294], "temperature": 0.0, "avg_logprob": -0.15872785207387563, "compression_ratio": 1.8795180722891567, "no_speech_prob": 0.04334542900323868}, {"id": 587, "seek": 239562, "start": 2414.22, "end": 2415.22, "text": " Yeah.", "tokens": [51294, 865, 13, 51344], "temperature": 0.0, "avg_logprob": -0.15872785207387563, "compression_ratio": 1.8795180722891567, "no_speech_prob": 0.04334542900323868}, {"id": 588, "seek": 239562, "start": 2415.22, "end": 2418.7799999999997, "text": " So there's this work that looks at like kind of the functions that can be expressed by", "tokens": [51344, 407, 456, 311, 341, 589, 300, 1542, 412, 411, 733, 295, 264, 6828, 300, 393, 312, 12675, 538, 51522], "temperature": 0.0, "avg_logprob": -0.15872785207387563, "compression_ratio": 1.8795180722891567, "no_speech_prob": 0.04334542900323868}, {"id": 589, "seek": 239562, "start": 2418.7799999999997, "end": 2422.1, "text": " wide networks and the functions that can be expressed by deep networks.", "tokens": [51522, 4874, 9590, 293, 264, 6828, 300, 393, 312, 12675, 538, 2452, 9590, 13, 51688], "temperature": 0.0, "avg_logprob": -0.15872785207387563, "compression_ratio": 1.8795180722891567, "no_speech_prob": 0.04334542900323868}, {"id": 590, "seek": 242210, "start": 2422.1, "end": 2428.18, "text": " And I guess like the neural networks seem to become exponentially more expressive as", "tokens": [50364, 400, 286, 2041, 411, 264, 18161, 9590, 1643, 281, 1813, 37330, 544, 40189, 382, 50668], "temperature": 0.0, "avg_logprob": -0.08732873088908645, "compression_ratio": 1.8833333333333333, "no_speech_prob": 0.00025312360958196223}, {"id": 591, "seek": 242210, "start": 2428.18, "end": 2429.9, "text": " you make them deeper.", "tokens": [50668, 291, 652, 552, 7731, 13, 50754], "temperature": 0.0, "avg_logprob": -0.08732873088908645, "compression_ratio": 1.8833333333333333, "no_speech_prob": 0.00025312360958196223}, {"id": 592, "seek": 242210, "start": 2429.9, "end": 2433.46, "text": " So it seems like in that sense depth is more important than width.", "tokens": [50754, 407, 309, 2544, 411, 294, 300, 2020, 7161, 307, 544, 1021, 813, 11402, 13, 50932], "temperature": 0.0, "avg_logprob": -0.08732873088908645, "compression_ratio": 1.8833333333333333, "no_speech_prob": 0.00025312360958196223}, {"id": 593, "seek": 242210, "start": 2433.46, "end": 2438.1, "text": " But on the other hand, like the neural networks that we actually train in this paper, like", "tokens": [50932, 583, 322, 264, 661, 1011, 11, 411, 264, 18161, 9590, 300, 321, 767, 3847, 294, 341, 3035, 11, 411, 51164], "temperature": 0.0, "avg_logprob": -0.08732873088908645, "compression_ratio": 1.8833333333333333, "no_speech_prob": 0.00025312360958196223}, {"id": 594, "seek": 242210, "start": 2438.1, "end": 2442.22, "text": " both the wide networks and the deep networks are big enough that they can overfit the entire", "tokens": [51164, 1293, 264, 4874, 9590, 293, 264, 2452, 9590, 366, 955, 1547, 300, 436, 393, 670, 6845, 264, 2302, 51370], "temperature": 0.0, "avg_logprob": -0.08732873088908645, "compression_ratio": 1.8833333333333333, "no_speech_prob": 0.00025312360958196223}, {"id": 595, "seek": 242210, "start": 2442.22, "end": 2443.54, "text": " training set.", "tokens": [51370, 3097, 992, 13, 51436], "temperature": 0.0, "avg_logprob": -0.08732873088908645, "compression_ratio": 1.8833333333333333, "no_speech_prob": 0.00025312360958196223}, {"id": 596, "seek": 242210, "start": 2443.54, "end": 2448.46, "text": " So in this case, like the expressibility of the network is not really important.", "tokens": [51436, 407, 294, 341, 1389, 11, 411, 264, 5109, 2841, 295, 264, 3209, 307, 406, 534, 1021, 13, 51682], "temperature": 0.0, "avg_logprob": -0.08732873088908645, "compression_ratio": 1.8833333333333333, "no_speech_prob": 0.00025312360958196223}, {"id": 597, "seek": 244846, "start": 2448.66, "end": 2452.26, "text": " Important is the function that the network actually ends up learning.", "tokens": [50374, 42908, 307, 264, 2445, 300, 264, 3209, 767, 5314, 493, 2539, 13, 50554], "temperature": 0.0, "avg_logprob": -0.1572347062357356, "compression_ratio": 1.7510729613733906, "no_speech_prob": 0.04081945866346359}, {"id": 598, "seek": 244846, "start": 2452.26, "end": 2457.7400000000002, "text": " So I guess even though networks could express more functions when they're deep, what we're", "tokens": [50554, 407, 286, 2041, 754, 1673, 9590, 727, 5109, 544, 6828, 562, 436, 434, 2452, 11, 437, 321, 434, 50828], "temperature": 0.0, "avg_logprob": -0.1572347062357356, "compression_ratio": 1.7510729613733906, "no_speech_prob": 0.04081945866346359}, {"id": 599, "seek": 244846, "start": 2457.7400000000002, "end": 2463.14, "text": " really studying is the function that you actually get when you train the neural network by gradient", "tokens": [50828, 534, 7601, 307, 264, 2445, 300, 291, 767, 483, 562, 291, 3847, 264, 18161, 3209, 538, 16235, 51098], "temperature": 0.0, "avg_logprob": -0.1572347062357356, "compression_ratio": 1.7510729613733906, "no_speech_prob": 0.04081945866346359}, {"id": 600, "seek": 244846, "start": 2463.14, "end": 2467.26, "text": " descent on some data, what the optimization process actually finds.", "tokens": [51098, 23475, 322, 512, 1412, 11, 437, 264, 19618, 1399, 767, 10704, 13, 51304], "temperature": 0.0, "avg_logprob": -0.1572347062357356, "compression_ratio": 1.7510729613733906, "no_speech_prob": 0.04081945866346359}, {"id": 601, "seek": 244846, "start": 2467.26, "end": 2472.06, "text": " One thing as well in that paper, you talked about the network pathology, right?", "tokens": [51304, 1485, 551, 382, 731, 294, 300, 3035, 11, 291, 2825, 466, 264, 3209, 3100, 1793, 11, 558, 30, 51544], "temperature": 0.0, "avg_logprob": -0.1572347062357356, "compression_ratio": 1.7510729613733906, "no_speech_prob": 0.04081945866346359}, {"id": 602, "seek": 247206, "start": 2472.06, "end": 2478.2599999999998, "text": " You said that two times depth accuracy 95%, four times 93.2, eight times 91.9.", "tokens": [50364, 509, 848, 300, 732, 1413, 7161, 14170, 13420, 8923, 1451, 1413, 28876, 13, 17, 11, 3180, 1413, 31064, 13, 24, 13, 50674], "temperature": 0.0, "avg_logprob": -0.1964083955488132, "compression_ratio": 1.6092307692307692, "no_speech_prob": 0.36854687333106995}, {"id": 603, "seek": 247206, "start": 2478.2599999999998, "end": 2481.46, "text": " So because this is this runs counter to what a lot of us would intuit.", "tokens": [50674, 407, 570, 341, 307, 341, 6676, 5682, 281, 437, 257, 688, 295, 505, 576, 16224, 13, 50834], "temperature": 0.0, "avg_logprob": -0.1964083955488132, "compression_ratio": 1.6092307692307692, "no_speech_prob": 0.36854687333106995}, {"id": 604, "seek": 247206, "start": 2481.46, "end": 2483.46, "text": " We think that you can have as much depth as you want.", "tokens": [50834, 492, 519, 300, 291, 393, 362, 382, 709, 7161, 382, 291, 528, 13, 50934], "temperature": 0.0, "avg_logprob": -0.1964083955488132, "compression_ratio": 1.6092307692307692, "no_speech_prob": 0.36854687333106995}, {"id": 605, "seek": 247206, "start": 2483.46, "end": 2487.2599999999998, "text": " And architectures like ResNet in some sense, they learn their own capacity.", "tokens": [50934, 400, 6331, 1303, 411, 5015, 31890, 294, 512, 2020, 11, 436, 1466, 641, 1065, 6042, 13, 51124], "temperature": 0.0, "avg_logprob": -0.1964083955488132, "compression_ratio": 1.6092307692307692, "no_speech_prob": 0.36854687333106995}, {"id": 606, "seek": 247206, "start": 2487.2599999999998, "end": 2489.34, "text": " There is a pathology there happening clearly.", "tokens": [51124, 821, 307, 257, 3100, 1793, 456, 2737, 4448, 13, 51228], "temperature": 0.0, "avg_logprob": -0.1964083955488132, "compression_ratio": 1.6092307692307692, "no_speech_prob": 0.36854687333106995}, {"id": 607, "seek": 247206, "start": 2489.34, "end": 2493.7799999999997, "text": " And how would you determine that from this visualization?", "tokens": [51228, 400, 577, 576, 291, 6997, 300, 490, 341, 25801, 30, 51450], "temperature": 0.0, "avg_logprob": -0.1964083955488132, "compression_ratio": 1.6092307692307692, "no_speech_prob": 0.36854687333106995}, {"id": 608, "seek": 247206, "start": 2493.7799999999997, "end": 2496.5, "text": " Yeah, so I guess there are two kind of results.", "tokens": [51450, 865, 11, 370, 286, 2041, 456, 366, 732, 733, 295, 3542, 13, 51586], "temperature": 0.0, "avg_logprob": -0.1964083955488132, "compression_ratio": 1.6092307692307692, "no_speech_prob": 0.36854687333106995}, {"id": 609, "seek": 247206, "start": 2496.5, "end": 2502.02, "text": " So like you can either look at networks without residual connections, where you do actually", "tokens": [51586, 407, 411, 291, 393, 2139, 574, 412, 9590, 1553, 27980, 9271, 11, 689, 291, 360, 767, 51862], "temperature": 0.0, "avg_logprob": -0.1964083955488132, "compression_ratio": 1.6092307692307692, "no_speech_prob": 0.36854687333106995}, {"id": 610, "seek": 250202, "start": 2502.1, "end": 2505.78, "text": " find that at some depth, the accuracy will start going down.", "tokens": [50368, 915, 300, 412, 512, 7161, 11, 264, 14170, 486, 722, 516, 760, 13, 50552], "temperature": 0.0, "avg_logprob": -0.15421313865512026, "compression_ratio": 1.7320754716981133, "no_speech_prob": 0.0016476312885060906}, {"id": 611, "seek": 250202, "start": 2505.78, "end": 2511.82, "text": " And in networks without residual connections, we find that like that the depth where accuracy", "tokens": [50552, 400, 294, 9590, 1553, 27980, 9271, 11, 321, 915, 300, 411, 300, 264, 7161, 689, 14170, 50854], "temperature": 0.0, "avg_logprob": -0.15421313865512026, "compression_ratio": 1.7320754716981133, "no_speech_prob": 0.0016476312885060906}, {"id": 612, "seek": 250202, "start": 2511.82, "end": 2516.86, "text": " starts to go down is like around the same depth where you begin seeing this kind of block", "tokens": [50854, 3719, 281, 352, 760, 307, 411, 926, 264, 912, 7161, 689, 291, 1841, 2577, 341, 733, 295, 3461, 51106], "temperature": 0.0, "avg_logprob": -0.15421313865512026, "compression_ratio": 1.7320754716981133, "no_speech_prob": 0.0016476312885060906}, {"id": 613, "seek": 250202, "start": 2516.86, "end": 2520.82, "text": " structure where many successive layers have similar representations.", "tokens": [51106, 3877, 689, 867, 48043, 7914, 362, 2531, 33358, 13, 51304], "temperature": 0.0, "avg_logprob": -0.15421313865512026, "compression_ratio": 1.7320754716981133, "no_speech_prob": 0.0016476312885060906}, {"id": 614, "seek": 250202, "start": 2520.82, "end": 2524.74, "text": " And it looks like the representation is no longer getting refined through the network.", "tokens": [51304, 400, 309, 1542, 411, 264, 10290, 307, 572, 2854, 1242, 26201, 807, 264, 3209, 13, 51500], "temperature": 0.0, "avg_logprob": -0.15421313865512026, "compression_ratio": 1.7320754716981133, "no_speech_prob": 0.0016476312885060906}, {"id": 615, "seek": 250202, "start": 2524.74, "end": 2527.74, "text": " Yeah, I mean, with ResNets, you can make them much deeper.", "tokens": [51500, 865, 11, 286, 914, 11, 365, 5015, 45, 1385, 11, 291, 393, 652, 552, 709, 7731, 13, 51650], "temperature": 0.0, "avg_logprob": -0.15421313865512026, "compression_ratio": 1.7320754716981133, "no_speech_prob": 0.0016476312885060906}, {"id": 616, "seek": 252774, "start": 2527.74, "end": 2532.8599999999997, "text": " And it seems like it doesn't hurt accuracy as much even once you start getting these blocks.", "tokens": [50364, 400, 309, 2544, 411, 309, 1177, 380, 4607, 14170, 382, 709, 754, 1564, 291, 722, 1242, 613, 8474, 13, 50620], "temperature": 0.0, "avg_logprob": -0.11937744334592658, "compression_ratio": 1.8093525179856116, "no_speech_prob": 0.005055551882833242}, {"id": 617, "seek": 252774, "start": 2533.1, "end": 2537.2599999999998, "text": " But it also seems once you start getting these blocks, making the network deeper, making", "tokens": [50632, 583, 309, 611, 2544, 1564, 291, 722, 1242, 613, 8474, 11, 1455, 264, 3209, 7731, 11, 1455, 50840], "temperature": 0.0, "avg_logprob": -0.11937744334592658, "compression_ratio": 1.8093525179856116, "no_speech_prob": 0.005055551882833242}, {"id": 618, "seek": 252774, "start": 2537.2599999999998, "end": 2541.58, "text": " that work wider, no longer really gives you any improvement in accuracy.", "tokens": [50840, 300, 589, 11842, 11, 572, 2854, 534, 2709, 291, 604, 10444, 294, 14170, 13, 51056], "temperature": 0.0, "avg_logprob": -0.11937744334592658, "compression_ratio": 1.8093525179856116, "no_speech_prob": 0.005055551882833242}, {"id": 619, "seek": 252774, "start": 2541.58, "end": 2547.02, "text": " So it seems like this is basically telling you that the network has fit the data as much as it can.", "tokens": [51056, 407, 309, 2544, 411, 341, 307, 1936, 3585, 291, 300, 264, 3209, 575, 3318, 264, 1412, 382, 709, 382, 309, 393, 13, 51328], "temperature": 0.0, "avg_logprob": -0.11937744334592658, "compression_ratio": 1.8093525179856116, "no_speech_prob": 0.005055551882833242}, {"id": 620, "seek": 252774, "start": 2547.02, "end": 2551.9399999999996, "text": " And and there's no real advantage to using something bigger.", "tokens": [51328, 400, 293, 456, 311, 572, 957, 5002, 281, 1228, 746, 3801, 13, 51574], "temperature": 0.0, "avg_logprob": -0.11937744334592658, "compression_ratio": 1.8093525179856116, "no_speech_prob": 0.005055551882833242}, {"id": 621, "seek": 252774, "start": 2553.18, "end": 2557.3399999999997, "text": " Fascinating. Let's move on to another paper that you've done, which is quite related in", "tokens": [51636, 49098, 8205, 13, 961, 311, 1286, 322, 281, 1071, 3035, 300, 291, 600, 1096, 11, 597, 307, 1596, 4077, 294, 51844], "temperature": 0.0, "avg_logprob": -0.11937744334592658, "compression_ratio": 1.8093525179856116, "no_speech_prob": 0.005055551882833242}, {"id": 622, "seek": 255734, "start": 2557.34, "end": 2560.02, "text": " terms of you've used the same analysis to reason about it.", "tokens": [50364, 2115, 295, 291, 600, 1143, 264, 912, 5215, 281, 1778, 466, 309, 13, 50498], "temperature": 0.0, "avg_logprob": -0.15954807422779224, "compression_ratio": 1.6953846153846155, "no_speech_prob": 0.0004540800000540912}, {"id": 623, "seek": 255734, "start": 2560.02, "end": 2563.26, "text": " But you had a paper called What's in a Loss Function for Image Classification.", "tokens": [50498, 583, 291, 632, 257, 3035, 1219, 708, 311, 294, 257, 441, 772, 11166, 882, 337, 29903, 9471, 3774, 13, 50660], "temperature": 0.0, "avg_logprob": -0.15954807422779224, "compression_ratio": 1.6953846153846155, "no_speech_prob": 0.0004540800000540912}, {"id": 624, "seek": 255734, "start": 2563.42, "end": 2567.82, "text": " And you looked at a whole bunch of different label smoothing and regularizers, which are", "tokens": [50668, 400, 291, 2956, 412, 257, 1379, 3840, 295, 819, 7645, 899, 6259, 571, 293, 3890, 22525, 11, 597, 366, 50888], "temperature": 0.0, "avg_logprob": -0.15954807422779224, "compression_ratio": 1.6953846153846155, "no_speech_prob": 0.0004540800000540912}, {"id": 625, "seek": 255734, "start": 2567.82, "end": 2569.58, "text": " things that you do on the end of the network.", "tokens": [50888, 721, 300, 291, 360, 322, 264, 917, 295, 264, 3209, 13, 50976], "temperature": 0.0, "avg_logprob": -0.15954807422779224, "compression_ratio": 1.6953846153846155, "no_speech_prob": 0.0004540800000540912}, {"id": 626, "seek": 255734, "start": 2569.58, "end": 2574.82, "text": " And you identified differences in accuracy and calibration and out of domain distribution.", "tokens": [50976, 400, 291, 9234, 7300, 294, 14170, 293, 38732, 293, 484, 295, 9274, 7316, 13, 51238], "temperature": 0.0, "avg_logprob": -0.15954807422779224, "compression_ratio": 1.6953846153846155, "no_speech_prob": 0.0004540800000540912}, {"id": 627, "seek": 255734, "start": 2575.02, "end": 2577.6200000000003, "text": " And you made some really interesting observations.", "tokens": [51248, 400, 291, 1027, 512, 534, 1880, 18163, 13, 51378], "temperature": 0.0, "avg_logprob": -0.15954807422779224, "compression_ratio": 1.6953846153846155, "no_speech_prob": 0.0004540800000540912}, {"id": 628, "seek": 255734, "start": 2577.6200000000003, "end": 2580.9, "text": " So by the way, we're talking about things like do we use the softmax or the squared", "tokens": [51378, 407, 538, 264, 636, 11, 321, 434, 1417, 466, 721, 411, 360, 321, 764, 264, 2787, 41167, 420, 264, 8889, 51542], "temperature": 0.0, "avg_logprob": -0.15954807422779224, "compression_ratio": 1.6953846153846155, "no_speech_prob": 0.0004540800000540912}, {"id": 629, "seek": 255734, "start": 2580.9, "end": 2583.78, "text": " area or dropout or label smoothing or logic penalty.", "tokens": [51542, 1859, 420, 3270, 346, 420, 7645, 899, 6259, 571, 420, 9952, 16263, 13, 51686], "temperature": 0.0, "avg_logprob": -0.15954807422779224, "compression_ratio": 1.6953846153846155, "no_speech_prob": 0.0004540800000540912}, {"id": 630, "seek": 258378, "start": 2583.94, "end": 2587.5400000000004, "text": " But you noticed using the same analysis technique that only affected the", "tokens": [50372, 583, 291, 5694, 1228, 264, 912, 5215, 6532, 300, 787, 8028, 264, 50552], "temperature": 0.0, "avg_logprob": -0.13120824199611858, "compression_ratio": 1.8326848249027237, "no_speech_prob": 0.0014538312098011374}, {"id": 631, "seek": 258378, "start": 2587.5400000000004, "end": 2590.7000000000003, "text": " representations on the penultimate layers of the neural network.", "tokens": [50552, 33358, 322, 264, 3435, 723, 2905, 7914, 295, 264, 18161, 3209, 13, 50710], "temperature": 0.0, "avg_logprob": -0.13120824199611858, "compression_ratio": 1.8326848249027237, "no_speech_prob": 0.0014538312098011374}, {"id": 632, "seek": 258378, "start": 2590.9, "end": 2592.5800000000004, "text": " What's going on there?", "tokens": [50720, 708, 311, 516, 322, 456, 30, 50804], "temperature": 0.0, "avg_logprob": -0.13120824199611858, "compression_ratio": 1.8326848249027237, "no_speech_prob": 0.0014538312098011374}, {"id": 633, "seek": 258378, "start": 2592.5800000000004, "end": 2595.02, "text": " Yeah, so it's not just the penultimate layer.", "tokens": [50804, 865, 11, 370, 309, 311, 406, 445, 264, 3435, 723, 2905, 4583, 13, 50926], "temperature": 0.0, "avg_logprob": -0.13120824199611858, "compression_ratio": 1.8326848249027237, "no_speech_prob": 0.0014538312098011374}, {"id": 634, "seek": 258378, "start": 2595.02, "end": 2600.5, "text": " It's like the the last maybe third of the network is affected by the loss function.", "tokens": [50926, 467, 311, 411, 264, 264, 1036, 1310, 2636, 295, 264, 3209, 307, 8028, 538, 264, 4470, 2445, 13, 51200], "temperature": 0.0, "avg_logprob": -0.13120824199611858, "compression_ratio": 1.8326848249027237, "no_speech_prob": 0.0014538312098011374}, {"id": 635, "seek": 258378, "start": 2600.5, "end": 2605.46, "text": " But then the first two thirds of the network, it seems like you learn the same representation", "tokens": [51200, 583, 550, 264, 700, 732, 34552, 295, 264, 3209, 11, 309, 2544, 411, 291, 1466, 264, 912, 10290, 51448], "temperature": 0.0, "avg_logprob": -0.13120824199611858, "compression_ratio": 1.8326848249027237, "no_speech_prob": 0.0014538312098011374}, {"id": 636, "seek": 258378, "start": 2605.46, "end": 2607.46, "text": " no matter what loss function you use.", "tokens": [51448, 572, 1871, 437, 4470, 2445, 291, 764, 13, 51548], "temperature": 0.0, "avg_logprob": -0.13120824199611858, "compression_ratio": 1.8326848249027237, "no_speech_prob": 0.0014538312098011374}, {"id": 637, "seek": 258378, "start": 2607.46, "end": 2609.86, "text": " So it doesn't change if you use label smoothing.", "tokens": [51548, 407, 309, 1177, 380, 1319, 498, 291, 764, 7645, 899, 6259, 571, 13, 51668], "temperature": 0.0, "avg_logprob": -0.13120824199611858, "compression_ratio": 1.8326848249027237, "no_speech_prob": 0.0014538312098011374}, {"id": 638, "seek": 260986, "start": 2610.1, "end": 2615.3, "text": " It doesn't even change if you use mean squared error instead of using softmax cross entropy.", "tokens": [50376, 467, 1177, 380, 754, 1319, 498, 291, 764, 914, 8889, 6713, 2602, 295, 1228, 2787, 41167, 3278, 30867, 13, 50636], "temperature": 0.0, "avg_logprob": -0.12992162940915952, "compression_ratio": 1.7743055555555556, "no_speech_prob": 0.003482168074697256}, {"id": 639, "seek": 260986, "start": 2615.3, "end": 2620.26, "text": " You still basically learn the same representation for the first two thirds of the network.", "tokens": [50636, 509, 920, 1936, 1466, 264, 912, 10290, 337, 264, 700, 732, 34552, 295, 264, 3209, 13, 50884], "temperature": 0.0, "avg_logprob": -0.12992162940915952, "compression_ratio": 1.7743055555555556, "no_speech_prob": 0.003482168074697256}, {"id": 640, "seek": 260986, "start": 2620.26, "end": 2624.02, "text": " And I think it's still it's a bit of a puzzle to us why this happens.", "tokens": [50884, 400, 286, 519, 309, 311, 920, 309, 311, 257, 857, 295, 257, 12805, 281, 505, 983, 341, 2314, 13, 51072], "temperature": 0.0, "avg_logprob": -0.12992162940915952, "compression_ratio": 1.7743055555555556, "no_speech_prob": 0.003482168074697256}, {"id": 641, "seek": 260986, "start": 2624.02, "end": 2627.54, "text": " Clearly, it matters that you're training the network with the loss function.", "tokens": [51072, 24120, 11, 309, 7001, 300, 291, 434, 3097, 264, 3209, 365, 264, 4470, 2445, 13, 51248], "temperature": 0.0, "avg_logprob": -0.12992162940915952, "compression_ratio": 1.7743055555555556, "no_speech_prob": 0.003482168074697256}, {"id": 642, "seek": 260986, "start": 2627.54, "end": 2632.82, "text": " There's those layers in the first two thirds of the network do change from the initialization.", "tokens": [51248, 821, 311, 729, 7914, 294, 264, 700, 732, 34552, 295, 264, 3209, 360, 1319, 490, 264, 5883, 2144, 13, 51512], "temperature": 0.0, "avg_logprob": -0.12992162940915952, "compression_ratio": 1.7743055555555556, "no_speech_prob": 0.003482168074697256}, {"id": 643, "seek": 260986, "start": 2632.82, "end": 2638.26, "text": " But I guess it seems that the last third of the network is setting up the penultimate", "tokens": [51512, 583, 286, 2041, 309, 2544, 300, 264, 1036, 2636, 295, 264, 3209, 307, 3287, 493, 264, 3435, 723, 2905, 51784], "temperature": 0.0, "avg_logprob": -0.12992162940915952, "compression_ratio": 1.7743055555555556, "no_speech_prob": 0.003482168074697256}, {"id": 644, "seek": 263826, "start": 2638.26, "end": 2642.1800000000003, "text": " layer representation in a way that is good for your loss function.", "tokens": [50364, 4583, 10290, 294, 257, 636, 300, 307, 665, 337, 428, 4470, 2445, 13, 50560], "temperature": 0.0, "avg_logprob": -0.11100964407319004, "compression_ratio": 1.8223938223938223, "no_speech_prob": 0.0011324319057166576}, {"id": 645, "seek": 263826, "start": 2642.1800000000003, "end": 2647.5400000000004, "text": " But the first two thirds of the network are somehow just learning general features.", "tokens": [50560, 583, 264, 700, 732, 34552, 295, 264, 3209, 366, 6063, 445, 2539, 2674, 4122, 13, 50828], "temperature": 0.0, "avg_logprob": -0.11100964407319004, "compression_ratio": 1.8223938223938223, "no_speech_prob": 0.0011324319057166576}, {"id": 646, "seek": 263826, "start": 2647.5400000000004, "end": 2651.3, "text": " I think this also like corresponds with the success of transfer learning,", "tokens": [50828, 286, 519, 341, 611, 411, 23249, 365, 264, 2245, 295, 5003, 2539, 11, 51016], "temperature": 0.0, "avg_logprob": -0.11100964407319004, "compression_ratio": 1.8223938223938223, "no_speech_prob": 0.0011324319057166576}, {"id": 647, "seek": 263826, "start": 2651.3, "end": 2655.7000000000003, "text": " where we can take features that we've learned on one task and transfer them to some other task.", "tokens": [51016, 689, 321, 393, 747, 4122, 300, 321, 600, 3264, 322, 472, 5633, 293, 5003, 552, 281, 512, 661, 5633, 13, 51236], "temperature": 0.0, "avg_logprob": -0.11100964407319004, "compression_ratio": 1.8223938223938223, "no_speech_prob": 0.0011324319057166576}, {"id": 648, "seek": 263826, "start": 2656.5, "end": 2661.94, "text": " What's the implication that it seems is the implication that the loss function", "tokens": [51276, 708, 311, 264, 37814, 300, 309, 2544, 307, 264, 37814, 300, 264, 4470, 2445, 51548], "temperature": 0.0, "avg_logprob": -0.11100964407319004, "compression_ratio": 1.8223938223938223, "no_speech_prob": 0.0011324319057166576}, {"id": 649, "seek": 263826, "start": 2661.94, "end": 2665.78, "text": " is not having any impact on the representations early on in the network?", "tokens": [51548, 307, 406, 1419, 604, 2712, 322, 264, 33358, 2440, 322, 294, 264, 3209, 30, 51740], "temperature": 0.0, "avg_logprob": -0.11100964407319004, "compression_ratio": 1.8223938223938223, "no_speech_prob": 0.0011324319057166576}, {"id": 650, "seek": 266578, "start": 2666.5, "end": 2668.1800000000003, "text": " That seems like quite a big implication.", "tokens": [50400, 663, 2544, 411, 1596, 257, 955, 37814, 13, 50484], "temperature": 0.0, "avg_logprob": -0.09426054358482361, "compression_ratio": 1.8201754385964912, "no_speech_prob": 0.0009691957966424525}, {"id": 651, "seek": 266578, "start": 2669.1400000000003, "end": 2674.5, "text": " Yeah, I think the loss function must have some impact because if you don't train", "tokens": [50532, 865, 11, 286, 519, 264, 4470, 2445, 1633, 362, 512, 2712, 570, 498, 291, 500, 380, 3847, 50800], "temperature": 0.0, "avg_logprob": -0.09426054358482361, "compression_ratio": 1.8201754385964912, "no_speech_prob": 0.0009691957966424525}, {"id": 652, "seek": 266578, "start": 2674.5, "end": 2680.1800000000003, "text": " the network, if you don't have any loss function at all, then the representation", "tokens": [50800, 264, 3209, 11, 498, 291, 500, 380, 362, 604, 4470, 2445, 412, 439, 11, 550, 264, 10290, 51084], "temperature": 0.0, "avg_logprob": -0.09426054358482361, "compression_ratio": 1.8201754385964912, "no_speech_prob": 0.0009691957966424525}, {"id": 653, "seek": 266578, "start": 2680.1800000000003, "end": 2684.82, "text": " in that first two thirds of the network is actually quite different.", "tokens": [51084, 294, 300, 700, 732, 34552, 295, 264, 3209, 307, 767, 1596, 819, 13, 51316], "temperature": 0.0, "avg_logprob": -0.09426054358482361, "compression_ratio": 1.8201754385964912, "no_speech_prob": 0.0009691957966424525}, {"id": 654, "seek": 266578, "start": 2684.82, "end": 2688.98, "text": " I think what's really happening is there are these differences among the loss functions,", "tokens": [51316, 286, 519, 437, 311, 534, 2737, 307, 456, 366, 613, 7300, 3654, 264, 4470, 6828, 11, 51524], "temperature": 0.0, "avg_logprob": -0.09426054358482361, "compression_ratio": 1.8201754385964912, "no_speech_prob": 0.0009691957966424525}, {"id": 655, "seek": 266578, "start": 2688.98, "end": 2692.6600000000003, "text": " which don't really matter except later in the network.", "tokens": [51524, 597, 500, 380, 534, 1871, 3993, 1780, 294, 264, 3209, 13, 51708], "temperature": 0.0, "avg_logprob": -0.09426054358482361, "compression_ratio": 1.8201754385964912, "no_speech_prob": 0.0009691957966424525}, {"id": 656, "seek": 269266, "start": 2692.74, "end": 2698.5, "text": " Although they will give you a slight change in accuracy and slight changes in robustness,", "tokens": [50368, 5780, 436, 486, 976, 291, 257, 4036, 1319, 294, 14170, 293, 4036, 2962, 294, 13956, 1287, 11, 50656], "temperature": 0.0, "avg_logprob": -0.0737197240193685, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.0006876008701510727}, {"id": 657, "seek": 269266, "start": 2698.5, "end": 2701.94, "text": " they don't matter for this general feature learning process.", "tokens": [50656, 436, 500, 380, 1871, 337, 341, 2674, 4111, 2539, 1399, 13, 50828], "temperature": 0.0, "avg_logprob": -0.0737197240193685, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.0006876008701510727}, {"id": 658, "seek": 269266, "start": 2701.94, "end": 2707.54, "text": " I guess maybe it's what we should expect because ultimately we're asking the network", "tokens": [50828, 286, 2041, 1310, 309, 311, 437, 321, 820, 2066, 570, 6284, 321, 434, 3365, 264, 3209, 51108], "temperature": 0.0, "avg_logprob": -0.0737197240193685, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.0006876008701510727}, {"id": 659, "seek": 269266, "start": 2707.54, "end": 2709.7, "text": " to do the same thing just in a slightly different way.", "tokens": [51108, 281, 360, 264, 912, 551, 445, 294, 257, 4748, 819, 636, 13, 51216], "temperature": 0.0, "avg_logprob": -0.0737197240193685, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.0006876008701510727}, {"id": 660, "seek": 269266, "start": 2709.7, "end": 2712.66, "text": " We're still asking the network to classify images.", "tokens": [51216, 492, 434, 920, 3365, 264, 3209, 281, 33872, 5267, 13, 51364], "temperature": 0.0, "avg_logprob": -0.0737197240193685, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.0006876008701510727}, {"id": 661, "seek": 269266, "start": 2712.66, "end": 2717.06, "text": " We're just asking it to provide slightly different outputs to produce a slightly", "tokens": [51364, 492, 434, 445, 3365, 309, 281, 2893, 4748, 819, 23930, 281, 5258, 257, 4748, 51584], "temperature": 0.0, "avg_logprob": -0.0737197240193685, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.0006876008701510727}, {"id": 662, "seek": 269266, "start": 2717.06, "end": 2720.02, "text": " different representation at the penultimate layer.", "tokens": [51584, 819, 10290, 412, 264, 3435, 723, 2905, 4583, 13, 51732], "temperature": 0.0, "avg_logprob": -0.0737197240193685, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.0006876008701510727}, {"id": 663, "seek": 272002, "start": 2720.1, "end": 2726.9, "text": " Maybe we should expect that those earlier features that are just trying to", "tokens": [50368, 2704, 321, 820, 2066, 300, 729, 3071, 4122, 300, 366, 445, 1382, 281, 50708], "temperature": 0.0, "avg_logprob": -0.10176398906301945, "compression_ratio": 1.7, "no_speech_prob": 0.0005882809637114406}, {"id": 664, "seek": 272002, "start": 2727.54, "end": 2733.54, "text": " represent general things about images, those will be the same no matter what loss function we pick.", "tokens": [50740, 2906, 2674, 721, 466, 5267, 11, 729, 486, 312, 264, 912, 572, 1871, 437, 4470, 2445, 321, 1888, 13, 51040], "temperature": 0.0, "avg_logprob": -0.10176398906301945, "compression_ratio": 1.7, "no_speech_prob": 0.0005882809637114406}, {"id": 665, "seek": 272002, "start": 2734.82, "end": 2739.38, "text": " In your experiments, did you find whether or not model capacity has anything to do with it?", "tokens": [51104, 682, 428, 12050, 11, 630, 291, 915, 1968, 420, 406, 2316, 6042, 575, 1340, 281, 360, 365, 309, 30, 51332], "temperature": 0.0, "avg_logprob": -0.10176398906301945, "compression_ratio": 1.7, "no_speech_prob": 0.0005882809637114406}, {"id": 666, "seek": 272002, "start": 2739.38, "end": 2744.58, "text": " Yeah, so we didn't really investigate different model capacities in that paper.", "tokens": [51332, 865, 11, 370, 321, 994, 380, 534, 15013, 819, 2316, 39396, 294, 300, 3035, 13, 51592], "temperature": 0.0, "avg_logprob": -0.10176398906301945, "compression_ratio": 1.7, "no_speech_prob": 0.0005882809637114406}, {"id": 667, "seek": 272002, "start": 2744.58, "end": 2749.38, "text": " I would expect that the same thing holds for a wide range of model capacities.", "tokens": [51592, 286, 576, 2066, 300, 264, 912, 551, 9190, 337, 257, 4874, 3613, 295, 2316, 39396, 13, 51832], "temperature": 0.0, "avg_logprob": -0.10176398906301945, "compression_ratio": 1.7, "no_speech_prob": 0.0005882809637114406}, {"id": 668, "seek": 274938, "start": 2749.7000000000003, "end": 2753.86, "text": " There's no indication from the experiments that if you use a bigger network or a slightly", "tokens": [50380, 821, 311, 572, 18877, 490, 264, 12050, 300, 498, 291, 764, 257, 3801, 3209, 420, 257, 4748, 50588], "temperature": 0.0, "avg_logprob": -0.13726318216769495, "compression_ratio": 1.76953125, "no_speech_prob": 0.0006770117324776947}, {"id": 669, "seek": 274938, "start": 2753.86, "end": 2755.86, "text": " smaller network that things would change all that much.", "tokens": [50588, 4356, 3209, 300, 721, 576, 1319, 439, 300, 709, 13, 50688], "temperature": 0.0, "avg_logprob": -0.13726318216769495, "compression_ratio": 1.76953125, "no_speech_prob": 0.0006770117324776947}, {"id": 670, "seek": 274938, "start": 2757.06, "end": 2761.3, "text": " Yeah, I think it's still an open question how model capacity changes things.", "tokens": [50748, 865, 11, 286, 519, 309, 311, 920, 364, 1269, 1168, 577, 2316, 6042, 2962, 721, 13, 50960], "temperature": 0.0, "avg_logprob": -0.13726318216769495, "compression_ratio": 1.76953125, "no_speech_prob": 0.0006770117324776947}, {"id": 671, "seek": 274938, "start": 2761.3, "end": 2766.1800000000003, "text": " I guess in the Sinclair paper, we found that model capacity can matter quite a bit.", "tokens": [50960, 286, 2041, 294, 264, 318, 4647, 24319, 3035, 11, 321, 1352, 300, 2316, 6042, 393, 1871, 1596, 257, 857, 13, 51204], "temperature": 0.0, "avg_logprob": -0.13726318216769495, "compression_ratio": 1.76953125, "no_speech_prob": 0.0006770117324776947}, {"id": 672, "seek": 274938, "start": 2766.1800000000003, "end": 2769.3, "text": " Yeah, so the general hypothesis there should also hold,", "tokens": [51204, 865, 11, 370, 264, 2674, 17291, 456, 820, 611, 1797, 11, 51360], "temperature": 0.0, "avg_logprob": -0.13726318216769495, "compression_ratio": 1.76953125, "no_speech_prob": 0.0006770117324776947}, {"id": 673, "seek": 274938, "start": 2769.3, "end": 2774.1800000000003, "text": " even though your model is bigger or smaller, no matter how big or smaller your network is,", "tokens": [51360, 754, 1673, 428, 2316, 307, 3801, 420, 4356, 11, 572, 1871, 577, 955, 420, 4356, 428, 3209, 307, 11, 51604], "temperature": 0.0, "avg_logprob": -0.13726318216769495, "compression_ratio": 1.76953125, "no_speech_prob": 0.0006770117324776947}, {"id": 674, "seek": 277418, "start": 2774.18, "end": 2779.06, "text": " the general feature learning regime or paradigm should still hold no matter what", "tokens": [50364, 264, 2674, 4111, 2539, 13120, 420, 24709, 820, 920, 1797, 572, 1871, 437, 50608], "temperature": 0.0, "avg_logprob": -0.07597988487308861, "compression_ratio": 1.779783393501805, "no_speech_prob": 0.0017269679810851812}, {"id": 675, "seek": 277418, "start": 2779.06, "end": 2781.14, "text": " loss function you would end up using.", "tokens": [50608, 4470, 2445, 291, 576, 917, 493, 1228, 13, 50712], "temperature": 0.0, "avg_logprob": -0.07597988487308861, "compression_ratio": 1.779783393501805, "no_speech_prob": 0.0017269679810851812}, {"id": 676, "seek": 277418, "start": 2781.14, "end": 2785.8599999999997, "text": " Yeah, that would be my guess. I think if you're in a regime where it's really hard for you to fit", "tokens": [50712, 865, 11, 300, 576, 312, 452, 2041, 13, 286, 519, 498, 291, 434, 294, 257, 13120, 689, 309, 311, 534, 1152, 337, 291, 281, 3318, 50948], "temperature": 0.0, "avg_logprob": -0.07597988487308861, "compression_ratio": 1.779783393501805, "no_speech_prob": 0.0017269679810851812}, {"id": 677, "seek": 277418, "start": 2785.8599999999997, "end": 2790.5, "text": " the training data, if you have a very small network, it might be the case that you see more", "tokens": [50948, 264, 3097, 1412, 11, 498, 291, 362, 257, 588, 1359, 3209, 11, 309, 1062, 312, 264, 1389, 300, 291, 536, 544, 51180], "temperature": 0.0, "avg_logprob": -0.07597988487308861, "compression_ratio": 1.779783393501805, "no_speech_prob": 0.0017269679810851812}, {"id": 678, "seek": 277418, "start": 2790.5, "end": 2796.74, "text": " differences in the earlier layers because it might be that the loss function really affects", "tokens": [51180, 7300, 294, 264, 3071, 7914, 570, 309, 1062, 312, 300, 264, 4470, 2445, 534, 11807, 51492], "temperature": 0.0, "avg_logprob": -0.07597988487308861, "compression_ratio": 1.779783393501805, "no_speech_prob": 0.0017269679810851812}, {"id": 679, "seek": 277418, "start": 2796.74, "end": 2802.1, "text": " what features are best there in a way that it wouldn't if the network is a bit bigger and if", "tokens": [51492, 437, 4122, 366, 1151, 456, 294, 257, 636, 300, 309, 2759, 380, 498, 264, 3209, 307, 257, 857, 3801, 293, 498, 51760], "temperature": 0.0, "avg_logprob": -0.07597988487308861, "compression_ratio": 1.779783393501805, "no_speech_prob": 0.0017269679810851812}, {"id": 680, "seek": 280210, "start": 2802.1, "end": 2807.94, "text": " it's more capable of fitting your training data. But I don't really know. I think this", "tokens": [50364, 309, 311, 544, 8189, 295, 15669, 428, 3097, 1412, 13, 583, 286, 500, 380, 534, 458, 13, 286, 519, 341, 50656], "temperature": 0.0, "avg_logprob": -0.11208429838481702, "compression_ratio": 1.7102040816326531, "no_speech_prob": 0.0002131357614416629}, {"id": 681, "seek": 280210, "start": 2807.94, "end": 2811.54, "text": " is something that is probably worth looking at in some follow-up work.", "tokens": [50656, 307, 746, 300, 307, 1391, 3163, 1237, 412, 294, 512, 1524, 12, 1010, 589, 13, 50836], "temperature": 0.0, "avg_logprob": -0.11208429838481702, "compression_ratio": 1.7102040816326531, "no_speech_prob": 0.0002131357614416629}, {"id": 682, "seek": 280210, "start": 2812.42, "end": 2817.22, "text": " And you found also there's implications for transfer learning with respect to the loss", "tokens": [50880, 400, 291, 1352, 611, 456, 311, 16602, 337, 5003, 2539, 365, 3104, 281, 264, 4470, 51120], "temperature": 0.0, "avg_logprob": -0.11208429838481702, "compression_ratio": 1.7102040816326531, "no_speech_prob": 0.0002131357614416629}, {"id": 683, "seek": 280210, "start": 2817.22, "end": 2823.54, "text": " function. There seems to be some inverse correlation between the gains you get from a loss", "tokens": [51120, 2445, 13, 821, 2544, 281, 312, 512, 17340, 20009, 1296, 264, 16823, 291, 483, 490, 257, 4470, 51436], "temperature": 0.0, "avg_logprob": -0.11208429838481702, "compression_ratio": 1.7102040816326531, "no_speech_prob": 0.0002131357614416629}, {"id": 684, "seek": 280210, "start": 2823.54, "end": 2829.22, "text": " function and how good it is for transfer learning. Or is there a connection between", "tokens": [51436, 2445, 293, 577, 665, 309, 307, 337, 5003, 2539, 13, 1610, 307, 456, 257, 4984, 1296, 51720], "temperature": 0.0, "avg_logprob": -0.11208429838481702, "compression_ratio": 1.7102040816326531, "no_speech_prob": 0.0002131357614416629}, {"id": 685, "seek": 282922, "start": 2829.22, "end": 2831.9399999999996, "text": " loss functions and regularizers and all of that?", "tokens": [50364, 4470, 6828, 293, 3890, 22525, 293, 439, 295, 300, 30, 50500], "temperature": 0.0, "avg_logprob": -0.06964537620544434, "compression_ratio": 1.67578125, "no_speech_prob": 0.0012838711263611913}, {"id": 686, "seek": 282922, "start": 2832.66, "end": 2837.3799999999997, "text": " Yeah, we look at just linear transfer in the paper. So if we take the features from the", "tokens": [50536, 865, 11, 321, 574, 412, 445, 8213, 5003, 294, 264, 3035, 13, 407, 498, 321, 747, 264, 4122, 490, 264, 50772], "temperature": 0.0, "avg_logprob": -0.06964537620544434, "compression_ratio": 1.67578125, "no_speech_prob": 0.0012838711263611913}, {"id": 687, "seek": 282922, "start": 2837.3799999999997, "end": 2842.4199999999996, "text": " penultimate layer and we try to use them directly for some other task, how good are those features", "tokens": [50772, 3435, 723, 2905, 4583, 293, 321, 853, 281, 764, 552, 3838, 337, 512, 661, 5633, 11, 577, 665, 366, 729, 4122, 51024], "temperature": 0.0, "avg_logprob": -0.06964537620544434, "compression_ratio": 1.67578125, "no_speech_prob": 0.0012838711263611913}, {"id": 688, "seek": 282922, "start": 2842.4199999999996, "end": 2850.8999999999996, "text": " going to be? And what we found was that if you use loss functions that give you higher accuracy", "tokens": [51024, 516, 281, 312, 30, 400, 437, 321, 1352, 390, 300, 498, 291, 764, 4470, 6828, 300, 976, 291, 2946, 14170, 51448], "temperature": 0.0, "avg_logprob": -0.06964537620544434, "compression_ratio": 1.67578125, "no_speech_prob": 0.0012838711263611913}, {"id": 689, "seek": 282922, "start": 2850.8999999999996, "end": 2857.9399999999996, "text": " on ImageNet, you tend to learn representations that transfer substantially worse in that setting.", "tokens": [51448, 322, 29903, 31890, 11, 291, 3928, 281, 1466, 33358, 300, 5003, 30797, 5324, 294, 300, 3287, 13, 51800], "temperature": 0.0, "avg_logprob": -0.06964537620544434, "compression_ratio": 1.67578125, "no_speech_prob": 0.0012838711263611913}, {"id": 690, "seek": 285794, "start": 2858.9, "end": 2864.34, "text": " And our intuition is you could learn many different kinds of representations in that", "tokens": [50412, 400, 527, 24002, 307, 291, 727, 1466, 867, 819, 3685, 295, 33358, 294, 300, 50684], "temperature": 0.0, "avg_logprob": -0.057487935195734474, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.0002530927595216781}, {"id": 691, "seek": 285794, "start": 2864.34, "end": 2870.98, "text": " penultimate layer and still do a reasonable job of classifying ImageNet. But what seems to happen", "tokens": [50684, 3435, 723, 2905, 4583, 293, 920, 360, 257, 10585, 1691, 295, 1508, 5489, 29903, 31890, 13, 583, 437, 2544, 281, 1051, 51016], "temperature": 0.0, "avg_logprob": -0.057487935195734474, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.0002530927595216781}, {"id": 692, "seek": 285794, "start": 2870.98, "end": 2876.82, "text": " is that the loss functions that perform better lead classes to become more separated in the", "tokens": [51016, 307, 300, 264, 4470, 6828, 300, 2042, 1101, 1477, 5359, 281, 1813, 544, 12005, 294, 264, 51308], "temperature": 0.0, "avg_logprob": -0.057487935195734474, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.0002530927595216781}, {"id": 693, "seek": 285794, "start": 2876.82, "end": 2883.2200000000003, "text": " penultimate layer. So like class A and class B will be farther apart relative to the variability", "tokens": [51308, 3435, 723, 2905, 4583, 13, 407, 411, 1508, 316, 293, 1508, 363, 486, 312, 20344, 4936, 4972, 281, 264, 35709, 51628], "temperature": 0.0, "avg_logprob": -0.057487935195734474, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.0002530927595216781}, {"id": 694, "seek": 288322, "start": 2883.22, "end": 2888.8199999999997, "text": " within the class. And when you have a situation like that, you have this penultimate layer", "tokens": [50364, 1951, 264, 1508, 13, 400, 562, 291, 362, 257, 2590, 411, 300, 11, 291, 362, 341, 3435, 723, 2905, 4583, 50644], "temperature": 0.0, "avg_logprob": -0.05603497883058944, "compression_ratio": 1.8410852713178294, "no_speech_prob": 0.03207923844456673}, {"id": 695, "seek": 288322, "start": 2888.8199999999997, "end": 2894.2599999999998, "text": " representation that's specialized for the classes in ImageNet. Like you've got a thousand clusters", "tokens": [50644, 10290, 300, 311, 19813, 337, 264, 5359, 294, 29903, 31890, 13, 1743, 291, 600, 658, 257, 4714, 23313, 50916], "temperature": 0.0, "avg_logprob": -0.05603497883058944, "compression_ratio": 1.8410852713178294, "no_speech_prob": 0.03207923844456673}, {"id": 696, "seek": 288322, "start": 2894.2599999999998, "end": 2900.18, "text": " corresponding to the thousand classes in ImageNet. And so then if you want to use like those kinds", "tokens": [50916, 11760, 281, 264, 4714, 5359, 294, 29903, 31890, 13, 400, 370, 550, 498, 291, 528, 281, 764, 411, 729, 3685, 51212], "temperature": 0.0, "avg_logprob": -0.05603497883058944, "compression_ratio": 1.8410852713178294, "no_speech_prob": 0.03207923844456673}, {"id": 697, "seek": 288322, "start": 2900.18, "end": 2906.1, "text": " of representations for some other task, it will only really work well if you have exactly the", "tokens": [51212, 295, 33358, 337, 512, 661, 5633, 11, 309, 486, 787, 534, 589, 731, 498, 291, 362, 2293, 264, 51508], "temperature": 0.0, "avg_logprob": -0.05603497883058944, "compression_ratio": 1.8410852713178294, "no_speech_prob": 0.03207923844456673}, {"id": 698, "seek": 288322, "start": 2906.1, "end": 2912.2599999999998, "text": " same classes that are in ImageNet because they're already organized by the ImageNet classes.", "tokens": [51508, 912, 5359, 300, 366, 294, 29903, 31890, 570, 436, 434, 1217, 9983, 538, 264, 29903, 31890, 5359, 13, 51816], "temperature": 0.0, "avg_logprob": -0.05603497883058944, "compression_ratio": 1.8410852713178294, "no_speech_prob": 0.03207923844456673}, {"id": 699, "seek": 291226, "start": 2912.34, "end": 2915.78, "text": " On the other hand, what we found is if you just use standard softmax loss,", "tokens": [50368, 1282, 264, 661, 1011, 11, 437, 321, 1352, 307, 498, 291, 445, 764, 3832, 2787, 41167, 4470, 11, 50540], "temperature": 0.0, "avg_logprob": -0.05802630865445701, "compression_ratio": 1.7322175732217573, "no_speech_prob": 0.0004953466122969985}, {"id": 700, "seek": 291226, "start": 2915.78, "end": 2920.5, "text": " actually the classes are not that separated from each other in the penultimate layer", "tokens": [50540, 767, 264, 5359, 366, 406, 300, 12005, 490, 1184, 661, 294, 264, 3435, 723, 2905, 4583, 50776], "temperature": 0.0, "avg_logprob": -0.05802630865445701, "compression_ratio": 1.7322175732217573, "no_speech_prob": 0.0004953466122969985}, {"id": 701, "seek": 291226, "start": 2920.5, "end": 2925.86, "text": " representation. And because they're not that separated, there are these features that you", "tokens": [50776, 10290, 13, 400, 570, 436, 434, 406, 300, 12005, 11, 456, 366, 613, 4122, 300, 291, 51044], "temperature": 0.0, "avg_logprob": -0.05802630865445701, "compression_ratio": 1.7322175732217573, "no_speech_prob": 0.0004953466122969985}, {"id": 702, "seek": 291226, "start": 2925.86, "end": 2931.6200000000003, "text": " could use to classify things that are not ImageNet that still convey some kind of", "tokens": [51044, 727, 764, 281, 33872, 721, 300, 366, 406, 29903, 31890, 300, 920, 16965, 512, 733, 295, 51332], "temperature": 0.0, "avg_logprob": -0.05802630865445701, "compression_ratio": 1.7322175732217573, "no_speech_prob": 0.0004953466122969985}, {"id": 703, "seek": 291226, "start": 2931.6200000000003, "end": 2937.0600000000004, "text": " useful information about the images that are not just their ImageNet class labels.", "tokens": [51332, 4420, 1589, 466, 264, 5267, 300, 366, 406, 445, 641, 29903, 31890, 1508, 16949, 13, 51604], "temperature": 0.0, "avg_logprob": -0.05802630865445701, "compression_ratio": 1.7322175732217573, "no_speech_prob": 0.0004953466122969985}, {"id": 704, "seek": 293706, "start": 2937.94, "end": 2943.7, "text": " It hints at a bit of a future where, you know, like right now on whatever TensorFlow Hub or", "tokens": [50408, 467, 27271, 412, 257, 857, 295, 257, 2027, 689, 11, 291, 458, 11, 411, 558, 586, 322, 2035, 37624, 18986, 420, 50696], "temperature": 0.0, "avg_logprob": -0.13730106548387178, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.006900762673467398}, {"id": 705, "seek": 293706, "start": 2943.7, "end": 2949.22, "text": " HuggingFace repositories and so on, we have these pre-trend models. And the pre-trend models,", "tokens": [50696, 46892, 3249, 37, 617, 22283, 2083, 293, 370, 322, 11, 321, 362, 613, 659, 12, 3599, 273, 5245, 13, 400, 264, 659, 12, 3599, 273, 5245, 11, 50972], "temperature": 0.0, "avg_logprob": -0.13730106548387178, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.006900762673467398}, {"id": 706, "seek": 293706, "start": 2949.22, "end": 2956.1, "text": " they're like full stack models and people usually take some sort of last or next to last hidden layer.", "tokens": [50972, 436, 434, 411, 1577, 8630, 5245, 293, 561, 2673, 747, 512, 1333, 295, 1036, 420, 958, 281, 1036, 7633, 4583, 13, 51316], "temperature": 0.0, "avg_logprob": -0.13730106548387178, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.006900762673467398}, {"id": 707, "seek": 293706, "start": 2956.82, "end": 2964.5, "text": " But maybe we should much more focus on actually providing like half of a network to share. Like", "tokens": [51352, 583, 1310, 321, 820, 709, 544, 1879, 322, 767, 6530, 411, 1922, 295, 257, 3209, 281, 2073, 13, 1743, 51736], "temperature": 0.0, "avg_logprob": -0.13730106548387178, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.006900762673467398}, {"id": 708, "seek": 296450, "start": 2964.5, "end": 2970.58, "text": " determining which are actually the best good or general representations from a data set and so on.", "tokens": [50364, 23751, 597, 366, 767, 264, 1151, 665, 420, 2674, 33358, 490, 257, 1412, 992, 293, 370, 322, 13, 50668], "temperature": 0.0, "avg_logprob": -0.08315972562106151, "compression_ratio": 1.7346938775510203, "no_speech_prob": 0.002756804460659623}, {"id": 709, "seek": 296450, "start": 2970.58, "end": 2973.38, "text": " Do you have any of this in mind when you do work like this?", "tokens": [50668, 1144, 291, 362, 604, 295, 341, 294, 1575, 562, 291, 360, 589, 411, 341, 30, 50808], "temperature": 0.0, "avg_logprob": -0.08315972562106151, "compression_ratio": 1.7346938775510203, "no_speech_prob": 0.002756804460659623}, {"id": 710, "seek": 296450, "start": 2974.5, "end": 2981.06, "text": " Yeah, at Google, what is generally best for us to do is just to fine-tune the whole network.", "tokens": [50864, 865, 11, 412, 3329, 11, 437, 307, 5101, 1151, 337, 505, 281, 360, 307, 445, 281, 2489, 12, 83, 2613, 264, 1379, 3209, 13, 51192], "temperature": 0.0, "avg_logprob": -0.08315972562106151, "compression_ratio": 1.7346938775510203, "no_speech_prob": 0.002756804460659623}, {"id": 711, "seek": 296450, "start": 2981.06, "end": 2984.66, "text": " And if you fine-tune the whole network, it eliminates some of these issues with", "tokens": [51192, 400, 498, 291, 2489, 12, 83, 2613, 264, 1379, 3209, 11, 309, 49893, 512, 295, 613, 2663, 365, 51372], "temperature": 0.0, "avg_logprob": -0.08315972562106151, "compression_ratio": 1.7346938775510203, "no_speech_prob": 0.002756804460659623}, {"id": 712, "seek": 296450, "start": 2985.3, "end": 2990.26, "text": " the actual form of the representation in the penultimate layer. Because even if you have this", "tokens": [51404, 264, 3539, 1254, 295, 264, 10290, 294, 264, 3435, 723, 2905, 4583, 13, 1436, 754, 498, 291, 362, 341, 51652], "temperature": 0.0, "avg_logprob": -0.08315972562106151, "compression_ratio": 1.7346938775510203, "no_speech_prob": 0.002756804460659623}, {"id": 713, "seek": 299026, "start": 2990.26, "end": 2994.9, "text": " kind of highly specialized penultimate layer, when if you're allowed to change all the other", "tokens": [50364, 733, 295, 5405, 19813, 3435, 723, 2905, 4583, 11, 562, 498, 291, 434, 4350, 281, 1319, 439, 264, 661, 50596], "temperature": 0.0, "avg_logprob": -0.0795303931603065, "compression_ratio": 1.7859424920127795, "no_speech_prob": 0.020010724663734436}, {"id": 714, "seek": 299026, "start": 2994.9, "end": 2998.5800000000004, "text": " weights in the network, you can fix that and you can specialize the rest of the network", "tokens": [50596, 17443, 294, 264, 3209, 11, 291, 393, 3191, 300, 293, 291, 393, 37938, 264, 1472, 295, 264, 3209, 50780], "temperature": 0.0, "avg_logprob": -0.0795303931603065, "compression_ratio": 1.7859424920127795, "no_speech_prob": 0.020010724663734436}, {"id": 715, "seek": 299026, "start": 2999.1400000000003, "end": 3004.9, "text": " for some other task. But yeah, I think like it's a really interesting question. If we just want", "tokens": [50808, 337, 512, 661, 5633, 13, 583, 1338, 11, 286, 519, 411, 309, 311, 257, 534, 1880, 1168, 13, 759, 321, 445, 528, 51096], "temperature": 0.0, "avg_logprob": -0.0795303931603065, "compression_ratio": 1.7859424920127795, "no_speech_prob": 0.020010724663734436}, {"id": 716, "seek": 299026, "start": 3004.9, "end": 3009.78, "text": " to turn an image into a vector that we could then train a linear classifier on top of,", "tokens": [51096, 281, 1261, 364, 3256, 666, 257, 8062, 300, 321, 727, 550, 3847, 257, 8213, 1508, 9902, 322, 1192, 295, 11, 51340], "temperature": 0.0, "avg_logprob": -0.0795303931603065, "compression_ratio": 1.7859424920127795, "no_speech_prob": 0.020010724663734436}, {"id": 717, "seek": 299026, "start": 3009.78, "end": 3014.1000000000004, "text": " what is the best way of doing that? How should we approach that problem? And how should we approach", "tokens": [51340, 437, 307, 264, 1151, 636, 295, 884, 300, 30, 1012, 820, 321, 3109, 300, 1154, 30, 400, 577, 820, 321, 3109, 51556], "temperature": 0.0, "avg_logprob": -0.0795303931603065, "compression_ratio": 1.7859424920127795, "no_speech_prob": 0.020010724663734436}, {"id": 718, "seek": 299026, "start": 3014.1000000000004, "end": 3019.6200000000003, "text": " that problem if we want this very like general universal vector representation of an image that", "tokens": [51556, 300, 1154, 498, 321, 528, 341, 588, 411, 2674, 11455, 8062, 10290, 295, 364, 3256, 300, 51832], "temperature": 0.0, "avg_logprob": -0.0795303931603065, "compression_ratio": 1.7859424920127795, "no_speech_prob": 0.020010724663734436}, {"id": 719, "seek": 301962, "start": 3019.62, "end": 3024.02, "text": " would work well for a lot of different tasks? And I think we don't really have good ways of", "tokens": [50364, 576, 589, 731, 337, 257, 688, 295, 819, 9608, 30, 400, 286, 519, 321, 500, 380, 534, 362, 665, 2098, 295, 50584], "temperature": 0.0, "avg_logprob": -0.07731487876490543, "compression_ratio": 1.6391752577319587, "no_speech_prob": 0.0005103083094581962}, {"id": 720, "seek": 301962, "start": 3024.02, "end": 3030.8199999999997, "text": " doing that because basically this is all empirical, right? Like, we don't know what makes a good", "tokens": [50584, 884, 300, 570, 1936, 341, 307, 439, 31886, 11, 558, 30, 1743, 11, 321, 500, 380, 458, 437, 1669, 257, 665, 50924], "temperature": 0.0, "avg_logprob": -0.07731487876490543, "compression_ratio": 1.6391752577319587, "no_speech_prob": 0.0005103083094581962}, {"id": 721, "seek": 301962, "start": 3030.8199999999997, "end": 3035.62, "text": " universal representation of an image. We've just got to try a bunch of things and figure out what", "tokens": [50924, 11455, 10290, 295, 364, 3256, 13, 492, 600, 445, 658, 281, 853, 257, 3840, 295, 721, 293, 2573, 484, 437, 51164], "temperature": 0.0, "avg_logprob": -0.07731487876490543, "compression_ratio": 1.6391752577319587, "no_speech_prob": 0.0005103083094581962}, {"id": 722, "seek": 301962, "start": 3035.62, "end": 3040.42, "text": " works best. And I guess, yeah, the insight from this paper is like actually the loss function", "tokens": [51164, 1985, 1151, 13, 400, 286, 2041, 11, 1338, 11, 264, 11269, 490, 341, 3035, 307, 411, 767, 264, 4470, 2445, 51404], "temperature": 0.0, "avg_logprob": -0.07731487876490543, "compression_ratio": 1.6391752577319587, "no_speech_prob": 0.0005103083094581962}, {"id": 723, "seek": 301962, "start": 3040.42, "end": 3045.94, "text": " that you use to train the network can make a huge difference there. Fascinating. I guess without", "tokens": [51404, 300, 291, 764, 281, 3847, 264, 3209, 393, 652, 257, 2603, 2649, 456, 13, 49098, 8205, 13, 286, 2041, 1553, 51680], "temperature": 0.0, "avg_logprob": -0.07731487876490543, "compression_ratio": 1.6391752577319587, "no_speech_prob": 0.0005103083094581962}, {"id": 724, "seek": 304594, "start": 3045.94, "end": 3052.18, "text": " any further ado, we should move on to SIMCLEAR, a simple framework for contrastive learning of", "tokens": [50364, 604, 3052, 22450, 11, 321, 820, 1286, 322, 281, 24738, 34, 2634, 1899, 11, 257, 2199, 8388, 337, 8712, 488, 2539, 295, 50676], "temperature": 0.0, "avg_logprob": -0.08370238487873602, "compression_ratio": 1.5876288659793814, "no_speech_prob": 0.009182480163872242}, {"id": 725, "seek": 304594, "start": 3052.18, "end": 3057.54, "text": " visual representations. We've been absolutely fascinated by this concept of unsupervised", "tokens": [50676, 5056, 33358, 13, 492, 600, 668, 3122, 24597, 538, 341, 3410, 295, 2693, 12879, 24420, 50944], "temperature": 0.0, "avg_logprob": -0.08370238487873602, "compression_ratio": 1.5876288659793814, "no_speech_prob": 0.009182480163872242}, {"id": 726, "seek": 304594, "start": 3057.54, "end": 3062.82, "text": " contrastive image representation learning algorithms. We've seen such a huge kind of step", "tokens": [50944, 8712, 488, 3256, 10290, 2539, 14642, 13, 492, 600, 1612, 1270, 257, 2603, 733, 295, 1823, 51208], "temperature": 0.0, "avg_logprob": -0.08370238487873602, "compression_ratio": 1.5876288659793814, "no_speech_prob": 0.009182480163872242}, {"id": 727, "seek": 304594, "start": 3062.82, "end": 3069.06, "text": " forward, haven't we, over the last couple of years in this area? Yeah, it's pretty amazing to me.", "tokens": [51208, 2128, 11, 2378, 380, 321, 11, 670, 264, 1036, 1916, 295, 924, 294, 341, 1859, 30, 865, 11, 309, 311, 1238, 2243, 281, 385, 13, 51520], "temperature": 0.0, "avg_logprob": -0.08370238487873602, "compression_ratio": 1.5876288659793814, "no_speech_prob": 0.009182480163872242}, {"id": 728, "seek": 304594, "start": 3069.62, "end": 3073.86, "text": " Could you just go back to real basics? Imagine that people out there have been living in a", "tokens": [51548, 7497, 291, 445, 352, 646, 281, 957, 14688, 30, 11739, 300, 561, 484, 456, 362, 668, 2647, 294, 257, 51760], "temperature": 0.0, "avg_logprob": -0.08370238487873602, "compression_ratio": 1.5876288659793814, "no_speech_prob": 0.009182480163872242}, {"id": 729, "seek": 307386, "start": 3073.86, "end": 3078.58, "text": " cave. They don't know what contrastive learning is. They don't know about image augmentation.", "tokens": [50364, 11730, 13, 814, 500, 380, 458, 437, 8712, 488, 2539, 307, 13, 814, 500, 380, 458, 466, 3256, 14501, 19631, 13, 50600], "temperature": 0.0, "avg_logprob": -0.07645859284834429, "compression_ratio": 1.892116182572614, "no_speech_prob": 0.0013235837686806917}, {"id": 730, "seek": 307386, "start": 3078.58, "end": 3083.94, "text": " How would you frame the whole thing up? The self-supervised learning setup is we've got a", "tokens": [50600, 1012, 576, 291, 3920, 264, 1379, 551, 493, 30, 440, 2698, 12, 48172, 24420, 2539, 8657, 307, 321, 600, 658, 257, 50868], "temperature": 0.0, "avg_logprob": -0.07645859284834429, "compression_ratio": 1.892116182572614, "no_speech_prob": 0.0013235837686806917}, {"id": 731, "seek": 307386, "start": 3083.94, "end": 3091.54, "text": " bunch of images and at least the initial like historical self-supervised learning setup is", "tokens": [50868, 3840, 295, 5267, 293, 412, 1935, 264, 5883, 411, 8584, 2698, 12, 48172, 24420, 2539, 8657, 307, 51248], "temperature": 0.0, "avg_logprob": -0.07645859284834429, "compression_ratio": 1.892116182572614, "no_speech_prob": 0.0013235837686806917}, {"id": 732, "seek": 307386, "start": 3091.54, "end": 3096.98, "text": " we've got a bunch of images. We want to train some kind of neural network on it. And we want", "tokens": [51248, 321, 600, 658, 257, 3840, 295, 5267, 13, 492, 528, 281, 3847, 512, 733, 295, 18161, 3209, 322, 309, 13, 400, 321, 528, 51520], "temperature": 0.0, "avg_logprob": -0.07645859284834429, "compression_ratio": 1.892116182572614, "no_speech_prob": 0.0013235837686806917}, {"id": 733, "seek": 307386, "start": 3096.98, "end": 3100.98, "text": " that neural network to learn a representation such that when we then just train a linear", "tokens": [51520, 300, 18161, 3209, 281, 1466, 257, 10290, 1270, 300, 562, 321, 550, 445, 3847, 257, 8213, 51720], "temperature": 0.0, "avg_logprob": -0.07645859284834429, "compression_ratio": 1.892116182572614, "no_speech_prob": 0.0013235837686806917}, {"id": 734, "seek": 310098, "start": 3100.98, "end": 3105.78, "text": " classifier on top of that representation to classify ImageNet, it's going to do well. But", "tokens": [50364, 1508, 9902, 322, 1192, 295, 300, 10290, 281, 33872, 29903, 31890, 11, 309, 311, 516, 281, 360, 731, 13, 583, 50604], "temperature": 0.0, "avg_logprob": -0.07584127978743793, "compression_ratio": 1.713235294117647, "no_speech_prob": 0.0015008036280050874}, {"id": 735, "seek": 310098, "start": 3105.78, "end": 3111.78, "text": " we want to learn the initial representation without using any kind of labels. And yeah,", "tokens": [50604, 321, 528, 281, 1466, 264, 5883, 10290, 1553, 1228, 604, 733, 295, 16949, 13, 400, 1338, 11, 50904], "temperature": 0.0, "avg_logprob": -0.07584127978743793, "compression_ratio": 1.713235294117647, "no_speech_prob": 0.0015008036280050874}, {"id": 736, "seek": 310098, "start": 3111.78, "end": 3116.98, "text": " I guess there are a lot of different approaches that people tried for this problem. Like people", "tokens": [50904, 286, 2041, 456, 366, 257, 688, 295, 819, 11587, 300, 561, 3031, 337, 341, 1154, 13, 1743, 561, 51164], "temperature": 0.0, "avg_logprob": -0.07584127978743793, "compression_ratio": 1.713235294117647, "no_speech_prob": 0.0015008036280050874}, {"id": 737, "seek": 310098, "start": 3116.98, "end": 3124.66, "text": " tried things like let's train a neural network so that we can cut up the image into just a grid", "tokens": [51164, 3031, 721, 411, 718, 311, 3847, 257, 18161, 3209, 370, 300, 321, 393, 1723, 493, 264, 3256, 666, 445, 257, 10748, 51548], "temperature": 0.0, "avg_logprob": -0.07584127978743793, "compression_ratio": 1.713235294117647, "no_speech_prob": 0.0015008036280050874}, {"id": 738, "seek": 310098, "start": 3124.66, "end": 3129.86, "text": " and shuffle the grid. And then the neural network has to figure out how to assemble these puzzle", "tokens": [51548, 293, 39426, 264, 10748, 13, 400, 550, 264, 18161, 3209, 575, 281, 2573, 484, 577, 281, 22364, 613, 12805, 51808], "temperature": 0.0, "avg_logprob": -0.07584127978743793, "compression_ratio": 1.713235294117647, "no_speech_prob": 0.0015008036280050874}, {"id": 739, "seek": 312986, "start": 3129.86, "end": 3134.9, "text": " pieces back into the original image. And maybe that'll give us a good representation. Or let's try", "tokens": [50364, 3755, 646, 666, 264, 3380, 3256, 13, 400, 1310, 300, 603, 976, 505, 257, 665, 10290, 13, 1610, 718, 311, 853, 50616], "temperature": 0.0, "avg_logprob": -0.0647480649463201, "compression_ratio": 1.7697841726618706, "no_speech_prob": 0.000687713676597923}, {"id": 740, "seek": 312986, "start": 3135.54, "end": 3141.46, "text": " just rotating the images so we can have images that are rotated 90, 180, 270 degrees. And then", "tokens": [50648, 445, 19627, 264, 5267, 370, 321, 393, 362, 5267, 300, 366, 42146, 4289, 11, 11971, 11, 40774, 5310, 13, 400, 550, 50944], "temperature": 0.0, "avg_logprob": -0.0647480649463201, "compression_ratio": 1.7697841726618706, "no_speech_prob": 0.000687713676597923}, {"id": 741, "seek": 312986, "start": 3141.46, "end": 3147.38, "text": " we'll have the neural network try to classify what rotation we fed into it. And so people came up", "tokens": [50944, 321, 603, 362, 264, 18161, 3209, 853, 281, 33872, 437, 12447, 321, 4636, 666, 309, 13, 400, 370, 561, 1361, 493, 51240], "temperature": 0.0, "avg_logprob": -0.0647480649463201, "compression_ratio": 1.7697841726618706, "no_speech_prob": 0.000687713676597923}, {"id": 742, "seek": 312986, "start": 3147.38, "end": 3152.34, "text": " with these kinds of tasks that you could try to train a neural network to do so that it would learn", "tokens": [51240, 365, 613, 3685, 295, 9608, 300, 291, 727, 853, 281, 3847, 257, 18161, 3209, 281, 360, 370, 300, 309, 576, 1466, 51488], "temperature": 0.0, "avg_logprob": -0.0647480649463201, "compression_ratio": 1.7697841726618706, "no_speech_prob": 0.000687713676597923}, {"id": 743, "seek": 312986, "start": 3152.34, "end": 3157.6200000000003, "text": " some kind of good representation. They were defined in this ad hoc way. Let's come up with some kind", "tokens": [51488, 512, 733, 295, 665, 10290, 13, 814, 645, 7642, 294, 341, 614, 16708, 636, 13, 961, 311, 808, 493, 365, 512, 733, 51752], "temperature": 0.0, "avg_logprob": -0.0647480649463201, "compression_ratio": 1.7697841726618706, "no_speech_prob": 0.000687713676597923}, {"id": 744, "seek": 315762, "start": 3157.62, "end": 3163.2999999999997, "text": " of funny thing where you don't need a label. You can have the neural network trained to do", "tokens": [50364, 295, 4074, 551, 689, 291, 500, 380, 643, 257, 7645, 13, 509, 393, 362, 264, 18161, 3209, 8895, 281, 360, 50648], "temperature": 0.0, "avg_logprob": -0.0796292584116866, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.003591920481994748}, {"id": 745, "seek": 315762, "start": 3163.2999999999997, "end": 3169.7, "text": " this kind of thing. And maybe it'll learn something about images. Starting in around 2018, there are", "tokens": [50648, 341, 733, 295, 551, 13, 400, 1310, 309, 603, 1466, 746, 466, 5267, 13, 16217, 294, 926, 6096, 11, 456, 366, 50968], "temperature": 0.0, "avg_logprob": -0.0796292584116866, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.003591920481994748}, {"id": 746, "seek": 315762, "start": 3169.7, "end": 3177.38, "text": " a few papers that basically suggested this alternative approach where you're trying to learn", "tokens": [50968, 257, 1326, 10577, 300, 1936, 10945, 341, 8535, 3109, 689, 291, 434, 1382, 281, 1466, 51352], "temperature": 0.0, "avg_logprob": -0.0796292584116866, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.003591920481994748}, {"id": 747, "seek": 315762, "start": 3177.38, "end": 3183.7799999999997, "text": " some kind of representation space where you've got different patches from an image or different", "tokens": [51352, 512, 733, 295, 10290, 1901, 689, 291, 600, 658, 819, 26531, 490, 364, 3256, 420, 819, 51672], "temperature": 0.0, "avg_logprob": -0.0796292584116866, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.003591920481994748}, {"id": 748, "seek": 318378, "start": 3183.86, "end": 3188.42, "text": " augmentations from an image, just different representations of the same image. And you want", "tokens": [50368, 29919, 763, 490, 364, 3256, 11, 445, 819, 33358, 295, 264, 912, 3256, 13, 400, 291, 528, 50596], "temperature": 0.0, "avg_logprob": -0.06480531215667724, "compression_ratio": 1.9709543568464731, "no_speech_prob": 0.015894362702965736}, {"id": 749, "seek": 318378, "start": 3188.42, "end": 3194.1800000000003, "text": " to learn a representation space where these representations of the same image are all close", "tokens": [50596, 281, 1466, 257, 10290, 1901, 689, 613, 33358, 295, 264, 912, 3256, 366, 439, 1998, 50884], "temperature": 0.0, "avg_logprob": -0.06480531215667724, "compression_ratio": 1.9709543568464731, "no_speech_prob": 0.015894362702965736}, {"id": 750, "seek": 318378, "start": 3194.1800000000003, "end": 3199.86, "text": " together in that representation space. And they're far apart from the representations of other images.", "tokens": [50884, 1214, 294, 300, 10290, 1901, 13, 400, 436, 434, 1400, 4936, 490, 264, 33358, 295, 661, 5267, 13, 51168], "temperature": 0.0, "avg_logprob": -0.06480531215667724, "compression_ratio": 1.9709543568464731, "no_speech_prob": 0.015894362702965736}, {"id": 751, "seek": 318378, "start": 3200.5800000000004, "end": 3207.2200000000003, "text": " This surprisingly seems to lead to very good representations. But it turns out there are a", "tokens": [51204, 639, 17600, 2544, 281, 1477, 281, 588, 665, 33358, 13, 583, 309, 4523, 484, 456, 366, 257, 51536], "temperature": 0.0, "avg_logprob": -0.06480531215667724, "compression_ratio": 1.9709543568464731, "no_speech_prob": 0.015894362702965736}, {"id": 752, "seek": 318378, "start": 3207.2200000000003, "end": 3212.98, "text": " lot of very important details to get this to work well. So it's really like a situation where the", "tokens": [51536, 688, 295, 588, 1021, 4365, 281, 483, 341, 281, 589, 731, 13, 407, 309, 311, 534, 411, 257, 2590, 689, 264, 51824], "temperature": 0.0, "avg_logprob": -0.06480531215667724, "compression_ratio": 1.9709543568464731, "no_speech_prob": 0.015894362702965736}, {"id": 753, "seek": 321298, "start": 3212.98, "end": 3219.3, "text": " basic idea is very simple. Let's create multiple views of an image and try to get them close to", "tokens": [50364, 3875, 1558, 307, 588, 2199, 13, 961, 311, 1884, 3866, 6809, 295, 364, 3256, 293, 853, 281, 483, 552, 1998, 281, 50680], "temperature": 0.0, "avg_logprob": -0.07000177151688905, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.00014878004731144756}, {"id": 754, "seek": 321298, "start": 3219.3, "end": 3225.14, "text": " each other and far away from everything else. But things like augmentation and things like the", "tokens": [50680, 1184, 661, 293, 1400, 1314, 490, 1203, 1646, 13, 583, 721, 411, 14501, 19631, 293, 721, 411, 264, 50972], "temperature": 0.0, "avg_logprob": -0.07000177151688905, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.00014878004731144756}, {"id": 755, "seek": 321298, "start": 3225.14, "end": 3230.82, "text": " exact way we set up the network end up being very important to learning a good representation with", "tokens": [50972, 1900, 636, 321, 992, 493, 264, 3209, 917, 493, 885, 588, 1021, 281, 2539, 257, 665, 10290, 365, 51256], "temperature": 0.0, "avg_logprob": -0.07000177151688905, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.00014878004731144756}, {"id": 756, "seek": 321298, "start": 3230.82, "end": 3235.78, "text": " this kind of technique. How does the negative sampling work? People have done this in different", "tokens": [51256, 341, 733, 295, 6532, 13, 1012, 775, 264, 3671, 21179, 589, 30, 3432, 362, 1096, 341, 294, 819, 51504], "temperature": 0.0, "avg_logprob": -0.07000177151688905, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.00014878004731144756}, {"id": 757, "seek": 321298, "start": 3235.78, "end": 3241.62, "text": " ways. So in Simclear, our way of doing negative sampling is very simple. So basically,", "tokens": [51504, 2098, 13, 407, 294, 3998, 43679, 11, 527, 636, 295, 884, 3671, 21179, 307, 588, 2199, 13, 407, 1936, 11, 51796], "temperature": 0.0, "avg_logprob": -0.07000177151688905, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.00014878004731144756}, {"id": 758, "seek": 324162, "start": 3242.3399999999997, "end": 3251.14, "text": " we are attracting two views of the same image. And then we have a mini batch that has 4,096", "tokens": [50400, 321, 366, 36594, 732, 6809, 295, 264, 912, 3256, 13, 400, 550, 321, 362, 257, 8382, 15245, 300, 575, 1017, 11, 13811, 21, 50840], "temperature": 0.0, "avg_logprob": -0.08028432570005718, "compression_ratio": 1.622093023255814, "no_speech_prob": 0.000969171873293817}, {"id": 759, "seek": 324162, "start": 3251.14, "end": 3258.42, "text": " images in it and two augmentations of each image. And so we are repelling using a softmax from all", "tokens": [50840, 5267, 294, 309, 293, 732, 29919, 763, 295, 1184, 3256, 13, 400, 370, 321, 366, 4301, 2669, 1228, 257, 2787, 41167, 490, 439, 51204], "temperature": 0.0, "avg_logprob": -0.08028432570005718, "compression_ratio": 1.622093023255814, "no_speech_prob": 0.000969171873293817}, {"id": 760, "seek": 324162, "start": 3258.42, "end": 3267.46, "text": " of the other 8,190 views in that mini batch. Basically, we want our two augmentations of", "tokens": [51204, 295, 264, 661, 1649, 11, 3405, 15, 6809, 294, 300, 8382, 15245, 13, 8537, 11, 321, 528, 527, 732, 29919, 763, 295, 51656], "temperature": 0.0, "avg_logprob": -0.08028432570005718, "compression_ratio": 1.622093023255814, "no_speech_prob": 0.000969171873293817}, {"id": 761, "seek": 326746, "start": 3267.46, "end": 3273.14, "text": " the same image close and we want them to be far from the other 8,190 images.", "tokens": [50364, 264, 912, 3256, 1998, 293, 321, 528, 552, 281, 312, 1400, 490, 264, 661, 1649, 11, 3405, 15, 5267, 13, 50648], "temperature": 0.0, "avg_logprob": -0.1182631930789432, "compression_ratio": 1.4385026737967914, "no_speech_prob": 0.006578505504876375}, {"id": 762, "seek": 326746, "start": 3274.42, "end": 3281.14, "text": " Yeah, it's a bit of a throwback to work to VEC. I think it's pretty cool how these ideas just come", "tokens": [50712, 865, 11, 309, 311, 257, 857, 295, 257, 3507, 3207, 281, 589, 281, 691, 8140, 13, 286, 519, 309, 311, 1238, 1627, 577, 613, 3487, 445, 808, 51048], "temperature": 0.0, "avg_logprob": -0.1182631930789432, "compression_ratio": 1.4385026737967914, "no_speech_prob": 0.006578505504876375}, {"id": 763, "seek": 326746, "start": 3281.14, "end": 3289.06, "text": " up through the eras and through the different models and so on. And there is seemingly always", "tokens": [51048, 493, 807, 264, 1189, 296, 293, 807, 264, 819, 5245, 293, 370, 322, 13, 400, 456, 307, 18709, 1009, 51444], "temperature": 0.0, "avg_logprob": -0.1182631930789432, "compression_ratio": 1.4385026737967914, "no_speech_prob": 0.006578505504876375}, {"id": 764, "seek": 328906, "start": 3289.06, "end": 3297.54, "text": " another layer on top of these ideas. Pretty cool. Yeah. So if you only consider, you know,", "tokens": [50364, 1071, 4583, 322, 1192, 295, 613, 3487, 13, 10693, 1627, 13, 865, 13, 407, 498, 291, 787, 1949, 11, 291, 458, 11, 50788], "temperature": 0.0, "avg_logprob": -0.08930061218586374, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.00498026330024004}, {"id": 765, "seek": 328906, "start": 3297.54, "end": 3302.9, "text": " two views that are coming out of the same image as the positive pair, so to speak, and all the other", "tokens": [50788, 732, 6809, 300, 366, 1348, 484, 295, 264, 912, 3256, 382, 264, 3353, 6119, 11, 370, 281, 1710, 11, 293, 439, 264, 661, 51056], "temperature": 0.0, "avg_logprob": -0.08930061218586374, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.00498026330024004}, {"id": 766, "seek": 328906, "start": 3302.9, "end": 3308.74, "text": " views are coming out of the different images located in the same mini batch, wouldn't this hurt", "tokens": [51056, 6809, 366, 1348, 484, 295, 264, 819, 5267, 6870, 294, 264, 912, 8382, 15245, 11, 2759, 380, 341, 4607, 51348], "temperature": 0.0, "avg_logprob": -0.08930061218586374, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.00498026330024004}, {"id": 767, "seek": 328906, "start": 3308.74, "end": 3315.7799999999997, "text": " the representation space to some extent? Let's say you have multiple images of dogs in a mini batch", "tokens": [51348, 264, 10290, 1901, 281, 512, 8396, 30, 961, 311, 584, 291, 362, 3866, 5267, 295, 7197, 294, 257, 8382, 15245, 51700], "temperature": 0.0, "avg_logprob": -0.08930061218586374, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.00498026330024004}, {"id": 768, "seek": 331578, "start": 3316.1800000000003, "end": 3323.2200000000003, "text": " of 4,096 samples. We would essentially want the representations of different dogs to map together", "tokens": [50384, 295, 1017, 11, 13811, 21, 10938, 13, 492, 576, 4476, 528, 264, 33358, 295, 819, 7197, 281, 4471, 1214, 50736], "temperature": 0.0, "avg_logprob": -0.12409707002861556, "compression_ratio": 1.6025641025641026, "no_speech_prob": 0.002049868693575263}, {"id": 769, "seek": 331578, "start": 3323.2200000000003, "end": 3328.5, "text": " as closer as possible in the representation space while representations of cats from dogs would", "tokens": [50736, 382, 4966, 382, 1944, 294, 264, 10290, 1901, 1339, 33358, 295, 11111, 490, 7197, 576, 51000], "temperature": 0.0, "avg_logprob": -0.12409707002861556, "compression_ratio": 1.6025641025641026, "no_speech_prob": 0.002049868693575263}, {"id": 770, "seek": 331578, "start": 3328.5, "end": 3334.5800000000004, "text": " get further away. Wouldn't we expect this? But how does Simclear ensure this rigorously? I guess", "tokens": [51000, 483, 3052, 1314, 13, 26291, 380, 321, 2066, 341, 30, 583, 577, 775, 3998, 43679, 5586, 341, 42191, 5098, 30, 286, 2041, 51304], "temperature": 0.0, "avg_logprob": -0.12409707002861556, "compression_ratio": 1.6025641025641026, "no_speech_prob": 0.002049868693575263}, {"id": 771, "seek": 331578, "start": 3334.5800000000004, "end": 3339.6200000000003, "text": " it's because of the larger batch sizes you use, but I still wanted to know from you.", "tokens": [51304, 309, 311, 570, 295, 264, 4833, 15245, 11602, 291, 764, 11, 457, 286, 920, 1415, 281, 458, 490, 291, 13, 51556], "temperature": 0.0, "avg_logprob": -0.12409707002861556, "compression_ratio": 1.6025641025641026, "no_speech_prob": 0.002049868693575263}, {"id": 772, "seek": 333962, "start": 3339.62, "end": 3346.42, "text": " Yeah, one thing is, even if we've got other kinds of images that we want to be close together in the", "tokens": [50364, 865, 11, 472, 551, 307, 11, 754, 498, 321, 600, 658, 661, 3685, 295, 5267, 300, 321, 528, 281, 312, 1998, 1214, 294, 264, 50704], "temperature": 0.0, "avg_logprob": -0.07914947976871413, "compression_ratio": 1.8851674641148326, "no_speech_prob": 0.002472095424309373}, {"id": 773, "seek": 333962, "start": 3346.42, "end": 3352.1, "text": " mini batch, even if we've got like a dog image and then another dog image and ultimately we want to", "tokens": [50704, 8382, 15245, 11, 754, 498, 321, 600, 658, 411, 257, 3000, 3256, 293, 550, 1071, 3000, 3256, 293, 6284, 321, 528, 281, 50988], "temperature": 0.0, "avg_logprob": -0.07914947976871413, "compression_ratio": 1.8851674641148326, "no_speech_prob": 0.002472095424309373}, {"id": 774, "seek": 333962, "start": 3352.1, "end": 3358.5, "text": " learn a representation space where maybe they're not so far apart, like on average, most of the", "tokens": [50988, 1466, 257, 10290, 1901, 689, 1310, 436, 434, 406, 370, 1400, 4936, 11, 411, 322, 4274, 11, 881, 295, 264, 51308], "temperature": 0.0, "avg_logprob": -0.07914947976871413, "compression_ratio": 1.8851674641148326, "no_speech_prob": 0.002472095424309373}, {"id": 775, "seek": 333962, "start": 3358.5, "end": 3364.3399999999997, "text": " images in the mini batch are things that we want to be really far apart from. So maybe it doesn't", "tokens": [51308, 5267, 294, 264, 8382, 15245, 366, 721, 300, 321, 528, 281, 312, 534, 1400, 4936, 490, 13, 407, 1310, 309, 1177, 380, 51600], "temperature": 0.0, "avg_logprob": -0.07914947976871413, "compression_ratio": 1.8851674641148326, "no_speech_prob": 0.002472095424309373}, {"id": 776, "seek": 336434, "start": 3364.34, "end": 3372.1800000000003, "text": " hurt that much if we're repelling from everything as opposed to just repelling from images that are", "tokens": [50364, 4607, 300, 709, 498, 321, 434, 4301, 2669, 490, 1203, 382, 8851, 281, 445, 4301, 2669, 490, 5267, 300, 366, 50756], "temperature": 0.0, "avg_logprob": -0.05353138245731951, "compression_ratio": 1.7477064220183487, "no_speech_prob": 0.025168541818857193}, {"id": 777, "seek": 336434, "start": 3372.1800000000003, "end": 3378.02, "text": " part of other classes. I think this actually is something that hurts current self-supervised", "tokens": [50756, 644, 295, 661, 5359, 13, 286, 519, 341, 767, 307, 746, 300, 11051, 2190, 2698, 12, 48172, 24420, 51048], "temperature": 0.0, "avg_logprob": -0.05353138245731951, "compression_ratio": 1.7477064220183487, "no_speech_prob": 0.025168541818857193}, {"id": 778, "seek": 336434, "start": 3378.02, "end": 3382.26, "text": " learning techniques and hurts contrastive techniques because we also know when you do the", "tokens": [51048, 2539, 7512, 293, 11051, 8712, 488, 7512, 570, 321, 611, 458, 562, 291, 360, 264, 51260], "temperature": 0.0, "avg_logprob": -0.05353138245731951, "compression_ratio": 1.7477064220183487, "no_speech_prob": 0.025168541818857193}, {"id": 779, "seek": 336434, "start": 3382.26, "end": 3389.2200000000003, "text": " contrastive loss, if you don't contrast against examples that are very close to you, that actually", "tokens": [51260, 8712, 488, 4470, 11, 498, 291, 500, 380, 8712, 1970, 5110, 300, 366, 588, 1998, 281, 291, 11, 300, 767, 51608], "temperature": 0.0, "avg_logprob": -0.05353138245731951, "compression_ratio": 1.7477064220183487, "no_speech_prob": 0.025168541818857193}, {"id": 780, "seek": 338922, "start": 3389.2999999999997, "end": 3394.4199999999996, "text": " improves things a little bit. So if you don't contrast against the very hard negatives,", "tokens": [50368, 24771, 721, 257, 707, 857, 13, 407, 498, 291, 500, 380, 8712, 1970, 264, 588, 1152, 40019, 11, 50624], "temperature": 0.0, "avg_logprob": -0.05930373760370108, "compression_ratio": 1.6775362318840579, "no_speech_prob": 0.05030839890241623}, {"id": 781, "seek": 338922, "start": 3394.4199999999996, "end": 3399.8599999999997, "text": " we've found that gives you slightly higher accuracy when you do this linear evaluation.", "tokens": [50624, 321, 600, 1352, 300, 2709, 291, 4748, 2946, 14170, 562, 291, 360, 341, 8213, 13344, 13, 50896], "temperature": 0.0, "avg_logprob": -0.05930373760370108, "compression_ratio": 1.6775362318840579, "no_speech_prob": 0.05030839890241623}, {"id": 782, "seek": 338922, "start": 3399.8599999999997, "end": 3404.3399999999997, "text": " That kind of suggests that this really is a problem with these techniques that maybe sometimes you", "tokens": [50896, 663, 733, 295, 13409, 300, 341, 534, 307, 257, 1154, 365, 613, 7512, 300, 1310, 2171, 291, 51120], "temperature": 0.0, "avg_logprob": -0.05930373760370108, "compression_ratio": 1.6775362318840579, "no_speech_prob": 0.05030839890241623}, {"id": 783, "seek": 338922, "start": 3404.3399999999997, "end": 3409.8599999999997, "text": " don't want to be as far apart from other images as the losses encouraging you to be. Now there's", "tokens": [51120, 500, 380, 528, 281, 312, 382, 1400, 4936, 490, 661, 5267, 382, 264, 15352, 14580, 291, 281, 312, 13, 823, 456, 311, 51396], "temperature": 0.0, "avg_logprob": -0.05930373760370108, "compression_ratio": 1.6775362318840579, "no_speech_prob": 0.05030839890241623}, {"id": 784, "seek": 338922, "start": 3409.8599999999997, "end": 3415.2999999999997, "text": " one other aspect which is that in Simclear, we don't actually use the representation that's", "tokens": [51396, 472, 661, 4171, 597, 307, 300, 294, 3998, 43679, 11, 321, 500, 380, 767, 764, 264, 10290, 300, 311, 51668], "temperature": 0.0, "avg_logprob": -0.05930373760370108, "compression_ratio": 1.6775362318840579, "no_speech_prob": 0.05030839890241623}, {"id": 785, "seek": 341530, "start": 3415.3, "end": 3421.78, "text": " feeding into the loss function. Like we have this projection head, an MLP on top of the network,", "tokens": [50364, 12919, 666, 264, 4470, 2445, 13, 1743, 321, 362, 341, 22743, 1378, 11, 364, 21601, 47, 322, 1192, 295, 264, 3209, 11, 50688], "temperature": 0.0, "avg_logprob": -0.08920351964122844, "compression_ratio": 1.9253112033195021, "no_speech_prob": 0.02159710042178631}, {"id": 786, "seek": 341530, "start": 3421.78, "end": 3426.9, "text": " and instead of using that representation at the end of the network, we use a representation", "tokens": [50688, 293, 2602, 295, 1228, 300, 10290, 412, 264, 917, 295, 264, 3209, 11, 321, 764, 257, 10290, 50944], "temperature": 0.0, "avg_logprob": -0.08920351964122844, "compression_ratio": 1.9253112033195021, "no_speech_prob": 0.02159710042178631}, {"id": 787, "seek": 341530, "start": 3426.9, "end": 3434.1000000000004, "text": " that's two layers back. And so by using a representation that's two layers back, even if", "tokens": [50944, 300, 311, 732, 7914, 646, 13, 400, 370, 538, 1228, 257, 10290, 300, 311, 732, 7914, 646, 11, 754, 498, 51304], "temperature": 0.0, "avg_logprob": -0.08920351964122844, "compression_ratio": 1.9253112033195021, "no_speech_prob": 0.02159710042178631}, {"id": 788, "seek": 341530, "start": 3434.1000000000004, "end": 3439.3, "text": " in the final layer we're pushing things apart, we kind of figure that this earlier representation", "tokens": [51304, 294, 264, 2572, 4583, 321, 434, 7380, 721, 4936, 11, 321, 733, 295, 2573, 300, 341, 3071, 10290, 51564], "temperature": 0.0, "avg_logprob": -0.08920351964122844, "compression_ratio": 1.9253112033195021, "no_speech_prob": 0.02159710042178631}, {"id": 789, "seek": 341530, "start": 3439.3, "end": 3444.02, "text": " might not have pushed apart the things that really are semantically similar. And indeed,", "tokens": [51564, 1062, 406, 362, 9152, 4936, 264, 721, 300, 534, 366, 4361, 49505, 2531, 13, 400, 6451, 11, 51800], "temperature": 0.0, "avg_logprob": -0.08920351964122844, "compression_ratio": 1.9253112033195021, "no_speech_prob": 0.02159710042178631}, {"id": 790, "seek": 344402, "start": 3444.02, "end": 3449.86, "text": " we find that using this earlier representation in the network leads to higher linear evaluation", "tokens": [50364, 321, 915, 300, 1228, 341, 3071, 10290, 294, 264, 3209, 6689, 281, 2946, 8213, 13344, 50656], "temperature": 0.0, "avg_logprob": -0.115604369871078, "compression_ratio": 1.6440677966101696, "no_speech_prob": 0.0003858112031593919}, {"id": 791, "seek": 344402, "start": 3449.86, "end": 3457.14, "text": " accuracy. So it works better. I was very fascinated by all of these different tricks that you apparently", "tokens": [50656, 14170, 13, 407, 309, 1985, 1101, 13, 286, 390, 588, 24597, 538, 439, 295, 613, 819, 11733, 300, 291, 7970, 51020], "temperature": 0.0, "avg_logprob": -0.115604369871078, "compression_ratio": 1.6440677966101696, "no_speech_prob": 0.0003858112031593919}, {"id": 792, "seek": 344402, "start": 3457.14, "end": 3464.5, "text": " have to get. And so big kudos to figuring all of this out for the rest of us. There has been a", "tokens": [51020, 362, 281, 483, 13, 400, 370, 955, 350, 35063, 281, 15213, 439, 295, 341, 484, 337, 264, 1472, 295, 505, 13, 821, 575, 668, 257, 51388], "temperature": 0.0, "avg_logprob": -0.115604369871078, "compression_ratio": 1.6440677966101696, "no_speech_prob": 0.0003858112031593919}, {"id": 793, "seek": 344402, "start": 3464.5, "end": 3472.18, "text": " lot of follow-up work on this idea. A lot of modifications. There is this bootstrap your own", "tokens": [51388, 688, 295, 1524, 12, 1010, 589, 322, 341, 1558, 13, 316, 688, 295, 26881, 13, 821, 307, 341, 11450, 372, 4007, 428, 1065, 51772], "temperature": 0.0, "avg_logprob": -0.115604369871078, "compression_ratio": 1.6440677966101696, "no_speech_prob": 0.0003858112031593919}, {"id": 794, "seek": 347218, "start": 3472.18, "end": 3479.06, "text": " latent where they completely leave out the negative sampling. Then I think just like one or two weeks", "tokens": [50364, 48994, 689, 436, 2584, 1856, 484, 264, 3671, 21179, 13, 1396, 286, 519, 445, 411, 472, 420, 732, 3259, 50708], "temperature": 0.0, "avg_logprob": -0.1052962887671686, "compression_ratio": 1.5780590717299579, "no_speech_prob": 0.009679905138909817}, {"id": 795, "seek": 347218, "start": 3479.06, "end": 3487.46, "text": " ago, there was a paper saying if you build in a stop gradient into the contrastive loss,", "tokens": [50708, 2057, 11, 456, 390, 257, 3035, 1566, 498, 291, 1322, 294, 257, 1590, 16235, 666, 264, 8712, 488, 4470, 11, 51128], "temperature": 0.0, "avg_logprob": -0.1052962887671686, "compression_ratio": 1.5780590717299579, "no_speech_prob": 0.009679905138909817}, {"id": 796, "seek": 347218, "start": 3487.46, "end": 3493.22, "text": " you also apparently don't need a negative and so on. Do you have maybe from your own work or", "tokens": [51128, 291, 611, 7970, 500, 380, 643, 257, 3671, 293, 370, 322, 13, 1144, 291, 362, 1310, 490, 428, 1065, 589, 420, 51416], "temperature": 0.0, "avg_logprob": -0.1052962887671686, "compression_ratio": 1.5780590717299579, "no_speech_prob": 0.009679905138909817}, {"id": 797, "seek": 347218, "start": 3493.22, "end": 3501.2999999999997, "text": " from work of others, do you have any sort of current? If I were to build a self-supervised", "tokens": [51416, 490, 589, 295, 2357, 11, 360, 291, 362, 604, 1333, 295, 2190, 30, 759, 286, 645, 281, 1322, 257, 2698, 12, 48172, 24420, 51820], "temperature": 0.0, "avg_logprob": -0.1052962887671686, "compression_ratio": 1.5780590717299579, "no_speech_prob": 0.009679905138909817}, {"id": 798, "seek": 350130, "start": 3501.38, "end": 3508.7400000000002, "text": " contrastive representation learner today, what is the top things I should do? What is my recipe?", "tokens": [50368, 8712, 488, 10290, 33347, 965, 11, 437, 307, 264, 1192, 721, 286, 820, 360, 30, 708, 307, 452, 6782, 30, 50736], "temperature": 0.0, "avg_logprob": -0.06672478793712144, "compression_ratio": 1.6343612334801763, "no_speech_prob": 0.00043032749090343714}, {"id": 799, "seek": 350130, "start": 3508.7400000000002, "end": 3515.38, "text": " How do I go about it? The most important part of the recipe is data augmentation. So we're", "tokens": [50736, 1012, 360, 286, 352, 466, 309, 30, 440, 881, 1021, 644, 295, 264, 6782, 307, 1412, 14501, 19631, 13, 407, 321, 434, 51068], "temperature": 0.0, "avg_logprob": -0.06672478793712144, "compression_ratio": 1.6343612334801763, "no_speech_prob": 0.00043032749090343714}, {"id": 800, "seek": 350130, "start": 3515.38, "end": 3520.42, "text": " going to use two views from the same image and it's very important how those two views are", "tokens": [51068, 516, 281, 764, 732, 6809, 490, 264, 912, 3256, 293, 309, 311, 588, 1021, 577, 729, 732, 6809, 366, 51320], "temperature": 0.0, "avg_logprob": -0.06672478793712144, "compression_ratio": 1.6343612334801763, "no_speech_prob": 0.00043032749090343714}, {"id": 801, "seek": 350130, "start": 3520.42, "end": 3527.46, "text": " constructed. But they're really only two super important data augmentations that we need. So", "tokens": [51320, 17083, 13, 583, 436, 434, 534, 787, 732, 1687, 1021, 1412, 29919, 763, 300, 321, 643, 13, 407, 51672], "temperature": 0.0, "avg_logprob": -0.06672478793712144, "compression_ratio": 1.6343612334801763, "no_speech_prob": 0.00043032749090343714}, {"id": 802, "seek": 352746, "start": 3527.46, "end": 3533.54, "text": " we have to take two different crops from the same image and then we have to do some kind of color", "tokens": [50364, 321, 362, 281, 747, 732, 819, 16829, 490, 264, 912, 3256, 293, 550, 321, 362, 281, 360, 512, 733, 295, 2017, 50668], "temperature": 0.0, "avg_logprob": -0.08827084435356988, "compression_ratio": 1.5933609958506223, "no_speech_prob": 0.00035690254298970103}, {"id": 803, "seek": 352746, "start": 3533.54, "end": 3541.2200000000003, "text": " distortion. So in SimClear we use very aggressive color distortion. So that is probably the most", "tokens": [50668, 28426, 13, 407, 294, 3998, 34, 5797, 321, 764, 588, 10762, 2017, 28426, 13, 407, 300, 307, 1391, 264, 881, 51052], "temperature": 0.0, "avg_logprob": -0.08827084435356988, "compression_ratio": 1.5933609958506223, "no_speech_prob": 0.00035690254298970103}, {"id": 804, "seek": 352746, "start": 3541.2200000000003, "end": 3546.9, "text": " important part of the recipe. Then I guess we feed that representation into a neural network", "tokens": [51052, 1021, 644, 295, 264, 6782, 13, 1396, 286, 2041, 321, 3154, 300, 10290, 666, 257, 18161, 3209, 51336], "temperature": 0.0, "avg_logprob": -0.08827084435356988, "compression_ratio": 1.5933609958506223, "no_speech_prob": 0.00035690254298970103}, {"id": 805, "seek": 352746, "start": 3546.9, "end": 3552.42, "text": " and fortunately we found that you can just use a regular ResNet 50 for this part. You don't have", "tokens": [51336, 293, 25511, 321, 1352, 300, 291, 393, 445, 764, 257, 3890, 5015, 31890, 2625, 337, 341, 644, 13, 509, 500, 380, 362, 51612], "temperature": 0.0, "avg_logprob": -0.08827084435356988, "compression_ratio": 1.5933609958506223, "no_speech_prob": 0.00035690254298970103}, {"id": 806, "seek": 355242, "start": 3552.42, "end": 3559.06, "text": " to worry about architecture, engineering, specifically for contrastive learning. Then", "tokens": [50364, 281, 3292, 466, 9482, 11, 7043, 11, 4682, 337, 8712, 488, 2539, 13, 1396, 50696], "temperature": 0.0, "avg_logprob": -0.0764970098223005, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.01168270967900753}, {"id": 807, "seek": 355242, "start": 3559.06, "end": 3564.5, "text": " I think all of the work since SimClear also uses this idea of putting an MLP on top of the end of", "tokens": [50696, 286, 519, 439, 295, 264, 589, 1670, 3998, 34, 5797, 611, 4960, 341, 1558, 295, 3372, 364, 21601, 47, 322, 1192, 295, 264, 917, 295, 50968], "temperature": 0.0, "avg_logprob": -0.0764970098223005, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.01168270967900753}, {"id": 808, "seek": 355242, "start": 3564.5, "end": 3571.06, "text": " the network and then using that to get whatever representation goes into the loss function,", "tokens": [50968, 264, 3209, 293, 550, 1228, 300, 281, 483, 2035, 10290, 1709, 666, 264, 4470, 2445, 11, 51296], "temperature": 0.0, "avg_logprob": -0.0764970098223005, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.01168270967900753}, {"id": 809, "seek": 355242, "start": 3571.06, "end": 3577.3, "text": " but then discarding part of the MLP when we later just want the representation for a downstream", "tokens": [51296, 457, 550, 31597, 278, 644, 295, 264, 21601, 47, 562, 321, 1780, 445, 528, 264, 10290, 337, 257, 30621, 51608], "temperature": 0.0, "avg_logprob": -0.0764970098223005, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.01168270967900753}, {"id": 810, "seek": 357730, "start": 3577.3, "end": 3585.54, "text": " task. All of those pieces are pieces that are shared by all of these modern self-supervised", "tokens": [50364, 5633, 13, 1057, 295, 729, 3755, 366, 3755, 300, 366, 5507, 538, 439, 295, 613, 4363, 2698, 12, 48172, 24420, 50776], "temperature": 0.0, "avg_logprob": -0.08861177617853339, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.010984884575009346}, {"id": 811, "seek": 357730, "start": 3585.54, "end": 3591.78, "text": " learning techniques. So like we introduced the idea of this projection head in SimClear and we", "tokens": [50776, 2539, 7512, 13, 407, 411, 321, 7268, 264, 1558, 295, 341, 22743, 1378, 294, 3998, 34, 5797, 293, 321, 51088], "temperature": 0.0, "avg_logprob": -0.08861177617853339, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.010984884575009346}, {"id": 812, "seek": 357730, "start": 3591.78, "end": 3596.6600000000003, "text": " also spend a lot of time studying the augmentation although we were not the first people to", "tokens": [51088, 611, 3496, 257, 688, 295, 565, 7601, 264, 14501, 19631, 4878, 321, 645, 406, 264, 700, 561, 281, 51332], "temperature": 0.0, "avg_logprob": -0.08861177617853339, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.010984884575009346}, {"id": 813, "seek": 357730, "start": 3597.6200000000003, "end": 3602.6600000000003, "text": " come up with the idea that the augmentation was important. Yeah, in terms of what the loss function", "tokens": [51380, 808, 493, 365, 264, 1558, 300, 264, 14501, 19631, 390, 1021, 13, 865, 11, 294, 2115, 295, 437, 264, 4470, 2445, 51632], "temperature": 0.0, "avg_logprob": -0.08861177617853339, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.010984884575009346}, {"id": 814, "seek": 360266, "start": 3602.66, "end": 3608.18, "text": " is, I guess it's surprising that there are so many things that work that we use this contrastive", "tokens": [50364, 307, 11, 286, 2041, 309, 311, 8830, 300, 456, 366, 370, 867, 721, 300, 589, 300, 321, 764, 341, 8712, 488, 50640], "temperature": 0.0, "avg_logprob": -0.09243484945858225, "compression_ratio": 1.7053571428571428, "no_speech_prob": 0.037856876850128174}, {"id": 815, "seek": 360266, "start": 3608.18, "end": 3613.06, "text": " loss in SimClear because it was what previous work had done and it's like intuitive that you might", "tokens": [50640, 4470, 294, 3998, 34, 5797, 570, 309, 390, 437, 3894, 589, 632, 1096, 293, 309, 311, 411, 21769, 300, 291, 1062, 50884], "temperature": 0.0, "avg_logprob": -0.09243484945858225, "compression_ratio": 1.7053571428571428, "no_speech_prob": 0.037856876850128174}, {"id": 816, "seek": 360266, "start": 3613.06, "end": 3618.74, "text": " want to learn a space where you're explicitly pushing away representations of other examples,", "tokens": [50884, 528, 281, 1466, 257, 1901, 689, 291, 434, 20803, 7380, 1314, 33358, 295, 661, 5110, 11, 51168], "temperature": 0.0, "avg_logprob": -0.09243484945858225, "compression_ratio": 1.7053571428571428, "no_speech_prob": 0.037856876850128174}, {"id": 817, "seek": 360266, "start": 3619.54, "end": 3626.02, "text": " but I guess like in BYOL they aren't explicitly contrasting against representations of other", "tokens": [51208, 457, 286, 2041, 411, 294, 26930, 5046, 436, 3212, 380, 20803, 8712, 278, 1970, 33358, 295, 661, 51532], "temperature": 0.0, "avg_logprob": -0.09243484945858225, "compression_ratio": 1.7053571428571428, "no_speech_prob": 0.037856876850128174}, {"id": 818, "seek": 362602, "start": 3626.02, "end": 3632.74, "text": " examples. So instead they have a network where they're taking a moving average of", "tokens": [50364, 5110, 13, 407, 2602, 436, 362, 257, 3209, 689, 436, 434, 1940, 257, 2684, 4274, 295, 50700], "temperature": 0.0, "avg_logprob": -0.0806556761264801, "compression_ratio": 1.84, "no_speech_prob": 0.05662372708320618}, {"id": 819, "seek": 362602, "start": 3633.62, "end": 3638.58, "text": " the weights that they've been learning and they try to match the representation that's coming", "tokens": [50744, 264, 17443, 300, 436, 600, 668, 2539, 293, 436, 853, 281, 2995, 264, 10290, 300, 311, 1348, 50992], "temperature": 0.0, "avg_logprob": -0.0806556761264801, "compression_ratio": 1.84, "no_speech_prob": 0.05662372708320618}, {"id": 820, "seek": 362602, "start": 3638.58, "end": 3643.86, "text": " out of the network that they're training to this representation of this moving average network", "tokens": [50992, 484, 295, 264, 3209, 300, 436, 434, 3097, 281, 341, 10290, 295, 341, 2684, 4274, 3209, 51256], "temperature": 0.0, "avg_logprob": -0.0806556761264801, "compression_ratio": 1.84, "no_speech_prob": 0.05662372708320618}, {"id": 821, "seek": 362602, "start": 3644.42, "end": 3650.74, "text": " and somehow magically that works and I guess it doesn't even have to be a moving average. I think", "tokens": [51284, 293, 6063, 39763, 300, 1985, 293, 286, 2041, 309, 1177, 380, 754, 362, 281, 312, 257, 2684, 4274, 13, 286, 519, 51600], "temperature": 0.0, "avg_logprob": -0.0806556761264801, "compression_ratio": 1.84, "no_speech_prob": 0.05662372708320618}, {"id": 822, "seek": 365074, "start": 3650.74, "end": 3657.14, "text": " you were referring to earlier like you can just match the representation of one network to", "tokens": [50364, 291, 645, 13761, 281, 3071, 411, 291, 393, 445, 2995, 264, 10290, 295, 472, 3209, 281, 50684], "temperature": 0.0, "avg_logprob": -0.062084412574768065, "compression_ratio": 1.6771300448430493, "no_speech_prob": 0.053371161222457886}, {"id": 823, "seek": 365074, "start": 3657.8599999999997, "end": 3661.9399999999996, "text": " stop gradient of the same network as long as you're matching the representation in an earlier", "tokens": [50720, 1590, 16235, 295, 264, 912, 3209, 382, 938, 382, 291, 434, 14324, 264, 10290, 294, 364, 3071, 50924], "temperature": 0.0, "avg_logprob": -0.062084412574768065, "compression_ratio": 1.6771300448430493, "no_speech_prob": 0.053371161222457886}, {"id": 824, "seek": 365074, "start": 3661.9399999999996, "end": 3669.7, "text": " layer and I think like it's still like mysterious why that should work. I don't really have any", "tokens": [50924, 4583, 293, 286, 519, 411, 309, 311, 920, 411, 13831, 983, 300, 820, 589, 13, 286, 500, 380, 534, 362, 604, 51312], "temperature": 0.0, "avg_logprob": -0.062084412574768065, "compression_ratio": 1.6771300448430493, "no_speech_prob": 0.053371161222457886}, {"id": 825, "seek": 365074, "start": 3669.7, "end": 3679.7, "text": " insight into how either BYOL or the more recent papers actually are learning a representation", "tokens": [51312, 11269, 666, 577, 2139, 26930, 5046, 420, 264, 544, 5162, 10577, 767, 366, 2539, 257, 10290, 51812], "temperature": 0.0, "avg_logprob": -0.062084412574768065, "compression_ratio": 1.6771300448430493, "no_speech_prob": 0.053371161222457886}, {"id": 826, "seek": 367970, "start": 3679.7, "end": 3684.58, "text": " that doesn't end up collapsing. The problem is if you're trying to match some earlier representation", "tokens": [50364, 300, 1177, 380, 917, 493, 45339, 13, 440, 1154, 307, 498, 291, 434, 1382, 281, 2995, 512, 3071, 10290, 50608], "temperature": 0.0, "avg_logprob": -0.08237329155507714, "compression_ratio": 1.7811320754716982, "no_speech_prob": 0.004272593650966883}, {"id": 827, "seek": 367970, "start": 3685.14, "end": 3689.14, "text": " you could just collapse to the point where all of your representations are the same and then", "tokens": [50636, 291, 727, 445, 15584, 281, 264, 935, 689, 439, 295, 428, 33358, 366, 264, 912, 293, 550, 50836], "temperature": 0.0, "avg_logprob": -0.08237329155507714, "compression_ratio": 1.7811320754716982, "no_speech_prob": 0.004272593650966883}, {"id": 828, "seek": 367970, "start": 3689.7, "end": 3696.18, "text": " like you would trivially be matching the earlier representation, but this doesn't happen and I", "tokens": [50864, 411, 291, 576, 1376, 85, 2270, 312, 14324, 264, 3071, 10290, 11, 457, 341, 1177, 380, 1051, 293, 286, 51188], "temperature": 0.0, "avg_logprob": -0.08237329155507714, "compression_ratio": 1.7811320754716982, "no_speech_prob": 0.004272593650966883}, {"id": 829, "seek": 367970, "start": 3696.18, "end": 3701.2999999999997, "text": " think why it doesn't happen relates to some mysteries about neural network training dynamics", "tokens": [51188, 519, 983, 309, 1177, 380, 1051, 16155, 281, 512, 30785, 466, 18161, 3209, 3097, 15679, 51444], "temperature": 0.0, "avg_logprob": -0.08237329155507714, "compression_ratio": 1.7811320754716982, "no_speech_prob": 0.004272593650966883}, {"id": 830, "seek": 367970, "start": 3701.2999999999997, "end": 3706.8199999999997, "text": " that we still don't entirely understand. I'm absolutely fascinated by this concept of data", "tokens": [51444, 300, 321, 920, 500, 380, 7696, 1223, 13, 286, 478, 3122, 24597, 538, 341, 3410, 295, 1412, 51720], "temperature": 0.0, "avg_logprob": -0.08237329155507714, "compression_ratio": 1.7811320754716982, "no_speech_prob": 0.004272593650966883}, {"id": 831, "seek": 370682, "start": 3706.82, "end": 3711.2200000000003, "text": " augmentation. Early on in my neural network career I just imagined it as being a way of", "tokens": [50364, 14501, 19631, 13, 18344, 322, 294, 452, 18161, 3209, 3988, 286, 445, 16590, 309, 382, 885, 257, 636, 295, 50584], "temperature": 0.0, "avg_logprob": -0.11744428754926801, "compression_ratio": 1.6332179930795847, "no_speech_prob": 0.03315182402729988}, {"id": 832, "seek": 370682, "start": 3711.2200000000003, "end": 3716.82, "text": " increasing the size of your training set, but in a sense you're not really adding new information.", "tokens": [50584, 5662, 264, 2744, 295, 428, 3097, 992, 11, 457, 294, 257, 2020, 291, 434, 406, 534, 5127, 777, 1589, 13, 50864], "temperature": 0.0, "avg_logprob": -0.11744428754926801, "compression_ratio": 1.6332179930795847, "no_speech_prob": 0.03315182402729988}, {"id": 833, "seek": 370682, "start": 3717.46, "end": 3723.38, "text": " You are creating semantically equivalent noise perturbations or examples similar to how BERT", "tokens": [50896, 509, 366, 4084, 4361, 49505, 10344, 5658, 40468, 763, 420, 5110, 2531, 281, 577, 363, 31479, 51192], "temperature": 0.0, "avg_logprob": -0.11744428754926801, "compression_ratio": 1.6332179930795847, "no_speech_prob": 0.03315182402729988}, {"id": 834, "seek": 370682, "start": 3723.38, "end": 3728.34, "text": " works the NLP model it's like a denoising autoencoder and you're creating noise diversions of the", "tokens": [51192, 1985, 264, 426, 45196, 2316, 309, 311, 411, 257, 1441, 78, 3436, 8399, 22660, 19866, 293, 291, 434, 4084, 5658, 6111, 626, 295, 264, 51440], "temperature": 0.0, "avg_logprob": -0.11744428754926801, "compression_ratio": 1.6332179930795847, "no_speech_prob": 0.03315182402729988}, {"id": 835, "seek": 370682, "start": 3728.34, "end": 3732.5800000000004, "text": " same thing and pushing the examples off the manifold. So there seems to be a dichotomy between", "tokens": [51440, 912, 551, 293, 7380, 264, 5110, 766, 264, 47138, 13, 407, 456, 2544, 281, 312, 257, 10390, 310, 8488, 1296, 51652], "temperature": 0.0, "avg_logprob": -0.11744428754926801, "compression_ratio": 1.6332179930795847, "no_speech_prob": 0.03315182402729988}, {"id": 836, "seek": 373258, "start": 3732.58, "end": 3736.2599999999998, "text": " on the one hand augmenting your data and it's almost like you're stopping the neural network", "tokens": [50364, 322, 264, 472, 1011, 29919, 278, 428, 1412, 293, 309, 311, 1920, 411, 291, 434, 12767, 264, 18161, 3209, 50548], "temperature": 0.0, "avg_logprob": -0.06169283483910749, "compression_ratio": 1.9417808219178083, "no_speech_prob": 0.0010957472259178758}, {"id": 837, "seek": 373258, "start": 3736.2599999999998, "end": 3741.7799999999997, "text": " from overfitting on things like the color or some specific feature you don't want to. You want to", "tokens": [50548, 490, 670, 69, 2414, 322, 721, 411, 264, 2017, 420, 512, 2685, 4111, 291, 500, 380, 528, 281, 13, 509, 528, 281, 50824], "temperature": 0.0, "avg_logprob": -0.06169283483910749, "compression_ratio": 1.9417808219178083, "no_speech_prob": 0.0010957472259178758}, {"id": 838, "seek": 373258, "start": 3741.7799999999997, "end": 3747.14, "text": " have a bit of generalization, but at the same time you are saying those things over there it's", "tokens": [50824, 362, 257, 857, 295, 2674, 2144, 11, 457, 412, 264, 912, 565, 291, 366, 1566, 729, 721, 670, 456, 309, 311, 51092], "temperature": 0.0, "avg_logprob": -0.06169283483910749, "compression_ratio": 1.9417808219178083, "no_speech_prob": 0.0010957472259178758}, {"id": 839, "seek": 373258, "start": 3747.14, "end": 3751.7, "text": " definitely nothing like that. The data augmentation that you need for contrastive learning is", "tokens": [51092, 2138, 1825, 411, 300, 13, 440, 1412, 14501, 19631, 300, 291, 643, 337, 8712, 488, 2539, 307, 51320], "temperature": 0.0, "avg_logprob": -0.06169283483910749, "compression_ratio": 1.9417808219178083, "no_speech_prob": 0.0010957472259178758}, {"id": 840, "seek": 373258, "start": 3751.7, "end": 3755.7799999999997, "text": " different from the data augmentation that you need for supervised learning because the task is", "tokens": [51320, 819, 490, 264, 1412, 14501, 19631, 300, 291, 643, 337, 46533, 2539, 570, 264, 5633, 307, 51524], "temperature": 0.0, "avg_logprob": -0.06169283483910749, "compression_ratio": 1.9417808219178083, "no_speech_prob": 0.0010957472259178758}, {"id": 841, "seek": 373258, "start": 3755.7799999999997, "end": 3761.22, "text": " different. When you have contrastive learning you have this problem that if there's just one", "tokens": [51524, 819, 13, 1133, 291, 362, 8712, 488, 2539, 291, 362, 341, 1154, 300, 498, 456, 311, 445, 472, 51796], "temperature": 0.0, "avg_logprob": -0.06169283483910749, "compression_ratio": 1.9417808219178083, "no_speech_prob": 0.0010957472259178758}, {"id": 842, "seek": 376122, "start": 3761.22, "end": 3767.7799999999997, "text": " feature in your data that can be used to do the contrastive task to get images of the same example", "tokens": [50364, 4111, 294, 428, 1412, 300, 393, 312, 1143, 281, 360, 264, 8712, 488, 5633, 281, 483, 5267, 295, 264, 912, 1365, 50692], "temperature": 0.0, "avg_logprob": -0.06809868262364314, "compression_ratio": 2.004405286343612, "no_speech_prob": 0.0007319128490053117}, {"id": 843, "seek": 376122, "start": 3767.7799999999997, "end": 3772.2599999999998, "text": " or views of the same example close together and far apart from views of all the other examples.", "tokens": [50692, 420, 6809, 295, 264, 912, 1365, 1998, 1214, 293, 1400, 4936, 490, 6809, 295, 439, 264, 661, 5110, 13, 50916], "temperature": 0.0, "avg_logprob": -0.06809868262364314, "compression_ratio": 2.004405286343612, "no_speech_prob": 0.0007319128490053117}, {"id": 844, "seek": 376122, "start": 3772.2599999999998, "end": 3776.3399999999997, "text": " If you could do that with one feature that would be the only feature the network would", "tokens": [50916, 759, 291, 727, 360, 300, 365, 472, 4111, 300, 576, 312, 264, 787, 4111, 264, 3209, 576, 51120], "temperature": 0.0, "avg_logprob": -0.06809868262364314, "compression_ratio": 2.004405286343612, "no_speech_prob": 0.0007319128490053117}, {"id": 845, "seek": 376122, "start": 3776.3399999999997, "end": 3781.4599999999996, "text": " ever learn or it might be the only feature the network would ever learn. And so with the augmentation", "tokens": [51120, 1562, 1466, 420, 309, 1062, 312, 264, 787, 4111, 264, 3209, 576, 1562, 1466, 13, 400, 370, 365, 264, 14501, 19631, 51376], "temperature": 0.0, "avg_logprob": -0.06809868262364314, "compression_ratio": 2.004405286343612, "no_speech_prob": 0.0007319128490053117}, {"id": 846, "seek": 376122, "start": 3781.4599999999996, "end": 3784.8199999999997, "text": " you're making the task harder so that the network actually has to learn", "tokens": [51376, 291, 434, 1455, 264, 5633, 6081, 370, 300, 264, 3209, 767, 575, 281, 1466, 51544], "temperature": 0.0, "avg_logprob": -0.06809868262364314, "compression_ratio": 2.004405286343612, "no_speech_prob": 0.0007319128490053117}, {"id": 847, "seek": 378482, "start": 3785.78, "end": 3791.2200000000003, "text": " many different kinds of features. So I guess we find that this color distortion", "tokens": [50412, 867, 819, 3685, 295, 4122, 13, 407, 286, 2041, 321, 915, 300, 341, 2017, 28426, 50684], "temperature": 0.0, "avg_logprob": -0.09019243102712729, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.03961414843797684}, {"id": 848, "seek": 378482, "start": 3791.2200000000003, "end": 3795.78, "text": " actually is very important for self-supervised learning, for contrastive learning,", "tokens": [50684, 767, 307, 588, 1021, 337, 2698, 12, 48172, 24420, 2539, 11, 337, 8712, 488, 2539, 11, 50912], "temperature": 0.0, "avg_logprob": -0.09019243102712729, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.03961414843797684}, {"id": 849, "seek": 378482, "start": 3795.78, "end": 3801.7000000000003, "text": " whereas it doesn't really matter for supervised learning. And what we think is going on is that", "tokens": [50912, 9735, 309, 1177, 380, 534, 1871, 337, 46533, 2539, 13, 400, 437, 321, 519, 307, 516, 322, 307, 300, 51208], "temperature": 0.0, "avg_logprob": -0.09019243102712729, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.03961414843797684}, {"id": 850, "seek": 378482, "start": 3801.7000000000003, "end": 3807.7000000000003, "text": " if you have two crops from the same image, generally their color histograms are surprisingly", "tokens": [51208, 498, 291, 362, 732, 16829, 490, 264, 912, 3256, 11, 5101, 641, 2017, 49816, 82, 366, 17600, 51508], "temperature": 0.0, "avg_logprob": -0.09019243102712729, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.03961414843797684}, {"id": 851, "seek": 378482, "start": 3807.7000000000003, "end": 3813.94, "text": " similar. If you just plot out the intensity histogram of the image you can see that the", "tokens": [51508, 2531, 13, 759, 291, 445, 7542, 484, 264, 13749, 49816, 295, 264, 3256, 291, 393, 536, 300, 264, 51820], "temperature": 0.0, "avg_logprob": -0.09019243102712729, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.03961414843797684}, {"id": 852, "seek": 381394, "start": 3813.94, "end": 3819.54, "text": " crops came from the same image. And that's a trick that the network is very good at doing", "tokens": [50364, 16829, 1361, 490, 264, 912, 3256, 13, 400, 300, 311, 257, 4282, 300, 264, 3209, 307, 588, 665, 412, 884, 50644], "temperature": 0.0, "avg_logprob": -0.0730587360905666, "compression_ratio": 1.7439024390243902, "no_speech_prob": 0.0006260412046685815}, {"id": 853, "seek": 381394, "start": 3819.54, "end": 3824.1, "text": " because I guess if you have ReLU activations they're very good at computing histograms.", "tokens": [50644, 570, 286, 2041, 498, 291, 362, 1300, 43, 52, 2430, 763, 436, 434, 588, 665, 412, 15866, 49816, 82, 13, 50872], "temperature": 0.0, "avg_logprob": -0.0730587360905666, "compression_ratio": 1.7439024390243902, "no_speech_prob": 0.0006260412046685815}, {"id": 854, "seek": 381394, "start": 3824.82, "end": 3830.5, "text": " And so by doing the color distortion we basically we don't let the network just learn", "tokens": [50908, 400, 370, 538, 884, 264, 2017, 28426, 321, 1936, 321, 500, 380, 718, 264, 3209, 445, 1466, 51192], "temperature": 0.0, "avg_logprob": -0.0730587360905666, "compression_ratio": 1.7439024390243902, "no_speech_prob": 0.0006260412046685815}, {"id": 855, "seek": 381394, "start": 3831.14, "end": 3835.62, "text": " the color histograms in order to do the contrastive task. We force the network", "tokens": [51224, 264, 2017, 49816, 82, 294, 1668, 281, 360, 264, 8712, 488, 5633, 13, 492, 3464, 264, 3209, 51448], "temperature": 0.0, "avg_logprob": -0.0730587360905666, "compression_ratio": 1.7439024390243902, "no_speech_prob": 0.0006260412046685815}, {"id": 856, "seek": 381394, "start": 3835.62, "end": 3840.66, "text": " to actually use other sorts of information and that ends up being like critical to the", "tokens": [51448, 281, 767, 764, 661, 7527, 295, 1589, 293, 300, 5314, 493, 885, 411, 4924, 281, 264, 51700], "temperature": 0.0, "avg_logprob": -0.0730587360905666, "compression_ratio": 1.7439024390243902, "no_speech_prob": 0.0006260412046685815}, {"id": 857, "seek": 384066, "start": 3840.66, "end": 3844.98, "text": " performance of these contrastive methods. Like it basically doesn't work unless you do", "tokens": [50364, 3389, 295, 613, 8712, 488, 7150, 13, 1743, 309, 1936, 1177, 380, 589, 5969, 291, 360, 50580], "temperature": 0.0, "avg_logprob": -0.0897044198853629, "compression_ratio": 1.813953488372093, "no_speech_prob": 0.0019260229310020804}, {"id": 858, "seek": 384066, "start": 3845.7, "end": 3850.18, "text": " that kind of aggressive color distortion. Because that seems to be the key thing then. So you're", "tokens": [50616, 300, 733, 295, 10762, 2017, 28426, 13, 1436, 300, 2544, 281, 312, 264, 2141, 551, 550, 13, 407, 291, 434, 50840], "temperature": 0.0, "avg_logprob": -0.0897044198853629, "compression_ratio": 1.813953488372093, "no_speech_prob": 0.0019260229310020804}, {"id": 859, "seek": 384066, "start": 3850.18, "end": 3856.58, "text": " not telling it to learn things, you're telling it not to learn things. We're telling it to learn", "tokens": [50840, 406, 3585, 309, 281, 1466, 721, 11, 291, 434, 3585, 309, 406, 281, 1466, 721, 13, 492, 434, 3585, 309, 281, 1466, 51160], "temperature": 0.0, "avg_logprob": -0.0897044198853629, "compression_ratio": 1.813953488372093, "no_speech_prob": 0.0019260229310020804}, {"id": 860, "seek": 384066, "start": 3856.58, "end": 3862.18, "text": " one thing. We're telling it to learn figure out which views came from the same image. But then,", "tokens": [51160, 472, 551, 13, 492, 434, 3585, 309, 281, 1466, 2573, 484, 597, 6809, 1361, 490, 264, 912, 3256, 13, 583, 550, 11, 51440], "temperature": 0.0, "avg_logprob": -0.0897044198853629, "compression_ratio": 1.813953488372093, "no_speech_prob": 0.0019260229310020804}, {"id": 861, "seek": 384066, "start": 3862.18, "end": 3868.74, "text": " yeah, we have to make sure that it learns to do that with a diverse set of features instead", "tokens": [51440, 1338, 11, 321, 362, 281, 652, 988, 300, 309, 27152, 281, 360, 300, 365, 257, 9521, 992, 295, 4122, 2602, 51768], "temperature": 0.0, "avg_logprob": -0.0897044198853629, "compression_ratio": 1.813953488372093, "no_speech_prob": 0.0019260229310020804}, {"id": 862, "seek": 386874, "start": 3868.74, "end": 3874.18, "text": " of just doing it in one way. Because I guess it's like a task that's actually pretty easy to do if", "tokens": [50364, 295, 445, 884, 309, 294, 472, 636, 13, 1436, 286, 2041, 309, 311, 411, 257, 5633, 300, 311, 767, 1238, 1858, 281, 360, 498, 50636], "temperature": 0.0, "avg_logprob": -0.08755785105179767, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.002215835964307189}, {"id": 863, "seek": 386874, "start": 3874.18, "end": 3881.06, "text": " you don't have this kind of aggressive augmentation. Yeah, I think in a way it helps the network to", "tokens": [50636, 291, 500, 380, 362, 341, 733, 295, 10762, 14501, 19631, 13, 865, 11, 286, 519, 294, 257, 636, 309, 3665, 264, 3209, 281, 50980], "temperature": 0.0, "avg_logprob": -0.08755785105179767, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.002215835964307189}, {"id": 864, "seek": 386874, "start": 3881.06, "end": 3886.58, "text": " also differentiate what actually what is the thing that differentiates two images. I think", "tokens": [50980, 611, 23203, 437, 767, 437, 307, 264, 551, 300, 27372, 1024, 732, 5267, 13, 286, 519, 51256], "temperature": 0.0, "avg_logprob": -0.08755785105179767, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.002215835964307189}, {"id": 865, "seek": 386874, "start": 3887.2999999999997, "end": 3893.3799999999997, "text": " it helps the network to learn, you know, pick up on that signal. To that end, I also wanted to ask", "tokens": [51292, 309, 3665, 264, 3209, 281, 1466, 11, 291, 458, 11, 1888, 493, 322, 300, 6358, 13, 1407, 300, 917, 11, 286, 611, 1415, 281, 1029, 51596], "temperature": 0.0, "avg_logprob": -0.08755785105179767, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.002215835964307189}, {"id": 866, "seek": 389338, "start": 3893.38, "end": 3899.78, "text": " for a custom dataset, if I wanted to, you know, apply a sim clear, what pointers should I take", "tokens": [50364, 337, 257, 2375, 28872, 11, 498, 286, 1415, 281, 11, 291, 458, 11, 3079, 257, 1034, 1850, 11, 437, 44548, 820, 286, 747, 50684], "temperature": 0.0, "avg_logprob": -0.12101481893788213, "compression_ratio": 1.6598639455782314, "no_speech_prob": 0.0013667335733771324}, {"id": 867, "seek": 389338, "start": 3899.78, "end": 3904.82, "text": " into consideration while designing my augmentation policy? I'm sure you have been asked about this", "tokens": [50684, 666, 12381, 1339, 14685, 452, 14501, 19631, 3897, 30, 286, 478, 988, 291, 362, 668, 2351, 466, 341, 50936], "temperature": 0.0, "avg_logprob": -0.12101481893788213, "compression_ratio": 1.6598639455782314, "no_speech_prob": 0.0013667335733771324}, {"id": 868, "seek": 389338, "start": 3904.82, "end": 3909.7000000000003, "text": " question quite a few times. But yeah, I think it's a good question. Like I think like we actually", "tokens": [50936, 1168, 1596, 257, 1326, 1413, 13, 583, 1338, 11, 286, 519, 309, 311, 257, 665, 1168, 13, 1743, 286, 519, 411, 321, 767, 51180], "temperature": 0.0, "avg_logprob": -0.12101481893788213, "compression_ratio": 1.6598639455782314, "no_speech_prob": 0.0013667335733771324}, {"id": 869, "seek": 389338, "start": 3909.7000000000003, "end": 3914.7400000000002, "text": " still don't really know how generalizable these contrastive learning techniques are beyond image", "tokens": [51180, 920, 500, 380, 534, 458, 577, 2674, 22395, 613, 8712, 488, 2539, 7512, 366, 4399, 3256, 51432], "temperature": 0.0, "avg_logprob": -0.12101481893788213, "compression_ratio": 1.6598639455782314, "no_speech_prob": 0.0013667335733771324}, {"id": 870, "seek": 389338, "start": 3914.7400000000002, "end": 3920.9, "text": " net. Like we know they work super well on image net. But like image net is like a boring dataset to", "tokens": [51432, 2533, 13, 1743, 321, 458, 436, 589, 1687, 731, 322, 3256, 2533, 13, 583, 411, 3256, 2533, 307, 411, 257, 9989, 28872, 281, 51740], "temperature": 0.0, "avg_logprob": -0.12101481893788213, "compression_ratio": 1.6598639455782314, "no_speech_prob": 0.0013667335733771324}, {"id": 871, "seek": 392090, "start": 3920.9, "end": 3924.98, "text": " apply contrastive learning to because we actually already have all the labels and we could just be", "tokens": [50364, 3079, 8712, 488, 2539, 281, 570, 321, 767, 1217, 362, 439, 264, 16949, 293, 321, 727, 445, 312, 50568], "temperature": 0.0, "avg_logprob": -0.07353673892074757, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0014101192355155945}, {"id": 872, "seek": 392090, "start": 3924.98, "end": 3932.6600000000003, "text": " doing supervised learning. But I think starting with the crop and color augmentation is definitely a", "tokens": [50568, 884, 46533, 2539, 13, 583, 286, 519, 2891, 365, 264, 9086, 293, 2017, 14501, 19631, 307, 2138, 257, 50952], "temperature": 0.0, "avg_logprob": -0.07353673892074757, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0014101192355155945}, {"id": 873, "seek": 392090, "start": 3932.6600000000003, "end": 3937.78, "text": " good idea, at least like for datasets that have color, I guess if you don't have color, then maybe", "tokens": [50952, 665, 1558, 11, 412, 1935, 411, 337, 42856, 300, 362, 2017, 11, 286, 2041, 498, 291, 500, 380, 362, 2017, 11, 550, 1310, 51208], "temperature": 0.0, "avg_logprob": -0.07353673892074757, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0014101192355155945}, {"id": 874, "seek": 392090, "start": 3937.78, "end": 3945.78, "text": " think about distorting intensities instead of colors. But beyond that, I think it depends on the", "tokens": [51208, 519, 466, 37555, 278, 14056, 1088, 2602, 295, 4577, 13, 583, 4399, 300, 11, 286, 519, 309, 5946, 322, 264, 51608], "temperature": 0.0, "avg_logprob": -0.07353673892074757, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0014101192355155945}, {"id": 875, "seek": 394578, "start": 3945.86, "end": 3951.46, "text": " specific task and what you really want the neural network to pick up out of the dataset.", "tokens": [50368, 2685, 5633, 293, 437, 291, 534, 528, 264, 18161, 3209, 281, 1888, 493, 484, 295, 264, 28872, 13, 50648], "temperature": 0.0, "avg_logprob": -0.09296609674181257, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.023684313520789146}, {"id": 876, "seek": 394578, "start": 3952.02, "end": 3956.82, "text": " I feel like there are probably some sorts of data where I wouldn't really expect", "tokens": [50676, 286, 841, 411, 456, 366, 1391, 512, 7527, 295, 1412, 689, 286, 2759, 380, 534, 2066, 50916], "temperature": 0.0, "avg_logprob": -0.09296609674181257, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.023684313520789146}, {"id": 877, "seek": 394578, "start": 3957.6200000000003, "end": 3964.34, "text": " contrastive learning to work well. So for example, like if you try to do contrastive learning on a", "tokens": [50956, 8712, 488, 2539, 281, 589, 731, 13, 407, 337, 1365, 11, 411, 498, 291, 853, 281, 360, 8712, 488, 2539, 322, 257, 51292], "temperature": 0.0, "avg_logprob": -0.09296609674181257, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.023684313520789146}, {"id": 878, "seek": 394578, "start": 3964.34, "end": 3971.6200000000003, "text": " dataset of medical images where you've just got healthy patients, and then you want to translate", "tokens": [51292, 28872, 295, 4625, 5267, 689, 291, 600, 445, 658, 4627, 4209, 11, 293, 550, 291, 528, 281, 13799, 51656], "temperature": 0.0, "avg_logprob": -0.09296609674181257, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.023684313520789146}, {"id": 879, "seek": 397162, "start": 3971.62, "end": 3977.62, "text": " that to like some sort of dataset of people with some kind of pathology, you might never pick up the", "tokens": [50364, 300, 281, 411, 512, 1333, 295, 28872, 295, 561, 365, 512, 733, 295, 3100, 1793, 11, 291, 1062, 1128, 1888, 493, 264, 50664], "temperature": 0.0, "avg_logprob": -0.07876081286736254, "compression_ratio": 1.7683823529411764, "no_speech_prob": 0.00668747816234827}, {"id": 880, "seek": 397162, "start": 3977.62, "end": 3982.9, "text": " features that are important for detecting the pathology. But yeah, I think this question of how", "tokens": [50664, 4122, 300, 366, 1021, 337, 40237, 264, 3100, 1793, 13, 583, 1338, 11, 286, 519, 341, 1168, 295, 577, 50928], "temperature": 0.0, "avg_logprob": -0.07876081286736254, "compression_ratio": 1.7683823529411764, "no_speech_prob": 0.00668747816234827}, {"id": 881, "seek": 397162, "start": 3982.9, "end": 3987.8599999999997, "text": " do you design the augmentation, what augmentation works well for datasets that maybe aren't natural", "tokens": [50928, 360, 291, 1715, 264, 14501, 19631, 11, 437, 14501, 19631, 1985, 731, 337, 42856, 300, 1310, 3212, 380, 3303, 51176], "temperature": 0.0, "avg_logprob": -0.07876081286736254, "compression_ratio": 1.7683823529411764, "no_speech_prob": 0.00668747816234827}, {"id": 882, "seek": 397162, "start": 3987.8599999999997, "end": 3994.02, "text": " images like these kinds of medical images or maybe like satellite images. That's an important", "tokens": [51176, 5267, 411, 613, 3685, 295, 4625, 5267, 420, 1310, 411, 16016, 5267, 13, 663, 311, 364, 1021, 51484], "temperature": 0.0, "avg_logprob": -0.07876081286736254, "compression_ratio": 1.7683823529411764, "no_speech_prob": 0.00668747816234827}, {"id": 883, "seek": 397162, "start": 3994.02, "end": 3999.2999999999997, "text": " question that we haven't addressed yet. There seems to be this fascinating universality of", "tokens": [51484, 1168, 300, 321, 2378, 380, 13847, 1939, 13, 821, 2544, 281, 312, 341, 10343, 5950, 1860, 295, 51748], "temperature": 0.0, "avg_logprob": -0.07876081286736254, "compression_ratio": 1.7683823529411764, "no_speech_prob": 0.00668747816234827}, {"id": 884, "seek": 399930, "start": 3999.3, "end": 4003.86, "text": " representations, especially in vision. This is exactly the kind of thing you can test with your", "tokens": [50364, 33358, 11, 2318, 294, 5201, 13, 639, 307, 2293, 264, 733, 295, 551, 291, 393, 1500, 365, 428, 50592], "temperature": 0.0, "avg_logprob": -0.06462430953979492, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.004322236403822899}, {"id": 885, "seek": 399930, "start": 4003.86, "end": 4009.7000000000003, "text": " wonderful similarity matrix idea. I'm not trying to be flippant when I say this because", "tokens": [50592, 3715, 32194, 8141, 1558, 13, 286, 478, 406, 1382, 281, 312, 932, 2488, 394, 562, 286, 584, 341, 570, 50884], "temperature": 0.0, "avg_logprob": -0.06462430953979492, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.004322236403822899}, {"id": 886, "seek": 399930, "start": 4009.7000000000003, "end": 4015.3, "text": " practitioners have used ImageNet on a variety of downstream tasks. For example, they might use it for", "tokens": [50884, 25742, 362, 1143, 29903, 31890, 322, 257, 5673, 295, 30621, 9608, 13, 1171, 1365, 11, 436, 1062, 764, 309, 337, 51164], "temperature": 0.0, "avg_logprob": -0.06462430953979492, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.004322236403822899}, {"id": 887, "seek": 399930, "start": 4015.3, "end": 4020.02, "text": " classifying circuit boards or something. And the miraculous thing is it just seems to work quite", "tokens": [51164, 1508, 5489, 9048, 13293, 420, 746, 13, 400, 264, 41101, 551, 307, 309, 445, 2544, 281, 589, 1596, 51400], "temperature": 0.0, "avg_logprob": -0.06462430953979492, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.004322236403822899}, {"id": 888, "seek": 399930, "start": 4020.02, "end": 4025.78, "text": " well. So do you think in your opinion that there is some kind of universality? I'm very skeptical", "tokens": [51400, 731, 13, 407, 360, 291, 519, 294, 428, 4800, 300, 456, 307, 512, 733, 295, 5950, 1860, 30, 286, 478, 588, 28601, 51688], "temperature": 0.0, "avg_logprob": -0.06462430953979492, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.004322236403822899}, {"id": 889, "seek": 402578, "start": 4025.78, "end": 4032.98, "text": " about like universality of ImageNet for different tasks. Like in the past, we did some work where", "tokens": [50364, 466, 411, 5950, 1860, 295, 29903, 31890, 337, 819, 9608, 13, 1743, 294, 264, 1791, 11, 321, 630, 512, 589, 689, 50724], "temperature": 0.0, "avg_logprob": -0.0841452084230573, "compression_ratio": 1.7194570135746607, "no_speech_prob": 0.0013668439351022243}, {"id": 890, "seek": 402578, "start": 4032.98, "end": 4039.38, "text": " we looked at how well ImageNet networks transfer to other tasks. And it seems like", "tokens": [50724, 321, 2956, 412, 577, 731, 29903, 31890, 9590, 5003, 281, 661, 9608, 13, 400, 309, 2544, 411, 51044], "temperature": 0.0, "avg_logprob": -0.0841452084230573, "compression_ratio": 1.7194570135746607, "no_speech_prob": 0.0013668439351022243}, {"id": 891, "seek": 402578, "start": 4040.1800000000003, "end": 4047.0600000000004, "text": " there are actually some tasks which are just like datasets of natural images where pre-training an", "tokens": [51084, 456, 366, 767, 512, 9608, 597, 366, 445, 411, 42856, 295, 3303, 5267, 689, 659, 12, 17227, 1760, 364, 51428], "temperature": 0.0, "avg_logprob": -0.0841452084230573, "compression_ratio": 1.7194570135746607, "no_speech_prob": 0.0013668439351022243}, {"id": 892, "seek": 402578, "start": 4047.0600000000004, "end": 4053.38, "text": " ImageNet doesn't really help at all. And those datasets just seem to be too different from ImageNet.", "tokens": [51428, 29903, 31890, 1177, 380, 534, 854, 412, 439, 13, 400, 729, 42856, 445, 1643, 281, 312, 886, 819, 490, 29903, 31890, 13, 51744], "temperature": 0.0, "avg_logprob": -0.0841452084230573, "compression_ratio": 1.7194570135746607, "no_speech_prob": 0.0013668439351022243}, {"id": 893, "seek": 405338, "start": 4053.38, "end": 4060.1, "text": " They're things like this Stanford cars dataset where you have to like classify different cars", "tokens": [50364, 814, 434, 721, 411, 341, 20374, 5163, 28872, 689, 291, 362, 281, 411, 33872, 819, 5163, 50700], "temperature": 0.0, "avg_logprob": -0.10778189971383693, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.0030749032739549875}, {"id": 894, "seek": 405338, "start": 4060.1, "end": 4065.1400000000003, "text": " according to their make, model, and year. It turns out even though there are lots of cars in ImageNet,", "tokens": [50700, 4650, 281, 641, 652, 11, 2316, 11, 293, 1064, 13, 467, 4523, 484, 754, 1673, 456, 366, 3195, 295, 5163, 294, 29903, 31890, 11, 50952], "temperature": 0.0, "avg_logprob": -0.10778189971383693, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.0030749032739549875}, {"id": 895, "seek": 405338, "start": 4065.1400000000003, "end": 4070.42, "text": " if you pre-train on ImageNet and you fine-tune on that dataset, you will learn to classify it", "tokens": [50952, 498, 291, 659, 12, 83, 7146, 322, 29903, 31890, 293, 291, 2489, 12, 83, 2613, 322, 300, 28872, 11, 291, 486, 1466, 281, 33872, 309, 51216], "temperature": 0.0, "avg_logprob": -0.10778189971383693, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.0030749032739549875}, {"id": 896, "seek": 405338, "start": 4070.42, "end": 4076.1, "text": " faster in fewer steps than if you had trained from scratch on the Stanford cars dataset.", "tokens": [51216, 4663, 294, 13366, 4439, 813, 498, 291, 632, 8895, 490, 8459, 322, 264, 20374, 5163, 28872, 13, 51500], "temperature": 0.0, "avg_logprob": -0.10778189971383693, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.0030749032739549875}, {"id": 897, "seek": 405338, "start": 4076.82, "end": 4081.7000000000003, "text": " But you won't actually perform any better at the end. And that's true even though the", "tokens": [51536, 583, 291, 1582, 380, 767, 2042, 604, 1101, 412, 264, 917, 13, 400, 300, 311, 2074, 754, 1673, 264, 51780], "temperature": 0.0, "avg_logprob": -0.10778189971383693, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.0030749032739549875}, {"id": 898, "seek": 408170, "start": 4081.7799999999997, "end": 4088.66, "text": " Stanford cars dataset has 10,000 images. So it's tiny compared to ImageNet. So I think like actually", "tokens": [50368, 20374, 5163, 28872, 575, 1266, 11, 1360, 5267, 13, 407, 309, 311, 5870, 5347, 281, 29903, 31890, 13, 407, 286, 519, 411, 767, 50712], "temperature": 0.0, "avg_logprob": -0.06640909494978658, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.00023780090850777924}, {"id": 899, "seek": 408170, "start": 4088.66, "end": 4096.0199999999995, "text": " representations of images are not that universal. And at least what works for natural images for", "tokens": [50712, 33358, 295, 5267, 366, 406, 300, 11455, 13, 400, 412, 1935, 437, 1985, 337, 3303, 5267, 337, 51080], "temperature": 0.0, "avg_logprob": -0.06640909494978658, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.00023780090850777924}, {"id": 900, "seek": 408170, "start": 4096.0199999999995, "end": 4102.82, "text": " images like those in ImageNet may not work on other datasets. I think there's also like limited", "tokens": [51080, 5267, 411, 729, 294, 29903, 31890, 815, 406, 589, 322, 661, 42856, 13, 286, 519, 456, 311, 611, 411, 5567, 51420], "temperature": 0.0, "avg_logprob": -0.06640909494978658, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.00023780090850777924}, {"id": 901, "seek": 408170, "start": 4102.82, "end": 4109.22, "text": " evidence for transfer from ImageNet to medical datasets. It seems if you don't like work really", "tokens": [51420, 4467, 337, 5003, 490, 29903, 31890, 281, 4625, 42856, 13, 467, 2544, 498, 291, 500, 380, 411, 589, 534, 51740], "temperature": 0.0, "avg_logprob": -0.06640909494978658, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.00023780090850777924}, {"id": 902, "seek": 410922, "start": 4109.22, "end": 4115.38, "text": " hard at tuning hyperparameters or if you don't train for long enough, you will get better accuracy", "tokens": [50364, 1152, 412, 15164, 9848, 2181, 335, 6202, 420, 498, 291, 500, 380, 3847, 337, 938, 1547, 11, 291, 486, 483, 1101, 14170, 50672], "temperature": 0.0, "avg_logprob": -0.056658525724668764, "compression_ratio": 1.8021978021978022, "no_speech_prob": 0.005554134491831064}, {"id": 903, "seek": 410922, "start": 4115.38, "end": 4120.18, "text": " by starting with an ImageNet pre-trained network. But if you do very thorough experiments and you", "tokens": [50672, 538, 2891, 365, 364, 29903, 31890, 659, 12, 17227, 2001, 3209, 13, 583, 498, 291, 360, 588, 12934, 12050, 293, 291, 50912], "temperature": 0.0, "avg_logprob": -0.056658525724668764, "compression_ratio": 1.8021978021978022, "no_speech_prob": 0.005554134491831064}, {"id": 904, "seek": 410922, "start": 4120.18, "end": 4124.820000000001, "text": " train for long enough, you try different learning rates and weight decay parameters, like actually", "tokens": [50912, 3847, 337, 938, 1547, 11, 291, 853, 819, 2539, 6846, 293, 3364, 21039, 9834, 11, 411, 767, 51144], "temperature": 0.0, "avg_logprob": -0.056658525724668764, "compression_ratio": 1.8021978021978022, "no_speech_prob": 0.005554134491831064}, {"id": 905, "seek": 410922, "start": 4124.820000000001, "end": 4130.5, "text": " it seems like training from scratch on most medical datasets will give you the same accuracy as if", "tokens": [51144, 309, 2544, 411, 3097, 490, 8459, 322, 881, 4625, 42856, 486, 976, 291, 264, 912, 14170, 382, 498, 51428], "temperature": 0.0, "avg_logprob": -0.056658525724668764, "compression_ratio": 1.8021978021978022, "no_speech_prob": 0.005554134491831064}, {"id": 906, "seek": 410922, "start": 4130.5, "end": 4136.26, "text": " you started from a network that's pre-trained on some other giant dataset. Maybe this makes sense", "tokens": [51428, 291, 1409, 490, 257, 3209, 300, 311, 659, 12, 17227, 2001, 322, 512, 661, 7410, 28872, 13, 2704, 341, 1669, 2020, 51716], "temperature": 0.0, "avg_logprob": -0.056658525724668764, "compression_ratio": 1.8021978021978022, "no_speech_prob": 0.005554134491831064}, {"id": 907, "seek": 413626, "start": 4136.26, "end": 4142.66, "text": " because if you think about radiologists, like it's not like a radiologist can just like at the", "tokens": [50364, 570, 498, 291, 519, 466, 16335, 12256, 11, 411, 309, 311, 406, 411, 257, 16335, 9201, 393, 445, 411, 412, 264, 50684], "temperature": 0.0, "avg_logprob": -0.0645759866592732, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.008058753795921803}, {"id": 908, "seek": 413626, "start": 4142.66, "end": 4148.1, "text": " beginning of their education, they can't just look at an MRI or an X-ray image and say this is", "tokens": [50684, 2863, 295, 641, 3309, 11, 436, 393, 380, 445, 574, 412, 364, 32812, 420, 364, 1783, 12, 3458, 3256, 293, 584, 341, 307, 50956], "temperature": 0.0, "avg_logprob": -0.0645759866592732, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.008058753795921803}, {"id": 909, "seek": 413626, "start": 4148.1, "end": 4153.860000000001, "text": " where the tumor is. It's something that takes them years of training to learn how to do. And so maybe", "tokens": [50956, 689, 264, 22512, 307, 13, 467, 311, 746, 300, 2516, 552, 924, 295, 3097, 281, 1466, 577, 281, 360, 13, 400, 370, 1310, 51244], "temperature": 0.0, "avg_logprob": -0.0645759866592732, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.008058753795921803}, {"id": 910, "seek": 413626, "start": 4153.860000000001, "end": 4159.54, "text": " it also makes sense that like our neural networks can't just immediately easily without lots of", "tokens": [51244, 309, 611, 1669, 2020, 300, 411, 527, 18161, 9590, 393, 380, 445, 4258, 3612, 1553, 3195, 295, 51528], "temperature": 0.0, "avg_logprob": -0.0645759866592732, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.008058753795921803}, {"id": 911, "seek": 415954, "start": 4159.54, "end": 4167.22, "text": " training pick up on very different image distributions. It does seem to make sense,", "tokens": [50364, 3097, 1888, 493, 322, 588, 819, 3256, 37870, 13, 467, 775, 1643, 281, 652, 2020, 11, 50748], "temperature": 0.0, "avg_logprob": -0.09690267190165903, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.004329393617808819}, {"id": 912, "seek": 415954, "start": 4167.22, "end": 4174.34, "text": " going a bit from the universality of representations to the universality of", "tokens": [50748, 516, 257, 857, 490, 264, 5950, 1860, 295, 33358, 281, 264, 5950, 1860, 295, 51104], "temperature": 0.0, "avg_logprob": -0.09690267190165903, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.004329393617808819}, {"id": 913, "seek": 415954, "start": 4174.34, "end": 4181.78, "text": " augmentation, since this is such a crucial part. Do you think that there is a systematic way how", "tokens": [51104, 14501, 19631, 11, 1670, 341, 307, 1270, 257, 11462, 644, 13, 1144, 291, 519, 300, 456, 307, 257, 27249, 636, 577, 51476], "temperature": 0.0, "avg_logprob": -0.09690267190165903, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.004329393617808819}, {"id": 914, "seek": 415954, "start": 4181.78, "end": 4187.3, "text": " we can discover augmentations? Because it seems right now, it seems to be kind of a whack-a-mole,", "tokens": [51476, 321, 393, 4411, 29919, 763, 30, 1436, 309, 2544, 558, 586, 11, 309, 2544, 281, 312, 733, 295, 257, 42877, 12, 64, 12, 3280, 306, 11, 51752], "temperature": 0.0, "avg_logprob": -0.09690267190165903, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.004329393617808819}, {"id": 915, "seek": 418730, "start": 4187.3, "end": 4192.18, "text": " right? It's okay, we just feed images and it's no, that's too easy. We crop them. Oh no, it's the", "tokens": [50364, 558, 30, 467, 311, 1392, 11, 321, 445, 3154, 5267, 293, 309, 311, 572, 11, 300, 311, 886, 1858, 13, 492, 9086, 552, 13, 876, 572, 11, 309, 311, 264, 50608], "temperature": 0.0, "avg_logprob": -0.13912447037235384, "compression_ratio": 1.6840277777777777, "no_speech_prob": 0.0023918445222079754}, {"id": 916, "seek": 418730, "start": 4192.18, "end": 4197.62, "text": " color histogram. So we like whack on the color and then it works better. But maybe someone finds out", "tokens": [50608, 2017, 49816, 13, 407, 321, 411, 42877, 322, 264, 2017, 293, 550, 309, 1985, 1101, 13, 583, 1310, 1580, 10704, 484, 50880], "temperature": 0.0, "avg_logprob": -0.13912447037235384, "compression_ratio": 1.6840277777777777, "no_speech_prob": 0.0023918445222079754}, {"id": 917, "seek": 418730, "start": 4197.62, "end": 4202.900000000001, "text": " oh, there is still this easy feature that the network every now and then pays attention to. So", "tokens": [50880, 1954, 11, 456, 307, 920, 341, 1858, 4111, 300, 264, 3209, 633, 586, 293, 550, 10604, 3202, 281, 13, 407, 51144], "temperature": 0.0, "avg_logprob": -0.13912447037235384, "compression_ratio": 1.6840277777777777, "no_speech_prob": 0.0023918445222079754}, {"id": 918, "seek": 418730, "start": 4202.900000000001, "end": 4210.02, "text": " we design a method to whack on that a bit. Do you think there is a systematic way or will this", "tokens": [51144, 321, 1715, 257, 3170, 281, 42877, 322, 300, 257, 857, 13, 1144, 291, 519, 456, 307, 257, 27249, 636, 420, 486, 341, 51500], "temperature": 0.0, "avg_logprob": -0.13912447037235384, "compression_ratio": 1.6840277777777777, "no_speech_prob": 0.0023918445222079754}, {"id": 919, "seek": 418730, "start": 4210.02, "end": 4216.34, "text": " kind of philosophically always rely on us humans having a higher level inside of what we want to", "tokens": [51500, 733, 295, 14529, 984, 1009, 10687, 322, 505, 6255, 1419, 257, 2946, 1496, 1854, 295, 437, 321, 528, 281, 51816], "temperature": 0.0, "avg_logprob": -0.13912447037235384, "compression_ratio": 1.6840277777777777, "no_speech_prob": 0.0023918445222079754}, {"id": 920, "seek": 421634, "start": 4216.34, "end": 4224.1, "text": " do with the dataset? Yeah, so I think actually I'm hopeful that at least for natural images,", "tokens": [50364, 360, 365, 264, 28872, 30, 865, 11, 370, 286, 519, 767, 286, 478, 20531, 300, 412, 1935, 337, 3303, 5267, 11, 50752], "temperature": 0.0, "avg_logprob": -0.10359309185510394, "compression_ratio": 1.5625, "no_speech_prob": 0.0014546825550496578}, {"id": 921, "seek": 421634, "start": 4224.1, "end": 4229.78, "text": " just like crops and color distortions are enough, because I guess like what we found is", "tokens": [50752, 445, 411, 16829, 293, 2017, 37555, 626, 366, 1547, 11, 570, 286, 2041, 411, 437, 321, 1352, 307, 51036], "temperature": 0.0, "avg_logprob": -0.10359309185510394, "compression_ratio": 1.5625, "no_speech_prob": 0.0014546825550496578}, {"id": 922, "seek": 421634, "start": 4229.78, "end": 4235.54, "text": " you combine those two augmentations and if you do that, like that gets you most of the way to", "tokens": [51036, 291, 10432, 729, 732, 29919, 763, 293, 498, 291, 360, 300, 11, 411, 300, 2170, 291, 881, 295, 264, 636, 281, 51324], "temperature": 0.0, "avg_logprob": -0.10359309185510394, "compression_ratio": 1.5625, "no_speech_prob": 0.0014546825550496578}, {"id": 923, "seek": 421634, "start": 4235.54, "end": 4241.14, "text": " supervised accuracy. So maybe we shouldn't expect huge gains from adding additional augmentations on", "tokens": [51324, 46533, 14170, 13, 407, 1310, 321, 4659, 380, 2066, 2603, 16823, 490, 5127, 4497, 29919, 763, 322, 51604], "temperature": 0.0, "avg_logprob": -0.10359309185510394, "compression_ratio": 1.5625, "no_speech_prob": 0.0014546825550496578}, {"id": 924, "seek": 424114, "start": 4241.14, "end": 4246.26, "text": " top of that, even though there are like in the Sinclair paper, we add like Gaussian blur, which", "tokens": [50364, 1192, 295, 300, 11, 754, 1673, 456, 366, 411, 294, 264, 318, 4647, 24319, 3035, 11, 321, 909, 411, 39148, 14257, 11, 597, 50620], "temperature": 0.0, "avg_logprob": -0.09535100096363132, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.012819288298487663}, {"id": 925, "seek": 424114, "start": 4246.26, "end": 4252.1, "text": " gives slight gains on top of that. I guess in the BYL paper, they add even more augmentations on top", "tokens": [50620, 2709, 4036, 16823, 322, 1192, 295, 300, 13, 286, 2041, 294, 264, 26930, 43, 3035, 11, 436, 909, 754, 544, 29919, 763, 322, 1192, 50912], "temperature": 0.0, "avg_logprob": -0.09535100096363132, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.012819288298487663}, {"id": 926, "seek": 424114, "start": 4252.1, "end": 4258.18, "text": " of that. So you can get small gains, but it seems like the gains are much smaller once you've got", "tokens": [50912, 295, 300, 13, 407, 291, 393, 483, 1359, 16823, 11, 457, 309, 2544, 411, 264, 16823, 366, 709, 4356, 1564, 291, 600, 658, 51216], "temperature": 0.0, "avg_logprob": -0.09535100096363132, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.012819288298487663}, {"id": 927, "seek": 424114, "start": 4258.18, "end": 4263.860000000001, "text": " the crops and the color distortions there. In terms of systematic ways of discovering", "tokens": [51216, 264, 16829, 293, 264, 2017, 37555, 626, 456, 13, 682, 2115, 295, 27249, 2098, 295, 24773, 51500], "temperature": 0.0, "avg_logprob": -0.09535100096363132, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.012819288298487663}, {"id": 928, "seek": 424114, "start": 4264.42, "end": 4269.62, "text": " what set of augmentations we should be using, I guess there's a paper that I saw where", "tokens": [51528, 437, 992, 295, 29919, 763, 321, 820, 312, 1228, 11, 286, 2041, 456, 311, 257, 3035, 300, 286, 1866, 689, 51788], "temperature": 0.0, "avg_logprob": -0.09535100096363132, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.012819288298487663}, {"id": 929, "seek": 426962, "start": 4270.42, "end": 4276.42, "text": " they basically use linear evaluation on the rotation prediction task to see whether the", "tokens": [50404, 436, 1936, 764, 8213, 13344, 322, 264, 12447, 17630, 5633, 281, 536, 1968, 264, 50704], "temperature": 0.0, "avg_logprob": -0.08521563329814393, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.0006876862607896328}, {"id": 930, "seek": 426962, "start": 4276.42, "end": 4281.86, "text": " augmentations are good and they claim that actually works for evaluating the augmentations.", "tokens": [50704, 29919, 763, 366, 665, 293, 436, 3932, 300, 767, 1985, 337, 27479, 264, 29919, 763, 13, 50976], "temperature": 0.0, "avg_logprob": -0.08521563329814393, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.0006876862607896328}, {"id": 931, "seek": 426962, "start": 4281.86, "end": 4288.34, "text": " So maybe that's one way, I don't know. There are all sorts of ways of designing augmentations", "tokens": [50976, 407, 1310, 300, 311, 472, 636, 11, 286, 500, 380, 458, 13, 821, 366, 439, 7527, 295, 2098, 295, 14685, 29919, 763, 51300], "temperature": 0.0, "avg_logprob": -0.08521563329814393, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.0006876862607896328}, {"id": 932, "seek": 426962, "start": 4288.34, "end": 4295.54, "text": " for supervised learning that could conceivably be applied to the self-supervised learning setting,", "tokens": [51300, 337, 46533, 2539, 300, 727, 10413, 592, 1188, 312, 6456, 281, 264, 2698, 12, 48172, 24420, 2539, 3287, 11, 51660], "temperature": 0.0, "avg_logprob": -0.08521563329814393, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.0006876862607896328}, {"id": 933, "seek": 429554, "start": 4295.62, "end": 4301.06, "text": " to the contrastive setting. There are these meta-learning based approaches for learning", "tokens": [50368, 281, 264, 8712, 488, 3287, 13, 821, 366, 613, 19616, 12, 47204, 2361, 11587, 337, 2539, 50640], "temperature": 0.0, "avg_logprob": -0.10288814968532986, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.01639740727841854}, {"id": 934, "seek": 429554, "start": 4301.06, "end": 4307.7, "text": " data augmentation. I'm not sure, those techniques tend to be pretty complicated. I'm not sure whether", "tokens": [50640, 1412, 14501, 19631, 13, 286, 478, 406, 988, 11, 729, 7512, 3928, 281, 312, 1238, 6179, 13, 286, 478, 406, 988, 1968, 50972], "temperature": 0.0, "avg_logprob": -0.10288814968532986, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.01639740727841854}, {"id": 935, "seek": 429554, "start": 4307.7, "end": 4313.14, "text": " it's actually easier to deal with those techniques than just like trying a bunch of things, but I", "tokens": [50972, 309, 311, 767, 3571, 281, 2028, 365, 729, 7512, 813, 445, 411, 1382, 257, 3840, 295, 721, 11, 457, 286, 51244], "temperature": 0.0, "avg_logprob": -0.10288814968532986, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.01639740727841854}, {"id": 936, "seek": 429554, "start": 4313.14, "end": 4319.46, "text": " think that maybe it doesn't matter that much. Maybe like just, at least if you're dealing with natural", "tokens": [51244, 519, 300, 1310, 309, 1177, 380, 1871, 300, 709, 13, 2704, 411, 445, 11, 412, 1935, 498, 291, 434, 6260, 365, 3303, 51560], "temperature": 0.0, "avg_logprob": -0.10288814968532986, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.01639740727841854}, {"id": 937, "seek": 431946, "start": 4319.46, "end": 4327.3, "text": " images, maybe crop and color distortion is enough. I guess if you think about other images,", "tokens": [50364, 5267, 11, 1310, 9086, 293, 2017, 28426, 307, 1547, 13, 286, 2041, 498, 291, 519, 466, 661, 5267, 11, 50756], "temperature": 0.0, "avg_logprob": -0.06839740051413482, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0460163950920105}, {"id": 938, "seek": 431946, "start": 4327.3, "end": 4331.22, "text": " I don't really have any idea. I guess it depends on what the images look like.", "tokens": [50756, 286, 500, 380, 534, 362, 604, 1558, 13, 286, 2041, 309, 5946, 322, 437, 264, 5267, 574, 411, 13, 50952], "temperature": 0.0, "avg_logprob": -0.06839740051413482, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0460163950920105}, {"id": 939, "seek": 431946, "start": 4331.94, "end": 4337.3, "text": " There are lots of things that you could be expressing as images like a spectrogram or", "tokens": [50988, 821, 366, 3195, 295, 721, 300, 291, 727, 312, 22171, 382, 5267, 411, 257, 6177, 340, 1342, 420, 51256], "temperature": 0.0, "avg_logprob": -0.06839740051413482, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0460163950920105}, {"id": 940, "seek": 431946, "start": 4337.3, "end": 4342.42, "text": " like some kind of chart or whatever, where you could be applying a neural network to it,", "tokens": [51256, 411, 512, 733, 295, 6927, 420, 2035, 11, 689, 291, 727, 312, 9275, 257, 18161, 3209, 281, 309, 11, 51512], "temperature": 0.0, "avg_logprob": -0.06839740051413482, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0460163950920105}, {"id": 941, "seek": 431946, "start": 4342.42, "end": 4347.38, "text": " but the further you get from natural images, the less clear it is what kind of augmentations", "tokens": [51512, 457, 264, 3052, 291, 483, 490, 3303, 5267, 11, 264, 1570, 1850, 309, 307, 437, 733, 295, 29919, 763, 51760], "temperature": 0.0, "avg_logprob": -0.06839740051413482, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0460163950920105}, {"id": 942, "seek": 434738, "start": 4347.46, "end": 4352.74, "text": " you should be working with. It is a fascinating thought though, this universality of augmentations.", "tokens": [50368, 291, 820, 312, 1364, 365, 13, 467, 307, 257, 10343, 1194, 1673, 11, 341, 5950, 1860, 295, 29919, 763, 13, 50632], "temperature": 0.0, "avg_logprob": -0.1134262600460568, "compression_ratio": 1.6607773851590106, "no_speech_prob": 0.0023403794039040804}, {"id": 943, "seek": 434738, "start": 4352.74, "end": 4359.78, "text": " When you said cropping and color, that made me think it seems to be related to the inductive", "tokens": [50632, 1133, 291, 848, 4848, 3759, 293, 2017, 11, 300, 1027, 385, 519, 309, 2544, 281, 312, 4077, 281, 264, 31612, 488, 50984], "temperature": 0.0, "avg_logprob": -0.1134262600460568, "compression_ratio": 1.6607773851590106, "no_speech_prob": 0.0023403794039040804}, {"id": 944, "seek": 434738, "start": 4359.78, "end": 4365.9400000000005, "text": " priors in the CNN architecture that we use and also to things like its regularly sampled, gridded,", "tokens": [50984, 1790, 830, 294, 264, 24859, 9482, 300, 321, 764, 293, 611, 281, 721, 411, 1080, 11672, 3247, 15551, 11, 10748, 9207, 11, 51292], "temperature": 0.0, "avg_logprob": -0.1134262600460568, "compression_ratio": 1.6607773851590106, "no_speech_prob": 0.0023403794039040804}, {"id": 945, "seek": 434738, "start": 4366.5, "end": 4370.58, "text": " discrete image data, because we're speaking with Max Welling the other week and as he's", "tokens": [51320, 27706, 3256, 1412, 11, 570, 321, 434, 4124, 365, 7402, 1042, 278, 264, 661, 1243, 293, 382, 415, 311, 51524], "temperature": 0.0, "avg_logprob": -0.1134262600460568, "compression_ratio": 1.6607773851590106, "no_speech_prob": 0.0023403794039040804}, {"id": 946, "seek": 434738, "start": 4370.58, "end": 4376.1, "text": " created lots of other interesting inductive priors for computer vision models. It does set", "tokens": [51524, 2942, 3195, 295, 661, 1880, 31612, 488, 1790, 830, 337, 3820, 5201, 5245, 13, 467, 775, 992, 51800], "temperature": 0.0, "avg_logprob": -0.1134262600460568, "compression_ratio": 1.6607773851590106, "no_speech_prob": 0.0023403794039040804}, {"id": 947, "seek": 437610, "start": 4376.18, "end": 4380.1, "text": " my mind racing a little bit because presumably there's a continuum. On the one hand, we don't do", "tokens": [50368, 452, 1575, 12553, 257, 707, 857, 570, 26742, 456, 311, 257, 36120, 13, 1282, 264, 472, 1011, 11, 321, 500, 380, 360, 50564], "temperature": 0.0, "avg_logprob": -0.08948549543108258, "compression_ratio": 1.8012422360248448, "no_speech_prob": 0.01496903970837593}, {"id": 948, "seek": 437610, "start": 4380.1, "end": 4384.740000000001, "text": " any augmentation and we just learn from examples. In the middle, we do the augmentation and then", "tokens": [50564, 604, 14501, 19631, 293, 321, 445, 1466, 490, 5110, 13, 682, 264, 2808, 11, 321, 360, 264, 14501, 19631, 293, 550, 50796], "temperature": 0.0, "avg_logprob": -0.08948549543108258, "compression_ratio": 1.8012422360248448, "no_speech_prob": 0.01496903970837593}, {"id": 949, "seek": 437610, "start": 4384.740000000001, "end": 4388.58, "text": " maybe in the future, because some people have said that computer vision systems don't have seen", "tokens": [50796, 1310, 294, 264, 2027, 11, 570, 512, 561, 362, 848, 300, 3820, 5201, 3652, 500, 380, 362, 1612, 50988], "temperature": 0.0, "avg_logprob": -0.08948549543108258, "compression_ratio": 1.8012422360248448, "no_speech_prob": 0.01496903970837593}, {"id": 950, "seek": 437610, "start": 4388.58, "end": 4392.900000000001, "text": " understanding. They don't understand physics. The ball might be on the table, but we don't know that", "tokens": [50988, 3701, 13, 814, 500, 380, 1223, 10649, 13, 440, 2594, 1062, 312, 322, 264, 3199, 11, 457, 321, 500, 380, 458, 300, 51204], "temperature": 0.0, "avg_logprob": -0.08948549543108258, "compression_ratio": 1.8012422360248448, "no_speech_prob": 0.01496903970837593}, {"id": 951, "seek": 437610, "start": 4392.900000000001, "end": 4397.780000000001, "text": " it's not falling and so on. There's a lot of missing information. Would the next step be some", "tokens": [51204, 309, 311, 406, 7440, 293, 370, 322, 13, 821, 311, 257, 688, 295, 5361, 1589, 13, 6068, 264, 958, 1823, 312, 512, 51448], "temperature": 0.0, "avg_logprob": -0.08948549543108258, "compression_ratio": 1.8012422360248448, "no_speech_prob": 0.01496903970837593}, {"id": 952, "seek": 437610, "start": 4397.780000000001, "end": 4402.42, "text": " simulation? Do you know what I mean? Where we impute physics and we impute some world knowledge", "tokens": [51448, 16575, 30, 1144, 291, 458, 437, 286, 914, 30, 2305, 321, 704, 1169, 10649, 293, 321, 704, 1169, 512, 1002, 3601, 51680], "temperature": 0.0, "avg_logprob": -0.08948549543108258, "compression_ratio": 1.8012422360248448, "no_speech_prob": 0.01496903970837593}, {"id": 953, "seek": 440242, "start": 4402.42, "end": 4404.9800000000005, "text": " and then I don't know whether we train a machine learning model from that?", "tokens": [50364, 293, 550, 286, 500, 380, 458, 1968, 321, 3847, 257, 3479, 2539, 2316, 490, 300, 30, 50492], "temperature": 0.0, "avg_logprob": -0.09693140142104205, "compression_ratio": 1.7896825396825398, "no_speech_prob": 0.0027084897737950087}, {"id": 954, "seek": 440242, "start": 4405.62, "end": 4411.38, "text": " Yeah, I think there are definitely shortcomings in our current machine learning models,", "tokens": [50524, 865, 11, 286, 519, 456, 366, 2138, 2099, 49886, 294, 527, 2190, 3479, 2539, 5245, 11, 50812], "temperature": 0.0, "avg_logprob": -0.09693140142104205, "compression_ratio": 1.7896825396825398, "no_speech_prob": 0.0027084897737950087}, {"id": 955, "seek": 440242, "start": 4411.38, "end": 4416.66, "text": " understandings of the world. There are probably things that we can't just solve by throwing more", "tokens": [50812, 1223, 1109, 295, 264, 1002, 13, 821, 366, 1391, 721, 300, 321, 393, 380, 445, 5039, 538, 10238, 544, 51076], "temperature": 0.0, "avg_logprob": -0.09693140142104205, "compression_ratio": 1.7896825396825398, "no_speech_prob": 0.0027084897737950087}, {"id": 956, "seek": 440242, "start": 4416.66, "end": 4423.38, "text": " static images at them. I think maybe the next step, rather than trying to immediately situate", "tokens": [51076, 13437, 5267, 412, 552, 13, 286, 519, 1310, 264, 958, 1823, 11, 2831, 813, 1382, 281, 4258, 2054, 473, 51412], "temperature": 0.0, "avg_logprob": -0.09693140142104205, "compression_ratio": 1.7896825396825398, "no_speech_prob": 0.0027084897737950087}, {"id": 957, "seek": 440242, "start": 4423.38, "end": 4429.78, "text": " the machine learning model in a simulated world, we could just think about video. I think there's", "tokens": [51412, 264, 3479, 2539, 2316, 294, 257, 41713, 1002, 11, 321, 727, 445, 519, 466, 960, 13, 286, 519, 456, 311, 51732], "temperature": 0.0, "avg_logprob": -0.09693140142104205, "compression_ratio": 1.7896825396825398, "no_speech_prob": 0.0027084897737950087}, {"id": 958, "seek": 442978, "start": 4429.78, "end": 4435.38, "text": " already a lot of additional information in video that a neural network could use to learn", "tokens": [50364, 1217, 257, 688, 295, 4497, 1589, 294, 960, 300, 257, 18161, 3209, 727, 764, 281, 1466, 50644], "temperature": 0.0, "avg_logprob": -0.08940488558549148, "compression_ratio": 1.83984375, "no_speech_prob": 0.0025490466505289078}, {"id": 959, "seek": 442978, "start": 4435.38, "end": 4442.099999999999, "text": " interesting representations. It seems like if you just see static images, it's hard to learn", "tokens": [50644, 1880, 33358, 13, 467, 2544, 411, 498, 291, 445, 536, 13437, 5267, 11, 309, 311, 1152, 281, 1466, 50980], "temperature": 0.0, "avg_logprob": -0.08940488558549148, "compression_ratio": 1.83984375, "no_speech_prob": 0.0025490466505289078}, {"id": 960, "seek": 442978, "start": 4442.099999999999, "end": 4448.5, "text": " how to segment objects. It's hard to learn where the object's boundaries are, but once you have", "tokens": [50980, 577, 281, 9469, 6565, 13, 467, 311, 1152, 281, 1466, 689, 264, 2657, 311, 13180, 366, 11, 457, 1564, 291, 362, 51300], "temperature": 0.0, "avg_logprob": -0.08940488558549148, "compression_ratio": 1.83984375, "no_speech_prob": 0.0025490466505289078}, {"id": 961, "seek": 442978, "start": 4448.5, "end": 4453.3, "text": " video, it's like the stuff that's moving together is an object and you can tell that because it's", "tokens": [51300, 960, 11, 309, 311, 411, 264, 1507, 300, 311, 2684, 1214, 307, 364, 2657, 293, 291, 393, 980, 300, 570, 309, 311, 51540], "temperature": 0.0, "avg_logprob": -0.08940488558549148, "compression_ratio": 1.83984375, "no_speech_prob": 0.0025490466505289078}, {"id": 962, "seek": 442978, "start": 4453.3, "end": 4458.98, "text": " moving together. I think there's a lot of potential for learning better visual representations", "tokens": [51540, 2684, 1214, 13, 286, 519, 456, 311, 257, 688, 295, 3995, 337, 2539, 1101, 5056, 33358, 51824], "temperature": 0.0, "avg_logprob": -0.08940488558549148, "compression_ratio": 1.83984375, "no_speech_prob": 0.0025490466505289078}, {"id": 963, "seek": 445978, "start": 4460.74, "end": 4466.0199999999995, "text": " and maybe eventually from these kinds of interactions in simulated environments. I", "tokens": [50412, 293, 1310, 4728, 490, 613, 3685, 295, 13280, 294, 41713, 12388, 13, 286, 50676], "temperature": 0.0, "avg_logprob": -0.11251089731852214, "compression_ratio": 1.6244541484716157, "no_speech_prob": 0.001244250452145934}, {"id": 964, "seek": 445978, "start": 4466.0199999999995, "end": 4472.0199999999995, "text": " think ultimately it becomes a computational headache. Even video is a computational headache", "tokens": [50676, 519, 6284, 309, 3643, 257, 28270, 23520, 13, 2754, 960, 307, 257, 28270, 23520, 50976], "temperature": 0.0, "avg_logprob": -0.11251089731852214, "compression_ratio": 1.6244541484716157, "no_speech_prob": 0.001244250452145934}, {"id": 965, "seek": 445978, "start": 4472.0199999999995, "end": 4476.82, "text": " because suddenly you've got all of these frames that you have to deal with. You probably want to be", "tokens": [50976, 570, 5800, 291, 600, 658, 439, 295, 613, 12083, 300, 291, 362, 281, 2028, 365, 13, 509, 1391, 528, 281, 312, 51216], "temperature": 0.0, "avg_logprob": -0.11251089731852214, "compression_ratio": 1.6244541484716157, "no_speech_prob": 0.001244250452145934}, {"id": 966, "seek": 445978, "start": 4478.259999999999, "end": 4485.46, "text": " thinking about how representations change over time and video data is just huge. It's especially", "tokens": [51288, 1953, 466, 577, 33358, 1319, 670, 565, 293, 960, 1412, 307, 445, 2603, 13, 467, 311, 2318, 51648], "temperature": 0.0, "avg_logprob": -0.11251089731852214, "compression_ratio": 1.6244541484716157, "no_speech_prob": 0.001244250452145934}, {"id": 967, "seek": 448546, "start": 4485.46, "end": 4493.62, "text": " huge if you have to process many frames at once on your accelerators. I think that's why this hasn't", "tokens": [50364, 2603, 498, 291, 362, 281, 1399, 867, 12083, 412, 1564, 322, 428, 10172, 3391, 13, 286, 519, 300, 311, 983, 341, 6132, 380, 50772], "temperature": 0.0, "avg_logprob": -0.10030303830685823, "compression_ratio": 1.625, "no_speech_prob": 0.009687346406280994}, {"id": 968, "seek": 448546, "start": 4493.62, "end": 4500.1, "text": " taken off yet, but I think probably representation learning from video is going to be a big thing", "tokens": [50772, 2726, 766, 1939, 11, 457, 286, 519, 1391, 10290, 2539, 490, 960, 307, 516, 281, 312, 257, 955, 551, 51096], "temperature": 0.0, "avg_logprob": -0.10030303830685823, "compression_ratio": 1.625, "no_speech_prob": 0.009687346406280994}, {"id": 969, "seek": 448546, "start": 4500.1, "end": 4507.78, "text": " next year or the year after or sometime in the near future. We would love to talk about your big", "tokens": [51096, 958, 1064, 420, 264, 1064, 934, 420, 15053, 294, 264, 2651, 2027, 13, 492, 576, 959, 281, 751, 466, 428, 955, 51480], "temperature": 0.0, "avg_logprob": -0.10030303830685823, "compression_ratio": 1.625, "no_speech_prob": 0.009687346406280994}, {"id": 970, "seek": 448546, "start": 4507.78, "end": 4512.18, "text": " self-supervised models, our strong semi-supervised learners. This is super interesting because", "tokens": [51480, 2698, 12, 48172, 24420, 5245, 11, 527, 2068, 12909, 12, 48172, 24420, 23655, 13, 639, 307, 1687, 1880, 570, 51700], "temperature": 0.0, "avg_logprob": -0.10030303830685823, "compression_ratio": 1.625, "no_speech_prob": 0.009687346406280994}, {"id": 971, "seek": 451218, "start": 4512.18, "end": 4516.02, "text": " you're combining the unsupervised stuff that we've been talking about in Simclear, but now", "tokens": [50364, 291, 434, 21928, 264, 2693, 12879, 24420, 1507, 300, 321, 600, 668, 1417, 466, 294, 3998, 43679, 11, 457, 586, 50556], "temperature": 0.0, "avg_logprob": -0.1072884140727676, "compression_ratio": 1.7509433962264151, "no_speech_prob": 0.0033606323413550854}, {"id": 972, "seek": 451218, "start": 4516.02, "end": 4521.54, "text": " we're in the semi-supervised domain where the label efficiency becomes super important. What's", "tokens": [50556, 321, 434, 294, 264, 12909, 12, 48172, 24420, 9274, 689, 264, 7645, 10493, 3643, 1687, 1021, 13, 708, 311, 50832], "temperature": 0.0, "avg_logprob": -0.1072884140727676, "compression_ratio": 1.7509433962264151, "no_speech_prob": 0.0033606323413550854}, {"id": 973, "seek": 451218, "start": 4521.54, "end": 4528.58, "text": " the deal there? Yeah. I guess in Simclear we focus on this question of linear evaluation", "tokens": [50832, 264, 2028, 456, 30, 865, 13, 286, 2041, 294, 3998, 43679, 321, 1879, 322, 341, 1168, 295, 8213, 13344, 51184], "temperature": 0.0, "avg_logprob": -0.1072884140727676, "compression_ratio": 1.7509433962264151, "no_speech_prob": 0.0033606323413550854}, {"id": 974, "seek": 451218, "start": 4528.58, "end": 4534.1, "text": " accuracy. We're just learning a representation without any labels and then training a linear", "tokens": [51184, 14170, 13, 492, 434, 445, 2539, 257, 10290, 1553, 604, 16949, 293, 550, 3097, 257, 8213, 51460], "temperature": 0.0, "avg_logprob": -0.1072884140727676, "compression_ratio": 1.7509433962264151, "no_speech_prob": 0.0033606323413550854}, {"id": 975, "seek": 451218, "start": 4534.1, "end": 4539.700000000001, "text": " classifier on top of that representation on the same data, but now with all the labels. It turns", "tokens": [51460, 1508, 9902, 322, 1192, 295, 300, 10290, 322, 264, 912, 1412, 11, 457, 586, 365, 439, 264, 16949, 13, 467, 4523, 51740], "temperature": 0.0, "avg_logprob": -0.1072884140727676, "compression_ratio": 1.7509433962264151, "no_speech_prob": 0.0033606323413550854}, {"id": 976, "seek": 453970, "start": 4539.78, "end": 4546.26, "text": " out that's not really a very practical problem if you have all the labels. There's not necessarily any", "tokens": [50368, 484, 300, 311, 406, 534, 257, 588, 8496, 1154, 498, 291, 362, 439, 264, 16949, 13, 821, 311, 406, 4725, 604, 50692], "temperature": 0.0, "avg_logprob": -0.06630995081759047, "compression_ratio": 1.7443946188340806, "no_speech_prob": 0.00218192464672029}, {"id": 977, "seek": 453970, "start": 4546.26, "end": 4552.58, "text": " reason in practice that you would want to first learn this representation and then train the", "tokens": [50692, 1778, 294, 3124, 300, 291, 576, 528, 281, 700, 1466, 341, 10290, 293, 550, 3847, 264, 51008], "temperature": 0.0, "avg_logprob": -0.06630995081759047, "compression_ratio": 1.7443946188340806, "no_speech_prob": 0.00218192464672029}, {"id": 978, "seek": 453970, "start": 4552.58, "end": 4558.66, "text": " classifier versus just doing standard supervised end-to-end training. What is a practical problem", "tokens": [51008, 1508, 9902, 5717, 445, 884, 3832, 46533, 917, 12, 1353, 12, 521, 3097, 13, 708, 307, 257, 8496, 1154, 51312], "temperature": 0.0, "avg_logprob": -0.06630995081759047, "compression_ratio": 1.7443946188340806, "no_speech_prob": 0.00218192464672029}, {"id": 979, "seek": 453970, "start": 4558.66, "end": 4565.46, "text": " is the situation where you have a lot of unlabeled data and then a very small amount of labeled", "tokens": [51312, 307, 264, 2590, 689, 291, 362, 257, 688, 295, 32118, 18657, 292, 1412, 293, 550, 257, 588, 1359, 2372, 295, 21335, 51652], "temperature": 0.0, "avg_logprob": -0.06630995081759047, "compression_ratio": 1.7443946188340806, "no_speech_prob": 0.00218192464672029}, {"id": 980, "seek": 456546, "start": 4565.46, "end": 4574.26, "text": " data. That's the situation that we look at in Simclear v2 in that paper. What we find there is", "tokens": [50364, 1412, 13, 663, 311, 264, 2590, 300, 321, 574, 412, 294, 3998, 43679, 371, 17, 294, 300, 3035, 13, 708, 321, 915, 456, 307, 50804], "temperature": 0.0, "avg_logprob": -0.08631628634882908, "compression_ratio": 1.6443514644351465, "no_speech_prob": 0.011327879503369331}, {"id": 981, "seek": 456546, "start": 4574.26, "end": 4582.18, "text": " that you can train this network fully unsupervised without using the labels on all the data and then", "tokens": [50804, 300, 291, 393, 3847, 341, 3209, 4498, 2693, 12879, 24420, 1553, 1228, 264, 16949, 322, 439, 264, 1412, 293, 550, 51200], "temperature": 0.0, "avg_logprob": -0.08631628634882908, "compression_ratio": 1.6443514644351465, "no_speech_prob": 0.011327879503369331}, {"id": 982, "seek": 456546, "start": 4582.18, "end": 4587.78, "text": " you can fine-tune it on just the subset where you've got the labels. If you do that, it's possible to", "tokens": [51200, 291, 393, 2489, 12, 83, 2613, 309, 322, 445, 264, 25993, 689, 291, 600, 658, 264, 16949, 13, 759, 291, 360, 300, 11, 309, 311, 1944, 281, 51480], "temperature": 0.0, "avg_logprob": -0.08631628634882908, "compression_ratio": 1.6443514644351465, "no_speech_prob": 0.011327879503369331}, {"id": 983, "seek": 456546, "start": 4587.78, "end": 4595.14, "text": " get very high accuracy, especially if the network is very big. Basically, we find if you have a", "tokens": [51480, 483, 588, 1090, 14170, 11, 2318, 498, 264, 3209, 307, 588, 955, 13, 8537, 11, 321, 915, 498, 291, 362, 257, 51848], "temperature": 0.0, "avg_logprob": -0.08631628634882908, "compression_ratio": 1.6443514644351465, "no_speech_prob": 0.011327879503369331}, {"id": 984, "seek": 459514, "start": 4595.14, "end": 4600.1, "text": " really big ResNet, if you have ResNet 152 and then you make the layers three times wider,", "tokens": [50364, 534, 955, 5015, 31890, 11, 498, 291, 362, 5015, 31890, 2119, 17, 293, 550, 291, 652, 264, 7914, 1045, 1413, 11842, 11, 50612], "temperature": 0.0, "avg_logprob": -0.06927057534209953, "compression_ratio": 1.9288537549407114, "no_speech_prob": 0.0007094849133864045}, {"id": 985, "seek": 459514, "start": 4600.660000000001, "end": 4607.9400000000005, "text": " when you do that, you can get accuracy when you fine-tune on 10% of the labels that's substantially", "tokens": [50640, 562, 291, 360, 300, 11, 291, 393, 483, 14170, 562, 291, 2489, 12, 83, 2613, 322, 1266, 4, 295, 264, 16949, 300, 311, 30797, 51004], "temperature": 0.0, "avg_logprob": -0.06927057534209953, "compression_ratio": 1.9288537549407114, "no_speech_prob": 0.0007094849133864045}, {"id": 986, "seek": 459514, "start": 4607.9400000000005, "end": 4614.02, "text": " better than if you trained ResNet 50 from scratch with all the labels. Once you have that really big", "tokens": [51004, 1101, 813, 498, 291, 8895, 5015, 31890, 2625, 490, 8459, 365, 439, 264, 16949, 13, 3443, 291, 362, 300, 534, 955, 51308], "temperature": 0.0, "avg_logprob": -0.06927057534209953, "compression_ratio": 1.9288537549407114, "no_speech_prob": 0.0007094849133864045}, {"id": 987, "seek": 459514, "start": 4614.02, "end": 4618.18, "text": " network, it turns out you don't have to put the really big network into production. You can take", "tokens": [51308, 3209, 11, 309, 4523, 484, 291, 500, 380, 362, 281, 829, 264, 534, 955, 3209, 666, 4265, 13, 509, 393, 747, 51516], "temperature": 0.0, "avg_logprob": -0.06927057534209953, "compression_ratio": 1.9288537549407114, "no_speech_prob": 0.0007094849133864045}, {"id": 988, "seek": 459514, "start": 4618.18, "end": 4624.900000000001, "text": " the really big network and you can then distill it back into a standard ResNet 50 and you can retain", "tokens": [51516, 264, 534, 955, 3209, 293, 291, 393, 550, 42923, 309, 646, 666, 257, 3832, 5015, 31890, 2625, 293, 291, 393, 18340, 51852], "temperature": 0.0, "avg_logprob": -0.06927057534209953, "compression_ratio": 1.9288537549407114, "no_speech_prob": 0.0007094849133864045}, {"id": 989, "seek": 462490, "start": 4624.9, "end": 4629.54, "text": " almost all of the accuracy when you do that. I guess what's important about this distillation", "tokens": [50364, 1920, 439, 295, 264, 14170, 562, 291, 360, 300, 13, 286, 2041, 437, 311, 1021, 466, 341, 42923, 399, 50596], "temperature": 0.0, "avg_logprob": -0.06183312707028146, "compression_ratio": 1.941908713692946, "no_speech_prob": 0.0002867942675948143}, {"id": 990, "seek": 462490, "start": 4629.54, "end": 4634.98, "text": " process is we're not just going to distill on the labeled dataset. We're going to also use", "tokens": [50596, 1399, 307, 321, 434, 406, 445, 516, 281, 42923, 322, 264, 21335, 28872, 13, 492, 434, 516, 281, 611, 764, 50868], "temperature": 0.0, "avg_logprob": -0.06183312707028146, "compression_ratio": 1.941908713692946, "no_speech_prob": 0.0002867942675948143}, {"id": 991, "seek": 462490, "start": 4635.86, "end": 4642.74, "text": " the labels that this giant network, which we fine-tuned on a small subset of the data,", "tokens": [50912, 264, 16949, 300, 341, 7410, 3209, 11, 597, 321, 2489, 12, 83, 43703, 322, 257, 1359, 25993, 295, 264, 1412, 11, 51256], "temperature": 0.0, "avg_logprob": -0.06183312707028146, "compression_ratio": 1.941908713692946, "no_speech_prob": 0.0002867942675948143}, {"id": 992, "seek": 462490, "start": 4642.74, "end": 4648.179999999999, "text": " we're going to use the labels that it gives on all of our unlabeled data. We're going to use it to", "tokens": [51256, 321, 434, 516, 281, 764, 264, 16949, 300, 309, 2709, 322, 439, 295, 527, 32118, 18657, 292, 1412, 13, 492, 434, 516, 281, 764, 309, 281, 51528], "temperature": 0.0, "avg_logprob": -0.06183312707028146, "compression_ratio": 1.941908713692946, "no_speech_prob": 0.0002867942675948143}, {"id": 993, "seek": 462490, "start": 4648.179999999999, "end": 4653.46, "text": " generate labels and then we're just going to use those labels to train a much smaller network. If", "tokens": [51528, 8460, 16949, 293, 550, 321, 434, 445, 516, 281, 764, 729, 16949, 281, 3847, 257, 709, 4356, 3209, 13, 759, 51792], "temperature": 0.0, "avg_logprob": -0.06183312707028146, "compression_ratio": 1.941908713692946, "no_speech_prob": 0.0002867942675948143}, {"id": 994, "seek": 465346, "start": 4653.46, "end": 4659.7, "text": " we do that, we get accuracy that's similar to or maybe even slightly better than standard supervised", "tokens": [50364, 321, 360, 300, 11, 321, 483, 14170, 300, 311, 2531, 281, 420, 1310, 754, 4748, 1101, 813, 3832, 46533, 50676], "temperature": 0.0, "avg_logprob": -0.09019462171807346, "compression_ratio": 1.602510460251046, "no_speech_prob": 0.0004107936401851475}, {"id": 995, "seek": 465346, "start": 4659.7, "end": 4666.9800000000005, "text": " training from scratch. This becomes a highly practically relatable approach toward doing", "tokens": [50676, 3097, 490, 8459, 13, 639, 3643, 257, 5405, 15667, 42355, 3109, 7361, 884, 51040], "temperature": 0.0, "avg_logprob": -0.09019462171807346, "compression_ratio": 1.602510460251046, "no_speech_prob": 0.0004107936401851475}, {"id": 996, "seek": 465346, "start": 4667.54, "end": 4674.42, "text": " computer vision related things. We see all the times that folks have a huge corpus of unlabeled", "tokens": [51068, 3820, 5201, 4077, 721, 13, 492, 536, 439, 264, 1413, 300, 4024, 362, 257, 2603, 1181, 31624, 295, 32118, 18657, 292, 51412], "temperature": 0.0, "avg_logprob": -0.09019462171807346, "compression_ratio": 1.602510460251046, "no_speech_prob": 0.0004107936401851475}, {"id": 997, "seek": 465346, "start": 4674.42, "end": 4682.02, "text": " images, but they only have maybe 5% or 10% labeled images. This immediately becomes a practically", "tokens": [51412, 5267, 11, 457, 436, 787, 362, 1310, 1025, 4, 420, 1266, 4, 21335, 5267, 13, 639, 4258, 3643, 257, 15667, 51792], "temperature": 0.0, "avg_logprob": -0.09019462171807346, "compression_ratio": 1.602510460251046, "no_speech_prob": 0.0004107936401851475}, {"id": 998, "seek": 468202, "start": 4682.1, "end": 4687.46, "text": " applicable recipe for them. I definitely am looking forward to seeing this thing", "tokens": [50368, 21142, 6782, 337, 552, 13, 286, 2138, 669, 1237, 2128, 281, 2577, 341, 551, 50636], "temperature": 0.0, "avg_logprob": -0.08866073570999444, "compression_ratio": 1.6793893129770991, "no_speech_prob": 0.0019869403913617134}, {"id": 999, "seek": 468202, "start": 4687.46, "end": 4693.3, "text": " implemented at scale at different companies. That's there. If I understood it correctly,", "tokens": [50636, 12270, 412, 4373, 412, 819, 3431, 13, 663, 311, 456, 13, 759, 286, 7320, 309, 8944, 11, 50928], "temperature": 0.0, "avg_logprob": -0.08866073570999444, "compression_ratio": 1.6793893129770991, "no_speech_prob": 0.0019869403913617134}, {"id": 1000, "seek": 468202, "start": 4693.3, "end": 4700.1, "text": " just for the viewers, you folks used a variant of distillation here, which is more popularly", "tokens": [50928, 445, 337, 264, 8499, 11, 291, 4024, 1143, 257, 17501, 295, 42923, 399, 510, 11, 597, 307, 544, 3743, 356, 51268], "temperature": 0.0, "avg_logprob": -0.08866073570999444, "compression_ratio": 1.6793893129770991, "no_speech_prob": 0.0019869403913617134}, {"id": 1001, "seek": 468202, "start": 4700.1, "end": 4704.34, "text": " referred to as self-training. I don't think there's really a difference between", "tokens": [51268, 10839, 281, 382, 2698, 12, 17227, 1760, 13, 286, 500, 380, 519, 456, 311, 534, 257, 2649, 1296, 51480], "temperature": 0.0, "avg_logprob": -0.08866073570999444, "compression_ratio": 1.6793893129770991, "no_speech_prob": 0.0019869403913617134}, {"id": 1002, "seek": 468202, "start": 4705.14, "end": 4711.38, "text": " what we call distillation and what other people call self-training. I guess the idea is basically", "tokens": [51520, 437, 321, 818, 42923, 399, 293, 437, 661, 561, 818, 2698, 12, 17227, 1760, 13, 286, 2041, 264, 1558, 307, 1936, 51832], "temperature": 0.0, "avg_logprob": -0.08866073570999444, "compression_ratio": 1.6793893129770991, "no_speech_prob": 0.0019869403913617134}, {"id": 1003, "seek": 471138, "start": 4711.46, "end": 4717.54, "text": " we will pass information into the network. We get its output probabilities and then we train", "tokens": [50368, 321, 486, 1320, 1589, 666, 264, 3209, 13, 492, 483, 1080, 5598, 33783, 293, 550, 321, 3847, 50672], "temperature": 0.0, "avg_logprob": -0.15622455195376747, "compression_ratio": 1.6476190476190475, "no_speech_prob": 0.0010318212443962693}, {"id": 1004, "seek": 471138, "start": 4717.54, "end": 4721.38, "text": " another neural network with those output probabilities as the targets.", "tokens": [50672, 1071, 18161, 3209, 365, 729, 5598, 33783, 382, 264, 12911, 13, 50864], "temperature": 0.0, "avg_logprob": -0.15622455195376747, "compression_ratio": 1.6476190476190475, "no_speech_prob": 0.0010318212443962693}, {"id": 1005, "seek": 471138, "start": 4722.18, "end": 4728.66, "text": " What I find fascinating is how many ideas come together in this paper. There's first,", "tokens": [50904, 708, 286, 915, 10343, 307, 577, 867, 3487, 808, 1214, 294, 341, 3035, 13, 821, 311, 700, 11, 51228], "temperature": 0.0, "avg_logprob": -0.15622455195376747, "compression_ratio": 1.6476190476190475, "no_speech_prob": 0.0010318212443962693}, {"id": 1006, "seek": 471138, "start": 4729.38, "end": 4736.1, "text": " there's this, let's do representation learning and then we have these just small labels. We find", "tokens": [51264, 456, 311, 341, 11, 718, 311, 360, 10290, 2539, 293, 550, 321, 362, 613, 445, 1359, 16949, 13, 492, 915, 51600], "temperature": 0.0, "avg_logprob": -0.15622455195376747, "compression_ratio": 1.6476190476190475, "no_speech_prob": 0.0010318212443962693}, {"id": 1007, "seek": 473610, "start": 4736.1, "end": 4742.58, "text": " tune and then there's big networks, small networks. Then you label, but you also apply", "tokens": [50364, 10864, 293, 550, 456, 311, 955, 9590, 11, 1359, 9590, 13, 1396, 291, 7645, 11, 457, 291, 611, 3079, 50688], "temperature": 0.0, "avg_logprob": -0.15826640409581802, "compression_ratio": 1.625, "no_speech_prob": 0.017421236261725426}, {"id": 1008, "seek": 473610, "start": 4742.58, "end": 4749.06, "text": " some noise, if I understand correctly, in the process of transferring. Maybe I'm misremembering", "tokens": [50688, 512, 5658, 11, 498, 286, 1223, 8944, 11, 294, 264, 1399, 295, 31437, 13, 2704, 286, 478, 3346, 2579, 1304, 278, 51012], "temperature": 0.0, "avg_logprob": -0.15826640409581802, "compression_ratio": 1.625, "no_speech_prob": 0.017421236261725426}, {"id": 1009, "seek": 473610, "start": 4749.06, "end": 4755.06, "text": " that, but there's a lot of ideas that come together. Yannick, you probably confused it with", "tokens": [51012, 300, 11, 457, 456, 311, 257, 688, 295, 3487, 300, 808, 1214, 13, 398, 969, 618, 11, 291, 1391, 9019, 309, 365, 51312], "temperature": 0.0, "avg_logprob": -0.15826640409581802, "compression_ratio": 1.625, "no_speech_prob": 0.017421236261725426}, {"id": 1010, "seek": 473610, "start": 4755.06, "end": 4760.26, "text": " noisy student training, where they impose noise during the student training.", "tokens": [51312, 24518, 3107, 3097, 11, 689, 436, 26952, 5658, 1830, 264, 3107, 3097, 13, 51572], "temperature": 0.0, "avg_logprob": -0.15826640409581802, "compression_ratio": 1.625, "no_speech_prob": 0.017421236261725426}, {"id": 1011, "seek": 476026, "start": 4760.820000000001, "end": 4767.06, "text": " Sorry, maybe not, but there is a lot of ideas that come together. Something tells me that", "tokens": [50392, 4919, 11, 1310, 406, 11, 457, 456, 307, 257, 688, 295, 3487, 300, 808, 1214, 13, 6595, 5112, 385, 300, 50704], "temperature": 0.0, "avg_logprob": -0.16499868392944336, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.02260468527674675}, {"id": 1012, "seek": 476026, "start": 4767.06, "end": 4775.3, "text": " there was a process behind going, you probably didn't sit down after SimClear1 and be like,", "tokens": [50704, 456, 390, 257, 1399, 2261, 516, 11, 291, 1391, 994, 380, 1394, 760, 934, 3998, 34, 5797, 16, 293, 312, 411, 11, 51116], "temperature": 0.0, "avg_logprob": -0.16499868392944336, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.02260468527674675}, {"id": 1013, "seek": 476026, "start": 4775.3, "end": 4780.1, "text": " all right, what do we do for SimClear2? Okay, let's do this. It tells me there was this process.", "tokens": [51116, 439, 558, 11, 437, 360, 321, 360, 337, 3998, 34, 5797, 17, 30, 1033, 11, 718, 311, 360, 341, 13, 467, 5112, 385, 456, 390, 341, 1399, 13, 51356], "temperature": 0.0, "avg_logprob": -0.16499868392944336, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.02260468527674675}, {"id": 1014, "seek": 476026, "start": 4780.74, "end": 4788.02, "text": " If you can maybe elaborate a bit on how did you going to build up the system towards the final", "tokens": [51388, 759, 291, 393, 1310, 20945, 257, 857, 322, 577, 630, 291, 516, 281, 1322, 493, 264, 1185, 3030, 264, 2572, 51752], "temperature": 0.0, "avg_logprob": -0.16499868392944336, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.02260468527674675}, {"id": 1015, "seek": 478802, "start": 4788.02, "end": 4794.42, "text": " output? Was there dead ends or was it like, let's build up until we can no longer make it better?", "tokens": [50364, 5598, 30, 3027, 456, 3116, 5314, 420, 390, 309, 411, 11, 718, 311, 1322, 493, 1826, 321, 393, 572, 2854, 652, 309, 1101, 30, 50684], "temperature": 0.0, "avg_logprob": -0.11464318107156192, "compression_ratio": 1.5679012345679013, "no_speech_prob": 0.0023959034588187933}, {"id": 1016, "seek": 478802, "start": 4794.42, "end": 4803.46, "text": " How was that? Yeah, I guess there was a bit of a process. After the original SimClear paper,", "tokens": [50684, 1012, 390, 300, 30, 865, 11, 286, 2041, 456, 390, 257, 857, 295, 257, 1399, 13, 2381, 264, 3380, 3998, 34, 5797, 3035, 11, 51136], "temperature": 0.0, "avg_logprob": -0.11464318107156192, "compression_ratio": 1.5679012345679013, "no_speech_prob": 0.0023959034588187933}, {"id": 1017, "seek": 478802, "start": 4803.46, "end": 4808.34, "text": " I guess it's clear from the SimClear paper that when we have this bigger network, we get much", "tokens": [51136, 286, 2041, 309, 311, 1850, 490, 264, 3998, 34, 5797, 3035, 300, 562, 321, 362, 341, 3801, 3209, 11, 321, 483, 709, 51380], "temperature": 0.0, "avg_logprob": -0.11464318107156192, "compression_ratio": 1.5679012345679013, "no_speech_prob": 0.0023959034588187933}, {"id": 1018, "seek": 478802, "start": 4808.34, "end": 4816.02, "text": " higher linear evaluation accuracy than we do if we just train SimClear with a ResNet50. Then the", "tokens": [51380, 2946, 8213, 13344, 14170, 813, 321, 360, 498, 321, 445, 3847, 3998, 34, 5797, 365, 257, 5015, 31890, 2803, 13, 1396, 264, 51764], "temperature": 0.0, "avg_logprob": -0.11464318107156192, "compression_ratio": 1.5679012345679013, "no_speech_prob": 0.0023959034588187933}, {"id": 1019, "seek": 481602, "start": 4816.02, "end": 4822.740000000001, "text": " question was, is there some way that we can somehow eliminate this dependence on this giant", "tokens": [50364, 1168, 390, 11, 307, 456, 512, 636, 300, 321, 393, 6063, 13819, 341, 31704, 322, 341, 7410, 50700], "temperature": 0.0, "avg_logprob": -0.07535174835559934, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.00077910564141348}, {"id": 1020, "seek": 481602, "start": 4822.740000000001, "end": 4827.14, "text": " network? Because the giant network is annoying to work with, it's computationally expensive,", "tokens": [50700, 3209, 30, 1436, 264, 7410, 3209, 307, 11304, 281, 589, 365, 11, 309, 311, 24903, 379, 5124, 11, 50920], "temperature": 0.0, "avg_logprob": -0.07535174835559934, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.00077910564141348}, {"id": 1021, "seek": 481602, "start": 4827.14, "end": 4835.22, "text": " it's big. We first tried what happens if you distill the unsupervised network. We basically", "tokens": [50920, 309, 311, 955, 13, 492, 700, 3031, 437, 2314, 498, 291, 42923, 264, 2693, 12879, 24420, 3209, 13, 492, 1936, 51324], "temperature": 0.0, "avg_logprob": -0.07535174835559934, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.00077910564141348}, {"id": 1022, "seek": 481602, "start": 4835.22, "end": 4842.02, "text": " have this task that is set up as a form of cross entropy loss when we're doing the contrast of", "tokens": [51324, 362, 341, 5633, 300, 307, 992, 493, 382, 257, 1254, 295, 3278, 30867, 4470, 562, 321, 434, 884, 264, 8712, 295, 51664], "temperature": 0.0, "avg_logprob": -0.07535174835559934, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.00077910564141348}, {"id": 1023, "seek": 484202, "start": 4842.02, "end": 4850.42, "text": " learning. You can also think about distilling on that task where you have a probability distribution", "tokens": [50364, 2539, 13, 509, 393, 611, 519, 466, 1483, 7345, 322, 300, 5633, 689, 291, 362, 257, 8482, 7316, 50784], "temperature": 0.0, "avg_logprob": -0.08646263473335354, "compression_ratio": 1.711111111111111, "no_speech_prob": 0.00884310808032751}, {"id": 1024, "seek": 484202, "start": 4850.42, "end": 4855.06, "text": " that corresponds to the similarity between an image and all the other images. You could use", "tokens": [50784, 300, 23249, 281, 264, 32194, 1296, 364, 3256, 293, 439, 264, 661, 5267, 13, 509, 727, 764, 51016], "temperature": 0.0, "avg_logprob": -0.08646263473335354, "compression_ratio": 1.711111111111111, "no_speech_prob": 0.00884310808032751}, {"id": 1025, "seek": 484202, "start": 4855.06, "end": 4860.900000000001, "text": " those kinds of targets to distill. We tried that and that kind of worked. Then we also tried the", "tokens": [51016, 729, 3685, 295, 12911, 281, 42923, 13, 492, 3031, 300, 293, 300, 733, 295, 2732, 13, 1396, 321, 611, 3031, 264, 51308], "temperature": 0.0, "avg_logprob": -0.08646263473335354, "compression_ratio": 1.711111111111111, "no_speech_prob": 0.00884310808032751}, {"id": 1026, "seek": 484202, "start": 4860.900000000001, "end": 4866.18, "text": " approach of first fine-tuning the big network and then distilling it. It turned out that worked", "tokens": [51308, 3109, 295, 700, 2489, 12, 83, 37726, 264, 955, 3209, 293, 550, 1483, 7345, 309, 13, 467, 3574, 484, 300, 2732, 51572], "temperature": 0.0, "avg_logprob": -0.08646263473335354, "compression_ratio": 1.711111111111111, "no_speech_prob": 0.00884310808032751}, {"id": 1027, "seek": 486618, "start": 4866.26, "end": 4874.58, "text": " a lot better. I guess we jumped straight to distillation because we knew that we could get", "tokens": [50368, 257, 688, 1101, 13, 286, 2041, 321, 13864, 2997, 281, 42923, 399, 570, 321, 2586, 300, 321, 727, 483, 50784], "temperature": 0.0, "avg_logprob": -0.05849343474193286, "compression_ratio": 1.6147186147186148, "no_speech_prob": 0.03565467894077301}, {"id": 1028, "seek": 486618, "start": 4874.58, "end": 4881.62, "text": " much better results by using a giant network with SimClear. Then once you realize that distillation", "tokens": [50784, 709, 1101, 3542, 538, 1228, 257, 7410, 3209, 365, 3998, 34, 5797, 13, 1396, 1564, 291, 4325, 300, 42923, 399, 51136], "temperature": 0.0, "avg_logprob": -0.05849343474193286, "compression_ratio": 1.6147186147186148, "no_speech_prob": 0.03565467894077301}, {"id": 1029, "seek": 486618, "start": 4881.62, "end": 4886.740000000001, "text": " is going to be important, the only thing you've got to figure out is what kind of distillation", "tokens": [51136, 307, 516, 281, 312, 1021, 11, 264, 787, 551, 291, 600, 658, 281, 2573, 484, 307, 437, 733, 295, 42923, 399, 51392], "temperature": 0.0, "avg_logprob": -0.05849343474193286, "compression_ratio": 1.6147186147186148, "no_speech_prob": 0.03565467894077301}, {"id": 1030, "seek": 486618, "start": 4886.740000000001, "end": 4891.9400000000005, "text": " should you be doing. What we found was this approach of pre-training, then fine-tuning,", "tokens": [51392, 820, 291, 312, 884, 13, 708, 321, 1352, 390, 341, 3109, 295, 659, 12, 17227, 1760, 11, 550, 2489, 12, 83, 37726, 11, 51652], "temperature": 0.0, "avg_logprob": -0.05849343474193286, "compression_ratio": 1.6147186147186148, "no_speech_prob": 0.03565467894077301}, {"id": 1031, "seek": 489194, "start": 4891.94, "end": 4897.0599999999995, "text": " then distilling works a lot better than pre-training, then distilling, then fine-tuning.", "tokens": [50364, 550, 1483, 7345, 1985, 257, 688, 1101, 813, 659, 12, 17227, 1760, 11, 550, 1483, 7345, 11, 550, 2489, 12, 83, 37726, 13, 50620], "temperature": 0.0, "avg_logprob": -0.0936154047648112, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.0013663813006132841}, {"id": 1032, "seek": 489194, "start": 4897.62, "end": 4905.86, "text": " How far down do you think one can go with this final distillation step? Is this something that is", "tokens": [50648, 1012, 1400, 760, 360, 291, 519, 472, 393, 352, 365, 341, 2572, 42923, 399, 1823, 30, 1119, 341, 746, 300, 307, 51060], "temperature": 0.0, "avg_logprob": -0.0936154047648112, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.0013663813006132841}, {"id": 1033, "seek": 489194, "start": 4905.86, "end": 4911.86, "text": " conceivably going to be available on, let's say, edge devices at some point, like that", "tokens": [51060, 10413, 592, 1188, 516, 281, 312, 2435, 322, 11, 718, 311, 584, 11, 4691, 5759, 412, 512, 935, 11, 411, 300, 51360], "temperature": 0.0, "avg_logprob": -0.0936154047648112, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.0013663813006132841}, {"id": 1034, "seek": 489194, "start": 4912.98, "end": 4919.139999999999, "text": " our glasses or something run with similar accuracies to these giant networks? Or", "tokens": [51416, 527, 10812, 420, 746, 1190, 365, 2531, 5771, 20330, 281, 613, 7410, 9590, 30, 1610, 51724], "temperature": 0.0, "avg_logprob": -0.0936154047648112, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.0013663813006132841}, {"id": 1035, "seek": 491914, "start": 4920.02, "end": 4923.700000000001, "text": " is it more a factor of four, a factor of 10 kind of stuff?", "tokens": [50408, 307, 309, 544, 257, 5952, 295, 1451, 11, 257, 5952, 295, 1266, 733, 295, 1507, 30, 50592], "temperature": 0.0, "avg_logprob": -0.11367789808526096, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.0016996600897982717}, {"id": 1036, "seek": 491914, "start": 4924.660000000001, "end": 4930.9800000000005, "text": " I think there are clearly some limits to distillation. I guess we probably shouldn't", "tokens": [50640, 286, 519, 456, 366, 4448, 512, 10406, 281, 42923, 399, 13, 286, 2041, 321, 1391, 4659, 380, 50956], "temperature": 0.0, "avg_logprob": -0.11367789808526096, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.0016996600897982717}, {"id": 1037, "seek": 491914, "start": 4930.9800000000005, "end": 4936.9800000000005, "text": " expect distillation of the kind that we do in SimClear v2 to work substantially better than", "tokens": [50956, 2066, 42923, 399, 295, 264, 733, 300, 321, 360, 294, 3998, 34, 5797, 371, 17, 281, 589, 30797, 1101, 813, 51256], "temperature": 0.0, "avg_logprob": -0.11367789808526096, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.0016996600897982717}, {"id": 1038, "seek": 491914, "start": 4937.62, "end": 4943.780000000001, "text": " supervised distillation, which has been around for quite a while now. I think what's impressive is", "tokens": [51288, 46533, 42923, 399, 11, 597, 575, 668, 926, 337, 1596, 257, 1339, 586, 13, 286, 519, 437, 311, 8992, 307, 51596], "temperature": 0.0, "avg_logprob": -0.11367789808526096, "compression_ratio": 1.568075117370892, "no_speech_prob": 0.0016996600897982717}, {"id": 1039, "seek": 494378, "start": 4943.86, "end": 4950.259999999999, "text": " that in the self-supervised case, in the contrastive case, distillation basically allows you to", "tokens": [50368, 300, 294, 264, 2698, 12, 48172, 24420, 1389, 11, 294, 264, 8712, 488, 1389, 11, 42923, 399, 1936, 4045, 291, 281, 50688], "temperature": 0.0, "avg_logprob": -0.08362971110777422, "compression_ratio": 1.8142857142857143, "no_speech_prob": 0.026749249547719955}, {"id": 1040, "seek": 494378, "start": 4950.259999999999, "end": 4955.219999999999, "text": " recover the same accuracy that you would get from training supervised from scratch, whereas without", "tokens": [50688, 8114, 264, 912, 14170, 300, 291, 576, 483, 490, 3097, 46533, 490, 8459, 11, 9735, 1553, 50936], "temperature": 0.0, "avg_logprob": -0.08362971110777422, "compression_ratio": 1.8142857142857143, "no_speech_prob": 0.026749249547719955}, {"id": 1041, "seek": 494378, "start": 4955.219999999999, "end": 4962.34, "text": " it, the accuracy is a lot worse. It seems like it maybe matters more in this contrastive case,", "tokens": [50936, 309, 11, 264, 14170, 307, 257, 688, 5324, 13, 467, 2544, 411, 309, 1310, 7001, 544, 294, 341, 8712, 488, 1389, 11, 51292], "temperature": 0.0, "avg_logprob": -0.08362971110777422, "compression_ratio": 1.8142857142857143, "no_speech_prob": 0.026749249547719955}, {"id": 1042, "seek": 494378, "start": 4962.98, "end": 4968.82, "text": " but I think generally when you do distillation in the supervised case, you can get maybe a", "tokens": [51324, 457, 286, 519, 5101, 562, 291, 360, 42923, 399, 294, 264, 46533, 1389, 11, 291, 393, 483, 1310, 257, 51616], "temperature": 0.0, "avg_logprob": -0.08362971110777422, "compression_ratio": 1.8142857142857143, "no_speech_prob": 0.026749249547719955}, {"id": 1043, "seek": 496882, "start": 4968.82, "end": 4974.98, "text": " percentage point gain, maybe a couple of percentage points. I think that's probably about the limit", "tokens": [50364, 9668, 935, 6052, 11, 1310, 257, 1916, 295, 9668, 2793, 13, 286, 519, 300, 311, 1391, 466, 264, 4948, 50672], "temperature": 0.0, "avg_logprob": -0.06686938436407792, "compression_ratio": 1.651567944250871, "no_speech_prob": 0.004891351796686649}, {"id": 1044, "seek": 496882, "start": 4974.98, "end": 4980.9, "text": " in terms of the improvement that you could get from any kind of distillation-based approach", "tokens": [50672, 294, 2115, 295, 264, 10444, 300, 291, 727, 483, 490, 604, 733, 295, 42923, 399, 12, 6032, 3109, 50968], "temperature": 0.0, "avg_logprob": -0.06686938436407792, "compression_ratio": 1.651567944250871, "no_speech_prob": 0.004891351796686649}, {"id": 1045, "seek": 496882, "start": 4980.9, "end": 4986.9, "text": " over supervised training from scratch. Fascinating. I don't know if you know that we've been playing", "tokens": [50968, 670, 46533, 3097, 490, 8459, 13, 49098, 8205, 13, 286, 500, 380, 458, 498, 291, 458, 300, 321, 600, 668, 2433, 51268], "temperature": 0.0, "avg_logprob": -0.06686938436407792, "compression_ratio": 1.651567944250871, "no_speech_prob": 0.004891351796686649}, {"id": 1046, "seek": 496882, "start": 4986.9, "end": 4991.86, "text": " with GPT-3 and you said something quite interesting just now. You said that they're deterministic,", "tokens": [51268, 365, 26039, 51, 12, 18, 293, 291, 848, 746, 1596, 1880, 445, 586, 13, 509, 848, 300, 436, 434, 15957, 3142, 11, 51516], "temperature": 0.0, "avg_logprob": -0.06686938436407792, "compression_ratio": 1.651567944250871, "no_speech_prob": 0.004891351796686649}, {"id": 1047, "seek": 496882, "start": 4991.86, "end": 4996.0199999999995, "text": " but in GPT-3, that's not really the case. If you sample from it deterministically,", "tokens": [51516, 457, 294, 26039, 51, 12, 18, 11, 300, 311, 406, 534, 264, 1389, 13, 759, 291, 6889, 490, 309, 15957, 20458, 11, 51724], "temperature": 0.0, "avg_logprob": -0.06686938436407792, "compression_ratio": 1.651567944250871, "no_speech_prob": 0.004891351796686649}, {"id": 1048, "seek": 499602, "start": 4996.02, "end": 5003.22, "text": " it gets stuck in cycles. You have to do some kind of trickery, some kind of random sampling from", "tokens": [50364, 309, 2170, 5541, 294, 17796, 13, 509, 362, 281, 360, 512, 733, 295, 4282, 2109, 11, 512, 733, 295, 4974, 21179, 490, 50724], "temperature": 0.0, "avg_logprob": -0.08869643089098808, "compression_ratio": 1.708185053380783, "no_speech_prob": 0.013560736551880836}, {"id": 1049, "seek": 499602, "start": 5003.22, "end": 5008.740000000001, "text": " this distribution. It might be the case in future computer vision models as well, that we have to", "tokens": [50724, 341, 7316, 13, 467, 1062, 312, 264, 1389, 294, 2027, 3820, 5201, 5245, 382, 731, 11, 300, 321, 362, 281, 51000], "temperature": 0.0, "avg_logprob": -0.08869643089098808, "compression_ratio": 1.708185053380783, "no_speech_prob": 0.013560736551880836}, {"id": 1050, "seek": 499602, "start": 5008.740000000001, "end": 5012.740000000001, "text": " randomly sample from them in some way, because otherwise it would get into some pathological", "tokens": [51000, 16979, 6889, 490, 552, 294, 512, 636, 11, 570, 5911, 309, 576, 483, 666, 512, 3100, 4383, 51200], "temperature": 0.0, "avg_logprob": -0.08869643089098808, "compression_ratio": 1.708185053380783, "no_speech_prob": 0.013560736551880836}, {"id": 1051, "seek": 499602, "start": 5012.740000000001, "end": 5017.780000000001, "text": " behavior. Maybe to do that, we need to have some kind of controller on the top. I suppose my question", "tokens": [51200, 5223, 13, 2704, 281, 360, 300, 11, 321, 643, 281, 362, 512, 733, 295, 10561, 322, 264, 1192, 13, 286, 7297, 452, 1168, 51452], "temperature": 0.0, "avg_logprob": -0.08869643089098808, "compression_ratio": 1.708185053380783, "no_speech_prob": 0.013560736551880836}, {"id": 1052, "seek": 499602, "start": 5017.780000000001, "end": 5022.26, "text": " is in the future, maybe we will be in the stochastic regime. What do you think about that?", "tokens": [51452, 307, 294, 264, 2027, 11, 1310, 321, 486, 312, 294, 264, 342, 8997, 2750, 13120, 13, 708, 360, 291, 519, 466, 300, 30, 51676], "temperature": 0.0, "avg_logprob": -0.08869643089098808, "compression_ratio": 1.708185053380783, "no_speech_prob": 0.013560736551880836}, {"id": 1053, "seek": 502226, "start": 5023.14, "end": 5029.62, "text": " With GPT-3, you're trying to generate data. When you generate data, there has to be some", "tokens": [50408, 2022, 26039, 51, 12, 18, 11, 291, 434, 1382, 281, 8460, 1412, 13, 1133, 291, 8460, 1412, 11, 456, 575, 281, 312, 512, 50732], "temperature": 0.0, "avg_logprob": -0.09528302086724175, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.0005882700788788497}, {"id": 1054, "seek": 502226, "start": 5029.62, "end": 5034.5, "text": " kind of noise that's coming from somewhere. The process of generating data is like turning", "tokens": [50732, 733, 295, 5658, 300, 311, 1348, 490, 4079, 13, 440, 1399, 295, 17746, 1412, 307, 411, 6246, 50976], "temperature": 0.0, "avg_logprob": -0.09528302086724175, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.0005882700788788497}, {"id": 1055, "seek": 502226, "start": 5034.5, "end": 5040.9800000000005, "text": " noise into data. For image classification, we have the data and we just want to turn it into", "tokens": [50976, 5658, 666, 1412, 13, 1171, 3256, 21538, 11, 321, 362, 264, 1412, 293, 321, 445, 528, 281, 1261, 309, 666, 51300], "temperature": 0.0, "avg_logprob": -0.09528302086724175, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.0005882700788788497}, {"id": 1056, "seek": 502226, "start": 5040.9800000000005, "end": 5047.38, "text": " a label. Maybe there's this implicit notion of stochasticity in that the network gives some", "tokens": [51300, 257, 7645, 13, 2704, 456, 311, 341, 26947, 10710, 295, 342, 8997, 2750, 507, 294, 300, 264, 3209, 2709, 512, 51620], "temperature": 0.0, "avg_logprob": -0.09528302086724175, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.0005882700788788497}, {"id": 1057, "seek": 504738, "start": 5047.86, "end": 5053.54, "text": " output distribution. I think we still want everything to be deterministic if it can be", "tokens": [50388, 5598, 7316, 13, 286, 519, 321, 920, 528, 1203, 281, 312, 15957, 3142, 498, 309, 393, 312, 50672], "temperature": 0.0, "avg_logprob": -0.08824671075699177, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.016395797953009605}, {"id": 1058, "seek": 504738, "start": 5053.54, "end": 5059.62, "text": " deterministic. We basically want the network to say, this is a dog with probability x.", "tokens": [50672, 15957, 3142, 13, 492, 1936, 528, 264, 3209, 281, 584, 11, 341, 307, 257, 3000, 365, 8482, 2031, 13, 50976], "temperature": 0.0, "avg_logprob": -0.08824671075699177, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.016395797953009605}, {"id": 1059, "seek": 504738, "start": 5060.34, "end": 5065.86, "text": " If there's some way to improve it with stochasticity, I don't know. I guess dropout used to be very", "tokens": [51012, 759, 456, 311, 512, 636, 281, 3470, 309, 365, 342, 8997, 2750, 507, 11, 286, 500, 380, 458, 13, 286, 2041, 3270, 346, 1143, 281, 312, 588, 51288], "temperature": 0.0, "avg_logprob": -0.08824671075699177, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.016395797953009605}, {"id": 1060, "seek": 504738, "start": 5065.86, "end": 5070.9800000000005, "text": " popular, but it seems like it's not so popular anymore and it doesn't really help us very much", "tokens": [51288, 3743, 11, 457, 309, 2544, 411, 309, 311, 406, 370, 3743, 3602, 293, 309, 1177, 380, 534, 854, 505, 588, 709, 51544], "temperature": 0.0, "avg_logprob": -0.08824671075699177, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.016395797953009605}, {"id": 1061, "seek": 507098, "start": 5070.98, "end": 5077.86, "text": " with vision models. Also, even dropout is generally only used when we train the neural", "tokens": [50364, 365, 5201, 5245, 13, 2743, 11, 754, 3270, 346, 307, 5101, 787, 1143, 562, 321, 3847, 264, 18161, 50708], "temperature": 0.0, "avg_logprob": -0.08769726976055965, "compression_ratio": 1.6353383458646618, "no_speech_prob": 0.02399633824825287}, {"id": 1062, "seek": 507098, "start": 5077.86, "end": 5086.259999999999, "text": " networks. On the other hand, the brain is very stochastic. The brain has lots of noise. I guess", "tokens": [50708, 9590, 13, 1282, 264, 661, 1011, 11, 264, 3567, 307, 588, 342, 8997, 2750, 13, 440, 3567, 575, 3195, 295, 5658, 13, 286, 2041, 51128], "temperature": 0.0, "avg_logprob": -0.08769726976055965, "compression_ratio": 1.6353383458646618, "no_speech_prob": 0.02399633824825287}, {"id": 1063, "seek": 507098, "start": 5086.259999999999, "end": 5090.9, "text": " that suggests that maybe there's some way to leverage noise to learn better representations", "tokens": [51128, 300, 13409, 300, 1310, 456, 311, 512, 636, 281, 13982, 5658, 281, 1466, 1101, 33358, 51360], "temperature": 0.0, "avg_logprob": -0.08769726976055965, "compression_ratio": 1.6353383458646618, "no_speech_prob": 0.02399633824825287}, {"id": 1064, "seek": 507098, "start": 5090.9, "end": 5094.339999999999, "text": " in neural networks as well and we just don't quite know the right way yet.", "tokens": [51360, 294, 18161, 9590, 382, 731, 293, 321, 445, 500, 380, 1596, 458, 264, 558, 636, 1939, 13, 51532], "temperature": 0.0, "avg_logprob": -0.08769726976055965, "compression_ratio": 1.6353383458646618, "no_speech_prob": 0.02399633824825287}, {"id": 1065, "seek": 507098, "start": 5094.9, "end": 5099.139999999999, "text": " That's right. Max Welling said to us that he thinks that the future of AI will have a", "tokens": [51560, 663, 311, 558, 13, 7402, 1042, 278, 848, 281, 505, 300, 415, 7309, 300, 264, 2027, 295, 7318, 486, 362, 257, 51772], "temperature": 0.0, "avg_logprob": -0.08769726976055965, "compression_ratio": 1.6353383458646618, "no_speech_prob": 0.02399633824825287}, {"id": 1066, "seek": 509914, "start": 5099.14, "end": 5104.660000000001, "text": " generative component. He thinks that we have the matrix in our minds. We have these simulations", "tokens": [50364, 1337, 1166, 6542, 13, 634, 7309, 300, 321, 362, 264, 8141, 294, 527, 9634, 13, 492, 362, 613, 35138, 50640], "temperature": 0.0, "avg_logprob": -0.05940596124400263, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.0027092243544757366}, {"id": 1067, "seek": 509914, "start": 5104.660000000001, "end": 5111.22, "text": " going on all the time and we're generating new scenarios. It's related to the data", "tokens": [50640, 516, 322, 439, 264, 565, 293, 321, 434, 17746, 777, 15077, 13, 467, 311, 4077, 281, 264, 1412, 50968], "temperature": 0.0, "avg_logprob": -0.05940596124400263, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.0027092243544757366}, {"id": 1068, "seek": 509914, "start": 5111.22, "end": 5116.34, "text": " augmentation thing as well. Some people have said to me in the past that using a GAN might be a way", "tokens": [50968, 14501, 19631, 551, 382, 731, 13, 2188, 561, 362, 848, 281, 385, 294, 264, 1791, 300, 1228, 257, 460, 1770, 1062, 312, 257, 636, 51224], "temperature": 0.0, "avg_logprob": -0.05940596124400263, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.0027092243544757366}, {"id": 1069, "seek": 509914, "start": 5116.34, "end": 5121.9400000000005, "text": " of doing data augmentation. Presumably, that would require some kind of stochastic sampling as well.", "tokens": [51224, 295, 884, 1412, 14501, 19631, 13, 2718, 449, 1188, 11, 300, 576, 3651, 512, 733, 295, 342, 8997, 2750, 21179, 382, 731, 13, 51504], "temperature": 0.0, "avg_logprob": -0.05940596124400263, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.0027092243544757366}, {"id": 1070, "seek": 509914, "start": 5121.9400000000005, "end": 5125.38, "text": " I suppose it's just quite interesting to see where these two things might meet in the middle at", "tokens": [51504, 286, 7297, 309, 311, 445, 1596, 1880, 281, 536, 689, 613, 732, 721, 1062, 1677, 294, 264, 2808, 412, 51676], "temperature": 0.0, "avg_logprob": -0.05940596124400263, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.0027092243544757366}, {"id": 1071, "seek": 512538, "start": 5125.38, "end": 5130.900000000001, "text": " some point. Max Yeah. I don't know. I guess like with a GAN, using a GAN to do data augmentation,", "tokens": [50364, 512, 935, 13, 7402, 865, 13, 286, 500, 380, 458, 13, 286, 2041, 411, 365, 257, 460, 1770, 11, 1228, 257, 460, 1770, 281, 360, 1412, 14501, 19631, 11, 50640], "temperature": 0.0, "avg_logprob": -0.08453778297670426, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.0021153248380869627}, {"id": 1072, "seek": 512538, "start": 5130.900000000001, "end": 5135.9400000000005, "text": " you have this problem that you still don't actually have more data. You have a GAN that's", "tokens": [50640, 291, 362, 341, 1154, 300, 291, 920, 500, 380, 767, 362, 544, 1412, 13, 509, 362, 257, 460, 1770, 300, 311, 50892], "temperature": 0.0, "avg_logprob": -0.08453778297670426, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.0021153248380869627}, {"id": 1073, "seek": 512538, "start": 5135.9400000000005, "end": 5142.34, "text": " trained on the same data. It might help you because your way of encoding inductive bias into the GAN", "tokens": [50892, 8895, 322, 264, 912, 1412, 13, 467, 1062, 854, 291, 570, 428, 636, 295, 43430, 31612, 488, 12577, 666, 264, 460, 1770, 51212], "temperature": 0.0, "avg_logprob": -0.08453778297670426, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.0021153248380869627}, {"id": 1074, "seek": 512538, "start": 5142.34, "end": 5148.1, "text": " is different from your way of encoding inductive bias into the neural network. Maybe by having", "tokens": [51212, 307, 819, 490, 428, 636, 295, 43430, 31612, 488, 12577, 666, 264, 18161, 3209, 13, 2704, 538, 1419, 51500], "temperature": 0.0, "avg_logprob": -0.08453778297670426, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.0021153248380869627}, {"id": 1075, "seek": 512538, "start": 5148.1, "end": 5154.5, "text": " more inductive bias, you can learn a better function. You still don't have more data at it.", "tokens": [51500, 544, 31612, 488, 12577, 11, 291, 393, 1466, 257, 1101, 2445, 13, 509, 920, 500, 380, 362, 544, 1412, 412, 309, 13, 51820], "temperature": 0.0, "avg_logprob": -0.08453778297670426, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.0021153248380869627}, {"id": 1076, "seek": 515450, "start": 5155.3, "end": 5161.3, "text": " Without having more data, there's no reason to expect a priority that you will be able to learn", "tokens": [50404, 9129, 1419, 544, 1412, 11, 456, 311, 572, 1778, 281, 2066, 257, 9365, 300, 291, 486, 312, 1075, 281, 1466, 50704], "temperature": 0.0, "avg_logprob": -0.18515271046122567, "compression_ratio": 1.6496350364963503, "no_speech_prob": 0.00020333693828433752}, {"id": 1077, "seek": 515450, "start": 5161.3, "end": 5166.34, "text": " a better function. Paul I'm so glad you said that. It was always my intuition. The amount of people", "tokens": [50704, 257, 1101, 2445, 13, 4552, 286, 478, 370, 5404, 291, 848, 300, 13, 467, 390, 1009, 452, 24002, 13, 440, 2372, 295, 561, 50956], "temperature": 0.0, "avg_logprob": -0.18515271046122567, "compression_ratio": 1.6496350364963503, "no_speech_prob": 0.00020333693828433752}, {"id": 1078, "seek": 515450, "start": 5166.34, "end": 5169.7, "text": " that have said to me that you should use a GAN for data augmentation. Anyway.", "tokens": [50956, 300, 362, 848, 281, 385, 300, 291, 820, 764, 257, 460, 1770, 337, 1412, 14501, 19631, 13, 5684, 13, 51124], "temperature": 0.0, "avg_logprob": -0.18515271046122567, "compression_ratio": 1.6496350364963503, "no_speech_prob": 0.00020333693828433752}, {"id": 1079, "seek": 515450, "start": 5169.7, "end": 5174.66, "text": " Max What's the first thing you think about if you're like, oh, what could I use a GAN for?", "tokens": [51124, 7402, 708, 311, 264, 700, 551, 291, 519, 466, 498, 291, 434, 411, 11, 1954, 11, 437, 727, 286, 764, 257, 460, 1770, 337, 30, 51372], "temperature": 0.0, "avg_logprob": -0.18515271046122567, "compression_ratio": 1.6496350364963503, "no_speech_prob": 0.00020333693828433752}, {"id": 1080, "seek": 515450, "start": 5174.66, "end": 5180.02, "text": " And then you learn about data, and they're like, wait, this is so much more data. Yeah,", "tokens": [51372, 400, 550, 291, 1466, 466, 1412, 11, 293, 436, 434, 411, 11, 1699, 11, 341, 307, 370, 709, 544, 1412, 13, 865, 11, 51640], "temperature": 0.0, "avg_logprob": -0.18515271046122567, "compression_ratio": 1.6496350364963503, "no_speech_prob": 0.00020333693828433752}, {"id": 1081, "seek": 518002, "start": 5180.02, "end": 5186.02, "text": " but conceptually, yes, you don't have more data. And ironically, when you do the simple", "tokens": [50364, 457, 3410, 671, 11, 2086, 11, 291, 500, 380, 362, 544, 1412, 13, 400, 41082, 11, 562, 291, 360, 264, 2199, 50664], "temperature": 0.0, "avg_logprob": -0.08273084958394368, "compression_ratio": 1.6650717703349283, "no_speech_prob": 0.002285868162289262}, {"id": 1082, "seek": 518002, "start": 5186.02, "end": 5191.780000000001, "text": " data augmentation, you do have more data because you put all the knowledge in there", "tokens": [50664, 1412, 14501, 19631, 11, 291, 360, 362, 544, 1412, 570, 291, 829, 439, 264, 3601, 294, 456, 50952], "temperature": 0.0, "avg_logprob": -0.08273084958394368, "compression_ratio": 1.6650717703349283, "no_speech_prob": 0.002285868162289262}, {"id": 1083, "seek": 518002, "start": 5191.780000000001, "end": 5199.06, "text": " as a human of what makes two images dissimilar visually, but still equivalent semantically,", "tokens": [50952, 382, 257, 1952, 295, 437, 1669, 732, 5267, 7802, 332, 2202, 19622, 11, 457, 920, 10344, 4361, 49505, 11, 51316], "temperature": 0.0, "avg_logprob": -0.08273084958394368, "compression_ratio": 1.6650717703349283, "no_speech_prob": 0.002285868162289262}, {"id": 1084, "seek": 518002, "start": 5199.06, "end": 5205.14, "text": " which again, is exactly the opposite. It gives you images that are visually similar,", "tokens": [51316, 597, 797, 11, 307, 2293, 264, 6182, 13, 467, 2709, 291, 5267, 300, 366, 19622, 2531, 11, 51620], "temperature": 0.0, "avg_logprob": -0.08273084958394368, "compression_ratio": 1.6650717703349283, "no_speech_prob": 0.002285868162289262}, {"id": 1085, "seek": 520514, "start": 5205.14, "end": 5211.700000000001, "text": " but it has no intuition of what the semantic similarity is. For my last question, I actually", "tokens": [50364, 457, 309, 575, 572, 24002, 295, 437, 264, 47982, 32194, 307, 13, 1171, 452, 1036, 1168, 11, 286, 767, 50692], "temperature": 0.0, "avg_logprob": -0.12202723995669858, "compression_ratio": 1.538152610441767, "no_speech_prob": 0.0032714044209569693}, {"id": 1086, "seek": 520514, "start": 5211.700000000001, "end": 5217.46, "text": " want to switch topics just a little bit to what Tim said at the beginning, namely your love of Julia.", "tokens": [50692, 528, 281, 3679, 8378, 445, 257, 707, 857, 281, 437, 7172, 848, 412, 264, 2863, 11, 20926, 428, 959, 295, 18551, 13, 50980], "temperature": 0.0, "avg_logprob": -0.12202723995669858, "compression_ratio": 1.538152610441767, "no_speech_prob": 0.0032714044209569693}, {"id": 1087, "seek": 520514, "start": 5218.26, "end": 5225.54, "text": " So I have seen a number of especially data scientists be strong advocates for Julia as a", "tokens": [51020, 407, 286, 362, 1612, 257, 1230, 295, 2318, 1412, 7708, 312, 2068, 25160, 337, 18551, 382, 257, 51384], "temperature": 0.0, "avg_logprob": -0.12202723995669858, "compression_ratio": 1.538152610441767, "no_speech_prob": 0.0032714044209569693}, {"id": 1088, "seek": 520514, "start": 5225.54, "end": 5232.18, "text": " language and so on. Do you want to give anyone sort of the pitch? Why should we even consider this?", "tokens": [51384, 2856, 293, 370, 322, 13, 1144, 291, 528, 281, 976, 2878, 1333, 295, 264, 7293, 30, 1545, 820, 321, 754, 1949, 341, 30, 51716], "temperature": 0.0, "avg_logprob": -0.12202723995669858, "compression_ratio": 1.538152610441767, "no_speech_prob": 0.0032714044209569693}, {"id": 1089, "seek": 523218, "start": 5233.06, "end": 5239.3, "text": " Yeah, so I think Julia is a much better programming language than Python in many ways.", "tokens": [50408, 865, 11, 370, 286, 519, 18551, 307, 257, 709, 1101, 9410, 2856, 813, 15329, 294, 867, 2098, 13, 50720], "temperature": 0.0, "avg_logprob": -0.0876867645665219, "compression_ratio": 1.674074074074074, "no_speech_prob": 0.002050424227491021}, {"id": 1090, "seek": 523218, "start": 5239.9400000000005, "end": 5244.9800000000005, "text": " I guess one thing and I guess the thing that first attracted me to Julia is that it's really", "tokens": [50752, 286, 2041, 472, 551, 293, 286, 2041, 264, 551, 300, 700, 15912, 385, 281, 18551, 307, 300, 309, 311, 534, 51004], "temperature": 0.0, "avg_logprob": -0.0876867645665219, "compression_ratio": 1.674074074074074, "no_speech_prob": 0.002050424227491021}, {"id": 1091, "seek": 523218, "start": 5244.9800000000005, "end": 5250.820000000001, "text": " fast, like you can write Julia code and with very little work, you will end up running as", "tokens": [51004, 2370, 11, 411, 291, 393, 2464, 18551, 3089, 293, 365, 588, 707, 589, 11, 291, 486, 917, 493, 2614, 382, 51296], "temperature": 0.0, "avg_logprob": -0.0876867645665219, "compression_ratio": 1.674074074074074, "no_speech_prob": 0.002050424227491021}, {"id": 1092, "seek": 523218, "start": 5250.820000000001, "end": 5256.820000000001, "text": " fast as equivalent C code. So that's something that you can't get out of standard Python code.", "tokens": [51296, 2370, 382, 10344, 383, 3089, 13, 407, 300, 311, 746, 300, 291, 393, 380, 483, 484, 295, 3832, 15329, 3089, 13, 51596], "temperature": 0.0, "avg_logprob": -0.0876867645665219, "compression_ratio": 1.674074074074074, "no_speech_prob": 0.002050424227491021}, {"id": 1093, "seek": 523218, "start": 5256.820000000001, "end": 5261.3, "text": " If you're just writing a for loop in Python, it's going to be super slow. But in Julia,", "tokens": [51596, 759, 291, 434, 445, 3579, 257, 337, 6367, 294, 15329, 11, 309, 311, 516, 281, 312, 1687, 2964, 13, 583, 294, 18551, 11, 51820], "temperature": 0.0, "avg_logprob": -0.0876867645665219, "compression_ratio": 1.674074074074074, "no_speech_prob": 0.002050424227491021}, {"id": 1094, "seek": 526130, "start": 5261.3, "end": 5264.900000000001, "text": " you don't have to worry about all of that. And you don't have to worry about like Cython or", "tokens": [50364, 291, 500, 380, 362, 281, 3292, 466, 439, 295, 300, 13, 400, 291, 500, 380, 362, 281, 3292, 466, 411, 10295, 11943, 420, 50544], "temperature": 0.0, "avg_logprob": -0.11115838863231518, "compression_ratio": 1.796875, "no_speech_prob": 0.002713952213525772}, {"id": 1095, "seek": 526130, "start": 5264.900000000001, "end": 5269.860000000001, "text": " number all of this other stuff that people have hacked on top of Python. Julia is just", "tokens": [50544, 1230, 439, 295, 341, 661, 1507, 300, 561, 362, 36218, 322, 1192, 295, 15329, 13, 18551, 307, 445, 50792], "temperature": 0.0, "avg_logprob": -0.11115838863231518, "compression_ratio": 1.796875, "no_speech_prob": 0.002713952213525772}, {"id": 1096, "seek": 526130, "start": 5269.860000000001, "end": 5277.62, "text": " designed to be fast and it works. I think there are other advantages to Julia as a language", "tokens": [50792, 4761, 281, 312, 2370, 293, 309, 1985, 13, 286, 519, 456, 366, 661, 14906, 281, 18551, 382, 257, 2856, 51180], "temperature": 0.0, "avg_logprob": -0.11115838863231518, "compression_ratio": 1.796875, "no_speech_prob": 0.002713952213525772}, {"id": 1097, "seek": 526130, "start": 5277.62, "end": 5284.820000000001, "text": " beyond that. I guess it's built on this idea of generic functions where you have a function that", "tokens": [51180, 4399, 300, 13, 286, 2041, 309, 311, 3094, 322, 341, 1558, 295, 19577, 6828, 689, 291, 362, 257, 2445, 300, 51540], "temperature": 0.0, "avg_logprob": -0.11115838863231518, "compression_ratio": 1.796875, "no_speech_prob": 0.002713952213525772}, {"id": 1098, "seek": 526130, "start": 5285.860000000001, "end": 5290.1, "text": " can take multiple types and you can define the function differently for the different types.", "tokens": [51592, 393, 747, 3866, 3467, 293, 291, 393, 6964, 264, 2445, 7614, 337, 264, 819, 3467, 13, 51804], "temperature": 0.0, "avg_logprob": -0.11115838863231518, "compression_ratio": 1.796875, "no_speech_prob": 0.002713952213525772}, {"id": 1099, "seek": 529010, "start": 5290.660000000001, "end": 5295.22, "text": " And this is something that we do all the time when we're doing like machine learning, like we", "tokens": [50392, 400, 341, 307, 746, 300, 321, 360, 439, 264, 565, 562, 321, 434, 884, 411, 3479, 2539, 11, 411, 321, 50620], "temperature": 0.0, "avg_logprob": -0.1278036265697294, "compression_ratio": 1.7769230769230768, "no_speech_prob": 0.0007552371243946254}, {"id": 1100, "seek": 529010, "start": 5295.22, "end": 5300.5, "text": " have matrix multiplication, which is a different form of multiplication that takes matrices and", "tokens": [50620, 362, 8141, 27290, 11, 597, 307, 257, 819, 1254, 295, 27290, 300, 2516, 32284, 293, 50884], "temperature": 0.0, "avg_logprob": -0.1278036265697294, "compression_ratio": 1.7769230769230768, "no_speech_prob": 0.0007552371243946254}, {"id": 1101, "seek": 529010, "start": 5300.5, "end": 5308.02, "text": " produces something. And I guess like in Python, it's so it used to be that you had to type dot dot", "tokens": [50884, 14725, 746, 13, 400, 286, 2041, 411, 294, 15329, 11, 309, 311, 370, 309, 1143, 281, 312, 300, 291, 632, 281, 2010, 5893, 5893, 51260], "temperature": 0.0, "avg_logprob": -0.1278036265697294, "compression_ratio": 1.7769230769230768, "no_speech_prob": 0.0007552371243946254}, {"id": 1102, "seek": 529010, "start": 5309.3, "end": 5314.9800000000005, "text": " to multiply things, but now it's like they have this add symbol that does matrix multiplication.", "tokens": [51324, 281, 12972, 721, 11, 457, 586, 309, 311, 411, 436, 362, 341, 909, 5986, 300, 775, 8141, 27290, 13, 51608], "temperature": 0.0, "avg_logprob": -0.1278036265697294, "compression_ratio": 1.7769230769230768, "no_speech_prob": 0.0007552371243946254}, {"id": 1103, "seek": 529010, "start": 5314.9800000000005, "end": 5319.700000000001, "text": " But Julia is designed for these situations where maybe beyond just matrices,", "tokens": [51608, 583, 18551, 307, 4761, 337, 613, 6851, 689, 1310, 4399, 445, 32284, 11, 51844], "temperature": 0.0, "avg_logprob": -0.1278036265697294, "compression_ratio": 1.7769230769230768, "no_speech_prob": 0.0007552371243946254}, {"id": 1104, "seek": 531970, "start": 5319.7, "end": 5324.179999999999, "text": " you have these funny types of structured matrices, you have sparse matrices, and you can define", "tokens": [50364, 291, 362, 613, 4074, 3467, 295, 18519, 32284, 11, 291, 362, 637, 11668, 32284, 11, 293, 291, 393, 6964, 50588], "temperature": 0.0, "avg_logprob": -0.07616647084554036, "compression_ratio": 1.7765567765567765, "no_speech_prob": 0.0007790728122927248}, {"id": 1105, "seek": 531970, "start": 5324.179999999999, "end": 5329.86, "text": " special methods for the product of a sparse matrix and a vector or all sorts of things where you", "tokens": [50588, 2121, 7150, 337, 264, 1674, 295, 257, 637, 11668, 8141, 293, 257, 8062, 420, 439, 7527, 295, 721, 689, 291, 50872], "temperature": 0.0, "avg_logprob": -0.07616647084554036, "compression_ratio": 1.7765567765567765, "no_speech_prob": 0.0007790728122927248}, {"id": 1106, "seek": 531970, "start": 5329.86, "end": 5335.94, "text": " might want different methods depending on the types. And even though it seems like this is", "tokens": [50872, 1062, 528, 819, 7150, 5413, 322, 264, 3467, 13, 400, 754, 1673, 309, 2544, 411, 341, 307, 51176], "temperature": 0.0, "avg_logprob": -0.07616647084554036, "compression_ratio": 1.7765567765567765, "no_speech_prob": 0.0007790728122927248}, {"id": 1107, "seek": 531970, "start": 5335.94, "end": 5340.9, "text": " complicated and you might have some trouble picking which version of the function is going to be called", "tokens": [51176, 6179, 293, 291, 1062, 362, 512, 5253, 8867, 597, 3037, 295, 264, 2445, 307, 516, 281, 312, 1219, 51424], "temperature": 0.0, "avg_logprob": -0.07616647084554036, "compression_ratio": 1.7765567765567765, "no_speech_prob": 0.0007790728122927248}, {"id": 1108, "seek": 531970, "start": 5340.9, "end": 5348.98, "text": " at runtime, because Julia is ultimately compiling everything when you call it. And because it has", "tokens": [51424, 412, 34474, 11, 570, 18551, 307, 6284, 715, 4883, 1203, 562, 291, 818, 309, 13, 400, 570, 309, 575, 51828], "temperature": 0.0, "avg_logprob": -0.07616647084554036, "compression_ratio": 1.7765567765567765, "no_speech_prob": 0.0007790728122927248}, {"id": 1109, "seek": 534898, "start": 5348.98, "end": 5356.58, "text": " this kind of strong type system, it can ultimately pick which method is going to be used and compile", "tokens": [50364, 341, 733, 295, 2068, 2010, 1185, 11, 309, 393, 6284, 1888, 597, 3170, 307, 516, 281, 312, 1143, 293, 31413, 50744], "temperature": 0.0, "avg_logprob": -0.073799144262555, "compression_ratio": 1.703056768558952, "no_speech_prob": 0.0005356818437576294}, {"id": 1110, "seek": 534898, "start": 5356.58, "end": 5361.62, "text": " that method call in and you don't have to worry about picking which one. And so it still ends up", "tokens": [50744, 300, 3170, 818, 294, 293, 291, 500, 380, 362, 281, 3292, 466, 8867, 597, 472, 13, 400, 370, 309, 920, 5314, 493, 50996], "temperature": 0.0, "avg_logprob": -0.073799144262555, "compression_ratio": 1.703056768558952, "no_speech_prob": 0.0005356818437576294}, {"id": 1111, "seek": 534898, "start": 5361.62, "end": 5369.62, "text": " being fast. I also think like there's this question of whether like the object oriented Python or", "tokens": [50996, 885, 2370, 13, 286, 611, 519, 411, 456, 311, 341, 1168, 295, 1968, 411, 264, 2657, 21841, 15329, 420, 51396], "temperature": 0.0, "avg_logprob": -0.073799144262555, "compression_ratio": 1.703056768558952, "no_speech_prob": 0.0005356818437576294}, {"id": 1112, "seek": 534898, "start": 5369.62, "end": 5376.9, "text": " the object oriented paradigm and Python is really like the best paradigm for machine learning.", "tokens": [51396, 264, 2657, 21841, 24709, 293, 15329, 307, 534, 411, 264, 1151, 24709, 337, 3479, 2539, 13, 51760], "temperature": 0.0, "avg_logprob": -0.073799144262555, "compression_ratio": 1.703056768558952, "no_speech_prob": 0.0005356818437576294}, {"id": 1113, "seek": 537690, "start": 5376.9, "end": 5382.98, "text": " Because I guess like it's like we have data and then we have functions that operate on the data.", "tokens": [50364, 1436, 286, 2041, 411, 309, 311, 411, 321, 362, 1412, 293, 550, 321, 362, 6828, 300, 9651, 322, 264, 1412, 13, 50668], "temperature": 0.0, "avg_logprob": -0.07011717719000739, "compression_ratio": 1.9317269076305221, "no_speech_prob": 0.0005702412454411387}, {"id": 1114, "seek": 537690, "start": 5382.98, "end": 5386.74, "text": " But in the object oriented paradigm, you want the functions that operate on the data to be", "tokens": [50668, 583, 294, 264, 2657, 21841, 24709, 11, 291, 528, 264, 6828, 300, 9651, 322, 264, 1412, 281, 312, 50856], "temperature": 0.0, "avg_logprob": -0.07011717719000739, "compression_ratio": 1.9317269076305221, "no_speech_prob": 0.0005702412454411387}, {"id": 1115, "seek": 537690, "start": 5386.74, "end": 5392.82, "text": " attached to the data, which is like a weird way of setting things up. And that Julia is not set up", "tokens": [50856, 8570, 281, 264, 1412, 11, 597, 307, 411, 257, 3657, 636, 295, 3287, 721, 493, 13, 400, 300, 18551, 307, 406, 992, 493, 51160], "temperature": 0.0, "avg_logprob": -0.07011717719000739, "compression_ratio": 1.9317269076305221, "no_speech_prob": 0.0005702412454411387}, {"id": 1116, "seek": 537690, "start": 5392.82, "end": 5398.82, "text": " that way. You have these data structures. And then because you are able to create functions that", "tokens": [51160, 300, 636, 13, 509, 362, 613, 1412, 9227, 13, 400, 550, 570, 291, 366, 1075, 281, 1884, 6828, 300, 51460], "temperature": 0.0, "avg_logprob": -0.07011717719000739, "compression_ratio": 1.9317269076305221, "no_speech_prob": 0.0005702412454411387}, {"id": 1117, "seek": 537690, "start": 5398.82, "end": 5404.259999999999, "text": " specialize on the data structures, you don't have to worry about attaching those functions to the", "tokens": [51460, 37938, 322, 264, 1412, 9227, 11, 291, 500, 380, 362, 281, 3292, 466, 39074, 729, 6828, 281, 264, 51732], "temperature": 0.0, "avg_logprob": -0.07011717719000739, "compression_ratio": 1.9317269076305221, "no_speech_prob": 0.0005702412454411387}, {"id": 1118, "seek": 540426, "start": 5404.34, "end": 5410.66, "text": " data structures themselves. Amazing. Dr. Simon Cornblith. Thank you very much for joining us", "tokens": [50368, 1412, 9227, 2969, 13, 14165, 13, 2491, 13, 13193, 21590, 5199, 355, 13, 1044, 291, 588, 709, 337, 5549, 505, 50684], "temperature": 0.0, "avg_logprob": -0.09823847831563746, "compression_ratio": 1.5394190871369295, "no_speech_prob": 0.014040730893611908}, {"id": 1119, "seek": 540426, "start": 5410.66, "end": 5415.780000000001, "text": " this evening. It's been an absolute pleasure. Thanks for having me. Thank you. I really hope", "tokens": [50684, 341, 5634, 13, 467, 311, 668, 364, 8236, 6834, 13, 2561, 337, 1419, 385, 13, 1044, 291, 13, 286, 534, 1454, 50940], "temperature": 0.0, "avg_logprob": -0.09823847831563746, "compression_ratio": 1.5394190871369295, "no_speech_prob": 0.014040730893611908}, {"id": 1120, "seek": 540426, "start": 5415.780000000001, "end": 5421.14, "text": " you've enjoyed the show today. We've had so much fun making it. Remember to like, comment,", "tokens": [50940, 291, 600, 4626, 264, 855, 965, 13, 492, 600, 632, 370, 709, 1019, 1455, 309, 13, 5459, 281, 411, 11, 2871, 11, 51208], "temperature": 0.0, "avg_logprob": -0.09823847831563746, "compression_ratio": 1.5394190871369295, "no_speech_prob": 0.014040730893611908}, {"id": 1121, "seek": 540426, "start": 5421.14, "end": 5426.18, "text": " and subscribe. We love reading your comments, every single one of them. And we'll see you back", "tokens": [51208, 293, 3022, 13, 492, 959, 3760, 428, 3053, 11, 633, 2167, 472, 295, 552, 13, 400, 321, 603, 536, 291, 646, 51460], "temperature": 0.0, "avg_logprob": -0.09823847831563746, "compression_ratio": 1.5394190871369295, "no_speech_prob": 0.014040730893611908}, {"id": 1122, "seek": 542618, "start": 5426.18, "end": 5429.06, "text": " next week.", "tokens": [50408, 958, 1243, 13, 50508], "temperature": 0.0, "avg_logprob": -0.5844686428705851, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.17291343212127686}], "language": "en"}