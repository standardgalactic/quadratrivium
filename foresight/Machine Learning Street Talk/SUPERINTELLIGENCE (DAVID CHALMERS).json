{"text": " He moved to Indiana University in 1989, where he obtained his PhD in philosophy and cognitive science, working for the legendary Douglas Hofstadter, by the way. I've got his book here in the Center for Research on Concepts and Cognition. Douglas, by the way, is one of the most legendary figures in the AI space. We also had the pleasure of interviewing one of his other PhD students, Professor Melanie Mitchell. Now, David recently wrote this fascinating book called Reality Plus. In that book, he discussed the three central philosophical questions, actually. The reality question, which is to say, are virtual worlds real? His answer to that is yes. The knowledge question, which is to say, can we know whether or not we're in a virtual world? His answer to that is no. Also, the value question, which is to say, can you lead a good life in a virtual world? And his answer to that is a resounding yes. Now, you probably also heard of this notion of an extended mind, something which David formulated with Professor Andy Clark, and they described the idea as active externalism, based on the active role of the environment in driving cognitive processes, or put simply, you might think of your phone as being an extension of your mind, for example. What was it like to work with Douglas during your PhD? Oh, he was great. He was so interested in so many things. It was officially, it was an AI lab, and most of the people there were AI researchers. You mentioned Melanie Mitchell. She was my colleague there. Bob French, who's done important work on AI, Gary McGraw, Jim Marshall, Wong-Pay, and others. I was the only philosopher. People were interested in so many things, whether it was, we had workshops on humor, or creativity, on mathematics, on politics, on everything, as well as all the stuff on AI, analogy, concepts. It was also a very exciting time to be there, because this was one of the, in the boom and bust cycle of machine learning and of neural networks. This was one of the boom periods, the early 1990s. The PDP books had just come out, parallel distributed processing by Rubble Hart, McClelland, and Hinton. There was so much excitement about the capacities of neural networks. I ended up writing a few papers on machine learning back then. One was on the evolution of learning systems. One was on getting machines to learn structural generalizations. All with fairly basic neural networks. A few years after that, the bottom fell out of neural networks for another 15 years or so, but this was a very exciting period to be there. One thing about Doug that you don't quite get from his books, his books, he's so enthusiastic about everything. He's not into all these ideas and so on, but it turns out there's 5% of things in the world or 1% that he's enthusiastic about. The other 99% he hates. He's like, he likes certain approaches to AI he loved, but even neural networks, he was like, he was not a big fan of most research in neural networks back then. He said, I think it was a, this is a bandwagon or even he said a bad wagon. Likewise for philosophy, there's bits of philosophy he loves. There's a lot of it. There's a lot of it he doesn't like. So maybe in person, you get more of a, more of that very opinionated side, but really he's a, he's just, you know, that book Go to Lesha Bark was just, I mean, it was what drew me into philosophy and AI as a teenager and it's so rich. And you go back to that book, there's still so many ideas there. The Mind's Eye is another book he edited with Dan Dennett. It was reading the Mind's Eye that really first got me thinking about issues about consciousness and the mind-body problem. So yeah, he's a very rich thinker. Yeah. Well, thank God for Douglas Tostata. Yeah, I love the Mind's Eye. It has one of the, one of the eeriest stories of all. What was it? The riddle of the universe and its solution where there's, there's some image or some text that if you read it, it causes your brain basically to core dump. And so it becomes this infectious thing where anybody who goes into that office and reads that thing, they just crash and they never, they go into a coma and they never wake up again. And so, you know, there's a huge investigation to figure out what's going on and more and more people keep going into comas, you know, because of this crazy ideas in that book. Could I just pick up on this point because you were saying that Douglas Tostata turned his nose up at Neural Networks. And I hope he still would actually, and Melanie Mitchell certainly does. And I mean, Douglas had that paper out called The Core of Cognition. He was always huge about this idea of the primacy of analogy making. And actually, there's a few researchers today that are mirroring that, that idea that Francois Chollet, for example, he says intelligence is literally sensitivity to abstract analogies. It's not memorizing the internet. So I think, thank God that we do have people out there thinking slightly differently because the modus operandi today is that we need to build a big hash table of everything. And even the way we formalize intelligence, as we were just saying previously, we're not really paying attention to why or how the things do what they do. We're just looking at the behavioral output bit like the Turing test, as long as it looks and smells like a duck, then it must be a duck. So thank God for Douglas Tostata. Yeah, I think he's always been at the same time an enthusiast about the possibility of AI while being somewhat skeptical about the capacities of existing AI and about the kind of hype that suggests that AI might just be 10 or 20 years around the corner. So in the early 90s, I think, yeah, that was, that was especially, especially natural. Back around then, people would say a year spent working in AI is enough to make you believe in God. It was so hard to get anything even like any kind of intelligence out of an AI system. And I think, you know, Doug was equally skeptical of both the symbolic and the connectionist on neural network approaches back then. I think ultimately his sympathies lay with it on the neural network side of things, with the idea that intelligence could in principle bubble up from a million, you know, from 100 billion separate little interactions, intelligence could bubble up from there. But I still think he'd be inclined to think that current approaches are too statistical, too simple, and so on. That said, you have to look at the, at the progress in machine learning over the last 10 years. And it's been amazing and surprising. And I think even somebody like, even people like Melanie or like Doug are going to have to say this has been something they did not expect. And that they did not predict. So I actually, I was back in Indiana just over two years ago, just before the pandemic got going February 2020. And I don't know, maybe that was before GBT three, but still there've been all these amazing developments in machine learning over the last few years. I asked Doug about this, and what do you make of this? And because he's on the record of saying, you know, there will be AI eventually, but it's going to have to be involve all these new kinds of complexity, not not something simple like this. And he says, Yeah, well, this is, this is troubling. This is concerning, you know, it could be, I don't know yet, but it could be that I was wrong. It could be there are simpler passes, paths to AI. And his attitude was that would be very disappointing. It turned out that you could actually train up an AGI, just using those simple methods to human levels. That would make, I think Doug's view was that would make kind of human level intelligence less, less grand and remarkable than, than he had thought. Well, actually, back in, back in Goethe-les-Sherbach, I think he said that even to have a machine that could beat a human at chess, it would have to be good at everything would be a good composer, it could tell jokes and so on. Okay, that one, that view got rolled out back in the, back in the 90s. So the question is, you know, is this, is this ever growing progress of just, of the kind of machine learning that says just throw a whole lot of compute, and a whole lot of data at it, and see what happens. Is that eventually going to get us to human level intelligence? Or is it, is it just going to get us so far with, and there's going to be principled limitations? I've always been on the side of, they'll probably only get us so far. But I have to say those principled limitations, those obstacles that have not yet been conquered are getting smaller and smaller. And the progress, if the progress of the last five or 10 years continues for another five or 10 years, then who's to say what's going to be left? Yeah, there was a fascinating anecdote in, in Melanie's book about how she and Hofstadter went to the Googleplex one time. And basically, as you said, Douglas was terrified that intelligence might be disappointingly simple to mechanize because he felt of the mind of Chopin as being infinitely nuanced. And just, just the incredible process that must have gone through his mind when he, when he produced his music. But I wanted to, and just quickly, by the way, you said that there was a conception in, in the 70s that task specific skill was what was required for intelligence or a collection of, of specific skills. And, and now the mindset is much more towards task acquisition efficiency and generalization. But I wanted to just quickly pick you up on the so-called intelligence explosion question. So this is a subject which Nick Bostrom has popularized after his book, Superintelligence. Personally speaking, we're not particularly sympathetic to this view. And Saigre Francois-Labe, he said in a blog post recently that this line of reasoning represents a misunderstanding of intelligence. He said that in his opinion, intelligence is situational. He said that our environment puts a hard limit on our individual intelligences. He said that most of our intelligence is not in the brain, it's externalized as civilization. And that an individual brain cannot implement recursive intelligence augmentation like a Godel machine. He also said that there are already many examples of recursively self-improving systems. Even personal investing, for example, is a recursively self-improving system. The more money you have, the more money you make. Anyway, so Bostrom described a thought experiment in 2003. I'm sure you've heard of this. The scenario describes an artificial, you know, like a very advanced artificial intelligence task with manufacturing paper clips. If such a machine were not programmed to value human life, then given enough power over its environment, it would try to turn all the matter in the universe, including human beings, into paper clips or machines which could manufacture paper clips. Do you think we might be on the precipice of being turned into paper clips, as Bostrom famously described in his thought experiment? Yeah, look, it's there's two different issues here. One is, will we get to some kind of much greater than human superintelligence relatively soon by some kind of intelligence explosion process? And second, if that happens, are there major dangers around? Yeah, I wrote about both of these things back in 2009. I had an article called, yeah, the Singularity of Philosophical Analysis, where I tried to take this line of reasoning for an intelligence explosion through recursive, through basically through recursive design of ever more sophisticated AIs. I tried to take that and turn it into an argument. I mean, the classic statement of this comes from I.J. Goode, the statistician and philosopher back in 1965 on the design of an ultra intelligent machine where he puts the basic idea right there that once you've got a machine which is smarter than a human, it will be able to design a machine which is smarter still, and then you're going to get recursive, runaway explosion of intelligence. I tried to analyze that to set out that article, that argument in as much detail as I could, analyze where it could go right, where it could go wrong, what the possible obstacles would be, and it's a long story. If anyone wants to look it up, it's out there on my website. But I in the end became convinced this is a pretty powerful argument. There's only so many ways it could go wrong. I think it's important that not every recursive augmentation process is going to lead to an intelligence explosion. It could easily bottom out, could asymptote before human intelligence. But I do think that once we start from greater than human intelligence, we have to find some way to get to greater than human intelligence first. This explosion won't get you that. But once you get there, then there's pretty good reason to think things in principle can take off from there. If intelligence is extended, I'm a big fan of the idea that intelligence is extended into the environment. But as far as I can tell, all that can in principle be augmented too. We develop extended systems, which are smarter than humans, and then they'll be able to design even better extended systems. And we could then have an intelligence explosion of extended intelligences. So I'm actually, nothing about this gets you to human level intelligence. But once we get to human level intelligence and a little bit beyond, then I think there's a pretty good case that there's some kind of potential explosion in the offing. Then the other issue you mentioned Bostrom and the paper clips is, yeah, what does this mean for the future of humanity? I guess I don't know what I'd say about the probabilities, but I'd say, yeah, once you have greater than human artificial general intelligence, then there's many ways that can go wrong for the obvious reasons that such a being is going to be extremely powerful. The most intelligent beings in the universe tend to be the most powerful for obvious reasons. Whatever they want, they have the capacity to get. So it's going to be extremely important that our AGI systems want the right things. That is, they have the right kind of goals. Or as people put it, these days that they are aligned with human goals. Because if they're even a little bit misaligned, then there's going to be the capacity for things to go very badly wrong. I know there are some people who think that the alignment is going to have to be so precise that, you know, missed by just the tiniest bit and will destroy the universe, whereas others think it's extremely robust. It may be more robust than that. I'm not totally sure about that. But I'm certainly on the side of people who think we have to take this issue extremely seriously. And there is at least potential existential risks here that if AGI is produced in an unthinking way, perhaps say in a military or a financial context where there's an AI arms race, and we suddenly have greater than human AIs that can achieve arbitrary goals, then suddenly it becomes an extremely sensitive matter what their goals are. So I'm certainly on Bostrom's side when it comes to, yeah, this is something we should take seriously. But isn't there a bit of, you know, it's a big distance to go from superior to human intelligence and achieve anything you want. I mean, I'm relatively intelligent, but I can't achieve flight, you know, by myself without, you know, apparatus to do that and airplane wings, whatever. I mean, there are physical limitations in the world. And I think sometimes there's this assumption that intelligence can kind of go to infinity, where in fact, maybe intelligence itself kind of bottoms out at IQ 1000 or something, there's just not much, you know, you can do beyond that certain IQ. I mean, isn't there a degree of kind of speculative, you know, extrapolation that we need to account for there? I would say this is certainly one way that things could, that the argument could fail, is if it turns out that basically there are diminishing, there's some kind of intelligence ceiling, and there's some kind of diminishing returns towards this. Just there is such a ceiling that we might find that when we make a being which is 10% smarter than us on some scale, it could only make a being which is 5% smarter than it. And that being will make a machine, make a being which is only 2.5% smarter than it. And all this will kind of asymptote to some intelligence ceiling. And I don't know, this turns on very subtle issues about the structure of intelligence space. I'm rather doubtful there is such an intelligence ceiling, or if there is one, maybe it's something like, you know, the limits of computability compared to, you know, hypercomputation that an infinite system could do. But I think that ceiling is so high that there's room for an awful lot of super intelligence before we get there. But in any case, I would say that, you know, for the purposes of, say, caution and thinking about the future, I would just turn the point back on you and say that the thought that there is such an intelligence ceiling is itself an extremely speculative one. I wouldn't want to rely on this, on this extremely speculative thought to kind of protect us from, from the, you know, potential risks of AGI in the future. If there's only a 20% chance there's not such an intelligence ceiling, then this is something that we very much need to be, to be worrying about. Yeah, I mean, fair enough, it's certainly a risk factor. It's certainly something that we need to need to keep a handle on. Well, let me ask you about one specific time there. So I'm thinking you're probably familiar with Carl Friston and, you know, his free energy principle. And he sends his regards, by the way, we talked to him a couple weeks back. And, and he wanted to ask you about kind of one line of thinking that he's been exploring lately. And I want to give you a quote from his 2018 article and my self conscious, or does self organization entail self consciousness. And he said, the proposal on offer here is that the mind comes into being when self evidencing has a temporal thickness, or counterfactual depth, which grounds inferences about the consequences of my action. On this view, consciousness is nothing more than the inference about my future, namely, self evidencing consequences of what I could do. What do you think about that, that perspective? Yeah, I'd have to know more about the connection to consciousness. I know that yeah, Friston is very has developed very deeply the idea of the mind as a prediction machine, a mind which is basically set up to, you know, predict whatever signal is coming next. And that's with that one basic key loss, you know, predict what's next, what's next, what's next, then you get to build these amazing models of the world with all of these, all of these, these capacities. And that's a really interesting perspective thinking about the mind and intelligence in general. And it's got to be at least one huge part of the story, even if it's not the whole story as Friston thinks it is, but I've never really understood the distinct what this kind of predictive approach has to say distinctively about consciousness. Because presumably there's a whole lot of different predictive processes at all kinds of levels of the hierarchy, including at the very early vision and very late cognition, and the whole mind is engaged in coming up with these predictions, but only some limited part of it is conscious. What you just said about, yeah, trying to figure out the predictions consequent on our actions, sounds to me like a very general statement of what the predictive approach says about the mind in general. And I haven't yet heard what is the part that corresponds to consciousness. Why, for example, or some representations get to be conscious where so much of it in the brain is not, I can give you I can give you a bit more detail, which may be helpful, because we did dig into him with a on a bit. And he said, for one thing, he expected that perhaps part of your response might might entail or talk about the meta hard problem. You know, why is it that certain beings, i.e. things like philosophers, and people like you and me puzzle so much about our qualitative experience. And the argument he makes there, he says that if we are inference machines that are built to actively self evidence, then that necessarily entails we need to have a generative model about our experienced world. And if we have that that generative model about our experience world, our experience world, then we have to entertain the hypothesis that we are things having a qualitative experience, along with the alternate to that hypothesis, which is that we're not having qualitative experiences. And so essentially that the capability to model the world generatively really requires that we entertain this hypothesis that we're actually having qualitative experiences or maybe not. And that's why we pontificate about it. Yeah, it's interesting. And I think the meta problem is a, yeah, as a promising approach is the meta problem is your why do we say and think the things we do about consciousness, instead of explaining consciousness directly, let's explain, you know, our internal model of consciousness. And yeah, there's got to be such a model. So I think this is a promising approach to take. I still don't fully, I mean, I think if you take the predictive approach, so what you would expect is, is the system would have many different models, you know, a big complex model of the world at all levels, it doesn't just correspond to experienced reality, but the models the world way beyond what's experienced, it would also you'd also expect the model to have a model of the mind to have a model of ourselves and relation to the world. But what actually happens in the in the human mind is we have, we have models at all levels, you know, there's like so many different levels of say of representation, even in the visual hierarchy. And somehow, though, only one of those levels seems to correspond to consciousness. The question is, why now do we need a distinctive model of those representations in us, which correspond to conscious experience? One idea, I think, one idea I quite like is that this could be like a simplification. In fact, we have millions of layers of representation of the world. But to build all that into our model of ourselves, and our relation of the world is going to be too complex. So we basically, we oversimplify by saying, ah, there's this one special relationship we have to the world, we call it consciousness or experience. And yet we experience certain things and then we use them to reason about them. And this is massively oversimplified as a model of the mind. But it could be that that simplification is then what actually gives us the sense that we have this special thing called consciousness. At least maybe that could explain why it seems to us that we have some special representations of the world. It's a further question why those conscious representations should seem to be so ineffable and subjective and hard to explain. And what in what Carl has written about this, I think he and Andy Clark had some ideas about the meta problem to try and push on this. Maybe that maybe there'd be certain representations that we'd have to be especially certain that we have them. Maybe that would give rise to the Descartes idea that, well, I'm not sure about the world, but I know that I'm thinking. I think, therefore, I am. And they had some kind of story about how this could get the whole, I think, therefore, I am certainty in one's own mind going. Anyway, I think it's an interesting approach and I'll be very cool to see if they can develop it further. Fascinating. I wanted to dig into this modeling thing. I was even thinking a second ago when you were talking about intelligence, that straight away you did the Hutter thing and we're talking about agents performing in environments and so on. And even that is a model. And of course, we're talking about complex phenomena and the way we model things depends on the level of analysis. But I'm really fascinated by this idea that some phenomena is so complex that it cannot be formalized or communicated, almost as if there's a representation problem. Now, you discussed in your consciousness book whether consciousness itself could be reductively explained and your knowledge argument, you spoke of this neuroscientist Mary that had been brought up in a black and white room. She's never seen any colors except for black and white and shades of gray. She's nevertheless one of the world's leading neuroscientists specializing in neurophysiology of color vision. She knows everything there is to know about neural processes involved in visual information processing, about the physics of optical processes, about the physical makeup of objects in the environment. But she doesn't know what it's like to see red. No amount of reasoning from physical facts alone will give her this knowledge. Physical facts about systems do not tell us what their conscious experiences are like. Now, you're speaking about this phenomenon in respect of the conscious or the phenomenological experience. But I think it's a much bigger problem of representation with any complex system, right? So what I find fascinating is that all of us have a conscious experience, but it's completely ineffable, as you just said, it's impossible for us to communicate it to others. And whenever we try to do so, we're reaching, right? Just like the blind men in the elephant, we end up defining some weird abstract motif, right? Chopping off 90% of the truth. The thing that fascinates me is that we need to have some kind of formalism or reduction in order to communicate, you know, in order to know or even understand anything. But so often is the case that all of the nuance and richness of the phenomena is lost in doing so. So I suspect that any formalism of a complex system might blind us from discovering a much better and richer formalism later because it kind of frames our thinking in quite a pernicious way in your book. So as I said, you were trying to separate the phenomenological experience as something that couldn't be described. But do you think it could be extended to any complex system? Well, we don't. As far as we know, you know, some complex systems actually have conscious subjective experience. But, you know, most of them don't. You know, this Mac that I'm using right now is a very complex system, but not much reason to think that it's conscious despite the complexity of what's going on within it. So certain kinds of complexity go along with consciousness. But if we were to kind of return to that meta problem approach for a moment, maybe there are certain kinds of properties of a complex system that tend to produce reports, for example, that the system is conscious. So maybe some complex systems have the capacity for a certain kind of direct self-modeling that corresponds to what we think of as introspection. We have introspection, which is a way of saying, this is what I'm perceiving right now. This is what I'm thinking right now. This is what I'm feeling right now. And we build a model of ourselves, and it may well be that that model is highly oversimplified. You don't have access to all these facts about ourselves. So perhaps you could tell a story where the kinds of complex systems that give rise at least to this capacity for introspection are then at least going to report themselves as being conscious. And maybe that could get at some element, maybe sort of the ineffability of consciousness. You'd expect to build these very simplified self-models. We wouldn't know immediately how to extend to other people. I mean, I still think, in principle, you could take Mary, who knows all about the human brain, and she could come to know all about those models in other people. But it still seems that she's never actually experienced red for herself. There's still something really crucial about this objective experience that she doesn't know. She doesn't know what it's like to experience red, and knowing all about the details of the model still hasn't told her that. So I think that's still something that needs explaining. Some people at this point just say that sense of something extra is an illusion. Something extra that the model hasn't explained is an illusion. But that's really where a lot of the action is at then. Just quickly, do you think there could be a sense of something extra to intelligence, as well as consciousness? Probably, yeah, we model our own intelligence with massively oversimplified self-models that were programmed into us by nature that model us as these agents with incredible capacities, free will, rationality, reason. It probably, again, it will, yeah, maybe I talked about consciousness is involving the subjective elements, intelligence is involving the objective elements. But yeah, we probably have oversimplified models of those conscious of those behavioral elements as well, perhaps that make us out to be more rational, or more free, or more capable than we actually are. I wanted to ask, what is an interesting simulation? Is our universe interesting or not? Because we represent just a pinprick of intelligence. So should intelligence be more spread out in the eyes of the simulator? Or in the vast majority of instances, would there just be gas everywhere or a singularity? Maybe stars can't form. Maybe the interesting phenomena itself is on the boundary between chaos and order, or between order and disorder, I should say, which is just a tiny sliver. So what do you think makes an interesting simulation? I don't know. I think it probably depends on your perspective, and it might, for example, depend on the perspective of the simulators, what they're after. One thing that a simulator might be doing is just create a whole lot of different universes with different potential laws of physics that they're simulating just to see what happens. And maybe if they're interested in, say, life or intelligence, then it could be that they're going to find that, okay, well, 99% of these simulations don't produce anything like life or intelligence. And yeah, 1% of them produce life, and 0.01% lead to intelligence. So if that's what they're interested in, in studying, fantastic. But they might be interested in who's to say the laws of physics or galaxy formation, more generally, totally independent of life and intelligence. So I don't think there's any single standard of what's interesting. I mean, to me, as a philosopher interested in consciousness, I'm especially interested in this question of what kinds of simulations might actually develop conscious beings within them, not least because that's going to be especially relevant to our situation. If we're in a simulation, it seems we're conscious. So there's a question about just how this kind of simulation might get set up. But I think this whole, I mean, already simulations are used in actual practice for a million different purposes by scientists studying this phenomenon or that phenomenon, by people doing entertainment, by people doing prediction of the future, by people doing simulation of the past. And I guess when it comes to simulated universes, all of those sources of interest may themselves be present.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.68, "text": " He moved to Indiana University in 1989, where he obtained his PhD in philosophy and cognitive", "tokens": [50364, 634, 4259, 281, 21858, 3535, 294, 22427, 11, 689, 415, 14879, 702, 14476, 294, 10675, 293, 15605, 50648], "temperature": 0.0, "avg_logprob": -0.10629068480597602, "compression_ratio": 1.58843537414966, "no_speech_prob": 0.016827352344989777}, {"id": 1, "seek": 0, "start": 5.68, "end": 11.36, "text": " science, working for the legendary Douglas Hofstadter, by the way. I've got his book here", "tokens": [50648, 3497, 11, 1364, 337, 264, 16698, 23010, 37379, 48299, 391, 11, 538, 264, 636, 13, 286, 600, 658, 702, 1446, 510, 50932], "temperature": 0.0, "avg_logprob": -0.10629068480597602, "compression_ratio": 1.58843537414966, "no_speech_prob": 0.016827352344989777}, {"id": 2, "seek": 0, "start": 11.36, "end": 16.88, "text": " in the Center for Research on Concepts and Cognition. Douglas, by the way, is one of the most", "tokens": [50932, 294, 264, 5169, 337, 10303, 322, 47482, 82, 293, 383, 2912, 849, 13, 23010, 11, 538, 264, 636, 11, 307, 472, 295, 264, 881, 51208], "temperature": 0.0, "avg_logprob": -0.10629068480597602, "compression_ratio": 1.58843537414966, "no_speech_prob": 0.016827352344989777}, {"id": 3, "seek": 0, "start": 16.88, "end": 21.36, "text": " legendary figures in the AI space. We also had the pleasure of interviewing one of his other", "tokens": [51208, 16698, 9624, 294, 264, 7318, 1901, 13, 492, 611, 632, 264, 6834, 295, 26524, 472, 295, 702, 661, 51432], "temperature": 0.0, "avg_logprob": -0.10629068480597602, "compression_ratio": 1.58843537414966, "no_speech_prob": 0.016827352344989777}, {"id": 4, "seek": 0, "start": 21.36, "end": 27.12, "text": " PhD students, Professor Melanie Mitchell. Now, David recently wrote this fascinating book called", "tokens": [51432, 14476, 1731, 11, 8419, 42798, 27582, 13, 823, 11, 4389, 3938, 4114, 341, 10343, 1446, 1219, 51720], "temperature": 0.0, "avg_logprob": -0.10629068480597602, "compression_ratio": 1.58843537414966, "no_speech_prob": 0.016827352344989777}, {"id": 5, "seek": 2712, "start": 27.12, "end": 34.96, "text": " Reality Plus. In that book, he discussed the three central philosophical questions, actually.", "tokens": [50364, 33822, 7721, 13, 682, 300, 1446, 11, 415, 7152, 264, 1045, 5777, 25066, 1651, 11, 767, 13, 50756], "temperature": 0.0, "avg_logprob": -0.07851327226517048, "compression_ratio": 1.86, "no_speech_prob": 0.013424183242022991}, {"id": 6, "seek": 2712, "start": 34.96, "end": 40.32, "text": " The reality question, which is to say, are virtual worlds real? His answer to that is yes.", "tokens": [50756, 440, 4103, 1168, 11, 597, 307, 281, 584, 11, 366, 6374, 13401, 957, 30, 2812, 1867, 281, 300, 307, 2086, 13, 51024], "temperature": 0.0, "avg_logprob": -0.07851327226517048, "compression_ratio": 1.86, "no_speech_prob": 0.013424183242022991}, {"id": 7, "seek": 2712, "start": 40.96, "end": 45.6, "text": " The knowledge question, which is to say, can we know whether or not we're in a virtual world?", "tokens": [51056, 440, 3601, 1168, 11, 597, 307, 281, 584, 11, 393, 321, 458, 1968, 420, 406, 321, 434, 294, 257, 6374, 1002, 30, 51288], "temperature": 0.0, "avg_logprob": -0.07851327226517048, "compression_ratio": 1.86, "no_speech_prob": 0.013424183242022991}, {"id": 8, "seek": 2712, "start": 45.6, "end": 53.44, "text": " His answer to that is no. Also, the value question, which is to say, can you lead a good life", "tokens": [51288, 2812, 1867, 281, 300, 307, 572, 13, 2743, 11, 264, 2158, 1168, 11, 597, 307, 281, 584, 11, 393, 291, 1477, 257, 665, 993, 51680], "temperature": 0.0, "avg_logprob": -0.07851327226517048, "compression_ratio": 1.86, "no_speech_prob": 0.013424183242022991}, {"id": 9, "seek": 5344, "start": 53.44, "end": 59.28, "text": " in a virtual world? And his answer to that is a resounding yes. Now, you probably also heard", "tokens": [50364, 294, 257, 6374, 1002, 30, 400, 702, 1867, 281, 300, 307, 257, 725, 24625, 2086, 13, 823, 11, 291, 1391, 611, 2198, 50656], "temperature": 0.0, "avg_logprob": -0.08280559134694328, "compression_ratio": 1.6174496644295302, "no_speech_prob": 0.003473847871646285}, {"id": 10, "seek": 5344, "start": 59.28, "end": 64.8, "text": " of this notion of an extended mind, something which David formulated with Professor Andy Clark,", "tokens": [50656, 295, 341, 10710, 295, 364, 10913, 1575, 11, 746, 597, 4389, 48936, 365, 8419, 13285, 18572, 11, 50932], "temperature": 0.0, "avg_logprob": -0.08280559134694328, "compression_ratio": 1.6174496644295302, "no_speech_prob": 0.003473847871646285}, {"id": 11, "seek": 5344, "start": 64.8, "end": 71.36, "text": " and they described the idea as active externalism, based on the active role of the environment in", "tokens": [50932, 293, 436, 7619, 264, 1558, 382, 4967, 8320, 1434, 11, 2361, 322, 264, 4967, 3090, 295, 264, 2823, 294, 51260], "temperature": 0.0, "avg_logprob": -0.08280559134694328, "compression_ratio": 1.6174496644295302, "no_speech_prob": 0.003473847871646285}, {"id": 12, "seek": 5344, "start": 71.36, "end": 76.4, "text": " driving cognitive processes, or put simply, you might think of your phone as being an extension", "tokens": [51260, 4840, 15605, 7555, 11, 420, 829, 2935, 11, 291, 1062, 519, 295, 428, 2593, 382, 885, 364, 10320, 51512], "temperature": 0.0, "avg_logprob": -0.08280559134694328, "compression_ratio": 1.6174496644295302, "no_speech_prob": 0.003473847871646285}, {"id": 13, "seek": 5344, "start": 76.4, "end": 81.68, "text": " of your mind, for example. What was it like to work with Douglas during your PhD? Oh, he was great.", "tokens": [51512, 295, 428, 1575, 11, 337, 1365, 13, 708, 390, 309, 411, 281, 589, 365, 23010, 1830, 428, 14476, 30, 876, 11, 415, 390, 869, 13, 51776], "temperature": 0.0, "avg_logprob": -0.08280559134694328, "compression_ratio": 1.6174496644295302, "no_speech_prob": 0.003473847871646285}, {"id": 14, "seek": 8168, "start": 81.68, "end": 91.2, "text": " He was so interested in so many things. It was officially, it was an AI lab, and most of the", "tokens": [50364, 634, 390, 370, 3102, 294, 370, 867, 721, 13, 467, 390, 12053, 11, 309, 390, 364, 7318, 2715, 11, 293, 881, 295, 264, 50840], "temperature": 0.0, "avg_logprob": -0.15964988951987408, "compression_ratio": 1.5913043478260869, "no_speech_prob": 0.0038167762104421854}, {"id": 15, "seek": 8168, "start": 91.2, "end": 96.64000000000001, "text": " people there were AI researchers. You mentioned Melanie Mitchell. She was my colleague there.", "tokens": [50840, 561, 456, 645, 7318, 10309, 13, 509, 2835, 42798, 27582, 13, 1240, 390, 452, 13532, 456, 13, 51112], "temperature": 0.0, "avg_logprob": -0.15964988951987408, "compression_ratio": 1.5913043478260869, "no_speech_prob": 0.0038167762104421854}, {"id": 16, "seek": 8168, "start": 96.64000000000001, "end": 104.80000000000001, "text": " Bob French, who's done important work on AI, Gary McGraw, Jim Marshall, Wong-Pay, and others.", "tokens": [51112, 6085, 5522, 11, 567, 311, 1096, 1021, 589, 322, 7318, 11, 13788, 21865, 5131, 11, 6637, 17279, 11, 41638, 12, 47, 320, 11, 293, 2357, 13, 51520], "temperature": 0.0, "avg_logprob": -0.15964988951987408, "compression_ratio": 1.5913043478260869, "no_speech_prob": 0.0038167762104421854}, {"id": 17, "seek": 8168, "start": 105.76, "end": 109.92000000000002, "text": " I was the only philosopher. People were interested in so many things, whether it was,", "tokens": [51568, 286, 390, 264, 787, 29805, 13, 3432, 645, 3102, 294, 370, 867, 721, 11, 1968, 309, 390, 11, 51776], "temperature": 0.0, "avg_logprob": -0.15964988951987408, "compression_ratio": 1.5913043478260869, "no_speech_prob": 0.0038167762104421854}, {"id": 18, "seek": 10992, "start": 110.64, "end": 119.92, "text": " we had workshops on humor, or creativity, on mathematics, on politics, on everything,", "tokens": [50400, 321, 632, 19162, 322, 14318, 11, 420, 12915, 11, 322, 18666, 11, 322, 7341, 11, 322, 1203, 11, 50864], "temperature": 0.0, "avg_logprob": -0.11655710745548857, "compression_ratio": 1.5280898876404494, "no_speech_prob": 0.0005351168802008033}, {"id": 19, "seek": 10992, "start": 119.92, "end": 126.8, "text": " as well as all the stuff on AI, analogy, concepts. It was also a very exciting time to be there,", "tokens": [50864, 382, 731, 382, 439, 264, 1507, 322, 7318, 11, 21663, 11, 10392, 13, 467, 390, 611, 257, 588, 4670, 565, 281, 312, 456, 11, 51208], "temperature": 0.0, "avg_logprob": -0.11655710745548857, "compression_ratio": 1.5280898876404494, "no_speech_prob": 0.0005351168802008033}, {"id": 20, "seek": 10992, "start": 126.8, "end": 137.44, "text": " because this was one of the, in the boom and bust cycle of machine learning and of neural", "tokens": [51208, 570, 341, 390, 472, 295, 264, 11, 294, 264, 9351, 293, 19432, 6586, 295, 3479, 2539, 293, 295, 18161, 51740], "temperature": 0.0, "avg_logprob": -0.11655710745548857, "compression_ratio": 1.5280898876404494, "no_speech_prob": 0.0005351168802008033}, {"id": 21, "seek": 13744, "start": 137.44, "end": 144.24, "text": " networks. This was one of the boom periods, the early 1990s. The PDP books had just come out,", "tokens": [50364, 9590, 13, 639, 390, 472, 295, 264, 9351, 13804, 11, 264, 2440, 13384, 82, 13, 440, 10464, 47, 3642, 632, 445, 808, 484, 11, 50704], "temperature": 0.0, "avg_logprob": -0.11149503873742145, "compression_ratio": 1.5614754098360655, "no_speech_prob": 0.00425428943708539}, {"id": 22, "seek": 13744, "start": 144.24, "end": 151.35999999999999, "text": " parallel distributed processing by Rubble Hart, McClelland, and Hinton. There was so much excitement", "tokens": [50704, 8952, 12631, 9007, 538, 10518, 638, 21414, 11, 12061, 306, 285, 474, 11, 293, 389, 12442, 13, 821, 390, 370, 709, 14755, 51060], "temperature": 0.0, "avg_logprob": -0.11149503873742145, "compression_ratio": 1.5614754098360655, "no_speech_prob": 0.00425428943708539}, {"id": 23, "seek": 13744, "start": 151.35999999999999, "end": 159.12, "text": " about the capacities of neural networks. I ended up writing a few papers on machine learning", "tokens": [51060, 466, 264, 39396, 295, 18161, 9590, 13, 286, 4590, 493, 3579, 257, 1326, 10577, 322, 3479, 2539, 51448], "temperature": 0.0, "avg_logprob": -0.11149503873742145, "compression_ratio": 1.5614754098360655, "no_speech_prob": 0.00425428943708539}, {"id": 24, "seek": 13744, "start": 159.12, "end": 164.72, "text": " back then. One was on the evolution of learning systems. One was on getting machines to learn", "tokens": [51448, 646, 550, 13, 1485, 390, 322, 264, 9303, 295, 2539, 3652, 13, 1485, 390, 322, 1242, 8379, 281, 1466, 51728], "temperature": 0.0, "avg_logprob": -0.11149503873742145, "compression_ratio": 1.5614754098360655, "no_speech_prob": 0.00425428943708539}, {"id": 25, "seek": 16472, "start": 165.35999999999999, "end": 174.07999999999998, "text": " structural generalizations. All with fairly basic neural networks. A few years after that,", "tokens": [50396, 15067, 2674, 14455, 13, 1057, 365, 6457, 3875, 18161, 9590, 13, 316, 1326, 924, 934, 300, 11, 50832], "temperature": 0.0, "avg_logprob": -0.14784387524208326, "compression_ratio": 1.605263157894737, "no_speech_prob": 0.0012225054670125246}, {"id": 26, "seek": 16472, "start": 174.07999999999998, "end": 179.76, "text": " the bottom fell out of neural networks for another 15 years or so, but this was a very", "tokens": [50832, 264, 2767, 5696, 484, 295, 18161, 9590, 337, 1071, 2119, 924, 420, 370, 11, 457, 341, 390, 257, 588, 51116], "temperature": 0.0, "avg_logprob": -0.14784387524208326, "compression_ratio": 1.605263157894737, "no_speech_prob": 0.0012225054670125246}, {"id": 27, "seek": 16472, "start": 179.76, "end": 184.48, "text": " exciting period to be there. One thing about Doug that you don't quite get from his books,", "tokens": [51116, 4670, 2896, 281, 312, 456, 13, 1485, 551, 466, 12742, 300, 291, 500, 380, 1596, 483, 490, 702, 3642, 11, 51352], "temperature": 0.0, "avg_logprob": -0.14784387524208326, "compression_ratio": 1.605263157894737, "no_speech_prob": 0.0012225054670125246}, {"id": 28, "seek": 16472, "start": 186.72, "end": 191.28, "text": " his books, he's so enthusiastic about everything. He's not into all these ideas and so on, but it", "tokens": [51464, 702, 3642, 11, 415, 311, 370, 28574, 466, 1203, 13, 634, 311, 406, 666, 439, 613, 3487, 293, 370, 322, 11, 457, 309, 51692], "temperature": 0.0, "avg_logprob": -0.14784387524208326, "compression_ratio": 1.605263157894737, "no_speech_prob": 0.0012225054670125246}, {"id": 29, "seek": 19128, "start": 191.28, "end": 198.0, "text": " turns out there's 5% of things in the world or 1% that he's enthusiastic about. The other 99% he hates.", "tokens": [50364, 4523, 484, 456, 311, 1025, 4, 295, 721, 294, 264, 1002, 420, 502, 4, 300, 415, 311, 28574, 466, 13, 440, 661, 11803, 4, 415, 23000, 13, 50700], "temperature": 0.0, "avg_logprob": -0.15313282579478651, "compression_ratio": 1.5982532751091703, "no_speech_prob": 0.00027319390210323036}, {"id": 30, "seek": 19128, "start": 200.4, "end": 207.04, "text": " He's like, he likes certain approaches to AI he loved, but even neural networks, he was like,", "tokens": [50820, 634, 311, 411, 11, 415, 5902, 1629, 11587, 281, 7318, 415, 4333, 11, 457, 754, 18161, 9590, 11, 415, 390, 411, 11, 51152], "temperature": 0.0, "avg_logprob": -0.15313282579478651, "compression_ratio": 1.5982532751091703, "no_speech_prob": 0.00027319390210323036}, {"id": 31, "seek": 19128, "start": 208.16, "end": 215.52, "text": " he was not a big fan of most research in neural networks back then. He said,", "tokens": [51208, 415, 390, 406, 257, 955, 3429, 295, 881, 2132, 294, 18161, 9590, 646, 550, 13, 634, 848, 11, 51576], "temperature": 0.0, "avg_logprob": -0.15313282579478651, "compression_ratio": 1.5982532751091703, "no_speech_prob": 0.00027319390210323036}, {"id": 32, "seek": 19128, "start": 215.52, "end": 220.56, "text": " I think it was a, this is a bandwagon or even he said a bad wagon. Likewise for philosophy,", "tokens": [51576, 286, 519, 309, 390, 257, 11, 341, 307, 257, 4116, 86, 6709, 420, 754, 415, 848, 257, 1578, 34453, 13, 30269, 337, 10675, 11, 51828], "temperature": 0.0, "avg_logprob": -0.15313282579478651, "compression_ratio": 1.5982532751091703, "no_speech_prob": 0.00027319390210323036}, {"id": 33, "seek": 22056, "start": 220.56, "end": 224.32, "text": " there's bits of philosophy he loves. There's a lot of it. There's a lot of it he doesn't like.", "tokens": [50364, 456, 311, 9239, 295, 10675, 415, 6752, 13, 821, 311, 257, 688, 295, 309, 13, 821, 311, 257, 688, 295, 309, 415, 1177, 380, 411, 13, 50552], "temperature": 0.0, "avg_logprob": -0.15880794801573822, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.001983609050512314}, {"id": 34, "seek": 22056, "start": 224.32, "end": 230.16, "text": " So maybe in person, you get more of a, more of that very opinionated side, but really he's a,", "tokens": [50552, 407, 1310, 294, 954, 11, 291, 483, 544, 295, 257, 11, 544, 295, 300, 588, 4800, 770, 1252, 11, 457, 534, 415, 311, 257, 11, 50844], "temperature": 0.0, "avg_logprob": -0.15880794801573822, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.001983609050512314}, {"id": 35, "seek": 22056, "start": 231.52, "end": 236.08, "text": " he's just, you know, that book Go to Lesha Bark was just, I mean, it was what drew me into philosophy", "tokens": [50912, 415, 311, 445, 11, 291, 458, 11, 300, 1446, 1037, 281, 6965, 1641, 36275, 390, 445, 11, 286, 914, 11, 309, 390, 437, 12804, 385, 666, 10675, 51140], "temperature": 0.0, "avg_logprob": -0.15880794801573822, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.001983609050512314}, {"id": 36, "seek": 22056, "start": 236.08, "end": 241.68, "text": " and AI as a teenager and it's so rich. And you go back to that book, there's still so many ideas", "tokens": [51140, 293, 7318, 382, 257, 21440, 293, 309, 311, 370, 4593, 13, 400, 291, 352, 646, 281, 300, 1446, 11, 456, 311, 920, 370, 867, 3487, 51420], "temperature": 0.0, "avg_logprob": -0.15880794801573822, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.001983609050512314}, {"id": 37, "seek": 22056, "start": 241.68, "end": 245.92000000000002, "text": " there. The Mind's Eye is another book he edited with Dan Dennett. It was reading the Mind's Eye", "tokens": [51420, 456, 13, 440, 13719, 311, 21603, 307, 1071, 1446, 415, 23016, 365, 3394, 19027, 3093, 13, 467, 390, 3760, 264, 13719, 311, 21603, 51632], "temperature": 0.0, "avg_logprob": -0.15880794801573822, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.001983609050512314}, {"id": 38, "seek": 24592, "start": 245.92, "end": 251.28, "text": " that really first got me thinking about issues about consciousness and the mind-body problem.", "tokens": [50364, 300, 534, 700, 658, 385, 1953, 466, 2663, 466, 10081, 293, 264, 1575, 12, 1067, 1154, 13, 50632], "temperature": 0.0, "avg_logprob": -0.14094240157330623, "compression_ratio": 1.5890410958904109, "no_speech_prob": 0.0038813622668385506}, {"id": 39, "seek": 24592, "start": 251.28, "end": 255.83999999999997, "text": " So yeah, he's a very rich thinker. Yeah. Well, thank God for Douglas Tostata.", "tokens": [50632, 407, 1338, 11, 415, 311, 257, 588, 4593, 519, 260, 13, 865, 13, 1042, 11, 1309, 1265, 337, 23010, 314, 555, 3274, 13, 50860], "temperature": 0.0, "avg_logprob": -0.14094240157330623, "compression_ratio": 1.5890410958904109, "no_speech_prob": 0.0038813622668385506}, {"id": 40, "seek": 24592, "start": 255.83999999999997, "end": 261.03999999999996, "text": " Yeah, I love the Mind's Eye. It has one of the, one of the eeriest stories of all. What was it?", "tokens": [50860, 865, 11, 286, 959, 264, 13719, 311, 21603, 13, 467, 575, 472, 295, 264, 11, 472, 295, 264, 25937, 6495, 3676, 295, 439, 13, 708, 390, 309, 30, 51120], "temperature": 0.0, "avg_logprob": -0.14094240157330623, "compression_ratio": 1.5890410958904109, "no_speech_prob": 0.0038813622668385506}, {"id": 41, "seek": 24592, "start": 261.03999999999996, "end": 266.08, "text": " The riddle of the universe and its solution where there's, there's some image or some text that if", "tokens": [51120, 440, 3973, 2285, 295, 264, 6445, 293, 1080, 3827, 689, 456, 311, 11, 456, 311, 512, 3256, 420, 512, 2487, 300, 498, 51372], "temperature": 0.0, "avg_logprob": -0.14094240157330623, "compression_ratio": 1.5890410958904109, "no_speech_prob": 0.0038813622668385506}, {"id": 42, "seek": 24592, "start": 266.08, "end": 271.59999999999997, "text": " you read it, it causes your brain basically to core dump. And so it becomes this infectious thing", "tokens": [51372, 291, 1401, 309, 11, 309, 7700, 428, 3567, 1936, 281, 4965, 11430, 13, 400, 370, 309, 3643, 341, 26780, 551, 51648], "temperature": 0.0, "avg_logprob": -0.14094240157330623, "compression_ratio": 1.5890410958904109, "no_speech_prob": 0.0038813622668385506}, {"id": 43, "seek": 27160, "start": 271.6, "end": 275.92, "text": " where anybody who goes into that office and reads that thing, they just crash and they never,", "tokens": [50364, 689, 4472, 567, 1709, 666, 300, 3398, 293, 15700, 300, 551, 11, 436, 445, 8252, 293, 436, 1128, 11, 50580], "temperature": 0.0, "avg_logprob": -0.09464335615617515, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.0018665611278265715}, {"id": 44, "seek": 27160, "start": 275.92, "end": 280.32000000000005, "text": " they go into a coma and they never wake up again. And so, you know, there's a huge investigation", "tokens": [50580, 436, 352, 666, 257, 35106, 293, 436, 1128, 6634, 493, 797, 13, 400, 370, 11, 291, 458, 11, 456, 311, 257, 2603, 9627, 50800], "temperature": 0.0, "avg_logprob": -0.09464335615617515, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.0018665611278265715}, {"id": 45, "seek": 27160, "start": 280.32000000000005, "end": 284.56, "text": " to figure out what's going on and more and more people keep going into comas, you know, because", "tokens": [50800, 281, 2573, 484, 437, 311, 516, 322, 293, 544, 293, 544, 561, 1066, 516, 666, 395, 296, 11, 291, 458, 11, 570, 51012], "temperature": 0.0, "avg_logprob": -0.09464335615617515, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.0018665611278265715}, {"id": 46, "seek": 27160, "start": 284.56, "end": 290.40000000000003, "text": " of this crazy ideas in that book. Could I just pick up on this point because you were saying that", "tokens": [51012, 295, 341, 3219, 3487, 294, 300, 1446, 13, 7497, 286, 445, 1888, 493, 322, 341, 935, 570, 291, 645, 1566, 300, 51304], "temperature": 0.0, "avg_logprob": -0.09464335615617515, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.0018665611278265715}, {"id": 47, "seek": 27160, "start": 290.40000000000003, "end": 294.64000000000004, "text": " Douglas Tostata turned his nose up at Neural Networks. And I hope he still would actually,", "tokens": [51304, 23010, 314, 555, 3274, 3574, 702, 6690, 493, 412, 1734, 1807, 12640, 82, 13, 400, 286, 1454, 415, 920, 576, 767, 11, 51516], "temperature": 0.0, "avg_logprob": -0.09464335615617515, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.0018665611278265715}, {"id": 48, "seek": 27160, "start": 294.64000000000004, "end": 298.48, "text": " and Melanie Mitchell certainly does. And I mean, Douglas had that paper out called", "tokens": [51516, 293, 42798, 27582, 3297, 775, 13, 400, 286, 914, 11, 23010, 632, 300, 3035, 484, 1219, 51708], "temperature": 0.0, "avg_logprob": -0.09464335615617515, "compression_ratio": 1.7547169811320755, "no_speech_prob": 0.0018665611278265715}, {"id": 49, "seek": 29848, "start": 298.48, "end": 303.52000000000004, "text": " The Core of Cognition. He was always huge about this idea of the primacy of analogy making.", "tokens": [50364, 440, 14798, 295, 383, 2912, 849, 13, 634, 390, 1009, 2603, 466, 341, 1558, 295, 264, 2886, 2551, 295, 21663, 1455, 13, 50616], "temperature": 0.0, "avg_logprob": -0.12064707640445593, "compression_ratio": 1.6706948640483383, "no_speech_prob": 0.0106809688732028}, {"id": 50, "seek": 29848, "start": 303.52000000000004, "end": 308.0, "text": " And actually, there's a few researchers today that are mirroring that, that idea that Francois", "tokens": [50616, 400, 767, 11, 456, 311, 257, 1326, 10309, 965, 300, 366, 8013, 278, 300, 11, 300, 1558, 300, 34695, 271, 50840], "temperature": 0.0, "avg_logprob": -0.12064707640445593, "compression_ratio": 1.6706948640483383, "no_speech_prob": 0.0106809688732028}, {"id": 51, "seek": 29848, "start": 308.0, "end": 312.88, "text": " Chollet, for example, he says intelligence is literally sensitivity to abstract analogies.", "tokens": [50840, 761, 1833, 302, 11, 337, 1365, 11, 415, 1619, 7599, 307, 3736, 19392, 281, 12649, 16660, 530, 13, 51084], "temperature": 0.0, "avg_logprob": -0.12064707640445593, "compression_ratio": 1.6706948640483383, "no_speech_prob": 0.0106809688732028}, {"id": 52, "seek": 29848, "start": 312.88, "end": 317.04, "text": " It's not memorizing the internet. So I think, thank God that we do have people out there", "tokens": [51084, 467, 311, 406, 10560, 3319, 264, 4705, 13, 407, 286, 519, 11, 1309, 1265, 300, 321, 360, 362, 561, 484, 456, 51292], "temperature": 0.0, "avg_logprob": -0.12064707640445593, "compression_ratio": 1.6706948640483383, "no_speech_prob": 0.0106809688732028}, {"id": 53, "seek": 29848, "start": 317.04, "end": 321.68, "text": " thinking slightly differently because the modus operandi today is that we need to build a big", "tokens": [51292, 1953, 4748, 7614, 570, 264, 1072, 301, 2208, 49460, 965, 307, 300, 321, 643, 281, 1322, 257, 955, 51524], "temperature": 0.0, "avg_logprob": -0.12064707640445593, "compression_ratio": 1.6706948640483383, "no_speech_prob": 0.0106809688732028}, {"id": 54, "seek": 29848, "start": 321.68, "end": 326.24, "text": " hash table of everything. And even the way we formalize intelligence, as we were just saying", "tokens": [51524, 22019, 3199, 295, 1203, 13, 400, 754, 264, 636, 321, 9860, 1125, 7599, 11, 382, 321, 645, 445, 1566, 51752], "temperature": 0.0, "avg_logprob": -0.12064707640445593, "compression_ratio": 1.6706948640483383, "no_speech_prob": 0.0106809688732028}, {"id": 55, "seek": 32624, "start": 326.24, "end": 331.84000000000003, "text": " previously, we're not really paying attention to why or how the things do what they do. We're", "tokens": [50364, 8046, 11, 321, 434, 406, 534, 6229, 3202, 281, 983, 420, 577, 264, 721, 360, 437, 436, 360, 13, 492, 434, 50644], "temperature": 0.0, "avg_logprob": -0.10692622143289317, "compression_ratio": 1.6631944444444444, "no_speech_prob": 0.0007293032831512392}, {"id": 56, "seek": 32624, "start": 331.84000000000003, "end": 335.76, "text": " just looking at the behavioral output bit like the Turing test, as long as it looks and smells", "tokens": [50644, 445, 1237, 412, 264, 19124, 5598, 857, 411, 264, 314, 1345, 1500, 11, 382, 938, 382, 309, 1542, 293, 10036, 50840], "temperature": 0.0, "avg_logprob": -0.10692622143289317, "compression_ratio": 1.6631944444444444, "no_speech_prob": 0.0007293032831512392}, {"id": 57, "seek": 32624, "start": 335.76, "end": 342.72, "text": " like a duck, then it must be a duck. So thank God for Douglas Tostata. Yeah, I think he's always been", "tokens": [50840, 411, 257, 12482, 11, 550, 309, 1633, 312, 257, 12482, 13, 407, 1309, 1265, 337, 23010, 314, 555, 3274, 13, 865, 11, 286, 519, 415, 311, 1009, 668, 51188], "temperature": 0.0, "avg_logprob": -0.10692622143289317, "compression_ratio": 1.6631944444444444, "no_speech_prob": 0.0007293032831512392}, {"id": 58, "seek": 32624, "start": 343.36, "end": 348.88, "text": " at the same time an enthusiast about the possibility of AI while being somewhat skeptical", "tokens": [51220, 412, 264, 912, 565, 364, 18076, 525, 466, 264, 7959, 295, 7318, 1339, 885, 8344, 28601, 51496], "temperature": 0.0, "avg_logprob": -0.10692622143289317, "compression_ratio": 1.6631944444444444, "no_speech_prob": 0.0007293032831512392}, {"id": 59, "seek": 32624, "start": 348.88, "end": 356.0, "text": " about the capacities of existing AI and about the kind of hype that suggests that AI might just be", "tokens": [51496, 466, 264, 39396, 295, 6741, 7318, 293, 466, 264, 733, 295, 24144, 300, 13409, 300, 7318, 1062, 445, 312, 51852], "temperature": 0.0, "avg_logprob": -0.10692622143289317, "compression_ratio": 1.6631944444444444, "no_speech_prob": 0.0007293032831512392}, {"id": 60, "seek": 35624, "start": 356.48, "end": 361.68, "text": " 10 or 20 years around the corner. So in the early 90s, I think, yeah, that was,", "tokens": [50376, 1266, 420, 945, 924, 926, 264, 4538, 13, 407, 294, 264, 2440, 4289, 82, 11, 286, 519, 11, 1338, 11, 300, 390, 11, 50636], "temperature": 0.0, "avg_logprob": -0.1051334401835566, "compression_ratio": 1.579646017699115, "no_speech_prob": 0.001547180232591927}, {"id": 61, "seek": 35624, "start": 363.04, "end": 368.08, "text": " that was especially, especially natural. Back around then, people would say a year spent working", "tokens": [50704, 300, 390, 2318, 11, 2318, 3303, 13, 5833, 926, 550, 11, 561, 576, 584, 257, 1064, 4418, 1364, 50956], "temperature": 0.0, "avg_logprob": -0.1051334401835566, "compression_ratio": 1.579646017699115, "no_speech_prob": 0.001547180232591927}, {"id": 62, "seek": 35624, "start": 368.08, "end": 373.36, "text": " in AI is enough to make you believe in God. It was so hard to get anything even like", "tokens": [50956, 294, 7318, 307, 1547, 281, 652, 291, 1697, 294, 1265, 13, 467, 390, 370, 1152, 281, 483, 1340, 754, 411, 51220], "temperature": 0.0, "avg_logprob": -0.1051334401835566, "compression_ratio": 1.579646017699115, "no_speech_prob": 0.001547180232591927}, {"id": 63, "seek": 35624, "start": 375.68, "end": 380.56, "text": " any kind of intelligence out of an AI system. And I think, you know, Doug was equally skeptical", "tokens": [51336, 604, 733, 295, 7599, 484, 295, 364, 7318, 1185, 13, 400, 286, 519, 11, 291, 458, 11, 12742, 390, 12309, 28601, 51580], "temperature": 0.0, "avg_logprob": -0.1051334401835566, "compression_ratio": 1.579646017699115, "no_speech_prob": 0.001547180232591927}, {"id": 64, "seek": 38056, "start": 380.56, "end": 386.72, "text": " of both the symbolic and the connectionist on neural network approaches back then.", "tokens": [50364, 295, 1293, 264, 25755, 293, 264, 4984, 468, 322, 18161, 3209, 11587, 646, 550, 13, 50672], "temperature": 0.0, "avg_logprob": -0.1262837058619449, "compression_ratio": 1.7751004016064258, "no_speech_prob": 0.04200545325875282}, {"id": 65, "seek": 38056, "start": 387.84, "end": 392.88, "text": " I think ultimately his sympathies lay with it on the neural network side of things,", "tokens": [50728, 286, 519, 6284, 702, 22276, 530, 2360, 365, 309, 322, 264, 18161, 3209, 1252, 295, 721, 11, 50980], "temperature": 0.0, "avg_logprob": -0.1262837058619449, "compression_ratio": 1.7751004016064258, "no_speech_prob": 0.04200545325875282}, {"id": 66, "seek": 38056, "start": 392.88, "end": 397.2, "text": " with the idea that intelligence could in principle bubble up from a million, you know,", "tokens": [50980, 365, 264, 1558, 300, 7599, 727, 294, 8665, 12212, 493, 490, 257, 2459, 11, 291, 458, 11, 51196], "temperature": 0.0, "avg_logprob": -0.1262837058619449, "compression_ratio": 1.7751004016064258, "no_speech_prob": 0.04200545325875282}, {"id": 67, "seek": 38056, "start": 397.2, "end": 402.0, "text": " from 100 billion separate little interactions, intelligence could bubble up from there. But", "tokens": [51196, 490, 2319, 5218, 4994, 707, 13280, 11, 7599, 727, 12212, 493, 490, 456, 13, 583, 51436], "temperature": 0.0, "avg_logprob": -0.1262837058619449, "compression_ratio": 1.7751004016064258, "no_speech_prob": 0.04200545325875282}, {"id": 68, "seek": 38056, "start": 402.0, "end": 407.52, "text": " I still think he'd be inclined to think that current approaches are too statistical, too simple,", "tokens": [51436, 286, 920, 519, 415, 1116, 312, 28173, 281, 519, 300, 2190, 11587, 366, 886, 22820, 11, 886, 2199, 11, 51712], "temperature": 0.0, "avg_logprob": -0.1262837058619449, "compression_ratio": 1.7751004016064258, "no_speech_prob": 0.04200545325875282}, {"id": 69, "seek": 40752, "start": 407.52, "end": 413.76, "text": " and so on. That said, you have to look at the, at the progress in machine learning over the last", "tokens": [50364, 293, 370, 322, 13, 663, 848, 11, 291, 362, 281, 574, 412, 264, 11, 412, 264, 4205, 294, 3479, 2539, 670, 264, 1036, 50676], "temperature": 0.0, "avg_logprob": -0.1316811035726672, "compression_ratio": 1.6203007518796992, "no_speech_prob": 0.00394229544326663}, {"id": 70, "seek": 40752, "start": 414.79999999999995, "end": 418.4, "text": " 10 years. And it's been amazing and surprising. And I think even somebody like,", "tokens": [50728, 1266, 924, 13, 400, 309, 311, 668, 2243, 293, 8830, 13, 400, 286, 519, 754, 2618, 411, 11, 50908], "temperature": 0.0, "avg_logprob": -0.1316811035726672, "compression_ratio": 1.6203007518796992, "no_speech_prob": 0.00394229544326663}, {"id": 71, "seek": 40752, "start": 419.28, "end": 422.79999999999995, "text": " even people like Melanie or like Doug are going to have to say this has been", "tokens": [50952, 754, 561, 411, 42798, 420, 411, 12742, 366, 516, 281, 362, 281, 584, 341, 575, 668, 51128], "temperature": 0.0, "avg_logprob": -0.1316811035726672, "compression_ratio": 1.6203007518796992, "no_speech_prob": 0.00394229544326663}, {"id": 72, "seek": 40752, "start": 422.79999999999995, "end": 428.4, "text": " something they did not expect. And that they did not predict. So I actually, I was back in", "tokens": [51128, 746, 436, 630, 406, 2066, 13, 400, 300, 436, 630, 406, 6069, 13, 407, 286, 767, 11, 286, 390, 646, 294, 51408], "temperature": 0.0, "avg_logprob": -0.1316811035726672, "compression_ratio": 1.6203007518796992, "no_speech_prob": 0.00394229544326663}, {"id": 73, "seek": 40752, "start": 428.4, "end": 434.47999999999996, "text": " Indiana just over two years ago, just before the pandemic got going February 2020. And", "tokens": [51408, 21858, 445, 670, 732, 924, 2057, 11, 445, 949, 264, 5388, 658, 516, 8711, 4808, 13, 400, 51712], "temperature": 0.0, "avg_logprob": -0.1316811035726672, "compression_ratio": 1.6203007518796992, "no_speech_prob": 0.00394229544326663}, {"id": 74, "seek": 43448, "start": 435.44, "end": 438.72, "text": " I don't know, maybe that was before GBT three, but still there've been all these amazing", "tokens": [50412, 286, 500, 380, 458, 11, 1310, 300, 390, 949, 26809, 51, 1045, 11, 457, 920, 456, 600, 668, 439, 613, 2243, 50576], "temperature": 0.0, "avg_logprob": -0.1129580752950319, "compression_ratio": 1.7025316455696202, "no_speech_prob": 0.0004792431427631527}, {"id": 75, "seek": 43448, "start": 439.84000000000003, "end": 444.88, "text": " developments in machine learning over the last few years. I asked Doug about this,", "tokens": [50632, 20862, 294, 3479, 2539, 670, 264, 1036, 1326, 924, 13, 286, 2351, 12742, 466, 341, 11, 50884], "temperature": 0.0, "avg_logprob": -0.1129580752950319, "compression_ratio": 1.7025316455696202, "no_speech_prob": 0.0004792431427631527}, {"id": 76, "seek": 43448, "start": 444.88, "end": 448.72, "text": " and what do you make of this? And because he's on the record of saying, you know,", "tokens": [50884, 293, 437, 360, 291, 652, 295, 341, 30, 400, 570, 415, 311, 322, 264, 2136, 295, 1566, 11, 291, 458, 11, 51076], "temperature": 0.0, "avg_logprob": -0.1129580752950319, "compression_ratio": 1.7025316455696202, "no_speech_prob": 0.0004792431427631527}, {"id": 77, "seek": 43448, "start": 448.72, "end": 453.36, "text": " there will be AI eventually, but it's going to have to be involve all these new kinds of complexity,", "tokens": [51076, 456, 486, 312, 7318, 4728, 11, 457, 309, 311, 516, 281, 362, 281, 312, 9494, 439, 613, 777, 3685, 295, 14024, 11, 51308], "temperature": 0.0, "avg_logprob": -0.1129580752950319, "compression_ratio": 1.7025316455696202, "no_speech_prob": 0.0004792431427631527}, {"id": 78, "seek": 43448, "start": 453.36, "end": 457.68, "text": " not not something simple like this. And he says, Yeah, well, this is, this is troubling.", "tokens": [51308, 406, 406, 746, 2199, 411, 341, 13, 400, 415, 1619, 11, 865, 11, 731, 11, 341, 307, 11, 341, 307, 38080, 13, 51524], "temperature": 0.0, "avg_logprob": -0.1129580752950319, "compression_ratio": 1.7025316455696202, "no_speech_prob": 0.0004792431427631527}, {"id": 79, "seek": 43448, "start": 457.68, "end": 461.76, "text": " This is concerning, you know, it could be, I don't know yet, but it could be that I was wrong.", "tokens": [51524, 639, 307, 18087, 11, 291, 458, 11, 309, 727, 312, 11, 286, 500, 380, 458, 1939, 11, 457, 309, 727, 312, 300, 286, 390, 2085, 13, 51728], "temperature": 0.0, "avg_logprob": -0.1129580752950319, "compression_ratio": 1.7025316455696202, "no_speech_prob": 0.0004792431427631527}, {"id": 80, "seek": 46176, "start": 462.32, "end": 467.44, "text": " It could be there are simpler passes, paths to AI. And his attitude was that would be very", "tokens": [50392, 467, 727, 312, 456, 366, 18587, 11335, 11, 14518, 281, 7318, 13, 400, 702, 10157, 390, 300, 576, 312, 588, 50648], "temperature": 0.0, "avg_logprob": -0.21815789051544973, "compression_ratio": 1.6886446886446886, "no_speech_prob": 0.002048243535682559}, {"id": 81, "seek": 46176, "start": 467.44, "end": 472.4, "text": " disappointing. It turned out that you could actually train up an AGI, just using those", "tokens": [50648, 25054, 13, 467, 3574, 484, 300, 291, 727, 767, 3847, 493, 364, 316, 26252, 11, 445, 1228, 729, 50896], "temperature": 0.0, "avg_logprob": -0.21815789051544973, "compression_ratio": 1.6886446886446886, "no_speech_prob": 0.002048243535682559}, {"id": 82, "seek": 46176, "start": 473.12, "end": 477.44, "text": " simple methods to human levels. That would make, I think Doug's view was that would make kind of", "tokens": [50932, 2199, 7150, 281, 1952, 4358, 13, 663, 576, 652, 11, 286, 519, 12742, 311, 1910, 390, 300, 576, 652, 733, 295, 51148], "temperature": 0.0, "avg_logprob": -0.21815789051544973, "compression_ratio": 1.6886446886446886, "no_speech_prob": 0.002048243535682559}, {"id": 83, "seek": 46176, "start": 477.44, "end": 484.56, "text": " human level intelligence less, less grand and remarkable than, than he had thought. Well,", "tokens": [51148, 1952, 1496, 7599, 1570, 11, 1570, 2697, 293, 12802, 813, 11, 813, 415, 632, 1194, 13, 1042, 11, 51504], "temperature": 0.0, "avg_logprob": -0.21815789051544973, "compression_ratio": 1.6886446886446886, "no_speech_prob": 0.002048243535682559}, {"id": 84, "seek": 46176, "start": 484.56, "end": 489.36, "text": " actually, back in, back in Goethe-les-Sherbach, I think he said that even to have a machine that", "tokens": [51504, 767, 11, 646, 294, 11, 646, 294, 1037, 302, 675, 12, 904, 12, 50, 511, 32096, 11, 286, 519, 415, 848, 300, 754, 281, 362, 257, 3479, 300, 51744], "temperature": 0.0, "avg_logprob": -0.21815789051544973, "compression_ratio": 1.6886446886446886, "no_speech_prob": 0.002048243535682559}, {"id": 85, "seek": 48936, "start": 489.36, "end": 494.0, "text": " could beat a human at chess, it would have to be good at everything would be a good composer,", "tokens": [50364, 727, 4224, 257, 1952, 412, 24122, 11, 309, 576, 362, 281, 312, 665, 412, 1203, 576, 312, 257, 665, 26003, 11, 50596], "temperature": 0.0, "avg_logprob": -0.1301137956522279, "compression_ratio": 1.72265625, "no_speech_prob": 0.0015950050437822938}, {"id": 86, "seek": 48936, "start": 494.0, "end": 499.04, "text": " it could tell jokes and so on. Okay, that one, that view got rolled out back in the,", "tokens": [50596, 309, 727, 980, 14439, 293, 370, 322, 13, 1033, 11, 300, 472, 11, 300, 1910, 658, 14306, 484, 646, 294, 264, 11, 50848], "temperature": 0.0, "avg_logprob": -0.1301137956522279, "compression_ratio": 1.72265625, "no_speech_prob": 0.0015950050437822938}, {"id": 87, "seek": 48936, "start": 499.04, "end": 507.92, "text": " back in the 90s. So the question is, you know, is this, is this ever growing progress of just,", "tokens": [50848, 646, 294, 264, 4289, 82, 13, 407, 264, 1168, 307, 11, 291, 458, 11, 307, 341, 11, 307, 341, 1562, 4194, 4205, 295, 445, 11, 51292], "temperature": 0.0, "avg_logprob": -0.1301137956522279, "compression_ratio": 1.72265625, "no_speech_prob": 0.0015950050437822938}, {"id": 88, "seek": 48936, "start": 507.92, "end": 511.2, "text": " of the kind of machine learning that says just throw a whole lot of compute,", "tokens": [51292, 295, 264, 733, 295, 3479, 2539, 300, 1619, 445, 3507, 257, 1379, 688, 295, 14722, 11, 51456], "temperature": 0.0, "avg_logprob": -0.1301137956522279, "compression_ratio": 1.72265625, "no_speech_prob": 0.0015950050437822938}, {"id": 89, "seek": 48936, "start": 511.2, "end": 516.24, "text": " and a whole lot of data at it, and see what happens. Is that eventually going to get us to", "tokens": [51456, 293, 257, 1379, 688, 295, 1412, 412, 309, 11, 293, 536, 437, 2314, 13, 1119, 300, 4728, 516, 281, 483, 505, 281, 51708], "temperature": 0.0, "avg_logprob": -0.1301137956522279, "compression_ratio": 1.72265625, "no_speech_prob": 0.0015950050437822938}, {"id": 90, "seek": 51624, "start": 516.32, "end": 519.84, "text": " human level intelligence? Or is it, is it just going to get us so far", "tokens": [50368, 1952, 1496, 7599, 30, 1610, 307, 309, 11, 307, 309, 445, 516, 281, 483, 505, 370, 1400, 50544], "temperature": 0.0, "avg_logprob": -0.13891411735897974, "compression_ratio": 1.7459016393442623, "no_speech_prob": 0.01535508967936039}, {"id": 91, "seek": 51624, "start": 520.8, "end": 524.5600000000001, "text": " with, and there's going to be principled limitations? I've always been on the side of,", "tokens": [50592, 365, 11, 293, 456, 311, 516, 281, 312, 3681, 15551, 15705, 30, 286, 600, 1009, 668, 322, 264, 1252, 295, 11, 50780], "temperature": 0.0, "avg_logprob": -0.13891411735897974, "compression_ratio": 1.7459016393442623, "no_speech_prob": 0.01535508967936039}, {"id": 92, "seek": 51624, "start": 525.36, "end": 530.5600000000001, "text": " they'll probably only get us so far. But I have to say those principled limitations,", "tokens": [50820, 436, 603, 1391, 787, 483, 505, 370, 1400, 13, 583, 286, 362, 281, 584, 729, 3681, 15551, 15705, 11, 51080], "temperature": 0.0, "avg_logprob": -0.13891411735897974, "compression_ratio": 1.7459016393442623, "no_speech_prob": 0.01535508967936039}, {"id": 93, "seek": 51624, "start": 530.5600000000001, "end": 537.84, "text": " those obstacles that have not yet been conquered are getting smaller and smaller. And the progress,", "tokens": [51080, 729, 17735, 300, 362, 406, 1939, 668, 32695, 366, 1242, 4356, 293, 4356, 13, 400, 264, 4205, 11, 51444], "temperature": 0.0, "avg_logprob": -0.13891411735897974, "compression_ratio": 1.7459016393442623, "no_speech_prob": 0.01535508967936039}, {"id": 94, "seek": 51624, "start": 537.84, "end": 541.12, "text": " if the progress of the last five or 10 years continues for another five or 10 years,", "tokens": [51444, 498, 264, 4205, 295, 264, 1036, 1732, 420, 1266, 924, 6515, 337, 1071, 1732, 420, 1266, 924, 11, 51608], "temperature": 0.0, "avg_logprob": -0.13891411735897974, "compression_ratio": 1.7459016393442623, "no_speech_prob": 0.01535508967936039}, {"id": 95, "seek": 54112, "start": 541.68, "end": 546.96, "text": " then who's to say what's going to be left? Yeah, there was a fascinating anecdote in,", "tokens": [50392, 550, 567, 311, 281, 584, 437, 311, 516, 281, 312, 1411, 30, 865, 11, 456, 390, 257, 10343, 49845, 294, 11, 50656], "temperature": 0.0, "avg_logprob": -0.10598496410334221, "compression_ratio": 1.5625, "no_speech_prob": 0.019168008118867874}, {"id": 96, "seek": 54112, "start": 546.96, "end": 552.4, "text": " in Melanie's book about how she and Hofstadter went to the Googleplex one time. And basically,", "tokens": [50656, 294, 42798, 311, 1446, 466, 577, 750, 293, 37379, 48299, 391, 1437, 281, 264, 3329, 18945, 472, 565, 13, 400, 1936, 11, 50928], "temperature": 0.0, "avg_logprob": -0.10598496410334221, "compression_ratio": 1.5625, "no_speech_prob": 0.019168008118867874}, {"id": 97, "seek": 54112, "start": 552.4, "end": 557.36, "text": " as you said, Douglas was terrified that intelligence might be disappointingly simple to", "tokens": [50928, 382, 291, 848, 11, 23010, 390, 23051, 300, 7599, 1062, 312, 8505, 12163, 2199, 281, 51176], "temperature": 0.0, "avg_logprob": -0.10598496410334221, "compression_ratio": 1.5625, "no_speech_prob": 0.019168008118867874}, {"id": 98, "seek": 54112, "start": 557.36, "end": 562.8, "text": " mechanize because he felt of the mind of Chopin as being infinitely nuanced. And just,", "tokens": [51176, 4236, 1125, 570, 415, 2762, 295, 264, 1575, 295, 25615, 259, 382, 885, 36227, 45115, 13, 400, 445, 11, 51448], "temperature": 0.0, "avg_logprob": -0.10598496410334221, "compression_ratio": 1.5625, "no_speech_prob": 0.019168008118867874}, {"id": 99, "seek": 54112, "start": 562.8, "end": 566.96, "text": " just the incredible process that must have gone through his mind when he, when he produced his", "tokens": [51448, 445, 264, 4651, 1399, 300, 1633, 362, 2780, 807, 702, 1575, 562, 415, 11, 562, 415, 7126, 702, 51656], "temperature": 0.0, "avg_logprob": -0.10598496410334221, "compression_ratio": 1.5625, "no_speech_prob": 0.019168008118867874}, {"id": 100, "seek": 56696, "start": 566.96, "end": 572.64, "text": " music. But I wanted to, and just quickly, by the way, you said that there was a conception in,", "tokens": [50364, 1318, 13, 583, 286, 1415, 281, 11, 293, 445, 2661, 11, 538, 264, 636, 11, 291, 848, 300, 456, 390, 257, 30698, 294, 11, 50648], "temperature": 0.0, "avg_logprob": -0.11020889797726192, "compression_ratio": 1.7195571955719557, "no_speech_prob": 0.0059610470198094845}, {"id": 101, "seek": 56696, "start": 572.64, "end": 578.08, "text": " in the 70s that task specific skill was what was required for intelligence or a collection of,", "tokens": [50648, 294, 264, 5285, 82, 300, 5633, 2685, 5389, 390, 437, 390, 4739, 337, 7599, 420, 257, 5765, 295, 11, 50920], "temperature": 0.0, "avg_logprob": -0.11020889797726192, "compression_ratio": 1.7195571955719557, "no_speech_prob": 0.0059610470198094845}, {"id": 102, "seek": 56696, "start": 578.08, "end": 584.1600000000001, "text": " of specific skills. And, and now the mindset is much more towards task acquisition efficiency", "tokens": [50920, 295, 2685, 3942, 13, 400, 11, 293, 586, 264, 12543, 307, 709, 544, 3030, 5633, 21668, 10493, 51224], "temperature": 0.0, "avg_logprob": -0.11020889797726192, "compression_ratio": 1.7195571955719557, "no_speech_prob": 0.0059610470198094845}, {"id": 103, "seek": 56696, "start": 584.1600000000001, "end": 589.44, "text": " and generalization. But I wanted to just quickly pick you up on the so-called intelligence", "tokens": [51224, 293, 2674, 2144, 13, 583, 286, 1415, 281, 445, 2661, 1888, 291, 493, 322, 264, 370, 12, 11880, 7599, 51488], "temperature": 0.0, "avg_logprob": -0.11020889797726192, "compression_ratio": 1.7195571955719557, "no_speech_prob": 0.0059610470198094845}, {"id": 104, "seek": 56696, "start": 589.44, "end": 594.4000000000001, "text": " explosion question. So this is a subject which Nick Bostrom has popularized after his book,", "tokens": [51488, 15673, 1168, 13, 407, 341, 307, 257, 3983, 597, 9449, 363, 555, 4397, 575, 3743, 1602, 934, 702, 1446, 11, 51736], "temperature": 0.0, "avg_logprob": -0.11020889797726192, "compression_ratio": 1.7195571955719557, "no_speech_prob": 0.0059610470198094845}, {"id": 105, "seek": 59440, "start": 594.48, "end": 599.68, "text": " Superintelligence. Personally speaking, we're not particularly sympathetic to this view. And", "tokens": [50368, 4548, 20761, 17644, 13, 21079, 4124, 11, 321, 434, 406, 4098, 36032, 281, 341, 1910, 13, 400, 50628], "temperature": 0.0, "avg_logprob": -0.15476316746657456, "compression_ratio": 1.8566666666666667, "no_speech_prob": 0.005307003855705261}, {"id": 106, "seek": 59440, "start": 599.68, "end": 604.56, "text": " Saigre Francois-Labe, he said in a blog post recently that this line of reasoning represents", "tokens": [50628, 6299, 328, 265, 34695, 271, 12, 43, 4488, 11, 415, 848, 294, 257, 6968, 2183, 3938, 300, 341, 1622, 295, 21577, 8855, 50872], "temperature": 0.0, "avg_logprob": -0.15476316746657456, "compression_ratio": 1.8566666666666667, "no_speech_prob": 0.005307003855705261}, {"id": 107, "seek": 59440, "start": 604.56, "end": 609.04, "text": " a misunderstanding of intelligence. He said that in his opinion, intelligence is situational.", "tokens": [50872, 257, 29227, 295, 7599, 13, 634, 848, 300, 294, 702, 4800, 11, 7599, 307, 2054, 1478, 13, 51096], "temperature": 0.0, "avg_logprob": -0.15476316746657456, "compression_ratio": 1.8566666666666667, "no_speech_prob": 0.005307003855705261}, {"id": 108, "seek": 59440, "start": 609.68, "end": 613.84, "text": " He said that our environment puts a hard limit on our individual intelligences. He said that", "tokens": [51128, 634, 848, 300, 527, 2823, 8137, 257, 1152, 4948, 322, 527, 2609, 5613, 2667, 13, 634, 848, 300, 51336], "temperature": 0.0, "avg_logprob": -0.15476316746657456, "compression_ratio": 1.8566666666666667, "no_speech_prob": 0.005307003855705261}, {"id": 109, "seek": 59440, "start": 613.84, "end": 618.72, "text": " most of our intelligence is not in the brain, it's externalized as civilization. And that an", "tokens": [51336, 881, 295, 527, 7599, 307, 406, 294, 264, 3567, 11, 309, 311, 8320, 1602, 382, 18036, 13, 400, 300, 364, 51580], "temperature": 0.0, "avg_logprob": -0.15476316746657456, "compression_ratio": 1.8566666666666667, "no_speech_prob": 0.005307003855705261}, {"id": 110, "seek": 59440, "start": 618.72, "end": 623.84, "text": " individual brain cannot implement recursive intelligence augmentation like a Godel machine.", "tokens": [51580, 2609, 3567, 2644, 4445, 20560, 488, 7599, 14501, 19631, 411, 257, 1265, 338, 3479, 13, 51836], "temperature": 0.0, "avg_logprob": -0.15476316746657456, "compression_ratio": 1.8566666666666667, "no_speech_prob": 0.005307003855705261}, {"id": 111, "seek": 62384, "start": 623.84, "end": 628.5600000000001, "text": " He also said that there are already many examples of recursively self-improving systems.", "tokens": [50364, 634, 611, 848, 300, 456, 366, 1217, 867, 5110, 295, 20560, 3413, 2698, 12, 332, 4318, 798, 3652, 13, 50600], "temperature": 0.0, "avg_logprob": -0.06666149411882673, "compression_ratio": 1.674922600619195, "no_speech_prob": 0.0005197882419452071}, {"id": 112, "seek": 62384, "start": 628.5600000000001, "end": 632.88, "text": " Even personal investing, for example, is a recursively self-improving system. The more", "tokens": [50600, 2754, 2973, 10978, 11, 337, 1365, 11, 307, 257, 20560, 3413, 2698, 12, 332, 4318, 798, 1185, 13, 440, 544, 50816], "temperature": 0.0, "avg_logprob": -0.06666149411882673, "compression_ratio": 1.674922600619195, "no_speech_prob": 0.0005197882419452071}, {"id": 113, "seek": 62384, "start": 632.88, "end": 638.64, "text": " money you have, the more money you make. Anyway, so Bostrom described a thought experiment in 2003.", "tokens": [50816, 1460, 291, 362, 11, 264, 544, 1460, 291, 652, 13, 5684, 11, 370, 363, 555, 4397, 7619, 257, 1194, 5120, 294, 16416, 13, 51104], "temperature": 0.0, "avg_logprob": -0.06666149411882673, "compression_ratio": 1.674922600619195, "no_speech_prob": 0.0005197882419452071}, {"id": 114, "seek": 62384, "start": 639.2800000000001, "end": 643.2800000000001, "text": " I'm sure you've heard of this. The scenario describes an artificial, you know, like a very", "tokens": [51136, 286, 478, 988, 291, 600, 2198, 295, 341, 13, 440, 9005, 15626, 364, 11677, 11, 291, 458, 11, 411, 257, 588, 51336], "temperature": 0.0, "avg_logprob": -0.06666149411882673, "compression_ratio": 1.674922600619195, "no_speech_prob": 0.0005197882419452071}, {"id": 115, "seek": 62384, "start": 643.2800000000001, "end": 647.84, "text": " advanced artificial intelligence task with manufacturing paper clips. If such a machine", "tokens": [51336, 7339, 11677, 7599, 5633, 365, 11096, 3035, 13117, 13, 759, 1270, 257, 3479, 51564], "temperature": 0.0, "avg_logprob": -0.06666149411882673, "compression_ratio": 1.674922600619195, "no_speech_prob": 0.0005197882419452071}, {"id": 116, "seek": 62384, "start": 647.84, "end": 652.0, "text": " were not programmed to value human life, then given enough power over its environment,", "tokens": [51564, 645, 406, 31092, 281, 2158, 1952, 993, 11, 550, 2212, 1547, 1347, 670, 1080, 2823, 11, 51772], "temperature": 0.0, "avg_logprob": -0.06666149411882673, "compression_ratio": 1.674922600619195, "no_speech_prob": 0.0005197882419452071}, {"id": 117, "seek": 65200, "start": 652.0, "end": 656.24, "text": " it would try to turn all the matter in the universe, including human beings,", "tokens": [50364, 309, 576, 853, 281, 1261, 439, 264, 1871, 294, 264, 6445, 11, 3009, 1952, 8958, 11, 50576], "temperature": 0.0, "avg_logprob": -0.08178744866297795, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0007397889858111739}, {"id": 118, "seek": 65200, "start": 656.24, "end": 661.04, "text": " into paper clips or machines which could manufacture paper clips. Do you think we might", "tokens": [50576, 666, 3035, 13117, 420, 8379, 597, 727, 27400, 3035, 13117, 13, 1144, 291, 519, 321, 1062, 50816], "temperature": 0.0, "avg_logprob": -0.08178744866297795, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0007397889858111739}, {"id": 119, "seek": 65200, "start": 661.04, "end": 665.44, "text": " be on the precipice of being turned into paper clips, as Bostrom famously described in his", "tokens": [50816, 312, 322, 264, 23354, 573, 295, 885, 3574, 666, 3035, 13117, 11, 382, 363, 555, 4397, 34360, 7619, 294, 702, 51036], "temperature": 0.0, "avg_logprob": -0.08178744866297795, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0007397889858111739}, {"id": 120, "seek": 65200, "start": 665.44, "end": 670.8, "text": " thought experiment? Yeah, look, it's there's two different issues here. One is, will we get to", "tokens": [51036, 1194, 5120, 30, 865, 11, 574, 11, 309, 311, 456, 311, 732, 819, 2663, 510, 13, 1485, 307, 11, 486, 321, 483, 281, 51304], "temperature": 0.0, "avg_logprob": -0.08178744866297795, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0007397889858111739}, {"id": 121, "seek": 65200, "start": 670.8, "end": 677.52, "text": " some kind of much greater than human superintelligence relatively soon by some kind of intelligence", "tokens": [51304, 512, 733, 295, 709, 5044, 813, 1952, 1687, 20761, 17644, 7226, 2321, 538, 512, 733, 295, 7599, 51640], "temperature": 0.0, "avg_logprob": -0.08178744866297795, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0007397889858111739}, {"id": 122, "seek": 67752, "start": 677.52, "end": 683.68, "text": " explosion process? And second, if that happens, are there major dangers around? Yeah, I wrote", "tokens": [50364, 15673, 1399, 30, 400, 1150, 11, 498, 300, 2314, 11, 366, 456, 2563, 27701, 926, 30, 865, 11, 286, 4114, 50672], "temperature": 0.0, "avg_logprob": -0.0856334353805682, "compression_ratio": 1.6583629893238434, "no_speech_prob": 0.034076105803251266}, {"id": 123, "seek": 67752, "start": 683.68, "end": 689.36, "text": " about both of these things back in 2009. I had an article called, yeah, the Singularity", "tokens": [50672, 466, 1293, 295, 613, 721, 646, 294, 11453, 13, 286, 632, 364, 7222, 1219, 11, 1338, 11, 264, 7474, 1040, 507, 50956], "temperature": 0.0, "avg_logprob": -0.0856334353805682, "compression_ratio": 1.6583629893238434, "no_speech_prob": 0.034076105803251266}, {"id": 124, "seek": 67752, "start": 689.36, "end": 695.36, "text": " of Philosophical Analysis, where I tried to take this line of reasoning for an intelligence", "tokens": [50956, 295, 31182, 5317, 804, 38172, 11, 689, 286, 3031, 281, 747, 341, 1622, 295, 21577, 337, 364, 7599, 51256], "temperature": 0.0, "avg_logprob": -0.0856334353805682, "compression_ratio": 1.6583629893238434, "no_speech_prob": 0.034076105803251266}, {"id": 125, "seek": 67752, "start": 695.36, "end": 702.24, "text": " explosion through recursive, through basically through recursive design of ever more sophisticated", "tokens": [51256, 15673, 807, 20560, 488, 11, 807, 1936, 807, 20560, 488, 1715, 295, 1562, 544, 16950, 51600], "temperature": 0.0, "avg_logprob": -0.0856334353805682, "compression_ratio": 1.6583629893238434, "no_speech_prob": 0.034076105803251266}, {"id": 126, "seek": 67752, "start": 702.24, "end": 706.48, "text": " AIs. I tried to take that and turn it into an argument. I mean, the classic statement of this", "tokens": [51600, 316, 6802, 13, 286, 3031, 281, 747, 300, 293, 1261, 309, 666, 364, 6770, 13, 286, 914, 11, 264, 7230, 5629, 295, 341, 51812], "temperature": 0.0, "avg_logprob": -0.0856334353805682, "compression_ratio": 1.6583629893238434, "no_speech_prob": 0.034076105803251266}, {"id": 127, "seek": 70648, "start": 706.48, "end": 713.52, "text": " comes from I.J. Goode, the statistician and philosopher back in 1965 on the design of an", "tokens": [50364, 1487, 490, 286, 13, 41, 13, 1037, 1429, 11, 264, 29588, 952, 293, 29805, 646, 294, 33809, 322, 264, 1715, 295, 364, 50716], "temperature": 0.0, "avg_logprob": -0.1216050148010254, "compression_ratio": 1.6130434782608696, "no_speech_prob": 0.00048727571265771985}, {"id": 128, "seek": 70648, "start": 713.52, "end": 718.8000000000001, "text": " ultra intelligent machine where he puts the basic idea right there that once you've got a machine", "tokens": [50716, 14808, 13232, 3479, 689, 415, 8137, 264, 3875, 1558, 558, 456, 300, 1564, 291, 600, 658, 257, 3479, 50980], "temperature": 0.0, "avg_logprob": -0.1216050148010254, "compression_ratio": 1.6130434782608696, "no_speech_prob": 0.00048727571265771985}, {"id": 129, "seek": 70648, "start": 718.8000000000001, "end": 726.5600000000001, "text": " which is smarter than a human, it will be able to design a machine which is smarter still,", "tokens": [50980, 597, 307, 20294, 813, 257, 1952, 11, 309, 486, 312, 1075, 281, 1715, 257, 3479, 597, 307, 20294, 920, 11, 51368], "temperature": 0.0, "avg_logprob": -0.1216050148010254, "compression_ratio": 1.6130434782608696, "no_speech_prob": 0.00048727571265771985}, {"id": 130, "seek": 70648, "start": 726.5600000000001, "end": 732.4, "text": " and then you're going to get recursive, runaway explosion of intelligence. I tried to analyze", "tokens": [51368, 293, 550, 291, 434, 516, 281, 483, 20560, 488, 11, 1190, 10318, 15673, 295, 7599, 13, 286, 3031, 281, 12477, 51660], "temperature": 0.0, "avg_logprob": -0.1216050148010254, "compression_ratio": 1.6130434782608696, "no_speech_prob": 0.00048727571265771985}, {"id": 131, "seek": 73240, "start": 732.4, "end": 738.48, "text": " that to set out that article, that argument in as much detail as I could, analyze where it could", "tokens": [50364, 300, 281, 992, 484, 300, 7222, 11, 300, 6770, 294, 382, 709, 2607, 382, 286, 727, 11, 12477, 689, 309, 727, 50668], "temperature": 0.0, "avg_logprob": -0.11121497194991152, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.027527151629328728}, {"id": 132, "seek": 73240, "start": 738.48, "end": 742.88, "text": " go right, where it could go wrong, what the possible obstacles would be, and it's a long story.", "tokens": [50668, 352, 558, 11, 689, 309, 727, 352, 2085, 11, 437, 264, 1944, 17735, 576, 312, 11, 293, 309, 311, 257, 938, 1657, 13, 50888], "temperature": 0.0, "avg_logprob": -0.11121497194991152, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.027527151629328728}, {"id": 133, "seek": 73240, "start": 743.84, "end": 750.16, "text": " If anyone wants to look it up, it's out there on my website. But I in the end became convinced", "tokens": [50936, 759, 2878, 2738, 281, 574, 309, 493, 11, 309, 311, 484, 456, 322, 452, 3144, 13, 583, 286, 294, 264, 917, 3062, 12561, 51252], "temperature": 0.0, "avg_logprob": -0.11121497194991152, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.027527151629328728}, {"id": 134, "seek": 73240, "start": 750.16, "end": 756.64, "text": " this is a pretty powerful argument. There's only so many ways it could go wrong. I think it's", "tokens": [51252, 341, 307, 257, 1238, 4005, 6770, 13, 821, 311, 787, 370, 867, 2098, 309, 727, 352, 2085, 13, 286, 519, 309, 311, 51576], "temperature": 0.0, "avg_logprob": -0.11121497194991152, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.027527151629328728}, {"id": 135, "seek": 73240, "start": 756.64, "end": 761.6, "text": " important that not every recursive augmentation process is going to lead to an intelligence", "tokens": [51576, 1021, 300, 406, 633, 20560, 488, 14501, 19631, 1399, 307, 516, 281, 1477, 281, 364, 7599, 51824], "temperature": 0.0, "avg_logprob": -0.11121497194991152, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.027527151629328728}, {"id": 136, "seek": 76160, "start": 761.6800000000001, "end": 766.88, "text": " explosion. It could easily bottom out, could asymptote before human intelligence. But I do", "tokens": [50368, 15673, 13, 467, 727, 3612, 2767, 484, 11, 727, 35114, 1370, 949, 1952, 7599, 13, 583, 286, 360, 50628], "temperature": 0.0, "avg_logprob": -0.06877348557958063, "compression_ratio": 1.9020408163265305, "no_speech_prob": 0.009995880536735058}, {"id": 137, "seek": 76160, "start": 766.88, "end": 771.2, "text": " think that once we start from greater than human intelligence, we have to find some way to get", "tokens": [50628, 519, 300, 1564, 321, 722, 490, 5044, 813, 1952, 7599, 11, 321, 362, 281, 915, 512, 636, 281, 483, 50844], "temperature": 0.0, "avg_logprob": -0.06877348557958063, "compression_ratio": 1.9020408163265305, "no_speech_prob": 0.009995880536735058}, {"id": 138, "seek": 76160, "start": 771.2, "end": 776.08, "text": " to greater than human intelligence first. This explosion won't get you that. But once you get", "tokens": [50844, 281, 5044, 813, 1952, 7599, 700, 13, 639, 15673, 1582, 380, 483, 291, 300, 13, 583, 1564, 291, 483, 51088], "temperature": 0.0, "avg_logprob": -0.06877348557958063, "compression_ratio": 1.9020408163265305, "no_speech_prob": 0.009995880536735058}, {"id": 139, "seek": 76160, "start": 776.08, "end": 782.24, "text": " there, then there's pretty good reason to think things in principle can take off from there.", "tokens": [51088, 456, 11, 550, 456, 311, 1238, 665, 1778, 281, 519, 721, 294, 8665, 393, 747, 766, 490, 456, 13, 51396], "temperature": 0.0, "avg_logprob": -0.06877348557958063, "compression_ratio": 1.9020408163265305, "no_speech_prob": 0.009995880536735058}, {"id": 140, "seek": 76160, "start": 782.24, "end": 788.88, "text": " If intelligence is extended, I'm a big fan of the idea that intelligence is extended into the", "tokens": [51396, 759, 7599, 307, 10913, 11, 286, 478, 257, 955, 3429, 295, 264, 1558, 300, 7599, 307, 10913, 666, 264, 51728], "temperature": 0.0, "avg_logprob": -0.06877348557958063, "compression_ratio": 1.9020408163265305, "no_speech_prob": 0.009995880536735058}, {"id": 141, "seek": 78888, "start": 788.88, "end": 795.28, "text": " environment. But as far as I can tell, all that can in principle be augmented too. We develop", "tokens": [50364, 2823, 13, 583, 382, 1400, 382, 286, 393, 980, 11, 439, 300, 393, 294, 8665, 312, 36155, 886, 13, 492, 1499, 50684], "temperature": 0.0, "avg_logprob": -0.12411398175118983, "compression_ratio": 1.6828193832599119, "no_speech_prob": 0.003590531647205353}, {"id": 142, "seek": 78888, "start": 795.28, "end": 801.76, "text": " extended systems, which are smarter than humans, and then they'll be able to design even better", "tokens": [50684, 10913, 3652, 11, 597, 366, 20294, 813, 6255, 11, 293, 550, 436, 603, 312, 1075, 281, 1715, 754, 1101, 51008], "temperature": 0.0, "avg_logprob": -0.12411398175118983, "compression_ratio": 1.6828193832599119, "no_speech_prob": 0.003590531647205353}, {"id": 143, "seek": 78888, "start": 801.76, "end": 809.2, "text": " extended systems. And we could then have an intelligence explosion of extended intelligences.", "tokens": [51008, 10913, 3652, 13, 400, 321, 727, 550, 362, 364, 7599, 15673, 295, 10913, 5613, 2667, 13, 51380], "temperature": 0.0, "avg_logprob": -0.12411398175118983, "compression_ratio": 1.6828193832599119, "no_speech_prob": 0.003590531647205353}, {"id": 144, "seek": 78888, "start": 809.2, "end": 814.72, "text": " So I'm actually, nothing about this gets you to human level intelligence. But once we get to human", "tokens": [51380, 407, 286, 478, 767, 11, 1825, 466, 341, 2170, 291, 281, 1952, 1496, 7599, 13, 583, 1564, 321, 483, 281, 1952, 51656], "temperature": 0.0, "avg_logprob": -0.12411398175118983, "compression_ratio": 1.6828193832599119, "no_speech_prob": 0.003590531647205353}, {"id": 145, "seek": 81472, "start": 814.72, "end": 820.5600000000001, "text": " level intelligence and a little bit beyond, then I think there's a pretty good case that there's some", "tokens": [50364, 1496, 7599, 293, 257, 707, 857, 4399, 11, 550, 286, 519, 456, 311, 257, 1238, 665, 1389, 300, 456, 311, 512, 50656], "temperature": 0.0, "avg_logprob": -0.11260311420147236, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.018235543742775917}, {"id": 146, "seek": 81472, "start": 820.5600000000001, "end": 826.1600000000001, "text": " kind of potential explosion in the offing. Then the other issue you mentioned Bostrom and the paper", "tokens": [50656, 733, 295, 3995, 15673, 294, 264, 766, 278, 13, 1396, 264, 661, 2734, 291, 2835, 363, 555, 4397, 293, 264, 3035, 50936], "temperature": 0.0, "avg_logprob": -0.11260311420147236, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.018235543742775917}, {"id": 147, "seek": 81472, "start": 826.1600000000001, "end": 832.8000000000001, "text": " clips is, yeah, what does this mean for the future of humanity? I guess I don't know what I'd say", "tokens": [50936, 13117, 307, 11, 1338, 11, 437, 775, 341, 914, 337, 264, 2027, 295, 10243, 30, 286, 2041, 286, 500, 380, 458, 437, 286, 1116, 584, 51268], "temperature": 0.0, "avg_logprob": -0.11260311420147236, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.018235543742775917}, {"id": 148, "seek": 81472, "start": 832.8000000000001, "end": 838.48, "text": " about the probabilities, but I'd say, yeah, once you have greater than human artificial general", "tokens": [51268, 466, 264, 33783, 11, 457, 286, 1116, 584, 11, 1338, 11, 1564, 291, 362, 5044, 813, 1952, 11677, 2674, 51552], "temperature": 0.0, "avg_logprob": -0.11260311420147236, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.018235543742775917}, {"id": 149, "seek": 81472, "start": 838.48, "end": 844.32, "text": " intelligence, then there's many ways that can go wrong for the obvious reasons that such a being", "tokens": [51552, 7599, 11, 550, 456, 311, 867, 2098, 300, 393, 352, 2085, 337, 264, 6322, 4112, 300, 1270, 257, 885, 51844], "temperature": 0.0, "avg_logprob": -0.11260311420147236, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.018235543742775917}, {"id": 150, "seek": 84432, "start": 844.32, "end": 850.0, "text": " is going to be extremely powerful. The most intelligent beings in the universe tend to be", "tokens": [50364, 307, 516, 281, 312, 4664, 4005, 13, 440, 881, 13232, 8958, 294, 264, 6445, 3928, 281, 312, 50648], "temperature": 0.0, "avg_logprob": -0.09129094017876518, "compression_ratio": 1.7072072072072073, "no_speech_prob": 0.0020453932229429483}, {"id": 151, "seek": 84432, "start": 850.0, "end": 856.4000000000001, "text": " the most powerful for obvious reasons. Whatever they want, they have the capacity to get. So it's", "tokens": [50648, 264, 881, 4005, 337, 6322, 4112, 13, 8541, 436, 528, 11, 436, 362, 264, 6042, 281, 483, 13, 407, 309, 311, 50968], "temperature": 0.0, "avg_logprob": -0.09129094017876518, "compression_ratio": 1.7072072072072073, "no_speech_prob": 0.0020453932229429483}, {"id": 152, "seek": 84432, "start": 856.4000000000001, "end": 863.6, "text": " going to be extremely important that our AGI systems want the right things. That is, they have", "tokens": [50968, 516, 281, 312, 4664, 1021, 300, 527, 316, 26252, 3652, 528, 264, 558, 721, 13, 663, 307, 11, 436, 362, 51328], "temperature": 0.0, "avg_logprob": -0.09129094017876518, "compression_ratio": 1.7072072072072073, "no_speech_prob": 0.0020453932229429483}, {"id": 153, "seek": 84432, "start": 863.6, "end": 869.12, "text": " the right kind of goals. Or as people put it, these days that they are aligned with human goals.", "tokens": [51328, 264, 558, 733, 295, 5493, 13, 1610, 382, 561, 829, 309, 11, 613, 1708, 300, 436, 366, 17962, 365, 1952, 5493, 13, 51604], "temperature": 0.0, "avg_logprob": -0.09129094017876518, "compression_ratio": 1.7072072072072073, "no_speech_prob": 0.0020453932229429483}, {"id": 154, "seek": 86912, "start": 870.0, "end": 875.76, "text": " Because if they're even a little bit misaligned, then there's going to be the capacity for things", "tokens": [50408, 1436, 498, 436, 434, 754, 257, 707, 857, 3346, 304, 16690, 11, 550, 456, 311, 516, 281, 312, 264, 6042, 337, 721, 50696], "temperature": 0.0, "avg_logprob": -0.08142436560937914, "compression_ratio": 1.7416974169741697, "no_speech_prob": 0.021584056317806244}, {"id": 155, "seek": 86912, "start": 875.76, "end": 879.84, "text": " to go very badly wrong. I know there are some people who think that the alignment is going to", "tokens": [50696, 281, 352, 588, 13425, 2085, 13, 286, 458, 456, 366, 512, 561, 567, 519, 300, 264, 18515, 307, 516, 281, 50900], "temperature": 0.0, "avg_logprob": -0.08142436560937914, "compression_ratio": 1.7416974169741697, "no_speech_prob": 0.021584056317806244}, {"id": 156, "seek": 86912, "start": 879.84, "end": 885.68, "text": " have to be so precise that, you know, missed by just the tiniest bit and will destroy the universe,", "tokens": [50900, 362, 281, 312, 370, 13600, 300, 11, 291, 458, 11, 6721, 538, 445, 264, 256, 3812, 377, 857, 293, 486, 5293, 264, 6445, 11, 51192], "temperature": 0.0, "avg_logprob": -0.08142436560937914, "compression_ratio": 1.7416974169741697, "no_speech_prob": 0.021584056317806244}, {"id": 157, "seek": 86912, "start": 885.68, "end": 891.6, "text": " whereas others think it's extremely robust. It may be more robust than that. I'm not", "tokens": [51192, 9735, 2357, 519, 309, 311, 4664, 13956, 13, 467, 815, 312, 544, 13956, 813, 300, 13, 286, 478, 406, 51488], "temperature": 0.0, "avg_logprob": -0.08142436560937914, "compression_ratio": 1.7416974169741697, "no_speech_prob": 0.021584056317806244}, {"id": 158, "seek": 86912, "start": 891.6, "end": 895.2, "text": " totally sure about that. But I'm certainly on the side of people who think we have to take this", "tokens": [51488, 3879, 988, 466, 300, 13, 583, 286, 478, 3297, 322, 264, 1252, 295, 561, 567, 519, 321, 362, 281, 747, 341, 51668], "temperature": 0.0, "avg_logprob": -0.08142436560937914, "compression_ratio": 1.7416974169741697, "no_speech_prob": 0.021584056317806244}, {"id": 159, "seek": 89520, "start": 895.2, "end": 901.2, "text": " issue extremely seriously. And there is at least potential existential risks here that if AGI is", "tokens": [50364, 2734, 4664, 6638, 13, 400, 456, 307, 412, 1935, 3995, 37133, 10888, 510, 300, 498, 316, 26252, 307, 50664], "temperature": 0.0, "avg_logprob": -0.13640916487749885, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.016359856352210045}, {"id": 160, "seek": 89520, "start": 901.2, "end": 907.2, "text": " produced in an unthinking way, perhaps say in a military or a financial context where there's", "tokens": [50664, 7126, 294, 364, 517, 39873, 636, 11, 4317, 584, 294, 257, 4632, 420, 257, 4669, 4319, 689, 456, 311, 50964], "temperature": 0.0, "avg_logprob": -0.13640916487749885, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.016359856352210045}, {"id": 161, "seek": 89520, "start": 907.2, "end": 917.9200000000001, "text": " an AI arms race, and we suddenly have greater than human AIs that can achieve arbitrary goals,", "tokens": [50964, 364, 7318, 5812, 4569, 11, 293, 321, 5800, 362, 5044, 813, 1952, 316, 6802, 300, 393, 4584, 23211, 5493, 11, 51500], "temperature": 0.0, "avg_logprob": -0.13640916487749885, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.016359856352210045}, {"id": 162, "seek": 89520, "start": 917.9200000000001, "end": 924.96, "text": " then suddenly it becomes an extremely sensitive matter what their goals are. So I'm certainly on", "tokens": [51500, 550, 5800, 309, 3643, 364, 4664, 9477, 1871, 437, 641, 5493, 366, 13, 407, 286, 478, 3297, 322, 51852], "temperature": 0.0, "avg_logprob": -0.13640916487749885, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.016359856352210045}, {"id": 163, "seek": 92496, "start": 924.96, "end": 928.1600000000001, "text": " Bostrom's side when it comes to, yeah, this is something we should take seriously.", "tokens": [50364, 363, 555, 4397, 311, 1252, 562, 309, 1487, 281, 11, 1338, 11, 341, 307, 746, 321, 820, 747, 6638, 13, 50524], "temperature": 0.0, "avg_logprob": -0.10658411546186967, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.000578997889533639}, {"id": 164, "seek": 92496, "start": 928.88, "end": 932.5600000000001, "text": " But isn't there a bit of, you know, it's a big distance to go from", "tokens": [50560, 583, 1943, 380, 456, 257, 857, 295, 11, 291, 458, 11, 309, 311, 257, 955, 4560, 281, 352, 490, 50744], "temperature": 0.0, "avg_logprob": -0.10658411546186967, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.000578997889533639}, {"id": 165, "seek": 92496, "start": 933.76, "end": 939.2800000000001, "text": " superior to human intelligence and achieve anything you want. I mean, I'm relatively", "tokens": [50804, 13028, 281, 1952, 7599, 293, 4584, 1340, 291, 528, 13, 286, 914, 11, 286, 478, 7226, 51080], "temperature": 0.0, "avg_logprob": -0.10658411546186967, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.000578997889533639}, {"id": 166, "seek": 92496, "start": 939.2800000000001, "end": 946.32, "text": " intelligent, but I can't achieve flight, you know, by myself without, you know, apparatus to do that", "tokens": [51080, 13232, 11, 457, 286, 393, 380, 4584, 7018, 11, 291, 458, 11, 538, 2059, 1553, 11, 291, 458, 11, 38573, 281, 360, 300, 51432], "temperature": 0.0, "avg_logprob": -0.10658411546186967, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.000578997889533639}, {"id": 167, "seek": 92496, "start": 946.32, "end": 951.0400000000001, "text": " and airplane wings, whatever. I mean, there are physical limitations in the world. And I think", "tokens": [51432, 293, 17130, 11405, 11, 2035, 13, 286, 914, 11, 456, 366, 4001, 15705, 294, 264, 1002, 13, 400, 286, 519, 51668], "temperature": 0.0, "avg_logprob": -0.10658411546186967, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.000578997889533639}, {"id": 168, "seek": 95104, "start": 951.04, "end": 955.1999999999999, "text": " sometimes there's this assumption that intelligence can kind of go to infinity,", "tokens": [50364, 2171, 456, 311, 341, 15302, 300, 7599, 393, 733, 295, 352, 281, 13202, 11, 50572], "temperature": 0.0, "avg_logprob": -0.10050365558037391, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.001699842163361609}, {"id": 169, "seek": 95104, "start": 955.1999999999999, "end": 960.8, "text": " where in fact, maybe intelligence itself kind of bottoms out at IQ 1000 or something, there's", "tokens": [50572, 689, 294, 1186, 11, 1310, 7599, 2564, 733, 295, 43413, 484, 412, 28921, 9714, 420, 746, 11, 456, 311, 50852], "temperature": 0.0, "avg_logprob": -0.10050365558037391, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.001699842163361609}, {"id": 170, "seek": 95104, "start": 960.8, "end": 965.36, "text": " just not much, you know, you can do beyond that certain IQ. I mean, isn't there a degree of", "tokens": [50852, 445, 406, 709, 11, 291, 458, 11, 291, 393, 360, 4399, 300, 1629, 28921, 13, 286, 914, 11, 1943, 380, 456, 257, 4314, 295, 51080], "temperature": 0.0, "avg_logprob": -0.10050365558037391, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.001699842163361609}, {"id": 171, "seek": 95104, "start": 966.16, "end": 972.4, "text": " kind of speculative, you know, extrapolation that we need to account for there?", "tokens": [51120, 733, 295, 49415, 11, 291, 458, 11, 48224, 399, 300, 321, 643, 281, 2696, 337, 456, 30, 51432], "temperature": 0.0, "avg_logprob": -0.10050365558037391, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.001699842163361609}, {"id": 172, "seek": 95104, "start": 973.8399999999999, "end": 977.92, "text": " I would say this is certainly one way that things could, that the argument could fail,", "tokens": [51504, 286, 576, 584, 341, 307, 3297, 472, 636, 300, 721, 727, 11, 300, 264, 6770, 727, 3061, 11, 51708], "temperature": 0.0, "avg_logprob": -0.10050365558037391, "compression_ratio": 1.6941176470588235, "no_speech_prob": 0.001699842163361609}, {"id": 173, "seek": 97792, "start": 977.92, "end": 981.4399999999999, "text": " is if it turns out that basically there are diminishing, there's some kind of intelligence", "tokens": [50364, 307, 498, 309, 4523, 484, 300, 1936, 456, 366, 15739, 3807, 11, 456, 311, 512, 733, 295, 7599, 50540], "temperature": 0.0, "avg_logprob": -0.09698433346218532, "compression_ratio": 2.013100436681223, "no_speech_prob": 0.009096462279558182}, {"id": 174, "seek": 97792, "start": 981.4399999999999, "end": 987.68, "text": " ceiling, and there's some kind of diminishing returns towards this. Just there is such a", "tokens": [50540, 13655, 11, 293, 456, 311, 512, 733, 295, 15739, 3807, 11247, 3030, 341, 13, 1449, 456, 307, 1270, 257, 50852], "temperature": 0.0, "avg_logprob": -0.09698433346218532, "compression_ratio": 2.013100436681223, "no_speech_prob": 0.009096462279558182}, {"id": 175, "seek": 97792, "start": 987.68, "end": 993.12, "text": " ceiling that we might find that when we make a being which is 10% smarter than us on some scale,", "tokens": [50852, 13655, 300, 321, 1062, 915, 300, 562, 321, 652, 257, 885, 597, 307, 1266, 4, 20294, 813, 505, 322, 512, 4373, 11, 51124], "temperature": 0.0, "avg_logprob": -0.09698433346218532, "compression_ratio": 2.013100436681223, "no_speech_prob": 0.009096462279558182}, {"id": 176, "seek": 97792, "start": 993.68, "end": 1000.24, "text": " it could only make a being which is 5% smarter than it. And that being will make a machine,", "tokens": [51152, 309, 727, 787, 652, 257, 885, 597, 307, 1025, 4, 20294, 813, 309, 13, 400, 300, 885, 486, 652, 257, 3479, 11, 51480], "temperature": 0.0, "avg_logprob": -0.09698433346218532, "compression_ratio": 2.013100436681223, "no_speech_prob": 0.009096462279558182}, {"id": 177, "seek": 97792, "start": 1000.24, "end": 1005.92, "text": " make a being which is only 2.5% smarter than it. And all this will kind of asymptote to some", "tokens": [51480, 652, 257, 885, 597, 307, 787, 568, 13, 20, 4, 20294, 813, 309, 13, 400, 439, 341, 486, 733, 295, 35114, 1370, 281, 512, 51764], "temperature": 0.0, "avg_logprob": -0.09698433346218532, "compression_ratio": 2.013100436681223, "no_speech_prob": 0.009096462279558182}, {"id": 178, "seek": 100592, "start": 1006.88, "end": 1012.0, "text": " intelligence ceiling. And I don't know, this turns on very subtle issues about the structure", "tokens": [50412, 7599, 13655, 13, 400, 286, 500, 380, 458, 11, 341, 4523, 322, 588, 13743, 2663, 466, 264, 3877, 50668], "temperature": 0.0, "avg_logprob": -0.09411070081922743, "compression_ratio": 1.8052434456928839, "no_speech_prob": 0.0010635355720296502}, {"id": 179, "seek": 100592, "start": 1012.0, "end": 1017.68, "text": " of intelligence space. I'm rather doubtful there is such an intelligence ceiling, or if there is", "tokens": [50668, 295, 7599, 1901, 13, 286, 478, 2831, 6385, 906, 456, 307, 1270, 364, 7599, 13655, 11, 420, 498, 456, 307, 50952], "temperature": 0.0, "avg_logprob": -0.09411070081922743, "compression_ratio": 1.8052434456928839, "no_speech_prob": 0.0010635355720296502}, {"id": 180, "seek": 100592, "start": 1017.68, "end": 1022.4, "text": " one, maybe it's something like, you know, the limits of computability compared to, you know,", "tokens": [50952, 472, 11, 1310, 309, 311, 746, 411, 11, 291, 458, 11, 264, 10406, 295, 2807, 2310, 5347, 281, 11, 291, 458, 11, 51188], "temperature": 0.0, "avg_logprob": -0.09411070081922743, "compression_ratio": 1.8052434456928839, "no_speech_prob": 0.0010635355720296502}, {"id": 181, "seek": 100592, "start": 1022.4, "end": 1027.84, "text": " hypercomputation that an infinite system could do. But I think that ceiling is so high that there's", "tokens": [51188, 9848, 1112, 2582, 399, 300, 364, 13785, 1185, 727, 360, 13, 583, 286, 519, 300, 13655, 307, 370, 1090, 300, 456, 311, 51460], "temperature": 0.0, "avg_logprob": -0.09411070081922743, "compression_ratio": 1.8052434456928839, "no_speech_prob": 0.0010635355720296502}, {"id": 182, "seek": 100592, "start": 1027.84, "end": 1034.08, "text": " room for an awful lot of super intelligence before we get there. But in any case, I would say that,", "tokens": [51460, 1808, 337, 364, 11232, 688, 295, 1687, 7599, 949, 321, 483, 456, 13, 583, 294, 604, 1389, 11, 286, 576, 584, 300, 11, 51772], "temperature": 0.0, "avg_logprob": -0.09411070081922743, "compression_ratio": 1.8052434456928839, "no_speech_prob": 0.0010635355720296502}, {"id": 183, "seek": 103408, "start": 1034.08, "end": 1039.04, "text": " you know, for the purposes of, say, caution and thinking about the future, I would just turn the", "tokens": [50364, 291, 458, 11, 337, 264, 9932, 295, 11, 584, 11, 23585, 293, 1953, 466, 264, 2027, 11, 286, 576, 445, 1261, 264, 50612], "temperature": 0.0, "avg_logprob": -0.06752482364917624, "compression_ratio": 1.8270676691729324, "no_speech_prob": 0.0024689824786037207}, {"id": 184, "seek": 103408, "start": 1039.04, "end": 1043.28, "text": " point back on you and say that the thought that there is such an intelligence ceiling is itself", "tokens": [50612, 935, 646, 322, 291, 293, 584, 300, 264, 1194, 300, 456, 307, 1270, 364, 7599, 13655, 307, 2564, 50824], "temperature": 0.0, "avg_logprob": -0.06752482364917624, "compression_ratio": 1.8270676691729324, "no_speech_prob": 0.0024689824786037207}, {"id": 185, "seek": 103408, "start": 1043.28, "end": 1048.3999999999999, "text": " an extremely speculative one. I wouldn't want to rely on this, on this extremely speculative thought", "tokens": [50824, 364, 4664, 49415, 472, 13, 286, 2759, 380, 528, 281, 10687, 322, 341, 11, 322, 341, 4664, 49415, 1194, 51080], "temperature": 0.0, "avg_logprob": -0.06752482364917624, "compression_ratio": 1.8270676691729324, "no_speech_prob": 0.0024689824786037207}, {"id": 186, "seek": 103408, "start": 1048.3999999999999, "end": 1053.84, "text": " to kind of protect us from, from the, you know, potential risks of AGI in the future. If there's", "tokens": [51080, 281, 733, 295, 2371, 505, 490, 11, 490, 264, 11, 291, 458, 11, 3995, 10888, 295, 316, 26252, 294, 264, 2027, 13, 759, 456, 311, 51352], "temperature": 0.0, "avg_logprob": -0.06752482364917624, "compression_ratio": 1.8270676691729324, "no_speech_prob": 0.0024689824786037207}, {"id": 187, "seek": 103408, "start": 1053.84, "end": 1059.84, "text": " only a 20% chance there's not such an intelligence ceiling, then this is something that we very", "tokens": [51352, 787, 257, 945, 4, 2931, 456, 311, 406, 1270, 364, 7599, 13655, 11, 550, 341, 307, 746, 300, 321, 588, 51652], "temperature": 0.0, "avg_logprob": -0.06752482364917624, "compression_ratio": 1.8270676691729324, "no_speech_prob": 0.0024689824786037207}, {"id": 188, "seek": 105984, "start": 1059.84, "end": 1064.72, "text": " much need to be, to be worrying about. Yeah, I mean, fair enough, it's certainly a risk factor.", "tokens": [50364, 709, 643, 281, 312, 11, 281, 312, 18788, 466, 13, 865, 11, 286, 914, 11, 3143, 1547, 11, 309, 311, 3297, 257, 3148, 5952, 13, 50608], "temperature": 0.0, "avg_logprob": -0.10782482147216797, "compression_ratio": 1.6701388888888888, "no_speech_prob": 0.01825772412121296}, {"id": 189, "seek": 105984, "start": 1064.72, "end": 1070.3999999999999, "text": " It's certainly something that we need to need to keep a handle on. Well, let me ask you about one", "tokens": [50608, 467, 311, 3297, 746, 300, 321, 643, 281, 643, 281, 1066, 257, 4813, 322, 13, 1042, 11, 718, 385, 1029, 291, 466, 472, 50892], "temperature": 0.0, "avg_logprob": -0.10782482147216797, "compression_ratio": 1.6701388888888888, "no_speech_prob": 0.01825772412121296}, {"id": 190, "seek": 105984, "start": 1070.3999999999999, "end": 1076.32, "text": " specific time there. So I'm thinking you're probably familiar with Carl Friston and, you know,", "tokens": [50892, 2685, 565, 456, 13, 407, 286, 478, 1953, 291, 434, 1391, 4963, 365, 14256, 1526, 47345, 293, 11, 291, 458, 11, 51188], "temperature": 0.0, "avg_logprob": -0.10782482147216797, "compression_ratio": 1.6701388888888888, "no_speech_prob": 0.01825772412121296}, {"id": 191, "seek": 105984, "start": 1076.32, "end": 1080.9599999999998, "text": " his free energy principle. And he sends his regards, by the way, we talked to him a couple", "tokens": [51188, 702, 1737, 2281, 8665, 13, 400, 415, 14790, 702, 14258, 11, 538, 264, 636, 11, 321, 2825, 281, 796, 257, 1916, 51420], "temperature": 0.0, "avg_logprob": -0.10782482147216797, "compression_ratio": 1.6701388888888888, "no_speech_prob": 0.01825772412121296}, {"id": 192, "seek": 105984, "start": 1080.9599999999998, "end": 1086.1599999999999, "text": " weeks back. And, and he wanted to ask you about kind of one line of thinking that he's been exploring", "tokens": [51420, 3259, 646, 13, 400, 11, 293, 415, 1415, 281, 1029, 291, 466, 733, 295, 472, 1622, 295, 1953, 300, 415, 311, 668, 12736, 51680], "temperature": 0.0, "avg_logprob": -0.10782482147216797, "compression_ratio": 1.6701388888888888, "no_speech_prob": 0.01825772412121296}, {"id": 193, "seek": 108616, "start": 1086.8000000000002, "end": 1092.72, "text": " lately. And I want to give you a quote from his 2018 article and my self conscious,", "tokens": [50396, 12881, 13, 400, 286, 528, 281, 976, 291, 257, 6513, 490, 702, 6096, 7222, 293, 452, 2698, 6648, 11, 50692], "temperature": 0.0, "avg_logprob": -0.10876616239547729, "compression_ratio": 1.5636363636363637, "no_speech_prob": 0.0034825392067432404}, {"id": 194, "seek": 108616, "start": 1092.72, "end": 1098.8000000000002, "text": " or does self organization entail self consciousness. And he said, the proposal on offer here", "tokens": [50692, 420, 775, 2698, 4475, 948, 864, 2698, 10081, 13, 400, 415, 848, 11, 264, 11494, 322, 2626, 510, 50996], "temperature": 0.0, "avg_logprob": -0.10876616239547729, "compression_ratio": 1.5636363636363637, "no_speech_prob": 0.0034825392067432404}, {"id": 195, "seek": 108616, "start": 1099.52, "end": 1104.96, "text": " is that the mind comes into being when self evidencing has a temporal thickness,", "tokens": [51032, 307, 300, 264, 1575, 1487, 666, 885, 562, 2698, 43699, 2175, 575, 257, 30881, 14855, 11, 51304], "temperature": 0.0, "avg_logprob": -0.10876616239547729, "compression_ratio": 1.5636363636363637, "no_speech_prob": 0.0034825392067432404}, {"id": 196, "seek": 108616, "start": 1105.68, "end": 1111.76, "text": " or counterfactual depth, which grounds inferences about the consequences of my action.", "tokens": [51340, 420, 5682, 44919, 901, 7161, 11, 597, 19196, 13596, 2667, 466, 264, 10098, 295, 452, 3069, 13, 51644], "temperature": 0.0, "avg_logprob": -0.10876616239547729, "compression_ratio": 1.5636363636363637, "no_speech_prob": 0.0034825392067432404}, {"id": 197, "seek": 111176, "start": 1112.48, "end": 1118.72, "text": " On this view, consciousness is nothing more than the inference about my future, namely,", "tokens": [50400, 1282, 341, 1910, 11, 10081, 307, 1825, 544, 813, 264, 38253, 466, 452, 2027, 11, 20926, 11, 50712], "temperature": 0.0, "avg_logprob": -0.09774733673442494, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.001283944584429264}, {"id": 198, "seek": 111176, "start": 1118.72, "end": 1125.12, "text": " self evidencing consequences of what I could do. What do you think about that, that perspective?", "tokens": [50712, 2698, 43699, 2175, 10098, 295, 437, 286, 727, 360, 13, 708, 360, 291, 519, 466, 300, 11, 300, 4585, 30, 51032], "temperature": 0.0, "avg_logprob": -0.09774733673442494, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.001283944584429264}, {"id": 199, "seek": 111176, "start": 1126.08, "end": 1130.56, "text": " Yeah, I'd have to know more about the connection to consciousness. I know that yeah, Friston is", "tokens": [51080, 865, 11, 286, 1116, 362, 281, 458, 544, 466, 264, 4984, 281, 10081, 13, 286, 458, 300, 1338, 11, 1526, 47345, 307, 51304], "temperature": 0.0, "avg_logprob": -0.09774733673442494, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.001283944584429264}, {"id": 200, "seek": 111176, "start": 1131.28, "end": 1137.04, "text": " very has developed very deeply the idea of the mind as a prediction machine, a mind which is", "tokens": [51340, 588, 575, 4743, 588, 8760, 264, 1558, 295, 264, 1575, 382, 257, 17630, 3479, 11, 257, 1575, 597, 307, 51628], "temperature": 0.0, "avg_logprob": -0.09774733673442494, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.001283944584429264}, {"id": 201, "seek": 113704, "start": 1137.04, "end": 1145.2, "text": " basically set up to, you know, predict whatever signal is coming next. And that's with that one", "tokens": [50364, 1936, 992, 493, 281, 11, 291, 458, 11, 6069, 2035, 6358, 307, 1348, 958, 13, 400, 300, 311, 365, 300, 472, 50772], "temperature": 0.0, "avg_logprob": -0.12272697366693969, "compression_ratio": 1.8495145631067962, "no_speech_prob": 0.009690143167972565}, {"id": 202, "seek": 113704, "start": 1145.2, "end": 1150.6399999999999, "text": " basic key loss, you know, predict what's next, what's next, what's next, then you get to build these", "tokens": [50772, 3875, 2141, 4470, 11, 291, 458, 11, 6069, 437, 311, 958, 11, 437, 311, 958, 11, 437, 311, 958, 11, 550, 291, 483, 281, 1322, 613, 51044], "temperature": 0.0, "avg_logprob": -0.12272697366693969, "compression_ratio": 1.8495145631067962, "no_speech_prob": 0.009690143167972565}, {"id": 203, "seek": 113704, "start": 1150.6399999999999, "end": 1157.76, "text": " amazing models of the world with all of these, all of these, these capacities. And that's a", "tokens": [51044, 2243, 5245, 295, 264, 1002, 365, 439, 295, 613, 11, 439, 295, 613, 11, 613, 39396, 13, 400, 300, 311, 257, 51400], "temperature": 0.0, "avg_logprob": -0.12272697366693969, "compression_ratio": 1.8495145631067962, "no_speech_prob": 0.009690143167972565}, {"id": 204, "seek": 113704, "start": 1157.76, "end": 1163.44, "text": " really interesting perspective thinking about the mind and intelligence in general. And it's", "tokens": [51400, 534, 1880, 4585, 1953, 466, 264, 1575, 293, 7599, 294, 2674, 13, 400, 309, 311, 51684], "temperature": 0.0, "avg_logprob": -0.12272697366693969, "compression_ratio": 1.8495145631067962, "no_speech_prob": 0.009690143167972565}, {"id": 205, "seek": 116344, "start": 1163.44, "end": 1169.76, "text": " got to be at least one huge part of the story, even if it's not the whole story as Friston thinks", "tokens": [50364, 658, 281, 312, 412, 1935, 472, 2603, 644, 295, 264, 1657, 11, 754, 498, 309, 311, 406, 264, 1379, 1657, 382, 1526, 47345, 7309, 50680], "temperature": 0.0, "avg_logprob": -0.09326267803416532, "compression_ratio": 1.6367521367521367, "no_speech_prob": 0.0009686386911198497}, {"id": 206, "seek": 116344, "start": 1169.76, "end": 1176.0800000000002, "text": " it is, but I've never really understood the distinct what this kind of predictive approach has to say", "tokens": [50680, 309, 307, 11, 457, 286, 600, 1128, 534, 7320, 264, 10644, 437, 341, 733, 295, 35521, 3109, 575, 281, 584, 50996], "temperature": 0.0, "avg_logprob": -0.09326267803416532, "compression_ratio": 1.6367521367521367, "no_speech_prob": 0.0009686386911198497}, {"id": 207, "seek": 116344, "start": 1176.0800000000002, "end": 1182.24, "text": " distinctively about consciousness. Because presumably there's a whole lot of different", "tokens": [50996, 10644, 3413, 466, 10081, 13, 1436, 26742, 456, 311, 257, 1379, 688, 295, 819, 51304], "temperature": 0.0, "avg_logprob": -0.09326267803416532, "compression_ratio": 1.6367521367521367, "no_speech_prob": 0.0009686386911198497}, {"id": 208, "seek": 116344, "start": 1182.24, "end": 1188.64, "text": " predictive processes at all kinds of levels of the hierarchy, including at the very early vision", "tokens": [51304, 35521, 7555, 412, 439, 3685, 295, 4358, 295, 264, 22333, 11, 3009, 412, 264, 588, 2440, 5201, 51624], "temperature": 0.0, "avg_logprob": -0.09326267803416532, "compression_ratio": 1.6367521367521367, "no_speech_prob": 0.0009686386911198497}, {"id": 209, "seek": 118864, "start": 1188.64, "end": 1194.4, "text": " and very late cognition, and the whole mind is engaged in coming up with these predictions,", "tokens": [50364, 293, 588, 3469, 46905, 11, 293, 264, 1379, 1575, 307, 8237, 294, 1348, 493, 365, 613, 21264, 11, 50652], "temperature": 0.0, "avg_logprob": -0.10319294119780918, "compression_ratio": 1.737037037037037, "no_speech_prob": 0.004190849140286446}, {"id": 210, "seek": 118864, "start": 1194.4, "end": 1201.6000000000001, "text": " but only some limited part of it is conscious. What you just said about, yeah, trying to figure out", "tokens": [50652, 457, 787, 512, 5567, 644, 295, 309, 307, 6648, 13, 708, 291, 445, 848, 466, 11, 1338, 11, 1382, 281, 2573, 484, 51012], "temperature": 0.0, "avg_logprob": -0.10319294119780918, "compression_ratio": 1.737037037037037, "no_speech_prob": 0.004190849140286446}, {"id": 211, "seek": 118864, "start": 1201.6000000000001, "end": 1205.92, "text": " the predictions consequent on our actions, sounds to me like a very general statement of", "tokens": [51012, 264, 21264, 7242, 317, 322, 527, 5909, 11, 3263, 281, 385, 411, 257, 588, 2674, 5629, 295, 51228], "temperature": 0.0, "avg_logprob": -0.10319294119780918, "compression_ratio": 1.737037037037037, "no_speech_prob": 0.004190849140286446}, {"id": 212, "seek": 118864, "start": 1207.0400000000002, "end": 1210.88, "text": " what the predictive approach says about the mind in general. And I haven't yet heard what is the", "tokens": [51284, 437, 264, 35521, 3109, 1619, 466, 264, 1575, 294, 2674, 13, 400, 286, 2378, 380, 1939, 2198, 437, 307, 264, 51476], "temperature": 0.0, "avg_logprob": -0.10319294119780918, "compression_ratio": 1.737037037037037, "no_speech_prob": 0.004190849140286446}, {"id": 213, "seek": 118864, "start": 1210.88, "end": 1216.16, "text": " part that corresponds to consciousness. Why, for example, or some representations get to be", "tokens": [51476, 644, 300, 23249, 281, 10081, 13, 1545, 11, 337, 1365, 11, 420, 512, 33358, 483, 281, 312, 51740], "temperature": 0.0, "avg_logprob": -0.10319294119780918, "compression_ratio": 1.737037037037037, "no_speech_prob": 0.004190849140286446}, {"id": 214, "seek": 121616, "start": 1216.16, "end": 1221.0400000000002, "text": " conscious where so much of it in the brain is not, I can give you I can give you a bit more", "tokens": [50364, 6648, 689, 370, 709, 295, 309, 294, 264, 3567, 307, 406, 11, 286, 393, 976, 291, 286, 393, 976, 291, 257, 857, 544, 50608], "temperature": 0.0, "avg_logprob": -0.13575058929191147, "compression_ratio": 1.6597222222222223, "no_speech_prob": 0.001987194176763296}, {"id": 215, "seek": 121616, "start": 1221.0400000000002, "end": 1227.0400000000002, "text": " detail, which may be helpful, because we did dig into him with a on a bit. And he said, for one thing,", "tokens": [50608, 2607, 11, 597, 815, 312, 4961, 11, 570, 321, 630, 2528, 666, 796, 365, 257, 322, 257, 857, 13, 400, 415, 848, 11, 337, 472, 551, 11, 50908], "temperature": 0.0, "avg_logprob": -0.13575058929191147, "compression_ratio": 1.6597222222222223, "no_speech_prob": 0.001987194176763296}, {"id": 216, "seek": 121616, "start": 1227.0400000000002, "end": 1232.8000000000002, "text": " he expected that perhaps part of your response might might entail or talk about the meta hard", "tokens": [50908, 415, 5176, 300, 4317, 644, 295, 428, 4134, 1062, 1062, 948, 864, 420, 751, 466, 264, 19616, 1152, 51196], "temperature": 0.0, "avg_logprob": -0.13575058929191147, "compression_ratio": 1.6597222222222223, "no_speech_prob": 0.001987194176763296}, {"id": 217, "seek": 121616, "start": 1232.8000000000002, "end": 1238.3200000000002, "text": " problem. You know, why is it that certain beings, i.e. things like philosophers, and people like you", "tokens": [51196, 1154, 13, 509, 458, 11, 983, 307, 309, 300, 1629, 8958, 11, 741, 13, 68, 13, 721, 411, 36839, 11, 293, 561, 411, 291, 51472], "temperature": 0.0, "avg_logprob": -0.13575058929191147, "compression_ratio": 1.6597222222222223, "no_speech_prob": 0.001987194176763296}, {"id": 218, "seek": 121616, "start": 1238.3200000000002, "end": 1242.96, "text": " and me puzzle so much about our qualitative experience. And the argument he makes there,", "tokens": [51472, 293, 385, 12805, 370, 709, 466, 527, 31312, 1752, 13, 400, 264, 6770, 415, 1669, 456, 11, 51704], "temperature": 0.0, "avg_logprob": -0.13575058929191147, "compression_ratio": 1.6597222222222223, "no_speech_prob": 0.001987194176763296}, {"id": 219, "seek": 124296, "start": 1242.96, "end": 1248.32, "text": " he says that if we are inference machines that are built to actively self evidence,", "tokens": [50364, 415, 1619, 300, 498, 321, 366, 38253, 8379, 300, 366, 3094, 281, 13022, 2698, 4467, 11, 50632], "temperature": 0.0, "avg_logprob": -0.05173984828748201, "compression_ratio": 2.027027027027027, "no_speech_prob": 0.0012063262984156609}, {"id": 220, "seek": 124296, "start": 1248.32, "end": 1253.8400000000001, "text": " then that necessarily entails we need to have a generative model about our experienced world.", "tokens": [50632, 550, 300, 4725, 50133, 321, 643, 281, 362, 257, 1337, 1166, 2316, 466, 527, 6751, 1002, 13, 50908], "temperature": 0.0, "avg_logprob": -0.05173984828748201, "compression_ratio": 2.027027027027027, "no_speech_prob": 0.0012063262984156609}, {"id": 221, "seek": 124296, "start": 1254.48, "end": 1259.76, "text": " And if we have that that generative model about our experience world, our experience world,", "tokens": [50940, 400, 498, 321, 362, 300, 300, 1337, 1166, 2316, 466, 527, 1752, 1002, 11, 527, 1752, 1002, 11, 51204], "temperature": 0.0, "avg_logprob": -0.05173984828748201, "compression_ratio": 2.027027027027027, "no_speech_prob": 0.0012063262984156609}, {"id": 222, "seek": 124296, "start": 1259.76, "end": 1266.64, "text": " then we have to entertain the hypothesis that we are things having a qualitative experience,", "tokens": [51204, 550, 321, 362, 281, 7655, 264, 17291, 300, 321, 366, 721, 1419, 257, 31312, 1752, 11, 51548], "temperature": 0.0, "avg_logprob": -0.05173984828748201, "compression_ratio": 2.027027027027027, "no_speech_prob": 0.0012063262984156609}, {"id": 223, "seek": 124296, "start": 1266.64, "end": 1271.76, "text": " along with the alternate to that hypothesis, which is that we're not having qualitative", "tokens": [51548, 2051, 365, 264, 18873, 281, 300, 17291, 11, 597, 307, 300, 321, 434, 406, 1419, 31312, 51804], "temperature": 0.0, "avg_logprob": -0.05173984828748201, "compression_ratio": 2.027027027027027, "no_speech_prob": 0.0012063262984156609}, {"id": 224, "seek": 127176, "start": 1271.76, "end": 1277.04, "text": " experiences. And so essentially that the capability to model the world generatively", "tokens": [50364, 5235, 13, 400, 370, 4476, 300, 264, 13759, 281, 2316, 264, 1002, 1337, 19020, 50628], "temperature": 0.0, "avg_logprob": -0.11530592890069036, "compression_ratio": 1.7604562737642586, "no_speech_prob": 0.00030523649184033275}, {"id": 225, "seek": 127176, "start": 1277.6, "end": 1282.96, "text": " really requires that we entertain this hypothesis that we're actually having qualitative experiences", "tokens": [50656, 534, 7029, 300, 321, 7655, 341, 17291, 300, 321, 434, 767, 1419, 31312, 5235, 50924], "temperature": 0.0, "avg_logprob": -0.11530592890069036, "compression_ratio": 1.7604562737642586, "no_speech_prob": 0.00030523649184033275}, {"id": 226, "seek": 127176, "start": 1282.96, "end": 1288.64, "text": " or maybe not. And that's why we pontificate about it. Yeah, it's interesting. And I think the meta", "tokens": [50924, 420, 1310, 406, 13, 400, 300, 311, 983, 321, 18770, 1089, 473, 466, 309, 13, 865, 11, 309, 311, 1880, 13, 400, 286, 519, 264, 19616, 51208], "temperature": 0.0, "avg_logprob": -0.11530592890069036, "compression_ratio": 1.7604562737642586, "no_speech_prob": 0.00030523649184033275}, {"id": 227, "seek": 127176, "start": 1288.64, "end": 1294.48, "text": " problem is a, yeah, as a promising approach is the meta problem is your why do we say and think", "tokens": [51208, 1154, 307, 257, 11, 1338, 11, 382, 257, 20257, 3109, 307, 264, 19616, 1154, 307, 428, 983, 360, 321, 584, 293, 519, 51500], "temperature": 0.0, "avg_logprob": -0.11530592890069036, "compression_ratio": 1.7604562737642586, "no_speech_prob": 0.00030523649184033275}, {"id": 228, "seek": 127176, "start": 1294.48, "end": 1299.04, "text": " the things we do about consciousness, instead of explaining consciousness directly,", "tokens": [51500, 264, 721, 321, 360, 466, 10081, 11, 2602, 295, 13468, 10081, 3838, 11, 51728], "temperature": 0.0, "avg_logprob": -0.11530592890069036, "compression_ratio": 1.7604562737642586, "no_speech_prob": 0.00030523649184033275}, {"id": 229, "seek": 129904, "start": 1299.04, "end": 1306.32, "text": " let's explain, you know, our internal model of consciousness. And yeah, there's got to be", "tokens": [50364, 718, 311, 2903, 11, 291, 458, 11, 527, 6920, 2316, 295, 10081, 13, 400, 1338, 11, 456, 311, 658, 281, 312, 50728], "temperature": 0.0, "avg_logprob": -0.10385856431784089, "compression_ratio": 1.603448275862069, "no_speech_prob": 0.0012630446581169963}, {"id": 230, "seek": 129904, "start": 1306.32, "end": 1312.0, "text": " such a model. So I think this is a promising approach to take. I still don't fully, I mean,", "tokens": [50728, 1270, 257, 2316, 13, 407, 286, 519, 341, 307, 257, 20257, 3109, 281, 747, 13, 286, 920, 500, 380, 4498, 11, 286, 914, 11, 51012], "temperature": 0.0, "avg_logprob": -0.10385856431784089, "compression_ratio": 1.603448275862069, "no_speech_prob": 0.0012630446581169963}, {"id": 231, "seek": 129904, "start": 1312.0, "end": 1316.48, "text": " I think if you take the predictive approach, so what you would expect is, is the system would have", "tokens": [51012, 286, 519, 498, 291, 747, 264, 35521, 3109, 11, 370, 437, 291, 576, 2066, 307, 11, 307, 264, 1185, 576, 362, 51236], "temperature": 0.0, "avg_logprob": -0.10385856431784089, "compression_ratio": 1.603448275862069, "no_speech_prob": 0.0012630446581169963}, {"id": 232, "seek": 129904, "start": 1316.48, "end": 1322.24, "text": " many different models, you know, a big complex model of the world at all levels, it doesn't", "tokens": [51236, 867, 819, 5245, 11, 291, 458, 11, 257, 955, 3997, 2316, 295, 264, 1002, 412, 439, 4358, 11, 309, 1177, 380, 51524], "temperature": 0.0, "avg_logprob": -0.10385856431784089, "compression_ratio": 1.603448275862069, "no_speech_prob": 0.0012630446581169963}, {"id": 233, "seek": 132224, "start": 1322.24, "end": 1329.36, "text": " just correspond to experienced reality, but the models the world way beyond what's experienced,", "tokens": [50364, 445, 6805, 281, 6751, 4103, 11, 457, 264, 5245, 264, 1002, 636, 4399, 437, 311, 6751, 11, 50720], "temperature": 0.0, "avg_logprob": -0.1252134944615739, "compression_ratio": 1.7971014492753623, "no_speech_prob": 0.011291048489511013}, {"id": 234, "seek": 132224, "start": 1329.36, "end": 1336.64, "text": " it would also you'd also expect the model to have a model of the mind to have a model of ourselves", "tokens": [50720, 309, 576, 611, 291, 1116, 611, 2066, 264, 2316, 281, 362, 257, 2316, 295, 264, 1575, 281, 362, 257, 2316, 295, 4175, 51084], "temperature": 0.0, "avg_logprob": -0.1252134944615739, "compression_ratio": 1.7971014492753623, "no_speech_prob": 0.011291048489511013}, {"id": 235, "seek": 132224, "start": 1336.64, "end": 1342.0, "text": " and relation to the world. But what actually happens in the in the human mind is we have,", "tokens": [51084, 293, 9721, 281, 264, 1002, 13, 583, 437, 767, 2314, 294, 264, 294, 264, 1952, 1575, 307, 321, 362, 11, 51352], "temperature": 0.0, "avg_logprob": -0.1252134944615739, "compression_ratio": 1.7971014492753623, "no_speech_prob": 0.011291048489511013}, {"id": 236, "seek": 132224, "start": 1343.1200000000001, "end": 1347.28, "text": " we have models at all levels, you know, there's like so many different levels of say of", "tokens": [51408, 321, 362, 5245, 412, 439, 4358, 11, 291, 458, 11, 456, 311, 411, 370, 867, 819, 4358, 295, 584, 295, 51616], "temperature": 0.0, "avg_logprob": -0.1252134944615739, "compression_ratio": 1.7971014492753623, "no_speech_prob": 0.011291048489511013}, {"id": 237, "seek": 134728, "start": 1347.28, "end": 1354.96, "text": " representation, even in the visual hierarchy. And somehow, though, only one of those", "tokens": [50364, 10290, 11, 754, 294, 264, 5056, 22333, 13, 400, 6063, 11, 1673, 11, 787, 472, 295, 729, 50748], "temperature": 0.0, "avg_logprob": -0.09998140983211184, "compression_ratio": 1.717557251908397, "no_speech_prob": 0.001031443476676941}, {"id": 238, "seek": 134728, "start": 1354.96, "end": 1358.72, "text": " levels seems to correspond to consciousness. The question is, why now do we need a distinctive", "tokens": [50748, 4358, 2544, 281, 6805, 281, 10081, 13, 440, 1168, 307, 11, 983, 586, 360, 321, 643, 257, 27766, 50936], "temperature": 0.0, "avg_logprob": -0.09998140983211184, "compression_ratio": 1.717557251908397, "no_speech_prob": 0.001031443476676941}, {"id": 239, "seek": 134728, "start": 1358.72, "end": 1366.56, "text": " model of those representations in us, which correspond to conscious experience? One idea,", "tokens": [50936, 2316, 295, 729, 33358, 294, 505, 11, 597, 6805, 281, 6648, 1752, 30, 1485, 1558, 11, 51328], "temperature": 0.0, "avg_logprob": -0.09998140983211184, "compression_ratio": 1.717557251908397, "no_speech_prob": 0.001031443476676941}, {"id": 240, "seek": 134728, "start": 1366.56, "end": 1371.04, "text": " I think, one idea I quite like is that this could be like a simplification. In fact,", "tokens": [51328, 286, 519, 11, 472, 1558, 286, 1596, 411, 307, 300, 341, 727, 312, 411, 257, 6883, 3774, 13, 682, 1186, 11, 51552], "temperature": 0.0, "avg_logprob": -0.09998140983211184, "compression_ratio": 1.717557251908397, "no_speech_prob": 0.001031443476676941}, {"id": 241, "seek": 134728, "start": 1371.04, "end": 1376.16, "text": " we have millions of layers of representation of the world. But to build all that into our model", "tokens": [51552, 321, 362, 6803, 295, 7914, 295, 10290, 295, 264, 1002, 13, 583, 281, 1322, 439, 300, 666, 527, 2316, 51808], "temperature": 0.0, "avg_logprob": -0.09998140983211184, "compression_ratio": 1.717557251908397, "no_speech_prob": 0.001031443476676941}, {"id": 242, "seek": 137616, "start": 1376.16, "end": 1381.3600000000001, "text": " of ourselves, and our relation of the world is going to be too complex. So we basically,", "tokens": [50364, 295, 4175, 11, 293, 527, 9721, 295, 264, 1002, 307, 516, 281, 312, 886, 3997, 13, 407, 321, 1936, 11, 50624], "temperature": 0.0, "avg_logprob": -0.08680286238678789, "compression_ratio": 1.8, "no_speech_prob": 0.0009091438842006028}, {"id": 243, "seek": 137616, "start": 1382.0, "end": 1387.28, "text": " we oversimplify by saying, ah, there's this one special relationship we have to the world,", "tokens": [50656, 321, 15488, 332, 564, 2505, 538, 1566, 11, 3716, 11, 456, 311, 341, 472, 2121, 2480, 321, 362, 281, 264, 1002, 11, 50920], "temperature": 0.0, "avg_logprob": -0.08680286238678789, "compression_ratio": 1.8, "no_speech_prob": 0.0009091438842006028}, {"id": 244, "seek": 137616, "start": 1387.28, "end": 1393.1200000000001, "text": " we call it consciousness or experience. And yet we experience certain things and then we use them", "tokens": [50920, 321, 818, 309, 10081, 420, 1752, 13, 400, 1939, 321, 1752, 1629, 721, 293, 550, 321, 764, 552, 51212], "temperature": 0.0, "avg_logprob": -0.08680286238678789, "compression_ratio": 1.8, "no_speech_prob": 0.0009091438842006028}, {"id": 245, "seek": 137616, "start": 1393.1200000000001, "end": 1398.88, "text": " to reason about them. And this is massively oversimplified as a model of the mind. But it could", "tokens": [51212, 281, 1778, 466, 552, 13, 400, 341, 307, 29379, 15488, 332, 564, 2587, 382, 257, 2316, 295, 264, 1575, 13, 583, 309, 727, 51500], "temperature": 0.0, "avg_logprob": -0.08680286238678789, "compression_ratio": 1.8, "no_speech_prob": 0.0009091438842006028}, {"id": 246, "seek": 137616, "start": 1398.88, "end": 1404.24, "text": " be that that simplification is then what actually gives us the sense that we have this special", "tokens": [51500, 312, 300, 300, 6883, 3774, 307, 550, 437, 767, 2709, 505, 264, 2020, 300, 321, 362, 341, 2121, 51768], "temperature": 0.0, "avg_logprob": -0.08680286238678789, "compression_ratio": 1.8, "no_speech_prob": 0.0009091438842006028}, {"id": 247, "seek": 140424, "start": 1404.24, "end": 1408.56, "text": " thing called consciousness. At least maybe that could explain why it seems to us that we have", "tokens": [50364, 551, 1219, 10081, 13, 1711, 1935, 1310, 300, 727, 2903, 983, 309, 2544, 281, 505, 300, 321, 362, 50580], "temperature": 0.0, "avg_logprob": -0.10827135086059571, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.0016971469158306718}, {"id": 248, "seek": 140424, "start": 1408.56, "end": 1415.28, "text": " some special representations of the world. It's a further question why those conscious", "tokens": [50580, 512, 2121, 33358, 295, 264, 1002, 13, 467, 311, 257, 3052, 1168, 983, 729, 6648, 50916], "temperature": 0.0, "avg_logprob": -0.10827135086059571, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.0016971469158306718}, {"id": 249, "seek": 140424, "start": 1415.28, "end": 1421.36, "text": " representations should seem to be so ineffable and subjective and hard to explain. And what", "tokens": [50916, 33358, 820, 1643, 281, 312, 370, 7167, 602, 712, 293, 25972, 293, 1152, 281, 2903, 13, 400, 437, 51220], "temperature": 0.0, "avg_logprob": -0.10827135086059571, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.0016971469158306718}, {"id": 250, "seek": 140424, "start": 1421.36, "end": 1426.16, "text": " in what Carl has written about this, I think he and Andy Clark had some ideas about the meta", "tokens": [51220, 294, 437, 14256, 575, 3720, 466, 341, 11, 286, 519, 415, 293, 13285, 18572, 632, 512, 3487, 466, 264, 19616, 51460], "temperature": 0.0, "avg_logprob": -0.10827135086059571, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.0016971469158306718}, {"id": 251, "seek": 140424, "start": 1426.16, "end": 1431.1200000000001, "text": " problem to try and push on this. Maybe that maybe there'd be certain representations that", "tokens": [51460, 1154, 281, 853, 293, 2944, 322, 341, 13, 2704, 300, 1310, 456, 1116, 312, 1629, 33358, 300, 51708], "temperature": 0.0, "avg_logprob": -0.10827135086059571, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.0016971469158306718}, {"id": 252, "seek": 143112, "start": 1431.1999999999998, "end": 1435.52, "text": " we'd have to be especially certain that we have them. Maybe that would give rise to", "tokens": [50368, 321, 1116, 362, 281, 312, 2318, 1629, 300, 321, 362, 552, 13, 2704, 300, 576, 976, 6272, 281, 50584], "temperature": 0.0, "avg_logprob": -0.13884135189219418, "compression_ratio": 1.715415019762846, "no_speech_prob": 0.006265363190323114}, {"id": 253, "seek": 143112, "start": 1436.32, "end": 1441.6799999999998, "text": " the Descartes idea that, well, I'm not sure about the world, but I know that I'm thinking.", "tokens": [50624, 264, 3885, 44672, 279, 1558, 300, 11, 731, 11, 286, 478, 406, 988, 466, 264, 1002, 11, 457, 286, 458, 300, 286, 478, 1953, 13, 50892], "temperature": 0.0, "avg_logprob": -0.13884135189219418, "compression_ratio": 1.715415019762846, "no_speech_prob": 0.006265363190323114}, {"id": 254, "seek": 143112, "start": 1442.6399999999999, "end": 1447.84, "text": " I think, therefore, I am. And they had some kind of story about how this could get the whole,", "tokens": [50940, 286, 519, 11, 4412, 11, 286, 669, 13, 400, 436, 632, 512, 733, 295, 1657, 466, 577, 341, 727, 483, 264, 1379, 11, 51200], "temperature": 0.0, "avg_logprob": -0.13884135189219418, "compression_ratio": 1.715415019762846, "no_speech_prob": 0.006265363190323114}, {"id": 255, "seek": 143112, "start": 1447.84, "end": 1453.6, "text": " I think, therefore, I am certainty in one's own mind going. Anyway, I think it's an interesting", "tokens": [51200, 286, 519, 11, 4412, 11, 286, 669, 27022, 294, 472, 311, 1065, 1575, 516, 13, 5684, 11, 286, 519, 309, 311, 364, 1880, 51488], "temperature": 0.0, "avg_logprob": -0.13884135189219418, "compression_ratio": 1.715415019762846, "no_speech_prob": 0.006265363190323114}, {"id": 256, "seek": 143112, "start": 1453.6, "end": 1456.7199999999998, "text": " approach and I'll be very cool to see if they can develop it further.", "tokens": [51488, 3109, 293, 286, 603, 312, 588, 1627, 281, 536, 498, 436, 393, 1499, 309, 3052, 13, 51644], "temperature": 0.0, "avg_logprob": -0.13884135189219418, "compression_ratio": 1.715415019762846, "no_speech_prob": 0.006265363190323114}, {"id": 257, "seek": 145672, "start": 1456.96, "end": 1461.6000000000001, "text": " Fascinating. I wanted to dig into this modeling thing. I was even thinking a second ago when", "tokens": [50376, 49098, 8205, 13, 286, 1415, 281, 2528, 666, 341, 15983, 551, 13, 286, 390, 754, 1953, 257, 1150, 2057, 562, 50608], "temperature": 0.0, "avg_logprob": -0.10881668521511939, "compression_ratio": 1.7941176470588236, "no_speech_prob": 0.001120447413995862}, {"id": 258, "seek": 145672, "start": 1461.6000000000001, "end": 1466.08, "text": " you were talking about intelligence, that straight away you did the Hutter thing and", "tokens": [50608, 291, 645, 1417, 466, 7599, 11, 300, 2997, 1314, 291, 630, 264, 389, 9947, 551, 293, 50832], "temperature": 0.0, "avg_logprob": -0.10881668521511939, "compression_ratio": 1.7941176470588236, "no_speech_prob": 0.001120447413995862}, {"id": 259, "seek": 145672, "start": 1466.08, "end": 1471.04, "text": " we're talking about agents performing in environments and so on. And even that is a model.", "tokens": [50832, 321, 434, 1417, 466, 12554, 10205, 294, 12388, 293, 370, 322, 13, 400, 754, 300, 307, 257, 2316, 13, 51080], "temperature": 0.0, "avg_logprob": -0.10881668521511939, "compression_ratio": 1.7941176470588236, "no_speech_prob": 0.001120447413995862}, {"id": 260, "seek": 145672, "start": 1471.04, "end": 1475.28, "text": " And of course, we're talking about complex phenomena and the way we model things depends", "tokens": [51080, 400, 295, 1164, 11, 321, 434, 1417, 466, 3997, 22004, 293, 264, 636, 321, 2316, 721, 5946, 51292], "temperature": 0.0, "avg_logprob": -0.10881668521511939, "compression_ratio": 1.7941176470588236, "no_speech_prob": 0.001120447413995862}, {"id": 261, "seek": 145672, "start": 1475.28, "end": 1480.64, "text": " on the level of analysis. But I'm really fascinated by this idea that some phenomena is so complex", "tokens": [51292, 322, 264, 1496, 295, 5215, 13, 583, 286, 478, 534, 24597, 538, 341, 1558, 300, 512, 22004, 307, 370, 3997, 51560], "temperature": 0.0, "avg_logprob": -0.10881668521511939, "compression_ratio": 1.7941176470588236, "no_speech_prob": 0.001120447413995862}, {"id": 262, "seek": 145672, "start": 1480.64, "end": 1485.52, "text": " that it cannot be formalized or communicated, almost as if there's a representation problem.", "tokens": [51560, 300, 309, 2644, 312, 9860, 1602, 420, 34989, 11, 1920, 382, 498, 456, 311, 257, 10290, 1154, 13, 51804], "temperature": 0.0, "avg_logprob": -0.10881668521511939, "compression_ratio": 1.7941176470588236, "no_speech_prob": 0.001120447413995862}, {"id": 263, "seek": 148552, "start": 1485.52, "end": 1489.2, "text": " Now, you discussed in your consciousness book whether consciousness itself could be", "tokens": [50364, 823, 11, 291, 7152, 294, 428, 10081, 1446, 1968, 10081, 2564, 727, 312, 50548], "temperature": 0.0, "avg_logprob": -0.08832761976453993, "compression_ratio": 1.8698224852071006, "no_speech_prob": 0.0029220266733318567}, {"id": 264, "seek": 148552, "start": 1489.2, "end": 1494.0, "text": " reductively explained and your knowledge argument, you spoke of this neuroscientist Mary", "tokens": [50548, 2783, 349, 3413, 8825, 293, 428, 3601, 6770, 11, 291, 7179, 295, 341, 28813, 5412, 468, 6059, 50788], "temperature": 0.0, "avg_logprob": -0.08832761976453993, "compression_ratio": 1.8698224852071006, "no_speech_prob": 0.0029220266733318567}, {"id": 265, "seek": 148552, "start": 1494.0, "end": 1497.6, "text": " that had been brought up in a black and white room. She's never seen any colors except for", "tokens": [50788, 300, 632, 668, 3038, 493, 294, 257, 2211, 293, 2418, 1808, 13, 1240, 311, 1128, 1612, 604, 4577, 3993, 337, 50968], "temperature": 0.0, "avg_logprob": -0.08832761976453993, "compression_ratio": 1.8698224852071006, "no_speech_prob": 0.0029220266733318567}, {"id": 266, "seek": 148552, "start": 1497.6, "end": 1501.44, "text": " black and white and shades of gray. She's nevertheless one of the world's leading", "tokens": [50968, 2211, 293, 2418, 293, 20639, 295, 10855, 13, 1240, 311, 26924, 472, 295, 264, 1002, 311, 5775, 51160], "temperature": 0.0, "avg_logprob": -0.08832761976453993, "compression_ratio": 1.8698224852071006, "no_speech_prob": 0.0029220266733318567}, {"id": 267, "seek": 148552, "start": 1501.44, "end": 1505.6, "text": " neuroscientists specializing in neurophysiology of color vision. She knows everything there is", "tokens": [51160, 28813, 5412, 1751, 2121, 3319, 294, 16499, 950, 749, 46457, 295, 2017, 5201, 13, 1240, 3255, 1203, 456, 307, 51368], "temperature": 0.0, "avg_logprob": -0.08832761976453993, "compression_ratio": 1.8698224852071006, "no_speech_prob": 0.0029220266733318567}, {"id": 268, "seek": 148552, "start": 1505.6, "end": 1510.24, "text": " to know about neural processes involved in visual information processing, about the physics of", "tokens": [51368, 281, 458, 466, 18161, 7555, 3288, 294, 5056, 1589, 9007, 11, 466, 264, 10649, 295, 51600], "temperature": 0.0, "avg_logprob": -0.08832761976453993, "compression_ratio": 1.8698224852071006, "no_speech_prob": 0.0029220266733318567}, {"id": 269, "seek": 148552, "start": 1510.24, "end": 1514.96, "text": " optical processes, about the physical makeup of objects in the environment. But she doesn't know", "tokens": [51600, 20674, 7555, 11, 466, 264, 4001, 6567, 295, 6565, 294, 264, 2823, 13, 583, 750, 1177, 380, 458, 51836], "temperature": 0.0, "avg_logprob": -0.08832761976453993, "compression_ratio": 1.8698224852071006, "no_speech_prob": 0.0029220266733318567}, {"id": 270, "seek": 151496, "start": 1515.04, "end": 1519.6000000000001, "text": " what it's like to see red. No amount of reasoning from physical facts alone will give her this", "tokens": [50368, 437, 309, 311, 411, 281, 536, 2182, 13, 883, 2372, 295, 21577, 490, 4001, 9130, 3312, 486, 976, 720, 341, 50596], "temperature": 0.0, "avg_logprob": -0.07420559077299843, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.0017732672858983278}, {"id": 271, "seek": 151496, "start": 1519.6000000000001, "end": 1525.52, "text": " knowledge. Physical facts about systems do not tell us what their conscious experiences are like.", "tokens": [50596, 3601, 13, 31918, 9130, 466, 3652, 360, 406, 980, 505, 437, 641, 6648, 5235, 366, 411, 13, 50892], "temperature": 0.0, "avg_logprob": -0.07420559077299843, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.0017732672858983278}, {"id": 272, "seek": 151496, "start": 1525.52, "end": 1530.8, "text": " Now, you're speaking about this phenomenon in respect of the conscious or the phenomenological", "tokens": [50892, 823, 11, 291, 434, 4124, 466, 341, 14029, 294, 3104, 295, 264, 6648, 420, 264, 9388, 4383, 51156], "temperature": 0.0, "avg_logprob": -0.07420559077299843, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.0017732672858983278}, {"id": 273, "seek": 151496, "start": 1530.8, "end": 1535.28, "text": " experience. But I think it's a much bigger problem of representation with any complex system, right?", "tokens": [51156, 1752, 13, 583, 286, 519, 309, 311, 257, 709, 3801, 1154, 295, 10290, 365, 604, 3997, 1185, 11, 558, 30, 51380], "temperature": 0.0, "avg_logprob": -0.07420559077299843, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.0017732672858983278}, {"id": 274, "seek": 151496, "start": 1535.28, "end": 1539.3600000000001, "text": " So what I find fascinating is that all of us have a conscious experience, but it's completely", "tokens": [51380, 407, 437, 286, 915, 10343, 307, 300, 439, 295, 505, 362, 257, 6648, 1752, 11, 457, 309, 311, 2584, 51584], "temperature": 0.0, "avg_logprob": -0.07420559077299843, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.0017732672858983278}, {"id": 275, "seek": 151496, "start": 1539.3600000000001, "end": 1543.68, "text": " ineffable, as you just said, it's impossible for us to communicate it to others. And whenever", "tokens": [51584, 7167, 602, 712, 11, 382, 291, 445, 848, 11, 309, 311, 6243, 337, 505, 281, 7890, 309, 281, 2357, 13, 400, 5699, 51800], "temperature": 0.0, "avg_logprob": -0.07420559077299843, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.0017732672858983278}, {"id": 276, "seek": 154368, "start": 1543.68, "end": 1548.0800000000002, "text": " we try to do so, we're reaching, right? Just like the blind men in the elephant, we end up defining", "tokens": [50364, 321, 853, 281, 360, 370, 11, 321, 434, 9906, 11, 558, 30, 1449, 411, 264, 6865, 1706, 294, 264, 19791, 11, 321, 917, 493, 17827, 50584], "temperature": 0.0, "avg_logprob": -0.06417411395481655, "compression_ratio": 1.7190332326283988, "no_speech_prob": 0.0020473250187933445}, {"id": 277, "seek": 154368, "start": 1548.0800000000002, "end": 1553.44, "text": " some weird abstract motif, right? Chopping off 90% of the truth. The thing that fascinates me is", "tokens": [50584, 512, 3657, 12649, 39478, 11, 558, 30, 25615, 3381, 766, 4289, 4, 295, 264, 3494, 13, 440, 551, 300, 7184, 259, 1024, 385, 307, 50852], "temperature": 0.0, "avg_logprob": -0.06417411395481655, "compression_ratio": 1.7190332326283988, "no_speech_prob": 0.0020473250187933445}, {"id": 278, "seek": 154368, "start": 1553.44, "end": 1558.0800000000002, "text": " that we need to have some kind of formalism or reduction in order to communicate, you know,", "tokens": [50852, 300, 321, 643, 281, 362, 512, 733, 295, 9860, 1434, 420, 11004, 294, 1668, 281, 7890, 11, 291, 458, 11, 51084], "temperature": 0.0, "avg_logprob": -0.06417411395481655, "compression_ratio": 1.7190332326283988, "no_speech_prob": 0.0020473250187933445}, {"id": 279, "seek": 154368, "start": 1558.0800000000002, "end": 1562.5600000000002, "text": " in order to know or even understand anything. But so often is the case that all of the nuance", "tokens": [51084, 294, 1668, 281, 458, 420, 754, 1223, 1340, 13, 583, 370, 2049, 307, 264, 1389, 300, 439, 295, 264, 42625, 51308], "temperature": 0.0, "avg_logprob": -0.06417411395481655, "compression_ratio": 1.7190332326283988, "no_speech_prob": 0.0020473250187933445}, {"id": 280, "seek": 154368, "start": 1562.5600000000002, "end": 1568.0800000000002, "text": " and richness of the phenomena is lost in doing so. So I suspect that any formalism of a complex", "tokens": [51308, 293, 44506, 295, 264, 22004, 307, 2731, 294, 884, 370, 13, 407, 286, 9091, 300, 604, 9860, 1434, 295, 257, 3997, 51584], "temperature": 0.0, "avg_logprob": -0.06417411395481655, "compression_ratio": 1.7190332326283988, "no_speech_prob": 0.0020473250187933445}, {"id": 281, "seek": 154368, "start": 1568.0800000000002, "end": 1572.16, "text": " system might blind us from discovering a much better and richer formalism later because it", "tokens": [51584, 1185, 1062, 6865, 505, 490, 24773, 257, 709, 1101, 293, 29021, 9860, 1434, 1780, 570, 309, 51788], "temperature": 0.0, "avg_logprob": -0.06417411395481655, "compression_ratio": 1.7190332326283988, "no_speech_prob": 0.0020473250187933445}, {"id": 282, "seek": 157216, "start": 1572.16, "end": 1577.44, "text": " kind of frames our thinking in quite a pernicious way in your book. So as I said, you were trying", "tokens": [50364, 733, 295, 12083, 527, 1953, 294, 1596, 257, 680, 77, 3784, 636, 294, 428, 1446, 13, 407, 382, 286, 848, 11, 291, 645, 1382, 50628], "temperature": 0.0, "avg_logprob": -0.09911988576253256, "compression_ratio": 1.6130434782608696, "no_speech_prob": 0.0003097003500442952}, {"id": 283, "seek": 157216, "start": 1577.44, "end": 1582.48, "text": " to separate the phenomenological experience as something that couldn't be described. But do", "tokens": [50628, 281, 4994, 264, 9388, 4383, 1752, 382, 746, 300, 2809, 380, 312, 7619, 13, 583, 360, 50880], "temperature": 0.0, "avg_logprob": -0.09911988576253256, "compression_ratio": 1.6130434782608696, "no_speech_prob": 0.0003097003500442952}, {"id": 284, "seek": 157216, "start": 1582.48, "end": 1590.24, "text": " you think it could be extended to any complex system? Well, we don't. As far as we know,", "tokens": [50880, 291, 519, 309, 727, 312, 10913, 281, 604, 3997, 1185, 30, 1042, 11, 321, 500, 380, 13, 1018, 1400, 382, 321, 458, 11, 51268], "temperature": 0.0, "avg_logprob": -0.09911988576253256, "compression_ratio": 1.6130434782608696, "no_speech_prob": 0.0003097003500442952}, {"id": 285, "seek": 157216, "start": 1590.24, "end": 1595.92, "text": " you know, some complex systems actually have conscious subjective experience. But, you know,", "tokens": [51268, 291, 458, 11, 512, 3997, 3652, 767, 362, 6648, 25972, 1752, 13, 583, 11, 291, 458, 11, 51552], "temperature": 0.0, "avg_logprob": -0.09911988576253256, "compression_ratio": 1.6130434782608696, "no_speech_prob": 0.0003097003500442952}, {"id": 286, "seek": 159592, "start": 1596.0, "end": 1602.88, "text": " most of them don't. You know, this Mac that I'm using right now is a very complex system,", "tokens": [50368, 881, 295, 552, 500, 380, 13, 509, 458, 11, 341, 5707, 300, 286, 478, 1228, 558, 586, 307, 257, 588, 3997, 1185, 11, 50712], "temperature": 0.0, "avg_logprob": -0.1013601151379672, "compression_ratio": 1.6244541484716157, "no_speech_prob": 0.002320214407518506}, {"id": 287, "seek": 159592, "start": 1602.88, "end": 1607.8400000000001, "text": " but not much reason to think that it's conscious despite the complexity of what's going on", "tokens": [50712, 457, 406, 709, 1778, 281, 519, 300, 309, 311, 6648, 7228, 264, 14024, 295, 437, 311, 516, 322, 50960], "temperature": 0.0, "avg_logprob": -0.1013601151379672, "compression_ratio": 1.6244541484716157, "no_speech_prob": 0.002320214407518506}, {"id": 288, "seek": 159592, "start": 1607.8400000000001, "end": 1613.3600000000001, "text": " within it. So certain kinds of complexity go along with consciousness. But if we were to kind of", "tokens": [50960, 1951, 309, 13, 407, 1629, 3685, 295, 14024, 352, 2051, 365, 10081, 13, 583, 498, 321, 645, 281, 733, 295, 51236], "temperature": 0.0, "avg_logprob": -0.1013601151379672, "compression_ratio": 1.6244541484716157, "no_speech_prob": 0.002320214407518506}, {"id": 289, "seek": 159592, "start": 1613.3600000000001, "end": 1618.64, "text": " return to that meta problem approach for a moment, maybe there are certain kinds of properties", "tokens": [51236, 2736, 281, 300, 19616, 1154, 3109, 337, 257, 1623, 11, 1310, 456, 366, 1629, 3685, 295, 7221, 51500], "temperature": 0.0, "avg_logprob": -0.1013601151379672, "compression_ratio": 1.6244541484716157, "no_speech_prob": 0.002320214407518506}, {"id": 290, "seek": 161864, "start": 1619.5200000000002, "end": 1624.96, "text": " of a complex system that tend to produce reports, for example, that the system", "tokens": [50408, 295, 257, 3997, 1185, 300, 3928, 281, 5258, 7122, 11, 337, 1365, 11, 300, 264, 1185, 50680], "temperature": 0.0, "avg_logprob": -0.08433194593949751, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.007453965023159981}, {"id": 291, "seek": 161864, "start": 1624.96, "end": 1632.5600000000002, "text": " is conscious. So maybe some complex systems have the capacity for a certain kind of direct", "tokens": [50680, 307, 6648, 13, 407, 1310, 512, 3997, 3652, 362, 264, 6042, 337, 257, 1629, 733, 295, 2047, 51060], "temperature": 0.0, "avg_logprob": -0.08433194593949751, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.007453965023159981}, {"id": 292, "seek": 161864, "start": 1632.5600000000002, "end": 1637.5200000000002, "text": " self-modeling that corresponds to what we think of as introspection. We have introspection,", "tokens": [51060, 2698, 12, 8014, 11031, 300, 23249, 281, 437, 321, 519, 295, 382, 560, 2635, 19997, 13, 492, 362, 560, 2635, 19997, 11, 51308], "temperature": 0.0, "avg_logprob": -0.08433194593949751, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.007453965023159981}, {"id": 293, "seek": 161864, "start": 1637.5200000000002, "end": 1642.4, "text": " which is a way of saying, this is what I'm perceiving right now. This is what I'm thinking", "tokens": [51308, 597, 307, 257, 636, 295, 1566, 11, 341, 307, 437, 286, 478, 9016, 2123, 558, 586, 13, 639, 307, 437, 286, 478, 1953, 51552], "temperature": 0.0, "avg_logprob": -0.08433194593949751, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.007453965023159981}, {"id": 294, "seek": 164240, "start": 1642.48, "end": 1648.3200000000002, "text": " right now. This is what I'm feeling right now. And we build a model of ourselves,", "tokens": [50368, 558, 586, 13, 639, 307, 437, 286, 478, 2633, 558, 586, 13, 400, 321, 1322, 257, 2316, 295, 4175, 11, 50660], "temperature": 0.0, "avg_logprob": -0.06701270114170031, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.007813279516994953}, {"id": 295, "seek": 164240, "start": 1648.3200000000002, "end": 1652.96, "text": " and it may well be that that model is highly oversimplified. You don't have access", "tokens": [50660, 293, 309, 815, 731, 312, 300, 300, 2316, 307, 5405, 15488, 332, 564, 2587, 13, 509, 500, 380, 362, 2105, 50892], "temperature": 0.0, "avg_logprob": -0.06701270114170031, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.007813279516994953}, {"id": 296, "seek": 164240, "start": 1652.96, "end": 1659.6000000000001, "text": " to all these facts about ourselves. So perhaps you could tell a story where the kinds of complex", "tokens": [50892, 281, 439, 613, 9130, 466, 4175, 13, 407, 4317, 291, 727, 980, 257, 1657, 689, 264, 3685, 295, 3997, 51224], "temperature": 0.0, "avg_logprob": -0.06701270114170031, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.007813279516994953}, {"id": 297, "seek": 164240, "start": 1659.6000000000001, "end": 1664.8000000000002, "text": " systems that give rise at least to this capacity for introspection are then at least going to report", "tokens": [51224, 3652, 300, 976, 6272, 412, 1935, 281, 341, 6042, 337, 560, 2635, 19997, 366, 550, 412, 1935, 516, 281, 2275, 51484], "temperature": 0.0, "avg_logprob": -0.06701270114170031, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.007813279516994953}, {"id": 298, "seek": 166480, "start": 1664.8, "end": 1673.2, "text": " themselves as being conscious. And maybe that could get at some element, maybe sort of the", "tokens": [50364, 2969, 382, 885, 6648, 13, 400, 1310, 300, 727, 483, 412, 512, 4478, 11, 1310, 1333, 295, 264, 50784], "temperature": 0.0, "avg_logprob": -0.1347935994466146, "compression_ratio": 1.4540816326530612, "no_speech_prob": 0.07154309749603271}, {"id": 299, "seek": 166480, "start": 1673.2, "end": 1681.84, "text": " ineffability of consciousness. You'd expect to build these very simplified self-models. We wouldn't", "tokens": [50784, 7167, 602, 2310, 295, 10081, 13, 509, 1116, 2066, 281, 1322, 613, 588, 26335, 2698, 12, 8014, 1625, 13, 492, 2759, 380, 51216], "temperature": 0.0, "avg_logprob": -0.1347935994466146, "compression_ratio": 1.4540816326530612, "no_speech_prob": 0.07154309749603271}, {"id": 300, "seek": 166480, "start": 1681.84, "end": 1690.6399999999999, "text": " know immediately how to extend to other people. I mean, I still think, in principle, you could", "tokens": [51216, 458, 4258, 577, 281, 10101, 281, 661, 561, 13, 286, 914, 11, 286, 920, 519, 11, 294, 8665, 11, 291, 727, 51656], "temperature": 0.0, "avg_logprob": -0.1347935994466146, "compression_ratio": 1.4540816326530612, "no_speech_prob": 0.07154309749603271}, {"id": 301, "seek": 169064, "start": 1690.64, "end": 1695.5200000000002, "text": " take Mary, who knows all about the human brain, and she could come to know all about those models", "tokens": [50364, 747, 6059, 11, 567, 3255, 439, 466, 264, 1952, 3567, 11, 293, 750, 727, 808, 281, 458, 439, 466, 729, 5245, 50608], "temperature": 0.0, "avg_logprob": -0.07964246207420979, "compression_ratio": 1.8532818532818534, "no_speech_prob": 0.01742473430931568}, {"id": 302, "seek": 169064, "start": 1696.0800000000002, "end": 1701.68, "text": " in other people. But it still seems that she's never actually experienced red for herself.", "tokens": [50636, 294, 661, 561, 13, 583, 309, 920, 2544, 300, 750, 311, 1128, 767, 6751, 2182, 337, 7530, 13, 50916], "temperature": 0.0, "avg_logprob": -0.07964246207420979, "compression_ratio": 1.8532818532818534, "no_speech_prob": 0.01742473430931568}, {"id": 303, "seek": 169064, "start": 1701.68, "end": 1706.0800000000002, "text": " There's still something really crucial about this objective experience that she doesn't know.", "tokens": [50916, 821, 311, 920, 746, 534, 11462, 466, 341, 10024, 1752, 300, 750, 1177, 380, 458, 13, 51136], "temperature": 0.0, "avg_logprob": -0.07964246207420979, "compression_ratio": 1.8532818532818534, "no_speech_prob": 0.01742473430931568}, {"id": 304, "seek": 169064, "start": 1706.0800000000002, "end": 1710.8000000000002, "text": " She doesn't know what it's like to experience red, and knowing all about the details of the model", "tokens": [51136, 1240, 1177, 380, 458, 437, 309, 311, 411, 281, 1752, 2182, 11, 293, 5276, 439, 466, 264, 4365, 295, 264, 2316, 51372], "temperature": 0.0, "avg_logprob": -0.07964246207420979, "compression_ratio": 1.8532818532818534, "no_speech_prob": 0.01742473430931568}, {"id": 305, "seek": 169064, "start": 1710.8000000000002, "end": 1716.4, "text": " still hasn't told her that. So I think that's still something that needs explaining. Some people at", "tokens": [51372, 920, 6132, 380, 1907, 720, 300, 13, 407, 286, 519, 300, 311, 920, 746, 300, 2203, 13468, 13, 2188, 561, 412, 51652], "temperature": 0.0, "avg_logprob": -0.07964246207420979, "compression_ratio": 1.8532818532818534, "no_speech_prob": 0.01742473430931568}, {"id": 306, "seek": 171640, "start": 1716.4, "end": 1723.1200000000001, "text": " this point just say that sense of something extra is an illusion. Something extra that the model", "tokens": [50364, 341, 935, 445, 584, 300, 2020, 295, 746, 2857, 307, 364, 18854, 13, 6595, 2857, 300, 264, 2316, 50700], "temperature": 0.0, "avg_logprob": -0.11204774205277605, "compression_ratio": 1.7129186602870814, "no_speech_prob": 0.0007656894158571959}, {"id": 307, "seek": 171640, "start": 1723.1200000000001, "end": 1727.44, "text": " hasn't explained is an illusion. But that's really where a lot of the action is at then.", "tokens": [50700, 6132, 380, 8825, 307, 364, 18854, 13, 583, 300, 311, 534, 689, 257, 688, 295, 264, 3069, 307, 412, 550, 13, 50916], "temperature": 0.0, "avg_logprob": -0.11204774205277605, "compression_ratio": 1.7129186602870814, "no_speech_prob": 0.0007656894158571959}, {"id": 308, "seek": 171640, "start": 1730.0800000000002, "end": 1733.92, "text": " Just quickly, do you think there could be a sense of something extra to intelligence,", "tokens": [51048, 1449, 2661, 11, 360, 291, 519, 456, 727, 312, 257, 2020, 295, 746, 2857, 281, 7599, 11, 51240], "temperature": 0.0, "avg_logprob": -0.11204774205277605, "compression_ratio": 1.7129186602870814, "no_speech_prob": 0.0007656894158571959}, {"id": 309, "seek": 171640, "start": 1733.92, "end": 1741.6000000000001, "text": " as well as consciousness? Probably, yeah, we model our own intelligence with massively", "tokens": [51240, 382, 731, 382, 10081, 30, 9210, 11, 1338, 11, 321, 2316, 527, 1065, 7599, 365, 29379, 51624], "temperature": 0.0, "avg_logprob": -0.11204774205277605, "compression_ratio": 1.7129186602870814, "no_speech_prob": 0.0007656894158571959}, {"id": 310, "seek": 174160, "start": 1741.6, "end": 1750.3999999999999, "text": " oversimplified self-models that were programmed into us by nature that model us as these agents", "tokens": [50364, 15488, 332, 564, 2587, 2698, 12, 8014, 1625, 300, 645, 31092, 666, 505, 538, 3687, 300, 2316, 505, 382, 613, 12554, 50804], "temperature": 0.0, "avg_logprob": -0.1518862247467041, "compression_ratio": 1.7239819004524888, "no_speech_prob": 0.0010981069644913077}, {"id": 311, "seek": 174160, "start": 1750.3999999999999, "end": 1760.32, "text": " with incredible capacities, free will, rationality, reason. It probably, again, it will, yeah, maybe", "tokens": [50804, 365, 4651, 39396, 11, 1737, 486, 11, 15090, 507, 11, 1778, 13, 467, 1391, 11, 797, 11, 309, 486, 11, 1338, 11, 1310, 51300], "temperature": 0.0, "avg_logprob": -0.1518862247467041, "compression_ratio": 1.7239819004524888, "no_speech_prob": 0.0010981069644913077}, {"id": 312, "seek": 174160, "start": 1760.9599999999998, "end": 1764.8, "text": " I talked about consciousness is involving the subjective elements, intelligence is involving", "tokens": [51332, 286, 2825, 466, 10081, 307, 17030, 264, 25972, 4959, 11, 7599, 307, 17030, 51524], "temperature": 0.0, "avg_logprob": -0.1518862247467041, "compression_ratio": 1.7239819004524888, "no_speech_prob": 0.0010981069644913077}, {"id": 313, "seek": 174160, "start": 1764.8, "end": 1770.3999999999999, "text": " the objective elements. But yeah, we probably have oversimplified models of those conscious", "tokens": [51524, 264, 10024, 4959, 13, 583, 1338, 11, 321, 1391, 362, 15488, 332, 564, 2587, 5245, 295, 729, 6648, 51804], "temperature": 0.0, "avg_logprob": -0.1518862247467041, "compression_ratio": 1.7239819004524888, "no_speech_prob": 0.0010981069644913077}, {"id": 314, "seek": 177160, "start": 1772.3999999999999, "end": 1778.8, "text": " of those behavioral elements as well, perhaps that make us out to be more rational, or more free,", "tokens": [50404, 295, 729, 19124, 4959, 382, 731, 11, 4317, 300, 652, 505, 484, 281, 312, 544, 15090, 11, 420, 544, 1737, 11, 50724], "temperature": 0.0, "avg_logprob": -0.11979912627827037, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.00011911201727343723}, {"id": 315, "seek": 177160, "start": 1779.76, "end": 1787.9199999999998, "text": " or more capable than we actually are. I wanted to ask, what is an interesting simulation? Is", "tokens": [50772, 420, 544, 8189, 813, 321, 767, 366, 13, 286, 1415, 281, 1029, 11, 437, 307, 364, 1880, 16575, 30, 1119, 51180], "temperature": 0.0, "avg_logprob": -0.11979912627827037, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.00011911201727343723}, {"id": 316, "seek": 177160, "start": 1787.9199999999998, "end": 1793.28, "text": " our universe interesting or not? Because we represent just a pinprick of intelligence. So", "tokens": [51180, 527, 6445, 1880, 420, 406, 30, 1436, 321, 2906, 445, 257, 5447, 1424, 618, 295, 7599, 13, 407, 51448], "temperature": 0.0, "avg_logprob": -0.11979912627827037, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.00011911201727343723}, {"id": 317, "seek": 177160, "start": 1793.28, "end": 1798.8, "text": " should intelligence be more spread out in the eyes of the simulator? Or in the vast majority of", "tokens": [51448, 820, 7599, 312, 544, 3974, 484, 294, 264, 2575, 295, 264, 32974, 30, 1610, 294, 264, 8369, 6286, 295, 51724], "temperature": 0.0, "avg_logprob": -0.11979912627827037, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.00011911201727343723}, {"id": 318, "seek": 179880, "start": 1798.8, "end": 1803.52, "text": " instances, would there just be gas everywhere or a singularity? Maybe stars can't form.", "tokens": [50364, 14519, 11, 576, 456, 445, 312, 4211, 5315, 420, 257, 20010, 507, 30, 2704, 6105, 393, 380, 1254, 13, 50600], "temperature": 0.0, "avg_logprob": -0.09478826522827148, "compression_ratio": 1.7022058823529411, "no_speech_prob": 0.002908179769292474}, {"id": 319, "seek": 179880, "start": 1804.3999999999999, "end": 1810.32, "text": " Maybe the interesting phenomena itself is on the boundary between chaos and order,", "tokens": [50644, 2704, 264, 1880, 22004, 2564, 307, 322, 264, 12866, 1296, 14158, 293, 1668, 11, 50940], "temperature": 0.0, "avg_logprob": -0.09478826522827148, "compression_ratio": 1.7022058823529411, "no_speech_prob": 0.002908179769292474}, {"id": 320, "seek": 179880, "start": 1811.04, "end": 1815.44, "text": " or between order and disorder, I should say, which is just a tiny sliver. So what do you think", "tokens": [50976, 420, 1296, 1668, 293, 13399, 11, 286, 820, 584, 11, 597, 307, 445, 257, 5870, 1061, 1837, 13, 407, 437, 360, 291, 519, 51196], "temperature": 0.0, "avg_logprob": -0.09478826522827148, "compression_ratio": 1.7022058823529411, "no_speech_prob": 0.002908179769292474}, {"id": 321, "seek": 179880, "start": 1815.44, "end": 1820.72, "text": " makes an interesting simulation? I don't know. I think it probably depends on your perspective,", "tokens": [51196, 1669, 364, 1880, 16575, 30, 286, 500, 380, 458, 13, 286, 519, 309, 1391, 5946, 322, 428, 4585, 11, 51460], "temperature": 0.0, "avg_logprob": -0.09478826522827148, "compression_ratio": 1.7022058823529411, "no_speech_prob": 0.002908179769292474}, {"id": 322, "seek": 179880, "start": 1820.72, "end": 1826.96, "text": " and it might, for example, depend on the perspective of the simulators, what they're after. One thing", "tokens": [51460, 293, 309, 1062, 11, 337, 1365, 11, 5672, 322, 264, 4585, 295, 264, 1034, 39265, 11, 437, 436, 434, 934, 13, 1485, 551, 51772], "temperature": 0.0, "avg_logprob": -0.09478826522827148, "compression_ratio": 1.7022058823529411, "no_speech_prob": 0.002908179769292474}, {"id": 323, "seek": 182696, "start": 1826.96, "end": 1832.4, "text": " that a simulator might be doing is just create a whole lot of different universes with different", "tokens": [50364, 300, 257, 32974, 1062, 312, 884, 307, 445, 1884, 257, 1379, 688, 295, 819, 50168, 365, 819, 50636], "temperature": 0.0, "avg_logprob": -0.10028012045498552, "compression_ratio": 1.8532818532818534, "no_speech_prob": 0.002710512140765786}, {"id": 324, "seek": 182696, "start": 1832.4, "end": 1839.6000000000001, "text": " potential laws of physics that they're simulating just to see what happens. And maybe if they're", "tokens": [50636, 3995, 6064, 295, 10649, 300, 436, 434, 1034, 12162, 445, 281, 536, 437, 2314, 13, 400, 1310, 498, 436, 434, 50996], "temperature": 0.0, "avg_logprob": -0.10028012045498552, "compression_ratio": 1.8532818532818534, "no_speech_prob": 0.002710512140765786}, {"id": 325, "seek": 182696, "start": 1839.6000000000001, "end": 1843.8400000000001, "text": " interested in, say, life or intelligence, then it could be that they're going to find that, okay,", "tokens": [50996, 3102, 294, 11, 584, 11, 993, 420, 7599, 11, 550, 309, 727, 312, 300, 436, 434, 516, 281, 915, 300, 11, 1392, 11, 51208], "temperature": 0.0, "avg_logprob": -0.10028012045498552, "compression_ratio": 1.8532818532818534, "no_speech_prob": 0.002710512140765786}, {"id": 326, "seek": 182696, "start": 1843.8400000000001, "end": 1849.3600000000001, "text": " well, 99% of these simulations don't produce anything like life or intelligence. And yeah,", "tokens": [51208, 731, 11, 11803, 4, 295, 613, 35138, 500, 380, 5258, 1340, 411, 993, 420, 7599, 13, 400, 1338, 11, 51484], "temperature": 0.0, "avg_logprob": -0.10028012045498552, "compression_ratio": 1.8532818532818534, "no_speech_prob": 0.002710512140765786}, {"id": 327, "seek": 182696, "start": 1849.3600000000001, "end": 1856.08, "text": " 1% of them produce life, and 0.01% lead to intelligence. So if that's what they're interested in,", "tokens": [51484, 502, 4, 295, 552, 5258, 993, 11, 293, 1958, 13, 10607, 4, 1477, 281, 7599, 13, 407, 498, 300, 311, 437, 436, 434, 3102, 294, 11, 51820], "temperature": 0.0, "avg_logprob": -0.10028012045498552, "compression_ratio": 1.8532818532818534, "no_speech_prob": 0.002710512140765786}, {"id": 328, "seek": 185696, "start": 1857.04, "end": 1862.72, "text": " in studying, fantastic. But they might be interested in who's to say the laws of physics or", "tokens": [50368, 294, 7601, 11, 5456, 13, 583, 436, 1062, 312, 3102, 294, 567, 311, 281, 584, 264, 6064, 295, 10649, 420, 50652], "temperature": 0.0, "avg_logprob": -0.10139423487137775, "compression_ratio": 1.6917293233082706, "no_speech_prob": 0.0007789348601363599}, {"id": 329, "seek": 185696, "start": 1862.72, "end": 1868.56, "text": " galaxy formation, more generally, totally independent of life and intelligence. So I don't", "tokens": [50652, 17639, 11723, 11, 544, 5101, 11, 3879, 6695, 295, 993, 293, 7599, 13, 407, 286, 500, 380, 50944], "temperature": 0.0, "avg_logprob": -0.10139423487137775, "compression_ratio": 1.6917293233082706, "no_speech_prob": 0.0007789348601363599}, {"id": 330, "seek": 185696, "start": 1868.56, "end": 1874.64, "text": " think there's any single standard of what's interesting. I mean, to me, as a philosopher", "tokens": [50944, 519, 456, 311, 604, 2167, 3832, 295, 437, 311, 1880, 13, 286, 914, 11, 281, 385, 11, 382, 257, 29805, 51248], "temperature": 0.0, "avg_logprob": -0.10139423487137775, "compression_ratio": 1.6917293233082706, "no_speech_prob": 0.0007789348601363599}, {"id": 331, "seek": 185696, "start": 1874.64, "end": 1879.44, "text": " interested in consciousness, I'm especially interested in this question of what kinds of", "tokens": [51248, 3102, 294, 10081, 11, 286, 478, 2318, 3102, 294, 341, 1168, 295, 437, 3685, 295, 51488], "temperature": 0.0, "avg_logprob": -0.10139423487137775, "compression_ratio": 1.6917293233082706, "no_speech_prob": 0.0007789348601363599}, {"id": 332, "seek": 185696, "start": 1879.44, "end": 1886.24, "text": " simulations might actually develop conscious beings within them, not least because that's", "tokens": [51488, 35138, 1062, 767, 1499, 6648, 8958, 1951, 552, 11, 406, 1935, 570, 300, 311, 51828], "temperature": 0.0, "avg_logprob": -0.10139423487137775, "compression_ratio": 1.6917293233082706, "no_speech_prob": 0.0007789348601363599}, {"id": 333, "seek": 188624, "start": 1886.24, "end": 1890.88, "text": " going to be especially relevant to our situation. If we're in a simulation, it seems we're conscious.", "tokens": [50364, 516, 281, 312, 2318, 7340, 281, 527, 2590, 13, 759, 321, 434, 294, 257, 16575, 11, 309, 2544, 321, 434, 6648, 13, 50596], "temperature": 0.0, "avg_logprob": -0.07521174988656673, "compression_ratio": 1.7720588235294117, "no_speech_prob": 0.0011148443445563316}, {"id": 334, "seek": 188624, "start": 1891.52, "end": 1897.84, "text": " So there's a question about just how this kind of simulation might get set up. But I think this", "tokens": [50628, 407, 456, 311, 257, 1168, 466, 445, 577, 341, 733, 295, 16575, 1062, 483, 992, 493, 13, 583, 286, 519, 341, 50944], "temperature": 0.0, "avg_logprob": -0.07521174988656673, "compression_ratio": 1.7720588235294117, "no_speech_prob": 0.0011148443445563316}, {"id": 335, "seek": 188624, "start": 1897.84, "end": 1903.44, "text": " whole, I mean, already simulations are used in actual practice for a million different purposes", "tokens": [50944, 1379, 11, 286, 914, 11, 1217, 35138, 366, 1143, 294, 3539, 3124, 337, 257, 2459, 819, 9932, 51224], "temperature": 0.0, "avg_logprob": -0.07521174988656673, "compression_ratio": 1.7720588235294117, "no_speech_prob": 0.0011148443445563316}, {"id": 336, "seek": 188624, "start": 1903.44, "end": 1908.16, "text": " by scientists studying this phenomenon or that phenomenon, by people doing entertainment, by", "tokens": [51224, 538, 7708, 7601, 341, 14029, 420, 300, 14029, 11, 538, 561, 884, 12393, 11, 538, 51460], "temperature": 0.0, "avg_logprob": -0.07521174988656673, "compression_ratio": 1.7720588235294117, "no_speech_prob": 0.0011148443445563316}, {"id": 337, "seek": 188624, "start": 1908.16, "end": 1913.04, "text": " people doing prediction of the future, by people doing simulation of the past. And I guess when", "tokens": [51460, 561, 884, 17630, 295, 264, 2027, 11, 538, 561, 884, 16575, 295, 264, 1791, 13, 400, 286, 2041, 562, 51704], "temperature": 0.0, "avg_logprob": -0.07521174988656673, "compression_ratio": 1.7720588235294117, "no_speech_prob": 0.0011148443445563316}, {"id": 338, "seek": 191304, "start": 1913.04, "end": 1918.6399999999999, "text": " it comes to simulated universes, all of those sources of interest may themselves be present.", "tokens": [50368, 309, 1487, 281, 41713, 50168, 11, 439, 295, 729, 7139, 295, 1179, 815, 2969, 312, 1974, 13, 50644], "temperature": 0.0, "avg_logprob": -0.22491097450256348, "compression_ratio": 1.15, "no_speech_prob": 0.004893086384981871}], "language": "en"}