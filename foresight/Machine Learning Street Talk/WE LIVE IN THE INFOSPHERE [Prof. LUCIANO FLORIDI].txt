Professor Luciano Floridi is the Oxford Internet Institute's Professor of Philosophy
and Ethics of Information at the University of Oxford, where he's also the Director of the
Digital Ethics Lab of the Oxford Internet Institute. Still in Oxford, he's a distinguished
research fellow of the Yuhiro Centre for Practical Ethics of the Faculty of Philosophy
and Research Associate and Fellow in Information Policy in the Department of Computer Science.
Outside Oxford, he's the Faculty Fellow of the Alan Turing Institute and Chair of its Data Ethics
Group and the Distinguished Scholar in Residence of the Department of Economics at the American
University in Washington DC. His research concerns primarily digital ethics, the philosophy of
information, which is a discipline he founded, and the philosophy of technology itself.
I will introduce AI as a divorce between the ability to perform a task successfully
in view of a goal, shall we say, play chess just to be trivial, and any need to be intelligent
in doing so. Replace that with parking a car, landing an aircraft, delivering something to your house.
You don't have to be intelligent to do that if you are a piece of AI. That's why it works.
If you had to wait to be intelligent, it would. My iPhone there, turn off properly, would not play
better chess than anyone else in this room if we had to wait for their iPhone to be as intelligent
as a rat. It is because it isn't, and we gave up on trying to make it intelligent as a rat.
We're in the midst of an information revolution, as well as a computing revolution.
Floridi said in his introductory book that all members of the G7 qualify as information
societies, because in each country, at least 70% of their GDP depends on intangible goods,
which are information related, not on material goods. Their functioning and growth requires
and generates immense amounts of data, more data than humanity has ever seen in its entire history.
It was estimated in 2003 that humanity had accumulated approximately 12 exabytes of data,
and we're fast approaching the age of the zettabyte, which is 1000 exabytes.
Sometimes people think in terms of, oh, can we regulate AI, which is a bit like, can we regulate
electricity? Well, it's a bit vague. What do you mean? It's not true, false, correct, incorrect.
It just doesn't yet make any friction with the real world.
Floridi thinks that the material world is becoming redundant. Our agency as humans is being
perniciously eroded, and that the increasing dominance of the information landscape, or the
infosphere as Floridi calls it, is becoming the primary basis for our reality.
Now about 95% of all of the data that we have today has been created by the current generation.
We're not talking about Shakespeare or Dante. We're talking about lots and lots of dogs and
cats. Floridi thinks that the infosphere is becoming so polluted with every passing day
that the manifold of the infosphere is increasingly determined by technology
and artificial intelligence. People are consumers. Consumers become followers.
Followers become barcodes. Increasingly, the data is stored in a representation,
which is primarily machine-readable, designed for consumption by other machines. Our very
existence is being squeezed as a result. It wouldn't be great to have something instead
of us doing it for us, better than us. Yeah, absolutely. I mean, if you read the description
of that something that does it instead of us, better than us, in Aristotle, it's a slave.
That's what we could do in the past. It was horrible. Luckily, it's not happening around us.
But we were using humans as means to an end. Now we can use technology.
Why this divorce? Why sort of pulling apart and saying, look, I want to develop something that
is successful. I don't care whether it does it in the same way as I do it. As long as it's successful,
that's fine. As opposed to, no, no, I want to implement human cognition. And if it's not human
cognition, I don't care whether it's successful or not, but it has to have a little spark. Now,
remember, AI, is it an engineering branch? Or is it a branch of colony science? Well,
as a branch of colony science, we are at year zero. No step forward. We do not have the intelligence,
as I said, of a rat. When it comes to engineering, that looks like magic. That looks like what has
happened to humanity. Who has given us so much brain to do what we're doing today? And the old
phrase like, is it worth asking whether a submarine can swim? Really? Can a computer think,
ah, that's the wrong question. That's not the framework within which we should understand
what a computer does. A submarine does what it does. An airplane does what it does. And it
doesn't do it like a bird, doesn't do it like a fish. But it does it successfully. And that's
the whole engineering point here. Success in delivering the output, given that particular input.
But how do you know it's not the same process? Well, imagine you have two, two,
four, and I tell you one is plus, the other one is multiplication. Which one did I use to get four
from two and two? I don't know. Two plus two is equal to four. Two by two is four. You see, you
can't say. So it's the same thing. No, it isn't. The way I do the dishes, the way my dishwasher
does the dishes, two different things. Florides said something very significant and profound
has recently happened to human self understanding. He said that in many respects,
we're not standalone entities, but rather interconnected informational organisms or
info orgs, sharing with biological agents and engineered artifacts, a global environment
ultimately made of information, what Florides calls the info sphere. This is the informational
environment constituted by all the informational processes, services and entities, thus,
including the informational agents, as well as their properties and interactions and mutual
relations. Now, if there was a representative scientist for the fourth revolution, this would
definitely be allenturing. It's now critical that we equip ourselves with a viable philosophy of
information.
Gazillions of data, yeah, of any kind, of any sort, and they're all digital, readable, machine
readable. When I mean machine readable, they're barcodes, not meant for our eyes, they're meant
for the machines. If you hear anything about the natives, the natives in this space are the robots,
not us. We scuba dive. But these machines, they are digital elements in the digital environment,
reading digital stuff and digital processing, etc. And of course, I show you better machine
learning, better algorithms, but also more and more internal things, things connected to other
things. And when you go home and you see all those green and blue lights, they're not for us,
they're talking to each other. And a lot of the data we have are generated by those machines.
Information and communication technologies have been changing the world profoundly and irreversibly
for more than half a century now, with breathtaking scope and at neck breaking pace. On the one hand,
they've brought concrete and imminent opportunities of enormous benefit to people's education,
welfare and prosperity, as well as great economic and scientific advantages.
This merging of our existence, both analog and digital, both online and offline,
we really ever offline? Of course not. So I'm reminded normally that if you have ever heard
the whale singing, if you don't even know what I'm talking about, then you're very, very young.
But if you know what I'm talking about, then you have used something called a modem.
That is called whale singing. And if you have heard the whale singing,
well, you're more like on my side of the divide. So we don't hear the whale singing anymore.
Floridi thinks that the risks are the nature of reality and our knowledge of it. The organization
of a fair society, considering the digital divide, our responsibilities and obligations to present
and future generations, our understanding of a global world, and the scope of our potential
interactions with the environment. And finally, conceptual implications and complexity of an
information and communication technology landscape. So we don't hear the whale singing anymore. There
is no terminator coming. There is no gods in the sky deciding for us. There's nobody but humanity
responsibility for what we're going to do with this technology. And anyone disagrees,
I hope is just naive and doesn't have an agenda.
Floridi said that the information society has grown quickly and chaotically,
leading to a lack of balance between technological growth and a lack of understanding
of the implications of this growth. It also highlights the need to dig deeper into the
nature and implications of the information age in order to better anticipate and identify
and resolve problems. We started understanding ourselves in roughly in two ways, who I am
and what I can do. I am, no humanity speaking, different, exceptional, special because of my
nature and because and or what I can do compared to anything else. So one is called personal identity.
It's going to come close to privacy and the gazillions of data out there are eroding or
transforming, exercising pressure on that particular who I am, my nature, my data subject,
as we are defined by the European legislation, we all data subjects here. GDPR, General Data Protection
Regulation says so. So if you have data subject and there's a gazillion of data about you
somewhere being manipulated, well certainly your identity is not sure we say in question.
The other half is remember not who I am but what I can do, as opposed to anyone else,
what I say I, and we define ourselves at least since Kant onwards in manner of the German
philosophy in terms of autonomy. We are special because we are in control of our actions, we
can decide, we can plan, we can choose. Well now we have autonomous agents out there and if you
are trying to identify yourself as we can only be not the ones who play chess, well then we are
really in trouble. You can devalue human skills, you can remove human responsibility, you can reduce
human control. Erode human self-determination is the other side of the coin. It's not super dangerous
but the rock who thought that their little drop of water was nothing, 18 years later has a big hole
in it because drop after drop after drop, the drop will shape the stone will shape the rock.
Surely we want to have a technology that makes us more capable of deciding what we want
or prefer what we really have in front of us and I'm a bit worried that here human nature,
no we philosophers we know something about human nature, we'll kick in, we're lazy,
we're also very malleable and we are easily convinced to do this or that so we need to be a
little bit more careful exposing this very fragile malleable entity to a very robust,
quite silly, very efficient, very successful technology that will probably tend to inadvertently
change the nature of that fragile entity. This is something that I would like to be a little
bit more concerned about, not terminator. So until recently you would go to know this wonderful techie
conferences and it was all about technology innovation. The average politician salivates
immediately as soon as you talk about innovation because innovation is growth, growth is money,
money is jobs and people happy. So innovation, innovation, yeah, absolutely and it's crucial
but it's not real challenge. I don't think that that's the most difficult challenge we are facing
now, not because it's easy but because something more difficult to do behind innovation. The challenge
therefore is how you govern all this but governance is a matter of design, designing the right policies
so that incentives and disincentives are in the right place, there are no loopholes, people tend
to do more the right thing than the bad thing. So all of a sudden we are shifting all this into
socio-political issues. It's a matter of design, design the kind of society we want, remember
what's the human project here that we want to implement. So anyway, I had a very fun trip up
to Oxford the other day and had a chat with Luciano himself. I hope you find this episode
valuable. Remember to subscribe and if you're listening give us a rating on Apple podcasts
or whatever you listen to the podcast on. Enjoy. So to start proceedings off with misinformation,
the internet has put the world in our pocket, knowledge at our fingertips but the business
of the internet is about ads and exploitation, debasement and derangement of human attention
and some have argued that social media is a bit like the climate change of our society.
Are you concerned that the current state of internet economics will create
a layer of plausible yet false abstraction between us and reality?
There is a risk of more and more content being worthless, unreliable, false, misleading,
fake news, propaganda. It is not a new problem but the size, the immensity, the impact is new.
It's one thing if you publish a few pamphlets with several lies and another thing if you have
hundreds or millions of followers believing at once that something was not the case and
something that was the case wasn't. And I'm talking about elections and very public figures.
I wouldn't however put the whole emphasis on the negative side. The social media are also,
if we want, the solution to the problem. Today are part of the problem, I agree,
but they could easily become part of the solution. Precisely because then if you remember,
and I close here, good old days when we were online and there was no web, only the internet,
we thought that we were going to create a more informed, more civilized, more reasonable
environment. We can still do that. It's the kind of business models and lack of political, legal
framework that has generated this tsunami of, shall we say, rubbish, which is polluting our
infosphere, the space of our information. So, yes, it is a problem, no, it doesn't have to be a
problem. It could be easily a big solution. One suggestion for all and as close here, imagine
if we were to ban, and it's a bit of a joke, advertisement online. We'd have to pay, we would
pay for the product. That means that there will be competition for quality. We'll be probably in
a different kind of game. Interesting. And we'll get into a minute, we'll get into the subject of how
the structures of, let's say, markets and economic models affect us as human beings and as a society,
but also affects our perception of reality, essentially. But before we get there, you wrote
a paper called GPT-3, It's Nature, Scopes, Limits and Consequences. And you said that
reversible and irreversible questions are based on mathematical logic,
libanate law and other fields such as computing and physics. Can you explain what you meant by that?
It's a simple idea. So, if I fail, it's my fault.
A question that I define there as reversible means that from the answer, you can reverse to
the actual identity of the source of the answer. An irreversible one is one that doesn't allow
you to do that. Let me give you an irreversible answer today. Come to my house, you find clean
dishes on the table. Who has cleaned the dishes? It's irreversible. You can't tell. It could be me
or it could be the dishwasher. So, you cannot tell, by looking at the dishes, the output,
whether those dishes have gone through a process of hand washing or machine washing,
and whether the source is one or the other. A reversible one would be the sort of question
today, and I'm talking today. We can ask to chat GPT. Use anything like Mary's mother has
three children, tell me the name of one of them, and GPT says, I don't know. It does, I have no
enough information. It's Mary's mother, so surely. So, that becomes immediately reversible. You know
exactly that the answer is coming from a computer, from a large language model, and not from a human
being who gets that immediately. Imagine the other way around. You ask for a super complex
calculation, and boom, you get the answer in a fraction of a second. The other one may come
snake and maybe takes longer, so who was the other side? So, increasingly in the paper, I write that,
and it was before chat GPT coming out, but it's obvious, and it's been, you know, our progress
since then. Increasingly, the sort of output that we are dealing with will become irreversible. We
will be unable to tell whether the source is, for example, a human being, a group of human being,
a human being with a computer, or chat GPT, or whatever is going to come, GPT4, etc. Imagine
GPT10, not many years from now. I think that it will be completely irreversible. It does not mean,
however, let me close here, that I'm like the dishwasher. If you can't tell who did the dishes,
what difference does it make? I've done them in one way, which is completely different.
The machine does it in a sort of mechanical, etc. So, we should be clear about what we infer from
the reversibility, any reversibility of the output, and that seems to me where a lot of confusion is
generated. Interesting. So, there's the provenance of the information. So, where it originated from,
we could go down the line of saying, because it is human aligned with this reinforcement
learning for human feedback, it's remarkably human aligned, actually, much more than the original
GPT3. Then, you spoke to this semantic divergence, and we can talk about the pragmatic divergence
as well. Actually, that's getting into a little bit about what John Sow talked about,
the difference between ontology and epistemology. Is that something that you're
seriously concerned about? Could you expand on that? I am concerned about it. I'm one of the
few people, or I hope many more than Sims, who agree with the Chinese room and the
philosophy behind it. Of course, you can always, among philosophers, you can always argue for
details and sophisticated counter-argument, etc. But the bottom line, I mean, John got it
right a long time ago, we're dealing with syntactic engines. There is no understanding,
there is no insight, there is no emotional involvement, etc. Anything that would go
into qualifying, characterizing human intelligence, which is also a rather fuzzy
concept, by the way. On that front, I think we're going to see more and more of successful machines
of the kind that we were just discussing. You mentioned the source, because that is
the real difference. Let me give you a small example.
Suppose you take from the shelf an amazing novel, a novel that John won the Nobel, for example.
I would be surprised if you were to confuse that for something that's been generated by GPTX.
The other thing is not true. Suppose you take a normal text, like an encyclopedia entry,
or a good summary of that novel. Would you be able to tell me whether is a human being or GPTX?
You wouldn't. So there's also a symmetry between the sort of product that we get and the sort of
inferences that we can run. Final point, you know, technique is not everything,
and we always fall into the same trap. You see someone reproducing on the pavement in a street,
the Sistine Chapel. It's amazing. I mean, I wish I could do that, but it's not Michelangelo.
Why? Well, because there is a different history, a different intention, there's a different aesthetics.
So the mere ability of reproducing or doing like fails to get the semantic capital behind all that,
the intention, the interpretation, the historical context, the continuity, the why did it happen
and did not happen something else. All that is the richness of our understanding and semantics.
We lose that if we think that all the difference that there is between Michelangelo and the artist
in the street is just technique. It's not the case, and we should not be confused on that.
I completely agree with you that there is a rich semantic context which is embedded,
and this is something I'm conflicted on. So I agree with Soil in the sense that he said
there was this rich and nagle actually, this impenetrable realm of the subject of experience,
and that informs the meaning. You know, there's an ontological difference in understanding,
which is what Soil said. But what's been so remarkable with chat GPT is it does seem to
confer some semantic sort of inference, if you like. And I think the reason for that is
going back to Pierce's triad, the symbolic version, the semantic content is embedded in
our language. And that's why GPT3, even though it's mimicry, it often appears to, I mean,
for example, it knows what the concept of Christmas is. So now it's becoming
such a close reflection of us, it's becoming more difficult to distinguish.
And at some point it would be impossible, if not already. But we should be careful not to confuse
this with what you mentioned before, the intentionality, the realm of meaning, of existential
experience of all this. Christmas is something that reverberates and provides meaning, for example,
in each of us for a reason that is utterly cultural. It would have meant nothing to play
obviously for historical reasons and so on. Let me give you an example. This would be like
saying that when you cut the tree and you find the rings of the tree telling the age of the tree,
the tree somehow told us its age. Well, it takes a little bit of imagination.
No, it did not. And yet the symbolic, the representational, it is true that the tree has
provided that information to begin with. But it's also because we can interpret that way. So
I would like to see more work done on the hermeneutical side of all this, so that we get
it clear on what we are consuming. Content, which is sometimes impeccable, sometimes irreversible,
cannot be distinguished from content that could have been produced by a human being,
but also the understanding, the interpretation, the context, the why it matters of their content.
Now, boilerplates are exactly what they are. And if there's something in a, for example,
encyclopedia entry or Wikipedia entry, that matters is exactly, is objectivity, is luck,
insofar as we can do that, of interpretation, of an angle, almost like as if the author had to
disappear. But that is exactly where tools like GPT number will excel. It would be different if
we were talking about the way in which an artist, a writer, or anyone simply putting notes in
her own diaries, is going through the process of verbalizing, conceptualizing the experience, etc.
So ultimately, allow me another analogy. There's a reason why, although we could have
the best director and the best orchestra performing that particular concert in the hall,
or just a recording that you had to play, we don't. And we can't get a few, a bunch of kids
in a choir and a few people who are rather amateurish here in Oxford and do a good job,
but certainly not as good as it could have been done by professionals. Is the human experience
that matters? It doesn't matter whether you could do that, better by having a tool.
Given the pollution of the infosphere with data generated from large language models,
what are the ethical implications on society?
There are quite enormous, I mean, the responsibility on so many fronts. This responsibility,
of course, of the source of this pollution. And by the way, we know that the actual sources are not
many. It's not that each of us is constantly pouring, providing extra bits of misleading
information and lies. We do inadvertently repeat and reverberate that, but the actual sources of,
say, for example, Russian propaganda are very few and well known. And likewise, you know,
on many other contexts. So first of all, a huge responsibility on those who are polluting the
environment. They are few, they are powerful, and they should be curtailed, shall we say,
if not entirely stopped. Huge responsibility on people who could legislate much better,
and more firmly. Look at the current debate, people listening to this and watching this should
look at the date, but look at what's happening these days to Twitter. I mean, the debate is open
about whether it's going to be a source of information or misinformation, and who should
be there or shouldn't, etc. How much do we want to control? How much do we want to not filter?
But also how our responsibility as a society, we should demand more, and we should be more
careful. So if you put together all these responsibilities between the producers, those
who take advantage of it, the consumers, we are all in on this. No wonder, it's a mess.
But as I said at the beginning, we could rectify it with a bit of goodwill.
No, you wrote an article in Aion a few years back called Should We Be Afraid of AI?
And the risk debate has been ongoing since the 1960s when Irvin John Goode prophesied a potential
intelligence explosion that could leave humanity behind. And on one side of those who believe in
true AI, the Church of the Singularitarians, as you wonderfully described them. And on the other
side, you have those who do not believe in true AI, known as the Church of the Atheists,
sort of that spell AI, which is absolutely delicious. And you said we should remain
tolerant of both views. But the real challenge is to ensure that AI is used in a way that
does not undermine human dignity. And you said the dogma of the Singularitarians consists of
three beliefs. The creation of some form of AI is likely and humanity will be dominated by it.
And it's the responsibility of the current generation to ensure it's benign.
So you said that Singularitarianism is implausible. It relies on weak senses of the possibility
of possibility and Moore's law, and it distracts from the real evils. It's almost an indulgent
of the Western elite. So what can be done to ensure that Singularitarianism is not a distraction?
I'm afraid that the only cure there will be history, meaning that as we move on,
we will see that AI in its variety of forms, natural language processing,
robots, even little gadgets that can help us to do this and that in our mobile phone,
I mean, that they improve say communication or enable us to take a better picture,
the recommended systems that you find on Netflix, et cetera, and all these things we will see as we
move on and grow up, that what has really happened is absolutely extraordinary,
but not extraordinary as the Singularitarian thing it is. We're actually separating and
increasingly so the ability to do these things and to solve problems, take care of tasks
successfully in view of some goal, some end, from any need to be intelligent in doing so,
that is extraordinary. This divorce between agency and intelligence, that is amazing.
And if anyone doesn't want to speculate, just think about chess playing. I mean chess playing
today is done at zero intelligence, at least I hope people will admit that my iPhone doesn't think
any bits, anyone I can encounter. So extraordinary ability that would require
intelligence if I were to play that way, I wish I could, but that it can be done as zero intelligence.
Now, as we learn more and more that there is the delta, the gap that we are building,
and these two things will go further and further away as we move on, things in terms of what we
just said in terms of large language models and the GPT and the other ones that are quick
following from other companies without advertising for anyone. We will find any Singularity narrative
science fiction, I mean entertaining at some point, frustrating at others, because as you said,
it is also distracting. We have plenty of problems generated by this divorce. If you have an enormous
new force or source of agency in the world, at zero intelligence, that requires intelligence,
hours, governance, law, ethics, a sense of what is the human project you want to build,
and meanwhile you're worried that your car would run away with your credit card to have a holiday
on a beach, well then certainly frustration starts building up because we're not taking care of the
real issues. Now, the discrimination, the digital divide, the amount of things that we're not doing,
no, sort of opportunity cost, wherever we are lacking a clear framework and so on. So Singularity,
I mean like all churches, I think they will become increasingly old and they will not die,
I mean they will always have a few faithful ones, but hopefully will not be in the headlines,
which is one of the reasons why people like to push forward the Singularity so that they get the
headlines. In terms of the end game though, you might argue that they have a point, I suppose
you're arguing that, I don't want to put words in your mouth, but you just spoke about the industrialized
attenuation of our agency and that maybe that's analogous to saying we're becoming increasingly
enslaved by technology and our children's generation much more so than we are. So in some sense,
would you argue? Oh no, it would be like saying, well I mean you could read that in terms of the
engine and wonder whether the engine and the whole industrial revolution and urbanization coming
say from model engine and so on has been liberating, has been enslaving, has been a good thing, a bad
thing, has all real historical and real philosophical issues. It's a mix back and you can't simply say
oh no, I wish the car had never been invented, really like I'm not quite sure, but on the other
hand the damage that we are caused to these environments, so same with the AI. Now one could
say I wish people had never taken this genie out of the particular bottle, really like the kind
of things that we can do thanks to this. Think of one case, just a simple case, like cold fusion,
I mean today if there is even a remote chance to get there is because of machine learning.
We will never get there without the enormous abilities of computational problem solving
provided by AI and so forth, so this case too requires more commitment, more sort of human
intelligence, more governance, not less. So sometimes I find that debate becomes a little bit of a
deterministic kind of debate between things that people who think they were doomed and things
rosy glasses think oh it's going to be a wonderful world, well honestly it just up to us. The crude
painful sort of truth is that unless we do something about it, it will be a mess, but if we do
something about it and we do it rightly, well then we can do an enormous amount of good things for
this, no at last point just to have some references, just look at the impact of AI in a variety of forms
again on the sustainable development goals has been already significant, could do so much more
at the same time, how much energy goes into development these sort of large language models,
huge, are we really doing the best with this sort of consumption and impact when then if we
were to use this for example for entertainment, for advertisement, when every bit of electricity
out there should be carefully considered, even impact on the environment, these are real issues,
but they are philosophical issues for human beings. Is there a way that we can embrace this
technology in a way that preserves human dignity? I think so, the question is not however to simplify
in terms of human-centric, because what reason maybe we can explore later, but we have done
too much of that precisely because we have been so human-centric, we have destroyed this world,
we have killed the environment, we should be more sort of at the service of both the natural and the
sort of man-made artificial environments as well, so to me the best way of using technology
is by respecting as we said before human dignity, but also using technology to the benefit of
quote-unquote the other, which could be future generations, it could be the environment,
it could also be us taking it as humanity, but not just us, if we use technology just for us
and our own benefit, we will ignore future generations, we will ignore the environment,
and we will not have done a full decent job, so yes there is, but it takes a little bit more
of a commitment that we have at the moment. What form of governance do you advocate for?
To me the governance that we could develop would inevitably leverage this digital revolution by
offering, not imposing, not expecting, offering more participation at the beginning of the
decision or process, so these are two distinctions that go against the right democracy, I'm not
advocating for the right democracy, I'm saying offering so cannot be expected or compulsory,
but plenty of offer at the beginning, not at the end, take a referendum, a painful memory here,
we are in the UK, a referendum is not the right democracy, why? Because you can't choose between
A and B, if you dislike both A and B, someone has prepared the alternative for you, the real
democracy that is co-designing of the choices, not the options at the end, but the initial
choices is the one that says, should we consider a referendum or blah blah blah, so the point here
is that the earlier the involvement, the better is to live in that kind of society, so the governance
that I'm advocating is a governance that has as early as possible involvement of people in a
co-design of the choices that we face, now that, and I was here sorry but it's a huge topic, that
means that behind this particular sort of mechanism, there's a separation between
those who have power, the people, and can delegate power, and those who exercise power but don't
have it, this structural separation between having power without exercising and exercising power
without having it, that to me is the ABC of any decent governance, governance fails, especially
political governance, no in the democratic sense of governance, fails the moment you have those who
have power exercise it and those who exercise it have it, it doesn't matter whether it's a majority,
it's minority, it's an oligarchy, it's three people, it's one person, it's a family, it's a tyranny
of a few people, maybe only one, as soon as you separate this then we start having the right
governance, then we can talk about involvement in the decisional process as early as possible,
then co-design, and therefore for all this the kind of technology that we have, this is doable if we
want to implement it. One thing that concerns me is that when we talk about the architectural
design of governance, the structure can sometimes exclude other parts of the complex world that
we live in, and also there's this compatibility with the Demos which is to say it needs to be
intelligible, and then you have this problem of people voting in their own self-interest,
even if they did understand the purpose of the governance. True, and we know that self-interest
can go only there far, we learned that from the past century, the 20th century, the 20th century
has been the century, especially the second half, so stuff has been a disaster, the second half much
more successful, has been the century of the citizen-consumer, and therefore the self-interest
as a citizen voting for the best options, making a difference, and therefore competition between
different parties etc, and the consumer having the same kind of choices, voting quote-unquote with
his note, that what they feed so to speak, choosing their restaurant or another, their shop
rather than another, their product or another, but this figure that was the selfish interest
consumer slash citizen has become not the user and the follower, so today instead of having
citizens we have sort of followers, instead of having consumers we have users, and therefore
there has been sort of impoverishment of precisely their selfish sort of interest, the caring for
my individual project, which is one of the two legs for democracy, so their leg has become weak,
the other leg is absent, which is the social side, so at some point society should also invite,
facilitate, support, so nudge gently towards more not social solutions, for the simple fact that
if we need to be more ambitious in our goals, we need to get together, it's not enough to not pursue
our own self-interest, we have to pursue interests that are shared, so imagine the following picture
out of this quick analysis, two legs, one has become weaker, the selfish interest for my individual
project, the other one which is a social project is not there for obvious reasons, when we tried in
the first half of the last century, it was the most horrible episode in human history, the Nazi,
the Soviet Union, no democracy going out of the window, I mean Auschwitz, I mean we have created
the most horrific possible nightmares that humanity has ever seen, so on this not so well
so established body of democracy which has one leg missing, at the other one we, there's a lot of
work to be done, we can do a better job reinforcing a sense of individual projects, what we call not
more selfish interest, yes, and no, instead of no, either or instead of weakening it, reinforcing it
and balancing it with a social project, the idea that no, if you get together you can do so much
more and so much better than just by yourself, finally an example, if that car, and I've used
that more than once, forgive me, but if that car doesn't start, it's totally pointless for you to go
and push and come back home and say I've done my duty, it has to be the five of us, and it has to be
the five of us, one, two, three, push, coordinated, so we need to have a society that increases the
support for individual projects and has a good liberal democracy and counterbalances that with
social common projects, so there we have both, now normally you find this a little bit more sort
of developed in, no, western social democracies of a Scandinavian kind, now I wonder everybody
wants to get there, I think you would agree, I mean Chomsky spoke to this but that you know
market forces as well as technological forces reontologize us, I want to pick up on this word
reontologize, I think it's an amazing word, I'm just going to scroll down to this, but yeah you
said that once digital immigrants like us are replaced by digital natives like our children,
the immigration will become complete and future generations will increasingly feel deprived,
excluded, handicapped or poor whenever they're disconnected from the infosphere like fish out
of the water, you said that information and communication technologies are reontologizing
which is an even more extreme form of re-engineering us in our society which is to say its intrinsic
nature is being transformed, you said that we're modifying our everyday perspectives on the ultimate
nature of reality that is our metaphysics from a materialistic one, you know in which physical
objects and processes play a key role to an informational one, so let's I mean you know
explain your rationale but I love this word reontologizing, yeah well this comes from a very
Kantian anti-metaphysical perspective, I find any metaphysics of the bad kind that Kant was talking
about beyond my comprehension, it's something that I just don't quite get, I mean how people
can possibly believe that they have a direct line with being capital B and being told by being,
what is like to be being is beyond me, so I'm afraid on that front I am rather deaf and I understand
that it might be my limitation, I rather speak, sorry when I use the word metaphysics that's
what I mean, the Kantian kind of thing that you don't do because it's meaningless to do it,
there's also a lot of no kind of Vienna circle kind of an analytic philosophy in all this but
ontology on the other hand is how we structure the world in the sense that we think that that's
the way it is, so with the kind of eyes we have and the kind of light around the world
that those are the colors we perceive, to me the colors in the world are part of the ontology of
the world they're not, nothing to do with metaphysics, it's not the way things are in themselves,
no woman and etc, I have no sense of what we're talking about but certainly a world full of
colors is the world which I take it to be, the world, that's my ontology, now reontologizing
means changing some of that particular nature, allow me a distinction so I hope it's not too
confusing, reality in itself call it system, description of reality as we perceive it,
enjoy it, conceptualize it, live through, model of the system, ontology to me is the ontology of
the model, it's not the metaphysics of the system, I hope I haven't made a complete mess here,
okay, so metaphysics no manom system, whatever the source of the data that we get, fantastic,
the data don't speak about the source, the music of the radio is not about the radio,
but there is a radio, of course the music is what we perceive, the music has its own ontology,
structure etc, the model, the model is at that point what we enjoy, why the digital revolution
has changed the nature of the world around us, not metaphysically but ontologically, so the
reontologizing, because some of the things that we have inherited from modernity, and I really mean
modernity in the ordinary sense, no three or four centuries depending on whether you have a
large short medium modernity from Columbus onwards or bit shorters, first world world,
your size, your preference, but modernity, we have been added from modernity a sense of the world
that is now being restructured and a certain understanding of the world, so re-epistemologizing
as well of that world, two simple examples, modernity onwards, which I know I've used in the past,
we have grown up with the idea that law and territoriality are two sides of the same coin,
you can't simply separate them, my place, my rules, your place, your rules,
if from Westphalia onwards, that's the ABC of any legal system for a long long time,
the law ends where the territory of that particular state that issues the law ends, no, at the border,
so law and territoriality, two sides of the same coin, or two sides of the same piece of paper,
you can't cut one without cutting the other, of course, that's the ontology of the world in which
I live, welcome to cyberspace, right to be forgotten, our whole debate and today we know that actually
law and territoriality are no longer two sides of the same coin, they've been completely decoupled
and you cannot have rules that for example are passed in Europe that apply to a search engine
that is based in the United States and yet is only one click away, so the right to be forgotten was
no, the moment when this became obvious, we were legislating about Google and Google not complied
in Europe, the complaint was like well but it's not changing the way google.com is working, well
the law doesn't apply there and of course there was a debate in terms of oh but it has to apply
everywhere in the physical space, so the decoupling of the law and the territoriality is a reontologization
of that particular space, we live in a different world, we perceive the world differently, conceptually
we also start thinking differently, now let me give you a small example and I close here
of a reontologizing of something we took absolutely for granted, right, if you have a taxi you have a
license, if you have a license you can be a taxi driver, the two things go hand in hand
and it's illegal etc, then Uber comes and having a car being allowed to give a lift to someone
is decoupled from having to have the license as a taxi driver, a cab driver, this decoupling
has generated an enormous amount of profit, problems, issues, a change in game and all of a
sudden we realize yeah those two things were not completely one side of the other, so obviously
this uberization of the world means decoupling things that we have taken for granted as a single
unit from modernity or gluing together things that we thought were completely independent
in the past, last example, personal identity, for a long long time we discussed personal
identity, I mean philosophically speaking, as you like substance, soul, body, what the incarnation
today if you look at anything that identities our data, that's the European legislation
describes as data subjects, I am my information, privacy, the whole privacy debate is discussed
in terms of what constitutes me as that body of information, privacy is a matter of getting my
body almost, so why is this important because if you look and I close here at the European
legislation how did they cope with the decoupling of space territoriality and law by coupling personal
identity and data, personal data so that today the legislation does not say you do as you're told
because it's my space but it says you do as you're told because this data are the data of the individual
who is my citizen wherever you are, so decoupling, recoupling, new legislation this is
incomprehensible unless you have this cut and paste in mind which is the reontologizing,
reappease demologizing of modernity through the digital evolution, it's a big deal.
The Uber example is absolutely beautiful and I can place myself in the startup and these folks
think they're being incredibly disruptive and what you said is interesting, we used to talk about
the mind-body dualism but now there's almost a kind of identity dualism, there's my digital
identity and that is becoming increasingly as you say the only thing which matters but
to close off this reontologizing thing, I'm not sure this might be a little bit tangential but
Heidegger conceived of technology as an intermediation between us and our environment,
I think in a similar way and it shapes the environment as much as it shapes us back
and in a sense reliance on technology can make us less human which is kind of what you're
relating to, is there an instructive contrast to Heidegger's analysis of the relationship
between humans and technology and you're right? I think Heidegger was onto something when obviously
technology is between us and the environment but allow me to be critical, he didn't see this
seems to me clearly enough because that description, the description of a first order,
what I like to call first order technology is essentially the very idea that between me and the
tree there might be a sowing mechanism or between me and that particular sort of garden
there might be a spade but increasingly unless the industrial revolution
instead of having humanity and nature and technology in the middle you have humanity,
technology and technology and that's a second order technology so we increasingly use more and
more technology to deal with other technology and that's not in Heidegger, it's a second order
technology but what AI does is to generate a third order technology where no between A and
B and C is technology throughout so it's a computer controlling a robot building a car
at that point we are outside that relationship and we can just control
check that everything goes in the right way we are on the loop or after the loop
at that point we can reinterpret the Heideggerian negative view of technology and say that is
exactly where you want to be, you want to be outside the me technology nature or me technology
technology I want to be on top of technology technology technology and see whether that goes in
the right direction now it's even more powerful even riskier but with higher risks higher rewards
it could also mean how humanity can actually take care of the world nature and itself properly
now we would not be able to save this planet and ourselves from ourselves on this planet
without technology it's inconceivable that now we can see at the end of the 21st century
as a success by abandoning technology like seriously no more embedded technology but then
we need to understand this no third order idea if we're still stuck in a sort of 19th century 19th
century idea that it's between me and the world we're not gonna get out this final point obviously
being on the loop or after the loop the designer of the whole loop comes with enormous responsibilities
that's why ultimately to me it's not digital innovation but it's the governance of the digital
that makes the whole difference digital innovation is it's it's not easy but it's not difficult
especially if you have deep pockets you buy the next startup and the next no three kids who come
up with a fantastic idea knowing what to do with that that takes a genius so um you said in your
information book that John Wheeler coined the notion of it from bit and some physicists entertain
an information based description of reality and you said that this informational metaphysics may
but does not have to endorse a more controversial view of the physical universe as a gigantic digital
computer according to which dynamic processes are some kind of transitions in computational
states in a style described similarly by Putnam and or maybe I call it Turing machine functionalism
so you pointed out the the ontological difference between imagining a stomach as if it were a
computer versus holding that the stomach is actually a computer you said that there's a clear
philosophical distinction between whether the physical universe might be modelled computationally
is a different question to whether the ultimate nature of the physical universe might actually
be digital and computational in itself so so what's your take I think the whole problem is ultimate
we go back to this temptation of talking about reality as if you were something that we need to
grasp catch portray hook uh spears um when in fact the the way I prefer to understand it is as
malleable understandable in a variety of ways um something that provides constraints
it doesn't mean that you can interpret in any possible way but leaves room for
different kind of interpretations so if the flow of data that come from whatever is out there
and again I'd rather be sort of agnostic about it can be modelled in a variety of ways um one way
is to especially 21st century given the technology we have etc to interpret that as
no an enormous computational kind of uh environment it's perfectly fine as long as we don't think that
there is our right metaphysics is the correct ontology for the 21st century now this is not
relativism because on the other hand different models of the same system are comparable depending
on why you're developing that particular model and let me give you a completely trivial exam
suppose you ask me whether that building is the same building
that question has no real answer because it depends on why you're asking that question
if your question is asked because you want to have directions I'm gonna say oh yeah it's the
same building so the same building yeah absolutely no go there turn left no traffic lights up but if
your question is like same function as I know it's completely different building it was a school now
is a hospital next question so is it or is it not the same that that question is the mistake
an absolute question that provides no interface what computer scientists call level of abstraction
chosen for one particular purpose so that I can compare whether an answer is better than another
let me crack a joke for the philosophers who might be listening to this huh there's your ship
is it the same or is not the same who is asking why because if it is the tax man the tax man
you're doomed man I mean there is no way you can play any who I change every plank that you're
gonna pay that tax is the same ship I don't care but if it is a collector that ship is worth zero
you change all the planks you must be joking it's worthless so is it or is it not the same
depends on why you're asking that particular question tell me why and I can give you the answer
now why in other words no frame within which we have chosen the interface that provides the model
of the system no potential answer so the question is like is the universe a computational
gigantic yes or no meaningless is it worth modeling the universe as a gigantic for the purpose of
making sense of our digital life oh yes definitely because we are informational organisms aha so
metaphysics no I meant in the 21st century the best way of understanding human beings today
is as information organisms last century we thought that biologically not made much more sense a lot
of water and sprinkle all the extra and so on mechanism the car time etc so not absolute answers
no relativistic answers but relational answers the relation between the question the purpose
and the actual answer but it takes three not two any absolute question absolute mess
this is so interesting I mean I spoke with David Chalmers recently and about the hard problem
and there was a thought experiment about maybe David lives in the matrix and one of the architects
came down to him and he said David you don't have the consciousness model installed we've
installed it on other people but we didn't bother installing on you but you're a philosophical zombie
or whatever and what would we need to do to to convince you that you're in a simulation and David
said well I'm outside the Empire State Building maybe if you turned it upside down I believe you
but but to be to be clear you're actually saying because I'm interested in this kind of
ontological distinction you're saying that even if we did exist in a computer simulation it wouldn't
make any difference it wouldn't it for the same reason that it doesn't matter whether we are in
God's mind as Berkeley's subjects it makes no difference because what you have lost there is
any traction by asking that particular question with anything that would provide any answer in other
words these are only sophisticated ways of playing as you lose tails I win find me a solution
you should stop engaging with these kind of questions is the trolley problem you should stop
engaging in that particular question because there is it but philosophers love those disposals
now they imagine the possible world in which well as soon as anyone start talking about imagine a
possible world what are they I reach for my Kalashnikov or something else I I think we should
really not indulge in these kind of things not because they have wronged but because they are
misused any real philosopher and I'm talking about this no 20 25 30 classics have been using
thought experiments logical possibilities for a purpose not in themselves you will not catch
they can't trying to solve the demon malicious demon problem that is a tool to get somewhere
is not something worth in itself same reason why now the trolley problem was developed to test
the particular theory not as a puzzling itself same reason why you know people are no no in a
matrix etc etc once again ask yourself what is the purpose for this particular question
because the purpose is a lot of mental enjoyment chess is much better beautiful well we've got
about two minutes left so I guess we'll have a closing statement but maybe also you could bring
in I mean I've got a machine learning audience so they would be interested in in in digital ethics
for example and and what they can do to learn more but also many folks are interested in getting into
digital ethics and philosophy so what what would you say to those people to the machine to machine
learning people I was always say like congratulations you are in the right business but secondly I
would say please don't forget where all this is going have a sense that these are not just toys
these are not just a matter of competition between one company another to have a larger model a faster
sort of computer a slightly improved quantum something and on and on we can go in a variety
of directions machine learning is one of the problems but think about the impact that they
will have on society on the environment and on individual lives it could be a fantastic impact
it could really make a difference in suffering in saving the environment or it could be a total
disaster so please mind your machine learning and be a little bit more aware of the importance of
your job don't underestimate how crucial it is what you're doing you are providing the foundations
for the 21st century information society that is not small task we do that right we're gonna
not be thanked by future generations you we do that wrongly future generations may not be even
there but if they are there they would not be grateful so please not be careful what can be done
well one of the things that no this will end up with self-advertisement a little bit but one of
the things that we are going to do with the new center Yale is precisely opening the doors to
all disciplines and all practitioners because research and development today is done especially
in AI especially machine learning especially in digital context enormously more within
industry than sometimes in even the top universities so opening up having this translational no from
blue sky to product and multi-disciplinary open idea that it's a big table out there we need
everybody around the table the politician the lawyer the engineer the machine learning expert
the philosopher the ethicist the social scientist etc everybody around the table then that point
that I made the beginning will become a little bit more reasonable doing it together to improve the
world improve the chances of saving the environment ourselves can be done and I'm not sticking some
on my actual so neck out so to speak on this but it's something that I truly believe it's
entirely up to us and we can do this properly if we put ourselves into it professor Luciano
Florida it's been an absolute honor thank you so much thanks a lot thank you so much
