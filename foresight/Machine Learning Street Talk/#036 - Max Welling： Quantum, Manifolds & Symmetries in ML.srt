1
00:00:00,000 --> 00:00:19,920
Qualcomm AI Research is hiring for several machine learning openings, so please check

2
00:00:19,920 --> 00:00:25,200
out their careers website if you're excited about solving the biggest problems with cutting

3
00:00:25,200 --> 00:00:34,960
edge AI research and improving the lives of billions of people.

4
00:00:34,960 --> 00:00:40,880
Today we got to speak with one of our heroes in machine learning, Professor Max Welling.

5
00:00:40,880 --> 00:00:45,600
It was good, the questions were really fantastic actually and I've never done this with the

6
00:00:45,600 --> 00:00:50,000
three of you but having a team of three people asking questions is really, it's a good idea

7
00:00:50,000 --> 00:00:53,920
and of course you're really smart people knowing what you're talking about so that went really

8
00:00:54,720 --> 00:00:59,600
well I think. Needs three brains to match yours. We asked Max some of your favorite questions

9
00:00:59,600 --> 00:01:03,760
from Reddit. Hi Max, when will you be changing your last name to pooling?

10
00:01:05,920 --> 00:01:11,360
Max has pioneered the discipline of non-euclidean geometric deep learning.

11
00:01:11,360 --> 00:01:17,600
So what is actually geometric deep learning? It's the idea of performing deep learning or

12
00:01:17,600 --> 00:01:22,800
machine learning more generally but let's say deep learning on data that is not euclidean in some

13
00:01:22,800 --> 00:01:32,480
sense so not a nice chain structure for audio or a planar structure for images but perhaps a sphere

14
00:01:32,480 --> 00:01:38,000
or graph or something more exotic like some kind of manifold with arbitrary curvature.

15
00:01:38,720 --> 00:01:42,960
You might want to model weather patterns or social interaction data. There are many types

16
00:01:42,960 --> 00:01:48,720
of data out there that are non-euclidean. Actually if you've been playing with graph neural networks

17
00:01:48,720 --> 00:01:54,080
then you've already been doing non-euclidean or geometric deep learning. So to make this work

18
00:01:54,080 --> 00:01:59,680
you just need to abstract some concepts so the euclidean distance or your neighborhood

19
00:01:59,680 --> 00:02:05,360
it becomes a function of connectedness just like on a social graph. Am I connected to John? Does John

20
00:02:05,360 --> 00:02:11,760
know Bob? Simple as that. Actually this kind of abstraction works in many areas of mathematics

21
00:02:11,760 --> 00:02:16,720
which Max will get into today as well as making neural networks work on non-euclidean data.

22
00:02:16,720 --> 00:02:22,000
The other thing that Max has really pioneered is this idea of recognizing symmetries

23
00:02:22,000 --> 00:02:27,440
in different manifolds. So in this blank slate paradigm that we have now in neural networks

24
00:02:27,440 --> 00:02:32,640
we're essentially wasting the representational capacity of the neural network because we're

25
00:02:32,640 --> 00:02:38,560
just learning the same thing again and again. For example in a fully connected neural network

26
00:02:38,560 --> 00:02:43,760
we would have to learn the dog in the top right corner and the top left corner because there's

27
00:02:43,760 --> 00:02:49,200
no translational symmetry. And it was exactly this reason why convolutional neural networks were so

28
00:02:49,200 --> 00:02:55,200
powerful because they introduced this concept of translational weight sharing. So you had this

29
00:02:55,200 --> 00:03:01,520
filter that you could shine over the entire planar manifold and it meant that those parameters could

30
00:03:01,520 --> 00:03:07,280
be reused and you could learn concepts in different parts of the visual field. It was an incredible

31
00:03:07,280 --> 00:03:12,800
breakthrough. Imputing this kind of knowledge into a deep learning model this is called an

32
00:03:12,800 --> 00:03:17,840
inductive prior. It means that we can take some prior knowledge about how things in the world

33
00:03:17,840 --> 00:03:23,360
works and we can impute them into our models. It makes our models more sample efficient and it

34
00:03:23,360 --> 00:03:29,440
makes them generalize better. When it comes to sophisticated inductive priors Max Welling is the

35
00:03:29,440 --> 00:03:35,920
king. When we think about AI and its capability to actually help us to enrich our lives we know

36
00:03:35,920 --> 00:03:42,160
we need to first help machines see and understand like humans do. Take this drone collecting data

37
00:03:42,160 --> 00:03:49,920
in 3D or this autonomous vehicle with cameras covering a 360 degrees view. Current deep learning

38
00:03:49,920 --> 00:03:55,680
technology can analyze 2D images very well. But how can we teach a machine to make sense of image

39
00:03:55,680 --> 00:04:01,600
data from a curved object like a sphere? And because we want this processing to happen on the

40
00:04:01,600 --> 00:04:07,760
device itself for reliability, immediacy and privacy reasons how can we achieve this in a

41
00:04:07,760 --> 00:04:13,280
power efficient manner? It turns out we can do this by applying the mathematics behind general

42
00:04:13,280 --> 00:04:18,880
relativity and quantum field theory to deep learning. Our neural network takes in data on

43
00:04:18,880 --> 00:04:24,560
virtually any kind of curved object and applies a new type of convolution to it. We can move the

44
00:04:24,560 --> 00:04:30,320
shape around and the AI will still recognize it. This is just one example of the exciting research

45
00:04:30,320 --> 00:04:36,480
we're doing at Falkamea research to shape AI in the near future. Anyway it turns out that these

46
00:04:36,480 --> 00:04:42,160
symmetries are absolutely everywhere. If you wanted any further proof of how useful these kind

47
00:04:42,160 --> 00:04:48,000
of equivariants and symmetries and manifolds can be, look no further than the recent announcement

48
00:04:48,000 --> 00:04:58,480
from DeepMind AlphaFold. It will change everything. DeepMind solves 50 year old grand challenge.

49
00:04:58,480 --> 00:05:06,160
The game has changed. So proteins are the structures that fold in a given way. The result

50
00:05:06,160 --> 00:05:13,520
of this year's competition came out and they looked something like this. Namely every entry here you

51
00:05:13,520 --> 00:05:21,840
see is a team participating in that competition of protein folding prediction and there is one team

52
00:05:21,840 --> 00:05:31,120
which is DeepMind's system AlphaFold 2 which completely dominates all the others to the point

53
00:05:31,120 --> 00:05:38,160
where the problem is now considered to be solved. By the way if this is not a great meme template

54
00:05:38,160 --> 00:05:45,040
I don't know what is. Just saying. Just saying. They say a folded protein can be thought of as a spatial

55
00:05:45,040 --> 00:05:53,920
graph. This here attention-based okay. So I'm going to guess for sure that they've replaced this convet

56
00:05:53,920 --> 00:06:00,480
with a transformer style with an attention layer or multiple attention layers. I would guess this

57
00:06:00,480 --> 00:06:04,960
is a big transformer right here. So there was a really interesting article that came out called

58
00:06:04,960 --> 00:06:11,600
AlphaFold and Equivariance by Justas Duparas and Fabian Fuchs. I'm so sorry Fabian I don't

59
00:06:11,600 --> 00:06:16,800
know how to pronounce your name but it does sound like a swear word. Justas and Fabian Etow

60
00:06:16,800 --> 00:06:23,120
comment on the announcement from DeepMind and they said in short this module is a neural network

61
00:06:23,120 --> 00:06:28,400
that iteratively refines the structure predictions while respecting and leveraging

62
00:06:28,480 --> 00:06:34,880
an important symmetry of the problem. Namely that of rototranslations. At this point DeepMind has not

63
00:06:34,880 --> 00:06:40,240
yet published a paper so we don't know exactly how they address this. However from their presentations

64
00:06:40,240 --> 00:06:48,400
it seems possible that part of their architecture is similar to the SE3 transformer. What's the SE3

65
00:06:48,400 --> 00:06:57,440
transformer? Lo and behold our friend Max Welling has had his hands all over it. So in the abstract

66
00:06:57,440 --> 00:07:03,360
it says the SE3 transformer a variant of the self-attention module for 3d point clouds and graphs

67
00:07:03,360 --> 00:07:10,080
which is equivariant under continuous 3d rototranslations. Equivariant is important to ensure

68
00:07:10,080 --> 00:07:15,280
stable and predictable performance in the presence of nuisance transformations of the data input.

69
00:07:15,280 --> 00:07:20,000
Right by the way you might be wondering what SE3 is. Let's have a quick look at the Wikipedia

70
00:07:20,000 --> 00:07:24,960
page. We are getting into group theory which is quite an abstract concept in mathematics but

71
00:07:24,960 --> 00:07:31,840
the Euclidean group which is SE3 it talks about all of the symmetries or the group transformations

72
00:07:31,840 --> 00:07:39,440
that can be applied to Euclidean data to preserve certain properties. Namely let's say the Euclidean

73
00:07:39,440 --> 00:07:43,840
distance between two points. Well these are things like translations and rotations and

74
00:07:43,840 --> 00:07:49,200
reflections. Very interesting that you can kind of abstract one level up in mathematics and that's

75
00:07:49,200 --> 00:07:53,360
what group theory is. The other comment I want to make is that all of these folks are independently

76
00:07:53,440 --> 00:07:57,200
amazing. I've watched presentations by most of them so that there's Fabian Fuchs,

77
00:07:57,200 --> 00:08:04,400
Daniel Worrell, Volker Fischer, fantastic. By the way when we look at Fabian's About Me page

78
00:08:04,400 --> 00:08:09,200
he's a machine learning PhD student at Oxford University. His research topic is learning

79
00:08:09,200 --> 00:08:14,160
invariant representations. Simply put where most of deep learning is concerned with finding the

80
00:08:14,160 --> 00:08:20,560
important information in an input he focuses on ignoring harmful or irrelevant parts of information.

81
00:08:20,560 --> 00:08:25,840
This can be important to counteract biases or to better leverage structure in the data.

82
00:08:25,840 --> 00:08:29,760
Structure in the data that's interesting. That's quite a cool point actually because if you think

83
00:08:29,760 --> 00:08:35,200
about it you could naively if you're doing a vision classifier you could naively just look at

84
00:08:35,200 --> 00:08:39,360
all of the pixels and what they are or if you're being smart about it you go one level up and you

85
00:08:39,360 --> 00:08:44,480
look for the hidden structure in the data and that is precisely what he's talking about things like

86
00:08:44,480 --> 00:08:50,320
the symmetries that are inherent in pretty much every type of data. Okay so one last thing

87
00:08:50,320 --> 00:08:56,880
DeepMind released an official PowerPoint deck on Alpha Fold 2 and it talks about they're on a long

88
00:08:56,880 --> 00:09:02,720
term mission to advance scientific progress. Now here are some of the protein examples. Now they

89
00:09:02,720 --> 00:09:07,200
specifically call out inductive biases for deep learning models where this is exactly what we're

90
00:09:07,200 --> 00:09:13,040
talking about so clearly convolutional neural networks are one such bias which has the translational

91
00:09:13,040 --> 00:09:18,800
weight sharing. It talks about graph networks and recurrent networks and indeed attention networks

92
00:09:18,800 --> 00:09:24,000
which is very much a generalisation of pretty much all of the others. They say that they are

93
00:09:24,000 --> 00:09:29,520
putting their protein knowledge into the model so physical insights are built into the network

94
00:09:29,520 --> 00:09:36,160
structure not just the process around it and these biases reflected their knowledge of protein

95
00:09:36,160 --> 00:09:41,280
physics and geometry and you can see here that there are residues in a protein so they're modelling

96
00:09:41,280 --> 00:09:47,040
topologically which residues are connected to which other residues in this kind of 3d space.

97
00:09:47,040 --> 00:09:51,760
They specifically call out here on the structure model page that they are building a 3d

98
00:09:51,760 --> 00:09:57,520
equivariant transformer architecture so anyway if this doesn't motivate you that symmetries

99
00:09:57,520 --> 00:10:02,640
and manifolds are an exciting idea in deep learning I don't know what will. So clearly Max has been in

100
00:10:02,640 --> 00:10:09,440
this game for a long time now back in 2004 with Kingma he invented the variational Bayes auto

101
00:10:09,440 --> 00:10:16,320
encoder. It's only recently that well relatively recently that Max has been focusing in on deep

102
00:10:16,320 --> 00:10:23,280
learning. Clearly like any other field also machine learning is subject to fashion right and so if

103
00:10:23,280 --> 00:10:29,120
there is a five to ten year cycles where people get really excited about a certain topic either

104
00:10:29,120 --> 00:10:36,800
because the theory is very beautiful or it just works really well. I started in biographical models

105
00:10:36,800 --> 00:10:42,800
and independent components analysis was the talk of the day and the support vector machines and

106
00:10:42,880 --> 00:10:48,320
basically non-parametric methods and then came Bayesian methods and non-parametric Bayesian

107
00:10:48,320 --> 00:10:53,600
methods and now it's all about deep learning. So what you see is that the field is subject to these

108
00:10:53,600 --> 00:11:00,400
sort of fashions and I think it's fine because we zoom in a new very promising tool and then we

109
00:11:00,400 --> 00:11:06,160
work it out and we get the most out of it. Max is a vice president at Qualcomm so clearly he

110
00:11:06,160 --> 00:11:11,520
thinks that computation is going to be absolutely critical for the future of artificial intelligence

111
00:11:11,520 --> 00:11:15,840
but having said that he also thinks that we need to be more efficient with our hardware

112
00:11:15,840 --> 00:11:21,920
tomorrow than we are today. That's just a reality that we all have to accept. So the more compute

113
00:11:21,920 --> 00:11:27,840
we throw at it the bigger we make our models somehow the better they perform and we don't know

114
00:11:27,840 --> 00:11:33,200
precisely why that is but we do know that they will use increasingly more energy to do the

115
00:11:33,200 --> 00:11:38,080
computations for us and at some point that's just not a viable economic model anymore. We'll see a

116
00:11:38,080 --> 00:11:44,080
continuation in making deep learning and machine learning more energy efficient. So there's a really

117
00:11:44,080 --> 00:11:51,200
interesting interplay between priors, experience and generalization. We want to have machine learning

118
00:11:51,200 --> 00:11:57,440
models that generalize really well to things that they haven't seen during training. If you move them

119
00:11:57,440 --> 00:12:03,440
into a new orientation or in a new situation in the context and that's what we think of when we say

120
00:12:04,320 --> 00:12:08,480
artificial general AI which means like not just something you train on one specific topic and

121
00:12:08,480 --> 00:12:12,720
then you ask it to do that and it does it very well but if you then move it into a new context

122
00:12:12,720 --> 00:12:17,760
it just completely fails as narrow AI. So humans are clearly much more flexible if you learn something

123
00:12:17,760 --> 00:12:22,080
in one context and then when you get put into a new context that we've never seen before suddenly

124
00:12:22,080 --> 00:12:28,480
we can still do very well and so we want our agents our artificial agents also to have this property.

125
00:12:28,480 --> 00:12:33,840
Max is also a huge proponent of generative models. He thinks that generative models might be the

126
00:12:33,840 --> 00:12:39,440
future of artificial intelligence so funnily enough I think Max and Carl Friston that we had on a

127
00:12:39,440 --> 00:12:45,040
couple of episodes ago I think they would see eye to eye. Basically what everybody else in the

128
00:12:45,040 --> 00:12:49,360
scientific community does which is write down a model of the world which we call a generative

129
00:12:49,360 --> 00:12:55,440
model which is how do I imagine that the world that I'm seeing in my measurement apparatus could

130
00:12:55,440 --> 00:13:01,680
have been generated by nature. We all have the matrix going on inside our heads. We are running

131
00:13:01,680 --> 00:13:08,640
simulations of reality and we're kind of integrating over the expected value of those simulations.

132
00:13:08,640 --> 00:13:14,080
This is just something that we do all the time. That seems to be the real trick for intelligence

133
00:13:14,080 --> 00:13:21,040
at least in humans so our ability to generate the world. Max also thinks that we need to be learning

134
00:13:21,120 --> 00:13:25,920
causal relationships in our models. Causal relationships have this really interesting

135
00:13:25,920 --> 00:13:32,640
property that they generalize better so Max comes up with this wonderful example of a certain color

136
00:13:32,640 --> 00:13:38,880
of car in the Netherlands might be associated with a higher accident rate but that probably

137
00:13:38,880 --> 00:13:44,160
wouldn't generalize very well to other countries because it's just a colloquialism whereas male

138
00:13:44,160 --> 00:13:49,440
testosterone levels that's a causal factor and that's going to generalize far better to other

139
00:13:49,440 --> 00:13:56,160
countries. So try to figure out what the true physics of the world is what causes what and if

140
00:13:56,160 --> 00:14:01,920
you have this causal structure of the world you understand much more about the actual world

141
00:14:01,920 --> 00:14:06,560
and then if you move it to a new context you can generalize a lot better in this new context.

142
00:14:06,560 --> 00:14:11,680
At this stage Max has bet on so many winning horses that you've got to wonder how the hell

143
00:14:11,680 --> 00:14:18,080
does he do it so we ask him what his secret is. It's incredibly hard to predict what will become

144
00:14:18,080 --> 00:14:22,880
well known. Sometimes you just happen to be working on something that takes off like a rocket.

145
00:14:22,880 --> 00:14:28,800
When we did things like the VAE or graph neural nets it didn't feel at all like this was going

146
00:14:28,800 --> 00:14:35,200
to be a big hit. When we read some of the research from Max's students we were just blown away it

147
00:14:35,200 --> 00:14:40,880
sometimes we've got to just remind ourselves that these are fairly young folks that are in their

148
00:14:40,880 --> 00:14:46,480
early 20s that you know they've just come out of university. How is this even possible?

149
00:14:46,560 --> 00:14:51,280
I've been very blessed with being able even with my industry funding to

150
00:14:51,280 --> 00:14:56,640
provide this level of freedom to the students and I think this is really key.

151
00:14:56,640 --> 00:15:01,440
So one of the things we asked Max was how does he select his research directions?

152
00:15:01,440 --> 00:15:05,440
One of the interesting things is that he's a physicist right so many of the things

153
00:15:05,440 --> 00:15:09,840
that he's been doing are straight out of his operating playbook from the physics world.

154
00:15:09,840 --> 00:15:13,680
So things like symmetries and manifolds and even quantum.

155
00:15:13,760 --> 00:15:19,040
Like symmetries have this this deep feeling right? Symmetries pervade basically all theories

156
00:15:19,040 --> 00:15:24,160
of physics and they have this profound impact on how you formulate the mathematics of a theory

157
00:15:24,960 --> 00:15:29,840
especially when it becomes almost mysterious right? Quantum mechanics is almost mysterious.

158
00:15:29,840 --> 00:15:34,160
How on earth is quantum mechanics possible? The fascinating thing here as we discussed on our

159
00:15:34,160 --> 00:15:40,800
GPT3 episode is that many of these roads actually lead back to computation itself.

160
00:15:40,800 --> 00:15:45,040
How does the brain compute things also feels like a very deep question right? How do we even

161
00:15:45,040 --> 00:15:50,400
compute things? What is computation even and does the universe compute its solution?

162
00:15:50,400 --> 00:15:56,560
What does it mean to be predictable? Can you compute faster than the universe can compute?

163
00:15:56,560 --> 00:16:01,600
One of the key concepts that we talk about in the show this evening is the bias variance trade-off.

164
00:16:01,600 --> 00:16:06,160
Nothing comes for free. There is no machine learning without assumptions. You have to

165
00:16:06,160 --> 00:16:10,640
interpolate between the dots and to interpolate means that you have to make assumptions on

166
00:16:10,640 --> 00:16:16,880
smoothness or something like that. These prior assumptions will help you transfer from one

167
00:16:16,880 --> 00:16:20,960
domain to another domain. One of the topics we've been discussing a lot on machine learning

168
00:16:20,960 --> 00:16:26,720
street talk recently is this notion of how far can we take data-driven approaches?

169
00:16:26,720 --> 00:16:32,560
Will they take us all the way to AGI or is it just like building a tower and trying to get

170
00:16:32,560 --> 00:16:38,880
closer to the moon? Perhaps we could generate more data with data augmentation or even a simulator.

171
00:16:38,880 --> 00:16:43,440
Perhaps we could use data more efficiently with machine teaching or active learning or some kind

172
00:16:43,440 --> 00:16:50,480
of controller on how we train the model but ultimately how far can we really go?

173
00:16:50,480 --> 00:16:56,400
The big question in some sense over time is can we simply take the data-driven approach

174
00:16:57,200 --> 00:17:03,840
and extend it all the way to AGI? So Max tells us about all the different schools of thoughts

175
00:17:03,840 --> 00:17:09,840
in the AI community and of course one interesting school of thought is the likes of Gary Marcus

176
00:17:09,840 --> 00:17:14,320
and Wallyed Subba that we had on the show a few weeks ago. These people think that we need to

177
00:17:14,320 --> 00:17:19,360
have an explicit model of the world. And then on the other side we just want a classical AI

178
00:17:19,920 --> 00:17:23,040
sort of community which is no, no, no, that's going to be ridiculous. You will never be able

179
00:17:23,040 --> 00:17:28,240
to do that. You really need to imbue these models with the structure of the world.

180
00:17:28,240 --> 00:17:34,160
In the show, Max tells us where he's placing his bets but we're not going to spoil the surprise.

181
00:17:34,160 --> 00:17:39,520
So as we said before, Max is extremely well known for creating these inductive priors and

182
00:17:39,520 --> 00:17:43,760
putting them into machine learning models, helping them generalize better and be more

183
00:17:43,760 --> 00:17:50,320
sample efficient. The whole endeavor of machine learning is defining the right inductive biases

184
00:17:51,120 --> 00:17:56,800
and leaving whatever you don't know to the data. If you put the wrong inductive bias into things

185
00:17:56,800 --> 00:18:03,600
we'll, things can actually deteriorate. We talk about Hinton's capsule networks. They tell you

186
00:18:03,600 --> 00:18:11,520
well we'll just keep the abstract nature of what we want which is some stack of things that transform

187
00:18:11,520 --> 00:18:16,480
in some way that we can vaguely specify and then we ask it to learn all these things.

188
00:18:17,360 --> 00:18:22,240
We talk about Professor Kenneth Stanley's Greatness Can't Be Planned book and also

189
00:18:22,240 --> 00:18:28,080
Sarah Hooker's The Lottery Paper. The thing that both of these ideas have in common is that

190
00:18:28,080 --> 00:18:32,400
they posit that we are locked in by the decisions of our past.

191
00:18:32,400 --> 00:18:37,840
And I do feel very strongly that as a field we need to open up. So we shoot value

192
00:18:38,560 --> 00:18:41,440
original ideas much more than we currently do.

193
00:18:42,320 --> 00:18:47,280
So Professor Kenneth Stanley has a fascinating take on this. He thinks that we should be

194
00:18:47,280 --> 00:18:52,400
treasure hunters. We should find interesting and novel stepping stones that might lead us

195
00:18:52,400 --> 00:18:57,120
somewhere interesting. He thinks we should do this in all aspects of our lives.

196
00:18:57,120 --> 00:19:01,280
So we all want to monotonically increase our objectives and what we should be is treasure

197
00:19:01,280 --> 00:19:05,360
hunters. Science should be about exploration not exploitation.

198
00:19:05,360 --> 00:19:10,880
How do we extend this to peer review in science? Ironically having a consensus peer review

199
00:19:10,880 --> 00:19:16,640
encourages groupthink and convergent behavior. If we genuinely want to have an exploratory

200
00:19:16,640 --> 00:19:21,280
divergent process we should almost optimize for people disagreeing with each other in the

201
00:19:21,280 --> 00:19:27,680
peer review process. I think the reviewing in our community is far too grumpy.

202
00:19:27,680 --> 00:19:33,360
I'm continuously amazed when I read these old papers from let's say Schmidhuber and like the

203
00:19:33,360 --> 00:19:39,040
first RL papers that just came up with a bit of an idea and then they had a bit of toy data and

204
00:19:39,040 --> 00:19:43,520
right and that's a paper and it's cool. There's a dichotomy between on the one hand

205
00:19:43,520 --> 00:19:48,960
having a stamp of approval having a paper published and presenting about it and on the other hand

206
00:19:48,960 --> 00:19:55,840
having a continuous stream of research which is peer reviewed online and with some accountability.

207
00:19:56,400 --> 00:20:02,640
Yeah I think we really need to disrupt the field a little bit. Quantum machine learning is a bit

208
00:20:02,640 --> 00:20:09,840
of a mystery to most people I feel including myself and even though I learned something in

209
00:20:09,840 --> 00:20:15,680
this conversation paradoxically it's more of a mystery than before the conversation.

210
00:20:16,400 --> 00:20:22,960
Crucially Max thinks that quantum computing will hugely impact the machine learning world in the

211
00:20:22,960 --> 00:20:29,520
future. So you can think of quantum mechanics as another theory of statistics in some sense right.

212
00:20:29,520 --> 00:20:36,880
Essentially quantum neural networks have nothing to do with particles necessarily or physics.

213
00:20:36,880 --> 00:20:44,720
It's applying the math behind quantum mechanics to machine learning and building neural networks

214
00:20:44,720 --> 00:20:51,520
as layers of functions of these quantum operations that forward propagate some signal

215
00:20:52,480 --> 00:20:58,320
as Max describes really nicely in this conversation. This is the counterintuitive part which is

216
00:20:58,320 --> 00:21:02,320
you can have a probability for an event or an amplitude for an event and then you have an

217
00:21:02,320 --> 00:21:06,720
amplitude for another event and you would think that if there's two probabilities for that event

218
00:21:06,720 --> 00:21:11,360
to happen then the probability of that event should grow but in quantum mechanics they can

219
00:21:11,360 --> 00:21:16,560
cancel and then the probability is suddenly zero that the event happens. So this seems bizarre but

220
00:21:16,560 --> 00:21:24,160
nature has chosen this theory of statistics anyway. I really felt like an ELI 5 here.

221
00:21:24,160 --> 00:21:30,320
Instead of calculating with probabilities you calculate with something like the square root

222
00:21:30,320 --> 00:21:37,520
of probabilities and thus events that can only stack in classical probability theory

223
00:21:37,520 --> 00:21:43,840
can all of a sudden cancel each other out and that gives rise to really interesting math.

224
00:21:43,840 --> 00:21:48,400
We talk about Max's recent quantum paper that just got released and so that was a paper that we

225
00:21:49,120 --> 00:21:54,240
recently pushed on the archive which is quantum deformed neural networks which we basically

226
00:21:54,240 --> 00:21:58,960
first say okay what if we would take a normal neural net and implement it on a quantum computer

227
00:21:58,960 --> 00:22:05,200
and then we slightly deform it into something where states get entangled. So by doing it in

228
00:22:05,200 --> 00:22:09,600
this particular way we could still run it efficiently on a classical computer. What this

229
00:22:09,600 --> 00:22:16,240
paper here did was to build a particular type of neural network of quantum neural network

230
00:22:16,720 --> 00:22:24,720
that can under the correct assumptions be simulated efficiently on a classical computer

231
00:22:24,720 --> 00:22:30,480
but also once we have a quantum computer it can release its full power basically.

232
00:22:31,120 --> 00:22:36,960
If you want to do classical predictions does it actually help to build a neural network that

233
00:22:36,960 --> 00:22:42,480
can run efficiently on a quantum computer that can do these predictions much better. Can you write down

234
00:22:42,720 --> 00:22:50,560
maybe even normal classical problems more conveniently in this quantum statistics.

235
00:22:50,560 --> 00:22:55,520
I found the conversation with Max to be extremely helpful here and he does a great

236
00:22:55,520 --> 00:23:01,520
job of explaining what's going on. Max has another exciting paper out. Probabilistic

237
00:23:01,520 --> 00:23:06,480
numeric convolutional neural networks it's a paper by Mark Finzi, Roberto Bondeson and of

238
00:23:06,480 --> 00:23:10,720
course Max Welling and it looks at what you can do with computer vision models if you move away

239
00:23:10,720 --> 00:23:15,920
from the assumption of discreetly sampled pixel grids and move to a continuous representation

240
00:23:15,920 --> 00:23:21,120
that's more like what an actual object in the real world projected on a screen behaves like.

241
00:23:21,120 --> 00:23:27,920
The observation is when we write down a deep learning algorithm let's say on for an image

242
00:23:28,560 --> 00:23:33,440
then we sort of treat the image as pixels and we think that's the real signal that we are looking

243
00:23:33,440 --> 00:23:39,280
at but you can also ask yourself what if I remove every second pixel now actually I have a very

244
00:23:39,280 --> 00:23:43,440
different neural network but should I have a very different neural network or what if the pixels are

245
00:23:43,440 --> 00:23:50,240
actually quite randomly distributed in the plane it's just some random places where I do measurements

246
00:23:50,240 --> 00:23:55,520
maybe more on the left upper corner and and fear on the left lower corner what the predictor should

247
00:23:55,520 --> 00:24:00,720
behave in a certain consistent way and so of course then you come to realize that really what

248
00:24:00,720 --> 00:24:06,720
you're doing is with a pixel grid is sampling an underlying continuous signal. So to get away

249
00:24:06,720 --> 00:24:11,360
from this assumption of this discreet even sampling they use these objects called Gaussian

250
00:24:11,360 --> 00:24:16,480
processes to model the data and a Gaussian process it's basically a universal function

251
00:24:16,480 --> 00:24:22,080
approximated like in your own network but it gives you a measure of uncertainty and the reason you

252
00:24:22,080 --> 00:24:26,400
might want to do this are many but in short it allows you to average over every possible model

253
00:24:26,400 --> 00:24:31,840
that describes your data and gives you a better result. In doing so you can start to do really

254
00:24:31,840 --> 00:24:37,760
interesting things like subpixel sampling or work with very sparse locations but in order to do that

255
00:24:37,760 --> 00:24:42,320
you need to re-conceptualize a lot of the familiar operators that work on our linear algebra

256
00:24:42,320 --> 00:24:48,160
representations such as like the the convolutional translation operation of our weights. The way

257
00:24:48,160 --> 00:24:53,120
they got around this was super interesting. So there's a very interesting tool which is called

258
00:24:53,120 --> 00:24:59,280
the Gaussian process it's basically interpolates between dots but in places where you don't have

259
00:24:59,280 --> 00:25:05,680
a lot of data you create uncertainty because you don't know what the real signal is. What does it mean

260
00:25:05,680 --> 00:25:11,920
to do a convolution on this space? The most interesting way to describe that is by looking

261
00:25:11,920 --> 00:25:17,600
at it as a partial differential equation. So they reframe this transformation as a differential

262
00:25:17,600 --> 00:25:22,880
equation that could just be parameterized calculated out in a closed form and directly

263
00:25:22,880 --> 00:25:26,560
applied to the parameters of the model that means you don't need to like do any sampling or anything

264
00:25:26,560 --> 00:25:30,000
like that you literally just calculate this thing apply it. It would be worth going into the

265
00:25:30,000 --> 00:25:35,600
differential equation stuff by itself but it gets very complicated very quickly needless to say it

266
00:25:35,600 --> 00:25:41,040
generalizes not just translation but also things like rotations and scaling but the way that they

267
00:25:41,040 --> 00:25:45,280
really did this was by finding very clever representations. It boiled everything down to

268
00:25:45,280 --> 00:25:49,840
normal distributions or almost everything could just be done in closed form which things have been

269
00:25:49,840 --> 00:25:54,160
done with the Gaussian processes in the past but they're typically computationally expensive so if

270
00:25:54,160 --> 00:26:00,000
you can do all these updates without constant re-computation then that's a huge computation

271
00:26:00,000 --> 00:26:04,480
and an advantage. The paper does some really cool things. Some of the benefits are now that

272
00:26:04,480 --> 00:26:09,280
first of all of course you cannot work on a unstructured set of points doesn't have to be a

273
00:26:09,280 --> 00:26:14,960
grid and you can even learn the positions of those points so you cannot direct the observations

274
00:26:15,760 --> 00:26:20,720
in places where you really need to do your observations in order to improve your prediction.

275
00:26:20,720 --> 00:26:26,640
So it turns out that all of this can be remapped back onto the quantum paradigm. I must admit I'm

276
00:26:26,640 --> 00:26:31,680
almost gutted that I didn't study physics at university. Physics seems to be one of the most

277
00:26:31,680 --> 00:26:37,600
robust scientific disciplines and the folks are just so smart because it's really really difficult

278
00:26:37,600 --> 00:26:42,560
and what I notice is that it's very very difficult for external folks to get anything published in

279
00:26:42,560 --> 00:26:47,520
the physics world but there's an asymmetry the reverse isn't true loads of these physicists

280
00:26:47,520 --> 00:26:51,600
are coming into the machine learning world and they're just implementing all of these things

281
00:26:51,600 --> 00:26:57,920
whether it's symmetries manifold topology chaos it's really really interesting to see this unfold.

282
00:26:57,920 --> 00:27:05,040
We also get a take from Max about GPT-3 and so you say GPT-3 isn't very good maybe but it's a

283
00:27:05,040 --> 00:27:11,120
receding horizon right. I had a chat with my old colleague from Microsoft Ilya Karmanov about 18

284
00:27:11,120 --> 00:27:17,440
months ago he introduced me to Max Welling's work it absolutely fascinated me ever since

285
00:27:17,440 --> 00:27:23,360
and guess what Ilya left Microsoft and he went to Qualcomm. Hey Tim how's it going? Ilya is going

286
00:27:23,360 --> 00:27:30,640
great how are you? I'm good different country different job different universe it seems but

287
00:27:30,640 --> 00:27:37,040
I'm doing pretty well. Ilya and I used to be work colleagues at Microsoft UK and I left Microsoft

288
00:27:37,040 --> 00:27:41,760
about a year ago and actually you left as well didn't you Ilya? Yeah we have a joint pact it was

289
00:27:41,760 --> 00:27:48,560
like you have to keep both of us or we leave. Indeed now Ilya and I made a YouTube video

290
00:27:48,560 --> 00:27:54,160
just over a year ago and it was all about Max Welling's work with Tako Kohen all about symmetries

291
00:27:54,160 --> 00:28:00,640
and manifolds and this work was hugely inspiring for me how did you discover it? I discovered it

292
00:28:00,640 --> 00:28:05,840
because my colleague Matthew and I whom you also interviewed and you should follow up with

293
00:28:05,840 --> 00:28:12,960
that. We were at Ilya and we saw Tako's talk about spherical CNNs which was a bit late already into

294
00:28:12,960 --> 00:28:17,360
his work which started with group equilibrium convolutions and I think both of us just thought

295
00:28:17,360 --> 00:28:21,680
it was really cool it was our favorite talk for the day because it was so different and it felt

296
00:28:21,680 --> 00:28:26,720
like it was setting up a different stream of research it wasn't necessarily about chasing

297
00:28:26,720 --> 00:28:32,000
SOTA it was just about really improving taking what makes convolutions great and making them even

298
00:28:32,000 --> 00:28:37,440
better and that was awesome. Oh amazing well we made that video together on Machine Learning Dojo

299
00:28:37,440 --> 00:28:43,040
and I must admit it was hugely inspiring for me and I reached out to Max Welling about two months

300
00:28:43,040 --> 00:28:47,760
ago and he actually came onto our podcast we interviewed him yesterday but yeah it all came

301
00:28:47,760 --> 00:28:51,920
from you and you know you introduced all of this stuff to me and I've been going through some of

302
00:28:51,920 --> 00:28:57,360
Max's work with some of his recent students and it's just incredible it's because he came from

303
00:28:57,360 --> 00:29:02,400
the physics world and all of this knowledge that he has around quantum and symmetries and

304
00:29:02,400 --> 00:29:06,880
topologies and manifolds that's his operating playbook and he's just taken it into the machine

305
00:29:06,880 --> 00:29:11,040
learning world and he's just been executing on it. Max is involved in a lot of papers

306
00:29:12,160 --> 00:29:16,640
as you would expect and a fair few of them are really fascinating. Yeah one of the things we

307
00:29:16,640 --> 00:29:22,080
spoke about was just how he nurtures his PhD students because some of these papers are just

308
00:29:22,080 --> 00:29:26,880
incredible and presumably these students have gone from nothing to producing that level of

309
00:29:26,880 --> 00:29:30,160
research in a very short period of time but presumably this was one of the reasons why you

310
00:29:30,160 --> 00:29:36,960
decided to apply for Qualcomm. Yeah I was chasing something that was publishing papers in the field

311
00:29:36,960 --> 00:29:42,640
of computer vision and it's one of the places in Europe, perhaps Zurich is another location

312
00:29:42,640 --> 00:29:47,120
when you have this kind of research. I thought it was extremely different and a super interesting

313
00:29:47,760 --> 00:29:53,360
research area so to speak to get into. Fantastic and what are you working on at the moment?

314
00:29:53,360 --> 00:29:58,640
We have just submitted actually our paper to CVPR this morning, the deadlines in a few days so

315
00:29:58,640 --> 00:30:03,520
that's pretty good I think and then maybe after that as well we have a few more topics and video

316
00:30:03,520 --> 00:30:08,560
basically self-training, how to improve representation learning, it's a mix of knowledge

317
00:30:08,560 --> 00:30:15,040
distillation and self-training and then also we have some interesting work with radio signals so

318
00:30:15,040 --> 00:30:20,720
it's like video in the sense that it's from that we extract the spatial and temporal signal

319
00:30:20,800 --> 00:30:26,080
but it's extremely different to video and that also makes it super fun. Amazing when I was

320
00:30:26,080 --> 00:30:31,120
discussing machine learning with Ilya at Microsoft we were fascinated by 3d convolution on your

321
00:30:31,120 --> 00:30:36,720
networks and i3d and video action detection and I know you are working on a 3d segmentation and a

322
00:30:36,720 --> 00:30:41,360
whole bunch of cool things like that but anyway I would love to get you on the show in the next

323
00:30:41,360 --> 00:30:44,960
few weeks to talk about some of your research and for those of you in the comments if you want to

324
00:30:44,960 --> 00:30:49,920
have more from Ilya let us know are you going to give us a demonstration of your front lever?

325
00:30:50,720 --> 00:30:55,840
Okay single leg. When Ilya comes on the show properly we're going to be doing a front lever

326
00:30:55,840 --> 00:31:04,080
competition that's pretty good so not only is Ilya a specialist in machine learning

327
00:31:04,080 --> 00:31:09,360
he also absolutely smashes it in the body weight game. No that wasn't smashing it that was after

328
00:31:09,360 --> 00:31:14,320
a climbing session it's actually really cool I met this guy here who's a calisthenics instructor

329
00:31:14,320 --> 00:31:20,240
called Soli and he just started climbing and yeah so we met up and we went climbing this morning

330
00:31:20,240 --> 00:31:24,560
and he was crazy good as you would expect and he gave me some tips on my front lever as well

331
00:31:24,560 --> 00:31:28,640
he was saying I should work more on the tuck instead of the single leg so hopefully you'll

332
00:31:28,640 --> 00:31:33,680
see much better than that in the future. Amazing Ilya thank you so much for coming on the show we

333
00:31:33,680 --> 00:31:39,200
look forward to interviewing you in a few weeks time. Thanks for helping me and thanks a lot for

334
00:31:39,200 --> 00:31:43,600
interviewing Max I'm like super excited to see that in a few days. Anyway I really hope you've

335
00:31:43,600 --> 00:31:48,640
enjoyed the show today this has been such a special episode for us because Max Welling is

336
00:31:48,640 --> 00:31:55,440
literally one of my heroes so anyway remember to like comment and subscribe we love reading

337
00:31:55,440 --> 00:32:00,400
your comments we really do actually we're getting so many amazing comments in the comment section

338
00:32:00,400 --> 00:32:09,280
so keep them coming and we will see you back next week. Welcome back to the Machine Learning

339
00:32:09,280 --> 00:32:15,920
Street Talk YouTube channel and podcast with my two compadres Alex Stenlake and Yannick Kiltcher

340
00:32:15,920 --> 00:32:21,680
and today we have someone who doesn't really need any introduction at all clearly one of the most

341
00:32:21,680 --> 00:32:27,760
impactful researchers in the ML world and has as near as makes no difference 40 000 citations

342
00:32:27,760 --> 00:32:32,640
he's on the executive board at NeurIPS he's a research chair and full professor at the AMLAB

343
00:32:32,640 --> 00:32:39,280
University of Amsterdam and co-director of the CUVA lab and Delta lab Max Welling. Max is a strong

344
00:32:39,280 --> 00:32:43,600
believer in the power of computation and its relevance to machine learning which is one of

345
00:32:43,600 --> 00:32:48,240
the reasons why he holds a vice president position at Qualcomm. He thinks the fastest way to make

346
00:32:48,240 --> 00:32:53,520
progress in artificial intelligence is to make specialized hardware for AI computation. He wrote

347
00:32:53,520 --> 00:32:58,000
a response to Rich Sutton's The Bitter Lesson but essentially agrees with him in the sense that one

348
00:32:58,000 --> 00:33:03,120
should work on scalable methods that maximally leverage compute but Max thinks that data is

349
00:33:03,120 --> 00:33:07,520
the fundamental ingredient of deep learning and you can't always generate it yourself like an

350
00:33:07,520 --> 00:33:12,720
AlphaGo which amounts to an interpolation problem. Much of Max's research portfolio is currently

351
00:33:12,720 --> 00:33:16,480
based on deep learning. He thinks it's the biggest hammer that we've produced thus far

352
00:33:16,480 --> 00:33:21,120
and we witness its impact every single day. He thinks that AGI is a possibility and it will

353
00:33:21,120 --> 00:33:26,240
manifest in a forward generative and causal direction. There's a really interesting cross

354
00:33:26,240 --> 00:33:31,120
pollination story here Max has a physics background he did a PhD in physics he knows all about

355
00:33:31,120 --> 00:33:36,080
manifolds and topologies and symmetries and quantum and actually this has been his operating

356
00:33:36,080 --> 00:33:40,080
playbook he's brought all of these incredible concepts in from the physics world to machine

357
00:33:40,080 --> 00:33:45,200
learning. Now there's a fundamental blank slate paradigm in machine learning experience and data

358
00:33:45,200 --> 00:33:50,720
currently rule the roost but Max wants to build a house on top of that blank slate. Max thinks

359
00:33:50,720 --> 00:33:55,760
that there are no predictions without assumptions no generalization without inductive bias. The

360
00:33:55,760 --> 00:34:00,080
bias variance trade-off tells us that we need to use additional human knowledge when data is

361
00:34:00,080 --> 00:34:04,720
insufficient. I think it's fair to say that Max Welling has pioneered many of the most sophisticated

362
00:34:04,720 --> 00:34:09,760
inductive priors and deep learning models developed in recent years. An example of an inductive prior

363
00:34:09,760 --> 00:34:14,800
is the CNN which means we can model local connectivity, weight sharing and equivalence to

364
00:34:14,800 --> 00:34:20,160
translational symmetries in gridded vision data. This is imputing human domain knowledge into the

365
00:34:20,160 --> 00:34:26,080
architecture it makes the model significantly more robust and sample efficient. Assumptions are

366
00:34:26,080 --> 00:34:30,320
everywhere even fully connected networks assume that there is a hierarchical organization of

367
00:34:30,320 --> 00:34:34,480
concepts and even further assumptions about the smoothness of the underlying function we're

368
00:34:34,480 --> 00:34:40,400
estimating. Max and many of his collaborators for example Tako Kohen took this idea so much

369
00:34:40,400 --> 00:34:44,560
further they introduced rotational equivalence and then they built models which would work

370
00:34:44,560 --> 00:34:51,120
extremely efficiently on non-geometric curved manifolds meshes or even graphs. Max wants to

371
00:34:51,120 --> 00:34:55,920
reduce the need for data in deep learning models increasing the representational fidelity of neural

372
00:34:55,920 --> 00:35:00,720
networks subject to discretization and sampling errors and improving the computational techniques

373
00:35:00,720 --> 00:35:06,640
to process them more efficiently. Max has recently put out two new papers Quantum Deformed Neural

374
00:35:06,640 --> 00:35:11,360
Networks and Probabilistic Numeric Convolutional Neural Networks which we'll be talking about

375
00:35:11,360 --> 00:35:16,720
today. Anyway Max it's an absolute pleasure welcome to the show. Thank you very much Tim for a very

376
00:35:16,720 --> 00:35:25,520
nice introduction it almost sounded like it's not me but it was a lot. Do you feel that this

377
00:35:26,160 --> 00:35:31,920
it describes you not maybe accurately but do you feel like there's a parts of your work that are

378
00:35:31,920 --> 00:35:38,320
overly well known and there may be parts of your work that you wish would be more well known?

379
00:35:40,080 --> 00:35:45,040
It's hard to say it's overly well known because of course it's very enjoyable when you can make a

380
00:35:45,040 --> 00:35:51,120
big impact but what I can say is that it's incredibly hard to predict what will become well

381
00:35:51,120 --> 00:35:55,120
known of course if you could predict that you would only write papers with like gazillions of

382
00:35:55,120 --> 00:36:01,520
citations. When we did things like the VAE or graph neural nets it didn't feel at all like this was

383
00:36:01,520 --> 00:36:08,720
going to be a big hit and some of these things are being singled out and they fly and precisely what

384
00:36:08,720 --> 00:36:14,960
makes these papers fly is in a way that's a big puzzle in a way and some other papers you can be

385
00:36:14,960 --> 00:36:20,720
very proud of and it takes so much time to actually get published it's a huge uphill battle

386
00:36:20,720 --> 00:36:24,800
you think why do the reviewers not understand better but we really want to do here and then

387
00:36:24,800 --> 00:36:29,360
yeah and so they I guess there's a lot of good work which disappears into oblivion

388
00:36:29,360 --> 00:36:36,480
and from many people and yeah it's mysterious but anyway. Your hits definitely seem to be

389
00:36:36,480 --> 00:36:41,760
more than your misses you're a prolific researcher yourself but you've nurtured some of the best

390
00:36:41,760 --> 00:36:46,400
and brightest minds across in not just deep learning but like the wider machine learning field

391
00:36:47,120 --> 00:36:50,800
how do you consistently do that is it fantastic mentorship or is it more

392
00:36:50,800 --> 00:36:56,000
finding the right spark in a student and nurturing that and that's a really good question and I should

393
00:36:56,000 --> 00:37:00,720
say that I've been extremely blessed by all these fantastic students right from the beginning

394
00:37:01,520 --> 00:37:07,760
but I do think there is something to nurturing talent so I think what doesn't work is to basically

395
00:37:08,720 --> 00:37:12,960
tell to be very constrained to a particular topic sometimes you see this happen if you write a

396
00:37:12,960 --> 00:37:18,160
grant proposal and then the grant proposal is about topic A and then really the student

397
00:37:18,880 --> 00:37:22,800
starts at topic A but figures out after a couple of months that they don't really like

398
00:37:22,800 --> 00:37:27,440
topic A and they want to move on to B and it's just very painful then to say no no no you cannot

399
00:37:27,440 --> 00:37:34,080
do that you have to be doing A and so I've been very blessed with being able even with my industry

400
00:37:34,080 --> 00:37:41,200
funding to provide this level of freedom to the students and I think this is really key so the

401
00:37:41,200 --> 00:37:45,520
other thing which I find really key is that the relationship you have with the student is

402
00:37:45,520 --> 00:37:49,840
very important first of all it changes over the years which is also very beautiful so you start

403
00:37:49,840 --> 00:37:56,000
off with much more guidance and towards the end you should actually not be doing any supervision

404
00:37:56,000 --> 00:38:01,440
you should just having a conversation at that point on equal footing and you see about halfway

405
00:38:01,440 --> 00:38:06,800
through a phd like it's like a flower that opens and then it's now they get it suddenly right now

406
00:38:06,800 --> 00:38:12,000
they get it and they go and they have a while huge interesting ideas in all directions and they

407
00:38:12,000 --> 00:38:17,280
can write all these papers and stuff so that's a beautiful moment when that happens and the other

408
00:38:17,280 --> 00:38:23,840
thing I think is that I think of supervision as nudging in the sense that I have a big a lot of

409
00:38:24,560 --> 00:38:31,280
experience and where is where is the interesting stuff to be found right where is the next wave

410
00:38:31,280 --> 00:38:35,840
that we can get people enthusiastic about what are the important questions to address in the

411
00:38:35,840 --> 00:38:41,280
community and things like that so that's where my experience lies now I'm not doing a lot of

412
00:38:41,280 --> 00:38:46,560
coding myself in fact I'm just all doing almost zero coding which I regret for this life and the

413
00:38:46,560 --> 00:38:52,160
other thing is that even in terms of math it's limited right now right but most maybe two pages

414
00:38:52,160 --> 00:38:58,320
of math to verify something or to compute something quickly but not like a lot of math anymore I just

415
00:38:58,320 --> 00:39:04,160
try to keep up with literature mostly and the students do though so they do the hard work

416
00:39:04,160 --> 00:39:08,400
literally so they really should they should do all that work and it's this interesting

417
00:39:08,400 --> 00:39:13,840
relationship where you have a discussion where you say I think you know this is an important

418
00:39:13,840 --> 00:39:18,720
direction an interesting direction and here are some other things which are connected to it very

419
00:39:18,720 --> 00:39:23,440
intuitively right so you may want to look there and then a good student will just pick up these

420
00:39:23,440 --> 00:39:30,160
ideas and we'll run with it and then come up with new ideas and then you could say it is maybe be

421
00:39:30,160 --> 00:39:34,160
careful about this direction don't go too deep or maybe this is more an interesting direction

422
00:39:34,160 --> 00:39:40,400
stuff like that but even there I've learned to be very careful and if a student comes up with a

423
00:39:40,400 --> 00:39:45,680
good idea and intuitively I think that's actually not a great idea this is going to be a dead end

424
00:39:46,560 --> 00:39:51,760
that I'm not going to tell the student that very soon so I'm just going to certainly leave the

425
00:39:51,760 --> 00:39:58,000
student about a month to explore that idea for sure and I've been surprised right I've been

426
00:39:58,000 --> 00:40:02,560
surprised and basically it turned out it was a great idea and I was wrong and so I've been very

427
00:40:02,560 --> 00:40:08,160
careful with these things too so I feel it's a very careful dance between the student and the

428
00:40:08,160 --> 00:40:14,480
supervisor with not too much direction also it's a very personal so some students like more direction

429
00:40:14,480 --> 00:40:19,360
and other students like less direction but I think it is a bit of an art that I've learned

430
00:40:20,080 --> 00:40:24,880
to appreciate it is a little bit of an art to have the right type of relationship with students

431
00:40:24,880 --> 00:40:29,440
yeah but of course it's all about them they are the ones that need to shine in in the end

432
00:40:29,440 --> 00:40:35,680
after four years and they need to get the good jobs and become famous in terms of that guidance and

433
00:40:35,680 --> 00:40:40,560
specifically what you said with respect to this direction might be interesting these are the

434
00:40:40,560 --> 00:40:47,600
interesting research directions is this something that you just have to develop or do you have some

435
00:40:47,600 --> 00:40:54,240
general can you give some high level patterns that you've observed throughout the years where

436
00:40:54,880 --> 00:41:01,120
you see recurring things and and you say oh that's another one of those probably like short term

437
00:41:01,120 --> 00:41:06,400
hypes or yeah have you observed some general patterns there yeah so there's two things right so

438
00:41:06,400 --> 00:41:12,240
there's some things where I think why what is the big deal why is everybody chasing this particular

439
00:41:12,240 --> 00:41:19,280
direction so that's can you predict what the crowd will follow that's one thing seems pretty hard

440
00:41:20,000 --> 00:41:25,920
the other one is to find directions which may be on longer time scales

441
00:41:26,960 --> 00:41:33,520
are impactful and interesting and for the second one it is deeply intuitive and it's very hard to

442
00:41:33,520 --> 00:41:39,760
figure out precisely what it is what features there are but for me I have to get a sense that

443
00:41:40,640 --> 00:41:45,680
there is some something very deep going on that I want to pursue like for instance

444
00:41:46,640 --> 00:41:52,000
so I clearly in physics so if you can think about gauge symmetry like symmetries have this this

445
00:41:52,000 --> 00:41:57,200
deep feeling right symmetries pervade basically all theories of physics and they have this

446
00:41:57,200 --> 00:42:02,720
profound impact on how you formulate the mathematics of a theory and so there's something very deep

447
00:42:02,720 --> 00:42:08,800
about symmetries and and about sort of manifolds and doing things on curved spaces and so that's

448
00:42:08,800 --> 00:42:13,200
I could sort of naturally drawn into this thing not now it's more quantum mechanics and there's

449
00:42:13,200 --> 00:42:18,480
something very deep and especially when it becomes almost mysterious right quantum mechanics is

450
00:42:18,480 --> 00:42:22,880
almost mysterious how on earth is quantum mechanics possible if you dive a little bit into this

451
00:42:22,880 --> 00:42:28,400
phenomenon of there's a two slit experiment where you have these individual photons which which go

452
00:42:28,400 --> 00:42:33,520
over two paths and if it's a wave that's perfectly fine they can interfere with each other but now

453
00:42:33,520 --> 00:42:38,640
these photons can go one by one and somehow they have to be aware of this other possibility that

454
00:42:38,640 --> 00:42:43,600
they could have taken to interfere with that other possibility I just think that's crazy what's

455
00:42:43,600 --> 00:42:48,240
going on here and so I'm naturally drawn into sort of these kinds of mysteries in some sense

456
00:42:48,960 --> 00:42:53,200
yeah and there's plenty more and the other one is also computation clearly right how does the brain

457
00:42:53,200 --> 00:42:57,600
computing also feels like a very deep question right how do we even compute things what is

458
00:42:57,600 --> 00:43:03,680
computation even and does the universe compute its solution what does it mean to be predictable can

459
00:43:03,680 --> 00:43:09,280
you predict can you compute faster than the universe can compute and so there's all these very

460
00:43:09,280 --> 00:43:14,080
deep questions about computation as well that you can ask but there's a mixture between

461
00:43:15,040 --> 00:43:19,680
things that are attractive in that sort of mysterious sense there's something very deep

462
00:43:19,680 --> 00:43:24,880
that needs to be pursued and things which are also highly practical which is sometimes it's also

463
00:43:24,880 --> 00:43:29,360
a lot of fun to work on something that where you can actually make a big impact for instance

464
00:43:29,360 --> 00:43:37,120
speed up MRI imaging with a factor of 10 so now suddenly you can actually both image and

465
00:43:37,120 --> 00:43:42,320
radiate cancer at the same time which could have a huge impact in the future and feeling that level

466
00:43:42,320 --> 00:43:48,480
of impact is also quite exciting I think amazing so I wanted to frame up some of the work that you've

467
00:43:48,480 --> 00:43:54,240
done around symmetries and manifolds it's absolutely fascinating that prevailing idea is that we are

468
00:43:54,240 --> 00:43:57,840
wasting the representational capacity of neural networks because we're essentially learning the

469
00:43:57,920 --> 00:44:04,400
same thing many times and your work absolutely pioneered this starting with sort of rotational

470
00:44:04,400 --> 00:44:10,240
equivariance on on CNNs and then moving on to meshes and graphs and different types of topology

471
00:44:10,240 --> 00:44:15,760
it's absolutely fascinating but philosophically the modus operandi in deep learning is this blank

472
00:44:15,760 --> 00:44:22,000
slate idea this idea that if we look at data and nothing else then we can learn everything we need

473
00:44:22,000 --> 00:44:27,120
to presumably not in a very sample efficient way transformers seems to be going in this direction

474
00:44:27,120 --> 00:44:31,760
in the natural language processing world that we just ingest infinite amounts of data and we can

475
00:44:31,760 --> 00:44:37,440
learn everything we need to and we spoke to a good old-fashioned AI person while it's over

476
00:44:37,440 --> 00:44:42,160
last week and and his argument was that the information is not in the data he was arguing

477
00:44:42,160 --> 00:44:48,080
that we have a kind of ontology or knowledge built into us which we can use to disambiguate

478
00:44:48,080 --> 00:44:53,760
information that we receive so fundamentally speaking do you believe that we can be data-driven

479
00:44:53,760 --> 00:44:58,080
and can you introduce some of the work you've done with some of these priors in deep learning

480
00:44:58,640 --> 00:45:04,160
yes so this is a very fundamental debate clearly but i think it's not all that black and white right

481
00:45:04,160 --> 00:45:09,840
so there is a basically at the core of machine learning there is basically trade-offs the the

482
00:45:09,840 --> 00:45:14,560
buy is very in straight-off for instance it clearly expresses this right the first thing i want to

483
00:45:14,560 --> 00:45:19,920
say there is no machine learning without assumptions it just basically you have to interpolate between

484
00:45:19,920 --> 00:45:24,560
the dots and to interpolate means that you have to make assumptions on smoothness or something

485
00:45:24,560 --> 00:45:28,960
like that so the machine learning doesn't exist without assumptions i think that's very clear

486
00:45:28,960 --> 00:45:34,400
clearly it's a dial right so you can have on the one end you can have problems with a huge amount

487
00:45:34,400 --> 00:45:40,720
of data it has to be available clearly and there you can dial down your inductive biases you can

488
00:45:40,720 --> 00:45:48,000
basically say let that the data do most of the work in some sense and let me make my prior assumptions

489
00:45:48,080 --> 00:45:53,280
quite minimal and with minimal i think i'm interested in a smooth mapping right the mapping

490
00:45:53,280 --> 00:45:58,320
needs to be smooth like that's a very minimal assumption but the disadvantage of that is if

491
00:45:58,320 --> 00:46:05,440
you don't put any prior assumptions is that if you need to take whatever you've learned into a new

492
00:46:05,440 --> 00:46:12,080
domain where this model wasn't learned it will very quickly break down because these prior assumptions

493
00:46:12,080 --> 00:46:19,040
will help you transfer from one domain to another domain and causality does play a big

494
00:46:19,040 --> 00:46:23,760
role here but we can talk about this later and then on the other hand there is basically what

495
00:46:23,760 --> 00:46:28,320
everybody else in the scientific community does which is write down a model of the world which

496
00:46:28,320 --> 00:46:33,600
we call a generative model which is how do i imagine that the world that i'm seeing in my

497
00:46:33,600 --> 00:46:39,680
measurement apparatus could have been generated by nature and and that's that you can put a lot of

498
00:46:40,240 --> 00:46:45,840
intuitive knowledge there because you could think the world is described by a PDE or some kind of

499
00:46:45,840 --> 00:46:51,760
generative model so the people in our community often call this probabilistic programming models

500
00:46:51,760 --> 00:46:56,960
created by probabilistic programs or graphical models but they are highly intuitive highly

501
00:46:56,960 --> 00:47:02,640
interpretable and because they describe the generative process they are often also causal

502
00:47:02,640 --> 00:47:06,480
because you can think of these variables and one causes the other variable to happen etc

503
00:47:07,200 --> 00:47:13,600
and because they are causal they really generalize very well which means that if i train you know

504
00:47:13,600 --> 00:47:19,920
and someone in one context i say i learn to drive in the Netherlands i'm driving on the right side

505
00:47:19,920 --> 00:47:26,640
on the road i have particular kind of traffic signs etc so now i can take whatever i've learned

506
00:47:26,640 --> 00:47:31,120
sort of these rules or whatever i've learned and now i can move to another country where you

507
00:47:31,120 --> 00:47:34,960
drive on the left hand side of the road completely different traffic signs and i can still survive

508
00:47:34,960 --> 00:47:40,320
so this is typically something that the the the purity data driven methods have a much harder

509
00:47:41,040 --> 00:47:47,920
time doing this sort of generalization so i think this is basically a trade of now it's it's the big

510
00:47:47,920 --> 00:47:55,920
question in some sense over time is can we simply take the data driven approach and extended all

511
00:47:55,920 --> 00:48:02,560
the way to agi but there are people on one side of the fence that are claiming that this is possible

512
00:48:02,800 --> 00:48:08,080
of course we also need to amplify computation right so we're just going to build faster and

513
00:48:08,080 --> 00:48:15,440
faster computers that can digest more and more data and at some point we'll just have agi emerge

514
00:48:15,440 --> 00:48:20,960
out of this kind of process and then on the other side we just want a classical ai sort of community

515
00:48:20,960 --> 00:48:24,960
which is no no no that's going to be ridiculous you will never be able to do that you really need

516
00:48:24,960 --> 00:48:31,840
to imbue these models with the structure of the world which which i take as how does physics work

517
00:48:31,840 --> 00:48:36,800
how does the world work can i tell you something about how data really gets generated in this work

518
00:48:36,800 --> 00:48:42,000
this will cut down the number of parameters to learn dramatically and because i'm following

519
00:48:42,000 --> 00:48:48,960
causality i can now basically generalize and create agi in this way and so this is going to be

520
00:48:48,960 --> 00:48:53,760
very interesting how this is going to play out and you know to be honest so i feel that i'm slightly

521
00:48:53,760 --> 00:48:59,440
in the camp of you really need to put generative information into your models but i've been continually

522
00:48:59,440 --> 00:49:04,400
surprised by what's happening on the other side of course lots of my work is also on the other side

523
00:49:05,200 --> 00:49:11,600
in the sense that gpt3 you know is completely 100 data driven and did we expect that it would

524
00:49:11,600 --> 00:49:17,920
do so well no so he is another big surprise right and so that's i think that's the fun part but it

525
00:49:17,920 --> 00:49:22,800
kind of doesn't do well though it doesn't have any reversibility so if you ask it how many feet fit

526
00:49:22,800 --> 00:49:29,040
in a shoe or we did the example last week so the corner table wants another beer it doesn't know

527
00:49:29,040 --> 00:49:33,200
that the corner table is a person because that's missing information we would fill in those gaps

528
00:49:33,200 --> 00:49:38,000
but it does raise the question though of the dichotomy between memorization and compute

529
00:49:38,000 --> 00:49:43,120
and the guy we were speaking to last week just said that even if you had an infinite amount of

530
00:49:43,120 --> 00:49:48,640
memory and the data is just not there you couldn't do it when you were responding to rich sutton and

531
00:49:48,640 --> 00:49:52,880
you actually spoke about all the different schools of thought in machine learning so you said compute

532
00:49:52,880 --> 00:49:58,640
driven versus knowledge and model driven or data driven and symbolic or statistical and white box

533
00:49:58,640 --> 00:50:03,200
or black box and generative and discriminative the generative thing is fascinating because our

534
00:50:03,200 --> 00:50:07,360
brains it's a bit like we've got the matrix or we've got a simulation going on behind the scenes

535
00:50:07,360 --> 00:50:11,600
haven't we we're always thinking about all these potential situations and possibly integrating

536
00:50:11,600 --> 00:50:17,680
between them yes i i do agree that seems to be the real trick for intelligence at least in humans

537
00:50:17,680 --> 00:50:24,800
so our ability to generate the world at least at a symbolic level we don't generate like high

538
00:50:24,800 --> 00:50:31,200
resolution videos in our brain but we do generate objects and interactions between objects and sort

539
00:50:31,200 --> 00:50:37,200
of how things will play out and this will also help us imagine things like what would have happened

540
00:50:37,200 --> 00:50:41,920
if i would have done this so now i can play out this alternative world and say that was bad let

541
00:50:41,920 --> 00:50:46,800
let me not do this now so i think that is going to be a key so that's the generative part of the

542
00:50:46,800 --> 00:50:52,640
modeling because you can generate you understand how the world works the physics of the world works

543
00:50:52,640 --> 00:50:57,440
and so you can generate possible futures to me i feel that's going to be a really important part

544
00:50:57,440 --> 00:51:04,720
of intelligence and i do agree that it's for me also very hard to see that you can generate enough

545
00:51:04,720 --> 00:51:10,720
data to cover all corner cases it's just very tough if you do it in the wrong direction which is the

546
00:51:10,720 --> 00:51:16,560
discriminative direction but again i have been surprised by how good these models really are

547
00:51:16,560 --> 00:51:23,680
and so you say gpt3 isn't very good maybe but it's a receding horizon right people may have not

548
00:51:23,680 --> 00:51:28,880
thought this was true or bet on something like gpt3 before it appeared and then it appeared and

549
00:51:28,880 --> 00:51:32,800
people were extremely impressed and then of course some people poke it and say but it doesn't

550
00:51:32,800 --> 00:51:37,840
understand this and this and then excitement goes away again a little bit but it is a bit of a

551
00:51:37,840 --> 00:51:41,920
receding horizon but i have generally be very impressed also with for instance the fact that

552
00:51:41,920 --> 00:51:48,320
we cannot generate faces of people that that don't exist we can create billions of faces that

553
00:51:48,320 --> 00:51:53,680
that don't exist on this planet and that look absolutely realistic would i have expected this

554
00:51:53,680 --> 00:51:58,480
no probably not so no and then of course there's alpha go and things like this which we also wouldn't

555
00:51:58,480 --> 00:52:03,760
have expected right before it happens let me play a bit of devil's advocate with respect to

556
00:52:04,320 --> 00:52:11,760
building priors into models it's of course like some of the easiest priors we can think of are

557
00:52:11,760 --> 00:52:18,000
let's say translation invariance in a cnn you can also extend this to rotational invariance and so

558
00:52:18,000 --> 00:52:25,200
but if we look at a true practical problem we say yes it makes sense that there is a rotational

559
00:52:25,200 --> 00:52:32,960
invariance in the world however on the image net dataset like for a real practical problem the sky

560
00:52:32,960 --> 00:52:39,200
is usually up and the object is usually in the center it's not like to the side it's it's usually

561
00:52:39,200 --> 00:52:46,960
in the center so in a way it seems like if we actually hit the true invariance that the world

562
00:52:47,520 --> 00:52:54,400
adheres to it's certainly beneficial but if we even slightly deviate if we build in a different

563
00:52:54,400 --> 00:53:00,480
invariance it seems like there is a level of accuracy and if we want to get past that these

564
00:53:00,480 --> 00:53:06,400
invariance seems to be hurting do you have a sense of can it be counterproductive or when is it

565
00:53:06,400 --> 00:53:12,800
counterproductive to build in such invariances it's a very good question and so this goes to the

566
00:53:12,800 --> 00:53:19,760
point of the bias variance decomposition again so if you hit the right bias then it can be beneficial

567
00:53:20,480 --> 00:53:26,160
if you you know impose the wrong bias then it's going to hurt you and this is a well-known trade

568
00:53:26,160 --> 00:53:32,480
off so of course the whole endeavor of machine earning is defining the right inductive biases

569
00:53:33,280 --> 00:53:39,760
and leaving whatever you don't know to the data and then basically learning to focus your models

570
00:53:39,760 --> 00:53:44,560
on the data that you're actually seeing but I agree if you put the wrong inductive bias in it

571
00:53:44,560 --> 00:53:51,840
things will be things can actually deteriorate now I should say here that for the rotation

572
00:53:51,840 --> 00:53:56,560
invariance or equivariance things are not as bad as you might think so you said if you just have

573
00:53:56,560 --> 00:54:03,120
slightly wrong inductive bias then it hurts but that happens to be not so much the case because

574
00:54:03,120 --> 00:54:10,800
there's objects inside images that do have if you turn a cat upside down or a tree upside down we

575
00:54:10,800 --> 00:54:16,560
still recognize it as a tree in some sense and it does give you a sort of robustness to to certain

576
00:54:16,560 --> 00:54:21,920
transformations on these objects that you would otherwise maybe try to model by data augmentation

577
00:54:22,000 --> 00:54:27,760
and stuff like that now for the sky maybe you're right that similarly in the digits a six and a

578
00:54:27,760 --> 00:54:33,040
nine you know you will start to confuse a six and a nine if you build in rotation and equivariance

579
00:54:33,040 --> 00:54:37,680
right and so there it will actually hurt but it's been surprisingly robust actually because

580
00:54:37,680 --> 00:54:41,920
basically because you also cut down on a number of parameters and by cutting down on the number of

581
00:54:41,920 --> 00:54:48,480
parameters you will you can actually help the system generalize better so the inductive bias

582
00:54:48,480 --> 00:54:53,760
doesn't have to be perfect and it can still help could we touch on the dichotomy between the work

583
00:54:53,760 --> 00:54:58,400
you've done and capsule networks for example as well as the sample efficiency thing for example

584
00:54:58,400 --> 00:55:04,720
with translational equivariance it means that you can you can move the dog and then the response map

585
00:55:04,720 --> 00:55:08,640
the dog has moved as well and much of that is about allowing neural networks to learn patterns more

586
00:55:08,640 --> 00:55:13,760
easily because they can map in every single layer so with capsule networks that's still a blank slate

587
00:55:13,840 --> 00:55:16,640
philosophy so you don't explicitly say what the capsules are

588
00:55:17,360 --> 00:55:22,400
whereas with with your approaches you explicitly define the priors with capsules it seems to be

589
00:55:22,400 --> 00:55:27,840
defined by the data you give it so if you train a capsule network on MNIST data it might inadvertently

590
00:55:27,840 --> 00:55:32,560
learn that one of the capsules is how bendy the stroke width is on the seven or it might learn

591
00:55:32,560 --> 00:55:37,760
that there's a rotation on the car because you've given it lots of rotated versions of the same car

592
00:55:37,760 --> 00:55:42,640
but it seems quite arbitrary and the algorithm is hideously inefficient and what's much more

593
00:55:42,640 --> 00:55:48,080
exciting to me is the kind of baked-in priors that you've designed in the encoder stage so could

594
00:55:48,080 --> 00:55:53,040
you draw the dots up between those two approaches yeah i think you actually you said it quite right

595
00:55:53,040 --> 00:55:58,880
so one is a much more constrained system than the other one but the actual representations that we

596
00:55:58,880 --> 00:56:06,960
put in our hidden layers in both cases are very similar they are stacks vectors and these vectors

597
00:56:06,960 --> 00:56:13,520
transform under certain operations so if i rotate the input then there is some operation on this

598
00:56:13,520 --> 00:56:20,160
stack of vectors which is they do rotate in the x y plane but they also permute in the sort of

599
00:56:20,160 --> 00:56:26,880
vector dimension and so that we tell it very explicitly how to transform we just say under

600
00:56:26,880 --> 00:56:31,920
these transformations you have to transform like this and we can do this because these these geometric

601
00:56:32,560 --> 00:56:38,320
transformations we know them that they appear in the real world but so it's also constraining

602
00:56:38,320 --> 00:56:43,520
because there is many other transformations that either we don't know precisely what the

603
00:56:43,520 --> 00:56:50,640
mathematics for the representations looks like or for instance like groups that are that are not

604
00:56:50,640 --> 00:56:55,440
compact maybe maybe we have looked at scaling but it's already a more of a stretch but there's of

605
00:56:55,440 --> 00:57:00,240
course you can do many other types of transformations that don't even have to be groups there could be

606
00:57:00,240 --> 00:57:05,840
other types of transformations like lighting changes or whatever if you wanted to incorporate

607
00:57:05,840 --> 00:57:10,160
all of these you would have to build the mathematical representation theory for each of them and then

608
00:57:10,160 --> 00:57:14,320
it would actually also explode in a number of feature maps that you would have to maintain

609
00:57:14,320 --> 00:57:20,080
and it's not a very practical approach so this works up to the transformation groups that we

610
00:57:20,080 --> 00:57:25,040
understand and that are everywhere around us if we want to go beyond it then basically something

611
00:57:25,040 --> 00:57:30,640
like capsules are very nice because they tell you well we'll just keep the abstract nature

612
00:57:30,640 --> 00:57:37,040
of what we want which is some stack of things that transform in some way that we can vaguely

613
00:57:37,040 --> 00:57:42,720
specify and then we ask it to learn all these things and we are actually ourselves also looking

614
00:57:42,720 --> 00:57:48,160
at these sort of more relaxed notions of equivariance where we don't tell the system precisely

615
00:57:48,160 --> 00:57:52,960
how to change we just want this to emerge automatically and again here the connection

616
00:57:52,960 --> 00:57:59,040
with the brain is very interesting in the brain we do seem to have all sorts of filters which are

617
00:57:59,040 --> 00:58:04,640
related by not only by rotations but all sorts of other transformations and they are topographically

618
00:58:04,640 --> 00:58:10,640
organized so they are right the ones that are related like a slightly rotated version is sitting

619
00:58:10,640 --> 00:58:17,200
right next to the other one in your brain and so presumably your brain have figured this out by

620
00:58:17,200 --> 00:58:21,680
just looking into the world for a long time and it's organized all these filters that way

621
00:58:22,320 --> 00:58:28,160
and it's known that if you prevent let's say a cat from seeing then it will not come up with

622
00:58:28,160 --> 00:58:33,360
this nice organization so you really have to get that by looking into the world a lot and that's

623
00:58:33,360 --> 00:58:38,480
super fascinating and I think that's where some of our research is being directed now can we learn

624
00:58:38,480 --> 00:58:42,880
from how this happens in the brain is there a connection between these topographic maps and

625
00:58:42,880 --> 00:58:48,800
equivariance somehow and between capsules and all of these things and I believe that it is a good

626
00:58:48,880 --> 00:58:54,880
strategy to to take the general ideas equivariance and then slowly relax it and let the system learn

627
00:58:54,880 --> 00:59:03,280
more and more so these capsule networks they've been a bit hyped when they were not really developed

628
00:59:03,280 --> 00:59:11,440
named first by Jeff Hinton and he has this concept or at least had it at the beginning that it's some

629
00:59:11,440 --> 00:59:18,080
sort of like an inverse rendering pipeline so the sort of the capsule networks do some sort of

630
00:59:18,160 --> 00:59:25,200
they take in the world and they inverse render it into these capsules how much do you agree with

631
00:59:25,200 --> 00:59:30,000
that type of formulation it seems what you've described is more of a forward way of looking at

632
00:59:30,000 --> 00:59:36,000
capsules where we have these invariances yeah yeah so I don't I very much agree with this idea that

633
00:59:36,000 --> 00:59:41,360
you have smaller things and they can be used in multiple ways but you have to align them in a

634
00:59:41,360 --> 00:59:46,800
particular way so that they build something at the higher level and obviously you can invert that

635
00:59:46,800 --> 00:59:53,200
idea too in order to start at something very abstract and then generate certain things this way

636
00:59:53,920 --> 01:00:00,960
and there is a lot of work now actually going into equivariant generative models for instance

637
01:00:00,960 --> 01:00:05,440
equivariant flows a prime example is for instance in physics and what's called quantum

638
01:00:05,440 --> 01:00:09,360
quorum or dynamics there is there's a theory that has a huge number of symmetries called

639
01:00:09,360 --> 01:00:16,400
gauge symmetries and if you transform these quarks in a way in a particular way the physics

640
01:00:16,400 --> 01:00:20,800
doesn't change you will have exactly the same observations right but still you need these

641
01:00:20,800 --> 01:00:27,040
all these symmetries to conveniently describe this model and so now when you generate you if you

642
01:00:27,040 --> 01:00:32,160
want to generate quark fields or something like this right then gauge fields then you can generate

643
01:00:32,160 --> 01:00:36,320
all these symmetries and it's not very helpful because you generate one configuration but you

644
01:00:36,320 --> 01:00:42,160
then if you generate all these sort of equivalent things which are only you know different by symmetry

645
01:00:42,160 --> 01:00:45,680
then you haven't really done much so understanding how to generate with these

646
01:00:45,680 --> 01:00:51,280
equivalents in it is actually a big topic of research in many groups I think you know Danilo

647
01:00:51,280 --> 01:00:56,800
Rosenda and this friend in DeepMind has done a lot of work and there's physicists at MIT and who

648
01:00:56,800 --> 01:01:02,400
don't work and we are with a group of students and physicists at Amsterdam we're also looking at these

649
01:01:02,400 --> 01:01:08,720
types of questions so that's I guess the inverse problem where also equivalents is playing an

650
01:01:08,720 --> 01:01:14,400
increasingly important role not many people are working on capsules I feel they've fallen

651
01:01:14,400 --> 01:01:22,240
out of the favor of the public because I don't know they're maybe hard to implement or they don't

652
01:01:22,240 --> 01:01:28,160
really work as advertised let's say do you have general thoughts about capsule networks I think

653
01:01:28,160 --> 01:01:33,360
with many of these things there is an underlying intuition which is correct so I haven't really

654
01:01:33,360 --> 01:01:39,440
worked myself in trying to implement them and so what's what you often see in this field is that

655
01:01:39,440 --> 01:01:45,440
there is an intuition about how something should work and often that's that is the correct intuition

656
01:01:45,440 --> 01:01:49,040
especially when it's coming from Jeff Hinton it is very likely to be the correct intuition

657
01:01:49,600 --> 01:01:54,960
now then there's the next step which is how do you make something practically implementable

658
01:01:54,960 --> 01:01:59,600
and these days that means that you have to run it super fast right you have to be able to implement

659
01:01:59,600 --> 01:02:06,320
it in GPUs all these kinds of constraints otherwise you will be so much slower than just an ordinary

660
01:02:06,320 --> 01:02:12,160
cnn and you will basically not be able to train as long as a cnn and you cannot train as many

661
01:02:12,160 --> 01:02:16,160
parameters as an ordinary cnn and you will not beat it and if you don't have the bold numbers

662
01:02:16,720 --> 01:02:21,600
hard to publish and so that might impede progress in something like this but then what happens is

663
01:02:21,600 --> 01:02:26,800
you wait and then for five or ten years and then the computers have become faster and then people

664
01:02:26,800 --> 01:02:30,240
go back to these ideas and then they think oh that was actually very interesting let me try again

665
01:02:30,800 --> 01:02:36,160
and then suddenly things start to work now that's of course the story of deep learning

666
01:02:36,160 --> 01:02:41,280
more generally speaking right because we had you know neural networks like a long time ago

667
01:02:41,920 --> 01:02:47,920
right in the 80s it was actually quite popular to work on these things but they didn't quite

668
01:02:47,920 --> 01:02:52,800
take off because we didn't have the compute power and maybe also not the the data to really train

669
01:02:52,800 --> 01:02:59,200
them well and it's only when we took them out of the the closet again and said hey man this thing

670
01:02:59,200 --> 01:03:04,400
actually works if you throw a whole bunch of GPUs at it that's when people then became popular again

671
01:03:04,400 --> 01:03:09,280
and so something like this might well happen again with with capsules or it is something like

672
01:03:09,280 --> 01:03:14,720
capsules in then by five to ten years do you have any other than capsule networks are there

673
01:03:14,720 --> 01:03:20,480
things that right now we are not looking back on but that would you know be worthy of of a revisit

674
01:03:21,120 --> 01:03:28,160
oh yeah that's very tough but i'm personally looking at things like ICA and topographic ICA

675
01:03:28,160 --> 01:03:34,320
so i think there's an interesting body of ideas there of course i risk now to mow away the grass

676
01:03:34,320 --> 01:03:40,560
before my own feet but okay let me let me entertain that and then probably marker

677
01:03:40,560 --> 01:03:45,120
random fields and things like this will probably make a comeback at some point or graphical models

678
01:03:45,200 --> 01:03:50,800
more generally will probably make a comeback or maybe that integrated with deep learning and

679
01:03:50,800 --> 01:03:54,960
some people have already attempted going in that direction energy based models have made a comeback

680
01:03:54,960 --> 01:04:01,280
already so yeah it is often going back to older ideas and there's probably a lot more that other

681
01:04:01,280 --> 01:04:06,800
people can sort of name i do have a prediction maybe for the future that people really haven't

682
01:04:06,800 --> 01:04:11,520
looked at yet in my opinion it's going to be quantum things so i think many people don't

683
01:04:11,520 --> 01:04:18,480
actually know understand the language of quantum mechanics or mathematics and i do think that first

684
01:04:18,480 --> 01:04:22,080
of all that language is very interesting it's a bit different than our normal probabilities it's

685
01:04:22,080 --> 01:04:26,800
like square roots of probabilities and with the advent of quantum computers which at some point

686
01:04:26,800 --> 01:04:34,080
will come we as a community will have to dive into that and maybe make it part of our curriculum

687
01:04:34,080 --> 01:04:40,000
and in university and then i think that will become that will start to boom could i just

688
01:04:40,000 --> 01:04:44,720
quickly introduce before we get to quantum i don't know if you read sarah hookers the hardware

689
01:04:44,720 --> 01:04:50,320
lottery paper and this is fascinating for you of course working at qualcomm but her idea was that

690
01:04:50,320 --> 01:04:54,720
there are certain things that cause a inertia or friction in the marketplace of ideas so is it a

691
01:04:54,720 --> 01:05:00,080
meritocracy of ideas or do the previous kind of hardware decisions and hardware landscape

692
01:05:00,080 --> 01:05:04,240
does it enslave us you know ideas succeed if they're compatible with the hardware and the

693
01:05:04,240 --> 01:05:08,800
software at the time and this is what she called a hardware lottery and she says the machine learning

694
01:05:08,800 --> 01:05:12,640
community is exceptional because the pace of innovation is so fast it's not like in the

695
01:05:12,640 --> 01:05:17,120
hardware world which you all know so well where it costs so much money to develop new hardware

696
01:05:17,120 --> 01:05:22,800
and the cost of being scooped is so high but i wanted to just come at this from i don't know

697
01:05:22,800 --> 01:05:27,360
how you see this right so with capsule networks the reason they're so slow is because it's a kind

698
01:05:27,360 --> 01:05:32,560
of sequential computing paradigm and no amount of hardware is going to solve that but there are

699
01:05:32,560 --> 01:05:36,800
entirely different paradigms of hardware like quantum which could potentially change the game

700
01:05:36,800 --> 01:05:41,520
but how much could they change the game is there still some limit on it there's always a limit

701
01:05:41,520 --> 01:05:47,200
clearly but i think the the situation is maybe slightly more subtle which is that working in a

702
01:05:47,200 --> 01:05:53,920
hardware company i can also see the other side of the coin a little bit so there is also a race

703
01:05:53,920 --> 01:06:00,720
in the hardware companies to build ASIC designs like which is specialized hardware to run the

704
01:06:00,720 --> 01:06:05,760
latest and the greatest machine learning algorithms which are being developed so it's not just rich

705
01:06:05,760 --> 01:06:10,560
machine learning algorithms work well on the current hardware that us being enslaved to the

706
01:06:10,560 --> 01:06:16,560
hardware there is actually a feedback which where now the companies are trying to build ASIC to first

707
01:06:16,560 --> 01:06:24,800
of all run the confolutions very efficiently and soon we'll have probably transformers run very

708
01:06:24,800 --> 01:06:30,000
efficiently and so that's the fascinating thing of course it's hard to get your paper published

709
01:06:30,000 --> 01:06:35,040
perhaps if if you're ahead of the game too much which i see a little bit in the machine learning

710
01:06:35,040 --> 01:06:40,000
community which is if you look at the papers which are published in the physics community they work

711
01:06:40,000 --> 01:06:45,440
with images of four by four pixels that's what they can do because otherwise you need a quantum

712
01:06:45,440 --> 01:06:51,280
computer obviously to run your algorithm and it's being looked down upon a lot by the machine

713
01:06:51,280 --> 01:06:56,320
learners basically saying what do we you know what why is that interesting and i do feel very

714
01:06:56,320 --> 01:07:03,200
strongly that as a field we need to open up so we we should value original ideas much more

715
01:07:03,200 --> 01:07:07,440
than we currently do and i don't know you know you can probably have a whole conversation on

716
01:07:07,440 --> 01:07:14,880
where this is coming from i think the reviewing in our community is far too grumpy i think people

717
01:07:14,880 --> 01:07:20,720
if it's not completely finished polished paper then you know they'll find a hole somewhere and

718
01:07:20,720 --> 01:07:27,200
they start pushing on it and i think you should look also at a sort of more holistic how original

719
01:07:27,200 --> 01:07:32,640
is this idea right can you be excited about the originality and the creativity of the idea that

720
01:07:32,640 --> 01:07:39,600
went into that and trust that maybe it takes the community a couple of years to further develop this

721
01:07:39,600 --> 01:07:45,600
and and and some things will die and that's fine but let all these flowers grow in a way and yeah so

722
01:07:45,600 --> 01:07:50,400
i i do feel a little bit that sometimes is a bit negative and i and that's maybe where some of

723
01:07:50,400 --> 01:07:55,360
that friction is coming from that yeah just on that it's fascinating we're talking to Kenneth

724
01:07:55,360 --> 01:08:00,400
Stanley on monday and he wrote a book greatness can't be planned and his big thing is exactly what

725
01:08:00,400 --> 01:08:04,880
you've just said that we have this convergent behavior in so many of our systems whether it's

726
01:08:04,880 --> 01:08:11,120
science or academia and it's because of this objective obsession so we all want to monotonically

727
01:08:11,120 --> 01:08:15,520
increase our objectives and what we should be is treasure hunters yes science should be about

728
01:08:15,520 --> 01:08:20,960
exploration not exploitation exploitation is one step away you already know how to build the bridge

729
01:08:20,960 --> 01:08:26,800
we don't seem to have this paradigm at the moment even when you submit your paper to be reviewed

730
01:08:26,800 --> 01:08:31,680
there's a consensus mechanism isn't there because you need to have multiple accepts from people and

731
01:08:31,680 --> 01:08:37,280
science advances one funeral at a time yes do you think this is a huge problem yeah i think it is a

732
01:08:37,280 --> 01:08:41,280
big problem but i think also we will probably i think it's a big problem because it will hold us

733
01:08:41,280 --> 01:08:46,960
back and it will also hold very brilliant students back so what do i advise my students now i advise

734
01:08:46,960 --> 01:08:53,200
them to have a mixed model a mixed sort of policy which is on the one hand you work on some papers

735
01:08:53,200 --> 01:08:58,560
which are easy to score on things that are very popular in the community and then on the other

736
01:08:58,560 --> 01:09:04,080
hand you work on things which might be you know huge innovations that are much more uncertain

737
01:09:04,080 --> 01:09:09,600
they might fail but then they might also be really big innovations and that way you get your papers

738
01:09:09,600 --> 01:09:14,080
and you can become famous but at least also you work on things which are highly risky but in fact

739
01:09:14,720 --> 01:09:19,840
it's a bit cynical to have to do that it would be much nicer if there would be much more appreciation

740
01:09:19,840 --> 01:09:26,400
for just originality and but i do also believe there is a solution to this so i think we are in

741
01:09:26,400 --> 01:09:31,040
a sort of a local minimum as a community in this sense but i think there's a way out and one way

742
01:09:31,040 --> 01:09:36,720
out which is basically and this has been already proposed a long time ago i think young mcconn

743
01:09:36,720 --> 01:09:41,840
and yasha benji were also talking about this and we are actually trying to implement this for a

744
01:09:41,840 --> 01:09:48,640
beige and deep learning workshop is to sort of to throw papers on the archive and not necessarily

745
01:09:48,640 --> 01:09:56,800
submit to conferences and to have a open reviewing of that and to give people reputation indices so if

746
01:09:56,800 --> 01:10:02,560
you do if you give a good review you can publish your own review or state it in your cv and people

747
01:10:02,560 --> 01:10:08,960
can rate your review and if you do poorer reviews you'll get horrible ratings and then your reputation

748
01:10:08,960 --> 01:10:14,000
will come down so there is some kind of way that you can probably design is that people are incentivized

749
01:10:14,000 --> 01:10:19,440
to give good reviews and to actually use these reviews as a half a paper that you can also be

750
01:10:19,440 --> 01:10:24,320
proud of and then good things will come up right they will at some point people will point to

751
01:10:24,320 --> 01:10:29,920
interesting ideas maybe we need some kind of recommender to make sure it's a bit unbiased in

752
01:10:29,920 --> 01:10:34,400
the sense that it's not only the famous people that will get their papers exposed but also less

753
01:10:34,400 --> 01:10:37,920
famous people so we need to have sort of maybe build a recommender around something like that

754
01:10:38,640 --> 01:10:43,440
every so now and then a conference comes by and it sort of harvests in this field of sort of

755
01:10:43,440 --> 01:10:48,880
papers and say that one you're all reviewed they have great reviews i'll take one or two more reviews

756
01:10:48,880 --> 01:10:54,240
anonymously and i'll then publish and then i invite you to present your paper in our conference

757
01:10:54,240 --> 01:11:01,120
that to me sounds like a much more natural way to proceed i also find it very demotivating for

758
01:11:01,120 --> 01:11:05,840
my students who have these ideas maybe this is the worst part so you're a student you're working on

759
01:11:05,840 --> 01:11:10,720
this thing which is not completely mainstream and then you get rejected two or three times from a

760
01:11:10,720 --> 01:11:16,720
conference right this is so demotivating for a student to then continue right at this case at

761
01:11:16,720 --> 01:11:21,040
least you just you push us on the archive and you engage with the community around your paper

762
01:11:21,680 --> 01:11:25,840
and that's a much more it's much less demotivating than these constant rejections

763
01:11:26,400 --> 01:11:31,440
from the big prizes right the NERIAPS paper or the ICML paper that everybody wants

764
01:11:31,440 --> 01:11:36,160
is like guys the idea at the moment a lot of people are talking about this how can we improve

765
01:11:36,160 --> 01:11:41,600
peer review like in every field people are moving towards this open review model but

766
01:11:41,600 --> 01:11:45,840
collectively as a research community we don't really have the collaboration tools at this

767
01:11:45,840 --> 01:11:51,280
point in time to take advantage of it open review is willing to implement this actually so yeah i

768
01:11:51,280 --> 01:11:57,760
think it will happen yeah it it's a good system to pivot back into new ideas and sort of exciting

769
01:11:57,760 --> 01:12:02,160
concepts that are coming out machine learning at the moment you mentioned quantum computing is this

770
01:12:02,160 --> 01:12:06,160
paradigm that's really critical that's not really well understood by the machine learning

771
01:12:06,160 --> 01:12:11,440
community would you be able to give our listeners like the five-minute spiel about quantum probability

772
01:12:11,440 --> 01:12:16,160
how it differs from the probabilities that we're used to yeah so you can think of quantum mechanics

773
01:12:16,160 --> 01:12:22,800
as another theory of statistics in some sense right so in AI for everything we can't totally

774
01:12:22,800 --> 01:12:28,000
observe we write down probabilities of things happening but of course underlying there is

775
01:12:28,000 --> 01:12:32,960
processes but we just don't observe everything and so we describe it by probability now in quantum

776
01:12:32,960 --> 01:12:38,560
mechanics it's very similar to taking the square root of a negative number in some sense it's like

777
01:12:38,560 --> 01:12:43,760
you let me put another way so it's very much like taking the square root of a probability

778
01:12:43,760 --> 01:12:49,600
which can actually become negative so minus one squared is one right okay or let's say

779
01:12:49,600 --> 01:12:55,920
minus two squared is four four is your probability and minus two could be your quantum amplitude

780
01:12:56,000 --> 01:13:02,560
this thing can be negative and the bizarre thing is that if you describe a system by these

781
01:13:02,560 --> 01:13:08,080
quantum amplitude these square roots then they can cancel which is this this is the counter

782
01:13:08,080 --> 01:13:13,120
intuitive part which is you can have a probability for an event or an amplitude for an event and then

783
01:13:13,120 --> 01:13:17,520
for you have an amplitude for another event and you would think that if there's two probabilities

784
01:13:17,520 --> 01:13:22,320
for that event to happen then the probability of that event should grow but in quantum mechanics

785
01:13:22,320 --> 01:13:27,040
they can cancel and then the probability is suddenly zero that the event happens so this

786
01:13:27,040 --> 01:13:33,360
seems bizarre but nature has chosen this theory of statistics anyway and so it behooves us to

787
01:13:33,360 --> 01:13:42,800
look into this more so first question is can you write down maybe even normal classical problems

788
01:13:42,800 --> 01:13:48,320
more conveniently in this quantum statistics and here I always remind myself when I first

789
01:13:48,320 --> 01:13:54,480
learned complex numbers when you learn to solve the damped oscillator equation you can do it in

790
01:13:54,480 --> 01:14:00,560
a complicated way or you can go to complex numbers and then suddenly it gets very easy to do it and

791
01:14:00,560 --> 01:14:07,440
so you can imagine that there is things to compute in classical statistics that are actually either

792
01:14:07,440 --> 01:14:13,680
shortcuts by using quantum mechanics somehow and and so the first thing that we've tried to do with

793
01:14:13,760 --> 01:14:20,880
quantum mechanics in deep learning is to say can we just design an architecture that would be

794
01:14:20,880 --> 01:14:26,640
naturally a natural fit to this quantum mechanical description of the world but we still want to be

795
01:14:26,640 --> 01:14:31,840
able to run it on a classical computer so we just want to describe this we just want to

796
01:14:32,480 --> 01:14:37,600
harvest this new degrees of freedom that we have from quantum mechanics and so that was a paper that

797
01:14:37,600 --> 01:14:43,520
we recently pushed on the archive which is quantum deformed neural networks which we basically

798
01:14:43,520 --> 01:14:48,320
first say okay what if we would take a normal neural net and implement it on a quantum computer

799
01:14:48,320 --> 01:14:54,560
and then we slightly deform it into something where states get entangled and this entanglement is

800
01:14:54,560 --> 01:15:01,440
another strange phenomenon in quantum mechanics where you can create states which you cannot

801
01:15:01,440 --> 01:15:07,360
really create classically superpositions of states and and so by doing it in this particular way

802
01:15:07,360 --> 01:15:12,000
we could still run it efficiently on a classical computer but it's just a very different beast

803
01:15:12,000 --> 01:15:16,720
than a normal neural network so that's already to me very interesting and then of course the big

804
01:15:16,720 --> 01:15:23,040
prize the big bonus is that if you adhere to this way of describing what's happening is that there

805
01:15:23,040 --> 01:15:27,440
is the opportunity to be able to run things very efficiently on a quantum computer so now you can

806
01:15:27,440 --> 01:15:33,120
design your neural network in such a way that classically actually it will be very hard to

807
01:15:33,120 --> 01:15:39,040
simulate it but then on a quantum computer you could potentially simulate it very efficiently

808
01:15:39,040 --> 01:15:43,760
and and of course we don't have quantum computer so it's very hard to actually prove your point

809
01:15:43,760 --> 01:15:48,960
but that also what makes it somewhat exciting in that paper specifically you make you make lots of

810
01:15:48,960 --> 01:15:54,960
references and connections to the Bayesian way of doing machine learning could you what's the

811
01:15:54,960 --> 01:16:01,120
connection there because it seems different both are I agree both are statistics and you already

812
01:16:01,120 --> 01:16:06,720
mentioned the square roots of probabilities but how do you connect the sort of uncertainty

813
01:16:06,720 --> 01:16:15,120
quantification in the Bayesian way with how particles move quantum mechanics is not necessarily

814
01:16:15,120 --> 01:16:22,480
about particles so you can just you can write quantum mechanics on just like states you can just

815
01:16:22,480 --> 01:16:28,720
write down a number of classical states like I say a sequence of zeros and ones and there's an

816
01:16:28,720 --> 01:16:34,000
exponential number of these states and then you can say classically I can only be in one of these

817
01:16:34,000 --> 01:16:38,320
states but in quantum mechanics I can be in any linear combination of these states which

818
01:16:38,320 --> 01:16:46,080
should have is a bigger space now what we did in that paper was to say we can treat both the world

819
01:16:46,080 --> 01:16:53,200
state as well as the parameter state as a quantum we describe it by a quantum wave function and then

820
01:16:53,280 --> 01:16:58,720
we entangle these different states which is similar to saying that I take my state classical

821
01:16:58,720 --> 01:17:05,440
state x I multiply it by a matrix of parameters and I get a new state out so here the analogy would

822
01:17:05,440 --> 01:17:11,040
be I have my quantum superposition of classical states I have a quantum superposition of

823
01:17:11,680 --> 01:17:16,080
parameter states and then there are some processes where we get entangled together

824
01:17:16,720 --> 01:17:21,520
and then I do a measurement which is now a function of both the parameters as well as the

825
01:17:22,080 --> 01:17:28,160
inputs and you train it to give you measurements that with high probability give you the answer

826
01:17:28,160 --> 01:17:32,160
that you want so that would be the training process now there is actually a very precise

827
01:17:32,160 --> 01:17:38,880
way in which you can relate Bayesian posterior inference in quantum mechanics but that's a fairly

828
01:17:38,880 --> 01:17:44,000
technical story but there is a using density matrices there is a fairly precise way in which

829
01:17:44,000 --> 01:17:49,120
you can say I have a state described by a density matrix and if I do a measurement I condition on

830
01:17:49,120 --> 01:17:54,640
something and a renormalize and stuff like that so that's possible so there are two things like

831
01:17:54,640 --> 01:18:01,920
first of all the quantum neural network formulation can be very slow on a classic computer but

832
01:18:01,920 --> 01:18:08,320
fast on a quantum computer on the other hand people do run like Bayesian inference on classical

833
01:18:08,320 --> 01:18:16,400
computers what makes the quantum neural networks that much harder to compute yeah it's this

834
01:18:16,480 --> 01:18:22,320
entanglement issue yeah so in so classically I agree there is an analogy in classical

835
01:18:23,200 --> 01:18:29,600
statistics where this looks very similar which is for instance if I have a exponentially large

836
01:18:29,600 --> 01:18:35,360
state space and I write down a probability distribution over all of these possible states

837
01:18:36,080 --> 01:18:40,560
where they have a number a positive number that sums to one for each one of these exponentially

838
01:18:40,560 --> 01:18:45,440
large states and if I ask you now compute an average of a function over this probability

839
01:18:45,440 --> 01:18:49,040
distribution you can't do it because there's an exponentially large number of things that you

840
01:18:49,040 --> 01:18:54,720
would have to sum and so we have ways to deal with it which is sampling from these distributions or

841
01:18:54,720 --> 01:19:01,280
variational approximations and anyway we have to approximate this state of affairs now in quantum

842
01:19:01,280 --> 01:19:07,760
that's fairly similar so there's you you face a similar exponential problem and you can also do

843
01:19:07,760 --> 01:19:13,520
approximations to get around that and but the interesting part is that in quantum mechanics

844
01:19:13,600 --> 01:19:18,880
you can for instance do a measurement and a measurement is something that you know that is

845
01:19:19,520 --> 01:19:24,560
it gets a physical thing and it's not very hard to do but it will be an operation which looks

846
01:19:24,560 --> 01:19:29,520
like sampling something down to a particular classical state again and it does look like the

847
01:19:29,520 --> 01:19:35,520
sampling operation that we do in sort of artificially in probability theory but it's also true that

848
01:19:35,520 --> 01:19:39,360
quantum computers can in principle compute things that classical computers can't compute and they

849
01:19:39,840 --> 01:19:44,000
can actually compute it much faster whether that actually maps to the things that we are

850
01:19:44,000 --> 01:19:49,280
interested in is not so clear so that's it's not at all clear right now that we will actually build

851
01:19:49,280 --> 01:19:57,920
quantum neural networks that are generalizing a lot better on classical problems right if you

852
01:19:57,920 --> 01:20:04,240
want to do classical predictions does it actually help to build a neural network that can run

853
01:20:04,240 --> 01:20:08,880
efficiently on a quantum computer that can do these predictions much better that's not known

854
01:20:08,880 --> 01:20:13,040
but that's what makes it exciting in my opinion because you can try to do it now there's also

855
01:20:14,160 --> 01:20:18,640
functions that you can't even do classically you have to do quantum mechanically but I don't

856
01:20:18,640 --> 01:20:25,600
know how relevant they are for AI fascinating can we conceivably say that at least one let's say

857
01:20:25,600 --> 01:20:31,440
applications are way for these neural networks or for the quantum neural networks to come in

858
01:20:31,440 --> 01:20:37,040
is in in the place where right now we have these renormalization problems let's say

859
01:20:37,760 --> 01:20:43,280
big word embeddings or yeah as you mentioned things like variational inference any anywhere

860
01:20:43,280 --> 01:20:51,840
where you have a partition function that you let's say have to sample to compute now we potentially

861
01:20:51,840 --> 01:20:57,280
introduce this new way of doing this yeah so I would say that is a different set of problems so

862
01:20:57,280 --> 01:21:04,080
there is some sampling algorithms which can be sped up by quantum sampling algorithms but I think

863
01:21:04,160 --> 01:21:09,840
the maximum speed up is like a square root so it's not insignificant but it's also not exponential

864
01:21:09,840 --> 01:21:13,840
okay right you can do something in square root time of what a normal classical computer could do

865
01:21:14,400 --> 01:21:20,720
and then there is these very interesting stories where people thought that they could do things much

866
01:21:20,720 --> 01:21:25,360
faster on a quantum computer but then somebody's thought really hard about it and they then invented

867
01:21:25,360 --> 01:21:31,200
actually a quantum inspired classical random algorithm which would do about the same speed or

868
01:21:32,080 --> 01:21:39,040
close close at least so it's very uncertain precisely what we can speed up but that what

869
01:21:39,040 --> 01:21:44,000
makes it interesting right especially if you can predict what's going to happen in some sense

870
01:21:44,000 --> 01:21:49,760
it's just a matter of executing right but if you don't know if they're what they're what the low

871
01:21:49,760 --> 01:21:54,800
hanging fruit is and if there is low hanging fruit and what the possible benefits in benefits are the

872
01:21:54,800 --> 01:21:59,040
possible bonus that you can get by doing these things then it gets really interesting in my opinion

873
01:21:59,840 --> 01:22:05,040
amazing now might be a good time to talk about your other paper that's just come out Max which

874
01:22:05,040 --> 01:22:09,920
is probabilistic numeric convolutional neural networks and this was also with Mark Finsey who

875
01:22:09,920 --> 01:22:14,320
we just discovered this morning just brought out a really interesting paper about equivalents on

876
01:22:14,320 --> 01:22:19,120
light groups so that might be a potential digression later but this works really fascinating because

877
01:22:19,120 --> 01:22:24,560
it's in the setting of irregularly sample data and we use these Gaussian processes to represent

878
01:22:24,560 --> 01:22:28,880
that and we can continuously interpolate between them in this convolutional setting absolutely

879
01:22:28,880 --> 01:22:34,720
fascinating could you give us the the elevator pitch yeah first let me say again that Mark Finsey

880
01:22:34,720 --> 01:22:40,960
was an intern at Qualcomm and and Roberto Bondeson was is the other person who was also working with

881
01:22:40,960 --> 01:22:47,360
me on the quantum stuff so those of my collaborators in this project and of course Mark did the bulk

882
01:22:47,360 --> 01:22:53,440
of the work for this paper so he should deserve much of the credit for it but here's the observation

883
01:22:53,520 --> 01:23:00,880
that we had the observation is when we write down a deep learning algorithm let's say on for an image

884
01:23:01,520 --> 01:23:06,560
then we sort of treat the image as pixels and we think that's the real signal that we are looking at

885
01:23:07,200 --> 01:23:12,240
but you can also ask yourself what if I remove every second pixel now actually I have a very

886
01:23:12,240 --> 01:23:16,400
different neural network but should I have a very different neural network or what if the pixels are

887
01:23:16,400 --> 01:23:23,200
actually quite randomly distributed in the plane it's just some random places where I do measurements

888
01:23:23,200 --> 01:23:28,320
maybe more on the left upper corner and and fear on the left lower corner what the predictor

889
01:23:28,320 --> 01:23:33,520
should behave in a certain consistent way and so of course then you come to realize that really

890
01:23:33,520 --> 01:23:37,840
what you're doing is with a pixel grid is sampling an underlying continuous signal

891
01:23:38,720 --> 01:23:43,760
so then we just started thinking how do you best deal with this so how do you how can you

892
01:23:43,760 --> 01:23:49,280
build this in and so there's a very interesting tool which is called the Gaussian process it's

893
01:23:49,280 --> 01:23:55,680
basically interpolates between dots but in places where you don't have a lot of data you create

894
01:23:55,680 --> 01:24:01,040
uncertainty because you don't know what the real signal is so you basically get some kind of interval

895
01:24:01,760 --> 01:24:06,800
which says okay I think the signal is somewhere in this interval with 95 percent you know certainty

896
01:24:06,800 --> 01:24:14,000
but I don't know precisely where now the mean function is a smooth actual continuous function

897
01:24:14,960 --> 01:24:19,600
and then the next step was say okay what what does it mean to do a convolution on this space

898
01:24:19,600 --> 01:24:26,480
this is the new Gaussian process interpolated space and what we found is that the most interesting

899
01:24:26,480 --> 01:24:32,160
way to describe that is by looking at it as a partial differential equation and so this ties

900
01:24:32,160 --> 01:24:37,200
back into another really interesting line of work which was started by David Duvenaux and authors

901
01:24:37,200 --> 01:24:43,520
on thinking of a neural network as an OD as an ordinary differential equation so here we're talking

902
01:24:43,520 --> 01:24:49,840
about a PDE basically because we have spatial extent and so we are looking at sort of derivatives

903
01:24:49,840 --> 01:24:55,440
and second-order derivatives in in the plane basically which which we apply on the continuous

904
01:24:55,440 --> 01:25:00,560
function so this is literally what people do when they solve a PDE is that they have some operator

905
01:25:00,560 --> 01:25:06,400
which is consists of derivatives which they apply to the function and then they have a time component

906
01:25:06,400 --> 01:25:12,320
which evolves this thing forward in time basically and it turns out that's a very natural way to

907
01:25:12,320 --> 01:25:17,920
describe a convolution you can also add symmetries in a very natural way by looking at that operator

908
01:25:17,920 --> 01:25:22,160
that sort of moves things forward and making sure it's invariant under certain transformations

909
01:25:22,960 --> 01:25:28,720
we had a bit of trouble really handling the nonlinearity that falls that happens then so we

910
01:25:28,720 --> 01:25:33,120
had to then project it back onto something that would then again easily handle by a Gaussian

911
01:25:33,120 --> 01:25:38,560
process etc so we had to do some work there but in the end this thing was now actually very general

912
01:25:38,560 --> 01:25:46,000
and interesting tool which is apply a Gaussian process apply PDE apply nonlinearity repeat

913
01:25:46,000 --> 01:25:52,000
and then in the end collect all your information and make a prediction and it so some of the benefits

914
01:25:52,000 --> 01:25:57,040
are now that first of all of course you cannot work on a unstructured set of points doesn't

915
01:25:57,040 --> 01:26:02,000
have to be a grid and you can even learn the positions of those points so you can now direct

916
01:26:02,000 --> 01:26:08,320
the observations in places where you really need to do observations in order to improve

917
01:26:08,320 --> 01:26:12,720
your prediction so it basically becomes a numerical integration procedure where you can

918
01:26:12,720 --> 01:26:18,640
learn where to move your integration points and what I also found very is fascinating is that

919
01:26:18,640 --> 01:26:25,680
this same paradigm can be mapped on again onto a quantum paradigm where you can think of that

920
01:26:26,240 --> 01:26:32,880
PDE that evolves now as a Schrodinger equation that sort of evolves like a wave function so it

921
01:26:32,880 --> 01:26:37,680
maps very nicely also again to a quantum problem and that's what we are working on now

922
01:26:38,400 --> 01:26:42,160
something that's really fascinating that keeps coming up again and again and these sorts of

923
01:26:42,160 --> 01:26:47,360
research programs is the matrix exponential like it's our connection to groups and algebras or

924
01:26:47,360 --> 01:26:52,880
like group representations and algebras and of course we use it to evolve our ODEs and PDEs

925
01:26:53,760 --> 01:26:58,320
I guess as a physicist you've probably got a deeper appreciation of this particular object

926
01:26:58,320 --> 01:27:03,600
but it's something that's still quite alien to a lot of people I know that work in applied

927
01:27:03,600 --> 01:27:08,720
machine learning what's the significance of the matrix exponential why does it connect all these

928
01:27:08,720 --> 01:27:14,800
really fundamental objects to things like Lie groups and stuff like that yeah so it's interesting

929
01:27:14,800 --> 01:27:19,920
that we actually just got a paper accepted in noreps on this and it's called the convolution

930
01:27:19,920 --> 01:27:26,000
exponential and you can look it up and Emil Hogebaum is the sort of the main author and

931
01:27:26,000 --> 01:27:33,920
generator of that idea and yeah so I guess it because it is the solution to the ODE or the PDE

932
01:27:33,920 --> 01:27:40,000
right so if you write down something that's very fundamental that is the first order differential

933
01:27:40,000 --> 01:27:46,880
equation which is d dt the derivative with respect to t of a state is some operator times that state

934
01:27:47,680 --> 01:27:54,320
then the solution of that thing will be the state over time is the matrix exponential times t

935
01:27:54,880 --> 01:28:00,160
times the state so that's I think where it comes from and so one other way to look at it is that

936
01:28:00,880 --> 01:28:05,360
in physics it's called the Green's function so it's basically the solution to this ODE so you

937
01:28:05,360 --> 01:28:13,760
can think of a neural net as basically we tend to describe it as a discrete you know map from one

938
01:28:13,760 --> 01:28:18,320
point to another point but if you think of it as a continuous process which is what we learned from

939
01:28:18,320 --> 01:28:25,120
the ODE description of a neural net if you think of it as a continuous process then it's really

940
01:28:25,840 --> 01:28:31,600
you can just think of that convolution this map you can just think of it as the matrix exponential

941
01:28:31,600 --> 01:28:37,040
solution to this to this ODE in math literature you call this the Green's function so you can

942
01:28:37,040 --> 01:28:42,240
think of a convolution basically as the Green's function of a partial differential equation I

943
01:28:42,240 --> 01:28:46,560
think that's where the word where this feels like a very fundamental object in some sense

944
01:28:47,360 --> 01:28:53,600
so in in a talk you gave recently on the future of graph neural networks you were talking about a

945
01:28:53,600 --> 01:28:59,200
number of ideas from physics that hadn't really made it into machine learning among them things

946
01:28:59,200 --> 01:29:05,040
like renormalization chaos and holography would you care to unpack these ideas a little bit and

947
01:29:05,040 --> 01:29:10,640
tell us where you see the future is in these ideas yeah so the reason I mentioned these because I

948
01:29:10,640 --> 01:29:15,840
think there's a lot of really cool ideas in physics which are still remain unexplored but there

949
01:29:15,840 --> 01:29:19,760
is more and more physicists who are moving into the field and some of these ideas are actually

950
01:29:19,760 --> 01:29:25,040
you know being worked out as we speak so I recently saw about two papers on renormalization

951
01:29:25,040 --> 01:29:31,040
so renormalization is something in in physics which basically you start with a system with a

952
01:29:31,040 --> 01:29:36,320
whole lot of degrees of freedom like say particles moving around or something like this and then

953
01:29:36,640 --> 01:29:44,000
coarse grain the system slowly and what means is that by coarse graining you zoom out and you

954
01:29:44,000 --> 01:29:48,800
build an effective theory of the underlying theory in the same sense as thermodynamics is an effective

955
01:29:48,800 --> 01:29:54,000
theory of statistical mechanics where basically all the particles are now removed but you now

956
01:29:54,000 --> 01:29:58,400
have an effective sort of description of your world this is the same as what happens in neural

957
01:29:58,400 --> 01:30:02,240
nets right the neural nets we talk about pixels at the bottom layer and maybe edge detectors and

958
01:30:02,240 --> 01:30:07,440
things at the very top of it we're talking about objects and relations between objects which are

959
01:30:07,440 --> 01:30:14,480
aggregated emergent properties from this neural net and ideas from renormalization theory might

960
01:30:14,480 --> 01:30:20,400
very nicely apply to this particular problem and indeed have already been applied with some success

961
01:30:20,400 --> 01:30:25,920
the other one which you mentioned was chaos and I think there is a very nice connection actually

962
01:30:25,920 --> 01:30:32,640
with chaos theory going back to work I did a long time ago which are called herding in particular

963
01:30:32,640 --> 01:30:38,800
you can think of sampling from a particular distribution you can do it either by the typical

964
01:30:38,800 --> 01:30:43,200
way is first of all you can think of it as a dynamical system as a stochastic dynamical system

965
01:30:43,200 --> 01:30:48,080
and you think of it as there's a you're at a particular point and then you propose to go

966
01:30:48,080 --> 01:30:52,000
somewhere and then you accept or reject a particular point and then you just jump through

967
01:30:52,000 --> 01:30:58,240
the space and you collect your the points that you jumped to then you look at that collection and

968
01:30:58,240 --> 01:31:02,640
that collection should then actually distribute according to the probability distribution that

969
01:31:02,640 --> 01:31:08,080
you're sampling from now that's a stochastic process but if you think very hard about that

970
01:31:08,800 --> 01:31:13,600
in fact it's a deterministic process even if you try to make it stochastic and the reason is that

971
01:31:13,600 --> 01:31:18,080
every you know you're doing a whole bunch of calculations and so now and then you call a

972
01:31:18,080 --> 01:31:23,200
random number generator but the random number generator really is a pseudo random number generator

973
01:31:23,200 --> 01:31:27,680
it is also a deterministic calculation that you're doing so the whole thing end to end is just a

974
01:31:28,400 --> 01:31:32,880
a deterministic calculation but because you're calling the pseudo random number generator it

975
01:31:32,880 --> 01:31:38,800
looks very stochastic but truly it is a chaotic process and so you should really be able to describe

976
01:31:38,800 --> 01:31:44,080
the system by chaos theory and the theory of nonlinear dynamical systems now what I've been

977
01:31:44,080 --> 01:31:52,240
working on with my postdoc and Roberto we've been working on is thinking about let's make it a little

978
01:31:52,240 --> 01:31:58,480
bit less chaotic so let's make this actually a deterministic system which is maybe at the edge

979
01:31:58,480 --> 01:32:03,840
of chaos and again this is one of these very deep questions that's in my head so I think so there's

980
01:32:04,480 --> 01:32:08,480
there is something very interesting and deep here which is if you do if you try to

981
01:32:09,120 --> 01:32:15,920
do a computation on the one hand you want to store information things that you've calculated

982
01:32:15,920 --> 01:32:21,840
and for that things need to be stable on the other hand you want to transform information

983
01:32:21,840 --> 01:32:26,240
because that's what a calculation is right and so there you want to be in this sort of

984
01:32:26,240 --> 01:32:31,360
more chaotic domain and it turns out that the best place to be is at the edge of two things

985
01:32:31,360 --> 01:32:35,120
where you can go to the right a little bit and be more stable and go to the left a little bit

986
01:32:35,120 --> 01:32:41,520
and you can transform things and compute things and so I also think that when you're trying to

987
01:32:41,520 --> 01:32:47,040
sample or in you know sampling can be equated with learning if you're Bayesian about things because

988
01:32:47,040 --> 01:32:51,360
in learning is basically sampling from the posterior distribution and that's same as learning

989
01:32:52,400 --> 01:32:59,120
you can if you can design samplers that are not completely chaotic as the ones that we describe

990
01:32:59,120 --> 01:33:04,000
now but they're more structured and less chaotic and more deterministic moving through the space

991
01:33:04,000 --> 01:33:08,880
you can learn a lot faster and I find that and then you can actually start to map it

992
01:33:08,880 --> 01:33:14,400
onto sort of complexity theory notions if you think of this sampling from a discrete set of

993
01:33:14,400 --> 01:33:20,080
states what kind of properties do the sequences that I generate have what is the entropy of the

994
01:33:20,080 --> 01:33:25,280
sequences that I'm generating for instance or what kind of substructures is it for instance going to

995
01:33:25,280 --> 01:33:29,760
be periodic or are there periodic substructures inside of it or all these things and these are

996
01:33:29,760 --> 01:33:34,800
studied by the theory of chaos and nonlinear dynamical systems so connecting these two fields

997
01:33:35,680 --> 01:33:41,280
feels to me like a very fundamental thing to try and do and some people have tried a few things

998
01:33:41,280 --> 01:33:45,760
people have looked at well if you look at a neural net there's an iterated map you map things to

999
01:33:45,760 --> 01:33:51,840
hidden layers in later if you think of that iterated map and think of it as is that map chaotic

1000
01:33:51,840 --> 01:33:58,080
being on the edge of chaos is the best thing you shouldn't be completely or nonmovable because

1001
01:33:58,160 --> 01:34:02,720
then everything you put in is going to be mapped to the same point very uninteresting you also

1002
01:34:02,720 --> 01:34:07,760
shouldn't be super chaotic because or whatever you put in you're going to some random point in space

1003
01:34:07,760 --> 01:34:12,800
and that's not very predictive so you need to be at this intersection space between chaos and non-

1004
01:34:12,800 --> 01:34:17,840
chaos and then you can do interesting computations so this is the same idea right so to me that's

1005
01:34:17,840 --> 01:34:23,840
exciting because now suddenly a whole field of exciting mathematics is cracked open and you can

1006
01:34:23,840 --> 01:34:29,440
start to use all these tools in machine learning awesome thank you fantastic now might be a good

1007
01:34:29,440 --> 01:34:36,720
time to go over to reddit we asked reddit for questions and the top rated question is by tsa

1008
01:34:37,360 --> 01:34:40,480
hi max when will you be changing your last name to pooling

1009
01:34:44,240 --> 01:34:50,160
so actually there is a paper that a colleague of mine wrote and i think they had an operator

1010
01:34:50,960 --> 01:34:57,200
instead of pooling you could you could do a a welling operator so and instead of changing

1011
01:34:57,200 --> 01:35:01,920
my name i i propose that we just change the operators that we use and change to welling

1012
01:35:01,920 --> 01:35:07,760
operators that's wonderful in the thread on reddit there were a few variations as well so maybe max

1013
01:35:07,760 --> 01:35:14,560
power and someone asserted that pooling is your brother but anyway red portal says the conventional

1014
01:35:14,560 --> 01:35:19,600
approach for analyzing continuous convolution would be Fourier analysis what was the rationale

1015
01:35:19,600 --> 01:35:24,880
behind the investigating continuous convolutions using probabilistic numerics that's a good question

1016
01:35:24,880 --> 01:35:31,040
so to me Fourier analysis it's true that you can i guess i could still do a Fourier analysis

1017
01:35:31,040 --> 01:35:36,880
right because a Gaussian process you can decompose in terms of its Fourier waves and then it's the

1018
01:35:36,880 --> 01:35:43,280
primal versus the dual view of a sort of any sort of kernel method so i could certainly go to the

1019
01:35:43,840 --> 01:35:48,320
Fourier domain and do my calculations in the Fourier domain the quantum mechanics this is

1020
01:35:48,320 --> 01:35:52,480
just another basis you just think of this as another basis you know not only quantum

1021
01:35:52,480 --> 01:35:57,600
mechanics in any signal processing sense and it's true that a convolution is easier there

1022
01:35:57,600 --> 01:36:05,680
because just multiplication on the other hand convolutions are very efficient in modern software

1023
01:36:05,680 --> 01:36:12,800
packages for gpu so sometimes it's also not necessarily faster to do that but it's a good

1024
01:36:12,800 --> 01:36:18,240
suggestion and maybe something nice happens when you go to Fourier space and i just didn't explore

1025
01:36:18,240 --> 01:36:26,720
that fantastic we've also got jimmy the ant lion says hi max i notice your co-authors come from a

1026
01:36:26,720 --> 01:36:32,800
physics background can you explain why there are so many x physicists in deep learning yeah so that's

1027
01:36:32,800 --> 01:36:38,480
interesting i think there's just a lot of physicists and a fraction of those physicists is looking for

1028
01:36:38,480 --> 01:36:44,160
other for greener pastures and i'm myself on one of those that i was looking for greener pastures

1029
01:36:44,880 --> 01:36:50,480
and they bring a really good toolbox so if you're done physics you're you have just a very good

1030
01:36:51,040 --> 01:36:56,400
mathematical toolbox but also very good intuition about PDEs and other world works and

1031
01:36:56,400 --> 01:37:01,760
symmetries and all these kinds of things you bring and i think in some sense physics is also a bit

1032
01:37:01,760 --> 01:37:06,240
of a container right if you do physics you can still do anything else afterwards in some sense

1033
01:37:06,800 --> 01:37:12,080
and i think just there's just people who are naturally interested in in ai of course ai became

1034
01:37:12,080 --> 01:37:17,280
very popular at some point and so you have automatically people flock into that into that

1035
01:37:17,280 --> 01:37:23,120
field but yeah in general they're smart people so i guess it's nice to work with them maybe just

1036
01:37:23,120 --> 01:37:28,240
circle back and close the loop to the beginning and we were talking about the research community

1037
01:37:28,240 --> 01:37:35,360
and kind of the machine learning research field i i loved what you suggested and as i understand

1038
01:37:35,360 --> 01:37:41,760
this is not fully your suggestion but the suggestion of let's say having a more open review kind of

1039
01:37:41,760 --> 01:37:47,680
system where a review could be as powerful as a paper itself i've been screaming for this for

1040
01:37:47,680 --> 01:37:54,960
a few years now and could i ask if you if you ever have the chance to propagate this what do you

1041
01:37:54,960 --> 01:38:00,800
think of the idea of having a continuous research like this paper notion that we have now i think

1042
01:38:00,800 --> 01:38:06,880
it's so outdated and once my paper is published i have no incentive to update that thing what what

1043
01:38:06,880 --> 01:38:12,640
if we do research in in this much more continuous way and then there's comments and then in response

1044
01:38:12,640 --> 01:38:19,040
to the comments everything changes and so on yeah no it's very good point it's it's so this is indeed

1045
01:38:19,040 --> 01:38:25,360
exactly part of this idea that we are trying open review to implement yeah but it's the idea is that

1046
01:38:25,360 --> 01:38:30,000
in open review you have a conversation with your reviewers and it's nice if the reviewers are not

1047
01:38:30,000 --> 01:38:34,560
anonymous and just you just have your conversation and other people can even contribute to the project

1048
01:38:34,560 --> 01:38:39,680
in a more open science way but it is also nice for now and then to present your work and so

1049
01:38:39,680 --> 01:38:46,240
that's why i say so now and then a conference might come in and harvest papers and just invite

1050
01:38:46,240 --> 01:38:50,960
people to present their work in sort of slightly more formal way and maybe put a stamp of approval

1051
01:38:50,960 --> 01:38:56,320
on it and say this conference has published or this particular paper with some independent reviews

1052
01:38:56,320 --> 01:39:01,360
and we think it's a great paper and so you get that stamp so it and i guess there should also be a

1053
01:39:01,360 --> 01:39:07,600
way to close off a particular project to move on to a new project but i also have the same view as you

1054
01:39:07,600 --> 01:39:14,720
have as this being a far more continuous process where you know if you didn't get picked this time

1055
01:39:14,720 --> 01:39:19,680
next time somebody some conference will come by and pick you out this it's much more like a marketplace

1056
01:39:19,680 --> 01:39:25,280
where ideas go around conferences come in and ask you to publish things and it's just you then

1057
01:39:25,280 --> 01:39:29,920
present it and then you can just continue with your research or stop and then go to a new piece of

1058
01:39:29,920 --> 01:39:35,280
work or something like this so yeah i i share that vision basically that's it's amazing i'm

1059
01:39:35,280 --> 01:39:41,520
continuously amazed when i read these old papers from let's say schmid uber and like the first rl

1060
01:39:41,520 --> 01:39:46,640
papers that just came up with a bit of an idea and then they had a bit of toy data and right and

1061
01:39:46,640 --> 01:39:53,520
that's a paper and and it's cool do you have any do you have any kind of thoughts about or recommendations

1062
01:39:53,520 --> 01:39:58,880
for the new generation of researchers that are now flooding the fields of how can we get to a

1063
01:39:58,880 --> 01:40:05,360
better field what kind of tips would you give the yeah we i think we really need to disrupt the field

1064
01:40:05,360 --> 01:40:10,720
a little bit and so i think we i think the new i think it's particularly tough for new researchers

1065
01:40:11,360 --> 01:40:17,200
because it's the acceptance rates for these conferences are very low and it feels like much

1066
01:40:17,200 --> 01:40:22,640
of your future career depends on getting papers in there and it's a fairly random process as well

1067
01:40:23,520 --> 01:40:26,960
so i think we just need to disrupt the field and there's enough people

1068
01:40:28,400 --> 01:40:33,840
with influence who want that so it's just a matter of actually executing on it and so that's

1069
01:40:33,840 --> 01:40:39,920
what we do it now for the bayesian deep learning workshop that we are organizing this we want this

1070
01:40:39,920 --> 01:40:48,160
to be a an off-split from new rips it was a very popular workshop there and somehow we got rejected

1071
01:40:48,160 --> 01:40:53,520
this year and we thought okay we'll just do it ourselves we do have actually a meet-up but then

1072
01:40:53,520 --> 01:40:58,480
next year we want to be our standalone conference but for that conference we want to implement this

1073
01:40:58,480 --> 01:41:03,600
plan and so we are working with open review to actually implement this for us and jaren gall is

1074
01:41:03,600 --> 01:41:09,520
working hard to try to actually roll this out we're talking to yashua benjo about it and he's

1075
01:41:09,520 --> 01:41:13,760
very supportive and there's a whole lot of people who are supportive about it but so if this can help

1076
01:41:14,720 --> 01:41:19,280
to make this a popular model then that will be a fantastic result of this interview

1077
01:41:19,280 --> 01:41:23,120
but i think people should just push for it and just say okay i'm just fed up with the

1078
01:41:23,120 --> 01:41:28,160
current way of doing things we should really change things and just a shout out and say

1079
01:41:28,160 --> 01:41:35,280
this is what we want and let's go for it awesome amazing professor max welling it's been an absolute

1080
01:41:35,280 --> 01:41:40,240
honor and a pleasure to have you on the show thank you so much for joining us today it was great

1081
01:41:40,240 --> 01:41:44,400
with the three of you asking questions that works really well fantastic thank you so much

1082
01:41:44,400 --> 01:41:50,160
thank you amazing it was good the questions were really fantastic actually and i've never

1083
01:41:50,160 --> 01:41:54,400
done this with the three of you but having a team of three people asking questions is really

1084
01:41:54,400 --> 01:41:58,640
it's a good idea and of course you're really smart people knowing what you're talking about so that

1085
01:41:58,640 --> 01:42:06,560
went really well i think needs three brains to match yours anyway i really hope you've enjoyed

1086
01:42:06,560 --> 01:42:12,080
the show today this has been such a special episode for us because max welling is is literally one

1087
01:42:12,080 --> 01:42:18,560
one of my heroes so anyway remember to like comment and subscribe we love reading your

1088
01:42:18,560 --> 01:42:23,600
comments we really do actually we're getting so many amazing comments in the comment section so

1089
01:42:23,600 --> 01:42:31,440
keep them coming and we will see you back next week

