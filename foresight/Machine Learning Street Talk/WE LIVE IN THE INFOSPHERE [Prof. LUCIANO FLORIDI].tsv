start	end	text
0	5680	Professor Luciano Floridi is the Oxford Internet Institute's Professor of Philosophy
5680	11440	and Ethics of Information at the University of Oxford, where he's also the Director of the
11440	17280	Digital Ethics Lab of the Oxford Internet Institute. Still in Oxford, he's a distinguished
17280	22400	research fellow of the Yuhiro Centre for Practical Ethics of the Faculty of Philosophy
22400	27680	and Research Associate and Fellow in Information Policy in the Department of Computer Science.
28480	34160	Outside Oxford, he's the Faculty Fellow of the Alan Turing Institute and Chair of its Data Ethics
34160	39760	Group and the Distinguished Scholar in Residence of the Department of Economics at the American
39760	46800	University in Washington DC. His research concerns primarily digital ethics, the philosophy of
46800	53200	information, which is a discipline he founded, and the philosophy of technology itself.
53200	61120	I will introduce AI as a divorce between the ability to perform a task successfully
61120	68560	in view of a goal, shall we say, play chess just to be trivial, and any need to be intelligent
68560	77200	in doing so. Replace that with parking a car, landing an aircraft, delivering something to your house.
77920	83600	You don't have to be intelligent to do that if you are a piece of AI. That's why it works.
84560	91920	If you had to wait to be intelligent, it would. My iPhone there, turn off properly, would not play
91920	97840	better chess than anyone else in this room if we had to wait for their iPhone to be as intelligent
97840	104160	as a rat. It is because it isn't, and we gave up on trying to make it intelligent as a rat.
105040	109840	We're in the midst of an information revolution, as well as a computing revolution.
110400	116560	Floridi said in his introductory book that all members of the G7 qualify as information
116560	123840	societies, because in each country, at least 70% of their GDP depends on intangible goods,
123840	130320	which are information related, not on material goods. Their functioning and growth requires
130320	138800	and generates immense amounts of data, more data than humanity has ever seen in its entire history.
138800	146880	It was estimated in 2003 that humanity had accumulated approximately 12 exabytes of data,
146880	152480	and we're fast approaching the age of the zettabyte, which is 1000 exabytes.
153280	158400	Sometimes people think in terms of, oh, can we regulate AI, which is a bit like, can we regulate
158400	164880	electricity? Well, it's a bit vague. What do you mean? It's not true, false, correct, incorrect.
164880	167840	It just doesn't yet make any friction with the real world.
169360	176000	Floridi thinks that the material world is becoming redundant. Our agency as humans is being
176000	181680	perniciously eroded, and that the increasing dominance of the information landscape, or the
182240	188000	infosphere as Floridi calls it, is becoming the primary basis for our reality.
189040	195840	Now about 95% of all of the data that we have today has been created by the current generation.
195840	202240	We're not talking about Shakespeare or Dante. We're talking about lots and lots of dogs and
202240	209200	cats. Floridi thinks that the infosphere is becoming so polluted with every passing day
209200	214320	that the manifold of the infosphere is increasingly determined by technology
214320	220000	and artificial intelligence. People are consumers. Consumers become followers.
220000	225120	Followers become barcodes. Increasingly, the data is stored in a representation,
225120	231200	which is primarily machine-readable, designed for consumption by other machines. Our very
231200	237200	existence is being squeezed as a result. It wouldn't be great to have something instead
237200	244400	of us doing it for us, better than us. Yeah, absolutely. I mean, if you read the description
244400	252080	of that something that does it instead of us, better than us, in Aristotle, it's a slave.
253360	260240	That's what we could do in the past. It was horrible. Luckily, it's not happening around us.
261200	266480	But we were using humans as means to an end. Now we can use technology.
267600	273200	Why this divorce? Why sort of pulling apart and saying, look, I want to develop something that
273200	278400	is successful. I don't care whether it does it in the same way as I do it. As long as it's successful,
278400	283520	that's fine. As opposed to, no, no, I want to implement human cognition. And if it's not human
283520	288160	cognition, I don't care whether it's successful or not, but it has to have a little spark. Now,
288160	293280	remember, AI, is it an engineering branch? Or is it a branch of colony science? Well,
293280	301200	as a branch of colony science, we are at year zero. No step forward. We do not have the intelligence,
301200	308960	as I said, of a rat. When it comes to engineering, that looks like magic. That looks like what has
308960	316240	happened to humanity. Who has given us so much brain to do what we're doing today? And the old
316240	323360	phrase like, is it worth asking whether a submarine can swim? Really? Can a computer think,
323360	328240	ah, that's the wrong question. That's not the framework within which we should understand
328240	332240	what a computer does. A submarine does what it does. An airplane does what it does. And it
332240	336800	doesn't do it like a bird, doesn't do it like a fish. But it does it successfully. And that's
336800	342880	the whole engineering point here. Success in delivering the output, given that particular input.
342880	346960	But how do you know it's not the same process? Well, imagine you have two, two,
346960	353040	four, and I tell you one is plus, the other one is multiplication. Which one did I use to get four
353040	358480	from two and two? I don't know. Two plus two is equal to four. Two by two is four. You see, you
358480	365200	can't say. So it's the same thing. No, it isn't. The way I do the dishes, the way my dishwasher
365200	371600	does the dishes, two different things. Florides said something very significant and profound
371600	377520	has recently happened to human self understanding. He said that in many respects,
377520	384000	we're not standalone entities, but rather interconnected informational organisms or
384000	391040	info orgs, sharing with biological agents and engineered artifacts, a global environment
391040	398080	ultimately made of information, what Florides calls the info sphere. This is the informational
398080	404880	environment constituted by all the informational processes, services and entities, thus,
404880	410640	including the informational agents, as well as their properties and interactions and mutual
410640	416480	relations. Now, if there was a representative scientist for the fourth revolution, this would
416480	423040	definitely be allenturing. It's now critical that we equip ourselves with a viable philosophy of
423040	423760	information.
427680	431920	Gazillions of data, yeah, of any kind, of any sort, and they're all digital, readable, machine
431920	436560	readable. When I mean machine readable, they're barcodes, not meant for our eyes, they're meant
436560	441440	for the machines. If you hear anything about the natives, the natives in this space are the robots,
441440	449200	not us. We scuba dive. But these machines, they are digital elements in the digital environment,
449200	455680	reading digital stuff and digital processing, etc. And of course, I show you better machine
455680	461040	learning, better algorithms, but also more and more internal things, things connected to other
461040	467280	things. And when you go home and you see all those green and blue lights, they're not for us,
467280	471840	they're talking to each other. And a lot of the data we have are generated by those machines.
472000	482160	Information and communication technologies have been changing the world profoundly and irreversibly
482160	489280	for more than half a century now, with breathtaking scope and at neck breaking pace. On the one hand,
489280	494960	they've brought concrete and imminent opportunities of enormous benefit to people's education,
494960	500240	welfare and prosperity, as well as great economic and scientific advantages.
502720	509440	This merging of our existence, both analog and digital, both online and offline,
510480	517120	we really ever offline? Of course not. So I'm reminded normally that if you have ever heard
517120	521440	the whale singing, if you don't even know what I'm talking about, then you're very, very young.
522000	525680	But if you know what I'm talking about, then you have used something called a modem.
528400	531760	That is called whale singing. And if you have heard the whale singing,
532320	537360	well, you're more like on my side of the divide. So we don't hear the whale singing anymore.
540320	546480	Floridi thinks that the risks are the nature of reality and our knowledge of it. The organization
546480	553040	of a fair society, considering the digital divide, our responsibilities and obligations to present
553040	559280	and future generations, our understanding of a global world, and the scope of our potential
559280	565760	interactions with the environment. And finally, conceptual implications and complexity of an
565760	571840	information and communication technology landscape. So we don't hear the whale singing anymore. There
571840	580640	is no terminator coming. There is no gods in the sky deciding for us. There's nobody but humanity
580640	585040	responsibility for what we're going to do with this technology. And anyone disagrees,
585840	589040	I hope is just naive and doesn't have an agenda.
593760	598240	Floridi said that the information society has grown quickly and chaotically,
598240	603040	leading to a lack of balance between technological growth and a lack of understanding
603040	608240	of the implications of this growth. It also highlights the need to dig deeper into the
608240	614480	nature and implications of the information age in order to better anticipate and identify
614480	623760	and resolve problems. We started understanding ourselves in roughly in two ways, who I am
624320	632800	and what I can do. I am, no humanity speaking, different, exceptional, special because of my
632800	641840	nature and because and or what I can do compared to anything else. So one is called personal identity.
642400	649680	It's going to come close to privacy and the gazillions of data out there are eroding or
650240	657680	transforming, exercising pressure on that particular who I am, my nature, my data subject,
657680	663440	as we are defined by the European legislation, we all data subjects here. GDPR, General Data Protection
663440	668640	Regulation says so. So if you have data subject and there's a gazillion of data about you
668640	674000	somewhere being manipulated, well certainly your identity is not sure we say in question.
674800	680240	The other half is remember not who I am but what I can do, as opposed to anyone else,
680240	685680	what I say I, and we define ourselves at least since Kant onwards in manner of the German
685680	692720	philosophy in terms of autonomy. We are special because we are in control of our actions, we
692720	699120	can decide, we can plan, we can choose. Well now we have autonomous agents out there and if you
699120	705600	are trying to identify yourself as we can only be not the ones who play chess, well then we are
705600	710800	really in trouble. You can devalue human skills, you can remove human responsibility, you can reduce
710800	716640	human control. Erode human self-determination is the other side of the coin. It's not super dangerous
717520	727120	but the rock who thought that their little drop of water was nothing, 18 years later has a big hole
727120	732880	in it because drop after drop after drop, the drop will shape the stone will shape the rock.
739840	746080	Surely we want to have a technology that makes us more capable of deciding what we want
747120	755520	or prefer what we really have in front of us and I'm a bit worried that here human nature,
755520	760960	no we philosophers we know something about human nature, we'll kick in, we're lazy,
762800	770720	we're also very malleable and we are easily convinced to do this or that so we need to be a
770720	777600	little bit more careful exposing this very fragile malleable entity to a very robust,
778400	787360	quite silly, very efficient, very successful technology that will probably tend to inadvertently
788080	793360	change the nature of that fragile entity. This is something that I would like to be a little
793360	800880	bit more concerned about, not terminator. So until recently you would go to know this wonderful techie
800960	809520	conferences and it was all about technology innovation. The average politician salivates
809520	814320	immediately as soon as you talk about innovation because innovation is growth, growth is money,
814320	819600	money is jobs and people happy. So innovation, innovation, yeah, absolutely and it's crucial
819600	823840	but it's not real challenge. I don't think that that's the most difficult challenge we are facing
823840	829200	now, not because it's easy but because something more difficult to do behind innovation. The challenge
829200	836160	therefore is how you govern all this but governance is a matter of design, designing the right policies
836160	841520	so that incentives and disincentives are in the right place, there are no loopholes, people tend
841520	846720	to do more the right thing than the bad thing. So all of a sudden we are shifting all this into
846720	851920	socio-political issues. It's a matter of design, design the kind of society we want, remember
851920	858720	what's the human project here that we want to implement. So anyway, I had a very fun trip up
858720	864960	to Oxford the other day and had a chat with Luciano himself. I hope you find this episode
864960	872160	valuable. Remember to subscribe and if you're listening give us a rating on Apple podcasts
872160	883120	or whatever you listen to the podcast on. Enjoy. So to start proceedings off with misinformation,
883760	890160	the internet has put the world in our pocket, knowledge at our fingertips but the business
890160	896320	of the internet is about ads and exploitation, debasement and derangement of human attention
896320	900880	and some have argued that social media is a bit like the climate change of our society.
901520	905600	Are you concerned that the current state of internet economics will create
905600	910400	a layer of plausible yet false abstraction between us and reality?
910480	919840	There is a risk of more and more content being worthless, unreliable, false, misleading,
920640	928560	fake news, propaganda. It is not a new problem but the size, the immensity, the impact is new.
929360	934880	It's one thing if you publish a few pamphlets with several lies and another thing if you have
935760	942240	hundreds or millions of followers believing at once that something was not the case and
942240	948160	something that was the case wasn't. And I'm talking about elections and very public figures.
950160	957760	I wouldn't however put the whole emphasis on the negative side. The social media are also,
957760	963120	if we want, the solution to the problem. Today are part of the problem, I agree,
963200	968080	but they could easily become part of the solution. Precisely because then if you remember,
968080	976160	and I close here, good old days when we were online and there was no web, only the internet,
977520	981760	we thought that we were going to create a more informed, more civilized, more reasonable
983120	990800	environment. We can still do that. It's the kind of business models and lack of political, legal
991760	999840	framework that has generated this tsunami of, shall we say, rubbish, which is polluting our
999840	1007120	infosphere, the space of our information. So, yes, it is a problem, no, it doesn't have to be a
1007120	1012640	problem. It could be easily a big solution. One suggestion for all and as close here, imagine
1012640	1019600	if we were to ban, and it's a bit of a joke, advertisement online. We'd have to pay, we would
1019600	1025040	pay for the product. That means that there will be competition for quality. We'll be probably in
1025040	1031040	a different kind of game. Interesting. And we'll get into a minute, we'll get into the subject of how
1031920	1040880	the structures of, let's say, markets and economic models affect us as human beings and as a society,
1040880	1049040	but also affects our perception of reality, essentially. But before we get there, you wrote
1049200	1056480	a paper called GPT-3, It's Nature, Scopes, Limits and Consequences. And you said that
1057200	1060640	reversible and irreversible questions are based on mathematical logic,
1061760	1067120	libanate law and other fields such as computing and physics. Can you explain what you meant by that?
1068960	1072560	It's a simple idea. So, if I fail, it's my fault.
1073440	1083120	A question that I define there as reversible means that from the answer, you can reverse to
1083840	1091520	the actual identity of the source of the answer. An irreversible one is one that doesn't allow
1091520	1098480	you to do that. Let me give you an irreversible answer today. Come to my house, you find clean
1098480	1104800	dishes on the table. Who has cleaned the dishes? It's irreversible. You can't tell. It could be me
1104800	1109440	or it could be the dishwasher. So, you cannot tell, by looking at the dishes, the output,
1110000	1113840	whether those dishes have gone through a process of hand washing or machine washing,
1113840	1119680	and whether the source is one or the other. A reversible one would be the sort of question
1120160	1129760	today, and I'm talking today. We can ask to chat GPT. Use anything like Mary's mother has
1129760	1136640	three children, tell me the name of one of them, and GPT says, I don't know. It does, I have no
1136640	1144640	enough information. It's Mary's mother, so surely. So, that becomes immediately reversible. You know
1144640	1153680	exactly that the answer is coming from a computer, from a large language model, and not from a human
1153680	1160800	being who gets that immediately. Imagine the other way around. You ask for a super complex
1160800	1166640	calculation, and boom, you get the answer in a fraction of a second. The other one may come
1166640	1173520	snake and maybe takes longer, so who was the other side? So, increasingly in the paper, I write that,
1174800	1179280	and it was before chat GPT coming out, but it's obvious, and it's been, you know, our progress
1179280	1186000	since then. Increasingly, the sort of output that we are dealing with will become irreversible. We
1186000	1191440	will be unable to tell whether the source is, for example, a human being, a group of human being,
1191440	1199600	a human being with a computer, or chat GPT, or whatever is going to come, GPT4, etc. Imagine
1199600	1206640	GPT10, not many years from now. I think that it will be completely irreversible. It does not mean,
1206640	1212000	however, let me close here, that I'm like the dishwasher. If you can't tell who did the dishes,
1212960	1217200	what difference does it make? I've done them in one way, which is completely different.
1217920	1224640	The machine does it in a sort of mechanical, etc. So, we should be clear about what we infer from
1225440	1231200	the reversibility, any reversibility of the output, and that seems to me where a lot of confusion is
1231200	1238080	generated. Interesting. So, there's the provenance of the information. So, where it originated from,
1238080	1243040	we could go down the line of saying, because it is human aligned with this reinforcement
1243040	1247120	learning for human feedback, it's remarkably human aligned, actually, much more than the original
1247120	1255520	GPT3. Then, you spoke to this semantic divergence, and we can talk about the pragmatic divergence
1255520	1260720	as well. Actually, that's getting into a little bit about what John Sow talked about,
1260720	1266800	the difference between ontology and epistemology. Is that something that you're
1266800	1272560	seriously concerned about? Could you expand on that? I am concerned about it. I'm one of the
1272560	1280480	few people, or I hope many more than Sims, who agree with the Chinese room and the
1280480	1285120	philosophy behind it. Of course, you can always, among philosophers, you can always argue for
1285120	1290240	details and sophisticated counter-argument, etc. But the bottom line, I mean, John got it
1290240	1295280	right a long time ago, we're dealing with syntactic engines. There is no understanding,
1295280	1300720	there is no insight, there is no emotional involvement, etc. Anything that would go
1300720	1305440	into qualifying, characterizing human intelligence, which is also a rather fuzzy
1305440	1311600	concept, by the way. On that front, I think we're going to see more and more of successful machines
1312480	1318160	of the kind that we were just discussing. You mentioned the source, because that is
1318160	1322640	the real difference. Let me give you a small example.
1323360	1334480	Suppose you take from the shelf an amazing novel, a novel that John won the Nobel, for example.
1336240	1341680	I would be surprised if you were to confuse that for something that's been generated by GPTX.
1343360	1348800	The other thing is not true. Suppose you take a normal text, like an encyclopedia entry,
1348800	1355120	or a good summary of that novel. Would you be able to tell me whether is a human being or GPTX?
1355120	1361120	You wouldn't. So there's also a symmetry between the sort of product that we get and the sort of
1362240	1368560	inferences that we can run. Final point, you know, technique is not everything,
1369200	1378000	and we always fall into the same trap. You see someone reproducing on the pavement in a street,
1378000	1382960	the Sistine Chapel. It's amazing. I mean, I wish I could do that, but it's not Michelangelo.
1382960	1389200	Why? Well, because there is a different history, a different intention, there's a different aesthetics.
1389760	1397280	So the mere ability of reproducing or doing like fails to get the semantic capital behind all that,
1397280	1403120	the intention, the interpretation, the historical context, the continuity, the why did it happen
1403120	1410960	and did not happen something else. All that is the richness of our understanding and semantics.
1410960	1417440	We lose that if we think that all the difference that there is between Michelangelo and the artist
1417440	1422160	in the street is just technique. It's not the case, and we should not be confused on that.
1423280	1428560	I completely agree with you that there is a rich semantic context which is embedded,
1429200	1436800	and this is something I'm conflicted on. So I agree with Soil in the sense that he said
1436800	1442560	there was this rich and nagle actually, this impenetrable realm of the subject of experience,
1442560	1447680	and that informs the meaning. You know, there's an ontological difference in understanding,
1447680	1453920	which is what Soil said. But what's been so remarkable with chat GPT is it does seem to
1454880	1462400	confer some semantic sort of inference, if you like. And I think the reason for that is
1462400	1471760	going back to Pierce's triad, the symbolic version, the semantic content is embedded in
1471760	1478400	our language. And that's why GPT3, even though it's mimicry, it often appears to, I mean,
1478480	1483040	for example, it knows what the concept of Christmas is. So now it's becoming
1484080	1488400	such a close reflection of us, it's becoming more difficult to distinguish.
1490160	1496240	And at some point it would be impossible, if not already. But we should be careful not to confuse
1496240	1503280	this with what you mentioned before, the intentionality, the realm of meaning, of existential
1504240	1512160	experience of all this. Christmas is something that reverberates and provides meaning, for example,
1512160	1517680	in each of us for a reason that is utterly cultural. It would have meant nothing to play
1518720	1523280	obviously for historical reasons and so on. Let me give you an example. This would be like
1523280	1528880	saying that when you cut the tree and you find the rings of the tree telling the age of the tree,
1528880	1536240	the tree somehow told us its age. Well, it takes a little bit of imagination.
1536240	1542160	No, it did not. And yet the symbolic, the representational, it is true that the tree has
1542720	1548400	provided that information to begin with. But it's also because we can interpret that way. So
1549440	1554480	I would like to see more work done on the hermeneutical side of all this, so that we get
1554720	1563920	it clear on what we are consuming. Content, which is sometimes impeccable, sometimes irreversible,
1564880	1568640	cannot be distinguished from content that could have been produced by a human being,
1569280	1574880	but also the understanding, the interpretation, the context, the why it matters of their content.
1574880	1582080	Now, boilerplates are exactly what they are. And if there's something in a, for example,
1582640	1589120	encyclopedia entry or Wikipedia entry, that matters is exactly, is objectivity, is luck,
1589120	1595440	insofar as we can do that, of interpretation, of an angle, almost like as if the author had to
1595440	1605840	disappear. But that is exactly where tools like GPT number will excel. It would be different if
1605840	1614000	we were talking about the way in which an artist, a writer, or anyone simply putting notes in
1614000	1620560	her own diaries, is going through the process of verbalizing, conceptualizing the experience, etc.
1620560	1627680	So ultimately, allow me another analogy. There's a reason why, although we could have
1627680	1633440	the best director and the best orchestra performing that particular concert in the hall,
1634080	1639680	or just a recording that you had to play, we don't. And we can't get a few, a bunch of kids
1640400	1646000	in a choir and a few people who are rather amateurish here in Oxford and do a good job,
1646000	1650880	but certainly not as good as it could have been done by professionals. Is the human experience
1650880	1654480	that matters? It doesn't matter whether you could do that, better by having a tool.
1655600	1662480	Given the pollution of the infosphere with data generated from large language models,
1662480	1664720	what are the ethical implications on society?
1666960	1673120	There are quite enormous, I mean, the responsibility on so many fronts. This responsibility,
1673120	1678320	of course, of the source of this pollution. And by the way, we know that the actual sources are not
1678320	1686560	many. It's not that each of us is constantly pouring, providing extra bits of misleading
1686560	1693840	information and lies. We do inadvertently repeat and reverberate that, but the actual sources of,
1693840	1700960	say, for example, Russian propaganda are very few and well known. And likewise, you know,
1700960	1706640	on many other contexts. So first of all, a huge responsibility on those who are polluting the
1706640	1714800	environment. They are few, they are powerful, and they should be curtailed, shall we say,
1714800	1720960	if not entirely stopped. Huge responsibility on people who could legislate much better,
1720960	1728000	and more firmly. Look at the current debate, people listening to this and watching this should
1728000	1732560	look at the date, but look at what's happening these days to Twitter. I mean, the debate is open
1732560	1737200	about whether it's going to be a source of information or misinformation, and who should
1737200	1741920	be there or shouldn't, etc. How much do we want to control? How much do we want to not filter?
1741920	1747440	But also how our responsibility as a society, we should demand more, and we should be more
1747440	1752160	careful. So if you put together all these responsibilities between the producers, those
1752160	1758960	who take advantage of it, the consumers, we are all in on this. No wonder, it's a mess.
1758960	1762480	But as I said at the beginning, we could rectify it with a bit of goodwill.
1764240	1770160	No, you wrote an article in Aion a few years back called Should We Be Afraid of AI?
1770160	1775840	And the risk debate has been ongoing since the 1960s when Irvin John Goode prophesied a potential
1775840	1782320	intelligence explosion that could leave humanity behind. And on one side of those who believe in
1782320	1789040	true AI, the Church of the Singularitarians, as you wonderfully described them. And on the other
1789040	1793600	side, you have those who do not believe in true AI, known as the Church of the Atheists,
1793600	1799280	sort of that spell AI, which is absolutely delicious. And you said we should remain
1799280	1803920	tolerant of both views. But the real challenge is to ensure that AI is used in a way that
1803920	1809600	does not undermine human dignity. And you said the dogma of the Singularitarians consists of
1809600	1816240	three beliefs. The creation of some form of AI is likely and humanity will be dominated by it.
1816240	1819840	And it's the responsibility of the current generation to ensure it's benign.
1821440	1828640	So you said that Singularitarianism is implausible. It relies on weak senses of the possibility
1830080	1835760	of possibility and Moore's law, and it distracts from the real evils. It's almost an indulgent
1835760	1843040	of the Western elite. So what can be done to ensure that Singularitarianism is not a distraction?
1844560	1851120	I'm afraid that the only cure there will be history, meaning that as we move on,
1852000	1858400	we will see that AI in its variety of forms, natural language processing,
1859600	1867440	robots, even little gadgets that can help us to do this and that in our mobile phone,
1867440	1871680	I mean, that they improve say communication or enable us to take a better picture,
1872240	1878080	the recommended systems that you find on Netflix, et cetera, and all these things we will see as we
1878880	1887440	move on and grow up, that what has really happened is absolutely extraordinary,
1887440	1895600	but not extraordinary as the Singularitarian thing it is. We're actually separating and
1895600	1901520	increasingly so the ability to do these things and to solve problems, take care of tasks
1902160	1908480	successfully in view of some goal, some end, from any need to be intelligent in doing so,
1908480	1913040	that is extraordinary. This divorce between agency and intelligence, that is amazing.
1913600	1917520	And if anyone doesn't want to speculate, just think about chess playing. I mean chess playing
1917520	1922880	today is done at zero intelligence, at least I hope people will admit that my iPhone doesn't think
1923760	1931760	any bits, anyone I can encounter. So extraordinary ability that would require
1931760	1937600	intelligence if I were to play that way, I wish I could, but that it can be done as zero intelligence.
1937600	1944640	Now, as we learn more and more that there is the delta, the gap that we are building,
1944640	1949760	and these two things will go further and further away as we move on, things in terms of what we
1949760	1955840	just said in terms of large language models and the GPT and the other ones that are quick
1955840	1963680	following from other companies without advertising for anyone. We will find any Singularity narrative
1963680	1970960	science fiction, I mean entertaining at some point, frustrating at others, because as you said,
1970960	1978400	it is also distracting. We have plenty of problems generated by this divorce. If you have an enormous
1978480	1986000	new force or source of agency in the world, at zero intelligence, that requires intelligence,
1986000	1992080	hours, governance, law, ethics, a sense of what is the human project you want to build,
1992800	1999920	and meanwhile you're worried that your car would run away with your credit card to have a holiday
1999920	2005920	on a beach, well then certainly frustration starts building up because we're not taking care of the
2005920	2011760	real issues. Now, the discrimination, the digital divide, the amount of things that we're not doing,
2011760	2018480	no, sort of opportunity cost, wherever we are lacking a clear framework and so on. So Singularity,
2018480	2024400	I mean like all churches, I think they will become increasingly old and they will not die,
2024400	2030080	I mean they will always have a few faithful ones, but hopefully will not be in the headlines,
2030080	2034640	which is one of the reasons why people like to push forward the Singularity so that they get the
2034640	2040800	headlines. In terms of the end game though, you might argue that they have a point, I suppose
2040800	2045840	you're arguing that, I don't want to put words in your mouth, but you just spoke about the industrialized
2045840	2050640	attenuation of our agency and that maybe that's analogous to saying we're becoming increasingly
2050640	2058320	enslaved by technology and our children's generation much more so than we are. So in some sense,
2059200	2064480	would you argue? Oh no, it would be like saying, well I mean you could read that in terms of the
2064480	2071360	engine and wonder whether the engine and the whole industrial revolution and urbanization coming
2071360	2079280	say from model engine and so on has been liberating, has been enslaving, has been a good thing, a bad
2079280	2086720	thing, has all real historical and real philosophical issues. It's a mix back and you can't simply say
2086720	2094080	oh no, I wish the car had never been invented, really like I'm not quite sure, but on the other
2094080	2098640	hand the damage that we are caused to these environments, so same with the AI. Now one could
2098640	2104080	say I wish people had never taken this genie out of the particular bottle, really like the kind
2104080	2110080	of things that we can do thanks to this. Think of one case, just a simple case, like cold fusion,
2110080	2116400	I mean today if there is even a remote chance to get there is because of machine learning.
2117200	2123120	We will never get there without the enormous abilities of computational problem solving
2123120	2132240	provided by AI and so forth, so this case too requires more commitment, more sort of human
2132240	2137920	intelligence, more governance, not less. So sometimes I find that debate becomes a little bit of a
2137920	2142960	deterministic kind of debate between things that people who think they were doomed and things
2145040	2151040	rosy glasses think oh it's going to be a wonderful world, well honestly it just up to us. The crude
2152480	2158000	painful sort of truth is that unless we do something about it, it will be a mess, but if we do
2158000	2162960	something about it and we do it rightly, well then we can do an enormous amount of good things for
2162960	2169440	this, no at last point just to have some references, just look at the impact of AI in a variety of forms
2169440	2175920	again on the sustainable development goals has been already significant, could do so much more
2175920	2181520	at the same time, how much energy goes into development these sort of large language models,
2181520	2187680	huge, are we really doing the best with this sort of consumption and impact when then if we
2187680	2194240	were to use this for example for entertainment, for advertisement, when every bit of electricity
2194240	2199440	out there should be carefully considered, even impact on the environment, these are real issues,
2199440	2205200	but they are philosophical issues for human beings. Is there a way that we can embrace this
2205200	2213200	technology in a way that preserves human dignity? I think so, the question is not however to simplify
2213840	2221760	in terms of human-centric, because what reason maybe we can explore later, but we have done
2221760	2226880	too much of that precisely because we have been so human-centric, we have destroyed this world,
2226880	2235760	we have killed the environment, we should be more sort of at the service of both the natural and the
2235840	2242960	sort of man-made artificial environments as well, so to me the best way of using technology
2242960	2250400	is by respecting as we said before human dignity, but also using technology to the benefit of
2251120	2256000	quote-unquote the other, which could be future generations, it could be the environment,
2256000	2262480	it could also be us taking it as humanity, but not just us, if we use technology just for us
2262480	2266320	and our own benefit, we will ignore future generations, we will ignore the environment,
2266320	2272560	and we will not have done a full decent job, so yes there is, but it takes a little bit more
2272560	2277360	of a commitment that we have at the moment. What form of governance do you advocate for?
2279760	2286080	To me the governance that we could develop would inevitably leverage this digital revolution by
2286960	2293840	offering, not imposing, not expecting, offering more participation at the beginning of the
2293840	2299040	decision or process, so these are two distinctions that go against the right democracy, I'm not
2299040	2306400	advocating for the right democracy, I'm saying offering so cannot be expected or compulsory,
2306400	2313360	but plenty of offer at the beginning, not at the end, take a referendum, a painful memory here,
2313520	2321120	we are in the UK, a referendum is not the right democracy, why? Because you can't choose between
2321680	2328720	A and B, if you dislike both A and B, someone has prepared the alternative for you, the real
2329360	2336000	democracy that is co-designing of the choices, not the options at the end, but the initial
2336000	2344320	choices is the one that says, should we consider a referendum or blah blah blah, so the point here
2344320	2351440	is that the earlier the involvement, the better is to live in that kind of society, so the governance
2351440	2358320	that I'm advocating is a governance that has as early as possible involvement of people in a
2358320	2367120	co-design of the choices that we face, now that, and I was here sorry but it's a huge topic, that
2368240	2374480	means that behind this particular sort of mechanism, there's a separation between
2375280	2384960	those who have power, the people, and can delegate power, and those who exercise power but don't
2385040	2393280	have it, this structural separation between having power without exercising and exercising power
2393280	2401520	without having it, that to me is the ABC of any decent governance, governance fails, especially
2401520	2407520	political governance, no in the democratic sense of governance, fails the moment you have those who
2407520	2412400	have power exercise it and those who exercise it have it, it doesn't matter whether it's a majority,
2412400	2418480	it's minority, it's an oligarchy, it's three people, it's one person, it's a family, it's a tyranny
2418480	2423920	of a few people, maybe only one, as soon as you separate this then we start having the right
2423920	2429440	governance, then we can talk about involvement in the decisional process as early as possible,
2429440	2435200	then co-design, and therefore for all this the kind of technology that we have, this is doable if we
2435200	2441280	want to implement it. One thing that concerns me is that when we talk about the architectural
2441280	2449440	design of governance, the structure can sometimes exclude other parts of the complex world that
2449440	2454320	we live in, and also there's this compatibility with the Demos which is to say it needs to be
2454320	2460320	intelligible, and then you have this problem of people voting in their own self-interest,
2460320	2467120	even if they did understand the purpose of the governance. True, and we know that self-interest
2467120	2473680	can go only there far, we learned that from the past century, the 20th century, the 20th century
2473680	2479280	has been the century, especially the second half, so stuff has been a disaster, the second half much
2479280	2486080	more successful, has been the century of the citizen-consumer, and therefore the self-interest
2486080	2492560	as a citizen voting for the best options, making a difference, and therefore competition between
2492560	2497200	different parties etc, and the consumer having the same kind of choices, voting quote-unquote with
2497200	2501680	his note, that what they feed so to speak, choosing their restaurant or another, their shop
2501680	2508480	rather than another, their product or another, but this figure that was the selfish interest
2509680	2519040	consumer slash citizen has become not the user and the follower, so today instead of having
2519040	2524320	citizens we have sort of followers, instead of having consumers we have users, and therefore
2524320	2533280	there has been sort of impoverishment of precisely their selfish sort of interest, the caring for
2533280	2538400	my individual project, which is one of the two legs for democracy, so their leg has become weak,
2538960	2545520	the other leg is absent, which is the social side, so at some point society should also invite,
2545520	2554640	facilitate, support, so nudge gently towards more not social solutions, for the simple fact that
2555440	2561760	if we need to be more ambitious in our goals, we need to get together, it's not enough to not pursue
2561760	2566960	our own self-interest, we have to pursue interests that are shared, so imagine the following picture
2566960	2573040	out of this quick analysis, two legs, one has become weaker, the selfish interest for my individual
2573040	2578800	project, the other one which is a social project is not there for obvious reasons, when we tried in
2578800	2585760	the first half of the last century, it was the most horrible episode in human history, the Nazi,
2585760	2592800	the Soviet Union, no democracy going out of the window, I mean Auschwitz, I mean we have created
2592800	2602000	the most horrific possible nightmares that humanity has ever seen, so on this not so well
2602160	2609360	so established body of democracy which has one leg missing, at the other one we, there's a lot of
2609360	2615760	work to be done, we can do a better job reinforcing a sense of individual projects, what we call not
2615760	2625680	more selfish interest, yes, and no, instead of no, either or instead of weakening it, reinforcing it
2625680	2631520	and balancing it with a social project, the idea that no, if you get together you can do so much
2631520	2636160	more and so much better than just by yourself, finally an example, if that car, and I've used
2636160	2641520	that more than once, forgive me, but if that car doesn't start, it's totally pointless for you to go
2641520	2646240	and push and come back home and say I've done my duty, it has to be the five of us, and it has to be
2646240	2654320	the five of us, one, two, three, push, coordinated, so we need to have a society that increases the
2654320	2660640	support for individual projects and has a good liberal democracy and counterbalances that with
2660640	2666480	social common projects, so there we have both, now normally you find this a little bit more sort
2666480	2673360	of developed in, no, western social democracies of a Scandinavian kind, now I wonder everybody
2673360	2679520	wants to get there, I think you would agree, I mean Chomsky spoke to this but that you know
2679520	2685760	market forces as well as technological forces reontologize us, I want to pick up on this word
2685760	2691280	reontologize, I think it's an amazing word, I'm just going to scroll down to this, but yeah you
2691280	2696640	said that once digital immigrants like us are replaced by digital natives like our children,
2696640	2702560	the immigration will become complete and future generations will increasingly feel deprived,
2702560	2707840	excluded, handicapped or poor whenever they're disconnected from the infosphere like fish out
2707840	2712800	of the water, you said that information and communication technologies are reontologizing
2713520	2720080	which is an even more extreme form of re-engineering us in our society which is to say its intrinsic
2720080	2725200	nature is being transformed, you said that we're modifying our everyday perspectives on the ultimate
2725200	2732000	nature of reality that is our metaphysics from a materialistic one, you know in which physical
2732000	2738000	objects and processes play a key role to an informational one, so let's I mean you know
2738000	2744800	explain your rationale but I love this word reontologizing, yeah well this comes from a very
2744800	2752640	Kantian anti-metaphysical perspective, I find any metaphysics of the bad kind that Kant was talking
2752640	2758640	about beyond my comprehension, it's something that I just don't quite get, I mean how people
2758640	2764960	can possibly believe that they have a direct line with being capital B and being told by being,
2764960	2774480	what is like to be being is beyond me, so I'm afraid on that front I am rather deaf and I understand
2774480	2780560	that it might be my limitation, I rather speak, sorry when I use the word metaphysics that's
2780560	2785920	what I mean, the Kantian kind of thing that you don't do because it's meaningless to do it,
2786560	2792320	there's also a lot of no kind of Vienna circle kind of an analytic philosophy in all this but
2792880	2801680	ontology on the other hand is how we structure the world in the sense that we think that that's
2801680	2808400	the way it is, so with the kind of eyes we have and the kind of light around the world
2808400	2813600	that those are the colors we perceive, to me the colors in the world are part of the ontology of
2813600	2818400	the world they're not, nothing to do with metaphysics, it's not the way things are in themselves,
2818400	2824080	no woman and etc, I have no sense of what we're talking about but certainly a world full of
2824080	2830800	colors is the world which I take it to be, the world, that's my ontology, now reontologizing
2830800	2838080	means changing some of that particular nature, allow me a distinction so I hope it's not too
2838080	2844480	confusing, reality in itself call it system, description of reality as we perceive it,
2844560	2850320	enjoy it, conceptualize it, live through, model of the system, ontology to me is the ontology of
2850320	2855440	the model, it's not the metaphysics of the system, I hope I haven't made a complete mess here,
2855440	2862720	okay, so metaphysics no manom system, whatever the source of the data that we get, fantastic,
2862720	2867680	the data don't speak about the source, the music of the radio is not about the radio,
2867680	2872480	but there is a radio, of course the music is what we perceive, the music has its own ontology,
2872480	2879360	structure etc, the model, the model is at that point what we enjoy, why the digital revolution
2879360	2885760	has changed the nature of the world around us, not metaphysically but ontologically, so the
2885760	2891120	reontologizing, because some of the things that we have inherited from modernity, and I really mean
2891120	2895200	modernity in the ordinary sense, no three or four centuries depending on whether you have a
2895200	2902160	large short medium modernity from Columbus onwards or bit shorters, first world world,
2902240	2908640	your size, your preference, but modernity, we have been added from modernity a sense of the world
2908640	2916320	that is now being restructured and a certain understanding of the world, so re-epistemologizing
2916320	2924080	as well of that world, two simple examples, modernity onwards, which I know I've used in the past,
2925040	2932560	we have grown up with the idea that law and territoriality are two sides of the same coin,
2933760	2938640	you can't simply separate them, my place, my rules, your place, your rules,
2938640	2944880	if from Westphalia onwards, that's the ABC of any legal system for a long long time,
2944880	2952320	the law ends where the territory of that particular state that issues the law ends, no, at the border,
2953280	2958160	so law and territoriality, two sides of the same coin, or two sides of the same piece of paper,
2958160	2962320	you can't cut one without cutting the other, of course, that's the ontology of the world in which
2962320	2969520	I live, welcome to cyberspace, right to be forgotten, our whole debate and today we know that actually
2969520	2975200	law and territoriality are no longer two sides of the same coin, they've been completely decoupled
2975200	2980560	and you cannot have rules that for example are passed in Europe that apply to a search engine
2980560	2985760	that is based in the United States and yet is only one click away, so the right to be forgotten was
2985760	2991760	no, the moment when this became obvious, we were legislating about Google and Google not complied
2991760	2997760	in Europe, the complaint was like well but it's not changing the way google.com is working, well
2997760	3001760	the law doesn't apply there and of course there was a debate in terms of oh but it has to apply
3001760	3009120	everywhere in the physical space, so the decoupling of the law and the territoriality is a reontologization
3009120	3014960	of that particular space, we live in a different world, we perceive the world differently, conceptually
3014960	3019920	we also start thinking differently, now let me give you a small example and I close here
3021200	3029360	of a reontologizing of something we took absolutely for granted, right, if you have a taxi you have a
3029360	3035280	license, if you have a license you can be a taxi driver, the two things go hand in hand
3035840	3043680	and it's illegal etc, then Uber comes and having a car being allowed to give a lift to someone
3043680	3050960	is decoupled from having to have the license as a taxi driver, a cab driver, this decoupling
3050960	3057840	has generated an enormous amount of profit, problems, issues, a change in game and all of a
3057840	3064960	sudden we realize yeah those two things were not completely one side of the other, so obviously
3064960	3070480	this uberization of the world means decoupling things that we have taken for granted as a single
3070480	3076880	unit from modernity or gluing together things that we thought were completely independent
3077520	3083120	in the past, last example, personal identity, for a long long time we discussed personal
3083120	3091840	identity, I mean philosophically speaking, as you like substance, soul, body, what the incarnation
3092320	3097600	today if you look at anything that identities our data, that's the European legislation
3097600	3104080	describes as data subjects, I am my information, privacy, the whole privacy debate is discussed
3104080	3111440	in terms of what constitutes me as that body of information, privacy is a matter of getting my
3111440	3116880	body almost, so why is this important because if you look and I close here at the European
3116880	3126480	legislation how did they cope with the decoupling of space territoriality and law by coupling personal
3126480	3134240	identity and data, personal data so that today the legislation does not say you do as you're told
3134240	3142320	because it's my space but it says you do as you're told because this data are the data of the individual
3142320	3149760	who is my citizen wherever you are, so decoupling, recoupling, new legislation this is
3149760	3155280	incomprehensible unless you have this cut and paste in mind which is the reontologizing,
3155280	3162000	reappease demologizing of modernity through the digital evolution, it's a big deal.
3163200	3169280	The Uber example is absolutely beautiful and I can place myself in the startup and these folks
3169280	3174400	think they're being incredibly disruptive and what you said is interesting, we used to talk about
3174400	3181360	the mind-body dualism but now there's almost a kind of identity dualism, there's my digital
3181360	3187120	identity and that is becoming increasingly as you say the only thing which matters but
3187120	3193120	to close off this reontologizing thing, I'm not sure this might be a little bit tangential but
3193120	3197520	Heidegger conceived of technology as an intermediation between us and our environment,
3198320	3204000	I think in a similar way and it shapes the environment as much as it shapes us back
3204560	3209440	and in a sense reliance on technology can make us less human which is kind of what you're
3209440	3214160	relating to, is there an instructive contrast to Heidegger's analysis of the relationship
3214160	3221280	between humans and technology and you're right? I think Heidegger was onto something when obviously
3221280	3229600	technology is between us and the environment but allow me to be critical, he didn't see this
3230480	3235760	seems to me clearly enough because that description, the description of a first order,
3235760	3240640	what I like to call first order technology is essentially the very idea that between me and the
3240640	3254640	tree there might be a sowing mechanism or between me and that particular sort of garden
3255440	3261120	there might be a spade but increasingly unless the industrial revolution
3262000	3265920	instead of having humanity and nature and technology in the middle you have humanity,
3265920	3272640	technology and technology and that's a second order technology so we increasingly use more and
3272640	3277920	more technology to deal with other technology and that's not in Heidegger, it's a second order
3277920	3284400	technology but what AI does is to generate a third order technology where no between A and
3284400	3288720	B and C is technology throughout so it's a computer controlling a robot building a car
3289840	3293760	at that point we are outside that relationship and we can just control
3294560	3297920	check that everything goes in the right way we are on the loop or after the loop
3298640	3304800	at that point we can reinterpret the Heideggerian negative view of technology and say that is
3304800	3312400	exactly where you want to be, you want to be outside the me technology nature or me technology
3312400	3318800	technology I want to be on top of technology technology technology and see whether that goes in
3318800	3327360	the right direction now it's even more powerful even riskier but with higher risks higher rewards
3327360	3334000	it could also mean how humanity can actually take care of the world nature and itself properly
3334640	3340960	now we would not be able to save this planet and ourselves from ourselves on this planet
3340960	3347040	without technology it's inconceivable that now we can see at the end of the 21st century
3347040	3353520	as a success by abandoning technology like seriously no more embedded technology but then
3353520	3360240	we need to understand this no third order idea if we're still stuck in a sort of 19th century 19th
3360240	3367040	century idea that it's between me and the world we're not gonna get out this final point obviously
3367040	3373440	being on the loop or after the loop the designer of the whole loop comes with enormous responsibilities
3373520	3379360	that's why ultimately to me it's not digital innovation but it's the governance of the digital
3380000	3385440	that makes the whole difference digital innovation is it's it's not easy but it's not difficult
3385440	3390080	especially if you have deep pockets you buy the next startup and the next no three kids who come
3390080	3396800	up with a fantastic idea knowing what to do with that that takes a genius so um you said in your
3396800	3402800	information book that John Wheeler coined the notion of it from bit and some physicists entertain
3402880	3408800	an information based description of reality and you said that this informational metaphysics may
3408800	3415040	but does not have to endorse a more controversial view of the physical universe as a gigantic digital
3415040	3420560	computer according to which dynamic processes are some kind of transitions in computational
3420560	3426640	states in a style described similarly by Putnam and or maybe I call it Turing machine functionalism
3427360	3433440	so you pointed out the the ontological difference between imagining a stomach as if it were a
3433440	3439360	computer versus holding that the stomach is actually a computer you said that there's a clear
3439360	3443760	philosophical distinction between whether the physical universe might be modelled computationally
3445040	3449040	is a different question to whether the ultimate nature of the physical universe might actually
3449040	3455440	be digital and computational in itself so so what's your take I think the whole problem is ultimate
3456800	3462480	we go back to this temptation of talking about reality as if you were something that we need to
3463360	3474880	grasp catch portray hook uh spears um when in fact the the way I prefer to understand it is as
3476480	3482720	malleable understandable in a variety of ways um something that provides constraints
3483440	3488320	it doesn't mean that you can interpret in any possible way but leaves room for
3489440	3494800	different kind of interpretations so if the flow of data that come from whatever is out there
3495520	3502720	and again I'd rather be sort of agnostic about it can be modelled in a variety of ways um one way
3502720	3508160	is to especially 21st century given the technology we have etc to interpret that as
3508160	3514000	no an enormous computational kind of uh environment it's perfectly fine as long as we don't think that
3514000	3521600	there is our right metaphysics is the correct ontology for the 21st century now this is not
3521600	3528480	relativism because on the other hand different models of the same system are comparable depending
3528480	3533280	on why you're developing that particular model and let me give you a completely trivial exam
3534080	3536720	suppose you ask me whether that building is the same building
3537920	3543920	that question has no real answer because it depends on why you're asking that question
3543920	3548160	if your question is asked because you want to have directions I'm gonna say oh yeah it's the
3548160	3553680	same building so the same building yeah absolutely no go there turn left no traffic lights up but if
3553680	3557840	your question is like same function as I know it's completely different building it was a school now
3557840	3566000	is a hospital next question so is it or is it not the same that that question is the mistake
3567200	3573760	an absolute question that provides no interface what computer scientists call level of abstraction
3574560	3580720	chosen for one particular purpose so that I can compare whether an answer is better than another
3580720	3584960	let me crack a joke for the philosophers who might be listening to this huh there's your ship
3584960	3591040	is it the same or is not the same who is asking why because if it is the tax man the tax man
3592480	3597520	you're doomed man I mean there is no way you can play any who I change every plank that you're
3597520	3604080	gonna pay that tax is the same ship I don't care but if it is a collector that ship is worth zero
3604080	3609280	you change all the planks you must be joking it's worthless so is it or is it not the same
3609840	3614720	depends on why you're asking that particular question tell me why and I can give you the answer
3615120	3621280	now why in other words no frame within which we have chosen the interface that provides the model
3621280	3627680	of the system no potential answer so the question is like is the universe a computational
3628320	3637520	gigantic yes or no meaningless is it worth modeling the universe as a gigantic for the purpose of
3637520	3643920	making sense of our digital life oh yes definitely because we are informational organisms aha so
3643920	3650080	metaphysics no I meant in the 21st century the best way of understanding human beings today
3650080	3656800	is as information organisms last century we thought that biologically not made much more sense a lot
3656800	3666080	of water and sprinkle all the extra and so on mechanism the car time etc so not absolute answers
3666080	3672960	no relativistic answers but relational answers the relation between the question the purpose
3673040	3678080	and the actual answer but it takes three not two any absolute question absolute mess
3679600	3685040	this is so interesting I mean I spoke with David Chalmers recently and about the hard problem
3685040	3690640	and there was a thought experiment about maybe David lives in the matrix and one of the architects
3690640	3695840	came down to him and he said David you don't have the consciousness model installed we've
3695840	3699760	installed it on other people but we didn't bother installing on you but you're a philosophical zombie
3699760	3704800	or whatever and what would we need to do to to convince you that you're in a simulation and David
3704800	3708480	said well I'm outside the Empire State Building maybe if you turned it upside down I believe you
3708480	3713680	but but to be to be clear you're actually saying because I'm interested in this kind of
3714640	3719840	ontological distinction you're saying that even if we did exist in a computer simulation it wouldn't
3719840	3726160	make any difference it wouldn't it for the same reason that it doesn't matter whether we are in
3726160	3734480	God's mind as Berkeley's subjects it makes no difference because what you have lost there is
3734480	3741200	any traction by asking that particular question with anything that would provide any answer in other
3741200	3749520	words these are only sophisticated ways of playing as you lose tails I win find me a solution
3750320	3756400	you should stop engaging with these kind of questions is the trolley problem you should stop
3756400	3760960	engaging in that particular question because there is it but philosophers love those disposals
3760960	3766640	now they imagine the possible world in which well as soon as anyone start talking about imagine a
3766640	3772560	possible world what are they I reach for my Kalashnikov or something else I I think we should
3772560	3776800	really not indulge in these kind of things not because they have wronged but because they are
3777520	3784720	misused any real philosopher and I'm talking about this no 20 25 30 classics have been using
3785680	3792560	thought experiments logical possibilities for a purpose not in themselves you will not catch
3792560	3800400	they can't trying to solve the demon malicious demon problem that is a tool to get somewhere
3801040	3805760	is not something worth in itself same reason why now the trolley problem was developed to test
3805760	3811920	the particular theory not as a puzzling itself same reason why you know people are no no in a
3811920	3818720	matrix etc etc once again ask yourself what is the purpose for this particular question
3819360	3826480	because the purpose is a lot of mental enjoyment chess is much better beautiful well we've got
3826480	3831360	about two minutes left so I guess we'll have a closing statement but maybe also you could bring
3831360	3837040	in I mean I've got a machine learning audience so they would be interested in in in digital ethics
3837040	3843280	for example and and what they can do to learn more but also many folks are interested in getting into
3843280	3849280	digital ethics and philosophy so what what would you say to those people to the machine to machine
3849280	3857440	learning people I was always say like congratulations you are in the right business but secondly I
3857440	3865600	would say please don't forget where all this is going have a sense that these are not just toys
3865600	3871200	these are not just a matter of competition between one company another to have a larger model a faster
3871200	3878080	sort of computer a slightly improved quantum something and on and on we can go in a variety
3878080	3881680	of directions machine learning is one of the problems but think about the impact that they
3881680	3887920	will have on society on the environment and on individual lives it could be a fantastic impact
3887920	3895440	it could really make a difference in suffering in saving the environment or it could be a total
3895440	3903760	disaster so please mind your machine learning and be a little bit more aware of the importance of
3903760	3909760	your job don't underestimate how crucial it is what you're doing you are providing the foundations
3909840	3915520	for the 21st century information society that is not small task we do that right we're gonna
3915520	3920880	not be thanked by future generations you we do that wrongly future generations may not be even
3920880	3926640	there but if they are there they would not be grateful so please not be careful what can be done
3926640	3931920	well one of the things that no this will end up with self-advertisement a little bit but one of
3931920	3937520	the things that we are going to do with the new center Yale is precisely opening the doors to
3937520	3943920	all disciplines and all practitioners because research and development today is done especially
3943920	3948720	in AI especially machine learning especially in digital context enormously more within
3948720	3956000	industry than sometimes in even the top universities so opening up having this translational no from
3956000	3963680	blue sky to product and multi-disciplinary open idea that it's a big table out there we need
3963760	3969120	everybody around the table the politician the lawyer the engineer the machine learning expert
3969120	3975440	the philosopher the ethicist the social scientist etc everybody around the table then that point
3975440	3983040	that I made the beginning will become a little bit more reasonable doing it together to improve the
3983040	3990160	world improve the chances of saving the environment ourselves can be done and I'm not sticking some
3990160	3998320	on my actual so neck out so to speak on this but it's something that I truly believe it's
3998320	4005600	entirely up to us and we can do this properly if we put ourselves into it professor Luciano
4005600	4011600	Florida it's been an absolute honor thank you so much thanks a lot thank you so much
