1
00:00:00,000 --> 00:00:17,840
Mae ein dweud, Prof. M glyran, oedd ysgol yn fy wir

2
00:00:17,840 --> 00:00:29,800
y cof AM dewis.

3
00:00:29,800 --> 00:00:32,680
..allwch chi'n ddweud mewn ar 모�f whackingr.

4
00:00:32,680 --> 00:00:47,560
Cyfanyd dros y tlaen ymar 700 o.r.l ar y ddangos oak Wfyn

5
00:00:47,560 --> 00:00:53,320
Rhaid da siar aheadwch Allwn ni i wneud anghofcond oherwydd dwyr am have eamen dda chi'n

6
00:00:53,320 --> 00:00:54,120
ddluciaethu rheidiol.

7
00:00:54,120 --> 00:00:58,600
On n ess bynnwyr y cy terriblyfyrdd isw pof wych yn iddiw i'w ffyn i'w wneud.

8
00:00:58,600 --> 00:01:00,800
Codd,Hayde, sy'n meddwl yn mynd i sicrhau y r communist.

9
00:01:00,800 --> 00:01:04,640
Mae'r pysigod ychydigbaradau ar y prydysig iechyd drumol rollun?

10
00:01:04,640 --> 00:01:06,880
Yn Clo.

11
00:01:06,880 --> 00:01:09,080
Ac mae'n rhaid mewn yw'r blwyddyn yn dolpa.

12
00:01:09,080 --> 00:01:11,600
Yn yr ardwaith a pob el擊wrom.

13
00:01:11,600 --> 00:01:13,160
Fel jei hy myślęНАЯ여

14
00:01:13,160 --> 00:01:14,120
neu saddleghio.

15
00:01:14,120 --> 00:01:17,000
Fe hyd yn cael yn cael yn ystyried.

16
00:01:17,480 --> 00:01:19,600
Dyma'r wrth another Richard however.

17
00:01:19,600 --> 00:01:21,840
Cyn ystyried eich ddimentisigon

18
00:01:22,840 --> 00:01:26,800
yr pawr deisasfer o'r ddyfod poetol

19
00:01:26,800 --> 00:01:28,100
i weld eich gobl nebneg

20
00:01:28,100 --> 00:01:33,840
o'r nesafелаidd arall, bwynt

21
00:01:34,260 --> 00:01:37,920
ein thaw wnaeth sy

22
00:01:37,920 --> 00:01:38,360
i eu tanfod ei lynƏn iw meddwl?

23
00:01:38,380 --> 00:01:39,940
Yn arglwr hwn.

24
00:01:40,040 --> 00:01:41,560
So ei hwn,dsaintar,

25
00:01:41,560 --> 00:01:45,660
awdurd ön weithen o gan disgwyl

26
00:01:45,660 --> 00:01:46,440
ac rhun sig yn gwneud

27
00:01:46,480 --> 00:01:48,580
a fydd creddo yn cael ei wneud

28
00:01:48,740 --> 00:01:50,460
a dyna ni'r gweithiool

29
00:01:50,800 --> 00:01:53,200
yn eu gwneud mwyn o dyng Nghaerurgical

30
00:01:53,740 --> 00:01:56,540
felly hwn yna'r 21 y sector

31
00:01:56,540 --> 00:01:57,940
sydd o argymell

32
00:01:57,940 --> 00:02:02,380
ac nifon â mount Goraen iawn,vision sy'n heb gyran â y proses Cysydd yr olan.

33
00:02:02,540 --> 00:02:08,940
Felly, gyda hynny fel dros amll וה연 hwn olanan i ddefnyddio effaith.

34
00:02:08,940 --> 00:02:13,640
Rydw i ty bedroom, tu'ch

35
00:02:13,640 --> 00:02:17,720
y gwneud i amddangos â'r twfynu.

36
00:02:17,720 --> 00:02:22,960
A ti'n mynedwch i gyd yn agorio your ehydol sy'n gyffredinol

37
00:02:22,960 --> 00:02:24,520
a gweithio sicrhau.

38
00:02:24,520 --> 00:02:38,520
I was pleased and honoured to write one of the, one of the blurbs for this and actually use the phrase, this is a book that grabs you and literally changes your mind, it's a nice quiz.

39
00:02:38,520 --> 00:02:44,520
And I've just noticed, yeah, little story about Andy.

40
00:02:44,520 --> 00:03:08,520
And if I remember correctly, Andy started at Sussex University with a good and great like Margaret Bowden, then after an itinerant and glorious career involving America ended up in Edinburgh, which he loved, but he couldn't surf in Edinburgh, so he's always wanted to get back to Brighton, back to Sussex.

41
00:03:08,520 --> 00:03:30,520
And a few years ago, Anil Seth, who's himself at Sussex, who I noticed here has also written some lovely blurb, I'll just read that, a predictably groundbreaking exploration of the predictive basis of our extended minds from one of our deepest and clearest thinkers.

42
00:03:30,520 --> 00:03:51,520
The experience machine delivers a remarkable combination of profound insight and practical relevance. So Anil was very pleased with himself, and I remember joyfully declaring when he'd actually secured Andy Clark or headhunted him from Edinburgh back to Sussex.

43
00:03:51,520 --> 00:04:18,520
So they could, when I say they, Andy and Alexa could go surfing again. And I remember the point at which he got confirmation of Andy's headhunting. We were actually trapped during a, what they call, a hurricane in the Mediterranean on a little Greek island drilling down, I think it was on the mathematical basis of consciousness.

44
00:04:18,520 --> 00:04:39,520
And we're in communicado with the waves raging outside, and Anil Seth was playing the piano, and he got this phone call to confirm that he'd managed to secure Andy Clark's chair at Sussex several years ago. So from what I understand, Andy is now happily, is he a cognitive philosopher?

45
00:04:39,520 --> 00:04:49,520
Yes, I'm incredibly jealous of his job title, a cognitive philosopher. That would be my aspiration one day to be a cognitive philosopher.

46
00:04:49,520 --> 00:05:08,520
Yes, surfing and philosophy. So he emailed me about this, must have been before Christmas, saying he'd written a pot boiler. And would I like to just look, pass my, read through it briefly. I had to Google what a pot boiler meant.

47
00:05:09,520 --> 00:05:25,520
Apparently, it's a brief and cheerful book to make money. So I've beautifully written, but then I had to reread it to write the blurb, and it's certainly more than a pot boiler.

48
00:05:25,520 --> 00:05:53,520
It's actually an interesting synthesis of, I think, where that style, certainly Andy's style of thinking about life and making sense of the lived world and physically engaging with that world, where he was prior to predictive processing an active inference before the sort of the pragmatic turn or the inactivist shift.

49
00:05:53,520 --> 00:06:22,520
He has been moved from the 21st century. So before that, he was famous for things like the extended mind, the designer environment that we, in the spirit of niche construction, we actually create our own niche, we create our own environment in a way that makes it much more predictable and affords the opportunity now to sort of download a lot of our cognitive capacities into the world.

50
00:06:23,520 --> 00:06:37,520
Memories are now in our iPhones. And then he's basically taken those foundational and fundamental ideas and contextualize them in the context of the modern predictive processing and active inference.

51
00:06:38,520 --> 00:06:42,520
And this is the synthesis. A lovely read.

52
00:06:42,520 --> 00:07:00,520
I wanted to pick up on something you just said, though, because when I was reading the book, I was rather struck by this idea that we live in a hallucination, which is conditioned by actual sensory information, but let's say 90% hallucination and 10% sensory information.

53
00:07:00,520 --> 00:07:11,520
And from an inactivism point of view, what's really interesting about that school of thought is that we create the world that we live in, as well as the world creating our own kind of sensorium.

54
00:07:12,520 --> 00:07:17,520
And that's just something that really struck me as being quite interesting. What's your take on this living hallucination?

55
00:07:18,520 --> 00:07:30,520
Well, you say 90% hallucination and 10%. I probably think it's 100%. That's absolutely right.

56
00:07:31,520 --> 00:07:52,520
So, if you believe that everything that we perceive as being real is a hypothesis, the product of a constructive organ, a statistical organ, a little scientist that just is our brain, then all you're saying is that the sensory data are just in the service of confirming that hypothesis,

57
00:07:52,520 --> 00:08:00,520
or this alternative hypothesis, or another hypothesis. The key observation being it's all hypotheses. It's all fantasy.

58
00:08:01,520 --> 00:08:15,520
So, using the fantasy word is nice because it means that the brain is literally a fantastic organ. It's a purveyor of a device for basically adjudicating, choosing the right hypothesis as a best fit to this sensory data.

59
00:08:16,520 --> 00:08:32,520
But of course, as you point out, it's not just the fact that we assess our brains, creatures, phenotypes that are delivered of data. Andy Clark would express this in terms of this outside in process.

60
00:08:33,520 --> 00:08:50,520
We actually have to actively select those data by moving, by palpating with our fingers, by moving our eyes around. We are in charge of the data that we now solicit to verify or disconfirm our hallucinations or our hypotheses.

61
00:08:50,520 --> 00:09:03,520
So, that's the inactive part. That's a sort of actively engaged in a way that induces this kind of circular causality. So, we are certainly constrained by our sensory data.

62
00:09:04,520 --> 00:09:21,520
Our predictions and hypotheses are informed and contextualized by sensory data, but at the same time, the ensuing hypotheses underwrite the way that we sample the next bit of data.

63
00:09:22,520 --> 00:09:28,520
So, there's this wonderful sort of autodidactic, you know, physical engagement with the lived world.

64
00:09:28,520 --> 00:09:43,520
Yes, yes. But I would love to understand where the autonomy comes from. And the reason I'm asking this question is there have been many papers on chat GPT recently that have essentially built an outer loop to find different prompts.

65
00:09:44,520 --> 00:09:51,520
So, if you think of GPT as an information retrieval system, there's an outer loop to explore prompts in the neighborhood of the original prompts.

66
00:09:52,520 --> 00:09:58,520
And this is very similar to what you're saying from the inactive point of view now. There are books about how we think with our bodies.

67
00:09:59,520 --> 00:10:10,520
And you just said that there's an outer loop that says, well, I now need to explore with my physical body in my physical environment to get more information to do inference.

68
00:10:11,520 --> 00:10:13,520
And what process is doing that outer loop?

69
00:10:14,520 --> 00:10:15,520
What process?

70
00:10:16,520 --> 00:10:42,520
So, I guess the body is in and of itself just a hypothesis and therefore the answer to your question, it can't be that the self is, if you like, driving this active engagement, this sort of active learning and active inference about the way the world works.

71
00:10:43,520 --> 00:10:52,520
If it is the case that the self is actually emergent from or an explanation we bring to the table to explain all of these data.

72
00:10:53,520 --> 00:11:03,520
So, there must be something underneath that. And as a true Bayesian statistician, my answer would be there are some prior belief.

73
00:11:03,520 --> 00:11:16,520
And I don't mean belief in a sort of folk psychology sense, I just mean in terms of some probabilistic distributions and probabilistic specification of what it is to be something like me.

74
00:11:17,520 --> 00:11:27,520
And then something like me goes around self evidencing, acquiring sensory data that supplies evidence for my model of this world.

75
00:11:27,520 --> 00:11:36,520
And I suddenly have the hypothesis that this world actually includes me as an agent, as an artifact, and then I develop a sense of self.

76
00:11:37,520 --> 00:11:54,520
So, I guess your question is where does the autonomy come from? As a mathematician, it comes from autonomous differential equations that underwrite the itinerancy and technically the attracting sex of the attractors that characterise me,

77
00:11:54,520 --> 00:11:59,520
that specify the characteristic states that I will remain in.

78
00:12:00,520 --> 00:12:11,520
So, technically speaking, I can, if you like, elu the question about where does autonomy come from, where it comes from autonomous differential equations that characterise an attracting set of characteristic states that make me.

79
00:12:11,520 --> 00:12:30,520
And you could actually simulate that, you can simulate all sorts of things that have this sort of bimetic aspect, you know, walking, talking, writing, all of these basically being a physical realisation or instantiation of these autonomous dynamics that, you know, in a very straightforward way,

80
00:12:30,520 --> 00:12:43,520
physically realised by neuronal dynamics. However, I suspect that your use of the word autonomy wasn't so technical or deflationary.

81
00:12:44,520 --> 00:12:56,520
I think that to be autonomous, first of all, is to be a kind of thing, a particle or person that can act upon the world.

82
00:12:56,520 --> 00:13:20,520
So, I think that, you know, there's a minimal requirement that you have various states that change the states on the outside of you that are external to you, that are extrinsic, that are hidden behind your sensations, your sensory veils that are latent in the sense that you'll never observe them directly.

83
00:13:20,520 --> 00:13:39,520
So, to be autonomous is to be able to move, but there's clearly more to it in the sense that if you're trying to explain your inactive or active engagement with the world in terms of making sense of the world, you're basically describing active inference,

84
00:13:39,520 --> 00:13:58,520
you're describing an evidence gathering machine, you're describing self-evidence as Jacob Howie would express it, another brother-in-arms and a friend of Andy Clarks, and another, I guess he'd probably be very pleased to call himself a cognitive philosopher.

85
00:13:59,520 --> 00:14:20,520
Jacob sort of has not invented but certainly repurposed the notion of self-evidencing as a very succinct and neat way to describe this kind of predictive processing that has this active engagement in active flavour.

86
00:14:20,520 --> 00:14:40,520
For me, that would be active inference, and what is it? Well, it's just basically gathering evidence from my models of the lived world. So, then you say, well, okay, what underwrites this evidence gathering, it's the generative model, it's the model that you are gathering evidence for and you're continually updating that model,

87
00:14:40,520 --> 00:15:05,520
and I mean generative model exactly in the spirit of generative AI, that there is an implicit and possibly sometimes explicit model that you are gathering evidence for, and that model affords the opportunity to generate the kind of content that will be generated or observed under that model,

88
00:15:05,520 --> 00:15:23,520
and hence you can look at generative AI in large language models exactly in that spirit. So, the question now reduces in terms of where does autonomy come from, it really comes from the generative model, where does that come from, what it comes from, probably from your mum and dad,

89
00:15:23,520 --> 00:15:42,520
in two senses, not just your genetic and epigenetic specification, but also the sort of cultural niche construction, the way that you are brought up, so that you have, if you like, a specification of the characteristic states that make you a good son or a good daughter or a good conspecific,

90
00:15:42,520 --> 00:16:04,520
and that now undergird the generative model and then you seek evidence for your model and you learn the particular specialisation, the parameters of your model, by being brought up properly and by being autododactic later on in your, the autonomous sense or sharing the autonomy that comes along with self-evidencing.

91
00:16:04,520 --> 00:16:10,520
They have tried to get autonomy into as many different sentences as possible for you.

