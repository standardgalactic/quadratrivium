WEBVTT

00:00.000 --> 00:01.080
To achieve your highest goals,

00:01.080 --> 00:02.840
you have to be willing to abandon them.

00:02.840 --> 00:04.880
Today, we're publishing the first

00:04.880 --> 00:07.280
in a small series of conversations

00:07.280 --> 00:10.040
with Professor Ken Stanley.

00:10.040 --> 00:13.440
Reading Ken's book, Why Greatness Cannot Be Planned,

00:13.440 --> 00:16.680
was one of the most intellectually awakening moments

00:16.680 --> 00:19.000
of the latter part of my life.

00:19.000 --> 00:21.640
It really turned my thinking upside down,

00:21.640 --> 00:24.680
making me question many deeply held beliefs

00:24.680 --> 00:26.040
which I had previously.

00:27.000 --> 00:28.280
The episode that we did with him

00:28.280 --> 00:30.440
was many months in the making,

00:30.440 --> 00:35.440
and perhaps the greatest ever episode of MLST.

00:35.440 --> 00:37.720
Ken argued in his book that our world

00:37.720 --> 00:41.440
has become saturated with objectives.

00:41.440 --> 00:44.200
The process of setting an objective,

00:44.200 --> 00:46.040
attempting to achieve it,

00:46.040 --> 00:48.440
and measuring progress along the way,

00:48.440 --> 00:52.560
has become the primary route to achievement in our culture.

00:52.560 --> 00:56.040
It's not like he's saying that objectives are bad, per se,

00:56.040 --> 00:57.720
especially if they're modest.

00:57.720 --> 01:00.440
But what he thinks are that when goals are ambitious,

01:00.440 --> 01:05.360
which is to say they are unknowable, complex, or abstract,

01:05.360 --> 01:09.960
or put more simply, that they entail discovery, creativity,

01:09.960 --> 01:13.680
invention, innovation, or happiness,

01:13.680 --> 01:17.040
then the search base becomes deceptive,

01:17.040 --> 01:22.040
which is to say the measure itself becomes a false compass

01:22.120 --> 01:24.200
which blinds us to the stepping stones

01:24.200 --> 01:26.200
which we should actually take.

01:26.200 --> 01:29.520
I mean, is the key to artificial intelligence

01:29.520 --> 01:32.160
really related to intelligence?

01:32.160 --> 01:35.040
Does taking a job with a higher salary

01:35.040 --> 01:38.360
really bring you closer to being a millionaire?

01:38.360 --> 01:40.520
The problem is that the stepping stones

01:40.520 --> 01:42.880
which lead to ambitious objectives

01:42.880 --> 01:45.000
tend to be pretty strange.

01:45.000 --> 01:48.520
They don't resemble the final end state.

01:48.520 --> 01:52.360
Vacuum tubes led to computers, for example,

01:52.360 --> 01:56.560
and YouTube started as a video dating website.

01:56.560 --> 02:01.560
In a sense, creativity itself is actually a search problem.

02:02.040 --> 02:06.560
Is it possible to explore a search space intelligently

02:06.560 --> 02:10.560
without using an objective to align towards discovery

02:10.560 --> 02:14.340
and away from the trap of preconceived results?

02:15.400 --> 02:18.880
Greatness is possible if you're willing to stop demanding

02:18.880 --> 02:21.560
what greatness should be.

02:21.600 --> 02:24.760
The greatest moments and epiphanies in our life

02:24.760 --> 02:28.760
are so often unexpected and unplanned.

02:28.760 --> 02:32.680
Serendipity can play an outsize role in our lives.

02:34.000 --> 02:37.520
At the end of Joel Lemon and Ken Stanley's 2011 paper,

02:37.520 --> 02:39.200
Abandoning Objectives,

02:39.200 --> 02:42.720
they concluded that it was almost like a riddle.

02:42.720 --> 02:46.600
Novelty search suggests a surprising new perspective

02:46.600 --> 02:49.320
on achievement, which is to say,

02:49.320 --> 02:51.520
to achieve your highest goals,

02:51.520 --> 02:53.880
you must be willing to abandon them.

02:54.800 --> 02:57.960
I always get engineers on my team to read this paper

02:57.960 --> 03:01.120
and it's illuminating in so many ways.

03:01.120 --> 03:05.080
I love using the visual analogy of a maze

03:05.080 --> 03:07.800
to represent the search problem of life

03:07.800 --> 03:10.400
and stepping stones in that maze

03:10.400 --> 03:15.080
as being either potential objectives or end states.

03:15.080 --> 03:17.640
Of course, we don't know about the existence

03:17.640 --> 03:20.080
of most of the objectives and the fog of war

03:20.080 --> 03:23.520
blinds us from seeing far ahead into the maze.

03:23.520 --> 03:27.640
The fundamental problem is the missing information problem.

03:27.640 --> 03:29.120
But as we'll soon find out,

03:29.120 --> 03:31.640
not just the information itself,

03:31.640 --> 03:35.000
but how we represent it, understand it,

03:35.000 --> 03:37.600
experience it and even know it.

03:38.640 --> 03:41.880
The fascinating thing is that if we were an oracle

03:41.880 --> 03:45.080
and we knew exactly which steps to take in life,

03:45.080 --> 03:47.680
we could become billionaires within months

03:47.680 --> 03:50.840
or we could achieve anything we wanted to.

03:50.840 --> 03:52.800
The only inconvenient thing stopping us

03:52.800 --> 03:55.080
from realizing our dreams

03:55.080 --> 03:58.680
is that the space of possibilities is exponentially large.

03:58.680 --> 04:01.960
It's very expensive to sample many trajectories

04:01.960 --> 04:04.720
in that space, so we tend to get stuck

04:04.720 --> 04:08.320
in certain sections of the maze for long stretches of time.

04:09.360 --> 04:13.040
Ken thinks that the most valuable commodity in search

04:13.040 --> 04:14.200
is information.

04:15.080 --> 04:18.360
We must accumulate as much of it as possible.

04:18.360 --> 04:21.160
There's an arrow of informational complexity

04:21.160 --> 04:22.840
and natural evolution.

04:22.840 --> 04:25.560
And Ken was the first machine learning researcher

04:25.560 --> 04:30.000
to take seriously the growing yet controversial view

04:30.000 --> 04:32.760
in biology that adaptive selection

04:32.760 --> 04:35.760
does not explain the arrow of complexity in nature.

04:36.680 --> 04:39.080
We're standing in a maze right now.

04:39.080 --> 04:42.000
There are many doors within walking distance

04:42.000 --> 04:45.480
which lead to unthinkable greatness.

04:45.480 --> 04:49.200
We simply haven't walked over and open them.

04:49.200 --> 04:52.960
We are existence proofs of general intelligence.

04:52.960 --> 04:54.960
Every single one of us has a brain,

04:54.960 --> 04:57.000
but just like the infinite number of doors

04:57.000 --> 04:59.320
we could open in the maze of life,

04:59.320 --> 05:02.120
it took evolution billions of years

05:02.120 --> 05:04.640
and gazillions of individual life forms

05:04.640 --> 05:06.720
to create our brains.

05:06.720 --> 05:10.040
Now, Ken is known for his pioneering research

05:10.040 --> 05:12.040
in the open-endedness space.

05:12.040 --> 05:13.640
You might recall the poet paper,

05:13.640 --> 05:16.640
the pairwise open-ended trailblazer.

05:16.640 --> 05:19.760
It was the first ever episode of MLST that we spoke about that,

05:19.760 --> 05:23.720
but that's an example of this line of research.

05:23.720 --> 05:27.640
Open-endedness might seem like a nebulous term,

05:27.640 --> 05:29.520
but you can think of it as being an AI system

05:29.520 --> 05:33.400
which doesn't have a boundary in its state space

05:33.400 --> 05:36.280
and doesn't ever finish accumulating information.

05:40.320 --> 05:43.360
Sir Arthur Stanley Eddington,

05:43.360 --> 05:45.360
the notorious astronomer and physicist

05:45.360 --> 05:47.480
born in the late 19th century,

05:47.480 --> 05:51.120
spoke about the subjectivity in science.

05:51.120 --> 05:54.800
His point is that science only tells us a sliver

05:54.800 --> 05:57.800
of what's really happening in the world around us,

05:57.800 --> 06:00.480
and we should be a lot less arrogant in our claims

06:00.480 --> 06:04.760
to understand it and our attempts to formalize it.

06:04.760 --> 06:06.360
Physics, he argued,

06:06.360 --> 06:09.240
can never reveal the true nature of things,

06:09.280 --> 06:12.760
rather it deals with relations between observables

06:12.760 --> 06:16.880
which are subjectively selected by the human mind.

06:16.880 --> 06:19.720
He says that he was inclined to attribute

06:19.720 --> 06:22.960
the whole responsibility for the laws of mechanics

06:22.960 --> 06:25.320
and gravitation to the mind

06:25.320 --> 06:29.440
and deny the external world any share in them.

06:29.440 --> 06:31.000
He went on to say,

06:31.000 --> 06:34.680
the laws which we have hitherto been unable to fit

06:34.680 --> 06:38.400
into a rational scheme are the true natural laws

06:38.400 --> 06:40.880
inherent in the external world,

06:40.880 --> 06:43.840
and mind has no chance of molding them

06:43.840 --> 06:46.600
in accordance with its own outlook.

06:48.120 --> 06:50.760
Subjectivity is everywhere,

06:50.760 --> 06:53.320
and yet in so many ways we delude ourselves

06:53.320 --> 06:58.200
that we are transforming subjectivity into objectivity.

06:58.200 --> 07:01.600
Imagine a fisherman catching fish in a small ocean.

07:01.600 --> 07:03.600
Depending on the size of his net,

07:03.600 --> 07:07.080
he might reason that there's nothing very small in the ocean

07:07.080 --> 07:09.680
because those objects are slipping through his net.

07:10.720 --> 07:13.040
What we can agree on is that our understanding

07:13.040 --> 07:16.280
of physics breaks if we zoom in too much

07:16.280 --> 07:17.960
or zoom out too much,

07:17.960 --> 07:21.160
so at best we have a frame of reference

07:21.160 --> 07:25.200
which Eddington would argue is observer relative.

07:25.200 --> 07:28.680
Surprisingly little in our world can actually be objectified

07:28.680 --> 07:31.560
without using abstract motifs.

07:31.560 --> 07:32.880
Have you ever asked a philosopher

07:32.880 --> 07:35.840
to define what it means to be real,

07:35.840 --> 07:38.560
or what it means to exist?

07:38.560 --> 07:42.080
I can guarantee you that they'll be reaching.

07:42.080 --> 07:45.200
They'll say things like something exists

07:45.200 --> 07:47.560
if it has a causal effect on the world,

07:47.560 --> 07:50.160
or if it can be measured,

07:50.160 --> 07:52.800
or if it's not illusory,

07:52.800 --> 07:56.200
which is to say it is as it appears,

07:56.200 --> 08:00.600
or perhaps that it's genuine in big air quotes.

08:01.640 --> 08:04.720
What does it mean to be intelligent?

08:04.720 --> 08:06.320
What is life?

08:06.320 --> 08:09.160
Describe an ecosystem.

08:09.160 --> 08:11.360
What is British culture?

08:11.360 --> 08:13.880
Describe your mind.

08:13.880 --> 08:17.280
Describe your conscious experience.

08:17.280 --> 08:18.640
Have you heard of the parable

08:18.640 --> 08:20.720
of the blind men and the elephant?

08:20.720 --> 08:23.440
Any attempt to formalize a complex phenomena

08:23.440 --> 08:26.480
lead to excluding large parts of the truth.

08:26.480 --> 08:28.520
What fascinated me about this conversation

08:28.520 --> 08:29.600
with Ken this evening

08:29.600 --> 08:32.920
is I got a much deeper understanding of his philosophy.

08:32.920 --> 08:34.760
He led by saying that he thought

08:34.760 --> 08:36.160
it's worth questioning

08:36.160 --> 08:37.600
whether artificial intelligence

08:37.600 --> 08:40.280
is even a science or not.

08:40.280 --> 08:43.480
Just let that sink in for a moment.

08:43.480 --> 08:46.160
I'd been too focused on my mental framework

08:46.160 --> 08:50.320
of objectives, behavior, and actions.

08:50.320 --> 08:52.240
The broader story is that Ken thinks

08:52.240 --> 08:54.600
society and institutions

08:54.600 --> 08:57.840
are scared of any subjectivity.

08:57.840 --> 09:00.360
Subjectivity in general.

09:00.360 --> 09:03.200
He thinks that attempts to formalize complex,

09:03.200 --> 09:05.840
emergent, and integrative phenomena

09:05.840 --> 09:09.840
like intelligence, consciousness, life, society,

09:09.840 --> 09:12.240
the mind, or anything else for that matter,

09:12.240 --> 09:14.800
only deludes us and blocks us

09:14.800 --> 09:18.760
from potentially discovering a deeper reality later.

09:18.760 --> 09:21.200
It's a very human trait to seek to understand

09:21.200 --> 09:22.280
the world around us

09:22.280 --> 09:24.640
to varying degrees of self-delusion.

09:24.640 --> 09:26.960
Before we understand a particular phenomena,

09:26.960 --> 09:28.960
it's almost impossible to come up

09:28.960 --> 09:32.280
with a good scientific and formal definition.

09:32.280 --> 09:34.080
How could we possibly define something

09:34.080 --> 09:36.000
which we don't understand well?

09:36.000 --> 09:39.320
This is the paradox in computer science and philosophy.

09:39.320 --> 09:40.920
The more we seek something,

09:40.920 --> 09:42.920
the more it eludes us.

09:44.000 --> 09:46.440
It sounds almost anti-intellectual, doesn't it?

09:46.440 --> 09:50.080
This idea that we should reject formalization.

09:50.080 --> 09:52.440
But Ken thinks that many phenomena

09:52.440 --> 09:55.920
will only be trivialized by vacant attempts

09:56.000 --> 09:59.680
to formalize them through oversimplification.

09:59.680 --> 10:02.920
Because inevitably, we'll chop off many aspects

10:02.920 --> 10:05.720
which might not be captured by the formalization.

10:05.720 --> 10:08.000
I had always associated Ken's philosophy

10:08.000 --> 10:10.960
with the missing information problem

10:10.960 --> 10:14.080
rather than the representation problem.

10:14.080 --> 10:15.440
The missing information problem

10:15.440 --> 10:17.480
is that we don't know something

10:17.480 --> 10:20.400
or we only know part of the truth.

10:20.400 --> 10:23.760
The representation problem is that we simply don't understand

10:23.760 --> 10:27.480
or at least we can't verbalize what we're experiencing.

10:27.480 --> 10:30.080
Ken says that the corporate world is dominated

10:30.080 --> 10:34.360
by the attempted veneer of objectivity.

10:34.360 --> 10:37.600
If you're trying to land an engineering role in Fang,

10:37.600 --> 10:42.080
your tolerance for ambiguity and subjectivity

10:42.080 --> 10:43.960
is the single most selective feature

10:43.960 --> 10:46.760
of the level which you get hired at.

10:46.760 --> 10:50.720
If you can solve clearly defined problems, you're a level four.

10:50.720 --> 10:52.880
If you can find the problems,

10:52.880 --> 10:54.640
you're a level six.

10:54.640 --> 10:58.800
If you can find the areas, you're a level seven.

10:58.800 --> 11:02.320
And if you can find people who can find the areas,

11:02.320 --> 11:05.400
you're a level eight or a level nine.

11:05.400 --> 11:08.520
I give loads of open-ended tasks to my team,

11:08.520 --> 11:10.360
discover people in the organization

11:10.360 --> 11:13.560
who are subject matter experts in domain X,

11:13.560 --> 11:15.880
build an operating model for knowledge sharing

11:15.880 --> 11:18.160
and standardization.

11:18.160 --> 11:20.320
What does good look like?

11:20.320 --> 11:22.560
It's possible we don't know it yet,

11:22.560 --> 11:24.640
which is the missing information problem.

11:24.640 --> 11:27.920
But it's also possible that we know it,

11:27.920 --> 11:30.040
but we're not able to verbalize it,

11:30.040 --> 11:31.920
which is the representation problem,

11:31.920 --> 11:35.080
inherent with all complex phenomena.

11:35.080 --> 11:36.080
It's quite interesting, actually.

11:36.080 --> 11:38.800
I'm building a code review platform called Merge.

11:38.800 --> 11:41.840
And it's easy to objectify all of the low-level metrics

11:41.840 --> 11:44.920
such as how many customer engineers we support

11:44.920 --> 11:47.560
or how efficiently we're sharing knowledge.

11:47.560 --> 11:49.000
All of the high-level outcomes

11:49.000 --> 11:51.760
like a better engineering culture.

11:51.760 --> 11:54.000
They're emergent properties, right?

11:54.000 --> 11:55.400
It's a bit like pornography.

11:55.400 --> 11:56.800
You know it when you see it.

11:58.960 --> 12:03.160
So now, I give you Professor Ken Stanley.

12:03.160 --> 12:04.800
We have a nose for the interesting.

12:04.800 --> 12:05.960
That's how we got this far.

12:05.960 --> 12:08.040
That's how civilization came out.

12:08.040 --> 12:11.000
That's why the history of innovation is so amazing.

12:11.000 --> 12:14.040
Everything washes out when we start ruling by committee.

12:14.040 --> 12:15.480
Like, we have to allow people

12:15.480 --> 12:17.480
to follow their passions to their extremes.

12:17.480 --> 12:20.480
And yet we run society as if this actually

12:20.480 --> 12:22.320
makes any sense at all.

12:22.320 --> 12:24.760
I think the gradient of interestingness

12:24.760 --> 12:26.760
is probably the best expression

12:26.760 --> 12:29.320
of the ideal divergent search.

12:29.320 --> 12:30.440
You get to this problem that, like,

12:30.440 --> 12:32.600
I don't know how to formalize interestingness,

12:32.600 --> 12:35.480
which you get to then are proxies for interestingness.

12:35.480 --> 12:37.680
That not everything that's novel is interesting,

12:37.680 --> 12:40.320
but just about everything that's interesting is novel.

12:40.320 --> 12:42.720
It is in my personality and nature

12:42.720 --> 12:45.600
to want to overthrow this,

12:45.600 --> 12:47.840
I guess we could say, tyranny of objectives.

12:51.480 --> 12:58.480
So today, we have an incredibly special guest.

12:58.480 --> 13:02.480
Indeed, my hero in AI, Professor Kenneth Stanley.

13:02.480 --> 13:04.920
Now, the Kenneth Stanley show that we filmed,

13:04.920 --> 13:07.320
which is to say episode 38,

13:07.320 --> 13:10.120
was my favorite episode that we've ever done.

13:10.120 --> 13:11.160
Reading Kenneth's book,

13:11.160 --> 13:12.480
Why Greatness Cannot Be Planned,

13:12.480 --> 13:13.760
and preparing for that show,

13:13.760 --> 13:17.160
triggered an incredible amount of intellectual growth for me.

13:17.160 --> 13:18.560
And a hallmark of that, you know,

13:18.560 --> 13:20.360
when you learn something profound,

13:20.440 --> 13:22.200
is that you start recognizing it

13:22.200 --> 13:23.760
in many other domains of your life.

13:23.760 --> 13:25.840
I mean, you remember when you learned probability theory

13:25.840 --> 13:26.760
for the first time,

13:26.760 --> 13:29.320
and you started seeing exponential distributions

13:29.320 --> 13:31.000
absolutely everywhere.

13:31.000 --> 13:32.720
So I was just saying to Kenneth

13:32.720 --> 13:35.120
that when we listened back to the show last night,

13:35.120 --> 13:37.360
it was probably the best example ever of a show

13:37.360 --> 13:38.640
we overprepared for,

13:38.640 --> 13:40.560
which is to say that during the interview,

13:40.560 --> 13:42.120
we were just bamboozling Kenneth.

13:42.120 --> 13:43.160
We were so excited,

13:43.160 --> 13:44.920
we almost couldn't control ourselves.

13:44.920 --> 13:46.840
And I think in particular,

13:46.840 --> 13:49.400
Keith and Kenneth reached a common ground, actually,

13:49.400 --> 13:51.680
in the sense that divergence and convergence

13:51.680 --> 13:53.400
don't have to be hyperbolic

13:53.400 --> 13:55.520
or entirely mutually exclusive.

13:55.520 --> 13:58.800
Now, Kenneth thinks that we have a nose for the interesting.

13:58.800 --> 14:00.480
That's how we got this far.

14:00.480 --> 14:02.760
It's the basis of all innovation

14:02.760 --> 14:05.000
and the secret of our society.

14:05.000 --> 14:08.640
Kenneth believes that the concept of deception in search,

14:08.640 --> 14:10.960
which is to say getting stuck in local optimans

14:10.960 --> 14:12.840
and indeed deluding ourselves

14:12.840 --> 14:15.560
that we even know what good looks like in the first place,

14:15.560 --> 14:18.680
is what regularly sends us into brick walls.

14:18.680 --> 14:22.320
Kenneth thinks that institutions are full of gatekeepers

14:22.320 --> 14:24.480
and the gatekeepers only want to see your objectives

14:24.480 --> 14:25.600
and metrics.

14:25.600 --> 14:29.400
Any expert on search would know that it's completely naive

14:29.400 --> 14:31.200
and yet we still use this approach

14:31.200 --> 14:33.600
for the most complex problems in our society.

14:33.600 --> 14:35.320
Committees wash out everything.

14:35.320 --> 14:38.240
We need to let people follow their interests to the extremes

14:38.240 --> 14:39.800
and risk has to be tolerated

14:39.800 --> 14:41.880
in order to make the greatest discoveries.

14:41.880 --> 14:43.640
Anyway, Professor Kenneth Stanley,

14:43.640 --> 14:46.400
it's an absolute honor to have you back on the show.

14:46.440 --> 14:48.160
Thank you for having me here.

14:48.160 --> 14:49.000
So it's been great.

14:49.000 --> 14:51.840
I really enjoyed being on it and I'm glad to be back here.

14:51.840 --> 14:54.160
I mean, even the thing you made in front of that show

14:54.160 --> 14:55.000
was awesome.

14:55.000 --> 14:57.640
That was, I showed that to my son and he was like,

14:57.640 --> 14:58.760
what the heck is that?

14:58.760 --> 15:00.280
He's like, that's not my dad.

15:00.280 --> 15:01.520
And I was like, that is, he's like,

15:01.520 --> 15:04.280
you've never seen me in that kind of environment,

15:04.280 --> 15:05.440
but it was pretty cool.

15:06.480 --> 15:09.120
Oh yeah, so we painted a cafe in behind you,

15:09.120 --> 15:11.600
but we did that first thing in Blender.

15:11.600 --> 15:13.240
But I had to learn Blender just for that.

15:13.240 --> 15:14.920
It was the first thing I ever did.

15:14.920 --> 15:16.680
And what I started doing afterwards,

15:16.680 --> 15:19.040
I wished that we did your show a tiny bit later.

15:19.040 --> 15:21.360
I started using my virtual reality headset.

15:21.360 --> 15:25.560
So I've got an Oculus Quest and then I use Google tilt brush

15:25.560 --> 15:28.040
and then I can kind of create a beautiful 3D environment.

15:28.040 --> 15:30.520
I can put slides and videos and all kinds of stuff up there.

15:30.520 --> 15:31.760
And that would have been perfect for that

15:31.760 --> 15:33.560
because I wanted to show all of the stepping stones

15:33.560 --> 15:36.840
in the divergent search in a 3D environment.

15:36.840 --> 15:39.560
But that's a cool thing is we're getting more sophisticated

15:39.560 --> 15:40.840
and we're starting to use, you know,

15:40.840 --> 15:42.400
manum to do animations

15:42.400 --> 15:44.480
because we want to be able to really kind of,

15:44.480 --> 15:45.920
at least for some of the episodes,

15:45.920 --> 15:49.600
tell the story in a very visual and educational way.

15:49.600 --> 15:51.520
So we're kind of going back now and revisiting

15:51.520 --> 15:54.360
some of our favorite, you know, favorite episodes

15:54.360 --> 15:56.040
and can we tell parts of it again

15:56.040 --> 15:58.800
with this new technology, if you will,

15:58.800 --> 16:00.960
or new techniques that we have skills at.

16:00.960 --> 16:02.520
That's cool, yeah.

16:02.520 --> 16:04.800
I got to tell you, just on a personal note,

16:04.800 --> 16:06.360
because you mentioned, you know, your son saying,

16:06.360 --> 16:09.200
that's not my dad, part of my motivation

16:09.200 --> 16:12.560
for doing these YouTube, you know, shows

16:12.600 --> 16:14.720
is that I want there to be something

16:14.720 --> 16:17.160
where my kids can go maybe when I'm gone or whatever

16:17.160 --> 16:19.040
and look back and say, oh yeah, that was my dad.

16:19.040 --> 16:20.080
That's what he sounded like.

16:20.080 --> 16:21.040
That's what he looked like.

16:21.040 --> 16:22.960
You know, that's how we talk.

16:22.960 --> 16:24.320
It's a really nice thing.

16:24.320 --> 16:25.400
Yeah.

16:25.400 --> 16:26.240
Yeah, yeah.

16:26.240 --> 16:27.160
The problem is no one understands

16:27.160 --> 16:28.120
what we're talking about.

16:28.120 --> 16:28.960
Well, maybe they will.

16:28.960 --> 16:30.160
One of my friends and family,

16:30.160 --> 16:32.160
they say, oh, I tried to watch it,

16:32.160 --> 16:34.960
but I just couldn't understand what you were talking about.

16:34.960 --> 16:37.200
It's so funny because from my perspective,

16:37.200 --> 16:39.960
we're really making things accessible

16:39.960 --> 16:41.440
and dumbing things down as much as possible.

16:41.840 --> 16:44.000
And I still think of myself as completely clueless,

16:44.000 --> 16:45.640
but it's quite deceptive, isn't it,

16:45.640 --> 16:47.800
that you don't realize you're talking another language.

16:47.800 --> 16:48.640
Yeah, it's funny.

16:48.640 --> 16:51.200
I mean, my mom, I said, here's this video,

16:51.200 --> 16:52.800
and she has no idea what this is,

16:52.800 --> 16:55.200
and but she showed her sister who's like eight years old

16:55.200 --> 16:56.800
and didn't know anything.

16:56.800 --> 16:59.600
And her sister was just like, you know,

16:59.600 --> 17:01.560
it seemed like you were really winning in that discussion,

17:01.560 --> 17:03.840
even though I have no idea what you're talking about.

17:03.840 --> 17:04.680
That's cool.

17:04.680 --> 17:05.520
Well, that's good.

17:05.520 --> 17:07.800
I mean, at least the tone sounded like I'm winning.

17:08.760 --> 17:10.120
Well, yeah, it's kind of funny.

17:10.120 --> 17:11.600
Well, speaking of winning,

17:11.600 --> 17:14.560
and that's kind of the question I wanted to ask you is that,

17:14.560 --> 17:16.040
you know, it's one of those ideas,

17:16.040 --> 17:17.560
Tim mentioned these kind of ideas

17:17.560 --> 17:19.840
that the first time you hear them,

17:19.840 --> 17:21.680
and after you kind of digested them a bit,

17:21.680 --> 17:23.320
then you start seeing them everywhere,

17:23.320 --> 17:25.560
and you start seeing, you know, connections,

17:25.560 --> 17:26.680
connections to it everywhere.

17:26.680 --> 17:29.880
And I think your ideas are like that.

17:29.880 --> 17:31.480
At least they were for me.

17:31.480 --> 17:34.760
And I started come to this line of thinking

17:34.760 --> 17:35.960
that I just wanted to ask you about,

17:35.960 --> 17:37.800
just to see if it's completely off base,

17:37.800 --> 17:40.280
or if there's any, maybe any kind of truth to it,

17:40.280 --> 17:43.360
which is, and I know I keep repeating this, Tim,

17:43.360 --> 17:44.200
and I apologize,

17:44.200 --> 17:47.120
but one of the most beautiful quotes I ever heard

17:47.120 --> 17:50.520
was from Claude Shannon many decades ago.

17:50.520 --> 17:53.760
I heard this, and he said, you know,

17:53.760 --> 17:58.280
we have knowledge of the past, but we cannot change it.

17:58.280 --> 18:02.360
We have no knowledge of the future, but we control it.

18:02.360 --> 18:05.080
And I realized back then that there's this duality,

18:05.080 --> 18:07.760
and it's reflected there in that asymmetry of time,

18:07.760 --> 18:11.280
but also in the way I think about science and engineering.

18:11.280 --> 18:13.720
So there are the two sides of a coin

18:13.720 --> 18:18.080
where scientists use engineering to control

18:18.080 --> 18:20.640
in order to gain new knowledge.

18:20.640 --> 18:23.240
Whereas engineers take the knowledge that we have,

18:23.240 --> 18:25.200
and they use it to gain control, you know,

18:25.200 --> 18:26.960
by building a better building,

18:26.960 --> 18:29.200
crossing a water stream or whatever.

18:29.200 --> 18:31.200
And it's also similar to the exploration

18:31.200 --> 18:34.480
versus exploitation, you know, trade-off.

18:34.480 --> 18:37.120
And I'm coming around to this way of thinking that,

18:37.120 --> 18:41.080
yeah, you know, objectives can be quite harmful

18:41.080 --> 18:44.280
when you're in that exploration, you know, phase,

18:44.280 --> 18:45.720
trying to learn new knowledge,

18:45.720 --> 18:47.640
because just as you point out,

18:47.640 --> 18:50.480
who knows what the stepping stones are gonna be like?

18:50.480 --> 18:51.560
And all the kind of, let's say,

18:51.560 --> 18:53.080
quote-unquote counter examples

18:53.080 --> 18:54.240
that I were thinking of before,

18:54.240 --> 18:56.760
it's because they fall more in the engineering side of things,

18:56.760 --> 18:59.040
which is, okay, look, we have some knowledge,

18:59.040 --> 19:00.840
and we do have a very specific goal

19:00.840 --> 19:02.840
we're trying to do with that knowledge,

19:02.840 --> 19:05.240
you know, build a faster rocket or whatever.

19:05.240 --> 19:07.480
And so, yeah, we just go down this kind of very

19:07.480 --> 19:09.960
refinement, objective-based kind of goal,

19:09.960 --> 19:11.960
but it's really not gonna lead us necessarily

19:11.960 --> 19:14.840
to new knowledge or new insight.

19:14.840 --> 19:17.780
Is this kind of a fair dichotomy or not?

19:18.880 --> 19:21.320
Yeah, I mean, you know, it's nice to keep to hear you're

19:21.320 --> 19:23.640
coming around to that way of thinking somewhat.

19:23.640 --> 19:25.640
It's like a while, isn't it?

19:25.640 --> 19:26.800
Hey, I'm open-minded.

19:28.120 --> 19:33.000
It's, yeah, it's interesting to connect to Shannon.

19:33.040 --> 19:35.320
That I appreciate and is an interesting connection.

19:35.320 --> 19:39.840
And I think the dichotomy is pretty fair,

19:39.840 --> 19:43.880
that like in search of discovery,

19:43.880 --> 19:45.720
yeah, a lot of engineering principles

19:45.720 --> 19:50.720
are not really the best tools for innovation necessarily,

19:51.200 --> 19:53.820
especially basic, like basic exploration.

19:55.120 --> 19:59.400
And it's true also that it seems like engineering

19:59.400 --> 20:02.400
culturally kind of pervades scientific education,

20:02.440 --> 20:03.440
at least in some sciences.

20:03.440 --> 20:06.120
I don't know, like I only know about my own experience

20:06.120 --> 20:08.600
in computer science, but like I was in

20:08.600 --> 20:10.960
computer science engineering major at U Penn

20:10.960 --> 20:14.520
that was like computer science engineering is like one thing.

20:14.520 --> 20:17.120
And so, yeah, a lot of engineering philosophy

20:17.120 --> 20:19.000
is like stuck in with the science.

20:19.880 --> 20:24.880
And maybe there is like some conflation there,

20:26.560 --> 20:29.520
but I also think like another thing to consider,

20:29.520 --> 20:31.440
which might be a little bit more out there,

20:31.440 --> 20:35.720
and controversial is that I think it's worth

20:35.720 --> 20:38.200
questioning whether artificial intelligence

20:38.200 --> 20:39.840
really is only science.

20:41.040 --> 20:43.200
And is that actually what we're doing?

20:43.200 --> 20:48.200
Like a lot of the discussion about AI will come back to,

20:49.680 --> 20:50.880
you know, that's not scientific,

20:50.880 --> 20:53.800
or does it kind of attack or a way of looking at like

20:53.800 --> 20:57.640
an idea where like we can sort of invoke science

20:57.640 --> 21:00.240
and slavery to put something down.

21:01.160 --> 21:03.440
And, you know, one interpretation is just that,

21:04.360 --> 21:07.680
you know, maybe there, it was a good scientific insight,

21:07.680 --> 21:09.560
but somebody just missed it or something.

21:09.560 --> 21:11.040
They're not seeing the big picture.

21:11.040 --> 21:12.520
But another interpretation is that actually

21:12.520 --> 21:15.480
this is not science, and it shouldn't be,

21:15.480 --> 21:18.240
it shouldn't be caged inside of that,

21:18.240 --> 21:19.640
only that way of thinking.

21:21.160 --> 21:23.400
And I've actually written about this,

21:23.400 --> 21:25.720
was much less received, much less attention

21:25.720 --> 21:27.600
when I wrote about it, but I thought a lot about it.

21:27.680 --> 21:29.960
Like that in some ways I think AI is,

21:29.960 --> 21:32.200
has a lot of connection to art.

21:32.200 --> 21:33.800
And I don't mean just in the sense that like

21:33.800 --> 21:35.120
you can use AI to generate art.

21:35.120 --> 21:36.960
I mean, you can do that, obviously.

21:36.960 --> 21:38.520
But I mean, in the sense that like,

21:38.520 --> 21:43.040
art is about the reproduction often, not always,

21:43.040 --> 21:45.800
but often it's about the reproduction of natural artifacts

21:45.800 --> 21:47.120
in an artificial way.

21:47.120 --> 21:48.880
Like, I mean, when you paint a picture

21:48.880 --> 21:51.440
of like an apple or something, like a still life,

21:51.440 --> 21:54.080
and nobody's expecting it to be a real apple.

21:54.080 --> 21:55.800
Like that's not the question.

21:55.800 --> 21:58.400
And nobody even expects there's necessarily

21:58.400 --> 22:00.240
a faithful reproduction of an apple.

22:00.240 --> 22:02.560
Or let's say like, you know, Van Gogh's Starry Night,

22:02.560 --> 22:04.840
it doesn't look anything like a real Starry Night

22:04.840 --> 22:06.720
that I bet anybody on earth has ever seen,

22:06.720 --> 22:08.800
even if they're on drugs.

22:08.800 --> 22:10.720
And yet, what does it do?

22:10.720 --> 22:12.560
What is the value of Starry Night then?

22:12.560 --> 22:14.160
Since it's not accurate.

22:14.160 --> 22:16.960
Scientifically, it's not a very good job.

22:16.960 --> 22:19.120
Well, it actually gives you new insight

22:19.120 --> 22:20.680
into something about Starry Night

22:20.680 --> 22:22.320
that you hadn't really thought about.

22:22.320 --> 22:24.240
And that's what's thrilling about it,

22:24.240 --> 22:26.000
is that like it gives you a new perspective

22:26.000 --> 22:28.240
on something that you're familiar with.

22:28.240 --> 22:30.360
AI is also concerned with the reproduction

22:30.360 --> 22:33.040
of natural phenomena in artifice.

22:33.040 --> 22:34.320
It's the same thing.

22:34.320 --> 22:37.840
And in a similar way, like an algorithm is,

22:37.840 --> 22:39.640
I think it's just another way,

22:39.640 --> 22:42.560
it's kind of like another painting.

22:42.560 --> 22:44.520
It's just a painting that's expressed

22:44.520 --> 22:45.880
rather than through brush strokes,

22:45.880 --> 22:47.920
it's expressed through code.

22:47.920 --> 22:49.200
But if you look at it that way,

22:49.200 --> 22:51.120
you can understand that like,

22:51.120 --> 22:53.000
it can be an interpretation of nature

22:53.000 --> 22:54.440
without being accurate.

22:54.440 --> 22:56.040
And that can still be valuable

22:56.040 --> 22:58.120
just as Starry Night is valuable.

22:58.120 --> 23:00.600
And the reason it can be valuable back to science

23:00.600 --> 23:02.160
is because some of the thoughts it gives you

23:02.160 --> 23:03.160
will be stepping stones

23:03.160 --> 23:05.400
that then lead back to scientific insights.

23:05.400 --> 23:07.960
So we're straddling between science and art here.

23:07.960 --> 23:08.800
But the thing is,

23:08.800 --> 23:11.320
it's not necessarily a harmful thing to do.

23:11.320 --> 23:15.120
And so we should actually consider whether,

23:15.120 --> 23:17.200
like to the extent that an algorithm actually

23:17.200 --> 23:18.560
is an artistic inspiration,

23:18.560 --> 23:20.920
which I think a lot of what I was doing was,

23:20.920 --> 23:22.640
like when I was building things like Neat,

23:22.640 --> 23:24.040
I was inspired by like,

23:24.040 --> 23:26.040
the increases in complexity in nature.

23:26.040 --> 23:27.640
I was never under the delusion

23:27.640 --> 23:29.560
that Neat is an accurate depiction

23:29.560 --> 23:31.640
of how evolution works in nature.

23:31.640 --> 23:33.560
But it's kind of an ode to nature in a way,

23:33.560 --> 23:35.480
like the way a painting might be.

23:35.480 --> 23:38.000
But it's never discussed in that way.

23:38.000 --> 23:40.960
You said in your presentation last time

23:40.960 --> 23:44.720
that you were becoming a little bit more radicalized

23:44.720 --> 23:47.240
because you were doing it to not computer scientists,

23:47.240 --> 23:50.080
artists, and all of a sudden they were saying to you,

23:50.080 --> 23:51.480
oh my God, Kenneth, like,

23:51.480 --> 23:53.000
finally, my parents keep saying to me,

23:53.000 --> 23:53.920
why are you doing art?

23:53.920 --> 23:55.200
Why are you wasting your time?

23:55.200 --> 23:56.400
And now I understand,

23:56.400 --> 23:57.880
now I actually have a sense of purpose,

23:57.880 --> 23:59.200
it means something.

23:59.200 --> 24:00.680
And I think what you were saying a second ago,

24:00.680 --> 24:01.680
because it's quite interesting you said,

24:01.680 --> 24:02.880
or a starry night.

24:02.880 --> 24:05.400
And you could say that's a kind of model

24:05.400 --> 24:06.680
or a kind of representation.

24:06.680 --> 24:09.000
But is it fair to say that you're actually more interested

24:09.000 --> 24:12.120
in analogizing the process itself?

24:12.120 --> 24:15.760
Like analogizing the process of discovery in AI with art.

24:15.760 --> 24:17.160
Is that what you mean?

24:17.160 --> 24:18.000
Yeah.

24:18.000 --> 24:19.800
I think there's an analogy between art and AI.

24:19.800 --> 24:21.040
It's more than just process.

24:21.040 --> 24:22.800
It's like, it is a branch of art.

24:22.800 --> 24:26.720
Like it's literally about like reproducing natural phenomena

24:26.720 --> 24:28.800
in artifice, which is what artists do.

24:29.880 --> 24:31.880
The difference is that the,

24:33.400 --> 24:36.440
the, I mean, art is, you know, you might say it's like,

24:36.440 --> 24:37.800
there's more of an aesthetic emphasis

24:37.800 --> 24:41.040
or something in art, but I mean, that's just a choice.

24:41.040 --> 24:43.520
I mean, that's what we're doing in AI.

24:43.520 --> 24:44.720
We're interested in,

24:44.720 --> 24:46.640
so one exception I should say for the artists

24:46.640 --> 24:49.160
who are listening, which are probably few,

24:49.360 --> 24:51.320
but I want to acknowledge that that's not the only thing

24:51.320 --> 24:52.520
that art is concerned with.

24:52.520 --> 24:54.200
When I wrote about this, I actually,

24:54.200 --> 24:55.320
I wrote a paper on this.

24:55.320 --> 24:57.560
It was one of the weirdest things I did

24:57.560 --> 24:59.600
because I actually went to like a real library

24:59.600 --> 25:01.560
and was researching art history and things like that.

25:01.560 --> 25:04.640
I felt like a real like scholar or something in the library.

25:04.640 --> 25:07.920
But so I got a lot of, I got some criticism from artists.

25:07.920 --> 25:09.400
And like one of the things they were pointing out was that

25:09.400 --> 25:11.120
it's not always about the reproduction of nature.

25:11.120 --> 25:13.360
Like there's some modern art that has nothing to do

25:13.360 --> 25:14.400
with reproducing anything.

25:14.400 --> 25:16.160
It's just about like the pure aesthetics.

25:16.160 --> 25:18.960
So let's just acknowledge that that's not all art is about.

25:18.960 --> 25:22.240
But much of art throughout art history has been about that.

25:22.240 --> 25:24.560
It's certainly a part of art is to reproduce

25:24.560 --> 25:25.920
natural phenomena and artifice.

25:25.920 --> 25:27.800
And that's what art AI is.

25:27.800 --> 25:29.120
So it's not just a connection.

25:29.120 --> 25:30.640
I think it is art.

25:30.640 --> 25:32.560
It's just that we're not willing to discuss that side of it

25:32.560 --> 25:35.400
because we're very proud of ourselves for being scientists.

25:35.400 --> 25:37.120
It makes us feel good about ourselves.

25:37.120 --> 25:38.800
But the reason I started thinking about this

25:38.800 --> 25:42.200
is because I was getting in some arguments with people

25:42.200 --> 25:45.360
where the kind of the crux, the breaking point

25:45.360 --> 25:46.840
where they tried to basically stop it

25:46.840 --> 25:48.600
and say this is the end of the argument

25:48.600 --> 25:52.600
was basically to say that what I was saying was not scientific.

25:52.600 --> 25:54.160
Or like this is not a scientific question.

25:54.160 --> 25:56.640
It can't be objectively analyzed.

25:56.640 --> 25:58.080
You can't get an objective,

25:58.080 --> 26:00.560
you can't get falsification on this question.

26:00.560 --> 26:02.400
So it's basically not subject to debate.

26:02.400 --> 26:04.640
Like let's not talk about it because it's pointless.

26:04.640 --> 26:06.800
And I felt like that is just pure cowardice.

26:06.800 --> 26:10.160
Like we are, you are just saying you are afraid to inquire

26:10.160 --> 26:12.920
in directions where you don't know how to falsify.

26:12.920 --> 26:14.360
To me that's just cowardice.

26:14.360 --> 26:17.160
And I do not like associating science with cowardice.

26:17.160 --> 26:21.320
And I started thinking about, am I really doing science?

26:21.320 --> 26:23.320
Like maybe there's another few here.

26:23.320 --> 26:25.680
I don't know that I was like fully just trying

26:25.680 --> 26:30.160
to create generate hypotheses and validate or falsify them.

26:30.160 --> 26:33.560
There's an artistic side to I think creating these algorithms.

26:33.560 --> 26:35.520
And I think it might be healthy to acknowledge that.

26:35.520 --> 26:37.480
It's interesting to think about.

26:37.480 --> 26:41.440
I think your frame of reference doesn't seem to fit

26:41.440 --> 26:43.400
into the paradigm of science in so many ways.

26:43.400 --> 26:45.280
And I remember you said on the show last time

26:45.280 --> 26:48.720
that you were exasperated that pickbreeder was not recognized

26:48.720 --> 26:50.560
as being scientifically useful.

26:50.560 --> 26:54.160
And there was another convergent committee version

26:54.160 --> 26:56.080
of pickbreeder and then the images just looked

26:56.080 --> 26:57.840
like wallpaper backgrounds.

26:57.840 --> 27:01.560
But to your point before, I kind of agree with you

27:01.560 --> 27:05.080
that when you look at what happens in the process of art,

27:05.080 --> 27:07.160
it seems very intelligent.

27:07.160 --> 27:10.560
But I'm trying to understand where the intelligence lies.

27:10.560 --> 27:13.880
Because I'm interested in the idea of it being embodied,

27:13.880 --> 27:16.760
for example, and an emergent phenomenon.

27:16.760 --> 27:20.000
So clearly when human beings collaborate together

27:20.000 --> 27:22.680
in this divergent way, that's something very interesting.

27:22.680 --> 27:26.800
But what would happen if the agents producing the art

27:26.800 --> 27:30.000
were much less intelligent than humans?

27:30.000 --> 27:34.280
Do you think that could still lead to a kind of intelligence

27:34.280 --> 27:35.880
at a larger scale?

27:36.960 --> 27:39.840
Yeah, and I just will also like preface

27:39.840 --> 27:42.040
by just saying that I'm not against science.

27:42.160 --> 27:44.160
I do like being associated with science.

27:44.160 --> 27:46.440
I don't want to be the out-characterized as an artist

27:46.440 --> 27:47.720
only.

27:47.720 --> 27:50.200
I just think that we're straddling both here.

27:50.200 --> 27:52.800
And the mechanisms of science clearly

27:52.800 --> 27:54.200
have served us well in many cases.

27:54.200 --> 27:56.560
So I don't want to be associated with kooky views

27:56.560 --> 27:59.000
that we should get rid of science or something like that.

27:59.000 --> 28:00.480
I just think it expands our horizons

28:00.480 --> 28:03.720
to understand what we're doing and how it relates to art.

28:03.720 --> 28:06.240
And also just before to answer the question,

28:06.240 --> 28:07.680
I think it's also important to note

28:07.680 --> 28:09.520
that I'm not just making the generic point

28:09.520 --> 28:12.560
that there's an aesthetic aspect to science, which

28:12.560 --> 28:14.600
people have written entire books about.

28:14.600 --> 28:16.680
People have pointed out before, not me,

28:16.680 --> 28:18.840
but there's famous books that have

28:18.840 --> 28:23.360
been written about how science has an artistic side,

28:23.360 --> 28:26.120
like an artistic inclination can help you as a scientist.

28:26.120 --> 28:29.120
I mean, this is not new to point these things out.

28:29.120 --> 28:31.160
But I'm trying to make a much more literal point

28:31.160 --> 28:34.680
that AI itself, specifically AI, with the word artificial

28:34.680 --> 28:38.920
in front of it, is really about art in a strong way.

28:38.960 --> 28:41.400
And this is what has not been acknowledged.

28:41.400 --> 28:43.600
This point has also come up in mathematics.

28:43.600 --> 28:46.440
And for the life of me, I can't think of whether it was

28:46.440 --> 28:48.720
Penrose or maybe even Gauss or somebody,

28:48.720 --> 28:51.920
but a legendary mathematician made this point.

28:51.920 --> 28:54.200
They were bemoaning the fact that there wasn't

28:54.200 --> 28:57.120
more creativity in mathematics.

28:57.120 --> 28:59.920
Because if you look at some of the greatest achievements

28:59.920 --> 29:02.520
of mathematics, they were these things that were created

29:02.520 --> 29:08.800
that were entirely new, like calculus from Leibniz

29:09.480 --> 29:10.320
or Newton, right?

29:10.320 --> 29:12.800
I mean, just these new creations, new ways of thinking

29:12.800 --> 29:15.240
about things that were really inspired

29:15.240 --> 29:17.320
from a more artistic sense.

29:17.320 --> 29:20.080
And he was making the same point that like,

29:20.080 --> 29:21.320
that's mathematics.

29:21.320 --> 29:23.040
And to kind of say like, well, no,

29:23.040 --> 29:26.080
if it doesn't have a certain level of rigor,

29:26.080 --> 29:27.400
it doesn't approach mathematics.

29:27.400 --> 29:30.440
Well, in order to get to those forms of rigor,

29:30.440 --> 29:32.280
you first have to have that stepping stone,

29:32.280 --> 29:36.600
that inspiration that generates something brand new.

29:36.600 --> 29:38.640
And I gotta figure this out,

29:38.640 --> 29:41.160
but I forget who it was and they made this point.

29:41.160 --> 29:44.000
So if it applies even to mathematics,

29:44.000 --> 29:45.720
it has to apply also to things

29:45.720 --> 29:47.760
that are more grounded in reality.

29:47.760 --> 29:50.200
So I think your point completely stands.

29:50.200 --> 29:55.200
And it is sad that people tried to dismiss it as,

29:55.760 --> 29:58.480
well, that's not science or that's not mathematics.

30:00.920 --> 30:02.200
There's an interesting response.

30:02.200 --> 30:03.680
There's a good, it's not science.

30:03.680 --> 30:05.720
Like, I wonder where that leads exactly.

30:05.720 --> 30:07.880
It's like, I'm not pretending to be talking about science.

30:07.880 --> 30:09.280
Like, it's still so we should discuss.

30:09.280 --> 30:12.520
Good, it's not already known, I'm doing something new.

30:12.520 --> 30:13.360
Yeah.

30:14.760 --> 30:17.480
So where does the intelligence lie?

30:17.480 --> 30:19.720
I think was where I was getting at.

30:19.720 --> 30:21.720
I'm really fascinated by this idea

30:21.720 --> 30:25.200
that it's not in the brain that it's in the process.

30:25.200 --> 30:27.640
And I think your ideas are going in that direction.

30:27.640 --> 30:29.080
Yeah, I remember your question.

30:29.080 --> 30:34.080
Yeah, yeah, so like, if there was a less intelligent

30:34.760 --> 30:38.680
kind of move towards our less intelligent type of agent

30:38.680 --> 30:41.800
that was involved in an artistic evolution,

30:41.800 --> 30:44.600
like what would be the quality of that?

30:45.920 --> 30:50.720
Yeah, I think, I do think it's possible for there to be

30:50.720 --> 30:55.720
artistic, it's complicated because like art is subjective.

30:55.720 --> 30:58.080
I mean, we're making it for ourselves.

30:58.080 --> 31:01.400
So like, if there were things that aren't us

31:01.400 --> 31:02.880
that are doing something artistic,

31:03.280 --> 31:04.880
presumably they're making it for themselves.

31:04.880 --> 31:07.400
So it might not be interesting to us.

31:07.400 --> 31:10.360
I'm not sure it would, it might be interesting to us,

31:10.360 --> 31:13.480
but it would be a process worth paying attention to

31:13.480 --> 31:15.920
in some way, I do believe that,

31:15.920 --> 31:20.920
because it would have these properties of trends

31:21.440 --> 31:25.200
and stepping stones and like an evolutionary process,

31:25.200 --> 31:27.960
like a phylogeny would result from that.

31:27.960 --> 31:29.680
Whether it's of interest to us is,

31:29.680 --> 31:31.560
I mean, just the artifacts themselves,

31:31.560 --> 31:34.480
I'm not totally sure that they would be.

31:34.480 --> 31:37.280
Cause a lot of, I mean, art does often reference things,

31:37.280 --> 31:39.840
like I said, in nature, cause that's what our experience is.

31:39.840 --> 31:42.520
I mean, if you have no experience of nature,

31:42.520 --> 31:44.560
art can't be about that then.

31:44.560 --> 31:45.520
So what is it about?

31:45.520 --> 31:47.280
And it could be about other things,

31:47.280 --> 31:48.480
just mathematical relationships.

31:48.480 --> 31:51.480
Some small subset of art is, like I said,

31:51.480 --> 31:53.400
like I mean, some modern art has nothing to do

31:53.400 --> 31:55.400
with referencing anything in the world.

31:58.000 --> 32:00.440
So maybe some people would appreciate that,

32:00.440 --> 32:01.760
but even those things seem to relate

32:01.760 --> 32:03.920
to some emotional resonance or something like that.

32:03.920 --> 32:07.200
Like these beings may have no emotion.

32:07.200 --> 32:08.640
So I don't know where you'd enjoy this,

32:08.640 --> 32:11.960
but from a kind of like just like analyzing

32:11.960 --> 32:13.320
the process point of view,

32:13.320 --> 32:14.480
I think it might be interesting

32:14.480 --> 32:16.720
cause there would be such a process.

32:16.720 --> 32:20.080
It's so interesting because the rubber meets the road.

32:20.080 --> 32:23.440
We're talking about this, all of these brains

32:23.440 --> 32:26.000
operating together in this divergent process.

32:26.000 --> 32:28.240
And you were just saying that an artist possibly

32:28.240 --> 32:30.440
has some kind of phenomenological resonance

32:30.440 --> 32:31.760
with a situation.

32:31.760 --> 32:35.000
And I'm interested in the kind of continuum

32:35.000 --> 32:37.320
between brains and the kind of algorithms

32:37.320 --> 32:38.760
we produce in computer science.

32:38.760 --> 32:40.520
Because I think we could all agree

32:40.520 --> 32:43.160
that neural networks and optimization algorithms,

32:43.160 --> 32:44.800
they don't seem very human-like

32:44.800 --> 32:47.120
and they certainly don't think the way humans do,

32:47.120 --> 32:50.360
even if they can produce intelligent senior behavior.

32:50.360 --> 32:52.080
So you really lean into this idea

32:52.080 --> 32:54.520
of trusting our instincts and subjectivity.

32:54.520 --> 32:57.120
And a cynical reading is that our subjectivity

32:57.120 --> 32:58.560
is essentially random.

32:58.560 --> 33:01.800
And a random search would be the most divergent search,

33:01.800 --> 33:03.760
but that would clearly be rubbish, right?

33:03.760 --> 33:05.440
So there must be some kind of continuum

33:05.440 --> 33:07.480
between a totally random search

33:07.480 --> 33:09.960
and a principled divergent search.

33:09.960 --> 33:13.060
So how would you kind of articulate and reason about that?

33:14.080 --> 33:19.080
Yeah, it's true that any kind of divergence

33:19.080 --> 33:21.640
that pushes too far towards a randomness,

33:21.640 --> 33:23.700
I don't think would be interesting.

33:24.560 --> 33:27.000
And I don't think that's what artists

33:27.000 --> 33:28.960
I don't think that's what human artists are doing

33:28.960 --> 33:31.600
because I don't think it would be interesting.

33:31.600 --> 33:34.360
It's just that art is,

33:35.920 --> 33:39.840
they are really concerned with what's interesting, I think,

33:39.840 --> 33:41.520
but without the constraints of science.

33:41.520 --> 33:44.760
So it's not supposed to prove something that you're trying

33:44.760 --> 33:46.920
to figure out whether it's true or not.

33:46.920 --> 33:49.520
It's just supposed to lead to some kind of insight

33:49.520 --> 33:52.200
or feeling or something, it depends on the artist.

33:52.200 --> 33:55.560
And of course that then points back to things we care about

33:55.560 --> 33:57.760
because we're humans and we care about having insights.

33:57.760 --> 34:00.560
And of course the things we want to have insights about vary

34:00.560 --> 34:02.760
but like generally art that we appreciate

34:02.760 --> 34:05.000
like leads you to having some realization

34:05.000 --> 34:07.400
that is generally commonly held

34:07.400 --> 34:10.280
like that people would agree is interesting.

34:10.280 --> 34:14.720
And so artists are exploring that

34:14.720 --> 34:19.240
and that leads to other ideas that might not be art.

34:19.240 --> 34:20.680
You know, I think, yeah, like a scientist

34:20.680 --> 34:24.560
can be inspired by art to think about a phenomenon

34:25.400 --> 34:26.960
or somebody else can be inspired architect,

34:26.960 --> 34:28.480
obviously many times inspired by arts.

34:28.480 --> 34:30.560
There's lots of inspiration that comes out of art

34:30.560 --> 34:31.840
if you feel philosophical as well

34:31.840 --> 34:35.000
like about like how the world works and what matters.

34:35.000 --> 34:36.680
There's plenty of topics to talk about

34:36.680 --> 34:39.800
that aren't falsifiable in a scientific sense.

34:40.840 --> 34:43.480
And, you know, with AI algorithms,

34:43.480 --> 34:47.320
they, I think secretly a lot of the explanation

34:47.320 --> 34:51.440
for what has risen and fallen within AI is that,

34:51.440 --> 34:54.480
not the actual scientific results.

34:54.480 --> 34:56.080
Is that people have resonated.

34:56.080 --> 34:58.040
I like that word because that's really about art.

34:58.040 --> 35:00.640
It's not, it's not about correctness or accuracy.

35:00.640 --> 35:02.000
It's about resonance.

35:02.000 --> 35:04.240
And people have resonated with certain algorithms.

35:04.240 --> 35:05.880
It's like they just felt it.

35:05.880 --> 35:07.400
It got to a point.

35:07.400 --> 35:09.360
Well, this is like an artistic realization,

35:09.360 --> 35:11.280
not a scientific realization.

35:11.280 --> 35:12.880
Like where it resonated with some sense

35:12.880 --> 35:14.680
of what intelligence is for you.

35:15.680 --> 35:16.920
And it's not like the whole thing.

35:16.920 --> 35:19.200
Nobody got the whole deal of intelligence obviously

35:19.200 --> 35:21.360
but some part of it like resonates.

35:21.360 --> 35:23.840
And that can be extremely inspiring.

35:23.840 --> 35:26.160
And I think explains certain like inflection points

35:26.160 --> 35:28.360
in the history of machine learning

35:28.360 --> 35:31.040
where I think it was resonance really that explains it.

35:31.040 --> 35:31.880
Yeah.

35:31.880 --> 35:33.440
And I think it's really interesting what you're saying.

35:33.440 --> 35:36.520
And I think there's a tendency of some

35:37.400 --> 35:41.640
to again dismiss this type of thing as not science,

35:41.640 --> 35:43.400
woo woo, you know, whatever.

35:43.400 --> 35:48.400
But I think that stems from a being insufficiently Darwinian

35:48.920 --> 35:52.400
in the sense that look, whatever's up in our brain,

35:52.400 --> 35:56.160
okay, it's the beneficiary of a billion years

35:56.160 --> 35:58.000
of evolution, okay.

35:58.000 --> 36:01.120
And these insights and intuitions that we have,

36:01.120 --> 36:02.680
even if we're not conscious of them,

36:02.680 --> 36:04.200
maybe they're not happening at a level

36:04.200 --> 36:07.840
that we can analytically break down consciously

36:07.840 --> 36:11.320
and think about could still be extremely useful

36:11.320 --> 36:12.480
and extremely valuable.

36:12.480 --> 36:14.720
And so I have no doubt believing that

36:14.720 --> 36:18.040
when a human mind sees an algorithm even,

36:18.040 --> 36:20.560
it can perceive some connections

36:20.600 --> 36:23.200
to some abstract concepts

36:23.200 --> 36:25.600
that have been proven out through evolution

36:25.600 --> 36:27.760
as being highly, highly useful.

36:27.760 --> 36:29.680
And so you may be seeing those connections.

36:29.680 --> 36:33.120
Is that, I mean, does that capture potentially a fair

36:33.120 --> 36:36.320
and scientific justification of why we should pay attention

36:36.320 --> 36:39.180
to intuition and artistic intuition?

36:40.360 --> 36:42.120
Yeah, I think it's fair.

36:42.120 --> 36:45.440
I think though I wouldn't only couch it

36:45.440 --> 36:47.080
in terms of evolution, I think it's broader

36:47.080 --> 36:48.760
than just from evolution.

36:48.800 --> 36:50.480
Like it's from our experience also,

36:50.480 --> 36:52.240
like experience since you were born,

36:53.360 --> 36:55.880
and that's your memories and the feelings

36:55.880 --> 36:57.520
that you've had over the course of your life

36:57.520 --> 36:59.560
that I think enter into.

36:59.560 --> 37:01.120
Of course, just some evolution explanation

37:01.120 --> 37:02.840
for how you process those experiences,

37:02.840 --> 37:05.120
but the experiences are also part of the background

37:05.120 --> 37:07.960
for what you appreciate and find interesting in your life.

37:07.960 --> 37:12.000
And yeah, I think that that is, as you say,

37:13.640 --> 37:17.560
an important part of the history of ideas,

37:17.560 --> 37:19.000
even in science.

37:19.000 --> 37:22.560
And what I guess, what's actionable about that though,

37:22.560 --> 37:26.960
is that it's interesting to think about the extent to it,

37:26.960 --> 37:31.840
we should actually allow or facilitate discussion

37:31.840 --> 37:33.840
on this level, not at this meta level

37:33.840 --> 37:35.680
that we're talking about, should we do this,

37:35.680 --> 37:38.680
but at the level of here is what resonates to me,

37:38.680 --> 37:40.400
like about the specific thing.

37:40.400 --> 37:42.440
This is why it's interesting, like as a reviewer,

37:42.440 --> 37:46.080
like I don't care if it gets like 5% less accuracy

37:46.080 --> 37:47.320
on this set, it's super interesting

37:47.320 --> 37:50.840
because XYZ, it reminds me of something,

37:50.840 --> 37:54.360
powerfully reminds me, like can we have discussions like this?

37:54.360 --> 37:55.440
We can't right now.

37:55.440 --> 37:57.720
And so it's interesting just to think about that,

37:57.720 --> 38:01.440
like would it help to facilitate progress?

38:01.440 --> 38:02.720
Would it stymie progress?

38:02.720 --> 38:03.880
Because I think most people,

38:03.880 --> 38:06.080
their first good instinct is it's bad for progress,

38:06.080 --> 38:09.320
because it opens the floodgates of sort of like unregulated,

38:09.320 --> 38:11.600
like unempirical type of speculation.

38:11.600 --> 38:13.200
We're all afraid of that.

38:13.200 --> 38:15.880
But I think we should be cautious,

38:15.920 --> 38:17.760
I think we're too afraid of it,

38:17.760 --> 38:19.920
and that like we can handle this,

38:19.920 --> 38:21.840
because like we actually know about

38:21.840 --> 38:22.840
what we're talking about.

38:22.840 --> 38:24.960
Like that's the thing that makes this valid.

38:24.960 --> 38:27.400
Like it's again, like if it was just some random person

38:27.400 --> 38:28.840
on the street, I wouldn't want it to have

38:28.840 --> 38:31.400
an aesthetic discussion of algorithms.

38:31.400 --> 38:33.680
But if it's experts, I don't understand why we're not allowed

38:33.680 --> 38:36.440
to have aesthetic feelings and relating things

38:36.440 --> 38:40.080
in like analogizing, things like that seem perfectly fine.

38:40.080 --> 38:41.320
We should be able to do, I would say,

38:41.320 --> 38:43.480
even if you can't do that, there's a problem.

38:43.480 --> 38:45.560
Like why are you an expert?

38:45.680 --> 38:47.120
Like if you can't make analogies

38:47.120 --> 38:48.680
and actually talk about what's interesting

38:48.680 --> 38:50.480
or inspiring about the work.

38:50.480 --> 38:51.320
Okay.

38:51.320 --> 38:54.080
One thing that I'm wrestling with a little bit here is,

38:54.080 --> 38:56.640
I mean, Douglas Hofstadter, the famous Douglas Hofstadter,

38:56.640 --> 38:59.600
he once said that he was terrified

38:59.600 --> 39:03.280
that AI might be disappointingly simple to mechanize.

39:03.280 --> 39:05.840
And I think a lot of the stuff that we're talking about here

39:05.840 --> 39:07.560
is, I mean, we're talking about subjectivity,

39:07.560 --> 39:10.040
but also we're talking about the externalization

39:10.040 --> 39:11.360
of intelligence.

39:11.360 --> 39:14.280
So rather than it being encapsulated

39:14.360 --> 39:17.440
in an individual brain, a lot of it is emergent

39:17.440 --> 39:21.520
and can be thought of as something completely different.

39:23.720 --> 39:26.840
I'm concerned about the lack of free will

39:26.840 --> 39:29.960
for want of a better, so we've been dealt

39:29.960 --> 39:32.680
with the experiences and the environment

39:32.680 --> 39:34.040
that we have in life.

39:34.040 --> 39:37.240
And to a certain extent, is it still intelligent

39:37.240 --> 39:39.840
if our cards are marked?

39:40.680 --> 39:43.360
If everything has been mapped out in my life

39:43.400 --> 39:46.680
as a function of the environment that I'm in

39:46.680 --> 39:48.760
and my life experiences.

39:48.760 --> 39:52.160
I guess I have this, just as Douglas Hofstadter did,

39:52.160 --> 39:55.120
I have this very fanciful idea in my mind

39:55.120 --> 39:57.960
of what intelligence is, that it's infinitely nuanced.

39:57.960 --> 40:00.720
And we have this phenomenological experience.

40:00.720 --> 40:05.720
And, you know, for example, Hofstadter spoke about Chopin,

40:05.720 --> 40:07.520
this beautiful piece of music

40:07.520 --> 40:10.040
and what the infinite nuance and subtlety

40:10.040 --> 40:12.320
that must have gone through his mind when he created it.

40:12.360 --> 40:16.120
And wouldn't it be horrible if that was just the result

40:16.120 --> 40:20.640
of quite a simple process that you could define using code?

40:22.160 --> 40:23.960
This is an interesting question.

40:25.120 --> 40:28.640
I think, yeah, it's clear that there's a movement

40:28.640 --> 40:32.200
in machine learning towards that kind of perspective

40:32.200 --> 40:34.080
of basically simplicity.

40:34.080 --> 40:35.800
And it goes back before deep learning.

40:35.800 --> 40:39.440
I mean, people were observing that they say, well, like,

40:39.440 --> 40:41.440
you know, cortical circuits like in the brain

40:41.480 --> 40:43.880
all share like a huge amount of similarity.

40:43.880 --> 40:46.280
It's like, it is possible it's all the same algorithm

40:46.280 --> 40:49.840
all throughout and there's just some simple explanation.

40:49.840 --> 40:52.680
And then, like, when we see, like,

40:52.680 --> 40:55.360
things like really large language models

40:55.360 --> 40:59.160
that are basically like uniform architectural structures

40:59.160 --> 41:02.200
that just get bigger, it seems to,

41:02.200 --> 41:03.800
it seems to point in that direction

41:03.800 --> 41:06.680
that like it's not like a bunch of really complex,

41:06.680 --> 41:09.040
rich subtlety like going on through the system.

41:09.440 --> 41:12.280
We don't know, though, yet, we don't know.

41:12.280 --> 41:14.080
I mean, the jury's still out.

41:14.080 --> 41:16.400
We haven't actually gotten to human level.

41:16.400 --> 41:20.200
And I think that, yeah, and I mean,

41:20.200 --> 41:22.520
you can also point to evolutionary processes too.

41:22.520 --> 41:24.360
And they're also simple, like there's a simple thing

41:24.360 --> 41:26.480
and this explains everything,

41:26.480 --> 41:28.560
like it's not really that interesting of a thing

41:28.560 --> 41:30.480
in and of itself.

41:30.480 --> 41:32.200
I don't, I guess to me it's just,

41:32.200 --> 41:33.840
we would like to know the answer to this.

41:33.840 --> 41:35.920
Like, can you actually get these things to work

41:35.920 --> 41:37.200
through very simple processes?

41:37.200 --> 41:40.040
That's probably really important to know,

41:40.040 --> 41:43.120
like just in terms of being able to do machine learning.

41:43.120 --> 41:45.200
But I don't think for me it would be

41:46.560 --> 41:49.440
that disappointing one way or another, I think.

41:49.440 --> 41:52.760
Cause I think the subtlety is still in there.

41:52.760 --> 41:54.840
It just came in through a different channel.

41:54.840 --> 41:57.760
Like, okay, maybe the subtlety is not in the architecture.

41:57.760 --> 42:00.040
I personally think there is subtlety in the architecture.

42:00.040 --> 42:03.440
That's my guess, like it's not gonna be super simple.

42:03.440 --> 42:05.040
But let's say it doesn't have to be,

42:05.040 --> 42:07.120
it could be all like uniform.

42:07.120 --> 42:11.000
But then, like what you do and what you care about

42:11.000 --> 42:14.440
can still be like the constellation of stuff

42:14.440 --> 42:17.480
that you learned, which you learned over your lifetime.

42:17.480 --> 42:20.720
Like what that amount to, you know, in aggregate

42:20.720 --> 42:24.200
can still be, I think, highly rich and subtle

42:24.200 --> 42:26.000
in its connectivity.

42:26.000 --> 42:28.440
It's just a structure that emerged from a simple process

42:28.440 --> 42:29.480
which allowed it to emerge,

42:29.480 --> 42:32.140
but then the structure itself is complex.

42:32.140 --> 42:33.760
So I don't think it would diminish sort of

42:33.800 --> 42:38.400
like the grandiosity of like what we are to me.

42:38.400 --> 42:40.160
I could see other people might think otherwise,

42:40.160 --> 42:41.640
but it's okay.

42:41.640 --> 42:42.960
I don't know what the actual truth is,

42:42.960 --> 42:44.640
but that wouldn't necessarily bother me.

42:44.640 --> 42:45.960
Yeah, I agree with you.

42:45.960 --> 42:49.080
It doesn't decrease the grandiosity of what we are.

42:49.080 --> 42:50.400
Consciousness you're talking about?

42:50.400 --> 42:54.320
I was surprised that the guy has so much conversation.

42:55.440 --> 42:57.520
I didn't realize it struck a chord.

42:57.520 --> 42:59.720
I find that I think we don't know

42:59.720 --> 43:01.960
what the motivation is behind that tweet.

43:01.960 --> 43:06.960
It's, I'm assuming it was meant to provoke conversation.

43:07.240 --> 43:09.080
There's no depth in that tweet at all,

43:09.080 --> 43:10.480
but it's not because it's dumb.

43:10.480 --> 43:12.520
It's because like it's a tweet and there's no room

43:12.520 --> 43:15.440
to actually talk about all the complexity of the issue.

43:15.440 --> 43:17.720
And so I'm assuming that he's not actually making an argument

43:17.720 --> 43:20.560
that he even thinks is like persuasive one way or another.

43:20.560 --> 43:22.620
He's just provoking discussion.

43:22.620 --> 43:24.320
And as such, I think it's effective.

43:24.320 --> 43:26.320
It provoked discussion certainly.

43:26.320 --> 43:27.600
It got a lot of discussion going

43:27.600 --> 43:30.280
and allowed people to show their cards on this.

43:30.280 --> 43:32.400
And I'm actually curious about what people's cards are

43:32.400 --> 43:34.880
on this, like people don't talk about this that much.

43:34.880 --> 43:37.000
I think it's not, it's not immediately germane

43:37.000 --> 43:38.240
to making progress in machine learning.

43:38.240 --> 43:40.360
So it's in some ways you might think it was a waste of time

43:40.360 --> 43:43.120
because we can't really use this discussion to get anywhere

43:43.120 --> 43:45.480
and people are busy trying to publish papers and stuff.

43:45.480 --> 43:47.800
But I'm just just personally curious like

43:47.800 --> 43:49.640
about what people think in this field

43:49.640 --> 43:51.200
because it's obviously relevant

43:51.200 --> 43:52.840
like to what we're trying to do.

43:52.840 --> 43:54.840
I mean, maybe we connected into quite a lot

43:54.840 --> 43:56.400
of the symbolic community.

43:56.400 --> 43:59.000
And on LinkedIn, everyone was just posting saying,

43:59.000 --> 44:02.120
oh my God, that this hype is getting out of control.

44:02.120 --> 44:04.000
The runaway train of deep learning.

44:04.000 --> 44:05.880
No, it's like, oh, you're basically just like

44:05.880 --> 44:06.720
feeding into the hype.

44:06.720 --> 44:08.800
But I could interpret that to be completely independent

44:08.800 --> 44:10.440
from deep learning height.

44:10.440 --> 44:11.280
Well.

44:11.280 --> 44:12.120
It's just basically saying like,

44:12.120 --> 44:14.320
is there a threshold that's crossed

44:14.320 --> 44:17.740
where there actually is like conscious phenomenon happening?

44:18.960 --> 44:20.640
And it doesn't mean that what we're doing

44:20.640 --> 44:21.960
is right at all right now.

44:21.960 --> 44:23.160
It's still an interesting question.

44:23.160 --> 44:27.320
I love it because it is provoking this conversation

44:27.320 --> 44:30.920
that we need to be a bit more defined

44:30.920 --> 44:32.440
in what we mean by consciousness

44:32.440 --> 44:34.040
or at least to think about it.

44:34.040 --> 44:36.920
So I thought it was for the purpose that can things

44:36.920 --> 44:38.680
which is to provoke conversation.

44:40.600 --> 44:42.800
And I will admit it provoked me to tweet something.

44:42.800 --> 44:45.280
I actually don't tweet much

44:45.280 --> 44:47.000
but I actually tweeted something last night

44:47.000 --> 44:49.920
because I just couldn't resist it unconsciousness.

44:49.920 --> 44:50.960
What did you tweet?

44:50.960 --> 44:52.560
I don't know if it'll upset you maybe.

44:52.560 --> 44:53.400
I don't know.

44:53.400 --> 44:54.240
Yeah, tell us.

44:54.240 --> 44:55.080
Tell us what did you tweet.

44:55.080 --> 44:55.920
What's upset him?

44:55.920 --> 44:56.760
What did I tweet?

44:56.760 --> 44:58.480
I'd have to look at my phone to remember that

44:58.480 --> 44:59.600
what I said exactly.

44:59.600 --> 45:00.960
Trigger warning, Tim.

45:00.960 --> 45:01.800
Be careful.

45:03.040 --> 45:05.560
Yeah, so this is actually connected to our discussion

45:05.560 --> 45:07.520
in some subtle way here that we've been having

45:07.520 --> 45:09.480
because like basically my tweet on consciousness

45:09.480 --> 45:12.600
I was pointing out that I noticed

45:12.600 --> 45:14.880
like since the original consciousness tweet

45:14.880 --> 45:18.160
like a lot of people making off-handed comments

45:18.160 --> 45:21.200
basically dismissing consciousness is not a good topic

45:21.200 --> 45:23.800
because it lacks an objective measure.

45:23.800 --> 45:26.080
This is an easy way to get out of this.

45:27.040 --> 45:28.800
And the thing that's being missed here

45:28.800 --> 45:30.680
is that is precisely why it's fascinating.

45:30.680 --> 45:32.960
Like it is the phenomenon of subjectivity.

45:32.960 --> 45:35.120
It cannot have an objective measure

45:35.120 --> 45:37.600
unless we're talking about a superficial aspect of it

45:37.600 --> 45:38.920
but the interesting aspect of it

45:38.920 --> 45:40.840
is the part that's hard to talk about.

45:40.840 --> 45:43.640
And so it's literally what it's like from the inside.

45:43.640 --> 45:46.200
And so the idea that we cannot discuss that

45:46.200 --> 45:48.800
is an interesting idea is exactly the kind of cowardice

45:48.800 --> 45:49.800
that I'm talking about.

45:49.800 --> 45:51.760
We're using science to block us

45:51.760 --> 45:54.600
from exploring something that's uncomfortable.

45:54.600 --> 45:56.600
And if science lacks the tools,

45:56.600 --> 45:57.720
like if that's what we're saying,

45:57.720 --> 46:01.000
it lacks the tools to address consciousness

46:01.000 --> 46:02.520
because it is subjective.

46:02.520 --> 46:04.680
That's not an indictment of consciousness as a concept,

46:04.680 --> 46:05.840
it's an indictment of science.

46:05.840 --> 46:06.680
That's right.

46:06.680 --> 46:07.520
You've got me there, I must admit

46:07.520 --> 46:09.040
that's a very clever response.

46:09.040 --> 46:10.160
There's my tweet.

46:10.160 --> 46:11.880
Yeah, I don't know how to respond to that

46:11.880 --> 46:14.600
but I mean, I personally like to think of consciousness

46:14.600 --> 46:16.640
as being the like qualia

46:16.640 --> 46:20.160
and the subjective phenomenological experience.

46:20.160 --> 46:22.160
And I thought it was a stretch to say

46:22.160 --> 46:24.680
that something like GPT-3

46:24.680 --> 46:27.920
could possibly have any kind of subjective experience.

46:27.920 --> 46:31.080
I find it a stretch that did you have subjective experience?

46:31.080 --> 46:32.080
I mean, or did I do?

46:32.080 --> 46:35.600
I mean, why a bag of atoms has a subjective experience

46:35.600 --> 46:36.440
like qualia?

46:36.440 --> 46:37.640
I have no idea why that would be.

46:37.640 --> 46:38.760
This is the problem, right?

46:38.760 --> 46:43.280
So we know quite a few people and they are so cynical

46:43.280 --> 46:47.880
and they argue that intelligence is just a parlor trick

46:47.880 --> 46:49.680
that GPT-3 is intelligent

46:49.680 --> 46:51.000
and we're not really intelligent.

46:51.000 --> 46:54.800
And when we think we're thinking,

46:54.800 --> 46:56.720
we're just doing some hash table lookup

46:56.720 --> 46:58.240
and it's all a trick.

46:58.240 --> 47:01.880
Yeah, I mean, there are people that have argued

47:01.880 --> 47:03.840
that consciousness is just like a trick.

47:03.840 --> 47:07.640
And we're just confused when we think we're conscious.

47:07.640 --> 47:09.480
It's really nothing special going on.

47:09.480 --> 47:10.640
Yeah, I mean, if you take that view,

47:10.640 --> 47:12.360
then none of this is very interesting.

47:12.360 --> 47:13.280
I don't take that view

47:13.280 --> 47:15.240
because I believe that there are qualia

47:15.240 --> 47:17.760
but that's just a belief I can't prove anything.

47:17.760 --> 47:19.080
But then again, how could I?

47:19.080 --> 47:20.880
It's a subjective discussion.

47:20.880 --> 47:24.440
And so like the real issue at hand here

47:24.440 --> 47:28.600
is like whether we think that subjective phenomena are real,

47:28.600 --> 47:30.280
like do they actually exist?

47:32.280 --> 47:33.880
To me, it's worth discussing

47:33.880 --> 47:36.560
even though it's actually outside of the bounds

47:36.560 --> 47:38.200
of current science.

47:38.200 --> 47:41.040
I don't know any way that we can look at this empirically

47:41.040 --> 47:43.400
but I don't find that ambiguity uncomfortable.

47:43.400 --> 47:44.240
I think it's interesting.

47:44.240 --> 47:45.080
I like things that are ambiguous.

47:45.080 --> 47:46.160
That's where we start learning things.

47:46.160 --> 47:47.280
I have to hand it to you.

47:47.280 --> 47:48.640
You've really got me there.

47:50.320 --> 47:53.280
Okay, well, that's good.

47:53.280 --> 47:54.120
Yeah.

47:54.120 --> 47:54.960
Made a point.

47:54.960 --> 47:56.400
Yeah, I mean, part of this,

47:56.400 --> 47:59.000
and some of those points are somewhat old.

47:59.000 --> 48:01.280
Like the point has been made, I think many times

48:01.280 --> 48:05.280
that science is lack of ability to describe consciousness

48:05.280 --> 48:07.560
is not an indictment of consciousness.

48:07.560 --> 48:09.280
It's an indictment of science.

48:09.280 --> 48:10.800
I mean, there's things missing from it.

48:10.800 --> 48:12.600
We need to expand it a bit.

48:12.600 --> 48:13.920
That you're quoting a tweet there

48:13.920 --> 48:14.760
but someone probably said it before.

48:15.520 --> 48:18.000
Yeah, it's kind of an old indictment of it

48:18.000 --> 48:23.080
but I think what I often see is that people often cling

48:23.080 --> 48:26.280
to kind of extreme definitions of things

48:26.280 --> 48:29.120
because if they're confronted with a middle ground

48:29.120 --> 48:32.080
that's completely reasonable, it's just boring.

48:32.080 --> 48:35.480
Like they almost just can't accept that that's the answer.

48:35.480 --> 48:39.880
For example, for me, consciousness, from my perspective,

48:39.880 --> 48:43.880
it's definitely a pattern of neural activity in the brain

48:43.920 --> 48:45.880
and it's probably one that's doing something

48:45.880 --> 48:48.000
like analyzing the neural activity

48:48.000 --> 48:51.760
of other parts of the brain and or itself and that's it.

48:51.760 --> 48:54.440
Like it's, you know, what's the big mystery here

48:54.440 --> 48:57.840
but that definition is almost like too easy

48:57.840 --> 49:00.040
and too reasonable and then we have to start talking about,

49:00.040 --> 49:03.000
yeah, but what does it feel like to be that,

49:03.000 --> 49:04.520
you know, that pattern of neurons?

49:04.520 --> 49:06.160
And I saw this happen like in a debate

49:06.160 --> 49:11.160
between Daniel Dennett and Sam Harris about free will, okay?

49:11.600 --> 49:14.320
Where Daniel Dennett is saying, look, to me,

49:14.320 --> 49:18.720
free will is the fact that you can evaluate options

49:18.720 --> 49:21.360
and you evaluate those options

49:21.360 --> 49:24.680
and one path is taken based on that evaluation.

49:24.680 --> 49:26.840
So for example, a chess program,

49:26.840 --> 49:29.320
if it's evaluating the board possibility

49:29.320 --> 49:31.400
and doing a Monte Carlo tree search

49:31.400 --> 49:34.760
and it evaluates one as being the best option

49:34.760 --> 49:37.640
and it takes that path, that's free will.

49:37.640 --> 49:40.800
In other words, it's freedom of parameter space.

49:41.040 --> 49:43.360
It's, you know, freedom of options.

49:43.360 --> 49:47.120
And Sam Harris' only response to that is like, well, okay,

49:47.120 --> 49:49.000
but that's not what people think.

49:49.000 --> 49:52.200
Like that's not what somebody on the street says is free will.

49:52.200 --> 49:55.880
They think it's this magical thing that, well, who cares?

49:55.880 --> 49:59.640
I mean, who cares what people think is surprising?

49:59.640 --> 50:01.680
Like there's people that believe all kinds of things

50:01.680 --> 50:04.840
that don't have any type of scientific basis

50:04.840 --> 50:06.120
or mathematical basis.

50:06.120 --> 50:09.800
We find a very reasonable definition of free will

50:09.800 --> 50:13.000
that's totally compatible with the reality

50:13.000 --> 50:15.560
and the pragmatic experience of free will.

50:15.560 --> 50:18.400
And yet because it's surprising to some people

50:18.400 --> 50:21.480
or because it's too boring, we just refuse to accept it.

50:23.560 --> 50:27.960
Yeah, well, you noted that like people tend to gravitate

50:27.960 --> 50:31.120
to extreme positions, it's pretty clear.

50:31.120 --> 50:33.120
Politics too, for a lot of reasons.

50:34.280 --> 50:37.040
But I also think there's something about human nature

50:37.080 --> 50:39.400
where people don't like to say, I don't know.

50:40.600 --> 50:43.600
And that's like, it's really interesting, I think,

50:43.600 --> 50:44.880
that we don't, we don't admit, we don't know.

50:44.880 --> 50:46.880
People respond with certitude to things

50:46.880 --> 50:49.040
that we have absolutely no idea about.

50:49.040 --> 50:51.600
And I feel like that is much more of the issue

50:51.600 --> 50:54.480
with consciousness is that we really don't know.

50:54.480 --> 50:58.520
And I disagree with like sort of Dennis' position

50:58.520 --> 51:01.240
because it's about, he's claiming to know.

51:01.240 --> 51:04.240
And I think that it's actually most courageous

51:04.240 --> 51:06.120
just to say, I don't really know what's going on here.

51:06.520 --> 51:08.800
The reason I think it's totally reasonable to say

51:08.800 --> 51:12.480
we don't know is because look at polarizes all of us.

51:12.480 --> 51:14.480
Like this is one of those issues where experts

51:14.480 --> 51:16.920
can come out of completely different extremes.

51:16.920 --> 51:18.960
And there's no consensus.

51:18.960 --> 51:20.080
And like when that's happening,

51:20.080 --> 51:22.520
probably nobody knows what's going on.

51:22.520 --> 51:24.280
We have not come to consensus yet.

51:24.280 --> 51:27.000
And so I think there is something deeper going on here

51:27.000 --> 51:29.680
that needs to be addressed and it's not simple

51:29.680 --> 51:32.200
and certitude is not the right response.

51:32.200 --> 51:34.880
So to me, it's just, I would say I don't really know,

51:34.880 --> 51:37.560
but I find interesting to delve into what it is

51:37.560 --> 51:40.200
that I don't know, like the details of what we don't know.

51:40.200 --> 51:41.320
Cause that's where it gets interesting.

51:41.320 --> 51:42.760
There's lots of things we do know,

51:42.760 --> 51:44.200
which is what tends to get rehashed

51:44.200 --> 51:45.760
when we respond with certitude.

51:45.760 --> 51:47.520
Like I know what I know, but I don't,

51:47.520 --> 51:48.840
I'm more interested in what I don't know.

51:48.840 --> 51:49.800
Well, let me just follow up there.

51:49.800 --> 51:52.600
So this was a debate between two extremists.

51:52.600 --> 51:55.200
One extremist saying there's no such thing as very well,

51:55.200 --> 51:56.520
it's an illusion.

51:56.520 --> 51:58.560
And the other one, actually a middle ground,

51:58.560 --> 52:01.840
but at least extreme from a certainty perspective,

52:01.840 --> 52:03.440
which is saying here's the definition.

52:03.440 --> 52:06.520
But the reason why I gravitate towards that position

52:06.520 --> 52:08.280
is because it at least provides us

52:08.280 --> 52:10.000
with an operational paradigm

52:10.000 --> 52:12.640
by which we can do exactly what you're suggesting,

52:12.640 --> 52:14.760
which is explore what we don't know.

52:14.760 --> 52:16.280
So if we take it as like, okay,

52:16.280 --> 52:18.800
here's a working definition of free will.

52:18.800 --> 52:21.240
Now let's find all the areas where it breaks down,

52:21.240 --> 52:22.880
explore them scientifically.

52:22.880 --> 52:24.360
It's at least useful, right?

52:24.360 --> 52:26.640
Whereas an extreme position saying,

52:26.640 --> 52:29.760
no, nothing is free will, it's an illusion, it's not useful.

52:29.760 --> 52:31.360
I can't do anything with that.

52:32.000 --> 52:34.640
I think it's quite hard to have a definition.

52:34.640 --> 52:37.000
I was challenging one of my friends yesterday, Kenneth,

52:37.000 --> 52:40.560
about imagine you wanted to become a billionaire,

52:40.560 --> 52:42.800
give me an objective to optimize.

52:42.800 --> 52:45.200
And it's really, really difficult

52:45.200 --> 52:47.200
because you can start to scratch around

52:47.200 --> 52:50.560
and talk about diversity and information, accumulation,

52:50.560 --> 52:52.280
all the stuff, novelty, interestingness,

52:52.280 --> 52:54.320
but you're really scratching around.

52:54.320 --> 52:55.920
And it's the same thing here.

52:55.920 --> 52:59.560
We're talking about consciousness and free will.

52:59.640 --> 53:02.080
And these are very subjective things.

53:02.080 --> 53:03.480
And when Keith was talking about

53:03.480 --> 53:05.160
the Dennett-Sam Harris debate,

53:06.240 --> 53:07.720
because it's not like free will

53:07.720 --> 53:12.000
is about maximizing the expected reward,

53:12.000 --> 53:13.920
although perhaps if you created an agent

53:13.920 --> 53:15.560
to do such a thing it would,

53:15.560 --> 53:18.000
maybe you could tune it to behave in such a way

53:18.000 --> 53:19.760
as humans behave.

53:19.760 --> 53:24.760
But from my perspective, free will is about the subjectivity

53:25.080 --> 53:28.680
and about the agency, those two things.

53:28.680 --> 53:30.640
And I can't really describe those two things

53:30.640 --> 53:32.920
in any more detail than that.

53:32.920 --> 53:33.840
Yeah.

53:33.840 --> 53:37.760
Well, one distinction that I think I want to make is that

53:37.760 --> 53:40.360
I would separate in my kind of like questioning

53:40.360 --> 53:42.880
and thinking free will from consciousness.

53:42.880 --> 53:45.360
Like I think it's two different questions for me.

53:45.360 --> 53:47.080
I could see why you might want to combine them,

53:47.080 --> 53:48.840
but I just think they're different.

53:48.840 --> 53:51.160
I've thought much more about consciousness than free will.

53:51.160 --> 53:53.360
So on that I think I'm not,

53:53.360 --> 53:54.640
I haven't really thought through

53:54.640 --> 53:56.760
how to address free will very well.

53:57.760 --> 53:59.600
But my consciousness I think,

53:59.600 --> 54:04.040
to me it's about the issue that's really problematic

54:04.040 --> 54:06.520
is when it comes to like quality and things like that.

54:06.520 --> 54:07.640
Like there are other aspects of consciousness

54:07.640 --> 54:09.560
we might talk about that I think they're less problematic,

54:09.560 --> 54:13.000
but that is very mysterious and I feel unresolved.

54:13.000 --> 54:15.080
But in case we're making a general point here

54:15.080 --> 54:17.960
about these kinds of discussions and yeah,

54:17.960 --> 54:21.280
I think the general points that he's making are reasonable.

54:22.160 --> 54:26.720
And so we have David Chalmers coming on the show next month.

54:26.720 --> 54:28.840
Oh, I was gonna say, did you read his book?

54:28.840 --> 54:30.720
I mean, that's like, now that was a book.

54:30.720 --> 54:34.400
I really liked that book because it is about not knowing.

54:34.400 --> 54:36.240
The book is basically trying to tell,

54:36.240 --> 54:37.080
that's how I interpret it.

54:37.080 --> 54:37.920
I'm no philosopher,

54:37.920 --> 54:39.480
so maybe I don't even understand what I'm reading,

54:39.480 --> 54:41.960
but my interpretation was basically a big argument

54:41.960 --> 54:43.960
about why we should admit

54:43.960 --> 54:46.080
that we really don't know what's going on.

54:46.080 --> 54:47.480
There's very few books like that.

54:47.480 --> 54:50.000
I love a good book about not knowing things.

54:50.040 --> 54:51.400
I don't know if you guys know that

54:51.400 --> 54:54.560
like one of the very first neuroevolution experiments

54:54.560 --> 54:56.720
cause I was in the field of neuroevolution was Chalmers.

54:56.720 --> 54:59.960
He actually did it long before all this stuff

54:59.960 --> 55:00.800
he's famous for.

55:01.920 --> 55:04.400
He re-evolved the rules of back propagation.

55:05.480 --> 55:06.320
Amazing.

55:07.560 --> 55:08.760
Sighted him many times for that.

55:08.760 --> 55:11.040
Amazing, he comes up absolutely everywhere.

55:11.040 --> 55:12.600
He's such an interesting guy.

55:13.640 --> 55:15.880
I wanted to talk a little bit about some of that stuff

55:15.880 --> 55:18.520
because there's not a lot of new work

55:18.520 --> 55:19.960
in your space at the moment.

55:19.960 --> 55:21.760
And I suppose like one way to frame the question

55:21.760 --> 55:25.120
is clearly poet and enhanced poet are fascinating.

55:25.120 --> 55:30.120
And they are much more divergent than many other algorithms.

55:30.480 --> 55:32.600
But are you aware of anything

55:32.600 --> 55:34.280
which has been artificially created

55:34.280 --> 55:36.240
which is extremely divergent?

55:36.240 --> 55:37.680
I mean, more so than poet even

55:37.680 --> 55:39.520
or is that currently the state of the art?

55:40.880 --> 55:42.960
Well, there are still things going on.

55:42.960 --> 55:46.640
Like one place to look is under the name quality diversity.

55:46.640 --> 55:48.280
Like you can find a website.

55:48.720 --> 55:50.400
I think it's called Quality Diversity Optimization.

55:50.400 --> 55:51.560
Unfortunately, the word optimization

55:51.560 --> 55:52.360
I wouldn't have put in there,

55:52.360 --> 55:54.640
but that's what they're calling it.

55:54.640 --> 55:56.160
And that's basically about,

55:56.160 --> 55:58.440
QD algorithms are basically about like novelty,

55:58.440 --> 55:59.880
like novelty seeking things combined

55:59.880 --> 56:01.440
with the notion of quality.

56:01.440 --> 56:03.640
And so you can see like the latest there.

56:03.640 --> 56:05.800
Like those are divergent at some level.

56:05.800 --> 56:07.760
Like almost every paper that there's like 150,

56:07.760 --> 56:09.320
I think the last time I looked.

56:10.200 --> 56:13.240
But the thing about it is it is not yet connected

56:13.240 --> 56:14.440
to the mainstream of machine learning,

56:14.440 --> 56:15.960
which is why you're not hearing about it

56:15.960 --> 56:17.480
or noticing it as much.

56:17.480 --> 56:18.960
That's always been a problem historically.

56:18.960 --> 56:21.200
Going back to neuro evolution,

56:21.200 --> 56:23.320
it's often evolutionary,

56:23.320 --> 56:24.480
but there are some,

56:24.480 --> 56:26.720
there is some drift out of that I think recently.

56:26.720 --> 56:29.520
Like people have sent me preprints.

56:29.520 --> 56:31.640
I think something's gonna come out soon, for example,

56:31.640 --> 56:34.080
trying to build on like the idea of poet.

56:34.080 --> 56:35.360
And like that are much more kind of

56:35.360 --> 56:38.440
machine learning, reinforcement learning oriented.

56:38.440 --> 56:39.840
And so there will be things.

56:39.840 --> 56:42.280
There's a trickle coming out in that direction.

56:42.280 --> 56:43.840
And then now we're seeing like

56:43.840 --> 56:46.320
there's open-ended learning symposium workshops,

56:46.320 --> 56:48.000
like popping up at mainstream conferences.

56:48.000 --> 56:51.520
I know I'm speaking at, I guess, is it iClear, I think?

56:51.520 --> 56:53.600
There's gonna be a workshop on open-endedness.

56:53.600 --> 56:57.640
And so there's definitely some momentum.

56:57.640 --> 57:00.680
I think it's still early and could fizzle out,

57:00.680 --> 57:02.280
but you're seeing stuff.

57:03.440 --> 57:05.440
But in any case, to the question,

57:05.440 --> 57:09.160
do we actually see something more open-ended than poet?

57:09.160 --> 57:10.800
I think the answer is no currently.

57:10.800 --> 57:13.800
I'm not aware of everything going on, but that's a pretty,

57:14.800 --> 57:17.720
like maybe like there's some things

57:17.720 --> 57:18.960
that improve on it in one way or another,

57:18.960 --> 57:20.680
but I wouldn't call it more open-ended.

57:20.680 --> 57:22.880
No, I think that that's a pretty high bar.

57:22.880 --> 57:26.880
Like, and there is headroom, I think,

57:26.880 --> 57:29.040
to be more open-ended than poet,

57:29.040 --> 57:31.560
but it's a high bar, it's really hard.

57:31.560 --> 57:36.560
And I think when people see poet, they focus,

57:37.400 --> 57:38.360
from machine learning perspective,

57:38.360 --> 57:41.840
they focus more on the curriculum learning aspect of it.

57:42.480 --> 57:43.560
Like the curriculum learning aspect

57:43.560 --> 57:45.160
is like a certain perspective you could have,

57:45.160 --> 57:47.280
and you could think about it as like,

57:47.280 --> 57:50.160
how do we get something really intelligent

57:50.160 --> 57:53.320
for a certain kind of problem that has generality?

57:53.320 --> 57:55.160
Like I think about something like that,

57:55.160 --> 57:58.200
and this is like give some clues in that direction.

57:58.200 --> 58:00.600
But that's not really going towards the part

58:00.600 --> 58:03.480
that like inspires me to the open-endedness side of it.

58:03.480 --> 58:05.360
You know, what I really wanna see is that

58:05.360 --> 58:08.000
it just continues to invent like totally out

58:08.000 --> 58:10.120
of the blue crazy stuff forever.

58:10.120 --> 58:12.560
And that like seems to get less mind-share,

58:12.560 --> 58:14.440
like that kind of question,

58:14.440 --> 58:15.960
maybe because it's not very practical,

58:15.960 --> 58:18.200
or nobody's really sure what we're even talking about,

58:18.200 --> 58:21.240
like what crazy things you actually want to see.

58:21.240 --> 58:23.200
But I would, that's the kind of thing

58:23.200 --> 58:26.720
where I don't think we're seeing a lot of push or progress.

58:26.720 --> 58:29.720
On the curriculum learning, I do think we see things,

58:29.720 --> 58:31.800
and they are interesting within that context.

58:31.800 --> 58:33.720
Yeah, the curriculum learning thing fascinates me,

58:33.720 --> 58:37.600
because I remember talking about, I think, ICML 2019,

58:37.600 --> 58:39.200
and he was saying, look on poet,

58:39.240 --> 58:42.200
there's an example of an agent,

58:42.200 --> 58:43.640
and we have this curriculum,

58:43.640 --> 58:45.680
and sometimes we need to kind of shift

58:45.680 --> 58:48.880
between a very kind of complex environment,

58:48.880 --> 58:50.440
and then back to a simple environment

58:50.440 --> 58:52.240
in order to solve this particular problem.

58:52.240 --> 58:54.120
But you spoke about generality,

58:54.120 --> 58:57.880
and I would still argue that the kind of program

58:57.880 --> 59:00.360
learned by poet doesn't have generality,

59:00.360 --> 59:03.480
but the process which produced it does.

59:03.480 --> 59:05.200
So Francois Choulet has this measure

59:05.200 --> 59:07.280
of intelligence conception,

59:07.280 --> 59:10.600
and he has this idea of intelligence being a process.

59:10.600 --> 59:12.720
So there's like a meta-learning process,

59:12.720 --> 59:14.760
and then it can produce skill programs,

59:14.760 --> 59:17.080
which can then work in any particular situation.

59:17.080 --> 59:19.760
So I mean, is that similar to your mindset?

59:21.080 --> 59:23.520
So I agree that it doesn't have generality.

59:23.520 --> 59:24.720
That's totally true.

59:24.720 --> 59:27.360
It's totally about hyper-specialization.

59:27.360 --> 59:28.800
This gets to actually the art aspect,

59:28.800 --> 59:31.040
the art discussion we were having before.

59:31.040 --> 59:35.480
To me, that is artistically appealing,

59:35.480 --> 59:37.720
because it's evocative of nature,

59:37.720 --> 59:41.440
where you're not going for a super-generalist in general.

59:41.440 --> 59:45.840
Each niche is basically a hyper-specialized niche,

59:45.840 --> 59:50.680
which interestingly eventually led to extreme generality,

59:50.680 --> 59:53.520
like us, like we have an extreme level of generality

59:53.520 --> 59:54.360
in certain ways.

59:54.360 --> 59:55.880
Like in certain ways, we're not photosynthetics,

59:55.880 --> 59:57.520
we don't have that kind of generality,

59:57.520 --> 59:59.600
but we have intelligent generality,

59:59.600 --> 01:00:01.640
but it went through hyper-specialization.

01:00:02.760 --> 01:00:04.360
If you go back through the ancestry,

01:00:04.360 --> 01:00:05.760
you're looking at hyper-specialists,

01:00:05.760 --> 01:00:06.920
not generalists that are trying to become

01:00:06.920 --> 01:00:07.920
more and more intelligent,

01:00:07.920 --> 01:00:09.520
like you're looking at things like flatworms again,

01:00:09.520 --> 01:00:12.240
or not generalists in any sense.

01:00:12.240 --> 01:00:14.640
Like it's a new reorganization of the body plan.

01:00:15.400 --> 01:00:17.000
And so I find, first of all,

01:00:17.000 --> 01:00:18.280
just from an artistic perspective,

01:00:18.280 --> 01:00:23.280
find the depiction of something that is about,

01:00:24.120 --> 01:00:27.600
like continually branching and just interesting aesthetically,

01:00:27.600 --> 01:00:29.240
and something that we should create.

01:00:29.240 --> 01:00:31.440
Like we should create things that do that.

01:00:31.440 --> 01:00:33.040
But what I notice is that always,

01:00:33.040 --> 01:00:34.760
people point to that as a weakness,

01:00:34.760 --> 01:00:36.160
and say, well, there's a caveat here,

01:00:36.160 --> 01:00:38.800
it's very specialist-oriented, you know?

01:00:38.800 --> 01:00:39.920
Why not go for generality?

01:00:39.920 --> 01:00:41.440
And actually you could.

01:00:41.440 --> 01:00:43.760
This is like a fairly intuitive notion,

01:00:43.760 --> 01:00:45.960
that like, yeah, we can get divergent curricula,

01:00:45.960 --> 01:00:49.480
but try to focus it back down to a centralized point

01:00:49.480 --> 01:00:50.520
where we're trying to get generality.

01:00:50.520 --> 01:00:52.560
I mean, I'm not gonna give it exact way you can do that,

01:00:52.560 --> 01:00:55.120
but this is like an intuitive concept, I think,

01:00:55.120 --> 01:00:57.080
to think about doing that.

01:00:57.080 --> 01:00:59.200
But the point I wanna make though is that,

01:00:59.200 --> 01:01:02.120
look, like some really great kinds of generality,

01:01:02.120 --> 01:01:04.160
the stepping stones are through specialists.

01:01:04.160 --> 01:01:05.840
What are we gonna do about that?

01:01:05.840 --> 01:01:07.360
Like, especially like us.

01:01:07.360 --> 01:01:08.600
Like you could claim that like,

01:01:08.600 --> 01:01:11.440
we're just gonna go straight to hypergeneralization.

01:01:11.440 --> 01:01:13.440
Like that's where we're trying to get our super generalists

01:01:13.440 --> 01:01:14.600
or something like that,

01:01:14.600 --> 01:01:16.440
by getting more and more and more and more general.

01:01:16.440 --> 01:01:18.520
Maybe you're right, like deep learning is magic,

01:01:18.520 --> 01:01:20.000
like we just add more data.

01:01:20.000 --> 01:01:21.000
It's not that simple though,

01:01:21.000 --> 01:01:22.320
because the fact that we're admitting

01:01:22.320 --> 01:01:24.200
we need a curriculum means we don't have the data,

01:01:24.200 --> 01:01:26.360
so we have to get it somehow.

01:01:26.360 --> 01:01:28.960
But you also have to just, there's something interesting,

01:01:28.960 --> 01:01:30.800
you have to admit there's something interesting

01:01:30.840 --> 01:01:34.480
about when hyper-specialization actually leads to generalization

01:01:34.480 --> 01:01:37.080
and this kind of paradoxical stepping stone principle,

01:01:37.080 --> 01:01:39.200
that the things that don't resemble what you want

01:01:39.200 --> 01:01:42.160
ultimately are the stepping stones that get you to it.

01:01:42.160 --> 01:01:45.320
And hyper-specialization is like a really powerful thing,

01:01:45.320 --> 01:01:46.680
because it allows you to drop,

01:01:46.680 --> 01:01:48.960
it allows you to make assumptions.

01:01:48.960 --> 01:01:50.960
Like you can assume something about the environment

01:01:50.960 --> 01:01:52.320
you're entering before you entered

01:01:52.320 --> 01:01:54.320
because you're a specialist in that environment.

01:01:54.320 --> 01:01:57.400
And I think that it can be a disability or a liability,

01:01:57.400 --> 01:01:59.440
like if you actually go into environments,

01:01:59.440 --> 01:02:01.720
having no assumptions whatsoever,

01:02:01.720 --> 01:02:04.200
so you have to be ready for all possible contingencies

01:02:04.200 --> 01:02:06.560
under the sun, that's what generalization means

01:02:06.560 --> 01:02:08.160
in a super general sense.

01:02:08.160 --> 01:02:10.200
Like would you want, you know, airline pilots

01:02:10.200 --> 01:02:12.560
to like not be sure whether they're flying a stunt jet

01:02:12.560 --> 01:02:13.760
or a passenger jet?

01:02:13.760 --> 01:02:15.480
Like they've got to do some checks upfront

01:02:15.480 --> 01:02:17.520
to see which scenario they're in.

01:02:17.520 --> 01:02:19.040
Like if you're just a passenger pilot,

01:02:19.040 --> 01:02:20.680
you don't do those checks.

01:02:20.680 --> 01:02:22.600
Like you know what you're doing.

01:02:22.600 --> 01:02:25.480
And so I think there's reason to talk more

01:02:25.480 --> 01:02:28.000
about this issue of like the specialization of poet

01:02:28.000 --> 01:02:30.240
is actually an interesting facet of it

01:02:30.240 --> 01:02:32.280
and not necessarily just like a liability

01:02:32.280 --> 01:02:33.600
that we have to get around.

01:02:33.600 --> 01:02:35.680
I've just thought of an interesting connection

01:02:35.680 --> 01:02:37.480
that hadn't occurred to me before,

01:02:37.480 --> 01:02:41.360
but there is a link between specialization and divergence.

01:02:41.360 --> 01:02:42.800
Because if you think about it at a general age,

01:02:42.800 --> 01:02:44.400
and that's the equivalent of the committee

01:02:44.400 --> 01:02:45.720
that you hate so much.

01:02:45.720 --> 01:02:48.560
And what you were just saying with evolution,

01:02:48.560 --> 01:02:51.600
starting with specialization actually allows you

01:02:51.600 --> 01:02:54.640
to explore many more interesting stepping stones.

01:02:54.640 --> 01:02:56.360
But the thing I want to get to you though

01:02:56.360 --> 01:02:59.080
is intelligence must be specialized.

01:02:59.080 --> 01:03:02.360
I mean certainly even in conceptions like AIXI,

01:03:02.360 --> 01:03:05.200
it's framed in terms of being able to perform tasks

01:03:05.200 --> 01:03:06.480
in certain environments.

01:03:06.480 --> 01:03:08.360
There's no such thing as general intelligence.

01:03:08.360 --> 01:03:09.760
So if you were an alien being

01:03:09.760 --> 01:03:11.480
and you came down to planet Earth,

01:03:11.480 --> 01:03:13.440
would you really see that much of a difference

01:03:13.440 --> 01:03:16.720
between our kind of intelligence and photosynthesis?

01:03:18.160 --> 01:03:20.760
So that is really interesting.

01:03:21.960 --> 01:03:24.840
It clearly originates from specialization.

01:03:25.040 --> 01:03:27.120
I don't think you can deny that.

01:03:27.120 --> 01:03:31.000
The explanatory apparatus are through specialization.

01:03:31.000 --> 01:03:32.320
Why is it what it is?

01:03:33.320 --> 01:03:34.920
It's related to the environment we're in.

01:03:34.920 --> 01:03:36.720
I mean, that must be true, obviously.

01:03:36.720 --> 01:03:40.600
So it has to do with optimizing within that environment.

01:03:40.600 --> 01:03:44.280
But I feel like what's going on is something to do with,

01:03:44.280 --> 01:03:49.040
from that specialization has emerged real generality.

01:03:49.040 --> 01:03:53.240
I feel like our intelligence is sufficiently general

01:03:53.240 --> 01:03:58.000
to move outside of anything in our environment at all.

01:03:58.000 --> 01:04:00.320
It gets to this question where people sometimes say

01:04:00.320 --> 01:04:02.280
that there are certain things we cannot understand.

01:04:02.280 --> 01:04:04.800
Like it's impossible, like as human beings.

01:04:04.800 --> 01:04:06.040
It's usually like, well, why can't we,

01:04:06.040 --> 01:04:07.480
why would there be things we can't understand?

01:04:07.480 --> 01:04:08.920
Well, it's like they're just so far outside

01:04:08.920 --> 01:04:09.760
of our environment.

01:04:09.760 --> 01:04:10.960
They have nothing to do with anything in the experience.

01:04:10.960 --> 01:04:13.840
I think, I don't really fall into that yet, but I think,

01:04:13.840 --> 01:04:16.560
I think we have the capacity to understand literally anything.

01:04:16.560 --> 01:04:18.640
Well, given enough information,

01:04:18.640 --> 01:04:20.240
like obviously we can't know about things

01:04:20.240 --> 01:04:23.040
that we can't actually observe at all.

01:04:23.040 --> 01:04:25.120
So we don't know those things.

01:04:25.120 --> 01:04:26.560
But like if I was given information,

01:04:26.560 --> 01:04:27.880
I believe I could understand the concept.

01:04:27.880 --> 01:04:30.480
Like I could understand where did the universe come from?

01:04:30.480 --> 01:04:34.000
If you told me what happened, like I think there is some,

01:04:34.000 --> 01:04:36.880
it has nothing to do with the kind of situation I come from.

01:04:36.880 --> 01:04:39.120
But I think I have the capacity to generality.

01:04:39.120 --> 01:04:41.440
So I think it's really interesting that,

01:04:41.440 --> 01:04:44.480
that like somehow a degree of generality

01:04:44.480 --> 01:04:47.760
emerged from this specialization, which goes beyond

01:04:47.760 --> 01:04:49.680
just being good in this environment.

01:04:49.680 --> 01:04:50.800
Could I distinguish though,

01:04:50.800 --> 01:04:52.960
because Jeff Hawkins made this point in his book as well,

01:04:53.040 --> 01:04:55.400
what's interesting about humans is for the first time,

01:04:55.400 --> 01:04:57.520
knowledge and genes have been separated.

01:04:57.520 --> 01:04:59.720
So I completely appreciate what you're saying,

01:04:59.720 --> 01:05:02.440
that we can understand the universe and everything in it,

01:05:02.440 --> 01:05:04.120
but our behavioral intelligence

01:05:04.120 --> 01:05:06.200
is still very much tied to our environment.

01:05:06.200 --> 01:05:08.400
I don't know whether you're familiar with James Lovelock

01:05:08.400 --> 01:05:09.880
and his Gaia theory.

01:05:09.880 --> 01:05:13.560
And he essentially thinks of all life on the planet

01:05:13.560 --> 01:05:17.240
as being kind of like an ecosystem or a meta ecosystem.

01:05:18.240 --> 01:05:21.040
So could you think of humans as just being a product

01:05:21.040 --> 01:05:23.040
of our environment in that same way?

01:05:24.320 --> 01:05:28.120
Is our intelligence limited by the environment we're in?

01:05:28.920 --> 01:05:33.760
I mean, we are, I do, our intelligence is,

01:05:33.760 --> 01:05:38.760
does, it has like some areas where it's more elastic

01:05:39.440 --> 01:05:41.720
than others, I guess, because of our environment.

01:05:41.720 --> 01:05:42.560
I think that would be true.

01:05:42.560 --> 01:05:44.040
Like there's some things that are easier to grok

01:05:44.040 --> 01:05:46.720
than other things, because the things that are easier

01:05:46.720 --> 01:05:50.040
to grok are more aligned with where we come from.

01:05:50.480 --> 01:05:53.440
And so that's like what conceptually we're adapted for.

01:05:53.440 --> 01:05:55.320
Like things like the difference between the third dimension

01:05:55.320 --> 01:05:56.720
and the fourth dimension.

01:05:56.720 --> 01:05:58.640
Like it's easy to reason in three dimensions.

01:05:58.640 --> 01:06:00.840
It's quite hard to reason in four dimensions.

01:06:00.840 --> 01:06:03.560
So we just aren't really adapted to that.

01:06:03.560 --> 01:06:05.240
Does it mean that I can't understand?

01:06:05.240 --> 01:06:06.760
I don't think it means I can't understand.

01:06:06.760 --> 01:06:09.960
But it's just not as flexible, it's not as elastic.

01:06:09.960 --> 01:06:12.040
And so I guess it's going somewhere in the middle.

01:06:12.040 --> 01:06:13.720
Maybe just a little bit of Keith's going to the middle.

01:06:13.720 --> 01:06:16.160
I don't, like, yeah, I don't think either extreme,

01:06:16.160 --> 01:06:18.720
like we were completely specialized.

01:06:18.760 --> 01:06:20.080
I don't think so.

01:06:20.080 --> 01:06:22.400
We're like absolutely like generalist

01:06:22.400 --> 01:06:24.280
in the most like flexible sense.

01:06:24.280 --> 01:06:26.640
No, we're somewhere in the middle.

01:06:26.640 --> 01:06:29.200
But I think that the toolbox we have is sufficient,

01:06:29.200 --> 01:06:32.640
I do believe, to ultimately capture anything.

01:06:32.640 --> 01:06:34.480
I do think we could do that.

01:06:34.480 --> 01:06:38.000
Yeah, so I would argue it's probably an open question.

01:06:38.000 --> 01:06:41.520
I think this may be a case where maybe you're being too certain

01:06:41.520 --> 01:06:44.800
because when you talk about like these dimensionality things,

01:06:44.800 --> 01:06:47.840
you know, I know there are many mathematical structures

01:06:48.000 --> 01:06:51.120
that exhibit very different, you know,

01:06:51.120 --> 01:06:54.080
fundamentally different behavior and say five dimensions

01:06:54.080 --> 01:06:56.240
versus six dimensions versus eight.

01:06:56.240 --> 01:06:59.360
And I think, sure, people have figured that out.

01:06:59.360 --> 01:07:02.080
And we did that by externalizing that intelligence,

01:07:02.080 --> 01:07:04.880
writing down symbolics, doing a bunch of equations.

01:07:04.880 --> 01:07:07.840
But I think it would be fair to say that no human being

01:07:07.840 --> 01:07:11.280
has ever claimed that they could grok that in their mind.

01:07:11.280 --> 01:07:14.640
Like they can do it by virtue of this externalized intelligence,

01:07:14.640 --> 01:07:18.320
but to really hold it in their brain and kind of intuit over it.

01:07:19.040 --> 01:07:22.800
You know, my guess would be there probably are limitations

01:07:22.800 --> 01:07:23.760
to what we can do.

01:07:23.760 --> 01:07:25.200
And that's one of the things that excites me

01:07:25.200 --> 01:07:27.040
about the potential for HEI.

01:07:27.840 --> 01:07:29.280
I don't know if we're going to get to it,

01:07:29.280 --> 01:07:32.480
but if we ever do get to it, it would be really interesting

01:07:32.480 --> 01:07:34.240
to see what it's capable of.

01:07:35.440 --> 01:07:38.080
Unshackled by the fact that it, you know,

01:07:38.080 --> 01:07:42.800
that we evolved in a three plus one dimensional environment,

01:07:42.800 --> 01:07:43.680
you know, to survive.

01:07:44.720 --> 01:07:46.320
Yeah, good points.

01:07:46.320 --> 01:07:47.760
Those are really good points.

01:07:47.760 --> 01:07:48.880
That's interesting to think about.

01:07:48.880 --> 01:07:49.600
Yeah, you're right.

01:07:49.600 --> 01:07:52.880
I hadn't thought of that angle about the AI has this potential

01:07:52.880 --> 01:07:53.840
to break out of that box.

01:07:53.840 --> 01:07:57.200
And that is an interesting thing about AGI.

01:07:58.320 --> 01:07:59.840
So yeah, okay, point taken.

01:08:01.520 --> 01:08:04.080
Yeah, so I am saying something extreme

01:08:04.080 --> 01:08:06.080
if I claim that we can understand everything.

01:08:06.080 --> 01:08:06.800
That is extreme.

01:08:07.760 --> 01:08:08.000
Right.

01:08:08.000 --> 01:08:09.520
I guess I'll still stick with my claim,

01:08:09.520 --> 01:08:12.320
but I might take a lot of effort, I guess.

01:08:12.560 --> 01:08:17.360
Well, the way I see it, and I think you may be right about this,

01:08:17.360 --> 01:08:18.640
at least from this perspective,

01:08:18.640 --> 01:08:22.400
is that it may well be the case that something like,

01:08:23.600 --> 01:08:27.360
you know, second order logic or category theory

01:08:27.360 --> 01:08:30.240
or these sorts of logics that we've already discovered,

01:08:30.240 --> 01:08:31.600
it may turn out to be the case

01:08:31.600 --> 01:08:33.520
that they're mathematically sufficient

01:08:34.080 --> 01:08:37.040
to describe any conceivable phenomenon

01:08:37.040 --> 01:08:39.200
that we'll observe in this universe.

01:08:39.200 --> 01:08:41.440
And so I guess I would say you could be right

01:08:41.440 --> 01:08:45.200
that our languages and our methods that we developed

01:08:45.920 --> 01:08:47.600
kind of externalized from us

01:08:47.600 --> 01:08:49.600
and something that we participate in

01:08:49.600 --> 01:08:52.640
have reached this kind of ultimate level of generality.

01:08:52.640 --> 01:08:54.240
I just think it's a little bit beyond

01:08:54.240 --> 01:08:56.240
what a single human mind,

01:08:56.240 --> 01:08:58.160
at least at this phase of our evolution,

01:08:58.160 --> 01:08:58.960
can comprehend.

01:09:00.160 --> 01:09:00.720
That's interesting,

01:09:00.720 --> 01:09:03.760
because that actually starts to go into this issue

01:09:03.760 --> 01:09:06.000
of what it means to understand.

01:09:06.000 --> 01:09:10.640
And this debate about do these AIs really understand

01:09:10.640 --> 01:09:14.000
and yeah, there's like different kind of levels of that.

01:09:14.000 --> 01:09:16.160
So it's true that when I say like,

01:09:16.160 --> 01:09:17.120
we can understand everything,

01:09:17.120 --> 01:09:18.800
it's a little unclear what I mean by understand.

01:09:18.800 --> 01:09:21.520
Like does it mean just apply the right logical language

01:09:21.520 --> 01:09:22.960
to describe the phenomenon,

01:09:22.960 --> 01:09:25.680
even though we don't really get that like flash feeling

01:09:25.680 --> 01:09:26.800
of like, wow, I really get it.

01:09:26.800 --> 01:09:28.880
And maybe that, maybe they're right.

01:09:28.880 --> 01:09:29.920
Maybe that is out of reach.

01:09:30.640 --> 01:09:31.920
Keith, why don't you just go and look up

01:09:31.920 --> 01:09:33.360
our definition of understanding.

01:09:33.360 --> 01:09:35.120
I can give you the definition of reasoning

01:09:35.120 --> 01:09:35.840
that we came up with,

01:09:35.840 --> 01:09:38.480
which is the ability to derive new knowledge

01:09:38.480 --> 01:09:40.240
from existing knowledge and experience.

01:09:41.600 --> 01:09:43.600
Right, but this reasoning thing is a big thing.

01:09:43.600 --> 01:09:45.840
Do you know when we say neural networks don't reason?

01:09:45.840 --> 01:09:49.360
A lot of it has to do with this notion of extrapolation.

01:09:49.360 --> 01:09:52.080
And people talk about the very geometric notion

01:09:52.080 --> 01:09:52.880
of extrapolation,

01:09:52.880 --> 01:09:56.640
but we're talking about being able to execute a function

01:09:56.640 --> 01:10:00.160
in some logical discrete space.

01:10:00.880 --> 01:10:03.440
So to be able to take something we know

01:10:03.440 --> 01:10:05.520
and extrapolate it into a new situation,

01:10:05.520 --> 01:10:06.720
spoken like Gary Marcus,

01:10:06.720 --> 01:10:09.200
and I'm sure you've had this conversation with Gary many times.

01:10:11.600 --> 01:10:13.360
Yeah, Gary has very strong feelings

01:10:13.360 --> 01:10:14.960
about understanding this, true.

01:10:16.320 --> 01:10:19.200
Yeah, very interesting feelings about that.

01:10:19.200 --> 01:10:21.040
So it just took me a bit to go look up

01:10:21.040 --> 01:10:23.440
because we did have some episode

01:10:23.440 --> 01:10:25.760
where we were really getting into defining

01:10:25.760 --> 01:10:28.400
some of these concepts with Gary.

01:10:28.400 --> 01:10:30.640
Right, and at least here's how I define these.

01:10:30.640 --> 01:10:32.720
So maybe we get your take on, it could be fun.

01:10:32.720 --> 01:10:36.080
So it's that reasoning is the act

01:10:36.080 --> 01:10:39.200
of deriving new knowledge from prior knowledge

01:10:39.280 --> 01:10:40.480
plus new information.

01:10:42.320 --> 01:10:45.200
Semantics, a mapping from structures,

01:10:45.200 --> 01:10:47.520
whether mathematical, logical, symbolic,

01:10:47.520 --> 01:10:50.720
or other structures to physical reality.

01:10:51.920 --> 01:10:55.520
And understanding we had as the act of deriving

01:10:55.520 --> 01:10:58.880
new semantic mappings from prior semantics

01:10:58.880 --> 01:10:59.760
plus new knowledge.

01:11:00.960 --> 01:11:03.040
That's esoteric, but that's how we defined it.

01:11:04.240 --> 01:11:07.280
So understanding is really was the ability to like,

01:11:07.280 --> 01:11:08.720
okay, if I have a world model

01:11:08.720 --> 01:11:10.720
that understands something about physics,

01:11:11.840 --> 01:11:16.800
that like gravity exists and balls roll and whatever,

01:11:16.800 --> 01:11:19.280
and somebody gives me some new knowledge,

01:11:19.280 --> 01:11:23.200
which says, hey, this ball is actually hollow.

01:11:24.240 --> 01:11:26.000
From kind of my understanding of physics,

01:11:26.000 --> 01:11:29.120
I can now, and I just use the word,

01:11:29.120 --> 01:11:32.080
because I understand this semantic model

01:11:32.080 --> 01:11:33.600
and you give me this new knowledge,

01:11:33.600 --> 01:11:36.320
I can now derive new semantics.

01:11:36.320 --> 01:11:39.440
I can say, well, the ball is gonna behave now in this way.

01:11:39.440 --> 01:11:42.400
In other words, I have a new mapping to this physical world

01:11:42.400 --> 01:11:43.680
because I've gained new knowledge.

01:11:44.560 --> 01:11:47.440
That's kind of the way in which we perceived understanding.

01:11:47.440 --> 01:11:50.320
So with like, this was in the context of natural language,

01:11:52.000 --> 01:11:53.920
you know, processing, let's say,

01:11:53.920 --> 01:11:56.400
or systems that do that, GPT-3 or whatever,

01:11:56.960 --> 01:11:59.600
because it doesn't have this semantic model of the world.

01:11:59.600 --> 01:12:02.880
If you say something like, the beer fell off the table,

01:12:03.600 --> 01:12:07.040
it may not be able to derive that now the floor is wet

01:12:07.040 --> 01:12:09.360
and somebody might slip if they fall,

01:12:10.160 --> 01:12:12.800
that that requires this kind of extra level of understanding.

01:12:14.160 --> 01:12:18.480
Yeah, and that's filling in the gaps as well.

01:12:18.480 --> 01:12:22.240
So a lot of NLU people say that the one thing

01:12:22.240 --> 01:12:25.200
neural networks can't do is extrapolate

01:12:25.200 --> 01:12:26.880
over the missing information.

01:12:26.880 --> 01:12:28.000
And that's a great example.

01:12:28.000 --> 01:12:30.800
So you could reason that we've just knocked the beer off the table,

01:12:30.800 --> 01:12:31.600
now the floor is wet.

01:12:32.320 --> 01:12:35.920
So there's a kind of exponential space of missing information

01:12:35.920 --> 01:12:37.360
that we need reasoning to fill in.

01:12:38.000 --> 01:12:43.920
Okay, I have to admit that I, it's probably disappointing you

01:12:43.920 --> 01:12:46.320
because I'm not, I don't really like definitions.

01:12:48.880 --> 01:12:52.080
I just never find definition discussions engaging

01:12:52.080 --> 01:12:53.680
are really helpful to me.

01:12:53.680 --> 01:12:58.160
I really, again, often find that appeal to definition

01:12:58.160 --> 01:13:01.280
is often just a way of escaping an uncomfortable situation.

01:13:01.280 --> 01:13:03.520
And I want to go towards the uncomfortable situation.

01:13:03.520 --> 01:13:04.960
So it's like, we often will say,

01:13:04.960 --> 01:13:06.960
well, no one's really clearly defined consciousness.

01:13:06.960 --> 01:13:09.040
Like, first, before I'm going to discuss it,

01:13:09.040 --> 01:13:10.960
you need to define it to my satisfaction.

01:13:11.760 --> 01:13:13.840
Well, okay, we're obviously not going to discuss it then.

01:13:13.840 --> 01:13:15.440
Like, I'll never satisfy you.

01:13:15.440 --> 01:13:16.320
Right, right.

01:13:16.320 --> 01:13:20.400
And so it's often in the AI, decades of discussion,

01:13:20.400 --> 01:13:21.280
what is intelligence?

01:13:22.480 --> 01:13:25.280
And we see it in open-endedness,

01:13:25.280 --> 01:13:27.680
we start having a problem, like in this small field,

01:13:27.680 --> 01:13:29.840
like there's open-endedness workshops that come

01:13:29.840 --> 01:13:31.360
and like half the papers were just like,

01:13:31.360 --> 01:13:35.440
what is long pages and pages of definition in terms.

01:13:35.440 --> 01:13:37.040
It's like, are we going to ever do anything?

01:13:37.040 --> 01:13:39.280
Or just we're going to argue about this for the next decade.

01:13:39.280 --> 01:13:40.960
Like, what are we even talking about

01:13:40.960 --> 01:13:41.920
is what we're going to talk about.

01:13:43.040 --> 01:13:46.240
And I feel like a lot of this is not necessary.

01:13:46.240 --> 01:13:48.400
I feel like I can talk about consciousness.

01:13:48.400 --> 01:13:50.160
I can't define it for you to your satisfaction.

01:13:50.160 --> 01:13:50.960
I can talk about intelligence.

01:13:50.960 --> 01:13:52.720
I can make progress on intelligence.

01:13:52.720 --> 01:13:54.080
I can talk about open-endedness.

01:13:54.080 --> 01:13:56.000
I don't care really what the definition is.

01:13:56.000 --> 01:13:57.840
It's just you're going to use it to stop me from talking.

01:13:57.840 --> 01:14:00.640
So the only thing I'll defend there is that, I mean,

01:14:01.680 --> 01:14:03.600
I, again, I'm a pragmatist.

01:14:03.600 --> 01:14:05.760
I believe in defining things to the extent

01:14:05.760 --> 01:14:07.760
necessary to communicate.

01:14:07.760 --> 01:14:10.400
And so we have to have, it's kind of like going back

01:14:10.400 --> 01:14:15.120
to the whole hyper-specialization leading to innovation.

01:14:15.120 --> 01:14:17.760
If you just have a divergent thing,

01:14:17.760 --> 01:14:20.160
I think I made this point in our first video,

01:14:20.160 --> 01:14:23.040
you're just going to end up with a universe of gray goo.

01:14:23.040 --> 01:14:25.040
Like the really fascinating thing is that

01:14:25.040 --> 01:14:27.440
because there are these constraints of you

01:14:27.520 --> 01:14:30.400
need to survive in order to pass on your information,

01:14:30.400 --> 01:14:32.880
you wind up with this kind of beautiful tapestry

01:14:32.880 --> 01:14:35.520
of hyper-specialized things that recombine

01:14:35.520 --> 01:14:37.280
to become more general.

01:14:37.280 --> 01:14:39.600
And, you know, it's far more interesting than either extreme,

01:14:39.600 --> 01:14:44.000
like either the gray goo or like the, you know, the nothing, you know.

01:14:44.000 --> 01:14:49.120
And so as far as definitions go, I think that I don't like

01:14:49.120 --> 01:14:52.080
to sit there and pedantically argue forever

01:14:52.080 --> 01:14:54.160
about what the definition of intelligence is,

01:14:54.160 --> 01:14:56.880
but we need to have enough of a definition

01:14:56.880 --> 01:14:58.960
that we can make progress in learning

01:14:58.960 --> 01:15:01.360
and kind of doing scientific discoveries.

01:15:01.360 --> 01:15:04.720
So things like the beer falls off the table and it's wet.

01:15:04.720 --> 01:15:08.560
Well, if a system can't figure that out,

01:15:09.600 --> 01:15:12.640
we notice that it can't figure out kind of a class of things.

01:15:12.640 --> 01:15:15.040
And that class of things has something in common

01:15:15.040 --> 01:15:17.360
and then we give it a name and maybe it's understanding

01:15:17.360 --> 01:15:18.800
or whatever, I don't care.

01:15:18.800 --> 01:15:22.400
But it's just a way of talking about that class of problems

01:15:22.400 --> 01:15:24.160
of things that it's not able to achieve

01:15:24.160 --> 01:15:26.560
because then we can try and figure out how to do that.

01:15:27.760 --> 01:15:31.040
Yeah, I think that the symbolists, though,

01:15:31.040 --> 01:15:35.200
that when they come up with formal arguments,

01:15:36.000 --> 01:15:38.400
it's not, that doesn't come first.

01:15:38.400 --> 01:15:41.680
They notice that neural networks can't do something,

01:15:41.680 --> 01:15:45.040
which is to say they can't fill in the missing gaps.

01:15:45.040 --> 01:15:48.080
And then they come up with a formalism to express why that is.

01:15:48.080 --> 01:15:50.000
And also, many of these symbolists believe

01:15:50.000 --> 01:15:53.520
that there are kind of platonic abstractions

01:15:53.520 --> 01:15:54.640
that exist in the universe.

01:15:54.640 --> 01:15:57.120
They think that mathematics is discovered, not invented.

01:15:57.920 --> 01:16:02.000
So that kind of formal apparatus

01:16:02.000 --> 01:16:03.600
is how they understand the world.

01:16:04.800 --> 01:16:07.520
Well, I feel like I should try to solidify my attack

01:16:07.520 --> 01:16:09.200
on definitions since it's obviously

01:16:09.200 --> 01:16:11.280
fairly, again, radical thing to say.

01:16:13.760 --> 01:16:16.560
I would acknowledge, like, in the sense that Keith is saying that,

01:16:17.440 --> 01:16:18.960
again, like, I don't want to be a prank.

01:16:18.960 --> 01:16:21.040
Like, obviously, you need to define some terms sometimes.

01:16:21.040 --> 01:16:22.240
Like, that's obviously clear.

01:16:22.240 --> 01:16:23.280
That should be completely clear.

01:16:23.280 --> 01:16:24.320
I'm not against that.

01:16:24.400 --> 01:16:28.160
Like, you know, especially, like, you're gonna derive something

01:16:28.160 --> 01:16:30.720
and you're writing a paper or you have a certain set of assumptions

01:16:30.720 --> 01:16:32.480
you need to know what they are, like, in order to prove

01:16:32.480 --> 01:16:33.760
that it actually is true and not true.

01:16:33.760 --> 01:16:36.720
If that's what you're trying to do, like, that makes total sense to me.

01:16:37.680 --> 01:16:40.560
So I'm not a blanket saying we shouldn't have definitions.

01:16:40.560 --> 01:16:42.640
But I think the thing about definitions that's interesting,

01:16:42.640 --> 01:16:45.680
like, a lot of things is that there just isn't solid ground.

01:16:45.680 --> 01:16:48.080
Like, in terms of, like, they're just generally good for you.

01:16:48.080 --> 01:16:50.480
Like, they can be good for you or they can be bad for you.

01:16:50.480 --> 01:16:52.320
They can be a tool of clarification

01:16:52.320 --> 01:16:54.080
or they can be a tool of obfuscation.

01:16:54.400 --> 01:16:56.160
And it depends how you use them.

01:16:56.160 --> 01:16:59.040
And I often find them to be tools of obfuscation.

01:16:59.040 --> 01:17:01.120
Like, especially when we're talking about things we don't know,

01:17:01.120 --> 01:17:03.040
which is, once again, the problem, which is what I'm interested in.

01:17:03.040 --> 01:17:05.120
I want to talk about things that we don't know.

01:17:05.120 --> 01:17:08.640
And that seems where people get really passionate about definitions.

01:17:08.640 --> 01:17:10.560
So it's like, what does it mean to understand?

01:17:10.560 --> 01:17:11.840
We don't know. I don't know.

01:17:11.840 --> 01:17:14.320
What I do know, though, I'm confident there's such a thing.

01:17:14.320 --> 01:17:15.280
There is understanding.

01:17:15.280 --> 01:17:18.160
It might be a continuum, maybe it's not just a binary concept.

01:17:18.160 --> 01:17:19.760
Beyond that, I don't really know what it means.

01:17:20.880 --> 01:17:23.120
And so I would be interested to talk in depth,

01:17:23.120 --> 01:17:24.320
like, what does this really mean?

01:17:24.320 --> 01:17:25.120
Like, let's look at this.

01:17:26.080 --> 01:17:28.880
But no, we have to, like, we just end up in this, like,

01:17:28.880 --> 01:17:30.480
a big argument about the definition.

01:17:31.440 --> 01:17:33.680
And I find that in that case, it's obfuscation,

01:17:33.680 --> 01:17:34.720
because it's fear.

01:17:34.720 --> 01:17:37.760
Because really, like, if your whole pitch is,

01:17:37.760 --> 01:17:40.720
like, your thing that you get a lot of traction on

01:17:40.720 --> 01:17:43.680
is basically attacking the fact that things don't understand,

01:17:44.560 --> 01:17:46.240
then you might be a little uncomfortable

01:17:46.240 --> 01:17:48.640
if we really start dissecting what you mean.

01:17:48.640 --> 01:17:50.880
And so you should just comment us and just tell us,

01:17:50.880 --> 01:17:53.040
like, hey, you're not even being clear in your terms.

01:17:53.600 --> 01:17:55.520
And just stop the argument in its tracks.

01:17:56.400 --> 01:17:58.240
And that's the kind of definition I don't like.

01:17:58.240 --> 01:18:00.560
I mean, I'd rather just, like, look, we agree there's,

01:18:00.560 --> 01:18:01.600
I don't know exactly what it is.

01:18:01.600 --> 01:18:02.720
You don't know exactly what it is.

01:18:02.720 --> 01:18:03.680
Let's talk about it anyway.

01:18:03.680 --> 01:18:04.400
It's uncomfortable.

01:18:04.960 --> 01:18:06.080
But there is such a thing.

01:18:06.080 --> 01:18:06.960
That's what we should agree on.

01:18:06.960 --> 01:18:08.160
Do we agree there's understanding?

01:18:08.160 --> 01:18:09.680
Like, is there anything that exists?

01:18:10.400 --> 01:18:11.760
Well, see, that's a problem is...

01:18:13.520 --> 01:18:16.000
Right, but that's a problem is you can run into some folks

01:18:16.000 --> 01:18:17.360
that will go that extreme and say,

01:18:17.360 --> 01:18:19.280
there's no such thing as intelligence.

01:18:19.280 --> 01:18:20.800
It's all just, yeah.

01:18:20.800 --> 01:18:22.560
So, but look, I agree with you in principle,

01:18:22.560 --> 01:18:25.200
which is, again, I like definitions

01:18:25.200 --> 01:18:28.720
insofar as they're necessary to enable communication.

01:18:28.720 --> 01:18:30.640
So I'm totally on board with the idea

01:18:30.640 --> 01:18:32.560
that we need to be talking about things.

01:18:32.560 --> 01:18:34.640
And that's why I kind of like say

01:18:34.640 --> 01:18:36.320
the coherence theory of knowledge

01:18:36.320 --> 01:18:38.000
because it acknowledges, look,

01:18:38.000 --> 01:18:40.800
we're never going to get to the foundation

01:18:40.800 --> 01:18:42.880
beyond which there's no other foundation

01:18:42.880 --> 01:18:43.680
that we can imagine.

01:18:43.680 --> 01:18:46.240
We just need to understand far enough

01:18:46.240 --> 01:18:48.720
and define things far enough that we can make progress.

01:18:49.600 --> 01:18:51.440
So, I'm a little bit...

01:18:51.440 --> 01:18:54.160
I can completely understand where you're coming from, Kenneth.

01:18:54.160 --> 01:18:58.480
You think that we have a fundamental fear of the unknown,

01:18:58.480 --> 01:19:00.720
and we're hiding behind our formalisms.

01:19:00.720 --> 01:19:04.640
And my only worry is that it seems

01:19:04.640 --> 01:19:06.400
a little bit anti-intellectual

01:19:06.400 --> 01:19:09.200
because you can make an observation

01:19:09.200 --> 01:19:13.520
that an AI model is not behaving the way we are.

01:19:13.520 --> 01:19:14.960
There's loads of assumptions there.

01:19:14.960 --> 01:19:16.960
We assume that we are behaving in a way

01:19:17.200 --> 01:19:21.200
and we are doing things the right way.

01:19:21.200 --> 01:19:23.520
But then you can say,

01:19:23.520 --> 01:19:26.240
oh, let's resist any formalism

01:19:26.240 --> 01:19:28.080
to try and break this down analytically.

01:19:29.600 --> 01:19:30.560
Do you see the conflict there?

01:19:31.360 --> 01:19:32.240
Yeah, absolutely.

01:19:32.240 --> 01:19:35.440
I mean, it's a dangerous position

01:19:35.440 --> 01:19:38.320
because it's clear that some formalism is necessary,

01:19:38.320 --> 01:19:39.440
like I tried to concede.

01:19:39.440 --> 01:19:41.840
I mean, I'm walking a tightrope.

01:19:41.840 --> 01:19:44.560
So it's not...

01:19:44.560 --> 01:19:45.760
Yeah, it can't be...

01:19:46.480 --> 01:19:48.160
I can't make this blanket claim

01:19:48.160 --> 01:19:51.280
that formalism needs to be completely thrown out the window.

01:19:51.840 --> 01:19:54.960
That would just destroy my credibility.

01:19:56.480 --> 01:19:58.320
But the point is...

01:19:58.320 --> 01:19:59.440
These are just pendulum.

01:19:59.440 --> 01:20:00.240
These are pendulum?

01:20:00.240 --> 01:20:00.960
What is the plural?

01:20:00.960 --> 01:20:01.520
Pendulums.

01:20:02.320 --> 01:20:03.040
These are pendulum.

01:20:03.040 --> 01:20:04.480
They swing in different directions.

01:20:04.480 --> 01:20:07.680
So we become so enamored with this,

01:20:07.680 --> 01:20:09.120
which is a useful tool,

01:20:09.120 --> 01:20:10.800
but to the point where it actually becomes

01:20:10.800 --> 01:20:12.480
like a form of obfuscation.

01:20:12.480 --> 01:20:14.400
And I do believe definition is like that.

01:20:14.480 --> 01:20:17.840
Definition is not always and it's not everybody.

01:20:17.840 --> 01:20:21.120
But a lot of the time when there's an uncomfortable issue,

01:20:21.120 --> 01:20:24.000
we immediately jump to definition to obfuscate.

01:20:24.000 --> 01:20:26.640
I think consciousness is one of the greatest examples of that.

01:20:26.640 --> 01:20:28.720
It's like there's clearly a mystery here.

01:20:29.920 --> 01:20:30.880
And I agree there are a few people

01:20:30.880 --> 01:20:32.560
who would disagree there's any mystery at all.

01:20:33.200 --> 01:20:35.120
But to me, it's clear there's a mystery.

01:20:35.120 --> 01:20:37.840
Don't need to have a definition to know there's a mystery.

01:20:37.840 --> 01:20:39.360
We could get into why it's mysterious.

01:20:39.360 --> 01:20:42.240
That's more interesting to me than what the definition is.

01:20:42.240 --> 01:20:44.320
But if you jump at me with this definition stuff,

01:20:44.640 --> 01:20:46.880
you're going to stop me from getting into that.

01:20:46.880 --> 01:20:48.320
I feel like that's pure obfuscation.

01:20:48.320 --> 01:20:50.080
This is one of the greatest unknown things

01:20:50.080 --> 01:20:53.040
in the entire scientific world, like consciousness.

01:20:53.040 --> 01:20:54.720
It's one of the greatest mysteries of all time.

01:20:55.840 --> 01:20:58.000
And like so, are you about definitions?

01:20:58.000 --> 01:20:59.440
Is that really where we're going to go with this?

01:21:00.320 --> 01:21:01.680
Maybe we don't have a good definition yet

01:21:01.680 --> 01:21:03.440
because we don't even know what we're talking about.

01:21:03.440 --> 01:21:04.960
That's part of why it's so mysterious.

01:21:06.000 --> 01:21:07.280
I think this is quite interesting though

01:21:07.280 --> 01:21:08.320
because with consciousness,

01:21:08.320 --> 01:21:10.480
we clearly don't have a mental apparatus.

01:21:11.360 --> 01:21:13.440
You know, like for example,

01:21:13.440 --> 01:21:15.520
if someone just took some hallucinogenics

01:21:15.520 --> 01:21:19.360
and they just had a completely crazy visual experience,

01:21:19.360 --> 01:21:21.120
they wouldn't have any words

01:21:21.120 --> 01:21:23.680
or any mental framework to hang this off.

01:21:23.680 --> 01:21:25.680
Whereas when we're talking about an apparatus

01:21:25.680 --> 01:21:27.440
to describe intelligent behavior,

01:21:27.440 --> 01:21:30.720
we absolutely do have an apparatus to hang things off.

01:21:30.720 --> 01:21:34.640
So I guess, is that a spectrum in your mind?

01:21:37.440 --> 01:21:38.640
Yeah, there is a spectrum.

01:21:39.040 --> 01:21:45.280
I would also concede that with consciousness,

01:21:46.320 --> 01:21:49.280
yeah, it's true that it's much worse for us.

01:21:49.280 --> 01:21:50.960
It's true because it's ineffable,

01:21:50.960 --> 01:21:53.200
which is another way of saying you can't put it into words.

01:21:53.200 --> 01:21:55.520
Like all the things we're discussing have no words.

01:21:56.480 --> 01:21:57.920
Like the blueness of blue.

01:21:57.920 --> 01:21:59.440
Like I can't actually describe it.

01:21:59.440 --> 01:22:01.520
You can't break it down into parts or say what it is.

01:22:02.560 --> 01:22:04.240
And so that makes it extremely difficult

01:22:04.240 --> 01:22:06.320
like to actually get into anything formal about it.

01:22:07.040 --> 01:22:10.080
Whereas intelligence, I would grant that you can,

01:22:10.960 --> 01:22:13.120
to some extent, like you can actually point to things

01:22:13.120 --> 01:22:17.760
that can be reduced to words or symbols or formalism.

01:22:18.640 --> 01:22:21.760
And so it's a little bit better on that slippery slope.

01:22:21.760 --> 01:22:24.080
It's higher up and less dangerous.

01:22:25.040 --> 01:22:27.920
But still, I think it's still on a slippery slope.

01:22:27.920 --> 01:22:29.840
Like there's, I don't think we,

01:22:29.840 --> 01:22:32.000
although we can talk about intelligence

01:22:32.000 --> 01:22:33.680
more easily than consciousness,

01:22:33.680 --> 01:22:36.800
I still don't think we really fully grasp this either

01:22:37.520 --> 01:22:40.240
or really have the words to really get at what we're talking about.

01:22:40.240 --> 01:22:41.600
We don't understand ourselves well enough

01:22:41.600 --> 01:22:42.880
to understand what we're talking about.

01:22:43.840 --> 01:22:47.600
And so it's, there's still a little bit of this room for obfuscation

01:22:48.480 --> 01:22:51.600
where we fail to address the mystery itself

01:22:51.600 --> 01:22:53.920
by just deciding to focus on the definition.

01:22:56.160 --> 01:22:59.200
Yeah, I mean, I think if we did understand it

01:22:59.760 --> 01:23:00.960
or had a clear definition,

01:23:00.960 --> 01:23:04.240
you know, we wouldn't be having so many interesting papers coming out,

01:23:04.240 --> 01:23:06.320
like on the measure of intelligence.

01:23:06.320 --> 01:23:09.680
And that was the thing that I liked about Chile's paper is,

01:23:10.560 --> 01:23:14.240
hey, as long as it's an operationally useful measure,

01:23:14.960 --> 01:23:16.160
then that helps us.

01:23:16.720 --> 01:23:19.520
It turns out, while it's kind of a nice framework

01:23:19.520 --> 01:23:22.080
to think about things, there isn't yet a measure of it,

01:23:22.640 --> 01:23:25.520
you know, kind of working on that and he's working on that.

01:23:25.520 --> 01:23:27.840
But again, I love the idea that we just,

01:23:28.720 --> 01:23:31.040
you know, the goal here, like you said earlier,

01:23:31.040 --> 01:23:32.800
is really to talk about things.

01:23:32.800 --> 01:23:35.040
You know, it's to communicate, it's to learn,

01:23:35.040 --> 01:23:39.440
it's to make progress, it's to explore and to some degree,

01:23:39.440 --> 01:23:41.280
to make life better, to exploit.

01:23:41.280 --> 01:23:45.600
But it's all about just doing almost the minimal necessary

01:23:45.600 --> 01:23:49.840
to enable communication and exploration, I think.

01:23:52.000 --> 01:23:53.600
Yeah, yeah, yeah.

01:23:53.600 --> 01:23:54.880
So I totally agree.

01:23:55.440 --> 01:23:57.440
Like the ultimate point is to explore.

01:23:58.240 --> 01:24:03.120
And yeah, I just like to go to places that are ambiguous,

01:24:03.120 --> 01:24:04.800
like on purpose for something.

01:24:04.800 --> 01:24:06.320
I feel like that's what we're supposed to do,

01:24:06.320 --> 01:24:08.320
like if we're talking about science or art,

01:24:09.440 --> 01:24:11.840
those are like the really interesting uncomfortable places

01:24:11.840 --> 01:24:12.720
where you're going to learn something.

01:24:12.720 --> 01:24:14.320
It's almost like how in physics,

01:24:14.320 --> 01:24:19.040
physicists always want to go to where two great theories collide

01:24:19.040 --> 01:24:20.800
and nobody knows what happens.

01:24:20.800 --> 01:24:23.040
Like what happens at the surface of a black hole

01:24:23.040 --> 01:24:26.320
where quantum mechanics and general relativity collide.

01:24:26.320 --> 01:24:28.560
There's a lot of unknown and ambiguity there.

01:24:28.560 --> 01:24:30.480
That's where the real progress is going to come from.

01:24:31.120 --> 01:24:34.480
You're sitting right on the boundary of chaos and order.

01:24:34.480 --> 01:24:37.200
You're trying to straddle that straddle line.

01:24:37.200 --> 01:24:38.320
Exactly, exactly.

01:24:39.280 --> 01:24:42.560
Well, Professor Kenestan, it's always an honor.

01:24:42.560 --> 01:24:44.000
Thank you so much for joining us.

01:24:45.040 --> 01:24:45.520
Thank you.

01:24:45.520 --> 01:24:46.080
That was super fun.

01:24:46.080 --> 01:24:46.560
Thank you.

01:24:46.560 --> 01:24:47.200
Thank you so much.

01:24:47.200 --> 01:24:47.840
Thank you so much.

01:24:47.840 --> 01:24:48.240
Amazing.

