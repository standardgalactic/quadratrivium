{"text": " Previous generations of the model have been weak reasoners, but they do reason. In the same way that hallucination was an existential threat to this technology, no, we'll never be able to trust this stuff. There are hundreds of millions of people using this techno, and they trust it. It's actually useful for them. We're making very good progress on the hallucination problem. I think we'll make very good progress this year and next on Reasoning. Here we are again, another episode of MLST. Today with Aidan Gomez, the CEO of Coheir. Now, I interviewed Aidan in London a couple of weeks ago just after their build event and after Aidan did his presentation, I sat him down for an hour and I gave him a grilling. And he was such a good sport for being so transparent and authentic. This is the difference with Coheir. They say it like it is. There's no bullshit. There's no digital gods. There's no super intelligence. They're just a bunch of folks solving real world business problems. Their models are incredibly good for a true vlogmented generation, for multilingual. But they also have some serious challenges that they need to overcome. We spoke about the AI risk discussion, where the language models take away our agency, how he's dealing with policy, right? So on the one hand, he's talking with governments, trying to get them to allow startups to be more competitive, to innovate. But at the same token, he's also very concerned about some of the societal risks of AI. So that's quite an interesting burden and juxtaposition that he has to hold in his mind. We spoke a lot about the company culture at Coheir. Now, I'm very impressed with Coheir. All of the people I've spoken to have been very smart, just really nice people. And how has he cultivated that culture? He was very frank and transparent about some of the mistakes he made early on as a CEO. So yeah, plenty to get your teeth into. I hope you enjoy the conversation. For Coheir, I think we're a little bit different than some of the other companies in the space, in the sense that we're not really here to build AGI. What we're here to do is create value for the world. And the way that we think we can do that is by putting this tech into the hands of enterprises so that they can integrate it into their products, they can augment their workforce with it. And so it's all about driving value and really putting this technology into the hands of more people and driving productivity for humanity. Aiden, welcome to MLSD. It's an absolute honor to have you on. Thank you so much. Appreciate it. There's a bit of a last mile problem with large language models, so you folks have created this incredible general technology. But when enterprises implement it, they have a whole bunch of legislative constraints, security constraints. Yeah, yeah, I think there's loads of barriers to access. Privacy to policy to just the familiarity of the teams with the tech, it's brand new. And so they haven't built with this technology before and they're still getting up to speed with the opportunity space, what they can do with it. That being said, people are so excited about AI and its opportunity that the motivation and the will is there to overcome a lot of these hurdles. So we're trying to help with that as much as we can, whether it's like our LMU education course to help general developers get up to speed on how to build with this stuff or us engaging at the policy level to make sure that we have sensible policy and not over-regulation or regulation that hurts startups or encumbers industry in adopting it. So we're trying to pull the levers that we can to help accelerate the adoption and make sure that it gets adopted in the right way. But yeah, no, it's definitely the past two years have been a push. There's a lot of stuff slowing down adoption that I would love to see eased. I think the tools need to get better, easier to use, more intuitive, more robust. Prompt engineering is still a thing. It shouldn't be right. It shouldn't matter how you phrase something specifically. It should be, the model should be smart enough to generally understand your intent and take action on your behalf reliably. So even at the technological layer, I think us as model builders, we have a lot to do to bring the barriers down. But I'm optimistic, like the pace of progress is fantastic. Yes. On that kind of prompt Britonist thing, I wonder whether you think that we are on a path to have it. I mean, in an ideal world, the model and the application would be completely decoupled. So you could swap the model out or when you folks bring out a new model, we can just swap it out and nothing breaks. But at the moment, that's not the case. But as the models become increasingly better, do you think they will be robust in that way? They should be, right? There will always be quirks to different models because we're all training on, you know, we hope different data that focuses on different aspects or elicits different behavior in the model. So there will always be quirks to the behavior of models, the personalities of models, what they're good at and bad at. But in general, in terms of like following an instruction, we should be quite robust to that universally. And so the ideal is that, yeah, you can just take a prompt and drop it into any system and see which one performs best and then move forward with that one. In reality, the status quo is a prompt that works on one system, fundamentally does not work on another. And so there's this rift or these walls in between systems that make them very, very different. Hopefully that'll start to lift. There's a lot of effort going into data augmentation that makes these models more robust to changes in prompt space. We're doing a lot of work on that. It's driven a lot by synthetic data and finding, doing search to basically find the prompts or the augmentations that changes to prompts that break the model and then training to fix that break. So I'm optimistic that sort of brittleness is gonna go away. Interesting. So kind of finding problems with the model and then robustifying and robustifying. In doing so, how does that change the characteristics of the model? Does it make it less creative or less capable in some sense? I mean, what do you ever feel for the trade-offs there? Yeah, I mean, I don't think so. I think that that's orthogonal. The process of making it more robust is orthogonal to creativity. There are aspects of the post-training procedure that do reduce creativity or, you know, some people like to say like lobotomize the model. So it's definitely a problem. It's something that we watch for and we're trying to prevent. I would say that one of the most disappointing aspects of the current regime of building these models is that a lot of people train on synthetic data from one source, right? Like just from the GPT models. And so all of them, all of the models that are being created, they sort of speak the same. They kind of have the same personality and it leads to this collapse into a lot of different models looking and feeling the same. And that makes them boring because like you have the same shortcomings across models rather than if you have a diverse set of models that have different failures in different places, you can much better address, you know, the preferences of much more people. I've noticed due to synthetic data taking off, just a total collapse in terms of the different types of behavior models exhibit and that cohere because our customers are enterprises. Like that's who we sell to. It's not consumers, it's not, you know, anything other than enterprises who want to adopt this tech. And they're very, very sensitive to what data went into the model. And so we exclude other model providers, data, you know, very aggressively. Of course, some will slip in as we're scraping the web, et cetera. But we make a very concerted effort to avoid other model outputs. And so if you talk to our model, when we release command R and R plus, one of the things I kept reading on Reddit and Twitter was it feels different. Like something feels special about this model. I don't think that's any like magic at cohere other than the fact that we didn't do what the other guys are doing, which is training on the model outputs of OpenAI. I agree with you. So when people, you know, see chat GPT or whatever for the first time, that they're blown away by it. But there are motifs that come up again and again and again, unraveling the mysteries, you know, delving into the intricate complexities or blah, blah, blah, blah, blah. And when you start to see these patterns and these constructions, you just start to think, oh, I don't like this very much because you start to see through it. It's a little bit like, you know, when you start to see through someone, they're not interesting anymore. And I haven't seen that with cohere, but I have seen it with many of the other models. Now, my intuition was always, I don't, I haven't really formed this very well, but I thought that maybe it could come from just the kind of data sets that we're using, or maybe it could come from the preference fine tuning. Are you saying that that monolithic effect is because they're kind of eating each other's poop? Yeah, no, yeah, yeah. It's some sort of like human centipede effect. I think, yeah, they're training on the outputs of a single model. And so it's all collapsing into that model's output distribution. And so if that output distribution has quirks like saying the word delve a lot, then it's gonna just pop up all over the place. And people will take it for granted that, oh, I guess LLMs just behave like this, but they don't have to. They don't have to. It's interesting how subjective creativity is as well, because a lot of people thought that it was creative a couple of years ago. And then when you see it everywhere, it's not creative anymore. So it needs to be novel to be creative. But I mean, you folks have just released the command R series of models and you've blown everyone away. Tell me about them. But if you wouldn't mind also, why did it take you a while to catch up and get state of the art performance? Yeah, we spent a lot of 2023 lagging. I think that that is accurate to say. What we were doing was sort of reorganizing internally. We were rebuilding the company, rebuilding the modeling team, the tech strategy and preparing for the runs that led to command R. It was clear to us that the process that we had used to build the first command and generations before that, it wasn't working. It wasn't gonna scale. And so we just rethought the entire pipeline. And it took us a while to rebuild things, run the experiments that we needed to run in order to make decisions on what the design of this new model building engine would look like. And then it takes time to do the runs. We spent a lot of last year doing that. But I think the results speak for themselves. And also with command R and R plus, it's just the first step in a series of new models that we wanna produce. We're very excited to lean into specific capabilities. And so while the general language model improvements, they're super important. They're crucial, right? Like the models have to get smarter. They have to get more capable. And we'll continue to press on that direction. We care about narrowing our focus a bit more. And so for 2024, even with the command R series, we focused in on rag and tool use. I think you're gonna see a continuation and extension of that focus really making these models robust at the key capabilities that enterprise cares about, that will drive productivity, that will automate really sophisticated processes that today, as humanity knows it, is only the domain of humans. We really wanna go after that. And give our models the ability to help in those spaces. Is it fair to say that, I don't know whether you feel that the general large language models are saturating. Maybe you could comment on that first, but if you do think that, does that give me a bit of a read that there's a move towards specialization of the models? I don't think they're saturating. I think they're getting so good that it's hard to see the incremental improvement. But that incremental improvement is extremely important. So once the models are smarter than you, it's really hard to, in a domain, in medicine, like Coher's model, it knows more than I do about medicine, for sure. Just absolutely. And so I can't really effectively assess whether we're improving in that dimension. I can't tell anyone. It's smarter than me. I trust it more than I trust myself to diagnose symptoms or process medical data. And so I'm not equipped to do that. Instead, what we need to do is create data sets or go out and find people who are still better than the model at those domains. And they can tell me whether it's improving. But for us, like the general population, at some point, we kind of stop seeing improvement between model versions. It's harder to feel. And you need to really zoom in to a place that you're an expert and that you know previous generations failed to see the progress. I think about it sometimes as like painting in a canvas of knowledge. And at some point, the holes in the canvas become so small. You have to take out a microscope to actually see it and paint it in. We're sort of in that part of the space for these models. And so improvement becomes much harder for us, the model builders, but it's much harder to feel and see for users who aren't diving in very close to analyze performance. I don't think it's saturating. I think it's still making, we're still making very significant progress. I do think the past 18 months, maybe a little bit less than 18 months. Yeah, the past 18 months, 12 months, we've been compressing. So we built these massive, giant, multi-trillion parameter models, which were just extraordinary artifacts of intelligence and capability. And we realized it's impractical. You can't actually put this thing into production, right? Like it takes 60, a 100s to certainly, it just, we could not productionize this. The economics don't work out. And so then we spent the year compressing those massive models down into much smaller form factors. There's very likely going to be a series of re-expansion and scale, both on the model scale in terms of parameters, but also data scale and data quality. And that's being supported by much better synthetic data methods that find much more useful synthetic data that are quite compelling at search to discover, to automatically discover weak points of models and then close those gaps. So I think we've, over the past year, gotten very good at making models more efficient. And we've created new methods that let us sort of just like plug in compute and data and have the model continuously improve. You've used words like smart and capabilities. And if you think of smart as knowledge, I completely agree with you. I think knowledge is a living thing. We're all improvising and we are generating new knowledge all the time. And it just increases exponentially. And there's no reason why language models can't become more and more and more knowledgeable because we just acquire more and more data. And in that sense, a medical doctor is smarter than me in that domain because they have the knowledge that I don't have. But some people could say that intelligence is something a little bit more abstract than that. It might be the ability to build models. It might be the ability to reason. It might be the ability to plan. And this is when we get into the kind of the age your own thing. So how do you demarcate those things? Are you saying that the models are becoming more knowledgeable but they're not necessarily becoming more intelligent like we are? I think reasoning is crucial to intelligence. I think that these models can reason and that's a controversial claim. I think a lot of people would debate that. A lot of people would make the claim that the architectures we're using or the methods we're using don't support that sort of behavior. I think that previous generations of the model have been weak reasoners, but they do reason. And it's not a discreet, does it have this capability or not? It's a continuum of how robust the reasoning engine inside these models is. We're getting much better methods for improving reasoning generally. We're getting much better methods of eliciting that behavior from the models and teaching them how to do it and apply it to many different domains, whether it's math, whether it's decision-making tasks, breaking down tasks, planning how to execute them. Those were key missing capabilities that were quite weak in previous generations of models, which are now starting to emerge in a significantly more robust fashion. And so in the same way that hallucination was it used to be an existential threat to this technology, no, we'll never be able to trust this stuff. There are hundreds of millions of people using this techno and they trust it. It's actually useful for them. They use it because it's useful to their job. We're making very good progress on the hallucination problem. I think we'll make very good progress this year and next on reasoning. I think it's just a capability, a skill that the model needs to be taught. And we're building the methods and data and techniques to support teaching, teaching these models. Yeah, it is interesting how you can kind of break intelligence down to all of these things and some you might argue are missing now, like planning, creativity is an interesting one. Agency is quite an interesting one. And presumably as a thing has more understanding and it has more autonomy, it could in principle develop agency at some point in the future. But you think of these things as skills. Could you give any hints to how you've moved the needle on this? So the knowledge thing, it seems to me that you would just get more data and curate and refine the data. But could you give any hints on how you've made it better at reasoning, for example? Yeah, with knowledge, I think it's about augmentation with RAG and better modeling techniques, cleaner data sets so that you remember the right stuff and don't retain the less relevant stuff. Those are the techniques that move the needle there. With reasoning, there are like circuits that you really need to bake in to the model. You need to show it and demonstrate it, how to break down tasks at a very low level, think through them. And that's stuff that's not actually that abundant on the internet. So it doesn't come for free using our previous techniques of just scrape the web and train the model and scale up. People don't usually write out their inner monologue, right? They usually write the results of that inner monologue. And so it's something that the model has been missing a view into. I think synthetic data will go a long way in closing that gap and supporting building multi-trillion token data sets that actually demonstrate how to have an inner monologue, how to reason through things, how to think through problems, make mistakes, identify mistakes, correct them and retry. That sort of long thought process data is actually extremely scarce. It's very rare. It's very rare. It's really hard to find. You can find it on the internet, of course. Stuff like forums where people help each other with homework and sort of break down. This is how I arrived at this answer. But when you look at the internet in totality, those are like pinpricks on the surface of this thing. And so pulling that forward, emphasizing it, augmenting it, producing more of that data should be a key priority if you're gonna actually teach these models to exhibit that behavior. Is there a trade-off between, I mean, for example, we could use the Unreal Engine to generate lots of visual training data for a Vision Foundation model. Or an alternative would be we could have like some kind of hybrid prediction architecture where we somehow encode naive physics into the architecture itself, which means rather than memorizing lots of generated data, we just kind of build a hybrid architecture. Is that a trade-off that you're kind of thinking about? Like specifically with the video side of things where physics is relevant, I think that's a totally fine strategy. I think that, yeah, a lot of the physics engines that people have built are, they're flawed, right? Like video games still don't look like reality. They still don't behave like reality. And so training off of that data, I think will leave you in a really unsatisfying place. Like there's just still some Uncanny Valley weirdness to it. I think like we have tons of actual video data of the real world where physics is definitely implemented and being represented completely accurately. And so that should be our go-to source. I think trying to use simulators at this stage is the wrong approach. I think you should take as much data from the real world as you can and use that as a bootstrap to then build synthetic data engines that help you iteratively improve. It's what happened in language as well, right? Like we didn't go to synthetic language, rules-based synthetic language generators to teach our language models, the basic principles of language using our linguistic models that we've built. No, we threw all that away. We took actual language data from humans, trained on that, and then used the models that were the output of that to improve iteratively and via experimentation. I think the same will be true in vision. That's a really interesting point, actually. Because with the SORA model from OpenAI, it does look a bit weird. It looks like it's always flying and it looks very game engine-like. And the language example is beautiful. But what about something like mathematics? Are there examples where rather than kind of, you know, perturbing or mutating what already exists, you might just start from first principles and rules? Totally, yeah. Like mathematics is so explicitly rule-driven and so explicitly verifiable. It's like the perfect example of synthetic data generation. I think it's definitely one of the domains that will crack first. And on top of that, code, right? You can completely, synthetically generate code, verify it. Does it run? Does it produce the outputs that you want on a test set? So when it is that explicit and verifiable, it's perfect for synthetic data generation, like just ideal. Yeah, but I guess this is kind of what I'm thinking about. That with code, you can actually constrain it way more than language. So you could, rather than using an existing self-attention transformer, you know, you might want to have something that only works on trees or whatever. And maybe that would work better for that particular thing. But then I guess we'd have to have some kind of mixture of experts and not have a single model. Yeah, I think that's behind the scenes actually, a lot of the strategy. You'll likely have an MOE where one component, one of those experts is gonna be an expert in code, very highly specialized to that. Heavily upsampled on synthetic code data and real code data, math, et cetera. And that expert will act as a general reasoning engine and will be very good at logic and those sorts of components. You might have a medical expert, which has dramatic upsampling along that axis. Yeah, I think that's a very effective path towards even more efficient models. So if you're in the medical domain or the math or code domain, you can then pull out that expert and use it independently. You don't need to keep around this huge monolithic model. You can just take out a sub-component and deploy that. Yeah, I think that architecture already exists. Yeah, I wonder if you can talk to that a little bit because I'm very excited about that because it now seems that maybe we could call what you just described an agentic distributed AI system where the agents can pass messages to each other and one of them might be an expert in mathematics, one of them might be an expert in coding or so on. But then you've got this problem that you kind of send a message into the nexus and all of the models are kind of passing messages to each other and it's kind of unbounded in runtime as opposed to one of the great things with the language model is it just does a fixed amount of compute per iteration. You just put some prompt in and you get the answer straight back out. So does that kind of unboundedness introduce problems? I mean, a language model could just generate infinitely and not produce a stop token and you would go on forever. So I think the problem already exists and models are quite well-behaved in terms of, if you train them to give up and to say, I need to respond, they will. They tend to. So I'm not too concerned about like, runaway processes that would just not be useful as well, hugely computationally expensive. And yeah, it seems like models can produce stop tokens. And I think that even in a multi-agent scenario, discourse between agents will conclude itself in a reasonable amount of time. Yeah, interesting. And I think even now with your multi-step tool use, that's basically what you've done. You could in principle do that recursively and you could constrain the computation graph so that there's no cycles and it comes back in a fixed amount of time. Yeah, we terminate execution after some number of failed attempts. So it's easy to solve that way. It's a little bit unsatisfying. I think our multi-optimal use right now, it's our very first pass. It's like the negative one. And so it's not that good at catching when it's made mistakes. It's not that good at correcting its mistakes, even if it's caught that it fucked up. And so I think we're still very early there, but those systems are gonna start to become extremely robust and reliable. And I'm very excited for that. Amazing. So I'm interested to know from, in your own words, how, I mean, we're just talking to you folks who've got this forward engineering team, your enterprise focused, you're helping bridge the last mile problem and really embedding yourselves into large enterprise, which is an amazing differentiator. But other than that, there's always the question, lots of people say these models are just kind of interchangeable and you're just kind of playing the token game at some point. And I just wondered like, what's your plan there? I agree with that sentiment. Models are way too similar. I think there's going to start to be differentiation between models. Like I was talking about before with command R and R plus, we're going to start really focusing in on key capabilities. The general language model game is, there's a lot of players and it's pretty saturated. I think people are gonna start to have to branch out. I think that consumer language models are going to separate away from enterprise language models. Within enterprise, there's gonna be a lot of specialization into specific domains. And so for Cohere, what I want to see us do is in product space, push into more tailored capabilities for particular problems. We want to drive value for enterprise and different enterprises operated in different spaces and they have different needs. The tools that their models might need to use look very different from one another. And we want to make sure that we're serving each of those niches particularly well or uniquely well. And that will be our value proposition differentiated from others. So that notion of specialization or enhanced capability in particular domains is something that we definitely want to explore at the product level and start to offer. Because like you say, the dollar per token space, it's super, we're not gonna stop that. It's important for the community, right? Like folks need to build on top of this. They need access to good models at fair prices. So we're gonna continue to give that to the world. But we want to create differentiated value. And I think that's gonna come from focusing on the actual problems that enterprises want to tackle and getting extremely, extremely good at them. Interesting. On that, are you planning kind of horizontal products or vertical products? And the reason I say horizontal is I know a few startups now that are building kind of low code, app dev platforms with large language models and they're making it incredibly easy in the enterprise to compose together different models and to deploy applications on phones. And it's really democratized because it's so much easier now for people to do artificial intelligence. That would be a good example of like a horizontal one, I guess. So I think our product right now is super horizontal, right? It's like general language models, embedding models, re-rank models. It's a platform that's deployable privately on every single cloud. You can deploy the model against any sort of data, whether it's medical, finance, legal, it doesn't matter. It's the most horizontal product and platform you can build. What we're gonna start to do is more towards verticalization and so specializing models at particular problems or objectives that exist in the world and offering a product that solves that for the enterprise. Would you ever go beyond the model and kind of plug a little bit deeper into the platform in the enterprise? So for example, building operating models or one approach would be to just fine-tune the model on lots of data from a particular domain, but it's still a language model. The interface with Coheir is the same or another one would be to let's say build something a little bit like Databricks or Snowflake or something like an enterprise-wide suite that allows you to deploy, discover, create, share artificial intelligence in an enterprise. The only reason I say that is as you're an AWS, they give you free credits. They want you to get on their platform because they know you're never leaving because you've got something there which is not easily replaceable. People learn how to use it, they love it. Would that be a potential future? Yeah, it's definitely still going to be a platform, customizable, something that the user, which for us as an enterprise can adopt and sort of bring into their environment, hook in their data, their tools, their whatever they want to plug in. The verticalization is gonna come from investing in the model to be good within a particular domain. That might mean fine-tuning on data within that domain. That might mean making sure the model is very good at using the tools that employees operating in that domain would use. But that's our focus. It's starting to get more specific and focused on the actual use cases that enterprises care about and not just doing, you know, version 345 of the same general model. So I saw you tweeted about Nick Bostrom's Future of Humanity Institute shutting down. Do you have any thoughts on that? Yeah, I think it sucks to see any sort of academic institute collapse. To be honest, I know nothing more than what's public there. So I don't know if there were some internal issues that caused the philosophy department to pull funding. But I've been a pretty vocal critic of ex-risk and the idea that language models are going to take over the world and kill everyone. But despite that, I still want people thinking about that. I still want academics thinking about that. I don't think that regulators and policy folks should be thinking about it yet because it's so far away and remote and potentially completely irrelevant. But that's the domain of academia, is to pursue those long horizon, high risk projects and make progress on them. And so I certainly don't want to see the academic front of that effort get defunded. That being said, I think that those organizations have really been trying to get their hands into policy and impact private sector, public sector in a way that is threatening to progress, misleading and so I think that we're starting to have within our community, like the AI machine learning community, a bit of a correction. Those people were kind of given a lot of power, were listened to a lot and developed what I think we all recognize as too much influence. And it started to produce bills and talks about policy that would totally collapse progress in the space, very, very prematurely about theoretical long-term risks that might be an issue. And so fortunately, I think there's a cultural correction happening where even the legislators and policymakers are starting to say, you know, this is not, it's not appropriate the level of influence that this one group is having and we should listen to a much more broad and diverse set of opinions. So I'm still concerned about that and I'll continue to speak out against that when I see it, but at the academic level, I don't want to see, you know, professors lose their funding. I think that they should continue to pursue those ideas. Yeah, I think Bostrom blogged that. He was trying to resist the entropic forces of the philosophy department for several years and eventually he lost. But I'm in two minds as well. So as you know, I've hosted many debates with, you know, like Connolly, he for example, and Beth Jezos and a bunch of different people. And one thing that strikes me is how ideological it is. I really thought as a podcaster, I could have an honest and open conversation and it's never gone well. And I've put a lot of thought into trying to understand why that is. And I think philosophically you can trace it back to things like paternalism and safetyism and utilitarianism and consequentialism and long-termism and, you know, these are ideologies that make one believe that even though it's just a subjective probability that I know better than you, I can predict the future better than you. And they've become much more pragmatic in recent years. So rather than talking about the old school Bostrom superintelligence, we're now talking about, you know, memetic risks and bio risks and things that I think are designed to get more people on board with it. And I agree with you that they've had a lot of influence. But why is it so difficult to have a rational conversation? Yeah, no, I think it's what you say. It's very ideological. There are camps and positions and it's, for some reason, it's become very cult-like on both sides. Obviously, there's the EA movement, which formed a cult-like environment of adherence to those principles and their recommended behaviors and actions, you know, what you should work on in your life. They have dating apps for you. Like, it's very insular. And then there was an ironic, I think, although it's increasingly not clear, an ironic counter-movement, which was EAAC. Yeah. And that has spun out into something that is very not ironic. It's very libertarian, accelerationist, which are ideals that I don't hold either. And so both of these camps I find really unappealing. I don't want to be associated with either of them. Yeah, I found, you know, EA was very dominant for a long time. And so when EAAC came out, it was, like, refreshing. Finally, someone's, like, calling them on their bullshit. But at this point, it's just mind-numbing and, like, completely not of interest to me. Yeah, we've had Beth on the show. He's a really nice guy, actually. I invested in Guillaume's company. Oh, did he? Yeah, yeah, yeah. Oh, it's not that... He's brilliant. Like, he's a really, really nice person. I'm proud to see Canadians doing great things. The best thing I found super funny. And I think EAAC was necessary. I now believe that both EAAC and EAAC need to be dissolved. We've seen them through to their logical conclusion, and now we're starting to get into territory that's very strange. From a philosophical perspective, how do you kind of see the role of AI in society? And I'm quite interested in how it's affecting our reality, and how we interface with technology is really dramatically changing over time. I mean, what do you think about that? Yeah, completely true. I think I view it in the same way I view the computer or the CPU. It's a tool. It's something that we're going to leverage, that we're going to build on top of and use to make our lives better, to make us more productive, to make things cheaper, more accessible. I think all the good that came from the computer and the internet is going to be dwarfed by this, the democratization of intelligence and having that always at your disposal at any time. That's something that, you know, 50 years ago, you couldn't even dream of it, right? It's surreal, the amount of progress that's been made in half a century. And so I'm really excited for that. I think it will do a lot of good and alleviate a lot of ills. I think the human experience, our lives, will be dramatically improved by having access to much more intelligence in our lives. I'm really excited as well, but are there particular things that you are concerned about? I mean, for example, people say that language models might enfee us, they might lead to mass manipulation and persuasion. I mean, Jan Lacoon tweeted the other day, he said, where's the mass manipulation? Where's the persuasion? There might be something that just happens gradually over time, but are there things that you do worry about? Of course, yeah, of course. It's a general technology, and so it can be used in a lot of different ways, many of which are, I think, abhorrent and ones that we should avoid and make very difficult to do. I'm much more of an optimist than I am a pessimist, but on the side of things that are risky, I think that misinformation is high up on the list. I think that we're already seeing social media platforms start to build in the mitigations. I think things like human verification are gonna become crucial. If I'm reading a poster talking about whatever Canadian elections or politicians, I wanna know that that's a voting Canadian citizen. I wanna know, because I want to know what my compatriots think, right? Even if they're on the opposite side of the fence to me, like that's fine. I wanna hear what they think, but I don't wanna hear what some foreign adversary has spun up a bot to push into the discourse. And so human verification, I think, is crucial. That's the one that's top of mind for me. I think some of the more remote risks, like bio weapons and this sort of stuff, I'm less concerned about. In feeblement and becoming dependent on the technology, I think folks said that about calculators and we wouldn't learn how to do basic math. Humans are intrinsically curious. We want to know things, and we can't ask the right questions of machines without knowing things. And so we'll continue to be really well educated, better educated, more knowledgeable than we were before without that technology. Yeah, because if you look at the enfeeblement pie chart, a calculator is a very small part and a general AI is quite a large part, which is a little bit concerning, I guess, but I agree with you that maybe the jobs one has spoken about. I've not seen a lot of evidence of that yet, but it's so pernicious, it might happen slowly over time. Daniel Dennett wrote an interesting article, and rest in peace, by the way, Daniel Dennett called Counterfeit People, which he published in The Atlantic, and he was kind of saying that when we have all of these bots and generative video models and so on, at some point they'll become indistinguishable from reality, and that will lead to a kind of acquiescence where we don't trust anything we see. And I think that's quite interesting, and I also think that these models might kind of affect our agency in quite a weird way, but it's so difficult to understand now how that's going to affect society. Yeah, I think even now, people have been taught to be extremely skeptical of what they read and see. There's a very strong prior inside of us, for any media that we consume, that it's been skewed or manipulated or produced to propagate an idea, and I think it's good to have a skeptical populace. I think it's good to be skeptical about what you read, regardless of the medium. And I think people will do what they've always done, which is filter towards sources they find trustworthy and objective. That'll happen even with ML and the loop, disinformation and misinformation campaigns, manipulation campaigns, they existed well before models existed. And so it's not like a novel concept, and it's always been a risk. And the question is how much more prevalent does the technology make that risk? I'm optimistic that we're quite robust and that we'll find ways to make it very hard for bad actors to exploit the technology. My rough take is that the more agency the AI has, the more of a risk it is, because if it is just doing supervised things, then every step of the process, it's being aligned and constrained and steered by humans. If we ever did create a gentile AI, then there's this kind of weird divergence and all sorts of scary things might happen. But I wanted to talk a little bit about policy and regulation. So you spoke to that earlier, you said that potentially there are some quite damaging policy changes being considered. Could you speak to that? Yeah, I've seen ideas floated. I don't think any seriously damaging policy has actually passed, fortunately. But within what's being considered, there are ideas that they will destroy innovation, they will destroy startups. And so you'll just entrench power with the existing incumbents. Some of those examples might be fines, which if they're a $100 million fine, that's gonna wipe out and stamp out a startup. But for a large, you know, big tech company, it's like 10 minutes of revenue. It just doesn't matter. It fundamentally is irrelevant. And certainly a cost they're willing to take to capture a market. And so very disproportionate consequences for the same punishment. Over-regulation in that way that it's thoughtless will have the exact opposite effect of what I think all of us in the public and in government want. We want competitive markets. We don't want oligopolies. And we're starting to see oligopolies emerge. And so there needs to be fairly strong action pushing against the entrenchment of those oligopolies. And we need to preserve the ability to self-disrupt. Because if you can't, if you have an oligopoly and you have entrenched incumbents, the likelihood of self-disrupting, of the new winner emerging within your market, being one of your players, goes down. And so you're gonna be disrupted from outside. That's a huge risk. And so you need competitive, self-disrupting markets. And it seems like some of the policy folks are just acting non-strategically and not considering that. But fortunately, what has been passed seems sensible. Can you comment in particular on the EU AI legislation and the Canadian? I probably can't say anything too specific. I think the Canadian legislation hasn't gone through yet. The EU AI Act has, but fortunately, it was reigned quite far back from its initial position. I think all of those regulators were in conversation with all of them when you talk to the folks, they wanna do the right thing. They're under a lot of pressure from different parties with conflicting interests, but they're trying to do the right thing. They're trying to make sure this technology gets out into the world in a safe way, that there's oversight, that we don't entrench the incumbents. And we ideally actually sort of bias towards disruption and the creation of new value and innovation, new players. So I think they all want that, but it's a tightrope. It's a very difficult line to walk. I think one of the issues is that not a lot of people certainly in the government understand how this technology works. It seems like magic. And many people, I mean, even in the AI space, I mean, Lacoon and Hinton, for example, people have very different opinions about it, but I'm also interested in your views on the kind of health of the startup scene. So we're in a bit of a downturn at the moment. It doesn't seem to have affected the LLM space, but even in the LLM space, I've noticed a trend that many people started kind of wrapper companies where they did an LLM, but it didn't really do anything that couldn't easily be replicated. And what are your thoughts there? Do you think we're gonna see a trend towards startups doing something that is very differentiated? Yeah, I mean, I think we're in a moment of churn. So I think there are gonna be some players who started a while ago who fold or go into other companies, get acquired, that type of thing, but there's a whole new generation emerging. I know a bunch of people starting up, Ivan and I, we invest in startups and we're seeing an uptick in the number of AI startups that are coming out. It's sort of like a reformatting. There was a bunch of folks building at one layer, like the LLM layer or the one layer above that, tooling, et cetera. The players have kind of been set in that space, it seems, yeah, of course, I'd be happy to see new players emerge. But we now need a set of ideas and products and companies building up the stack. So more abstract concepts, stuff like end user products and agent companies, they're all starting to pop up and create really interesting new ideas. And then that will sort of settle and we'll have our players at that layer. So it's a continuous cycle. Yeah, I'm really excited about the AI startup space. It feels like we're finally starting to get our feet on the ground a little bit. For example, with the tool use, with the RAG, it's starting to look a lot more like traditional software engineering. So what we're seeing now is people kind of rolling up their sleeves and actually building out these very sophisticated software architectures that compose LLMs in interesting ways. And they're not just kind of, you know, just building a simple LLM with a prompt on the top. Yeah, it's definitely getting more sophisticated. And as the tools get more robust and reliable, it's unlocking totally new applications. And the utility is starting to be seen and felt in the real world. I think last year was very much like the year the world woke up to the technology and got their footing with it. So it got familiarity. This year is when things are gonna start hitting production. They're gonna actually start to hit our hands and we're gonna be able to use this as part of our work, part of our play, the products that we use. It's gonna become a much more fundamental part of our daily life. So it's very gratifying. Like we've been building Cohere for four and a half years now. We're in our fifth year. And I think for a long time, we were out there sort of preaching, this is really cool, please care about this. Like this is gonna be an important thing. And folks would pat us on the back and say, nice science project. But finally, we're actually starting to see the fruits of all that labor. And so it's really gratifying to see real world impact. And I think that's what we exist for is really trying to accelerate that and make more of it happen faster and in the best way possible. And what was your biggest mistake? I mean, do you have any advice for other startup founders? What did you do that perhaps they should avoid? I fucked up constantly at every stage of the company. I think, I guess just like admitting that you've messed up and trying not to be in denial about it and fixing it as quickly as possible has been the most important thing to continue to thrive and exist. But yeah, this is the first company I started. Same for Nick and Ivan. And so the whole founding team, we were fresh into it and we made potentially every mistake you could possibly make. Fortunately, we were good at listening to others who had done it before and seen a lot more than we'd seen. And so I'm sure we've dodged some mistakes, but it feels like we've made them all. Yeah, if you don't make mistakes you're not learning, I guess, but just final question. How do you, because it's such a large organization now and there's this problem of vertical information flow. So there might be a problem that some of your folks have discovered now and it takes a while to filter through to you. But obviously it needs to be scalable so you need to delegate. How do you deal with that? Yeah, I'm very close to like the ICs. I'm very close. Like I'm not someone who works through their reports or follows the chain of command. I just talk to the people who are actually doing the work. And so information flows quite freely. I'm sometimes, I think I'm mostly annoying people at this point because I'm like pinging them every day. How's that run going? You know, have we tried this experiment? I'm very deeply involved in stuff. So we haven't had too much. I don't feel like there's an information flow issue echo here with scaling, collaboration between teams, especially when you're a global company and you're not sitting in the same office as a person. That's very difficult. I think remote work is really, really hard. It's not easy. It's not easy. And I think that concentrating teams to geographical areas or at least time zones is very important and leads to a lot more productivity and effectiveness. It's part of the reason I moved here to London is to be closer to a good chunk of our machine learning team. Phil's here, Patrick is here. Like I want to be present and involved in the ML component of the company as much as possible. Yeah, I think as we've scaled, there's been systems that we've used that have broken down at each phase, stuff that worked for the first 10 of us, didn't work for the next 20, didn't work for the next 100. Now we're pushing 350, I think. And there are people at the company who I don't know, which is insane. A super weird experience. But we've hired really fantastic people and we continue to do so. And I think you just trust that people will still make the right decisions going forward and that you've set standards high enough that you don't need to approve every single hire. You don't need to know what every single person is working on. And you just trust your colleagues. Yeah, I can attest that you hire very well. It's probably the best culture I've ever seen in any company, actually. Thank you so much. Final question, I mean, just out of interest, do you get like microcosms in the different offices? I mean, do you see like different mini cultures? Oh yeah, totally, 100%. Like the London office compared to the Toronto office compared to SF, New York. The vibes are very, very different. Like so different. London is so nice. It feels really tight-knit. Like it still feels like a startup, which we are a startup, but it still feels like a tiny 30-person startup where you go out for beers with your colleagues after work at the pub like regularly. Everyone knows what everyone else is working on inside the office, calls on each other for help. London is super tight-knit. I think the culture here is like, I can't pick favorites, but I really like the culture here. In Toronto, it's our biggest office, and so it's much broader, but the culture there is amazing too. Super hard-working, stay late, and like grind very passionate. There's like different groups that are close with each other there. New York is new, but that city is just so much fun. It's just like such an incredible city, so much energy, always awake, work hard, play hard. SF, I spend the least time in. I'm not a huge SF fan, to be completely honest. It's our second HQ, but I just haven't gotten into the city, I think, in the way that others have. I think SF compared to like New York, Toronto, London, I feel like New York, Toronto, and London are real cities. There are artists, there are, you know, people just doing a very diverse set of things, and across all the different fields that are going on there, you have some of the best people in the world. SF is much more, it feels more homogenous to me. It's a lot of people doing the same stuff. There's sort of one topic of conversation. You don't bump into someone with a categorically different worldview than you, or perspective, or experience. And so I like visiting, because I meet like brilliant people in our field, in tech. But to live there would be really cool. To live there would be really difficult for me. I would feel like I'm sacrificing whole pieces of my life. But I love visiting. It's a great place. And I love the folks who are there, and most of our investors are there. And so it's a really cool environment, very intense and like competitive, and those are really good things. It's very motivating to be there. But I think I can get that just by visiting. I don't need to commit myself full time. Aidan Gomez, it's been an honor and a pleasure. Thank you so much for joining us. Thank you so much for having me.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 3.68, "text": " Previous generations of the model have been weak reasoners,", "tokens": [50364, 6001, 1502, 10593, 295, 264, 2316, 362, 668, 5336, 1778, 433, 11, 50548], "temperature": 0.0, "avg_logprob": -0.1521178065119563, "compression_ratio": 1.6876971608832807, "no_speech_prob": 0.030056968331336975}, {"id": 1, "seek": 0, "start": 3.68, "end": 4.5600000000000005, "text": " but they do reason.", "tokens": [50548, 457, 436, 360, 1778, 13, 50592], "temperature": 0.0, "avg_logprob": -0.1521178065119563, "compression_ratio": 1.6876971608832807, "no_speech_prob": 0.030056968331336975}, {"id": 2, "seek": 0, "start": 4.5600000000000005, "end": 6.28, "text": " In the same way that hallucination", "tokens": [50592, 682, 264, 912, 636, 300, 35212, 2486, 50678], "temperature": 0.0, "avg_logprob": -0.1521178065119563, "compression_ratio": 1.6876971608832807, "no_speech_prob": 0.030056968331336975}, {"id": 3, "seek": 0, "start": 6.28, "end": 8.84, "text": " was an existential threat to this technology,", "tokens": [50678, 390, 364, 37133, 4734, 281, 341, 2899, 11, 50806], "temperature": 0.0, "avg_logprob": -0.1521178065119563, "compression_ratio": 1.6876971608832807, "no_speech_prob": 0.030056968331336975}, {"id": 4, "seek": 0, "start": 8.84, "end": 11.48, "text": " no, we'll never be able to trust this stuff.", "tokens": [50806, 572, 11, 321, 603, 1128, 312, 1075, 281, 3361, 341, 1507, 13, 50938], "temperature": 0.0, "avg_logprob": -0.1521178065119563, "compression_ratio": 1.6876971608832807, "no_speech_prob": 0.030056968331336975}, {"id": 5, "seek": 0, "start": 11.48, "end": 13.120000000000001, "text": " There are hundreds of millions of people", "tokens": [50938, 821, 366, 6779, 295, 6803, 295, 561, 51020], "temperature": 0.0, "avg_logprob": -0.1521178065119563, "compression_ratio": 1.6876971608832807, "no_speech_prob": 0.030056968331336975}, {"id": 6, "seek": 0, "start": 13.120000000000001, "end": 14.8, "text": " using this techno, and they trust it.", "tokens": [51020, 1228, 341, 36728, 11, 293, 436, 3361, 309, 13, 51104], "temperature": 0.0, "avg_logprob": -0.1521178065119563, "compression_ratio": 1.6876971608832807, "no_speech_prob": 0.030056968331336975}, {"id": 7, "seek": 0, "start": 14.8, "end": 16.0, "text": " It's actually useful for them.", "tokens": [51104, 467, 311, 767, 4420, 337, 552, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1521178065119563, "compression_ratio": 1.6876971608832807, "no_speech_prob": 0.030056968331336975}, {"id": 8, "seek": 0, "start": 16.0, "end": 18.36, "text": " We're making very good progress on the hallucination problem.", "tokens": [51164, 492, 434, 1455, 588, 665, 4205, 322, 264, 35212, 2486, 1154, 13, 51282], "temperature": 0.0, "avg_logprob": -0.1521178065119563, "compression_ratio": 1.6876971608832807, "no_speech_prob": 0.030056968331336975}, {"id": 9, "seek": 0, "start": 18.36, "end": 20.48, "text": " I think we'll make very good progress", "tokens": [51282, 286, 519, 321, 603, 652, 588, 665, 4205, 51388], "temperature": 0.0, "avg_logprob": -0.1521178065119563, "compression_ratio": 1.6876971608832807, "no_speech_prob": 0.030056968331336975}, {"id": 10, "seek": 0, "start": 20.48, "end": 22.36, "text": " this year and next on Reasoning.", "tokens": [51388, 341, 1064, 293, 958, 322, 39693, 278, 13, 51482], "temperature": 0.0, "avg_logprob": -0.1521178065119563, "compression_ratio": 1.6876971608832807, "no_speech_prob": 0.030056968331336975}, {"id": 11, "seek": 0, "start": 22.36, "end": 25.36, "text": " Here we are again, another episode of MLST.", "tokens": [51482, 1692, 321, 366, 797, 11, 1071, 3500, 295, 376, 19198, 51, 13, 51632], "temperature": 0.0, "avg_logprob": -0.1521178065119563, "compression_ratio": 1.6876971608832807, "no_speech_prob": 0.030056968331336975}, {"id": 12, "seek": 0, "start": 25.36, "end": 28.6, "text": " Today with Aidan Gomez, the CEO of Coheir.", "tokens": [51632, 2692, 365, 316, 31675, 43537, 11, 264, 9282, 295, 3066, 675, 347, 13, 51794], "temperature": 0.0, "avg_logprob": -0.1521178065119563, "compression_ratio": 1.6876971608832807, "no_speech_prob": 0.030056968331336975}, {"id": 13, "seek": 2860, "start": 28.6, "end": 31.360000000000003, "text": " Now, I interviewed Aidan in London a couple of weeks ago", "tokens": [50364, 823, 11, 286, 19770, 316, 31675, 294, 7042, 257, 1916, 295, 3259, 2057, 50502], "temperature": 0.0, "avg_logprob": -0.08549332795319733, "compression_ratio": 1.6689655172413793, "no_speech_prob": 0.0030911355279386044}, {"id": 14, "seek": 2860, "start": 31.360000000000003, "end": 32.84, "text": " just after their build event", "tokens": [50502, 445, 934, 641, 1322, 2280, 50576], "temperature": 0.0, "avg_logprob": -0.08549332795319733, "compression_ratio": 1.6689655172413793, "no_speech_prob": 0.0030911355279386044}, {"id": 15, "seek": 2860, "start": 32.84, "end": 35.44, "text": " and after Aidan did his presentation,", "tokens": [50576, 293, 934, 316, 31675, 630, 702, 5860, 11, 50706], "temperature": 0.0, "avg_logprob": -0.08549332795319733, "compression_ratio": 1.6689655172413793, "no_speech_prob": 0.0030911355279386044}, {"id": 16, "seek": 2860, "start": 35.44, "end": 38.84, "text": " I sat him down for an hour and I gave him a grilling.", "tokens": [50706, 286, 3227, 796, 760, 337, 364, 1773, 293, 286, 2729, 796, 257, 49961, 13, 50876], "temperature": 0.0, "avg_logprob": -0.08549332795319733, "compression_ratio": 1.6689655172413793, "no_speech_prob": 0.0030911355279386044}, {"id": 17, "seek": 2860, "start": 38.84, "end": 40.36, "text": " And he was such a good sport", "tokens": [50876, 400, 415, 390, 1270, 257, 665, 7282, 50952], "temperature": 0.0, "avg_logprob": -0.08549332795319733, "compression_ratio": 1.6689655172413793, "no_speech_prob": 0.0030911355279386044}, {"id": 18, "seek": 2860, "start": 40.36, "end": 42.96, "text": " for being so transparent and authentic.", "tokens": [50952, 337, 885, 370, 12737, 293, 12466, 13, 51082], "temperature": 0.0, "avg_logprob": -0.08549332795319733, "compression_ratio": 1.6689655172413793, "no_speech_prob": 0.0030911355279386044}, {"id": 19, "seek": 2860, "start": 42.96, "end": 45.0, "text": " This is the difference with Coheir.", "tokens": [51082, 639, 307, 264, 2649, 365, 3066, 675, 347, 13, 51184], "temperature": 0.0, "avg_logprob": -0.08549332795319733, "compression_ratio": 1.6689655172413793, "no_speech_prob": 0.0030911355279386044}, {"id": 20, "seek": 2860, "start": 45.0, "end": 46.84, "text": " They say it like it is.", "tokens": [51184, 814, 584, 309, 411, 309, 307, 13, 51276], "temperature": 0.0, "avg_logprob": -0.08549332795319733, "compression_ratio": 1.6689655172413793, "no_speech_prob": 0.0030911355279386044}, {"id": 21, "seek": 2860, "start": 46.84, "end": 48.16, "text": " There's no bullshit.", "tokens": [51276, 821, 311, 572, 22676, 13, 51342], "temperature": 0.0, "avg_logprob": -0.08549332795319733, "compression_ratio": 1.6689655172413793, "no_speech_prob": 0.0030911355279386044}, {"id": 22, "seek": 2860, "start": 48.16, "end": 49.72, "text": " There's no digital gods.", "tokens": [51342, 821, 311, 572, 4562, 14049, 13, 51420], "temperature": 0.0, "avg_logprob": -0.08549332795319733, "compression_ratio": 1.6689655172413793, "no_speech_prob": 0.0030911355279386044}, {"id": 23, "seek": 2860, "start": 49.72, "end": 51.52, "text": " There's no super intelligence.", "tokens": [51420, 821, 311, 572, 1687, 7599, 13, 51510], "temperature": 0.0, "avg_logprob": -0.08549332795319733, "compression_ratio": 1.6689655172413793, "no_speech_prob": 0.0030911355279386044}, {"id": 24, "seek": 2860, "start": 51.52, "end": 53.36, "text": " They're just a bunch of folks", "tokens": [51510, 814, 434, 445, 257, 3840, 295, 4024, 51602], "temperature": 0.0, "avg_logprob": -0.08549332795319733, "compression_ratio": 1.6689655172413793, "no_speech_prob": 0.0030911355279386044}, {"id": 25, "seek": 2860, "start": 53.36, "end": 55.56, "text": " solving real world business problems.", "tokens": [51602, 12606, 957, 1002, 1606, 2740, 13, 51712], "temperature": 0.0, "avg_logprob": -0.08549332795319733, "compression_ratio": 1.6689655172413793, "no_speech_prob": 0.0030911355279386044}, {"id": 26, "seek": 2860, "start": 55.56, "end": 57.160000000000004, "text": " Their models are incredibly good", "tokens": [51712, 6710, 5245, 366, 6252, 665, 51792], "temperature": 0.0, "avg_logprob": -0.08549332795319733, "compression_ratio": 1.6689655172413793, "no_speech_prob": 0.0030911355279386044}, {"id": 27, "seek": 5716, "start": 57.16, "end": 59.8, "text": " for a true vlogmented generation, for multilingual.", "tokens": [50364, 337, 257, 2074, 8917, 14684, 5125, 11, 337, 2120, 38219, 13, 50496], "temperature": 0.0, "avg_logprob": -0.11461265993789888, "compression_ratio": 1.671875, "no_speech_prob": 0.01052219606935978}, {"id": 28, "seek": 5716, "start": 59.8, "end": 62.08, "text": " But they also have some serious challenges", "tokens": [50496, 583, 436, 611, 362, 512, 3156, 4759, 50610], "temperature": 0.0, "avg_logprob": -0.11461265993789888, "compression_ratio": 1.671875, "no_speech_prob": 0.01052219606935978}, {"id": 29, "seek": 5716, "start": 62.08, "end": 63.4, "text": " that they need to overcome.", "tokens": [50610, 300, 436, 643, 281, 10473, 13, 50676], "temperature": 0.0, "avg_logprob": -0.11461265993789888, "compression_ratio": 1.671875, "no_speech_prob": 0.01052219606935978}, {"id": 30, "seek": 5716, "start": 63.4, "end": 65.96, "text": " We spoke about the AI risk discussion,", "tokens": [50676, 492, 7179, 466, 264, 7318, 3148, 5017, 11, 50804], "temperature": 0.0, "avg_logprob": -0.11461265993789888, "compression_ratio": 1.671875, "no_speech_prob": 0.01052219606935978}, {"id": 31, "seek": 5716, "start": 65.96, "end": 68.39999999999999, "text": " where the language models take away our agency,", "tokens": [50804, 689, 264, 2856, 5245, 747, 1314, 527, 7934, 11, 50926], "temperature": 0.0, "avg_logprob": -0.11461265993789888, "compression_ratio": 1.671875, "no_speech_prob": 0.01052219606935978}, {"id": 32, "seek": 5716, "start": 68.39999999999999, "end": 70.12, "text": " how he's dealing with policy, right?", "tokens": [50926, 577, 415, 311, 6260, 365, 3897, 11, 558, 30, 51012], "temperature": 0.0, "avg_logprob": -0.11461265993789888, "compression_ratio": 1.671875, "no_speech_prob": 0.01052219606935978}, {"id": 33, "seek": 5716, "start": 70.12, "end": 72.84, "text": " So on the one hand, he's talking with governments,", "tokens": [51012, 407, 322, 264, 472, 1011, 11, 415, 311, 1417, 365, 11280, 11, 51148], "temperature": 0.0, "avg_logprob": -0.11461265993789888, "compression_ratio": 1.671875, "no_speech_prob": 0.01052219606935978}, {"id": 34, "seek": 5716, "start": 72.84, "end": 75.75999999999999, "text": " trying to get them to allow startups", "tokens": [51148, 1382, 281, 483, 552, 281, 2089, 28041, 51294], "temperature": 0.0, "avg_logprob": -0.11461265993789888, "compression_ratio": 1.671875, "no_speech_prob": 0.01052219606935978}, {"id": 35, "seek": 5716, "start": 75.75999999999999, "end": 78.52, "text": " to be more competitive, to innovate.", "tokens": [51294, 281, 312, 544, 10043, 11, 281, 33444, 13, 51432], "temperature": 0.0, "avg_logprob": -0.11461265993789888, "compression_ratio": 1.671875, "no_speech_prob": 0.01052219606935978}, {"id": 36, "seek": 5716, "start": 78.52, "end": 81.03999999999999, "text": " But at the same token, he's also very concerned", "tokens": [51432, 583, 412, 264, 912, 14862, 11, 415, 311, 611, 588, 5922, 51558], "temperature": 0.0, "avg_logprob": -0.11461265993789888, "compression_ratio": 1.671875, "no_speech_prob": 0.01052219606935978}, {"id": 37, "seek": 5716, "start": 81.03999999999999, "end": 83.44, "text": " about some of the societal risks of AI.", "tokens": [51558, 466, 512, 295, 264, 33472, 10888, 295, 7318, 13, 51678], "temperature": 0.0, "avg_logprob": -0.11461265993789888, "compression_ratio": 1.671875, "no_speech_prob": 0.01052219606935978}, {"id": 38, "seek": 5716, "start": 83.44, "end": 85.0, "text": " So that's quite an interesting burden", "tokens": [51678, 407, 300, 311, 1596, 364, 1880, 12578, 51756], "temperature": 0.0, "avg_logprob": -0.11461265993789888, "compression_ratio": 1.671875, "no_speech_prob": 0.01052219606935978}, {"id": 39, "seek": 5716, "start": 85.0, "end": 86.88, "text": " and juxtaposition that he has to hold", "tokens": [51756, 293, 3649, 734, 569, 5830, 300, 415, 575, 281, 1797, 51850], "temperature": 0.0, "avg_logprob": -0.11461265993789888, "compression_ratio": 1.671875, "no_speech_prob": 0.01052219606935978}, {"id": 40, "seek": 8688, "start": 87.08, "end": 88.28, "text": " in his mind.", "tokens": [50374, 294, 702, 1575, 13, 50434], "temperature": 0.0, "avg_logprob": -0.09453048090780936, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.001037896960042417}, {"id": 41, "seek": 8688, "start": 88.28, "end": 90.6, "text": " We spoke a lot about the company culture at Coheir.", "tokens": [50434, 492, 7179, 257, 688, 466, 264, 2237, 3713, 412, 3066, 675, 347, 13, 50550], "temperature": 0.0, "avg_logprob": -0.09453048090780936, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.001037896960042417}, {"id": 42, "seek": 8688, "start": 90.6, "end": 92.03999999999999, "text": " Now, I'm very impressed with Coheir.", "tokens": [50550, 823, 11, 286, 478, 588, 11679, 365, 3066, 675, 347, 13, 50622], "temperature": 0.0, "avg_logprob": -0.09453048090780936, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.001037896960042417}, {"id": 43, "seek": 8688, "start": 92.03999999999999, "end": 94.47999999999999, "text": " All of the people I've spoken to have been very smart,", "tokens": [50622, 1057, 295, 264, 561, 286, 600, 10759, 281, 362, 668, 588, 4069, 11, 50744], "temperature": 0.0, "avg_logprob": -0.09453048090780936, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.001037896960042417}, {"id": 44, "seek": 8688, "start": 94.47999999999999, "end": 96.28, "text": " just really nice people.", "tokens": [50744, 445, 534, 1481, 561, 13, 50834], "temperature": 0.0, "avg_logprob": -0.09453048090780936, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.001037896960042417}, {"id": 45, "seek": 8688, "start": 96.28, "end": 99.44, "text": " And how has he cultivated that culture?", "tokens": [50834, 400, 577, 575, 415, 46770, 300, 3713, 30, 50992], "temperature": 0.0, "avg_logprob": -0.09453048090780936, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.001037896960042417}, {"id": 46, "seek": 8688, "start": 99.44, "end": 101.08, "text": " He was very frank and transparent", "tokens": [50992, 634, 390, 588, 10455, 293, 12737, 51074], "temperature": 0.0, "avg_logprob": -0.09453048090780936, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.001037896960042417}, {"id": 47, "seek": 8688, "start": 101.08, "end": 104.36, "text": " about some of the mistakes he made early on as a CEO.", "tokens": [51074, 466, 512, 295, 264, 8038, 415, 1027, 2440, 322, 382, 257, 9282, 13, 51238], "temperature": 0.0, "avg_logprob": -0.09453048090780936, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.001037896960042417}, {"id": 48, "seek": 8688, "start": 104.36, "end": 106.47999999999999, "text": " So yeah, plenty to get your teeth into.", "tokens": [51238, 407, 1338, 11, 7140, 281, 483, 428, 7798, 666, 13, 51344], "temperature": 0.0, "avg_logprob": -0.09453048090780936, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.001037896960042417}, {"id": 49, "seek": 8688, "start": 106.47999999999999, "end": 108.28, "text": " I hope you enjoy the conversation.", "tokens": [51344, 286, 1454, 291, 2103, 264, 3761, 13, 51434], "temperature": 0.0, "avg_logprob": -0.09453048090780936, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.001037896960042417}, {"id": 50, "seek": 8688, "start": 109.44, "end": 111.19999999999999, "text": " For Coheir, I think we're a little bit different", "tokens": [51492, 1171, 3066, 675, 347, 11, 286, 519, 321, 434, 257, 707, 857, 819, 51580], "temperature": 0.0, "avg_logprob": -0.09453048090780936, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.001037896960042417}, {"id": 51, "seek": 8688, "start": 111.19999999999999, "end": 113.16, "text": " than some of the other companies in the space,", "tokens": [51580, 813, 512, 295, 264, 661, 3431, 294, 264, 1901, 11, 51678], "temperature": 0.0, "avg_logprob": -0.09453048090780936, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.001037896960042417}, {"id": 52, "seek": 8688, "start": 113.16, "end": 116.52, "text": " in the sense that we're not really here to build AGI.", "tokens": [51678, 294, 264, 2020, 300, 321, 434, 406, 534, 510, 281, 1322, 316, 26252, 13, 51846], "temperature": 0.0, "avg_logprob": -0.09453048090780936, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.001037896960042417}, {"id": 53, "seek": 11652, "start": 116.52, "end": 119.28, "text": " What we're here to do is create value for the world.", "tokens": [50364, 708, 321, 434, 510, 281, 360, 307, 1884, 2158, 337, 264, 1002, 13, 50502], "temperature": 0.0, "avg_logprob": -0.09671462083063206, "compression_ratio": 1.7440944881889764, "no_speech_prob": 0.0017784751253202558}, {"id": 54, "seek": 11652, "start": 119.28, "end": 120.84, "text": " And the way that we think we can do that", "tokens": [50502, 400, 264, 636, 300, 321, 519, 321, 393, 360, 300, 50580], "temperature": 0.0, "avg_logprob": -0.09671462083063206, "compression_ratio": 1.7440944881889764, "no_speech_prob": 0.0017784751253202558}, {"id": 55, "seek": 11652, "start": 120.84, "end": 125.0, "text": " is by putting this tech into the hands of enterprises", "tokens": [50580, 307, 538, 3372, 341, 7553, 666, 264, 2377, 295, 29034, 50788], "temperature": 0.0, "avg_logprob": -0.09671462083063206, "compression_ratio": 1.7440944881889764, "no_speech_prob": 0.0017784751253202558}, {"id": 56, "seek": 11652, "start": 125.0, "end": 127.24, "text": " so that they can integrate it into their products,", "tokens": [50788, 370, 300, 436, 393, 13365, 309, 666, 641, 3383, 11, 50900], "temperature": 0.0, "avg_logprob": -0.09671462083063206, "compression_ratio": 1.7440944881889764, "no_speech_prob": 0.0017784751253202558}, {"id": 57, "seek": 11652, "start": 127.24, "end": 130.64, "text": " they can augment their workforce with it.", "tokens": [50900, 436, 393, 29919, 641, 14201, 365, 309, 13, 51070], "temperature": 0.0, "avg_logprob": -0.09671462083063206, "compression_ratio": 1.7440944881889764, "no_speech_prob": 0.0017784751253202558}, {"id": 58, "seek": 11652, "start": 130.64, "end": 133.44, "text": " And so it's all about driving value", "tokens": [51070, 400, 370, 309, 311, 439, 466, 4840, 2158, 51210], "temperature": 0.0, "avg_logprob": -0.09671462083063206, "compression_ratio": 1.7440944881889764, "no_speech_prob": 0.0017784751253202558}, {"id": 59, "seek": 11652, "start": 133.44, "end": 135.6, "text": " and really putting this technology", "tokens": [51210, 293, 534, 3372, 341, 2899, 51318], "temperature": 0.0, "avg_logprob": -0.09671462083063206, "compression_ratio": 1.7440944881889764, "no_speech_prob": 0.0017784751253202558}, {"id": 60, "seek": 11652, "start": 135.6, "end": 137.88, "text": " into the hands of more people", "tokens": [51318, 666, 264, 2377, 295, 544, 561, 51432], "temperature": 0.0, "avg_logprob": -0.09671462083063206, "compression_ratio": 1.7440944881889764, "no_speech_prob": 0.0017784751253202558}, {"id": 61, "seek": 11652, "start": 137.88, "end": 141.0, "text": " and driving productivity for humanity.", "tokens": [51432, 293, 4840, 15604, 337, 10243, 13, 51588], "temperature": 0.0, "avg_logprob": -0.09671462083063206, "compression_ratio": 1.7440944881889764, "no_speech_prob": 0.0017784751253202558}, {"id": 62, "seek": 11652, "start": 141.84, "end": 143.16, "text": " Aiden, welcome to MLSD.", "tokens": [51630, 316, 4380, 11, 2928, 281, 376, 19198, 35, 13, 51696], "temperature": 0.0, "avg_logprob": -0.09671462083063206, "compression_ratio": 1.7440944881889764, "no_speech_prob": 0.0017784751253202558}, {"id": 63, "seek": 11652, "start": 143.16, "end": 145.16, "text": " It's an absolute honor to have you on.", "tokens": [51696, 467, 311, 364, 8236, 5968, 281, 362, 291, 322, 13, 51796], "temperature": 0.0, "avg_logprob": -0.09671462083063206, "compression_ratio": 1.7440944881889764, "no_speech_prob": 0.0017784751253202558}, {"id": 64, "seek": 14516, "start": 145.2, "end": 147.2, "text": " Thank you so much. Appreciate it.", "tokens": [50366, 1044, 291, 370, 709, 13, 37601, 309, 13, 50466], "temperature": 0.0, "avg_logprob": -0.12483745510295285, "compression_ratio": 1.6408450704225352, "no_speech_prob": 0.0011290101101621985}, {"id": 65, "seek": 14516, "start": 147.2, "end": 148.64, "text": " There's a bit of a last mile problem", "tokens": [50466, 821, 311, 257, 857, 295, 257, 1036, 12620, 1154, 50538], "temperature": 0.0, "avg_logprob": -0.12483745510295285, "compression_ratio": 1.6408450704225352, "no_speech_prob": 0.0011290101101621985}, {"id": 66, "seek": 14516, "start": 148.64, "end": 149.79999999999998, "text": " with large language models,", "tokens": [50538, 365, 2416, 2856, 5245, 11, 50596], "temperature": 0.0, "avg_logprob": -0.12483745510295285, "compression_ratio": 1.6408450704225352, "no_speech_prob": 0.0011290101101621985}, {"id": 67, "seek": 14516, "start": 149.79999999999998, "end": 153.68, "text": " so you folks have created this incredible general technology.", "tokens": [50596, 370, 291, 4024, 362, 2942, 341, 4651, 2674, 2899, 13, 50790], "temperature": 0.0, "avg_logprob": -0.12483745510295285, "compression_ratio": 1.6408450704225352, "no_speech_prob": 0.0011290101101621985}, {"id": 68, "seek": 14516, "start": 153.68, "end": 156.07999999999998, "text": " But when enterprises implement it,", "tokens": [50790, 583, 562, 29034, 4445, 309, 11, 50910], "temperature": 0.0, "avg_logprob": -0.12483745510295285, "compression_ratio": 1.6408450704225352, "no_speech_prob": 0.0011290101101621985}, {"id": 69, "seek": 14516, "start": 156.07999999999998, "end": 159.56, "text": " they have a whole bunch of legislative constraints,", "tokens": [50910, 436, 362, 257, 1379, 3840, 295, 21331, 18491, 11, 51084], "temperature": 0.0, "avg_logprob": -0.12483745510295285, "compression_ratio": 1.6408450704225352, "no_speech_prob": 0.0011290101101621985}, {"id": 70, "seek": 14516, "start": 159.56, "end": 161.28, "text": " security constraints.", "tokens": [51084, 3825, 18491, 13, 51170], "temperature": 0.0, "avg_logprob": -0.12483745510295285, "compression_ratio": 1.6408450704225352, "no_speech_prob": 0.0011290101101621985}, {"id": 71, "seek": 14516, "start": 161.28, "end": 165.6, "text": " Yeah, yeah, I think there's loads of barriers to access.", "tokens": [51170, 865, 11, 1338, 11, 286, 519, 456, 311, 12668, 295, 13565, 281, 2105, 13, 51386], "temperature": 0.0, "avg_logprob": -0.12483745510295285, "compression_ratio": 1.6408450704225352, "no_speech_prob": 0.0011290101101621985}, {"id": 72, "seek": 14516, "start": 165.6, "end": 170.44, "text": " Privacy to policy to just the familiarity of the teams", "tokens": [51386, 39691, 2551, 281, 3897, 281, 445, 264, 49828, 295, 264, 5491, 51628], "temperature": 0.0, "avg_logprob": -0.12483745510295285, "compression_ratio": 1.6408450704225352, "no_speech_prob": 0.0011290101101621985}, {"id": 73, "seek": 14516, "start": 170.44, "end": 172.56, "text": " with the tech, it's brand new.", "tokens": [51628, 365, 264, 7553, 11, 309, 311, 3360, 777, 13, 51734], "temperature": 0.0, "avg_logprob": -0.12483745510295285, "compression_ratio": 1.6408450704225352, "no_speech_prob": 0.0011290101101621985}, {"id": 74, "seek": 14516, "start": 172.56, "end": 174.92, "text": " And so they haven't built with this technology before", "tokens": [51734, 400, 370, 436, 2378, 380, 3094, 365, 341, 2899, 949, 51852], "temperature": 0.0, "avg_logprob": -0.12483745510295285, "compression_ratio": 1.6408450704225352, "no_speech_prob": 0.0011290101101621985}, {"id": 75, "seek": 17492, "start": 174.92, "end": 176.95999999999998, "text": " and they're still getting up to speed", "tokens": [50364, 293, 436, 434, 920, 1242, 493, 281, 3073, 50466], "temperature": 0.0, "avg_logprob": -0.06986634484652815, "compression_ratio": 1.6844106463878328, "no_speech_prob": 0.0010312622180208564}, {"id": 76, "seek": 17492, "start": 176.95999999999998, "end": 180.79999999999998, "text": " with the opportunity space, what they can do with it.", "tokens": [50466, 365, 264, 2650, 1901, 11, 437, 436, 393, 360, 365, 309, 13, 50658], "temperature": 0.0, "avg_logprob": -0.06986634484652815, "compression_ratio": 1.6844106463878328, "no_speech_prob": 0.0010312622180208564}, {"id": 77, "seek": 17492, "start": 180.79999999999998, "end": 185.23999999999998, "text": " That being said, people are so excited about AI", "tokens": [50658, 663, 885, 848, 11, 561, 366, 370, 2919, 466, 7318, 50880], "temperature": 0.0, "avg_logprob": -0.06986634484652815, "compression_ratio": 1.6844106463878328, "no_speech_prob": 0.0010312622180208564}, {"id": 78, "seek": 17492, "start": 185.23999999999998, "end": 188.23999999999998, "text": " and its opportunity that the motivation and the will", "tokens": [50880, 293, 1080, 2650, 300, 264, 12335, 293, 264, 486, 51030], "temperature": 0.0, "avg_logprob": -0.06986634484652815, "compression_ratio": 1.6844106463878328, "no_speech_prob": 0.0010312622180208564}, {"id": 79, "seek": 17492, "start": 188.23999999999998, "end": 190.76, "text": " is there to overcome a lot of these hurdles.", "tokens": [51030, 307, 456, 281, 10473, 257, 688, 295, 613, 48387, 13, 51156], "temperature": 0.0, "avg_logprob": -0.06986634484652815, "compression_ratio": 1.6844106463878328, "no_speech_prob": 0.0010312622180208564}, {"id": 80, "seek": 17492, "start": 190.76, "end": 193.51999999999998, "text": " So we're trying to help with that as much as we can,", "tokens": [51156, 407, 321, 434, 1382, 281, 854, 365, 300, 382, 709, 382, 321, 393, 11, 51294], "temperature": 0.0, "avg_logprob": -0.06986634484652815, "compression_ratio": 1.6844106463878328, "no_speech_prob": 0.0010312622180208564}, {"id": 81, "seek": 17492, "start": 193.51999999999998, "end": 197.32, "text": " whether it's like our LMU education course", "tokens": [51294, 1968, 309, 311, 411, 527, 46529, 52, 3309, 1164, 51484], "temperature": 0.0, "avg_logprob": -0.06986634484652815, "compression_ratio": 1.6844106463878328, "no_speech_prob": 0.0010312622180208564}, {"id": 82, "seek": 17492, "start": 197.32, "end": 199.72, "text": " to help general developers get up to speed", "tokens": [51484, 281, 854, 2674, 8849, 483, 493, 281, 3073, 51604], "temperature": 0.0, "avg_logprob": -0.06986634484652815, "compression_ratio": 1.6844106463878328, "no_speech_prob": 0.0010312622180208564}, {"id": 83, "seek": 17492, "start": 199.72, "end": 201.27999999999997, "text": " on how to build with this stuff", "tokens": [51604, 322, 577, 281, 1322, 365, 341, 1507, 51682], "temperature": 0.0, "avg_logprob": -0.06986634484652815, "compression_ratio": 1.6844106463878328, "no_speech_prob": 0.0010312622180208564}, {"id": 84, "seek": 17492, "start": 201.27999999999997, "end": 203.48, "text": " or us engaging at the policy level", "tokens": [51682, 420, 505, 11268, 412, 264, 3897, 1496, 51792], "temperature": 0.0, "avg_logprob": -0.06986634484652815, "compression_ratio": 1.6844106463878328, "no_speech_prob": 0.0010312622180208564}, {"id": 85, "seek": 20348, "start": 203.48, "end": 206.11999999999998, "text": " to make sure that we have sensible policy", "tokens": [50364, 281, 652, 988, 300, 321, 362, 25380, 3897, 50496], "temperature": 0.0, "avg_logprob": -0.09978429760251727, "compression_ratio": 1.652, "no_speech_prob": 0.0006262108217924833}, {"id": 86, "seek": 20348, "start": 206.11999999999998, "end": 208.88, "text": " and not over-regulation or regulation", "tokens": [50496, 293, 406, 670, 12, 3375, 2776, 420, 15062, 50634], "temperature": 0.0, "avg_logprob": -0.09978429760251727, "compression_ratio": 1.652, "no_speech_prob": 0.0006262108217924833}, {"id": 87, "seek": 20348, "start": 208.88, "end": 213.88, "text": " that hurts startups or encumbers industry in adopting it.", "tokens": [50634, 300, 11051, 28041, 420, 2058, 36353, 3518, 294, 32328, 309, 13, 50884], "temperature": 0.0, "avg_logprob": -0.09978429760251727, "compression_ratio": 1.652, "no_speech_prob": 0.0006262108217924833}, {"id": 88, "seek": 20348, "start": 214.04, "end": 215.56, "text": " So we're trying to pull the levers that we can", "tokens": [50892, 407, 321, 434, 1382, 281, 2235, 264, 45571, 300, 321, 393, 50968], "temperature": 0.0, "avg_logprob": -0.09978429760251727, "compression_ratio": 1.652, "no_speech_prob": 0.0006262108217924833}, {"id": 89, "seek": 20348, "start": 215.56, "end": 217.28, "text": " to help accelerate the adoption", "tokens": [50968, 281, 854, 21341, 264, 19215, 51054], "temperature": 0.0, "avg_logprob": -0.09978429760251727, "compression_ratio": 1.652, "no_speech_prob": 0.0006262108217924833}, {"id": 90, "seek": 20348, "start": 217.28, "end": 220.56, "text": " and make sure that it gets adopted in the right way.", "tokens": [51054, 293, 652, 988, 300, 309, 2170, 12175, 294, 264, 558, 636, 13, 51218], "temperature": 0.0, "avg_logprob": -0.09978429760251727, "compression_ratio": 1.652, "no_speech_prob": 0.0006262108217924833}, {"id": 91, "seek": 20348, "start": 220.56, "end": 222.95999999999998, "text": " But yeah, no, it's definitely the past two years", "tokens": [51218, 583, 1338, 11, 572, 11, 309, 311, 2138, 264, 1791, 732, 924, 51338], "temperature": 0.0, "avg_logprob": -0.09978429760251727, "compression_ratio": 1.652, "no_speech_prob": 0.0006262108217924833}, {"id": 92, "seek": 20348, "start": 222.95999999999998, "end": 226.83999999999997, "text": " have been a push.", "tokens": [51338, 362, 668, 257, 2944, 13, 51532], "temperature": 0.0, "avg_logprob": -0.09978429760251727, "compression_ratio": 1.652, "no_speech_prob": 0.0006262108217924833}, {"id": 93, "seek": 20348, "start": 226.83999999999997, "end": 229.51999999999998, "text": " There's a lot of stuff slowing down adoption", "tokens": [51532, 821, 311, 257, 688, 295, 1507, 26958, 760, 19215, 51666], "temperature": 0.0, "avg_logprob": -0.09978429760251727, "compression_ratio": 1.652, "no_speech_prob": 0.0006262108217924833}, {"id": 94, "seek": 20348, "start": 229.51999999999998, "end": 231.35999999999999, "text": " that I would love to see eased.", "tokens": [51666, 300, 286, 576, 959, 281, 536, 1195, 292, 13, 51758], "temperature": 0.0, "avg_logprob": -0.09978429760251727, "compression_ratio": 1.652, "no_speech_prob": 0.0006262108217924833}, {"id": 95, "seek": 23136, "start": 231.4, "end": 233.72000000000003, "text": " I think the tools need to get better, easier to use,", "tokens": [50366, 286, 519, 264, 3873, 643, 281, 483, 1101, 11, 3571, 281, 764, 11, 50482], "temperature": 0.0, "avg_logprob": -0.1224878471316272, "compression_ratio": 1.7054794520547945, "no_speech_prob": 0.0011692165862768888}, {"id": 96, "seek": 23136, "start": 233.72000000000003, "end": 235.72000000000003, "text": " more intuitive, more robust.", "tokens": [50482, 544, 21769, 11, 544, 13956, 13, 50582], "temperature": 0.0, "avg_logprob": -0.1224878471316272, "compression_ratio": 1.7054794520547945, "no_speech_prob": 0.0011692165862768888}, {"id": 97, "seek": 23136, "start": 235.72000000000003, "end": 237.96, "text": " Prompt engineering is still a thing.", "tokens": [50582, 15833, 662, 7043, 307, 920, 257, 551, 13, 50694], "temperature": 0.0, "avg_logprob": -0.1224878471316272, "compression_ratio": 1.7054794520547945, "no_speech_prob": 0.0011692165862768888}, {"id": 98, "seek": 23136, "start": 237.96, "end": 239.52, "text": " It shouldn't be right.", "tokens": [50694, 467, 4659, 380, 312, 558, 13, 50772], "temperature": 0.0, "avg_logprob": -0.1224878471316272, "compression_ratio": 1.7054794520547945, "no_speech_prob": 0.0011692165862768888}, {"id": 99, "seek": 23136, "start": 239.52, "end": 242.20000000000002, "text": " It shouldn't matter how you phrase something specifically.", "tokens": [50772, 467, 4659, 380, 1871, 577, 291, 9535, 746, 4682, 13, 50906], "temperature": 0.0, "avg_logprob": -0.1224878471316272, "compression_ratio": 1.7054794520547945, "no_speech_prob": 0.0011692165862768888}, {"id": 100, "seek": 23136, "start": 242.20000000000002, "end": 244.56, "text": " It should be, the model should be smart enough", "tokens": [50906, 467, 820, 312, 11, 264, 2316, 820, 312, 4069, 1547, 51024], "temperature": 0.0, "avg_logprob": -0.1224878471316272, "compression_ratio": 1.7054794520547945, "no_speech_prob": 0.0011692165862768888}, {"id": 101, "seek": 23136, "start": 244.56, "end": 246.68, "text": " to generally understand your intent", "tokens": [51024, 281, 5101, 1223, 428, 8446, 51130], "temperature": 0.0, "avg_logprob": -0.1224878471316272, "compression_ratio": 1.7054794520547945, "no_speech_prob": 0.0011692165862768888}, {"id": 102, "seek": 23136, "start": 246.68, "end": 249.52, "text": " and take action on your behalf reliably.", "tokens": [51130, 293, 747, 3069, 322, 428, 9490, 49927, 13, 51272], "temperature": 0.0, "avg_logprob": -0.1224878471316272, "compression_ratio": 1.7054794520547945, "no_speech_prob": 0.0011692165862768888}, {"id": 103, "seek": 23136, "start": 249.52, "end": 251.68, "text": " So even at the technological layer,", "tokens": [51272, 407, 754, 412, 264, 18439, 4583, 11, 51380], "temperature": 0.0, "avg_logprob": -0.1224878471316272, "compression_ratio": 1.7054794520547945, "no_speech_prob": 0.0011692165862768888}, {"id": 104, "seek": 23136, "start": 251.68, "end": 254.32000000000002, "text": " I think us as model builders, we have a lot to do", "tokens": [51380, 286, 519, 505, 382, 2316, 36281, 11, 321, 362, 257, 688, 281, 360, 51512], "temperature": 0.0, "avg_logprob": -0.1224878471316272, "compression_ratio": 1.7054794520547945, "no_speech_prob": 0.0011692165862768888}, {"id": 105, "seek": 23136, "start": 254.32000000000002, "end": 256.48, "text": " to bring the barriers down.", "tokens": [51512, 281, 1565, 264, 13565, 760, 13, 51620], "temperature": 0.0, "avg_logprob": -0.1224878471316272, "compression_ratio": 1.7054794520547945, "no_speech_prob": 0.0011692165862768888}, {"id": 106, "seek": 23136, "start": 256.48, "end": 260.68, "text": " But I'm optimistic, like the pace of progress is fantastic.", "tokens": [51620, 583, 286, 478, 19397, 11, 411, 264, 11638, 295, 4205, 307, 5456, 13, 51830], "temperature": 0.0, "avg_logprob": -0.1224878471316272, "compression_ratio": 1.7054794520547945, "no_speech_prob": 0.0011692165862768888}, {"id": 107, "seek": 26068, "start": 260.68, "end": 261.76, "text": " Yes.", "tokens": [50364, 1079, 13, 50418], "temperature": 0.0, "avg_logprob": -0.13358717806199016, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0005570200737565756}, {"id": 108, "seek": 26068, "start": 261.76, "end": 265.0, "text": " On that kind of prompt Britonist thing,", "tokens": [50418, 1282, 300, 733, 295, 12391, 4760, 266, 468, 551, 11, 50580], "temperature": 0.0, "avg_logprob": -0.13358717806199016, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0005570200737565756}, {"id": 109, "seek": 26068, "start": 265.0, "end": 268.08, "text": " I wonder whether you think that we are on a path to have it.", "tokens": [50580, 286, 2441, 1968, 291, 519, 300, 321, 366, 322, 257, 3100, 281, 362, 309, 13, 50734], "temperature": 0.0, "avg_logprob": -0.13358717806199016, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0005570200737565756}, {"id": 110, "seek": 26068, "start": 268.08, "end": 270.0, "text": " I mean, in an ideal world,", "tokens": [50734, 286, 914, 11, 294, 364, 7157, 1002, 11, 50830], "temperature": 0.0, "avg_logprob": -0.13358717806199016, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0005570200737565756}, {"id": 111, "seek": 26068, "start": 270.0, "end": 273.24, "text": " the model and the application would be completely decoupled.", "tokens": [50830, 264, 2316, 293, 264, 3861, 576, 312, 2584, 979, 263, 15551, 13, 50992], "temperature": 0.0, "avg_logprob": -0.13358717806199016, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0005570200737565756}, {"id": 112, "seek": 26068, "start": 273.24, "end": 274.6, "text": " So you could swap the model out", "tokens": [50992, 407, 291, 727, 18135, 264, 2316, 484, 51060], "temperature": 0.0, "avg_logprob": -0.13358717806199016, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0005570200737565756}, {"id": 113, "seek": 26068, "start": 274.6, "end": 276.08, "text": " or when you folks bring out a new model,", "tokens": [51060, 420, 562, 291, 4024, 1565, 484, 257, 777, 2316, 11, 51134], "temperature": 0.0, "avg_logprob": -0.13358717806199016, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0005570200737565756}, {"id": 114, "seek": 26068, "start": 276.08, "end": 278.6, "text": " we can just swap it out and nothing breaks.", "tokens": [51134, 321, 393, 445, 18135, 309, 484, 293, 1825, 9857, 13, 51260], "temperature": 0.0, "avg_logprob": -0.13358717806199016, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0005570200737565756}, {"id": 115, "seek": 26068, "start": 278.6, "end": 280.36, "text": " But at the moment, that's not the case.", "tokens": [51260, 583, 412, 264, 1623, 11, 300, 311, 406, 264, 1389, 13, 51348], "temperature": 0.0, "avg_logprob": -0.13358717806199016, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0005570200737565756}, {"id": 116, "seek": 26068, "start": 280.36, "end": 283.64, "text": " But as the models become increasingly better,", "tokens": [51348, 583, 382, 264, 5245, 1813, 12980, 1101, 11, 51512], "temperature": 0.0, "avg_logprob": -0.13358717806199016, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0005570200737565756}, {"id": 117, "seek": 26068, "start": 283.64, "end": 285.96000000000004, "text": " do you think they will be robust in that way?", "tokens": [51512, 360, 291, 519, 436, 486, 312, 13956, 294, 300, 636, 30, 51628], "temperature": 0.0, "avg_logprob": -0.13358717806199016, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0005570200737565756}, {"id": 118, "seek": 26068, "start": 285.96000000000004, "end": 287.16, "text": " They should be, right?", "tokens": [51628, 814, 820, 312, 11, 558, 30, 51688], "temperature": 0.0, "avg_logprob": -0.13358717806199016, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0005570200737565756}, {"id": 119, "seek": 28716, "start": 288.16, "end": 290.84000000000003, "text": " There will always be quirks to different models", "tokens": [50414, 821, 486, 1009, 312, 35645, 1694, 281, 819, 5245, 50548], "temperature": 0.0, "avg_logprob": -0.20653392246791294, "compression_ratio": 1.7887931034482758, "no_speech_prob": 0.0006662477389909327}, {"id": 120, "seek": 28716, "start": 290.84000000000003, "end": 292.8, "text": " because we're all training on, you know,", "tokens": [50548, 570, 321, 434, 439, 3097, 322, 11, 291, 458, 11, 50646], "temperature": 0.0, "avg_logprob": -0.20653392246791294, "compression_ratio": 1.7887931034482758, "no_speech_prob": 0.0006662477389909327}, {"id": 121, "seek": 28716, "start": 292.8, "end": 296.68, "text": " we hope different data that focuses on different aspects", "tokens": [50646, 321, 1454, 819, 1412, 300, 16109, 322, 819, 7270, 50840], "temperature": 0.0, "avg_logprob": -0.20653392246791294, "compression_ratio": 1.7887931034482758, "no_speech_prob": 0.0006662477389909327}, {"id": 122, "seek": 28716, "start": 296.68, "end": 300.68, "text": " or elicits different behavior in the model.", "tokens": [50840, 420, 806, 299, 1208, 819, 5223, 294, 264, 2316, 13, 51040], "temperature": 0.0, "avg_logprob": -0.20653392246791294, "compression_ratio": 1.7887931034482758, "no_speech_prob": 0.0006662477389909327}, {"id": 123, "seek": 28716, "start": 300.68, "end": 305.44000000000005, "text": " So there will always be quirks to the behavior of models,", "tokens": [51040, 407, 456, 486, 1009, 312, 35645, 1694, 281, 264, 5223, 295, 5245, 11, 51278], "temperature": 0.0, "avg_logprob": -0.20653392246791294, "compression_ratio": 1.7887931034482758, "no_speech_prob": 0.0006662477389909327}, {"id": 124, "seek": 28716, "start": 305.44000000000005, "end": 307.44000000000005, "text": " the personalities of models,", "tokens": [51278, 264, 25308, 295, 5245, 11, 51378], "temperature": 0.0, "avg_logprob": -0.20653392246791294, "compression_ratio": 1.7887931034482758, "no_speech_prob": 0.0006662477389909327}, {"id": 125, "seek": 28716, "start": 307.44000000000005, "end": 309.20000000000005, "text": " what they're good at and bad at.", "tokens": [51378, 437, 436, 434, 665, 412, 293, 1578, 412, 13, 51466], "temperature": 0.0, "avg_logprob": -0.20653392246791294, "compression_ratio": 1.7887931034482758, "no_speech_prob": 0.0006662477389909327}, {"id": 126, "seek": 28716, "start": 309.20000000000005, "end": 313.44000000000005, "text": " But in general, in terms of like following an instruction,", "tokens": [51466, 583, 294, 2674, 11, 294, 2115, 295, 411, 3480, 364, 10951, 11, 51678], "temperature": 0.0, "avg_logprob": -0.20653392246791294, "compression_ratio": 1.7887931034482758, "no_speech_prob": 0.0006662477389909327}, {"id": 127, "seek": 28716, "start": 313.44000000000005, "end": 316.68, "text": " we should be quite robust to that universally.", "tokens": [51678, 321, 820, 312, 1596, 13956, 281, 300, 43995, 13, 51840], "temperature": 0.0, "avg_logprob": -0.20653392246791294, "compression_ratio": 1.7887931034482758, "no_speech_prob": 0.0006662477389909327}, {"id": 128, "seek": 31716, "start": 318.16, "end": 319.68, "text": " And so the ideal is that, yeah,", "tokens": [50414, 400, 370, 264, 7157, 307, 300, 11, 1338, 11, 50490], "temperature": 0.0, "avg_logprob": -0.11009980837504069, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.00010553102765697986}, {"id": 129, "seek": 31716, "start": 319.68, "end": 322.68, "text": " you can just take a prompt and drop it into any system", "tokens": [50490, 291, 393, 445, 747, 257, 12391, 293, 3270, 309, 666, 604, 1185, 50640], "temperature": 0.0, "avg_logprob": -0.11009980837504069, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.00010553102765697986}, {"id": 130, "seek": 31716, "start": 322.68, "end": 324.20000000000005, "text": " and see which one performs best", "tokens": [50640, 293, 536, 597, 472, 26213, 1151, 50716], "temperature": 0.0, "avg_logprob": -0.11009980837504069, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.00010553102765697986}, {"id": 131, "seek": 31716, "start": 324.20000000000005, "end": 326.32000000000005, "text": " and then move forward with that one.", "tokens": [50716, 293, 550, 1286, 2128, 365, 300, 472, 13, 50822], "temperature": 0.0, "avg_logprob": -0.11009980837504069, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.00010553102765697986}, {"id": 132, "seek": 31716, "start": 326.32000000000005, "end": 329.08000000000004, "text": " In reality, the status quo is a prompt", "tokens": [50822, 682, 4103, 11, 264, 6558, 28425, 307, 257, 12391, 50960], "temperature": 0.0, "avg_logprob": -0.11009980837504069, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.00010553102765697986}, {"id": 133, "seek": 31716, "start": 329.08000000000004, "end": 330.16, "text": " that works on one system,", "tokens": [50960, 300, 1985, 322, 472, 1185, 11, 51014], "temperature": 0.0, "avg_logprob": -0.11009980837504069, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.00010553102765697986}, {"id": 134, "seek": 31716, "start": 330.16, "end": 332.92, "text": " fundamentally does not work on another.", "tokens": [51014, 17879, 775, 406, 589, 322, 1071, 13, 51152], "temperature": 0.0, "avg_logprob": -0.11009980837504069, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.00010553102765697986}, {"id": 135, "seek": 31716, "start": 332.92, "end": 337.92, "text": " And so there's this rift or these walls in between systems", "tokens": [51152, 400, 370, 456, 311, 341, 367, 2008, 420, 613, 7920, 294, 1296, 3652, 51402], "temperature": 0.0, "avg_logprob": -0.11009980837504069, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.00010553102765697986}, {"id": 136, "seek": 31716, "start": 338.24, "end": 340.32000000000005, "text": " that make them very, very different.", "tokens": [51418, 300, 652, 552, 588, 11, 588, 819, 13, 51522], "temperature": 0.0, "avg_logprob": -0.11009980837504069, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.00010553102765697986}, {"id": 137, "seek": 31716, "start": 340.32000000000005, "end": 342.84000000000003, "text": " Hopefully that'll start to lift.", "tokens": [51522, 10429, 300, 603, 722, 281, 5533, 13, 51648], "temperature": 0.0, "avg_logprob": -0.11009980837504069, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.00010553102765697986}, {"id": 138, "seek": 31716, "start": 342.84000000000003, "end": 346.28000000000003, "text": " There's a lot of effort going into data augmentation", "tokens": [51648, 821, 311, 257, 688, 295, 4630, 516, 666, 1412, 14501, 19631, 51820], "temperature": 0.0, "avg_logprob": -0.11009980837504069, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.00010553102765697986}, {"id": 139, "seek": 34628, "start": 346.28, "end": 347.79999999999995, "text": " that makes these models more robust", "tokens": [50364, 300, 1669, 613, 5245, 544, 13956, 50440], "temperature": 0.0, "avg_logprob": -0.10148208513172395, "compression_ratio": 1.729957805907173, "no_speech_prob": 0.00018508198263589293}, {"id": 140, "seek": 34628, "start": 347.79999999999995, "end": 350.32, "text": " to changes in prompt space.", "tokens": [50440, 281, 2962, 294, 12391, 1901, 13, 50566], "temperature": 0.0, "avg_logprob": -0.10148208513172395, "compression_ratio": 1.729957805907173, "no_speech_prob": 0.00018508198263589293}, {"id": 141, "seek": 34628, "start": 350.32, "end": 351.71999999999997, "text": " We're doing a lot of work on that.", "tokens": [50566, 492, 434, 884, 257, 688, 295, 589, 322, 300, 13, 50636], "temperature": 0.0, "avg_logprob": -0.10148208513172395, "compression_ratio": 1.729957805907173, "no_speech_prob": 0.00018508198263589293}, {"id": 142, "seek": 34628, "start": 351.71999999999997, "end": 355.11999999999995, "text": " It's driven a lot by synthetic data", "tokens": [50636, 467, 311, 9555, 257, 688, 538, 23420, 1412, 50806], "temperature": 0.0, "avg_logprob": -0.10148208513172395, "compression_ratio": 1.729957805907173, "no_speech_prob": 0.00018508198263589293}, {"id": 143, "seek": 34628, "start": 355.11999999999995, "end": 359.55999999999995, "text": " and finding, doing search to basically find the prompts", "tokens": [50806, 293, 5006, 11, 884, 3164, 281, 1936, 915, 264, 41095, 51028], "temperature": 0.0, "avg_logprob": -0.10148208513172395, "compression_ratio": 1.729957805907173, "no_speech_prob": 0.00018508198263589293}, {"id": 144, "seek": 34628, "start": 359.55999999999995, "end": 362.32, "text": " or the augmentations that changes to prompts", "tokens": [51028, 420, 264, 29919, 763, 300, 2962, 281, 41095, 51166], "temperature": 0.0, "avg_logprob": -0.10148208513172395, "compression_ratio": 1.729957805907173, "no_speech_prob": 0.00018508198263589293}, {"id": 145, "seek": 34628, "start": 362.32, "end": 366.91999999999996, "text": " that break the model and then training to fix that break.", "tokens": [51166, 300, 1821, 264, 2316, 293, 550, 3097, 281, 3191, 300, 1821, 13, 51396], "temperature": 0.0, "avg_logprob": -0.10148208513172395, "compression_ratio": 1.729957805907173, "no_speech_prob": 0.00018508198263589293}, {"id": 146, "seek": 34628, "start": 367.88, "end": 369.96, "text": " So I'm optimistic that sort of brittleness", "tokens": [51444, 407, 286, 478, 19397, 300, 1333, 295, 738, 593, 45887, 51548], "temperature": 0.0, "avg_logprob": -0.10148208513172395, "compression_ratio": 1.729957805907173, "no_speech_prob": 0.00018508198263589293}, {"id": 147, "seek": 34628, "start": 369.96, "end": 370.79999999999995, "text": " is gonna go away.", "tokens": [51548, 307, 799, 352, 1314, 13, 51590], "temperature": 0.0, "avg_logprob": -0.10148208513172395, "compression_ratio": 1.729957805907173, "no_speech_prob": 0.00018508198263589293}, {"id": 148, "seek": 34628, "start": 370.79999999999995, "end": 371.79999999999995, "text": " Interesting.", "tokens": [51590, 14711, 13, 51640], "temperature": 0.0, "avg_logprob": -0.10148208513172395, "compression_ratio": 1.729957805907173, "no_speech_prob": 0.00018508198263589293}, {"id": 149, "seek": 34628, "start": 371.79999999999995, "end": 374.4, "text": " So kind of finding problems with the model", "tokens": [51640, 407, 733, 295, 5006, 2740, 365, 264, 2316, 51770], "temperature": 0.0, "avg_logprob": -0.10148208513172395, "compression_ratio": 1.729957805907173, "no_speech_prob": 0.00018508198263589293}, {"id": 150, "seek": 37440, "start": 374.4, "end": 377.4, "text": " and then robustifying and robustifying.", "tokens": [50364, 293, 550, 13956, 5489, 293, 13956, 5489, 13, 50514], "temperature": 0.0, "avg_logprob": -0.11905202632997094, "compression_ratio": 1.757936507936508, "no_speech_prob": 0.00026878065546043217}, {"id": 151, "seek": 37440, "start": 377.4, "end": 379.23999999999995, "text": " In doing so, how does that change", "tokens": [50514, 682, 884, 370, 11, 577, 775, 300, 1319, 50606], "temperature": 0.0, "avg_logprob": -0.11905202632997094, "compression_ratio": 1.757936507936508, "no_speech_prob": 0.00026878065546043217}, {"id": 152, "seek": 37440, "start": 379.23999999999995, "end": 381.28, "text": " the characteristics of the model?", "tokens": [50606, 264, 10891, 295, 264, 2316, 30, 50708], "temperature": 0.0, "avg_logprob": -0.11905202632997094, "compression_ratio": 1.757936507936508, "no_speech_prob": 0.00026878065546043217}, {"id": 153, "seek": 37440, "start": 381.28, "end": 384.47999999999996, "text": " Does it make it less creative or less capable in some sense?", "tokens": [50708, 4402, 309, 652, 309, 1570, 5880, 420, 1570, 8189, 294, 512, 2020, 30, 50868], "temperature": 0.0, "avg_logprob": -0.11905202632997094, "compression_ratio": 1.757936507936508, "no_speech_prob": 0.00026878065546043217}, {"id": 154, "seek": 37440, "start": 384.47999999999996, "end": 386.44, "text": " I mean, what do you ever feel for the trade-offs there?", "tokens": [50868, 286, 914, 11, 437, 360, 291, 1562, 841, 337, 264, 4923, 12, 19231, 456, 30, 50966], "temperature": 0.0, "avg_logprob": -0.11905202632997094, "compression_ratio": 1.757936507936508, "no_speech_prob": 0.00026878065546043217}, {"id": 155, "seek": 37440, "start": 386.44, "end": 389.23999999999995, "text": " Yeah, I mean, I don't think so.", "tokens": [50966, 865, 11, 286, 914, 11, 286, 500, 380, 519, 370, 13, 51106], "temperature": 0.0, "avg_logprob": -0.11905202632997094, "compression_ratio": 1.757936507936508, "no_speech_prob": 0.00026878065546043217}, {"id": 156, "seek": 37440, "start": 389.23999999999995, "end": 392.67999999999995, "text": " I think that that's orthogonal.", "tokens": [51106, 286, 519, 300, 300, 311, 41488, 13, 51278], "temperature": 0.0, "avg_logprob": -0.11905202632997094, "compression_ratio": 1.757936507936508, "no_speech_prob": 0.00026878065546043217}, {"id": 157, "seek": 37440, "start": 392.67999999999995, "end": 394.28, "text": " The process of making it more robust", "tokens": [51278, 440, 1399, 295, 1455, 309, 544, 13956, 51358], "temperature": 0.0, "avg_logprob": -0.11905202632997094, "compression_ratio": 1.757936507936508, "no_speech_prob": 0.00026878065546043217}, {"id": 158, "seek": 37440, "start": 394.28, "end": 395.71999999999997, "text": " is orthogonal to creativity.", "tokens": [51358, 307, 41488, 281, 12915, 13, 51430], "temperature": 0.0, "avg_logprob": -0.11905202632997094, "compression_ratio": 1.757936507936508, "no_speech_prob": 0.00026878065546043217}, {"id": 159, "seek": 37440, "start": 395.71999999999997, "end": 397.84, "text": " There are aspects of the post-training procedure", "tokens": [51430, 821, 366, 7270, 295, 264, 2183, 12, 17227, 1760, 10747, 51536], "temperature": 0.0, "avg_logprob": -0.11905202632997094, "compression_ratio": 1.757936507936508, "no_speech_prob": 0.00026878065546043217}, {"id": 160, "seek": 37440, "start": 397.84, "end": 401.91999999999996, "text": " that do reduce creativity or, you know,", "tokens": [51536, 300, 360, 5407, 12915, 420, 11, 291, 458, 11, 51740], "temperature": 0.0, "avg_logprob": -0.11905202632997094, "compression_ratio": 1.757936507936508, "no_speech_prob": 0.00026878065546043217}, {"id": 161, "seek": 40192, "start": 401.96000000000004, "end": 404.72, "text": " some people like to say like lobotomize the model.", "tokens": [50366, 512, 561, 411, 281, 584, 411, 14366, 42939, 1125, 264, 2316, 13, 50504], "temperature": 0.0, "avg_logprob": -0.11445098174245734, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.00043043168261647224}, {"id": 162, "seek": 40192, "start": 406.0, "end": 407.68, "text": " So it's definitely a problem.", "tokens": [50568, 407, 309, 311, 2138, 257, 1154, 13, 50652], "temperature": 0.0, "avg_logprob": -0.11445098174245734, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.00043043168261647224}, {"id": 163, "seek": 40192, "start": 407.68, "end": 410.32, "text": " It's something that we watch for", "tokens": [50652, 467, 311, 746, 300, 321, 1159, 337, 50784], "temperature": 0.0, "avg_logprob": -0.11445098174245734, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.00043043168261647224}, {"id": 164, "seek": 40192, "start": 410.32, "end": 414.04, "text": " and we're trying to prevent.", "tokens": [50784, 293, 321, 434, 1382, 281, 4871, 13, 50970], "temperature": 0.0, "avg_logprob": -0.11445098174245734, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.00043043168261647224}, {"id": 165, "seek": 40192, "start": 414.04, "end": 419.04, "text": " I would say that one of the most disappointing aspects", "tokens": [50970, 286, 576, 584, 300, 472, 295, 264, 881, 25054, 7270, 51220], "temperature": 0.0, "avg_logprob": -0.11445098174245734, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.00043043168261647224}, {"id": 166, "seek": 40192, "start": 419.04, "end": 420.96000000000004, "text": " of the current regime of building these models", "tokens": [51220, 295, 264, 2190, 13120, 295, 2390, 613, 5245, 51316], "temperature": 0.0, "avg_logprob": -0.11445098174245734, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.00043043168261647224}, {"id": 167, "seek": 40192, "start": 420.96000000000004, "end": 424.44, "text": " is that a lot of people train on synthetic data", "tokens": [51316, 307, 300, 257, 688, 295, 561, 3847, 322, 23420, 1412, 51490], "temperature": 0.0, "avg_logprob": -0.11445098174245734, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.00043043168261647224}, {"id": 168, "seek": 40192, "start": 424.44, "end": 425.76, "text": " from one source, right?", "tokens": [51490, 490, 472, 4009, 11, 558, 30, 51556], "temperature": 0.0, "avg_logprob": -0.11445098174245734, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.00043043168261647224}, {"id": 169, "seek": 40192, "start": 425.76, "end": 427.72, "text": " Like just from the GPT models.", "tokens": [51556, 1743, 445, 490, 264, 26039, 51, 5245, 13, 51654], "temperature": 0.0, "avg_logprob": -0.11445098174245734, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.00043043168261647224}, {"id": 170, "seek": 40192, "start": 427.72, "end": 429.68, "text": " And so all of them, all of the models", "tokens": [51654, 400, 370, 439, 295, 552, 11, 439, 295, 264, 5245, 51752], "temperature": 0.0, "avg_logprob": -0.11445098174245734, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.00043043168261647224}, {"id": 171, "seek": 40192, "start": 429.68, "end": 431.76, "text": " that are being created,", "tokens": [51752, 300, 366, 885, 2942, 11, 51856], "temperature": 0.0, "avg_logprob": -0.11445098174245734, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.00043043168261647224}, {"id": 172, "seek": 43176, "start": 431.76, "end": 433.4, "text": " they sort of speak the same.", "tokens": [50364, 436, 1333, 295, 1710, 264, 912, 13, 50446], "temperature": 0.0, "avg_logprob": -0.14259998003641763, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.00026936971698887646}, {"id": 173, "seek": 43176, "start": 433.4, "end": 435.68, "text": " They kind of have the same personality", "tokens": [50446, 814, 733, 295, 362, 264, 912, 9033, 50560], "temperature": 0.0, "avg_logprob": -0.14259998003641763, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.00026936971698887646}, {"id": 174, "seek": 43176, "start": 435.68, "end": 438.56, "text": " and it leads to this collapse", "tokens": [50560, 293, 309, 6689, 281, 341, 15584, 50704], "temperature": 0.0, "avg_logprob": -0.14259998003641763, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.00026936971698887646}, {"id": 175, "seek": 43176, "start": 438.56, "end": 441.15999999999997, "text": " into a lot of different models", "tokens": [50704, 666, 257, 688, 295, 819, 5245, 50834], "temperature": 0.0, "avg_logprob": -0.14259998003641763, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.00026936971698887646}, {"id": 176, "seek": 43176, "start": 441.15999999999997, "end": 442.64, "text": " looking and feeling the same.", "tokens": [50834, 1237, 293, 2633, 264, 912, 13, 50908], "temperature": 0.0, "avg_logprob": -0.14259998003641763, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.00026936971698887646}, {"id": 177, "seek": 43176, "start": 445.15999999999997, "end": 446.2, "text": " And that makes them boring", "tokens": [51034, 400, 300, 1669, 552, 9989, 51086], "temperature": 0.0, "avg_logprob": -0.14259998003641763, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.00026936971698887646}, {"id": 178, "seek": 43176, "start": 447.28, "end": 451.8, "text": " because like you have the same shortcomings across models", "tokens": [51140, 570, 411, 291, 362, 264, 912, 2099, 49886, 2108, 5245, 51366], "temperature": 0.0, "avg_logprob": -0.14259998003641763, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.00026936971698887646}, {"id": 179, "seek": 43176, "start": 451.8, "end": 454.52, "text": " rather than if you have a diverse set of models", "tokens": [51366, 2831, 813, 498, 291, 362, 257, 9521, 992, 295, 5245, 51502], "temperature": 0.0, "avg_logprob": -0.14259998003641763, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.00026936971698887646}, {"id": 180, "seek": 43176, "start": 454.52, "end": 456.84, "text": " that have different failures in different places,", "tokens": [51502, 300, 362, 819, 20774, 294, 819, 3190, 11, 51618], "temperature": 0.0, "avg_logprob": -0.14259998003641763, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.00026936971698887646}, {"id": 181, "seek": 43176, "start": 456.84, "end": 459.76, "text": " you can much better address, you know,", "tokens": [51618, 291, 393, 709, 1101, 2985, 11, 291, 458, 11, 51764], "temperature": 0.0, "avg_logprob": -0.14259998003641763, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.00026936971698887646}, {"id": 182, "seek": 45976, "start": 459.76, "end": 462.8, "text": " the preferences of much more people.", "tokens": [50364, 264, 21910, 295, 709, 544, 561, 13, 50516], "temperature": 0.0, "avg_logprob": -0.17009907183439835, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.0003300307143945247}, {"id": 183, "seek": 45976, "start": 464.48, "end": 468.32, "text": " I've noticed due to synthetic data taking off,", "tokens": [50600, 286, 600, 5694, 3462, 281, 23420, 1412, 1940, 766, 11, 50792], "temperature": 0.0, "avg_logprob": -0.17009907183439835, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.0003300307143945247}, {"id": 184, "seek": 45976, "start": 469.28, "end": 471.59999999999997, "text": " just a total collapse in terms of", "tokens": [50840, 445, 257, 3217, 15584, 294, 2115, 295, 50956], "temperature": 0.0, "avg_logprob": -0.17009907183439835, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.0003300307143945247}, {"id": 185, "seek": 45976, "start": 472.59999999999997, "end": 477.4, "text": " the different types of behavior models exhibit", "tokens": [51006, 264, 819, 3467, 295, 5223, 5245, 20487, 51246], "temperature": 0.0, "avg_logprob": -0.17009907183439835, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.0003300307143945247}, {"id": 186, "seek": 45976, "start": 477.4, "end": 481.28, "text": " and that cohere because our customers are enterprises.", "tokens": [51246, 293, 300, 598, 6703, 570, 527, 4581, 366, 29034, 13, 51440], "temperature": 0.0, "avg_logprob": -0.17009907183439835, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.0003300307143945247}, {"id": 187, "seek": 45976, "start": 481.28, "end": 482.36, "text": " Like that's who we sell to.", "tokens": [51440, 1743, 300, 311, 567, 321, 3607, 281, 13, 51494], "temperature": 0.0, "avg_logprob": -0.17009907183439835, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.0003300307143945247}, {"id": 188, "seek": 45976, "start": 482.36, "end": 484.08, "text": " It's not consumers, it's not, you know,", "tokens": [51494, 467, 311, 406, 11883, 11, 309, 311, 406, 11, 291, 458, 11, 51580], "temperature": 0.0, "avg_logprob": -0.17009907183439835, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.0003300307143945247}, {"id": 189, "seek": 45976, "start": 484.08, "end": 486.24, "text": " anything other than enterprises", "tokens": [51580, 1340, 661, 813, 29034, 51688], "temperature": 0.0, "avg_logprob": -0.17009907183439835, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.0003300307143945247}, {"id": 190, "seek": 45976, "start": 486.24, "end": 488.59999999999997, "text": " who want to adopt this tech.", "tokens": [51688, 567, 528, 281, 6878, 341, 7553, 13, 51806], "temperature": 0.0, "avg_logprob": -0.17009907183439835, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.0003300307143945247}, {"id": 191, "seek": 48860, "start": 488.6, "end": 490.04, "text": " And they're very, very sensitive", "tokens": [50364, 400, 436, 434, 588, 11, 588, 9477, 50436], "temperature": 0.0, "avg_logprob": -0.10370500882466634, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0004441050114110112}, {"id": 192, "seek": 48860, "start": 490.04, "end": 491.84000000000003, "text": " to what data went into the model.", "tokens": [50436, 281, 437, 1412, 1437, 666, 264, 2316, 13, 50526], "temperature": 0.0, "avg_logprob": -0.10370500882466634, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0004441050114110112}, {"id": 193, "seek": 48860, "start": 491.84000000000003, "end": 494.8, "text": " And so we exclude other model providers,", "tokens": [50526, 400, 370, 321, 33536, 661, 2316, 11330, 11, 50674], "temperature": 0.0, "avg_logprob": -0.10370500882466634, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0004441050114110112}, {"id": 194, "seek": 48860, "start": 494.8, "end": 498.04, "text": " data, you know, very aggressively.", "tokens": [50674, 1412, 11, 291, 458, 11, 588, 32024, 13, 50836], "temperature": 0.0, "avg_logprob": -0.10370500882466634, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0004441050114110112}, {"id": 195, "seek": 48860, "start": 498.04, "end": 499.32000000000005, "text": " Of course, some will slip in", "tokens": [50836, 2720, 1164, 11, 512, 486, 11140, 294, 50900], "temperature": 0.0, "avg_logprob": -0.10370500882466634, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0004441050114110112}, {"id": 196, "seek": 48860, "start": 499.32000000000005, "end": 501.12, "text": " as we're scraping the web, et cetera.", "tokens": [50900, 382, 321, 434, 43738, 264, 3670, 11, 1030, 11458, 13, 50990], "temperature": 0.0, "avg_logprob": -0.10370500882466634, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0004441050114110112}, {"id": 197, "seek": 48860, "start": 501.12, "end": 503.0, "text": " But we make a very concerted effort", "tokens": [50990, 583, 321, 652, 257, 588, 8543, 292, 4630, 51084], "temperature": 0.0, "avg_logprob": -0.10370500882466634, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0004441050114110112}, {"id": 198, "seek": 48860, "start": 503.0, "end": 506.28000000000003, "text": " to avoid other model outputs.", "tokens": [51084, 281, 5042, 661, 2316, 23930, 13, 51248], "temperature": 0.0, "avg_logprob": -0.10370500882466634, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0004441050114110112}, {"id": 199, "seek": 48860, "start": 506.28000000000003, "end": 508.32000000000005, "text": " And so if you talk to our model,", "tokens": [51248, 400, 370, 498, 291, 751, 281, 527, 2316, 11, 51350], "temperature": 0.0, "avg_logprob": -0.10370500882466634, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0004441050114110112}, {"id": 200, "seek": 48860, "start": 508.32000000000005, "end": 510.28000000000003, "text": " when we release command R and R plus,", "tokens": [51350, 562, 321, 4374, 5622, 497, 293, 497, 1804, 11, 51448], "temperature": 0.0, "avg_logprob": -0.10370500882466634, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0004441050114110112}, {"id": 201, "seek": 48860, "start": 510.28000000000003, "end": 513.28, "text": " one of the things I kept reading on Reddit and Twitter", "tokens": [51448, 472, 295, 264, 721, 286, 4305, 3760, 322, 32210, 293, 5794, 51598], "temperature": 0.0, "avg_logprob": -0.10370500882466634, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0004441050114110112}, {"id": 202, "seek": 48860, "start": 513.28, "end": 514.6, "text": " was it feels different.", "tokens": [51598, 390, 309, 3417, 819, 13, 51664], "temperature": 0.0, "avg_logprob": -0.10370500882466634, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0004441050114110112}, {"id": 203, "seek": 48860, "start": 514.6, "end": 517.6800000000001, "text": " Like something feels special about this model.", "tokens": [51664, 1743, 746, 3417, 2121, 466, 341, 2316, 13, 51818], "temperature": 0.0, "avg_logprob": -0.10370500882466634, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0004441050114110112}, {"id": 204, "seek": 51768, "start": 517.68, "end": 520.3599999999999, "text": " I don't think that's any like magic at cohere", "tokens": [50364, 286, 500, 380, 519, 300, 311, 604, 411, 5585, 412, 598, 6703, 50498], "temperature": 0.0, "avg_logprob": -0.12432666647023168, "compression_ratio": 1.71875, "no_speech_prob": 0.0001875392481451854}, {"id": 205, "seek": 51768, "start": 520.3599999999999, "end": 521.8, "text": " other than the fact that we didn't do", "tokens": [50498, 661, 813, 264, 1186, 300, 321, 994, 380, 360, 50570], "temperature": 0.0, "avg_logprob": -0.12432666647023168, "compression_ratio": 1.71875, "no_speech_prob": 0.0001875392481451854}, {"id": 206, "seek": 51768, "start": 521.8, "end": 523.2399999999999, "text": " what the other guys are doing,", "tokens": [50570, 437, 264, 661, 1074, 366, 884, 11, 50642], "temperature": 0.0, "avg_logprob": -0.12432666647023168, "compression_ratio": 1.71875, "no_speech_prob": 0.0001875392481451854}, {"id": 207, "seek": 51768, "start": 523.2399999999999, "end": 526.3599999999999, "text": " which is training on the model outputs of OpenAI.", "tokens": [50642, 597, 307, 3097, 322, 264, 2316, 23930, 295, 7238, 48698, 13, 50798], "temperature": 0.0, "avg_logprob": -0.12432666647023168, "compression_ratio": 1.71875, "no_speech_prob": 0.0001875392481451854}, {"id": 208, "seek": 51768, "start": 526.3599999999999, "end": 527.1999999999999, "text": " I agree with you.", "tokens": [50798, 286, 3986, 365, 291, 13, 50840], "temperature": 0.0, "avg_logprob": -0.12432666647023168, "compression_ratio": 1.71875, "no_speech_prob": 0.0001875392481451854}, {"id": 209, "seek": 51768, "start": 527.1999999999999, "end": 530.04, "text": " So when people, you know,", "tokens": [50840, 407, 562, 561, 11, 291, 458, 11, 50982], "temperature": 0.0, "avg_logprob": -0.12432666647023168, "compression_ratio": 1.71875, "no_speech_prob": 0.0001875392481451854}, {"id": 210, "seek": 51768, "start": 530.04, "end": 532.0, "text": " see chat GPT or whatever for the first time,", "tokens": [50982, 536, 5081, 26039, 51, 420, 2035, 337, 264, 700, 565, 11, 51080], "temperature": 0.0, "avg_logprob": -0.12432666647023168, "compression_ratio": 1.71875, "no_speech_prob": 0.0001875392481451854}, {"id": 211, "seek": 51768, "start": 532.0, "end": 533.76, "text": " that they're blown away by it.", "tokens": [51080, 300, 436, 434, 16479, 1314, 538, 309, 13, 51168], "temperature": 0.0, "avg_logprob": -0.12432666647023168, "compression_ratio": 1.71875, "no_speech_prob": 0.0001875392481451854}, {"id": 212, "seek": 51768, "start": 533.76, "end": 537.1999999999999, "text": " But there are motifs that come up again and again", "tokens": [51168, 583, 456, 366, 2184, 18290, 300, 808, 493, 797, 293, 797, 51340], "temperature": 0.0, "avg_logprob": -0.12432666647023168, "compression_ratio": 1.71875, "no_speech_prob": 0.0001875392481451854}, {"id": 213, "seek": 51768, "start": 537.1999999999999, "end": 540.04, "text": " and again, unraveling the mysteries, you know,", "tokens": [51340, 293, 797, 11, 40507, 278, 264, 30785, 11, 291, 458, 11, 51482], "temperature": 0.0, "avg_logprob": -0.12432666647023168, "compression_ratio": 1.71875, "no_speech_prob": 0.0001875392481451854}, {"id": 214, "seek": 51768, "start": 540.04, "end": 542.64, "text": " delving into the intricate complexities", "tokens": [51482, 1103, 798, 666, 264, 38015, 48705, 51612], "temperature": 0.0, "avg_logprob": -0.12432666647023168, "compression_ratio": 1.71875, "no_speech_prob": 0.0001875392481451854}, {"id": 215, "seek": 51768, "start": 542.64, "end": 544.0, "text": " or blah, blah, blah, blah, blah.", "tokens": [51612, 420, 12288, 11, 12288, 11, 12288, 11, 12288, 11, 12288, 13, 51680], "temperature": 0.0, "avg_logprob": -0.12432666647023168, "compression_ratio": 1.71875, "no_speech_prob": 0.0001875392481451854}, {"id": 216, "seek": 51768, "start": 544.0, "end": 546.3199999999999, "text": " And when you start to see these patterns", "tokens": [51680, 400, 562, 291, 722, 281, 536, 613, 8294, 51796], "temperature": 0.0, "avg_logprob": -0.12432666647023168, "compression_ratio": 1.71875, "no_speech_prob": 0.0001875392481451854}, {"id": 217, "seek": 54632, "start": 546.32, "end": 549.08, "text": " and these constructions, you just start to think,", "tokens": [50364, 293, 613, 7690, 626, 11, 291, 445, 722, 281, 519, 11, 50502], "temperature": 0.0, "avg_logprob": -0.11351933198816636, "compression_ratio": 1.8448275862068966, "no_speech_prob": 0.002432543318718672}, {"id": 218, "seek": 54632, "start": 549.08, "end": 550.72, "text": " oh, I don't like this very much", "tokens": [50502, 1954, 11, 286, 500, 380, 411, 341, 588, 709, 50584], "temperature": 0.0, "avg_logprob": -0.11351933198816636, "compression_ratio": 1.8448275862068966, "no_speech_prob": 0.002432543318718672}, {"id": 219, "seek": 54632, "start": 550.72, "end": 552.08, "text": " because you start to see through it.", "tokens": [50584, 570, 291, 722, 281, 536, 807, 309, 13, 50652], "temperature": 0.0, "avg_logprob": -0.11351933198816636, "compression_ratio": 1.8448275862068966, "no_speech_prob": 0.002432543318718672}, {"id": 220, "seek": 54632, "start": 552.08, "end": 553.1600000000001, "text": " It's a little bit like, you know,", "tokens": [50652, 467, 311, 257, 707, 857, 411, 11, 291, 458, 11, 50706], "temperature": 0.0, "avg_logprob": -0.11351933198816636, "compression_ratio": 1.8448275862068966, "no_speech_prob": 0.002432543318718672}, {"id": 221, "seek": 54632, "start": 553.1600000000001, "end": 554.8000000000001, "text": " when you start to see through someone,", "tokens": [50706, 562, 291, 722, 281, 536, 807, 1580, 11, 50788], "temperature": 0.0, "avg_logprob": -0.11351933198816636, "compression_ratio": 1.8448275862068966, "no_speech_prob": 0.002432543318718672}, {"id": 222, "seek": 54632, "start": 554.8000000000001, "end": 556.5200000000001, "text": " they're not interesting anymore.", "tokens": [50788, 436, 434, 406, 1880, 3602, 13, 50874], "temperature": 0.0, "avg_logprob": -0.11351933198816636, "compression_ratio": 1.8448275862068966, "no_speech_prob": 0.002432543318718672}, {"id": 223, "seek": 54632, "start": 556.5200000000001, "end": 558.72, "text": " And I haven't seen that with cohere,", "tokens": [50874, 400, 286, 2378, 380, 1612, 300, 365, 598, 6703, 11, 50984], "temperature": 0.0, "avg_logprob": -0.11351933198816636, "compression_ratio": 1.8448275862068966, "no_speech_prob": 0.002432543318718672}, {"id": 224, "seek": 54632, "start": 558.72, "end": 561.5200000000001, "text": " but I have seen it with many of the other models.", "tokens": [50984, 457, 286, 362, 1612, 309, 365, 867, 295, 264, 661, 5245, 13, 51124], "temperature": 0.0, "avg_logprob": -0.11351933198816636, "compression_ratio": 1.8448275862068966, "no_speech_prob": 0.002432543318718672}, {"id": 225, "seek": 54632, "start": 561.5200000000001, "end": 564.0400000000001, "text": " Now, my intuition was always,", "tokens": [51124, 823, 11, 452, 24002, 390, 1009, 11, 51250], "temperature": 0.0, "avg_logprob": -0.11351933198816636, "compression_ratio": 1.8448275862068966, "no_speech_prob": 0.002432543318718672}, {"id": 226, "seek": 54632, "start": 564.0400000000001, "end": 565.84, "text": " I don't, I haven't really formed this very well,", "tokens": [51250, 286, 500, 380, 11, 286, 2378, 380, 534, 8693, 341, 588, 731, 11, 51340], "temperature": 0.0, "avg_logprob": -0.11351933198816636, "compression_ratio": 1.8448275862068966, "no_speech_prob": 0.002432543318718672}, {"id": 227, "seek": 54632, "start": 565.84, "end": 568.4000000000001, "text": " but I thought that maybe it could come from", "tokens": [51340, 457, 286, 1194, 300, 1310, 309, 727, 808, 490, 51468], "temperature": 0.0, "avg_logprob": -0.11351933198816636, "compression_ratio": 1.8448275862068966, "no_speech_prob": 0.002432543318718672}, {"id": 228, "seek": 54632, "start": 568.4000000000001, "end": 570.2800000000001, "text": " just the kind of data sets that we're using,", "tokens": [51468, 445, 264, 733, 295, 1412, 6352, 300, 321, 434, 1228, 11, 51562], "temperature": 0.0, "avg_logprob": -0.11351933198816636, "compression_ratio": 1.8448275862068966, "no_speech_prob": 0.002432543318718672}, {"id": 229, "seek": 54632, "start": 570.2800000000001, "end": 574.0400000000001, "text": " or maybe it could come from the preference fine tuning.", "tokens": [51562, 420, 1310, 309, 727, 808, 490, 264, 17502, 2489, 15164, 13, 51750], "temperature": 0.0, "avg_logprob": -0.11351933198816636, "compression_ratio": 1.8448275862068966, "no_speech_prob": 0.002432543318718672}, {"id": 230, "seek": 57404, "start": 574.4, "end": 576.9599999999999, "text": " Are you saying that that monolithic effect", "tokens": [50382, 2014, 291, 1566, 300, 300, 1108, 42878, 1802, 50510], "temperature": 0.0, "avg_logprob": -0.10724796209120213, "compression_ratio": 1.7518796992481203, "no_speech_prob": 0.003421292407438159}, {"id": 231, "seek": 57404, "start": 576.9599999999999, "end": 580.0799999999999, "text": " is because they're kind of eating each other's poop?", "tokens": [50510, 307, 570, 436, 434, 733, 295, 3936, 1184, 661, 311, 17153, 30, 50666], "temperature": 0.0, "avg_logprob": -0.10724796209120213, "compression_ratio": 1.7518796992481203, "no_speech_prob": 0.003421292407438159}, {"id": 232, "seek": 57404, "start": 580.0799999999999, "end": 581.64, "text": " Yeah, no, yeah, yeah.", "tokens": [50666, 865, 11, 572, 11, 1338, 11, 1338, 13, 50744], "temperature": 0.0, "avg_logprob": -0.10724796209120213, "compression_ratio": 1.7518796992481203, "no_speech_prob": 0.003421292407438159}, {"id": 233, "seek": 57404, "start": 581.64, "end": 584.4399999999999, "text": " It's some sort of like human centipede effect.", "tokens": [50744, 467, 311, 512, 1333, 295, 411, 1952, 1489, 647, 4858, 1802, 13, 50884], "temperature": 0.0, "avg_logprob": -0.10724796209120213, "compression_ratio": 1.7518796992481203, "no_speech_prob": 0.003421292407438159}, {"id": 234, "seek": 57404, "start": 584.4399999999999, "end": 588.9599999999999, "text": " I think, yeah, they're training on the outputs", "tokens": [50884, 286, 519, 11, 1338, 11, 436, 434, 3097, 322, 264, 23930, 51110], "temperature": 0.0, "avg_logprob": -0.10724796209120213, "compression_ratio": 1.7518796992481203, "no_speech_prob": 0.003421292407438159}, {"id": 235, "seek": 57404, "start": 588.9599999999999, "end": 590.36, "text": " of a single model.", "tokens": [51110, 295, 257, 2167, 2316, 13, 51180], "temperature": 0.0, "avg_logprob": -0.10724796209120213, "compression_ratio": 1.7518796992481203, "no_speech_prob": 0.003421292407438159}, {"id": 236, "seek": 57404, "start": 590.36, "end": 592.9599999999999, "text": " And so it's all collapsing into that model's", "tokens": [51180, 400, 370, 309, 311, 439, 45339, 666, 300, 2316, 311, 51310], "temperature": 0.0, "avg_logprob": -0.10724796209120213, "compression_ratio": 1.7518796992481203, "no_speech_prob": 0.003421292407438159}, {"id": 237, "seek": 57404, "start": 592.9599999999999, "end": 594.0, "text": " output distribution.", "tokens": [51310, 5598, 7316, 13, 51362], "temperature": 0.0, "avg_logprob": -0.10724796209120213, "compression_ratio": 1.7518796992481203, "no_speech_prob": 0.003421292407438159}, {"id": 238, "seek": 57404, "start": 594.0, "end": 596.0799999999999, "text": " And so if that output distribution has quirks", "tokens": [51362, 400, 370, 498, 300, 5598, 7316, 575, 35645, 1694, 51466], "temperature": 0.0, "avg_logprob": -0.10724796209120213, "compression_ratio": 1.7518796992481203, "no_speech_prob": 0.003421292407438159}, {"id": 239, "seek": 57404, "start": 596.0799999999999, "end": 599.4399999999999, "text": " like saying the word delve a lot,", "tokens": [51466, 411, 1566, 264, 1349, 43098, 257, 688, 11, 51634], "temperature": 0.0, "avg_logprob": -0.10724796209120213, "compression_ratio": 1.7518796992481203, "no_speech_prob": 0.003421292407438159}, {"id": 240, "seek": 57404, "start": 599.4399999999999, "end": 601.4, "text": " then it's gonna just pop up all over the place.", "tokens": [51634, 550, 309, 311, 799, 445, 1665, 493, 439, 670, 264, 1081, 13, 51732], "temperature": 0.0, "avg_logprob": -0.10724796209120213, "compression_ratio": 1.7518796992481203, "no_speech_prob": 0.003421292407438159}, {"id": 241, "seek": 57404, "start": 601.4, "end": 603.88, "text": " And people will take it for granted that,", "tokens": [51732, 400, 561, 486, 747, 309, 337, 12344, 300, 11, 51856], "temperature": 0.0, "avg_logprob": -0.10724796209120213, "compression_ratio": 1.7518796992481203, "no_speech_prob": 0.003421292407438159}, {"id": 242, "seek": 60388, "start": 603.88, "end": 606.28, "text": " oh, I guess LLMs just behave like this,", "tokens": [50364, 1954, 11, 286, 2041, 441, 43, 26386, 445, 15158, 411, 341, 11, 50484], "temperature": 0.0, "avg_logprob": -0.12297391302791642, "compression_ratio": 1.674772036474164, "no_speech_prob": 0.00016849390522111207}, {"id": 243, "seek": 60388, "start": 606.28, "end": 607.64, "text": " but they don't have to.", "tokens": [50484, 457, 436, 500, 380, 362, 281, 13, 50552], "temperature": 0.0, "avg_logprob": -0.12297391302791642, "compression_ratio": 1.674772036474164, "no_speech_prob": 0.00016849390522111207}, {"id": 244, "seek": 60388, "start": 607.64, "end": 608.48, "text": " They don't have to.", "tokens": [50552, 814, 500, 380, 362, 281, 13, 50594], "temperature": 0.0, "avg_logprob": -0.12297391302791642, "compression_ratio": 1.674772036474164, "no_speech_prob": 0.00016849390522111207}, {"id": 245, "seek": 60388, "start": 608.48, "end": 610.76, "text": " It's interesting how subjective creativity is as well,", "tokens": [50594, 467, 311, 1880, 577, 25972, 12915, 307, 382, 731, 11, 50708], "temperature": 0.0, "avg_logprob": -0.12297391302791642, "compression_ratio": 1.674772036474164, "no_speech_prob": 0.00016849390522111207}, {"id": 246, "seek": 60388, "start": 610.76, "end": 611.84, "text": " because a lot of people thought", "tokens": [50708, 570, 257, 688, 295, 561, 1194, 50762], "temperature": 0.0, "avg_logprob": -0.12297391302791642, "compression_ratio": 1.674772036474164, "no_speech_prob": 0.00016849390522111207}, {"id": 247, "seek": 60388, "start": 611.84, "end": 613.88, "text": " that it was creative a couple of years ago.", "tokens": [50762, 300, 309, 390, 5880, 257, 1916, 295, 924, 2057, 13, 50864], "temperature": 0.0, "avg_logprob": -0.12297391302791642, "compression_ratio": 1.674772036474164, "no_speech_prob": 0.00016849390522111207}, {"id": 248, "seek": 60388, "start": 613.88, "end": 614.84, "text": " And then when you see it everywhere,", "tokens": [50864, 400, 550, 562, 291, 536, 309, 5315, 11, 50912], "temperature": 0.0, "avg_logprob": -0.12297391302791642, "compression_ratio": 1.674772036474164, "no_speech_prob": 0.00016849390522111207}, {"id": 249, "seek": 60388, "start": 614.84, "end": 615.8, "text": " it's not creative anymore.", "tokens": [50912, 309, 311, 406, 5880, 3602, 13, 50960], "temperature": 0.0, "avg_logprob": -0.12297391302791642, "compression_ratio": 1.674772036474164, "no_speech_prob": 0.00016849390522111207}, {"id": 250, "seek": 60388, "start": 615.8, "end": 618.28, "text": " So it needs to be novel to be creative.", "tokens": [50960, 407, 309, 2203, 281, 312, 7613, 281, 312, 5880, 13, 51084], "temperature": 0.0, "avg_logprob": -0.12297391302791642, "compression_ratio": 1.674772036474164, "no_speech_prob": 0.00016849390522111207}, {"id": 251, "seek": 60388, "start": 618.28, "end": 621.16, "text": " But I mean, you folks have just released", "tokens": [51084, 583, 286, 914, 11, 291, 4024, 362, 445, 4736, 51228], "temperature": 0.0, "avg_logprob": -0.12297391302791642, "compression_ratio": 1.674772036474164, "no_speech_prob": 0.00016849390522111207}, {"id": 252, "seek": 60388, "start": 621.16, "end": 622.72, "text": " the command R series of models", "tokens": [51228, 264, 5622, 497, 2638, 295, 5245, 51306], "temperature": 0.0, "avg_logprob": -0.12297391302791642, "compression_ratio": 1.674772036474164, "no_speech_prob": 0.00016849390522111207}, {"id": 253, "seek": 60388, "start": 622.72, "end": 625.48, "text": " and you've blown everyone away.", "tokens": [51306, 293, 291, 600, 16479, 1518, 1314, 13, 51444], "temperature": 0.0, "avg_logprob": -0.12297391302791642, "compression_ratio": 1.674772036474164, "no_speech_prob": 0.00016849390522111207}, {"id": 254, "seek": 60388, "start": 625.48, "end": 626.36, "text": " Tell me about them.", "tokens": [51444, 5115, 385, 466, 552, 13, 51488], "temperature": 0.0, "avg_logprob": -0.12297391302791642, "compression_ratio": 1.674772036474164, "no_speech_prob": 0.00016849390522111207}, {"id": 255, "seek": 60388, "start": 626.36, "end": 628.08, "text": " But if you wouldn't mind also,", "tokens": [51488, 583, 498, 291, 2759, 380, 1575, 611, 11, 51574], "temperature": 0.0, "avg_logprob": -0.12297391302791642, "compression_ratio": 1.674772036474164, "no_speech_prob": 0.00016849390522111207}, {"id": 256, "seek": 60388, "start": 628.08, "end": 630.4, "text": " why did it take you a while to catch up", "tokens": [51574, 983, 630, 309, 747, 291, 257, 1339, 281, 3745, 493, 51690], "temperature": 0.0, "avg_logprob": -0.12297391302791642, "compression_ratio": 1.674772036474164, "no_speech_prob": 0.00016849390522111207}, {"id": 257, "seek": 60388, "start": 630.4, "end": 631.8, "text": " and get state of the art performance?", "tokens": [51690, 293, 483, 1785, 295, 264, 1523, 3389, 30, 51760], "temperature": 0.0, "avg_logprob": -0.12297391302791642, "compression_ratio": 1.674772036474164, "no_speech_prob": 0.00016849390522111207}, {"id": 258, "seek": 63180, "start": 631.8399999999999, "end": 636.28, "text": " Yeah, we spent a lot of 2023 lagging.", "tokens": [50366, 865, 11, 321, 4418, 257, 688, 295, 44377, 8953, 3249, 13, 50588], "temperature": 0.0, "avg_logprob": -0.11271786045383762, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.00033522892044857144}, {"id": 259, "seek": 63180, "start": 636.28, "end": 638.52, "text": " I think that that is accurate to say.", "tokens": [50588, 286, 519, 300, 300, 307, 8559, 281, 584, 13, 50700], "temperature": 0.0, "avg_logprob": -0.11271786045383762, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.00033522892044857144}, {"id": 260, "seek": 63180, "start": 639.4, "end": 643.88, "text": " What we were doing was sort of reorganizing internally.", "tokens": [50744, 708, 321, 645, 884, 390, 1333, 295, 41203, 3319, 19501, 13, 50968], "temperature": 0.0, "avg_logprob": -0.11271786045383762, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.00033522892044857144}, {"id": 261, "seek": 63180, "start": 643.88, "end": 645.1999999999999, "text": " We were rebuilding the company,", "tokens": [50968, 492, 645, 36717, 264, 2237, 11, 51034], "temperature": 0.0, "avg_logprob": -0.11271786045383762, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.00033522892044857144}, {"id": 262, "seek": 63180, "start": 645.1999999999999, "end": 648.4799999999999, "text": " rebuilding the modeling team, the tech strategy", "tokens": [51034, 36717, 264, 15983, 1469, 11, 264, 7553, 5206, 51198], "temperature": 0.0, "avg_logprob": -0.11271786045383762, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.00033522892044857144}, {"id": 263, "seek": 63180, "start": 648.4799999999999, "end": 652.8, "text": " and preparing for the runs that led to command R.", "tokens": [51198, 293, 10075, 337, 264, 6676, 300, 4684, 281, 5622, 497, 13, 51414], "temperature": 0.0, "avg_logprob": -0.11271786045383762, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.00033522892044857144}, {"id": 264, "seek": 63180, "start": 652.8, "end": 654.12, "text": " It was clear to us that the process", "tokens": [51414, 467, 390, 1850, 281, 505, 300, 264, 1399, 51480], "temperature": 0.0, "avg_logprob": -0.11271786045383762, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.00033522892044857144}, {"id": 265, "seek": 63180, "start": 654.12, "end": 656.28, "text": " that we had used to build the first command", "tokens": [51480, 300, 321, 632, 1143, 281, 1322, 264, 700, 5622, 51588], "temperature": 0.0, "avg_logprob": -0.11271786045383762, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.00033522892044857144}, {"id": 266, "seek": 63180, "start": 656.28, "end": 658.9599999999999, "text": " and generations before that, it wasn't working.", "tokens": [51588, 293, 10593, 949, 300, 11, 309, 2067, 380, 1364, 13, 51722], "temperature": 0.0, "avg_logprob": -0.11271786045383762, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.00033522892044857144}, {"id": 267, "seek": 63180, "start": 658.9599999999999, "end": 660.28, "text": " It wasn't gonna scale.", "tokens": [51722, 467, 2067, 380, 799, 4373, 13, 51788], "temperature": 0.0, "avg_logprob": -0.11271786045383762, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.00033522892044857144}, {"id": 268, "seek": 66028, "start": 660.28, "end": 663.52, "text": " And so we just rethought the entire pipeline.", "tokens": [50364, 400, 370, 321, 445, 319, 43135, 264, 2302, 15517, 13, 50526], "temperature": 0.0, "avg_logprob": -0.10506209418887184, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.00011958140385104343}, {"id": 269, "seek": 66028, "start": 663.52, "end": 666.52, "text": " And it took us a while to rebuild things,", "tokens": [50526, 400, 309, 1890, 505, 257, 1339, 281, 16877, 721, 11, 50676], "temperature": 0.0, "avg_logprob": -0.10506209418887184, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.00011958140385104343}, {"id": 270, "seek": 66028, "start": 667.8399999999999, "end": 670.36, "text": " run the experiments that we needed to run", "tokens": [50742, 1190, 264, 12050, 300, 321, 2978, 281, 1190, 50868], "temperature": 0.0, "avg_logprob": -0.10506209418887184, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.00011958140385104343}, {"id": 271, "seek": 66028, "start": 670.36, "end": 672.4399999999999, "text": " in order to make decisions on what the design", "tokens": [50868, 294, 1668, 281, 652, 5327, 322, 437, 264, 1715, 50972], "temperature": 0.0, "avg_logprob": -0.10506209418887184, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.00011958140385104343}, {"id": 272, "seek": 66028, "start": 672.4399999999999, "end": 677.16, "text": " of this new model building engine would look like.", "tokens": [50972, 295, 341, 777, 2316, 2390, 2848, 576, 574, 411, 13, 51208], "temperature": 0.0, "avg_logprob": -0.10506209418887184, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.00011958140385104343}, {"id": 273, "seek": 66028, "start": 679.04, "end": 681.04, "text": " And then it takes time to do the runs.", "tokens": [51302, 400, 550, 309, 2516, 565, 281, 360, 264, 6676, 13, 51402], "temperature": 0.0, "avg_logprob": -0.10506209418887184, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.00011958140385104343}, {"id": 274, "seek": 66028, "start": 681.04, "end": 683.0799999999999, "text": " We spent a lot of last year doing that.", "tokens": [51402, 492, 4418, 257, 688, 295, 1036, 1064, 884, 300, 13, 51504], "temperature": 0.0, "avg_logprob": -0.10506209418887184, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.00011958140385104343}, {"id": 275, "seek": 66028, "start": 683.0799999999999, "end": 685.88, "text": " But I think the results speak for themselves.", "tokens": [51504, 583, 286, 519, 264, 3542, 1710, 337, 2969, 13, 51644], "temperature": 0.0, "avg_logprob": -0.10506209418887184, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.00011958140385104343}, {"id": 276, "seek": 66028, "start": 685.88, "end": 688.12, "text": " And also with command R and R plus,", "tokens": [51644, 400, 611, 365, 5622, 497, 293, 497, 1804, 11, 51756], "temperature": 0.0, "avg_logprob": -0.10506209418887184, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.00011958140385104343}, {"id": 277, "seek": 68812, "start": 688.12, "end": 691.88, "text": " it's just the first step in a series of new models", "tokens": [50364, 309, 311, 445, 264, 700, 1823, 294, 257, 2638, 295, 777, 5245, 50552], "temperature": 0.0, "avg_logprob": -0.1253220694405692, "compression_ratio": 1.6131687242798354, "no_speech_prob": 0.0005701238987967372}, {"id": 278, "seek": 68812, "start": 691.88, "end": 693.2, "text": " that we wanna produce.", "tokens": [50552, 300, 321, 1948, 5258, 13, 50618], "temperature": 0.0, "avg_logprob": -0.1253220694405692, "compression_ratio": 1.6131687242798354, "no_speech_prob": 0.0005701238987967372}, {"id": 279, "seek": 68812, "start": 693.2, "end": 697.32, "text": " We're very excited to lean into specific capabilities.", "tokens": [50618, 492, 434, 588, 2919, 281, 11659, 666, 2685, 10862, 13, 50824], "temperature": 0.0, "avg_logprob": -0.1253220694405692, "compression_ratio": 1.6131687242798354, "no_speech_prob": 0.0005701238987967372}, {"id": 280, "seek": 68812, "start": 697.32, "end": 701.72, "text": " And so while the general language model improvements,", "tokens": [50824, 400, 370, 1339, 264, 2674, 2856, 2316, 13797, 11, 51044], "temperature": 0.0, "avg_logprob": -0.1253220694405692, "compression_ratio": 1.6131687242798354, "no_speech_prob": 0.0005701238987967372}, {"id": 281, "seek": 68812, "start": 701.72, "end": 702.76, "text": " they're super important.", "tokens": [51044, 436, 434, 1687, 1021, 13, 51096], "temperature": 0.0, "avg_logprob": -0.1253220694405692, "compression_ratio": 1.6131687242798354, "no_speech_prob": 0.0005701238987967372}, {"id": 282, "seek": 68812, "start": 702.76, "end": 703.6, "text": " They're crucial, right?", "tokens": [51096, 814, 434, 11462, 11, 558, 30, 51138], "temperature": 0.0, "avg_logprob": -0.1253220694405692, "compression_ratio": 1.6131687242798354, "no_speech_prob": 0.0005701238987967372}, {"id": 283, "seek": 68812, "start": 703.6, "end": 704.72, "text": " Like the models have to get smarter.", "tokens": [51138, 1743, 264, 5245, 362, 281, 483, 20294, 13, 51194], "temperature": 0.0, "avg_logprob": -0.1253220694405692, "compression_ratio": 1.6131687242798354, "no_speech_prob": 0.0005701238987967372}, {"id": 284, "seek": 68812, "start": 704.72, "end": 707.12, "text": " They have to get more capable.", "tokens": [51194, 814, 362, 281, 483, 544, 8189, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1253220694405692, "compression_ratio": 1.6131687242798354, "no_speech_prob": 0.0005701238987967372}, {"id": 285, "seek": 68812, "start": 707.12, "end": 709.82, "text": " And we'll continue to press on that direction.", "tokens": [51314, 400, 321, 603, 2354, 281, 1886, 322, 300, 3513, 13, 51449], "temperature": 0.0, "avg_logprob": -0.1253220694405692, "compression_ratio": 1.6131687242798354, "no_speech_prob": 0.0005701238987967372}, {"id": 286, "seek": 68812, "start": 710.76, "end": 714.08, "text": " We care about narrowing our focus a bit more.", "tokens": [51496, 492, 1127, 466, 9432, 278, 527, 1879, 257, 857, 544, 13, 51662], "temperature": 0.0, "avg_logprob": -0.1253220694405692, "compression_ratio": 1.6131687242798354, "no_speech_prob": 0.0005701238987967372}, {"id": 287, "seek": 71408, "start": 714.12, "end": 718.36, "text": " And so for 2024, even with the command R series,", "tokens": [50366, 400, 370, 337, 45237, 11, 754, 365, 264, 5622, 497, 2638, 11, 50578], "temperature": 0.0, "avg_logprob": -0.09033080509730748, "compression_ratio": 1.61328125, "no_speech_prob": 0.0004043714143335819}, {"id": 288, "seek": 71408, "start": 718.36, "end": 720.6800000000001, "text": " we focused in on rag and tool use.", "tokens": [50578, 321, 5178, 294, 322, 17539, 293, 2290, 764, 13, 50694], "temperature": 0.0, "avg_logprob": -0.09033080509730748, "compression_ratio": 1.61328125, "no_speech_prob": 0.0004043714143335819}, {"id": 289, "seek": 71408, "start": 720.6800000000001, "end": 723.08, "text": " I think you're gonna see a continuation", "tokens": [50694, 286, 519, 291, 434, 799, 536, 257, 29357, 50814], "temperature": 0.0, "avg_logprob": -0.09033080509730748, "compression_ratio": 1.61328125, "no_speech_prob": 0.0004043714143335819}, {"id": 290, "seek": 71408, "start": 723.08, "end": 725.5200000000001, "text": " and extension of that focus", "tokens": [50814, 293, 10320, 295, 300, 1879, 50936], "temperature": 0.0, "avg_logprob": -0.09033080509730748, "compression_ratio": 1.61328125, "no_speech_prob": 0.0004043714143335819}, {"id": 291, "seek": 71408, "start": 725.5200000000001, "end": 727.6, "text": " really making these models robust", "tokens": [50936, 534, 1455, 613, 5245, 13956, 51040], "temperature": 0.0, "avg_logprob": -0.09033080509730748, "compression_ratio": 1.61328125, "no_speech_prob": 0.0004043714143335819}, {"id": 292, "seek": 71408, "start": 727.6, "end": 730.6, "text": " at the key capabilities that enterprise cares about,", "tokens": [51040, 412, 264, 2141, 10862, 300, 14132, 12310, 466, 11, 51190], "temperature": 0.0, "avg_logprob": -0.09033080509730748, "compression_ratio": 1.61328125, "no_speech_prob": 0.0004043714143335819}, {"id": 293, "seek": 71408, "start": 730.6, "end": 732.0, "text": " that will drive productivity,", "tokens": [51190, 300, 486, 3332, 15604, 11, 51260], "temperature": 0.0, "avg_logprob": -0.09033080509730748, "compression_ratio": 1.61328125, "no_speech_prob": 0.0004043714143335819}, {"id": 294, "seek": 71408, "start": 732.0, "end": 734.72, "text": " that will automate really sophisticated processes", "tokens": [51260, 300, 486, 31605, 534, 16950, 7555, 51396], "temperature": 0.0, "avg_logprob": -0.09033080509730748, "compression_ratio": 1.61328125, "no_speech_prob": 0.0004043714143335819}, {"id": 295, "seek": 71408, "start": 734.72, "end": 739.1600000000001, "text": " that today, as humanity knows it,", "tokens": [51396, 300, 965, 11, 382, 10243, 3255, 309, 11, 51618], "temperature": 0.0, "avg_logprob": -0.09033080509730748, "compression_ratio": 1.61328125, "no_speech_prob": 0.0004043714143335819}, {"id": 296, "seek": 71408, "start": 739.1600000000001, "end": 741.4000000000001, "text": " is only the domain of humans.", "tokens": [51618, 307, 787, 264, 9274, 295, 6255, 13, 51730], "temperature": 0.0, "avg_logprob": -0.09033080509730748, "compression_ratio": 1.61328125, "no_speech_prob": 0.0004043714143335819}, {"id": 297, "seek": 71408, "start": 741.4000000000001, "end": 742.9200000000001, "text": " We really wanna go after that.", "tokens": [51730, 492, 534, 1948, 352, 934, 300, 13, 51806], "temperature": 0.0, "avg_logprob": -0.09033080509730748, "compression_ratio": 1.61328125, "no_speech_prob": 0.0004043714143335819}, {"id": 298, "seek": 74292, "start": 743.92, "end": 748.92, "text": " And give our models the ability to help in those spaces.", "tokens": [50414, 400, 976, 527, 5245, 264, 3485, 281, 854, 294, 729, 7673, 13, 50664], "temperature": 0.0, "avg_logprob": -0.11887583967115058, "compression_ratio": 1.7351778656126482, "no_speech_prob": 0.0005858648801222444}, {"id": 299, "seek": 74292, "start": 749.12, "end": 750.68, "text": " Is it fair to say that,", "tokens": [50674, 1119, 309, 3143, 281, 584, 300, 11, 50752], "temperature": 0.0, "avg_logprob": -0.11887583967115058, "compression_ratio": 1.7351778656126482, "no_speech_prob": 0.0005858648801222444}, {"id": 300, "seek": 74292, "start": 750.68, "end": 751.8399999999999, "text": " I don't know whether you feel", "tokens": [50752, 286, 500, 380, 458, 1968, 291, 841, 50810], "temperature": 0.0, "avg_logprob": -0.11887583967115058, "compression_ratio": 1.7351778656126482, "no_speech_prob": 0.0005858648801222444}, {"id": 301, "seek": 74292, "start": 751.8399999999999, "end": 755.0, "text": " that the general large language models are saturating.", "tokens": [50810, 300, 264, 2674, 2416, 2856, 5245, 366, 21160, 990, 13, 50968], "temperature": 0.0, "avg_logprob": -0.11887583967115058, "compression_ratio": 1.7351778656126482, "no_speech_prob": 0.0005858648801222444}, {"id": 302, "seek": 74292, "start": 755.0, "end": 756.24, "text": " Maybe you could comment on that first,", "tokens": [50968, 2704, 291, 727, 2871, 322, 300, 700, 11, 51030], "temperature": 0.0, "avg_logprob": -0.11887583967115058, "compression_ratio": 1.7351778656126482, "no_speech_prob": 0.0005858648801222444}, {"id": 303, "seek": 74292, "start": 756.24, "end": 758.0, "text": " but if you do think that,", "tokens": [51030, 457, 498, 291, 360, 519, 300, 11, 51118], "temperature": 0.0, "avg_logprob": -0.11887583967115058, "compression_ratio": 1.7351778656126482, "no_speech_prob": 0.0005858648801222444}, {"id": 304, "seek": 74292, "start": 759.0, "end": 760.4399999999999, "text": " does that give me a bit of a read", "tokens": [51168, 775, 300, 976, 385, 257, 857, 295, 257, 1401, 51240], "temperature": 0.0, "avg_logprob": -0.11887583967115058, "compression_ratio": 1.7351778656126482, "no_speech_prob": 0.0005858648801222444}, {"id": 305, "seek": 74292, "start": 760.4399999999999, "end": 763.8, "text": " that there's a move towards specialization of the models?", "tokens": [51240, 300, 456, 311, 257, 1286, 3030, 2121, 2144, 295, 264, 5245, 30, 51408], "temperature": 0.0, "avg_logprob": -0.11887583967115058, "compression_ratio": 1.7351778656126482, "no_speech_prob": 0.0005858648801222444}, {"id": 306, "seek": 74292, "start": 763.8, "end": 765.56, "text": " I don't think they're saturating.", "tokens": [51408, 286, 500, 380, 519, 436, 434, 21160, 990, 13, 51496], "temperature": 0.0, "avg_logprob": -0.11887583967115058, "compression_ratio": 1.7351778656126482, "no_speech_prob": 0.0005858648801222444}, {"id": 307, "seek": 74292, "start": 765.56, "end": 766.9599999999999, "text": " I think they're getting so good", "tokens": [51496, 286, 519, 436, 434, 1242, 370, 665, 51566], "temperature": 0.0, "avg_logprob": -0.11887583967115058, "compression_ratio": 1.7351778656126482, "no_speech_prob": 0.0005858648801222444}, {"id": 308, "seek": 74292, "start": 766.9599999999999, "end": 769.7199999999999, "text": " that it's hard to see the incremental improvement.", "tokens": [51566, 300, 309, 311, 1152, 281, 536, 264, 35759, 10444, 13, 51704], "temperature": 0.0, "avg_logprob": -0.11887583967115058, "compression_ratio": 1.7351778656126482, "no_speech_prob": 0.0005858648801222444}, {"id": 309, "seek": 76972, "start": 770.72, "end": 775.48, "text": " But that incremental improvement is extremely important.", "tokens": [50414, 583, 300, 35759, 10444, 307, 4664, 1021, 13, 50652], "temperature": 0.0, "avg_logprob": -0.18265689815486874, "compression_ratio": 1.6837606837606838, "no_speech_prob": 0.0005356447072699666}, {"id": 310, "seek": 76972, "start": 775.48, "end": 778.88, "text": " So once the models are smarter than you,", "tokens": [50652, 407, 1564, 264, 5245, 366, 20294, 813, 291, 11, 50822], "temperature": 0.0, "avg_logprob": -0.18265689815486874, "compression_ratio": 1.6837606837606838, "no_speech_prob": 0.0005356447072699666}, {"id": 311, "seek": 76972, "start": 778.88, "end": 782.12, "text": " it's really hard to, in a domain, in medicine,", "tokens": [50822, 309, 311, 534, 1152, 281, 11, 294, 257, 9274, 11, 294, 7195, 11, 50984], "temperature": 0.0, "avg_logprob": -0.18265689815486874, "compression_ratio": 1.6837606837606838, "no_speech_prob": 0.0005356447072699666}, {"id": 312, "seek": 76972, "start": 782.12, "end": 784.2, "text": " like Coher's model,", "tokens": [50984, 411, 3066, 511, 311, 2316, 11, 51088], "temperature": 0.0, "avg_logprob": -0.18265689815486874, "compression_ratio": 1.6837606837606838, "no_speech_prob": 0.0005356447072699666}, {"id": 313, "seek": 76972, "start": 784.2, "end": 787.96, "text": " it knows more than I do about medicine, for sure.", "tokens": [51088, 309, 3255, 544, 813, 286, 360, 466, 7195, 11, 337, 988, 13, 51276], "temperature": 0.0, "avg_logprob": -0.18265689815486874, "compression_ratio": 1.6837606837606838, "no_speech_prob": 0.0005356447072699666}, {"id": 314, "seek": 76972, "start": 787.96, "end": 789.1600000000001, "text": " Just absolutely.", "tokens": [51276, 1449, 3122, 13, 51336], "temperature": 0.0, "avg_logprob": -0.18265689815486874, "compression_ratio": 1.6837606837606838, "no_speech_prob": 0.0005356447072699666}, {"id": 315, "seek": 76972, "start": 789.1600000000001, "end": 791.28, "text": " And so I can't really effectively assess", "tokens": [51336, 400, 370, 286, 393, 380, 534, 8659, 5877, 51442], "temperature": 0.0, "avg_logprob": -0.18265689815486874, "compression_ratio": 1.6837606837606838, "no_speech_prob": 0.0005356447072699666}, {"id": 316, "seek": 76972, "start": 791.28, "end": 794.0, "text": " whether we're improving in that dimension.", "tokens": [51442, 1968, 321, 434, 11470, 294, 300, 10139, 13, 51578], "temperature": 0.0, "avg_logprob": -0.18265689815486874, "compression_ratio": 1.6837606837606838, "no_speech_prob": 0.0005356447072699666}, {"id": 317, "seek": 76972, "start": 794.0, "end": 795.24, "text": " I can't tell anyone.", "tokens": [51578, 286, 393, 380, 980, 2878, 13, 51640], "temperature": 0.0, "avg_logprob": -0.18265689815486874, "compression_ratio": 1.6837606837606838, "no_speech_prob": 0.0005356447072699666}, {"id": 318, "seek": 76972, "start": 795.24, "end": 796.64, "text": " It's smarter than me.", "tokens": [51640, 467, 311, 20294, 813, 385, 13, 51710], "temperature": 0.0, "avg_logprob": -0.18265689815486874, "compression_ratio": 1.6837606837606838, "no_speech_prob": 0.0005356447072699666}, {"id": 319, "seek": 76972, "start": 796.64, "end": 798.6, "text": " I trust it more than I trust myself", "tokens": [51710, 286, 3361, 309, 544, 813, 286, 3361, 2059, 51808], "temperature": 0.0, "avg_logprob": -0.18265689815486874, "compression_ratio": 1.6837606837606838, "no_speech_prob": 0.0005356447072699666}, {"id": 320, "seek": 79860, "start": 798.6, "end": 803.44, "text": " to diagnose symptoms or process medical data.", "tokens": [50364, 281, 36238, 8332, 420, 1399, 4625, 1412, 13, 50606], "temperature": 0.0, "avg_logprob": -0.1206631794154087, "compression_ratio": 1.6115702479338843, "no_speech_prob": 0.00047273695236071944}, {"id": 321, "seek": 79860, "start": 803.44, "end": 804.72, "text": " And so I'm not equipped to do that.", "tokens": [50606, 400, 370, 286, 478, 406, 15218, 281, 360, 300, 13, 50670], "temperature": 0.0, "avg_logprob": -0.1206631794154087, "compression_ratio": 1.6115702479338843, "no_speech_prob": 0.00047273695236071944}, {"id": 322, "seek": 79860, "start": 804.72, "end": 807.0400000000001, "text": " Instead, what we need to do is create data sets", "tokens": [50670, 7156, 11, 437, 321, 643, 281, 360, 307, 1884, 1412, 6352, 50786], "temperature": 0.0, "avg_logprob": -0.1206631794154087, "compression_ratio": 1.6115702479338843, "no_speech_prob": 0.00047273695236071944}, {"id": 323, "seek": 79860, "start": 807.0400000000001, "end": 810.0, "text": " or go out and find people who are still better", "tokens": [50786, 420, 352, 484, 293, 915, 561, 567, 366, 920, 1101, 50934], "temperature": 0.0, "avg_logprob": -0.1206631794154087, "compression_ratio": 1.6115702479338843, "no_speech_prob": 0.00047273695236071944}, {"id": 324, "seek": 79860, "start": 810.0, "end": 812.5600000000001, "text": " than the model at those domains.", "tokens": [50934, 813, 264, 2316, 412, 729, 25514, 13, 51062], "temperature": 0.0, "avg_logprob": -0.1206631794154087, "compression_ratio": 1.6115702479338843, "no_speech_prob": 0.00047273695236071944}, {"id": 325, "seek": 79860, "start": 812.5600000000001, "end": 815.5600000000001, "text": " And they can tell me whether it's improving.", "tokens": [51062, 400, 436, 393, 980, 385, 1968, 309, 311, 11470, 13, 51212], "temperature": 0.0, "avg_logprob": -0.1206631794154087, "compression_ratio": 1.6115702479338843, "no_speech_prob": 0.00047273695236071944}, {"id": 326, "seek": 79860, "start": 815.5600000000001, "end": 818.48, "text": " But for us, like the general population,", "tokens": [51212, 583, 337, 505, 11, 411, 264, 2674, 4415, 11, 51358], "temperature": 0.0, "avg_logprob": -0.1206631794154087, "compression_ratio": 1.6115702479338843, "no_speech_prob": 0.00047273695236071944}, {"id": 327, "seek": 79860, "start": 819.6, "end": 823.9200000000001, "text": " at some point, we kind of stop seeing improvement", "tokens": [51414, 412, 512, 935, 11, 321, 733, 295, 1590, 2577, 10444, 51630], "temperature": 0.0, "avg_logprob": -0.1206631794154087, "compression_ratio": 1.6115702479338843, "no_speech_prob": 0.00047273695236071944}, {"id": 328, "seek": 79860, "start": 823.9200000000001, "end": 825.0400000000001, "text": " between model versions.", "tokens": [51630, 1296, 2316, 9606, 13, 51686], "temperature": 0.0, "avg_logprob": -0.1206631794154087, "compression_ratio": 1.6115702479338843, "no_speech_prob": 0.00047273695236071944}, {"id": 329, "seek": 79860, "start": 825.0400000000001, "end": 826.64, "text": " It's harder to feel.", "tokens": [51686, 467, 311, 6081, 281, 841, 13, 51766], "temperature": 0.0, "avg_logprob": -0.1206631794154087, "compression_ratio": 1.6115702479338843, "no_speech_prob": 0.00047273695236071944}, {"id": 330, "seek": 82664, "start": 826.96, "end": 829.4, "text": " And you need to really zoom in", "tokens": [50380, 400, 291, 643, 281, 534, 8863, 294, 50502], "temperature": 0.0, "avg_logprob": -0.11702290410580843, "compression_ratio": 1.66796875, "no_speech_prob": 0.00024528108770027757}, {"id": 331, "seek": 82664, "start": 829.4, "end": 831.08, "text": " to a place that you're an expert", "tokens": [50502, 281, 257, 1081, 300, 291, 434, 364, 5844, 50586], "temperature": 0.0, "avg_logprob": -0.11702290410580843, "compression_ratio": 1.66796875, "no_speech_prob": 0.00024528108770027757}, {"id": 332, "seek": 82664, "start": 831.08, "end": 833.76, "text": " and that you know previous generations failed", "tokens": [50586, 293, 300, 291, 458, 3894, 10593, 7612, 50720], "temperature": 0.0, "avg_logprob": -0.11702290410580843, "compression_ratio": 1.66796875, "no_speech_prob": 0.00024528108770027757}, {"id": 333, "seek": 82664, "start": 833.76, "end": 835.16, "text": " to see the progress.", "tokens": [50720, 281, 536, 264, 4205, 13, 50790], "temperature": 0.0, "avg_logprob": -0.11702290410580843, "compression_ratio": 1.66796875, "no_speech_prob": 0.00024528108770027757}, {"id": 334, "seek": 82664, "start": 836.1999999999999, "end": 838.0, "text": " I think about it sometimes as like", "tokens": [50842, 286, 519, 466, 309, 2171, 382, 411, 50932], "temperature": 0.0, "avg_logprob": -0.11702290410580843, "compression_ratio": 1.66796875, "no_speech_prob": 0.00024528108770027757}, {"id": 335, "seek": 82664, "start": 839.36, "end": 843.04, "text": " painting in a canvas of knowledge.", "tokens": [51000, 5370, 294, 257, 16267, 295, 3601, 13, 51184], "temperature": 0.0, "avg_logprob": -0.11702290410580843, "compression_ratio": 1.66796875, "no_speech_prob": 0.00024528108770027757}, {"id": 336, "seek": 82664, "start": 843.04, "end": 846.56, "text": " And at some point, the holes in the canvas become so small.", "tokens": [51184, 400, 412, 512, 935, 11, 264, 8118, 294, 264, 16267, 1813, 370, 1359, 13, 51360], "temperature": 0.0, "avg_logprob": -0.11702290410580843, "compression_ratio": 1.66796875, "no_speech_prob": 0.00024528108770027757}, {"id": 337, "seek": 82664, "start": 846.56, "end": 848.0, "text": " You have to take out a microscope", "tokens": [51360, 509, 362, 281, 747, 484, 257, 29753, 51432], "temperature": 0.0, "avg_logprob": -0.11702290410580843, "compression_ratio": 1.66796875, "no_speech_prob": 0.00024528108770027757}, {"id": 338, "seek": 82664, "start": 848.0, "end": 850.1999999999999, "text": " to actually see it and paint it in.", "tokens": [51432, 281, 767, 536, 309, 293, 4225, 309, 294, 13, 51542], "temperature": 0.0, "avg_logprob": -0.11702290410580843, "compression_ratio": 1.66796875, "no_speech_prob": 0.00024528108770027757}, {"id": 339, "seek": 82664, "start": 850.1999999999999, "end": 853.64, "text": " We're sort of in that part of the space for these models.", "tokens": [51542, 492, 434, 1333, 295, 294, 300, 644, 295, 264, 1901, 337, 613, 5245, 13, 51714], "temperature": 0.0, "avg_logprob": -0.11702290410580843, "compression_ratio": 1.66796875, "no_speech_prob": 0.00024528108770027757}, {"id": 340, "seek": 82664, "start": 853.64, "end": 855.56, "text": " And so improvement becomes much harder", "tokens": [51714, 400, 370, 10444, 3643, 709, 6081, 51810], "temperature": 0.0, "avg_logprob": -0.11702290410580843, "compression_ratio": 1.66796875, "no_speech_prob": 0.00024528108770027757}, {"id": 341, "seek": 85556, "start": 855.56, "end": 857.4399999999999, "text": " for us, the model builders,", "tokens": [50364, 337, 505, 11, 264, 2316, 36281, 11, 50458], "temperature": 0.0, "avg_logprob": -0.10576641118084942, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.00045816623605787754}, {"id": 342, "seek": 85556, "start": 857.4399999999999, "end": 860.52, "text": " but it's much harder to feel and see for users", "tokens": [50458, 457, 309, 311, 709, 6081, 281, 841, 293, 536, 337, 5022, 50612], "temperature": 0.0, "avg_logprob": -0.10576641118084942, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.00045816623605787754}, {"id": 343, "seek": 85556, "start": 860.52, "end": 865.52, "text": " who aren't diving in very close to analyze performance.", "tokens": [50612, 567, 3212, 380, 20241, 294, 588, 1998, 281, 12477, 3389, 13, 50862], "temperature": 0.0, "avg_logprob": -0.10576641118084942, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.00045816623605787754}, {"id": 344, "seek": 85556, "start": 866.0799999999999, "end": 867.16, "text": " I don't think it's saturating.", "tokens": [50890, 286, 500, 380, 519, 309, 311, 21160, 990, 13, 50944], "temperature": 0.0, "avg_logprob": -0.10576641118084942, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.00045816623605787754}, {"id": 345, "seek": 85556, "start": 867.16, "end": 869.04, "text": " I think it's still making,", "tokens": [50944, 286, 519, 309, 311, 920, 1455, 11, 51038], "temperature": 0.0, "avg_logprob": -0.10576641118084942, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.00045816623605787754}, {"id": 346, "seek": 85556, "start": 869.04, "end": 872.0, "text": " we're still making very significant progress.", "tokens": [51038, 321, 434, 920, 1455, 588, 4776, 4205, 13, 51186], "temperature": 0.0, "avg_logprob": -0.10576641118084942, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.00045816623605787754}, {"id": 347, "seek": 85556, "start": 872.0, "end": 875.04, "text": " I do think the past 18 months,", "tokens": [51186, 286, 360, 519, 264, 1791, 2443, 2493, 11, 51338], "temperature": 0.0, "avg_logprob": -0.10576641118084942, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.00045816623605787754}, {"id": 348, "seek": 85556, "start": 876.28, "end": 877.9599999999999, "text": " maybe a little bit less than 18 months.", "tokens": [51400, 1310, 257, 707, 857, 1570, 813, 2443, 2493, 13, 51484], "temperature": 0.0, "avg_logprob": -0.10576641118084942, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.00045816623605787754}, {"id": 349, "seek": 85556, "start": 877.9599999999999, "end": 880.76, "text": " Yeah, the past 18 months, 12 months,", "tokens": [51484, 865, 11, 264, 1791, 2443, 2493, 11, 2272, 2493, 11, 51624], "temperature": 0.0, "avg_logprob": -0.10576641118084942, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.00045816623605787754}, {"id": 350, "seek": 85556, "start": 880.76, "end": 883.92, "text": " we've been compressing.", "tokens": [51624, 321, 600, 668, 14778, 278, 13, 51782], "temperature": 0.0, "avg_logprob": -0.10576641118084942, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.00045816623605787754}, {"id": 351, "seek": 88392, "start": 884.92, "end": 887.36, "text": " So we built these massive, giant,", "tokens": [50414, 407, 321, 3094, 613, 5994, 11, 7410, 11, 50536], "temperature": 0.0, "avg_logprob": -0.19154779343377976, "compression_ratio": 1.490272373540856, "no_speech_prob": 0.0001354784908471629}, {"id": 352, "seek": 88392, "start": 887.36, "end": 889.68, "text": " multi-trillion parameter models,", "tokens": [50536, 4825, 12, 6903, 11836, 13075, 5245, 11, 50652], "temperature": 0.0, "avg_logprob": -0.19154779343377976, "compression_ratio": 1.490272373540856, "no_speech_prob": 0.0001354784908471629}, {"id": 353, "seek": 88392, "start": 889.68, "end": 893.1999999999999, "text": " which were just extraordinary artifacts", "tokens": [50652, 597, 645, 445, 10581, 24617, 50828], "temperature": 0.0, "avg_logprob": -0.19154779343377976, "compression_ratio": 1.490272373540856, "no_speech_prob": 0.0001354784908471629}, {"id": 354, "seek": 88392, "start": 893.1999999999999, "end": 896.24, "text": " of intelligence and capability.", "tokens": [50828, 295, 7599, 293, 13759, 13, 50980], "temperature": 0.0, "avg_logprob": -0.19154779343377976, "compression_ratio": 1.490272373540856, "no_speech_prob": 0.0001354784908471629}, {"id": 355, "seek": 88392, "start": 896.24, "end": 899.9599999999999, "text": " And we realized it's impractical.", "tokens": [50980, 400, 321, 5334, 309, 311, 704, 1897, 804, 13, 51166], "temperature": 0.0, "avg_logprob": -0.19154779343377976, "compression_ratio": 1.490272373540856, "no_speech_prob": 0.0001354784908471629}, {"id": 356, "seek": 88392, "start": 899.9599999999999, "end": 902.4399999999999, "text": " You can't actually put this thing into production, right?", "tokens": [51166, 509, 393, 380, 767, 829, 341, 551, 666, 4265, 11, 558, 30, 51290], "temperature": 0.0, "avg_logprob": -0.19154779343377976, "compression_ratio": 1.490272373540856, "no_speech_prob": 0.0001354784908471629}, {"id": 357, "seek": 88392, "start": 902.4399999999999, "end": 905.52, "text": " Like it takes 60, a 100s to certainly,", "tokens": [51290, 1743, 309, 2516, 4060, 11, 257, 2319, 82, 281, 3297, 11, 51444], "temperature": 0.0, "avg_logprob": -0.19154779343377976, "compression_ratio": 1.490272373540856, "no_speech_prob": 0.0001354784908471629}, {"id": 358, "seek": 88392, "start": 905.52, "end": 908.88, "text": " it just, we could not productionize this.", "tokens": [51444, 309, 445, 11, 321, 727, 406, 4265, 1125, 341, 13, 51612], "temperature": 0.0, "avg_logprob": -0.19154779343377976, "compression_ratio": 1.490272373540856, "no_speech_prob": 0.0001354784908471629}, {"id": 359, "seek": 88392, "start": 908.88, "end": 910.76, "text": " The economics don't work out.", "tokens": [51612, 440, 14564, 500, 380, 589, 484, 13, 51706], "temperature": 0.0, "avg_logprob": -0.19154779343377976, "compression_ratio": 1.490272373540856, "no_speech_prob": 0.0001354784908471629}, {"id": 360, "seek": 88392, "start": 910.76, "end": 913.28, "text": " And so then we spent the year compressing", "tokens": [51706, 400, 370, 550, 321, 4418, 264, 1064, 14778, 278, 51832], "temperature": 0.0, "avg_logprob": -0.19154779343377976, "compression_ratio": 1.490272373540856, "no_speech_prob": 0.0001354784908471629}, {"id": 361, "seek": 91328, "start": 913.28, "end": 916.8, "text": " those massive models down into much smaller form factors.", "tokens": [50364, 729, 5994, 5245, 760, 666, 709, 4356, 1254, 6771, 13, 50540], "temperature": 0.0, "avg_logprob": -0.18188140266820005, "compression_ratio": 1.5538461538461539, "no_speech_prob": 0.00024532442330382764}, {"id": 362, "seek": 91328, "start": 918.68, "end": 923.68, "text": " There's very likely going to be a series of re-expansion", "tokens": [50634, 821, 311, 588, 3700, 516, 281, 312, 257, 2638, 295, 319, 12, 15952, 599, 313, 50884], "temperature": 0.0, "avg_logprob": -0.18188140266820005, "compression_ratio": 1.5538461538461539, "no_speech_prob": 0.00024532442330382764}, {"id": 363, "seek": 91328, "start": 923.9599999999999, "end": 928.9599999999999, "text": " and scale, both on the model scale", "tokens": [50898, 293, 4373, 11, 1293, 322, 264, 2316, 4373, 51148], "temperature": 0.0, "avg_logprob": -0.18188140266820005, "compression_ratio": 1.5538461538461539, "no_speech_prob": 0.00024532442330382764}, {"id": 364, "seek": 91328, "start": 930.3199999999999, "end": 934.8, "text": " in terms of parameters, but also data scale and data quality.", "tokens": [51216, 294, 2115, 295, 9834, 11, 457, 611, 1412, 4373, 293, 1412, 3125, 13, 51440], "temperature": 0.0, "avg_logprob": -0.18188140266820005, "compression_ratio": 1.5538461538461539, "no_speech_prob": 0.00024532442330382764}, {"id": 365, "seek": 91328, "start": 934.8, "end": 937.9599999999999, "text": " And that's being supported by much better", "tokens": [51440, 400, 300, 311, 885, 8104, 538, 709, 1101, 51598], "temperature": 0.0, "avg_logprob": -0.18188140266820005, "compression_ratio": 1.5538461538461539, "no_speech_prob": 0.00024532442330382764}, {"id": 366, "seek": 91328, "start": 937.9599999999999, "end": 940.68, "text": " synthetic data methods that find much more useful", "tokens": [51598, 23420, 1412, 7150, 300, 915, 709, 544, 4420, 51734], "temperature": 0.0, "avg_logprob": -0.18188140266820005, "compression_ratio": 1.5538461538461539, "no_speech_prob": 0.00024532442330382764}, {"id": 367, "seek": 94068, "start": 940.68, "end": 944.52, "text": " synthetic data that are quite compelling at search", "tokens": [50364, 23420, 1412, 300, 366, 1596, 20050, 412, 3164, 50556], "temperature": 0.0, "avg_logprob": -0.16095513310925713, "compression_ratio": 1.5644444444444445, "no_speech_prob": 0.0010000915499404073}, {"id": 368, "seek": 94068, "start": 944.52, "end": 948.56, "text": " to discover, to automatically discover weak points of models", "tokens": [50556, 281, 4411, 11, 281, 6772, 4411, 5336, 2793, 295, 5245, 50758], "temperature": 0.0, "avg_logprob": -0.16095513310925713, "compression_ratio": 1.5644444444444445, "no_speech_prob": 0.0010000915499404073}, {"id": 369, "seek": 94068, "start": 948.56, "end": 950.68, "text": " and then close those gaps.", "tokens": [50758, 293, 550, 1998, 729, 15031, 13, 50864], "temperature": 0.0, "avg_logprob": -0.16095513310925713, "compression_ratio": 1.5644444444444445, "no_speech_prob": 0.0010000915499404073}, {"id": 370, "seek": 94068, "start": 951.76, "end": 954.3199999999999, "text": " So I think we've, over the past year,", "tokens": [50918, 407, 286, 519, 321, 600, 11, 670, 264, 1791, 1064, 11, 51046], "temperature": 0.0, "avg_logprob": -0.16095513310925713, "compression_ratio": 1.5644444444444445, "no_speech_prob": 0.0010000915499404073}, {"id": 371, "seek": 94068, "start": 954.3199999999999, "end": 958.3199999999999, "text": " gotten very good at making models more efficient.", "tokens": [51046, 5768, 588, 665, 412, 1455, 5245, 544, 7148, 13, 51246], "temperature": 0.0, "avg_logprob": -0.16095513310925713, "compression_ratio": 1.5644444444444445, "no_speech_prob": 0.0010000915499404073}, {"id": 372, "seek": 94068, "start": 958.3199999999999, "end": 963.0799999999999, "text": " And we've created new methods that let us", "tokens": [51246, 400, 321, 600, 2942, 777, 7150, 300, 718, 505, 51484], "temperature": 0.0, "avg_logprob": -0.16095513310925713, "compression_ratio": 1.5644444444444445, "no_speech_prob": 0.0010000915499404073}, {"id": 373, "seek": 94068, "start": 963.0799999999999, "end": 966.3199999999999, "text": " sort of just like plug in compute and data", "tokens": [51484, 1333, 295, 445, 411, 5452, 294, 14722, 293, 1412, 51646], "temperature": 0.0, "avg_logprob": -0.16095513310925713, "compression_ratio": 1.5644444444444445, "no_speech_prob": 0.0010000915499404073}, {"id": 374, "seek": 94068, "start": 966.3199999999999, "end": 969.28, "text": " and have the model continuously improve.", "tokens": [51646, 293, 362, 264, 2316, 15684, 3470, 13, 51794], "temperature": 0.0, "avg_logprob": -0.16095513310925713, "compression_ratio": 1.5644444444444445, "no_speech_prob": 0.0010000915499404073}, {"id": 375, "seek": 96928, "start": 969.28, "end": 973.24, "text": " You've used words like smart and capabilities.", "tokens": [50364, 509, 600, 1143, 2283, 411, 4069, 293, 10862, 13, 50562], "temperature": 0.0, "avg_logprob": -0.09143845367431641, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.0005652952822856605}, {"id": 376, "seek": 96928, "start": 973.24, "end": 976.76, "text": " And if you think of smart as knowledge,", "tokens": [50562, 400, 498, 291, 519, 295, 4069, 382, 3601, 11, 50738], "temperature": 0.0, "avg_logprob": -0.09143845367431641, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.0005652952822856605}, {"id": 377, "seek": 96928, "start": 976.76, "end": 977.72, "text": " I completely agree with you.", "tokens": [50738, 286, 2584, 3986, 365, 291, 13, 50786], "temperature": 0.0, "avg_logprob": -0.09143845367431641, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.0005652952822856605}, {"id": 378, "seek": 96928, "start": 977.72, "end": 980.64, "text": " I think knowledge is a living thing.", "tokens": [50786, 286, 519, 3601, 307, 257, 2647, 551, 13, 50932], "temperature": 0.0, "avg_logprob": -0.09143845367431641, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.0005652952822856605}, {"id": 379, "seek": 96928, "start": 980.64, "end": 983.48, "text": " We're all improvising and we are generating", "tokens": [50932, 492, 434, 439, 29424, 3436, 293, 321, 366, 17746, 51074], "temperature": 0.0, "avg_logprob": -0.09143845367431641, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.0005652952822856605}, {"id": 380, "seek": 96928, "start": 983.48, "end": 984.76, "text": " new knowledge all the time.", "tokens": [51074, 777, 3601, 439, 264, 565, 13, 51138], "temperature": 0.0, "avg_logprob": -0.09143845367431641, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.0005652952822856605}, {"id": 381, "seek": 96928, "start": 984.76, "end": 987.4, "text": " And it just increases exponentially.", "tokens": [51138, 400, 309, 445, 8637, 37330, 13, 51270], "temperature": 0.0, "avg_logprob": -0.09143845367431641, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.0005652952822856605}, {"id": 382, "seek": 96928, "start": 987.4, "end": 989.4399999999999, "text": " And there's no reason why language models", "tokens": [51270, 400, 456, 311, 572, 1778, 983, 2856, 5245, 51372], "temperature": 0.0, "avg_logprob": -0.09143845367431641, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.0005652952822856605}, {"id": 383, "seek": 96928, "start": 989.4399999999999, "end": 991.1999999999999, "text": " can't become more and more and more knowledgeable", "tokens": [51372, 393, 380, 1813, 544, 293, 544, 293, 544, 33800, 51460], "temperature": 0.0, "avg_logprob": -0.09143845367431641, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.0005652952822856605}, {"id": 384, "seek": 96928, "start": 991.1999999999999, "end": 993.9599999999999, "text": " because we just acquire more and more data.", "tokens": [51460, 570, 321, 445, 20001, 544, 293, 544, 1412, 13, 51598], "temperature": 0.0, "avg_logprob": -0.09143845367431641, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.0005652952822856605}, {"id": 385, "seek": 96928, "start": 993.9599999999999, "end": 997.52, "text": " And in that sense, a medical doctor is smarter than me", "tokens": [51598, 400, 294, 300, 2020, 11, 257, 4625, 4631, 307, 20294, 813, 385, 51776], "temperature": 0.0, "avg_logprob": -0.09143845367431641, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.0005652952822856605}, {"id": 386, "seek": 96928, "start": 997.52, "end": 999.24, "text": " in that domain because they have the knowledge", "tokens": [51776, 294, 300, 9274, 570, 436, 362, 264, 3601, 51862], "temperature": 0.0, "avg_logprob": -0.09143845367431641, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.0005652952822856605}, {"id": 387, "seek": 99924, "start": 999.44, "end": 1000.6800000000001, "text": " that I don't have.", "tokens": [50374, 300, 286, 500, 380, 362, 13, 50436], "temperature": 0.0, "avg_logprob": -0.1467088167784644, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.0005852539907209575}, {"id": 388, "seek": 99924, "start": 1000.6800000000001, "end": 1002.92, "text": " But some people could say that intelligence", "tokens": [50436, 583, 512, 561, 727, 584, 300, 7599, 50548], "temperature": 0.0, "avg_logprob": -0.1467088167784644, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.0005852539907209575}, {"id": 389, "seek": 99924, "start": 1002.92, "end": 1005.64, "text": " is something a little bit more abstract than that.", "tokens": [50548, 307, 746, 257, 707, 857, 544, 12649, 813, 300, 13, 50684], "temperature": 0.0, "avg_logprob": -0.1467088167784644, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.0005852539907209575}, {"id": 390, "seek": 99924, "start": 1005.64, "end": 1008.6, "text": " It might be the ability to build models.", "tokens": [50684, 467, 1062, 312, 264, 3485, 281, 1322, 5245, 13, 50832], "temperature": 0.0, "avg_logprob": -0.1467088167784644, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.0005852539907209575}, {"id": 391, "seek": 99924, "start": 1009.64, "end": 1011.2, "text": " It might be the ability to reason.", "tokens": [50884, 467, 1062, 312, 264, 3485, 281, 1778, 13, 50962], "temperature": 0.0, "avg_logprob": -0.1467088167784644, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.0005852539907209575}, {"id": 392, "seek": 99924, "start": 1011.2, "end": 1013.24, "text": " It might be the ability to plan.", "tokens": [50962, 467, 1062, 312, 264, 3485, 281, 1393, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1467088167784644, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.0005852539907209575}, {"id": 393, "seek": 99924, "start": 1013.24, "end": 1016.04, "text": " And this is when we get into the kind of the age your own", "tokens": [51064, 400, 341, 307, 562, 321, 483, 666, 264, 733, 295, 264, 3205, 428, 1065, 51204], "temperature": 0.0, "avg_logprob": -0.1467088167784644, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.0005852539907209575}, {"id": 394, "seek": 99924, "start": 1016.04, "end": 1017.4, "text": " thing.", "tokens": [51204, 551, 13, 51272], "temperature": 0.0, "avg_logprob": -0.1467088167784644, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.0005852539907209575}, {"id": 395, "seek": 99924, "start": 1017.4, "end": 1020.24, "text": " So how do you demarcate those things?", "tokens": [51272, 407, 577, 360, 291, 1371, 40088, 473, 729, 721, 30, 51414], "temperature": 0.0, "avg_logprob": -0.1467088167784644, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.0005852539907209575}, {"id": 396, "seek": 99924, "start": 1020.24, "end": 1022.48, "text": " Are you saying that the models are becoming more knowledgeable", "tokens": [51414, 2014, 291, 1566, 300, 264, 5245, 366, 5617, 544, 33800, 51526], "temperature": 0.0, "avg_logprob": -0.1467088167784644, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.0005852539907209575}, {"id": 397, "seek": 99924, "start": 1022.48, "end": 1024.6, "text": " but they're not necessarily becoming more intelligent", "tokens": [51526, 457, 436, 434, 406, 4725, 5617, 544, 13232, 51632], "temperature": 0.0, "avg_logprob": -0.1467088167784644, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.0005852539907209575}, {"id": 398, "seek": 99924, "start": 1024.6, "end": 1025.52, "text": " like we are?", "tokens": [51632, 411, 321, 366, 30, 51678], "temperature": 0.0, "avg_logprob": -0.1467088167784644, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.0005852539907209575}, {"id": 399, "seek": 102552, "start": 1025.52, "end": 1030.52, "text": " I think reasoning is crucial to intelligence.", "tokens": [50364, 286, 519, 21577, 307, 11462, 281, 7599, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1091095763858002, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.0002867764560505748}, {"id": 400, "seek": 102552, "start": 1033.12, "end": 1036.2, "text": " I think that these models can reason", "tokens": [50744, 286, 519, 300, 613, 5245, 393, 1778, 50898], "temperature": 0.0, "avg_logprob": -0.1091095763858002, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.0002867764560505748}, {"id": 401, "seek": 102552, "start": 1036.2, "end": 1038.08, "text": " and that's a controversial claim.", "tokens": [50898, 293, 300, 311, 257, 17323, 3932, 13, 50992], "temperature": 0.0, "avg_logprob": -0.1091095763858002, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.0002867764560505748}, {"id": 402, "seek": 102552, "start": 1038.08, "end": 1040.16, "text": " I think a lot of people would debate that.", "tokens": [50992, 286, 519, 257, 688, 295, 561, 576, 7958, 300, 13, 51096], "temperature": 0.0, "avg_logprob": -0.1091095763858002, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.0002867764560505748}, {"id": 403, "seek": 102552, "start": 1040.16, "end": 1041.32, "text": " A lot of people would make the claim", "tokens": [51096, 316, 688, 295, 561, 576, 652, 264, 3932, 51154], "temperature": 0.0, "avg_logprob": -0.1091095763858002, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.0002867764560505748}, {"id": 404, "seek": 102552, "start": 1041.32, "end": 1042.96, "text": " that the architectures we're using", "tokens": [51154, 300, 264, 6331, 1303, 321, 434, 1228, 51236], "temperature": 0.0, "avg_logprob": -0.1091095763858002, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.0002867764560505748}, {"id": 405, "seek": 102552, "start": 1042.96, "end": 1045.24, "text": " or the methods we're using don't support", "tokens": [51236, 420, 264, 7150, 321, 434, 1228, 500, 380, 1406, 51350], "temperature": 0.0, "avg_logprob": -0.1091095763858002, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.0002867764560505748}, {"id": 406, "seek": 102552, "start": 1046.6, "end": 1047.92, "text": " that sort of behavior.", "tokens": [51418, 300, 1333, 295, 5223, 13, 51484], "temperature": 0.0, "avg_logprob": -0.1091095763858002, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.0002867764560505748}, {"id": 407, "seek": 102552, "start": 1047.92, "end": 1051.4, "text": " I think that previous generations of the model", "tokens": [51484, 286, 519, 300, 3894, 10593, 295, 264, 2316, 51658], "temperature": 0.0, "avg_logprob": -0.1091095763858002, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.0002867764560505748}, {"id": 408, "seek": 102552, "start": 1051.4, "end": 1054.32, "text": " have been weak reasoners, but they do reason.", "tokens": [51658, 362, 668, 5336, 1778, 433, 11, 457, 436, 360, 1778, 13, 51804], "temperature": 0.0, "avg_logprob": -0.1091095763858002, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.0002867764560505748}, {"id": 409, "seek": 105552, "start": 1055.56, "end": 1058.28, "text": " And it's not a discreet,", "tokens": [50366, 400, 309, 311, 406, 257, 2983, 4751, 11, 50502], "temperature": 0.0, "avg_logprob": -0.1225225289662679, "compression_ratio": 1.776061776061776, "no_speech_prob": 8.477675874019042e-05}, {"id": 410, "seek": 105552, "start": 1058.28, "end": 1060.04, "text": " does it have this capability or not?", "tokens": [50502, 775, 309, 362, 341, 13759, 420, 406, 30, 50590], "temperature": 0.0, "avg_logprob": -0.1225225289662679, "compression_ratio": 1.776061776061776, "no_speech_prob": 8.477675874019042e-05}, {"id": 411, "seek": 105552, "start": 1060.04, "end": 1062.84, "text": " It's a continuum of how robust the reasoning engine", "tokens": [50590, 467, 311, 257, 36120, 295, 577, 13956, 264, 21577, 2848, 50730], "temperature": 0.0, "avg_logprob": -0.1225225289662679, "compression_ratio": 1.776061776061776, "no_speech_prob": 8.477675874019042e-05}, {"id": 412, "seek": 105552, "start": 1062.84, "end": 1064.48, "text": " inside these models is.", "tokens": [50730, 1854, 613, 5245, 307, 13, 50812], "temperature": 0.0, "avg_logprob": -0.1225225289662679, "compression_ratio": 1.776061776061776, "no_speech_prob": 8.477675874019042e-05}, {"id": 413, "seek": 105552, "start": 1065.44, "end": 1067.24, "text": " We're getting much better methods", "tokens": [50860, 492, 434, 1242, 709, 1101, 7150, 50950], "temperature": 0.0, "avg_logprob": -0.1225225289662679, "compression_ratio": 1.776061776061776, "no_speech_prob": 8.477675874019042e-05}, {"id": 414, "seek": 105552, "start": 1067.24, "end": 1070.32, "text": " for improving reasoning generally.", "tokens": [50950, 337, 11470, 21577, 5101, 13, 51104], "temperature": 0.0, "avg_logprob": -0.1225225289662679, "compression_ratio": 1.776061776061776, "no_speech_prob": 8.477675874019042e-05}, {"id": 415, "seek": 105552, "start": 1070.32, "end": 1071.6399999999999, "text": " We're getting much better methods", "tokens": [51104, 492, 434, 1242, 709, 1101, 7150, 51170], "temperature": 0.0, "avg_logprob": -0.1225225289662679, "compression_ratio": 1.776061776061776, "no_speech_prob": 8.477675874019042e-05}, {"id": 416, "seek": 105552, "start": 1071.6399999999999, "end": 1074.12, "text": " of eliciting that behavior from the models", "tokens": [51170, 295, 806, 299, 1748, 300, 5223, 490, 264, 5245, 51294], "temperature": 0.0, "avg_logprob": -0.1225225289662679, "compression_ratio": 1.776061776061776, "no_speech_prob": 8.477675874019042e-05}, {"id": 417, "seek": 105552, "start": 1074.12, "end": 1075.92, "text": " and teaching them how to do it", "tokens": [51294, 293, 4571, 552, 577, 281, 360, 309, 51384], "temperature": 0.0, "avg_logprob": -0.1225225289662679, "compression_ratio": 1.776061776061776, "no_speech_prob": 8.477675874019042e-05}, {"id": 418, "seek": 105552, "start": 1075.92, "end": 1077.8799999999999, "text": " and apply it to many different domains,", "tokens": [51384, 293, 3079, 309, 281, 867, 819, 25514, 11, 51482], "temperature": 0.0, "avg_logprob": -0.1225225289662679, "compression_ratio": 1.776061776061776, "no_speech_prob": 8.477675874019042e-05}, {"id": 419, "seek": 105552, "start": 1077.8799999999999, "end": 1081.96, "text": " whether it's math, whether it's decision-making tasks,", "tokens": [51482, 1968, 309, 311, 5221, 11, 1968, 309, 311, 3537, 12, 12402, 9608, 11, 51686], "temperature": 0.0, "avg_logprob": -0.1225225289662679, "compression_ratio": 1.776061776061776, "no_speech_prob": 8.477675874019042e-05}, {"id": 420, "seek": 105552, "start": 1081.96, "end": 1084.86, "text": " breaking down tasks, planning how to execute them.", "tokens": [51686, 7697, 760, 9608, 11, 5038, 577, 281, 14483, 552, 13, 51831], "temperature": 0.0, "avg_logprob": -0.1225225289662679, "compression_ratio": 1.776061776061776, "no_speech_prob": 8.477675874019042e-05}, {"id": 421, "seek": 108552, "start": 1086.44, "end": 1089.72, "text": " Those were key missing capabilities", "tokens": [50410, 3950, 645, 2141, 5361, 10862, 50574], "temperature": 0.0, "avg_logprob": -0.16716277712867372, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.00010227749589830637}, {"id": 422, "seek": 108552, "start": 1089.72, "end": 1093.08, "text": " that were quite weak in previous generations of models,", "tokens": [50574, 300, 645, 1596, 5336, 294, 3894, 10593, 295, 5245, 11, 50742], "temperature": 0.0, "avg_logprob": -0.16716277712867372, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.00010227749589830637}, {"id": 423, "seek": 108552, "start": 1093.08, "end": 1095.56, "text": " which are now starting to emerge", "tokens": [50742, 597, 366, 586, 2891, 281, 21511, 50866], "temperature": 0.0, "avg_logprob": -0.16716277712867372, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.00010227749589830637}, {"id": 424, "seek": 108552, "start": 1096.8799999999999, "end": 1099.96, "text": " in a significantly more robust fashion.", "tokens": [50932, 294, 257, 10591, 544, 13956, 6700, 13, 51086], "temperature": 0.0, "avg_logprob": -0.16716277712867372, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.00010227749589830637}, {"id": 425, "seek": 108552, "start": 1099.96, "end": 1102.76, "text": " And so in the same way that hallucination", "tokens": [51086, 400, 370, 294, 264, 912, 636, 300, 35212, 2486, 51226], "temperature": 0.0, "avg_logprob": -0.16716277712867372, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.00010227749589830637}, {"id": 426, "seek": 108552, "start": 1102.76, "end": 1106.28, "text": " was it used to be an existential threat to this technology,", "tokens": [51226, 390, 309, 1143, 281, 312, 364, 37133, 4734, 281, 341, 2899, 11, 51402], "temperature": 0.0, "avg_logprob": -0.16716277712867372, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.00010227749589830637}, {"id": 427, "seek": 108552, "start": 1106.28, "end": 1108.52, "text": " no, we'll never be able to trust this stuff.", "tokens": [51402, 572, 11, 321, 603, 1128, 312, 1075, 281, 3361, 341, 1507, 13, 51514], "temperature": 0.0, "avg_logprob": -0.16716277712867372, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.00010227749589830637}, {"id": 428, "seek": 108552, "start": 1109.52, "end": 1112.16, "text": " There are hundreds of millions of people using this techno", "tokens": [51564, 821, 366, 6779, 295, 6803, 295, 561, 1228, 341, 36728, 51696], "temperature": 0.0, "avg_logprob": -0.16716277712867372, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.00010227749589830637}, {"id": 429, "seek": 108552, "start": 1112.16, "end": 1113.0, "text": " and they trust it.", "tokens": [51696, 293, 436, 3361, 309, 13, 51738], "temperature": 0.0, "avg_logprob": -0.16716277712867372, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.00010227749589830637}, {"id": 430, "seek": 108552, "start": 1113.0, "end": 1113.96, "text": " It's actually useful for them.", "tokens": [51738, 467, 311, 767, 4420, 337, 552, 13, 51786], "temperature": 0.0, "avg_logprob": -0.16716277712867372, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.00010227749589830637}, {"id": 431, "seek": 111396, "start": 1113.96, "end": 1116.28, "text": " They use it because it's useful to their job.", "tokens": [50364, 814, 764, 309, 570, 309, 311, 4420, 281, 641, 1691, 13, 50480], "temperature": 0.0, "avg_logprob": -0.09106793319969847, "compression_ratio": 1.6716981132075472, "no_speech_prob": 0.00014874606858938932}, {"id": 432, "seek": 111396, "start": 1116.28, "end": 1118.68, "text": " We're making very good progress on the hallucination problem.", "tokens": [50480, 492, 434, 1455, 588, 665, 4205, 322, 264, 35212, 2486, 1154, 13, 50600], "temperature": 0.0, "avg_logprob": -0.09106793319969847, "compression_ratio": 1.6716981132075472, "no_speech_prob": 0.00014874606858938932}, {"id": 433, "seek": 111396, "start": 1118.68, "end": 1120.8400000000001, "text": " I think we'll make very good progress", "tokens": [50600, 286, 519, 321, 603, 652, 588, 665, 4205, 50708], "temperature": 0.0, "avg_logprob": -0.09106793319969847, "compression_ratio": 1.6716981132075472, "no_speech_prob": 0.00014874606858938932}, {"id": 434, "seek": 111396, "start": 1120.8400000000001, "end": 1123.16, "text": " this year and next on reasoning.", "tokens": [50708, 341, 1064, 293, 958, 322, 21577, 13, 50824], "temperature": 0.0, "avg_logprob": -0.09106793319969847, "compression_ratio": 1.6716981132075472, "no_speech_prob": 0.00014874606858938932}, {"id": 435, "seek": 111396, "start": 1123.16, "end": 1126.64, "text": " I think it's just a capability,", "tokens": [50824, 286, 519, 309, 311, 445, 257, 13759, 11, 50998], "temperature": 0.0, "avg_logprob": -0.09106793319969847, "compression_ratio": 1.6716981132075472, "no_speech_prob": 0.00014874606858938932}, {"id": 436, "seek": 111396, "start": 1126.64, "end": 1131.64, "text": " a skill that the model needs to be taught.", "tokens": [50998, 257, 5389, 300, 264, 2316, 2203, 281, 312, 5928, 13, 51248], "temperature": 0.0, "avg_logprob": -0.09106793319969847, "compression_ratio": 1.6716981132075472, "no_speech_prob": 0.00014874606858938932}, {"id": 437, "seek": 111396, "start": 1131.8, "end": 1134.56, "text": " And we're building the methods and data", "tokens": [51256, 400, 321, 434, 2390, 264, 7150, 293, 1412, 51394], "temperature": 0.0, "avg_logprob": -0.09106793319969847, "compression_ratio": 1.6716981132075472, "no_speech_prob": 0.00014874606858938932}, {"id": 438, "seek": 111396, "start": 1134.56, "end": 1139.56, "text": " and techniques to support teaching, teaching these models.", "tokens": [51394, 293, 7512, 281, 1406, 4571, 11, 4571, 613, 5245, 13, 51644], "temperature": 0.0, "avg_logprob": -0.09106793319969847, "compression_ratio": 1.6716981132075472, "no_speech_prob": 0.00014874606858938932}, {"id": 439, "seek": 111396, "start": 1139.6000000000001, "end": 1141.44, "text": " Yeah, it is interesting how you can kind of break", "tokens": [51646, 865, 11, 309, 307, 1880, 577, 291, 393, 733, 295, 1821, 51738], "temperature": 0.0, "avg_logprob": -0.09106793319969847, "compression_ratio": 1.6716981132075472, "no_speech_prob": 0.00014874606858938932}, {"id": 440, "seek": 111396, "start": 1141.44, "end": 1143.24, "text": " intelligence down to all of these things", "tokens": [51738, 7599, 760, 281, 439, 295, 613, 721, 51828], "temperature": 0.0, "avg_logprob": -0.09106793319969847, "compression_ratio": 1.6716981132075472, "no_speech_prob": 0.00014874606858938932}, {"id": 441, "seek": 114324, "start": 1143.24, "end": 1145.24, "text": " and some you might argue are missing now,", "tokens": [50364, 293, 512, 291, 1062, 9695, 366, 5361, 586, 11, 50464], "temperature": 0.0, "avg_logprob": -0.13761697709560394, "compression_ratio": 1.7381818181818183, "no_speech_prob": 0.00026219754363410175}, {"id": 442, "seek": 114324, "start": 1145.24, "end": 1149.68, "text": " like planning, creativity is an interesting one.", "tokens": [50464, 411, 5038, 11, 12915, 307, 364, 1880, 472, 13, 50686], "temperature": 0.0, "avg_logprob": -0.13761697709560394, "compression_ratio": 1.7381818181818183, "no_speech_prob": 0.00026219754363410175}, {"id": 443, "seek": 114324, "start": 1149.68, "end": 1151.72, "text": " Agency is quite an interesting one.", "tokens": [50686, 21649, 307, 1596, 364, 1880, 472, 13, 50788], "temperature": 0.0, "avg_logprob": -0.13761697709560394, "compression_ratio": 1.7381818181818183, "no_speech_prob": 0.00026219754363410175}, {"id": 444, "seek": 114324, "start": 1151.72, "end": 1155.0, "text": " And presumably as a thing has more understanding", "tokens": [50788, 400, 26742, 382, 257, 551, 575, 544, 3701, 50952], "temperature": 0.0, "avg_logprob": -0.13761697709560394, "compression_ratio": 1.7381818181818183, "no_speech_prob": 0.00026219754363410175}, {"id": 445, "seek": 114324, "start": 1155.0, "end": 1156.28, "text": " and it has more autonomy,", "tokens": [50952, 293, 309, 575, 544, 27278, 11, 51016], "temperature": 0.0, "avg_logprob": -0.13761697709560394, "compression_ratio": 1.7381818181818183, "no_speech_prob": 0.00026219754363410175}, {"id": 446, "seek": 114324, "start": 1156.28, "end": 1159.0, "text": " it could in principle develop agency", "tokens": [51016, 309, 727, 294, 8665, 1499, 7934, 51152], "temperature": 0.0, "avg_logprob": -0.13761697709560394, "compression_ratio": 1.7381818181818183, "no_speech_prob": 0.00026219754363410175}, {"id": 447, "seek": 114324, "start": 1159.0, "end": 1159.96, "text": " at some point in the future.", "tokens": [51152, 412, 512, 935, 294, 264, 2027, 13, 51200], "temperature": 0.0, "avg_logprob": -0.13761697709560394, "compression_ratio": 1.7381818181818183, "no_speech_prob": 0.00026219754363410175}, {"id": 448, "seek": 114324, "start": 1159.96, "end": 1162.44, "text": " But you think of these things as skills.", "tokens": [51200, 583, 291, 519, 295, 613, 721, 382, 3942, 13, 51324], "temperature": 0.0, "avg_logprob": -0.13761697709560394, "compression_ratio": 1.7381818181818183, "no_speech_prob": 0.00026219754363410175}, {"id": 449, "seek": 114324, "start": 1162.44, "end": 1165.6, "text": " Could you give any hints to how you've moved the needle", "tokens": [51324, 7497, 291, 976, 604, 27271, 281, 577, 291, 600, 4259, 264, 11037, 51482], "temperature": 0.0, "avg_logprob": -0.13761697709560394, "compression_ratio": 1.7381818181818183, "no_speech_prob": 0.00026219754363410175}, {"id": 450, "seek": 114324, "start": 1165.6, "end": 1166.44, "text": " on this?", "tokens": [51482, 322, 341, 30, 51524], "temperature": 0.0, "avg_logprob": -0.13761697709560394, "compression_ratio": 1.7381818181818183, "no_speech_prob": 0.00026219754363410175}, {"id": 451, "seek": 114324, "start": 1166.44, "end": 1167.88, "text": " So the knowledge thing, it seems to me", "tokens": [51524, 407, 264, 3601, 551, 11, 309, 2544, 281, 385, 51596], "temperature": 0.0, "avg_logprob": -0.13761697709560394, "compression_ratio": 1.7381818181818183, "no_speech_prob": 0.00026219754363410175}, {"id": 452, "seek": 114324, "start": 1167.88, "end": 1169.84, "text": " that you would just get more data", "tokens": [51596, 300, 291, 576, 445, 483, 544, 1412, 51694], "temperature": 0.0, "avg_logprob": -0.13761697709560394, "compression_ratio": 1.7381818181818183, "no_speech_prob": 0.00026219754363410175}, {"id": 453, "seek": 114324, "start": 1169.84, "end": 1171.44, "text": " and curate and refine the data.", "tokens": [51694, 293, 1262, 473, 293, 33906, 264, 1412, 13, 51774], "temperature": 0.0, "avg_logprob": -0.13761697709560394, "compression_ratio": 1.7381818181818183, "no_speech_prob": 0.00026219754363410175}, {"id": 454, "seek": 117144, "start": 1171.44, "end": 1172.88, "text": " But could you give any hints", "tokens": [50364, 583, 727, 291, 976, 604, 27271, 50436], "temperature": 0.0, "avg_logprob": -0.12365325959790655, "compression_ratio": 1.6727941176470589, "no_speech_prob": 7.248116889968514e-05}, {"id": 455, "seek": 117144, "start": 1172.88, "end": 1175.0800000000002, "text": " on how you've made it better at reasoning, for example?", "tokens": [50436, 322, 577, 291, 600, 1027, 309, 1101, 412, 21577, 11, 337, 1365, 30, 50546], "temperature": 0.0, "avg_logprob": -0.12365325959790655, "compression_ratio": 1.6727941176470589, "no_speech_prob": 7.248116889968514e-05}, {"id": 456, "seek": 117144, "start": 1175.0800000000002, "end": 1175.92, "text": " Yeah, with knowledge,", "tokens": [50546, 865, 11, 365, 3601, 11, 50588], "temperature": 0.0, "avg_logprob": -0.12365325959790655, "compression_ratio": 1.6727941176470589, "no_speech_prob": 7.248116889968514e-05}, {"id": 457, "seek": 117144, "start": 1175.92, "end": 1178.72, "text": " I think it's about augmentation with RAG", "tokens": [50588, 286, 519, 309, 311, 466, 14501, 19631, 365, 14626, 38, 50728], "temperature": 0.0, "avg_logprob": -0.12365325959790655, "compression_ratio": 1.6727941176470589, "no_speech_prob": 7.248116889968514e-05}, {"id": 458, "seek": 117144, "start": 1178.72, "end": 1182.04, "text": " and better modeling techniques, cleaner data sets", "tokens": [50728, 293, 1101, 15983, 7512, 11, 16532, 1412, 6352, 50894], "temperature": 0.0, "avg_logprob": -0.12365325959790655, "compression_ratio": 1.6727941176470589, "no_speech_prob": 7.248116889968514e-05}, {"id": 459, "seek": 117144, "start": 1182.04, "end": 1184.72, "text": " so that you remember the right stuff", "tokens": [50894, 370, 300, 291, 1604, 264, 558, 1507, 51028], "temperature": 0.0, "avg_logprob": -0.12365325959790655, "compression_ratio": 1.6727941176470589, "no_speech_prob": 7.248116889968514e-05}, {"id": 460, "seek": 117144, "start": 1184.72, "end": 1188.2, "text": " and don't retain the less relevant stuff.", "tokens": [51028, 293, 500, 380, 18340, 264, 1570, 7340, 1507, 13, 51202], "temperature": 0.0, "avg_logprob": -0.12365325959790655, "compression_ratio": 1.6727941176470589, "no_speech_prob": 7.248116889968514e-05}, {"id": 461, "seek": 117144, "start": 1189.56, "end": 1192.4, "text": " Those are the techniques that move the needle there.", "tokens": [51270, 3950, 366, 264, 7512, 300, 1286, 264, 11037, 456, 13, 51412], "temperature": 0.0, "avg_logprob": -0.12365325959790655, "compression_ratio": 1.6727941176470589, "no_speech_prob": 7.248116889968514e-05}, {"id": 462, "seek": 117144, "start": 1192.4, "end": 1195.3600000000001, "text": " With reasoning, there are like circuits", "tokens": [51412, 2022, 21577, 11, 456, 366, 411, 26354, 51560], "temperature": 0.0, "avg_logprob": -0.12365325959790655, "compression_ratio": 1.6727941176470589, "no_speech_prob": 7.248116889968514e-05}, {"id": 463, "seek": 117144, "start": 1195.3600000000001, "end": 1197.64, "text": " that you really need to bake in to the model.", "tokens": [51560, 300, 291, 534, 643, 281, 16562, 294, 281, 264, 2316, 13, 51674], "temperature": 0.0, "avg_logprob": -0.12365325959790655, "compression_ratio": 1.6727941176470589, "no_speech_prob": 7.248116889968514e-05}, {"id": 464, "seek": 117144, "start": 1197.64, "end": 1199.56, "text": " You need to show it and demonstrate it,", "tokens": [51674, 509, 643, 281, 855, 309, 293, 11698, 309, 11, 51770], "temperature": 0.0, "avg_logprob": -0.12365325959790655, "compression_ratio": 1.6727941176470589, "no_speech_prob": 7.248116889968514e-05}, {"id": 465, "seek": 119956, "start": 1199.6, "end": 1202.1599999999999, "text": " how to break down tasks at a very low level,", "tokens": [50366, 577, 281, 1821, 760, 9608, 412, 257, 588, 2295, 1496, 11, 50494], "temperature": 0.0, "avg_logprob": -0.0968910140991211, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.0007552675087936223}, {"id": 466, "seek": 119956, "start": 1203.12, "end": 1204.6799999999998, "text": " think through them.", "tokens": [50542, 519, 807, 552, 13, 50620], "temperature": 0.0, "avg_logprob": -0.0968910140991211, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.0007552675087936223}, {"id": 467, "seek": 119956, "start": 1204.6799999999998, "end": 1206.76, "text": " And that's stuff that's not actually", "tokens": [50620, 400, 300, 311, 1507, 300, 311, 406, 767, 50724], "temperature": 0.0, "avg_logprob": -0.0968910140991211, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.0007552675087936223}, {"id": 468, "seek": 119956, "start": 1206.76, "end": 1208.8799999999999, "text": " that abundant on the internet.", "tokens": [50724, 300, 30657, 322, 264, 4705, 13, 50830], "temperature": 0.0, "avg_logprob": -0.0968910140991211, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.0007552675087936223}, {"id": 469, "seek": 119956, "start": 1208.8799999999999, "end": 1212.1599999999999, "text": " So it doesn't come for free using our previous techniques", "tokens": [50830, 407, 309, 1177, 380, 808, 337, 1737, 1228, 527, 3894, 7512, 50994], "temperature": 0.0, "avg_logprob": -0.0968910140991211, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.0007552675087936223}, {"id": 470, "seek": 119956, "start": 1212.1599999999999, "end": 1215.04, "text": " of just scrape the web and train the model and scale up.", "tokens": [50994, 295, 445, 32827, 264, 3670, 293, 3847, 264, 2316, 293, 4373, 493, 13, 51138], "temperature": 0.0, "avg_logprob": -0.0968910140991211, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.0007552675087936223}, {"id": 471, "seek": 119956, "start": 1215.04, "end": 1218.52, "text": " People don't usually write out their inner monologue, right?", "tokens": [51138, 3432, 500, 380, 2673, 2464, 484, 641, 7284, 1108, 42298, 11, 558, 30, 51312], "temperature": 0.0, "avg_logprob": -0.0968910140991211, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.0007552675087936223}, {"id": 472, "seek": 119956, "start": 1218.52, "end": 1220.72, "text": " They usually write the results of that inner monologue.", "tokens": [51312, 814, 2673, 2464, 264, 3542, 295, 300, 7284, 1108, 42298, 13, 51422], "temperature": 0.0, "avg_logprob": -0.0968910140991211, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.0007552675087936223}, {"id": 473, "seek": 119956, "start": 1220.72, "end": 1223.52, "text": " And so it's something that the model", "tokens": [51422, 400, 370, 309, 311, 746, 300, 264, 2316, 51562], "temperature": 0.0, "avg_logprob": -0.0968910140991211, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.0007552675087936223}, {"id": 474, "seek": 119956, "start": 1223.52, "end": 1226.56, "text": " has been missing a view into.", "tokens": [51562, 575, 668, 5361, 257, 1910, 666, 13, 51714], "temperature": 0.0, "avg_logprob": -0.0968910140991211, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.0007552675087936223}, {"id": 475, "seek": 119956, "start": 1226.56, "end": 1228.8, "text": " I think synthetic data will go a long way", "tokens": [51714, 286, 519, 23420, 1412, 486, 352, 257, 938, 636, 51826], "temperature": 0.0, "avg_logprob": -0.0968910140991211, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.0007552675087936223}, {"id": 476, "seek": 122880, "start": 1228.8, "end": 1231.76, "text": " in closing that gap and supporting building", "tokens": [50364, 294, 10377, 300, 7417, 293, 7231, 2390, 50512], "temperature": 0.0, "avg_logprob": -0.115936511495839, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.000646097818389535}, {"id": 477, "seek": 122880, "start": 1232.76, "end": 1236.3999999999999, "text": " multi-trillion token data sets", "tokens": [50562, 4825, 12, 6903, 11836, 14862, 1412, 6352, 50744], "temperature": 0.0, "avg_logprob": -0.115936511495839, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.000646097818389535}, {"id": 478, "seek": 122880, "start": 1236.3999999999999, "end": 1240.28, "text": " that actually demonstrate how to have an inner monologue,", "tokens": [50744, 300, 767, 11698, 577, 281, 362, 364, 7284, 1108, 42298, 11, 50938], "temperature": 0.0, "avg_logprob": -0.115936511495839, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.000646097818389535}, {"id": 479, "seek": 122880, "start": 1240.28, "end": 1241.48, "text": " how to reason through things,", "tokens": [50938, 577, 281, 1778, 807, 721, 11, 50998], "temperature": 0.0, "avg_logprob": -0.115936511495839, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.000646097818389535}, {"id": 480, "seek": 122880, "start": 1241.48, "end": 1244.44, "text": " how to think through problems, make mistakes,", "tokens": [50998, 577, 281, 519, 807, 2740, 11, 652, 8038, 11, 51146], "temperature": 0.0, "avg_logprob": -0.115936511495839, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.000646097818389535}, {"id": 481, "seek": 122880, "start": 1244.44, "end": 1247.68, "text": " identify mistakes, correct them and retry.", "tokens": [51146, 5876, 8038, 11, 3006, 552, 293, 1533, 627, 13, 51308], "temperature": 0.0, "avg_logprob": -0.115936511495839, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.000646097818389535}, {"id": 482, "seek": 122880, "start": 1247.68, "end": 1250.44, "text": " That sort of long thought process data", "tokens": [51308, 663, 1333, 295, 938, 1194, 1399, 1412, 51446], "temperature": 0.0, "avg_logprob": -0.115936511495839, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.000646097818389535}, {"id": 483, "seek": 122880, "start": 1250.44, "end": 1253.68, "text": " is actually extremely scarce.", "tokens": [51446, 307, 767, 4664, 41340, 13, 51608], "temperature": 0.0, "avg_logprob": -0.115936511495839, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.000646097818389535}, {"id": 484, "seek": 122880, "start": 1253.68, "end": 1254.52, "text": " It's very rare.", "tokens": [51608, 467, 311, 588, 5892, 13, 51650], "temperature": 0.0, "avg_logprob": -0.115936511495839, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.000646097818389535}, {"id": 485, "seek": 122880, "start": 1254.52, "end": 1255.36, "text": " It's very rare.", "tokens": [51650, 467, 311, 588, 5892, 13, 51692], "temperature": 0.0, "avg_logprob": -0.115936511495839, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.000646097818389535}, {"id": 486, "seek": 122880, "start": 1255.36, "end": 1256.2, "text": " It's really hard to find.", "tokens": [51692, 467, 311, 534, 1152, 281, 915, 13, 51734], "temperature": 0.0, "avg_logprob": -0.115936511495839, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.000646097818389535}, {"id": 487, "seek": 122880, "start": 1256.2, "end": 1257.04, "text": " You can find it on the internet, of course.", "tokens": [51734, 509, 393, 915, 309, 322, 264, 4705, 11, 295, 1164, 13, 51776], "temperature": 0.0, "avg_logprob": -0.115936511495839, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.000646097818389535}, {"id": 488, "seek": 125704, "start": 1257.24, "end": 1262.24, "text": " Stuff like forums where people help each other", "tokens": [50374, 31347, 411, 26998, 689, 561, 854, 1184, 661, 50624], "temperature": 0.0, "avg_logprob": -0.13018055791440217, "compression_ratio": 1.5719424460431655, "no_speech_prob": 0.0009393349755555391}, {"id": 489, "seek": 125704, "start": 1262.28, "end": 1263.8799999999999, "text": " with homework and sort of break down.", "tokens": [50626, 365, 14578, 293, 1333, 295, 1821, 760, 13, 50706], "temperature": 0.0, "avg_logprob": -0.13018055791440217, "compression_ratio": 1.5719424460431655, "no_speech_prob": 0.0009393349755555391}, {"id": 490, "seek": 125704, "start": 1263.8799999999999, "end": 1266.56, "text": " This is how I arrived at this answer.", "tokens": [50706, 639, 307, 577, 286, 6678, 412, 341, 1867, 13, 50840], "temperature": 0.0, "avg_logprob": -0.13018055791440217, "compression_ratio": 1.5719424460431655, "no_speech_prob": 0.0009393349755555391}, {"id": 491, "seek": 125704, "start": 1266.56, "end": 1269.12, "text": " But when you look at the internet in totality,", "tokens": [50840, 583, 562, 291, 574, 412, 264, 4705, 294, 1993, 1860, 11, 50968], "temperature": 0.0, "avg_logprob": -0.13018055791440217, "compression_ratio": 1.5719424460431655, "no_speech_prob": 0.0009393349755555391}, {"id": 492, "seek": 125704, "start": 1269.12, "end": 1272.56, "text": " those are like pinpricks on the surface of this thing.", "tokens": [50968, 729, 366, 411, 5447, 1424, 7663, 322, 264, 3753, 295, 341, 551, 13, 51140], "temperature": 0.0, "avg_logprob": -0.13018055791440217, "compression_ratio": 1.5719424460431655, "no_speech_prob": 0.0009393349755555391}, {"id": 493, "seek": 125704, "start": 1272.56, "end": 1275.04, "text": " And so pulling that forward, emphasizing it,", "tokens": [51140, 400, 370, 8407, 300, 2128, 11, 45550, 309, 11, 51264], "temperature": 0.0, "avg_logprob": -0.13018055791440217, "compression_ratio": 1.5719424460431655, "no_speech_prob": 0.0009393349755555391}, {"id": 494, "seek": 125704, "start": 1275.04, "end": 1278.24, "text": " augmenting it, producing more of that data", "tokens": [51264, 29919, 278, 309, 11, 10501, 544, 295, 300, 1412, 51424], "temperature": 0.0, "avg_logprob": -0.13018055791440217, "compression_ratio": 1.5719424460431655, "no_speech_prob": 0.0009393349755555391}, {"id": 495, "seek": 125704, "start": 1278.24, "end": 1282.24, "text": " should be a key priority if you're gonna actually", "tokens": [51424, 820, 312, 257, 2141, 9365, 498, 291, 434, 799, 767, 51624], "temperature": 0.0, "avg_logprob": -0.13018055791440217, "compression_ratio": 1.5719424460431655, "no_speech_prob": 0.0009393349755555391}, {"id": 496, "seek": 125704, "start": 1282.24, "end": 1284.92, "text": " teach these models to exhibit that behavior.", "tokens": [51624, 2924, 613, 5245, 281, 20487, 300, 5223, 13, 51758], "temperature": 0.0, "avg_logprob": -0.13018055791440217, "compression_ratio": 1.5719424460431655, "no_speech_prob": 0.0009393349755555391}, {"id": 497, "seek": 125704, "start": 1284.92, "end": 1286.56, "text": " Is there a trade-off between,", "tokens": [51758, 1119, 456, 257, 4923, 12, 4506, 1296, 11, 51840], "temperature": 0.0, "avg_logprob": -0.13018055791440217, "compression_ratio": 1.5719424460431655, "no_speech_prob": 0.0009393349755555391}, {"id": 498, "seek": 128656, "start": 1286.6, "end": 1289.8, "text": " I mean, for example, we could use the Unreal Engine", "tokens": [50366, 286, 914, 11, 337, 1365, 11, 321, 727, 764, 264, 34464, 7659, 50526], "temperature": 0.0, "avg_logprob": -0.1512437917418399, "compression_ratio": 1.7038327526132404, "no_speech_prob": 0.0003050180966965854}, {"id": 499, "seek": 128656, "start": 1289.8, "end": 1292.32, "text": " to generate lots of visual training data", "tokens": [50526, 281, 8460, 3195, 295, 5056, 3097, 1412, 50652], "temperature": 0.0, "avg_logprob": -0.1512437917418399, "compression_ratio": 1.7038327526132404, "no_speech_prob": 0.0003050180966965854}, {"id": 500, "seek": 128656, "start": 1292.32, "end": 1294.6799999999998, "text": " for a Vision Foundation model.", "tokens": [50652, 337, 257, 25170, 10335, 2316, 13, 50770], "temperature": 0.0, "avg_logprob": -0.1512437917418399, "compression_ratio": 1.7038327526132404, "no_speech_prob": 0.0003050180966965854}, {"id": 501, "seek": 128656, "start": 1294.6799999999998, "end": 1296.6799999999998, "text": " Or an alternative would be we could have", "tokens": [50770, 1610, 364, 8535, 576, 312, 321, 727, 362, 50870], "temperature": 0.0, "avg_logprob": -0.1512437917418399, "compression_ratio": 1.7038327526132404, "no_speech_prob": 0.0003050180966965854}, {"id": 502, "seek": 128656, "start": 1296.6799999999998, "end": 1299.3999999999999, "text": " like some kind of hybrid prediction architecture", "tokens": [50870, 411, 512, 733, 295, 13051, 17630, 9482, 51006], "temperature": 0.0, "avg_logprob": -0.1512437917418399, "compression_ratio": 1.7038327526132404, "no_speech_prob": 0.0003050180966965854}, {"id": 503, "seek": 128656, "start": 1299.3999999999999, "end": 1302.52, "text": " where we somehow encode naive physics", "tokens": [51006, 689, 321, 6063, 2058, 1429, 29052, 10649, 51162], "temperature": 0.0, "avg_logprob": -0.1512437917418399, "compression_ratio": 1.7038327526132404, "no_speech_prob": 0.0003050180966965854}, {"id": 504, "seek": 128656, "start": 1302.52, "end": 1303.96, "text": " into the architecture itself,", "tokens": [51162, 666, 264, 9482, 2564, 11, 51234], "temperature": 0.0, "avg_logprob": -0.1512437917418399, "compression_ratio": 1.7038327526132404, "no_speech_prob": 0.0003050180966965854}, {"id": 505, "seek": 128656, "start": 1303.96, "end": 1307.32, "text": " which means rather than memorizing lots of generated data,", "tokens": [51234, 597, 1355, 2831, 813, 10560, 3319, 3195, 295, 10833, 1412, 11, 51402], "temperature": 0.0, "avg_logprob": -0.1512437917418399, "compression_ratio": 1.7038327526132404, "no_speech_prob": 0.0003050180966965854}, {"id": 506, "seek": 128656, "start": 1307.32, "end": 1310.9199999999998, "text": " we just kind of build a hybrid architecture.", "tokens": [51402, 321, 445, 733, 295, 1322, 257, 13051, 9482, 13, 51582], "temperature": 0.0, "avg_logprob": -0.1512437917418399, "compression_ratio": 1.7038327526132404, "no_speech_prob": 0.0003050180966965854}, {"id": 507, "seek": 128656, "start": 1310.9199999999998, "end": 1313.76, "text": " Is that a trade-off that you're kind of thinking about?", "tokens": [51582, 1119, 300, 257, 4923, 12, 4506, 300, 291, 434, 733, 295, 1953, 466, 30, 51724], "temperature": 0.0, "avg_logprob": -0.1512437917418399, "compression_ratio": 1.7038327526132404, "no_speech_prob": 0.0003050180966965854}, {"id": 508, "seek": 128656, "start": 1313.76, "end": 1316.28, "text": " Like specifically with the video side of things", "tokens": [51724, 1743, 4682, 365, 264, 960, 1252, 295, 721, 51850], "temperature": 0.0, "avg_logprob": -0.1512437917418399, "compression_ratio": 1.7038327526132404, "no_speech_prob": 0.0003050180966965854}, {"id": 509, "seek": 131628, "start": 1316.32, "end": 1318.56, "text": " where physics is relevant, I think that's", "tokens": [50366, 689, 10649, 307, 7340, 11, 286, 519, 300, 311, 50478], "temperature": 0.0, "avg_logprob": -0.161454943606728, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.00030530791264027357}, {"id": 510, "seek": 131628, "start": 1320.04, "end": 1321.6, "text": " a totally fine strategy.", "tokens": [50552, 257, 3879, 2489, 5206, 13, 50630], "temperature": 0.0, "avg_logprob": -0.161454943606728, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.00030530791264027357}, {"id": 511, "seek": 131628, "start": 1321.6, "end": 1325.08, "text": " I think that, yeah, a lot of the physics engines", "tokens": [50630, 286, 519, 300, 11, 1338, 11, 257, 688, 295, 264, 10649, 12982, 50804], "temperature": 0.0, "avg_logprob": -0.161454943606728, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.00030530791264027357}, {"id": 512, "seek": 131628, "start": 1325.08, "end": 1329.44, "text": " that people have built are, they're flawed, right?", "tokens": [50804, 300, 561, 362, 3094, 366, 11, 436, 434, 38823, 11, 558, 30, 51022], "temperature": 0.0, "avg_logprob": -0.161454943606728, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.00030530791264027357}, {"id": 513, "seek": 131628, "start": 1329.44, "end": 1332.6, "text": " Like video games still don't look like reality.", "tokens": [51022, 1743, 960, 2813, 920, 500, 380, 574, 411, 4103, 13, 51180], "temperature": 0.0, "avg_logprob": -0.161454943606728, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.00030530791264027357}, {"id": 514, "seek": 131628, "start": 1332.6, "end": 1334.6399999999999, "text": " They still don't behave like reality.", "tokens": [51180, 814, 920, 500, 380, 15158, 411, 4103, 13, 51282], "temperature": 0.0, "avg_logprob": -0.161454943606728, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.00030530791264027357}, {"id": 515, "seek": 131628, "start": 1334.6399999999999, "end": 1337.04, "text": " And so training off of that data,", "tokens": [51282, 400, 370, 3097, 766, 295, 300, 1412, 11, 51402], "temperature": 0.0, "avg_logprob": -0.161454943606728, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.00030530791264027357}, {"id": 516, "seek": 131628, "start": 1337.04, "end": 1341.84, "text": " I think will leave you in a really unsatisfying place.", "tokens": [51402, 286, 519, 486, 1856, 291, 294, 257, 534, 2693, 25239, 1840, 1081, 13, 51642], "temperature": 0.0, "avg_logprob": -0.161454943606728, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.00030530791264027357}, {"id": 517, "seek": 134184, "start": 1341.8799999999999, "end": 1346.48, "text": " Like there's just still some Uncanny Valley weirdness to it.", "tokens": [50366, 1743, 456, 311, 445, 920, 512, 1156, 66, 11612, 10666, 3657, 1287, 281, 309, 13, 50596], "temperature": 0.0, "avg_logprob": -0.10910787668314066, "compression_ratio": 1.6706827309236947, "no_speech_prob": 0.00035693662357516587}, {"id": 518, "seek": 134184, "start": 1348.08, "end": 1350.6799999999998, "text": " I think like we have tons of actual video data", "tokens": [50676, 286, 519, 411, 321, 362, 9131, 295, 3539, 960, 1412, 50806], "temperature": 0.0, "avg_logprob": -0.10910787668314066, "compression_ratio": 1.6706827309236947, "no_speech_prob": 0.00035693662357516587}, {"id": 519, "seek": 134184, "start": 1350.6799999999998, "end": 1354.12, "text": " of the real world where physics is definitely implemented", "tokens": [50806, 295, 264, 957, 1002, 689, 10649, 307, 2138, 12270, 50978], "temperature": 0.0, "avg_logprob": -0.10910787668314066, "compression_ratio": 1.6706827309236947, "no_speech_prob": 0.00035693662357516587}, {"id": 520, "seek": 134184, "start": 1354.12, "end": 1357.0, "text": " and being represented completely accurately.", "tokens": [50978, 293, 885, 10379, 2584, 20095, 13, 51122], "temperature": 0.0, "avg_logprob": -0.10910787668314066, "compression_ratio": 1.6706827309236947, "no_speech_prob": 0.00035693662357516587}, {"id": 521, "seek": 134184, "start": 1357.0, "end": 1360.48, "text": " And so that should be our go-to source.", "tokens": [51122, 400, 370, 300, 820, 312, 527, 352, 12, 1353, 4009, 13, 51296], "temperature": 0.0, "avg_logprob": -0.10910787668314066, "compression_ratio": 1.6706827309236947, "no_speech_prob": 0.00035693662357516587}, {"id": 522, "seek": 134184, "start": 1360.48, "end": 1365.48, "text": " I think trying to use simulators at this stage", "tokens": [51296, 286, 519, 1382, 281, 764, 1034, 39265, 412, 341, 3233, 51546], "temperature": 0.0, "avg_logprob": -0.10910787668314066, "compression_ratio": 1.6706827309236947, "no_speech_prob": 0.00035693662357516587}, {"id": 523, "seek": 134184, "start": 1365.9199999999998, "end": 1366.76, "text": " is the wrong approach.", "tokens": [51568, 307, 264, 2085, 3109, 13, 51610], "temperature": 0.0, "avg_logprob": -0.10910787668314066, "compression_ratio": 1.6706827309236947, "no_speech_prob": 0.00035693662357516587}, {"id": 524, "seek": 134184, "start": 1366.76, "end": 1368.6799999999998, "text": " I think you should take as much data", "tokens": [51610, 286, 519, 291, 820, 747, 382, 709, 1412, 51706], "temperature": 0.0, "avg_logprob": -0.10910787668314066, "compression_ratio": 1.6706827309236947, "no_speech_prob": 0.00035693662357516587}, {"id": 525, "seek": 134184, "start": 1368.6799999999998, "end": 1370.0, "text": " from the real world as you can", "tokens": [51706, 490, 264, 957, 1002, 382, 291, 393, 51772], "temperature": 0.0, "avg_logprob": -0.10910787668314066, "compression_ratio": 1.6706827309236947, "no_speech_prob": 0.00035693662357516587}, {"id": 526, "seek": 134184, "start": 1370.0, "end": 1371.6, "text": " and use that as a bootstrap", "tokens": [51772, 293, 764, 300, 382, 257, 11450, 372, 4007, 51852], "temperature": 0.0, "avg_logprob": -0.10910787668314066, "compression_ratio": 1.6706827309236947, "no_speech_prob": 0.00035693662357516587}, {"id": 527, "seek": 137160, "start": 1371.6, "end": 1373.7199999999998, "text": " to then build synthetic data engines", "tokens": [50364, 281, 550, 1322, 23420, 1412, 12982, 50470], "temperature": 0.0, "avg_logprob": -0.11776392083418996, "compression_ratio": 1.768627450980392, "no_speech_prob": 0.00019103796512354165}, {"id": 528, "seek": 137160, "start": 1373.7199999999998, "end": 1376.32, "text": " that help you iteratively improve.", "tokens": [50470, 300, 854, 291, 17138, 19020, 3470, 13, 50600], "temperature": 0.0, "avg_logprob": -0.11776392083418996, "compression_ratio": 1.768627450980392, "no_speech_prob": 0.00019103796512354165}, {"id": 529, "seek": 137160, "start": 1376.32, "end": 1378.12, "text": " It's what happened in language as well, right?", "tokens": [50600, 467, 311, 437, 2011, 294, 2856, 382, 731, 11, 558, 30, 50690], "temperature": 0.0, "avg_logprob": -0.11776392083418996, "compression_ratio": 1.768627450980392, "no_speech_prob": 0.00019103796512354165}, {"id": 530, "seek": 137160, "start": 1378.12, "end": 1381.6399999999999, "text": " Like we didn't go to synthetic language,", "tokens": [50690, 1743, 321, 994, 380, 352, 281, 23420, 2856, 11, 50866], "temperature": 0.0, "avg_logprob": -0.11776392083418996, "compression_ratio": 1.768627450980392, "no_speech_prob": 0.00019103796512354165}, {"id": 531, "seek": 137160, "start": 1381.6399999999999, "end": 1384.1599999999999, "text": " rules-based synthetic language generators", "tokens": [50866, 4474, 12, 6032, 23420, 2856, 38662, 50992], "temperature": 0.0, "avg_logprob": -0.11776392083418996, "compression_ratio": 1.768627450980392, "no_speech_prob": 0.00019103796512354165}, {"id": 532, "seek": 137160, "start": 1384.1599999999999, "end": 1385.48, "text": " to teach our language models,", "tokens": [50992, 281, 2924, 527, 2856, 5245, 11, 51058], "temperature": 0.0, "avg_logprob": -0.11776392083418996, "compression_ratio": 1.768627450980392, "no_speech_prob": 0.00019103796512354165}, {"id": 533, "seek": 137160, "start": 1385.48, "end": 1387.52, "text": " the basic principles of language", "tokens": [51058, 264, 3875, 9156, 295, 2856, 51160], "temperature": 0.0, "avg_logprob": -0.11776392083418996, "compression_ratio": 1.768627450980392, "no_speech_prob": 0.00019103796512354165}, {"id": 534, "seek": 137160, "start": 1387.52, "end": 1391.36, "text": " using our linguistic models that we've built.", "tokens": [51160, 1228, 527, 43002, 5245, 300, 321, 600, 3094, 13, 51352], "temperature": 0.0, "avg_logprob": -0.11776392083418996, "compression_ratio": 1.768627450980392, "no_speech_prob": 0.00019103796512354165}, {"id": 535, "seek": 137160, "start": 1391.36, "end": 1393.1999999999998, "text": " No, we threw all that away.", "tokens": [51352, 883, 11, 321, 11918, 439, 300, 1314, 13, 51444], "temperature": 0.0, "avg_logprob": -0.11776392083418996, "compression_ratio": 1.768627450980392, "no_speech_prob": 0.00019103796512354165}, {"id": 536, "seek": 137160, "start": 1393.1999999999998, "end": 1397.36, "text": " We took actual language data from humans, trained on that,", "tokens": [51444, 492, 1890, 3539, 2856, 1412, 490, 6255, 11, 8895, 322, 300, 11, 51652], "temperature": 0.0, "avg_logprob": -0.11776392083418996, "compression_ratio": 1.768627450980392, "no_speech_prob": 0.00019103796512354165}, {"id": 537, "seek": 137160, "start": 1397.36, "end": 1400.28, "text": " and then used the models that were the output of that", "tokens": [51652, 293, 550, 1143, 264, 5245, 300, 645, 264, 5598, 295, 300, 51798], "temperature": 0.0, "avg_logprob": -0.11776392083418996, "compression_ratio": 1.768627450980392, "no_speech_prob": 0.00019103796512354165}, {"id": 538, "seek": 140028, "start": 1400.32, "end": 1405.32, "text": " to improve iteratively and via experimentation.", "tokens": [50366, 281, 3470, 17138, 19020, 293, 5766, 37142, 13, 50616], "temperature": 0.0, "avg_logprob": -0.18179123489945023, "compression_ratio": 1.5475285171102662, "no_speech_prob": 0.0004225698357913643}, {"id": 539, "seek": 140028, "start": 1407.04, "end": 1409.6, "text": " I think the same will be true in vision.", "tokens": [50702, 286, 519, 264, 912, 486, 312, 2074, 294, 5201, 13, 50830], "temperature": 0.0, "avg_logprob": -0.18179123489945023, "compression_ratio": 1.5475285171102662, "no_speech_prob": 0.0004225698357913643}, {"id": 540, "seek": 140028, "start": 1409.6, "end": 1412.16, "text": " That's a really interesting point, actually.", "tokens": [50830, 663, 311, 257, 534, 1880, 935, 11, 767, 13, 50958], "temperature": 0.0, "avg_logprob": -0.18179123489945023, "compression_ratio": 1.5475285171102662, "no_speech_prob": 0.0004225698357913643}, {"id": 541, "seek": 140028, "start": 1412.16, "end": 1414.3999999999999, "text": " Because with the SORA model from OpenAI,", "tokens": [50958, 1436, 365, 264, 318, 36860, 2316, 490, 7238, 48698, 11, 51070], "temperature": 0.0, "avg_logprob": -0.18179123489945023, "compression_ratio": 1.5475285171102662, "no_speech_prob": 0.0004225698357913643}, {"id": 542, "seek": 140028, "start": 1414.3999999999999, "end": 1415.72, "text": " it does look a bit weird.", "tokens": [51070, 309, 775, 574, 257, 857, 3657, 13, 51136], "temperature": 0.0, "avg_logprob": -0.18179123489945023, "compression_ratio": 1.5475285171102662, "no_speech_prob": 0.0004225698357913643}, {"id": 543, "seek": 140028, "start": 1415.72, "end": 1417.16, "text": " It looks like it's always flying", "tokens": [51136, 467, 1542, 411, 309, 311, 1009, 7137, 51208], "temperature": 0.0, "avg_logprob": -0.18179123489945023, "compression_ratio": 1.5475285171102662, "no_speech_prob": 0.0004225698357913643}, {"id": 544, "seek": 140028, "start": 1417.16, "end": 1419.76, "text": " and it looks very game engine-like.", "tokens": [51208, 293, 309, 1542, 588, 1216, 2848, 12, 4092, 13, 51338], "temperature": 0.0, "avg_logprob": -0.18179123489945023, "compression_ratio": 1.5475285171102662, "no_speech_prob": 0.0004225698357913643}, {"id": 545, "seek": 140028, "start": 1419.76, "end": 1422.32, "text": " And the language example is beautiful.", "tokens": [51338, 400, 264, 2856, 1365, 307, 2238, 13, 51466], "temperature": 0.0, "avg_logprob": -0.18179123489945023, "compression_ratio": 1.5475285171102662, "no_speech_prob": 0.0004225698357913643}, {"id": 546, "seek": 140028, "start": 1422.32, "end": 1424.96, "text": " But what about something like mathematics?", "tokens": [51466, 583, 437, 466, 746, 411, 18666, 30, 51598], "temperature": 0.0, "avg_logprob": -0.18179123489945023, "compression_ratio": 1.5475285171102662, "no_speech_prob": 0.0004225698357913643}, {"id": 547, "seek": 140028, "start": 1424.96, "end": 1428.56, "text": " Are there examples where rather than kind of, you know,", "tokens": [51598, 2014, 456, 5110, 689, 2831, 813, 733, 295, 11, 291, 458, 11, 51778], "temperature": 0.0, "avg_logprob": -0.18179123489945023, "compression_ratio": 1.5475285171102662, "no_speech_prob": 0.0004225698357913643}, {"id": 548, "seek": 142856, "start": 1428.56, "end": 1431.36, "text": " perturbing or mutating what already exists,", "tokens": [50364, 13269, 374, 4324, 420, 5839, 990, 437, 1217, 8198, 11, 50504], "temperature": 0.0, "avg_logprob": -0.121341104860659, "compression_ratio": 1.4952380952380953, "no_speech_prob": 0.0002867428120225668}, {"id": 549, "seek": 142856, "start": 1431.36, "end": 1434.28, "text": " you might just start from first principles and rules?", "tokens": [50504, 291, 1062, 445, 722, 490, 700, 9156, 293, 4474, 30, 50650], "temperature": 0.0, "avg_logprob": -0.121341104860659, "compression_ratio": 1.4952380952380953, "no_speech_prob": 0.0002867428120225668}, {"id": 550, "seek": 142856, "start": 1434.28, "end": 1435.28, "text": " Totally, yeah.", "tokens": [50650, 22837, 11, 1338, 13, 50700], "temperature": 0.0, "avg_logprob": -0.121341104860659, "compression_ratio": 1.4952380952380953, "no_speech_prob": 0.0002867428120225668}, {"id": 551, "seek": 142856, "start": 1435.28, "end": 1440.28, "text": " Like mathematics is so explicitly rule-driven", "tokens": [50700, 1743, 18666, 307, 370, 20803, 4978, 12, 25456, 50950], "temperature": 0.0, "avg_logprob": -0.121341104860659, "compression_ratio": 1.4952380952380953, "no_speech_prob": 0.0002867428120225668}, {"id": 552, "seek": 142856, "start": 1441.04, "end": 1444.0, "text": " and so explicitly verifiable.", "tokens": [50988, 293, 370, 20803, 1306, 30876, 13, 51136], "temperature": 0.0, "avg_logprob": -0.121341104860659, "compression_ratio": 1.4952380952380953, "no_speech_prob": 0.0002867428120225668}, {"id": 553, "seek": 142856, "start": 1444.0, "end": 1448.6, "text": " It's like the perfect example of synthetic data generation.", "tokens": [51136, 467, 311, 411, 264, 2176, 1365, 295, 23420, 1412, 5125, 13, 51366], "temperature": 0.0, "avg_logprob": -0.121341104860659, "compression_ratio": 1.4952380952380953, "no_speech_prob": 0.0002867428120225668}, {"id": 554, "seek": 142856, "start": 1448.6, "end": 1453.6, "text": " I think it's definitely one of the domains", "tokens": [51366, 286, 519, 309, 311, 2138, 472, 295, 264, 25514, 51616], "temperature": 0.0, "avg_logprob": -0.121341104860659, "compression_ratio": 1.4952380952380953, "no_speech_prob": 0.0002867428120225668}, {"id": 555, "seek": 142856, "start": 1453.76, "end": 1455.24, "text": " that will crack first.", "tokens": [51624, 300, 486, 6226, 700, 13, 51698], "temperature": 0.0, "avg_logprob": -0.121341104860659, "compression_ratio": 1.4952380952380953, "no_speech_prob": 0.0002867428120225668}, {"id": 556, "seek": 145524, "start": 1455.44, "end": 1459.24, "text": " And on top of that, code, right?", "tokens": [50374, 400, 322, 1192, 295, 300, 11, 3089, 11, 558, 30, 50564], "temperature": 0.0, "avg_logprob": -0.17314293110265142, "compression_ratio": 1.5776892430278884, "no_speech_prob": 0.0027951840311288834}, {"id": 557, "seek": 145524, "start": 1459.24, "end": 1462.28, "text": " You can completely, synthetically generate code, verify it.", "tokens": [50564, 509, 393, 2584, 11, 10657, 22652, 8460, 3089, 11, 16888, 309, 13, 50716], "temperature": 0.0, "avg_logprob": -0.17314293110265142, "compression_ratio": 1.5776892430278884, "no_speech_prob": 0.0027951840311288834}, {"id": 558, "seek": 145524, "start": 1462.28, "end": 1463.1200000000001, "text": " Does it run?", "tokens": [50716, 4402, 309, 1190, 30, 50758], "temperature": 0.0, "avg_logprob": -0.17314293110265142, "compression_ratio": 1.5776892430278884, "no_speech_prob": 0.0027951840311288834}, {"id": 559, "seek": 145524, "start": 1463.1200000000001, "end": 1466.56, "text": " Does it produce the outputs that you want on a test set?", "tokens": [50758, 4402, 309, 5258, 264, 23930, 300, 291, 528, 322, 257, 1500, 992, 30, 50930], "temperature": 0.0, "avg_logprob": -0.17314293110265142, "compression_ratio": 1.5776892430278884, "no_speech_prob": 0.0027951840311288834}, {"id": 560, "seek": 145524, "start": 1467.96, "end": 1471.24, "text": " So when it is that explicit and verifiable,", "tokens": [51000, 407, 562, 309, 307, 300, 13691, 293, 1306, 30876, 11, 51164], "temperature": 0.0, "avg_logprob": -0.17314293110265142, "compression_ratio": 1.5776892430278884, "no_speech_prob": 0.0027951840311288834}, {"id": 561, "seek": 145524, "start": 1471.24, "end": 1473.68, "text": " it's perfect for synthetic data generation,", "tokens": [51164, 309, 311, 2176, 337, 23420, 1412, 5125, 11, 51286], "temperature": 0.0, "avg_logprob": -0.17314293110265142, "compression_ratio": 1.5776892430278884, "no_speech_prob": 0.0027951840311288834}, {"id": 562, "seek": 145524, "start": 1473.68, "end": 1474.88, "text": " like just ideal.", "tokens": [51286, 411, 445, 7157, 13, 51346], "temperature": 0.0, "avg_logprob": -0.17314293110265142, "compression_ratio": 1.5776892430278884, "no_speech_prob": 0.0027951840311288834}, {"id": 563, "seek": 145524, "start": 1474.88, "end": 1477.84, "text": " Yeah, but I guess this is kind of what I'm thinking about.", "tokens": [51346, 865, 11, 457, 286, 2041, 341, 307, 733, 295, 437, 286, 478, 1953, 466, 13, 51494], "temperature": 0.0, "avg_logprob": -0.17314293110265142, "compression_ratio": 1.5776892430278884, "no_speech_prob": 0.0027951840311288834}, {"id": 564, "seek": 145524, "start": 1477.84, "end": 1480.68, "text": " That with code, you can actually constrain it way more", "tokens": [51494, 663, 365, 3089, 11, 291, 393, 767, 1817, 7146, 309, 636, 544, 51636], "temperature": 0.0, "avg_logprob": -0.17314293110265142, "compression_ratio": 1.5776892430278884, "no_speech_prob": 0.0027951840311288834}, {"id": 565, "seek": 145524, "start": 1480.68, "end": 1481.88, "text": " than language.", "tokens": [51636, 813, 2856, 13, 51696], "temperature": 0.0, "avg_logprob": -0.17314293110265142, "compression_ratio": 1.5776892430278884, "no_speech_prob": 0.0027951840311288834}, {"id": 566, "seek": 148188, "start": 1481.88, "end": 1485.5200000000002, "text": " So you could, rather than using an existing self-attention", "tokens": [50364, 407, 291, 727, 11, 2831, 813, 1228, 364, 6741, 2698, 12, 1591, 1251, 50546], "temperature": 0.0, "avg_logprob": -0.13400250187626592, "compression_ratio": 1.6463022508038585, "no_speech_prob": 0.0006249861908145249}, {"id": 567, "seek": 148188, "start": 1485.5200000000002, "end": 1487.68, "text": " transformer, you know, you might want to have something", "tokens": [50546, 31782, 11, 291, 458, 11, 291, 1062, 528, 281, 362, 746, 50654], "temperature": 0.0, "avg_logprob": -0.13400250187626592, "compression_ratio": 1.6463022508038585, "no_speech_prob": 0.0006249861908145249}, {"id": 568, "seek": 148188, "start": 1487.68, "end": 1490.0800000000002, "text": " that only works on trees or whatever.", "tokens": [50654, 300, 787, 1985, 322, 5852, 420, 2035, 13, 50774], "temperature": 0.0, "avg_logprob": -0.13400250187626592, "compression_ratio": 1.6463022508038585, "no_speech_prob": 0.0006249861908145249}, {"id": 569, "seek": 148188, "start": 1490.0800000000002, "end": 1492.96, "text": " And maybe that would work better for that particular thing.", "tokens": [50774, 400, 1310, 300, 576, 589, 1101, 337, 300, 1729, 551, 13, 50918], "temperature": 0.0, "avg_logprob": -0.13400250187626592, "compression_ratio": 1.6463022508038585, "no_speech_prob": 0.0006249861908145249}, {"id": 570, "seek": 148188, "start": 1492.96, "end": 1495.24, "text": " But then I guess we'd have to have some kind of mixture", "tokens": [50918, 583, 550, 286, 2041, 321, 1116, 362, 281, 362, 512, 733, 295, 9925, 51032], "temperature": 0.0, "avg_logprob": -0.13400250187626592, "compression_ratio": 1.6463022508038585, "no_speech_prob": 0.0006249861908145249}, {"id": 571, "seek": 148188, "start": 1495.24, "end": 1498.64, "text": " of experts and not have a single model.", "tokens": [51032, 295, 8572, 293, 406, 362, 257, 2167, 2316, 13, 51202], "temperature": 0.0, "avg_logprob": -0.13400250187626592, "compression_ratio": 1.6463022508038585, "no_speech_prob": 0.0006249861908145249}, {"id": 572, "seek": 148188, "start": 1498.64, "end": 1502.64, "text": " Yeah, I think that's behind the scenes actually,", "tokens": [51202, 865, 11, 286, 519, 300, 311, 2261, 264, 8026, 767, 11, 51402], "temperature": 0.0, "avg_logprob": -0.13400250187626592, "compression_ratio": 1.6463022508038585, "no_speech_prob": 0.0006249861908145249}, {"id": 573, "seek": 148188, "start": 1502.64, "end": 1504.0400000000002, "text": " a lot of the strategy.", "tokens": [51402, 257, 688, 295, 264, 5206, 13, 51472], "temperature": 0.0, "avg_logprob": -0.13400250187626592, "compression_ratio": 1.6463022508038585, "no_speech_prob": 0.0006249861908145249}, {"id": 574, "seek": 148188, "start": 1504.0400000000002, "end": 1507.44, "text": " You'll likely have an MOE where one component,", "tokens": [51472, 509, 603, 3700, 362, 364, 19290, 36, 689, 472, 6542, 11, 51642], "temperature": 0.0, "avg_logprob": -0.13400250187626592, "compression_ratio": 1.6463022508038585, "no_speech_prob": 0.0006249861908145249}, {"id": 575, "seek": 148188, "start": 1507.44, "end": 1510.0, "text": " one of those experts is gonna be an expert in code,", "tokens": [51642, 472, 295, 729, 8572, 307, 799, 312, 364, 5844, 294, 3089, 11, 51770], "temperature": 0.0, "avg_logprob": -0.13400250187626592, "compression_ratio": 1.6463022508038585, "no_speech_prob": 0.0006249861908145249}, {"id": 576, "seek": 148188, "start": 1510.0, "end": 1511.8000000000002, "text": " very highly specialized to that.", "tokens": [51770, 588, 5405, 19813, 281, 300, 13, 51860], "temperature": 0.0, "avg_logprob": -0.13400250187626592, "compression_ratio": 1.6463022508038585, "no_speech_prob": 0.0006249861908145249}, {"id": 577, "seek": 151180, "start": 1511.84, "end": 1514.6, "text": " Heavily upsampled on synthetic code data", "tokens": [50366, 634, 706, 953, 15497, 335, 15551, 322, 23420, 3089, 1412, 50504], "temperature": 0.0, "avg_logprob": -0.14069023728370667, "compression_ratio": 1.5619469026548674, "no_speech_prob": 9.60911056608893e-05}, {"id": 578, "seek": 151180, "start": 1514.6, "end": 1517.48, "text": " and real code data, math, et cetera.", "tokens": [50504, 293, 957, 3089, 1412, 11, 5221, 11, 1030, 11458, 13, 50648], "temperature": 0.0, "avg_logprob": -0.14069023728370667, "compression_ratio": 1.5619469026548674, "no_speech_prob": 9.60911056608893e-05}, {"id": 579, "seek": 151180, "start": 1518.76, "end": 1522.12, "text": " And that expert will act as a general reasoning engine", "tokens": [50712, 400, 300, 5844, 486, 605, 382, 257, 2674, 21577, 2848, 50880], "temperature": 0.0, "avg_logprob": -0.14069023728370667, "compression_ratio": 1.5619469026548674, "no_speech_prob": 9.60911056608893e-05}, {"id": 580, "seek": 151180, "start": 1522.12, "end": 1523.68, "text": " and will be very good at logic", "tokens": [50880, 293, 486, 312, 588, 665, 412, 9952, 50958], "temperature": 0.0, "avg_logprob": -0.14069023728370667, "compression_ratio": 1.5619469026548674, "no_speech_prob": 9.60911056608893e-05}, {"id": 581, "seek": 151180, "start": 1523.68, "end": 1525.76, "text": " and those sorts of components.", "tokens": [50958, 293, 729, 7527, 295, 6677, 13, 51062], "temperature": 0.0, "avg_logprob": -0.14069023728370667, "compression_ratio": 1.5619469026548674, "no_speech_prob": 9.60911056608893e-05}, {"id": 582, "seek": 151180, "start": 1525.76, "end": 1528.32, "text": " You might have a medical expert,", "tokens": [51062, 509, 1062, 362, 257, 4625, 5844, 11, 51190], "temperature": 0.0, "avg_logprob": -0.14069023728370667, "compression_ratio": 1.5619469026548674, "no_speech_prob": 9.60911056608893e-05}, {"id": 583, "seek": 151180, "start": 1528.32, "end": 1531.96, "text": " which has dramatic upsampling along that axis.", "tokens": [51190, 597, 575, 12023, 15497, 335, 11970, 2051, 300, 10298, 13, 51372], "temperature": 0.0, "avg_logprob": -0.14069023728370667, "compression_ratio": 1.5619469026548674, "no_speech_prob": 9.60911056608893e-05}, {"id": 584, "seek": 151180, "start": 1534.2, "end": 1539.2, "text": " Yeah, I think that's a very effective path towards", "tokens": [51484, 865, 11, 286, 519, 300, 311, 257, 588, 4942, 3100, 3030, 51734], "temperature": 0.0, "avg_logprob": -0.14069023728370667, "compression_ratio": 1.5619469026548674, "no_speech_prob": 9.60911056608893e-05}, {"id": 585, "seek": 151180, "start": 1539.44, "end": 1541.58, "text": " even more efficient models.", "tokens": [51746, 754, 544, 7148, 5245, 13, 51853], "temperature": 0.0, "avg_logprob": -0.14069023728370667, "compression_ratio": 1.5619469026548674, "no_speech_prob": 9.60911056608893e-05}, {"id": 586, "seek": 154158, "start": 1541.58, "end": 1543.74, "text": " So if you're in the medical domain", "tokens": [50364, 407, 498, 291, 434, 294, 264, 4625, 9274, 50472], "temperature": 0.0, "avg_logprob": -0.11969418274728875, "compression_ratio": 1.6746987951807228, "no_speech_prob": 9.902926831273362e-05}, {"id": 587, "seek": 154158, "start": 1543.74, "end": 1545.9399999999998, "text": " or the math or code domain,", "tokens": [50472, 420, 264, 5221, 420, 3089, 9274, 11, 50582], "temperature": 0.0, "avg_logprob": -0.11969418274728875, "compression_ratio": 1.6746987951807228, "no_speech_prob": 9.902926831273362e-05}, {"id": 588, "seek": 154158, "start": 1545.9399999999998, "end": 1547.98, "text": " you can then pull out that expert", "tokens": [50582, 291, 393, 550, 2235, 484, 300, 5844, 50684], "temperature": 0.0, "avg_logprob": -0.11969418274728875, "compression_ratio": 1.6746987951807228, "no_speech_prob": 9.902926831273362e-05}, {"id": 589, "seek": 154158, "start": 1547.98, "end": 1549.4199999999998, "text": " and use it independently.", "tokens": [50684, 293, 764, 309, 21761, 13, 50756], "temperature": 0.0, "avg_logprob": -0.11969418274728875, "compression_ratio": 1.6746987951807228, "no_speech_prob": 9.902926831273362e-05}, {"id": 590, "seek": 154158, "start": 1549.4199999999998, "end": 1554.4199999999998, "text": " You don't need to keep around this huge monolithic model.", "tokens": [50756, 509, 500, 380, 643, 281, 1066, 926, 341, 2603, 1108, 42878, 2316, 13, 51006], "temperature": 0.0, "avg_logprob": -0.11969418274728875, "compression_ratio": 1.6746987951807228, "no_speech_prob": 9.902926831273362e-05}, {"id": 591, "seek": 154158, "start": 1554.6599999999999, "end": 1557.46, "text": " You can just take out a sub-component and deploy that.", "tokens": [51018, 509, 393, 445, 747, 484, 257, 1422, 12, 21541, 30365, 293, 7274, 300, 13, 51158], "temperature": 0.0, "avg_logprob": -0.11969418274728875, "compression_ratio": 1.6746987951807228, "no_speech_prob": 9.902926831273362e-05}, {"id": 592, "seek": 154158, "start": 1559.3799999999999, "end": 1562.1799999999998, "text": " Yeah, I think that architecture already exists.", "tokens": [51254, 865, 11, 286, 519, 300, 9482, 1217, 8198, 13, 51394], "temperature": 0.0, "avg_logprob": -0.11969418274728875, "compression_ratio": 1.6746987951807228, "no_speech_prob": 9.902926831273362e-05}, {"id": 593, "seek": 154158, "start": 1562.1799999999998, "end": 1563.82, "text": " Yeah, I wonder if you can talk to that a little bit", "tokens": [51394, 865, 11, 286, 2441, 498, 291, 393, 751, 281, 300, 257, 707, 857, 51476], "temperature": 0.0, "avg_logprob": -0.11969418274728875, "compression_ratio": 1.6746987951807228, "no_speech_prob": 9.902926831273362e-05}, {"id": 594, "seek": 154158, "start": 1563.82, "end": 1565.1799999999998, "text": " because I'm very excited about that", "tokens": [51476, 570, 286, 478, 588, 2919, 466, 300, 51544], "temperature": 0.0, "avg_logprob": -0.11969418274728875, "compression_ratio": 1.6746987951807228, "no_speech_prob": 9.902926831273362e-05}, {"id": 595, "seek": 154158, "start": 1565.1799999999998, "end": 1568.06, "text": " because it now seems that maybe we could call", "tokens": [51544, 570, 309, 586, 2544, 300, 1310, 321, 727, 818, 51688], "temperature": 0.0, "avg_logprob": -0.11969418274728875, "compression_ratio": 1.6746987951807228, "no_speech_prob": 9.902926831273362e-05}, {"id": 596, "seek": 156806, "start": 1568.06, "end": 1572.4199999999998, "text": " what you just described an agentic distributed AI system", "tokens": [50364, 437, 291, 445, 7619, 364, 9461, 299, 12631, 7318, 1185, 50582], "temperature": 0.0, "avg_logprob": -0.1354759389703924, "compression_ratio": 1.878228782287823, "no_speech_prob": 0.0032520093955099583}, {"id": 597, "seek": 156806, "start": 1572.4199999999998, "end": 1575.82, "text": " where the agents can pass messages to each other", "tokens": [50582, 689, 264, 12554, 393, 1320, 7897, 281, 1184, 661, 50752], "temperature": 0.0, "avg_logprob": -0.1354759389703924, "compression_ratio": 1.878228782287823, "no_speech_prob": 0.0032520093955099583}, {"id": 598, "seek": 156806, "start": 1575.82, "end": 1578.5, "text": " and one of them might be an expert in mathematics,", "tokens": [50752, 293, 472, 295, 552, 1062, 312, 364, 5844, 294, 18666, 11, 50886], "temperature": 0.0, "avg_logprob": -0.1354759389703924, "compression_ratio": 1.878228782287823, "no_speech_prob": 0.0032520093955099583}, {"id": 599, "seek": 156806, "start": 1578.5, "end": 1580.86, "text": " one of them might be an expert in coding or so on.", "tokens": [50886, 472, 295, 552, 1062, 312, 364, 5844, 294, 17720, 420, 370, 322, 13, 51004], "temperature": 0.0, "avg_logprob": -0.1354759389703924, "compression_ratio": 1.878228782287823, "no_speech_prob": 0.0032520093955099583}, {"id": 600, "seek": 156806, "start": 1580.86, "end": 1581.86, "text": " But then you've got this problem", "tokens": [51004, 583, 550, 291, 600, 658, 341, 1154, 51054], "temperature": 0.0, "avg_logprob": -0.1354759389703924, "compression_ratio": 1.878228782287823, "no_speech_prob": 0.0032520093955099583}, {"id": 601, "seek": 156806, "start": 1581.86, "end": 1584.3, "text": " that you kind of send a message into the nexus", "tokens": [51054, 300, 291, 733, 295, 2845, 257, 3636, 666, 264, 408, 32618, 51176], "temperature": 0.0, "avg_logprob": -0.1354759389703924, "compression_ratio": 1.878228782287823, "no_speech_prob": 0.0032520093955099583}, {"id": 602, "seek": 156806, "start": 1584.3, "end": 1586.86, "text": " and all of the models are kind of passing messages", "tokens": [51176, 293, 439, 295, 264, 5245, 366, 733, 295, 8437, 7897, 51304], "temperature": 0.0, "avg_logprob": -0.1354759389703924, "compression_ratio": 1.878228782287823, "no_speech_prob": 0.0032520093955099583}, {"id": 603, "seek": 156806, "start": 1586.86, "end": 1590.46, "text": " to each other and it's kind of unbounded in runtime", "tokens": [51304, 281, 1184, 661, 293, 309, 311, 733, 295, 517, 18767, 292, 294, 34474, 51484], "temperature": 0.0, "avg_logprob": -0.1354759389703924, "compression_ratio": 1.878228782287823, "no_speech_prob": 0.0032520093955099583}, {"id": 604, "seek": 156806, "start": 1590.46, "end": 1591.86, "text": " as opposed to one of the great things", "tokens": [51484, 382, 8851, 281, 472, 295, 264, 869, 721, 51554], "temperature": 0.0, "avg_logprob": -0.1354759389703924, "compression_ratio": 1.878228782287823, "no_speech_prob": 0.0032520093955099583}, {"id": 605, "seek": 156806, "start": 1591.86, "end": 1593.34, "text": " with the language model is", "tokens": [51554, 365, 264, 2856, 2316, 307, 51628], "temperature": 0.0, "avg_logprob": -0.1354759389703924, "compression_ratio": 1.878228782287823, "no_speech_prob": 0.0032520093955099583}, {"id": 606, "seek": 156806, "start": 1593.34, "end": 1595.94, "text": " it just does a fixed amount of compute per iteration.", "tokens": [51628, 309, 445, 775, 257, 6806, 2372, 295, 14722, 680, 24784, 13, 51758], "temperature": 0.0, "avg_logprob": -0.1354759389703924, "compression_ratio": 1.878228782287823, "no_speech_prob": 0.0032520093955099583}, {"id": 607, "seek": 159594, "start": 1596.02, "end": 1598.02, "text": " You just put some prompt in", "tokens": [50368, 509, 445, 829, 512, 12391, 294, 50468], "temperature": 0.0, "avg_logprob": -0.14015734961273474, "compression_ratio": 1.5951417004048583, "no_speech_prob": 0.0003907608042936772}, {"id": 608, "seek": 159594, "start": 1598.02, "end": 1600.18, "text": " and you get the answer straight back out.", "tokens": [50468, 293, 291, 483, 264, 1867, 2997, 646, 484, 13, 50576], "temperature": 0.0, "avg_logprob": -0.14015734961273474, "compression_ratio": 1.5951417004048583, "no_speech_prob": 0.0003907608042936772}, {"id": 609, "seek": 159594, "start": 1600.18, "end": 1604.02, "text": " So does that kind of unboundedness introduce problems?", "tokens": [50576, 407, 775, 300, 733, 295, 517, 18767, 292, 1287, 5366, 2740, 30, 50768], "temperature": 0.0, "avg_logprob": -0.14015734961273474, "compression_ratio": 1.5951417004048583, "no_speech_prob": 0.0003907608042936772}, {"id": 610, "seek": 159594, "start": 1605.06, "end": 1607.94, "text": " I mean, a language model could just generate infinitely", "tokens": [50820, 286, 914, 11, 257, 2856, 2316, 727, 445, 8460, 36227, 50964], "temperature": 0.0, "avg_logprob": -0.14015734961273474, "compression_ratio": 1.5951417004048583, "no_speech_prob": 0.0003907608042936772}, {"id": 611, "seek": 159594, "start": 1607.94, "end": 1609.5800000000002, "text": " and not produce a stop token", "tokens": [50964, 293, 406, 5258, 257, 1590, 14862, 51046], "temperature": 0.0, "avg_logprob": -0.14015734961273474, "compression_ratio": 1.5951417004048583, "no_speech_prob": 0.0003907608042936772}, {"id": 612, "seek": 159594, "start": 1609.5800000000002, "end": 1611.5800000000002, "text": " and you would go on forever.", "tokens": [51046, 293, 291, 576, 352, 322, 5680, 13, 51146], "temperature": 0.0, "avg_logprob": -0.14015734961273474, "compression_ratio": 1.5951417004048583, "no_speech_prob": 0.0003907608042936772}, {"id": 613, "seek": 159594, "start": 1611.5800000000002, "end": 1613.66, "text": " So I think the problem already exists", "tokens": [51146, 407, 286, 519, 264, 1154, 1217, 8198, 51250], "temperature": 0.0, "avg_logprob": -0.14015734961273474, "compression_ratio": 1.5951417004048583, "no_speech_prob": 0.0003907608042936772}, {"id": 614, "seek": 159594, "start": 1613.66, "end": 1616.02, "text": " and models are quite well-behaved in terms of,", "tokens": [51250, 293, 5245, 366, 1596, 731, 12, 29437, 12865, 294, 2115, 295, 11, 51368], "temperature": 0.0, "avg_logprob": -0.14015734961273474, "compression_ratio": 1.5951417004048583, "no_speech_prob": 0.0003907608042936772}, {"id": 615, "seek": 159594, "start": 1618.7, "end": 1622.02, "text": " if you train them to give up", "tokens": [51502, 498, 291, 3847, 552, 281, 976, 493, 51668], "temperature": 0.0, "avg_logprob": -0.14015734961273474, "compression_ratio": 1.5951417004048583, "no_speech_prob": 0.0003907608042936772}, {"id": 616, "seek": 159594, "start": 1622.02, "end": 1625.22, "text": " and to say, I need to respond, they will.", "tokens": [51668, 293, 281, 584, 11, 286, 643, 281, 4196, 11, 436, 486, 13, 51828], "temperature": 0.0, "avg_logprob": -0.14015734961273474, "compression_ratio": 1.5951417004048583, "no_speech_prob": 0.0003907608042936772}, {"id": 617, "seek": 162594, "start": 1625.94, "end": 1626.94, "text": " They tend to.", "tokens": [50364, 814, 3928, 281, 13, 50414], "temperature": 0.0, "avg_logprob": -0.1568609372837337, "compression_ratio": 1.6366782006920415, "no_speech_prob": 0.0009234483586624265}, {"id": 618, "seek": 162594, "start": 1627.8200000000002, "end": 1629.9, "text": " So I'm not too concerned about like,", "tokens": [50458, 407, 286, 478, 406, 886, 5922, 466, 411, 11, 50562], "temperature": 0.0, "avg_logprob": -0.1568609372837337, "compression_ratio": 1.6366782006920415, "no_speech_prob": 0.0009234483586624265}, {"id": 619, "seek": 162594, "start": 1629.9, "end": 1633.18, "text": " runaway processes that would just not be useful", "tokens": [50562, 1190, 10318, 7555, 300, 576, 445, 406, 312, 4420, 50726], "temperature": 0.0, "avg_logprob": -0.1568609372837337, "compression_ratio": 1.6366782006920415, "no_speech_prob": 0.0009234483586624265}, {"id": 620, "seek": 162594, "start": 1633.18, "end": 1636.18, "text": " as well, hugely computationally expensive.", "tokens": [50726, 382, 731, 11, 27417, 24903, 379, 5124, 13, 50876], "temperature": 0.0, "avg_logprob": -0.1568609372837337, "compression_ratio": 1.6366782006920415, "no_speech_prob": 0.0009234483586624265}, {"id": 621, "seek": 162594, "start": 1636.18, "end": 1639.06, "text": " And yeah, it seems like models can produce stop tokens.", "tokens": [50876, 400, 1338, 11, 309, 2544, 411, 5245, 393, 5258, 1590, 22667, 13, 51020], "temperature": 0.0, "avg_logprob": -0.1568609372837337, "compression_ratio": 1.6366782006920415, "no_speech_prob": 0.0009234483586624265}, {"id": 622, "seek": 162594, "start": 1639.06, "end": 1642.7, "text": " And I think that even in a multi-agent scenario,", "tokens": [51020, 400, 286, 519, 300, 754, 294, 257, 4825, 12, 559, 317, 9005, 11, 51202], "temperature": 0.0, "avg_logprob": -0.1568609372837337, "compression_ratio": 1.6366782006920415, "no_speech_prob": 0.0009234483586624265}, {"id": 623, "seek": 162594, "start": 1644.3400000000001, "end": 1647.38, "text": " discourse between agents will conclude itself", "tokens": [51284, 23938, 1296, 12554, 486, 16886, 2564, 51436], "temperature": 0.0, "avg_logprob": -0.1568609372837337, "compression_ratio": 1.6366782006920415, "no_speech_prob": 0.0009234483586624265}, {"id": 624, "seek": 162594, "start": 1647.38, "end": 1648.54, "text": " in a reasonable amount of time.", "tokens": [51436, 294, 257, 10585, 2372, 295, 565, 13, 51494], "temperature": 0.0, "avg_logprob": -0.1568609372837337, "compression_ratio": 1.6366782006920415, "no_speech_prob": 0.0009234483586624265}, {"id": 625, "seek": 162594, "start": 1648.54, "end": 1649.38, "text": " Yeah, interesting.", "tokens": [51494, 865, 11, 1880, 13, 51536], "temperature": 0.0, "avg_logprob": -0.1568609372837337, "compression_ratio": 1.6366782006920415, "no_speech_prob": 0.0009234483586624265}, {"id": 626, "seek": 162594, "start": 1649.38, "end": 1652.3400000000001, "text": " And I think even now with your multi-step tool use,", "tokens": [51536, 400, 286, 519, 754, 586, 365, 428, 4825, 12, 16792, 2290, 764, 11, 51684], "temperature": 0.0, "avg_logprob": -0.1568609372837337, "compression_ratio": 1.6366782006920415, "no_speech_prob": 0.0009234483586624265}, {"id": 627, "seek": 162594, "start": 1652.3400000000001, "end": 1653.3400000000001, "text": " that's basically what you've done.", "tokens": [51684, 300, 311, 1936, 437, 291, 600, 1096, 13, 51734], "temperature": 0.0, "avg_logprob": -0.1568609372837337, "compression_ratio": 1.6366782006920415, "no_speech_prob": 0.0009234483586624265}, {"id": 628, "seek": 162594, "start": 1653.3400000000001, "end": 1655.42, "text": " You could in principle do that recursively", "tokens": [51734, 509, 727, 294, 8665, 360, 300, 20560, 3413, 51838], "temperature": 0.0, "avg_logprob": -0.1568609372837337, "compression_ratio": 1.6366782006920415, "no_speech_prob": 0.0009234483586624265}, {"id": 629, "seek": 165542, "start": 1655.42, "end": 1657.7, "text": " and you could constrain the computation graph", "tokens": [50364, 293, 291, 727, 1817, 7146, 264, 24903, 4295, 50478], "temperature": 0.0, "avg_logprob": -0.11201347521881559, "compression_ratio": 1.6678966789667897, "no_speech_prob": 0.0002376366319367662}, {"id": 630, "seek": 165542, "start": 1657.7, "end": 1659.0600000000002, "text": " so that there's no cycles", "tokens": [50478, 370, 300, 456, 311, 572, 17796, 50546], "temperature": 0.0, "avg_logprob": -0.11201347521881559, "compression_ratio": 1.6678966789667897, "no_speech_prob": 0.0002376366319367662}, {"id": 631, "seek": 165542, "start": 1659.0600000000002, "end": 1661.3400000000001, "text": " and it comes back in a fixed amount of time.", "tokens": [50546, 293, 309, 1487, 646, 294, 257, 6806, 2372, 295, 565, 13, 50660], "temperature": 0.0, "avg_logprob": -0.11201347521881559, "compression_ratio": 1.6678966789667897, "no_speech_prob": 0.0002376366319367662}, {"id": 632, "seek": 165542, "start": 1661.3400000000001, "end": 1664.0600000000002, "text": " Yeah, we terminate execution", "tokens": [50660, 865, 11, 321, 10761, 473, 15058, 50796], "temperature": 0.0, "avg_logprob": -0.11201347521881559, "compression_ratio": 1.6678966789667897, "no_speech_prob": 0.0002376366319367662}, {"id": 633, "seek": 165542, "start": 1664.0600000000002, "end": 1666.6200000000001, "text": " after some number of failed attempts.", "tokens": [50796, 934, 512, 1230, 295, 7612, 15257, 13, 50924], "temperature": 0.0, "avg_logprob": -0.11201347521881559, "compression_ratio": 1.6678966789667897, "no_speech_prob": 0.0002376366319367662}, {"id": 634, "seek": 165542, "start": 1666.6200000000001, "end": 1668.74, "text": " So it's easy to solve that way.", "tokens": [50924, 407, 309, 311, 1858, 281, 5039, 300, 636, 13, 51030], "temperature": 0.0, "avg_logprob": -0.11201347521881559, "compression_ratio": 1.6678966789667897, "no_speech_prob": 0.0002376366319367662}, {"id": 635, "seek": 165542, "start": 1668.74, "end": 1671.0600000000002, "text": " It's a little bit unsatisfying.", "tokens": [51030, 467, 311, 257, 707, 857, 2693, 25239, 1840, 13, 51146], "temperature": 0.0, "avg_logprob": -0.11201347521881559, "compression_ratio": 1.6678966789667897, "no_speech_prob": 0.0002376366319367662}, {"id": 636, "seek": 165542, "start": 1671.0600000000002, "end": 1673.6200000000001, "text": " I think our multi-optimal use right now,", "tokens": [51146, 286, 519, 527, 4825, 12, 5747, 10650, 764, 558, 586, 11, 51274], "temperature": 0.0, "avg_logprob": -0.11201347521881559, "compression_ratio": 1.6678966789667897, "no_speech_prob": 0.0002376366319367662}, {"id": 637, "seek": 165542, "start": 1673.6200000000001, "end": 1675.0600000000002, "text": " it's our very first pass.", "tokens": [51274, 309, 311, 527, 588, 700, 1320, 13, 51346], "temperature": 0.0, "avg_logprob": -0.11201347521881559, "compression_ratio": 1.6678966789667897, "no_speech_prob": 0.0002376366319367662}, {"id": 638, "seek": 165542, "start": 1675.0600000000002, "end": 1677.18, "text": " It's like the negative one.", "tokens": [51346, 467, 311, 411, 264, 3671, 472, 13, 51452], "temperature": 0.0, "avg_logprob": -0.11201347521881559, "compression_ratio": 1.6678966789667897, "no_speech_prob": 0.0002376366319367662}, {"id": 639, "seek": 165542, "start": 1677.18, "end": 1680.8600000000001, "text": " And so it's not that good at catching", "tokens": [51452, 400, 370, 309, 311, 406, 300, 665, 412, 16124, 51636], "temperature": 0.0, "avg_logprob": -0.11201347521881559, "compression_ratio": 1.6678966789667897, "no_speech_prob": 0.0002376366319367662}, {"id": 640, "seek": 165542, "start": 1680.8600000000001, "end": 1682.0600000000002, "text": " when it's made mistakes.", "tokens": [51636, 562, 309, 311, 1027, 8038, 13, 51696], "temperature": 0.0, "avg_logprob": -0.11201347521881559, "compression_ratio": 1.6678966789667897, "no_speech_prob": 0.0002376366319367662}, {"id": 641, "seek": 165542, "start": 1682.0600000000002, "end": 1684.2, "text": " It's not that good at correcting its mistakes,", "tokens": [51696, 467, 311, 406, 300, 665, 412, 47032, 1080, 8038, 11, 51803], "temperature": 0.0, "avg_logprob": -0.11201347521881559, "compression_ratio": 1.6678966789667897, "no_speech_prob": 0.0002376366319367662}, {"id": 642, "seek": 168420, "start": 1684.2, "end": 1686.32, "text": " even if it's caught that it fucked up.", "tokens": [50364, 754, 498, 309, 311, 5415, 300, 309, 22518, 493, 13, 50470], "temperature": 0.0, "avg_logprob": -0.2161382995875536, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.0008482788689434528}, {"id": 643, "seek": 168420, "start": 1687.3600000000001, "end": 1690.72, "text": " And so I think we're still very early there,", "tokens": [50522, 400, 370, 286, 519, 321, 434, 920, 588, 2440, 456, 11, 50690], "temperature": 0.0, "avg_logprob": -0.2161382995875536, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.0008482788689434528}, {"id": 644, "seek": 168420, "start": 1690.72, "end": 1692.52, "text": " but those systems are gonna start to become", "tokens": [50690, 457, 729, 3652, 366, 799, 722, 281, 1813, 50780], "temperature": 0.0, "avg_logprob": -0.2161382995875536, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.0008482788689434528}, {"id": 645, "seek": 168420, "start": 1692.52, "end": 1696.04, "text": " extremely robust and reliable.", "tokens": [50780, 4664, 13956, 293, 12924, 13, 50956], "temperature": 0.0, "avg_logprob": -0.2161382995875536, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.0008482788689434528}, {"id": 646, "seek": 168420, "start": 1696.04, "end": 1698.16, "text": " And I'm very excited for that.", "tokens": [50956, 400, 286, 478, 588, 2919, 337, 300, 13, 51062], "temperature": 0.0, "avg_logprob": -0.2161382995875536, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.0008482788689434528}, {"id": 647, "seek": 168420, "start": 1698.16, "end": 1699.0, "text": " Amazing.", "tokens": [51062, 14165, 13, 51104], "temperature": 0.0, "avg_logprob": -0.2161382995875536, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.0008482788689434528}, {"id": 648, "seek": 168420, "start": 1699.0, "end": 1704.0, "text": " So I'm interested to know from, in your own words,", "tokens": [51104, 407, 286, 478, 3102, 281, 458, 490, 11, 294, 428, 1065, 2283, 11, 51354], "temperature": 0.0, "avg_logprob": -0.2161382995875536, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.0008482788689434528}, {"id": 649, "seek": 168420, "start": 1704.0, "end": 1707.32, "text": " how, I mean, we're just talking to you folks", "tokens": [51354, 577, 11, 286, 914, 11, 321, 434, 445, 1417, 281, 291, 4024, 51520], "temperature": 0.0, "avg_logprob": -0.2161382995875536, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.0008482788689434528}, {"id": 650, "seek": 168420, "start": 1707.32, "end": 1709.68, "text": " who've got this forward engineering team,", "tokens": [51520, 567, 600, 658, 341, 2128, 7043, 1469, 11, 51638], "temperature": 0.0, "avg_logprob": -0.2161382995875536, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.0008482788689434528}, {"id": 651, "seek": 168420, "start": 1709.68, "end": 1711.3600000000001, "text": " your enterprise focused,", "tokens": [51638, 428, 14132, 5178, 11, 51722], "temperature": 0.0, "avg_logprob": -0.2161382995875536, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.0008482788689434528}, {"id": 652, "seek": 168420, "start": 1711.3600000000001, "end": 1713.56, "text": " you're helping bridge the last mile problem", "tokens": [51722, 291, 434, 4315, 7283, 264, 1036, 12620, 1154, 51832], "temperature": 0.0, "avg_logprob": -0.2161382995875536, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.0008482788689434528}, {"id": 653, "seek": 171356, "start": 1713.56, "end": 1715.9199999999998, "text": " and really embedding yourselves into large enterprise,", "tokens": [50364, 293, 534, 12240, 3584, 14791, 666, 2416, 14132, 11, 50482], "temperature": 0.0, "avg_logprob": -0.17078866733340767, "compression_ratio": 1.6902356902356903, "no_speech_prob": 0.00045771131408400834}, {"id": 654, "seek": 171356, "start": 1715.9199999999998, "end": 1718.28, "text": " which is an amazing differentiator.", "tokens": [50482, 597, 307, 364, 2243, 27372, 1639, 13, 50600], "temperature": 0.0, "avg_logprob": -0.17078866733340767, "compression_ratio": 1.6902356902356903, "no_speech_prob": 0.00045771131408400834}, {"id": 655, "seek": 171356, "start": 1718.28, "end": 1720.6799999999998, "text": " But other than that, there's always the question,", "tokens": [50600, 583, 661, 813, 300, 11, 456, 311, 1009, 264, 1168, 11, 50720], "temperature": 0.0, "avg_logprob": -0.17078866733340767, "compression_ratio": 1.6902356902356903, "no_speech_prob": 0.00045771131408400834}, {"id": 656, "seek": 171356, "start": 1720.6799999999998, "end": 1724.2, "text": " lots of people say these models are just kind of interchangeable", "tokens": [50720, 3195, 295, 561, 584, 613, 5245, 366, 445, 733, 295, 30358, 712, 50896], "temperature": 0.0, "avg_logprob": -0.17078866733340767, "compression_ratio": 1.6902356902356903, "no_speech_prob": 0.00045771131408400834}, {"id": 657, "seek": 171356, "start": 1724.2, "end": 1728.0, "text": " and you're just kind of playing the token game at some point.", "tokens": [50896, 293, 291, 434, 445, 733, 295, 2433, 264, 14862, 1216, 412, 512, 935, 13, 51086], "temperature": 0.0, "avg_logprob": -0.17078866733340767, "compression_ratio": 1.6902356902356903, "no_speech_prob": 0.00045771131408400834}, {"id": 658, "seek": 171356, "start": 1728.0, "end": 1730.76, "text": " And I just wondered like, what's your plan there?", "tokens": [51086, 400, 286, 445, 17055, 411, 11, 437, 311, 428, 1393, 456, 30, 51224], "temperature": 0.0, "avg_logprob": -0.17078866733340767, "compression_ratio": 1.6902356902356903, "no_speech_prob": 0.00045771131408400834}, {"id": 659, "seek": 171356, "start": 1730.76, "end": 1732.76, "text": " I agree with that sentiment.", "tokens": [51224, 286, 3986, 365, 300, 16149, 13, 51324], "temperature": 0.0, "avg_logprob": -0.17078866733340767, "compression_ratio": 1.6902356902356903, "no_speech_prob": 0.00045771131408400834}, {"id": 660, "seek": 171356, "start": 1732.76, "end": 1734.8799999999999, "text": " Models are way too similar.", "tokens": [51324, 6583, 1625, 366, 636, 886, 2531, 13, 51430], "temperature": 0.0, "avg_logprob": -0.17078866733340767, "compression_ratio": 1.6902356902356903, "no_speech_prob": 0.00045771131408400834}, {"id": 661, "seek": 171356, "start": 1734.8799999999999, "end": 1737.72, "text": " I think there's going to start to be differentiation", "tokens": [51430, 286, 519, 456, 311, 516, 281, 722, 281, 312, 38902, 51572], "temperature": 0.0, "avg_logprob": -0.17078866733340767, "compression_ratio": 1.6902356902356903, "no_speech_prob": 0.00045771131408400834}, {"id": 662, "seek": 171356, "start": 1737.72, "end": 1738.56, "text": " between models.", "tokens": [51572, 1296, 5245, 13, 51614], "temperature": 0.0, "avg_logprob": -0.17078866733340767, "compression_ratio": 1.6902356902356903, "no_speech_prob": 0.00045771131408400834}, {"id": 663, "seek": 171356, "start": 1738.56, "end": 1742.72, "text": " Like I was talking about before with command R and R plus,", "tokens": [51614, 1743, 286, 390, 1417, 466, 949, 365, 5622, 497, 293, 497, 1804, 11, 51822], "temperature": 0.0, "avg_logprob": -0.17078866733340767, "compression_ratio": 1.6902356902356903, "no_speech_prob": 0.00045771131408400834}, {"id": 664, "seek": 174356, "start": 1743.9199999999998, "end": 1748.48, "text": " we're going to start really focusing in on key capabilities.", "tokens": [50382, 321, 434, 516, 281, 722, 534, 8416, 294, 322, 2141, 10862, 13, 50610], "temperature": 0.0, "avg_logprob": -0.1263612316500756, "compression_ratio": 1.740909090909091, "no_speech_prob": 0.00039188313530758023}, {"id": 665, "seek": 174356, "start": 1748.48, "end": 1752.04, "text": " The general language model game is,", "tokens": [50610, 440, 2674, 2856, 2316, 1216, 307, 11, 50788], "temperature": 0.0, "avg_logprob": -0.1263612316500756, "compression_ratio": 1.740909090909091, "no_speech_prob": 0.00039188313530758023}, {"id": 666, "seek": 174356, "start": 1753.0, "end": 1756.6799999999998, "text": " there's a lot of players and it's pretty saturated.", "tokens": [50836, 456, 311, 257, 688, 295, 4150, 293, 309, 311, 1238, 25408, 13, 51020], "temperature": 0.0, "avg_logprob": -0.1263612316500756, "compression_ratio": 1.740909090909091, "no_speech_prob": 0.00039188313530758023}, {"id": 667, "seek": 174356, "start": 1758.8799999999999, "end": 1761.48, "text": " I think people are gonna start to have to branch out.", "tokens": [51130, 286, 519, 561, 366, 799, 722, 281, 362, 281, 9819, 484, 13, 51260], "temperature": 0.0, "avg_logprob": -0.1263612316500756, "compression_ratio": 1.740909090909091, "no_speech_prob": 0.00039188313530758023}, {"id": 668, "seek": 174356, "start": 1761.48, "end": 1764.24, "text": " I think that consumer language models", "tokens": [51260, 286, 519, 300, 9711, 2856, 5245, 51398], "temperature": 0.0, "avg_logprob": -0.1263612316500756, "compression_ratio": 1.740909090909091, "no_speech_prob": 0.00039188313530758023}, {"id": 669, "seek": 174356, "start": 1764.24, "end": 1767.0, "text": " are going to separate away from enterprise language models.", "tokens": [51398, 366, 516, 281, 4994, 1314, 490, 14132, 2856, 5245, 13, 51536], "temperature": 0.0, "avg_logprob": -0.1263612316500756, "compression_ratio": 1.740909090909091, "no_speech_prob": 0.00039188313530758023}, {"id": 670, "seek": 174356, "start": 1767.0, "end": 1769.32, "text": " Within enterprise, there's gonna be a lot of specialization", "tokens": [51536, 15996, 14132, 11, 456, 311, 799, 312, 257, 688, 295, 2121, 2144, 51652], "temperature": 0.0, "avg_logprob": -0.1263612316500756, "compression_ratio": 1.740909090909091, "no_speech_prob": 0.00039188313530758023}, {"id": 671, "seek": 174356, "start": 1769.32, "end": 1771.1, "text": " into specific domains.", "tokens": [51652, 666, 2685, 25514, 13, 51741], "temperature": 0.0, "avg_logprob": -0.1263612316500756, "compression_ratio": 1.740909090909091, "no_speech_prob": 0.00039188313530758023}, {"id": 672, "seek": 177110, "start": 1771.6599999999999, "end": 1775.5, "text": " And so for Cohere, what I want to see us do", "tokens": [50392, 400, 370, 337, 3066, 6703, 11, 437, 286, 528, 281, 536, 505, 360, 50584], "temperature": 0.0, "avg_logprob": -0.1401149461854179, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00045823512482456863}, {"id": 673, "seek": 177110, "start": 1775.5, "end": 1780.5, "text": " is in product space, push into more tailored capabilities", "tokens": [50584, 307, 294, 1674, 1901, 11, 2944, 666, 544, 34858, 10862, 50834], "temperature": 0.0, "avg_logprob": -0.1401149461854179, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00045823512482456863}, {"id": 674, "seek": 177110, "start": 1781.34, "end": 1782.74, "text": " for particular problems.", "tokens": [50876, 337, 1729, 2740, 13, 50946], "temperature": 0.0, "avg_logprob": -0.1401149461854179, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00045823512482456863}, {"id": 675, "seek": 177110, "start": 1784.74, "end": 1786.98, "text": " We want to drive value for enterprise", "tokens": [51046, 492, 528, 281, 3332, 2158, 337, 14132, 51158], "temperature": 0.0, "avg_logprob": -0.1401149461854179, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00045823512482456863}, {"id": 676, "seek": 177110, "start": 1786.98, "end": 1789.34, "text": " and different enterprises operated in different spaces", "tokens": [51158, 293, 819, 29034, 20826, 294, 819, 7673, 51276], "temperature": 0.0, "avg_logprob": -0.1401149461854179, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00045823512482456863}, {"id": 677, "seek": 177110, "start": 1789.34, "end": 1790.34, "text": " and they have different needs.", "tokens": [51276, 293, 436, 362, 819, 2203, 13, 51326], "temperature": 0.0, "avg_logprob": -0.1401149461854179, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00045823512482456863}, {"id": 678, "seek": 177110, "start": 1790.34, "end": 1792.26, "text": " The tools that their models might need to use", "tokens": [51326, 440, 3873, 300, 641, 5245, 1062, 643, 281, 764, 51422], "temperature": 0.0, "avg_logprob": -0.1401149461854179, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00045823512482456863}, {"id": 679, "seek": 177110, "start": 1792.26, "end": 1794.4599999999998, "text": " look very different from one another.", "tokens": [51422, 574, 588, 819, 490, 472, 1071, 13, 51532], "temperature": 0.0, "avg_logprob": -0.1401149461854179, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00045823512482456863}, {"id": 680, "seek": 177110, "start": 1794.4599999999998, "end": 1796.1799999999998, "text": " And we want to make sure that we're serving", "tokens": [51532, 400, 321, 528, 281, 652, 988, 300, 321, 434, 8148, 51618], "temperature": 0.0, "avg_logprob": -0.1401149461854179, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00045823512482456863}, {"id": 681, "seek": 177110, "start": 1796.1799999999998, "end": 1800.1399999999999, "text": " each of those niches particularly well or uniquely well.", "tokens": [51618, 1184, 295, 729, 25570, 279, 4098, 731, 420, 31474, 731, 13, 51816], "temperature": 0.0, "avg_logprob": -0.1401149461854179, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.00045823512482456863}, {"id": 682, "seek": 180014, "start": 1800.14, "end": 1801.8200000000002, "text": " And that will be our value proposition", "tokens": [50364, 400, 300, 486, 312, 527, 2158, 24830, 50448], "temperature": 0.0, "avg_logprob": -0.12840278395291033, "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.00013549800496548414}, {"id": 683, "seek": 180014, "start": 1801.8200000000002, "end": 1803.38, "text": " differentiated from others.", "tokens": [50448, 27372, 770, 490, 2357, 13, 50526], "temperature": 0.0, "avg_logprob": -0.12840278395291033, "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.00013549800496548414}, {"id": 684, "seek": 180014, "start": 1805.1000000000001, "end": 1809.18, "text": " So that notion of specialization", "tokens": [50612, 407, 300, 10710, 295, 2121, 2144, 50816], "temperature": 0.0, "avg_logprob": -0.12840278395291033, "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.00013549800496548414}, {"id": 685, "seek": 180014, "start": 1809.18, "end": 1812.42, "text": " or enhanced capability in particular domains", "tokens": [50816, 420, 21191, 13759, 294, 1729, 25514, 50978], "temperature": 0.0, "avg_logprob": -0.12840278395291033, "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.00013549800496548414}, {"id": 686, "seek": 180014, "start": 1812.42, "end": 1814.66, "text": " is something that we definitely want to explore", "tokens": [50978, 307, 746, 300, 321, 2138, 528, 281, 6839, 51090], "temperature": 0.0, "avg_logprob": -0.12840278395291033, "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.00013549800496548414}, {"id": 687, "seek": 180014, "start": 1814.66, "end": 1817.46, "text": " at the product level and start to offer.", "tokens": [51090, 412, 264, 1674, 1496, 293, 722, 281, 2626, 13, 51230], "temperature": 0.0, "avg_logprob": -0.12840278395291033, "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.00013549800496548414}, {"id": 688, "seek": 180014, "start": 1817.46, "end": 1820.5800000000002, "text": " Because like you say, the dollar per token space,", "tokens": [51230, 1436, 411, 291, 584, 11, 264, 7241, 680, 14862, 1901, 11, 51386], "temperature": 0.0, "avg_logprob": -0.12840278395291033, "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.00013549800496548414}, {"id": 689, "seek": 180014, "start": 1820.5800000000002, "end": 1823.1000000000001, "text": " it's super, we're not gonna stop that.", "tokens": [51386, 309, 311, 1687, 11, 321, 434, 406, 799, 1590, 300, 13, 51512], "temperature": 0.0, "avg_logprob": -0.12840278395291033, "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.00013549800496548414}, {"id": 690, "seek": 180014, "start": 1823.1000000000001, "end": 1824.8200000000002, "text": " It's important for the community, right?", "tokens": [51512, 467, 311, 1021, 337, 264, 1768, 11, 558, 30, 51598], "temperature": 0.0, "avg_logprob": -0.12840278395291033, "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.00013549800496548414}, {"id": 691, "seek": 180014, "start": 1824.8200000000002, "end": 1826.6200000000001, "text": " Like folks need to build on top of this.", "tokens": [51598, 1743, 4024, 643, 281, 1322, 322, 1192, 295, 341, 13, 51688], "temperature": 0.0, "avg_logprob": -0.12840278395291033, "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.00013549800496548414}, {"id": 692, "seek": 180014, "start": 1826.6200000000001, "end": 1829.74, "text": " They need access to good models at fair prices.", "tokens": [51688, 814, 643, 2105, 281, 665, 5245, 412, 3143, 7901, 13, 51844], "temperature": 0.0, "avg_logprob": -0.12840278395291033, "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.00013549800496548414}, {"id": 693, "seek": 182974, "start": 1829.98, "end": 1833.34, "text": " So we're gonna continue to give that to the world.", "tokens": [50376, 407, 321, 434, 799, 2354, 281, 976, 300, 281, 264, 1002, 13, 50544], "temperature": 0.0, "avg_logprob": -0.1558992838122181, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.0004829632234759629}, {"id": 694, "seek": 182974, "start": 1834.78, "end": 1836.94, "text": " But we want to create differentiated value.", "tokens": [50616, 583, 321, 528, 281, 1884, 27372, 770, 2158, 13, 50724], "temperature": 0.0, "avg_logprob": -0.1558992838122181, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.0004829632234759629}, {"id": 695, "seek": 182974, "start": 1836.94, "end": 1839.22, "text": " And I think that's gonna come from focusing on", "tokens": [50724, 400, 286, 519, 300, 311, 799, 808, 490, 8416, 322, 50838], "temperature": 0.0, "avg_logprob": -0.1558992838122181, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.0004829632234759629}, {"id": 696, "seek": 182974, "start": 1839.22, "end": 1842.22, "text": " the actual problems that enterprises want to tackle", "tokens": [50838, 264, 3539, 2740, 300, 29034, 528, 281, 14896, 50988], "temperature": 0.0, "avg_logprob": -0.1558992838122181, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.0004829632234759629}, {"id": 697, "seek": 182974, "start": 1842.22, "end": 1845.14, "text": " and getting extremely, extremely good at them.", "tokens": [50988, 293, 1242, 4664, 11, 4664, 665, 412, 552, 13, 51134], "temperature": 0.0, "avg_logprob": -0.1558992838122181, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.0004829632234759629}, {"id": 698, "seek": 182974, "start": 1845.14, "end": 1845.98, "text": " Interesting.", "tokens": [51134, 14711, 13, 51176], "temperature": 0.0, "avg_logprob": -0.1558992838122181, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.0004829632234759629}, {"id": 699, "seek": 182974, "start": 1845.98, "end": 1850.9, "text": " On that, are you planning kind of horizontal products", "tokens": [51176, 1282, 300, 11, 366, 291, 5038, 733, 295, 12750, 3383, 51422], "temperature": 0.0, "avg_logprob": -0.1558992838122181, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.0004829632234759629}, {"id": 700, "seek": 182974, "start": 1850.9, "end": 1852.34, "text": " or vertical products?", "tokens": [51422, 420, 9429, 3383, 30, 51494], "temperature": 0.0, "avg_logprob": -0.1558992838122181, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.0004829632234759629}, {"id": 701, "seek": 182974, "start": 1852.34, "end": 1856.82, "text": " And the reason I say horizontal is I know a few startups now", "tokens": [51494, 400, 264, 1778, 286, 584, 12750, 307, 286, 458, 257, 1326, 28041, 586, 51718], "temperature": 0.0, "avg_logprob": -0.1558992838122181, "compression_ratio": 1.6182572614107884, "no_speech_prob": 0.0004829632234759629}, {"id": 702, "seek": 185682, "start": 1856.86, "end": 1860.06, "text": " that are building kind of low code,", "tokens": [50366, 300, 366, 2390, 733, 295, 2295, 3089, 11, 50526], "temperature": 0.0, "avg_logprob": -0.12371993064880371, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.00036630925023928285}, {"id": 703, "seek": 185682, "start": 1860.06, "end": 1862.4199999999998, "text": " app dev platforms with large language models", "tokens": [50526, 724, 1905, 9473, 365, 2416, 2856, 5245, 50644], "temperature": 0.0, "avg_logprob": -0.12371993064880371, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.00036630925023928285}, {"id": 704, "seek": 185682, "start": 1862.4199999999998, "end": 1864.58, "text": " and they're making it incredibly easy in the enterprise", "tokens": [50644, 293, 436, 434, 1455, 309, 6252, 1858, 294, 264, 14132, 50752], "temperature": 0.0, "avg_logprob": -0.12371993064880371, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.00036630925023928285}, {"id": 705, "seek": 185682, "start": 1864.58, "end": 1866.74, "text": " to compose together different models", "tokens": [50752, 281, 35925, 1214, 819, 5245, 50860], "temperature": 0.0, "avg_logprob": -0.12371993064880371, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.00036630925023928285}, {"id": 706, "seek": 185682, "start": 1866.74, "end": 1868.8999999999999, "text": " and to deploy applications on phones.", "tokens": [50860, 293, 281, 7274, 5821, 322, 10216, 13, 50968], "temperature": 0.0, "avg_logprob": -0.12371993064880371, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.00036630925023928285}, {"id": 707, "seek": 185682, "start": 1868.8999999999999, "end": 1872.6599999999999, "text": " And it's really democratized because it's so much easier", "tokens": [50968, 400, 309, 311, 534, 37221, 1602, 570, 309, 311, 370, 709, 3571, 51156], "temperature": 0.0, "avg_logprob": -0.12371993064880371, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.00036630925023928285}, {"id": 708, "seek": 185682, "start": 1872.6599999999999, "end": 1874.58, "text": " now for people to do artificial intelligence.", "tokens": [51156, 586, 337, 561, 281, 360, 11677, 7599, 13, 51252], "temperature": 0.0, "avg_logprob": -0.12371993064880371, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.00036630925023928285}, {"id": 709, "seek": 185682, "start": 1874.58, "end": 1877.82, "text": " That would be a good example of like a horizontal one, I guess.", "tokens": [51252, 663, 576, 312, 257, 665, 1365, 295, 411, 257, 12750, 472, 11, 286, 2041, 13, 51414], "temperature": 0.0, "avg_logprob": -0.12371993064880371, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.00036630925023928285}, {"id": 710, "seek": 185682, "start": 1877.82, "end": 1880.82, "text": " So I think our product right now is super horizontal, right?", "tokens": [51414, 407, 286, 519, 527, 1674, 558, 586, 307, 1687, 12750, 11, 558, 30, 51564], "temperature": 0.0, "avg_logprob": -0.12371993064880371, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.00036630925023928285}, {"id": 711, "seek": 185682, "start": 1880.82, "end": 1882.82, "text": " It's like general language models, embedding models,", "tokens": [51564, 467, 311, 411, 2674, 2856, 5245, 11, 12240, 3584, 5245, 11, 51664], "temperature": 0.0, "avg_logprob": -0.12371993064880371, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.00036630925023928285}, {"id": 712, "seek": 185682, "start": 1882.82, "end": 1883.6599999999999, "text": " re-rank models.", "tokens": [51664, 319, 12, 20479, 5245, 13, 51706], "temperature": 0.0, "avg_logprob": -0.12371993064880371, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.00036630925023928285}, {"id": 713, "seek": 185682, "start": 1883.6599999999999, "end": 1886.02, "text": " It's a platform that's deployable privately", "tokens": [51706, 467, 311, 257, 3663, 300, 311, 7274, 712, 31919, 51824], "temperature": 0.0, "avg_logprob": -0.12371993064880371, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.00036630925023928285}, {"id": 714, "seek": 188602, "start": 1886.02, "end": 1887.98, "text": " on every single cloud.", "tokens": [50364, 322, 633, 2167, 4588, 13, 50462], "temperature": 0.0, "avg_logprob": -0.1124204593700367, "compression_ratio": 1.55793991416309, "no_speech_prob": 0.0002165063051506877}, {"id": 715, "seek": 188602, "start": 1887.98, "end": 1891.46, "text": " You can deploy the model against any sort of data,", "tokens": [50462, 509, 393, 7274, 264, 2316, 1970, 604, 1333, 295, 1412, 11, 50636], "temperature": 0.0, "avg_logprob": -0.1124204593700367, "compression_ratio": 1.55793991416309, "no_speech_prob": 0.0002165063051506877}, {"id": 716, "seek": 188602, "start": 1891.46, "end": 1895.54, "text": " whether it's medical, finance, legal, it doesn't matter.", "tokens": [50636, 1968, 309, 311, 4625, 11, 10719, 11, 5089, 11, 309, 1177, 380, 1871, 13, 50840], "temperature": 0.0, "avg_logprob": -0.1124204593700367, "compression_ratio": 1.55793991416309, "no_speech_prob": 0.0002165063051506877}, {"id": 717, "seek": 188602, "start": 1895.54, "end": 1900.54, "text": " It's the most horizontal product and platform you can build.", "tokens": [50840, 467, 311, 264, 881, 12750, 1674, 293, 3663, 291, 393, 1322, 13, 51090], "temperature": 0.0, "avg_logprob": -0.1124204593700367, "compression_ratio": 1.55793991416309, "no_speech_prob": 0.0002165063051506877}, {"id": 718, "seek": 188602, "start": 1901.66, "end": 1904.02, "text": " What we're gonna start to do is more", "tokens": [51146, 708, 321, 434, 799, 722, 281, 360, 307, 544, 51264], "temperature": 0.0, "avg_logprob": -0.1124204593700367, "compression_ratio": 1.55793991416309, "no_speech_prob": 0.0002165063051506877}, {"id": 719, "seek": 188602, "start": 1904.02, "end": 1907.82, "text": " towards verticalization and so specializing models", "tokens": [51264, 3030, 9429, 2144, 293, 370, 2121, 3319, 5245, 51454], "temperature": 0.0, "avg_logprob": -0.1124204593700367, "compression_ratio": 1.55793991416309, "no_speech_prob": 0.0002165063051506877}, {"id": 720, "seek": 188602, "start": 1907.82, "end": 1911.06, "text": " at particular problems or objectives", "tokens": [51454, 412, 1729, 2740, 420, 15961, 51616], "temperature": 0.0, "avg_logprob": -0.1124204593700367, "compression_ratio": 1.55793991416309, "no_speech_prob": 0.0002165063051506877}, {"id": 721, "seek": 188602, "start": 1911.06, "end": 1915.1, "text": " that exist in the world and offering a product", "tokens": [51616, 300, 2514, 294, 264, 1002, 293, 8745, 257, 1674, 51818], "temperature": 0.0, "avg_logprob": -0.1124204593700367, "compression_ratio": 1.55793991416309, "no_speech_prob": 0.0002165063051506877}, {"id": 722, "seek": 191510, "start": 1915.1, "end": 1917.06, "text": " that solves that for the enterprise.", "tokens": [50364, 300, 39890, 300, 337, 264, 14132, 13, 50462], "temperature": 0.0, "avg_logprob": -0.1189334727515859, "compression_ratio": 1.6779026217228465, "no_speech_prob": 0.0006923057953827083}, {"id": 723, "seek": 191510, "start": 1917.06, "end": 1919.2199999999998, "text": " Would you ever go beyond the model", "tokens": [50462, 6068, 291, 1562, 352, 4399, 264, 2316, 50570], "temperature": 0.0, "avg_logprob": -0.1189334727515859, "compression_ratio": 1.6779026217228465, "no_speech_prob": 0.0006923057953827083}, {"id": 724, "seek": 191510, "start": 1919.2199999999998, "end": 1921.58, "text": " and kind of plug a little bit deeper", "tokens": [50570, 293, 733, 295, 5452, 257, 707, 857, 7731, 50688], "temperature": 0.0, "avg_logprob": -0.1189334727515859, "compression_ratio": 1.6779026217228465, "no_speech_prob": 0.0006923057953827083}, {"id": 725, "seek": 191510, "start": 1921.58, "end": 1923.1799999999998, "text": " into the platform in the enterprise?", "tokens": [50688, 666, 264, 3663, 294, 264, 14132, 30, 50768], "temperature": 0.0, "avg_logprob": -0.1189334727515859, "compression_ratio": 1.6779026217228465, "no_speech_prob": 0.0006923057953827083}, {"id": 726, "seek": 191510, "start": 1923.1799999999998, "end": 1926.58, "text": " So for example, building operating models", "tokens": [50768, 407, 337, 1365, 11, 2390, 7447, 5245, 50938], "temperature": 0.0, "avg_logprob": -0.1189334727515859, "compression_ratio": 1.6779026217228465, "no_speech_prob": 0.0006923057953827083}, {"id": 727, "seek": 191510, "start": 1926.58, "end": 1930.78, "text": " or one approach would be to just fine-tune the model", "tokens": [50938, 420, 472, 3109, 576, 312, 281, 445, 2489, 12, 83, 2613, 264, 2316, 51148], "temperature": 0.0, "avg_logprob": -0.1189334727515859, "compression_ratio": 1.6779026217228465, "no_speech_prob": 0.0006923057953827083}, {"id": 728, "seek": 191510, "start": 1930.78, "end": 1932.62, "text": " on lots of data from a particular domain,", "tokens": [51148, 322, 3195, 295, 1412, 490, 257, 1729, 9274, 11, 51240], "temperature": 0.0, "avg_logprob": -0.1189334727515859, "compression_ratio": 1.6779026217228465, "no_speech_prob": 0.0006923057953827083}, {"id": 729, "seek": 191510, "start": 1932.62, "end": 1934.26, "text": " but it's still a language model.", "tokens": [51240, 457, 309, 311, 920, 257, 2856, 2316, 13, 51322], "temperature": 0.0, "avg_logprob": -0.1189334727515859, "compression_ratio": 1.6779026217228465, "no_speech_prob": 0.0006923057953827083}, {"id": 730, "seek": 191510, "start": 1934.26, "end": 1936.1799999999998, "text": " The interface with Coheir is the same", "tokens": [51322, 440, 9226, 365, 3066, 675, 347, 307, 264, 912, 51418], "temperature": 0.0, "avg_logprob": -0.1189334727515859, "compression_ratio": 1.6779026217228465, "no_speech_prob": 0.0006923057953827083}, {"id": 731, "seek": 191510, "start": 1936.1799999999998, "end": 1939.8999999999999, "text": " or another one would be to let's say build", "tokens": [51418, 420, 1071, 472, 576, 312, 281, 718, 311, 584, 1322, 51604], "temperature": 0.0, "avg_logprob": -0.1189334727515859, "compression_ratio": 1.6779026217228465, "no_speech_prob": 0.0006923057953827083}, {"id": 732, "seek": 191510, "start": 1939.8999999999999, "end": 1942.4599999999998, "text": " something a little bit like Databricks or Snowflake", "tokens": [51604, 746, 257, 707, 857, 411, 40461, 81, 7663, 420, 14827, 3423, 619, 51732], "temperature": 0.0, "avg_logprob": -0.1189334727515859, "compression_ratio": 1.6779026217228465, "no_speech_prob": 0.0006923057953827083}, {"id": 733, "seek": 194246, "start": 1942.5, "end": 1945.82, "text": " or something like an enterprise-wide suite", "tokens": [50366, 420, 746, 411, 364, 14132, 12, 7990, 14205, 50532], "temperature": 0.0, "avg_logprob": -0.10551262738411887, "compression_ratio": 1.6526717557251909, "no_speech_prob": 0.009677150286734104}, {"id": 734, "seek": 194246, "start": 1945.82, "end": 1949.9, "text": " that allows you to deploy, discover, create, share", "tokens": [50532, 300, 4045, 291, 281, 7274, 11, 4411, 11, 1884, 11, 2073, 50736], "temperature": 0.0, "avg_logprob": -0.10551262738411887, "compression_ratio": 1.6526717557251909, "no_speech_prob": 0.009677150286734104}, {"id": 735, "seek": 194246, "start": 1949.9, "end": 1952.06, "text": " artificial intelligence in an enterprise.", "tokens": [50736, 11677, 7599, 294, 364, 14132, 13, 50844], "temperature": 0.0, "avg_logprob": -0.10551262738411887, "compression_ratio": 1.6526717557251909, "no_speech_prob": 0.009677150286734104}, {"id": 736, "seek": 194246, "start": 1952.06, "end": 1955.78, "text": " The only reason I say that is as you're an AWS,", "tokens": [50844, 440, 787, 1778, 286, 584, 300, 307, 382, 291, 434, 364, 17650, 11, 51030], "temperature": 0.0, "avg_logprob": -0.10551262738411887, "compression_ratio": 1.6526717557251909, "no_speech_prob": 0.009677150286734104}, {"id": 737, "seek": 194246, "start": 1955.78, "end": 1957.78, "text": " they give you free credits.", "tokens": [51030, 436, 976, 291, 1737, 16816, 13, 51130], "temperature": 0.0, "avg_logprob": -0.10551262738411887, "compression_ratio": 1.6526717557251909, "no_speech_prob": 0.009677150286734104}, {"id": 738, "seek": 194246, "start": 1957.78, "end": 1959.9, "text": " They want you to get on their platform", "tokens": [51130, 814, 528, 291, 281, 483, 322, 641, 3663, 51236], "temperature": 0.0, "avg_logprob": -0.10551262738411887, "compression_ratio": 1.6526717557251909, "no_speech_prob": 0.009677150286734104}, {"id": 739, "seek": 194246, "start": 1959.9, "end": 1961.78, "text": " because they know you're never leaving", "tokens": [51236, 570, 436, 458, 291, 434, 1128, 5012, 51330], "temperature": 0.0, "avg_logprob": -0.10551262738411887, "compression_ratio": 1.6526717557251909, "no_speech_prob": 0.009677150286734104}, {"id": 740, "seek": 194246, "start": 1961.78, "end": 1964.18, "text": " because you've got something there", "tokens": [51330, 570, 291, 600, 658, 746, 456, 51450], "temperature": 0.0, "avg_logprob": -0.10551262738411887, "compression_ratio": 1.6526717557251909, "no_speech_prob": 0.009677150286734104}, {"id": 741, "seek": 194246, "start": 1964.18, "end": 1966.1000000000001, "text": " which is not easily replaceable.", "tokens": [51450, 597, 307, 406, 3612, 7406, 712, 13, 51546], "temperature": 0.0, "avg_logprob": -0.10551262738411887, "compression_ratio": 1.6526717557251909, "no_speech_prob": 0.009677150286734104}, {"id": 742, "seek": 194246, "start": 1966.1000000000001, "end": 1968.54, "text": " People learn how to use it, they love it.", "tokens": [51546, 3432, 1466, 577, 281, 764, 309, 11, 436, 959, 309, 13, 51668], "temperature": 0.0, "avg_logprob": -0.10551262738411887, "compression_ratio": 1.6526717557251909, "no_speech_prob": 0.009677150286734104}, {"id": 743, "seek": 194246, "start": 1968.54, "end": 1969.98, "text": " Would that be a potential future?", "tokens": [51668, 6068, 300, 312, 257, 3995, 2027, 30, 51740], "temperature": 0.0, "avg_logprob": -0.10551262738411887, "compression_ratio": 1.6526717557251909, "no_speech_prob": 0.009677150286734104}, {"id": 744, "seek": 196998, "start": 1969.98, "end": 1974.46, "text": " Yeah, it's definitely still going to be a platform,", "tokens": [50364, 865, 11, 309, 311, 2138, 920, 516, 281, 312, 257, 3663, 11, 50588], "temperature": 0.0, "avg_logprob": -0.10302658989315941, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.00014878738147672266}, {"id": 745, "seek": 196998, "start": 1974.46, "end": 1977.06, "text": " customizable, something that the user,", "tokens": [50588, 47922, 11, 746, 300, 264, 4195, 11, 50718], "temperature": 0.0, "avg_logprob": -0.10302658989315941, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.00014878738147672266}, {"id": 746, "seek": 196998, "start": 1977.06, "end": 1979.22, "text": " which for us as an enterprise can adopt", "tokens": [50718, 597, 337, 505, 382, 364, 14132, 393, 6878, 50826], "temperature": 0.0, "avg_logprob": -0.10302658989315941, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.00014878738147672266}, {"id": 747, "seek": 196998, "start": 1979.22, "end": 1981.46, "text": " and sort of bring into their environment,", "tokens": [50826, 293, 1333, 295, 1565, 666, 641, 2823, 11, 50938], "temperature": 0.0, "avg_logprob": -0.10302658989315941, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.00014878738147672266}, {"id": 748, "seek": 196998, "start": 1981.46, "end": 1984.66, "text": " hook in their data, their tools,", "tokens": [50938, 6328, 294, 641, 1412, 11, 641, 3873, 11, 51098], "temperature": 0.0, "avg_logprob": -0.10302658989315941, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.00014878738147672266}, {"id": 749, "seek": 196998, "start": 1984.66, "end": 1987.82, "text": " their whatever they want to plug in.", "tokens": [51098, 641, 2035, 436, 528, 281, 5452, 294, 13, 51256], "temperature": 0.0, "avg_logprob": -0.10302658989315941, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.00014878738147672266}, {"id": 750, "seek": 196998, "start": 1987.82, "end": 1990.9, "text": " The verticalization is gonna come from", "tokens": [51256, 440, 9429, 2144, 307, 799, 808, 490, 51410], "temperature": 0.0, "avg_logprob": -0.10302658989315941, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.00014878738147672266}, {"id": 751, "seek": 196998, "start": 1990.9, "end": 1992.78, "text": " investing in the model to be good", "tokens": [51410, 10978, 294, 264, 2316, 281, 312, 665, 51504], "temperature": 0.0, "avg_logprob": -0.10302658989315941, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.00014878738147672266}, {"id": 752, "seek": 196998, "start": 1992.78, "end": 1994.3, "text": " within a particular domain.", "tokens": [51504, 1951, 257, 1729, 9274, 13, 51580], "temperature": 0.0, "avg_logprob": -0.10302658989315941, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.00014878738147672266}, {"id": 753, "seek": 196998, "start": 1994.3, "end": 1996.9, "text": " That might mean fine-tuning on data within that domain.", "tokens": [51580, 663, 1062, 914, 2489, 12, 83, 37726, 322, 1412, 1951, 300, 9274, 13, 51710], "temperature": 0.0, "avg_logprob": -0.10302658989315941, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.00014878738147672266}, {"id": 754, "seek": 199690, "start": 1996.9, "end": 2000.5, "text": " That might mean making sure the model is very good", "tokens": [50364, 663, 1062, 914, 1455, 988, 264, 2316, 307, 588, 665, 50544], "temperature": 0.0, "avg_logprob": -0.14984982284073978, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.0006456321571022272}, {"id": 755, "seek": 199690, "start": 2000.5, "end": 2003.7, "text": " at using the tools that employees operating", "tokens": [50544, 412, 1228, 264, 3873, 300, 6619, 7447, 50704], "temperature": 0.0, "avg_logprob": -0.14984982284073978, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.0006456321571022272}, {"id": 756, "seek": 199690, "start": 2003.7, "end": 2005.14, "text": " in that domain would use.", "tokens": [50704, 294, 300, 9274, 576, 764, 13, 50776], "temperature": 0.0, "avg_logprob": -0.14984982284073978, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.0006456321571022272}, {"id": 757, "seek": 199690, "start": 2005.14, "end": 2005.98, "text": " But that's our focus.", "tokens": [50776, 583, 300, 311, 527, 1879, 13, 50818], "temperature": 0.0, "avg_logprob": -0.14984982284073978, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.0006456321571022272}, {"id": 758, "seek": 199690, "start": 2005.98, "end": 2007.66, "text": " It's starting to get more specific", "tokens": [50818, 467, 311, 2891, 281, 483, 544, 2685, 50902], "temperature": 0.0, "avg_logprob": -0.14984982284073978, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.0006456321571022272}, {"id": 759, "seek": 199690, "start": 2007.66, "end": 2010.42, "text": " and focused on the actual use cases", "tokens": [50902, 293, 5178, 322, 264, 3539, 764, 3331, 51040], "temperature": 0.0, "avg_logprob": -0.14984982284073978, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.0006456321571022272}, {"id": 760, "seek": 199690, "start": 2010.42, "end": 2011.7800000000002, "text": " that enterprises care about", "tokens": [51040, 300, 29034, 1127, 466, 51108], "temperature": 0.0, "avg_logprob": -0.14984982284073978, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.0006456321571022272}, {"id": 761, "seek": 199690, "start": 2011.7800000000002, "end": 2014.42, "text": " and not just doing, you know,", "tokens": [51108, 293, 406, 445, 884, 11, 291, 458, 11, 51240], "temperature": 0.0, "avg_logprob": -0.14984982284073978, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.0006456321571022272}, {"id": 762, "seek": 199690, "start": 2014.42, "end": 2019.42, "text": " version 345 of the same general model.", "tokens": [51240, 3037, 805, 8465, 295, 264, 912, 2674, 2316, 13, 51490], "temperature": 0.0, "avg_logprob": -0.14984982284073978, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.0006456321571022272}, {"id": 763, "seek": 199690, "start": 2022.0600000000002, "end": 2025.22, "text": " So I saw you tweeted about Nick Bostrom's", "tokens": [51622, 407, 286, 1866, 291, 25646, 466, 9449, 363, 555, 4397, 311, 51780], "temperature": 0.0, "avg_logprob": -0.14984982284073978, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.0006456321571022272}, {"id": 764, "seek": 202522, "start": 2025.26, "end": 2028.34, "text": " Future of Humanity Institute shutting down.", "tokens": [50366, 20805, 295, 10294, 507, 9446, 36057, 760, 13, 50520], "temperature": 0.0, "avg_logprob": -0.1469768241599754, "compression_ratio": 1.4741784037558685, "no_speech_prob": 0.001309099025093019}, {"id": 765, "seek": 202522, "start": 2028.34, "end": 2030.06, "text": " Do you have any thoughts on that?", "tokens": [50520, 1144, 291, 362, 604, 4598, 322, 300, 30, 50606], "temperature": 0.0, "avg_logprob": -0.1469768241599754, "compression_ratio": 1.4741784037558685, "no_speech_prob": 0.001309099025093019}, {"id": 766, "seek": 202522, "start": 2031.5, "end": 2034.34, "text": " Yeah, I think it sucks to see", "tokens": [50678, 865, 11, 286, 519, 309, 15846, 281, 536, 50820], "temperature": 0.0, "avg_logprob": -0.1469768241599754, "compression_ratio": 1.4741784037558685, "no_speech_prob": 0.001309099025093019}, {"id": 767, "seek": 202522, "start": 2034.34, "end": 2039.34, "text": " any sort of academic institute collapse.", "tokens": [50820, 604, 1333, 295, 7778, 26860, 15584, 13, 51070], "temperature": 0.0, "avg_logprob": -0.1469768241599754, "compression_ratio": 1.4741784037558685, "no_speech_prob": 0.001309099025093019}, {"id": 768, "seek": 202522, "start": 2040.78, "end": 2043.34, "text": " To be honest, I know nothing more than what's public there.", "tokens": [51142, 1407, 312, 3245, 11, 286, 458, 1825, 544, 813, 437, 311, 1908, 456, 13, 51270], "temperature": 0.0, "avg_logprob": -0.1469768241599754, "compression_ratio": 1.4741784037558685, "no_speech_prob": 0.001309099025093019}, {"id": 769, "seek": 202522, "start": 2043.34, "end": 2046.22, "text": " So I don't know if there were some internal issues", "tokens": [51270, 407, 286, 500, 380, 458, 498, 456, 645, 512, 6920, 2663, 51414], "temperature": 0.0, "avg_logprob": -0.1469768241599754, "compression_ratio": 1.4741784037558685, "no_speech_prob": 0.001309099025093019}, {"id": 770, "seek": 202522, "start": 2046.22, "end": 2050.18, "text": " that caused the philosophy department to pull funding.", "tokens": [51414, 300, 7008, 264, 10675, 5882, 281, 2235, 6137, 13, 51612], "temperature": 0.0, "avg_logprob": -0.1469768241599754, "compression_ratio": 1.4741784037558685, "no_speech_prob": 0.001309099025093019}, {"id": 771, "seek": 205018, "start": 2051.18, "end": 2056.18, "text": " But I've been a pretty vocal critic of ex-risk", "tokens": [50414, 583, 286, 600, 668, 257, 1238, 11657, 7850, 295, 454, 12, 33263, 50664], "temperature": 0.0, "avg_logprob": -0.1310699462890625, "compression_ratio": 1.6908212560386473, "no_speech_prob": 0.0006876904517412186}, {"id": 772, "seek": 205018, "start": 2057.8199999999997, "end": 2062.18, "text": " and the idea that language models are going to", "tokens": [50746, 293, 264, 1558, 300, 2856, 5245, 366, 516, 281, 50964], "temperature": 0.0, "avg_logprob": -0.1310699462890625, "compression_ratio": 1.6908212560386473, "no_speech_prob": 0.0006876904517412186}, {"id": 773, "seek": 205018, "start": 2062.18, "end": 2064.2599999999998, "text": " take over the world and kill everyone.", "tokens": [50964, 747, 670, 264, 1002, 293, 1961, 1518, 13, 51068], "temperature": 0.0, "avg_logprob": -0.1310699462890625, "compression_ratio": 1.6908212560386473, "no_speech_prob": 0.0006876904517412186}, {"id": 774, "seek": 205018, "start": 2065.7, "end": 2068.8199999999997, "text": " But despite that, I still want people thinking about that.", "tokens": [51140, 583, 7228, 300, 11, 286, 920, 528, 561, 1953, 466, 300, 13, 51296], "temperature": 0.0, "avg_logprob": -0.1310699462890625, "compression_ratio": 1.6908212560386473, "no_speech_prob": 0.0006876904517412186}, {"id": 775, "seek": 205018, "start": 2068.8199999999997, "end": 2070.46, "text": " I still want academics thinking about that.", "tokens": [51296, 286, 920, 528, 25695, 1953, 466, 300, 13, 51378], "temperature": 0.0, "avg_logprob": -0.1310699462890625, "compression_ratio": 1.6908212560386473, "no_speech_prob": 0.0006876904517412186}, {"id": 776, "seek": 205018, "start": 2070.46, "end": 2074.1, "text": " I don't think that regulators and policy folks", "tokens": [51378, 286, 500, 380, 519, 300, 37311, 293, 3897, 4024, 51560], "temperature": 0.0, "avg_logprob": -0.1310699462890625, "compression_ratio": 1.6908212560386473, "no_speech_prob": 0.0006876904517412186}, {"id": 777, "seek": 205018, "start": 2074.1, "end": 2075.5, "text": " should be thinking about it yet", "tokens": [51560, 820, 312, 1953, 466, 309, 1939, 51630], "temperature": 0.0, "avg_logprob": -0.1310699462890625, "compression_ratio": 1.6908212560386473, "no_speech_prob": 0.0006876904517412186}, {"id": 778, "seek": 205018, "start": 2075.5, "end": 2077.4199999999996, "text": " because it's so far away and remote", "tokens": [51630, 570, 309, 311, 370, 1400, 1314, 293, 8607, 51726], "temperature": 0.0, "avg_logprob": -0.1310699462890625, "compression_ratio": 1.6908212560386473, "no_speech_prob": 0.0006876904517412186}, {"id": 779, "seek": 207742, "start": 2078.3, "end": 2080.1800000000003, "text": " and potentially completely irrelevant.", "tokens": [50408, 293, 7263, 2584, 28682, 13, 50502], "temperature": 0.0, "avg_logprob": -0.1400237334401984, "compression_ratio": 1.556910569105691, "no_speech_prob": 0.0013246271992102265}, {"id": 780, "seek": 207742, "start": 2080.1800000000003, "end": 2082.54, "text": " But that's the domain of academia,", "tokens": [50502, 583, 300, 311, 264, 9274, 295, 28937, 11, 50620], "temperature": 0.0, "avg_logprob": -0.1400237334401984, "compression_ratio": 1.556910569105691, "no_speech_prob": 0.0013246271992102265}, {"id": 781, "seek": 207742, "start": 2082.54, "end": 2086.06, "text": " is to pursue those long horizon, high risk projects", "tokens": [50620, 307, 281, 12392, 729, 938, 18046, 11, 1090, 3148, 4455, 50796], "temperature": 0.0, "avg_logprob": -0.1400237334401984, "compression_ratio": 1.556910569105691, "no_speech_prob": 0.0013246271992102265}, {"id": 782, "seek": 207742, "start": 2086.06, "end": 2087.06, "text": " and make progress on them.", "tokens": [50796, 293, 652, 4205, 322, 552, 13, 50846], "temperature": 0.0, "avg_logprob": -0.1400237334401984, "compression_ratio": 1.556910569105691, "no_speech_prob": 0.0013246271992102265}, {"id": 783, "seek": 207742, "start": 2087.06, "end": 2090.2200000000003, "text": " And so I certainly don't want to see", "tokens": [50846, 400, 370, 286, 3297, 500, 380, 528, 281, 536, 51004], "temperature": 0.0, "avg_logprob": -0.1400237334401984, "compression_ratio": 1.556910569105691, "no_speech_prob": 0.0013246271992102265}, {"id": 784, "seek": 207742, "start": 2090.2200000000003, "end": 2095.2200000000003, "text": " the academic front of that effort get defunded.", "tokens": [51004, 264, 7778, 1868, 295, 300, 4630, 483, 1060, 997, 292, 13, 51254], "temperature": 0.0, "avg_logprob": -0.1400237334401984, "compression_ratio": 1.556910569105691, "no_speech_prob": 0.0013246271992102265}, {"id": 785, "seek": 207742, "start": 2097.1800000000003, "end": 2099.7400000000002, "text": " That being said, I think that those organizations", "tokens": [51352, 663, 885, 848, 11, 286, 519, 300, 729, 6150, 51480], "temperature": 0.0, "avg_logprob": -0.1400237334401984, "compression_ratio": 1.556910569105691, "no_speech_prob": 0.0013246271992102265}, {"id": 786, "seek": 207742, "start": 2099.7400000000002, "end": 2103.82, "text": " have really been trying to get their hands into policy", "tokens": [51480, 362, 534, 668, 1382, 281, 483, 641, 2377, 666, 3897, 51684], "temperature": 0.0, "avg_logprob": -0.1400237334401984, "compression_ratio": 1.556910569105691, "no_speech_prob": 0.0013246271992102265}, {"id": 787, "seek": 207742, "start": 2103.82, "end": 2107.1, "text": " and impact private sector, public sector", "tokens": [51684, 293, 2712, 4551, 6977, 11, 1908, 6977, 51848], "temperature": 0.0, "avg_logprob": -0.1400237334401984, "compression_ratio": 1.556910569105691, "no_speech_prob": 0.0013246271992102265}, {"id": 788, "seek": 210710, "start": 2107.1, "end": 2110.74, "text": " in a way that is threatening to progress,", "tokens": [50364, 294, 257, 636, 300, 307, 20768, 281, 4205, 11, 50546], "temperature": 0.0, "avg_logprob": -0.24535078160903034, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.0002340090140933171}, {"id": 789, "seek": 210710, "start": 2111.9, "end": 2116.9, "text": " misleading and so I think that we're starting", "tokens": [50604, 36429, 293, 370, 286, 519, 300, 321, 434, 2891, 50854], "temperature": 0.0, "avg_logprob": -0.24535078160903034, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.0002340090140933171}, {"id": 790, "seek": 210710, "start": 2119.2599999999998, "end": 2120.86, "text": " to have within our community,", "tokens": [50972, 281, 362, 1951, 527, 1768, 11, 51052], "temperature": 0.0, "avg_logprob": -0.24535078160903034, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.0002340090140933171}, {"id": 791, "seek": 210710, "start": 2120.86, "end": 2123.2999999999997, "text": " like the AI machine learning community,", "tokens": [51052, 411, 264, 7318, 3479, 2539, 1768, 11, 51174], "temperature": 0.0, "avg_logprob": -0.24535078160903034, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.0002340090140933171}, {"id": 792, "seek": 210710, "start": 2123.2999999999997, "end": 2124.54, "text": " a bit of a correction.", "tokens": [51174, 257, 857, 295, 257, 19984, 13, 51236], "temperature": 0.0, "avg_logprob": -0.24535078160903034, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.0002340090140933171}, {"id": 793, "seek": 210710, "start": 2125.46, "end": 2127.58, "text": " Those people were kind of given a lot of power,", "tokens": [51282, 3950, 561, 645, 733, 295, 2212, 257, 688, 295, 1347, 11, 51388], "temperature": 0.0, "avg_logprob": -0.24535078160903034, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.0002340090140933171}, {"id": 794, "seek": 210710, "start": 2127.58, "end": 2128.86, "text": " were listened to a lot", "tokens": [51388, 645, 13207, 281, 257, 688, 51452], "temperature": 0.0, "avg_logprob": -0.24535078160903034, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.0002340090140933171}, {"id": 795, "seek": 210710, "start": 2130.7799999999997, "end": 2134.14, "text": " and developed what I think we all", "tokens": [51548, 293, 4743, 437, 286, 519, 321, 439, 51716], "temperature": 0.0, "avg_logprob": -0.24535078160903034, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.0002340090140933171}, {"id": 796, "seek": 210710, "start": 2134.14, "end": 2136.18, "text": " recognize as too much influence.", "tokens": [51716, 5521, 382, 886, 709, 6503, 13, 51818], "temperature": 0.0, "avg_logprob": -0.24535078160903034, "compression_ratio": 1.551219512195122, "no_speech_prob": 0.0002340090140933171}, {"id": 797, "seek": 213710, "start": 2137.18, "end": 2140.74, "text": " And it started to produce bills", "tokens": [50368, 400, 309, 1409, 281, 5258, 12433, 50546], "temperature": 0.0, "avg_logprob": -0.15290319351922899, "compression_ratio": 1.576036866359447, "no_speech_prob": 0.00041715489351190627}, {"id": 798, "seek": 213710, "start": 2140.74, "end": 2145.74, "text": " and talks about policy that would totally collapse progress", "tokens": [50546, 293, 6686, 466, 3897, 300, 576, 3879, 15584, 4205, 50796], "temperature": 0.0, "avg_logprob": -0.15290319351922899, "compression_ratio": 1.576036866359447, "no_speech_prob": 0.00041715489351190627}, {"id": 799, "seek": 213710, "start": 2146.46, "end": 2149.18, "text": " in the space, very, very prematurely", "tokens": [50832, 294, 264, 1901, 11, 588, 11, 588, 34877, 356, 50968], "temperature": 0.0, "avg_logprob": -0.15290319351922899, "compression_ratio": 1.576036866359447, "no_speech_prob": 0.00041715489351190627}, {"id": 800, "seek": 213710, "start": 2149.18, "end": 2154.18, "text": " about theoretical long-term risks that might be an issue.", "tokens": [50968, 466, 20864, 938, 12, 7039, 10888, 300, 1062, 312, 364, 2734, 13, 51218], "temperature": 0.0, "avg_logprob": -0.15290319351922899, "compression_ratio": 1.576036866359447, "no_speech_prob": 0.00041715489351190627}, {"id": 801, "seek": 213710, "start": 2154.54, "end": 2155.38, "text": " And so fortunately,", "tokens": [51236, 400, 370, 25511, 11, 51278], "temperature": 0.0, "avg_logprob": -0.15290319351922899, "compression_ratio": 1.576036866359447, "no_speech_prob": 0.00041715489351190627}, {"id": 802, "seek": 213710, "start": 2155.38, "end": 2157.38, "text": " I think there's a cultural correction happening", "tokens": [51278, 286, 519, 456, 311, 257, 6988, 19984, 2737, 51378], "temperature": 0.0, "avg_logprob": -0.15290319351922899, "compression_ratio": 1.576036866359447, "no_speech_prob": 0.00041715489351190627}, {"id": 803, "seek": 213710, "start": 2157.38, "end": 2159.5, "text": " where even the legislators and policymakers", "tokens": [51378, 689, 754, 264, 39264, 293, 47325, 51484], "temperature": 0.0, "avg_logprob": -0.15290319351922899, "compression_ratio": 1.576036866359447, "no_speech_prob": 0.00041715489351190627}, {"id": 804, "seek": 213710, "start": 2159.5, "end": 2162.62, "text": " are starting to say, you know, this is not,", "tokens": [51484, 366, 2891, 281, 584, 11, 291, 458, 11, 341, 307, 406, 11, 51640], "temperature": 0.0, "avg_logprob": -0.15290319351922899, "compression_ratio": 1.576036866359447, "no_speech_prob": 0.00041715489351190627}, {"id": 805, "seek": 216262, "start": 2163.62, "end": 2167.2999999999997, "text": " it's not appropriate the level of influence", "tokens": [50414, 309, 311, 406, 6854, 264, 1496, 295, 6503, 50598], "temperature": 0.0, "avg_logprob": -0.11762201889701511, "compression_ratio": 1.63671875, "no_speech_prob": 0.00029548336169682443}, {"id": 806, "seek": 216262, "start": 2167.2999999999997, "end": 2169.58, "text": " that this one group is having", "tokens": [50598, 300, 341, 472, 1594, 307, 1419, 50712], "temperature": 0.0, "avg_logprob": -0.11762201889701511, "compression_ratio": 1.63671875, "no_speech_prob": 0.00029548336169682443}, {"id": 807, "seek": 216262, "start": 2169.58, "end": 2171.62, "text": " and we should listen to a much more broad", "tokens": [50712, 293, 321, 820, 2140, 281, 257, 709, 544, 4152, 50814], "temperature": 0.0, "avg_logprob": -0.11762201889701511, "compression_ratio": 1.63671875, "no_speech_prob": 0.00029548336169682443}, {"id": 808, "seek": 216262, "start": 2171.62, "end": 2174.8599999999997, "text": " and diverse set of opinions.", "tokens": [50814, 293, 9521, 992, 295, 11819, 13, 50976], "temperature": 0.0, "avg_logprob": -0.11762201889701511, "compression_ratio": 1.63671875, "no_speech_prob": 0.00029548336169682443}, {"id": 809, "seek": 216262, "start": 2174.8599999999997, "end": 2176.2599999999998, "text": " So I'm still concerned about that", "tokens": [50976, 407, 286, 478, 920, 5922, 466, 300, 51046], "temperature": 0.0, "avg_logprob": -0.11762201889701511, "compression_ratio": 1.63671875, "no_speech_prob": 0.00029548336169682443}, {"id": 810, "seek": 216262, "start": 2176.2599999999998, "end": 2179.1, "text": " and I'll continue to speak out against that when I see it,", "tokens": [51046, 293, 286, 603, 2354, 281, 1710, 484, 1970, 300, 562, 286, 536, 309, 11, 51188], "temperature": 0.0, "avg_logprob": -0.11762201889701511, "compression_ratio": 1.63671875, "no_speech_prob": 0.00029548336169682443}, {"id": 811, "seek": 216262, "start": 2179.1, "end": 2181.42, "text": " but at the academic level,", "tokens": [51188, 457, 412, 264, 7778, 1496, 11, 51304], "temperature": 0.0, "avg_logprob": -0.11762201889701511, "compression_ratio": 1.63671875, "no_speech_prob": 0.00029548336169682443}, {"id": 812, "seek": 216262, "start": 2181.42, "end": 2186.42, "text": " I don't want to see, you know, professors lose their funding.", "tokens": [51304, 286, 500, 380, 528, 281, 536, 11, 291, 458, 11, 15924, 3624, 641, 6137, 13, 51554], "temperature": 0.0, "avg_logprob": -0.11762201889701511, "compression_ratio": 1.63671875, "no_speech_prob": 0.00029548336169682443}, {"id": 813, "seek": 216262, "start": 2186.54, "end": 2190.06, "text": " I think that they should continue to pursue those ideas.", "tokens": [51560, 286, 519, 300, 436, 820, 2354, 281, 12392, 729, 3487, 13, 51736], "temperature": 0.0, "avg_logprob": -0.11762201889701511, "compression_ratio": 1.63671875, "no_speech_prob": 0.00029548336169682443}, {"id": 814, "seek": 216262, "start": 2190.06, "end": 2191.58, "text": " Yeah, I think Bostrom blogged that.", "tokens": [51736, 865, 11, 286, 519, 363, 555, 4397, 6968, 3004, 300, 13, 51812], "temperature": 0.0, "avg_logprob": -0.11762201889701511, "compression_ratio": 1.63671875, "no_speech_prob": 0.00029548336169682443}, {"id": 815, "seek": 219158, "start": 2191.58, "end": 2194.18, "text": " He was trying to resist the entropic forces", "tokens": [50364, 634, 390, 1382, 281, 4597, 264, 948, 39173, 5874, 50494], "temperature": 0.0, "avg_logprob": -0.13060747434015144, "compression_ratio": 1.6419354838709677, "no_speech_prob": 0.01653626561164856}, {"id": 816, "seek": 219158, "start": 2194.18, "end": 2196.18, "text": " of the philosophy department for several years", "tokens": [50494, 295, 264, 10675, 5882, 337, 2940, 924, 50594], "temperature": 0.0, "avg_logprob": -0.13060747434015144, "compression_ratio": 1.6419354838709677, "no_speech_prob": 0.01653626561164856}, {"id": 817, "seek": 219158, "start": 2196.18, "end": 2198.18, "text": " and eventually he lost.", "tokens": [50594, 293, 4728, 415, 2731, 13, 50694], "temperature": 0.0, "avg_logprob": -0.13060747434015144, "compression_ratio": 1.6419354838709677, "no_speech_prob": 0.01653626561164856}, {"id": 818, "seek": 219158, "start": 2198.18, "end": 2199.98, "text": " But I'm in two minds as well.", "tokens": [50694, 583, 286, 478, 294, 732, 9634, 382, 731, 13, 50784], "temperature": 0.0, "avg_logprob": -0.13060747434015144, "compression_ratio": 1.6419354838709677, "no_speech_prob": 0.01653626561164856}, {"id": 819, "seek": 219158, "start": 2199.98, "end": 2202.02, "text": " So as you know, I've hosted many debates", "tokens": [50784, 407, 382, 291, 458, 11, 286, 600, 19204, 867, 24203, 50886], "temperature": 0.0, "avg_logprob": -0.13060747434015144, "compression_ratio": 1.6419354838709677, "no_speech_prob": 0.01653626561164856}, {"id": 820, "seek": 219158, "start": 2202.02, "end": 2203.2599999999998, "text": " with, you know, like Connolly,", "tokens": [50886, 365, 11, 291, 458, 11, 411, 2656, 1771, 13020, 11, 50948], "temperature": 0.0, "avg_logprob": -0.13060747434015144, "compression_ratio": 1.6419354838709677, "no_speech_prob": 0.01653626561164856}, {"id": 821, "seek": 219158, "start": 2203.2599999999998, "end": 2205.02, "text": " he for example, and Beth Jezos", "tokens": [50948, 415, 337, 1365, 11, 293, 14011, 2588, 27681, 51036], "temperature": 0.0, "avg_logprob": -0.13060747434015144, "compression_ratio": 1.6419354838709677, "no_speech_prob": 0.01653626561164856}, {"id": 822, "seek": 219158, "start": 2205.02, "end": 2206.7, "text": " and a bunch of different people.", "tokens": [51036, 293, 257, 3840, 295, 819, 561, 13, 51120], "temperature": 0.0, "avg_logprob": -0.13060747434015144, "compression_ratio": 1.6419354838709677, "no_speech_prob": 0.01653626561164856}, {"id": 823, "seek": 219158, "start": 2206.7, "end": 2209.5, "text": " And one thing that strikes me is how ideological it is.", "tokens": [51120, 400, 472, 551, 300, 16750, 385, 307, 577, 35341, 309, 307, 13, 51260], "temperature": 0.0, "avg_logprob": -0.13060747434015144, "compression_ratio": 1.6419354838709677, "no_speech_prob": 0.01653626561164856}, {"id": 824, "seek": 219158, "start": 2209.5, "end": 2211.18, "text": " I really thought as a podcaster,", "tokens": [51260, 286, 534, 1194, 382, 257, 2497, 42640, 11, 51344], "temperature": 0.0, "avg_logprob": -0.13060747434015144, "compression_ratio": 1.6419354838709677, "no_speech_prob": 0.01653626561164856}, {"id": 825, "seek": 219158, "start": 2211.18, "end": 2214.14, "text": " I could have an honest and open conversation", "tokens": [51344, 286, 727, 362, 364, 3245, 293, 1269, 3761, 51492], "temperature": 0.0, "avg_logprob": -0.13060747434015144, "compression_ratio": 1.6419354838709677, "no_speech_prob": 0.01653626561164856}, {"id": 826, "seek": 219158, "start": 2214.14, "end": 2216.2599999999998, "text": " and it's never gone well.", "tokens": [51492, 293, 309, 311, 1128, 2780, 731, 13, 51598], "temperature": 0.0, "avg_logprob": -0.13060747434015144, "compression_ratio": 1.6419354838709677, "no_speech_prob": 0.01653626561164856}, {"id": 827, "seek": 219158, "start": 2216.2599999999998, "end": 2217.7799999999997, "text": " And I've put a lot of thought", "tokens": [51598, 400, 286, 600, 829, 257, 688, 295, 1194, 51674], "temperature": 0.0, "avg_logprob": -0.13060747434015144, "compression_ratio": 1.6419354838709677, "no_speech_prob": 0.01653626561164856}, {"id": 828, "seek": 219158, "start": 2217.7799999999997, "end": 2220.06, "text": " into trying to understand why that is.", "tokens": [51674, 666, 1382, 281, 1223, 983, 300, 307, 13, 51788], "temperature": 0.0, "avg_logprob": -0.13060747434015144, "compression_ratio": 1.6419354838709677, "no_speech_prob": 0.01653626561164856}, {"id": 829, "seek": 222006, "start": 2220.06, "end": 2222.5, "text": " And I think philosophically you can trace it back", "tokens": [50364, 400, 286, 519, 14529, 984, 291, 393, 13508, 309, 646, 50486], "temperature": 0.0, "avg_logprob": -0.09081315994262695, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0008436052594333887}, {"id": 830, "seek": 222006, "start": 2222.5, "end": 2225.86, "text": " to things like paternalism and safetyism", "tokens": [50486, 281, 721, 411, 42302, 4660, 1434, 293, 4514, 1434, 50654], "temperature": 0.0, "avg_logprob": -0.09081315994262695, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0008436052594333887}, {"id": 831, "seek": 222006, "start": 2225.86, "end": 2228.62, "text": " and utilitarianism and consequentialism", "tokens": [50654, 293, 4976, 13707, 1434, 293, 7242, 2549, 1434, 50792], "temperature": 0.0, "avg_logprob": -0.09081315994262695, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0008436052594333887}, {"id": 832, "seek": 222006, "start": 2228.62, "end": 2230.62, "text": " and long-termism and, you know,", "tokens": [50792, 293, 938, 12, 7039, 1434, 293, 11, 291, 458, 11, 50892], "temperature": 0.0, "avg_logprob": -0.09081315994262695, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0008436052594333887}, {"id": 833, "seek": 222006, "start": 2230.62, "end": 2235.06, "text": " these are ideologies that make one believe", "tokens": [50892, 613, 366, 1153, 6204, 300, 652, 472, 1697, 51114], "temperature": 0.0, "avg_logprob": -0.09081315994262695, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0008436052594333887}, {"id": 834, "seek": 222006, "start": 2235.06, "end": 2237.82, "text": " that even though it's just a subjective probability", "tokens": [51114, 300, 754, 1673, 309, 311, 445, 257, 25972, 8482, 51252], "temperature": 0.0, "avg_logprob": -0.09081315994262695, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0008436052594333887}, {"id": 835, "seek": 222006, "start": 2237.82, "end": 2240.02, "text": " that I know better than you,", "tokens": [51252, 300, 286, 458, 1101, 813, 291, 11, 51362], "temperature": 0.0, "avg_logprob": -0.09081315994262695, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0008436052594333887}, {"id": 836, "seek": 222006, "start": 2240.02, "end": 2242.18, "text": " I can predict the future better than you.", "tokens": [51362, 286, 393, 6069, 264, 2027, 1101, 813, 291, 13, 51470], "temperature": 0.0, "avg_logprob": -0.09081315994262695, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0008436052594333887}, {"id": 837, "seek": 222006, "start": 2242.18, "end": 2244.98, "text": " And they've become much more pragmatic in recent years.", "tokens": [51470, 400, 436, 600, 1813, 709, 544, 46904, 294, 5162, 924, 13, 51610], "temperature": 0.0, "avg_logprob": -0.09081315994262695, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0008436052594333887}, {"id": 838, "seek": 222006, "start": 2244.98, "end": 2246.7, "text": " So rather than talking about", "tokens": [51610, 407, 2831, 813, 1417, 466, 51696], "temperature": 0.0, "avg_logprob": -0.09081315994262695, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0008436052594333887}, {"id": 839, "seek": 222006, "start": 2246.7, "end": 2248.86, "text": " the old school Bostrom superintelligence,", "tokens": [51696, 264, 1331, 1395, 363, 555, 4397, 1687, 20761, 17644, 11, 51804], "temperature": 0.0, "avg_logprob": -0.09081315994262695, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0008436052594333887}, {"id": 840, "seek": 224886, "start": 2248.86, "end": 2250.78, "text": " we're now talking about, you know,", "tokens": [50364, 321, 434, 586, 1417, 466, 11, 291, 458, 11, 50460], "temperature": 0.0, "avg_logprob": -0.13497860705266235, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.0019932319410145283}, {"id": 841, "seek": 224886, "start": 2250.78, "end": 2253.38, "text": " memetic risks and bio risks and things", "tokens": [50460, 1334, 3532, 10888, 293, 12198, 10888, 293, 721, 50590], "temperature": 0.0, "avg_logprob": -0.13497860705266235, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.0019932319410145283}, {"id": 842, "seek": 224886, "start": 2253.38, "end": 2256.46, "text": " that I think are designed to get more people on board with it.", "tokens": [50590, 300, 286, 519, 366, 4761, 281, 483, 544, 561, 322, 3150, 365, 309, 13, 50744], "temperature": 0.0, "avg_logprob": -0.13497860705266235, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.0019932319410145283}, {"id": 843, "seek": 224886, "start": 2256.46, "end": 2259.6200000000003, "text": " And I agree with you that they've had a lot of influence.", "tokens": [50744, 400, 286, 3986, 365, 291, 300, 436, 600, 632, 257, 688, 295, 6503, 13, 50902], "temperature": 0.0, "avg_logprob": -0.13497860705266235, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.0019932319410145283}, {"id": 844, "seek": 224886, "start": 2259.6200000000003, "end": 2261.58, "text": " But why is it so difficult", "tokens": [50902, 583, 983, 307, 309, 370, 2252, 51000], "temperature": 0.0, "avg_logprob": -0.13497860705266235, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.0019932319410145283}, {"id": 845, "seek": 224886, "start": 2261.58, "end": 2263.34, "text": " to have a rational conversation?", "tokens": [51000, 281, 362, 257, 15090, 3761, 30, 51088], "temperature": 0.0, "avg_logprob": -0.13497860705266235, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.0019932319410145283}, {"id": 846, "seek": 224886, "start": 2263.34, "end": 2264.78, "text": " Yeah, no, I think it's what you say.", "tokens": [51088, 865, 11, 572, 11, 286, 519, 309, 311, 437, 291, 584, 13, 51160], "temperature": 0.0, "avg_logprob": -0.13497860705266235, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.0019932319410145283}, {"id": 847, "seek": 224886, "start": 2264.78, "end": 2266.98, "text": " It's very ideological.", "tokens": [51160, 467, 311, 588, 35341, 13, 51270], "temperature": 0.0, "avg_logprob": -0.13497860705266235, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.0019932319410145283}, {"id": 848, "seek": 224886, "start": 2266.98, "end": 2269.1400000000003, "text": " There are camps and positions", "tokens": [51270, 821, 366, 16573, 293, 8432, 51378], "temperature": 0.0, "avg_logprob": -0.13497860705266235, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.0019932319410145283}, {"id": 849, "seek": 224886, "start": 2269.1400000000003, "end": 2272.5, "text": " and it's, for some reason,", "tokens": [51378, 293, 309, 311, 11, 337, 512, 1778, 11, 51546], "temperature": 0.0, "avg_logprob": -0.13497860705266235, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.0019932319410145283}, {"id": 850, "seek": 224886, "start": 2272.5, "end": 2275.42, "text": " it's become very cult-like on both sides.", "tokens": [51546, 309, 311, 1813, 588, 2376, 12, 4092, 322, 1293, 4881, 13, 51692], "temperature": 0.0, "avg_logprob": -0.13497860705266235, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.0019932319410145283}, {"id": 851, "seek": 227542, "start": 2276.42, "end": 2278.82, "text": " Obviously, there's the EA movement,", "tokens": [50414, 7580, 11, 456, 311, 264, 35747, 3963, 11, 50534], "temperature": 0.0, "avg_logprob": -0.1728611718053403, "compression_ratio": 1.490990990990991, "no_speech_prob": 0.0004509508144110441}, {"id": 852, "seek": 227542, "start": 2278.82, "end": 2282.2200000000003, "text": " which formed a cult-like environment", "tokens": [50534, 597, 8693, 257, 2376, 12, 4092, 2823, 50704], "temperature": 0.0, "avg_logprob": -0.1728611718053403, "compression_ratio": 1.490990990990991, "no_speech_prob": 0.0004509508144110441}, {"id": 853, "seek": 227542, "start": 2282.2200000000003, "end": 2285.1, "text": " of adherence to those principles", "tokens": [50704, 295, 30106, 655, 281, 729, 9156, 50848], "temperature": 0.0, "avg_logprob": -0.1728611718053403, "compression_ratio": 1.490990990990991, "no_speech_prob": 0.0004509508144110441}, {"id": 854, "seek": 227542, "start": 2285.1, "end": 2289.82, "text": " and their recommended behaviors and actions,", "tokens": [50848, 293, 641, 9628, 15501, 293, 5909, 11, 51084], "temperature": 0.0, "avg_logprob": -0.1728611718053403, "compression_ratio": 1.490990990990991, "no_speech_prob": 0.0004509508144110441}, {"id": 855, "seek": 227542, "start": 2289.82, "end": 2293.1, "text": " you know, what you should work on in your life.", "tokens": [51084, 291, 458, 11, 437, 291, 820, 589, 322, 294, 428, 993, 13, 51248], "temperature": 0.0, "avg_logprob": -0.1728611718053403, "compression_ratio": 1.490990990990991, "no_speech_prob": 0.0004509508144110441}, {"id": 856, "seek": 227542, "start": 2293.1, "end": 2294.86, "text": " They have dating apps for you.", "tokens": [51248, 814, 362, 10689, 7733, 337, 291, 13, 51336], "temperature": 0.0, "avg_logprob": -0.1728611718053403, "compression_ratio": 1.490990990990991, "no_speech_prob": 0.0004509508144110441}, {"id": 857, "seek": 227542, "start": 2294.86, "end": 2296.54, "text": " Like, it's very insular.", "tokens": [51336, 1743, 11, 309, 311, 588, 1028, 1040, 13, 51420], "temperature": 0.0, "avg_logprob": -0.1728611718053403, "compression_ratio": 1.490990990990991, "no_speech_prob": 0.0004509508144110441}, {"id": 858, "seek": 227542, "start": 2296.54, "end": 2301.14, "text": " And then there was an ironic, I think,", "tokens": [51420, 400, 550, 456, 390, 364, 33719, 11, 286, 519, 11, 51650], "temperature": 0.0, "avg_logprob": -0.1728611718053403, "compression_ratio": 1.490990990990991, "no_speech_prob": 0.0004509508144110441}, {"id": 859, "seek": 227542, "start": 2301.14, "end": 2303.82, "text": " although it's increasingly not clear,", "tokens": [51650, 4878, 309, 311, 12980, 406, 1850, 11, 51784], "temperature": 0.0, "avg_logprob": -0.1728611718053403, "compression_ratio": 1.490990990990991, "no_speech_prob": 0.0004509508144110441}, {"id": 860, "seek": 230382, "start": 2303.94, "end": 2306.54, "text": " an ironic counter-movement, which was EAAC.", "tokens": [50370, 364, 33719, 5682, 12, 76, 1682, 518, 11, 597, 390, 35747, 4378, 13, 50500], "temperature": 0.0, "avg_logprob": -0.19063633411854236, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.0005701315822079778}, {"id": 861, "seek": 230382, "start": 2306.54, "end": 2308.26, "text": " Yeah.", "tokens": [50500, 865, 13, 50586], "temperature": 0.0, "avg_logprob": -0.19063633411854236, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.0005701315822079778}, {"id": 862, "seek": 230382, "start": 2308.26, "end": 2309.7000000000003, "text": " And that has spun out into something", "tokens": [50586, 400, 300, 575, 37038, 484, 666, 746, 50658], "temperature": 0.0, "avg_logprob": -0.19063633411854236, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.0005701315822079778}, {"id": 863, "seek": 230382, "start": 2309.7000000000003, "end": 2311.3, "text": " that is very not ironic.", "tokens": [50658, 300, 307, 588, 406, 33719, 13, 50738], "temperature": 0.0, "avg_logprob": -0.19063633411854236, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.0005701315822079778}, {"id": 864, "seek": 230382, "start": 2311.3, "end": 2315.6200000000003, "text": " It's very libertarian, accelerationist,", "tokens": [50738, 467, 311, 588, 18058, 10652, 11, 17162, 468, 11, 50954], "temperature": 0.0, "avg_logprob": -0.19063633411854236, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.0005701315822079778}, {"id": 865, "seek": 230382, "start": 2315.6200000000003, "end": 2318.38, "text": " which are ideals that I don't hold either.", "tokens": [50954, 597, 366, 30956, 300, 286, 500, 380, 1797, 2139, 13, 51092], "temperature": 0.0, "avg_logprob": -0.19063633411854236, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.0005701315822079778}, {"id": 866, "seek": 230382, "start": 2318.38, "end": 2322.98, "text": " And so both of these camps I find really unappealing.", "tokens": [51092, 400, 370, 1293, 295, 613, 16573, 286, 915, 534, 517, 46408, 4270, 13, 51322], "temperature": 0.0, "avg_logprob": -0.19063633411854236, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.0005701315822079778}, {"id": 867, "seek": 230382, "start": 2322.98, "end": 2324.7000000000003, "text": " I don't want to be associated with either of them.", "tokens": [51322, 286, 500, 380, 528, 281, 312, 6615, 365, 2139, 295, 552, 13, 51408], "temperature": 0.0, "avg_logprob": -0.19063633411854236, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.0005701315822079778}, {"id": 868, "seek": 230382, "start": 2324.7000000000003, "end": 2329.42, "text": " Yeah, I found, you know, EA was very dominant", "tokens": [51408, 865, 11, 286, 1352, 11, 291, 458, 11, 35747, 390, 588, 15657, 51644], "temperature": 0.0, "avg_logprob": -0.19063633411854236, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.0005701315822079778}, {"id": 869, "seek": 230382, "start": 2329.42, "end": 2330.5, "text": " for a long time.", "tokens": [51644, 337, 257, 938, 565, 13, 51698], "temperature": 0.0, "avg_logprob": -0.19063633411854236, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.0005701315822079778}, {"id": 870, "seek": 233050, "start": 2330.54, "end": 2334.3, "text": " And so when EAAC came out, it was, like, refreshing.", "tokens": [50366, 400, 370, 562, 35747, 4378, 1361, 484, 11, 309, 390, 11, 411, 11, 19772, 13, 50554], "temperature": 0.0, "avg_logprob": -0.15275426106910184, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.000615705968812108}, {"id": 871, "seek": 233050, "start": 2334.3, "end": 2337.54, "text": " Finally, someone's, like, calling them on their bullshit.", "tokens": [50554, 6288, 11, 1580, 311, 11, 411, 11, 5141, 552, 322, 641, 22676, 13, 50716], "temperature": 0.0, "avg_logprob": -0.15275426106910184, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.000615705968812108}, {"id": 872, "seek": 233050, "start": 2337.54, "end": 2339.42, "text": " But at this point, it's just mind-numbing", "tokens": [50716, 583, 412, 341, 935, 11, 309, 311, 445, 1575, 12, 77, 34236, 50810], "temperature": 0.0, "avg_logprob": -0.15275426106910184, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.000615705968812108}, {"id": 873, "seek": 233050, "start": 2339.42, "end": 2343.7, "text": " and, like, completely not of interest to me.", "tokens": [50810, 293, 11, 411, 11, 2584, 406, 295, 1179, 281, 385, 13, 51024], "temperature": 0.0, "avg_logprob": -0.15275426106910184, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.000615705968812108}, {"id": 874, "seek": 233050, "start": 2343.7, "end": 2344.98, "text": " Yeah, we've had Beth on the show.", "tokens": [51024, 865, 11, 321, 600, 632, 14011, 322, 264, 855, 13, 51088], "temperature": 0.0, "avg_logprob": -0.15275426106910184, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.000615705968812108}, {"id": 875, "seek": 233050, "start": 2344.98, "end": 2346.42, "text": " He's a really nice guy, actually.", "tokens": [51088, 634, 311, 257, 534, 1481, 2146, 11, 767, 13, 51160], "temperature": 0.0, "avg_logprob": -0.15275426106910184, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.000615705968812108}, {"id": 876, "seek": 233050, "start": 2346.42, "end": 2348.66, "text": " I invested in Guillaume's company.", "tokens": [51160, 286, 13104, 294, 2694, 5291, 2540, 311, 2237, 13, 51272], "temperature": 0.0, "avg_logprob": -0.15275426106910184, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.000615705968812108}, {"id": 877, "seek": 233050, "start": 2348.66, "end": 2349.7, "text": " Oh, did he? Yeah, yeah, yeah.", "tokens": [51272, 876, 11, 630, 415, 30, 865, 11, 1338, 11, 1338, 13, 51324], "temperature": 0.0, "avg_logprob": -0.15275426106910184, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.000615705968812108}, {"id": 878, "seek": 233050, "start": 2349.7, "end": 2350.78, "text": " Oh, it's not that...", "tokens": [51324, 876, 11, 309, 311, 406, 300, 485, 51378], "temperature": 0.0, "avg_logprob": -0.15275426106910184, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.000615705968812108}, {"id": 879, "seek": 233050, "start": 2350.78, "end": 2354.42, "text": " He's brilliant. Like, he's a really, really nice person.", "tokens": [51378, 634, 311, 10248, 13, 1743, 11, 415, 311, 257, 534, 11, 534, 1481, 954, 13, 51560], "temperature": 0.0, "avg_logprob": -0.15275426106910184, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.000615705968812108}, {"id": 880, "seek": 233050, "start": 2355.62, "end": 2358.7, "text": " I'm proud to see Canadians doing great things.", "tokens": [51620, 286, 478, 4570, 281, 536, 30053, 884, 869, 721, 13, 51774], "temperature": 0.0, "avg_logprob": -0.15275426106910184, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.000615705968812108}, {"id": 881, "seek": 235870, "start": 2359.7, "end": 2361.58, "text": " The best thing I found super funny.", "tokens": [50414, 440, 1151, 551, 286, 1352, 1687, 4074, 13, 50508], "temperature": 0.0, "avg_logprob": -0.16725353025040537, "compression_ratio": 1.541501976284585, "no_speech_prob": 0.0005860393866896629}, {"id": 882, "seek": 235870, "start": 2361.58, "end": 2364.2599999999998, "text": " And I think EAAC was necessary.", "tokens": [50508, 400, 286, 519, 35747, 4378, 390, 4818, 13, 50642], "temperature": 0.0, "avg_logprob": -0.16725353025040537, "compression_ratio": 1.541501976284585, "no_speech_prob": 0.0005860393866896629}, {"id": 883, "seek": 235870, "start": 2364.2599999999998, "end": 2368.18, "text": " I now believe that both EAAC and EAAC need to be dissolved.", "tokens": [50642, 286, 586, 1697, 300, 1293, 35747, 4378, 293, 35747, 4378, 643, 281, 312, 30651, 13, 50838], "temperature": 0.0, "avg_logprob": -0.16725353025040537, "compression_ratio": 1.541501976284585, "no_speech_prob": 0.0005860393866896629}, {"id": 884, "seek": 235870, "start": 2368.18, "end": 2373.3799999999997, "text": " We've seen them through to their logical conclusion,", "tokens": [50838, 492, 600, 1612, 552, 807, 281, 641, 14978, 10063, 11, 51098], "temperature": 0.0, "avg_logprob": -0.16725353025040537, "compression_ratio": 1.541501976284585, "no_speech_prob": 0.0005860393866896629}, {"id": 885, "seek": 235870, "start": 2373.3799999999997, "end": 2375.1, "text": " and now we're starting to get into territory", "tokens": [51098, 293, 586, 321, 434, 2891, 281, 483, 666, 11360, 51184], "temperature": 0.0, "avg_logprob": -0.16725353025040537, "compression_ratio": 1.541501976284585, "no_speech_prob": 0.0005860393866896629}, {"id": 886, "seek": 235870, "start": 2375.1, "end": 2378.06, "text": " that's very strange.", "tokens": [51184, 300, 311, 588, 5861, 13, 51332], "temperature": 0.0, "avg_logprob": -0.16725353025040537, "compression_ratio": 1.541501976284585, "no_speech_prob": 0.0005860393866896629}, {"id": 887, "seek": 235870, "start": 2378.06, "end": 2379.4199999999996, "text": " From a philosophical perspective,", "tokens": [51332, 3358, 257, 25066, 4585, 11, 51400], "temperature": 0.0, "avg_logprob": -0.16725353025040537, "compression_ratio": 1.541501976284585, "no_speech_prob": 0.0005860393866896629}, {"id": 888, "seek": 235870, "start": 2379.4199999999996, "end": 2383.02, "text": " how do you kind of see the role of AI in society?", "tokens": [51400, 577, 360, 291, 733, 295, 536, 264, 3090, 295, 7318, 294, 4086, 30, 51580], "temperature": 0.0, "avg_logprob": -0.16725353025040537, "compression_ratio": 1.541501976284585, "no_speech_prob": 0.0005860393866896629}, {"id": 889, "seek": 235870, "start": 2383.02, "end": 2387.06, "text": " And I'm quite interested in how it's affecting our reality,", "tokens": [51580, 400, 286, 478, 1596, 3102, 294, 577, 309, 311, 17476, 527, 4103, 11, 51782], "temperature": 0.0, "avg_logprob": -0.16725353025040537, "compression_ratio": 1.541501976284585, "no_speech_prob": 0.0005860393866896629}, {"id": 890, "seek": 238706, "start": 2387.06, "end": 2389.98, "text": " and how we interface with technology", "tokens": [50364, 293, 577, 321, 9226, 365, 2899, 50510], "temperature": 0.0, "avg_logprob": -0.17655064509465143, "compression_ratio": 1.6584362139917694, "no_speech_prob": 0.008517857640981674}, {"id": 891, "seek": 238706, "start": 2389.98, "end": 2391.74, "text": " is really dramatically changing over time.", "tokens": [50510, 307, 534, 17548, 4473, 670, 565, 13, 50598], "temperature": 0.0, "avg_logprob": -0.17655064509465143, "compression_ratio": 1.6584362139917694, "no_speech_prob": 0.008517857640981674}, {"id": 892, "seek": 238706, "start": 2391.74, "end": 2392.9, "text": " I mean, what do you think about that?", "tokens": [50598, 286, 914, 11, 437, 360, 291, 519, 466, 300, 30, 50656], "temperature": 0.0, "avg_logprob": -0.17655064509465143, "compression_ratio": 1.6584362139917694, "no_speech_prob": 0.008517857640981674}, {"id": 893, "seek": 238706, "start": 2392.9, "end": 2394.94, "text": " Yeah, completely true.", "tokens": [50656, 865, 11, 2584, 2074, 13, 50758], "temperature": 0.0, "avg_logprob": -0.17655064509465143, "compression_ratio": 1.6584362139917694, "no_speech_prob": 0.008517857640981674}, {"id": 894, "seek": 238706, "start": 2394.94, "end": 2400.02, "text": " I think I view it in the same way I view the computer", "tokens": [50758, 286, 519, 286, 1910, 309, 294, 264, 912, 636, 286, 1910, 264, 3820, 51012], "temperature": 0.0, "avg_logprob": -0.17655064509465143, "compression_ratio": 1.6584362139917694, "no_speech_prob": 0.008517857640981674}, {"id": 895, "seek": 238706, "start": 2400.02, "end": 2401.66, "text": " or the CPU.", "tokens": [51012, 420, 264, 13199, 13, 51094], "temperature": 0.0, "avg_logprob": -0.17655064509465143, "compression_ratio": 1.6584362139917694, "no_speech_prob": 0.008517857640981674}, {"id": 896, "seek": 238706, "start": 2401.66, "end": 2402.62, "text": " It's a tool.", "tokens": [51094, 467, 311, 257, 2290, 13, 51142], "temperature": 0.0, "avg_logprob": -0.17655064509465143, "compression_ratio": 1.6584362139917694, "no_speech_prob": 0.008517857640981674}, {"id": 897, "seek": 238706, "start": 2402.62, "end": 2404.02, "text": " It's something that we're going to leverage,", "tokens": [51142, 467, 311, 746, 300, 321, 434, 516, 281, 13982, 11, 51212], "temperature": 0.0, "avg_logprob": -0.17655064509465143, "compression_ratio": 1.6584362139917694, "no_speech_prob": 0.008517857640981674}, {"id": 898, "seek": 238706, "start": 2404.02, "end": 2406.58, "text": " that we're going to build on top of", "tokens": [51212, 300, 321, 434, 516, 281, 1322, 322, 1192, 295, 51340], "temperature": 0.0, "avg_logprob": -0.17655064509465143, "compression_ratio": 1.6584362139917694, "no_speech_prob": 0.008517857640981674}, {"id": 899, "seek": 238706, "start": 2406.58, "end": 2408.66, "text": " and use to make our lives better,", "tokens": [51340, 293, 764, 281, 652, 527, 2909, 1101, 11, 51444], "temperature": 0.0, "avg_logprob": -0.17655064509465143, "compression_ratio": 1.6584362139917694, "no_speech_prob": 0.008517857640981674}, {"id": 900, "seek": 238706, "start": 2408.66, "end": 2411.06, "text": " to make us more productive,", "tokens": [51444, 281, 652, 505, 544, 13304, 11, 51564], "temperature": 0.0, "avg_logprob": -0.17655064509465143, "compression_ratio": 1.6584362139917694, "no_speech_prob": 0.008517857640981674}, {"id": 901, "seek": 238706, "start": 2411.06, "end": 2413.7, "text": " to make things cheaper, more accessible.", "tokens": [51564, 281, 652, 721, 12284, 11, 544, 9515, 13, 51696], "temperature": 0.0, "avg_logprob": -0.17655064509465143, "compression_ratio": 1.6584362139917694, "no_speech_prob": 0.008517857640981674}, {"id": 902, "seek": 241370, "start": 2414.7, "end": 2418.18, "text": " I think all the good that came from the computer", "tokens": [50414, 286, 519, 439, 264, 665, 300, 1361, 490, 264, 3820, 50588], "temperature": 0.0, "avg_logprob": -0.21829247024824033, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.0006459515425376594}, {"id": 903, "seek": 241370, "start": 2418.18, "end": 2421.7, "text": " and the internet is going to be dwarfed by this,", "tokens": [50588, 293, 264, 4705, 307, 516, 281, 312, 24524, 33712, 538, 341, 11, 50764], "temperature": 0.0, "avg_logprob": -0.21829247024824033, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.0006459515425376594}, {"id": 904, "seek": 241370, "start": 2421.7, "end": 2425.7, "text": " the democratization of intelligence", "tokens": [50764, 264, 37221, 2144, 295, 7599, 50964], "temperature": 0.0, "avg_logprob": -0.21829247024824033, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.0006459515425376594}, {"id": 905, "seek": 241370, "start": 2425.7, "end": 2429.18, "text": " and having that always at your disposal at any time.", "tokens": [50964, 293, 1419, 300, 1009, 412, 428, 26400, 412, 604, 565, 13, 51138], "temperature": 0.0, "avg_logprob": -0.21829247024824033, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.0006459515425376594}, {"id": 906, "seek": 241370, "start": 2429.18, "end": 2432.7, "text": " That's something that, you know, 50 years ago,", "tokens": [51138, 663, 311, 746, 300, 11, 291, 458, 11, 2625, 924, 2057, 11, 51314], "temperature": 0.0, "avg_logprob": -0.21829247024824033, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.0006459515425376594}, {"id": 907, "seek": 241370, "start": 2432.7, "end": 2435.98, "text": " you couldn't even dream of it, right?", "tokens": [51314, 291, 2809, 380, 754, 3055, 295, 309, 11, 558, 30, 51478], "temperature": 0.0, "avg_logprob": -0.21829247024824033, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.0006459515425376594}, {"id": 908, "seek": 241370, "start": 2435.98, "end": 2438.8999999999996, "text": " It's surreal, the amount of progress", "tokens": [51478, 467, 311, 32513, 11, 264, 2372, 295, 4205, 51624], "temperature": 0.0, "avg_logprob": -0.21829247024824033, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.0006459515425376594}, {"id": 909, "seek": 241370, "start": 2438.8999999999996, "end": 2440.58, "text": " that's been made in half a century.", "tokens": [51624, 300, 311, 668, 1027, 294, 1922, 257, 4901, 13, 51708], "temperature": 0.0, "avg_logprob": -0.21829247024824033, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.0006459515425376594}, {"id": 910, "seek": 241370, "start": 2440.58, "end": 2441.9399999999996, "text": " And so I'm really excited for that.", "tokens": [51708, 400, 370, 286, 478, 534, 2919, 337, 300, 13, 51776], "temperature": 0.0, "avg_logprob": -0.21829247024824033, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.0006459515425376594}, {"id": 911, "seek": 244194, "start": 2442.38, "end": 2447.38, "text": " I think it will do a lot of good and alleviate a lot of ills.", "tokens": [50386, 286, 519, 309, 486, 360, 257, 688, 295, 665, 293, 42701, 257, 688, 295, 220, 2565, 13, 50636], "temperature": 0.0, "avg_logprob": -0.14755988675494527, "compression_ratio": 1.5660377358490567, "no_speech_prob": 0.0024141359608620405}, {"id": 912, "seek": 244194, "start": 2449.14, "end": 2452.42, "text": " I think the human experience, our lives,", "tokens": [50724, 286, 519, 264, 1952, 1752, 11, 527, 2909, 11, 50888], "temperature": 0.0, "avg_logprob": -0.14755988675494527, "compression_ratio": 1.5660377358490567, "no_speech_prob": 0.0024141359608620405}, {"id": 913, "seek": 244194, "start": 2452.42, "end": 2455.9, "text": " will be dramatically improved by having access", "tokens": [50888, 486, 312, 17548, 9689, 538, 1419, 2105, 51062], "temperature": 0.0, "avg_logprob": -0.14755988675494527, "compression_ratio": 1.5660377358490567, "no_speech_prob": 0.0024141359608620405}, {"id": 914, "seek": 244194, "start": 2455.9, "end": 2459.3, "text": " to much more intelligence in our lives.", "tokens": [51062, 281, 709, 544, 7599, 294, 527, 2909, 13, 51232], "temperature": 0.0, "avg_logprob": -0.14755988675494527, "compression_ratio": 1.5660377358490567, "no_speech_prob": 0.0024141359608620405}, {"id": 915, "seek": 244194, "start": 2459.3, "end": 2460.38, "text": " I'm really excited as well,", "tokens": [51232, 286, 478, 534, 2919, 382, 731, 11, 51286], "temperature": 0.0, "avg_logprob": -0.14755988675494527, "compression_ratio": 1.5660377358490567, "no_speech_prob": 0.0024141359608620405}, {"id": 916, "seek": 244194, "start": 2460.38, "end": 2464.42, "text": " but are there particular things that you are concerned about?", "tokens": [51286, 457, 366, 456, 1729, 721, 300, 291, 366, 5922, 466, 30, 51488], "temperature": 0.0, "avg_logprob": -0.14755988675494527, "compression_ratio": 1.5660377358490567, "no_speech_prob": 0.0024141359608620405}, {"id": 917, "seek": 244194, "start": 2464.42, "end": 2467.94, "text": " I mean, for example, people say that language models", "tokens": [51488, 286, 914, 11, 337, 1365, 11, 561, 584, 300, 2856, 5245, 51664], "temperature": 0.0, "avg_logprob": -0.14755988675494527, "compression_ratio": 1.5660377358490567, "no_speech_prob": 0.0024141359608620405}, {"id": 918, "seek": 246794, "start": 2467.94, "end": 2469.58, "text": " might enfee us,", "tokens": [50364, 1062, 10667, 1653, 505, 11, 50446], "temperature": 0.0, "avg_logprob": -0.14961245362187775, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.003533052047714591}, {"id": 919, "seek": 246794, "start": 2469.58, "end": 2473.02, "text": " they might lead to mass manipulation and persuasion.", "tokens": [50446, 436, 1062, 1477, 281, 2758, 26475, 293, 16336, 6822, 13, 50618], "temperature": 0.0, "avg_logprob": -0.14961245362187775, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.003533052047714591}, {"id": 920, "seek": 246794, "start": 2473.02, "end": 2475.2200000000003, "text": " I mean, Jan Lacoon tweeted the other day,", "tokens": [50618, 286, 914, 11, 4956, 40113, 4106, 25646, 264, 661, 786, 11, 50728], "temperature": 0.0, "avg_logprob": -0.14961245362187775, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.003533052047714591}, {"id": 921, "seek": 246794, "start": 2475.2200000000003, "end": 2478.14, "text": " he said, where's the mass manipulation?", "tokens": [50728, 415, 848, 11, 689, 311, 264, 2758, 26475, 30, 50874], "temperature": 0.0, "avg_logprob": -0.14961245362187775, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.003533052047714591}, {"id": 922, "seek": 246794, "start": 2478.14, "end": 2479.18, "text": " Where's the persuasion?", "tokens": [50874, 2305, 311, 264, 16336, 6822, 30, 50926], "temperature": 0.0, "avg_logprob": -0.14961245362187775, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.003533052047714591}, {"id": 923, "seek": 246794, "start": 2479.18, "end": 2481.58, "text": " There might be something that just happens gradually", "tokens": [50926, 821, 1062, 312, 746, 300, 445, 2314, 13145, 51046], "temperature": 0.0, "avg_logprob": -0.14961245362187775, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.003533052047714591}, {"id": 924, "seek": 246794, "start": 2481.58, "end": 2483.14, "text": " over time, but are there things", "tokens": [51046, 670, 565, 11, 457, 366, 456, 721, 51124], "temperature": 0.0, "avg_logprob": -0.14961245362187775, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.003533052047714591}, {"id": 925, "seek": 246794, "start": 2483.14, "end": 2485.26, "text": " that you do worry about?", "tokens": [51124, 300, 291, 360, 3292, 466, 30, 51230], "temperature": 0.0, "avg_logprob": -0.14961245362187775, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.003533052047714591}, {"id": 926, "seek": 246794, "start": 2485.26, "end": 2486.58, "text": " Of course, yeah, of course.", "tokens": [51230, 2720, 1164, 11, 1338, 11, 295, 1164, 13, 51296], "temperature": 0.0, "avg_logprob": -0.14961245362187775, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.003533052047714591}, {"id": 927, "seek": 246794, "start": 2486.58, "end": 2488.18, "text": " It's a general technology,", "tokens": [51296, 467, 311, 257, 2674, 2899, 11, 51376], "temperature": 0.0, "avg_logprob": -0.14961245362187775, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.003533052047714591}, {"id": 928, "seek": 246794, "start": 2488.18, "end": 2491.34, "text": " and so it can be used in a lot of different ways,", "tokens": [51376, 293, 370, 309, 393, 312, 1143, 294, 257, 688, 295, 819, 2098, 11, 51534], "temperature": 0.0, "avg_logprob": -0.14961245362187775, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.003533052047714591}, {"id": 929, "seek": 246794, "start": 2491.34, "end": 2493.5, "text": " many of which are, I think,", "tokens": [51534, 867, 295, 597, 366, 11, 286, 519, 11, 51642], "temperature": 0.0, "avg_logprob": -0.14961245362187775, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.003533052047714591}, {"id": 930, "seek": 246794, "start": 2493.5, "end": 2495.62, "text": " abhorrent and ones that we should avoid", "tokens": [51642, 410, 2335, 1753, 293, 2306, 300, 321, 820, 5042, 51748], "temperature": 0.0, "avg_logprob": -0.14961245362187775, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.003533052047714591}, {"id": 931, "seek": 246794, "start": 2495.62, "end": 2497.34, "text": " and make very difficult to do.", "tokens": [51748, 293, 652, 588, 2252, 281, 360, 13, 51834], "temperature": 0.0, "avg_logprob": -0.14961245362187775, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.003533052047714591}, {"id": 932, "seek": 249794, "start": 2498.94, "end": 2502.7000000000003, "text": " I'm much more of an optimist than I am a pessimist,", "tokens": [50414, 286, 478, 709, 544, 295, 364, 5028, 468, 813, 286, 669, 257, 37399, 468, 11, 50602], "temperature": 0.0, "avg_logprob": -0.10856440827086732, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0005355388857424259}, {"id": 933, "seek": 249794, "start": 2502.7000000000003, "end": 2506.66, "text": " but on the side of things that are risky,", "tokens": [50602, 457, 322, 264, 1252, 295, 721, 300, 366, 21137, 11, 50800], "temperature": 0.0, "avg_logprob": -0.10856440827086732, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0005355388857424259}, {"id": 934, "seek": 249794, "start": 2506.66, "end": 2509.98, "text": " I think that misinformation is high up on the list.", "tokens": [50800, 286, 519, 300, 34238, 307, 1090, 493, 322, 264, 1329, 13, 50966], "temperature": 0.0, "avg_logprob": -0.10856440827086732, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0005355388857424259}, {"id": 935, "seek": 249794, "start": 2509.98, "end": 2512.18, "text": " I think that we're already seeing", "tokens": [50966, 286, 519, 300, 321, 434, 1217, 2577, 51076], "temperature": 0.0, "avg_logprob": -0.10856440827086732, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0005355388857424259}, {"id": 936, "seek": 249794, "start": 2513.54, "end": 2516.7000000000003, "text": " social media platforms start to build in the mitigations.", "tokens": [51144, 2093, 3021, 9473, 722, 281, 1322, 294, 264, 15699, 763, 13, 51302], "temperature": 0.0, "avg_logprob": -0.10856440827086732, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0005355388857424259}, {"id": 937, "seek": 249794, "start": 2516.7000000000003, "end": 2518.5, "text": " I think things like human verification", "tokens": [51302, 286, 519, 721, 411, 1952, 30206, 51392], "temperature": 0.0, "avg_logprob": -0.10856440827086732, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0005355388857424259}, {"id": 938, "seek": 249794, "start": 2518.5, "end": 2519.78, "text": " are gonna become crucial.", "tokens": [51392, 366, 799, 1813, 11462, 13, 51456], "temperature": 0.0, "avg_logprob": -0.10856440827086732, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0005355388857424259}, {"id": 939, "seek": 249794, "start": 2520.7400000000002, "end": 2524.02, "text": " If I'm reading a poster talking about", "tokens": [51504, 759, 286, 478, 3760, 257, 17171, 1417, 466, 51668], "temperature": 0.0, "avg_logprob": -0.10856440827086732, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0005355388857424259}, {"id": 940, "seek": 252402, "start": 2524.94, "end": 2528.02, "text": " whatever Canadian elections or politicians,", "tokens": [50410, 2035, 12641, 12870, 420, 14756, 11, 50564], "temperature": 0.0, "avg_logprob": -0.09040051815556545, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.003271531080827117}, {"id": 941, "seek": 252402, "start": 2528.02, "end": 2531.62, "text": " I wanna know that that's a voting Canadian citizen.", "tokens": [50564, 286, 1948, 458, 300, 300, 311, 257, 10419, 12641, 13326, 13, 50744], "temperature": 0.0, "avg_logprob": -0.09040051815556545, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.003271531080827117}, {"id": 942, "seek": 252402, "start": 2531.62, "end": 2534.1, "text": " I wanna know, because I want to know", "tokens": [50744, 286, 1948, 458, 11, 570, 286, 528, 281, 458, 50868], "temperature": 0.0, "avg_logprob": -0.09040051815556545, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.003271531080827117}, {"id": 943, "seek": 252402, "start": 2534.1, "end": 2537.06, "text": " what my compatriots think, right?", "tokens": [50868, 437, 452, 13147, 470, 1971, 519, 11, 558, 30, 51016], "temperature": 0.0, "avg_logprob": -0.09040051815556545, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.003271531080827117}, {"id": 944, "seek": 252402, "start": 2537.06, "end": 2539.82, "text": " Even if they're on the opposite side of the fence to me,", "tokens": [51016, 2754, 498, 436, 434, 322, 264, 6182, 1252, 295, 264, 15422, 281, 385, 11, 51154], "temperature": 0.0, "avg_logprob": -0.09040051815556545, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.003271531080827117}, {"id": 945, "seek": 252402, "start": 2539.82, "end": 2540.86, "text": " like that's fine.", "tokens": [51154, 411, 300, 311, 2489, 13, 51206], "temperature": 0.0, "avg_logprob": -0.09040051815556545, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.003271531080827117}, {"id": 946, "seek": 252402, "start": 2540.86, "end": 2544.06, "text": " I wanna hear what they think,", "tokens": [51206, 286, 1948, 1568, 437, 436, 519, 11, 51366], "temperature": 0.0, "avg_logprob": -0.09040051815556545, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.003271531080827117}, {"id": 947, "seek": 252402, "start": 2545.14, "end": 2548.3, "text": " but I don't wanna hear what some foreign adversary", "tokens": [51420, 457, 286, 500, 380, 1948, 1568, 437, 512, 5329, 48222, 51578], "temperature": 0.0, "avg_logprob": -0.09040051815556545, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.003271531080827117}, {"id": 948, "seek": 252402, "start": 2548.3, "end": 2552.5, "text": " has spun up a bot to push into the discourse.", "tokens": [51578, 575, 37038, 493, 257, 10592, 281, 2944, 666, 264, 23938, 13, 51788], "temperature": 0.0, "avg_logprob": -0.09040051815556545, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.003271531080827117}, {"id": 949, "seek": 255250, "start": 2552.5, "end": 2556.46, "text": " And so human verification, I think, is crucial.", "tokens": [50364, 400, 370, 1952, 30206, 11, 286, 519, 11, 307, 11462, 13, 50562], "temperature": 0.0, "avg_logprob": -0.13457850722579268, "compression_ratio": 1.5737051792828685, "no_speech_prob": 0.0005353199667297304}, {"id": 950, "seek": 255250, "start": 2556.46, "end": 2559.06, "text": " That's the one that's top of mind for me.", "tokens": [50562, 663, 311, 264, 472, 300, 311, 1192, 295, 1575, 337, 385, 13, 50692], "temperature": 0.0, "avg_logprob": -0.13457850722579268, "compression_ratio": 1.5737051792828685, "no_speech_prob": 0.0005353199667297304}, {"id": 951, "seek": 255250, "start": 2559.06, "end": 2561.14, "text": " I think some of the more remote risks,", "tokens": [50692, 286, 519, 512, 295, 264, 544, 8607, 10888, 11, 50796], "temperature": 0.0, "avg_logprob": -0.13457850722579268, "compression_ratio": 1.5737051792828685, "no_speech_prob": 0.0005353199667297304}, {"id": 952, "seek": 255250, "start": 2561.14, "end": 2566.06, "text": " like bio weapons and this sort of stuff,", "tokens": [50796, 411, 12198, 7278, 293, 341, 1333, 295, 1507, 11, 51042], "temperature": 0.0, "avg_logprob": -0.13457850722579268, "compression_ratio": 1.5737051792828685, "no_speech_prob": 0.0005353199667297304}, {"id": 953, "seek": 255250, "start": 2566.06, "end": 2567.5, "text": " I'm less concerned about.", "tokens": [51042, 286, 478, 1570, 5922, 466, 13, 51114], "temperature": 0.0, "avg_logprob": -0.13457850722579268, "compression_ratio": 1.5737051792828685, "no_speech_prob": 0.0005353199667297304}, {"id": 954, "seek": 255250, "start": 2567.5, "end": 2571.1, "text": " In feeblement and becoming dependent on the technology,", "tokens": [51114, 682, 12054, 638, 518, 293, 5617, 12334, 322, 264, 2899, 11, 51294], "temperature": 0.0, "avg_logprob": -0.13457850722579268, "compression_ratio": 1.5737051792828685, "no_speech_prob": 0.0005353199667297304}, {"id": 955, "seek": 255250, "start": 2571.1, "end": 2573.34, "text": " I think folks said that about calculators", "tokens": [51294, 286, 519, 4024, 848, 300, 466, 4322, 3391, 51406], "temperature": 0.0, "avg_logprob": -0.13457850722579268, "compression_ratio": 1.5737051792828685, "no_speech_prob": 0.0005353199667297304}, {"id": 956, "seek": 255250, "start": 2573.34, "end": 2575.94, "text": " and we wouldn't learn how to do basic math.", "tokens": [51406, 293, 321, 2759, 380, 1466, 577, 281, 360, 3875, 5221, 13, 51536], "temperature": 0.0, "avg_logprob": -0.13457850722579268, "compression_ratio": 1.5737051792828685, "no_speech_prob": 0.0005353199667297304}, {"id": 957, "seek": 255250, "start": 2575.94, "end": 2579.66, "text": " Humans are intrinsically curious.", "tokens": [51536, 35809, 366, 28621, 984, 6369, 13, 51722], "temperature": 0.0, "avg_logprob": -0.13457850722579268, "compression_ratio": 1.5737051792828685, "no_speech_prob": 0.0005353199667297304}, {"id": 958, "seek": 255250, "start": 2579.66, "end": 2580.74, "text": " We want to know things,", "tokens": [51722, 492, 528, 281, 458, 721, 11, 51776], "temperature": 0.0, "avg_logprob": -0.13457850722579268, "compression_ratio": 1.5737051792828685, "no_speech_prob": 0.0005353199667297304}, {"id": 959, "seek": 258074, "start": 2580.74, "end": 2584.1, "text": " and we can't ask the right questions of machines", "tokens": [50364, 293, 321, 393, 380, 1029, 264, 558, 1651, 295, 8379, 50532], "temperature": 0.0, "avg_logprob": -0.1292734586275541, "compression_ratio": 1.611295681063123, "no_speech_prob": 0.00032269995426759124}, {"id": 960, "seek": 258074, "start": 2584.1, "end": 2585.62, "text": " without knowing things.", "tokens": [50532, 1553, 5276, 721, 13, 50608], "temperature": 0.0, "avg_logprob": -0.1292734586275541, "compression_ratio": 1.611295681063123, "no_speech_prob": 0.00032269995426759124}, {"id": 961, "seek": 258074, "start": 2585.62, "end": 2588.9799999999996, "text": " And so we'll continue to be really well educated,", "tokens": [50608, 400, 370, 321, 603, 2354, 281, 312, 534, 731, 15872, 11, 50776], "temperature": 0.0, "avg_logprob": -0.1292734586275541, "compression_ratio": 1.611295681063123, "no_speech_prob": 0.00032269995426759124}, {"id": 962, "seek": 258074, "start": 2588.9799999999996, "end": 2592.14, "text": " better educated, more knowledgeable than we were before", "tokens": [50776, 1101, 15872, 11, 544, 33800, 813, 321, 645, 949, 50934], "temperature": 0.0, "avg_logprob": -0.1292734586275541, "compression_ratio": 1.611295681063123, "no_speech_prob": 0.00032269995426759124}, {"id": 963, "seek": 258074, "start": 2592.14, "end": 2593.2599999999998, "text": " without that technology.", "tokens": [50934, 1553, 300, 2899, 13, 50990], "temperature": 0.0, "avg_logprob": -0.1292734586275541, "compression_ratio": 1.611295681063123, "no_speech_prob": 0.00032269995426759124}, {"id": 964, "seek": 258074, "start": 2593.2599999999998, "end": 2595.8199999999997, "text": " Yeah, because if you look at the enfeeblement pie chart,", "tokens": [50990, 865, 11, 570, 498, 291, 574, 412, 264, 10667, 1653, 638, 518, 1730, 6927, 11, 51118], "temperature": 0.0, "avg_logprob": -0.1292734586275541, "compression_ratio": 1.611295681063123, "no_speech_prob": 0.00032269995426759124}, {"id": 965, "seek": 258074, "start": 2595.8199999999997, "end": 2597.5, "text": " a calculator is a very small part", "tokens": [51118, 257, 24993, 307, 257, 588, 1359, 644, 51202], "temperature": 0.0, "avg_logprob": -0.1292734586275541, "compression_ratio": 1.611295681063123, "no_speech_prob": 0.00032269995426759124}, {"id": 966, "seek": 258074, "start": 2597.5, "end": 2599.9399999999996, "text": " and a general AI is quite a large part,", "tokens": [51202, 293, 257, 2674, 7318, 307, 1596, 257, 2416, 644, 11, 51324], "temperature": 0.0, "avg_logprob": -0.1292734586275541, "compression_ratio": 1.611295681063123, "no_speech_prob": 0.00032269995426759124}, {"id": 967, "seek": 258074, "start": 2599.9399999999996, "end": 2601.9399999999996, "text": " which is a little bit concerning, I guess,", "tokens": [51324, 597, 307, 257, 707, 857, 18087, 11, 286, 2041, 11, 51424], "temperature": 0.0, "avg_logprob": -0.1292734586275541, "compression_ratio": 1.611295681063123, "no_speech_prob": 0.00032269995426759124}, {"id": 968, "seek": 258074, "start": 2601.9399999999996, "end": 2606.9399999999996, "text": " but I agree with you that maybe the jobs one has spoken about.", "tokens": [51424, 457, 286, 3986, 365, 291, 300, 1310, 264, 4782, 472, 575, 10759, 466, 13, 51674], "temperature": 0.0, "avg_logprob": -0.1292734586275541, "compression_ratio": 1.611295681063123, "no_speech_prob": 0.00032269995426759124}, {"id": 969, "seek": 258074, "start": 2606.9399999999996, "end": 2608.5, "text": " I've not seen a lot of evidence of that yet,", "tokens": [51674, 286, 600, 406, 1612, 257, 688, 295, 4467, 295, 300, 1939, 11, 51752], "temperature": 0.0, "avg_logprob": -0.1292734586275541, "compression_ratio": 1.611295681063123, "no_speech_prob": 0.00032269995426759124}, {"id": 970, "seek": 260850, "start": 2608.5, "end": 2611.46, "text": " but it's so pernicious, it might happen slowly over time.", "tokens": [50364, 457, 309, 311, 370, 680, 77, 3784, 11, 309, 1062, 1051, 5692, 670, 565, 13, 50512], "temperature": 0.0, "avg_logprob": -0.1521295087090854, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.01069274079054594}, {"id": 971, "seek": 260850, "start": 2611.46, "end": 2613.22, "text": " Daniel Dennett wrote an interesting article,", "tokens": [50512, 8033, 19027, 3093, 4114, 364, 1880, 7222, 11, 50600], "temperature": 0.0, "avg_logprob": -0.1521295087090854, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.01069274079054594}, {"id": 972, "seek": 260850, "start": 2613.22, "end": 2615.18, "text": " and rest in peace, by the way,", "tokens": [50600, 293, 1472, 294, 4336, 11, 538, 264, 636, 11, 50698], "temperature": 0.0, "avg_logprob": -0.1521295087090854, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.01069274079054594}, {"id": 973, "seek": 260850, "start": 2615.18, "end": 2617.74, "text": " Daniel Dennett called Counterfeit People,", "tokens": [50698, 8033, 19027, 3093, 1219, 35607, 37434, 3432, 11, 50826], "temperature": 0.0, "avg_logprob": -0.1521295087090854, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.01069274079054594}, {"id": 974, "seek": 260850, "start": 2617.74, "end": 2619.02, "text": " which he published in The Atlantic,", "tokens": [50826, 597, 415, 6572, 294, 440, 20233, 11, 50890], "temperature": 0.0, "avg_logprob": -0.1521295087090854, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.01069274079054594}, {"id": 975, "seek": 260850, "start": 2619.02, "end": 2621.46, "text": " and he was kind of saying that when we have all of these bots", "tokens": [50890, 293, 415, 390, 733, 295, 1566, 300, 562, 321, 362, 439, 295, 613, 35410, 51012], "temperature": 0.0, "avg_logprob": -0.1521295087090854, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.01069274079054594}, {"id": 976, "seek": 260850, "start": 2621.46, "end": 2624.78, "text": " and generative video models and so on,", "tokens": [51012, 293, 1337, 1166, 960, 5245, 293, 370, 322, 11, 51178], "temperature": 0.0, "avg_logprob": -0.1521295087090854, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.01069274079054594}, {"id": 977, "seek": 260850, "start": 2624.78, "end": 2627.86, "text": " at some point they'll become indistinguishable from reality,", "tokens": [51178, 412, 512, 935, 436, 603, 1813, 1016, 468, 7050, 742, 712, 490, 4103, 11, 51332], "temperature": 0.0, "avg_logprob": -0.1521295087090854, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.01069274079054594}, {"id": 978, "seek": 260850, "start": 2627.86, "end": 2630.06, "text": " and that will lead to a kind of acquiescence", "tokens": [51332, 293, 300, 486, 1477, 281, 257, 733, 295, 6667, 530, 25434, 51442], "temperature": 0.0, "avg_logprob": -0.1521295087090854, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.01069274079054594}, {"id": 979, "seek": 260850, "start": 2630.06, "end": 2632.26, "text": " where we don't trust anything we see.", "tokens": [51442, 689, 321, 500, 380, 3361, 1340, 321, 536, 13, 51552], "temperature": 0.0, "avg_logprob": -0.1521295087090854, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.01069274079054594}, {"id": 980, "seek": 260850, "start": 2632.26, "end": 2635.02, "text": " And I think that's quite interesting,", "tokens": [51552, 400, 286, 519, 300, 311, 1596, 1880, 11, 51690], "temperature": 0.0, "avg_logprob": -0.1521295087090854, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.01069274079054594}, {"id": 981, "seek": 260850, "start": 2635.02, "end": 2637.3, "text": " and I also think that these models", "tokens": [51690, 293, 286, 611, 519, 300, 613, 5245, 51804], "temperature": 0.0, "avg_logprob": -0.1521295087090854, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.01069274079054594}, {"id": 982, "seek": 263730, "start": 2637.3, "end": 2640.94, "text": " might kind of affect our agency in quite a weird way,", "tokens": [50364, 1062, 733, 295, 3345, 527, 7934, 294, 1596, 257, 3657, 636, 11, 50546], "temperature": 0.0, "avg_logprob": -0.11788451571424469, "compression_ratio": 1.6197718631178708, "no_speech_prob": 0.002134394133463502}, {"id": 983, "seek": 263730, "start": 2640.94, "end": 2642.98, "text": " but it's so difficult to understand now", "tokens": [50546, 457, 309, 311, 370, 2252, 281, 1223, 586, 50648], "temperature": 0.0, "avg_logprob": -0.11788451571424469, "compression_ratio": 1.6197718631178708, "no_speech_prob": 0.002134394133463502}, {"id": 984, "seek": 263730, "start": 2642.98, "end": 2645.78, "text": " how that's going to affect society.", "tokens": [50648, 577, 300, 311, 516, 281, 3345, 4086, 13, 50788], "temperature": 0.0, "avg_logprob": -0.11788451571424469, "compression_ratio": 1.6197718631178708, "no_speech_prob": 0.002134394133463502}, {"id": 985, "seek": 263730, "start": 2645.78, "end": 2648.7000000000003, "text": " Yeah, I think even now,", "tokens": [50788, 865, 11, 286, 519, 754, 586, 11, 50934], "temperature": 0.0, "avg_logprob": -0.11788451571424469, "compression_ratio": 1.6197718631178708, "no_speech_prob": 0.002134394133463502}, {"id": 986, "seek": 263730, "start": 2648.7000000000003, "end": 2651.42, "text": " people have been taught to be extremely skeptical", "tokens": [50934, 561, 362, 668, 5928, 281, 312, 4664, 28601, 51070], "temperature": 0.0, "avg_logprob": -0.11788451571424469, "compression_ratio": 1.6197718631178708, "no_speech_prob": 0.002134394133463502}, {"id": 987, "seek": 263730, "start": 2651.42, "end": 2654.2200000000003, "text": " of what they read and see.", "tokens": [51070, 295, 437, 436, 1401, 293, 536, 13, 51210], "temperature": 0.0, "avg_logprob": -0.11788451571424469, "compression_ratio": 1.6197718631178708, "no_speech_prob": 0.002134394133463502}, {"id": 988, "seek": 263730, "start": 2654.2200000000003, "end": 2657.1000000000004, "text": " There's a very strong prior inside of us,", "tokens": [51210, 821, 311, 257, 588, 2068, 4059, 1854, 295, 505, 11, 51354], "temperature": 0.0, "avg_logprob": -0.11788451571424469, "compression_ratio": 1.6197718631178708, "no_speech_prob": 0.002134394133463502}, {"id": 989, "seek": 263730, "start": 2657.1000000000004, "end": 2658.38, "text": " for any media that we consume,", "tokens": [51354, 337, 604, 3021, 300, 321, 14732, 11, 51418], "temperature": 0.0, "avg_logprob": -0.11788451571424469, "compression_ratio": 1.6197718631178708, "no_speech_prob": 0.002134394133463502}, {"id": 990, "seek": 263730, "start": 2658.38, "end": 2661.1000000000004, "text": " that it's been skewed or manipulated", "tokens": [51418, 300, 309, 311, 668, 8756, 26896, 420, 37161, 51554], "temperature": 0.0, "avg_logprob": -0.11788451571424469, "compression_ratio": 1.6197718631178708, "no_speech_prob": 0.002134394133463502}, {"id": 991, "seek": 263730, "start": 2661.1000000000004, "end": 2664.42, "text": " or produced to propagate an idea,", "tokens": [51554, 420, 7126, 281, 48256, 364, 1558, 11, 51720], "temperature": 0.0, "avg_logprob": -0.11788451571424469, "compression_ratio": 1.6197718631178708, "no_speech_prob": 0.002134394133463502}, {"id": 992, "seek": 263730, "start": 2664.42, "end": 2666.78, "text": " and I think it's good to have a skeptical populace.", "tokens": [51720, 293, 286, 519, 309, 311, 665, 281, 362, 257, 28601, 24017, 617, 13, 51838], "temperature": 0.0, "avg_logprob": -0.11788451571424469, "compression_ratio": 1.6197718631178708, "no_speech_prob": 0.002134394133463502}, {"id": 993, "seek": 266678, "start": 2666.78, "end": 2668.5, "text": " I think it's good to be skeptical", "tokens": [50364, 286, 519, 309, 311, 665, 281, 312, 28601, 50450], "temperature": 0.0, "avg_logprob": -0.15605175133907434, "compression_ratio": 1.6, "no_speech_prob": 6.81369419908151e-05}, {"id": 994, "seek": 266678, "start": 2668.5, "end": 2672.02, "text": " about what you read, regardless of the medium.", "tokens": [50450, 466, 437, 291, 1401, 11, 10060, 295, 264, 6399, 13, 50626], "temperature": 0.0, "avg_logprob": -0.15605175133907434, "compression_ratio": 1.6, "no_speech_prob": 6.81369419908151e-05}, {"id": 995, "seek": 266678, "start": 2672.02, "end": 2674.02, "text": " And I think people will do what they've always done,", "tokens": [50626, 400, 286, 519, 561, 486, 360, 437, 436, 600, 1009, 1096, 11, 50726], "temperature": 0.0, "avg_logprob": -0.15605175133907434, "compression_ratio": 1.6, "no_speech_prob": 6.81369419908151e-05}, {"id": 996, "seek": 266678, "start": 2674.02, "end": 2676.26, "text": " which is filter towards sources", "tokens": [50726, 597, 307, 6608, 3030, 7139, 50838], "temperature": 0.0, "avg_logprob": -0.15605175133907434, "compression_ratio": 1.6, "no_speech_prob": 6.81369419908151e-05}, {"id": 997, "seek": 266678, "start": 2676.26, "end": 2678.1400000000003, "text": " they find trustworthy and objective.", "tokens": [50838, 436, 915, 39714, 293, 10024, 13, 50932], "temperature": 0.0, "avg_logprob": -0.15605175133907434, "compression_ratio": 1.6, "no_speech_prob": 6.81369419908151e-05}, {"id": 998, "seek": 266678, "start": 2680.2200000000003, "end": 2683.82, "text": " That'll happen even with ML and the loop,", "tokens": [51036, 663, 603, 1051, 754, 365, 21601, 293, 264, 6367, 11, 51216], "temperature": 0.0, "avg_logprob": -0.15605175133907434, "compression_ratio": 1.6, "no_speech_prob": 6.81369419908151e-05}, {"id": 999, "seek": 266678, "start": 2683.82, "end": 2685.94, "text": " disinformation and misinformation campaigns,", "tokens": [51216, 717, 20941, 293, 34238, 16840, 11, 51322], "temperature": 0.0, "avg_logprob": -0.15605175133907434, "compression_ratio": 1.6, "no_speech_prob": 6.81369419908151e-05}, {"id": 1000, "seek": 266678, "start": 2685.94, "end": 2687.26, "text": " manipulation campaigns,", "tokens": [51322, 26475, 16840, 11, 51388], "temperature": 0.0, "avg_logprob": -0.15605175133907434, "compression_ratio": 1.6, "no_speech_prob": 6.81369419908151e-05}, {"id": 1001, "seek": 266678, "start": 2687.26, "end": 2690.5, "text": " they existed well before models existed.", "tokens": [51388, 436, 13135, 731, 949, 5245, 13135, 13, 51550], "temperature": 0.0, "avg_logprob": -0.15605175133907434, "compression_ratio": 1.6, "no_speech_prob": 6.81369419908151e-05}, {"id": 1002, "seek": 266678, "start": 2691.78, "end": 2694.7000000000003, "text": " And so it's not like a novel concept,", "tokens": [51614, 400, 370, 309, 311, 406, 411, 257, 7613, 3410, 11, 51760], "temperature": 0.0, "avg_logprob": -0.15605175133907434, "compression_ratio": 1.6, "no_speech_prob": 6.81369419908151e-05}, {"id": 1003, "seek": 269470, "start": 2694.98, "end": 2696.46, "text": " and it's always been a risk.", "tokens": [50378, 293, 309, 311, 1009, 668, 257, 3148, 13, 50452], "temperature": 0.0, "avg_logprob": -0.11406593130092428, "compression_ratio": 1.6272727272727272, "no_speech_prob": 0.0011006576241925359}, {"id": 1004, "seek": 269470, "start": 2697.66, "end": 2700.8599999999997, "text": " And the question is how much more prevalent", "tokens": [50512, 400, 264, 1168, 307, 577, 709, 544, 30652, 50672], "temperature": 0.0, "avg_logprob": -0.11406593130092428, "compression_ratio": 1.6272727272727272, "no_speech_prob": 0.0011006576241925359}, {"id": 1005, "seek": 269470, "start": 2700.8599999999997, "end": 2703.8999999999996, "text": " does the technology make that risk?", "tokens": [50672, 775, 264, 2899, 652, 300, 3148, 30, 50824], "temperature": 0.0, "avg_logprob": -0.11406593130092428, "compression_ratio": 1.6272727272727272, "no_speech_prob": 0.0011006576241925359}, {"id": 1006, "seek": 269470, "start": 2705.62, "end": 2709.2599999999998, "text": " I'm optimistic that we're quite robust", "tokens": [50910, 286, 478, 19397, 300, 321, 434, 1596, 13956, 51092], "temperature": 0.0, "avg_logprob": -0.11406593130092428, "compression_ratio": 1.6272727272727272, "no_speech_prob": 0.0011006576241925359}, {"id": 1007, "seek": 269470, "start": 2709.2599999999998, "end": 2713.1, "text": " and that we'll find ways to make it very hard", "tokens": [51092, 293, 300, 321, 603, 915, 2098, 281, 652, 309, 588, 1152, 51284], "temperature": 0.0, "avg_logprob": -0.11406593130092428, "compression_ratio": 1.6272727272727272, "no_speech_prob": 0.0011006576241925359}, {"id": 1008, "seek": 269470, "start": 2713.1, "end": 2715.22, "text": " for bad actors to exploit the technology.", "tokens": [51284, 337, 1578, 10037, 281, 25924, 264, 2899, 13, 51390], "temperature": 0.0, "avg_logprob": -0.11406593130092428, "compression_ratio": 1.6272727272727272, "no_speech_prob": 0.0011006576241925359}, {"id": 1009, "seek": 269470, "start": 2715.22, "end": 2718.74, "text": " My rough take is that the more agency the AI has,", "tokens": [51390, 1222, 5903, 747, 307, 300, 264, 544, 7934, 264, 7318, 575, 11, 51566], "temperature": 0.0, "avg_logprob": -0.11406593130092428, "compression_ratio": 1.6272727272727272, "no_speech_prob": 0.0011006576241925359}, {"id": 1010, "seek": 269470, "start": 2718.74, "end": 2720.02, "text": " the more of a risk it is,", "tokens": [51566, 264, 544, 295, 257, 3148, 309, 307, 11, 51630], "temperature": 0.0, "avg_logprob": -0.11406593130092428, "compression_ratio": 1.6272727272727272, "no_speech_prob": 0.0011006576241925359}, {"id": 1011, "seek": 269470, "start": 2720.02, "end": 2722.7799999999997, "text": " because if it is just doing supervised things,", "tokens": [51630, 570, 498, 309, 307, 445, 884, 46533, 721, 11, 51768], "temperature": 0.0, "avg_logprob": -0.11406593130092428, "compression_ratio": 1.6272727272727272, "no_speech_prob": 0.0011006576241925359}, {"id": 1012, "seek": 272278, "start": 2722.82, "end": 2725.34, "text": " then every step of the process,", "tokens": [50366, 550, 633, 1823, 295, 264, 1399, 11, 50492], "temperature": 0.0, "avg_logprob": -0.10186989051251372, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.0015324255218729377}, {"id": 1013, "seek": 272278, "start": 2725.34, "end": 2729.0600000000004, "text": " it's being aligned and constrained and steered by humans.", "tokens": [50492, 309, 311, 885, 17962, 293, 38901, 293, 2126, 4073, 538, 6255, 13, 50678], "temperature": 0.0, "avg_logprob": -0.10186989051251372, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.0015324255218729377}, {"id": 1014, "seek": 272278, "start": 2729.0600000000004, "end": 2731.42, "text": " If we ever did create a gentile AI,", "tokens": [50678, 759, 321, 1562, 630, 1884, 257, 16108, 794, 7318, 11, 50796], "temperature": 0.0, "avg_logprob": -0.10186989051251372, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.0015324255218729377}, {"id": 1015, "seek": 272278, "start": 2731.42, "end": 2734.26, "text": " then there's this kind of weird divergence", "tokens": [50796, 550, 456, 311, 341, 733, 295, 3657, 47387, 50938], "temperature": 0.0, "avg_logprob": -0.10186989051251372, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.0015324255218729377}, {"id": 1016, "seek": 272278, "start": 2734.26, "end": 2736.78, "text": " and all sorts of scary things might happen.", "tokens": [50938, 293, 439, 7527, 295, 6958, 721, 1062, 1051, 13, 51064], "temperature": 0.0, "avg_logprob": -0.10186989051251372, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.0015324255218729377}, {"id": 1017, "seek": 272278, "start": 2736.78, "end": 2738.34, "text": " But I wanted to talk a little bit", "tokens": [51064, 583, 286, 1415, 281, 751, 257, 707, 857, 51142], "temperature": 0.0, "avg_logprob": -0.10186989051251372, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.0015324255218729377}, {"id": 1018, "seek": 272278, "start": 2738.34, "end": 2739.9, "text": " about policy and regulation.", "tokens": [51142, 466, 3897, 293, 15062, 13, 51220], "temperature": 0.0, "avg_logprob": -0.10186989051251372, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.0015324255218729377}, {"id": 1019, "seek": 272278, "start": 2739.9, "end": 2741.1000000000004, "text": " So you spoke to that earlier,", "tokens": [51220, 407, 291, 7179, 281, 300, 3071, 11, 51280], "temperature": 0.0, "avg_logprob": -0.10186989051251372, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.0015324255218729377}, {"id": 1020, "seek": 272278, "start": 2741.1000000000004, "end": 2743.3, "text": " you said that potentially there are some", "tokens": [51280, 291, 848, 300, 7263, 456, 366, 512, 51390], "temperature": 0.0, "avg_logprob": -0.10186989051251372, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.0015324255218729377}, {"id": 1021, "seek": 272278, "start": 2743.3, "end": 2746.7000000000003, "text": " quite damaging policy changes being considered.", "tokens": [51390, 1596, 25342, 3897, 2962, 885, 4888, 13, 51560], "temperature": 0.0, "avg_logprob": -0.10186989051251372, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.0015324255218729377}, {"id": 1022, "seek": 272278, "start": 2746.7000000000003, "end": 2747.5400000000004, "text": " Could you speak to that?", "tokens": [51560, 7497, 291, 1710, 281, 300, 30, 51602], "temperature": 0.0, "avg_logprob": -0.10186989051251372, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.0015324255218729377}, {"id": 1023, "seek": 272278, "start": 2747.5400000000004, "end": 2750.1800000000003, "text": " Yeah, I've seen ideas floated.", "tokens": [51602, 865, 11, 286, 600, 1612, 3487, 2591, 770, 13, 51734], "temperature": 0.0, "avg_logprob": -0.10186989051251372, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.0015324255218729377}, {"id": 1024, "seek": 275018, "start": 2750.18, "end": 2753.3799999999997, "text": " I don't think any seriously damaging policy", "tokens": [50364, 286, 500, 380, 519, 604, 6638, 25342, 3897, 50524], "temperature": 0.0, "avg_logprob": -0.14020988858979325, "compression_ratio": 1.5136363636363637, "no_speech_prob": 0.00017947849119082093}, {"id": 1025, "seek": 275018, "start": 2753.3799999999997, "end": 2755.8599999999997, "text": " has actually passed, fortunately.", "tokens": [50524, 575, 767, 4678, 11, 25511, 13, 50648], "temperature": 0.0, "avg_logprob": -0.14020988858979325, "compression_ratio": 1.5136363636363637, "no_speech_prob": 0.00017947849119082093}, {"id": 1026, "seek": 275018, "start": 2755.8599999999997, "end": 2757.94, "text": " But within what's being considered,", "tokens": [50648, 583, 1951, 437, 311, 885, 4888, 11, 50752], "temperature": 0.0, "avg_logprob": -0.14020988858979325, "compression_ratio": 1.5136363636363637, "no_speech_prob": 0.00017947849119082093}, {"id": 1027, "seek": 275018, "start": 2757.94, "end": 2762.2999999999997, "text": " there are ideas that they will destroy innovation,", "tokens": [50752, 456, 366, 3487, 300, 436, 486, 5293, 8504, 11, 50970], "temperature": 0.0, "avg_logprob": -0.14020988858979325, "compression_ratio": 1.5136363636363637, "no_speech_prob": 0.00017947849119082093}, {"id": 1028, "seek": 275018, "start": 2762.2999999999997, "end": 2763.62, "text": " they will destroy startups.", "tokens": [50970, 436, 486, 5293, 28041, 13, 51036], "temperature": 0.0, "avg_logprob": -0.14020988858979325, "compression_ratio": 1.5136363636363637, "no_speech_prob": 0.00017947849119082093}, {"id": 1029, "seek": 275018, "start": 2765.02, "end": 2766.8599999999997, "text": " And so you'll just entrench power", "tokens": [51106, 400, 370, 291, 603, 445, 948, 4442, 1347, 51198], "temperature": 0.0, "avg_logprob": -0.14020988858979325, "compression_ratio": 1.5136363636363637, "no_speech_prob": 0.00017947849119082093}, {"id": 1030, "seek": 275018, "start": 2766.8599999999997, "end": 2768.58, "text": " with the existing incumbents.", "tokens": [51198, 365, 264, 6741, 39854, 791, 13, 51284], "temperature": 0.0, "avg_logprob": -0.14020988858979325, "compression_ratio": 1.5136363636363637, "no_speech_prob": 0.00017947849119082093}, {"id": 1031, "seek": 275018, "start": 2769.5, "end": 2773.3399999999997, "text": " Some of those examples might be fines,", "tokens": [51330, 2188, 295, 729, 5110, 1062, 312, 37989, 11, 51522], "temperature": 0.0, "avg_logprob": -0.14020988858979325, "compression_ratio": 1.5136363636363637, "no_speech_prob": 0.00017947849119082093}, {"id": 1032, "seek": 275018, "start": 2774.3399999999997, "end": 2777.22, "text": " which if they're a $100 million fine,", "tokens": [51572, 597, 498, 436, 434, 257, 1848, 6879, 2459, 2489, 11, 51716], "temperature": 0.0, "avg_logprob": -0.14020988858979325, "compression_ratio": 1.5136363636363637, "no_speech_prob": 0.00017947849119082093}, {"id": 1033, "seek": 277722, "start": 2777.2599999999998, "end": 2780.62, "text": " that's gonna wipe out and stamp out a startup.", "tokens": [50366, 300, 311, 799, 14082, 484, 293, 9921, 484, 257, 18578, 13, 50534], "temperature": 0.0, "avg_logprob": -0.14522994330169958, "compression_ratio": 1.5405405405405406, "no_speech_prob": 0.0006262126262299716}, {"id": 1034, "seek": 277722, "start": 2780.62, "end": 2784.7, "text": " But for a large, you know, big tech company,", "tokens": [50534, 583, 337, 257, 2416, 11, 291, 458, 11, 955, 7553, 2237, 11, 50738], "temperature": 0.0, "avg_logprob": -0.14522994330169958, "compression_ratio": 1.5405405405405406, "no_speech_prob": 0.0006262126262299716}, {"id": 1035, "seek": 277722, "start": 2784.7, "end": 2787.14, "text": " it's like 10 minutes of revenue.", "tokens": [50738, 309, 311, 411, 1266, 2077, 295, 9324, 13, 50860], "temperature": 0.0, "avg_logprob": -0.14522994330169958, "compression_ratio": 1.5405405405405406, "no_speech_prob": 0.0006262126262299716}, {"id": 1036, "seek": 277722, "start": 2787.14, "end": 2788.14, "text": " It just doesn't matter.", "tokens": [50860, 467, 445, 1177, 380, 1871, 13, 50910], "temperature": 0.0, "avg_logprob": -0.14522994330169958, "compression_ratio": 1.5405405405405406, "no_speech_prob": 0.0006262126262299716}, {"id": 1037, "seek": 277722, "start": 2788.14, "end": 2789.7799999999997, "text": " It fundamentally is irrelevant.", "tokens": [50910, 467, 17879, 307, 28682, 13, 50992], "temperature": 0.0, "avg_logprob": -0.14522994330169958, "compression_ratio": 1.5405405405405406, "no_speech_prob": 0.0006262126262299716}, {"id": 1038, "seek": 277722, "start": 2789.7799999999997, "end": 2792.02, "text": " And certainly a cost they're willing to take", "tokens": [50992, 400, 3297, 257, 2063, 436, 434, 4950, 281, 747, 51104], "temperature": 0.0, "avg_logprob": -0.14522994330169958, "compression_ratio": 1.5405405405405406, "no_speech_prob": 0.0006262126262299716}, {"id": 1039, "seek": 277722, "start": 2792.02, "end": 2793.18, "text": " to capture a market.", "tokens": [51104, 281, 7983, 257, 2142, 13, 51162], "temperature": 0.0, "avg_logprob": -0.14522994330169958, "compression_ratio": 1.5405405405405406, "no_speech_prob": 0.0006262126262299716}, {"id": 1040, "seek": 277722, "start": 2794.8199999999997, "end": 2797.8199999999997, "text": " And so very disproportionate consequences", "tokens": [51244, 400, 370, 588, 28734, 473, 10098, 51394], "temperature": 0.0, "avg_logprob": -0.14522994330169958, "compression_ratio": 1.5405405405405406, "no_speech_prob": 0.0006262126262299716}, {"id": 1041, "seek": 277722, "start": 2797.8199999999997, "end": 2801.4199999999996, "text": " for the same punishment.", "tokens": [51394, 337, 264, 912, 14133, 13, 51574], "temperature": 0.0, "avg_logprob": -0.14522994330169958, "compression_ratio": 1.5405405405405406, "no_speech_prob": 0.0006262126262299716}, {"id": 1042, "seek": 277722, "start": 2801.4199999999996, "end": 2805.18, "text": " Over-regulation in that way that it's thoughtless", "tokens": [51574, 4886, 12, 3375, 2776, 294, 300, 636, 300, 309, 311, 1194, 1832, 51762], "temperature": 0.0, "avg_logprob": -0.14522994330169958, "compression_ratio": 1.5405405405405406, "no_speech_prob": 0.0006262126262299716}, {"id": 1043, "seek": 277722, "start": 2805.18, "end": 2807.02, "text": " will have the exact opposite effect", "tokens": [51762, 486, 362, 264, 1900, 6182, 1802, 51854], "temperature": 0.0, "avg_logprob": -0.14522994330169958, "compression_ratio": 1.5405405405405406, "no_speech_prob": 0.0006262126262299716}, {"id": 1044, "seek": 280702, "start": 2807.02, "end": 2809.86, "text": " of what I think all of us in the public", "tokens": [50364, 295, 437, 286, 519, 439, 295, 505, 294, 264, 1908, 50506], "temperature": 0.0, "avg_logprob": -0.1260224991485852, "compression_ratio": 1.7033898305084745, "no_speech_prob": 0.0003918970178347081}, {"id": 1045, "seek": 280702, "start": 2809.86, "end": 2811.34, "text": " and in government want.", "tokens": [50506, 293, 294, 2463, 528, 13, 50580], "temperature": 0.0, "avg_logprob": -0.1260224991485852, "compression_ratio": 1.7033898305084745, "no_speech_prob": 0.0003918970178347081}, {"id": 1046, "seek": 280702, "start": 2811.34, "end": 2812.98, "text": " We want competitive markets.", "tokens": [50580, 492, 528, 10043, 8383, 13, 50662], "temperature": 0.0, "avg_logprob": -0.1260224991485852, "compression_ratio": 1.7033898305084745, "no_speech_prob": 0.0003918970178347081}, {"id": 1047, "seek": 280702, "start": 2812.98, "end": 2814.9, "text": " We don't want oligopolies.", "tokens": [50662, 492, 500, 380, 528, 2545, 328, 19946, 530, 13, 50758], "temperature": 0.0, "avg_logprob": -0.1260224991485852, "compression_ratio": 1.7033898305084745, "no_speech_prob": 0.0003918970178347081}, {"id": 1048, "seek": 280702, "start": 2815.74, "end": 2818.58, "text": " And we're starting to see oligopolies emerge.", "tokens": [50800, 400, 321, 434, 2891, 281, 536, 2545, 328, 19946, 530, 21511, 13, 50942], "temperature": 0.0, "avg_logprob": -0.1260224991485852, "compression_ratio": 1.7033898305084745, "no_speech_prob": 0.0003918970178347081}, {"id": 1049, "seek": 280702, "start": 2818.58, "end": 2822.54, "text": " And so there needs to be fairly strong action", "tokens": [50942, 400, 370, 456, 2203, 281, 312, 6457, 2068, 3069, 51140], "temperature": 0.0, "avg_logprob": -0.1260224991485852, "compression_ratio": 1.7033898305084745, "no_speech_prob": 0.0003918970178347081}, {"id": 1050, "seek": 280702, "start": 2822.54, "end": 2825.5, "text": " pushing against the entrenchment of those oligopolies.", "tokens": [51140, 7380, 1970, 264, 948, 4442, 518, 295, 729, 2545, 328, 19946, 530, 13, 51288], "temperature": 0.0, "avg_logprob": -0.1260224991485852, "compression_ratio": 1.7033898305084745, "no_speech_prob": 0.0003918970178347081}, {"id": 1051, "seek": 280702, "start": 2825.5, "end": 2829.86, "text": " And we need to preserve the ability to self-disrupt.", "tokens": [51288, 400, 321, 643, 281, 15665, 264, 3485, 281, 2698, 12, 13731, 5428, 13, 51506], "temperature": 0.0, "avg_logprob": -0.1260224991485852, "compression_ratio": 1.7033898305084745, "no_speech_prob": 0.0003918970178347081}, {"id": 1052, "seek": 280702, "start": 2829.86, "end": 2832.1, "text": " Because if you can't, if you have an oligopoly", "tokens": [51506, 1436, 498, 291, 393, 380, 11, 498, 291, 362, 364, 2545, 328, 27891, 51618], "temperature": 0.0, "avg_logprob": -0.1260224991485852, "compression_ratio": 1.7033898305084745, "no_speech_prob": 0.0003918970178347081}, {"id": 1053, "seek": 280702, "start": 2832.1, "end": 2833.9, "text": " and you have entrenched incumbents,", "tokens": [51618, 293, 291, 362, 948, 42388, 39854, 791, 11, 51708], "temperature": 0.0, "avg_logprob": -0.1260224991485852, "compression_ratio": 1.7033898305084745, "no_speech_prob": 0.0003918970178347081}, {"id": 1054, "seek": 283390, "start": 2834.62, "end": 2838.5, "text": " the likelihood of self-disrupting,", "tokens": [50400, 264, 22119, 295, 2698, 12, 13731, 5428, 278, 11, 50594], "temperature": 0.0, "avg_logprob": -0.16152943397054867, "compression_ratio": 1.6255924170616114, "no_speech_prob": 0.00017950267647393048}, {"id": 1055, "seek": 283390, "start": 2838.5, "end": 2841.9, "text": " of the new winner emerging within your market,", "tokens": [50594, 295, 264, 777, 8507, 14989, 1951, 428, 2142, 11, 50764], "temperature": 0.0, "avg_logprob": -0.16152943397054867, "compression_ratio": 1.6255924170616114, "no_speech_prob": 0.00017950267647393048}, {"id": 1056, "seek": 283390, "start": 2841.9, "end": 2844.48, "text": " being one of your players, goes down.", "tokens": [50764, 885, 472, 295, 428, 4150, 11, 1709, 760, 13, 50893], "temperature": 0.0, "avg_logprob": -0.16152943397054867, "compression_ratio": 1.6255924170616114, "no_speech_prob": 0.00017950267647393048}, {"id": 1057, "seek": 283390, "start": 2844.48, "end": 2847.3, "text": " And so you're gonna be disrupted from outside.", "tokens": [50893, 400, 370, 291, 434, 799, 312, 42271, 490, 2380, 13, 51034], "temperature": 0.0, "avg_logprob": -0.16152943397054867, "compression_ratio": 1.6255924170616114, "no_speech_prob": 0.00017950267647393048}, {"id": 1058, "seek": 283390, "start": 2847.3, "end": 2848.38, "text": " That's a huge risk.", "tokens": [51034, 663, 311, 257, 2603, 3148, 13, 51088], "temperature": 0.0, "avg_logprob": -0.16152943397054867, "compression_ratio": 1.6255924170616114, "no_speech_prob": 0.00017950267647393048}, {"id": 1059, "seek": 283390, "start": 2848.38, "end": 2851.82, "text": " And so you need competitive, self-disrupting markets.", "tokens": [51088, 400, 370, 291, 643, 10043, 11, 2698, 12, 13731, 5428, 278, 8383, 13, 51260], "temperature": 0.0, "avg_logprob": -0.16152943397054867, "compression_ratio": 1.6255924170616114, "no_speech_prob": 0.00017950267647393048}, {"id": 1060, "seek": 283390, "start": 2851.82, "end": 2855.62, "text": " And it seems like some of the policy folks", "tokens": [51260, 400, 309, 2544, 411, 512, 295, 264, 3897, 4024, 51450], "temperature": 0.0, "avg_logprob": -0.16152943397054867, "compression_ratio": 1.6255924170616114, "no_speech_prob": 0.00017950267647393048}, {"id": 1061, "seek": 283390, "start": 2855.62, "end": 2857.54, "text": " are just acting non-strategically", "tokens": [51450, 366, 445, 6577, 2107, 12, 9733, 2968, 984, 51546], "temperature": 0.0, "avg_logprob": -0.16152943397054867, "compression_ratio": 1.6255924170616114, "no_speech_prob": 0.00017950267647393048}, {"id": 1062, "seek": 283390, "start": 2857.54, "end": 2860.14, "text": " and not considering that.", "tokens": [51546, 293, 406, 8079, 300, 13, 51676], "temperature": 0.0, "avg_logprob": -0.16152943397054867, "compression_ratio": 1.6255924170616114, "no_speech_prob": 0.00017950267647393048}, {"id": 1063, "seek": 286014, "start": 2861.1, "end": 2865.98, "text": " But fortunately, what has been passed seems sensible.", "tokens": [50412, 583, 25511, 11, 437, 575, 668, 4678, 2544, 25380, 13, 50656], "temperature": 0.0, "avg_logprob": -0.18260935128453265, "compression_ratio": 1.5507246376811594, "no_speech_prob": 0.001671666745096445}, {"id": 1064, "seek": 286014, "start": 2865.98, "end": 2867.74, "text": " Can you comment in particular", "tokens": [50656, 1664, 291, 2871, 294, 1729, 50744], "temperature": 0.0, "avg_logprob": -0.18260935128453265, "compression_ratio": 1.5507246376811594, "no_speech_prob": 0.001671666745096445}, {"id": 1065, "seek": 286014, "start": 2867.74, "end": 2872.74, "text": " on the EU AI legislation and the Canadian?", "tokens": [50744, 322, 264, 10887, 7318, 11329, 293, 264, 12641, 30, 50994], "temperature": 0.0, "avg_logprob": -0.18260935128453265, "compression_ratio": 1.5507246376811594, "no_speech_prob": 0.001671666745096445}, {"id": 1066, "seek": 286014, "start": 2872.8199999999997, "end": 2875.18, "text": " I probably can't say anything too specific.", "tokens": [50998, 286, 1391, 393, 380, 584, 1340, 886, 2685, 13, 51116], "temperature": 0.0, "avg_logprob": -0.18260935128453265, "compression_ratio": 1.5507246376811594, "no_speech_prob": 0.001671666745096445}, {"id": 1067, "seek": 286014, "start": 2875.18, "end": 2880.1, "text": " I think the Canadian legislation hasn't gone through yet.", "tokens": [51116, 286, 519, 264, 12641, 11329, 6132, 380, 2780, 807, 1939, 13, 51362], "temperature": 0.0, "avg_logprob": -0.18260935128453265, "compression_ratio": 1.5507246376811594, "no_speech_prob": 0.001671666745096445}, {"id": 1068, "seek": 286014, "start": 2880.1, "end": 2883.74, "text": " The EU AI Act has, but fortunately,", "tokens": [51362, 440, 10887, 7318, 3251, 575, 11, 457, 25511, 11, 51544], "temperature": 0.0, "avg_logprob": -0.18260935128453265, "compression_ratio": 1.5507246376811594, "no_speech_prob": 0.001671666745096445}, {"id": 1069, "seek": 286014, "start": 2883.74, "end": 2886.42, "text": " it was reigned quite far back", "tokens": [51544, 309, 390, 319, 16690, 1596, 1400, 646, 51678], "temperature": 0.0, "avg_logprob": -0.18260935128453265, "compression_ratio": 1.5507246376811594, "no_speech_prob": 0.001671666745096445}, {"id": 1070, "seek": 286014, "start": 2886.42, "end": 2889.2599999999998, "text": " from its initial position.", "tokens": [51678, 490, 1080, 5883, 2535, 13, 51820], "temperature": 0.0, "avg_logprob": -0.18260935128453265, "compression_ratio": 1.5507246376811594, "no_speech_prob": 0.001671666745096445}, {"id": 1071, "seek": 288926, "start": 2889.26, "end": 2891.3, "text": " I think all of those regulators were in conversation", "tokens": [50364, 286, 519, 439, 295, 729, 37311, 645, 294, 3761, 50466], "temperature": 0.0, "avg_logprob": -0.14541392856174046, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.00041063284152187407}, {"id": 1072, "seek": 288926, "start": 2891.3, "end": 2895.0200000000004, "text": " with all of them when you talk to the folks,", "tokens": [50466, 365, 439, 295, 552, 562, 291, 751, 281, 264, 4024, 11, 50652], "temperature": 0.0, "avg_logprob": -0.14541392856174046, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.00041063284152187407}, {"id": 1073, "seek": 288926, "start": 2895.0200000000004, "end": 2896.7400000000002, "text": " they wanna do the right thing.", "tokens": [50652, 436, 1948, 360, 264, 558, 551, 13, 50738], "temperature": 0.0, "avg_logprob": -0.14541392856174046, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.00041063284152187407}, {"id": 1074, "seek": 288926, "start": 2896.7400000000002, "end": 2899.0600000000004, "text": " They're under a lot of pressure from different parties", "tokens": [50738, 814, 434, 833, 257, 688, 295, 3321, 490, 819, 8265, 50854], "temperature": 0.0, "avg_logprob": -0.14541392856174046, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.00041063284152187407}, {"id": 1075, "seek": 288926, "start": 2899.0600000000004, "end": 2902.34, "text": " with conflicting interests,", "tokens": [50854, 365, 43784, 8847, 11, 51018], "temperature": 0.0, "avg_logprob": -0.14541392856174046, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.00041063284152187407}, {"id": 1076, "seek": 288926, "start": 2902.34, "end": 2903.3, "text": " but they're trying to do the right thing.", "tokens": [51018, 457, 436, 434, 1382, 281, 360, 264, 558, 551, 13, 51066], "temperature": 0.0, "avg_logprob": -0.14541392856174046, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.00041063284152187407}, {"id": 1077, "seek": 288926, "start": 2903.3, "end": 2904.5400000000004, "text": " They're trying to make sure this technology", "tokens": [51066, 814, 434, 1382, 281, 652, 988, 341, 2899, 51128], "temperature": 0.0, "avg_logprob": -0.14541392856174046, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.00041063284152187407}, {"id": 1078, "seek": 288926, "start": 2904.5400000000004, "end": 2906.1400000000003, "text": " gets out into the world in a safe way,", "tokens": [51128, 2170, 484, 666, 264, 1002, 294, 257, 3273, 636, 11, 51208], "temperature": 0.0, "avg_logprob": -0.14541392856174046, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.00041063284152187407}, {"id": 1079, "seek": 288926, "start": 2906.1400000000003, "end": 2908.1400000000003, "text": " that there's oversight,", "tokens": [51208, 300, 456, 311, 29146, 11, 51308], "temperature": 0.0, "avg_logprob": -0.14541392856174046, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.00041063284152187407}, {"id": 1080, "seek": 288926, "start": 2908.1400000000003, "end": 2911.3, "text": " that we don't entrench the incumbents.", "tokens": [51308, 300, 321, 500, 380, 948, 4442, 264, 39854, 791, 13, 51466], "temperature": 0.0, "avg_logprob": -0.14541392856174046, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.00041063284152187407}, {"id": 1081, "seek": 288926, "start": 2911.3, "end": 2916.3, "text": " And we ideally actually sort of bias towards disruption", "tokens": [51466, 400, 321, 22915, 767, 1333, 295, 12577, 3030, 28751, 51716], "temperature": 0.0, "avg_logprob": -0.14541392856174046, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.00041063284152187407}, {"id": 1082, "seek": 291630, "start": 2916.46, "end": 2921.46, "text": " and the creation of new value and innovation, new players.", "tokens": [50372, 293, 264, 8016, 295, 777, 2158, 293, 8504, 11, 777, 4150, 13, 50622], "temperature": 0.0, "avg_logprob": -0.1672463814417521, "compression_ratio": 1.543778801843318, "no_speech_prob": 0.0014841377269476652}, {"id": 1083, "seek": 291630, "start": 2925.0600000000004, "end": 2928.7400000000002, "text": " So I think they all want that, but it's a tightrope.", "tokens": [50802, 407, 286, 519, 436, 439, 528, 300, 11, 457, 309, 311, 257, 4524, 340, 494, 13, 50986], "temperature": 0.0, "avg_logprob": -0.1672463814417521, "compression_ratio": 1.543778801843318, "no_speech_prob": 0.0014841377269476652}, {"id": 1084, "seek": 291630, "start": 2928.7400000000002, "end": 2932.6600000000003, "text": " It's a very difficult line to walk.", "tokens": [50986, 467, 311, 257, 588, 2252, 1622, 281, 1792, 13, 51182], "temperature": 0.0, "avg_logprob": -0.1672463814417521, "compression_ratio": 1.543778801843318, "no_speech_prob": 0.0014841377269476652}, {"id": 1085, "seek": 291630, "start": 2932.6600000000003, "end": 2934.86, "text": " I think one of the issues is that", "tokens": [51182, 286, 519, 472, 295, 264, 2663, 307, 300, 51292], "temperature": 0.0, "avg_logprob": -0.1672463814417521, "compression_ratio": 1.543778801843318, "no_speech_prob": 0.0014841377269476652}, {"id": 1086, "seek": 291630, "start": 2934.86, "end": 2937.5, "text": " not a lot of people certainly in the government", "tokens": [51292, 406, 257, 688, 295, 561, 3297, 294, 264, 2463, 51424], "temperature": 0.0, "avg_logprob": -0.1672463814417521, "compression_ratio": 1.543778801843318, "no_speech_prob": 0.0014841377269476652}, {"id": 1087, "seek": 291630, "start": 2937.5, "end": 2939.34, "text": " understand how this technology works.", "tokens": [51424, 1223, 577, 341, 2899, 1985, 13, 51516], "temperature": 0.0, "avg_logprob": -0.1672463814417521, "compression_ratio": 1.543778801843318, "no_speech_prob": 0.0014841377269476652}, {"id": 1088, "seek": 291630, "start": 2939.34, "end": 2940.86, "text": " It seems like magic.", "tokens": [51516, 467, 2544, 411, 5585, 13, 51592], "temperature": 0.0, "avg_logprob": -0.1672463814417521, "compression_ratio": 1.543778801843318, "no_speech_prob": 0.0014841377269476652}, {"id": 1089, "seek": 291630, "start": 2940.86, "end": 2944.6600000000003, "text": " And many people, I mean, even in the AI space,", "tokens": [51592, 400, 867, 561, 11, 286, 914, 11, 754, 294, 264, 7318, 1901, 11, 51782], "temperature": 0.0, "avg_logprob": -0.1672463814417521, "compression_ratio": 1.543778801843318, "no_speech_prob": 0.0014841377269476652}, {"id": 1090, "seek": 294466, "start": 2944.7, "end": 2946.8599999999997, "text": " I mean, Lacoon and Hinton, for example,", "tokens": [50366, 286, 914, 11, 40113, 4106, 293, 389, 12442, 11, 337, 1365, 11, 50474], "temperature": 0.0, "avg_logprob": -0.09469427470288246, "compression_ratio": 1.7066246056782335, "no_speech_prob": 0.004630840849131346}, {"id": 1091, "seek": 294466, "start": 2946.8599999999997, "end": 2948.98, "text": " people have very different opinions about it,", "tokens": [50474, 561, 362, 588, 819, 11819, 466, 309, 11, 50580], "temperature": 0.0, "avg_logprob": -0.09469427470288246, "compression_ratio": 1.7066246056782335, "no_speech_prob": 0.004630840849131346}, {"id": 1092, "seek": 294466, "start": 2948.98, "end": 2950.8599999999997, "text": " but I'm also interested in your views", "tokens": [50580, 457, 286, 478, 611, 3102, 294, 428, 6809, 50674], "temperature": 0.0, "avg_logprob": -0.09469427470288246, "compression_ratio": 1.7066246056782335, "no_speech_prob": 0.004630840849131346}, {"id": 1093, "seek": 294466, "start": 2950.8599999999997, "end": 2952.94, "text": " on the kind of health of the startup scene.", "tokens": [50674, 322, 264, 733, 295, 1585, 295, 264, 18578, 4145, 13, 50778], "temperature": 0.0, "avg_logprob": -0.09469427470288246, "compression_ratio": 1.7066246056782335, "no_speech_prob": 0.004630840849131346}, {"id": 1094, "seek": 294466, "start": 2952.94, "end": 2954.8599999999997, "text": " So we're in a bit of a downturn at the moment.", "tokens": [50778, 407, 321, 434, 294, 257, 857, 295, 257, 11655, 925, 412, 264, 1623, 13, 50874], "temperature": 0.0, "avg_logprob": -0.09469427470288246, "compression_ratio": 1.7066246056782335, "no_speech_prob": 0.004630840849131346}, {"id": 1095, "seek": 294466, "start": 2954.8599999999997, "end": 2957.58, "text": " It doesn't seem to have affected the LLM space,", "tokens": [50874, 467, 1177, 380, 1643, 281, 362, 8028, 264, 441, 43, 44, 1901, 11, 51010], "temperature": 0.0, "avg_logprob": -0.09469427470288246, "compression_ratio": 1.7066246056782335, "no_speech_prob": 0.004630840849131346}, {"id": 1096, "seek": 294466, "start": 2957.58, "end": 2959.7, "text": " but even in the LLM space, I've noticed a trend", "tokens": [51010, 457, 754, 294, 264, 441, 43, 44, 1901, 11, 286, 600, 5694, 257, 6028, 51116], "temperature": 0.0, "avg_logprob": -0.09469427470288246, "compression_ratio": 1.7066246056782335, "no_speech_prob": 0.004630840849131346}, {"id": 1097, "seek": 294466, "start": 2959.7, "end": 2963.06, "text": " that many people started kind of wrapper companies", "tokens": [51116, 300, 867, 561, 1409, 733, 295, 46906, 3431, 51284], "temperature": 0.0, "avg_logprob": -0.09469427470288246, "compression_ratio": 1.7066246056782335, "no_speech_prob": 0.004630840849131346}, {"id": 1098, "seek": 294466, "start": 2963.06, "end": 2966.42, "text": " where they did an LLM, but it didn't really do anything", "tokens": [51284, 689, 436, 630, 364, 441, 43, 44, 11, 457, 309, 994, 380, 534, 360, 1340, 51452], "temperature": 0.0, "avg_logprob": -0.09469427470288246, "compression_ratio": 1.7066246056782335, "no_speech_prob": 0.004630840849131346}, {"id": 1099, "seek": 294466, "start": 2966.42, "end": 2968.46, "text": " that couldn't easily be replicated.", "tokens": [51452, 300, 2809, 380, 3612, 312, 46365, 13, 51554], "temperature": 0.0, "avg_logprob": -0.09469427470288246, "compression_ratio": 1.7066246056782335, "no_speech_prob": 0.004630840849131346}, {"id": 1100, "seek": 294466, "start": 2968.46, "end": 2970.18, "text": " And what are your thoughts there?", "tokens": [51554, 400, 437, 366, 428, 4598, 456, 30, 51640], "temperature": 0.0, "avg_logprob": -0.09469427470288246, "compression_ratio": 1.7066246056782335, "no_speech_prob": 0.004630840849131346}, {"id": 1101, "seek": 294466, "start": 2970.18, "end": 2973.02, "text": " Do you think we're gonna see a trend towards startups", "tokens": [51640, 1144, 291, 519, 321, 434, 799, 536, 257, 6028, 3030, 28041, 51782], "temperature": 0.0, "avg_logprob": -0.09469427470288246, "compression_ratio": 1.7066246056782335, "no_speech_prob": 0.004630840849131346}, {"id": 1102, "seek": 297302, "start": 2973.06, "end": 2975.74, "text": " doing something that is very differentiated?", "tokens": [50366, 884, 746, 300, 307, 588, 27372, 770, 30, 50500], "temperature": 0.0, "avg_logprob": -0.11987746436640902, "compression_ratio": 1.5732217573221758, "no_speech_prob": 0.0018666688119992614}, {"id": 1103, "seek": 297302, "start": 2975.74, "end": 2978.7, "text": " Yeah, I mean, I think we're in a moment of churn.", "tokens": [50500, 865, 11, 286, 914, 11, 286, 519, 321, 434, 294, 257, 1623, 295, 417, 925, 13, 50648], "temperature": 0.0, "avg_logprob": -0.11987746436640902, "compression_ratio": 1.5732217573221758, "no_speech_prob": 0.0018666688119992614}, {"id": 1104, "seek": 297302, "start": 2978.7, "end": 2983.7, "text": " So I think there are gonna be some players", "tokens": [50648, 407, 286, 519, 456, 366, 799, 312, 512, 4150, 50898], "temperature": 0.0, "avg_logprob": -0.11987746436640902, "compression_ratio": 1.5732217573221758, "no_speech_prob": 0.0018666688119992614}, {"id": 1105, "seek": 297302, "start": 2983.7, "end": 2988.7, "text": " who started a while ago who fold or go into other companies,", "tokens": [50898, 567, 1409, 257, 1339, 2057, 567, 4860, 420, 352, 666, 661, 3431, 11, 51148], "temperature": 0.0, "avg_logprob": -0.11987746436640902, "compression_ratio": 1.5732217573221758, "no_speech_prob": 0.0018666688119992614}, {"id": 1106, "seek": 297302, "start": 2988.7, "end": 2991.18, "text": " get acquired, that type of thing,", "tokens": [51148, 483, 17554, 11, 300, 2010, 295, 551, 11, 51272], "temperature": 0.0, "avg_logprob": -0.11987746436640902, "compression_ratio": 1.5732217573221758, "no_speech_prob": 0.0018666688119992614}, {"id": 1107, "seek": 297302, "start": 2991.18, "end": 2993.1, "text": " but there's a whole new generation emerging.", "tokens": [51272, 457, 456, 311, 257, 1379, 777, 5125, 14989, 13, 51368], "temperature": 0.0, "avg_logprob": -0.11987746436640902, "compression_ratio": 1.5732217573221758, "no_speech_prob": 0.0018666688119992614}, {"id": 1108, "seek": 297302, "start": 2993.1, "end": 2997.66, "text": " I know a bunch of people starting up, Ivan and I,", "tokens": [51368, 286, 458, 257, 3840, 295, 561, 2891, 493, 11, 28893, 293, 286, 11, 51596], "temperature": 0.0, "avg_logprob": -0.11987746436640902, "compression_ratio": 1.5732217573221758, "no_speech_prob": 0.0018666688119992614}, {"id": 1109, "seek": 297302, "start": 2997.66, "end": 3001.1, "text": " we invest in startups and we're seeing an uptick", "tokens": [51596, 321, 1963, 294, 28041, 293, 321, 434, 2577, 364, 493, 83, 618, 51768], "temperature": 0.0, "avg_logprob": -0.11987746436640902, "compression_ratio": 1.5732217573221758, "no_speech_prob": 0.0018666688119992614}, {"id": 1110, "seek": 300110, "start": 3001.1, "end": 3003.5, "text": " in the number of AI startups that are coming out.", "tokens": [50364, 294, 264, 1230, 295, 7318, 28041, 300, 366, 1348, 484, 13, 50484], "temperature": 0.0, "avg_logprob": -0.16090954961003484, "compression_ratio": 1.5957446808510638, "no_speech_prob": 0.0005702075432054698}, {"id": 1111, "seek": 300110, "start": 3004.98, "end": 3006.8199999999997, "text": " It's sort of like a reformatting.", "tokens": [50558, 467, 311, 1333, 295, 411, 257, 8290, 267, 783, 13, 50650], "temperature": 0.0, "avg_logprob": -0.16090954961003484, "compression_ratio": 1.5957446808510638, "no_speech_prob": 0.0005702075432054698}, {"id": 1112, "seek": 300110, "start": 3006.8199999999997, "end": 3009.5, "text": " There was a bunch of folks building at one layer,", "tokens": [50650, 821, 390, 257, 3840, 295, 4024, 2390, 412, 472, 4583, 11, 50784], "temperature": 0.0, "avg_logprob": -0.16090954961003484, "compression_ratio": 1.5957446808510638, "no_speech_prob": 0.0005702075432054698}, {"id": 1113, "seek": 300110, "start": 3009.5, "end": 3013.24, "text": " like the LLM layer or the one layer above that,", "tokens": [50784, 411, 264, 441, 43, 44, 4583, 420, 264, 472, 4583, 3673, 300, 11, 50971], "temperature": 0.0, "avg_logprob": -0.16090954961003484, "compression_ratio": 1.5957446808510638, "no_speech_prob": 0.0005702075432054698}, {"id": 1114, "seek": 300110, "start": 3014.5, "end": 3015.8199999999997, "text": " tooling, et cetera.", "tokens": [51034, 46593, 11, 1030, 11458, 13, 51100], "temperature": 0.0, "avg_logprob": -0.16090954961003484, "compression_ratio": 1.5957446808510638, "no_speech_prob": 0.0005702075432054698}, {"id": 1115, "seek": 300110, "start": 3016.74, "end": 3019.14, "text": " The players have kind of been set in that space,", "tokens": [51146, 440, 4150, 362, 733, 295, 668, 992, 294, 300, 1901, 11, 51266], "temperature": 0.0, "avg_logprob": -0.16090954961003484, "compression_ratio": 1.5957446808510638, "no_speech_prob": 0.0005702075432054698}, {"id": 1116, "seek": 300110, "start": 3019.14, "end": 3020.98, "text": " it seems, yeah, of course,", "tokens": [51266, 309, 2544, 11, 1338, 11, 295, 1164, 11, 51358], "temperature": 0.0, "avg_logprob": -0.16090954961003484, "compression_ratio": 1.5957446808510638, "no_speech_prob": 0.0005702075432054698}, {"id": 1117, "seek": 300110, "start": 3020.98, "end": 3023.24, "text": " I'd be happy to see new players emerge.", "tokens": [51358, 286, 1116, 312, 2055, 281, 536, 777, 4150, 21511, 13, 51471], "temperature": 0.0, "avg_logprob": -0.16090954961003484, "compression_ratio": 1.5957446808510638, "no_speech_prob": 0.0005702075432054698}, {"id": 1118, "seek": 300110, "start": 3024.5, "end": 3029.5, "text": " But we now need a set of ideas and products and companies", "tokens": [51534, 583, 321, 586, 643, 257, 992, 295, 3487, 293, 3383, 293, 3431, 51784], "temperature": 0.0, "avg_logprob": -0.16090954961003484, "compression_ratio": 1.5957446808510638, "no_speech_prob": 0.0005702075432054698}, {"id": 1119, "seek": 302950, "start": 3030.1, "end": 3031.9, "text": " building up the stack.", "tokens": [50394, 2390, 493, 264, 8630, 13, 50484], "temperature": 0.0, "avg_logprob": -0.1321507987626102, "compression_ratio": 1.6294820717131475, "no_speech_prob": 0.000645848864223808}, {"id": 1120, "seek": 302950, "start": 3031.9, "end": 3036.9, "text": " So more abstract concepts, stuff like end user products", "tokens": [50484, 407, 544, 12649, 10392, 11, 1507, 411, 917, 4195, 3383, 50734], "temperature": 0.0, "avg_logprob": -0.1321507987626102, "compression_ratio": 1.6294820717131475, "no_speech_prob": 0.000645848864223808}, {"id": 1121, "seek": 302950, "start": 3037.3, "end": 3040.14, "text": " and agent companies, they're all starting to pop up", "tokens": [50754, 293, 9461, 3431, 11, 436, 434, 439, 2891, 281, 1665, 493, 50896], "temperature": 0.0, "avg_logprob": -0.1321507987626102, "compression_ratio": 1.6294820717131475, "no_speech_prob": 0.000645848864223808}, {"id": 1122, "seek": 302950, "start": 3040.14, "end": 3043.94, "text": " and create really interesting new ideas.", "tokens": [50896, 293, 1884, 534, 1880, 777, 3487, 13, 51086], "temperature": 0.0, "avg_logprob": -0.1321507987626102, "compression_ratio": 1.6294820717131475, "no_speech_prob": 0.000645848864223808}, {"id": 1123, "seek": 302950, "start": 3043.94, "end": 3045.5, "text": " And then that will sort of settle", "tokens": [51086, 400, 550, 300, 486, 1333, 295, 11852, 51164], "temperature": 0.0, "avg_logprob": -0.1321507987626102, "compression_ratio": 1.6294820717131475, "no_speech_prob": 0.000645848864223808}, {"id": 1124, "seek": 302950, "start": 3045.5, "end": 3047.82, "text": " and we'll have our players at that layer.", "tokens": [51164, 293, 321, 603, 362, 527, 4150, 412, 300, 4583, 13, 51280], "temperature": 0.0, "avg_logprob": -0.1321507987626102, "compression_ratio": 1.6294820717131475, "no_speech_prob": 0.000645848864223808}, {"id": 1125, "seek": 302950, "start": 3047.82, "end": 3050.98, "text": " So it's a continuous cycle.", "tokens": [51280, 407, 309, 311, 257, 10957, 6586, 13, 51438], "temperature": 0.0, "avg_logprob": -0.1321507987626102, "compression_ratio": 1.6294820717131475, "no_speech_prob": 0.000645848864223808}, {"id": 1126, "seek": 302950, "start": 3052.82, "end": 3055.22, "text": " Yeah, I'm really excited about the AI startup space.", "tokens": [51530, 865, 11, 286, 478, 534, 2919, 466, 264, 7318, 18578, 1901, 13, 51650], "temperature": 0.0, "avg_logprob": -0.1321507987626102, "compression_ratio": 1.6294820717131475, "no_speech_prob": 0.000645848864223808}, {"id": 1127, "seek": 302950, "start": 3055.22, "end": 3057.9, "text": " It feels like we're finally starting to get our feet", "tokens": [51650, 467, 3417, 411, 321, 434, 2721, 2891, 281, 483, 527, 3521, 51784], "temperature": 0.0, "avg_logprob": -0.1321507987626102, "compression_ratio": 1.6294820717131475, "no_speech_prob": 0.000645848864223808}, {"id": 1128, "seek": 302950, "start": 3057.9, "end": 3058.74, "text": " on the ground a little bit.", "tokens": [51784, 322, 264, 2727, 257, 707, 857, 13, 51826], "temperature": 0.0, "avg_logprob": -0.1321507987626102, "compression_ratio": 1.6294820717131475, "no_speech_prob": 0.000645848864223808}, {"id": 1129, "seek": 305874, "start": 3059.02, "end": 3061.4599999999996, "text": " For example, with the tool use, with the RAG,", "tokens": [50378, 1171, 1365, 11, 365, 264, 2290, 764, 11, 365, 264, 14626, 38, 11, 50500], "temperature": 0.0, "avg_logprob": -0.14720020144004523, "compression_ratio": 1.6885813148788926, "no_speech_prob": 0.00016233355563599616}, {"id": 1130, "seek": 305874, "start": 3061.4599999999996, "end": 3063.74, "text": " it's starting to look a lot more like traditional", "tokens": [50500, 309, 311, 2891, 281, 574, 257, 688, 544, 411, 5164, 50614], "temperature": 0.0, "avg_logprob": -0.14720020144004523, "compression_ratio": 1.6885813148788926, "no_speech_prob": 0.00016233355563599616}, {"id": 1131, "seek": 305874, "start": 3063.74, "end": 3064.8199999999997, "text": " software engineering.", "tokens": [50614, 4722, 7043, 13, 50668], "temperature": 0.0, "avg_logprob": -0.14720020144004523, "compression_ratio": 1.6885813148788926, "no_speech_prob": 0.00016233355563599616}, {"id": 1132, "seek": 305874, "start": 3064.8199999999997, "end": 3066.9799999999996, "text": " So what we're seeing now is people kind of rolling up", "tokens": [50668, 407, 437, 321, 434, 2577, 586, 307, 561, 733, 295, 9439, 493, 50776], "temperature": 0.0, "avg_logprob": -0.14720020144004523, "compression_ratio": 1.6885813148788926, "no_speech_prob": 0.00016233355563599616}, {"id": 1133, "seek": 305874, "start": 3066.9799999999996, "end": 3068.3799999999997, "text": " their sleeves and actually building out", "tokens": [50776, 641, 24555, 293, 767, 2390, 484, 50846], "temperature": 0.0, "avg_logprob": -0.14720020144004523, "compression_ratio": 1.6885813148788926, "no_speech_prob": 0.00016233355563599616}, {"id": 1134, "seek": 305874, "start": 3068.3799999999997, "end": 3070.66, "text": " these very sophisticated software architectures", "tokens": [50846, 613, 588, 16950, 4722, 6331, 1303, 50960], "temperature": 0.0, "avg_logprob": -0.14720020144004523, "compression_ratio": 1.6885813148788926, "no_speech_prob": 0.00016233355563599616}, {"id": 1135, "seek": 305874, "start": 3070.66, "end": 3073.18, "text": " that compose LLMs in interesting ways.", "tokens": [50960, 300, 35925, 441, 43, 26386, 294, 1880, 2098, 13, 51086], "temperature": 0.0, "avg_logprob": -0.14720020144004523, "compression_ratio": 1.6885813148788926, "no_speech_prob": 0.00016233355563599616}, {"id": 1136, "seek": 305874, "start": 3073.18, "end": 3075.4599999999996, "text": " And they're not just kind of, you know,", "tokens": [51086, 400, 436, 434, 406, 445, 733, 295, 11, 291, 458, 11, 51200], "temperature": 0.0, "avg_logprob": -0.14720020144004523, "compression_ratio": 1.6885813148788926, "no_speech_prob": 0.00016233355563599616}, {"id": 1137, "seek": 305874, "start": 3075.4599999999996, "end": 3078.02, "text": " just building a simple LLM with a prompt on the top.", "tokens": [51200, 445, 2390, 257, 2199, 441, 43, 44, 365, 257, 12391, 322, 264, 1192, 13, 51328], "temperature": 0.0, "avg_logprob": -0.14720020144004523, "compression_ratio": 1.6885813148788926, "no_speech_prob": 0.00016233355563599616}, {"id": 1138, "seek": 305874, "start": 3079.02, "end": 3081.1, "text": " Yeah, it's definitely getting more sophisticated.", "tokens": [51378, 865, 11, 309, 311, 2138, 1242, 544, 16950, 13, 51482], "temperature": 0.0, "avg_logprob": -0.14720020144004523, "compression_ratio": 1.6885813148788926, "no_speech_prob": 0.00016233355563599616}, {"id": 1139, "seek": 305874, "start": 3081.1, "end": 3085.14, "text": " And as the tools get more robust and reliable,", "tokens": [51482, 400, 382, 264, 3873, 483, 544, 13956, 293, 12924, 11, 51684], "temperature": 0.0, "avg_logprob": -0.14720020144004523, "compression_ratio": 1.6885813148788926, "no_speech_prob": 0.00016233355563599616}, {"id": 1140, "seek": 308514, "start": 3085.14, "end": 3088.98, "text": " it's unlocking totally new applications.", "tokens": [50364, 309, 311, 49620, 3879, 777, 5821, 13, 50556], "temperature": 0.0, "avg_logprob": -0.09811826105471011, "compression_ratio": 1.6748971193415638, "no_speech_prob": 0.0003249420551583171}, {"id": 1141, "seek": 308514, "start": 3088.98, "end": 3092.06, "text": " And the utility is starting to be seen and felt", "tokens": [50556, 400, 264, 14877, 307, 2891, 281, 312, 1612, 293, 2762, 50710], "temperature": 0.0, "avg_logprob": -0.09811826105471011, "compression_ratio": 1.6748971193415638, "no_speech_prob": 0.0003249420551583171}, {"id": 1142, "seek": 308514, "start": 3092.06, "end": 3093.1, "text": " in the real world.", "tokens": [50710, 294, 264, 957, 1002, 13, 50762], "temperature": 0.0, "avg_logprob": -0.09811826105471011, "compression_ratio": 1.6748971193415638, "no_speech_prob": 0.0003249420551583171}, {"id": 1143, "seek": 308514, "start": 3093.1, "end": 3095.42, "text": " I think last year was very much like the year", "tokens": [50762, 286, 519, 1036, 1064, 390, 588, 709, 411, 264, 1064, 50878], "temperature": 0.0, "avg_logprob": -0.09811826105471011, "compression_ratio": 1.6748971193415638, "no_speech_prob": 0.0003249420551583171}, {"id": 1144, "seek": 308514, "start": 3095.42, "end": 3098.2599999999998, "text": " the world woke up to the technology", "tokens": [50878, 264, 1002, 12852, 493, 281, 264, 2899, 51020], "temperature": 0.0, "avg_logprob": -0.09811826105471011, "compression_ratio": 1.6748971193415638, "no_speech_prob": 0.0003249420551583171}, {"id": 1145, "seek": 308514, "start": 3098.2599999999998, "end": 3100.8199999999997, "text": " and got their footing with it.", "tokens": [51020, 293, 658, 641, 45959, 365, 309, 13, 51148], "temperature": 0.0, "avg_logprob": -0.09811826105471011, "compression_ratio": 1.6748971193415638, "no_speech_prob": 0.0003249420551583171}, {"id": 1146, "seek": 308514, "start": 3100.8199999999997, "end": 3102.3799999999997, "text": " So it got familiarity.", "tokens": [51148, 407, 309, 658, 49828, 13, 51226], "temperature": 0.0, "avg_logprob": -0.09811826105471011, "compression_ratio": 1.6748971193415638, "no_speech_prob": 0.0003249420551583171}, {"id": 1147, "seek": 308514, "start": 3104.2599999999998, "end": 3109.2599999999998, "text": " This year is when things are gonna start hitting production.", "tokens": [51320, 639, 1064, 307, 562, 721, 366, 799, 722, 8850, 4265, 13, 51570], "temperature": 0.0, "avg_logprob": -0.09811826105471011, "compression_ratio": 1.6748971193415638, "no_speech_prob": 0.0003249420551583171}, {"id": 1148, "seek": 308514, "start": 3109.2599999999998, "end": 3111.22, "text": " They're gonna actually start to hit our hands", "tokens": [51570, 814, 434, 799, 767, 722, 281, 2045, 527, 2377, 51668], "temperature": 0.0, "avg_logprob": -0.09811826105471011, "compression_ratio": 1.6748971193415638, "no_speech_prob": 0.0003249420551583171}, {"id": 1149, "seek": 308514, "start": 3111.22, "end": 3114.2599999999998, "text": " and we're gonna be able to use this as part of our work,", "tokens": [51668, 293, 321, 434, 799, 312, 1075, 281, 764, 341, 382, 644, 295, 527, 589, 11, 51820], "temperature": 0.0, "avg_logprob": -0.09811826105471011, "compression_ratio": 1.6748971193415638, "no_speech_prob": 0.0003249420551583171}, {"id": 1150, "seek": 311426, "start": 3114.26, "end": 3118.34, "text": " part of our play, the products that we use.", "tokens": [50364, 644, 295, 527, 862, 11, 264, 3383, 300, 321, 764, 13, 50568], "temperature": 0.0, "avg_logprob": -0.17569719314575194, "compression_ratio": 1.4866071428571428, "no_speech_prob": 0.00015353741764556617}, {"id": 1151, "seek": 311426, "start": 3119.38, "end": 3122.26, "text": " It's gonna become a much more fundamental part", "tokens": [50620, 467, 311, 799, 1813, 257, 709, 544, 8088, 644, 50764], "temperature": 0.0, "avg_logprob": -0.17569719314575194, "compression_ratio": 1.4866071428571428, "no_speech_prob": 0.00015353741764556617}, {"id": 1152, "seek": 311426, "start": 3122.26, "end": 3123.42, "text": " of our daily life.", "tokens": [50764, 295, 527, 5212, 993, 13, 50822], "temperature": 0.0, "avg_logprob": -0.17569719314575194, "compression_ratio": 1.4866071428571428, "no_speech_prob": 0.00015353741764556617}, {"id": 1153, "seek": 311426, "start": 3125.82, "end": 3126.78, "text": " So it's very gratifying.", "tokens": [50942, 407, 309, 311, 588, 10158, 5489, 13, 50990], "temperature": 0.0, "avg_logprob": -0.17569719314575194, "compression_ratio": 1.4866071428571428, "no_speech_prob": 0.00015353741764556617}, {"id": 1154, "seek": 311426, "start": 3126.78, "end": 3131.0200000000004, "text": " Like we've been building Cohere for four and a half years now.", "tokens": [50990, 1743, 321, 600, 668, 2390, 3066, 6703, 337, 1451, 293, 257, 1922, 924, 586, 13, 51202], "temperature": 0.0, "avg_logprob": -0.17569719314575194, "compression_ratio": 1.4866071428571428, "no_speech_prob": 0.00015353741764556617}, {"id": 1155, "seek": 311426, "start": 3131.0200000000004, "end": 3132.0800000000004, "text": " We're in our fifth year.", "tokens": [51202, 492, 434, 294, 527, 9266, 1064, 13, 51255], "temperature": 0.0, "avg_logprob": -0.17569719314575194, "compression_ratio": 1.4866071428571428, "no_speech_prob": 0.00015353741764556617}, {"id": 1156, "seek": 311426, "start": 3135.5800000000004, "end": 3137.6600000000003, "text": " And I think for a long time,", "tokens": [51430, 400, 286, 519, 337, 257, 938, 565, 11, 51534], "temperature": 0.0, "avg_logprob": -0.17569719314575194, "compression_ratio": 1.4866071428571428, "no_speech_prob": 0.00015353741764556617}, {"id": 1157, "seek": 311426, "start": 3137.6600000000003, "end": 3139.6600000000003, "text": " we were out there sort of preaching,", "tokens": [51534, 321, 645, 484, 456, 1333, 295, 25381, 11, 51634], "temperature": 0.0, "avg_logprob": -0.17569719314575194, "compression_ratio": 1.4866071428571428, "no_speech_prob": 0.00015353741764556617}, {"id": 1158, "seek": 311426, "start": 3139.6600000000003, "end": 3142.1000000000004, "text": " this is really cool, please care about this.", "tokens": [51634, 341, 307, 534, 1627, 11, 1767, 1127, 466, 341, 13, 51756], "temperature": 0.0, "avg_logprob": -0.17569719314575194, "compression_ratio": 1.4866071428571428, "no_speech_prob": 0.00015353741764556617}, {"id": 1159, "seek": 314210, "start": 3142.42, "end": 3145.46, "text": " Like this is gonna be an important thing.", "tokens": [50380, 1743, 341, 307, 799, 312, 364, 1021, 551, 13, 50532], "temperature": 0.0, "avg_logprob": -0.18341862238370454, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.00014880139497108757}, {"id": 1160, "seek": 314210, "start": 3145.46, "end": 3146.7799999999997, "text": " And folks would pat us on the back", "tokens": [50532, 400, 4024, 576, 1947, 505, 322, 264, 646, 50598], "temperature": 0.0, "avg_logprob": -0.18341862238370454, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.00014880139497108757}, {"id": 1161, "seek": 314210, "start": 3146.7799999999997, "end": 3149.18, "text": " and say, nice science project.", "tokens": [50598, 293, 584, 11, 1481, 3497, 1716, 13, 50718], "temperature": 0.0, "avg_logprob": -0.18341862238370454, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.00014880139497108757}, {"id": 1162, "seek": 314210, "start": 3152.18, "end": 3155.2599999999998, "text": " But finally, we're actually starting to see", "tokens": [50868, 583, 2721, 11, 321, 434, 767, 2891, 281, 536, 51022], "temperature": 0.0, "avg_logprob": -0.18341862238370454, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.00014880139497108757}, {"id": 1163, "seek": 314210, "start": 3155.2599999999998, "end": 3157.8199999999997, "text": " the fruits of all that labor.", "tokens": [51022, 264, 12148, 295, 439, 300, 5938, 13, 51150], "temperature": 0.0, "avg_logprob": -0.18341862238370454, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.00014880139497108757}, {"id": 1164, "seek": 314210, "start": 3157.8199999999997, "end": 3161.54, "text": " And so it's really gratifying to see real world impact.", "tokens": [51150, 400, 370, 309, 311, 534, 10158, 5489, 281, 536, 957, 1002, 2712, 13, 51336], "temperature": 0.0, "avg_logprob": -0.18341862238370454, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.00014880139497108757}, {"id": 1165, "seek": 314210, "start": 3161.54, "end": 3163.18, "text": " And I think that's what we exist for", "tokens": [51336, 400, 286, 519, 300, 311, 437, 321, 2514, 337, 51418], "temperature": 0.0, "avg_logprob": -0.18341862238370454, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.00014880139497108757}, {"id": 1166, "seek": 314210, "start": 3163.18, "end": 3165.1, "text": " is really trying to accelerate that", "tokens": [51418, 307, 534, 1382, 281, 21341, 300, 51514], "temperature": 0.0, "avg_logprob": -0.18341862238370454, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.00014880139497108757}, {"id": 1167, "seek": 314210, "start": 3165.1, "end": 3168.42, "text": " and make more of it happen faster", "tokens": [51514, 293, 652, 544, 295, 309, 1051, 4663, 51680], "temperature": 0.0, "avg_logprob": -0.18341862238370454, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.00014880139497108757}, {"id": 1168, "seek": 314210, "start": 3168.42, "end": 3172.06, "text": " and in the best way possible.", "tokens": [51680, 293, 294, 264, 1151, 636, 1944, 13, 51862], "temperature": 0.0, "avg_logprob": -0.18341862238370454, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.00014880139497108757}, {"id": 1169, "seek": 317206, "start": 3172.06, "end": 3173.66, "text": " And what was your biggest mistake?", "tokens": [50364, 400, 437, 390, 428, 3880, 6146, 30, 50444], "temperature": 0.0, "avg_logprob": -0.1488382760868516, "compression_ratio": 1.5114155251141552, "no_speech_prob": 0.00042992376256734133}, {"id": 1170, "seek": 317206, "start": 3173.66, "end": 3176.54, "text": " I mean, do you have any advice for other startup founders?", "tokens": [50444, 286, 914, 11, 360, 291, 362, 604, 5192, 337, 661, 18578, 25608, 30, 50588], "temperature": 0.0, "avg_logprob": -0.1488382760868516, "compression_ratio": 1.5114155251141552, "no_speech_prob": 0.00042992376256734133}, {"id": 1171, "seek": 317206, "start": 3176.54, "end": 3179.86, "text": " What did you do that perhaps they should avoid?", "tokens": [50588, 708, 630, 291, 360, 300, 4317, 436, 820, 5042, 30, 50754], "temperature": 0.0, "avg_logprob": -0.1488382760868516, "compression_ratio": 1.5114155251141552, "no_speech_prob": 0.00042992376256734133}, {"id": 1172, "seek": 317206, "start": 3181.1, "end": 3186.1, "text": " I fucked up constantly at every stage of the company.", "tokens": [50816, 286, 22518, 493, 6460, 412, 633, 3233, 295, 264, 2237, 13, 51066], "temperature": 0.0, "avg_logprob": -0.1488382760868516, "compression_ratio": 1.5114155251141552, "no_speech_prob": 0.00042992376256734133}, {"id": 1173, "seek": 317206, "start": 3189.22, "end": 3192.98, "text": " I think, I guess just like admitting that you've messed up", "tokens": [51222, 286, 519, 11, 286, 2041, 445, 411, 44056, 300, 291, 600, 16507, 493, 51410], "temperature": 0.0, "avg_logprob": -0.1488382760868516, "compression_ratio": 1.5114155251141552, "no_speech_prob": 0.00042992376256734133}, {"id": 1174, "seek": 317206, "start": 3194.06, "end": 3198.42, "text": " and trying not to be in denial about it", "tokens": [51464, 293, 1382, 406, 281, 312, 294, 28754, 466, 309, 51682], "temperature": 0.0, "avg_logprob": -0.1488382760868516, "compression_ratio": 1.5114155251141552, "no_speech_prob": 0.00042992376256734133}, {"id": 1175, "seek": 317206, "start": 3198.42, "end": 3200.2599999999998, "text": " and fixing it as quickly as possible", "tokens": [51682, 293, 19442, 309, 382, 2661, 382, 1944, 51774], "temperature": 0.0, "avg_logprob": -0.1488382760868516, "compression_ratio": 1.5114155251141552, "no_speech_prob": 0.00042992376256734133}, {"id": 1176, "seek": 320026, "start": 3200.3, "end": 3203.6200000000003, "text": " has been the most important thing", "tokens": [50366, 575, 668, 264, 881, 1021, 551, 50532], "temperature": 0.0, "avg_logprob": -0.13929295539855957, "compression_ratio": 1.4780487804878049, "no_speech_prob": 0.00019107117259409279}, {"id": 1177, "seek": 320026, "start": 3203.6200000000003, "end": 3207.7400000000002, "text": " to continue to thrive and exist.", "tokens": [50532, 281, 2354, 281, 21233, 293, 2514, 13, 50738], "temperature": 0.0, "avg_logprob": -0.13929295539855957, "compression_ratio": 1.4780487804878049, "no_speech_prob": 0.00019107117259409279}, {"id": 1178, "seek": 320026, "start": 3209.0200000000004, "end": 3212.34, "text": " But yeah, this is the first company I started.", "tokens": [50802, 583, 1338, 11, 341, 307, 264, 700, 2237, 286, 1409, 13, 50968], "temperature": 0.0, "avg_logprob": -0.13929295539855957, "compression_ratio": 1.4780487804878049, "no_speech_prob": 0.00019107117259409279}, {"id": 1179, "seek": 320026, "start": 3212.34, "end": 3213.7000000000003, "text": " Same for Nick and Ivan.", "tokens": [50968, 10635, 337, 9449, 293, 28893, 13, 51036], "temperature": 0.0, "avg_logprob": -0.13929295539855957, "compression_ratio": 1.4780487804878049, "no_speech_prob": 0.00019107117259409279}, {"id": 1180, "seek": 320026, "start": 3213.7000000000003, "end": 3217.26, "text": " And so the whole founding team, we were fresh into it", "tokens": [51036, 400, 370, 264, 1379, 22223, 1469, 11, 321, 645, 4451, 666, 309, 51214], "temperature": 0.0, "avg_logprob": -0.13929295539855957, "compression_ratio": 1.4780487804878049, "no_speech_prob": 0.00019107117259409279}, {"id": 1181, "seek": 320026, "start": 3217.26, "end": 3220.0400000000004, "text": " and we made potentially every mistake", "tokens": [51214, 293, 321, 1027, 7263, 633, 6146, 51353], "temperature": 0.0, "avg_logprob": -0.13929295539855957, "compression_ratio": 1.4780487804878049, "no_speech_prob": 0.00019107117259409279}, {"id": 1182, "seek": 320026, "start": 3220.0400000000004, "end": 3221.4, "text": " you could possibly make.", "tokens": [51353, 291, 727, 6264, 652, 13, 51421], "temperature": 0.0, "avg_logprob": -0.13929295539855957, "compression_ratio": 1.4780487804878049, "no_speech_prob": 0.00019107117259409279}, {"id": 1183, "seek": 320026, "start": 3223.3, "end": 3228.0600000000004, "text": " Fortunately, we were good at listening to others", "tokens": [51516, 20652, 11, 321, 645, 665, 412, 4764, 281, 2357, 51754], "temperature": 0.0, "avg_logprob": -0.13929295539855957, "compression_ratio": 1.4780487804878049, "no_speech_prob": 0.00019107117259409279}, {"id": 1184, "seek": 322806, "start": 3228.1, "end": 3229.58, "text": " who had done it before", "tokens": [50366, 567, 632, 1096, 309, 949, 50440], "temperature": 0.0, "avg_logprob": -0.12560394040999873, "compression_ratio": 1.7232704402515724, "no_speech_prob": 0.001196768251247704}, {"id": 1185, "seek": 322806, "start": 3229.58, "end": 3232.18, "text": " and seen a lot more than we'd seen.", "tokens": [50440, 293, 1612, 257, 688, 544, 813, 321, 1116, 1612, 13, 50570], "temperature": 0.0, "avg_logprob": -0.12560394040999873, "compression_ratio": 1.7232704402515724, "no_speech_prob": 0.001196768251247704}, {"id": 1186, "seek": 322806, "start": 3232.18, "end": 3234.74, "text": " And so I'm sure we've dodged some mistakes,", "tokens": [50570, 400, 370, 286, 478, 988, 321, 600, 13886, 3004, 512, 8038, 11, 50698], "temperature": 0.0, "avg_logprob": -0.12560394040999873, "compression_ratio": 1.7232704402515724, "no_speech_prob": 0.001196768251247704}, {"id": 1187, "seek": 322806, "start": 3234.74, "end": 3237.94, "text": " but it feels like we've made them all.", "tokens": [50698, 457, 309, 3417, 411, 321, 600, 1027, 552, 439, 13, 50858], "temperature": 0.0, "avg_logprob": -0.12560394040999873, "compression_ratio": 1.7232704402515724, "no_speech_prob": 0.001196768251247704}, {"id": 1188, "seek": 322806, "start": 3237.94, "end": 3239.5, "text": " Yeah, if you don't make mistakes you're not learning,", "tokens": [50858, 865, 11, 498, 291, 500, 380, 652, 8038, 291, 434, 406, 2539, 11, 50936], "temperature": 0.0, "avg_logprob": -0.12560394040999873, "compression_ratio": 1.7232704402515724, "no_speech_prob": 0.001196768251247704}, {"id": 1189, "seek": 322806, "start": 3239.5, "end": 3241.06, "text": " I guess, but just final question.", "tokens": [50936, 286, 2041, 11, 457, 445, 2572, 1168, 13, 51014], "temperature": 0.0, "avg_logprob": -0.12560394040999873, "compression_ratio": 1.7232704402515724, "no_speech_prob": 0.001196768251247704}, {"id": 1190, "seek": 322806, "start": 3241.06, "end": 3244.7, "text": " How do you, because it's such a large organization now", "tokens": [51014, 1012, 360, 291, 11, 570, 309, 311, 1270, 257, 2416, 4475, 586, 51196], "temperature": 0.0, "avg_logprob": -0.12560394040999873, "compression_ratio": 1.7232704402515724, "no_speech_prob": 0.001196768251247704}, {"id": 1191, "seek": 322806, "start": 3244.7, "end": 3246.98, "text": " and there's this problem of vertical information flow.", "tokens": [51196, 293, 456, 311, 341, 1154, 295, 9429, 1589, 3095, 13, 51310], "temperature": 0.0, "avg_logprob": -0.12560394040999873, "compression_ratio": 1.7232704402515724, "no_speech_prob": 0.001196768251247704}, {"id": 1192, "seek": 322806, "start": 3246.98, "end": 3248.14, "text": " So there might be a problem", "tokens": [51310, 407, 456, 1062, 312, 257, 1154, 51368], "temperature": 0.0, "avg_logprob": -0.12560394040999873, "compression_ratio": 1.7232704402515724, "no_speech_prob": 0.001196768251247704}, {"id": 1193, "seek": 322806, "start": 3248.14, "end": 3249.86, "text": " that some of your folks have discovered now", "tokens": [51368, 300, 512, 295, 428, 4024, 362, 6941, 586, 51454], "temperature": 0.0, "avg_logprob": -0.12560394040999873, "compression_ratio": 1.7232704402515724, "no_speech_prob": 0.001196768251247704}, {"id": 1194, "seek": 322806, "start": 3249.86, "end": 3252.58, "text": " and it takes a while to filter through to you.", "tokens": [51454, 293, 309, 2516, 257, 1339, 281, 6608, 807, 281, 291, 13, 51590], "temperature": 0.0, "avg_logprob": -0.12560394040999873, "compression_ratio": 1.7232704402515724, "no_speech_prob": 0.001196768251247704}, {"id": 1195, "seek": 322806, "start": 3252.58, "end": 3254.7, "text": " But obviously it needs to be scalable", "tokens": [51590, 583, 2745, 309, 2203, 281, 312, 38481, 51696], "temperature": 0.0, "avg_logprob": -0.12560394040999873, "compression_ratio": 1.7232704402515724, "no_speech_prob": 0.001196768251247704}, {"id": 1196, "seek": 322806, "start": 3254.7, "end": 3255.54, "text": " so you need to delegate.", "tokens": [51696, 370, 291, 643, 281, 40999, 13, 51738], "temperature": 0.0, "avg_logprob": -0.12560394040999873, "compression_ratio": 1.7232704402515724, "no_speech_prob": 0.001196768251247704}, {"id": 1197, "seek": 322806, "start": 3255.54, "end": 3256.86, "text": " How do you deal with that?", "tokens": [51738, 1012, 360, 291, 2028, 365, 300, 30, 51804], "temperature": 0.0, "avg_logprob": -0.12560394040999873, "compression_ratio": 1.7232704402515724, "no_speech_prob": 0.001196768251247704}, {"id": 1198, "seek": 325686, "start": 3256.86, "end": 3261.58, "text": " Yeah, I'm very close to like the ICs.", "tokens": [50364, 865, 11, 286, 478, 588, 1998, 281, 411, 264, 14360, 82, 13, 50600], "temperature": 0.0, "avg_logprob": -0.2138700236444888, "compression_ratio": 1.594488188976378, "no_speech_prob": 0.000606824061833322}, {"id": 1199, "seek": 325686, "start": 3261.58, "end": 3262.42, "text": " I'm very close.", "tokens": [50600, 286, 478, 588, 1998, 13, 50642], "temperature": 0.0, "avg_logprob": -0.2138700236444888, "compression_ratio": 1.594488188976378, "no_speech_prob": 0.000606824061833322}, {"id": 1200, "seek": 325686, "start": 3262.42, "end": 3266.58, "text": " Like I'm not someone who works through their reports", "tokens": [50642, 1743, 286, 478, 406, 1580, 567, 1985, 807, 641, 7122, 50850], "temperature": 0.0, "avg_logprob": -0.2138700236444888, "compression_ratio": 1.594488188976378, "no_speech_prob": 0.000606824061833322}, {"id": 1201, "seek": 325686, "start": 3266.58, "end": 3268.42, "text": " or follows the chain of command.", "tokens": [50850, 420, 10002, 264, 5021, 295, 5622, 13, 50942], "temperature": 0.0, "avg_logprob": -0.2138700236444888, "compression_ratio": 1.594488188976378, "no_speech_prob": 0.000606824061833322}, {"id": 1202, "seek": 325686, "start": 3268.42, "end": 3272.54, "text": " I just talk to the people who are actually doing the work.", "tokens": [50942, 286, 445, 751, 281, 264, 561, 567, 366, 767, 884, 264, 589, 13, 51148], "temperature": 0.0, "avg_logprob": -0.2138700236444888, "compression_ratio": 1.594488188976378, "no_speech_prob": 0.000606824061833322}, {"id": 1203, "seek": 325686, "start": 3274.02, "end": 3277.54, "text": " And so information flows quite freely.", "tokens": [51222, 400, 370, 1589, 12867, 1596, 16433, 13, 51398], "temperature": 0.0, "avg_logprob": -0.2138700236444888, "compression_ratio": 1.594488188976378, "no_speech_prob": 0.000606824061833322}, {"id": 1204, "seek": 325686, "start": 3279.1400000000003, "end": 3282.02, "text": " I'm sometimes, I think I'm mostly annoying people", "tokens": [51478, 286, 478, 2171, 11, 286, 519, 286, 478, 5240, 11304, 561, 51622], "temperature": 0.0, "avg_logprob": -0.2138700236444888, "compression_ratio": 1.594488188976378, "no_speech_prob": 0.000606824061833322}, {"id": 1205, "seek": 325686, "start": 3282.02, "end": 3283.7000000000003, "text": " at this point because I'm like pinging them every day.", "tokens": [51622, 412, 341, 935, 570, 286, 478, 411, 280, 8716, 552, 633, 786, 13, 51706], "temperature": 0.0, "avg_logprob": -0.2138700236444888, "compression_ratio": 1.594488188976378, "no_speech_prob": 0.000606824061833322}, {"id": 1206, "seek": 325686, "start": 3283.7000000000003, "end": 3284.58, "text": " How's that run going?", "tokens": [51706, 1012, 311, 300, 1190, 516, 30, 51750], "temperature": 0.0, "avg_logprob": -0.2138700236444888, "compression_ratio": 1.594488188976378, "no_speech_prob": 0.000606824061833322}, {"id": 1207, "seek": 325686, "start": 3284.58, "end": 3286.6600000000003, "text": " You know, have we tried this experiment?", "tokens": [51750, 509, 458, 11, 362, 321, 3031, 341, 5120, 30, 51854], "temperature": 0.0, "avg_logprob": -0.2138700236444888, "compression_ratio": 1.594488188976378, "no_speech_prob": 0.000606824061833322}, {"id": 1208, "seek": 328666, "start": 3286.66, "end": 3288.74, "text": " I'm very deeply involved in stuff.", "tokens": [50364, 286, 478, 588, 8760, 3288, 294, 1507, 13, 50468], "temperature": 0.0, "avg_logprob": -0.15847620917755423, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.00013132105232216418}, {"id": 1209, "seek": 328666, "start": 3289.7, "end": 3291.3799999999997, "text": " So we haven't had too much.", "tokens": [50516, 407, 321, 2378, 380, 632, 886, 709, 13, 50600], "temperature": 0.0, "avg_logprob": -0.15847620917755423, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.00013132105232216418}, {"id": 1210, "seek": 328666, "start": 3292.74, "end": 3297.74, "text": " I don't feel like there's an information flow issue", "tokens": [50668, 286, 500, 380, 841, 411, 456, 311, 364, 1589, 3095, 2734, 50918], "temperature": 0.0, "avg_logprob": -0.15847620917755423, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.00013132105232216418}, {"id": 1211, "seek": 328666, "start": 3298.1, "end": 3303.1, "text": " echo here with scaling, collaboration between teams,", "tokens": [50936, 14300, 510, 365, 21589, 11, 9363, 1296, 5491, 11, 51186], "temperature": 0.0, "avg_logprob": -0.15847620917755423, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.00013132105232216418}, {"id": 1212, "seek": 328666, "start": 3303.3799999999997, "end": 3305.12, "text": " especially when you're a global company", "tokens": [51200, 2318, 562, 291, 434, 257, 4338, 2237, 51287], "temperature": 0.0, "avg_logprob": -0.15847620917755423, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.00013132105232216418}, {"id": 1213, "seek": 328666, "start": 3305.12, "end": 3308.12, "text": " and you're not sitting in the same office as a person.", "tokens": [51287, 293, 291, 434, 406, 3798, 294, 264, 912, 3398, 382, 257, 954, 13, 51437], "temperature": 0.0, "avg_logprob": -0.15847620917755423, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.00013132105232216418}, {"id": 1214, "seek": 328666, "start": 3309.8599999999997, "end": 3310.98, "text": " That's very difficult.", "tokens": [51524, 663, 311, 588, 2252, 13, 51580], "temperature": 0.0, "avg_logprob": -0.15847620917755423, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.00013132105232216418}, {"id": 1215, "seek": 328666, "start": 3310.98, "end": 3313.22, "text": " I think remote work is really, really hard.", "tokens": [51580, 286, 519, 8607, 589, 307, 534, 11, 534, 1152, 13, 51692], "temperature": 0.0, "avg_logprob": -0.15847620917755423, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.00013132105232216418}, {"id": 1216, "seek": 328666, "start": 3313.22, "end": 3314.3799999999997, "text": " It's not easy.", "tokens": [51692, 467, 311, 406, 1858, 13, 51750], "temperature": 0.0, "avg_logprob": -0.15847620917755423, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.00013132105232216418}, {"id": 1217, "seek": 328666, "start": 3314.3799999999997, "end": 3315.22, "text": " It's not easy.", "tokens": [51750, 467, 311, 406, 1858, 13, 51792], "temperature": 0.0, "avg_logprob": -0.15847620917755423, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.00013132105232216418}, {"id": 1218, "seek": 331522, "start": 3315.22, "end": 3320.22, "text": " And I think that concentrating teams to geographical areas", "tokens": [50364, 400, 286, 519, 300, 40571, 5491, 281, 39872, 3179, 50614], "temperature": 0.0, "avg_logprob": -0.1926593351899908, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0003458939027041197}, {"id": 1219, "seek": 331522, "start": 3320.8199999999997, "end": 3324.8999999999996, "text": " or at least time zones is very important", "tokens": [50644, 420, 412, 1935, 565, 16025, 307, 588, 1021, 50848], "temperature": 0.0, "avg_logprob": -0.1926593351899908, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0003458939027041197}, {"id": 1220, "seek": 331522, "start": 3324.8999999999996, "end": 3328.7799999999997, "text": " and leads to a lot more productivity and effectiveness.", "tokens": [50848, 293, 6689, 281, 257, 688, 544, 15604, 293, 21208, 13, 51042], "temperature": 0.0, "avg_logprob": -0.1926593351899908, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0003458939027041197}, {"id": 1221, "seek": 331522, "start": 3328.7799999999997, "end": 3331.7799999999997, "text": " It's part of the reason I moved here to London", "tokens": [51042, 467, 311, 644, 295, 264, 1778, 286, 4259, 510, 281, 7042, 51192], "temperature": 0.0, "avg_logprob": -0.1926593351899908, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0003458939027041197}, {"id": 1222, "seek": 331522, "start": 3331.7799999999997, "end": 3334.22, "text": " is to be closer to a good chunk", "tokens": [51192, 307, 281, 312, 4966, 281, 257, 665, 16635, 51314], "temperature": 0.0, "avg_logprob": -0.1926593351899908, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0003458939027041197}, {"id": 1223, "seek": 331522, "start": 3334.22, "end": 3335.4599999999996, "text": " of our machine learning team.", "tokens": [51314, 295, 527, 3479, 2539, 1469, 13, 51376], "temperature": 0.0, "avg_logprob": -0.1926593351899908, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0003458939027041197}, {"id": 1224, "seek": 331522, "start": 3335.4599999999996, "end": 3338.18, "text": " Phil's here, Patrick is here.", "tokens": [51376, 7777, 311, 510, 11, 13980, 307, 510, 13, 51512], "temperature": 0.0, "avg_logprob": -0.1926593351899908, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0003458939027041197}, {"id": 1225, "seek": 331522, "start": 3340.66, "end": 3343.62, "text": " Like I want to be present and involved in the ML", "tokens": [51636, 1743, 286, 528, 281, 312, 1974, 293, 3288, 294, 264, 21601, 51784], "temperature": 0.0, "avg_logprob": -0.1926593351899908, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0003458939027041197}, {"id": 1226, "seek": 334362, "start": 3343.62, "end": 3346.18, "text": " component of the company as much as possible.", "tokens": [50364, 6542, 295, 264, 2237, 382, 709, 382, 1944, 13, 50492], "temperature": 0.0, "avg_logprob": -0.1396576622936213, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0012835977831855416}, {"id": 1227, "seek": 334362, "start": 3349.3399999999997, "end": 3351.14, "text": " Yeah, I think as we've scaled,", "tokens": [50650, 865, 11, 286, 519, 382, 321, 600, 36039, 11, 50740], "temperature": 0.0, "avg_logprob": -0.1396576622936213, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0012835977831855416}, {"id": 1228, "seek": 334362, "start": 3351.14, "end": 3354.14, "text": " there's been systems that we've used", "tokens": [50740, 456, 311, 668, 3652, 300, 321, 600, 1143, 50890], "temperature": 0.0, "avg_logprob": -0.1396576622936213, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0012835977831855416}, {"id": 1229, "seek": 334362, "start": 3354.14, "end": 3356.1, "text": " that have broken down at each phase,", "tokens": [50890, 300, 362, 5463, 760, 412, 1184, 5574, 11, 50988], "temperature": 0.0, "avg_logprob": -0.1396576622936213, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0012835977831855416}, {"id": 1230, "seek": 334362, "start": 3356.1, "end": 3358.94, "text": " stuff that worked for the first 10 of us,", "tokens": [50988, 1507, 300, 2732, 337, 264, 700, 1266, 295, 505, 11, 51130], "temperature": 0.0, "avg_logprob": -0.1396576622936213, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0012835977831855416}, {"id": 1231, "seek": 334362, "start": 3358.94, "end": 3361.22, "text": " didn't work for the next 20,", "tokens": [51130, 994, 380, 589, 337, 264, 958, 945, 11, 51244], "temperature": 0.0, "avg_logprob": -0.1396576622936213, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0012835977831855416}, {"id": 1232, "seek": 334362, "start": 3362.22, "end": 3364.18, "text": " didn't work for the next 100.", "tokens": [51294, 994, 380, 589, 337, 264, 958, 2319, 13, 51392], "temperature": 0.0, "avg_logprob": -0.1396576622936213, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0012835977831855416}, {"id": 1233, "seek": 334362, "start": 3364.18, "end": 3369.18, "text": " Now we're pushing 350, I think.", "tokens": [51392, 823, 321, 434, 7380, 18065, 11, 286, 519, 13, 51642], "temperature": 0.0, "avg_logprob": -0.1396576622936213, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0012835977831855416}, {"id": 1234, "seek": 334362, "start": 3369.74, "end": 3372.2599999999998, "text": " And there are people at the company who I don't know,", "tokens": [51670, 400, 456, 366, 561, 412, 264, 2237, 567, 286, 500, 380, 458, 11, 51796], "temperature": 0.0, "avg_logprob": -0.1396576622936213, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0012835977831855416}, {"id": 1235, "seek": 334362, "start": 3372.2599999999998, "end": 3373.38, "text": " which is insane.", "tokens": [51796, 597, 307, 10838, 13, 51852], "temperature": 0.0, "avg_logprob": -0.1396576622936213, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.0012835977831855416}, {"id": 1236, "seek": 337362, "start": 3374.62, "end": 3378.7799999999997, "text": " A super weird experience.", "tokens": [50414, 316, 1687, 3657, 1752, 13, 50622], "temperature": 0.0, "avg_logprob": -0.18200180747292258, "compression_ratio": 1.6105769230769231, "no_speech_prob": 0.00020980936824344099}, {"id": 1237, "seek": 337362, "start": 3381.06, "end": 3383.2599999999998, "text": " But we've hired really fantastic people", "tokens": [50736, 583, 321, 600, 13144, 534, 5456, 561, 50846], "temperature": 0.0, "avg_logprob": -0.18200180747292258, "compression_ratio": 1.6105769230769231, "no_speech_prob": 0.00020980936824344099}, {"id": 1238, "seek": 337362, "start": 3383.2599999999998, "end": 3384.74, "text": " and we continue to do so.", "tokens": [50846, 293, 321, 2354, 281, 360, 370, 13, 50920], "temperature": 0.0, "avg_logprob": -0.18200180747292258, "compression_ratio": 1.6105769230769231, "no_speech_prob": 0.00020980936824344099}, {"id": 1239, "seek": 337362, "start": 3384.74, "end": 3388.7799999999997, "text": " And I think you just trust that people will still", "tokens": [50920, 400, 286, 519, 291, 445, 3361, 300, 561, 486, 920, 51122], "temperature": 0.0, "avg_logprob": -0.18200180747292258, "compression_ratio": 1.6105769230769231, "no_speech_prob": 0.00020980936824344099}, {"id": 1240, "seek": 337362, "start": 3388.7799999999997, "end": 3390.62, "text": " make the right decisions going forward", "tokens": [51122, 652, 264, 558, 5327, 516, 2128, 51214], "temperature": 0.0, "avg_logprob": -0.18200180747292258, "compression_ratio": 1.6105769230769231, "no_speech_prob": 0.00020980936824344099}, {"id": 1241, "seek": 337362, "start": 3390.62, "end": 3393.46, "text": " and that you've set standards high enough", "tokens": [51214, 293, 300, 291, 600, 992, 7787, 1090, 1547, 51356], "temperature": 0.0, "avg_logprob": -0.18200180747292258, "compression_ratio": 1.6105769230769231, "no_speech_prob": 0.00020980936824344099}, {"id": 1242, "seek": 337362, "start": 3395.74, "end": 3398.14, "text": " that you don't need to approve every single hire.", "tokens": [51470, 300, 291, 500, 380, 643, 281, 18827, 633, 2167, 11158, 13, 51590], "temperature": 0.0, "avg_logprob": -0.18200180747292258, "compression_ratio": 1.6105769230769231, "no_speech_prob": 0.00020980936824344099}, {"id": 1243, "seek": 337362, "start": 3398.14, "end": 3399.74, "text": " You don't need to know what every single person", "tokens": [51590, 509, 500, 380, 643, 281, 458, 437, 633, 2167, 954, 51670], "temperature": 0.0, "avg_logprob": -0.18200180747292258, "compression_ratio": 1.6105769230769231, "no_speech_prob": 0.00020980936824344099}, {"id": 1244, "seek": 337362, "start": 3399.74, "end": 3400.8199999999997, "text": " is working on.", "tokens": [51670, 307, 1364, 322, 13, 51724], "temperature": 0.0, "avg_logprob": -0.18200180747292258, "compression_ratio": 1.6105769230769231, "no_speech_prob": 0.00020980936824344099}, {"id": 1245, "seek": 340082, "start": 3401.82, "end": 3405.1800000000003, "text": " And you just trust your colleagues.", "tokens": [50414, 400, 291, 445, 3361, 428, 7734, 13, 50582], "temperature": 0.0, "avg_logprob": -0.17695523897806803, "compression_ratio": 1.6045627376425855, "no_speech_prob": 0.0006331013864837587}, {"id": 1246, "seek": 340082, "start": 3405.1800000000003, "end": 3407.9, "text": " Yeah, I can attest that you hire very well.", "tokens": [50582, 865, 11, 286, 393, 951, 377, 300, 291, 11158, 588, 731, 13, 50718], "temperature": 0.0, "avg_logprob": -0.17695523897806803, "compression_ratio": 1.6045627376425855, "no_speech_prob": 0.0006331013864837587}, {"id": 1247, "seek": 340082, "start": 3407.9, "end": 3409.82, "text": " It's probably the best culture I've ever seen", "tokens": [50718, 467, 311, 1391, 264, 1151, 3713, 286, 600, 1562, 1612, 50814], "temperature": 0.0, "avg_logprob": -0.17695523897806803, "compression_ratio": 1.6045627376425855, "no_speech_prob": 0.0006331013864837587}, {"id": 1248, "seek": 340082, "start": 3409.82, "end": 3411.7000000000003, "text": " in any company, actually.", "tokens": [50814, 294, 604, 2237, 11, 767, 13, 50908], "temperature": 0.0, "avg_logprob": -0.17695523897806803, "compression_ratio": 1.6045627376425855, "no_speech_prob": 0.0006331013864837587}, {"id": 1249, "seek": 340082, "start": 3411.7000000000003, "end": 3413.02, "text": " Thank you so much.", "tokens": [50908, 1044, 291, 370, 709, 13, 50974], "temperature": 0.0, "avg_logprob": -0.17695523897806803, "compression_ratio": 1.6045627376425855, "no_speech_prob": 0.0006331013864837587}, {"id": 1250, "seek": 340082, "start": 3413.02, "end": 3415.02, "text": " Final question, I mean, just out of interest,", "tokens": [50974, 13443, 1168, 11, 286, 914, 11, 445, 484, 295, 1179, 11, 51074], "temperature": 0.0, "avg_logprob": -0.17695523897806803, "compression_ratio": 1.6045627376425855, "no_speech_prob": 0.0006331013864837587}, {"id": 1251, "seek": 340082, "start": 3415.02, "end": 3417.54, "text": " do you get like microcosms in the different offices?", "tokens": [51074, 360, 291, 483, 411, 4532, 6877, 2592, 294, 264, 819, 14434, 30, 51200], "temperature": 0.0, "avg_logprob": -0.17695523897806803, "compression_ratio": 1.6045627376425855, "no_speech_prob": 0.0006331013864837587}, {"id": 1252, "seek": 340082, "start": 3417.54, "end": 3421.2200000000003, "text": " I mean, do you see like different mini cultures?", "tokens": [51200, 286, 914, 11, 360, 291, 536, 411, 819, 8382, 12951, 30, 51384], "temperature": 0.0, "avg_logprob": -0.17695523897806803, "compression_ratio": 1.6045627376425855, "no_speech_prob": 0.0006331013864837587}, {"id": 1253, "seek": 340082, "start": 3421.2200000000003, "end": 3422.94, "text": " Oh yeah, totally, 100%.", "tokens": [51384, 876, 1338, 11, 3879, 11, 2319, 6856, 51470], "temperature": 0.0, "avg_logprob": -0.17695523897806803, "compression_ratio": 1.6045627376425855, "no_speech_prob": 0.0006331013864837587}, {"id": 1254, "seek": 340082, "start": 3422.94, "end": 3426.1400000000003, "text": " Like the London office compared to the Toronto office", "tokens": [51470, 1743, 264, 7042, 3398, 5347, 281, 264, 14140, 3398, 51630], "temperature": 0.0, "avg_logprob": -0.17695523897806803, "compression_ratio": 1.6045627376425855, "no_speech_prob": 0.0006331013864837587}, {"id": 1255, "seek": 340082, "start": 3426.1400000000003, "end": 3428.98, "text": " compared to SF, New York.", "tokens": [51630, 5347, 281, 31095, 11, 1873, 3609, 13, 51772], "temperature": 0.0, "avg_logprob": -0.17695523897806803, "compression_ratio": 1.6045627376425855, "no_speech_prob": 0.0006331013864837587}, {"id": 1256, "seek": 343082, "start": 3430.9, "end": 3433.3, "text": " The vibes are very, very different.", "tokens": [50368, 440, 27636, 366, 588, 11, 588, 819, 13, 50488], "temperature": 0.0, "avg_logprob": -0.15049270283092153, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.0004953424795530736}, {"id": 1257, "seek": 343082, "start": 3433.3, "end": 3434.6200000000003, "text": " Like so different.", "tokens": [50488, 1743, 370, 819, 13, 50554], "temperature": 0.0, "avg_logprob": -0.15049270283092153, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.0004953424795530736}, {"id": 1258, "seek": 343082, "start": 3436.1800000000003, "end": 3438.1800000000003, "text": " London is so nice.", "tokens": [50632, 7042, 307, 370, 1481, 13, 50732], "temperature": 0.0, "avg_logprob": -0.15049270283092153, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.0004953424795530736}, {"id": 1259, "seek": 343082, "start": 3438.1800000000003, "end": 3441.02, "text": " It feels really tight-knit.", "tokens": [50732, 467, 3417, 534, 4524, 12, 5457, 270, 13, 50874], "temperature": 0.0, "avg_logprob": -0.15049270283092153, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.0004953424795530736}, {"id": 1260, "seek": 343082, "start": 3441.02, "end": 3442.82, "text": " Like it still feels like a startup,", "tokens": [50874, 1743, 309, 920, 3417, 411, 257, 18578, 11, 50964], "temperature": 0.0, "avg_logprob": -0.15049270283092153, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.0004953424795530736}, {"id": 1261, "seek": 343082, "start": 3444.42, "end": 3445.34, "text": " which we are a startup,", "tokens": [51044, 597, 321, 366, 257, 18578, 11, 51090], "temperature": 0.0, "avg_logprob": -0.15049270283092153, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.0004953424795530736}, {"id": 1262, "seek": 343082, "start": 3445.34, "end": 3447.9, "text": " but it still feels like a tiny 30-person startup", "tokens": [51090, 457, 309, 920, 3417, 411, 257, 5870, 2217, 12, 10813, 18578, 51218], "temperature": 0.0, "avg_logprob": -0.15049270283092153, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.0004953424795530736}, {"id": 1263, "seek": 343082, "start": 3447.9, "end": 3451.42, "text": " where you go out for beers with your colleagues", "tokens": [51218, 689, 291, 352, 484, 337, 34159, 365, 428, 7734, 51394], "temperature": 0.0, "avg_logprob": -0.15049270283092153, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.0004953424795530736}, {"id": 1264, "seek": 343082, "start": 3451.42, "end": 3454.7000000000003, "text": " after work at the pub like regularly.", "tokens": [51394, 934, 589, 412, 264, 1535, 411, 11672, 13, 51558], "temperature": 0.0, "avg_logprob": -0.15049270283092153, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.0004953424795530736}, {"id": 1265, "seek": 343082, "start": 3454.7000000000003, "end": 3456.6200000000003, "text": " Everyone knows what everyone else is working on", "tokens": [51558, 5198, 3255, 437, 1518, 1646, 307, 1364, 322, 51654], "temperature": 0.0, "avg_logprob": -0.15049270283092153, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.0004953424795530736}, {"id": 1266, "seek": 343082, "start": 3456.6200000000003, "end": 3460.7000000000003, "text": " inside the office, calls on each other for help.", "tokens": [51654, 1854, 264, 3398, 11, 5498, 322, 1184, 661, 337, 854, 13, 51858], "temperature": 0.0, "avg_logprob": -0.15049270283092153, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.0004953424795530736}, {"id": 1267, "seek": 346070, "start": 3460.74, "end": 3461.98, "text": " London is super tight-knit.", "tokens": [50366, 7042, 307, 1687, 4524, 12, 5457, 270, 13, 50428], "temperature": 0.0, "avg_logprob": -0.19457437424432664, "compression_ratio": 1.5972850678733033, "no_speech_prob": 4.262427319190465e-05}, {"id": 1268, "seek": 346070, "start": 3461.98, "end": 3463.62, "text": " I think the culture here is like,", "tokens": [50428, 286, 519, 264, 3713, 510, 307, 411, 11, 50510], "temperature": 0.0, "avg_logprob": -0.19457437424432664, "compression_ratio": 1.5972850678733033, "no_speech_prob": 4.262427319190465e-05}, {"id": 1269, "seek": 346070, "start": 3465.3799999999997, "end": 3466.8999999999996, "text": " I can't pick favorites,", "tokens": [50598, 286, 393, 380, 1888, 16907, 11, 50674], "temperature": 0.0, "avg_logprob": -0.19457437424432664, "compression_ratio": 1.5972850678733033, "no_speech_prob": 4.262427319190465e-05}, {"id": 1270, "seek": 346070, "start": 3466.8999999999996, "end": 3468.58, "text": " but I really like the culture here.", "tokens": [50674, 457, 286, 534, 411, 264, 3713, 510, 13, 50758], "temperature": 0.0, "avg_logprob": -0.19457437424432664, "compression_ratio": 1.5972850678733033, "no_speech_prob": 4.262427319190465e-05}, {"id": 1271, "seek": 346070, "start": 3470.06, "end": 3472.3799999999997, "text": " In Toronto, it's our biggest office,", "tokens": [50832, 682, 14140, 11, 309, 311, 527, 3880, 3398, 11, 50948], "temperature": 0.0, "avg_logprob": -0.19457437424432664, "compression_ratio": 1.5972850678733033, "no_speech_prob": 4.262427319190465e-05}, {"id": 1272, "seek": 346070, "start": 3472.3799999999997, "end": 3474.9399999999996, "text": " and so it's much broader,", "tokens": [50948, 293, 370, 309, 311, 709, 13227, 11, 51076], "temperature": 0.0, "avg_logprob": -0.19457437424432664, "compression_ratio": 1.5972850678733033, "no_speech_prob": 4.262427319190465e-05}, {"id": 1273, "seek": 346070, "start": 3476.7799999999997, "end": 3478.02, "text": " but the culture there is amazing too.", "tokens": [51168, 457, 264, 3713, 456, 307, 2243, 886, 13, 51230], "temperature": 0.0, "avg_logprob": -0.19457437424432664, "compression_ratio": 1.5972850678733033, "no_speech_prob": 4.262427319190465e-05}, {"id": 1274, "seek": 346070, "start": 3478.02, "end": 3480.7, "text": " Super hard-working, stay late,", "tokens": [51230, 4548, 1152, 12, 22475, 11, 1754, 3469, 11, 51364], "temperature": 0.0, "avg_logprob": -0.19457437424432664, "compression_ratio": 1.5972850678733033, "no_speech_prob": 4.262427319190465e-05}, {"id": 1275, "seek": 346070, "start": 3480.7, "end": 3483.22, "text": " and like grind very passionate.", "tokens": [51364, 293, 411, 16700, 588, 11410, 13, 51490], "temperature": 0.0, "avg_logprob": -0.19457437424432664, "compression_ratio": 1.5972850678733033, "no_speech_prob": 4.262427319190465e-05}, {"id": 1276, "seek": 346070, "start": 3483.22, "end": 3484.8199999999997, "text": " There's like different groups", "tokens": [51490, 821, 311, 411, 819, 3935, 51570], "temperature": 0.0, "avg_logprob": -0.19457437424432664, "compression_ratio": 1.5972850678733033, "no_speech_prob": 4.262427319190465e-05}, {"id": 1277, "seek": 346070, "start": 3484.8199999999997, "end": 3486.62, "text": " that are close with each other there.", "tokens": [51570, 300, 366, 1998, 365, 1184, 661, 456, 13, 51660], "temperature": 0.0, "avg_logprob": -0.19457437424432664, "compression_ratio": 1.5972850678733033, "no_speech_prob": 4.262427319190465e-05}, {"id": 1278, "seek": 348662, "start": 3487.62, "end": 3490.9, "text": " New York is new, but that city is just so much fun.", "tokens": [50414, 1873, 3609, 307, 777, 11, 457, 300, 2307, 307, 445, 370, 709, 1019, 13, 50578], "temperature": 0.0, "avg_logprob": -0.27394973314725435, "compression_ratio": 1.5358851674641147, "no_speech_prob": 0.00012144778884248808}, {"id": 1279, "seek": 348662, "start": 3490.9, "end": 3493.5, "text": " It's just like such an incredible city,", "tokens": [50578, 467, 311, 445, 411, 1270, 364, 4651, 2307, 11, 50708], "temperature": 0.0, "avg_logprob": -0.27394973314725435, "compression_ratio": 1.5358851674641147, "no_speech_prob": 0.00012144778884248808}, {"id": 1280, "seek": 348662, "start": 3493.5, "end": 3496.14, "text": " so much energy, always awake,", "tokens": [50708, 370, 709, 2281, 11, 1009, 15994, 11, 50840], "temperature": 0.0, "avg_logprob": -0.27394973314725435, "compression_ratio": 1.5358851674641147, "no_speech_prob": 0.00012144778884248808}, {"id": 1281, "seek": 348662, "start": 3496.14, "end": 3497.7799999999997, "text": " work hard, play hard.", "tokens": [50840, 589, 1152, 11, 862, 1152, 13, 50922], "temperature": 0.0, "avg_logprob": -0.27394973314725435, "compression_ratio": 1.5358851674641147, "no_speech_prob": 0.00012144778884248808}, {"id": 1282, "seek": 348662, "start": 3499.58, "end": 3501.3399999999997, "text": " SF, I spend the least time in.", "tokens": [51012, 31095, 11, 286, 3496, 264, 1935, 565, 294, 13, 51100], "temperature": 0.0, "avg_logprob": -0.27394973314725435, "compression_ratio": 1.5358851674641147, "no_speech_prob": 0.00012144778884248808}, {"id": 1283, "seek": 348662, "start": 3501.3399999999997, "end": 3505.42, "text": " I'm not a huge SF fan, to be completely honest.", "tokens": [51100, 286, 478, 406, 257, 2603, 31095, 3429, 11, 281, 312, 2584, 3245, 13, 51304], "temperature": 0.0, "avg_logprob": -0.27394973314725435, "compression_ratio": 1.5358851674641147, "no_speech_prob": 0.00012144778884248808}, {"id": 1284, "seek": 348662, "start": 3505.42, "end": 3506.8599999999997, "text": " It's our second HQ,", "tokens": [51304, 467, 311, 527, 1150, 43209, 11, 51376], "temperature": 0.0, "avg_logprob": -0.27394973314725435, "compression_ratio": 1.5358851674641147, "no_speech_prob": 0.00012144778884248808}, {"id": 1285, "seek": 348662, "start": 3507.74, "end": 3511.8199999999997, "text": " but I just haven't gotten into the city,", "tokens": [51420, 457, 286, 445, 2378, 380, 5768, 666, 264, 2307, 11, 51624], "temperature": 0.0, "avg_logprob": -0.27394973314725435, "compression_ratio": 1.5358851674641147, "no_speech_prob": 0.00012144778884248808}, {"id": 1286, "seek": 348662, "start": 3511.8199999999997, "end": 3513.98, "text": " I think, in the way that others have.", "tokens": [51624, 286, 519, 11, 294, 264, 636, 300, 2357, 362, 13, 51732], "temperature": 0.0, "avg_logprob": -0.27394973314725435, "compression_ratio": 1.5358851674641147, "no_speech_prob": 0.00012144778884248808}, {"id": 1287, "seek": 351398, "start": 3514.82, "end": 3518.62, "text": " I think SF compared to like New York, Toronto, London,", "tokens": [50406, 286, 519, 31095, 5347, 281, 411, 1873, 3609, 11, 14140, 11, 7042, 11, 50596], "temperature": 0.0, "avg_logprob": -0.38822438500144263, "compression_ratio": 1.617801047120419, "no_speech_prob": 0.0003149186377413571}, {"id": 1288, "seek": 351398, "start": 3519.54, "end": 3521.58, "text": " I feel like New York, Toronto, and London", "tokens": [50642, 286, 841, 411, 1873, 3609, 11, 14140, 11, 293, 7042, 50744], "temperature": 0.0, "avg_logprob": -0.38822438500144263, "compression_ratio": 1.617801047120419, "no_speech_prob": 0.0003149186377413571}, {"id": 1289, "seek": 351398, "start": 3521.58, "end": 3524.22, "text": " are real cities.", "tokens": [50744, 366, 957, 6486, 13, 50876], "temperature": 0.0, "avg_logprob": -0.38822438500144263, "compression_ratio": 1.617801047120419, "no_speech_prob": 0.0003149186377413571}, {"id": 1290, "seek": 351398, "start": 3525.22, "end": 3528.58, "text": " There are artists, there are, you know,", "tokens": [50926, 821, 366, 6910, 11, 456, 366, 11, 291, 458, 11, 51094], "temperature": 0.0, "avg_logprob": -0.38822438500144263, "compression_ratio": 1.617801047120419, "no_speech_prob": 0.0003149186377413571}, {"id": 1291, "seek": 351398, "start": 3528.58, "end": 3532.78, "text": " people just doing a very diverse set of things,", "tokens": [51094, 561, 445, 884, 257, 588, 9521, 992, 295, 721, 11, 51304], "temperature": 0.0, "avg_logprob": -0.38822438500144263, "compression_ratio": 1.617801047120419, "no_speech_prob": 0.0003149186377413571}, {"id": 1292, "seek": 351398, "start": 3532.78, "end": 3536.38, "text": " and across all the different fields", "tokens": [51304, 293, 2108, 439, 264, 819, 7909, 51484], "temperature": 0.0, "avg_logprob": -0.38822438500144263, "compression_ratio": 1.617801047120419, "no_speech_prob": 0.0003149186377413571}, {"id": 1293, "seek": 351398, "start": 3536.38, "end": 3538.06, "text": " that are going on there,", "tokens": [51484, 300, 366, 516, 322, 456, 11, 51568], "temperature": 0.0, "avg_logprob": -0.38822438500144263, "compression_ratio": 1.617801047120419, "no_speech_prob": 0.0003149186377413571}, {"id": 1294, "seek": 351398, "start": 3538.06, "end": 3540.22, "text": " you have some of the best people in the world.", "tokens": [51568, 291, 362, 512, 295, 264, 1151, 561, 294, 264, 1002, 13, 51676], "temperature": 0.0, "avg_logprob": -0.38822438500144263, "compression_ratio": 1.617801047120419, "no_speech_prob": 0.0003149186377413571}, {"id": 1295, "seek": 354022, "start": 3541.22, "end": 3544.1, "text": " SF is much more, it feels more homogenous to me.", "tokens": [50414, 31095, 307, 709, 544, 11, 309, 3417, 544, 3655, 45519, 281, 385, 13, 50558], "temperature": 0.0, "avg_logprob": -0.39468709160299864, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.0013659148244187236}, {"id": 1296, "seek": 354022, "start": 3544.1, "end": 3545.54, "text": " It's a lot of people doing the same stuff.", "tokens": [50558, 467, 311, 257, 688, 295, 561, 884, 264, 912, 1507, 13, 50630], "temperature": 0.0, "avg_logprob": -0.39468709160299864, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.0013659148244187236}, {"id": 1297, "seek": 354022, "start": 3545.54, "end": 3547.5, "text": " There's sort of one topic of conversation.", "tokens": [50630, 821, 311, 1333, 295, 472, 4829, 295, 3761, 13, 50728], "temperature": 0.0, "avg_logprob": -0.39468709160299864, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.0013659148244187236}, {"id": 1298, "seek": 354022, "start": 3547.5, "end": 3549.8599999999997, "text": " You don't bump into someone", "tokens": [50728, 509, 500, 380, 9961, 666, 1580, 50846], "temperature": 0.0, "avg_logprob": -0.39468709160299864, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.0013659148244187236}, {"id": 1299, "seek": 354022, "start": 3549.8599999999997, "end": 3554.06, "text": " with a categorically different worldview than you,", "tokens": [50846, 365, 257, 19250, 984, 819, 41141, 813, 291, 11, 51056], "temperature": 0.0, "avg_logprob": -0.39468709160299864, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.0013659148244187236}, {"id": 1300, "seek": 354022, "start": 3554.06, "end": 3556.06, "text": " or perspective, or experience.", "tokens": [51056, 420, 4585, 11, 420, 1752, 13, 51156], "temperature": 0.0, "avg_logprob": -0.39468709160299864, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.0013659148244187236}, {"id": 1301, "seek": 354022, "start": 3558.06, "end": 3559.5, "text": " And so I like visiting,", "tokens": [51256, 400, 370, 286, 411, 11700, 11, 51328], "temperature": 0.0, "avg_logprob": -0.39468709160299864, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.0013659148244187236}, {"id": 1302, "seek": 354022, "start": 3559.5, "end": 3563.5, "text": " because I meet like brilliant people in our field, in tech.", "tokens": [51328, 570, 286, 1677, 411, 10248, 561, 294, 527, 2519, 11, 294, 7553, 13, 51528], "temperature": 0.0, "avg_logprob": -0.39468709160299864, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.0013659148244187236}, {"id": 1303, "seek": 354022, "start": 3565.4599999999996, "end": 3568.4599999999996, "text": " But to live there would be really cool.", "tokens": [51626, 583, 281, 1621, 456, 576, 312, 534, 1627, 13, 51776], "temperature": 0.0, "avg_logprob": -0.39468709160299864, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.0013659148244187236}, {"id": 1304, "seek": 356846, "start": 3568.46, "end": 3572.42, "text": " To live there would be really difficult for me.", "tokens": [50364, 1407, 1621, 456, 576, 312, 534, 2252, 337, 385, 13, 50562], "temperature": 0.0, "avg_logprob": -0.1500517280356398, "compression_ratio": 1.6759259259259258, "no_speech_prob": 0.0004876972525380552}, {"id": 1305, "seek": 356846, "start": 3572.42, "end": 3577.42, "text": " I would feel like I'm sacrificing whole pieces of my life.", "tokens": [50562, 286, 576, 841, 411, 286, 478, 42294, 1379, 3755, 295, 452, 993, 13, 50812], "temperature": 0.0, "avg_logprob": -0.1500517280356398, "compression_ratio": 1.6759259259259258, "no_speech_prob": 0.0004876972525380552}, {"id": 1306, "seek": 356846, "start": 3581.34, "end": 3582.42, "text": " But I love visiting.", "tokens": [51008, 583, 286, 959, 11700, 13, 51062], "temperature": 0.0, "avg_logprob": -0.1500517280356398, "compression_ratio": 1.6759259259259258, "no_speech_prob": 0.0004876972525380552}, {"id": 1307, "seek": 356846, "start": 3582.42, "end": 3583.26, "text": " It's a great place.", "tokens": [51062, 467, 311, 257, 869, 1081, 13, 51104], "temperature": 0.0, "avg_logprob": -0.1500517280356398, "compression_ratio": 1.6759259259259258, "no_speech_prob": 0.0004876972525380552}, {"id": 1308, "seek": 356846, "start": 3583.26, "end": 3584.9, "text": " And I love the folks who are there,", "tokens": [51104, 400, 286, 959, 264, 4024, 567, 366, 456, 11, 51186], "temperature": 0.0, "avg_logprob": -0.1500517280356398, "compression_ratio": 1.6759259259259258, "no_speech_prob": 0.0004876972525380552}, {"id": 1309, "seek": 356846, "start": 3584.9, "end": 3587.46, "text": " and most of our investors are there.", "tokens": [51186, 293, 881, 295, 527, 11519, 366, 456, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1500517280356398, "compression_ratio": 1.6759259259259258, "no_speech_prob": 0.0004876972525380552}, {"id": 1310, "seek": 356846, "start": 3587.46, "end": 3591.3, "text": " And so it's a really cool environment,", "tokens": [51314, 400, 370, 309, 311, 257, 534, 1627, 2823, 11, 51506], "temperature": 0.0, "avg_logprob": -0.1500517280356398, "compression_ratio": 1.6759259259259258, "no_speech_prob": 0.0004876972525380552}, {"id": 1311, "seek": 356846, "start": 3591.3, "end": 3593.7, "text": " very intense and like competitive,", "tokens": [51506, 588, 9447, 293, 411, 10043, 11, 51626], "temperature": 0.0, "avg_logprob": -0.1500517280356398, "compression_ratio": 1.6759259259259258, "no_speech_prob": 0.0004876972525380552}, {"id": 1312, "seek": 356846, "start": 3593.7, "end": 3595.94, "text": " and those are really good things.", "tokens": [51626, 293, 729, 366, 534, 665, 721, 13, 51738], "temperature": 0.0, "avg_logprob": -0.1500517280356398, "compression_ratio": 1.6759259259259258, "no_speech_prob": 0.0004876972525380552}, {"id": 1313, "seek": 356846, "start": 3595.94, "end": 3598.26, "text": " It's very motivating to be there.", "tokens": [51738, 467, 311, 588, 41066, 281, 312, 456, 13, 51854], "temperature": 0.0, "avg_logprob": -0.1500517280356398, "compression_ratio": 1.6759259259259258, "no_speech_prob": 0.0004876972525380552}, {"id": 1314, "seek": 359826, "start": 3598.26, "end": 3600.26, "text": " But I think I can get that just by visiting.", "tokens": [50364, 583, 286, 519, 286, 393, 483, 300, 445, 538, 11700, 13, 50464], "temperature": 0.0, "avg_logprob": -0.12629767714953813, "compression_ratio": 1.408450704225352, "no_speech_prob": 0.00034412002423778176}, {"id": 1315, "seek": 359826, "start": 3600.26, "end": 3603.1400000000003, "text": " I don't need to commit myself full time.", "tokens": [50464, 286, 500, 380, 643, 281, 5599, 2059, 1577, 565, 13, 50608], "temperature": 0.0, "avg_logprob": -0.12629767714953813, "compression_ratio": 1.408450704225352, "no_speech_prob": 0.00034412002423778176}, {"id": 1316, "seek": 359826, "start": 3603.98, "end": 3606.3, "text": " Aidan Gomez, it's been an honor and a pleasure.", "tokens": [50650, 316, 31675, 43537, 11, 309, 311, 668, 364, 5968, 293, 257, 6834, 13, 50766], "temperature": 0.0, "avg_logprob": -0.12629767714953813, "compression_ratio": 1.408450704225352, "no_speech_prob": 0.00034412002423778176}, {"id": 1317, "seek": 359826, "start": 3606.3, "end": 3607.5800000000004, "text": " Thank you so much for joining us.", "tokens": [50766, 1044, 291, 370, 709, 337, 5549, 505, 13, 50830], "temperature": 0.0, "avg_logprob": -0.12629767714953813, "compression_ratio": 1.408450704225352, "no_speech_prob": 0.00034412002423778176}, {"id": 1318, "seek": 359826, "start": 3607.5800000000004, "end": 3609.2200000000003, "text": " Thank you so much for having me.", "tokens": [50830, 1044, 291, 370, 709, 337, 1419, 385, 13, 50912], "temperature": 0.0, "avg_logprob": -0.12629767714953813, "compression_ratio": 1.408450704225352, "no_speech_prob": 0.00034412002423778176}], "language": "en"}