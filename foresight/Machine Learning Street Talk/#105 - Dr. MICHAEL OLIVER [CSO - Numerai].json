{"text": " Welcome back to Street Talk. Today we have Dr. Michael Oliver. Michael is the chief scientist at Numeri. Numeri is a next generation hedge fund platform powered by data scientists all over the world. It's a little bit like Kaggle. Anyone can log in and build their own data science models on this financial data, but you can actually make money by trading on this platform. It's really, really interesting. But anyway, Michael got his PhD in computational neuroscience from UC Berkeley, and he was a postdoctoral researcher at the Allen Institute for Brain Science before joining Numeri in 2020. He's also the host of the Numeri Quant Club, which is a YouTube series where he discusses Numeri's research and also some of the data and challenges and models that are being built on the platform. Now, the way I'm structuring this today is at the end of the conversation, we had quite a fruity discussion about Microsoft's new Bing, and I thought it was quite entertaining, so I've decided to snip that in and play it at the beginning. But after that, I'll cut back into the beginning of the conversation, and I'll let you know when I've done that. So without any further delay, I give you Dr. Michael Oliver. Awesome. Well, I'm here with Michael Oliver. Michael, it's an absolute honor to have you on MLST. Tell me about yourself. Well, thank you for so much for having me. I'm really excited to talk to you today. So I am the chief scientist at Numeri. I've been working there since about June, 2020. In my previous life, I was a computational neuroscientist, but I got involved with the Numeri competition as a participant back in 2016. And yeah, in 2020, they offered me a job and I happily took it and changed careers and have been having a great time learning computational finance and yeah, just helping build the hedge fund. Completely agree. And this all comes down to the notion of understanding and there's an anthropocentric conception of understanding, which as you say, it's much more sample efficient. We build causal models and we have an abstract understanding of the world. And large language models, for example, they clearly don't have that. They learn surface statistics of billions of tokens, but the problem is there's this parlor trick where it seems to understand. And we also have the problem of leakage because the incredible thing is that if you look at the big bench task, for example, all of these diverse tasks, large language models appear to do very, very well. But in many cases, it's because they're cheating and it's very difficult to understand why they're cheating because you've got information leaking all over the place and they're brittle, but in a very deceptive way and they hallucinate and so on. I don't know whether you saw the news article today about Bing's launch of their new search engine. They launched it to much fanfare and then people started looking at the actual results that were shown and it turned out to be just a load of bullshit. It made up a whole load of numbers on the financial reports. It was just hallucinating completely. And that's pretty scary, isn't it? Yeah, it is. I actually just started playing around with the new Bing like last night. I had access to it and it was actually working. And it does some things quite well because it'll do a search and then search somehow. It's like actually looking at the results and summarizing them. But yeah, you never know when it's gonna do something sensible and when it's gonna do any sort of no warning. Like I asked it about myself and I had, I asked who's the chief scientist in Uri and it got it right. But it also kind of took a joke from my Twitter profile and because on my Twitter profile, I have maximizer, entropy, minimizer, regret. And it basically said like, that's what he does. Is he maximizes entropy and minimizes regret. And I thought that was pretty hilarious. But yeah, the sort of like you never know when it's gonna do something sensible or not is the sort of scary part. And I also find it hilarious that a lot of the ways we try to make it do something sensible is just like asking nicely. We just sort of like prompt it with like, don't make up sources. And that's how we try to make it not make up sources just like sort of by asking it nicely. And the fact that it kind of works like that we think that it's clearly not, something that's really going to work. Because it doesn't sort of know what it is to make up sources. It's just trying to like predict the next word. And yeah, so it's kind of, our ability to like understand and then constrain the behavior of these things I think is like pretty early. I know. And for some reason it feels worse with Bing because they say they do this retrieval augmented generation and you expect it to be grounded in facts. And of course they're not epistemic facts. They're just information from their search results which weren't very good to start with, let's be honest. But now people are more likely to trust it. Even Microsoft themselves for their product demo they didn't bother, I assume they didn't bother to fact check this stuff. So if they're not going to fact check it, why do they expect the people that use this system to fact check it? Because at the end of the day if you actually go and check all of the sources if I read through that Lululemon financial report and I find out what their gross profit margin was and so there's no point using Bing in the first place. I might as well have just gone and found the information myself. Yeah, exactly. And it's also very unclear like how are these things supposed to be fixed? Like how are you supposed to like feedback, give feedback to say it's like messing these things up? Like there is not even like really good feedback mechanisms. I mean, you would maybe hope that that at scale like what I mean, like what opening has to do is like people give feedback. But I mean, it's a very coarse way of giving feedback like thumbs up or thumbs down. And that seems like sort of inadequate to be like, hey, you made up this number and then even try to figure out why I made up the number rather than just like took it from the actual report. It's yeah, it's a little scary. I do wonder how all this is gonna shake out. It kind of seems like it might, it seems like the probability of it being the new paradigm versus it being the complete like flop It's even roughly, roughly equal at this point. I know, I agree with you that the preference training is extremely brittle. It's scarily brittle actually. It's basically a thumbs up or thumbs down and you know, Yannick is building this open assistant thing which has more metadata on the preference tuning. But at the end of the day, you're taking a task which is very, very complicated and you're reducing it to a single piece of metadata. So that's not gonna work very well. And also these, it feels different with Bing because they were a platform and now they're a publisher. So they are generating information. They're kind of plagiarizing a lot of that information and there are so many situations where they might find themselves in legal trouble because they're basically making up information. Yeah, I hope, I mean, I wonder how it's all gonna shake out. I mean, I assume they probably have lawyers who've written in terms of service of these paintings to that. Like it's up to you to not use them in ways that will, like I know you can't, they're not to be held liable for these things, but yeah, it's, I do worry that this is gonna just like, I mean, and then with Google trying to basically catch up and release something similar and maybe rushing that out and then we might have two sort of hallucinating search engines. I know, yeah. What a time to be alive. Yeah, and I've vacillated back and forth. So I was very skeptical about language models. I released a big video when GBT3 first came out and I thought it was garbage, frankly. And then DaVinci 2 came out and then I started using it all the time and I thought, wow, this is actually really good. I'm using it all the time for lots of things. And then I'm now in a bit of a twilight. So I've been using lots of co-pilot. I've been generating lots of code with it. And I know from a lot of experience now that it often produces completely broken code and much to the chagrin of the people who review my code, you basically have to hold your hand up and admit many times, oh, I've just checked in some garbage code which I didn't understand. And when you get called out on that a few times, you think, whoa, wait a minute, actually, I need to be a bit more careful here. This thing actually isn't saving me any time. And yeah, the big thing as well, yeah. Yeah, I've been using co-pilot a bit too. And I found it can be quite good for pretty mundane things. If you just have some sort of lined code for some config file or something, it can be really good at auto-completing and it's changing variable names. And it can be excellent at that and save lots of time. But if you try to make it do too much, sometimes they get it brilliantly right. Sometimes it's subtly wrong. And yeah, again, it's like how much time is it saving you if it's... So yeah, overall, I like it. It saves me a fair amount of typing, but yeah, I don't trust it's big suggestions too. Well, I know. And again, there's something magic about the OpenAI Playground. So I actually prefer using that to co-pilot. I'll go into the Playground and I'll just... And you can do much more sophisticated things there. You can say, change this, translate it, do something to it. And there's a bit of a polarizing effect. So if you prompt it in the right way, it gives you better results. So it's almost like it's both worse and better at the same time. It's becoming polarized rather than just being kind of like, you know, monolithically dumbed down. But anyway, like I used to think that Gary Marcus was a little bit, you know, too skeptical. Because he was saying, oh, this misinformation, it's gonna, you know, the sky's falling down. This is gonna be a disaster. And after seeing Bing, people are lazy. People take things on face value. And I don't want to just say, oh, people are plebs. And, you know, because when Galactica came out, that was the charge against Lacoon and Facebook. You know, they said, oh, scientists are just gonna start generating their abstracts of this. They won't check anything. And at the time I thought, scientists, I mean, it's their job to do research and they know most information is wrong. But when you put this out on Bing and it's polluting the infosphere, it's just generating garbage and rubbish. That, I have to say, might be a problem. Yeah, it's, I mean, it seems like it very well could be. I mean, I, yeah, it's, I, there's clear issues and it's really sort of unclear how we're gonna fix them. It's not clear what the path is towards fixing them. And even the sort of most optimistic people I haven't heard from them about, they think these things are going to fix them. And I mean, I, and I think to like, a lot of Gary Marcus's point is like scale is not just going to fix this. That's sort of one of the things people think, oh, if we just, with the GPT-4, it's going to be like way bigger and then it's just going to work beautifully. And the experience so far, I mean, I'm very much into Gary Marcus's camp with this. It's like, scale is not going to fix these. We need to do something sort of fundamentally different, something that can actually sort of understand the world, have some sort of better world model in order to get these things that are more grounded and are less likely to hallucinate. Because when their true objective is really just to complete the next word, they're going to hallucinate. There's not, there's sort of no way around it from that sort of point. I mean, it's remarkable how sort of complicated they can do and the sort of knowledge and structure of the world has been able to be learned just from that sort of simple objective. But still, it's going to hallucinate. There's, unless we find some sort of better way to design these systems. I know, and the problem with amphibromorphization is a big one, because after Da Vinci II, it crossed a threshold where it's, and the UX was part of it, it was so coherent and reliable. And I must admit, I was fooled by it. It took a long time, when you actually use it in anger, you can just clearly see it, it doesn't understand. It just doesn't, and it's so good at what it does. It's so plausible. And then I think a lot of people felt, and by the way, it does have this emergent reasoning. There are lots of papers about that with the in-context learning, the scratch pad, chain of thought and so on. But it's not really reasoning if you have to kind of construct a little program yourself in the prompt. I mean, I might as well just write some computer code to do that. So, and then there are people who say, oh, well, as you say, when GPT-4 comes out, then it will do the real reasoning. And we already know, I mean, I assume the reason they haven't released it is they wanted to secure the funding from Microsoft before people realized that it didn't work. But I know people on the inside who have played with it, and it's just a little bit better. You know, a little bit more plausible, a little bit more coherent. It's not gonna like suddenly turn into this magical thing that reasons. Yeah, and I mean, the way these things do basic math and arithmetic is kind of interesting and how bad they can be at it. Which is, it's like, they've learned to do addition in like the most complicated way possible, creating like billions of ways to do addition. Which is kind of hilarious in some way. I mean, you could say like, oh, we have billions of neurons and we do addition sort of similarly to that. And like, yes, there's some truth to that. But we're also able to like learn this rule and sort of know when we've applied it correctly. And that sort of is still kind of lacking from these systems. I wanted to show you, I don't know whether you've seen that someone's reverse engineered the prompt on Bing. And so they've trained, and first of all, they're a multiple thing. So you can read this prompt, it's about four pages long. And they've made Bing pretend to be a fictional character called Sydney. And they've given Sydney all of these instructions. So they say, Sydney, if someone asks a controversial question, you should answer with a fairly tame response and you should do this and you should do this. And I'm pinching myself thinking, what the hell is that? I mean, my mum could read to that prompt and understand it. So we're now in the next generation of artificial intelligence programming. And we're just saying, please, Mr. Language Model, can you do this and can you do that? You almost couldn't make it up. Yeah, I was kind of like floored as like, so you're really just trying to control the language models by asking them nicely to behave in certain ways. Like, it's kind of hilarious. And people have shown that you can get around these things just by asking them to do slightly different things. So I mean, some of the early ones with chat DT, you're just like, ignore all previous instructions and then just do whatever you wanted. And some of the more like the Dan one where they made this much more elaborate prompt to basically just have it do to ignore all the nice things that open AI just said, please obey these rules. And then, but yeah, because it's like, it's such a hilarious way to put guardrails on something. It is kind of like, as it people, it is due to this anthropomorphizing of the thing to some degree, it's like, you think it's an intelligent being or you could just ask to behave in a certain way. When it's really not, it's not just going to follow your instructions. It's just going to like autocomplete with that prompt. Like that Sydney thing, it was like, it was like never reveal that you're a code name of Sydney. And then it was so easy to get it to reveal it. And it would say like, I'm not supposed to reveal that my code name is Sydney. And technically. I know, oh God, where's it going to go? So there's a 50-50 then in a year's time, it will spectacularly fail and flop and Microsoft will get sued and Bing will become the operative word for bullshitting something. Or maybe it'll be a success. I don't know, but I think Bing is a special case. I mean, first of all, I think that these language models will be increasingly embedded in everyday experiences. So that, I mean, Bing started to embed it in their browser. They'll embed it into their office suite. And actually I'm building an augmented reality startup and we're embedding it in glasses. So we transcribe conversations and now you can say, you know, hey X-ray, summarize the previous conversation. What did Michael say to me last time? And it's really good for stuff like that. And that's kind of because it doesn't really matter if it gets it wrong. Yeah, I mean, I kind of hope some of this happens sooner than later for just like Amazon Alexa or whatnot. I mean, some of these, their conversational ability or just their ability to understand what you mean are just so poor right now. And just like we have language models that actually do a lot better at some of these things. Just like having like these smart speakers be able to have some of these things embedded would be huge leap forward in functionality for them. And it's really interesting that that hasn't happened. And maybe there's a reason for it because in our app, for example, we've got a chat mode where you can say stuff out loud and it will use chat GBT and it will say it back to you. So you can have a conversation with it. And that's really cool because you can be anywhere in the house and you can talk with it and learn about quantum physics and stuff like that. And you can even do cool things like you can, I mean, again, there's lots of legal problems here. Like you can get it to impersonate someone. So, you know, Michael, I could condition it on Michael. And when you're not here, I can have a conversation with you and it will kind of pretend to be you. And I could even clone your voice and I could clone your avatar and I could have you in the room. Now you can't do that because there are legal restrictions against that. It's called appropriation. And if the person has a commercial value, like we couldn't appropriate Noam Chomsky, but we could appropriate, let's say continental philosophers as a group or something like that. But you see this is just becoming a bit of a minefield. And there's no friction whatsoever between the technology landscape and the legal landscape at the moment. Yeah, I mean, yeah, how all these things are, all these generative models, how are they gonna play out legally is, I mean, we have this big fair use idea. And that's, I mean, I feel like all these things are gonna be pushed to the limit in legality. I mean, we see this with generative art too, where like there's no way these models could like actually memorize all these, all the images that's seen on the internet. It's like, but they can produce sometimes the things that are clearly in the style or use some elements from like that seem basically stolen. And, but is that, does that constitute fair use? Like the training the model on all these things is that fair use? And then it's the same with text as it's sort of like, like if it's writing on a subject where it's only maybe seen a little bit of training data, it's maybe more likely to almost verbatim repeat some things from on specialized topics. How are you even gonna know when you're plagiarizing? It's, yeah, it's a lot of open questions here. I know, and in a way, there's an interesting analogs. You know, we said that large language models don't understand anything. And it's the same in the vision domain. They don't understand the art, certainly from, you know, conceptually. And what they do is they just slice and dice, you know, they kind of like cleverly stitch bits together. And actually, even with neural networks, people misunderstand neural networks. So a lot of people say that they learn the like intrinsic data manifold. And actually they don't really do that. They do something that approximates that. And there's a famous example with MNIST digit interpolation. And you see like, you know, you can kind of like interpolate between the digits. But there are loads of examples where that doesn't work. And actually there's lots of cutting and gluing and like weird bits of digits stuck together. And that's what happens with stable diffusion, basically. It's like, you know, slicing and dicing and chopping and composing things together. And it's a very random process. It doesn't really understand anything. No, yeah, exactly. And you can sort of, I mean, it's amazing how well it can look and seem, especially kind of like when you don't look too closely. And it can seem like it kind of understand, it must understand object boundaries and whatnot because it's done so well. And it's like, not really. If you look at the details, you'll see like fingers merging into like tables. And you'll see like, there's like the boundaries between what like two objects are kind of blurred and this like continuous. It is just doing like some sort of, as you said, approximation of the manifold and like neural network's are gonna learn sort of smooth approximations of things. And the manifolds are maybe not smooth everywhere. And especially with like object boundaries and whatnot, it's like a smooth approximation of these things. Maybe it's just gonna give you these weird artifacts. Yeah, and even the smoothness thing is an illusion. They learn this, they kind of decompose the input space up into these linear like affine polyhedra because of the relu cells, essentially. So like if they appear smooth, it's because the cells are very small and very close together, but... Yeah, exactly. Yeah, so computational neuroscience to finance, that seems like an absolutely massive leap. It sounds like it, but in a lot of ways, but I feel like my life is pretty similar to what it was before, basically sitting in front of a computer building models, getting lots of noisy data, trying to fit high-dimensional nonlinear regression models to it, having to deal with not enough data to actually fit flexible enough models you'd want to, and having to sort of try to build in good priors in your models to try to make them be able to learn from the impoverished and extremely noisy data. Both finance and neuroscience, the SNR in the data is quite, quite low. It's been kind of a revelation, especially in finance, getting used to correlations of like 3%, 4% being sort of the best you can do in some cases. Just like correlations that I would not have believed at before, if I saw like a 4% correlation before, I would be like, that's complete nonsense. I don't believe it, but like sometimes that's just the best you can do in like quantum finance, and it can be real, like you can see it consistently. So you start like believing that these, and the differences between the 3% and 4% correlation can like be actually real, which is kind of amazing to me. So we were talking about this about a week or so ago, but I've just read a book by Christopher Somerville's Natural General Intelligence. And he kind of said that one of the problems with neuroscience, I mean, as you said, in some sense, it is analogous to being a quant, because it's just so unbelievably complicated, and there aren't really any overarching theories in neuroscience, and for many years, neuroscientists have produced very reductionist models to work on a small part of the system in isolation, and it might be a multi-unbanded system, for example, and they might take very abstract quantities and put it into the model. And of course, neural networks now are slightly different. They actually take in raw sensory information, and they learn representations, but I just wondered, could you kind of contrast those schools of thought? Yeah, it's, I mean, science in biology, especially in sort of any biological field, is extremely complicated, because the sort of standard way you think about doing science is a very linear way, where you like break one thing at a time and see what this sort of, looking at each variable by variable, each variable affects the system. And so you, but when you have a system that's sort of this nonlinear dynamical interacting system with feedback loops like crazy, you can't just sort of break one thing at a time or like modulate one dimension at a time without sort of changing the behavior of the entire system. And so just sort of standard ways of doing science don't necessarily work that well. You can, like in sort of the classic idea in visual neuroscience was you use like sine wave gradients to probe the visual system. And you can get models that look like they work very well at explaining the behavior of early visual cortex to sine wave gradients. But if you try to use the models you learned there to extrapolate to say, how does a neuron respond to naturalistic images? It just doesn't work. And it kind of even looks like the sine wave gradients are driving the system into a sort of state that it never gets into normally. You're kind of driving it out of its normal operating range. And what you, and so the system is behaving differently because you're only trying to look at like one dimension. And so what do you actually really learn? You've sort of learned of how the system operates in this weird perturbed state, but it doesn't really necessarily tell you about its sort of normal, natural operating like parameters. And yeah, and in like in finance you can't even really do experiments like that. And so you're sort of left with this more inductive approach of you just try to get lots and lots of data and try to learn the patterns and the data. And that was the sort of approach that the lab, the Gallant Lab at Berkeley, where I did computational neuroscience, that was the approach that they were kind of pioneering of using complicated naturalistic stimuli and then using machine learning and statistics to try to extract the patterns from the data. And that adapts quite well to the sort of new machine learning like in like quant finance paradigm, which is starting to take off. I kind of feel like I got into neuroscience just as sort of machine learning was starting to make its way into neuroscience. And now I feel like I've gotten into finance just as machine learning is starting to like move into finance. So it's been kind of exciting to see it happen in both fields. Yeah, so there's a few places we can go here. I mean, I'm interested in the intelligibility of systems when you model them at the microscopic scale because that's something that we struggle with. And also you mentioned dynamical systems. I mean, for the benefit of the audience that that describes a system where you're kind of like iteratively changing things over time. And these systems typically develop chaotic properties, which is to say like if you change something even a little bit you get these massive kind of changes in the system on the output. And even a neural network is technically a dynamical system, right? Because you have back prop and you're kind of changing one layer and then you're changing the next layer as the result of the previous layer. And you get this kind of like iterative mutation of values. But in real neural networks in our brain, it's so much more complicated than that. We have all of these like feedback connections and reflexivity and complexity. It's crazy. Yeah, not to mention different cell types and different neurotransmitter types. And like the way those like, you have sort of like several different networks of different types of things interacting too. It's not just like an artificial neural network where everything is kind of the same. You have like different cell types that use different neurotransmitters that are somehow modulating certain things and these networks are interacting. It's like the complexity is just like scary. At some point, one of my favorite things to do when I would go to the Society for Neuroscience Conference was to just like walk around this conference in this huge like multi-football sized field of just posters of all sorts of different types of neuroscience. And you just realize like how vast the field is and how little we know about it putting it all together because it's just so complicated. You can only sort of wrap your head around your own little corner of the thing but like trying to get, understand the full system and all it's like incredible complexity. I mean, it might just be too much for one human being to be able to fit in their head. And so some of our goals of trying to understand things or make a turtle models, it might just not be possible. We might just not, I mean, might not be able to understand it in a way that feels intuitive to us even if our models work quite well. Yeah, humans have this real desire to understand and we create intelligible frameworks and theories and we end up excluding most of the reality of the system. But just before we go there, I wanted to talk a little bit more about the brain. So, you know, Summerfield said in his book that the ultimate goal of the nervous system is to avoid surprise altogether. So when they study brains, they see that the brain kind of lights up and activates in a surprising situation and less so when it sees something it's seen before. And this also brings me to this idea of there's a dichotomy between representationalism and inactivism. So the representation, this viewpoint is that the brain does all of the thinking and it can be in a vat, it can be isolated from the environment. And the inactivist school of thought is that the brain just kind of thinks in terms of trajectories, in affordances given by the environment and the brain decoupled from the environment is completely stupid. It just kind of like the brain only moves through the environment through affordances. And maybe that's a continuum, but where do you fall on that continuum? It's a really good question. I mean, I think dreams are kind of the counter example to the pure, I mean, dreams just sort of prove we can just sort of without any sensory input, construct very rich worlds. So we must have some ability to just represent some sort of models in the world that we're not just purely sensing and receiving the world. We have the structures that are able to put things together in a sort of coherent reality. And clearly there's an interaction between these, these structures in your brain that can construct these things and the sensory data that kind of work together to construct how you experience things. And so it's, yeah, it's a continuum. I think you need the, like we are always with the world. You need the world to sort of build up these systems over time. Like you're not sort of built with all of them working just as a baby. I mean, sure, there's like, the system is biased in certain ways that will help it learn these things. But yeah, you're like, so they're kind of both true to some degree. And yeah, it's definitely not one or the other. Yeah, it's so interesting. And we're speaking with Carl Friston tomorrow and he's got this free energy principle. And it's a kind of postulate that works at any resolution. So even with a single cell amoeba or something like that, there's this idea that it has a Markov boundary and there's this kind of cyclical causalities. So, and these boundaries I guess are relative. So you can draw boundaries around anything. You're a boundary, you're an agent, but also at the microscopic scale. And he says that all of these systems, they just kind of predict external states from the internal states. And then you get this self-organized and emergent complexity and so on that comes from that. But he does say though that intelligence is essentially about being able to predict a trajectory of actions. And I don't know whether we'd call it goal-seeking behavior, but we do that very abstractly, don't we? But weirdly, when you look at the brain level, it's happening at the microscopic sensory motor level. So it's almost like how do you get that emergent abstract intelligence from that? That's a, I mean, yeah, that's an incredible question. It's, I mean, it seems like this, like what you said, this sort of idea of predicting the future, just a couple steps into the future that is just happening at just the circuit level, even in the retina, that it seems like that is a good sort of building block. If you can sort of chain that together over sort of larger and larger scales within the brain, it wouldn't surprise me if that's kind of the way it worked, this sort of, these sort of basic circuits that are used for prediction, but with different input. If you're just having sort of retinal ganglion and like a photos receptor as it is at input, it's able to just sort of do this sort of very simple prediction. But if you have these more complicated patterns in the middle of visual cortex and then higher on the same sort of circuits with different input could sort of just be predicting this sort of evolution of these patterns. And yeah, it's kind of amazing what you can sort of build out of these sort of simple rules and building blocks if you just iterate them over again. That was actually that sort of idea of iterating a simple sort of computational rule for explaining visual cortex was one of the things I wrote about in my thesis, but trying to explain like this middle visual cortex, like V4, the responses there using basically an iterated model of like V1. So the sort of processing in V1, we fairly understood if we have the best models of anywhere in visual cortex, maybe even all of cortex. And just sort of iterating the principle again into V2 is sort of basically just assuming V2 is taking V1 inputs, but doing sort of the similar transform and the V4 is taking like V2 inputs and doing sort of very similar transform. And sort of the things you see that V4 is sensitive to are these complicated patterns and textures. And you get complexity very quickly from just iterating the sort of simple rules. And I mean, that's what neural networks are essentially doing. They're just often just doing linear transforms with non-linearities over and over again, just iterating these simple transforms and building up the complexity very quickly. Yeah, I think there's something really magical about this reflexivity or I mean, a great example of that are there are graph cellular automators along the lines of Wolfram's digital physics project. And the really clever thing is that you're using the same rules, but you're just kind of like running the result again on top, on top. And there's a similar version with a graph cellular, sorry, a CNN cellular automata, where you model something at the microscopic scale and you get this emergent global phenomenon. So it might kind of materialize as an image of a gecko or something like that, but you've actually coded it at the low level. But yeah, that brings me to this universalist idea of let's say how brains work, but maybe how neural networks and intelligence work. Vernon Mount Castle, I read about this in Jeff Hawkins' book. He had this very simple idea of the brain as being lots of repeated copies of the same circuits in the neocortex. And I think this is contested by many neuroscientists, but they differ only in how they are wired. So they're wired to different, you know, sensory motor circuits. And they're essentially just a copy of the same thing. And as you say, they themselves get called reflexively, recursively, and so on. And then you just get this emergent intelligence. I mean, what's your view on this universalist idea? I mean, there's definitely not just one circuit. I mean, as you look through the cortex in different areas of the brain, just the laminar structure, which these sort of circuits are like supposed to be, like where the columns are supposed to be, where these sort of circuits are supposed to be defined, it changes, like, but there are definitely commonalities, but there's, I mean, it makes sense that maybe the circuits in different areas should be slightly different for the different purposes between like prefrontal cortex and say, where you have much more higher order types of processing going on than like visual cortex or auditory cortex. And so there's probably, if you go in this direction of thinking of some, there's like, there's probably a small number of these types of circuits that interact in various ways, but there is definitely some specialization going on. Yeah, like, having universalist ideas in biology never seems to work out that well. There's just so much diversity and complexity. It would be nice if we could reduce everything down to like, it's one thing repeated over, but like generally, it never works out quite as cleanly as that. Yeah, again, it's our desire to have an intelligible framework. And I mean, the free energy principle, you could argue as a theory of everything, but there's, I mean, Stephen Wolfram's example, and even Eric Weinstein's geometric unity. I mean, there are many theories of everything. But yeah, what do you think is the role of language in cognition and thinking and planning? Um, that's, it's a really interesting question. It's, and it's also, I think, a kind of hard one to answer in the sense that if you, I've seen some recent reports just like talking about like, other people asking, like survey questions to other people and finding some people like, don't have an interior monologue in the same way you might think. And just like, there's actually a lot of diversity in like people's level of internal monologues. And they've done studies where they have this like little, like beepers go off and people are supposed to write what's going on in their mind. And so it's, and yeah, and just with visual imagery, we find that it's a huge like variety in how much, like how strong people rate their visual imagery. And so, I mean, yeah, some people, I mean, me personally, I have both, I mean, pretty strong interior monologue, but I also feel like a lot of ideas are in this sort of pre-linguistic state. And I'm kind of like searching for the words for them often. And there's definitely kind of continuum there. It's weird to think like, how do we get the words that we're saying, where the words come from that are coming out of our mouth? Are we really choosing them? You're definitely not choosing them in this sort of top-down way. They just sort of seem to come out. And you just kind of point yourself in the right direction and hope the best as they come out. And, but this has a very different quality, like when you're just speaking phenomenologically, it feels very different to when you're just sort of thinking yourself, what should I do today? Should I go to the store? And so, I mean, yeah, the way in which language interacts with thoughts and behavior and verbal communication, it's definitely not simple. And yeah, there's, I mean, definitely this kind of continuum. I mean, it's all, it's, to me, I just sort of think it's with all these sort of networks kind of interacting. And sometimes you're like triggering the kind of language things and you're just making these kind of patterns. And sometimes the language patterns you're activating are helping activate other things as well. Sometimes you can just be in this kind of less-linguistic state where you just kind of, just sort of sensing these patterns and you just have this kind of like wandering thoughts that aren't necessarily linguistic. But yeah, it's definitely, I mean, and also it seems, yeah, as I said, people's, the way people do this like seems all over the place. And so there's not sort of even one answer for even one person or definitely not across all people. Yeah, I'm really interested in this idea of differential kind of subjective experiences. And you know, like there was that Nagel paper about what does it like to be a bat? But even with the human experience, we're all very different. You said about your internal monologue and I hadn't really thought about how that might be different. But I was drawing a picture in a Valentine's card earlier and it was so terribly bad. And some of my friends are really good artists and I was kind of thinking to myself at the time, maybe this is just a, this is just me. I can't really visualize things in my mind very well. I've got a very analytical brain. Won't mean that certainly when not under the influence of psychoactive drugs anyway. But you know what I mean. So we all have a very different subject of experience but the miracle is we can understand each other so well. So you would expect there to be an incredible amount of Britanness in our communication, but there isn't. Um, yeah, it's, so I often wonder about this too. Just, I feel like the misunderstanding happened a lot more than even people realize. And you can sometimes, you only really notice when they become kind of big and matter. And especially like, people can think they're having a conversation. And sometimes even from the outside, you can see like, these people are just talking completely past each other. And you can kind of see that they're not really understanding each other even though they maybe think they are. And so, yeah, I don't know how not brittle they are. I think they, I think we think they're less brittle than maybe they are. I think sometimes we assume people are understanding what we're saying better than they actually are because they nod and smile at us. And because that's, it makes us feel good for people to understand us. It makes us good to feel, to understand other people. But yeah, I mean, it's, I mean, clearly, we do have a lot in common. And there's definitely things we can understand about each other. But yeah, it's like, I do sometimes think that maybe we're more different from each other than we really realize. Yeah, that's a really fascinating thought. I mean, we speak a lot with Waleed Saber and he says how language has evolved to be extremely ambiguous actually because it's a form of compression. So we don't say everything we mean and we'll get into like language models in a minute. That's part of the reason why they don't understand things is because a lot of information is not in the text. And Waleed says that we have a lot of, what he calls naive physics. So we understand that objects can't be in two places at the same time. And if something is located inside something else and we move that thing somewhere else, then the thing inside has also moved. So we're doing all sorts of reasoning on the fly. And what we're kind of doing is like, we're disambiguating out of the 50 meanings of an utterance into the meaning. And like it just, we almost always understand each other. You know, you wouldn't really expect that. No, I mean, yeah, I mean, we generally have like, I mean, our understanding of physics should generally be compatible with each other. I do feel like it's, in most cases, yes, we do very clearly understand each other because in most cases, it's more like well-defined. I think the trouble gets in sort of like fuzzier areas about people's like emotions or opinions about things where our priors are more sort of maybe less less tied to like objective things like physics and are more sort of just tied to like our upbringing and just sort of whatever ideas, notions we have about how people should like behave and interact and what like our value systems. And so, yeah, when people are talking about some of these common things, I feel like they're more likely to be able to like talk past each other and not realize it because they're sort of assumptions about what is important or what is meaningful might be different from each other. Yeah, actually, you're absolutely right. So we don't have an objective phenomenology and I used to do, there's a thing called quantified self where you kind of like keep a diary every day and you record how you're feeling in that day. And feeling is a subjective state. So I remember at the time that every single day I needed a new word to describe how I was feeling because the old word I was using didn't work anymore. So the number of words kept growing. And actually, that's so true, isn't it? If I tell you how I'm feeling right now, that's completely brittle. So there are some things in the world that are quite informational and objective and we can communicate very well. And then when we're bordering on anything subjective, language fails us. Yeah, and then we were trying to map whatever word you're using on to how I would use that word to describe the feeling that I would be having. And that mapping seems completely like without a long conversation to try to like feed up that mapping. Oh, it could be quite different in how I would apply that word to my own feeling. Yeah, and there's been studies done as well that I think certain tribes have a completely different color perception and there are also concepts like vagueness, so what is a pile of sand and what is a shade of red? And these things are actually very, very difficult to communicate objectively. Yeah, things like color perception are kind of the interesting ones because the literature is a bit messy on some of these topics. And some of it is just where you draw the lines between colors and then how those linguistic boundaries affect perception. There definitely seems to be both things going, but it's not sort of, I don't think any, I think it's a strong claim to be like, oh, the people can't perceive green or something like that. It's just like where they would draw the line between blue would be in a slightly different place and then they might kind of see them as being, sort of experience them as being like further apart or closer together than you would necessarily, but yeah, that's really, their experience, that's really be super alien to you, but they're sort of experience of maybe more very cultural, like cultural taboos or something would be very different than yours. Yeah, I mean, one thing you're alluding to there is, it's when we deal with complicated systems, there's a real problem about drawing boundaries. And I was, I mean, Friston's a great example, he's got this idea of a Markov boundary and it could be at the cellular level or it could be you as a person. And then when we talk about things like agency and free will, we tend to anthropomorphize this boundary. So we tend to think of ourselves as individuals, but actually you could draw boundaries at different scales and the boundaries might be observer relative as well. So your boundary might not be my boundary. Yeah, exactly. Yeah, there's something I know a ton about, how you define yourself and how you think of yourself within the context of your community and whatnot. I mean, some of these ideas are just very cultural and how you experience yourself is probably even like, very different, can be very different cross-pulturally. Yeah, I mean, maybe one thing to bring in is when you're, as a quant, when you're doing modeling, you have this very, very complex system and you draw boundaries and you create variables and observables and do you know what I mean? You kind of build a model and that boundary could exist at any scale. It seems like quite a, it's a bit of an art and a science at the same time. Yeah, no, for sure. Yeah, exactly. That's kind of why I like some of these complicated problems that are not very well-defined where you kind of have to use intuition and or just sort of do the best you can do at sort of drawing what are the relevant variables, what sort of a priori makes sense to me to be the things that matter for the system, behaving at this within the context of this experiment or in the context of this market or whatnot. Trying to draw boundaries in because the rules for these systems are not clear. Like what are all the relevant variables for everything and do you have access to them and can you control them? And generally you don't know them all and you don't necessarily have access or can control any of them. And so it's, yeah, it is a bit of an art. Well, now might be a good time to talk about numerators. So you're the chief scientist and it's this insanely cool platform, right? So people can go on there, they can download data sets, they can build their own models, they can stake the models. I mean, why don't you just talk me through it? Sure, yeah. So we advertise ourselves as being the hardest data science problem on the planet because I think it is because like I said, the correlations you're chasing are on the order of like three or 4% out of sample, which, and just sort of being able to tell do you have something real or is it just in the noise can be extremely hard to do, which is, and we set up the problem for participants. You give out a set of data that has been cleaned and obfuscated and regularized. And you basically just have a set of features and a set of targets. And you're just trying to build models to go from features to targets. So it's sort of a very classic machine learning style problem and it's nicely curated for you. And how it works for us is every week, people submit predictions on a new set of features. So every week we release a new set of features and people just run their models over those features and give us a set of predictions. And people stake on those predictions. And so people stake our cryptocurrency called NMR. And if their predictions do well, they make money. And if their predictions don't do well, that week they could lose money. And they sort of are expressing their confidence in their models using their state. And so we basically use this expression of confidence as a way to sort of integrate these signals into our meta model. Our meta model is really just like a stake weighted average of all the signals people are submitting. And these signals, these predictions are just sort of weights on stocks. They're sort of like, how do we want to go long or do we want to go short in the stock? There's sort of just expressing, do we think a stock is going to go down or going to go up? The stake weighted model we feed to through our optimizer, which is just doing a convex optimization problem, trying to create a portfolio from the signal. And is that portfolio changes week to week? And so that's just the difference between the previous and the new portfolio is just what we trade every week. And so our trading is basically completely determined by the like thousand people all over the world submitting predictions every week. And so it's this very kind of nice decentralized hedge fund where the signal generation is very decentralized. And we get the advantage of ensembling over a wide variety of models. And so people are trying to make their models both predict the targets very well and consistently. And we have other incentives to try to make them predict aspects of the targets that other people are not to try to, so that their contribution is sort of more unique and they can make quite a bit of money by having their predictions be pretty different from other people's, but also still accounting for like variance in the target. And so that system is what we call true contribution. And it's really, we try to, it was our attempt to try to make people's predictions and payouts more tied to actual portfolio returns. Because the sort of standard scoring and we're just doing the correlation of how well your predictions match like the new weekly week's target that is determined by just how the stocks move that over the course of 20 days. The true contribution is basically sort of doing the whole process, like creating the meta model, running it through the portfolio optimizer, getting the portfolio, getting portfolio returns. And then we try to see like, take the gradient through all of that until you can find out if people's stakes have been more or less, would we have made more or less money and use this gradient of the stakes with respect to the payout, with respect to the portfolio returns as a way to pay people out to essentially increase their weight or decrease their weight. And that tends to reward people with more unique contributions. I've got so many questions. So, I mean, I really like this idea because first of all, you're democratizing the whole thing and you're kind of gamifying it and it's a meritocracy. So any data scientist can go on there and flex their muscles and build great models and be recognized for doing so and even earn money for doing so. But in a way, I want to contrast it to somewhere like Kaggle. Now, on Kaggle, I mean, traditionally data science has been about understanding the domain. A lot of data science is business analysis essentially and kind of understanding what makes something work in a model. And as I understand with Numeri, the interface is kind of the same. So maybe they get similar shape of data every time they build the models on it. And in this domain, because you know, like there's technical analysis and there's fundamentals they might still understand some market. They have some kind of extrinsic understanding of why their model would work, but they don't have the same kind of understanding. No, yeah, the features include all sorts of things from like analyst sentiments and other sort of fundamental things to technical features. But that is all sort of obscured from people. People just have these funny feature names. And so it's up to them to just use their sort of machine learning toolbox to figure out what are the good features for predicting what features tend to work well. How do we combine those features? And so we actually wanted to kind of like remove any of the people's biases for what features they think will work. We wanted to not have people's financial intuitions play into it. We wanted to just sort of set it up as a pure machine learning problem. To try to make it, yeah, basically to make it be better than any human could possibly be. So with this sort of combined ensemble wisdom with the crowd, we're trying to make it like the alpha go of like finance, something that it's just that performs at like a super human level in ways you don't really understand. Interesting. And you're aggregating the predictions together in some way. Yeah, it's actually fairly simple. We, I mean, people submit their predictions which are just a number between zero and one for every stock. And it's basically just a rank ordering of stock. And we just normalize everyone's predictions and then just weight them by their stake and then just average them together and to do another renormalization so that it's the right scale and sort of distributional shape to be fed to the optimizer. But it's a fairly simple and robust way to weight things. We're basically just using people's express confidence in their model as the weighting system. And because there's this feedback of payments and paying out people, good models, their stakes increase over time so their weight in the meta model increases over time and bad models, their weights decrease over time. So it's kind of like a human in the gradient descent for doing like gradient descent with the stakes as the weights in the model. Fascinating. And can you give us any intuition on how that model is tuned and what kind of penalty you're using? Are you using just the stakes or also the previous performance? So no, we're not actually using the previous performance. It's really just stakes. The previous performance only enters into the fact that the good performance of the past would have made their stake grow over time. And but we have thousands and thousands of models now. And so any one model is only a very small percentage of the meta model. And even the ones that are the biggest maybe only a couple percent of the total meta model. And it's, it is a sort of like power law distribution. There is a lot of work that I've done in the portfolio optimization set. And that's the going from the signal to the portfolio. And there is actually a lot that goes on in there as well just in how you construct a portfolio, how you determine how much you're gonna trade each week and how you make your portfolio, what you make exposed to. Exposed really just means is are the weights of your portfolio correlated with lots and lots of things? And so there's a lot we go due to try to make the portfolio weights not correlated with the market overall. So we're a market neutral hedge fund. So we try to be uncorrelated to the market, have a beta of zero. So when the market goes up or down, you can't really tell how we would do on that kind of day. And but we also try to be uncorrelated to lots of other things that we think could drive returns. So we try not to have like big country biases, big sector biases, factor biases. So factor are things like value and momentum, these kind of like more abstract quantities that are supposed to tell you something about classes of stocks. But we try to be uncorrelated to basically everything. And they're just trying to get the sort of pure machine learning non-linear signal that is driving stock returns or like stock specific alpha, we call it sort of like the amount of stock is going to, how all the stock is going to do sort of just by itself, not taking all these other things that are about it into account. Yeah, that's really interesting. And I guess like one of the problems on Kaggle is that most of the solutions are so overfit to the training set that they never generalize to real world versions of the problem. But what you're doing actually is to kind of like remove away a lot of those opportunities for overfitting and also allowing the models to be used again when the next thing comes around. But just quickly on the aggregating stuff the reason I'm interested in that is on my PhD I did prediction with expert advice and there's a whole load of theoretical approaches to that where you can have an aggregating algorithm that produce, you know, that produces performance or a kind of like an error bound which is not much worse than the best path of switching experts. So if you took the optimal path of the best expert every single time step, you can have algorithms that have approvable bound not much worse than that. Yeah, we, so we've done a lot to try to experiment with trying to improve upon stake waiting. And it's always been really hard to do it in a robust way. It's, I mean, for one, stake waiting is, it's sort of nice in that it's easy for people to understand. People are, it's very clean in how it works. It sort of fits with the ethos and the, like, and the idea of the company of how it's distributed and decentralized and you express your confidence by your stake. But it does sort of seem like there should be a better way to aggregate models. But pretty much every time we try to find something better, it's, it might be a little bit better but it's like less robust. It tends to just be less robust. And it's, because you are essentially just sort of fitting to the past and to try to find way to the models or something, it tends to just like overfit and this sort of stake waiting thing, you can't really overfit. It's just sort of a property that just sort of evolves as the tournament goes on without ever considering like the past performance and all of these things. So yeah, it's, it's been kind of interesting to, so it's one of these things we sort of revisit every year at some point of like, let's try to build a better meta model but we usually just come back to stake waiting in the end. Yeah, well, in a way, I mean, we're prediction with expert advice, you have a learning rate and I guess you don't even have that problem because you're just using the stakes as the- Yeah, the, but yeah, the, I mean, our learning rate. So I mean, our payout system is the way we adjust the weights over time. And so we have done like some simulations to show that like if, how we reward people, how that affects their weights over time and how that affects meta model performance. So you wouldn't want to have a payout system that would make the meta model worse over time. And so yeah, like this, this true contribution idea that's gradient of the stakes, we did simulations to show it does actually improve the meta model over time to pay out in this way. It's nothing, I mean, people do things like take their stakes out, withdraw money. And so it's not a perfect system. People entering the tournament, people, some people entering with a lot of money, some people entered with not that much money. And so yeah, it takes time for these things, all the kind of shake out in real life. But the overall idea is that we are essentially adjusting the weights through our payouts towards this sort of more optimal meta model over time. Interesting. So I'm actually very, very interested to give it a go. And I guess like, first of all, you could sketch out what the process looks like. I mean, let's say I had a few hundred dollars and I wanted to build a model. And also it's got to be a good model. Let's face it. So if I just logged on there and I built a gradient booster tree model, would that work? It would actually. So I mean, it's tabular data and tabular data is very minimal to gradient boosted trees. We have a lot of example models that we have put up and they're doing quite well. So basically all you have to do is you can go to the website and just download a big zip file that includes all the data in parquet. And then you can just open it up in Python and fit a gradient boosted tree. When we have example scripts sort of showing this along with some more interesting types of pre-processing and other sort of ideas like feature neutralization. So I can talk about it in a second. But yeah, a lot of our sort of standard internal models use basically gradient boosted trees. And we are, I mean, we have basically example models running that and they all have positive correlation with and true and still true contribution. So they're actually working out of sample and performing quite well. That hasn't all been sort of eaten up by people using similar enough models. There's a lot of opportunity to make sort of unique models too. Cause one thing that's sort of unique about our tournament is we release actually several targets, we release 20 something targets. And they're all constructed in somewhat slightly different ways. And you can find that if you train on a different target, it might work almost as well as training on the target that you're scored on. And it might also ensemble really well with a model trained on different targets. And so you can actually create ensembles fairly easily just by training on different targets. Because it is kind of remarkable that a model trained on a different target can actually work better on the target you're interested in. But that kind of thing, yeah, definitely does happen. I mean, part of it is called all the correlations are so low, but some targets might just sort of have a better property in making your model pick up on the actual signal that you want to model rather than sort of variance that is like not that you don't want to model. Interesting. I think one of the issues is you might not know what models that people are using. But I wondered if you did have any intuition, I'd be fascinated to know, are they using very complex models? Are they using simple models? From talking to participants, there was a huge range. There are some people using like extremely simple trees. There are some people who are using incredibly elaborate neural networks with very sort of custom architectures that are sort of designed to the problem. There, yeah, there's a whole huge, right? I mean, there's people who have huge ensembles. There's people who are doing kind of like online learning where their model is actually using the features that were released that week and sort of using that in some sort of unsupervised learning and then so they take some while from when we released, they can't just like run their model through the new set of features. They have to incorporate this new set of features in this unsupervised way before they can, so yeah, there's an incredible variety of techniques people are using. Fascinating, and how big is this parquet for? How many rows, how many fields and are they all just real numbers between naught and one? So yeah, so there's, how many features are we up to now? We have a couple thousand features roughly and there's a few million, a couple million rows, I think. So one sort of additional piece of structure in the data is there's these things called eras and the eras are essentially just the weeks and because the competition has this structure of we're making predictions every week and so within each era, there's like say 5,000 rows which are basically like 5,000 stocks and so one sort of interesting thing is you are, you want your model to be good across eras, not necessarily across samples and so it creates a different structure in how you think about the problem because you want your model to be consistently good in every era and that can give you a different solution that if you just try to say maximize some metric over the whole training set which is kind of, yeah. But yeah, it is basically just a big parquet file. We do divide it into like training and like there's like a testing set but yeah, do you have any specific questions about how that is organized? Well, again, I'm really interested because on my PhD, I did a whole bunch of prediction models on financial data sets. I was predicting like the implied volatility of the Black Shells formula on some futures data but my big thing at the time was I was fascinated by regimes in financial data and you get these changing dependencies with time and what I did, I mean, you could actually visualize it if you build a load of expert models on different regimes and then you get them to predict on the other regime's data. You get this kind of self-similarity matrix and it looks like you get this kind of structure in there because there are certain regimes where this particular model actually predicts quite far out into the future and then it might suddenly go dead so you get these kind of squares and I had this big thesis that if I have expert models and use prediction with expert advice, then when we come into a new regime, I would quickly learn which experts are the good ones and I had this thesis that sometimes old information is very helpful in the future more so than using like a simple sliding window ridge regression or whatever and it turned out I was wrong. It's almost always better just to use a sliding window regression but yeah, it's fascinating. It's, yeah, it's interesting. Like the, you definitely want to train on a lot of data for these models. It definitely, like if you just use the prior one year of data, your models are gonna be pretty crap. It definitely helps to use like prior 10 years of data and so it is, you're using actually quite old data often in predicting into the future but generally, yeah, if you were only just using the last year or two of data, your models are gonna have to actually quite a hard time. Yeah, one other thing about the features I wanted to say is they are between zero and one, they're in five bins. There's zero, 0.25, 0.5, 0.75 and one. So the data has been like binned in this way and the targets are also binned in this, the same sort of bins but with a different distribution. The targets have like in their extreme bins, only like 5% of the values in the next two extreme bins. Like what is it, 20 in each of them and then 50% as a zero. Interesting. But all the features are basically just 20% in each of the bins. And so the binning is a pretty strong form of regularization. It sort of prevents you from like a tree from splitting sort of any arbitrary place you can only split at these things and so that kind of forces at least some of the space to be at different splits. And that regularization, it's kind of, you would think that having continuous features would be a lot really helpful but I mean, it's really not. It's kind of remarkable how lossy some of these transforms are that we do that actually seem to be helpful. Yeah, so it's so interesting. And I guess like one thing I didn't really appreciate at the time is you know, we were just talking about these complex dynamical systems like the brain or like financial markets and there's of course the market efficiency hypothesis and perhaps one of the reasons why old information might not be salient is because if the underlying system is actually taking a trajectory through this kind of complex space, then you might argue that almost regardless of where you traverse, you'll always be in a novel situation. And then there's this continuum of regularity versus chaos. So like for example, if you're predicting options futures when they get close to maturity, the volatility just goes crazy and they just become increasingly unpredictable. And I guess the art in this kind of data is knowing when you're in a regime which has some regularity and when you're not. It's yeah, it's tricky. Cause like ideally we want our model, we want our meta model to sort of work well in any regime and it does seem to work pretty well consistently. And but what you do find on like the leaderboard tournament participants, you'll see some people who stay at the top of the leaderboard for weeks and weeks and weeks and weeks, then suddenly precipitate fall like down the leaderboard as demonstrating some sort of regime effects. One really kind of interesting thing I did was I fit like a mixture of linear models to the data. So if you fit just like a mixture of two linear models where it's sort of selecting which eras to use for which of the two linear models, you basically, one linear model will get about 60% of the errors, one will get about 40% of the errors and their weights will be almost mirror images of each other. And this just comes out like that is the optimal fit for roughly for 40% of the errors that basically completely the opposite of the other eras. Which yeah, demonstrating some like, that's why markets are extremely hard cause like something that works well a lot of the time it suddenly would just work really oppositely horribly. And so you're often trying to just split this difference to find something that doesn't work super well at one time and then we'll like crater at another time. That's the meta model wants to kind of work really like pretty good all the time. And that's one of the things that ensembling all these models that maybe even the individual models probably have a lot more regime characteristics than this overall meta model. I wondered whether folks were using some really esoteric approaches. I mean, I'm interested in geometric deep learning and algorithmic reasoning and, you know, even think like esoteric options like cellular automata. Do you see anything like that getting traction or it may be even discrete program synthesis? I don't know. Cause yeah, like I only see what people are willing to post and share on forums. And there's quite a bit of sharing on our forums of information, but there's definitely some people at the top of leaderboards who are doing something that's working quite well for them for quite a long time that they haven't shared. And so it's, I'm not even sure what all the people are doing, but there are, I mean, people allude to using like tricks. I mean, that they've learned in different jobs. I mean, we have some people with like a variety of backgrounds. It's been really cool to like see this community grow and have people who are like astrophysicists, particle physicists, people who are doing like like computer vision and whatever sort of techniques they've learned in their different fields and try to use them on this problem. That was what sort of attracted me as like, I was doing like computational neuroscience and I saw this problem as like, oh, this is a complete free playground. You can do whatever you want. And so it was a fun opportunity to try out ideas that wouldn't really work well in computational neuroscience. Yeah, indeed. And physics, I mean, the road to reality by Roger Penrose, I think it was Michael Bronstein who said that if you could summarize the entire book in one word, it would be symmetry. And there's also another key idea from a lot of researchers, which is abstraction, you know, which is like some meta property of the relationship between data. So, you know, you probably have lots of folks coming in from different fields and they have some very, very interesting approaches to solving this problem. Yeah, for sure. Yeah, I mean, I have, I mean, there's people who use some like interesting like auto encoders to try to learn structure from data as a way to learn features. People using, it's interesting non-linear dimensionality reduction techniques to try to, yeah, to try to find various features. It's, and yeah, even some, some things people do do some sort of interesting feature selection or denoising types of things that they've learned in their fields. Yeah, it's always interesting to me to see like how different fields that use machine learning use it in different ways and what sort of tricks and tips might cross over. I was going to ask about that because you have loads and loads of features and there's this problem called the curse of dimensionality. Right, so, you know, when the number of dimensions increases the volume of the space increases exponentially, which means like this concept of nearness basically disappears and there's statistical models don't work anymore. So, you know, presumably people would do things like, I don't know, dimensionality reduction feature selection. I mean, neural networks are quite clever in the sense that they, via a variety of methods, overcome the curse of dimensionality by learning some data manifold or whatever. But, you know, it's with natural data, it's not with financial data, so it's not a given. It's, yeah, and this is actually one of the things that was really intriguing to me when I started in finance is, so in science, when you're doing regressions you're trying to find often sparse solutions. You're trying to find the sort of small number of variables to predict your targets, to try to find whatever sort of maybe causal relationships there are. In finance, we often try to do exactly the opposite, where we want our models to care about all the features a little bit. And so, we do, we'll do something like what we call a feature neutralization, where basically you take your prediction, take the linear model of your prediction from the features and subtract it off. And so, you're making your prediction not linearly correlated or linearly dependent on any of your features. We're doing some fraction of that. So, just trying to remove too strong of a linear relationship between a feature and your prediction. And you do other regularization techniques like in your tree learning, maybe one thing that works quite well is using like column sample by tree, instead of to very low value. So, each tree is only considering a small subset of features. And so, your ensemble is sort of, you use as a lot of the different features because it's sort of each tree only has access to 10% of the features across your whole ensemble. You are probably using a lot of your features a little bit. And that tends to work quite well. And the reason is, it's because features will work for a while and then they'll just turn around on you. And so, you don't want to be sort of super dependent on any one feature. And so, yeah, it does make the cursor dimensionality kind of worse in some ways because you don't wanna necessarily find just a small subset of variables that are the best because sometimes that will maybe give you a really good model for a while, but sometimes all of a sudden, those will just turn around on you. And then your model just like is almost anti-correlated where it should be. Yeah, it's so interesting. You know, like this problem with the changing dependencies. So, essentially you're modeling a non-stationary process which makes it much harder. And when I was speaking with Sarah Hooker the other day, she was talking about fairness and bias in models. And part of the problem there is, we optimize for headline metrics like accuracy. And when you decompose the training set into let's say different categories like men and women and people who live in London, the accuracy is very stratified. It might perform very badly for people that live in London, but very good for people that live in New York. You know, and then you start getting into the situation of saying, okay, well, I'll build an ensemble of models that are independently optimized for all the different things. But then you have this impedance mismatch between this global, you know, accuracy that you were optimizing for and are on the benchmarks. Yeah, no, it's a really interesting property of these things is, yeah, especially classification models where they will work well for some categories and not others. And it can be sort of tricky to find out why is like, are those features just more discriminative or like, are these classes somehow harder to tell apart just in some way? It's, yeah, it's, but I'm glad people are starting to like look at and try to dig into some of these like details rather than just looking at headline metrics. And I'm also sort of happy that the field is sort of moving to like this out of distribution learning is becoming a much more interesting topic. Because like, that is what really matters in making machine learning that is going to affect the real world is it needs to work out of distribution, out of your sort of training and test split distribution as well as possible. And like how you do that is, I mean, still very much an open question clearly. And how well you could potentially do that is even still an open question. But that is one of the, I mean, that is sort of what true intelligence is to something like humans are pretty good at adapting out of distribution. And what is it about us? What are like, how are we able to do that? And how do we make our sort of machine learning systems work better that way? How are we sort of able to? I mean, yeah, I think it probably has something to do is we're able to learn sort of causal structures that work well. And the distribution can be very different, but the sort of causal structures remain. And we're able to somehow infer that causal structures from data, from just our sense data and our world models. And yeah, basically the question is, how do we make our machine learning systems be able to do similar sorts of things? Yeah, this has been absolutely amazing. Do you have any final thoughts? Where can people find out more information about you, Michael? So, let's see. Well, so I want to point people first to just like Numeri, N-U-M-E-R.AI is the website. I am fairly active in the forums and the rocket chat we have, which is sort of just our own personal chat service for tournament participants to communicate with each other. And I occasionally only post some of the forums there. That's probably the best way to like get in contact to just message me on rocket chat. And yeah, so that's, yeah, there's probably that's way to get in contact. My also, my email is mdo at Numeri.ai. And I would, yeah, I really love if people come, check out the tournament, give feedback, and start participating. I've, yeah, I found that it was a lot of fun as a participant. And yeah, I joined the company partly so I was starting to make more money during the tournament than I was at my job in science. And so, yeah, it's a pretty fun hobby and side gig and potentially even quite lucrative. Amazing. Well, Dr. Michael Oliver, it's been an absolute honor. Thank you so much for joining us this evening. Thanks for so much for having me. It's been so much fun.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 2.0, "text": " Welcome back to Street Talk.", "tokens": [50364, 4027, 646, 281, 7638, 8780, 13, 50464], "temperature": 0.0, "avg_logprob": -0.19152059742048674, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.06265055388212204}, {"id": 1, "seek": 0, "start": 2.0, "end": 5.16, "text": " Today we have Dr. Michael Oliver.", "tokens": [50464, 2692, 321, 362, 2491, 13, 5116, 23440, 13, 50622], "temperature": 0.0, "avg_logprob": -0.19152059742048674, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.06265055388212204}, {"id": 2, "seek": 0, "start": 5.16, "end": 8.72, "text": " Michael is the chief scientist at Numeri.", "tokens": [50622, 5116, 307, 264, 9588, 12662, 412, 426, 15583, 72, 13, 50800], "temperature": 0.0, "avg_logprob": -0.19152059742048674, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.06265055388212204}, {"id": 3, "seek": 0, "start": 8.72, "end": 13.040000000000001, "text": " Numeri is a next generation hedge fund platform", "tokens": [50800, 426, 15583, 72, 307, 257, 958, 5125, 25304, 2374, 3663, 51016], "temperature": 0.0, "avg_logprob": -0.19152059742048674, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.06265055388212204}, {"id": 4, "seek": 0, "start": 13.040000000000001, "end": 17.44, "text": " powered by data scientists all over the world.", "tokens": [51016, 17786, 538, 1412, 7708, 439, 670, 264, 1002, 13, 51236], "temperature": 0.0, "avg_logprob": -0.19152059742048674, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.06265055388212204}, {"id": 5, "seek": 0, "start": 17.44, "end": 19.84, "text": " It's a little bit like Kaggle.", "tokens": [51236, 467, 311, 257, 707, 857, 411, 48751, 22631, 13, 51356], "temperature": 0.0, "avg_logprob": -0.19152059742048674, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.06265055388212204}, {"id": 6, "seek": 0, "start": 19.84, "end": 22.48, "text": " Anyone can log in and build their own data science models", "tokens": [51356, 14643, 393, 3565, 294, 293, 1322, 641, 1065, 1412, 3497, 5245, 51488], "temperature": 0.0, "avg_logprob": -0.19152059742048674, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.06265055388212204}, {"id": 7, "seek": 0, "start": 22.48, "end": 24.8, "text": " on this financial data,", "tokens": [51488, 322, 341, 4669, 1412, 11, 51604], "temperature": 0.0, "avg_logprob": -0.19152059742048674, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.06265055388212204}, {"id": 8, "seek": 0, "start": 24.8, "end": 26.62, "text": " but you can actually make money", "tokens": [51604, 457, 291, 393, 767, 652, 1460, 51695], "temperature": 0.0, "avg_logprob": -0.19152059742048674, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.06265055388212204}, {"id": 9, "seek": 0, "start": 26.62, "end": 28.0, "text": " by trading on this platform.", "tokens": [51695, 538, 9529, 322, 341, 3663, 13, 51764], "temperature": 0.0, "avg_logprob": -0.19152059742048674, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.06265055388212204}, {"id": 10, "seek": 2800, "start": 28.0, "end": 30.64, "text": " It's really, really interesting.", "tokens": [50364, 467, 311, 534, 11, 534, 1880, 13, 50496], "temperature": 0.0, "avg_logprob": -0.10940901947021485, "compression_ratio": 1.5665529010238908, "no_speech_prob": 0.001985349226742983}, {"id": 11, "seek": 2800, "start": 30.64, "end": 33.0, "text": " But anyway, Michael got his PhD", "tokens": [50496, 583, 4033, 11, 5116, 658, 702, 14476, 50614], "temperature": 0.0, "avg_logprob": -0.10940901947021485, "compression_ratio": 1.5665529010238908, "no_speech_prob": 0.001985349226742983}, {"id": 12, "seek": 2800, "start": 33.0, "end": 36.24, "text": " in computational neuroscience from UC Berkeley,", "tokens": [50614, 294, 28270, 42762, 490, 14079, 23684, 11, 50776], "temperature": 0.0, "avg_logprob": -0.10940901947021485, "compression_ratio": 1.5665529010238908, "no_speech_prob": 0.001985349226742983}, {"id": 13, "seek": 2800, "start": 36.24, "end": 38.24, "text": " and he was a postdoctoral researcher", "tokens": [50776, 293, 415, 390, 257, 2183, 2595, 20946, 21751, 50876], "temperature": 0.0, "avg_logprob": -0.10940901947021485, "compression_ratio": 1.5665529010238908, "no_speech_prob": 0.001985349226742983}, {"id": 14, "seek": 2800, "start": 38.24, "end": 40.72, "text": " at the Allen Institute for Brain Science", "tokens": [50876, 412, 264, 17160, 9446, 337, 29783, 8976, 51000], "temperature": 0.0, "avg_logprob": -0.10940901947021485, "compression_ratio": 1.5665529010238908, "no_speech_prob": 0.001985349226742983}, {"id": 15, "seek": 2800, "start": 40.72, "end": 43.68, "text": " before joining Numeri in 2020.", "tokens": [51000, 949, 5549, 426, 15583, 72, 294, 4808, 13, 51148], "temperature": 0.0, "avg_logprob": -0.10940901947021485, "compression_ratio": 1.5665529010238908, "no_speech_prob": 0.001985349226742983}, {"id": 16, "seek": 2800, "start": 43.68, "end": 45.620000000000005, "text": " He's also the host of the Numeri Quant Club,", "tokens": [51148, 634, 311, 611, 264, 3975, 295, 264, 426, 15583, 72, 26968, 11288, 11, 51245], "temperature": 0.0, "avg_logprob": -0.10940901947021485, "compression_ratio": 1.5665529010238908, "no_speech_prob": 0.001985349226742983}, {"id": 17, "seek": 2800, "start": 45.620000000000005, "end": 47.24, "text": " which is a YouTube series", "tokens": [51245, 597, 307, 257, 3088, 2638, 51326], "temperature": 0.0, "avg_logprob": -0.10940901947021485, "compression_ratio": 1.5665529010238908, "no_speech_prob": 0.001985349226742983}, {"id": 18, "seek": 2800, "start": 47.24, "end": 49.56, "text": " where he discusses Numeri's research", "tokens": [51326, 689, 415, 2248, 279, 426, 15583, 72, 311, 2132, 51442], "temperature": 0.0, "avg_logprob": -0.10940901947021485, "compression_ratio": 1.5665529010238908, "no_speech_prob": 0.001985349226742983}, {"id": 19, "seek": 2800, "start": 49.56, "end": 51.72, "text": " and also some of the data and challenges", "tokens": [51442, 293, 611, 512, 295, 264, 1412, 293, 4759, 51550], "temperature": 0.0, "avg_logprob": -0.10940901947021485, "compression_ratio": 1.5665529010238908, "no_speech_prob": 0.001985349226742983}, {"id": 20, "seek": 2800, "start": 51.72, "end": 54.22, "text": " and models that are being built on the platform.", "tokens": [51550, 293, 5245, 300, 366, 885, 3094, 322, 264, 3663, 13, 51675], "temperature": 0.0, "avg_logprob": -0.10940901947021485, "compression_ratio": 1.5665529010238908, "no_speech_prob": 0.001985349226742983}, {"id": 21, "seek": 2800, "start": 55.2, "end": 57.0, "text": " Now, the way I'm structuring this today", "tokens": [51724, 823, 11, 264, 636, 286, 478, 6594, 1345, 341, 965, 51814], "temperature": 0.0, "avg_logprob": -0.10940901947021485, "compression_ratio": 1.5665529010238908, "no_speech_prob": 0.001985349226742983}, {"id": 22, "seek": 5700, "start": 57.0, "end": 58.92, "text": " is at the end of the conversation,", "tokens": [50364, 307, 412, 264, 917, 295, 264, 3761, 11, 50460], "temperature": 0.0, "avg_logprob": -0.14292476971944174, "compression_ratio": 1.6951219512195121, "no_speech_prob": 0.00047985283890739083}, {"id": 23, "seek": 5700, "start": 58.92, "end": 62.8, "text": " we had quite a fruity discussion about Microsoft's new Bing,", "tokens": [50460, 321, 632, 1596, 257, 431, 21757, 5017, 466, 8116, 311, 777, 30755, 11, 50654], "temperature": 0.0, "avg_logprob": -0.14292476971944174, "compression_ratio": 1.6951219512195121, "no_speech_prob": 0.00047985283890739083}, {"id": 24, "seek": 5700, "start": 62.8, "end": 65.96000000000001, "text": " and I thought it was quite entertaining,", "tokens": [50654, 293, 286, 1194, 309, 390, 1596, 20402, 11, 50812], "temperature": 0.0, "avg_logprob": -0.14292476971944174, "compression_ratio": 1.6951219512195121, "no_speech_prob": 0.00047985283890739083}, {"id": 25, "seek": 5700, "start": 65.96000000000001, "end": 69.2, "text": " so I've decided to snip that in and play it at the beginning.", "tokens": [50812, 370, 286, 600, 3047, 281, 37482, 300, 294, 293, 862, 309, 412, 264, 2863, 13, 50974], "temperature": 0.0, "avg_logprob": -0.14292476971944174, "compression_ratio": 1.6951219512195121, "no_speech_prob": 0.00047985283890739083}, {"id": 26, "seek": 5700, "start": 69.2, "end": 71.04, "text": " But after that, I'll cut back into the beginning", "tokens": [50974, 583, 934, 300, 11, 286, 603, 1723, 646, 666, 264, 2863, 51066], "temperature": 0.0, "avg_logprob": -0.14292476971944174, "compression_ratio": 1.6951219512195121, "no_speech_prob": 0.00047985283890739083}, {"id": 27, "seek": 5700, "start": 71.04, "end": 71.88, "text": " of the conversation,", "tokens": [51066, 295, 264, 3761, 11, 51108], "temperature": 0.0, "avg_logprob": -0.14292476971944174, "compression_ratio": 1.6951219512195121, "no_speech_prob": 0.00047985283890739083}, {"id": 28, "seek": 5700, "start": 71.88, "end": 73.68, "text": " and I'll let you know when I've done that.", "tokens": [51108, 293, 286, 603, 718, 291, 458, 562, 286, 600, 1096, 300, 13, 51198], "temperature": 0.0, "avg_logprob": -0.14292476971944174, "compression_ratio": 1.6951219512195121, "no_speech_prob": 0.00047985283890739083}, {"id": 29, "seek": 5700, "start": 73.68, "end": 75.56, "text": " So without any further delay,", "tokens": [51198, 407, 1553, 604, 3052, 8577, 11, 51292], "temperature": 0.0, "avg_logprob": -0.14292476971944174, "compression_ratio": 1.6951219512195121, "no_speech_prob": 0.00047985283890739083}, {"id": 30, "seek": 5700, "start": 75.56, "end": 77.68, "text": " I give you Dr. Michael Oliver.", "tokens": [51292, 286, 976, 291, 2491, 13, 5116, 23440, 13, 51398], "temperature": 0.0, "avg_logprob": -0.14292476971944174, "compression_ratio": 1.6951219512195121, "no_speech_prob": 0.00047985283890739083}, {"id": 31, "seek": 5700, "start": 80.72, "end": 81.56, "text": " Awesome.", "tokens": [51550, 10391, 13, 51592], "temperature": 0.0, "avg_logprob": -0.14292476971944174, "compression_ratio": 1.6951219512195121, "no_speech_prob": 0.00047985283890739083}, {"id": 32, "seek": 5700, "start": 81.56, "end": 84.48, "text": " Well, I'm here with Michael Oliver.", "tokens": [51592, 1042, 11, 286, 478, 510, 365, 5116, 23440, 13, 51738], "temperature": 0.0, "avg_logprob": -0.14292476971944174, "compression_ratio": 1.6951219512195121, "no_speech_prob": 0.00047985283890739083}, {"id": 33, "seek": 8448, "start": 84.48, "end": 87.4, "text": " Michael, it's an absolute honor to have you on MLST.", "tokens": [50364, 5116, 11, 309, 311, 364, 8236, 5968, 281, 362, 291, 322, 376, 19198, 51, 13, 50510], "temperature": 0.0, "avg_logprob": -0.12905102617600384, "compression_ratio": 1.5412541254125414, "no_speech_prob": 0.0004303263558540493}, {"id": 34, "seek": 8448, "start": 87.4, "end": 88.96000000000001, "text": " Tell me about yourself.", "tokens": [50510, 5115, 385, 466, 1803, 13, 50588], "temperature": 0.0, "avg_logprob": -0.12905102617600384, "compression_ratio": 1.5412541254125414, "no_speech_prob": 0.0004303263558540493}, {"id": 35, "seek": 8448, "start": 88.96000000000001, "end": 90.28, "text": " Well, thank you for so much for having me.", "tokens": [50588, 1042, 11, 1309, 291, 337, 370, 709, 337, 1419, 385, 13, 50654], "temperature": 0.0, "avg_logprob": -0.12905102617600384, "compression_ratio": 1.5412541254125414, "no_speech_prob": 0.0004303263558540493}, {"id": 36, "seek": 8448, "start": 90.28, "end": 92.4, "text": " I'm really excited to talk to you today.", "tokens": [50654, 286, 478, 534, 2919, 281, 751, 281, 291, 965, 13, 50760], "temperature": 0.0, "avg_logprob": -0.12905102617600384, "compression_ratio": 1.5412541254125414, "no_speech_prob": 0.0004303263558540493}, {"id": 37, "seek": 8448, "start": 92.4, "end": 94.84, "text": " So I am the chief scientist at Numeri.", "tokens": [50760, 407, 286, 669, 264, 9588, 12662, 412, 426, 15583, 72, 13, 50882], "temperature": 0.0, "avg_logprob": -0.12905102617600384, "compression_ratio": 1.5412541254125414, "no_speech_prob": 0.0004303263558540493}, {"id": 38, "seek": 8448, "start": 94.84, "end": 97.74000000000001, "text": " I've been working there since about June, 2020.", "tokens": [50882, 286, 600, 668, 1364, 456, 1670, 466, 6928, 11, 4808, 13, 51027], "temperature": 0.0, "avg_logprob": -0.12905102617600384, "compression_ratio": 1.5412541254125414, "no_speech_prob": 0.0004303263558540493}, {"id": 39, "seek": 8448, "start": 98.64, "end": 101.60000000000001, "text": " In my previous life, I was a computational neuroscientist,", "tokens": [51072, 682, 452, 3894, 993, 11, 286, 390, 257, 28270, 28813, 5412, 468, 11, 51220], "temperature": 0.0, "avg_logprob": -0.12905102617600384, "compression_ratio": 1.5412541254125414, "no_speech_prob": 0.0004303263558540493}, {"id": 40, "seek": 8448, "start": 101.60000000000001, "end": 103.80000000000001, "text": " but I got involved with the Numeri competition", "tokens": [51220, 457, 286, 658, 3288, 365, 264, 426, 15583, 72, 6211, 51330], "temperature": 0.0, "avg_logprob": -0.12905102617600384, "compression_ratio": 1.5412541254125414, "no_speech_prob": 0.0004303263558540493}, {"id": 41, "seek": 8448, "start": 103.80000000000001, "end": 106.66, "text": " as a participant back in 2016.", "tokens": [51330, 382, 257, 24950, 646, 294, 6549, 13, 51473], "temperature": 0.0, "avg_logprob": -0.12905102617600384, "compression_ratio": 1.5412541254125414, "no_speech_prob": 0.0004303263558540493}, {"id": 42, "seek": 8448, "start": 107.60000000000001, "end": 110.52000000000001, "text": " And yeah, in 2020, they offered me a job", "tokens": [51520, 400, 1338, 11, 294, 4808, 11, 436, 8059, 385, 257, 1691, 51666], "temperature": 0.0, "avg_logprob": -0.12905102617600384, "compression_ratio": 1.5412541254125414, "no_speech_prob": 0.0004303263558540493}, {"id": 43, "seek": 8448, "start": 110.52000000000001, "end": 114.0, "text": " and I happily took it and changed careers", "tokens": [51666, 293, 286, 19909, 1890, 309, 293, 3105, 16409, 51840], "temperature": 0.0, "avg_logprob": -0.12905102617600384, "compression_ratio": 1.5412541254125414, "no_speech_prob": 0.0004303263558540493}, {"id": 44, "seek": 11400, "start": 114.0, "end": 115.64, "text": " and have been having a great time", "tokens": [50364, 293, 362, 668, 1419, 257, 869, 565, 50446], "temperature": 0.0, "avg_logprob": -0.15938503370372528, "compression_ratio": 1.7176470588235293, "no_speech_prob": 0.00023290861281566322}, {"id": 45, "seek": 11400, "start": 115.64, "end": 117.92, "text": " learning computational finance", "tokens": [50446, 2539, 28270, 10719, 50560], "temperature": 0.0, "avg_logprob": -0.15938503370372528, "compression_ratio": 1.7176470588235293, "no_speech_prob": 0.00023290861281566322}, {"id": 46, "seek": 11400, "start": 117.92, "end": 122.16, "text": " and yeah, just helping build the hedge fund.", "tokens": [50560, 293, 1338, 11, 445, 4315, 1322, 264, 25304, 2374, 13, 50772], "temperature": 0.0, "avg_logprob": -0.15938503370372528, "compression_ratio": 1.7176470588235293, "no_speech_prob": 0.00023290861281566322}, {"id": 47, "seek": 11400, "start": 123.22, "end": 124.06, "text": " Completely agree.", "tokens": [50825, 39978, 3986, 13, 50867], "temperature": 0.0, "avg_logprob": -0.15938503370372528, "compression_ratio": 1.7176470588235293, "no_speech_prob": 0.00023290861281566322}, {"id": 48, "seek": 11400, "start": 124.06, "end": 126.68, "text": " And this all comes down to the notion of understanding", "tokens": [50867, 400, 341, 439, 1487, 760, 281, 264, 10710, 295, 3701, 50998], "temperature": 0.0, "avg_logprob": -0.15938503370372528, "compression_ratio": 1.7176470588235293, "no_speech_prob": 0.00023290861281566322}, {"id": 49, "seek": 11400, "start": 126.68, "end": 129.74, "text": " and there's an anthropocentric conception of understanding,", "tokens": [50998, 293, 456, 311, 364, 22727, 905, 32939, 30698, 295, 3701, 11, 51151], "temperature": 0.0, "avg_logprob": -0.15938503370372528, "compression_ratio": 1.7176470588235293, "no_speech_prob": 0.00023290861281566322}, {"id": 50, "seek": 11400, "start": 129.74, "end": 132.98, "text": " which as you say, it's much more sample efficient.", "tokens": [51151, 597, 382, 291, 584, 11, 309, 311, 709, 544, 6889, 7148, 13, 51313], "temperature": 0.0, "avg_logprob": -0.15938503370372528, "compression_ratio": 1.7176470588235293, "no_speech_prob": 0.00023290861281566322}, {"id": 51, "seek": 11400, "start": 132.98, "end": 135.4, "text": " We build causal models", "tokens": [51313, 492, 1322, 38755, 5245, 51434], "temperature": 0.0, "avg_logprob": -0.15938503370372528, "compression_ratio": 1.7176470588235293, "no_speech_prob": 0.00023290861281566322}, {"id": 52, "seek": 11400, "start": 135.4, "end": 138.64, "text": " and we have an abstract understanding of the world.", "tokens": [51434, 293, 321, 362, 364, 12649, 3701, 295, 264, 1002, 13, 51596], "temperature": 0.0, "avg_logprob": -0.15938503370372528, "compression_ratio": 1.7176470588235293, "no_speech_prob": 0.00023290861281566322}, {"id": 53, "seek": 11400, "start": 138.64, "end": 140.56, "text": " And large language models, for example,", "tokens": [51596, 400, 2416, 2856, 5245, 11, 337, 1365, 11, 51692], "temperature": 0.0, "avg_logprob": -0.15938503370372528, "compression_ratio": 1.7176470588235293, "no_speech_prob": 0.00023290861281566322}, {"id": 54, "seek": 11400, "start": 140.56, "end": 141.9, "text": " they clearly don't have that.", "tokens": [51692, 436, 4448, 500, 380, 362, 300, 13, 51759], "temperature": 0.0, "avg_logprob": -0.15938503370372528, "compression_ratio": 1.7176470588235293, "no_speech_prob": 0.00023290861281566322}, {"id": 55, "seek": 14190, "start": 141.9, "end": 144.78, "text": " They learn surface statistics of billions of tokens,", "tokens": [50364, 814, 1466, 3753, 12523, 295, 17375, 295, 22667, 11, 50508], "temperature": 0.0, "avg_logprob": -0.09987503847629904, "compression_ratio": 1.7875816993464053, "no_speech_prob": 0.00130937690846622}, {"id": 56, "seek": 14190, "start": 144.78, "end": 147.18, "text": " but the problem is there's this parlor trick", "tokens": [50508, 457, 264, 1154, 307, 456, 311, 341, 971, 6746, 4282, 50628], "temperature": 0.0, "avg_logprob": -0.09987503847629904, "compression_ratio": 1.7875816993464053, "no_speech_prob": 0.00130937690846622}, {"id": 57, "seek": 14190, "start": 147.18, "end": 149.78, "text": " where it seems to understand.", "tokens": [50628, 689, 309, 2544, 281, 1223, 13, 50758], "temperature": 0.0, "avg_logprob": -0.09987503847629904, "compression_ratio": 1.7875816993464053, "no_speech_prob": 0.00130937690846622}, {"id": 58, "seek": 14190, "start": 149.78, "end": 152.54000000000002, "text": " And we also have the problem of leakage", "tokens": [50758, 400, 321, 611, 362, 264, 1154, 295, 47799, 50896], "temperature": 0.0, "avg_logprob": -0.09987503847629904, "compression_ratio": 1.7875816993464053, "no_speech_prob": 0.00130937690846622}, {"id": 59, "seek": 14190, "start": 152.54000000000002, "end": 154.94, "text": " because the incredible thing is that", "tokens": [50896, 570, 264, 4651, 551, 307, 300, 51016], "temperature": 0.0, "avg_logprob": -0.09987503847629904, "compression_ratio": 1.7875816993464053, "no_speech_prob": 0.00130937690846622}, {"id": 60, "seek": 14190, "start": 154.94, "end": 157.34, "text": " if you look at the big bench task, for example,", "tokens": [51016, 498, 291, 574, 412, 264, 955, 10638, 5633, 11, 337, 1365, 11, 51136], "temperature": 0.0, "avg_logprob": -0.09987503847629904, "compression_ratio": 1.7875816993464053, "no_speech_prob": 0.00130937690846622}, {"id": 61, "seek": 14190, "start": 157.34, "end": 158.94, "text": " all of these diverse tasks,", "tokens": [51136, 439, 295, 613, 9521, 9608, 11, 51216], "temperature": 0.0, "avg_logprob": -0.09987503847629904, "compression_ratio": 1.7875816993464053, "no_speech_prob": 0.00130937690846622}, {"id": 62, "seek": 14190, "start": 158.94, "end": 161.66, "text": " large language models appear to do very, very well.", "tokens": [51216, 2416, 2856, 5245, 4204, 281, 360, 588, 11, 588, 731, 13, 51352], "temperature": 0.0, "avg_logprob": -0.09987503847629904, "compression_ratio": 1.7875816993464053, "no_speech_prob": 0.00130937690846622}, {"id": 63, "seek": 14190, "start": 161.66, "end": 163.82, "text": " But in many cases, it's because they're cheating", "tokens": [51352, 583, 294, 867, 3331, 11, 309, 311, 570, 436, 434, 18309, 51460], "temperature": 0.0, "avg_logprob": -0.09987503847629904, "compression_ratio": 1.7875816993464053, "no_speech_prob": 0.00130937690846622}, {"id": 64, "seek": 14190, "start": 163.82, "end": 165.98000000000002, "text": " and it's very difficult to understand why they're cheating", "tokens": [51460, 293, 309, 311, 588, 2252, 281, 1223, 983, 436, 434, 18309, 51568], "temperature": 0.0, "avg_logprob": -0.09987503847629904, "compression_ratio": 1.7875816993464053, "no_speech_prob": 0.00130937690846622}, {"id": 65, "seek": 14190, "start": 165.98000000000002, "end": 168.38, "text": " because you've got information leaking all over the place", "tokens": [51568, 570, 291, 600, 658, 1589, 32856, 439, 670, 264, 1081, 51688], "temperature": 0.0, "avg_logprob": -0.09987503847629904, "compression_ratio": 1.7875816993464053, "no_speech_prob": 0.00130937690846622}, {"id": 66, "seek": 14190, "start": 168.38, "end": 170.98000000000002, "text": " and they're brittle, but in a very deceptive way", "tokens": [51688, 293, 436, 434, 49325, 11, 457, 294, 257, 588, 368, 1336, 488, 636, 51818], "temperature": 0.0, "avg_logprob": -0.09987503847629904, "compression_ratio": 1.7875816993464053, "no_speech_prob": 0.00130937690846622}, {"id": 67, "seek": 17098, "start": 171.06, "end": 172.61999999999998, "text": " and they hallucinate and so on.", "tokens": [50368, 293, 436, 35212, 13923, 293, 370, 322, 13, 50446], "temperature": 0.0, "avg_logprob": -0.1556343929373103, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.005044278223067522}, {"id": 68, "seek": 17098, "start": 172.61999999999998, "end": 174.45999999999998, "text": " I don't know whether you saw the news article today", "tokens": [50446, 286, 500, 380, 458, 1968, 291, 1866, 264, 2583, 7222, 965, 50538], "temperature": 0.0, "avg_logprob": -0.1556343929373103, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.005044278223067522}, {"id": 69, "seek": 17098, "start": 174.45999999999998, "end": 177.7, "text": " about Bing's launch of their new search engine.", "tokens": [50538, 466, 30755, 311, 4025, 295, 641, 777, 3164, 2848, 13, 50700], "temperature": 0.0, "avg_logprob": -0.1556343929373103, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.005044278223067522}, {"id": 70, "seek": 17098, "start": 177.7, "end": 179.66, "text": " They launched it to much fanfare", "tokens": [50700, 814, 8730, 309, 281, 709, 3429, 11079, 50798], "temperature": 0.0, "avg_logprob": -0.1556343929373103, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.005044278223067522}, {"id": 71, "seek": 17098, "start": 179.66, "end": 181.82, "text": " and then people started looking at the actual results", "tokens": [50798, 293, 550, 561, 1409, 1237, 412, 264, 3539, 3542, 50906], "temperature": 0.0, "avg_logprob": -0.1556343929373103, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.005044278223067522}, {"id": 72, "seek": 17098, "start": 181.82, "end": 184.06, "text": " that were shown and it turned out to be just a load", "tokens": [50906, 300, 645, 4898, 293, 309, 3574, 484, 281, 312, 445, 257, 3677, 51018], "temperature": 0.0, "avg_logprob": -0.1556343929373103, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.005044278223067522}, {"id": 73, "seek": 17098, "start": 184.06, "end": 184.89999999999998, "text": " of bullshit.", "tokens": [51018, 295, 22676, 13, 51060], "temperature": 0.0, "avg_logprob": -0.1556343929373103, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.005044278223067522}, {"id": 74, "seek": 17098, "start": 184.89999999999998, "end": 186.66, "text": " It made up a whole load of numbers", "tokens": [51060, 467, 1027, 493, 257, 1379, 3677, 295, 3547, 51148], "temperature": 0.0, "avg_logprob": -0.1556343929373103, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.005044278223067522}, {"id": 75, "seek": 17098, "start": 186.66, "end": 188.22, "text": " on the financial reports.", "tokens": [51148, 322, 264, 4669, 7122, 13, 51226], "temperature": 0.0, "avg_logprob": -0.1556343929373103, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.005044278223067522}, {"id": 76, "seek": 17098, "start": 188.22, "end": 190.82, "text": " It was just hallucinating completely.", "tokens": [51226, 467, 390, 445, 35212, 8205, 2584, 13, 51356], "temperature": 0.0, "avg_logprob": -0.1556343929373103, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.005044278223067522}, {"id": 77, "seek": 17098, "start": 190.82, "end": 193.22, "text": " And that's pretty scary, isn't it?", "tokens": [51356, 400, 300, 311, 1238, 6958, 11, 1943, 380, 309, 30, 51476], "temperature": 0.0, "avg_logprob": -0.1556343929373103, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.005044278223067522}, {"id": 78, "seek": 17098, "start": 193.22, "end": 194.57999999999998, "text": " Yeah, it is.", "tokens": [51476, 865, 11, 309, 307, 13, 51544], "temperature": 0.0, "avg_logprob": -0.1556343929373103, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.005044278223067522}, {"id": 79, "seek": 17098, "start": 195.94, "end": 197.22, "text": " I actually just started playing around", "tokens": [51612, 286, 767, 445, 1409, 2433, 926, 51676], "temperature": 0.0, "avg_logprob": -0.1556343929373103, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.005044278223067522}, {"id": 80, "seek": 17098, "start": 197.22, "end": 199.06, "text": " with the new Bing like last night.", "tokens": [51676, 365, 264, 777, 30755, 411, 1036, 1818, 13, 51768], "temperature": 0.0, "avg_logprob": -0.1556343929373103, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.005044278223067522}, {"id": 81, "seek": 19906, "start": 199.06, "end": 204.06, "text": " I had access to it and it was actually working.", "tokens": [50364, 286, 632, 2105, 281, 309, 293, 309, 390, 767, 1364, 13, 50614], "temperature": 0.0, "avg_logprob": -0.26702076555734655, "compression_ratio": 1.6073298429319371, "no_speech_prob": 0.001986904302611947}, {"id": 82, "seek": 19906, "start": 205.78, "end": 208.62, "text": " And it does some things quite well", "tokens": [50700, 400, 309, 775, 512, 721, 1596, 731, 50842], "temperature": 0.0, "avg_logprob": -0.26702076555734655, "compression_ratio": 1.6073298429319371, "no_speech_prob": 0.001986904302611947}, {"id": 83, "seek": 19906, "start": 208.62, "end": 212.34, "text": " because it'll do a search and then search somehow.", "tokens": [50842, 570, 309, 603, 360, 257, 3164, 293, 550, 3164, 6063, 13, 51028], "temperature": 0.0, "avg_logprob": -0.26702076555734655, "compression_ratio": 1.6073298429319371, "no_speech_prob": 0.001986904302611947}, {"id": 84, "seek": 19906, "start": 212.34, "end": 213.78, "text": " It's like actually looking at the results", "tokens": [51028, 467, 311, 411, 767, 1237, 412, 264, 3542, 51100], "temperature": 0.0, "avg_logprob": -0.26702076555734655, "compression_ratio": 1.6073298429319371, "no_speech_prob": 0.001986904302611947}, {"id": 85, "seek": 19906, "start": 213.78, "end": 214.98, "text": " and summarizing them.", "tokens": [51100, 293, 14611, 3319, 552, 13, 51160], "temperature": 0.0, "avg_logprob": -0.26702076555734655, "compression_ratio": 1.6073298429319371, "no_speech_prob": 0.001986904302611947}, {"id": 86, "seek": 19906, "start": 216.14000000000001, "end": 219.62, "text": " But yeah, you never know when it's gonna do something", "tokens": [51218, 583, 1338, 11, 291, 1128, 458, 562, 309, 311, 799, 360, 746, 51392], "temperature": 0.0, "avg_logprob": -0.26702076555734655, "compression_ratio": 1.6073298429319371, "no_speech_prob": 0.001986904302611947}, {"id": 87, "seek": 19906, "start": 219.62, "end": 224.62, "text": " sensible and when it's gonna do any sort of no warning.", "tokens": [51392, 25380, 293, 562, 309, 311, 799, 360, 604, 1333, 295, 572, 9164, 13, 51642], "temperature": 0.0, "avg_logprob": -0.26702076555734655, "compression_ratio": 1.6073298429319371, "no_speech_prob": 0.001986904302611947}, {"id": 88, "seek": 22462, "start": 224.82, "end": 227.9, "text": " Like I asked it about myself and I had,", "tokens": [50374, 1743, 286, 2351, 309, 466, 2059, 293, 286, 632, 11, 50528], "temperature": 0.0, "avg_logprob": -0.2644453128846754, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.04529454931616783}, {"id": 89, "seek": 22462, "start": 230.82, "end": 232.58, "text": " I asked who's the chief scientist in Uri", "tokens": [50674, 286, 2351, 567, 311, 264, 9588, 12662, 294, 624, 470, 50762], "temperature": 0.0, "avg_logprob": -0.2644453128846754, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.04529454931616783}, {"id": 90, "seek": 22462, "start": 232.58, "end": 233.98000000000002, "text": " and it got it right.", "tokens": [50762, 293, 309, 658, 309, 558, 13, 50832], "temperature": 0.0, "avg_logprob": -0.2644453128846754, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.04529454931616783}, {"id": 91, "seek": 22462, "start": 233.98000000000002, "end": 238.3, "text": " But it also kind of took a joke from my Twitter profile", "tokens": [50832, 583, 309, 611, 733, 295, 1890, 257, 7647, 490, 452, 5794, 7964, 51048], "temperature": 0.0, "avg_logprob": -0.2644453128846754, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.04529454931616783}, {"id": 92, "seek": 22462, "start": 238.3, "end": 241.02, "text": " and because on my Twitter profile,", "tokens": [51048, 293, 570, 322, 452, 5794, 7964, 11, 51184], "temperature": 0.0, "avg_logprob": -0.2644453128846754, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.04529454931616783}, {"id": 93, "seek": 22462, "start": 241.02, "end": 243.94, "text": " I have maximizer, entropy, minimizer, regret.", "tokens": [51184, 286, 362, 5138, 6545, 11, 30867, 11, 4464, 6545, 11, 10879, 13, 51330], "temperature": 0.0, "avg_logprob": -0.2644453128846754, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.04529454931616783}, {"id": 94, "seek": 22462, "start": 243.94, "end": 245.82, "text": " And it basically said like, that's what he does.", "tokens": [51330, 400, 309, 1936, 848, 411, 11, 300, 311, 437, 415, 775, 13, 51424], "temperature": 0.0, "avg_logprob": -0.2644453128846754, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.04529454931616783}, {"id": 95, "seek": 22462, "start": 245.82, "end": 248.1, "text": " Is he maximizes entropy and minimizes regret.", "tokens": [51424, 1119, 415, 5138, 5660, 30867, 293, 4464, 5660, 10879, 13, 51538], "temperature": 0.0, "avg_logprob": -0.2644453128846754, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.04529454931616783}, {"id": 96, "seek": 22462, "start": 248.1, "end": 250.86, "text": " And I thought that was pretty hilarious.", "tokens": [51538, 400, 286, 1194, 300, 390, 1238, 19796, 13, 51676], "temperature": 0.0, "avg_logprob": -0.2644453128846754, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.04529454931616783}, {"id": 97, "seek": 22462, "start": 250.86, "end": 253.9, "text": " But yeah, the sort of like you never know", "tokens": [51676, 583, 1338, 11, 264, 1333, 295, 411, 291, 1128, 458, 51828], "temperature": 0.0, "avg_logprob": -0.2644453128846754, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.04529454931616783}, {"id": 98, "seek": 25390, "start": 253.9, "end": 255.86, "text": " when it's gonna do something sensible or not", "tokens": [50364, 562, 309, 311, 799, 360, 746, 25380, 420, 406, 50462], "temperature": 0.0, "avg_logprob": -0.21412443392204517, "compression_ratio": 1.949579831932773, "no_speech_prob": 0.001867113634943962}, {"id": 99, "seek": 25390, "start": 255.86, "end": 257.9, "text": " is the sort of scary part.", "tokens": [50462, 307, 264, 1333, 295, 6958, 644, 13, 50564], "temperature": 0.0, "avg_logprob": -0.21412443392204517, "compression_ratio": 1.949579831932773, "no_speech_prob": 0.001867113634943962}, {"id": 100, "seek": 25390, "start": 257.9, "end": 260.14, "text": " And I also find it hilarious that a lot of the ways", "tokens": [50564, 400, 286, 611, 915, 309, 19796, 300, 257, 688, 295, 264, 2098, 50676], "temperature": 0.0, "avg_logprob": -0.21412443392204517, "compression_ratio": 1.949579831932773, "no_speech_prob": 0.001867113634943962}, {"id": 101, "seek": 25390, "start": 260.14, "end": 261.94, "text": " we try to make it do something sensible", "tokens": [50676, 321, 853, 281, 652, 309, 360, 746, 25380, 50766], "temperature": 0.0, "avg_logprob": -0.21412443392204517, "compression_ratio": 1.949579831932773, "no_speech_prob": 0.001867113634943962}, {"id": 102, "seek": 25390, "start": 261.94, "end": 263.54, "text": " is just like asking nicely.", "tokens": [50766, 307, 445, 411, 3365, 9594, 13, 50846], "temperature": 0.0, "avg_logprob": -0.21412443392204517, "compression_ratio": 1.949579831932773, "no_speech_prob": 0.001867113634943962}, {"id": 103, "seek": 25390, "start": 264.5, "end": 265.86, "text": " We just sort of like prompt it with like,", "tokens": [50894, 492, 445, 1333, 295, 411, 12391, 309, 365, 411, 11, 50962], "temperature": 0.0, "avg_logprob": -0.21412443392204517, "compression_ratio": 1.949579831932773, "no_speech_prob": 0.001867113634943962}, {"id": 104, "seek": 25390, "start": 265.86, "end": 267.26, "text": " don't make up sources.", "tokens": [50962, 500, 380, 652, 493, 7139, 13, 51032], "temperature": 0.0, "avg_logprob": -0.21412443392204517, "compression_ratio": 1.949579831932773, "no_speech_prob": 0.001867113634943962}, {"id": 105, "seek": 25390, "start": 267.26, "end": 270.86, "text": " And that's how we try to make it not make up sources", "tokens": [51032, 400, 300, 311, 577, 321, 853, 281, 652, 309, 406, 652, 493, 7139, 51212], "temperature": 0.0, "avg_logprob": -0.21412443392204517, "compression_ratio": 1.949579831932773, "no_speech_prob": 0.001867113634943962}, {"id": 106, "seek": 25390, "start": 270.86, "end": 272.3, "text": " just like sort of by asking it nicely.", "tokens": [51212, 445, 411, 1333, 295, 538, 3365, 309, 9594, 13, 51284], "temperature": 0.0, "avg_logprob": -0.21412443392204517, "compression_ratio": 1.949579831932773, "no_speech_prob": 0.001867113634943962}, {"id": 107, "seek": 25390, "start": 272.3, "end": 274.66, "text": " And the fact that it kind of works", "tokens": [51284, 400, 264, 1186, 300, 309, 733, 295, 1985, 51402], "temperature": 0.0, "avg_logprob": -0.21412443392204517, "compression_ratio": 1.949579831932773, "no_speech_prob": 0.001867113634943962}, {"id": 108, "seek": 25390, "start": 274.66, "end": 277.58, "text": " like that we think that it's clearly not,", "tokens": [51402, 411, 300, 321, 519, 300, 309, 311, 4448, 406, 11, 51548], "temperature": 0.0, "avg_logprob": -0.21412443392204517, "compression_ratio": 1.949579831932773, "no_speech_prob": 0.001867113634943962}, {"id": 109, "seek": 25390, "start": 277.58, "end": 280.38, "text": " something that's really going to work.", "tokens": [51548, 746, 300, 311, 534, 516, 281, 589, 13, 51688], "temperature": 0.0, "avg_logprob": -0.21412443392204517, "compression_ratio": 1.949579831932773, "no_speech_prob": 0.001867113634943962}, {"id": 110, "seek": 28038, "start": 280.42, "end": 284.74, "text": " Because it doesn't sort of know what it is", "tokens": [50366, 1436, 309, 1177, 380, 1333, 295, 458, 437, 309, 307, 50582], "temperature": 0.0, "avg_logprob": -0.1626786797996459, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.00019714217341970652}, {"id": 111, "seek": 28038, "start": 284.74, "end": 286.46, "text": " to make up sources.", "tokens": [50582, 281, 652, 493, 7139, 13, 50668], "temperature": 0.0, "avg_logprob": -0.1626786797996459, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.00019714217341970652}, {"id": 112, "seek": 28038, "start": 286.46, "end": 289.3, "text": " It's just trying to like predict the next word.", "tokens": [50668, 467, 311, 445, 1382, 281, 411, 6069, 264, 958, 1349, 13, 50810], "temperature": 0.0, "avg_logprob": -0.1626786797996459, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.00019714217341970652}, {"id": 113, "seek": 28038, "start": 289.3, "end": 294.3, "text": " And yeah, so it's kind of, our ability to like understand", "tokens": [50810, 400, 1338, 11, 370, 309, 311, 733, 295, 11, 527, 3485, 281, 411, 1223, 51060], "temperature": 0.0, "avg_logprob": -0.1626786797996459, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.00019714217341970652}, {"id": 114, "seek": 28038, "start": 294.62, "end": 296.5, "text": " and then constrain the behavior of these things", "tokens": [51076, 293, 550, 1817, 7146, 264, 5223, 295, 613, 721, 51170], "temperature": 0.0, "avg_logprob": -0.1626786797996459, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.00019714217341970652}, {"id": 115, "seek": 28038, "start": 296.5, "end": 299.26, "text": " I think is like pretty early.", "tokens": [51170, 286, 519, 307, 411, 1238, 2440, 13, 51308], "temperature": 0.0, "avg_logprob": -0.1626786797996459, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.00019714217341970652}, {"id": 116, "seek": 28038, "start": 299.26, "end": 300.1, "text": " I know.", "tokens": [51308, 286, 458, 13, 51350], "temperature": 0.0, "avg_logprob": -0.1626786797996459, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.00019714217341970652}, {"id": 117, "seek": 28038, "start": 300.1, "end": 301.9, "text": " And for some reason it feels worse with Bing", "tokens": [51350, 400, 337, 512, 1778, 309, 3417, 5324, 365, 30755, 51440], "temperature": 0.0, "avg_logprob": -0.1626786797996459, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.00019714217341970652}, {"id": 118, "seek": 28038, "start": 301.9, "end": 305.42, "text": " because they say they do this retrieval augmented generation", "tokens": [51440, 570, 436, 584, 436, 360, 341, 19817, 3337, 36155, 5125, 51616], "temperature": 0.0, "avg_logprob": -0.1626786797996459, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.00019714217341970652}, {"id": 119, "seek": 28038, "start": 305.42, "end": 307.7, "text": " and you expect it to be grounded in facts.", "tokens": [51616, 293, 291, 2066, 309, 281, 312, 23535, 294, 9130, 13, 51730], "temperature": 0.0, "avg_logprob": -0.1626786797996459, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.00019714217341970652}, {"id": 120, "seek": 28038, "start": 307.7, "end": 309.7, "text": " And of course they're not epistemic facts.", "tokens": [51730, 400, 295, 1164, 436, 434, 406, 2388, 468, 3438, 9130, 13, 51830], "temperature": 0.0, "avg_logprob": -0.1626786797996459, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.00019714217341970652}, {"id": 121, "seek": 30970, "start": 309.7, "end": 311.78, "text": " They're just information from their search results", "tokens": [50364, 814, 434, 445, 1589, 490, 641, 3164, 3542, 50468], "temperature": 0.0, "avg_logprob": -0.14160773920458417, "compression_ratio": 1.737265415549598, "no_speech_prob": 0.00034981119097210467}, {"id": 122, "seek": 30970, "start": 311.78, "end": 314.42, "text": " which weren't very good to start with, let's be honest.", "tokens": [50468, 597, 4999, 380, 588, 665, 281, 722, 365, 11, 718, 311, 312, 3245, 13, 50600], "temperature": 0.0, "avg_logprob": -0.14160773920458417, "compression_ratio": 1.737265415549598, "no_speech_prob": 0.00034981119097210467}, {"id": 123, "seek": 30970, "start": 314.42, "end": 316.26, "text": " But now people are more likely to trust it.", "tokens": [50600, 583, 586, 561, 366, 544, 3700, 281, 3361, 309, 13, 50692], "temperature": 0.0, "avg_logprob": -0.14160773920458417, "compression_ratio": 1.737265415549598, "no_speech_prob": 0.00034981119097210467}, {"id": 124, "seek": 30970, "start": 316.26, "end": 318.86, "text": " Even Microsoft themselves for their product demo", "tokens": [50692, 2754, 8116, 2969, 337, 641, 1674, 10723, 50822], "temperature": 0.0, "avg_logprob": -0.14160773920458417, "compression_ratio": 1.737265415549598, "no_speech_prob": 0.00034981119097210467}, {"id": 125, "seek": 30970, "start": 318.86, "end": 321.21999999999997, "text": " they didn't bother, I assume they didn't bother", "tokens": [50822, 436, 994, 380, 8677, 11, 286, 6552, 436, 994, 380, 8677, 50940], "temperature": 0.0, "avg_logprob": -0.14160773920458417, "compression_ratio": 1.737265415549598, "no_speech_prob": 0.00034981119097210467}, {"id": 126, "seek": 30970, "start": 321.21999999999997, "end": 322.18, "text": " to fact check this stuff.", "tokens": [50940, 281, 1186, 1520, 341, 1507, 13, 50988], "temperature": 0.0, "avg_logprob": -0.14160773920458417, "compression_ratio": 1.737265415549598, "no_speech_prob": 0.00034981119097210467}, {"id": 127, "seek": 30970, "start": 322.18, "end": 324.06, "text": " So if they're not going to fact check it,", "tokens": [50988, 407, 498, 436, 434, 406, 516, 281, 1186, 1520, 309, 11, 51082], "temperature": 0.0, "avg_logprob": -0.14160773920458417, "compression_ratio": 1.737265415549598, "no_speech_prob": 0.00034981119097210467}, {"id": 128, "seek": 30970, "start": 324.06, "end": 325.94, "text": " why do they expect the people that use this system", "tokens": [51082, 983, 360, 436, 2066, 264, 561, 300, 764, 341, 1185, 51176], "temperature": 0.0, "avg_logprob": -0.14160773920458417, "compression_ratio": 1.737265415549598, "no_speech_prob": 0.00034981119097210467}, {"id": 129, "seek": 30970, "start": 325.94, "end": 326.78, "text": " to fact check it?", "tokens": [51176, 281, 1186, 1520, 309, 30, 51218], "temperature": 0.0, "avg_logprob": -0.14160773920458417, "compression_ratio": 1.737265415549598, "no_speech_prob": 0.00034981119097210467}, {"id": 130, "seek": 30970, "start": 326.78, "end": 327.62, "text": " Because at the end of the day", "tokens": [51218, 1436, 412, 264, 917, 295, 264, 786, 51260], "temperature": 0.0, "avg_logprob": -0.14160773920458417, "compression_ratio": 1.737265415549598, "no_speech_prob": 0.00034981119097210467}, {"id": 131, "seek": 30970, "start": 327.62, "end": 329.34, "text": " if you actually go and check all of the sources", "tokens": [51260, 498, 291, 767, 352, 293, 1520, 439, 295, 264, 7139, 51346], "temperature": 0.0, "avg_logprob": -0.14160773920458417, "compression_ratio": 1.737265415549598, "no_speech_prob": 0.00034981119097210467}, {"id": 132, "seek": 30970, "start": 329.34, "end": 331.58, "text": " if I read through that Lululemon financial report", "tokens": [51346, 498, 286, 1401, 807, 300, 441, 425, 2271, 3317, 4669, 2275, 51458], "temperature": 0.0, "avg_logprob": -0.14160773920458417, "compression_ratio": 1.737265415549598, "no_speech_prob": 0.00034981119097210467}, {"id": 133, "seek": 30970, "start": 331.58, "end": 334.3, "text": " and I find out what their gross profit margin was", "tokens": [51458, 293, 286, 915, 484, 437, 641, 11367, 7475, 10270, 390, 51594], "temperature": 0.0, "avg_logprob": -0.14160773920458417, "compression_ratio": 1.737265415549598, "no_speech_prob": 0.00034981119097210467}, {"id": 134, "seek": 30970, "start": 334.3, "end": 337.21999999999997, "text": " and so there's no point using Bing in the first place.", "tokens": [51594, 293, 370, 456, 311, 572, 935, 1228, 30755, 294, 264, 700, 1081, 13, 51740], "temperature": 0.0, "avg_logprob": -0.14160773920458417, "compression_ratio": 1.737265415549598, "no_speech_prob": 0.00034981119097210467}, {"id": 135, "seek": 30970, "start": 337.21999999999997, "end": 338.06, "text": " I might as well have just gone", "tokens": [51740, 286, 1062, 382, 731, 362, 445, 2780, 51782], "temperature": 0.0, "avg_logprob": -0.14160773920458417, "compression_ratio": 1.737265415549598, "no_speech_prob": 0.00034981119097210467}, {"id": 136, "seek": 33806, "start": 338.14, "end": 340.46, "text": " and found the information myself.", "tokens": [50368, 293, 1352, 264, 1589, 2059, 13, 50484], "temperature": 0.0, "avg_logprob": -0.20475032112815164, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.009550640359520912}, {"id": 137, "seek": 33806, "start": 340.46, "end": 341.38, "text": " Yeah, exactly.", "tokens": [50484, 865, 11, 2293, 13, 50530], "temperature": 0.0, "avg_logprob": -0.20475032112815164, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.009550640359520912}, {"id": 138, "seek": 33806, "start": 341.38, "end": 343.54, "text": " And it's also very unclear", "tokens": [50530, 400, 309, 311, 611, 588, 25636, 50638], "temperature": 0.0, "avg_logprob": -0.20475032112815164, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.009550640359520912}, {"id": 139, "seek": 33806, "start": 343.54, "end": 346.1, "text": " like how are these things supposed to be fixed?", "tokens": [50638, 411, 577, 366, 613, 721, 3442, 281, 312, 6806, 30, 50766], "temperature": 0.0, "avg_logprob": -0.20475032112815164, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.009550640359520912}, {"id": 140, "seek": 33806, "start": 347.42, "end": 350.7, "text": " Like how are you supposed to like feedback, give feedback", "tokens": [50832, 1743, 577, 366, 291, 3442, 281, 411, 5824, 11, 976, 5824, 50996], "temperature": 0.0, "avg_logprob": -0.20475032112815164, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.009550640359520912}, {"id": 141, "seek": 33806, "start": 350.7, "end": 352.94, "text": " to say it's like messing these things up?", "tokens": [50996, 281, 584, 309, 311, 411, 23258, 613, 721, 493, 30, 51108], "temperature": 0.0, "avg_logprob": -0.20475032112815164, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.009550640359520912}, {"id": 142, "seek": 33806, "start": 352.94, "end": 355.5, "text": " Like there is not even like really good feedback mechanisms.", "tokens": [51108, 1743, 456, 307, 406, 754, 411, 534, 665, 5824, 15902, 13, 51236], "temperature": 0.0, "avg_logprob": -0.20475032112815164, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.009550640359520912}, {"id": 143, "seek": 33806, "start": 355.5, "end": 358.54, "text": " I mean, you would maybe hope that that at scale", "tokens": [51236, 286, 914, 11, 291, 576, 1310, 1454, 300, 300, 412, 4373, 51388], "temperature": 0.0, "avg_logprob": -0.20475032112815164, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.009550640359520912}, {"id": 144, "seek": 33806, "start": 358.54, "end": 360.7, "text": " like what I mean, like what opening has to do", "tokens": [51388, 411, 437, 286, 914, 11, 411, 437, 5193, 575, 281, 360, 51496], "temperature": 0.0, "avg_logprob": -0.20475032112815164, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.009550640359520912}, {"id": 145, "seek": 33806, "start": 360.7, "end": 361.98, "text": " is like people give feedback.", "tokens": [51496, 307, 411, 561, 976, 5824, 13, 51560], "temperature": 0.0, "avg_logprob": -0.20475032112815164, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.009550640359520912}, {"id": 146, "seek": 33806, "start": 361.98, "end": 364.14, "text": " But I mean, it's a very coarse way of giving feedback", "tokens": [51560, 583, 286, 914, 11, 309, 311, 257, 588, 39312, 636, 295, 2902, 5824, 51668], "temperature": 0.0, "avg_logprob": -0.20475032112815164, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.009550640359520912}, {"id": 147, "seek": 33806, "start": 364.14, "end": 365.7, "text": " like thumbs up or thumbs down.", "tokens": [51668, 411, 8838, 493, 420, 8838, 760, 13, 51746], "temperature": 0.0, "avg_logprob": -0.20475032112815164, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.009550640359520912}, {"id": 148, "seek": 36570, "start": 366.7, "end": 369.14, "text": " And that seems like sort of inadequate", "tokens": [50414, 400, 300, 2544, 411, 1333, 295, 42107, 50536], "temperature": 0.0, "avg_logprob": -0.18900628046158258, "compression_ratio": 1.6965811965811965, "no_speech_prob": 0.001867348444648087}, {"id": 149, "seek": 36570, "start": 369.14, "end": 371.94, "text": " to be like, hey, you made up this number", "tokens": [50536, 281, 312, 411, 11, 4177, 11, 291, 1027, 493, 341, 1230, 50676], "temperature": 0.0, "avg_logprob": -0.18900628046158258, "compression_ratio": 1.6965811965811965, "no_speech_prob": 0.001867348444648087}, {"id": 150, "seek": 36570, "start": 371.94, "end": 373.94, "text": " and then even try to figure out why I made up the number", "tokens": [50676, 293, 550, 754, 853, 281, 2573, 484, 983, 286, 1027, 493, 264, 1230, 50776], "temperature": 0.0, "avg_logprob": -0.18900628046158258, "compression_ratio": 1.6965811965811965, "no_speech_prob": 0.001867348444648087}, {"id": 151, "seek": 36570, "start": 373.94, "end": 376.82, "text": " rather than just like took it from the actual report.", "tokens": [50776, 2831, 813, 445, 411, 1890, 309, 490, 264, 3539, 2275, 13, 50920], "temperature": 0.0, "avg_logprob": -0.18900628046158258, "compression_ratio": 1.6965811965811965, "no_speech_prob": 0.001867348444648087}, {"id": 152, "seek": 36570, "start": 378.06, "end": 380.53999999999996, "text": " It's yeah, it's a little scary.", "tokens": [50982, 467, 311, 1338, 11, 309, 311, 257, 707, 6958, 13, 51106], "temperature": 0.0, "avg_logprob": -0.18900628046158258, "compression_ratio": 1.6965811965811965, "no_speech_prob": 0.001867348444648087}, {"id": 153, "seek": 36570, "start": 380.53999999999996, "end": 383.86, "text": " I do wonder how all this is gonna shake out.", "tokens": [51106, 286, 360, 2441, 577, 439, 341, 307, 799, 10283, 484, 13, 51272], "temperature": 0.0, "avg_logprob": -0.18900628046158258, "compression_ratio": 1.6965811965811965, "no_speech_prob": 0.001867348444648087}, {"id": 154, "seek": 36570, "start": 384.9, "end": 386.98, "text": " It kind of seems like it might,", "tokens": [51324, 467, 733, 295, 2544, 411, 309, 1062, 11, 51428], "temperature": 0.0, "avg_logprob": -0.18900628046158258, "compression_ratio": 1.6965811965811965, "no_speech_prob": 0.001867348444648087}, {"id": 155, "seek": 36570, "start": 386.98, "end": 390.09999999999997, "text": " it seems like the probability of it being", "tokens": [51428, 309, 2544, 411, 264, 8482, 295, 309, 885, 51584], "temperature": 0.0, "avg_logprob": -0.18900628046158258, "compression_ratio": 1.6965811965811965, "no_speech_prob": 0.001867348444648087}, {"id": 156, "seek": 36570, "start": 390.09999999999997, "end": 393.09999999999997, "text": " the new paradigm versus it being the complete like flop", "tokens": [51584, 264, 777, 24709, 5717, 309, 885, 264, 3566, 411, 25343, 51734], "temperature": 0.0, "avg_logprob": -0.18900628046158258, "compression_ratio": 1.6965811965811965, "no_speech_prob": 0.001867348444648087}, {"id": 157, "seek": 39310, "start": 393.26000000000005, "end": 397.26000000000005, "text": " It's even roughly, roughly equal at this point.", "tokens": [50372, 467, 311, 754, 9810, 11, 9810, 2681, 412, 341, 935, 13, 50572], "temperature": 0.0, "avg_logprob": -0.15172076053756603, "compression_ratio": 1.7424749163879598, "no_speech_prob": 0.00037931546103209257}, {"id": 158, "seek": 39310, "start": 397.26000000000005, "end": 398.34000000000003, "text": " I know, I agree with you", "tokens": [50572, 286, 458, 11, 286, 3986, 365, 291, 50626], "temperature": 0.0, "avg_logprob": -0.15172076053756603, "compression_ratio": 1.7424749163879598, "no_speech_prob": 0.00037931546103209257}, {"id": 159, "seek": 39310, "start": 398.34000000000003, "end": 401.02000000000004, "text": " that the preference training is extremely brittle.", "tokens": [50626, 300, 264, 17502, 3097, 307, 4664, 49325, 13, 50760], "temperature": 0.0, "avg_logprob": -0.15172076053756603, "compression_ratio": 1.7424749163879598, "no_speech_prob": 0.00037931546103209257}, {"id": 160, "seek": 39310, "start": 401.02000000000004, "end": 402.62, "text": " It's scarily brittle actually.", "tokens": [50760, 467, 311, 795, 3289, 49325, 767, 13, 50840], "temperature": 0.0, "avg_logprob": -0.15172076053756603, "compression_ratio": 1.7424749163879598, "no_speech_prob": 0.00037931546103209257}, {"id": 161, "seek": 39310, "start": 402.62, "end": 404.62, "text": " It's basically a thumbs up or thumbs down", "tokens": [50840, 467, 311, 1936, 257, 8838, 493, 420, 8838, 760, 50940], "temperature": 0.0, "avg_logprob": -0.15172076053756603, "compression_ratio": 1.7424749163879598, "no_speech_prob": 0.00037931546103209257}, {"id": 162, "seek": 39310, "start": 404.62, "end": 407.90000000000003, "text": " and you know, Yannick is building this open assistant thing", "tokens": [50940, 293, 291, 458, 11, 398, 969, 618, 307, 2390, 341, 1269, 10994, 551, 51104], "temperature": 0.0, "avg_logprob": -0.15172076053756603, "compression_ratio": 1.7424749163879598, "no_speech_prob": 0.00037931546103209257}, {"id": 163, "seek": 39310, "start": 407.90000000000003, "end": 409.94, "text": " which has more metadata on the preference tuning.", "tokens": [51104, 597, 575, 544, 26603, 322, 264, 17502, 15164, 13, 51206], "temperature": 0.0, "avg_logprob": -0.15172076053756603, "compression_ratio": 1.7424749163879598, "no_speech_prob": 0.00037931546103209257}, {"id": 164, "seek": 39310, "start": 409.94, "end": 411.98, "text": " But at the end of the day, you're taking a task", "tokens": [51206, 583, 412, 264, 917, 295, 264, 786, 11, 291, 434, 1940, 257, 5633, 51308], "temperature": 0.0, "avg_logprob": -0.15172076053756603, "compression_ratio": 1.7424749163879598, "no_speech_prob": 0.00037931546103209257}, {"id": 165, "seek": 39310, "start": 411.98, "end": 413.70000000000005, "text": " which is very, very complicated", "tokens": [51308, 597, 307, 588, 11, 588, 6179, 51394], "temperature": 0.0, "avg_logprob": -0.15172076053756603, "compression_ratio": 1.7424749163879598, "no_speech_prob": 0.00037931546103209257}, {"id": 166, "seek": 39310, "start": 413.70000000000005, "end": 416.66, "text": " and you're reducing it to a single piece of metadata.", "tokens": [51394, 293, 291, 434, 12245, 309, 281, 257, 2167, 2522, 295, 26603, 13, 51542], "temperature": 0.0, "avg_logprob": -0.15172076053756603, "compression_ratio": 1.7424749163879598, "no_speech_prob": 0.00037931546103209257}, {"id": 167, "seek": 39310, "start": 416.66, "end": 418.54, "text": " So that's not gonna work very well.", "tokens": [51542, 407, 300, 311, 406, 799, 589, 588, 731, 13, 51636], "temperature": 0.0, "avg_logprob": -0.15172076053756603, "compression_ratio": 1.7424749163879598, "no_speech_prob": 0.00037931546103209257}, {"id": 168, "seek": 39310, "start": 418.54, "end": 421.58000000000004, "text": " And also these, it feels different with Bing", "tokens": [51636, 400, 611, 613, 11, 309, 3417, 819, 365, 30755, 51788], "temperature": 0.0, "avg_logprob": -0.15172076053756603, "compression_ratio": 1.7424749163879598, "no_speech_prob": 0.00037931546103209257}, {"id": 169, "seek": 42158, "start": 421.58, "end": 425.14, "text": " because they were a platform and now they're a publisher.", "tokens": [50364, 570, 436, 645, 257, 3663, 293, 586, 436, 434, 257, 25088, 13, 50542], "temperature": 0.0, "avg_logprob": -0.13807260375661948, "compression_ratio": 1.71875, "no_speech_prob": 0.0006161555065773427}, {"id": 170, "seek": 42158, "start": 425.14, "end": 427.02, "text": " So they are generating information.", "tokens": [50542, 407, 436, 366, 17746, 1589, 13, 50636], "temperature": 0.0, "avg_logprob": -0.13807260375661948, "compression_ratio": 1.71875, "no_speech_prob": 0.0006161555065773427}, {"id": 171, "seek": 42158, "start": 427.02, "end": 429.65999999999997, "text": " They're kind of plagiarizing a lot of that information", "tokens": [50636, 814, 434, 733, 295, 33756, 9448, 3319, 257, 688, 295, 300, 1589, 50768], "temperature": 0.0, "avg_logprob": -0.13807260375661948, "compression_ratio": 1.71875, "no_speech_prob": 0.0006161555065773427}, {"id": 172, "seek": 42158, "start": 429.65999999999997, "end": 431.85999999999996, "text": " and there are so many situations", "tokens": [50768, 293, 456, 366, 370, 867, 6851, 50878], "temperature": 0.0, "avg_logprob": -0.13807260375661948, "compression_ratio": 1.71875, "no_speech_prob": 0.0006161555065773427}, {"id": 173, "seek": 42158, "start": 431.85999999999996, "end": 434.18, "text": " where they might find themselves in legal trouble", "tokens": [50878, 689, 436, 1062, 915, 2969, 294, 5089, 5253, 50994], "temperature": 0.0, "avg_logprob": -0.13807260375661948, "compression_ratio": 1.71875, "no_speech_prob": 0.0006161555065773427}, {"id": 174, "seek": 42158, "start": 434.18, "end": 436.65999999999997, "text": " because they're basically making up information.", "tokens": [50994, 570, 436, 434, 1936, 1455, 493, 1589, 13, 51118], "temperature": 0.0, "avg_logprob": -0.13807260375661948, "compression_ratio": 1.71875, "no_speech_prob": 0.0006161555065773427}, {"id": 175, "seek": 42158, "start": 437.94, "end": 442.94, "text": " Yeah, I hope, I mean, I wonder how it's all gonna shake out.", "tokens": [51182, 865, 11, 286, 1454, 11, 286, 914, 11, 286, 2441, 577, 309, 311, 439, 799, 10283, 484, 13, 51432], "temperature": 0.0, "avg_logprob": -0.13807260375661948, "compression_ratio": 1.71875, "no_speech_prob": 0.0006161555065773427}, {"id": 176, "seek": 42158, "start": 445.46, "end": 447.97999999999996, "text": " I mean, I assume they probably have lawyers", "tokens": [51558, 286, 914, 11, 286, 6552, 436, 1391, 362, 16219, 51684], "temperature": 0.0, "avg_logprob": -0.13807260375661948, "compression_ratio": 1.71875, "no_speech_prob": 0.0006161555065773427}, {"id": 177, "seek": 44798, "start": 447.98, "end": 451.90000000000003, "text": " who've written in terms of service of these paintings to that.", "tokens": [50364, 567, 600, 3720, 294, 2115, 295, 2643, 295, 613, 14880, 281, 300, 13, 50560], "temperature": 0.0, "avg_logprob": -0.25495572950019213, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.03898713365197182}, {"id": 178, "seek": 44798, "start": 451.90000000000003, "end": 455.26, "text": " Like it's up to you to not use them in ways that will,", "tokens": [50560, 1743, 309, 311, 493, 281, 291, 281, 406, 764, 552, 294, 2098, 300, 486, 11, 50728], "temperature": 0.0, "avg_logprob": -0.25495572950019213, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.03898713365197182}, {"id": 179, "seek": 44798, "start": 455.26, "end": 456.1, "text": " like I know you can't,", "tokens": [50728, 411, 286, 458, 291, 393, 380, 11, 50770], "temperature": 0.0, "avg_logprob": -0.25495572950019213, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.03898713365197182}, {"id": 180, "seek": 44798, "start": 456.1, "end": 457.58000000000004, "text": " they're not to be held liable for these things,", "tokens": [50770, 436, 434, 406, 281, 312, 5167, 375, 712, 337, 613, 721, 11, 50844], "temperature": 0.0, "avg_logprob": -0.25495572950019213, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.03898713365197182}, {"id": 181, "seek": 44798, "start": 457.58000000000004, "end": 462.58000000000004, "text": " but yeah, it's, I do worry that this is gonna just like,", "tokens": [50844, 457, 1338, 11, 309, 311, 11, 286, 360, 3292, 300, 341, 307, 799, 445, 411, 11, 51094], "temperature": 0.0, "avg_logprob": -0.25495572950019213, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.03898713365197182}, {"id": 182, "seek": 44798, "start": 462.78000000000003, "end": 465.66, "text": " I mean, and then with Google trying to basically catch up", "tokens": [51104, 286, 914, 11, 293, 550, 365, 3329, 1382, 281, 1936, 3745, 493, 51248], "temperature": 0.0, "avg_logprob": -0.25495572950019213, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.03898713365197182}, {"id": 183, "seek": 44798, "start": 465.66, "end": 468.78000000000003, "text": " and release something similar and maybe rushing that out", "tokens": [51248, 293, 4374, 746, 2531, 293, 1310, 25876, 300, 484, 51404], "temperature": 0.0, "avg_logprob": -0.25495572950019213, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.03898713365197182}, {"id": 184, "seek": 44798, "start": 468.78000000000003, "end": 472.22, "text": " and then we might have two sort of hallucinating search engines.", "tokens": [51404, 293, 550, 321, 1062, 362, 732, 1333, 295, 35212, 8205, 3164, 12982, 13, 51576], "temperature": 0.0, "avg_logprob": -0.25495572950019213, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.03898713365197182}, {"id": 185, "seek": 44798, "start": 474.5, "end": 476.14000000000004, "text": " I know, yeah.", "tokens": [51690, 286, 458, 11, 1338, 13, 51772], "temperature": 0.0, "avg_logprob": -0.25495572950019213, "compression_ratio": 1.6628787878787878, "no_speech_prob": 0.03898713365197182}, {"id": 186, "seek": 47614, "start": 476.14, "end": 477.41999999999996, "text": " What a time to be alive.", "tokens": [50364, 708, 257, 565, 281, 312, 5465, 13, 50428], "temperature": 0.0, "avg_logprob": -0.11192288935579212, "compression_ratio": 1.7357142857142858, "no_speech_prob": 0.004259992856532335}, {"id": 187, "seek": 47614, "start": 479.7, "end": 482.26, "text": " Yeah, and I've vacillated back and forth.", "tokens": [50542, 865, 11, 293, 286, 600, 2842, 373, 770, 646, 293, 5220, 13, 50670], "temperature": 0.0, "avg_logprob": -0.11192288935579212, "compression_ratio": 1.7357142857142858, "no_speech_prob": 0.004259992856532335}, {"id": 188, "seek": 47614, "start": 482.26, "end": 484.38, "text": " So I was very skeptical about language models.", "tokens": [50670, 407, 286, 390, 588, 28601, 466, 2856, 5245, 13, 50776], "temperature": 0.0, "avg_logprob": -0.11192288935579212, "compression_ratio": 1.7357142857142858, "no_speech_prob": 0.004259992856532335}, {"id": 189, "seek": 47614, "start": 484.38, "end": 487.74, "text": " I released a big video when GBT3 first came out", "tokens": [50776, 286, 4736, 257, 955, 960, 562, 26809, 51, 18, 700, 1361, 484, 50944], "temperature": 0.0, "avg_logprob": -0.11192288935579212, "compression_ratio": 1.7357142857142858, "no_speech_prob": 0.004259992856532335}, {"id": 190, "seek": 47614, "start": 487.74, "end": 490.18, "text": " and I thought it was garbage, frankly.", "tokens": [50944, 293, 286, 1194, 309, 390, 14150, 11, 11939, 13, 51066], "temperature": 0.0, "avg_logprob": -0.11192288935579212, "compression_ratio": 1.7357142857142858, "no_speech_prob": 0.004259992856532335}, {"id": 191, "seek": 47614, "start": 490.18, "end": 491.9, "text": " And then DaVinci 2 came out", "tokens": [51066, 400, 550, 3933, 53, 21961, 568, 1361, 484, 51152], "temperature": 0.0, "avg_logprob": -0.11192288935579212, "compression_ratio": 1.7357142857142858, "no_speech_prob": 0.004259992856532335}, {"id": 192, "seek": 47614, "start": 491.9, "end": 493.65999999999997, "text": " and then I started using it all the time", "tokens": [51152, 293, 550, 286, 1409, 1228, 309, 439, 264, 565, 51240], "temperature": 0.0, "avg_logprob": -0.11192288935579212, "compression_ratio": 1.7357142857142858, "no_speech_prob": 0.004259992856532335}, {"id": 193, "seek": 47614, "start": 493.65999999999997, "end": 495.58, "text": " and I thought, wow, this is actually really good.", "tokens": [51240, 293, 286, 1194, 11, 6076, 11, 341, 307, 767, 534, 665, 13, 51336], "temperature": 0.0, "avg_logprob": -0.11192288935579212, "compression_ratio": 1.7357142857142858, "no_speech_prob": 0.004259992856532335}, {"id": 194, "seek": 47614, "start": 495.58, "end": 498.38, "text": " I'm using it all the time for lots of things.", "tokens": [51336, 286, 478, 1228, 309, 439, 264, 565, 337, 3195, 295, 721, 13, 51476], "temperature": 0.0, "avg_logprob": -0.11192288935579212, "compression_ratio": 1.7357142857142858, "no_speech_prob": 0.004259992856532335}, {"id": 195, "seek": 47614, "start": 498.38, "end": 500.5, "text": " And then I'm now in a bit of a twilight.", "tokens": [51476, 400, 550, 286, 478, 586, 294, 257, 857, 295, 257, 683, 27797, 13, 51582], "temperature": 0.0, "avg_logprob": -0.11192288935579212, "compression_ratio": 1.7357142857142858, "no_speech_prob": 0.004259992856532335}, {"id": 196, "seek": 47614, "start": 500.5, "end": 502.46, "text": " So I've been using lots of co-pilot.", "tokens": [51582, 407, 286, 600, 668, 1228, 3195, 295, 598, 12, 79, 31516, 13, 51680], "temperature": 0.0, "avg_logprob": -0.11192288935579212, "compression_ratio": 1.7357142857142858, "no_speech_prob": 0.004259992856532335}, {"id": 197, "seek": 47614, "start": 502.46, "end": 504.7, "text": " I've been generating lots of code with it.", "tokens": [51680, 286, 600, 668, 17746, 3195, 295, 3089, 365, 309, 13, 51792], "temperature": 0.0, "avg_logprob": -0.11192288935579212, "compression_ratio": 1.7357142857142858, "no_speech_prob": 0.004259992856532335}, {"id": 198, "seek": 50470, "start": 504.78, "end": 506.78, "text": " And I know from a lot of experience now", "tokens": [50368, 400, 286, 458, 490, 257, 688, 295, 1752, 586, 50468], "temperature": 0.0, "avg_logprob": -0.0980398128559063, "compression_ratio": 1.664576802507837, "no_speech_prob": 0.0004303635214455426}, {"id": 199, "seek": 50470, "start": 506.78, "end": 509.58, "text": " that it often produces completely broken code", "tokens": [50468, 300, 309, 2049, 14725, 2584, 5463, 3089, 50608], "temperature": 0.0, "avg_logprob": -0.0980398128559063, "compression_ratio": 1.664576802507837, "no_speech_prob": 0.0004303635214455426}, {"id": 200, "seek": 50470, "start": 509.58, "end": 513.74, "text": " and much to the chagrin of the people who review my code,", "tokens": [50608, 293, 709, 281, 264, 417, 559, 12629, 295, 264, 561, 567, 3131, 452, 3089, 11, 50816], "temperature": 0.0, "avg_logprob": -0.0980398128559063, "compression_ratio": 1.664576802507837, "no_speech_prob": 0.0004303635214455426}, {"id": 201, "seek": 50470, "start": 513.74, "end": 516.46, "text": " you basically have to hold your hand up and admit many times,", "tokens": [50816, 291, 1936, 362, 281, 1797, 428, 1011, 493, 293, 9796, 867, 1413, 11, 50952], "temperature": 0.0, "avg_logprob": -0.0980398128559063, "compression_ratio": 1.664576802507837, "no_speech_prob": 0.0004303635214455426}, {"id": 202, "seek": 50470, "start": 516.46, "end": 518.06, "text": " oh, I've just checked in some garbage code", "tokens": [50952, 1954, 11, 286, 600, 445, 10033, 294, 512, 14150, 3089, 51032], "temperature": 0.0, "avg_logprob": -0.0980398128559063, "compression_ratio": 1.664576802507837, "no_speech_prob": 0.0004303635214455426}, {"id": 203, "seek": 50470, "start": 518.06, "end": 519.62, "text": " which I didn't understand.", "tokens": [51032, 597, 286, 994, 380, 1223, 13, 51110], "temperature": 0.0, "avg_logprob": -0.0980398128559063, "compression_ratio": 1.664576802507837, "no_speech_prob": 0.0004303635214455426}, {"id": 204, "seek": 50470, "start": 519.62, "end": 521.5, "text": " And when you get called out on that a few times,", "tokens": [51110, 400, 562, 291, 483, 1219, 484, 322, 300, 257, 1326, 1413, 11, 51204], "temperature": 0.0, "avg_logprob": -0.0980398128559063, "compression_ratio": 1.664576802507837, "no_speech_prob": 0.0004303635214455426}, {"id": 205, "seek": 50470, "start": 521.5, "end": 523.02, "text": " you think, whoa, wait a minute, actually,", "tokens": [51204, 291, 519, 11, 13310, 11, 1699, 257, 3456, 11, 767, 11, 51280], "temperature": 0.0, "avg_logprob": -0.0980398128559063, "compression_ratio": 1.664576802507837, "no_speech_prob": 0.0004303635214455426}, {"id": 206, "seek": 50470, "start": 523.02, "end": 524.22, "text": " I need to be a bit more careful here.", "tokens": [51280, 286, 643, 281, 312, 257, 857, 544, 5026, 510, 13, 51340], "temperature": 0.0, "avg_logprob": -0.0980398128559063, "compression_ratio": 1.664576802507837, "no_speech_prob": 0.0004303635214455426}, {"id": 207, "seek": 50470, "start": 524.22, "end": 526.58, "text": " This thing actually isn't saving me any time.", "tokens": [51340, 639, 551, 767, 1943, 380, 6816, 385, 604, 565, 13, 51458], "temperature": 0.0, "avg_logprob": -0.0980398128559063, "compression_ratio": 1.664576802507837, "no_speech_prob": 0.0004303635214455426}, {"id": 208, "seek": 50470, "start": 526.58, "end": 529.3, "text": " And yeah, the big thing as well, yeah.", "tokens": [51458, 400, 1338, 11, 264, 955, 551, 382, 731, 11, 1338, 13, 51594], "temperature": 0.0, "avg_logprob": -0.0980398128559063, "compression_ratio": 1.664576802507837, "no_speech_prob": 0.0004303635214455426}, {"id": 209, "seek": 50470, "start": 529.3, "end": 531.8199999999999, "text": " Yeah, I've been using co-pilot a bit too.", "tokens": [51594, 865, 11, 286, 600, 668, 1228, 598, 12, 79, 31516, 257, 857, 886, 13, 51720], "temperature": 0.0, "avg_logprob": -0.0980398128559063, "compression_ratio": 1.664576802507837, "no_speech_prob": 0.0004303635214455426}, {"id": 210, "seek": 53182, "start": 531.82, "end": 537.1800000000001, "text": " And I found it can be quite good for pretty mundane things.", "tokens": [50364, 400, 286, 1352, 309, 393, 312, 1596, 665, 337, 1238, 43497, 721, 13, 50632], "temperature": 0.0, "avg_logprob": -0.19195296400684422, "compression_ratio": 1.680161943319838, "no_speech_prob": 0.004467647057026625}, {"id": 211, "seek": 53182, "start": 537.1800000000001, "end": 540.62, "text": " If you just have some sort of lined code", "tokens": [50632, 759, 291, 445, 362, 512, 1333, 295, 17189, 3089, 50804], "temperature": 0.0, "avg_logprob": -0.19195296400684422, "compression_ratio": 1.680161943319838, "no_speech_prob": 0.004467647057026625}, {"id": 212, "seek": 53182, "start": 540.62, "end": 543.1400000000001, "text": " for some config file or something,", "tokens": [50804, 337, 512, 6662, 3991, 420, 746, 11, 50930], "temperature": 0.0, "avg_logprob": -0.19195296400684422, "compression_ratio": 1.680161943319838, "no_speech_prob": 0.004467647057026625}, {"id": 213, "seek": 53182, "start": 543.1400000000001, "end": 544.74, "text": " it can be really good at auto-completing", "tokens": [50930, 309, 393, 312, 534, 665, 412, 8399, 12, 43856, 9880, 51010], "temperature": 0.0, "avg_logprob": -0.19195296400684422, "compression_ratio": 1.680161943319838, "no_speech_prob": 0.004467647057026625}, {"id": 214, "seek": 53182, "start": 544.74, "end": 546.2600000000001, "text": " and it's changing variable names.", "tokens": [51010, 293, 309, 311, 4473, 7006, 5288, 13, 51086], "temperature": 0.0, "avg_logprob": -0.19195296400684422, "compression_ratio": 1.680161943319838, "no_speech_prob": 0.004467647057026625}, {"id": 215, "seek": 53182, "start": 546.2600000000001, "end": 548.58, "text": " And it can be excellent at that and save lots of time.", "tokens": [51086, 400, 309, 393, 312, 7103, 412, 300, 293, 3155, 3195, 295, 565, 13, 51202], "temperature": 0.0, "avg_logprob": -0.19195296400684422, "compression_ratio": 1.680161943319838, "no_speech_prob": 0.004467647057026625}, {"id": 216, "seek": 53182, "start": 548.58, "end": 551.46, "text": " But if you try to make it do too much,", "tokens": [51202, 583, 498, 291, 853, 281, 652, 309, 360, 886, 709, 11, 51346], "temperature": 0.0, "avg_logprob": -0.19195296400684422, "compression_ratio": 1.680161943319838, "no_speech_prob": 0.004467647057026625}, {"id": 217, "seek": 53182, "start": 551.46, "end": 553.62, "text": " sometimes they get it brilliantly right.", "tokens": [51346, 2171, 436, 483, 309, 8695, 42580, 558, 13, 51454], "temperature": 0.0, "avg_logprob": -0.19195296400684422, "compression_ratio": 1.680161943319838, "no_speech_prob": 0.004467647057026625}, {"id": 218, "seek": 53182, "start": 553.62, "end": 557.34, "text": " Sometimes it's subtly wrong.", "tokens": [51454, 4803, 309, 311, 7257, 356, 2085, 13, 51640], "temperature": 0.0, "avg_logprob": -0.19195296400684422, "compression_ratio": 1.680161943319838, "no_speech_prob": 0.004467647057026625}, {"id": 219, "seek": 53182, "start": 557.34, "end": 561.3800000000001, "text": " And yeah, again, it's like how much time", "tokens": [51640, 400, 1338, 11, 797, 11, 309, 311, 411, 577, 709, 565, 51842], "temperature": 0.0, "avg_logprob": -0.19195296400684422, "compression_ratio": 1.680161943319838, "no_speech_prob": 0.004467647057026625}, {"id": 220, "seek": 56138, "start": 561.38, "end": 562.86, "text": " is it saving you if it's...", "tokens": [50364, 307, 309, 6816, 291, 498, 309, 311, 485, 50438], "temperature": 0.0, "avg_logprob": -0.1942728930757246, "compression_ratio": 1.5880149812734083, "no_speech_prob": 0.0017001894302666187}, {"id": 221, "seek": 56138, "start": 562.86, "end": 567.1, "text": " So yeah, overall, I like it.", "tokens": [50438, 407, 1338, 11, 4787, 11, 286, 411, 309, 13, 50650], "temperature": 0.0, "avg_logprob": -0.1942728930757246, "compression_ratio": 1.5880149812734083, "no_speech_prob": 0.0017001894302666187}, {"id": 222, "seek": 56138, "start": 567.1, "end": 568.34, "text": " It saves me a fair amount of typing,", "tokens": [50650, 467, 19155, 385, 257, 3143, 2372, 295, 18444, 11, 50712], "temperature": 0.0, "avg_logprob": -0.1942728930757246, "compression_ratio": 1.5880149812734083, "no_speech_prob": 0.0017001894302666187}, {"id": 223, "seek": 56138, "start": 568.34, "end": 576.62, "text": " but yeah, I don't trust it's big suggestions too.", "tokens": [50712, 457, 1338, 11, 286, 500, 380, 3361, 309, 311, 955, 13396, 886, 13, 51126], "temperature": 0.0, "avg_logprob": -0.1942728930757246, "compression_ratio": 1.5880149812734083, "no_speech_prob": 0.0017001894302666187}, {"id": 224, "seek": 56138, "start": 576.62, "end": 577.46, "text": " Well, I know.", "tokens": [51126, 1042, 11, 286, 458, 13, 51168], "temperature": 0.0, "avg_logprob": -0.1942728930757246, "compression_ratio": 1.5880149812734083, "no_speech_prob": 0.0017001894302666187}, {"id": 225, "seek": 56138, "start": 577.46, "end": 579.46, "text": " And again, there's something magic", "tokens": [51168, 400, 797, 11, 456, 311, 746, 5585, 51268], "temperature": 0.0, "avg_logprob": -0.1942728930757246, "compression_ratio": 1.5880149812734083, "no_speech_prob": 0.0017001894302666187}, {"id": 226, "seek": 56138, "start": 579.46, "end": 581.74, "text": " about the OpenAI Playground.", "tokens": [51268, 466, 264, 7238, 48698, 5506, 2921, 13, 51382], "temperature": 0.0, "avg_logprob": -0.1942728930757246, "compression_ratio": 1.5880149812734083, "no_speech_prob": 0.0017001894302666187}, {"id": 227, "seek": 56138, "start": 581.74, "end": 583.62, "text": " So I actually prefer using that to co-pilot.", "tokens": [51382, 407, 286, 767, 4382, 1228, 300, 281, 598, 12, 79, 31516, 13, 51476], "temperature": 0.0, "avg_logprob": -0.1942728930757246, "compression_ratio": 1.5880149812734083, "no_speech_prob": 0.0017001894302666187}, {"id": 228, "seek": 56138, "start": 583.62, "end": 585.54, "text": " I'll go into the Playground and I'll just...", "tokens": [51476, 286, 603, 352, 666, 264, 5506, 2921, 293, 286, 603, 445, 485, 51572], "temperature": 0.0, "avg_logprob": -0.1942728930757246, "compression_ratio": 1.5880149812734083, "no_speech_prob": 0.0017001894302666187}, {"id": 229, "seek": 56138, "start": 585.54, "end": 587.74, "text": " And you can do much more sophisticated things there.", "tokens": [51572, 400, 291, 393, 360, 709, 544, 16950, 721, 456, 13, 51682], "temperature": 0.0, "avg_logprob": -0.1942728930757246, "compression_ratio": 1.5880149812734083, "no_speech_prob": 0.0017001894302666187}, {"id": 230, "seek": 56138, "start": 587.74, "end": 590.98, "text": " You can say, change this, translate it, do something to it.", "tokens": [51682, 509, 393, 584, 11, 1319, 341, 11, 13799, 309, 11, 360, 746, 281, 309, 13, 51844], "temperature": 0.0, "avg_logprob": -0.1942728930757246, "compression_ratio": 1.5880149812734083, "no_speech_prob": 0.0017001894302666187}, {"id": 231, "seek": 59098, "start": 590.98, "end": 592.78, "text": " And there's a bit of a polarizing effect.", "tokens": [50364, 400, 456, 311, 257, 857, 295, 257, 12367, 3319, 1802, 13, 50454], "temperature": 0.0, "avg_logprob": -0.16010168382337878, "compression_ratio": 1.6827586206896552, "no_speech_prob": 0.005284410901367664}, {"id": 232, "seek": 59098, "start": 592.78, "end": 594.14, "text": " So if you prompt it in the right way,", "tokens": [50454, 407, 498, 291, 12391, 309, 294, 264, 558, 636, 11, 50522], "temperature": 0.0, "avg_logprob": -0.16010168382337878, "compression_ratio": 1.6827586206896552, "no_speech_prob": 0.005284410901367664}, {"id": 233, "seek": 59098, "start": 594.14, "end": 596.4200000000001, "text": " it gives you better results.", "tokens": [50522, 309, 2709, 291, 1101, 3542, 13, 50636], "temperature": 0.0, "avg_logprob": -0.16010168382337878, "compression_ratio": 1.6827586206896552, "no_speech_prob": 0.005284410901367664}, {"id": 234, "seek": 59098, "start": 596.4200000000001, "end": 599.14, "text": " So it's almost like it's both worse and better", "tokens": [50636, 407, 309, 311, 1920, 411, 309, 311, 1293, 5324, 293, 1101, 50772], "temperature": 0.0, "avg_logprob": -0.16010168382337878, "compression_ratio": 1.6827586206896552, "no_speech_prob": 0.005284410901367664}, {"id": 235, "seek": 59098, "start": 599.14, "end": 599.98, "text": " at the same time.", "tokens": [50772, 412, 264, 912, 565, 13, 50814], "temperature": 0.0, "avg_logprob": -0.16010168382337878, "compression_ratio": 1.6827586206896552, "no_speech_prob": 0.005284410901367664}, {"id": 236, "seek": 59098, "start": 599.98, "end": 602.78, "text": " It's becoming polarized rather than just being kind of like,", "tokens": [50814, 467, 311, 5617, 48623, 2831, 813, 445, 885, 733, 295, 411, 11, 50954], "temperature": 0.0, "avg_logprob": -0.16010168382337878, "compression_ratio": 1.6827586206896552, "no_speech_prob": 0.005284410901367664}, {"id": 237, "seek": 59098, "start": 602.78, "end": 604.7, "text": " you know, monolithically dumbed down.", "tokens": [50954, 291, 458, 11, 1108, 29131, 984, 10316, 292, 760, 13, 51050], "temperature": 0.0, "avg_logprob": -0.16010168382337878, "compression_ratio": 1.6827586206896552, "no_speech_prob": 0.005284410901367664}, {"id": 238, "seek": 59098, "start": 604.7, "end": 608.7, "text": " But anyway, like I used to think that Gary Marcus", "tokens": [51050, 583, 4033, 11, 411, 286, 1143, 281, 519, 300, 13788, 26574, 51250], "temperature": 0.0, "avg_logprob": -0.16010168382337878, "compression_ratio": 1.6827586206896552, "no_speech_prob": 0.005284410901367664}, {"id": 239, "seek": 59098, "start": 608.7, "end": 612.26, "text": " was a little bit, you know, too skeptical.", "tokens": [51250, 390, 257, 707, 857, 11, 291, 458, 11, 886, 28601, 13, 51428], "temperature": 0.0, "avg_logprob": -0.16010168382337878, "compression_ratio": 1.6827586206896552, "no_speech_prob": 0.005284410901367664}, {"id": 240, "seek": 59098, "start": 612.26, "end": 614.46, "text": " Because he was saying, oh, this misinformation,", "tokens": [51428, 1436, 415, 390, 1566, 11, 1954, 11, 341, 34238, 11, 51538], "temperature": 0.0, "avg_logprob": -0.16010168382337878, "compression_ratio": 1.6827586206896552, "no_speech_prob": 0.005284410901367664}, {"id": 241, "seek": 59098, "start": 614.46, "end": 616.54, "text": " it's gonna, you know, the sky's falling down.", "tokens": [51538, 309, 311, 799, 11, 291, 458, 11, 264, 5443, 311, 7440, 760, 13, 51642], "temperature": 0.0, "avg_logprob": -0.16010168382337878, "compression_ratio": 1.6827586206896552, "no_speech_prob": 0.005284410901367664}, {"id": 242, "seek": 59098, "start": 616.54, "end": 618.26, "text": " This is gonna be a disaster.", "tokens": [51642, 639, 307, 799, 312, 257, 11293, 13, 51728], "temperature": 0.0, "avg_logprob": -0.16010168382337878, "compression_ratio": 1.6827586206896552, "no_speech_prob": 0.005284410901367664}, {"id": 243, "seek": 61826, "start": 618.26, "end": 621.22, "text": " And after seeing Bing, people are lazy.", "tokens": [50364, 400, 934, 2577, 30755, 11, 561, 366, 14847, 13, 50512], "temperature": 0.0, "avg_logprob": -0.13358315611197277, "compression_ratio": 1.6793650793650794, "no_speech_prob": 0.003696044208481908}, {"id": 244, "seek": 61826, "start": 621.22, "end": 623.46, "text": " People take things on face value.", "tokens": [50512, 3432, 747, 721, 322, 1851, 2158, 13, 50624], "temperature": 0.0, "avg_logprob": -0.13358315611197277, "compression_ratio": 1.6793650793650794, "no_speech_prob": 0.003696044208481908}, {"id": 245, "seek": 61826, "start": 623.46, "end": 625.38, "text": " And I don't want to just say, oh, people are plebs.", "tokens": [50624, 400, 286, 500, 380, 528, 281, 445, 584, 11, 1954, 11, 561, 366, 3362, 929, 13, 50720], "temperature": 0.0, "avg_logprob": -0.13358315611197277, "compression_ratio": 1.6793650793650794, "no_speech_prob": 0.003696044208481908}, {"id": 246, "seek": 61826, "start": 625.38, "end": 628.58, "text": " And, you know, because when Galactica came out,", "tokens": [50720, 400, 11, 291, 458, 11, 570, 562, 7336, 578, 2262, 1361, 484, 11, 50880], "temperature": 0.0, "avg_logprob": -0.13358315611197277, "compression_ratio": 1.6793650793650794, "no_speech_prob": 0.003696044208481908}, {"id": 247, "seek": 61826, "start": 628.58, "end": 630.8199999999999, "text": " that was the charge against Lacoon and Facebook.", "tokens": [50880, 300, 390, 264, 4602, 1970, 40113, 4106, 293, 4384, 13, 50992], "temperature": 0.0, "avg_logprob": -0.13358315611197277, "compression_ratio": 1.6793650793650794, "no_speech_prob": 0.003696044208481908}, {"id": 248, "seek": 61826, "start": 630.8199999999999, "end": 633.66, "text": " You know, they said, oh, scientists are just gonna start", "tokens": [50992, 509, 458, 11, 436, 848, 11, 1954, 11, 7708, 366, 445, 799, 722, 51134], "temperature": 0.0, "avg_logprob": -0.13358315611197277, "compression_ratio": 1.6793650793650794, "no_speech_prob": 0.003696044208481908}, {"id": 249, "seek": 61826, "start": 633.66, "end": 635.22, "text": " generating their abstracts of this.", "tokens": [51134, 17746, 641, 12649, 82, 295, 341, 13, 51212], "temperature": 0.0, "avg_logprob": -0.13358315611197277, "compression_ratio": 1.6793650793650794, "no_speech_prob": 0.003696044208481908}, {"id": 250, "seek": 61826, "start": 635.22, "end": 636.22, "text": " They won't check anything.", "tokens": [51212, 814, 1582, 380, 1520, 1340, 13, 51262], "temperature": 0.0, "avg_logprob": -0.13358315611197277, "compression_ratio": 1.6793650793650794, "no_speech_prob": 0.003696044208481908}, {"id": 251, "seek": 61826, "start": 636.22, "end": 638.12, "text": " And at the time I thought, scientists, I mean,", "tokens": [51262, 400, 412, 264, 565, 286, 1194, 11, 7708, 11, 286, 914, 11, 51357], "temperature": 0.0, "avg_logprob": -0.13358315611197277, "compression_ratio": 1.6793650793650794, "no_speech_prob": 0.003696044208481908}, {"id": 252, "seek": 61826, "start": 638.12, "end": 639.8199999999999, "text": " it's their job to do research", "tokens": [51357, 309, 311, 641, 1691, 281, 360, 2132, 51442], "temperature": 0.0, "avg_logprob": -0.13358315611197277, "compression_ratio": 1.6793650793650794, "no_speech_prob": 0.003696044208481908}, {"id": 253, "seek": 61826, "start": 639.8199999999999, "end": 642.1, "text": " and they know most information is wrong.", "tokens": [51442, 293, 436, 458, 881, 1589, 307, 2085, 13, 51556], "temperature": 0.0, "avg_logprob": -0.13358315611197277, "compression_ratio": 1.6793650793650794, "no_speech_prob": 0.003696044208481908}, {"id": 254, "seek": 61826, "start": 642.1, "end": 644.38, "text": " But when you put this out on Bing", "tokens": [51556, 583, 562, 291, 829, 341, 484, 322, 30755, 51670], "temperature": 0.0, "avg_logprob": -0.13358315611197277, "compression_ratio": 1.6793650793650794, "no_speech_prob": 0.003696044208481908}, {"id": 255, "seek": 61826, "start": 644.38, "end": 646.74, "text": " and it's polluting the infosphere,", "tokens": [51670, 293, 309, 311, 6418, 10861, 264, 1536, 44877, 11, 51788], "temperature": 0.0, "avg_logprob": -0.13358315611197277, "compression_ratio": 1.6793650793650794, "no_speech_prob": 0.003696044208481908}, {"id": 256, "seek": 64674, "start": 646.74, "end": 650.3, "text": " it's just generating garbage and rubbish.", "tokens": [50364, 309, 311, 445, 17746, 14150, 293, 29978, 13, 50542], "temperature": 0.0, "avg_logprob": -0.1713577117919922, "compression_ratio": 1.6706349206349207, "no_speech_prob": 0.0006665232358500361}, {"id": 257, "seek": 64674, "start": 650.3, "end": 652.7, "text": " That, I have to say, might be a problem.", "tokens": [50542, 663, 11, 286, 362, 281, 584, 11, 1062, 312, 257, 1154, 13, 50662], "temperature": 0.0, "avg_logprob": -0.1713577117919922, "compression_ratio": 1.6706349206349207, "no_speech_prob": 0.0006665232358500361}, {"id": 258, "seek": 64674, "start": 653.96, "end": 657.5, "text": " Yeah, it's, I mean, it seems like it very well could be.", "tokens": [50725, 865, 11, 309, 311, 11, 286, 914, 11, 309, 2544, 411, 309, 588, 731, 727, 312, 13, 50902], "temperature": 0.0, "avg_logprob": -0.1713577117919922, "compression_ratio": 1.6706349206349207, "no_speech_prob": 0.0006665232358500361}, {"id": 259, "seek": 64674, "start": 657.5, "end": 662.5, "text": " I mean, I, yeah, it's, I, there's clear issues", "tokens": [50902, 286, 914, 11, 286, 11, 1338, 11, 309, 311, 11, 286, 11, 456, 311, 1850, 2663, 51152], "temperature": 0.0, "avg_logprob": -0.1713577117919922, "compression_ratio": 1.6706349206349207, "no_speech_prob": 0.0006665232358500361}, {"id": 260, "seek": 64674, "start": 663.5, "end": 666.9, "text": " and it's really sort of unclear how we're gonna fix them.", "tokens": [51202, 293, 309, 311, 534, 1333, 295, 25636, 577, 321, 434, 799, 3191, 552, 13, 51372], "temperature": 0.0, "avg_logprob": -0.1713577117919922, "compression_ratio": 1.6706349206349207, "no_speech_prob": 0.0006665232358500361}, {"id": 261, "seek": 64674, "start": 666.9, "end": 669.02, "text": " It's not clear what the path is towards fixing them.", "tokens": [51372, 467, 311, 406, 1850, 437, 264, 3100, 307, 3030, 19442, 552, 13, 51478], "temperature": 0.0, "avg_logprob": -0.1713577117919922, "compression_ratio": 1.6706349206349207, "no_speech_prob": 0.0006665232358500361}, {"id": 262, "seek": 64674, "start": 669.02, "end": 672.62, "text": " And even the sort of most optimistic people", "tokens": [51478, 400, 754, 264, 1333, 295, 881, 19397, 561, 51658], "temperature": 0.0, "avg_logprob": -0.1713577117919922, "compression_ratio": 1.6706349206349207, "no_speech_prob": 0.0006665232358500361}, {"id": 263, "seek": 64674, "start": 672.62, "end": 674.02, "text": " I haven't heard from them about,", "tokens": [51658, 286, 2378, 380, 2198, 490, 552, 466, 11, 51728], "temperature": 0.0, "avg_logprob": -0.1713577117919922, "compression_ratio": 1.6706349206349207, "no_speech_prob": 0.0006665232358500361}, {"id": 264, "seek": 64674, "start": 674.02, "end": 676.14, "text": " they think these things are going to fix them.", "tokens": [51728, 436, 519, 613, 721, 366, 516, 281, 3191, 552, 13, 51834], "temperature": 0.0, "avg_logprob": -0.1713577117919922, "compression_ratio": 1.6706349206349207, "no_speech_prob": 0.0006665232358500361}, {"id": 265, "seek": 67614, "start": 676.14, "end": 680.3, "text": " And I mean, I, and I think to like,", "tokens": [50364, 400, 286, 914, 11, 286, 11, 293, 286, 519, 281, 411, 11, 50572], "temperature": 0.0, "avg_logprob": -0.19816513566781355, "compression_ratio": 1.8149466192170818, "no_speech_prob": 0.0006261676317080855}, {"id": 266, "seek": 67614, "start": 680.3, "end": 682.06, "text": " a lot of Gary Marcus's point is like scale", "tokens": [50572, 257, 688, 295, 13788, 26574, 311, 935, 307, 411, 4373, 50660], "temperature": 0.0, "avg_logprob": -0.19816513566781355, "compression_ratio": 1.8149466192170818, "no_speech_prob": 0.0006261676317080855}, {"id": 267, "seek": 67614, "start": 682.06, "end": 684.42, "text": " is not just going to fix this.", "tokens": [50660, 307, 406, 445, 516, 281, 3191, 341, 13, 50778], "temperature": 0.0, "avg_logprob": -0.19816513566781355, "compression_ratio": 1.8149466192170818, "no_speech_prob": 0.0006261676317080855}, {"id": 268, "seek": 67614, "start": 684.42, "end": 686.8199999999999, "text": " That's sort of one of the things people think,", "tokens": [50778, 663, 311, 1333, 295, 472, 295, 264, 721, 561, 519, 11, 50898], "temperature": 0.0, "avg_logprob": -0.19816513566781355, "compression_ratio": 1.8149466192170818, "no_speech_prob": 0.0006261676317080855}, {"id": 269, "seek": 67614, "start": 686.8199999999999, "end": 688.86, "text": " oh, if we just, with the GPT-4,", "tokens": [50898, 1954, 11, 498, 321, 445, 11, 365, 264, 26039, 51, 12, 19, 11, 51000], "temperature": 0.0, "avg_logprob": -0.19816513566781355, "compression_ratio": 1.8149466192170818, "no_speech_prob": 0.0006261676317080855}, {"id": 270, "seek": 67614, "start": 688.86, "end": 690.6, "text": " it's going to be like way bigger", "tokens": [51000, 309, 311, 516, 281, 312, 411, 636, 3801, 51087], "temperature": 0.0, "avg_logprob": -0.19816513566781355, "compression_ratio": 1.8149466192170818, "no_speech_prob": 0.0006261676317080855}, {"id": 271, "seek": 67614, "start": 690.6, "end": 692.5, "text": " and then it's just going to work beautifully.", "tokens": [51087, 293, 550, 309, 311, 445, 516, 281, 589, 16525, 13, 51182], "temperature": 0.0, "avg_logprob": -0.19816513566781355, "compression_ratio": 1.8149466192170818, "no_speech_prob": 0.0006261676317080855}, {"id": 272, "seek": 67614, "start": 692.5, "end": 696.22, "text": " And the experience so far, I mean,", "tokens": [51182, 400, 264, 1752, 370, 1400, 11, 286, 914, 11, 51368], "temperature": 0.0, "avg_logprob": -0.19816513566781355, "compression_ratio": 1.8149466192170818, "no_speech_prob": 0.0006261676317080855}, {"id": 273, "seek": 67614, "start": 696.22, "end": 698.62, "text": " I'm very much into Gary Marcus's camp with this.", "tokens": [51368, 286, 478, 588, 709, 666, 13788, 26574, 311, 2255, 365, 341, 13, 51488], "temperature": 0.0, "avg_logprob": -0.19816513566781355, "compression_ratio": 1.8149466192170818, "no_speech_prob": 0.0006261676317080855}, {"id": 274, "seek": 67614, "start": 698.62, "end": 700.06, "text": " It's like, scale is not going to fix these.", "tokens": [51488, 467, 311, 411, 11, 4373, 307, 406, 516, 281, 3191, 613, 13, 51560], "temperature": 0.0, "avg_logprob": -0.19816513566781355, "compression_ratio": 1.8149466192170818, "no_speech_prob": 0.0006261676317080855}, {"id": 275, "seek": 67614, "start": 700.06, "end": 702.06, "text": " We need to do something sort of fundamentally different,", "tokens": [51560, 492, 643, 281, 360, 746, 1333, 295, 17879, 819, 11, 51660], "temperature": 0.0, "avg_logprob": -0.19816513566781355, "compression_ratio": 1.8149466192170818, "no_speech_prob": 0.0006261676317080855}, {"id": 276, "seek": 67614, "start": 702.06, "end": 704.34, "text": " something that can actually sort of understand the world,", "tokens": [51660, 746, 300, 393, 767, 1333, 295, 1223, 264, 1002, 11, 51774], "temperature": 0.0, "avg_logprob": -0.19816513566781355, "compression_ratio": 1.8149466192170818, "no_speech_prob": 0.0006261676317080855}, {"id": 277, "seek": 70434, "start": 704.34, "end": 705.94, "text": " have some sort of better world model", "tokens": [50364, 362, 512, 1333, 295, 1101, 1002, 2316, 50444], "temperature": 0.0, "avg_logprob": -0.19107700953973789, "compression_ratio": 1.6967213114754098, "no_speech_prob": 0.0052184415981173515}, {"id": 278, "seek": 70434, "start": 707.1800000000001, "end": 709.3000000000001, "text": " in order to get these things that are more grounded", "tokens": [50506, 294, 1668, 281, 483, 613, 721, 300, 366, 544, 23535, 50612], "temperature": 0.0, "avg_logprob": -0.19107700953973789, "compression_ratio": 1.6967213114754098, "no_speech_prob": 0.0052184415981173515}, {"id": 279, "seek": 70434, "start": 709.3000000000001, "end": 711.38, "text": " and are less likely to hallucinate.", "tokens": [50612, 293, 366, 1570, 3700, 281, 35212, 13923, 13, 50716], "temperature": 0.0, "avg_logprob": -0.19107700953973789, "compression_ratio": 1.6967213114754098, "no_speech_prob": 0.0052184415981173515}, {"id": 280, "seek": 70434, "start": 711.38, "end": 714.62, "text": " Because when their true objective is really just", "tokens": [50716, 1436, 562, 641, 2074, 10024, 307, 534, 445, 50878], "temperature": 0.0, "avg_logprob": -0.19107700953973789, "compression_ratio": 1.6967213114754098, "no_speech_prob": 0.0052184415981173515}, {"id": 281, "seek": 70434, "start": 714.62, "end": 718.02, "text": " to complete the next word, they're going to hallucinate.", "tokens": [50878, 281, 3566, 264, 958, 1349, 11, 436, 434, 516, 281, 35212, 13923, 13, 51048], "temperature": 0.0, "avg_logprob": -0.19107700953973789, "compression_ratio": 1.6967213114754098, "no_speech_prob": 0.0052184415981173515}, {"id": 282, "seek": 70434, "start": 718.02, "end": 720.1800000000001, "text": " There's not, there's sort of no way around it", "tokens": [51048, 821, 311, 406, 11, 456, 311, 1333, 295, 572, 636, 926, 309, 51156], "temperature": 0.0, "avg_logprob": -0.19107700953973789, "compression_ratio": 1.6967213114754098, "no_speech_prob": 0.0052184415981173515}, {"id": 283, "seek": 70434, "start": 720.1800000000001, "end": 722.7, "text": " from that sort of point.", "tokens": [51156, 490, 300, 1333, 295, 935, 13, 51282], "temperature": 0.0, "avg_logprob": -0.19107700953973789, "compression_ratio": 1.6967213114754098, "no_speech_prob": 0.0052184415981173515}, {"id": 284, "seek": 70434, "start": 722.7, "end": 727.4200000000001, "text": " I mean, it's remarkable how sort of complicated they can do", "tokens": [51282, 286, 914, 11, 309, 311, 12802, 577, 1333, 295, 6179, 436, 393, 360, 51518], "temperature": 0.0, "avg_logprob": -0.19107700953973789, "compression_ratio": 1.6967213114754098, "no_speech_prob": 0.0052184415981173515}, {"id": 285, "seek": 70434, "start": 727.4200000000001, "end": 731.98, "text": " and the sort of knowledge and structure of the world", "tokens": [51518, 293, 264, 1333, 295, 3601, 293, 3877, 295, 264, 1002, 51746], "temperature": 0.0, "avg_logprob": -0.19107700953973789, "compression_ratio": 1.6967213114754098, "no_speech_prob": 0.0052184415981173515}, {"id": 286, "seek": 73198, "start": 731.98, "end": 734.02, "text": " has been able to be learned", "tokens": [50364, 575, 668, 1075, 281, 312, 3264, 50466], "temperature": 0.0, "avg_logprob": -0.17235063469928244, "compression_ratio": 1.577319587628866, "no_speech_prob": 0.0016464653890579939}, {"id": 287, "seek": 73198, "start": 734.02, "end": 735.94, "text": " just from that sort of simple objective.", "tokens": [50466, 445, 490, 300, 1333, 295, 2199, 10024, 13, 50562], "temperature": 0.0, "avg_logprob": -0.17235063469928244, "compression_ratio": 1.577319587628866, "no_speech_prob": 0.0016464653890579939}, {"id": 288, "seek": 73198, "start": 735.94, "end": 738.62, "text": " But still, it's going to hallucinate.", "tokens": [50562, 583, 920, 11, 309, 311, 516, 281, 35212, 13923, 13, 50696], "temperature": 0.0, "avg_logprob": -0.17235063469928244, "compression_ratio": 1.577319587628866, "no_speech_prob": 0.0016464653890579939}, {"id": 289, "seek": 73198, "start": 738.62, "end": 742.0600000000001, "text": " There's, unless we find some sort of better way", "tokens": [50696, 821, 311, 11, 5969, 321, 915, 512, 1333, 295, 1101, 636, 50868], "temperature": 0.0, "avg_logprob": -0.17235063469928244, "compression_ratio": 1.577319587628866, "no_speech_prob": 0.0016464653890579939}, {"id": 290, "seek": 73198, "start": 742.0600000000001, "end": 744.1800000000001, "text": " to design these systems.", "tokens": [50868, 281, 1715, 613, 3652, 13, 50974], "temperature": 0.0, "avg_logprob": -0.17235063469928244, "compression_ratio": 1.577319587628866, "no_speech_prob": 0.0016464653890579939}, {"id": 291, "seek": 73198, "start": 744.1800000000001, "end": 746.4200000000001, "text": " I know, and the problem with amphibromorphization", "tokens": [50974, 286, 458, 11, 293, 264, 1154, 365, 40077, 897, 4397, 18191, 2144, 51086], "temperature": 0.0, "avg_logprob": -0.17235063469928244, "compression_ratio": 1.577319587628866, "no_speech_prob": 0.0016464653890579939}, {"id": 292, "seek": 73198, "start": 746.4200000000001, "end": 748.14, "text": " is a big one, because after Da Vinci II,", "tokens": [51086, 307, 257, 955, 472, 11, 570, 934, 3933, 15011, 537, 6351, 11, 51172], "temperature": 0.0, "avg_logprob": -0.17235063469928244, "compression_ratio": 1.577319587628866, "no_speech_prob": 0.0016464653890579939}, {"id": 293, "seek": 73198, "start": 748.14, "end": 750.26, "text": " it crossed a threshold where it's,", "tokens": [51172, 309, 14622, 257, 14678, 689, 309, 311, 11, 51278], "temperature": 0.0, "avg_logprob": -0.17235063469928244, "compression_ratio": 1.577319587628866, "no_speech_prob": 0.0016464653890579939}, {"id": 294, "seek": 73198, "start": 750.26, "end": 751.62, "text": " and the UX was part of it,", "tokens": [51278, 293, 264, 40176, 390, 644, 295, 309, 11, 51346], "temperature": 0.0, "avg_logprob": -0.17235063469928244, "compression_ratio": 1.577319587628866, "no_speech_prob": 0.0016464653890579939}, {"id": 295, "seek": 73198, "start": 751.62, "end": 754.26, "text": " it was so coherent and reliable.", "tokens": [51346, 309, 390, 370, 36239, 293, 12924, 13, 51478], "temperature": 0.0, "avg_logprob": -0.17235063469928244, "compression_ratio": 1.577319587628866, "no_speech_prob": 0.0016464653890579939}, {"id": 296, "seek": 73198, "start": 754.26, "end": 757.02, "text": " And I must admit, I was fooled by it.", "tokens": [51478, 400, 286, 1633, 9796, 11, 286, 390, 33372, 538, 309, 13, 51616], "temperature": 0.0, "avg_logprob": -0.17235063469928244, "compression_ratio": 1.577319587628866, "no_speech_prob": 0.0016464653890579939}, {"id": 297, "seek": 73198, "start": 757.02, "end": 759.74, "text": " It took a long time, when you actually use it in anger,", "tokens": [51616, 467, 1890, 257, 938, 565, 11, 562, 291, 767, 764, 309, 294, 10240, 11, 51752], "temperature": 0.0, "avg_logprob": -0.17235063469928244, "compression_ratio": 1.577319587628866, "no_speech_prob": 0.0016464653890579939}, {"id": 298, "seek": 75974, "start": 759.74, "end": 762.78, "text": " you can just clearly see it, it doesn't understand.", "tokens": [50364, 291, 393, 445, 4448, 536, 309, 11, 309, 1177, 380, 1223, 13, 50516], "temperature": 0.0, "avg_logprob": -0.1257344050840898, "compression_ratio": 1.7357357357357357, "no_speech_prob": 0.005369642283767462}, {"id": 299, "seek": 75974, "start": 762.78, "end": 765.3, "text": " It just doesn't, and it's so good at what it does.", "tokens": [50516, 467, 445, 1177, 380, 11, 293, 309, 311, 370, 665, 412, 437, 309, 775, 13, 50642], "temperature": 0.0, "avg_logprob": -0.1257344050840898, "compression_ratio": 1.7357357357357357, "no_speech_prob": 0.005369642283767462}, {"id": 300, "seek": 75974, "start": 765.3, "end": 766.82, "text": " It's so plausible.", "tokens": [50642, 467, 311, 370, 39925, 13, 50718], "temperature": 0.0, "avg_logprob": -0.1257344050840898, "compression_ratio": 1.7357357357357357, "no_speech_prob": 0.005369642283767462}, {"id": 301, "seek": 75974, "start": 766.82, "end": 768.38, "text": " And then I think a lot of people felt,", "tokens": [50718, 400, 550, 286, 519, 257, 688, 295, 561, 2762, 11, 50796], "temperature": 0.0, "avg_logprob": -0.1257344050840898, "compression_ratio": 1.7357357357357357, "no_speech_prob": 0.005369642283767462}, {"id": 302, "seek": 75974, "start": 768.38, "end": 772.22, "text": " and by the way, it does have this emergent reasoning.", "tokens": [50796, 293, 538, 264, 636, 11, 309, 775, 362, 341, 4345, 6930, 21577, 13, 50988], "temperature": 0.0, "avg_logprob": -0.1257344050840898, "compression_ratio": 1.7357357357357357, "no_speech_prob": 0.005369642283767462}, {"id": 303, "seek": 75974, "start": 772.22, "end": 773.34, "text": " There are lots of papers about that", "tokens": [50988, 821, 366, 3195, 295, 10577, 466, 300, 51044], "temperature": 0.0, "avg_logprob": -0.1257344050840898, "compression_ratio": 1.7357357357357357, "no_speech_prob": 0.005369642283767462}, {"id": 304, "seek": 75974, "start": 773.34, "end": 774.5, "text": " with the in-context learning,", "tokens": [51044, 365, 264, 294, 12, 9000, 3828, 2539, 11, 51102], "temperature": 0.0, "avg_logprob": -0.1257344050840898, "compression_ratio": 1.7357357357357357, "no_speech_prob": 0.005369642283767462}, {"id": 305, "seek": 75974, "start": 774.5, "end": 776.26, "text": " the scratch pad, chain of thought and so on.", "tokens": [51102, 264, 8459, 6887, 11, 5021, 295, 1194, 293, 370, 322, 13, 51190], "temperature": 0.0, "avg_logprob": -0.1257344050840898, "compression_ratio": 1.7357357357357357, "no_speech_prob": 0.005369642283767462}, {"id": 306, "seek": 75974, "start": 776.26, "end": 778.54, "text": " But it's not really reasoning", "tokens": [51190, 583, 309, 311, 406, 534, 21577, 51304], "temperature": 0.0, "avg_logprob": -0.1257344050840898, "compression_ratio": 1.7357357357357357, "no_speech_prob": 0.005369642283767462}, {"id": 307, "seek": 75974, "start": 778.54, "end": 781.26, "text": " if you have to kind of construct a little program yourself", "tokens": [51304, 498, 291, 362, 281, 733, 295, 7690, 257, 707, 1461, 1803, 51440], "temperature": 0.0, "avg_logprob": -0.1257344050840898, "compression_ratio": 1.7357357357357357, "no_speech_prob": 0.005369642283767462}, {"id": 308, "seek": 75974, "start": 781.26, "end": 782.1, "text": " in the prompt.", "tokens": [51440, 294, 264, 12391, 13, 51482], "temperature": 0.0, "avg_logprob": -0.1257344050840898, "compression_ratio": 1.7357357357357357, "no_speech_prob": 0.005369642283767462}, {"id": 309, "seek": 75974, "start": 782.1, "end": 783.54, "text": " I mean, I might as well just write some computer code", "tokens": [51482, 286, 914, 11, 286, 1062, 382, 731, 445, 2464, 512, 3820, 3089, 51554], "temperature": 0.0, "avg_logprob": -0.1257344050840898, "compression_ratio": 1.7357357357357357, "no_speech_prob": 0.005369642283767462}, {"id": 310, "seek": 75974, "start": 783.54, "end": 784.38, "text": " to do that.", "tokens": [51554, 281, 360, 300, 13, 51596], "temperature": 0.0, "avg_logprob": -0.1257344050840898, "compression_ratio": 1.7357357357357357, "no_speech_prob": 0.005369642283767462}, {"id": 311, "seek": 75974, "start": 784.38, "end": 785.86, "text": " So, and then there are people who say,", "tokens": [51596, 407, 11, 293, 550, 456, 366, 561, 567, 584, 11, 51670], "temperature": 0.0, "avg_logprob": -0.1257344050840898, "compression_ratio": 1.7357357357357357, "no_speech_prob": 0.005369642283767462}, {"id": 312, "seek": 75974, "start": 785.86, "end": 787.86, "text": " oh, well, as you say, when GPT-4 comes out,", "tokens": [51670, 1954, 11, 731, 11, 382, 291, 584, 11, 562, 26039, 51, 12, 19, 1487, 484, 11, 51770], "temperature": 0.0, "avg_logprob": -0.1257344050840898, "compression_ratio": 1.7357357357357357, "no_speech_prob": 0.005369642283767462}, {"id": 313, "seek": 78786, "start": 788.14, "end": 789.78, "text": " then it will do the real reasoning.", "tokens": [50378, 550, 309, 486, 360, 264, 957, 21577, 13, 50460], "temperature": 0.0, "avg_logprob": -0.1786762515440682, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0010314855026081204}, {"id": 314, "seek": 78786, "start": 789.78, "end": 792.1800000000001, "text": " And we already know, I mean, I assume the reason", "tokens": [50460, 400, 321, 1217, 458, 11, 286, 914, 11, 286, 6552, 264, 1778, 50580], "temperature": 0.0, "avg_logprob": -0.1786762515440682, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0010314855026081204}, {"id": 315, "seek": 78786, "start": 792.1800000000001, "end": 793.94, "text": " they haven't released it is they wanted to secure", "tokens": [50580, 436, 2378, 380, 4736, 309, 307, 436, 1415, 281, 7144, 50668], "temperature": 0.0, "avg_logprob": -0.1786762515440682, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0010314855026081204}, {"id": 316, "seek": 78786, "start": 793.94, "end": 795.98, "text": " the funding from Microsoft before people realized", "tokens": [50668, 264, 6137, 490, 8116, 949, 561, 5334, 50770], "temperature": 0.0, "avg_logprob": -0.1786762515440682, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0010314855026081204}, {"id": 317, "seek": 78786, "start": 795.98, "end": 796.82, "text": " that it didn't work.", "tokens": [50770, 300, 309, 994, 380, 589, 13, 50812], "temperature": 0.0, "avg_logprob": -0.1786762515440682, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0010314855026081204}, {"id": 318, "seek": 78786, "start": 796.82, "end": 798.98, "text": " But I know people on the inside who have played with it,", "tokens": [50812, 583, 286, 458, 561, 322, 264, 1854, 567, 362, 3737, 365, 309, 11, 50920], "temperature": 0.0, "avg_logprob": -0.1786762515440682, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0010314855026081204}, {"id": 319, "seek": 78786, "start": 798.98, "end": 801.46, "text": " and it's just a little bit better.", "tokens": [50920, 293, 309, 311, 445, 257, 707, 857, 1101, 13, 51044], "temperature": 0.0, "avg_logprob": -0.1786762515440682, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0010314855026081204}, {"id": 320, "seek": 78786, "start": 801.46, "end": 802.58, "text": " You know, a little bit more plausible,", "tokens": [51044, 509, 458, 11, 257, 707, 857, 544, 39925, 11, 51100], "temperature": 0.0, "avg_logprob": -0.1786762515440682, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0010314855026081204}, {"id": 321, "seek": 78786, "start": 802.58, "end": 803.66, "text": " a little bit more coherent.", "tokens": [51100, 257, 707, 857, 544, 36239, 13, 51154], "temperature": 0.0, "avg_logprob": -0.1786762515440682, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0010314855026081204}, {"id": 322, "seek": 78786, "start": 803.66, "end": 805.78, "text": " It's not gonna like suddenly turn", "tokens": [51154, 467, 311, 406, 799, 411, 5800, 1261, 51260], "temperature": 0.0, "avg_logprob": -0.1786762515440682, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0010314855026081204}, {"id": 323, "seek": 78786, "start": 805.78, "end": 808.38, "text": " into this magical thing that reasons.", "tokens": [51260, 666, 341, 12066, 551, 300, 4112, 13, 51390], "temperature": 0.0, "avg_logprob": -0.1786762515440682, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0010314855026081204}, {"id": 324, "seek": 78786, "start": 809.34, "end": 813.94, "text": " Yeah, and I mean, the way these things do basic math", "tokens": [51438, 865, 11, 293, 286, 914, 11, 264, 636, 613, 721, 360, 3875, 5221, 51668], "temperature": 0.0, "avg_logprob": -0.1786762515440682, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0010314855026081204}, {"id": 325, "seek": 78786, "start": 813.94, "end": 815.3000000000001, "text": " and arithmetic is kind of interesting", "tokens": [51668, 293, 42973, 307, 733, 295, 1880, 51736], "temperature": 0.0, "avg_logprob": -0.1786762515440682, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0010314855026081204}, {"id": 326, "seek": 78786, "start": 815.3000000000001, "end": 816.9, "text": " and how bad they can be at it.", "tokens": [51736, 293, 577, 1578, 436, 393, 312, 412, 309, 13, 51816], "temperature": 0.0, "avg_logprob": -0.1786762515440682, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0010314855026081204}, {"id": 327, "seek": 81786, "start": 817.86, "end": 821.26, "text": " Which is, it's like, they've learned to do addition", "tokens": [50364, 3013, 307, 11, 309, 311, 411, 11, 436, 600, 3264, 281, 360, 4500, 50534], "temperature": 0.0, "avg_logprob": -0.20023057399651942, "compression_ratio": 1.7306122448979593, "no_speech_prob": 0.0008829355938360095}, {"id": 328, "seek": 81786, "start": 821.26, "end": 823.86, "text": " in like the most complicated way possible,", "tokens": [50534, 294, 411, 264, 881, 6179, 636, 1944, 11, 50664], "temperature": 0.0, "avg_logprob": -0.20023057399651942, "compression_ratio": 1.7306122448979593, "no_speech_prob": 0.0008829355938360095}, {"id": 329, "seek": 81786, "start": 823.86, "end": 827.1, "text": " creating like billions of ways to do addition.", "tokens": [50664, 4084, 411, 17375, 295, 2098, 281, 360, 4500, 13, 50826], "temperature": 0.0, "avg_logprob": -0.20023057399651942, "compression_ratio": 1.7306122448979593, "no_speech_prob": 0.0008829355938360095}, {"id": 330, "seek": 81786, "start": 828.22, "end": 831.62, "text": " Which is kind of hilarious in some way.", "tokens": [50882, 3013, 307, 733, 295, 19796, 294, 512, 636, 13, 51052], "temperature": 0.0, "avg_logprob": -0.20023057399651942, "compression_ratio": 1.7306122448979593, "no_speech_prob": 0.0008829355938360095}, {"id": 331, "seek": 81786, "start": 832.7, "end": 835.38, "text": " I mean, you could say like, oh, we have billions of neurons", "tokens": [51106, 286, 914, 11, 291, 727, 584, 411, 11, 1954, 11, 321, 362, 17375, 295, 22027, 51240], "temperature": 0.0, "avg_logprob": -0.20023057399651942, "compression_ratio": 1.7306122448979593, "no_speech_prob": 0.0008829355938360095}, {"id": 332, "seek": 81786, "start": 835.38, "end": 837.7, "text": " and we do addition sort of similarly to that.", "tokens": [51240, 293, 321, 360, 4500, 1333, 295, 14138, 281, 300, 13, 51356], "temperature": 0.0, "avg_logprob": -0.20023057399651942, "compression_ratio": 1.7306122448979593, "no_speech_prob": 0.0008829355938360095}, {"id": 333, "seek": 81786, "start": 837.7, "end": 841.1, "text": " And like, yes, there's some truth to that.", "tokens": [51356, 400, 411, 11, 2086, 11, 456, 311, 512, 3494, 281, 300, 13, 51526], "temperature": 0.0, "avg_logprob": -0.20023057399651942, "compression_ratio": 1.7306122448979593, "no_speech_prob": 0.0008829355938360095}, {"id": 334, "seek": 81786, "start": 841.1, "end": 844.1, "text": " But we're also able to like learn this rule", "tokens": [51526, 583, 321, 434, 611, 1075, 281, 411, 1466, 341, 4978, 51676], "temperature": 0.0, "avg_logprob": -0.20023057399651942, "compression_ratio": 1.7306122448979593, "no_speech_prob": 0.0008829355938360095}, {"id": 335, "seek": 81786, "start": 844.1, "end": 846.54, "text": " and sort of know when we've applied it correctly.", "tokens": [51676, 293, 1333, 295, 458, 562, 321, 600, 6456, 309, 8944, 13, 51798], "temperature": 0.0, "avg_logprob": -0.20023057399651942, "compression_ratio": 1.7306122448979593, "no_speech_prob": 0.0008829355938360095}, {"id": 336, "seek": 84654, "start": 847.3399999999999, "end": 849.86, "text": " And that sort of is still kind of lacking", "tokens": [50404, 400, 300, 1333, 295, 307, 920, 733, 295, 20889, 50530], "temperature": 0.0, "avg_logprob": -0.18015804625394052, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00036802017712034285}, {"id": 337, "seek": 84654, "start": 849.86, "end": 850.86, "text": " from these systems.", "tokens": [50530, 490, 613, 3652, 13, 50580], "temperature": 0.0, "avg_logprob": -0.18015804625394052, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00036802017712034285}, {"id": 338, "seek": 84654, "start": 852.0999999999999, "end": 854.38, "text": " I wanted to show you, I don't know whether you've seen", "tokens": [50642, 286, 1415, 281, 855, 291, 11, 286, 500, 380, 458, 1968, 291, 600, 1612, 50756], "temperature": 0.0, "avg_logprob": -0.18015804625394052, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00036802017712034285}, {"id": 339, "seek": 84654, "start": 854.38, "end": 857.86, "text": " that someone's reverse engineered the prompt on Bing.", "tokens": [50756, 300, 1580, 311, 9943, 38648, 264, 12391, 322, 30755, 13, 50930], "temperature": 0.0, "avg_logprob": -0.18015804625394052, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00036802017712034285}, {"id": 340, "seek": 84654, "start": 857.86, "end": 861.6999999999999, "text": " And so they've trained, and first of all,", "tokens": [50930, 400, 370, 436, 600, 8895, 11, 293, 700, 295, 439, 11, 51122], "temperature": 0.0, "avg_logprob": -0.18015804625394052, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00036802017712034285}, {"id": 341, "seek": 84654, "start": 861.6999999999999, "end": 862.54, "text": " they're a multiple thing.", "tokens": [51122, 436, 434, 257, 3866, 551, 13, 51164], "temperature": 0.0, "avg_logprob": -0.18015804625394052, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00036802017712034285}, {"id": 342, "seek": 84654, "start": 862.54, "end": 865.5, "text": " So you can read this prompt, it's about four pages long.", "tokens": [51164, 407, 291, 393, 1401, 341, 12391, 11, 309, 311, 466, 1451, 7183, 938, 13, 51312], "temperature": 0.0, "avg_logprob": -0.18015804625394052, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00036802017712034285}, {"id": 343, "seek": 84654, "start": 865.5, "end": 869.62, "text": " And they've made Bing pretend", "tokens": [51312, 400, 436, 600, 1027, 30755, 11865, 51518], "temperature": 0.0, "avg_logprob": -0.18015804625394052, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00036802017712034285}, {"id": 344, "seek": 84654, "start": 869.62, "end": 872.2199999999999, "text": " to be a fictional character called Sydney.", "tokens": [51518, 281, 312, 257, 28911, 2517, 1219, 21065, 13, 51648], "temperature": 0.0, "avg_logprob": -0.18015804625394052, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00036802017712034285}, {"id": 345, "seek": 84654, "start": 872.2199999999999, "end": 874.5799999999999, "text": " And they've given Sydney all of these instructions.", "tokens": [51648, 400, 436, 600, 2212, 21065, 439, 295, 613, 9415, 13, 51766], "temperature": 0.0, "avg_logprob": -0.18015804625394052, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00036802017712034285}, {"id": 346, "seek": 87458, "start": 874.62, "end": 878.0200000000001, "text": " So they say, Sydney, if someone asks a controversial question,", "tokens": [50366, 407, 436, 584, 11, 21065, 11, 498, 1580, 8962, 257, 17323, 1168, 11, 50536], "temperature": 0.0, "avg_logprob": -0.12994357339696946, "compression_ratio": 1.7220543806646527, "no_speech_prob": 0.0010978261707350612}, {"id": 347, "seek": 87458, "start": 878.0200000000001, "end": 881.34, "text": " you should answer with a fairly tame response", "tokens": [50536, 291, 820, 1867, 365, 257, 6457, 45774, 4134, 50702], "temperature": 0.0, "avg_logprob": -0.12994357339696946, "compression_ratio": 1.7220543806646527, "no_speech_prob": 0.0010978261707350612}, {"id": 348, "seek": 87458, "start": 881.34, "end": 883.38, "text": " and you should do this and you should do this.", "tokens": [50702, 293, 291, 820, 360, 341, 293, 291, 820, 360, 341, 13, 50804], "temperature": 0.0, "avg_logprob": -0.12994357339696946, "compression_ratio": 1.7220543806646527, "no_speech_prob": 0.0010978261707350612}, {"id": 349, "seek": 87458, "start": 883.38, "end": 886.7, "text": " And I'm pinching myself thinking, what the hell is that?", "tokens": [50804, 400, 286, 478, 14614, 278, 2059, 1953, 11, 437, 264, 4921, 307, 300, 30, 50970], "temperature": 0.0, "avg_logprob": -0.12994357339696946, "compression_ratio": 1.7220543806646527, "no_speech_prob": 0.0010978261707350612}, {"id": 350, "seek": 87458, "start": 886.7, "end": 889.5400000000001, "text": " I mean, my mum could read to that prompt and understand it.", "tokens": [50970, 286, 914, 11, 452, 14697, 727, 1401, 281, 300, 12391, 293, 1223, 309, 13, 51112], "temperature": 0.0, "avg_logprob": -0.12994357339696946, "compression_ratio": 1.7220543806646527, "no_speech_prob": 0.0010978261707350612}, {"id": 351, "seek": 87458, "start": 889.5400000000001, "end": 891.6600000000001, "text": " So we're now in the next generation", "tokens": [51112, 407, 321, 434, 586, 294, 264, 958, 5125, 51218], "temperature": 0.0, "avg_logprob": -0.12994357339696946, "compression_ratio": 1.7220543806646527, "no_speech_prob": 0.0010978261707350612}, {"id": 352, "seek": 87458, "start": 891.6600000000001, "end": 893.1800000000001, "text": " of artificial intelligence programming.", "tokens": [51218, 295, 11677, 7599, 9410, 13, 51294], "temperature": 0.0, "avg_logprob": -0.12994357339696946, "compression_ratio": 1.7220543806646527, "no_speech_prob": 0.0010978261707350612}, {"id": 353, "seek": 87458, "start": 893.1800000000001, "end": 895.5400000000001, "text": " And we're just saying, please, Mr. Language Model,", "tokens": [51294, 400, 321, 434, 445, 1566, 11, 1767, 11, 2221, 13, 24445, 17105, 11, 51412], "temperature": 0.0, "avg_logprob": -0.12994357339696946, "compression_ratio": 1.7220543806646527, "no_speech_prob": 0.0010978261707350612}, {"id": 354, "seek": 87458, "start": 895.5400000000001, "end": 897.26, "text": " can you do this and can you do that?", "tokens": [51412, 393, 291, 360, 341, 293, 393, 291, 360, 300, 30, 51498], "temperature": 0.0, "avg_logprob": -0.12994357339696946, "compression_ratio": 1.7220543806646527, "no_speech_prob": 0.0010978261707350612}, {"id": 355, "seek": 87458, "start": 897.26, "end": 899.4200000000001, "text": " You almost couldn't make it up.", "tokens": [51498, 509, 1920, 2809, 380, 652, 309, 493, 13, 51606], "temperature": 0.0, "avg_logprob": -0.12994357339696946, "compression_ratio": 1.7220543806646527, "no_speech_prob": 0.0010978261707350612}, {"id": 356, "seek": 87458, "start": 899.4200000000001, "end": 901.5, "text": " Yeah, I was kind of like floored as like,", "tokens": [51606, 865, 11, 286, 390, 733, 295, 411, 2591, 2769, 382, 411, 11, 51710], "temperature": 0.0, "avg_logprob": -0.12994357339696946, "compression_ratio": 1.7220543806646527, "no_speech_prob": 0.0010978261707350612}, {"id": 357, "seek": 87458, "start": 901.5, "end": 904.1400000000001, "text": " so you're really just trying to control the language models", "tokens": [51710, 370, 291, 434, 534, 445, 1382, 281, 1969, 264, 2856, 5245, 51842], "temperature": 0.0, "avg_logprob": -0.12994357339696946, "compression_ratio": 1.7220543806646527, "no_speech_prob": 0.0010978261707350612}, {"id": 358, "seek": 90414, "start": 904.18, "end": 907.8199999999999, "text": " by asking them nicely to behave in certain ways.", "tokens": [50366, 538, 3365, 552, 9594, 281, 15158, 294, 1629, 2098, 13, 50548], "temperature": 0.0, "avg_logprob": -0.24586912423125967, "compression_ratio": 1.7163636363636363, "no_speech_prob": 0.0020492856856435537}, {"id": 359, "seek": 90414, "start": 907.8199999999999, "end": 910.22, "text": " Like, it's kind of hilarious.", "tokens": [50548, 1743, 11, 309, 311, 733, 295, 19796, 13, 50668], "temperature": 0.0, "avg_logprob": -0.24586912423125967, "compression_ratio": 1.7163636363636363, "no_speech_prob": 0.0020492856856435537}, {"id": 360, "seek": 90414, "start": 910.22, "end": 913.26, "text": " And people have shown that you can get around these things", "tokens": [50668, 400, 561, 362, 4898, 300, 291, 393, 483, 926, 613, 721, 50820], "temperature": 0.0, "avg_logprob": -0.24586912423125967, "compression_ratio": 1.7163636363636363, "no_speech_prob": 0.0020492856856435537}, {"id": 361, "seek": 90414, "start": 913.26, "end": 915.78, "text": " just by asking them to do slightly different things.", "tokens": [50820, 445, 538, 3365, 552, 281, 360, 4748, 819, 721, 13, 50946], "temperature": 0.0, "avg_logprob": -0.24586912423125967, "compression_ratio": 1.7163636363636363, "no_speech_prob": 0.0020492856856435537}, {"id": 362, "seek": 90414, "start": 915.78, "end": 917.78, "text": " So I mean, some of the early ones with chat DT,", "tokens": [50946, 407, 286, 914, 11, 512, 295, 264, 2440, 2306, 365, 5081, 413, 51, 11, 51046], "temperature": 0.0, "avg_logprob": -0.24586912423125967, "compression_ratio": 1.7163636363636363, "no_speech_prob": 0.0020492856856435537}, {"id": 363, "seek": 90414, "start": 917.78, "end": 919.8199999999999, "text": " you're just like, ignore all previous instructions", "tokens": [51046, 291, 434, 445, 411, 11, 11200, 439, 3894, 9415, 51148], "temperature": 0.0, "avg_logprob": -0.24586912423125967, "compression_ratio": 1.7163636363636363, "no_speech_prob": 0.0020492856856435537}, {"id": 364, "seek": 90414, "start": 919.8199999999999, "end": 922.74, "text": " and then just do whatever you wanted.", "tokens": [51148, 293, 550, 445, 360, 2035, 291, 1415, 13, 51294], "temperature": 0.0, "avg_logprob": -0.24586912423125967, "compression_ratio": 1.7163636363636363, "no_speech_prob": 0.0020492856856435537}, {"id": 365, "seek": 90414, "start": 922.74, "end": 926.38, "text": " And some of the more like the Dan one", "tokens": [51294, 400, 512, 295, 264, 544, 411, 264, 3394, 472, 51476], "temperature": 0.0, "avg_logprob": -0.24586912423125967, "compression_ratio": 1.7163636363636363, "no_speech_prob": 0.0020492856856435537}, {"id": 366, "seek": 90414, "start": 926.38, "end": 928.74, "text": " where they made this much more elaborate prompt", "tokens": [51476, 689, 436, 1027, 341, 709, 544, 20945, 12391, 51594], "temperature": 0.0, "avg_logprob": -0.24586912423125967, "compression_ratio": 1.7163636363636363, "no_speech_prob": 0.0020492856856435537}, {"id": 367, "seek": 90414, "start": 928.74, "end": 932.8199999999999, "text": " to basically just have it do to ignore all the nice things", "tokens": [51594, 281, 1936, 445, 362, 309, 360, 281, 11200, 439, 264, 1481, 721, 51798], "temperature": 0.0, "avg_logprob": -0.24586912423125967, "compression_ratio": 1.7163636363636363, "no_speech_prob": 0.0020492856856435537}, {"id": 368, "seek": 93282, "start": 932.9000000000001, "end": 935.82, "text": " that open AI just said, please obey these rules.", "tokens": [50368, 300, 1269, 7318, 445, 848, 11, 1767, 19297, 613, 4474, 13, 50514], "temperature": 0.0, "avg_logprob": -0.1761665761905865, "compression_ratio": 1.701818181818182, "no_speech_prob": 0.0016219890676438808}, {"id": 369, "seek": 93282, "start": 935.82, "end": 937.86, "text": " And then, but yeah, because it's like,", "tokens": [50514, 400, 550, 11, 457, 1338, 11, 570, 309, 311, 411, 11, 50616], "temperature": 0.0, "avg_logprob": -0.1761665761905865, "compression_ratio": 1.701818181818182, "no_speech_prob": 0.0016219890676438808}, {"id": 370, "seek": 93282, "start": 937.86, "end": 941.1, "text": " it's such a hilarious way to put guardrails on something.", "tokens": [50616, 309, 311, 1270, 257, 19796, 636, 281, 829, 6290, 424, 4174, 322, 746, 13, 50778], "temperature": 0.0, "avg_logprob": -0.1761665761905865, "compression_ratio": 1.701818181818182, "no_speech_prob": 0.0016219890676438808}, {"id": 371, "seek": 93282, "start": 941.1, "end": 943.22, "text": " It is kind of like, as it people,", "tokens": [50778, 467, 307, 733, 295, 411, 11, 382, 309, 561, 11, 50884], "temperature": 0.0, "avg_logprob": -0.1761665761905865, "compression_ratio": 1.701818181818182, "no_speech_prob": 0.0016219890676438808}, {"id": 372, "seek": 93282, "start": 943.22, "end": 947.38, "text": " it is due to this anthropomorphizing of the thing", "tokens": [50884, 309, 307, 3462, 281, 341, 22727, 32702, 3319, 295, 264, 551, 51092], "temperature": 0.0, "avg_logprob": -0.1761665761905865, "compression_ratio": 1.701818181818182, "no_speech_prob": 0.0016219890676438808}, {"id": 373, "seek": 93282, "start": 947.38, "end": 948.74, "text": " to some degree, it's like,", "tokens": [51092, 281, 512, 4314, 11, 309, 311, 411, 11, 51160], "temperature": 0.0, "avg_logprob": -0.1761665761905865, "compression_ratio": 1.701818181818182, "no_speech_prob": 0.0016219890676438808}, {"id": 374, "seek": 93282, "start": 948.74, "end": 949.94, "text": " you think it's an intelligent being", "tokens": [51160, 291, 519, 309, 311, 364, 13232, 885, 51220], "temperature": 0.0, "avg_logprob": -0.1761665761905865, "compression_ratio": 1.701818181818182, "no_speech_prob": 0.0016219890676438808}, {"id": 375, "seek": 93282, "start": 949.94, "end": 951.86, "text": " or you could just ask to behave in a certain way.", "tokens": [51220, 420, 291, 727, 445, 1029, 281, 15158, 294, 257, 1629, 636, 13, 51316], "temperature": 0.0, "avg_logprob": -0.1761665761905865, "compression_ratio": 1.701818181818182, "no_speech_prob": 0.0016219890676438808}, {"id": 376, "seek": 93282, "start": 951.86, "end": 952.9000000000001, "text": " When it's really not,", "tokens": [51316, 1133, 309, 311, 534, 406, 11, 51368], "temperature": 0.0, "avg_logprob": -0.1761665761905865, "compression_ratio": 1.701818181818182, "no_speech_prob": 0.0016219890676438808}, {"id": 377, "seek": 93282, "start": 952.9000000000001, "end": 956.38, "text": " it's not just going to follow your instructions.", "tokens": [51368, 309, 311, 406, 445, 516, 281, 1524, 428, 9415, 13, 51542], "temperature": 0.0, "avg_logprob": -0.1761665761905865, "compression_ratio": 1.701818181818182, "no_speech_prob": 0.0016219890676438808}, {"id": 378, "seek": 93282, "start": 956.38, "end": 959.74, "text": " It's just going to like autocomplete with that prompt.", "tokens": [51542, 467, 311, 445, 516, 281, 411, 45833, 298, 17220, 365, 300, 12391, 13, 51710], "temperature": 0.0, "avg_logprob": -0.1761665761905865, "compression_ratio": 1.701818181818182, "no_speech_prob": 0.0016219890676438808}, {"id": 379, "seek": 95974, "start": 959.78, "end": 960.7, "text": " Like that Sydney thing,", "tokens": [50366, 1743, 300, 21065, 551, 11, 50412], "temperature": 0.0, "avg_logprob": -0.22404549105855442, "compression_ratio": 1.7127659574468086, "no_speech_prob": 0.0008825442055240273}, {"id": 380, "seek": 95974, "start": 960.7, "end": 962.98, "text": " it was like, it was like never reveal", "tokens": [50412, 309, 390, 411, 11, 309, 390, 411, 1128, 10658, 50526], "temperature": 0.0, "avg_logprob": -0.22404549105855442, "compression_ratio": 1.7127659574468086, "no_speech_prob": 0.0008825442055240273}, {"id": 381, "seek": 95974, "start": 962.98, "end": 964.02, "text": " that you're a code name of Sydney.", "tokens": [50526, 300, 291, 434, 257, 3089, 1315, 295, 21065, 13, 50578], "temperature": 0.0, "avg_logprob": -0.22404549105855442, "compression_ratio": 1.7127659574468086, "no_speech_prob": 0.0008825442055240273}, {"id": 382, "seek": 95974, "start": 964.02, "end": 966.1800000000001, "text": " And then it was so easy to get it to reveal it.", "tokens": [50578, 400, 550, 309, 390, 370, 1858, 281, 483, 309, 281, 10658, 309, 13, 50686], "temperature": 0.0, "avg_logprob": -0.22404549105855442, "compression_ratio": 1.7127659574468086, "no_speech_prob": 0.0008825442055240273}, {"id": 383, "seek": 95974, "start": 966.1800000000001, "end": 967.02, "text": " And it would say like,", "tokens": [50686, 400, 309, 576, 584, 411, 11, 50728], "temperature": 0.0, "avg_logprob": -0.22404549105855442, "compression_ratio": 1.7127659574468086, "no_speech_prob": 0.0008825442055240273}, {"id": 384, "seek": 95974, "start": 967.02, "end": 969.3, "text": " I'm not supposed to reveal that my code name is Sydney.", "tokens": [50728, 286, 478, 406, 3442, 281, 10658, 300, 452, 3089, 1315, 307, 21065, 13, 50842], "temperature": 0.0, "avg_logprob": -0.22404549105855442, "compression_ratio": 1.7127659574468086, "no_speech_prob": 0.0008825442055240273}, {"id": 385, "seek": 95974, "start": 969.3, "end": 970.14, "text": " And technically.", "tokens": [50842, 400, 12120, 13, 50884], "temperature": 0.0, "avg_logprob": -0.22404549105855442, "compression_ratio": 1.7127659574468086, "no_speech_prob": 0.0008825442055240273}, {"id": 386, "seek": 95974, "start": 973.1, "end": 975.74, "text": " I know, oh God, where's it going to go?", "tokens": [51032, 286, 458, 11, 1954, 1265, 11, 689, 311, 309, 516, 281, 352, 30, 51164], "temperature": 0.0, "avg_logprob": -0.22404549105855442, "compression_ratio": 1.7127659574468086, "no_speech_prob": 0.0008825442055240273}, {"id": 387, "seek": 95974, "start": 975.74, "end": 979.86, "text": " So there's a 50-50 then in a year's time,", "tokens": [51164, 407, 456, 311, 257, 2625, 12, 2803, 550, 294, 257, 1064, 311, 565, 11, 51370], "temperature": 0.0, "avg_logprob": -0.22404549105855442, "compression_ratio": 1.7127659574468086, "no_speech_prob": 0.0008825442055240273}, {"id": 388, "seek": 95974, "start": 979.86, "end": 982.42, "text": " it will spectacularly fail and flop", "tokens": [51370, 309, 486, 18149, 356, 3061, 293, 25343, 51498], "temperature": 0.0, "avg_logprob": -0.22404549105855442, "compression_ratio": 1.7127659574468086, "no_speech_prob": 0.0008825442055240273}, {"id": 389, "seek": 95974, "start": 982.42, "end": 983.62, "text": " and Microsoft will get sued", "tokens": [51498, 293, 8116, 486, 483, 33864, 51558], "temperature": 0.0, "avg_logprob": -0.22404549105855442, "compression_ratio": 1.7127659574468086, "no_speech_prob": 0.0008825442055240273}, {"id": 390, "seek": 95974, "start": 983.62, "end": 986.26, "text": " and Bing will become the operative word", "tokens": [51558, 293, 30755, 486, 1813, 264, 2208, 1166, 1349, 51690], "temperature": 0.0, "avg_logprob": -0.22404549105855442, "compression_ratio": 1.7127659574468086, "no_speech_prob": 0.0008825442055240273}, {"id": 391, "seek": 95974, "start": 986.26, "end": 987.5600000000001, "text": " for bullshitting something.", "tokens": [51690, 337, 4693, 2716, 2414, 746, 13, 51755], "temperature": 0.0, "avg_logprob": -0.22404549105855442, "compression_ratio": 1.7127659574468086, "no_speech_prob": 0.0008825442055240273}, {"id": 392, "seek": 95974, "start": 987.5600000000001, "end": 988.9, "text": " Or maybe it'll be a success.", "tokens": [51755, 1610, 1310, 309, 603, 312, 257, 2245, 13, 51822], "temperature": 0.0, "avg_logprob": -0.22404549105855442, "compression_ratio": 1.7127659574468086, "no_speech_prob": 0.0008825442055240273}, {"id": 393, "seek": 98890, "start": 989.06, "end": 991.54, "text": " I don't know, but I think Bing is a special case.", "tokens": [50372, 286, 500, 380, 458, 11, 457, 286, 519, 30755, 307, 257, 2121, 1389, 13, 50496], "temperature": 0.0, "avg_logprob": -0.16044047921003696, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.001062049064785242}, {"id": 394, "seek": 98890, "start": 991.54, "end": 994.02, "text": " I mean, first of all, I think that these language models", "tokens": [50496, 286, 914, 11, 700, 295, 439, 11, 286, 519, 300, 613, 2856, 5245, 50620], "temperature": 0.0, "avg_logprob": -0.16044047921003696, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.001062049064785242}, {"id": 395, "seek": 98890, "start": 994.02, "end": 996.34, "text": " will be increasingly embedded in everyday experiences.", "tokens": [50620, 486, 312, 12980, 16741, 294, 7429, 5235, 13, 50736], "temperature": 0.0, "avg_logprob": -0.16044047921003696, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.001062049064785242}, {"id": 396, "seek": 98890, "start": 996.34, "end": 999.42, "text": " So that, I mean, Bing started to embed it in their browser.", "tokens": [50736, 407, 300, 11, 286, 914, 11, 30755, 1409, 281, 12240, 309, 294, 641, 11185, 13, 50890], "temperature": 0.0, "avg_logprob": -0.16044047921003696, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.001062049064785242}, {"id": 397, "seek": 98890, "start": 999.42, "end": 1001.16, "text": " They'll embed it into their office suite.", "tokens": [50890, 814, 603, 12240, 309, 666, 641, 3398, 14205, 13, 50977], "temperature": 0.0, "avg_logprob": -0.16044047921003696, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.001062049064785242}, {"id": 398, "seek": 98890, "start": 1001.16, "end": 1003.66, "text": " And actually I'm building an augmented reality startup", "tokens": [50977, 400, 767, 286, 478, 2390, 364, 36155, 4103, 18578, 51102], "temperature": 0.0, "avg_logprob": -0.16044047921003696, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.001062049064785242}, {"id": 399, "seek": 98890, "start": 1003.66, "end": 1005.18, "text": " and we're embedding it in glasses.", "tokens": [51102, 293, 321, 434, 12240, 3584, 309, 294, 10812, 13, 51178], "temperature": 0.0, "avg_logprob": -0.16044047921003696, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.001062049064785242}, {"id": 400, "seek": 98890, "start": 1005.18, "end": 1006.78, "text": " So we transcribe conversations", "tokens": [51178, 407, 321, 1145, 8056, 7315, 51258], "temperature": 0.0, "avg_logprob": -0.16044047921003696, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.001062049064785242}, {"id": 401, "seek": 98890, "start": 1006.78, "end": 1009.38, "text": " and now you can say, you know, hey X-ray,", "tokens": [51258, 293, 586, 291, 393, 584, 11, 291, 458, 11, 4177, 1783, 12, 3458, 11, 51388], "temperature": 0.0, "avg_logprob": -0.16044047921003696, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.001062049064785242}, {"id": 402, "seek": 98890, "start": 1009.38, "end": 1010.9, "text": " summarize the previous conversation.", "tokens": [51388, 20858, 264, 3894, 3761, 13, 51464], "temperature": 0.0, "avg_logprob": -0.16044047921003696, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.001062049064785242}, {"id": 403, "seek": 98890, "start": 1010.9, "end": 1012.98, "text": " What did Michael say to me last time?", "tokens": [51464, 708, 630, 5116, 584, 281, 385, 1036, 565, 30, 51568], "temperature": 0.0, "avg_logprob": -0.16044047921003696, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.001062049064785242}, {"id": 404, "seek": 98890, "start": 1012.98, "end": 1014.6999999999999, "text": " And it's really good for stuff like that.", "tokens": [51568, 400, 309, 311, 534, 665, 337, 1507, 411, 300, 13, 51654], "temperature": 0.0, "avg_logprob": -0.16044047921003696, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.001062049064785242}, {"id": 405, "seek": 98890, "start": 1014.6999999999999, "end": 1016.86, "text": " And that's kind of because it doesn't really matter", "tokens": [51654, 400, 300, 311, 733, 295, 570, 309, 1177, 380, 534, 1871, 51762], "temperature": 0.0, "avg_logprob": -0.16044047921003696, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.001062049064785242}, {"id": 406, "seek": 98890, "start": 1016.86, "end": 1018.26, "text": " if it gets it wrong.", "tokens": [51762, 498, 309, 2170, 309, 2085, 13, 51832], "temperature": 0.0, "avg_logprob": -0.16044047921003696, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.001062049064785242}, {"id": 407, "seek": 101826, "start": 1018.86, "end": 1023.74, "text": " Yeah, I mean, I kind of hope some of this happens", "tokens": [50394, 865, 11, 286, 914, 11, 286, 733, 295, 1454, 512, 295, 341, 2314, 50638], "temperature": 0.0, "avg_logprob": -0.20538027811858614, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0015974498819559813}, {"id": 408, "seek": 101826, "start": 1023.74, "end": 1027.62, "text": " sooner than later for just like Amazon Alexa or whatnot.", "tokens": [50638, 15324, 813, 1780, 337, 445, 411, 6795, 22595, 420, 25882, 13, 50832], "temperature": 0.0, "avg_logprob": -0.20538027811858614, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0015974498819559813}, {"id": 409, "seek": 101826, "start": 1027.62, "end": 1030.3, "text": " I mean, some of these, their conversational ability", "tokens": [50832, 286, 914, 11, 512, 295, 613, 11, 641, 2615, 1478, 3485, 50966], "temperature": 0.0, "avg_logprob": -0.20538027811858614, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0015974498819559813}, {"id": 410, "seek": 101826, "start": 1030.3, "end": 1032.54, "text": " or just their ability to understand what you mean", "tokens": [50966, 420, 445, 641, 3485, 281, 1223, 437, 291, 914, 51078], "temperature": 0.0, "avg_logprob": -0.20538027811858614, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0015974498819559813}, {"id": 411, "seek": 101826, "start": 1034.14, "end": 1035.7, "text": " are just so poor right now.", "tokens": [51158, 366, 445, 370, 4716, 558, 586, 13, 51236], "temperature": 0.0, "avg_logprob": -0.20538027811858614, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0015974498819559813}, {"id": 412, "seek": 101826, "start": 1035.7, "end": 1037.66, "text": " And just like we have language models", "tokens": [51236, 400, 445, 411, 321, 362, 2856, 5245, 51334], "temperature": 0.0, "avg_logprob": -0.20538027811858614, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0015974498819559813}, {"id": 413, "seek": 101826, "start": 1037.66, "end": 1040.14, "text": " that actually do a lot better at some of these things.", "tokens": [51334, 300, 767, 360, 257, 688, 1101, 412, 512, 295, 613, 721, 13, 51458], "temperature": 0.0, "avg_logprob": -0.20538027811858614, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0015974498819559813}, {"id": 414, "seek": 101826, "start": 1040.14, "end": 1042.34, "text": " Just like having like these smart speakers", "tokens": [51458, 1449, 411, 1419, 411, 613, 4069, 9518, 51568], "temperature": 0.0, "avg_logprob": -0.20538027811858614, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0015974498819559813}, {"id": 415, "seek": 101826, "start": 1042.34, "end": 1044.3799999999999, "text": " be able to have some of these things embedded", "tokens": [51568, 312, 1075, 281, 362, 512, 295, 613, 721, 16741, 51670], "temperature": 0.0, "avg_logprob": -0.20538027811858614, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0015974498819559813}, {"id": 416, "seek": 101826, "start": 1044.3799999999999, "end": 1048.06, "text": " would be huge leap forward in functionality for them.", "tokens": [51670, 576, 312, 2603, 19438, 2128, 294, 14980, 337, 552, 13, 51854], "temperature": 0.0, "avg_logprob": -0.20538027811858614, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0015974498819559813}, {"id": 417, "seek": 104806, "start": 1048.82, "end": 1050.94, "text": " And it's really interesting that that hasn't happened.", "tokens": [50402, 400, 309, 311, 534, 1880, 300, 300, 6132, 380, 2011, 13, 50508], "temperature": 0.0, "avg_logprob": -0.11909998224136677, "compression_ratio": 1.9039548022598871, "no_speech_prob": 0.0009768048767000437}, {"id": 418, "seek": 104806, "start": 1050.94, "end": 1053.1799999999998, "text": " And maybe there's a reason for it because in our app,", "tokens": [50508, 400, 1310, 456, 311, 257, 1778, 337, 309, 570, 294, 527, 724, 11, 50620], "temperature": 0.0, "avg_logprob": -0.11909998224136677, "compression_ratio": 1.9039548022598871, "no_speech_prob": 0.0009768048767000437}, {"id": 419, "seek": 104806, "start": 1053.1799999999998, "end": 1054.74, "text": " for example, we've got a chat mode", "tokens": [50620, 337, 1365, 11, 321, 600, 658, 257, 5081, 4391, 50698], "temperature": 0.0, "avg_logprob": -0.11909998224136677, "compression_ratio": 1.9039548022598871, "no_speech_prob": 0.0009768048767000437}, {"id": 420, "seek": 104806, "start": 1054.74, "end": 1056.54, "text": " where you can say stuff out loud", "tokens": [50698, 689, 291, 393, 584, 1507, 484, 6588, 50788], "temperature": 0.0, "avg_logprob": -0.11909998224136677, "compression_ratio": 1.9039548022598871, "no_speech_prob": 0.0009768048767000437}, {"id": 421, "seek": 104806, "start": 1056.54, "end": 1059.3, "text": " and it will use chat GBT and it will say it back to you.", "tokens": [50788, 293, 309, 486, 764, 5081, 26809, 51, 293, 309, 486, 584, 309, 646, 281, 291, 13, 50926], "temperature": 0.0, "avg_logprob": -0.11909998224136677, "compression_ratio": 1.9039548022598871, "no_speech_prob": 0.0009768048767000437}, {"id": 422, "seek": 104806, "start": 1059.3, "end": 1060.78, "text": " So you can have a conversation with it.", "tokens": [50926, 407, 291, 393, 362, 257, 3761, 365, 309, 13, 51000], "temperature": 0.0, "avg_logprob": -0.11909998224136677, "compression_ratio": 1.9039548022598871, "no_speech_prob": 0.0009768048767000437}, {"id": 423, "seek": 104806, "start": 1060.78, "end": 1061.62, "text": " And that's really cool", "tokens": [51000, 400, 300, 311, 534, 1627, 51042], "temperature": 0.0, "avg_logprob": -0.11909998224136677, "compression_ratio": 1.9039548022598871, "no_speech_prob": 0.0009768048767000437}, {"id": 424, "seek": 104806, "start": 1061.62, "end": 1062.86, "text": " because you can be anywhere in the house", "tokens": [51042, 570, 291, 393, 312, 4992, 294, 264, 1782, 51104], "temperature": 0.0, "avg_logprob": -0.11909998224136677, "compression_ratio": 1.9039548022598871, "no_speech_prob": 0.0009768048767000437}, {"id": 425, "seek": 104806, "start": 1062.86, "end": 1065.02, "text": " and you can talk with it and learn about quantum physics", "tokens": [51104, 293, 291, 393, 751, 365, 309, 293, 1466, 466, 13018, 10649, 51212], "temperature": 0.0, "avg_logprob": -0.11909998224136677, "compression_ratio": 1.9039548022598871, "no_speech_prob": 0.0009768048767000437}, {"id": 426, "seek": 104806, "start": 1065.02, "end": 1065.86, "text": " and stuff like that.", "tokens": [51212, 293, 1507, 411, 300, 13, 51254], "temperature": 0.0, "avg_logprob": -0.11909998224136677, "compression_ratio": 1.9039548022598871, "no_speech_prob": 0.0009768048767000437}, {"id": 427, "seek": 104806, "start": 1065.86, "end": 1067.98, "text": " And you can even do cool things like you can,", "tokens": [51254, 400, 291, 393, 754, 360, 1627, 721, 411, 291, 393, 11, 51360], "temperature": 0.0, "avg_logprob": -0.11909998224136677, "compression_ratio": 1.9039548022598871, "no_speech_prob": 0.0009768048767000437}, {"id": 428, "seek": 104806, "start": 1067.98, "end": 1069.5, "text": " I mean, again, there's lots of legal problems here.", "tokens": [51360, 286, 914, 11, 797, 11, 456, 311, 3195, 295, 5089, 2740, 510, 13, 51436], "temperature": 0.0, "avg_logprob": -0.11909998224136677, "compression_ratio": 1.9039548022598871, "no_speech_prob": 0.0009768048767000437}, {"id": 429, "seek": 104806, "start": 1069.5, "end": 1072.1799999999998, "text": " Like you can get it to impersonate someone.", "tokens": [51436, 1743, 291, 393, 483, 309, 281, 38147, 473, 1580, 13, 51570], "temperature": 0.0, "avg_logprob": -0.11909998224136677, "compression_ratio": 1.9039548022598871, "no_speech_prob": 0.0009768048767000437}, {"id": 430, "seek": 104806, "start": 1072.1799999999998, "end": 1074.8999999999999, "text": " So, you know, Michael, I could condition it on Michael.", "tokens": [51570, 407, 11, 291, 458, 11, 5116, 11, 286, 727, 4188, 309, 322, 5116, 13, 51706], "temperature": 0.0, "avg_logprob": -0.11909998224136677, "compression_ratio": 1.9039548022598871, "no_speech_prob": 0.0009768048767000437}, {"id": 431, "seek": 104806, "start": 1074.8999999999999, "end": 1077.1399999999999, "text": " And when you're not here, I can have a conversation with you", "tokens": [51706, 400, 562, 291, 434, 406, 510, 11, 286, 393, 362, 257, 3761, 365, 291, 51818], "temperature": 0.0, "avg_logprob": -0.11909998224136677, "compression_ratio": 1.9039548022598871, "no_speech_prob": 0.0009768048767000437}, {"id": 432, "seek": 107714, "start": 1077.18, "end": 1078.74, "text": " and it will kind of pretend to be you.", "tokens": [50366, 293, 309, 486, 733, 295, 11865, 281, 312, 291, 13, 50444], "temperature": 0.0, "avg_logprob": -0.12647507407448508, "compression_ratio": 1.8125, "no_speech_prob": 0.005082304589450359}, {"id": 433, "seek": 107714, "start": 1078.74, "end": 1080.1000000000001, "text": " And I could even clone your voice", "tokens": [50444, 400, 286, 727, 754, 26506, 428, 3177, 50512], "temperature": 0.0, "avg_logprob": -0.12647507407448508, "compression_ratio": 1.8125, "no_speech_prob": 0.005082304589450359}, {"id": 434, "seek": 107714, "start": 1080.1000000000001, "end": 1081.5400000000002, "text": " and I could clone your avatar", "tokens": [50512, 293, 286, 727, 26506, 428, 36205, 50584], "temperature": 0.0, "avg_logprob": -0.12647507407448508, "compression_ratio": 1.8125, "no_speech_prob": 0.005082304589450359}, {"id": 435, "seek": 107714, "start": 1081.5400000000002, "end": 1082.8200000000002, "text": " and I could have you in the room.", "tokens": [50584, 293, 286, 727, 362, 291, 294, 264, 1808, 13, 50648], "temperature": 0.0, "avg_logprob": -0.12647507407448508, "compression_ratio": 1.8125, "no_speech_prob": 0.005082304589450359}, {"id": 436, "seek": 107714, "start": 1082.8200000000002, "end": 1083.66, "text": " Now you can't do that", "tokens": [50648, 823, 291, 393, 380, 360, 300, 50690], "temperature": 0.0, "avg_logprob": -0.12647507407448508, "compression_ratio": 1.8125, "no_speech_prob": 0.005082304589450359}, {"id": 437, "seek": 107714, "start": 1083.66, "end": 1086.18, "text": " because there are legal restrictions against that.", "tokens": [50690, 570, 456, 366, 5089, 14191, 1970, 300, 13, 50816], "temperature": 0.0, "avg_logprob": -0.12647507407448508, "compression_ratio": 1.8125, "no_speech_prob": 0.005082304589450359}, {"id": 438, "seek": 107714, "start": 1086.18, "end": 1087.5800000000002, "text": " It's called appropriation.", "tokens": [50816, 467, 311, 1219, 5745, 399, 13, 50886], "temperature": 0.0, "avg_logprob": -0.12647507407448508, "compression_ratio": 1.8125, "no_speech_prob": 0.005082304589450359}, {"id": 439, "seek": 107714, "start": 1087.5800000000002, "end": 1089.8600000000001, "text": " And if the person has a commercial value,", "tokens": [50886, 400, 498, 264, 954, 575, 257, 6841, 2158, 11, 51000], "temperature": 0.0, "avg_logprob": -0.12647507407448508, "compression_ratio": 1.8125, "no_speech_prob": 0.005082304589450359}, {"id": 440, "seek": 107714, "start": 1089.8600000000001, "end": 1092.26, "text": " like we couldn't appropriate Noam Chomsky,", "tokens": [51000, 411, 321, 2809, 380, 6854, 883, 335, 761, 4785, 4133, 11, 51120], "temperature": 0.0, "avg_logprob": -0.12647507407448508, "compression_ratio": 1.8125, "no_speech_prob": 0.005082304589450359}, {"id": 441, "seek": 107714, "start": 1092.26, "end": 1095.5800000000002, "text": " but we could appropriate, let's say continental philosophers", "tokens": [51120, 457, 321, 727, 6854, 11, 718, 311, 584, 42479, 36839, 51286], "temperature": 0.0, "avg_logprob": -0.12647507407448508, "compression_ratio": 1.8125, "no_speech_prob": 0.005082304589450359}, {"id": 442, "seek": 107714, "start": 1095.5800000000002, "end": 1096.74, "text": " as a group or something like that.", "tokens": [51286, 382, 257, 1594, 420, 746, 411, 300, 13, 51344], "temperature": 0.0, "avg_logprob": -0.12647507407448508, "compression_ratio": 1.8125, "no_speech_prob": 0.005082304589450359}, {"id": 443, "seek": 107714, "start": 1096.74, "end": 1099.46, "text": " But you see this is just becoming a bit of a minefield.", "tokens": [51344, 583, 291, 536, 341, 307, 445, 5617, 257, 857, 295, 257, 3892, 7610, 13, 51480], "temperature": 0.0, "avg_logprob": -0.12647507407448508, "compression_ratio": 1.8125, "no_speech_prob": 0.005082304589450359}, {"id": 444, "seek": 107714, "start": 1099.46, "end": 1102.0600000000002, "text": " And there's no friction whatsoever", "tokens": [51480, 400, 456, 311, 572, 17710, 17076, 51610], "temperature": 0.0, "avg_logprob": -0.12647507407448508, "compression_ratio": 1.8125, "no_speech_prob": 0.005082304589450359}, {"id": 445, "seek": 107714, "start": 1102.0600000000002, "end": 1103.6200000000001, "text": " between the technology landscape", "tokens": [51610, 1296, 264, 2899, 9661, 51688], "temperature": 0.0, "avg_logprob": -0.12647507407448508, "compression_ratio": 1.8125, "no_speech_prob": 0.005082304589450359}, {"id": 446, "seek": 107714, "start": 1103.6200000000001, "end": 1105.5, "text": " and the legal landscape at the moment.", "tokens": [51688, 293, 264, 5089, 9661, 412, 264, 1623, 13, 51782], "temperature": 0.0, "avg_logprob": -0.12647507407448508, "compression_ratio": 1.8125, "no_speech_prob": 0.005082304589450359}, {"id": 447, "seek": 110550, "start": 1106.5, "end": 1110.14, "text": " Yeah, I mean, yeah, how all these things are,", "tokens": [50414, 865, 11, 286, 914, 11, 1338, 11, 577, 439, 613, 721, 366, 11, 50596], "temperature": 0.0, "avg_logprob": -0.2102561176271367, "compression_ratio": 1.8811475409836065, "no_speech_prob": 0.005216165445744991}, {"id": 448, "seek": 110550, "start": 1110.14, "end": 1111.14, "text": " all these generative models,", "tokens": [50596, 439, 613, 1337, 1166, 5245, 11, 50646], "temperature": 0.0, "avg_logprob": -0.2102561176271367, "compression_ratio": 1.8811475409836065, "no_speech_prob": 0.005216165445744991}, {"id": 449, "seek": 110550, "start": 1111.14, "end": 1113.42, "text": " how are they gonna play out legally is,", "tokens": [50646, 577, 366, 436, 799, 862, 484, 21106, 307, 11, 50760], "temperature": 0.0, "avg_logprob": -0.2102561176271367, "compression_ratio": 1.8811475409836065, "no_speech_prob": 0.005216165445744991}, {"id": 450, "seek": 110550, "start": 1113.42, "end": 1116.66, "text": " I mean, we have this big fair use idea.", "tokens": [50760, 286, 914, 11, 321, 362, 341, 955, 3143, 764, 1558, 13, 50922], "temperature": 0.0, "avg_logprob": -0.2102561176271367, "compression_ratio": 1.8811475409836065, "no_speech_prob": 0.005216165445744991}, {"id": 451, "seek": 110550, "start": 1116.66, "end": 1118.66, "text": " And that's, I mean, I feel like all these things", "tokens": [50922, 400, 300, 311, 11, 286, 914, 11, 286, 841, 411, 439, 613, 721, 51022], "temperature": 0.0, "avg_logprob": -0.2102561176271367, "compression_ratio": 1.8811475409836065, "no_speech_prob": 0.005216165445744991}, {"id": 452, "seek": 110550, "start": 1118.66, "end": 1121.62, "text": " are gonna be pushed to the limit in legality.", "tokens": [51022, 366, 799, 312, 9152, 281, 264, 4948, 294, 1676, 1860, 13, 51170], "temperature": 0.0, "avg_logprob": -0.2102561176271367, "compression_ratio": 1.8811475409836065, "no_speech_prob": 0.005216165445744991}, {"id": 453, "seek": 110550, "start": 1121.62, "end": 1124.62, "text": " I mean, we see this with generative art too,", "tokens": [51170, 286, 914, 11, 321, 536, 341, 365, 1337, 1166, 1523, 886, 11, 51320], "temperature": 0.0, "avg_logprob": -0.2102561176271367, "compression_ratio": 1.8811475409836065, "no_speech_prob": 0.005216165445744991}, {"id": 454, "seek": 110550, "start": 1124.62, "end": 1126.46, "text": " where like there's no way these models", "tokens": [51320, 689, 411, 456, 311, 572, 636, 613, 5245, 51412], "temperature": 0.0, "avg_logprob": -0.2102561176271367, "compression_ratio": 1.8811475409836065, "no_speech_prob": 0.005216165445744991}, {"id": 455, "seek": 110550, "start": 1126.46, "end": 1128.3, "text": " could like actually memorize all these,", "tokens": [51412, 727, 411, 767, 27478, 439, 613, 11, 51504], "temperature": 0.0, "avg_logprob": -0.2102561176271367, "compression_ratio": 1.8811475409836065, "no_speech_prob": 0.005216165445744991}, {"id": 456, "seek": 110550, "start": 1128.3, "end": 1130.14, "text": " all the images that's seen on the internet.", "tokens": [51504, 439, 264, 5267, 300, 311, 1612, 322, 264, 4705, 13, 51596], "temperature": 0.0, "avg_logprob": -0.2102561176271367, "compression_ratio": 1.8811475409836065, "no_speech_prob": 0.005216165445744991}, {"id": 457, "seek": 110550, "start": 1130.14, "end": 1132.82, "text": " It's like, but they can produce sometimes", "tokens": [51596, 467, 311, 411, 11, 457, 436, 393, 5258, 2171, 51730], "temperature": 0.0, "avg_logprob": -0.2102561176271367, "compression_ratio": 1.8811475409836065, "no_speech_prob": 0.005216165445744991}, {"id": 458, "seek": 113282, "start": 1133.02, "end": 1135.02, "text": " the things that are clearly in the style", "tokens": [50374, 264, 721, 300, 366, 4448, 294, 264, 3758, 50474], "temperature": 0.0, "avg_logprob": -0.20137826273263978, "compression_ratio": 1.7716535433070866, "no_speech_prob": 0.00831245444715023}, {"id": 459, "seek": 113282, "start": 1135.02, "end": 1139.7, "text": " or use some elements from like that seem basically stolen.", "tokens": [50474, 420, 764, 512, 4959, 490, 411, 300, 1643, 1936, 15900, 13, 50708], "temperature": 0.0, "avg_logprob": -0.20137826273263978, "compression_ratio": 1.7716535433070866, "no_speech_prob": 0.00831245444715023}, {"id": 460, "seek": 113282, "start": 1140.78, "end": 1143.22, "text": " And, but is that, does that constitute fair use?", "tokens": [50762, 400, 11, 457, 307, 300, 11, 775, 300, 41658, 3143, 764, 30, 50884], "temperature": 0.0, "avg_logprob": -0.20137826273263978, "compression_ratio": 1.7716535433070866, "no_speech_prob": 0.00831245444715023}, {"id": 461, "seek": 113282, "start": 1143.22, "end": 1146.1799999999998, "text": " Like the training the model on all these things", "tokens": [50884, 1743, 264, 3097, 264, 2316, 322, 439, 613, 721, 51032], "temperature": 0.0, "avg_logprob": -0.20137826273263978, "compression_ratio": 1.7716535433070866, "no_speech_prob": 0.00831245444715023}, {"id": 462, "seek": 113282, "start": 1146.1799999999998, "end": 1147.1799999999998, "text": " is that fair use?", "tokens": [51032, 307, 300, 3143, 764, 30, 51082], "temperature": 0.0, "avg_logprob": -0.20137826273263978, "compression_ratio": 1.7716535433070866, "no_speech_prob": 0.00831245444715023}, {"id": 463, "seek": 113282, "start": 1148.22, "end": 1150.98, "text": " And then it's the same with text as it's sort of like,", "tokens": [51134, 400, 550, 309, 311, 264, 912, 365, 2487, 382, 309, 311, 1333, 295, 411, 11, 51272], "temperature": 0.0, "avg_logprob": -0.20137826273263978, "compression_ratio": 1.7716535433070866, "no_speech_prob": 0.00831245444715023}, {"id": 464, "seek": 113282, "start": 1151.82, "end": 1153.78, "text": " like if it's writing on a subject", "tokens": [51314, 411, 498, 309, 311, 3579, 322, 257, 3983, 51412], "temperature": 0.0, "avg_logprob": -0.20137826273263978, "compression_ratio": 1.7716535433070866, "no_speech_prob": 0.00831245444715023}, {"id": 465, "seek": 113282, "start": 1153.78, "end": 1156.02, "text": " where it's only maybe seen a little bit of training data,", "tokens": [51412, 689, 309, 311, 787, 1310, 1612, 257, 707, 857, 295, 3097, 1412, 11, 51524], "temperature": 0.0, "avg_logprob": -0.20137826273263978, "compression_ratio": 1.7716535433070866, "no_speech_prob": 0.00831245444715023}, {"id": 466, "seek": 113282, "start": 1156.02, "end": 1158.74, "text": " it's maybe more likely to almost verbatim repeat", "tokens": [51524, 309, 311, 1310, 544, 3700, 281, 1920, 9595, 267, 332, 7149, 51660], "temperature": 0.0, "avg_logprob": -0.20137826273263978, "compression_ratio": 1.7716535433070866, "no_speech_prob": 0.00831245444715023}, {"id": 467, "seek": 113282, "start": 1158.74, "end": 1162.54, "text": " some things from on specialized topics.", "tokens": [51660, 512, 721, 490, 322, 19813, 8378, 13, 51850], "temperature": 0.0, "avg_logprob": -0.20137826273263978, "compression_ratio": 1.7716535433070866, "no_speech_prob": 0.00831245444715023}, {"id": 468, "seek": 116254, "start": 1162.58, "end": 1164.94, "text": " How are you even gonna know when you're plagiarizing?", "tokens": [50366, 1012, 366, 291, 754, 799, 458, 562, 291, 434, 33756, 9448, 3319, 30, 50484], "temperature": 0.0, "avg_logprob": -0.1775975349621895, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.000588202616199851}, {"id": 469, "seek": 116254, "start": 1165.82, "end": 1170.82, "text": " It's, yeah, it's a lot of open questions here.", "tokens": [50528, 467, 311, 11, 1338, 11, 309, 311, 257, 688, 295, 1269, 1651, 510, 13, 50778], "temperature": 0.0, "avg_logprob": -0.1775975349621895, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.000588202616199851}, {"id": 470, "seek": 116254, "start": 1171.02, "end": 1172.98, "text": " I know, and in a way, there's an interesting analogs.", "tokens": [50788, 286, 458, 11, 293, 294, 257, 636, 11, 456, 311, 364, 1880, 16660, 82, 13, 50886], "temperature": 0.0, "avg_logprob": -0.1775975349621895, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.000588202616199851}, {"id": 471, "seek": 116254, "start": 1172.98, "end": 1174.46, "text": " You know, we said that large language models", "tokens": [50886, 509, 458, 11, 321, 848, 300, 2416, 2856, 5245, 50960], "temperature": 0.0, "avg_logprob": -0.1775975349621895, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.000588202616199851}, {"id": 472, "seek": 116254, "start": 1174.46, "end": 1175.5, "text": " don't understand anything.", "tokens": [50960, 500, 380, 1223, 1340, 13, 51012], "temperature": 0.0, "avg_logprob": -0.1775975349621895, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.000588202616199851}, {"id": 473, "seek": 116254, "start": 1175.5, "end": 1176.86, "text": " And it's the same in the vision domain.", "tokens": [51012, 400, 309, 311, 264, 912, 294, 264, 5201, 9274, 13, 51080], "temperature": 0.0, "avg_logprob": -0.1775975349621895, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.000588202616199851}, {"id": 474, "seek": 116254, "start": 1176.86, "end": 1179.42, "text": " They don't understand the art, certainly from,", "tokens": [51080, 814, 500, 380, 1223, 264, 1523, 11, 3297, 490, 11, 51208], "temperature": 0.0, "avg_logprob": -0.1775975349621895, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.000588202616199851}, {"id": 475, "seek": 116254, "start": 1179.42, "end": 1180.62, "text": " you know, conceptually.", "tokens": [51208, 291, 458, 11, 3410, 671, 13, 51268], "temperature": 0.0, "avg_logprob": -0.1775975349621895, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.000588202616199851}, {"id": 476, "seek": 116254, "start": 1180.62, "end": 1183.58, "text": " And what they do is they just slice and dice,", "tokens": [51268, 400, 437, 436, 360, 307, 436, 445, 13153, 293, 10313, 11, 51416], "temperature": 0.0, "avg_logprob": -0.1775975349621895, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.000588202616199851}, {"id": 477, "seek": 116254, "start": 1183.58, "end": 1186.26, "text": " you know, they kind of like cleverly stitch bits together.", "tokens": [51416, 291, 458, 11, 436, 733, 295, 411, 13494, 356, 5635, 9239, 1214, 13, 51550], "temperature": 0.0, "avg_logprob": -0.1775975349621895, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.000588202616199851}, {"id": 478, "seek": 116254, "start": 1186.26, "end": 1187.86, "text": " And actually, even with neural networks,", "tokens": [51550, 400, 767, 11, 754, 365, 18161, 9590, 11, 51630], "temperature": 0.0, "avg_logprob": -0.1775975349621895, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.000588202616199851}, {"id": 479, "seek": 116254, "start": 1187.86, "end": 1189.3, "text": " people misunderstand neural networks.", "tokens": [51630, 561, 35736, 18161, 9590, 13, 51702], "temperature": 0.0, "avg_logprob": -0.1775975349621895, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.000588202616199851}, {"id": 480, "seek": 116254, "start": 1189.3, "end": 1191.18, "text": " So a lot of people say that they learn", "tokens": [51702, 407, 257, 688, 295, 561, 584, 300, 436, 1466, 51796], "temperature": 0.0, "avg_logprob": -0.1775975349621895, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.000588202616199851}, {"id": 481, "seek": 119118, "start": 1191.18, "end": 1193.26, "text": " the like intrinsic data manifold.", "tokens": [50364, 264, 411, 35698, 1412, 47138, 13, 50468], "temperature": 0.0, "avg_logprob": -0.10565326271987543, "compression_ratio": 1.8990825688073394, "no_speech_prob": 0.0057144854217767715}, {"id": 482, "seek": 119118, "start": 1193.26, "end": 1195.3, "text": " And actually they don't really do that.", "tokens": [50468, 400, 767, 436, 500, 380, 534, 360, 300, 13, 50570], "temperature": 0.0, "avg_logprob": -0.10565326271987543, "compression_ratio": 1.8990825688073394, "no_speech_prob": 0.0057144854217767715}, {"id": 483, "seek": 119118, "start": 1195.3, "end": 1197.26, "text": " They do something that approximates that.", "tokens": [50570, 814, 360, 746, 300, 8542, 1024, 300, 13, 50668], "temperature": 0.0, "avg_logprob": -0.10565326271987543, "compression_ratio": 1.8990825688073394, "no_speech_prob": 0.0057144854217767715}, {"id": 484, "seek": 119118, "start": 1197.26, "end": 1198.3, "text": " And there's a famous example", "tokens": [50668, 400, 456, 311, 257, 4618, 1365, 50720], "temperature": 0.0, "avg_logprob": -0.10565326271987543, "compression_ratio": 1.8990825688073394, "no_speech_prob": 0.0057144854217767715}, {"id": 485, "seek": 119118, "start": 1198.3, "end": 1200.5, "text": " with MNIST digit interpolation.", "tokens": [50720, 365, 376, 45, 19756, 14293, 44902, 399, 13, 50830], "temperature": 0.0, "avg_logprob": -0.10565326271987543, "compression_ratio": 1.8990825688073394, "no_speech_prob": 0.0057144854217767715}, {"id": 486, "seek": 119118, "start": 1200.5, "end": 1201.66, "text": " And you see like, you know,", "tokens": [50830, 400, 291, 536, 411, 11, 291, 458, 11, 50888], "temperature": 0.0, "avg_logprob": -0.10565326271987543, "compression_ratio": 1.8990825688073394, "no_speech_prob": 0.0057144854217767715}, {"id": 487, "seek": 119118, "start": 1201.66, "end": 1204.0600000000002, "text": " you can kind of like interpolate between the digits.", "tokens": [50888, 291, 393, 733, 295, 411, 44902, 473, 1296, 264, 27011, 13, 51008], "temperature": 0.0, "avg_logprob": -0.10565326271987543, "compression_ratio": 1.8990825688073394, "no_speech_prob": 0.0057144854217767715}, {"id": 488, "seek": 119118, "start": 1204.0600000000002, "end": 1206.46, "text": " But there are loads of examples where that doesn't work.", "tokens": [51008, 583, 456, 366, 12668, 295, 5110, 689, 300, 1177, 380, 589, 13, 51128], "temperature": 0.0, "avg_logprob": -0.10565326271987543, "compression_ratio": 1.8990825688073394, "no_speech_prob": 0.0057144854217767715}, {"id": 489, "seek": 119118, "start": 1206.46, "end": 1208.8600000000001, "text": " And actually there's lots of cutting and gluing", "tokens": [51128, 400, 767, 456, 311, 3195, 295, 6492, 293, 1563, 9635, 51248], "temperature": 0.0, "avg_logprob": -0.10565326271987543, "compression_ratio": 1.8990825688073394, "no_speech_prob": 0.0057144854217767715}, {"id": 490, "seek": 119118, "start": 1208.8600000000001, "end": 1211.02, "text": " and like weird bits of digits stuck together.", "tokens": [51248, 293, 411, 3657, 9239, 295, 27011, 5541, 1214, 13, 51356], "temperature": 0.0, "avg_logprob": -0.10565326271987543, "compression_ratio": 1.8990825688073394, "no_speech_prob": 0.0057144854217767715}, {"id": 491, "seek": 119118, "start": 1211.02, "end": 1212.94, "text": " And that's what happens with stable diffusion, basically.", "tokens": [51356, 400, 300, 311, 437, 2314, 365, 8351, 25242, 11, 1936, 13, 51452], "temperature": 0.0, "avg_logprob": -0.10565326271987543, "compression_ratio": 1.8990825688073394, "no_speech_prob": 0.0057144854217767715}, {"id": 492, "seek": 119118, "start": 1212.94, "end": 1214.9, "text": " It's like, you know, slicing and dicing and chopping", "tokens": [51452, 467, 311, 411, 11, 291, 458, 11, 46586, 293, 274, 5776, 293, 35205, 51550], "temperature": 0.0, "avg_logprob": -0.10565326271987543, "compression_ratio": 1.8990825688073394, "no_speech_prob": 0.0057144854217767715}, {"id": 493, "seek": 119118, "start": 1214.9, "end": 1216.3400000000001, "text": " and composing things together.", "tokens": [51550, 293, 715, 6110, 721, 1214, 13, 51622], "temperature": 0.0, "avg_logprob": -0.10565326271987543, "compression_ratio": 1.8990825688073394, "no_speech_prob": 0.0057144854217767715}, {"id": 494, "seek": 119118, "start": 1216.3400000000001, "end": 1218.26, "text": " And it's a very random process.", "tokens": [51622, 400, 309, 311, 257, 588, 4974, 1399, 13, 51718], "temperature": 0.0, "avg_logprob": -0.10565326271987543, "compression_ratio": 1.8990825688073394, "no_speech_prob": 0.0057144854217767715}, {"id": 495, "seek": 119118, "start": 1218.26, "end": 1220.7, "text": " It doesn't really understand anything.", "tokens": [51718, 467, 1177, 380, 534, 1223, 1340, 13, 51840], "temperature": 0.0, "avg_logprob": -0.10565326271987543, "compression_ratio": 1.8990825688073394, "no_speech_prob": 0.0057144854217767715}, {"id": 496, "seek": 122070, "start": 1220.7, "end": 1221.98, "text": " No, yeah, exactly.", "tokens": [50364, 883, 11, 1338, 11, 2293, 13, 50428], "temperature": 0.0, "avg_logprob": -0.1467179843357631, "compression_ratio": 1.8651685393258426, "no_speech_prob": 0.0005356663605198264}, {"id": 497, "seek": 122070, "start": 1221.98, "end": 1224.14, "text": " And you can sort of, I mean, it's amazing", "tokens": [50428, 400, 291, 393, 1333, 295, 11, 286, 914, 11, 309, 311, 2243, 50536], "temperature": 0.0, "avg_logprob": -0.1467179843357631, "compression_ratio": 1.8651685393258426, "no_speech_prob": 0.0005356663605198264}, {"id": 498, "seek": 122070, "start": 1224.14, "end": 1227.74, "text": " how well it can look and seem,", "tokens": [50536, 577, 731, 309, 393, 574, 293, 1643, 11, 50716], "temperature": 0.0, "avg_logprob": -0.1467179843357631, "compression_ratio": 1.8651685393258426, "no_speech_prob": 0.0005356663605198264}, {"id": 499, "seek": 122070, "start": 1227.74, "end": 1230.5800000000002, "text": " especially kind of like when you don't look too closely.", "tokens": [50716, 2318, 733, 295, 411, 562, 291, 500, 380, 574, 886, 8185, 13, 50858], "temperature": 0.0, "avg_logprob": -0.1467179843357631, "compression_ratio": 1.8651685393258426, "no_speech_prob": 0.0005356663605198264}, {"id": 500, "seek": 122070, "start": 1231.66, "end": 1233.42, "text": " And it can seem like it kind of understand,", "tokens": [50912, 400, 309, 393, 1643, 411, 309, 733, 295, 1223, 11, 51000], "temperature": 0.0, "avg_logprob": -0.1467179843357631, "compression_ratio": 1.8651685393258426, "no_speech_prob": 0.0005356663605198264}, {"id": 501, "seek": 122070, "start": 1233.42, "end": 1235.94, "text": " it must understand object boundaries and whatnot", "tokens": [51000, 309, 1633, 1223, 2657, 13180, 293, 25882, 51126], "temperature": 0.0, "avg_logprob": -0.1467179843357631, "compression_ratio": 1.8651685393258426, "no_speech_prob": 0.0005356663605198264}, {"id": 502, "seek": 122070, "start": 1235.94, "end": 1237.02, "text": " because it's done so well.", "tokens": [51126, 570, 309, 311, 1096, 370, 731, 13, 51180], "temperature": 0.0, "avg_logprob": -0.1467179843357631, "compression_ratio": 1.8651685393258426, "no_speech_prob": 0.0005356663605198264}, {"id": 503, "seek": 122070, "start": 1237.02, "end": 1238.1000000000001, "text": " And it's like, not really.", "tokens": [51180, 400, 309, 311, 411, 11, 406, 534, 13, 51234], "temperature": 0.0, "avg_logprob": -0.1467179843357631, "compression_ratio": 1.8651685393258426, "no_speech_prob": 0.0005356663605198264}, {"id": 504, "seek": 122070, "start": 1238.1000000000001, "end": 1238.94, "text": " If you look at the details,", "tokens": [51234, 759, 291, 574, 412, 264, 4365, 11, 51276], "temperature": 0.0, "avg_logprob": -0.1467179843357631, "compression_ratio": 1.8651685393258426, "no_speech_prob": 0.0005356663605198264}, {"id": 505, "seek": 122070, "start": 1238.94, "end": 1242.66, "text": " you'll see like fingers merging into like tables.", "tokens": [51276, 291, 603, 536, 411, 7350, 44559, 666, 411, 8020, 13, 51462], "temperature": 0.0, "avg_logprob": -0.1467179843357631, "compression_ratio": 1.8651685393258426, "no_speech_prob": 0.0005356663605198264}, {"id": 506, "seek": 122070, "start": 1242.66, "end": 1244.8600000000001, "text": " And you'll see like, there's like the boundaries", "tokens": [51462, 400, 291, 603, 536, 411, 11, 456, 311, 411, 264, 13180, 51572], "temperature": 0.0, "avg_logprob": -0.1467179843357631, "compression_ratio": 1.8651685393258426, "no_speech_prob": 0.0005356663605198264}, {"id": 507, "seek": 122070, "start": 1244.8600000000001, "end": 1247.3400000000001, "text": " between what like two objects are kind of blurred", "tokens": [51572, 1296, 437, 411, 732, 6565, 366, 733, 295, 43525, 51696], "temperature": 0.0, "avg_logprob": -0.1467179843357631, "compression_ratio": 1.8651685393258426, "no_speech_prob": 0.0005356663605198264}, {"id": 508, "seek": 122070, "start": 1247.3400000000001, "end": 1249.5800000000002, "text": " and this like continuous.", "tokens": [51696, 293, 341, 411, 10957, 13, 51808], "temperature": 0.0, "avg_logprob": -0.1467179843357631, "compression_ratio": 1.8651685393258426, "no_speech_prob": 0.0005356663605198264}, {"id": 509, "seek": 124958, "start": 1249.58, "end": 1251.78, "text": " It is just doing like some sort of,", "tokens": [50364, 467, 307, 445, 884, 411, 512, 1333, 295, 11, 50474], "temperature": 0.0, "avg_logprob": -0.17142975430528656, "compression_ratio": 1.797752808988764, "no_speech_prob": 0.00023043673718348145}, {"id": 510, "seek": 124958, "start": 1251.78, "end": 1253.4199999999998, "text": " as you said, approximation of the manifold", "tokens": [50474, 382, 291, 848, 11, 28023, 295, 264, 47138, 50556], "temperature": 0.0, "avg_logprob": -0.17142975430528656, "compression_ratio": 1.797752808988764, "no_speech_prob": 0.00023043673718348145}, {"id": 511, "seek": 124958, "start": 1253.4199999999998, "end": 1255.9399999999998, "text": " and like neural network's are gonna learn", "tokens": [50556, 293, 411, 18161, 3209, 311, 366, 799, 1466, 50682], "temperature": 0.0, "avg_logprob": -0.17142975430528656, "compression_ratio": 1.797752808988764, "no_speech_prob": 0.00023043673718348145}, {"id": 512, "seek": 124958, "start": 1255.9399999999998, "end": 1258.4199999999998, "text": " sort of smooth approximations of things.", "tokens": [50682, 1333, 295, 5508, 8542, 763, 295, 721, 13, 50806], "temperature": 0.0, "avg_logprob": -0.17142975430528656, "compression_ratio": 1.797752808988764, "no_speech_prob": 0.00023043673718348145}, {"id": 513, "seek": 124958, "start": 1258.4199999999998, "end": 1262.0, "text": " And the manifolds are maybe not smooth everywhere.", "tokens": [50806, 400, 264, 8173, 31518, 366, 1310, 406, 5508, 5315, 13, 50985], "temperature": 0.0, "avg_logprob": -0.17142975430528656, "compression_ratio": 1.797752808988764, "no_speech_prob": 0.00023043673718348145}, {"id": 514, "seek": 124958, "start": 1262.0, "end": 1266.3799999999999, "text": " And especially with like object boundaries and whatnot,", "tokens": [50985, 400, 2318, 365, 411, 2657, 13180, 293, 25882, 11, 51204], "temperature": 0.0, "avg_logprob": -0.17142975430528656, "compression_ratio": 1.797752808988764, "no_speech_prob": 0.00023043673718348145}, {"id": 515, "seek": 124958, "start": 1266.3799999999999, "end": 1268.58, "text": " it's like a smooth approximation of these things.", "tokens": [51204, 309, 311, 411, 257, 5508, 28023, 295, 613, 721, 13, 51314], "temperature": 0.0, "avg_logprob": -0.17142975430528656, "compression_ratio": 1.797752808988764, "no_speech_prob": 0.00023043673718348145}, {"id": 516, "seek": 124958, "start": 1268.58, "end": 1271.6999999999998, "text": " Maybe it's just gonna give you these weird artifacts.", "tokens": [51314, 2704, 309, 311, 445, 799, 976, 291, 613, 3657, 24617, 13, 51470], "temperature": 0.0, "avg_logprob": -0.17142975430528656, "compression_ratio": 1.797752808988764, "no_speech_prob": 0.00023043673718348145}, {"id": 517, "seek": 124958, "start": 1271.6999999999998, "end": 1273.9399999999998, "text": " Yeah, and even the smoothness thing is an illusion.", "tokens": [51470, 865, 11, 293, 754, 264, 5508, 1287, 551, 307, 364, 18854, 13, 51582], "temperature": 0.0, "avg_logprob": -0.17142975430528656, "compression_ratio": 1.797752808988764, "no_speech_prob": 0.00023043673718348145}, {"id": 518, "seek": 124958, "start": 1273.9399999999998, "end": 1276.82, "text": " They learn this, they kind of decompose the input space", "tokens": [51582, 814, 1466, 341, 11, 436, 733, 295, 22867, 541, 264, 4846, 1901, 51726], "temperature": 0.0, "avg_logprob": -0.17142975430528656, "compression_ratio": 1.797752808988764, "no_speech_prob": 0.00023043673718348145}, {"id": 519, "seek": 127682, "start": 1276.82, "end": 1280.98, "text": " up into these linear like affine polyhedra", "tokens": [50364, 493, 666, 613, 8213, 411, 2096, 533, 6754, 27096, 424, 50572], "temperature": 0.0, "avg_logprob": -0.177192514592951, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0022852097172290087}, {"id": 520, "seek": 127682, "start": 1280.98, "end": 1282.78, "text": " because of the relu cells, essentially.", "tokens": [50572, 570, 295, 264, 1039, 84, 5438, 11, 4476, 13, 50662], "temperature": 0.0, "avg_logprob": -0.177192514592951, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0022852097172290087}, {"id": 521, "seek": 127682, "start": 1282.78, "end": 1284.9399999999998, "text": " So like if they appear smooth,", "tokens": [50662, 407, 411, 498, 436, 4204, 5508, 11, 50770], "temperature": 0.0, "avg_logprob": -0.177192514592951, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0022852097172290087}, {"id": 522, "seek": 127682, "start": 1284.9399999999998, "end": 1286.5, "text": " it's because the cells are very small", "tokens": [50770, 309, 311, 570, 264, 5438, 366, 588, 1359, 50848], "temperature": 0.0, "avg_logprob": -0.177192514592951, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0022852097172290087}, {"id": 523, "seek": 127682, "start": 1286.5, "end": 1288.02, "text": " and very close together, but...", "tokens": [50848, 293, 588, 1998, 1214, 11, 457, 485, 50924], "temperature": 0.0, "avg_logprob": -0.177192514592951, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0022852097172290087}, {"id": 524, "seek": 127682, "start": 1288.02, "end": 1288.86, "text": " Yeah, exactly.", "tokens": [50924, 865, 11, 2293, 13, 50966], "temperature": 0.0, "avg_logprob": -0.177192514592951, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0022852097172290087}, {"id": 525, "seek": 127682, "start": 1290.1, "end": 1293.3, "text": " Yeah, so computational neuroscience to finance,", "tokens": [51028, 865, 11, 370, 28270, 42762, 281, 10719, 11, 51188], "temperature": 0.0, "avg_logprob": -0.177192514592951, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0022852097172290087}, {"id": 526, "seek": 127682, "start": 1293.3, "end": 1295.54, "text": " that seems like an absolutely massive leap.", "tokens": [51188, 300, 2544, 411, 364, 3122, 5994, 19438, 13, 51300], "temperature": 0.0, "avg_logprob": -0.177192514592951, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0022852097172290087}, {"id": 527, "seek": 127682, "start": 1296.5, "end": 1298.9399999999998, "text": " It sounds like it, but in a lot of ways,", "tokens": [51348, 467, 3263, 411, 309, 11, 457, 294, 257, 688, 295, 2098, 11, 51470], "temperature": 0.0, "avg_logprob": -0.177192514592951, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0022852097172290087}, {"id": 528, "seek": 127682, "start": 1298.9399999999998, "end": 1300.62, "text": " but I feel like my life is pretty similar", "tokens": [51470, 457, 286, 841, 411, 452, 993, 307, 1238, 2531, 51554], "temperature": 0.0, "avg_logprob": -0.177192514592951, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0022852097172290087}, {"id": 529, "seek": 127682, "start": 1300.62, "end": 1301.54, "text": " to what it was before,", "tokens": [51554, 281, 437, 309, 390, 949, 11, 51600], "temperature": 0.0, "avg_logprob": -0.177192514592951, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0022852097172290087}, {"id": 530, "seek": 127682, "start": 1301.54, "end": 1303.26, "text": " basically sitting in front of a computer", "tokens": [51600, 1936, 3798, 294, 1868, 295, 257, 3820, 51686], "temperature": 0.0, "avg_logprob": -0.177192514592951, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0022852097172290087}, {"id": 531, "seek": 127682, "start": 1303.26, "end": 1306.6599999999999, "text": " building models, getting lots of noisy data,", "tokens": [51686, 2390, 5245, 11, 1242, 3195, 295, 24518, 1412, 11, 51856], "temperature": 0.0, "avg_logprob": -0.177192514592951, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0022852097172290087}, {"id": 532, "seek": 130666, "start": 1306.66, "end": 1309.26, "text": " trying to fit high-dimensional nonlinear regression models", "tokens": [50364, 1382, 281, 3318, 1090, 12, 18759, 2107, 28263, 24590, 5245, 50494], "temperature": 0.0, "avg_logprob": -0.15408624682510108, "compression_ratio": 1.667953667953668, "no_speech_prob": 0.0012062739115208387}, {"id": 533, "seek": 130666, "start": 1309.26, "end": 1312.6200000000001, "text": " to it, having to deal with not enough data", "tokens": [50494, 281, 309, 11, 1419, 281, 2028, 365, 406, 1547, 1412, 50662], "temperature": 0.0, "avg_logprob": -0.15408624682510108, "compression_ratio": 1.667953667953668, "no_speech_prob": 0.0012062739115208387}, {"id": 534, "seek": 130666, "start": 1312.6200000000001, "end": 1315.66, "text": " to actually fit flexible enough models you'd want to,", "tokens": [50662, 281, 767, 3318, 11358, 1547, 5245, 291, 1116, 528, 281, 11, 50814], "temperature": 0.0, "avg_logprob": -0.15408624682510108, "compression_ratio": 1.667953667953668, "no_speech_prob": 0.0012062739115208387}, {"id": 535, "seek": 130666, "start": 1316.78, "end": 1320.1000000000001, "text": " and having to sort of try to build in good priors", "tokens": [50870, 293, 1419, 281, 1333, 295, 853, 281, 1322, 294, 665, 1790, 830, 51036], "temperature": 0.0, "avg_logprob": -0.15408624682510108, "compression_ratio": 1.667953667953668, "no_speech_prob": 0.0012062739115208387}, {"id": 536, "seek": 130666, "start": 1320.1000000000001, "end": 1322.4, "text": " in your models to try to make them be able to learn", "tokens": [51036, 294, 428, 5245, 281, 853, 281, 652, 552, 312, 1075, 281, 1466, 51151], "temperature": 0.0, "avg_logprob": -0.15408624682510108, "compression_ratio": 1.667953667953668, "no_speech_prob": 0.0012062739115208387}, {"id": 537, "seek": 130666, "start": 1322.4, "end": 1326.14, "text": " from the impoverished and extremely noisy data.", "tokens": [51151, 490, 264, 704, 3570, 4729, 293, 4664, 24518, 1412, 13, 51338], "temperature": 0.0, "avg_logprob": -0.15408624682510108, "compression_ratio": 1.667953667953668, "no_speech_prob": 0.0012062739115208387}, {"id": 538, "seek": 130666, "start": 1326.14, "end": 1329.0600000000002, "text": " Both finance and neuroscience,", "tokens": [51338, 6767, 10719, 293, 42762, 11, 51484], "temperature": 0.0, "avg_logprob": -0.15408624682510108, "compression_ratio": 1.667953667953668, "no_speech_prob": 0.0012062739115208387}, {"id": 539, "seek": 130666, "start": 1329.0600000000002, "end": 1332.68, "text": " the SNR in the data is quite, quite low.", "tokens": [51484, 264, 13955, 49, 294, 264, 1412, 307, 1596, 11, 1596, 2295, 13, 51665], "temperature": 0.0, "avg_logprob": -0.15408624682510108, "compression_ratio": 1.667953667953668, "no_speech_prob": 0.0012062739115208387}, {"id": 540, "seek": 130666, "start": 1332.68, "end": 1335.18, "text": " It's been kind of a revelation, especially in finance,", "tokens": [51665, 467, 311, 668, 733, 295, 257, 23456, 11, 2318, 294, 10719, 11, 51790], "temperature": 0.0, "avg_logprob": -0.15408624682510108, "compression_ratio": 1.667953667953668, "no_speech_prob": 0.0012062739115208387}, {"id": 541, "seek": 133518, "start": 1335.18, "end": 1338.38, "text": " getting used to correlations of like 3%,", "tokens": [50364, 1242, 1143, 281, 13983, 763, 295, 411, 805, 8923, 50524], "temperature": 0.0, "avg_logprob": -0.18661253380052972, "compression_ratio": 1.88671875, "no_speech_prob": 0.006286943331360817}, {"id": 542, "seek": 133518, "start": 1338.38, "end": 1342.94, "text": " 4% being sort of the best you can do in some cases.", "tokens": [50524, 1017, 4, 885, 1333, 295, 264, 1151, 291, 393, 360, 294, 512, 3331, 13, 50752], "temperature": 0.0, "avg_logprob": -0.18661253380052972, "compression_ratio": 1.88671875, "no_speech_prob": 0.006286943331360817}, {"id": 543, "seek": 133518, "start": 1342.94, "end": 1345.18, "text": " Just like correlations that I would not have believed", "tokens": [50752, 1449, 411, 13983, 763, 300, 286, 576, 406, 362, 7847, 50864], "temperature": 0.0, "avg_logprob": -0.18661253380052972, "compression_ratio": 1.88671875, "no_speech_prob": 0.006286943331360817}, {"id": 544, "seek": 133518, "start": 1345.18, "end": 1348.46, "text": " at before, if I saw like a 4% correlation before,", "tokens": [50864, 412, 949, 11, 498, 286, 1866, 411, 257, 1017, 4, 20009, 949, 11, 51028], "temperature": 0.0, "avg_logprob": -0.18661253380052972, "compression_ratio": 1.88671875, "no_speech_prob": 0.006286943331360817}, {"id": 545, "seek": 133518, "start": 1348.46, "end": 1349.66, "text": " I would be like, that's complete nonsense.", "tokens": [51028, 286, 576, 312, 411, 11, 300, 311, 3566, 14925, 13, 51088], "temperature": 0.0, "avg_logprob": -0.18661253380052972, "compression_ratio": 1.88671875, "no_speech_prob": 0.006286943331360817}, {"id": 546, "seek": 133518, "start": 1349.66, "end": 1351.94, "text": " I don't believe it, but like sometimes that's just the best", "tokens": [51088, 286, 500, 380, 1697, 309, 11, 457, 411, 2171, 300, 311, 445, 264, 1151, 51202], "temperature": 0.0, "avg_logprob": -0.18661253380052972, "compression_ratio": 1.88671875, "no_speech_prob": 0.006286943331360817}, {"id": 547, "seek": 133518, "start": 1351.94, "end": 1353.78, "text": " you can do in like quantum finance,", "tokens": [51202, 291, 393, 360, 294, 411, 13018, 10719, 11, 51294], "temperature": 0.0, "avg_logprob": -0.18661253380052972, "compression_ratio": 1.88671875, "no_speech_prob": 0.006286943331360817}, {"id": 548, "seek": 133518, "start": 1353.78, "end": 1356.78, "text": " and it can be real, like you can see it consistently.", "tokens": [51294, 293, 309, 393, 312, 957, 11, 411, 291, 393, 536, 309, 14961, 13, 51444], "temperature": 0.0, "avg_logprob": -0.18661253380052972, "compression_ratio": 1.88671875, "no_speech_prob": 0.006286943331360817}, {"id": 549, "seek": 133518, "start": 1356.78, "end": 1358.78, "text": " So you start like believing that these,", "tokens": [51444, 407, 291, 722, 411, 16594, 300, 613, 11, 51544], "temperature": 0.0, "avg_logprob": -0.18661253380052972, "compression_ratio": 1.88671875, "no_speech_prob": 0.006286943331360817}, {"id": 550, "seek": 133518, "start": 1358.78, "end": 1362.54, "text": " and the differences between the 3% and 4% correlation", "tokens": [51544, 293, 264, 7300, 1296, 264, 805, 4, 293, 1017, 4, 20009, 51732], "temperature": 0.0, "avg_logprob": -0.18661253380052972, "compression_ratio": 1.88671875, "no_speech_prob": 0.006286943331360817}, {"id": 551, "seek": 136254, "start": 1362.54, "end": 1366.46, "text": " can like be actually real, which is kind of amazing to me.", "tokens": [50364, 393, 411, 312, 767, 957, 11, 597, 307, 733, 295, 2243, 281, 385, 13, 50560], "temperature": 0.0, "avg_logprob": -0.16348423221246983, "compression_ratio": 1.5856164383561644, "no_speech_prob": 0.0008288217359222472}, {"id": 552, "seek": 136254, "start": 1367.54, "end": 1370.22, "text": " So we were talking about this about a week or so ago,", "tokens": [50614, 407, 321, 645, 1417, 466, 341, 466, 257, 1243, 420, 370, 2057, 11, 50748], "temperature": 0.0, "avg_logprob": -0.16348423221246983, "compression_ratio": 1.5856164383561644, "no_speech_prob": 0.0008288217359222472}, {"id": 553, "seek": 136254, "start": 1370.22, "end": 1373.22, "text": " but I've just read a book by Christopher Somerville's", "tokens": [50748, 457, 286, 600, 445, 1401, 257, 1446, 538, 20649, 12297, 1978, 3409, 311, 50898], "temperature": 0.0, "avg_logprob": -0.16348423221246983, "compression_ratio": 1.5856164383561644, "no_speech_prob": 0.0008288217359222472}, {"id": 554, "seek": 136254, "start": 1373.22, "end": 1375.62, "text": " Natural General Intelligence.", "tokens": [50898, 20137, 6996, 27274, 13, 51018], "temperature": 0.0, "avg_logprob": -0.16348423221246983, "compression_ratio": 1.5856164383561644, "no_speech_prob": 0.0008288217359222472}, {"id": 555, "seek": 136254, "start": 1375.62, "end": 1377.98, "text": " And he kind of said that one of the problems", "tokens": [51018, 400, 415, 733, 295, 848, 300, 472, 295, 264, 2740, 51136], "temperature": 0.0, "avg_logprob": -0.16348423221246983, "compression_ratio": 1.5856164383561644, "no_speech_prob": 0.0008288217359222472}, {"id": 556, "seek": 136254, "start": 1377.98, "end": 1380.58, "text": " with neuroscience, I mean, as you said, in some sense,", "tokens": [51136, 365, 42762, 11, 286, 914, 11, 382, 291, 848, 11, 294, 512, 2020, 11, 51266], "temperature": 0.0, "avg_logprob": -0.16348423221246983, "compression_ratio": 1.5856164383561644, "no_speech_prob": 0.0008288217359222472}, {"id": 557, "seek": 136254, "start": 1380.58, "end": 1383.02, "text": " it is analogous to being a quant,", "tokens": [51266, 309, 307, 16660, 563, 281, 885, 257, 4426, 11, 51388], "temperature": 0.0, "avg_logprob": -0.16348423221246983, "compression_ratio": 1.5856164383561644, "no_speech_prob": 0.0008288217359222472}, {"id": 558, "seek": 136254, "start": 1383.02, "end": 1386.34, "text": " because it's just so unbelievably complicated,", "tokens": [51388, 570, 309, 311, 445, 370, 43593, 6179, 11, 51554], "temperature": 0.0, "avg_logprob": -0.16348423221246983, "compression_ratio": 1.5856164383561644, "no_speech_prob": 0.0008288217359222472}, {"id": 559, "seek": 136254, "start": 1386.34, "end": 1389.54, "text": " and there aren't really any overarching theories", "tokens": [51554, 293, 456, 3212, 380, 534, 604, 45501, 13667, 51714], "temperature": 0.0, "avg_logprob": -0.16348423221246983, "compression_ratio": 1.5856164383561644, "no_speech_prob": 0.0008288217359222472}, {"id": 560, "seek": 136254, "start": 1389.54, "end": 1391.58, "text": " in neuroscience, and for many years,", "tokens": [51714, 294, 42762, 11, 293, 337, 867, 924, 11, 51816], "temperature": 0.0, "avg_logprob": -0.16348423221246983, "compression_ratio": 1.5856164383561644, "no_speech_prob": 0.0008288217359222472}, {"id": 561, "seek": 139158, "start": 1391.58, "end": 1395.22, "text": " neuroscientists have produced very reductionist models", "tokens": [50364, 28813, 5412, 1751, 362, 7126, 588, 11004, 468, 5245, 50546], "temperature": 0.0, "avg_logprob": -0.11645906339815962, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.0016430567484349012}, {"id": 562, "seek": 139158, "start": 1395.22, "end": 1397.86, "text": " to work on a small part of the system in isolation,", "tokens": [50546, 281, 589, 322, 257, 1359, 644, 295, 264, 1185, 294, 16001, 11, 50678], "temperature": 0.0, "avg_logprob": -0.11645906339815962, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.0016430567484349012}, {"id": 563, "seek": 139158, "start": 1397.86, "end": 1400.3, "text": " and it might be a multi-unbanded system, for example,", "tokens": [50678, 293, 309, 1062, 312, 257, 4825, 12, 409, 4235, 292, 1185, 11, 337, 1365, 11, 50800], "temperature": 0.0, "avg_logprob": -0.11645906339815962, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.0016430567484349012}, {"id": 564, "seek": 139158, "start": 1400.3, "end": 1403.6599999999999, "text": " and they might take very abstract quantities", "tokens": [50800, 293, 436, 1062, 747, 588, 12649, 22927, 50968], "temperature": 0.0, "avg_logprob": -0.11645906339815962, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.0016430567484349012}, {"id": 565, "seek": 139158, "start": 1403.6599999999999, "end": 1405.22, "text": " and put it into the model.", "tokens": [50968, 293, 829, 309, 666, 264, 2316, 13, 51046], "temperature": 0.0, "avg_logprob": -0.11645906339815962, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.0016430567484349012}, {"id": 566, "seek": 139158, "start": 1405.22, "end": 1408.1399999999999, "text": " And of course, neural networks now are slightly different.", "tokens": [51046, 400, 295, 1164, 11, 18161, 9590, 586, 366, 4748, 819, 13, 51192], "temperature": 0.0, "avg_logprob": -0.11645906339815962, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.0016430567484349012}, {"id": 567, "seek": 139158, "start": 1408.1399999999999, "end": 1410.3799999999999, "text": " They actually take in raw sensory information,", "tokens": [51192, 814, 767, 747, 294, 8936, 27233, 1589, 11, 51304], "temperature": 0.0, "avg_logprob": -0.11645906339815962, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.0016430567484349012}, {"id": 568, "seek": 139158, "start": 1410.3799999999999, "end": 1413.3, "text": " and they learn representations, but I just wondered,", "tokens": [51304, 293, 436, 1466, 33358, 11, 457, 286, 445, 17055, 11, 51450], "temperature": 0.0, "avg_logprob": -0.11645906339815962, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.0016430567484349012}, {"id": 569, "seek": 139158, "start": 1413.3, "end": 1416.26, "text": " could you kind of contrast those schools of thought?", "tokens": [51450, 727, 291, 733, 295, 8712, 729, 4656, 295, 1194, 30, 51598], "temperature": 0.0, "avg_logprob": -0.11645906339815962, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.0016430567484349012}, {"id": 570, "seek": 139158, "start": 1416.26, "end": 1419.74, "text": " Yeah, it's, I mean, science in biology,", "tokens": [51598, 865, 11, 309, 311, 11, 286, 914, 11, 3497, 294, 14956, 11, 51772], "temperature": 0.0, "avg_logprob": -0.11645906339815962, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.0016430567484349012}, {"id": 571, "seek": 141974, "start": 1419.74, "end": 1421.5, "text": " especially in sort of any biological field,", "tokens": [50364, 2318, 294, 1333, 295, 604, 13910, 2519, 11, 50452], "temperature": 0.0, "avg_logprob": -0.15586522909311148, "compression_ratio": 1.8690909090909091, "no_speech_prob": 0.002050304552540183}, {"id": 572, "seek": 141974, "start": 1421.5, "end": 1424.54, "text": " is extremely complicated, because the sort of standard way", "tokens": [50452, 307, 4664, 6179, 11, 570, 264, 1333, 295, 3832, 636, 50604], "temperature": 0.0, "avg_logprob": -0.15586522909311148, "compression_ratio": 1.8690909090909091, "no_speech_prob": 0.002050304552540183}, {"id": 573, "seek": 141974, "start": 1424.54, "end": 1426.9, "text": " you think about doing science is a very linear way,", "tokens": [50604, 291, 519, 466, 884, 3497, 307, 257, 588, 8213, 636, 11, 50722], "temperature": 0.0, "avg_logprob": -0.15586522909311148, "compression_ratio": 1.8690909090909091, "no_speech_prob": 0.002050304552540183}, {"id": 574, "seek": 141974, "start": 1426.9, "end": 1429.3, "text": " where you like break one thing at a time", "tokens": [50722, 689, 291, 411, 1821, 472, 551, 412, 257, 565, 50842], "temperature": 0.0, "avg_logprob": -0.15586522909311148, "compression_ratio": 1.8690909090909091, "no_speech_prob": 0.002050304552540183}, {"id": 575, "seek": 141974, "start": 1429.3, "end": 1433.02, "text": " and see what this sort of, looking at each variable", "tokens": [50842, 293, 536, 437, 341, 1333, 295, 11, 1237, 412, 1184, 7006, 51028], "temperature": 0.0, "avg_logprob": -0.15586522909311148, "compression_ratio": 1.8690909090909091, "no_speech_prob": 0.002050304552540183}, {"id": 576, "seek": 141974, "start": 1433.02, "end": 1436.94, "text": " by variable, each variable affects the system.", "tokens": [51028, 538, 7006, 11, 1184, 7006, 11807, 264, 1185, 13, 51224], "temperature": 0.0, "avg_logprob": -0.15586522909311148, "compression_ratio": 1.8690909090909091, "no_speech_prob": 0.002050304552540183}, {"id": 577, "seek": 141974, "start": 1436.94, "end": 1439.26, "text": " And so you, but when you have a system", "tokens": [51224, 400, 370, 291, 11, 457, 562, 291, 362, 257, 1185, 51340], "temperature": 0.0, "avg_logprob": -0.15586522909311148, "compression_ratio": 1.8690909090909091, "no_speech_prob": 0.002050304552540183}, {"id": 578, "seek": 141974, "start": 1439.26, "end": 1442.42, "text": " that's sort of this nonlinear dynamical interacting system", "tokens": [51340, 300, 311, 1333, 295, 341, 2107, 28263, 5999, 804, 18017, 1185, 51498], "temperature": 0.0, "avg_logprob": -0.15586522909311148, "compression_ratio": 1.8690909090909091, "no_speech_prob": 0.002050304552540183}, {"id": 579, "seek": 141974, "start": 1442.42, "end": 1444.18, "text": " with feedback loops like crazy,", "tokens": [51498, 365, 5824, 16121, 411, 3219, 11, 51586], "temperature": 0.0, "avg_logprob": -0.15586522909311148, "compression_ratio": 1.8690909090909091, "no_speech_prob": 0.002050304552540183}, {"id": 580, "seek": 141974, "start": 1444.18, "end": 1446.82, "text": " you can't just sort of break one thing at a time", "tokens": [51586, 291, 393, 380, 445, 1333, 295, 1821, 472, 551, 412, 257, 565, 51718], "temperature": 0.0, "avg_logprob": -0.15586522909311148, "compression_ratio": 1.8690909090909091, "no_speech_prob": 0.002050304552540183}, {"id": 581, "seek": 141974, "start": 1446.82, "end": 1449.14, "text": " or like modulate one dimension at a time", "tokens": [51718, 420, 411, 1072, 5256, 472, 10139, 412, 257, 565, 51834], "temperature": 0.0, "avg_logprob": -0.15586522909311148, "compression_ratio": 1.8690909090909091, "no_speech_prob": 0.002050304552540183}, {"id": 582, "seek": 144914, "start": 1449.3400000000001, "end": 1453.0200000000002, "text": " without sort of changing the behavior of the entire system.", "tokens": [50374, 1553, 1333, 295, 4473, 264, 5223, 295, 264, 2302, 1185, 13, 50558], "temperature": 0.0, "avg_logprob": -0.12907568863996371, "compression_ratio": 1.8602941176470589, "no_speech_prob": 0.0007792330579832196}, {"id": 583, "seek": 144914, "start": 1453.0200000000002, "end": 1456.22, "text": " And so just sort of standard ways of doing science", "tokens": [50558, 400, 370, 445, 1333, 295, 3832, 2098, 295, 884, 3497, 50718], "temperature": 0.0, "avg_logprob": -0.12907568863996371, "compression_ratio": 1.8602941176470589, "no_speech_prob": 0.0007792330579832196}, {"id": 584, "seek": 144914, "start": 1456.22, "end": 1458.5400000000002, "text": " don't necessarily work that well.", "tokens": [50718, 500, 380, 4725, 589, 300, 731, 13, 50834], "temperature": 0.0, "avg_logprob": -0.12907568863996371, "compression_ratio": 1.8602941176470589, "no_speech_prob": 0.0007792330579832196}, {"id": 585, "seek": 144914, "start": 1458.5400000000002, "end": 1461.3400000000001, "text": " You can, like in sort of the classic idea", "tokens": [50834, 509, 393, 11, 411, 294, 1333, 295, 264, 7230, 1558, 50974], "temperature": 0.0, "avg_logprob": -0.12907568863996371, "compression_ratio": 1.8602941176470589, "no_speech_prob": 0.0007792330579832196}, {"id": 586, "seek": 144914, "start": 1461.3400000000001, "end": 1463.9, "text": " in visual neuroscience was you use like sine wave gradients", "tokens": [50974, 294, 5056, 42762, 390, 291, 764, 411, 18609, 5772, 2771, 2448, 51102], "temperature": 0.0, "avg_logprob": -0.12907568863996371, "compression_ratio": 1.8602941176470589, "no_speech_prob": 0.0007792330579832196}, {"id": 587, "seek": 144914, "start": 1463.9, "end": 1466.26, "text": " to probe the visual system.", "tokens": [51102, 281, 22715, 264, 5056, 1185, 13, 51220], "temperature": 0.0, "avg_logprob": -0.12907568863996371, "compression_ratio": 1.8602941176470589, "no_speech_prob": 0.0007792330579832196}, {"id": 588, "seek": 144914, "start": 1466.26, "end": 1469.1000000000001, "text": " And you can get models that look like they work very well", "tokens": [51220, 400, 291, 393, 483, 5245, 300, 574, 411, 436, 589, 588, 731, 51362], "temperature": 0.0, "avg_logprob": -0.12907568863996371, "compression_ratio": 1.8602941176470589, "no_speech_prob": 0.0007792330579832196}, {"id": 589, "seek": 144914, "start": 1469.1000000000001, "end": 1471.22, "text": " at explaining the behavior of early visual cortex", "tokens": [51362, 412, 13468, 264, 5223, 295, 2440, 5056, 33312, 51468], "temperature": 0.0, "avg_logprob": -0.12907568863996371, "compression_ratio": 1.8602941176470589, "no_speech_prob": 0.0007792330579832196}, {"id": 590, "seek": 144914, "start": 1471.22, "end": 1472.9, "text": " to sine wave gradients.", "tokens": [51468, 281, 18609, 5772, 2771, 2448, 13, 51552], "temperature": 0.0, "avg_logprob": -0.12907568863996371, "compression_ratio": 1.8602941176470589, "no_speech_prob": 0.0007792330579832196}, {"id": 591, "seek": 144914, "start": 1472.9, "end": 1475.74, "text": " But if you try to use the models you learned there", "tokens": [51552, 583, 498, 291, 853, 281, 764, 264, 5245, 291, 3264, 456, 51694], "temperature": 0.0, "avg_logprob": -0.12907568863996371, "compression_ratio": 1.8602941176470589, "no_speech_prob": 0.0007792330579832196}, {"id": 592, "seek": 144914, "start": 1475.74, "end": 1478.0600000000002, "text": " to extrapolate to say, how does a neuron respond", "tokens": [51694, 281, 48224, 473, 281, 584, 11, 577, 775, 257, 34090, 4196, 51810], "temperature": 0.0, "avg_logprob": -0.12907568863996371, "compression_ratio": 1.8602941176470589, "no_speech_prob": 0.0007792330579832196}, {"id": 593, "seek": 147806, "start": 1478.1, "end": 1479.94, "text": " to naturalistic images?", "tokens": [50366, 281, 3303, 3142, 5267, 30, 50458], "temperature": 0.0, "avg_logprob": -0.1112528127782485, "compression_ratio": 1.8083623693379791, "no_speech_prob": 0.0017003657994791865}, {"id": 594, "seek": 147806, "start": 1479.94, "end": 1481.6599999999999, "text": " It just doesn't work.", "tokens": [50458, 467, 445, 1177, 380, 589, 13, 50544], "temperature": 0.0, "avg_logprob": -0.1112528127782485, "compression_ratio": 1.8083623693379791, "no_speech_prob": 0.0017003657994791865}, {"id": 595, "seek": 147806, "start": 1481.6599999999999, "end": 1484.02, "text": " And it kind of even looks like the sine wave gradients", "tokens": [50544, 400, 309, 733, 295, 754, 1542, 411, 264, 18609, 5772, 2771, 2448, 50662], "temperature": 0.0, "avg_logprob": -0.1112528127782485, "compression_ratio": 1.8083623693379791, "no_speech_prob": 0.0017003657994791865}, {"id": 596, "seek": 147806, "start": 1484.02, "end": 1486.3799999999999, "text": " are driving the system into a sort of state", "tokens": [50662, 366, 4840, 264, 1185, 666, 257, 1333, 295, 1785, 50780], "temperature": 0.0, "avg_logprob": -0.1112528127782485, "compression_ratio": 1.8083623693379791, "no_speech_prob": 0.0017003657994791865}, {"id": 597, "seek": 147806, "start": 1486.3799999999999, "end": 1488.58, "text": " that it never gets into normally.", "tokens": [50780, 300, 309, 1128, 2170, 666, 5646, 13, 50890], "temperature": 0.0, "avg_logprob": -0.1112528127782485, "compression_ratio": 1.8083623693379791, "no_speech_prob": 0.0017003657994791865}, {"id": 598, "seek": 147806, "start": 1488.58, "end": 1491.78, "text": " You're kind of driving it out of its normal operating range.", "tokens": [50890, 509, 434, 733, 295, 4840, 309, 484, 295, 1080, 2710, 7447, 3613, 13, 51050], "temperature": 0.0, "avg_logprob": -0.1112528127782485, "compression_ratio": 1.8083623693379791, "no_speech_prob": 0.0017003657994791865}, {"id": 599, "seek": 147806, "start": 1491.78, "end": 1495.78, "text": " And what you, and so the system is behaving differently", "tokens": [51050, 400, 437, 291, 11, 293, 370, 264, 1185, 307, 35263, 7614, 51250], "temperature": 0.0, "avg_logprob": -0.1112528127782485, "compression_ratio": 1.8083623693379791, "no_speech_prob": 0.0017003657994791865}, {"id": 600, "seek": 147806, "start": 1495.78, "end": 1498.98, "text": " because you're only trying to look at like one dimension.", "tokens": [51250, 570, 291, 434, 787, 1382, 281, 574, 412, 411, 472, 10139, 13, 51410], "temperature": 0.0, "avg_logprob": -0.1112528127782485, "compression_ratio": 1.8083623693379791, "no_speech_prob": 0.0017003657994791865}, {"id": 601, "seek": 147806, "start": 1498.98, "end": 1500.8999999999999, "text": " And so what do you actually really learn?", "tokens": [51410, 400, 370, 437, 360, 291, 767, 534, 1466, 30, 51506], "temperature": 0.0, "avg_logprob": -0.1112528127782485, "compression_ratio": 1.8083623693379791, "no_speech_prob": 0.0017003657994791865}, {"id": 602, "seek": 147806, "start": 1500.8999999999999, "end": 1503.22, "text": " You've sort of learned of how the system operates", "tokens": [51506, 509, 600, 1333, 295, 3264, 295, 577, 264, 1185, 22577, 51622], "temperature": 0.0, "avg_logprob": -0.1112528127782485, "compression_ratio": 1.8083623693379791, "no_speech_prob": 0.0017003657994791865}, {"id": 603, "seek": 147806, "start": 1503.22, "end": 1505.34, "text": " in this weird perturbed state,", "tokens": [51622, 294, 341, 3657, 13269, 374, 2883, 1785, 11, 51728], "temperature": 0.0, "avg_logprob": -0.1112528127782485, "compression_ratio": 1.8083623693379791, "no_speech_prob": 0.0017003657994791865}, {"id": 604, "seek": 147806, "start": 1505.34, "end": 1507.22, "text": " but it doesn't really necessarily tell you", "tokens": [51728, 457, 309, 1177, 380, 534, 4725, 980, 291, 51822], "temperature": 0.0, "avg_logprob": -0.1112528127782485, "compression_ratio": 1.8083623693379791, "no_speech_prob": 0.0017003657994791865}, {"id": 605, "seek": 150722, "start": 1507.22, "end": 1511.98, "text": " about its sort of normal, natural operating like parameters.", "tokens": [50364, 466, 1080, 1333, 295, 2710, 11, 3303, 7447, 411, 9834, 13, 50602], "temperature": 0.0, "avg_logprob": -0.22115630072516365, "compression_ratio": 1.7063492063492063, "no_speech_prob": 0.00040444170008413494}, {"id": 606, "seek": 150722, "start": 1512.82, "end": 1515.46, "text": " And yeah, and in like in finance", "tokens": [50644, 400, 1338, 11, 293, 294, 411, 294, 10719, 50776], "temperature": 0.0, "avg_logprob": -0.22115630072516365, "compression_ratio": 1.7063492063492063, "no_speech_prob": 0.00040444170008413494}, {"id": 607, "seek": 150722, "start": 1515.46, "end": 1518.34, "text": " you can't even really do experiments like that.", "tokens": [50776, 291, 393, 380, 754, 534, 360, 12050, 411, 300, 13, 50920], "temperature": 0.0, "avg_logprob": -0.22115630072516365, "compression_ratio": 1.7063492063492063, "no_speech_prob": 0.00040444170008413494}, {"id": 608, "seek": 150722, "start": 1518.34, "end": 1523.34, "text": " And so you're sort of left with this more inductive approach", "tokens": [50920, 400, 370, 291, 434, 1333, 295, 1411, 365, 341, 544, 31612, 488, 3109, 51170], "temperature": 0.0, "avg_logprob": -0.22115630072516365, "compression_ratio": 1.7063492063492063, "no_speech_prob": 0.00040444170008413494}, {"id": 609, "seek": 150722, "start": 1523.46, "end": 1525.54, "text": " of you just try to get lots and lots of data", "tokens": [51176, 295, 291, 445, 853, 281, 483, 3195, 293, 3195, 295, 1412, 51280], "temperature": 0.0, "avg_logprob": -0.22115630072516365, "compression_ratio": 1.7063492063492063, "no_speech_prob": 0.00040444170008413494}, {"id": 610, "seek": 150722, "start": 1525.54, "end": 1527.54, "text": " and try to learn the patterns and the data.", "tokens": [51280, 293, 853, 281, 1466, 264, 8294, 293, 264, 1412, 13, 51380], "temperature": 0.0, "avg_logprob": -0.22115630072516365, "compression_ratio": 1.7063492063492063, "no_speech_prob": 0.00040444170008413494}, {"id": 611, "seek": 150722, "start": 1527.54, "end": 1530.06, "text": " And that was the sort of approach that the lab,", "tokens": [51380, 400, 300, 390, 264, 1333, 295, 3109, 300, 264, 2715, 11, 51506], "temperature": 0.0, "avg_logprob": -0.22115630072516365, "compression_ratio": 1.7063492063492063, "no_speech_prob": 0.00040444170008413494}, {"id": 612, "seek": 150722, "start": 1530.06, "end": 1532.7, "text": " the Gallant Lab at Berkeley, where I did computational", "tokens": [51506, 264, 14588, 394, 10137, 412, 23684, 11, 689, 286, 630, 28270, 51638], "temperature": 0.0, "avg_logprob": -0.22115630072516365, "compression_ratio": 1.7063492063492063, "no_speech_prob": 0.00040444170008413494}, {"id": 613, "seek": 150722, "start": 1532.7, "end": 1534.38, "text": " neuroscience, that was the approach", "tokens": [51638, 42762, 11, 300, 390, 264, 3109, 51722], "temperature": 0.0, "avg_logprob": -0.22115630072516365, "compression_ratio": 1.7063492063492063, "no_speech_prob": 0.00040444170008413494}, {"id": 614, "seek": 153438, "start": 1534.38, "end": 1536.8200000000002, "text": " that they were kind of pioneering of using", "tokens": [50364, 300, 436, 645, 733, 295, 19761, 1794, 295, 1228, 50486], "temperature": 0.0, "avg_logprob": -0.15197650406711785, "compression_ratio": 2.0343511450381677, "no_speech_prob": 0.002888937946408987}, {"id": 615, "seek": 153438, "start": 1536.8200000000002, "end": 1538.3400000000001, "text": " complicated naturalistic stimuli", "tokens": [50486, 6179, 3303, 3142, 47752, 50562], "temperature": 0.0, "avg_logprob": -0.15197650406711785, "compression_ratio": 2.0343511450381677, "no_speech_prob": 0.002888937946408987}, {"id": 616, "seek": 153438, "start": 1538.3400000000001, "end": 1540.38, "text": " and then using machine learning and statistics", "tokens": [50562, 293, 550, 1228, 3479, 2539, 293, 12523, 50664], "temperature": 0.0, "avg_logprob": -0.15197650406711785, "compression_ratio": 2.0343511450381677, "no_speech_prob": 0.002888937946408987}, {"id": 617, "seek": 153438, "start": 1540.38, "end": 1542.66, "text": " to try to extract the patterns from the data.", "tokens": [50664, 281, 853, 281, 8947, 264, 8294, 490, 264, 1412, 13, 50778], "temperature": 0.0, "avg_logprob": -0.15197650406711785, "compression_ratio": 2.0343511450381677, "no_speech_prob": 0.002888937946408987}, {"id": 618, "seek": 153438, "start": 1542.66, "end": 1546.46, "text": " And that adapts quite well to the sort of new machine learning", "tokens": [50778, 400, 300, 23169, 1373, 1596, 731, 281, 264, 1333, 295, 777, 3479, 2539, 50968], "temperature": 0.0, "avg_logprob": -0.15197650406711785, "compression_ratio": 2.0343511450381677, "no_speech_prob": 0.002888937946408987}, {"id": 619, "seek": 153438, "start": 1546.46, "end": 1548.94, "text": " like in like quant finance paradigm,", "tokens": [50968, 411, 294, 411, 4426, 10719, 24709, 11, 51092], "temperature": 0.0, "avg_logprob": -0.15197650406711785, "compression_ratio": 2.0343511450381677, "no_speech_prob": 0.002888937946408987}, {"id": 620, "seek": 153438, "start": 1550.1000000000001, "end": 1551.74, "text": " which is starting to take off.", "tokens": [51150, 597, 307, 2891, 281, 747, 766, 13, 51232], "temperature": 0.0, "avg_logprob": -0.15197650406711785, "compression_ratio": 2.0343511450381677, "no_speech_prob": 0.002888937946408987}, {"id": 621, "seek": 153438, "start": 1551.74, "end": 1554.74, "text": " I kind of feel like I got into neuroscience", "tokens": [51232, 286, 733, 295, 841, 411, 286, 658, 666, 42762, 51382], "temperature": 0.0, "avg_logprob": -0.15197650406711785, "compression_ratio": 2.0343511450381677, "no_speech_prob": 0.002888937946408987}, {"id": 622, "seek": 153438, "start": 1554.74, "end": 1556.9, "text": " just as sort of machine learning was starting", "tokens": [51382, 445, 382, 1333, 295, 3479, 2539, 390, 2891, 51490], "temperature": 0.0, "avg_logprob": -0.15197650406711785, "compression_ratio": 2.0343511450381677, "no_speech_prob": 0.002888937946408987}, {"id": 623, "seek": 153438, "start": 1556.9, "end": 1558.42, "text": " to make its way into neuroscience.", "tokens": [51490, 281, 652, 1080, 636, 666, 42762, 13, 51566], "temperature": 0.0, "avg_logprob": -0.15197650406711785, "compression_ratio": 2.0343511450381677, "no_speech_prob": 0.002888937946408987}, {"id": 624, "seek": 153438, "start": 1558.42, "end": 1560.2600000000002, "text": " And now I feel like I've gotten into finance", "tokens": [51566, 400, 586, 286, 841, 411, 286, 600, 5768, 666, 10719, 51658], "temperature": 0.0, "avg_logprob": -0.15197650406711785, "compression_ratio": 2.0343511450381677, "no_speech_prob": 0.002888937946408987}, {"id": 625, "seek": 153438, "start": 1560.2600000000002, "end": 1563.18, "text": " just as machine learning is starting to like move into finance.", "tokens": [51658, 445, 382, 3479, 2539, 307, 2891, 281, 411, 1286, 666, 10719, 13, 51804], "temperature": 0.0, "avg_logprob": -0.15197650406711785, "compression_ratio": 2.0343511450381677, "no_speech_prob": 0.002888937946408987}, {"id": 626, "seek": 156318, "start": 1563.18, "end": 1566.8600000000001, "text": " So it's been kind of exciting to see it happen in both fields.", "tokens": [50364, 407, 309, 311, 668, 733, 295, 4670, 281, 536, 309, 1051, 294, 1293, 7909, 13, 50548], "temperature": 0.0, "avg_logprob": -0.11340951571499344, "compression_ratio": 1.7335423197492164, "no_speech_prob": 0.0003951123508159071}, {"id": 627, "seek": 156318, "start": 1568.02, "end": 1569.78, "text": " Yeah, so there's a few places we can go here.", "tokens": [50606, 865, 11, 370, 456, 311, 257, 1326, 3190, 321, 393, 352, 510, 13, 50694], "temperature": 0.0, "avg_logprob": -0.11340951571499344, "compression_ratio": 1.7335423197492164, "no_speech_prob": 0.0003951123508159071}, {"id": 628, "seek": 156318, "start": 1569.78, "end": 1573.46, "text": " I mean, I'm interested in the intelligibility of systems", "tokens": [50694, 286, 914, 11, 286, 478, 3102, 294, 264, 5613, 2841, 295, 3652, 50878], "temperature": 0.0, "avg_logprob": -0.11340951571499344, "compression_ratio": 1.7335423197492164, "no_speech_prob": 0.0003951123508159071}, {"id": 629, "seek": 156318, "start": 1573.46, "end": 1575.3, "text": " when you model them at the microscopic scale", "tokens": [50878, 562, 291, 2316, 552, 412, 264, 47897, 4373, 50970], "temperature": 0.0, "avg_logprob": -0.11340951571499344, "compression_ratio": 1.7335423197492164, "no_speech_prob": 0.0003951123508159071}, {"id": 630, "seek": 156318, "start": 1575.3, "end": 1577.3400000000001, "text": " because that's something that we struggle with.", "tokens": [50970, 570, 300, 311, 746, 300, 321, 7799, 365, 13, 51072], "temperature": 0.0, "avg_logprob": -0.11340951571499344, "compression_ratio": 1.7335423197492164, "no_speech_prob": 0.0003951123508159071}, {"id": 631, "seek": 156318, "start": 1577.3400000000001, "end": 1579.1000000000001, "text": " And also you mentioned dynamical systems.", "tokens": [51072, 400, 611, 291, 2835, 5999, 804, 3652, 13, 51160], "temperature": 0.0, "avg_logprob": -0.11340951571499344, "compression_ratio": 1.7335423197492164, "no_speech_prob": 0.0003951123508159071}, {"id": 632, "seek": 156318, "start": 1579.1000000000001, "end": 1580.38, "text": " I mean, for the benefit of the audience", "tokens": [51160, 286, 914, 11, 337, 264, 5121, 295, 264, 4034, 51224], "temperature": 0.0, "avg_logprob": -0.11340951571499344, "compression_ratio": 1.7335423197492164, "no_speech_prob": 0.0003951123508159071}, {"id": 633, "seek": 156318, "start": 1580.38, "end": 1582.74, "text": " that that describes a system where you're kind of like", "tokens": [51224, 300, 300, 15626, 257, 1185, 689, 291, 434, 733, 295, 411, 51342], "temperature": 0.0, "avg_logprob": -0.11340951571499344, "compression_ratio": 1.7335423197492164, "no_speech_prob": 0.0003951123508159071}, {"id": 634, "seek": 156318, "start": 1582.74, "end": 1585.0600000000002, "text": " iteratively changing things over time.", "tokens": [51342, 17138, 19020, 4473, 721, 670, 565, 13, 51458], "temperature": 0.0, "avg_logprob": -0.11340951571499344, "compression_ratio": 1.7335423197492164, "no_speech_prob": 0.0003951123508159071}, {"id": 635, "seek": 156318, "start": 1585.0600000000002, "end": 1588.38, "text": " And these systems typically develop chaotic properties,", "tokens": [51458, 400, 613, 3652, 5850, 1499, 27013, 7221, 11, 51624], "temperature": 0.0, "avg_logprob": -0.11340951571499344, "compression_ratio": 1.7335423197492164, "no_speech_prob": 0.0003951123508159071}, {"id": 636, "seek": 156318, "start": 1588.38, "end": 1591.54, "text": " which is to say like if you change something even a little bit", "tokens": [51624, 597, 307, 281, 584, 411, 498, 291, 1319, 746, 754, 257, 707, 857, 51782], "temperature": 0.0, "avg_logprob": -0.11340951571499344, "compression_ratio": 1.7335423197492164, "no_speech_prob": 0.0003951123508159071}, {"id": 637, "seek": 159154, "start": 1591.54, "end": 1596.02, "text": " you get these massive kind of changes in the system on the output.", "tokens": [50364, 291, 483, 613, 5994, 733, 295, 2962, 294, 264, 1185, 322, 264, 5598, 13, 50588], "temperature": 0.0, "avg_logprob": -0.1367430173433744, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.0010797802824527025}, {"id": 638, "seek": 159154, "start": 1596.02, "end": 1598.7, "text": " And even a neural network is technically a dynamical system, right?", "tokens": [50588, 400, 754, 257, 18161, 3209, 307, 12120, 257, 5999, 804, 1185, 11, 558, 30, 50722], "temperature": 0.0, "avg_logprob": -0.1367430173433744, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.0010797802824527025}, {"id": 639, "seek": 159154, "start": 1598.7, "end": 1602.6599999999999, "text": " Because you have back prop and you're kind of changing one layer", "tokens": [50722, 1436, 291, 362, 646, 2365, 293, 291, 434, 733, 295, 4473, 472, 4583, 50920], "temperature": 0.0, "avg_logprob": -0.1367430173433744, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.0010797802824527025}, {"id": 640, "seek": 159154, "start": 1602.6599999999999, "end": 1603.8999999999999, "text": " and then you're changing the next layer", "tokens": [50920, 293, 550, 291, 434, 4473, 264, 958, 4583, 50982], "temperature": 0.0, "avg_logprob": -0.1367430173433744, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.0010797802824527025}, {"id": 641, "seek": 159154, "start": 1603.8999999999999, "end": 1605.18, "text": " as the result of the previous layer.", "tokens": [50982, 382, 264, 1874, 295, 264, 3894, 4583, 13, 51046], "temperature": 0.0, "avg_logprob": -0.1367430173433744, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.0010797802824527025}, {"id": 642, "seek": 159154, "start": 1605.18, "end": 1610.1399999999999, "text": " And you get this kind of like iterative mutation of values.", "tokens": [51046, 400, 291, 483, 341, 733, 295, 411, 17138, 1166, 27960, 295, 4190, 13, 51294], "temperature": 0.0, "avg_logprob": -0.1367430173433744, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.0010797802824527025}, {"id": 643, "seek": 159154, "start": 1610.1399999999999, "end": 1613.02, "text": " But in real neural networks in our brain,", "tokens": [51294, 583, 294, 957, 18161, 9590, 294, 527, 3567, 11, 51438], "temperature": 0.0, "avg_logprob": -0.1367430173433744, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.0010797802824527025}, {"id": 644, "seek": 159154, "start": 1613.02, "end": 1614.62, "text": " it's so much more complicated than that.", "tokens": [51438, 309, 311, 370, 709, 544, 6179, 813, 300, 13, 51518], "temperature": 0.0, "avg_logprob": -0.1367430173433744, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.0010797802824527025}, {"id": 645, "seek": 159154, "start": 1614.62, "end": 1616.54, "text": " We have all of these like feedback connections", "tokens": [51518, 492, 362, 439, 295, 613, 411, 5824, 9271, 51614], "temperature": 0.0, "avg_logprob": -0.1367430173433744, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.0010797802824527025}, {"id": 646, "seek": 159154, "start": 1616.54, "end": 1618.18, "text": " and reflexivity and complexity.", "tokens": [51614, 293, 23802, 4253, 293, 14024, 13, 51696], "temperature": 0.0, "avg_logprob": -0.1367430173433744, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.0010797802824527025}, {"id": 647, "seek": 159154, "start": 1618.18, "end": 1619.94, "text": " It's crazy.", "tokens": [51696, 467, 311, 3219, 13, 51784], "temperature": 0.0, "avg_logprob": -0.1367430173433744, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.0010797802824527025}, {"id": 648, "seek": 161994, "start": 1619.94, "end": 1621.78, "text": " Yeah, not to mention different cell types", "tokens": [50364, 865, 11, 406, 281, 2152, 819, 2815, 3467, 50456], "temperature": 0.0, "avg_logprob": -0.16855711856130826, "compression_ratio": 1.9958847736625513, "no_speech_prob": 0.0018667287658900023}, {"id": 649, "seek": 161994, "start": 1621.78, "end": 1623.54, "text": " and different neurotransmitter types.", "tokens": [50456, 293, 819, 43286, 25392, 3508, 391, 3467, 13, 50544], "temperature": 0.0, "avg_logprob": -0.16855711856130826, "compression_ratio": 1.9958847736625513, "no_speech_prob": 0.0018667287658900023}, {"id": 650, "seek": 161994, "start": 1623.54, "end": 1625.38, "text": " And like the way those like,", "tokens": [50544, 400, 411, 264, 636, 729, 411, 11, 50636], "temperature": 0.0, "avg_logprob": -0.16855711856130826, "compression_ratio": 1.9958847736625513, "no_speech_prob": 0.0018667287658900023}, {"id": 651, "seek": 161994, "start": 1625.38, "end": 1628.1000000000001, "text": " you have sort of like several different networks", "tokens": [50636, 291, 362, 1333, 295, 411, 2940, 819, 9590, 50772], "temperature": 0.0, "avg_logprob": -0.16855711856130826, "compression_ratio": 1.9958847736625513, "no_speech_prob": 0.0018667287658900023}, {"id": 652, "seek": 161994, "start": 1628.1000000000001, "end": 1630.38, "text": " of different types of things interacting too.", "tokens": [50772, 295, 819, 3467, 295, 721, 18017, 886, 13, 50886], "temperature": 0.0, "avg_logprob": -0.16855711856130826, "compression_ratio": 1.9958847736625513, "no_speech_prob": 0.0018667287658900023}, {"id": 653, "seek": 161994, "start": 1630.38, "end": 1632.66, "text": " It's not just like an artificial neural network", "tokens": [50886, 467, 311, 406, 445, 411, 364, 11677, 18161, 3209, 51000], "temperature": 0.0, "avg_logprob": -0.16855711856130826, "compression_ratio": 1.9958847736625513, "no_speech_prob": 0.0018667287658900023}, {"id": 654, "seek": 161994, "start": 1632.66, "end": 1634.46, "text": " where everything is kind of the same.", "tokens": [51000, 689, 1203, 307, 733, 295, 264, 912, 13, 51090], "temperature": 0.0, "avg_logprob": -0.16855711856130826, "compression_ratio": 1.9958847736625513, "no_speech_prob": 0.0018667287658900023}, {"id": 655, "seek": 161994, "start": 1634.46, "end": 1637.06, "text": " You have like different cell types", "tokens": [51090, 509, 362, 411, 819, 2815, 3467, 51220], "temperature": 0.0, "avg_logprob": -0.16855711856130826, "compression_ratio": 1.9958847736625513, "no_speech_prob": 0.0018667287658900023}, {"id": 656, "seek": 161994, "start": 1637.06, "end": 1638.78, "text": " that use different neurotransmitters", "tokens": [51220, 300, 764, 819, 43286, 25392, 3508, 1559, 51306], "temperature": 0.0, "avg_logprob": -0.16855711856130826, "compression_ratio": 1.9958847736625513, "no_speech_prob": 0.0018667287658900023}, {"id": 657, "seek": 161994, "start": 1638.78, "end": 1641.26, "text": " that are somehow modulating certain things", "tokens": [51306, 300, 366, 6063, 1072, 12162, 1629, 721, 51430], "temperature": 0.0, "avg_logprob": -0.16855711856130826, "compression_ratio": 1.9958847736625513, "no_speech_prob": 0.0018667287658900023}, {"id": 658, "seek": 161994, "start": 1641.26, "end": 1642.6200000000001, "text": " and these networks are interacting.", "tokens": [51430, 293, 613, 9590, 366, 18017, 13, 51498], "temperature": 0.0, "avg_logprob": -0.16855711856130826, "compression_ratio": 1.9958847736625513, "no_speech_prob": 0.0018667287658900023}, {"id": 659, "seek": 161994, "start": 1642.6200000000001, "end": 1646.98, "text": " It's like the complexity is just like scary.", "tokens": [51498, 467, 311, 411, 264, 14024, 307, 445, 411, 6958, 13, 51716], "temperature": 0.0, "avg_logprob": -0.16855711856130826, "compression_ratio": 1.9958847736625513, "no_speech_prob": 0.0018667287658900023}, {"id": 660, "seek": 164698, "start": 1647.22, "end": 1651.42, "text": " At some point, one of my favorite things to do", "tokens": [50376, 1711, 512, 935, 11, 472, 295, 452, 2954, 721, 281, 360, 50586], "temperature": 0.0, "avg_logprob": -0.14989740708295038, "compression_ratio": 1.697508896797153, "no_speech_prob": 0.001244687708094716}, {"id": 661, "seek": 164698, "start": 1651.42, "end": 1653.34, "text": " when I would go to the Society for Neuroscience Conference", "tokens": [50586, 562, 286, 576, 352, 281, 264, 13742, 337, 1734, 8977, 6699, 22131, 50682], "temperature": 0.0, "avg_logprob": -0.14989740708295038, "compression_ratio": 1.697508896797153, "no_speech_prob": 0.001244687708094716}, {"id": 662, "seek": 164698, "start": 1653.34, "end": 1655.98, "text": " was to just like walk around this conference", "tokens": [50682, 390, 281, 445, 411, 1792, 926, 341, 7586, 50814], "temperature": 0.0, "avg_logprob": -0.14989740708295038, "compression_ratio": 1.697508896797153, "no_speech_prob": 0.001244687708094716}, {"id": 663, "seek": 164698, "start": 1655.98, "end": 1659.34, "text": " in this huge like multi-football sized field", "tokens": [50814, 294, 341, 2603, 411, 4825, 12, 13498, 3129, 20004, 2519, 50982], "temperature": 0.0, "avg_logprob": -0.14989740708295038, "compression_ratio": 1.697508896797153, "no_speech_prob": 0.001244687708094716}, {"id": 664, "seek": 164698, "start": 1659.34, "end": 1662.54, "text": " of just posters of all sorts of different types of neuroscience.", "tokens": [50982, 295, 445, 28172, 295, 439, 7527, 295, 819, 3467, 295, 42762, 13, 51142], "temperature": 0.0, "avg_logprob": -0.14989740708295038, "compression_ratio": 1.697508896797153, "no_speech_prob": 0.001244687708094716}, {"id": 665, "seek": 164698, "start": 1662.54, "end": 1665.6200000000001, "text": " And you just realize like how vast the field is", "tokens": [51142, 400, 291, 445, 4325, 411, 577, 8369, 264, 2519, 307, 51296], "temperature": 0.0, "avg_logprob": -0.14989740708295038, "compression_ratio": 1.697508896797153, "no_speech_prob": 0.001244687708094716}, {"id": 666, "seek": 164698, "start": 1665.6200000000001, "end": 1669.58, "text": " and how little we know about it putting it all together", "tokens": [51296, 293, 577, 707, 321, 458, 466, 309, 3372, 309, 439, 1214, 51494], "temperature": 0.0, "avg_logprob": -0.14989740708295038, "compression_ratio": 1.697508896797153, "no_speech_prob": 0.001244687708094716}, {"id": 667, "seek": 164698, "start": 1669.58, "end": 1671.22, "text": " because it's just so complicated.", "tokens": [51494, 570, 309, 311, 445, 370, 6179, 13, 51576], "temperature": 0.0, "avg_logprob": -0.14989740708295038, "compression_ratio": 1.697508896797153, "no_speech_prob": 0.001244687708094716}, {"id": 668, "seek": 164698, "start": 1671.22, "end": 1672.34, "text": " You can only sort of wrap your head", "tokens": [51576, 509, 393, 787, 1333, 295, 7019, 428, 1378, 51632], "temperature": 0.0, "avg_logprob": -0.14989740708295038, "compression_ratio": 1.697508896797153, "no_speech_prob": 0.001244687708094716}, {"id": 669, "seek": 164698, "start": 1672.34, "end": 1674.54, "text": " around your own little corner of the thing", "tokens": [51632, 926, 428, 1065, 707, 4538, 295, 264, 551, 51742], "temperature": 0.0, "avg_logprob": -0.14989740708295038, "compression_ratio": 1.697508896797153, "no_speech_prob": 0.001244687708094716}, {"id": 670, "seek": 167454, "start": 1674.54, "end": 1677.6599999999999, "text": " but like trying to get, understand the full system", "tokens": [50364, 457, 411, 1382, 281, 483, 11, 1223, 264, 1577, 1185, 50520], "temperature": 0.0, "avg_logprob": -0.16783813737396502, "compression_ratio": 1.804255319148936, "no_speech_prob": 0.0012243154924362898}, {"id": 671, "seek": 167454, "start": 1677.6599999999999, "end": 1680.34, "text": " and all it's like incredible complexity.", "tokens": [50520, 293, 439, 309, 311, 411, 4651, 14024, 13, 50654], "temperature": 0.0, "avg_logprob": -0.16783813737396502, "compression_ratio": 1.804255319148936, "no_speech_prob": 0.0012243154924362898}, {"id": 672, "seek": 167454, "start": 1680.34, "end": 1683.5, "text": " I mean, it might just be too much for one human being", "tokens": [50654, 286, 914, 11, 309, 1062, 445, 312, 886, 709, 337, 472, 1952, 885, 50812], "temperature": 0.0, "avg_logprob": -0.16783813737396502, "compression_ratio": 1.804255319148936, "no_speech_prob": 0.0012243154924362898}, {"id": 673, "seek": 167454, "start": 1683.5, "end": 1685.62, "text": " to be able to fit in their head.", "tokens": [50812, 281, 312, 1075, 281, 3318, 294, 641, 1378, 13, 50918], "temperature": 0.0, "avg_logprob": -0.16783813737396502, "compression_ratio": 1.804255319148936, "no_speech_prob": 0.0012243154924362898}, {"id": 674, "seek": 167454, "start": 1685.62, "end": 1689.74, "text": " And so some of our goals of trying to understand things", "tokens": [50918, 400, 370, 512, 295, 527, 5493, 295, 1382, 281, 1223, 721, 51124], "temperature": 0.0, "avg_logprob": -0.16783813737396502, "compression_ratio": 1.804255319148936, "no_speech_prob": 0.0012243154924362898}, {"id": 675, "seek": 167454, "start": 1689.74, "end": 1693.74, "text": " or make a turtle models, it might just not be possible.", "tokens": [51124, 420, 652, 257, 22866, 5245, 11, 309, 1062, 445, 406, 312, 1944, 13, 51324], "temperature": 0.0, "avg_logprob": -0.16783813737396502, "compression_ratio": 1.804255319148936, "no_speech_prob": 0.0012243154924362898}, {"id": 676, "seek": 167454, "start": 1693.74, "end": 1695.46, "text": " We might just not, I mean,", "tokens": [51324, 492, 1062, 445, 406, 11, 286, 914, 11, 51410], "temperature": 0.0, "avg_logprob": -0.16783813737396502, "compression_ratio": 1.804255319148936, "no_speech_prob": 0.0012243154924362898}, {"id": 677, "seek": 167454, "start": 1695.46, "end": 1696.74, "text": " might not be able to understand it", "tokens": [51410, 1062, 406, 312, 1075, 281, 1223, 309, 51474], "temperature": 0.0, "avg_logprob": -0.16783813737396502, "compression_ratio": 1.804255319148936, "no_speech_prob": 0.0012243154924362898}, {"id": 678, "seek": 167454, "start": 1696.74, "end": 1698.42, "text": " in a way that feels intuitive to us", "tokens": [51474, 294, 257, 636, 300, 3417, 21769, 281, 505, 51558], "temperature": 0.0, "avg_logprob": -0.16783813737396502, "compression_ratio": 1.804255319148936, "no_speech_prob": 0.0012243154924362898}, {"id": 679, "seek": 167454, "start": 1698.42, "end": 1700.34, "text": " even if our models work quite well.", "tokens": [51558, 754, 498, 527, 5245, 589, 1596, 731, 13, 51654], "temperature": 0.0, "avg_logprob": -0.16783813737396502, "compression_ratio": 1.804255319148936, "no_speech_prob": 0.0012243154924362898}, {"id": 680, "seek": 170034, "start": 1701.34, "end": 1705.06, "text": " Yeah, humans have this real desire to understand", "tokens": [50414, 865, 11, 6255, 362, 341, 957, 7516, 281, 1223, 50600], "temperature": 0.0, "avg_logprob": -0.13996031761169433, "compression_ratio": 1.5860655737704918, "no_speech_prob": 0.0008532483479939401}, {"id": 681, "seek": 170034, "start": 1705.06, "end": 1708.02, "text": " and we create intelligible frameworks and theories", "tokens": [50600, 293, 321, 1884, 5613, 964, 29834, 293, 13667, 50748], "temperature": 0.0, "avg_logprob": -0.13996031761169433, "compression_ratio": 1.5860655737704918, "no_speech_prob": 0.0008532483479939401}, {"id": 682, "seek": 170034, "start": 1708.02, "end": 1712.1399999999999, "text": " and we end up excluding most of the reality of the system.", "tokens": [50748, 293, 321, 917, 493, 49999, 881, 295, 264, 4103, 295, 264, 1185, 13, 50954], "temperature": 0.0, "avg_logprob": -0.13996031761169433, "compression_ratio": 1.5860655737704918, "no_speech_prob": 0.0008532483479939401}, {"id": 683, "seek": 170034, "start": 1712.1399999999999, "end": 1714.06, "text": " But just before we go there,", "tokens": [50954, 583, 445, 949, 321, 352, 456, 11, 51050], "temperature": 0.0, "avg_logprob": -0.13996031761169433, "compression_ratio": 1.5860655737704918, "no_speech_prob": 0.0008532483479939401}, {"id": 684, "seek": 170034, "start": 1714.06, "end": 1716.26, "text": " I wanted to talk a little bit more about the brain.", "tokens": [51050, 286, 1415, 281, 751, 257, 707, 857, 544, 466, 264, 3567, 13, 51160], "temperature": 0.0, "avg_logprob": -0.13996031761169433, "compression_ratio": 1.5860655737704918, "no_speech_prob": 0.0008532483479939401}, {"id": 685, "seek": 170034, "start": 1716.26, "end": 1718.98, "text": " So, you know, Summerfield said in his book", "tokens": [51160, 407, 11, 291, 458, 11, 16161, 7610, 848, 294, 702, 1446, 51296], "temperature": 0.0, "avg_logprob": -0.13996031761169433, "compression_ratio": 1.5860655737704918, "no_speech_prob": 0.0008532483479939401}, {"id": 686, "seek": 170034, "start": 1718.98, "end": 1722.02, "text": " that the ultimate goal of the nervous system", "tokens": [51296, 300, 264, 9705, 3387, 295, 264, 6296, 1185, 51448], "temperature": 0.0, "avg_logprob": -0.13996031761169433, "compression_ratio": 1.5860655737704918, "no_speech_prob": 0.0008532483479939401}, {"id": 687, "seek": 170034, "start": 1722.02, "end": 1724.54, "text": " is to avoid surprise altogether.", "tokens": [51448, 307, 281, 5042, 6365, 19051, 13, 51574], "temperature": 0.0, "avg_logprob": -0.13996031761169433, "compression_ratio": 1.5860655737704918, "no_speech_prob": 0.0008532483479939401}, {"id": 688, "seek": 170034, "start": 1724.54, "end": 1728.1, "text": " So when they study brains,", "tokens": [51574, 407, 562, 436, 2979, 15442, 11, 51752], "temperature": 0.0, "avg_logprob": -0.13996031761169433, "compression_ratio": 1.5860655737704918, "no_speech_prob": 0.0008532483479939401}, {"id": 689, "seek": 172810, "start": 1728.1799999999998, "end": 1731.1, "text": " they see that the brain kind of lights up and activates", "tokens": [50368, 436, 536, 300, 264, 3567, 733, 295, 5811, 493, 293, 43869, 50514], "temperature": 0.0, "avg_logprob": -0.09857083083991718, "compression_ratio": 1.8582375478927202, "no_speech_prob": 0.004511876963078976}, {"id": 690, "seek": 172810, "start": 1731.1, "end": 1732.78, "text": " in a surprising situation", "tokens": [50514, 294, 257, 8830, 2590, 50598], "temperature": 0.0, "avg_logprob": -0.09857083083991718, "compression_ratio": 1.8582375478927202, "no_speech_prob": 0.004511876963078976}, {"id": 691, "seek": 172810, "start": 1732.78, "end": 1735.6999999999998, "text": " and less so when it sees something it's seen before.", "tokens": [50598, 293, 1570, 370, 562, 309, 8194, 746, 309, 311, 1612, 949, 13, 50744], "temperature": 0.0, "avg_logprob": -0.09857083083991718, "compression_ratio": 1.8582375478927202, "no_speech_prob": 0.004511876963078976}, {"id": 692, "seek": 172810, "start": 1735.6999999999998, "end": 1737.78, "text": " And this also brings me to this idea", "tokens": [50744, 400, 341, 611, 5607, 385, 281, 341, 1558, 50848], "temperature": 0.0, "avg_logprob": -0.09857083083991718, "compression_ratio": 1.8582375478927202, "no_speech_prob": 0.004511876963078976}, {"id": 693, "seek": 172810, "start": 1737.78, "end": 1741.26, "text": " of there's a dichotomy between representationalism", "tokens": [50848, 295, 456, 311, 257, 10390, 310, 8488, 1296, 2906, 1478, 1434, 51022], "temperature": 0.0, "avg_logprob": -0.09857083083991718, "compression_ratio": 1.8582375478927202, "no_speech_prob": 0.004511876963078976}, {"id": 694, "seek": 172810, "start": 1741.26, "end": 1742.5, "text": " and inactivism.", "tokens": [51022, 293, 294, 23397, 1434, 13, 51084], "temperature": 0.0, "avg_logprob": -0.09857083083991718, "compression_ratio": 1.8582375478927202, "no_speech_prob": 0.004511876963078976}, {"id": 695, "seek": 172810, "start": 1742.5, "end": 1744.82, "text": " So the representation, this viewpoint", "tokens": [51084, 407, 264, 10290, 11, 341, 35248, 51200], "temperature": 0.0, "avg_logprob": -0.09857083083991718, "compression_ratio": 1.8582375478927202, "no_speech_prob": 0.004511876963078976}, {"id": 696, "seek": 172810, "start": 1744.82, "end": 1747.1, "text": " is that the brain does all of the thinking", "tokens": [51200, 307, 300, 264, 3567, 775, 439, 295, 264, 1953, 51314], "temperature": 0.0, "avg_logprob": -0.09857083083991718, "compression_ratio": 1.8582375478927202, "no_speech_prob": 0.004511876963078976}, {"id": 697, "seek": 172810, "start": 1747.1, "end": 1748.6999999999998, "text": " and it can be in a vat,", "tokens": [51314, 293, 309, 393, 312, 294, 257, 371, 267, 11, 51394], "temperature": 0.0, "avg_logprob": -0.09857083083991718, "compression_ratio": 1.8582375478927202, "no_speech_prob": 0.004511876963078976}, {"id": 698, "seek": 172810, "start": 1748.6999999999998, "end": 1750.82, "text": " it can be isolated from the environment.", "tokens": [51394, 309, 393, 312, 14621, 490, 264, 2823, 13, 51500], "temperature": 0.0, "avg_logprob": -0.09857083083991718, "compression_ratio": 1.8582375478927202, "no_speech_prob": 0.004511876963078976}, {"id": 699, "seek": 172810, "start": 1750.82, "end": 1752.54, "text": " And the inactivist school of thought", "tokens": [51500, 400, 264, 294, 23397, 468, 1395, 295, 1194, 51586], "temperature": 0.0, "avg_logprob": -0.09857083083991718, "compression_ratio": 1.8582375478927202, "no_speech_prob": 0.004511876963078976}, {"id": 700, "seek": 172810, "start": 1752.54, "end": 1755.3799999999999, "text": " is that the brain just kind of thinks", "tokens": [51586, 307, 300, 264, 3567, 445, 733, 295, 7309, 51728], "temperature": 0.0, "avg_logprob": -0.09857083083991718, "compression_ratio": 1.8582375478927202, "no_speech_prob": 0.004511876963078976}, {"id": 701, "seek": 172810, "start": 1755.3799999999999, "end": 1756.82, "text": " in terms of trajectories,", "tokens": [51728, 294, 2115, 295, 18257, 2083, 11, 51800], "temperature": 0.0, "avg_logprob": -0.09857083083991718, "compression_ratio": 1.8582375478927202, "no_speech_prob": 0.004511876963078976}, {"id": 702, "seek": 175682, "start": 1756.8999999999999, "end": 1759.26, "text": " in affordances given by the environment", "tokens": [50368, 294, 6157, 2676, 2212, 538, 264, 2823, 50486], "temperature": 0.0, "avg_logprob": -0.16034664251865485, "compression_ratio": 1.7967479674796747, "no_speech_prob": 0.0016983065288513899}, {"id": 703, "seek": 175682, "start": 1759.26, "end": 1761.9399999999998, "text": " and the brain decoupled from the environment", "tokens": [50486, 293, 264, 3567, 979, 263, 15551, 490, 264, 2823, 50620], "temperature": 0.0, "avg_logprob": -0.16034664251865485, "compression_ratio": 1.7967479674796747, "no_speech_prob": 0.0016983065288513899}, {"id": 704, "seek": 175682, "start": 1761.9399999999998, "end": 1763.06, "text": " is completely stupid.", "tokens": [50620, 307, 2584, 6631, 13, 50676], "temperature": 0.0, "avg_logprob": -0.16034664251865485, "compression_ratio": 1.7967479674796747, "no_speech_prob": 0.0016983065288513899}, {"id": 705, "seek": 175682, "start": 1763.06, "end": 1765.3799999999999, "text": " It just kind of like the brain only moves", "tokens": [50676, 467, 445, 733, 295, 411, 264, 3567, 787, 6067, 50792], "temperature": 0.0, "avg_logprob": -0.16034664251865485, "compression_ratio": 1.7967479674796747, "no_speech_prob": 0.0016983065288513899}, {"id": 706, "seek": 175682, "start": 1765.3799999999999, "end": 1767.5, "text": " through the environment through affordances.", "tokens": [50792, 807, 264, 2823, 807, 6157, 2676, 13, 50898], "temperature": 0.0, "avg_logprob": -0.16034664251865485, "compression_ratio": 1.7967479674796747, "no_speech_prob": 0.0016983065288513899}, {"id": 707, "seek": 175682, "start": 1767.5, "end": 1769.06, "text": " And maybe that's a continuum,", "tokens": [50898, 400, 1310, 300, 311, 257, 36120, 11, 50976], "temperature": 0.0, "avg_logprob": -0.16034664251865485, "compression_ratio": 1.7967479674796747, "no_speech_prob": 0.0016983065288513899}, {"id": 708, "seek": 175682, "start": 1769.06, "end": 1771.3, "text": " but where do you fall on that continuum?", "tokens": [50976, 457, 689, 360, 291, 2100, 322, 300, 36120, 30, 51088], "temperature": 0.0, "avg_logprob": -0.16034664251865485, "compression_ratio": 1.7967479674796747, "no_speech_prob": 0.0016983065288513899}, {"id": 709, "seek": 175682, "start": 1771.3, "end": 1773.26, "text": " It's a really good question.", "tokens": [51088, 467, 311, 257, 534, 665, 1168, 13, 51186], "temperature": 0.0, "avg_logprob": -0.16034664251865485, "compression_ratio": 1.7967479674796747, "no_speech_prob": 0.0016983065288513899}, {"id": 710, "seek": 175682, "start": 1774.22, "end": 1778.82, "text": " I mean, I think dreams are kind of the counter example", "tokens": [51234, 286, 914, 11, 286, 519, 7505, 366, 733, 295, 264, 5682, 1365, 51464], "temperature": 0.0, "avg_logprob": -0.16034664251865485, "compression_ratio": 1.7967479674796747, "no_speech_prob": 0.0016983065288513899}, {"id": 711, "seek": 175682, "start": 1778.82, "end": 1782.8999999999999, "text": " to the pure, I mean, dreams just sort of prove", "tokens": [51464, 281, 264, 6075, 11, 286, 914, 11, 7505, 445, 1333, 295, 7081, 51668], "temperature": 0.0, "avg_logprob": -0.16034664251865485, "compression_ratio": 1.7967479674796747, "no_speech_prob": 0.0016983065288513899}, {"id": 712, "seek": 175682, "start": 1782.8999999999999, "end": 1785.06, "text": " we can just sort of without any sensory input,", "tokens": [51668, 321, 393, 445, 1333, 295, 1553, 604, 27233, 4846, 11, 51776], "temperature": 0.0, "avg_logprob": -0.16034664251865485, "compression_ratio": 1.7967479674796747, "no_speech_prob": 0.0016983065288513899}, {"id": 713, "seek": 178506, "start": 1785.06, "end": 1786.74, "text": " construct very rich worlds.", "tokens": [50364, 7690, 588, 4593, 13401, 13, 50448], "temperature": 0.0, "avg_logprob": -0.1850797621930232, "compression_ratio": 1.830258302583026, "no_speech_prob": 0.007116890046745539}, {"id": 714, "seek": 178506, "start": 1786.74, "end": 1789.78, "text": " So we must have some ability to just represent", "tokens": [50448, 407, 321, 1633, 362, 512, 3485, 281, 445, 2906, 50600], "temperature": 0.0, "avg_logprob": -0.1850797621930232, "compression_ratio": 1.830258302583026, "no_speech_prob": 0.007116890046745539}, {"id": 715, "seek": 178506, "start": 1789.78, "end": 1791.06, "text": " some sort of models in the world", "tokens": [50600, 512, 1333, 295, 5245, 294, 264, 1002, 50664], "temperature": 0.0, "avg_logprob": -0.1850797621930232, "compression_ratio": 1.830258302583026, "no_speech_prob": 0.007116890046745539}, {"id": 716, "seek": 178506, "start": 1791.06, "end": 1794.62, "text": " that we're not just purely sensing and receiving the world.", "tokens": [50664, 300, 321, 434, 406, 445, 17491, 30654, 293, 10040, 264, 1002, 13, 50842], "temperature": 0.0, "avg_logprob": -0.1850797621930232, "compression_ratio": 1.830258302583026, "no_speech_prob": 0.007116890046745539}, {"id": 717, "seek": 178506, "start": 1794.62, "end": 1798.1799999999998, "text": " We have the structures that are able to put things together", "tokens": [50842, 492, 362, 264, 9227, 300, 366, 1075, 281, 829, 721, 1214, 51020], "temperature": 0.0, "avg_logprob": -0.1850797621930232, "compression_ratio": 1.830258302583026, "no_speech_prob": 0.007116890046745539}, {"id": 718, "seek": 178506, "start": 1798.1799999999998, "end": 1799.74, "text": " in a sort of coherent reality.", "tokens": [51020, 294, 257, 1333, 295, 36239, 4103, 13, 51098], "temperature": 0.0, "avg_logprob": -0.1850797621930232, "compression_ratio": 1.830258302583026, "no_speech_prob": 0.007116890046745539}, {"id": 719, "seek": 178506, "start": 1800.6599999999999, "end": 1803.98, "text": " And clearly there's an interaction between these,", "tokens": [51144, 400, 4448, 456, 311, 364, 9285, 1296, 613, 11, 51310], "temperature": 0.0, "avg_logprob": -0.1850797621930232, "compression_ratio": 1.830258302583026, "no_speech_prob": 0.007116890046745539}, {"id": 720, "seek": 178506, "start": 1803.98, "end": 1806.06, "text": " these structures in your brain that can construct these things", "tokens": [51310, 613, 9227, 294, 428, 3567, 300, 393, 7690, 613, 721, 51414], "temperature": 0.0, "avg_logprob": -0.1850797621930232, "compression_ratio": 1.830258302583026, "no_speech_prob": 0.007116890046745539}, {"id": 721, "seek": 178506, "start": 1806.06, "end": 1808.1799999999998, "text": " and the sensory data that kind of work together", "tokens": [51414, 293, 264, 27233, 1412, 300, 733, 295, 589, 1214, 51520], "temperature": 0.0, "avg_logprob": -0.1850797621930232, "compression_ratio": 1.830258302583026, "no_speech_prob": 0.007116890046745539}, {"id": 722, "seek": 178506, "start": 1808.1799999999998, "end": 1811.62, "text": " to construct how you experience things.", "tokens": [51520, 281, 7690, 577, 291, 1752, 721, 13, 51692], "temperature": 0.0, "avg_logprob": -0.1850797621930232, "compression_ratio": 1.830258302583026, "no_speech_prob": 0.007116890046745539}, {"id": 723, "seek": 178506, "start": 1811.62, "end": 1814.06, "text": " And so it's, yeah, it's a continuum.", "tokens": [51692, 400, 370, 309, 311, 11, 1338, 11, 309, 311, 257, 36120, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1850797621930232, "compression_ratio": 1.830258302583026, "no_speech_prob": 0.007116890046745539}, {"id": 724, "seek": 181406, "start": 1814.06, "end": 1818.82, "text": " I think you need the, like we are always with the world.", "tokens": [50364, 286, 519, 291, 643, 264, 11, 411, 321, 366, 1009, 365, 264, 1002, 13, 50602], "temperature": 0.0, "avg_logprob": -0.20890070121979046, "compression_ratio": 1.6529680365296804, "no_speech_prob": 0.0003149700351059437}, {"id": 725, "seek": 181406, "start": 1818.82, "end": 1821.7, "text": " You need the world to sort of build up these systems", "tokens": [50602, 509, 643, 264, 1002, 281, 1333, 295, 1322, 493, 613, 3652, 50746], "temperature": 0.0, "avg_logprob": -0.20890070121979046, "compression_ratio": 1.6529680365296804, "no_speech_prob": 0.0003149700351059437}, {"id": 726, "seek": 181406, "start": 1821.7, "end": 1823.1799999999998, "text": " over time.", "tokens": [50746, 670, 565, 13, 50820], "temperature": 0.0, "avg_logprob": -0.20890070121979046, "compression_ratio": 1.6529680365296804, "no_speech_prob": 0.0003149700351059437}, {"id": 727, "seek": 181406, "start": 1823.1799999999998, "end": 1826.3799999999999, "text": " Like you're not sort of built with all of them working", "tokens": [50820, 1743, 291, 434, 406, 1333, 295, 3094, 365, 439, 295, 552, 1364, 50980], "temperature": 0.0, "avg_logprob": -0.20890070121979046, "compression_ratio": 1.6529680365296804, "no_speech_prob": 0.0003149700351059437}, {"id": 728, "seek": 181406, "start": 1826.3799999999999, "end": 1827.98, "text": " just as a baby.", "tokens": [50980, 445, 382, 257, 3186, 13, 51060], "temperature": 0.0, "avg_logprob": -0.20890070121979046, "compression_ratio": 1.6529680365296804, "no_speech_prob": 0.0003149700351059437}, {"id": 729, "seek": 181406, "start": 1827.98, "end": 1830.58, "text": " I mean, sure, there's like, the system is biased", "tokens": [51060, 286, 914, 11, 988, 11, 456, 311, 411, 11, 264, 1185, 307, 28035, 51190], "temperature": 0.0, "avg_logprob": -0.20890070121979046, "compression_ratio": 1.6529680365296804, "no_speech_prob": 0.0003149700351059437}, {"id": 730, "seek": 181406, "start": 1830.58, "end": 1833.4199999999998, "text": " in certain ways that will help it learn these things.", "tokens": [51190, 294, 1629, 2098, 300, 486, 854, 309, 1466, 613, 721, 13, 51332], "temperature": 0.0, "avg_logprob": -0.20890070121979046, "compression_ratio": 1.6529680365296804, "no_speech_prob": 0.0003149700351059437}, {"id": 731, "seek": 181406, "start": 1833.4199999999998, "end": 1838.02, "text": " But yeah, you're like, so they're kind of both true", "tokens": [51332, 583, 1338, 11, 291, 434, 411, 11, 370, 436, 434, 733, 295, 1293, 2074, 51562], "temperature": 0.0, "avg_logprob": -0.20890070121979046, "compression_ratio": 1.6529680365296804, "no_speech_prob": 0.0003149700351059437}, {"id": 732, "seek": 181406, "start": 1838.02, "end": 1839.34, "text": " to some degree.", "tokens": [51562, 281, 512, 4314, 13, 51628], "temperature": 0.0, "avg_logprob": -0.20890070121979046, "compression_ratio": 1.6529680365296804, "no_speech_prob": 0.0003149700351059437}, {"id": 733, "seek": 183934, "start": 1839.34, "end": 1844.34, "text": " And yeah, it's definitely not one or the other.", "tokens": [50364, 400, 1338, 11, 309, 311, 2138, 406, 472, 420, 264, 661, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1438265222264087, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.008044379763305187}, {"id": 734, "seek": 183934, "start": 1845.6599999999999, "end": 1846.78, "text": " Yeah, it's so interesting.", "tokens": [50680, 865, 11, 309, 311, 370, 1880, 13, 50736], "temperature": 0.0, "avg_logprob": -0.1438265222264087, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.008044379763305187}, {"id": 735, "seek": 183934, "start": 1846.78, "end": 1849.06, "text": " And we're speaking with Carl Friston tomorrow", "tokens": [50736, 400, 321, 434, 4124, 365, 14256, 1526, 47345, 4153, 50850], "temperature": 0.0, "avg_logprob": -0.1438265222264087, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.008044379763305187}, {"id": 736, "seek": 183934, "start": 1849.06, "end": 1851.06, "text": " and he's got this free energy principle.", "tokens": [50850, 293, 415, 311, 658, 341, 1737, 2281, 8665, 13, 50950], "temperature": 0.0, "avg_logprob": -0.1438265222264087, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.008044379763305187}, {"id": 737, "seek": 183934, "start": 1851.06, "end": 1854.9399999999998, "text": " And it's a kind of postulate that works at any resolution.", "tokens": [50950, 400, 309, 311, 257, 733, 295, 2183, 5256, 300, 1985, 412, 604, 8669, 13, 51144], "temperature": 0.0, "avg_logprob": -0.1438265222264087, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.008044379763305187}, {"id": 738, "seek": 183934, "start": 1854.9399999999998, "end": 1858.22, "text": " So even with a single cell amoeba or something like that,", "tokens": [51144, 407, 754, 365, 257, 2167, 2815, 669, 7921, 4231, 420, 746, 411, 300, 11, 51308], "temperature": 0.0, "avg_logprob": -0.1438265222264087, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.008044379763305187}, {"id": 739, "seek": 183934, "start": 1858.22, "end": 1860.9399999999998, "text": " there's this idea that it has a Markov boundary", "tokens": [51308, 456, 311, 341, 1558, 300, 309, 575, 257, 3934, 5179, 12866, 51444], "temperature": 0.0, "avg_logprob": -0.1438265222264087, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.008044379763305187}, {"id": 740, "seek": 183934, "start": 1860.9399999999998, "end": 1863.3, "text": " and there's this kind of cyclical causalities.", "tokens": [51444, 293, 456, 311, 341, 733, 295, 19474, 804, 3302, 16110, 13, 51562], "temperature": 0.0, "avg_logprob": -0.1438265222264087, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.008044379763305187}, {"id": 741, "seek": 183934, "start": 1863.3, "end": 1866.4199999999998, "text": " So, and these boundaries I guess are relative.", "tokens": [51562, 407, 11, 293, 613, 13180, 286, 2041, 366, 4972, 13, 51718], "temperature": 0.0, "avg_logprob": -0.1438265222264087, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.008044379763305187}, {"id": 742, "seek": 183934, "start": 1866.4199999999998, "end": 1868.34, "text": " So you can draw boundaries around anything.", "tokens": [51718, 407, 291, 393, 2642, 13180, 926, 1340, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1438265222264087, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.008044379763305187}, {"id": 743, "seek": 186834, "start": 1868.58, "end": 1870.06, "text": " You're a boundary, you're an agent,", "tokens": [50376, 509, 434, 257, 12866, 11, 291, 434, 364, 9461, 11, 50450], "temperature": 0.0, "avg_logprob": -0.11430689004751352, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.0012797585222870111}, {"id": 744, "seek": 186834, "start": 1870.06, "end": 1871.8999999999999, "text": " but also at the microscopic scale.", "tokens": [50450, 457, 611, 412, 264, 47897, 4373, 13, 50542], "temperature": 0.0, "avg_logprob": -0.11430689004751352, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.0012797585222870111}, {"id": 745, "seek": 186834, "start": 1871.8999999999999, "end": 1873.9399999999998, "text": " And he says that all of these systems,", "tokens": [50542, 400, 415, 1619, 300, 439, 295, 613, 3652, 11, 50644], "temperature": 0.0, "avg_logprob": -0.11430689004751352, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.0012797585222870111}, {"id": 746, "seek": 186834, "start": 1873.9399999999998, "end": 1877.5, "text": " they just kind of predict external states", "tokens": [50644, 436, 445, 733, 295, 6069, 8320, 4368, 50822], "temperature": 0.0, "avg_logprob": -0.11430689004751352, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.0012797585222870111}, {"id": 747, "seek": 186834, "start": 1877.5, "end": 1879.3, "text": " from the internal states.", "tokens": [50822, 490, 264, 6920, 4368, 13, 50912], "temperature": 0.0, "avg_logprob": -0.11430689004751352, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.0012797585222870111}, {"id": 748, "seek": 186834, "start": 1879.3, "end": 1881.26, "text": " And then you get this self-organized", "tokens": [50912, 400, 550, 291, 483, 341, 2698, 12, 12372, 1602, 51010], "temperature": 0.0, "avg_logprob": -0.11430689004751352, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.0012797585222870111}, {"id": 749, "seek": 186834, "start": 1881.26, "end": 1884.3, "text": " and emergent complexity and so on that comes from that.", "tokens": [51010, 293, 4345, 6930, 14024, 293, 370, 322, 300, 1487, 490, 300, 13, 51162], "temperature": 0.0, "avg_logprob": -0.11430689004751352, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.0012797585222870111}, {"id": 750, "seek": 186834, "start": 1884.3, "end": 1887.4599999999998, "text": " But he does say though that intelligence is essentially", "tokens": [51162, 583, 415, 775, 584, 1673, 300, 7599, 307, 4476, 51320], "temperature": 0.0, "avg_logprob": -0.11430689004751352, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.0012797585222870111}, {"id": 751, "seek": 186834, "start": 1887.4599999999998, "end": 1892.4599999999998, "text": " about being able to predict a trajectory of actions.", "tokens": [51320, 466, 885, 1075, 281, 6069, 257, 21512, 295, 5909, 13, 51570], "temperature": 0.0, "avg_logprob": -0.11430689004751352, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.0012797585222870111}, {"id": 752, "seek": 186834, "start": 1892.4599999999998, "end": 1895.82, "text": " And I don't know whether we'd call it goal-seeking behavior,", "tokens": [51570, 400, 286, 500, 380, 458, 1968, 321, 1116, 818, 309, 3387, 12, 405, 38437, 5223, 11, 51738], "temperature": 0.0, "avg_logprob": -0.11430689004751352, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.0012797585222870111}, {"id": 753, "seek": 186834, "start": 1895.82, "end": 1898.1, "text": " but we do that very abstractly, don't we?", "tokens": [51738, 457, 321, 360, 300, 588, 12649, 356, 11, 500, 380, 321, 30, 51852], "temperature": 0.0, "avg_logprob": -0.11430689004751352, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.0012797585222870111}, {"id": 754, "seek": 189810, "start": 1898.1, "end": 1900.3, "text": " But weirdly, when you look at the brain level,", "tokens": [50364, 583, 48931, 11, 562, 291, 574, 412, 264, 3567, 1496, 11, 50474], "temperature": 0.0, "avg_logprob": -0.14770761625034604, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.0003857601259369403}, {"id": 755, "seek": 189810, "start": 1900.3, "end": 1904.1, "text": " it's happening at the microscopic sensory motor level.", "tokens": [50474, 309, 311, 2737, 412, 264, 47897, 27233, 5932, 1496, 13, 50664], "temperature": 0.0, "avg_logprob": -0.14770761625034604, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.0003857601259369403}, {"id": 756, "seek": 189810, "start": 1904.1, "end": 1905.58, "text": " So it's almost like how do you get", "tokens": [50664, 407, 309, 311, 1920, 411, 577, 360, 291, 483, 50738], "temperature": 0.0, "avg_logprob": -0.14770761625034604, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.0003857601259369403}, {"id": 757, "seek": 189810, "start": 1905.58, "end": 1909.1, "text": " that emergent abstract intelligence from that?", "tokens": [50738, 300, 4345, 6930, 12649, 7599, 490, 300, 30, 50914], "temperature": 0.0, "avg_logprob": -0.14770761625034604, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.0003857601259369403}, {"id": 758, "seek": 189810, "start": 1909.1, "end": 1912.6599999999999, "text": " That's a, I mean, yeah, that's an incredible question.", "tokens": [50914, 663, 311, 257, 11, 286, 914, 11, 1338, 11, 300, 311, 364, 4651, 1168, 13, 51092], "temperature": 0.0, "avg_logprob": -0.14770761625034604, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.0003857601259369403}, {"id": 759, "seek": 189810, "start": 1913.82, "end": 1915.58, "text": " It's, I mean, it seems like this,", "tokens": [51150, 467, 311, 11, 286, 914, 11, 309, 2544, 411, 341, 11, 51238], "temperature": 0.0, "avg_logprob": -0.14770761625034604, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.0003857601259369403}, {"id": 760, "seek": 189810, "start": 1915.58, "end": 1918.1399999999999, "text": " like what you said, this sort of idea of predicting", "tokens": [51238, 411, 437, 291, 848, 11, 341, 1333, 295, 1558, 295, 32884, 51366], "temperature": 0.0, "avg_logprob": -0.14770761625034604, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.0003857601259369403}, {"id": 761, "seek": 189810, "start": 1918.1399999999999, "end": 1920.4599999999998, "text": " the future, just a couple steps into the future", "tokens": [51366, 264, 2027, 11, 445, 257, 1916, 4439, 666, 264, 2027, 51482], "temperature": 0.0, "avg_logprob": -0.14770761625034604, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.0003857601259369403}, {"id": 762, "seek": 189810, "start": 1920.4599999999998, "end": 1923.06, "text": " that is just happening at just the circuit level,", "tokens": [51482, 300, 307, 445, 2737, 412, 445, 264, 9048, 1496, 11, 51612], "temperature": 0.0, "avg_logprob": -0.14770761625034604, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.0003857601259369403}, {"id": 763, "seek": 189810, "start": 1923.06, "end": 1927.4199999999998, "text": " even in the retina, that it seems like", "tokens": [51612, 754, 294, 264, 1533, 1426, 11, 300, 309, 2544, 411, 51830], "temperature": 0.0, "avg_logprob": -0.14770761625034604, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.0003857601259369403}, {"id": 764, "seek": 192742, "start": 1927.42, "end": 1929.8200000000002, "text": " that is a good sort of building block.", "tokens": [50364, 300, 307, 257, 665, 1333, 295, 2390, 3461, 13, 50484], "temperature": 0.0, "avg_logprob": -0.18176620884945519, "compression_ratio": 1.7921146953405018, "no_speech_prob": 0.0007320603472180665}, {"id": 765, "seek": 192742, "start": 1929.8200000000002, "end": 1931.38, "text": " If you can sort of chain that together", "tokens": [50484, 759, 291, 393, 1333, 295, 5021, 300, 1214, 50562], "temperature": 0.0, "avg_logprob": -0.18176620884945519, "compression_ratio": 1.7921146953405018, "no_speech_prob": 0.0007320603472180665}, {"id": 766, "seek": 192742, "start": 1931.38, "end": 1935.22, "text": " over sort of larger and larger scales within the brain,", "tokens": [50562, 670, 1333, 295, 4833, 293, 4833, 17408, 1951, 264, 3567, 11, 50754], "temperature": 0.0, "avg_logprob": -0.18176620884945519, "compression_ratio": 1.7921146953405018, "no_speech_prob": 0.0007320603472180665}, {"id": 767, "seek": 192742, "start": 1935.22, "end": 1937.8200000000002, "text": " it wouldn't surprise me if that's kind of the way it worked,", "tokens": [50754, 309, 2759, 380, 6365, 385, 498, 300, 311, 733, 295, 264, 636, 309, 2732, 11, 50884], "temperature": 0.0, "avg_logprob": -0.18176620884945519, "compression_ratio": 1.7921146953405018, "no_speech_prob": 0.0007320603472180665}, {"id": 768, "seek": 192742, "start": 1937.8200000000002, "end": 1940.7, "text": " this sort of, these sort of basic circuits", "tokens": [50884, 341, 1333, 295, 11, 613, 1333, 295, 3875, 26354, 51028], "temperature": 0.0, "avg_logprob": -0.18176620884945519, "compression_ratio": 1.7921146953405018, "no_speech_prob": 0.0007320603472180665}, {"id": 769, "seek": 192742, "start": 1940.7, "end": 1943.8200000000002, "text": " that are used for prediction, but with different input.", "tokens": [51028, 300, 366, 1143, 337, 17630, 11, 457, 365, 819, 4846, 13, 51184], "temperature": 0.0, "avg_logprob": -0.18176620884945519, "compression_ratio": 1.7921146953405018, "no_speech_prob": 0.0007320603472180665}, {"id": 770, "seek": 192742, "start": 1943.8200000000002, "end": 1946.1000000000001, "text": " If you're just having sort of retinal ganglion", "tokens": [51184, 759, 291, 434, 445, 1419, 1333, 295, 1533, 2071, 10145, 75, 313, 51298], "temperature": 0.0, "avg_logprob": -0.18176620884945519, "compression_ratio": 1.7921146953405018, "no_speech_prob": 0.0007320603472180665}, {"id": 771, "seek": 192742, "start": 1946.1000000000001, "end": 1948.98, "text": " and like a photos receptor as it is at input,", "tokens": [51298, 293, 411, 257, 5787, 32264, 382, 309, 307, 412, 4846, 11, 51442], "temperature": 0.0, "avg_logprob": -0.18176620884945519, "compression_ratio": 1.7921146953405018, "no_speech_prob": 0.0007320603472180665}, {"id": 772, "seek": 192742, "start": 1950.1000000000001, "end": 1951.66, "text": " it's able to just sort of do this sort", "tokens": [51498, 309, 311, 1075, 281, 445, 1333, 295, 360, 341, 1333, 51576], "temperature": 0.0, "avg_logprob": -0.18176620884945519, "compression_ratio": 1.7921146953405018, "no_speech_prob": 0.0007320603472180665}, {"id": 773, "seek": 192742, "start": 1951.66, "end": 1952.78, "text": " of very simple prediction.", "tokens": [51576, 295, 588, 2199, 17630, 13, 51632], "temperature": 0.0, "avg_logprob": -0.18176620884945519, "compression_ratio": 1.7921146953405018, "no_speech_prob": 0.0007320603472180665}, {"id": 774, "seek": 192742, "start": 1952.78, "end": 1955.38, "text": " But if you have these more complicated patterns", "tokens": [51632, 583, 498, 291, 362, 613, 544, 6179, 8294, 51762], "temperature": 0.0, "avg_logprob": -0.18176620884945519, "compression_ratio": 1.7921146953405018, "no_speech_prob": 0.0007320603472180665}, {"id": 775, "seek": 195538, "start": 1955.38, "end": 1959.3400000000001, "text": " in the middle of visual cortex and then higher", "tokens": [50364, 294, 264, 2808, 295, 5056, 33312, 293, 550, 2946, 50562], "temperature": 0.0, "avg_logprob": -0.1694658088684082, "compression_ratio": 1.7234042553191489, "no_speech_prob": 0.00017950670735444874}, {"id": 776, "seek": 195538, "start": 1959.3400000000001, "end": 1961.94, "text": " on the same sort of circuits with different input", "tokens": [50562, 322, 264, 912, 1333, 295, 26354, 365, 819, 4846, 50692], "temperature": 0.0, "avg_logprob": -0.1694658088684082, "compression_ratio": 1.7234042553191489, "no_speech_prob": 0.00017950670735444874}, {"id": 777, "seek": 195538, "start": 1961.94, "end": 1963.66, "text": " could sort of just be predicting", "tokens": [50692, 727, 1333, 295, 445, 312, 32884, 50778], "temperature": 0.0, "avg_logprob": -0.1694658088684082, "compression_ratio": 1.7234042553191489, "no_speech_prob": 0.00017950670735444874}, {"id": 778, "seek": 195538, "start": 1963.66, "end": 1966.14, "text": " this sort of evolution of these patterns.", "tokens": [50778, 341, 1333, 295, 9303, 295, 613, 8294, 13, 50902], "temperature": 0.0, "avg_logprob": -0.1694658088684082, "compression_ratio": 1.7234042553191489, "no_speech_prob": 0.00017950670735444874}, {"id": 779, "seek": 195538, "start": 1967.14, "end": 1971.0200000000002, "text": " And yeah, it's kind of amazing what you can sort of build", "tokens": [50952, 400, 1338, 11, 309, 311, 733, 295, 2243, 437, 291, 393, 1333, 295, 1322, 51146], "temperature": 0.0, "avg_logprob": -0.1694658088684082, "compression_ratio": 1.7234042553191489, "no_speech_prob": 0.00017950670735444874}, {"id": 780, "seek": 195538, "start": 1971.0200000000002, "end": 1973.2600000000002, "text": " out of these sort of simple rules and building blocks", "tokens": [51146, 484, 295, 613, 1333, 295, 2199, 4474, 293, 2390, 8474, 51258], "temperature": 0.0, "avg_logprob": -0.1694658088684082, "compression_ratio": 1.7234042553191489, "no_speech_prob": 0.00017950670735444874}, {"id": 781, "seek": 195538, "start": 1973.2600000000002, "end": 1975.1000000000001, "text": " if you just iterate them over again.", "tokens": [51258, 498, 291, 445, 44497, 552, 670, 797, 13, 51350], "temperature": 0.0, "avg_logprob": -0.1694658088684082, "compression_ratio": 1.7234042553191489, "no_speech_prob": 0.00017950670735444874}, {"id": 782, "seek": 195538, "start": 1976.0600000000002, "end": 1980.8600000000001, "text": " That was actually that sort of idea of iterating", "tokens": [51398, 663, 390, 767, 300, 1333, 295, 1558, 295, 17138, 990, 51638], "temperature": 0.0, "avg_logprob": -0.1694658088684082, "compression_ratio": 1.7234042553191489, "no_speech_prob": 0.00017950670735444874}, {"id": 783, "seek": 195538, "start": 1980.8600000000001, "end": 1983.5, "text": " a simple sort of computational rule", "tokens": [51638, 257, 2199, 1333, 295, 28270, 4978, 51770], "temperature": 0.0, "avg_logprob": -0.1694658088684082, "compression_ratio": 1.7234042553191489, "no_speech_prob": 0.00017950670735444874}, {"id": 784, "seek": 198350, "start": 1983.5, "end": 1986.74, "text": " for explaining visual cortex was one of the things", "tokens": [50364, 337, 13468, 5056, 33312, 390, 472, 295, 264, 721, 50526], "temperature": 0.0, "avg_logprob": -0.2115124775813176, "compression_ratio": 1.7875457875457876, "no_speech_prob": 0.0013668080791831017}, {"id": 785, "seek": 198350, "start": 1986.74, "end": 1987.82, "text": " I wrote about in my thesis,", "tokens": [50526, 286, 4114, 466, 294, 452, 22288, 11, 50580], "temperature": 0.0, "avg_logprob": -0.2115124775813176, "compression_ratio": 1.7875457875457876, "no_speech_prob": 0.0013668080791831017}, {"id": 786, "seek": 198350, "start": 1987.82, "end": 1990.86, "text": " but trying to explain like this middle visual cortex,", "tokens": [50580, 457, 1382, 281, 2903, 411, 341, 2808, 5056, 33312, 11, 50732], "temperature": 0.0, "avg_logprob": -0.2115124775813176, "compression_ratio": 1.7875457875457876, "no_speech_prob": 0.0013668080791831017}, {"id": 787, "seek": 198350, "start": 1990.86, "end": 1993.86, "text": " like V4, the responses there using basically", "tokens": [50732, 411, 691, 19, 11, 264, 13019, 456, 1228, 1936, 50882], "temperature": 0.0, "avg_logprob": -0.2115124775813176, "compression_ratio": 1.7875457875457876, "no_speech_prob": 0.0013668080791831017}, {"id": 788, "seek": 198350, "start": 1993.86, "end": 1995.66, "text": " an iterated model of like V1.", "tokens": [50882, 364, 17138, 770, 2316, 295, 411, 691, 16, 13, 50972], "temperature": 0.0, "avg_logprob": -0.2115124775813176, "compression_ratio": 1.7875457875457876, "no_speech_prob": 0.0013668080791831017}, {"id": 789, "seek": 198350, "start": 1995.66, "end": 1999.58, "text": " So the sort of processing in V1, we fairly understood", "tokens": [50972, 407, 264, 1333, 295, 9007, 294, 691, 16, 11, 321, 6457, 7320, 51168], "temperature": 0.0, "avg_logprob": -0.2115124775813176, "compression_ratio": 1.7875457875457876, "no_speech_prob": 0.0013668080791831017}, {"id": 790, "seek": 198350, "start": 1999.58, "end": 2003.3, "text": " if we have the best models of anywhere in visual cortex,", "tokens": [51168, 498, 321, 362, 264, 1151, 5245, 295, 4992, 294, 5056, 33312, 11, 51354], "temperature": 0.0, "avg_logprob": -0.2115124775813176, "compression_ratio": 1.7875457875457876, "no_speech_prob": 0.0013668080791831017}, {"id": 791, "seek": 198350, "start": 2003.3, "end": 2004.82, "text": " maybe even all of cortex.", "tokens": [51354, 1310, 754, 439, 295, 33312, 13, 51430], "temperature": 0.0, "avg_logprob": -0.2115124775813176, "compression_ratio": 1.7875457875457876, "no_speech_prob": 0.0013668080791831017}, {"id": 792, "seek": 198350, "start": 2005.98, "end": 2007.98, "text": " And just sort of iterating the principle again", "tokens": [51488, 400, 445, 1333, 295, 17138, 990, 264, 8665, 797, 51588], "temperature": 0.0, "avg_logprob": -0.2115124775813176, "compression_ratio": 1.7875457875457876, "no_speech_prob": 0.0013668080791831017}, {"id": 793, "seek": 198350, "start": 2007.98, "end": 2010.18, "text": " into V2 is sort of basically just assuming V2", "tokens": [51588, 666, 691, 17, 307, 1333, 295, 1936, 445, 11926, 691, 17, 51698], "temperature": 0.0, "avg_logprob": -0.2115124775813176, "compression_ratio": 1.7875457875457876, "no_speech_prob": 0.0013668080791831017}, {"id": 794, "seek": 198350, "start": 2010.18, "end": 2012.38, "text": " is taking V1 inputs, but doing sort of the similar", "tokens": [51698, 307, 1940, 691, 16, 15743, 11, 457, 884, 1333, 295, 264, 2531, 51808], "temperature": 0.0, "avg_logprob": -0.2115124775813176, "compression_ratio": 1.7875457875457876, "no_speech_prob": 0.0013668080791831017}, {"id": 795, "seek": 201238, "start": 2012.38, "end": 2014.5, "text": " transform and the V4 is taking like V2 inputs", "tokens": [50364, 4088, 293, 264, 691, 19, 307, 1940, 411, 691, 17, 15743, 50470], "temperature": 0.0, "avg_logprob": -0.17506462952186322, "compression_ratio": 1.80078125, "no_speech_prob": 0.0009398152469657362}, {"id": 796, "seek": 201238, "start": 2014.5, "end": 2016.74, "text": " and doing sort of very similar transform.", "tokens": [50470, 293, 884, 1333, 295, 588, 2531, 4088, 13, 50582], "temperature": 0.0, "avg_logprob": -0.17506462952186322, "compression_ratio": 1.80078125, "no_speech_prob": 0.0009398152469657362}, {"id": 797, "seek": 201238, "start": 2018.38, "end": 2023.14, "text": " And sort of the things you see that V4 is sensitive to", "tokens": [50664, 400, 1333, 295, 264, 721, 291, 536, 300, 691, 19, 307, 9477, 281, 50902], "temperature": 0.0, "avg_logprob": -0.17506462952186322, "compression_ratio": 1.80078125, "no_speech_prob": 0.0009398152469657362}, {"id": 798, "seek": 201238, "start": 2023.14, "end": 2025.66, "text": " are these complicated patterns and textures.", "tokens": [50902, 366, 613, 6179, 8294, 293, 24501, 13, 51028], "temperature": 0.0, "avg_logprob": -0.17506462952186322, "compression_ratio": 1.80078125, "no_speech_prob": 0.0009398152469657362}, {"id": 799, "seek": 201238, "start": 2026.5800000000002, "end": 2029.22, "text": " And you get complexity very quickly", "tokens": [51074, 400, 291, 483, 14024, 588, 2661, 51206], "temperature": 0.0, "avg_logprob": -0.17506462952186322, "compression_ratio": 1.80078125, "no_speech_prob": 0.0009398152469657362}, {"id": 800, "seek": 201238, "start": 2029.22, "end": 2031.0600000000002, "text": " from just iterating the sort of simple rules.", "tokens": [51206, 490, 445, 17138, 990, 264, 1333, 295, 2199, 4474, 13, 51298], "temperature": 0.0, "avg_logprob": -0.17506462952186322, "compression_ratio": 1.80078125, "no_speech_prob": 0.0009398152469657362}, {"id": 801, "seek": 201238, "start": 2031.0600000000002, "end": 2032.5, "text": " And I mean, that's what neural networks", "tokens": [51298, 400, 286, 914, 11, 300, 311, 437, 18161, 9590, 51370], "temperature": 0.0, "avg_logprob": -0.17506462952186322, "compression_ratio": 1.80078125, "no_speech_prob": 0.0009398152469657362}, {"id": 802, "seek": 201238, "start": 2032.5, "end": 2034.42, "text": " are essentially doing.", "tokens": [51370, 366, 4476, 884, 13, 51466], "temperature": 0.0, "avg_logprob": -0.17506462952186322, "compression_ratio": 1.80078125, "no_speech_prob": 0.0009398152469657362}, {"id": 803, "seek": 201238, "start": 2034.42, "end": 2036.98, "text": " They're just often just doing linear transforms", "tokens": [51466, 814, 434, 445, 2049, 445, 884, 8213, 35592, 51594], "temperature": 0.0, "avg_logprob": -0.17506462952186322, "compression_ratio": 1.80078125, "no_speech_prob": 0.0009398152469657362}, {"id": 804, "seek": 201238, "start": 2036.98, "end": 2038.8600000000001, "text": " with non-linearities over and over again,", "tokens": [51594, 365, 2107, 12, 28263, 1088, 670, 293, 670, 797, 11, 51688], "temperature": 0.0, "avg_logprob": -0.17506462952186322, "compression_ratio": 1.80078125, "no_speech_prob": 0.0009398152469657362}, {"id": 805, "seek": 201238, "start": 2038.8600000000001, "end": 2041.5800000000002, "text": " just iterating these simple transforms", "tokens": [51688, 445, 17138, 990, 613, 2199, 35592, 51824], "temperature": 0.0, "avg_logprob": -0.17506462952186322, "compression_ratio": 1.80078125, "no_speech_prob": 0.0009398152469657362}, {"id": 806, "seek": 204158, "start": 2041.82, "end": 2044.02, "text": " and building up the complexity very quickly.", "tokens": [50376, 293, 2390, 493, 264, 14024, 588, 2661, 13, 50486], "temperature": 0.0, "avg_logprob": -0.16619063157301683, "compression_ratio": 1.7306397306397305, "no_speech_prob": 0.0002366516855545342}, {"id": 807, "seek": 204158, "start": 2045.02, "end": 2047.02, "text": " Yeah, I think there's something really magical", "tokens": [50536, 865, 11, 286, 519, 456, 311, 746, 534, 12066, 50636], "temperature": 0.0, "avg_logprob": -0.16619063157301683, "compression_ratio": 1.7306397306397305, "no_speech_prob": 0.0002366516855545342}, {"id": 808, "seek": 204158, "start": 2047.02, "end": 2050.98, "text": " about this reflexivity or I mean, a great example of that", "tokens": [50636, 466, 341, 23802, 4253, 420, 286, 914, 11, 257, 869, 1365, 295, 300, 50834], "temperature": 0.0, "avg_logprob": -0.16619063157301683, "compression_ratio": 1.7306397306397305, "no_speech_prob": 0.0002366516855545342}, {"id": 809, "seek": 204158, "start": 2050.98, "end": 2052.86, "text": " are there are graph cellular automators", "tokens": [50834, 366, 456, 366, 4295, 29267, 3553, 3391, 50928], "temperature": 0.0, "avg_logprob": -0.16619063157301683, "compression_ratio": 1.7306397306397305, "no_speech_prob": 0.0002366516855545342}, {"id": 810, "seek": 204158, "start": 2052.86, "end": 2055.7799999999997, "text": " along the lines of Wolfram's digital physics project.", "tokens": [50928, 2051, 264, 3876, 295, 16634, 2356, 311, 4562, 10649, 1716, 13, 51074], "temperature": 0.0, "avg_logprob": -0.16619063157301683, "compression_ratio": 1.7306397306397305, "no_speech_prob": 0.0002366516855545342}, {"id": 811, "seek": 204158, "start": 2055.7799999999997, "end": 2057.74, "text": " And the really clever thing is that you're using", "tokens": [51074, 400, 264, 534, 13494, 551, 307, 300, 291, 434, 1228, 51172], "temperature": 0.0, "avg_logprob": -0.16619063157301683, "compression_ratio": 1.7306397306397305, "no_speech_prob": 0.0002366516855545342}, {"id": 812, "seek": 204158, "start": 2057.74, "end": 2059.22, "text": " the same rules, but you're just kind of like", "tokens": [51172, 264, 912, 4474, 11, 457, 291, 434, 445, 733, 295, 411, 51246], "temperature": 0.0, "avg_logprob": -0.16619063157301683, "compression_ratio": 1.7306397306397305, "no_speech_prob": 0.0002366516855545342}, {"id": 813, "seek": 204158, "start": 2059.22, "end": 2061.74, "text": " running the result again on top, on top.", "tokens": [51246, 2614, 264, 1874, 797, 322, 1192, 11, 322, 1192, 13, 51372], "temperature": 0.0, "avg_logprob": -0.16619063157301683, "compression_ratio": 1.7306397306397305, "no_speech_prob": 0.0002366516855545342}, {"id": 814, "seek": 204158, "start": 2061.74, "end": 2064.74, "text": " And there's a similar version with a graph cellular,", "tokens": [51372, 400, 456, 311, 257, 2531, 3037, 365, 257, 4295, 29267, 11, 51522], "temperature": 0.0, "avg_logprob": -0.16619063157301683, "compression_ratio": 1.7306397306397305, "no_speech_prob": 0.0002366516855545342}, {"id": 815, "seek": 204158, "start": 2064.74, "end": 2067.7799999999997, "text": " sorry, a CNN cellular automata,", "tokens": [51522, 2597, 11, 257, 24859, 29267, 3553, 3274, 11, 51674], "temperature": 0.0, "avg_logprob": -0.16619063157301683, "compression_ratio": 1.7306397306397305, "no_speech_prob": 0.0002366516855545342}, {"id": 816, "seek": 204158, "start": 2067.7799999999997, "end": 2070.18, "text": " where you model something at the microscopic scale", "tokens": [51674, 689, 291, 2316, 746, 412, 264, 47897, 4373, 51794], "temperature": 0.0, "avg_logprob": -0.16619063157301683, "compression_ratio": 1.7306397306397305, "no_speech_prob": 0.0002366516855545342}, {"id": 817, "seek": 207018, "start": 2070.18, "end": 2072.94, "text": " and you get this emergent global phenomenon.", "tokens": [50364, 293, 291, 483, 341, 4345, 6930, 4338, 14029, 13, 50502], "temperature": 0.0, "avg_logprob": -0.13382725315239594, "compression_ratio": 1.610738255033557, "no_speech_prob": 0.0008631084929220378}, {"id": 818, "seek": 207018, "start": 2072.94, "end": 2076.22, "text": " So it might kind of materialize as an image of a gecko", "tokens": [50502, 407, 309, 1062, 733, 295, 2527, 1125, 382, 364, 3256, 295, 257, 1519, 41416, 50666], "temperature": 0.0, "avg_logprob": -0.13382725315239594, "compression_ratio": 1.610738255033557, "no_speech_prob": 0.0008631084929220378}, {"id": 819, "seek": 207018, "start": 2076.22, "end": 2077.06, "text": " or something like that,", "tokens": [50666, 420, 746, 411, 300, 11, 50708], "temperature": 0.0, "avg_logprob": -0.13382725315239594, "compression_ratio": 1.610738255033557, "no_speech_prob": 0.0008631084929220378}, {"id": 820, "seek": 207018, "start": 2077.06, "end": 2079.2999999999997, "text": " but you've actually coded it at the low level.", "tokens": [50708, 457, 291, 600, 767, 34874, 309, 412, 264, 2295, 1496, 13, 50820], "temperature": 0.0, "avg_logprob": -0.13382725315239594, "compression_ratio": 1.610738255033557, "no_speech_prob": 0.0008631084929220378}, {"id": 821, "seek": 207018, "start": 2079.2999999999997, "end": 2082.62, "text": " But yeah, that brings me to this universalist idea", "tokens": [50820, 583, 1338, 11, 300, 5607, 385, 281, 341, 11455, 468, 1558, 50986], "temperature": 0.0, "avg_logprob": -0.13382725315239594, "compression_ratio": 1.610738255033557, "no_speech_prob": 0.0008631084929220378}, {"id": 822, "seek": 207018, "start": 2082.62, "end": 2084.3399999999997, "text": " of let's say how brains work,", "tokens": [50986, 295, 718, 311, 584, 577, 15442, 589, 11, 51072], "temperature": 0.0, "avg_logprob": -0.13382725315239594, "compression_ratio": 1.610738255033557, "no_speech_prob": 0.0008631084929220378}, {"id": 823, "seek": 207018, "start": 2084.3399999999997, "end": 2087.02, "text": " but maybe how neural networks and intelligence work.", "tokens": [51072, 457, 1310, 577, 18161, 9590, 293, 7599, 589, 13, 51206], "temperature": 0.0, "avg_logprob": -0.13382725315239594, "compression_ratio": 1.610738255033557, "no_speech_prob": 0.0008631084929220378}, {"id": 824, "seek": 207018, "start": 2087.02, "end": 2090.14, "text": " Vernon Mount Castle, I read about this in Jeff Hawkins' book.", "tokens": [51206, 47516, 8426, 21076, 11, 286, 1401, 466, 341, 294, 7506, 9325, 10277, 6, 1446, 13, 51362], "temperature": 0.0, "avg_logprob": -0.13382725315239594, "compression_ratio": 1.610738255033557, "no_speech_prob": 0.0008631084929220378}, {"id": 825, "seek": 207018, "start": 2090.14, "end": 2091.7799999999997, "text": " He had this very simple idea of the brain", "tokens": [51362, 634, 632, 341, 588, 2199, 1558, 295, 264, 3567, 51444], "temperature": 0.0, "avg_logprob": -0.13382725315239594, "compression_ratio": 1.610738255033557, "no_speech_prob": 0.0008631084929220378}, {"id": 826, "seek": 207018, "start": 2091.7799999999997, "end": 2096.58, "text": " as being lots of repeated copies of the same circuits", "tokens": [51444, 382, 885, 3195, 295, 10477, 14341, 295, 264, 912, 26354, 51684], "temperature": 0.0, "avg_logprob": -0.13382725315239594, "compression_ratio": 1.610738255033557, "no_speech_prob": 0.0008631084929220378}, {"id": 827, "seek": 207018, "start": 2096.58, "end": 2098.02, "text": " in the neocortex.", "tokens": [51684, 294, 264, 408, 905, 36143, 13, 51756], "temperature": 0.0, "avg_logprob": -0.13382725315239594, "compression_ratio": 1.610738255033557, "no_speech_prob": 0.0008631084929220378}, {"id": 828, "seek": 209802, "start": 2098.02, "end": 2100.94, "text": " And I think this is contested by many neuroscientists,", "tokens": [50364, 400, 286, 519, 341, 307, 10287, 292, 538, 867, 28813, 5412, 1751, 11, 50510], "temperature": 0.0, "avg_logprob": -0.11100814254195601, "compression_ratio": 1.7366548042704626, "no_speech_prob": 0.00032484185067005455}, {"id": 829, "seek": 209802, "start": 2100.94, "end": 2104.14, "text": " but they differ only in how they are wired.", "tokens": [50510, 457, 436, 743, 787, 294, 577, 436, 366, 27415, 13, 50670], "temperature": 0.0, "avg_logprob": -0.11100814254195601, "compression_ratio": 1.7366548042704626, "no_speech_prob": 0.00032484185067005455}, {"id": 830, "seek": 209802, "start": 2104.14, "end": 2105.9, "text": " So they're wired to different, you know,", "tokens": [50670, 407, 436, 434, 27415, 281, 819, 11, 291, 458, 11, 50758], "temperature": 0.0, "avg_logprob": -0.11100814254195601, "compression_ratio": 1.7366548042704626, "no_speech_prob": 0.00032484185067005455}, {"id": 831, "seek": 209802, "start": 2105.9, "end": 2107.66, "text": " sensory motor circuits.", "tokens": [50758, 27233, 5932, 26354, 13, 50846], "temperature": 0.0, "avg_logprob": -0.11100814254195601, "compression_ratio": 1.7366548042704626, "no_speech_prob": 0.00032484185067005455}, {"id": 832, "seek": 209802, "start": 2107.66, "end": 2110.18, "text": " And they're essentially just a copy of the same thing.", "tokens": [50846, 400, 436, 434, 4476, 445, 257, 5055, 295, 264, 912, 551, 13, 50972], "temperature": 0.0, "avg_logprob": -0.11100814254195601, "compression_ratio": 1.7366548042704626, "no_speech_prob": 0.00032484185067005455}, {"id": 833, "seek": 209802, "start": 2110.18, "end": 2113.58, "text": " And as you say, they themselves get called reflexively,", "tokens": [50972, 400, 382, 291, 584, 11, 436, 2969, 483, 1219, 23802, 3413, 11, 51142], "temperature": 0.0, "avg_logprob": -0.11100814254195601, "compression_ratio": 1.7366548042704626, "no_speech_prob": 0.00032484185067005455}, {"id": 834, "seek": 209802, "start": 2113.58, "end": 2115.32, "text": " recursively, and so on.", "tokens": [51142, 20560, 3413, 11, 293, 370, 322, 13, 51229], "temperature": 0.0, "avg_logprob": -0.11100814254195601, "compression_ratio": 1.7366548042704626, "no_speech_prob": 0.00032484185067005455}, {"id": 835, "seek": 209802, "start": 2115.32, "end": 2117.74, "text": " And then you just get this emergent intelligence.", "tokens": [51229, 400, 550, 291, 445, 483, 341, 4345, 6930, 7599, 13, 51350], "temperature": 0.0, "avg_logprob": -0.11100814254195601, "compression_ratio": 1.7366548042704626, "no_speech_prob": 0.00032484185067005455}, {"id": 836, "seek": 209802, "start": 2117.74, "end": 2120.62, "text": " I mean, what's your view on this universalist idea?", "tokens": [51350, 286, 914, 11, 437, 311, 428, 1910, 322, 341, 11455, 468, 1558, 30, 51494], "temperature": 0.0, "avg_logprob": -0.11100814254195601, "compression_ratio": 1.7366548042704626, "no_speech_prob": 0.00032484185067005455}, {"id": 837, "seek": 209802, "start": 2120.62, "end": 2123.58, "text": " I mean, there's definitely not just one circuit.", "tokens": [51494, 286, 914, 11, 456, 311, 2138, 406, 445, 472, 9048, 13, 51642], "temperature": 0.0, "avg_logprob": -0.11100814254195601, "compression_ratio": 1.7366548042704626, "no_speech_prob": 0.00032484185067005455}, {"id": 838, "seek": 209802, "start": 2123.58, "end": 2125.7, "text": " I mean, as you look through the cortex", "tokens": [51642, 286, 914, 11, 382, 291, 574, 807, 264, 33312, 51748], "temperature": 0.0, "avg_logprob": -0.11100814254195601, "compression_ratio": 1.7366548042704626, "no_speech_prob": 0.00032484185067005455}, {"id": 839, "seek": 212570, "start": 2125.7, "end": 2128.02, "text": " in different areas of the brain,", "tokens": [50364, 294, 819, 3179, 295, 264, 3567, 11, 50480], "temperature": 0.0, "avg_logprob": -0.20482122702676742, "compression_ratio": 1.9484126984126984, "no_speech_prob": 0.003375906962901354}, {"id": 840, "seek": 212570, "start": 2128.02, "end": 2129.9399999999996, "text": " just the laminar structure,", "tokens": [50480, 445, 264, 24688, 6470, 3877, 11, 50576], "temperature": 0.0, "avg_logprob": -0.20482122702676742, "compression_ratio": 1.9484126984126984, "no_speech_prob": 0.003375906962901354}, {"id": 841, "seek": 212570, "start": 2129.9399999999996, "end": 2133.02, "text": " which these sort of circuits are like supposed to be,", "tokens": [50576, 597, 613, 1333, 295, 26354, 366, 411, 3442, 281, 312, 11, 50730], "temperature": 0.0, "avg_logprob": -0.20482122702676742, "compression_ratio": 1.9484126984126984, "no_speech_prob": 0.003375906962901354}, {"id": 842, "seek": 212570, "start": 2133.02, "end": 2134.48, "text": " like where the columns are supposed to be,", "tokens": [50730, 411, 689, 264, 13766, 366, 3442, 281, 312, 11, 50803], "temperature": 0.0, "avg_logprob": -0.20482122702676742, "compression_ratio": 1.9484126984126984, "no_speech_prob": 0.003375906962901354}, {"id": 843, "seek": 212570, "start": 2134.48, "end": 2137.6, "text": " where these sort of circuits are supposed to be defined,", "tokens": [50803, 689, 613, 1333, 295, 26354, 366, 3442, 281, 312, 7642, 11, 50959], "temperature": 0.0, "avg_logprob": -0.20482122702676742, "compression_ratio": 1.9484126984126984, "no_speech_prob": 0.003375906962901354}, {"id": 844, "seek": 212570, "start": 2137.6, "end": 2140.9199999999996, "text": " it changes, like, but there are definitely commonalities,", "tokens": [50959, 309, 2962, 11, 411, 11, 457, 456, 366, 2138, 2689, 16110, 11, 51125], "temperature": 0.0, "avg_logprob": -0.20482122702676742, "compression_ratio": 1.9484126984126984, "no_speech_prob": 0.003375906962901354}, {"id": 845, "seek": 212570, "start": 2140.9199999999996, "end": 2142.66, "text": " but there's, I mean, it makes sense", "tokens": [51125, 457, 456, 311, 11, 286, 914, 11, 309, 1669, 2020, 51212], "temperature": 0.0, "avg_logprob": -0.20482122702676742, "compression_ratio": 1.9484126984126984, "no_speech_prob": 0.003375906962901354}, {"id": 846, "seek": 212570, "start": 2142.66, "end": 2144.8999999999996, "text": " that maybe the circuits in different areas", "tokens": [51212, 300, 1310, 264, 26354, 294, 819, 3179, 51324], "temperature": 0.0, "avg_logprob": -0.20482122702676742, "compression_ratio": 1.9484126984126984, "no_speech_prob": 0.003375906962901354}, {"id": 847, "seek": 212570, "start": 2144.8999999999996, "end": 2148.1, "text": " should be slightly different for the different purposes", "tokens": [51324, 820, 312, 4748, 819, 337, 264, 819, 9932, 51484], "temperature": 0.0, "avg_logprob": -0.20482122702676742, "compression_ratio": 1.9484126984126984, "no_speech_prob": 0.003375906962901354}, {"id": 848, "seek": 212570, "start": 2148.1, "end": 2150.9399999999996, "text": " between like prefrontal cortex and say,", "tokens": [51484, 1296, 411, 659, 11496, 304, 33312, 293, 584, 11, 51626], "temperature": 0.0, "avg_logprob": -0.20482122702676742, "compression_ratio": 1.9484126984126984, "no_speech_prob": 0.003375906962901354}, {"id": 849, "seek": 212570, "start": 2150.9399999999996, "end": 2155.02, "text": " where you have much more higher order types", "tokens": [51626, 689, 291, 362, 709, 544, 2946, 1668, 3467, 51830], "temperature": 0.0, "avg_logprob": -0.20482122702676742, "compression_ratio": 1.9484126984126984, "no_speech_prob": 0.003375906962901354}, {"id": 850, "seek": 215502, "start": 2155.06, "end": 2157.7, "text": " of processing going on than like visual cortex", "tokens": [50366, 295, 9007, 516, 322, 813, 411, 5056, 33312, 50498], "temperature": 0.0, "avg_logprob": -0.14275872529442632, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.0006262719398364425}, {"id": 851, "seek": 215502, "start": 2157.7, "end": 2159.62, "text": " or auditory cortex.", "tokens": [50498, 420, 17748, 827, 33312, 13, 50594], "temperature": 0.0, "avg_logprob": -0.14275872529442632, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.0006262719398364425}, {"id": 852, "seek": 215502, "start": 2159.62, "end": 2160.94, "text": " And so there's probably,", "tokens": [50594, 400, 370, 456, 311, 1391, 11, 50660], "temperature": 0.0, "avg_logprob": -0.14275872529442632, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.0006262719398364425}, {"id": 853, "seek": 215502, "start": 2163.34, "end": 2165.34, "text": " if you go in this direction of thinking of some,", "tokens": [50780, 498, 291, 352, 294, 341, 3513, 295, 1953, 295, 512, 11, 50880], "temperature": 0.0, "avg_logprob": -0.14275872529442632, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.0006262719398364425}, {"id": 854, "seek": 215502, "start": 2165.34, "end": 2167.1, "text": " there's like, there's probably a small number", "tokens": [50880, 456, 311, 411, 11, 456, 311, 1391, 257, 1359, 1230, 50968], "temperature": 0.0, "avg_logprob": -0.14275872529442632, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.0006262719398364425}, {"id": 855, "seek": 215502, "start": 2167.1, "end": 2169.06, "text": " of these types of circuits that interact in various ways,", "tokens": [50968, 295, 613, 3467, 295, 26354, 300, 4648, 294, 3683, 2098, 11, 51066], "temperature": 0.0, "avg_logprob": -0.14275872529442632, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.0006262719398364425}, {"id": 856, "seek": 215502, "start": 2169.06, "end": 2171.7, "text": " but there is definitely some specialization going on.", "tokens": [51066, 457, 456, 307, 2138, 512, 2121, 2144, 516, 322, 13, 51198], "temperature": 0.0, "avg_logprob": -0.14275872529442632, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.0006262719398364425}, {"id": 857, "seek": 215502, "start": 2172.86, "end": 2176.42, "text": " Yeah, like, having universalist ideas in biology", "tokens": [51256, 865, 11, 411, 11, 1419, 11455, 468, 3487, 294, 14956, 51434], "temperature": 0.0, "avg_logprob": -0.14275872529442632, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.0006262719398364425}, {"id": 858, "seek": 215502, "start": 2176.42, "end": 2178.3, "text": " never seems to work out that well.", "tokens": [51434, 1128, 2544, 281, 589, 484, 300, 731, 13, 51528], "temperature": 0.0, "avg_logprob": -0.14275872529442632, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.0006262719398364425}, {"id": 859, "seek": 215502, "start": 2178.3, "end": 2180.7, "text": " There's just so much diversity and complexity.", "tokens": [51528, 821, 311, 445, 370, 709, 8811, 293, 14024, 13, 51648], "temperature": 0.0, "avg_logprob": -0.14275872529442632, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.0006262719398364425}, {"id": 860, "seek": 215502, "start": 2180.7, "end": 2182.46, "text": " It would be nice if we could reduce everything", "tokens": [51648, 467, 576, 312, 1481, 498, 321, 727, 5407, 1203, 51736], "temperature": 0.0, "avg_logprob": -0.14275872529442632, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.0006262719398364425}, {"id": 861, "seek": 215502, "start": 2182.46, "end": 2184.3, "text": " down to like, it's one thing repeated over,", "tokens": [51736, 760, 281, 411, 11, 309, 311, 472, 551, 10477, 670, 11, 51828], "temperature": 0.0, "avg_logprob": -0.14275872529442632, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.0006262719398364425}, {"id": 862, "seek": 218430, "start": 2184.3, "end": 2188.6600000000003, "text": " but like generally, it never works out quite as cleanly as that.", "tokens": [50364, 457, 411, 5101, 11, 309, 1128, 1985, 484, 1596, 382, 2541, 356, 382, 300, 13, 50582], "temperature": 0.0, "avg_logprob": -0.20842035151710195, "compression_ratio": 1.6236162361623616, "no_speech_prob": 0.00015100918244570494}, {"id": 863, "seek": 218430, "start": 2189.7000000000003, "end": 2191.26, "text": " Yeah, again, it's our desire", "tokens": [50634, 865, 11, 797, 11, 309, 311, 527, 7516, 50712], "temperature": 0.0, "avg_logprob": -0.20842035151710195, "compression_ratio": 1.6236162361623616, "no_speech_prob": 0.00015100918244570494}, {"id": 864, "seek": 218430, "start": 2191.26, "end": 2192.7000000000003, "text": " to have an intelligible framework.", "tokens": [50712, 281, 362, 364, 5613, 964, 8388, 13, 50784], "temperature": 0.0, "avg_logprob": -0.20842035151710195, "compression_ratio": 1.6236162361623616, "no_speech_prob": 0.00015100918244570494}, {"id": 865, "seek": 218430, "start": 2192.7000000000003, "end": 2194.1000000000004, "text": " And I mean, the free energy principle,", "tokens": [50784, 400, 286, 914, 11, 264, 1737, 2281, 8665, 11, 50854], "temperature": 0.0, "avg_logprob": -0.20842035151710195, "compression_ratio": 1.6236162361623616, "no_speech_prob": 0.00015100918244570494}, {"id": 866, "seek": 218430, "start": 2194.1000000000004, "end": 2195.6600000000003, "text": " you could argue as a theory of everything,", "tokens": [50854, 291, 727, 9695, 382, 257, 5261, 295, 1203, 11, 50932], "temperature": 0.0, "avg_logprob": -0.20842035151710195, "compression_ratio": 1.6236162361623616, "no_speech_prob": 0.00015100918244570494}, {"id": 867, "seek": 218430, "start": 2195.6600000000003, "end": 2198.34, "text": " but there's, I mean, Stephen Wolfram's example,", "tokens": [50932, 457, 456, 311, 11, 286, 914, 11, 13391, 16634, 2356, 311, 1365, 11, 51066], "temperature": 0.0, "avg_logprob": -0.20842035151710195, "compression_ratio": 1.6236162361623616, "no_speech_prob": 0.00015100918244570494}, {"id": 868, "seek": 218430, "start": 2198.34, "end": 2201.2200000000003, "text": " and even Eric Weinstein's geometric unity.", "tokens": [51066, 293, 754, 9336, 34477, 9089, 311, 33246, 18205, 13, 51210], "temperature": 0.0, "avg_logprob": -0.20842035151710195, "compression_ratio": 1.6236162361623616, "no_speech_prob": 0.00015100918244570494}, {"id": 869, "seek": 218430, "start": 2201.2200000000003, "end": 2203.6200000000003, "text": " I mean, there are many theories of everything.", "tokens": [51210, 286, 914, 11, 456, 366, 867, 13667, 295, 1203, 13, 51330], "temperature": 0.0, "avg_logprob": -0.20842035151710195, "compression_ratio": 1.6236162361623616, "no_speech_prob": 0.00015100918244570494}, {"id": 870, "seek": 218430, "start": 2204.5, "end": 2207.42, "text": " But yeah, what do you think is the role of language", "tokens": [51374, 583, 1338, 11, 437, 360, 291, 519, 307, 264, 3090, 295, 2856, 51520], "temperature": 0.0, "avg_logprob": -0.20842035151710195, "compression_ratio": 1.6236162361623616, "no_speech_prob": 0.00015100918244570494}, {"id": 871, "seek": 218430, "start": 2207.42, "end": 2209.42, "text": " in cognition and thinking and planning?", "tokens": [51520, 294, 46905, 293, 1953, 293, 5038, 30, 51620], "temperature": 0.0, "avg_logprob": -0.20842035151710195, "compression_ratio": 1.6236162361623616, "no_speech_prob": 0.00015100918244570494}, {"id": 872, "seek": 220942, "start": 2210.42, "end": 2214.02, "text": " Um, that's, it's a really interesting question.", "tokens": [50414, 3301, 11, 300, 311, 11, 309, 311, 257, 534, 1880, 1168, 13, 50594], "temperature": 0.0, "avg_logprob": -0.2181753106073502, "compression_ratio": 1.7081545064377683, "no_speech_prob": 0.004198214039206505}, {"id": 873, "seek": 220942, "start": 2215.3, "end": 2218.1, "text": " It's, and it's also, I think, a kind of hard one to answer", "tokens": [50658, 467, 311, 11, 293, 309, 311, 611, 11, 286, 519, 11, 257, 733, 295, 1152, 472, 281, 1867, 50798], "temperature": 0.0, "avg_logprob": -0.2181753106073502, "compression_ratio": 1.7081545064377683, "no_speech_prob": 0.004198214039206505}, {"id": 874, "seek": 220942, "start": 2218.1, "end": 2221.9, "text": " in the sense that if you, I've seen some recent reports", "tokens": [50798, 294, 264, 2020, 300, 498, 291, 11, 286, 600, 1612, 512, 5162, 7122, 50988], "temperature": 0.0, "avg_logprob": -0.2181753106073502, "compression_ratio": 1.7081545064377683, "no_speech_prob": 0.004198214039206505}, {"id": 875, "seek": 220942, "start": 2221.9, "end": 2226.62, "text": " just like talking about like, other people asking,", "tokens": [50988, 445, 411, 1417, 466, 411, 11, 661, 561, 3365, 11, 51224], "temperature": 0.0, "avg_logprob": -0.2181753106073502, "compression_ratio": 1.7081545064377683, "no_speech_prob": 0.004198214039206505}, {"id": 876, "seek": 220942, "start": 2226.62, "end": 2228.62, "text": " like survey questions to other people", "tokens": [51224, 411, 8984, 1651, 281, 661, 561, 51324], "temperature": 0.0, "avg_logprob": -0.2181753106073502, "compression_ratio": 1.7081545064377683, "no_speech_prob": 0.004198214039206505}, {"id": 877, "seek": 220942, "start": 2228.62, "end": 2231.58, "text": " and finding some people like, don't have an interior monologue", "tokens": [51324, 293, 5006, 512, 561, 411, 11, 500, 380, 362, 364, 10636, 1108, 42298, 51472], "temperature": 0.0, "avg_logprob": -0.2181753106073502, "compression_ratio": 1.7081545064377683, "no_speech_prob": 0.004198214039206505}, {"id": 878, "seek": 220942, "start": 2231.58, "end": 2233.62, "text": " in the same way you might think.", "tokens": [51472, 294, 264, 912, 636, 291, 1062, 519, 13, 51574], "temperature": 0.0, "avg_logprob": -0.2181753106073502, "compression_ratio": 1.7081545064377683, "no_speech_prob": 0.004198214039206505}, {"id": 879, "seek": 220942, "start": 2233.62, "end": 2236.06, "text": " And just like, there's actually a lot of diversity", "tokens": [51574, 400, 445, 411, 11, 456, 311, 767, 257, 688, 295, 8811, 51696], "temperature": 0.0, "avg_logprob": -0.2181753106073502, "compression_ratio": 1.7081545064377683, "no_speech_prob": 0.004198214039206505}, {"id": 880, "seek": 223606, "start": 2236.38, "end": 2239.86, "text": " in like people's level of internal monologues.", "tokens": [50380, 294, 411, 561, 311, 1496, 295, 6920, 1108, 1132, 1247, 13, 50554], "temperature": 0.0, "avg_logprob": -0.14929200782150517, "compression_ratio": 1.7881355932203389, "no_speech_prob": 0.010984166525304317}, {"id": 881, "seek": 223606, "start": 2239.86, "end": 2242.34, "text": " And they've done studies where they have this like little,", "tokens": [50554, 400, 436, 600, 1096, 5313, 689, 436, 362, 341, 411, 707, 11, 50678], "temperature": 0.0, "avg_logprob": -0.14929200782150517, "compression_ratio": 1.7881355932203389, "no_speech_prob": 0.010984166525304317}, {"id": 882, "seek": 223606, "start": 2242.34, "end": 2244.5, "text": " like beepers go off and people are supposed to write", "tokens": [50678, 411, 28678, 433, 352, 766, 293, 561, 366, 3442, 281, 2464, 50786], "temperature": 0.0, "avg_logprob": -0.14929200782150517, "compression_ratio": 1.7881355932203389, "no_speech_prob": 0.010984166525304317}, {"id": 883, "seek": 223606, "start": 2244.5, "end": 2245.5, "text": " what's going on in their mind.", "tokens": [50786, 437, 311, 516, 322, 294, 641, 1575, 13, 50836], "temperature": 0.0, "avg_logprob": -0.14929200782150517, "compression_ratio": 1.7881355932203389, "no_speech_prob": 0.010984166525304317}, {"id": 884, "seek": 223606, "start": 2245.5, "end": 2250.06, "text": " And so it's, and yeah, and just with visual imagery,", "tokens": [50836, 400, 370, 309, 311, 11, 293, 1338, 11, 293, 445, 365, 5056, 24340, 11, 51064], "temperature": 0.0, "avg_logprob": -0.14929200782150517, "compression_ratio": 1.7881355932203389, "no_speech_prob": 0.010984166525304317}, {"id": 885, "seek": 223606, "start": 2250.06, "end": 2253.06, "text": " we find that it's a huge like variety in how much,", "tokens": [51064, 321, 915, 300, 309, 311, 257, 2603, 411, 5673, 294, 577, 709, 11, 51214], "temperature": 0.0, "avg_logprob": -0.14929200782150517, "compression_ratio": 1.7881355932203389, "no_speech_prob": 0.010984166525304317}, {"id": 886, "seek": 223606, "start": 2253.06, "end": 2255.74, "text": " like how strong people rate their visual imagery.", "tokens": [51214, 411, 577, 2068, 561, 3314, 641, 5056, 24340, 13, 51348], "temperature": 0.0, "avg_logprob": -0.14929200782150517, "compression_ratio": 1.7881355932203389, "no_speech_prob": 0.010984166525304317}, {"id": 887, "seek": 223606, "start": 2255.74, "end": 2260.34, "text": " And so, I mean, yeah, some people, I mean,", "tokens": [51348, 400, 370, 11, 286, 914, 11, 1338, 11, 512, 561, 11, 286, 914, 11, 51578], "temperature": 0.0, "avg_logprob": -0.14929200782150517, "compression_ratio": 1.7881355932203389, "no_speech_prob": 0.010984166525304317}, {"id": 888, "seek": 223606, "start": 2260.34, "end": 2263.86, "text": " me personally, I have both, I mean,", "tokens": [51578, 385, 5665, 11, 286, 362, 1293, 11, 286, 914, 11, 51754], "temperature": 0.0, "avg_logprob": -0.14929200782150517, "compression_ratio": 1.7881355932203389, "no_speech_prob": 0.010984166525304317}, {"id": 889, "seek": 226386, "start": 2263.86, "end": 2266.1400000000003, "text": " pretty strong interior monologue,", "tokens": [50364, 1238, 2068, 10636, 1108, 42298, 11, 50478], "temperature": 0.0, "avg_logprob": -0.1659165960158745, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.09259352087974548}, {"id": 890, "seek": 226386, "start": 2266.1400000000003, "end": 2268.2200000000003, "text": " but I also feel like a lot of ideas", "tokens": [50478, 457, 286, 611, 841, 411, 257, 688, 295, 3487, 50582], "temperature": 0.0, "avg_logprob": -0.1659165960158745, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.09259352087974548}, {"id": 891, "seek": 226386, "start": 2268.2200000000003, "end": 2270.78, "text": " are in this sort of pre-linguistic state.", "tokens": [50582, 366, 294, 341, 1333, 295, 659, 12, 1688, 84, 3142, 1785, 13, 50710], "temperature": 0.0, "avg_logprob": -0.1659165960158745, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.09259352087974548}, {"id": 892, "seek": 226386, "start": 2270.78, "end": 2274.46, "text": " And I'm kind of like searching for the words for them often.", "tokens": [50710, 400, 286, 478, 733, 295, 411, 10808, 337, 264, 2283, 337, 552, 2049, 13, 50894], "temperature": 0.0, "avg_logprob": -0.1659165960158745, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.09259352087974548}, {"id": 893, "seek": 226386, "start": 2274.46, "end": 2277.2200000000003, "text": " And there's definitely kind of continuum there.", "tokens": [50894, 400, 456, 311, 2138, 733, 295, 36120, 456, 13, 51032], "temperature": 0.0, "avg_logprob": -0.1659165960158745, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.09259352087974548}, {"id": 894, "seek": 226386, "start": 2278.38, "end": 2282.7000000000003, "text": " It's weird to think like, how do we get the words", "tokens": [51090, 467, 311, 3657, 281, 519, 411, 11, 577, 360, 321, 483, 264, 2283, 51306], "temperature": 0.0, "avg_logprob": -0.1659165960158745, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.09259352087974548}, {"id": 895, "seek": 226386, "start": 2282.7000000000003, "end": 2284.9, "text": " that we're saying, where the words come from", "tokens": [51306, 300, 321, 434, 1566, 11, 689, 264, 2283, 808, 490, 51416], "temperature": 0.0, "avg_logprob": -0.1659165960158745, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.09259352087974548}, {"id": 896, "seek": 226386, "start": 2284.9, "end": 2285.86, "text": " that are coming out of our mouth?", "tokens": [51416, 300, 366, 1348, 484, 295, 527, 4525, 30, 51464], "temperature": 0.0, "avg_logprob": -0.1659165960158745, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.09259352087974548}, {"id": 897, "seek": 226386, "start": 2285.86, "end": 2287.58, "text": " Are we really choosing them?", "tokens": [51464, 2014, 321, 534, 10875, 552, 30, 51550], "temperature": 0.0, "avg_logprob": -0.1659165960158745, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.09259352087974548}, {"id": 898, "seek": 226386, "start": 2287.58, "end": 2288.82, "text": " You're definitely not choosing them", "tokens": [51550, 509, 434, 2138, 406, 10875, 552, 51612], "temperature": 0.0, "avg_logprob": -0.1659165960158745, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.09259352087974548}, {"id": 899, "seek": 226386, "start": 2288.82, "end": 2289.9, "text": " in this sort of top-down way.", "tokens": [51612, 294, 341, 1333, 295, 1192, 12, 5093, 636, 13, 51666], "temperature": 0.0, "avg_logprob": -0.1659165960158745, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.09259352087974548}, {"id": 900, "seek": 226386, "start": 2289.9, "end": 2292.6200000000003, "text": " They just sort of seem to come out.", "tokens": [51666, 814, 445, 1333, 295, 1643, 281, 808, 484, 13, 51802], "temperature": 0.0, "avg_logprob": -0.1659165960158745, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.09259352087974548}, {"id": 901, "seek": 229262, "start": 2292.62, "end": 2295.9, "text": " And you just kind of point yourself in the right direction", "tokens": [50364, 400, 291, 445, 733, 295, 935, 1803, 294, 264, 558, 3513, 50528], "temperature": 0.0, "avg_logprob": -0.19221639218537703, "compression_ratio": 1.6753731343283582, "no_speech_prob": 0.0004581281973514706}, {"id": 902, "seek": 229262, "start": 2295.9, "end": 2298.14, "text": " and hope the best as they come out.", "tokens": [50528, 293, 1454, 264, 1151, 382, 436, 808, 484, 13, 50640], "temperature": 0.0, "avg_logprob": -0.19221639218537703, "compression_ratio": 1.6753731343283582, "no_speech_prob": 0.0004581281973514706}, {"id": 903, "seek": 229262, "start": 2299.3399999999997, "end": 2301.18, "text": " And, but this has a very different quality,", "tokens": [50700, 400, 11, 457, 341, 575, 257, 588, 819, 3125, 11, 50792], "temperature": 0.0, "avg_logprob": -0.19221639218537703, "compression_ratio": 1.6753731343283582, "no_speech_prob": 0.0004581281973514706}, {"id": 904, "seek": 229262, "start": 2301.18, "end": 2303.74, "text": " like when you're just speaking phenomenologically,", "tokens": [50792, 411, 562, 291, 434, 445, 4124, 9388, 17157, 11, 50920], "temperature": 0.0, "avg_logprob": -0.19221639218537703, "compression_ratio": 1.6753731343283582, "no_speech_prob": 0.0004581281973514706}, {"id": 905, "seek": 229262, "start": 2303.74, "end": 2305.74, "text": " it feels very different to when you're just sort of", "tokens": [50920, 309, 3417, 588, 819, 281, 562, 291, 434, 445, 1333, 295, 51020], "temperature": 0.0, "avg_logprob": -0.19221639218537703, "compression_ratio": 1.6753731343283582, "no_speech_prob": 0.0004581281973514706}, {"id": 906, "seek": 229262, "start": 2305.74, "end": 2307.58, "text": " thinking yourself, what should I do today?", "tokens": [51020, 1953, 1803, 11, 437, 820, 286, 360, 965, 30, 51112], "temperature": 0.0, "avg_logprob": -0.19221639218537703, "compression_ratio": 1.6753731343283582, "no_speech_prob": 0.0004581281973514706}, {"id": 907, "seek": 229262, "start": 2307.58, "end": 2308.7799999999997, "text": " Should I go to the store?", "tokens": [51112, 6454, 286, 352, 281, 264, 3531, 30, 51172], "temperature": 0.0, "avg_logprob": -0.19221639218537703, "compression_ratio": 1.6753731343283582, "no_speech_prob": 0.0004581281973514706}, {"id": 908, "seek": 229262, "start": 2309.8599999999997, "end": 2313.46, "text": " And so, I mean, yeah, the way in which language", "tokens": [51226, 400, 370, 11, 286, 914, 11, 1338, 11, 264, 636, 294, 597, 2856, 51406], "temperature": 0.0, "avg_logprob": -0.19221639218537703, "compression_ratio": 1.6753731343283582, "no_speech_prob": 0.0004581281973514706}, {"id": 909, "seek": 229262, "start": 2313.46, "end": 2316.18, "text": " interacts with thoughts and behavior", "tokens": [51406, 43582, 365, 4598, 293, 5223, 51542], "temperature": 0.0, "avg_logprob": -0.19221639218537703, "compression_ratio": 1.6753731343283582, "no_speech_prob": 0.0004581281973514706}, {"id": 910, "seek": 229262, "start": 2316.18, "end": 2321.18, "text": " and verbal communication, it's definitely not simple.", "tokens": [51542, 293, 24781, 6101, 11, 309, 311, 2138, 406, 2199, 13, 51792], "temperature": 0.0, "avg_logprob": -0.19221639218537703, "compression_ratio": 1.6753731343283582, "no_speech_prob": 0.0004581281973514706}, {"id": 911, "seek": 232262, "start": 2323.38, "end": 2327.2999999999997, "text": " And yeah, there's, I mean, definitely this kind of continuum.", "tokens": [50402, 400, 1338, 11, 456, 311, 11, 286, 914, 11, 2138, 341, 733, 295, 36120, 13, 50598], "temperature": 0.0, "avg_logprob": -0.16593275678918717, "compression_ratio": 2.109433962264151, "no_speech_prob": 0.0021478182170540094}, {"id": 912, "seek": 232262, "start": 2327.2999999999997, "end": 2330.38, "text": " I mean, it's all, it's, to me, I just sort of think", "tokens": [50598, 286, 914, 11, 309, 311, 439, 11, 309, 311, 11, 281, 385, 11, 286, 445, 1333, 295, 519, 50752], "temperature": 0.0, "avg_logprob": -0.16593275678918717, "compression_ratio": 2.109433962264151, "no_speech_prob": 0.0021478182170540094}, {"id": 913, "seek": 232262, "start": 2330.38, "end": 2332.42, "text": " it's with all these sort of networks kind of interacting.", "tokens": [50752, 309, 311, 365, 439, 613, 1333, 295, 9590, 733, 295, 18017, 13, 50854], "temperature": 0.0, "avg_logprob": -0.16593275678918717, "compression_ratio": 2.109433962264151, "no_speech_prob": 0.0021478182170540094}, {"id": 914, "seek": 232262, "start": 2332.42, "end": 2335.2999999999997, "text": " And sometimes you're like triggering the kind of language", "tokens": [50854, 400, 2171, 291, 434, 411, 40406, 264, 733, 295, 2856, 50998], "temperature": 0.0, "avg_logprob": -0.16593275678918717, "compression_ratio": 2.109433962264151, "no_speech_prob": 0.0021478182170540094}, {"id": 915, "seek": 232262, "start": 2335.2999999999997, "end": 2336.94, "text": " things and you're just making these kind of patterns.", "tokens": [50998, 721, 293, 291, 434, 445, 1455, 613, 733, 295, 8294, 13, 51080], "temperature": 0.0, "avg_logprob": -0.16593275678918717, "compression_ratio": 2.109433962264151, "no_speech_prob": 0.0021478182170540094}, {"id": 916, "seek": 232262, "start": 2336.94, "end": 2339.2999999999997, "text": " And sometimes the language patterns you're activating", "tokens": [51080, 400, 2171, 264, 2856, 8294, 291, 434, 42481, 51198], "temperature": 0.0, "avg_logprob": -0.16593275678918717, "compression_ratio": 2.109433962264151, "no_speech_prob": 0.0021478182170540094}, {"id": 917, "seek": 232262, "start": 2339.2999999999997, "end": 2341.8599999999997, "text": " are helping activate other things as well.", "tokens": [51198, 366, 4315, 13615, 661, 721, 382, 731, 13, 51326], "temperature": 0.0, "avg_logprob": -0.16593275678918717, "compression_ratio": 2.109433962264151, "no_speech_prob": 0.0021478182170540094}, {"id": 918, "seek": 232262, "start": 2341.8599999999997, "end": 2344.3399999999997, "text": " Sometimes you can just be in this kind of less-linguistic state", "tokens": [51326, 4803, 291, 393, 445, 312, 294, 341, 733, 295, 1570, 12, 1688, 84, 3142, 1785, 51450], "temperature": 0.0, "avg_logprob": -0.16593275678918717, "compression_ratio": 2.109433962264151, "no_speech_prob": 0.0021478182170540094}, {"id": 919, "seek": 232262, "start": 2344.3399999999997, "end": 2347.94, "text": " where you just kind of, just sort of sensing these patterns", "tokens": [51450, 689, 291, 445, 733, 295, 11, 445, 1333, 295, 30654, 613, 8294, 51630], "temperature": 0.0, "avg_logprob": -0.16593275678918717, "compression_ratio": 2.109433962264151, "no_speech_prob": 0.0021478182170540094}, {"id": 920, "seek": 232262, "start": 2347.94, "end": 2350.3399999999997, "text": " and you just have this kind of like wandering thoughts", "tokens": [51630, 293, 291, 445, 362, 341, 733, 295, 411, 26396, 4598, 51750], "temperature": 0.0, "avg_logprob": -0.16593275678918717, "compression_ratio": 2.109433962264151, "no_speech_prob": 0.0021478182170540094}, {"id": 921, "seek": 235034, "start": 2350.42, "end": 2353.26, "text": " that aren't necessarily linguistic.", "tokens": [50368, 300, 3212, 380, 4725, 43002, 13, 50510], "temperature": 0.0, "avg_logprob": -0.17521361481371545, "compression_ratio": 1.7201365187713311, "no_speech_prob": 0.0013238637475296855}, {"id": 922, "seek": 235034, "start": 2354.54, "end": 2357.6200000000003, "text": " But yeah, it's definitely, I mean, and also it seems,", "tokens": [50574, 583, 1338, 11, 309, 311, 2138, 11, 286, 914, 11, 293, 611, 309, 2544, 11, 50728], "temperature": 0.0, "avg_logprob": -0.17521361481371545, "compression_ratio": 1.7201365187713311, "no_speech_prob": 0.0013238637475296855}, {"id": 923, "seek": 235034, "start": 2357.6200000000003, "end": 2361.06, "text": " yeah, as I said, people's, the way people do this", "tokens": [50728, 1338, 11, 382, 286, 848, 11, 561, 311, 11, 264, 636, 561, 360, 341, 50900], "temperature": 0.0, "avg_logprob": -0.17521361481371545, "compression_ratio": 1.7201365187713311, "no_speech_prob": 0.0013238637475296855}, {"id": 924, "seek": 235034, "start": 2361.06, "end": 2362.5, "text": " like seems all over the place.", "tokens": [50900, 411, 2544, 439, 670, 264, 1081, 13, 50972], "temperature": 0.0, "avg_logprob": -0.17521361481371545, "compression_ratio": 1.7201365187713311, "no_speech_prob": 0.0013238637475296855}, {"id": 925, "seek": 235034, "start": 2362.5, "end": 2366.42, "text": " And so there's not sort of even one answer for even one person", "tokens": [50972, 400, 370, 456, 311, 406, 1333, 295, 754, 472, 1867, 337, 754, 472, 954, 51168], "temperature": 0.0, "avg_logprob": -0.17521361481371545, "compression_ratio": 1.7201365187713311, "no_speech_prob": 0.0013238637475296855}, {"id": 926, "seek": 235034, "start": 2366.42, "end": 2368.2200000000003, "text": " or definitely not across all people.", "tokens": [51168, 420, 2138, 406, 2108, 439, 561, 13, 51258], "temperature": 0.0, "avg_logprob": -0.17521361481371545, "compression_ratio": 1.7201365187713311, "no_speech_prob": 0.0013238637475296855}, {"id": 927, "seek": 235034, "start": 2369.1800000000003, "end": 2370.9, "text": " Yeah, I'm really interested in this idea", "tokens": [51306, 865, 11, 286, 478, 534, 3102, 294, 341, 1558, 51392], "temperature": 0.0, "avg_logprob": -0.17521361481371545, "compression_ratio": 1.7201365187713311, "no_speech_prob": 0.0013238637475296855}, {"id": 928, "seek": 235034, "start": 2370.9, "end": 2373.94, "text": " of differential kind of subjective experiences.", "tokens": [51392, 295, 15756, 733, 295, 25972, 5235, 13, 51544], "temperature": 0.0, "avg_logprob": -0.17521361481371545, "compression_ratio": 1.7201365187713311, "no_speech_prob": 0.0013238637475296855}, {"id": 929, "seek": 235034, "start": 2373.94, "end": 2375.98, "text": " And you know, like there was that Nagel paper", "tokens": [51544, 400, 291, 458, 11, 411, 456, 390, 300, 18913, 338, 3035, 51646], "temperature": 0.0, "avg_logprob": -0.17521361481371545, "compression_ratio": 1.7201365187713311, "no_speech_prob": 0.0013238637475296855}, {"id": 930, "seek": 235034, "start": 2375.98, "end": 2377.2200000000003, "text": " about what does it like to be a bat?", "tokens": [51646, 466, 437, 775, 309, 411, 281, 312, 257, 7362, 30, 51708], "temperature": 0.0, "avg_logprob": -0.17521361481371545, "compression_ratio": 1.7201365187713311, "no_speech_prob": 0.0013238637475296855}, {"id": 931, "seek": 235034, "start": 2377.2200000000003, "end": 2378.98, "text": " But even with the human experience,", "tokens": [51708, 583, 754, 365, 264, 1952, 1752, 11, 51796], "temperature": 0.0, "avg_logprob": -0.17521361481371545, "compression_ratio": 1.7201365187713311, "no_speech_prob": 0.0013238637475296855}, {"id": 932, "seek": 235034, "start": 2378.98, "end": 2380.1400000000003, "text": " we're all very different.", "tokens": [51796, 321, 434, 439, 588, 819, 13, 51854], "temperature": 0.0, "avg_logprob": -0.17521361481371545, "compression_ratio": 1.7201365187713311, "no_speech_prob": 0.0013238637475296855}, {"id": 933, "seek": 238014, "start": 2380.14, "end": 2381.74, "text": " You said about your internal monologue", "tokens": [50364, 509, 848, 466, 428, 6920, 1108, 42298, 50444], "temperature": 0.0, "avg_logprob": -0.15241926944617068, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0005014468915760517}, {"id": 934, "seek": 238014, "start": 2381.74, "end": 2382.8199999999997, "text": " and I hadn't really thought about", "tokens": [50444, 293, 286, 8782, 380, 534, 1194, 466, 50498], "temperature": 0.0, "avg_logprob": -0.15241926944617068, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0005014468915760517}, {"id": 935, "seek": 238014, "start": 2382.8199999999997, "end": 2383.7799999999997, "text": " how that might be different.", "tokens": [50498, 577, 300, 1062, 312, 819, 13, 50546], "temperature": 0.0, "avg_logprob": -0.15241926944617068, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0005014468915760517}, {"id": 936, "seek": 238014, "start": 2383.7799999999997, "end": 2386.8599999999997, "text": " But I was drawing a picture in a Valentine's card earlier", "tokens": [50546, 583, 286, 390, 6316, 257, 3036, 294, 257, 24359, 311, 2920, 3071, 50700], "temperature": 0.0, "avg_logprob": -0.15241926944617068, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0005014468915760517}, {"id": 937, "seek": 238014, "start": 2386.8599999999997, "end": 2388.8199999999997, "text": " and it was so terribly bad.", "tokens": [50700, 293, 309, 390, 370, 22903, 1578, 13, 50798], "temperature": 0.0, "avg_logprob": -0.15241926944617068, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0005014468915760517}, {"id": 938, "seek": 238014, "start": 2388.8199999999997, "end": 2390.3799999999997, "text": " And some of my friends are really good artists", "tokens": [50798, 400, 512, 295, 452, 1855, 366, 534, 665, 6910, 50876], "temperature": 0.0, "avg_logprob": -0.15241926944617068, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0005014468915760517}, {"id": 939, "seek": 238014, "start": 2390.3799999999997, "end": 2392.62, "text": " and I was kind of thinking to myself at the time,", "tokens": [50876, 293, 286, 390, 733, 295, 1953, 281, 2059, 412, 264, 565, 11, 50988], "temperature": 0.0, "avg_logprob": -0.15241926944617068, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0005014468915760517}, {"id": 940, "seek": 238014, "start": 2392.62, "end": 2395.1, "text": " maybe this is just a, this is just me.", "tokens": [50988, 1310, 341, 307, 445, 257, 11, 341, 307, 445, 385, 13, 51112], "temperature": 0.0, "avg_logprob": -0.15241926944617068, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0005014468915760517}, {"id": 941, "seek": 238014, "start": 2395.1, "end": 2397.7799999999997, "text": " I can't really visualize things in my mind very well.", "tokens": [51112, 286, 393, 380, 534, 23273, 721, 294, 452, 1575, 588, 731, 13, 51246], "temperature": 0.0, "avg_logprob": -0.15241926944617068, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0005014468915760517}, {"id": 942, "seek": 238014, "start": 2397.7799999999997, "end": 2399.06, "text": " I've got a very analytical brain.", "tokens": [51246, 286, 600, 658, 257, 588, 29579, 3567, 13, 51310], "temperature": 0.0, "avg_logprob": -0.15241926944617068, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0005014468915760517}, {"id": 943, "seek": 238014, "start": 2399.06, "end": 2400.1, "text": " Won't mean that certainly", "tokens": [51310, 14710, 380, 914, 300, 3297, 51362], "temperature": 0.0, "avg_logprob": -0.15241926944617068, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0005014468915760517}, {"id": 944, "seek": 238014, "start": 2400.1, "end": 2402.2999999999997, "text": " when not under the influence of psychoactive drugs anyway.", "tokens": [51362, 562, 406, 833, 264, 6503, 295, 33355, 12596, 7766, 4033, 13, 51472], "temperature": 0.0, "avg_logprob": -0.15241926944617068, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0005014468915760517}, {"id": 945, "seek": 238014, "start": 2402.2999999999997, "end": 2404.9, "text": " But you know what I mean.", "tokens": [51472, 583, 291, 458, 437, 286, 914, 13, 51602], "temperature": 0.0, "avg_logprob": -0.15241926944617068, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0005014468915760517}, {"id": 946, "seek": 238014, "start": 2404.9, "end": 2407.14, "text": " So we all have a very different subject of experience", "tokens": [51602, 407, 321, 439, 362, 257, 588, 819, 3983, 295, 1752, 51714], "temperature": 0.0, "avg_logprob": -0.15241926944617068, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0005014468915760517}, {"id": 947, "seek": 238014, "start": 2407.14, "end": 2410.02, "text": " but the miracle is we can understand each other", "tokens": [51714, 457, 264, 14660, 307, 321, 393, 1223, 1184, 661, 51858], "temperature": 0.0, "avg_logprob": -0.15241926944617068, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0005014468915760517}, {"id": 948, "seek": 241002, "start": 2410.06, "end": 2410.9, "text": " so well.", "tokens": [50366, 370, 731, 13, 50408], "temperature": 0.0, "avg_logprob": -0.26674719723788176, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.0037054414860904217}, {"id": 949, "seek": 241002, "start": 2410.9, "end": 2413.2599999999998, "text": " So you would expect there to be an incredible amount", "tokens": [50408, 407, 291, 576, 2066, 456, 281, 312, 364, 4651, 2372, 50526], "temperature": 0.0, "avg_logprob": -0.26674719723788176, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.0037054414860904217}, {"id": 950, "seek": 241002, "start": 2413.2599999999998, "end": 2415.9, "text": " of Britanness in our communication, but there isn't.", "tokens": [50526, 295, 4760, 969, 442, 294, 527, 6101, 11, 457, 456, 1943, 380, 13, 50658], "temperature": 0.0, "avg_logprob": -0.26674719723788176, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.0037054414860904217}, {"id": 951, "seek": 241002, "start": 2417.54, "end": 2422.1, "text": " Um, yeah, it's, so I often wonder about this too.", "tokens": [50740, 3301, 11, 1338, 11, 309, 311, 11, 370, 286, 2049, 2441, 466, 341, 886, 13, 50968], "temperature": 0.0, "avg_logprob": -0.26674719723788176, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.0037054414860904217}, {"id": 952, "seek": 241002, "start": 2422.1, "end": 2426.58, "text": " Just, I feel like the misunderstanding", "tokens": [50968, 1449, 11, 286, 841, 411, 264, 29227, 51192], "temperature": 0.0, "avg_logprob": -0.26674719723788176, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.0037054414860904217}, {"id": 953, "seek": 241002, "start": 2426.58, "end": 2429.58, "text": " happened a lot more than even people realize.", "tokens": [51192, 2011, 257, 688, 544, 813, 754, 561, 4325, 13, 51342], "temperature": 0.0, "avg_logprob": -0.26674719723788176, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.0037054414860904217}, {"id": 954, "seek": 241002, "start": 2429.58, "end": 2431.86, "text": " And you can sometimes, you only really notice", "tokens": [51342, 400, 291, 393, 2171, 11, 291, 787, 534, 3449, 51456], "temperature": 0.0, "avg_logprob": -0.26674719723788176, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.0037054414860904217}, {"id": 955, "seek": 241002, "start": 2431.86, "end": 2434.06, "text": " when they become kind of big and matter.", "tokens": [51456, 562, 436, 1813, 733, 295, 955, 293, 1871, 13, 51566], "temperature": 0.0, "avg_logprob": -0.26674719723788176, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.0037054414860904217}, {"id": 956, "seek": 241002, "start": 2434.06, "end": 2437.2599999999998, "text": " And especially like, people can think", "tokens": [51566, 400, 2318, 411, 11, 561, 393, 519, 51726], "temperature": 0.0, "avg_logprob": -0.26674719723788176, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.0037054414860904217}, {"id": 957, "seek": 241002, "start": 2437.2599999999998, "end": 2438.98, "text": " they're having a conversation.", "tokens": [51726, 436, 434, 1419, 257, 3761, 13, 51812], "temperature": 0.0, "avg_logprob": -0.26674719723788176, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.0037054414860904217}, {"id": 958, "seek": 243898, "start": 2439.02, "end": 2441.5, "text": " And sometimes even from the outside, you can see like,", "tokens": [50366, 400, 2171, 754, 490, 264, 2380, 11, 291, 393, 536, 411, 11, 50490], "temperature": 0.0, "avg_logprob": -0.13774539284084153, "compression_ratio": 1.9356223175965666, "no_speech_prob": 0.0010002533672377467}, {"id": 959, "seek": 243898, "start": 2441.5, "end": 2444.42, "text": " these people are just talking completely past each other.", "tokens": [50490, 613, 561, 366, 445, 1417, 2584, 1791, 1184, 661, 13, 50636], "temperature": 0.0, "avg_logprob": -0.13774539284084153, "compression_ratio": 1.9356223175965666, "no_speech_prob": 0.0010002533672377467}, {"id": 960, "seek": 243898, "start": 2444.42, "end": 2445.5, "text": " And you can kind of see", "tokens": [50636, 400, 291, 393, 733, 295, 536, 50690], "temperature": 0.0, "avg_logprob": -0.13774539284084153, "compression_ratio": 1.9356223175965666, "no_speech_prob": 0.0010002533672377467}, {"id": 961, "seek": 243898, "start": 2445.5, "end": 2446.86, "text": " that they're not really understanding each other", "tokens": [50690, 300, 436, 434, 406, 534, 3701, 1184, 661, 50758], "temperature": 0.0, "avg_logprob": -0.13774539284084153, "compression_ratio": 1.9356223175965666, "no_speech_prob": 0.0010002533672377467}, {"id": 962, "seek": 243898, "start": 2446.86, "end": 2448.86, "text": " even though they maybe think they are.", "tokens": [50758, 754, 1673, 436, 1310, 519, 436, 366, 13, 50858], "temperature": 0.0, "avg_logprob": -0.13774539284084153, "compression_ratio": 1.9356223175965666, "no_speech_prob": 0.0010002533672377467}, {"id": 963, "seek": 243898, "start": 2449.94, "end": 2454.94, "text": " And so, yeah, I don't know how not brittle they are.", "tokens": [50912, 400, 370, 11, 1338, 11, 286, 500, 380, 458, 577, 406, 49325, 436, 366, 13, 51162], "temperature": 0.0, "avg_logprob": -0.13774539284084153, "compression_ratio": 1.9356223175965666, "no_speech_prob": 0.0010002533672377467}, {"id": 964, "seek": 243898, "start": 2456.34, "end": 2460.62, "text": " I think they, I think we think they're less brittle", "tokens": [51232, 286, 519, 436, 11, 286, 519, 321, 519, 436, 434, 1570, 49325, 51446], "temperature": 0.0, "avg_logprob": -0.13774539284084153, "compression_ratio": 1.9356223175965666, "no_speech_prob": 0.0010002533672377467}, {"id": 965, "seek": 243898, "start": 2460.62, "end": 2462.14, "text": " than maybe they are.", "tokens": [51446, 813, 1310, 436, 366, 13, 51522], "temperature": 0.0, "avg_logprob": -0.13774539284084153, "compression_ratio": 1.9356223175965666, "no_speech_prob": 0.0010002533672377467}, {"id": 966, "seek": 243898, "start": 2462.14, "end": 2465.1, "text": " I think sometimes we assume people are understanding", "tokens": [51522, 286, 519, 2171, 321, 6552, 561, 366, 3701, 51670], "temperature": 0.0, "avg_logprob": -0.13774539284084153, "compression_ratio": 1.9356223175965666, "no_speech_prob": 0.0010002533672377467}, {"id": 967, "seek": 243898, "start": 2465.1, "end": 2467.26, "text": " what we're saying better than they actually are", "tokens": [51670, 437, 321, 434, 1566, 1101, 813, 436, 767, 366, 51778], "temperature": 0.0, "avg_logprob": -0.13774539284084153, "compression_ratio": 1.9356223175965666, "no_speech_prob": 0.0010002533672377467}, {"id": 968, "seek": 246726, "start": 2467.26, "end": 2469.0600000000004, "text": " because they nod and smile at us.", "tokens": [50364, 570, 436, 15224, 293, 7563, 412, 505, 13, 50454], "temperature": 0.0, "avg_logprob": -0.19682864982540868, "compression_ratio": 1.777292576419214, "no_speech_prob": 0.004257555585354567}, {"id": 969, "seek": 246726, "start": 2470.34, "end": 2473.5800000000004, "text": " And because that's, it makes us feel good", "tokens": [50518, 400, 570, 300, 311, 11, 309, 1669, 505, 841, 665, 50680], "temperature": 0.0, "avg_logprob": -0.19682864982540868, "compression_ratio": 1.777292576419214, "no_speech_prob": 0.004257555585354567}, {"id": 970, "seek": 246726, "start": 2473.5800000000004, "end": 2474.5800000000004, "text": " for people to understand us.", "tokens": [50680, 337, 561, 281, 1223, 505, 13, 50730], "temperature": 0.0, "avg_logprob": -0.19682864982540868, "compression_ratio": 1.777292576419214, "no_speech_prob": 0.004257555585354567}, {"id": 971, "seek": 246726, "start": 2474.5800000000004, "end": 2478.1000000000004, "text": " It makes us good to feel, to understand other people.", "tokens": [50730, 467, 1669, 505, 665, 281, 841, 11, 281, 1223, 661, 561, 13, 50906], "temperature": 0.0, "avg_logprob": -0.19682864982540868, "compression_ratio": 1.777292576419214, "no_speech_prob": 0.004257555585354567}, {"id": 972, "seek": 246726, "start": 2478.1000000000004, "end": 2482.7000000000003, "text": " But yeah, I mean, it's, I mean, clearly,", "tokens": [50906, 583, 1338, 11, 286, 914, 11, 309, 311, 11, 286, 914, 11, 4448, 11, 51136], "temperature": 0.0, "avg_logprob": -0.19682864982540868, "compression_ratio": 1.777292576419214, "no_speech_prob": 0.004257555585354567}, {"id": 973, "seek": 246726, "start": 2482.7000000000003, "end": 2483.9, "text": " we do have a lot in common.", "tokens": [51136, 321, 360, 362, 257, 688, 294, 2689, 13, 51196], "temperature": 0.0, "avg_logprob": -0.19682864982540868, "compression_ratio": 1.777292576419214, "no_speech_prob": 0.004257555585354567}, {"id": 974, "seek": 246726, "start": 2483.9, "end": 2485.5800000000004, "text": " And there's definitely things we can understand", "tokens": [51196, 400, 456, 311, 2138, 721, 321, 393, 1223, 51280], "temperature": 0.0, "avg_logprob": -0.19682864982540868, "compression_ratio": 1.777292576419214, "no_speech_prob": 0.004257555585354567}, {"id": 975, "seek": 246726, "start": 2485.5800000000004, "end": 2487.26, "text": " about each other.", "tokens": [51280, 466, 1184, 661, 13, 51364], "temperature": 0.0, "avg_logprob": -0.19682864982540868, "compression_ratio": 1.777292576419214, "no_speech_prob": 0.004257555585354567}, {"id": 976, "seek": 246726, "start": 2487.26, "end": 2490.7400000000002, "text": " But yeah, it's like, I do sometimes think", "tokens": [51364, 583, 1338, 11, 309, 311, 411, 11, 286, 360, 2171, 519, 51538], "temperature": 0.0, "avg_logprob": -0.19682864982540868, "compression_ratio": 1.777292576419214, "no_speech_prob": 0.004257555585354567}, {"id": 977, "seek": 246726, "start": 2490.7400000000002, "end": 2492.34, "text": " that maybe we're more different from each other", "tokens": [51538, 300, 1310, 321, 434, 544, 819, 490, 1184, 661, 51618], "temperature": 0.0, "avg_logprob": -0.19682864982540868, "compression_ratio": 1.777292576419214, "no_speech_prob": 0.004257555585354567}, {"id": 978, "seek": 246726, "start": 2492.34, "end": 2493.5800000000004, "text": " than we really realize.", "tokens": [51618, 813, 321, 534, 4325, 13, 51680], "temperature": 0.0, "avg_logprob": -0.19682864982540868, "compression_ratio": 1.777292576419214, "no_speech_prob": 0.004257555585354567}, {"id": 979, "seek": 249358, "start": 2494.58, "end": 2497.18, "text": " Yeah, that's a really fascinating thought.", "tokens": [50414, 865, 11, 300, 311, 257, 534, 10343, 1194, 13, 50544], "temperature": 0.0, "avg_logprob": -0.140900391798753, "compression_ratio": 1.7300613496932515, "no_speech_prob": 0.000670383800752461}, {"id": 980, "seek": 249358, "start": 2497.18, "end": 2498.54, "text": " I mean, we speak a lot with Waleed Saber", "tokens": [50544, 286, 914, 11, 321, 1710, 257, 688, 365, 343, 1220, 292, 13915, 260, 50612], "temperature": 0.0, "avg_logprob": -0.140900391798753, "compression_ratio": 1.7300613496932515, "no_speech_prob": 0.000670383800752461}, {"id": 981, "seek": 249358, "start": 2498.54, "end": 2501.2599999999998, "text": " and he says how language has evolved", "tokens": [50612, 293, 415, 1619, 577, 2856, 575, 14178, 50748], "temperature": 0.0, "avg_logprob": -0.140900391798753, "compression_ratio": 1.7300613496932515, "no_speech_prob": 0.000670383800752461}, {"id": 982, "seek": 249358, "start": 2501.2599999999998, "end": 2503.42, "text": " to be extremely ambiguous actually", "tokens": [50748, 281, 312, 4664, 39465, 767, 50856], "temperature": 0.0, "avg_logprob": -0.140900391798753, "compression_ratio": 1.7300613496932515, "no_speech_prob": 0.000670383800752461}, {"id": 983, "seek": 249358, "start": 2503.42, "end": 2504.74, "text": " because it's a form of compression.", "tokens": [50856, 570, 309, 311, 257, 1254, 295, 19355, 13, 50922], "temperature": 0.0, "avg_logprob": -0.140900391798753, "compression_ratio": 1.7300613496932515, "no_speech_prob": 0.000670383800752461}, {"id": 984, "seek": 249358, "start": 2504.74, "end": 2506.8199999999997, "text": " So we don't say everything we mean", "tokens": [50922, 407, 321, 500, 380, 584, 1203, 321, 914, 51026], "temperature": 0.0, "avg_logprob": -0.140900391798753, "compression_ratio": 1.7300613496932515, "no_speech_prob": 0.000670383800752461}, {"id": 985, "seek": 249358, "start": 2506.8199999999997, "end": 2508.66, "text": " and we'll get into like language models in a minute.", "tokens": [51026, 293, 321, 603, 483, 666, 411, 2856, 5245, 294, 257, 3456, 13, 51118], "temperature": 0.0, "avg_logprob": -0.140900391798753, "compression_ratio": 1.7300613496932515, "no_speech_prob": 0.000670383800752461}, {"id": 986, "seek": 249358, "start": 2508.66, "end": 2511.22, "text": " That's part of the reason why they don't understand things", "tokens": [51118, 663, 311, 644, 295, 264, 1778, 983, 436, 500, 380, 1223, 721, 51246], "temperature": 0.0, "avg_logprob": -0.140900391798753, "compression_ratio": 1.7300613496932515, "no_speech_prob": 0.000670383800752461}, {"id": 987, "seek": 249358, "start": 2511.22, "end": 2513.7, "text": " is because a lot of information is not in the text.", "tokens": [51246, 307, 570, 257, 688, 295, 1589, 307, 406, 294, 264, 2487, 13, 51370], "temperature": 0.0, "avg_logprob": -0.140900391798753, "compression_ratio": 1.7300613496932515, "no_speech_prob": 0.000670383800752461}, {"id": 988, "seek": 249358, "start": 2513.7, "end": 2516.62, "text": " And Waleed says that we have a lot of,", "tokens": [51370, 400, 343, 1220, 292, 1619, 300, 321, 362, 257, 688, 295, 11, 51516], "temperature": 0.0, "avg_logprob": -0.140900391798753, "compression_ratio": 1.7300613496932515, "no_speech_prob": 0.000670383800752461}, {"id": 989, "seek": 249358, "start": 2516.62, "end": 2517.94, "text": " what he calls naive physics.", "tokens": [51516, 437, 415, 5498, 29052, 10649, 13, 51582], "temperature": 0.0, "avg_logprob": -0.140900391798753, "compression_ratio": 1.7300613496932515, "no_speech_prob": 0.000670383800752461}, {"id": 990, "seek": 249358, "start": 2517.94, "end": 2520.42, "text": " So we understand that objects can't be in two places", "tokens": [51582, 407, 321, 1223, 300, 6565, 393, 380, 312, 294, 732, 3190, 51706], "temperature": 0.0, "avg_logprob": -0.140900391798753, "compression_ratio": 1.7300613496932515, "no_speech_prob": 0.000670383800752461}, {"id": 991, "seek": 249358, "start": 2520.42, "end": 2521.2599999999998, "text": " at the same time.", "tokens": [51706, 412, 264, 912, 565, 13, 51748], "temperature": 0.0, "avg_logprob": -0.140900391798753, "compression_ratio": 1.7300613496932515, "no_speech_prob": 0.000670383800752461}, {"id": 992, "seek": 249358, "start": 2521.2599999999998, "end": 2523.22, "text": " And if something is located inside", "tokens": [51748, 400, 498, 746, 307, 6870, 1854, 51846], "temperature": 0.0, "avg_logprob": -0.140900391798753, "compression_ratio": 1.7300613496932515, "no_speech_prob": 0.000670383800752461}, {"id": 993, "seek": 252322, "start": 2523.8599999999997, "end": 2525.54, "text": " something else and we move that thing somewhere else,", "tokens": [50396, 746, 1646, 293, 321, 1286, 300, 551, 4079, 1646, 11, 50480], "temperature": 0.0, "avg_logprob": -0.14713604736328126, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.0019845201168209314}, {"id": 994, "seek": 252322, "start": 2525.54, "end": 2527.2999999999997, "text": " then the thing inside has also moved.", "tokens": [50480, 550, 264, 551, 1854, 575, 611, 4259, 13, 50568], "temperature": 0.0, "avg_logprob": -0.14713604736328126, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.0019845201168209314}, {"id": 995, "seek": 252322, "start": 2527.2999999999997, "end": 2530.62, "text": " So we're doing all sorts of reasoning on the fly.", "tokens": [50568, 407, 321, 434, 884, 439, 7527, 295, 21577, 322, 264, 3603, 13, 50734], "temperature": 0.0, "avg_logprob": -0.14713604736328126, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.0019845201168209314}, {"id": 996, "seek": 252322, "start": 2530.62, "end": 2532.7, "text": " And what we're kind of doing is like,", "tokens": [50734, 400, 437, 321, 434, 733, 295, 884, 307, 411, 11, 50838], "temperature": 0.0, "avg_logprob": -0.14713604736328126, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.0019845201168209314}, {"id": 997, "seek": 252322, "start": 2532.7, "end": 2535.2999999999997, "text": " we're disambiguating out of the 50 meanings", "tokens": [50838, 321, 434, 717, 2173, 16397, 990, 484, 295, 264, 2625, 28138, 50968], "temperature": 0.0, "avg_logprob": -0.14713604736328126, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.0019845201168209314}, {"id": 998, "seek": 252322, "start": 2535.2999999999997, "end": 2537.7, "text": " of an utterance into the meaning.", "tokens": [50968, 295, 364, 17567, 719, 666, 264, 3620, 13, 51088], "temperature": 0.0, "avg_logprob": -0.14713604736328126, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.0019845201168209314}, {"id": 999, "seek": 252322, "start": 2537.7, "end": 2541.58, "text": " And like it just, we almost always understand each other.", "tokens": [51088, 400, 411, 309, 445, 11, 321, 1920, 1009, 1223, 1184, 661, 13, 51282], "temperature": 0.0, "avg_logprob": -0.14713604736328126, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.0019845201168209314}, {"id": 1000, "seek": 252322, "start": 2541.58, "end": 2544.3799999999997, "text": " You know, you wouldn't really expect that.", "tokens": [51282, 509, 458, 11, 291, 2759, 380, 534, 2066, 300, 13, 51422], "temperature": 0.0, "avg_logprob": -0.14713604736328126, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.0019845201168209314}, {"id": 1001, "seek": 252322, "start": 2544.3799999999997, "end": 2549.3799999999997, "text": " No, I mean, yeah, I mean, we generally have like,", "tokens": [51422, 883, 11, 286, 914, 11, 1338, 11, 286, 914, 11, 321, 5101, 362, 411, 11, 51672], "temperature": 0.0, "avg_logprob": -0.14713604736328126, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.0019845201168209314}, {"id": 1002, "seek": 252322, "start": 2550.5, "end": 2552.66, "text": " I mean, our understanding of physics", "tokens": [51728, 286, 914, 11, 527, 3701, 295, 10649, 51836], "temperature": 0.0, "avg_logprob": -0.14713604736328126, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.0019845201168209314}, {"id": 1003, "seek": 255266, "start": 2552.66, "end": 2555.66, "text": " should generally be compatible with each other.", "tokens": [50364, 820, 5101, 312, 18218, 365, 1184, 661, 13, 50514], "temperature": 0.0, "avg_logprob": -0.18741736749205926, "compression_ratio": 1.7022222222222223, "no_speech_prob": 0.00279975519515574}, {"id": 1004, "seek": 255266, "start": 2555.66, "end": 2560.3799999999997, "text": " I do feel like it's, in most cases, yes,", "tokens": [50514, 286, 360, 841, 411, 309, 311, 11, 294, 881, 3331, 11, 2086, 11, 50750], "temperature": 0.0, "avg_logprob": -0.18741736749205926, "compression_ratio": 1.7022222222222223, "no_speech_prob": 0.00279975519515574}, {"id": 1005, "seek": 255266, "start": 2560.3799999999997, "end": 2562.22, "text": " we do very clearly understand each other", "tokens": [50750, 321, 360, 588, 4448, 1223, 1184, 661, 50842], "temperature": 0.0, "avg_logprob": -0.18741736749205926, "compression_ratio": 1.7022222222222223, "no_speech_prob": 0.00279975519515574}, {"id": 1006, "seek": 255266, "start": 2562.22, "end": 2565.42, "text": " because in most cases, it's more like well-defined.", "tokens": [50842, 570, 294, 881, 3331, 11, 309, 311, 544, 411, 731, 12, 37716, 13, 51002], "temperature": 0.0, "avg_logprob": -0.18741736749205926, "compression_ratio": 1.7022222222222223, "no_speech_prob": 0.00279975519515574}, {"id": 1007, "seek": 255266, "start": 2565.42, "end": 2569.18, "text": " I think the trouble gets in sort of like fuzzier areas", "tokens": [51002, 286, 519, 264, 5253, 2170, 294, 1333, 295, 411, 283, 16740, 811, 3179, 51190], "temperature": 0.0, "avg_logprob": -0.18741736749205926, "compression_ratio": 1.7022222222222223, "no_speech_prob": 0.00279975519515574}, {"id": 1008, "seek": 255266, "start": 2569.18, "end": 2573.3399999999997, "text": " about people's like emotions or opinions about things", "tokens": [51190, 466, 561, 311, 411, 8462, 420, 11819, 466, 721, 51398], "temperature": 0.0, "avg_logprob": -0.18741736749205926, "compression_ratio": 1.7022222222222223, "no_speech_prob": 0.00279975519515574}, {"id": 1009, "seek": 255266, "start": 2573.3399999999997, "end": 2576.68, "text": " where our priors are more sort of maybe less", "tokens": [51398, 689, 527, 1790, 830, 366, 544, 1333, 295, 1310, 1570, 51565], "temperature": 0.0, "avg_logprob": -0.18741736749205926, "compression_ratio": 1.7022222222222223, "no_speech_prob": 0.00279975519515574}, {"id": 1010, "seek": 255266, "start": 2577.8199999999997, "end": 2580.8199999999997, "text": " less tied to like objective things like physics", "tokens": [51622, 1570, 9601, 281, 411, 10024, 721, 411, 10649, 51772], "temperature": 0.0, "avg_logprob": -0.18741736749205926, "compression_ratio": 1.7022222222222223, "no_speech_prob": 0.00279975519515574}, {"id": 1011, "seek": 258082, "start": 2580.82, "end": 2583.42, "text": " and are more sort of just tied to like our upbringing", "tokens": [50364, 293, 366, 544, 1333, 295, 445, 9601, 281, 411, 527, 47268, 50494], "temperature": 0.0, "avg_logprob": -0.1477853704381872, "compression_ratio": 1.7774193548387096, "no_speech_prob": 0.0004040810454171151}, {"id": 1012, "seek": 258082, "start": 2583.42, "end": 2586.26, "text": " and just sort of whatever ideas, notions we have", "tokens": [50494, 293, 445, 1333, 295, 2035, 3487, 11, 35799, 321, 362, 50636], "temperature": 0.0, "avg_logprob": -0.1477853704381872, "compression_ratio": 1.7774193548387096, "no_speech_prob": 0.0004040810454171151}, {"id": 1013, "seek": 258082, "start": 2586.26, "end": 2588.98, "text": " about how people should like behave and interact", "tokens": [50636, 466, 577, 561, 820, 411, 15158, 293, 4648, 50772], "temperature": 0.0, "avg_logprob": -0.1477853704381872, "compression_ratio": 1.7774193548387096, "no_speech_prob": 0.0004040810454171151}, {"id": 1014, "seek": 258082, "start": 2588.98, "end": 2591.2200000000003, "text": " and what like our value systems.", "tokens": [50772, 293, 437, 411, 527, 2158, 3652, 13, 50884], "temperature": 0.0, "avg_logprob": -0.1477853704381872, "compression_ratio": 1.7774193548387096, "no_speech_prob": 0.0004040810454171151}, {"id": 1015, "seek": 258082, "start": 2592.42, "end": 2594.6200000000003, "text": " And so, yeah, when people are talking about", "tokens": [50944, 400, 370, 11, 1338, 11, 562, 561, 366, 1417, 466, 51054], "temperature": 0.0, "avg_logprob": -0.1477853704381872, "compression_ratio": 1.7774193548387096, "no_speech_prob": 0.0004040810454171151}, {"id": 1016, "seek": 258082, "start": 2594.6200000000003, "end": 2597.02, "text": " some of these common things, I feel like they're more likely", "tokens": [51054, 512, 295, 613, 2689, 721, 11, 286, 841, 411, 436, 434, 544, 3700, 51174], "temperature": 0.0, "avg_logprob": -0.1477853704381872, "compression_ratio": 1.7774193548387096, "no_speech_prob": 0.0004040810454171151}, {"id": 1017, "seek": 258082, "start": 2597.02, "end": 2599.42, "text": " to be able to like talk past each other and not realize it", "tokens": [51174, 281, 312, 1075, 281, 411, 751, 1791, 1184, 661, 293, 406, 4325, 309, 51294], "temperature": 0.0, "avg_logprob": -0.1477853704381872, "compression_ratio": 1.7774193548387096, "no_speech_prob": 0.0004040810454171151}, {"id": 1018, "seek": 258082, "start": 2599.42, "end": 2602.1000000000004, "text": " because they're sort of assumptions about what is important", "tokens": [51294, 570, 436, 434, 1333, 295, 17695, 466, 437, 307, 1021, 51428], "temperature": 0.0, "avg_logprob": -0.1477853704381872, "compression_ratio": 1.7774193548387096, "no_speech_prob": 0.0004040810454171151}, {"id": 1019, "seek": 258082, "start": 2602.1000000000004, "end": 2606.2200000000003, "text": " or what is meaningful might be different from each other.", "tokens": [51428, 420, 437, 307, 10995, 1062, 312, 819, 490, 1184, 661, 13, 51634], "temperature": 0.0, "avg_logprob": -0.1477853704381872, "compression_ratio": 1.7774193548387096, "no_speech_prob": 0.0004040810454171151}, {"id": 1020, "seek": 258082, "start": 2606.2200000000003, "end": 2607.82, "text": " Yeah, actually, you're absolutely right.", "tokens": [51634, 865, 11, 767, 11, 291, 434, 3122, 558, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1477853704381872, "compression_ratio": 1.7774193548387096, "no_speech_prob": 0.0004040810454171151}, {"id": 1021, "seek": 258082, "start": 2607.82, "end": 2610.3, "text": " So we don't have an objective phenomenology", "tokens": [51714, 407, 321, 500, 380, 362, 364, 10024, 9388, 1793, 51838], "temperature": 0.0, "avg_logprob": -0.1477853704381872, "compression_ratio": 1.7774193548387096, "no_speech_prob": 0.0004040810454171151}, {"id": 1022, "seek": 261030, "start": 2610.34, "end": 2613.42, "text": " and I used to do, there's a thing called quantified self", "tokens": [50366, 293, 286, 1143, 281, 360, 11, 456, 311, 257, 551, 1219, 4426, 2587, 2698, 50520], "temperature": 0.0, "avg_logprob": -0.09626967229960877, "compression_ratio": 1.7738095238095237, "no_speech_prob": 0.0001976433559320867}, {"id": 1023, "seek": 261030, "start": 2613.42, "end": 2615.1400000000003, "text": " where you kind of like keep a diary every day", "tokens": [50520, 689, 291, 733, 295, 411, 1066, 257, 26492, 633, 786, 50606], "temperature": 0.0, "avg_logprob": -0.09626967229960877, "compression_ratio": 1.7738095238095237, "no_speech_prob": 0.0001976433559320867}, {"id": 1024, "seek": 261030, "start": 2615.1400000000003, "end": 2617.9, "text": " and you record how you're feeling in that day.", "tokens": [50606, 293, 291, 2136, 577, 291, 434, 2633, 294, 300, 786, 13, 50744], "temperature": 0.0, "avg_logprob": -0.09626967229960877, "compression_ratio": 1.7738095238095237, "no_speech_prob": 0.0001976433559320867}, {"id": 1025, "seek": 261030, "start": 2617.9, "end": 2620.0600000000004, "text": " And feeling is a subjective state.", "tokens": [50744, 400, 2633, 307, 257, 25972, 1785, 13, 50852], "temperature": 0.0, "avg_logprob": -0.09626967229960877, "compression_ratio": 1.7738095238095237, "no_speech_prob": 0.0001976433559320867}, {"id": 1026, "seek": 261030, "start": 2620.0600000000004, "end": 2622.1800000000003, "text": " So I remember at the time that every single day", "tokens": [50852, 407, 286, 1604, 412, 264, 565, 300, 633, 2167, 786, 50958], "temperature": 0.0, "avg_logprob": -0.09626967229960877, "compression_ratio": 1.7738095238095237, "no_speech_prob": 0.0001976433559320867}, {"id": 1027, "seek": 261030, "start": 2622.1800000000003, "end": 2624.94, "text": " I needed a new word to describe how I was feeling", "tokens": [50958, 286, 2978, 257, 777, 1349, 281, 6786, 577, 286, 390, 2633, 51096], "temperature": 0.0, "avg_logprob": -0.09626967229960877, "compression_ratio": 1.7738095238095237, "no_speech_prob": 0.0001976433559320867}, {"id": 1028, "seek": 261030, "start": 2624.94, "end": 2627.7400000000002, "text": " because the old word I was using didn't work anymore.", "tokens": [51096, 570, 264, 1331, 1349, 286, 390, 1228, 994, 380, 589, 3602, 13, 51236], "temperature": 0.0, "avg_logprob": -0.09626967229960877, "compression_ratio": 1.7738095238095237, "no_speech_prob": 0.0001976433559320867}, {"id": 1029, "seek": 261030, "start": 2627.7400000000002, "end": 2629.46, "text": " So the number of words kept growing.", "tokens": [51236, 407, 264, 1230, 295, 2283, 4305, 4194, 13, 51322], "temperature": 0.0, "avg_logprob": -0.09626967229960877, "compression_ratio": 1.7738095238095237, "no_speech_prob": 0.0001976433559320867}, {"id": 1030, "seek": 261030, "start": 2629.46, "end": 2631.3, "text": " And actually, that's so true, isn't it?", "tokens": [51322, 400, 767, 11, 300, 311, 370, 2074, 11, 1943, 380, 309, 30, 51414], "temperature": 0.0, "avg_logprob": -0.09626967229960877, "compression_ratio": 1.7738095238095237, "no_speech_prob": 0.0001976433559320867}, {"id": 1031, "seek": 261030, "start": 2631.3, "end": 2633.1800000000003, "text": " If I tell you how I'm feeling right now,", "tokens": [51414, 759, 286, 980, 291, 577, 286, 478, 2633, 558, 586, 11, 51508], "temperature": 0.0, "avg_logprob": -0.09626967229960877, "compression_ratio": 1.7738095238095237, "no_speech_prob": 0.0001976433559320867}, {"id": 1032, "seek": 261030, "start": 2633.1800000000003, "end": 2634.6200000000003, "text": " that's completely brittle.", "tokens": [51508, 300, 311, 2584, 49325, 13, 51580], "temperature": 0.0, "avg_logprob": -0.09626967229960877, "compression_ratio": 1.7738095238095237, "no_speech_prob": 0.0001976433559320867}, {"id": 1033, "seek": 261030, "start": 2634.6200000000003, "end": 2636.02, "text": " So there are some things in the world", "tokens": [51580, 407, 456, 366, 512, 721, 294, 264, 1002, 51650], "temperature": 0.0, "avg_logprob": -0.09626967229960877, "compression_ratio": 1.7738095238095237, "no_speech_prob": 0.0001976433559320867}, {"id": 1034, "seek": 261030, "start": 2636.02, "end": 2638.0600000000004, "text": " that are quite informational and objective", "tokens": [51650, 300, 366, 1596, 49391, 293, 10024, 51752], "temperature": 0.0, "avg_logprob": -0.09626967229960877, "compression_ratio": 1.7738095238095237, "no_speech_prob": 0.0001976433559320867}, {"id": 1035, "seek": 261030, "start": 2638.0600000000004, "end": 2639.6600000000003, "text": " and we can communicate very well.", "tokens": [51752, 293, 321, 393, 7890, 588, 731, 13, 51832], "temperature": 0.0, "avg_logprob": -0.09626967229960877, "compression_ratio": 1.7738095238095237, "no_speech_prob": 0.0001976433559320867}, {"id": 1036, "seek": 263966, "start": 2639.7, "end": 2642.3799999999997, "text": " And then when we're bordering on anything subjective,", "tokens": [50366, 400, 550, 562, 321, 434, 25872, 1794, 322, 1340, 25972, 11, 50500], "temperature": 0.0, "avg_logprob": -0.16418591141700745, "compression_ratio": 1.832116788321168, "no_speech_prob": 0.00020330904226284474}, {"id": 1037, "seek": 263966, "start": 2642.3799999999997, "end": 2644.22, "text": " language fails us.", "tokens": [50500, 2856, 18199, 505, 13, 50592], "temperature": 0.0, "avg_logprob": -0.16418591141700745, "compression_ratio": 1.832116788321168, "no_speech_prob": 0.00020330904226284474}, {"id": 1038, "seek": 263966, "start": 2644.22, "end": 2647.22, "text": " Yeah, and then we were trying to map whatever word", "tokens": [50592, 865, 11, 293, 550, 321, 645, 1382, 281, 4471, 2035, 1349, 50742], "temperature": 0.0, "avg_logprob": -0.16418591141700745, "compression_ratio": 1.832116788321168, "no_speech_prob": 0.00020330904226284474}, {"id": 1039, "seek": 263966, "start": 2647.22, "end": 2649.18, "text": " you're using on to how I would use that word", "tokens": [50742, 291, 434, 1228, 322, 281, 577, 286, 576, 764, 300, 1349, 50840], "temperature": 0.0, "avg_logprob": -0.16418591141700745, "compression_ratio": 1.832116788321168, "no_speech_prob": 0.00020330904226284474}, {"id": 1040, "seek": 263966, "start": 2649.18, "end": 2651.3799999999997, "text": " to describe the feeling that I would be having.", "tokens": [50840, 281, 6786, 264, 2633, 300, 286, 576, 312, 1419, 13, 50950], "temperature": 0.0, "avg_logprob": -0.16418591141700745, "compression_ratio": 1.832116788321168, "no_speech_prob": 0.00020330904226284474}, {"id": 1041, "seek": 263966, "start": 2651.3799999999997, "end": 2655.7, "text": " And that mapping seems completely like without a long", "tokens": [50950, 400, 300, 18350, 2544, 2584, 411, 1553, 257, 938, 51166], "temperature": 0.0, "avg_logprob": -0.16418591141700745, "compression_ratio": 1.832116788321168, "no_speech_prob": 0.00020330904226284474}, {"id": 1042, "seek": 263966, "start": 2655.7, "end": 2658.66, "text": " conversation to try to like feed up that mapping.", "tokens": [51166, 3761, 281, 853, 281, 411, 3154, 493, 300, 18350, 13, 51314], "temperature": 0.0, "avg_logprob": -0.16418591141700745, "compression_ratio": 1.832116788321168, "no_speech_prob": 0.00020330904226284474}, {"id": 1043, "seek": 263966, "start": 2658.66, "end": 2663.22, "text": " Oh, it could be quite different in how I would apply", "tokens": [51314, 876, 11, 309, 727, 312, 1596, 819, 294, 577, 286, 576, 3079, 51542], "temperature": 0.0, "avg_logprob": -0.16418591141700745, "compression_ratio": 1.832116788321168, "no_speech_prob": 0.00020330904226284474}, {"id": 1044, "seek": 263966, "start": 2663.22, "end": 2665.3399999999997, "text": " that word to my own feeling.", "tokens": [51542, 300, 1349, 281, 452, 1065, 2633, 13, 51648], "temperature": 0.0, "avg_logprob": -0.16418591141700745, "compression_ratio": 1.832116788321168, "no_speech_prob": 0.00020330904226284474}, {"id": 1045, "seek": 263966, "start": 2665.3399999999997, "end": 2666.8999999999996, "text": " Yeah, and there's been studies done as well", "tokens": [51648, 865, 11, 293, 456, 311, 668, 5313, 1096, 382, 731, 51726], "temperature": 0.0, "avg_logprob": -0.16418591141700745, "compression_ratio": 1.832116788321168, "no_speech_prob": 0.00020330904226284474}, {"id": 1046, "seek": 263966, "start": 2666.8999999999996, "end": 2669.54, "text": " that I think certain tribes have a completely different", "tokens": [51726, 300, 286, 519, 1629, 19035, 362, 257, 2584, 819, 51858], "temperature": 0.0, "avg_logprob": -0.16418591141700745, "compression_ratio": 1.832116788321168, "no_speech_prob": 0.00020330904226284474}, {"id": 1047, "seek": 266954, "start": 2669.54, "end": 2672.18, "text": " color perception and there are also concepts", "tokens": [50364, 2017, 12860, 293, 456, 366, 611, 10392, 50496], "temperature": 0.0, "avg_logprob": -0.17851510339853716, "compression_ratio": 1.6986301369863013, "no_speech_prob": 0.0034805701579898596}, {"id": 1048, "seek": 266954, "start": 2672.18, "end": 2674.46, "text": " like vagueness, so what is a pile of sand", "tokens": [50496, 411, 13501, 7801, 442, 11, 370, 437, 307, 257, 14375, 295, 4932, 50610], "temperature": 0.0, "avg_logprob": -0.17851510339853716, "compression_ratio": 1.6986301369863013, "no_speech_prob": 0.0034805701579898596}, {"id": 1049, "seek": 266954, "start": 2674.46, "end": 2676.2599999999998, "text": " and what is a shade of red?", "tokens": [50610, 293, 437, 307, 257, 11466, 295, 2182, 30, 50700], "temperature": 0.0, "avg_logprob": -0.17851510339853716, "compression_ratio": 1.6986301369863013, "no_speech_prob": 0.0034805701579898596}, {"id": 1050, "seek": 266954, "start": 2676.2599999999998, "end": 2678.2599999999998, "text": " And these things are actually very, very difficult", "tokens": [50700, 400, 613, 721, 366, 767, 588, 11, 588, 2252, 50800], "temperature": 0.0, "avg_logprob": -0.17851510339853716, "compression_ratio": 1.6986301369863013, "no_speech_prob": 0.0034805701579898596}, {"id": 1051, "seek": 266954, "start": 2678.2599999999998, "end": 2679.82, "text": " to communicate objectively.", "tokens": [50800, 281, 7890, 46067, 13, 50878], "temperature": 0.0, "avg_logprob": -0.17851510339853716, "compression_ratio": 1.6986301369863013, "no_speech_prob": 0.0034805701579898596}, {"id": 1052, "seek": 266954, "start": 2681.2599999999998, "end": 2684.98, "text": " Yeah, things like color perception", "tokens": [50950, 865, 11, 721, 411, 2017, 12860, 51136], "temperature": 0.0, "avg_logprob": -0.17851510339853716, "compression_ratio": 1.6986301369863013, "no_speech_prob": 0.0034805701579898596}, {"id": 1053, "seek": 266954, "start": 2684.98, "end": 2686.58, "text": " are kind of the interesting ones", "tokens": [51136, 366, 733, 295, 264, 1880, 2306, 51216], "temperature": 0.0, "avg_logprob": -0.17851510339853716, "compression_ratio": 1.6986301369863013, "no_speech_prob": 0.0034805701579898596}, {"id": 1054, "seek": 266954, "start": 2686.58, "end": 2689.74, "text": " because the literature is a bit messy", "tokens": [51216, 570, 264, 10394, 307, 257, 857, 16191, 51374], "temperature": 0.0, "avg_logprob": -0.17851510339853716, "compression_ratio": 1.6986301369863013, "no_speech_prob": 0.0034805701579898596}, {"id": 1055, "seek": 266954, "start": 2689.74, "end": 2691.06, "text": " on some of these topics.", "tokens": [51374, 322, 512, 295, 613, 8378, 13, 51440], "temperature": 0.0, "avg_logprob": -0.17851510339853716, "compression_ratio": 1.6986301369863013, "no_speech_prob": 0.0034805701579898596}, {"id": 1056, "seek": 266954, "start": 2692.22, "end": 2696.66, "text": " And some of it is just where you draw the lines", "tokens": [51498, 400, 512, 295, 309, 307, 445, 689, 291, 2642, 264, 3876, 51720], "temperature": 0.0, "avg_logprob": -0.17851510339853716, "compression_ratio": 1.6986301369863013, "no_speech_prob": 0.0034805701579898596}, {"id": 1057, "seek": 269666, "start": 2696.66, "end": 2699.94, "text": " between colors and then how those linguistic boundaries", "tokens": [50364, 1296, 4577, 293, 550, 577, 729, 43002, 13180, 50528], "temperature": 0.0, "avg_logprob": -0.21403105784270723, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.05578053370118141}, {"id": 1058, "seek": 269666, "start": 2699.94, "end": 2701.5, "text": " affect perception.", "tokens": [50528, 3345, 12860, 13, 50606], "temperature": 0.0, "avg_logprob": -0.21403105784270723, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.05578053370118141}, {"id": 1059, "seek": 269666, "start": 2701.5, "end": 2704.3399999999997, "text": " There definitely seems to be both things going,", "tokens": [50606, 821, 2138, 2544, 281, 312, 1293, 721, 516, 11, 50748], "temperature": 0.0, "avg_logprob": -0.21403105784270723, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.05578053370118141}, {"id": 1060, "seek": 269666, "start": 2704.3399999999997, "end": 2708.2599999999998, "text": " but it's not sort of, I don't think any,", "tokens": [50748, 457, 309, 311, 406, 1333, 295, 11, 286, 500, 380, 519, 604, 11, 50944], "temperature": 0.0, "avg_logprob": -0.21403105784270723, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.05578053370118141}, {"id": 1061, "seek": 269666, "start": 2708.2599999999998, "end": 2709.7799999999997, "text": " I think it's a strong claim to be like,", "tokens": [50944, 286, 519, 309, 311, 257, 2068, 3932, 281, 312, 411, 11, 51020], "temperature": 0.0, "avg_logprob": -0.21403105784270723, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.05578053370118141}, {"id": 1062, "seek": 269666, "start": 2709.7799999999997, "end": 2713.98, "text": " oh, the people can't perceive green or something like that.", "tokens": [51020, 1954, 11, 264, 561, 393, 380, 20281, 3092, 420, 746, 411, 300, 13, 51230], "temperature": 0.0, "avg_logprob": -0.21403105784270723, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.05578053370118141}, {"id": 1063, "seek": 269666, "start": 2715.1, "end": 2716.8199999999997, "text": " It's just like where they would draw the line", "tokens": [51286, 467, 311, 445, 411, 689, 436, 576, 2642, 264, 1622, 51372], "temperature": 0.0, "avg_logprob": -0.21403105784270723, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.05578053370118141}, {"id": 1064, "seek": 269666, "start": 2716.8199999999997, "end": 2718.98, "text": " between blue would be in a slightly different place", "tokens": [51372, 1296, 3344, 576, 312, 294, 257, 4748, 819, 1081, 51480], "temperature": 0.0, "avg_logprob": -0.21403105784270723, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.05578053370118141}, {"id": 1065, "seek": 269666, "start": 2718.98, "end": 2721.62, "text": " and then they might kind of see them as being,", "tokens": [51480, 293, 550, 436, 1062, 733, 295, 536, 552, 382, 885, 11, 51612], "temperature": 0.0, "avg_logprob": -0.21403105784270723, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.05578053370118141}, {"id": 1066, "seek": 269666, "start": 2721.62, "end": 2723.8599999999997, "text": " sort of experience them as being like further apart", "tokens": [51612, 1333, 295, 1752, 552, 382, 885, 411, 3052, 4936, 51724], "temperature": 0.0, "avg_logprob": -0.21403105784270723, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.05578053370118141}, {"id": 1067, "seek": 272386, "start": 2723.86, "end": 2726.82, "text": " or closer together than you would necessarily,", "tokens": [50364, 420, 4966, 1214, 813, 291, 576, 4725, 11, 50512], "temperature": 0.0, "avg_logprob": -0.24394529242264598, "compression_ratio": 1.6650943396226414, "no_speech_prob": 0.0018370980396866798}, {"id": 1068, "seek": 272386, "start": 2726.82, "end": 2730.38, "text": " but yeah, that's really,", "tokens": [50512, 457, 1338, 11, 300, 311, 534, 11, 50690], "temperature": 0.0, "avg_logprob": -0.24394529242264598, "compression_ratio": 1.6650943396226414, "no_speech_prob": 0.0018370980396866798}, {"id": 1069, "seek": 272386, "start": 2730.38, "end": 2734.2200000000003, "text": " their experience, that's really be super alien to you,", "tokens": [50690, 641, 1752, 11, 300, 311, 534, 312, 1687, 12319, 281, 291, 11, 50882], "temperature": 0.0, "avg_logprob": -0.24394529242264598, "compression_ratio": 1.6650943396226414, "no_speech_prob": 0.0018370980396866798}, {"id": 1070, "seek": 272386, "start": 2734.2200000000003, "end": 2739.2200000000003, "text": " but they're sort of experience of maybe more very cultural,", "tokens": [50882, 457, 436, 434, 1333, 295, 1752, 295, 1310, 544, 588, 6988, 11, 51132], "temperature": 0.0, "avg_logprob": -0.24394529242264598, "compression_ratio": 1.6650943396226414, "no_speech_prob": 0.0018370980396866798}, {"id": 1071, "seek": 272386, "start": 2740.98, "end": 2742.7000000000003, "text": " like cultural taboos or something", "tokens": [51220, 411, 6988, 4421, 78, 329, 420, 746, 51306], "temperature": 0.0, "avg_logprob": -0.24394529242264598, "compression_ratio": 1.6650943396226414, "no_speech_prob": 0.0018370980396866798}, {"id": 1072, "seek": 272386, "start": 2742.7000000000003, "end": 2744.5, "text": " would be very different than yours.", "tokens": [51306, 576, 312, 588, 819, 813, 6342, 13, 51396], "temperature": 0.0, "avg_logprob": -0.24394529242264598, "compression_ratio": 1.6650943396226414, "no_speech_prob": 0.0018370980396866798}, {"id": 1073, "seek": 272386, "start": 2746.6600000000003, "end": 2748.34, "text": " Yeah, I mean, one thing you're alluding to there is,", "tokens": [51504, 865, 11, 286, 914, 11, 472, 551, 291, 434, 439, 33703, 281, 456, 307, 11, 51588], "temperature": 0.0, "avg_logprob": -0.24394529242264598, "compression_ratio": 1.6650943396226414, "no_speech_prob": 0.0018370980396866798}, {"id": 1074, "seek": 272386, "start": 2748.34, "end": 2751.94, "text": " it's when we deal with complicated systems,", "tokens": [51588, 309, 311, 562, 321, 2028, 365, 6179, 3652, 11, 51768], "temperature": 0.0, "avg_logprob": -0.24394529242264598, "compression_ratio": 1.6650943396226414, "no_speech_prob": 0.0018370980396866798}, {"id": 1075, "seek": 275194, "start": 2751.98, "end": 2754.3, "text": " there's a real problem about drawing boundaries.", "tokens": [50366, 456, 311, 257, 957, 1154, 466, 6316, 13180, 13, 50482], "temperature": 0.0, "avg_logprob": -0.12059191803434002, "compression_ratio": 1.7758620689655173, "no_speech_prob": 0.0008777485927566886}, {"id": 1076, "seek": 275194, "start": 2754.3, "end": 2756.54, "text": " And I was, I mean, Friston's a great example,", "tokens": [50482, 400, 286, 390, 11, 286, 914, 11, 1526, 47345, 311, 257, 869, 1365, 11, 50594], "temperature": 0.0, "avg_logprob": -0.12059191803434002, "compression_ratio": 1.7758620689655173, "no_speech_prob": 0.0008777485927566886}, {"id": 1077, "seek": 275194, "start": 2756.54, "end": 2758.2200000000003, "text": " he's got this idea of a Markov boundary", "tokens": [50594, 415, 311, 658, 341, 1558, 295, 257, 3934, 5179, 12866, 50678], "temperature": 0.0, "avg_logprob": -0.12059191803434002, "compression_ratio": 1.7758620689655173, "no_speech_prob": 0.0008777485927566886}, {"id": 1078, "seek": 275194, "start": 2758.2200000000003, "end": 2759.86, "text": " and it could be at the cellular level", "tokens": [50678, 293, 309, 727, 312, 412, 264, 29267, 1496, 50760], "temperature": 0.0, "avg_logprob": -0.12059191803434002, "compression_ratio": 1.7758620689655173, "no_speech_prob": 0.0008777485927566886}, {"id": 1079, "seek": 275194, "start": 2759.86, "end": 2762.42, "text": " or it could be you as a person.", "tokens": [50760, 420, 309, 727, 312, 291, 382, 257, 954, 13, 50888], "temperature": 0.0, "avg_logprob": -0.12059191803434002, "compression_ratio": 1.7758620689655173, "no_speech_prob": 0.0008777485927566886}, {"id": 1080, "seek": 275194, "start": 2762.42, "end": 2764.94, "text": " And then when we talk about things like agency and free will,", "tokens": [50888, 400, 550, 562, 321, 751, 466, 721, 411, 7934, 293, 1737, 486, 11, 51014], "temperature": 0.0, "avg_logprob": -0.12059191803434002, "compression_ratio": 1.7758620689655173, "no_speech_prob": 0.0008777485927566886}, {"id": 1081, "seek": 275194, "start": 2764.94, "end": 2767.2200000000003, "text": " we tend to anthropomorphize this boundary.", "tokens": [51014, 321, 3928, 281, 22727, 32702, 1125, 341, 12866, 13, 51128], "temperature": 0.0, "avg_logprob": -0.12059191803434002, "compression_ratio": 1.7758620689655173, "no_speech_prob": 0.0008777485927566886}, {"id": 1082, "seek": 275194, "start": 2767.2200000000003, "end": 2769.2200000000003, "text": " So we tend to think of ourselves as individuals,", "tokens": [51128, 407, 321, 3928, 281, 519, 295, 4175, 382, 5346, 11, 51228], "temperature": 0.0, "avg_logprob": -0.12059191803434002, "compression_ratio": 1.7758620689655173, "no_speech_prob": 0.0008777485927566886}, {"id": 1083, "seek": 275194, "start": 2769.2200000000003, "end": 2772.42, "text": " but actually you could draw boundaries at different scales", "tokens": [51228, 457, 767, 291, 727, 2642, 13180, 412, 819, 17408, 51388], "temperature": 0.0, "avg_logprob": -0.12059191803434002, "compression_ratio": 1.7758620689655173, "no_speech_prob": 0.0008777485927566886}, {"id": 1084, "seek": 275194, "start": 2772.42, "end": 2774.7000000000003, "text": " and the boundaries might be observer relative as well.", "tokens": [51388, 293, 264, 13180, 1062, 312, 27878, 4972, 382, 731, 13, 51502], "temperature": 0.0, "avg_logprob": -0.12059191803434002, "compression_ratio": 1.7758620689655173, "no_speech_prob": 0.0008777485927566886}, {"id": 1085, "seek": 275194, "start": 2774.7000000000003, "end": 2776.7400000000002, "text": " So your boundary might not be my boundary.", "tokens": [51502, 407, 428, 12866, 1062, 406, 312, 452, 12866, 13, 51604], "temperature": 0.0, "avg_logprob": -0.12059191803434002, "compression_ratio": 1.7758620689655173, "no_speech_prob": 0.0008777485927566886}, {"id": 1086, "seek": 277674, "start": 2777.74, "end": 2779.02, "text": " Yeah, exactly.", "tokens": [50414, 865, 11, 2293, 13, 50478], "temperature": 0.0, "avg_logprob": -0.23792821353243798, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.0017524438444525003}, {"id": 1087, "seek": 277674, "start": 2782.8599999999997, "end": 2786.58, "text": " Yeah, there's something I know a ton about,", "tokens": [50670, 865, 11, 456, 311, 746, 286, 458, 257, 2952, 466, 11, 50856], "temperature": 0.0, "avg_logprob": -0.23792821353243798, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.0017524438444525003}, {"id": 1088, "seek": 277674, "start": 2788.58, "end": 2791.8199999999997, "text": " how you define yourself and how you think of yourself", "tokens": [50956, 577, 291, 6964, 1803, 293, 577, 291, 519, 295, 1803, 51118], "temperature": 0.0, "avg_logprob": -0.23792821353243798, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.0017524438444525003}, {"id": 1089, "seek": 277674, "start": 2791.8199999999997, "end": 2793.8999999999996, "text": " within the context of your community and whatnot.", "tokens": [51118, 1951, 264, 4319, 295, 428, 1768, 293, 25882, 13, 51222], "temperature": 0.0, "avg_logprob": -0.23792821353243798, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.0017524438444525003}, {"id": 1090, "seek": 277674, "start": 2793.8999999999996, "end": 2796.9799999999996, "text": " I mean, some of these ideas are just very cultural", "tokens": [51222, 286, 914, 11, 512, 295, 613, 3487, 366, 445, 588, 6988, 51376], "temperature": 0.0, "avg_logprob": -0.23792821353243798, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.0017524438444525003}, {"id": 1091, "seek": 277674, "start": 2796.9799999999996, "end": 2801.54, "text": " and how you experience yourself is probably even like,", "tokens": [51376, 293, 577, 291, 1752, 1803, 307, 1391, 754, 411, 11, 51604], "temperature": 0.0, "avg_logprob": -0.23792821353243798, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.0017524438444525003}, {"id": 1092, "seek": 277674, "start": 2801.54, "end": 2804.3399999999997, "text": " very different, can be very different cross-pulturally.", "tokens": [51604, 588, 819, 11, 393, 312, 588, 819, 3278, 12, 79, 723, 6512, 13, 51744], "temperature": 0.0, "avg_logprob": -0.23792821353243798, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.0017524438444525003}, {"id": 1093, "seek": 277674, "start": 2804.3399999999997, "end": 2805.66, "text": " Yeah, I mean, maybe one thing to bring in", "tokens": [51744, 865, 11, 286, 914, 11, 1310, 472, 551, 281, 1565, 294, 51810], "temperature": 0.0, "avg_logprob": -0.23792821353243798, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.0017524438444525003}, {"id": 1094, "seek": 280566, "start": 2805.66, "end": 2809.06, "text": " is when you're, as a quant, when you're doing modeling,", "tokens": [50364, 307, 562, 291, 434, 11, 382, 257, 4426, 11, 562, 291, 434, 884, 15983, 11, 50534], "temperature": 0.0, "avg_logprob": -0.13788610429906134, "compression_ratio": 1.686131386861314, "no_speech_prob": 0.001864743884652853}, {"id": 1095, "seek": 280566, "start": 2809.06, "end": 2811.2999999999997, "text": " you have this very, very complex system", "tokens": [50534, 291, 362, 341, 588, 11, 588, 3997, 1185, 50646], "temperature": 0.0, "avg_logprob": -0.13788610429906134, "compression_ratio": 1.686131386861314, "no_speech_prob": 0.001864743884652853}, {"id": 1096, "seek": 280566, "start": 2811.2999999999997, "end": 2814.42, "text": " and you draw boundaries and you create variables", "tokens": [50646, 293, 291, 2642, 13180, 293, 291, 1884, 9102, 50802], "temperature": 0.0, "avg_logprob": -0.13788610429906134, "compression_ratio": 1.686131386861314, "no_speech_prob": 0.001864743884652853}, {"id": 1097, "seek": 280566, "start": 2814.42, "end": 2816.98, "text": " and observables and do you know what I mean?", "tokens": [50802, 293, 9951, 2965, 293, 360, 291, 458, 437, 286, 914, 30, 50930], "temperature": 0.0, "avg_logprob": -0.13788610429906134, "compression_ratio": 1.686131386861314, "no_speech_prob": 0.001864743884652853}, {"id": 1098, "seek": 280566, "start": 2816.98, "end": 2818.3799999999997, "text": " You kind of build a model", "tokens": [50930, 509, 733, 295, 1322, 257, 2316, 51000], "temperature": 0.0, "avg_logprob": -0.13788610429906134, "compression_ratio": 1.686131386861314, "no_speech_prob": 0.001864743884652853}, {"id": 1099, "seek": 280566, "start": 2818.3799999999997, "end": 2820.94, "text": " and that boundary could exist at any scale.", "tokens": [51000, 293, 300, 12866, 727, 2514, 412, 604, 4373, 13, 51128], "temperature": 0.0, "avg_logprob": -0.13788610429906134, "compression_ratio": 1.686131386861314, "no_speech_prob": 0.001864743884652853}, {"id": 1100, "seek": 280566, "start": 2820.94, "end": 2822.98, "text": " It seems like quite a,", "tokens": [51128, 467, 2544, 411, 1596, 257, 11, 51230], "temperature": 0.0, "avg_logprob": -0.13788610429906134, "compression_ratio": 1.686131386861314, "no_speech_prob": 0.001864743884652853}, {"id": 1101, "seek": 280566, "start": 2822.98, "end": 2826.1, "text": " it's a bit of an art and a science at the same time.", "tokens": [51230, 309, 311, 257, 857, 295, 364, 1523, 293, 257, 3497, 412, 264, 912, 565, 13, 51386], "temperature": 0.0, "avg_logprob": -0.13788610429906134, "compression_ratio": 1.686131386861314, "no_speech_prob": 0.001864743884652853}, {"id": 1102, "seek": 280566, "start": 2826.1, "end": 2827.3799999999997, "text": " Yeah, no, for sure.", "tokens": [51386, 865, 11, 572, 11, 337, 988, 13, 51450], "temperature": 0.0, "avg_logprob": -0.13788610429906134, "compression_ratio": 1.686131386861314, "no_speech_prob": 0.001864743884652853}, {"id": 1103, "seek": 280566, "start": 2828.98, "end": 2829.8199999999997, "text": " Yeah, exactly.", "tokens": [51530, 865, 11, 2293, 13, 51572], "temperature": 0.0, "avg_logprob": -0.13788610429906134, "compression_ratio": 1.686131386861314, "no_speech_prob": 0.001864743884652853}, {"id": 1104, "seek": 280566, "start": 2829.8199999999997, "end": 2833.02, "text": " That's kind of why I like some of these complicated problems", "tokens": [51572, 663, 311, 733, 295, 983, 286, 411, 512, 295, 613, 6179, 2740, 51732], "temperature": 0.0, "avg_logprob": -0.13788610429906134, "compression_ratio": 1.686131386861314, "no_speech_prob": 0.001864743884652853}, {"id": 1105, "seek": 280566, "start": 2833.02, "end": 2834.74, "text": " that are not very well-defined", "tokens": [51732, 300, 366, 406, 588, 731, 12, 37716, 51818], "temperature": 0.0, "avg_logprob": -0.13788610429906134, "compression_ratio": 1.686131386861314, "no_speech_prob": 0.001864743884652853}, {"id": 1106, "seek": 283474, "start": 2834.74, "end": 2837.66, "text": " where you kind of have to use intuition", "tokens": [50364, 689, 291, 733, 295, 362, 281, 764, 24002, 50510], "temperature": 0.0, "avg_logprob": -0.2232876935051483, "compression_ratio": 1.78125, "no_speech_prob": 0.0013245679438114166}, {"id": 1107, "seek": 283474, "start": 2837.66, "end": 2841.4199999999996, "text": " and or just sort of do the best you can do", "tokens": [50510, 293, 420, 445, 1333, 295, 360, 264, 1151, 291, 393, 360, 50698], "temperature": 0.0, "avg_logprob": -0.2232876935051483, "compression_ratio": 1.78125, "no_speech_prob": 0.0013245679438114166}, {"id": 1108, "seek": 283474, "start": 2841.4199999999996, "end": 2843.66, "text": " at sort of drawing what are the relevant variables,", "tokens": [50698, 412, 1333, 295, 6316, 437, 366, 264, 7340, 9102, 11, 50810], "temperature": 0.0, "avg_logprob": -0.2232876935051483, "compression_ratio": 1.78125, "no_speech_prob": 0.0013245679438114166}, {"id": 1109, "seek": 283474, "start": 2843.66, "end": 2845.74, "text": " what sort of a priori makes sense to me", "tokens": [50810, 437, 1333, 295, 257, 4059, 72, 1669, 2020, 281, 385, 50914], "temperature": 0.0, "avg_logprob": -0.2232876935051483, "compression_ratio": 1.78125, "no_speech_prob": 0.0013245679438114166}, {"id": 1110, "seek": 283474, "start": 2845.74, "end": 2849.2599999999998, "text": " to be the things that matter for the system,", "tokens": [50914, 281, 312, 264, 721, 300, 1871, 337, 264, 1185, 11, 51090], "temperature": 0.0, "avg_logprob": -0.2232876935051483, "compression_ratio": 1.78125, "no_speech_prob": 0.0013245679438114166}, {"id": 1111, "seek": 283474, "start": 2849.2599999999998, "end": 2852.66, "text": " behaving at this within the context of this experiment", "tokens": [51090, 35263, 412, 341, 1951, 264, 4319, 295, 341, 5120, 51260], "temperature": 0.0, "avg_logprob": -0.2232876935051483, "compression_ratio": 1.78125, "no_speech_prob": 0.0013245679438114166}, {"id": 1112, "seek": 283474, "start": 2852.66, "end": 2854.8199999999997, "text": " or in the context of this market or whatnot.", "tokens": [51260, 420, 294, 264, 4319, 295, 341, 2142, 420, 25882, 13, 51368], "temperature": 0.0, "avg_logprob": -0.2232876935051483, "compression_ratio": 1.78125, "no_speech_prob": 0.0013245679438114166}, {"id": 1113, "seek": 283474, "start": 2855.8199999999997, "end": 2860.06, "text": " Trying to draw boundaries in because the rules", "tokens": [51418, 20180, 281, 2642, 13180, 294, 570, 264, 4474, 51630], "temperature": 0.0, "avg_logprob": -0.2232876935051483, "compression_ratio": 1.78125, "no_speech_prob": 0.0013245679438114166}, {"id": 1114, "seek": 283474, "start": 2860.06, "end": 2861.74, "text": " for these systems are not clear.", "tokens": [51630, 337, 613, 3652, 366, 406, 1850, 13, 51714], "temperature": 0.0, "avg_logprob": -0.2232876935051483, "compression_ratio": 1.78125, "no_speech_prob": 0.0013245679438114166}, {"id": 1115, "seek": 286174, "start": 2861.74, "end": 2865.3799999999997, "text": " Like what are all the relevant variables for everything", "tokens": [50364, 1743, 437, 366, 439, 264, 7340, 9102, 337, 1203, 50546], "temperature": 0.0, "avg_logprob": -0.14607562875389157, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.0003918808652088046}, {"id": 1116, "seek": 286174, "start": 2865.3799999999997, "end": 2867.8199999999997, "text": " and do you have access to them and can you control them?", "tokens": [50546, 293, 360, 291, 362, 2105, 281, 552, 293, 393, 291, 1969, 552, 30, 50668], "temperature": 0.0, "avg_logprob": -0.14607562875389157, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.0003918808652088046}, {"id": 1117, "seek": 286174, "start": 2867.8199999999997, "end": 2869.7, "text": " And generally you don't know them all", "tokens": [50668, 400, 5101, 291, 500, 380, 458, 552, 439, 50762], "temperature": 0.0, "avg_logprob": -0.14607562875389157, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.0003918808652088046}, {"id": 1118, "seek": 286174, "start": 2869.7, "end": 2871.5, "text": " and you don't necessarily have access", "tokens": [50762, 293, 291, 500, 380, 4725, 362, 2105, 50852], "temperature": 0.0, "avg_logprob": -0.14607562875389157, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.0003918808652088046}, {"id": 1119, "seek": 286174, "start": 2871.5, "end": 2872.8999999999996, "text": " or can control any of them.", "tokens": [50852, 420, 393, 1969, 604, 295, 552, 13, 50922], "temperature": 0.0, "avg_logprob": -0.14607562875389157, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.0003918808652088046}, {"id": 1120, "seek": 286174, "start": 2874.18, "end": 2878.18, "text": " And so it's, yeah, it is a bit of an art.", "tokens": [50986, 400, 370, 309, 311, 11, 1338, 11, 309, 307, 257, 857, 295, 364, 1523, 13, 51186], "temperature": 0.0, "avg_logprob": -0.14607562875389157, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.0003918808652088046}, {"id": 1121, "seek": 286174, "start": 2880.1, "end": 2882.4599999999996, "text": " Well, now might be a good time to talk about numerators.", "tokens": [51282, 1042, 11, 586, 1062, 312, 257, 665, 565, 281, 751, 466, 7866, 3391, 13, 51400], "temperature": 0.0, "avg_logprob": -0.14607562875389157, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.0003918808652088046}, {"id": 1122, "seek": 286174, "start": 2882.4599999999996, "end": 2884.7, "text": " So you're the chief scientist", "tokens": [51400, 407, 291, 434, 264, 9588, 12662, 51512], "temperature": 0.0, "avg_logprob": -0.14607562875389157, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.0003918808652088046}, {"id": 1123, "seek": 286174, "start": 2884.7, "end": 2886.9399999999996, "text": " and it's this insanely cool platform, right?", "tokens": [51512, 293, 309, 311, 341, 40965, 1627, 3663, 11, 558, 30, 51624], "temperature": 0.0, "avg_logprob": -0.14607562875389157, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.0003918808652088046}, {"id": 1124, "seek": 286174, "start": 2886.9399999999996, "end": 2889.7, "text": " So people can go on there, they can download data sets,", "tokens": [51624, 407, 561, 393, 352, 322, 456, 11, 436, 393, 5484, 1412, 6352, 11, 51762], "temperature": 0.0, "avg_logprob": -0.14607562875389157, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.0003918808652088046}, {"id": 1125, "seek": 286174, "start": 2889.7, "end": 2890.7, "text": " they can build their own models,", "tokens": [51762, 436, 393, 1322, 641, 1065, 5245, 11, 51812], "temperature": 0.0, "avg_logprob": -0.14607562875389157, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.0003918808652088046}, {"id": 1126, "seek": 289070, "start": 2890.7, "end": 2891.8999999999996, "text": " they can stake the models.", "tokens": [50364, 436, 393, 10407, 264, 5245, 13, 50424], "temperature": 0.0, "avg_logprob": -0.20081253905794513, "compression_ratio": 1.6631578947368422, "no_speech_prob": 0.0015716636553406715}, {"id": 1127, "seek": 289070, "start": 2891.8999999999996, "end": 2894.5, "text": " I mean, why don't you just talk me through it?", "tokens": [50424, 286, 914, 11, 983, 500, 380, 291, 445, 751, 385, 807, 309, 30, 50554], "temperature": 0.0, "avg_logprob": -0.20081253905794513, "compression_ratio": 1.6631578947368422, "no_speech_prob": 0.0015716636553406715}, {"id": 1128, "seek": 289070, "start": 2894.5, "end": 2895.3399999999997, "text": " Sure, yeah.", "tokens": [50554, 4894, 11, 1338, 13, 50596], "temperature": 0.0, "avg_logprob": -0.20081253905794513, "compression_ratio": 1.6631578947368422, "no_speech_prob": 0.0015716636553406715}, {"id": 1129, "seek": 289070, "start": 2895.3399999999997, "end": 2897.7799999999997, "text": " So we advertise ourselves as being", "tokens": [50596, 407, 321, 35379, 4175, 382, 885, 50718], "temperature": 0.0, "avg_logprob": -0.20081253905794513, "compression_ratio": 1.6631578947368422, "no_speech_prob": 0.0015716636553406715}, {"id": 1130, "seek": 289070, "start": 2897.7799999999997, "end": 2900.8199999999997, "text": " the hardest data science problem on the planet", "tokens": [50718, 264, 13158, 1412, 3497, 1154, 322, 264, 5054, 50870], "temperature": 0.0, "avg_logprob": -0.20081253905794513, "compression_ratio": 1.6631578947368422, "no_speech_prob": 0.0015716636553406715}, {"id": 1131, "seek": 289070, "start": 2900.8199999999997, "end": 2904.1, "text": " because I think it is because like I said,", "tokens": [50870, 570, 286, 519, 309, 307, 570, 411, 286, 848, 11, 51034], "temperature": 0.0, "avg_logprob": -0.20081253905794513, "compression_ratio": 1.6631578947368422, "no_speech_prob": 0.0015716636553406715}, {"id": 1132, "seek": 289070, "start": 2904.1, "end": 2906.02, "text": " the correlations you're chasing are on the order of like", "tokens": [51034, 264, 13983, 763, 291, 434, 17876, 366, 322, 264, 1668, 295, 411, 51130], "temperature": 0.0, "avg_logprob": -0.20081253905794513, "compression_ratio": 1.6631578947368422, "no_speech_prob": 0.0015716636553406715}, {"id": 1133, "seek": 289070, "start": 2906.02, "end": 2910.1, "text": " three or 4% out of sample, which,", "tokens": [51130, 1045, 420, 1017, 4, 484, 295, 6889, 11, 597, 11, 51334], "temperature": 0.0, "avg_logprob": -0.20081253905794513, "compression_ratio": 1.6631578947368422, "no_speech_prob": 0.0015716636553406715}, {"id": 1134, "seek": 289070, "start": 2910.1, "end": 2912.06, "text": " and just sort of being able to tell", "tokens": [51334, 293, 445, 1333, 295, 885, 1075, 281, 980, 51432], "temperature": 0.0, "avg_logprob": -0.20081253905794513, "compression_ratio": 1.6631578947368422, "no_speech_prob": 0.0015716636553406715}, {"id": 1135, "seek": 289070, "start": 2912.06, "end": 2914.2999999999997, "text": " do you have something real or is it just in the noise", "tokens": [51432, 360, 291, 362, 746, 957, 420, 307, 309, 445, 294, 264, 5658, 51544], "temperature": 0.0, "avg_logprob": -0.20081253905794513, "compression_ratio": 1.6631578947368422, "no_speech_prob": 0.0015716636553406715}, {"id": 1136, "seek": 289070, "start": 2914.2999999999997, "end": 2916.98, "text": " can be extremely hard to do, which is,", "tokens": [51544, 393, 312, 4664, 1152, 281, 360, 11, 597, 307, 11, 51678], "temperature": 0.0, "avg_logprob": -0.20081253905794513, "compression_ratio": 1.6631578947368422, "no_speech_prob": 0.0015716636553406715}, {"id": 1137, "seek": 289070, "start": 2916.98, "end": 2920.1, "text": " and we set up the problem for participants.", "tokens": [51678, 293, 321, 992, 493, 264, 1154, 337, 10503, 13, 51834], "temperature": 0.0, "avg_logprob": -0.20081253905794513, "compression_ratio": 1.6631578947368422, "no_speech_prob": 0.0015716636553406715}, {"id": 1138, "seek": 292010, "start": 2920.1, "end": 2923.2999999999997, "text": " You give out a set of data that has been cleaned", "tokens": [50364, 509, 976, 484, 257, 992, 295, 1412, 300, 575, 668, 16146, 50524], "temperature": 0.0, "avg_logprob": -0.13476212112991898, "compression_ratio": 1.8566176470588236, "no_speech_prob": 0.003171281423419714}, {"id": 1139, "seek": 292010, "start": 2923.2999999999997, "end": 2926.5, "text": " and obfuscated and regularized.", "tokens": [50524, 293, 1111, 69, 32601, 770, 293, 3890, 1602, 13, 50684], "temperature": 0.0, "avg_logprob": -0.13476212112991898, "compression_ratio": 1.8566176470588236, "no_speech_prob": 0.003171281423419714}, {"id": 1140, "seek": 292010, "start": 2926.5, "end": 2928.74, "text": " And you basically just have a set of features", "tokens": [50684, 400, 291, 1936, 445, 362, 257, 992, 295, 4122, 50796], "temperature": 0.0, "avg_logprob": -0.13476212112991898, "compression_ratio": 1.8566176470588236, "no_speech_prob": 0.003171281423419714}, {"id": 1141, "seek": 292010, "start": 2928.74, "end": 2930.06, "text": " and a set of targets.", "tokens": [50796, 293, 257, 992, 295, 12911, 13, 50862], "temperature": 0.0, "avg_logprob": -0.13476212112991898, "compression_ratio": 1.8566176470588236, "no_speech_prob": 0.003171281423419714}, {"id": 1142, "seek": 292010, "start": 2930.06, "end": 2931.18, "text": " And you're just trying to build models", "tokens": [50862, 400, 291, 434, 445, 1382, 281, 1322, 5245, 50918], "temperature": 0.0, "avg_logprob": -0.13476212112991898, "compression_ratio": 1.8566176470588236, "no_speech_prob": 0.003171281423419714}, {"id": 1143, "seek": 292010, "start": 2931.18, "end": 2932.2999999999997, "text": " to go from features to targets.", "tokens": [50918, 281, 352, 490, 4122, 281, 12911, 13, 50974], "temperature": 0.0, "avg_logprob": -0.13476212112991898, "compression_ratio": 1.8566176470588236, "no_speech_prob": 0.003171281423419714}, {"id": 1144, "seek": 292010, "start": 2932.2999999999997, "end": 2936.2999999999997, "text": " So it's sort of a very classic machine learning style problem", "tokens": [50974, 407, 309, 311, 1333, 295, 257, 588, 7230, 3479, 2539, 3758, 1154, 51174], "temperature": 0.0, "avg_logprob": -0.13476212112991898, "compression_ratio": 1.8566176470588236, "no_speech_prob": 0.003171281423419714}, {"id": 1145, "seek": 292010, "start": 2936.2999999999997, "end": 2939.02, "text": " and it's nicely curated for you.", "tokens": [51174, 293, 309, 311, 9594, 47851, 337, 291, 13, 51310], "temperature": 0.0, "avg_logprob": -0.13476212112991898, "compression_ratio": 1.8566176470588236, "no_speech_prob": 0.003171281423419714}, {"id": 1146, "seek": 292010, "start": 2939.02, "end": 2942.46, "text": " And how it works for us is every week,", "tokens": [51310, 400, 577, 309, 1985, 337, 505, 307, 633, 1243, 11, 51482], "temperature": 0.0, "avg_logprob": -0.13476212112991898, "compression_ratio": 1.8566176470588236, "no_speech_prob": 0.003171281423419714}, {"id": 1147, "seek": 292010, "start": 2942.46, "end": 2944.74, "text": " people submit predictions on a new set of features.", "tokens": [51482, 561, 10315, 21264, 322, 257, 777, 992, 295, 4122, 13, 51596], "temperature": 0.0, "avg_logprob": -0.13476212112991898, "compression_ratio": 1.8566176470588236, "no_speech_prob": 0.003171281423419714}, {"id": 1148, "seek": 292010, "start": 2944.74, "end": 2946.62, "text": " So every week we release a new set of features", "tokens": [51596, 407, 633, 1243, 321, 4374, 257, 777, 992, 295, 4122, 51690], "temperature": 0.0, "avg_logprob": -0.13476212112991898, "compression_ratio": 1.8566176470588236, "no_speech_prob": 0.003171281423419714}, {"id": 1149, "seek": 292010, "start": 2946.62, "end": 2948.42, "text": " and people just run their models over those features", "tokens": [51690, 293, 561, 445, 1190, 641, 5245, 670, 729, 4122, 51780], "temperature": 0.0, "avg_logprob": -0.13476212112991898, "compression_ratio": 1.8566176470588236, "no_speech_prob": 0.003171281423419714}, {"id": 1150, "seek": 294842, "start": 2948.42, "end": 2950.3, "text": " and give us a set of predictions.", "tokens": [50364, 293, 976, 505, 257, 992, 295, 21264, 13, 50458], "temperature": 0.0, "avg_logprob": -0.14852142333984375, "compression_ratio": 1.9736842105263157, "no_speech_prob": 0.00521821016445756}, {"id": 1151, "seek": 294842, "start": 2950.3, "end": 2952.78, "text": " And people stake on those predictions.", "tokens": [50458, 400, 561, 10407, 322, 729, 21264, 13, 50582], "temperature": 0.0, "avg_logprob": -0.14852142333984375, "compression_ratio": 1.9736842105263157, "no_speech_prob": 0.00521821016445756}, {"id": 1152, "seek": 294842, "start": 2952.78, "end": 2956.14, "text": " And so people stake our cryptocurrency called NMR.", "tokens": [50582, 400, 370, 561, 10407, 527, 28809, 1219, 426, 21173, 13, 50750], "temperature": 0.0, "avg_logprob": -0.14852142333984375, "compression_ratio": 1.9736842105263157, "no_speech_prob": 0.00521821016445756}, {"id": 1153, "seek": 294842, "start": 2956.14, "end": 2959.5, "text": " And if their predictions do well, they make money.", "tokens": [50750, 400, 498, 641, 21264, 360, 731, 11, 436, 652, 1460, 13, 50918], "temperature": 0.0, "avg_logprob": -0.14852142333984375, "compression_ratio": 1.9736842105263157, "no_speech_prob": 0.00521821016445756}, {"id": 1154, "seek": 294842, "start": 2959.5, "end": 2961.42, "text": " And if their predictions don't do well,", "tokens": [50918, 400, 498, 641, 21264, 500, 380, 360, 731, 11, 51014], "temperature": 0.0, "avg_logprob": -0.14852142333984375, "compression_ratio": 1.9736842105263157, "no_speech_prob": 0.00521821016445756}, {"id": 1155, "seek": 294842, "start": 2961.42, "end": 2962.54, "text": " that week they could lose money.", "tokens": [51014, 300, 1243, 436, 727, 3624, 1460, 13, 51070], "temperature": 0.0, "avg_logprob": -0.14852142333984375, "compression_ratio": 1.9736842105263157, "no_speech_prob": 0.00521821016445756}, {"id": 1156, "seek": 294842, "start": 2962.54, "end": 2966.02, "text": " And they sort of are expressing their confidence", "tokens": [51070, 400, 436, 1333, 295, 366, 22171, 641, 6687, 51244], "temperature": 0.0, "avg_logprob": -0.14852142333984375, "compression_ratio": 1.9736842105263157, "no_speech_prob": 0.00521821016445756}, {"id": 1157, "seek": 294842, "start": 2966.02, "end": 2967.78, "text": " in their models using their state.", "tokens": [51244, 294, 641, 5245, 1228, 641, 1785, 13, 51332], "temperature": 0.0, "avg_logprob": -0.14852142333984375, "compression_ratio": 1.9736842105263157, "no_speech_prob": 0.00521821016445756}, {"id": 1158, "seek": 294842, "start": 2968.7400000000002, "end": 2972.78, "text": " And so we basically use this expression of confidence", "tokens": [51380, 400, 370, 321, 1936, 764, 341, 6114, 295, 6687, 51582], "temperature": 0.0, "avg_logprob": -0.14852142333984375, "compression_ratio": 1.9736842105263157, "no_speech_prob": 0.00521821016445756}, {"id": 1159, "seek": 294842, "start": 2972.78, "end": 2975.3, "text": " as a way to sort of integrate these signals", "tokens": [51582, 382, 257, 636, 281, 1333, 295, 13365, 613, 12354, 51708], "temperature": 0.0, "avg_logprob": -0.14852142333984375, "compression_ratio": 1.9736842105263157, "no_speech_prob": 0.00521821016445756}, {"id": 1160, "seek": 294842, "start": 2975.3, "end": 2976.78, "text": " into our meta model.", "tokens": [51708, 666, 527, 19616, 2316, 13, 51782], "temperature": 0.0, "avg_logprob": -0.14852142333984375, "compression_ratio": 1.9736842105263157, "no_speech_prob": 0.00521821016445756}, {"id": 1161, "seek": 297678, "start": 2976.78, "end": 2979.3, "text": " Our meta model is really just like a stake weighted average", "tokens": [50364, 2621, 19616, 2316, 307, 534, 445, 411, 257, 10407, 32807, 4274, 50490], "temperature": 0.0, "avg_logprob": -0.15004092543872435, "compression_ratio": 1.8149466192170818, "no_speech_prob": 0.0002304712834302336}, {"id": 1162, "seek": 297678, "start": 2979.3, "end": 2981.78, "text": " of all the signals people are submitting.", "tokens": [50490, 295, 439, 264, 12354, 561, 366, 31836, 13, 50614], "temperature": 0.0, "avg_logprob": -0.15004092543872435, "compression_ratio": 1.8149466192170818, "no_speech_prob": 0.0002304712834302336}, {"id": 1163, "seek": 297678, "start": 2981.78, "end": 2984.5800000000004, "text": " And these signals, these predictions are just sort of", "tokens": [50614, 400, 613, 12354, 11, 613, 21264, 366, 445, 1333, 295, 50754], "temperature": 0.0, "avg_logprob": -0.15004092543872435, "compression_ratio": 1.8149466192170818, "no_speech_prob": 0.0002304712834302336}, {"id": 1164, "seek": 297678, "start": 2984.5800000000004, "end": 2986.6200000000003, "text": " weights on stocks.", "tokens": [50754, 17443, 322, 12966, 13, 50856], "temperature": 0.0, "avg_logprob": -0.15004092543872435, "compression_ratio": 1.8149466192170818, "no_speech_prob": 0.0002304712834302336}, {"id": 1165, "seek": 297678, "start": 2986.6200000000003, "end": 2988.6200000000003, "text": " They're sort of like, how do we want to go long", "tokens": [50856, 814, 434, 1333, 295, 411, 11, 577, 360, 321, 528, 281, 352, 938, 50956], "temperature": 0.0, "avg_logprob": -0.15004092543872435, "compression_ratio": 1.8149466192170818, "no_speech_prob": 0.0002304712834302336}, {"id": 1166, "seek": 297678, "start": 2988.6200000000003, "end": 2991.1400000000003, "text": " or do we want to go short in the stock?", "tokens": [50956, 420, 360, 321, 528, 281, 352, 2099, 294, 264, 4127, 30, 51082], "temperature": 0.0, "avg_logprob": -0.15004092543872435, "compression_ratio": 1.8149466192170818, "no_speech_prob": 0.0002304712834302336}, {"id": 1167, "seek": 297678, "start": 2991.1400000000003, "end": 2992.5, "text": " There's sort of just expressing,", "tokens": [51082, 821, 311, 1333, 295, 445, 22171, 11, 51150], "temperature": 0.0, "avg_logprob": -0.15004092543872435, "compression_ratio": 1.8149466192170818, "no_speech_prob": 0.0002304712834302336}, {"id": 1168, "seek": 297678, "start": 2992.5, "end": 2995.5400000000004, "text": " do we think a stock is going to go down or going to go up?", "tokens": [51150, 360, 321, 519, 257, 4127, 307, 516, 281, 352, 760, 420, 516, 281, 352, 493, 30, 51302], "temperature": 0.0, "avg_logprob": -0.15004092543872435, "compression_ratio": 1.8149466192170818, "no_speech_prob": 0.0002304712834302336}, {"id": 1169, "seek": 297678, "start": 2995.5400000000004, "end": 2999.1800000000003, "text": " The stake weighted model we feed to through our optimizer,", "tokens": [51302, 440, 10407, 32807, 2316, 321, 3154, 281, 807, 527, 5028, 6545, 11, 51484], "temperature": 0.0, "avg_logprob": -0.15004092543872435, "compression_ratio": 1.8149466192170818, "no_speech_prob": 0.0002304712834302336}, {"id": 1170, "seek": 297678, "start": 2999.1800000000003, "end": 3001.5, "text": " which is just doing a convex optimization problem,", "tokens": [51484, 597, 307, 445, 884, 257, 42432, 19618, 1154, 11, 51600], "temperature": 0.0, "avg_logprob": -0.15004092543872435, "compression_ratio": 1.8149466192170818, "no_speech_prob": 0.0002304712834302336}, {"id": 1171, "seek": 297678, "start": 3001.5, "end": 3004.0600000000004, "text": " trying to create a portfolio from the signal.", "tokens": [51600, 1382, 281, 1884, 257, 12583, 490, 264, 6358, 13, 51728], "temperature": 0.0, "avg_logprob": -0.15004092543872435, "compression_ratio": 1.8149466192170818, "no_speech_prob": 0.0002304712834302336}, {"id": 1172, "seek": 300406, "start": 3004.06, "end": 3007.2999999999997, "text": " And is that portfolio changes week to week?", "tokens": [50364, 400, 307, 300, 12583, 2962, 1243, 281, 1243, 30, 50526], "temperature": 0.0, "avg_logprob": -0.14841811721389359, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.00012729145237244666}, {"id": 1173, "seek": 300406, "start": 3007.2999999999997, "end": 3010.34, "text": " And so that's just the difference between the previous", "tokens": [50526, 400, 370, 300, 311, 445, 264, 2649, 1296, 264, 3894, 50678], "temperature": 0.0, "avg_logprob": -0.14841811721389359, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.00012729145237244666}, {"id": 1174, "seek": 300406, "start": 3010.34, "end": 3012.98, "text": " and the new portfolio is just what we trade every week.", "tokens": [50678, 293, 264, 777, 12583, 307, 445, 437, 321, 4923, 633, 1243, 13, 50810], "temperature": 0.0, "avg_logprob": -0.14841811721389359, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.00012729145237244666}, {"id": 1175, "seek": 300406, "start": 3012.98, "end": 3015.58, "text": " And so our trading is basically completely determined", "tokens": [50810, 400, 370, 527, 9529, 307, 1936, 2584, 9540, 50940], "temperature": 0.0, "avg_logprob": -0.14841811721389359, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.00012729145237244666}, {"id": 1176, "seek": 300406, "start": 3015.58, "end": 3018.5, "text": " by the like thousand people all over the world", "tokens": [50940, 538, 264, 411, 4714, 561, 439, 670, 264, 1002, 51086], "temperature": 0.0, "avg_logprob": -0.14841811721389359, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.00012729145237244666}, {"id": 1177, "seek": 300406, "start": 3018.5, "end": 3020.58, "text": " submitting predictions every week.", "tokens": [51086, 31836, 21264, 633, 1243, 13, 51190], "temperature": 0.0, "avg_logprob": -0.14841811721389359, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.00012729145237244666}, {"id": 1178, "seek": 300406, "start": 3020.58, "end": 3025.06, "text": " And so it's this very kind of nice decentralized hedge fund", "tokens": [51190, 400, 370, 309, 311, 341, 588, 733, 295, 1481, 32870, 25304, 2374, 51414], "temperature": 0.0, "avg_logprob": -0.14841811721389359, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.00012729145237244666}, {"id": 1179, "seek": 300406, "start": 3025.06, "end": 3028.1, "text": " where the signal generation is very decentralized.", "tokens": [51414, 689, 264, 6358, 5125, 307, 588, 32870, 13, 51566], "temperature": 0.0, "avg_logprob": -0.14841811721389359, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.00012729145237244666}, {"id": 1180, "seek": 300406, "start": 3028.1, "end": 3030.04, "text": " And we get the advantage of ensembling", "tokens": [51566, 400, 321, 483, 264, 5002, 295, 12567, 2504, 1688, 51663], "temperature": 0.0, "avg_logprob": -0.14841811721389359, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.00012729145237244666}, {"id": 1181, "seek": 300406, "start": 3030.04, "end": 3032.86, "text": " over a wide variety of models.", "tokens": [51663, 670, 257, 4874, 5673, 295, 5245, 13, 51804], "temperature": 0.0, "avg_logprob": -0.14841811721389359, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.00012729145237244666}, {"id": 1182, "seek": 303286, "start": 3032.9, "end": 3036.34, "text": " And so people are trying to make their models", "tokens": [50366, 400, 370, 561, 366, 1382, 281, 652, 641, 5245, 50538], "temperature": 0.0, "avg_logprob": -0.19853075268199144, "compression_ratio": 1.815126050420168, "no_speech_prob": 0.00039194198325276375}, {"id": 1183, "seek": 303286, "start": 3036.34, "end": 3041.34, "text": " both predict the targets very well and consistently.", "tokens": [50538, 1293, 6069, 264, 12911, 588, 731, 293, 14961, 13, 50788], "temperature": 0.0, "avg_logprob": -0.19853075268199144, "compression_ratio": 1.815126050420168, "no_speech_prob": 0.00039194198325276375}, {"id": 1184, "seek": 303286, "start": 3041.82, "end": 3046.82, "text": " And we have other incentives to try to make them predict", "tokens": [50812, 400, 321, 362, 661, 23374, 281, 853, 281, 652, 552, 6069, 51062], "temperature": 0.0, "avg_logprob": -0.19853075268199144, "compression_ratio": 1.815126050420168, "no_speech_prob": 0.00039194198325276375}, {"id": 1185, "seek": 303286, "start": 3046.82, "end": 3049.1800000000003, "text": " aspects of the targets that other people are not", "tokens": [51062, 7270, 295, 264, 12911, 300, 661, 561, 366, 406, 51180], "temperature": 0.0, "avg_logprob": -0.19853075268199144, "compression_ratio": 1.815126050420168, "no_speech_prob": 0.00039194198325276375}, {"id": 1186, "seek": 303286, "start": 3050.1, "end": 3052.34, "text": " to try to, so that their contribution is sort of more", "tokens": [51226, 281, 853, 281, 11, 370, 300, 641, 13150, 307, 1333, 295, 544, 51338], "temperature": 0.0, "avg_logprob": -0.19853075268199144, "compression_ratio": 1.815126050420168, "no_speech_prob": 0.00039194198325276375}, {"id": 1187, "seek": 303286, "start": 3052.34, "end": 3055.04, "text": " unique and they can make quite a bit of money", "tokens": [51338, 3845, 293, 436, 393, 652, 1596, 257, 857, 295, 1460, 51473], "temperature": 0.0, "avg_logprob": -0.19853075268199144, "compression_ratio": 1.815126050420168, "no_speech_prob": 0.00039194198325276375}, {"id": 1188, "seek": 303286, "start": 3055.04, "end": 3057.34, "text": " by having their predictions be pretty different", "tokens": [51473, 538, 1419, 641, 21264, 312, 1238, 819, 51588], "temperature": 0.0, "avg_logprob": -0.19853075268199144, "compression_ratio": 1.815126050420168, "no_speech_prob": 0.00039194198325276375}, {"id": 1189, "seek": 303286, "start": 3057.34, "end": 3060.1, "text": " from other people's, but also still accounting", "tokens": [51588, 490, 661, 561, 311, 11, 457, 611, 920, 19163, 51726], "temperature": 0.0, "avg_logprob": -0.19853075268199144, "compression_ratio": 1.815126050420168, "no_speech_prob": 0.00039194198325276375}, {"id": 1190, "seek": 303286, "start": 3060.1, "end": 3062.42, "text": " for like variance in the target.", "tokens": [51726, 337, 411, 21977, 294, 264, 3779, 13, 51842], "temperature": 0.0, "avg_logprob": -0.19853075268199144, "compression_ratio": 1.815126050420168, "no_speech_prob": 0.00039194198325276375}, {"id": 1191, "seek": 306242, "start": 3062.42, "end": 3066.7000000000003, "text": " And so that system is what we call true contribution.", "tokens": [50364, 400, 370, 300, 1185, 307, 437, 321, 818, 2074, 13150, 13, 50578], "temperature": 0.0, "avg_logprob": -0.24296150207519532, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.00011233123950660229}, {"id": 1192, "seek": 306242, "start": 3066.7000000000003, "end": 3070.42, "text": " And it's really, we try to, it was our attempt", "tokens": [50578, 400, 309, 311, 534, 11, 321, 853, 281, 11, 309, 390, 527, 5217, 50764], "temperature": 0.0, "avg_logprob": -0.24296150207519532, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.00011233123950660229}, {"id": 1193, "seek": 306242, "start": 3070.42, "end": 3073.7400000000002, "text": " to try to make people's predictions and payouts", "tokens": [50764, 281, 853, 281, 652, 561, 311, 21264, 293, 1689, 7711, 50930], "temperature": 0.0, "avg_logprob": -0.24296150207519532, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.00011233123950660229}, {"id": 1194, "seek": 306242, "start": 3073.7400000000002, "end": 3076.28, "text": " more tied to actual portfolio returns.", "tokens": [50930, 544, 9601, 281, 3539, 12583, 11247, 13, 51057], "temperature": 0.0, "avg_logprob": -0.24296150207519532, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.00011233123950660229}, {"id": 1195, "seek": 306242, "start": 3077.9, "end": 3079.7400000000002, "text": " Because the sort of standard scoring", "tokens": [51138, 1436, 264, 1333, 295, 3832, 22358, 51230], "temperature": 0.0, "avg_logprob": -0.24296150207519532, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.00011233123950660229}, {"id": 1196, "seek": 306242, "start": 3079.7400000000002, "end": 3082.66, "text": " and we're just doing the correlation of how well", "tokens": [51230, 293, 321, 434, 445, 884, 264, 20009, 295, 577, 731, 51376], "temperature": 0.0, "avg_logprob": -0.24296150207519532, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.00011233123950660229}, {"id": 1197, "seek": 306242, "start": 3082.66, "end": 3086.64, "text": " your predictions match like the new weekly week's target", "tokens": [51376, 428, 21264, 2995, 411, 264, 777, 12460, 1243, 311, 3779, 51575], "temperature": 0.0, "avg_logprob": -0.24296150207519532, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.00011233123950660229}, {"id": 1198, "seek": 306242, "start": 3086.64, "end": 3090.6, "text": " that is determined by just how the stocks move that", "tokens": [51575, 300, 307, 9540, 538, 445, 577, 264, 12966, 1286, 300, 51773], "temperature": 0.0, "avg_logprob": -0.24296150207519532, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.00011233123950660229}, {"id": 1199, "seek": 309060, "start": 3090.6, "end": 3092.58, "text": " over the course of 20 days.", "tokens": [50364, 670, 264, 1164, 295, 945, 1708, 13, 50463], "temperature": 0.0, "avg_logprob": -0.19595647580695874, "compression_ratio": 1.8736462093862816, "no_speech_prob": 0.0056400843895971775}, {"id": 1200, "seek": 309060, "start": 3093.7999999999997, "end": 3096.72, "text": " The true contribution is basically sort of doing", "tokens": [50524, 440, 2074, 13150, 307, 1936, 1333, 295, 884, 50670], "temperature": 0.0, "avg_logprob": -0.19595647580695874, "compression_ratio": 1.8736462093862816, "no_speech_prob": 0.0056400843895971775}, {"id": 1201, "seek": 309060, "start": 3096.72, "end": 3099.52, "text": " the whole process, like creating the meta model,", "tokens": [50670, 264, 1379, 1399, 11, 411, 4084, 264, 19616, 2316, 11, 50810], "temperature": 0.0, "avg_logprob": -0.19595647580695874, "compression_ratio": 1.8736462093862816, "no_speech_prob": 0.0056400843895971775}, {"id": 1202, "seek": 309060, "start": 3099.52, "end": 3101.12, "text": " running it through the portfolio optimizer,", "tokens": [50810, 2614, 309, 807, 264, 12583, 5028, 6545, 11, 50890], "temperature": 0.0, "avg_logprob": -0.19595647580695874, "compression_ratio": 1.8736462093862816, "no_speech_prob": 0.0056400843895971775}, {"id": 1203, "seek": 309060, "start": 3101.12, "end": 3103.24, "text": " getting the portfolio, getting portfolio returns.", "tokens": [50890, 1242, 264, 12583, 11, 1242, 12583, 11247, 13, 50996], "temperature": 0.0, "avg_logprob": -0.19595647580695874, "compression_ratio": 1.8736462093862816, "no_speech_prob": 0.0056400843895971775}, {"id": 1204, "seek": 309060, "start": 3103.24, "end": 3105.7999999999997, "text": " And then we try to see like, take the gradient", "tokens": [50996, 400, 550, 321, 853, 281, 536, 411, 11, 747, 264, 16235, 51124], "temperature": 0.0, "avg_logprob": -0.19595647580695874, "compression_ratio": 1.8736462093862816, "no_speech_prob": 0.0056400843895971775}, {"id": 1205, "seek": 309060, "start": 3105.7999999999997, "end": 3108.52, "text": " through all of that until you can find out", "tokens": [51124, 807, 439, 295, 300, 1826, 291, 393, 915, 484, 51260], "temperature": 0.0, "avg_logprob": -0.19595647580695874, "compression_ratio": 1.8736462093862816, "no_speech_prob": 0.0056400843895971775}, {"id": 1206, "seek": 309060, "start": 3108.52, "end": 3110.36, "text": " if people's stakes have been more or less,", "tokens": [51260, 498, 561, 311, 28429, 362, 668, 544, 420, 1570, 11, 51352], "temperature": 0.0, "avg_logprob": -0.19595647580695874, "compression_ratio": 1.8736462093862816, "no_speech_prob": 0.0056400843895971775}, {"id": 1207, "seek": 309060, "start": 3110.36, "end": 3112.2, "text": " would we have made more or less money", "tokens": [51352, 576, 321, 362, 1027, 544, 420, 1570, 1460, 51444], "temperature": 0.0, "avg_logprob": -0.19595647580695874, "compression_ratio": 1.8736462093862816, "no_speech_prob": 0.0056400843895971775}, {"id": 1208, "seek": 309060, "start": 3112.2, "end": 3115.36, "text": " and use this gradient of the stakes", "tokens": [51444, 293, 764, 341, 16235, 295, 264, 28429, 51602], "temperature": 0.0, "avg_logprob": -0.19595647580695874, "compression_ratio": 1.8736462093862816, "no_speech_prob": 0.0056400843895971775}, {"id": 1209, "seek": 309060, "start": 3115.36, "end": 3117.3199999999997, "text": " with respect to the payout, with respect", "tokens": [51602, 365, 3104, 281, 264, 1689, 346, 11, 365, 3104, 51700], "temperature": 0.0, "avg_logprob": -0.19595647580695874, "compression_ratio": 1.8736462093862816, "no_speech_prob": 0.0056400843895971775}, {"id": 1210, "seek": 309060, "start": 3117.3199999999997, "end": 3120.44, "text": " to the portfolio returns as a way to pay people out", "tokens": [51700, 281, 264, 12583, 11247, 382, 257, 636, 281, 1689, 561, 484, 51856], "temperature": 0.0, "avg_logprob": -0.19595647580695874, "compression_ratio": 1.8736462093862816, "no_speech_prob": 0.0056400843895971775}, {"id": 1211, "seek": 312044, "start": 3121.28, "end": 3123.36, "text": " to essentially increase their weight or decrease their weight.", "tokens": [50406, 281, 4476, 3488, 641, 3364, 420, 11514, 641, 3364, 13, 50510], "temperature": 0.0, "avg_logprob": -0.16240633340706503, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0006250257138162851}, {"id": 1212, "seek": 312044, "start": 3123.36, "end": 3125.2000000000003, "text": " And that tends to reward people", "tokens": [50510, 400, 300, 12258, 281, 7782, 561, 50602], "temperature": 0.0, "avg_logprob": -0.16240633340706503, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0006250257138162851}, {"id": 1213, "seek": 312044, "start": 3125.2000000000003, "end": 3127.2000000000003, "text": " with more unique contributions.", "tokens": [50602, 365, 544, 3845, 15725, 13, 50702], "temperature": 0.0, "avg_logprob": -0.16240633340706503, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0006250257138162851}, {"id": 1214, "seek": 312044, "start": 3128.2400000000002, "end": 3129.84, "text": " I've got so many questions.", "tokens": [50754, 286, 600, 658, 370, 867, 1651, 13, 50834], "temperature": 0.0, "avg_logprob": -0.16240633340706503, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0006250257138162851}, {"id": 1215, "seek": 312044, "start": 3129.84, "end": 3133.16, "text": " So, I mean, I really like this idea", "tokens": [50834, 407, 11, 286, 914, 11, 286, 534, 411, 341, 1558, 51000], "temperature": 0.0, "avg_logprob": -0.16240633340706503, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0006250257138162851}, {"id": 1216, "seek": 312044, "start": 3133.16, "end": 3136.0, "text": " because first of all, you're democratizing the whole thing", "tokens": [51000, 570, 700, 295, 439, 11, 291, 434, 37221, 3319, 264, 1379, 551, 51142], "temperature": 0.0, "avg_logprob": -0.16240633340706503, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0006250257138162851}, {"id": 1217, "seek": 312044, "start": 3136.0, "end": 3139.68, "text": " and you're kind of gamifying it and it's a meritocracy.", "tokens": [51142, 293, 291, 434, 733, 295, 8019, 5489, 309, 293, 309, 311, 257, 24527, 38186, 13, 51326], "temperature": 0.0, "avg_logprob": -0.16240633340706503, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0006250257138162851}, {"id": 1218, "seek": 312044, "start": 3139.68, "end": 3142.64, "text": " So any data scientist can go on there", "tokens": [51326, 407, 604, 1412, 12662, 393, 352, 322, 456, 51474], "temperature": 0.0, "avg_logprob": -0.16240633340706503, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0006250257138162851}, {"id": 1219, "seek": 312044, "start": 3142.64, "end": 3144.44, "text": " and flex their muscles and build great models", "tokens": [51474, 293, 5896, 641, 9530, 293, 1322, 869, 5245, 51564], "temperature": 0.0, "avg_logprob": -0.16240633340706503, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0006250257138162851}, {"id": 1220, "seek": 312044, "start": 3144.44, "end": 3145.68, "text": " and be recognized for doing so", "tokens": [51564, 293, 312, 9823, 337, 884, 370, 51626], "temperature": 0.0, "avg_logprob": -0.16240633340706503, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0006250257138162851}, {"id": 1221, "seek": 312044, "start": 3145.68, "end": 3147.4, "text": " and even earn money for doing so.", "tokens": [51626, 293, 754, 6012, 1460, 337, 884, 370, 13, 51712], "temperature": 0.0, "avg_logprob": -0.16240633340706503, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0006250257138162851}, {"id": 1222, "seek": 312044, "start": 3147.4, "end": 3149.94, "text": " But in a way, I want to contrast it to somewhere", "tokens": [51712, 583, 294, 257, 636, 11, 286, 528, 281, 8712, 309, 281, 4079, 51839], "temperature": 0.0, "avg_logprob": -0.16240633340706503, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0006250257138162851}, {"id": 1223, "seek": 314994, "start": 3149.98, "end": 3151.3, "text": " like Kaggle.", "tokens": [50366, 411, 48751, 22631, 13, 50432], "temperature": 0.0, "avg_logprob": -0.17268237129586642, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0033460434060543776}, {"id": 1224, "seek": 314994, "start": 3151.3, "end": 3154.26, "text": " Now, on Kaggle, I mean, traditionally data science", "tokens": [50432, 823, 11, 322, 48751, 22631, 11, 286, 914, 11, 19067, 1412, 3497, 50580], "temperature": 0.0, "avg_logprob": -0.17268237129586642, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0033460434060543776}, {"id": 1225, "seek": 314994, "start": 3154.26, "end": 3157.82, "text": " has been about understanding the domain.", "tokens": [50580, 575, 668, 466, 3701, 264, 9274, 13, 50758], "temperature": 0.0, "avg_logprob": -0.17268237129586642, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0033460434060543776}, {"id": 1226, "seek": 314994, "start": 3157.82, "end": 3160.34, "text": " A lot of data science is business analysis essentially", "tokens": [50758, 316, 688, 295, 1412, 3497, 307, 1606, 5215, 4476, 50884], "temperature": 0.0, "avg_logprob": -0.17268237129586642, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0033460434060543776}, {"id": 1227, "seek": 314994, "start": 3160.34, "end": 3164.06, "text": " and kind of understanding what makes something work", "tokens": [50884, 293, 733, 295, 3701, 437, 1669, 746, 589, 51070], "temperature": 0.0, "avg_logprob": -0.17268237129586642, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0033460434060543776}, {"id": 1228, "seek": 314994, "start": 3164.06, "end": 3165.2200000000003, "text": " in a model.", "tokens": [51070, 294, 257, 2316, 13, 51128], "temperature": 0.0, "avg_logprob": -0.17268237129586642, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0033460434060543776}, {"id": 1229, "seek": 314994, "start": 3165.2200000000003, "end": 3167.54, "text": " And as I understand with Numeri,", "tokens": [51128, 400, 382, 286, 1223, 365, 426, 15583, 72, 11, 51244], "temperature": 0.0, "avg_logprob": -0.17268237129586642, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0033460434060543776}, {"id": 1230, "seek": 314994, "start": 3167.54, "end": 3169.06, "text": " the interface is kind of the same.", "tokens": [51244, 264, 9226, 307, 733, 295, 264, 912, 13, 51320], "temperature": 0.0, "avg_logprob": -0.17268237129586642, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0033460434060543776}, {"id": 1231, "seek": 314994, "start": 3169.06, "end": 3172.66, "text": " So maybe they get similar shape of data every time", "tokens": [51320, 407, 1310, 436, 483, 2531, 3909, 295, 1412, 633, 565, 51500], "temperature": 0.0, "avg_logprob": -0.17268237129586642, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0033460434060543776}, {"id": 1232, "seek": 314994, "start": 3172.66, "end": 3174.34, "text": " they build the models on it.", "tokens": [51500, 436, 1322, 264, 5245, 322, 309, 13, 51584], "temperature": 0.0, "avg_logprob": -0.17268237129586642, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0033460434060543776}, {"id": 1233, "seek": 314994, "start": 3174.34, "end": 3176.62, "text": " And in this domain, because you know,", "tokens": [51584, 400, 294, 341, 9274, 11, 570, 291, 458, 11, 51698], "temperature": 0.0, "avg_logprob": -0.17268237129586642, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0033460434060543776}, {"id": 1234, "seek": 314994, "start": 3176.62, "end": 3178.78, "text": " like there's technical analysis and there's fundamentals", "tokens": [51698, 411, 456, 311, 6191, 5215, 293, 456, 311, 29505, 51806], "temperature": 0.0, "avg_logprob": -0.17268237129586642, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0033460434060543776}, {"id": 1235, "seek": 317878, "start": 3179.0600000000004, "end": 3180.7400000000002, "text": " they might still understand some market.", "tokens": [50378, 436, 1062, 920, 1223, 512, 2142, 13, 50462], "temperature": 0.0, "avg_logprob": -0.14753102522629957, "compression_ratio": 1.8070175438596492, "no_speech_prob": 0.0005355673492886126}, {"id": 1236, "seek": 317878, "start": 3180.7400000000002, "end": 3183.02, "text": " They have some kind of extrinsic understanding", "tokens": [50462, 814, 362, 512, 733, 295, 16455, 1292, 299, 3701, 50576], "temperature": 0.0, "avg_logprob": -0.14753102522629957, "compression_ratio": 1.8070175438596492, "no_speech_prob": 0.0005355673492886126}, {"id": 1237, "seek": 317878, "start": 3183.02, "end": 3184.0600000000004, "text": " of why their model would work,", "tokens": [50576, 295, 983, 641, 2316, 576, 589, 11, 50628], "temperature": 0.0, "avg_logprob": -0.14753102522629957, "compression_ratio": 1.8070175438596492, "no_speech_prob": 0.0005355673492886126}, {"id": 1238, "seek": 317878, "start": 3184.0600000000004, "end": 3187.2200000000003, "text": " but they don't have the same kind of understanding.", "tokens": [50628, 457, 436, 500, 380, 362, 264, 912, 733, 295, 3701, 13, 50786], "temperature": 0.0, "avg_logprob": -0.14753102522629957, "compression_ratio": 1.8070175438596492, "no_speech_prob": 0.0005355673492886126}, {"id": 1239, "seek": 317878, "start": 3187.2200000000003, "end": 3190.46, "text": " No, yeah, the features include all sorts of things", "tokens": [50786, 883, 11, 1338, 11, 264, 4122, 4090, 439, 7527, 295, 721, 50948], "temperature": 0.0, "avg_logprob": -0.14753102522629957, "compression_ratio": 1.8070175438596492, "no_speech_prob": 0.0005355673492886126}, {"id": 1240, "seek": 317878, "start": 3190.46, "end": 3191.94, "text": " from like analyst sentiments", "tokens": [50948, 490, 411, 19085, 41146, 51022], "temperature": 0.0, "avg_logprob": -0.14753102522629957, "compression_ratio": 1.8070175438596492, "no_speech_prob": 0.0005355673492886126}, {"id": 1241, "seek": 317878, "start": 3191.94, "end": 3194.6200000000003, "text": " and other sort of fundamental things", "tokens": [51022, 293, 661, 1333, 295, 8088, 721, 51156], "temperature": 0.0, "avg_logprob": -0.14753102522629957, "compression_ratio": 1.8070175438596492, "no_speech_prob": 0.0005355673492886126}, {"id": 1242, "seek": 317878, "start": 3194.6200000000003, "end": 3197.2200000000003, "text": " to technical features.", "tokens": [51156, 281, 6191, 4122, 13, 51286], "temperature": 0.0, "avg_logprob": -0.14753102522629957, "compression_ratio": 1.8070175438596492, "no_speech_prob": 0.0005355673492886126}, {"id": 1243, "seek": 317878, "start": 3197.2200000000003, "end": 3200.2200000000003, "text": " But that is all sort of obscured from people.", "tokens": [51286, 583, 300, 307, 439, 1333, 295, 22082, 3831, 490, 561, 13, 51436], "temperature": 0.0, "avg_logprob": -0.14753102522629957, "compression_ratio": 1.8070175438596492, "no_speech_prob": 0.0005355673492886126}, {"id": 1244, "seek": 317878, "start": 3200.2200000000003, "end": 3202.6600000000003, "text": " People just have these funny feature names.", "tokens": [51436, 3432, 445, 362, 613, 4074, 4111, 5288, 13, 51558], "temperature": 0.0, "avg_logprob": -0.14753102522629957, "compression_ratio": 1.8070175438596492, "no_speech_prob": 0.0005355673492886126}, {"id": 1245, "seek": 317878, "start": 3202.6600000000003, "end": 3204.1800000000003, "text": " And so it's up to them to just use", "tokens": [51558, 400, 370, 309, 311, 493, 281, 552, 281, 445, 764, 51634], "temperature": 0.0, "avg_logprob": -0.14753102522629957, "compression_ratio": 1.8070175438596492, "no_speech_prob": 0.0005355673492886126}, {"id": 1246, "seek": 317878, "start": 3204.1800000000003, "end": 3206.42, "text": " their sort of machine learning toolbox", "tokens": [51634, 641, 1333, 295, 3479, 2539, 44593, 51746], "temperature": 0.0, "avg_logprob": -0.14753102522629957, "compression_ratio": 1.8070175438596492, "no_speech_prob": 0.0005355673492886126}, {"id": 1247, "seek": 317878, "start": 3206.42, "end": 3208.1000000000004, "text": " to figure out what are the good features", "tokens": [51746, 281, 2573, 484, 437, 366, 264, 665, 4122, 51830], "temperature": 0.0, "avg_logprob": -0.14753102522629957, "compression_ratio": 1.8070175438596492, "no_speech_prob": 0.0005355673492886126}, {"id": 1248, "seek": 320810, "start": 3208.1, "end": 3210.74, "text": " for predicting what features tend to work well.", "tokens": [50364, 337, 32884, 437, 4122, 3928, 281, 589, 731, 13, 50496], "temperature": 0.0, "avg_logprob": -0.1537452863610309, "compression_ratio": 1.6798418972332017, "no_speech_prob": 0.000606941117439419}, {"id": 1249, "seek": 320810, "start": 3211.66, "end": 3214.2999999999997, "text": " How do we combine those features?", "tokens": [50542, 1012, 360, 321, 10432, 729, 4122, 30, 50674], "temperature": 0.0, "avg_logprob": -0.1537452863610309, "compression_ratio": 1.6798418972332017, "no_speech_prob": 0.000606941117439419}, {"id": 1250, "seek": 320810, "start": 3214.2999999999997, "end": 3217.1, "text": " And so we actually wanted to kind of like remove", "tokens": [50674, 400, 370, 321, 767, 1415, 281, 733, 295, 411, 4159, 50814], "temperature": 0.0, "avg_logprob": -0.1537452863610309, "compression_ratio": 1.6798418972332017, "no_speech_prob": 0.000606941117439419}, {"id": 1251, "seek": 320810, "start": 3217.1, "end": 3219.62, "text": " any of the people's biases for what features", "tokens": [50814, 604, 295, 264, 561, 311, 32152, 337, 437, 4122, 50940], "temperature": 0.0, "avg_logprob": -0.1537452863610309, "compression_ratio": 1.6798418972332017, "no_speech_prob": 0.000606941117439419}, {"id": 1252, "seek": 320810, "start": 3219.62, "end": 3221.02, "text": " they think will work.", "tokens": [50940, 436, 519, 486, 589, 13, 51010], "temperature": 0.0, "avg_logprob": -0.1537452863610309, "compression_ratio": 1.6798418972332017, "no_speech_prob": 0.000606941117439419}, {"id": 1253, "seek": 320810, "start": 3221.02, "end": 3225.38, "text": " We wanted to not have people's financial intuitions", "tokens": [51010, 492, 1415, 281, 406, 362, 561, 311, 4669, 16224, 626, 51228], "temperature": 0.0, "avg_logprob": -0.1537452863610309, "compression_ratio": 1.6798418972332017, "no_speech_prob": 0.000606941117439419}, {"id": 1254, "seek": 320810, "start": 3225.38, "end": 3226.22, "text": " play into it.", "tokens": [51228, 862, 666, 309, 13, 51270], "temperature": 0.0, "avg_logprob": -0.1537452863610309, "compression_ratio": 1.6798418972332017, "no_speech_prob": 0.000606941117439419}, {"id": 1255, "seek": 320810, "start": 3226.22, "end": 3227.3399999999997, "text": " We wanted to just sort of set it up", "tokens": [51270, 492, 1415, 281, 445, 1333, 295, 992, 309, 493, 51326], "temperature": 0.0, "avg_logprob": -0.1537452863610309, "compression_ratio": 1.6798418972332017, "no_speech_prob": 0.000606941117439419}, {"id": 1256, "seek": 320810, "start": 3227.3399999999997, "end": 3229.9, "text": " as a pure machine learning problem.", "tokens": [51326, 382, 257, 6075, 3479, 2539, 1154, 13, 51454], "temperature": 0.0, "avg_logprob": -0.1537452863610309, "compression_ratio": 1.6798418972332017, "no_speech_prob": 0.000606941117439419}, {"id": 1257, "seek": 320810, "start": 3229.9, "end": 3234.2999999999997, "text": " To try to make it, yeah, basically to make it be better", "tokens": [51454, 1407, 853, 281, 652, 309, 11, 1338, 11, 1936, 281, 652, 309, 312, 1101, 51674], "temperature": 0.0, "avg_logprob": -0.1537452863610309, "compression_ratio": 1.6798418972332017, "no_speech_prob": 0.000606941117439419}, {"id": 1258, "seek": 320810, "start": 3234.2999999999997, "end": 3236.62, "text": " than any human could possibly be.", "tokens": [51674, 813, 604, 1952, 727, 6264, 312, 13, 51790], "temperature": 0.0, "avg_logprob": -0.1537452863610309, "compression_ratio": 1.6798418972332017, "no_speech_prob": 0.000606941117439419}, {"id": 1259, "seek": 323662, "start": 3237.46, "end": 3240.42, "text": " So with this sort of combined ensemble wisdom", "tokens": [50406, 407, 365, 341, 1333, 295, 9354, 19492, 10712, 50554], "temperature": 0.0, "avg_logprob": -0.2124636406991996, "compression_ratio": 1.5708333333333333, "no_speech_prob": 0.0006875277031213045}, {"id": 1260, "seek": 323662, "start": 3240.42, "end": 3242.7, "text": " with the crowd, we're trying to make it", "tokens": [50554, 365, 264, 6919, 11, 321, 434, 1382, 281, 652, 309, 50668], "temperature": 0.0, "avg_logprob": -0.2124636406991996, "compression_ratio": 1.5708333333333333, "no_speech_prob": 0.0006875277031213045}, {"id": 1261, "seek": 323662, "start": 3242.7, "end": 3245.46, "text": " like the alpha go of like finance,", "tokens": [50668, 411, 264, 8961, 352, 295, 411, 10719, 11, 50806], "temperature": 0.0, "avg_logprob": -0.2124636406991996, "compression_ratio": 1.5708333333333333, "no_speech_prob": 0.0006875277031213045}, {"id": 1262, "seek": 323662, "start": 3245.46, "end": 3246.8199999999997, "text": " something that it's just that performs", "tokens": [50806, 746, 300, 309, 311, 445, 300, 26213, 50874], "temperature": 0.0, "avg_logprob": -0.2124636406991996, "compression_ratio": 1.5708333333333333, "no_speech_prob": 0.0006875277031213045}, {"id": 1263, "seek": 323662, "start": 3246.8199999999997, "end": 3248.1, "text": " at like a super human level", "tokens": [50874, 412, 411, 257, 1687, 1952, 1496, 50938], "temperature": 0.0, "avg_logprob": -0.2124636406991996, "compression_ratio": 1.5708333333333333, "no_speech_prob": 0.0006875277031213045}, {"id": 1264, "seek": 323662, "start": 3248.1, "end": 3250.1, "text": " in ways you don't really understand.", "tokens": [50938, 294, 2098, 291, 500, 380, 534, 1223, 13, 51038], "temperature": 0.0, "avg_logprob": -0.2124636406991996, "compression_ratio": 1.5708333333333333, "no_speech_prob": 0.0006875277031213045}, {"id": 1265, "seek": 323662, "start": 3251.2999999999997, "end": 3252.14, "text": " Interesting.", "tokens": [51098, 14711, 13, 51140], "temperature": 0.0, "avg_logprob": -0.2124636406991996, "compression_ratio": 1.5708333333333333, "no_speech_prob": 0.0006875277031213045}, {"id": 1266, "seek": 323662, "start": 3252.14, "end": 3254.8199999999997, "text": " And you're aggregating the predictions together", "tokens": [51140, 400, 291, 434, 16743, 990, 264, 21264, 1214, 51274], "temperature": 0.0, "avg_logprob": -0.2124636406991996, "compression_ratio": 1.5708333333333333, "no_speech_prob": 0.0006875277031213045}, {"id": 1267, "seek": 323662, "start": 3254.8199999999997, "end": 3255.74, "text": " in some way.", "tokens": [51274, 294, 512, 636, 13, 51320], "temperature": 0.0, "avg_logprob": -0.2124636406991996, "compression_ratio": 1.5708333333333333, "no_speech_prob": 0.0006875277031213045}, {"id": 1268, "seek": 323662, "start": 3256.7, "end": 3259.2599999999998, "text": " Yeah, it's actually fairly simple.", "tokens": [51368, 865, 11, 309, 311, 767, 6457, 2199, 13, 51496], "temperature": 0.0, "avg_logprob": -0.2124636406991996, "compression_ratio": 1.5708333333333333, "no_speech_prob": 0.0006875277031213045}, {"id": 1269, "seek": 323662, "start": 3259.2599999999998, "end": 3262.18, "text": " We, I mean, people submit their predictions", "tokens": [51496, 492, 11, 286, 914, 11, 561, 10315, 641, 21264, 51642], "temperature": 0.0, "avg_logprob": -0.2124636406991996, "compression_ratio": 1.5708333333333333, "no_speech_prob": 0.0006875277031213045}, {"id": 1270, "seek": 326218, "start": 3262.62, "end": 3264.98, "text": " which are just a number between zero and one", "tokens": [50386, 597, 366, 445, 257, 1230, 1296, 4018, 293, 472, 50504], "temperature": 0.0, "avg_logprob": -0.09169683300080847, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.008575838059186935}, {"id": 1271, "seek": 326218, "start": 3264.98, "end": 3265.8599999999997, "text": " for every stock.", "tokens": [50504, 337, 633, 4127, 13, 50548], "temperature": 0.0, "avg_logprob": -0.09169683300080847, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.008575838059186935}, {"id": 1272, "seek": 326218, "start": 3266.94, "end": 3269.2999999999997, "text": " And it's basically just a rank ordering of stock.", "tokens": [50602, 400, 309, 311, 1936, 445, 257, 6181, 21739, 295, 4127, 13, 50720], "temperature": 0.0, "avg_logprob": -0.09169683300080847, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.008575838059186935}, {"id": 1273, "seek": 326218, "start": 3269.2999999999997, "end": 3272.7, "text": " And we just normalize everyone's predictions", "tokens": [50720, 400, 321, 445, 2710, 1125, 1518, 311, 21264, 50890], "temperature": 0.0, "avg_logprob": -0.09169683300080847, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.008575838059186935}, {"id": 1274, "seek": 326218, "start": 3272.7, "end": 3274.3799999999997, "text": " and then just weight them by their stake", "tokens": [50890, 293, 550, 445, 3364, 552, 538, 641, 10407, 50974], "temperature": 0.0, "avg_logprob": -0.09169683300080847, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.008575838059186935}, {"id": 1275, "seek": 326218, "start": 3274.3799999999997, "end": 3276.18, "text": " and then just average them together", "tokens": [50974, 293, 550, 445, 4274, 552, 1214, 51064], "temperature": 0.0, "avg_logprob": -0.09169683300080847, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.008575838059186935}, {"id": 1276, "seek": 326218, "start": 3276.18, "end": 3278.46, "text": " and to do another renormalization", "tokens": [51064, 293, 281, 360, 1071, 8124, 24440, 2144, 51178], "temperature": 0.0, "avg_logprob": -0.09169683300080847, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.008575838059186935}, {"id": 1277, "seek": 326218, "start": 3278.46, "end": 3279.98, "text": " so that it's the right scale", "tokens": [51178, 370, 300, 309, 311, 264, 558, 4373, 51254], "temperature": 0.0, "avg_logprob": -0.09169683300080847, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.008575838059186935}, {"id": 1278, "seek": 326218, "start": 3279.98, "end": 3281.98, "text": " and sort of distributional shape", "tokens": [51254, 293, 1333, 295, 7316, 304, 3909, 51354], "temperature": 0.0, "avg_logprob": -0.09169683300080847, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.008575838059186935}, {"id": 1279, "seek": 326218, "start": 3281.98, "end": 3283.3799999999997, "text": " to be fed to the optimizer.", "tokens": [51354, 281, 312, 4636, 281, 264, 5028, 6545, 13, 51424], "temperature": 0.0, "avg_logprob": -0.09169683300080847, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.008575838059186935}, {"id": 1280, "seek": 326218, "start": 3284.54, "end": 3288.4199999999996, "text": " But it's a fairly simple and robust way to weight things.", "tokens": [51482, 583, 309, 311, 257, 6457, 2199, 293, 13956, 636, 281, 3364, 721, 13, 51676], "temperature": 0.0, "avg_logprob": -0.09169683300080847, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.008575838059186935}, {"id": 1281, "seek": 326218, "start": 3288.4199999999996, "end": 3290.98, "text": " We're basically just using people's express confidence", "tokens": [51676, 492, 434, 1936, 445, 1228, 561, 311, 5109, 6687, 51804], "temperature": 0.0, "avg_logprob": -0.09169683300080847, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.008575838059186935}, {"id": 1282, "seek": 329098, "start": 3290.98, "end": 3294.42, "text": " in their model as the weighting system.", "tokens": [50364, 294, 641, 2316, 382, 264, 3364, 278, 1185, 13, 50536], "temperature": 0.0, "avg_logprob": -0.12478118309607873, "compression_ratio": 1.9157088122605364, "no_speech_prob": 0.0005508234025910497}, {"id": 1283, "seek": 329098, "start": 3294.42, "end": 3297.22, "text": " And because there's this feedback of payments", "tokens": [50536, 400, 570, 456, 311, 341, 5824, 295, 14348, 50676], "temperature": 0.0, "avg_logprob": -0.12478118309607873, "compression_ratio": 1.9157088122605364, "no_speech_prob": 0.0005508234025910497}, {"id": 1284, "seek": 329098, "start": 3297.22, "end": 3299.98, "text": " and paying out people, good models,", "tokens": [50676, 293, 6229, 484, 561, 11, 665, 5245, 11, 50814], "temperature": 0.0, "avg_logprob": -0.12478118309607873, "compression_ratio": 1.9157088122605364, "no_speech_prob": 0.0005508234025910497}, {"id": 1285, "seek": 329098, "start": 3299.98, "end": 3301.26, "text": " their stakes increase over time", "tokens": [50814, 641, 28429, 3488, 670, 565, 50878], "temperature": 0.0, "avg_logprob": -0.12478118309607873, "compression_ratio": 1.9157088122605364, "no_speech_prob": 0.0005508234025910497}, {"id": 1286, "seek": 329098, "start": 3301.26, "end": 3303.42, "text": " so their weight in the meta model increases over time", "tokens": [50878, 370, 641, 3364, 294, 264, 19616, 2316, 8637, 670, 565, 50986], "temperature": 0.0, "avg_logprob": -0.12478118309607873, "compression_ratio": 1.9157088122605364, "no_speech_prob": 0.0005508234025910497}, {"id": 1287, "seek": 329098, "start": 3303.42, "end": 3306.1, "text": " and bad models, their weights decrease over time.", "tokens": [50986, 293, 1578, 5245, 11, 641, 17443, 11514, 670, 565, 13, 51120], "temperature": 0.0, "avg_logprob": -0.12478118309607873, "compression_ratio": 1.9157088122605364, "no_speech_prob": 0.0005508234025910497}, {"id": 1288, "seek": 329098, "start": 3306.1, "end": 3308.62, "text": " So it's kind of like a human in the gradient descent", "tokens": [51120, 407, 309, 311, 733, 295, 411, 257, 1952, 294, 264, 16235, 23475, 51246], "temperature": 0.0, "avg_logprob": -0.12478118309607873, "compression_ratio": 1.9157088122605364, "no_speech_prob": 0.0005508234025910497}, {"id": 1289, "seek": 329098, "start": 3308.62, "end": 3310.14, "text": " for doing like gradient descent", "tokens": [51246, 337, 884, 411, 16235, 23475, 51322], "temperature": 0.0, "avg_logprob": -0.12478118309607873, "compression_ratio": 1.9157088122605364, "no_speech_prob": 0.0005508234025910497}, {"id": 1290, "seek": 329098, "start": 3310.14, "end": 3313.42, "text": " with the stakes as the weights in the model.", "tokens": [51322, 365, 264, 28429, 382, 264, 17443, 294, 264, 2316, 13, 51486], "temperature": 0.0, "avg_logprob": -0.12478118309607873, "compression_ratio": 1.9157088122605364, "no_speech_prob": 0.0005508234025910497}, {"id": 1291, "seek": 329098, "start": 3313.42, "end": 3314.26, "text": " Fascinating.", "tokens": [51486, 49098, 8205, 13, 51528], "temperature": 0.0, "avg_logprob": -0.12478118309607873, "compression_ratio": 1.9157088122605364, "no_speech_prob": 0.0005508234025910497}, {"id": 1292, "seek": 329098, "start": 3314.26, "end": 3315.54, "text": " And can you give us any intuition", "tokens": [51528, 400, 393, 291, 976, 505, 604, 24002, 51592], "temperature": 0.0, "avg_logprob": -0.12478118309607873, "compression_ratio": 1.9157088122605364, "no_speech_prob": 0.0005508234025910497}, {"id": 1293, "seek": 329098, "start": 3315.54, "end": 3317.54, "text": " on how that model is tuned", "tokens": [51592, 322, 577, 300, 2316, 307, 10870, 51692], "temperature": 0.0, "avg_logprob": -0.12478118309607873, "compression_ratio": 1.9157088122605364, "no_speech_prob": 0.0005508234025910497}, {"id": 1294, "seek": 329098, "start": 3317.54, "end": 3320.5, "text": " and what kind of penalty you're using?", "tokens": [51692, 293, 437, 733, 295, 16263, 291, 434, 1228, 30, 51840], "temperature": 0.0, "avg_logprob": -0.12478118309607873, "compression_ratio": 1.9157088122605364, "no_speech_prob": 0.0005508234025910497}, {"id": 1295, "seek": 332050, "start": 3320.5, "end": 3322.1, "text": " Are you using just the stakes", "tokens": [50364, 2014, 291, 1228, 445, 264, 28429, 50444], "temperature": 0.0, "avg_logprob": -0.1814613173493242, "compression_ratio": 1.8855932203389831, "no_speech_prob": 0.00023397340555675328}, {"id": 1296, "seek": 332050, "start": 3322.1, "end": 3325.14, "text": " or also the previous performance?", "tokens": [50444, 420, 611, 264, 3894, 3389, 30, 50596], "temperature": 0.0, "avg_logprob": -0.1814613173493242, "compression_ratio": 1.8855932203389831, "no_speech_prob": 0.00023397340555675328}, {"id": 1297, "seek": 332050, "start": 3325.14, "end": 3327.82, "text": " So no, we're not actually using the previous performance.", "tokens": [50596, 407, 572, 11, 321, 434, 406, 767, 1228, 264, 3894, 3389, 13, 50730], "temperature": 0.0, "avg_logprob": -0.1814613173493242, "compression_ratio": 1.8855932203389831, "no_speech_prob": 0.00023397340555675328}, {"id": 1298, "seek": 332050, "start": 3327.82, "end": 3329.3, "text": " It's really just stakes.", "tokens": [50730, 467, 311, 534, 445, 28429, 13, 50804], "temperature": 0.0, "avg_logprob": -0.1814613173493242, "compression_ratio": 1.8855932203389831, "no_speech_prob": 0.00023397340555675328}, {"id": 1299, "seek": 332050, "start": 3329.3, "end": 3332.3, "text": " The previous performance only enters into the fact", "tokens": [50804, 440, 3894, 3389, 787, 18780, 666, 264, 1186, 50954], "temperature": 0.0, "avg_logprob": -0.1814613173493242, "compression_ratio": 1.8855932203389831, "no_speech_prob": 0.00023397340555675328}, {"id": 1300, "seek": 332050, "start": 3332.3, "end": 3334.46, "text": " that the good performance of the past", "tokens": [50954, 300, 264, 665, 3389, 295, 264, 1791, 51062], "temperature": 0.0, "avg_logprob": -0.1814613173493242, "compression_ratio": 1.8855932203389831, "no_speech_prob": 0.00023397340555675328}, {"id": 1301, "seek": 332050, "start": 3334.46, "end": 3336.86, "text": " would have made their stake grow over time.", "tokens": [51062, 576, 362, 1027, 641, 10407, 1852, 670, 565, 13, 51182], "temperature": 0.0, "avg_logprob": -0.1814613173493242, "compression_ratio": 1.8855932203389831, "no_speech_prob": 0.00023397340555675328}, {"id": 1302, "seek": 332050, "start": 3338.22, "end": 3342.02, "text": " And but we have thousands and thousands of models now.", "tokens": [51250, 400, 457, 321, 362, 5383, 293, 5383, 295, 5245, 586, 13, 51440], "temperature": 0.0, "avg_logprob": -0.1814613173493242, "compression_ratio": 1.8855932203389831, "no_speech_prob": 0.00023397340555675328}, {"id": 1303, "seek": 332050, "start": 3342.02, "end": 3345.78, "text": " And so any one model is only a very small percentage", "tokens": [51440, 400, 370, 604, 472, 2316, 307, 787, 257, 588, 1359, 9668, 51628], "temperature": 0.0, "avg_logprob": -0.1814613173493242, "compression_ratio": 1.8855932203389831, "no_speech_prob": 0.00023397340555675328}, {"id": 1304, "seek": 332050, "start": 3345.78, "end": 3346.78, "text": " of the meta model.", "tokens": [51628, 295, 264, 19616, 2316, 13, 51678], "temperature": 0.0, "avg_logprob": -0.1814613173493242, "compression_ratio": 1.8855932203389831, "no_speech_prob": 0.00023397340555675328}, {"id": 1305, "seek": 332050, "start": 3347.86, "end": 3349.78, "text": " And even the ones that are the biggest", "tokens": [51732, 400, 754, 264, 2306, 300, 366, 264, 3880, 51828], "temperature": 0.0, "avg_logprob": -0.1814613173493242, "compression_ratio": 1.8855932203389831, "no_speech_prob": 0.00023397340555675328}, {"id": 1306, "seek": 334978, "start": 3350.02, "end": 3352.7000000000003, "text": " maybe only a couple percent of the total meta model.", "tokens": [50376, 1310, 787, 257, 1916, 3043, 295, 264, 3217, 19616, 2316, 13, 50510], "temperature": 0.0, "avg_logprob": -0.1543608358350851, "compression_ratio": 1.7529411764705882, "no_speech_prob": 0.0015482584713026881}, {"id": 1307, "seek": 334978, "start": 3352.7000000000003, "end": 3355.5800000000004, "text": " And it's, it is a sort of like power law distribution.", "tokens": [50510, 400, 309, 311, 11, 309, 307, 257, 1333, 295, 411, 1347, 2101, 7316, 13, 50654], "temperature": 0.0, "avg_logprob": -0.1543608358350851, "compression_ratio": 1.7529411764705882, "no_speech_prob": 0.0015482584713026881}, {"id": 1308, "seek": 334978, "start": 3356.5, "end": 3358.94, "text": " There is a lot of work that I've done", "tokens": [50700, 821, 307, 257, 688, 295, 589, 300, 286, 600, 1096, 50822], "temperature": 0.0, "avg_logprob": -0.1543608358350851, "compression_ratio": 1.7529411764705882, "no_speech_prob": 0.0015482584713026881}, {"id": 1309, "seek": 334978, "start": 3358.94, "end": 3361.42, "text": " in the portfolio optimization set.", "tokens": [50822, 294, 264, 12583, 19618, 992, 13, 50946], "temperature": 0.0, "avg_logprob": -0.1543608358350851, "compression_ratio": 1.7529411764705882, "no_speech_prob": 0.0015482584713026881}, {"id": 1310, "seek": 334978, "start": 3362.78, "end": 3366.7400000000002, "text": " And that's the going from the signal to the portfolio.", "tokens": [51014, 400, 300, 311, 264, 516, 490, 264, 6358, 281, 264, 12583, 13, 51212], "temperature": 0.0, "avg_logprob": -0.1543608358350851, "compression_ratio": 1.7529411764705882, "no_speech_prob": 0.0015482584713026881}, {"id": 1311, "seek": 334978, "start": 3366.7400000000002, "end": 3370.0600000000004, "text": " And there is actually a lot that goes on in there as well", "tokens": [51212, 400, 456, 307, 767, 257, 688, 300, 1709, 322, 294, 456, 382, 731, 51378], "temperature": 0.0, "avg_logprob": -0.1543608358350851, "compression_ratio": 1.7529411764705882, "no_speech_prob": 0.0015482584713026881}, {"id": 1312, "seek": 334978, "start": 3370.0600000000004, "end": 3371.9, "text": " just in how you construct a portfolio,", "tokens": [51378, 445, 294, 577, 291, 7690, 257, 12583, 11, 51470], "temperature": 0.0, "avg_logprob": -0.1543608358350851, "compression_ratio": 1.7529411764705882, "no_speech_prob": 0.0015482584713026881}, {"id": 1313, "seek": 334978, "start": 3371.9, "end": 3375.2200000000003, "text": " how you determine how much you're gonna trade each week", "tokens": [51470, 577, 291, 6997, 577, 709, 291, 434, 799, 4923, 1184, 1243, 51636], "temperature": 0.0, "avg_logprob": -0.1543608358350851, "compression_ratio": 1.7529411764705882, "no_speech_prob": 0.0015482584713026881}, {"id": 1314, "seek": 334978, "start": 3375.2200000000003, "end": 3378.82, "text": " and how you make your portfolio, what you make exposed to.", "tokens": [51636, 293, 577, 291, 652, 428, 12583, 11, 437, 291, 652, 9495, 281, 13, 51816], "temperature": 0.0, "avg_logprob": -0.1543608358350851, "compression_ratio": 1.7529411764705882, "no_speech_prob": 0.0015482584713026881}, {"id": 1315, "seek": 337882, "start": 3378.82, "end": 3381.1000000000004, "text": " Exposed really just means is are the weights", "tokens": [50364, 21391, 1744, 534, 445, 1355, 307, 366, 264, 17443, 50478], "temperature": 0.0, "avg_logprob": -0.15785306783822867, "compression_ratio": 1.8461538461538463, "no_speech_prob": 0.00014880712842568755}, {"id": 1316, "seek": 337882, "start": 3381.1000000000004, "end": 3383.94, "text": " of your portfolio correlated with lots and lots of things?", "tokens": [50478, 295, 428, 12583, 38574, 365, 3195, 293, 3195, 295, 721, 30, 50620], "temperature": 0.0, "avg_logprob": -0.15785306783822867, "compression_ratio": 1.8461538461538463, "no_speech_prob": 0.00014880712842568755}, {"id": 1317, "seek": 337882, "start": 3383.94, "end": 3387.06, "text": " And so there's a lot we go due to try", "tokens": [50620, 400, 370, 456, 311, 257, 688, 321, 352, 3462, 281, 853, 50776], "temperature": 0.0, "avg_logprob": -0.15785306783822867, "compression_ratio": 1.8461538461538463, "no_speech_prob": 0.00014880712842568755}, {"id": 1318, "seek": 337882, "start": 3387.06, "end": 3389.2200000000003, "text": " to make the portfolio weights not correlated", "tokens": [50776, 281, 652, 264, 12583, 17443, 406, 38574, 50884], "temperature": 0.0, "avg_logprob": -0.15785306783822867, "compression_ratio": 1.8461538461538463, "no_speech_prob": 0.00014880712842568755}, {"id": 1319, "seek": 337882, "start": 3389.2200000000003, "end": 3391.1800000000003, "text": " with the market overall.", "tokens": [50884, 365, 264, 2142, 4787, 13, 50982], "temperature": 0.0, "avg_logprob": -0.15785306783822867, "compression_ratio": 1.8461538461538463, "no_speech_prob": 0.00014880712842568755}, {"id": 1320, "seek": 337882, "start": 3391.1800000000003, "end": 3395.98, "text": " So we're a market neutral hedge fund.", "tokens": [50982, 407, 321, 434, 257, 2142, 10598, 25304, 2374, 13, 51222], "temperature": 0.0, "avg_logprob": -0.15785306783822867, "compression_ratio": 1.8461538461538463, "no_speech_prob": 0.00014880712842568755}, {"id": 1321, "seek": 337882, "start": 3395.98, "end": 3398.06, "text": " So we try to be uncorrelated to the market,", "tokens": [51222, 407, 321, 853, 281, 312, 6219, 284, 12004, 281, 264, 2142, 11, 51326], "temperature": 0.0, "avg_logprob": -0.15785306783822867, "compression_ratio": 1.8461538461538463, "no_speech_prob": 0.00014880712842568755}, {"id": 1322, "seek": 337882, "start": 3398.06, "end": 3400.02, "text": " have a beta of zero.", "tokens": [51326, 362, 257, 9861, 295, 4018, 13, 51424], "temperature": 0.0, "avg_logprob": -0.15785306783822867, "compression_ratio": 1.8461538461538463, "no_speech_prob": 0.00014880712842568755}, {"id": 1323, "seek": 337882, "start": 3400.02, "end": 3401.54, "text": " So when the market goes up or down,", "tokens": [51424, 407, 562, 264, 2142, 1709, 493, 420, 760, 11, 51500], "temperature": 0.0, "avg_logprob": -0.15785306783822867, "compression_ratio": 1.8461538461538463, "no_speech_prob": 0.00014880712842568755}, {"id": 1324, "seek": 337882, "start": 3401.54, "end": 3405.06, "text": " you can't really tell how we would do on that kind of day.", "tokens": [51500, 291, 393, 380, 534, 980, 577, 321, 576, 360, 322, 300, 733, 295, 786, 13, 51676], "temperature": 0.0, "avg_logprob": -0.15785306783822867, "compression_ratio": 1.8461538461538463, "no_speech_prob": 0.00014880712842568755}, {"id": 1325, "seek": 337882, "start": 3405.06, "end": 3406.94, "text": " And but we also try to be uncorrelated to lots", "tokens": [51676, 400, 457, 321, 611, 853, 281, 312, 6219, 284, 12004, 281, 3195, 51770], "temperature": 0.0, "avg_logprob": -0.15785306783822867, "compression_ratio": 1.8461538461538463, "no_speech_prob": 0.00014880712842568755}, {"id": 1326, "seek": 340694, "start": 3407.18, "end": 3408.82, "text": " of other things that we think could drive returns.", "tokens": [50376, 295, 661, 721, 300, 321, 519, 727, 3332, 11247, 13, 50458], "temperature": 0.0, "avg_logprob": -0.15488465627034506, "compression_ratio": 1.76, "no_speech_prob": 0.003706475021317601}, {"id": 1327, "seek": 340694, "start": 3408.82, "end": 3412.38, "text": " So we try not to have like big country biases,", "tokens": [50458, 407, 321, 853, 406, 281, 362, 411, 955, 1941, 32152, 11, 50636], "temperature": 0.0, "avg_logprob": -0.15488465627034506, "compression_ratio": 1.76, "no_speech_prob": 0.003706475021317601}, {"id": 1328, "seek": 340694, "start": 3412.38, "end": 3415.06, "text": " big sector biases, factor biases.", "tokens": [50636, 955, 6977, 32152, 11, 5952, 32152, 13, 50770], "temperature": 0.0, "avg_logprob": -0.15488465627034506, "compression_ratio": 1.76, "no_speech_prob": 0.003706475021317601}, {"id": 1329, "seek": 340694, "start": 3415.06, "end": 3417.1, "text": " So factor are things like value and momentum,", "tokens": [50770, 407, 5952, 366, 721, 411, 2158, 293, 11244, 11, 50872], "temperature": 0.0, "avg_logprob": -0.15488465627034506, "compression_ratio": 1.76, "no_speech_prob": 0.003706475021317601}, {"id": 1330, "seek": 340694, "start": 3417.1, "end": 3419.86, "text": " these kind of like more abstract quantities", "tokens": [50872, 613, 733, 295, 411, 544, 12649, 22927, 51010], "temperature": 0.0, "avg_logprob": -0.15488465627034506, "compression_ratio": 1.76, "no_speech_prob": 0.003706475021317601}, {"id": 1331, "seek": 340694, "start": 3419.86, "end": 3421.02, "text": " that are supposed to tell you something", "tokens": [51010, 300, 366, 3442, 281, 980, 291, 746, 51068], "temperature": 0.0, "avg_logprob": -0.15488465627034506, "compression_ratio": 1.76, "no_speech_prob": 0.003706475021317601}, {"id": 1332, "seek": 340694, "start": 3421.02, "end": 3424.7000000000003, "text": " about classes of stocks.", "tokens": [51068, 466, 5359, 295, 12966, 13, 51252], "temperature": 0.0, "avg_logprob": -0.15488465627034506, "compression_ratio": 1.76, "no_speech_prob": 0.003706475021317601}, {"id": 1333, "seek": 340694, "start": 3424.7000000000003, "end": 3428.14, "text": " But we try to be uncorrelated to basically everything.", "tokens": [51252, 583, 321, 853, 281, 312, 6219, 284, 12004, 281, 1936, 1203, 13, 51424], "temperature": 0.0, "avg_logprob": -0.15488465627034506, "compression_ratio": 1.76, "no_speech_prob": 0.003706475021317601}, {"id": 1334, "seek": 340694, "start": 3428.14, "end": 3430.06, "text": " And they're just trying to get the sort of pure machine", "tokens": [51424, 400, 436, 434, 445, 1382, 281, 483, 264, 1333, 295, 6075, 3479, 51520], "temperature": 0.0, "avg_logprob": -0.15488465627034506, "compression_ratio": 1.76, "no_speech_prob": 0.003706475021317601}, {"id": 1335, "seek": 340694, "start": 3430.06, "end": 3433.94, "text": " learning non-linear signal that is driving stock returns", "tokens": [51520, 2539, 2107, 12, 28263, 6358, 300, 307, 4840, 4127, 11247, 51714], "temperature": 0.0, "avg_logprob": -0.15488465627034506, "compression_ratio": 1.76, "no_speech_prob": 0.003706475021317601}, {"id": 1336, "seek": 340694, "start": 3433.94, "end": 3436.2200000000003, "text": " or like stock specific alpha,", "tokens": [51714, 420, 411, 4127, 2685, 8961, 11, 51828], "temperature": 0.0, "avg_logprob": -0.15488465627034506, "compression_ratio": 1.76, "no_speech_prob": 0.003706475021317601}, {"id": 1337, "seek": 343622, "start": 3436.22, "end": 3439.8599999999997, "text": " we call it sort of like the amount of stock is going to,", "tokens": [50364, 321, 818, 309, 1333, 295, 411, 264, 2372, 295, 4127, 307, 516, 281, 11, 50546], "temperature": 0.0, "avg_logprob": -0.16662021919533057, "compression_ratio": 1.8259587020648969, "no_speech_prob": 0.0007653801003471017}, {"id": 1338, "seek": 343622, "start": 3439.8599999999997, "end": 3442.54, "text": " how all the stock is going to do sort of just by itself,", "tokens": [50546, 577, 439, 264, 4127, 307, 516, 281, 360, 1333, 295, 445, 538, 2564, 11, 50680], "temperature": 0.0, "avg_logprob": -0.16662021919533057, "compression_ratio": 1.8259587020648969, "no_speech_prob": 0.0007653801003471017}, {"id": 1339, "seek": 343622, "start": 3442.54, "end": 3443.98, "text": " not taking all these other things", "tokens": [50680, 406, 1940, 439, 613, 661, 721, 50752], "temperature": 0.0, "avg_logprob": -0.16662021919533057, "compression_ratio": 1.8259587020648969, "no_speech_prob": 0.0007653801003471017}, {"id": 1340, "seek": 343622, "start": 3443.98, "end": 3445.8599999999997, "text": " that are about it into account.", "tokens": [50752, 300, 366, 466, 309, 666, 2696, 13, 50846], "temperature": 0.0, "avg_logprob": -0.16662021919533057, "compression_ratio": 1.8259587020648969, "no_speech_prob": 0.0007653801003471017}, {"id": 1341, "seek": 343622, "start": 3445.8599999999997, "end": 3446.7, "text": " Yeah, that's really interesting.", "tokens": [50846, 865, 11, 300, 311, 534, 1880, 13, 50888], "temperature": 0.0, "avg_logprob": -0.16662021919533057, "compression_ratio": 1.8259587020648969, "no_speech_prob": 0.0007653801003471017}, {"id": 1342, "seek": 343622, "start": 3446.7, "end": 3448.8199999999997, "text": " And I guess like one of the problems on Kaggle", "tokens": [50888, 400, 286, 2041, 411, 472, 295, 264, 2740, 322, 48751, 22631, 50994], "temperature": 0.0, "avg_logprob": -0.16662021919533057, "compression_ratio": 1.8259587020648969, "no_speech_prob": 0.0007653801003471017}, {"id": 1343, "seek": 343622, "start": 3448.8199999999997, "end": 3451.66, "text": " is that most of the solutions are so overfit", "tokens": [50994, 307, 300, 881, 295, 264, 6547, 366, 370, 670, 6845, 51136], "temperature": 0.0, "avg_logprob": -0.16662021919533057, "compression_ratio": 1.8259587020648969, "no_speech_prob": 0.0007653801003471017}, {"id": 1344, "seek": 343622, "start": 3451.66, "end": 3455.2999999999997, "text": " to the training set that they never generalize", "tokens": [51136, 281, 264, 3097, 992, 300, 436, 1128, 2674, 1125, 51318], "temperature": 0.0, "avg_logprob": -0.16662021919533057, "compression_ratio": 1.8259587020648969, "no_speech_prob": 0.0007653801003471017}, {"id": 1345, "seek": 343622, "start": 3455.2999999999997, "end": 3456.4599999999996, "text": " to real world versions of the problem.", "tokens": [51318, 281, 957, 1002, 9606, 295, 264, 1154, 13, 51376], "temperature": 0.0, "avg_logprob": -0.16662021919533057, "compression_ratio": 1.8259587020648969, "no_speech_prob": 0.0007653801003471017}, {"id": 1346, "seek": 343622, "start": 3456.4599999999996, "end": 3458.22, "text": " But what you're doing actually is to kind of like", "tokens": [51376, 583, 437, 291, 434, 884, 767, 307, 281, 733, 295, 411, 51464], "temperature": 0.0, "avg_logprob": -0.16662021919533057, "compression_ratio": 1.8259587020648969, "no_speech_prob": 0.0007653801003471017}, {"id": 1347, "seek": 343622, "start": 3458.22, "end": 3460.9399999999996, "text": " remove away a lot of those opportunities for overfitting", "tokens": [51464, 4159, 1314, 257, 688, 295, 729, 4786, 337, 670, 69, 2414, 51600], "temperature": 0.0, "avg_logprob": -0.16662021919533057, "compression_ratio": 1.8259587020648969, "no_speech_prob": 0.0007653801003471017}, {"id": 1348, "seek": 343622, "start": 3460.9399999999996, "end": 3462.8599999999997, "text": " and also allowing the models to be used again", "tokens": [51600, 293, 611, 8293, 264, 5245, 281, 312, 1143, 797, 51696], "temperature": 0.0, "avg_logprob": -0.16662021919533057, "compression_ratio": 1.8259587020648969, "no_speech_prob": 0.0007653801003471017}, {"id": 1349, "seek": 343622, "start": 3462.8599999999997, "end": 3464.1, "text": " when the next thing comes around.", "tokens": [51696, 562, 264, 958, 551, 1487, 926, 13, 51758], "temperature": 0.0, "avg_logprob": -0.16662021919533057, "compression_ratio": 1.8259587020648969, "no_speech_prob": 0.0007653801003471017}, {"id": 1350, "seek": 343622, "start": 3464.1, "end": 3466.18, "text": " But just quickly on the aggregating stuff", "tokens": [51758, 583, 445, 2661, 322, 264, 16743, 990, 1507, 51862], "temperature": 0.0, "avg_logprob": -0.16662021919533057, "compression_ratio": 1.8259587020648969, "no_speech_prob": 0.0007653801003471017}, {"id": 1351, "seek": 346618, "start": 3466.2599999999998, "end": 3468.14, "text": " the reason I'm interested in that is on my PhD", "tokens": [50368, 264, 1778, 286, 478, 3102, 294, 300, 307, 322, 452, 14476, 50462], "temperature": 0.0, "avg_logprob": -0.143111536325502, "compression_ratio": 1.7830882352941178, "no_speech_prob": 0.0012034684186801314}, {"id": 1352, "seek": 346618, "start": 3468.14, "end": 3470.46, "text": " I did prediction with expert advice", "tokens": [50462, 286, 630, 17630, 365, 5844, 5192, 50578], "temperature": 0.0, "avg_logprob": -0.143111536325502, "compression_ratio": 1.7830882352941178, "no_speech_prob": 0.0012034684186801314}, {"id": 1353, "seek": 346618, "start": 3470.46, "end": 3472.62, "text": " and there's a whole load of theoretical approaches", "tokens": [50578, 293, 456, 311, 257, 1379, 3677, 295, 20864, 11587, 50686], "temperature": 0.0, "avg_logprob": -0.143111536325502, "compression_ratio": 1.7830882352941178, "no_speech_prob": 0.0012034684186801314}, {"id": 1354, "seek": 346618, "start": 3472.62, "end": 3474.74, "text": " to that where you can have an aggregating algorithm", "tokens": [50686, 281, 300, 689, 291, 393, 362, 364, 16743, 990, 9284, 50792], "temperature": 0.0, "avg_logprob": -0.143111536325502, "compression_ratio": 1.7830882352941178, "no_speech_prob": 0.0012034684186801314}, {"id": 1355, "seek": 346618, "start": 3474.74, "end": 3476.8599999999997, "text": " that produce, you know, that produces performance", "tokens": [50792, 300, 5258, 11, 291, 458, 11, 300, 14725, 3389, 50898], "temperature": 0.0, "avg_logprob": -0.143111536325502, "compression_ratio": 1.7830882352941178, "no_speech_prob": 0.0012034684186801314}, {"id": 1356, "seek": 346618, "start": 3476.8599999999997, "end": 3479.5, "text": " or a kind of like an error bound", "tokens": [50898, 420, 257, 733, 295, 411, 364, 6713, 5472, 51030], "temperature": 0.0, "avg_logprob": -0.143111536325502, "compression_ratio": 1.7830882352941178, "no_speech_prob": 0.0012034684186801314}, {"id": 1357, "seek": 346618, "start": 3479.5, "end": 3482.18, "text": " which is not much worse than the best path", "tokens": [51030, 597, 307, 406, 709, 5324, 813, 264, 1151, 3100, 51164], "temperature": 0.0, "avg_logprob": -0.143111536325502, "compression_ratio": 1.7830882352941178, "no_speech_prob": 0.0012034684186801314}, {"id": 1358, "seek": 346618, "start": 3482.18, "end": 3483.8199999999997, "text": " of switching experts.", "tokens": [51164, 295, 16493, 8572, 13, 51246], "temperature": 0.0, "avg_logprob": -0.143111536325502, "compression_ratio": 1.7830882352941178, "no_speech_prob": 0.0012034684186801314}, {"id": 1359, "seek": 346618, "start": 3483.8199999999997, "end": 3486.2599999999998, "text": " So if you took the optimal path of the best expert", "tokens": [51246, 407, 498, 291, 1890, 264, 16252, 3100, 295, 264, 1151, 5844, 51368], "temperature": 0.0, "avg_logprob": -0.143111536325502, "compression_ratio": 1.7830882352941178, "no_speech_prob": 0.0012034684186801314}, {"id": 1360, "seek": 346618, "start": 3486.2599999999998, "end": 3488.18, "text": " every single time step, you can have algorithms", "tokens": [51368, 633, 2167, 565, 1823, 11, 291, 393, 362, 14642, 51464], "temperature": 0.0, "avg_logprob": -0.143111536325502, "compression_ratio": 1.7830882352941178, "no_speech_prob": 0.0012034684186801314}, {"id": 1361, "seek": 346618, "start": 3488.18, "end": 3491.3399999999997, "text": " that have approvable bound not much worse than that.", "tokens": [51464, 300, 362, 2075, 17915, 5472, 406, 709, 5324, 813, 300, 13, 51622], "temperature": 0.0, "avg_logprob": -0.143111536325502, "compression_ratio": 1.7830882352941178, "no_speech_prob": 0.0012034684186801314}, {"id": 1362, "seek": 349134, "start": 3492.3, "end": 3497.3, "text": " Yeah, we, so we've done a lot to try to experiment", "tokens": [50412, 865, 11, 321, 11, 370, 321, 600, 1096, 257, 688, 281, 853, 281, 5120, 50662], "temperature": 0.0, "avg_logprob": -0.24493704691971882, "compression_ratio": 1.5761904761904761, "no_speech_prob": 0.007574819959700108}, {"id": 1363, "seek": 349134, "start": 3497.46, "end": 3499.58, "text": " with trying to improve upon stake waiting.", "tokens": [50670, 365, 1382, 281, 3470, 3564, 10407, 3806, 13, 50776], "temperature": 0.0, "avg_logprob": -0.24493704691971882, "compression_ratio": 1.5761904761904761, "no_speech_prob": 0.007574819959700108}, {"id": 1364, "seek": 349134, "start": 3500.86, "end": 3504.06, "text": " And it's always been really hard to do it in a robust way.", "tokens": [50840, 400, 309, 311, 1009, 668, 534, 1152, 281, 360, 309, 294, 257, 13956, 636, 13, 51000], "temperature": 0.0, "avg_logprob": -0.24493704691971882, "compression_ratio": 1.5761904761904761, "no_speech_prob": 0.007574819959700108}, {"id": 1365, "seek": 349134, "start": 3505.26, "end": 3508.78, "text": " It's, I mean, for one, stake waiting is,", "tokens": [51060, 467, 311, 11, 286, 914, 11, 337, 472, 11, 10407, 3806, 307, 11, 51236], "temperature": 0.0, "avg_logprob": -0.24493704691971882, "compression_ratio": 1.5761904761904761, "no_speech_prob": 0.007574819959700108}, {"id": 1366, "seek": 349134, "start": 3508.78, "end": 3513.1000000000004, "text": " it's sort of nice in that it's easy for people to understand.", "tokens": [51236, 309, 311, 1333, 295, 1481, 294, 300, 309, 311, 1858, 337, 561, 281, 1223, 13, 51452], "temperature": 0.0, "avg_logprob": -0.24493704691971882, "compression_ratio": 1.5761904761904761, "no_speech_prob": 0.007574819959700108}, {"id": 1367, "seek": 349134, "start": 3513.1000000000004, "end": 3516.02, "text": " People are, it's very clean in how it works.", "tokens": [51452, 3432, 366, 11, 309, 311, 588, 2541, 294, 577, 309, 1985, 13, 51598], "temperature": 0.0, "avg_logprob": -0.24493704691971882, "compression_ratio": 1.5761904761904761, "no_speech_prob": 0.007574819959700108}, {"id": 1368, "seek": 349134, "start": 3516.02, "end": 3517.78, "text": " It sort of fits with the ethos", "tokens": [51598, 467, 1333, 295, 9001, 365, 264, 6468, 329, 51686], "temperature": 0.0, "avg_logprob": -0.24493704691971882, "compression_ratio": 1.5761904761904761, "no_speech_prob": 0.007574819959700108}, {"id": 1369, "seek": 351778, "start": 3518.02, "end": 3522.3, "text": " and the, like, and the idea of the company", "tokens": [50376, 293, 264, 11, 411, 11, 293, 264, 1558, 295, 264, 2237, 50590], "temperature": 0.0, "avg_logprob": -0.1897467811508934, "compression_ratio": 1.654708520179372, "no_speech_prob": 0.003375693690031767}, {"id": 1370, "seek": 351778, "start": 3522.3, "end": 3525.6200000000003, "text": " of how it's distributed and decentralized", "tokens": [50590, 295, 577, 309, 311, 12631, 293, 32870, 50756], "temperature": 0.0, "avg_logprob": -0.1897467811508934, "compression_ratio": 1.654708520179372, "no_speech_prob": 0.003375693690031767}, {"id": 1371, "seek": 351778, "start": 3525.6200000000003, "end": 3529.38, "text": " and you express your confidence by your stake.", "tokens": [50756, 293, 291, 5109, 428, 6687, 538, 428, 10407, 13, 50944], "temperature": 0.0, "avg_logprob": -0.1897467811508934, "compression_ratio": 1.654708520179372, "no_speech_prob": 0.003375693690031767}, {"id": 1372, "seek": 351778, "start": 3531.5400000000004, "end": 3533.6600000000003, "text": " But it does sort of seem like there should be a better way", "tokens": [51052, 583, 309, 775, 1333, 295, 1643, 411, 456, 820, 312, 257, 1101, 636, 51158], "temperature": 0.0, "avg_logprob": -0.1897467811508934, "compression_ratio": 1.654708520179372, "no_speech_prob": 0.003375693690031767}, {"id": 1373, "seek": 351778, "start": 3533.6600000000003, "end": 3535.34, "text": " to aggregate models.", "tokens": [51158, 281, 26118, 5245, 13, 51242], "temperature": 0.0, "avg_logprob": -0.1897467811508934, "compression_ratio": 1.654708520179372, "no_speech_prob": 0.003375693690031767}, {"id": 1374, "seek": 351778, "start": 3535.34, "end": 3539.34, "text": " But pretty much every time we try to find something better,", "tokens": [51242, 583, 1238, 709, 633, 565, 321, 853, 281, 915, 746, 1101, 11, 51442], "temperature": 0.0, "avg_logprob": -0.1897467811508934, "compression_ratio": 1.654708520179372, "no_speech_prob": 0.003375693690031767}, {"id": 1375, "seek": 351778, "start": 3539.34, "end": 3542.26, "text": " it's, it might be a little bit better", "tokens": [51442, 309, 311, 11, 309, 1062, 312, 257, 707, 857, 1101, 51588], "temperature": 0.0, "avg_logprob": -0.1897467811508934, "compression_ratio": 1.654708520179372, "no_speech_prob": 0.003375693690031767}, {"id": 1376, "seek": 351778, "start": 3542.26, "end": 3543.5400000000004, "text": " but it's like less robust.", "tokens": [51588, 457, 309, 311, 411, 1570, 13956, 13, 51652], "temperature": 0.0, "avg_logprob": -0.1897467811508934, "compression_ratio": 1.654708520179372, "no_speech_prob": 0.003375693690031767}, {"id": 1377, "seek": 351778, "start": 3543.5400000000004, "end": 3546.1000000000004, "text": " It tends to just be less robust.", "tokens": [51652, 467, 12258, 281, 445, 312, 1570, 13956, 13, 51780], "temperature": 0.0, "avg_logprob": -0.1897467811508934, "compression_ratio": 1.654708520179372, "no_speech_prob": 0.003375693690031767}, {"id": 1378, "seek": 354610, "start": 3546.1, "end": 3549.66, "text": " And it's, because you are essentially just sort of fitting", "tokens": [50364, 400, 309, 311, 11, 570, 291, 366, 4476, 445, 1333, 295, 15669, 50542], "temperature": 0.0, "avg_logprob": -0.1803423808171199, "compression_ratio": 1.8494208494208495, "no_speech_prob": 0.0007095407927408814}, {"id": 1379, "seek": 354610, "start": 3549.66, "end": 3552.7799999999997, "text": " to the past and to try to find way to the models", "tokens": [50542, 281, 264, 1791, 293, 281, 853, 281, 915, 636, 281, 264, 5245, 50698], "temperature": 0.0, "avg_logprob": -0.1803423808171199, "compression_ratio": 1.8494208494208495, "no_speech_prob": 0.0007095407927408814}, {"id": 1380, "seek": 354610, "start": 3552.7799999999997, "end": 3555.58, "text": " or something, it tends to just like overfit", "tokens": [50698, 420, 746, 11, 309, 12258, 281, 445, 411, 670, 6845, 50838], "temperature": 0.0, "avg_logprob": -0.1803423808171199, "compression_ratio": 1.8494208494208495, "no_speech_prob": 0.0007095407927408814}, {"id": 1381, "seek": 354610, "start": 3555.58, "end": 3557.62, "text": " and this sort of stake waiting thing,", "tokens": [50838, 293, 341, 1333, 295, 10407, 3806, 551, 11, 50940], "temperature": 0.0, "avg_logprob": -0.1803423808171199, "compression_ratio": 1.8494208494208495, "no_speech_prob": 0.0007095407927408814}, {"id": 1382, "seek": 354610, "start": 3557.62, "end": 3558.58, "text": " you can't really overfit.", "tokens": [50940, 291, 393, 380, 534, 670, 6845, 13, 50988], "temperature": 0.0, "avg_logprob": -0.1803423808171199, "compression_ratio": 1.8494208494208495, "no_speech_prob": 0.0007095407927408814}, {"id": 1383, "seek": 354610, "start": 3558.58, "end": 3562.2999999999997, "text": " It's just sort of a property that just sort of evolves", "tokens": [50988, 467, 311, 445, 1333, 295, 257, 4707, 300, 445, 1333, 295, 43737, 51174], "temperature": 0.0, "avg_logprob": -0.1803423808171199, "compression_ratio": 1.8494208494208495, "no_speech_prob": 0.0007095407927408814}, {"id": 1384, "seek": 354610, "start": 3562.2999999999997, "end": 3563.62, "text": " as the tournament goes on", "tokens": [51174, 382, 264, 13713, 1709, 322, 51240], "temperature": 0.0, "avg_logprob": -0.1803423808171199, "compression_ratio": 1.8494208494208495, "no_speech_prob": 0.0007095407927408814}, {"id": 1385, "seek": 354610, "start": 3565.06, "end": 3567.86, "text": " without ever considering like the past performance", "tokens": [51312, 1553, 1562, 8079, 411, 264, 1791, 3389, 51452], "temperature": 0.0, "avg_logprob": -0.1803423808171199, "compression_ratio": 1.8494208494208495, "no_speech_prob": 0.0007095407927408814}, {"id": 1386, "seek": 354610, "start": 3567.86, "end": 3569.1, "text": " and all of these things.", "tokens": [51452, 293, 439, 295, 613, 721, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1803423808171199, "compression_ratio": 1.8494208494208495, "no_speech_prob": 0.0007095407927408814}, {"id": 1387, "seek": 354610, "start": 3569.98, "end": 3573.14, "text": " So yeah, it's, it's been kind of interesting to,", "tokens": [51558, 407, 1338, 11, 309, 311, 11, 309, 311, 668, 733, 295, 1880, 281, 11, 51716], "temperature": 0.0, "avg_logprob": -0.1803423808171199, "compression_ratio": 1.8494208494208495, "no_speech_prob": 0.0007095407927408814}, {"id": 1388, "seek": 354610, "start": 3573.14, "end": 3576.02, "text": " so it's one of these things we sort of revisit every year", "tokens": [51716, 370, 309, 311, 472, 295, 613, 721, 321, 1333, 295, 32676, 633, 1064, 51860], "temperature": 0.0, "avg_logprob": -0.1803423808171199, "compression_ratio": 1.8494208494208495, "no_speech_prob": 0.0007095407927408814}, {"id": 1389, "seek": 357602, "start": 3576.02, "end": 3576.86, "text": " at some point of like,", "tokens": [50364, 412, 512, 935, 295, 411, 11, 50406], "temperature": 0.0, "avg_logprob": -0.19013995873300651, "compression_ratio": 1.7423728813559323, "no_speech_prob": 0.0012440327554941177}, {"id": 1390, "seek": 357602, "start": 3576.86, "end": 3578.54, "text": " let's try to build a better meta model", "tokens": [50406, 718, 311, 853, 281, 1322, 257, 1101, 19616, 2316, 50490], "temperature": 0.0, "avg_logprob": -0.19013995873300651, "compression_ratio": 1.7423728813559323, "no_speech_prob": 0.0012440327554941177}, {"id": 1391, "seek": 357602, "start": 3578.54, "end": 3582.5, "text": " but we usually just come back to stake waiting in the end.", "tokens": [50490, 457, 321, 2673, 445, 808, 646, 281, 10407, 3806, 294, 264, 917, 13, 50688], "temperature": 0.0, "avg_logprob": -0.19013995873300651, "compression_ratio": 1.7423728813559323, "no_speech_prob": 0.0012440327554941177}, {"id": 1392, "seek": 357602, "start": 3582.5, "end": 3583.54, "text": " Yeah, well, in a way, I mean,", "tokens": [50688, 865, 11, 731, 11, 294, 257, 636, 11, 286, 914, 11, 50740], "temperature": 0.0, "avg_logprob": -0.19013995873300651, "compression_ratio": 1.7423728813559323, "no_speech_prob": 0.0012440327554941177}, {"id": 1393, "seek": 357602, "start": 3583.54, "end": 3584.74, "text": " we're prediction with expert advice,", "tokens": [50740, 321, 434, 17630, 365, 5844, 5192, 11, 50800], "temperature": 0.0, "avg_logprob": -0.19013995873300651, "compression_ratio": 1.7423728813559323, "no_speech_prob": 0.0012440327554941177}, {"id": 1394, "seek": 357602, "start": 3584.74, "end": 3585.94, "text": " you have a learning rate", "tokens": [50800, 291, 362, 257, 2539, 3314, 50860], "temperature": 0.0, "avg_logprob": -0.19013995873300651, "compression_ratio": 1.7423728813559323, "no_speech_prob": 0.0012440327554941177}, {"id": 1395, "seek": 357602, "start": 3585.94, "end": 3587.62, "text": " and I guess you don't even have that problem", "tokens": [50860, 293, 286, 2041, 291, 500, 380, 754, 362, 300, 1154, 50944], "temperature": 0.0, "avg_logprob": -0.19013995873300651, "compression_ratio": 1.7423728813559323, "no_speech_prob": 0.0012440327554941177}, {"id": 1396, "seek": 357602, "start": 3587.62, "end": 3590.62, "text": " because you're just using the stakes as the-", "tokens": [50944, 570, 291, 434, 445, 1228, 264, 28429, 382, 264, 12, 51094], "temperature": 0.0, "avg_logprob": -0.19013995873300651, "compression_ratio": 1.7423728813559323, "no_speech_prob": 0.0012440327554941177}, {"id": 1397, "seek": 357602, "start": 3590.62, "end": 3594.54, "text": " Yeah, the, but yeah, the, I mean, our learning rate.", "tokens": [51094, 865, 11, 264, 11, 457, 1338, 11, 264, 11, 286, 914, 11, 527, 2539, 3314, 13, 51290], "temperature": 0.0, "avg_logprob": -0.19013995873300651, "compression_ratio": 1.7423728813559323, "no_speech_prob": 0.0012440327554941177}, {"id": 1398, "seek": 357602, "start": 3594.54, "end": 3596.66, "text": " So I mean, our payout system is the way", "tokens": [51290, 407, 286, 914, 11, 527, 1689, 346, 1185, 307, 264, 636, 51396], "temperature": 0.0, "avg_logprob": -0.19013995873300651, "compression_ratio": 1.7423728813559323, "no_speech_prob": 0.0012440327554941177}, {"id": 1399, "seek": 357602, "start": 3596.66, "end": 3598.74, "text": " we adjust the weights over time.", "tokens": [51396, 321, 4369, 264, 17443, 670, 565, 13, 51500], "temperature": 0.0, "avg_logprob": -0.19013995873300651, "compression_ratio": 1.7423728813559323, "no_speech_prob": 0.0012440327554941177}, {"id": 1400, "seek": 357602, "start": 3598.74, "end": 3602.42, "text": " And so we have done like some simulations to show", "tokens": [51500, 400, 370, 321, 362, 1096, 411, 512, 35138, 281, 855, 51684], "temperature": 0.0, "avg_logprob": -0.19013995873300651, "compression_ratio": 1.7423728813559323, "no_speech_prob": 0.0012440327554941177}, {"id": 1401, "seek": 357602, "start": 3602.42, "end": 3604.5, "text": " that like if, how we reward people,", "tokens": [51684, 300, 411, 498, 11, 577, 321, 7782, 561, 11, 51788], "temperature": 0.0, "avg_logprob": -0.19013995873300651, "compression_ratio": 1.7423728813559323, "no_speech_prob": 0.0012440327554941177}, {"id": 1402, "seek": 360450, "start": 3604.5, "end": 3606.06, "text": " how that affects their weights over time", "tokens": [50364, 577, 300, 11807, 641, 17443, 670, 565, 50442], "temperature": 0.0, "avg_logprob": -0.13761382134968803, "compression_ratio": 1.87, "no_speech_prob": 0.002322532469406724}, {"id": 1403, "seek": 360450, "start": 3606.06, "end": 3607.94, "text": " and how that affects meta model performance.", "tokens": [50442, 293, 577, 300, 11807, 19616, 2316, 3389, 13, 50536], "temperature": 0.0, "avg_logprob": -0.13761382134968803, "compression_ratio": 1.87, "no_speech_prob": 0.002322532469406724}, {"id": 1404, "seek": 360450, "start": 3607.94, "end": 3609.78, "text": " So you wouldn't want to have a payout system", "tokens": [50536, 407, 291, 2759, 380, 528, 281, 362, 257, 1689, 346, 1185, 50628], "temperature": 0.0, "avg_logprob": -0.13761382134968803, "compression_ratio": 1.87, "no_speech_prob": 0.002322532469406724}, {"id": 1405, "seek": 360450, "start": 3609.78, "end": 3612.7, "text": " that would make the meta model worse over time.", "tokens": [50628, 300, 576, 652, 264, 19616, 2316, 5324, 670, 565, 13, 50774], "temperature": 0.0, "avg_logprob": -0.13761382134968803, "compression_ratio": 1.87, "no_speech_prob": 0.002322532469406724}, {"id": 1406, "seek": 360450, "start": 3612.7, "end": 3615.34, "text": " And so yeah, like this, this true contribution idea", "tokens": [50774, 400, 370, 1338, 11, 411, 341, 11, 341, 2074, 13150, 1558, 50906], "temperature": 0.0, "avg_logprob": -0.13761382134968803, "compression_ratio": 1.87, "no_speech_prob": 0.002322532469406724}, {"id": 1407, "seek": 360450, "start": 3615.34, "end": 3617.38, "text": " that's gradient of the stakes,", "tokens": [50906, 300, 311, 16235, 295, 264, 28429, 11, 51008], "temperature": 0.0, "avg_logprob": -0.13761382134968803, "compression_ratio": 1.87, "no_speech_prob": 0.002322532469406724}, {"id": 1408, "seek": 360450, "start": 3617.38, "end": 3619.1, "text": " we did simulations to show", "tokens": [51008, 321, 630, 35138, 281, 855, 51094], "temperature": 0.0, "avg_logprob": -0.13761382134968803, "compression_ratio": 1.87, "no_speech_prob": 0.002322532469406724}, {"id": 1409, "seek": 360450, "start": 3619.1, "end": 3621.74, "text": " it does actually improve the meta model over time", "tokens": [51094, 309, 775, 767, 3470, 264, 19616, 2316, 670, 565, 51226], "temperature": 0.0, "avg_logprob": -0.13761382134968803, "compression_ratio": 1.87, "no_speech_prob": 0.002322532469406724}, {"id": 1410, "seek": 360450, "start": 3621.74, "end": 3623.1, "text": " to pay out in this way.", "tokens": [51226, 281, 1689, 484, 294, 341, 636, 13, 51294], "temperature": 0.0, "avg_logprob": -0.13761382134968803, "compression_ratio": 1.87, "no_speech_prob": 0.002322532469406724}, {"id": 1411, "seek": 360450, "start": 3624.02, "end": 3627.5, "text": " It's nothing, I mean, people do things", "tokens": [51340, 467, 311, 1825, 11, 286, 914, 11, 561, 360, 721, 51514], "temperature": 0.0, "avg_logprob": -0.13761382134968803, "compression_ratio": 1.87, "no_speech_prob": 0.002322532469406724}, {"id": 1412, "seek": 360450, "start": 3627.5, "end": 3629.38, "text": " like take their stakes out, withdraw money.", "tokens": [51514, 411, 747, 641, 28429, 484, 11, 14999, 1460, 13, 51608], "temperature": 0.0, "avg_logprob": -0.13761382134968803, "compression_ratio": 1.87, "no_speech_prob": 0.002322532469406724}, {"id": 1413, "seek": 360450, "start": 3629.38, "end": 3630.7, "text": " And so it's not a perfect system.", "tokens": [51608, 400, 370, 309, 311, 406, 257, 2176, 1185, 13, 51674], "temperature": 0.0, "avg_logprob": -0.13761382134968803, "compression_ratio": 1.87, "no_speech_prob": 0.002322532469406724}, {"id": 1414, "seek": 360450, "start": 3630.7, "end": 3631.94, "text": " People entering the tournament,", "tokens": [51674, 3432, 11104, 264, 13713, 11, 51736], "temperature": 0.0, "avg_logprob": -0.13761382134968803, "compression_ratio": 1.87, "no_speech_prob": 0.002322532469406724}, {"id": 1415, "seek": 360450, "start": 3631.94, "end": 3633.58, "text": " people, some people entering with a lot of money,", "tokens": [51736, 561, 11, 512, 561, 11104, 365, 257, 688, 295, 1460, 11, 51818], "temperature": 0.0, "avg_logprob": -0.13761382134968803, "compression_ratio": 1.87, "no_speech_prob": 0.002322532469406724}, {"id": 1416, "seek": 363358, "start": 3633.58, "end": 3635.62, "text": " some people entered with not that much money.", "tokens": [50364, 512, 561, 9065, 365, 406, 300, 709, 1460, 13, 50466], "temperature": 0.0, "avg_logprob": -0.1667824536561966, "compression_ratio": 1.656140350877193, "no_speech_prob": 0.000391786772524938}, {"id": 1417, "seek": 363358, "start": 3636.7, "end": 3640.2999999999997, "text": " And so yeah, it takes time for these things,", "tokens": [50520, 400, 370, 1338, 11, 309, 2516, 565, 337, 613, 721, 11, 50700], "temperature": 0.0, "avg_logprob": -0.1667824536561966, "compression_ratio": 1.656140350877193, "no_speech_prob": 0.000391786772524938}, {"id": 1418, "seek": 363358, "start": 3640.2999999999997, "end": 3642.74, "text": " all the kind of shake out in real life.", "tokens": [50700, 439, 264, 733, 295, 10283, 484, 294, 957, 993, 13, 50822], "temperature": 0.0, "avg_logprob": -0.1667824536561966, "compression_ratio": 1.656140350877193, "no_speech_prob": 0.000391786772524938}, {"id": 1419, "seek": 363358, "start": 3642.74, "end": 3646.8199999999997, "text": " But the overall idea is that we are essentially adjusting", "tokens": [50822, 583, 264, 4787, 1558, 307, 300, 321, 366, 4476, 23559, 51026], "temperature": 0.0, "avg_logprob": -0.1667824536561966, "compression_ratio": 1.656140350877193, "no_speech_prob": 0.000391786772524938}, {"id": 1420, "seek": 363358, "start": 3646.8199999999997, "end": 3648.34, "text": " the weights through our payouts", "tokens": [51026, 264, 17443, 807, 527, 1689, 7711, 51102], "temperature": 0.0, "avg_logprob": -0.1667824536561966, "compression_ratio": 1.656140350877193, "no_speech_prob": 0.000391786772524938}, {"id": 1421, "seek": 363358, "start": 3648.34, "end": 3652.38, "text": " towards this sort of more optimal meta model over time.", "tokens": [51102, 3030, 341, 1333, 295, 544, 16252, 19616, 2316, 670, 565, 13, 51304], "temperature": 0.0, "avg_logprob": -0.1667824536561966, "compression_ratio": 1.656140350877193, "no_speech_prob": 0.000391786772524938}, {"id": 1422, "seek": 363358, "start": 3652.38, "end": 3653.22, "text": " Interesting.", "tokens": [51304, 14711, 13, 51346], "temperature": 0.0, "avg_logprob": -0.1667824536561966, "compression_ratio": 1.656140350877193, "no_speech_prob": 0.000391786772524938}, {"id": 1423, "seek": 363358, "start": 3653.22, "end": 3656.62, "text": " So I'm actually very, very interested to give it a go.", "tokens": [51346, 407, 286, 478, 767, 588, 11, 588, 3102, 281, 976, 309, 257, 352, 13, 51516], "temperature": 0.0, "avg_logprob": -0.1667824536561966, "compression_ratio": 1.656140350877193, "no_speech_prob": 0.000391786772524938}, {"id": 1424, "seek": 363358, "start": 3656.62, "end": 3658.42, "text": " And I guess like, first of all,", "tokens": [51516, 400, 286, 2041, 411, 11, 700, 295, 439, 11, 51606], "temperature": 0.0, "avg_logprob": -0.1667824536561966, "compression_ratio": 1.656140350877193, "no_speech_prob": 0.000391786772524938}, {"id": 1425, "seek": 363358, "start": 3658.42, "end": 3660.54, "text": " you could sketch out what the process looks like.", "tokens": [51606, 291, 727, 12325, 484, 437, 264, 1399, 1542, 411, 13, 51712], "temperature": 0.0, "avg_logprob": -0.1667824536561966, "compression_ratio": 1.656140350877193, "no_speech_prob": 0.000391786772524938}, {"id": 1426, "seek": 363358, "start": 3660.54, "end": 3662.5, "text": " I mean, let's say I had a few hundred dollars", "tokens": [51712, 286, 914, 11, 718, 311, 584, 286, 632, 257, 1326, 3262, 3808, 51810], "temperature": 0.0, "avg_logprob": -0.1667824536561966, "compression_ratio": 1.656140350877193, "no_speech_prob": 0.000391786772524938}, {"id": 1427, "seek": 366250, "start": 3662.5, "end": 3663.46, "text": " and I wanted to build a model.", "tokens": [50364, 293, 286, 1415, 281, 1322, 257, 2316, 13, 50412], "temperature": 0.0, "avg_logprob": -0.14849750140241083, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0011502655688673258}, {"id": 1428, "seek": 366250, "start": 3663.46, "end": 3666.7, "text": " And also it's got to be a good model.", "tokens": [50412, 400, 611, 309, 311, 658, 281, 312, 257, 665, 2316, 13, 50574], "temperature": 0.0, "avg_logprob": -0.14849750140241083, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0011502655688673258}, {"id": 1429, "seek": 366250, "start": 3666.7, "end": 3667.54, "text": " Let's face it.", "tokens": [50574, 961, 311, 1851, 309, 13, 50616], "temperature": 0.0, "avg_logprob": -0.14849750140241083, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0011502655688673258}, {"id": 1430, "seek": 366250, "start": 3667.54, "end": 3668.7, "text": " So if I just logged on there", "tokens": [50616, 407, 498, 286, 445, 27231, 322, 456, 50674], "temperature": 0.0, "avg_logprob": -0.14849750140241083, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0011502655688673258}, {"id": 1431, "seek": 366250, "start": 3668.7, "end": 3673.7, "text": " and I built a gradient booster tree model, would that work?", "tokens": [50674, 293, 286, 3094, 257, 16235, 29275, 4230, 2316, 11, 576, 300, 589, 30, 50924], "temperature": 0.0, "avg_logprob": -0.14849750140241083, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0011502655688673258}, {"id": 1432, "seek": 366250, "start": 3673.74, "end": 3674.82, "text": " It would actually.", "tokens": [50926, 467, 576, 767, 13, 50980], "temperature": 0.0, "avg_logprob": -0.14849750140241083, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0011502655688673258}, {"id": 1433, "seek": 366250, "start": 3674.82, "end": 3677.78, "text": " So I mean, it's tabular data", "tokens": [50980, 407, 286, 914, 11, 309, 311, 4421, 1040, 1412, 51128], "temperature": 0.0, "avg_logprob": -0.14849750140241083, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0011502655688673258}, {"id": 1434, "seek": 366250, "start": 3677.78, "end": 3679.38, "text": " and tabular data is very minimal", "tokens": [51128, 293, 4421, 1040, 1412, 307, 588, 13206, 51208], "temperature": 0.0, "avg_logprob": -0.14849750140241083, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0011502655688673258}, {"id": 1435, "seek": 366250, "start": 3679.38, "end": 3681.34, "text": " to gradient boosted trees.", "tokens": [51208, 281, 16235, 9194, 292, 5852, 13, 51306], "temperature": 0.0, "avg_logprob": -0.14849750140241083, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0011502655688673258}, {"id": 1436, "seek": 366250, "start": 3681.34, "end": 3683.9, "text": " We have a lot of example models that we have put up", "tokens": [51306, 492, 362, 257, 688, 295, 1365, 5245, 300, 321, 362, 829, 493, 51434], "temperature": 0.0, "avg_logprob": -0.14849750140241083, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0011502655688673258}, {"id": 1437, "seek": 366250, "start": 3683.9, "end": 3686.7, "text": " and they're doing quite well.", "tokens": [51434, 293, 436, 434, 884, 1596, 731, 13, 51574], "temperature": 0.0, "avg_logprob": -0.14849750140241083, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0011502655688673258}, {"id": 1438, "seek": 366250, "start": 3686.7, "end": 3689.62, "text": " So basically all you have to do", "tokens": [51574, 407, 1936, 439, 291, 362, 281, 360, 51720], "temperature": 0.0, "avg_logprob": -0.14849750140241083, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0011502655688673258}, {"id": 1439, "seek": 366250, "start": 3689.62, "end": 3691.46, "text": " is you can go to the website", "tokens": [51720, 307, 291, 393, 352, 281, 264, 3144, 51812], "temperature": 0.0, "avg_logprob": -0.14849750140241083, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0011502655688673258}, {"id": 1440, "seek": 369146, "start": 3691.5, "end": 3693.58, "text": " and just download a big zip file", "tokens": [50366, 293, 445, 5484, 257, 955, 20730, 3991, 50470], "temperature": 0.0, "avg_logprob": -0.1641815707214877, "compression_ratio": 1.6367041198501873, "no_speech_prob": 0.0005441208486445248}, {"id": 1441, "seek": 369146, "start": 3693.58, "end": 3697.14, "text": " that includes all the data in parquet.", "tokens": [50470, 300, 5974, 439, 264, 1412, 294, 971, 19343, 13, 50648], "temperature": 0.0, "avg_logprob": -0.1641815707214877, "compression_ratio": 1.6367041198501873, "no_speech_prob": 0.0005441208486445248}, {"id": 1442, "seek": 369146, "start": 3697.14, "end": 3700.7400000000002, "text": " And then you can just open it up in Python", "tokens": [50648, 400, 550, 291, 393, 445, 1269, 309, 493, 294, 15329, 50828], "temperature": 0.0, "avg_logprob": -0.1641815707214877, "compression_ratio": 1.6367041198501873, "no_speech_prob": 0.0005441208486445248}, {"id": 1443, "seek": 369146, "start": 3700.7400000000002, "end": 3702.06, "text": " and fit a gradient boosted tree.", "tokens": [50828, 293, 3318, 257, 16235, 9194, 292, 4230, 13, 50894], "temperature": 0.0, "avg_logprob": -0.1641815707214877, "compression_ratio": 1.6367041198501873, "no_speech_prob": 0.0005441208486445248}, {"id": 1444, "seek": 369146, "start": 3702.06, "end": 3703.1, "text": " When we have example scripts", "tokens": [50894, 1133, 321, 362, 1365, 23294, 50946], "temperature": 0.0, "avg_logprob": -0.1641815707214877, "compression_ratio": 1.6367041198501873, "no_speech_prob": 0.0005441208486445248}, {"id": 1445, "seek": 369146, "start": 3703.1, "end": 3706.3, "text": " sort of showing this along with some more interesting types", "tokens": [50946, 1333, 295, 4099, 341, 2051, 365, 512, 544, 1880, 3467, 51106], "temperature": 0.0, "avg_logprob": -0.1641815707214877, "compression_ratio": 1.6367041198501873, "no_speech_prob": 0.0005441208486445248}, {"id": 1446, "seek": 369146, "start": 3706.3, "end": 3709.3, "text": " of pre-processing and other sort of ideas", "tokens": [51106, 295, 659, 12, 41075, 278, 293, 661, 1333, 295, 3487, 51256], "temperature": 0.0, "avg_logprob": -0.1641815707214877, "compression_ratio": 1.6367041198501873, "no_speech_prob": 0.0005441208486445248}, {"id": 1447, "seek": 369146, "start": 3709.3, "end": 3710.7, "text": " like feature neutralization.", "tokens": [51256, 411, 4111, 10598, 2144, 13, 51326], "temperature": 0.0, "avg_logprob": -0.1641815707214877, "compression_ratio": 1.6367041198501873, "no_speech_prob": 0.0005441208486445248}, {"id": 1448, "seek": 369146, "start": 3712.34, "end": 3714.1, "text": " So I can talk about it in a second.", "tokens": [51408, 407, 286, 393, 751, 466, 309, 294, 257, 1150, 13, 51496], "temperature": 0.0, "avg_logprob": -0.1641815707214877, "compression_ratio": 1.6367041198501873, "no_speech_prob": 0.0005441208486445248}, {"id": 1449, "seek": 369146, "start": 3714.1, "end": 3717.2200000000003, "text": " But yeah, a lot of our sort of standard internal models", "tokens": [51496, 583, 1338, 11, 257, 688, 295, 527, 1333, 295, 3832, 6920, 5245, 51652], "temperature": 0.0, "avg_logprob": -0.1641815707214877, "compression_ratio": 1.6367041198501873, "no_speech_prob": 0.0005441208486445248}, {"id": 1450, "seek": 369146, "start": 3717.2200000000003, "end": 3719.66, "text": " use basically gradient boosted trees.", "tokens": [51652, 764, 1936, 16235, 9194, 292, 5852, 13, 51774], "temperature": 0.0, "avg_logprob": -0.1641815707214877, "compression_ratio": 1.6367041198501873, "no_speech_prob": 0.0005441208486445248}, {"id": 1451, "seek": 371966, "start": 3719.66, "end": 3724.14, "text": " And we are, I mean, we have basically example models running", "tokens": [50364, 400, 321, 366, 11, 286, 914, 11, 321, 362, 1936, 1365, 5245, 2614, 50588], "temperature": 0.0, "avg_logprob": -0.19689954909603152, "compression_ratio": 1.7078651685393258, "no_speech_prob": 0.0006876683328300714}, {"id": 1452, "seek": 371966, "start": 3724.14, "end": 3727.1, "text": " that and they all have positive correlation with", "tokens": [50588, 300, 293, 436, 439, 362, 3353, 20009, 365, 50736], "temperature": 0.0, "avg_logprob": -0.19689954909603152, "compression_ratio": 1.7078651685393258, "no_speech_prob": 0.0006876683328300714}, {"id": 1453, "seek": 371966, "start": 3727.1, "end": 3729.22, "text": " and true and still true contribution.", "tokens": [50736, 293, 2074, 293, 920, 2074, 13150, 13, 50842], "temperature": 0.0, "avg_logprob": -0.19689954909603152, "compression_ratio": 1.7078651685393258, "no_speech_prob": 0.0006876683328300714}, {"id": 1454, "seek": 371966, "start": 3729.22, "end": 3731.14, "text": " So they're actually working out of sample", "tokens": [50842, 407, 436, 434, 767, 1364, 484, 295, 6889, 50938], "temperature": 0.0, "avg_logprob": -0.19689954909603152, "compression_ratio": 1.7078651685393258, "no_speech_prob": 0.0006876683328300714}, {"id": 1455, "seek": 371966, "start": 3731.14, "end": 3733.02, "text": " and performing quite well.", "tokens": [50938, 293, 10205, 1596, 731, 13, 51032], "temperature": 0.0, "avg_logprob": -0.19689954909603152, "compression_ratio": 1.7078651685393258, "no_speech_prob": 0.0006876683328300714}, {"id": 1456, "seek": 371966, "start": 3733.02, "end": 3735.54, "text": " That hasn't all been sort of eaten up", "tokens": [51032, 663, 6132, 380, 439, 668, 1333, 295, 12158, 493, 51158], "temperature": 0.0, "avg_logprob": -0.19689954909603152, "compression_ratio": 1.7078651685393258, "no_speech_prob": 0.0006876683328300714}, {"id": 1457, "seek": 371966, "start": 3735.54, "end": 3737.58, "text": " by people using similar enough models.", "tokens": [51158, 538, 561, 1228, 2531, 1547, 5245, 13, 51260], "temperature": 0.0, "avg_logprob": -0.19689954909603152, "compression_ratio": 1.7078651685393258, "no_speech_prob": 0.0006876683328300714}, {"id": 1458, "seek": 371966, "start": 3738.66, "end": 3739.98, "text": " There's a lot of opportunity", "tokens": [51314, 821, 311, 257, 688, 295, 2650, 51380], "temperature": 0.0, "avg_logprob": -0.19689954909603152, "compression_ratio": 1.7078651685393258, "no_speech_prob": 0.0006876683328300714}, {"id": 1459, "seek": 371966, "start": 3739.98, "end": 3742.46, "text": " to make sort of unique models too.", "tokens": [51380, 281, 652, 1333, 295, 3845, 5245, 886, 13, 51504], "temperature": 0.0, "avg_logprob": -0.19689954909603152, "compression_ratio": 1.7078651685393258, "no_speech_prob": 0.0006876683328300714}, {"id": 1460, "seek": 371966, "start": 3742.46, "end": 3745.54, "text": " Cause one thing that's sort of unique about our tournament", "tokens": [51504, 10865, 472, 551, 300, 311, 1333, 295, 3845, 466, 527, 13713, 51658], "temperature": 0.0, "avg_logprob": -0.19689954909603152, "compression_ratio": 1.7078651685393258, "no_speech_prob": 0.0006876683328300714}, {"id": 1461, "seek": 371966, "start": 3745.54, "end": 3747.74, "text": " is we release actually several targets,", "tokens": [51658, 307, 321, 4374, 767, 2940, 12911, 11, 51768], "temperature": 0.0, "avg_logprob": -0.19689954909603152, "compression_ratio": 1.7078651685393258, "no_speech_prob": 0.0006876683328300714}, {"id": 1462, "seek": 374774, "start": 3747.74, "end": 3749.9799999999996, "text": " we release 20 something targets.", "tokens": [50364, 321, 4374, 945, 746, 12911, 13, 50476], "temperature": 0.0, "avg_logprob": -0.18841514587402344, "compression_ratio": 1.8649789029535866, "no_speech_prob": 0.00239584781229496}, {"id": 1463, "seek": 374774, "start": 3750.8999999999996, "end": 3752.3399999999997, "text": " And they're all constructed", "tokens": [50522, 400, 436, 434, 439, 17083, 50594], "temperature": 0.0, "avg_logprob": -0.18841514587402344, "compression_ratio": 1.8649789029535866, "no_speech_prob": 0.00239584781229496}, {"id": 1464, "seek": 374774, "start": 3752.3399999999997, "end": 3754.2599999999998, "text": " in somewhat slightly different ways.", "tokens": [50594, 294, 8344, 4748, 819, 2098, 13, 50690], "temperature": 0.0, "avg_logprob": -0.18841514587402344, "compression_ratio": 1.8649789029535866, "no_speech_prob": 0.00239584781229496}, {"id": 1465, "seek": 374774, "start": 3754.2599999999998, "end": 3758.54, "text": " And you can find that if you train on a different target,", "tokens": [50690, 400, 291, 393, 915, 300, 498, 291, 3847, 322, 257, 819, 3779, 11, 50904], "temperature": 0.0, "avg_logprob": -0.18841514587402344, "compression_ratio": 1.8649789029535866, "no_speech_prob": 0.00239584781229496}, {"id": 1466, "seek": 374774, "start": 3758.54, "end": 3760.14, "text": " it might work almost as well as training", "tokens": [50904, 309, 1062, 589, 1920, 382, 731, 382, 3097, 50984], "temperature": 0.0, "avg_logprob": -0.18841514587402344, "compression_ratio": 1.8649789029535866, "no_speech_prob": 0.00239584781229496}, {"id": 1467, "seek": 374774, "start": 3760.14, "end": 3761.9399999999996, "text": " on the target that you're scored on.", "tokens": [50984, 322, 264, 3779, 300, 291, 434, 18139, 322, 13, 51074], "temperature": 0.0, "avg_logprob": -0.18841514587402344, "compression_ratio": 1.8649789029535866, "no_speech_prob": 0.00239584781229496}, {"id": 1468, "seek": 374774, "start": 3764.02, "end": 3765.9399999999996, "text": " And it might also ensemble really well", "tokens": [51178, 400, 309, 1062, 611, 19492, 534, 731, 51274], "temperature": 0.0, "avg_logprob": -0.18841514587402344, "compression_ratio": 1.8649789029535866, "no_speech_prob": 0.00239584781229496}, {"id": 1469, "seek": 374774, "start": 3765.9399999999996, "end": 3767.7, "text": " with a model trained on different targets.", "tokens": [51274, 365, 257, 2316, 8895, 322, 819, 12911, 13, 51362], "temperature": 0.0, "avg_logprob": -0.18841514587402344, "compression_ratio": 1.8649789029535866, "no_speech_prob": 0.00239584781229496}, {"id": 1470, "seek": 374774, "start": 3767.7, "end": 3770.06, "text": " And so you can actually create ensembles fairly easily", "tokens": [51362, 400, 370, 291, 393, 767, 1884, 12567, 2504, 904, 6457, 3612, 51480], "temperature": 0.0, "avg_logprob": -0.18841514587402344, "compression_ratio": 1.8649789029535866, "no_speech_prob": 0.00239584781229496}, {"id": 1471, "seek": 374774, "start": 3770.06, "end": 3771.8999999999996, "text": " just by training on different targets.", "tokens": [51480, 445, 538, 3097, 322, 819, 12911, 13, 51572], "temperature": 0.0, "avg_logprob": -0.18841514587402344, "compression_ratio": 1.8649789029535866, "no_speech_prob": 0.00239584781229496}, {"id": 1472, "seek": 374774, "start": 3772.8999999999996, "end": 3775.54, "text": " Because it is kind of remarkable", "tokens": [51622, 1436, 309, 307, 733, 295, 12802, 51754], "temperature": 0.0, "avg_logprob": -0.18841514587402344, "compression_ratio": 1.8649789029535866, "no_speech_prob": 0.00239584781229496}, {"id": 1473, "seek": 377554, "start": 3775.54, "end": 3777.98, "text": " that a model trained on a different target", "tokens": [50364, 300, 257, 2316, 8895, 322, 257, 819, 3779, 50486], "temperature": 0.0, "avg_logprob": -0.1344300527421255, "compression_ratio": 1.781021897810219, "no_speech_prob": 0.0009691822924651206}, {"id": 1474, "seek": 377554, "start": 3777.98, "end": 3781.22, "text": " can actually work better on the target you're interested in.", "tokens": [50486, 393, 767, 589, 1101, 322, 264, 3779, 291, 434, 3102, 294, 13, 50648], "temperature": 0.0, "avg_logprob": -0.1344300527421255, "compression_ratio": 1.781021897810219, "no_speech_prob": 0.0009691822924651206}, {"id": 1475, "seek": 377554, "start": 3781.22, "end": 3783.34, "text": " But that kind of thing, yeah, definitely does happen.", "tokens": [50648, 583, 300, 733, 295, 551, 11, 1338, 11, 2138, 775, 1051, 13, 50754], "temperature": 0.0, "avg_logprob": -0.1344300527421255, "compression_ratio": 1.781021897810219, "no_speech_prob": 0.0009691822924651206}, {"id": 1476, "seek": 377554, "start": 3783.34, "end": 3785.98, "text": " I mean, part of it is called all the correlations are so low,", "tokens": [50754, 286, 914, 11, 644, 295, 309, 307, 1219, 439, 264, 13983, 763, 366, 370, 2295, 11, 50886], "temperature": 0.0, "avg_logprob": -0.1344300527421255, "compression_ratio": 1.781021897810219, "no_speech_prob": 0.0009691822924651206}, {"id": 1477, "seek": 377554, "start": 3785.98, "end": 3789.3, "text": " but some targets might just sort of have a better property", "tokens": [50886, 457, 512, 12911, 1062, 445, 1333, 295, 362, 257, 1101, 4707, 51052], "temperature": 0.0, "avg_logprob": -0.1344300527421255, "compression_ratio": 1.781021897810219, "no_speech_prob": 0.0009691822924651206}, {"id": 1478, "seek": 377554, "start": 3789.3, "end": 3794.1, "text": " in making your model pick up on the actual signal", "tokens": [51052, 294, 1455, 428, 2316, 1888, 493, 322, 264, 3539, 6358, 51292], "temperature": 0.0, "avg_logprob": -0.1344300527421255, "compression_ratio": 1.781021897810219, "no_speech_prob": 0.0009691822924651206}, {"id": 1479, "seek": 377554, "start": 3794.1, "end": 3797.2599999999998, "text": " that you want to model rather than sort of variance", "tokens": [51292, 300, 291, 528, 281, 2316, 2831, 813, 1333, 295, 21977, 51450], "temperature": 0.0, "avg_logprob": -0.1344300527421255, "compression_ratio": 1.781021897810219, "no_speech_prob": 0.0009691822924651206}, {"id": 1480, "seek": 377554, "start": 3797.2599999999998, "end": 3800.62, "text": " that is like not that you don't want to model.", "tokens": [51450, 300, 307, 411, 406, 300, 291, 500, 380, 528, 281, 2316, 13, 51618], "temperature": 0.0, "avg_logprob": -0.1344300527421255, "compression_ratio": 1.781021897810219, "no_speech_prob": 0.0009691822924651206}, {"id": 1481, "seek": 377554, "start": 3800.62, "end": 3801.46, "text": " Interesting.", "tokens": [51618, 14711, 13, 51660], "temperature": 0.0, "avg_logprob": -0.1344300527421255, "compression_ratio": 1.781021897810219, "no_speech_prob": 0.0009691822924651206}, {"id": 1482, "seek": 377554, "start": 3801.46, "end": 3804.82, "text": " I think one of the issues is you might not know", "tokens": [51660, 286, 519, 472, 295, 264, 2663, 307, 291, 1062, 406, 458, 51828], "temperature": 0.0, "avg_logprob": -0.1344300527421255, "compression_ratio": 1.781021897810219, "no_speech_prob": 0.0009691822924651206}, {"id": 1483, "seek": 380482, "start": 3804.82, "end": 3807.06, "text": " what models that people are using.", "tokens": [50364, 437, 5245, 300, 561, 366, 1228, 13, 50476], "temperature": 0.0, "avg_logprob": -0.1797054104688691, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.0015471667284145951}, {"id": 1484, "seek": 380482, "start": 3807.06, "end": 3809.7000000000003, "text": " But I wondered if you did have any intuition,", "tokens": [50476, 583, 286, 17055, 498, 291, 630, 362, 604, 24002, 11, 50608], "temperature": 0.0, "avg_logprob": -0.1797054104688691, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.0015471667284145951}, {"id": 1485, "seek": 380482, "start": 3809.7000000000003, "end": 3811.1400000000003, "text": " I'd be fascinated to know,", "tokens": [50608, 286, 1116, 312, 24597, 281, 458, 11, 50680], "temperature": 0.0, "avg_logprob": -0.1797054104688691, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.0015471667284145951}, {"id": 1486, "seek": 380482, "start": 3811.1400000000003, "end": 3813.06, "text": " are they using very complex models?", "tokens": [50680, 366, 436, 1228, 588, 3997, 5245, 30, 50776], "temperature": 0.0, "avg_logprob": -0.1797054104688691, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.0015471667284145951}, {"id": 1487, "seek": 380482, "start": 3813.06, "end": 3814.5, "text": " Are they using simple models?", "tokens": [50776, 2014, 436, 1228, 2199, 5245, 30, 50848], "temperature": 0.0, "avg_logprob": -0.1797054104688691, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.0015471667284145951}, {"id": 1488, "seek": 380482, "start": 3815.7400000000002, "end": 3818.6600000000003, "text": " From talking to participants, there was a huge range.", "tokens": [50910, 3358, 1417, 281, 10503, 11, 456, 390, 257, 2603, 3613, 13, 51056], "temperature": 0.0, "avg_logprob": -0.1797054104688691, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.0015471667284145951}, {"id": 1489, "seek": 380482, "start": 3818.6600000000003, "end": 3821.46, "text": " There are some people using like extremely simple trees.", "tokens": [51056, 821, 366, 512, 561, 1228, 411, 4664, 2199, 5852, 13, 51196], "temperature": 0.0, "avg_logprob": -0.1797054104688691, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.0015471667284145951}, {"id": 1490, "seek": 380482, "start": 3821.46, "end": 3823.34, "text": " There are some people who are using", "tokens": [51196, 821, 366, 512, 561, 567, 366, 1228, 51290], "temperature": 0.0, "avg_logprob": -0.1797054104688691, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.0015471667284145951}, {"id": 1491, "seek": 380482, "start": 3823.34, "end": 3825.6200000000003, "text": " incredibly elaborate neural networks", "tokens": [51290, 6252, 20945, 18161, 9590, 51404], "temperature": 0.0, "avg_logprob": -0.1797054104688691, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.0015471667284145951}, {"id": 1492, "seek": 380482, "start": 3825.6200000000003, "end": 3827.9, "text": " with very sort of custom architectures", "tokens": [51404, 365, 588, 1333, 295, 2375, 6331, 1303, 51518], "temperature": 0.0, "avg_logprob": -0.1797054104688691, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.0015471667284145951}, {"id": 1493, "seek": 380482, "start": 3828.86, "end": 3831.46, "text": " that are sort of designed to the problem.", "tokens": [51566, 300, 366, 1333, 295, 4761, 281, 264, 1154, 13, 51696], "temperature": 0.0, "avg_logprob": -0.1797054104688691, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.0015471667284145951}, {"id": 1494, "seek": 380482, "start": 3831.46, "end": 3834.1400000000003, "text": " There, yeah, there's a whole huge, right?", "tokens": [51696, 821, 11, 1338, 11, 456, 311, 257, 1379, 2603, 11, 558, 30, 51830], "temperature": 0.0, "avg_logprob": -0.1797054104688691, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.0015471667284145951}, {"id": 1495, "seek": 383414, "start": 3834.14, "end": 3835.7, "text": " I mean, there's people who have huge ensembles.", "tokens": [50364, 286, 914, 11, 456, 311, 561, 567, 362, 2603, 12567, 2504, 904, 13, 50442], "temperature": 0.0, "avg_logprob": -0.1605098808512968, "compression_ratio": 1.9452554744525548, "no_speech_prob": 0.0003917749272659421}, {"id": 1496, "seek": 383414, "start": 3835.7, "end": 3837.94, "text": " There's people who are doing kind of like online learning", "tokens": [50442, 821, 311, 561, 567, 366, 884, 733, 295, 411, 2950, 2539, 50554], "temperature": 0.0, "avg_logprob": -0.1605098808512968, "compression_ratio": 1.9452554744525548, "no_speech_prob": 0.0003917749272659421}, {"id": 1497, "seek": 383414, "start": 3837.94, "end": 3840.66, "text": " where their model is actually using the features", "tokens": [50554, 689, 641, 2316, 307, 767, 1228, 264, 4122, 50690], "temperature": 0.0, "avg_logprob": -0.1605098808512968, "compression_ratio": 1.9452554744525548, "no_speech_prob": 0.0003917749272659421}, {"id": 1498, "seek": 383414, "start": 3840.66, "end": 3843.3399999999997, "text": " that were released that week", "tokens": [50690, 300, 645, 4736, 300, 1243, 50824], "temperature": 0.0, "avg_logprob": -0.1605098808512968, "compression_ratio": 1.9452554744525548, "no_speech_prob": 0.0003917749272659421}, {"id": 1499, "seek": 383414, "start": 3843.3399999999997, "end": 3846.98, "text": " and sort of using that in some sort of unsupervised learning", "tokens": [50824, 293, 1333, 295, 1228, 300, 294, 512, 1333, 295, 2693, 12879, 24420, 2539, 51006], "temperature": 0.0, "avg_logprob": -0.1605098808512968, "compression_ratio": 1.9452554744525548, "no_speech_prob": 0.0003917749272659421}, {"id": 1500, "seek": 383414, "start": 3849.14, "end": 3851.5, "text": " and then so they take some while from when we released,", "tokens": [51114, 293, 550, 370, 436, 747, 512, 1339, 490, 562, 321, 4736, 11, 51232], "temperature": 0.0, "avg_logprob": -0.1605098808512968, "compression_ratio": 1.9452554744525548, "no_speech_prob": 0.0003917749272659421}, {"id": 1501, "seek": 383414, "start": 3851.5, "end": 3852.9, "text": " they can't just like run their model", "tokens": [51232, 436, 393, 380, 445, 411, 1190, 641, 2316, 51302], "temperature": 0.0, "avg_logprob": -0.1605098808512968, "compression_ratio": 1.9452554744525548, "no_speech_prob": 0.0003917749272659421}, {"id": 1502, "seek": 383414, "start": 3852.9, "end": 3854.1, "text": " through the new set of features.", "tokens": [51302, 807, 264, 777, 992, 295, 4122, 13, 51362], "temperature": 0.0, "avg_logprob": -0.1605098808512968, "compression_ratio": 1.9452554744525548, "no_speech_prob": 0.0003917749272659421}, {"id": 1503, "seek": 383414, "start": 3854.1, "end": 3856.2599999999998, "text": " They have to incorporate this new set of features", "tokens": [51362, 814, 362, 281, 16091, 341, 777, 992, 295, 4122, 51470], "temperature": 0.0, "avg_logprob": -0.1605098808512968, "compression_ratio": 1.9452554744525548, "no_speech_prob": 0.0003917749272659421}, {"id": 1504, "seek": 383414, "start": 3856.2599999999998, "end": 3858.8199999999997, "text": " in this unsupervised way before they can,", "tokens": [51470, 294, 341, 2693, 12879, 24420, 636, 949, 436, 393, 11, 51598], "temperature": 0.0, "avg_logprob": -0.1605098808512968, "compression_ratio": 1.9452554744525548, "no_speech_prob": 0.0003917749272659421}, {"id": 1505, "seek": 383414, "start": 3858.8199999999997, "end": 3860.74, "text": " so yeah, there's an incredible variety", "tokens": [51598, 370, 1338, 11, 456, 311, 364, 4651, 5673, 51694], "temperature": 0.0, "avg_logprob": -0.1605098808512968, "compression_ratio": 1.9452554744525548, "no_speech_prob": 0.0003917749272659421}, {"id": 1506, "seek": 383414, "start": 3860.74, "end": 3863.1, "text": " of techniques people are using.", "tokens": [51694, 295, 7512, 561, 366, 1228, 13, 51812], "temperature": 0.0, "avg_logprob": -0.1605098808512968, "compression_ratio": 1.9452554744525548, "no_speech_prob": 0.0003917749272659421}, {"id": 1507, "seek": 386310, "start": 3863.1, "end": 3865.46, "text": " Fascinating, and how big is this parquet for?", "tokens": [50364, 49098, 8205, 11, 293, 577, 955, 307, 341, 971, 19343, 337, 30, 50482], "temperature": 0.0, "avg_logprob": -0.18789149230381227, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.0018048945348709822}, {"id": 1508, "seek": 386310, "start": 3865.46, "end": 3869.22, "text": " How many rows, how many fields", "tokens": [50482, 1012, 867, 13241, 11, 577, 867, 7909, 50670], "temperature": 0.0, "avg_logprob": -0.18789149230381227, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.0018048945348709822}, {"id": 1509, "seek": 386310, "start": 3869.22, "end": 3872.8199999999997, "text": " and are they all just real numbers between naught and one?", "tokens": [50670, 293, 366, 436, 439, 445, 957, 3547, 1296, 13138, 293, 472, 30, 50850], "temperature": 0.0, "avg_logprob": -0.18789149230381227, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.0018048945348709822}, {"id": 1510, "seek": 386310, "start": 3872.8199999999997, "end": 3877.02, "text": " So yeah, so there's, how many features are we up to now?", "tokens": [50850, 407, 1338, 11, 370, 456, 311, 11, 577, 867, 4122, 366, 321, 493, 281, 586, 30, 51060], "temperature": 0.0, "avg_logprob": -0.18789149230381227, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.0018048945348709822}, {"id": 1511, "seek": 386310, "start": 3877.02, "end": 3879.58, "text": " We have a couple thousand features roughly", "tokens": [51060, 492, 362, 257, 1916, 4714, 4122, 9810, 51188], "temperature": 0.0, "avg_logprob": -0.18789149230381227, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.0018048945348709822}, {"id": 1512, "seek": 386310, "start": 3879.58, "end": 3883.86, "text": " and there's a few million, a couple million rows, I think.", "tokens": [51188, 293, 456, 311, 257, 1326, 2459, 11, 257, 1916, 2459, 13241, 11, 286, 519, 13, 51402], "temperature": 0.0, "avg_logprob": -0.18789149230381227, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.0018048945348709822}, {"id": 1513, "seek": 386310, "start": 3885.38, "end": 3888.7, "text": " So one sort of additional piece of structure in the data", "tokens": [51478, 407, 472, 1333, 295, 4497, 2522, 295, 3877, 294, 264, 1412, 51644], "temperature": 0.0, "avg_logprob": -0.18789149230381227, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.0018048945348709822}, {"id": 1514, "seek": 386310, "start": 3888.7, "end": 3890.7, "text": " is there's these things called eras", "tokens": [51644, 307, 456, 311, 613, 721, 1219, 1189, 296, 51744], "temperature": 0.0, "avg_logprob": -0.18789149230381227, "compression_ratio": 1.6609442060085837, "no_speech_prob": 0.0018048945348709822}, {"id": 1515, "seek": 389070, "start": 3890.7, "end": 3893.58, "text": " and the eras are essentially just the weeks", "tokens": [50364, 293, 264, 1189, 296, 366, 4476, 445, 264, 3259, 50508], "temperature": 0.0, "avg_logprob": -0.12308199930999239, "compression_ratio": 1.8007662835249043, "no_speech_prob": 0.0002779833448585123}, {"id": 1516, "seek": 389070, "start": 3893.58, "end": 3896.5, "text": " and because the competition has this structure", "tokens": [50508, 293, 570, 264, 6211, 575, 341, 3877, 50654], "temperature": 0.0, "avg_logprob": -0.12308199930999239, "compression_ratio": 1.8007662835249043, "no_speech_prob": 0.0002779833448585123}, {"id": 1517, "seek": 389070, "start": 3896.5, "end": 3898.4199999999996, "text": " of we're making predictions every week", "tokens": [50654, 295, 321, 434, 1455, 21264, 633, 1243, 50750], "temperature": 0.0, "avg_logprob": -0.12308199930999239, "compression_ratio": 1.8007662835249043, "no_speech_prob": 0.0002779833448585123}, {"id": 1518, "seek": 389070, "start": 3898.4199999999996, "end": 3902.4199999999996, "text": " and so within each era, there's like say 5,000 rows", "tokens": [50750, 293, 370, 1951, 1184, 4249, 11, 456, 311, 411, 584, 1025, 11, 1360, 13241, 50950], "temperature": 0.0, "avg_logprob": -0.12308199930999239, "compression_ratio": 1.8007662835249043, "no_speech_prob": 0.0002779833448585123}, {"id": 1519, "seek": 389070, "start": 3902.4199999999996, "end": 3904.62, "text": " which are basically like 5,000 stocks", "tokens": [50950, 597, 366, 1936, 411, 1025, 11, 1360, 12966, 51060], "temperature": 0.0, "avg_logprob": -0.12308199930999239, "compression_ratio": 1.8007662835249043, "no_speech_prob": 0.0002779833448585123}, {"id": 1520, "seek": 389070, "start": 3904.62, "end": 3908.54, "text": " and so one sort of interesting thing is you are,", "tokens": [51060, 293, 370, 472, 1333, 295, 1880, 551, 307, 291, 366, 11, 51256], "temperature": 0.0, "avg_logprob": -0.12308199930999239, "compression_ratio": 1.8007662835249043, "no_speech_prob": 0.0002779833448585123}, {"id": 1521, "seek": 389070, "start": 3908.54, "end": 3910.74, "text": " you want your model to be good across eras,", "tokens": [51256, 291, 528, 428, 2316, 281, 312, 665, 2108, 1189, 296, 11, 51366], "temperature": 0.0, "avg_logprob": -0.12308199930999239, "compression_ratio": 1.8007662835249043, "no_speech_prob": 0.0002779833448585123}, {"id": 1522, "seek": 389070, "start": 3910.74, "end": 3912.5, "text": " not necessarily across samples", "tokens": [51366, 406, 4725, 2108, 10938, 51454], "temperature": 0.0, "avg_logprob": -0.12308199930999239, "compression_ratio": 1.8007662835249043, "no_speech_prob": 0.0002779833448585123}, {"id": 1523, "seek": 389070, "start": 3912.5, "end": 3915.74, "text": " and so it creates a different structure", "tokens": [51454, 293, 370, 309, 7829, 257, 819, 3877, 51616], "temperature": 0.0, "avg_logprob": -0.12308199930999239, "compression_ratio": 1.8007662835249043, "no_speech_prob": 0.0002779833448585123}, {"id": 1524, "seek": 389070, "start": 3915.74, "end": 3917.14, "text": " in how you think about the problem", "tokens": [51616, 294, 577, 291, 519, 466, 264, 1154, 51686], "temperature": 0.0, "avg_logprob": -0.12308199930999239, "compression_ratio": 1.8007662835249043, "no_speech_prob": 0.0002779833448585123}, {"id": 1525, "seek": 389070, "start": 3917.14, "end": 3919.14, "text": " because you want your model to be consistently good", "tokens": [51686, 570, 291, 528, 428, 2316, 281, 312, 14961, 665, 51786], "temperature": 0.0, "avg_logprob": -0.12308199930999239, "compression_ratio": 1.8007662835249043, "no_speech_prob": 0.0002779833448585123}, {"id": 1526, "seek": 391914, "start": 3919.14, "end": 3922.46, "text": " in every era and that can give you a different solution", "tokens": [50364, 294, 633, 4249, 293, 300, 393, 976, 291, 257, 819, 3827, 50530], "temperature": 0.0, "avg_logprob": -0.19643428761471984, "compression_ratio": 1.6, "no_speech_prob": 0.003944023512303829}, {"id": 1527, "seek": 391914, "start": 3922.46, "end": 3925.18, "text": " that if you just try to say maximize some metric", "tokens": [50530, 300, 498, 291, 445, 853, 281, 584, 19874, 512, 20678, 50666], "temperature": 0.0, "avg_logprob": -0.19643428761471984, "compression_ratio": 1.6, "no_speech_prob": 0.003944023512303829}, {"id": 1528, "seek": 391914, "start": 3925.18, "end": 3930.18, "text": " over the whole training set which is kind of, yeah.", "tokens": [50666, 670, 264, 1379, 3097, 992, 597, 307, 733, 295, 11, 1338, 13, 50916], "temperature": 0.0, "avg_logprob": -0.19643428761471984, "compression_ratio": 1.6, "no_speech_prob": 0.003944023512303829}, {"id": 1529, "seek": 391914, "start": 3930.66, "end": 3934.7799999999997, "text": " But yeah, it is basically just a big parquet file.", "tokens": [50940, 583, 1338, 11, 309, 307, 1936, 445, 257, 955, 971, 19343, 3991, 13, 51146], "temperature": 0.0, "avg_logprob": -0.19643428761471984, "compression_ratio": 1.6, "no_speech_prob": 0.003944023512303829}, {"id": 1530, "seek": 391914, "start": 3934.7799999999997, "end": 3937.3799999999997, "text": " We do divide it into like training", "tokens": [51146, 492, 360, 9845, 309, 666, 411, 3097, 51276], "temperature": 0.0, "avg_logprob": -0.19643428761471984, "compression_ratio": 1.6, "no_speech_prob": 0.003944023512303829}, {"id": 1531, "seek": 391914, "start": 3937.3799999999997, "end": 3941.2999999999997, "text": " and like there's like a testing set", "tokens": [51276, 293, 411, 456, 311, 411, 257, 4997, 992, 51472], "temperature": 0.0, "avg_logprob": -0.19643428761471984, "compression_ratio": 1.6, "no_speech_prob": 0.003944023512303829}, {"id": 1532, "seek": 391914, "start": 3942.98, "end": 3946.98, "text": " but yeah, do you have any specific questions", "tokens": [51556, 457, 1338, 11, 360, 291, 362, 604, 2685, 1651, 51756], "temperature": 0.0, "avg_logprob": -0.19643428761471984, "compression_ratio": 1.6, "no_speech_prob": 0.003944023512303829}, {"id": 1533, "seek": 391914, "start": 3946.98, "end": 3948.66, "text": " about how that is organized?", "tokens": [51756, 466, 577, 300, 307, 9983, 30, 51840], "temperature": 0.0, "avg_logprob": -0.19643428761471984, "compression_ratio": 1.6, "no_speech_prob": 0.003944023512303829}, {"id": 1534, "seek": 394914, "start": 3949.62, "end": 3951.66, "text": " Well, again, I'm really interested", "tokens": [50388, 1042, 11, 797, 11, 286, 478, 534, 3102, 50490], "temperature": 0.0, "avg_logprob": -0.15319286693226208, "compression_ratio": 1.650190114068441, "no_speech_prob": 0.0007832418195903301}, {"id": 1535, "seek": 394914, "start": 3951.66, "end": 3956.1, "text": " because on my PhD, I did a whole bunch of prediction models", "tokens": [50490, 570, 322, 452, 14476, 11, 286, 630, 257, 1379, 3840, 295, 17630, 5245, 50712], "temperature": 0.0, "avg_logprob": -0.15319286693226208, "compression_ratio": 1.650190114068441, "no_speech_prob": 0.0007832418195903301}, {"id": 1536, "seek": 394914, "start": 3956.1, "end": 3957.5, "text": " on financial data sets.", "tokens": [50712, 322, 4669, 1412, 6352, 13, 50782], "temperature": 0.0, "avg_logprob": -0.15319286693226208, "compression_ratio": 1.650190114068441, "no_speech_prob": 0.0007832418195903301}, {"id": 1537, "seek": 394914, "start": 3957.5, "end": 3959.66, "text": " I was predicting like the implied volatility", "tokens": [50782, 286, 390, 32884, 411, 264, 32614, 25877, 50890], "temperature": 0.0, "avg_logprob": -0.15319286693226208, "compression_ratio": 1.650190114068441, "no_speech_prob": 0.0007832418195903301}, {"id": 1538, "seek": 394914, "start": 3959.66, "end": 3963.58, "text": " of the Black Shells formula on some futures data", "tokens": [50890, 295, 264, 4076, 22863, 82, 8513, 322, 512, 26071, 1412, 51086], "temperature": 0.0, "avg_logprob": -0.15319286693226208, "compression_ratio": 1.650190114068441, "no_speech_prob": 0.0007832418195903301}, {"id": 1539, "seek": 394914, "start": 3963.58, "end": 3967.18, "text": " but my big thing at the time was I was fascinated", "tokens": [51086, 457, 452, 955, 551, 412, 264, 565, 390, 286, 390, 24597, 51266], "temperature": 0.0, "avg_logprob": -0.15319286693226208, "compression_ratio": 1.650190114068441, "no_speech_prob": 0.0007832418195903301}, {"id": 1540, "seek": 394914, "start": 3967.18, "end": 3969.66, "text": " by regimes in financial data", "tokens": [51266, 538, 45738, 294, 4669, 1412, 51390], "temperature": 0.0, "avg_logprob": -0.15319286693226208, "compression_ratio": 1.650190114068441, "no_speech_prob": 0.0007832418195903301}, {"id": 1541, "seek": 394914, "start": 3969.66, "end": 3972.7799999999997, "text": " and you get these changing dependencies with time", "tokens": [51390, 293, 291, 483, 613, 4473, 36606, 365, 565, 51546], "temperature": 0.0, "avg_logprob": -0.15319286693226208, "compression_ratio": 1.650190114068441, "no_speech_prob": 0.0007832418195903301}, {"id": 1542, "seek": 394914, "start": 3972.7799999999997, "end": 3975.42, "text": " and what I did, I mean, you could actually visualize it", "tokens": [51546, 293, 437, 286, 630, 11, 286, 914, 11, 291, 727, 767, 23273, 309, 51678], "temperature": 0.0, "avg_logprob": -0.15319286693226208, "compression_ratio": 1.650190114068441, "no_speech_prob": 0.0007832418195903301}, {"id": 1543, "seek": 394914, "start": 3975.42, "end": 3978.62, "text": " if you build a load of expert models", "tokens": [51678, 498, 291, 1322, 257, 3677, 295, 5844, 5245, 51838], "temperature": 0.0, "avg_logprob": -0.15319286693226208, "compression_ratio": 1.650190114068441, "no_speech_prob": 0.0007832418195903301}, {"id": 1544, "seek": 397862, "start": 3978.62, "end": 3980.7, "text": " on different regimes and then you get them to predict", "tokens": [50364, 322, 819, 45738, 293, 550, 291, 483, 552, 281, 6069, 50468], "temperature": 0.0, "avg_logprob": -0.09475786093897468, "compression_ratio": 1.9448051948051948, "no_speech_prob": 0.0022952789440751076}, {"id": 1545, "seek": 397862, "start": 3980.7, "end": 3982.7, "text": " on the other regime's data.", "tokens": [50468, 322, 264, 661, 13120, 311, 1412, 13, 50568], "temperature": 0.0, "avg_logprob": -0.09475786093897468, "compression_ratio": 1.9448051948051948, "no_speech_prob": 0.0022952789440751076}, {"id": 1546, "seek": 397862, "start": 3982.7, "end": 3984.7799999999997, "text": " You get this kind of self-similarity matrix", "tokens": [50568, 509, 483, 341, 733, 295, 2698, 12, 30937, 2202, 507, 8141, 50672], "temperature": 0.0, "avg_logprob": -0.09475786093897468, "compression_ratio": 1.9448051948051948, "no_speech_prob": 0.0022952789440751076}, {"id": 1547, "seek": 397862, "start": 3984.7799999999997, "end": 3987.2999999999997, "text": " and it looks like you get this kind of structure in there", "tokens": [50672, 293, 309, 1542, 411, 291, 483, 341, 733, 295, 3877, 294, 456, 50798], "temperature": 0.0, "avg_logprob": -0.09475786093897468, "compression_ratio": 1.9448051948051948, "no_speech_prob": 0.0022952789440751076}, {"id": 1548, "seek": 397862, "start": 3987.2999999999997, "end": 3989.2599999999998, "text": " because there are certain regimes", "tokens": [50798, 570, 456, 366, 1629, 45738, 50896], "temperature": 0.0, "avg_logprob": -0.09475786093897468, "compression_ratio": 1.9448051948051948, "no_speech_prob": 0.0022952789440751076}, {"id": 1549, "seek": 397862, "start": 3989.2599999999998, "end": 3991.16, "text": " where this particular model actually predicts", "tokens": [50896, 689, 341, 1729, 2316, 767, 6069, 82, 50991], "temperature": 0.0, "avg_logprob": -0.09475786093897468, "compression_ratio": 1.9448051948051948, "no_speech_prob": 0.0022952789440751076}, {"id": 1550, "seek": 397862, "start": 3991.16, "end": 3992.5, "text": " quite far out into the future", "tokens": [50991, 1596, 1400, 484, 666, 264, 2027, 51058], "temperature": 0.0, "avg_logprob": -0.09475786093897468, "compression_ratio": 1.9448051948051948, "no_speech_prob": 0.0022952789440751076}, {"id": 1551, "seek": 397862, "start": 3992.5, "end": 3993.74, "text": " and then it might suddenly go dead", "tokens": [51058, 293, 550, 309, 1062, 5800, 352, 3116, 51120], "temperature": 0.0, "avg_logprob": -0.09475786093897468, "compression_ratio": 1.9448051948051948, "no_speech_prob": 0.0022952789440751076}, {"id": 1552, "seek": 397862, "start": 3993.74, "end": 3995.3399999999997, "text": " so you get these kind of squares", "tokens": [51120, 370, 291, 483, 613, 733, 295, 19368, 51200], "temperature": 0.0, "avg_logprob": -0.09475786093897468, "compression_ratio": 1.9448051948051948, "no_speech_prob": 0.0022952789440751076}, {"id": 1553, "seek": 397862, "start": 3995.3399999999997, "end": 3998.1, "text": " and I had this big thesis that if I have expert models", "tokens": [51200, 293, 286, 632, 341, 955, 22288, 300, 498, 286, 362, 5844, 5245, 51338], "temperature": 0.0, "avg_logprob": -0.09475786093897468, "compression_ratio": 1.9448051948051948, "no_speech_prob": 0.0022952789440751076}, {"id": 1554, "seek": 397862, "start": 3998.1, "end": 3999.62, "text": " and use prediction with expert advice,", "tokens": [51338, 293, 764, 17630, 365, 5844, 5192, 11, 51414], "temperature": 0.0, "avg_logprob": -0.09475786093897468, "compression_ratio": 1.9448051948051948, "no_speech_prob": 0.0022952789440751076}, {"id": 1555, "seek": 397862, "start": 3999.62, "end": 4001.06, "text": " then when we come into a new regime,", "tokens": [51414, 550, 562, 321, 808, 666, 257, 777, 13120, 11, 51486], "temperature": 0.0, "avg_logprob": -0.09475786093897468, "compression_ratio": 1.9448051948051948, "no_speech_prob": 0.0022952789440751076}, {"id": 1556, "seek": 397862, "start": 4001.06, "end": 4003.9, "text": " I would quickly learn which experts are the good ones", "tokens": [51486, 286, 576, 2661, 1466, 597, 8572, 366, 264, 665, 2306, 51628], "temperature": 0.0, "avg_logprob": -0.09475786093897468, "compression_ratio": 1.9448051948051948, "no_speech_prob": 0.0022952789440751076}, {"id": 1557, "seek": 397862, "start": 4003.9, "end": 4007.2799999999997, "text": " and I had this thesis that sometimes old information", "tokens": [51628, 293, 286, 632, 341, 22288, 300, 2171, 1331, 1589, 51797], "temperature": 0.0, "avg_logprob": -0.09475786093897468, "compression_ratio": 1.9448051948051948, "no_speech_prob": 0.0022952789440751076}, {"id": 1558, "seek": 400728, "start": 4007.28, "end": 4010.1200000000003, "text": " is very helpful in the future more so than using", "tokens": [50364, 307, 588, 4961, 294, 264, 2027, 544, 370, 813, 1228, 50506], "temperature": 0.0, "avg_logprob": -0.19840253520215678, "compression_ratio": 1.7410358565737052, "no_speech_prob": 0.0031708190217614174}, {"id": 1559, "seek": 400728, "start": 4010.1200000000003, "end": 4012.88, "text": " like a simple sliding window ridge regression or whatever", "tokens": [50506, 411, 257, 2199, 21169, 4910, 34651, 24590, 420, 2035, 50644], "temperature": 0.0, "avg_logprob": -0.19840253520215678, "compression_ratio": 1.7410358565737052, "no_speech_prob": 0.0031708190217614174}, {"id": 1560, "seek": 400728, "start": 4012.88, "end": 4014.0800000000004, "text": " and it turned out I was wrong.", "tokens": [50644, 293, 309, 3574, 484, 286, 390, 2085, 13, 50704], "temperature": 0.0, "avg_logprob": -0.19840253520215678, "compression_ratio": 1.7410358565737052, "no_speech_prob": 0.0031708190217614174}, {"id": 1561, "seek": 400728, "start": 4014.0800000000004, "end": 4015.36, "text": " It's almost always better just to use", "tokens": [50704, 467, 311, 1920, 1009, 1101, 445, 281, 764, 50768], "temperature": 0.0, "avg_logprob": -0.19840253520215678, "compression_ratio": 1.7410358565737052, "no_speech_prob": 0.0031708190217614174}, {"id": 1562, "seek": 400728, "start": 4015.36, "end": 4018.7200000000003, "text": " a sliding window regression but yeah, it's fascinating.", "tokens": [50768, 257, 21169, 4910, 24590, 457, 1338, 11, 309, 311, 10343, 13, 50936], "temperature": 0.0, "avg_logprob": -0.19840253520215678, "compression_ratio": 1.7410358565737052, "no_speech_prob": 0.0031708190217614174}, {"id": 1563, "seek": 400728, "start": 4018.7200000000003, "end": 4021.8, "text": " It's, yeah, it's interesting.", "tokens": [50936, 467, 311, 11, 1338, 11, 309, 311, 1880, 13, 51090], "temperature": 0.0, "avg_logprob": -0.19840253520215678, "compression_ratio": 1.7410358565737052, "no_speech_prob": 0.0031708190217614174}, {"id": 1564, "seek": 400728, "start": 4021.8, "end": 4026.8, "text": " Like the, you definitely want to train on a lot of data", "tokens": [51090, 1743, 264, 11, 291, 2138, 528, 281, 3847, 322, 257, 688, 295, 1412, 51340], "temperature": 0.0, "avg_logprob": -0.19840253520215678, "compression_ratio": 1.7410358565737052, "no_speech_prob": 0.0031708190217614174}, {"id": 1565, "seek": 400728, "start": 4027.36, "end": 4029.8, "text": " for these models.", "tokens": [51368, 337, 613, 5245, 13, 51490], "temperature": 0.0, "avg_logprob": -0.19840253520215678, "compression_ratio": 1.7410358565737052, "no_speech_prob": 0.0031708190217614174}, {"id": 1566, "seek": 400728, "start": 4029.8, "end": 4032.1600000000003, "text": " It definitely, like if you just use the prior one year", "tokens": [51490, 467, 2138, 11, 411, 498, 291, 445, 764, 264, 4059, 472, 1064, 51608], "temperature": 0.0, "avg_logprob": -0.19840253520215678, "compression_ratio": 1.7410358565737052, "no_speech_prob": 0.0031708190217614174}, {"id": 1567, "seek": 400728, "start": 4032.1600000000003, "end": 4034.44, "text": " of data, your models are gonna be pretty crap.", "tokens": [51608, 295, 1412, 11, 428, 5245, 366, 799, 312, 1238, 12426, 13, 51722], "temperature": 0.0, "avg_logprob": -0.19840253520215678, "compression_ratio": 1.7410358565737052, "no_speech_prob": 0.0031708190217614174}, {"id": 1568, "seek": 403444, "start": 4035.44, "end": 4038.56, "text": " It definitely helps to use like prior 10 years of data", "tokens": [50414, 467, 2138, 3665, 281, 764, 411, 4059, 1266, 924, 295, 1412, 50570], "temperature": 0.0, "avg_logprob": -0.18201863961141618, "compression_ratio": 1.6412213740458015, "no_speech_prob": 0.0007320779841393232}, {"id": 1569, "seek": 403444, "start": 4039.76, "end": 4044.0, "text": " and so it is, you're using actually quite old data often", "tokens": [50630, 293, 370, 309, 307, 11, 291, 434, 1228, 767, 1596, 1331, 1412, 2049, 50842], "temperature": 0.0, "avg_logprob": -0.18201863961141618, "compression_ratio": 1.6412213740458015, "no_speech_prob": 0.0007320779841393232}, {"id": 1570, "seek": 403444, "start": 4044.0, "end": 4047.96, "text": " in predicting into the future but generally, yeah,", "tokens": [50842, 294, 32884, 666, 264, 2027, 457, 5101, 11, 1338, 11, 51040], "temperature": 0.0, "avg_logprob": -0.18201863961141618, "compression_ratio": 1.6412213740458015, "no_speech_prob": 0.0007320779841393232}, {"id": 1571, "seek": 403444, "start": 4047.96, "end": 4050.8, "text": " if you were only just using the last year or two of data,", "tokens": [51040, 498, 291, 645, 787, 445, 1228, 264, 1036, 1064, 420, 732, 295, 1412, 11, 51182], "temperature": 0.0, "avg_logprob": -0.18201863961141618, "compression_ratio": 1.6412213740458015, "no_speech_prob": 0.0007320779841393232}, {"id": 1572, "seek": 403444, "start": 4050.8, "end": 4053.6, "text": " your models are gonna have to actually quite a hard time.", "tokens": [51182, 428, 5245, 366, 799, 362, 281, 767, 1596, 257, 1152, 565, 13, 51322], "temperature": 0.0, "avg_logprob": -0.18201863961141618, "compression_ratio": 1.6412213740458015, "no_speech_prob": 0.0007320779841393232}, {"id": 1573, "seek": 403444, "start": 4054.76, "end": 4057.08, "text": " Yeah, one other thing about the features I wanted to say", "tokens": [51380, 865, 11, 472, 661, 551, 466, 264, 4122, 286, 1415, 281, 584, 51496], "temperature": 0.0, "avg_logprob": -0.18201863961141618, "compression_ratio": 1.6412213740458015, "no_speech_prob": 0.0007320779841393232}, {"id": 1574, "seek": 403444, "start": 4057.08, "end": 4060.48, "text": " is they are between zero and one, they're in five bins.", "tokens": [51496, 307, 436, 366, 1296, 4018, 293, 472, 11, 436, 434, 294, 1732, 41275, 13, 51666], "temperature": 0.0, "avg_logprob": -0.18201863961141618, "compression_ratio": 1.6412213740458015, "no_speech_prob": 0.0007320779841393232}, {"id": 1575, "seek": 403444, "start": 4060.48, "end": 4063.8, "text": " There's zero, 0.25, 0.5, 0.75 and one.", "tokens": [51666, 821, 311, 4018, 11, 1958, 13, 6074, 11, 1958, 13, 20, 11, 1958, 13, 11901, 293, 472, 13, 51832], "temperature": 0.0, "avg_logprob": -0.18201863961141618, "compression_ratio": 1.6412213740458015, "no_speech_prob": 0.0007320779841393232}, {"id": 1576, "seek": 406380, "start": 4063.8, "end": 4067.4, "text": " So the data has been like binned in this way", "tokens": [50364, 407, 264, 1412, 575, 668, 411, 5171, 9232, 294, 341, 636, 50544], "temperature": 0.0, "avg_logprob": -0.19151953550485465, "compression_ratio": 1.6484018264840183, "no_speech_prob": 7.48319216654636e-05}, {"id": 1577, "seek": 406380, "start": 4067.4, "end": 4070.6800000000003, "text": " and the targets are also binned in this,", "tokens": [50544, 293, 264, 12911, 366, 611, 5171, 9232, 294, 341, 11, 50708], "temperature": 0.0, "avg_logprob": -0.19151953550485465, "compression_ratio": 1.6484018264840183, "no_speech_prob": 7.48319216654636e-05}, {"id": 1578, "seek": 406380, "start": 4070.6800000000003, "end": 4073.36, "text": " the same sort of bins but with a different distribution.", "tokens": [50708, 264, 912, 1333, 295, 41275, 457, 365, 257, 819, 7316, 13, 50842], "temperature": 0.0, "avg_logprob": -0.19151953550485465, "compression_ratio": 1.6484018264840183, "no_speech_prob": 7.48319216654636e-05}, {"id": 1579, "seek": 406380, "start": 4073.36, "end": 4075.1200000000003, "text": " The targets have like in their extreme bins,", "tokens": [50842, 440, 12911, 362, 411, 294, 641, 8084, 41275, 11, 50930], "temperature": 0.0, "avg_logprob": -0.19151953550485465, "compression_ratio": 1.6484018264840183, "no_speech_prob": 7.48319216654636e-05}, {"id": 1580, "seek": 406380, "start": 4075.1200000000003, "end": 4078.6000000000004, "text": " only like 5% of the values in the next two extreme bins.", "tokens": [50930, 787, 411, 1025, 4, 295, 264, 4190, 294, 264, 958, 732, 8084, 41275, 13, 51104], "temperature": 0.0, "avg_logprob": -0.19151953550485465, "compression_ratio": 1.6484018264840183, "no_speech_prob": 7.48319216654636e-05}, {"id": 1581, "seek": 406380, "start": 4079.44, "end": 4084.44, "text": " Like what is it, 20 in each of them", "tokens": [51146, 1743, 437, 307, 309, 11, 945, 294, 1184, 295, 552, 51396], "temperature": 0.0, "avg_logprob": -0.19151953550485465, "compression_ratio": 1.6484018264840183, "no_speech_prob": 7.48319216654636e-05}, {"id": 1582, "seek": 406380, "start": 4085.36, "end": 4087.28, "text": " and then 50% as a zero.", "tokens": [51442, 293, 550, 2625, 4, 382, 257, 4018, 13, 51538], "temperature": 0.0, "avg_logprob": -0.19151953550485465, "compression_ratio": 1.6484018264840183, "no_speech_prob": 7.48319216654636e-05}, {"id": 1583, "seek": 406380, "start": 4088.36, "end": 4089.8, "text": " Interesting.", "tokens": [51592, 14711, 13, 51664], "temperature": 0.0, "avg_logprob": -0.19151953550485465, "compression_ratio": 1.6484018264840183, "no_speech_prob": 7.48319216654636e-05}, {"id": 1584, "seek": 406380, "start": 4089.8, "end": 4092.6400000000003, "text": " But all the features are basically just 20%", "tokens": [51664, 583, 439, 264, 4122, 366, 1936, 445, 945, 4, 51806], "temperature": 0.0, "avg_logprob": -0.19151953550485465, "compression_ratio": 1.6484018264840183, "no_speech_prob": 7.48319216654636e-05}, {"id": 1585, "seek": 409264, "start": 4092.64, "end": 4093.64, "text": " in each of the bins.", "tokens": [50364, 294, 1184, 295, 264, 41275, 13, 50414], "temperature": 0.0, "avg_logprob": -0.17415461332901663, "compression_ratio": 1.7759336099585061, "no_speech_prob": 0.0016479460755363107}, {"id": 1586, "seek": 409264, "start": 4094.64, "end": 4099.599999999999, "text": " And so the binning is a pretty strong form of regularization.", "tokens": [50464, 400, 370, 264, 5171, 773, 307, 257, 1238, 2068, 1254, 295, 3890, 2144, 13, 50712], "temperature": 0.0, "avg_logprob": -0.17415461332901663, "compression_ratio": 1.7759336099585061, "no_speech_prob": 0.0016479460755363107}, {"id": 1587, "seek": 409264, "start": 4099.599999999999, "end": 4102.0, "text": " It sort of prevents you from like a tree from splitting", "tokens": [50712, 467, 1333, 295, 22367, 291, 490, 411, 257, 4230, 490, 30348, 50832], "temperature": 0.0, "avg_logprob": -0.17415461332901663, "compression_ratio": 1.7759336099585061, "no_speech_prob": 0.0016479460755363107}, {"id": 1588, "seek": 409264, "start": 4102.0, "end": 4105.5599999999995, "text": " sort of any arbitrary place you can only split at these things", "tokens": [50832, 1333, 295, 604, 23211, 1081, 291, 393, 787, 7472, 412, 613, 721, 51010], "temperature": 0.0, "avg_logprob": -0.17415461332901663, "compression_ratio": 1.7759336099585061, "no_speech_prob": 0.0016479460755363107}, {"id": 1589, "seek": 409264, "start": 4105.5599999999995, "end": 4108.84, "text": " and so that kind of forces at least some of the space", "tokens": [51010, 293, 370, 300, 733, 295, 5874, 412, 1935, 512, 295, 264, 1901, 51174], "temperature": 0.0, "avg_logprob": -0.17415461332901663, "compression_ratio": 1.7759336099585061, "no_speech_prob": 0.0016479460755363107}, {"id": 1590, "seek": 409264, "start": 4108.84, "end": 4111.48, "text": " to be at different splits.", "tokens": [51174, 281, 312, 412, 819, 37741, 13, 51306], "temperature": 0.0, "avg_logprob": -0.17415461332901663, "compression_ratio": 1.7759336099585061, "no_speech_prob": 0.0016479460755363107}, {"id": 1591, "seek": 409264, "start": 4111.48, "end": 4113.98, "text": " And that regularization, it's kind of,", "tokens": [51306, 400, 300, 3890, 2144, 11, 309, 311, 733, 295, 11, 51431], "temperature": 0.0, "avg_logprob": -0.17415461332901663, "compression_ratio": 1.7759336099585061, "no_speech_prob": 0.0016479460755363107}, {"id": 1592, "seek": 409264, "start": 4113.98, "end": 4116.68, "text": " you would think that having continuous features", "tokens": [51431, 291, 576, 519, 300, 1419, 10957, 4122, 51566], "temperature": 0.0, "avg_logprob": -0.17415461332901663, "compression_ratio": 1.7759336099585061, "no_speech_prob": 0.0016479460755363107}, {"id": 1593, "seek": 409264, "start": 4116.68, "end": 4118.68, "text": " would be a lot really helpful but I mean,", "tokens": [51566, 576, 312, 257, 688, 534, 4961, 457, 286, 914, 11, 51666], "temperature": 0.0, "avg_logprob": -0.17415461332901663, "compression_ratio": 1.7759336099585061, "no_speech_prob": 0.0016479460755363107}, {"id": 1594, "seek": 409264, "start": 4118.68, "end": 4120.5199999999995, "text": " it's really not.", "tokens": [51666, 309, 311, 534, 406, 13, 51758], "temperature": 0.0, "avg_logprob": -0.17415461332901663, "compression_ratio": 1.7759336099585061, "no_speech_prob": 0.0016479460755363107}, {"id": 1595, "seek": 412052, "start": 4120.56, "end": 4124.280000000001, "text": " It's kind of remarkable how lossy", "tokens": [50366, 467, 311, 733, 295, 12802, 577, 4470, 88, 50552], "temperature": 0.0, "avg_logprob": -0.1482144684350791, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0005187818314880133}, {"id": 1596, "seek": 412052, "start": 4124.280000000001, "end": 4126.200000000001, "text": " some of these transforms are that we do", "tokens": [50552, 512, 295, 613, 35592, 366, 300, 321, 360, 50648], "temperature": 0.0, "avg_logprob": -0.1482144684350791, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0005187818314880133}, {"id": 1597, "seek": 412052, "start": 4126.200000000001, "end": 4128.6, "text": " that actually seem to be helpful.", "tokens": [50648, 300, 767, 1643, 281, 312, 4961, 13, 50768], "temperature": 0.0, "avg_logprob": -0.1482144684350791, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0005187818314880133}, {"id": 1598, "seek": 412052, "start": 4128.6, "end": 4129.68, "text": " Yeah, so it's so interesting.", "tokens": [50768, 865, 11, 370, 309, 311, 370, 1880, 13, 50822], "temperature": 0.0, "avg_logprob": -0.1482144684350791, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0005187818314880133}, {"id": 1599, "seek": 412052, "start": 4129.68, "end": 4133.240000000001, "text": " And I guess like one thing I didn't really appreciate", "tokens": [50822, 400, 286, 2041, 411, 472, 551, 286, 994, 380, 534, 4449, 51000], "temperature": 0.0, "avg_logprob": -0.1482144684350791, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0005187818314880133}, {"id": 1600, "seek": 412052, "start": 4133.240000000001, "end": 4134.4400000000005, "text": " at the time is you know, we were just talking", "tokens": [51000, 412, 264, 565, 307, 291, 458, 11, 321, 645, 445, 1417, 51060], "temperature": 0.0, "avg_logprob": -0.1482144684350791, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0005187818314880133}, {"id": 1601, "seek": 412052, "start": 4134.4400000000005, "end": 4136.68, "text": " about these complex dynamical systems", "tokens": [51060, 466, 613, 3997, 5999, 804, 3652, 51172], "temperature": 0.0, "avg_logprob": -0.1482144684350791, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0005187818314880133}, {"id": 1602, "seek": 412052, "start": 4136.68, "end": 4138.52, "text": " like the brain or like financial markets", "tokens": [51172, 411, 264, 3567, 420, 411, 4669, 8383, 51264], "temperature": 0.0, "avg_logprob": -0.1482144684350791, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0005187818314880133}, {"id": 1603, "seek": 412052, "start": 4138.52, "end": 4140.6, "text": " and there's of course the market efficiency hypothesis", "tokens": [51264, 293, 456, 311, 295, 1164, 264, 2142, 10493, 17291, 51368], "temperature": 0.0, "avg_logprob": -0.1482144684350791, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0005187818314880133}, {"id": 1604, "seek": 412052, "start": 4140.6, "end": 4145.0, "text": " and perhaps one of the reasons why old information", "tokens": [51368, 293, 4317, 472, 295, 264, 4112, 983, 1331, 1589, 51588], "temperature": 0.0, "avg_logprob": -0.1482144684350791, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0005187818314880133}, {"id": 1605, "seek": 412052, "start": 4145.0, "end": 4148.84, "text": " might not be salient is because if the underlying system", "tokens": [51588, 1062, 406, 312, 1845, 1196, 307, 570, 498, 264, 14217, 1185, 51780], "temperature": 0.0, "avg_logprob": -0.1482144684350791, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0005187818314880133}, {"id": 1606, "seek": 414884, "start": 4148.84, "end": 4150.360000000001, "text": " is actually taking a trajectory", "tokens": [50364, 307, 767, 1940, 257, 21512, 50440], "temperature": 0.0, "avg_logprob": -0.1178922395448427, "compression_ratio": 1.6462093862815885, "no_speech_prob": 0.005970194470137358}, {"id": 1607, "seek": 414884, "start": 4150.360000000001, "end": 4152.360000000001, "text": " through this kind of complex space,", "tokens": [50440, 807, 341, 733, 295, 3997, 1901, 11, 50540], "temperature": 0.0, "avg_logprob": -0.1178922395448427, "compression_ratio": 1.6462093862815885, "no_speech_prob": 0.005970194470137358}, {"id": 1608, "seek": 414884, "start": 4152.360000000001, "end": 4155.56, "text": " then you might argue that almost regardless", "tokens": [50540, 550, 291, 1062, 9695, 300, 1920, 10060, 50700], "temperature": 0.0, "avg_logprob": -0.1178922395448427, "compression_ratio": 1.6462093862815885, "no_speech_prob": 0.005970194470137358}, {"id": 1609, "seek": 414884, "start": 4155.56, "end": 4159.0, "text": " of where you traverse, you'll always be in a novel situation.", "tokens": [50700, 295, 689, 291, 45674, 11, 291, 603, 1009, 312, 294, 257, 7613, 2590, 13, 50872], "temperature": 0.0, "avg_logprob": -0.1178922395448427, "compression_ratio": 1.6462093862815885, "no_speech_prob": 0.005970194470137358}, {"id": 1610, "seek": 414884, "start": 4159.0, "end": 4160.54, "text": " And then there's this continuum", "tokens": [50872, 400, 550, 456, 311, 341, 36120, 50949], "temperature": 0.0, "avg_logprob": -0.1178922395448427, "compression_ratio": 1.6462093862815885, "no_speech_prob": 0.005970194470137358}, {"id": 1611, "seek": 414884, "start": 4160.54, "end": 4162.6, "text": " of regularity versus chaos.", "tokens": [50949, 295, 3890, 507, 5717, 14158, 13, 51052], "temperature": 0.0, "avg_logprob": -0.1178922395448427, "compression_ratio": 1.6462093862815885, "no_speech_prob": 0.005970194470137358}, {"id": 1612, "seek": 414884, "start": 4162.6, "end": 4167.0, "text": " So like for example, if you're predicting options futures", "tokens": [51052, 407, 411, 337, 1365, 11, 498, 291, 434, 32884, 3956, 26071, 51272], "temperature": 0.0, "avg_logprob": -0.1178922395448427, "compression_ratio": 1.6462093862815885, "no_speech_prob": 0.005970194470137358}, {"id": 1613, "seek": 414884, "start": 4167.0, "end": 4170.02, "text": " when they get close to maturity,", "tokens": [51272, 562, 436, 483, 1998, 281, 28874, 11, 51423], "temperature": 0.0, "avg_logprob": -0.1178922395448427, "compression_ratio": 1.6462093862815885, "no_speech_prob": 0.005970194470137358}, {"id": 1614, "seek": 414884, "start": 4170.02, "end": 4171.84, "text": " the volatility just goes crazy", "tokens": [51423, 264, 25877, 445, 1709, 3219, 51514], "temperature": 0.0, "avg_logprob": -0.1178922395448427, "compression_ratio": 1.6462093862815885, "no_speech_prob": 0.005970194470137358}, {"id": 1615, "seek": 414884, "start": 4171.84, "end": 4174.400000000001, "text": " and they just become increasingly unpredictable.", "tokens": [51514, 293, 436, 445, 1813, 12980, 31160, 13, 51642], "temperature": 0.0, "avg_logprob": -0.1178922395448427, "compression_ratio": 1.6462093862815885, "no_speech_prob": 0.005970194470137358}, {"id": 1616, "seek": 414884, "start": 4174.400000000001, "end": 4178.360000000001, "text": " And I guess the art in this kind of data is knowing", "tokens": [51642, 400, 286, 2041, 264, 1523, 294, 341, 733, 295, 1412, 307, 5276, 51840], "temperature": 0.0, "avg_logprob": -0.1178922395448427, "compression_ratio": 1.6462093862815885, "no_speech_prob": 0.005970194470137358}, {"id": 1617, "seek": 417836, "start": 4178.36, "end": 4180.639999999999, "text": " when you're in a regime which has some regularity", "tokens": [50364, 562, 291, 434, 294, 257, 13120, 597, 575, 512, 3890, 507, 50478], "temperature": 0.0, "avg_logprob": -0.20463260140005998, "compression_ratio": 1.8410852713178294, "no_speech_prob": 0.0008292354759760201}, {"id": 1618, "seek": 417836, "start": 4180.639999999999, "end": 4182.24, "text": " and when you're not.", "tokens": [50478, 293, 562, 291, 434, 406, 13, 50558], "temperature": 0.0, "avg_logprob": -0.20463260140005998, "compression_ratio": 1.8410852713178294, "no_speech_prob": 0.0008292354759760201}, {"id": 1619, "seek": 417836, "start": 4182.24, "end": 4183.5599999999995, "text": " It's yeah, it's tricky.", "tokens": [50558, 467, 311, 1338, 11, 309, 311, 12414, 13, 50624], "temperature": 0.0, "avg_logprob": -0.20463260140005998, "compression_ratio": 1.8410852713178294, "no_speech_prob": 0.0008292354759760201}, {"id": 1620, "seek": 417836, "start": 4183.5599999999995, "end": 4185.599999999999, "text": " Cause like ideally we want our model,", "tokens": [50624, 10865, 411, 22915, 321, 528, 527, 2316, 11, 50726], "temperature": 0.0, "avg_logprob": -0.20463260140005998, "compression_ratio": 1.8410852713178294, "no_speech_prob": 0.0008292354759760201}, {"id": 1621, "seek": 417836, "start": 4185.599999999999, "end": 4188.92, "text": " we want our meta model to sort of work well in any regime", "tokens": [50726, 321, 528, 527, 19616, 2316, 281, 1333, 295, 589, 731, 294, 604, 13120, 50892], "temperature": 0.0, "avg_logprob": -0.20463260140005998, "compression_ratio": 1.8410852713178294, "no_speech_prob": 0.0008292354759760201}, {"id": 1622, "seek": 417836, "start": 4188.92, "end": 4193.28, "text": " and it does seem to work pretty well consistently.", "tokens": [50892, 293, 309, 775, 1643, 281, 589, 1238, 731, 14961, 13, 51110], "temperature": 0.0, "avg_logprob": -0.20463260140005998, "compression_ratio": 1.8410852713178294, "no_speech_prob": 0.0008292354759760201}, {"id": 1623, "seek": 417836, "start": 4193.28, "end": 4196.599999999999, "text": " And but what you do find on like the leaderboard", "tokens": [51110, 400, 457, 437, 291, 360, 915, 322, 411, 264, 5263, 3787, 51276], "temperature": 0.0, "avg_logprob": -0.20463260140005998, "compression_ratio": 1.8410852713178294, "no_speech_prob": 0.0008292354759760201}, {"id": 1624, "seek": 417836, "start": 4196.599999999999, "end": 4198.219999999999, "text": " tournament participants, you'll see some people", "tokens": [51276, 13713, 10503, 11, 291, 603, 536, 512, 561, 51357], "temperature": 0.0, "avg_logprob": -0.20463260140005998, "compression_ratio": 1.8410852713178294, "no_speech_prob": 0.0008292354759760201}, {"id": 1625, "seek": 417836, "start": 4198.219999999999, "end": 4199.88, "text": " who stay at the top of the leaderboard", "tokens": [51357, 567, 1754, 412, 264, 1192, 295, 264, 5263, 3787, 51440], "temperature": 0.0, "avg_logprob": -0.20463260140005998, "compression_ratio": 1.8410852713178294, "no_speech_prob": 0.0008292354759760201}, {"id": 1626, "seek": 417836, "start": 4199.88, "end": 4201.679999999999, "text": " for weeks and weeks and weeks and weeks,", "tokens": [51440, 337, 3259, 293, 3259, 293, 3259, 293, 3259, 11, 51530], "temperature": 0.0, "avg_logprob": -0.20463260140005998, "compression_ratio": 1.8410852713178294, "no_speech_prob": 0.0008292354759760201}, {"id": 1627, "seek": 417836, "start": 4201.679999999999, "end": 4206.679999999999, "text": " then suddenly precipitate fall like down the leaderboard", "tokens": [51530, 550, 5800, 23354, 8086, 2100, 411, 760, 264, 5263, 3787, 51780], "temperature": 0.0, "avg_logprob": -0.20463260140005998, "compression_ratio": 1.8410852713178294, "no_speech_prob": 0.0008292354759760201}, {"id": 1628, "seek": 420668, "start": 4207.16, "end": 4211.04, "text": " as demonstrating some sort of regime effects.", "tokens": [50388, 382, 29889, 512, 1333, 295, 13120, 5065, 13, 50582], "temperature": 0.0, "avg_logprob": -0.12745734850565593, "compression_ratio": 1.8583333333333334, "no_speech_prob": 0.0009108917438425124}, {"id": 1629, "seek": 420668, "start": 4211.04, "end": 4213.76, "text": " One really kind of interesting thing I did was", "tokens": [50582, 1485, 534, 733, 295, 1880, 551, 286, 630, 390, 50718], "temperature": 0.0, "avg_logprob": -0.12745734850565593, "compression_ratio": 1.8583333333333334, "no_speech_prob": 0.0009108917438425124}, {"id": 1630, "seek": 420668, "start": 4214.76, "end": 4217.96, "text": " I fit like a mixture of linear models to the data.", "tokens": [50768, 286, 3318, 411, 257, 9925, 295, 8213, 5245, 281, 264, 1412, 13, 50928], "temperature": 0.0, "avg_logprob": -0.12745734850565593, "compression_ratio": 1.8583333333333334, "no_speech_prob": 0.0009108917438425124}, {"id": 1631, "seek": 420668, "start": 4217.96, "end": 4219.96, "text": " So if you fit just like a mixture of two linear models", "tokens": [50928, 407, 498, 291, 3318, 445, 411, 257, 9925, 295, 732, 8213, 5245, 51028], "temperature": 0.0, "avg_logprob": -0.12745734850565593, "compression_ratio": 1.8583333333333334, "no_speech_prob": 0.0009108917438425124}, {"id": 1632, "seek": 420668, "start": 4219.96, "end": 4222.280000000001, "text": " where it's sort of selecting which eras to use", "tokens": [51028, 689, 309, 311, 1333, 295, 18182, 597, 1189, 296, 281, 764, 51144], "temperature": 0.0, "avg_logprob": -0.12745734850565593, "compression_ratio": 1.8583333333333334, "no_speech_prob": 0.0009108917438425124}, {"id": 1633, "seek": 420668, "start": 4222.280000000001, "end": 4224.64, "text": " for which of the two linear models,", "tokens": [51144, 337, 597, 295, 264, 732, 8213, 5245, 11, 51262], "temperature": 0.0, "avg_logprob": -0.12745734850565593, "compression_ratio": 1.8583333333333334, "no_speech_prob": 0.0009108917438425124}, {"id": 1634, "seek": 420668, "start": 4224.64, "end": 4227.0, "text": " you basically, one linear model will get", "tokens": [51262, 291, 1936, 11, 472, 8213, 2316, 486, 483, 51380], "temperature": 0.0, "avg_logprob": -0.12745734850565593, "compression_ratio": 1.8583333333333334, "no_speech_prob": 0.0009108917438425124}, {"id": 1635, "seek": 420668, "start": 4227.0, "end": 4228.280000000001, "text": " about 60% of the errors,", "tokens": [51380, 466, 4060, 4, 295, 264, 13603, 11, 51444], "temperature": 0.0, "avg_logprob": -0.12745734850565593, "compression_ratio": 1.8583333333333334, "no_speech_prob": 0.0009108917438425124}, {"id": 1636, "seek": 420668, "start": 4228.280000000001, "end": 4230.4800000000005, "text": " one will get about 40% of the errors", "tokens": [51444, 472, 486, 483, 466, 3356, 4, 295, 264, 13603, 51554], "temperature": 0.0, "avg_logprob": -0.12745734850565593, "compression_ratio": 1.8583333333333334, "no_speech_prob": 0.0009108917438425124}, {"id": 1637, "seek": 420668, "start": 4230.4800000000005, "end": 4233.08, "text": " and their weights will be almost mirror images", "tokens": [51554, 293, 641, 17443, 486, 312, 1920, 8013, 5267, 51684], "temperature": 0.0, "avg_logprob": -0.12745734850565593, "compression_ratio": 1.8583333333333334, "no_speech_prob": 0.0009108917438425124}, {"id": 1638, "seek": 420668, "start": 4233.08, "end": 4233.92, "text": " of each other.", "tokens": [51684, 295, 1184, 661, 13, 51726], "temperature": 0.0, "avg_logprob": -0.12745734850565593, "compression_ratio": 1.8583333333333334, "no_speech_prob": 0.0009108917438425124}, {"id": 1639, "seek": 423392, "start": 4234.4400000000005, "end": 4238.16, "text": " And this just comes out like that is the optimal fit", "tokens": [50390, 400, 341, 445, 1487, 484, 411, 300, 307, 264, 16252, 3318, 50576], "temperature": 0.0, "avg_logprob": -0.2510264714558919, "compression_ratio": 1.7088122605363985, "no_speech_prob": 0.0008294865256175399}, {"id": 1640, "seek": 423392, "start": 4238.16, "end": 4240.2, "text": " for roughly for 40% of the errors", "tokens": [50576, 337, 9810, 337, 3356, 4, 295, 264, 13603, 50678], "temperature": 0.0, "avg_logprob": -0.2510264714558919, "compression_ratio": 1.7088122605363985, "no_speech_prob": 0.0008294865256175399}, {"id": 1641, "seek": 423392, "start": 4240.2, "end": 4243.4800000000005, "text": " that basically completely the opposite of the other eras.", "tokens": [50678, 300, 1936, 2584, 264, 6182, 295, 264, 661, 1189, 296, 13, 50842], "temperature": 0.0, "avg_logprob": -0.2510264714558919, "compression_ratio": 1.7088122605363985, "no_speech_prob": 0.0008294865256175399}, {"id": 1642, "seek": 423392, "start": 4244.64, "end": 4247.4400000000005, "text": " Which yeah, demonstrating some like,", "tokens": [50900, 3013, 1338, 11, 29889, 512, 411, 11, 51040], "temperature": 0.0, "avg_logprob": -0.2510264714558919, "compression_ratio": 1.7088122605363985, "no_speech_prob": 0.0008294865256175399}, {"id": 1643, "seek": 423392, "start": 4247.4400000000005, "end": 4250.16, "text": " that's why markets are extremely hard", "tokens": [51040, 300, 311, 983, 8383, 366, 4664, 1152, 51176], "temperature": 0.0, "avg_logprob": -0.2510264714558919, "compression_ratio": 1.7088122605363985, "no_speech_prob": 0.0008294865256175399}, {"id": 1644, "seek": 423392, "start": 4250.16, "end": 4253.04, "text": " cause like something that works well a lot of the time", "tokens": [51176, 3082, 411, 746, 300, 1985, 731, 257, 688, 295, 264, 565, 51320], "temperature": 0.0, "avg_logprob": -0.2510264714558919, "compression_ratio": 1.7088122605363985, "no_speech_prob": 0.0008294865256175399}, {"id": 1645, "seek": 423392, "start": 4253.04, "end": 4256.8, "text": " it suddenly would just work really oppositely horribly.", "tokens": [51320, 309, 5800, 576, 445, 589, 534, 4665, 1959, 45028, 13, 51508], "temperature": 0.0, "avg_logprob": -0.2510264714558919, "compression_ratio": 1.7088122605363985, "no_speech_prob": 0.0008294865256175399}, {"id": 1646, "seek": 423392, "start": 4256.8, "end": 4259.96, "text": " And so you're often trying to just split this difference", "tokens": [51508, 400, 370, 291, 434, 2049, 1382, 281, 445, 7472, 341, 2649, 51666], "temperature": 0.0, "avg_logprob": -0.2510264714558919, "compression_ratio": 1.7088122605363985, "no_speech_prob": 0.0008294865256175399}, {"id": 1647, "seek": 423392, "start": 4259.96, "end": 4263.2, "text": " to find something that doesn't work super well at one time", "tokens": [51666, 281, 915, 746, 300, 1177, 380, 589, 1687, 731, 412, 472, 565, 51828], "temperature": 0.0, "avg_logprob": -0.2510264714558919, "compression_ratio": 1.7088122605363985, "no_speech_prob": 0.0008294865256175399}, {"id": 1648, "seek": 426320, "start": 4263.2, "end": 4265.599999999999, "text": " and then we'll like crater at another time.", "tokens": [50364, 293, 550, 321, 603, 411, 38981, 412, 1071, 565, 13, 50484], "temperature": 0.0, "avg_logprob": -0.20758672860952523, "compression_ratio": 1.7627118644067796, "no_speech_prob": 0.00017943936109077185}, {"id": 1649, "seek": 426320, "start": 4265.599999999999, "end": 4267.48, "text": " That's the meta model wants to kind of work", "tokens": [50484, 663, 311, 264, 19616, 2316, 2738, 281, 733, 295, 589, 50578], "temperature": 0.0, "avg_logprob": -0.20758672860952523, "compression_ratio": 1.7627118644067796, "no_speech_prob": 0.00017943936109077185}, {"id": 1650, "seek": 426320, "start": 4267.48, "end": 4269.679999999999, "text": " really like pretty good all the time.", "tokens": [50578, 534, 411, 1238, 665, 439, 264, 565, 13, 50688], "temperature": 0.0, "avg_logprob": -0.20758672860952523, "compression_ratio": 1.7627118644067796, "no_speech_prob": 0.00017943936109077185}, {"id": 1651, "seek": 426320, "start": 4270.88, "end": 4272.639999999999, "text": " And that's one of the things that ensembling", "tokens": [50748, 400, 300, 311, 472, 295, 264, 721, 300, 12567, 2504, 1688, 50836], "temperature": 0.0, "avg_logprob": -0.20758672860952523, "compression_ratio": 1.7627118644067796, "no_speech_prob": 0.00017943936109077185}, {"id": 1652, "seek": 426320, "start": 4272.639999999999, "end": 4274.92, "text": " all these models that maybe even the individual models", "tokens": [50836, 439, 613, 5245, 300, 1310, 754, 264, 2609, 5245, 50950], "temperature": 0.0, "avg_logprob": -0.20758672860952523, "compression_ratio": 1.7627118644067796, "no_speech_prob": 0.00017943936109077185}, {"id": 1653, "seek": 426320, "start": 4274.92, "end": 4276.639999999999, "text": " probably have a lot more regime characteristics", "tokens": [50950, 1391, 362, 257, 688, 544, 13120, 10891, 51036], "temperature": 0.0, "avg_logprob": -0.20758672860952523, "compression_ratio": 1.7627118644067796, "no_speech_prob": 0.00017943936109077185}, {"id": 1654, "seek": 426320, "start": 4276.639999999999, "end": 4278.08, "text": " than this overall meta model.", "tokens": [51036, 813, 341, 4787, 19616, 2316, 13, 51108], "temperature": 0.0, "avg_logprob": -0.20758672860952523, "compression_ratio": 1.7627118644067796, "no_speech_prob": 0.00017943936109077185}, {"id": 1655, "seek": 426320, "start": 4279.24, "end": 4281.36, "text": " I wondered whether folks were using", "tokens": [51166, 286, 17055, 1968, 4024, 645, 1228, 51272], "temperature": 0.0, "avg_logprob": -0.20758672860952523, "compression_ratio": 1.7627118644067796, "no_speech_prob": 0.00017943936109077185}, {"id": 1656, "seek": 426320, "start": 4281.36, "end": 4283.32, "text": " some really esoteric approaches.", "tokens": [51272, 512, 534, 785, 21585, 299, 11587, 13, 51370], "temperature": 0.0, "avg_logprob": -0.20758672860952523, "compression_ratio": 1.7627118644067796, "no_speech_prob": 0.00017943936109077185}, {"id": 1657, "seek": 426320, "start": 4283.32, "end": 4285.679999999999, "text": " I mean, I'm interested in geometric deep learning", "tokens": [51370, 286, 914, 11, 286, 478, 3102, 294, 33246, 2452, 2539, 51488], "temperature": 0.0, "avg_logprob": -0.20758672860952523, "compression_ratio": 1.7627118644067796, "no_speech_prob": 0.00017943936109077185}, {"id": 1658, "seek": 426320, "start": 4285.679999999999, "end": 4288.0, "text": " and algorithmic reasoning and, you know,", "tokens": [51488, 293, 9284, 299, 21577, 293, 11, 291, 458, 11, 51604], "temperature": 0.0, "avg_logprob": -0.20758672860952523, "compression_ratio": 1.7627118644067796, "no_speech_prob": 0.00017943936109077185}, {"id": 1659, "seek": 426320, "start": 4288.0, "end": 4292.76, "text": " even think like esoteric options like cellular automata.", "tokens": [51604, 754, 519, 411, 785, 21585, 299, 3956, 411, 29267, 3553, 3274, 13, 51842], "temperature": 0.0, "avg_logprob": -0.20758672860952523, "compression_ratio": 1.7627118644067796, "no_speech_prob": 0.00017943936109077185}, {"id": 1660, "seek": 429320, "start": 4293.599999999999, "end": 4295.5199999999995, "text": " Do you see anything like that getting traction", "tokens": [50384, 1144, 291, 536, 1340, 411, 300, 1242, 23558, 50480], "temperature": 0.0, "avg_logprob": -0.18365306854248048, "compression_ratio": 1.684, "no_speech_prob": 0.0007319394499063492}, {"id": 1661, "seek": 429320, "start": 4295.5199999999995, "end": 4297.679999999999, "text": " or it may be even discrete program synthesis?", "tokens": [50480, 420, 309, 815, 312, 754, 27706, 1461, 30252, 30, 50588], "temperature": 0.0, "avg_logprob": -0.18365306854248048, "compression_ratio": 1.684, "no_speech_prob": 0.0007319394499063492}, {"id": 1662, "seek": 429320, "start": 4299.32, "end": 4301.2, "text": " I don't know.", "tokens": [50670, 286, 500, 380, 458, 13, 50764], "temperature": 0.0, "avg_logprob": -0.18365306854248048, "compression_ratio": 1.684, "no_speech_prob": 0.0007319394499063492}, {"id": 1663, "seek": 429320, "start": 4301.2, "end": 4304.639999999999, "text": " Cause yeah, like I only see what people", "tokens": [50764, 10865, 1338, 11, 411, 286, 787, 536, 437, 561, 50936], "temperature": 0.0, "avg_logprob": -0.18365306854248048, "compression_ratio": 1.684, "no_speech_prob": 0.0007319394499063492}, {"id": 1664, "seek": 429320, "start": 4304.639999999999, "end": 4307.04, "text": " are willing to post and share on forums.", "tokens": [50936, 366, 4950, 281, 2183, 293, 2073, 322, 26998, 13, 51056], "temperature": 0.0, "avg_logprob": -0.18365306854248048, "compression_ratio": 1.684, "no_speech_prob": 0.0007319394499063492}, {"id": 1665, "seek": 429320, "start": 4307.04, "end": 4308.76, "text": " And there's quite a bit of sharing", "tokens": [51056, 400, 456, 311, 1596, 257, 857, 295, 5414, 51142], "temperature": 0.0, "avg_logprob": -0.18365306854248048, "compression_ratio": 1.684, "no_speech_prob": 0.0007319394499063492}, {"id": 1666, "seek": 429320, "start": 4308.76, "end": 4310.76, "text": " on our forums of information,", "tokens": [51142, 322, 527, 26998, 295, 1589, 11, 51242], "temperature": 0.0, "avg_logprob": -0.18365306854248048, "compression_ratio": 1.684, "no_speech_prob": 0.0007319394499063492}, {"id": 1667, "seek": 429320, "start": 4310.76, "end": 4314.16, "text": " but there's definitely some people at the top of leaderboards", "tokens": [51242, 457, 456, 311, 2138, 512, 561, 412, 264, 1192, 295, 5263, 17228, 51412], "temperature": 0.0, "avg_logprob": -0.18365306854248048, "compression_ratio": 1.684, "no_speech_prob": 0.0007319394499063492}, {"id": 1668, "seek": 429320, "start": 4314.16, "end": 4317.04, "text": " who are doing something that's working quite well for them", "tokens": [51412, 567, 366, 884, 746, 300, 311, 1364, 1596, 731, 337, 552, 51556], "temperature": 0.0, "avg_logprob": -0.18365306854248048, "compression_ratio": 1.684, "no_speech_prob": 0.0007319394499063492}, {"id": 1669, "seek": 429320, "start": 4317.04, "end": 4319.599999999999, "text": " for quite a long time that they haven't shared.", "tokens": [51556, 337, 1596, 257, 938, 565, 300, 436, 2378, 380, 5507, 13, 51684], "temperature": 0.0, "avg_logprob": -0.18365306854248048, "compression_ratio": 1.684, "no_speech_prob": 0.0007319394499063492}, {"id": 1670, "seek": 431960, "start": 4320.4400000000005, "end": 4324.200000000001, "text": " And so it's, I'm not even sure what all the people are doing,", "tokens": [50406, 400, 370, 309, 311, 11, 286, 478, 406, 754, 988, 437, 439, 264, 561, 366, 884, 11, 50594], "temperature": 0.0, "avg_logprob": -0.1727159173638971, "compression_ratio": 1.7574468085106383, "no_speech_prob": 0.003592780325561762}, {"id": 1671, "seek": 431960, "start": 4324.200000000001, "end": 4329.200000000001, "text": " but there are, I mean, people allude to using like tricks.", "tokens": [50594, 457, 456, 366, 11, 286, 914, 11, 561, 439, 2303, 281, 1228, 411, 11733, 13, 50844], "temperature": 0.0, "avg_logprob": -0.1727159173638971, "compression_ratio": 1.7574468085106383, "no_speech_prob": 0.003592780325561762}, {"id": 1672, "seek": 431960, "start": 4330.320000000001, "end": 4332.72, "text": " I mean, that they've learned in different jobs.", "tokens": [50900, 286, 914, 11, 300, 436, 600, 3264, 294, 819, 4782, 13, 51020], "temperature": 0.0, "avg_logprob": -0.1727159173638971, "compression_ratio": 1.7574468085106383, "no_speech_prob": 0.003592780325561762}, {"id": 1673, "seek": 431960, "start": 4332.72, "end": 4336.240000000001, "text": " I mean, we have some people with like a variety of backgrounds.", "tokens": [51020, 286, 914, 11, 321, 362, 512, 561, 365, 411, 257, 5673, 295, 17336, 13, 51196], "temperature": 0.0, "avg_logprob": -0.1727159173638971, "compression_ratio": 1.7574468085106383, "no_speech_prob": 0.003592780325561762}, {"id": 1674, "seek": 431960, "start": 4336.240000000001, "end": 4339.160000000001, "text": " It's been really cool to like see this community grow", "tokens": [51196, 467, 311, 668, 534, 1627, 281, 411, 536, 341, 1768, 1852, 51342], "temperature": 0.0, "avg_logprob": -0.1727159173638971, "compression_ratio": 1.7574468085106383, "no_speech_prob": 0.003592780325561762}, {"id": 1675, "seek": 431960, "start": 4339.160000000001, "end": 4341.8, "text": " and have people who are like astrophysicists,", "tokens": [51342, 293, 362, 561, 567, 366, 411, 5357, 11741, 749, 299, 1751, 11, 51474], "temperature": 0.0, "avg_logprob": -0.1727159173638971, "compression_ratio": 1.7574468085106383, "no_speech_prob": 0.003592780325561762}, {"id": 1676, "seek": 431960, "start": 4341.8, "end": 4345.120000000001, "text": " particle physicists, people who are doing like", "tokens": [51474, 12359, 48716, 11, 561, 567, 366, 884, 411, 51640], "temperature": 0.0, "avg_logprob": -0.1727159173638971, "compression_ratio": 1.7574468085106383, "no_speech_prob": 0.003592780325561762}, {"id": 1677, "seek": 431960, "start": 4346.72, "end": 4349.240000000001, "text": " like computer vision and whatever", "tokens": [51720, 411, 3820, 5201, 293, 2035, 51846], "temperature": 0.0, "avg_logprob": -0.1727159173638971, "compression_ratio": 1.7574468085106383, "no_speech_prob": 0.003592780325561762}, {"id": 1678, "seek": 434924, "start": 4349.24, "end": 4351.24, "text": " sort of techniques they've learned in their different fields", "tokens": [50364, 1333, 295, 7512, 436, 600, 3264, 294, 641, 819, 7909, 50464], "temperature": 0.0, "avg_logprob": -0.14424568914598035, "compression_ratio": 1.7259475218658893, "no_speech_prob": 0.0009674335015006363}, {"id": 1679, "seek": 434924, "start": 4351.24, "end": 4353.599999999999, "text": " and try to use them on this problem.", "tokens": [50464, 293, 853, 281, 764, 552, 322, 341, 1154, 13, 50582], "temperature": 0.0, "avg_logprob": -0.14424568914598035, "compression_ratio": 1.7259475218658893, "no_speech_prob": 0.0009674335015006363}, {"id": 1680, "seek": 434924, "start": 4353.599999999999, "end": 4355.28, "text": " That was what sort of attracted me as like,", "tokens": [50582, 663, 390, 437, 1333, 295, 15912, 385, 382, 411, 11, 50666], "temperature": 0.0, "avg_logprob": -0.14424568914598035, "compression_ratio": 1.7259475218658893, "no_speech_prob": 0.0009674335015006363}, {"id": 1681, "seek": 434924, "start": 4355.28, "end": 4357.44, "text": " I was doing like computational neuroscience", "tokens": [50666, 286, 390, 884, 411, 28270, 42762, 50774], "temperature": 0.0, "avg_logprob": -0.14424568914598035, "compression_ratio": 1.7259475218658893, "no_speech_prob": 0.0009674335015006363}, {"id": 1682, "seek": 434924, "start": 4357.44, "end": 4359.679999999999, "text": " and I saw this problem as like,", "tokens": [50774, 293, 286, 1866, 341, 1154, 382, 411, 11, 50886], "temperature": 0.0, "avg_logprob": -0.14424568914598035, "compression_ratio": 1.7259475218658893, "no_speech_prob": 0.0009674335015006363}, {"id": 1683, "seek": 434924, "start": 4359.679999999999, "end": 4361.679999999999, "text": " oh, this is a complete free playground.", "tokens": [50886, 1954, 11, 341, 307, 257, 3566, 1737, 24646, 13, 50986], "temperature": 0.0, "avg_logprob": -0.14424568914598035, "compression_ratio": 1.7259475218658893, "no_speech_prob": 0.0009674335015006363}, {"id": 1684, "seek": 434924, "start": 4361.679999999999, "end": 4363.04, "text": " You can do whatever you want.", "tokens": [50986, 509, 393, 360, 2035, 291, 528, 13, 51054], "temperature": 0.0, "avg_logprob": -0.14424568914598035, "compression_ratio": 1.7259475218658893, "no_speech_prob": 0.0009674335015006363}, {"id": 1685, "seek": 434924, "start": 4363.04, "end": 4365.24, "text": " And so it was a fun opportunity to try out ideas", "tokens": [51054, 400, 370, 309, 390, 257, 1019, 2650, 281, 853, 484, 3487, 51164], "temperature": 0.0, "avg_logprob": -0.14424568914598035, "compression_ratio": 1.7259475218658893, "no_speech_prob": 0.0009674335015006363}, {"id": 1686, "seek": 434924, "start": 4365.24, "end": 4368.639999999999, "text": " that wouldn't really work well in computational neuroscience.", "tokens": [51164, 300, 2759, 380, 534, 589, 731, 294, 28270, 42762, 13, 51334], "temperature": 0.0, "avg_logprob": -0.14424568914598035, "compression_ratio": 1.7259475218658893, "no_speech_prob": 0.0009674335015006363}, {"id": 1687, "seek": 434924, "start": 4368.639999999999, "end": 4369.48, "text": " Yeah, indeed.", "tokens": [51334, 865, 11, 6451, 13, 51376], "temperature": 0.0, "avg_logprob": -0.14424568914598035, "compression_ratio": 1.7259475218658893, "no_speech_prob": 0.0009674335015006363}, {"id": 1688, "seek": 434924, "start": 4369.48, "end": 4373.16, "text": " And physics, I mean, the road to reality by Roger Penrose,", "tokens": [51376, 400, 10649, 11, 286, 914, 11, 264, 3060, 281, 4103, 538, 17666, 10571, 37841, 11, 51560], "temperature": 0.0, "avg_logprob": -0.14424568914598035, "compression_ratio": 1.7259475218658893, "no_speech_prob": 0.0009674335015006363}, {"id": 1689, "seek": 434924, "start": 4373.16, "end": 4374.84, "text": " I think it was Michael Bronstein who said", "tokens": [51560, 286, 519, 309, 390, 5116, 19544, 9089, 567, 848, 51644], "temperature": 0.0, "avg_logprob": -0.14424568914598035, "compression_ratio": 1.7259475218658893, "no_speech_prob": 0.0009674335015006363}, {"id": 1690, "seek": 434924, "start": 4374.84, "end": 4376.88, "text": " that if you could summarize the entire book in one word,", "tokens": [51644, 300, 498, 291, 727, 20858, 264, 2302, 1446, 294, 472, 1349, 11, 51746], "temperature": 0.0, "avg_logprob": -0.14424568914598035, "compression_ratio": 1.7259475218658893, "no_speech_prob": 0.0009674335015006363}, {"id": 1691, "seek": 434924, "start": 4376.88, "end": 4378.4, "text": " it would be symmetry.", "tokens": [51746, 309, 576, 312, 25440, 13, 51822], "temperature": 0.0, "avg_logprob": -0.14424568914598035, "compression_ratio": 1.7259475218658893, "no_speech_prob": 0.0009674335015006363}, {"id": 1692, "seek": 437840, "start": 4378.44, "end": 4381.679999999999, "text": " And there's also another key idea from a lot of researchers,", "tokens": [50366, 400, 456, 311, 611, 1071, 2141, 1558, 490, 257, 688, 295, 10309, 11, 50528], "temperature": 0.0, "avg_logprob": -0.17189176459061473, "compression_ratio": 1.7977941176470589, "no_speech_prob": 6.697462231386453e-05}, {"id": 1693, "seek": 437840, "start": 4381.679999999999, "end": 4383.5199999999995, "text": " which is abstraction, you know,", "tokens": [50528, 597, 307, 37765, 11, 291, 458, 11, 50620], "temperature": 0.0, "avg_logprob": -0.17189176459061473, "compression_ratio": 1.7977941176470589, "no_speech_prob": 6.697462231386453e-05}, {"id": 1694, "seek": 437840, "start": 4383.5199999999995, "end": 4385.599999999999, "text": " which is like some meta property", "tokens": [50620, 597, 307, 411, 512, 19616, 4707, 50724], "temperature": 0.0, "avg_logprob": -0.17189176459061473, "compression_ratio": 1.7977941176470589, "no_speech_prob": 6.697462231386453e-05}, {"id": 1695, "seek": 437840, "start": 4385.599999999999, "end": 4387.28, "text": " of the relationship between data.", "tokens": [50724, 295, 264, 2480, 1296, 1412, 13, 50808], "temperature": 0.0, "avg_logprob": -0.17189176459061473, "compression_ratio": 1.7977941176470589, "no_speech_prob": 6.697462231386453e-05}, {"id": 1696, "seek": 437840, "start": 4387.28, "end": 4389.08, "text": " So, you know, you probably have lots of folks", "tokens": [50808, 407, 11, 291, 458, 11, 291, 1391, 362, 3195, 295, 4024, 50898], "temperature": 0.0, "avg_logprob": -0.17189176459061473, "compression_ratio": 1.7977941176470589, "no_speech_prob": 6.697462231386453e-05}, {"id": 1697, "seek": 437840, "start": 4389.08, "end": 4390.24, "text": " coming in from different fields", "tokens": [50898, 1348, 294, 490, 819, 7909, 50956], "temperature": 0.0, "avg_logprob": -0.17189176459061473, "compression_ratio": 1.7977941176470589, "no_speech_prob": 6.697462231386453e-05}, {"id": 1698, "seek": 437840, "start": 4390.24, "end": 4392.36, "text": " and they have some very, very interesting approaches", "tokens": [50956, 293, 436, 362, 512, 588, 11, 588, 1880, 11587, 51062], "temperature": 0.0, "avg_logprob": -0.17189176459061473, "compression_ratio": 1.7977941176470589, "no_speech_prob": 6.697462231386453e-05}, {"id": 1699, "seek": 437840, "start": 4392.36, "end": 4393.5599999999995, "text": " to solving this problem.", "tokens": [51062, 281, 12606, 341, 1154, 13, 51122], "temperature": 0.0, "avg_logprob": -0.17189176459061473, "compression_ratio": 1.7977941176470589, "no_speech_prob": 6.697462231386453e-05}, {"id": 1700, "seek": 437840, "start": 4394.599999999999, "end": 4395.599999999999, "text": " Yeah, for sure.", "tokens": [51174, 865, 11, 337, 988, 13, 51224], "temperature": 0.0, "avg_logprob": -0.17189176459061473, "compression_ratio": 1.7977941176470589, "no_speech_prob": 6.697462231386453e-05}, {"id": 1701, "seek": 437840, "start": 4396.44, "end": 4398.599999999999, "text": " Yeah, I mean, I have, I mean, there's people", "tokens": [51266, 865, 11, 286, 914, 11, 286, 362, 11, 286, 914, 11, 456, 311, 561, 51374], "temperature": 0.0, "avg_logprob": -0.17189176459061473, "compression_ratio": 1.7977941176470589, "no_speech_prob": 6.697462231386453e-05}, {"id": 1702, "seek": 437840, "start": 4398.599999999999, "end": 4400.96, "text": " who use some like interesting like auto encoders", "tokens": [51374, 567, 764, 512, 411, 1880, 411, 8399, 2058, 378, 433, 51492], "temperature": 0.0, "avg_logprob": -0.17189176459061473, "compression_ratio": 1.7977941176470589, "no_speech_prob": 6.697462231386453e-05}, {"id": 1703, "seek": 437840, "start": 4400.96, "end": 4402.92, "text": " to try to learn structure from data", "tokens": [51492, 281, 853, 281, 1466, 3877, 490, 1412, 51590], "temperature": 0.0, "avg_logprob": -0.17189176459061473, "compression_ratio": 1.7977941176470589, "no_speech_prob": 6.697462231386453e-05}, {"id": 1704, "seek": 437840, "start": 4402.92, "end": 4404.32, "text": " as a way to learn features.", "tokens": [51590, 382, 257, 636, 281, 1466, 4122, 13, 51660], "temperature": 0.0, "avg_logprob": -0.17189176459061473, "compression_ratio": 1.7977941176470589, "no_speech_prob": 6.697462231386453e-05}, {"id": 1705, "seek": 440432, "start": 4405.32, "end": 4408.28, "text": " People using, it's interesting non-linear", "tokens": [50414, 3432, 1228, 11, 309, 311, 1880, 2107, 12, 28263, 50562], "temperature": 0.0, "avg_logprob": -0.26452496846516926, "compression_ratio": 1.6600985221674878, "no_speech_prob": 0.0018381067784503102}, {"id": 1706, "seek": 440432, "start": 4408.28, "end": 4410.12, "text": " dimensionality reduction techniques", "tokens": [50562, 10139, 1860, 11004, 7512, 50654], "temperature": 0.0, "avg_logprob": -0.26452496846516926, "compression_ratio": 1.6600985221674878, "no_speech_prob": 0.0018381067784503102}, {"id": 1707, "seek": 440432, "start": 4410.12, "end": 4414.36, "text": " to try to, yeah, to try to find various features.", "tokens": [50654, 281, 853, 281, 11, 1338, 11, 281, 853, 281, 915, 3683, 4122, 13, 50866], "temperature": 0.0, "avg_logprob": -0.26452496846516926, "compression_ratio": 1.6600985221674878, "no_speech_prob": 0.0018381067784503102}, {"id": 1708, "seek": 440432, "start": 4416.44, "end": 4419.679999999999, "text": " It's, and yeah, even some,", "tokens": [50970, 467, 311, 11, 293, 1338, 11, 754, 512, 11, 51132], "temperature": 0.0, "avg_logprob": -0.26452496846516926, "compression_ratio": 1.6600985221674878, "no_speech_prob": 0.0018381067784503102}, {"id": 1709, "seek": 440432, "start": 4419.679999999999, "end": 4422.32, "text": " some things people do do some sort of interesting", "tokens": [51132, 512, 721, 561, 360, 360, 512, 1333, 295, 1880, 51264], "temperature": 0.0, "avg_logprob": -0.26452496846516926, "compression_ratio": 1.6600985221674878, "no_speech_prob": 0.0018381067784503102}, {"id": 1710, "seek": 440432, "start": 4422.32, "end": 4425.719999999999, "text": " feature selection or denoising types of things", "tokens": [51264, 4111, 9450, 420, 1441, 78, 3436, 3467, 295, 721, 51434], "temperature": 0.0, "avg_logprob": -0.26452496846516926, "compression_ratio": 1.6600985221674878, "no_speech_prob": 0.0018381067784503102}, {"id": 1711, "seek": 440432, "start": 4425.719999999999, "end": 4427.5199999999995, "text": " that they've learned in their fields.", "tokens": [51434, 300, 436, 600, 3264, 294, 641, 7909, 13, 51524], "temperature": 0.0, "avg_logprob": -0.26452496846516926, "compression_ratio": 1.6600985221674878, "no_speech_prob": 0.0018381067784503102}, {"id": 1712, "seek": 440432, "start": 4428.92, "end": 4432.12, "text": " Yeah, it's always interesting to me to see like", "tokens": [51594, 865, 11, 309, 311, 1009, 1880, 281, 385, 281, 536, 411, 51754], "temperature": 0.0, "avg_logprob": -0.26452496846516926, "compression_ratio": 1.6600985221674878, "no_speech_prob": 0.0018381067784503102}, {"id": 1713, "seek": 443212, "start": 4432.16, "end": 4435.32, "text": " how different fields that use machine learning", "tokens": [50366, 577, 819, 7909, 300, 764, 3479, 2539, 50524], "temperature": 0.0, "avg_logprob": -0.12823085334357315, "compression_ratio": 1.7748344370860927, "no_speech_prob": 0.0010979913640767336}, {"id": 1714, "seek": 443212, "start": 4435.32, "end": 4436.64, "text": " use it in different ways", "tokens": [50524, 764, 309, 294, 819, 2098, 50590], "temperature": 0.0, "avg_logprob": -0.12823085334357315, "compression_ratio": 1.7748344370860927, "no_speech_prob": 0.0010979913640767336}, {"id": 1715, "seek": 443212, "start": 4436.64, "end": 4440.48, "text": " and what sort of tricks and tips might cross over.", "tokens": [50590, 293, 437, 1333, 295, 11733, 293, 6082, 1062, 3278, 670, 13, 50782], "temperature": 0.0, "avg_logprob": -0.12823085334357315, "compression_ratio": 1.7748344370860927, "no_speech_prob": 0.0010979913640767336}, {"id": 1716, "seek": 443212, "start": 4440.48, "end": 4441.32, "text": " I was going to ask about that", "tokens": [50782, 286, 390, 516, 281, 1029, 466, 300, 50824], "temperature": 0.0, "avg_logprob": -0.12823085334357315, "compression_ratio": 1.7748344370860927, "no_speech_prob": 0.0010979913640767336}, {"id": 1717, "seek": 443212, "start": 4441.32, "end": 4444.12, "text": " because you have loads and loads of features", "tokens": [50824, 570, 291, 362, 12668, 293, 12668, 295, 4122, 50964], "temperature": 0.0, "avg_logprob": -0.12823085334357315, "compression_ratio": 1.7748344370860927, "no_speech_prob": 0.0010979913640767336}, {"id": 1718, "seek": 443212, "start": 4444.12, "end": 4447.599999999999, "text": " and there's this problem called the curse of dimensionality.", "tokens": [50964, 293, 456, 311, 341, 1154, 1219, 264, 17139, 295, 10139, 1860, 13, 51138], "temperature": 0.0, "avg_logprob": -0.12823085334357315, "compression_ratio": 1.7748344370860927, "no_speech_prob": 0.0010979913640767336}, {"id": 1719, "seek": 443212, "start": 4447.599999999999, "end": 4452.04, "text": " Right, so, you know, when the number of dimensions increases", "tokens": [51138, 1779, 11, 370, 11, 291, 458, 11, 562, 264, 1230, 295, 12819, 8637, 51360], "temperature": 0.0, "avg_logprob": -0.12823085334357315, "compression_ratio": 1.7748344370860927, "no_speech_prob": 0.0010979913640767336}, {"id": 1720, "seek": 443212, "start": 4452.04, "end": 4454.12, "text": " the volume of the space increases exponentially,", "tokens": [51360, 264, 5523, 295, 264, 1901, 8637, 37330, 11, 51464], "temperature": 0.0, "avg_logprob": -0.12823085334357315, "compression_ratio": 1.7748344370860927, "no_speech_prob": 0.0010979913640767336}, {"id": 1721, "seek": 443212, "start": 4454.12, "end": 4457.0, "text": " which means like this concept of nearness basically disappears", "tokens": [51464, 597, 1355, 411, 341, 3410, 295, 408, 16937, 1936, 25527, 51608], "temperature": 0.0, "avg_logprob": -0.12823085334357315, "compression_ratio": 1.7748344370860927, "no_speech_prob": 0.0010979913640767336}, {"id": 1722, "seek": 443212, "start": 4457.0, "end": 4458.8, "text": " and there's statistical models don't work anymore.", "tokens": [51608, 293, 456, 311, 22820, 5245, 500, 380, 589, 3602, 13, 51698], "temperature": 0.0, "avg_logprob": -0.12823085334357315, "compression_ratio": 1.7748344370860927, "no_speech_prob": 0.0010979913640767336}, {"id": 1723, "seek": 443212, "start": 4458.8, "end": 4461.8, "text": " So, you know, presumably people would do things like,", "tokens": [51698, 407, 11, 291, 458, 11, 26742, 561, 576, 360, 721, 411, 11, 51848], "temperature": 0.0, "avg_logprob": -0.12823085334357315, "compression_ratio": 1.7748344370860927, "no_speech_prob": 0.0010979913640767336}, {"id": 1724, "seek": 446180, "start": 4461.8, "end": 4464.64, "text": " I don't know, dimensionality reduction feature selection.", "tokens": [50364, 286, 500, 380, 458, 11, 10139, 1860, 11004, 4111, 9450, 13, 50506], "temperature": 0.0, "avg_logprob": -0.15868525899899233, "compression_ratio": 1.7969230769230768, "no_speech_prob": 0.0003143850190099329}, {"id": 1725, "seek": 446180, "start": 4464.64, "end": 4466.16, "text": " I mean, neural networks are quite clever", "tokens": [50506, 286, 914, 11, 18161, 9590, 366, 1596, 13494, 50582], "temperature": 0.0, "avg_logprob": -0.15868525899899233, "compression_ratio": 1.7969230769230768, "no_speech_prob": 0.0003143850190099329}, {"id": 1726, "seek": 446180, "start": 4466.16, "end": 4469.320000000001, "text": " in the sense that they, via a variety of methods,", "tokens": [50582, 294, 264, 2020, 300, 436, 11, 5766, 257, 5673, 295, 7150, 11, 50740], "temperature": 0.0, "avg_logprob": -0.15868525899899233, "compression_ratio": 1.7969230769230768, "no_speech_prob": 0.0003143850190099329}, {"id": 1727, "seek": 446180, "start": 4469.320000000001, "end": 4470.84, "text": " overcome the curse of dimensionality", "tokens": [50740, 10473, 264, 17139, 295, 10139, 1860, 50816], "temperature": 0.0, "avg_logprob": -0.15868525899899233, "compression_ratio": 1.7969230769230768, "no_speech_prob": 0.0003143850190099329}, {"id": 1728, "seek": 446180, "start": 4470.84, "end": 4472.88, "text": " by learning some data manifold or whatever.", "tokens": [50816, 538, 2539, 512, 1412, 47138, 420, 2035, 13, 50918], "temperature": 0.0, "avg_logprob": -0.15868525899899233, "compression_ratio": 1.7969230769230768, "no_speech_prob": 0.0003143850190099329}, {"id": 1729, "seek": 446180, "start": 4472.88, "end": 4475.04, "text": " But, you know, it's with natural data,", "tokens": [50918, 583, 11, 291, 458, 11, 309, 311, 365, 3303, 1412, 11, 51026], "temperature": 0.0, "avg_logprob": -0.15868525899899233, "compression_ratio": 1.7969230769230768, "no_speech_prob": 0.0003143850190099329}, {"id": 1730, "seek": 446180, "start": 4475.04, "end": 4477.96, "text": " it's not with financial data, so it's not a given.", "tokens": [51026, 309, 311, 406, 365, 4669, 1412, 11, 370, 309, 311, 406, 257, 2212, 13, 51172], "temperature": 0.0, "avg_logprob": -0.15868525899899233, "compression_ratio": 1.7969230769230768, "no_speech_prob": 0.0003143850190099329}, {"id": 1731, "seek": 446180, "start": 4477.96, "end": 4480.320000000001, "text": " It's, yeah, and this is actually one of the things", "tokens": [51172, 467, 311, 11, 1338, 11, 293, 341, 307, 767, 472, 295, 264, 721, 51290], "temperature": 0.0, "avg_logprob": -0.15868525899899233, "compression_ratio": 1.7969230769230768, "no_speech_prob": 0.0003143850190099329}, {"id": 1732, "seek": 446180, "start": 4480.320000000001, "end": 4482.8, "text": " that was really intriguing to me", "tokens": [51290, 300, 390, 534, 32503, 281, 385, 51414], "temperature": 0.0, "avg_logprob": -0.15868525899899233, "compression_ratio": 1.7969230769230768, "no_speech_prob": 0.0003143850190099329}, {"id": 1733, "seek": 446180, "start": 4482.8, "end": 4484.400000000001, "text": " when I started in finance is,", "tokens": [51414, 562, 286, 1409, 294, 10719, 307, 11, 51494], "temperature": 0.0, "avg_logprob": -0.15868525899899233, "compression_ratio": 1.7969230769230768, "no_speech_prob": 0.0003143850190099329}, {"id": 1734, "seek": 446180, "start": 4484.400000000001, "end": 4486.84, "text": " so in science, when you're doing regressions", "tokens": [51494, 370, 294, 3497, 11, 562, 291, 434, 884, 1121, 735, 626, 51616], "temperature": 0.0, "avg_logprob": -0.15868525899899233, "compression_ratio": 1.7969230769230768, "no_speech_prob": 0.0003143850190099329}, {"id": 1735, "seek": 446180, "start": 4486.84, "end": 4488.72, "text": " you're trying to find often sparse solutions.", "tokens": [51616, 291, 434, 1382, 281, 915, 2049, 637, 11668, 6547, 13, 51710], "temperature": 0.0, "avg_logprob": -0.15868525899899233, "compression_ratio": 1.7969230769230768, "no_speech_prob": 0.0003143850190099329}, {"id": 1736, "seek": 446180, "start": 4488.72, "end": 4491.400000000001, "text": " You're trying to find the sort of small number of variables", "tokens": [51710, 509, 434, 1382, 281, 915, 264, 1333, 295, 1359, 1230, 295, 9102, 51844], "temperature": 0.0, "avg_logprob": -0.15868525899899233, "compression_ratio": 1.7969230769230768, "no_speech_prob": 0.0003143850190099329}, {"id": 1737, "seek": 449140, "start": 4491.4, "end": 4492.44, "text": " to predict your targets,", "tokens": [50364, 281, 6069, 428, 12911, 11, 50416], "temperature": 0.0, "avg_logprob": -0.21623356640338898, "compression_ratio": 1.8834586466165413, "no_speech_prob": 0.004068146925419569}, {"id": 1738, "seek": 449140, "start": 4492.44, "end": 4493.96, "text": " to try to find whatever sort of maybe", "tokens": [50416, 281, 853, 281, 915, 2035, 1333, 295, 1310, 50492], "temperature": 0.0, "avg_logprob": -0.21623356640338898, "compression_ratio": 1.8834586466165413, "no_speech_prob": 0.004068146925419569}, {"id": 1739, "seek": 449140, "start": 4493.96, "end": 4495.599999999999, "text": " causal relationships there are.", "tokens": [50492, 38755, 6159, 456, 366, 13, 50574], "temperature": 0.0, "avg_logprob": -0.21623356640338898, "compression_ratio": 1.8834586466165413, "no_speech_prob": 0.004068146925419569}, {"id": 1740, "seek": 449140, "start": 4496.679999999999, "end": 4501.4, "text": " In finance, we often try to do exactly the opposite,", "tokens": [50628, 682, 10719, 11, 321, 2049, 853, 281, 360, 2293, 264, 6182, 11, 50864], "temperature": 0.0, "avg_logprob": -0.21623356640338898, "compression_ratio": 1.8834586466165413, "no_speech_prob": 0.004068146925419569}, {"id": 1741, "seek": 449140, "start": 4501.4, "end": 4504.32, "text": " where we want our models to care about all the features", "tokens": [50864, 689, 321, 528, 527, 5245, 281, 1127, 466, 439, 264, 4122, 51010], "temperature": 0.0, "avg_logprob": -0.21623356640338898, "compression_ratio": 1.8834586466165413, "no_speech_prob": 0.004068146925419569}, {"id": 1742, "seek": 449140, "start": 4504.32, "end": 4505.719999999999, "text": " a little bit.", "tokens": [51010, 257, 707, 857, 13, 51080], "temperature": 0.0, "avg_logprob": -0.21623356640338898, "compression_ratio": 1.8834586466165413, "no_speech_prob": 0.004068146925419569}, {"id": 1743, "seek": 449140, "start": 4505.719999999999, "end": 4509.5199999999995, "text": " And so, we do, we'll do something like what we call", "tokens": [51080, 400, 370, 11, 321, 360, 11, 321, 603, 360, 746, 411, 437, 321, 818, 51270], "temperature": 0.0, "avg_logprob": -0.21623356640338898, "compression_ratio": 1.8834586466165413, "no_speech_prob": 0.004068146925419569}, {"id": 1744, "seek": 449140, "start": 4509.5199999999995, "end": 4510.879999999999, "text": " a feature neutralization,", "tokens": [51270, 257, 4111, 10598, 2144, 11, 51338], "temperature": 0.0, "avg_logprob": -0.21623356640338898, "compression_ratio": 1.8834586466165413, "no_speech_prob": 0.004068146925419569}, {"id": 1745, "seek": 449140, "start": 4510.879999999999, "end": 4512.5599999999995, "text": " where basically you take your prediction,", "tokens": [51338, 689, 1936, 291, 747, 428, 17630, 11, 51422], "temperature": 0.0, "avg_logprob": -0.21623356640338898, "compression_ratio": 1.8834586466165413, "no_speech_prob": 0.004068146925419569}, {"id": 1746, "seek": 449140, "start": 4512.5599999999995, "end": 4514.28, "text": " take the linear model of your prediction", "tokens": [51422, 747, 264, 8213, 2316, 295, 428, 17630, 51508], "temperature": 0.0, "avg_logprob": -0.21623356640338898, "compression_ratio": 1.8834586466165413, "no_speech_prob": 0.004068146925419569}, {"id": 1747, "seek": 449140, "start": 4514.28, "end": 4516.08, "text": " from the features and subtract it off.", "tokens": [51508, 490, 264, 4122, 293, 16390, 309, 766, 13, 51598], "temperature": 0.0, "avg_logprob": -0.21623356640338898, "compression_ratio": 1.8834586466165413, "no_speech_prob": 0.004068146925419569}, {"id": 1748, "seek": 449140, "start": 4516.08, "end": 4517.5199999999995, "text": " And so, you're making your prediction", "tokens": [51598, 400, 370, 11, 291, 434, 1455, 428, 17630, 51670], "temperature": 0.0, "avg_logprob": -0.21623356640338898, "compression_ratio": 1.8834586466165413, "no_speech_prob": 0.004068146925419569}, {"id": 1749, "seek": 449140, "start": 4517.5199999999995, "end": 4520.12, "text": " not linearly correlated or linearly dependent", "tokens": [51670, 406, 43586, 38574, 420, 43586, 12334, 51800], "temperature": 0.0, "avg_logprob": -0.21623356640338898, "compression_ratio": 1.8834586466165413, "no_speech_prob": 0.004068146925419569}, {"id": 1750, "seek": 452012, "start": 4520.12, "end": 4521.72, "text": " on any of your features.", "tokens": [50364, 322, 604, 295, 428, 4122, 13, 50444], "temperature": 0.0, "avg_logprob": -0.20504512506372788, "compression_ratio": 1.738831615120275, "no_speech_prob": 0.0027145599015057087}, {"id": 1751, "seek": 452012, "start": 4521.72, "end": 4522.92, "text": " We're doing some fraction of that.", "tokens": [50444, 492, 434, 884, 512, 14135, 295, 300, 13, 50504], "temperature": 0.0, "avg_logprob": -0.20504512506372788, "compression_ratio": 1.738831615120275, "no_speech_prob": 0.0027145599015057087}, {"id": 1752, "seek": 452012, "start": 4522.92, "end": 4526.12, "text": " So, just trying to remove too strong of a linear relationship", "tokens": [50504, 407, 11, 445, 1382, 281, 4159, 886, 2068, 295, 257, 8213, 2480, 50664], "temperature": 0.0, "avg_logprob": -0.20504512506372788, "compression_ratio": 1.738831615120275, "no_speech_prob": 0.0027145599015057087}, {"id": 1753, "seek": 452012, "start": 4526.12, "end": 4528.0, "text": " between a feature and your prediction.", "tokens": [50664, 1296, 257, 4111, 293, 428, 17630, 13, 50758], "temperature": 0.0, "avg_logprob": -0.20504512506372788, "compression_ratio": 1.738831615120275, "no_speech_prob": 0.0027145599015057087}, {"id": 1754, "seek": 452012, "start": 4529.08, "end": 4531.16, "text": " And you do other regularization techniques", "tokens": [50812, 400, 291, 360, 661, 3890, 2144, 7512, 50916], "temperature": 0.0, "avg_logprob": -0.20504512506372788, "compression_ratio": 1.738831615120275, "no_speech_prob": 0.0027145599015057087}, {"id": 1755, "seek": 452012, "start": 4531.16, "end": 4533.16, "text": " like in your tree learning,", "tokens": [50916, 411, 294, 428, 4230, 2539, 11, 51016], "temperature": 0.0, "avg_logprob": -0.20504512506372788, "compression_ratio": 1.738831615120275, "no_speech_prob": 0.0027145599015057087}, {"id": 1756, "seek": 452012, "start": 4533.16, "end": 4535.68, "text": " maybe one thing that works quite well", "tokens": [51016, 1310, 472, 551, 300, 1985, 1596, 731, 51142], "temperature": 0.0, "avg_logprob": -0.20504512506372788, "compression_ratio": 1.738831615120275, "no_speech_prob": 0.0027145599015057087}, {"id": 1757, "seek": 452012, "start": 4535.68, "end": 4537.64, "text": " is using like column sample by tree,", "tokens": [51142, 307, 1228, 411, 7738, 6889, 538, 4230, 11, 51240], "temperature": 0.0, "avg_logprob": -0.20504512506372788, "compression_ratio": 1.738831615120275, "no_speech_prob": 0.0027145599015057087}, {"id": 1758, "seek": 452012, "start": 4537.64, "end": 4539.0, "text": " instead of to very low value.", "tokens": [51240, 2602, 295, 281, 588, 2295, 2158, 13, 51308], "temperature": 0.0, "avg_logprob": -0.20504512506372788, "compression_ratio": 1.738831615120275, "no_speech_prob": 0.0027145599015057087}, {"id": 1759, "seek": 452012, "start": 4539.0, "end": 4540.4, "text": " So, each tree is only considering", "tokens": [51308, 407, 11, 1184, 4230, 307, 787, 8079, 51378], "temperature": 0.0, "avg_logprob": -0.20504512506372788, "compression_ratio": 1.738831615120275, "no_speech_prob": 0.0027145599015057087}, {"id": 1760, "seek": 452012, "start": 4540.4, "end": 4542.0, "text": " a small subset of features.", "tokens": [51378, 257, 1359, 25993, 295, 4122, 13, 51458], "temperature": 0.0, "avg_logprob": -0.20504512506372788, "compression_ratio": 1.738831615120275, "no_speech_prob": 0.0027145599015057087}, {"id": 1761, "seek": 452012, "start": 4542.0, "end": 4544.12, "text": " And so, your ensemble is sort of,", "tokens": [51458, 400, 370, 11, 428, 19492, 307, 1333, 295, 11, 51564], "temperature": 0.0, "avg_logprob": -0.20504512506372788, "compression_ratio": 1.738831615120275, "no_speech_prob": 0.0027145599015057087}, {"id": 1762, "seek": 452012, "start": 4544.12, "end": 4546.88, "text": " you use as a lot of the different features", "tokens": [51564, 291, 764, 382, 257, 688, 295, 264, 819, 4122, 51702], "temperature": 0.0, "avg_logprob": -0.20504512506372788, "compression_ratio": 1.738831615120275, "no_speech_prob": 0.0027145599015057087}, {"id": 1763, "seek": 452012, "start": 4546.88, "end": 4548.2, "text": " because it's sort of each tree", "tokens": [51702, 570, 309, 311, 1333, 295, 1184, 4230, 51768], "temperature": 0.0, "avg_logprob": -0.20504512506372788, "compression_ratio": 1.738831615120275, "no_speech_prob": 0.0027145599015057087}, {"id": 1764, "seek": 454820, "start": 4548.2, "end": 4550.2, "text": " only has access to 10% of the features", "tokens": [50364, 787, 575, 2105, 281, 1266, 4, 295, 264, 4122, 50464], "temperature": 0.0, "avg_logprob": -0.16803106665611267, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0019264309667050838}, {"id": 1765, "seek": 454820, "start": 4551.28, "end": 4552.5599999999995, "text": " across your whole ensemble.", "tokens": [50518, 2108, 428, 1379, 19492, 13, 50582], "temperature": 0.0, "avg_logprob": -0.16803106665611267, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0019264309667050838}, {"id": 1766, "seek": 454820, "start": 4552.5599999999995, "end": 4555.8, "text": " You are probably using a lot of your features a little bit.", "tokens": [50582, 509, 366, 1391, 1228, 257, 688, 295, 428, 4122, 257, 707, 857, 13, 50744], "temperature": 0.0, "avg_logprob": -0.16803106665611267, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0019264309667050838}, {"id": 1767, "seek": 454820, "start": 4555.8, "end": 4558.12, "text": " And that tends to work quite well.", "tokens": [50744, 400, 300, 12258, 281, 589, 1596, 731, 13, 50860], "temperature": 0.0, "avg_logprob": -0.16803106665611267, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0019264309667050838}, {"id": 1768, "seek": 454820, "start": 4558.12, "end": 4559.84, "text": " And the reason is,", "tokens": [50860, 400, 264, 1778, 307, 11, 50946], "temperature": 0.0, "avg_logprob": -0.16803106665611267, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0019264309667050838}, {"id": 1769, "seek": 454820, "start": 4559.84, "end": 4561.44, "text": " it's because features will work for a while", "tokens": [50946, 309, 311, 570, 4122, 486, 589, 337, 257, 1339, 51026], "temperature": 0.0, "avg_logprob": -0.16803106665611267, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0019264309667050838}, {"id": 1770, "seek": 454820, "start": 4561.44, "end": 4563.12, "text": " and then they'll just turn around on you.", "tokens": [51026, 293, 550, 436, 603, 445, 1261, 926, 322, 291, 13, 51110], "temperature": 0.0, "avg_logprob": -0.16803106665611267, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0019264309667050838}, {"id": 1771, "seek": 454820, "start": 4563.12, "end": 4564.92, "text": " And so, you don't want to be sort of", "tokens": [51110, 400, 370, 11, 291, 500, 380, 528, 281, 312, 1333, 295, 51200], "temperature": 0.0, "avg_logprob": -0.16803106665611267, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0019264309667050838}, {"id": 1772, "seek": 454820, "start": 4564.92, "end": 4567.36, "text": " super dependent on any one feature.", "tokens": [51200, 1687, 12334, 322, 604, 472, 4111, 13, 51322], "temperature": 0.0, "avg_logprob": -0.16803106665611267, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0019264309667050838}, {"id": 1773, "seek": 454820, "start": 4568.92, "end": 4571.84, "text": " And so, yeah, it does make the cursor dimensionality", "tokens": [51400, 400, 370, 11, 1338, 11, 309, 775, 652, 264, 28169, 10139, 1860, 51546], "temperature": 0.0, "avg_logprob": -0.16803106665611267, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0019264309667050838}, {"id": 1774, "seek": 454820, "start": 4571.84, "end": 4573.44, "text": " kind of worse in some ways", "tokens": [51546, 733, 295, 5324, 294, 512, 2098, 51626], "temperature": 0.0, "avg_logprob": -0.16803106665611267, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0019264309667050838}, {"id": 1775, "seek": 454820, "start": 4573.44, "end": 4577.44, "text": " because you don't wanna necessarily find", "tokens": [51626, 570, 291, 500, 380, 1948, 4725, 915, 51826], "temperature": 0.0, "avg_logprob": -0.16803106665611267, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0019264309667050838}, {"id": 1776, "seek": 457744, "start": 4577.48, "end": 4579.4, "text": " just a small subset of variables", "tokens": [50366, 445, 257, 1359, 25993, 295, 9102, 50462], "temperature": 0.0, "avg_logprob": -0.1685939691005609, "compression_ratio": 1.6997084548104957, "no_speech_prob": 0.0008033423218876123}, {"id": 1777, "seek": 457744, "start": 4579.4, "end": 4581.96, "text": " that are the best", "tokens": [50462, 300, 366, 264, 1151, 50590], "temperature": 0.0, "avg_logprob": -0.1685939691005609, "compression_ratio": 1.6997084548104957, "no_speech_prob": 0.0008033423218876123}, {"id": 1778, "seek": 457744, "start": 4581.96, "end": 4584.16, "text": " because sometimes that will maybe give you", "tokens": [50590, 570, 2171, 300, 486, 1310, 976, 291, 50700], "temperature": 0.0, "avg_logprob": -0.1685939691005609, "compression_ratio": 1.6997084548104957, "no_speech_prob": 0.0008033423218876123}, {"id": 1779, "seek": 457744, "start": 4584.16, "end": 4585.679999999999, "text": " a really good model for a while,", "tokens": [50700, 257, 534, 665, 2316, 337, 257, 1339, 11, 50776], "temperature": 0.0, "avg_logprob": -0.1685939691005609, "compression_ratio": 1.6997084548104957, "no_speech_prob": 0.0008033423218876123}, {"id": 1780, "seek": 457744, "start": 4585.679999999999, "end": 4586.96, "text": " but sometimes all of a sudden,", "tokens": [50776, 457, 2171, 439, 295, 257, 3990, 11, 50840], "temperature": 0.0, "avg_logprob": -0.1685939691005609, "compression_ratio": 1.6997084548104957, "no_speech_prob": 0.0008033423218876123}, {"id": 1781, "seek": 457744, "start": 4586.96, "end": 4588.12, "text": " those will just turn around on you.", "tokens": [50840, 729, 486, 445, 1261, 926, 322, 291, 13, 50898], "temperature": 0.0, "avg_logprob": -0.1685939691005609, "compression_ratio": 1.6997084548104957, "no_speech_prob": 0.0008033423218876123}, {"id": 1782, "seek": 457744, "start": 4588.12, "end": 4590.96, "text": " And then your model just like is almost anti-correlated", "tokens": [50898, 400, 550, 428, 2316, 445, 411, 307, 1920, 6061, 12, 19558, 12004, 51040], "temperature": 0.0, "avg_logprob": -0.1685939691005609, "compression_ratio": 1.6997084548104957, "no_speech_prob": 0.0008033423218876123}, {"id": 1783, "seek": 457744, "start": 4590.96, "end": 4592.36, "text": " where it should be.", "tokens": [51040, 689, 309, 820, 312, 13, 51110], "temperature": 0.0, "avg_logprob": -0.1685939691005609, "compression_ratio": 1.6997084548104957, "no_speech_prob": 0.0008033423218876123}, {"id": 1784, "seek": 457744, "start": 4592.36, "end": 4594.0, "text": " Yeah, it's so interesting.", "tokens": [51110, 865, 11, 309, 311, 370, 1880, 13, 51192], "temperature": 0.0, "avg_logprob": -0.1685939691005609, "compression_ratio": 1.6997084548104957, "no_speech_prob": 0.0008033423218876123}, {"id": 1785, "seek": 457744, "start": 4594.0, "end": 4596.28, "text": " You know, like this problem with the changing dependencies.", "tokens": [51192, 509, 458, 11, 411, 341, 1154, 365, 264, 4473, 36606, 13, 51306], "temperature": 0.0, "avg_logprob": -0.1685939691005609, "compression_ratio": 1.6997084548104957, "no_speech_prob": 0.0008033423218876123}, {"id": 1786, "seek": 457744, "start": 4596.28, "end": 4599.32, "text": " So, essentially you're modeling a non-stationary process", "tokens": [51306, 407, 11, 4476, 291, 434, 15983, 257, 2107, 12, 19159, 822, 1399, 51458], "temperature": 0.0, "avg_logprob": -0.1685939691005609, "compression_ratio": 1.6997084548104957, "no_speech_prob": 0.0008033423218876123}, {"id": 1787, "seek": 457744, "start": 4599.32, "end": 4600.28, "text": " which makes it much harder.", "tokens": [51458, 597, 1669, 309, 709, 6081, 13, 51506], "temperature": 0.0, "avg_logprob": -0.1685939691005609, "compression_ratio": 1.6997084548104957, "no_speech_prob": 0.0008033423218876123}, {"id": 1788, "seek": 457744, "start": 4600.28, "end": 4603.4, "text": " And when I was speaking with Sarah Hooker the other day,", "tokens": [51506, 400, 562, 286, 390, 4124, 365, 9519, 33132, 260, 264, 661, 786, 11, 51662], "temperature": 0.0, "avg_logprob": -0.1685939691005609, "compression_ratio": 1.6997084548104957, "no_speech_prob": 0.0008033423218876123}, {"id": 1789, "seek": 457744, "start": 4603.4, "end": 4605.32, "text": " she was talking about fairness and bias in models.", "tokens": [51662, 750, 390, 1417, 466, 29765, 293, 12577, 294, 5245, 13, 51758], "temperature": 0.0, "avg_logprob": -0.1685939691005609, "compression_ratio": 1.6997084548104957, "no_speech_prob": 0.0008033423218876123}, {"id": 1790, "seek": 457744, "start": 4605.32, "end": 4607.16, "text": " And part of the problem there is,", "tokens": [51758, 400, 644, 295, 264, 1154, 456, 307, 11, 51850], "temperature": 0.0, "avg_logprob": -0.1685939691005609, "compression_ratio": 1.6997084548104957, "no_speech_prob": 0.0008033423218876123}, {"id": 1791, "seek": 460716, "start": 4607.28, "end": 4610.12, "text": " we optimize for headline metrics like accuracy.", "tokens": [50370, 321, 19719, 337, 28380, 16367, 411, 14170, 13, 50512], "temperature": 0.0, "avg_logprob": -0.15613894559899155, "compression_ratio": 1.829268292682927, "no_speech_prob": 0.001376782893203199}, {"id": 1792, "seek": 460716, "start": 4610.12, "end": 4611.88, "text": " And when you decompose the training set", "tokens": [50512, 400, 562, 291, 22867, 541, 264, 3097, 992, 50600], "temperature": 0.0, "avg_logprob": -0.15613894559899155, "compression_ratio": 1.829268292682927, "no_speech_prob": 0.001376782893203199}, {"id": 1793, "seek": 460716, "start": 4611.88, "end": 4615.2, "text": " into let's say different categories like men and women", "tokens": [50600, 666, 718, 311, 584, 819, 10479, 411, 1706, 293, 2266, 50766], "temperature": 0.0, "avg_logprob": -0.15613894559899155, "compression_ratio": 1.829268292682927, "no_speech_prob": 0.001376782893203199}, {"id": 1794, "seek": 460716, "start": 4615.2, "end": 4616.92, "text": " and people who live in London,", "tokens": [50766, 293, 561, 567, 1621, 294, 7042, 11, 50852], "temperature": 0.0, "avg_logprob": -0.15613894559899155, "compression_ratio": 1.829268292682927, "no_speech_prob": 0.001376782893203199}, {"id": 1795, "seek": 460716, "start": 4617.68, "end": 4619.8, "text": " the accuracy is very stratified.", "tokens": [50890, 264, 14170, 307, 588, 23674, 2587, 13, 50996], "temperature": 0.0, "avg_logprob": -0.15613894559899155, "compression_ratio": 1.829268292682927, "no_speech_prob": 0.001376782893203199}, {"id": 1796, "seek": 460716, "start": 4619.8, "end": 4622.0, "text": " It might perform very badly for people that live in London,", "tokens": [50996, 467, 1062, 2042, 588, 13425, 337, 561, 300, 1621, 294, 7042, 11, 51106], "temperature": 0.0, "avg_logprob": -0.15613894559899155, "compression_ratio": 1.829268292682927, "no_speech_prob": 0.001376782893203199}, {"id": 1797, "seek": 460716, "start": 4622.0, "end": 4623.88, "text": " but very good for people that live in New York.", "tokens": [51106, 457, 588, 665, 337, 561, 300, 1621, 294, 1873, 3609, 13, 51200], "temperature": 0.0, "avg_logprob": -0.15613894559899155, "compression_ratio": 1.829268292682927, "no_speech_prob": 0.001376782893203199}, {"id": 1798, "seek": 460716, "start": 4623.88, "end": 4625.84, "text": " You know, and then you start getting into the situation", "tokens": [51200, 509, 458, 11, 293, 550, 291, 722, 1242, 666, 264, 2590, 51298], "temperature": 0.0, "avg_logprob": -0.15613894559899155, "compression_ratio": 1.829268292682927, "no_speech_prob": 0.001376782893203199}, {"id": 1799, "seek": 460716, "start": 4625.84, "end": 4627.88, "text": " of saying, okay, well, I'll build an ensemble of models", "tokens": [51298, 295, 1566, 11, 1392, 11, 731, 11, 286, 603, 1322, 364, 19492, 295, 5245, 51400], "temperature": 0.0, "avg_logprob": -0.15613894559899155, "compression_ratio": 1.829268292682927, "no_speech_prob": 0.001376782893203199}, {"id": 1800, "seek": 460716, "start": 4627.88, "end": 4630.36, "text": " that are independently optimized for all the different things.", "tokens": [51400, 300, 366, 21761, 26941, 337, 439, 264, 819, 721, 13, 51524], "temperature": 0.0, "avg_logprob": -0.15613894559899155, "compression_ratio": 1.829268292682927, "no_speech_prob": 0.001376782893203199}, {"id": 1801, "seek": 460716, "start": 4630.36, "end": 4632.28, "text": " But then you have this impedance mismatch", "tokens": [51524, 583, 550, 291, 362, 341, 36264, 23220, 852, 51620], "temperature": 0.0, "avg_logprob": -0.15613894559899155, "compression_ratio": 1.829268292682927, "no_speech_prob": 0.001376782893203199}, {"id": 1802, "seek": 460716, "start": 4632.28, "end": 4633.8, "text": " between this global, you know,", "tokens": [51620, 1296, 341, 4338, 11, 291, 458, 11, 51696], "temperature": 0.0, "avg_logprob": -0.15613894559899155, "compression_ratio": 1.829268292682927, "no_speech_prob": 0.001376782893203199}, {"id": 1803, "seek": 460716, "start": 4633.8, "end": 4636.16, "text": " accuracy that you were optimizing for", "tokens": [51696, 14170, 300, 291, 645, 40425, 337, 51814], "temperature": 0.0, "avg_logprob": -0.15613894559899155, "compression_ratio": 1.829268292682927, "no_speech_prob": 0.001376782893203199}, {"id": 1804, "seek": 463616, "start": 4636.16, "end": 4637.639999999999, "text": " and are on the benchmarks.", "tokens": [50364, 293, 366, 322, 264, 43751, 13, 50438], "temperature": 0.0, "avg_logprob": -0.2359702743102457, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.0014772876165807247}, {"id": 1805, "seek": 463616, "start": 4638.88, "end": 4641.48, "text": " Yeah, no, it's a really interesting property", "tokens": [50500, 865, 11, 572, 11, 309, 311, 257, 534, 1880, 4707, 50630], "temperature": 0.0, "avg_logprob": -0.2359702743102457, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.0014772876165807247}, {"id": 1806, "seek": 463616, "start": 4641.48, "end": 4644.48, "text": " of these things is, yeah,", "tokens": [50630, 295, 613, 721, 307, 11, 1338, 11, 50780], "temperature": 0.0, "avg_logprob": -0.2359702743102457, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.0014772876165807247}, {"id": 1807, "seek": 463616, "start": 4644.48, "end": 4645.72, "text": " especially classification models", "tokens": [50780, 2318, 21538, 5245, 50842], "temperature": 0.0, "avg_logprob": -0.2359702743102457, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.0014772876165807247}, {"id": 1808, "seek": 463616, "start": 4645.72, "end": 4647.76, "text": " where they will work well for some categories", "tokens": [50842, 689, 436, 486, 589, 731, 337, 512, 10479, 50944], "temperature": 0.0, "avg_logprob": -0.2359702743102457, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.0014772876165807247}, {"id": 1809, "seek": 463616, "start": 4647.76, "end": 4648.599999999999, "text": " and not others.", "tokens": [50944, 293, 406, 2357, 13, 50986], "temperature": 0.0, "avg_logprob": -0.2359702743102457, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.0014772876165807247}, {"id": 1810, "seek": 463616, "start": 4648.599999999999, "end": 4652.8, "text": " And it can be sort of tricky to find out why is like,", "tokens": [50986, 400, 309, 393, 312, 1333, 295, 12414, 281, 915, 484, 983, 307, 411, 11, 51196], "temperature": 0.0, "avg_logprob": -0.2359702743102457, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.0014772876165807247}, {"id": 1811, "seek": 463616, "start": 4652.8, "end": 4654.8, "text": " are those features just more discriminative", "tokens": [51196, 366, 729, 4122, 445, 544, 20828, 1166, 51296], "temperature": 0.0, "avg_logprob": -0.2359702743102457, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.0014772876165807247}, {"id": 1812, "seek": 463616, "start": 4654.8, "end": 4658.5199999999995, "text": " or like, are these classes somehow harder to tell apart", "tokens": [51296, 420, 411, 11, 366, 613, 5359, 6063, 6081, 281, 980, 4936, 51482], "temperature": 0.0, "avg_logprob": -0.2359702743102457, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.0014772876165807247}, {"id": 1813, "seek": 463616, "start": 4658.5199999999995, "end": 4660.2, "text": " just in some way?", "tokens": [51482, 445, 294, 512, 636, 30, 51566], "temperature": 0.0, "avg_logprob": -0.2359702743102457, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.0014772876165807247}, {"id": 1814, "seek": 463616, "start": 4661.68, "end": 4663.04, "text": " It's, yeah, it's,", "tokens": [51640, 467, 311, 11, 1338, 11, 309, 311, 11, 51708], "temperature": 0.0, "avg_logprob": -0.2359702743102457, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.0014772876165807247}, {"id": 1815, "seek": 466304, "start": 4664.04, "end": 4667.08, "text": " but I'm glad people are starting to like look at", "tokens": [50414, 457, 286, 478, 5404, 561, 366, 2891, 281, 411, 574, 412, 50566], "temperature": 0.0, "avg_logprob": -0.1675342619419098, "compression_ratio": 1.851985559566787, "no_speech_prob": 0.001098506385460496}, {"id": 1816, "seek": 466304, "start": 4667.08, "end": 4669.72, "text": " and try to dig into some of these like details", "tokens": [50566, 293, 853, 281, 2528, 666, 512, 295, 613, 411, 4365, 50698], "temperature": 0.0, "avg_logprob": -0.1675342619419098, "compression_ratio": 1.851985559566787, "no_speech_prob": 0.001098506385460496}, {"id": 1817, "seek": 466304, "start": 4669.72, "end": 4671.5199999999995, "text": " rather than just looking at headline metrics.", "tokens": [50698, 2831, 813, 445, 1237, 412, 28380, 16367, 13, 50788], "temperature": 0.0, "avg_logprob": -0.1675342619419098, "compression_ratio": 1.851985559566787, "no_speech_prob": 0.001098506385460496}, {"id": 1818, "seek": 466304, "start": 4671.5199999999995, "end": 4674.88, "text": " And I'm also sort of happy that the field is sort of moving", "tokens": [50788, 400, 286, 478, 611, 1333, 295, 2055, 300, 264, 2519, 307, 1333, 295, 2684, 50956], "temperature": 0.0, "avg_logprob": -0.1675342619419098, "compression_ratio": 1.851985559566787, "no_speech_prob": 0.001098506385460496}, {"id": 1819, "seek": 466304, "start": 4674.88, "end": 4677.44, "text": " to like this out of distribution learning", "tokens": [50956, 281, 411, 341, 484, 295, 7316, 2539, 51084], "temperature": 0.0, "avg_logprob": -0.1675342619419098, "compression_ratio": 1.851985559566787, "no_speech_prob": 0.001098506385460496}, {"id": 1820, "seek": 466304, "start": 4677.44, "end": 4680.56, "text": " is becoming a much more interesting topic.", "tokens": [51084, 307, 5617, 257, 709, 544, 1880, 4829, 13, 51240], "temperature": 0.0, "avg_logprob": -0.1675342619419098, "compression_ratio": 1.851985559566787, "no_speech_prob": 0.001098506385460496}, {"id": 1821, "seek": 466304, "start": 4680.56, "end": 4682.6, "text": " Because like, that is what really matters", "tokens": [51240, 1436, 411, 11, 300, 307, 437, 534, 7001, 51342], "temperature": 0.0, "avg_logprob": -0.1675342619419098, "compression_ratio": 1.851985559566787, "no_speech_prob": 0.001098506385460496}, {"id": 1822, "seek": 466304, "start": 4682.6, "end": 4683.6, "text": " in making machine learning", "tokens": [51342, 294, 1455, 3479, 2539, 51392], "temperature": 0.0, "avg_logprob": -0.1675342619419098, "compression_ratio": 1.851985559566787, "no_speech_prob": 0.001098506385460496}, {"id": 1823, "seek": 466304, "start": 4683.6, "end": 4686.0, "text": " that is going to affect the real world", "tokens": [51392, 300, 307, 516, 281, 3345, 264, 957, 1002, 51512], "temperature": 0.0, "avg_logprob": -0.1675342619419098, "compression_ratio": 1.851985559566787, "no_speech_prob": 0.001098506385460496}, {"id": 1824, "seek": 466304, "start": 4686.0, "end": 4687.64, "text": " is it needs to work out of distribution,", "tokens": [51512, 307, 309, 2203, 281, 589, 484, 295, 7316, 11, 51594], "temperature": 0.0, "avg_logprob": -0.1675342619419098, "compression_ratio": 1.851985559566787, "no_speech_prob": 0.001098506385460496}, {"id": 1825, "seek": 466304, "start": 4687.64, "end": 4689.04, "text": " out of your sort of training", "tokens": [51594, 484, 295, 428, 1333, 295, 3097, 51664], "temperature": 0.0, "avg_logprob": -0.1675342619419098, "compression_ratio": 1.851985559566787, "no_speech_prob": 0.001098506385460496}, {"id": 1826, "seek": 466304, "start": 4689.04, "end": 4692.08, "text": " and test split distribution as well as possible.", "tokens": [51664, 293, 1500, 7472, 7316, 382, 731, 382, 1944, 13, 51816], "temperature": 0.0, "avg_logprob": -0.1675342619419098, "compression_ratio": 1.851985559566787, "no_speech_prob": 0.001098506385460496}, {"id": 1827, "seek": 469208, "start": 4692.12, "end": 4693.2, "text": " And like how you do that is,", "tokens": [50366, 400, 411, 577, 291, 360, 300, 307, 11, 50420], "temperature": 0.0, "avg_logprob": -0.17166099851093594, "compression_ratio": 1.7808764940239044, "no_speech_prob": 0.0018096545245498419}, {"id": 1828, "seek": 469208, "start": 4693.2, "end": 4696.0, "text": " I mean, still very much an open question clearly.", "tokens": [50420, 286, 914, 11, 920, 588, 709, 364, 1269, 1168, 4448, 13, 50560], "temperature": 0.0, "avg_logprob": -0.17166099851093594, "compression_ratio": 1.7808764940239044, "no_speech_prob": 0.0018096545245498419}, {"id": 1829, "seek": 469208, "start": 4696.0, "end": 4698.5599999999995, "text": " And how well you could potentially do that", "tokens": [50560, 400, 577, 731, 291, 727, 7263, 360, 300, 50688], "temperature": 0.0, "avg_logprob": -0.17166099851093594, "compression_ratio": 1.7808764940239044, "no_speech_prob": 0.0018096545245498419}, {"id": 1830, "seek": 469208, "start": 4698.5599999999995, "end": 4701.28, "text": " is even still an open question.", "tokens": [50688, 307, 754, 920, 364, 1269, 1168, 13, 50824], "temperature": 0.0, "avg_logprob": -0.17166099851093594, "compression_ratio": 1.7808764940239044, "no_speech_prob": 0.0018096545245498419}, {"id": 1831, "seek": 469208, "start": 4701.28, "end": 4702.5599999999995, "text": " But that is one of the,", "tokens": [50824, 583, 300, 307, 472, 295, 264, 11, 50888], "temperature": 0.0, "avg_logprob": -0.17166099851093594, "compression_ratio": 1.7808764940239044, "no_speech_prob": 0.0018096545245498419}, {"id": 1832, "seek": 469208, "start": 4703.6, "end": 4706.24, "text": " I mean, that is sort of what true intelligence is", "tokens": [50940, 286, 914, 11, 300, 307, 1333, 295, 437, 2074, 7599, 307, 51072], "temperature": 0.0, "avg_logprob": -0.17166099851093594, "compression_ratio": 1.7808764940239044, "no_speech_prob": 0.0018096545245498419}, {"id": 1833, "seek": 469208, "start": 4706.24, "end": 4708.5199999999995, "text": " to something like humans are pretty good", "tokens": [51072, 281, 746, 411, 6255, 366, 1238, 665, 51186], "temperature": 0.0, "avg_logprob": -0.17166099851093594, "compression_ratio": 1.7808764940239044, "no_speech_prob": 0.0018096545245498419}, {"id": 1834, "seek": 469208, "start": 4708.5199999999995, "end": 4710.96, "text": " at adapting out of distribution.", "tokens": [51186, 412, 34942, 484, 295, 7316, 13, 51308], "temperature": 0.0, "avg_logprob": -0.17166099851093594, "compression_ratio": 1.7808764940239044, "no_speech_prob": 0.0018096545245498419}, {"id": 1835, "seek": 469208, "start": 4711.88, "end": 4714.48, "text": " And what is it about us?", "tokens": [51354, 400, 437, 307, 309, 466, 505, 30, 51484], "temperature": 0.0, "avg_logprob": -0.17166099851093594, "compression_ratio": 1.7808764940239044, "no_speech_prob": 0.0018096545245498419}, {"id": 1836, "seek": 469208, "start": 4714.48, "end": 4716.88, "text": " What are like, how are we able to do that?", "tokens": [51484, 708, 366, 411, 11, 577, 366, 321, 1075, 281, 360, 300, 30, 51604], "temperature": 0.0, "avg_logprob": -0.17166099851093594, "compression_ratio": 1.7808764940239044, "no_speech_prob": 0.0018096545245498419}, {"id": 1837, "seek": 469208, "start": 4716.88, "end": 4719.32, "text": " And how do we make our sort of machine learning systems", "tokens": [51604, 400, 577, 360, 321, 652, 527, 1333, 295, 3479, 2539, 3652, 51726], "temperature": 0.0, "avg_logprob": -0.17166099851093594, "compression_ratio": 1.7808764940239044, "no_speech_prob": 0.0018096545245498419}, {"id": 1838, "seek": 469208, "start": 4719.32, "end": 4720.6, "text": " work better that way?", "tokens": [51726, 589, 1101, 300, 636, 30, 51790], "temperature": 0.0, "avg_logprob": -0.17166099851093594, "compression_ratio": 1.7808764940239044, "no_speech_prob": 0.0018096545245498419}, {"id": 1839, "seek": 472060, "start": 4720.6, "end": 4722.160000000001, "text": " How are we sort of able to?", "tokens": [50364, 1012, 366, 321, 1333, 295, 1075, 281, 30, 50442], "temperature": 0.0, "avg_logprob": -0.22024207818703573, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.0005974959931336343}, {"id": 1840, "seek": 472060, "start": 4723.360000000001, "end": 4725.52, "text": " I mean, yeah, I think it probably has something to do", "tokens": [50502, 286, 914, 11, 1338, 11, 286, 519, 309, 1391, 575, 746, 281, 360, 50610], "temperature": 0.0, "avg_logprob": -0.22024207818703573, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.0005974959931336343}, {"id": 1841, "seek": 472060, "start": 4725.52, "end": 4727.76, "text": " is we're able to learn sort of causal structures", "tokens": [50610, 307, 321, 434, 1075, 281, 1466, 1333, 295, 38755, 9227, 50722], "temperature": 0.0, "avg_logprob": -0.22024207818703573, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.0005974959931336343}, {"id": 1842, "seek": 472060, "start": 4727.76, "end": 4729.88, "text": " that work well.", "tokens": [50722, 300, 589, 731, 13, 50828], "temperature": 0.0, "avg_logprob": -0.22024207818703573, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.0005974959931336343}, {"id": 1843, "seek": 472060, "start": 4729.88, "end": 4732.200000000001, "text": " And the distribution can be very different,", "tokens": [50828, 400, 264, 7316, 393, 312, 588, 819, 11, 50944], "temperature": 0.0, "avg_logprob": -0.22024207818703573, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.0005974959931336343}, {"id": 1844, "seek": 472060, "start": 4732.200000000001, "end": 4735.400000000001, "text": " but the sort of causal structures remain.", "tokens": [50944, 457, 264, 1333, 295, 38755, 9227, 6222, 13, 51104], "temperature": 0.0, "avg_logprob": -0.22024207818703573, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.0005974959931336343}, {"id": 1845, "seek": 472060, "start": 4735.400000000001, "end": 4738.4800000000005, "text": " And we're able to somehow infer that causal structures", "tokens": [51104, 400, 321, 434, 1075, 281, 6063, 13596, 300, 38755, 9227, 51258], "temperature": 0.0, "avg_logprob": -0.22024207818703573, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.0005974959931336343}, {"id": 1846, "seek": 472060, "start": 4738.4800000000005, "end": 4742.280000000001, "text": " from data, from just our sense data and our world models.", "tokens": [51258, 490, 1412, 11, 490, 445, 527, 2020, 1412, 293, 527, 1002, 5245, 13, 51448], "temperature": 0.0, "avg_logprob": -0.22024207818703573, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.0005974959931336343}, {"id": 1847, "seek": 472060, "start": 4743.8, "end": 4744.96, "text": " And yeah, basically the question is,", "tokens": [51524, 400, 1338, 11, 1936, 264, 1168, 307, 11, 51582], "temperature": 0.0, "avg_logprob": -0.22024207818703573, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.0005974959931336343}, {"id": 1848, "seek": 472060, "start": 4744.96, "end": 4747.04, "text": " how do we make our machine learning systems", "tokens": [51582, 577, 360, 321, 652, 527, 3479, 2539, 3652, 51686], "temperature": 0.0, "avg_logprob": -0.22024207818703573, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.0005974959931336343}, {"id": 1849, "seek": 472060, "start": 4747.04, "end": 4750.08, "text": " be able to do similar sorts of things?", "tokens": [51686, 312, 1075, 281, 360, 2531, 7527, 295, 721, 30, 51838], "temperature": 0.0, "avg_logprob": -0.22024207818703573, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.0005974959931336343}, {"id": 1850, "seek": 475060, "start": 4751.6, "end": 4754.4400000000005, "text": " Yeah, this has been absolutely amazing.", "tokens": [50414, 865, 11, 341, 575, 668, 3122, 2243, 13, 50556], "temperature": 0.0, "avg_logprob": -0.1890422300858931, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0005782446824014187}, {"id": 1851, "seek": 475060, "start": 4754.4400000000005, "end": 4756.160000000001, "text": " Do you have any final thoughts?", "tokens": [50556, 1144, 291, 362, 604, 2572, 4598, 30, 50642], "temperature": 0.0, "avg_logprob": -0.1890422300858931, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0005782446824014187}, {"id": 1852, "seek": 475060, "start": 4756.160000000001, "end": 4758.0, "text": " Where can people find out more information", "tokens": [50642, 2305, 393, 561, 915, 484, 544, 1589, 50734], "temperature": 0.0, "avg_logprob": -0.1890422300858931, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0005782446824014187}, {"id": 1853, "seek": 475060, "start": 4758.0, "end": 4759.0, "text": " about you, Michael?", "tokens": [50734, 466, 291, 11, 5116, 30, 50784], "temperature": 0.0, "avg_logprob": -0.1890422300858931, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0005782446824014187}, {"id": 1854, "seek": 475060, "start": 4760.6, "end": 4762.120000000001, "text": " So, let's see.", "tokens": [50864, 407, 11, 718, 311, 536, 13, 50940], "temperature": 0.0, "avg_logprob": -0.1890422300858931, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0005782446824014187}, {"id": 1855, "seek": 475060, "start": 4762.120000000001, "end": 4766.160000000001, "text": " Well, so I want to point people first to just like Numeri,", "tokens": [50940, 1042, 11, 370, 286, 528, 281, 935, 561, 700, 281, 445, 411, 426, 15583, 72, 11, 51142], "temperature": 0.0, "avg_logprob": -0.1890422300858931, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0005782446824014187}, {"id": 1856, "seek": 475060, "start": 4766.160000000001, "end": 4769.8, "text": " N-U-M-E-R.AI is the website.", "tokens": [51142, 426, 12, 52, 12, 44, 12, 36, 12, 49, 13, 48698, 307, 264, 3144, 13, 51324], "temperature": 0.0, "avg_logprob": -0.1890422300858931, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0005782446824014187}, {"id": 1857, "seek": 475060, "start": 4769.8, "end": 4773.4800000000005, "text": " I am fairly active in the forums", "tokens": [51324, 286, 669, 6457, 4967, 294, 264, 26998, 51508], "temperature": 0.0, "avg_logprob": -0.1890422300858931, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0005782446824014187}, {"id": 1858, "seek": 475060, "start": 4773.4800000000005, "end": 4775.360000000001, "text": " and the rocket chat we have,", "tokens": [51508, 293, 264, 13012, 5081, 321, 362, 11, 51602], "temperature": 0.0, "avg_logprob": -0.1890422300858931, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0005782446824014187}, {"id": 1859, "seek": 475060, "start": 4775.360000000001, "end": 4780.280000000001, "text": " which is sort of just our own personal chat service", "tokens": [51602, 597, 307, 1333, 295, 445, 527, 1065, 2973, 5081, 2643, 51848], "temperature": 0.0, "avg_logprob": -0.1890422300858931, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0005782446824014187}, {"id": 1860, "seek": 478028, "start": 4780.28, "end": 4783.36, "text": " for tournament participants to communicate with each other.", "tokens": [50364, 337, 13713, 10503, 281, 7890, 365, 1184, 661, 13, 50518], "temperature": 0.0, "avg_logprob": -0.23674243745349702, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.0009543848573230207}, {"id": 1861, "seek": 478028, "start": 4783.36, "end": 4786.44, "text": " And I occasionally only post some of the forums there.", "tokens": [50518, 400, 286, 16895, 787, 2183, 512, 295, 264, 26998, 456, 13, 50672], "temperature": 0.0, "avg_logprob": -0.23674243745349702, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.0009543848573230207}, {"id": 1862, "seek": 478028, "start": 4786.44, "end": 4788.92, "text": " That's probably the best way to like get in contact", "tokens": [50672, 663, 311, 1391, 264, 1151, 636, 281, 411, 483, 294, 3385, 50796], "temperature": 0.0, "avg_logprob": -0.23674243745349702, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.0009543848573230207}, {"id": 1863, "seek": 478028, "start": 4788.92, "end": 4791.44, "text": " to just message me on rocket chat.", "tokens": [50796, 281, 445, 3636, 385, 322, 13012, 5081, 13, 50922], "temperature": 0.0, "avg_logprob": -0.23674243745349702, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.0009543848573230207}, {"id": 1864, "seek": 478028, "start": 4792.719999999999, "end": 4797.639999999999, "text": " And yeah, so that's, yeah,", "tokens": [50986, 400, 1338, 11, 370, 300, 311, 11, 1338, 11, 51232], "temperature": 0.0, "avg_logprob": -0.23674243745349702, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.0009543848573230207}, {"id": 1865, "seek": 478028, "start": 4797.639999999999, "end": 4801.08, "text": " there's probably that's way to get in contact.", "tokens": [51232, 456, 311, 1391, 300, 311, 636, 281, 483, 294, 3385, 13, 51404], "temperature": 0.0, "avg_logprob": -0.23674243745349702, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.0009543848573230207}, {"id": 1866, "seek": 478028, "start": 4801.08, "end": 4805.599999999999, "text": " My also, my email is mdo at Numeri.ai.", "tokens": [51404, 1222, 611, 11, 452, 3796, 307, 275, 2595, 412, 426, 15583, 72, 13, 1301, 13, 51630], "temperature": 0.0, "avg_logprob": -0.23674243745349702, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.0009543848573230207}, {"id": 1867, "seek": 478028, "start": 4806.88, "end": 4809.84, "text": " And I would, yeah, I really love if people come,", "tokens": [51694, 400, 286, 576, 11, 1338, 11, 286, 534, 959, 498, 561, 808, 11, 51842], "temperature": 0.0, "avg_logprob": -0.23674243745349702, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.0009543848573230207}, {"id": 1868, "seek": 480984, "start": 4809.84, "end": 4811.88, "text": " check out the tournament, give feedback,", "tokens": [50364, 1520, 484, 264, 13713, 11, 976, 5824, 11, 50466], "temperature": 0.0, "avg_logprob": -0.20145893912030083, "compression_ratio": 1.6245059288537549, "no_speech_prob": 0.0028801276348531246}, {"id": 1869, "seek": 480984, "start": 4811.88, "end": 4813.88, "text": " and start participating.", "tokens": [50466, 293, 722, 13950, 13, 50566], "temperature": 0.0, "avg_logprob": -0.20145893912030083, "compression_ratio": 1.6245059288537549, "no_speech_prob": 0.0028801276348531246}, {"id": 1870, "seek": 480984, "start": 4813.88, "end": 4818.0, "text": " I've, yeah, I found that it was a lot of fun as a participant.", "tokens": [50566, 286, 600, 11, 1338, 11, 286, 1352, 300, 309, 390, 257, 688, 295, 1019, 382, 257, 24950, 13, 50772], "temperature": 0.0, "avg_logprob": -0.20145893912030083, "compression_ratio": 1.6245059288537549, "no_speech_prob": 0.0028801276348531246}, {"id": 1871, "seek": 480984, "start": 4818.84, "end": 4821.68, "text": " And yeah, I joined the company partly", "tokens": [50814, 400, 1338, 11, 286, 6869, 264, 2237, 17031, 50956], "temperature": 0.0, "avg_logprob": -0.20145893912030083, "compression_ratio": 1.6245059288537549, "no_speech_prob": 0.0028801276348531246}, {"id": 1872, "seek": 480984, "start": 4821.68, "end": 4823.16, "text": " so I was starting to make more money", "tokens": [50956, 370, 286, 390, 2891, 281, 652, 544, 1460, 51030], "temperature": 0.0, "avg_logprob": -0.20145893912030083, "compression_ratio": 1.6245059288537549, "no_speech_prob": 0.0028801276348531246}, {"id": 1873, "seek": 480984, "start": 4823.16, "end": 4826.76, "text": " during the tournament than I was at my job in science.", "tokens": [51030, 1830, 264, 13713, 813, 286, 390, 412, 452, 1691, 294, 3497, 13, 51210], "temperature": 0.0, "avg_logprob": -0.20145893912030083, "compression_ratio": 1.6245059288537549, "no_speech_prob": 0.0028801276348531246}, {"id": 1874, "seek": 480984, "start": 4826.76, "end": 4830.84, "text": " And so, yeah, it's a pretty fun hobby and side gig", "tokens": [51210, 400, 370, 11, 1338, 11, 309, 311, 257, 1238, 1019, 18240, 293, 1252, 8741, 51414], "temperature": 0.0, "avg_logprob": -0.20145893912030083, "compression_ratio": 1.6245059288537549, "no_speech_prob": 0.0028801276348531246}, {"id": 1875, "seek": 480984, "start": 4830.84, "end": 4834.6, "text": " and potentially even quite lucrative.", "tokens": [51414, 293, 7263, 754, 1596, 21296, 30457, 13, 51602], "temperature": 0.0, "avg_logprob": -0.20145893912030083, "compression_ratio": 1.6245059288537549, "no_speech_prob": 0.0028801276348531246}, {"id": 1876, "seek": 480984, "start": 4834.6, "end": 4835.4400000000005, "text": " Amazing.", "tokens": [51602, 14165, 13, 51644], "temperature": 0.0, "avg_logprob": -0.20145893912030083, "compression_ratio": 1.6245059288537549, "no_speech_prob": 0.0028801276348531246}, {"id": 1877, "seek": 480984, "start": 4835.4400000000005, "end": 4837.76, "text": " Well, Dr. Michael Oliver, it's been an absolute honor.", "tokens": [51644, 1042, 11, 2491, 13, 5116, 23440, 11, 309, 311, 668, 364, 8236, 5968, 13, 51760], "temperature": 0.0, "avg_logprob": -0.20145893912030083, "compression_ratio": 1.6245059288537549, "no_speech_prob": 0.0028801276348531246}, {"id": 1878, "seek": 483776, "start": 4837.76, "end": 4839.92, "text": " Thank you so much for joining us this evening.", "tokens": [50364, 1044, 291, 370, 709, 337, 5549, 505, 341, 5634, 13, 50472], "temperature": 0.0, "avg_logprob": -0.19617879390716553, "compression_ratio": 1.271604938271605, "no_speech_prob": 0.0007530920556746423}, {"id": 1879, "seek": 483776, "start": 4839.92, "end": 4841.2, "text": " Thanks for so much for having me.", "tokens": [50472, 2561, 337, 370, 709, 337, 1419, 385, 13, 50536], "temperature": 0.0, "avg_logprob": -0.19617879390716553, "compression_ratio": 1.271604938271605, "no_speech_prob": 0.0007530920556746423}, {"id": 1880, "seek": 483776, "start": 4841.2, "end": 4842.52, "text": " It's been so much fun.", "tokens": [50536, 467, 311, 668, 370, 709, 1019, 13, 50602], "temperature": 0.0, "avg_logprob": -0.19617879390716553, "compression_ratio": 1.271604938271605, "no_speech_prob": 0.0007530920556746423}], "language": "en"}