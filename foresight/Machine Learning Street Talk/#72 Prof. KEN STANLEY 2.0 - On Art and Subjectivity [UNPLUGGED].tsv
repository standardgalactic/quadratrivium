start	end	text
0	1080	To achieve your highest goals,
1080	2840	you have to be willing to abandon them.
2840	4880	Today, we're publishing the first
4880	7280	in a small series of conversations
7280	10040	with Professor Ken Stanley.
10040	13440	Reading Ken's book, Why Greatness Cannot Be Planned,
13440	16680	was one of the most intellectually awakening moments
16680	19000	of the latter part of my life.
19000	21640	It really turned my thinking upside down,
21640	24680	making me question many deeply held beliefs
24680	26040	which I had previously.
27000	28280	The episode that we did with him
28280	30440	was many months in the making,
30440	35440	and perhaps the greatest ever episode of MLST.
35440	37720	Ken argued in his book that our world
37720	41440	has become saturated with objectives.
41440	44200	The process of setting an objective,
44200	46040	attempting to achieve it,
46040	48440	and measuring progress along the way,
48440	52560	has become the primary route to achievement in our culture.
52560	56040	It's not like he's saying that objectives are bad, per se,
56040	57720	especially if they're modest.
57720	60440	But what he thinks are that when goals are ambitious,
60440	65360	which is to say they are unknowable, complex, or abstract,
65360	69960	or put more simply, that they entail discovery, creativity,
69960	73680	invention, innovation, or happiness,
73680	77040	then the search base becomes deceptive,
77040	82040	which is to say the measure itself becomes a false compass
82120	84200	which blinds us to the stepping stones
84200	86200	which we should actually take.
86200	89520	I mean, is the key to artificial intelligence
89520	92160	really related to intelligence?
92160	95040	Does taking a job with a higher salary
95040	98360	really bring you closer to being a millionaire?
98360	100520	The problem is that the stepping stones
100520	102880	which lead to ambitious objectives
102880	105000	tend to be pretty strange.
105000	108520	They don't resemble the final end state.
108520	112360	Vacuum tubes led to computers, for example,
112360	116560	and YouTube started as a video dating website.
116560	121560	In a sense, creativity itself is actually a search problem.
122040	126560	Is it possible to explore a search space intelligently
126560	130560	without using an objective to align towards discovery
130560	134340	and away from the trap of preconceived results?
135400	138880	Greatness is possible if you're willing to stop demanding
138880	141560	what greatness should be.
141600	144760	The greatest moments and epiphanies in our life
144760	148760	are so often unexpected and unplanned.
148760	152680	Serendipity can play an outsize role in our lives.
154000	157520	At the end of Joel Lemon and Ken Stanley's 2011 paper,
157520	159200	Abandoning Objectives,
159200	162720	they concluded that it was almost like a riddle.
162720	166600	Novelty search suggests a surprising new perspective
166600	169320	on achievement, which is to say,
169320	171520	to achieve your highest goals,
171520	173880	you must be willing to abandon them.
174800	177960	I always get engineers on my team to read this paper
177960	181120	and it's illuminating in so many ways.
181120	185080	I love using the visual analogy of a maze
185080	187800	to represent the search problem of life
187800	190400	and stepping stones in that maze
190400	195080	as being either potential objectives or end states.
195080	197640	Of course, we don't know about the existence
197640	200080	of most of the objectives and the fog of war
200080	203520	blinds us from seeing far ahead into the maze.
203520	207640	The fundamental problem is the missing information problem.
207640	209120	But as we'll soon find out,
209120	211640	not just the information itself,
211640	215000	but how we represent it, understand it,
215000	217600	experience it and even know it.
218640	221880	The fascinating thing is that if we were an oracle
221880	225080	and we knew exactly which steps to take in life,
225080	227680	we could become billionaires within months
227680	230840	or we could achieve anything we wanted to.
230840	232800	The only inconvenient thing stopping us
232800	235080	from realizing our dreams
235080	238680	is that the space of possibilities is exponentially large.
238680	241960	It's very expensive to sample many trajectories
241960	244720	in that space, so we tend to get stuck
244720	248320	in certain sections of the maze for long stretches of time.
249360	253040	Ken thinks that the most valuable commodity in search
253040	254200	is information.
255080	258360	We must accumulate as much of it as possible.
258360	261160	There's an arrow of informational complexity
261160	262840	and natural evolution.
262840	265560	And Ken was the first machine learning researcher
265560	270000	to take seriously the growing yet controversial view
270000	272760	in biology that adaptive selection
272760	275760	does not explain the arrow of complexity in nature.
276680	279080	We're standing in a maze right now.
279080	282000	There are many doors within walking distance
282000	285480	which lead to unthinkable greatness.
285480	289200	We simply haven't walked over and open them.
289200	292960	We are existence proofs of general intelligence.
292960	294960	Every single one of us has a brain,
294960	297000	but just like the infinite number of doors
297000	299320	we could open in the maze of life,
299320	302120	it took evolution billions of years
302120	304640	and gazillions of individual life forms
304640	306720	to create our brains.
306720	310040	Now, Ken is known for his pioneering research
310040	312040	in the open-endedness space.
312040	313640	You might recall the poet paper,
313640	316640	the pairwise open-ended trailblazer.
316640	319760	It was the first ever episode of MLST that we spoke about that,
319760	323720	but that's an example of this line of research.
323720	327640	Open-endedness might seem like a nebulous term,
327640	329520	but you can think of it as being an AI system
329520	333400	which doesn't have a boundary in its state space
333400	336280	and doesn't ever finish accumulating information.
340320	343360	Sir Arthur Stanley Eddington,
343360	345360	the notorious astronomer and physicist
345360	347480	born in the late 19th century,
347480	351120	spoke about the subjectivity in science.
351120	354800	His point is that science only tells us a sliver
354800	357800	of what's really happening in the world around us,
357800	360480	and we should be a lot less arrogant in our claims
360480	364760	to understand it and our attempts to formalize it.
364760	366360	Physics, he argued,
366360	369240	can never reveal the true nature of things,
369280	372760	rather it deals with relations between observables
372760	376880	which are subjectively selected by the human mind.
376880	379720	He says that he was inclined to attribute
379720	382960	the whole responsibility for the laws of mechanics
382960	385320	and gravitation to the mind
385320	389440	and deny the external world any share in them.
389440	391000	He went on to say,
391000	394680	the laws which we have hitherto been unable to fit
394680	398400	into a rational scheme are the true natural laws
398400	400880	inherent in the external world,
400880	403840	and mind has no chance of molding them
403840	406600	in accordance with its own outlook.
408120	410760	Subjectivity is everywhere,
410760	413320	and yet in so many ways we delude ourselves
413320	418200	that we are transforming subjectivity into objectivity.
418200	421600	Imagine a fisherman catching fish in a small ocean.
421600	423600	Depending on the size of his net,
423600	427080	he might reason that there's nothing very small in the ocean
427080	429680	because those objects are slipping through his net.
430720	433040	What we can agree on is that our understanding
433040	436280	of physics breaks if we zoom in too much
436280	437960	or zoom out too much,
437960	441160	so at best we have a frame of reference
441160	445200	which Eddington would argue is observer relative.
445200	448680	Surprisingly little in our world can actually be objectified
448680	451560	without using abstract motifs.
451560	452880	Have you ever asked a philosopher
452880	455840	to define what it means to be real,
455840	458560	or what it means to exist?
458560	462080	I can guarantee you that they'll be reaching.
462080	465200	They'll say things like something exists
465200	467560	if it has a causal effect on the world,
467560	470160	or if it can be measured,
470160	472800	or if it's not illusory,
472800	476200	which is to say it is as it appears,
476200	480600	or perhaps that it's genuine in big air quotes.
481640	484720	What does it mean to be intelligent?
484720	486320	What is life?
486320	489160	Describe an ecosystem.
489160	491360	What is British culture?
491360	493880	Describe your mind.
493880	497280	Describe your conscious experience.
497280	498640	Have you heard of the parable
498640	500720	of the blind men and the elephant?
500720	503440	Any attempt to formalize a complex phenomena
503440	506480	lead to excluding large parts of the truth.
506480	508520	What fascinated me about this conversation
508520	509600	with Ken this evening
509600	512920	is I got a much deeper understanding of his philosophy.
512920	514760	He led by saying that he thought
514760	516160	it's worth questioning
516160	517600	whether artificial intelligence
517600	520280	is even a science or not.
520280	523480	Just let that sink in for a moment.
523480	526160	I'd been too focused on my mental framework
526160	530320	of objectives, behavior, and actions.
530320	532240	The broader story is that Ken thinks
532240	534600	society and institutions
534600	537840	are scared of any subjectivity.
537840	540360	Subjectivity in general.
540360	543200	He thinks that attempts to formalize complex,
543200	545840	emergent, and integrative phenomena
545840	549840	like intelligence, consciousness, life, society,
549840	552240	the mind, or anything else for that matter,
552240	554800	only deludes us and blocks us
554800	558760	from potentially discovering a deeper reality later.
558760	561200	It's a very human trait to seek to understand
561200	562280	the world around us
562280	564640	to varying degrees of self-delusion.
564640	566960	Before we understand a particular phenomena,
566960	568960	it's almost impossible to come up
568960	572280	with a good scientific and formal definition.
572280	574080	How could we possibly define something
574080	576000	which we don't understand well?
576000	579320	This is the paradox in computer science and philosophy.
579320	580920	The more we seek something,
580920	582920	the more it eludes us.
584000	586440	It sounds almost anti-intellectual, doesn't it?
586440	590080	This idea that we should reject formalization.
590080	592440	But Ken thinks that many phenomena
592440	595920	will only be trivialized by vacant attempts
596000	599680	to formalize them through oversimplification.
599680	602920	Because inevitably, we'll chop off many aspects
602920	605720	which might not be captured by the formalization.
605720	608000	I had always associated Ken's philosophy
608000	610960	with the missing information problem
610960	614080	rather than the representation problem.
614080	615440	The missing information problem
615440	617480	is that we don't know something
617480	620400	or we only know part of the truth.
620400	623760	The representation problem is that we simply don't understand
623760	627480	or at least we can't verbalize what we're experiencing.
627480	630080	Ken says that the corporate world is dominated
630080	634360	by the attempted veneer of objectivity.
634360	637600	If you're trying to land an engineering role in Fang,
637600	642080	your tolerance for ambiguity and subjectivity
642080	643960	is the single most selective feature
643960	646760	of the level which you get hired at.
646760	650720	If you can solve clearly defined problems, you're a level four.
650720	652880	If you can find the problems,
652880	654640	you're a level six.
654640	658800	If you can find the areas, you're a level seven.
658800	662320	And if you can find people who can find the areas,
662320	665400	you're a level eight or a level nine.
665400	668520	I give loads of open-ended tasks to my team,
668520	670360	discover people in the organization
670360	673560	who are subject matter experts in domain X,
673560	675880	build an operating model for knowledge sharing
675880	678160	and standardization.
678160	680320	What does good look like?
680320	682560	It's possible we don't know it yet,
682560	684640	which is the missing information problem.
684640	687920	But it's also possible that we know it,
687920	690040	but we're not able to verbalize it,
690040	691920	which is the representation problem,
691920	695080	inherent with all complex phenomena.
695080	696080	It's quite interesting, actually.
696080	698800	I'm building a code review platform called Merge.
698800	701840	And it's easy to objectify all of the low-level metrics
701840	704920	such as how many customer engineers we support
704920	707560	or how efficiently we're sharing knowledge.
707560	709000	All of the high-level outcomes
709000	711760	like a better engineering culture.
711760	714000	They're emergent properties, right?
714000	715400	It's a bit like pornography.
715400	716800	You know it when you see it.
718960	723160	So now, I give you Professor Ken Stanley.
723160	724800	We have a nose for the interesting.
724800	725960	That's how we got this far.
725960	728040	That's how civilization came out.
728040	731000	That's why the history of innovation is so amazing.
731000	734040	Everything washes out when we start ruling by committee.
734040	735480	Like, we have to allow people
735480	737480	to follow their passions to their extremes.
737480	740480	And yet we run society as if this actually
740480	742320	makes any sense at all.
742320	744760	I think the gradient of interestingness
744760	746760	is probably the best expression
746760	749320	of the ideal divergent search.
749320	750440	You get to this problem that, like,
750440	752600	I don't know how to formalize interestingness,
752600	755480	which you get to then are proxies for interestingness.
755480	757680	That not everything that's novel is interesting,
757680	760320	but just about everything that's interesting is novel.
760320	762720	It is in my personality and nature
762720	765600	to want to overthrow this,
765600	767840	I guess we could say, tyranny of objectives.
771480	778480	So today, we have an incredibly special guest.
778480	782480	Indeed, my hero in AI, Professor Kenneth Stanley.
782480	784920	Now, the Kenneth Stanley show that we filmed,
784920	787320	which is to say episode 38,
787320	790120	was my favorite episode that we've ever done.
790120	791160	Reading Kenneth's book,
791160	792480	Why Greatness Cannot Be Planned,
792480	793760	and preparing for that show,
793760	797160	triggered an incredible amount of intellectual growth for me.
797160	798560	And a hallmark of that, you know,
798560	800360	when you learn something profound,
800440	802200	is that you start recognizing it
802200	803760	in many other domains of your life.
803760	805840	I mean, you remember when you learned probability theory
805840	806760	for the first time,
806760	809320	and you started seeing exponential distributions
809320	811000	absolutely everywhere.
811000	812720	So I was just saying to Kenneth
812720	815120	that when we listened back to the show last night,
815120	817360	it was probably the best example ever of a show
817360	818640	we overprepared for,
818640	820560	which is to say that during the interview,
820560	822120	we were just bamboozling Kenneth.
822120	823160	We were so excited,
823160	824920	we almost couldn't control ourselves.
824920	826840	And I think in particular,
826840	829400	Keith and Kenneth reached a common ground, actually,
829400	831680	in the sense that divergence and convergence
831680	833400	don't have to be hyperbolic
833400	835520	or entirely mutually exclusive.
835520	838800	Now, Kenneth thinks that we have a nose for the interesting.
838800	840480	That's how we got this far.
840480	842760	It's the basis of all innovation
842760	845000	and the secret of our society.
845000	848640	Kenneth believes that the concept of deception in search,
848640	850960	which is to say getting stuck in local optimans
850960	852840	and indeed deluding ourselves
852840	855560	that we even know what good looks like in the first place,
855560	858680	is what regularly sends us into brick walls.
858680	862320	Kenneth thinks that institutions are full of gatekeepers
862320	864480	and the gatekeepers only want to see your objectives
864480	865600	and metrics.
865600	869400	Any expert on search would know that it's completely naive
869400	871200	and yet we still use this approach
871200	873600	for the most complex problems in our society.
873600	875320	Committees wash out everything.
875320	878240	We need to let people follow their interests to the extremes
878240	879800	and risk has to be tolerated
879800	881880	in order to make the greatest discoveries.
881880	883640	Anyway, Professor Kenneth Stanley,
883640	886400	it's an absolute honor to have you back on the show.
886440	888160	Thank you for having me here.
888160	889000	So it's been great.
889000	891840	I really enjoyed being on it and I'm glad to be back here.
891840	894160	I mean, even the thing you made in front of that show
894160	895000	was awesome.
895000	897640	That was, I showed that to my son and he was like,
897640	898760	what the heck is that?
898760	900280	He's like, that's not my dad.
900280	901520	And I was like, that is, he's like,
901520	904280	you've never seen me in that kind of environment,
904280	905440	but it was pretty cool.
906480	909120	Oh yeah, so we painted a cafe in behind you,
909120	911600	but we did that first thing in Blender.
911600	913240	But I had to learn Blender just for that.
913240	914920	It was the first thing I ever did.
914920	916680	And what I started doing afterwards,
916680	919040	I wished that we did your show a tiny bit later.
919040	921360	I started using my virtual reality headset.
921360	925560	So I've got an Oculus Quest and then I use Google tilt brush
925560	928040	and then I can kind of create a beautiful 3D environment.
928040	930520	I can put slides and videos and all kinds of stuff up there.
930520	931760	And that would have been perfect for that
931760	933560	because I wanted to show all of the stepping stones
933560	936840	in the divergent search in a 3D environment.
936840	939560	But that's a cool thing is we're getting more sophisticated
939560	940840	and we're starting to use, you know,
940840	942400	manum to do animations
942400	944480	because we want to be able to really kind of,
944480	945920	at least for some of the episodes,
945920	949600	tell the story in a very visual and educational way.
949600	951520	So we're kind of going back now and revisiting
951520	954360	some of our favorite, you know, favorite episodes
954360	956040	and can we tell parts of it again
956040	958800	with this new technology, if you will,
958800	960960	or new techniques that we have skills at.
960960	962520	That's cool, yeah.
962520	964800	I got to tell you, just on a personal note,
964800	966360	because you mentioned, you know, your son saying,
966360	969200	that's not my dad, part of my motivation
969200	972560	for doing these YouTube, you know, shows
972600	974720	is that I want there to be something
974720	977160	where my kids can go maybe when I'm gone or whatever
977160	979040	and look back and say, oh yeah, that was my dad.
979040	980080	That's what he sounded like.
980080	981040	That's what he looked like.
981040	982960	You know, that's how we talk.
982960	984320	It's a really nice thing.
984320	985400	Yeah.
985400	986240	Yeah, yeah.
986240	987160	The problem is no one understands
987160	988120	what we're talking about.
988120	988960	Well, maybe they will.
988960	990160	One of my friends and family,
990160	992160	they say, oh, I tried to watch it,
992160	994960	but I just couldn't understand what you were talking about.
994960	997200	It's so funny because from my perspective,
997200	999960	we're really making things accessible
999960	1001440	and dumbing things down as much as possible.
1001840	1004000	And I still think of myself as completely clueless,
1004000	1005640	but it's quite deceptive, isn't it,
1005640	1007800	that you don't realize you're talking another language.
1007800	1008640	Yeah, it's funny.
1008640	1011200	I mean, my mom, I said, here's this video,
1011200	1012800	and she has no idea what this is,
1012800	1015200	and but she showed her sister who's like eight years old
1015200	1016800	and didn't know anything.
1016800	1019600	And her sister was just like, you know,
1019600	1021560	it seemed like you were really winning in that discussion,
1021560	1023840	even though I have no idea what you're talking about.
1023840	1024680	That's cool.
1024680	1025520	Well, that's good.
1025520	1027800	I mean, at least the tone sounded like I'm winning.
1028760	1030120	Well, yeah, it's kind of funny.
1030120	1031600	Well, speaking of winning,
1031600	1034560	and that's kind of the question I wanted to ask you is that,
1034560	1036040	you know, it's one of those ideas,
1036040	1037560	Tim mentioned these kind of ideas
1037560	1039840	that the first time you hear them,
1039840	1041680	and after you kind of digested them a bit,
1041680	1043320	then you start seeing them everywhere,
1043320	1045560	and you start seeing, you know, connections,
1045560	1046680	connections to it everywhere.
1046680	1049880	And I think your ideas are like that.
1049880	1051480	At least they were for me.
1051480	1054760	And I started come to this line of thinking
1054760	1055960	that I just wanted to ask you about,
1055960	1057800	just to see if it's completely off base,
1057800	1060280	or if there's any, maybe any kind of truth to it,
1060280	1063360	which is, and I know I keep repeating this, Tim,
1063360	1064200	and I apologize,
1064200	1067120	but one of the most beautiful quotes I ever heard
1067120	1070520	was from Claude Shannon many decades ago.
1070520	1073760	I heard this, and he said, you know,
1073760	1078280	we have knowledge of the past, but we cannot change it.
1078280	1082360	We have no knowledge of the future, but we control it.
1082360	1085080	And I realized back then that there's this duality,
1085080	1087760	and it's reflected there in that asymmetry of time,
1087760	1091280	but also in the way I think about science and engineering.
1091280	1093720	So there are the two sides of a coin
1093720	1098080	where scientists use engineering to control
1098080	1100640	in order to gain new knowledge.
1100640	1103240	Whereas engineers take the knowledge that we have,
1103240	1105200	and they use it to gain control, you know,
1105200	1106960	by building a better building,
1106960	1109200	crossing a water stream or whatever.
1109200	1111200	And it's also similar to the exploration
1111200	1114480	versus exploitation, you know, trade-off.
1114480	1117120	And I'm coming around to this way of thinking that,
1117120	1121080	yeah, you know, objectives can be quite harmful
1121080	1124280	when you're in that exploration, you know, phase,
1124280	1125720	trying to learn new knowledge,
1125720	1127640	because just as you point out,
1127640	1130480	who knows what the stepping stones are gonna be like?
1130480	1131560	And all the kind of, let's say,
1131560	1133080	quote-unquote counter examples
1133080	1134240	that I were thinking of before,
1134240	1136760	it's because they fall more in the engineering side of things,
1136760	1139040	which is, okay, look, we have some knowledge,
1139040	1140840	and we do have a very specific goal
1140840	1142840	we're trying to do with that knowledge,
1142840	1145240	you know, build a faster rocket or whatever.
1145240	1147480	And so, yeah, we just go down this kind of very
1147480	1149960	refinement, objective-based kind of goal,
1149960	1151960	but it's really not gonna lead us necessarily
1151960	1154840	to new knowledge or new insight.
1154840	1157780	Is this kind of a fair dichotomy or not?
1158880	1161320	Yeah, I mean, you know, it's nice to keep to hear you're
1161320	1163640	coming around to that way of thinking somewhat.
1163640	1165640	It's like a while, isn't it?
1165640	1166800	Hey, I'm open-minded.
1168120	1173000	It's, yeah, it's interesting to connect to Shannon.
1173040	1175320	That I appreciate and is an interesting connection.
1175320	1179840	And I think the dichotomy is pretty fair,
1179840	1183880	that like in search of discovery,
1183880	1185720	yeah, a lot of engineering principles
1185720	1190720	are not really the best tools for innovation necessarily,
1191200	1193820	especially basic, like basic exploration.
1195120	1199400	And it's true also that it seems like engineering
1199400	1202400	culturally kind of pervades scientific education,
1202440	1203440	at least in some sciences.
1203440	1206120	I don't know, like I only know about my own experience
1206120	1208600	in computer science, but like I was in
1208600	1210960	computer science engineering major at U Penn
1210960	1214520	that was like computer science engineering is like one thing.
1214520	1217120	And so, yeah, a lot of engineering philosophy
1217120	1219000	is like stuck in with the science.
1219880	1224880	And maybe there is like some conflation there,
1226560	1229520	but I also think like another thing to consider,
1229520	1231440	which might be a little bit more out there,
1231440	1235720	and controversial is that I think it's worth
1235720	1238200	questioning whether artificial intelligence
1238200	1239840	really is only science.
1241040	1243200	And is that actually what we're doing?
1243200	1248200	Like a lot of the discussion about AI will come back to,
1249680	1250880	you know, that's not scientific,
1250880	1253800	or does it kind of attack or a way of looking at like
1253800	1257640	an idea where like we can sort of invoke science
1257640	1260240	and slavery to put something down.
1261160	1263440	And, you know, one interpretation is just that,
1264360	1267680	you know, maybe there, it was a good scientific insight,
1267680	1269560	but somebody just missed it or something.
1269560	1271040	They're not seeing the big picture.
1271040	1272520	But another interpretation is that actually
1272520	1275480	this is not science, and it shouldn't be,
1275480	1278240	it shouldn't be caged inside of that,
1278240	1279640	only that way of thinking.
1281160	1283400	And I've actually written about this,
1283400	1285720	was much less received, much less attention
1285720	1287600	when I wrote about it, but I thought a lot about it.
1287680	1289960	Like that in some ways I think AI is,
1289960	1292200	has a lot of connection to art.
1292200	1293800	And I don't mean just in the sense that like
1293800	1295120	you can use AI to generate art.
1295120	1296960	I mean, you can do that, obviously.
1296960	1298520	But I mean, in the sense that like,
1298520	1303040	art is about the reproduction often, not always,
1303040	1305800	but often it's about the reproduction of natural artifacts
1305800	1307120	in an artificial way.
1307120	1308880	Like, I mean, when you paint a picture
1308880	1311440	of like an apple or something, like a still life,
1311440	1314080	and nobody's expecting it to be a real apple.
1314080	1315800	Like that's not the question.
1315800	1318400	And nobody even expects there's necessarily
1318400	1320240	a faithful reproduction of an apple.
1320240	1322560	Or let's say like, you know, Van Gogh's Starry Night,
1322560	1324840	it doesn't look anything like a real Starry Night
1324840	1326720	that I bet anybody on earth has ever seen,
1326720	1328800	even if they're on drugs.
1328800	1330720	And yet, what does it do?
1330720	1332560	What is the value of Starry Night then?
1332560	1334160	Since it's not accurate.
1334160	1336960	Scientifically, it's not a very good job.
1336960	1339120	Well, it actually gives you new insight
1339120	1340680	into something about Starry Night
1340680	1342320	that you hadn't really thought about.
1342320	1344240	And that's what's thrilling about it,
1344240	1346000	is that like it gives you a new perspective
1346000	1348240	on something that you're familiar with.
1348240	1350360	AI is also concerned with the reproduction
1350360	1353040	of natural phenomena in artifice.
1353040	1354320	It's the same thing.
1354320	1357840	And in a similar way, like an algorithm is,
1357840	1359640	I think it's just another way,
1359640	1362560	it's kind of like another painting.
1362560	1364520	It's just a painting that's expressed
1364520	1365880	rather than through brush strokes,
1365880	1367920	it's expressed through code.
1367920	1369200	But if you look at it that way,
1369200	1371120	you can understand that like,
1371120	1373000	it can be an interpretation of nature
1373000	1374440	without being accurate.
1374440	1376040	And that can still be valuable
1376040	1378120	just as Starry Night is valuable.
1378120	1380600	And the reason it can be valuable back to science
1380600	1382160	is because some of the thoughts it gives you
1382160	1383160	will be stepping stones
1383160	1385400	that then lead back to scientific insights.
1385400	1387960	So we're straddling between science and art here.
1387960	1388800	But the thing is,
1388800	1391320	it's not necessarily a harmful thing to do.
1391320	1395120	And so we should actually consider whether,
1395120	1397200	like to the extent that an algorithm actually
1397200	1398560	is an artistic inspiration,
1398560	1400920	which I think a lot of what I was doing was,
1400920	1402640	like when I was building things like Neat,
1402640	1404040	I was inspired by like,
1404040	1406040	the increases in complexity in nature.
1406040	1407640	I was never under the delusion
1407640	1409560	that Neat is an accurate depiction
1409560	1411640	of how evolution works in nature.
1411640	1413560	But it's kind of an ode to nature in a way,
1413560	1415480	like the way a painting might be.
1415480	1418000	But it's never discussed in that way.
1418000	1420960	You said in your presentation last time
1420960	1424720	that you were becoming a little bit more radicalized
1424720	1427240	because you were doing it to not computer scientists,
1427240	1430080	artists, and all of a sudden they were saying to you,
1430080	1431480	oh my God, Kenneth, like,
1431480	1433000	finally, my parents keep saying to me,
1433000	1433920	why are you doing art?
1433920	1435200	Why are you wasting your time?
1435200	1436400	And now I understand,
1436400	1437880	now I actually have a sense of purpose,
1437880	1439200	it means something.
1439200	1440680	And I think what you were saying a second ago,
1440680	1441680	because it's quite interesting you said,
1441680	1442880	or a starry night.
1442880	1445400	And you could say that's a kind of model
1445400	1446680	or a kind of representation.
1446680	1449000	But is it fair to say that you're actually more interested
1449000	1452120	in analogizing the process itself?
1452120	1455760	Like analogizing the process of discovery in AI with art.
1455760	1457160	Is that what you mean?
1457160	1458000	Yeah.
1458000	1459800	I think there's an analogy between art and AI.
1459800	1461040	It's more than just process.
1461040	1462800	It's like, it is a branch of art.
1462800	1466720	Like it's literally about like reproducing natural phenomena
1466720	1468800	in artifice, which is what artists do.
1469880	1471880	The difference is that the,
1473400	1476440	the, I mean, art is, you know, you might say it's like,
1476440	1477800	there's more of an aesthetic emphasis
1477800	1481040	or something in art, but I mean, that's just a choice.
1481040	1483520	I mean, that's what we're doing in AI.
1483520	1484720	We're interested in,
1484720	1486640	so one exception I should say for the artists
1486640	1489160	who are listening, which are probably few,
1489360	1491320	but I want to acknowledge that that's not the only thing
1491320	1492520	that art is concerned with.
1492520	1494200	When I wrote about this, I actually,
1494200	1495320	I wrote a paper on this.
1495320	1497560	It was one of the weirdest things I did
1497560	1499600	because I actually went to like a real library
1499600	1501560	and was researching art history and things like that.
1501560	1504640	I felt like a real like scholar or something in the library.
1504640	1507920	But so I got a lot of, I got some criticism from artists.
1507920	1509400	And like one of the things they were pointing out was that
1509400	1511120	it's not always about the reproduction of nature.
1511120	1513360	Like there's some modern art that has nothing to do
1513360	1514400	with reproducing anything.
1514400	1516160	It's just about like the pure aesthetics.
1516160	1518960	So let's just acknowledge that that's not all art is about.
1518960	1522240	But much of art throughout art history has been about that.
1522240	1524560	It's certainly a part of art is to reproduce
1524560	1525920	natural phenomena and artifice.
1525920	1527800	And that's what art AI is.
1527800	1529120	So it's not just a connection.
1529120	1530640	I think it is art.
1530640	1532560	It's just that we're not willing to discuss that side of it
1532560	1535400	because we're very proud of ourselves for being scientists.
1535400	1537120	It makes us feel good about ourselves.
1537120	1538800	But the reason I started thinking about this
1538800	1542200	is because I was getting in some arguments with people
1542200	1545360	where the kind of the crux, the breaking point
1545360	1546840	where they tried to basically stop it
1546840	1548600	and say this is the end of the argument
1548600	1552600	was basically to say that what I was saying was not scientific.
1552600	1554160	Or like this is not a scientific question.
1554160	1556640	It can't be objectively analyzed.
1556640	1558080	You can't get an objective,
1558080	1560560	you can't get falsification on this question.
1560560	1562400	So it's basically not subject to debate.
1562400	1564640	Like let's not talk about it because it's pointless.
1564640	1566800	And I felt like that is just pure cowardice.
1566800	1570160	Like we are, you are just saying you are afraid to inquire
1570160	1572920	in directions where you don't know how to falsify.
1572920	1574360	To me that's just cowardice.
1574360	1577160	And I do not like associating science with cowardice.
1577160	1581320	And I started thinking about, am I really doing science?
1581320	1583320	Like maybe there's another few here.
1583320	1585680	I don't know that I was like fully just trying
1585680	1590160	to create generate hypotheses and validate or falsify them.
1590160	1593560	There's an artistic side to I think creating these algorithms.
1593560	1595520	And I think it might be healthy to acknowledge that.
1595520	1597480	It's interesting to think about.
1597480	1601440	I think your frame of reference doesn't seem to fit
1601440	1603400	into the paradigm of science in so many ways.
1603400	1605280	And I remember you said on the show last time
1605280	1608720	that you were exasperated that pickbreeder was not recognized
1608720	1610560	as being scientifically useful.
1610560	1614160	And there was another convergent committee version
1614160	1616080	of pickbreeder and then the images just looked
1616080	1617840	like wallpaper backgrounds.
1617840	1621560	But to your point before, I kind of agree with you
1621560	1625080	that when you look at what happens in the process of art,
1625080	1627160	it seems very intelligent.
1627160	1630560	But I'm trying to understand where the intelligence lies.
1630560	1633880	Because I'm interested in the idea of it being embodied,
1633880	1636760	for example, and an emergent phenomenon.
1636760	1640000	So clearly when human beings collaborate together
1640000	1642680	in this divergent way, that's something very interesting.
1642680	1646800	But what would happen if the agents producing the art
1646800	1650000	were much less intelligent than humans?
1650000	1654280	Do you think that could still lead to a kind of intelligence
1654280	1655880	at a larger scale?
1656960	1659840	Yeah, and I just will also like preface
1659840	1662040	by just saying that I'm not against science.
1662160	1664160	I do like being associated with science.
1664160	1666440	I don't want to be the out-characterized as an artist
1666440	1667720	only.
1667720	1670200	I just think that we're straddling both here.
1670200	1672800	And the mechanisms of science clearly
1672800	1674200	have served us well in many cases.
1674200	1676560	So I don't want to be associated with kooky views
1676560	1679000	that we should get rid of science or something like that.
1679000	1680480	I just think it expands our horizons
1680480	1683720	to understand what we're doing and how it relates to art.
1683720	1686240	And also just before to answer the question,
1686240	1687680	I think it's also important to note
1687680	1689520	that I'm not just making the generic point
1689520	1692560	that there's an aesthetic aspect to science, which
1692560	1694600	people have written entire books about.
1694600	1696680	People have pointed out before, not me,
1696680	1698840	but there's famous books that have
1698840	1703360	been written about how science has an artistic side,
1703360	1706120	like an artistic inclination can help you as a scientist.
1706120	1709120	I mean, this is not new to point these things out.
1709120	1711160	But I'm trying to make a much more literal point
1711160	1714680	that AI itself, specifically AI, with the word artificial
1714680	1718920	in front of it, is really about art in a strong way.
1718960	1721400	And this is what has not been acknowledged.
1721400	1723600	This point has also come up in mathematics.
1723600	1726440	And for the life of me, I can't think of whether it was
1726440	1728720	Penrose or maybe even Gauss or somebody,
1728720	1731920	but a legendary mathematician made this point.
1731920	1734200	They were bemoaning the fact that there wasn't
1734200	1737120	more creativity in mathematics.
1737120	1739920	Because if you look at some of the greatest achievements
1739920	1742520	of mathematics, they were these things that were created
1742520	1748800	that were entirely new, like calculus from Leibniz
1749480	1750320	or Newton, right?
1750320	1752800	I mean, just these new creations, new ways of thinking
1752800	1755240	about things that were really inspired
1755240	1757320	from a more artistic sense.
1757320	1760080	And he was making the same point that like,
1760080	1761320	that's mathematics.
1761320	1763040	And to kind of say like, well, no,
1763040	1766080	if it doesn't have a certain level of rigor,
1766080	1767400	it doesn't approach mathematics.
1767400	1770440	Well, in order to get to those forms of rigor,
1770440	1772280	you first have to have that stepping stone,
1772280	1776600	that inspiration that generates something brand new.
1776600	1778640	And I gotta figure this out,
1778640	1781160	but I forget who it was and they made this point.
1781160	1784000	So if it applies even to mathematics,
1784000	1785720	it has to apply also to things
1785720	1787760	that are more grounded in reality.
1787760	1790200	So I think your point completely stands.
1790200	1795200	And it is sad that people tried to dismiss it as,
1795760	1798480	well, that's not science or that's not mathematics.
1800920	1802200	There's an interesting response.
1802200	1803680	There's a good, it's not science.
1803680	1805720	Like, I wonder where that leads exactly.
1805720	1807880	It's like, I'm not pretending to be talking about science.
1807880	1809280	Like, it's still so we should discuss.
1809280	1812520	Good, it's not already known, I'm doing something new.
1812520	1813360	Yeah.
1814760	1817480	So where does the intelligence lie?
1817480	1819720	I think was where I was getting at.
1819720	1821720	I'm really fascinated by this idea
1821720	1825200	that it's not in the brain that it's in the process.
1825200	1827640	And I think your ideas are going in that direction.
1827640	1829080	Yeah, I remember your question.
1829080	1834080	Yeah, yeah, so like, if there was a less intelligent
1834760	1838680	kind of move towards our less intelligent type of agent
1838680	1841800	that was involved in an artistic evolution,
1841800	1844600	like what would be the quality of that?
1845920	1850720	Yeah, I think, I do think it's possible for there to be
1850720	1855720	artistic, it's complicated because like art is subjective.
1855720	1858080	I mean, we're making it for ourselves.
1858080	1861400	So like, if there were things that aren't us
1861400	1862880	that are doing something artistic,
1863280	1864880	presumably they're making it for themselves.
1864880	1867400	So it might not be interesting to us.
1867400	1870360	I'm not sure it would, it might be interesting to us,
1870360	1873480	but it would be a process worth paying attention to
1873480	1875920	in some way, I do believe that,
1875920	1880920	because it would have these properties of trends
1881440	1885200	and stepping stones and like an evolutionary process,
1885200	1887960	like a phylogeny would result from that.
1887960	1889680	Whether it's of interest to us is,
1889680	1891560	I mean, just the artifacts themselves,
1891560	1894480	I'm not totally sure that they would be.
1894480	1897280	Cause a lot of, I mean, art does often reference things,
1897280	1899840	like I said, in nature, cause that's what our experience is.
1899840	1902520	I mean, if you have no experience of nature,
1902520	1904560	art can't be about that then.
1904560	1905520	So what is it about?
1905520	1907280	And it could be about other things,
1907280	1908480	just mathematical relationships.
1908480	1911480	Some small subset of art is, like I said,
1911480	1913400	like I mean, some modern art has nothing to do
1913400	1915400	with referencing anything in the world.
1918000	1920440	So maybe some people would appreciate that,
1920440	1921760	but even those things seem to relate
1921760	1923920	to some emotional resonance or something like that.
1923920	1927200	Like these beings may have no emotion.
1927200	1928640	So I don't know where you'd enjoy this,
1928640	1931960	but from a kind of like just like analyzing
1931960	1933320	the process point of view,
1933320	1934480	I think it might be interesting
1934480	1936720	cause there would be such a process.
1936720	1940080	It's so interesting because the rubber meets the road.
1940080	1943440	We're talking about this, all of these brains
1943440	1946000	operating together in this divergent process.
1946000	1948240	And you were just saying that an artist possibly
1948240	1950440	has some kind of phenomenological resonance
1950440	1951760	with a situation.
1951760	1955000	And I'm interested in the kind of continuum
1955000	1957320	between brains and the kind of algorithms
1957320	1958760	we produce in computer science.
1958760	1960520	Because I think we could all agree
1960520	1963160	that neural networks and optimization algorithms,
1963160	1964800	they don't seem very human-like
1964800	1967120	and they certainly don't think the way humans do,
1967120	1970360	even if they can produce intelligent senior behavior.
1970360	1972080	So you really lean into this idea
1972080	1974520	of trusting our instincts and subjectivity.
1974520	1977120	And a cynical reading is that our subjectivity
1977120	1978560	is essentially random.
1978560	1981800	And a random search would be the most divergent search,
1981800	1983760	but that would clearly be rubbish, right?
1983760	1985440	So there must be some kind of continuum
1985440	1987480	between a totally random search
1987480	1989960	and a principled divergent search.
1989960	1993060	So how would you kind of articulate and reason about that?
1994080	1999080	Yeah, it's true that any kind of divergence
1999080	2001640	that pushes too far towards a randomness,
2001640	2003700	I don't think would be interesting.
2004560	2007000	And I don't think that's what artists
2007000	2008960	I don't think that's what human artists are doing
2008960	2011600	because I don't think it would be interesting.
2011600	2014360	It's just that art is,
2015920	2019840	they are really concerned with what's interesting, I think,
2019840	2021520	but without the constraints of science.
2021520	2024760	So it's not supposed to prove something that you're trying
2024760	2026920	to figure out whether it's true or not.
2026920	2029520	It's just supposed to lead to some kind of insight
2029520	2032200	or feeling or something, it depends on the artist.
2032200	2035560	And of course that then points back to things we care about
2035560	2037760	because we're humans and we care about having insights.
2037760	2040560	And of course the things we want to have insights about vary
2040560	2042760	but like generally art that we appreciate
2042760	2045000	like leads you to having some realization
2045000	2047400	that is generally commonly held
2047400	2050280	like that people would agree is interesting.
2050280	2054720	And so artists are exploring that
2054720	2059240	and that leads to other ideas that might not be art.
2059240	2060680	You know, I think, yeah, like a scientist
2060680	2064560	can be inspired by art to think about a phenomenon
2065400	2066960	or somebody else can be inspired architect,
2066960	2068480	obviously many times inspired by arts.
2068480	2070560	There's lots of inspiration that comes out of art
2070560	2071840	if you feel philosophical as well
2071840	2075000	like about like how the world works and what matters.
2075000	2076680	There's plenty of topics to talk about
2076680	2079800	that aren't falsifiable in a scientific sense.
2080840	2083480	And, you know, with AI algorithms,
2083480	2087320	they, I think secretly a lot of the explanation
2087320	2091440	for what has risen and fallen within AI is that,
2091440	2094480	not the actual scientific results.
2094480	2096080	Is that people have resonated.
2096080	2098040	I like that word because that's really about art.
2098040	2100640	It's not, it's not about correctness or accuracy.
2100640	2102000	It's about resonance.
2102000	2104240	And people have resonated with certain algorithms.
2104240	2105880	It's like they just felt it.
2105880	2107400	It got to a point.
2107400	2109360	Well, this is like an artistic realization,
2109360	2111280	not a scientific realization.
2111280	2112880	Like where it resonated with some sense
2112880	2114680	of what intelligence is for you.
2115680	2116920	And it's not like the whole thing.
2116920	2119200	Nobody got the whole deal of intelligence obviously
2119200	2121360	but some part of it like resonates.
2121360	2123840	And that can be extremely inspiring.
2123840	2126160	And I think explains certain like inflection points
2126160	2128360	in the history of machine learning
2128360	2131040	where I think it was resonance really that explains it.
2131040	2131880	Yeah.
2131880	2133440	And I think it's really interesting what you're saying.
2133440	2136520	And I think there's a tendency of some
2137400	2141640	to again dismiss this type of thing as not science,
2141640	2143400	woo woo, you know, whatever.
2143400	2148400	But I think that stems from a being insufficiently Darwinian
2148920	2152400	in the sense that look, whatever's up in our brain,
2152400	2156160	okay, it's the beneficiary of a billion years
2156160	2158000	of evolution, okay.
2158000	2161120	And these insights and intuitions that we have,
2161120	2162680	even if we're not conscious of them,
2162680	2164200	maybe they're not happening at a level
2164200	2167840	that we can analytically break down consciously
2167840	2171320	and think about could still be extremely useful
2171320	2172480	and extremely valuable.
2172480	2174720	And so I have no doubt believing that
2174720	2178040	when a human mind sees an algorithm even,
2178040	2180560	it can perceive some connections
2180600	2183200	to some abstract concepts
2183200	2185600	that have been proven out through evolution
2185600	2187760	as being highly, highly useful.
2187760	2189680	And so you may be seeing those connections.
2189680	2193120	Is that, I mean, does that capture potentially a fair
2193120	2196320	and scientific justification of why we should pay attention
2196320	2199180	to intuition and artistic intuition?
2200360	2202120	Yeah, I think it's fair.
2202120	2205440	I think though I wouldn't only couch it
2205440	2207080	in terms of evolution, I think it's broader
2207080	2208760	than just from evolution.
2208800	2210480	Like it's from our experience also,
2210480	2212240	like experience since you were born,
2213360	2215880	and that's your memories and the feelings
2215880	2217520	that you've had over the course of your life
2217520	2219560	that I think enter into.
2219560	2221120	Of course, just some evolution explanation
2221120	2222840	for how you process those experiences,
2222840	2225120	but the experiences are also part of the background
2225120	2227960	for what you appreciate and find interesting in your life.
2227960	2232000	And yeah, I think that that is, as you say,
2233640	2237560	an important part of the history of ideas,
2237560	2239000	even in science.
2239000	2242560	And what I guess, what's actionable about that though,
2242560	2246960	is that it's interesting to think about the extent to it,
2246960	2251840	we should actually allow or facilitate discussion
2251840	2253840	on this level, not at this meta level
2253840	2255680	that we're talking about, should we do this,
2255680	2258680	but at the level of here is what resonates to me,
2258680	2260400	like about the specific thing.
2260400	2262440	This is why it's interesting, like as a reviewer,
2262440	2266080	like I don't care if it gets like 5% less accuracy
2266080	2267320	on this set, it's super interesting
2267320	2270840	because XYZ, it reminds me of something,
2270840	2274360	powerfully reminds me, like can we have discussions like this?
2274360	2275440	We can't right now.
2275440	2277720	And so it's interesting just to think about that,
2277720	2281440	like would it help to facilitate progress?
2281440	2282720	Would it stymie progress?
2282720	2283880	Because I think most people,
2283880	2286080	their first good instinct is it's bad for progress,
2286080	2289320	because it opens the floodgates of sort of like unregulated,
2289320	2291600	like unempirical type of speculation.
2291600	2293200	We're all afraid of that.
2293200	2295880	But I think we should be cautious,
2295920	2297760	I think we're too afraid of it,
2297760	2299920	and that like we can handle this,
2299920	2301840	because like we actually know about
2301840	2302840	what we're talking about.
2302840	2304960	Like that's the thing that makes this valid.
2304960	2307400	Like it's again, like if it was just some random person
2307400	2308840	on the street, I wouldn't want it to have
2308840	2311400	an aesthetic discussion of algorithms.
2311400	2313680	But if it's experts, I don't understand why we're not allowed
2313680	2316440	to have aesthetic feelings and relating things
2316440	2320080	in like analogizing, things like that seem perfectly fine.
2320080	2321320	We should be able to do, I would say,
2321320	2323480	even if you can't do that, there's a problem.
2323480	2325560	Like why are you an expert?
2325680	2327120	Like if you can't make analogies
2327120	2328680	and actually talk about what's interesting
2328680	2330480	or inspiring about the work.
2330480	2331320	Okay.
2331320	2334080	One thing that I'm wrestling with a little bit here is,
2334080	2336640	I mean, Douglas Hofstadter, the famous Douglas Hofstadter,
2336640	2339600	he once said that he was terrified
2339600	2343280	that AI might be disappointingly simple to mechanize.
2343280	2345840	And I think a lot of the stuff that we're talking about here
2345840	2347560	is, I mean, we're talking about subjectivity,
2347560	2350040	but also we're talking about the externalization
2350040	2351360	of intelligence.
2351360	2354280	So rather than it being encapsulated
2354360	2357440	in an individual brain, a lot of it is emergent
2357440	2361520	and can be thought of as something completely different.
2363720	2366840	I'm concerned about the lack of free will
2366840	2369960	for want of a better, so we've been dealt
2369960	2372680	with the experiences and the environment
2372680	2374040	that we have in life.
2374040	2377240	And to a certain extent, is it still intelligent
2377240	2379840	if our cards are marked?
2380680	2383360	If everything has been mapped out in my life
2383400	2386680	as a function of the environment that I'm in
2386680	2388760	and my life experiences.
2388760	2392160	I guess I have this, just as Douglas Hofstadter did,
2392160	2395120	I have this very fanciful idea in my mind
2395120	2397960	of what intelligence is, that it's infinitely nuanced.
2397960	2400720	And we have this phenomenological experience.
2400720	2405720	And, you know, for example, Hofstadter spoke about Chopin,
2405720	2407520	this beautiful piece of music
2407520	2410040	and what the infinite nuance and subtlety
2410040	2412320	that must have gone through his mind when he created it.
2412360	2416120	And wouldn't it be horrible if that was just the result
2416120	2420640	of quite a simple process that you could define using code?
2422160	2423960	This is an interesting question.
2425120	2428640	I think, yeah, it's clear that there's a movement
2428640	2432200	in machine learning towards that kind of perspective
2432200	2434080	of basically simplicity.
2434080	2435800	And it goes back before deep learning.
2435800	2439440	I mean, people were observing that they say, well, like,
2439440	2441440	you know, cortical circuits like in the brain
2441480	2443880	all share like a huge amount of similarity.
2443880	2446280	It's like, it is possible it's all the same algorithm
2446280	2449840	all throughout and there's just some simple explanation.
2449840	2452680	And then, like, when we see, like,
2452680	2455360	things like really large language models
2455360	2459160	that are basically like uniform architectural structures
2459160	2462200	that just get bigger, it seems to,
2462200	2463800	it seems to point in that direction
2463800	2466680	that like it's not like a bunch of really complex,
2466680	2469040	rich subtlety like going on through the system.
2469440	2472280	We don't know, though, yet, we don't know.
2472280	2474080	I mean, the jury's still out.
2474080	2476400	We haven't actually gotten to human level.
2476400	2480200	And I think that, yeah, and I mean,
2480200	2482520	you can also point to evolutionary processes too.
2482520	2484360	And they're also simple, like there's a simple thing
2484360	2486480	and this explains everything,
2486480	2488560	like it's not really that interesting of a thing
2488560	2490480	in and of itself.
2490480	2492200	I don't, I guess to me it's just,
2492200	2493840	we would like to know the answer to this.
2493840	2495920	Like, can you actually get these things to work
2495920	2497200	through very simple processes?
2497200	2500040	That's probably really important to know,
2500040	2503120	like just in terms of being able to do machine learning.
2503120	2505200	But I don't think for me it would be
2506560	2509440	that disappointing one way or another, I think.
2509440	2512760	Cause I think the subtlety is still in there.
2512760	2514840	It just came in through a different channel.
2514840	2517760	Like, okay, maybe the subtlety is not in the architecture.
2517760	2520040	I personally think there is subtlety in the architecture.
2520040	2523440	That's my guess, like it's not gonna be super simple.
2523440	2525040	But let's say it doesn't have to be,
2525040	2527120	it could be all like uniform.
2527120	2531000	But then, like what you do and what you care about
2531000	2534440	can still be like the constellation of stuff
2534440	2537480	that you learned, which you learned over your lifetime.
2537480	2540720	Like what that amount to, you know, in aggregate
2540720	2544200	can still be, I think, highly rich and subtle
2544200	2546000	in its connectivity.
2546000	2548440	It's just a structure that emerged from a simple process
2548440	2549480	which allowed it to emerge,
2549480	2552140	but then the structure itself is complex.
2552140	2553760	So I don't think it would diminish sort of
2553800	2558400	like the grandiosity of like what we are to me.
2558400	2560160	I could see other people might think otherwise,
2560160	2561640	but it's okay.
2561640	2562960	I don't know what the actual truth is,
2562960	2564640	but that wouldn't necessarily bother me.
2564640	2565960	Yeah, I agree with you.
2565960	2569080	It doesn't decrease the grandiosity of what we are.
2569080	2570400	Consciousness you're talking about?
2570400	2574320	I was surprised that the guy has so much conversation.
2575440	2577520	I didn't realize it struck a chord.
2577520	2579720	I find that I think we don't know
2579720	2581960	what the motivation is behind that tweet.
2581960	2586960	It's, I'm assuming it was meant to provoke conversation.
2587240	2589080	There's no depth in that tweet at all,
2589080	2590480	but it's not because it's dumb.
2590480	2592520	It's because like it's a tweet and there's no room
2592520	2595440	to actually talk about all the complexity of the issue.
2595440	2597720	And so I'm assuming that he's not actually making an argument
2597720	2600560	that he even thinks is like persuasive one way or another.
2600560	2602620	He's just provoking discussion.
2602620	2604320	And as such, I think it's effective.
2604320	2606320	It provoked discussion certainly.
2606320	2607600	It got a lot of discussion going
2607600	2610280	and allowed people to show their cards on this.
2610280	2612400	And I'm actually curious about what people's cards are
2612400	2614880	on this, like people don't talk about this that much.
2614880	2617000	I think it's not, it's not immediately germane
2617000	2618240	to making progress in machine learning.
2618240	2620360	So it's in some ways you might think it was a waste of time
2620360	2623120	because we can't really use this discussion to get anywhere
2623120	2625480	and people are busy trying to publish papers and stuff.
2625480	2627800	But I'm just just personally curious like
2627800	2629640	about what people think in this field
2629640	2631200	because it's obviously relevant
2631200	2632840	like to what we're trying to do.
2632840	2634840	I mean, maybe we connected into quite a lot
2634840	2636400	of the symbolic community.
2636400	2639000	And on LinkedIn, everyone was just posting saying,
2639000	2642120	oh my God, that this hype is getting out of control.
2642120	2644000	The runaway train of deep learning.
2644000	2645880	No, it's like, oh, you're basically just like
2645880	2646720	feeding into the hype.
2646720	2648800	But I could interpret that to be completely independent
2648800	2650440	from deep learning height.
2650440	2651280	Well.
2651280	2652120	It's just basically saying like,
2652120	2654320	is there a threshold that's crossed
2654320	2657740	where there actually is like conscious phenomenon happening?
2658960	2660640	And it doesn't mean that what we're doing
2660640	2661960	is right at all right now.
2661960	2663160	It's still an interesting question.
2663160	2667320	I love it because it is provoking this conversation
2667320	2670920	that we need to be a bit more defined
2670920	2672440	in what we mean by consciousness
2672440	2674040	or at least to think about it.
2674040	2676920	So I thought it was for the purpose that can things
2676920	2678680	which is to provoke conversation.
2680600	2682800	And I will admit it provoked me to tweet something.
2682800	2685280	I actually don't tweet much
2685280	2687000	but I actually tweeted something last night
2687000	2689920	because I just couldn't resist it unconsciousness.
2689920	2690960	What did you tweet?
2690960	2692560	I don't know if it'll upset you maybe.
2692560	2693400	I don't know.
2693400	2694240	Yeah, tell us.
2694240	2695080	Tell us what did you tweet.
2695080	2695920	What's upset him?
2695920	2696760	What did I tweet?
2696760	2698480	I'd have to look at my phone to remember that
2698480	2699600	what I said exactly.
2699600	2700960	Trigger warning, Tim.
2700960	2701800	Be careful.
2703040	2705560	Yeah, so this is actually connected to our discussion
2705560	2707520	in some subtle way here that we've been having
2707520	2709480	because like basically my tweet on consciousness
2709480	2712600	I was pointing out that I noticed
2712600	2714880	like since the original consciousness tweet
2714880	2718160	like a lot of people making off-handed comments
2718160	2721200	basically dismissing consciousness is not a good topic
2721200	2723800	because it lacks an objective measure.
2723800	2726080	This is an easy way to get out of this.
2727040	2728800	And the thing that's being missed here
2728800	2730680	is that is precisely why it's fascinating.
2730680	2732960	Like it is the phenomenon of subjectivity.
2732960	2735120	It cannot have an objective measure
2735120	2737600	unless we're talking about a superficial aspect of it
2737600	2738920	but the interesting aspect of it
2738920	2740840	is the part that's hard to talk about.
2740840	2743640	And so it's literally what it's like from the inside.
2743640	2746200	And so the idea that we cannot discuss that
2746200	2748800	is an interesting idea is exactly the kind of cowardice
2748800	2749800	that I'm talking about.
2749800	2751760	We're using science to block us
2751760	2754600	from exploring something that's uncomfortable.
2754600	2756600	And if science lacks the tools,
2756600	2757720	like if that's what we're saying,
2757720	2761000	it lacks the tools to address consciousness
2761000	2762520	because it is subjective.
2762520	2764680	That's not an indictment of consciousness as a concept,
2764680	2765840	it's an indictment of science.
2765840	2766680	That's right.
2766680	2767520	You've got me there, I must admit
2767520	2769040	that's a very clever response.
2769040	2770160	There's my tweet.
2770160	2771880	Yeah, I don't know how to respond to that
2771880	2774600	but I mean, I personally like to think of consciousness
2774600	2776640	as being the like qualia
2776640	2780160	and the subjective phenomenological experience.
2780160	2782160	And I thought it was a stretch to say
2782160	2784680	that something like GPT-3
2784680	2787920	could possibly have any kind of subjective experience.
2787920	2791080	I find it a stretch that did you have subjective experience?
2791080	2792080	I mean, or did I do?
2792080	2795600	I mean, why a bag of atoms has a subjective experience
2795600	2796440	like qualia?
2796440	2797640	I have no idea why that would be.
2797640	2798760	This is the problem, right?
2798760	2803280	So we know quite a few people and they are so cynical
2803280	2807880	and they argue that intelligence is just a parlor trick
2807880	2809680	that GPT-3 is intelligent
2809680	2811000	and we're not really intelligent.
2811000	2814800	And when we think we're thinking,
2814800	2816720	we're just doing some hash table lookup
2816720	2818240	and it's all a trick.
2818240	2821880	Yeah, I mean, there are people that have argued
2821880	2823840	that consciousness is just like a trick.
2823840	2827640	And we're just confused when we think we're conscious.
2827640	2829480	It's really nothing special going on.
2829480	2830640	Yeah, I mean, if you take that view,
2830640	2832360	then none of this is very interesting.
2832360	2833280	I don't take that view
2833280	2835240	because I believe that there are qualia
2835240	2837760	but that's just a belief I can't prove anything.
2837760	2839080	But then again, how could I?
2839080	2840880	It's a subjective discussion.
2840880	2844440	And so like the real issue at hand here
2844440	2848600	is like whether we think that subjective phenomena are real,
2848600	2850280	like do they actually exist?
2852280	2853880	To me, it's worth discussing
2853880	2856560	even though it's actually outside of the bounds
2856560	2858200	of current science.
2858200	2861040	I don't know any way that we can look at this empirically
2861040	2863400	but I don't find that ambiguity uncomfortable.
2863400	2864240	I think it's interesting.
2864240	2865080	I like things that are ambiguous.
2865080	2866160	That's where we start learning things.
2866160	2867280	I have to hand it to you.
2867280	2868640	You've really got me there.
2870320	2873280	Okay, well, that's good.
2873280	2874120	Yeah.
2874120	2874960	Made a point.
2874960	2876400	Yeah, I mean, part of this,
2876400	2879000	and some of those points are somewhat old.
2879000	2881280	Like the point has been made, I think many times
2881280	2885280	that science is lack of ability to describe consciousness
2885280	2887560	is not an indictment of consciousness.
2887560	2889280	It's an indictment of science.
2889280	2890800	I mean, there's things missing from it.
2890800	2892600	We need to expand it a bit.
2892600	2893920	That you're quoting a tweet there
2893920	2894760	but someone probably said it before.
2895520	2898000	Yeah, it's kind of an old indictment of it
2898000	2903080	but I think what I often see is that people often cling
2903080	2906280	to kind of extreme definitions of things
2906280	2909120	because if they're confronted with a middle ground
2909120	2912080	that's completely reasonable, it's just boring.
2912080	2915480	Like they almost just can't accept that that's the answer.
2915480	2919880	For example, for me, consciousness, from my perspective,
2919880	2923880	it's definitely a pattern of neural activity in the brain
2923920	2925880	and it's probably one that's doing something
2925880	2928000	like analyzing the neural activity
2928000	2931760	of other parts of the brain and or itself and that's it.
2931760	2934440	Like it's, you know, what's the big mystery here
2934440	2937840	but that definition is almost like too easy
2937840	2940040	and too reasonable and then we have to start talking about,
2940040	2943000	yeah, but what does it feel like to be that,
2943000	2944520	you know, that pattern of neurons?
2944520	2946160	And I saw this happen like in a debate
2946160	2951160	between Daniel Dennett and Sam Harris about free will, okay?
2951600	2954320	Where Daniel Dennett is saying, look, to me,
2954320	2958720	free will is the fact that you can evaluate options
2958720	2961360	and you evaluate those options
2961360	2964680	and one path is taken based on that evaluation.
2964680	2966840	So for example, a chess program,
2966840	2969320	if it's evaluating the board possibility
2969320	2971400	and doing a Monte Carlo tree search
2971400	2974760	and it evaluates one as being the best option
2974760	2977640	and it takes that path, that's free will.
2977640	2980800	In other words, it's freedom of parameter space.
2981040	2983360	It's, you know, freedom of options.
2983360	2987120	And Sam Harris' only response to that is like, well, okay,
2987120	2989000	but that's not what people think.
2989000	2992200	Like that's not what somebody on the street says is free will.
2992200	2995880	They think it's this magical thing that, well, who cares?
2995880	2999640	I mean, who cares what people think is surprising?
2999640	3001680	Like there's people that believe all kinds of things
3001680	3004840	that don't have any type of scientific basis
3004840	3006120	or mathematical basis.
3006120	3009800	We find a very reasonable definition of free will
3009800	3013000	that's totally compatible with the reality
3013000	3015560	and the pragmatic experience of free will.
3015560	3018400	And yet because it's surprising to some people
3018400	3021480	or because it's too boring, we just refuse to accept it.
3023560	3027960	Yeah, well, you noted that like people tend to gravitate
3027960	3031120	to extreme positions, it's pretty clear.
3031120	3033120	Politics too, for a lot of reasons.
3034280	3037040	But I also think there's something about human nature
3037080	3039400	where people don't like to say, I don't know.
3040600	3043600	And that's like, it's really interesting, I think,
3043600	3044880	that we don't, we don't admit, we don't know.
3044880	3046880	People respond with certitude to things
3046880	3049040	that we have absolutely no idea about.
3049040	3051600	And I feel like that is much more of the issue
3051600	3054480	with consciousness is that we really don't know.
3054480	3058520	And I disagree with like sort of Dennis' position
3058520	3061240	because it's about, he's claiming to know.
3061240	3064240	And I think that it's actually most courageous
3064240	3066120	just to say, I don't really know what's going on here.
3066520	3068800	The reason I think it's totally reasonable to say
3068800	3072480	we don't know is because look at polarizes all of us.
3072480	3074480	Like this is one of those issues where experts
3074480	3076920	can come out of completely different extremes.
3076920	3078960	And there's no consensus.
3078960	3080080	And like when that's happening,
3080080	3082520	probably nobody knows what's going on.
3082520	3084280	We have not come to consensus yet.
3084280	3087000	And so I think there is something deeper going on here
3087000	3089680	that needs to be addressed and it's not simple
3089680	3092200	and certitude is not the right response.
3092200	3094880	So to me, it's just, I would say I don't really know,
3094880	3097560	but I find interesting to delve into what it is
3097560	3100200	that I don't know, like the details of what we don't know.
3100200	3101320	Cause that's where it gets interesting.
3101320	3102760	There's lots of things we do know,
3102760	3104200	which is what tends to get rehashed
3104200	3105760	when we respond with certitude.
3105760	3107520	Like I know what I know, but I don't,
3107520	3108840	I'm more interested in what I don't know.
3108840	3109800	Well, let me just follow up there.
3109800	3112600	So this was a debate between two extremists.
3112600	3115200	One extremist saying there's no such thing as very well,
3115200	3116520	it's an illusion.
3116520	3118560	And the other one, actually a middle ground,
3118560	3121840	but at least extreme from a certainty perspective,
3121840	3123440	which is saying here's the definition.
3123440	3126520	But the reason why I gravitate towards that position
3126520	3128280	is because it at least provides us
3128280	3130000	with an operational paradigm
3130000	3132640	by which we can do exactly what you're suggesting,
3132640	3134760	which is explore what we don't know.
3134760	3136280	So if we take it as like, okay,
3136280	3138800	here's a working definition of free will.
3138800	3141240	Now let's find all the areas where it breaks down,
3141240	3142880	explore them scientifically.
3142880	3144360	It's at least useful, right?
3144360	3146640	Whereas an extreme position saying,
3146640	3149760	no, nothing is free will, it's an illusion, it's not useful.
3149760	3151360	I can't do anything with that.
3152000	3154640	I think it's quite hard to have a definition.
3154640	3157000	I was challenging one of my friends yesterday, Kenneth,
3157000	3160560	about imagine you wanted to become a billionaire,
3160560	3162800	give me an objective to optimize.
3162800	3165200	And it's really, really difficult
3165200	3167200	because you can start to scratch around
3167200	3170560	and talk about diversity and information, accumulation,
3170560	3172280	all the stuff, novelty, interestingness,
3172280	3174320	but you're really scratching around.
3174320	3175920	And it's the same thing here.
3175920	3179560	We're talking about consciousness and free will.
3179640	3182080	And these are very subjective things.
3182080	3183480	And when Keith was talking about
3183480	3185160	the Dennett-Sam Harris debate,
3186240	3187720	because it's not like free will
3187720	3192000	is about maximizing the expected reward,
3192000	3193920	although perhaps if you created an agent
3193920	3195560	to do such a thing it would,
3195560	3198000	maybe you could tune it to behave in such a way
3198000	3199760	as humans behave.
3199760	3204760	But from my perspective, free will is about the subjectivity
3205080	3208680	and about the agency, those two things.
3208680	3210640	And I can't really describe those two things
3210640	3212920	in any more detail than that.
3212920	3213840	Yeah.
3213840	3217760	Well, one distinction that I think I want to make is that
3217760	3220360	I would separate in my kind of like questioning
3220360	3222880	and thinking free will from consciousness.
3222880	3225360	Like I think it's two different questions for me.
3225360	3227080	I could see why you might want to combine them,
3227080	3228840	but I just think they're different.
3228840	3231160	I've thought much more about consciousness than free will.
3231160	3233360	So on that I think I'm not,
3233360	3234640	I haven't really thought through
3234640	3236760	how to address free will very well.
3237760	3239600	But my consciousness I think,
3239600	3244040	to me it's about the issue that's really problematic
3244040	3246520	is when it comes to like quality and things like that.
3246520	3247640	Like there are other aspects of consciousness
3247640	3249560	we might talk about that I think they're less problematic,
3249560	3253000	but that is very mysterious and I feel unresolved.
3253000	3255080	But in case we're making a general point here
3255080	3257960	about these kinds of discussions and yeah,
3257960	3261280	I think the general points that he's making are reasonable.
3262160	3266720	And so we have David Chalmers coming on the show next month.
3266720	3268840	Oh, I was gonna say, did you read his book?
3268840	3270720	I mean, that's like, now that was a book.
3270720	3274400	I really liked that book because it is about not knowing.
3274400	3276240	The book is basically trying to tell,
3276240	3277080	that's how I interpret it.
3277080	3277920	I'm no philosopher,
3277920	3279480	so maybe I don't even understand what I'm reading,
3279480	3281960	but my interpretation was basically a big argument
3281960	3283960	about why we should admit
3283960	3286080	that we really don't know what's going on.
3286080	3287480	There's very few books like that.
3287480	3290000	I love a good book about not knowing things.
3290040	3291400	I don't know if you guys know that
3291400	3294560	like one of the very first neuroevolution experiments
3294560	3296720	cause I was in the field of neuroevolution was Chalmers.
3296720	3299960	He actually did it long before all this stuff
3299960	3300800	he's famous for.
3301920	3304400	He re-evolved the rules of back propagation.
3305480	3306320	Amazing.
3307560	3308760	Sighted him many times for that.
3308760	3311040	Amazing, he comes up absolutely everywhere.
3311040	3312600	He's such an interesting guy.
3313640	3315880	I wanted to talk a little bit about some of that stuff
3315880	3318520	because there's not a lot of new work
3318520	3319960	in your space at the moment.
3319960	3321760	And I suppose like one way to frame the question
3321760	3325120	is clearly poet and enhanced poet are fascinating.
3325120	3330120	And they are much more divergent than many other algorithms.
3330480	3332600	But are you aware of anything
3332600	3334280	which has been artificially created
3334280	3336240	which is extremely divergent?
3336240	3337680	I mean, more so than poet even
3337680	3339520	or is that currently the state of the art?
3340880	3342960	Well, there are still things going on.
3342960	3346640	Like one place to look is under the name quality diversity.
3346640	3348280	Like you can find a website.
3348720	3350400	I think it's called Quality Diversity Optimization.
3350400	3351560	Unfortunately, the word optimization
3351560	3352360	I wouldn't have put in there,
3352360	3354640	but that's what they're calling it.
3354640	3356160	And that's basically about,
3356160	3358440	QD algorithms are basically about like novelty,
3358440	3359880	like novelty seeking things combined
3359880	3361440	with the notion of quality.
3361440	3363640	And so you can see like the latest there.
3363640	3365800	Like those are divergent at some level.
3365800	3367760	Like almost every paper that there's like 150,
3367760	3369320	I think the last time I looked.
3370200	3373240	But the thing about it is it is not yet connected
3373240	3374440	to the mainstream of machine learning,
3374440	3375960	which is why you're not hearing about it
3375960	3377480	or noticing it as much.
3377480	3378960	That's always been a problem historically.
3378960	3381200	Going back to neuro evolution,
3381200	3383320	it's often evolutionary,
3383320	3384480	but there are some,
3384480	3386720	there is some drift out of that I think recently.
3386720	3389520	Like people have sent me preprints.
3389520	3391640	I think something's gonna come out soon, for example,
3391640	3394080	trying to build on like the idea of poet.
3394080	3395360	And like that are much more kind of
3395360	3398440	machine learning, reinforcement learning oriented.
3398440	3399840	And so there will be things.
3399840	3402280	There's a trickle coming out in that direction.
3402280	3403840	And then now we're seeing like
3403840	3406320	there's open-ended learning symposium workshops,
3406320	3408000	like popping up at mainstream conferences.
3408000	3411520	I know I'm speaking at, I guess, is it iClear, I think?
3411520	3413600	There's gonna be a workshop on open-endedness.
3413600	3417640	And so there's definitely some momentum.
3417640	3420680	I think it's still early and could fizzle out,
3420680	3422280	but you're seeing stuff.
3423440	3425440	But in any case, to the question,
3425440	3429160	do we actually see something more open-ended than poet?
3429160	3430800	I think the answer is no currently.
3430800	3433800	I'm not aware of everything going on, but that's a pretty,
3434800	3437720	like maybe like there's some things
3437720	3438960	that improve on it in one way or another,
3438960	3440680	but I wouldn't call it more open-ended.
3440680	3442880	No, I think that that's a pretty high bar.
3442880	3446880	Like, and there is headroom, I think,
3446880	3449040	to be more open-ended than poet,
3449040	3451560	but it's a high bar, it's really hard.
3451560	3456560	And I think when people see poet, they focus,
3457400	3458360	from machine learning perspective,
3458360	3461840	they focus more on the curriculum learning aspect of it.
3462480	3463560	Like the curriculum learning aspect
3463560	3465160	is like a certain perspective you could have,
3465160	3467280	and you could think about it as like,
3467280	3470160	how do we get something really intelligent
3470160	3473320	for a certain kind of problem that has generality?
3473320	3475160	Like I think about something like that,
3475160	3478200	and this is like give some clues in that direction.
3478200	3480600	But that's not really going towards the part
3480600	3483480	that like inspires me to the open-endedness side of it.
3483480	3485360	You know, what I really wanna see is that
3485360	3488000	it just continues to invent like totally out
3488000	3490120	of the blue crazy stuff forever.
3490120	3492560	And that like seems to get less mind-share,
3492560	3494440	like that kind of question,
3494440	3495960	maybe because it's not very practical,
3495960	3498200	or nobody's really sure what we're even talking about,
3498200	3501240	like what crazy things you actually want to see.
3501240	3503200	But I would, that's the kind of thing
3503200	3506720	where I don't think we're seeing a lot of push or progress.
3506720	3509720	On the curriculum learning, I do think we see things,
3509720	3511800	and they are interesting within that context.
3511800	3513720	Yeah, the curriculum learning thing fascinates me,
3513720	3517600	because I remember talking about, I think, ICML 2019,
3517600	3519200	and he was saying, look on poet,
3519240	3522200	there's an example of an agent,
3522200	3523640	and we have this curriculum,
3523640	3525680	and sometimes we need to kind of shift
3525680	3528880	between a very kind of complex environment,
3528880	3530440	and then back to a simple environment
3530440	3532240	in order to solve this particular problem.
3532240	3534120	But you spoke about generality,
3534120	3537880	and I would still argue that the kind of program
3537880	3540360	learned by poet doesn't have generality,
3540360	3543480	but the process which produced it does.
3543480	3545200	So Francois Choulet has this measure
3545200	3547280	of intelligence conception,
3547280	3550600	and he has this idea of intelligence being a process.
3550600	3552720	So there's like a meta-learning process,
3552720	3554760	and then it can produce skill programs,
3554760	3557080	which can then work in any particular situation.
3557080	3559760	So I mean, is that similar to your mindset?
3561080	3563520	So I agree that it doesn't have generality.
3563520	3564720	That's totally true.
3564720	3567360	It's totally about hyper-specialization.
3567360	3568800	This gets to actually the art aspect,
3568800	3571040	the art discussion we were having before.
3571040	3575480	To me, that is artistically appealing,
3575480	3577720	because it's evocative of nature,
3577720	3581440	where you're not going for a super-generalist in general.
3581440	3585840	Each niche is basically a hyper-specialized niche,
3585840	3590680	which interestingly eventually led to extreme generality,
3590680	3593520	like us, like we have an extreme level of generality
3593520	3594360	in certain ways.
3594360	3595880	Like in certain ways, we're not photosynthetics,
3595880	3597520	we don't have that kind of generality,
3597520	3599600	but we have intelligent generality,
3599600	3601640	but it went through hyper-specialization.
3602760	3604360	If you go back through the ancestry,
3604360	3605760	you're looking at hyper-specialists,
3605760	3606920	not generalists that are trying to become
3606920	3607920	more and more intelligent,
3607920	3609520	like you're looking at things like flatworms again,
3609520	3612240	or not generalists in any sense.
3612240	3614640	Like it's a new reorganization of the body plan.
3615400	3617000	And so I find, first of all,
3617000	3618280	just from an artistic perspective,
3618280	3623280	find the depiction of something that is about,
3624120	3627600	like continually branching and just interesting aesthetically,
3627600	3629240	and something that we should create.
3629240	3631440	Like we should create things that do that.
3631440	3633040	But what I notice is that always,
3633040	3634760	people point to that as a weakness,
3634760	3636160	and say, well, there's a caveat here,
3636160	3638800	it's very specialist-oriented, you know?
3638800	3639920	Why not go for generality?
3639920	3641440	And actually you could.
3641440	3643760	This is like a fairly intuitive notion,
3643760	3645960	that like, yeah, we can get divergent curricula,
3645960	3649480	but try to focus it back down to a centralized point
3649480	3650520	where we're trying to get generality.
3650520	3652560	I mean, I'm not gonna give it exact way you can do that,
3652560	3655120	but this is like an intuitive concept, I think,
3655120	3657080	to think about doing that.
3657080	3659200	But the point I wanna make though is that,
3659200	3662120	look, like some really great kinds of generality,
3662120	3664160	the stepping stones are through specialists.
3664160	3665840	What are we gonna do about that?
3665840	3667360	Like, especially like us.
3667360	3668600	Like you could claim that like,
3668600	3671440	we're just gonna go straight to hypergeneralization.
3671440	3673440	Like that's where we're trying to get our super generalists
3673440	3674600	or something like that,
3674600	3676440	by getting more and more and more and more general.
3676440	3678520	Maybe you're right, like deep learning is magic,
3678520	3680000	like we just add more data.
3680000	3681000	It's not that simple though,
3681000	3682320	because the fact that we're admitting
3682320	3684200	we need a curriculum means we don't have the data,
3684200	3686360	so we have to get it somehow.
3686360	3688960	But you also have to just, there's something interesting,
3688960	3690800	you have to admit there's something interesting
3690840	3694480	about when hyper-specialization actually leads to generalization
3694480	3697080	and this kind of paradoxical stepping stone principle,
3697080	3699200	that the things that don't resemble what you want
3699200	3702160	ultimately are the stepping stones that get you to it.
3702160	3705320	And hyper-specialization is like a really powerful thing,
3705320	3706680	because it allows you to drop,
3706680	3708960	it allows you to make assumptions.
3708960	3710960	Like you can assume something about the environment
3710960	3712320	you're entering before you entered
3712320	3714320	because you're a specialist in that environment.
3714320	3717400	And I think that it can be a disability or a liability,
3717400	3719440	like if you actually go into environments,
3719440	3721720	having no assumptions whatsoever,
3721720	3724200	so you have to be ready for all possible contingencies
3724200	3726560	under the sun, that's what generalization means
3726560	3728160	in a super general sense.
3728160	3730200	Like would you want, you know, airline pilots
3730200	3732560	to like not be sure whether they're flying a stunt jet
3732560	3733760	or a passenger jet?
3733760	3735480	Like they've got to do some checks upfront
3735480	3737520	to see which scenario they're in.
3737520	3739040	Like if you're just a passenger pilot,
3739040	3740680	you don't do those checks.
3740680	3742600	Like you know what you're doing.
3742600	3745480	And so I think there's reason to talk more
3745480	3748000	about this issue of like the specialization of poet
3748000	3750240	is actually an interesting facet of it
3750240	3752280	and not necessarily just like a liability
3752280	3753600	that we have to get around.
3753600	3755680	I've just thought of an interesting connection
3755680	3757480	that hadn't occurred to me before,
3757480	3761360	but there is a link between specialization and divergence.
3761360	3762800	Because if you think about it at a general age,
3762800	3764400	and that's the equivalent of the committee
3764400	3765720	that you hate so much.
3765720	3768560	And what you were just saying with evolution,
3768560	3771600	starting with specialization actually allows you
3771600	3774640	to explore many more interesting stepping stones.
3774640	3776360	But the thing I want to get to you though
3776360	3779080	is intelligence must be specialized.
3779080	3782360	I mean certainly even in conceptions like AIXI,
3782360	3785200	it's framed in terms of being able to perform tasks
3785200	3786480	in certain environments.
3786480	3788360	There's no such thing as general intelligence.
3788360	3789760	So if you were an alien being
3789760	3791480	and you came down to planet Earth,
3791480	3793440	would you really see that much of a difference
3793440	3796720	between our kind of intelligence and photosynthesis?
3798160	3800760	So that is really interesting.
3801960	3804840	It clearly originates from specialization.
3805040	3807120	I don't think you can deny that.
3807120	3811000	The explanatory apparatus are through specialization.
3811000	3812320	Why is it what it is?
3813320	3814920	It's related to the environment we're in.
3814920	3816720	I mean, that must be true, obviously.
3816720	3820600	So it has to do with optimizing within that environment.
3820600	3824280	But I feel like what's going on is something to do with,
3824280	3829040	from that specialization has emerged real generality.
3829040	3833240	I feel like our intelligence is sufficiently general
3833240	3838000	to move outside of anything in our environment at all.
3838000	3840320	It gets to this question where people sometimes say
3840320	3842280	that there are certain things we cannot understand.
3842280	3844800	Like it's impossible, like as human beings.
3844800	3846040	It's usually like, well, why can't we,
3846040	3847480	why would there be things we can't understand?
3847480	3848920	Well, it's like they're just so far outside
3848920	3849760	of our environment.
3849760	3850960	They have nothing to do with anything in the experience.
3850960	3853840	I think, I don't really fall into that yet, but I think,
3853840	3856560	I think we have the capacity to understand literally anything.
3856560	3858640	Well, given enough information,
3858640	3860240	like obviously we can't know about things
3860240	3863040	that we can't actually observe at all.
3863040	3865120	So we don't know those things.
3865120	3866560	But like if I was given information,
3866560	3867880	I believe I could understand the concept.
3867880	3870480	Like I could understand where did the universe come from?
3870480	3874000	If you told me what happened, like I think there is some,
3874000	3876880	it has nothing to do with the kind of situation I come from.
3876880	3879120	But I think I have the capacity to generality.
3879120	3881440	So I think it's really interesting that,
3881440	3884480	that like somehow a degree of generality
3884480	3887760	emerged from this specialization, which goes beyond
3887760	3889680	just being good in this environment.
3889680	3890800	Could I distinguish though,
3890800	3892960	because Jeff Hawkins made this point in his book as well,
3893040	3895400	what's interesting about humans is for the first time,
3895400	3897520	knowledge and genes have been separated.
3897520	3899720	So I completely appreciate what you're saying,
3899720	3902440	that we can understand the universe and everything in it,
3902440	3904120	but our behavioral intelligence
3904120	3906200	is still very much tied to our environment.
3906200	3908400	I don't know whether you're familiar with James Lovelock
3908400	3909880	and his Gaia theory.
3909880	3913560	And he essentially thinks of all life on the planet
3913560	3917240	as being kind of like an ecosystem or a meta ecosystem.
3918240	3921040	So could you think of humans as just being a product
3921040	3923040	of our environment in that same way?
3924320	3928120	Is our intelligence limited by the environment we're in?
3928920	3933760	I mean, we are, I do, our intelligence is,
3933760	3938760	does, it has like some areas where it's more elastic
3939440	3941720	than others, I guess, because of our environment.
3941720	3942560	I think that would be true.
3942560	3944040	Like there's some things that are easier to grok
3944040	3946720	than other things, because the things that are easier
3946720	3950040	to grok are more aligned with where we come from.
3950480	3953440	And so that's like what conceptually we're adapted for.
3953440	3955320	Like things like the difference between the third dimension
3955320	3956720	and the fourth dimension.
3956720	3958640	Like it's easy to reason in three dimensions.
3958640	3960840	It's quite hard to reason in four dimensions.
3960840	3963560	So we just aren't really adapted to that.
3963560	3965240	Does it mean that I can't understand?
3965240	3966760	I don't think it means I can't understand.
3966760	3969960	But it's just not as flexible, it's not as elastic.
3969960	3972040	And so I guess it's going somewhere in the middle.
3972040	3973720	Maybe just a little bit of Keith's going to the middle.
3973720	3976160	I don't, like, yeah, I don't think either extreme,
3976160	3978720	like we were completely specialized.
3978760	3980080	I don't think so.
3980080	3982400	We're like absolutely like generalist
3982400	3984280	in the most like flexible sense.
3984280	3986640	No, we're somewhere in the middle.
3986640	3989200	But I think that the toolbox we have is sufficient,
3989200	3992640	I do believe, to ultimately capture anything.
3992640	3994480	I do think we could do that.
3994480	3998000	Yeah, so I would argue it's probably an open question.
3998000	4001520	I think this may be a case where maybe you're being too certain
4001520	4004800	because when you talk about like these dimensionality things,
4004800	4007840	you know, I know there are many mathematical structures
4008000	4011120	that exhibit very different, you know,
4011120	4014080	fundamentally different behavior and say five dimensions
4014080	4016240	versus six dimensions versus eight.
4016240	4019360	And I think, sure, people have figured that out.
4019360	4022080	And we did that by externalizing that intelligence,
4022080	4024880	writing down symbolics, doing a bunch of equations.
4024880	4027840	But I think it would be fair to say that no human being
4027840	4031280	has ever claimed that they could grok that in their mind.
4031280	4034640	Like they can do it by virtue of this externalized intelligence,
4034640	4038320	but to really hold it in their brain and kind of intuit over it.
4039040	4042800	You know, my guess would be there probably are limitations
4042800	4043760	to what we can do.
4043760	4045200	And that's one of the things that excites me
4045200	4047040	about the potential for HEI.
4047840	4049280	I don't know if we're going to get to it,
4049280	4052480	but if we ever do get to it, it would be really interesting
4052480	4054240	to see what it's capable of.
4055440	4058080	Unshackled by the fact that it, you know,
4058080	4062800	that we evolved in a three plus one dimensional environment,
4062800	4063680	you know, to survive.
4064720	4066320	Yeah, good points.
4066320	4067760	Those are really good points.
4067760	4068880	That's interesting to think about.
4068880	4069600	Yeah, you're right.
4069600	4072880	I hadn't thought of that angle about the AI has this potential
4072880	4073840	to break out of that box.
4073840	4077200	And that is an interesting thing about AGI.
4078320	4079840	So yeah, okay, point taken.
4081520	4084080	Yeah, so I am saying something extreme
4084080	4086080	if I claim that we can understand everything.
4086080	4086800	That is extreme.
4087760	4088000	Right.
4088000	4089520	I guess I'll still stick with my claim,
4089520	4092320	but I might take a lot of effort, I guess.
4092560	4097360	Well, the way I see it, and I think you may be right about this,
4097360	4098640	at least from this perspective,
4098640	4102400	is that it may well be the case that something like,
4103600	4107360	you know, second order logic or category theory
4107360	4110240	or these sorts of logics that we've already discovered,
4110240	4111600	it may turn out to be the case
4111600	4113520	that they're mathematically sufficient
4114080	4117040	to describe any conceivable phenomenon
4117040	4119200	that we'll observe in this universe.
4119200	4121440	And so I guess I would say you could be right
4121440	4125200	that our languages and our methods that we developed
4125920	4127600	kind of externalized from us
4127600	4129600	and something that we participate in
4129600	4132640	have reached this kind of ultimate level of generality.
4132640	4134240	I just think it's a little bit beyond
4134240	4136240	what a single human mind,
4136240	4138160	at least at this phase of our evolution,
4138160	4138960	can comprehend.
4140160	4140720	That's interesting,
4140720	4143760	because that actually starts to go into this issue
4143760	4146000	of what it means to understand.
4146000	4150640	And this debate about do these AIs really understand
4150640	4154000	and yeah, there's like different kind of levels of that.
4154000	4156160	So it's true that when I say like,
4156160	4157120	we can understand everything,
4157120	4158800	it's a little unclear what I mean by understand.
4158800	4161520	Like does it mean just apply the right logical language
4161520	4162960	to describe the phenomenon,
4162960	4165680	even though we don't really get that like flash feeling
4165680	4166800	of like, wow, I really get it.
4166800	4168880	And maybe that, maybe they're right.
4168880	4169920	Maybe that is out of reach.
4170640	4171920	Keith, why don't you just go and look up
4171920	4173360	our definition of understanding.
4173360	4175120	I can give you the definition of reasoning
4175120	4175840	that we came up with,
4175840	4178480	which is the ability to derive new knowledge
4178480	4180240	from existing knowledge and experience.
4181600	4183600	Right, but this reasoning thing is a big thing.
4183600	4185840	Do you know when we say neural networks don't reason?
4185840	4189360	A lot of it has to do with this notion of extrapolation.
4189360	4192080	And people talk about the very geometric notion
4192080	4192880	of extrapolation,
4192880	4196640	but we're talking about being able to execute a function
4196640	4200160	in some logical discrete space.
4200880	4203440	So to be able to take something we know
4203440	4205520	and extrapolate it into a new situation,
4205520	4206720	spoken like Gary Marcus,
4206720	4209200	and I'm sure you've had this conversation with Gary many times.
4211600	4213360	Yeah, Gary has very strong feelings
4213360	4214960	about understanding this, true.
4216320	4219200	Yeah, very interesting feelings about that.
4219200	4221040	So it just took me a bit to go look up
4221040	4223440	because we did have some episode
4223440	4225760	where we were really getting into defining
4225760	4228400	some of these concepts with Gary.
4228400	4230640	Right, and at least here's how I define these.
4230640	4232720	So maybe we get your take on, it could be fun.
4232720	4236080	So it's that reasoning is the act
4236080	4239200	of deriving new knowledge from prior knowledge
4239280	4240480	plus new information.
4242320	4245200	Semantics, a mapping from structures,
4245200	4247520	whether mathematical, logical, symbolic,
4247520	4250720	or other structures to physical reality.
4251920	4255520	And understanding we had as the act of deriving
4255520	4258880	new semantic mappings from prior semantics
4258880	4259760	plus new knowledge.
4260960	4263040	That's esoteric, but that's how we defined it.
4264240	4267280	So understanding is really was the ability to like,
4267280	4268720	okay, if I have a world model
4268720	4270720	that understands something about physics,
4271840	4276800	that like gravity exists and balls roll and whatever,
4276800	4279280	and somebody gives me some new knowledge,
4279280	4283200	which says, hey, this ball is actually hollow.
4284240	4286000	From kind of my understanding of physics,
4286000	4289120	I can now, and I just use the word,
4289120	4292080	because I understand this semantic model
4292080	4293600	and you give me this new knowledge,
4293600	4296320	I can now derive new semantics.
4296320	4299440	I can say, well, the ball is gonna behave now in this way.
4299440	4302400	In other words, I have a new mapping to this physical world
4302400	4303680	because I've gained new knowledge.
4304560	4307440	That's kind of the way in which we perceived understanding.
4307440	4310320	So with like, this was in the context of natural language,
4312000	4313920	you know, processing, let's say,
4313920	4316400	or systems that do that, GPT-3 or whatever,
4316960	4319600	because it doesn't have this semantic model of the world.
4319600	4322880	If you say something like, the beer fell off the table,
4323600	4327040	it may not be able to derive that now the floor is wet
4327040	4329360	and somebody might slip if they fall,
4330160	4332800	that that requires this kind of extra level of understanding.
4334160	4338480	Yeah, and that's filling in the gaps as well.
4338480	4342240	So a lot of NLU people say that the one thing
4342240	4345200	neural networks can't do is extrapolate
4345200	4346880	over the missing information.
4346880	4348000	And that's a great example.
4348000	4350800	So you could reason that we've just knocked the beer off the table,
4350800	4351600	now the floor is wet.
4352320	4355920	So there's a kind of exponential space of missing information
4355920	4357360	that we need reasoning to fill in.
4358000	4363920	Okay, I have to admit that I, it's probably disappointing you
4363920	4366320	because I'm not, I don't really like definitions.
4368880	4372080	I just never find definition discussions engaging
4372080	4373680	are really helpful to me.
4373680	4378160	I really, again, often find that appeal to definition
4378160	4381280	is often just a way of escaping an uncomfortable situation.
4381280	4383520	And I want to go towards the uncomfortable situation.
4383520	4384960	So it's like, we often will say,
4384960	4386960	well, no one's really clearly defined consciousness.
4386960	4389040	Like, first, before I'm going to discuss it,
4389040	4390960	you need to define it to my satisfaction.
4391760	4393840	Well, okay, we're obviously not going to discuss it then.
4393840	4395440	Like, I'll never satisfy you.
4395440	4396320	Right, right.
4396320	4400400	And so it's often in the AI, decades of discussion,
4400400	4401280	what is intelligence?
4402480	4405280	And we see it in open-endedness,
4405280	4407680	we start having a problem, like in this small field,
4407680	4409840	like there's open-endedness workshops that come
4409840	4411360	and like half the papers were just like,
4411360	4415440	what is long pages and pages of definition in terms.
4415440	4417040	It's like, are we going to ever do anything?
4417040	4419280	Or just we're going to argue about this for the next decade.
4419280	4420960	Like, what are we even talking about
4420960	4421920	is what we're going to talk about.
4423040	4426240	And I feel like a lot of this is not necessary.
4426240	4428400	I feel like I can talk about consciousness.
4428400	4430160	I can't define it for you to your satisfaction.
4430160	4430960	I can talk about intelligence.
4430960	4432720	I can make progress on intelligence.
4432720	4434080	I can talk about open-endedness.
4434080	4436000	I don't care really what the definition is.
4436000	4437840	It's just you're going to use it to stop me from talking.
4437840	4440640	So the only thing I'll defend there is that, I mean,
4441680	4443600	I, again, I'm a pragmatist.
4443600	4445760	I believe in defining things to the extent
4445760	4447760	necessary to communicate.
4447760	4450400	And so we have to have, it's kind of like going back
4450400	4455120	to the whole hyper-specialization leading to innovation.
4455120	4457760	If you just have a divergent thing,
4457760	4460160	I think I made this point in our first video,
4460160	4463040	you're just going to end up with a universe of gray goo.
4463040	4465040	Like the really fascinating thing is that
4465040	4467440	because there are these constraints of you
4467520	4470400	need to survive in order to pass on your information,
4470400	4472880	you wind up with this kind of beautiful tapestry
4472880	4475520	of hyper-specialized things that recombine
4475520	4477280	to become more general.
4477280	4479600	And, you know, it's far more interesting than either extreme,
4479600	4484000	like either the gray goo or like the, you know, the nothing, you know.
4484000	4489120	And so as far as definitions go, I think that I don't like
4489120	4492080	to sit there and pedantically argue forever
4492080	4494160	about what the definition of intelligence is,
4494160	4496880	but we need to have enough of a definition
4496880	4498960	that we can make progress in learning
4498960	4501360	and kind of doing scientific discoveries.
4501360	4504720	So things like the beer falls off the table and it's wet.
4504720	4508560	Well, if a system can't figure that out,
4509600	4512640	we notice that it can't figure out kind of a class of things.
4512640	4515040	And that class of things has something in common
4515040	4517360	and then we give it a name and maybe it's understanding
4517360	4518800	or whatever, I don't care.
4518800	4522400	But it's just a way of talking about that class of problems
4522400	4524160	of things that it's not able to achieve
4524160	4526560	because then we can try and figure out how to do that.
4527760	4531040	Yeah, I think that the symbolists, though,
4531040	4535200	that when they come up with formal arguments,
4536000	4538400	it's not, that doesn't come first.
4538400	4541680	They notice that neural networks can't do something,
4541680	4545040	which is to say they can't fill in the missing gaps.
4545040	4548080	And then they come up with a formalism to express why that is.
4548080	4550000	And also, many of these symbolists believe
4550000	4553520	that there are kind of platonic abstractions
4553520	4554640	that exist in the universe.
4554640	4557120	They think that mathematics is discovered, not invented.
4557920	4562000	So that kind of formal apparatus
4562000	4563600	is how they understand the world.
4564800	4567520	Well, I feel like I should try to solidify my attack
4567520	4569200	on definitions since it's obviously
4569200	4571280	fairly, again, radical thing to say.
4573760	4576560	I would acknowledge, like, in the sense that Keith is saying that,
4577440	4578960	again, like, I don't want to be a prank.
4578960	4581040	Like, obviously, you need to define some terms sometimes.
4581040	4582240	Like, that's obviously clear.
4582240	4583280	That should be completely clear.
4583280	4584320	I'm not against that.
4584400	4588160	Like, you know, especially, like, you're gonna derive something
4588160	4590720	and you're writing a paper or you have a certain set of assumptions
4590720	4592480	you need to know what they are, like, in order to prove
4592480	4593760	that it actually is true and not true.
4593760	4596720	If that's what you're trying to do, like, that makes total sense to me.
4597680	4600560	So I'm not a blanket saying we shouldn't have definitions.
4600560	4602640	But I think the thing about definitions that's interesting,
4602640	4605680	like, a lot of things is that there just isn't solid ground.
4605680	4608080	Like, in terms of, like, they're just generally good for you.
4608080	4610480	Like, they can be good for you or they can be bad for you.
4610480	4612320	They can be a tool of clarification
4612320	4614080	or they can be a tool of obfuscation.
4614400	4616160	And it depends how you use them.
4616160	4619040	And I often find them to be tools of obfuscation.
4619040	4621120	Like, especially when we're talking about things we don't know,
4621120	4623040	which is, once again, the problem, which is what I'm interested in.
4623040	4625120	I want to talk about things that we don't know.
4625120	4628640	And that seems where people get really passionate about definitions.
4628640	4630560	So it's like, what does it mean to understand?
4630560	4631840	We don't know. I don't know.
4631840	4634320	What I do know, though, I'm confident there's such a thing.
4634320	4635280	There is understanding.
4635280	4638160	It might be a continuum, maybe it's not just a binary concept.
4638160	4639760	Beyond that, I don't really know what it means.
4640880	4643120	And so I would be interested to talk in depth,
4643120	4644320	like, what does this really mean?
4644320	4645120	Like, let's look at this.
4646080	4648880	But no, we have to, like, we just end up in this, like,
4648880	4650480	a big argument about the definition.
4651440	4653680	And I find that in that case, it's obfuscation,
4653680	4654720	because it's fear.
4654720	4657760	Because really, like, if your whole pitch is,
4657760	4660720	like, your thing that you get a lot of traction on
4660720	4663680	is basically attacking the fact that things don't understand,
4664560	4666240	then you might be a little uncomfortable
4666240	4668640	if we really start dissecting what you mean.
4668640	4670880	And so you should just comment us and just tell us,
4670880	4673040	like, hey, you're not even being clear in your terms.
4673600	4675520	And just stop the argument in its tracks.
4676400	4678240	And that's the kind of definition I don't like.
4678240	4680560	I mean, I'd rather just, like, look, we agree there's,
4680560	4681600	I don't know exactly what it is.
4681600	4682720	You don't know exactly what it is.
4682720	4683680	Let's talk about it anyway.
4683680	4684400	It's uncomfortable.
4684960	4686080	But there is such a thing.
4686080	4686960	That's what we should agree on.
4686960	4688160	Do we agree there's understanding?
4688160	4689680	Like, is there anything that exists?
4690400	4691760	Well, see, that's a problem is...
4693520	4696000	Right, but that's a problem is you can run into some folks
4696000	4697360	that will go that extreme and say,
4697360	4699280	there's no such thing as intelligence.
4699280	4700800	It's all just, yeah.
4700800	4702560	So, but look, I agree with you in principle,
4702560	4705200	which is, again, I like definitions
4705200	4708720	insofar as they're necessary to enable communication.
4708720	4710640	So I'm totally on board with the idea
4710640	4712560	that we need to be talking about things.
4712560	4714640	And that's why I kind of like say
4714640	4716320	the coherence theory of knowledge
4716320	4718000	because it acknowledges, look,
4718000	4720800	we're never going to get to the foundation
4720800	4722880	beyond which there's no other foundation
4722880	4723680	that we can imagine.
4723680	4726240	We just need to understand far enough
4726240	4728720	and define things far enough that we can make progress.
4729600	4731440	So, I'm a little bit...
4731440	4734160	I can completely understand where you're coming from, Kenneth.
4734160	4738480	You think that we have a fundamental fear of the unknown,
4738480	4740720	and we're hiding behind our formalisms.
4740720	4744640	And my only worry is that it seems
4744640	4746400	a little bit anti-intellectual
4746400	4749200	because you can make an observation
4749200	4753520	that an AI model is not behaving the way we are.
4753520	4754960	There's loads of assumptions there.
4754960	4756960	We assume that we are behaving in a way
4757200	4761200	and we are doing things the right way.
4761200	4763520	But then you can say,
4763520	4766240	oh, let's resist any formalism
4766240	4768080	to try and break this down analytically.
4769600	4770560	Do you see the conflict there?
4771360	4772240	Yeah, absolutely.
4772240	4775440	I mean, it's a dangerous position
4775440	4778320	because it's clear that some formalism is necessary,
4778320	4779440	like I tried to concede.
4779440	4781840	I mean, I'm walking a tightrope.
4781840	4784560	So it's not...
4784560	4785760	Yeah, it can't be...
4786480	4788160	I can't make this blanket claim
4788160	4791280	that formalism needs to be completely thrown out the window.
4791840	4794960	That would just destroy my credibility.
4796480	4798320	But the point is...
4798320	4799440	These are just pendulum.
4799440	4800240	These are pendulum?
4800240	4800960	What is the plural?
4800960	4801520	Pendulums.
4802320	4803040	These are pendulum.
4803040	4804480	They swing in different directions.
4804480	4807680	So we become so enamored with this,
4807680	4809120	which is a useful tool,
4809120	4810800	but to the point where it actually becomes
4810800	4812480	like a form of obfuscation.
4812480	4814400	And I do believe definition is like that.
4814480	4817840	Definition is not always and it's not everybody.
4817840	4821120	But a lot of the time when there's an uncomfortable issue,
4821120	4824000	we immediately jump to definition to obfuscate.
4824000	4826640	I think consciousness is one of the greatest examples of that.
4826640	4828720	It's like there's clearly a mystery here.
4829920	4830880	And I agree there are a few people
4830880	4832560	who would disagree there's any mystery at all.
4833200	4835120	But to me, it's clear there's a mystery.
4835120	4837840	Don't need to have a definition to know there's a mystery.
4837840	4839360	We could get into why it's mysterious.
4839360	4842240	That's more interesting to me than what the definition is.
4842240	4844320	But if you jump at me with this definition stuff,
4844640	4846880	you're going to stop me from getting into that.
4846880	4848320	I feel like that's pure obfuscation.
4848320	4850080	This is one of the greatest unknown things
4850080	4853040	in the entire scientific world, like consciousness.
4853040	4854720	It's one of the greatest mysteries of all time.
4855840	4858000	And like so, are you about definitions?
4858000	4859440	Is that really where we're going to go with this?
4860320	4861680	Maybe we don't have a good definition yet
4861680	4863440	because we don't even know what we're talking about.
4863440	4864960	That's part of why it's so mysterious.
4866000	4867280	I think this is quite interesting though
4867280	4868320	because with consciousness,
4868320	4870480	we clearly don't have a mental apparatus.
4871360	4873440	You know, like for example,
4873440	4875520	if someone just took some hallucinogenics
4875520	4879360	and they just had a completely crazy visual experience,
4879360	4881120	they wouldn't have any words
4881120	4883680	or any mental framework to hang this off.
4883680	4885680	Whereas when we're talking about an apparatus
4885680	4887440	to describe intelligent behavior,
4887440	4890720	we absolutely do have an apparatus to hang things off.
4890720	4894640	So I guess, is that a spectrum in your mind?
4897440	4898640	Yeah, there is a spectrum.
4899040	4905280	I would also concede that with consciousness,
4906320	4909280	yeah, it's true that it's much worse for us.
4909280	4910960	It's true because it's ineffable,
4910960	4913200	which is another way of saying you can't put it into words.
4913200	4915520	Like all the things we're discussing have no words.
4916480	4917920	Like the blueness of blue.
4917920	4919440	Like I can't actually describe it.
4919440	4921520	You can't break it down into parts or say what it is.
4922560	4924240	And so that makes it extremely difficult
4924240	4926320	like to actually get into anything formal about it.
4927040	4930080	Whereas intelligence, I would grant that you can,
4930960	4933120	to some extent, like you can actually point to things
4933120	4937760	that can be reduced to words or symbols or formalism.
4938640	4941760	And so it's a little bit better on that slippery slope.
4941760	4944080	It's higher up and less dangerous.
4945040	4947920	But still, I think it's still on a slippery slope.
4947920	4949840	Like there's, I don't think we,
4949840	4952000	although we can talk about intelligence
4952000	4953680	more easily than consciousness,
4953680	4956800	I still don't think we really fully grasp this either
4957520	4960240	or really have the words to really get at what we're talking about.
4960240	4961600	We don't understand ourselves well enough
4961600	4962880	to understand what we're talking about.
4963840	4967600	And so it's, there's still a little bit of this room for obfuscation
4968480	4971600	where we fail to address the mystery itself
4971600	4973920	by just deciding to focus on the definition.
4976160	4979200	Yeah, I mean, I think if we did understand it
4979760	4980960	or had a clear definition,
4980960	4984240	you know, we wouldn't be having so many interesting papers coming out,
4984240	4986320	like on the measure of intelligence.
4986320	4989680	And that was the thing that I liked about Chile's paper is,
4990560	4994240	hey, as long as it's an operationally useful measure,
4994960	4996160	then that helps us.
4996720	4999520	It turns out, while it's kind of a nice framework
4999520	5002080	to think about things, there isn't yet a measure of it,
5002640	5005520	you know, kind of working on that and he's working on that.
5005520	5007840	But again, I love the idea that we just,
5008720	5011040	you know, the goal here, like you said earlier,
5011040	5012800	is really to talk about things.
5012800	5015040	You know, it's to communicate, it's to learn,
5015040	5019440	it's to make progress, it's to explore and to some degree,
5019440	5021280	to make life better, to exploit.
5021280	5025600	But it's all about just doing almost the minimal necessary
5025600	5029840	to enable communication and exploration, I think.
5032000	5033600	Yeah, yeah, yeah.
5033600	5034880	So I totally agree.
5035440	5037440	Like the ultimate point is to explore.
5038240	5043120	And yeah, I just like to go to places that are ambiguous,
5043120	5044800	like on purpose for something.
5044800	5046320	I feel like that's what we're supposed to do,
5046320	5048320	like if we're talking about science or art,
5049440	5051840	those are like the really interesting uncomfortable places
5051840	5052720	where you're going to learn something.
5052720	5054320	It's almost like how in physics,
5054320	5059040	physicists always want to go to where two great theories collide
5059040	5060800	and nobody knows what happens.
5060800	5063040	Like what happens at the surface of a black hole
5063040	5066320	where quantum mechanics and general relativity collide.
5066320	5068560	There's a lot of unknown and ambiguity there.
5068560	5070480	That's where the real progress is going to come from.
5071120	5074480	You're sitting right on the boundary of chaos and order.
5074480	5077200	You're trying to straddle that straddle line.
5077200	5078320	Exactly, exactly.
5079280	5082560	Well, Professor Kenestan, it's always an honor.
5082560	5084000	Thank you so much for joining us.
5085040	5085520	Thank you.
5085520	5086080	That was super fun.
5086080	5086560	Thank you.
5086560	5087200	Thank you so much.
5087200	5087840	Thank you so much.
5087840	5088240	Amazing.
