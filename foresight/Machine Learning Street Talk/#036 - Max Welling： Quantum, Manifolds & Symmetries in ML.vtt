WEBVTT

00:00.000 --> 00:19.920
Qualcomm AI Research is hiring for several machine learning openings, so please check

00:19.920 --> 00:25.200
out their careers website if you're excited about solving the biggest problems with cutting

00:25.200 --> 00:34.960
edge AI research and improving the lives of billions of people.

00:34.960 --> 00:40.880
Today we got to speak with one of our heroes in machine learning, Professor Max Welling.

00:40.880 --> 00:45.600
It was good, the questions were really fantastic actually and I've never done this with the

00:45.600 --> 00:50.000
three of you but having a team of three people asking questions is really, it's a good idea

00:50.000 --> 00:53.920
and of course you're really smart people knowing what you're talking about so that went really

00:54.720 --> 00:59.600
well I think. Needs three brains to match yours. We asked Max some of your favorite questions

00:59.600 --> 01:03.760
from Reddit. Hi Max, when will you be changing your last name to pooling?

01:05.920 --> 01:11.360
Max has pioneered the discipline of non-euclidean geometric deep learning.

01:11.360 --> 01:17.600
So what is actually geometric deep learning? It's the idea of performing deep learning or

01:17.600 --> 01:22.800
machine learning more generally but let's say deep learning on data that is not euclidean in some

01:22.800 --> 01:32.480
sense so not a nice chain structure for audio or a planar structure for images but perhaps a sphere

01:32.480 --> 01:38.000
or graph or something more exotic like some kind of manifold with arbitrary curvature.

01:38.720 --> 01:42.960
You might want to model weather patterns or social interaction data. There are many types

01:42.960 --> 01:48.720
of data out there that are non-euclidean. Actually if you've been playing with graph neural networks

01:48.720 --> 01:54.080
then you've already been doing non-euclidean or geometric deep learning. So to make this work

01:54.080 --> 01:59.680
you just need to abstract some concepts so the euclidean distance or your neighborhood

01:59.680 --> 02:05.360
it becomes a function of connectedness just like on a social graph. Am I connected to John? Does John

02:05.360 --> 02:11.760
know Bob? Simple as that. Actually this kind of abstraction works in many areas of mathematics

02:11.760 --> 02:16.720
which Max will get into today as well as making neural networks work on non-euclidean data.

02:16.720 --> 02:22.000
The other thing that Max has really pioneered is this idea of recognizing symmetries

02:22.000 --> 02:27.440
in different manifolds. So in this blank slate paradigm that we have now in neural networks

02:27.440 --> 02:32.640
we're essentially wasting the representational capacity of the neural network because we're

02:32.640 --> 02:38.560
just learning the same thing again and again. For example in a fully connected neural network

02:38.560 --> 02:43.760
we would have to learn the dog in the top right corner and the top left corner because there's

02:43.760 --> 02:49.200
no translational symmetry. And it was exactly this reason why convolutional neural networks were so

02:49.200 --> 02:55.200
powerful because they introduced this concept of translational weight sharing. So you had this

02:55.200 --> 03:01.520
filter that you could shine over the entire planar manifold and it meant that those parameters could

03:01.520 --> 03:07.280
be reused and you could learn concepts in different parts of the visual field. It was an incredible

03:07.280 --> 03:12.800
breakthrough. Imputing this kind of knowledge into a deep learning model this is called an

03:12.800 --> 03:17.840
inductive prior. It means that we can take some prior knowledge about how things in the world

03:17.840 --> 03:23.360
works and we can impute them into our models. It makes our models more sample efficient and it

03:23.360 --> 03:29.440
makes them generalize better. When it comes to sophisticated inductive priors Max Welling is the

03:29.440 --> 03:35.920
king. When we think about AI and its capability to actually help us to enrich our lives we know

03:35.920 --> 03:42.160
we need to first help machines see and understand like humans do. Take this drone collecting data

03:42.160 --> 03:49.920
in 3D or this autonomous vehicle with cameras covering a 360 degrees view. Current deep learning

03:49.920 --> 03:55.680
technology can analyze 2D images very well. But how can we teach a machine to make sense of image

03:55.680 --> 04:01.600
data from a curved object like a sphere? And because we want this processing to happen on the

04:01.600 --> 04:07.760
device itself for reliability, immediacy and privacy reasons how can we achieve this in a

04:07.760 --> 04:13.280
power efficient manner? It turns out we can do this by applying the mathematics behind general

04:13.280 --> 04:18.880
relativity and quantum field theory to deep learning. Our neural network takes in data on

04:18.880 --> 04:24.560
virtually any kind of curved object and applies a new type of convolution to it. We can move the

04:24.560 --> 04:30.320
shape around and the AI will still recognize it. This is just one example of the exciting research

04:30.320 --> 04:36.480
we're doing at Falkamea research to shape AI in the near future. Anyway it turns out that these

04:36.480 --> 04:42.160
symmetries are absolutely everywhere. If you wanted any further proof of how useful these kind

04:42.160 --> 04:48.000
of equivariants and symmetries and manifolds can be, look no further than the recent announcement

04:48.000 --> 04:58.480
from DeepMind AlphaFold. It will change everything. DeepMind solves 50 year old grand challenge.

04:58.480 --> 05:06.160
The game has changed. So proteins are the structures that fold in a given way. The result

05:06.160 --> 05:13.520
of this year's competition came out and they looked something like this. Namely every entry here you

05:13.520 --> 05:21.840
see is a team participating in that competition of protein folding prediction and there is one team

05:21.840 --> 05:31.120
which is DeepMind's system AlphaFold 2 which completely dominates all the others to the point

05:31.120 --> 05:38.160
where the problem is now considered to be solved. By the way if this is not a great meme template

05:38.160 --> 05:45.040
I don't know what is. Just saying. Just saying. They say a folded protein can be thought of as a spatial

05:45.040 --> 05:53.920
graph. This here attention-based okay. So I'm going to guess for sure that they've replaced this convet

05:53.920 --> 06:00.480
with a transformer style with an attention layer or multiple attention layers. I would guess this

06:00.480 --> 06:04.960
is a big transformer right here. So there was a really interesting article that came out called

06:04.960 --> 06:11.600
AlphaFold and Equivariance by Justas Duparas and Fabian Fuchs. I'm so sorry Fabian I don't

06:11.600 --> 06:16.800
know how to pronounce your name but it does sound like a swear word. Justas and Fabian Etow

06:16.800 --> 06:23.120
comment on the announcement from DeepMind and they said in short this module is a neural network

06:23.120 --> 06:28.400
that iteratively refines the structure predictions while respecting and leveraging

06:28.480 --> 06:34.880
an important symmetry of the problem. Namely that of rototranslations. At this point DeepMind has not

06:34.880 --> 06:40.240
yet published a paper so we don't know exactly how they address this. However from their presentations

06:40.240 --> 06:48.400
it seems possible that part of their architecture is similar to the SE3 transformer. What's the SE3

06:48.400 --> 06:57.440
transformer? Lo and behold our friend Max Welling has had his hands all over it. So in the abstract

06:57.440 --> 07:03.360
it says the SE3 transformer a variant of the self-attention module for 3d point clouds and graphs

07:03.360 --> 07:10.080
which is equivariant under continuous 3d rototranslations. Equivariant is important to ensure

07:10.080 --> 07:15.280
stable and predictable performance in the presence of nuisance transformations of the data input.

07:15.280 --> 07:20.000
Right by the way you might be wondering what SE3 is. Let's have a quick look at the Wikipedia

07:20.000 --> 07:24.960
page. We are getting into group theory which is quite an abstract concept in mathematics but

07:24.960 --> 07:31.840
the Euclidean group which is SE3 it talks about all of the symmetries or the group transformations

07:31.840 --> 07:39.440
that can be applied to Euclidean data to preserve certain properties. Namely let's say the Euclidean

07:39.440 --> 07:43.840
distance between two points. Well these are things like translations and rotations and

07:43.840 --> 07:49.200
reflections. Very interesting that you can kind of abstract one level up in mathematics and that's

07:49.200 --> 07:53.360
what group theory is. The other comment I want to make is that all of these folks are independently

07:53.440 --> 07:57.200
amazing. I've watched presentations by most of them so that there's Fabian Fuchs,

07:57.200 --> 08:04.400
Daniel Worrell, Volker Fischer, fantastic. By the way when we look at Fabian's About Me page

08:04.400 --> 08:09.200
he's a machine learning PhD student at Oxford University. His research topic is learning

08:09.200 --> 08:14.160
invariant representations. Simply put where most of deep learning is concerned with finding the

08:14.160 --> 08:20.560
important information in an input he focuses on ignoring harmful or irrelevant parts of information.

08:20.560 --> 08:25.840
This can be important to counteract biases or to better leverage structure in the data.

08:25.840 --> 08:29.760
Structure in the data that's interesting. That's quite a cool point actually because if you think

08:29.760 --> 08:35.200
about it you could naively if you're doing a vision classifier you could naively just look at

08:35.200 --> 08:39.360
all of the pixels and what they are or if you're being smart about it you go one level up and you

08:39.360 --> 08:44.480
look for the hidden structure in the data and that is precisely what he's talking about things like

08:44.480 --> 08:50.320
the symmetries that are inherent in pretty much every type of data. Okay so one last thing

08:50.320 --> 08:56.880
DeepMind released an official PowerPoint deck on Alpha Fold 2 and it talks about they're on a long

08:56.880 --> 09:02.720
term mission to advance scientific progress. Now here are some of the protein examples. Now they

09:02.720 --> 09:07.200
specifically call out inductive biases for deep learning models where this is exactly what we're

09:07.200 --> 09:13.040
talking about so clearly convolutional neural networks are one such bias which has the translational

09:13.040 --> 09:18.800
weight sharing. It talks about graph networks and recurrent networks and indeed attention networks

09:18.800 --> 09:24.000
which is very much a generalisation of pretty much all of the others. They say that they are

09:24.000 --> 09:29.520
putting their protein knowledge into the model so physical insights are built into the network

09:29.520 --> 09:36.160
structure not just the process around it and these biases reflected their knowledge of protein

09:36.160 --> 09:41.280
physics and geometry and you can see here that there are residues in a protein so they're modelling

09:41.280 --> 09:47.040
topologically which residues are connected to which other residues in this kind of 3d space.

09:47.040 --> 09:51.760
They specifically call out here on the structure model page that they are building a 3d

09:51.760 --> 09:57.520
equivariant transformer architecture so anyway if this doesn't motivate you that symmetries

09:57.520 --> 10:02.640
and manifolds are an exciting idea in deep learning I don't know what will. So clearly Max has been in

10:02.640 --> 10:09.440
this game for a long time now back in 2004 with Kingma he invented the variational Bayes auto

10:09.440 --> 10:16.320
encoder. It's only recently that well relatively recently that Max has been focusing in on deep

10:16.320 --> 10:23.280
learning. Clearly like any other field also machine learning is subject to fashion right and so if

10:23.280 --> 10:29.120
there is a five to ten year cycles where people get really excited about a certain topic either

10:29.120 --> 10:36.800
because the theory is very beautiful or it just works really well. I started in biographical models

10:36.800 --> 10:42.800
and independent components analysis was the talk of the day and the support vector machines and

10:42.880 --> 10:48.320
basically non-parametric methods and then came Bayesian methods and non-parametric Bayesian

10:48.320 --> 10:53.600
methods and now it's all about deep learning. So what you see is that the field is subject to these

10:53.600 --> 11:00.400
sort of fashions and I think it's fine because we zoom in a new very promising tool and then we

11:00.400 --> 11:06.160
work it out and we get the most out of it. Max is a vice president at Qualcomm so clearly he

11:06.160 --> 11:11.520
thinks that computation is going to be absolutely critical for the future of artificial intelligence

11:11.520 --> 11:15.840
but having said that he also thinks that we need to be more efficient with our hardware

11:15.840 --> 11:21.920
tomorrow than we are today. That's just a reality that we all have to accept. So the more compute

11:21.920 --> 11:27.840
we throw at it the bigger we make our models somehow the better they perform and we don't know

11:27.840 --> 11:33.200
precisely why that is but we do know that they will use increasingly more energy to do the

11:33.200 --> 11:38.080
computations for us and at some point that's just not a viable economic model anymore. We'll see a

11:38.080 --> 11:44.080
continuation in making deep learning and machine learning more energy efficient. So there's a really

11:44.080 --> 11:51.200
interesting interplay between priors, experience and generalization. We want to have machine learning

11:51.200 --> 11:57.440
models that generalize really well to things that they haven't seen during training. If you move them

11:57.440 --> 12:03.440
into a new orientation or in a new situation in the context and that's what we think of when we say

12:04.320 --> 12:08.480
artificial general AI which means like not just something you train on one specific topic and

12:08.480 --> 12:12.720
then you ask it to do that and it does it very well but if you then move it into a new context

12:12.720 --> 12:17.760
it just completely fails as narrow AI. So humans are clearly much more flexible if you learn something

12:17.760 --> 12:22.080
in one context and then when you get put into a new context that we've never seen before suddenly

12:22.080 --> 12:28.480
we can still do very well and so we want our agents our artificial agents also to have this property.

12:28.480 --> 12:33.840
Max is also a huge proponent of generative models. He thinks that generative models might be the

12:33.840 --> 12:39.440
future of artificial intelligence so funnily enough I think Max and Carl Friston that we had on a

12:39.440 --> 12:45.040
couple of episodes ago I think they would see eye to eye. Basically what everybody else in the

12:45.040 --> 12:49.360
scientific community does which is write down a model of the world which we call a generative

12:49.360 --> 12:55.440
model which is how do I imagine that the world that I'm seeing in my measurement apparatus could

12:55.440 --> 13:01.680
have been generated by nature. We all have the matrix going on inside our heads. We are running

13:01.680 --> 13:08.640
simulations of reality and we're kind of integrating over the expected value of those simulations.

13:08.640 --> 13:14.080
This is just something that we do all the time. That seems to be the real trick for intelligence

13:14.080 --> 13:21.040
at least in humans so our ability to generate the world. Max also thinks that we need to be learning

13:21.120 --> 13:25.920
causal relationships in our models. Causal relationships have this really interesting

13:25.920 --> 13:32.640
property that they generalize better so Max comes up with this wonderful example of a certain color

13:32.640 --> 13:38.880
of car in the Netherlands might be associated with a higher accident rate but that probably

13:38.880 --> 13:44.160
wouldn't generalize very well to other countries because it's just a colloquialism whereas male

13:44.160 --> 13:49.440
testosterone levels that's a causal factor and that's going to generalize far better to other

13:49.440 --> 13:56.160
countries. So try to figure out what the true physics of the world is what causes what and if

13:56.160 --> 14:01.920
you have this causal structure of the world you understand much more about the actual world

14:01.920 --> 14:06.560
and then if you move it to a new context you can generalize a lot better in this new context.

14:06.560 --> 14:11.680
At this stage Max has bet on so many winning horses that you've got to wonder how the hell

14:11.680 --> 14:18.080
does he do it so we ask him what his secret is. It's incredibly hard to predict what will become

14:18.080 --> 14:22.880
well known. Sometimes you just happen to be working on something that takes off like a rocket.

14:22.880 --> 14:28.800
When we did things like the VAE or graph neural nets it didn't feel at all like this was going

14:28.800 --> 14:35.200
to be a big hit. When we read some of the research from Max's students we were just blown away it

14:35.200 --> 14:40.880
sometimes we've got to just remind ourselves that these are fairly young folks that are in their

14:40.880 --> 14:46.480
early 20s that you know they've just come out of university. How is this even possible?

14:46.560 --> 14:51.280
I've been very blessed with being able even with my industry funding to

14:51.280 --> 14:56.640
provide this level of freedom to the students and I think this is really key.

14:56.640 --> 15:01.440
So one of the things we asked Max was how does he select his research directions?

15:01.440 --> 15:05.440
One of the interesting things is that he's a physicist right so many of the things

15:05.440 --> 15:09.840
that he's been doing are straight out of his operating playbook from the physics world.

15:09.840 --> 15:13.680
So things like symmetries and manifolds and even quantum.

15:13.760 --> 15:19.040
Like symmetries have this this deep feeling right? Symmetries pervade basically all theories

15:19.040 --> 15:24.160
of physics and they have this profound impact on how you formulate the mathematics of a theory

15:24.960 --> 15:29.840
especially when it becomes almost mysterious right? Quantum mechanics is almost mysterious.

15:29.840 --> 15:34.160
How on earth is quantum mechanics possible? The fascinating thing here as we discussed on our

15:34.160 --> 15:40.800
GPT3 episode is that many of these roads actually lead back to computation itself.

15:40.800 --> 15:45.040
How does the brain compute things also feels like a very deep question right? How do we even

15:45.040 --> 15:50.400
compute things? What is computation even and does the universe compute its solution?

15:50.400 --> 15:56.560
What does it mean to be predictable? Can you compute faster than the universe can compute?

15:56.560 --> 16:01.600
One of the key concepts that we talk about in the show this evening is the bias variance trade-off.

16:01.600 --> 16:06.160
Nothing comes for free. There is no machine learning without assumptions. You have to

16:06.160 --> 16:10.640
interpolate between the dots and to interpolate means that you have to make assumptions on

16:10.640 --> 16:16.880
smoothness or something like that. These prior assumptions will help you transfer from one

16:16.880 --> 16:20.960
domain to another domain. One of the topics we've been discussing a lot on machine learning

16:20.960 --> 16:26.720
street talk recently is this notion of how far can we take data-driven approaches?

16:26.720 --> 16:32.560
Will they take us all the way to AGI or is it just like building a tower and trying to get

16:32.560 --> 16:38.880
closer to the moon? Perhaps we could generate more data with data augmentation or even a simulator.

16:38.880 --> 16:43.440
Perhaps we could use data more efficiently with machine teaching or active learning or some kind

16:43.440 --> 16:50.480
of controller on how we train the model but ultimately how far can we really go?

16:50.480 --> 16:56.400
The big question in some sense over time is can we simply take the data-driven approach

16:57.200 --> 17:03.840
and extend it all the way to AGI? So Max tells us about all the different schools of thoughts

17:03.840 --> 17:09.840
in the AI community and of course one interesting school of thought is the likes of Gary Marcus

17:09.840 --> 17:14.320
and Wallyed Subba that we had on the show a few weeks ago. These people think that we need to

17:14.320 --> 17:19.360
have an explicit model of the world. And then on the other side we just want a classical AI

17:19.920 --> 17:23.040
sort of community which is no, no, no, that's going to be ridiculous. You will never be able

17:23.040 --> 17:28.240
to do that. You really need to imbue these models with the structure of the world.

17:28.240 --> 17:34.160
In the show, Max tells us where he's placing his bets but we're not going to spoil the surprise.

17:34.160 --> 17:39.520
So as we said before, Max is extremely well known for creating these inductive priors and

17:39.520 --> 17:43.760
putting them into machine learning models, helping them generalize better and be more

17:43.760 --> 17:50.320
sample efficient. The whole endeavor of machine learning is defining the right inductive biases

17:51.120 --> 17:56.800
and leaving whatever you don't know to the data. If you put the wrong inductive bias into things

17:56.800 --> 18:03.600
we'll, things can actually deteriorate. We talk about Hinton's capsule networks. They tell you

18:03.600 --> 18:11.520
well we'll just keep the abstract nature of what we want which is some stack of things that transform

18:11.520 --> 18:16.480
in some way that we can vaguely specify and then we ask it to learn all these things.

18:17.360 --> 18:22.240
We talk about Professor Kenneth Stanley's Greatness Can't Be Planned book and also

18:22.240 --> 18:28.080
Sarah Hooker's The Lottery Paper. The thing that both of these ideas have in common is that

18:28.080 --> 18:32.400
they posit that we are locked in by the decisions of our past.

18:32.400 --> 18:37.840
And I do feel very strongly that as a field we need to open up. So we shoot value

18:38.560 --> 18:41.440
original ideas much more than we currently do.

18:42.320 --> 18:47.280
So Professor Kenneth Stanley has a fascinating take on this. He thinks that we should be

18:47.280 --> 18:52.400
treasure hunters. We should find interesting and novel stepping stones that might lead us

18:52.400 --> 18:57.120
somewhere interesting. He thinks we should do this in all aspects of our lives.

18:57.120 --> 19:01.280
So we all want to monotonically increase our objectives and what we should be is treasure

19:01.280 --> 19:05.360
hunters. Science should be about exploration not exploitation.

19:05.360 --> 19:10.880
How do we extend this to peer review in science? Ironically having a consensus peer review

19:10.880 --> 19:16.640
encourages groupthink and convergent behavior. If we genuinely want to have an exploratory

19:16.640 --> 19:21.280
divergent process we should almost optimize for people disagreeing with each other in the

19:21.280 --> 19:27.680
peer review process. I think the reviewing in our community is far too grumpy.

19:27.680 --> 19:33.360
I'm continuously amazed when I read these old papers from let's say Schmidhuber and like the

19:33.360 --> 19:39.040
first RL papers that just came up with a bit of an idea and then they had a bit of toy data and

19:39.040 --> 19:43.520
right and that's a paper and it's cool. There's a dichotomy between on the one hand

19:43.520 --> 19:48.960
having a stamp of approval having a paper published and presenting about it and on the other hand

19:48.960 --> 19:55.840
having a continuous stream of research which is peer reviewed online and with some accountability.

19:56.400 --> 20:02.640
Yeah I think we really need to disrupt the field a little bit. Quantum machine learning is a bit

20:02.640 --> 20:09.840
of a mystery to most people I feel including myself and even though I learned something in

20:09.840 --> 20:15.680
this conversation paradoxically it's more of a mystery than before the conversation.

20:16.400 --> 20:22.960
Crucially Max thinks that quantum computing will hugely impact the machine learning world in the

20:22.960 --> 20:29.520
future. So you can think of quantum mechanics as another theory of statistics in some sense right.

20:29.520 --> 20:36.880
Essentially quantum neural networks have nothing to do with particles necessarily or physics.

20:36.880 --> 20:44.720
It's applying the math behind quantum mechanics to machine learning and building neural networks

20:44.720 --> 20:51.520
as layers of functions of these quantum operations that forward propagate some signal

20:52.480 --> 20:58.320
as Max describes really nicely in this conversation. This is the counterintuitive part which is

20:58.320 --> 21:02.320
you can have a probability for an event or an amplitude for an event and then you have an

21:02.320 --> 21:06.720
amplitude for another event and you would think that if there's two probabilities for that event

21:06.720 --> 21:11.360
to happen then the probability of that event should grow but in quantum mechanics they can

21:11.360 --> 21:16.560
cancel and then the probability is suddenly zero that the event happens. So this seems bizarre but

21:16.560 --> 21:24.160
nature has chosen this theory of statistics anyway. I really felt like an ELI 5 here.

21:24.160 --> 21:30.320
Instead of calculating with probabilities you calculate with something like the square root

21:30.320 --> 21:37.520
of probabilities and thus events that can only stack in classical probability theory

21:37.520 --> 21:43.840
can all of a sudden cancel each other out and that gives rise to really interesting math.

21:43.840 --> 21:48.400
We talk about Max's recent quantum paper that just got released and so that was a paper that we

21:49.120 --> 21:54.240
recently pushed on the archive which is quantum deformed neural networks which we basically

21:54.240 --> 21:58.960
first say okay what if we would take a normal neural net and implement it on a quantum computer

21:58.960 --> 22:05.200
and then we slightly deform it into something where states get entangled. So by doing it in

22:05.200 --> 22:09.600
this particular way we could still run it efficiently on a classical computer. What this

22:09.600 --> 22:16.240
paper here did was to build a particular type of neural network of quantum neural network

22:16.720 --> 22:24.720
that can under the correct assumptions be simulated efficiently on a classical computer

22:24.720 --> 22:30.480
but also once we have a quantum computer it can release its full power basically.

22:31.120 --> 22:36.960
If you want to do classical predictions does it actually help to build a neural network that

22:36.960 --> 22:42.480
can run efficiently on a quantum computer that can do these predictions much better. Can you write down

22:42.720 --> 22:50.560
maybe even normal classical problems more conveniently in this quantum statistics.

22:50.560 --> 22:55.520
I found the conversation with Max to be extremely helpful here and he does a great

22:55.520 --> 23:01.520
job of explaining what's going on. Max has another exciting paper out. Probabilistic

23:01.520 --> 23:06.480
numeric convolutional neural networks it's a paper by Mark Finzi, Roberto Bondeson and of

23:06.480 --> 23:10.720
course Max Welling and it looks at what you can do with computer vision models if you move away

23:10.720 --> 23:15.920
from the assumption of discreetly sampled pixel grids and move to a continuous representation

23:15.920 --> 23:21.120
that's more like what an actual object in the real world projected on a screen behaves like.

23:21.120 --> 23:27.920
The observation is when we write down a deep learning algorithm let's say on for an image

23:28.560 --> 23:33.440
then we sort of treat the image as pixels and we think that's the real signal that we are looking

23:33.440 --> 23:39.280
at but you can also ask yourself what if I remove every second pixel now actually I have a very

23:39.280 --> 23:43.440
different neural network but should I have a very different neural network or what if the pixels are

23:43.440 --> 23:50.240
actually quite randomly distributed in the plane it's just some random places where I do measurements

23:50.240 --> 23:55.520
maybe more on the left upper corner and and fear on the left lower corner what the predictor should

23:55.520 --> 24:00.720
behave in a certain consistent way and so of course then you come to realize that really what

24:00.720 --> 24:06.720
you're doing is with a pixel grid is sampling an underlying continuous signal. So to get away

24:06.720 --> 24:11.360
from this assumption of this discreet even sampling they use these objects called Gaussian

24:11.360 --> 24:16.480
processes to model the data and a Gaussian process it's basically a universal function

24:16.480 --> 24:22.080
approximated like in your own network but it gives you a measure of uncertainty and the reason you

24:22.080 --> 24:26.400
might want to do this are many but in short it allows you to average over every possible model

24:26.400 --> 24:31.840
that describes your data and gives you a better result. In doing so you can start to do really

24:31.840 --> 24:37.760
interesting things like subpixel sampling or work with very sparse locations but in order to do that

24:37.760 --> 24:42.320
you need to re-conceptualize a lot of the familiar operators that work on our linear algebra

24:42.320 --> 24:48.160
representations such as like the the convolutional translation operation of our weights. The way

24:48.160 --> 24:53.120
they got around this was super interesting. So there's a very interesting tool which is called

24:53.120 --> 24:59.280
the Gaussian process it's basically interpolates between dots but in places where you don't have

24:59.280 --> 25:05.680
a lot of data you create uncertainty because you don't know what the real signal is. What does it mean

25:05.680 --> 25:11.920
to do a convolution on this space? The most interesting way to describe that is by looking

25:11.920 --> 25:17.600
at it as a partial differential equation. So they reframe this transformation as a differential

25:17.600 --> 25:22.880
equation that could just be parameterized calculated out in a closed form and directly

25:22.880 --> 25:26.560
applied to the parameters of the model that means you don't need to like do any sampling or anything

25:26.560 --> 25:30.000
like that you literally just calculate this thing apply it. It would be worth going into the

25:30.000 --> 25:35.600
differential equation stuff by itself but it gets very complicated very quickly needless to say it

25:35.600 --> 25:41.040
generalizes not just translation but also things like rotations and scaling but the way that they

25:41.040 --> 25:45.280
really did this was by finding very clever representations. It boiled everything down to

25:45.280 --> 25:49.840
normal distributions or almost everything could just be done in closed form which things have been

25:49.840 --> 25:54.160
done with the Gaussian processes in the past but they're typically computationally expensive so if

25:54.160 --> 26:00.000
you can do all these updates without constant re-computation then that's a huge computation

26:00.000 --> 26:04.480
and an advantage. The paper does some really cool things. Some of the benefits are now that

26:04.480 --> 26:09.280
first of all of course you cannot work on a unstructured set of points doesn't have to be a

26:09.280 --> 26:14.960
grid and you can even learn the positions of those points so you cannot direct the observations

26:15.760 --> 26:20.720
in places where you really need to do your observations in order to improve your prediction.

26:20.720 --> 26:26.640
So it turns out that all of this can be remapped back onto the quantum paradigm. I must admit I'm

26:26.640 --> 26:31.680
almost gutted that I didn't study physics at university. Physics seems to be one of the most

26:31.680 --> 26:37.600
robust scientific disciplines and the folks are just so smart because it's really really difficult

26:37.600 --> 26:42.560
and what I notice is that it's very very difficult for external folks to get anything published in

26:42.560 --> 26:47.520
the physics world but there's an asymmetry the reverse isn't true loads of these physicists

26:47.520 --> 26:51.600
are coming into the machine learning world and they're just implementing all of these things

26:51.600 --> 26:57.920
whether it's symmetries manifold topology chaos it's really really interesting to see this unfold.

26:57.920 --> 27:05.040
We also get a take from Max about GPT-3 and so you say GPT-3 isn't very good maybe but it's a

27:05.040 --> 27:11.120
receding horizon right. I had a chat with my old colleague from Microsoft Ilya Karmanov about 18

27:11.120 --> 27:17.440
months ago he introduced me to Max Welling's work it absolutely fascinated me ever since

27:17.440 --> 27:23.360
and guess what Ilya left Microsoft and he went to Qualcomm. Hey Tim how's it going? Ilya is going

27:23.360 --> 27:30.640
great how are you? I'm good different country different job different universe it seems but

27:30.640 --> 27:37.040
I'm doing pretty well. Ilya and I used to be work colleagues at Microsoft UK and I left Microsoft

27:37.040 --> 27:41.760
about a year ago and actually you left as well didn't you Ilya? Yeah we have a joint pact it was

27:41.760 --> 27:48.560
like you have to keep both of us or we leave. Indeed now Ilya and I made a YouTube video

27:48.560 --> 27:54.160
just over a year ago and it was all about Max Welling's work with Tako Kohen all about symmetries

27:54.160 --> 28:00.640
and manifolds and this work was hugely inspiring for me how did you discover it? I discovered it

28:00.640 --> 28:05.840
because my colleague Matthew and I whom you also interviewed and you should follow up with

28:05.840 --> 28:12.960
that. We were at Ilya and we saw Tako's talk about spherical CNNs which was a bit late already into

28:12.960 --> 28:17.360
his work which started with group equilibrium convolutions and I think both of us just thought

28:17.360 --> 28:21.680
it was really cool it was our favorite talk for the day because it was so different and it felt

28:21.680 --> 28:26.720
like it was setting up a different stream of research it wasn't necessarily about chasing

28:26.720 --> 28:32.000
SOTA it was just about really improving taking what makes convolutions great and making them even

28:32.000 --> 28:37.440
better and that was awesome. Oh amazing well we made that video together on Machine Learning Dojo

28:37.440 --> 28:43.040
and I must admit it was hugely inspiring for me and I reached out to Max Welling about two months

28:43.040 --> 28:47.760
ago and he actually came onto our podcast we interviewed him yesterday but yeah it all came

28:47.760 --> 28:51.920
from you and you know you introduced all of this stuff to me and I've been going through some of

28:51.920 --> 28:57.360
Max's work with some of his recent students and it's just incredible it's because he came from

28:57.360 --> 29:02.400
the physics world and all of this knowledge that he has around quantum and symmetries and

29:02.400 --> 29:06.880
topologies and manifolds that's his operating playbook and he's just taken it into the machine

29:06.880 --> 29:11.040
learning world and he's just been executing on it. Max is involved in a lot of papers

29:12.160 --> 29:16.640
as you would expect and a fair few of them are really fascinating. Yeah one of the things we

29:16.640 --> 29:22.080
spoke about was just how he nurtures his PhD students because some of these papers are just

29:22.080 --> 29:26.880
incredible and presumably these students have gone from nothing to producing that level of

29:26.880 --> 29:30.160
research in a very short period of time but presumably this was one of the reasons why you

29:30.160 --> 29:36.960
decided to apply for Qualcomm. Yeah I was chasing something that was publishing papers in the field

29:36.960 --> 29:42.640
of computer vision and it's one of the places in Europe, perhaps Zurich is another location

29:42.640 --> 29:47.120
when you have this kind of research. I thought it was extremely different and a super interesting

29:47.760 --> 29:53.360
research area so to speak to get into. Fantastic and what are you working on at the moment?

29:53.360 --> 29:58.640
We have just submitted actually our paper to CVPR this morning, the deadlines in a few days so

29:58.640 --> 30:03.520
that's pretty good I think and then maybe after that as well we have a few more topics and video

30:03.520 --> 30:08.560
basically self-training, how to improve representation learning, it's a mix of knowledge

30:08.560 --> 30:15.040
distillation and self-training and then also we have some interesting work with radio signals so

30:15.040 --> 30:20.720
it's like video in the sense that it's from that we extract the spatial and temporal signal

30:20.800 --> 30:26.080
but it's extremely different to video and that also makes it super fun. Amazing when I was

30:26.080 --> 30:31.120
discussing machine learning with Ilya at Microsoft we were fascinated by 3d convolution on your

30:31.120 --> 30:36.720
networks and i3d and video action detection and I know you are working on a 3d segmentation and a

30:36.720 --> 30:41.360
whole bunch of cool things like that but anyway I would love to get you on the show in the next

30:41.360 --> 30:44.960
few weeks to talk about some of your research and for those of you in the comments if you want to

30:44.960 --> 30:49.920
have more from Ilya let us know are you going to give us a demonstration of your front lever?

30:50.720 --> 30:55.840
Okay single leg. When Ilya comes on the show properly we're going to be doing a front lever

30:55.840 --> 31:04.080
competition that's pretty good so not only is Ilya a specialist in machine learning

31:04.080 --> 31:09.360
he also absolutely smashes it in the body weight game. No that wasn't smashing it that was after

31:09.360 --> 31:14.320
a climbing session it's actually really cool I met this guy here who's a calisthenics instructor

31:14.320 --> 31:20.240
called Soli and he just started climbing and yeah so we met up and we went climbing this morning

31:20.240 --> 31:24.560
and he was crazy good as you would expect and he gave me some tips on my front lever as well

31:24.560 --> 31:28.640
he was saying I should work more on the tuck instead of the single leg so hopefully you'll

31:28.640 --> 31:33.680
see much better than that in the future. Amazing Ilya thank you so much for coming on the show we

31:33.680 --> 31:39.200
look forward to interviewing you in a few weeks time. Thanks for helping me and thanks a lot for

31:39.200 --> 31:43.600
interviewing Max I'm like super excited to see that in a few days. Anyway I really hope you've

31:43.600 --> 31:48.640
enjoyed the show today this has been such a special episode for us because Max Welling is

31:48.640 --> 31:55.440
literally one of my heroes so anyway remember to like comment and subscribe we love reading

31:55.440 --> 32:00.400
your comments we really do actually we're getting so many amazing comments in the comment section

32:00.400 --> 32:09.280
so keep them coming and we will see you back next week. Welcome back to the Machine Learning

32:09.280 --> 32:15.920
Street Talk YouTube channel and podcast with my two compadres Alex Stenlake and Yannick Kiltcher

32:15.920 --> 32:21.680
and today we have someone who doesn't really need any introduction at all clearly one of the most

32:21.680 --> 32:27.760
impactful researchers in the ML world and has as near as makes no difference 40 000 citations

32:27.760 --> 32:32.640
he's on the executive board at NeurIPS he's a research chair and full professor at the AMLAB

32:32.640 --> 32:39.280
University of Amsterdam and co-director of the CUVA lab and Delta lab Max Welling. Max is a strong

32:39.280 --> 32:43.600
believer in the power of computation and its relevance to machine learning which is one of

32:43.600 --> 32:48.240
the reasons why he holds a vice president position at Qualcomm. He thinks the fastest way to make

32:48.240 --> 32:53.520
progress in artificial intelligence is to make specialized hardware for AI computation. He wrote

32:53.520 --> 32:58.000
a response to Rich Sutton's The Bitter Lesson but essentially agrees with him in the sense that one

32:58.000 --> 33:03.120
should work on scalable methods that maximally leverage compute but Max thinks that data is

33:03.120 --> 33:07.520
the fundamental ingredient of deep learning and you can't always generate it yourself like an

33:07.520 --> 33:12.720
AlphaGo which amounts to an interpolation problem. Much of Max's research portfolio is currently

33:12.720 --> 33:16.480
based on deep learning. He thinks it's the biggest hammer that we've produced thus far

33:16.480 --> 33:21.120
and we witness its impact every single day. He thinks that AGI is a possibility and it will

33:21.120 --> 33:26.240
manifest in a forward generative and causal direction. There's a really interesting cross

33:26.240 --> 33:31.120
pollination story here Max has a physics background he did a PhD in physics he knows all about

33:31.120 --> 33:36.080
manifolds and topologies and symmetries and quantum and actually this has been his operating

33:36.080 --> 33:40.080
playbook he's brought all of these incredible concepts in from the physics world to machine

33:40.080 --> 33:45.200
learning. Now there's a fundamental blank slate paradigm in machine learning experience and data

33:45.200 --> 33:50.720
currently rule the roost but Max wants to build a house on top of that blank slate. Max thinks

33:50.720 --> 33:55.760
that there are no predictions without assumptions no generalization without inductive bias. The

33:55.760 --> 34:00.080
bias variance trade-off tells us that we need to use additional human knowledge when data is

34:00.080 --> 34:04.720
insufficient. I think it's fair to say that Max Welling has pioneered many of the most sophisticated

34:04.720 --> 34:09.760
inductive priors and deep learning models developed in recent years. An example of an inductive prior

34:09.760 --> 34:14.800
is the CNN which means we can model local connectivity, weight sharing and equivalence to

34:14.800 --> 34:20.160
translational symmetries in gridded vision data. This is imputing human domain knowledge into the

34:20.160 --> 34:26.080
architecture it makes the model significantly more robust and sample efficient. Assumptions are

34:26.080 --> 34:30.320
everywhere even fully connected networks assume that there is a hierarchical organization of

34:30.320 --> 34:34.480
concepts and even further assumptions about the smoothness of the underlying function we're

34:34.480 --> 34:40.400
estimating. Max and many of his collaborators for example Tako Kohen took this idea so much

34:40.400 --> 34:44.560
further they introduced rotational equivalence and then they built models which would work

34:44.560 --> 34:51.120
extremely efficiently on non-geometric curved manifolds meshes or even graphs. Max wants to

34:51.120 --> 34:55.920
reduce the need for data in deep learning models increasing the representational fidelity of neural

34:55.920 --> 35:00.720
networks subject to discretization and sampling errors and improving the computational techniques

35:00.720 --> 35:06.640
to process them more efficiently. Max has recently put out two new papers Quantum Deformed Neural

35:06.640 --> 35:11.360
Networks and Probabilistic Numeric Convolutional Neural Networks which we'll be talking about

35:11.360 --> 35:16.720
today. Anyway Max it's an absolute pleasure welcome to the show. Thank you very much Tim for a very

35:16.720 --> 35:25.520
nice introduction it almost sounded like it's not me but it was a lot. Do you feel that this

35:26.160 --> 35:31.920
it describes you not maybe accurately but do you feel like there's a parts of your work that are

35:31.920 --> 35:38.320
overly well known and there may be parts of your work that you wish would be more well known?

35:40.080 --> 35:45.040
It's hard to say it's overly well known because of course it's very enjoyable when you can make a

35:45.040 --> 35:51.120
big impact but what I can say is that it's incredibly hard to predict what will become well

35:51.120 --> 35:55.120
known of course if you could predict that you would only write papers with like gazillions of

35:55.120 --> 36:01.520
citations. When we did things like the VAE or graph neural nets it didn't feel at all like this was

36:01.520 --> 36:08.720
going to be a big hit and some of these things are being singled out and they fly and precisely what

36:08.720 --> 36:14.960
makes these papers fly is in a way that's a big puzzle in a way and some other papers you can be

36:14.960 --> 36:20.720
very proud of and it takes so much time to actually get published it's a huge uphill battle

36:20.720 --> 36:24.800
you think why do the reviewers not understand better but we really want to do here and then

36:24.800 --> 36:29.360
yeah and so they I guess there's a lot of good work which disappears into oblivion

36:29.360 --> 36:36.480
and from many people and yeah it's mysterious but anyway. Your hits definitely seem to be

36:36.480 --> 36:41.760
more than your misses you're a prolific researcher yourself but you've nurtured some of the best

36:41.760 --> 36:46.400
and brightest minds across in not just deep learning but like the wider machine learning field

36:47.120 --> 36:50.800
how do you consistently do that is it fantastic mentorship or is it more

36:50.800 --> 36:56.000
finding the right spark in a student and nurturing that and that's a really good question and I should

36:56.000 --> 37:00.720
say that I've been extremely blessed by all these fantastic students right from the beginning

37:01.520 --> 37:07.760
but I do think there is something to nurturing talent so I think what doesn't work is to basically

37:08.720 --> 37:12.960
tell to be very constrained to a particular topic sometimes you see this happen if you write a

37:12.960 --> 37:18.160
grant proposal and then the grant proposal is about topic A and then really the student

37:18.880 --> 37:22.800
starts at topic A but figures out after a couple of months that they don't really like

37:22.800 --> 37:27.440
topic A and they want to move on to B and it's just very painful then to say no no no you cannot

37:27.440 --> 37:34.080
do that you have to be doing A and so I've been very blessed with being able even with my industry

37:34.080 --> 37:41.200
funding to provide this level of freedom to the students and I think this is really key so the

37:41.200 --> 37:45.520
other thing which I find really key is that the relationship you have with the student is

37:45.520 --> 37:49.840
very important first of all it changes over the years which is also very beautiful so you start

37:49.840 --> 37:56.000
off with much more guidance and towards the end you should actually not be doing any supervision

37:56.000 --> 38:01.440
you should just having a conversation at that point on equal footing and you see about halfway

38:01.440 --> 38:06.800
through a phd like it's like a flower that opens and then it's now they get it suddenly right now

38:06.800 --> 38:12.000
they get it and they go and they have a while huge interesting ideas in all directions and they

38:12.000 --> 38:17.280
can write all these papers and stuff so that's a beautiful moment when that happens and the other

38:17.280 --> 38:23.840
thing I think is that I think of supervision as nudging in the sense that I have a big a lot of

38:24.560 --> 38:31.280
experience and where is where is the interesting stuff to be found right where is the next wave

38:31.280 --> 38:35.840
that we can get people enthusiastic about what are the important questions to address in the

38:35.840 --> 38:41.280
community and things like that so that's where my experience lies now I'm not doing a lot of

38:41.280 --> 38:46.560
coding myself in fact I'm just all doing almost zero coding which I regret for this life and the

38:46.560 --> 38:52.160
other thing is that even in terms of math it's limited right now right but most maybe two pages

38:52.160 --> 38:58.320
of math to verify something or to compute something quickly but not like a lot of math anymore I just

38:58.320 --> 39:04.160
try to keep up with literature mostly and the students do though so they do the hard work

39:04.160 --> 39:08.400
literally so they really should they should do all that work and it's this interesting

39:08.400 --> 39:13.840
relationship where you have a discussion where you say I think you know this is an important

39:13.840 --> 39:18.720
direction an interesting direction and here are some other things which are connected to it very

39:18.720 --> 39:23.440
intuitively right so you may want to look there and then a good student will just pick up these

39:23.440 --> 39:30.160
ideas and we'll run with it and then come up with new ideas and then you could say it is maybe be

39:30.160 --> 39:34.160
careful about this direction don't go too deep or maybe this is more an interesting direction

39:34.160 --> 39:40.400
stuff like that but even there I've learned to be very careful and if a student comes up with a

39:40.400 --> 39:45.680
good idea and intuitively I think that's actually not a great idea this is going to be a dead end

39:46.560 --> 39:51.760
that I'm not going to tell the student that very soon so I'm just going to certainly leave the

39:51.760 --> 39:58.000
student about a month to explore that idea for sure and I've been surprised right I've been

39:58.000 --> 40:02.560
surprised and basically it turned out it was a great idea and I was wrong and so I've been very

40:02.560 --> 40:08.160
careful with these things too so I feel it's a very careful dance between the student and the

40:08.160 --> 40:14.480
supervisor with not too much direction also it's a very personal so some students like more direction

40:14.480 --> 40:19.360
and other students like less direction but I think it is a bit of an art that I've learned

40:20.080 --> 40:24.880
to appreciate it is a little bit of an art to have the right type of relationship with students

40:24.880 --> 40:29.440
yeah but of course it's all about them they are the ones that need to shine in in the end

40:29.440 --> 40:35.680
after four years and they need to get the good jobs and become famous in terms of that guidance and

40:35.680 --> 40:40.560
specifically what you said with respect to this direction might be interesting these are the

40:40.560 --> 40:47.600
interesting research directions is this something that you just have to develop or do you have some

40:47.600 --> 40:54.240
general can you give some high level patterns that you've observed throughout the years where

40:54.880 --> 41:01.120
you see recurring things and and you say oh that's another one of those probably like short term

41:01.120 --> 41:06.400
hypes or yeah have you observed some general patterns there yeah so there's two things right so

41:06.400 --> 41:12.240
there's some things where I think why what is the big deal why is everybody chasing this particular

41:12.240 --> 41:19.280
direction so that's can you predict what the crowd will follow that's one thing seems pretty hard

41:20.000 --> 41:25.920
the other one is to find directions which may be on longer time scales

41:26.960 --> 41:33.520
are impactful and interesting and for the second one it is deeply intuitive and it's very hard to

41:33.520 --> 41:39.760
figure out precisely what it is what features there are but for me I have to get a sense that

41:40.640 --> 41:45.680
there is some something very deep going on that I want to pursue like for instance

41:46.640 --> 41:52.000
so I clearly in physics so if you can think about gauge symmetry like symmetries have this this

41:52.000 --> 41:57.200
deep feeling right symmetries pervade basically all theories of physics and they have this

41:57.200 --> 42:02.720
profound impact on how you formulate the mathematics of a theory and so there's something very deep

42:02.720 --> 42:08.800
about symmetries and and about sort of manifolds and doing things on curved spaces and so that's

42:08.800 --> 42:13.200
I could sort of naturally drawn into this thing not now it's more quantum mechanics and there's

42:13.200 --> 42:18.480
something very deep and especially when it becomes almost mysterious right quantum mechanics is

42:18.480 --> 42:22.880
almost mysterious how on earth is quantum mechanics possible if you dive a little bit into this

42:22.880 --> 42:28.400
phenomenon of there's a two slit experiment where you have these individual photons which which go

42:28.400 --> 42:33.520
over two paths and if it's a wave that's perfectly fine they can interfere with each other but now

42:33.520 --> 42:38.640
these photons can go one by one and somehow they have to be aware of this other possibility that

42:38.640 --> 42:43.600
they could have taken to interfere with that other possibility I just think that's crazy what's

42:43.600 --> 42:48.240
going on here and so I'm naturally drawn into sort of these kinds of mysteries in some sense

42:48.960 --> 42:53.200
yeah and there's plenty more and the other one is also computation clearly right how does the brain

42:53.200 --> 42:57.600
computing also feels like a very deep question right how do we even compute things what is

42:57.600 --> 43:03.680
computation even and does the universe compute its solution what does it mean to be predictable can

43:03.680 --> 43:09.280
you predict can you compute faster than the universe can compute and so there's all these very

43:09.280 --> 43:14.080
deep questions about computation as well that you can ask but there's a mixture between

43:15.040 --> 43:19.680
things that are attractive in that sort of mysterious sense there's something very deep

43:19.680 --> 43:24.880
that needs to be pursued and things which are also highly practical which is sometimes it's also

43:24.880 --> 43:29.360
a lot of fun to work on something that where you can actually make a big impact for instance

43:29.360 --> 43:37.120
speed up MRI imaging with a factor of 10 so now suddenly you can actually both image and

43:37.120 --> 43:42.320
radiate cancer at the same time which could have a huge impact in the future and feeling that level

43:42.320 --> 43:48.480
of impact is also quite exciting I think amazing so I wanted to frame up some of the work that you've

43:48.480 --> 43:54.240
done around symmetries and manifolds it's absolutely fascinating that prevailing idea is that we are

43:54.240 --> 43:57.840
wasting the representational capacity of neural networks because we're essentially learning the

43:57.920 --> 44:04.400
same thing many times and your work absolutely pioneered this starting with sort of rotational

44:04.400 --> 44:10.240
equivariance on on CNNs and then moving on to meshes and graphs and different types of topology

44:10.240 --> 44:15.760
it's absolutely fascinating but philosophically the modus operandi in deep learning is this blank

44:15.760 --> 44:22.000
slate idea this idea that if we look at data and nothing else then we can learn everything we need

44:22.000 --> 44:27.120
to presumably not in a very sample efficient way transformers seems to be going in this direction

44:27.120 --> 44:31.760
in the natural language processing world that we just ingest infinite amounts of data and we can

44:31.760 --> 44:37.440
learn everything we need to and we spoke to a good old-fashioned AI person while it's over

44:37.440 --> 44:42.160
last week and and his argument was that the information is not in the data he was arguing

44:42.160 --> 44:48.080
that we have a kind of ontology or knowledge built into us which we can use to disambiguate

44:48.080 --> 44:53.760
information that we receive so fundamentally speaking do you believe that we can be data-driven

44:53.760 --> 44:58.080
and can you introduce some of the work you've done with some of these priors in deep learning

44:58.640 --> 45:04.160
yes so this is a very fundamental debate clearly but i think it's not all that black and white right

45:04.160 --> 45:09.840
so there is a basically at the core of machine learning there is basically trade-offs the the

45:09.840 --> 45:14.560
buy is very in straight-off for instance it clearly expresses this right the first thing i want to

45:14.560 --> 45:19.920
say there is no machine learning without assumptions it just basically you have to interpolate between

45:19.920 --> 45:24.560
the dots and to interpolate means that you have to make assumptions on smoothness or something

45:24.560 --> 45:28.960
like that so the machine learning doesn't exist without assumptions i think that's very clear

45:28.960 --> 45:34.400
clearly it's a dial right so you can have on the one end you can have problems with a huge amount

45:34.400 --> 45:40.720
of data it has to be available clearly and there you can dial down your inductive biases you can

45:40.720 --> 45:48.000
basically say let that the data do most of the work in some sense and let me make my prior assumptions

45:48.080 --> 45:53.280
quite minimal and with minimal i think i'm interested in a smooth mapping right the mapping

45:53.280 --> 45:58.320
needs to be smooth like that's a very minimal assumption but the disadvantage of that is if

45:58.320 --> 46:05.440
you don't put any prior assumptions is that if you need to take whatever you've learned into a new

46:05.440 --> 46:12.080
domain where this model wasn't learned it will very quickly break down because these prior assumptions

46:12.080 --> 46:19.040
will help you transfer from one domain to another domain and causality does play a big

46:19.040 --> 46:23.760
role here but we can talk about this later and then on the other hand there is basically what

46:23.760 --> 46:28.320
everybody else in the scientific community does which is write down a model of the world which

46:28.320 --> 46:33.600
we call a generative model which is how do i imagine that the world that i'm seeing in my

46:33.600 --> 46:39.680
measurement apparatus could have been generated by nature and and that's that you can put a lot of

46:40.240 --> 46:45.840
intuitive knowledge there because you could think the world is described by a PDE or some kind of

46:45.840 --> 46:51.760
generative model so the people in our community often call this probabilistic programming models

46:51.760 --> 46:56.960
created by probabilistic programs or graphical models but they are highly intuitive highly

46:56.960 --> 47:02.640
interpretable and because they describe the generative process they are often also causal

47:02.640 --> 47:06.480
because you can think of these variables and one causes the other variable to happen etc

47:07.200 --> 47:13.600
and because they are causal they really generalize very well which means that if i train you know

47:13.600 --> 47:19.920
and someone in one context i say i learn to drive in the Netherlands i'm driving on the right side

47:19.920 --> 47:26.640
on the road i have particular kind of traffic signs etc so now i can take whatever i've learned

47:26.640 --> 47:31.120
sort of these rules or whatever i've learned and now i can move to another country where you

47:31.120 --> 47:34.960
drive on the left hand side of the road completely different traffic signs and i can still survive

47:34.960 --> 47:40.320
so this is typically something that the the the purity data driven methods have a much harder

47:41.040 --> 47:47.920
time doing this sort of generalization so i think this is basically a trade of now it's it's the big

47:47.920 --> 47:55.920
question in some sense over time is can we simply take the data driven approach and extended all

47:55.920 --> 48:02.560
the way to agi but there are people on one side of the fence that are claiming that this is possible

48:02.800 --> 48:08.080
of course we also need to amplify computation right so we're just going to build faster and

48:08.080 --> 48:15.440
faster computers that can digest more and more data and at some point we'll just have agi emerge

48:15.440 --> 48:20.960
out of this kind of process and then on the other side we just want a classical ai sort of community

48:20.960 --> 48:24.960
which is no no no that's going to be ridiculous you will never be able to do that you really need

48:24.960 --> 48:31.840
to imbue these models with the structure of the world which which i take as how does physics work

48:31.840 --> 48:36.800
how does the world work can i tell you something about how data really gets generated in this work

48:36.800 --> 48:42.000
this will cut down the number of parameters to learn dramatically and because i'm following

48:42.000 --> 48:48.960
causality i can now basically generalize and create agi in this way and so this is going to be

48:48.960 --> 48:53.760
very interesting how this is going to play out and you know to be honest so i feel that i'm slightly

48:53.760 --> 48:59.440
in the camp of you really need to put generative information into your models but i've been continually

48:59.440 --> 49:04.400
surprised by what's happening on the other side of course lots of my work is also on the other side

49:05.200 --> 49:11.600
in the sense that gpt3 you know is completely 100 data driven and did we expect that it would

49:11.600 --> 49:17.920
do so well no so he is another big surprise right and so that's i think that's the fun part but it

49:17.920 --> 49:22.800
kind of doesn't do well though it doesn't have any reversibility so if you ask it how many feet fit

49:22.800 --> 49:29.040
in a shoe or we did the example last week so the corner table wants another beer it doesn't know

49:29.040 --> 49:33.200
that the corner table is a person because that's missing information we would fill in those gaps

49:33.200 --> 49:38.000
but it does raise the question though of the dichotomy between memorization and compute

49:38.000 --> 49:43.120
and the guy we were speaking to last week just said that even if you had an infinite amount of

49:43.120 --> 49:48.640
memory and the data is just not there you couldn't do it when you were responding to rich sutton and

49:48.640 --> 49:52.880
you actually spoke about all the different schools of thought in machine learning so you said compute

49:52.880 --> 49:58.640
driven versus knowledge and model driven or data driven and symbolic or statistical and white box

49:58.640 --> 50:03.200
or black box and generative and discriminative the generative thing is fascinating because our

50:03.200 --> 50:07.360
brains it's a bit like we've got the matrix or we've got a simulation going on behind the scenes

50:07.360 --> 50:11.600
haven't we we're always thinking about all these potential situations and possibly integrating

50:11.600 --> 50:17.680
between them yes i i do agree that seems to be the real trick for intelligence at least in humans

50:17.680 --> 50:24.800
so our ability to generate the world at least at a symbolic level we don't generate like high

50:24.800 --> 50:31.200
resolution videos in our brain but we do generate objects and interactions between objects and sort

50:31.200 --> 50:37.200
of how things will play out and this will also help us imagine things like what would have happened

50:37.200 --> 50:41.920
if i would have done this so now i can play out this alternative world and say that was bad let

50:41.920 --> 50:46.800
let me not do this now so i think that is going to be a key so that's the generative part of the

50:46.800 --> 50:52.640
modeling because you can generate you understand how the world works the physics of the world works

50:52.640 --> 50:57.440
and so you can generate possible futures to me i feel that's going to be a really important part

50:57.440 --> 51:04.720
of intelligence and i do agree that it's for me also very hard to see that you can generate enough

51:04.720 --> 51:10.720
data to cover all corner cases it's just very tough if you do it in the wrong direction which is the

51:10.720 --> 51:16.560
discriminative direction but again i have been surprised by how good these models really are

51:16.560 --> 51:23.680
and so you say gpt3 isn't very good maybe but it's a receding horizon right people may have not

51:23.680 --> 51:28.880
thought this was true or bet on something like gpt3 before it appeared and then it appeared and

51:28.880 --> 51:32.800
people were extremely impressed and then of course some people poke it and say but it doesn't

51:32.800 --> 51:37.840
understand this and this and then excitement goes away again a little bit but it is a bit of a

51:37.840 --> 51:41.920
receding horizon but i have generally be very impressed also with for instance the fact that

51:41.920 --> 51:48.320
we cannot generate faces of people that that don't exist we can create billions of faces that

51:48.320 --> 51:53.680
that don't exist on this planet and that look absolutely realistic would i have expected this

51:53.680 --> 51:58.480
no probably not so no and then of course there's alpha go and things like this which we also wouldn't

51:58.480 --> 52:03.760
have expected right before it happens let me play a bit of devil's advocate with respect to

52:04.320 --> 52:11.760
building priors into models it's of course like some of the easiest priors we can think of are

52:11.760 --> 52:18.000
let's say translation invariance in a cnn you can also extend this to rotational invariance and so

52:18.000 --> 52:25.200
but if we look at a true practical problem we say yes it makes sense that there is a rotational

52:25.200 --> 52:32.960
invariance in the world however on the image net dataset like for a real practical problem the sky

52:32.960 --> 52:39.200
is usually up and the object is usually in the center it's not like to the side it's it's usually

52:39.200 --> 52:46.960
in the center so in a way it seems like if we actually hit the true invariance that the world

52:47.520 --> 52:54.400
adheres to it's certainly beneficial but if we even slightly deviate if we build in a different

52:54.400 --> 53:00.480
invariance it seems like there is a level of accuracy and if we want to get past that these

53:00.480 --> 53:06.400
invariance seems to be hurting do you have a sense of can it be counterproductive or when is it

53:06.400 --> 53:12.800
counterproductive to build in such invariances it's a very good question and so this goes to the

53:12.800 --> 53:19.760
point of the bias variance decomposition again so if you hit the right bias then it can be beneficial

53:20.480 --> 53:26.160
if you you know impose the wrong bias then it's going to hurt you and this is a well-known trade

53:26.160 --> 53:32.480
off so of course the whole endeavor of machine earning is defining the right inductive biases

53:33.280 --> 53:39.760
and leaving whatever you don't know to the data and then basically learning to focus your models

53:39.760 --> 53:44.560
on the data that you're actually seeing but I agree if you put the wrong inductive bias in it

53:44.560 --> 53:51.840
things will be things can actually deteriorate now I should say here that for the rotation

53:51.840 --> 53:56.560
invariance or equivariance things are not as bad as you might think so you said if you just have

53:56.560 --> 54:03.120
slightly wrong inductive bias then it hurts but that happens to be not so much the case because

54:03.120 --> 54:10.800
there's objects inside images that do have if you turn a cat upside down or a tree upside down we

54:10.800 --> 54:16.560
still recognize it as a tree in some sense and it does give you a sort of robustness to to certain

54:16.560 --> 54:21.920
transformations on these objects that you would otherwise maybe try to model by data augmentation

54:22.000 --> 54:27.760
and stuff like that now for the sky maybe you're right that similarly in the digits a six and a

54:27.760 --> 54:33.040
nine you know you will start to confuse a six and a nine if you build in rotation and equivariance

54:33.040 --> 54:37.680
right and so there it will actually hurt but it's been surprisingly robust actually because

54:37.680 --> 54:41.920
basically because you also cut down on a number of parameters and by cutting down on the number of

54:41.920 --> 54:48.480
parameters you will you can actually help the system generalize better so the inductive bias

54:48.480 --> 54:53.760
doesn't have to be perfect and it can still help could we touch on the dichotomy between the work

54:53.760 --> 54:58.400
you've done and capsule networks for example as well as the sample efficiency thing for example

54:58.400 --> 55:04.720
with translational equivariance it means that you can you can move the dog and then the response map

55:04.720 --> 55:08.640
the dog has moved as well and much of that is about allowing neural networks to learn patterns more

55:08.640 --> 55:13.760
easily because they can map in every single layer so with capsule networks that's still a blank slate

55:13.840 --> 55:16.640
philosophy so you don't explicitly say what the capsules are

55:17.360 --> 55:22.400
whereas with with your approaches you explicitly define the priors with capsules it seems to be

55:22.400 --> 55:27.840
defined by the data you give it so if you train a capsule network on MNIST data it might inadvertently

55:27.840 --> 55:32.560
learn that one of the capsules is how bendy the stroke width is on the seven or it might learn

55:32.560 --> 55:37.760
that there's a rotation on the car because you've given it lots of rotated versions of the same car

55:37.760 --> 55:42.640
but it seems quite arbitrary and the algorithm is hideously inefficient and what's much more

55:42.640 --> 55:48.080
exciting to me is the kind of baked-in priors that you've designed in the encoder stage so could

55:48.080 --> 55:53.040
you draw the dots up between those two approaches yeah i think you actually you said it quite right

55:53.040 --> 55:58.880
so one is a much more constrained system than the other one but the actual representations that we

55:58.880 --> 56:06.960
put in our hidden layers in both cases are very similar they are stacks vectors and these vectors

56:06.960 --> 56:13.520
transform under certain operations so if i rotate the input then there is some operation on this

56:13.520 --> 56:20.160
stack of vectors which is they do rotate in the x y plane but they also permute in the sort of

56:20.160 --> 56:26.880
vector dimension and so that we tell it very explicitly how to transform we just say under

56:26.880 --> 56:31.920
these transformations you have to transform like this and we can do this because these these geometric

56:32.560 --> 56:38.320
transformations we know them that they appear in the real world but so it's also constraining

56:38.320 --> 56:43.520
because there is many other transformations that either we don't know precisely what the

56:43.520 --> 56:50.640
mathematics for the representations looks like or for instance like groups that are that are not

56:50.640 --> 56:55.440
compact maybe maybe we have looked at scaling but it's already a more of a stretch but there's of

56:55.440 --> 57:00.240
course you can do many other types of transformations that don't even have to be groups there could be

57:00.240 --> 57:05.840
other types of transformations like lighting changes or whatever if you wanted to incorporate

57:05.840 --> 57:10.160
all of these you would have to build the mathematical representation theory for each of them and then

57:10.160 --> 57:14.320
it would actually also explode in a number of feature maps that you would have to maintain

57:14.320 --> 57:20.080
and it's not a very practical approach so this works up to the transformation groups that we

57:20.080 --> 57:25.040
understand and that are everywhere around us if we want to go beyond it then basically something

57:25.040 --> 57:30.640
like capsules are very nice because they tell you well we'll just keep the abstract nature

57:30.640 --> 57:37.040
of what we want which is some stack of things that transform in some way that we can vaguely

57:37.040 --> 57:42.720
specify and then we ask it to learn all these things and we are actually ourselves also looking

57:42.720 --> 57:48.160
at these sort of more relaxed notions of equivariance where we don't tell the system precisely

57:48.160 --> 57:52.960
how to change we just want this to emerge automatically and again here the connection

57:52.960 --> 57:59.040
with the brain is very interesting in the brain we do seem to have all sorts of filters which are

57:59.040 --> 58:04.640
related by not only by rotations but all sorts of other transformations and they are topographically

58:04.640 --> 58:10.640
organized so they are right the ones that are related like a slightly rotated version is sitting

58:10.640 --> 58:17.200
right next to the other one in your brain and so presumably your brain have figured this out by

58:17.200 --> 58:21.680
just looking into the world for a long time and it's organized all these filters that way

58:22.320 --> 58:28.160
and it's known that if you prevent let's say a cat from seeing then it will not come up with

58:28.160 --> 58:33.360
this nice organization so you really have to get that by looking into the world a lot and that's

58:33.360 --> 58:38.480
super fascinating and I think that's where some of our research is being directed now can we learn

58:38.480 --> 58:42.880
from how this happens in the brain is there a connection between these topographic maps and

58:42.880 --> 58:48.800
equivariance somehow and between capsules and all of these things and I believe that it is a good

58:48.880 --> 58:54.880
strategy to to take the general ideas equivariance and then slowly relax it and let the system learn

58:54.880 --> 59:03.280
more and more so these capsule networks they've been a bit hyped when they were not really developed

59:03.280 --> 59:11.440
named first by Jeff Hinton and he has this concept or at least had it at the beginning that it's some

59:11.440 --> 59:18.080
sort of like an inverse rendering pipeline so the sort of the capsule networks do some sort of

59:18.160 --> 59:25.200
they take in the world and they inverse render it into these capsules how much do you agree with

59:25.200 --> 59:30.000
that type of formulation it seems what you've described is more of a forward way of looking at

59:30.000 --> 59:36.000
capsules where we have these invariances yeah yeah so I don't I very much agree with this idea that

59:36.000 --> 59:41.360
you have smaller things and they can be used in multiple ways but you have to align them in a

59:41.360 --> 59:46.800
particular way so that they build something at the higher level and obviously you can invert that

59:46.800 --> 59:53.200
idea too in order to start at something very abstract and then generate certain things this way

59:53.920 --> 01:00:00.960
and there is a lot of work now actually going into equivariant generative models for instance

01:00:00.960 --> 01:00:05.440
equivariant flows a prime example is for instance in physics and what's called quantum

01:00:05.440 --> 01:00:09.360
quorum or dynamics there is there's a theory that has a huge number of symmetries called

01:00:09.360 --> 01:00:16.400
gauge symmetries and if you transform these quarks in a way in a particular way the physics

01:00:16.400 --> 01:00:20.800
doesn't change you will have exactly the same observations right but still you need these

01:00:20.800 --> 01:00:27.040
all these symmetries to conveniently describe this model and so now when you generate you if you

01:00:27.040 --> 01:00:32.160
want to generate quark fields or something like this right then gauge fields then you can generate

01:00:32.160 --> 01:00:36.320
all these symmetries and it's not very helpful because you generate one configuration but you

01:00:36.320 --> 01:00:42.160
then if you generate all these sort of equivalent things which are only you know different by symmetry

01:00:42.160 --> 01:00:45.680
then you haven't really done much so understanding how to generate with these

01:00:45.680 --> 01:00:51.280
equivalents in it is actually a big topic of research in many groups I think you know Danilo

01:00:51.280 --> 01:00:56.800
Rosenda and this friend in DeepMind has done a lot of work and there's physicists at MIT and who

01:00:56.800 --> 01:01:02.400
don't work and we are with a group of students and physicists at Amsterdam we're also looking at these

01:01:02.400 --> 01:01:08.720
types of questions so that's I guess the inverse problem where also equivalents is playing an

01:01:08.720 --> 01:01:14.400
increasingly important role not many people are working on capsules I feel they've fallen

01:01:14.400 --> 01:01:22.240
out of the favor of the public because I don't know they're maybe hard to implement or they don't

01:01:22.240 --> 01:01:28.160
really work as advertised let's say do you have general thoughts about capsule networks I think

01:01:28.160 --> 01:01:33.360
with many of these things there is an underlying intuition which is correct so I haven't really

01:01:33.360 --> 01:01:39.440
worked myself in trying to implement them and so what's what you often see in this field is that

01:01:39.440 --> 01:01:45.440
there is an intuition about how something should work and often that's that is the correct intuition

01:01:45.440 --> 01:01:49.040
especially when it's coming from Jeff Hinton it is very likely to be the correct intuition

01:01:49.600 --> 01:01:54.960
now then there's the next step which is how do you make something practically implementable

01:01:54.960 --> 01:01:59.600
and these days that means that you have to run it super fast right you have to be able to implement

01:01:59.600 --> 01:02:06.320
it in GPUs all these kinds of constraints otherwise you will be so much slower than just an ordinary

01:02:06.320 --> 01:02:12.160
cnn and you will basically not be able to train as long as a cnn and you cannot train as many

01:02:12.160 --> 01:02:16.160
parameters as an ordinary cnn and you will not beat it and if you don't have the bold numbers

01:02:16.720 --> 01:02:21.600
hard to publish and so that might impede progress in something like this but then what happens is

01:02:21.600 --> 01:02:26.800
you wait and then for five or ten years and then the computers have become faster and then people

01:02:26.800 --> 01:02:30.240
go back to these ideas and then they think oh that was actually very interesting let me try again

01:02:30.800 --> 01:02:36.160
and then suddenly things start to work now that's of course the story of deep learning

01:02:36.160 --> 01:02:41.280
more generally speaking right because we had you know neural networks like a long time ago

01:02:41.920 --> 01:02:47.920
right in the 80s it was actually quite popular to work on these things but they didn't quite

01:02:47.920 --> 01:02:52.800
take off because we didn't have the compute power and maybe also not the the data to really train

01:02:52.800 --> 01:02:59.200
them well and it's only when we took them out of the the closet again and said hey man this thing

01:02:59.200 --> 01:03:04.400
actually works if you throw a whole bunch of GPUs at it that's when people then became popular again

01:03:04.400 --> 01:03:09.280
and so something like this might well happen again with with capsules or it is something like

01:03:09.280 --> 01:03:14.720
capsules in then by five to ten years do you have any other than capsule networks are there

01:03:14.720 --> 01:03:20.480
things that right now we are not looking back on but that would you know be worthy of of a revisit

01:03:21.120 --> 01:03:28.160
oh yeah that's very tough but i'm personally looking at things like ICA and topographic ICA

01:03:28.160 --> 01:03:34.320
so i think there's an interesting body of ideas there of course i risk now to mow away the grass

01:03:34.320 --> 01:03:40.560
before my own feet but okay let me let me entertain that and then probably marker

01:03:40.560 --> 01:03:45.120
random fields and things like this will probably make a comeback at some point or graphical models

01:03:45.200 --> 01:03:50.800
more generally will probably make a comeback or maybe that integrated with deep learning and

01:03:50.800 --> 01:03:54.960
some people have already attempted going in that direction energy based models have made a comeback

01:03:54.960 --> 01:04:01.280
already so yeah it is often going back to older ideas and there's probably a lot more that other

01:04:01.280 --> 01:04:06.800
people can sort of name i do have a prediction maybe for the future that people really haven't

01:04:06.800 --> 01:04:11.520
looked at yet in my opinion it's going to be quantum things so i think many people don't

01:04:11.520 --> 01:04:18.480
actually know understand the language of quantum mechanics or mathematics and i do think that first

01:04:18.480 --> 01:04:22.080
of all that language is very interesting it's a bit different than our normal probabilities it's

01:04:22.080 --> 01:04:26.800
like square roots of probabilities and with the advent of quantum computers which at some point

01:04:26.800 --> 01:04:34.080
will come we as a community will have to dive into that and maybe make it part of our curriculum

01:04:34.080 --> 01:04:40.000
and in university and then i think that will become that will start to boom could i just

01:04:40.000 --> 01:04:44.720
quickly introduce before we get to quantum i don't know if you read sarah hookers the hardware

01:04:44.720 --> 01:04:50.320
lottery paper and this is fascinating for you of course working at qualcomm but her idea was that

01:04:50.320 --> 01:04:54.720
there are certain things that cause a inertia or friction in the marketplace of ideas so is it a

01:04:54.720 --> 01:05:00.080
meritocracy of ideas or do the previous kind of hardware decisions and hardware landscape

01:05:00.080 --> 01:05:04.240
does it enslave us you know ideas succeed if they're compatible with the hardware and the

01:05:04.240 --> 01:05:08.800
software at the time and this is what she called a hardware lottery and she says the machine learning

01:05:08.800 --> 01:05:12.640
community is exceptional because the pace of innovation is so fast it's not like in the

01:05:12.640 --> 01:05:17.120
hardware world which you all know so well where it costs so much money to develop new hardware

01:05:17.120 --> 01:05:22.800
and the cost of being scooped is so high but i wanted to just come at this from i don't know

01:05:22.800 --> 01:05:27.360
how you see this right so with capsule networks the reason they're so slow is because it's a kind

01:05:27.360 --> 01:05:32.560
of sequential computing paradigm and no amount of hardware is going to solve that but there are

01:05:32.560 --> 01:05:36.800
entirely different paradigms of hardware like quantum which could potentially change the game

01:05:36.800 --> 01:05:41.520
but how much could they change the game is there still some limit on it there's always a limit

01:05:41.520 --> 01:05:47.200
clearly but i think the the situation is maybe slightly more subtle which is that working in a

01:05:47.200 --> 01:05:53.920
hardware company i can also see the other side of the coin a little bit so there is also a race

01:05:53.920 --> 01:06:00.720
in the hardware companies to build ASIC designs like which is specialized hardware to run the

01:06:00.720 --> 01:06:05.760
latest and the greatest machine learning algorithms which are being developed so it's not just rich

01:06:05.760 --> 01:06:10.560
machine learning algorithms work well on the current hardware that us being enslaved to the

01:06:10.560 --> 01:06:16.560
hardware there is actually a feedback which where now the companies are trying to build ASIC to first

01:06:16.560 --> 01:06:24.800
of all run the confolutions very efficiently and soon we'll have probably transformers run very

01:06:24.800 --> 01:06:30.000
efficiently and so that's the fascinating thing of course it's hard to get your paper published

01:06:30.000 --> 01:06:35.040
perhaps if if you're ahead of the game too much which i see a little bit in the machine learning

01:06:35.040 --> 01:06:40.000
community which is if you look at the papers which are published in the physics community they work

01:06:40.000 --> 01:06:45.440
with images of four by four pixels that's what they can do because otherwise you need a quantum

01:06:45.440 --> 01:06:51.280
computer obviously to run your algorithm and it's being looked down upon a lot by the machine

01:06:51.280 --> 01:06:56.320
learners basically saying what do we you know what why is that interesting and i do feel very

01:06:56.320 --> 01:07:03.200
strongly that as a field we need to open up so we we should value original ideas much more

01:07:03.200 --> 01:07:07.440
than we currently do and i don't know you know you can probably have a whole conversation on

01:07:07.440 --> 01:07:14.880
where this is coming from i think the reviewing in our community is far too grumpy i think people

01:07:14.880 --> 01:07:20.720
if it's not completely finished polished paper then you know they'll find a hole somewhere and

01:07:20.720 --> 01:07:27.200
they start pushing on it and i think you should look also at a sort of more holistic how original

01:07:27.200 --> 01:07:32.640
is this idea right can you be excited about the originality and the creativity of the idea that

01:07:32.640 --> 01:07:39.600
went into that and trust that maybe it takes the community a couple of years to further develop this

01:07:39.600 --> 01:07:45.600
and and and some things will die and that's fine but let all these flowers grow in a way and yeah so

01:07:45.600 --> 01:07:50.400
i i do feel a little bit that sometimes is a bit negative and i and that's maybe where some of

01:07:50.400 --> 01:07:55.360
that friction is coming from that yeah just on that it's fascinating we're talking to Kenneth

01:07:55.360 --> 01:08:00.400
Stanley on monday and he wrote a book greatness can't be planned and his big thing is exactly what

01:08:00.400 --> 01:08:04.880
you've just said that we have this convergent behavior in so many of our systems whether it's

01:08:04.880 --> 01:08:11.120
science or academia and it's because of this objective obsession so we all want to monotonically

01:08:11.120 --> 01:08:15.520
increase our objectives and what we should be is treasure hunters yes science should be about

01:08:15.520 --> 01:08:20.960
exploration not exploitation exploitation is one step away you already know how to build the bridge

01:08:20.960 --> 01:08:26.800
we don't seem to have this paradigm at the moment even when you submit your paper to be reviewed

01:08:26.800 --> 01:08:31.680
there's a consensus mechanism isn't there because you need to have multiple accepts from people and

01:08:31.680 --> 01:08:37.280
science advances one funeral at a time yes do you think this is a huge problem yeah i think it is a

01:08:37.280 --> 01:08:41.280
big problem but i think also we will probably i think it's a big problem because it will hold us

01:08:41.280 --> 01:08:46.960
back and it will also hold very brilliant students back so what do i advise my students now i advise

01:08:46.960 --> 01:08:53.200
them to have a mixed model a mixed sort of policy which is on the one hand you work on some papers

01:08:53.200 --> 01:08:58.560
which are easy to score on things that are very popular in the community and then on the other

01:08:58.560 --> 01:09:04.080
hand you work on things which might be you know huge innovations that are much more uncertain

01:09:04.080 --> 01:09:09.600
they might fail but then they might also be really big innovations and that way you get your papers

01:09:09.600 --> 01:09:14.080
and you can become famous but at least also you work on things which are highly risky but in fact

01:09:14.720 --> 01:09:19.840
it's a bit cynical to have to do that it would be much nicer if there would be much more appreciation

01:09:19.840 --> 01:09:26.400
for just originality and but i do also believe there is a solution to this so i think we are in

01:09:26.400 --> 01:09:31.040
a sort of a local minimum as a community in this sense but i think there's a way out and one way

01:09:31.040 --> 01:09:36.720
out which is basically and this has been already proposed a long time ago i think young mcconn

01:09:36.720 --> 01:09:41.840
and yasha benji were also talking about this and we are actually trying to implement this for a

01:09:41.840 --> 01:09:48.640
beige and deep learning workshop is to sort of to throw papers on the archive and not necessarily

01:09:48.640 --> 01:09:56.800
submit to conferences and to have a open reviewing of that and to give people reputation indices so if

01:09:56.800 --> 01:10:02.560
you do if you give a good review you can publish your own review or state it in your cv and people

01:10:02.560 --> 01:10:08.960
can rate your review and if you do poorer reviews you'll get horrible ratings and then your reputation

01:10:08.960 --> 01:10:14.000
will come down so there is some kind of way that you can probably design is that people are incentivized

01:10:14.000 --> 01:10:19.440
to give good reviews and to actually use these reviews as a half a paper that you can also be

01:10:19.440 --> 01:10:24.320
proud of and then good things will come up right they will at some point people will point to

01:10:24.320 --> 01:10:29.920
interesting ideas maybe we need some kind of recommender to make sure it's a bit unbiased in

01:10:29.920 --> 01:10:34.400
the sense that it's not only the famous people that will get their papers exposed but also less

01:10:34.400 --> 01:10:37.920
famous people so we need to have sort of maybe build a recommender around something like that

01:10:38.640 --> 01:10:43.440
every so now and then a conference comes by and it sort of harvests in this field of sort of

01:10:43.440 --> 01:10:48.880
papers and say that one you're all reviewed they have great reviews i'll take one or two more reviews

01:10:48.880 --> 01:10:54.240
anonymously and i'll then publish and then i invite you to present your paper in our conference

01:10:54.240 --> 01:11:01.120
that to me sounds like a much more natural way to proceed i also find it very demotivating for

01:11:01.120 --> 01:11:05.840
my students who have these ideas maybe this is the worst part so you're a student you're working on

01:11:05.840 --> 01:11:10.720
this thing which is not completely mainstream and then you get rejected two or three times from a

01:11:10.720 --> 01:11:16.720
conference right this is so demotivating for a student to then continue right at this case at

01:11:16.720 --> 01:11:21.040
least you just you push us on the archive and you engage with the community around your paper

01:11:21.680 --> 01:11:25.840
and that's a much more it's much less demotivating than these constant rejections

01:11:26.400 --> 01:11:31.440
from the big prizes right the NERIAPS paper or the ICML paper that everybody wants

01:11:31.440 --> 01:11:36.160
is like guys the idea at the moment a lot of people are talking about this how can we improve

01:11:36.160 --> 01:11:41.600
peer review like in every field people are moving towards this open review model but

01:11:41.600 --> 01:11:45.840
collectively as a research community we don't really have the collaboration tools at this

01:11:45.840 --> 01:11:51.280
point in time to take advantage of it open review is willing to implement this actually so yeah i

01:11:51.280 --> 01:11:57.760
think it will happen yeah it it's a good system to pivot back into new ideas and sort of exciting

01:11:57.760 --> 01:12:02.160
concepts that are coming out machine learning at the moment you mentioned quantum computing is this

01:12:02.160 --> 01:12:06.160
paradigm that's really critical that's not really well understood by the machine learning

01:12:06.160 --> 01:12:11.440
community would you be able to give our listeners like the five-minute spiel about quantum probability

01:12:11.440 --> 01:12:16.160
how it differs from the probabilities that we're used to yeah so you can think of quantum mechanics

01:12:16.160 --> 01:12:22.800
as another theory of statistics in some sense right so in AI for everything we can't totally

01:12:22.800 --> 01:12:28.000
observe we write down probabilities of things happening but of course underlying there is

01:12:28.000 --> 01:12:32.960
processes but we just don't observe everything and so we describe it by probability now in quantum

01:12:32.960 --> 01:12:38.560
mechanics it's very similar to taking the square root of a negative number in some sense it's like

01:12:38.560 --> 01:12:43.760
you let me put another way so it's very much like taking the square root of a probability

01:12:43.760 --> 01:12:49.600
which can actually become negative so minus one squared is one right okay or let's say

01:12:49.600 --> 01:12:55.920
minus two squared is four four is your probability and minus two could be your quantum amplitude

01:12:56.000 --> 01:13:02.560
this thing can be negative and the bizarre thing is that if you describe a system by these

01:13:02.560 --> 01:13:08.080
quantum amplitude these square roots then they can cancel which is this this is the counter

01:13:08.080 --> 01:13:13.120
intuitive part which is you can have a probability for an event or an amplitude for an event and then

01:13:13.120 --> 01:13:17.520
for you have an amplitude for another event and you would think that if there's two probabilities

01:13:17.520 --> 01:13:22.320
for that event to happen then the probability of that event should grow but in quantum mechanics

01:13:22.320 --> 01:13:27.040
they can cancel and then the probability is suddenly zero that the event happens so this

01:13:27.040 --> 01:13:33.360
seems bizarre but nature has chosen this theory of statistics anyway and so it behooves us to

01:13:33.360 --> 01:13:42.800
look into this more so first question is can you write down maybe even normal classical problems

01:13:42.800 --> 01:13:48.320
more conveniently in this quantum statistics and here I always remind myself when I first

01:13:48.320 --> 01:13:54.480
learned complex numbers when you learn to solve the damped oscillator equation you can do it in

01:13:54.480 --> 01:14:00.560
a complicated way or you can go to complex numbers and then suddenly it gets very easy to do it and

01:14:00.560 --> 01:14:07.440
so you can imagine that there is things to compute in classical statistics that are actually either

01:14:07.440 --> 01:14:13.680
shortcuts by using quantum mechanics somehow and and so the first thing that we've tried to do with

01:14:13.760 --> 01:14:20.880
quantum mechanics in deep learning is to say can we just design an architecture that would be

01:14:20.880 --> 01:14:26.640
naturally a natural fit to this quantum mechanical description of the world but we still want to be

01:14:26.640 --> 01:14:31.840
able to run it on a classical computer so we just want to describe this we just want to

01:14:32.480 --> 01:14:37.600
harvest this new degrees of freedom that we have from quantum mechanics and so that was a paper that

01:14:37.600 --> 01:14:43.520
we recently pushed on the archive which is quantum deformed neural networks which we basically

01:14:43.520 --> 01:14:48.320
first say okay what if we would take a normal neural net and implement it on a quantum computer

01:14:48.320 --> 01:14:54.560
and then we slightly deform it into something where states get entangled and this entanglement is

01:14:54.560 --> 01:15:01.440
another strange phenomenon in quantum mechanics where you can create states which you cannot

01:15:01.440 --> 01:15:07.360
really create classically superpositions of states and and so by doing it in this particular way

01:15:07.360 --> 01:15:12.000
we could still run it efficiently on a classical computer but it's just a very different beast

01:15:12.000 --> 01:15:16.720
than a normal neural network so that's already to me very interesting and then of course the big

01:15:16.720 --> 01:15:23.040
prize the big bonus is that if you adhere to this way of describing what's happening is that there

01:15:23.040 --> 01:15:27.440
is the opportunity to be able to run things very efficiently on a quantum computer so now you can

01:15:27.440 --> 01:15:33.120
design your neural network in such a way that classically actually it will be very hard to

01:15:33.120 --> 01:15:39.040
simulate it but then on a quantum computer you could potentially simulate it very efficiently

01:15:39.040 --> 01:15:43.760
and and of course we don't have quantum computer so it's very hard to actually prove your point

01:15:43.760 --> 01:15:48.960
but that also what makes it somewhat exciting in that paper specifically you make you make lots of

01:15:48.960 --> 01:15:54.960
references and connections to the Bayesian way of doing machine learning could you what's the

01:15:54.960 --> 01:16:01.120
connection there because it seems different both are I agree both are statistics and you already

01:16:01.120 --> 01:16:06.720
mentioned the square roots of probabilities but how do you connect the sort of uncertainty

01:16:06.720 --> 01:16:15.120
quantification in the Bayesian way with how particles move quantum mechanics is not necessarily

01:16:15.120 --> 01:16:22.480
about particles so you can just you can write quantum mechanics on just like states you can just

01:16:22.480 --> 01:16:28.720
write down a number of classical states like I say a sequence of zeros and ones and there's an

01:16:28.720 --> 01:16:34.000
exponential number of these states and then you can say classically I can only be in one of these

01:16:34.000 --> 01:16:38.320
states but in quantum mechanics I can be in any linear combination of these states which

01:16:38.320 --> 01:16:46.080
should have is a bigger space now what we did in that paper was to say we can treat both the world

01:16:46.080 --> 01:16:53.200
state as well as the parameter state as a quantum we describe it by a quantum wave function and then

01:16:53.280 --> 01:16:58.720
we entangle these different states which is similar to saying that I take my state classical

01:16:58.720 --> 01:17:05.440
state x I multiply it by a matrix of parameters and I get a new state out so here the analogy would

01:17:05.440 --> 01:17:11.040
be I have my quantum superposition of classical states I have a quantum superposition of

01:17:11.680 --> 01:17:16.080
parameter states and then there are some processes where we get entangled together

01:17:16.720 --> 01:17:21.520
and then I do a measurement which is now a function of both the parameters as well as the

01:17:22.080 --> 01:17:28.160
inputs and you train it to give you measurements that with high probability give you the answer

01:17:28.160 --> 01:17:32.160
that you want so that would be the training process now there is actually a very precise

01:17:32.160 --> 01:17:38.880
way in which you can relate Bayesian posterior inference in quantum mechanics but that's a fairly

01:17:38.880 --> 01:17:44.000
technical story but there is a using density matrices there is a fairly precise way in which

01:17:44.000 --> 01:17:49.120
you can say I have a state described by a density matrix and if I do a measurement I condition on

01:17:49.120 --> 01:17:54.640
something and a renormalize and stuff like that so that's possible so there are two things like

01:17:54.640 --> 01:18:01.920
first of all the quantum neural network formulation can be very slow on a classic computer but

01:18:01.920 --> 01:18:08.320
fast on a quantum computer on the other hand people do run like Bayesian inference on classical

01:18:08.320 --> 01:18:16.400
computers what makes the quantum neural networks that much harder to compute yeah it's this

01:18:16.480 --> 01:18:22.320
entanglement issue yeah so in so classically I agree there is an analogy in classical

01:18:23.200 --> 01:18:29.600
statistics where this looks very similar which is for instance if I have a exponentially large

01:18:29.600 --> 01:18:35.360
state space and I write down a probability distribution over all of these possible states

01:18:36.080 --> 01:18:40.560
where they have a number a positive number that sums to one for each one of these exponentially

01:18:40.560 --> 01:18:45.440
large states and if I ask you now compute an average of a function over this probability

01:18:45.440 --> 01:18:49.040
distribution you can't do it because there's an exponentially large number of things that you

01:18:49.040 --> 01:18:54.720
would have to sum and so we have ways to deal with it which is sampling from these distributions or

01:18:54.720 --> 01:19:01.280
variational approximations and anyway we have to approximate this state of affairs now in quantum

01:19:01.280 --> 01:19:07.760
that's fairly similar so there's you you face a similar exponential problem and you can also do

01:19:07.760 --> 01:19:13.520
approximations to get around that and but the interesting part is that in quantum mechanics

01:19:13.600 --> 01:19:18.880
you can for instance do a measurement and a measurement is something that you know that is

01:19:19.520 --> 01:19:24.560
it gets a physical thing and it's not very hard to do but it will be an operation which looks

01:19:24.560 --> 01:19:29.520
like sampling something down to a particular classical state again and it does look like the

01:19:29.520 --> 01:19:35.520
sampling operation that we do in sort of artificially in probability theory but it's also true that

01:19:35.520 --> 01:19:39.360
quantum computers can in principle compute things that classical computers can't compute and they

01:19:39.840 --> 01:19:44.000
can actually compute it much faster whether that actually maps to the things that we are

01:19:44.000 --> 01:19:49.280
interested in is not so clear so that's it's not at all clear right now that we will actually build

01:19:49.280 --> 01:19:57.920
quantum neural networks that are generalizing a lot better on classical problems right if you

01:19:57.920 --> 01:20:04.240
want to do classical predictions does it actually help to build a neural network that can run

01:20:04.240 --> 01:20:08.880
efficiently on a quantum computer that can do these predictions much better that's not known

01:20:08.880 --> 01:20:13.040
but that's what makes it exciting in my opinion because you can try to do it now there's also

01:20:14.160 --> 01:20:18.640
functions that you can't even do classically you have to do quantum mechanically but I don't

01:20:18.640 --> 01:20:25.600
know how relevant they are for AI fascinating can we conceivably say that at least one let's say

01:20:25.600 --> 01:20:31.440
applications are way for these neural networks or for the quantum neural networks to come in

01:20:31.440 --> 01:20:37.040
is in in the place where right now we have these renormalization problems let's say

01:20:37.760 --> 01:20:43.280
big word embeddings or yeah as you mentioned things like variational inference any anywhere

01:20:43.280 --> 01:20:51.840
where you have a partition function that you let's say have to sample to compute now we potentially

01:20:51.840 --> 01:20:57.280
introduce this new way of doing this yeah so I would say that is a different set of problems so

01:20:57.280 --> 01:21:04.080
there is some sampling algorithms which can be sped up by quantum sampling algorithms but I think

01:21:04.160 --> 01:21:09.840
the maximum speed up is like a square root so it's not insignificant but it's also not exponential

01:21:09.840 --> 01:21:13.840
okay right you can do something in square root time of what a normal classical computer could do

01:21:14.400 --> 01:21:20.720
and then there is these very interesting stories where people thought that they could do things much

01:21:20.720 --> 01:21:25.360
faster on a quantum computer but then somebody's thought really hard about it and they then invented

01:21:25.360 --> 01:21:31.200
actually a quantum inspired classical random algorithm which would do about the same speed or

01:21:32.080 --> 01:21:39.040
close close at least so it's very uncertain precisely what we can speed up but that what

01:21:39.040 --> 01:21:44.000
makes it interesting right especially if you can predict what's going to happen in some sense

01:21:44.000 --> 01:21:49.760
it's just a matter of executing right but if you don't know if they're what they're what the low

01:21:49.760 --> 01:21:54.800
hanging fruit is and if there is low hanging fruit and what the possible benefits in benefits are the

01:21:54.800 --> 01:21:59.040
possible bonus that you can get by doing these things then it gets really interesting in my opinion

01:21:59.840 --> 01:22:05.040
amazing now might be a good time to talk about your other paper that's just come out Max which

01:22:05.040 --> 01:22:09.920
is probabilistic numeric convolutional neural networks and this was also with Mark Finsey who

01:22:09.920 --> 01:22:14.320
we just discovered this morning just brought out a really interesting paper about equivalents on

01:22:14.320 --> 01:22:19.120
light groups so that might be a potential digression later but this works really fascinating because

01:22:19.120 --> 01:22:24.560
it's in the setting of irregularly sample data and we use these Gaussian processes to represent

01:22:24.560 --> 01:22:28.880
that and we can continuously interpolate between them in this convolutional setting absolutely

01:22:28.880 --> 01:22:34.720
fascinating could you give us the the elevator pitch yeah first let me say again that Mark Finsey

01:22:34.720 --> 01:22:40.960
was an intern at Qualcomm and and Roberto Bondeson was is the other person who was also working with

01:22:40.960 --> 01:22:47.360
me on the quantum stuff so those of my collaborators in this project and of course Mark did the bulk

01:22:47.360 --> 01:22:53.440
of the work for this paper so he should deserve much of the credit for it but here's the observation

01:22:53.520 --> 01:23:00.880
that we had the observation is when we write down a deep learning algorithm let's say on for an image

01:23:01.520 --> 01:23:06.560
then we sort of treat the image as pixels and we think that's the real signal that we are looking at

01:23:07.200 --> 01:23:12.240
but you can also ask yourself what if I remove every second pixel now actually I have a very

01:23:12.240 --> 01:23:16.400
different neural network but should I have a very different neural network or what if the pixels are

01:23:16.400 --> 01:23:23.200
actually quite randomly distributed in the plane it's just some random places where I do measurements

01:23:23.200 --> 01:23:28.320
maybe more on the left upper corner and and fear on the left lower corner what the predictor

01:23:28.320 --> 01:23:33.520
should behave in a certain consistent way and so of course then you come to realize that really

01:23:33.520 --> 01:23:37.840
what you're doing is with a pixel grid is sampling an underlying continuous signal

01:23:38.720 --> 01:23:43.760
so then we just started thinking how do you best deal with this so how do you how can you

01:23:43.760 --> 01:23:49.280
build this in and so there's a very interesting tool which is called the Gaussian process it's

01:23:49.280 --> 01:23:55.680
basically interpolates between dots but in places where you don't have a lot of data you create

01:23:55.680 --> 01:24:01.040
uncertainty because you don't know what the real signal is so you basically get some kind of interval

01:24:01.760 --> 01:24:06.800
which says okay I think the signal is somewhere in this interval with 95 percent you know certainty

01:24:06.800 --> 01:24:14.000
but I don't know precisely where now the mean function is a smooth actual continuous function

01:24:14.960 --> 01:24:19.600
and then the next step was say okay what what does it mean to do a convolution on this space

01:24:19.600 --> 01:24:26.480
this is the new Gaussian process interpolated space and what we found is that the most interesting

01:24:26.480 --> 01:24:32.160
way to describe that is by looking at it as a partial differential equation and so this ties

01:24:32.160 --> 01:24:37.200
back into another really interesting line of work which was started by David Duvenaux and authors

01:24:37.200 --> 01:24:43.520
on thinking of a neural network as an OD as an ordinary differential equation so here we're talking

01:24:43.520 --> 01:24:49.840
about a PDE basically because we have spatial extent and so we are looking at sort of derivatives

01:24:49.840 --> 01:24:55.440
and second-order derivatives in in the plane basically which which we apply on the continuous

01:24:55.440 --> 01:25:00.560
function so this is literally what people do when they solve a PDE is that they have some operator

01:25:00.560 --> 01:25:06.400
which is consists of derivatives which they apply to the function and then they have a time component

01:25:06.400 --> 01:25:12.320
which evolves this thing forward in time basically and it turns out that's a very natural way to

01:25:12.320 --> 01:25:17.920
describe a convolution you can also add symmetries in a very natural way by looking at that operator

01:25:17.920 --> 01:25:22.160
that sort of moves things forward and making sure it's invariant under certain transformations

01:25:22.960 --> 01:25:28.720
we had a bit of trouble really handling the nonlinearity that falls that happens then so we

01:25:28.720 --> 01:25:33.120
had to then project it back onto something that would then again easily handle by a Gaussian

01:25:33.120 --> 01:25:38.560
process etc so we had to do some work there but in the end this thing was now actually very general

01:25:38.560 --> 01:25:46.000
and interesting tool which is apply a Gaussian process apply PDE apply nonlinearity repeat

01:25:46.000 --> 01:25:52.000
and then in the end collect all your information and make a prediction and it so some of the benefits

01:25:52.000 --> 01:25:57.040
are now that first of all of course you cannot work on a unstructured set of points doesn't

01:25:57.040 --> 01:26:02.000
have to be a grid and you can even learn the positions of those points so you can now direct

01:26:02.000 --> 01:26:08.320
the observations in places where you really need to do observations in order to improve

01:26:08.320 --> 01:26:12.720
your prediction so it basically becomes a numerical integration procedure where you can

01:26:12.720 --> 01:26:18.640
learn where to move your integration points and what I also found very is fascinating is that

01:26:18.640 --> 01:26:25.680
this same paradigm can be mapped on again onto a quantum paradigm where you can think of that

01:26:26.240 --> 01:26:32.880
PDE that evolves now as a Schrodinger equation that sort of evolves like a wave function so it

01:26:32.880 --> 01:26:37.680
maps very nicely also again to a quantum problem and that's what we are working on now

01:26:38.400 --> 01:26:42.160
something that's really fascinating that keeps coming up again and again and these sorts of

01:26:42.160 --> 01:26:47.360
research programs is the matrix exponential like it's our connection to groups and algebras or

01:26:47.360 --> 01:26:52.880
like group representations and algebras and of course we use it to evolve our ODEs and PDEs

01:26:53.760 --> 01:26:58.320
I guess as a physicist you've probably got a deeper appreciation of this particular object

01:26:58.320 --> 01:27:03.600
but it's something that's still quite alien to a lot of people I know that work in applied

01:27:03.600 --> 01:27:08.720
machine learning what's the significance of the matrix exponential why does it connect all these

01:27:08.720 --> 01:27:14.800
really fundamental objects to things like Lie groups and stuff like that yeah so it's interesting

01:27:14.800 --> 01:27:19.920
that we actually just got a paper accepted in noreps on this and it's called the convolution

01:27:19.920 --> 01:27:26.000
exponential and you can look it up and Emil Hogebaum is the sort of the main author and

01:27:26.000 --> 01:27:33.920
generator of that idea and yeah so I guess it because it is the solution to the ODE or the PDE

01:27:33.920 --> 01:27:40.000
right so if you write down something that's very fundamental that is the first order differential

01:27:40.000 --> 01:27:46.880
equation which is d dt the derivative with respect to t of a state is some operator times that state

01:27:47.680 --> 01:27:54.320
then the solution of that thing will be the state over time is the matrix exponential times t

01:27:54.880 --> 01:28:00.160
times the state so that's I think where it comes from and so one other way to look at it is that

01:28:00.880 --> 01:28:05.360
in physics it's called the Green's function so it's basically the solution to this ODE so you

01:28:05.360 --> 01:28:13.760
can think of a neural net as basically we tend to describe it as a discrete you know map from one

01:28:13.760 --> 01:28:18.320
point to another point but if you think of it as a continuous process which is what we learned from

01:28:18.320 --> 01:28:25.120
the ODE description of a neural net if you think of it as a continuous process then it's really

01:28:25.840 --> 01:28:31.600
you can just think of that convolution this map you can just think of it as the matrix exponential

01:28:31.600 --> 01:28:37.040
solution to this to this ODE in math literature you call this the Green's function so you can

01:28:37.040 --> 01:28:42.240
think of a convolution basically as the Green's function of a partial differential equation I

01:28:42.240 --> 01:28:46.560
think that's where the word where this feels like a very fundamental object in some sense

01:28:47.360 --> 01:28:53.600
so in in a talk you gave recently on the future of graph neural networks you were talking about a

01:28:53.600 --> 01:28:59.200
number of ideas from physics that hadn't really made it into machine learning among them things

01:28:59.200 --> 01:29:05.040
like renormalization chaos and holography would you care to unpack these ideas a little bit and

01:29:05.040 --> 01:29:10.640
tell us where you see the future is in these ideas yeah so the reason I mentioned these because I

01:29:10.640 --> 01:29:15.840
think there's a lot of really cool ideas in physics which are still remain unexplored but there

01:29:15.840 --> 01:29:19.760
is more and more physicists who are moving into the field and some of these ideas are actually

01:29:19.760 --> 01:29:25.040
you know being worked out as we speak so I recently saw about two papers on renormalization

01:29:25.040 --> 01:29:31.040
so renormalization is something in in physics which basically you start with a system with a

01:29:31.040 --> 01:29:36.320
whole lot of degrees of freedom like say particles moving around or something like this and then

01:29:36.640 --> 01:29:44.000
coarse grain the system slowly and what means is that by coarse graining you zoom out and you

01:29:44.000 --> 01:29:48.800
build an effective theory of the underlying theory in the same sense as thermodynamics is an effective

01:29:48.800 --> 01:29:54.000
theory of statistical mechanics where basically all the particles are now removed but you now

01:29:54.000 --> 01:29:58.400
have an effective sort of description of your world this is the same as what happens in neural

01:29:58.400 --> 01:30:02.240
nets right the neural nets we talk about pixels at the bottom layer and maybe edge detectors and

01:30:02.240 --> 01:30:07.440
things at the very top of it we're talking about objects and relations between objects which are

01:30:07.440 --> 01:30:14.480
aggregated emergent properties from this neural net and ideas from renormalization theory might

01:30:14.480 --> 01:30:20.400
very nicely apply to this particular problem and indeed have already been applied with some success

01:30:20.400 --> 01:30:25.920
the other one which you mentioned was chaos and I think there is a very nice connection actually

01:30:25.920 --> 01:30:32.640
with chaos theory going back to work I did a long time ago which are called herding in particular

01:30:32.640 --> 01:30:38.800
you can think of sampling from a particular distribution you can do it either by the typical

01:30:38.800 --> 01:30:43.200
way is first of all you can think of it as a dynamical system as a stochastic dynamical system

01:30:43.200 --> 01:30:48.080
and you think of it as there's a you're at a particular point and then you propose to go

01:30:48.080 --> 01:30:52.000
somewhere and then you accept or reject a particular point and then you just jump through

01:30:52.000 --> 01:30:58.240
the space and you collect your the points that you jumped to then you look at that collection and

01:30:58.240 --> 01:31:02.640
that collection should then actually distribute according to the probability distribution that

01:31:02.640 --> 01:31:08.080
you're sampling from now that's a stochastic process but if you think very hard about that

01:31:08.800 --> 01:31:13.600
in fact it's a deterministic process even if you try to make it stochastic and the reason is that

01:31:13.600 --> 01:31:18.080
every you know you're doing a whole bunch of calculations and so now and then you call a

01:31:18.080 --> 01:31:23.200
random number generator but the random number generator really is a pseudo random number generator

01:31:23.200 --> 01:31:27.680
it is also a deterministic calculation that you're doing so the whole thing end to end is just a

01:31:28.400 --> 01:31:32.880
a deterministic calculation but because you're calling the pseudo random number generator it

01:31:32.880 --> 01:31:38.800
looks very stochastic but truly it is a chaotic process and so you should really be able to describe

01:31:38.800 --> 01:31:44.080
the system by chaos theory and the theory of nonlinear dynamical systems now what I've been

01:31:44.080 --> 01:31:52.240
working on with my postdoc and Roberto we've been working on is thinking about let's make it a little

01:31:52.240 --> 01:31:58.480
bit less chaotic so let's make this actually a deterministic system which is maybe at the edge

01:31:58.480 --> 01:32:03.840
of chaos and again this is one of these very deep questions that's in my head so I think so there's

01:32:04.480 --> 01:32:08.480
there is something very interesting and deep here which is if you do if you try to

01:32:09.120 --> 01:32:15.920
do a computation on the one hand you want to store information things that you've calculated

01:32:15.920 --> 01:32:21.840
and for that things need to be stable on the other hand you want to transform information

01:32:21.840 --> 01:32:26.240
because that's what a calculation is right and so there you want to be in this sort of

01:32:26.240 --> 01:32:31.360
more chaotic domain and it turns out that the best place to be is at the edge of two things

01:32:31.360 --> 01:32:35.120
where you can go to the right a little bit and be more stable and go to the left a little bit

01:32:35.120 --> 01:32:41.520
and you can transform things and compute things and so I also think that when you're trying to

01:32:41.520 --> 01:32:47.040
sample or in you know sampling can be equated with learning if you're Bayesian about things because

01:32:47.040 --> 01:32:51.360
in learning is basically sampling from the posterior distribution and that's same as learning

01:32:52.400 --> 01:32:59.120
you can if you can design samplers that are not completely chaotic as the ones that we describe

01:32:59.120 --> 01:33:04.000
now but they're more structured and less chaotic and more deterministic moving through the space

01:33:04.000 --> 01:33:08.880
you can learn a lot faster and I find that and then you can actually start to map it

01:33:08.880 --> 01:33:14.400
onto sort of complexity theory notions if you think of this sampling from a discrete set of

01:33:14.400 --> 01:33:20.080
states what kind of properties do the sequences that I generate have what is the entropy of the

01:33:20.080 --> 01:33:25.280
sequences that I'm generating for instance or what kind of substructures is it for instance going to

01:33:25.280 --> 01:33:29.760
be periodic or are there periodic substructures inside of it or all these things and these are

01:33:29.760 --> 01:33:34.800
studied by the theory of chaos and nonlinear dynamical systems so connecting these two fields

01:33:35.680 --> 01:33:41.280
feels to me like a very fundamental thing to try and do and some people have tried a few things

01:33:41.280 --> 01:33:45.760
people have looked at well if you look at a neural net there's an iterated map you map things to

01:33:45.760 --> 01:33:51.840
hidden layers in later if you think of that iterated map and think of it as is that map chaotic

01:33:51.840 --> 01:33:58.080
being on the edge of chaos is the best thing you shouldn't be completely or nonmovable because

01:33:58.160 --> 01:34:02.720
then everything you put in is going to be mapped to the same point very uninteresting you also

01:34:02.720 --> 01:34:07.760
shouldn't be super chaotic because or whatever you put in you're going to some random point in space

01:34:07.760 --> 01:34:12.800
and that's not very predictive so you need to be at this intersection space between chaos and non-

01:34:12.800 --> 01:34:17.840
chaos and then you can do interesting computations so this is the same idea right so to me that's

01:34:17.840 --> 01:34:23.840
exciting because now suddenly a whole field of exciting mathematics is cracked open and you can

01:34:23.840 --> 01:34:29.440
start to use all these tools in machine learning awesome thank you fantastic now might be a good

01:34:29.440 --> 01:34:36.720
time to go over to reddit we asked reddit for questions and the top rated question is by tsa

01:34:37.360 --> 01:34:40.480
hi max when will you be changing your last name to pooling

01:34:44.240 --> 01:34:50.160
so actually there is a paper that a colleague of mine wrote and i think they had an operator

01:34:50.960 --> 01:34:57.200
instead of pooling you could you could do a a welling operator so and instead of changing

01:34:57.200 --> 01:35:01.920
my name i i propose that we just change the operators that we use and change to welling

01:35:01.920 --> 01:35:07.760
operators that's wonderful in the thread on reddit there were a few variations as well so maybe max

01:35:07.760 --> 01:35:14.560
power and someone asserted that pooling is your brother but anyway red portal says the conventional

01:35:14.560 --> 01:35:19.600
approach for analyzing continuous convolution would be Fourier analysis what was the rationale

01:35:19.600 --> 01:35:24.880
behind the investigating continuous convolutions using probabilistic numerics that's a good question

01:35:24.880 --> 01:35:31.040
so to me Fourier analysis it's true that you can i guess i could still do a Fourier analysis

01:35:31.040 --> 01:35:36.880
right because a Gaussian process you can decompose in terms of its Fourier waves and then it's the

01:35:36.880 --> 01:35:43.280
primal versus the dual view of a sort of any sort of kernel method so i could certainly go to the

01:35:43.840 --> 01:35:48.320
Fourier domain and do my calculations in the Fourier domain the quantum mechanics this is

01:35:48.320 --> 01:35:52.480
just another basis you just think of this as another basis you know not only quantum

01:35:52.480 --> 01:35:57.600
mechanics in any signal processing sense and it's true that a convolution is easier there

01:35:57.600 --> 01:36:05.680
because just multiplication on the other hand convolutions are very efficient in modern software

01:36:05.680 --> 01:36:12.800
packages for gpu so sometimes it's also not necessarily faster to do that but it's a good

01:36:12.800 --> 01:36:18.240
suggestion and maybe something nice happens when you go to Fourier space and i just didn't explore

01:36:18.240 --> 01:36:26.720
that fantastic we've also got jimmy the ant lion says hi max i notice your co-authors come from a

01:36:26.720 --> 01:36:32.800
physics background can you explain why there are so many x physicists in deep learning yeah so that's

01:36:32.800 --> 01:36:38.480
interesting i think there's just a lot of physicists and a fraction of those physicists is looking for

01:36:38.480 --> 01:36:44.160
other for greener pastures and i'm myself on one of those that i was looking for greener pastures

01:36:44.880 --> 01:36:50.480
and they bring a really good toolbox so if you're done physics you're you have just a very good

01:36:51.040 --> 01:36:56.400
mathematical toolbox but also very good intuition about PDEs and other world works and

01:36:56.400 --> 01:37:01.760
symmetries and all these kinds of things you bring and i think in some sense physics is also a bit

01:37:01.760 --> 01:37:06.240
of a container right if you do physics you can still do anything else afterwards in some sense

01:37:06.800 --> 01:37:12.080
and i think just there's just people who are naturally interested in in ai of course ai became

01:37:12.080 --> 01:37:17.280
very popular at some point and so you have automatically people flock into that into that

01:37:17.280 --> 01:37:23.120
field but yeah in general they're smart people so i guess it's nice to work with them maybe just

01:37:23.120 --> 01:37:28.240
circle back and close the loop to the beginning and we were talking about the research community

01:37:28.240 --> 01:37:35.360
and kind of the machine learning research field i i loved what you suggested and as i understand

01:37:35.360 --> 01:37:41.760
this is not fully your suggestion but the suggestion of let's say having a more open review kind of

01:37:41.760 --> 01:37:47.680
system where a review could be as powerful as a paper itself i've been screaming for this for

01:37:47.680 --> 01:37:54.960
a few years now and could i ask if you if you ever have the chance to propagate this what do you

01:37:54.960 --> 01:38:00.800
think of the idea of having a continuous research like this paper notion that we have now i think

01:38:00.800 --> 01:38:06.880
it's so outdated and once my paper is published i have no incentive to update that thing what what

01:38:06.880 --> 01:38:12.640
if we do research in in this much more continuous way and then there's comments and then in response

01:38:12.640 --> 01:38:19.040
to the comments everything changes and so on yeah no it's very good point it's it's so this is indeed

01:38:19.040 --> 01:38:25.360
exactly part of this idea that we are trying open review to implement yeah but it's the idea is that

01:38:25.360 --> 01:38:30.000
in open review you have a conversation with your reviewers and it's nice if the reviewers are not

01:38:30.000 --> 01:38:34.560
anonymous and just you just have your conversation and other people can even contribute to the project

01:38:34.560 --> 01:38:39.680
in a more open science way but it is also nice for now and then to present your work and so

01:38:39.680 --> 01:38:46.240
that's why i say so now and then a conference might come in and harvest papers and just invite

01:38:46.240 --> 01:38:50.960
people to present their work in sort of slightly more formal way and maybe put a stamp of approval

01:38:50.960 --> 01:38:56.320
on it and say this conference has published or this particular paper with some independent reviews

01:38:56.320 --> 01:39:01.360
and we think it's a great paper and so you get that stamp so it and i guess there should also be a

01:39:01.360 --> 01:39:07.600
way to close off a particular project to move on to a new project but i also have the same view as you

01:39:07.600 --> 01:39:14.720
have as this being a far more continuous process where you know if you didn't get picked this time

01:39:14.720 --> 01:39:19.680
next time somebody some conference will come by and pick you out this it's much more like a marketplace

01:39:19.680 --> 01:39:25.280
where ideas go around conferences come in and ask you to publish things and it's just you then

01:39:25.280 --> 01:39:29.920
present it and then you can just continue with your research or stop and then go to a new piece of

01:39:29.920 --> 01:39:35.280
work or something like this so yeah i i share that vision basically that's it's amazing i'm

01:39:35.280 --> 01:39:41.520
continuously amazed when i read these old papers from let's say schmid uber and like the first rl

01:39:41.520 --> 01:39:46.640
papers that just came up with a bit of an idea and then they had a bit of toy data and right and

01:39:46.640 --> 01:39:53.520
that's a paper and and it's cool do you have any do you have any kind of thoughts about or recommendations

01:39:53.520 --> 01:39:58.880
for the new generation of researchers that are now flooding the fields of how can we get to a

01:39:58.880 --> 01:40:05.360
better field what kind of tips would you give the yeah we i think we really need to disrupt the field

01:40:05.360 --> 01:40:10.720
a little bit and so i think we i think the new i think it's particularly tough for new researchers

01:40:11.360 --> 01:40:17.200
because it's the acceptance rates for these conferences are very low and it feels like much

01:40:17.200 --> 01:40:22.640
of your future career depends on getting papers in there and it's a fairly random process as well

01:40:23.520 --> 01:40:26.960
so i think we just need to disrupt the field and there's enough people

01:40:28.400 --> 01:40:33.840
with influence who want that so it's just a matter of actually executing on it and so that's

01:40:33.840 --> 01:40:39.920
what we do it now for the bayesian deep learning workshop that we are organizing this we want this

01:40:39.920 --> 01:40:48.160
to be a an off-split from new rips it was a very popular workshop there and somehow we got rejected

01:40:48.160 --> 01:40:53.520
this year and we thought okay we'll just do it ourselves we do have actually a meet-up but then

01:40:53.520 --> 01:40:58.480
next year we want to be our standalone conference but for that conference we want to implement this

01:40:58.480 --> 01:41:03.600
plan and so we are working with open review to actually implement this for us and jaren gall is

01:41:03.600 --> 01:41:09.520
working hard to try to actually roll this out we're talking to yashua benjo about it and he's

01:41:09.520 --> 01:41:13.760
very supportive and there's a whole lot of people who are supportive about it but so if this can help

01:41:14.720 --> 01:41:19.280
to make this a popular model then that will be a fantastic result of this interview

01:41:19.280 --> 01:41:23.120
but i think people should just push for it and just say okay i'm just fed up with the

01:41:23.120 --> 01:41:28.160
current way of doing things we should really change things and just a shout out and say

01:41:28.160 --> 01:41:35.280
this is what we want and let's go for it awesome amazing professor max welling it's been an absolute

01:41:35.280 --> 01:41:40.240
honor and a pleasure to have you on the show thank you so much for joining us today it was great

01:41:40.240 --> 01:41:44.400
with the three of you asking questions that works really well fantastic thank you so much

01:41:44.400 --> 01:41:50.160
thank you amazing it was good the questions were really fantastic actually and i've never

01:41:50.160 --> 01:41:54.400
done this with the three of you but having a team of three people asking questions is really

01:41:54.400 --> 01:41:58.640
it's a good idea and of course you're really smart people knowing what you're talking about so that

01:41:58.640 --> 01:42:06.560
went really well i think needs three brains to match yours anyway i really hope you've enjoyed

01:42:06.560 --> 01:42:12.080
the show today this has been such a special episode for us because max welling is is literally one

01:42:12.080 --> 01:42:18.560
one of my heroes so anyway remember to like comment and subscribe we love reading your

01:42:18.560 --> 01:42:23.600
comments we really do actually we're getting so many amazing comments in the comment section so

01:42:23.600 --> 01:42:31.440
keep them coming and we will see you back next week

