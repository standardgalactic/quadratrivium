{"text": " Let's have Melanie Mitchell to give our final opening statement, six minutes on the clock, Melanie. Yeah, so this is my opportunity to say I love Melanie. She is amazing, and she's coming back on MLST in about two weeks. Oh, amazing. Yeah, that's good. Yeah, she gives a good representation of herself in here, I think. Melanie is amazing. Fears about machines unleashing human extinction have deep roots in our collective psyche. These fears are as old as the invention of machines themselves. But tonight, we're debating whether these fears belong in the realm of science fiction and philosophical speculation, or whether AI is an actual real life existential threat. I'm going to argue that AI does not pose such a threat in any reasonably near future. Large language models have sparked heated debate on whether AI's exhibit genuine understanding of language and the world. With capabilities rivaling humans across diverse benchmarks, some hail language models as harbingers of real intelligence. But skeptics argue that their mastery is skin deep, lacking true comprehension. So how can we assess these claims and gain insight into the nature of what it means to understand? Now, on the show today, we have Professor Melanie Mitchell, a leading thinker on AI and intelligence, and one of the researchers in the community I personally most align with and look up to the most. Melanie's distinguished career crosses computer science, complex systems, and cognitive science, and she wrote the influential books Artificial Intelligence, A Guide for Thinking Humans, and also Complexity, A Guided Tour. Now central to Melanie's perspective is the idea that human understanding relies on flexible mental models grounded in sensory experience. Now she wrote that understanding language requires having the concepts that language describes. Large language models are trained purely on statistical relationships between words. Their knowledge is not grounded in a causal model of reality. Now Melanie is the Davis Professor of Complexity at the Santa Fe Institute, and her major work has been in the areas of analogical reasoning, complex systems, genetic algorithms, and cellular automata. She's achieved legendary status in the field of AI. She received her PhD in 1990 from the University of Michigan under Douglas Hofstadter, the famous author of Godel Escherbach. Melanie argues that we must rethink how AI systems are evaluated. Typical benchmarks summarize aggregate performance and, you know, these obscure failure modes and mask the underlying mechanisms. We need rigorous granular testing focused keenly on abstract generalization. Sort of like a sorcerer's apprentice gone nuclear. For example, Yoshua Benjiro wrote about this thought experiment. We might ask an AI to fix climate change and to solve the problem it could design a virus that decimates the human population, presto, humans dead, no more carbon emissions. This is an example of what's called the fallacy of dumb superintelligence. That is, it's a fallacy to think that a machine could be, quote, smarter than humans in all respects, unquote, and still lack any common sense understanding of humans, such as understanding why we made the request to fix climate change and the fact that we prefer not to be wiped out. This is all about having insight into one's goals and the likely effect of one's actions. We would never give unchecked autonomy and resources to an AI that lacked these basic aspects of intelligence. It just does not make sense. The third scenario. Yeah, that is absolutely. She made that point so much more eloquently than I've tried to make it in the past. Yeah, even earlier in this conversation, I was trying to get that across, but that's exactly it. It's this dumb superintelligence. Yeah, exactly. Anyway, folks, I hope you enjoy the show, and now I bring you Professor Melanie Mitchell. Sounds like almost like there's a very quiet supercomputer running behind the screen. It's my brain. Yeah. I think that's what this is. You know, we can robustly adapt much more so than GPT-4. You and I have the same chair. We have the same chair, I think. Oh, yeah. I can't see your chair. Yeah. Me too. They're home in Miller. Yeah, I think they're all the same chair. Yeah. Yeah. Excellent chair. Yep, chair buddies. Yeah. I felt it would be hundreds of years before anything even remotely like a human mind would be asymptotically approaching the level of the human mind, but from beneath. I never imagined that computers would rival or let alone surpass human intelligence, but it seemed to me like it was a goal that was so far away. I wasn't worried about it, but when certain systems started appearing and then this started happening at an accelerating pace, it felt as if not only are my belief systems collapsing, but it feels as if the entire human race is going to be eclipsed and left in the dust. Douglas Hofstadter, he came out as a doomer. Well, I don't know if he came out exactly. He's been a doomer for quite a while. Oh, go on. I wasn't aware of that. Well, I don't, you know, doomer is, you know, there's different kinds of doomers. In my AI book, the first chapter, the prologue is called Terrified, and it's all about how Doug is very terrified about AI and the possible things that are going to come. That was based on a talk he gave in 2013, and earlier than that, he was extremely worried about the singularity, the idea of the singularity from Kurzweil, and wrote quite a bit about that. So, I feel like that it's not that new, but maybe this is sort of because there's so much talk about AI, doom, and so on, that this is kind of, people are kind of paying attention now. Yeah, I don't know whether I misunderstood something because I read out, you had this beautiful piece about the Googleplex in Chopin, and he was terrified that cognition might be disappointingly simple to mechanize, and, you know, surely we couldn't replicate the infinite nuance of the mental state that went into writing that beautiful music. But so maybe he was worried about it, but he didn't think it was possible in principle or something. Well, no, he was quite worried about that it was going to happen sooner than he thought, and that, you know, his quote that it's AI is going to leave us in the dust. So that's kind of his flavor of doomer. I'm not sure he has the same, like, existential worry about things as, like, Stuart Russell or somebody. Okay. So he's not so worried about them necessarily churning us into, you know, fertilizer or raw materials or something, but just that it's not so specific, I think. But yeah, yeah, I talk to him about it all the time, and he wavers. Oh, interesting, because I've heard you define yourself as a centrist on other podcasts, because I'm sure the doomers would lump you in with Cholet and Lacune, maybe, and some of the critics, but you do think that these models are intelligent, right? I do think that they're intelligent. Well, you know, intelligence is an ill-defined notion. Oh, yeah. It's multidimensional, and, you know, I don't know if we can say yes or no about something being intelligent rather than, you know, intelligent in certain ways or to certain degrees. Yeah. Well, we've got so much to get into. I mean, I think slowly we'll talk about arc and your concept arc work, but I kind of agree with you that, and actually you had that paper out about the four fallacies, and you spoke about this fallacy of pure intelligence, and I kind of agree that the gnarly reality is far more complex than that. There was a really interesting paper that you linked on, no, it was an article by Dileep George, and he said that a university professor has a much better understanding of a vector, because it's just grounded in so many real-world situations and contexts and so on, and an undergraduate or, indeed, a language model would have a very ungrounded, very kind of low-resolution idea of what this concept is, and it kind of leans away from this puritanical, ungrounded, abstract form of intelligence to something which is really very complex and intermingled. Yeah. I mean, I agree with that. Well, except that there's another aspect to that, too, which you write about, which is, I agree that that happens, but what the human mind also seems to do is, as the thing becomes more grounded in more cases, then we develop yet another concept that kind of describes the similar aspects that we see throughout all those different concepts, right? So we're kind of this iterative loop where we're always finding more and more context, and then we're also finding newer and newer concepts that span those increasing contexts. Is that fair? Yeah, sure, yeah. I mean, that kind of goes along with the whole sort of metaphor theory of cognition, of Lake Offit at all, and that we're sort of building on these physical metaphors, and we can build up many, many layers of abstraction. So, yeah, we can talk about that. We're not recording yet, right? Oh, no, we are. We are. This is all recording. Oh, we are? I hope you're okay with what you said so far. But yeah, so there's the Lake Off building on the body of symbols as pointers. And by the way, that Dileep George article was really fascinating because it was saying that language is a conditioning force. So actually, we all have these high-resolution world simulators built into us, and we kind of condition how that operates and generate counterfactuals through language, which I thought was quite interesting. Yeah. Yeah. But, Tim, why don't you frame up the debate? Because we found a beautiful paragraph. We did. We did. We found an amazing bit. Yeah. But just to close the loop on what I was saying, we were discussing an activism last night. I'm not sure if you're familiar with some of these externalized forms of cognition, and we were talking about the concept of a goal. And agents, of course, they just have these high-resolution belief trajectories of, you know, I can do all of these different actions. And that's not really a goal. You know, a goal is this very abstract thing which emerges at the system level, and no individual agents in the system have a concept of a goal. And it might be similar with some of these concepts that we're talking about, which is, to what extent do they exist, and to what extent are they just something intelligible that we can point to, but they don't really meaningfully exist in the system at a high-resolution. Are you talking about an AI or in people, a little piece here? All of the above. I mean, I think goal is a wonderful example, because we think of it. I mean, it's even one of Spelke's core priors. It seems like something so primitive. But I don't think they really do exist in us. I mean, we're interesting because we have this reflexive conception of a goal, but does a mouse have a goal? Right. I mean, goal is another one of those words that, you know, we use in a very fluid way. So we talk about, for instance, a reinforcement learning agent having a goal that we've given to it, right? Or it might have a goal to kind of maximize its information gain or something. But is that the same thing as a human having a goal that it's like, you know, to graduate from college or to, you know, make something of your life for all of these things? It's a very different sense of goal. And so I would say, yes, a mouse has goals, but those goals are different in degree and in kind of qualitatively than many of the things we call goals in humans and in machines. So I think goal is one of those sort of anthropomorphizing words that we need to be careful about when we equate goals in these different systems as being the same thing. And I actually, you know, had a discussion with, I think it was with Stuart Russell about the notion of goal. And his view, and I think this is a view of many other people in AI, is that large language models actually have goals, complex goals, that they, that emerge out of this, you know, their loss function of predicting the next token, because the only way to successfully predict the next token in human language is to develop human-like goals. I find that dubious, but it's an interesting perspective. Yeah, I'm amenable to it, because there's always this dichotomy, as you say, of there's the objective, there's perplexity, and there's these emergent goals, and there's even this simulator's theory of large language models, which is that they're a superposition of agents. And it's quite situated as well, because goals kind of materialize depending on your perspective. So if you use a language model in a certain way from a certain perspective, it might appear that there is some kind of goal there, but of course, it's just an aspect onto something which is very complex. But I think we should frame up this beautiful piece, actually, from your Modes of Understanding paper from much this year. I always call it the Modes of Understanding paper. It was actually titled The Debate over Understanding in AI's Large Language Models. And you said, towards the end, that the key question of the debate about understanding in large language models is, one, is talking of understanding in such systems simply a category error, which is mistaking associations between language tokens for associations between tokens and physical, social, and mental experience? In short, is it the case that these models are not and will never be the kind of things that can understand, or conversely, to do these systems or their near term successes? Actually, even in the absence of physical experience, create something like the rich concept based mental models that are central to human understanding. And if so, does scaling these models create even better concepts? Or three, if these systems do not create such concepts, can their unimaginably large systems of statistical correlations, produce abilities that are fundamentally equivalent to human understanding, or indeed that enable new forms of higher order logic that humans are incapable of accessing? And at this point, will it still make sense to call such correlations spurious and the resulting solutions shortcuts? And would it make sense to see these systems' behaviors not as competence without comprehension, but as a new, non-human form of understanding? And you said that these questions are no longer in the realm of abstract philosophical discussions, but they touch on very real concerns about the capabilities and robustness and safety and ethics of AI systems. So let's use that as a leader. What do you think, Melanie? It's beautiful. That was a beautiful paragraph, by the way. Yeah, it's so good. Wow. This exactly crystallizes the discussion. Yeah, I think that it's something that we in AI are all grappling with now. And I think it's something that the history of AI has forced us to grapple with mental terms like understand, or consciousness, and even intelligence. Because we keep saying, oh, well, understanding, if you can do X, then that means that you're actually understanding. You can't do language translation without understanding. You can't do speech to text without understanding. You can't generate articulate natural language without understanding. And I think this is, in many cases, we then step back and say, wait, that's not what we meant by understanding. It turns out you can do all these things without understanding. So we're sort of saying, well, we didn't really know what we meant by the term understanding, I think. And often, some people criticize that as moving the goalposts. You're moving the goalposts. The so-called AI effect, right? Right. It's the AI effect. But I think of it more as AI is forcing people to really refine their notions of that that have been quite fuzzy about what these terms actually mean. And there was a fantastic talk by Dave Chalmers, the philosopher, who I think you've probably had on this show, where he talks about conceptual engineering, which is something that philosophers do where they take a term like understanding and they refine it. And he said, okay, well, we have p-understanding, which is like personal, phenomenological. And then we have c-understanding and e-understanding and x-understanding and all these different letters that meant to say that this term is not a unified thing that we can apply to a system. We have to really specify what we mean exactly. Well, one way I've come to think about it, and it's largely from reading your work and your assessments about it, is that for the first time, we're actually being forced to do the science of machine cognition, right? Because for too long, it's either just not been sophisticated enough. Why bother? Like it's obviously not doing any cognition. And as you point out, it's now actually having real world impacts. And so we actually have to start doing the science, right? We have to say, okay, does this thing have cognition? Here's a hypothesis. Let's do some test. Okay, it failed. What was the failure mode? Why did it fail? Let's understand that more. How can we engineer it not to fail? It's like we can no longer ignore adversarial examples, shortcut learning, et cetera. We have to finally grapple with it, it seems to me. Yeah, I think that's exactly right. And what's interesting is we, computer scientists, were never trained in experimental methods. We never learned about like controls and confounding things. It's a great point. And so now people are doing, applying human tests of understanding or intelligence or reasoning, what have you, to machines without having the right experimental methods to say whether or not what they're testing is actually valid. So there's a cognitive scientist named Michael Frank at Stanford, who's been writing a lot of stuff about experimental method and how do you apply it to AI and why you need sort of expertise in this area to really make sense of these systems. And I'm totally on board with that. Yeah, we'll talk about your piece with Tannenbaum later, but as you say, a lot of AI folks don't really think about experiment design. But actually, even with Chalet's ARC challenge, maybe we should talk about that. So he invented this measure of intelligence, which unfortunately was not computable, but it was mathematically beautiful. Basically saying that, and he's a huge Spelke fan, I kind of put Chalet very, very close to you actually in AI researcher space. And his measure of intelligence basically says, I give you priors, I give you experience, you give me a skill program, it extrapolates into these different spaces and experience space. And the kind of the conversion ratio between those priors and experience and the space that I get is intelligence. And that's very interesting. And then he produced this corpus, this ARC challenge. And it's a bit like an IQ test. It's this kind of 2D gridded colored cells. And you have a couple of examples, and you have to do another one or two examples. And it was very diverse because it was testing what he called developer aware generalization. And there were a couple of issues with that. So you wrote this beautiful concept ARC paper, and maybe you can introduce that. But one of the things you pointed out, which I felt was quite interesting is that even if people succeeded on Francois's challenge, it wouldn't necessarily be what we would call intelligence, because it's not necessarily demonstrating systematic generalization beyond those one or two examples in his test set. So our motivation was twofold. So first of all, I love the ARC challenge. It's beautiful. It's super elegant. And I'm very sympathetic with Francois' definition of intelligence, although I think there's probably, again, intelligence is very multi-dimensional. But this is one aspect of it for sure. And his problems are great because they just give a few examples, and people are pretty good at abstracting a rule or a concept from just a few examples. And they don't use language, so they don't get into the whole prior knowledge of language and a lot of things that you don't want to confound these tests. But one of the problems with ARC is that many of the problems are quite hard. They're quite hard for people. And they're so hard that they don't really differentiate between different programs that are attempting to solve this challenge. So there was a Kaggle competition with the ARC challenge, and there were two, the two best programs got about, they each got about 20% accuracy on the hidden test set. So it didn't really distinguish them at all. And the other problem was that, as you mentioned, the test wasn't very systematic, meaning that let's say there's a problem in ARC that deals with the concept of inside, something being inside something else. And let's say that something, a program gets that one right. Does that mean that it understands the concept of inside in a general way? Well, we don't know because the test doesn't test that systematically. And that was actually intentional from Sholey, because he didn't want any way to, for programs to be able to reverse engineer the generation process of these problems. So if you say, oh, well, I'm going to deal with these 10 concepts, then somebody presumably could reverse engineer those, the problems and not be general. But for us, we wanted to say, well, how would you just systematically test a program for understanding of a concept of a very basic, spatial or semantic concept? And so what we did was we took the ARC domain and we created about almost 500 new problems that were systematically grouped into concept groups. So like inside of, that was one of the groups. And so we looked at, we created several problems that were variations on that concept. And there were variations that ranged in like abstraction, degree of abstraction, and sort of complexity of the problem. And the hypothesis was that if a human or a program could successfully solve the problems in a given concept group, they really do have a good sort of grasp of that concept. So this was the genesis of concept ARC. You know, it's fascinating because so you're, you're attempting again to build the science of machine cognitive science, essentially. And hey, it has to be systematized, we need to have these concept categories, we need to be able to generate examples of progressive complexity and, you know, layer of abstraction, everything. And then yet you mentioned Chalet intentionally didn't systematize it to avoid reverse engineering. And that's kind of a fascinating point because reverse engineering can even happen, you know, just by way of selection bias. So I mean, researchers are out there, they're fooling around with different neural network structures, maybe I'll add like a you here or some horseshoe over there. And lo and behold, suddenly, it works really well on the concept of inside out. And I'm going to claim this is machine learning, even though it was actually human engineering that sort of put that structure into the network. So in the long term, you know, how do we, how do we balance that? Or how do we avoid it? Or how do we test for machine induced, you know, prior knowledge versus actual machine learning? Yeah, no, I understand it's a hard problem. And I think, you know, the goal with this concept arc benchmark wasn't to sort of supplant arc in any way, it was really meant to be complementary. And it was meant to be kind of a stepping stone to the much larger and more difficult arc set. Because I think, you know, even if I tell you all of these problems have to do with the concept of inside versus outside, you would still have to have a good grasp of those concepts in order to solve these problems. And I'm not sure that you could sort of engineer something that would solve those cons problems of that concept in general, without having a more, you know, really a general understanding in some sense of those that concept. But to Keith's your point, I think having a static benchmark is a problem, sort of putting out a benchmark that everybody can kind of try and optimize their program to solve. We've seen that over and over again. That ends up being sort of a way that people end up reverse engineering to a particular task rather than to a more general set of conceptual understanding. So I do think that we have to keep changing our benchmarks. We can't just say, okay, here's image net, go, you know, beat on that for the next 20 years until you've solved it. That's not going to yield general intelligence. Yeah, I think one of the issues we're talking about in general is extrapolation. So, you know, Sholey used extrapolation to talk about skill programs and being able to do things beyond your priors and experience. But with benchmarks, it's about human extrapolation. So I think part of the problem with the risk debate, by the way, why everyone's so suddenly worried about risk is because of this benchmark problem. And that's because we see that humans who can do A can do B. And now we see machines that can do A. And we have all of these built-in assumptions in benchmarks. And we don't really realize that we're talking about machines now. We're not talking about computers anymore. And I think it's causing a real problem. I don't want to be hyperbolic here, but it feels like there's this massive delusion taking over the entire machine learning community. And we're seriously talking about AI risk. And I think it all comes down to these benchmarks fundamentally. Yeah, I do think all of our benchmarks have, as you say, have this problem of that they have assumptions built in that if a human could do this, that then the machine must, if the machine does it, it has the same kind of generalization capacity as a human who could solve that problem. This goes back all the way to say chess as a benchmark. So people used to think that if, because if a human can play chess at a grandmaster level, that means they must be super intelligent in other ways, that if a machine could play chess at that level, it would also be super intelligent like a human. Herbert Simon even said that explicitly. But then we saw that chess actually could be conquered by very unintelligent brute force search that didn't generalize in any way. So I think this is an issue today with large language models. They can do things like pass the bar exam and pass other standardized human tests of skill or intelligence. But what does that mean? It doesn't necessarily mean the same thing for a machine as it does for a human for many different reasons. Yeah, I guess it's a similar thing with the McCorduck effect that we have relative pointers to what we think of as being intelligence. We just point to something and then when that thing becomes easy, then we need to kind of move the pointer. Yeah, I think it also feeds into, as Tim was saying, I think it heightens the fear of existential risk because of this, this concept that we have of intelligence always wins, which even among humans is, is a flawed concept, right? I mean, you know, many nerds who grew up through elementary school can tell you like intelligence doesn't always win, right? Like sometimes it's numbers or brute force or whatever else kind of kind of wins. And they assume like, well, if we were to have this purified intelligence that was super intelligence, it would be as if a human brain were super intelligent and they'd be able to do everything a human being could do and hurt other people and conquer the world and fight wars. And that again, is this anthropomorphic projection, right? Yeah, I mean, right. So, and it's this notion that intelligence is this thing that you can just have more and more of. Forever. Forever. Or so far that it's just beyond any, you know, it's almost magical, right? And it's capable. Right. And it's not, you know, a different view of intelligence is that it's a collection of adaptations to specific problems for a particular kind of organism in an environment. And it's not the sort of an open-ended, pure domain independent thing. So, I think this is why, you know, you see a lot of discussion of super intelligence, AGI, you know, AI risk in among computer scientists, but you don't see a lot of it discussed among like psychologists or animal intelligence people or other cognitive scientists. Because that's not the way that they understand intelligence. I would love to explore more about that because, I mean, only yesterday when we were talking about an activism, we're also talking about Gibson's ecological psychology. And even Elizabeth Spelke, I mean, this kind of cognitive psychology view is very related to nativism. It's this idea that we have these fundamental cognitive primitives and intelligence in some sense is just traversing or recomposing this library of cognitive modules that we have. And those modules are very physically situated, you know, they tell you something about the environment that you're in. Which means that intelligence is just very gnarly and it's very kind of coupled to the environment we're in. It can't really be magically abstracted in a computer with infinite scale. Yeah, I think that's right. That's, you know, people have different views about the nativism, empiricism, debate. And there's whole different schools and cognitive science about like how how much is learned, how much is evolutionarily built in and all of that. But I think most people in the field would agree with what you said that intelligence is very gnarly. It is situated, it is specific to particular domains of concern to a particular organism, and that it's not easily abstractable. You know, that back in the early days of AI we had Newell and Simon, two of the pioneers of AI who had this thing called the physical symbol system hypothesis, which was that basically you could sift off intelligence from any material substrate like the brain and put it in some other material substrate like a computer. They were thinking about symbols, but nowadays people have the same kind of view with neural nets or transformers or whatever, that you can take human intelligence that's very situated and tied to the environment and sort of sift off the pure part and leave all of that bodily stuff and you can get something like superintelligence. And I don't think most people in cognitive science would agree with that. Well, on the other hand though, I think, and I'd be curious to get your take on this, is one direction that that comes from is for those of us, and I include myself in this camp tentatively, that at the end of the day what the brain does is some form of computation. You know, like absence, the proof that there's such a thing as hypercomputation, like our brain, all of its calculations could be embodied in a large enough you know, Turing machine and a large enough computer of some kind. And therefore, everything that we do, including our intelligent activities, could be coded somehow or another into a Turing equivalent system. And for the record, I don't believe neural networks are. I've said this like multiple times, at least in their current manifestations, they're not, they're just a feed forward, you know, thing at the end of the day. But if you actually had a computer, you could have human symbolic intelligence encoded. Like, where do you stand on that, on that debate, if you will? Yeah, I have nothing against the idea that the brain does computations. I think that's, that's, you know, one possible way to look at it. And that those kinds of computations could be implemented in another kind of computer. But the brain is a very special kind of sort of biological computer that's been evolved to do specific things. And one of the main things the brain has been evolved to do is control the body, and in particular kinds of environments. And so I think the brain is doing computations, but it's doing very, very highly evolved, very domain specific computations that perhaps don't necessarily make sense without having a body. Now, that's debatable. But it does seem like a lot of the way that we reason is by reference to our own sort of episodic experience in the world. Or at least to the capabilities that have been built into us, you know, like visual, using our visual cortex to imagine cubes and steers and whatever else we need to solve a physics problem or a geometric problem. Sure, sure. Yeah, so I'm fine with saying the brain is a computer of a certain kind, but that's not to say that it's going to be, you can just kind of lift off the computations and then put them in a different substrate and kind of get everything that's human like, because I'm not sure that those computations are going to make sense in the absence of the rest of the organism. Yeah, there was something that always confused me about the autopoietic inactivists, because of course they as they issue representationalism and information processing, but they also issue computationalism in general. And as Keith was just saying, I don't even if cognition is externalized, I don't see any reason why in principle, you couldn't just compute the entire system and and recreate the computation. I just wanted to close the loop on the ARC challenge stuff though. So you said that the winning solutions to Francois' challenge on Kaggle, they were quite simplistic in a way. They were like a genetic search over lots of primitive kind of functions. And even the winner said that they didn't feel it was a satisfying solution, which was interesting. And then you tried it on GPT4. And I think you said you got around 30%. There's now a deep mind paper out very recently, which just basically turned it all into a character set with a random mapping, put it into GPT4, I think got nearly 60%. Even even somewhat invariant to the translation between the character set mapping. Some folks on our Discord forum tried to reproduce it and couldn't. That's the problem with GPT4. You can never reproduce anything. But I was just wondering, would you consider that to be an elegant solution? It's not really much better than searching over a DSL, is it? By that, you mean giving it to GPT4? Well, I mean, it's quite an interesting thing, isn't it? If there's the McCorduck effect, and even before you get to a solution, what would a good AI solution look like? I mean, what would someone have to create for you to say, oh, that's a really cool AI solution? Well, if you had a program that really could solve these tasks in a general way, that would, however it worked, it would be a good AI solution. I don't necessarily think we have to have something like the way people do it. Well, let me see if I can guess, though, maybe an extension to what you said. It's in line with your argument that the benchmarks have to evolve. Because I think that these benchmarks really is just first pass or low pass filters. It's like they weed out the junk. It's like, well, if you can't pass the art challenge, I'm not going to bother with you. If you pass the art challenge, now we have to look further, right? Which is like, okay, so it's been able to generalize along these 19 concepts that we've defined in concept art with little pixel grids. What about if we give it full frame pictures or video or something? Is it able to generalize there? No, okay, it failed. Why did it fail? Well, now we need to do some more engineering. It's going to be this kind of never ending sort of iterative process. So I would say if something passes arc or concept arc, then it's worthy of further study. Sure. Yeah, I agree. I mean, one question is that arcs are very idealized kind of micro world type domain. So does it capture what's interesting about the real world in terms of abstraction? To some extent, yes, probably, and to some extent, probably no. So you're right. Solving arc doesn't mean we're at AGI, if you want to talk about that. It's like in chess, what you brought up earlier. If you took whatever the current best, let's say LC zero or something like that, and it's been trained on standard chess, and then you have a go play chess 960, formerly called Fisher random, where you just random, it's going to suck like humans are going to destroy it, right? Because humans have learned a more generalized and by the way, that also destroys human beings who rely on memory and just sort of like the memorized positions that haven't learned, let's say the skill of playing chess, right? And so this is the type of thing that's going to happen, right? It's like you say, when you take this intelligence and try to apply it to a different context, that's when the rubber meets the road as to whether or not you really learned the concepts, right? Yeah, no, definitely. I agree. And I don't think like our concept arc wasn't meant to be like a test of AGI in any sense. It was meant to be kind of a stepping stone to getting to abilities for abstraction. And clearly, if some program was able to solve all of the problems in that domain, and we'd have to then test further, we'd have to have it be able to extrapolate to a new kind of domain that tested the same kinds of concepts. So you're right, there's no end in some sense. But at some point, I guess, and I don't know when that point is, we have to say, well, this thing seems to be understanding this concept. That's the wonderful continuum, though, because you said earlier, there's something deeply unsatisfying about chess brute forcing everything. And when we apply Francois' measure of intelligence, we don't think of that as intelligent because it's just brute force experience. And then we find something which is a little bit more efficient. So it's something which appears to work. But now, another interesting thing is when you talk about concepts, you had this beautiful article out earlier that she had talking about, on top of, she's on top of the world. And what would Dali draw? It would draw a globe with someone dancing on top of it, or I'm on the TV. What does that mean? It should mean that I'm actually being rendered on the TV. Now, it's kind of like what we were saying with goals, isn't it? Because this skill program, someone just goes on Kaggle and they gives you this program and it seems to work. But it's horribly complicated. And how do you know that the internal representations are in any way related to these abstractions? And do you think that the abstractions as well are somehow universal in the same way Spelki would say that the cognitive priors are? Yeah, I think it's something we can't say. And we don't know with humans. And we don't know with machines, because both of these are very complex systems that are hard to kind of pull apart. What are the internal representations? So in most cases, we have to rely on behavior, which is very noisy. It can be misleading. And it turns out that humans often are not, if you give them a problem, like a reasoning problem, in a familiar domain, they're much better at doing that problem as doing the exact same reasoning kind of abstract reasoning task in an unfamiliar domain. And I think that's something that people have shown is also true of large language models, because they've learned from human language and have incorporated sort of the statistics of some of the statistics of human experience that they're much better on familiar domains than on non-familiar domains. But the one thing that humans can do is often they can kind of transcend that and learn how to reason much more abstractly, which I don't know if we will get to that point with language models yet. So there's a wonderful paper that just came out from a group at MIT and some other places called, I can't remember what it was called, it was something like reasoning versus reciting. And what they do is they talk about this notion of a counterfactual task, which is if you can do one task, like addition and base 10, and you really understand that notion of addition, you should be able to do addition and base eight. And so, but you haven't had as much experience as like for a language model, it's not almost all of the training data has to do with base 10. So, but can, so they tested, they did a whole bunch of these so-called counterfactual tasks and showed that GPT-4 is really good at the original task, but not so good at the counterfactual task. So it's not, in some sense, it is relying on sort of patterns in its training data rather than genuine abstraction. It's a stochastic parrot, right? Well, you know, it could be argued that humans do that a lot too. I don't know if you called a stochastic parrot, but it's more like a pattern matcher. And it's not, it's not reasoning about the things in the sense that we think of reasoning, you know, as sort of domain independent ability. It's very domain dependent. Yeah, so the difference is that I guess the difference I would say is that humans, it can kind of overcome that domain dependency in some cases and actually get to the true abstraction, but I don't know that language models can. Yeah, I mean, there's a couple of things here. So first of all, these language models fail at things which four-year-old children can do. And they can pass the bar exam, but as you've said previously, you wouldn't want one of these things to actually go and practice more. My God, could you imagine the thought? And there was this Sparks of AGI paper where they gave this, I mean, maybe you could recite this better than me, but there was the thing about the book Nine Eggs, a laptop, a bottle, and a nail. Can you balance it in a stable manner? And this comes back to the experiment design because, my God, in any other discipline of science, they would just tear this apart. They would say, well, that's not very robust. I mean, you came up with an example with a pudding, a marshmallow, a toothpick. How would it balance it? Yeah, did it not balance the full glass of water on top of the marshmallow? Well, it stuck the toothpick into the marshmallow and then that's not exactly what we had in mind. No, and in fact, the Sparks of AGI paper, they explicitly said, we're doing anthropology, not cognitive science. Well, that's not the way it was interpreted. Unfortunately, there are YouTube channels now dedicated to educating people on AI and they're taking this as gospel. I mean, what's going on? I think there's just not as much of a focus on sort of scientific method in this field as there should be. And I think in science, if you're looking at a phenomenon and you're trying to replicate it, if it only replicates half the time, that's not a replication. That's not a robust replication. Whereas for language models, people are saying, well, if it can do this task once in one particular circumstances, then it probably has this more general capability. So if it can do this stacking problem once, then wow, it has physical common sense. And people with my marshmallow example, people, of course, jumped on it and said, wait, if you prompt it in a certain way and you do all this prompt engineering, human engineering, it does it right. And then like, well, that's not the point. The point is not any particular example. The point is figuring out how to test things so that you actually have some kind of robust ability for replicating a capability, which we haven't seen with experiments on language models very much. I mean, people are starting to do this. People are starting to do this kind of more scientifically grounded, experimental method on language models, but it's still not very, there's not very much of it. So you might appreciate a phrase I recently coined because it covers this leakage too, of like sort of leakage of human knowledge, which is if you can't find the priors, look in the mirror. It's like, we have to learn how to do experimental science and computer science, and you've got to guard against this type of leak at Drillian, human engineering, and over-involved and whatever. And this is why I really want to collaborate with people in developmental psychology, with people in animal cognition who face this kind of issue all the time. And one example was, I got from a developmental psychologist was that sometimes like a three-year-old can tell you something like four plus three is seven, but if you say, if you give them a bunch of marbles and say, pick out four of them, they can't do it. So there you say, okay, that this kid doesn't understand the concept of four, they're kind of just reciting something that they've heard. And this is the kind of experiments that people in developmental psychology do all the time to really tease out what the system, what babies and children know and what they can do. And it's not an easy thing to do in this kind of experiment. The problem with that is it's extremely complex and requires so much domain knowledge. So it takes a very long time, because I think there was another article that spoke about how we study rats. And those folks in different disciplines, they're really, really good experimental design, and they have experts who kind of create very, very clear criteria for measuring this behavior. And with AI, everything's going up on archive, and everything's going a million miles an hour. And by the time you actually design a systematic rigorous study for the first thing, there's already another paper coming out, which is claiming to do it differently. So we just can't keep up. It's just, it's an absolute nightmare. Absolutely. Yeah. Agreed. I want to just, so I'll quickly touch on one more thing. And I know Keith wants to go into complexity. But yeah, so the information leakage is a problem. The brittleness is a problem. I do think of these GPT models a bit like a database. And so anything that requires physical grounding, of course, doesn't work very well. Some things work surprisingly well, like, you know, programming, because programming is mostly in the internet, it still has all sorts of failure modes, and it's not very reliable, but it's surprisingly reliable. But you put a paper out with Tanenbaum and a whole bunch of other people. And you actually said, well, if you want some policy advice, if you really want to think about how we can improve the situation, you said, aggregating benchmarks and also giving instance level failure modes can actually help us understand why things went wrong or, you know, why things gave us the right answer for the wrong reasons. And there were all sorts of limiting factors, you said. You know, we have this kind of censorship by concision. You're only allowed to have seven pages in your conference workshop paper, and there's no policy about this. So can you give us a heads up on that? Yeah, I mean, you know, traditionally in machine learning, people use accuracy and similar kinds of aggregate measures to report their results. And, you know, if someone tells you that the accuracy was, you know, 78%, what does that tell you exactly? I think, you know, this gets back to the idea of scientific method. You know, in science, the most interesting things are the failures. And those are the things you really have to focus on. It's like, why did it fail? And that's what we need to know to understand machine learning systems. So the most simple kind of reporting would be just to report for every instance in your benchmark, your data set. How did the system do? What was its answer? And that's not, you know, it doesn't seem like a very big ask, but it would be very useful. And we now have in conferences, you're allowed to have some kind of supplementary material online. So you could have this available. And we did this for our concept arc paper. We showed for every instance, like what humans did, what machines did, we tried to analyze the errors of the system. And I think this these kinds of reporting will be will give us a lot more insight into what these systems are doing and what their like real capabilities are. Yeah. And it's, and back to the difficulty that Tim mentioned earlier, totally agree. And this is work that has to be done. Like if, if we are going to build a science of machine cognition, you know, this work has to be done. Yeah, I think. And I just want to shout out to Ryan Bernal, who spearheaded that paper, because he really is the one pushing for all this. And I think it's fantastic. So just in the last few minutes, you know, since we have you, complexity and complexity theory is a topic I really love. I'm not an expert in it at all, but I like to think about I like to explore it. I'm just curious, you know, from your perspective, um, what are some of the most interesting things happening right now in complexity theory? And if I wanted to go learn a bit more and check out just some cool, you know, latest stuff, what should what should we go look at? So I think there's, you know, there's a lot of interesting stuff going on, obviously, and complex systems is a huge umbrella for a lot of research. But if you're interested in the one big topic that people look at is called scaling. And it's the question of like, what happens to a system as it gets bigger in some sense? So this started out with some work on the sort of energy use of systems like animals as they as their maths increases. And people discovered some really interesting scaling laws that were very non-intuitive and they were able to explain these laws using ideas like fractal fractals and the fractal structure of complex systems. But now, so this is all on like biological metabolism and things like that. But now a lot of people are extending that scaling work to cities. So asking what happens to cities when they increase in size, either in area or in population size. And there's all kinds of phenomena that you can see, like what's the rate of innovation measured by something like patents? And what's the rate of sort of energy usage by a city? And what's how do these things change? Even like the happiness of the people, you know, are people in New York happier than people in Santa Fe, which is a much smaller city? These things scale in really interesting ways. And it's opening up a lot of new ideas about how social systems work. And how... Is it a similar thing that you can't trust the benchmarks? Because how happy people are, might you look at the rate of antidepressant usage or something? Yeah. So you do have all these... Right. I don't know if that's exactly what they use, but you do have to look at ways to measure these things, which can be questioned. But there are a lot of really... And I think this whole science, the science of cities, is it's very preliminary. And there's a lot of ideas about how to measure these things, how to develop sort of analytical descriptions or laws that govern certain properties and how to interpret them. But there's just a lot of really interesting work in this. And it turns out that now that everybody has a cell phone, you can really do a lot of tracking. A lot of these quantities can be tracked by people's sort of their movement, their interaction with other people, and all these things that you can measure using cell phones. So that's very cool. That is... Yeah. Thank you. That sounds actually fascinating. And one reason why for me particularly is... Are you familiar with Asimov's Foundation series? Yeah. So you know, psycho history in there was the science... And it was almost like a thermodynamics of human behavior that was only applicable at kind of planet scale and beyond. So it's like these scaling laws. So this is maybe one step towards... Very similar, psycho history. Yeah. One step towards psycho history of Asimov's kind. Exactly. Yeah. Cool. And in closing, does that give you intuition on the scaling of intelligence? Well... That's a great question. And I think, you know, one question you can ask is like, there's individual intelligence and then there's collective intelligence. And how much of the intelligence that we have individually is actually grounded in a more collective intelligence? You know, there's many things that I don't know, like I don't understand quantum mechanics or something, but I know somebody who does. And therefore, I feel like it's understood. And a lot of our intelligence, I think, is sort of more social than we think. Oh, absolutely. And folks should definitely read Melanie's book. So your complexity book, we actually covered that quite a lot on our show on Emergence. It's absolutely wonderful. And of course, your book on AI is probably the best book on AI I've ever read. It's up there with Christopher Sommerfield's book. But anyway, Melanie, honestly, you are my hero. Thank you so much for coming on MLS2. I really appreciate it. Thanks so much for having me. I really enjoyed it. It's great talking to you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 9.72, "text": " Let's have Melanie Mitchell to give our final opening statement, six minutes on the clock,", "tokens": [50364, 961, 311, 362, 42798, 27582, 281, 976, 527, 2572, 5193, 5629, 11, 2309, 2077, 322, 264, 7830, 11, 50850], "temperature": 0.0, "avg_logprob": -0.2575170772591817, "compression_ratio": 1.5622119815668203, "no_speech_prob": 0.08692145347595215}, {"id": 1, "seek": 0, "start": 9.72, "end": 10.72, "text": " Melanie.", "tokens": [50850, 42798, 13, 50900], "temperature": 0.0, "avg_logprob": -0.2575170772591817, "compression_ratio": 1.5622119815668203, "no_speech_prob": 0.08692145347595215}, {"id": 2, "seek": 0, "start": 10.72, "end": 13.86, "text": " Yeah, so this is my opportunity to say I love Melanie.", "tokens": [50900, 865, 11, 370, 341, 307, 452, 2650, 281, 584, 286, 959, 42798, 13, 51057], "temperature": 0.0, "avg_logprob": -0.2575170772591817, "compression_ratio": 1.5622119815668203, "no_speech_prob": 0.08692145347595215}, {"id": 3, "seek": 0, "start": 13.86, "end": 19.400000000000002, "text": " She is amazing, and she's coming back on MLST in about two weeks.", "tokens": [51057, 1240, 307, 2243, 11, 293, 750, 311, 1348, 646, 322, 21601, 6840, 294, 466, 732, 3259, 13, 51334], "temperature": 0.0, "avg_logprob": -0.2575170772591817, "compression_ratio": 1.5622119815668203, "no_speech_prob": 0.08692145347595215}, {"id": 4, "seek": 0, "start": 19.400000000000002, "end": 20.400000000000002, "text": " Oh, amazing.", "tokens": [51334, 876, 11, 2243, 13, 51384], "temperature": 0.0, "avg_logprob": -0.2575170772591817, "compression_ratio": 1.5622119815668203, "no_speech_prob": 0.08692145347595215}, {"id": 5, "seek": 0, "start": 20.400000000000002, "end": 21.400000000000002, "text": " Yeah, that's good.", "tokens": [51384, 865, 11, 300, 311, 665, 13, 51434], "temperature": 0.0, "avg_logprob": -0.2575170772591817, "compression_ratio": 1.5622119815668203, "no_speech_prob": 0.08692145347595215}, {"id": 6, "seek": 0, "start": 21.400000000000002, "end": 23.84, "text": " Yeah, she gives a good representation of herself in here, I think.", "tokens": [51434, 865, 11, 750, 2709, 257, 665, 10290, 295, 7530, 294, 510, 11, 286, 519, 13, 51556], "temperature": 0.0, "avg_logprob": -0.2575170772591817, "compression_ratio": 1.5622119815668203, "no_speech_prob": 0.08692145347595215}, {"id": 7, "seek": 0, "start": 23.84, "end": 24.84, "text": " Melanie is amazing.", "tokens": [51556, 42798, 307, 2243, 13, 51606], "temperature": 0.0, "avg_logprob": -0.2575170772591817, "compression_ratio": 1.5622119815668203, "no_speech_prob": 0.08692145347595215}, {"id": 8, "seek": 2484, "start": 25.52, "end": 30.72, "text": " Fears about machines unleashing human extinction have deep roots in our collective psyche.", "tokens": [50398, 3697, 685, 466, 8379, 25272, 11077, 1952, 33163, 362, 2452, 10669, 294, 527, 12590, 50223, 13, 50658], "temperature": 0.0, "avg_logprob": -0.184992928435837, "compression_ratio": 1.5741626794258374, "no_speech_prob": 0.02359900437295437}, {"id": 9, "seek": 2484, "start": 30.72, "end": 34.480000000000004, "text": " These fears are as old as the invention of machines themselves.", "tokens": [50658, 1981, 15649, 366, 382, 1331, 382, 264, 22265, 295, 8379, 2969, 13, 50846], "temperature": 0.0, "avg_logprob": -0.184992928435837, "compression_ratio": 1.5741626794258374, "no_speech_prob": 0.02359900437295437}, {"id": 10, "seek": 2484, "start": 34.480000000000004, "end": 40.36, "text": " But tonight, we're debating whether these fears belong in the realm of science fiction", "tokens": [50846, 583, 4440, 11, 321, 434, 40647, 1968, 613, 15649, 5784, 294, 264, 15355, 295, 3497, 13266, 51140], "temperature": 0.0, "avg_logprob": -0.184992928435837, "compression_ratio": 1.5741626794258374, "no_speech_prob": 0.02359900437295437}, {"id": 11, "seek": 2484, "start": 40.36, "end": 48.68, "text": " and philosophical speculation, or whether AI is an actual real life existential threat.", "tokens": [51140, 293, 25066, 27696, 11, 420, 1968, 7318, 307, 364, 3539, 957, 993, 37133, 4734, 13, 51556], "temperature": 0.0, "avg_logprob": -0.184992928435837, "compression_ratio": 1.5741626794258374, "no_speech_prob": 0.02359900437295437}, {"id": 12, "seek": 4868, "start": 48.68, "end": 55.48, "text": " I'm going to argue that AI does not pose such a threat in any reasonably near future.", "tokens": [50364, 286, 478, 516, 281, 9695, 300, 7318, 775, 406, 10774, 1270, 257, 4734, 294, 604, 23551, 2651, 2027, 13, 50704], "temperature": 0.0, "avg_logprob": -0.1342956242936381, "compression_ratio": 1.5891472868217054, "no_speech_prob": 0.004328190814703703}, {"id": 13, "seek": 4868, "start": 55.48, "end": 61.32, "text": " Large language models have sparked heated debate on whether AI's exhibit genuine understanding", "tokens": [50704, 33092, 2856, 5245, 362, 39653, 18806, 7958, 322, 1968, 7318, 311, 20487, 16699, 3701, 50996], "temperature": 0.0, "avg_logprob": -0.1342956242936381, "compression_ratio": 1.5891472868217054, "no_speech_prob": 0.004328190814703703}, {"id": 14, "seek": 4868, "start": 61.32, "end": 63.96, "text": " of language and the world.", "tokens": [50996, 295, 2856, 293, 264, 1002, 13, 51128], "temperature": 0.0, "avg_logprob": -0.1342956242936381, "compression_ratio": 1.5891472868217054, "no_speech_prob": 0.004328190814703703}, {"id": 15, "seek": 4868, "start": 63.96, "end": 69.42, "text": " With capabilities rivaling humans across diverse benchmarks, some hail language models as", "tokens": [51128, 2022, 10862, 16286, 278, 6255, 2108, 9521, 43751, 11, 512, 38157, 2856, 5245, 382, 51401], "temperature": 0.0, "avg_logprob": -0.1342956242936381, "compression_ratio": 1.5891472868217054, "no_speech_prob": 0.004328190814703703}, {"id": 16, "seek": 4868, "start": 69.42, "end": 72.32, "text": " harbingers of real intelligence.", "tokens": [51401, 2233, 4324, 433, 295, 957, 7599, 13, 51546], "temperature": 0.0, "avg_logprob": -0.1342956242936381, "compression_ratio": 1.5891472868217054, "no_speech_prob": 0.004328190814703703}, {"id": 17, "seek": 4868, "start": 72.32, "end": 78.4, "text": " But skeptics argue that their mastery is skin deep, lacking true comprehension.", "tokens": [51546, 583, 19128, 1167, 9695, 300, 641, 37951, 307, 3178, 2452, 11, 20889, 2074, 44991, 13, 51850], "temperature": 0.0, "avg_logprob": -0.1342956242936381, "compression_ratio": 1.5891472868217054, "no_speech_prob": 0.004328190814703703}, {"id": 18, "seek": 7840, "start": 78.4, "end": 83.56, "text": " So how can we assess these claims and gain insight into the nature of what it means to", "tokens": [50364, 407, 577, 393, 321, 5877, 613, 9441, 293, 6052, 11269, 666, 264, 3687, 295, 437, 309, 1355, 281, 50622], "temperature": 0.0, "avg_logprob": -0.1793193817138672, "compression_ratio": 1.592741935483871, "no_speech_prob": 0.010290161706507206}, {"id": 19, "seek": 7840, "start": 83.56, "end": 84.56, "text": " understand?", "tokens": [50622, 1223, 30, 50672], "temperature": 0.0, "avg_logprob": -0.1793193817138672, "compression_ratio": 1.592741935483871, "no_speech_prob": 0.010290161706507206}, {"id": 20, "seek": 7840, "start": 84.56, "end": 91.0, "text": " Now, on the show today, we have Professor Melanie Mitchell, a leading thinker on AI and intelligence,", "tokens": [50672, 823, 11, 322, 264, 855, 965, 11, 321, 362, 8419, 42798, 27582, 11, 257, 5775, 519, 260, 322, 7318, 293, 7599, 11, 50994], "temperature": 0.0, "avg_logprob": -0.1793193817138672, "compression_ratio": 1.592741935483871, "no_speech_prob": 0.010290161706507206}, {"id": 21, "seek": 7840, "start": 91.0, "end": 95.44, "text": " and one of the researchers in the community I personally most align with and look up to", "tokens": [50994, 293, 472, 295, 264, 10309, 294, 264, 1768, 286, 5665, 881, 7975, 365, 293, 574, 493, 281, 51216], "temperature": 0.0, "avg_logprob": -0.1793193817138672, "compression_ratio": 1.592741935483871, "no_speech_prob": 0.010290161706507206}, {"id": 22, "seek": 7840, "start": 95.44, "end": 97.24000000000001, "text": " the most.", "tokens": [51216, 264, 881, 13, 51306], "temperature": 0.0, "avg_logprob": -0.1793193817138672, "compression_ratio": 1.592741935483871, "no_speech_prob": 0.010290161706507206}, {"id": 23, "seek": 7840, "start": 97.24000000000001, "end": 103.52000000000001, "text": " Melanie's distinguished career crosses computer science, complex systems, and cognitive science,", "tokens": [51306, 42798, 311, 21702, 3988, 28467, 3820, 3497, 11, 3997, 3652, 11, 293, 15605, 3497, 11, 51620], "temperature": 0.0, "avg_logprob": -0.1793193817138672, "compression_ratio": 1.592741935483871, "no_speech_prob": 0.010290161706507206}, {"id": 24, "seek": 10352, "start": 103.52, "end": 108.61999999999999, "text": " and she wrote the influential books Artificial Intelligence, A Guide for Thinking Humans,", "tokens": [50364, 293, 750, 4114, 264, 22215, 3642, 5735, 10371, 27274, 11, 316, 18727, 337, 24460, 35809, 11, 50619], "temperature": 0.0, "avg_logprob": -0.17943016258445946, "compression_ratio": 1.5720524017467248, "no_speech_prob": 0.13992753624916077}, {"id": 25, "seek": 10352, "start": 108.61999999999999, "end": 111.67999999999999, "text": " and also Complexity, A Guided Tour.", "tokens": [50619, 293, 611, 41184, 507, 11, 316, 2694, 2112, 13077, 13, 50772], "temperature": 0.0, "avg_logprob": -0.17943016258445946, "compression_ratio": 1.5720524017467248, "no_speech_prob": 0.13992753624916077}, {"id": 26, "seek": 10352, "start": 111.67999999999999, "end": 117.32, "text": " Now central to Melanie's perspective is the idea that human understanding relies on flexible", "tokens": [50772, 823, 5777, 281, 42798, 311, 4585, 307, 264, 1558, 300, 1952, 3701, 30910, 322, 11358, 51054], "temperature": 0.0, "avg_logprob": -0.17943016258445946, "compression_ratio": 1.5720524017467248, "no_speech_prob": 0.13992753624916077}, {"id": 27, "seek": 10352, "start": 117.32, "end": 121.56, "text": " mental models grounded in sensory experience.", "tokens": [51054, 4973, 5245, 23535, 294, 27233, 1752, 13, 51266], "temperature": 0.0, "avg_logprob": -0.17943016258445946, "compression_ratio": 1.5720524017467248, "no_speech_prob": 0.13992753624916077}, {"id": 28, "seek": 10352, "start": 121.56, "end": 128.64, "text": " Now she wrote that understanding language requires having the concepts that language describes.", "tokens": [51266, 823, 750, 4114, 300, 3701, 2856, 7029, 1419, 264, 10392, 300, 2856, 15626, 13, 51620], "temperature": 0.0, "avg_logprob": -0.17943016258445946, "compression_ratio": 1.5720524017467248, "no_speech_prob": 0.13992753624916077}, {"id": 29, "seek": 12864, "start": 128.64, "end": 134.04, "text": " Large language models are trained purely on statistical relationships between words.", "tokens": [50364, 33092, 2856, 5245, 366, 8895, 17491, 322, 22820, 6159, 1296, 2283, 13, 50634], "temperature": 0.0, "avg_logprob": -0.14765911959530262, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.13610760867595673}, {"id": 30, "seek": 12864, "start": 134.04, "end": 138.6, "text": " Their knowledge is not grounded in a causal model of reality.", "tokens": [50634, 6710, 3601, 307, 406, 23535, 294, 257, 38755, 2316, 295, 4103, 13, 50862], "temperature": 0.0, "avg_logprob": -0.14765911959530262, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.13610760867595673}, {"id": 31, "seek": 12864, "start": 138.6, "end": 144.32, "text": " Now Melanie is the Davis Professor of Complexity at the Santa Fe Institute, and her major work", "tokens": [50862, 823, 42798, 307, 264, 15658, 8419, 295, 41184, 507, 412, 264, 9933, 3697, 9446, 11, 293, 720, 2563, 589, 51148], "temperature": 0.0, "avg_logprob": -0.14765911959530262, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.13610760867595673}, {"id": 32, "seek": 12864, "start": 144.32, "end": 150.6, "text": " has been in the areas of analogical reasoning, complex systems, genetic algorithms, and cellular", "tokens": [51148, 575, 668, 294, 264, 3179, 295, 16660, 804, 21577, 11, 3997, 3652, 11, 12462, 14642, 11, 293, 29267, 51462], "temperature": 0.0, "avg_logprob": -0.14765911959530262, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.13610760867595673}, {"id": 33, "seek": 12864, "start": 150.6, "end": 152.1, "text": " automata.", "tokens": [51462, 3553, 3274, 13, 51537], "temperature": 0.0, "avg_logprob": -0.14765911959530262, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.13610760867595673}, {"id": 34, "seek": 12864, "start": 152.1, "end": 155.48, "text": " She's achieved legendary status in the field of AI.", "tokens": [51537, 1240, 311, 11042, 16698, 6558, 294, 264, 2519, 295, 7318, 13, 51706], "temperature": 0.0, "avg_logprob": -0.14765911959530262, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.13610760867595673}, {"id": 35, "seek": 15548, "start": 155.48, "end": 161.32, "text": " She received her PhD in 1990 from the University of Michigan under Douglas Hofstadter, the", "tokens": [50364, 1240, 4613, 720, 14476, 294, 13384, 490, 264, 3535, 295, 11925, 833, 23010, 37379, 48299, 391, 11, 264, 50656], "temperature": 0.0, "avg_logprob": -0.18985794330465383, "compression_ratio": 1.4472727272727273, "no_speech_prob": 0.03251536190509796}, {"id": 36, "seek": 15548, "start": 161.32, "end": 164.23999999999998, "text": " famous author of Godel Escherbach.", "tokens": [50656, 4618, 3793, 295, 1265, 338, 2313, 6759, 32096, 13, 50802], "temperature": 0.0, "avg_logprob": -0.18985794330465383, "compression_ratio": 1.4472727272727273, "no_speech_prob": 0.03251536190509796}, {"id": 37, "seek": 15548, "start": 164.23999999999998, "end": 169.6, "text": " Melanie argues that we must rethink how AI systems are evaluated.", "tokens": [50802, 42798, 38218, 300, 321, 1633, 34595, 577, 7318, 3652, 366, 25509, 13, 51070], "temperature": 0.0, "avg_logprob": -0.18985794330465383, "compression_ratio": 1.4472727272727273, "no_speech_prob": 0.03251536190509796}, {"id": 38, "seek": 15548, "start": 169.6, "end": 174.48, "text": " Typical benchmarks summarize aggregate performance and, you know, these obscure failure modes", "tokens": [51070, 17722, 804, 43751, 20858, 26118, 3389, 293, 11, 291, 458, 11, 613, 34443, 7763, 14068, 51314], "temperature": 0.0, "avg_logprob": -0.18985794330465383, "compression_ratio": 1.4472727272727273, "no_speech_prob": 0.03251536190509796}, {"id": 39, "seek": 15548, "start": 174.48, "end": 177.67999999999998, "text": " and mask the underlying mechanisms.", "tokens": [51314, 293, 6094, 264, 14217, 15902, 13, 51474], "temperature": 0.0, "avg_logprob": -0.18985794330465383, "compression_ratio": 1.4472727272727273, "no_speech_prob": 0.03251536190509796}, {"id": 40, "seek": 15548, "start": 177.67999999999998, "end": 183.6, "text": " We need rigorous granular testing focused keenly on abstract generalization.", "tokens": [51474, 492, 643, 29882, 39962, 4997, 5178, 20297, 356, 322, 12649, 2674, 2144, 13, 51770], "temperature": 0.0, "avg_logprob": -0.18985794330465383, "compression_ratio": 1.4472727272727273, "no_speech_prob": 0.03251536190509796}, {"id": 41, "seek": 18360, "start": 183.6, "end": 187.76, "text": " Sort of like a sorcerer's apprentice gone nuclear.", "tokens": [50364, 26149, 295, 411, 257, 41349, 260, 311, 40207, 2780, 8179, 13, 50572], "temperature": 0.0, "avg_logprob": -0.21646029328646726, "compression_ratio": 1.4306930693069306, "no_speech_prob": 0.07890129834413528}, {"id": 42, "seek": 18360, "start": 187.76, "end": 192.12, "text": " For example, Yoshua Benjiro wrote about this thought experiment.", "tokens": [50572, 1171, 1365, 11, 38949, 4398, 3964, 4013, 340, 4114, 466, 341, 1194, 5120, 13, 50790], "temperature": 0.0, "avg_logprob": -0.21646029328646726, "compression_ratio": 1.4306930693069306, "no_speech_prob": 0.07890129834413528}, {"id": 43, "seek": 18360, "start": 192.12, "end": 197.35999999999999, "text": " We might ask an AI to fix climate change and to solve the problem it could design a virus", "tokens": [50790, 492, 1062, 1029, 364, 7318, 281, 3191, 5659, 1319, 293, 281, 5039, 264, 1154, 309, 727, 1715, 257, 5752, 51052], "temperature": 0.0, "avg_logprob": -0.21646029328646726, "compression_ratio": 1.4306930693069306, "no_speech_prob": 0.07890129834413528}, {"id": 44, "seek": 18360, "start": 197.35999999999999, "end": 206.35999999999999, "text": " that decimates the human population, presto, humans dead, no more carbon emissions.", "tokens": [51052, 300, 979, 332, 1024, 264, 1952, 4415, 11, 16305, 78, 11, 6255, 3116, 11, 572, 544, 5954, 14607, 13, 51502], "temperature": 0.0, "avg_logprob": -0.21646029328646726, "compression_ratio": 1.4306930693069306, "no_speech_prob": 0.07890129834413528}, {"id": 45, "seek": 20636, "start": 206.36, "end": 214.28, "text": " This is an example of what's called the fallacy of dumb superintelligence.", "tokens": [50364, 639, 307, 364, 1365, 295, 437, 311, 1219, 264, 2100, 2551, 295, 10316, 1687, 20761, 17644, 13, 50760], "temperature": 0.0, "avg_logprob": -0.14649377399020724, "compression_ratio": 1.6244343891402715, "no_speech_prob": 0.5219436883926392}, {"id": 46, "seek": 20636, "start": 214.28, "end": 220.4, "text": " That is, it's a fallacy to think that a machine could be, quote, smarter than humans in all", "tokens": [50760, 663, 307, 11, 309, 311, 257, 2100, 2551, 281, 519, 300, 257, 3479, 727, 312, 11, 6513, 11, 20294, 813, 6255, 294, 439, 51066], "temperature": 0.0, "avg_logprob": -0.14649377399020724, "compression_ratio": 1.6244343891402715, "no_speech_prob": 0.5219436883926392}, {"id": 47, "seek": 20636, "start": 220.4, "end": 227.32000000000002, "text": " respects, unquote, and still lack any common sense understanding of humans, such as understanding", "tokens": [51066, 24126, 11, 37557, 11, 293, 920, 5011, 604, 2689, 2020, 3701, 295, 6255, 11, 1270, 382, 3701, 51412], "temperature": 0.0, "avg_logprob": -0.14649377399020724, "compression_ratio": 1.6244343891402715, "no_speech_prob": 0.5219436883926392}, {"id": 48, "seek": 20636, "start": 227.32000000000002, "end": 232.84, "text": " why we made the request to fix climate change and the fact that we prefer not to be wiped", "tokens": [51412, 983, 321, 1027, 264, 5308, 281, 3191, 5659, 1319, 293, 264, 1186, 300, 321, 4382, 406, 281, 312, 26879, 51688], "temperature": 0.0, "avg_logprob": -0.14649377399020724, "compression_ratio": 1.6244343891402715, "no_speech_prob": 0.5219436883926392}, {"id": 49, "seek": 20636, "start": 232.84, "end": 235.04000000000002, "text": " out.", "tokens": [51688, 484, 13, 51798], "temperature": 0.0, "avg_logprob": -0.14649377399020724, "compression_ratio": 1.6244343891402715, "no_speech_prob": 0.5219436883926392}, {"id": 50, "seek": 23504, "start": 235.04, "end": 242.2, "text": " This is all about having insight into one's goals and the likely effect of one's actions.", "tokens": [50364, 639, 307, 439, 466, 1419, 11269, 666, 472, 311, 5493, 293, 264, 3700, 1802, 295, 472, 311, 5909, 13, 50722], "temperature": 0.0, "avg_logprob": -0.2008875161409378, "compression_ratio": 1.6225165562913908, "no_speech_prob": 0.11387739330530167}, {"id": 51, "seek": 23504, "start": 242.2, "end": 247.68, "text": " We would never give unchecked autonomy and resources to an AI that lacked these basic", "tokens": [50722, 492, 576, 1128, 976, 46672, 292, 27278, 293, 3593, 281, 364, 7318, 300, 41481, 613, 3875, 50996], "temperature": 0.0, "avg_logprob": -0.2008875161409378, "compression_ratio": 1.6225165562913908, "no_speech_prob": 0.11387739330530167}, {"id": 52, "seek": 23504, "start": 247.68, "end": 249.48, "text": " aspects of intelligence.", "tokens": [50996, 7270, 295, 7599, 13, 51086], "temperature": 0.0, "avg_logprob": -0.2008875161409378, "compression_ratio": 1.6225165562913908, "no_speech_prob": 0.11387739330530167}, {"id": 53, "seek": 23504, "start": 249.48, "end": 252.32, "text": " It just does not make sense.", "tokens": [51086, 467, 445, 775, 406, 652, 2020, 13, 51228], "temperature": 0.0, "avg_logprob": -0.2008875161409378, "compression_ratio": 1.6225165562913908, "no_speech_prob": 0.11387739330530167}, {"id": 54, "seek": 23504, "start": 252.32, "end": 253.32, "text": " The third scenario.", "tokens": [51228, 440, 2636, 9005, 13, 51278], "temperature": 0.0, "avg_logprob": -0.2008875161409378, "compression_ratio": 1.6225165562913908, "no_speech_prob": 0.11387739330530167}, {"id": 55, "seek": 23504, "start": 253.32, "end": 254.76, "text": " Yeah, that is absolutely.", "tokens": [51278, 865, 11, 300, 307, 3122, 13, 51350], "temperature": 0.0, "avg_logprob": -0.2008875161409378, "compression_ratio": 1.6225165562913908, "no_speech_prob": 0.11387739330530167}, {"id": 56, "seek": 23504, "start": 254.76, "end": 258.64, "text": " She made that point so much more eloquently than I've tried to make it in the past.", "tokens": [51350, 1240, 1027, 300, 935, 370, 709, 544, 38682, 47519, 813, 286, 600, 3031, 281, 652, 309, 294, 264, 1791, 13, 51544], "temperature": 0.0, "avg_logprob": -0.2008875161409378, "compression_ratio": 1.6225165562913908, "no_speech_prob": 0.11387739330530167}, {"id": 57, "seek": 23504, "start": 258.64, "end": 262.15999999999997, "text": " Yeah, even earlier in this conversation, I was trying to get that across, but that's", "tokens": [51544, 865, 11, 754, 3071, 294, 341, 3761, 11, 286, 390, 1382, 281, 483, 300, 2108, 11, 457, 300, 311, 51720], "temperature": 0.0, "avg_logprob": -0.2008875161409378, "compression_ratio": 1.6225165562913908, "no_speech_prob": 0.11387739330530167}, {"id": 58, "seek": 23504, "start": 262.15999999999997, "end": 263.15999999999997, "text": " exactly it.", "tokens": [51720, 2293, 309, 13, 51770], "temperature": 0.0, "avg_logprob": -0.2008875161409378, "compression_ratio": 1.6225165562913908, "no_speech_prob": 0.11387739330530167}, {"id": 59, "seek": 23504, "start": 263.15999999999997, "end": 264.15999999999997, "text": " It's this dumb superintelligence.", "tokens": [51770, 467, 311, 341, 10316, 1687, 20761, 17644, 13, 51820], "temperature": 0.0, "avg_logprob": -0.2008875161409378, "compression_ratio": 1.6225165562913908, "no_speech_prob": 0.11387739330530167}, {"id": 60, "seek": 26416, "start": 265.16, "end": 266.16, "text": " Yeah, exactly.", "tokens": [50414, 865, 11, 2293, 13, 50464], "temperature": 0.0, "avg_logprob": -0.31666718130036603, "compression_ratio": 1.5603112840466926, "no_speech_prob": 0.06361153721809387}, {"id": 61, "seek": 26416, "start": 266.16, "end": 271.88000000000005, "text": " Anyway, folks, I hope you enjoy the show, and now I bring you Professor Melanie Mitchell.", "tokens": [50464, 5684, 11, 4024, 11, 286, 1454, 291, 2103, 264, 855, 11, 293, 586, 286, 1565, 291, 8419, 42798, 27582, 13, 50750], "temperature": 0.0, "avg_logprob": -0.31666718130036603, "compression_ratio": 1.5603112840466926, "no_speech_prob": 0.06361153721809387}, {"id": 62, "seek": 26416, "start": 271.88000000000005, "end": 277.92, "text": " Sounds like almost like there's a very quiet supercomputer running behind the screen.", "tokens": [50750, 14576, 411, 1920, 411, 456, 311, 257, 588, 5677, 36708, 2614, 2261, 264, 2568, 13, 51052], "temperature": 0.0, "avg_logprob": -0.31666718130036603, "compression_ratio": 1.5603112840466926, "no_speech_prob": 0.06361153721809387}, {"id": 63, "seek": 26416, "start": 277.92, "end": 278.92, "text": " It's my brain.", "tokens": [51052, 467, 311, 452, 3567, 13, 51102], "temperature": 0.0, "avg_logprob": -0.31666718130036603, "compression_ratio": 1.5603112840466926, "no_speech_prob": 0.06361153721809387}, {"id": 64, "seek": 26416, "start": 278.92, "end": 279.92, "text": " Yeah.", "tokens": [51102, 865, 13, 51152], "temperature": 0.0, "avg_logprob": -0.31666718130036603, "compression_ratio": 1.5603112840466926, "no_speech_prob": 0.06361153721809387}, {"id": 65, "seek": 26416, "start": 279.92, "end": 281.92, "text": " I think that's what this is.", "tokens": [51152, 286, 519, 300, 311, 437, 341, 307, 13, 51252], "temperature": 0.0, "avg_logprob": -0.31666718130036603, "compression_ratio": 1.5603112840466926, "no_speech_prob": 0.06361153721809387}, {"id": 66, "seek": 26416, "start": 281.92, "end": 286.32000000000005, "text": " You know, we can robustly adapt much more so than GPT-4.", "tokens": [51252, 509, 458, 11, 321, 393, 13956, 356, 6231, 709, 544, 370, 813, 26039, 51, 12, 19, 13, 51472], "temperature": 0.0, "avg_logprob": -0.31666718130036603, "compression_ratio": 1.5603112840466926, "no_speech_prob": 0.06361153721809387}, {"id": 67, "seek": 26416, "start": 286.32000000000005, "end": 288.32000000000005, "text": " You and I have the same chair.", "tokens": [51472, 509, 293, 286, 362, 264, 912, 6090, 13, 51572], "temperature": 0.0, "avg_logprob": -0.31666718130036603, "compression_ratio": 1.5603112840466926, "no_speech_prob": 0.06361153721809387}, {"id": 68, "seek": 26416, "start": 288.32000000000005, "end": 290.32000000000005, "text": " We have the same chair, I think.", "tokens": [51572, 492, 362, 264, 912, 6090, 11, 286, 519, 13, 51672], "temperature": 0.0, "avg_logprob": -0.31666718130036603, "compression_ratio": 1.5603112840466926, "no_speech_prob": 0.06361153721809387}, {"id": 69, "seek": 26416, "start": 290.32000000000005, "end": 291.32000000000005, "text": " Oh, yeah.", "tokens": [51672, 876, 11, 1338, 13, 51722], "temperature": 0.0, "avg_logprob": -0.31666718130036603, "compression_ratio": 1.5603112840466926, "no_speech_prob": 0.06361153721809387}, {"id": 70, "seek": 26416, "start": 291.32000000000005, "end": 292.32000000000005, "text": " I can't see your chair.", "tokens": [51722, 286, 393, 380, 536, 428, 6090, 13, 51772], "temperature": 0.0, "avg_logprob": -0.31666718130036603, "compression_ratio": 1.5603112840466926, "no_speech_prob": 0.06361153721809387}, {"id": 71, "seek": 26416, "start": 292.32000000000005, "end": 293.32000000000005, "text": " Yeah.", "tokens": [51772, 865, 13, 51822], "temperature": 0.0, "avg_logprob": -0.31666718130036603, "compression_ratio": 1.5603112840466926, "no_speech_prob": 0.06361153721809387}, {"id": 72, "seek": 29332, "start": 293.96, "end": 294.96, "text": " Me too.", "tokens": [50396, 1923, 886, 13, 50446], "temperature": 0.0, "avg_logprob": -0.20654901225915115, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.003940531983971596}, {"id": 73, "seek": 29332, "start": 294.96, "end": 295.96, "text": " They're home in Miller.", "tokens": [50446, 814, 434, 1280, 294, 16932, 13, 50496], "temperature": 0.0, "avg_logprob": -0.20654901225915115, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.003940531983971596}, {"id": 74, "seek": 29332, "start": 295.96, "end": 298.59999999999997, "text": " Yeah, I think they're all the same chair.", "tokens": [50496, 865, 11, 286, 519, 436, 434, 439, 264, 912, 6090, 13, 50628], "temperature": 0.0, "avg_logprob": -0.20654901225915115, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.003940531983971596}, {"id": 75, "seek": 29332, "start": 298.59999999999997, "end": 299.59999999999997, "text": " Yeah.", "tokens": [50628, 865, 13, 50678], "temperature": 0.0, "avg_logprob": -0.20654901225915115, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.003940531983971596}, {"id": 76, "seek": 29332, "start": 299.59999999999997, "end": 300.59999999999997, "text": " Yeah.", "tokens": [50678, 865, 13, 50728], "temperature": 0.0, "avg_logprob": -0.20654901225915115, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.003940531983971596}, {"id": 77, "seek": 29332, "start": 300.59999999999997, "end": 301.59999999999997, "text": " Excellent chair.", "tokens": [50728, 16723, 6090, 13, 50778], "temperature": 0.0, "avg_logprob": -0.20654901225915115, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.003940531983971596}, {"id": 78, "seek": 29332, "start": 301.59999999999997, "end": 302.59999999999997, "text": " Yep, chair buddies.", "tokens": [50778, 7010, 11, 6090, 30649, 13, 50828], "temperature": 0.0, "avg_logprob": -0.20654901225915115, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.003940531983971596}, {"id": 79, "seek": 29332, "start": 302.59999999999997, "end": 303.59999999999997, "text": " Yeah.", "tokens": [50828, 865, 13, 50878], "temperature": 0.0, "avg_logprob": -0.20654901225915115, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.003940531983971596}, {"id": 80, "seek": 29332, "start": 303.59999999999997, "end": 310.84, "text": " I felt it would be hundreds of years before anything even remotely like a human mind would", "tokens": [50878, 286, 2762, 309, 576, 312, 6779, 295, 924, 949, 1340, 754, 20824, 411, 257, 1952, 1575, 576, 51240], "temperature": 0.0, "avg_logprob": -0.20654901225915115, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.003940531983971596}, {"id": 81, "seek": 29332, "start": 310.84, "end": 317.0, "text": " be asymptotically approaching the level of the human mind, but from beneath.", "tokens": [51240, 312, 35114, 310, 984, 14908, 264, 1496, 295, 264, 1952, 1575, 11, 457, 490, 17149, 13, 51548], "temperature": 0.0, "avg_logprob": -0.20654901225915115, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.003940531983971596}, {"id": 82, "seek": 31700, "start": 317.0, "end": 325.68, "text": " I never imagined that computers would rival or let alone surpass human intelligence, but", "tokens": [50364, 286, 1128, 16590, 300, 10807, 576, 16286, 420, 718, 3312, 27650, 1952, 7599, 11, 457, 50798], "temperature": 0.0, "avg_logprob": -0.11684860229492187, "compression_ratio": 1.604878048780488, "no_speech_prob": 0.11255274713039398}, {"id": 83, "seek": 31700, "start": 325.68, "end": 329.32, "text": " it seemed to me like it was a goal that was so far away.", "tokens": [50798, 309, 6576, 281, 385, 411, 309, 390, 257, 3387, 300, 390, 370, 1400, 1314, 13, 50980], "temperature": 0.0, "avg_logprob": -0.11684860229492187, "compression_ratio": 1.604878048780488, "no_speech_prob": 0.11255274713039398}, {"id": 84, "seek": 31700, "start": 329.32, "end": 335.04, "text": " I wasn't worried about it, but when certain systems started appearing and then this started", "tokens": [50980, 286, 2067, 380, 5804, 466, 309, 11, 457, 562, 1629, 3652, 1409, 19870, 293, 550, 341, 1409, 51266], "temperature": 0.0, "avg_logprob": -0.11684860229492187, "compression_ratio": 1.604878048780488, "no_speech_prob": 0.11255274713039398}, {"id": 85, "seek": 31700, "start": 335.04, "end": 341.4, "text": " happening at an accelerating pace, it felt as if not only are my belief systems collapsing,", "tokens": [51266, 2737, 412, 364, 34391, 11638, 11, 309, 2762, 382, 498, 406, 787, 366, 452, 7107, 3652, 45339, 11, 51584], "temperature": 0.0, "avg_logprob": -0.11684860229492187, "compression_ratio": 1.604878048780488, "no_speech_prob": 0.11255274713039398}, {"id": 86, "seek": 34140, "start": 341.4, "end": 350.56, "text": " but it feels as if the entire human race is going to be eclipsed and left in the dust.", "tokens": [50364, 457, 309, 3417, 382, 498, 264, 2302, 1952, 4569, 307, 516, 281, 312, 308, 3474, 2600, 292, 293, 1411, 294, 264, 8634, 13, 50822], "temperature": 0.0, "avg_logprob": -0.18687871524265834, "compression_ratio": 1.604878048780488, "no_speech_prob": 0.015413174405694008}, {"id": 87, "seek": 34140, "start": 350.56, "end": 355.15999999999997, "text": " Douglas Hofstadter, he came out as a doomer.", "tokens": [50822, 23010, 37379, 48299, 391, 11, 415, 1361, 484, 382, 257, 360, 14301, 13, 51052], "temperature": 0.0, "avg_logprob": -0.18687871524265834, "compression_ratio": 1.604878048780488, "no_speech_prob": 0.015413174405694008}, {"id": 88, "seek": 34140, "start": 355.15999999999997, "end": 359.32, "text": " Well, I don't know if he came out exactly.", "tokens": [51052, 1042, 11, 286, 500, 380, 458, 498, 415, 1361, 484, 2293, 13, 51260], "temperature": 0.0, "avg_logprob": -0.18687871524265834, "compression_ratio": 1.604878048780488, "no_speech_prob": 0.015413174405694008}, {"id": 89, "seek": 34140, "start": 359.32, "end": 362.03999999999996, "text": " He's been a doomer for quite a while.", "tokens": [51260, 634, 311, 668, 257, 360, 14301, 337, 1596, 257, 1339, 13, 51396], "temperature": 0.0, "avg_logprob": -0.18687871524265834, "compression_ratio": 1.604878048780488, "no_speech_prob": 0.015413174405694008}, {"id": 90, "seek": 34140, "start": 362.03999999999996, "end": 363.52, "text": " Oh, go on.", "tokens": [51396, 876, 11, 352, 322, 13, 51470], "temperature": 0.0, "avg_logprob": -0.18687871524265834, "compression_ratio": 1.604878048780488, "no_speech_prob": 0.015413174405694008}, {"id": 91, "seek": 34140, "start": 363.52, "end": 365.32, "text": " I wasn't aware of that.", "tokens": [51470, 286, 2067, 380, 3650, 295, 300, 13, 51560], "temperature": 0.0, "avg_logprob": -0.18687871524265834, "compression_ratio": 1.604878048780488, "no_speech_prob": 0.015413174405694008}, {"id": 92, "seek": 34140, "start": 365.32, "end": 370.0, "text": " Well, I don't, you know, doomer is, you know, there's different kinds of doomers.", "tokens": [51560, 1042, 11, 286, 500, 380, 11, 291, 458, 11, 360, 14301, 307, 11, 291, 458, 11, 456, 311, 819, 3685, 295, 360, 298, 433, 13, 51794], "temperature": 0.0, "avg_logprob": -0.18687871524265834, "compression_ratio": 1.604878048780488, "no_speech_prob": 0.015413174405694008}, {"id": 93, "seek": 37000, "start": 370.76, "end": 376.5, "text": " In my AI book, the first chapter, the prologue is called Terrified, and it's all about how", "tokens": [50402, 682, 452, 7318, 1446, 11, 264, 700, 7187, 11, 264, 447, 4987, 622, 307, 1219, 36591, 2587, 11, 293, 309, 311, 439, 466, 577, 50689], "temperature": 0.0, "avg_logprob": -0.17627732893999884, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.004901875276118517}, {"id": 94, "seek": 37000, "start": 376.5, "end": 384.72, "text": " Doug is very terrified about AI and the possible things that are going to come.", "tokens": [50689, 12742, 307, 588, 23051, 466, 7318, 293, 264, 1944, 721, 300, 366, 516, 281, 808, 13, 51100], "temperature": 0.0, "avg_logprob": -0.17627732893999884, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.004901875276118517}, {"id": 95, "seek": 37000, "start": 384.72, "end": 394.6, "text": " That was based on a talk he gave in 2013, and earlier than that, he was extremely worried", "tokens": [51100, 663, 390, 2361, 322, 257, 751, 415, 2729, 294, 9012, 11, 293, 3071, 813, 300, 11, 415, 390, 4664, 5804, 51594], "temperature": 0.0, "avg_logprob": -0.17627732893999884, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.004901875276118517}, {"id": 96, "seek": 39460, "start": 394.6, "end": 401.8, "text": " about the singularity, the idea of the singularity from Kurzweil, and wrote quite a bit about", "tokens": [50364, 466, 264, 20010, 507, 11, 264, 1558, 295, 264, 20010, 507, 490, 45307, 826, 388, 11, 293, 4114, 1596, 257, 857, 466, 50724], "temperature": 0.0, "avg_logprob": -0.17985455040792817, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.10069230198860168}, {"id": 97, "seek": 39460, "start": 401.8, "end": 402.8, "text": " that.", "tokens": [50724, 300, 13, 50774], "temperature": 0.0, "avg_logprob": -0.17985455040792817, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.10069230198860168}, {"id": 98, "seek": 39460, "start": 402.8, "end": 409.04, "text": " So, I feel like that it's not that new, but maybe this is sort of because there's so much", "tokens": [50774, 407, 11, 286, 841, 411, 300, 309, 311, 406, 300, 777, 11, 457, 1310, 341, 307, 1333, 295, 570, 456, 311, 370, 709, 51086], "temperature": 0.0, "avg_logprob": -0.17985455040792817, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.10069230198860168}, {"id": 99, "seek": 39460, "start": 409.04, "end": 414.96000000000004, "text": " talk about AI, doom, and so on, that this is kind of, people are kind of paying attention", "tokens": [51086, 751, 466, 7318, 11, 37131, 11, 293, 370, 322, 11, 300, 341, 307, 733, 295, 11, 561, 366, 733, 295, 6229, 3202, 51382], "temperature": 0.0, "avg_logprob": -0.17985455040792817, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.10069230198860168}, {"id": 100, "seek": 39460, "start": 414.96000000000004, "end": 415.96000000000004, "text": " now.", "tokens": [51382, 586, 13, 51432], "temperature": 0.0, "avg_logprob": -0.17985455040792817, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.10069230198860168}, {"id": 101, "seek": 39460, "start": 415.96000000000004, "end": 419.48, "text": " Yeah, I don't know whether I misunderstood something because I read out, you had this", "tokens": [51432, 865, 11, 286, 500, 380, 458, 1968, 286, 33870, 746, 570, 286, 1401, 484, 11, 291, 632, 341, 51608], "temperature": 0.0, "avg_logprob": -0.17985455040792817, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.10069230198860168}, {"id": 102, "seek": 41948, "start": 419.48, "end": 425.04, "text": " beautiful piece about the Googleplex in Chopin, and he was terrified that cognition might", "tokens": [50364, 2238, 2522, 466, 264, 3329, 18945, 294, 25615, 259, 11, 293, 415, 390, 23051, 300, 46905, 1062, 50642], "temperature": 0.0, "avg_logprob": -0.1541579264514851, "compression_ratio": 1.671641791044776, "no_speech_prob": 0.11674298346042633}, {"id": 103, "seek": 41948, "start": 425.04, "end": 430.56, "text": " be disappointingly simple to mechanize, and, you know, surely we couldn't replicate the", "tokens": [50642, 312, 8505, 12163, 2199, 281, 4236, 1125, 11, 293, 11, 291, 458, 11, 11468, 321, 2809, 380, 25356, 264, 50918], "temperature": 0.0, "avg_logprob": -0.1541579264514851, "compression_ratio": 1.671641791044776, "no_speech_prob": 0.11674298346042633}, {"id": 104, "seek": 41948, "start": 430.56, "end": 436.12, "text": " infinite nuance of the mental state that went into writing that beautiful music.", "tokens": [50918, 13785, 42625, 295, 264, 4973, 1785, 300, 1437, 666, 3579, 300, 2238, 1318, 13, 51196], "temperature": 0.0, "avg_logprob": -0.1541579264514851, "compression_ratio": 1.671641791044776, "no_speech_prob": 0.11674298346042633}, {"id": 105, "seek": 41948, "start": 436.12, "end": 440.04, "text": " But so maybe he was worried about it, but he didn't think it was possible in principle", "tokens": [51196, 583, 370, 1310, 415, 390, 5804, 466, 309, 11, 457, 415, 994, 380, 519, 309, 390, 1944, 294, 8665, 51392], "temperature": 0.0, "avg_logprob": -0.1541579264514851, "compression_ratio": 1.671641791044776, "no_speech_prob": 0.11674298346042633}, {"id": 106, "seek": 41948, "start": 440.04, "end": 441.04, "text": " or something.", "tokens": [51392, 420, 746, 13, 51442], "temperature": 0.0, "avg_logprob": -0.1541579264514851, "compression_ratio": 1.671641791044776, "no_speech_prob": 0.11674298346042633}, {"id": 107, "seek": 41948, "start": 441.04, "end": 446.96000000000004, "text": " Well, no, he was quite worried about that it was going to happen sooner than he thought,", "tokens": [51442, 1042, 11, 572, 11, 415, 390, 1596, 5804, 466, 300, 309, 390, 516, 281, 1051, 15324, 813, 415, 1194, 11, 51738], "temperature": 0.0, "avg_logprob": -0.1541579264514851, "compression_ratio": 1.671641791044776, "no_speech_prob": 0.11674298346042633}, {"id": 108, "seek": 44696, "start": 446.96, "end": 452.4, "text": " and that, you know, his quote that it's AI is going to leave us in the dust.", "tokens": [50364, 293, 300, 11, 291, 458, 11, 702, 6513, 300, 309, 311, 7318, 307, 516, 281, 1856, 505, 294, 264, 8634, 13, 50636], "temperature": 0.0, "avg_logprob": -0.2464462627064098, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.06001963093876839}, {"id": 109, "seek": 44696, "start": 452.4, "end": 454.64, "text": " So that's kind of his flavor of doomer.", "tokens": [50636, 407, 300, 311, 733, 295, 702, 6813, 295, 360, 14301, 13, 50748], "temperature": 0.0, "avg_logprob": -0.2464462627064098, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.06001963093876839}, {"id": 110, "seek": 44696, "start": 454.64, "end": 463.71999999999997, "text": " I'm not sure he has the same, like, existential worry about things as, like, Stuart Russell", "tokens": [50748, 286, 478, 406, 988, 415, 575, 264, 912, 11, 411, 11, 37133, 3292, 466, 721, 382, 11, 411, 11, 36236, 20937, 51202], "temperature": 0.0, "avg_logprob": -0.2464462627064098, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.06001963093876839}, {"id": 111, "seek": 44696, "start": 463.71999999999997, "end": 464.71999999999997, "text": " or somebody.", "tokens": [51202, 420, 2618, 13, 51252], "temperature": 0.0, "avg_logprob": -0.2464462627064098, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.06001963093876839}, {"id": 112, "seek": 44696, "start": 464.71999999999997, "end": 465.71999999999997, "text": " Okay.", "tokens": [51252, 1033, 13, 51302], "temperature": 0.0, "avg_logprob": -0.2464462627064098, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.06001963093876839}, {"id": 113, "seek": 44696, "start": 465.71999999999997, "end": 472.76, "text": " So he's not so worried about them necessarily churning us into, you know, fertilizer or", "tokens": [51302, 407, 415, 311, 406, 370, 5804, 466, 552, 4725, 417, 10656, 505, 666, 11, 291, 458, 11, 31549, 420, 51654], "temperature": 0.0, "avg_logprob": -0.2464462627064098, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.06001963093876839}, {"id": 114, "seek": 44696, "start": 472.76, "end": 476.91999999999996, "text": " raw materials or something, but just that it's not so specific, I think.", "tokens": [51654, 8936, 5319, 420, 746, 11, 457, 445, 300, 309, 311, 406, 370, 2685, 11, 286, 519, 13, 51862], "temperature": 0.0, "avg_logprob": -0.2464462627064098, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.06001963093876839}, {"id": 115, "seek": 47692, "start": 477.88, "end": 482.68, "text": " But yeah, yeah, I talk to him about it all the time, and he wavers.", "tokens": [50412, 583, 1338, 11, 1338, 11, 286, 751, 281, 796, 466, 309, 439, 264, 565, 11, 293, 415, 5406, 840, 13, 50652], "temperature": 0.0, "avg_logprob": -0.26527476069903133, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.012005377560853958}, {"id": 116, "seek": 47692, "start": 484.0, "end": 488.48, "text": " Oh, interesting, because I've heard you define yourself as a centrist on other podcasts,", "tokens": [50718, 876, 11, 1880, 11, 570, 286, 600, 2198, 291, 6964, 1803, 382, 257, 1489, 12940, 322, 661, 24045, 11, 50942], "temperature": 0.0, "avg_logprob": -0.26527476069903133, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.012005377560853958}, {"id": 117, "seek": 47692, "start": 488.48, "end": 495.32, "text": " because I'm sure the doomers would lump you in with Cholet and Lacune, maybe, and some", "tokens": [50942, 570, 286, 478, 988, 264, 360, 298, 433, 576, 25551, 291, 294, 365, 761, 401, 302, 293, 40113, 2613, 11, 1310, 11, 293, 512, 51284], "temperature": 0.0, "avg_logprob": -0.26527476069903133, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.012005377560853958}, {"id": 118, "seek": 47692, "start": 495.32, "end": 501.0, "text": " of the critics, but you do think that these models are intelligent, right?", "tokens": [51284, 295, 264, 22503, 11, 457, 291, 360, 519, 300, 613, 5245, 366, 13232, 11, 558, 30, 51568], "temperature": 0.0, "avg_logprob": -0.26527476069903133, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.012005377560853958}, {"id": 119, "seek": 47692, "start": 501.96000000000004, "end": 503.56, "text": " I do think that they're intelligent.", "tokens": [51616, 286, 360, 519, 300, 436, 434, 13232, 13, 51696], "temperature": 0.0, "avg_logprob": -0.26527476069903133, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.012005377560853958}, {"id": 120, "seek": 50356, "start": 503.64, "end": 509.4, "text": " Well, you know, intelligence is an ill-defined notion.", "tokens": [50368, 1042, 11, 291, 458, 11, 7599, 307, 364, 3171, 12, 37716, 10710, 13, 50656], "temperature": 0.0, "avg_logprob": -0.20369498512961648, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.0021639701444655657}, {"id": 121, "seek": 50356, "start": 510.04, "end": 510.52, "text": " Oh, yeah.", "tokens": [50688, 876, 11, 1338, 13, 50712], "temperature": 0.0, "avg_logprob": -0.20369498512961648, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.0021639701444655657}, {"id": 122, "seek": 50356, "start": 510.52, "end": 516.04, "text": " It's multidimensional, and, you know, I don't know if we can say yes or no about something", "tokens": [50712, 467, 311, 2120, 327, 332, 11075, 11, 293, 11, 291, 458, 11, 286, 500, 380, 458, 498, 321, 393, 584, 2086, 420, 572, 466, 746, 50988], "temperature": 0.0, "avg_logprob": -0.20369498512961648, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.0021639701444655657}, {"id": 123, "seek": 50356, "start": 516.04, "end": 521.68, "text": " being intelligent rather than, you know, intelligent in certain ways or to certain degrees.", "tokens": [50988, 885, 13232, 2831, 813, 11, 291, 458, 11, 13232, 294, 1629, 2098, 420, 281, 1629, 5310, 13, 51270], "temperature": 0.0, "avg_logprob": -0.20369498512961648, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.0021639701444655657}, {"id": 124, "seek": 50356, "start": 522.64, "end": 523.0, "text": " Yeah.", "tokens": [51318, 865, 13, 51336], "temperature": 0.0, "avg_logprob": -0.20369498512961648, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.0021639701444655657}, {"id": 125, "seek": 50356, "start": 523.0, "end": 525.28, "text": " Well, we've got so much to get into.", "tokens": [51336, 1042, 11, 321, 600, 658, 370, 709, 281, 483, 666, 13, 51450], "temperature": 0.0, "avg_logprob": -0.20369498512961648, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.0021639701444655657}, {"id": 126, "seek": 50356, "start": 525.28, "end": 532.44, "text": " I mean, I think slowly we'll talk about arc and your concept arc work, but I kind of agree", "tokens": [51450, 286, 914, 11, 286, 519, 5692, 321, 603, 751, 466, 10346, 293, 428, 3410, 10346, 589, 11, 457, 286, 733, 295, 3986, 51808], "temperature": 0.0, "avg_logprob": -0.20369498512961648, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.0021639701444655657}, {"id": 127, "seek": 53244, "start": 532.44, "end": 536.6, "text": " with you that, and actually you had that paper out about the four fallacies, and you spoke", "tokens": [50364, 365, 291, 300, 11, 293, 767, 291, 632, 300, 3035, 484, 466, 264, 1451, 2100, 20330, 11, 293, 291, 7179, 50572], "temperature": 0.0, "avg_logprob": -0.1413705776899289, "compression_ratio": 1.6978417266187051, "no_speech_prob": 0.004540255758911371}, {"id": 128, "seek": 53244, "start": 536.6, "end": 543.4000000000001, "text": " about this fallacy of pure intelligence, and I kind of agree that the gnarly reality is far", "tokens": [50572, 466, 341, 2100, 2551, 295, 6075, 7599, 11, 293, 286, 733, 295, 3986, 300, 264, 290, 20062, 356, 4103, 307, 1400, 50912], "temperature": 0.0, "avg_logprob": -0.1413705776899289, "compression_ratio": 1.6978417266187051, "no_speech_prob": 0.004540255758911371}, {"id": 129, "seek": 53244, "start": 543.4000000000001, "end": 544.36, "text": " more complex than that.", "tokens": [50912, 544, 3997, 813, 300, 13, 50960], "temperature": 0.0, "avg_logprob": -0.1413705776899289, "compression_ratio": 1.6978417266187051, "no_speech_prob": 0.004540255758911371}, {"id": 130, "seek": 53244, "start": 544.36, "end": 549.8000000000001, "text": " There was a really interesting paper that you linked on, no, it was an article by Dileep George,", "tokens": [50960, 821, 390, 257, 534, 1880, 3035, 300, 291, 9408, 322, 11, 572, 11, 309, 390, 364, 7222, 538, 413, 794, 595, 7136, 11, 51232], "temperature": 0.0, "avg_logprob": -0.1413705776899289, "compression_ratio": 1.6978417266187051, "no_speech_prob": 0.004540255758911371}, {"id": 131, "seek": 53244, "start": 549.8000000000001, "end": 553.96, "text": " and he said that a university professor has a much better understanding of a vector,", "tokens": [51232, 293, 415, 848, 300, 257, 5454, 8304, 575, 257, 709, 1101, 3701, 295, 257, 8062, 11, 51440], "temperature": 0.0, "avg_logprob": -0.1413705776899289, "compression_ratio": 1.6978417266187051, "no_speech_prob": 0.004540255758911371}, {"id": 132, "seek": 53244, "start": 554.5200000000001, "end": 560.2800000000001, "text": " because it's just grounded in so many real-world situations and contexts and so on,", "tokens": [51468, 570, 309, 311, 445, 23535, 294, 370, 867, 957, 12, 13217, 6851, 293, 30628, 293, 370, 322, 11, 51756], "temperature": 0.0, "avg_logprob": -0.1413705776899289, "compression_ratio": 1.6978417266187051, "no_speech_prob": 0.004540255758911371}, {"id": 133, "seek": 56028, "start": 560.28, "end": 564.68, "text": " and an undergraduate or, indeed, a language model would have a very ungrounded, very kind", "tokens": [50364, 293, 364, 19113, 420, 11, 6451, 11, 257, 2856, 2316, 576, 362, 257, 588, 517, 2921, 292, 11, 588, 733, 50584], "temperature": 0.0, "avg_logprob": -0.12246280149980025, "compression_ratio": 1.6294820717131475, "no_speech_prob": 0.00016047457756940275}, {"id": 134, "seek": 56028, "start": 564.68, "end": 571.8, "text": " of low-resolution idea of what this concept is, and it kind of leans away from this puritanical,", "tokens": [50584, 295, 2295, 12, 495, 3386, 1558, 295, 437, 341, 3410, 307, 11, 293, 309, 733, 295, 476, 599, 1314, 490, 341, 1864, 9670, 804, 11, 50940], "temperature": 0.0, "avg_logprob": -0.12246280149980025, "compression_ratio": 1.6294820717131475, "no_speech_prob": 0.00016047457756940275}, {"id": 135, "seek": 56028, "start": 571.8, "end": 577.24, "text": " ungrounded, abstract form of intelligence to something which is really very complex and intermingled.", "tokens": [50940, 517, 2921, 292, 11, 12649, 1254, 295, 7599, 281, 746, 597, 307, 534, 588, 3997, 293, 728, 2810, 1493, 13, 51212], "temperature": 0.0, "avg_logprob": -0.12246280149980025, "compression_ratio": 1.6294820717131475, "no_speech_prob": 0.00016047457756940275}, {"id": 136, "seek": 56028, "start": 577.9599999999999, "end": 578.36, "text": " Yeah.", "tokens": [51248, 865, 13, 51268], "temperature": 0.0, "avg_logprob": -0.12246280149980025, "compression_ratio": 1.6294820717131475, "no_speech_prob": 0.00016047457756940275}, {"id": 137, "seek": 56028, "start": 578.36, "end": 579.56, "text": " I mean, I agree with that.", "tokens": [51268, 286, 914, 11, 286, 3986, 365, 300, 13, 51328], "temperature": 0.0, "avg_logprob": -0.12246280149980025, "compression_ratio": 1.6294820717131475, "no_speech_prob": 0.00016047457756940275}, {"id": 138, "seek": 56028, "start": 581.0799999999999, "end": 585.16, "text": " Well, except that there's another aspect to that, too, which you write about, which is,", "tokens": [51404, 1042, 11, 3993, 300, 456, 311, 1071, 4171, 281, 300, 11, 886, 11, 597, 291, 2464, 466, 11, 597, 307, 11, 51608], "temperature": 0.0, "avg_logprob": -0.12246280149980025, "compression_ratio": 1.6294820717131475, "no_speech_prob": 0.00016047457756940275}, {"id": 139, "seek": 58516, "start": 585.9599999999999, "end": 589.7199999999999, "text": " I agree that that happens, but what the human mind also seems to do is,", "tokens": [50404, 286, 3986, 300, 300, 2314, 11, 457, 437, 264, 1952, 1575, 611, 2544, 281, 360, 307, 11, 50592], "temperature": 0.0, "avg_logprob": -0.06443917751312256, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.00029594264924526215}, {"id": 140, "seek": 58516, "start": 590.36, "end": 596.92, "text": " as the thing becomes more grounded in more cases, then we develop yet another concept", "tokens": [50624, 382, 264, 551, 3643, 544, 23535, 294, 544, 3331, 11, 550, 321, 1499, 1939, 1071, 3410, 50952], "temperature": 0.0, "avg_logprob": -0.06443917751312256, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.00029594264924526215}, {"id": 141, "seek": 58516, "start": 596.92, "end": 603.48, "text": " that kind of describes the similar aspects that we see throughout all those different", "tokens": [50952, 300, 733, 295, 15626, 264, 2531, 7270, 300, 321, 536, 3710, 439, 729, 819, 51280], "temperature": 0.0, "avg_logprob": -0.06443917751312256, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.00029594264924526215}, {"id": 142, "seek": 58516, "start": 603.48, "end": 604.28, "text": " concepts, right?", "tokens": [51280, 10392, 11, 558, 30, 51320], "temperature": 0.0, "avg_logprob": -0.06443917751312256, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.00029594264924526215}, {"id": 143, "seek": 58516, "start": 604.28, "end": 608.92, "text": " So we're kind of this iterative loop where we're always finding more and more context,", "tokens": [51320, 407, 321, 434, 733, 295, 341, 17138, 1166, 6367, 689, 321, 434, 1009, 5006, 544, 293, 544, 4319, 11, 51552], "temperature": 0.0, "avg_logprob": -0.06443917751312256, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.00029594264924526215}, {"id": 144, "seek": 58516, "start": 608.92, "end": 614.52, "text": " and then we're also finding newer and newer concepts that span those increasing contexts.", "tokens": [51552, 293, 550, 321, 434, 611, 5006, 17628, 293, 17628, 10392, 300, 16174, 729, 5662, 30628, 13, 51832], "temperature": 0.0, "avg_logprob": -0.06443917751312256, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.00029594264924526215}, {"id": 145, "seek": 61452, "start": 614.52, "end": 615.3199999999999, "text": " Is that fair?", "tokens": [50364, 1119, 300, 3143, 30, 50404], "temperature": 0.0, "avg_logprob": -0.18308078265580974, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.003171307500451803}, {"id": 146, "seek": 61452, "start": 615.3199999999999, "end": 616.28, "text": " Yeah, sure, yeah.", "tokens": [50404, 865, 11, 988, 11, 1338, 13, 50452], "temperature": 0.0, "avg_logprob": -0.18308078265580974, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.003171307500451803}, {"id": 147, "seek": 61452, "start": 617.0, "end": 621.0799999999999, "text": " I mean, that kind of goes along with the whole sort of", "tokens": [50488, 286, 914, 11, 300, 733, 295, 1709, 2051, 365, 264, 1379, 1333, 295, 50692], "temperature": 0.0, "avg_logprob": -0.18308078265580974, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.003171307500451803}, {"id": 148, "seek": 61452, "start": 623.16, "end": 631.0, "text": " metaphor theory of cognition, of Lake Offit at all, and that we're sort of building on these", "tokens": [50796, 19157, 5261, 295, 46905, 11, 295, 10582, 6318, 270, 412, 439, 11, 293, 300, 321, 434, 1333, 295, 2390, 322, 613, 51188], "temperature": 0.0, "avg_logprob": -0.18308078265580974, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.003171307500451803}, {"id": 149, "seek": 61452, "start": 631.0, "end": 634.4399999999999, "text": " physical metaphors, and we can build up many, many layers of abstraction.", "tokens": [51188, 4001, 30946, 830, 11, 293, 321, 393, 1322, 493, 867, 11, 867, 7914, 295, 37765, 13, 51360], "temperature": 0.0, "avg_logprob": -0.18308078265580974, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.003171307500451803}, {"id": 150, "seek": 61452, "start": 636.76, "end": 638.28, "text": " So, yeah, we can talk about that.", "tokens": [51476, 407, 11, 1338, 11, 321, 393, 751, 466, 300, 13, 51552], "temperature": 0.0, "avg_logprob": -0.18308078265580974, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.003171307500451803}, {"id": 151, "seek": 61452, "start": 639.8, "end": 640.92, "text": " We're not recording yet, right?", "tokens": [51628, 492, 434, 406, 6613, 1939, 11, 558, 30, 51684], "temperature": 0.0, "avg_logprob": -0.18308078265580974, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.003171307500451803}, {"id": 152, "seek": 61452, "start": 641.56, "end": 642.28, "text": " Oh, no, we are.", "tokens": [51716, 876, 11, 572, 11, 321, 366, 13, 51752], "temperature": 0.0, "avg_logprob": -0.18308078265580974, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.003171307500451803}, {"id": 153, "seek": 61452, "start": 642.28, "end": 642.52, "text": " We are.", "tokens": [51752, 492, 366, 13, 51764], "temperature": 0.0, "avg_logprob": -0.18308078265580974, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.003171307500451803}, {"id": 154, "seek": 61452, "start": 642.52, "end": 643.24, "text": " This is all recording.", "tokens": [51764, 639, 307, 439, 6613, 13, 51800], "temperature": 0.0, "avg_logprob": -0.18308078265580974, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.003171307500451803}, {"id": 155, "seek": 61452, "start": 643.24, "end": 643.8, "text": " Oh, we are?", "tokens": [51800, 876, 11, 321, 366, 30, 51828], "temperature": 0.0, "avg_logprob": -0.18308078265580974, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.003171307500451803}, {"id": 156, "seek": 64380, "start": 644.04, "end": 645.8, "text": " I hope you're okay with what you said so far.", "tokens": [50376, 286, 1454, 291, 434, 1392, 365, 437, 291, 848, 370, 1400, 13, 50464], "temperature": 0.0, "avg_logprob": -0.166504395313752, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0012022571172565222}, {"id": 157, "seek": 64380, "start": 645.8, "end": 651.9599999999999, "text": " But yeah, so there's the Lake Off building on the body of symbols as pointers.", "tokens": [50464, 583, 1338, 11, 370, 456, 311, 264, 10582, 6318, 2390, 322, 264, 1772, 295, 16944, 382, 44548, 13, 50772], "temperature": 0.0, "avg_logprob": -0.166504395313752, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0012022571172565222}, {"id": 158, "seek": 64380, "start": 651.9599999999999, "end": 655.4, "text": " And by the way, that Dileep George article was really fascinating because it was saying", "tokens": [50772, 400, 538, 264, 636, 11, 300, 413, 794, 595, 7136, 7222, 390, 534, 10343, 570, 309, 390, 1566, 50944], "temperature": 0.0, "avg_logprob": -0.166504395313752, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0012022571172565222}, {"id": 159, "seek": 64380, "start": 655.4, "end": 657.56, "text": " that language is a conditioning force.", "tokens": [50944, 300, 2856, 307, 257, 21901, 3464, 13, 51052], "temperature": 0.0, "avg_logprob": -0.166504395313752, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0012022571172565222}, {"id": 160, "seek": 64380, "start": 657.56, "end": 662.3599999999999, "text": " So actually, we all have these high-resolution world simulators built into us, and we kind of", "tokens": [51052, 407, 767, 11, 321, 439, 362, 613, 1090, 12, 495, 3386, 1002, 1034, 39265, 3094, 666, 505, 11, 293, 321, 733, 295, 51292], "temperature": 0.0, "avg_logprob": -0.166504395313752, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0012022571172565222}, {"id": 161, "seek": 64380, "start": 663.0, "end": 667.9599999999999, "text": " condition how that operates and generate counterfactuals through language,", "tokens": [51324, 4188, 577, 300, 22577, 293, 8460, 5682, 44919, 901, 82, 807, 2856, 11, 51572], "temperature": 0.0, "avg_logprob": -0.166504395313752, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0012022571172565222}, {"id": 162, "seek": 64380, "start": 667.9599999999999, "end": 669.24, "text": " which I thought was quite interesting.", "tokens": [51572, 597, 286, 1194, 390, 1596, 1880, 13, 51636], "temperature": 0.0, "avg_logprob": -0.166504395313752, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0012022571172565222}, {"id": 163, "seek": 64380, "start": 670.12, "end": 670.4399999999999, "text": " Yeah.", "tokens": [51680, 865, 13, 51696], "temperature": 0.0, "avg_logprob": -0.166504395313752, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0012022571172565222}, {"id": 164, "seek": 67044, "start": 671.4000000000001, "end": 671.8800000000001, "text": " Yeah.", "tokens": [50412, 865, 13, 50436], "temperature": 0.0, "avg_logprob": -0.22047271226581774, "compression_ratio": 1.646875, "no_speech_prob": 0.0015442820731550455}, {"id": 165, "seek": 67044, "start": 671.8800000000001, "end": 675.0, "text": " But, Tim, why don't you frame up the debate?", "tokens": [50436, 583, 11, 7172, 11, 983, 500, 380, 291, 3920, 493, 264, 7958, 30, 50592], "temperature": 0.0, "avg_logprob": -0.22047271226581774, "compression_ratio": 1.646875, "no_speech_prob": 0.0015442820731550455}, {"id": 166, "seek": 67044, "start": 675.0, "end": 676.44, "text": " Because we found a beautiful paragraph.", "tokens": [50592, 1436, 321, 1352, 257, 2238, 18865, 13, 50664], "temperature": 0.0, "avg_logprob": -0.22047271226581774, "compression_ratio": 1.646875, "no_speech_prob": 0.0015442820731550455}, {"id": 167, "seek": 67044, "start": 677.08, "end": 677.48, "text": " We did.", "tokens": [50696, 492, 630, 13, 50716], "temperature": 0.0, "avg_logprob": -0.22047271226581774, "compression_ratio": 1.646875, "no_speech_prob": 0.0015442820731550455}, {"id": 168, "seek": 67044, "start": 677.48, "end": 677.72, "text": " We did.", "tokens": [50716, 492, 630, 13, 50728], "temperature": 0.0, "avg_logprob": -0.22047271226581774, "compression_ratio": 1.646875, "no_speech_prob": 0.0015442820731550455}, {"id": 169, "seek": 67044, "start": 677.72, "end": 679.6400000000001, "text": " We found an amazing bit.", "tokens": [50728, 492, 1352, 364, 2243, 857, 13, 50824], "temperature": 0.0, "avg_logprob": -0.22047271226581774, "compression_ratio": 1.646875, "no_speech_prob": 0.0015442820731550455}, {"id": 170, "seek": 67044, "start": 679.6400000000001, "end": 680.44, "text": " Yeah.", "tokens": [50824, 865, 13, 50864], "temperature": 0.0, "avg_logprob": -0.22047271226581774, "compression_ratio": 1.646875, "no_speech_prob": 0.0015442820731550455}, {"id": 171, "seek": 67044, "start": 680.44, "end": 684.2, "text": " But just to close the loop on what I was saying, we were discussing an activism last night.", "tokens": [50864, 583, 445, 281, 1998, 264, 6367, 322, 437, 286, 390, 1566, 11, 321, 645, 10850, 364, 29040, 1036, 1818, 13, 51052], "temperature": 0.0, "avg_logprob": -0.22047271226581774, "compression_ratio": 1.646875, "no_speech_prob": 0.0015442820731550455}, {"id": 172, "seek": 67044, "start": 684.2, "end": 687.5600000000001, "text": " I'm not sure if you're familiar with some of these externalized forms of cognition,", "tokens": [51052, 286, 478, 406, 988, 498, 291, 434, 4963, 365, 512, 295, 613, 8320, 1602, 6422, 295, 46905, 11, 51220], "temperature": 0.0, "avg_logprob": -0.22047271226581774, "compression_ratio": 1.646875, "no_speech_prob": 0.0015442820731550455}, {"id": 173, "seek": 67044, "start": 687.5600000000001, "end": 690.2, "text": " and we were talking about the concept of a goal.", "tokens": [51220, 293, 321, 645, 1417, 466, 264, 3410, 295, 257, 3387, 13, 51352], "temperature": 0.0, "avg_logprob": -0.22047271226581774, "compression_ratio": 1.646875, "no_speech_prob": 0.0015442820731550455}, {"id": 174, "seek": 67044, "start": 690.7600000000001, "end": 695.48, "text": " And agents, of course, they just have these high-resolution belief trajectories of,", "tokens": [51380, 400, 12554, 11, 295, 1164, 11, 436, 445, 362, 613, 1090, 12, 495, 3386, 7107, 18257, 2083, 295, 11, 51616], "temperature": 0.0, "avg_logprob": -0.22047271226581774, "compression_ratio": 1.646875, "no_speech_prob": 0.0015442820731550455}, {"id": 175, "seek": 67044, "start": 696.0400000000001, "end": 697.8800000000001, "text": " you know, I can do all of these different actions.", "tokens": [51644, 291, 458, 11, 286, 393, 360, 439, 295, 613, 819, 5909, 13, 51736], "temperature": 0.0, "avg_logprob": -0.22047271226581774, "compression_ratio": 1.646875, "no_speech_prob": 0.0015442820731550455}, {"id": 176, "seek": 67044, "start": 697.8800000000001, "end": 699.32, "text": " And that's not really a goal.", "tokens": [51736, 400, 300, 311, 406, 534, 257, 3387, 13, 51808], "temperature": 0.0, "avg_logprob": -0.22047271226581774, "compression_ratio": 1.646875, "no_speech_prob": 0.0015442820731550455}, {"id": 177, "seek": 69932, "start": 699.32, "end": 704.5200000000001, "text": " You know, a goal is this very abstract thing which emerges at the system level,", "tokens": [50364, 509, 458, 11, 257, 3387, 307, 341, 588, 12649, 551, 597, 38965, 412, 264, 1185, 1496, 11, 50624], "temperature": 0.0, "avg_logprob": -0.11883412590322569, "compression_ratio": 1.7535211267605635, "no_speech_prob": 0.0013976130867376924}, {"id": 178, "seek": 69932, "start": 704.5200000000001, "end": 707.88, "text": " and no individual agents in the system have a concept of a goal.", "tokens": [50624, 293, 572, 2609, 12554, 294, 264, 1185, 362, 257, 3410, 295, 257, 3387, 13, 50792], "temperature": 0.0, "avg_logprob": -0.11883412590322569, "compression_ratio": 1.7535211267605635, "no_speech_prob": 0.0013976130867376924}, {"id": 179, "seek": 69932, "start": 707.88, "end": 711.0, "text": " And it might be similar with some of these concepts that we're talking about,", "tokens": [50792, 400, 309, 1062, 312, 2531, 365, 512, 295, 613, 10392, 300, 321, 434, 1417, 466, 11, 50948], "temperature": 0.0, "avg_logprob": -0.11883412590322569, "compression_ratio": 1.7535211267605635, "no_speech_prob": 0.0013976130867376924}, {"id": 180, "seek": 69932, "start": 711.0, "end": 714.6, "text": " which is, to what extent do they exist, and to what extent are they just", "tokens": [50948, 597, 307, 11, 281, 437, 8396, 360, 436, 2514, 11, 293, 281, 437, 8396, 366, 436, 445, 51128], "temperature": 0.0, "avg_logprob": -0.11883412590322569, "compression_ratio": 1.7535211267605635, "no_speech_prob": 0.0013976130867376924}, {"id": 181, "seek": 69932, "start": 714.6, "end": 718.6800000000001, "text": " something intelligible that we can point to, but they don't really meaningfully exist", "tokens": [51128, 746, 5613, 964, 300, 321, 393, 935, 281, 11, 457, 436, 500, 380, 534, 3620, 2277, 2514, 51332], "temperature": 0.0, "avg_logprob": -0.11883412590322569, "compression_ratio": 1.7535211267605635, "no_speech_prob": 0.0013976130867376924}, {"id": 182, "seek": 69932, "start": 718.6800000000001, "end": 720.2, "text": " in the system at a high-resolution.", "tokens": [51332, 294, 264, 1185, 412, 257, 1090, 12, 495, 3386, 13, 51408], "temperature": 0.0, "avg_logprob": -0.11883412590322569, "compression_ratio": 1.7535211267605635, "no_speech_prob": 0.0013976130867376924}, {"id": 183, "seek": 69932, "start": 721.48, "end": 726.2, "text": " Are you talking about an AI or in people, a little piece here?", "tokens": [51472, 2014, 291, 1417, 466, 364, 7318, 420, 294, 561, 11, 257, 707, 2522, 510, 30, 51708], "temperature": 0.0, "avg_logprob": -0.11883412590322569, "compression_ratio": 1.7535211267605635, "no_speech_prob": 0.0013976130867376924}, {"id": 184, "seek": 69932, "start": 726.2, "end": 726.7600000000001, "text": " All of the above.", "tokens": [51708, 1057, 295, 264, 3673, 13, 51736], "temperature": 0.0, "avg_logprob": -0.11883412590322569, "compression_ratio": 1.7535211267605635, "no_speech_prob": 0.0013976130867376924}, {"id": 185, "seek": 72676, "start": 727.72, "end": 730.84, "text": " I mean, I think goal is a wonderful example, because we think of it.", "tokens": [50412, 286, 914, 11, 286, 519, 3387, 307, 257, 3715, 1365, 11, 570, 321, 519, 295, 309, 13, 50568], "temperature": 0.0, "avg_logprob": -0.11766963169492524, "compression_ratio": 1.6610878661087867, "no_speech_prob": 0.0012221770593896508}, {"id": 186, "seek": 72676, "start": 730.84, "end": 733.56, "text": " I mean, it's even one of Spelke's core priors.", "tokens": [50568, 286, 914, 11, 309, 311, 754, 472, 295, 1738, 338, 330, 311, 4965, 1790, 830, 13, 50704], "temperature": 0.0, "avg_logprob": -0.11766963169492524, "compression_ratio": 1.6610878661087867, "no_speech_prob": 0.0012221770593896508}, {"id": 187, "seek": 72676, "start": 733.56, "end": 735.4, "text": " It seems like something so primitive.", "tokens": [50704, 467, 2544, 411, 746, 370, 28540, 13, 50796], "temperature": 0.0, "avg_logprob": -0.11766963169492524, "compression_ratio": 1.6610878661087867, "no_speech_prob": 0.0012221770593896508}, {"id": 188, "seek": 72676, "start": 736.52, "end": 740.4399999999999, "text": " But I don't think they really do exist in us.", "tokens": [50852, 583, 286, 500, 380, 519, 436, 534, 360, 2514, 294, 505, 13, 51048], "temperature": 0.0, "avg_logprob": -0.11766963169492524, "compression_ratio": 1.6610878661087867, "no_speech_prob": 0.0012221770593896508}, {"id": 189, "seek": 72676, "start": 740.4399999999999, "end": 745.56, "text": " I mean, we're interesting because we have this reflexive conception of a goal,", "tokens": [51048, 286, 914, 11, 321, 434, 1880, 570, 321, 362, 341, 23802, 488, 30698, 295, 257, 3387, 11, 51304], "temperature": 0.0, "avg_logprob": -0.11766963169492524, "compression_ratio": 1.6610878661087867, "no_speech_prob": 0.0012221770593896508}, {"id": 190, "seek": 72676, "start": 745.56, "end": 748.12, "text": " but does a mouse have a goal?", "tokens": [51304, 457, 775, 257, 9719, 362, 257, 3387, 30, 51432], "temperature": 0.0, "avg_logprob": -0.11766963169492524, "compression_ratio": 1.6610878661087867, "no_speech_prob": 0.0012221770593896508}, {"id": 191, "seek": 72676, "start": 750.52, "end": 756.68, "text": " Right. I mean, goal is another one of those words that, you know, we use in a very fluid", "tokens": [51552, 1779, 13, 286, 914, 11, 3387, 307, 1071, 472, 295, 729, 2283, 300, 11, 291, 458, 11, 321, 764, 294, 257, 588, 9113, 51860], "temperature": 0.0, "avg_logprob": -0.11766963169492524, "compression_ratio": 1.6610878661087867, "no_speech_prob": 0.0012221770593896508}, {"id": 192, "seek": 75668, "start": 756.68, "end": 761.16, "text": " way. So we talk about, for instance, a reinforcement learning agent having a goal", "tokens": [50364, 636, 13, 407, 321, 751, 466, 11, 337, 5197, 11, 257, 29280, 2539, 9461, 1419, 257, 3387, 50588], "temperature": 0.0, "avg_logprob": -0.14414141394875266, "compression_ratio": 1.6179245283018868, "no_speech_prob": 0.0005355749744921923}, {"id": 193, "seek": 75668, "start": 761.88, "end": 768.12, "text": " that we've given to it, right? Or it might have a goal to kind of maximize its information gain", "tokens": [50624, 300, 321, 600, 2212, 281, 309, 11, 558, 30, 1610, 309, 1062, 362, 257, 3387, 281, 733, 295, 19874, 1080, 1589, 6052, 50936], "temperature": 0.0, "avg_logprob": -0.14414141394875266, "compression_ratio": 1.6179245283018868, "no_speech_prob": 0.0005355749744921923}, {"id": 194, "seek": 75668, "start": 768.12, "end": 776.4399999999999, "text": " or something. But is that the same thing as a human having a goal that it's like,", "tokens": [50936, 420, 746, 13, 583, 307, 300, 264, 912, 551, 382, 257, 1952, 1419, 257, 3387, 300, 309, 311, 411, 11, 51352], "temperature": 0.0, "avg_logprob": -0.14414141394875266, "compression_ratio": 1.6179245283018868, "no_speech_prob": 0.0005355749744921923}, {"id": 195, "seek": 75668, "start": 776.4399999999999, "end": 784.76, "text": " you know, to graduate from college or to, you know, make something of your life for", "tokens": [51352, 291, 458, 11, 281, 8080, 490, 3859, 420, 281, 11, 291, 458, 11, 652, 746, 295, 428, 993, 337, 51768], "temperature": 0.0, "avg_logprob": -0.14414141394875266, "compression_ratio": 1.6179245283018868, "no_speech_prob": 0.0005355749744921923}, {"id": 196, "seek": 78476, "start": 784.76, "end": 788.84, "text": " all of these things? It's a very different sense of goal.", "tokens": [50364, 439, 295, 613, 721, 30, 467, 311, 257, 588, 819, 2020, 295, 3387, 13, 50568], "temperature": 0.0, "avg_logprob": -0.08498191251987364, "compression_ratio": 1.5643564356435644, "no_speech_prob": 0.00035689788637682796}, {"id": 197, "seek": 78476, "start": 788.84, "end": 797.96, "text": " And so I would say, yes, a mouse has goals, but those goals are different in degree and in kind", "tokens": [50568, 400, 370, 286, 576, 584, 11, 2086, 11, 257, 9719, 575, 5493, 11, 457, 729, 5493, 366, 819, 294, 4314, 293, 294, 733, 51024], "temperature": 0.0, "avg_logprob": -0.08498191251987364, "compression_ratio": 1.5643564356435644, "no_speech_prob": 0.00035689788637682796}, {"id": 198, "seek": 78476, "start": 797.96, "end": 803.24, "text": " of qualitatively than many of the things we call goals in humans and in machines.", "tokens": [51024, 295, 31312, 356, 813, 867, 295, 264, 721, 321, 818, 5493, 294, 6255, 293, 294, 8379, 13, 51288], "temperature": 0.0, "avg_logprob": -0.08498191251987364, "compression_ratio": 1.5643564356435644, "no_speech_prob": 0.00035689788637682796}, {"id": 199, "seek": 78476, "start": 803.24, "end": 809.72, "text": " So I think goal is one of those sort of anthropomorphizing words that we need to", "tokens": [51288, 407, 286, 519, 3387, 307, 472, 295, 729, 1333, 295, 22727, 32702, 3319, 2283, 300, 321, 643, 281, 51612], "temperature": 0.0, "avg_logprob": -0.08498191251987364, "compression_ratio": 1.5643564356435644, "no_speech_prob": 0.00035689788637682796}, {"id": 200, "seek": 80972, "start": 809.8000000000001, "end": 816.6, "text": " be careful about when we equate goals in these different systems as being the same thing.", "tokens": [50368, 312, 5026, 466, 562, 321, 1267, 473, 5493, 294, 613, 819, 3652, 382, 885, 264, 912, 551, 13, 50708], "temperature": 0.0, "avg_logprob": -0.1257403729909874, "compression_ratio": 1.5904761904761904, "no_speech_prob": 0.0067937639541924}, {"id": 201, "seek": 80972, "start": 817.1600000000001, "end": 821.48, "text": " And I actually, you know, had a discussion with, I think it was with Stuart Russell", "tokens": [50736, 400, 286, 767, 11, 291, 458, 11, 632, 257, 5017, 365, 11, 286, 519, 309, 390, 365, 36236, 20937, 50952], "temperature": 0.0, "avg_logprob": -0.1257403729909874, "compression_ratio": 1.5904761904761904, "no_speech_prob": 0.0067937639541924}, {"id": 202, "seek": 80972, "start": 822.76, "end": 829.96, "text": " about the notion of goal. And his view, and I think this is a view of many other people", "tokens": [51016, 466, 264, 10710, 295, 3387, 13, 400, 702, 1910, 11, 293, 286, 519, 341, 307, 257, 1910, 295, 867, 661, 561, 51376], "temperature": 0.0, "avg_logprob": -0.1257403729909874, "compression_ratio": 1.5904761904761904, "no_speech_prob": 0.0067937639541924}, {"id": 203, "seek": 80972, "start": 830.84, "end": 837.88, "text": " in AI, is that large language models actually have goals, complex goals,", "tokens": [51420, 294, 7318, 11, 307, 300, 2416, 2856, 5245, 767, 362, 5493, 11, 3997, 5493, 11, 51772], "temperature": 0.0, "avg_logprob": -0.1257403729909874, "compression_ratio": 1.5904761904761904, "no_speech_prob": 0.0067937639541924}, {"id": 204, "seek": 83788, "start": 838.4399999999999, "end": 849.0, "text": " that they, that emerge out of this, you know, their loss function of predicting the next token,", "tokens": [50392, 300, 436, 11, 300, 21511, 484, 295, 341, 11, 291, 458, 11, 641, 4470, 2445, 295, 32884, 264, 958, 14862, 11, 50920], "temperature": 0.0, "avg_logprob": -0.1097102997794984, "compression_ratio": 1.5202312138728324, "no_speech_prob": 0.0008033494814299047}, {"id": 205, "seek": 83788, "start": 850.12, "end": 856.4399999999999, "text": " because the only way to successfully predict the next token in human language is to develop", "tokens": [50976, 570, 264, 787, 636, 281, 10727, 6069, 264, 958, 14862, 294, 1952, 2856, 307, 281, 1499, 51292], "temperature": 0.0, "avg_logprob": -0.1097102997794984, "compression_ratio": 1.5202312138728324, "no_speech_prob": 0.0008033494814299047}, {"id": 206, "seek": 83788, "start": 856.4399999999999, "end": 862.12, "text": " human-like goals. I find that dubious, but it's an interesting perspective.", "tokens": [51292, 1952, 12, 4092, 5493, 13, 286, 915, 300, 18540, 851, 11, 457, 309, 311, 364, 1880, 4585, 13, 51576], "temperature": 0.0, "avg_logprob": -0.1097102997794984, "compression_ratio": 1.5202312138728324, "no_speech_prob": 0.0008033494814299047}, {"id": 207, "seek": 86212, "start": 862.36, "end": 868.76, "text": " Yeah, I'm amenable to it, because there's always this dichotomy, as you say, of there's the objective,", "tokens": [50376, 865, 11, 286, 478, 18497, 712, 281, 309, 11, 570, 456, 311, 1009, 341, 10390, 310, 8488, 11, 382, 291, 584, 11, 295, 456, 311, 264, 10024, 11, 50696], "temperature": 0.0, "avg_logprob": -0.100912078221639, "compression_ratio": 1.794776119402985, "no_speech_prob": 0.004889312200248241}, {"id": 208, "seek": 86212, "start": 868.76, "end": 872.84, "text": " there's perplexity, and there's these emergent goals, and there's even this simulator's theory", "tokens": [50696, 456, 311, 680, 18945, 507, 11, 293, 456, 311, 613, 4345, 6930, 5493, 11, 293, 456, 311, 754, 341, 32974, 311, 5261, 50900], "temperature": 0.0, "avg_logprob": -0.100912078221639, "compression_ratio": 1.794776119402985, "no_speech_prob": 0.004889312200248241}, {"id": 209, "seek": 86212, "start": 872.84, "end": 878.04, "text": " of large language models, which is that they're a superposition of agents. And it's quite situated", "tokens": [50900, 295, 2416, 2856, 5245, 11, 597, 307, 300, 436, 434, 257, 1687, 38078, 295, 12554, 13, 400, 309, 311, 1596, 30143, 51160], "temperature": 0.0, "avg_logprob": -0.100912078221639, "compression_ratio": 1.794776119402985, "no_speech_prob": 0.004889312200248241}, {"id": 210, "seek": 86212, "start": 878.04, "end": 883.24, "text": " as well, because goals kind of materialize depending on your perspective. So if you use a", "tokens": [51160, 382, 731, 11, 570, 5493, 733, 295, 2527, 1125, 5413, 322, 428, 4585, 13, 407, 498, 291, 764, 257, 51420], "temperature": 0.0, "avg_logprob": -0.100912078221639, "compression_ratio": 1.794776119402985, "no_speech_prob": 0.004889312200248241}, {"id": 211, "seek": 86212, "start": 883.24, "end": 887.32, "text": " language model in a certain way from a certain perspective, it might appear that there is some", "tokens": [51420, 2856, 2316, 294, 257, 1629, 636, 490, 257, 1629, 4585, 11, 309, 1062, 4204, 300, 456, 307, 512, 51624], "temperature": 0.0, "avg_logprob": -0.100912078221639, "compression_ratio": 1.794776119402985, "no_speech_prob": 0.004889312200248241}, {"id": 212, "seek": 88732, "start": 887.32, "end": 892.2, "text": " kind of goal there, but of course, it's just an aspect onto something which is very complex.", "tokens": [50364, 733, 295, 3387, 456, 11, 457, 295, 1164, 11, 309, 311, 445, 364, 4171, 3911, 746, 597, 307, 588, 3997, 13, 50608], "temperature": 0.0, "avg_logprob": -0.1292103070479173, "compression_ratio": 1.6988416988416988, "no_speech_prob": 0.005012820940464735}, {"id": 213, "seek": 88732, "start": 892.7600000000001, "end": 896.7600000000001, "text": " But I think we should frame up this beautiful piece, actually, from your", "tokens": [50636, 583, 286, 519, 321, 820, 3920, 493, 341, 2238, 2522, 11, 767, 11, 490, 428, 50836], "temperature": 0.0, "avg_logprob": -0.1292103070479173, "compression_ratio": 1.6988416988416988, "no_speech_prob": 0.005012820940464735}, {"id": 214, "seek": 88732, "start": 897.4000000000001, "end": 901.5600000000001, "text": " Modes of Understanding paper from much this year. I always call it the Modes of Understanding paper.", "tokens": [50868, 376, 4789, 295, 36858, 3035, 490, 709, 341, 1064, 13, 286, 1009, 818, 309, 264, 376, 4789, 295, 36858, 3035, 13, 51076], "temperature": 0.0, "avg_logprob": -0.1292103070479173, "compression_ratio": 1.6988416988416988, "no_speech_prob": 0.005012820940464735}, {"id": 215, "seek": 88732, "start": 901.5600000000001, "end": 906.0400000000001, "text": " It was actually titled The Debate over Understanding in AI's Large Language Models.", "tokens": [51076, 467, 390, 767, 19841, 440, 27347, 473, 670, 36858, 294, 7318, 311, 33092, 24445, 6583, 1625, 13, 51300], "temperature": 0.0, "avg_logprob": -0.1292103070479173, "compression_ratio": 1.6988416988416988, "no_speech_prob": 0.005012820940464735}, {"id": 216, "seek": 88732, "start": 906.0400000000001, "end": 911.48, "text": " And you said, towards the end, that the key question of the debate about understanding in", "tokens": [51300, 400, 291, 848, 11, 3030, 264, 917, 11, 300, 264, 2141, 1168, 295, 264, 7958, 466, 3701, 294, 51572], "temperature": 0.0, "avg_logprob": -0.1292103070479173, "compression_ratio": 1.6988416988416988, "no_speech_prob": 0.005012820940464735}, {"id": 217, "seek": 91148, "start": 911.5600000000001, "end": 918.04, "text": " large language models is, one, is talking of understanding in such systems simply a category", "tokens": [50368, 2416, 2856, 5245, 307, 11, 472, 11, 307, 1417, 295, 3701, 294, 1270, 3652, 2935, 257, 7719, 50692], "temperature": 0.0, "avg_logprob": -0.11210345072918627, "compression_ratio": 1.7465437788018434, "no_speech_prob": 0.067088283598423}, {"id": 218, "seek": 91148, "start": 918.04, "end": 922.9200000000001, "text": " error, which is mistaking associations between language tokens for associations between", "tokens": [50692, 6713, 11, 597, 307, 3544, 2456, 26597, 1296, 2856, 22667, 337, 26597, 1296, 50936], "temperature": 0.0, "avg_logprob": -0.11210345072918627, "compression_ratio": 1.7465437788018434, "no_speech_prob": 0.067088283598423}, {"id": 219, "seek": 91148, "start": 923.5600000000001, "end": 930.2, "text": " tokens and physical, social, and mental experience? In short, is it the case that these models are", "tokens": [50968, 22667, 293, 4001, 11, 2093, 11, 293, 4973, 1752, 30, 682, 2099, 11, 307, 309, 264, 1389, 300, 613, 5245, 366, 51300], "temperature": 0.0, "avg_logprob": -0.11210345072918627, "compression_ratio": 1.7465437788018434, "no_speech_prob": 0.067088283598423}, {"id": 220, "seek": 91148, "start": 930.2, "end": 936.76, "text": " not and will never be the kind of things that can understand, or conversely, to do these systems or", "tokens": [51300, 406, 293, 486, 1128, 312, 264, 733, 295, 721, 300, 393, 1223, 11, 420, 2615, 736, 11, 281, 360, 613, 3652, 420, 51628], "temperature": 0.0, "avg_logprob": -0.11210345072918627, "compression_ratio": 1.7465437788018434, "no_speech_prob": 0.067088283598423}, {"id": 221, "seek": 93676, "start": 936.76, "end": 941.72, "text": " their near term successes? Actually, even in the absence of physical experience, create something", "tokens": [50364, 641, 2651, 1433, 26101, 30, 5135, 11, 754, 294, 264, 17145, 295, 4001, 1752, 11, 1884, 746, 50612], "temperature": 0.0, "avg_logprob": -0.10576413540129966, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.02741285227239132}, {"id": 222, "seek": 93676, "start": 941.72, "end": 946.52, "text": " like the rich concept based mental models that are central to human understanding. And if so,", "tokens": [50612, 411, 264, 4593, 3410, 2361, 4973, 5245, 300, 366, 5777, 281, 1952, 3701, 13, 400, 498, 370, 11, 50852], "temperature": 0.0, "avg_logprob": -0.10576413540129966, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.02741285227239132}, {"id": 223, "seek": 93676, "start": 946.52, "end": 951.8, "text": " does scaling these models create even better concepts? Or three, if these systems do not", "tokens": [50852, 775, 21589, 613, 5245, 1884, 754, 1101, 10392, 30, 1610, 1045, 11, 498, 613, 3652, 360, 406, 51116], "temperature": 0.0, "avg_logprob": -0.10576413540129966, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.02741285227239132}, {"id": 224, "seek": 93676, "start": 951.8, "end": 957.3199999999999, "text": " create such concepts, can their unimaginably large systems of statistical correlations,", "tokens": [51116, 1884, 1270, 10392, 11, 393, 641, 517, 44976, 1188, 2416, 3652, 295, 22820, 13983, 763, 11, 51392], "temperature": 0.0, "avg_logprob": -0.10576413540129966, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.02741285227239132}, {"id": 225, "seek": 93676, "start": 957.3199999999999, "end": 962.76, "text": " produce abilities that are fundamentally equivalent to human understanding, or indeed that enable", "tokens": [51392, 5258, 11582, 300, 366, 17879, 10344, 281, 1952, 3701, 11, 420, 6451, 300, 9528, 51664], "temperature": 0.0, "avg_logprob": -0.10576413540129966, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.02741285227239132}, {"id": 226, "seek": 96276, "start": 962.76, "end": 968.12, "text": " new forms of higher order logic that humans are incapable of accessing? And at this point,", "tokens": [50364, 777, 6422, 295, 2946, 1668, 9952, 300, 6255, 366, 44174, 295, 26440, 30, 400, 412, 341, 935, 11, 50632], "temperature": 0.0, "avg_logprob": -0.07706128740773617, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.01057656854391098}, {"id": 227, "seek": 96276, "start": 968.12, "end": 975.56, "text": " will it still make sense to call such correlations spurious and the resulting solutions shortcuts?", "tokens": [50632, 486, 309, 920, 652, 2020, 281, 818, 1270, 13983, 763, 637, 24274, 293, 264, 16505, 6547, 34620, 30, 51004], "temperature": 0.0, "avg_logprob": -0.07706128740773617, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.01057656854391098}, {"id": 228, "seek": 96276, "start": 975.56, "end": 981.4, "text": " And would it make sense to see these systems' behaviors not as competence without comprehension,", "tokens": [51004, 400, 576, 309, 652, 2020, 281, 536, 613, 3652, 6, 15501, 406, 382, 39965, 1553, 44991, 11, 51296], "temperature": 0.0, "avg_logprob": -0.07706128740773617, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.01057656854391098}, {"id": 229, "seek": 96276, "start": 981.4, "end": 986.28, "text": " but as a new, non-human form of understanding? And you said that these questions are no longer", "tokens": [51296, 457, 382, 257, 777, 11, 2107, 12, 18796, 1254, 295, 3701, 30, 400, 291, 848, 300, 613, 1651, 366, 572, 2854, 51540], "temperature": 0.0, "avg_logprob": -0.07706128740773617, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.01057656854391098}, {"id": 230, "seek": 96276, "start": 986.28, "end": 991.72, "text": " in the realm of abstract philosophical discussions, but they touch on very real concerns about the", "tokens": [51540, 294, 264, 15355, 295, 12649, 25066, 11088, 11, 457, 436, 2557, 322, 588, 957, 7389, 466, 264, 51812], "temperature": 0.0, "avg_logprob": -0.07706128740773617, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.01057656854391098}, {"id": 231, "seek": 99172, "start": 991.72, "end": 997.96, "text": " capabilities and robustness and safety and ethics of AI systems. So let's use that as a leader.", "tokens": [50364, 10862, 293, 13956, 1287, 293, 4514, 293, 19769, 295, 7318, 3652, 13, 407, 718, 311, 764, 300, 382, 257, 5263, 13, 50676], "temperature": 0.0, "avg_logprob": -0.13945889734959865, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.0018346772994846106}, {"id": 232, "seek": 99172, "start": 997.96, "end": 1001.48, "text": " What do you think, Melanie? It's beautiful. That was a beautiful paragraph, by the way.", "tokens": [50676, 708, 360, 291, 519, 11, 42798, 30, 467, 311, 2238, 13, 663, 390, 257, 2238, 18865, 11, 538, 264, 636, 13, 50852], "temperature": 0.0, "avg_logprob": -0.13945889734959865, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.0018346772994846106}, {"id": 233, "seek": 99172, "start": 1001.48, "end": 1005.72, "text": " Yeah, it's so good. Wow. This exactly crystallizes the discussion.", "tokens": [50852, 865, 11, 309, 311, 370, 665, 13, 3153, 13, 639, 2293, 31924, 5660, 264, 5017, 13, 51064], "temperature": 0.0, "avg_logprob": -0.13945889734959865, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.0018346772994846106}, {"id": 234, "seek": 99172, "start": 1008.28, "end": 1015.4, "text": " Yeah, I think that it's something that we in AI are all grappling with now. And I think it's", "tokens": [51192, 865, 11, 286, 519, 300, 309, 311, 746, 300, 321, 294, 7318, 366, 439, 50086, 365, 586, 13, 400, 286, 519, 309, 311, 51548], "temperature": 0.0, "avg_logprob": -0.13945889734959865, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.0018346772994846106}, {"id": 235, "seek": 101540, "start": 1015.4, "end": 1022.92, "text": " something that the history of AI has forced us to grapple with mental terms like understand,", "tokens": [50364, 746, 300, 264, 2503, 295, 7318, 575, 7579, 505, 281, 27165, 306, 365, 4973, 2115, 411, 1223, 11, 50740], "temperature": 0.0, "avg_logprob": -0.13588761549729567, "compression_ratio": 1.5159574468085106, "no_speech_prob": 0.010647309944033623}, {"id": 236, "seek": 101540, "start": 1023.72, "end": 1033.08, "text": " or consciousness, and even intelligence. Because we keep saying, oh, well, understanding, if you", "tokens": [50780, 420, 10081, 11, 293, 754, 7599, 13, 1436, 321, 1066, 1566, 11, 1954, 11, 731, 11, 3701, 11, 498, 291, 51248], "temperature": 0.0, "avg_logprob": -0.13588761549729567, "compression_ratio": 1.5159574468085106, "no_speech_prob": 0.010647309944033623}, {"id": 237, "seek": 101540, "start": 1033.08, "end": 1043.08, "text": " can do X, then that means that you're actually understanding. You can't do language translation", "tokens": [51248, 393, 360, 1783, 11, 550, 300, 1355, 300, 291, 434, 767, 3701, 13, 509, 393, 380, 360, 2856, 12853, 51748], "temperature": 0.0, "avg_logprob": -0.13588761549729567, "compression_ratio": 1.5159574468085106, "no_speech_prob": 0.010647309944033623}, {"id": 238, "seek": 104308, "start": 1043.08, "end": 1050.28, "text": " without understanding. You can't do speech to text without understanding. You can't generate", "tokens": [50364, 1553, 3701, 13, 509, 393, 380, 360, 6218, 281, 2487, 1553, 3701, 13, 509, 393, 380, 8460, 50724], "temperature": 0.0, "avg_logprob": -0.08607099850972494, "compression_ratio": 1.892156862745098, "no_speech_prob": 0.0017541610868647695}, {"id": 239, "seek": 104308, "start": 1050.28, "end": 1059.72, "text": " articulate natural language without understanding. And I think this is, in many cases, we then step", "tokens": [50724, 30305, 3303, 2856, 1553, 3701, 13, 400, 286, 519, 341, 307, 11, 294, 867, 3331, 11, 321, 550, 1823, 51196], "temperature": 0.0, "avg_logprob": -0.08607099850972494, "compression_ratio": 1.892156862745098, "no_speech_prob": 0.0017541610868647695}, {"id": 240, "seek": 104308, "start": 1059.72, "end": 1064.36, "text": " back and say, wait, that's not what we meant by understanding. It turns out you can do all these", "tokens": [51196, 646, 293, 584, 11, 1699, 11, 300, 311, 406, 437, 321, 4140, 538, 3701, 13, 467, 4523, 484, 291, 393, 360, 439, 613, 51428], "temperature": 0.0, "avg_logprob": -0.08607099850972494, "compression_ratio": 1.892156862745098, "no_speech_prob": 0.0017541610868647695}, {"id": 241, "seek": 104308, "start": 1064.36, "end": 1069.08, "text": " things without understanding. So we're sort of saying, well, we didn't really know what we meant", "tokens": [51428, 721, 1553, 3701, 13, 407, 321, 434, 1333, 295, 1566, 11, 731, 11, 321, 994, 380, 534, 458, 437, 321, 4140, 51664], "temperature": 0.0, "avg_logprob": -0.08607099850972494, "compression_ratio": 1.892156862745098, "no_speech_prob": 0.0017541610868647695}, {"id": 242, "seek": 106908, "start": 1069.08, "end": 1076.6, "text": " by the term understanding, I think. And often, some people criticize that as moving the goalposts.", "tokens": [50364, 538, 264, 1433, 3701, 11, 286, 519, 13, 400, 2049, 11, 512, 561, 31010, 300, 382, 2684, 264, 3387, 23744, 82, 13, 50740], "temperature": 0.0, "avg_logprob": -0.1399987756389461, "compression_ratio": 1.5085714285714287, "no_speech_prob": 0.004197613801807165}, {"id": 243, "seek": 106908, "start": 1078.1999999999998, "end": 1080.52, "text": " You're moving the goalposts. The so-called AI effect, right?", "tokens": [50820, 509, 434, 2684, 264, 3387, 23744, 82, 13, 440, 370, 12, 11880, 7318, 1802, 11, 558, 30, 50936], "temperature": 0.0, "avg_logprob": -0.1399987756389461, "compression_ratio": 1.5085714285714287, "no_speech_prob": 0.004197613801807165}, {"id": 244, "seek": 106908, "start": 1080.52, "end": 1082.1999999999998, "text": " Right. It's the AI effect.", "tokens": [50936, 1779, 13, 467, 311, 264, 7318, 1802, 13, 51020], "temperature": 0.0, "avg_logprob": -0.1399987756389461, "compression_ratio": 1.5085714285714287, "no_speech_prob": 0.004197613801807165}, {"id": 245, "seek": 106908, "start": 1082.1999999999998, "end": 1091.8, "text": " But I think of it more as AI is forcing people to really refine their notions", "tokens": [51020, 583, 286, 519, 295, 309, 544, 382, 7318, 307, 19030, 561, 281, 534, 33906, 641, 35799, 51500], "temperature": 0.0, "avg_logprob": -0.1399987756389461, "compression_ratio": 1.5085714285714287, "no_speech_prob": 0.004197613801807165}, {"id": 246, "seek": 109180, "start": 1092.68, "end": 1097.1599999999999, "text": " of that that have been quite fuzzy about what these terms actually mean.", "tokens": [50408, 295, 300, 300, 362, 668, 1596, 34710, 466, 437, 613, 2115, 767, 914, 13, 50632], "temperature": 0.0, "avg_logprob": -0.12780496933880975, "compression_ratio": 1.6177777777777778, "no_speech_prob": 0.006001347675919533}, {"id": 247, "seek": 109180, "start": 1098.2, "end": 1105.32, "text": " And there was a fantastic talk by Dave Chalmers, the philosopher, who I think you've probably had", "tokens": [50684, 400, 456, 390, 257, 5456, 751, 538, 11017, 761, 304, 18552, 11, 264, 29805, 11, 567, 286, 519, 291, 600, 1391, 632, 51040], "temperature": 0.0, "avg_logprob": -0.12780496933880975, "compression_ratio": 1.6177777777777778, "no_speech_prob": 0.006001347675919533}, {"id": 248, "seek": 109180, "start": 1105.32, "end": 1113.6399999999999, "text": " on this show, where he talks about conceptual engineering, which is something that philosophers", "tokens": [51040, 322, 341, 855, 11, 689, 415, 6686, 466, 24106, 7043, 11, 597, 307, 746, 300, 36839, 51456], "temperature": 0.0, "avg_logprob": -0.12780496933880975, "compression_ratio": 1.6177777777777778, "no_speech_prob": 0.006001347675919533}, {"id": 249, "seek": 109180, "start": 1113.6399999999999, "end": 1119.24, "text": " do where they take a term like understanding and they refine it. And he said, okay, well, we have", "tokens": [51456, 360, 689, 436, 747, 257, 1433, 411, 3701, 293, 436, 33906, 309, 13, 400, 415, 848, 11, 1392, 11, 731, 11, 321, 362, 51736], "temperature": 0.0, "avg_logprob": -0.12780496933880975, "compression_ratio": 1.6177777777777778, "no_speech_prob": 0.006001347675919533}, {"id": 250, "seek": 111924, "start": 1120.2, "end": 1128.76, "text": " p-understanding, which is like personal, phenomenological. And then we have c-understanding", "tokens": [50412, 280, 12, 6617, 8618, 11, 597, 307, 411, 2973, 11, 9388, 4383, 13, 400, 550, 321, 362, 269, 12, 6617, 8618, 50840], "temperature": 0.0, "avg_logprob": -0.0979054073492686, "compression_ratio": 1.7008928571428572, "no_speech_prob": 0.005383667536079884}, {"id": 251, "seek": 111924, "start": 1128.76, "end": 1134.52, "text": " and e-understanding and x-understanding and all these different letters that meant to say that", "tokens": [50840, 293, 308, 12, 6617, 8618, 293, 2031, 12, 6617, 8618, 293, 439, 613, 819, 7825, 300, 4140, 281, 584, 300, 51128], "temperature": 0.0, "avg_logprob": -0.0979054073492686, "compression_ratio": 1.7008928571428572, "no_speech_prob": 0.005383667536079884}, {"id": 252, "seek": 111924, "start": 1134.52, "end": 1141.48, "text": " this term is not a unified thing that we can apply to a system. We have to really specify what we", "tokens": [51128, 341, 1433, 307, 406, 257, 26787, 551, 300, 321, 393, 3079, 281, 257, 1185, 13, 492, 362, 281, 534, 16500, 437, 321, 51476], "temperature": 0.0, "avg_logprob": -0.0979054073492686, "compression_ratio": 1.7008928571428572, "no_speech_prob": 0.005383667536079884}, {"id": 253, "seek": 111924, "start": 1141.48, "end": 1148.04, "text": " mean exactly. Well, one way I've come to think about it, and it's largely from reading your work", "tokens": [51476, 914, 2293, 13, 1042, 11, 472, 636, 286, 600, 808, 281, 519, 466, 309, 11, 293, 309, 311, 11611, 490, 3760, 428, 589, 51804], "temperature": 0.0, "avg_logprob": -0.0979054073492686, "compression_ratio": 1.7008928571428572, "no_speech_prob": 0.005383667536079884}, {"id": 254, "seek": 114804, "start": 1148.04, "end": 1152.76, "text": " and your assessments about it, is that for the first time, we're actually being forced to do", "tokens": [50364, 293, 428, 24338, 466, 309, 11, 307, 300, 337, 264, 700, 565, 11, 321, 434, 767, 885, 7579, 281, 360, 50600], "temperature": 0.0, "avg_logprob": -0.09949683320933375, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.006096480879932642}, {"id": 255, "seek": 114804, "start": 1153.72, "end": 1160.92, "text": " the science of machine cognition, right? Because for too long, it's either just not been sophisticated", "tokens": [50648, 264, 3497, 295, 3479, 46905, 11, 558, 30, 1436, 337, 886, 938, 11, 309, 311, 2139, 445, 406, 668, 16950, 51008], "temperature": 0.0, "avg_logprob": -0.09949683320933375, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.006096480879932642}, {"id": 256, "seek": 114804, "start": 1160.92, "end": 1166.84, "text": " enough. Why bother? Like it's obviously not doing any cognition. And as you point out, it's now", "tokens": [51008, 1547, 13, 1545, 8677, 30, 1743, 309, 311, 2745, 406, 884, 604, 46905, 13, 400, 382, 291, 935, 484, 11, 309, 311, 586, 51304], "temperature": 0.0, "avg_logprob": -0.09949683320933375, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.006096480879932642}, {"id": 257, "seek": 114804, "start": 1166.84, "end": 1172.52, "text": " actually having real world impacts. And so we actually have to start doing the science, right?", "tokens": [51304, 767, 1419, 957, 1002, 11606, 13, 400, 370, 321, 767, 362, 281, 722, 884, 264, 3497, 11, 558, 30, 51588], "temperature": 0.0, "avg_logprob": -0.09949683320933375, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.006096480879932642}, {"id": 258, "seek": 114804, "start": 1172.52, "end": 1177.6399999999999, "text": " We have to say, okay, does this thing have cognition? Here's a hypothesis. Let's do some", "tokens": [51588, 492, 362, 281, 584, 11, 1392, 11, 775, 341, 551, 362, 46905, 30, 1692, 311, 257, 17291, 13, 961, 311, 360, 512, 51844], "temperature": 0.0, "avg_logprob": -0.09949683320933375, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.006096480879932642}, {"id": 259, "seek": 117764, "start": 1177.64, "end": 1182.3600000000001, "text": " test. Okay, it failed. What was the failure mode? Why did it fail? Let's understand that more. How", "tokens": [50364, 1500, 13, 1033, 11, 309, 7612, 13, 708, 390, 264, 7763, 4391, 30, 1545, 630, 309, 3061, 30, 961, 311, 1223, 300, 544, 13, 1012, 50600], "temperature": 0.0, "avg_logprob": -0.09100569340220668, "compression_ratio": 1.5972222222222223, "no_speech_prob": 0.0006070332019589841}, {"id": 260, "seek": 117764, "start": 1182.3600000000001, "end": 1187.88, "text": " can we engineer it not to fail? It's like we can no longer ignore adversarial examples,", "tokens": [50600, 393, 321, 11403, 309, 406, 281, 3061, 30, 467, 311, 411, 321, 393, 572, 2854, 11200, 17641, 44745, 5110, 11, 50876], "temperature": 0.0, "avg_logprob": -0.09100569340220668, "compression_ratio": 1.5972222222222223, "no_speech_prob": 0.0006070332019589841}, {"id": 261, "seek": 117764, "start": 1187.88, "end": 1191.8000000000002, "text": " shortcut learning, et cetera. We have to finally grapple with it, it seems to me.", "tokens": [50876, 24822, 2539, 11, 1030, 11458, 13, 492, 362, 281, 2721, 27165, 306, 365, 309, 11, 309, 2544, 281, 385, 13, 51072], "temperature": 0.0, "avg_logprob": -0.09100569340220668, "compression_ratio": 1.5972222222222223, "no_speech_prob": 0.0006070332019589841}, {"id": 262, "seek": 117764, "start": 1192.68, "end": 1197.0800000000002, "text": " Yeah, I think that's exactly right. And what's interesting is we, computer scientists, were", "tokens": [51116, 865, 11, 286, 519, 300, 311, 2293, 558, 13, 400, 437, 311, 1880, 307, 321, 11, 3820, 7708, 11, 645, 51336], "temperature": 0.0, "avg_logprob": -0.09100569340220668, "compression_ratio": 1.5972222222222223, "no_speech_prob": 0.0006070332019589841}, {"id": 263, "seek": 117764, "start": 1197.0800000000002, "end": 1205.48, "text": " never trained in experimental methods. We never learned about like controls and confounding things.", "tokens": [51336, 1128, 8895, 294, 17069, 7150, 13, 492, 1128, 3264, 466, 411, 9003, 293, 1497, 24625, 721, 13, 51756], "temperature": 0.0, "avg_logprob": -0.09100569340220668, "compression_ratio": 1.5972222222222223, "no_speech_prob": 0.0006070332019589841}, {"id": 264, "seek": 120548, "start": 1205.48, "end": 1218.84, "text": " It's a great point. And so now people are doing, applying human tests of understanding or intelligence", "tokens": [50364, 467, 311, 257, 869, 935, 13, 400, 370, 586, 561, 366, 884, 11, 9275, 1952, 6921, 295, 3701, 420, 7599, 51032], "temperature": 0.0, "avg_logprob": -0.13525806367397308, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.0005702669150196016}, {"id": 265, "seek": 120548, "start": 1218.84, "end": 1226.52, "text": " or reasoning, what have you, to machines without having the right experimental methods to say whether", "tokens": [51032, 420, 21577, 11, 437, 362, 291, 11, 281, 8379, 1553, 1419, 264, 558, 17069, 7150, 281, 584, 1968, 51416], "temperature": 0.0, "avg_logprob": -0.13525806367397308, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.0005702669150196016}, {"id": 266, "seek": 120548, "start": 1226.52, "end": 1233.48, "text": " or not what they're testing is actually valid. So there's a cognitive scientist named Michael", "tokens": [51416, 420, 406, 437, 436, 434, 4997, 307, 767, 7363, 13, 407, 456, 311, 257, 15605, 12662, 4926, 5116, 51764], "temperature": 0.0, "avg_logprob": -0.13525806367397308, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.0005702669150196016}, {"id": 267, "seek": 123348, "start": 1233.48, "end": 1238.76, "text": " Frank at Stanford, who's been writing a lot of stuff about experimental method and how do you", "tokens": [50364, 6823, 412, 20374, 11, 567, 311, 668, 3579, 257, 688, 295, 1507, 466, 17069, 3170, 293, 577, 360, 291, 50628], "temperature": 0.0, "avg_logprob": -0.11149773848684211, "compression_ratio": 1.596638655462185, "no_speech_prob": 0.0009107213118113577}, {"id": 268, "seek": 123348, "start": 1238.76, "end": 1248.1200000000001, "text": " apply it to AI and why you need sort of expertise in this area to really make sense of these systems.", "tokens": [50628, 3079, 309, 281, 7318, 293, 983, 291, 643, 1333, 295, 11769, 294, 341, 1859, 281, 534, 652, 2020, 295, 613, 3652, 13, 51096], "temperature": 0.0, "avg_logprob": -0.11149773848684211, "compression_ratio": 1.596638655462185, "no_speech_prob": 0.0009107213118113577}, {"id": 269, "seek": 123348, "start": 1248.1200000000001, "end": 1254.1200000000001, "text": " And I'm totally on board with that. Yeah, we'll talk about your piece with Tannenbaum later,", "tokens": [51096, 400, 286, 478, 3879, 322, 3150, 365, 300, 13, 865, 11, 321, 603, 751, 466, 428, 2522, 365, 314, 44792, 46641, 1780, 11, 51396], "temperature": 0.0, "avg_logprob": -0.11149773848684211, "compression_ratio": 1.596638655462185, "no_speech_prob": 0.0009107213118113577}, {"id": 270, "seek": 123348, "start": 1254.1200000000001, "end": 1259.24, "text": " but as you say, a lot of AI folks don't really think about experiment design. But actually,", "tokens": [51396, 457, 382, 291, 584, 11, 257, 688, 295, 7318, 4024, 500, 380, 534, 519, 466, 5120, 1715, 13, 583, 767, 11, 51652], "temperature": 0.0, "avg_logprob": -0.11149773848684211, "compression_ratio": 1.596638655462185, "no_speech_prob": 0.0009107213118113577}, {"id": 271, "seek": 125924, "start": 1259.24, "end": 1263.48, "text": " even with Chalet's ARC challenge, maybe we should talk about that. So he invented this", "tokens": [50364, 754, 365, 761, 49744, 311, 8943, 34, 3430, 11, 1310, 321, 820, 751, 466, 300, 13, 407, 415, 14479, 341, 50576], "temperature": 0.0, "avg_logprob": -0.1546032428741455, "compression_ratio": 1.6897810218978102, "no_speech_prob": 0.005405742675065994}, {"id": 272, "seek": 125924, "start": 1263.48, "end": 1268.92, "text": " measure of intelligence, which unfortunately was not computable, but it was mathematically", "tokens": [50576, 3481, 295, 7599, 11, 597, 7015, 390, 406, 2807, 712, 11, 457, 309, 390, 44003, 50848], "temperature": 0.0, "avg_logprob": -0.1546032428741455, "compression_ratio": 1.6897810218978102, "no_speech_prob": 0.005405742675065994}, {"id": 273, "seek": 125924, "start": 1268.92, "end": 1274.76, "text": " beautiful. Basically saying that, and he's a huge Spelke fan, I kind of put Chalet very,", "tokens": [50848, 2238, 13, 8537, 1566, 300, 11, 293, 415, 311, 257, 2603, 1738, 338, 330, 3429, 11, 286, 733, 295, 829, 761, 49744, 588, 11, 51140], "temperature": 0.0, "avg_logprob": -0.1546032428741455, "compression_ratio": 1.6897810218978102, "no_speech_prob": 0.005405742675065994}, {"id": 274, "seek": 125924, "start": 1274.76, "end": 1280.68, "text": " very close to you actually in AI researcher space. And his measure of intelligence basically says,", "tokens": [51140, 588, 1998, 281, 291, 767, 294, 7318, 21751, 1901, 13, 400, 702, 3481, 295, 7599, 1936, 1619, 11, 51436], "temperature": 0.0, "avg_logprob": -0.1546032428741455, "compression_ratio": 1.6897810218978102, "no_speech_prob": 0.005405742675065994}, {"id": 275, "seek": 125924, "start": 1281.32, "end": 1286.36, "text": " I give you priors, I give you experience, you give me a skill program, it extrapolates into these", "tokens": [51468, 286, 976, 291, 1790, 830, 11, 286, 976, 291, 1752, 11, 291, 976, 385, 257, 5389, 1461, 11, 309, 48224, 1024, 666, 613, 51720], "temperature": 0.0, "avg_logprob": -0.1546032428741455, "compression_ratio": 1.6897810218978102, "no_speech_prob": 0.005405742675065994}, {"id": 276, "seek": 128636, "start": 1286.36, "end": 1291.1599999999999, "text": " different spaces and experience space. And the kind of the conversion ratio between those", "tokens": [50364, 819, 7673, 293, 1752, 1901, 13, 400, 264, 733, 295, 264, 14298, 8509, 1296, 729, 50604], "temperature": 0.0, "avg_logprob": -0.09567247118268694, "compression_ratio": 1.7782101167315174, "no_speech_prob": 0.004631685093045235}, {"id": 277, "seek": 128636, "start": 1291.1599999999999, "end": 1297.0, "text": " priors and experience and the space that I get is intelligence. And that's very interesting.", "tokens": [50604, 1790, 830, 293, 1752, 293, 264, 1901, 300, 286, 483, 307, 7599, 13, 400, 300, 311, 588, 1880, 13, 50896], "temperature": 0.0, "avg_logprob": -0.09567247118268694, "compression_ratio": 1.7782101167315174, "no_speech_prob": 0.004631685093045235}, {"id": 278, "seek": 128636, "start": 1297.0, "end": 1301.8799999999999, "text": " And then he produced this corpus, this ARC challenge. And it's a bit like an IQ test. It's", "tokens": [50896, 400, 550, 415, 7126, 341, 1181, 31624, 11, 341, 8943, 34, 3430, 13, 400, 309, 311, 257, 857, 411, 364, 28921, 1500, 13, 467, 311, 51140], "temperature": 0.0, "avg_logprob": -0.09567247118268694, "compression_ratio": 1.7782101167315174, "no_speech_prob": 0.004631685093045235}, {"id": 279, "seek": 128636, "start": 1301.8799999999999, "end": 1309.0, "text": " this kind of 2D gridded colored cells. And you have a couple of examples, and you have to do", "tokens": [51140, 341, 733, 295, 568, 35, 10748, 9207, 14332, 5438, 13, 400, 291, 362, 257, 1916, 295, 5110, 11, 293, 291, 362, 281, 360, 51496], "temperature": 0.0, "avg_logprob": -0.09567247118268694, "compression_ratio": 1.7782101167315174, "no_speech_prob": 0.004631685093045235}, {"id": 280, "seek": 128636, "start": 1309.0, "end": 1313.8799999999999, "text": " another one or two examples. And it was very diverse because it was testing what he called", "tokens": [51496, 1071, 472, 420, 732, 5110, 13, 400, 309, 390, 588, 9521, 570, 309, 390, 4997, 437, 415, 1219, 51740], "temperature": 0.0, "avg_logprob": -0.09567247118268694, "compression_ratio": 1.7782101167315174, "no_speech_prob": 0.004631685093045235}, {"id": 281, "seek": 131388, "start": 1313.88, "end": 1319.4, "text": " developer aware generalization. And there were a couple of issues with that. So you wrote this", "tokens": [50364, 10754, 3650, 2674, 2144, 13, 400, 456, 645, 257, 1916, 295, 2663, 365, 300, 13, 407, 291, 4114, 341, 50640], "temperature": 0.0, "avg_logprob": -0.07261776456645891, "compression_ratio": 1.6306620209059233, "no_speech_prob": 0.0007063426310196519}, {"id": 282, "seek": 131388, "start": 1319.4, "end": 1325.3200000000002, "text": " beautiful concept ARC paper, and maybe you can introduce that. But one of the things you pointed", "tokens": [50640, 2238, 3410, 8943, 34, 3035, 11, 293, 1310, 291, 393, 5366, 300, 13, 583, 472, 295, 264, 721, 291, 10932, 50936], "temperature": 0.0, "avg_logprob": -0.07261776456645891, "compression_ratio": 1.6306620209059233, "no_speech_prob": 0.0007063426310196519}, {"id": 283, "seek": 131388, "start": 1325.3200000000002, "end": 1331.88, "text": " out, which I felt was quite interesting is that even if people succeeded on Francois's challenge,", "tokens": [50936, 484, 11, 597, 286, 2762, 390, 1596, 1880, 307, 300, 754, 498, 561, 20263, 322, 34695, 271, 311, 3430, 11, 51264], "temperature": 0.0, "avg_logprob": -0.07261776456645891, "compression_ratio": 1.6306620209059233, "no_speech_prob": 0.0007063426310196519}, {"id": 284, "seek": 131388, "start": 1331.88, "end": 1336.7600000000002, "text": " it wouldn't necessarily be what we would call intelligence, because it's not necessarily", "tokens": [51264, 309, 2759, 380, 4725, 312, 437, 321, 576, 818, 7599, 11, 570, 309, 311, 406, 4725, 51508], "temperature": 0.0, "avg_logprob": -0.07261776456645891, "compression_ratio": 1.6306620209059233, "no_speech_prob": 0.0007063426310196519}, {"id": 285, "seek": 131388, "start": 1336.7600000000002, "end": 1342.1200000000001, "text": " demonstrating systematic generalization beyond those one or two examples in his test set.", "tokens": [51508, 29889, 27249, 2674, 2144, 4399, 729, 472, 420, 732, 5110, 294, 702, 1500, 992, 13, 51776], "temperature": 0.0, "avg_logprob": -0.07261776456645891, "compression_ratio": 1.6306620209059233, "no_speech_prob": 0.0007063426310196519}, {"id": 286, "seek": 134212, "start": 1342.6, "end": 1350.9199999999998, "text": " So our motivation was twofold. So first of all, I love the ARC challenge. It's beautiful.", "tokens": [50388, 407, 527, 12335, 390, 732, 18353, 13, 407, 700, 295, 439, 11, 286, 959, 264, 8943, 34, 3430, 13, 467, 311, 2238, 13, 50804], "temperature": 0.0, "avg_logprob": -0.18151904597426904, "compression_ratio": 1.398936170212766, "no_speech_prob": 0.00037983781658113003}, {"id": 287, "seek": 134212, "start": 1351.8799999999999, "end": 1363.32, "text": " It's super elegant. And I'm very sympathetic with Francois' definition of intelligence,", "tokens": [50852, 467, 311, 1687, 21117, 13, 400, 286, 478, 588, 36032, 365, 34695, 271, 6, 7123, 295, 7599, 11, 51424], "temperature": 0.0, "avg_logprob": -0.18151904597426904, "compression_ratio": 1.398936170212766, "no_speech_prob": 0.00037983781658113003}, {"id": 288, "seek": 134212, "start": 1363.32, "end": 1369.08, "text": " although I think there's probably, again, intelligence is very multi-dimensional. But", "tokens": [51424, 4878, 286, 519, 456, 311, 1391, 11, 797, 11, 7599, 307, 588, 4825, 12, 18759, 13, 583, 51712], "temperature": 0.0, "avg_logprob": -0.18151904597426904, "compression_ratio": 1.398936170212766, "no_speech_prob": 0.00037983781658113003}, {"id": 289, "seek": 136908, "start": 1369.1599999999999, "end": 1375.3999999999999, "text": " this is one aspect of it for sure. And his problems are great because they", "tokens": [50368, 341, 307, 472, 4171, 295, 309, 337, 988, 13, 400, 702, 2740, 366, 869, 570, 436, 50680], "temperature": 0.0, "avg_logprob": -0.09190231381040631, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00497839879244566}, {"id": 290, "seek": 136908, "start": 1376.1999999999998, "end": 1382.6, "text": " just give a few examples, and people are pretty good at abstracting a rule or a concept from", "tokens": [50720, 445, 976, 257, 1326, 5110, 11, 293, 561, 366, 1238, 665, 412, 12649, 278, 257, 4978, 420, 257, 3410, 490, 51040], "temperature": 0.0, "avg_logprob": -0.09190231381040631, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00497839879244566}, {"id": 291, "seek": 136908, "start": 1382.6, "end": 1391.0, "text": " just a few examples. And they don't use language, so they don't get into the whole prior knowledge", "tokens": [51040, 445, 257, 1326, 5110, 13, 400, 436, 500, 380, 764, 2856, 11, 370, 436, 500, 380, 483, 666, 264, 1379, 4059, 3601, 51460], "temperature": 0.0, "avg_logprob": -0.09190231381040631, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00497839879244566}, {"id": 292, "seek": 139100, "start": 1391.0, "end": 1401.72, "text": " of language and a lot of things that you don't want to confound these tests. But one of the", "tokens": [50364, 295, 2856, 293, 257, 688, 295, 721, 300, 291, 500, 380, 528, 281, 1497, 554, 613, 6921, 13, 583, 472, 295, 264, 50900], "temperature": 0.0, "avg_logprob": -0.06364952434193004, "compression_ratio": 1.6407185628742516, "no_speech_prob": 0.007934710010886192}, {"id": 293, "seek": 139100, "start": 1401.72, "end": 1406.6, "text": " problems with ARC is that many of the problems are quite hard. They're quite hard for people.", "tokens": [50900, 2740, 365, 8943, 34, 307, 300, 867, 295, 264, 2740, 366, 1596, 1152, 13, 814, 434, 1596, 1152, 337, 561, 13, 51144], "temperature": 0.0, "avg_logprob": -0.06364952434193004, "compression_ratio": 1.6407185628742516, "no_speech_prob": 0.007934710010886192}, {"id": 294, "seek": 139100, "start": 1407.32, "end": 1415.72, "text": " And they're so hard that they don't really differentiate between different programs that", "tokens": [51180, 400, 436, 434, 370, 1152, 300, 436, 500, 380, 534, 23203, 1296, 819, 4268, 300, 51600], "temperature": 0.0, "avg_logprob": -0.06364952434193004, "compression_ratio": 1.6407185628742516, "no_speech_prob": 0.007934710010886192}, {"id": 295, "seek": 141572, "start": 1415.72, "end": 1422.1200000000001, "text": " are attempting to solve this challenge. So there was a Kaggle competition with the ARC challenge,", "tokens": [50364, 366, 22001, 281, 5039, 341, 3430, 13, 407, 456, 390, 257, 48751, 22631, 6211, 365, 264, 8943, 34, 3430, 11, 50684], "temperature": 0.0, "avg_logprob": -0.0950509888785226, "compression_ratio": 1.5106382978723405, "no_speech_prob": 0.0036479062400758266}, {"id": 296, "seek": 141572, "start": 1422.1200000000001, "end": 1430.3600000000001, "text": " and there were two, the two best programs got about, they each got about 20% accuracy on the", "tokens": [50684, 293, 456, 645, 732, 11, 264, 732, 1151, 4268, 658, 466, 11, 436, 1184, 658, 466, 945, 4, 14170, 322, 264, 51096], "temperature": 0.0, "avg_logprob": -0.0950509888785226, "compression_ratio": 1.5106382978723405, "no_speech_prob": 0.0036479062400758266}, {"id": 297, "seek": 141572, "start": 1430.3600000000001, "end": 1440.3600000000001, "text": " hidden test set. So it didn't really distinguish them at all. And the other problem was that,", "tokens": [51096, 7633, 1500, 992, 13, 407, 309, 994, 380, 534, 20206, 552, 412, 439, 13, 400, 264, 661, 1154, 390, 300, 11, 51596], "temperature": 0.0, "avg_logprob": -0.0950509888785226, "compression_ratio": 1.5106382978723405, "no_speech_prob": 0.0036479062400758266}, {"id": 298, "seek": 144036, "start": 1441.32, "end": 1446.84, "text": " as you mentioned, the test wasn't very systematic, meaning that let's say there's a", "tokens": [50412, 382, 291, 2835, 11, 264, 1500, 2067, 380, 588, 27249, 11, 3620, 300, 718, 311, 584, 456, 311, 257, 50688], "temperature": 0.0, "avg_logprob": -0.06465273760677723, "compression_ratio": 1.7149532710280373, "no_speech_prob": 0.0019261008128523827}, {"id": 299, "seek": 144036, "start": 1447.6399999999999, "end": 1453.8799999999999, "text": " problem in ARC that deals with the concept of inside, something being inside something else.", "tokens": [50728, 1154, 294, 8943, 34, 300, 11215, 365, 264, 3410, 295, 1854, 11, 746, 885, 1854, 746, 1646, 13, 51040], "temperature": 0.0, "avg_logprob": -0.06465273760677723, "compression_ratio": 1.7149532710280373, "no_speech_prob": 0.0019261008128523827}, {"id": 300, "seek": 144036, "start": 1453.8799999999999, "end": 1459.8, "text": " And let's say that something, a program gets that one right. Does that mean that it understands", "tokens": [51040, 400, 718, 311, 584, 300, 746, 11, 257, 1461, 2170, 300, 472, 558, 13, 4402, 300, 914, 300, 309, 15146, 51336], "temperature": 0.0, "avg_logprob": -0.06465273760677723, "compression_ratio": 1.7149532710280373, "no_speech_prob": 0.0019261008128523827}, {"id": 301, "seek": 144036, "start": 1459.8, "end": 1466.52, "text": " the concept of inside in a general way? Well, we don't know because the test doesn't test that", "tokens": [51336, 264, 3410, 295, 1854, 294, 257, 2674, 636, 30, 1042, 11, 321, 500, 380, 458, 570, 264, 1500, 1177, 380, 1500, 300, 51672], "temperature": 0.0, "avg_logprob": -0.06465273760677723, "compression_ratio": 1.7149532710280373, "no_speech_prob": 0.0019261008128523827}, {"id": 302, "seek": 146652, "start": 1466.52, "end": 1474.68, "text": " systematically. And that was actually intentional from Sholey, because he didn't want any way to,", "tokens": [50364, 39531, 13, 400, 300, 390, 767, 21935, 490, 31404, 3420, 11, 570, 415, 994, 380, 528, 604, 636, 281, 11, 50772], "temperature": 0.0, "avg_logprob": -0.1042130396916316, "compression_ratio": 1.4473684210526316, "no_speech_prob": 0.004465547855943441}, {"id": 303, "seek": 146652, "start": 1475.4, "end": 1482.92, "text": " for programs to be able to reverse engineer the generation process of these problems.", "tokens": [50808, 337, 4268, 281, 312, 1075, 281, 9943, 11403, 264, 5125, 1399, 295, 613, 2740, 13, 51184], "temperature": 0.0, "avg_logprob": -0.1042130396916316, "compression_ratio": 1.4473684210526316, "no_speech_prob": 0.004465547855943441}, {"id": 304, "seek": 146652, "start": 1482.92, "end": 1488.6, "text": " So if you say, oh, well, I'm going to deal with these 10 concepts, then somebody presumably", "tokens": [51184, 407, 498, 291, 584, 11, 1954, 11, 731, 11, 286, 478, 516, 281, 2028, 365, 613, 1266, 10392, 11, 550, 2618, 26742, 51468], "temperature": 0.0, "avg_logprob": -0.1042130396916316, "compression_ratio": 1.4473684210526316, "no_speech_prob": 0.004465547855943441}, {"id": 305, "seek": 148860, "start": 1488.6, "end": 1496.4399999999998, "text": " could reverse engineer those, the problems and not be general. But for us, we wanted to say, well,", "tokens": [50364, 727, 9943, 11403, 729, 11, 264, 2740, 293, 406, 312, 2674, 13, 583, 337, 505, 11, 321, 1415, 281, 584, 11, 731, 11, 50756], "temperature": 0.0, "avg_logprob": -0.08748402481987363, "compression_ratio": 1.5974025974025974, "no_speech_prob": 0.0011693367268890142}, {"id": 306, "seek": 148860, "start": 1496.4399999999998, "end": 1502.1999999999998, "text": " how would you just systematically test a program for understanding of a concept of a very basic,", "tokens": [50756, 577, 576, 291, 445, 39531, 1500, 257, 1461, 337, 3701, 295, 257, 3410, 295, 257, 588, 3875, 11, 51044], "temperature": 0.0, "avg_logprob": -0.08748402481987363, "compression_ratio": 1.5974025974025974, "no_speech_prob": 0.0011693367268890142}, {"id": 307, "seek": 148860, "start": 1502.1999999999998, "end": 1508.4399999999998, "text": " spatial or semantic concept? And so what we did was we took the ARC domain and we created", "tokens": [51044, 23598, 420, 47982, 3410, 30, 400, 370, 437, 321, 630, 390, 321, 1890, 264, 8943, 34, 9274, 293, 321, 2942, 51356], "temperature": 0.0, "avg_logprob": -0.08748402481987363, "compression_ratio": 1.5974025974025974, "no_speech_prob": 0.0011693367268890142}, {"id": 308, "seek": 148860, "start": 1509.56, "end": 1517.32, "text": " about almost 500 new problems that were systematically grouped into concept groups.", "tokens": [51412, 466, 1920, 5923, 777, 2740, 300, 645, 39531, 41877, 666, 3410, 3935, 13, 51800], "temperature": 0.0, "avg_logprob": -0.08748402481987363, "compression_ratio": 1.5974025974025974, "no_speech_prob": 0.0011693367268890142}, {"id": 309, "seek": 151732, "start": 1517.32, "end": 1524.4399999999998, "text": " So like inside of, that was one of the groups. And so we looked at, we created several problems", "tokens": [50364, 407, 411, 1854, 295, 11, 300, 390, 472, 295, 264, 3935, 13, 400, 370, 321, 2956, 412, 11, 321, 2942, 2940, 2740, 50720], "temperature": 0.0, "avg_logprob": -0.11631648468248772, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.00013550338917411864}, {"id": 310, "seek": 151732, "start": 1524.4399999999998, "end": 1531.56, "text": " that were variations on that concept. And there were variations that ranged in like abstraction,", "tokens": [50720, 300, 645, 17840, 322, 300, 3410, 13, 400, 456, 645, 17840, 300, 45570, 294, 411, 37765, 11, 51076], "temperature": 0.0, "avg_logprob": -0.11631648468248772, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.00013550338917411864}, {"id": 311, "seek": 151732, "start": 1531.56, "end": 1541.08, "text": " degree of abstraction, and sort of complexity of the problem. And the hypothesis was that if a", "tokens": [51076, 4314, 295, 37765, 11, 293, 1333, 295, 14024, 295, 264, 1154, 13, 400, 264, 17291, 390, 300, 498, 257, 51552], "temperature": 0.0, "avg_logprob": -0.11631648468248772, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.00013550338917411864}, {"id": 312, "seek": 154108, "start": 1541.72, "end": 1549.8799999999999, "text": " human or a program could successfully solve the problems in a given concept group, they really", "tokens": [50396, 1952, 420, 257, 1461, 727, 10727, 5039, 264, 2740, 294, 257, 2212, 3410, 1594, 11, 436, 534, 50804], "temperature": 0.0, "avg_logprob": -0.105534302009331, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.0003053339896723628}, {"id": 313, "seek": 154108, "start": 1549.8799999999999, "end": 1557.08, "text": " do have a good sort of grasp of that concept. So this was the genesis of concept ARC.", "tokens": [50804, 360, 362, 257, 665, 1333, 295, 21743, 295, 300, 3410, 13, 407, 341, 390, 264, 1049, 9374, 295, 3410, 8943, 34, 13, 51164], "temperature": 0.0, "avg_logprob": -0.105534302009331, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.0003053339896723628}, {"id": 314, "seek": 154108, "start": 1558.1999999999998, "end": 1563.1599999999999, "text": " You know, it's fascinating because so you're, you're attempting again to build the science of", "tokens": [51220, 509, 458, 11, 309, 311, 10343, 570, 370, 291, 434, 11, 291, 434, 22001, 797, 281, 1322, 264, 3497, 295, 51468], "temperature": 0.0, "avg_logprob": -0.105534302009331, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.0003053339896723628}, {"id": 315, "seek": 154108, "start": 1563.96, "end": 1568.6, "text": " machine cognitive science, essentially. And hey, it has to be systematized, we need to have these", "tokens": [51508, 3479, 15605, 3497, 11, 4476, 13, 400, 4177, 11, 309, 575, 281, 312, 1185, 267, 1602, 11, 321, 643, 281, 362, 613, 51740], "temperature": 0.0, "avg_logprob": -0.105534302009331, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.0003053339896723628}, {"id": 316, "seek": 156860, "start": 1568.6, "end": 1574.28, "text": " concept categories, we need to be able to generate examples of progressive complexity and, you know,", "tokens": [50364, 3410, 10479, 11, 321, 643, 281, 312, 1075, 281, 8460, 5110, 295, 16131, 14024, 293, 11, 291, 458, 11, 50648], "temperature": 0.0, "avg_logprob": -0.10182868733125575, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.0012842136202380061}, {"id": 317, "seek": 156860, "start": 1574.28, "end": 1579.08, "text": " layer of abstraction, everything. And then yet you mentioned Chalet intentionally didn't", "tokens": [50648, 4583, 295, 37765, 11, 1203, 13, 400, 550, 1939, 291, 2835, 761, 49744, 22062, 994, 380, 50888], "temperature": 0.0, "avg_logprob": -0.10182868733125575, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.0012842136202380061}, {"id": 318, "seek": 156860, "start": 1579.08, "end": 1582.84, "text": " systematize it to avoid reverse engineering. And that's kind of a fascinating", "tokens": [50888, 1185, 267, 1125, 309, 281, 5042, 9943, 7043, 13, 400, 300, 311, 733, 295, 257, 10343, 51076], "temperature": 0.0, "avg_logprob": -0.10182868733125575, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.0012842136202380061}, {"id": 319, "seek": 156860, "start": 1583.48, "end": 1589.48, "text": " point because reverse engineering can even happen, you know, just by way of selection bias. So I mean,", "tokens": [51108, 935, 570, 9943, 7043, 393, 754, 1051, 11, 291, 458, 11, 445, 538, 636, 295, 9450, 12577, 13, 407, 286, 914, 11, 51408], "temperature": 0.0, "avg_logprob": -0.10182868733125575, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.0012842136202380061}, {"id": 320, "seek": 156860, "start": 1589.48, "end": 1593.9599999999998, "text": " researchers are out there, they're fooling around with different neural network structures, maybe", "tokens": [51408, 10309, 366, 484, 456, 11, 436, 434, 7979, 278, 926, 365, 819, 18161, 3209, 9227, 11, 1310, 51632], "temperature": 0.0, "avg_logprob": -0.10182868733125575, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.0012842136202380061}, {"id": 321, "seek": 159396, "start": 1593.96, "end": 1599.16, "text": " I'll add like a you here or some horseshoe over there. And lo and behold, suddenly, it works", "tokens": [50364, 286, 603, 909, 411, 257, 291, 510, 420, 512, 13112, 33810, 670, 456, 13, 400, 450, 293, 27234, 11, 5800, 11, 309, 1985, 50624], "temperature": 0.0, "avg_logprob": -0.07749280358991052, "compression_ratio": 1.7481203007518797, "no_speech_prob": 0.007575713563710451}, {"id": 322, "seek": 159396, "start": 1599.16, "end": 1604.44, "text": " really well on the concept of inside out. And I'm going to claim this is machine learning,", "tokens": [50624, 534, 731, 322, 264, 3410, 295, 1854, 484, 13, 400, 286, 478, 516, 281, 3932, 341, 307, 3479, 2539, 11, 50888], "temperature": 0.0, "avg_logprob": -0.07749280358991052, "compression_ratio": 1.7481203007518797, "no_speech_prob": 0.007575713563710451}, {"id": 323, "seek": 159396, "start": 1604.44, "end": 1609.32, "text": " even though it was actually human engineering that sort of put that structure into the network.", "tokens": [50888, 754, 1673, 309, 390, 767, 1952, 7043, 300, 1333, 295, 829, 300, 3877, 666, 264, 3209, 13, 51132], "temperature": 0.0, "avg_logprob": -0.07749280358991052, "compression_ratio": 1.7481203007518797, "no_speech_prob": 0.007575713563710451}, {"id": 324, "seek": 159396, "start": 1609.32, "end": 1614.44, "text": " So in the long term, you know, how do we, how do we balance that? Or how do we avoid it? Or how do", "tokens": [51132, 407, 294, 264, 938, 1433, 11, 291, 458, 11, 577, 360, 321, 11, 577, 360, 321, 4772, 300, 30, 1610, 577, 360, 321, 5042, 309, 30, 1610, 577, 360, 51388], "temperature": 0.0, "avg_logprob": -0.07749280358991052, "compression_ratio": 1.7481203007518797, "no_speech_prob": 0.007575713563710451}, {"id": 325, "seek": 159396, "start": 1614.44, "end": 1620.52, "text": " we test for machine induced, you know, prior knowledge versus actual machine learning?", "tokens": [51388, 321, 1500, 337, 3479, 33991, 11, 291, 458, 11, 4059, 3601, 5717, 3539, 3479, 2539, 30, 51692], "temperature": 0.0, "avg_logprob": -0.07749280358991052, "compression_ratio": 1.7481203007518797, "no_speech_prob": 0.007575713563710451}, {"id": 326, "seek": 162052, "start": 1621.48, "end": 1630.44, "text": " Yeah, no, I understand it's a hard problem. And I think, you know, the goal with this concept arc", "tokens": [50412, 865, 11, 572, 11, 286, 1223, 309, 311, 257, 1152, 1154, 13, 400, 286, 519, 11, 291, 458, 11, 264, 3387, 365, 341, 3410, 10346, 50860], "temperature": 0.0, "avg_logprob": -0.16488868713378907, "compression_ratio": 1.5052631578947369, "no_speech_prob": 0.0021823288407176733}, {"id": 327, "seek": 162052, "start": 1631.72, "end": 1637.56, "text": " benchmark wasn't to sort of supplant arc in any way, it was really meant to be complementary.", "tokens": [50924, 18927, 2067, 380, 281, 1333, 295, 9386, 394, 10346, 294, 604, 636, 11, 309, 390, 534, 4140, 281, 312, 40705, 13, 51216], "temperature": 0.0, "avg_logprob": -0.16488868713378907, "compression_ratio": 1.5052631578947369, "no_speech_prob": 0.0021823288407176733}, {"id": 328, "seek": 162052, "start": 1638.2, "end": 1647.48, "text": " And it was meant to be kind of a stepping stone to the much larger and more difficult arc set.", "tokens": [51248, 400, 309, 390, 4140, 281, 312, 733, 295, 257, 16821, 7581, 281, 264, 709, 4833, 293, 544, 2252, 10346, 992, 13, 51712], "temperature": 0.0, "avg_logprob": -0.16488868713378907, "compression_ratio": 1.5052631578947369, "no_speech_prob": 0.0021823288407176733}, {"id": 329, "seek": 164748, "start": 1648.04, "end": 1652.76, "text": " Because I think, you know, even if I tell you all of these problems have to do with", "tokens": [50392, 1436, 286, 519, 11, 291, 458, 11, 754, 498, 286, 980, 291, 439, 295, 613, 2740, 362, 281, 360, 365, 50628], "temperature": 0.0, "avg_logprob": -0.0730378483280991, "compression_ratio": 1.5930232558139534, "no_speech_prob": 0.0014548789476975799}, {"id": 330, "seek": 164748, "start": 1652.76, "end": 1661.24, "text": " the concept of inside versus outside, you would still have to have a good grasp of those concepts", "tokens": [50628, 264, 3410, 295, 1854, 5717, 2380, 11, 291, 576, 920, 362, 281, 362, 257, 665, 21743, 295, 729, 10392, 51052], "temperature": 0.0, "avg_logprob": -0.0730378483280991, "compression_ratio": 1.5930232558139534, "no_speech_prob": 0.0014548789476975799}, {"id": 331, "seek": 164748, "start": 1661.24, "end": 1668.6, "text": " in order to solve these problems. And I'm not sure that you could sort of engineer something", "tokens": [51052, 294, 1668, 281, 5039, 613, 2740, 13, 400, 286, 478, 406, 988, 300, 291, 727, 1333, 295, 11403, 746, 51420], "temperature": 0.0, "avg_logprob": -0.0730378483280991, "compression_ratio": 1.5930232558139534, "no_speech_prob": 0.0014548789476975799}, {"id": 332, "seek": 166860, "start": 1669.1599999999999, "end": 1677.32, "text": " that would solve those cons problems of that concept in general, without having a more,", "tokens": [50392, 300, 576, 5039, 729, 1014, 2740, 295, 300, 3410, 294, 2674, 11, 1553, 1419, 257, 544, 11, 50800], "temperature": 0.0, "avg_logprob": -0.16198798756540558, "compression_ratio": 1.610091743119266, "no_speech_prob": 0.051064930856227875}, {"id": 333, "seek": 166860, "start": 1677.32, "end": 1681.48, "text": " you know, really a general understanding in some sense of those that concept.", "tokens": [50800, 291, 458, 11, 534, 257, 2674, 3701, 294, 512, 2020, 295, 729, 300, 3410, 13, 51008], "temperature": 0.0, "avg_logprob": -0.16198798756540558, "compression_ratio": 1.610091743119266, "no_speech_prob": 0.051064930856227875}, {"id": 334, "seek": 166860, "start": 1682.12, "end": 1690.52, "text": " But to Keith's your point, I think having a static benchmark is a problem, sort of putting out a", "tokens": [51040, 583, 281, 20613, 311, 428, 935, 11, 286, 519, 1419, 257, 13437, 18927, 307, 257, 1154, 11, 1333, 295, 3372, 484, 257, 51460], "temperature": 0.0, "avg_logprob": -0.16198798756540558, "compression_ratio": 1.610091743119266, "no_speech_prob": 0.051064930856227875}, {"id": 335, "seek": 166860, "start": 1690.52, "end": 1697.6399999999999, "text": " benchmark that everybody can kind of try and optimize their program to solve. We've seen", "tokens": [51460, 18927, 300, 2201, 393, 733, 295, 853, 293, 19719, 641, 1461, 281, 5039, 13, 492, 600, 1612, 51816], "temperature": 0.0, "avg_logprob": -0.16198798756540558, "compression_ratio": 1.610091743119266, "no_speech_prob": 0.051064930856227875}, {"id": 336, "seek": 169764, "start": 1697.64, "end": 1707.8000000000002, "text": " that over and over again. That ends up being sort of a way that people end up reverse engineering", "tokens": [50364, 300, 670, 293, 670, 797, 13, 663, 5314, 493, 885, 1333, 295, 257, 636, 300, 561, 917, 493, 9943, 7043, 50872], "temperature": 0.0, "avg_logprob": -0.09339814399605367, "compression_ratio": 1.4919786096256684, "no_speech_prob": 0.004608309827744961}, {"id": 337, "seek": 169764, "start": 1708.68, "end": 1716.1200000000001, "text": " to a particular task rather than to a more general set of conceptual understanding. So", "tokens": [50916, 281, 257, 1729, 5633, 2831, 813, 281, 257, 544, 2674, 992, 295, 24106, 3701, 13, 407, 51288], "temperature": 0.0, "avg_logprob": -0.09339814399605367, "compression_ratio": 1.4919786096256684, "no_speech_prob": 0.004608309827744961}, {"id": 338, "seek": 169764, "start": 1716.1200000000001, "end": 1722.3600000000001, "text": " I do think that we have to keep changing our benchmarks. We can't just say, okay, here's image", "tokens": [51288, 286, 360, 519, 300, 321, 362, 281, 1066, 4473, 527, 43751, 13, 492, 393, 380, 445, 584, 11, 1392, 11, 510, 311, 3256, 51600], "temperature": 0.0, "avg_logprob": -0.09339814399605367, "compression_ratio": 1.4919786096256684, "no_speech_prob": 0.004608309827744961}, {"id": 339, "seek": 172236, "start": 1722.36, "end": 1729.1599999999999, "text": " net, go, you know, beat on that for the next 20 years until you've solved it.", "tokens": [50364, 2533, 11, 352, 11, 291, 458, 11, 4224, 322, 300, 337, 264, 958, 945, 924, 1826, 291, 600, 13041, 309, 13, 50704], "temperature": 0.0, "avg_logprob": -0.10833646718738149, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.017935415729880333}, {"id": 340, "seek": 172236, "start": 1729.7199999999998, "end": 1732.76, "text": " That's not going to yield general intelligence.", "tokens": [50732, 663, 311, 406, 516, 281, 11257, 2674, 7599, 13, 50884], "temperature": 0.0, "avg_logprob": -0.10833646718738149, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.017935415729880333}, {"id": 341, "seek": 172236, "start": 1733.8799999999999, "end": 1738.52, "text": " Yeah, I think one of the issues we're talking about in general is extrapolation. So, you know,", "tokens": [50940, 865, 11, 286, 519, 472, 295, 264, 2663, 321, 434, 1417, 466, 294, 2674, 307, 48224, 399, 13, 407, 11, 291, 458, 11, 51172], "temperature": 0.0, "avg_logprob": -0.10833646718738149, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.017935415729880333}, {"id": 342, "seek": 172236, "start": 1738.52, "end": 1744.9199999999998, "text": " Sholey used extrapolation to talk about skill programs and being able to do things beyond", "tokens": [51172, 31404, 3420, 1143, 48224, 399, 281, 751, 466, 5389, 4268, 293, 885, 1075, 281, 360, 721, 4399, 51492], "temperature": 0.0, "avg_logprob": -0.10833646718738149, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.017935415729880333}, {"id": 343, "seek": 172236, "start": 1744.9199999999998, "end": 1751.0, "text": " your priors and experience. But with benchmarks, it's about human extrapolation. So I think part", "tokens": [51492, 428, 1790, 830, 293, 1752, 13, 583, 365, 43751, 11, 309, 311, 466, 1952, 48224, 399, 13, 407, 286, 519, 644, 51796], "temperature": 0.0, "avg_logprob": -0.10833646718738149, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.017935415729880333}, {"id": 344, "seek": 175100, "start": 1751.08, "end": 1755.56, "text": " of the problem with the risk debate, by the way, why everyone's so suddenly worried about risk is", "tokens": [50368, 295, 264, 1154, 365, 264, 3148, 7958, 11, 538, 264, 636, 11, 983, 1518, 311, 370, 5800, 5804, 466, 3148, 307, 50592], "temperature": 0.0, "avg_logprob": -0.08051489995530814, "compression_ratio": 1.839080459770115, "no_speech_prob": 0.0026567825116217136}, {"id": 345, "seek": 175100, "start": 1755.56, "end": 1761.56, "text": " because of this benchmark problem. And that's because we see that humans who can do A can do", "tokens": [50592, 570, 295, 341, 18927, 1154, 13, 400, 300, 311, 570, 321, 536, 300, 6255, 567, 393, 360, 316, 393, 360, 50892], "temperature": 0.0, "avg_logprob": -0.08051489995530814, "compression_ratio": 1.839080459770115, "no_speech_prob": 0.0026567825116217136}, {"id": 346, "seek": 175100, "start": 1761.56, "end": 1767.8, "text": " B. And now we see machines that can do A. And we have all of these built-in assumptions in", "tokens": [50892, 363, 13, 400, 586, 321, 536, 8379, 300, 393, 360, 316, 13, 400, 321, 362, 439, 295, 613, 3094, 12, 259, 17695, 294, 51204], "temperature": 0.0, "avg_logprob": -0.08051489995530814, "compression_ratio": 1.839080459770115, "no_speech_prob": 0.0026567825116217136}, {"id": 347, "seek": 175100, "start": 1767.8, "end": 1772.36, "text": " benchmarks. And we don't really realize that we're talking about machines now. We're not talking", "tokens": [51204, 43751, 13, 400, 321, 500, 380, 534, 4325, 300, 321, 434, 1417, 466, 8379, 586, 13, 492, 434, 406, 1417, 51432], "temperature": 0.0, "avg_logprob": -0.08051489995530814, "compression_ratio": 1.839080459770115, "no_speech_prob": 0.0026567825116217136}, {"id": 348, "seek": 175100, "start": 1772.36, "end": 1778.44, "text": " about computers anymore. And I think it's causing a real problem. I don't want to be hyperbolic here,", "tokens": [51432, 466, 10807, 3602, 13, 400, 286, 519, 309, 311, 9853, 257, 957, 1154, 13, 286, 500, 380, 528, 281, 312, 9848, 65, 7940, 510, 11, 51736], "temperature": 0.0, "avg_logprob": -0.08051489995530814, "compression_ratio": 1.839080459770115, "no_speech_prob": 0.0026567825116217136}, {"id": 349, "seek": 177844, "start": 1778.44, "end": 1784.28, "text": " but it feels like there's this massive delusion taking over the entire machine learning community.", "tokens": [50364, 457, 309, 3417, 411, 456, 311, 341, 5994, 1103, 5704, 1940, 670, 264, 2302, 3479, 2539, 1768, 13, 50656], "temperature": 0.0, "avg_logprob": -0.08595327584140272, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.0003458314167801291}, {"id": 350, "seek": 177844, "start": 1784.28, "end": 1789.56, "text": " And we're seriously talking about AI risk. And I think it all comes down to these", "tokens": [50656, 400, 321, 434, 6638, 1417, 466, 7318, 3148, 13, 400, 286, 519, 309, 439, 1487, 760, 281, 613, 50920], "temperature": 0.0, "avg_logprob": -0.08595327584140272, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.0003458314167801291}, {"id": 351, "seek": 177844, "start": 1789.56, "end": 1797.16, "text": " benchmarks fundamentally. Yeah, I do think all of our benchmarks have, as you say,", "tokens": [50920, 43751, 17879, 13, 865, 11, 286, 360, 519, 439, 295, 527, 43751, 362, 11, 382, 291, 584, 11, 51300], "temperature": 0.0, "avg_logprob": -0.08595327584140272, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.0003458314167801291}, {"id": 352, "seek": 177844, "start": 1797.16, "end": 1805.3200000000002, "text": " have this problem of that they have assumptions built in that if a human could do this, that", "tokens": [51300, 362, 341, 1154, 295, 300, 436, 362, 17695, 3094, 294, 300, 498, 257, 1952, 727, 360, 341, 11, 300, 51708], "temperature": 0.0, "avg_logprob": -0.08595327584140272, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.0003458314167801291}, {"id": 353, "seek": 180532, "start": 1805.32, "end": 1809.72, "text": " then the machine must, if the machine does it, it has the same kind of", "tokens": [50364, 550, 264, 3479, 1633, 11, 498, 264, 3479, 775, 309, 11, 309, 575, 264, 912, 733, 295, 50584], "temperature": 0.0, "avg_logprob": -0.11964853243394331, "compression_ratio": 1.6451612903225807, "no_speech_prob": 0.00035693543031811714}, {"id": 354, "seek": 180532, "start": 1812.04, "end": 1817.8799999999999, "text": " generalization capacity as a human who could solve that problem. This goes back all the way to say", "tokens": [50700, 2674, 2144, 6042, 382, 257, 1952, 567, 727, 5039, 300, 1154, 13, 639, 1709, 646, 439, 264, 636, 281, 584, 50992], "temperature": 0.0, "avg_logprob": -0.11964853243394331, "compression_ratio": 1.6451612903225807, "no_speech_prob": 0.00035693543031811714}, {"id": 355, "seek": 180532, "start": 1819.6399999999999, "end": 1827.48, "text": " chess as a benchmark. So people used to think that if, because if a human can play chess at a", "tokens": [51080, 24122, 382, 257, 18927, 13, 407, 561, 1143, 281, 519, 300, 498, 11, 570, 498, 257, 1952, 393, 862, 24122, 412, 257, 51472], "temperature": 0.0, "avg_logprob": -0.11964853243394331, "compression_ratio": 1.6451612903225807, "no_speech_prob": 0.00035693543031811714}, {"id": 356, "seek": 180532, "start": 1827.48, "end": 1834.28, "text": " grandmaster level, that means they must be super intelligent in other ways, that if a machine", "tokens": [51472, 2697, 21640, 1496, 11, 300, 1355, 436, 1633, 312, 1687, 13232, 294, 661, 2098, 11, 300, 498, 257, 3479, 51812], "temperature": 0.0, "avg_logprob": -0.11964853243394331, "compression_ratio": 1.6451612903225807, "no_speech_prob": 0.00035693543031811714}, {"id": 357, "seek": 183428, "start": 1834.28, "end": 1840.92, "text": " could play chess at that level, it would also be super intelligent like a human. Herbert Simon", "tokens": [50364, 727, 862, 24122, 412, 300, 1496, 11, 309, 576, 611, 312, 1687, 13232, 411, 257, 1952, 13, 41942, 13193, 50696], "temperature": 0.0, "avg_logprob": -0.06951066219445431, "compression_ratio": 1.4973262032085561, "no_speech_prob": 0.00035688187927007675}, {"id": 358, "seek": 183428, "start": 1840.92, "end": 1848.12, "text": " even said that explicitly. But then we saw that chess actually could be conquered by very", "tokens": [50696, 754, 848, 300, 20803, 13, 583, 550, 321, 1866, 300, 24122, 767, 727, 312, 32695, 538, 588, 51056], "temperature": 0.0, "avg_logprob": -0.06951066219445431, "compression_ratio": 1.4973262032085561, "no_speech_prob": 0.00035688187927007675}, {"id": 359, "seek": 183428, "start": 1848.12, "end": 1857.8, "text": " unintelligent brute force search that didn't generalize in any way. So I think this is an issue", "tokens": [51056, 517, 20761, 25002, 47909, 3464, 3164, 300, 994, 380, 2674, 1125, 294, 604, 636, 13, 407, 286, 519, 341, 307, 364, 2734, 51540], "temperature": 0.0, "avg_logprob": -0.06951066219445431, "compression_ratio": 1.4973262032085561, "no_speech_prob": 0.00035688187927007675}, {"id": 360, "seek": 185780, "start": 1857.8, "end": 1865.48, "text": " today with large language models. They can do things like pass the bar exam and pass other", "tokens": [50364, 965, 365, 2416, 2856, 5245, 13, 814, 393, 360, 721, 411, 1320, 264, 2159, 1139, 293, 1320, 661, 50748], "temperature": 0.0, "avg_logprob": -0.09323041211991083, "compression_ratio": 1.5708154506437768, "no_speech_prob": 0.0032681503798812628}, {"id": 361, "seek": 185780, "start": 1866.12, "end": 1874.36, "text": " standardized human tests of skill or intelligence. But what does that mean? It doesn't necessarily", "tokens": [50780, 31677, 1952, 6921, 295, 5389, 420, 7599, 13, 583, 437, 775, 300, 914, 30, 467, 1177, 380, 4725, 51192], "temperature": 0.0, "avg_logprob": -0.09323041211991083, "compression_ratio": 1.5708154506437768, "no_speech_prob": 0.0032681503798812628}, {"id": 362, "seek": 185780, "start": 1874.36, "end": 1878.12, "text": " mean the same thing for a machine as it does for a human for many different reasons.", "tokens": [51192, 914, 264, 912, 551, 337, 257, 3479, 382, 309, 775, 337, 257, 1952, 337, 867, 819, 4112, 13, 51380], "temperature": 0.0, "avg_logprob": -0.09323041211991083, "compression_ratio": 1.5708154506437768, "no_speech_prob": 0.0032681503798812628}, {"id": 363, "seek": 185780, "start": 1879.32, "end": 1883.8, "text": " Yeah, I guess it's a similar thing with the McCorduck effect that we have relative pointers", "tokens": [51440, 865, 11, 286, 2041, 309, 311, 257, 2531, 551, 365, 264, 12061, 765, 1134, 1802, 300, 321, 362, 4972, 44548, 51664], "temperature": 0.0, "avg_logprob": -0.09323041211991083, "compression_ratio": 1.5708154506437768, "no_speech_prob": 0.0032681503798812628}, {"id": 364, "seek": 188380, "start": 1883.8, "end": 1889.24, "text": " to what we think of as being intelligence. We just point to something and then when that thing", "tokens": [50364, 281, 437, 321, 519, 295, 382, 885, 7599, 13, 492, 445, 935, 281, 746, 293, 550, 562, 300, 551, 50636], "temperature": 0.0, "avg_logprob": -0.09404005030150055, "compression_ratio": 1.6784140969162995, "no_speech_prob": 0.0005100663984194398}, {"id": 365, "seek": 188380, "start": 1890.12, "end": 1897.48, "text": " becomes easy, then we need to kind of move the pointer. Yeah, I think it also feeds into, as", "tokens": [50680, 3643, 1858, 11, 550, 321, 643, 281, 733, 295, 1286, 264, 23918, 13, 865, 11, 286, 519, 309, 611, 23712, 666, 11, 382, 51048], "temperature": 0.0, "avg_logprob": -0.09404005030150055, "compression_ratio": 1.6784140969162995, "no_speech_prob": 0.0005100663984194398}, {"id": 366, "seek": 188380, "start": 1897.48, "end": 1903.56, "text": " Tim was saying, I think it heightens the fear of existential risk because of this, this concept", "tokens": [51048, 7172, 390, 1566, 11, 286, 519, 309, 6681, 694, 264, 4240, 295, 37133, 3148, 570, 295, 341, 11, 341, 3410, 51352], "temperature": 0.0, "avg_logprob": -0.09404005030150055, "compression_ratio": 1.6784140969162995, "no_speech_prob": 0.0005100663984194398}, {"id": 367, "seek": 188380, "start": 1903.56, "end": 1910.12, "text": " that we have of intelligence always wins, which even among humans is, is a flawed concept, right?", "tokens": [51352, 300, 321, 362, 295, 7599, 1009, 10641, 11, 597, 754, 3654, 6255, 307, 11, 307, 257, 38823, 3410, 11, 558, 30, 51680], "temperature": 0.0, "avg_logprob": -0.09404005030150055, "compression_ratio": 1.6784140969162995, "no_speech_prob": 0.0005100663984194398}, {"id": 368, "seek": 191012, "start": 1910.12, "end": 1914.36, "text": " I mean, you know, many nerds who grew up through elementary school can tell you like", "tokens": [50364, 286, 914, 11, 291, 458, 11, 867, 23229, 82, 567, 6109, 493, 807, 16429, 1395, 393, 980, 291, 411, 50576], "temperature": 0.0, "avg_logprob": -0.07693011805696308, "compression_ratio": 1.713740458015267, "no_speech_prob": 0.0013248835457488894}, {"id": 369, "seek": 191012, "start": 1914.36, "end": 1920.28, "text": " intelligence doesn't always win, right? Like sometimes it's numbers or brute force or", "tokens": [50576, 7599, 1177, 380, 1009, 1942, 11, 558, 30, 1743, 2171, 309, 311, 3547, 420, 47909, 3464, 420, 50872], "temperature": 0.0, "avg_logprob": -0.07693011805696308, "compression_ratio": 1.713740458015267, "no_speech_prob": 0.0013248835457488894}, {"id": 370, "seek": 191012, "start": 1920.28, "end": 1924.52, "text": " whatever else kind of kind of wins. And they assume like, well, if we were to have this", "tokens": [50872, 2035, 1646, 733, 295, 733, 295, 10641, 13, 400, 436, 6552, 411, 11, 731, 11, 498, 321, 645, 281, 362, 341, 51084], "temperature": 0.0, "avg_logprob": -0.07693011805696308, "compression_ratio": 1.713740458015267, "no_speech_prob": 0.0013248835457488894}, {"id": 371, "seek": 191012, "start": 1924.52, "end": 1930.6, "text": " purified intelligence that was super intelligence, it would be as if a human brain were super", "tokens": [51084, 1864, 2587, 7599, 300, 390, 1687, 7599, 11, 309, 576, 312, 382, 498, 257, 1952, 3567, 645, 1687, 51388], "temperature": 0.0, "avg_logprob": -0.07693011805696308, "compression_ratio": 1.713740458015267, "no_speech_prob": 0.0013248835457488894}, {"id": 372, "seek": 191012, "start": 1930.6, "end": 1935.8799999999999, "text": " intelligent and they'd be able to do everything a human being could do and hurt other people and", "tokens": [51388, 13232, 293, 436, 1116, 312, 1075, 281, 360, 1203, 257, 1952, 885, 727, 360, 293, 4607, 661, 561, 293, 51652], "temperature": 0.0, "avg_logprob": -0.07693011805696308, "compression_ratio": 1.713740458015267, "no_speech_prob": 0.0013248835457488894}, {"id": 373, "seek": 193588, "start": 1935.88, "end": 1941.64, "text": " conquer the world and fight wars. And that again, is this anthropomorphic projection, right?", "tokens": [50364, 24136, 264, 1002, 293, 2092, 13718, 13, 400, 300, 797, 11, 307, 341, 22727, 32702, 299, 22743, 11, 558, 30, 50652], "temperature": 0.0, "avg_logprob": -0.13459437370300292, "compression_ratio": 1.6743119266055047, "no_speech_prob": 0.002800344256684184}, {"id": 374, "seek": 193588, "start": 1942.44, "end": 1950.2800000000002, "text": " Yeah, I mean, right. So, and it's this notion that intelligence is this thing that you can just", "tokens": [50692, 865, 11, 286, 914, 11, 558, 13, 407, 11, 293, 309, 311, 341, 10710, 300, 7599, 307, 341, 551, 300, 291, 393, 445, 51084], "temperature": 0.0, "avg_logprob": -0.13459437370300292, "compression_ratio": 1.6743119266055047, "no_speech_prob": 0.002800344256684184}, {"id": 375, "seek": 193588, "start": 1950.2800000000002, "end": 1957.0, "text": " have more and more of. Forever. Forever. Or so far that it's just beyond any, you know,", "tokens": [51084, 362, 544, 293, 544, 295, 13, 30703, 13, 30703, 13, 1610, 370, 1400, 300, 309, 311, 445, 4399, 604, 11, 291, 458, 11, 51420], "temperature": 0.0, "avg_logprob": -0.13459437370300292, "compression_ratio": 1.6743119266055047, "no_speech_prob": 0.002800344256684184}, {"id": 376, "seek": 193588, "start": 1957.0, "end": 1962.0400000000002, "text": " it's almost magical, right? And it's capable. Right. And it's not, you know, a different", "tokens": [51420, 309, 311, 1920, 12066, 11, 558, 30, 400, 309, 311, 8189, 13, 1779, 13, 400, 309, 311, 406, 11, 291, 458, 11, 257, 819, 51672], "temperature": 0.0, "avg_logprob": -0.13459437370300292, "compression_ratio": 1.6743119266055047, "no_speech_prob": 0.002800344256684184}, {"id": 377, "seek": 196204, "start": 1962.04, "end": 1969.24, "text": " view of intelligence is that it's a collection of adaptations to specific problems for a particular", "tokens": [50364, 1910, 295, 7599, 307, 300, 309, 311, 257, 5765, 295, 44465, 281, 2685, 2740, 337, 257, 1729, 50724], "temperature": 0.0, "avg_logprob": -0.10439952682046329, "compression_ratio": 1.4787234042553192, "no_speech_prob": 0.006484780460596085}, {"id": 378, "seek": 196204, "start": 1969.24, "end": 1980.2, "text": " kind of organism in an environment. And it's not the sort of an open-ended, pure domain", "tokens": [50724, 733, 295, 24128, 294, 364, 2823, 13, 400, 309, 311, 406, 264, 1333, 295, 364, 1269, 12, 3502, 11, 6075, 9274, 51272], "temperature": 0.0, "avg_logprob": -0.10439952682046329, "compression_ratio": 1.4787234042553192, "no_speech_prob": 0.006484780460596085}, {"id": 379, "seek": 196204, "start": 1980.2, "end": 1986.92, "text": " independent thing. So, I think this is why, you know, you see a lot of discussion of super", "tokens": [51272, 6695, 551, 13, 407, 11, 286, 519, 341, 307, 983, 11, 291, 458, 11, 291, 536, 257, 688, 295, 5017, 295, 1687, 51608], "temperature": 0.0, "avg_logprob": -0.10439952682046329, "compression_ratio": 1.4787234042553192, "no_speech_prob": 0.006484780460596085}, {"id": 380, "seek": 198692, "start": 1987.0, "end": 1996.68, "text": " intelligence, AGI, you know, AI risk in among computer scientists, but you don't see a lot of it", "tokens": [50368, 7599, 11, 316, 26252, 11, 291, 458, 11, 7318, 3148, 294, 3654, 3820, 7708, 11, 457, 291, 500, 380, 536, 257, 688, 295, 309, 50852], "temperature": 0.0, "avg_logprob": -0.1106414061326247, "compression_ratio": 1.59009009009009, "no_speech_prob": 0.0031624343246221542}, {"id": 381, "seek": 198692, "start": 1997.24, "end": 2004.44, "text": " discussed among like psychologists or animal intelligence people or other cognitive scientists.", "tokens": [50880, 7152, 3654, 411, 41562, 420, 5496, 7599, 561, 420, 661, 15605, 7708, 13, 51240], "temperature": 0.0, "avg_logprob": -0.1106414061326247, "compression_ratio": 1.59009009009009, "no_speech_prob": 0.0031624343246221542}, {"id": 382, "seek": 198692, "start": 2005.4, "end": 2008.1200000000001, "text": " Because that's not the way that they understand intelligence.", "tokens": [51288, 1436, 300, 311, 406, 264, 636, 300, 436, 1223, 7599, 13, 51424], "temperature": 0.0, "avg_logprob": -0.1106414061326247, "compression_ratio": 1.59009009009009, "no_speech_prob": 0.0031624343246221542}, {"id": 383, "seek": 198692, "start": 2009.24, "end": 2013.16, "text": " I would love to explore more about that because, I mean, only yesterday when we were talking about", "tokens": [51480, 286, 576, 959, 281, 6839, 544, 466, 300, 570, 11, 286, 914, 11, 787, 5186, 562, 321, 645, 1417, 466, 51676], "temperature": 0.0, "avg_logprob": -0.1106414061326247, "compression_ratio": 1.59009009009009, "no_speech_prob": 0.0031624343246221542}, {"id": 384, "seek": 201316, "start": 2013.24, "end": 2019.5600000000002, "text": " an activism, we're also talking about Gibson's ecological psychology. And even Elizabeth Spelke,", "tokens": [50368, 364, 29040, 11, 321, 434, 611, 1417, 466, 42250, 311, 31054, 15105, 13, 400, 754, 12978, 1738, 338, 330, 11, 50684], "temperature": 0.0, "avg_logprob": -0.09335428697091562, "compression_ratio": 1.7157894736842105, "no_speech_prob": 0.005149264354258776}, {"id": 385, "seek": 201316, "start": 2019.5600000000002, "end": 2024.52, "text": " I mean, this kind of cognitive psychology view is very related to nativism. It's this idea that we", "tokens": [50684, 286, 914, 11, 341, 733, 295, 15605, 15105, 1910, 307, 588, 4077, 281, 2249, 592, 1434, 13, 467, 311, 341, 1558, 300, 321, 50932], "temperature": 0.0, "avg_logprob": -0.09335428697091562, "compression_ratio": 1.7157894736842105, "no_speech_prob": 0.005149264354258776}, {"id": 386, "seek": 201316, "start": 2024.52, "end": 2030.2, "text": " have these fundamental cognitive primitives and intelligence in some sense is just traversing", "tokens": [50932, 362, 613, 8088, 15605, 2886, 38970, 293, 7599, 294, 512, 2020, 307, 445, 23149, 278, 51216], "temperature": 0.0, "avg_logprob": -0.09335428697091562, "compression_ratio": 1.7157894736842105, "no_speech_prob": 0.005149264354258776}, {"id": 387, "seek": 201316, "start": 2030.2, "end": 2036.1200000000001, "text": " or recomposing this library of cognitive modules that we have. And those modules are very physically", "tokens": [51216, 420, 48000, 6110, 341, 6405, 295, 15605, 16679, 300, 321, 362, 13, 400, 729, 16679, 366, 588, 9762, 51512], "temperature": 0.0, "avg_logprob": -0.09335428697091562, "compression_ratio": 1.7157894736842105, "no_speech_prob": 0.005149264354258776}, {"id": 388, "seek": 201316, "start": 2036.1200000000001, "end": 2041.5600000000002, "text": " situated, you know, they tell you something about the environment that you're in. Which means that", "tokens": [51512, 30143, 11, 291, 458, 11, 436, 980, 291, 746, 466, 264, 2823, 300, 291, 434, 294, 13, 3013, 1355, 300, 51784], "temperature": 0.0, "avg_logprob": -0.09335428697091562, "compression_ratio": 1.7157894736842105, "no_speech_prob": 0.005149264354258776}, {"id": 389, "seek": 204156, "start": 2041.6399999999999, "end": 2047.0, "text": " intelligence is just very gnarly and it's very kind of coupled to the environment we're in. It", "tokens": [50368, 7599, 307, 445, 588, 290, 20062, 356, 293, 309, 311, 588, 733, 295, 29482, 281, 264, 2823, 321, 434, 294, 13, 467, 50636], "temperature": 0.0, "avg_logprob": -0.11457344581340921, "compression_ratio": 1.5347826086956522, "no_speech_prob": 0.00039748300332576036}, {"id": 390, "seek": 204156, "start": 2047.0, "end": 2051.56, "text": " can't really be magically abstracted in a computer with infinite scale.", "tokens": [50636, 393, 380, 534, 312, 39763, 12649, 292, 294, 257, 3820, 365, 13785, 4373, 13, 50864], "temperature": 0.0, "avg_logprob": -0.11457344581340921, "compression_ratio": 1.5347826086956522, "no_speech_prob": 0.00039748300332576036}, {"id": 391, "seek": 204156, "start": 2052.7599999999998, "end": 2058.36, "text": " Yeah, I think that's right. That's, you know, people have different views about the nativism,", "tokens": [50924, 865, 11, 286, 519, 300, 311, 558, 13, 663, 311, 11, 291, 458, 11, 561, 362, 819, 6809, 466, 264, 2249, 592, 1434, 11, 51204], "temperature": 0.0, "avg_logprob": -0.11457344581340921, "compression_ratio": 1.5347826086956522, "no_speech_prob": 0.00039748300332576036}, {"id": 392, "seek": 204156, "start": 2059.88, "end": 2066.04, "text": " empiricism, debate. And there's whole different schools and cognitive science about like how", "tokens": [51280, 25790, 26356, 11, 7958, 13, 400, 456, 311, 1379, 819, 4656, 293, 15605, 3497, 466, 411, 577, 51588], "temperature": 0.0, "avg_logprob": -0.11457344581340921, "compression_ratio": 1.5347826086956522, "no_speech_prob": 0.00039748300332576036}, {"id": 393, "seek": 206604, "start": 2066.7599999999998, "end": 2072.84, "text": " how much is learned, how much is evolutionarily built in and all of that. But I think most people", "tokens": [50400, 577, 709, 307, 3264, 11, 577, 709, 307, 9303, 3289, 3094, 294, 293, 439, 295, 300, 13, 583, 286, 519, 881, 561, 50704], "temperature": 0.0, "avg_logprob": -0.13301448822021483, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.0017540830885991454}, {"id": 394, "seek": 206604, "start": 2073.4, "end": 2083.8, "text": " in the field would agree with what you said that intelligence is very gnarly. It is situated, it", "tokens": [50732, 294, 264, 2519, 576, 3986, 365, 437, 291, 848, 300, 7599, 307, 588, 290, 20062, 356, 13, 467, 307, 30143, 11, 309, 51252], "temperature": 0.0, "avg_logprob": -0.13301448822021483, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.0017540830885991454}, {"id": 395, "seek": 206604, "start": 2083.8, "end": 2094.2799999999997, "text": " is specific to particular domains of concern to a particular organism, and that it's not easily", "tokens": [51252, 307, 2685, 281, 1729, 25514, 295, 3136, 281, 257, 1729, 24128, 11, 293, 300, 309, 311, 406, 3612, 51776], "temperature": 0.0, "avg_logprob": -0.13301448822021483, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.0017540830885991454}, {"id": 396, "seek": 209428, "start": 2094.28, "end": 2097.96, "text": " abstractable. You know, that back in the early days of AI we had", "tokens": [50364, 12649, 712, 13, 509, 458, 11, 300, 646, 294, 264, 2440, 1708, 295, 7318, 321, 632, 50548], "temperature": 0.0, "avg_logprob": -0.10736031532287597, "compression_ratio": 1.6192660550458715, "no_speech_prob": 0.0006665728287771344}, {"id": 397, "seek": 209428, "start": 2100.52, "end": 2106.36, "text": " Newell and Simon, two of the pioneers of AI who had this thing called the physical symbol system", "tokens": [50676, 1734, 6326, 293, 13193, 11, 732, 295, 264, 47381, 295, 7318, 567, 632, 341, 551, 1219, 264, 4001, 5986, 1185, 50968], "temperature": 0.0, "avg_logprob": -0.10736031532287597, "compression_ratio": 1.6192660550458715, "no_speech_prob": 0.0006665728287771344}, {"id": 398, "seek": 209428, "start": 2106.36, "end": 2113.8, "text": " hypothesis, which was that basically you could sift off intelligence from any material substrate", "tokens": [50968, 17291, 11, 597, 390, 300, 1936, 291, 727, 262, 2008, 766, 7599, 490, 604, 2527, 27585, 51340], "temperature": 0.0, "avg_logprob": -0.10736031532287597, "compression_ratio": 1.6192660550458715, "no_speech_prob": 0.0006665728287771344}, {"id": 399, "seek": 209428, "start": 2113.8, "end": 2118.84, "text": " like the brain and put it in some other material substrate like a computer. They were thinking", "tokens": [51340, 411, 264, 3567, 293, 829, 309, 294, 512, 661, 2527, 27585, 411, 257, 3820, 13, 814, 645, 1953, 51592], "temperature": 0.0, "avg_logprob": -0.10736031532287597, "compression_ratio": 1.6192660550458715, "no_speech_prob": 0.0006665728287771344}, {"id": 400, "seek": 211884, "start": 2118.84, "end": 2127.1600000000003, "text": " about symbols, but nowadays people have the same kind of view with neural nets or", "tokens": [50364, 466, 16944, 11, 457, 13434, 561, 362, 264, 912, 733, 295, 1910, 365, 18161, 36170, 420, 50780], "temperature": 0.0, "avg_logprob": -0.08752350748321157, "compression_ratio": 1.6036036036036037, "no_speech_prob": 0.008573958650231361}, {"id": 401, "seek": 211884, "start": 2128.6000000000004, "end": 2134.92, "text": " transformers or whatever, that you can take human intelligence that's very situated and", "tokens": [50852, 4088, 433, 420, 2035, 11, 300, 291, 393, 747, 1952, 7599, 300, 311, 588, 30143, 293, 51168], "temperature": 0.0, "avg_logprob": -0.08752350748321157, "compression_ratio": 1.6036036036036037, "no_speech_prob": 0.008573958650231361}, {"id": 402, "seek": 211884, "start": 2135.8, "end": 2141.7200000000003, "text": " tied to the environment and sort of sift off the pure part and leave all of that bodily stuff", "tokens": [51212, 9601, 281, 264, 2823, 293, 1333, 295, 262, 2008, 766, 264, 6075, 644, 293, 1856, 439, 295, 300, 39576, 1507, 51508], "temperature": 0.0, "avg_logprob": -0.08752350748321157, "compression_ratio": 1.6036036036036037, "no_speech_prob": 0.008573958650231361}, {"id": 403, "seek": 211884, "start": 2142.36, "end": 2146.52, "text": " and you can get something like superintelligence. And I don't think most people in cognitive", "tokens": [51540, 293, 291, 393, 483, 746, 411, 1687, 20761, 17644, 13, 400, 286, 500, 380, 519, 881, 561, 294, 15605, 51748], "temperature": 0.0, "avg_logprob": -0.08752350748321157, "compression_ratio": 1.6036036036036037, "no_speech_prob": 0.008573958650231361}, {"id": 404, "seek": 214652, "start": 2146.52, "end": 2152.04, "text": " science would agree with that. Well, on the other hand though, I think, and I'd be curious to get", "tokens": [50364, 3497, 576, 3986, 365, 300, 13, 1042, 11, 322, 264, 661, 1011, 1673, 11, 286, 519, 11, 293, 286, 1116, 312, 6369, 281, 483, 50640], "temperature": 0.0, "avg_logprob": -0.13091971956450363, "compression_ratio": 1.7067669172932332, "no_speech_prob": 0.0004044040688313544}, {"id": 405, "seek": 214652, "start": 2152.04, "end": 2157.48, "text": " your take on this, is one direction that that comes from is for those of us, and I include", "tokens": [50640, 428, 747, 322, 341, 11, 307, 472, 3513, 300, 300, 1487, 490, 307, 337, 729, 295, 505, 11, 293, 286, 4090, 50912], "temperature": 0.0, "avg_logprob": -0.13091971956450363, "compression_ratio": 1.7067669172932332, "no_speech_prob": 0.0004044040688313544}, {"id": 406, "seek": 214652, "start": 2157.48, "end": 2163.48, "text": " myself in this camp tentatively, that at the end of the day what the brain does is some form of", "tokens": [50912, 2059, 294, 341, 2255, 7054, 19020, 11, 300, 412, 264, 917, 295, 264, 786, 437, 264, 3567, 775, 307, 512, 1254, 295, 51212], "temperature": 0.0, "avg_logprob": -0.13091971956450363, "compression_ratio": 1.7067669172932332, "no_speech_prob": 0.0004044040688313544}, {"id": 407, "seek": 214652, "start": 2163.48, "end": 2168.12, "text": " computation. You know, like absence, the proof that there's such a thing as hypercomputation,", "tokens": [51212, 24903, 13, 509, 458, 11, 411, 17145, 11, 264, 8177, 300, 456, 311, 1270, 257, 551, 382, 9848, 1112, 2582, 399, 11, 51444], "temperature": 0.0, "avg_logprob": -0.13091971956450363, "compression_ratio": 1.7067669172932332, "no_speech_prob": 0.0004044040688313544}, {"id": 408, "seek": 214652, "start": 2168.12, "end": 2174.04, "text": " like our brain, all of its calculations could be embodied in a large enough", "tokens": [51444, 411, 527, 3567, 11, 439, 295, 1080, 20448, 727, 312, 42046, 294, 257, 2416, 1547, 51740], "temperature": 0.0, "avg_logprob": -0.13091971956450363, "compression_ratio": 1.7067669172932332, "no_speech_prob": 0.0004044040688313544}, {"id": 409, "seek": 217404, "start": 2174.6, "end": 2179.0, "text": " you know, Turing machine and a large enough computer of some kind. And therefore, everything", "tokens": [50392, 291, 458, 11, 314, 1345, 3479, 293, 257, 2416, 1547, 3820, 295, 512, 733, 13, 400, 4412, 11, 1203, 50612], "temperature": 0.0, "avg_logprob": -0.10365346047730573, "compression_ratio": 1.6468531468531469, "no_speech_prob": 0.0009697068599052727}, {"id": 410, "seek": 217404, "start": 2179.0, "end": 2187.16, "text": " that we do, including our intelligent activities, could be coded somehow or another into a Turing", "tokens": [50612, 300, 321, 360, 11, 3009, 527, 13232, 5354, 11, 727, 312, 34874, 6063, 420, 1071, 666, 257, 314, 1345, 51020], "temperature": 0.0, "avg_logprob": -0.10365346047730573, "compression_ratio": 1.6468531468531469, "no_speech_prob": 0.0009697068599052727}, {"id": 411, "seek": 217404, "start": 2187.16, "end": 2191.8, "text": " equivalent system. And for the record, I don't believe neural networks are. I've said this like", "tokens": [51020, 10344, 1185, 13, 400, 337, 264, 2136, 11, 286, 500, 380, 1697, 18161, 9590, 366, 13, 286, 600, 848, 341, 411, 51252], "temperature": 0.0, "avg_logprob": -0.10365346047730573, "compression_ratio": 1.6468531468531469, "no_speech_prob": 0.0009697068599052727}, {"id": 412, "seek": 217404, "start": 2191.8, "end": 2195.96, "text": " multiple times, at least in their current manifestations, they're not, they're just a", "tokens": [51252, 3866, 1413, 11, 412, 1935, 294, 641, 2190, 46931, 11, 436, 434, 406, 11, 436, 434, 445, 257, 51460], "temperature": 0.0, "avg_logprob": -0.10365346047730573, "compression_ratio": 1.6468531468531469, "no_speech_prob": 0.0009697068599052727}, {"id": 413, "seek": 217404, "start": 2195.96, "end": 2200.12, "text": " feed forward, you know, thing at the end of the day. But if you actually had a computer, you could", "tokens": [51460, 3154, 2128, 11, 291, 458, 11, 551, 412, 264, 917, 295, 264, 786, 13, 583, 498, 291, 767, 632, 257, 3820, 11, 291, 727, 51668], "temperature": 0.0, "avg_logprob": -0.10365346047730573, "compression_ratio": 1.6468531468531469, "no_speech_prob": 0.0009697068599052727}, {"id": 414, "seek": 220012, "start": 2200.12, "end": 2207.16, "text": " have human symbolic intelligence encoded. Like, where do you stand on that, on that debate, if you", "tokens": [50364, 362, 1952, 25755, 7599, 2058, 12340, 13, 1743, 11, 689, 360, 291, 1463, 322, 300, 11, 322, 300, 7958, 11, 498, 291, 50716], "temperature": 0.0, "avg_logprob": -0.11106451670328776, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.00043041876051574945}, {"id": 415, "seek": 220012, "start": 2207.16, "end": 2216.2, "text": " will? Yeah, I have nothing against the idea that the brain does computations. I think that's,", "tokens": [50716, 486, 30, 865, 11, 286, 362, 1825, 1970, 264, 1558, 300, 264, 3567, 775, 2807, 763, 13, 286, 519, 300, 311, 11, 51168], "temperature": 0.0, "avg_logprob": -0.11106451670328776, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.00043041876051574945}, {"id": 416, "seek": 220012, "start": 2217.08, "end": 2225.48, "text": " that's, you know, one possible way to look at it. And that those kinds of computations could be", "tokens": [51212, 300, 311, 11, 291, 458, 11, 472, 1944, 636, 281, 574, 412, 309, 13, 400, 300, 729, 3685, 295, 2807, 763, 727, 312, 51632], "temperature": 0.0, "avg_logprob": -0.11106451670328776, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.00043041876051574945}, {"id": 417, "seek": 222548, "start": 2225.48, "end": 2230.6, "text": " implemented in another kind of computer. But the brain is a very special kind of", "tokens": [50364, 12270, 294, 1071, 733, 295, 3820, 13, 583, 264, 3567, 307, 257, 588, 2121, 733, 295, 50620], "temperature": 0.0, "avg_logprob": -0.05954108127327853, "compression_ratio": 1.803921568627451, "no_speech_prob": 0.03208060562610626}, {"id": 418, "seek": 222548, "start": 2230.6, "end": 2235.48, "text": " sort of biological computer that's been evolved to do specific things. And one of the main things", "tokens": [50620, 1333, 295, 13910, 3820, 300, 311, 668, 14178, 281, 360, 2685, 721, 13, 400, 472, 295, 264, 2135, 721, 50864], "temperature": 0.0, "avg_logprob": -0.05954108127327853, "compression_ratio": 1.803921568627451, "no_speech_prob": 0.03208060562610626}, {"id": 419, "seek": 222548, "start": 2235.48, "end": 2241.16, "text": " the brain has been evolved to do is control the body, and in particular kinds of environments.", "tokens": [50864, 264, 3567, 575, 668, 14178, 281, 360, 307, 1969, 264, 1772, 11, 293, 294, 1729, 3685, 295, 12388, 13, 51148], "temperature": 0.0, "avg_logprob": -0.05954108127327853, "compression_ratio": 1.803921568627451, "no_speech_prob": 0.03208060562610626}, {"id": 420, "seek": 222548, "start": 2241.8, "end": 2248.68, "text": " And so I think the brain is doing computations, but it's doing very, very highly evolved, very", "tokens": [51180, 400, 370, 286, 519, 264, 3567, 307, 884, 2807, 763, 11, 457, 309, 311, 884, 588, 11, 588, 5405, 14178, 11, 588, 51524], "temperature": 0.0, "avg_logprob": -0.05954108127327853, "compression_ratio": 1.803921568627451, "no_speech_prob": 0.03208060562610626}, {"id": 421, "seek": 224868, "start": 2248.68, "end": 2259.48, "text": " domain specific computations that perhaps don't necessarily make sense without having a body.", "tokens": [50364, 9274, 2685, 2807, 763, 300, 4317, 500, 380, 4725, 652, 2020, 1553, 1419, 257, 1772, 13, 50904], "temperature": 0.0, "avg_logprob": -0.1120427946249644, "compression_ratio": 1.3586206896551725, "no_speech_prob": 0.008060047402977943}, {"id": 422, "seek": 224868, "start": 2261.64, "end": 2272.6, "text": " Now, that's debatable. But it does seem like a lot of the way that we reason is by reference to our own", "tokens": [51012, 823, 11, 300, 311, 3001, 31415, 13, 583, 309, 775, 1643, 411, 257, 688, 295, 264, 636, 300, 321, 1778, 307, 538, 6408, 281, 527, 1065, 51560], "temperature": 0.0, "avg_logprob": -0.1120427946249644, "compression_ratio": 1.3586206896551725, "no_speech_prob": 0.008060047402977943}, {"id": 423, "seek": 227260, "start": 2272.7599999999998, "end": 2277.4, "text": " sort of episodic experience in the world.", "tokens": [50372, 1333, 295, 39200, 299, 1752, 294, 264, 1002, 13, 50604], "temperature": 0.0, "avg_logprob": -0.16482254396001977, "compression_ratio": 1.51131221719457, "no_speech_prob": 0.006288934499025345}, {"id": 424, "seek": 227260, "start": 2279.16, "end": 2284.7599999999998, "text": " Or at least to the capabilities that have been built into us, you know, like visual, using our", "tokens": [50692, 1610, 412, 1935, 281, 264, 10862, 300, 362, 668, 3094, 666, 505, 11, 291, 458, 11, 411, 5056, 11, 1228, 527, 50972], "temperature": 0.0, "avg_logprob": -0.16482254396001977, "compression_ratio": 1.51131221719457, "no_speech_prob": 0.006288934499025345}, {"id": 425, "seek": 227260, "start": 2284.7599999999998, "end": 2291.24, "text": " visual cortex to imagine cubes and steers and whatever else we need to solve a physics problem", "tokens": [50972, 5056, 33312, 281, 3811, 25415, 293, 2126, 433, 293, 2035, 1646, 321, 643, 281, 5039, 257, 10649, 1154, 51296], "temperature": 0.0, "avg_logprob": -0.16482254396001977, "compression_ratio": 1.51131221719457, "no_speech_prob": 0.006288934499025345}, {"id": 426, "seek": 227260, "start": 2291.24, "end": 2297.48, "text": " or a geometric problem. Sure, sure. Yeah, so I'm fine with saying the brain is a computer of a certain", "tokens": [51296, 420, 257, 33246, 1154, 13, 4894, 11, 988, 13, 865, 11, 370, 286, 478, 2489, 365, 1566, 264, 3567, 307, 257, 3820, 295, 257, 1629, 51608], "temperature": 0.0, "avg_logprob": -0.16482254396001977, "compression_ratio": 1.51131221719457, "no_speech_prob": 0.006288934499025345}, {"id": 427, "seek": 229748, "start": 2297.48, "end": 2308.84, "text": " kind, but that's not to say that it's going to be, you can just kind of lift off the computations", "tokens": [50364, 733, 11, 457, 300, 311, 406, 281, 584, 300, 309, 311, 516, 281, 312, 11, 291, 393, 445, 733, 295, 5533, 766, 264, 2807, 763, 50932], "temperature": 0.0, "avg_logprob": -0.11404741314095511, "compression_ratio": 1.630057803468208, "no_speech_prob": 0.023309634998440742}, {"id": 428, "seek": 229748, "start": 2311.08, "end": 2317.64, "text": " and then put them in a different substrate and kind of get everything that's human like,", "tokens": [51044, 293, 550, 829, 552, 294, 257, 819, 27585, 293, 733, 295, 483, 1203, 300, 311, 1952, 411, 11, 51372], "temperature": 0.0, "avg_logprob": -0.11404741314095511, "compression_ratio": 1.630057803468208, "no_speech_prob": 0.023309634998440742}, {"id": 429, "seek": 229748, "start": 2317.64, "end": 2322.52, "text": " because I'm not sure that those computations are going to make sense in the absence of the rest", "tokens": [51372, 570, 286, 478, 406, 988, 300, 729, 2807, 763, 366, 516, 281, 652, 2020, 294, 264, 17145, 295, 264, 1472, 51616], "temperature": 0.0, "avg_logprob": -0.11404741314095511, "compression_ratio": 1.630057803468208, "no_speech_prob": 0.023309634998440742}, {"id": 430, "seek": 232252, "start": 2323.08, "end": 2329.72, "text": " of the organism. Yeah, there was something that always confused me about the autopoietic", "tokens": [50392, 295, 264, 24128, 13, 865, 11, 456, 390, 746, 300, 1009, 9019, 385, 466, 264, 31090, 78, 1684, 299, 50724], "temperature": 0.0, "avg_logprob": -0.1354840715354848, "compression_ratio": 1.7047970479704797, "no_speech_prob": 0.0009322543628513813}, {"id": 431, "seek": 232252, "start": 2329.72, "end": 2336.28, "text": " inactivists, because of course they as they issue representationalism and information", "tokens": [50724, 294, 23397, 1751, 11, 570, 295, 1164, 436, 382, 436, 2734, 2906, 1478, 1434, 293, 1589, 51052], "temperature": 0.0, "avg_logprob": -0.1354840715354848, "compression_ratio": 1.7047970479704797, "no_speech_prob": 0.0009322543628513813}, {"id": 432, "seek": 232252, "start": 2336.28, "end": 2341.64, "text": " processing, but they also issue computationalism in general. And as Keith was just saying, I don't", "tokens": [51052, 9007, 11, 457, 436, 611, 2734, 28270, 1434, 294, 2674, 13, 400, 382, 20613, 390, 445, 1566, 11, 286, 500, 380, 51320], "temperature": 0.0, "avg_logprob": -0.1354840715354848, "compression_ratio": 1.7047970479704797, "no_speech_prob": 0.0009322543628513813}, {"id": 433, "seek": 232252, "start": 2341.64, "end": 2346.28, "text": " even if cognition is externalized, I don't see any reason why in principle, you couldn't just", "tokens": [51320, 754, 498, 46905, 307, 8320, 1602, 11, 286, 500, 380, 536, 604, 1778, 983, 294, 8665, 11, 291, 2809, 380, 445, 51552], "temperature": 0.0, "avg_logprob": -0.1354840715354848, "compression_ratio": 1.7047970479704797, "no_speech_prob": 0.0009322543628513813}, {"id": 434, "seek": 232252, "start": 2346.28, "end": 2351.72, "text": " compute the entire system and and recreate the computation. I just wanted to close the loop on", "tokens": [51552, 14722, 264, 2302, 1185, 293, 293, 25833, 264, 24903, 13, 286, 445, 1415, 281, 1998, 264, 6367, 322, 51824], "temperature": 0.0, "avg_logprob": -0.1354840715354848, "compression_ratio": 1.7047970479704797, "no_speech_prob": 0.0009322543628513813}, {"id": 435, "seek": 235172, "start": 2351.72, "end": 2358.6, "text": " the ARC challenge stuff though. So you said that the winning solutions to Francois' challenge on", "tokens": [50364, 264, 8943, 34, 3430, 1507, 1673, 13, 407, 291, 848, 300, 264, 8224, 6547, 281, 34695, 271, 6, 3430, 322, 50708], "temperature": 0.0, "avg_logprob": -0.11873836517333984, "compression_ratio": 1.6357388316151202, "no_speech_prob": 0.0030965865589678288}, {"id": 436, "seek": 235172, "start": 2358.6, "end": 2363.3199999999997, "text": " Kaggle, they were quite simplistic in a way. They were like a genetic search over lots of", "tokens": [50708, 48751, 22631, 11, 436, 645, 1596, 44199, 294, 257, 636, 13, 814, 645, 411, 257, 12462, 3164, 670, 3195, 295, 50944], "temperature": 0.0, "avg_logprob": -0.11873836517333984, "compression_ratio": 1.6357388316151202, "no_speech_prob": 0.0030965865589678288}, {"id": 437, "seek": 235172, "start": 2363.3199999999997, "end": 2368.6, "text": " primitive kind of functions. And even the winner said that they didn't feel it was a satisfying", "tokens": [50944, 28540, 733, 295, 6828, 13, 400, 754, 264, 8507, 848, 300, 436, 994, 380, 841, 309, 390, 257, 18348, 51208], "temperature": 0.0, "avg_logprob": -0.11873836517333984, "compression_ratio": 1.6357388316151202, "no_speech_prob": 0.0030965865589678288}, {"id": 438, "seek": 235172, "start": 2368.6, "end": 2373.48, "text": " solution, which was interesting. And then you tried it on GPT4. And I think you said you got", "tokens": [51208, 3827, 11, 597, 390, 1880, 13, 400, 550, 291, 3031, 309, 322, 26039, 51, 19, 13, 400, 286, 519, 291, 848, 291, 658, 51452], "temperature": 0.0, "avg_logprob": -0.11873836517333984, "compression_ratio": 1.6357388316151202, "no_speech_prob": 0.0030965865589678288}, {"id": 439, "seek": 235172, "start": 2373.48, "end": 2379.9599999999996, "text": " around 30%. There's now a deep mind paper out very recently, which just basically turned it all into", "tokens": [51452, 926, 2217, 6856, 821, 311, 586, 257, 2452, 1575, 3035, 484, 588, 3938, 11, 597, 445, 1936, 3574, 309, 439, 666, 51776], "temperature": 0.0, "avg_logprob": -0.11873836517333984, "compression_ratio": 1.6357388316151202, "no_speech_prob": 0.0030965865589678288}, {"id": 440, "seek": 237996, "start": 2380.04, "end": 2385.7200000000003, "text": " a character set with a random mapping, put it into GPT4, I think got nearly 60%. Even", "tokens": [50368, 257, 2517, 992, 365, 257, 4974, 18350, 11, 829, 309, 666, 26039, 51, 19, 11, 286, 519, 658, 6217, 4060, 6856, 2754, 50652], "temperature": 0.0, "avg_logprob": -0.08556590256867586, "compression_ratio": 1.5390070921985815, "no_speech_prob": 0.004971788264811039}, {"id": 441, "seek": 237996, "start": 2385.7200000000003, "end": 2391.56, "text": " even somewhat invariant to the translation between the character set mapping. Some folks on our", "tokens": [50652, 754, 8344, 33270, 394, 281, 264, 12853, 1296, 264, 2517, 992, 18350, 13, 2188, 4024, 322, 527, 50944], "temperature": 0.0, "avg_logprob": -0.08556590256867586, "compression_ratio": 1.5390070921985815, "no_speech_prob": 0.004971788264811039}, {"id": 442, "seek": 237996, "start": 2391.56, "end": 2395.8, "text": " Discord forum tried to reproduce it and couldn't. That's the problem with GPT4. You can never", "tokens": [50944, 32623, 17542, 3031, 281, 29501, 309, 293, 2809, 380, 13, 663, 311, 264, 1154, 365, 26039, 51, 19, 13, 509, 393, 1128, 51156], "temperature": 0.0, "avg_logprob": -0.08556590256867586, "compression_ratio": 1.5390070921985815, "no_speech_prob": 0.004971788264811039}, {"id": 443, "seek": 237996, "start": 2395.8, "end": 2402.6, "text": " reproduce anything. But I was just wondering, would you consider that to be an elegant solution?", "tokens": [51156, 29501, 1340, 13, 583, 286, 390, 445, 6359, 11, 576, 291, 1949, 300, 281, 312, 364, 21117, 3827, 30, 51496], "temperature": 0.0, "avg_logprob": -0.08556590256867586, "compression_ratio": 1.5390070921985815, "no_speech_prob": 0.004971788264811039}, {"id": 444, "seek": 237996, "start": 2402.6, "end": 2406.12, "text": " It's not really much better than searching over a DSL, is it?", "tokens": [51496, 467, 311, 406, 534, 709, 1101, 813, 10808, 670, 257, 15816, 43, 11, 307, 309, 30, 51672], "temperature": 0.0, "avg_logprob": -0.08556590256867586, "compression_ratio": 1.5390070921985815, "no_speech_prob": 0.004971788264811039}, {"id": 445, "seek": 240612, "start": 2406.8399999999997, "end": 2409.24, "text": " By that, you mean giving it to GPT4?", "tokens": [50400, 3146, 300, 11, 291, 914, 2902, 309, 281, 26039, 51, 19, 30, 50520], "temperature": 0.0, "avg_logprob": -0.11309159739633624, "compression_ratio": 1.5175879396984924, "no_speech_prob": 0.001409319695085287}, {"id": 446, "seek": 240612, "start": 2410.2799999999997, "end": 2415.4, "text": " Well, I mean, it's quite an interesting thing, isn't it? If there's the McCorduck effect,", "tokens": [50572, 1042, 11, 286, 914, 11, 309, 311, 1596, 364, 1880, 551, 11, 1943, 380, 309, 30, 759, 456, 311, 264, 12061, 765, 1134, 1802, 11, 50828], "temperature": 0.0, "avg_logprob": -0.11309159739633624, "compression_ratio": 1.5175879396984924, "no_speech_prob": 0.001409319695085287}, {"id": 447, "seek": 240612, "start": 2415.4, "end": 2421.3199999999997, "text": " and even before you get to a solution, what would a good AI solution look like? I mean,", "tokens": [50828, 293, 754, 949, 291, 483, 281, 257, 3827, 11, 437, 576, 257, 665, 7318, 3827, 574, 411, 30, 286, 914, 11, 51124], "temperature": 0.0, "avg_logprob": -0.11309159739633624, "compression_ratio": 1.5175879396984924, "no_speech_prob": 0.001409319695085287}, {"id": 448, "seek": 240612, "start": 2421.3199999999997, "end": 2425.7999999999997, "text": " what would someone have to create for you to say, oh, that's a really cool AI solution?", "tokens": [51124, 437, 576, 1580, 362, 281, 1884, 337, 291, 281, 584, 11, 1954, 11, 300, 311, 257, 534, 1627, 7318, 3827, 30, 51348], "temperature": 0.0, "avg_logprob": -0.11309159739633624, "compression_ratio": 1.5175879396984924, "no_speech_prob": 0.001409319695085287}, {"id": 449, "seek": 242580, "start": 2425.88, "end": 2436.36, "text": " Well, if you had a program that really could solve these tasks in a general way,", "tokens": [50368, 1042, 11, 498, 291, 632, 257, 1461, 300, 534, 727, 5039, 613, 9608, 294, 257, 2674, 636, 11, 50892], "temperature": 0.0, "avg_logprob": -0.13464230431450738, "compression_ratio": 1.5644444444444445, "no_speech_prob": 0.04671693593263626}, {"id": 450, "seek": 242580, "start": 2436.36, "end": 2443.0, "text": " that would, however it worked, it would be a good AI solution. I don't necessarily think we have to", "tokens": [50892, 300, 576, 11, 4461, 309, 2732, 11, 309, 576, 312, 257, 665, 7318, 3827, 13, 286, 500, 380, 4725, 519, 321, 362, 281, 51224], "temperature": 0.0, "avg_logprob": -0.13464230431450738, "compression_ratio": 1.5644444444444445, "no_speech_prob": 0.04671693593263626}, {"id": 451, "seek": 242580, "start": 2443.0, "end": 2449.88, "text": " have something like the way people do it. Well, let me see if I can guess, though,", "tokens": [51224, 362, 746, 411, 264, 636, 561, 360, 309, 13, 1042, 11, 718, 385, 536, 498, 286, 393, 2041, 11, 1673, 11, 51568], "temperature": 0.0, "avg_logprob": -0.13464230431450738, "compression_ratio": 1.5644444444444445, "no_speech_prob": 0.04671693593263626}, {"id": 452, "seek": 242580, "start": 2449.88, "end": 2455.48, "text": " maybe an extension to what you said. It's in line with your argument that the benchmarks", "tokens": [51568, 1310, 364, 10320, 281, 437, 291, 848, 13, 467, 311, 294, 1622, 365, 428, 6770, 300, 264, 43751, 51848], "temperature": 0.0, "avg_logprob": -0.13464230431450738, "compression_ratio": 1.5644444444444445, "no_speech_prob": 0.04671693593263626}, {"id": 453, "seek": 245548, "start": 2455.48, "end": 2460.52, "text": " have to evolve. Because I think that these benchmarks really is just first pass or low", "tokens": [50364, 362, 281, 16693, 13, 1436, 286, 519, 300, 613, 43751, 534, 307, 445, 700, 1320, 420, 2295, 50616], "temperature": 0.0, "avg_logprob": -0.0928245024247603, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0014548517065122724}, {"id": 454, "seek": 245548, "start": 2460.52, "end": 2465.32, "text": " pass filters. It's like they weed out the junk. It's like, well, if you can't pass the art challenge,", "tokens": [50616, 1320, 15995, 13, 467, 311, 411, 436, 20852, 484, 264, 19109, 13, 467, 311, 411, 11, 731, 11, 498, 291, 393, 380, 1320, 264, 1523, 3430, 11, 50856], "temperature": 0.0, "avg_logprob": -0.0928245024247603, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0014548517065122724}, {"id": 455, "seek": 245548, "start": 2465.32, "end": 2469.2400000000002, "text": " I'm not going to bother with you. If you pass the art challenge, now we have to look further,", "tokens": [50856, 286, 478, 406, 516, 281, 8677, 365, 291, 13, 759, 291, 1320, 264, 1523, 3430, 11, 586, 321, 362, 281, 574, 3052, 11, 51052], "temperature": 0.0, "avg_logprob": -0.0928245024247603, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0014548517065122724}, {"id": 456, "seek": 245548, "start": 2469.2400000000002, "end": 2475.0, "text": " right? Which is like, okay, so it's been able to generalize along these 19 concepts that we've", "tokens": [51052, 558, 30, 3013, 307, 411, 11, 1392, 11, 370, 309, 311, 668, 1075, 281, 2674, 1125, 2051, 613, 1294, 10392, 300, 321, 600, 51340], "temperature": 0.0, "avg_logprob": -0.0928245024247603, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0014548517065122724}, {"id": 457, "seek": 245548, "start": 2475.0, "end": 2482.52, "text": " defined in concept art with little pixel grids. What about if we give it full frame pictures", "tokens": [51340, 7642, 294, 3410, 1523, 365, 707, 19261, 677, 3742, 13, 708, 466, 498, 321, 976, 309, 1577, 3920, 5242, 51716], "temperature": 0.0, "avg_logprob": -0.0928245024247603, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0014548517065122724}, {"id": 458, "seek": 248252, "start": 2482.52, "end": 2488.28, "text": " or video or something? Is it able to generalize there? No, okay, it failed. Why did it fail?", "tokens": [50364, 420, 960, 420, 746, 30, 1119, 309, 1075, 281, 2674, 1125, 456, 30, 883, 11, 1392, 11, 309, 7612, 13, 1545, 630, 309, 3061, 30, 50652], "temperature": 0.0, "avg_logprob": -0.11608018226993894, "compression_ratio": 1.542857142857143, "no_speech_prob": 0.000709613726940006}, {"id": 459, "seek": 248252, "start": 2488.28, "end": 2492.36, "text": " Well, now we need to do some more engineering. It's going to be this kind of never ending sort", "tokens": [50652, 1042, 11, 586, 321, 643, 281, 360, 512, 544, 7043, 13, 467, 311, 516, 281, 312, 341, 733, 295, 1128, 8121, 1333, 50856], "temperature": 0.0, "avg_logprob": -0.11608018226993894, "compression_ratio": 1.542857142857143, "no_speech_prob": 0.000709613726940006}, {"id": 460, "seek": 248252, "start": 2492.36, "end": 2498.28, "text": " of iterative process. So I would say if something passes arc or concept arc, then it's worthy of", "tokens": [50856, 295, 17138, 1166, 1399, 13, 407, 286, 576, 584, 498, 746, 11335, 10346, 420, 3410, 10346, 11, 550, 309, 311, 14829, 295, 51152], "temperature": 0.0, "avg_logprob": -0.11608018226993894, "compression_ratio": 1.542857142857143, "no_speech_prob": 0.000709613726940006}, {"id": 461, "seek": 248252, "start": 2498.28, "end": 2506.28, "text": " further study. Sure. Yeah, I agree. I mean, one question is that arcs are very idealized kind", "tokens": [51152, 3052, 2979, 13, 4894, 13, 865, 11, 286, 3986, 13, 286, 914, 11, 472, 1168, 307, 300, 10346, 82, 366, 588, 7157, 1602, 733, 51552], "temperature": 0.0, "avg_logprob": -0.11608018226993894, "compression_ratio": 1.542857142857143, "no_speech_prob": 0.000709613726940006}, {"id": 462, "seek": 250628, "start": 2506.36, "end": 2513.88, "text": " of micro world type domain. So does it capture what's interesting about the real world", "tokens": [50368, 295, 4532, 1002, 2010, 9274, 13, 407, 775, 309, 7983, 437, 311, 1880, 466, 264, 957, 1002, 50744], "temperature": 0.0, "avg_logprob": -0.13739656632946384, "compression_ratio": 1.5810810810810811, "no_speech_prob": 0.1644490659236908}, {"id": 463, "seek": 250628, "start": 2514.6000000000004, "end": 2521.0, "text": " in terms of abstraction? To some extent, yes, probably, and to some extent, probably no.", "tokens": [50780, 294, 2115, 295, 37765, 30, 1407, 512, 8396, 11, 2086, 11, 1391, 11, 293, 281, 512, 8396, 11, 1391, 572, 13, 51100], "temperature": 0.0, "avg_logprob": -0.13739656632946384, "compression_ratio": 1.5810810810810811, "no_speech_prob": 0.1644490659236908}, {"id": 464, "seek": 250628, "start": 2521.0, "end": 2528.6800000000003, "text": " So you're right. Solving arc doesn't mean we're at AGI, if you want to talk about that.", "tokens": [51100, 407, 291, 434, 558, 13, 7026, 798, 10346, 1177, 380, 914, 321, 434, 412, 316, 26252, 11, 498, 291, 528, 281, 751, 466, 300, 13, 51484], "temperature": 0.0, "avg_logprob": -0.13739656632946384, "compression_ratio": 1.5810810810810811, "no_speech_prob": 0.1644490659236908}, {"id": 465, "seek": 250628, "start": 2528.6800000000003, "end": 2535.2400000000002, "text": " It's like in chess, what you brought up earlier. If you took whatever the current best,", "tokens": [51484, 467, 311, 411, 294, 24122, 11, 437, 291, 3038, 493, 3071, 13, 759, 291, 1890, 2035, 264, 2190, 1151, 11, 51812], "temperature": 0.0, "avg_logprob": -0.13739656632946384, "compression_ratio": 1.5810810810810811, "no_speech_prob": 0.1644490659236908}, {"id": 466, "seek": 253524, "start": 2535.24, "end": 2539.9599999999996, "text": " let's say LC zero or something like that, and it's been trained on standard chess,", "tokens": [50364, 718, 311, 584, 42198, 4018, 420, 746, 411, 300, 11, 293, 309, 311, 668, 8895, 322, 3832, 24122, 11, 50600], "temperature": 0.0, "avg_logprob": -0.1227191799091843, "compression_ratio": 1.71875, "no_speech_prob": 0.001244518207386136}, {"id": 467, "seek": 253524, "start": 2539.9599999999996, "end": 2545.3999999999996, "text": " and then you have a go play chess 960, formerly called Fisher random, where you just random,", "tokens": [50600, 293, 550, 291, 362, 257, 352, 862, 24122, 1722, 4550, 11, 34777, 1219, 26676, 4974, 11, 689, 291, 445, 4974, 11, 50872], "temperature": 0.0, "avg_logprob": -0.1227191799091843, "compression_ratio": 1.71875, "no_speech_prob": 0.001244518207386136}, {"id": 468, "seek": 253524, "start": 2545.3999999999996, "end": 2550.4399999999996, "text": " it's going to suck like humans are going to destroy it, right? Because humans have learned", "tokens": [50872, 309, 311, 516, 281, 9967, 411, 6255, 366, 516, 281, 5293, 309, 11, 558, 30, 1436, 6255, 362, 3264, 51124], "temperature": 0.0, "avg_logprob": -0.1227191799091843, "compression_ratio": 1.71875, "no_speech_prob": 0.001244518207386136}, {"id": 469, "seek": 253524, "start": 2550.4399999999996, "end": 2557.16, "text": " a more generalized and by the way, that also destroys human beings who rely on memory and", "tokens": [51124, 257, 544, 44498, 293, 538, 264, 636, 11, 300, 611, 36714, 1952, 8958, 567, 10687, 322, 4675, 293, 51460], "temperature": 0.0, "avg_logprob": -0.1227191799091843, "compression_ratio": 1.71875, "no_speech_prob": 0.001244518207386136}, {"id": 470, "seek": 253524, "start": 2557.16, "end": 2562.12, "text": " just sort of like the memorized positions that haven't learned, let's say the skill", "tokens": [51460, 445, 1333, 295, 411, 264, 46677, 8432, 300, 2378, 380, 3264, 11, 718, 311, 584, 264, 5389, 51708], "temperature": 0.0, "avg_logprob": -0.1227191799091843, "compression_ratio": 1.71875, "no_speech_prob": 0.001244518207386136}, {"id": 471, "seek": 256212, "start": 2562.12, "end": 2566.44, "text": " of playing chess, right? And so this is the type of thing that's going to happen, right?", "tokens": [50364, 295, 2433, 24122, 11, 558, 30, 400, 370, 341, 307, 264, 2010, 295, 551, 300, 311, 516, 281, 1051, 11, 558, 30, 50580], "temperature": 0.0, "avg_logprob": -0.08082117239634196, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.0013248621253296733}, {"id": 472, "seek": 256212, "start": 2566.44, "end": 2570.92, "text": " It's like you say, when you take this intelligence and try to apply it to a different context,", "tokens": [50580, 467, 311, 411, 291, 584, 11, 562, 291, 747, 341, 7599, 293, 853, 281, 3079, 309, 281, 257, 819, 4319, 11, 50804], "temperature": 0.0, "avg_logprob": -0.08082117239634196, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.0013248621253296733}, {"id": 473, "seek": 256212, "start": 2571.56, "end": 2575.3199999999997, "text": " that's when the rubber meets the road as to whether or not you really learned", "tokens": [50836, 300, 311, 562, 264, 11593, 13961, 264, 3060, 382, 281, 1968, 420, 406, 291, 534, 3264, 51024], "temperature": 0.0, "avg_logprob": -0.08082117239634196, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.0013248621253296733}, {"id": 474, "seek": 256212, "start": 2575.3199999999997, "end": 2580.52, "text": " the concepts, right? Yeah, no, definitely. I agree. And I don't think like our concept arc", "tokens": [51024, 264, 10392, 11, 558, 30, 865, 11, 572, 11, 2138, 13, 286, 3986, 13, 400, 286, 500, 380, 519, 411, 527, 3410, 10346, 51284], "temperature": 0.0, "avg_logprob": -0.08082117239634196, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.0013248621253296733}, {"id": 475, "seek": 256212, "start": 2580.52, "end": 2587.08, "text": " wasn't meant to be like a test of AGI in any sense. It was meant to be kind of a stepping stone to", "tokens": [51284, 2067, 380, 4140, 281, 312, 411, 257, 1500, 295, 316, 26252, 294, 604, 2020, 13, 467, 390, 4140, 281, 312, 733, 295, 257, 16821, 7581, 281, 51612], "temperature": 0.0, "avg_logprob": -0.08082117239634196, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.0013248621253296733}, {"id": 476, "seek": 258708, "start": 2587.08, "end": 2594.6, "text": " getting to abilities for abstraction. And clearly, if some program was able to solve all of the", "tokens": [50364, 1242, 281, 11582, 337, 37765, 13, 400, 4448, 11, 498, 512, 1461, 390, 1075, 281, 5039, 439, 295, 264, 50740], "temperature": 0.0, "avg_logprob": -0.06130970848931207, "compression_ratio": 1.6419213973799127, "no_speech_prob": 0.006288220174610615}, {"id": 477, "seek": 258708, "start": 2594.6, "end": 2601.08, "text": " problems in that domain, and we'd have to then test further, we'd have to have it be able to", "tokens": [50740, 2740, 294, 300, 9274, 11, 293, 321, 1116, 362, 281, 550, 1500, 3052, 11, 321, 1116, 362, 281, 362, 309, 312, 1075, 281, 51064], "temperature": 0.0, "avg_logprob": -0.06130970848931207, "compression_ratio": 1.6419213973799127, "no_speech_prob": 0.006288220174610615}, {"id": 478, "seek": 258708, "start": 2601.08, "end": 2606.7599999999998, "text": " extrapolate to a new kind of domain that tested the same kinds of concepts. So you're right,", "tokens": [51064, 48224, 473, 281, 257, 777, 733, 295, 9274, 300, 8246, 264, 912, 3685, 295, 10392, 13, 407, 291, 434, 558, 11, 51348], "temperature": 0.0, "avg_logprob": -0.06130970848931207, "compression_ratio": 1.6419213973799127, "no_speech_prob": 0.006288220174610615}, {"id": 479, "seek": 258708, "start": 2606.7599999999998, "end": 2612.6, "text": " there's no end in some sense. But at some point, I guess, and I don't know when that point is,", "tokens": [51348, 456, 311, 572, 917, 294, 512, 2020, 13, 583, 412, 512, 935, 11, 286, 2041, 11, 293, 286, 500, 380, 458, 562, 300, 935, 307, 11, 51640], "temperature": 0.0, "avg_logprob": -0.06130970848931207, "compression_ratio": 1.6419213973799127, "no_speech_prob": 0.006288220174610615}, {"id": 480, "seek": 261260, "start": 2612.6, "end": 2617.3199999999997, "text": " we have to say, well, this thing seems to be understanding this concept.", "tokens": [50364, 321, 362, 281, 584, 11, 731, 11, 341, 551, 2544, 281, 312, 3701, 341, 3410, 13, 50600], "temperature": 0.0, "avg_logprob": -0.10982709664564866, "compression_ratio": 1.6988847583643123, "no_speech_prob": 0.003320448799058795}, {"id": 481, "seek": 261260, "start": 2619.96, "end": 2623.72, "text": " That's the wonderful continuum, though, because you said earlier, there's something deeply", "tokens": [50732, 663, 311, 264, 3715, 36120, 11, 1673, 11, 570, 291, 848, 3071, 11, 456, 311, 746, 8760, 50920], "temperature": 0.0, "avg_logprob": -0.10982709664564866, "compression_ratio": 1.6988847583643123, "no_speech_prob": 0.003320448799058795}, {"id": 482, "seek": 261260, "start": 2623.72, "end": 2630.04, "text": " unsatisfying about chess brute forcing everything. And when we apply Francois' measure of intelligence,", "tokens": [50920, 2693, 25239, 1840, 466, 24122, 47909, 19030, 1203, 13, 400, 562, 321, 3079, 34695, 271, 6, 3481, 295, 7599, 11, 51236], "temperature": 0.0, "avg_logprob": -0.10982709664564866, "compression_ratio": 1.6988847583643123, "no_speech_prob": 0.003320448799058795}, {"id": 483, "seek": 261260, "start": 2630.04, "end": 2636.04, "text": " we don't think of that as intelligent because it's just brute force experience. And then we", "tokens": [51236, 321, 500, 380, 519, 295, 300, 382, 13232, 570, 309, 311, 445, 47909, 3464, 1752, 13, 400, 550, 321, 51536], "temperature": 0.0, "avg_logprob": -0.10982709664564866, "compression_ratio": 1.6988847583643123, "no_speech_prob": 0.003320448799058795}, {"id": 484, "seek": 261260, "start": 2636.04, "end": 2640.04, "text": " find something which is a little bit more efficient. So it's something which appears to work. But", "tokens": [51536, 915, 746, 597, 307, 257, 707, 857, 544, 7148, 13, 407, 309, 311, 746, 597, 7038, 281, 589, 13, 583, 51736], "temperature": 0.0, "avg_logprob": -0.10982709664564866, "compression_ratio": 1.6988847583643123, "no_speech_prob": 0.003320448799058795}, {"id": 485, "seek": 264004, "start": 2640.7599999999998, "end": 2645.4, "text": " now, another interesting thing is when you talk about concepts, you had this beautiful article", "tokens": [50400, 586, 11, 1071, 1880, 551, 307, 562, 291, 751, 466, 10392, 11, 291, 632, 341, 2238, 7222, 50632], "temperature": 0.0, "avg_logprob": -0.1116172356334159, "compression_ratio": 1.6928571428571428, "no_speech_prob": 0.0009645079844631255}, {"id": 486, "seek": 264004, "start": 2645.4, "end": 2650.92, "text": " out earlier that she had talking about, on top of, she's on top of the world. And what would", "tokens": [50632, 484, 3071, 300, 750, 632, 1417, 466, 11, 322, 1192, 295, 11, 750, 311, 322, 1192, 295, 264, 1002, 13, 400, 437, 576, 50908], "temperature": 0.0, "avg_logprob": -0.1116172356334159, "compression_ratio": 1.6928571428571428, "no_speech_prob": 0.0009645079844631255}, {"id": 487, "seek": 264004, "start": 2650.92, "end": 2658.2, "text": " Dali draw? It would draw a globe with someone dancing on top of it, or I'm on the TV. What", "tokens": [50908, 413, 5103, 2642, 30, 467, 576, 2642, 257, 15371, 365, 1580, 8898, 322, 1192, 295, 309, 11, 420, 286, 478, 322, 264, 3558, 13, 708, 51272], "temperature": 0.0, "avg_logprob": -0.1116172356334159, "compression_ratio": 1.6928571428571428, "no_speech_prob": 0.0009645079844631255}, {"id": 488, "seek": 264004, "start": 2658.2, "end": 2663.56, "text": " does that mean? It should mean that I'm actually being rendered on the TV. Now, it's kind of like", "tokens": [51272, 775, 300, 914, 30, 467, 820, 914, 300, 286, 478, 767, 885, 28748, 322, 264, 3558, 13, 823, 11, 309, 311, 733, 295, 411, 51540], "temperature": 0.0, "avg_logprob": -0.1116172356334159, "compression_ratio": 1.6928571428571428, "no_speech_prob": 0.0009645079844631255}, {"id": 489, "seek": 264004, "start": 2663.56, "end": 2668.84, "text": " what we were saying with goals, isn't it? Because this skill program, someone just goes on Kaggle", "tokens": [51540, 437, 321, 645, 1566, 365, 5493, 11, 1943, 380, 309, 30, 1436, 341, 5389, 1461, 11, 1580, 445, 1709, 322, 48751, 22631, 51804], "temperature": 0.0, "avg_logprob": -0.1116172356334159, "compression_ratio": 1.6928571428571428, "no_speech_prob": 0.0009645079844631255}, {"id": 490, "seek": 266884, "start": 2668.84, "end": 2674.2000000000003, "text": " and they gives you this program and it seems to work. But it's horribly complicated. And how do", "tokens": [50364, 293, 436, 2709, 291, 341, 1461, 293, 309, 2544, 281, 589, 13, 583, 309, 311, 45028, 6179, 13, 400, 577, 360, 50632], "temperature": 0.0, "avg_logprob": -0.09362706732242665, "compression_ratio": 1.658008658008658, "no_speech_prob": 0.0019852654077112675}, {"id": 491, "seek": 266884, "start": 2674.2000000000003, "end": 2679.88, "text": " you know that the internal representations are in any way related to these abstractions? And do", "tokens": [50632, 291, 458, 300, 264, 6920, 33358, 366, 294, 604, 636, 4077, 281, 613, 12649, 626, 30, 400, 360, 50916], "temperature": 0.0, "avg_logprob": -0.09362706732242665, "compression_ratio": 1.658008658008658, "no_speech_prob": 0.0019852654077112675}, {"id": 492, "seek": 266884, "start": 2679.88, "end": 2685.4, "text": " you think that the abstractions as well are somehow universal in the same way Spelki would say that", "tokens": [50916, 291, 519, 300, 264, 12649, 626, 382, 731, 366, 6063, 11455, 294, 264, 912, 636, 1738, 338, 2984, 576, 584, 300, 51192], "temperature": 0.0, "avg_logprob": -0.09362706732242665, "compression_ratio": 1.658008658008658, "no_speech_prob": 0.0019852654077112675}, {"id": 493, "seek": 266884, "start": 2685.4, "end": 2692.92, "text": " the cognitive priors are? Yeah, I think it's something we can't say. And we don't know with", "tokens": [51192, 264, 15605, 1790, 830, 366, 30, 865, 11, 286, 519, 309, 311, 746, 321, 393, 380, 584, 13, 400, 321, 500, 380, 458, 365, 51568], "temperature": 0.0, "avg_logprob": -0.09362706732242665, "compression_ratio": 1.658008658008658, "no_speech_prob": 0.0019852654077112675}, {"id": 494, "seek": 269292, "start": 2693.0, "end": 2699.7200000000003, "text": " humans. And we don't know with machines, because both of these are very complex systems that are", "tokens": [50368, 6255, 13, 400, 321, 500, 380, 458, 365, 8379, 11, 570, 1293, 295, 613, 366, 588, 3997, 3652, 300, 366, 50704], "temperature": 0.0, "avg_logprob": -0.10725176852682362, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.0176976528018713}, {"id": 495, "seek": 269292, "start": 2699.7200000000003, "end": 2708.12, "text": " hard to kind of pull apart. What are the internal representations? So in most cases, we have to", "tokens": [50704, 1152, 281, 733, 295, 2235, 4936, 13, 708, 366, 264, 6920, 33358, 30, 407, 294, 881, 3331, 11, 321, 362, 281, 51124], "temperature": 0.0, "avg_logprob": -0.10725176852682362, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.0176976528018713}, {"id": 496, "seek": 269292, "start": 2708.12, "end": 2717.88, "text": " rely on behavior, which is very noisy. It can be misleading. And it turns out that humans", "tokens": [51124, 10687, 322, 5223, 11, 597, 307, 588, 24518, 13, 467, 393, 312, 36429, 13, 400, 309, 4523, 484, 300, 6255, 51612], "temperature": 0.0, "avg_logprob": -0.10725176852682362, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.0176976528018713}, {"id": 497, "seek": 271788, "start": 2718.6800000000003, "end": 2728.12, "text": " often are not, if you give them a problem, like a reasoning problem, in a familiar domain,", "tokens": [50404, 2049, 366, 406, 11, 498, 291, 976, 552, 257, 1154, 11, 411, 257, 21577, 1154, 11, 294, 257, 4963, 9274, 11, 50876], "temperature": 0.0, "avg_logprob": -0.117166625128852, "compression_ratio": 1.6566265060240963, "no_speech_prob": 0.0028002108447253704}, {"id": 498, "seek": 271788, "start": 2728.84, "end": 2734.04, "text": " they're much better at doing that problem as doing the exact same reasoning kind of abstract", "tokens": [50912, 436, 434, 709, 1101, 412, 884, 300, 1154, 382, 884, 264, 1900, 912, 21577, 733, 295, 12649, 51172], "temperature": 0.0, "avg_logprob": -0.117166625128852, "compression_ratio": 1.6566265060240963, "no_speech_prob": 0.0028002108447253704}, {"id": 499, "seek": 271788, "start": 2734.04, "end": 2741.7200000000003, "text": " reasoning task in an unfamiliar domain. And I think that's something that people have shown", "tokens": [51172, 21577, 5633, 294, 364, 29415, 9274, 13, 400, 286, 519, 300, 311, 746, 300, 561, 362, 4898, 51556], "temperature": 0.0, "avg_logprob": -0.117166625128852, "compression_ratio": 1.6566265060240963, "no_speech_prob": 0.0028002108447253704}, {"id": 500, "seek": 274172, "start": 2741.72, "end": 2750.6, "text": " is also true of large language models, because they've learned from human language and have", "tokens": [50364, 307, 611, 2074, 295, 2416, 2856, 5245, 11, 570, 436, 600, 3264, 490, 1952, 2856, 293, 362, 50808], "temperature": 0.0, "avg_logprob": -0.08245046545819538, "compression_ratio": 1.7799043062200957, "no_speech_prob": 0.0023227042984217405}, {"id": 501, "seek": 274172, "start": 2750.6, "end": 2755.9599999999996, "text": " incorporated sort of the statistics of some of the statistics of human experience that they're", "tokens": [50808, 21654, 1333, 295, 264, 12523, 295, 512, 295, 264, 12523, 295, 1952, 1752, 300, 436, 434, 51076], "temperature": 0.0, "avg_logprob": -0.08245046545819538, "compression_ratio": 1.7799043062200957, "no_speech_prob": 0.0023227042984217405}, {"id": 502, "seek": 274172, "start": 2755.9599999999996, "end": 2761.3999999999996, "text": " much better on familiar domains than on non-familiar domains. But the one thing that humans can do", "tokens": [51076, 709, 1101, 322, 4963, 25514, 813, 322, 2107, 12, 69, 27393, 25514, 13, 583, 264, 472, 551, 300, 6255, 393, 360, 51348], "temperature": 0.0, "avg_logprob": -0.08245046545819538, "compression_ratio": 1.7799043062200957, "no_speech_prob": 0.0023227042984217405}, {"id": 503, "seek": 274172, "start": 2761.3999999999996, "end": 2767.48, "text": " is often they can kind of transcend that and learn how to reason much more abstractly,", "tokens": [51348, 307, 2049, 436, 393, 733, 295, 28535, 300, 293, 1466, 577, 281, 1778, 709, 544, 12649, 356, 11, 51652], "temperature": 0.0, "avg_logprob": -0.08245046545819538, "compression_ratio": 1.7799043062200957, "no_speech_prob": 0.0023227042984217405}, {"id": 504, "seek": 276748, "start": 2767.8, "end": 2774.76, "text": " which I don't know if we will get to that point with language models yet. So there's a wonderful", "tokens": [50380, 597, 286, 500, 380, 458, 498, 321, 486, 483, 281, 300, 935, 365, 2856, 5245, 1939, 13, 407, 456, 311, 257, 3715, 50728], "temperature": 0.0, "avg_logprob": -0.20450563016145126, "compression_ratio": 1.4656084656084656, "no_speech_prob": 0.000666615494992584}, {"id": 505, "seek": 276748, "start": 2774.76, "end": 2784.76, "text": " paper that just came out from a group at MIT and some other places called, I can't remember", "tokens": [50728, 3035, 300, 445, 1361, 484, 490, 257, 1594, 412, 13100, 293, 512, 661, 3190, 1219, 11, 286, 393, 380, 1604, 51228], "temperature": 0.0, "avg_logprob": -0.20450563016145126, "compression_ratio": 1.4656084656084656, "no_speech_prob": 0.000666615494992584}, {"id": 506, "seek": 276748, "start": 2784.76, "end": 2791.72, "text": " what it was called, it was something like reasoning versus reciting. And what they do is", "tokens": [51228, 437, 309, 390, 1219, 11, 309, 390, 746, 411, 21577, 5717, 850, 1748, 13, 400, 437, 436, 360, 307, 51576], "temperature": 0.0, "avg_logprob": -0.20450563016145126, "compression_ratio": 1.4656084656084656, "no_speech_prob": 0.000666615494992584}, {"id": 507, "seek": 279172, "start": 2792.2799999999997, "end": 2799.48, "text": " they talk about this notion of a counterfactual task, which is if you can do one task, like", "tokens": [50392, 436, 751, 466, 341, 10710, 295, 257, 5682, 44919, 901, 5633, 11, 597, 307, 498, 291, 393, 360, 472, 5633, 11, 411, 50752], "temperature": 0.0, "avg_logprob": -0.11949671745300293, "compression_ratio": 1.6812227074235808, "no_speech_prob": 0.006486887112259865}, {"id": 508, "seek": 279172, "start": 2799.48, "end": 2804.8399999999997, "text": " addition and base 10, and you really understand that notion of addition, you should be able to do", "tokens": [50752, 4500, 293, 3096, 1266, 11, 293, 291, 534, 1223, 300, 10710, 295, 4500, 11, 291, 820, 312, 1075, 281, 360, 51020], "temperature": 0.0, "avg_logprob": -0.11949671745300293, "compression_ratio": 1.6812227074235808, "no_speech_prob": 0.006486887112259865}, {"id": 509, "seek": 279172, "start": 2804.8399999999997, "end": 2811.16, "text": " addition and base eight. And so, but you haven't had as much experience as like for a language model,", "tokens": [51020, 4500, 293, 3096, 3180, 13, 400, 370, 11, 457, 291, 2378, 380, 632, 382, 709, 1752, 382, 411, 337, 257, 2856, 2316, 11, 51336], "temperature": 0.0, "avg_logprob": -0.11949671745300293, "compression_ratio": 1.6812227074235808, "no_speech_prob": 0.006486887112259865}, {"id": 510, "seek": 279172, "start": 2811.16, "end": 2819.0, "text": " it's not almost all of the training data has to do with base 10. So, but can, so they tested,", "tokens": [51336, 309, 311, 406, 1920, 439, 295, 264, 3097, 1412, 575, 281, 360, 365, 3096, 1266, 13, 407, 11, 457, 393, 11, 370, 436, 8246, 11, 51728], "temperature": 0.0, "avg_logprob": -0.11949671745300293, "compression_ratio": 1.6812227074235808, "no_speech_prob": 0.006486887112259865}, {"id": 511, "seek": 281900, "start": 2819.0, "end": 2821.96, "text": " they did a whole bunch of these so-called counterfactual tasks", "tokens": [50364, 436, 630, 257, 1379, 3840, 295, 613, 370, 12, 11880, 5682, 44919, 901, 9608, 50512], "temperature": 0.0, "avg_logprob": -0.12486053862661686, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0007320523145608604}, {"id": 512, "seek": 281900, "start": 2823.24, "end": 2829.08, "text": " and showed that GPT-4 is really good at the original task, but not so good at the counterfactual task.", "tokens": [50576, 293, 4712, 300, 26039, 51, 12, 19, 307, 534, 665, 412, 264, 3380, 5633, 11, 457, 406, 370, 665, 412, 264, 5682, 44919, 901, 5633, 13, 50868], "temperature": 0.0, "avg_logprob": -0.12486053862661686, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0007320523145608604}, {"id": 513, "seek": 281900, "start": 2830.28, "end": 2834.92, "text": " So it's not, in some sense, it is relying on sort of patterns in its training data rather than", "tokens": [50928, 407, 309, 311, 406, 11, 294, 512, 2020, 11, 309, 307, 24140, 322, 1333, 295, 8294, 294, 1080, 3097, 1412, 2831, 813, 51160], "temperature": 0.0, "avg_logprob": -0.12486053862661686, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0007320523145608604}, {"id": 514, "seek": 281900, "start": 2836.2, "end": 2838.36, "text": " genuine abstraction.", "tokens": [51224, 16699, 37765, 13, 51332], "temperature": 0.0, "avg_logprob": -0.12486053862661686, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0007320523145608604}, {"id": 515, "seek": 281900, "start": 2839.88, "end": 2841.56, "text": " It's a stochastic parrot, right?", "tokens": [51408, 467, 311, 257, 342, 8997, 2750, 42462, 11, 558, 30, 51492], "temperature": 0.0, "avg_logprob": -0.12486053862661686, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0007320523145608604}, {"id": 516, "seek": 281900, "start": 2842.12, "end": 2845.64, "text": " Well, you know, it could be argued that humans do that a lot too.", "tokens": [51520, 1042, 11, 291, 458, 11, 309, 727, 312, 20219, 300, 6255, 360, 300, 257, 688, 886, 13, 51696], "temperature": 0.0, "avg_logprob": -0.12486053862661686, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0007320523145608604}, {"id": 517, "seek": 284564, "start": 2846.6, "end": 2851.3199999999997, "text": " I don't know if you called a stochastic parrot, but it's more like a pattern matcher.", "tokens": [50412, 286, 500, 380, 458, 498, 291, 1219, 257, 342, 8997, 2750, 42462, 11, 457, 309, 311, 544, 411, 257, 5102, 2995, 260, 13, 50648], "temperature": 0.0, "avg_logprob": -0.14592320268804376, "compression_ratio": 1.6633663366336633, "no_speech_prob": 0.0019873008131980896}, {"id": 518, "seek": 284564, "start": 2852.52, "end": 2859.56, "text": " And it's not, it's not reasoning about the things in the sense that we think of reasoning,", "tokens": [50708, 400, 309, 311, 406, 11, 309, 311, 406, 21577, 466, 264, 721, 294, 264, 2020, 300, 321, 519, 295, 21577, 11, 51060], "temperature": 0.0, "avg_logprob": -0.14592320268804376, "compression_ratio": 1.6633663366336633, "no_speech_prob": 0.0019873008131980896}, {"id": 519, "seek": 284564, "start": 2859.56, "end": 2866.2, "text": " you know, as sort of domain independent ability. It's very domain dependent.", "tokens": [51060, 291, 458, 11, 382, 1333, 295, 9274, 6695, 3485, 13, 467, 311, 588, 9274, 12334, 13, 51392], "temperature": 0.0, "avg_logprob": -0.14592320268804376, "compression_ratio": 1.6633663366336633, "no_speech_prob": 0.0019873008131980896}, {"id": 520, "seek": 284564, "start": 2869.16, "end": 2872.2799999999997, "text": " Yeah, so the difference is that I guess the difference I would say is that humans,", "tokens": [51540, 865, 11, 370, 264, 2649, 307, 300, 286, 2041, 264, 2649, 286, 576, 584, 307, 300, 6255, 11, 51696], "temperature": 0.0, "avg_logprob": -0.14592320268804376, "compression_ratio": 1.6633663366336633, "no_speech_prob": 0.0019873008131980896}, {"id": 521, "seek": 287228, "start": 2872.52, "end": 2883.0800000000004, "text": " it can kind of overcome that domain dependency in some cases and actually get to the true", "tokens": [50376, 309, 393, 733, 295, 10473, 300, 9274, 33621, 294, 512, 3331, 293, 767, 483, 281, 264, 2074, 50904], "temperature": 0.0, "avg_logprob": -0.1250250727631325, "compression_ratio": 1.5534883720930233, "no_speech_prob": 0.00040415767580270767}, {"id": 522, "seek": 287228, "start": 2883.0800000000004, "end": 2886.6800000000003, "text": " abstraction, but I don't know that language models can.", "tokens": [50904, 37765, 11, 457, 286, 500, 380, 458, 300, 2856, 5245, 393, 13, 51084], "temperature": 0.0, "avg_logprob": -0.1250250727631325, "compression_ratio": 1.5534883720930233, "no_speech_prob": 0.00040415767580270767}, {"id": 523, "seek": 287228, "start": 2888.36, "end": 2893.88, "text": " Yeah, I mean, there's a couple of things here. So first of all, these language models fail at", "tokens": [51168, 865, 11, 286, 914, 11, 456, 311, 257, 1916, 295, 721, 510, 13, 407, 700, 295, 439, 11, 613, 2856, 5245, 3061, 412, 51444], "temperature": 0.0, "avg_logprob": -0.1250250727631325, "compression_ratio": 1.5534883720930233, "no_speech_prob": 0.00040415767580270767}, {"id": 524, "seek": 287228, "start": 2893.88, "end": 2901.0800000000004, "text": " things which four-year-old children can do. And they can pass the bar exam, but as you've said", "tokens": [51444, 721, 597, 1451, 12, 5294, 12, 2641, 2227, 393, 360, 13, 400, 436, 393, 1320, 264, 2159, 1139, 11, 457, 382, 291, 600, 848, 51804], "temperature": 0.0, "avg_logprob": -0.1250250727631325, "compression_ratio": 1.5534883720930233, "no_speech_prob": 0.00040415767580270767}, {"id": 525, "seek": 290108, "start": 2901.08, "end": 2904.6, "text": " previously, you wouldn't want one of these things to actually go and practice more.", "tokens": [50364, 8046, 11, 291, 2759, 380, 528, 472, 295, 613, 721, 281, 767, 352, 293, 3124, 544, 13, 50540], "temperature": 0.0, "avg_logprob": -0.10496343983163078, "compression_ratio": 1.6646153846153846, "no_speech_prob": 0.0043627056293189526}, {"id": 526, "seek": 290108, "start": 2904.6, "end": 2911.56, "text": " My God, could you imagine the thought? And there was this Sparks of AGI paper where they gave this,", "tokens": [50540, 1222, 1265, 11, 727, 291, 3811, 264, 1194, 30, 400, 456, 390, 341, 1738, 20851, 295, 316, 26252, 3035, 689, 436, 2729, 341, 11, 50888], "temperature": 0.0, "avg_logprob": -0.10496343983163078, "compression_ratio": 1.6646153846153846, "no_speech_prob": 0.0043627056293189526}, {"id": 527, "seek": 290108, "start": 2911.56, "end": 2915.16, "text": " I mean, maybe you could recite this better than me, but there was the thing about the", "tokens": [50888, 286, 914, 11, 1310, 291, 727, 39434, 341, 1101, 813, 385, 11, 457, 456, 390, 264, 551, 466, 264, 51068], "temperature": 0.0, "avg_logprob": -0.10496343983163078, "compression_ratio": 1.6646153846153846, "no_speech_prob": 0.0043627056293189526}, {"id": 528, "seek": 290108, "start": 2915.16, "end": 2920.44, "text": " book Nine Eggs, a laptop, a bottle, and a nail. Can you balance it in a stable manner?", "tokens": [51068, 1446, 18939, 42486, 11, 257, 10732, 11, 257, 7817, 11, 293, 257, 10173, 13, 1664, 291, 4772, 309, 294, 257, 8351, 9060, 30, 51332], "temperature": 0.0, "avg_logprob": -0.10496343983163078, "compression_ratio": 1.6646153846153846, "no_speech_prob": 0.0043627056293189526}, {"id": 529, "seek": 290108, "start": 2920.44, "end": 2925.96, "text": " And this comes back to the experiment design because, my God, in any other discipline of science,", "tokens": [51332, 400, 341, 1487, 646, 281, 264, 5120, 1715, 570, 11, 452, 1265, 11, 294, 604, 661, 13635, 295, 3497, 11, 51608], "temperature": 0.0, "avg_logprob": -0.10496343983163078, "compression_ratio": 1.6646153846153846, "no_speech_prob": 0.0043627056293189526}, {"id": 530, "seek": 290108, "start": 2925.96, "end": 2930.7599999999998, "text": " they would just tear this apart. They would say, well, that's not very robust. I mean,", "tokens": [51608, 436, 576, 445, 12556, 341, 4936, 13, 814, 576, 584, 11, 731, 11, 300, 311, 406, 588, 13956, 13, 286, 914, 11, 51848], "temperature": 0.0, "avg_logprob": -0.10496343983163078, "compression_ratio": 1.6646153846153846, "no_speech_prob": 0.0043627056293189526}, {"id": 531, "seek": 293076, "start": 2930.76, "end": 2938.0400000000004, "text": " you came up with an example with a pudding, a marshmallow, a toothpick. How would it balance it?", "tokens": [50364, 291, 1361, 493, 365, 364, 1365, 365, 257, 29149, 11, 257, 43896, 11, 257, 27003, 618, 13, 1012, 576, 309, 4772, 309, 30, 50728], "temperature": 0.0, "avg_logprob": -0.15949283175998263, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.0009103482589125633}, {"id": 532, "seek": 293076, "start": 2940.0400000000004, "end": 2943.8, "text": " Yeah, did it not balance the full glass of water on top of the marshmallow?", "tokens": [50828, 865, 11, 630, 309, 406, 4772, 264, 1577, 4276, 295, 1281, 322, 1192, 295, 264, 43896, 30, 51016], "temperature": 0.0, "avg_logprob": -0.15949283175998263, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.0009103482589125633}, {"id": 533, "seek": 293076, "start": 2944.84, "end": 2949.96, "text": " Well, it stuck the toothpick into the marshmallow and then that's not exactly what we had in mind.", "tokens": [51068, 1042, 11, 309, 5541, 264, 27003, 618, 666, 264, 43896, 293, 550, 300, 311, 406, 2293, 437, 321, 632, 294, 1575, 13, 51324], "temperature": 0.0, "avg_logprob": -0.15949283175998263, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.0009103482589125633}, {"id": 534, "seek": 293076, "start": 2950.5200000000004, "end": 2954.44, "text": " No, and in fact, the Sparks of AGI paper, they explicitly said,", "tokens": [51352, 883, 11, 293, 294, 1186, 11, 264, 1738, 20851, 295, 316, 26252, 3035, 11, 436, 20803, 848, 11, 51548], "temperature": 0.0, "avg_logprob": -0.15949283175998263, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.0009103482589125633}, {"id": 535, "seek": 295444, "start": 2955.4, "end": 2959.32, "text": " we're doing anthropology, not cognitive science.", "tokens": [50412, 321, 434, 884, 44518, 11, 406, 15605, 3497, 13, 50608], "temperature": 0.0, "avg_logprob": -0.10283203125, "compression_ratio": 1.5253456221198156, "no_speech_prob": 0.018519889563322067}, {"id": 536, "seek": 295444, "start": 2960.6, "end": 2964.52, "text": " Well, that's not the way it was interpreted. Unfortunately, there are YouTube channels", "tokens": [50672, 1042, 11, 300, 311, 406, 264, 636, 309, 390, 26749, 13, 8590, 11, 456, 366, 3088, 9235, 50868], "temperature": 0.0, "avg_logprob": -0.10283203125, "compression_ratio": 1.5253456221198156, "no_speech_prob": 0.018519889563322067}, {"id": 537, "seek": 295444, "start": 2964.52, "end": 2971.16, "text": " now dedicated to educating people on AI and they're taking this as gospel. I mean, what's going on?", "tokens": [50868, 586, 8374, 281, 28835, 561, 322, 7318, 293, 436, 434, 1940, 341, 382, 14943, 13, 286, 914, 11, 437, 311, 516, 322, 30, 51200], "temperature": 0.0, "avg_logprob": -0.10283203125, "compression_ratio": 1.5253456221198156, "no_speech_prob": 0.018519889563322067}, {"id": 538, "seek": 295444, "start": 2971.88, "end": 2980.12, "text": " I think there's just not as much of a focus on sort of scientific method in this field as there", "tokens": [51236, 286, 519, 456, 311, 445, 406, 382, 709, 295, 257, 1879, 322, 1333, 295, 8134, 3170, 294, 341, 2519, 382, 456, 51648], "temperature": 0.0, "avg_logprob": -0.10283203125, "compression_ratio": 1.5253456221198156, "no_speech_prob": 0.018519889563322067}, {"id": 539, "seek": 298012, "start": 2980.12, "end": 2989.96, "text": " should be. And I think in science, if you're looking at a phenomenon and you're trying to", "tokens": [50364, 820, 312, 13, 400, 286, 519, 294, 3497, 11, 498, 291, 434, 1237, 412, 257, 14029, 293, 291, 434, 1382, 281, 50856], "temperature": 0.0, "avg_logprob": -0.0962982111506992, "compression_ratio": 1.6046511627906976, "no_speech_prob": 0.003823399543762207}, {"id": 540, "seek": 298012, "start": 2989.96, "end": 2997.24, "text": " replicate it, if it only replicates half the time, that's not a replication. That's not a", "tokens": [50856, 25356, 309, 11, 498, 309, 787, 3248, 299, 1024, 1922, 264, 565, 11, 300, 311, 406, 257, 39911, 13, 663, 311, 406, 257, 51220], "temperature": 0.0, "avg_logprob": -0.0962982111506992, "compression_ratio": 1.6046511627906976, "no_speech_prob": 0.003823399543762207}, {"id": 541, "seek": 298012, "start": 2997.24, "end": 3003.72, "text": " robust replication. Whereas for language models, people are saying, well, if it can do this task", "tokens": [51220, 13956, 39911, 13, 13813, 337, 2856, 5245, 11, 561, 366, 1566, 11, 731, 11, 498, 309, 393, 360, 341, 5633, 51544], "temperature": 0.0, "avg_logprob": -0.0962982111506992, "compression_ratio": 1.6046511627906976, "no_speech_prob": 0.003823399543762207}, {"id": 542, "seek": 300372, "start": 3003.72, "end": 3011.72, "text": " once in one particular circumstances, then it probably has this more general capability.", "tokens": [50364, 1564, 294, 472, 1729, 9121, 11, 550, 309, 1391, 575, 341, 544, 2674, 13759, 13, 50764], "temperature": 0.0, "avg_logprob": -0.13419709667082755, "compression_ratio": 1.4772727272727273, "no_speech_prob": 0.02842840552330017}, {"id": 543, "seek": 300372, "start": 3012.2799999999997, "end": 3018.4399999999996, "text": " So if it can do this stacking problem once, then wow, it has physical common sense.", "tokens": [50792, 407, 498, 309, 393, 360, 341, 41376, 1154, 1564, 11, 550, 6076, 11, 309, 575, 4001, 2689, 2020, 13, 51100], "temperature": 0.0, "avg_logprob": -0.13419709667082755, "compression_ratio": 1.4772727272727273, "no_speech_prob": 0.02842840552330017}, {"id": 544, "seek": 300372, "start": 3020.7599999999998, "end": 3028.52, "text": " And people with my marshmallow example, people, of course, jumped on it and said, wait,", "tokens": [51216, 400, 561, 365, 452, 43896, 1365, 11, 561, 11, 295, 1164, 11, 13864, 322, 309, 293, 848, 11, 1699, 11, 51604], "temperature": 0.0, "avg_logprob": -0.13419709667082755, "compression_ratio": 1.4772727272727273, "no_speech_prob": 0.02842840552330017}, {"id": 545, "seek": 302852, "start": 3028.52, "end": 3033.4, "text": " if you prompt it in a certain way and you do all this prompt engineering,", "tokens": [50364, 498, 291, 12391, 309, 294, 257, 1629, 636, 293, 291, 360, 439, 341, 12391, 7043, 11, 50608], "temperature": 0.0, "avg_logprob": -0.11301281987404337, "compression_ratio": 1.6477732793522266, "no_speech_prob": 0.002322431420907378}, {"id": 546, "seek": 302852, "start": 3033.4, "end": 3039.0, "text": " human engineering, it does it right. And then like, well, that's not the point.", "tokens": [50608, 1952, 7043, 11, 309, 775, 309, 558, 13, 400, 550, 411, 11, 731, 11, 300, 311, 406, 264, 935, 13, 50888], "temperature": 0.0, "avg_logprob": -0.11301281987404337, "compression_ratio": 1.6477732793522266, "no_speech_prob": 0.002322431420907378}, {"id": 547, "seek": 302852, "start": 3039.72, "end": 3044.7599999999998, "text": " The point is not any particular example. The point is figuring out how to test things", "tokens": [50924, 440, 935, 307, 406, 604, 1729, 1365, 13, 440, 935, 307, 15213, 484, 577, 281, 1500, 721, 51176], "temperature": 0.0, "avg_logprob": -0.11301281987404337, "compression_ratio": 1.6477732793522266, "no_speech_prob": 0.002322431420907378}, {"id": 548, "seek": 302852, "start": 3044.7599999999998, "end": 3051.4, "text": " so that you actually have some kind of robust ability for replicating a capability,", "tokens": [51176, 370, 300, 291, 767, 362, 512, 733, 295, 13956, 3485, 337, 3248, 30541, 257, 13759, 11, 51508], "temperature": 0.0, "avg_logprob": -0.11301281987404337, "compression_ratio": 1.6477732793522266, "no_speech_prob": 0.002322431420907378}, {"id": 549, "seek": 302852, "start": 3052.68, "end": 3057.08, "text": " which we haven't seen with experiments on language models very much. I mean, people", "tokens": [51572, 597, 321, 2378, 380, 1612, 365, 12050, 322, 2856, 5245, 588, 709, 13, 286, 914, 11, 561, 51792], "temperature": 0.0, "avg_logprob": -0.11301281987404337, "compression_ratio": 1.6477732793522266, "no_speech_prob": 0.002322431420907378}, {"id": 550, "seek": 305708, "start": 3057.08, "end": 3062.84, "text": " are starting to do this. People are starting to do this kind of more scientifically grounded,", "tokens": [50364, 366, 2891, 281, 360, 341, 13, 3432, 366, 2891, 281, 360, 341, 733, 295, 544, 39719, 23535, 11, 50652], "temperature": 0.0, "avg_logprob": -0.1409683969285753, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.001284047611989081}, {"id": 551, "seek": 305708, "start": 3062.84, "end": 3070.36, "text": " experimental method on language models, but it's still not very, there's not very much of it.", "tokens": [50652, 17069, 3170, 322, 2856, 5245, 11, 457, 309, 311, 920, 406, 588, 11, 456, 311, 406, 588, 709, 295, 309, 13, 51028], "temperature": 0.0, "avg_logprob": -0.1409683969285753, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.001284047611989081}, {"id": 552, "seek": 305708, "start": 3071.24, "end": 3076.2, "text": " So you might appreciate a phrase I recently coined because it covers this leakage too,", "tokens": [51072, 407, 291, 1062, 4449, 257, 9535, 286, 3938, 45222, 570, 309, 10538, 341, 47799, 886, 11, 51320], "temperature": 0.0, "avg_logprob": -0.1409683969285753, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.001284047611989081}, {"id": 553, "seek": 305708, "start": 3076.2, "end": 3082.12, "text": " of like sort of leakage of human knowledge, which is if you can't find the priors, look in the mirror.", "tokens": [51320, 295, 411, 1333, 295, 47799, 295, 1952, 3601, 11, 597, 307, 498, 291, 393, 380, 915, 264, 1790, 830, 11, 574, 294, 264, 8013, 13, 51616], "temperature": 0.0, "avg_logprob": -0.1409683969285753, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.001284047611989081}, {"id": 554, "seek": 308212, "start": 3083.08, "end": 3087.3199999999997, "text": " It's like, we have to learn how to do experimental science and computer science,", "tokens": [50412, 467, 311, 411, 11, 321, 362, 281, 1466, 577, 281, 360, 17069, 3497, 293, 3820, 3497, 11, 50624], "temperature": 0.0, "avg_logprob": -0.2193129436079278, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.01565726473927498}, {"id": 555, "seek": 308212, "start": 3087.3199999999997, "end": 3092.2799999999997, "text": " and you've got to guard against this type of leak at Drillian, human engineering,", "tokens": [50624, 293, 291, 600, 658, 281, 6290, 1970, 341, 2010, 295, 17143, 412, 2491, 373, 952, 11, 1952, 7043, 11, 50872], "temperature": 0.0, "avg_logprob": -0.2193129436079278, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.01565726473927498}, {"id": 556, "seek": 308212, "start": 3092.2799999999997, "end": 3097.96, "text": " and over-involved and whatever. And this is why I really want to collaborate with people in", "tokens": [50872, 293, 670, 12, 259, 9646, 937, 293, 2035, 13, 400, 341, 307, 983, 286, 534, 528, 281, 18338, 365, 561, 294, 51156], "temperature": 0.0, "avg_logprob": -0.2193129436079278, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.01565726473927498}, {"id": 557, "seek": 308212, "start": 3097.96, "end": 3104.68, "text": " developmental psychology, with people in animal cognition who face this kind of issue all the", "tokens": [51156, 30160, 15105, 11, 365, 561, 294, 5496, 46905, 567, 1851, 341, 733, 295, 2734, 439, 264, 51492], "temperature": 0.0, "avg_logprob": -0.2193129436079278, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.01565726473927498}, {"id": 558, "seek": 310468, "start": 3104.68, "end": 3115.7999999999997, "text": " time. And one example was, I got from a developmental psychologist was that sometimes", "tokens": [50364, 565, 13, 400, 472, 1365, 390, 11, 286, 658, 490, 257, 30160, 29514, 390, 300, 2171, 50920], "temperature": 0.0, "avg_logprob": -0.10666808276109292, "compression_ratio": 1.4858757062146892, "no_speech_prob": 0.09801806509494781}, {"id": 559, "seek": 310468, "start": 3115.7999999999997, "end": 3125.48, "text": " like a three-year-old can tell you something like four plus three is seven, but if you say,", "tokens": [50920, 411, 257, 1045, 12, 5294, 12, 2641, 393, 980, 291, 746, 411, 1451, 1804, 1045, 307, 3407, 11, 457, 498, 291, 584, 11, 51404], "temperature": 0.0, "avg_logprob": -0.10666808276109292, "compression_ratio": 1.4858757062146892, "no_speech_prob": 0.09801806509494781}, {"id": 560, "seek": 310468, "start": 3125.48, "end": 3130.04, "text": " if you give them a bunch of marbles and say, pick out four of them, they can't do it.", "tokens": [51404, 498, 291, 976, 552, 257, 3840, 295, 1849, 8806, 293, 584, 11, 1888, 484, 1451, 295, 552, 11, 436, 393, 380, 360, 309, 13, 51632], "temperature": 0.0, "avg_logprob": -0.10666808276109292, "compression_ratio": 1.4858757062146892, "no_speech_prob": 0.09801806509494781}, {"id": 561, "seek": 313004, "start": 3130.36, "end": 3137.48, "text": " So there you say, okay, that this kid doesn't understand the concept of four,", "tokens": [50380, 407, 456, 291, 584, 11, 1392, 11, 300, 341, 1636, 1177, 380, 1223, 264, 3410, 295, 1451, 11, 50736], "temperature": 0.0, "avg_logprob": -0.15185848502225655, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.0014100176049396396}, {"id": 562, "seek": 313004, "start": 3137.48, "end": 3143.64, "text": " they're kind of just reciting something that they've heard. And this is the kind of experiments", "tokens": [50736, 436, 434, 733, 295, 445, 850, 1748, 746, 300, 436, 600, 2198, 13, 400, 341, 307, 264, 733, 295, 12050, 51044], "temperature": 0.0, "avg_logprob": -0.15185848502225655, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.0014100176049396396}, {"id": 563, "seek": 313004, "start": 3143.64, "end": 3150.04, "text": " that people in developmental psychology do all the time to really tease out what the system,", "tokens": [51044, 300, 561, 294, 30160, 15105, 360, 439, 264, 565, 281, 534, 30444, 484, 437, 264, 1185, 11, 51364], "temperature": 0.0, "avg_logprob": -0.15185848502225655, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.0014100176049396396}, {"id": 564, "seek": 313004, "start": 3150.04, "end": 3156.68, "text": " what babies and children know and what they can do. And it's not an easy thing to do in", "tokens": [51364, 437, 10917, 293, 2227, 458, 293, 437, 436, 393, 360, 13, 400, 309, 311, 406, 364, 1858, 551, 281, 360, 294, 51696], "temperature": 0.0, "avg_logprob": -0.15185848502225655, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.0014100176049396396}, {"id": 565, "seek": 315668, "start": 3157.3999999999996, "end": 3163.7999999999997, "text": " this kind of experiment. The problem with that is it's extremely complex and requires so much", "tokens": [50400, 341, 733, 295, 5120, 13, 440, 1154, 365, 300, 307, 309, 311, 4664, 3997, 293, 7029, 370, 709, 50720], "temperature": 0.0, "avg_logprob": -0.11991401710132561, "compression_ratio": 1.6063829787234043, "no_speech_prob": 0.002532190177589655}, {"id": 566, "seek": 315668, "start": 3163.7999999999997, "end": 3168.6, "text": " domain knowledge. So it takes a very long time, because I think there was another article that", "tokens": [50720, 9274, 3601, 13, 407, 309, 2516, 257, 588, 938, 565, 11, 570, 286, 519, 456, 390, 1071, 7222, 300, 50960], "temperature": 0.0, "avg_logprob": -0.11991401710132561, "compression_ratio": 1.6063829787234043, "no_speech_prob": 0.002532190177589655}, {"id": 567, "seek": 315668, "start": 3168.6, "end": 3174.44, "text": " spoke about how we study rats. And those folks in different disciplines, they're really,", "tokens": [50960, 7179, 466, 577, 321, 2979, 25691, 13, 400, 729, 4024, 294, 819, 21919, 11, 436, 434, 534, 11, 51252], "temperature": 0.0, "avg_logprob": -0.11991401710132561, "compression_ratio": 1.6063829787234043, "no_speech_prob": 0.002532190177589655}, {"id": 568, "seek": 315668, "start": 3174.44, "end": 3180.12, "text": " really good experimental design, and they have experts who kind of create very, very clear", "tokens": [51252, 534, 665, 17069, 1715, 11, 293, 436, 362, 8572, 567, 733, 295, 1884, 588, 11, 588, 1850, 51536], "temperature": 0.0, "avg_logprob": -0.11991401710132561, "compression_ratio": 1.6063829787234043, "no_speech_prob": 0.002532190177589655}, {"id": 569, "seek": 315668, "start": 3180.12, "end": 3186.04, "text": " criteria for measuring this behavior. And with AI, everything's going up on archive,", "tokens": [51536, 11101, 337, 13389, 341, 5223, 13, 400, 365, 7318, 11, 1203, 311, 516, 493, 322, 23507, 11, 51832], "temperature": 0.0, "avg_logprob": -0.11991401710132561, "compression_ratio": 1.6063829787234043, "no_speech_prob": 0.002532190177589655}, {"id": 570, "seek": 318604, "start": 3186.04, "end": 3189.96, "text": " and everything's going a million miles an hour. And by the time you actually design", "tokens": [50364, 293, 1203, 311, 516, 257, 2459, 6193, 364, 1773, 13, 400, 538, 264, 565, 291, 767, 1715, 50560], "temperature": 0.0, "avg_logprob": -0.10809745187834492, "compression_ratio": 1.625, "no_speech_prob": 0.0005101971328258514}, {"id": 571, "seek": 318604, "start": 3189.96, "end": 3193.72, "text": " a systematic rigorous study for the first thing, there's already another paper coming out,", "tokens": [50560, 257, 27249, 29882, 2979, 337, 264, 700, 551, 11, 456, 311, 1217, 1071, 3035, 1348, 484, 11, 50748], "temperature": 0.0, "avg_logprob": -0.10809745187834492, "compression_ratio": 1.625, "no_speech_prob": 0.0005101971328258514}, {"id": 572, "seek": 318604, "start": 3193.72, "end": 3197.16, "text": " which is claiming to do it differently. So we just can't keep up. It's just,", "tokens": [50748, 597, 307, 19232, 281, 360, 309, 7614, 13, 407, 321, 445, 393, 380, 1066, 493, 13, 467, 311, 445, 11, 50920], "temperature": 0.0, "avg_logprob": -0.10809745187834492, "compression_ratio": 1.625, "no_speech_prob": 0.0005101971328258514}, {"id": 573, "seek": 318604, "start": 3197.16, "end": 3202.44, "text": " it's an absolute nightmare. Absolutely. Yeah. Agreed.", "tokens": [50920, 309, 311, 364, 8236, 18724, 13, 7021, 13, 865, 13, 29324, 292, 13, 51184], "temperature": 0.0, "avg_logprob": -0.10809745187834492, "compression_ratio": 1.625, "no_speech_prob": 0.0005101971328258514}, {"id": 574, "seek": 318604, "start": 3204.2799999999997, "end": 3207.88, "text": " I want to just, so I'll quickly touch on one more thing. And I know Keith wants to go into", "tokens": [51276, 286, 528, 281, 445, 11, 370, 286, 603, 2661, 2557, 322, 472, 544, 551, 13, 400, 286, 458, 20613, 2738, 281, 352, 666, 51456], "temperature": 0.0, "avg_logprob": -0.10809745187834492, "compression_ratio": 1.625, "no_speech_prob": 0.0005101971328258514}, {"id": 575, "seek": 318604, "start": 3207.88, "end": 3212.52, "text": " complexity. But yeah, so the information leakage is a problem. The brittleness is a problem. I do", "tokens": [51456, 14024, 13, 583, 1338, 11, 370, 264, 1589, 47799, 307, 257, 1154, 13, 440, 738, 593, 45887, 307, 257, 1154, 13, 286, 360, 51688], "temperature": 0.0, "avg_logprob": -0.10809745187834492, "compression_ratio": 1.625, "no_speech_prob": 0.0005101971328258514}, {"id": 576, "seek": 321252, "start": 3212.52, "end": 3219.08, "text": " think of these GPT models a bit like a database. And so anything that requires physical grounding,", "tokens": [50364, 519, 295, 613, 26039, 51, 5245, 257, 857, 411, 257, 8149, 13, 400, 370, 1340, 300, 7029, 4001, 46727, 11, 50692], "temperature": 0.0, "avg_logprob": -0.08694580219410084, "compression_ratio": 1.709480122324159, "no_speech_prob": 0.005527023691684008}, {"id": 577, "seek": 321252, "start": 3219.08, "end": 3222.68, "text": " of course, doesn't work very well. Some things work surprisingly well, like, you know,", "tokens": [50692, 295, 1164, 11, 1177, 380, 589, 588, 731, 13, 2188, 721, 589, 17600, 731, 11, 411, 11, 291, 458, 11, 50872], "temperature": 0.0, "avg_logprob": -0.08694580219410084, "compression_ratio": 1.709480122324159, "no_speech_prob": 0.005527023691684008}, {"id": 578, "seek": 321252, "start": 3222.68, "end": 3226.7599999999998, "text": " programming, because programming is mostly in the internet, it still has all sorts of", "tokens": [50872, 9410, 11, 570, 9410, 307, 5240, 294, 264, 4705, 11, 309, 920, 575, 439, 7527, 295, 51076], "temperature": 0.0, "avg_logprob": -0.08694580219410084, "compression_ratio": 1.709480122324159, "no_speech_prob": 0.005527023691684008}, {"id": 579, "seek": 321252, "start": 3226.7599999999998, "end": 3233.32, "text": " failure modes, and it's not very reliable, but it's surprisingly reliable. But you put a paper", "tokens": [51076, 7763, 14068, 11, 293, 309, 311, 406, 588, 12924, 11, 457, 309, 311, 17600, 12924, 13, 583, 291, 829, 257, 3035, 51404], "temperature": 0.0, "avg_logprob": -0.08694580219410084, "compression_ratio": 1.709480122324159, "no_speech_prob": 0.005527023691684008}, {"id": 580, "seek": 321252, "start": 3233.32, "end": 3237.16, "text": " out with Tanenbaum and a whole bunch of other people. And you actually said, well, if you want", "tokens": [51404, 484, 365, 17046, 268, 46641, 293, 257, 1379, 3840, 295, 661, 561, 13, 400, 291, 767, 848, 11, 731, 11, 498, 291, 528, 51596], "temperature": 0.0, "avg_logprob": -0.08694580219410084, "compression_ratio": 1.709480122324159, "no_speech_prob": 0.005527023691684008}, {"id": 581, "seek": 321252, "start": 3237.16, "end": 3242.28, "text": " some policy advice, if you really want to think about how we can improve the situation, you said,", "tokens": [51596, 512, 3897, 5192, 11, 498, 291, 534, 528, 281, 519, 466, 577, 321, 393, 3470, 264, 2590, 11, 291, 848, 11, 51852], "temperature": 0.0, "avg_logprob": -0.08694580219410084, "compression_ratio": 1.709480122324159, "no_speech_prob": 0.005527023691684008}, {"id": 582, "seek": 324228, "start": 3242.36, "end": 3248.84, "text": " aggregating benchmarks and also giving instance level failure modes can actually help us understand", "tokens": [50368, 16743, 990, 43751, 293, 611, 2902, 5197, 1496, 7763, 14068, 393, 767, 854, 505, 1223, 50692], "temperature": 0.0, "avg_logprob": -0.10390351853280697, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.0025407581124454737}, {"id": 583, "seek": 324228, "start": 3248.84, "end": 3255.0800000000004, "text": " why things went wrong or, you know, why things gave us the right answer for the wrong reasons.", "tokens": [50692, 983, 721, 1437, 2085, 420, 11, 291, 458, 11, 983, 721, 2729, 505, 264, 558, 1867, 337, 264, 2085, 4112, 13, 51004], "temperature": 0.0, "avg_logprob": -0.10390351853280697, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.0025407581124454737}, {"id": 584, "seek": 324228, "start": 3255.7200000000003, "end": 3260.44, "text": " And there were all sorts of limiting factors, you said. You know, we have this kind of", "tokens": [51036, 400, 456, 645, 439, 7527, 295, 22083, 6771, 11, 291, 848, 13, 509, 458, 11, 321, 362, 341, 733, 295, 51272], "temperature": 0.0, "avg_logprob": -0.10390351853280697, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.0025407581124454737}, {"id": 585, "seek": 324228, "start": 3260.44, "end": 3265.88, "text": " censorship by concision. You're only allowed to have seven pages in your conference workshop paper,", "tokens": [51272, 40985, 538, 1588, 1991, 13, 509, 434, 787, 4350, 281, 362, 3407, 7183, 294, 428, 7586, 13541, 3035, 11, 51544], "temperature": 0.0, "avg_logprob": -0.10390351853280697, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.0025407581124454737}, {"id": 586, "seek": 324228, "start": 3265.88, "end": 3269.6400000000003, "text": " and there's no policy about this. So can you give us a heads up on that?", "tokens": [51544, 293, 456, 311, 572, 3897, 466, 341, 13, 407, 393, 291, 976, 505, 257, 8050, 493, 322, 300, 30, 51732], "temperature": 0.0, "avg_logprob": -0.10390351853280697, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.0025407581124454737}, {"id": 587, "seek": 326964, "start": 3270.2799999999997, "end": 3276.6, "text": " Yeah, I mean, you know, traditionally in machine learning, people use accuracy and similar kinds", "tokens": [50396, 865, 11, 286, 914, 11, 291, 458, 11, 19067, 294, 3479, 2539, 11, 561, 764, 14170, 293, 2531, 3685, 50712], "temperature": 0.0, "avg_logprob": -0.12234998518420805, "compression_ratio": 1.6637931034482758, "no_speech_prob": 0.0002959080447908491}, {"id": 588, "seek": 326964, "start": 3276.6, "end": 3284.52, "text": " of aggregate measures to report their results. And, you know, if someone tells you that the accuracy", "tokens": [50712, 295, 26118, 8000, 281, 2275, 641, 3542, 13, 400, 11, 291, 458, 11, 498, 1580, 5112, 291, 300, 264, 14170, 51108], "temperature": 0.0, "avg_logprob": -0.12234998518420805, "compression_ratio": 1.6637931034482758, "no_speech_prob": 0.0002959080447908491}, {"id": 589, "seek": 326964, "start": 3284.52, "end": 3293.0, "text": " was, you know, 78%, what does that tell you exactly? I think, you know, this gets back to the idea of", "tokens": [51108, 390, 11, 291, 458, 11, 26369, 8923, 437, 775, 300, 980, 291, 2293, 30, 286, 519, 11, 291, 458, 11, 341, 2170, 646, 281, 264, 1558, 295, 51532], "temperature": 0.0, "avg_logprob": -0.12234998518420805, "compression_ratio": 1.6637931034482758, "no_speech_prob": 0.0002959080447908491}, {"id": 590, "seek": 326964, "start": 3293.0, "end": 3297.64, "text": " scientific method. You know, in science, the most interesting things are the failures.", "tokens": [51532, 8134, 3170, 13, 509, 458, 11, 294, 3497, 11, 264, 881, 1880, 721, 366, 264, 20774, 13, 51764], "temperature": 0.0, "avg_logprob": -0.12234998518420805, "compression_ratio": 1.6637931034482758, "no_speech_prob": 0.0002959080447908491}, {"id": 591, "seek": 329764, "start": 3298.6, "end": 3301.7999999999997, "text": " And those are the things you really have to focus on. It's like, why did it fail?", "tokens": [50412, 400, 729, 366, 264, 721, 291, 534, 362, 281, 1879, 322, 13, 467, 311, 411, 11, 983, 630, 309, 3061, 30, 50572], "temperature": 0.0, "avg_logprob": -0.10274800486948299, "compression_ratio": 1.5529953917050692, "no_speech_prob": 0.0005357486079446971}, {"id": 592, "seek": 329764, "start": 3302.44, "end": 3308.68, "text": " And that's what we need to know to understand machine learning systems. So the most simple", "tokens": [50604, 400, 300, 311, 437, 321, 643, 281, 458, 281, 1223, 3479, 2539, 3652, 13, 407, 264, 881, 2199, 50916], "temperature": 0.0, "avg_logprob": -0.10274800486948299, "compression_ratio": 1.5529953917050692, "no_speech_prob": 0.0005357486079446971}, {"id": 593, "seek": 329764, "start": 3309.64, "end": 3312.8399999999997, "text": " kind of reporting would be just to report for every instance in your", "tokens": [50964, 733, 295, 10031, 576, 312, 445, 281, 2275, 337, 633, 5197, 294, 428, 51124], "temperature": 0.0, "avg_logprob": -0.10274800486948299, "compression_ratio": 1.5529953917050692, "no_speech_prob": 0.0005357486079446971}, {"id": 594, "seek": 329764, "start": 3313.72, "end": 3320.52, "text": " benchmark, your data set. How did the system do? What was its answer? And that's not, you know,", "tokens": [51168, 18927, 11, 428, 1412, 992, 13, 1012, 630, 264, 1185, 360, 30, 708, 390, 1080, 1867, 30, 400, 300, 311, 406, 11, 291, 458, 11, 51508], "temperature": 0.0, "avg_logprob": -0.10274800486948299, "compression_ratio": 1.5529953917050692, "no_speech_prob": 0.0005357486079446971}, {"id": 595, "seek": 332052, "start": 3321.32, "end": 3330.36, "text": " it doesn't seem like a very big ask, but it would be very useful. And we now have in conferences,", "tokens": [50404, 309, 1177, 380, 1643, 411, 257, 588, 955, 1029, 11, 457, 309, 576, 312, 588, 4420, 13, 400, 321, 586, 362, 294, 22032, 11, 50856], "temperature": 0.0, "avg_logprob": -0.1339501289472188, "compression_ratio": 1.5181347150259068, "no_speech_prob": 0.001225437968969345}, {"id": 596, "seek": 332052, "start": 3331.08, "end": 3336.44, "text": " you're allowed to have some kind of supplementary material online. So you could have this available.", "tokens": [50892, 291, 434, 4350, 281, 362, 512, 733, 295, 15436, 822, 2527, 2950, 13, 407, 291, 727, 362, 341, 2435, 13, 51160], "temperature": 0.0, "avg_logprob": -0.1339501289472188, "compression_ratio": 1.5181347150259068, "no_speech_prob": 0.001225437968969345}, {"id": 597, "seek": 332052, "start": 3337.0, "end": 3345.32, "text": " And we did this for our concept arc paper. We showed for every instance, like what humans did,", "tokens": [51188, 400, 321, 630, 341, 337, 527, 3410, 10346, 3035, 13, 492, 4712, 337, 633, 5197, 11, 411, 437, 6255, 630, 11, 51604], "temperature": 0.0, "avg_logprob": -0.1339501289472188, "compression_ratio": 1.5181347150259068, "no_speech_prob": 0.001225437968969345}, {"id": 598, "seek": 334532, "start": 3345.32, "end": 3352.1200000000003, "text": " what machines did, we tried to analyze the errors of the system. And I think this these kinds of", "tokens": [50364, 437, 8379, 630, 11, 321, 3031, 281, 12477, 264, 13603, 295, 264, 1185, 13, 400, 286, 519, 341, 613, 3685, 295, 50704], "temperature": 0.0, "avg_logprob": -0.14483170760305306, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.003172163153067231}, {"id": 599, "seek": 334532, "start": 3352.1200000000003, "end": 3357.32, "text": " reporting will be will give us a lot more insight into what these systems are doing and what their", "tokens": [50704, 10031, 486, 312, 486, 976, 505, 257, 688, 544, 11269, 666, 437, 613, 3652, 366, 884, 293, 437, 641, 50964], "temperature": 0.0, "avg_logprob": -0.14483170760305306, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.003172163153067231}, {"id": 600, "seek": 334532, "start": 3357.32, "end": 3365.48, "text": " like real capabilities are. Yeah. And it's, and back to the difficulty that Tim mentioned earlier,", "tokens": [50964, 411, 957, 10862, 366, 13, 865, 13, 400, 309, 311, 11, 293, 646, 281, 264, 10360, 300, 7172, 2835, 3071, 11, 51372], "temperature": 0.0, "avg_logprob": -0.14483170760305306, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.003172163153067231}, {"id": 601, "seek": 334532, "start": 3366.1200000000003, "end": 3370.84, "text": " totally agree. And this is work that has to be done. Like if, if we are going to build a science", "tokens": [51404, 3879, 3986, 13, 400, 341, 307, 589, 300, 575, 281, 312, 1096, 13, 1743, 498, 11, 498, 321, 366, 516, 281, 1322, 257, 3497, 51640], "temperature": 0.0, "avg_logprob": -0.14483170760305306, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.003172163153067231}, {"id": 602, "seek": 337084, "start": 3370.84, "end": 3377.0, "text": " of machine cognition, you know, this work has to be done. Yeah, I think. And I just want to shout", "tokens": [50364, 295, 3479, 46905, 11, 291, 458, 11, 341, 589, 575, 281, 312, 1096, 13, 865, 11, 286, 519, 13, 400, 286, 445, 528, 281, 8043, 50672], "temperature": 0.0, "avg_logprob": -0.11014890670776367, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.002433976624161005}, {"id": 603, "seek": 337084, "start": 3377.0, "end": 3382.92, "text": " out to Ryan Bernal, who spearheaded that paper, because he really is the one pushing for all", "tokens": [50672, 484, 281, 9116, 10781, 304, 11, 567, 26993, 28409, 300, 3035, 11, 570, 415, 534, 307, 264, 472, 7380, 337, 439, 50968], "temperature": 0.0, "avg_logprob": -0.11014890670776367, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.002433976624161005}, {"id": 604, "seek": 337084, "start": 3382.92, "end": 3389.88, "text": " this. And I think it's fantastic. So just in the last few minutes, you know, since we have you,", "tokens": [50968, 341, 13, 400, 286, 519, 309, 311, 5456, 13, 407, 445, 294, 264, 1036, 1326, 2077, 11, 291, 458, 11, 1670, 321, 362, 291, 11, 51316], "temperature": 0.0, "avg_logprob": -0.11014890670776367, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.002433976624161005}, {"id": 605, "seek": 337084, "start": 3390.6800000000003, "end": 3396.84, "text": " complexity and complexity theory is a topic I really love. I'm not an expert in it at all,", "tokens": [51356, 14024, 293, 14024, 5261, 307, 257, 4829, 286, 534, 959, 13, 286, 478, 406, 364, 5844, 294, 309, 412, 439, 11, 51664], "temperature": 0.0, "avg_logprob": -0.11014890670776367, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.002433976624161005}, {"id": 606, "seek": 339684, "start": 3396.84, "end": 3401.48, "text": " but I like to think about I like to explore it. I'm just curious, you know, from your perspective,", "tokens": [50364, 457, 286, 411, 281, 519, 466, 286, 411, 281, 6839, 309, 13, 286, 478, 445, 6369, 11, 291, 458, 11, 490, 428, 4585, 11, 50596], "temperature": 0.0, "avg_logprob": -0.09088091850280762, "compression_ratio": 1.758364312267658, "no_speech_prob": 0.0005032828194089234}, {"id": 607, "seek": 339684, "start": 3401.48, "end": 3406.52, "text": " um, what are some of the most interesting things happening right now in complexity theory? And", "tokens": [50596, 1105, 11, 437, 366, 512, 295, 264, 881, 1880, 721, 2737, 558, 586, 294, 14024, 5261, 30, 400, 50848], "temperature": 0.0, "avg_logprob": -0.09088091850280762, "compression_ratio": 1.758364312267658, "no_speech_prob": 0.0005032828194089234}, {"id": 608, "seek": 339684, "start": 3406.52, "end": 3411.56, "text": " if I wanted to go learn a bit more and check out just some cool, you know, latest stuff, what should", "tokens": [50848, 498, 286, 1415, 281, 352, 1466, 257, 857, 544, 293, 1520, 484, 445, 512, 1627, 11, 291, 458, 11, 6792, 1507, 11, 437, 820, 51100], "temperature": 0.0, "avg_logprob": -0.09088091850280762, "compression_ratio": 1.758364312267658, "no_speech_prob": 0.0005032828194089234}, {"id": 609, "seek": 339684, "start": 3411.56, "end": 3418.04, "text": " what should we go look at? So I think there's, you know, there's a lot of interesting stuff going on,", "tokens": [51100, 437, 820, 321, 352, 574, 412, 30, 407, 286, 519, 456, 311, 11, 291, 458, 11, 456, 311, 257, 688, 295, 1880, 1507, 516, 322, 11, 51424], "temperature": 0.0, "avg_logprob": -0.09088091850280762, "compression_ratio": 1.758364312267658, "no_speech_prob": 0.0005032828194089234}, {"id": 610, "seek": 339684, "start": 3418.04, "end": 3423.8, "text": " obviously, and complex systems is a huge umbrella for a lot of research. But", "tokens": [51424, 2745, 11, 293, 3997, 3652, 307, 257, 2603, 21925, 337, 257, 688, 295, 2132, 13, 583, 51712], "temperature": 0.0, "avg_logprob": -0.09088091850280762, "compression_ratio": 1.758364312267658, "no_speech_prob": 0.0005032828194089234}, {"id": 611, "seek": 342380, "start": 3424.76, "end": 3431.48, "text": " if you're interested in the one big topic that people look at is called scaling. And it's the", "tokens": [50412, 498, 291, 434, 3102, 294, 264, 472, 955, 4829, 300, 561, 574, 412, 307, 1219, 21589, 13, 400, 309, 311, 264, 50748], "temperature": 0.0, "avg_logprob": -0.16998699733189174, "compression_ratio": 1.5319148936170213, "no_speech_prob": 0.00011958000686718151}, {"id": 612, "seek": 342380, "start": 3431.48, "end": 3438.1200000000003, "text": " question of like, what happens to a system as it gets bigger in some sense? So this started out", "tokens": [50748, 1168, 295, 411, 11, 437, 2314, 281, 257, 1185, 382, 309, 2170, 3801, 294, 512, 2020, 30, 407, 341, 1409, 484, 51080], "temperature": 0.0, "avg_logprob": -0.16998699733189174, "compression_ratio": 1.5319148936170213, "no_speech_prob": 0.00011958000686718151}, {"id": 613, "seek": 342380, "start": 3438.1200000000003, "end": 3447.88, "text": " with some work on the sort of energy use of systems like animals as they as their maths increases.", "tokens": [51080, 365, 512, 589, 322, 264, 1333, 295, 2281, 764, 295, 3652, 411, 4882, 382, 436, 382, 641, 36287, 8637, 13, 51568], "temperature": 0.0, "avg_logprob": -0.16998699733189174, "compression_ratio": 1.5319148936170213, "no_speech_prob": 0.00011958000686718151}, {"id": 614, "seek": 344788, "start": 3448.6800000000003, "end": 3455.32, "text": " And people discovered some really interesting scaling laws that were very non-intuitive and", "tokens": [50404, 400, 561, 6941, 512, 534, 1880, 21589, 6064, 300, 645, 588, 2107, 12, 686, 48314, 293, 50736], "temperature": 0.0, "avg_logprob": -0.11111742112694717, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.03208032250404358}, {"id": 615, "seek": 344788, "start": 3455.32, "end": 3462.84, "text": " they were able to explain these laws using ideas like fractal fractals and the fractal structure", "tokens": [50736, 436, 645, 1075, 281, 2903, 613, 6064, 1228, 3487, 411, 17948, 304, 17948, 1124, 293, 264, 17948, 304, 3877, 51112], "temperature": 0.0, "avg_logprob": -0.11111742112694717, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.03208032250404358}, {"id": 616, "seek": 344788, "start": 3462.84, "end": 3469.6400000000003, "text": " of complex systems. But now, so this is all on like biological metabolism and things like that.", "tokens": [51112, 295, 3997, 3652, 13, 583, 586, 11, 370, 341, 307, 439, 322, 411, 13910, 31190, 293, 721, 411, 300, 13, 51452], "temperature": 0.0, "avg_logprob": -0.11111742112694717, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.03208032250404358}, {"id": 617, "seek": 344788, "start": 3470.36, "end": 3477.2400000000002, "text": " But now a lot of people are extending that scaling work to cities. So asking what happens", "tokens": [51488, 583, 586, 257, 688, 295, 561, 366, 24360, 300, 21589, 589, 281, 6486, 13, 407, 3365, 437, 2314, 51832], "temperature": 0.0, "avg_logprob": -0.11111742112694717, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.03208032250404358}, {"id": 618, "seek": 347788, "start": 3477.88, "end": 3484.36, "text": " to cities when they increase in size, either in area or in population size. And", "tokens": [50364, 281, 6486, 562, 436, 3488, 294, 2744, 11, 2139, 294, 1859, 420, 294, 4415, 2744, 13, 400, 50688], "temperature": 0.0, "avg_logprob": -0.1253793297744379, "compression_ratio": 1.6517412935323383, "no_speech_prob": 0.0028880881145596504}, {"id": 619, "seek": 347788, "start": 3485.4, "end": 3489.6400000000003, "text": " there's all kinds of phenomena that you can see, like what's the rate of innovation", "tokens": [50740, 456, 311, 439, 3685, 295, 22004, 300, 291, 393, 536, 11, 411, 437, 311, 264, 3314, 295, 8504, 50952], "temperature": 0.0, "avg_logprob": -0.1253793297744379, "compression_ratio": 1.6517412935323383, "no_speech_prob": 0.0028880881145596504}, {"id": 620, "seek": 347788, "start": 3490.44, "end": 3497.88, "text": " measured by something like patents? And what's the rate of sort of energy usage by a city?", "tokens": [50992, 12690, 538, 746, 411, 38142, 30, 400, 437, 311, 264, 3314, 295, 1333, 295, 2281, 14924, 538, 257, 2307, 30, 51364], "temperature": 0.0, "avg_logprob": -0.1253793297744379, "compression_ratio": 1.6517412935323383, "no_speech_prob": 0.0028880881145596504}, {"id": 621, "seek": 347788, "start": 3499.88, "end": 3506.28, "text": " And what's how do these things change? Even like the happiness of the people,", "tokens": [51464, 400, 437, 311, 577, 360, 613, 721, 1319, 30, 2754, 411, 264, 8324, 295, 264, 561, 11, 51784], "temperature": 0.0, "avg_logprob": -0.1253793297744379, "compression_ratio": 1.6517412935323383, "no_speech_prob": 0.0028880881145596504}, {"id": 622, "seek": 350628, "start": 3507.2400000000002, "end": 3511.88, "text": " you know, are people in New York happier than people in Santa Fe, which is a much smaller city?", "tokens": [50412, 291, 458, 11, 366, 561, 294, 1873, 3609, 20423, 813, 561, 294, 9933, 3697, 11, 597, 307, 257, 709, 4356, 2307, 30, 50644], "temperature": 0.0, "avg_logprob": -0.13654742702361075, "compression_ratio": 1.5387755102040817, "no_speech_prob": 0.0016462610801681876}, {"id": 623, "seek": 350628, "start": 3514.52, "end": 3522.0400000000004, "text": " These things scale in really interesting ways. And it's opening up a lot of new ideas about how", "tokens": [50776, 1981, 721, 4373, 294, 534, 1880, 2098, 13, 400, 309, 311, 5193, 493, 257, 688, 295, 777, 3487, 466, 577, 51152], "temperature": 0.0, "avg_logprob": -0.13654742702361075, "compression_ratio": 1.5387755102040817, "no_speech_prob": 0.0016462610801681876}, {"id": 624, "seek": 350628, "start": 3522.76, "end": 3530.44, "text": " social systems work. And how... Is it a similar thing that you can't trust the benchmarks? Because", "tokens": [51188, 2093, 3652, 589, 13, 400, 577, 485, 1119, 309, 257, 2531, 551, 300, 291, 393, 380, 3361, 264, 43751, 30, 1436, 51572], "temperature": 0.0, "avg_logprob": -0.13654742702361075, "compression_ratio": 1.5387755102040817, "no_speech_prob": 0.0016462610801681876}, {"id": 625, "seek": 350628, "start": 3530.44, "end": 3535.4, "text": " how happy people are, might you look at the rate of antidepressant usage or something?", "tokens": [51572, 577, 2055, 561, 366, 11, 1062, 291, 574, 412, 264, 3314, 295, 2511, 482, 11637, 394, 14924, 420, 746, 30, 51820], "temperature": 0.0, "avg_logprob": -0.13654742702361075, "compression_ratio": 1.5387755102040817, "no_speech_prob": 0.0016462610801681876}, {"id": 626, "seek": 353540, "start": 3535.4, "end": 3539.88, "text": " Yeah. So you do have all these... Right. I don't know if that's exactly what they use, but", "tokens": [50364, 865, 13, 407, 291, 360, 362, 439, 613, 485, 1779, 13, 286, 500, 380, 458, 498, 300, 311, 2293, 437, 436, 764, 11, 457, 50588], "temperature": 0.0, "avg_logprob": -0.10902073562786144, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.0018380455439910293}, {"id": 627, "seek": 353540, "start": 3541.1600000000003, "end": 3545.1600000000003, "text": " you do have to look at ways to measure these things, which can be questioned.", "tokens": [50652, 291, 360, 362, 281, 574, 412, 2098, 281, 3481, 613, 721, 11, 597, 393, 312, 28146, 13, 50852], "temperature": 0.0, "avg_logprob": -0.10902073562786144, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.0018380455439910293}, {"id": 628, "seek": 353540, "start": 3546.84, "end": 3552.52, "text": " But there are a lot of really... And I think this whole science, the science of cities, is", "tokens": [50936, 583, 456, 366, 257, 688, 295, 534, 485, 400, 286, 519, 341, 1379, 3497, 11, 264, 3497, 295, 6486, 11, 307, 51220], "temperature": 0.0, "avg_logprob": -0.10902073562786144, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.0018380455439910293}, {"id": 629, "seek": 353540, "start": 3553.4, "end": 3559.2400000000002, "text": " it's very preliminary. And there's a lot of ideas about how to measure these things, how to", "tokens": [51264, 309, 311, 588, 28817, 13, 400, 456, 311, 257, 688, 295, 3487, 466, 577, 281, 3481, 613, 721, 11, 577, 281, 51556], "temperature": 0.0, "avg_logprob": -0.10902073562786144, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.0018380455439910293}, {"id": 630, "seek": 355924, "start": 3559.4799999999996, "end": 3566.3599999999997, "text": " develop sort of analytical descriptions or laws that govern certain properties and how to", "tokens": [50376, 1499, 1333, 295, 29579, 24406, 420, 6064, 300, 1980, 1629, 7221, 293, 577, 281, 50720], "temperature": 0.0, "avg_logprob": -0.1562351467965663, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.017705250531435013}, {"id": 631, "seek": 355924, "start": 3566.3599999999997, "end": 3572.7599999999998, "text": " interpret them. But there's just a lot of really interesting work in this. And it turns out that", "tokens": [50720, 7302, 552, 13, 583, 456, 311, 445, 257, 688, 295, 534, 1880, 589, 294, 341, 13, 400, 309, 4523, 484, 300, 51040], "temperature": 0.0, "avg_logprob": -0.1562351467965663, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.017705250531435013}, {"id": 632, "seek": 355924, "start": 3572.7599999999998, "end": 3580.52, "text": " now that everybody has a cell phone, you can really do a lot of tracking. A lot of these quantities", "tokens": [51040, 586, 300, 2201, 575, 257, 2815, 2593, 11, 291, 393, 534, 360, 257, 688, 295, 11603, 13, 316, 688, 295, 613, 22927, 51428], "temperature": 0.0, "avg_logprob": -0.1562351467965663, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.017705250531435013}, {"id": 633, "seek": 355924, "start": 3580.52, "end": 3588.2799999999997, "text": " can be tracked by people's sort of their movement, their interaction with other people, and all these", "tokens": [51428, 393, 312, 31703, 538, 561, 311, 1333, 295, 641, 3963, 11, 641, 9285, 365, 661, 561, 11, 293, 439, 613, 51816], "temperature": 0.0, "avg_logprob": -0.1562351467965663, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.017705250531435013}, {"id": 634, "seek": 358828, "start": 3588.84, "end": 3595.88, "text": " things that you can measure using cell phones. So that's very cool.", "tokens": [50392, 721, 300, 291, 393, 3481, 1228, 2815, 10216, 13, 407, 300, 311, 588, 1627, 13, 50744], "temperature": 0.0, "avg_logprob": -0.18272607271061386, "compression_ratio": 1.5497835497835497, "no_speech_prob": 0.00022685994917992502}, {"id": 635, "seek": 358828, "start": 3597.1600000000003, "end": 3603.0, "text": " That is... Yeah. Thank you. That sounds actually fascinating. And one reason why for me particularly", "tokens": [50808, 663, 307, 485, 865, 13, 1044, 291, 13, 663, 3263, 767, 10343, 13, 400, 472, 1778, 983, 337, 385, 4098, 51100], "temperature": 0.0, "avg_logprob": -0.18272607271061386, "compression_ratio": 1.5497835497835497, "no_speech_prob": 0.00022685994917992502}, {"id": 636, "seek": 358828, "start": 3603.0, "end": 3610.1200000000003, "text": " is... Are you familiar with Asimov's Foundation series? Yeah. So you know, psycho history in", "tokens": [51100, 307, 485, 2014, 291, 4963, 365, 1018, 332, 5179, 311, 10335, 2638, 30, 865, 13, 407, 291, 458, 11, 33355, 2503, 294, 51456], "temperature": 0.0, "avg_logprob": -0.18272607271061386, "compression_ratio": 1.5497835497835497, "no_speech_prob": 0.00022685994917992502}, {"id": 637, "seek": 358828, "start": 3610.1200000000003, "end": 3616.76, "text": " there was the science... And it was almost like a thermodynamics of human behavior that was only", "tokens": [51456, 456, 390, 264, 3497, 485, 400, 309, 390, 1920, 411, 257, 8810, 35483, 295, 1952, 5223, 300, 390, 787, 51788], "temperature": 0.0, "avg_logprob": -0.18272607271061386, "compression_ratio": 1.5497835497835497, "no_speech_prob": 0.00022685994917992502}, {"id": 638, "seek": 361676, "start": 3616.84, "end": 3621.5600000000004, "text": " applicable at kind of planet scale and beyond. So it's like these scaling laws. So this is maybe", "tokens": [50368, 21142, 412, 733, 295, 5054, 4373, 293, 4399, 13, 407, 309, 311, 411, 613, 21589, 6064, 13, 407, 341, 307, 1310, 50604], "temperature": 0.0, "avg_logprob": -0.15244200735381155, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.0070076859556138515}, {"id": 639, "seek": 361676, "start": 3621.5600000000004, "end": 3626.2000000000003, "text": " one step towards... Very similar, psycho history. Yeah. One step towards psycho history of Asimov's", "tokens": [50604, 472, 1823, 3030, 485, 4372, 2531, 11, 33355, 2503, 13, 865, 13, 1485, 1823, 3030, 33355, 2503, 295, 1018, 332, 5179, 311, 50836], "temperature": 0.0, "avg_logprob": -0.15244200735381155, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.0070076859556138515}, {"id": 640, "seek": 361676, "start": 3626.2000000000003, "end": 3633.0, "text": " kind. Exactly. Yeah. Cool. And in closing, does that give you intuition on the scaling of intelligence?", "tokens": [50836, 733, 13, 7587, 13, 865, 13, 8561, 13, 400, 294, 10377, 11, 775, 300, 976, 291, 24002, 322, 264, 21589, 295, 7599, 30, 51176], "temperature": 0.0, "avg_logprob": -0.15244200735381155, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.0070076859556138515}, {"id": 641, "seek": 361676, "start": 3634.76, "end": 3645.1600000000003, "text": " Well... That's a great question. And I think, you know, one question you can ask is like,", "tokens": [51264, 1042, 485, 663, 311, 257, 869, 1168, 13, 400, 286, 519, 11, 291, 458, 11, 472, 1168, 291, 393, 1029, 307, 411, 11, 51784], "temperature": 0.0, "avg_logprob": -0.15244200735381155, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.0070076859556138515}, {"id": 642, "seek": 364516, "start": 3645.16, "end": 3649.48, "text": " there's individual intelligence and then there's collective intelligence.", "tokens": [50364, 456, 311, 2609, 7599, 293, 550, 456, 311, 12590, 7599, 13, 50580], "temperature": 0.0, "avg_logprob": -0.13385992050170897, "compression_ratio": 1.7815533980582525, "no_speech_prob": 0.008837654255330563}, {"id": 643, "seek": 364516, "start": 3650.68, "end": 3656.12, "text": " And how much of the intelligence that we have individually is actually grounded in a more", "tokens": [50640, 400, 577, 709, 295, 264, 7599, 300, 321, 362, 16652, 307, 767, 23535, 294, 257, 544, 50912], "temperature": 0.0, "avg_logprob": -0.13385992050170897, "compression_ratio": 1.7815533980582525, "no_speech_prob": 0.008837654255330563}, {"id": 644, "seek": 364516, "start": 3656.12, "end": 3663.08, "text": " collective intelligence? You know, there's many things that I don't know, like I don't understand", "tokens": [50912, 12590, 7599, 30, 509, 458, 11, 456, 311, 867, 721, 300, 286, 500, 380, 458, 11, 411, 286, 500, 380, 1223, 51260], "temperature": 0.0, "avg_logprob": -0.13385992050170897, "compression_ratio": 1.7815533980582525, "no_speech_prob": 0.008837654255330563}, {"id": 645, "seek": 364516, "start": 3663.08, "end": 3669.96, "text": " quantum mechanics or something, but I know somebody who does. And therefore, I feel like it's understood.", "tokens": [51260, 13018, 12939, 420, 746, 11, 457, 286, 458, 2618, 567, 775, 13, 400, 4412, 11, 286, 841, 411, 309, 311, 7320, 13, 51604], "temperature": 0.0, "avg_logprob": -0.13385992050170897, "compression_ratio": 1.7815533980582525, "no_speech_prob": 0.008837654255330563}, {"id": 646, "seek": 366996, "start": 3670.36, "end": 3677.48, "text": " And a lot of our intelligence, I think, is sort of more social than we think.", "tokens": [50384, 400, 257, 688, 295, 527, 7599, 11, 286, 519, 11, 307, 1333, 295, 544, 2093, 813, 321, 519, 13, 50740], "temperature": 0.0, "avg_logprob": -0.09153797862293957, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.003807959845289588}, {"id": 647, "seek": 366996, "start": 3679.2400000000002, "end": 3685.88, "text": " Oh, absolutely. And folks should definitely read Melanie's book. So your complexity book,", "tokens": [50828, 876, 11, 3122, 13, 400, 4024, 820, 2138, 1401, 42798, 311, 1446, 13, 407, 428, 14024, 1446, 11, 51160], "temperature": 0.0, "avg_logprob": -0.09153797862293957, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.003807959845289588}, {"id": 648, "seek": 366996, "start": 3685.88, "end": 3690.04, "text": " we actually covered that quite a lot on our show on Emergence. It's absolutely wonderful. And of", "tokens": [51160, 321, 767, 5343, 300, 1596, 257, 688, 322, 527, 855, 322, 18477, 15260, 13, 467, 311, 3122, 3715, 13, 400, 295, 51368], "temperature": 0.0, "avg_logprob": -0.09153797862293957, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.003807959845289588}, {"id": 649, "seek": 366996, "start": 3690.04, "end": 3696.68, "text": " course, your book on AI is probably the best book on AI I've ever read. It's up there with", "tokens": [51368, 1164, 11, 428, 1446, 322, 7318, 307, 1391, 264, 1151, 1446, 322, 7318, 286, 600, 1562, 1401, 13, 467, 311, 493, 456, 365, 51700], "temperature": 0.0, "avg_logprob": -0.09153797862293957, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.003807959845289588}, {"id": 650, "seek": 369668, "start": 3696.68, "end": 3701.56, "text": " Christopher Sommerfield's book. But anyway, Melanie, honestly, you are my hero. Thank you so", "tokens": [50364, 20649, 35022, 7610, 311, 1446, 13, 583, 4033, 11, 42798, 11, 6095, 11, 291, 366, 452, 5316, 13, 1044, 291, 370, 50608], "temperature": 0.0, "avg_logprob": -0.1461318333943685, "compression_ratio": 1.394904458598726, "no_speech_prob": 0.055376943200826645}, {"id": 651, "seek": 369668, "start": 3701.56, "end": 3705.96, "text": " much for coming on MLS2. I really appreciate it. Thanks so much for having me. I really enjoyed", "tokens": [50608, 709, 337, 1348, 322, 376, 19198, 17, 13, 286, 534, 4449, 309, 13, 2561, 370, 709, 337, 1419, 385, 13, 286, 534, 4626, 50828], "temperature": 0.0, "avg_logprob": -0.1461318333943685, "compression_ratio": 1.394904458598726, "no_speech_prob": 0.055376943200826645}, {"id": 652, "seek": 369668, "start": 3705.96, "end": 3707.64, "text": " it. It's great talking to you.", "tokens": [50828, 309, 13, 467, 311, 869, 1417, 281, 291, 13, 50912], "temperature": 0.0, "avg_logprob": -0.1461318333943685, "compression_ratio": 1.394904458598726, "no_speech_prob": 0.055376943200826645}], "language": "en"}