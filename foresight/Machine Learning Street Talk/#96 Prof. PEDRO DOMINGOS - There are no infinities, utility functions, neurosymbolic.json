{"text": " Hi, I'm Peter Domingos, I'm a professor of computer science at the University of Washington and machine learning researcher, probably best known as the author of the master algorithm, popular science introduction to machine learning. I'm here at NeurIPS 2022 of the vast amounts of stuff that's happening here. The two that I found most interesting and are closest to my own research are Neurosymbolic AI and symmetry-based learning. Okay, Professor Pedro Domingos, it's an absolute honor to have you back on the show. Pedro is a professor at the University of Washington and give us a quick introduction to yourself, to your experience here in Europe so far and what's top of mind for you? I'm a machine learning researcher, I've worked in most of the major areas. I've also written a popular science book on machine learning called the Master Algorithm. I'm having a lot of fun here at NeurIPS, listening to various talks like David Chalmers on Consciousness and Geoff Hinton on Sleep and looking forward to the rest of it. Awesome, I'd love to get your thoughts on Chalmers in a bit actually, but the first thing I wanted to talk about just because it's top of mind is this whole galactica situation. So first of all, I was speaking with Ian the other day and I think it's a little bit unfair that Meta really bear the brunt of this. OpenAI have just released this new chat GPT bot which suffers from similar failure modes and it just kind of feels that they're not getting anywhere near as much stick as Meta is. Well I think, I agree with you, I think the brouhaha about galactica is way overblown. That system is really largely harmless. It's just another large language model that's designed for actually something that to me as a scientist is very interesting. I would love to have a system like that to help me out with certain things and I think it's a step in the right direction and I think the brouhaha however is an instance of people jumping the gun on a lot of these AI things in a way that to me is very excessive. Having said that in a way they set themselves up for it in a way that they need and have, they kind of over claimed what it did and the problem with these LLMs is that they generate a lot of stuff that looks good but can be completely wrong and in a way there's no worse place to do that than in writing scientific articles. So when they came out with it, they should have been more careful about how they frame it. I think they took concerns sort of like this competition and one upping each other on who comes up with the frilliest demo and that kind of backfired. So they shouldn't have had to withdraw it. I think that's all pathetic and hopefully they've learned the lesson that next time they will do it slightly differently. Yes. Okay. Okay. Well, so Gary Marcus has been very loud about this on Twitter so he's really pushing the point about misinformation and the thing is as well I don't want to characterize the ethics folks as having monolithic views because they don't have monolithic views and I also think that a lot of the ethics guidelines for large language models are very reasonable. Like I interviewed the CEO of Coheir the other week, Aidan Gomez. I went through their terms and conditions and policies all very reasonable. The only sticking point for me is the misinformation one. I think the kind of the moral valence of it is in its use and especially with misrepresentation. I don't like this paternalism telling me what's good for me. I've just lost out on using a really cool tool basically. I completely agree with you. I would take it even further. I do not want other people deciding for me what is misinformation and what is therefore allowed to be said because it's misinformation or not. For a couple of reasons. One is that these people who claim to be big critics of misinformation, a lot of them are misinformers themselves. And the bottom line is that you always have your ideology that informs what you think is true and false. And I don't want anybody, every one of us in a democracy should be deciding for themselves what is true and what is false and what is valid and what isn't. And I have no fear of attempts to misinform me as long as I have a multiplicity of sources. The biggest misinformation danger is when you have only one monolithic source of truth, whatever it is, which is unfortunately what a lot of these anti-misinformation people, I think consciously or unconsciously want. Give me 10 things, 9 of which are misinformation. I can do the job of figuring out which one I think is valid. Give me only one of those things and chances are 9 in 10 that it is misinformation and then I have no chance to overcome it. So this whole attack on things because they're misinformation. And I mean, I understand the impulse that like, why have all this falsehood flying around? But the way to overcome that falsehood is not by censoring it. You should know this, right? You should be having to refight all of this over again in the context of social media and large language models and so on. So you said something really interesting, which is that this notion of a pure truth or a monolithic truth, and there's this concept of epistemic subjectivity, right? Or things observe a relative, even complex phenomena like intelligence. No one understands what it is. You can't reduce it to one particular thing. People have different views on it, right? So this notion that there is a pure monolithic truth of the world, I think is horrifying. Well, I would put it slightly differently. So first of all, there's a question, is there one reality or not, right? Is there truth or is there my truth and your truth, right? And actually, I understand the impulse to talk about my truth and your truth, but I think as a... So what is really true? We don't know. But as a... I think the most useful, including socially useful working hypothesis is that there is a single reality and the single truth, but it's extremely complex. So no single one of us can get at it. So what we need is many different people coming at it from different angles. But with the premise that we need to try to make these things consistent. So just saying, oh, we have different truths and there's no reality, that is actually very counterproductive because it gives everybody a pass to just believe whatever wacky thing they want. And then the consequences of that when you have to make the real decisions are very bad. At the same time, I agree with you. If I think that I have access to that truth and everybody just needs to, you know, count out to it, that is very dangerous. So I think we need to entertain these two ideas that there is a truth, but it's very complex and no one has a monopoly on it. And the key is, you know, like objective truth is what different observers can agree on. And now we can figure out what it is that we agree on. And that way we make progress in understanding reality. And we also tend to make more of the right decisions because we're closer to the truth. Okay. But do you see it as, I mean, I think the reality thing is interesting, but do you just see it cynically as gatekeeping? As in having a clerical class control? Oh, absolutely. No, absolutely. That's precisely the danger that I was referring to is that if you, let me put it this way. If ever there is, and this is a commonly mooted proposal, right, and not even proposed like, are we going to have a truth commission of people who decide what is true on whatever, Twitter or something, right? That is a really alarming thing because there is no commission that can do that. What they're going to do is they're going to impose their version of reality on everybody else, which unfortunately is what a lot of these people want to do. They convince that they have the truth and they want to impose it on the rest of us. And that is really alarming. We know historically what happens when people succeed in doing that. Yes. Yes. But I suppose my point with the gatekeeping is it almost gets you to the actual truth of the matter is irrelevant. It's actually about power. But what's your take on, I don't know whether you think this is putting it too strongly, but this being a form of industrial kind of gaslighting, kind of, you know, in an Orwellian sense, trying to shape people's reality through, you know, language, culture and interactions on the internet. I think a lot of it is deliberate. Some of it is, I mean, I'm an optimist about human nature at the end of the day. Maybe in, you know, maybe with justification, maybe without. I think so there's this postmodern view that it's all about power and it's certainly partly about power. I think a lot of the people doing this, unfortunately, or maybe fortunately, they are, they're not seeking power for its own sake. They have a set of beliefs that they think is right. And then the means, you know, they unjustify the means, right? That's the problem. So that gatekeeping, you know, and that gaslighting happen not because, not for their own sake, they happen for the sake of a cause. And now there's two problems with this is that these days the causes on behalf of which this is being done, in my view, are largely wrong, right? But whether they're right or wrong, right? The problem is that this is just noxious in its own right. And also then a lot of sort of like, again, personal desire for power and promotion and prevailing over others. Then of course, you know, hitches are right onto this. Yeah, interesting. I mean, we'll get into consequentialism in a minute because I think there's quite an interesting journey we can go there. But I wanted to cite Francois Chollet, I'm a big fan of him. He just tweeted saying, I'm not too concerned of whether what I read is right or wrong. I can figure that part out myself. I'm interested in things that are useful, thought-provoking, novel. Sometimes the most creative thinkers have a bias towards wrongness, but they're still worth reading. Would you agree with that? Yes, I largely agree with that. So as I was saying before, you know, I can tell for myself or I can do that exercise of figuring out what is right and wrong. The most important thing that I want is to not miss out on things that I don't want to miss out on. Like, you know, the known unknowns and the unknown unknowns, the biggest killer is the unknown unknowns. So if anybody trying to learn or understand something, they're for person or organization or society, right? If all they do is move the unknown unknowns to known unknowns, they've already gone an enormous distance, right? And so I appreciate people who I disagree with, first of all, because that's how you sharpen ideas. Yeah. But also because they may just bring things to my attention that if we were all conforming to the more majority view, would not come to our attention. And then those more often than not are the ones that kill you. Yeah, that's so interesting. I mean, there's a real analogy here, even this might be tenuous, but between symbolism and connectionism or, you know, Rich Sutton said we shouldn't be hand-crafting our AI systems. We should kind of let them emerge. And it's a similar thing with our moral framework, but you're kind of saying that it should be emergent from low level complexity and diversity and interestingness. And there is another school of thought, which is that we should be top down and we already have a representation. I actually think it should be, it needs to be a combination. We need to have both. This is one of those debates that in some sense puzzles me because to me the obvious answer is that we need both. And then if you read the master argument, this is what I do. I look at the different paradigms of machine learning and I don't come out in favor of any of them because I actually think we need ideas from all of them. And then we need to combine them into something coherent. And if you look at psychology, like your brain does bottom up and top down processing. And if it only did one of them, either one, it wouldn't work. And I think as we try to build a larger intelligence, it's the same thing. We definitely need the bottom up part and, you know, by volume, the bottom up part is going to be bigger. So if you could only have one, that would probably be, you know, the choice. But the top down part is also very important. If you go all the way back, the top down part probably started this bottom up and got synthesized and improved. But now we need that loop. The loop is actually very important. Well, that's interesting. So in your book, I guess I want to sketch out different types of AI architecture. So, you know, you get universalists to this kind of deep mind idea that a very simple underlying algorithm could produce everything. And then you get, you know, hybrid folks on the other side of the spectrum. And then there's an integrated approach in the middle. Like, where would you kind of place yourself on that continuum? I would place myself very much in the frame of mind, well, let me put it this way. I don't know, but which is nobody does, right? If somebody tells you that they know how we're going to get to intelligence, you should be suspicious right away. But what do I think is the most promising approach and the one that ideally would be the best one if we can pull it off? It's there being a single algorithm. So at that level, I very much sympathize with what is effectively the deep mind's agenda. Now, we're at part with a lot of these people is that I don't think the algorithm that we need is as simple as many of those people think it is. And I don't think it exists. It is probably the case that the algorithm that we really need at the end of the day doesn't even look that much like any of the things that we have now. So I think hopefully there is such an algorithm, but we're still far from it. Interesting. I mean, they would cite the example of evolution as being a very simple underlying algorithm. Although Ken Stanley would say that people misunderstand evolution. So I agree with them at that level. In fact, in the master algorithm, I have a chapter where I go over the objections and the reasons to believe that there is a master algorithm. The majority of the people even in the field are skeptical of that notion, even though I would claim that effectively that's what they're pursuing. People like Rich Sutton and Jeff Hitton, I asked a bunch of people before I wrote the book and they do believe in this idea of having a master algorithm. A lot of people believe that, but intuitively a lot of people believe that no, there is no such thing. And I understand that intuition, but I don't think it's a well-founded intuition. Let me put it that way. But in a sense, we know there is such a thing, because look at cellular automata, look at what we've already done with deep learning. I think the context is, is there such a thing that will produce what we want? To take your example or DeepMind's example of evolution, in the book I mentioned empirical evidence that there is a master algorithm and exhibit one is evolution. If you think of evolution as an algorithm, which by the way is a very old idea, I think it was George Bull that said, God does not create animals and plants, he creates the algorithm by which animals and plants come about. He didn't use the word algorithm, but that's essentially what he said. This I think is right on. Another example is your brain. If the algorithm doesn't have to be something as simple as backprop and you're a materialist like most of the scientists are, your brain, if the master algorithm is an algorithm that can learn anything you do, then your brain is that algorithm. But then there's another one which is even more fundamental, but I think from the point of view of this debate is very illuminating, which is the laws of physics. Why stop at evolution? The laws of physics are the master algorithm. Evolution is very complicated. In fact, what I think about evolution in AI currently is that evolution in reality is much more complex than we give it credit for, which is why a lot of our current generic algorithms don't work that well. But the laws of physics at this level are much simpler. If you think about it, from the laws of physics comes evolution and comes all the intelligence that we have. It's very intriguing why that happens and why the laws are such that that happens. But even just the laws of physics are already a master algorithm. Now what you could say, and many people immediately say is like, oh, but if you start from there, you'll never get anywhere, right? But then you can say evolution is the laws of physics sped up in a certain direction. And then our reinforcement learning is like evolution. People have pointed out the same way except it's faster. And in a way what we're trying to do now in machine learning is the same thing yet again except only even faster. But what are the consequences of? I mean, let's say it is actually a very high resolution algorithm. So it's something that appears to be completely unintelligible to in respect of the output phenomena. Is that is that even a good place to be? Because, you know, just like with cellular automata, there's no real paradigmatic relationship between the underlying rules and the emergent phenomena, right? So is that really even something we want? No, I think there is. So we don't know. But I think people and this is very common among connections is to say this stuff is also complex that we can't possibly have a handle on it. We just have to let it happen. And I think that is not giving enough credit to our human brains, right? We are incredibly good at making sense of things that in the beginning, I mean, over and over and over in the history of science and technology, you start out with things that you don't understand very well at all. But then over time, we kind of change our representation of the world to make those things actually be intelligible to us. And we should not a priori assume that that's not going to be the case here. So, for example, cellular automata, amazing things come out of whatever the game of life that seemed completely disconnected from those, but they aren't, right? And, you know, there's various depths at which you could go into this. There will probably at the end of the day be some large element of this that we can't figure out very well, but we can figure out enough that we have a handle on it. So, this singularity notion that at some point AI is just completely beyond our understanding. I tend not to buy. I don't think it will be completely beyond our understanding. But it's an analog back to our Twitter discussion, like, because we can only understand it through. It's like having views on a mountain range, you know, the view looks different depending on where you're standing. And it's the same thing with the emergent phenomena in a cellular automata. No, very good. And, you know, the classic example of this is the blind man and the elephant, right? And that's actually the metaphor that is in the book, as I say, you know, the different tribes are like different blind men, right? But precisely so, AI is one of the blind men. I can see part of the elephant, but it'd be who's meant to also talk to you who see another part of the elephant. And then each of us understands a little bit more of the elephant than we would if we were on our own. But most importantly, we collectively, which is what really matters, actually understand maybe not the elephant completely, but much more of the elephant than either any of us would alone, right? And it's certainly a lot better than just giving up and say, like, oh, we're never going to understand this strange thing that's in front of us. Interesting. But that's a great argument to what you were saying before. So it's beyond our cognitive horizon. Therefore we need to have diversity of aspect. There's a, yes, there's a question of whether it's beyond the cognitive ability of a single human. Yeah. And then there's the question of whether it's beyond the cognitive ability of an entire society of humans. And obviously, there'll be things that are beyond the cognitive ability of a single human, but not beyond the cognitive ability of a society. Also these days, we have computers. So our cognitive power is augmented by our machine. So we can understand things or bring things to the point where we understand them to a degree today that we couldn't a hundred years ago. Right now, that is a fascinating point. So it's beyond our cognitive horizon individually, but it might not be beyond the cognitive horizon of loads and loads of humans on the internet, you know, the wisdom of crowds. But we don't, I mean, how do we know that the crowd understands? But we know, well, that's the, in some sense, the beauty of this, right, is that we never, what is the crowd really understanding, right? And again, once the crowd is augmented by machines, like machine learning algorithms, right, we can ask what do we as a society equipped with all of our, you know, large language models and so on and so forth, what do we really understand, right? Now, at some level, you can't answer that question individually because you are just an individual, but right, there's a couple of very important things that we shouldn't forget. You could, one thing you can do and that I do do is say, like, do I now actually even just individually understand things better than I did before when it was just me looking at it? And the answer to that is almost invariably yes, right? So there is a big game to be heard there. And the second one is that you, ultimately, you tell by the consequences, right? And like, for example, take a deep network, right? And you may not know how it works, but if it's doing medical diagnosis, you can tell whether it, you know, gets the diagnosis right more often than it did before or more often than another model. So we as a society may not, you know, we individuals may not very understand very well what we as a society understand, but we can see the consequences and at some level, that's the point. Yeah. So on that, I mean, that sounds like a bit of an appeal to behaviorism and we're going to talk about that in respect of charmers as well. But it also brings us back to, you know, we were talking about empiricism versus rationalism and nativism and all of these topics. Would you place yourself in that camp of being a nativist and a rationalist or completely the other way? No, absolutely not. Again, this is one of the points that I, you know, go back to is there are the empiricists and there are the rationalists and you could see naively machine learning as being the triumph of the empiricists, but it actually is not there are very fundamental reasons why it's not. And I really do think, and this is not just think there's this thing called the no free lunch theorem, right? And if you take those things seriously, the solution has to be a combination of empiricism and rationalism. I don't think either side alone has or even can have the whole answer. So very much we need both of those. And if you're a pure empiricist or a pure rationalist, I'm already suspicious of you. Wonderful. Coming back to what Franz Walsh said in his quote, he said, you know, producing things that are thought provoking novel and all the rest of it. And I was speaking to some alignment folks yesterday and we'll pivot to that in a minute. The big thing for me after doing an episode on sales, the Chinese room is, you know, where does intentionality come from and Chomsky talks about agency, for example, we do things that are appropriate to the situation, but not caused by them. So from my perspective, all these generative models, all these large language models and so on, the creativity, the real spark of genius still comes from us, right? We've just kind of like, you know, the boring bit of actually doing the task is now delegated to the algorithm. I would disagree with that. I think you are, I mean, your position is very reasonable and actually, I would say probably the most common, but I think when you do that, you are giving us too much credit and the large language models too little. We tend to have this notion that creativity is something magical. In fact, I remember for many years, so quick parenthesis, in the previous life I was a musician. So, you know, I, in some sense know about, and a lot of my job was composing songs, right? And I was always, at the same time I was already studying AI and I couldn't help but connect it too, right? And think about like, what would an AI look that was able to compose music, right? And talking to late people who are not musicians, they think that composing songs is some kind of magic thing that comes from, you know, whatever the great beyond, and it's not. It's a very human enterprise and it can very well be automated. It's actually now, you know, people, I used to say to people like, people always say like, well, creativity will be the last thing that we automate because we humans can do it and there's no machine school and be like, no, it's going to be the opposite. You automate creativity long before many other things and we're there now, right? In just the last, so I think when you, let me put it this way, your prompt to the LLM, let's say, is like the grain of sand to the oyster, right? You should not give yourself credit for having made the pearl because it put the grain of sand in there. That's a, that's a brilliant analogy, right? So it is still the LLM, we need to, we can critique how creative it is or not and there's a lot to be said there and a lot of progress to be made, but we need to give it credit for what it does, right? It is well or not so well, right? Maybe it's more of an illusion that we're giving credit for and whatnot, but that text or that image or whatever, they were created by the AI. And in many ways, the thing that was created by the AI is no worse than what would have been created by an artist if I gave them the prompt. No, okay. Well, on that, I agree with you. I mean, Melanie Mitchell had this wonderful anecdote from the Google Plex when she was with Douglas Hofstadter and he was talking at the time about, you know, how he would be devastated if an AI could produce a Chopin piece, you know, which was indistinguishable from one which he actually created and of course, that did happen, but then we get into this discussion of where does it start, right? Where does it start? Computers only do what we tell them to do, right? They've been trained and actually I was speaking to Sep about this the other day that, you know, all of the abstractions, all of the things that the computers and the models do, they are crystallized snapshots of things that humans have previously done and we've written the computer code. So where does the creativity start? Well, but we, by that standard, we humans also only do what we're told to do. We do what we're told to do by our genes. Our genes do what they're told to do by evolution, which does what is told to do by the laws of physics, right? Right. And now, again, this gets back to this notion that there's nothing magical about creativity. Creativity really is, to a large extent, cutting and pasting stuff and satisfying consistency constraints between them. And I'm not just saying this in the abstract, like long before the modern era, there's this guy called David Cope, you know, a composer and professor of music at UC Santa Cruz who created these programs that exactly they would write, they can write, this was pre-machine learning. It was list code that what it did was basically have rules about how music should be. And then it takes snippets and combines them, right? You could say it's just parroting those bits, but the truth is at the end of the day and you can choose. You say, like, give me something in the style of Mozart. And it creates something that looks indistinguishable from what Mozart did, but all it's doing is this kind of recombination of pieces. So we humans, we have too much respect for appreciation of our own intelligence. That's also what we're doing. Yeah, I think I agree with you. I mean, first of all, intelligence is a receding horizon and there's the McCorduck effect. I agree with all of that. But yeah, I think it's a similar thing to how we anthropomorphise large language models and even, you know, it's tempting to say large language models are slightly conscious and we'll talk about that in a minute, but maybe like we also anthropomorphise our own agency, right? We have like a little bubble around ourselves and we kind of delude ourselves that we exist as an individual unit with agency disconnected from the rest of the world. Well, precisely the problem with how we largely take AI today, this has always been the case, by the way, is that we have a new resistible notion to anthropomorphise anything that behaves even remotely like us. We're the only intelligent things that we know, so if something starts behaving intelligently, then we project onto it all of these other human characteristics. Same with consciousness, same with creativity. We don't know anything else that's creative besides us. So once a machine starts behaving creatively, we cannot help but project a lot of things onto it. It's just reasoning by analogy, right? So it's a kind of analogical, so like you're like me in this respect, so you probably are in this other spec. Now, the good news is that we always start out with this kind of very good reasoning by analogy, but after a while, we actually start to build a model of the real thing. So AI for the public at large right now is very new, but gradually we'll come to a point where we zero in on what AI really is rather than just the shallow analogies that we initially used to try to understand. Okay. Well, I'll try it from a slightly different angle. So we were just saying Seoul makes the argument that it's a biological property and that's where intentionality and consciousness comes from and it's a requisite, but we'll leave that for the time being. Let's go the Fodor and the Gary Marcus and the Chomsky group, and they would argue that creativity is basically this notion of, or even analogy making by extension, is this notion of being able to select from a set which has an infinite cardinality. And as you know, neural networks can't represent infinite sets because they're finite state automators, therefore they make the move we need to have this compositionality. What do you say to that? Well, there's a lot to unpack there. I think we definitely need compositionality, right? If somebody asked me, make a list of how there's some things that are actually essential for intelligence, compositionality would be one of them, right? And this, of course, is the thing that people like Chomsky and Gary are not really care about, right? Having said that, I think first of all, there is no such thing as an infinite set, right? Like infinite set is a useful but extremely dangerous and confusing mathematical tool, right? There is no such thing as an infinite anything and there never will be. So I would just raise this at, well, yes, creativity and almost anything we can do in AI is selecting from a very large set, not infinite, but very large, right? And now, but now we don't just select like one full element at a time. We compose it out of pieces and that's actually where the intelligence comes in. Interesting. I don't want to go too far down the digital physics route, but we did just have Yoshua Barkon and I mean, just to reclamify on that, would you place yourself in that camp that the universe is digital and made of information? Valid question. I certainly think the universe is finite. I think, I mean, like Seth Lloyd says, the universe is a computer, right? And I think that is true or false depending on what you take the word computer to mean, right? So if you say that the universe is digital or is a computer as kind of like an analogy that lets us understand it better, I'm all for that. I don't think the universe is little, you know, here's the way to put this. The universe is a computation. Like, I don't know what the computer is or if there is one. Now the universe is digital in the sense that deep down at the most basic level, the universe is made of discrete things. OK, is this like the it from bit, the John Wheeler type hypothesis? Yes. I mean, if you read that paper, it is, I mean, John Wheeler was a brilliant person. Again, very, you know, to get back to Fran\u00e7ois Chalice's tweet, he was very good at coming up with his provocative notions, right? And the it from the thing, of course, is like newly unveiled today. And I do so at that level, I do agree that looking at the universe is being made of information is very useful. And in particular, if you want a grand unified master algorithm, in some sense, the only way that I at least can see of doing that is by seeing everything as information. So I think, and if I do something that I am working on that, looking at everything as information is a very productive thing to do. Yeah, but but my caution is that information is one aspect of everything. So I can give you a theory of everything that's based on information. But it's not truly a theory of everything. It's a theory of one aspect of everything. And I think there's a lot to be done there. But again, we shouldn't forget what we're living out when we focus on that aspect. Yeah, I mean, we've spoken a lot on the show about, you know, Penrose's view and obviously Sal's view that arises from from biology. And I know if Keith was here, he would argue strongly that he believes in in continuum, and therefore we would need, you know, hyper computation to have this universe. That would be an interesting discussion to have, because I really don't see where there is physical or any evidence for continuum of any kind. The evidence is always that continuum are a useful approximation, but always underlying the continuum is a discrete reality. You take a sensor of anything, right? You know, quantum mechanics is like the quintessential example of this, right? What do we measure at the end that it's always discrete events? Right? Like it's the detection of a photon by, you know, by whatever detector, right? Could be a model of Dobson or a CCD or whatever. But it's a it's a it's a change of state. It really is a bit. Oh, interesting. Well, how would you contrast that? You know, Stephen Wolfram has got this idea of of digital physics and, you know, maybe and again, unfortunately, we have to use arguments from behavior, you know, to kind of say, well, we've we've got potentially a graph cellular automata and it creates this beautiful emergent structure, which is very much like the universe. But, you know, Scott Aronson would make the argument that he's discounting quantum mechanics. I mean, what would you say to that? So I think Steve Wolfram's theory is very interesting. And he gets some things right that a lot of other physicists don't, in particular, that the universe at heart is discrete. So I'm very much with him on that aspect of his agenda. And thank God there's someone like him and a number of others, you know, going that route, right? They're the minority in physics. But actually, I think if you look at just what has happened in the last 10 years, things are very much moving in this direction. And I think they're going to move more, right? Now, having said that, his specific theory, I think has a lot of shortcomings. And I don't think it's the ultimate theory or maybe even the best path to a theory, you know, to a discrete theory of the universe. Scott Aaronson's critique in that regard, I think misses the point, right? It's interesting because it's interesting that you should like pair those two because Steve Wolfram, in a way, is a physicist to become a computer scientist. And Scott is the other way around, right? And I think, you know, like I greatly admire both of them and I'm friends with both of them. I've had many discussions with them. I think, you know, just to very, you know, cruelly caricature things in a way, the problem with Steve is that he has bought into the computer science assumptions too much. And the problem with Scott is that he has bought into the quantum physics assumptions too much, right? So if you really think carefully and rigorously about quantum mechanics, all that continuous mathematics is there just to make discrete predictions. So the continuity may be useful. It is useful. I'm not arguing against the use of continuity and infinity in our mathematics. In fact, we'd be nowhere if we didn't have it. We just have to remember that it's an approximation. It's a useful fiction, right? So quantum mechanics in no way invalidates Steve Wolf from theories, right? The problem, however, is that he has not entirely, you know, ever since cellular automata days, right? He was always saying like, oh, you know, the laws of physics will come out of this cellular automata, right? And people had these objections and, and, you know, now he and others have partly answered some of them. But the truth is at the end of the day, he the only way to answer that objection is to say, look, here is how quantum mechanics arises from my discrete model of the world. And I think this will happen, but it hasn't happened yet. Interesting. OK, we'd love to get Steven on the show. Actually, he's got a he's got a new book out now, which is kind of like expanding on his previous work. But OK, I was having a chat with some alignment folks yesterday. And it's something that I'm a bit naive to, but as I said, I've just read a book. I think it's called The Rationalists Guide to the to the Universe. And it kind of talks all about the the early embryonic stages of Robin Hansen and Nick Bostrom and Eliezer Yuckowski and the Les Ron community and, you know, the info hazards. And, you know, I don't know if you've heard of Rocco's Basilicist and all of this line of thought, basically. And yeah, so where to go with this? Now, I kind of put forward that part of my problem with their conception is that it relies on this rational agent making trajectories of optimal decisions. And also, they they tend to be utilitarianism and utilitarianists and consequentialists. And yeah, I just wondered, what's your kind of like high level take on this? Well, there's many aspects to this, right? I think let me put it this way. I. A rational agent, right, is an agent that maximizes maximizes expected utility, right? The definition of rationality is that it's, you know, expected utility maximization, right? And there is a lot of content to this, right? And, you know, people in many fields like economics and and and, you know, AI, right? They make good use of it. It doesn't answer the question of what is the utility that you're maximizing, right? So if you give me utility function, right? Now, if you maximize it, you're rational. You can it can be bound. You can be boundedly rational because you're and indeed this this is the interesting and prevalent cases that you can only maximize it within bounds and you have to make compromises, says this fast and what not. But still, you're rational. If you don't do that, you are irrational, right? So rational is a very, you know, like so many mistakes that we make as a society as individuals would be avoided if only we were rational in that sense. So at that level, I sympathize very much with that view of the world. Having said that, there's a huge gaping hole in the middle of this, which is like, but what is your utility function? Right. And and, you know, one attitude is like, oh, that's for you to decide. You know, you you tell what me or your utility function is. But but then you you you're you're entitled to sell what like. But like my whole problem is that I want to figure out what my utility function should be. And at that point, this whole theory of rationality just doesn't help you at all. The utility function is an input, right? So another question becomes what is your utility function, right? And then there's a very related, but as Hume said, very different question, which is like, what should your utility function be like? Should is a very loaded worth here, right? And then what what usually happens is things like this is that our notions of morality and so on are trying to impose a should on you, a utility function that you should have because it serves the utility of the society. Now, from the point of view, the society, this is good, right? But from the point of view, because the society hopefully will live and prosper if its elements contribute to its utility, not just their own, right? But it still doesn't answer the question. So you can you're entitled to ask. So what does answer the question? Right. And my view on this is that none of these people and these people include Kant and Bentham and, you know, Plato and everybody, right? They you can't do that, right? The the the so to me, the supreme reality of life, Supreme maybe is a bad word, but like the overarching reality is evolution, right? Everything we are is created by evolution. And as somebody famously said, nothing in biology makes sense, except in light of evolution, nothing in morality makes sense, except in light of evolution, not just biological evolution, even though that's part of it, but also social and cultural evolution. So at the end of the day, the question that you need to ask yourself is like, is which utility functions are fitter? And those are the ones that will prevail. So so let's let's go there. That's really interesting. Now, you're known as a skeptic of collectivist thought, right? We know, and there's this interesting dichotomy we were talking about of, you know, monolithic truth, but the utility functions interesting as well. Because in a sense, I mean, I know these folks are consequentialists, but in a sense, that's more leaning towards deontology. I did it again, deontology, you know, which is this idea that we have kind of like a principled approach to to morality. And I'm skeptical as well that it's possible to create such a utility function because it wouldn't really be parsimonious. But how do you wrestle that, that you have a simple utility function, even though you believe in diversity of ideas? Oh, no, I didn't say simple. Go on. Crucial point, the utility function could be extremely complex. And in fact, the utility function. So first of all, there's there's more than one level to this. You to let's say you believe in utilitarianism, right, which I don't, but have, you know, compared to the others, it's probably the least bad. Right. Yeah. Believing you tell if you believe in maximizing utility function that in no way sanctions collectivism. Collectivism is one particular strength that historically came out of that. Right. And, and, and, you know, again, and Bentham is responsible for it. But it's this notion that you should have a utility function in which everybody counts equally. This is now making a choice of utility function, which is different from having one. Okay, but I think you're saying something quite interesting as well, which is that at the moment, the utility is a function of market value, which is very much inspired by Adam Smith's hidden hand of the market. But I think your views against collectivism is very much against this idea of equality of outcome. And that's definitely not what you're saying. No, I mean, that's even going beyond that, right? Equality of outcome is actually irrational, frankly, to we could go into that. But, you know, you mentioned the market, right? And the market is the size utility. Again, that is a one way to decide. I mean, that is also a very critical approximation to what you really want. So actually, all we have with capitalism or carnimism at this point, in terms of utility function, are very imperfect, right? And that's even saying it generously. And really, our job is to try to come up with something better, which I totally think we can, right? And by the way, one very salient question here, which again, for economists, it's very salient, is this question of like, should you have one utility function overarching, controlling everything, even if it's complex, right? Or should you not, right? And that I think is a very interesting question, right? And there are good arguments in both directions, right? So let me just give you one silly example, which then I think also generalizes two other things. Does your brain have a singular utility function? And I think the answer is no. Now, you could say from an evolutionary point of view, the overarching utility is fitness. But then the way that cashes out in your brain is that your genes need to control this adaptive machine, right? In such a way that you give the machine freedom, right? To do things that the genes by themselves couldn't. But at the same time, at the end of the day, that machine has to subserve the propagation of those genes. And the way you do this, right, at least the way evolution seems to have done, and I think it makes a lot of sense, is that you don't just have one utility. You have several ones which correspond to your emotions. And then they fight it out. So I actually think there's this connection between rationality and the emotion that people don't make, which is that your emotions are really your utility functions. You just have different ones that cater to different things, right? You know, fear and anger and so on. And so I think in reality, we actually have multiple utility functions. But because, again, it gets to this problem that what we're trying to do is approximate something that is very complex and difficult to get at, maybe it is just one, but we're better off trying to approximate it with 10 or 20 different things than just trying to nail that one thing. That's really interesting. And is your view then on having this diversity of utility functions analogous to your views on the master algorithm? Huh. It's analogous, but you're actually talking about different dimensions, right? You could make a table where on one side you have all the different utilities, and then on the other side you have the algorithms. And now you can pair off any one of them. I can say, I'm going to pursue this, you know, minimize your fear using symbolism or minimum. So any combination is valid. Really, really interesting. Okay. And then let's get into meritocracy, for example. So at the moment, we do have the market system. And presumably you think that some people do genuinely have more market value than others. For sure. No. And by the way, I think, I'm definitely a big believer in meritocracy. I think. But what does it mean to you? Right. Very good. So let's get that down first, right? Meritocracy, so our goal is to have the society that functions best and provides best for everybody, right? And I mean, we could refine even that, but let's just take that for now as our assumption, right? But then if that is the case, one of our primary goals, maybe even the most important one, is to get everybody to contribute the most they can, right? Meritocracy is often seen as like, I'm going to rank all the people, and at the top is the greatest genius, and at the bottom is the most useless person, and this is wrong, right? Meritocracy is a many-dimension thing, right? The goal of meritocracy is to find for everybody what they're best at doing so that they can do it, maximize everybody's contribution to society, right? And this is a very complicated process. There isn't a single scale of intelligence or anything else. Having said that, it very much is the case that some people are better for some things than others, right? And if you deny that, you are actually in the process of destroying the society and making it dysfunctional. So I find the attacks on meritocracy extremely disturbing, right? And a lot of them are, I've talked with many people who have those beliefs, right? And the number one thing that they say is, it basically boils down to like, oh, meritocracy isn't perfect, so we should junk it. Something not being perfect has never been a reason to junk it. It's a reason to improve it. So there's a lot of room to improve in meritocracy, but if you throw it away, you are destroying society. Well, I mean, you can trace this back to our argument about utility. But the thing is though, if we had a value function which represented actual market contributions or even societal contributions, that would be one thing. But would you agree that we have a lot of game playing at the moment? So utility is based on playing the success game or the dominance game or the virtue game, as Will Stor said in his book. So we've got these kind of emerging games and it's not really representing utility. Well, absolutely. So far we've been talking about utility, right? But what happens in the real world is that there are multiple agents, each with their own different utility. And at this point, what you have is game theory, right? Game theory is just what you have when there's not a single optimization going on, but multiple optimizations which are partly contradictory, maybe partly not. So the best way to understand everything that we've been talking about, including society and evolution and even what happens inside your brain is as a big game. A much bigger and more complex game than game theorists and economists and so on and evolutionary biologists, right, prominently, have been able to handle in the past. But I think they are very much in the right track and we can understand a lot of these phenomena that you're referring to as they are games being played by people that have certain utilities, right? And now you are going to impose your, you know, like, and it's a game, right? I don't, you don't know who's going to win until you actually do the linear program and figure out how this is going to, you know, and of course games are, you know, in reality, you know, most games are not single round games, right? They're continuing games, right? So things get very, very interesting, but this I think is the most productive way to look at all of this. Okay, good, good. But then some might say that this is a platonic way of looking at the world and the world is actually much more complicated than that. And again, we're kind of fooled by randomness because we're anthropomorphizing the world and we're kind of framing it as a game. It might be much more complicated than that. And I've already said this a couple of times, but you know, the concept of power, for example, did when Napoleon said, I want the men to march into this country, is it just a simple kind of chain of command that goes down? No, it's not. It's so much more complicated than that. Well, yes, but that's, actually, I'm not even sure what you mean by when you say it's much more complicated than a game. Again, when I say a game, maybe what comes to your mind is something simple, like in a prisoner's dilemma, two players, two moves. It's a game with, you know, with a vast number of players, each with a vast number of moves. Interesting, but I think this gets to the core of what the rationalists talk about. They have these thought experiments. They talk about prisoners dilemma. They have that, I forget the name of that game where there's the two boxes, and you have to choose the box, I forget that. But I guess what I'm saying is that if you do have this rationalist conception of the world, and think about it in terms of game theory, just like the symbolists do, and the people who handcraft cognitive architectures do, or even with causality, for example, we create these variables, it's all anthropomorphic. Well, I would not, so let me put it this way, right? You can model almost anything, can is an important word here. You can model almost anything in the world, in any domain, from physics to psychology to sociology, name it, as optimizing a function. Whether you should is a debatable question, but you can, right? But now, what really happens is that there are many different optimizations going on at the same time, all the way from maximizing entropy to me deciding what I have for lunch today. And now what you have is all of these interlocking optimizations, and that's what I'm calling game theory, right? One of those optimizations is I'm Napoleon, I want to conquer Russia, you're the Tsar of Russia, you don't want to be conquered, right? And then we play a very complicated game, which includes other agents, like your soldiers, which maybe, you know, I, a French soldier, you know, want to conquer Russia, but I also want to stay alive, whereas an opponent really couldn't care less whether I, in particular, stay alive or not, as long as he conquers Russia in the end. So this very complex game, I think, is what goes on. I don't think framing things in this way is anthropomorphizing them. In fact, I think this is our best hope to not anthropomorphize things, although at the end of the day, I think you can look at almost anything and see a ghost of anthropomorphization there. But if there's a less anthropomorphic way to look at the universe than through this lens, I'd be interested to see what it is. Well, the only reason I'm saying this is, first of all, I want to play devil's advocate a little bit, and we even spoke about the blind men and the elephant a little while ago, and I'm sure folks on the left, as they did, they criticized Ayan Ran, for example, and they said that she had this very transactional way of viewing the world as this kind of Nash equilibrium of self-interested actors. And are we guilty of doing that? Are we kind of cutting off many aspects of the truth by doing this? I guess that's what I'm saying. So we are always cutting off some aspect of the truth when we look at anything in any way, which is not a reason to look at nothing in no way. So I think this is a very productive way to look at things, but not the only one. It doesn't exhaust what there is to be said, but I personally feel like it's the one where the most progress can come from. Interesting. Now, that's sort of like Ayan Randian simplification of the world. Looking at things this way does not imply over-simplifying them. On the contrary, I would actually say it gives us a handle on how to go into the complexity and not get lost and not devolve into like platitudes or over-simplifying ideologies. The fact that there's a mathematical component to this is very important. Mathematics, when you can apply it, gives you a very solid handle on things. We are now at the point where we can handle a lot of things mathematically slash computationally that we couldn't before. So when von Neumann invented game theory, he said, this is the future of the social sciences. And so far it hasn't been, but I think we're actually now at the point partly because we have the data. We actually can now usefully apply this point of view in a way that we couldn't before. How far it takes us, we'll see. It's not the only possible to look at things, but I do think it's probably the most productive at this point. Interesting. Okay. So coming back to this rationalist school of thought, one thing that I'm interested in is morality. But let's go one step at a time. So I think Bostrom came up with this idea of instrumental convergence, which is this notion that in the pursuit of doing a particular task, the intelligence system might actually potentially kill everyone on the planet or do adjacent. And this is where the interesting thing comes from. So one task, but adjacent multitask ability and potential intelligence and so on. So there was an example of a cauldron. So you've got someone filling up a cauldron and in the pursuit of filling up the cauldron to just the right level, they might kill the person who looks after the cauldron room just so that the agent could do it more efficiently. Are you cynical about that or what do you think? No, I'm not cynical about that, but let me put it this way. I don't lose any sleep worrying about the paperclip factory that's going to take over the world. I think you have to take that as a philosopher's thought experiment. The philosopher being Nick in this case. I think there's a real danger that there's putting its finger on, but it's also mistaking reality for something else. So let's look at both parts of that. The real danger is that if you give an AI an oversimplified, a hugely oversimplified objective function, and at the same time a very large amount of power, bad things will happen and we need to worry about that. By the way, this is already a problem today in many maybe more modest ways, but also more relevant, frankly. So what do you do? First of all, the utility function needs to be as rich and as complex and as subtle as the people that it's trying to serve. As long as what you have to take a really world example today, social media, who are all designed to just maximize engagement, you have an enormous amount of AI at the service of maximizing engagement. I understand why companies do it and partly they have the right to. We can get into that. But the point is, it's ignoring too many things. So one line of defense against is that you have to enrich your utility function until it's like a bit, and then this is an open-ended problem. We're never going to have the final utility function. It's something that the AIs have to be continually, you know, AIs, I think Stuart Russell said this and I agree, like they should spend half their time figuring out what the utility function is and then the other half maximizing it. Whereas today it's like I wrote down my utility function in one line and now I spend this enormous amount of power maximizing it. So that's one line. The other line or like one other line is you have to put constraints on the machine. Hard constraints. You can win the pursuit of this utility function. You can think of it as like, you know, terms with infinite weight in the utility function. You can't go outside this. And then the other one is the single biggest reason why I sort of like this paperclip experiment is silly is that, you know, along with that paperclip factoring the world, there are going to be a million other AIs, you know, each of which is doing the same thing. So none of them is ever going to acquire the power to cause that damage unless it's doing something very different from just trying to make paperclips. So at some level that example is extremely unrealistic and leads us down the wrong track. Right, loads of places to go there. But first of all, I think you do believe in AI alignment then because you're saying exactly the same as what they do, which is that we need to have the utility function that represents the richness of the human condition. So that's the first thing. So essentially you're all on board of alignment. Well, I believe in AI alignment in one sense of it. Many different things get go under that umbrella of AI alignment. Right. I think in the near term, thinking of things into, I mean, if I like, let me put it this way. If AI alignment is just trying to have a really accurate utility function, then yes. And then the machines are optimizing that function. Absolutely. Right. Yeah. And in the near term, I think talking about AI alignment is a little, I mean, the problem that I have with the concept of alignment is that goes far beyond that. It tends to see AIs as these independent agents that we have to align their goals to ours. Right. And if that just caches out as like, here's the utility function, that's fine. But the problem is AIs are not independent agents. AIs are our tools. Just to push back on that a little bit, because I always had that conception of these folks. I thought I was arguing against people who believed in a pure monolithic intelligence. And a lot of them are transhumanists actually, and they say that they want to ensure human flourishing through the use of AIs in tandem, almost as a kind of extended mind from David Chalmers. But then I really wanted to get into their fears of recursive self-improving intelligence and superintelligence. Because when you do have this kind of heterogeneous approach to humans and machines, there are going to be bottlenecks everywhere. Now, I like to think of it a bit like the market efficiency hypothesis, which is that you reach an equilibria where the individual actors in the market become more efficient, will become more efficient programmers. Because we're using codecs. But we will reach a limit, surely. Well, to touch on transhumanism for just a second, because I do agree, at least sociologically, a lot of that crowd is the same. Let me put it this way. And I'm sure this is a controversial statement. But maybe in the long run, the AIs should take over the world. Why are we so arrogant that we think whatever the AI is, it should always be there to serve us. We are a step. If you take the long view of this, we're a step in evolution. We're amazing. Maybe I'm a human chauvinist, but I do think we are amazing. But we're not the last word. So the other day, I tweeted something that is maybe provocative, but it's like, I think in Gemswich, which is, I said that the killer app of humans is producing AI. Maybe our role in evolution is that we're going to produce an AI. That is the next level of whatever you like. Consciousness, intelligence, et cetera, et cetera. And so the notion that in the very long term, the AIs should still be there to serve us, by this point of view, is actually silly. Right, but a lot of folks, let's say the ethics folks, would find it horrifying. And I was speaking to Irina actually yesterday, and she said something a little bit tongue in cheek, which is that which is actually... Who, sorry? Irina from Montreal, Mila, and Irina Rich. Oh yeah, I know her, yeah. We were classmates at UC Irvine. Amazing, yeah, I really love her. But no, she was kind of joking that we should almost align human values to the AGI values. Well, that I find alarming. Well, I think she was saying it tongue in cheek. I'm not alarmed by a lot of things, but yeah. But what do you think about this ethical concern that if it is the case that you believe that we're just one rung on the ladder and transhumanism is more AI than it is human? People would find that horrifying. Well, I understand why people would find that horrifying. And I mean, again, we have to distinguish the short from the meaning from the long term. When I say something like this, I'm talking about the very long term, right? Trying to make humans subservient to AI today is a horrifying idea, right? Now, I think the reason a lot of people are horrified with this idea period, right? Is natural, but in my view, naive is just, they are seeing humans as the end goal. If humans are the end goal, then the idea that they should be subservient to developing the next level of AI is horrifying. If you have a moral system where humans are the be all and end all, then all of this is horrifying. But again, if you take the long view of evolution, humans are not the be all and end all. Okay, I mean, eventually this might take us to the effective altruism discussion. But I think, as we were saying, Sam Harris recently had a podcast talking about the FTX disaster. And he was kind of making the argument that we're all consequentialists, even if we don't realize it, but there are different degrees of consequentialism. And I think a lot of the ethics folks at the moment, they really, really don't like what's going on with long termism. And it's because there's this slippery slope of the kind of horizon of consequentialism. So with Nick Bostrom, he came up with this number that there could be simulated humans living on other planets in the future. It's a very big number. I think it's got a lot of zeros on it. And what's to stop us from just making the argument and what's to stop AIs from making the argument that those simulated lives have more value than our lives? Okay, there's a lot to unpack there. So, but let's take this one step at a time. I very much by the idea of effective altruism on principle. I think that is the way to go about a lot of things. I think in some ways, if you are not an effective altruist, maybe unconsciously, you are being irrational or maybe evil, right? If you believe in altruism, I mean, think about both parts of that, right? If altruism is good, then let's say we take that, right? And then why should you be in favor of ineffective altruism, right? If you're an altruist, if you want the good of other people, you should try to do the best you can, right? And so, for example, I very much by the notion that like, you want to make the most money you can, so then you can give away that money as opposed to volunteering at the soup kitchen. Volunteering at the soup kitchen for, say, someone with a PhD in machine learning is an ineffective form of altruism. Now, having said that, I think the focus on the long term has been in many ways, I mean, certainly the long term is important, right? But the problem with the whole effective altruism movement is that it got overly focused on that, and we can talk about why. And then even, and then a further mistake is that it got overly focused on these supposedly existential dangers that are much less of a big deal than people think like AI. So between effective altruism and fixating on AI as an existential danger lies a huge gulf. I'm for effective altruism, I think, you know, the long term, you know, there's ins and outs there, right? And then this focus on like these existential dangers is very problematic. You know, for example, you know, to get back to the, you know, Bostromian notion of like all these minds that matter more than us and whatnot, there is a basic idea, right, that like any economist knows, which is that you have to discount the future. And the question is what your discount rate is, right? And if your discount rate is high, right, those minds matter not at all. And now why do you have that discount rate? The primary reason is that there's uncertainty about the future, right? I have to weigh the certain benefit of helping you today with the increasingly hypothetical benefit of helping your mind. There's less and less likely to exist in the future. So in many of those cases, the present and the short-term do win. Okay, but a couple of things to contrast that. So a lot of effective altruism is this idea that we're born with faulty programming, right? So we have these views, you know, like we have this concept of moral value and it gets discounted in space and time, right? So we need ways of overcoming our programming. But you were saying that we should be thinking about this, but contrast that with your, you know, with your statement about Ayan Rand earlier, right? So Ayan Rand was very, very transactional because I think the folks that criticize this movement are suspicious that we are actually being a bit more like Ayan Rand, but with the guise of altruism. And I think they think of the FTX disaster as being kind of like evidence of that. A lot of different points there. The FTX disaster actually has nothing whatsoever to do with any of this, right? Sam Beckman Fried was one guy or is one guy, funny that I used the past tense. He's one guy who believed in effective altruism, good for him, right? He was, I mean, the whole FTX thing was also obviously, I mean, yeah, we could get into that, but the point is you should not, I understand why people's image of effective altruism would be tainted by what happened with Sam Beckman Fried, but really it shouldn't be, right? An idea is not responsible for the mistakes that its believers make in unrelated domains, point one, point two, transactionalism. There is nothing in what I've said whatsoever that implies transactionalism, in fact, the opposite, right? I think relationalism is actually the key concept. And part of this is that games are not one shot. Your games are played in a repeated way. And famously, for example, if you play things like Prisoners of the Lemon and whatnot repeated, like you're like, cooperate, defect and whatnot, as soon as you start bringing in these other things, like that make things more realistic, you actually start to get behavior that is much more, what's the way to put it, rational in some ways and human and whatnot, right? Another one is that traditional economics, which I think Ayn Rand was influenced by, viewed and still views the world as linear, but the world is non-linear. Once you start seeing the world as non-linear, all of these things really change, the face of them changes, right? So I think we have to look at all these concepts in this view, right? And we want to focus on the long, so... So to get back to your first point, right? We are born with faulty programming. Part of our fa... And that's what if effective alteration is there to overcome, right? Part of our faulty programming is that our discount rate is too high, because we evolved in a world where your time horizon was very short. The fact that it's too high doesn't mean that we should make it zero and care only about the future. But what would... You know, the ethics folks who advocate for gatekeeping and paternalism, couldn't you just say that they're doing the same thing? Well, you should ask them, right? Wouldn't they lead by saying our programming is faulty and therefore, you know, we need to... No, I mean, look, we can... So part one, we can debate whether our programming is faulty or not and why. And so to just start by touching on that, our programming is faulty. So our programming is not faulty in the sense that we evolved for a particular set of conditions, right? And that evolution may not be complete or optimal, et cetera, et cetera. But roughly speaking, we are not faulty in that sense. The reason... Because evolution is doing its job, right? We have all those impulses for a reason, right? Now, the problem is that we, unlike any other species, we actually have actually succeeded in creating a world that is better for us. But at the same time, and this is the problem, we're actually now adapted to a different world from the one that we live in. So the faulty program just comes from the fact that we evolved for one set of conditions. For example, among many other examples where your time horizon was very short, and now we live in a very different world. And so our job as rational people, that's what our rational minds are for, among other things, is to now adapt ourselves to the world that we really are in so that we do things that are rational in the world that we're in, right? So now, the fact that our programming is faulty does not see anything about what are the faults and how you fix them. And what these people have, I think, is first of all, the wrong notion of what our faults are and then on top of that, the wrong notion of how to fix them. Okay, now, I want to get into the utility function again. Again, one of the things that makes me skeptical is this notion of immutability, both of what we're doing and in the case of what we've been speaking about with utilitarianism, what the utility function is. Now, you were kind of hinting to something interesting before, which is that it might be diverse and it might also be self-updating. But I'm constantly asking myself the question, how does that work and who gets to say? Well, so very much, I think it's complex and it should be self-updating, right? We're never going to final itself. If you buy this notion that the ultimate arbiter is evolution, then utility functions are subject to evolution. Right, so you think about it or you can't think about it. It's a wrong world. You can't think about this and it's useful to think about this in the following ways. To a first approximation, the number one entity that's evolving is utility functions. What you have in the world at any point is a population of utility functions, right? And now they combine, they evolve, you have next generation of utility functions. And then there's also how the utility function gets optimized. That is also subject to evolution, right? And now how the utility function is optimized changes a lot faster and this is a lot more complex than the utility function itself, which is the point, right? So at a certain time horizon, it's reasonable to approximate utilities as being fixed. Like for example, the utilities that are encoded in your brain are fixed by your genes, right? So in the context of our present human moment and effective ultramism or not, it makes perfect sense to think of utilities fixed. But it is evolving and not just on eon time scales, but by the generation, right? Things evolve by the generation. Okay, but it's still relatively glacial and I take your point that there's a kind of divergence between the world we live in and the programming that we've got. But then, okay, let's imagine that we create a new population and I guess what I'm saying is that you think that the utility function should emerge and evolve, but I would argue for some kind of morphogenetic engineering where it's a kind of hybrid between something which is emergent but something which we can nudge. Oh, I mean, I'm glad you brought that up. Nudging is a form of emergence. You yourself are emergent and the things that you do are emergent as well. Everything is emergent, right? Utilities are emergent. Maybe the laws of physics aren't emergent. Some people will say even those are, right? Like, you know, we live in a universe with this constant because blah, blah, blah, right? So, but to first approximation, every single thing that we've been talking about is emergent. We make a distinction between emergent and designed because that is anthropomorphic, right? Is this things that we do are not emergent? Actually, no, when you nudge something that is an emergent behavior, right? We are emergent as well, right? So everything that is human, you know, so here's a very good way, I think, to think about a lot of things which I first saw, you know, in Richard Dawkins, which is although he really didn't go into this and I wish he had like this notion of the extended phenotype, right? Technology is our extended phenotype. So all these things that we do, right? All these things that we build, including AS and whatnot, they are extensions of our phenotype. So if you take the long view, all of, you know, technology is the continuation of biology by another means. So when you make this distinction between emergent and not emergent and top down and bottom up, it's all emergent. Interesting. Well, we recently did a show on emergence and it's a topic of interest to me personally and there's weak emergence and strong emergence and there's, you know, like the view of weak emergence, so there's some, you know, surprising macroscopic phenomena, maybe something which transiently emerges and Wolfram would add in the whole, you know, computational irreducibility angle. And then with the strong emergence, Chalmers would say it's something which is paradigmatically surprising. It's something which is not deducible for many fundamental truths in the lower level domain. But I just wondered, like, how do you think about emergence? Well, I think that is a very, the distinction between weak and strong immersion is a very useful one. Right. And I would actually phrase it in slightly different terms, which is starting from physics, right? I think most physicists and scientists believe in weak emergence. Well, could I, could I add that Sabine Hossenfelder had a paper and she frames it with this idea of the resolution of physical theories. So like, like a lower resolution theory as weakly emergent from a high resolution theory. Well, exactly. And, you know, like, I like Sabine, but this is not her idea, right? This far predates all of us here, right? Yeah. And again, it's, it's a very interesting history and a very important concept. Now, so my point was that I think few people have a quarrel with the notion of weak emergence in the sense that, you know, I can give you a theory of everything in the form of whatever string theory let's take a candidate, right? But no string theory claims that that's a theory of everything in the sense that like now, to study biology or psychology or sociology, you should just study string theory. No one believes that, right? There's actually interesting things to be said there, but, but let's not, let's look at, let's not go there for a second, right? There are these levels that emerge weakly in the sense that they are determined by the lower levels. They're just so much more complex that you're better off focusing on the menu. Now there's this other notion which to me is the really interesting one, which is that there is, there are phenomena that are at the higher levels that are just not reducible to the lower levels, right? So the true emergent is in some sense is someone who believes the latter. And now you can ask the question, like do you believe in that or not, right? And I think to give the very short answer first is that ultimately there's probably no way of knowing. But pragmatically, you're actually probably better off treating the world as if it has strong emergence. And now strong emergence is actually a very strong segment to make is to say, and by the way, going down to the lowest levels to make things very clear, you don't need to think about biology or society or consciousness or anything. Condensed metaphysics, right? The particle physicists tend to believe that what they do is what everything reduces to. You talk to the condensed metaphysicists. This was actually an interesting discussion that I had with Scott, you know, Aronson, because like he was very much on the, we're both computer scientists, but he was very much on the side of the particle physicists, I don't know very much on the side of the condensed metaphysicists. What they will tell you over and over again, they see is things that you cannot explain using quantum mechanics. And now people say like, oh, but you can always explain things in quantum mechanics. You just haven't done the calculations. But the point is precisely that you can't do the calculations, right? The calculations are chaotic. I have a theory, I can come up with 500 theories of these phenomena and semiconductors and whatnot. And like, I never actually get to test them because the computations diverge before I get to test them. So for all intents and purposes, it is strong emergence. Whether truly that came from below is unanswerable because you can't compute the predictions. Well, we spoke about that. So I think Keith would call that semi-strong emergence, which is like, you know, whether it's computationally reachable from the lower resolution to the high resolution to the lower resolution. But no, Sabine in her paper, A Case for Strong Emergence, she was talking about singularities as being a really good example of what might be strong emergence. And the philosopher Mark Badau, I think, said that strong emergence is ridiculous. It's basically an affront on physicalism. Well, certainly, you know, strong emergence and physicalism, or let's just call it reductionism, right? Reductionism, yeah. Strong emergence and reductionism are incompatible. Yeah. And we scientists tend to be reductionists, right? Now, at some level, I'm both a reductionist and someone who is willing to believe in strong emergence. Again, I don't believe in strong emergence. I just don't see a way to disprove it, right? And like, you know, if there's an empirical way to distinguish semi-strong from strong emergence, I'd be very interested to know what it is. But now, I think the thing that is very important that a lot of people, including a lot of physicists and scientists don't see is that we have this hypothesis that everything can be reduced to the laws of physics as we know it. We should not forget that it's just a hypothesis. And it's a hypothesis that, again, counter to a lot of people's say, is very, very, very, very far from established. And usually, people say like, oh, but, you know, look at all the successes of the laws of physics and blah, blah. And then I say, like, you know, putting on my machine learning hat, the sample that you've used to validate the laws of physics is extraordinarily biased in the direction of simple systems. OK, so you can't make this claim of if the data was IID, I could say with great confidence, these laws apply universally. But I haven't done it. It's more like I've just landed in a new continent and I've sealed up all the rivers. And I say, I know what this continent looks like. You've never climbed the mountains. You've never gone in the jungle. So like this notion that the laws of physics capture everything about daily life, we just don't know how exactly. Maybe it's true, but it could also equally well be completely false. Brilliant. Well, you gave a bit of a hint to this earlier, actually, because you used the word relationism, right? Which is basically the... Or relationalism. Relationalism. Maybe it should be shortened to relationalism. Relationalism. But yeah, I think Rosen is a great advocate of this, and he has a whole category theory calculus for describing living systems. And also we spoke to Bob Koek, the quantum physics professor from Cambridge, and he was talking about this concept of Cartesian togetherness, which is another category or framework. But I just wondered, does that inform your view? Well, relationalism, at least in one way of defining the term, very much informs my view, right? And one way to come at this is to say, the world is not made of independent entities. Actually, let's just start with machine learning, which is a very concrete way to look at this. A very large part, maybe even the largest part of my research in the last 20 years, has been to do away with the assumption of IID data, right? That the world is made of independent entities, in particular, society is made of independent agents, et cetera, et cetera, right? Now, we make this assumption, both as human beings, to some extent, and certainly very much so in science, because it makes life easier. The math is way, way, way easier when you assume independence. But it's a blatantly false assumption, right? Unfortunately, a lot of, for example, economics prominently has embedded in it this notion that the world is a bunch of independent agents, and it just doesn't work like that. And moreover, it's a distinction that is full of consequences. A society and economy is a network of agents, and almost all the action is in their interactions. Until you really start taking that seriously, you really don't understand the world. Again, I have no quarrel with classic economics as a first approximation. It's exactly what it should be, right? But then, and by the way, you should also not just throw it away and say, like, oh, this is garbage, like some people say. You have to go the next stage. It's actually now we have the mathematical and computational tools to do, and understand it as being a system of interacting agents. And all of the questions that we are talking about, including in evolution, even in physics, right? A piece of condensed matter is a network of interacting, spins, et cetera, et cetera, you name it. So the relations are at the heart of it, and moreover, like as I said, a lot of my work is we now have the representations, the learning inference algorithms to handle things that are big piles of relations, and the whole world is better understood in those terms, and we just need people to catch up with that. You know, once you do that, you get into things that can easily be computational, intractable, and so on and so forth. But there's a lot of things that we can do there and a lot more that we'll do. So at this level, I think relationalism is really should be a cornerstone of our understanding of the world in a way that it hasn't been in the past. Okay, and which existing complexity science brings to mind? But I mean, which existing techniques and areas can folks look into to take that on board? Well, you know, Markov logic, which is what I developed for this purpose essentially, and I do think, you know, this is my talking about my work, so you should naturally be suspicious, but I think it's the best that we have, and I think by a wide measure, compared to anything else that we have so far. Okay, and can you sketch it out? Yeah, so to sketch it out in the simplest terms, right, we want to combine all the traditional goodies that we have from assuming the world is IID with the power to model, you know, relationships, there are themselves potentially very complicated. The way we do the Markov logic is, there's the logical part. We actually do not need to solve a new, the problem of how to represent and do inference with relations. We have first order logic for that. First order logic is the language of relations. That's actually the term that is used, right, and how the relations depend predicates. Sometimes they're called predicates, but let's just call them relations, right? We have a formal language to talk about relations. And by the way, essentially all of computer science can be reduced to that. You give me your favorite, you know, whatever, knowledge representation, data structure, et cetera, et cetera. And I, anybody who knows can immediately say how to do that in logic. So that's one part. The other part is the statistical, you know, machine learning probabilistic aspect of the world, right? And then again, going all the way back to physics, right? All of these things that we deal with are essentially special cases of what are variously called Markov networks, which is where the name Markov comes from. Or graphical models, or log linear models, Gibbs distributions, Boltzmann machines, right? All of these things are essentially the same, right? That whole neck of the woods is captured by Markov networks. Let's call them that. And Markov logic is combining Markov networks with first order logic in a single language, which you can now do everything with. Okay, okay. So just to like push back a tiny bit. So in the past, we've tried to create, let's say things like psych, which is a knowledge representation of the world. Folks like Montague have tried to do semantics using first order logic to set some, you know, varying degrees of success. And then we have the grounding problem we were just talking before about, you know, like even Searle said this, that you have kind of epistemic objectivity and subjectivity and some things are observer relative, like even economics is observer relative. So with this kind of formalism, how would that work? That's so very good. The problem with or the main problem with a lot of these things that you mentioned, like, you know, certain types of semantics and whatnot, that are based essentially on first order logic, right? Is that they're too brittle. In fact, the problem with symbolic AI is that it's too brittle. And this is exactly what Markov logic fixes. It fixes it by making it statistical. When I give you a logical statement now, I'm no longer, for example, simple logical statement, you know, a smoking causes cancer, right? In English, this is a valid statement. Smoking does cause cancer. But actually, once you translate it to logic for every x, smokes of x implies cancer of x, it's false because some smokers don't get cancer, right? What this really was meant to be all along is a statistical statement that says, smokers are more likely to get cancer. So the way we overcome a lot of those problems is precisely that we take all of this logic, which again, the language exists, we don't have to change it, we can, but we don't have to. And we make it statistical. As a result of which, it's no longer brittle. Or at least now it's only as brittle as machine learning and graphical model or not. It's not as brittle as, you know, traditional symbolic AI. Okay. And so we speak into a lot of Go-Fi people and I mean, Wally Subba, for example, he's a rationalist and what's interesting about the rationalist is they hate any form of uncertainty, right? They think in absolute binaries. You either know it or you don't. No, I mean, let me push back on that. There's this, again, you need to distinguish, you know, a general field or idea from its subtypes, right? There is a type of rationalist. That hits uncertainty, big mistake, big, big mistake. There's a type of rationalist that, you know, uncertainty is what they, you know, like, an uncertainty calculus is a type of rationalism. And some of the best, you know, AI, philosophy, etc. is just that. So there is no incompatibility at all between rationalism and uncertainty. In fact, if rationalism, if being rational is maximizing expected utility, notice the expected in there, right? You cannot be rational if you ignore the uncertainty. Interesting. Okay, but then what about the resolution of modeling? I mean, smoking is a really good one. So us humans, we anthropomorphize things. We understand the world in macroscopic terms using macroscopic ideas that we understand. And that kind of leads to a certain type of modeling. And that modeling presumably would be represented at that resolution, you know, using this formalism. Sure. And what's the question? Well, it seemed, again, like I'm intuitively suspicious that we were just saying the world is a complex place. And with a lot of causal modeling, for example, a lot of the art is understanding what is relevant and what is not relevant. What is relevant might just be kind of, you know, relevant to us. No, well, what is relevant is what is relevant relative to your utility function. Okay, again, it gets back to that precisely. The whole problem is that the world is infinitely complex and we have only finite computational resources, whether it's in our brains or our computers or whatever, right? So now what do you do, right? You are forced to oversimplify the world, not just simplify, but oversimplify, right? But now the whole art, that's actually a good word to use, even if it's done with computers, is how do you not only oversimplify as little as you can, but pick out the simplifications that are least harmful to your objective. By the way, the art of the physicist, physicist would tell you, is precisely doing this, right? Physicists are very good at deciding what to simplify. And in fact, almost, I think at some level, almost any good scientist, this is what they do, right? So, and now how do I decide what and how to simplify is by relevance to my utility function, right? I want to ignore parts of the world that do not affect my utility function, number one, right? And for example, the notion of conditional independence, which is the foundation of graphical models, that's what the whole idea is. It's like, once I know these things, I don't have to know about those others. Thank God, right? Okay, but if Ken Stanley was here, he says that the great thing about evolution is it's divergent, it's not convergent, it's discovering new information. And my worry is with a system like this, with any form of anthropomorphic design, would inevitably become convergent. And it might look like, oh, those things over there that we're ignoring don't matter, but actually they might really matter if they got introduced into the utility. Well, I wouldn't say that maximizing expected utility is anthropomorphic, right? In fact, it's one of the least... I think maybe there's some degree of anthropomorphism is almost anything we do, and the progress of science is becoming less and less anthropomorphic, and we should keep pushing on that. But I would say that maximizing expected utility is one of the least anthropomorphic things we can do. Well, this is actually a really interesting point, because one of the key tenets of the rationalist movement and their conception of intelligence, because all of the other definitions of intelligence are anthropomorphic. So, you know, there's based on behavior, capability, AI, principal function is a big one, you know, from Norvig. And this is the principal based AI, which is just making rational moves. So why is there such a push to be as, you know, to be as the least amount anthropomorphic? Oh, the push is not to be, at least in my view, being less anthropomorphic is not a goal. That's not the goal. The goal is to be as accurate and complete as we can in modeling the world, right? We're just trying to understand the world better, right? For whatever purpose, maybe for its own sake, maybe for the purpose of the utility and the evolution and so on, right? But that's the goal. The problem is that, and this has been the problem since they won, right? They won of humanity, is that because we anthropomorphize the world, that gets in the way of understanding how it really works, right? If I say the wind is some God blowing, right? I understand, right? That's all they could think of. But it's a big obstacle to understanding what the wind really is, like there's a pressure difference, et cetera, et cetera, right? And we've done away with a lot of anthropomorphism. By the way, one of the problems that we're always having is that it's always pushing back, right? You know, there's always, you know, again, intuitively we have a very strong tendency to anthropomorphism, as much as science broadly construed as a great victory, it's always in danger from this, right? But even within science, we've gone from doing away with the obvious forms of anthropomorphism and anthropomorphism to having many things that are still there that are less obviously anthropomorphic, but still are, right? But if there's something anthropomorphic that's actually is accurate, then more power to it. Interesting, yeah. And then I guess we have so many cognitive priors, right? In our brains that give us a cone of attention, which is completely anthropocentric. Well, very good. So those priors, and maybe a better term is heuristics, right? Our brains are full of heuristics that evolution put there for a good reason, because those heuristics work, right? But they are heuristics. So they have failure modes, right? And we need to understand what is that those heuristics really are getting at so that we also, so that we use them when they're good. But then when they're not good, we use something else. Brilliant, brilliant. So Pedro, we're here at NeurIPS this week. And could you just like sketch out some of the some of the things you've seen? And I also know that you're a huge fan in that there's a Neurosymbolic algorithm that you want to tell us about. So let's let's hear it. So I indeed, I've been enjoying NeurIPS this week. One of the big things in AI in the last several years has been Neurosymbolic AI, which you probably will not surprise by the fact that I very much believe in. So and I believe this since I was a grad student and the whole idea of Neurosymbolic AI was something that nobody was interested in, right? And now suddenly everybody is, which I think is a good development. And this is the idea that if we really want to solve AI by some definite, if we want to get to like human level intelligence, etc, etc, we need to have both, you know, like, for example, deep learning is not enough, right? There are symbolic reasoning capabilities that we have and that are essential. And we need to get them. And I think, you know, intelligent connection is like, I don't know, Yoshua Ben-Joe, you know, Yanle Kunase, they don't disagree with this. But one way to look at this is say, we're just going to realize those, you know, capabilities using purely connectionist means, right? And what I see happening in that direction, unfortunately, is a lot of reinventing the wheel. So I do think, you know, symbolic AI got wedged for some reasons, including brittleness. And, you know, and we have learned from that at the same time, they did discover and understand a lot of things that are extremely relevant. So it's just not good science to ignore it. So I'm working on an approach to combine, you know, symbolic AI with deep learning. Again, this is a popular exercise, there are many interesting approaches out there. As much as I sympathize with them, I think they're all very far from solving the problem. They are over complicated and not powerful enough. So, you know, I've been working on an approach called TensorFlow logic that I do believe is as simple as it can be and as general as it can or needs to be. And this, you know, it really is a deep unification of the two things in the sense that it's not just that you combine them using, you know, a neural model that causes symbolic one or vice versa, which is a lot of what these things that you have today do. And a lot of the claims that like, oh, this system is neuro symbolic, which it is. It's like, you know, AlphaGo is neuro symbolic because some of what it does is symbolic. But I'm talking about something much deeper, which is once you start doing AI, learning inference representation in TensorFlow logic, there's just no distinction between symbolic and neural at all anymore. Can you explain that? So TensorFlow logic, I'm just inferring from that that the primary representation of substrate is a continuous vector space. Is that right? Are you encoding discrete information into the vector space? So it's a vector space. Yeah. Right. In fact, this was the original term that we had for this was vector space logic. But then we changed it to TensorFlow logic because it's much more appropriate. But it's it's vector space in the abstract algebra sense of vector space, not in the traditional, you know, vectors of numbers. But anyway, so as the name implies, right, TensorFlow logic is a combination or unification of tensor algebra on the one hand and logic programming on the other. So is it similar because Bob Koeck had a similar idea using like tensor outer products? Is it that kind of? It's related, but I think it goes well beyond. Okay. And the basic idea is actually pretty simple. And it's just the following, right, without going into too much, you know, technical detail. All of deep learning can be done using tensor algebra. Yeah, you know, plus univariate nonlinearities. Right. So we've got the tensor algebra to do that. All of symbolic AI can be done using logic programming. And moreover, it has been done using logic program. So if you can unify these two things, this part of the job is done. Right. And as it turns out, you can unify them shockingly easily because a tensor so tensor algebra is operating on tensors, you know, in that logic, so logic programming, and then for learning in that logic program and symbolic AI, they are all operating on relations. Yeah. Right. So what is the relationship between the tensor and the relation? Right. A relation is just this and efficiently represented sparse Boolean tensor. So at this point, we actually know that the foundation of these two things is actually the same. If your tensor is Boolean and is very sparse, now I'm better off representing it with a relation, but at a certain level of abstraction, nothing has changed. Right. So by this prism, you can look at logic programming and logic programming is doing tensor algebra. Okay. Just help me understand this a little bit. So, you know, the main criticism of using a neural network as a combined computational and memory substrate is that it's a finite state automator. So without having the augmented memory like a Turing machine, you can't represent infinite objects. That's the main reason the symbol is, you know, that's the main argument I used. So wouldn't that argument still be leveled against you? Well, no, because I'm glad you brought that up because there is a very common misconception. If you realize that there is no such thing as infinity, right? And in particular, there is no such thing as an infinite memory. That problem doesn't arise. So there's the, so the, unfortunately, a lot of theorists, including computer theorists, they foster this misconception, right? There's the Chomsky hierarchy, right? With finite automata at the bottom and Turing complete, you know, Turing machines bubble at the top, right? If your Turing machine has only a finite tape, it's a finite automata. So everything is just finite automata. Let's get that out of the way, right? A lot of what people do is like completely mistaken because of that. Now, the fact that everything is finite automata does not mean that everything is equally good. Some representations are far more efficient, compact, etc., etc., for certain purposes than others. And the whole game here is that like, I'm not going to solve a finite automata. The question is like, what do I need to do? Not because I need to go to a higher level of Chomsky hierarchy, because in reality, they don't exist. But because, you know, I mean, if you have infinite resources, you could solve a gap with a lookup table. But would you, would you not? I mean, for example, there was this DeepMind paper that mapped architectures to different levels of the Chomsky hierarchy transformers, I think were, you know, FSAs, RNNs actually were one step higher. They could represent regular languages and they got context-free languages. I mean, do you think there's any meaningful distinction between those language levels? As I said, there is a meaningful distinction, but it's not the distinction that people usually make, because once you, I mean, you can debate whether the universe is finite, but certainly computers are finite. So as far as anything that you're going to run on a computer, there truly is no distinction at this theoretical level between a Turing machine and a finite automata. That does, so like, I can reduce and people have, there are papers reducing, you know, any of these things to any of the others, right? It's like it's a fairly trivial exercise. So at that level, those distinctions are completely meaningless. However, they are meaningful in the sense that for many purposes, I am better off having an RNN than having, you know, a transformer. And for many purposes, I'm better off. So like, let's take, you know, propositional logic versus first-order logic, right? If there's no such thing as infinity, first-order logic is reducible to propositional logic. But that does not mean that it's useless because it can represent a lot of things exponentially more compactly than propositional logic. If I want to represent the rules of chess in first-order logic, it's a page, right? If I want to represent them in propositional logic, it's more pages that you can have. Okay, well, I think that that's a very, very good point. But I mean, just, just a devil's advocate from the psychologist, you know, do you remember that, that photo, Felician Connectionism critique paper, arguing productivity and systematicity? Productivity is all about the infinite cardinality of language. I mean, presumably you would agree that language has an infinite cardinality. No, well, again, another instance of the same problem. Productivity is very important. But the point to just be a little precisely for a second is, is to be able to generate a vast number of things beyond the ones that you started with. Vast, not infinite. In fact, mathematically, infinity is not a number. Infinity is just a shorthand for something that is so large that it doesn't matter how large it is. Okay. I mean, at the end of the day, I'm not a mathematician, but surely mathematicians would push back on this because, you know, infinity is, is a quantity in mathematics. No, I mean, again, people in every field, mathematicians, physicists, computer scientists are all are often guilty of they, they, they, they have this notational shorthand or like, you know, this terminological shorthand that serves them well. But then they, and then they use that and then the newer generations come along and the, and the public also, right, they don't even realize that what's being talked about is a little bit different. Infinity is a perfect example. Any serious mathematician will tell you that infinity does not have the properties of a number. So for example, if I multiply infinity by 2, I still get infinity. There's no number that that happens to, right? So infinity is, is not a number, right? When I say infinity is not a number, mathematicians might quibble about the way I'm stating it, but this is a, this is a mathematical truth, right? Infinity truly isn't, I'm being colloquial, of course, when I say that it's a shorthand for something that is so large that it doesn't matter how large it is. When you take limits, you know, in calculus in anything and the limit of this blah, blah, as I go to infinity, this is exactly what I'm doing. I'm going to the point where I'm saying like, at this point, it doesn't matter how large the number is, the result will be the same. And in this way, infinitely is an extraordinarily useful concept. So I'm not here to rail against infinity. I'm just saying like, we really need to understand, I mean, like, let me give you a very banal example, right? From the point of view of, you know, what to have for lunch, right? Because some things cost more than others. Elon Musk is infinitely rich. He does not have infinite money. But it makes no difference whatsoever whether he has whatever 100 billion or 200 billion to what he's going to have for lunch. You know, like a street person who has $5 to them, like their fortune is not infinite, because it very much matters what lunch costs, right? So this is the real sense of infinity, which we can and should use, but we shouldn't confuse it with like, oh, but then your, you know, like your formalism is incomplete because it doesn't encompass infinity. Yeah, it doesn't need to infinity doesn't exist. Okay, okay. Well, let's come at it from the other from the composition, you know, compositionality and systematicity. So that's all about being able to do, you know, like their main argument was when you have a symbolic representation, you can kind of reuse the previous representations downstream composition, compositionally. And when you take a discrete symbolic representation, and you kind of encode it in the envelope of a vector space, you have a real problem doing that because it's now like, it's irreversible that transformation, right? You can't go back to the original variables. Well, it is reversible if you realize that all those real numbers are actually finite. Right? So notice that real number, there's nothing less real than a real number, real numbers are imaginary, right? Real numbers are numbers with infinite precision, which is a monstrosity. And many people have said this, including mathematicians and physicists, right? The notion of an infinite, of a number with an infinite number of digits is just monstrous. And again, in particular on a computer, even if you use, you know, you know, like numbers with unlimited floating point precision, right? It's limited by the size of your memory. So this transfer from which is actually very important that again, that's what tensor logic largely is about, from purely symbolic structures to embeddings in a vector space, right? That vector space is still finite. So there's actually nothing irreversible about what happened there. Interesting. Okay. So how can people, you know, find out more information about this? And can you just sketch out, you know, just, just to bring it home to people where they could actually use it and how it would be, you know, better than what they can currently do? Right. The answer to the first question, unfortunately, is this is not published yet, but hopefully it will be soon. So for the moment, there is no very good place to point people to unfortunately, but that hopefully will be fixed soon. The question of where to apply it is, our goal for this is that this should become the language or hope, I should say our hope, is that this will become the language we're doing just about anything in AI. So for example, if what you want to do is actually nothing symbolic, but you just want to build a convent, you can express a convent incredibly elegantly in tensor logic. Like if you think of, for example, tensor floor or PyTorch versus NumPy, right, they allow that thing to be said much more compactly, compared to tensor logic, they are as bad as NumPy is compared to them. Right. Same thing on the symbolic side. But of course, the real action comes in all the problems where you have both components, the problem with all those problems, which ultimately is every problem in AI, right. You're always like, what happens today that is very frustrating. And that's what we're trying to overcome is like, you start from one of these sides these days, mainly the connectionist one, which you have a good mastery of. And then the other side, for example, the symbolic one, the knowledge representation, the reasoning, the composability, you just hack. Yeah. And your hack solution is terrible. You're like, you're inventing the wheel, you're making it square, you're trying to make it turn, but it's square, right. It's just, you know, it's a disaster. And with tensor logic, you can actually have a very well founded, very well understood basis on either side. So now you don't have to hack either side. Now there's, of course, still things that you're going to have to hack at the end of the day, because at the end of the day, you know, AI is intractable and things are heuristic. But this, you know, is, you know, you know, this notion of a tradeoff that is very important in engineering. Like, people have been exploring different points on this tradeoff curve. The point of tensor logic is that whatever your application is, we're moving you to a better tradeoff curve. It's still a tradeoff curve, but it dominates the old one. For any given X, you have a better Y and vice versa. Okay. And just help me understand, because we'll move over to, you know, the discrete program search and some of Josh Tannenbaum's work in a moment. But there are two schools of thought, right? There's discrete first and there's continuous first, you're on the continuous substrate. But usually the reason for the continuous substrate is stochastic gradient descent, learnability, et cetera, et cetera. And like, help me understand. So are you saying we start with symbolic representation and then we encode it into the envelope? So where does learning come into it? No, very good. So in tensor logic, you can do broadly speaking, two kinds of learning. You can learn the structure of these tensor equations, as we call them, using inductive logic programming techniques. Again, that whole technology is there. And then once you have that, you can learn the numbers by the back prop in particular ways called back propagation through structure, because the structure can vary from example to example, but we know what the type parameters are. So all of the machinery of inductive logic programming and all the machinery of gradient descent and deep learning or not, they're both there available to be used as you traditionally have. Okay, what if I made the argument, though, that it's almost like the inductive logic, you know, like the program search, that's the hard bit. So if you've already got the program, why do I then need to put it into a vector space? No, actually, these are also at the end of the day, in machine learning, we're always trying to learn a program of some kind, right? The question is like, what is the easiest way to do that? And precisely the problem with ILPS with symbolic logic is, that's really a couple of problems. One is that if all that you do, you learn programs that are too brittle, and we don't want them to be brittle, right? And the other one is that each type of search has its limitations. So in particular, in symbolic AI, including ILP, we tend to use a lot of combinatorial optimization types of search, right? What we in AI call search is discrete search. And that is good in some ways, but also very limited in others. The same thing is true of gradient descent, right? And now to go to that for just a second. Gradient descent is not a continuous optimization algorithm. It's not, right? Again, those real numbers are not infinite precision. There's actually nothing continuous going on in the computer. Gradient descent truly literally rigorously mathematically is a discrete optimization algorithm. It takes discrete steps. The assumption that gradient descent depends on, which is that the infinitesimally small updates do not hold. And moreover, in machine learning, as a numerical analysis, we are constantly dealing with this fact that there's a mismatch between our mathematical conceptual model of the space that we're working with as continuous with the reality of the computer that is not continuous. So now this is not, but gradient descent still is a different optimization technique with some very important advantages, in particular the key, right? The power of gradient descent comes from the fact that to move from my current point to a better one, I don't need to try out all the neighboring points because that takes order of the time of the neighboring points. I have a closed form way to compute what is the best one, right? And then I move there. And this is absolutely brilliant, right? Like we don't want to let go of that, right? This is, you know, Newton's enlightenment is bright idea, right? The price of that is that in order to do that you have to make this approximation, which again, calculus is an approximation. It assumes that certain effects are second order and can be ignored. Now, ironically, when you learn a large deep network these days, you're actually in a regime where they cannot be ignored, right? Because these infinitesimal changes are not that infinitesimal because you take a finite step, right? The gradient descent is always taking finite steps, which is why it's a discrete algorithm. And once you take that finite step for any reasonable learning rate, the total effect of the approximations that you've made typically swamps the step that you're taking. So the assumption of calculus that gradient descent is founded on is actually false. Now, in some ways this invalidates a lot of our intuitions. In many ways, and again, this remains to be resolved, a lot of why gradient descent works better than people expected to is in fact that it's doing something else. It's doing stochastic search partly because of the SGD as opposed to being matched partly because of things like this. Okay, well, this is really interesting. A couple of places we can go. But first of all, I remember you did the paper and that introduced elements of NTK theory as well, which might be an argument against the discreteness of the optimization. But also, I wanted to trade off the two types. Well, why is there an argument against the discreteness? Well, isn't there a, with NTK, isn't there like a closed form solution? Doesn't that kind of like erode the discreteness of the optimization? No, I mean, so there's several things here. But like, if you have a closed form solution, absolutely brilliantly go for it, right? There's nothing, having a closed form solution in no implies that it's continuous or discrete or any other thing, right? So, let's say there was a closed form solution and it was like an infinite kernel when it represented some neural network, doesn't that erode the argument? Well, so first, okay, so first of all, in the work that, so the work that I've done that I think you're referring to is like, I have a proof that every model learned by gradient descent is a kernel machine. Yeah, right. And it's something called the path kernel, which is the integral of the neural tangent kernel over the overgraded descent, right? Yeah. And now the neural tangent kernel does not assume that your network is infinite. Most of the theory that people have done with it assumes that the network is infinitely wide, but the definition absolutely does not require that. And none of what I do, and in fact, that's part of why, you know, of its part is that it assumes no infinity of anything. It's for any architecture that you use, and in particular, you know, finite architectures. Okay, interesting. Okay, so hence the discreteness, but can we come back to this contrasting of the discrete program search and the, you know, stochastic gradient descent on a vector space? Now, in the vector space, there are certain characteristics, you know, there are certain symmetries, and even though it's a discrete search through the space, I would argue that it's still continuous in nature, it has certain characteristics. So contrast those two forms of optimization. Precisely so. Exactly. I mean, I think you've put your finger in now. The whole point of these continuous spaces, right, is not that they're continuous, because again, that's, that's a fiction, is that they have a certain locality structure, yeah, that you can exploit to very good effect. And this is exactly what we're going to send us, right? Now, that locality structure doesn't have to be infinitesimal, right? You don't need points to be infinitely close for all this to apply approximately. And again, they never are, and it's always an approximation. Now, the question is, do you want to make these locality assumptions or not, right? Making them buys you certain things, right? But it's also potentially unrealistic in some ways, right? Now, this actually, to take a very concrete instance of this, think of space, right? We model space in science and physics and in anything as a continuous thing, which it is not, right? Which is not to say that, and by the way, physicists are coming to this conclusion, right? These days, the prevailing views is that it's from big thing, is that like, it's, you know, space arises from entanglement, et cetera, et cetera, like space is not the fundamental reality, right? And now, I think that where this is inevitably going one way or another is that we realize that space is discrete, right? But, and this is key, it has certain properties, including symmetries like translations in variance, rotation in variance, et cetera, et cetera, that whole, approximately or exactly, but if those hold a whole bunch of things like that, then you have, you know, your latent variable structure, right, is very well approximated by our notion of continuous space, in which case, it would be foolish to not use it, right? To formulate the laws of physics and to do computer vision and so on and so forth. But at the same time, right, if we believe in it too literally, we walk ourselves into a blind alley. So concretely, look at computer vision, right? People in the universities of computer vision started out trying to do it with differential equations and Fourier analysis and all of that could continue with stuff, right? Because that was the obvious thing to do, right? And it failed. That doesn't work. That's why we need things like deep learning and, you know, Markov random fields that are discrete grids that use, you know, to model the images and whatnot, because you are, along with the approximate continuity, you also often have large discontinuities. And if you can only model the world continuously, you don't know what to do. And the problem precisely is that you have all these phenomena that are like this, including, you know, in vision, but also in, in turbulence and condensed metaphysics and so on, you've got to realize that there are discontinues and not try to shoehorn them into continuity when that's no longer appropriate. Interesting. Okay. Well, can we bring in ILP and can you contrast like the kind of function spaces that are learnable in both methods? Yeah. So ILP, so let me actually preface this with the following. People in every one of these schools of AI tend to have this view that I can represent everything in the world using my approach. So I can like, look, prologue is too incomplete. So why do you need neural networks? But I can also say neural networks are too incomplete. So why do I need prologue? And in fact, kernel machines have a represented theorem that says you can approximate any function, blah, blah, blah, right? So everybody has one of these represent their theorems, right? That says, I can represent anything, right? So in particular, you can do, right? I mean, look, first, our logic was invented by, by Frege, essentially, to, to model the real numbers. So it can almost by definition model real numbers, right? Anything you might want to say about real numbers and, and weight and descent and neural networks. And in fact, people have even done this. So you can say it all in, in logic programming, right? So why not just do that? Well, precisely because certain things are much more easily done in other ways, right? So what you have to ask about anything, but then about, you know, not the logic program in particular, like, what things are well represented in this way, like compactly represented, and then in such a way that learning them and doing inference with them is easy, right? And those things are different for logic programming and for things like deep learning, which is why we need a unification of both. So what is things like logic programming and ILP good for, right? It's precisely, I mean, it's many things, but the key thing is, it's precisely for learning pieces of knowledge that can then be reused and composed in arbitrary ways. This is the huge power symbolic AI that connectionism does not have, right? It's like, I learned the fact here, I learned a rule there. And tomorrow you ask me a question, and I combine that fact, actually, several rules by rule changing, right? There's a whole proof tree of rules that could have come from very different places. And I do a completely novel chain of inference that answers your question. This is spectacular, right? And this is surely court-wide intelligence is all about. And the symbolists know how to do it. The connectionists don't. But if I was a connectionist, I'd be like, you know, I know if it was a good one, and the better ones like Yoshio Benji are doing this, right? It's like, go and try to understand what those people understand so that you can then not combine it with those other ideas. Yes. Yeah. Yeah, I completely agree. So a huge part of intelligence is this symbolic, you know, extrapolation. Yeah. So how do you bring abstraction into this? Because the thing that I always get caught on is that the traditional go fi vision was to, you know, handcraft the knowledge. And actually, what we need is dynamic knowledge acquisition. And we need the ability to create abstractions on the fly rather than just what we do now, which is crystallizing existing human abstraction. How could we do that bit? Well, abstraction traditionally was and still is a central topic in symbolic AI, right? Like be precise. I mean, I think nobody questions that having levels of abstraction, someone is very important. The only question is how. So if you look at classic knowledge representation, planning, et cetera, et cetera, abstraction is all over the place. If you look at things like reinforcement learning, and I mean, even like, you know, the whole idea or hope of a convent is that it captures objects at multiple levels of abstraction, at least to some degree. In reality, it doesn't, right? But that's what people are trying to do and not quite doing, right? Well, good. Let's touch on that then. So I mean, certainly in Jan McCoon's view, I spoke with Jan the other day, he's got this autonomous path, a paper. And, you know, his system is learning abstractions, but they're abstractions which are deducible from base abstraction priors, like objectness and, you know, basic visual priors. And so there's this assumption that everything is deducible from the priors that we put into the model. But I have this kind of intuition that abstraction space is much larger than that. Yeah. I mean, so I would even say that if you arrive at your abstractions solely by deduction, you have a very impoverished notion of abstraction. In fact, most of inductive learning is forming abstractions. And form abstractions at the most basic level is something very trivial. It's like, I have an example described by a thousand attributes. If from that I induce a rule that uses only 10, I've abstracted the way the other 990, right? But if a symbolist was here, they would talk about intention versus extension, and they would say that, you know, you're selecting from this infinite set of possible attributes. You couldn't possibly represent all of the attributes in this. I mean, just to give you a concrete example, you know, you could have a, a, a, a, a, a, a, you know what I mean? You can have like this. Again, I hate to bring up infinity again, because that's always what these folks bring up. But how could you select from a set that large? Well, I don't need to because it is finite. But what I need to do is so, so, but there is actually a good example. And, you know, infinity does not bother us at all, at all there, because what it's like, if my training set, right, is a set of strings, and those strings are a, a, a, a, a, a, a, right? Going up to whatever number you want to pick, like, you know, a million or a quid drill in, you know, or a Google, right? Then R is your learning algorithm able to induce that the, the language that these rules come out of, right? The grammar is, you know, it's a series of A's, right? You and I can do that immediately. You know, most deep networks have no end of trouble doing that, even though it's that basic. So it is a very good example of what symbolic learning and reasoning can do versus connection is you don't need to go anywhere near infinity to actually have that be a very elegant example. Well, let me bring up just one other, we've touched on a lot of great things, right? There's one in this space of things that we've been talking about, there's one that I think is very important, which I believe you're also a fan of. And I very much am. And I think it's going to, you know, maybe you're going back to the question of what I'm interested in that's happening at, at new reps right now or not. So new symbolic AI is definitely a big one. Another big one. And to my mind, maybe these are the two biggest ones are most interesting is, is what I call symmetry based learning. And these days is more popular known by the, by the, by the name of like geometric deep learning and things like that. I tend to view geometric deep learning as a special case of symmetry based learning. But this idea of, I think, let me, you know, to go straight to the punchline, we know that, for example, AI and machine learning in particular, have as foundations, things like, you know, logic, probability optimization. And I think another foundation is symmetry group theory. In fact, I was having, you know, dinner with, with Max Welling just the other day, who, who, of course, have also interviewed and is, you know, like a great, you know, person in this area. And we, you know, I think we have very similar views on this. Well, Pedro, yesterday, and Taka Kohen was sitting where you were sitting. So there you go. Yeah. Again, I remember talking with Taka Kohen, some ICML many years ago, where he published one of the first papers on this. And I was like, and he seemed a little disheartened by the lack of interest that people had. And I said to him, just wait, this is going to be big and we're there now, right? And it's going to be even bigger, I think. But also, I think to become bigger and again, to jump straight to the punch line, most of the work, including me, that people have done to date has been exploiting known symmetries, like, you know, translation invariance is the quintessential example. For example, we have something called deep affine networks that generalize coordinates to, you know, rotation, you know, scaling, et cetera, et cetera. This is all well and good. But I think if this is, and if you look at New York's today, for example, most is in that vein. And there's a lot of good work to be done there. But if that's all we ever do, we will always remain a niche in AI with certain very good applications, like science applications, where we know that certain symmetries hold and whatnot. Max and Taka are doing things like that. But I don't want to just do that. I really, you know, I'm trying to make progress towards human level AI. And I think the key there is to discover symmetries from data. Yeah. And I think most of us agree with this. It's a hard problem, right? But that's what we're here for. We want to discover symmetries from data. And, you know, there's an interesting, you know, discussion of how to do that, you know, I have a number of ideas and a number of people have, then the power of discovering symmetries, right, connecting back to our early conversation is that symmetries can, individual symmetries can be very easy to discover because they're often very simple. But then, right, by the group axioms, axioms, you can compose them arbitrarily. Yeah. Which means I can, for example, by learning 100 different symmetries of a cat from 100 different examples, then I can compose them and correctly recognize as a cat something that is extremely different from any concrete example of a cat that I saw before. Could I push back on a tiny bit? So, I mean, in the geometric deep learning prototype book, I mean, they spoke about, you know, the various symmetries of groups like SO3, you know, preserves translations and angles, you know, like how primitive and how platonic are these symmetries? And aren't they just like obvious in respect of the domain that you're in? No, very good. So this is actually a key question. Symmetry group theory is one of them. It's a central area in mathematics that it's a very highly developed and it's the foundation of modern physics, like the standard model is a bunch of symmetries and so on. But the way, and there is an exhaustive listing of what all the possible symmetry groups are, discrete ones, you know, continuous ones, you know, so-called lead groups, etc., etc. So at that level, this is not naive because people already have a handle on what the space is, right? But crucially for our purpose is for AI, that's not enough because precisely because those, again, the analogy with logic is actually a very good one here. First of all, the logic is to brittle, right? And plain symmetry group theory, the way people have mostly applied so far, is also too brilliant for the same reason. So for example, right? Something like, you know, people almost always immediately come up with, so like, oh, I understand, you know, I like symmetries with the light to recognize, you know, perturbed digits, but a 6 is not a 9. So some, like, if you just take naive symmetry group theory and you say, like, well, arbitrary composability, as I was just talking about, I was like, well, now you've just said that a 6, you've lost the ability to distinguish a 6 from a 9, right? Now, what we need precisely is to combine symmetry group theory with the other things like statistics and optimization and say something like the following. The space of things that you can compose is unlimited. You can have, you know, unlimited compositions, but for example, you pay a cost for composing more symmetries. And now when you find the least cost path, and that's how you're going to match things, or, you know, your digit becomes less and less probable to be in 6, the more you've rotated it, right? So now we know how to do all of that very well. So we know symmetry group theory very well. We know how to do all these probabilistic costs, minimizing blah, blah, blah things, machine learning very well. We just need to combine it to the same way that we have previously combined these things with first order logic. So I'm glad you brought in the cost that that was really, really good. So there were trade offs everywhere. I mean, for example, if you want to make the models more fair and, you know, prioritize the low frequency attributes on the long tail, the headline accuracy goes down. Same thing with robustness. If you robustify a model, the headline accuracy goes down. Same thing with symmetry groups. If you introduce other symmetry groups, you know, that the headline accuracy goes down. So it all comes back to the bias variance trade off at the end of the day. And, you know, where is the limit here? How much can we optimize these models and what does good look like? The bias variance trade off is a very useful tool, right? But it's not the deepest reality, right? The way to think about bias variance is that, again, talking about this notion of a trade off curve, there's a trade off between bias and variance, right, which is in some sense unavoidable, right? In machine learning, if you have finite data, you're trying to learn powerful models, bias variance is a trade off. And it's a very consequential trade off in the sense that, for example, the things that work best with small amounts of data tend not to work best with large amounts of data, right? This is something that we should all, you know, grow up knowing in machine learning. But so many mistakes have been done because of that, because people study things in the easy or historically, that's all they had, right? And then they're very surprised when something that seemed not very good, like, say, deep learning, right, turns out to be better when you have a large amount of data, or they believe in, like, silly things like, you know, Occam's razor version that, you know, accurate, you know, simply is more accurate and whatnot. So a lot of mistakes have been made because of lack of understanding of this. Having said that, what you really want is to move to a better trade off curve between bias and variance, which you can, if you get at what the reality is, right? So the real game in machine, once you're evaluating your learner and figuring out, you're like, how much to prune and whatnot, or how much to regulate bias variance is very important. But before that, the most important question is like, what we're trying to do here is figure out what are the inductive biases? What are the regularities that the world really has, at least approximately, that we build our algorithms on top of that? And then if you give me a better one than I have now, I'll still have a bias variance trade off, but I'll be in a curve where for the same variance, I can have less bias and vice versa. And that's where the real action is. Oh, interesting. Well, I didn't quite understand that because bias and variance, they are mutually exclusive. And I thought at first you were saying, well, if we understand what the biases are better, the prototypical symmetries of the world we live in, then we can have more bias without having an approximation error, basically. The confusion arises because bias is a very unfortunately overloaded term. Right. This is not even getting into the psychological notion of bias like in Danny Kahneman's work, or even the sociological notion of bias like racial biases, gender biases and whatnot. So we need to distinguish. I just used my bad, the word bias into completely different senses, completely but not unrelated. That's the thing. One of them is the statistical notion of bias. There really is a trade off between the two. There's a sum of squares, blah, blah, blah. The machine learning notion of inductive bias, it's the preference that you have for certain models of our others, which is really just another way of saying your priors, whether they are assumptions or knowledge. Maybe actually instead of bias, they're like, what you really want to do is figure out what are the priors? What are the model classes? What are the preferences? The bias is a kind of preference that really line up with the world in reality or the domain and therefore let you move to a better trade off curve among statistical bias and statistical variance. Amazing. Well, Pedro, just tell us a little bit about what have you seen at NeurIPS and how's the week been for you? We've already touched on some of the interesting things that I saw, in particular some of the areas that I'm interested in. The thing about NeurIPS is this, of course, is that it's a vast conference. In the early days, I used to at least go through the proceedings and look at the title and maybe the abstract of every paper. This is now impossible. Now, these days, if all you do is try to walk through the poster sessions, you never get to the end. I haven't been to a single poster session in this NeurIPS where I actually got through all. I like to go through the poster sessions quickly once and then just to see what's there and then go back to the ones that I found really interesting. I haven't actually been able to even finish that walk through because they're so vast. You're also running to people which is part of the point and talk and whatnot, but when there's 500 posters in every session and there's 3,000 papers in the conference, it becomes very hard to find the ones that are most relevant. Of course, an easy thing to do is look at what they, I mean, something about NeurIPS this year that I honestly thought was absolutely terrible, like a really, really terrible idea is that it's a hybrid conference and their idea of a hybrid conference is that there are no talks. The talks are all virtual next week. Nips this year to a first approximation was one big poster session, which I mean, to me, this is just an incredibly bad idea. In that sense, I haven't gotten as much out of Nips by this point of the conference as I would have in most years. There's also looking at the papers that were usually selected as oral, but this time they call them oral equivalent because there are no oral papers, but they still want to have that distinction. The number of those papers these days is 160 or something, which is bigger than Nips and ICML some years ago. Usually from those papers, some of them kind of like jump out at you as being great and very relevant. I've only looked at them briefly, so don't quote me on this, if you will, but none of those have jumped out to me as like, oh, yeah, this sounds like something really brilliant and that I want to dig into, but there probably are many. I just haven't really had a chance to look at them yet. Yeah. I mean, I have a similar reaction. I mean, it feels like we're at the point of saturation and there are loads and loads of microvariations on the same idea. It's completely overwhelming, but what I find is that it's a very social experience. When I walk through the posters, I just immediately become engrossed in conversation and hours go by and I just think, oh my God, what have I just been doing for the last year? That's the real point. The posters are very good. It's like the grain of sand and the oyster. The poster is the grain of sand. The oyster is the conversation that you have with the person at the poster or with other people around there. To touch on another point that you made that I think is actually important. New Europe's and ICML and so on are bigger today than they've ever been. Actually, not strictly true because these recent lips, surprisingly, they tend to have gone down a lot. We can and should ask why, but we need to scale. There are bigger conferences, like the New Science Conference is one conference and it's 35,000 people every year and they make it work. It's good to experiment. I think New Europe's at the scale that it is today can work, but it is not working very well. One of the ways in which it's not working very well is that we need to think a lot more. I don't understand this is working. It's hard and people have day jobs or not, so this is not a criticism in that sense. We need to really work on making it easy for people to find the papers that are relevant to them. Number one, number two, and maybe even more important, there is more machine learning research today than ever, but in some sense the diversity of that research is in some ways lower than ever. Another point that you brought up and I think is very important to do with the scaling of New Europe's and the machine learning communities that we have in just raw numbers, more machine learning and AI research going on today than ever before by an order of magnitude. But in terms of diversity, there's probably less diversity in the research now than there was before, which is a tragedy. I understand why people have kind of like converged to deep learning. I'm a huge fan of deep learning. I was doing it before it was cool as they say and whatnot, but the extent to which 90% of the community, not just in machine learning but AI, is not just pursuing and not even deep learning, but a special type of deep learning, which you might call applications of backprop, is extremely undesirable. We have an infinite number of micro-improvement papers along a particular direction that is almost certainly a local optimum, and we're just digging into that local optimum with ever more papers and never more, you know, minimal publishable units when this large amount of manpower that has come into the field or is moving around, we really need to have a greater diversity of research in machine learning, within deep learning, within AI, and so like we are making very poor use of our research, you know, manpower right now, and we see that very much at NeurIPS today. Yeah, I mean, Sarah Hooker talked about the hardware lottery, you know, being stuck in a basin of attraction determined by hardware, but there's also an idea lottery. It might just be the case that NeurIPS historically has always been very connectionist anyway. I mean, maybe it hasn't, right? That's one of the ironies, but it's something as well. I wasn't aware of that. Okay. Oh, absolutely not. I mean, in fact, the joke is, right, that NeurIPS started in the 80s, it was called Neural Information Processing Systems, and by the 90s, it should have become BIPs for Patient Information Processing Systems, right? There was this study that they did at one point of predictors of acceptance and rejection among words in the title, and the biggest predictor of rejection was the world neural. Really? And this was very famous in the field, because indeed, if you could, you know, 1990 something, you were submitting papers to NIPs with the world neural in the title, you didn't know what you were doing. And then in the 2000s, right, it became BIPs, or should have become BIPs, sorry, KIPs, Kernal Information Processing Systems. And in fact, I remember having lunch with Yoshio Bingo at the ICML in Montreal in 2009, and we were talking about this, right? The fact that every day kid, and, you know, not a new paradigm, but another one of the same paradigm seems to now be on top, right? And, you know, he asked, like, so what is the next decade going to be? And I said, it's going to be DIPs, Deep Information Processing Systems. And then we both laughed, and I could tell that I believe this, but he, Yoshio Bingo, was actually skeptical of this. So, you know, the deep, little did we know, right? If somebody told us that, you know, this is going to be on the page of the, on the front page of the New York Times, in a couple of years would be like, what are you smoking, right? So the way to which this decade has been DIPs is just mind-blowing, but looking forward, right? And to this point of, you know, diversity in research approaches, I think if you extrapolate naively from the past, the next decade will be about something else. And the trillion-dollar question is what, what is that else going to be? Amazing. Okay. You watched Charma's talk, right? Yeah. What's your high-level view? I thought it was a nice talk. I thought it was a very appropriate talk for an opening talk at the conference. Actually, if New Europe's had, like, some conferences, a dinner talk, right? Which is supposed to be interesting, but not as, you know, deep or as technical as other. This would have been the perfect dinner talk for New Europe's, because the topic is very current, right? Our machine's sentient. And, you know, who better to talk about it than Dave Chalmers, right? The world's expert on, on, on, on consciousness, right? And by and large, I thought the talk was excellent. In fact, you know, when journalists ask me questions, you know, consciousness is like one of their top three, right? Along with Terminator and, you know, Unfairness or something like that, right? And I will point them to this talk because it kind of like lays out, you know, the, you know, the ground. And, you know, it's good for people to at least have those things in mind. At the end of the day, so I think, of course, the notion that Lambda was sentient is, you know, ridiculous, as, as most of us do. You could ask a slightly more fine-going question was if, if, if, if, if consciousness is on a continuum, right? Which I think Dave believes in. And if you believe in like this, you know, IT theory and phi and whatnot, you know, like, phi is never zero, right? So there's always some consciousness, right? Pensychism and whatnot. I'm not saying I believe in that. We could, we could go into the, but like, if you believe in that, then you can ask, well, on that scale, you know, where is Lambda? Where are these large language models? And, and, and surely higher than previous AI systems, right? But in my view, still very, very, very far. And I think what you want to keep in mind is that consciousness does not, does not increase continuously. Precisely, there's these transitions where you go, you know, more is different is the, is the famous, you know, phrase about emergence, right? Consciousness is very much an emerging, you know, phenomenon. And I think what happens is that there are points at which your consciousness will leap. Maybe a thermostat does have consciousness, like, you know, or, you know, or purpose or whatever, right? Like, like people in, like people like McCarthy, for example, had had had that as an example. But the amount of consciousness is minuscule. And, and that, and the way I will put that is that these large language models still have not passed that first threshold. Interesting. So, so in a similar way to some of the discussion about large language models, there are kind of scaling breaks in the levels of consciousness. I mean, Chalmers made the comment, though, that rather than it being a pure continuum, he said that a bottle was not conscious, but then there was a kind of. No, yes. So very key point. Scaling is part of it, but not only. It's not just that. So your cortex to first approximation is a monkey brain scaled up, right? There was a module there that evolution discovered, and it really paid to keep making more and more of it. And we can easily speculate why. But the point is, so let me contrast two things, right? Which is true for consciousness, but also for just AI in general. A lot of people are scaling believers and like open AI is the poster child of this in a quite conscious ways. Like, we're just going to scale the heck out of things. And then a lot of people, like, you know, Gary Marcus being a good example, they just completely poo poo that they say, like, oh, no, this is a joke. Right. And I think the truth is that scaling is good, right? Again, you know, part of what we are, our intelligence is scaling. But the question is, what are you scaling? And the things that we're scaling today, it doesn't matter how much we scale them, we never get to human level intelligence or consciousness. So I think we need some fundamentally different algorithms, if you want to think at the level of algorithms, or fundamentally different architect architectures, if you want to think about it in a way, and then scaling those up at some point will give us consciousness. If you live that it's possible for a computer to be conscious, but we're not there yet, either in terms of the scaling, although actually scaling is actually the easier part of this way, we're actually at the point where a computer can have the same amount of computing power that your brain does, which was not the case before. But the bigger deeper problem, and the more fundamental one is like, we need the architecture to scale. Right. And this is where I sympathize, you know, with people like Jeff Hinton, who's just, you know, playing with, you know, ideas using Mathematica and very small examples, which in some ways, sounds very underpowered, but I think it's people like that, they are going to come up with the things that we then scale. As in fact, it was David Roemmerhardt doing that kind of work that invented backprop. Right. If he hadn't invented backprop, this whole industry would not exist. So what I think is that the real backprop, the real master algorithm is not there yet, and we need to discover that first. And then we, and then when we scale that up, which will not be trivial, but will be much easier by comparison, then we'll have, you know, human level, intelligence, consciousness, et cetera. Interesting. Okay. And so Charmes is a structuralist computationalist. So, you know, he thinks information, not biology. And he's also a functionalist, right? So, you know, which is very similar to behavior. And, you know, Hillary Putnam made the move that you can kind of like represent a computation in any open physical system. And he kind of like used that on, you know, if you follow that line of thought, it almost trivializes computationalism because, you know, it leads to panpsychism very, very quickly. So, first of all, I mean, what's your take on this idea that information could give rise to intelligence and consciousness? So I agree, like most scientists, and I think in particular most computer scientists, that to a first approximation, the substrate does not matter. And in particular, you're not going to convince me that something is not conscious just because it's not biological. There is no reason to think that only biological things can have consciousness. Now, the deeper problem, and you know, indeed the hard problem, is that so as Dave Chalmers defined it, so there's a basic fork here, which you've alluded to, which is, if consciousness is subjective experience, then all these questions about consciousness are ultimately unresolvable, because only I have my subjective experience. I know that I'm conscious, no one can persuade me of the contrary. I don't even know if you are conscious, let alone some machine. Right? So if consciousness is an intrinsic property of something that cannot be evaluated from the outside, then we're doomed. We're never going to answer this question. And maybe that is the case. Right? So I'm not saying that's false, and you need to always keep that in mind. But now, if we're going to make any kind of progress, right, we need to look at what are, to generalize a well known term, the external correlates of consciousness. Right? One of those which has been well studied by people like Christoph Koch and so on, and I think that's a very good direction, is the neural correlates of consciousness. Right? What goes on in your brain that correlates with consciousness? And we've made a lot of progress with that. You can also talk about what are sort of like the informational computational correlates of consciousness. Are there computational structures that support consciousness and the ones that don't? I think that is also a useful thing to do. Let's develop. It actually interests this panpsychism because it's not like everything is consciousness just because it can compute. Some computations after this emergence and these, you know, phase transitions may give rise to consciousness. Whereas others, it doesn't matter how much of them you have, they will never be conscious. So I think this is also a very useful way to make progress on this question and one to which AI versus, you know, a neuroscience or psychology is very well suited to. Interesting. So on the functionalism point, and I think Chalmers has been very, very consistent. He uses this kind of calculi to reason about intelligence as well. So a system is intelligent if it can perform reasoning, if it can perform planning, if it has sensing and so on. So we have this collection of functions. And then he's kind of like moved this over to the domain of consciousness. So similarly, if a system performs these functions and is used in a positive and a negative way. So some functions would indicate an absence of consciousness and some functions would, you know, lead to the presence of consciousness. And it's kind of like leading towards a, you know, touring test for consciousness. I mean, do you kind of support that? That's a very interesting question. In fact, you know, I was having dinner with Dave after his talk and I actually brought this up because it wasn't clear from his talk. And I said, look, this is the answer that I usually give to journalists when they ask me, you know, will machines ever be conscious and whatnot? And asked me a few, and asked me if he agreed with it and actually expected him to disagree. But I think again, don't want to put words in his mouth, but that he agreed, right? And the answer is the following, is that human beings, right? As we've discussed, have an amazing tendency to anthropoformize things. It's reasoning by analogy. And what happens, I used to say, this is what's going to happen at this point is this is what is already happening is that as soon as a machine behaves externally, even vaguely like it's consciousness, we immediately start treating it as if it's consciousness. So if you look for 10, 20, 50 years from now, we will just treat AI's as if they're consciousness and people won't even ask that question. They will assume AI's are conscious in the same way that we assume that each other, that we're conscious, right? But then, and so like from that pragmatic external point of view, maybe the question is answered, right? But you could be a philosopher or like sort of like a very, you know, rigorous, you know, technical person and so like, no, no, no, no, I really want to know if things, they may look, you know, conscious from the outside, but are they really, right? But that question, as far as I can tell, unfortunately, at the end of the day is probably unanswerable. Now, there's a middle ground between these two things that maybe is where we'll wind up. And to me, sounds like probably the best thing that we're going to be able to do, which is that like, our understanding of the neural informational, et cetera, correlates of consciousness evolves to a point where we have the feeling that we do understand consciousness. It's not just the late person calls this consciousness even though haha, it's not like lambda is not conscious, you know, poor bozo, et cetera, et cetera. It's like, you know, there are many analogies to that in the history of science. There used to be a lot of things that were like magical, right? And we were like, oh, we're never going to stand like life was magical, right? Life did not obey the laws of physics. It's just something else, right? This sounds laughable right now, but it wasn't laughable at all then, right? And now, it's not like we've understood everything about life very far from it. When you say like, there's DNA and their cells and then this is how it all arises, right? And I think we're at the point in consciousness where it's to like, oh, consciousness is some so beyond us, right? I think we will get, you know, there will be a structure of DNA moment in the history of the study of consciousness. And I think, yeah, I think things like Phi and this, you know, IT3 and whatnot, they're very brave attempts to make progress in this direction. I think, you know, like Julia Tononi in a way is, you know, very deluded in thinking that he has nailed what consciousness is, right? I think, you know, Phi maybe is an upper bound on consciousness, but with steps like this, hopefully at some point, and very much with the help of AI, right? AI is really useful for this, because it's a brain that might be consciousness that we have a lot of control of. And you can do experiments that you can't, you know, with people, right? So I think we will make at least some progress in that direction for sure. Maybe to the point where we feel that, yes, we do understand what consciousness is, we're not asking ourselves that question anymore. And then we can point to things and say, this is consciousness, this is that kind of consciousness, that amount of consciousness, and so on. Yeah, that's really interesting. I agree, we're making a lot of progress in getting a handle on this. And although the biggest game in town is still the computationalism game. And as you say, historically, the only alternative was mysterious. And my friend, Professor Mark Bishop, that he said that that's one of the reasons why he's become interested in the forays in cognitive science, because for the first time, it's given him a kind of robust alternative to computationalism. But just coming back quickly, you know, as Charlie's reference, Thomas Nagel, you know, which is that it is something it is like to be a bat. What do you think about that? So I'm not sure your question is, but let me check. Well, what do you mean? Do you agree that there is something it is like to be a bat? Oh, absolutely. Right. So there is more and more than that, right? There is something that it's like to be a bat. And it's very different from being a human, right? And we grossly underestimate, right? Again, we do this thing that again, it's a heuristic, it works very well as like, we project ourselves into the bat, because what else could we do, right? But then what you see is a bat seen through the mind of a human, right? And in fact, there's this famous, I would say, even more famous, you know, you know, notion from, from Wittgenstein, right? That if the lion could talk, I would not understand anything that the lion was saying. Because his world is so different from mine. Now, I actually think, I think this is a very important position to, as a reference point, right? Certainly a defensible one. And, you know, Wittgenstein was a good defender of it. But I actually think that this is going too far. I think, ultimately, I mean, never be able to completely know what it's like to be a lion. But we can make a lot, don't underestimate us either, right? We can make a lot of inwards into understanding what it's like to be a lion, much more than we understand today. Same thing for a bat. And, you know, you could also ask that for a fruit fly, right? In a way, a fruit fly is more different from us than a lion, but it's easy to understand, right? Because at some level, that thing is so simple that we can understand what's going on with it, because it's not that deep. Yeah, that's a beautiful quote, actually. So, closing this off, do you think that large language models are slightly conscious or will be in the near future? I think language, I think large language models are not slightly conscious by the reasonable, you know, everyday definition of the world slightly, meaning that their consciousness, so I think that either their consciousness is just zero, right? If somebody asked me, like, you know, how much, you know, consciousness does, you know, lambda half, tell me in one word, and the answer would be zero, right? But another answer which is hard to distinguish from the first one is epsilon, right? Maybe it has a very tiny amount of consciousness, but it's so tiny that it doesn't even qualify as slightly. Again, this gets back to what its architecture is. It actually gets too lot of things, but for purposes of this discussion, right, lambda and these large language models are not very different from a big lookup table. Any big lookup table is not conscious. Now, I mean, there are a lot of interesting distinctions that you can make it well. What if what I have is an efficient approximation to a lookup table? Isn't that what your brain is, right? And I would say yes, and then people say, well, but then why is your brain conscious but not the lookup table, right? And precisely the interesting question is that the consciousness comes about from the fact that you have to concentrate all of this information, you know, in real time, into something, you know, very compact and that leads to action continuously, right? So to put this in another way, maybe God is unconscious because he doesn't need to be, right? If you're omnipotent and omniscient, you don't need to be conscious. You are effectively just a lookup table. Exactly. And I loved your response earlier about the grain of sand and the oyster. I thought that was a beautiful way of looking at it. And having recently studied so, I mean, personally, I think it's a lot to do with intentionality and agency, but I remember you responded to that. Just final quick question. What's your definition of intelligence? So let me start with the technical definition, which is unfortunately not widely known enough and not appreciated enough. But I think it's a really important one to have, right? Intelligence is solving NP-complete problems using heuristics. This is the real technical definition of AI, right? And there's a lot packed into that, right? The fact that it's NP-complete problems and the fact that it's using heuristics. If your problem is solvable with a lookup table with polynomial algorithms, you don't need intelligence and there's no intelligence there. It's when you start solving hard problems using heuristics that you're getting into the realm of intelligence. Moreover, NP-complete is not the same as exponential, right? The crucial thing about an NP-complete problem that connects very directly to our entire discussion of utility and whatnot is that the solution is easy to check. This is the key. If you're working on problems whose solution is impossible to check effectively, I can't even tell if you're intelligent or not. The whole thing about intelligence in humans and machines is that how you solve the problem requires a lot of intelligence, a lot of computing power and whatnot, but then I can easily check the solution. Now, hang on a minute, could that say a step away from behavior then if you're saying that, you know, like you have the percepts, the state and the action and you're saying the state is also important? No, so to answer that head on, intelligence is not behavior, right? Intelligence to give a slightly more general definition and then there's several and they all have their merits. Intelligence is the ability to solve hard problems. Then more concretely, it's NP-complete problems and using heuristics, but like, for example, if you create an AI system that cures cancer, it doesn't behave in the sense that a human and a robot behave, but, you know, it's damn intelligence, it's more intelligent than we are, right? It would be childish to deny intelligence to that system, no matter how it solves cancer. If it finds a ridiculously simple way to solve cancer, then it's even more brilliant, right? In fact, the simpler your outcome, the more intelligent you are, right? It takes intelligence to produce something simple. Wow. Concretely, in many circumstances, in particular evolution, right? Intelligence manifests itself as behavior. There's a sequential decision making problem, there's an agent in the world that said a certain stuff, being a stochastic parrot. And I think also from, you know, theoretical reasons, by analyzing what a transformer can represent and how it can learn, my best guess, which could be wrong again, I don't think anybody has the answer to this and it's interesting question is that those transformers, right, not LLM scholars, that means more of like a task rather than the, you know, than the architecture. Transformers have a certain limited ability to do compositionality, very limited to compare to full logic programming, etc., but exponentially better than something like an ordinary multilayer perceptron. And if you just, I mean, even a multilayer perceptron or any learning algorithm is more than a stochastic parrot, because it's general, the whole point of machine learning is to generalize beyond the data. If you generalize correctly beyond the data, you're not just a parrot anymore. And, you know, I think it's not an accident that that term stochastic parrot came from Emily Bender, my linguistics colleague at UW, who does not understand machine learning. She's a classic linguist of the Chomsky and Variety, who does, you know, does not fundamentally understand what I think, you know, she might disagree, what machine learning is all about. And she would probably look at any learning algorithm and say that it's a stochastic parrot, missing the fact that the whole point of machine learning and the thing that we focus on from, you know, beginning to end is generalizing. And as soon as you're generalizing correctly, even if you have no compositionality, you're already doing something that has a little bit of intelligence, and that's beyond what a parrot would do. Yeah, I mean, to be fair, it's not a binary. And at the time, I thought they were stochastic parents as well. I've updated my view. And you were talking as well about creativity. There's a kind of blurred hyperplane of creativity. And we discussed, you know, where that hyperplane sits. But, you know, what's really interested me, I've interviewed quite a few people that are working on working on in context learning in these language models. And it seems like these language models are almost almost like a new type of compiler, you know, you're writing a program inside the language prompt. And they seem to work extremely well outside of the training range if you're doing like basic multiplication tasks. I think it is useful to look at them as a new type of compiler. In fact, I've been saying for a long time that, you know, like, there's this continuum from programming an assembly code to high level languages to doing AI, right? The point of AI is to continue along that path to making the language that computers speak ever closer to ours, so that we can just program them by talking to them or writing things at them, right? Having said that, I think that, you know, what goes on in the innards of a transformer, right, is actually still very primitive, for lack of a better word, right? There's a lot of, so something I tweeted that got a lot of follow up from people like Yan and Gary and who the pro because they were all bringing in their own angles. So this was like, I said, and I think this is an interesting question. It's like the interesting question about transformers is what needs to be added to them to get real intelligence. So we should not deny what they have, like the attention mechanism in particular, right? And the embeddings and the context. So like, there are two very important things in transformers that are beyond what was in neural networks 10 years ago and are key. One of them is attention, right? Attention is a real advance. And the other one is context specific embeddings, right? Each of these ideas is important in its own right and combining them together is very powerful, right? Again, because the context sensitive embeddings get that the similarity part of intelligence, the attention combined with the context sensitivity of the embeddings gets at the compositionality part. So they do have, so there are a couple of steps forward on the road to human level intelligence, but there are many more. And rather than either saying like, oh, they're just parrots, they don't do anything, we're saying like, we've almost solved the eye, what we really should, we should try to understand better, you know, how the, you know, the attention and the context is dependent embeddings work, which we don't. But we also need to focus like, now, what are we still missing? Because we definitely are. And that's really where most of our focus should be. Yeah, I completely agree. And also just in defense of Bender, I mean, I think she's a brilliant linguist. And I personally think having that diversity of views from different people is useful. No, I mean, so I very much think that having a diversity of views is very important. And I think something that I'm always saying to my deep learning friends who can't stand, you know, who hate the guts of Gary Marcus is we really, really need informed critics. Yeah. And very typically, your informed critics are not people in the field. We are experts, but then we also suffer from the distortion of being experts. It's people in adjacent areas. And people like linguists and psychologists are very much those people, they're in adjacent areas, enough to have a good critique of AI. So for example, something that Jan is always throwing at Gary Marcus, that kind of doesn't sit well with me, says like, well, you should try building a real system sometime, and you can criticize this until we do. If we take the attitude that only engineers can criticize engineers, we're doomed. Having said that, there is a very big distinction between the knowledgeable informed critics like Gary Marcus, and the not so knowledgeable, not so well informed ones, which unfortunately, Emily is an example. I mean, she's my colleague at UW. And I've talked with her about some of these things. And her criticism of machine learning, unfortunately, like a lot of people, comes from a place of actually not fundamental understanding it very well. But people do say that Gary isn't an expert in deep learning and that he's, you know, attention seeking. What would you say to that? No, he's not an expert in deep learning. And so like, I agree with some of his criticisms, I disagree with others. Probably on balance, I disagree more with him than I agree. But first of all, there is a value to having critics like that, number one. But then number two, the reason his criticism, I mean, it would be better if he was also an expert in deep learning and made the same criticisms. And then the problem is that often his criticisms are wrong because he has a mental model of deep learning that is already outdated, or is oversimplified, right? But that to some degree is unavoidable. But the thing that makes his criticism valuable is that he's doing it at a level where on a good day, on a bad day, his criticisms miss the mark. But on a good day, which is the ones that matter, his criticism is actually useful because it's at a level where you don't need to understand the details. It's like, you claim to be producing intelligence. I as a psychologist know a lot about intelligence. That's what I study for a living, right? He knows more about aspects of intelligence than I do. Yeah. And from that point of view, what you're doing is lacking. And that I mean, like, he's written the whole books about, you know, again, because this goes back to when he was a PhD student and, you know, and symbolic learning and whatnot, there are very, you know, the deep learning folks have repeatedly underestimated how well he understands some of these problems. Because as a psychologist in particular interested in language learning, he's actually thought very long and hard about them. Oh, I know. So I've read his book and we've had him on the show three times. Which book? The algebraic mind. Yeah. So that's the most relevant one here. Yeah. As a psychologist, you know, he spent a lot of time studying how children learn rules. Right. And he talks very elegantly about a compositionality. And we've spoken about this. It's irrefutable. And I agree with him and we've supported him. I guess some of the things he argues are based on ethics, politics and virtue. And some of the things like compositionality, I think are irrefutable. I mean, I think irrefutable is a very strong word. I wouldn't say that they're irrefutable. I would say that they have, they have very strong backing, which the connectionists have not been able to effectively refute. But some of the criticisms that they have, you know, meaning people like Pinker and Prince and whatnot, famously of connectionists in the 80s, some of them are still valid, which is very salient. But some of them not really. And again, to go back to the daddy of this whole school of thought, who's Chomsky, right? His, you know, he made his name basically panning things like, you know, Markov models of language in Graham models, which he could say large language models are just a very glorified version of, right? But and at the time, you could, that criticism was very apt and, you know, and timely and it was useful, right? But, but, but, and famously, it's like, it's like, you can't learn a context free grammar, but context free grammar is what you do. Well, actually, now we know formally that you can learn a context free grammar. And, and, you know, because you only have to learn it probabilistically, which is what we do. And what our systems do. So his criticism was just, you know, mathematically off the mark. But also, when you look at systems that do speech language, et cetera, et cetera, it is that statistical approach that he made his name panning that has prevailed. And for reasons that we understand very well, and large language models are just the latest greatest expression of that. So at that level, a whole Chomsky and Pinker, Gary Marcus view of things, not only is it not irrefutable, it has been refuted. Okay. Let's just quickly come back to your definition of intelligence. So solving NP hard problems, I assume you would zoom out a little bit and, you know, it's more of a meta learning algorithm. So the ability to sell to sell different problems. Yes. So it's, if very good point, if all you have is the ability to solve one NP complete problem, that does not qualify as general intelligence, right? There's like, these days, this is a common definition to make this different difference between, you know, narrow intelligence and general intelligence and AGI and whatnot, right? And if you only solve one NP complete problem very well, you have narrow intelligence is the way I would put it, but you do not have general intelligence. General intelligence is precisely the ability to solve a limitless variety of problems, all that have this characteristic of they're hard to solve, but the solution is easy to check. Right? I mean, if you have the ability to solve problems, whose solution isn't easy to check, then maybe you're intelligent, but I can't decide whether intelligent or not. Interesting. Okay. And actually, Gary did, he put a paper about 20 years ago talking about how neural networks can't extrapolate. I think it was when he encoded numbers with a binary encoding or whatever. And we've been on a bit of a journey on this. So we had Randall Bellistrier, I've interviewed him yesterday, he's got this paper called the spline theory of neural networks. It basically says that a neural network decomposes an input space into these input activated polyhedra. And when we first read that, we felt that it kind of indicated Francois Chollet's assertion that neural networks are locality sensitive hashing tables, and they only generalize within, you know, these tiny polyhedra. And Randall's now updated this view to say in contrast to decision trees, these hyperplanes, they actually inform a lot of information in the extrapolative regime outside of the training range. So I always thought it was the inductive priors that gave the extrapolative performance on neural networks by photocopying the information everywhere. And so like, you know, this is a great example of where, you know, Gary might update his views because even basic MLPs are far more extrapolative than anyone realized. This is a very interesting question. But the way I would put it is that in that regard, in some sense, both of the sides are right. And the reason they're both right is that we're in very high dimensional spaces. Yeah. And we're in a very high dimensional space. The follow thing can happen, which is, you know, you have a data point, and you generalize to a vast region around that data point. And it's unfair to characterize these things as saying they just interpolate. In some sense, they really do extrapolate. But at the same time, that vast region that they generalize correctly to is an infinitesimal fraction of the much, much vaster reason that they have not generalized to but you and I can. So you got to keep that distinction in mind. And then in particular, right, I like to say that deep learning is nearest neighbor in curved space. And both parts of that are very important, right? So, you know, Jan Lacoon was famous, you know, during the glory days of kernel machines for saying that kernel machines are just glorified template matches. Right. And of course, they didn't earn him any friends, but he was right. They really are just glorified template matches. Kernel machine is really a souped up, more mathematically elegant and blah, blah, blah version of nearest neighbor. Right. And the nearest neighbor is just a template matcher. The beauty in the power of nearest neighbor, though, is that there is a neighborhood within which often it generalizes very well. Right. Now, I think what Jan was missing, and I probably still is, is that coordinates and deep learning, they are still just a glory. They are also glorified nearest neighbor, except more glorified. And the way in which they're more glorified, which is very important is that they are doing nearest neighbor in curved space. They are still just doing, you know, generalization by similarity, which you could argue is all that machine learning does is generalizing by similarity. Another notion of similarity can vary. Right. But the important thing that they've done is that nearest neighbor just uses some distance measured in the original space, whereas the neural networks are warping the space to make the problem easier for the nearest neighbor, you know, essentially dot product based similarity computation that they're actually doing. Oh, sure. But you're very much arguing, this is the way Francois Chouelet puts it, that, you know, you have all of these transformations and you kind of distort the space, you know, to represent the data manifold. And, you know, you want it to, you stop SGD at the right time so that you approximate the data manifold and you can do this kind of latent space, you know, interpolation on the geodesic of that manifold. But, you know, Randall's idea is completely away from that idea of, you know, these models learning this curved space. And so if you do slice the space up with these hyperplanes, rather than it being a locality prior, which is what you're talking about, these hyperplanes give you globally relevant information to things that are, you know, miles away from the training data. Yeah, so, but these two perspectives are more similar than you might think, because I can take a distorted version of space and decompose it into polyhedron, right? And one or the other might approximate what's really going on better. I mean, these neural networks do form curved spaces, except they're in practice, they're not curved because they find it, but ignoring that, right? When, let me put it this way, an eloquent example of this is if you look back at the original space, right? Again, treat this thing as a black box. Where does it generalize to? Does it generalize only to things, neural networks as we have them today? Does it generalize correctly only to things that are locally near the data point, or you can generalize well to things that are far, right? And the thing is that with nearest neighbor, you buy, you know, almost intrinsically, you only generalize period at all to things that are local. The beauty of deep learning and of the space swapping that's going on is, again, going back to this notion of the path kernel is that you're actually doing a nearest neighbor computation, not just in a space that's swapped, but you're doing it in the space of gradients, which actually means that you can generalize correctly to things that are very far from your examples, except they look similar in gradient space. A very simple example of this is a sine wave, right? If I try to learn a sine wave using nearest neighbor, I need an infinite number of examples, right? Because, you know, like what I've learned over here helps me not at all with the next turn of the sine wave, like that continuous extrapolation, right? At some point, there's this disaster where if the last piece of the sine was going up, I just keep going up and getting more and more wrong, right? And in fact, this kind of thing does happen in neural networks, but they also have the part to say like, and this again, this also happens, which is I'm going to transform this space more into a more intelligent one, which is the space of the slopes, right? And now if I've seen one cycle of the sine wave with some density of examples, by similarity in that transformed space, I generalize correctly and trivially to every other turn of the sine wave. So there's a very big fundamental difference between the two. Interesting. And you think with an MLP, it would be possible to have that kind of extrapolative generalization on a sine wave? Well, so people have studied this in multiple ways. And the problem, so the question is, it depends on what are the basis functions that it's using. Yes. So something that we didn't allude to at all in this conversation, but analyze all of this is like, what is your choice of basis functions, right? And the thing is, an MLP with the traditional, say, sigmoid or allude basis functions will not learn this, no matter, for obvious reasons, right? And again, you can represent it, right? The representative theorem is there, like the sine wave is just one sigmoid and then another one, you know, with a minus sign and then another one, but the data doesn't let you learn it. If as a basis function, you have sine waves, which is nothing unimaginable, that's what a Fourier transform is then, then you can learn it so easily, it's not even funny. So it depends dramatically on the basis function. And the question really becomes, what are the basis functions and the architect that let me generalize correctly to a lot of things, including this, such that, for example, and this is a very simple test, is like, I can nail a sine wave with a small number of examples without it being one of my basis functions. Yeah, exactly. And then this all comes back to, you know, we're talking about inductive prize and the bias variance trade off and even symmetries, actually. I mean, the Taco Cohen once said that, you know, if you encode all of the symmetries into the label function, then you would only need one labeled example. So it's always a trade off between how much induction are you doing? Well, interesting, you should say that I understand why he says that and it's, and it's not technically wrong. But I would say that practically what you need is such a set of symmetries per region of the space, per cluster, right? But, you know, in another way, I would actually make an even stronger statement, which again, is very perfectly mathematical, sounds same when you say, an object is just the sum of its symmetries or a function. If you tell me all the symmetries, every last one of an object, you've defined the object. So if I can learn the symmetries at that level, I don't need anything else. Of course, as we already discussed, that's not the whole answer. Likewise, with any function, if you tell me all the properties of the function, there are there, you know, to be more precise, all the symmetries of a function at some point, you've told me the whole function. And vice versa, from the function, I can, you know, I can read out all the symmetries that it has. In principle, doing that in practice can be, you know, a very difficult and subtle thing to do. That's a beautiful thing to say. You give me the symmetries and I'll give you the object. Yeah, exactly. Amazing. Professor Pedro Domingos, thank you so much for joining us today. It's been an honor. Thanks for having me. Amazing.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.72, "text": " Hi, I'm Peter Domingos, I'm a professor of computer science at the University of Washington", "tokens": [50364, 2421, 11, 286, 478, 6508, 413, 10539, 329, 11, 286, 478, 257, 8304, 295, 3820, 3497, 412, 264, 3535, 295, 6149, 50650], "temperature": 0.0, "avg_logprob": -0.25435100737072175, "compression_ratio": 1.6526717557251909, "no_speech_prob": 0.06596062332391739}, {"id": 1, "seek": 0, "start": 5.72, "end": 11.24, "text": " and machine learning researcher, probably best known as the author of the master algorithm,", "tokens": [50650, 293, 3479, 2539, 21751, 11, 1391, 1151, 2570, 382, 264, 3793, 295, 264, 4505, 9284, 11, 50926], "temperature": 0.0, "avg_logprob": -0.25435100737072175, "compression_ratio": 1.6526717557251909, "no_speech_prob": 0.06596062332391739}, {"id": 2, "seek": 0, "start": 11.24, "end": 14.48, "text": " popular science introduction to machine learning.", "tokens": [50926, 3743, 3497, 9339, 281, 3479, 2539, 13, 51088], "temperature": 0.0, "avg_logprob": -0.25435100737072175, "compression_ratio": 1.6526717557251909, "no_speech_prob": 0.06596062332391739}, {"id": 3, "seek": 0, "start": 14.48, "end": 20.68, "text": " I'm here at NeurIPS 2022 of the vast amounts of stuff that's happening here.", "tokens": [51088, 286, 478, 510, 412, 1734, 374, 40, 6273, 20229, 295, 264, 8369, 11663, 295, 1507, 300, 311, 2737, 510, 13, 51398], "temperature": 0.0, "avg_logprob": -0.25435100737072175, "compression_ratio": 1.6526717557251909, "no_speech_prob": 0.06596062332391739}, {"id": 4, "seek": 0, "start": 20.68, "end": 26.02, "text": " The two that I found most interesting and are closest to my own research are Neurosymbolic", "tokens": [51398, 440, 732, 300, 286, 1352, 881, 1880, 293, 366, 13699, 281, 452, 1065, 2132, 366, 1734, 8977, 88, 5612, 299, 51665], "temperature": 0.0, "avg_logprob": -0.25435100737072175, "compression_ratio": 1.6526717557251909, "no_speech_prob": 0.06596062332391739}, {"id": 5, "seek": 0, "start": 26.02, "end": 28.52, "text": " AI and symmetry-based learning.", "tokens": [51665, 7318, 293, 25440, 12, 6032, 2539, 13, 51790], "temperature": 0.0, "avg_logprob": -0.25435100737072175, "compression_ratio": 1.6526717557251909, "no_speech_prob": 0.06596062332391739}, {"id": 6, "seek": 2852, "start": 28.52, "end": 33.44, "text": " Okay, Professor Pedro Domingos, it's an absolute honor to have you back on the show.", "tokens": [50364, 1033, 11, 8419, 26662, 413, 10539, 329, 11, 309, 311, 364, 8236, 5968, 281, 362, 291, 646, 322, 264, 855, 13, 50610], "temperature": 0.0, "avg_logprob": -0.23060681981947814, "compression_ratio": 1.588679245283019, "no_speech_prob": 0.002737410133704543}, {"id": 7, "seek": 2852, "start": 33.44, "end": 38.84, "text": " Pedro is a professor at the University of Washington and give us a quick introduction", "tokens": [50610, 26662, 307, 257, 8304, 412, 264, 3535, 295, 6149, 293, 976, 505, 257, 1702, 9339, 50880], "temperature": 0.0, "avg_logprob": -0.23060681981947814, "compression_ratio": 1.588679245283019, "no_speech_prob": 0.002737410133704543}, {"id": 8, "seek": 2852, "start": 38.84, "end": 44.879999999999995, "text": " to yourself, to your experience here in Europe so far and what's top of mind for you?", "tokens": [50880, 281, 1803, 11, 281, 428, 1752, 510, 294, 3315, 370, 1400, 293, 437, 311, 1192, 295, 1575, 337, 291, 30, 51182], "temperature": 0.0, "avg_logprob": -0.23060681981947814, "compression_ratio": 1.588679245283019, "no_speech_prob": 0.002737410133704543}, {"id": 9, "seek": 2852, "start": 44.879999999999995, "end": 48.68, "text": " I'm a machine learning researcher, I've worked in most of the major areas.", "tokens": [51182, 286, 478, 257, 3479, 2539, 21751, 11, 286, 600, 2732, 294, 881, 295, 264, 2563, 3179, 13, 51372], "temperature": 0.0, "avg_logprob": -0.23060681981947814, "compression_ratio": 1.588679245283019, "no_speech_prob": 0.002737410133704543}, {"id": 10, "seek": 2852, "start": 48.68, "end": 54.16, "text": " I've also written a popular science book on machine learning called the Master Algorithm.", "tokens": [51372, 286, 600, 611, 3720, 257, 3743, 3497, 1446, 322, 3479, 2539, 1219, 264, 6140, 35014, 6819, 76, 13, 51646], "temperature": 0.0, "avg_logprob": -0.23060681981947814, "compression_ratio": 1.588679245283019, "no_speech_prob": 0.002737410133704543}, {"id": 11, "seek": 5416, "start": 54.16, "end": 59.199999999999996, "text": " I'm having a lot of fun here at NeurIPS, listening to various talks like David Chalmers", "tokens": [50364, 286, 478, 1419, 257, 688, 295, 1019, 510, 412, 1734, 374, 40, 6273, 11, 4764, 281, 3683, 6686, 411, 4389, 761, 304, 18552, 50616], "temperature": 0.0, "avg_logprob": -0.2318844067848335, "compression_ratio": 1.579136690647482, "no_speech_prob": 0.04371683672070503}, {"id": 12, "seek": 5416, "start": 59.199999999999996, "end": 65.32, "text": " on Consciousness and Geoff Hinton on Sleep and looking forward to the rest of it.", "tokens": [50616, 322, 6923, 4139, 1287, 293, 26119, 389, 12442, 322, 19383, 293, 1237, 2128, 281, 264, 1472, 295, 309, 13, 50922], "temperature": 0.0, "avg_logprob": -0.2318844067848335, "compression_ratio": 1.579136690647482, "no_speech_prob": 0.04371683672070503}, {"id": 13, "seek": 5416, "start": 65.32, "end": 70.47999999999999, "text": " Awesome, I'd love to get your thoughts on Chalmers in a bit actually, but the first", "tokens": [50922, 10391, 11, 286, 1116, 959, 281, 483, 428, 4598, 322, 761, 304, 18552, 294, 257, 857, 767, 11, 457, 264, 700, 51180], "temperature": 0.0, "avg_logprob": -0.2318844067848335, "compression_ratio": 1.579136690647482, "no_speech_prob": 0.04371683672070503}, {"id": 14, "seek": 5416, "start": 70.47999999999999, "end": 76.0, "text": " thing I wanted to talk about just because it's top of mind is this whole galactica situation.", "tokens": [51180, 551, 286, 1415, 281, 751, 466, 445, 570, 309, 311, 1192, 295, 1575, 307, 341, 1379, 7660, 578, 2262, 2590, 13, 51456], "temperature": 0.0, "avg_logprob": -0.2318844067848335, "compression_ratio": 1.579136690647482, "no_speech_prob": 0.04371683672070503}, {"id": 15, "seek": 5416, "start": 76.0, "end": 80.36, "text": " So first of all, I was speaking with Ian the other day and I think it's a little bit unfair", "tokens": [51456, 407, 700, 295, 439, 11, 286, 390, 4124, 365, 19595, 264, 661, 786, 293, 286, 519, 309, 311, 257, 707, 857, 17019, 51674], "temperature": 0.0, "avg_logprob": -0.2318844067848335, "compression_ratio": 1.579136690647482, "no_speech_prob": 0.04371683672070503}, {"id": 16, "seek": 8036, "start": 80.36, "end": 83.72, "text": " that Meta really bear the brunt of this.", "tokens": [50364, 300, 6377, 64, 534, 6155, 264, 738, 2760, 295, 341, 13, 50532], "temperature": 0.0, "avg_logprob": -0.1982383898326329, "compression_ratio": 1.5912408759124088, "no_speech_prob": 0.06073067709803581}, {"id": 17, "seek": 8036, "start": 83.72, "end": 89.44, "text": " OpenAI have just released this new chat GPT bot which suffers from similar failure modes", "tokens": [50532, 7238, 48698, 362, 445, 4736, 341, 777, 5081, 26039, 51, 10592, 597, 33776, 490, 2531, 7763, 14068, 50818], "temperature": 0.0, "avg_logprob": -0.1982383898326329, "compression_ratio": 1.5912408759124088, "no_speech_prob": 0.06073067709803581}, {"id": 18, "seek": 8036, "start": 89.44, "end": 94.24, "text": " and it just kind of feels that they're not getting anywhere near as much stick as Meta is.", "tokens": [50818, 293, 309, 445, 733, 295, 3417, 300, 436, 434, 406, 1242, 4992, 2651, 382, 709, 2897, 382, 6377, 64, 307, 13, 51058], "temperature": 0.0, "avg_logprob": -0.1982383898326329, "compression_ratio": 1.5912408759124088, "no_speech_prob": 0.06073067709803581}, {"id": 19, "seek": 8036, "start": 94.24, "end": 102.03999999999999, "text": " Well I think, I agree with you, I think the brouhaha about galactica is way overblown.", "tokens": [51058, 1042, 286, 519, 11, 286, 3986, 365, 291, 11, 286, 519, 264, 738, 263, 71, 4408, 466, 7660, 578, 2262, 307, 636, 670, 5199, 648, 13, 51448], "temperature": 0.0, "avg_logprob": -0.1982383898326329, "compression_ratio": 1.5912408759124088, "no_speech_prob": 0.06073067709803581}, {"id": 20, "seek": 8036, "start": 102.03999999999999, "end": 104.48, "text": " That system is really largely harmless.", "tokens": [51448, 663, 1185, 307, 534, 11611, 40160, 13, 51570], "temperature": 0.0, "avg_logprob": -0.1982383898326329, "compression_ratio": 1.5912408759124088, "no_speech_prob": 0.06073067709803581}, {"id": 21, "seek": 8036, "start": 104.48, "end": 108.4, "text": " It's just another large language model that's designed for actually something that to me", "tokens": [51570, 467, 311, 445, 1071, 2416, 2856, 2316, 300, 311, 4761, 337, 767, 746, 300, 281, 385, 51766], "temperature": 0.0, "avg_logprob": -0.1982383898326329, "compression_ratio": 1.5912408759124088, "no_speech_prob": 0.06073067709803581}, {"id": 22, "seek": 10840, "start": 108.4, "end": 110.96000000000001, "text": " as a scientist is very interesting.", "tokens": [50364, 382, 257, 12662, 307, 588, 1880, 13, 50492], "temperature": 0.0, "avg_logprob": -0.1390760468273628, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.05652734637260437}, {"id": 23, "seek": 10840, "start": 110.96000000000001, "end": 115.56, "text": " I would love to have a system like that to help me out with certain things and I think", "tokens": [50492, 286, 576, 959, 281, 362, 257, 1185, 411, 300, 281, 854, 385, 484, 365, 1629, 721, 293, 286, 519, 50722], "temperature": 0.0, "avg_logprob": -0.1390760468273628, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.05652734637260437}, {"id": 24, "seek": 10840, "start": 115.56, "end": 120.92, "text": " it's a step in the right direction and I think the brouhaha however is an instance of people", "tokens": [50722, 309, 311, 257, 1823, 294, 264, 558, 3513, 293, 286, 519, 264, 738, 263, 71, 4408, 4461, 307, 364, 5197, 295, 561, 50990], "temperature": 0.0, "avg_logprob": -0.1390760468273628, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.05652734637260437}, {"id": 25, "seek": 10840, "start": 120.92, "end": 126.28, "text": " jumping the gun on a lot of these AI things in a way that to me is very excessive.", "tokens": [50990, 11233, 264, 3874, 322, 257, 688, 295, 613, 7318, 721, 294, 257, 636, 300, 281, 385, 307, 588, 22704, 13, 51258], "temperature": 0.0, "avg_logprob": -0.1390760468273628, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.05652734637260437}, {"id": 26, "seek": 10840, "start": 126.28, "end": 131.4, "text": " Having said that in a way they set themselves up for it in a way that they need and have,", "tokens": [51258, 10222, 848, 300, 294, 257, 636, 436, 992, 2969, 493, 337, 309, 294, 257, 636, 300, 436, 643, 293, 362, 11, 51514], "temperature": 0.0, "avg_logprob": -0.1390760468273628, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.05652734637260437}, {"id": 27, "seek": 10840, "start": 131.4, "end": 137.56, "text": " they kind of over claimed what it did and the problem with these LLMs is that they generate", "tokens": [51514, 436, 733, 295, 670, 12941, 437, 309, 630, 293, 264, 1154, 365, 613, 441, 43, 26386, 307, 300, 436, 8460, 51822], "temperature": 0.0, "avg_logprob": -0.1390760468273628, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.05652734637260437}, {"id": 28, "seek": 13756, "start": 137.56, "end": 142.56, "text": " a lot of stuff that looks good but can be completely wrong and in a way there's no worse", "tokens": [50364, 257, 688, 295, 1507, 300, 1542, 665, 457, 393, 312, 2584, 2085, 293, 294, 257, 636, 456, 311, 572, 5324, 50614], "temperature": 0.0, "avg_logprob": -0.2035750758891203, "compression_ratio": 1.6340425531914893, "no_speech_prob": 0.11649277806282043}, {"id": 29, "seek": 13756, "start": 142.56, "end": 145.6, "text": " place to do that than in writing scientific articles.", "tokens": [50614, 1081, 281, 360, 300, 813, 294, 3579, 8134, 11290, 13, 50766], "temperature": 0.0, "avg_logprob": -0.2035750758891203, "compression_ratio": 1.6340425531914893, "no_speech_prob": 0.11649277806282043}, {"id": 30, "seek": 13756, "start": 145.6, "end": 150.32, "text": " So when they came out with it, they should have been more careful about how they frame", "tokens": [50766, 407, 562, 436, 1361, 484, 365, 309, 11, 436, 820, 362, 668, 544, 5026, 466, 577, 436, 3920, 51002], "temperature": 0.0, "avg_logprob": -0.2035750758891203, "compression_ratio": 1.6340425531914893, "no_speech_prob": 0.11649277806282043}, {"id": 31, "seek": 13756, "start": 150.32, "end": 151.32, "text": " it.", "tokens": [51002, 309, 13, 51052], "temperature": 0.0, "avg_logprob": -0.2035750758891203, "compression_ratio": 1.6340425531914893, "no_speech_prob": 0.11649277806282043}, {"id": 32, "seek": 13756, "start": 151.32, "end": 154.52, "text": " I think they took concerns sort of like this competition and one upping each other on who", "tokens": [51052, 286, 519, 436, 1890, 7389, 1333, 295, 411, 341, 6211, 293, 472, 344, 3759, 1184, 661, 322, 567, 51212], "temperature": 0.0, "avg_logprob": -0.2035750758891203, "compression_ratio": 1.6340425531914893, "no_speech_prob": 0.11649277806282043}, {"id": 33, "seek": 13756, "start": 154.52, "end": 159.8, "text": " comes up with the frilliest demo and that kind of backfired.", "tokens": [51212, 1487, 493, 365, 264, 431, 373, 6495, 10723, 293, 300, 733, 295, 646, 69, 1824, 13, 51476], "temperature": 0.0, "avg_logprob": -0.2035750758891203, "compression_ratio": 1.6340425531914893, "no_speech_prob": 0.11649277806282043}, {"id": 34, "seek": 15980, "start": 159.8, "end": 165.20000000000002, "text": " So they shouldn't have had to withdraw it.", "tokens": [50364, 407, 436, 4659, 380, 362, 632, 281, 14999, 309, 13, 50634], "temperature": 0.0, "avg_logprob": -0.1930103302001953, "compression_ratio": 1.6313868613138687, "no_speech_prob": 0.5670954585075378}, {"id": 35, "seek": 15980, "start": 165.20000000000002, "end": 170.84, "text": " I think that's all pathetic and hopefully they've learned the lesson that next time", "tokens": [50634, 286, 519, 300, 311, 439, 35506, 293, 4696, 436, 600, 3264, 264, 6898, 300, 958, 565, 50916], "temperature": 0.0, "avg_logprob": -0.1930103302001953, "compression_ratio": 1.6313868613138687, "no_speech_prob": 0.5670954585075378}, {"id": 36, "seek": 15980, "start": 170.84, "end": 172.52, "text": " they will do it slightly differently.", "tokens": [50916, 436, 486, 360, 309, 4748, 7614, 13, 51000], "temperature": 0.0, "avg_logprob": -0.1930103302001953, "compression_ratio": 1.6313868613138687, "no_speech_prob": 0.5670954585075378}, {"id": 37, "seek": 15980, "start": 172.52, "end": 173.52, "text": " Yes.", "tokens": [51000, 1079, 13, 51050], "temperature": 0.0, "avg_logprob": -0.1930103302001953, "compression_ratio": 1.6313868613138687, "no_speech_prob": 0.5670954585075378}, {"id": 38, "seek": 15980, "start": 173.52, "end": 174.52, "text": " Okay.", "tokens": [51050, 1033, 13, 51100], "temperature": 0.0, "avg_logprob": -0.1930103302001953, "compression_ratio": 1.6313868613138687, "no_speech_prob": 0.5670954585075378}, {"id": 39, "seek": 15980, "start": 174.52, "end": 175.52, "text": " Okay.", "tokens": [51100, 1033, 13, 51150], "temperature": 0.0, "avg_logprob": -0.1930103302001953, "compression_ratio": 1.6313868613138687, "no_speech_prob": 0.5670954585075378}, {"id": 40, "seek": 15980, "start": 175.52, "end": 179.88000000000002, "text": " Well, so Gary Marcus has been very loud about this on Twitter so he's really pushing", "tokens": [51150, 1042, 11, 370, 13788, 26574, 575, 668, 588, 6588, 466, 341, 322, 5794, 370, 415, 311, 534, 7380, 51368], "temperature": 0.0, "avg_logprob": -0.1930103302001953, "compression_ratio": 1.6313868613138687, "no_speech_prob": 0.5670954585075378}, {"id": 41, "seek": 15980, "start": 179.88000000000002, "end": 185.16000000000003, "text": " the point about misinformation and the thing is as well I don't want to characterize the", "tokens": [51368, 264, 935, 466, 34238, 293, 264, 551, 307, 382, 731, 286, 500, 380, 528, 281, 38463, 264, 51632], "temperature": 0.0, "avg_logprob": -0.1930103302001953, "compression_ratio": 1.6313868613138687, "no_speech_prob": 0.5670954585075378}, {"id": 42, "seek": 15980, "start": 185.16000000000003, "end": 189.16000000000003, "text": " ethics folks as having monolithic views because they don't have monolithic views and I also", "tokens": [51632, 19769, 4024, 382, 1419, 1108, 42878, 6809, 570, 436, 500, 380, 362, 1108, 42878, 6809, 293, 286, 611, 51832], "temperature": 0.0, "avg_logprob": -0.1930103302001953, "compression_ratio": 1.6313868613138687, "no_speech_prob": 0.5670954585075378}, {"id": 43, "seek": 18916, "start": 189.2, "end": 192.88, "text": " think that a lot of the ethics guidelines for large language models are very reasonable.", "tokens": [50366, 519, 300, 257, 688, 295, 264, 19769, 12470, 337, 2416, 2856, 5245, 366, 588, 10585, 13, 50550], "temperature": 0.0, "avg_logprob": -0.18399555969238282, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.10802929103374481}, {"id": 44, "seek": 18916, "start": 192.88, "end": 196.84, "text": " Like I interviewed the CEO of Coheir the other week, Aidan Gomez.", "tokens": [50550, 1743, 286, 19770, 264, 9282, 295, 3066, 675, 347, 264, 661, 1243, 11, 316, 31675, 43537, 13, 50748], "temperature": 0.0, "avg_logprob": -0.18399555969238282, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.10802929103374481}, {"id": 45, "seek": 18916, "start": 196.84, "end": 200.8, "text": " I went through their terms and conditions and policies all very reasonable.", "tokens": [50748, 286, 1437, 807, 641, 2115, 293, 4487, 293, 7657, 439, 588, 10585, 13, 50946], "temperature": 0.0, "avg_logprob": -0.18399555969238282, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.10802929103374481}, {"id": 46, "seek": 18916, "start": 200.8, "end": 203.35999999999999, "text": " The only sticking point for me is the misinformation one.", "tokens": [50946, 440, 787, 13465, 935, 337, 385, 307, 264, 34238, 472, 13, 51074], "temperature": 0.0, "avg_logprob": -0.18399555969238282, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.10802929103374481}, {"id": 47, "seek": 18916, "start": 203.35999999999999, "end": 211.72, "text": " I think the kind of the moral valence of it is in its use and especially with misrepresentation.", "tokens": [51074, 286, 519, 264, 733, 295, 264, 9723, 1323, 655, 295, 309, 307, 294, 1080, 764, 293, 2318, 365, 3346, 19919, 11662, 399, 13, 51492], "temperature": 0.0, "avg_logprob": -0.18399555969238282, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.10802929103374481}, {"id": 48, "seek": 18916, "start": 211.72, "end": 215.35999999999999, "text": " I don't like this paternalism telling me what's good for me.", "tokens": [51492, 286, 500, 380, 411, 341, 42302, 4660, 1434, 3585, 385, 437, 311, 665, 337, 385, 13, 51674], "temperature": 0.0, "avg_logprob": -0.18399555969238282, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.10802929103374481}, {"id": 49, "seek": 18916, "start": 215.35999999999999, "end": 218.16, "text": " I've just lost out on using a really cool tool basically.", "tokens": [51674, 286, 600, 445, 2731, 484, 322, 1228, 257, 534, 1627, 2290, 1936, 13, 51814], "temperature": 0.0, "avg_logprob": -0.18399555969238282, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.10802929103374481}, {"id": 50, "seek": 21816, "start": 218.84, "end": 219.88, "text": " I completely agree with you.", "tokens": [50398, 286, 2584, 3986, 365, 291, 13, 50450], "temperature": 0.0, "avg_logprob": -0.1464036649411863, "compression_ratio": 1.735408560311284, "no_speech_prob": 0.017143672332167625}, {"id": 51, "seek": 21816, "start": 219.88, "end": 221.12, "text": " I would take it even further.", "tokens": [50450, 286, 576, 747, 309, 754, 3052, 13, 50512], "temperature": 0.0, "avg_logprob": -0.1464036649411863, "compression_ratio": 1.735408560311284, "no_speech_prob": 0.017143672332167625}, {"id": 52, "seek": 21816, "start": 221.12, "end": 226.4, "text": " I do not want other people deciding for me what is misinformation and what is therefore", "tokens": [50512, 286, 360, 406, 528, 661, 561, 17990, 337, 385, 437, 307, 34238, 293, 437, 307, 4412, 50776], "temperature": 0.0, "avg_logprob": -0.1464036649411863, "compression_ratio": 1.735408560311284, "no_speech_prob": 0.017143672332167625}, {"id": 53, "seek": 21816, "start": 226.4, "end": 229.2, "text": " allowed to be said because it's misinformation or not.", "tokens": [50776, 4350, 281, 312, 848, 570, 309, 311, 34238, 420, 406, 13, 50916], "temperature": 0.0, "avg_logprob": -0.1464036649411863, "compression_ratio": 1.735408560311284, "no_speech_prob": 0.017143672332167625}, {"id": 54, "seek": 21816, "start": 229.2, "end": 230.2, "text": " For a couple of reasons.", "tokens": [50916, 1171, 257, 1916, 295, 4112, 13, 50966], "temperature": 0.0, "avg_logprob": -0.1464036649411863, "compression_ratio": 1.735408560311284, "no_speech_prob": 0.017143672332167625}, {"id": 55, "seek": 21816, "start": 230.2, "end": 234.04, "text": " One is that these people who claim to be big critics of misinformation, a lot of them", "tokens": [50966, 1485, 307, 300, 613, 561, 567, 3932, 281, 312, 955, 22503, 295, 34238, 11, 257, 688, 295, 552, 51158], "temperature": 0.0, "avg_logprob": -0.1464036649411863, "compression_ratio": 1.735408560311284, "no_speech_prob": 0.017143672332167625}, {"id": 56, "seek": 21816, "start": 234.04, "end": 236.68, "text": " are misinformers themselves.", "tokens": [51158, 366, 32333, 837, 433, 2969, 13, 51290], "temperature": 0.0, "avg_logprob": -0.1464036649411863, "compression_ratio": 1.735408560311284, "no_speech_prob": 0.017143672332167625}, {"id": 57, "seek": 21816, "start": 236.68, "end": 242.12, "text": " And the bottom line is that you always have your ideology that informs what you think", "tokens": [51290, 400, 264, 2767, 1622, 307, 300, 291, 1009, 362, 428, 23101, 300, 45320, 437, 291, 519, 51562], "temperature": 0.0, "avg_logprob": -0.1464036649411863, "compression_ratio": 1.735408560311284, "no_speech_prob": 0.017143672332167625}, {"id": 58, "seek": 21816, "start": 242.12, "end": 244.0, "text": " is true and false.", "tokens": [51562, 307, 2074, 293, 7908, 13, 51656], "temperature": 0.0, "avg_logprob": -0.1464036649411863, "compression_ratio": 1.735408560311284, "no_speech_prob": 0.017143672332167625}, {"id": 59, "seek": 24400, "start": 244.0, "end": 250.52, "text": " And I don't want anybody, every one of us in a democracy should be deciding for themselves", "tokens": [50364, 400, 286, 500, 380, 528, 4472, 11, 633, 472, 295, 505, 294, 257, 10528, 820, 312, 17990, 337, 2969, 50690], "temperature": 0.0, "avg_logprob": -0.15240976451772503, "compression_ratio": 1.7613636363636365, "no_speech_prob": 0.010805029422044754}, {"id": 60, "seek": 24400, "start": 250.52, "end": 253.8, "text": " what is true and what is false and what is valid and what isn't.", "tokens": [50690, 437, 307, 2074, 293, 437, 307, 7908, 293, 437, 307, 7363, 293, 437, 1943, 380, 13, 50854], "temperature": 0.0, "avg_logprob": -0.15240976451772503, "compression_ratio": 1.7613636363636365, "no_speech_prob": 0.010805029422044754}, {"id": 61, "seek": 24400, "start": 253.8, "end": 260.32, "text": " And I have no fear of attempts to misinform me as long as I have a multiplicity of sources.", "tokens": [50854, 400, 286, 362, 572, 4240, 295, 15257, 281, 32333, 837, 385, 382, 938, 382, 286, 362, 257, 17596, 507, 295, 7139, 13, 51180], "temperature": 0.0, "avg_logprob": -0.15240976451772503, "compression_ratio": 1.7613636363636365, "no_speech_prob": 0.010805029422044754}, {"id": 62, "seek": 24400, "start": 260.32, "end": 266.36, "text": " The biggest misinformation danger is when you have only one monolithic source of truth,", "tokens": [51180, 440, 3880, 34238, 4330, 307, 562, 291, 362, 787, 472, 1108, 42878, 4009, 295, 3494, 11, 51482], "temperature": 0.0, "avg_logprob": -0.15240976451772503, "compression_ratio": 1.7613636363636365, "no_speech_prob": 0.010805029422044754}, {"id": 63, "seek": 24400, "start": 266.36, "end": 270.76, "text": " whatever it is, which is unfortunately what a lot of these anti-misinformation people,", "tokens": [51482, 2035, 309, 307, 11, 597, 307, 7015, 437, 257, 688, 295, 613, 6061, 12, 45634, 20941, 561, 11, 51702], "temperature": 0.0, "avg_logprob": -0.15240976451772503, "compression_ratio": 1.7613636363636365, "no_speech_prob": 0.010805029422044754}, {"id": 64, "seek": 24400, "start": 270.76, "end": 273.72, "text": " I think consciously or unconsciously want.", "tokens": [51702, 286, 519, 32538, 420, 18900, 356, 528, 13, 51850], "temperature": 0.0, "avg_logprob": -0.15240976451772503, "compression_ratio": 1.7613636363636365, "no_speech_prob": 0.010805029422044754}, {"id": 65, "seek": 27372, "start": 273.72, "end": 276.8, "text": " Give me 10 things, 9 of which are misinformation.", "tokens": [50364, 5303, 385, 1266, 721, 11, 1722, 295, 597, 366, 34238, 13, 50518], "temperature": 0.0, "avg_logprob": -0.18706429389215284, "compression_ratio": 1.7554744525547445, "no_speech_prob": 0.15869180858135223}, {"id": 66, "seek": 27372, "start": 276.8, "end": 279.96000000000004, "text": " I can do the job of figuring out which one I think is valid.", "tokens": [50518, 286, 393, 360, 264, 1691, 295, 15213, 484, 597, 472, 286, 519, 307, 7363, 13, 50676], "temperature": 0.0, "avg_logprob": -0.18706429389215284, "compression_ratio": 1.7554744525547445, "no_speech_prob": 0.15869180858135223}, {"id": 67, "seek": 27372, "start": 279.96000000000004, "end": 283.88000000000005, "text": " Give me only one of those things and chances are 9 in 10 that it is misinformation and", "tokens": [50676, 5303, 385, 787, 472, 295, 729, 721, 293, 10486, 366, 1722, 294, 1266, 300, 309, 307, 34238, 293, 50872], "temperature": 0.0, "avg_logprob": -0.18706429389215284, "compression_ratio": 1.7554744525547445, "no_speech_prob": 0.15869180858135223}, {"id": 68, "seek": 27372, "start": 283.88000000000005, "end": 285.64000000000004, "text": " then I have no chance to overcome it.", "tokens": [50872, 550, 286, 362, 572, 2931, 281, 10473, 309, 13, 50960], "temperature": 0.0, "avg_logprob": -0.18706429389215284, "compression_ratio": 1.7554744525547445, "no_speech_prob": 0.15869180858135223}, {"id": 69, "seek": 27372, "start": 285.64000000000004, "end": 289.88000000000005, "text": " So this whole attack on things because they're misinformation.", "tokens": [50960, 407, 341, 1379, 2690, 322, 721, 570, 436, 434, 34238, 13, 51172], "temperature": 0.0, "avg_logprob": -0.18706429389215284, "compression_ratio": 1.7554744525547445, "no_speech_prob": 0.15869180858135223}, {"id": 70, "seek": 27372, "start": 289.88000000000005, "end": 295.12, "text": " And I mean, I understand the impulse that like, why have all this falsehood flying around?", "tokens": [51172, 400, 286, 914, 11, 286, 1223, 264, 26857, 300, 411, 11, 983, 362, 439, 341, 7908, 3809, 7137, 926, 30, 51434], "temperature": 0.0, "avg_logprob": -0.18706429389215284, "compression_ratio": 1.7554744525547445, "no_speech_prob": 0.15869180858135223}, {"id": 71, "seek": 27372, "start": 295.12, "end": 299.08000000000004, "text": " But the way to overcome that falsehood is not by censoring it.", "tokens": [51434, 583, 264, 636, 281, 10473, 300, 7908, 3809, 307, 406, 538, 19019, 3662, 309, 13, 51632], "temperature": 0.0, "avg_logprob": -0.18706429389215284, "compression_ratio": 1.7554744525547445, "no_speech_prob": 0.15869180858135223}, {"id": 72, "seek": 27372, "start": 299.08000000000004, "end": 300.88000000000005, "text": " You should know this, right?", "tokens": [51632, 509, 820, 458, 341, 11, 558, 30, 51722], "temperature": 0.0, "avg_logprob": -0.18706429389215284, "compression_ratio": 1.7554744525547445, "no_speech_prob": 0.15869180858135223}, {"id": 73, "seek": 30088, "start": 300.88, "end": 305.28, "text": " You should be having to refight all of this over again in the context of social media", "tokens": [50364, 509, 820, 312, 1419, 281, 1895, 397, 439, 295, 341, 670, 797, 294, 264, 4319, 295, 2093, 3021, 50584], "temperature": 0.0, "avg_logprob": -0.16001993922863977, "compression_ratio": 1.6094276094276094, "no_speech_prob": 0.0072042616084218025}, {"id": 74, "seek": 30088, "start": 305.28, "end": 309.2, "text": " and large language models and so on.", "tokens": [50584, 293, 2416, 2856, 5245, 293, 370, 322, 13, 50780], "temperature": 0.0, "avg_logprob": -0.16001993922863977, "compression_ratio": 1.6094276094276094, "no_speech_prob": 0.0072042616084218025}, {"id": 75, "seek": 30088, "start": 309.2, "end": 313.0, "text": " So you said something really interesting, which is that this notion of a pure truth", "tokens": [50780, 407, 291, 848, 746, 534, 1880, 11, 597, 307, 300, 341, 10710, 295, 257, 6075, 3494, 50970], "temperature": 0.0, "avg_logprob": -0.16001993922863977, "compression_ratio": 1.6094276094276094, "no_speech_prob": 0.0072042616084218025}, {"id": 76, "seek": 30088, "start": 313.0, "end": 319.56, "text": " or a monolithic truth, and there's this concept of epistemic subjectivity, right?", "tokens": [50970, 420, 257, 1108, 42878, 3494, 11, 293, 456, 311, 341, 3410, 295, 2388, 468, 3438, 3983, 4253, 11, 558, 30, 51298], "temperature": 0.0, "avg_logprob": -0.16001993922863977, "compression_ratio": 1.6094276094276094, "no_speech_prob": 0.0072042616084218025}, {"id": 77, "seek": 30088, "start": 319.56, "end": 325.24, "text": " Or things observe a relative, even complex phenomena like intelligence.", "tokens": [51298, 1610, 721, 11441, 257, 4972, 11, 754, 3997, 22004, 411, 7599, 13, 51582], "temperature": 0.0, "avg_logprob": -0.16001993922863977, "compression_ratio": 1.6094276094276094, "no_speech_prob": 0.0072042616084218025}, {"id": 78, "seek": 30088, "start": 325.24, "end": 326.48, "text": " No one understands what it is.", "tokens": [51582, 883, 472, 15146, 437, 309, 307, 13, 51644], "temperature": 0.0, "avg_logprob": -0.16001993922863977, "compression_ratio": 1.6094276094276094, "no_speech_prob": 0.0072042616084218025}, {"id": 79, "seek": 30088, "start": 326.48, "end": 328.44, "text": " You can't reduce it to one particular thing.", "tokens": [51644, 509, 393, 380, 5407, 309, 281, 472, 1729, 551, 13, 51742], "temperature": 0.0, "avg_logprob": -0.16001993922863977, "compression_ratio": 1.6094276094276094, "no_speech_prob": 0.0072042616084218025}, {"id": 80, "seek": 30088, "start": 328.44, "end": 329.96, "text": " People have different views on it, right?", "tokens": [51742, 3432, 362, 819, 6809, 322, 309, 11, 558, 30, 51818], "temperature": 0.0, "avg_logprob": -0.16001993922863977, "compression_ratio": 1.6094276094276094, "no_speech_prob": 0.0072042616084218025}, {"id": 81, "seek": 32996, "start": 329.96, "end": 335.44, "text": " So this notion that there is a pure monolithic truth of the world, I think is horrifying.", "tokens": [50364, 407, 341, 10710, 300, 456, 307, 257, 6075, 1108, 42878, 3494, 295, 264, 1002, 11, 286, 519, 307, 40227, 13, 50638], "temperature": 0.0, "avg_logprob": -0.20665378064180898, "compression_ratio": 1.728448275862069, "no_speech_prob": 0.00777629017829895}, {"id": 82, "seek": 32996, "start": 335.44, "end": 339.88, "text": " Well, I would put it slightly differently.", "tokens": [50638, 1042, 11, 286, 576, 829, 309, 4748, 7614, 13, 50860], "temperature": 0.0, "avg_logprob": -0.20665378064180898, "compression_ratio": 1.728448275862069, "no_speech_prob": 0.00777629017829895}, {"id": 83, "seek": 32996, "start": 339.88, "end": 344.0, "text": " So first of all, there's a question, is there one reality or not, right?", "tokens": [50860, 407, 700, 295, 439, 11, 456, 311, 257, 1168, 11, 307, 456, 472, 4103, 420, 406, 11, 558, 30, 51066], "temperature": 0.0, "avg_logprob": -0.20665378064180898, "compression_ratio": 1.728448275862069, "no_speech_prob": 0.00777629017829895}, {"id": 84, "seek": 32996, "start": 344.0, "end": 347.08, "text": " Is there truth or is there my truth and your truth, right?", "tokens": [51066, 1119, 456, 3494, 420, 307, 456, 452, 3494, 293, 428, 3494, 11, 558, 30, 51220], "temperature": 0.0, "avg_logprob": -0.20665378064180898, "compression_ratio": 1.728448275862069, "no_speech_prob": 0.00777629017829895}, {"id": 85, "seek": 32996, "start": 347.08, "end": 351.52, "text": " And actually, I understand the impulse to talk about my truth and your truth, but I", "tokens": [51220, 400, 767, 11, 286, 1223, 264, 26857, 281, 751, 466, 452, 3494, 293, 428, 3494, 11, 457, 286, 51442], "temperature": 0.0, "avg_logprob": -0.20665378064180898, "compression_ratio": 1.728448275862069, "no_speech_prob": 0.00777629017829895}, {"id": 86, "seek": 32996, "start": 351.52, "end": 354.08, "text": " think as a...", "tokens": [51442, 519, 382, 257, 485, 51570], "temperature": 0.0, "avg_logprob": -0.20665378064180898, "compression_ratio": 1.728448275862069, "no_speech_prob": 0.00777629017829895}, {"id": 87, "seek": 32996, "start": 354.08, "end": 355.2, "text": " So what is really true?", "tokens": [51570, 407, 437, 307, 534, 2074, 30, 51626], "temperature": 0.0, "avg_logprob": -0.20665378064180898, "compression_ratio": 1.728448275862069, "no_speech_prob": 0.00777629017829895}, {"id": 88, "seek": 32996, "start": 355.2, "end": 356.35999999999996, "text": " We don't know.", "tokens": [51626, 492, 500, 380, 458, 13, 51684], "temperature": 0.0, "avg_logprob": -0.20665378064180898, "compression_ratio": 1.728448275862069, "no_speech_prob": 0.00777629017829895}, {"id": 89, "seek": 35636, "start": 356.36, "end": 357.76, "text": " But as a...", "tokens": [50364, 583, 382, 257, 485, 50434], "temperature": 0.0, "avg_logprob": -0.12855409275401722, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.05619291216135025}, {"id": 90, "seek": 35636, "start": 357.76, "end": 363.88, "text": " I think the most useful, including socially useful working hypothesis is that there is", "tokens": [50434, 286, 519, 264, 881, 4420, 11, 3009, 21397, 4420, 1364, 17291, 307, 300, 456, 307, 50740], "temperature": 0.0, "avg_logprob": -0.12855409275401722, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.05619291216135025}, {"id": 91, "seek": 35636, "start": 363.88, "end": 368.68, "text": " a single reality and the single truth, but it's extremely complex.", "tokens": [50740, 257, 2167, 4103, 293, 264, 2167, 3494, 11, 457, 309, 311, 4664, 3997, 13, 50980], "temperature": 0.0, "avg_logprob": -0.12855409275401722, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.05619291216135025}, {"id": 92, "seek": 35636, "start": 368.68, "end": 371.44, "text": " So no single one of us can get at it.", "tokens": [50980, 407, 572, 2167, 472, 295, 505, 393, 483, 412, 309, 13, 51118], "temperature": 0.0, "avg_logprob": -0.12855409275401722, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.05619291216135025}, {"id": 93, "seek": 35636, "start": 371.44, "end": 375.28000000000003, "text": " So what we need is many different people coming at it from different angles.", "tokens": [51118, 407, 437, 321, 643, 307, 867, 819, 561, 1348, 412, 309, 490, 819, 14708, 13, 51310], "temperature": 0.0, "avg_logprob": -0.12855409275401722, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.05619291216135025}, {"id": 94, "seek": 35636, "start": 375.28000000000003, "end": 378.96000000000004, "text": " But with the premise that we need to try to make these things consistent.", "tokens": [51310, 583, 365, 264, 22045, 300, 321, 643, 281, 853, 281, 652, 613, 721, 8398, 13, 51494], "temperature": 0.0, "avg_logprob": -0.12855409275401722, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.05619291216135025}, {"id": 95, "seek": 35636, "start": 378.96000000000004, "end": 383.64, "text": " So just saying, oh, we have different truths and there's no reality, that is actually very", "tokens": [51494, 407, 445, 1566, 11, 1954, 11, 321, 362, 819, 30079, 293, 456, 311, 572, 4103, 11, 300, 307, 767, 588, 51728], "temperature": 0.0, "avg_logprob": -0.12855409275401722, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.05619291216135025}, {"id": 96, "seek": 38364, "start": 383.64, "end": 388.08, "text": " counterproductive because it gives everybody a pass to just believe whatever wacky thing", "tokens": [50364, 5682, 14314, 20221, 570, 309, 2709, 2201, 257, 1320, 281, 445, 1697, 2035, 42138, 88, 551, 50586], "temperature": 0.0, "avg_logprob": -0.13602793601251417, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.06448677182197571}, {"id": 97, "seek": 38364, "start": 388.08, "end": 389.08, "text": " they want.", "tokens": [50586, 436, 528, 13, 50636], "temperature": 0.0, "avg_logprob": -0.13602793601251417, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.06448677182197571}, {"id": 98, "seek": 38364, "start": 389.08, "end": 392.84, "text": " And then the consequences of that when you have to make the real decisions are very bad.", "tokens": [50636, 400, 550, 264, 10098, 295, 300, 562, 291, 362, 281, 652, 264, 957, 5327, 366, 588, 1578, 13, 50824], "temperature": 0.0, "avg_logprob": -0.13602793601251417, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.06448677182197571}, {"id": 99, "seek": 38364, "start": 392.84, "end": 396.64, "text": " At the same time, I agree with you.", "tokens": [50824, 1711, 264, 912, 565, 11, 286, 3986, 365, 291, 13, 51014], "temperature": 0.0, "avg_logprob": -0.13602793601251417, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.06448677182197571}, {"id": 100, "seek": 38364, "start": 396.64, "end": 401.08, "text": " If I think that I have access to that truth and everybody just needs to, you know, count", "tokens": [51014, 759, 286, 519, 300, 286, 362, 2105, 281, 300, 3494, 293, 2201, 445, 2203, 281, 11, 291, 458, 11, 1207, 51236], "temperature": 0.0, "avg_logprob": -0.13602793601251417, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.06448677182197571}, {"id": 101, "seek": 38364, "start": 401.08, "end": 402.68, "text": " out to it, that is very dangerous.", "tokens": [51236, 484, 281, 309, 11, 300, 307, 588, 5795, 13, 51316], "temperature": 0.0, "avg_logprob": -0.13602793601251417, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.06448677182197571}, {"id": 102, "seek": 38364, "start": 402.68, "end": 406.96, "text": " So I think we need to entertain these two ideas that there is a truth, but it's very", "tokens": [51316, 407, 286, 519, 321, 643, 281, 7655, 613, 732, 3487, 300, 456, 307, 257, 3494, 11, 457, 309, 311, 588, 51530], "temperature": 0.0, "avg_logprob": -0.13602793601251417, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.06448677182197571}, {"id": 103, "seek": 38364, "start": 406.96, "end": 409.68, "text": " complex and no one has a monopoly on it.", "tokens": [51530, 3997, 293, 572, 472, 575, 257, 37061, 322, 309, 13, 51666], "temperature": 0.0, "avg_logprob": -0.13602793601251417, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.06448677182197571}, {"id": 104, "seek": 40968, "start": 409.68, "end": 414.36, "text": " And the key is, you know, like objective truth is what different observers can agree on.", "tokens": [50364, 400, 264, 2141, 307, 11, 291, 458, 11, 411, 10024, 3494, 307, 437, 819, 48090, 393, 3986, 322, 13, 50598], "temperature": 0.0, "avg_logprob": -0.19583977433971891, "compression_ratio": 1.7077464788732395, "no_speech_prob": 0.16775862872600555}, {"id": 105, "seek": 40968, "start": 414.36, "end": 416.6, "text": " And now we can figure out what it is that we agree on.", "tokens": [50598, 400, 586, 321, 393, 2573, 484, 437, 309, 307, 300, 321, 3986, 322, 13, 50710], "temperature": 0.0, "avg_logprob": -0.19583977433971891, "compression_ratio": 1.7077464788732395, "no_speech_prob": 0.16775862872600555}, {"id": 106, "seek": 40968, "start": 416.6, "end": 419.28000000000003, "text": " And that way we make progress in understanding reality.", "tokens": [50710, 400, 300, 636, 321, 652, 4205, 294, 3701, 4103, 13, 50844], "temperature": 0.0, "avg_logprob": -0.19583977433971891, "compression_ratio": 1.7077464788732395, "no_speech_prob": 0.16775862872600555}, {"id": 107, "seek": 40968, "start": 419.28000000000003, "end": 423.8, "text": " And we also tend to make more of the right decisions because we're closer to the truth.", "tokens": [50844, 400, 321, 611, 3928, 281, 652, 544, 295, 264, 558, 5327, 570, 321, 434, 4966, 281, 264, 3494, 13, 51070], "temperature": 0.0, "avg_logprob": -0.19583977433971891, "compression_ratio": 1.7077464788732395, "no_speech_prob": 0.16775862872600555}, {"id": 108, "seek": 40968, "start": 423.8, "end": 424.8, "text": " Okay.", "tokens": [51070, 1033, 13, 51120], "temperature": 0.0, "avg_logprob": -0.19583977433971891, "compression_ratio": 1.7077464788732395, "no_speech_prob": 0.16775862872600555}, {"id": 109, "seek": 40968, "start": 424.8, "end": 429.6, "text": " But do you see it as, I mean, I think the reality thing is interesting, but do you just see", "tokens": [51120, 583, 360, 291, 536, 309, 382, 11, 286, 914, 11, 286, 519, 264, 4103, 551, 307, 1880, 11, 457, 360, 291, 445, 536, 51360], "temperature": 0.0, "avg_logprob": -0.19583977433971891, "compression_ratio": 1.7077464788732395, "no_speech_prob": 0.16775862872600555}, {"id": 110, "seek": 40968, "start": 429.6, "end": 432.28000000000003, "text": " it cynically as gatekeeping?", "tokens": [51360, 309, 28365, 984, 382, 8539, 25769, 30, 51494], "temperature": 0.0, "avg_logprob": -0.19583977433971891, "compression_ratio": 1.7077464788732395, "no_speech_prob": 0.16775862872600555}, {"id": 111, "seek": 40968, "start": 432.28000000000003, "end": 434.52, "text": " As in having a clerical class control?", "tokens": [51494, 1018, 294, 1419, 257, 25902, 804, 1508, 1969, 30, 51606], "temperature": 0.0, "avg_logprob": -0.19583977433971891, "compression_ratio": 1.7077464788732395, "no_speech_prob": 0.16775862872600555}, {"id": 112, "seek": 40968, "start": 434.52, "end": 435.52, "text": " Oh, absolutely.", "tokens": [51606, 876, 11, 3122, 13, 51656], "temperature": 0.0, "avg_logprob": -0.19583977433971891, "compression_ratio": 1.7077464788732395, "no_speech_prob": 0.16775862872600555}, {"id": 113, "seek": 40968, "start": 435.52, "end": 436.52, "text": " No, absolutely.", "tokens": [51656, 883, 11, 3122, 13, 51706], "temperature": 0.0, "avg_logprob": -0.19583977433971891, "compression_ratio": 1.7077464788732395, "no_speech_prob": 0.16775862872600555}, {"id": 114, "seek": 43652, "start": 436.88, "end": 442.96, "text": " That's precisely the danger that I was referring to is that if you, let me put it this way.", "tokens": [50382, 663, 311, 13402, 264, 4330, 300, 286, 390, 13761, 281, 307, 300, 498, 291, 11, 718, 385, 829, 309, 341, 636, 13, 50686], "temperature": 0.0, "avg_logprob": -0.2208746548356681, "compression_ratio": 1.7840909090909092, "no_speech_prob": 0.08123207092285156}, {"id": 115, "seek": 43652, "start": 442.96, "end": 447.91999999999996, "text": " If ever there is, and this is a commonly mooted proposal, right, and not even proposed like,", "tokens": [50686, 759, 1562, 456, 307, 11, 293, 341, 307, 257, 12719, 705, 23325, 11494, 11, 558, 11, 293, 406, 754, 10348, 411, 11, 50934], "temperature": 0.0, "avg_logprob": -0.2208746548356681, "compression_ratio": 1.7840909090909092, "no_speech_prob": 0.08123207092285156}, {"id": 116, "seek": 43652, "start": 447.91999999999996, "end": 453.28, "text": " are we going to have a truth commission of people who decide what is true on whatever,", "tokens": [50934, 366, 321, 516, 281, 362, 257, 3494, 9221, 295, 561, 567, 4536, 437, 307, 2074, 322, 2035, 11, 51202], "temperature": 0.0, "avg_logprob": -0.2208746548356681, "compression_ratio": 1.7840909090909092, "no_speech_prob": 0.08123207092285156}, {"id": 117, "seek": 43652, "start": 453.28, "end": 455.15999999999997, "text": " Twitter or something, right?", "tokens": [51202, 5794, 420, 746, 11, 558, 30, 51296], "temperature": 0.0, "avg_logprob": -0.2208746548356681, "compression_ratio": 1.7840909090909092, "no_speech_prob": 0.08123207092285156}, {"id": 118, "seek": 43652, "start": 455.15999999999997, "end": 460.76, "text": " That is a really alarming thing because there is no commission that can do that.", "tokens": [51296, 663, 307, 257, 534, 44043, 551, 570, 456, 307, 572, 9221, 300, 393, 360, 300, 13, 51576], "temperature": 0.0, "avg_logprob": -0.2208746548356681, "compression_ratio": 1.7840909090909092, "no_speech_prob": 0.08123207092285156}, {"id": 119, "seek": 43652, "start": 460.76, "end": 464.12, "text": " What they're going to do is they're going to impose their version of reality on everybody", "tokens": [51576, 708, 436, 434, 516, 281, 360, 307, 436, 434, 516, 281, 26952, 641, 3037, 295, 4103, 322, 2201, 51744], "temperature": 0.0, "avg_logprob": -0.2208746548356681, "compression_ratio": 1.7840909090909092, "no_speech_prob": 0.08123207092285156}, {"id": 120, "seek": 46412, "start": 464.12, "end": 467.64, "text": " else, which unfortunately is what a lot of these people want to do.", "tokens": [50364, 1646, 11, 597, 7015, 307, 437, 257, 688, 295, 613, 561, 528, 281, 360, 13, 50540], "temperature": 0.0, "avg_logprob": -0.14528867660030242, "compression_ratio": 1.7351190476190477, "no_speech_prob": 0.09757347404956818}, {"id": 121, "seek": 46412, "start": 467.64, "end": 470.6, "text": " They convince that they have the truth and they want to impose it on the rest of us.", "tokens": [50540, 814, 13447, 300, 436, 362, 264, 3494, 293, 436, 528, 281, 26952, 309, 322, 264, 1472, 295, 505, 13, 50688], "temperature": 0.0, "avg_logprob": -0.14528867660030242, "compression_ratio": 1.7351190476190477, "no_speech_prob": 0.09757347404956818}, {"id": 122, "seek": 46412, "start": 470.6, "end": 472.04, "text": " And that is really alarming.", "tokens": [50688, 400, 300, 307, 534, 44043, 13, 50760], "temperature": 0.0, "avg_logprob": -0.14528867660030242, "compression_ratio": 1.7351190476190477, "no_speech_prob": 0.09757347404956818}, {"id": 123, "seek": 46412, "start": 472.04, "end": 475.2, "text": " We know historically what happens when people succeed in doing that.", "tokens": [50760, 492, 458, 16180, 437, 2314, 562, 561, 7754, 294, 884, 300, 13, 50918], "temperature": 0.0, "avg_logprob": -0.14528867660030242, "compression_ratio": 1.7351190476190477, "no_speech_prob": 0.09757347404956818}, {"id": 124, "seek": 46412, "start": 475.2, "end": 476.2, "text": " Yes.", "tokens": [50918, 1079, 13, 50968], "temperature": 0.0, "avg_logprob": -0.14528867660030242, "compression_ratio": 1.7351190476190477, "no_speech_prob": 0.09757347404956818}, {"id": 125, "seek": 46412, "start": 476.2, "end": 477.2, "text": " Yes.", "tokens": [50968, 1079, 13, 51018], "temperature": 0.0, "avg_logprob": -0.14528867660030242, "compression_ratio": 1.7351190476190477, "no_speech_prob": 0.09757347404956818}, {"id": 126, "seek": 46412, "start": 477.2, "end": 480.48, "text": " But I suppose my point with the gatekeeping is it almost gets you to the actual truth", "tokens": [51018, 583, 286, 7297, 452, 935, 365, 264, 8539, 25769, 307, 309, 1920, 2170, 291, 281, 264, 3539, 3494, 51182], "temperature": 0.0, "avg_logprob": -0.14528867660030242, "compression_ratio": 1.7351190476190477, "no_speech_prob": 0.09757347404956818}, {"id": 127, "seek": 46412, "start": 480.48, "end": 482.12, "text": " of the matter is irrelevant.", "tokens": [51182, 295, 264, 1871, 307, 28682, 13, 51264], "temperature": 0.0, "avg_logprob": -0.14528867660030242, "compression_ratio": 1.7351190476190477, "no_speech_prob": 0.09757347404956818}, {"id": 128, "seek": 46412, "start": 482.12, "end": 483.76, "text": " It's actually about power.", "tokens": [51264, 467, 311, 767, 466, 1347, 13, 51346], "temperature": 0.0, "avg_logprob": -0.14528867660030242, "compression_ratio": 1.7351190476190477, "no_speech_prob": 0.09757347404956818}, {"id": 129, "seek": 46412, "start": 483.76, "end": 487.92, "text": " But what's your take on, I don't know whether you think this is putting it too strongly,", "tokens": [51346, 583, 437, 311, 428, 747, 322, 11, 286, 500, 380, 458, 1968, 291, 519, 341, 307, 3372, 309, 886, 10613, 11, 51554], "temperature": 0.0, "avg_logprob": -0.14528867660030242, "compression_ratio": 1.7351190476190477, "no_speech_prob": 0.09757347404956818}, {"id": 130, "seek": 46412, "start": 487.92, "end": 493.8, "text": " but this being a form of industrial kind of gaslighting, kind of, you know, in an Orwellian", "tokens": [51554, 457, 341, 885, 257, 1254, 295, 9987, 733, 295, 4211, 2764, 278, 11, 733, 295, 11, 291, 458, 11, 294, 364, 1610, 6326, 952, 51848], "temperature": 0.0, "avg_logprob": -0.14528867660030242, "compression_ratio": 1.7351190476190477, "no_speech_prob": 0.09757347404956818}, {"id": 131, "seek": 49380, "start": 493.8, "end": 499.0, "text": " sense, trying to shape people's reality through, you know, language, culture and interactions", "tokens": [50364, 2020, 11, 1382, 281, 3909, 561, 311, 4103, 807, 11, 291, 458, 11, 2856, 11, 3713, 293, 13280, 50624], "temperature": 0.0, "avg_logprob": -0.17693354048818913, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.06505691260099411}, {"id": 132, "seek": 49380, "start": 499.0, "end": 500.52000000000004, "text": " on the internet.", "tokens": [50624, 322, 264, 4705, 13, 50700], "temperature": 0.0, "avg_logprob": -0.17693354048818913, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.06505691260099411}, {"id": 133, "seek": 49380, "start": 500.52000000000004, "end": 503.6, "text": " I think a lot of it is deliberate.", "tokens": [50700, 286, 519, 257, 688, 295, 309, 307, 30515, 13, 50854], "temperature": 0.0, "avg_logprob": -0.17693354048818913, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.06505691260099411}, {"id": 134, "seek": 49380, "start": 503.6, "end": 509.72, "text": " Some of it is, I mean, I'm an optimist about human nature at the end of the day.", "tokens": [50854, 2188, 295, 309, 307, 11, 286, 914, 11, 286, 478, 364, 5028, 468, 466, 1952, 3687, 412, 264, 917, 295, 264, 786, 13, 51160], "temperature": 0.0, "avg_logprob": -0.17693354048818913, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.06505691260099411}, {"id": 135, "seek": 49380, "start": 509.72, "end": 512.72, "text": " Maybe in, you know, maybe with justification, maybe without.", "tokens": [51160, 2704, 294, 11, 291, 458, 11, 1310, 365, 31591, 11, 1310, 1553, 13, 51310], "temperature": 0.0, "avg_logprob": -0.17693354048818913, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.06505691260099411}, {"id": 136, "seek": 49380, "start": 512.72, "end": 518.2, "text": " I think so there's this postmodern view that it's all about power and it's certainly partly", "tokens": [51310, 286, 519, 370, 456, 311, 341, 2183, 42359, 1910, 300, 309, 311, 439, 466, 1347, 293, 309, 311, 3297, 17031, 51584], "temperature": 0.0, "avg_logprob": -0.17693354048818913, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.06505691260099411}, {"id": 137, "seek": 49380, "start": 518.2, "end": 519.2, "text": " about power.", "tokens": [51584, 466, 1347, 13, 51634], "temperature": 0.0, "avg_logprob": -0.17693354048818913, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.06505691260099411}, {"id": 138, "seek": 51920, "start": 519.2, "end": 524.6, "text": " I think a lot of the people doing this, unfortunately, or maybe fortunately, they are, they're not", "tokens": [50364, 286, 519, 257, 688, 295, 264, 561, 884, 341, 11, 7015, 11, 420, 1310, 25511, 11, 436, 366, 11, 436, 434, 406, 50634], "temperature": 0.0, "avg_logprob": -0.18409142127403846, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.15137697756290436}, {"id": 139, "seek": 51920, "start": 524.6, "end": 526.88, "text": " seeking power for its own sake.", "tokens": [50634, 11670, 1347, 337, 1080, 1065, 9717, 13, 50748], "temperature": 0.0, "avg_logprob": -0.18409142127403846, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.15137697756290436}, {"id": 140, "seek": 51920, "start": 526.88, "end": 529.76, "text": " They have a set of beliefs that they think is right.", "tokens": [50748, 814, 362, 257, 992, 295, 13585, 300, 436, 519, 307, 558, 13, 50892], "temperature": 0.0, "avg_logprob": -0.18409142127403846, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.15137697756290436}, {"id": 141, "seek": 51920, "start": 529.76, "end": 533.12, "text": " And then the means, you know, they unjustify the means, right?", "tokens": [50892, 400, 550, 264, 1355, 11, 291, 458, 11, 436, 37046, 2505, 264, 1355, 11, 558, 30, 51060], "temperature": 0.0, "avg_logprob": -0.18409142127403846, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.15137697756290436}, {"id": 142, "seek": 51920, "start": 533.12, "end": 534.12, "text": " That's the problem.", "tokens": [51060, 663, 311, 264, 1154, 13, 51110], "temperature": 0.0, "avg_logprob": -0.18409142127403846, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.15137697756290436}, {"id": 143, "seek": 51920, "start": 534.12, "end": 541.48, "text": " So that gatekeeping, you know, and that gaslighting happen not because, not for their own sake,", "tokens": [51110, 407, 300, 8539, 25769, 11, 291, 458, 11, 293, 300, 4211, 2764, 278, 1051, 406, 570, 11, 406, 337, 641, 1065, 9717, 11, 51478], "temperature": 0.0, "avg_logprob": -0.18409142127403846, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.15137697756290436}, {"id": 144, "seek": 51920, "start": 541.48, "end": 542.88, "text": " they happen for the sake of a cause.", "tokens": [51478, 436, 1051, 337, 264, 9717, 295, 257, 3082, 13, 51548], "temperature": 0.0, "avg_logprob": -0.18409142127403846, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.15137697756290436}, {"id": 145, "seek": 51920, "start": 542.88, "end": 547.08, "text": " And now there's two problems with this is that these days the causes on behalf of which", "tokens": [51548, 400, 586, 456, 311, 732, 2740, 365, 341, 307, 300, 613, 1708, 264, 7700, 322, 9490, 295, 597, 51758], "temperature": 0.0, "avg_logprob": -0.18409142127403846, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.15137697756290436}, {"id": 146, "seek": 54708, "start": 547.08, "end": 550.44, "text": " this is being done, in my view, are largely wrong, right?", "tokens": [50364, 341, 307, 885, 1096, 11, 294, 452, 1910, 11, 366, 11611, 2085, 11, 558, 30, 50532], "temperature": 0.0, "avg_logprob": -0.18687819163004557, "compression_ratio": 1.644859813084112, "no_speech_prob": 0.14991046488285065}, {"id": 147, "seek": 54708, "start": 550.44, "end": 552.1600000000001, "text": " But whether they're right or wrong, right?", "tokens": [50532, 583, 1968, 436, 434, 558, 420, 2085, 11, 558, 30, 50618], "temperature": 0.0, "avg_logprob": -0.18687819163004557, "compression_ratio": 1.644859813084112, "no_speech_prob": 0.14991046488285065}, {"id": 148, "seek": 54708, "start": 552.1600000000001, "end": 555.48, "text": " The problem is that this is just noxious in its own right.", "tokens": [50618, 440, 1154, 307, 300, 341, 307, 445, 572, 87, 851, 294, 1080, 1065, 558, 13, 50784], "temperature": 0.0, "avg_logprob": -0.18687819163004557, "compression_ratio": 1.644859813084112, "no_speech_prob": 0.14991046488285065}, {"id": 149, "seek": 54708, "start": 555.48, "end": 561.84, "text": " And also then a lot of sort of like, again, personal desire for power and promotion and", "tokens": [50784, 400, 611, 550, 257, 688, 295, 1333, 295, 411, 11, 797, 11, 2973, 7516, 337, 1347, 293, 15783, 293, 51102], "temperature": 0.0, "avg_logprob": -0.18687819163004557, "compression_ratio": 1.644859813084112, "no_speech_prob": 0.14991046488285065}, {"id": 150, "seek": 54708, "start": 561.84, "end": 562.84, "text": " prevailing over others.", "tokens": [51102, 12642, 23315, 670, 2357, 13, 51152], "temperature": 0.0, "avg_logprob": -0.18687819163004557, "compression_ratio": 1.644859813084112, "no_speech_prob": 0.14991046488285065}, {"id": 151, "seek": 54708, "start": 562.84, "end": 565.08, "text": " Then of course, you know, hitches are right onto this.", "tokens": [51152, 1396, 295, 1164, 11, 291, 458, 11, 33259, 279, 366, 558, 3911, 341, 13, 51264], "temperature": 0.0, "avg_logprob": -0.18687819163004557, "compression_ratio": 1.644859813084112, "no_speech_prob": 0.14991046488285065}, {"id": 152, "seek": 54708, "start": 565.08, "end": 566.08, "text": " Yeah, interesting.", "tokens": [51264, 865, 11, 1880, 13, 51314], "temperature": 0.0, "avg_logprob": -0.18687819163004557, "compression_ratio": 1.644859813084112, "no_speech_prob": 0.14991046488285065}, {"id": 153, "seek": 54708, "start": 566.08, "end": 570.0, "text": " I mean, we'll get into consequentialism in a minute because I think there's quite an", "tokens": [51314, 286, 914, 11, 321, 603, 483, 666, 7242, 2549, 1434, 294, 257, 3456, 570, 286, 519, 456, 311, 1596, 364, 51510], "temperature": 0.0, "avg_logprob": -0.18687819163004557, "compression_ratio": 1.644859813084112, "no_speech_prob": 0.14991046488285065}, {"id": 154, "seek": 54708, "start": 570.0, "end": 571.72, "text": " interesting journey we can go there.", "tokens": [51510, 1880, 4671, 321, 393, 352, 456, 13, 51596], "temperature": 0.0, "avg_logprob": -0.18687819163004557, "compression_ratio": 1.644859813084112, "no_speech_prob": 0.14991046488285065}, {"id": 155, "seek": 54708, "start": 571.72, "end": 575.5600000000001, "text": " But I wanted to cite Francois Chollet, I'm a big fan of him.", "tokens": [51596, 583, 286, 1415, 281, 37771, 34695, 271, 761, 1833, 302, 11, 286, 478, 257, 955, 3429, 295, 796, 13, 51788], "temperature": 0.0, "avg_logprob": -0.18687819163004557, "compression_ratio": 1.644859813084112, "no_speech_prob": 0.14991046488285065}, {"id": 156, "seek": 57556, "start": 575.56, "end": 579.76, "text": " He just tweeted saying, I'm not too concerned of whether what I read is right or wrong.", "tokens": [50364, 634, 445, 25646, 1566, 11, 286, 478, 406, 886, 5922, 295, 1968, 437, 286, 1401, 307, 558, 420, 2085, 13, 50574], "temperature": 0.0, "avg_logprob": -0.12412152327890472, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.2557161748409271}, {"id": 157, "seek": 57556, "start": 579.76, "end": 582.04, "text": " I can figure that part out myself.", "tokens": [50574, 286, 393, 2573, 300, 644, 484, 2059, 13, 50688], "temperature": 0.0, "avg_logprob": -0.12412152327890472, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.2557161748409271}, {"id": 158, "seek": 57556, "start": 582.04, "end": 586.04, "text": " I'm interested in things that are useful, thought-provoking, novel.", "tokens": [50688, 286, 478, 3102, 294, 721, 300, 366, 4420, 11, 1194, 12, 49911, 5953, 11, 7613, 13, 50888], "temperature": 0.0, "avg_logprob": -0.12412152327890472, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.2557161748409271}, {"id": 159, "seek": 57556, "start": 586.04, "end": 589.1999999999999, "text": " Sometimes the most creative thinkers have a bias towards wrongness, but they're still", "tokens": [50888, 4803, 264, 881, 5880, 37895, 362, 257, 12577, 3030, 2085, 1287, 11, 457, 436, 434, 920, 51046], "temperature": 0.0, "avg_logprob": -0.12412152327890472, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.2557161748409271}, {"id": 160, "seek": 57556, "start": 589.1999999999999, "end": 590.1999999999999, "text": " worth reading.", "tokens": [51046, 3163, 3760, 13, 51096], "temperature": 0.0, "avg_logprob": -0.12412152327890472, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.2557161748409271}, {"id": 161, "seek": 57556, "start": 590.1999999999999, "end": 591.1999999999999, "text": " Would you agree with that?", "tokens": [51096, 6068, 291, 3986, 365, 300, 30, 51146], "temperature": 0.0, "avg_logprob": -0.12412152327890472, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.2557161748409271}, {"id": 162, "seek": 57556, "start": 591.1999999999999, "end": 592.68, "text": " Yes, I largely agree with that.", "tokens": [51146, 1079, 11, 286, 11611, 3986, 365, 300, 13, 51220], "temperature": 0.0, "avg_logprob": -0.12412152327890472, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.2557161748409271}, {"id": 163, "seek": 57556, "start": 592.68, "end": 599.0799999999999, "text": " So as I was saying before, you know, I can tell for myself or I can do that exercise", "tokens": [51220, 407, 382, 286, 390, 1566, 949, 11, 291, 458, 11, 286, 393, 980, 337, 2059, 420, 286, 393, 360, 300, 5380, 51540], "temperature": 0.0, "avg_logprob": -0.12412152327890472, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.2557161748409271}, {"id": 164, "seek": 57556, "start": 599.0799999999999, "end": 600.8399999999999, "text": " of figuring out what is right and wrong.", "tokens": [51540, 295, 15213, 484, 437, 307, 558, 293, 2085, 13, 51628], "temperature": 0.0, "avg_logprob": -0.12412152327890472, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.2557161748409271}, {"id": 165, "seek": 60084, "start": 600.84, "end": 606.0, "text": " The most important thing that I want is to not miss out on things that I don't want to", "tokens": [50364, 440, 881, 1021, 551, 300, 286, 528, 307, 281, 406, 1713, 484, 322, 721, 300, 286, 500, 380, 528, 281, 50622], "temperature": 0.0, "avg_logprob": -0.12891161719033883, "compression_ratio": 1.8602150537634408, "no_speech_prob": 0.29224032163619995}, {"id": 166, "seek": 60084, "start": 606.0, "end": 607.0, "text": " miss out on.", "tokens": [50622, 1713, 484, 322, 13, 50672], "temperature": 0.0, "avg_logprob": -0.12891161719033883, "compression_ratio": 1.8602150537634408, "no_speech_prob": 0.29224032163619995}, {"id": 167, "seek": 60084, "start": 607.0, "end": 611.32, "text": " Like, you know, the known unknowns and the unknown unknowns, the biggest killer is the", "tokens": [50672, 1743, 11, 291, 458, 11, 264, 2570, 46048, 293, 264, 9841, 46048, 11, 264, 3880, 13364, 307, 264, 50888], "temperature": 0.0, "avg_logprob": -0.12891161719033883, "compression_ratio": 1.8602150537634408, "no_speech_prob": 0.29224032163619995}, {"id": 168, "seek": 60084, "start": 611.32, "end": 612.32, "text": " unknown unknowns.", "tokens": [50888, 9841, 46048, 13, 50938], "temperature": 0.0, "avg_logprob": -0.12891161719033883, "compression_ratio": 1.8602150537634408, "no_speech_prob": 0.29224032163619995}, {"id": 169, "seek": 60084, "start": 612.32, "end": 617.5400000000001, "text": " So if anybody trying to learn or understand something, they're for person or organization", "tokens": [50938, 407, 498, 4472, 1382, 281, 1466, 420, 1223, 746, 11, 436, 434, 337, 954, 420, 4475, 51199], "temperature": 0.0, "avg_logprob": -0.12891161719033883, "compression_ratio": 1.8602150537634408, "no_speech_prob": 0.29224032163619995}, {"id": 170, "seek": 60084, "start": 617.5400000000001, "end": 619.0400000000001, "text": " or society, right?", "tokens": [51199, 420, 4086, 11, 558, 30, 51274], "temperature": 0.0, "avg_logprob": -0.12891161719033883, "compression_ratio": 1.8602150537634408, "no_speech_prob": 0.29224032163619995}, {"id": 171, "seek": 60084, "start": 619.0400000000001, "end": 623.8000000000001, "text": " If all they do is move the unknown unknowns to known unknowns, they've already gone an", "tokens": [51274, 759, 439, 436, 360, 307, 1286, 264, 9841, 46048, 281, 2570, 46048, 11, 436, 600, 1217, 2780, 364, 51512], "temperature": 0.0, "avg_logprob": -0.12891161719033883, "compression_ratio": 1.8602150537634408, "no_speech_prob": 0.29224032163619995}, {"id": 172, "seek": 60084, "start": 623.8000000000001, "end": 625.84, "text": " enormous distance, right?", "tokens": [51512, 11322, 4560, 11, 558, 30, 51614], "temperature": 0.0, "avg_logprob": -0.12891161719033883, "compression_ratio": 1.8602150537634408, "no_speech_prob": 0.29224032163619995}, {"id": 173, "seek": 60084, "start": 625.84, "end": 630.64, "text": " And so I appreciate people who I disagree with, first of all, because that's how you sharpen", "tokens": [51614, 400, 370, 286, 4449, 561, 567, 286, 14091, 365, 11, 700, 295, 439, 11, 570, 300, 311, 577, 291, 31570, 51854], "temperature": 0.0, "avg_logprob": -0.12891161719033883, "compression_ratio": 1.8602150537634408, "no_speech_prob": 0.29224032163619995}, {"id": 174, "seek": 63064, "start": 630.64, "end": 631.64, "text": " ideas.", "tokens": [50364, 3487, 13, 50414], "temperature": 0.0, "avg_logprob": -0.1569765635899135, "compression_ratio": 1.7129909365558913, "no_speech_prob": 0.04549116641283035}, {"id": 175, "seek": 63064, "start": 631.64, "end": 632.64, "text": " Yeah.", "tokens": [50414, 865, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1569765635899135, "compression_ratio": 1.7129909365558913, "no_speech_prob": 0.04549116641283035}, {"id": 176, "seek": 63064, "start": 632.64, "end": 638.28, "text": " But also because they may just bring things to my attention that if we were all conforming", "tokens": [50464, 583, 611, 570, 436, 815, 445, 1565, 721, 281, 452, 3202, 300, 498, 321, 645, 439, 18975, 278, 50746], "temperature": 0.0, "avg_logprob": -0.1569765635899135, "compression_ratio": 1.7129909365558913, "no_speech_prob": 0.04549116641283035}, {"id": 177, "seek": 63064, "start": 638.28, "end": 642.52, "text": " to the more majority view, would not come to our attention.", "tokens": [50746, 281, 264, 544, 6286, 1910, 11, 576, 406, 808, 281, 527, 3202, 13, 50958], "temperature": 0.0, "avg_logprob": -0.1569765635899135, "compression_ratio": 1.7129909365558913, "no_speech_prob": 0.04549116641283035}, {"id": 178, "seek": 63064, "start": 642.52, "end": 645.0, "text": " And then those more often than not are the ones that kill you.", "tokens": [50958, 400, 550, 729, 544, 2049, 813, 406, 366, 264, 2306, 300, 1961, 291, 13, 51082], "temperature": 0.0, "avg_logprob": -0.1569765635899135, "compression_ratio": 1.7129909365558913, "no_speech_prob": 0.04549116641283035}, {"id": 179, "seek": 63064, "start": 645.0, "end": 646.0, "text": " Yeah, that's so interesting.", "tokens": [51082, 865, 11, 300, 311, 370, 1880, 13, 51132], "temperature": 0.0, "avg_logprob": -0.1569765635899135, "compression_ratio": 1.7129909365558913, "no_speech_prob": 0.04549116641283035}, {"id": 180, "seek": 63064, "start": 646.0, "end": 649.76, "text": " I mean, there's a real analogy here, even this might be tenuous, but between symbolism", "tokens": [51132, 286, 914, 11, 456, 311, 257, 957, 21663, 510, 11, 754, 341, 1062, 312, 2064, 12549, 11, 457, 1296, 47061, 51320], "temperature": 0.0, "avg_logprob": -0.1569765635899135, "compression_ratio": 1.7129909365558913, "no_speech_prob": 0.04549116641283035}, {"id": 181, "seek": 63064, "start": 649.76, "end": 654.84, "text": " and connectionism or, you know, Rich Sutton said we shouldn't be hand-crafting our AI", "tokens": [51320, 293, 4984, 1434, 420, 11, 291, 458, 11, 6781, 40492, 1756, 848, 321, 4659, 380, 312, 1011, 12, 66, 10437, 783, 527, 7318, 51574], "temperature": 0.0, "avg_logprob": -0.1569765635899135, "compression_ratio": 1.7129909365558913, "no_speech_prob": 0.04549116641283035}, {"id": 182, "seek": 63064, "start": 654.84, "end": 655.84, "text": " systems.", "tokens": [51574, 3652, 13, 51624], "temperature": 0.0, "avg_logprob": -0.1569765635899135, "compression_ratio": 1.7129909365558913, "no_speech_prob": 0.04549116641283035}, {"id": 183, "seek": 63064, "start": 655.84, "end": 657.0, "text": " We should kind of let them emerge.", "tokens": [51624, 492, 820, 733, 295, 718, 552, 21511, 13, 51682], "temperature": 0.0, "avg_logprob": -0.1569765635899135, "compression_ratio": 1.7129909365558913, "no_speech_prob": 0.04549116641283035}, {"id": 184, "seek": 63064, "start": 657.0, "end": 660.04, "text": " And it's a similar thing with our moral framework, but you're kind of saying that it should be", "tokens": [51682, 400, 309, 311, 257, 2531, 551, 365, 527, 9723, 8388, 11, 457, 291, 434, 733, 295, 1566, 300, 309, 820, 312, 51834], "temperature": 0.0, "avg_logprob": -0.1569765635899135, "compression_ratio": 1.7129909365558913, "no_speech_prob": 0.04549116641283035}, {"id": 185, "seek": 66004, "start": 660.04, "end": 665.1999999999999, "text": " emergent from low level complexity and diversity and interestingness.", "tokens": [50364, 4345, 6930, 490, 2295, 1496, 14024, 293, 8811, 293, 1880, 1287, 13, 50622], "temperature": 0.0, "avg_logprob": -0.15805913441216768, "compression_ratio": 1.7032258064516128, "no_speech_prob": 0.047920744866132736}, {"id": 186, "seek": 66004, "start": 665.1999999999999, "end": 668.28, "text": " And there is another school of thought, which is that we should be top down and we already", "tokens": [50622, 400, 456, 307, 1071, 1395, 295, 1194, 11, 597, 307, 300, 321, 820, 312, 1192, 760, 293, 321, 1217, 50776], "temperature": 0.0, "avg_logprob": -0.15805913441216768, "compression_ratio": 1.7032258064516128, "no_speech_prob": 0.047920744866132736}, {"id": 187, "seek": 66004, "start": 668.28, "end": 669.4399999999999, "text": " have a representation.", "tokens": [50776, 362, 257, 10290, 13, 50834], "temperature": 0.0, "avg_logprob": -0.15805913441216768, "compression_ratio": 1.7032258064516128, "no_speech_prob": 0.047920744866132736}, {"id": 188, "seek": 66004, "start": 669.4399999999999, "end": 673.5999999999999, "text": " I actually think it should be, it needs to be a combination.", "tokens": [50834, 286, 767, 519, 309, 820, 312, 11, 309, 2203, 281, 312, 257, 6562, 13, 51042], "temperature": 0.0, "avg_logprob": -0.15805913441216768, "compression_ratio": 1.7032258064516128, "no_speech_prob": 0.047920744866132736}, {"id": 189, "seek": 66004, "start": 673.5999999999999, "end": 675.3199999999999, "text": " We need to have both.", "tokens": [51042, 492, 643, 281, 362, 1293, 13, 51128], "temperature": 0.0, "avg_logprob": -0.15805913441216768, "compression_ratio": 1.7032258064516128, "no_speech_prob": 0.047920744866132736}, {"id": 190, "seek": 66004, "start": 675.3199999999999, "end": 678.56, "text": " This is one of those debates that in some sense puzzles me because to me the obvious", "tokens": [51128, 639, 307, 472, 295, 729, 24203, 300, 294, 512, 2020, 24138, 385, 570, 281, 385, 264, 6322, 51290], "temperature": 0.0, "avg_logprob": -0.15805913441216768, "compression_ratio": 1.7032258064516128, "no_speech_prob": 0.047920744866132736}, {"id": 191, "seek": 66004, "start": 678.56, "end": 680.88, "text": " answer is that we need both.", "tokens": [51290, 1867, 307, 300, 321, 643, 1293, 13, 51406], "temperature": 0.0, "avg_logprob": -0.15805913441216768, "compression_ratio": 1.7032258064516128, "no_speech_prob": 0.047920744866132736}, {"id": 192, "seek": 66004, "start": 680.88, "end": 683.16, "text": " And then if you read the master argument, this is what I do.", "tokens": [51406, 400, 550, 498, 291, 1401, 264, 4505, 6770, 11, 341, 307, 437, 286, 360, 13, 51520], "temperature": 0.0, "avg_logprob": -0.15805913441216768, "compression_ratio": 1.7032258064516128, "no_speech_prob": 0.047920744866132736}, {"id": 193, "seek": 66004, "start": 683.16, "end": 686.7199999999999, "text": " I look at the different paradigms of machine learning and I don't come out in favor of", "tokens": [51520, 286, 574, 412, 264, 819, 13480, 328, 2592, 295, 3479, 2539, 293, 286, 500, 380, 808, 484, 294, 2294, 295, 51698], "temperature": 0.0, "avg_logprob": -0.15805913441216768, "compression_ratio": 1.7032258064516128, "no_speech_prob": 0.047920744866132736}, {"id": 194, "seek": 68672, "start": 686.72, "end": 690.48, "text": " any of them because I actually think we need ideas from all of them.", "tokens": [50364, 604, 295, 552, 570, 286, 767, 519, 321, 643, 3487, 490, 439, 295, 552, 13, 50552], "temperature": 0.0, "avg_logprob": -0.11650665133607153, "compression_ratio": 1.8322784810126582, "no_speech_prob": 0.22202272713184357}, {"id": 195, "seek": 68672, "start": 690.48, "end": 692.84, "text": " And then we need to combine them into something coherent.", "tokens": [50552, 400, 550, 321, 643, 281, 10432, 552, 666, 746, 36239, 13, 50670], "temperature": 0.0, "avg_logprob": -0.11650665133607153, "compression_ratio": 1.8322784810126582, "no_speech_prob": 0.22202272713184357}, {"id": 196, "seek": 68672, "start": 692.84, "end": 696.96, "text": " And if you look at psychology, like your brain does bottom up and top down processing.", "tokens": [50670, 400, 498, 291, 574, 412, 15105, 11, 411, 428, 3567, 775, 2767, 493, 293, 1192, 760, 9007, 13, 50876], "temperature": 0.0, "avg_logprob": -0.11650665133607153, "compression_ratio": 1.8322784810126582, "no_speech_prob": 0.22202272713184357}, {"id": 197, "seek": 68672, "start": 696.96, "end": 700.4, "text": " And if it only did one of them, either one, it wouldn't work.", "tokens": [50876, 400, 498, 309, 787, 630, 472, 295, 552, 11, 2139, 472, 11, 309, 2759, 380, 589, 13, 51048], "temperature": 0.0, "avg_logprob": -0.11650665133607153, "compression_ratio": 1.8322784810126582, "no_speech_prob": 0.22202272713184357}, {"id": 198, "seek": 68672, "start": 700.4, "end": 703.88, "text": " And I think as we try to build a larger intelligence, it's the same thing.", "tokens": [51048, 400, 286, 519, 382, 321, 853, 281, 1322, 257, 4833, 7599, 11, 309, 311, 264, 912, 551, 13, 51222], "temperature": 0.0, "avg_logprob": -0.11650665133607153, "compression_ratio": 1.8322784810126582, "no_speech_prob": 0.22202272713184357}, {"id": 199, "seek": 68672, "start": 703.88, "end": 708.1600000000001, "text": " We definitely need the bottom up part and, you know, by volume, the bottom up part is", "tokens": [51222, 492, 2138, 643, 264, 2767, 493, 644, 293, 11, 291, 458, 11, 538, 5523, 11, 264, 2767, 493, 644, 307, 51436], "temperature": 0.0, "avg_logprob": -0.11650665133607153, "compression_ratio": 1.8322784810126582, "no_speech_prob": 0.22202272713184357}, {"id": 200, "seek": 68672, "start": 708.1600000000001, "end": 709.1600000000001, "text": " going to be bigger.", "tokens": [51436, 516, 281, 312, 3801, 13, 51486], "temperature": 0.0, "avg_logprob": -0.11650665133607153, "compression_ratio": 1.8322784810126582, "no_speech_prob": 0.22202272713184357}, {"id": 201, "seek": 68672, "start": 709.1600000000001, "end": 712.96, "text": " So if you could only have one, that would probably be, you know, the choice.", "tokens": [51486, 407, 498, 291, 727, 787, 362, 472, 11, 300, 576, 1391, 312, 11, 291, 458, 11, 264, 3922, 13, 51676], "temperature": 0.0, "avg_logprob": -0.11650665133607153, "compression_ratio": 1.8322784810126582, "no_speech_prob": 0.22202272713184357}, {"id": 202, "seek": 68672, "start": 712.96, "end": 716.2, "text": " But the top down part is also very important.", "tokens": [51676, 583, 264, 1192, 760, 644, 307, 611, 588, 1021, 13, 51838], "temperature": 0.0, "avg_logprob": -0.11650665133607153, "compression_ratio": 1.8322784810126582, "no_speech_prob": 0.22202272713184357}, {"id": 203, "seek": 71620, "start": 716.24, "end": 720.44, "text": " If you go all the way back, the top down part probably started this bottom up and got synthesized", "tokens": [50366, 759, 291, 352, 439, 264, 636, 646, 11, 264, 1192, 760, 644, 1391, 1409, 341, 2767, 493, 293, 658, 26617, 1602, 50576], "temperature": 0.0, "avg_logprob": -0.13552174010834137, "compression_ratio": 1.6925207756232687, "no_speech_prob": 0.007796197663992643}, {"id": 204, "seek": 71620, "start": 720.44, "end": 721.44, "text": " and improved.", "tokens": [50576, 293, 9689, 13, 50626], "temperature": 0.0, "avg_logprob": -0.13552174010834137, "compression_ratio": 1.6925207756232687, "no_speech_prob": 0.007796197663992643}, {"id": 205, "seek": 71620, "start": 721.44, "end": 722.88, "text": " But now we need that loop.", "tokens": [50626, 583, 586, 321, 643, 300, 6367, 13, 50698], "temperature": 0.0, "avg_logprob": -0.13552174010834137, "compression_ratio": 1.6925207756232687, "no_speech_prob": 0.007796197663992643}, {"id": 206, "seek": 71620, "start": 722.88, "end": 724.32, "text": " The loop is actually very important.", "tokens": [50698, 440, 6367, 307, 767, 588, 1021, 13, 50770], "temperature": 0.0, "avg_logprob": -0.13552174010834137, "compression_ratio": 1.6925207756232687, "no_speech_prob": 0.007796197663992643}, {"id": 207, "seek": 71620, "start": 724.32, "end": 725.32, "text": " Well, that's interesting.", "tokens": [50770, 1042, 11, 300, 311, 1880, 13, 50820], "temperature": 0.0, "avg_logprob": -0.13552174010834137, "compression_ratio": 1.6925207756232687, "no_speech_prob": 0.007796197663992643}, {"id": 208, "seek": 71620, "start": 725.32, "end": 729.6, "text": " So in your book, I guess I want to sketch out different types of AI architecture.", "tokens": [50820, 407, 294, 428, 1446, 11, 286, 2041, 286, 528, 281, 12325, 484, 819, 3467, 295, 7318, 9482, 13, 51034], "temperature": 0.0, "avg_logprob": -0.13552174010834137, "compression_ratio": 1.6925207756232687, "no_speech_prob": 0.007796197663992643}, {"id": 209, "seek": 71620, "start": 729.6, "end": 732.84, "text": " So, you know, you get universalists to this kind of deep mind idea that a very simple", "tokens": [51034, 407, 11, 291, 458, 11, 291, 483, 11455, 1751, 281, 341, 733, 295, 2452, 1575, 1558, 300, 257, 588, 2199, 51196], "temperature": 0.0, "avg_logprob": -0.13552174010834137, "compression_ratio": 1.6925207756232687, "no_speech_prob": 0.007796197663992643}, {"id": 210, "seek": 71620, "start": 732.84, "end": 735.0, "text": " underlying algorithm could produce everything.", "tokens": [51196, 14217, 9284, 727, 5258, 1203, 13, 51304], "temperature": 0.0, "avg_logprob": -0.13552174010834137, "compression_ratio": 1.6925207756232687, "no_speech_prob": 0.007796197663992643}, {"id": 211, "seek": 71620, "start": 735.0, "end": 738.0, "text": " And then you get, you know, hybrid folks on the other side of the spectrum.", "tokens": [51304, 400, 550, 291, 483, 11, 291, 458, 11, 13051, 4024, 322, 264, 661, 1252, 295, 264, 11143, 13, 51454], "temperature": 0.0, "avg_logprob": -0.13552174010834137, "compression_ratio": 1.6925207756232687, "no_speech_prob": 0.007796197663992643}, {"id": 212, "seek": 71620, "start": 738.0, "end": 740.0, "text": " And then there's an integrated approach in the middle.", "tokens": [51454, 400, 550, 456, 311, 364, 10919, 3109, 294, 264, 2808, 13, 51554], "temperature": 0.0, "avg_logprob": -0.13552174010834137, "compression_ratio": 1.6925207756232687, "no_speech_prob": 0.007796197663992643}, {"id": 213, "seek": 71620, "start": 740.0, "end": 742.6800000000001, "text": " Like, where would you kind of place yourself on that continuum?", "tokens": [51554, 1743, 11, 689, 576, 291, 733, 295, 1081, 1803, 322, 300, 36120, 30, 51688], "temperature": 0.0, "avg_logprob": -0.13552174010834137, "compression_ratio": 1.6925207756232687, "no_speech_prob": 0.007796197663992643}, {"id": 214, "seek": 74268, "start": 742.68, "end": 748.4799999999999, "text": " I would place myself very much in the frame of mind, well, let me put it this way.", "tokens": [50364, 286, 576, 1081, 2059, 588, 709, 294, 264, 3920, 295, 1575, 11, 731, 11, 718, 385, 829, 309, 341, 636, 13, 50654], "temperature": 0.0, "avg_logprob": -0.17020347301776592, "compression_ratio": 1.6476510067114094, "no_speech_prob": 0.009394017979502678}, {"id": 215, "seek": 74268, "start": 748.4799999999999, "end": 751.3199999999999, "text": " I don't know, but which is nobody does, right?", "tokens": [50654, 286, 500, 380, 458, 11, 457, 597, 307, 5079, 775, 11, 558, 30, 50796], "temperature": 0.0, "avg_logprob": -0.17020347301776592, "compression_ratio": 1.6476510067114094, "no_speech_prob": 0.009394017979502678}, {"id": 216, "seek": 74268, "start": 751.3199999999999, "end": 754.64, "text": " If somebody tells you that they know how we're going to get to intelligence, you should be", "tokens": [50796, 759, 2618, 5112, 291, 300, 436, 458, 577, 321, 434, 516, 281, 483, 281, 7599, 11, 291, 820, 312, 50962], "temperature": 0.0, "avg_logprob": -0.17020347301776592, "compression_ratio": 1.6476510067114094, "no_speech_prob": 0.009394017979502678}, {"id": 217, "seek": 74268, "start": 754.64, "end": 756.1999999999999, "text": " suspicious right away.", "tokens": [50962, 17931, 558, 1314, 13, 51040], "temperature": 0.0, "avg_logprob": -0.17020347301776592, "compression_ratio": 1.6476510067114094, "no_speech_prob": 0.009394017979502678}, {"id": 218, "seek": 74268, "start": 756.1999999999999, "end": 760.92, "text": " But what do I think is the most promising approach and the one that ideally would be", "tokens": [51040, 583, 437, 360, 286, 519, 307, 264, 881, 20257, 3109, 293, 264, 472, 300, 22915, 576, 312, 51276], "temperature": 0.0, "avg_logprob": -0.17020347301776592, "compression_ratio": 1.6476510067114094, "no_speech_prob": 0.009394017979502678}, {"id": 219, "seek": 74268, "start": 760.92, "end": 762.5999999999999, "text": " the best one if we can pull it off?", "tokens": [51276, 264, 1151, 472, 498, 321, 393, 2235, 309, 766, 30, 51360], "temperature": 0.0, "avg_logprob": -0.17020347301776592, "compression_ratio": 1.6476510067114094, "no_speech_prob": 0.009394017979502678}, {"id": 220, "seek": 74268, "start": 762.5999999999999, "end": 764.52, "text": " It's there being a single algorithm.", "tokens": [51360, 467, 311, 456, 885, 257, 2167, 9284, 13, 51456], "temperature": 0.0, "avg_logprob": -0.17020347301776592, "compression_ratio": 1.6476510067114094, "no_speech_prob": 0.009394017979502678}, {"id": 221, "seek": 74268, "start": 764.52, "end": 769.24, "text": " So at that level, I very much sympathize with what is effectively the deep mind's agenda.", "tokens": [51456, 407, 412, 300, 1496, 11, 286, 588, 709, 22276, 1125, 365, 437, 307, 8659, 264, 2452, 1575, 311, 9829, 13, 51692], "temperature": 0.0, "avg_logprob": -0.17020347301776592, "compression_ratio": 1.6476510067114094, "no_speech_prob": 0.009394017979502678}, {"id": 222, "seek": 76924, "start": 769.24, "end": 775.08, "text": " Now, we're at part with a lot of these people is that I don't think the algorithm that we", "tokens": [50364, 823, 11, 321, 434, 412, 644, 365, 257, 688, 295, 613, 561, 307, 300, 286, 500, 380, 519, 264, 9284, 300, 321, 50656], "temperature": 0.0, "avg_logprob": -0.15908499409381607, "compression_ratio": 1.8618181818181818, "no_speech_prob": 0.1448117345571518}, {"id": 223, "seek": 76924, "start": 775.08, "end": 779.24, "text": " need is as simple as many of those people think it is.", "tokens": [50656, 643, 307, 382, 2199, 382, 867, 295, 729, 561, 519, 309, 307, 13, 50864], "temperature": 0.0, "avg_logprob": -0.15908499409381607, "compression_ratio": 1.8618181818181818, "no_speech_prob": 0.1448117345571518}, {"id": 224, "seek": 76924, "start": 779.24, "end": 781.76, "text": " And I don't think it exists.", "tokens": [50864, 400, 286, 500, 380, 519, 309, 8198, 13, 50990], "temperature": 0.0, "avg_logprob": -0.15908499409381607, "compression_ratio": 1.8618181818181818, "no_speech_prob": 0.1448117345571518}, {"id": 225, "seek": 76924, "start": 781.76, "end": 785.84, "text": " It is probably the case that the algorithm that we really need at the end of the day", "tokens": [50990, 467, 307, 1391, 264, 1389, 300, 264, 9284, 300, 321, 534, 643, 412, 264, 917, 295, 264, 786, 51194], "temperature": 0.0, "avg_logprob": -0.15908499409381607, "compression_ratio": 1.8618181818181818, "no_speech_prob": 0.1448117345571518}, {"id": 226, "seek": 76924, "start": 785.84, "end": 789.04, "text": " doesn't even look that much like any of the things that we have now.", "tokens": [51194, 1177, 380, 754, 574, 300, 709, 411, 604, 295, 264, 721, 300, 321, 362, 586, 13, 51354], "temperature": 0.0, "avg_logprob": -0.15908499409381607, "compression_ratio": 1.8618181818181818, "no_speech_prob": 0.1448117345571518}, {"id": 227, "seek": 76924, "start": 789.04, "end": 792.48, "text": " So I think hopefully there is such an algorithm, but we're still far from it.", "tokens": [51354, 407, 286, 519, 4696, 456, 307, 1270, 364, 9284, 11, 457, 321, 434, 920, 1400, 490, 309, 13, 51526], "temperature": 0.0, "avg_logprob": -0.15908499409381607, "compression_ratio": 1.8618181818181818, "no_speech_prob": 0.1448117345571518}, {"id": 228, "seek": 76924, "start": 792.48, "end": 793.48, "text": " Interesting.", "tokens": [51526, 14711, 13, 51576], "temperature": 0.0, "avg_logprob": -0.15908499409381607, "compression_ratio": 1.8618181818181818, "no_speech_prob": 0.1448117345571518}, {"id": 229, "seek": 76924, "start": 793.48, "end": 797.76, "text": " I mean, they would cite the example of evolution as being a very simple underlying algorithm.", "tokens": [51576, 286, 914, 11, 436, 576, 37771, 264, 1365, 295, 9303, 382, 885, 257, 588, 2199, 14217, 9284, 13, 51790], "temperature": 0.0, "avg_logprob": -0.15908499409381607, "compression_ratio": 1.8618181818181818, "no_speech_prob": 0.1448117345571518}, {"id": 230, "seek": 79776, "start": 797.76, "end": 802.04, "text": " Although Ken Stanley would say that people misunderstand evolution.", "tokens": [50364, 5780, 8273, 28329, 576, 584, 300, 561, 35736, 9303, 13, 50578], "temperature": 0.0, "avg_logprob": -0.14470781806771083, "compression_ratio": 1.7908496732026145, "no_speech_prob": 0.16522130370140076}, {"id": 231, "seek": 79776, "start": 802.04, "end": 803.72, "text": " So I agree with them at that level.", "tokens": [50578, 407, 286, 3986, 365, 552, 412, 300, 1496, 13, 50662], "temperature": 0.0, "avg_logprob": -0.14470781806771083, "compression_ratio": 1.7908496732026145, "no_speech_prob": 0.16522130370140076}, {"id": 232, "seek": 79776, "start": 803.72, "end": 807.92, "text": " In fact, in the master algorithm, I have a chapter where I go over the objections and", "tokens": [50662, 682, 1186, 11, 294, 264, 4505, 9284, 11, 286, 362, 257, 7187, 689, 286, 352, 670, 264, 44649, 293, 50872], "temperature": 0.0, "avg_logprob": -0.14470781806771083, "compression_ratio": 1.7908496732026145, "no_speech_prob": 0.16522130370140076}, {"id": 233, "seek": 79776, "start": 807.92, "end": 811.04, "text": " the reasons to believe that there is a master algorithm.", "tokens": [50872, 264, 4112, 281, 1697, 300, 456, 307, 257, 4505, 9284, 13, 51028], "temperature": 0.0, "avg_logprob": -0.14470781806771083, "compression_ratio": 1.7908496732026145, "no_speech_prob": 0.16522130370140076}, {"id": 234, "seek": 79776, "start": 811.04, "end": 815.72, "text": " The majority of the people even in the field are skeptical of that notion, even though", "tokens": [51028, 440, 6286, 295, 264, 561, 754, 294, 264, 2519, 366, 28601, 295, 300, 10710, 11, 754, 1673, 51262], "temperature": 0.0, "avg_logprob": -0.14470781806771083, "compression_ratio": 1.7908496732026145, "no_speech_prob": 0.16522130370140076}, {"id": 235, "seek": 79776, "start": 815.72, "end": 818.64, "text": " I would claim that effectively that's what they're pursuing.", "tokens": [51262, 286, 576, 3932, 300, 8659, 300, 311, 437, 436, 434, 20222, 13, 51408], "temperature": 0.0, "avg_logprob": -0.14470781806771083, "compression_ratio": 1.7908496732026145, "no_speech_prob": 0.16522130370140076}, {"id": 236, "seek": 79776, "start": 818.64, "end": 821.68, "text": " People like Rich Sutton and Jeff Hitton, I asked a bunch of people before I wrote the", "tokens": [51408, 3432, 411, 6781, 40492, 1756, 293, 7506, 389, 593, 266, 11, 286, 2351, 257, 3840, 295, 561, 949, 286, 4114, 264, 51560], "temperature": 0.0, "avg_logprob": -0.14470781806771083, "compression_ratio": 1.7908496732026145, "no_speech_prob": 0.16522130370140076}, {"id": 237, "seek": 79776, "start": 821.68, "end": 825.0, "text": " book and they do believe in this idea of having a master algorithm.", "tokens": [51560, 1446, 293, 436, 360, 1697, 294, 341, 1558, 295, 1419, 257, 4505, 9284, 13, 51726], "temperature": 0.0, "avg_logprob": -0.14470781806771083, "compression_ratio": 1.7908496732026145, "no_speech_prob": 0.16522130370140076}, {"id": 238, "seek": 82500, "start": 825.0, "end": 829.92, "text": " A lot of people believe that, but intuitively a lot of people believe that no, there is", "tokens": [50364, 316, 688, 295, 561, 1697, 300, 11, 457, 46506, 257, 688, 295, 561, 1697, 300, 572, 11, 456, 307, 50610], "temperature": 0.0, "avg_logprob": -0.19735542096589742, "compression_ratio": 1.794871794871795, "no_speech_prob": 0.029626045376062393}, {"id": 239, "seek": 82500, "start": 829.92, "end": 831.56, "text": " no such thing.", "tokens": [50610, 572, 1270, 551, 13, 50692], "temperature": 0.0, "avg_logprob": -0.19735542096589742, "compression_ratio": 1.794871794871795, "no_speech_prob": 0.029626045376062393}, {"id": 240, "seek": 82500, "start": 831.56, "end": 840.92, "text": " And I understand that intuition, but I don't think it's a well-founded intuition.", "tokens": [50692, 400, 286, 1223, 300, 24002, 11, 457, 286, 500, 380, 519, 309, 311, 257, 731, 12, 49547, 24002, 13, 51160], "temperature": 0.0, "avg_logprob": -0.19735542096589742, "compression_ratio": 1.794871794871795, "no_speech_prob": 0.029626045376062393}, {"id": 241, "seek": 82500, "start": 840.92, "end": 841.92, "text": " Let me put it that way.", "tokens": [51160, 961, 385, 829, 309, 300, 636, 13, 51210], "temperature": 0.0, "avg_logprob": -0.19735542096589742, "compression_ratio": 1.794871794871795, "no_speech_prob": 0.029626045376062393}, {"id": 242, "seek": 82500, "start": 841.92, "end": 845.52, "text": " But in a sense, we know there is such a thing, because look at cellular automata, look at", "tokens": [51210, 583, 294, 257, 2020, 11, 321, 458, 456, 307, 1270, 257, 551, 11, 570, 574, 412, 29267, 3553, 3274, 11, 574, 412, 51390], "temperature": 0.0, "avg_logprob": -0.19735542096589742, "compression_ratio": 1.794871794871795, "no_speech_prob": 0.029626045376062393}, {"id": 243, "seek": 82500, "start": 845.52, "end": 847.36, "text": " what we've already done with deep learning.", "tokens": [51390, 437, 321, 600, 1217, 1096, 365, 2452, 2539, 13, 51482], "temperature": 0.0, "avg_logprob": -0.19735542096589742, "compression_ratio": 1.794871794871795, "no_speech_prob": 0.029626045376062393}, {"id": 244, "seek": 82500, "start": 847.36, "end": 851.44, "text": " I think the context is, is there such a thing that will produce what we want?", "tokens": [51482, 286, 519, 264, 4319, 307, 11, 307, 456, 1270, 257, 551, 300, 486, 5258, 437, 321, 528, 30, 51686], "temperature": 0.0, "avg_logprob": -0.19735542096589742, "compression_ratio": 1.794871794871795, "no_speech_prob": 0.029626045376062393}, {"id": 245, "seek": 85144, "start": 852.44, "end": 861.72, "text": " To take your example or DeepMind's example of evolution, in the book I mentioned empirical", "tokens": [50414, 1407, 747, 428, 1365, 420, 14895, 44, 471, 311, 1365, 295, 9303, 11, 294, 264, 1446, 286, 2835, 31886, 50878], "temperature": 0.0, "avg_logprob": -0.22197279722794241, "compression_ratio": 1.7035398230088497, "no_speech_prob": 0.5003089308738708}, {"id": 246, "seek": 85144, "start": 861.72, "end": 865.84, "text": " evidence that there is a master algorithm and exhibit one is evolution.", "tokens": [50878, 4467, 300, 456, 307, 257, 4505, 9284, 293, 20487, 472, 307, 9303, 13, 51084], "temperature": 0.0, "avg_logprob": -0.22197279722794241, "compression_ratio": 1.7035398230088497, "no_speech_prob": 0.5003089308738708}, {"id": 247, "seek": 85144, "start": 865.84, "end": 868.8800000000001, "text": " If you think of evolution as an algorithm, which by the way is a very old idea, I think", "tokens": [51084, 759, 291, 519, 295, 9303, 382, 364, 9284, 11, 597, 538, 264, 636, 307, 257, 588, 1331, 1558, 11, 286, 519, 51236], "temperature": 0.0, "avg_logprob": -0.22197279722794241, "compression_ratio": 1.7035398230088497, "no_speech_prob": 0.5003089308738708}, {"id": 248, "seek": 85144, "start": 868.8800000000001, "end": 875.2, "text": " it was George Bull that said, God does not create animals and plants, he creates the", "tokens": [51236, 309, 390, 7136, 14131, 300, 848, 11, 1265, 775, 406, 1884, 4882, 293, 5972, 11, 415, 7829, 264, 51552], "temperature": 0.0, "avg_logprob": -0.22197279722794241, "compression_ratio": 1.7035398230088497, "no_speech_prob": 0.5003089308738708}, {"id": 249, "seek": 85144, "start": 875.2, "end": 878.32, "text": " algorithm by which animals and plants come about.", "tokens": [51552, 9284, 538, 597, 4882, 293, 5972, 808, 466, 13, 51708], "temperature": 0.0, "avg_logprob": -0.22197279722794241, "compression_ratio": 1.7035398230088497, "no_speech_prob": 0.5003089308738708}, {"id": 250, "seek": 87832, "start": 878.6, "end": 881.72, "text": " He didn't use the word algorithm, but that's essentially what he said.", "tokens": [50378, 634, 994, 380, 764, 264, 1349, 9284, 11, 457, 300, 311, 4476, 437, 415, 848, 13, 50534], "temperature": 0.0, "avg_logprob": -0.1391470610205807, "compression_ratio": 1.7892976588628762, "no_speech_prob": 0.32648375630378723}, {"id": 251, "seek": 87832, "start": 881.72, "end": 883.9200000000001, "text": " This I think is right on.", "tokens": [50534, 639, 286, 519, 307, 558, 322, 13, 50644], "temperature": 0.0, "avg_logprob": -0.1391470610205807, "compression_ratio": 1.7892976588628762, "no_speech_prob": 0.32648375630378723}, {"id": 252, "seek": 87832, "start": 883.9200000000001, "end": 886.5200000000001, "text": " Another example is your brain.", "tokens": [50644, 3996, 1365, 307, 428, 3567, 13, 50774], "temperature": 0.0, "avg_logprob": -0.1391470610205807, "compression_ratio": 1.7892976588628762, "no_speech_prob": 0.32648375630378723}, {"id": 253, "seek": 87832, "start": 886.5200000000001, "end": 890.48, "text": " If the algorithm doesn't have to be something as simple as backprop and you're a materialist", "tokens": [50774, 759, 264, 9284, 1177, 380, 362, 281, 312, 746, 382, 2199, 382, 646, 79, 1513, 293, 291, 434, 257, 2527, 468, 50972], "temperature": 0.0, "avg_logprob": -0.1391470610205807, "compression_ratio": 1.7892976588628762, "no_speech_prob": 0.32648375630378723}, {"id": 254, "seek": 87832, "start": 890.48, "end": 894.6400000000001, "text": " like most of the scientists are, your brain, if the master algorithm is an algorithm that", "tokens": [50972, 411, 881, 295, 264, 7708, 366, 11, 428, 3567, 11, 498, 264, 4505, 9284, 307, 364, 9284, 300, 51180], "temperature": 0.0, "avg_logprob": -0.1391470610205807, "compression_ratio": 1.7892976588628762, "no_speech_prob": 0.32648375630378723}, {"id": 255, "seek": 87832, "start": 894.6400000000001, "end": 898.2, "text": " can learn anything you do, then your brain is that algorithm.", "tokens": [51180, 393, 1466, 1340, 291, 360, 11, 550, 428, 3567, 307, 300, 9284, 13, 51358], "temperature": 0.0, "avg_logprob": -0.1391470610205807, "compression_ratio": 1.7892976588628762, "no_speech_prob": 0.32648375630378723}, {"id": 256, "seek": 87832, "start": 898.2, "end": 902.6, "text": " But then there's another one which is even more fundamental, but I think from the point", "tokens": [51358, 583, 550, 456, 311, 1071, 472, 597, 307, 754, 544, 8088, 11, 457, 286, 519, 490, 264, 935, 51578], "temperature": 0.0, "avg_logprob": -0.1391470610205807, "compression_ratio": 1.7892976588628762, "no_speech_prob": 0.32648375630378723}, {"id": 257, "seek": 87832, "start": 902.6, "end": 907.1600000000001, "text": " of view of this debate is very illuminating, which is the laws of physics.", "tokens": [51578, 295, 1910, 295, 341, 7958, 307, 588, 28593, 990, 11, 597, 307, 264, 6064, 295, 10649, 13, 51806], "temperature": 0.0, "avg_logprob": -0.1391470610205807, "compression_ratio": 1.7892976588628762, "no_speech_prob": 0.32648375630378723}, {"id": 258, "seek": 90716, "start": 907.16, "end": 908.68, "text": " Why stop at evolution?", "tokens": [50364, 1545, 1590, 412, 9303, 30, 50440], "temperature": 0.0, "avg_logprob": -0.14864729190694875, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.2580719590187073}, {"id": 259, "seek": 90716, "start": 908.68, "end": 911.48, "text": " The laws of physics are the master algorithm.", "tokens": [50440, 440, 6064, 295, 10649, 366, 264, 4505, 9284, 13, 50580], "temperature": 0.0, "avg_logprob": -0.14864729190694875, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.2580719590187073}, {"id": 260, "seek": 90716, "start": 911.48, "end": 913.0799999999999, "text": " Evolution is very complicated.", "tokens": [50580, 40800, 307, 588, 6179, 13, 50660], "temperature": 0.0, "avg_logprob": -0.14864729190694875, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.2580719590187073}, {"id": 261, "seek": 90716, "start": 913.0799999999999, "end": 917.8, "text": " In fact, what I think about evolution in AI currently is that evolution in reality is", "tokens": [50660, 682, 1186, 11, 437, 286, 519, 466, 9303, 294, 7318, 4362, 307, 300, 9303, 294, 4103, 307, 50896], "temperature": 0.0, "avg_logprob": -0.14864729190694875, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.2580719590187073}, {"id": 262, "seek": 90716, "start": 917.8, "end": 921.76, "text": " much more complex than we give it credit for, which is why a lot of our current generic", "tokens": [50896, 709, 544, 3997, 813, 321, 976, 309, 5397, 337, 11, 597, 307, 983, 257, 688, 295, 527, 2190, 19577, 51094], "temperature": 0.0, "avg_logprob": -0.14864729190694875, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.2580719590187073}, {"id": 263, "seek": 90716, "start": 921.76, "end": 923.3199999999999, "text": " algorithms don't work that well.", "tokens": [51094, 14642, 500, 380, 589, 300, 731, 13, 51172], "temperature": 0.0, "avg_logprob": -0.14864729190694875, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.2580719590187073}, {"id": 264, "seek": 90716, "start": 923.3199999999999, "end": 926.56, "text": " But the laws of physics at this level are much simpler.", "tokens": [51172, 583, 264, 6064, 295, 10649, 412, 341, 1496, 366, 709, 18587, 13, 51334], "temperature": 0.0, "avg_logprob": -0.14864729190694875, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.2580719590187073}, {"id": 265, "seek": 90716, "start": 926.56, "end": 931.48, "text": " If you think about it, from the laws of physics comes evolution and comes all the intelligence", "tokens": [51334, 759, 291, 519, 466, 309, 11, 490, 264, 6064, 295, 10649, 1487, 9303, 293, 1487, 439, 264, 7599, 51580], "temperature": 0.0, "avg_logprob": -0.14864729190694875, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.2580719590187073}, {"id": 266, "seek": 90716, "start": 931.48, "end": 933.48, "text": " that we have.", "tokens": [51580, 300, 321, 362, 13, 51680], "temperature": 0.0, "avg_logprob": -0.14864729190694875, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.2580719590187073}, {"id": 267, "seek": 93348, "start": 933.48, "end": 937.16, "text": " It's very intriguing why that happens and why the laws are such that that happens.", "tokens": [50364, 467, 311, 588, 32503, 983, 300, 2314, 293, 983, 264, 6064, 366, 1270, 300, 300, 2314, 13, 50548], "temperature": 0.0, "avg_logprob": -0.17295656272833296, "compression_ratio": 1.7886435331230284, "no_speech_prob": 0.44125381112098694}, {"id": 268, "seek": 93348, "start": 937.16, "end": 940.16, "text": " But even just the laws of physics are already a master algorithm.", "tokens": [50548, 583, 754, 445, 264, 6064, 295, 10649, 366, 1217, 257, 4505, 9284, 13, 50698], "temperature": 0.0, "avg_logprob": -0.17295656272833296, "compression_ratio": 1.7886435331230284, "no_speech_prob": 0.44125381112098694}, {"id": 269, "seek": 93348, "start": 940.16, "end": 944.6800000000001, "text": " Now what you could say, and many people immediately say is like, oh, but if you start from there,", "tokens": [50698, 823, 437, 291, 727, 584, 11, 293, 867, 561, 4258, 584, 307, 411, 11, 1954, 11, 457, 498, 291, 722, 490, 456, 11, 50924], "temperature": 0.0, "avg_logprob": -0.17295656272833296, "compression_ratio": 1.7886435331230284, "no_speech_prob": 0.44125381112098694}, {"id": 270, "seek": 93348, "start": 944.6800000000001, "end": 946.2, "text": " you'll never get anywhere, right?", "tokens": [50924, 291, 603, 1128, 483, 4992, 11, 558, 30, 51000], "temperature": 0.0, "avg_logprob": -0.17295656272833296, "compression_ratio": 1.7886435331230284, "no_speech_prob": 0.44125381112098694}, {"id": 271, "seek": 93348, "start": 946.2, "end": 952.28, "text": " But then you can say evolution is the laws of physics sped up in a certain direction.", "tokens": [51000, 583, 550, 291, 393, 584, 9303, 307, 264, 6064, 295, 10649, 637, 292, 493, 294, 257, 1629, 3513, 13, 51304], "temperature": 0.0, "avg_logprob": -0.17295656272833296, "compression_ratio": 1.7886435331230284, "no_speech_prob": 0.44125381112098694}, {"id": 272, "seek": 93348, "start": 952.28, "end": 955.12, "text": " And then our reinforcement learning is like evolution.", "tokens": [51304, 400, 550, 527, 29280, 2539, 307, 411, 9303, 13, 51446], "temperature": 0.0, "avg_logprob": -0.17295656272833296, "compression_ratio": 1.7886435331230284, "no_speech_prob": 0.44125381112098694}, {"id": 273, "seek": 93348, "start": 955.12, "end": 957.9200000000001, "text": " People have pointed out the same way except it's faster.", "tokens": [51446, 3432, 362, 10932, 484, 264, 912, 636, 3993, 309, 311, 4663, 13, 51586], "temperature": 0.0, "avg_logprob": -0.17295656272833296, "compression_ratio": 1.7886435331230284, "no_speech_prob": 0.44125381112098694}, {"id": 274, "seek": 93348, "start": 957.9200000000001, "end": 961.6800000000001, "text": " And in a way what we're trying to do now in machine learning is the same thing yet again", "tokens": [51586, 400, 294, 257, 636, 437, 321, 434, 1382, 281, 360, 586, 294, 3479, 2539, 307, 264, 912, 551, 1939, 797, 51774], "temperature": 0.0, "avg_logprob": -0.17295656272833296, "compression_ratio": 1.7886435331230284, "no_speech_prob": 0.44125381112098694}, {"id": 275, "seek": 96168, "start": 961.7199999999999, "end": 963.92, "text": " except only even faster.", "tokens": [50366, 3993, 787, 754, 4663, 13, 50476], "temperature": 0.0, "avg_logprob": -0.14934686404555592, "compression_ratio": 1.6366559485530547, "no_speech_prob": 0.04795807600021362}, {"id": 276, "seek": 96168, "start": 963.92, "end": 965.52, "text": " But what are the consequences of?", "tokens": [50476, 583, 437, 366, 264, 10098, 295, 30, 50556], "temperature": 0.0, "avg_logprob": -0.14934686404555592, "compression_ratio": 1.6366559485530547, "no_speech_prob": 0.04795807600021362}, {"id": 277, "seek": 96168, "start": 965.52, "end": 968.76, "text": " I mean, let's say it is actually a very high resolution algorithm.", "tokens": [50556, 286, 914, 11, 718, 311, 584, 309, 307, 767, 257, 588, 1090, 8669, 9284, 13, 50718], "temperature": 0.0, "avg_logprob": -0.14934686404555592, "compression_ratio": 1.6366559485530547, "no_speech_prob": 0.04795807600021362}, {"id": 278, "seek": 96168, "start": 968.76, "end": 973.5999999999999, "text": " So it's something that appears to be completely unintelligible to in respect of the output", "tokens": [50718, 407, 309, 311, 746, 300, 7038, 281, 312, 2584, 517, 27356, 281, 294, 3104, 295, 264, 5598, 50960], "temperature": 0.0, "avg_logprob": -0.14934686404555592, "compression_ratio": 1.6366559485530547, "no_speech_prob": 0.04795807600021362}, {"id": 279, "seek": 96168, "start": 973.5999999999999, "end": 974.4799999999999, "text": " phenomena.", "tokens": [50960, 22004, 13, 51004], "temperature": 0.0, "avg_logprob": -0.14934686404555592, "compression_ratio": 1.6366559485530547, "no_speech_prob": 0.04795807600021362}, {"id": 280, "seek": 96168, "start": 974.4799999999999, "end": 976.2399999999999, "text": " Is that is that even a good place to be?", "tokens": [51004, 1119, 300, 307, 300, 754, 257, 665, 1081, 281, 312, 30, 51092], "temperature": 0.0, "avg_logprob": -0.14934686404555592, "compression_ratio": 1.6366559485530547, "no_speech_prob": 0.04795807600021362}, {"id": 281, "seek": 96168, "start": 976.2399999999999, "end": 980.8, "text": " Because, you know, just like with cellular automata, there's no real paradigmatic", "tokens": [51092, 1436, 11, 291, 458, 11, 445, 411, 365, 29267, 3553, 3274, 11, 456, 311, 572, 957, 24709, 2399, 51320], "temperature": 0.0, "avg_logprob": -0.14934686404555592, "compression_ratio": 1.6366559485530547, "no_speech_prob": 0.04795807600021362}, {"id": 282, "seek": 96168, "start": 980.8, "end": 983.5999999999999, "text": " relationship between the underlying rules and the emergent phenomena, right?", "tokens": [51320, 2480, 1296, 264, 14217, 4474, 293, 264, 4345, 6930, 22004, 11, 558, 30, 51460], "temperature": 0.0, "avg_logprob": -0.14934686404555592, "compression_ratio": 1.6366559485530547, "no_speech_prob": 0.04795807600021362}, {"id": 283, "seek": 96168, "start": 983.5999999999999, "end": 986.4, "text": " So is that really even something we want?", "tokens": [51460, 407, 307, 300, 534, 754, 746, 321, 528, 30, 51600], "temperature": 0.0, "avg_logprob": -0.14934686404555592, "compression_ratio": 1.6366559485530547, "no_speech_prob": 0.04795807600021362}, {"id": 284, "seek": 96168, "start": 986.4, "end": 987.52, "text": " No, I think there is.", "tokens": [51600, 883, 11, 286, 519, 456, 307, 13, 51656], "temperature": 0.0, "avg_logprob": -0.14934686404555592, "compression_ratio": 1.6366559485530547, "no_speech_prob": 0.04795807600021362}, {"id": 285, "seek": 96168, "start": 987.52, "end": 989.5999999999999, "text": " So we don't know.", "tokens": [51656, 407, 321, 500, 380, 458, 13, 51760], "temperature": 0.0, "avg_logprob": -0.14934686404555592, "compression_ratio": 1.6366559485530547, "no_speech_prob": 0.04795807600021362}, {"id": 286, "seek": 98960, "start": 989.6, "end": 993.36, "text": " But I think people and this is very common among connections is to say this stuff is", "tokens": [50364, 583, 286, 519, 561, 293, 341, 307, 588, 2689, 3654, 9271, 307, 281, 584, 341, 1507, 307, 50552], "temperature": 0.0, "avg_logprob": -0.11164093017578125, "compression_ratio": 1.7455089820359282, "no_speech_prob": 0.017123080790042877}, {"id": 287, "seek": 98960, "start": 993.36, "end": 996.52, "text": " also complex that we can't possibly have a handle on it.", "tokens": [50552, 611, 3997, 300, 321, 393, 380, 6264, 362, 257, 4813, 322, 309, 13, 50710], "temperature": 0.0, "avg_logprob": -0.11164093017578125, "compression_ratio": 1.7455089820359282, "no_speech_prob": 0.017123080790042877}, {"id": 288, "seek": 98960, "start": 996.52, "end": 998.0, "text": " We just have to let it happen.", "tokens": [50710, 492, 445, 362, 281, 718, 309, 1051, 13, 50784], "temperature": 0.0, "avg_logprob": -0.11164093017578125, "compression_ratio": 1.7455089820359282, "no_speech_prob": 0.017123080790042877}, {"id": 289, "seek": 98960, "start": 998.0, "end": 1001.84, "text": " And I think that is not giving enough credit to our human brains, right?", "tokens": [50784, 400, 286, 519, 300, 307, 406, 2902, 1547, 5397, 281, 527, 1952, 15442, 11, 558, 30, 50976], "temperature": 0.0, "avg_logprob": -0.11164093017578125, "compression_ratio": 1.7455089820359282, "no_speech_prob": 0.017123080790042877}, {"id": 290, "seek": 98960, "start": 1001.84, "end": 1006.32, "text": " We are incredibly good at making sense of things that in the beginning, I mean, over", "tokens": [50976, 492, 366, 6252, 665, 412, 1455, 2020, 295, 721, 300, 294, 264, 2863, 11, 286, 914, 11, 670, 51200], "temperature": 0.0, "avg_logprob": -0.11164093017578125, "compression_ratio": 1.7455089820359282, "no_speech_prob": 0.017123080790042877}, {"id": 291, "seek": 98960, "start": 1006.32, "end": 1010.28, "text": " and over and over in the history of science and technology, you start out with things", "tokens": [51200, 293, 670, 293, 670, 294, 264, 2503, 295, 3497, 293, 2899, 11, 291, 722, 484, 365, 721, 51398], "temperature": 0.0, "avg_logprob": -0.11164093017578125, "compression_ratio": 1.7455089820359282, "no_speech_prob": 0.017123080790042877}, {"id": 292, "seek": 98960, "start": 1010.28, "end": 1012.6, "text": " that you don't understand very well at all.", "tokens": [51398, 300, 291, 500, 380, 1223, 588, 731, 412, 439, 13, 51514], "temperature": 0.0, "avg_logprob": -0.11164093017578125, "compression_ratio": 1.7455089820359282, "no_speech_prob": 0.017123080790042877}, {"id": 293, "seek": 98960, "start": 1012.6, "end": 1017.32, "text": " But then over time, we kind of change our representation of the world to make those", "tokens": [51514, 583, 550, 670, 565, 11, 321, 733, 295, 1319, 527, 10290, 295, 264, 1002, 281, 652, 729, 51750], "temperature": 0.0, "avg_logprob": -0.11164093017578125, "compression_ratio": 1.7455089820359282, "no_speech_prob": 0.017123080790042877}, {"id": 294, "seek": 98960, "start": 1017.32, "end": 1019.52, "text": " things actually be intelligible to us.", "tokens": [51750, 721, 767, 312, 5613, 964, 281, 505, 13, 51860], "temperature": 0.0, "avg_logprob": -0.11164093017578125, "compression_ratio": 1.7455089820359282, "no_speech_prob": 0.017123080790042877}, {"id": 295, "seek": 101952, "start": 1019.52, "end": 1023.48, "text": " And we should not a priori assume that that's not going to be the case here.", "tokens": [50364, 400, 321, 820, 406, 257, 4059, 72, 6552, 300, 300, 311, 406, 516, 281, 312, 264, 1389, 510, 13, 50562], "temperature": 0.0, "avg_logprob": -0.1619220449904765, "compression_ratio": 1.6458333333333333, "no_speech_prob": 0.005432036239653826}, {"id": 296, "seek": 101952, "start": 1023.48, "end": 1028.8, "text": " So, for example, cellular automata, amazing things come out of whatever the game of life", "tokens": [50562, 407, 11, 337, 1365, 11, 29267, 3553, 3274, 11, 2243, 721, 808, 484, 295, 2035, 264, 1216, 295, 993, 50828], "temperature": 0.0, "avg_logprob": -0.1619220449904765, "compression_ratio": 1.6458333333333333, "no_speech_prob": 0.005432036239653826}, {"id": 297, "seek": 101952, "start": 1028.8, "end": 1032.84, "text": " that seemed completely disconnected from those, but they aren't, right?", "tokens": [50828, 300, 6576, 2584, 29426, 490, 729, 11, 457, 436, 3212, 380, 11, 558, 30, 51030], "temperature": 0.0, "avg_logprob": -0.1619220449904765, "compression_ratio": 1.6458333333333333, "no_speech_prob": 0.005432036239653826}, {"id": 298, "seek": 101952, "start": 1032.84, "end": 1038.16, "text": " And, you know, there's various depths at which you could go into this.", "tokens": [51030, 400, 11, 291, 458, 11, 456, 311, 3683, 28439, 412, 597, 291, 727, 352, 666, 341, 13, 51296], "temperature": 0.0, "avg_logprob": -0.1619220449904765, "compression_ratio": 1.6458333333333333, "no_speech_prob": 0.005432036239653826}, {"id": 299, "seek": 101952, "start": 1038.16, "end": 1042.4, "text": " There will probably at the end of the day be some large element of this that we can't", "tokens": [51296, 821, 486, 1391, 412, 264, 917, 295, 264, 786, 312, 512, 2416, 4478, 295, 341, 300, 321, 393, 380, 51508], "temperature": 0.0, "avg_logprob": -0.1619220449904765, "compression_ratio": 1.6458333333333333, "no_speech_prob": 0.005432036239653826}, {"id": 300, "seek": 101952, "start": 1042.4, "end": 1046.8, "text": " figure out very well, but we can figure out enough that we have a handle on it.", "tokens": [51508, 2573, 484, 588, 731, 11, 457, 321, 393, 2573, 484, 1547, 300, 321, 362, 257, 4813, 322, 309, 13, 51728], "temperature": 0.0, "avg_logprob": -0.1619220449904765, "compression_ratio": 1.6458333333333333, "no_speech_prob": 0.005432036239653826}, {"id": 301, "seek": 104680, "start": 1046.8, "end": 1051.3999999999999, "text": " So, this singularity notion that at some point AI is just completely beyond our understanding.", "tokens": [50364, 407, 11, 341, 20010, 507, 10710, 300, 412, 512, 935, 7318, 307, 445, 2584, 4399, 527, 3701, 13, 50594], "temperature": 0.0, "avg_logprob": -0.2090786487072498, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.09187731891870499}, {"id": 302, "seek": 104680, "start": 1051.3999999999999, "end": 1053.04, "text": " I tend not to buy.", "tokens": [50594, 286, 3928, 406, 281, 2256, 13, 50676], "temperature": 0.0, "avg_logprob": -0.2090786487072498, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.09187731891870499}, {"id": 303, "seek": 104680, "start": 1053.04, "end": 1055.6, "text": " I don't think it will be completely beyond our understanding.", "tokens": [50676, 286, 500, 380, 519, 309, 486, 312, 2584, 4399, 527, 3701, 13, 50804], "temperature": 0.0, "avg_logprob": -0.2090786487072498, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.09187731891870499}, {"id": 304, "seek": 104680, "start": 1055.6, "end": 1060.32, "text": " But it's an analog back to our Twitter discussion, like, because we can only understand it through.", "tokens": [50804, 583, 309, 311, 364, 16660, 646, 281, 527, 5794, 5017, 11, 411, 11, 570, 321, 393, 787, 1223, 309, 807, 13, 51040], "temperature": 0.0, "avg_logprob": -0.2090786487072498, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.09187731891870499}, {"id": 305, "seek": 104680, "start": 1060.32, "end": 1063.48, "text": " It's like having views on a mountain range, you know, the view looks different depending", "tokens": [51040, 467, 311, 411, 1419, 6809, 322, 257, 6937, 3613, 11, 291, 458, 11, 264, 1910, 1542, 819, 5413, 51198], "temperature": 0.0, "avg_logprob": -0.2090786487072498, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.09187731891870499}, {"id": 306, "seek": 104680, "start": 1063.48, "end": 1065.08, "text": " on where you're standing.", "tokens": [51198, 322, 689, 291, 434, 4877, 13, 51278], "temperature": 0.0, "avg_logprob": -0.2090786487072498, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.09187731891870499}, {"id": 307, "seek": 104680, "start": 1065.08, "end": 1068.76, "text": " And it's the same thing with the emergent phenomena in a cellular automata.", "tokens": [51278, 400, 309, 311, 264, 912, 551, 365, 264, 4345, 6930, 22004, 294, 257, 29267, 3553, 3274, 13, 51462], "temperature": 0.0, "avg_logprob": -0.2090786487072498, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.09187731891870499}, {"id": 308, "seek": 104680, "start": 1068.76, "end": 1069.76, "text": " No, very good.", "tokens": [51462, 883, 11, 588, 665, 13, 51512], "temperature": 0.0, "avg_logprob": -0.2090786487072498, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.09187731891870499}, {"id": 309, "seek": 104680, "start": 1069.76, "end": 1074.3999999999999, "text": " And, you know, the classic example of this is the blind man and the elephant, right?", "tokens": [51512, 400, 11, 291, 458, 11, 264, 7230, 1365, 295, 341, 307, 264, 6865, 587, 293, 264, 19791, 11, 558, 30, 51744], "temperature": 0.0, "avg_logprob": -0.2090786487072498, "compression_ratio": 1.7469135802469136, "no_speech_prob": 0.09187731891870499}, {"id": 310, "seek": 107440, "start": 1074.4, "end": 1077.92, "text": " And that's actually the metaphor that is in the book, as I say, you know, the different", "tokens": [50364, 400, 300, 311, 767, 264, 19157, 300, 307, 294, 264, 1446, 11, 382, 286, 584, 11, 291, 458, 11, 264, 819, 50540], "temperature": 0.0, "avg_logprob": -0.1401483601537244, "compression_ratio": 1.9, "no_speech_prob": 0.04722684994339943}, {"id": 311, "seek": 107440, "start": 1077.92, "end": 1080.64, "text": " tribes are like different blind men, right?", "tokens": [50540, 19035, 366, 411, 819, 6865, 1706, 11, 558, 30, 50676], "temperature": 0.0, "avg_logprob": -0.1401483601537244, "compression_ratio": 1.9, "no_speech_prob": 0.04722684994339943}, {"id": 312, "seek": 107440, "start": 1080.64, "end": 1083.48, "text": " But precisely so, AI is one of the blind men.", "tokens": [50676, 583, 13402, 370, 11, 7318, 307, 472, 295, 264, 6865, 1706, 13, 50818], "temperature": 0.0, "avg_logprob": -0.1401483601537244, "compression_ratio": 1.9, "no_speech_prob": 0.04722684994339943}, {"id": 313, "seek": 107440, "start": 1083.48, "end": 1087.8000000000002, "text": " I can see part of the elephant, but it'd be who's meant to also talk to you who see another", "tokens": [50818, 286, 393, 536, 644, 295, 264, 19791, 11, 457, 309, 1116, 312, 567, 311, 4140, 281, 611, 751, 281, 291, 567, 536, 1071, 51034], "temperature": 0.0, "avg_logprob": -0.1401483601537244, "compression_ratio": 1.9, "no_speech_prob": 0.04722684994339943}, {"id": 314, "seek": 107440, "start": 1087.8000000000002, "end": 1088.8000000000002, "text": " part of the elephant.", "tokens": [51034, 644, 295, 264, 19791, 13, 51084], "temperature": 0.0, "avg_logprob": -0.1401483601537244, "compression_ratio": 1.9, "no_speech_prob": 0.04722684994339943}, {"id": 315, "seek": 107440, "start": 1088.8000000000002, "end": 1092.6000000000001, "text": " And then each of us understands a little bit more of the elephant than we would if we were", "tokens": [51084, 400, 550, 1184, 295, 505, 15146, 257, 707, 857, 544, 295, 264, 19791, 813, 321, 576, 498, 321, 645, 51274], "temperature": 0.0, "avg_logprob": -0.1401483601537244, "compression_ratio": 1.9, "no_speech_prob": 0.04722684994339943}, {"id": 316, "seek": 107440, "start": 1092.6000000000001, "end": 1093.6000000000001, "text": " on our own.", "tokens": [51274, 322, 527, 1065, 13, 51324], "temperature": 0.0, "avg_logprob": -0.1401483601537244, "compression_ratio": 1.9, "no_speech_prob": 0.04722684994339943}, {"id": 317, "seek": 107440, "start": 1093.6000000000001, "end": 1098.8000000000002, "text": " But most importantly, we collectively, which is what really matters, actually understand", "tokens": [51324, 583, 881, 8906, 11, 321, 24341, 11, 597, 307, 437, 534, 7001, 11, 767, 1223, 51584], "temperature": 0.0, "avg_logprob": -0.1401483601537244, "compression_ratio": 1.9, "no_speech_prob": 0.04722684994339943}, {"id": 318, "seek": 107440, "start": 1098.8000000000002, "end": 1103.8400000000001, "text": " maybe not the elephant completely, but much more of the elephant than either any of us", "tokens": [51584, 1310, 406, 264, 19791, 2584, 11, 457, 709, 544, 295, 264, 19791, 813, 2139, 604, 295, 505, 51836], "temperature": 0.0, "avg_logprob": -0.1401483601537244, "compression_ratio": 1.9, "no_speech_prob": 0.04722684994339943}, {"id": 319, "seek": 110384, "start": 1103.9599999999998, "end": 1105.56, "text": " would alone, right?", "tokens": [50370, 576, 3312, 11, 558, 30, 50450], "temperature": 0.0, "avg_logprob": -0.18839792824961657, "compression_ratio": 2.0226537216828477, "no_speech_prob": 0.1923321634531021}, {"id": 320, "seek": 110384, "start": 1105.56, "end": 1108.32, "text": " And it's certainly a lot better than just giving up and say, like, oh, we're never going to", "tokens": [50450, 400, 309, 311, 3297, 257, 688, 1101, 813, 445, 2902, 493, 293, 584, 11, 411, 11, 1954, 11, 321, 434, 1128, 516, 281, 50588], "temperature": 0.0, "avg_logprob": -0.18839792824961657, "compression_ratio": 2.0226537216828477, "no_speech_prob": 0.1923321634531021}, {"id": 321, "seek": 110384, "start": 1108.32, "end": 1110.56, "text": " understand this strange thing that's in front of us.", "tokens": [50588, 1223, 341, 5861, 551, 300, 311, 294, 1868, 295, 505, 13, 50700], "temperature": 0.0, "avg_logprob": -0.18839792824961657, "compression_ratio": 2.0226537216828477, "no_speech_prob": 0.1923321634531021}, {"id": 322, "seek": 110384, "start": 1110.56, "end": 1111.56, "text": " Interesting.", "tokens": [50700, 14711, 13, 50750], "temperature": 0.0, "avg_logprob": -0.18839792824961657, "compression_ratio": 2.0226537216828477, "no_speech_prob": 0.1923321634531021}, {"id": 323, "seek": 110384, "start": 1111.56, "end": 1113.08, "text": " But that's a great argument to what you were saying before.", "tokens": [50750, 583, 300, 311, 257, 869, 6770, 281, 437, 291, 645, 1566, 949, 13, 50826], "temperature": 0.0, "avg_logprob": -0.18839792824961657, "compression_ratio": 2.0226537216828477, "no_speech_prob": 0.1923321634531021}, {"id": 324, "seek": 110384, "start": 1113.08, "end": 1115.8799999999999, "text": " So it's beyond our cognitive horizon.", "tokens": [50826, 407, 309, 311, 4399, 527, 15605, 18046, 13, 50966], "temperature": 0.0, "avg_logprob": -0.18839792824961657, "compression_ratio": 2.0226537216828477, "no_speech_prob": 0.1923321634531021}, {"id": 325, "seek": 110384, "start": 1115.8799999999999, "end": 1118.6799999999998, "text": " Therefore we need to have diversity of aspect.", "tokens": [50966, 7504, 321, 643, 281, 362, 8811, 295, 4171, 13, 51106], "temperature": 0.0, "avg_logprob": -0.18839792824961657, "compression_ratio": 2.0226537216828477, "no_speech_prob": 0.1923321634531021}, {"id": 326, "seek": 110384, "start": 1118.6799999999998, "end": 1122.36, "text": " There's a, yes, there's a question of whether it's beyond the cognitive ability of a single", "tokens": [51106, 821, 311, 257, 11, 2086, 11, 456, 311, 257, 1168, 295, 1968, 309, 311, 4399, 264, 15605, 3485, 295, 257, 2167, 51290], "temperature": 0.0, "avg_logprob": -0.18839792824961657, "compression_ratio": 2.0226537216828477, "no_speech_prob": 0.1923321634531021}, {"id": 327, "seek": 110384, "start": 1122.36, "end": 1123.36, "text": " human.", "tokens": [51290, 1952, 13, 51340], "temperature": 0.0, "avg_logprob": -0.18839792824961657, "compression_ratio": 2.0226537216828477, "no_speech_prob": 0.1923321634531021}, {"id": 328, "seek": 110384, "start": 1123.36, "end": 1124.36, "text": " Yeah.", "tokens": [51340, 865, 13, 51390], "temperature": 0.0, "avg_logprob": -0.18839792824961657, "compression_ratio": 2.0226537216828477, "no_speech_prob": 0.1923321634531021}, {"id": 329, "seek": 110384, "start": 1124.36, "end": 1126.3999999999999, "text": " And then there's the question of whether it's beyond the cognitive ability of an entire", "tokens": [51390, 400, 550, 456, 311, 264, 1168, 295, 1968, 309, 311, 4399, 264, 15605, 3485, 295, 364, 2302, 51492], "temperature": 0.0, "avg_logprob": -0.18839792824961657, "compression_ratio": 2.0226537216828477, "no_speech_prob": 0.1923321634531021}, {"id": 330, "seek": 110384, "start": 1126.3999999999999, "end": 1127.9199999999998, "text": " society of humans.", "tokens": [51492, 4086, 295, 6255, 13, 51568], "temperature": 0.0, "avg_logprob": -0.18839792824961657, "compression_ratio": 2.0226537216828477, "no_speech_prob": 0.1923321634531021}, {"id": 331, "seek": 110384, "start": 1127.9199999999998, "end": 1131.84, "text": " And obviously, there'll be things that are beyond the cognitive ability of a single human,", "tokens": [51568, 400, 2745, 11, 456, 603, 312, 721, 300, 366, 4399, 264, 15605, 3485, 295, 257, 2167, 1952, 11, 51764], "temperature": 0.0, "avg_logprob": -0.18839792824961657, "compression_ratio": 2.0226537216828477, "no_speech_prob": 0.1923321634531021}, {"id": 332, "seek": 113184, "start": 1131.84, "end": 1133.9199999999998, "text": " but not beyond the cognitive ability of a society.", "tokens": [50364, 457, 406, 4399, 264, 15605, 3485, 295, 257, 4086, 13, 50468], "temperature": 0.0, "avg_logprob": -0.1624456903208857, "compression_ratio": 1.8327868852459017, "no_speech_prob": 0.13475432991981506}, {"id": 333, "seek": 113184, "start": 1133.9199999999998, "end": 1136.28, "text": " Also these days, we have computers.", "tokens": [50468, 2743, 613, 1708, 11, 321, 362, 10807, 13, 50586], "temperature": 0.0, "avg_logprob": -0.1624456903208857, "compression_ratio": 1.8327868852459017, "no_speech_prob": 0.13475432991981506}, {"id": 334, "seek": 113184, "start": 1136.28, "end": 1138.6799999999998, "text": " So our cognitive power is augmented by our machine.", "tokens": [50586, 407, 527, 15605, 1347, 307, 36155, 538, 527, 3479, 13, 50706], "temperature": 0.0, "avg_logprob": -0.1624456903208857, "compression_ratio": 1.8327868852459017, "no_speech_prob": 0.13475432991981506}, {"id": 335, "seek": 113184, "start": 1138.6799999999998, "end": 1143.32, "text": " So we can understand things or bring things to the point where we understand them to a", "tokens": [50706, 407, 321, 393, 1223, 721, 420, 1565, 721, 281, 264, 935, 689, 321, 1223, 552, 281, 257, 50938], "temperature": 0.0, "avg_logprob": -0.1624456903208857, "compression_ratio": 1.8327868852459017, "no_speech_prob": 0.13475432991981506}, {"id": 336, "seek": 113184, "start": 1143.32, "end": 1145.6399999999999, "text": " degree today that we couldn't a hundred years ago.", "tokens": [50938, 4314, 965, 300, 321, 2809, 380, 257, 3262, 924, 2057, 13, 51054], "temperature": 0.0, "avg_logprob": -0.1624456903208857, "compression_ratio": 1.8327868852459017, "no_speech_prob": 0.13475432991981506}, {"id": 337, "seek": 113184, "start": 1145.6399999999999, "end": 1147.1999999999998, "text": " Right now, that is a fascinating point.", "tokens": [51054, 1779, 586, 11, 300, 307, 257, 10343, 935, 13, 51132], "temperature": 0.0, "avg_logprob": -0.1624456903208857, "compression_ratio": 1.8327868852459017, "no_speech_prob": 0.13475432991981506}, {"id": 338, "seek": 113184, "start": 1147.1999999999998, "end": 1153.08, "text": " So it's beyond our cognitive horizon individually, but it might not be beyond the cognitive horizon", "tokens": [51132, 407, 309, 311, 4399, 527, 15605, 18046, 16652, 11, 457, 309, 1062, 406, 312, 4399, 264, 15605, 18046, 51426], "temperature": 0.0, "avg_logprob": -0.1624456903208857, "compression_ratio": 1.8327868852459017, "no_speech_prob": 0.13475432991981506}, {"id": 339, "seek": 113184, "start": 1153.08, "end": 1157.08, "text": " of loads and loads of humans on the internet, you know, the wisdom of crowds.", "tokens": [51426, 295, 12668, 293, 12668, 295, 6255, 322, 264, 4705, 11, 291, 458, 11, 264, 10712, 295, 26070, 13, 51626], "temperature": 0.0, "avg_logprob": -0.1624456903208857, "compression_ratio": 1.8327868852459017, "no_speech_prob": 0.13475432991981506}, {"id": 340, "seek": 113184, "start": 1157.08, "end": 1161.1599999999999, "text": " But we don't, I mean, how do we know that the crowd understands?", "tokens": [51626, 583, 321, 500, 380, 11, 286, 914, 11, 577, 360, 321, 458, 300, 264, 6919, 15146, 30, 51830], "temperature": 0.0, "avg_logprob": -0.1624456903208857, "compression_ratio": 1.8327868852459017, "no_speech_prob": 0.13475432991981506}, {"id": 341, "seek": 116116, "start": 1161.16, "end": 1166.3200000000002, "text": " But we know, well, that's the, in some sense, the beauty of this, right, is that we never,", "tokens": [50364, 583, 321, 458, 11, 731, 11, 300, 311, 264, 11, 294, 512, 2020, 11, 264, 6643, 295, 341, 11, 558, 11, 307, 300, 321, 1128, 11, 50622], "temperature": 0.0, "avg_logprob": -0.18855709499782985, "compression_ratio": 1.8161290322580645, "no_speech_prob": 0.11828179657459259}, {"id": 342, "seek": 116116, "start": 1166.3200000000002, "end": 1168.0400000000002, "text": " what is the crowd really understanding, right?", "tokens": [50622, 437, 307, 264, 6919, 534, 3701, 11, 558, 30, 50708], "temperature": 0.0, "avg_logprob": -0.18855709499782985, "compression_ratio": 1.8161290322580645, "no_speech_prob": 0.11828179657459259}, {"id": 343, "seek": 116116, "start": 1168.0400000000002, "end": 1171.92, "text": " And again, once the crowd is augmented by machines, like machine learning algorithms,", "tokens": [50708, 400, 797, 11, 1564, 264, 6919, 307, 36155, 538, 8379, 11, 411, 3479, 2539, 14642, 11, 50902], "temperature": 0.0, "avg_logprob": -0.18855709499782985, "compression_ratio": 1.8161290322580645, "no_speech_prob": 0.11828179657459259}, {"id": 344, "seek": 116116, "start": 1171.92, "end": 1176.8000000000002, "text": " right, we can ask what do we as a society equipped with all of our, you know, large", "tokens": [50902, 558, 11, 321, 393, 1029, 437, 360, 321, 382, 257, 4086, 15218, 365, 439, 295, 527, 11, 291, 458, 11, 2416, 51146], "temperature": 0.0, "avg_logprob": -0.18855709499782985, "compression_ratio": 1.8161290322580645, "no_speech_prob": 0.11828179657459259}, {"id": 345, "seek": 116116, "start": 1176.8000000000002, "end": 1180.1200000000001, "text": " language models and so on and so forth, what do we really understand, right?", "tokens": [51146, 2856, 5245, 293, 370, 322, 293, 370, 5220, 11, 437, 360, 321, 534, 1223, 11, 558, 30, 51312], "temperature": 0.0, "avg_logprob": -0.18855709499782985, "compression_ratio": 1.8161290322580645, "no_speech_prob": 0.11828179657459259}, {"id": 346, "seek": 116116, "start": 1180.1200000000001, "end": 1184.48, "text": " Now, at some level, you can't answer that question individually because you are just", "tokens": [51312, 823, 11, 412, 512, 1496, 11, 291, 393, 380, 1867, 300, 1168, 16652, 570, 291, 366, 445, 51530], "temperature": 0.0, "avg_logprob": -0.18855709499782985, "compression_ratio": 1.8161290322580645, "no_speech_prob": 0.11828179657459259}, {"id": 347, "seek": 116116, "start": 1184.48, "end": 1188.1200000000001, "text": " an individual, but right, there's a couple of very important things that we shouldn't", "tokens": [51530, 364, 2609, 11, 457, 558, 11, 456, 311, 257, 1916, 295, 588, 1021, 721, 300, 321, 4659, 380, 51712], "temperature": 0.0, "avg_logprob": -0.18855709499782985, "compression_ratio": 1.8161290322580645, "no_speech_prob": 0.11828179657459259}, {"id": 348, "seek": 116116, "start": 1188.1200000000001, "end": 1189.1200000000001, "text": " forget.", "tokens": [51712, 2870, 13, 51762], "temperature": 0.0, "avg_logprob": -0.18855709499782985, "compression_ratio": 1.8161290322580645, "no_speech_prob": 0.11828179657459259}, {"id": 349, "seek": 118912, "start": 1189.2399999999998, "end": 1194.08, "text": " You could, one thing you can do and that I do do is say, like, do I now actually even", "tokens": [50370, 509, 727, 11, 472, 551, 291, 393, 360, 293, 300, 286, 360, 360, 307, 584, 11, 411, 11, 360, 286, 586, 767, 754, 50612], "temperature": 0.0, "avg_logprob": -0.1873013652972321, "compression_ratio": 1.710344827586207, "no_speech_prob": 0.021511774510145187}, {"id": 350, "seek": 118912, "start": 1194.08, "end": 1199.32, "text": " just individually understand things better than I did before when it was just me looking", "tokens": [50612, 445, 16652, 1223, 721, 1101, 813, 286, 630, 949, 562, 309, 390, 445, 385, 1237, 50874], "temperature": 0.0, "avg_logprob": -0.1873013652972321, "compression_ratio": 1.710344827586207, "no_speech_prob": 0.021511774510145187}, {"id": 351, "seek": 118912, "start": 1199.32, "end": 1200.32, "text": " at it?", "tokens": [50874, 412, 309, 30, 50924], "temperature": 0.0, "avg_logprob": -0.1873013652972321, "compression_ratio": 1.710344827586207, "no_speech_prob": 0.021511774510145187}, {"id": 352, "seek": 118912, "start": 1200.32, "end": 1202.76, "text": " And the answer to that is almost invariably yes, right?", "tokens": [50924, 400, 264, 1867, 281, 300, 307, 1920, 33270, 1188, 2086, 11, 558, 30, 51046], "temperature": 0.0, "avg_logprob": -0.1873013652972321, "compression_ratio": 1.710344827586207, "no_speech_prob": 0.021511774510145187}, {"id": 353, "seek": 118912, "start": 1202.76, "end": 1205.0, "text": " So there is a big game to be heard there.", "tokens": [51046, 407, 456, 307, 257, 955, 1216, 281, 312, 2198, 456, 13, 51158], "temperature": 0.0, "avg_logprob": -0.1873013652972321, "compression_ratio": 1.710344827586207, "no_speech_prob": 0.021511774510145187}, {"id": 354, "seek": 118912, "start": 1205.0, "end": 1211.4399999999998, "text": " And the second one is that you, ultimately, you tell by the consequences, right?", "tokens": [51158, 400, 264, 1150, 472, 307, 300, 291, 11, 6284, 11, 291, 980, 538, 264, 10098, 11, 558, 30, 51480], "temperature": 0.0, "avg_logprob": -0.1873013652972321, "compression_ratio": 1.710344827586207, "no_speech_prob": 0.021511774510145187}, {"id": 355, "seek": 118912, "start": 1211.4399999999998, "end": 1214.12, "text": " And like, for example, take a deep network, right?", "tokens": [51480, 400, 411, 11, 337, 1365, 11, 747, 257, 2452, 3209, 11, 558, 30, 51614], "temperature": 0.0, "avg_logprob": -0.1873013652972321, "compression_ratio": 1.710344827586207, "no_speech_prob": 0.021511774510145187}, {"id": 356, "seek": 118912, "start": 1214.12, "end": 1217.9199999999998, "text": " And you may not know how it works, but if it's doing medical diagnosis, you can tell", "tokens": [51614, 400, 291, 815, 406, 458, 577, 309, 1985, 11, 457, 498, 309, 311, 884, 4625, 15217, 11, 291, 393, 980, 51804], "temperature": 0.0, "avg_logprob": -0.1873013652972321, "compression_ratio": 1.710344827586207, "no_speech_prob": 0.021511774510145187}, {"id": 357, "seek": 121792, "start": 1217.92, "end": 1222.52, "text": " whether it, you know, gets the diagnosis right more often than it did before or more", "tokens": [50364, 1968, 309, 11, 291, 458, 11, 2170, 264, 15217, 558, 544, 2049, 813, 309, 630, 949, 420, 544, 50594], "temperature": 0.0, "avg_logprob": -0.14394707773246018, "compression_ratio": 1.8164556962025316, "no_speech_prob": 0.004434596281498671}, {"id": 358, "seek": 121792, "start": 1222.52, "end": 1223.52, "text": " often than another model.", "tokens": [50594, 2049, 813, 1071, 2316, 13, 50644], "temperature": 0.0, "avg_logprob": -0.14394707773246018, "compression_ratio": 1.8164556962025316, "no_speech_prob": 0.004434596281498671}, {"id": 359, "seek": 121792, "start": 1223.52, "end": 1228.92, "text": " So we as a society may not, you know, we individuals may not very understand very well what we", "tokens": [50644, 407, 321, 382, 257, 4086, 815, 406, 11, 291, 458, 11, 321, 5346, 815, 406, 588, 1223, 588, 731, 437, 321, 50914], "temperature": 0.0, "avg_logprob": -0.14394707773246018, "compression_ratio": 1.8164556962025316, "no_speech_prob": 0.004434596281498671}, {"id": 360, "seek": 121792, "start": 1228.92, "end": 1232.88, "text": " as a society understand, but we can see the consequences and at some level, that's the", "tokens": [50914, 382, 257, 4086, 1223, 11, 457, 321, 393, 536, 264, 10098, 293, 412, 512, 1496, 11, 300, 311, 264, 51112], "temperature": 0.0, "avg_logprob": -0.14394707773246018, "compression_ratio": 1.8164556962025316, "no_speech_prob": 0.004434596281498671}, {"id": 361, "seek": 121792, "start": 1232.88, "end": 1233.88, "text": " point.", "tokens": [51112, 935, 13, 51162], "temperature": 0.0, "avg_logprob": -0.14394707773246018, "compression_ratio": 1.8164556962025316, "no_speech_prob": 0.004434596281498671}, {"id": 362, "seek": 121792, "start": 1233.88, "end": 1234.88, "text": " Yeah.", "tokens": [51162, 865, 13, 51212], "temperature": 0.0, "avg_logprob": -0.14394707773246018, "compression_ratio": 1.8164556962025316, "no_speech_prob": 0.004434596281498671}, {"id": 363, "seek": 121792, "start": 1234.88, "end": 1237.76, "text": " So on that, I mean, that sounds like a bit of an appeal to behaviorism and we're going", "tokens": [51212, 407, 322, 300, 11, 286, 914, 11, 300, 3263, 411, 257, 857, 295, 364, 13668, 281, 5223, 1434, 293, 321, 434, 516, 51356], "temperature": 0.0, "avg_logprob": -0.14394707773246018, "compression_ratio": 1.8164556962025316, "no_speech_prob": 0.004434596281498671}, {"id": 364, "seek": 121792, "start": 1237.76, "end": 1239.76, "text": " to talk about that in respect of charmers as well.", "tokens": [51356, 281, 751, 466, 300, 294, 3104, 295, 1290, 18552, 382, 731, 13, 51456], "temperature": 0.0, "avg_logprob": -0.14394707773246018, "compression_ratio": 1.8164556962025316, "no_speech_prob": 0.004434596281498671}, {"id": 365, "seek": 121792, "start": 1239.76, "end": 1243.8400000000001, "text": " But it also brings us back to, you know, we were talking about empiricism versus rationalism", "tokens": [51456, 583, 309, 611, 5607, 505, 646, 281, 11, 291, 458, 11, 321, 645, 1417, 466, 25790, 26356, 5717, 15090, 1434, 51660], "temperature": 0.0, "avg_logprob": -0.14394707773246018, "compression_ratio": 1.8164556962025316, "no_speech_prob": 0.004434596281498671}, {"id": 366, "seek": 121792, "start": 1243.8400000000001, "end": 1246.6000000000001, "text": " and nativism and all of these topics.", "tokens": [51660, 293, 2249, 592, 1434, 293, 439, 295, 613, 8378, 13, 51798], "temperature": 0.0, "avg_logprob": -0.14394707773246018, "compression_ratio": 1.8164556962025316, "no_speech_prob": 0.004434596281498671}, {"id": 367, "seek": 124660, "start": 1246.6, "end": 1251.1999999999998, "text": " Would you place yourself in that camp of being a nativist and a rationalist or completely", "tokens": [50364, 6068, 291, 1081, 1803, 294, 300, 2255, 295, 885, 257, 2249, 592, 468, 293, 257, 15090, 468, 420, 2584, 50594], "temperature": 0.0, "avg_logprob": -0.14368975863737218, "compression_ratio": 1.7655172413793103, "no_speech_prob": 0.10754619538784027}, {"id": 368, "seek": 124660, "start": 1251.1999999999998, "end": 1252.1999999999998, "text": " the other way?", "tokens": [50594, 264, 661, 636, 30, 50644], "temperature": 0.0, "avg_logprob": -0.14368975863737218, "compression_ratio": 1.7655172413793103, "no_speech_prob": 0.10754619538784027}, {"id": 369, "seek": 124660, "start": 1252.1999999999998, "end": 1253.4399999999998, "text": " No, absolutely not.", "tokens": [50644, 883, 11, 3122, 406, 13, 50706], "temperature": 0.0, "avg_logprob": -0.14368975863737218, "compression_ratio": 1.7655172413793103, "no_speech_prob": 0.10754619538784027}, {"id": 370, "seek": 124660, "start": 1253.4399999999998, "end": 1259.04, "text": " Again, this is one of the points that I, you know, go back to is there are the empiricists", "tokens": [50706, 3764, 11, 341, 307, 472, 295, 264, 2793, 300, 286, 11, 291, 458, 11, 352, 646, 281, 307, 456, 366, 264, 25790, 299, 1751, 50986], "temperature": 0.0, "avg_logprob": -0.14368975863737218, "compression_ratio": 1.7655172413793103, "no_speech_prob": 0.10754619538784027}, {"id": 371, "seek": 124660, "start": 1259.04, "end": 1263.6399999999999, "text": " and there are the rationalists and you could see naively machine learning as being the", "tokens": [50986, 293, 456, 366, 264, 15090, 1751, 293, 291, 727, 536, 1667, 3413, 3479, 2539, 382, 885, 264, 51216], "temperature": 0.0, "avg_logprob": -0.14368975863737218, "compression_ratio": 1.7655172413793103, "no_speech_prob": 0.10754619538784027}, {"id": 372, "seek": 124660, "start": 1263.6399999999999, "end": 1268.0, "text": " triumph of the empiricists, but it actually is not there are very fundamental reasons", "tokens": [51216, 29156, 295, 264, 25790, 299, 1751, 11, 457, 309, 767, 307, 406, 456, 366, 588, 8088, 4112, 51434], "temperature": 0.0, "avg_logprob": -0.14368975863737218, "compression_ratio": 1.7655172413793103, "no_speech_prob": 0.10754619538784027}, {"id": 373, "seek": 124660, "start": 1268.0, "end": 1269.0, "text": " why it's not.", "tokens": [51434, 983, 309, 311, 406, 13, 51484], "temperature": 0.0, "avg_logprob": -0.14368975863737218, "compression_ratio": 1.7655172413793103, "no_speech_prob": 0.10754619538784027}, {"id": 374, "seek": 124660, "start": 1269.0, "end": 1272.7199999999998, "text": " And I really do think, and this is not just think there's this thing called the no free", "tokens": [51484, 400, 286, 534, 360, 519, 11, 293, 341, 307, 406, 445, 519, 456, 311, 341, 551, 1219, 264, 572, 1737, 51670], "temperature": 0.0, "avg_logprob": -0.14368975863737218, "compression_ratio": 1.7655172413793103, "no_speech_prob": 0.10754619538784027}, {"id": 375, "seek": 124660, "start": 1272.7199999999998, "end": 1274.56, "text": " lunch theorem, right?", "tokens": [51670, 6349, 20904, 11, 558, 30, 51762], "temperature": 0.0, "avg_logprob": -0.14368975863737218, "compression_ratio": 1.7655172413793103, "no_speech_prob": 0.10754619538784027}, {"id": 376, "seek": 127456, "start": 1274.56, "end": 1278.84, "text": " And if you take those things seriously, the solution has to be a combination of empiricism", "tokens": [50364, 400, 498, 291, 747, 729, 721, 6638, 11, 264, 3827, 575, 281, 312, 257, 6562, 295, 25790, 26356, 50578], "temperature": 0.0, "avg_logprob": -0.1393105453915066, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.01202781219035387}, {"id": 377, "seek": 127456, "start": 1278.84, "end": 1279.84, "text": " and rationalism.", "tokens": [50578, 293, 15090, 1434, 13, 50628], "temperature": 0.0, "avg_logprob": -0.1393105453915066, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.01202781219035387}, {"id": 378, "seek": 127456, "start": 1279.84, "end": 1283.84, "text": " I don't think either side alone has or even can have the whole answer.", "tokens": [50628, 286, 500, 380, 519, 2139, 1252, 3312, 575, 420, 754, 393, 362, 264, 1379, 1867, 13, 50828], "temperature": 0.0, "avg_logprob": -0.1393105453915066, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.01202781219035387}, {"id": 379, "seek": 127456, "start": 1283.84, "end": 1286.2, "text": " So very much we need both of those.", "tokens": [50828, 407, 588, 709, 321, 643, 1293, 295, 729, 13, 50946], "temperature": 0.0, "avg_logprob": -0.1393105453915066, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.01202781219035387}, {"id": 380, "seek": 127456, "start": 1286.2, "end": 1291.1599999999999, "text": " And if you're a pure empiricist or a pure rationalist, I'm already suspicious of you.", "tokens": [50946, 400, 498, 291, 434, 257, 6075, 25790, 299, 468, 420, 257, 6075, 15090, 468, 11, 286, 478, 1217, 17931, 295, 291, 13, 51194], "temperature": 0.0, "avg_logprob": -0.1393105453915066, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.01202781219035387}, {"id": 381, "seek": 127456, "start": 1291.1599999999999, "end": 1292.1599999999999, "text": " Wonderful.", "tokens": [51194, 22768, 13, 51244], "temperature": 0.0, "avg_logprob": -0.1393105453915066, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.01202781219035387}, {"id": 382, "seek": 127456, "start": 1292.1599999999999, "end": 1296.6399999999999, "text": " Coming back to what Franz Walsh said in his quote, he said, you know, producing things", "tokens": [51244, 12473, 646, 281, 437, 33084, 343, 1124, 71, 848, 294, 702, 6513, 11, 415, 848, 11, 291, 458, 11, 10501, 721, 51468], "temperature": 0.0, "avg_logprob": -0.1393105453915066, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.01202781219035387}, {"id": 383, "seek": 127456, "start": 1296.6399999999999, "end": 1299.36, "text": " that are thought provoking novel and all the rest of it.", "tokens": [51468, 300, 366, 1194, 1439, 5953, 7613, 293, 439, 264, 1472, 295, 309, 13, 51604], "temperature": 0.0, "avg_logprob": -0.1393105453915066, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.01202781219035387}, {"id": 384, "seek": 127456, "start": 1299.36, "end": 1302.36, "text": " And I was speaking to some alignment folks yesterday and we'll pivot to that in a minute.", "tokens": [51604, 400, 286, 390, 4124, 281, 512, 18515, 4024, 5186, 293, 321, 603, 14538, 281, 300, 294, 257, 3456, 13, 51754], "temperature": 0.0, "avg_logprob": -0.1393105453915066, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.01202781219035387}, {"id": 385, "seek": 130236, "start": 1302.9599999999998, "end": 1307.1599999999999, "text": " The big thing for me after doing an episode on sales, the Chinese room is, you know, where", "tokens": [50394, 440, 955, 551, 337, 385, 934, 884, 364, 3500, 322, 5763, 11, 264, 4649, 1808, 307, 11, 291, 458, 11, 689, 50604], "temperature": 0.0, "avg_logprob": -0.15744217582370923, "compression_ratio": 1.6904024767801857, "no_speech_prob": 0.12451775372028351}, {"id": 386, "seek": 130236, "start": 1307.1599999999999, "end": 1311.6399999999999, "text": " does intentionality come from and Chomsky talks about agency, for example, we do things", "tokens": [50604, 775, 7789, 1860, 808, 490, 293, 761, 4785, 4133, 6686, 466, 7934, 11, 337, 1365, 11, 321, 360, 721, 50828], "temperature": 0.0, "avg_logprob": -0.15744217582370923, "compression_ratio": 1.6904024767801857, "no_speech_prob": 0.12451775372028351}, {"id": 387, "seek": 130236, "start": 1311.6399999999999, "end": 1314.1999999999998, "text": " that are appropriate to the situation, but not caused by them.", "tokens": [50828, 300, 366, 6854, 281, 264, 2590, 11, 457, 406, 7008, 538, 552, 13, 50956], "temperature": 0.0, "avg_logprob": -0.15744217582370923, "compression_ratio": 1.6904024767801857, "no_speech_prob": 0.12451775372028351}, {"id": 388, "seek": 130236, "start": 1314.1999999999998, "end": 1317.28, "text": " So from my perspective, all these generative models, all these large language models and", "tokens": [50956, 407, 490, 452, 4585, 11, 439, 613, 1337, 1166, 5245, 11, 439, 613, 2416, 2856, 5245, 293, 51110], "temperature": 0.0, "avg_logprob": -0.15744217582370923, "compression_ratio": 1.6904024767801857, "no_speech_prob": 0.12451775372028351}, {"id": 389, "seek": 130236, "start": 1317.28, "end": 1321.12, "text": " so on, the creativity, the real spark of genius still comes from us, right?", "tokens": [51110, 370, 322, 11, 264, 12915, 11, 264, 957, 9908, 295, 14017, 920, 1487, 490, 505, 11, 558, 30, 51302], "temperature": 0.0, "avg_logprob": -0.15744217582370923, "compression_ratio": 1.6904024767801857, "no_speech_prob": 0.12451775372028351}, {"id": 390, "seek": 130236, "start": 1321.12, "end": 1326.6799999999998, "text": " We've just kind of like, you know, the boring bit of actually doing the task is now delegated", "tokens": [51302, 492, 600, 445, 733, 295, 411, 11, 291, 458, 11, 264, 9989, 857, 295, 767, 884, 264, 5633, 307, 586, 15824, 770, 51580], "temperature": 0.0, "avg_logprob": -0.15744217582370923, "compression_ratio": 1.6904024767801857, "no_speech_prob": 0.12451775372028351}, {"id": 391, "seek": 130236, "start": 1326.6799999999998, "end": 1328.24, "text": " to the algorithm.", "tokens": [51580, 281, 264, 9284, 13, 51658], "temperature": 0.0, "avg_logprob": -0.15744217582370923, "compression_ratio": 1.6904024767801857, "no_speech_prob": 0.12451775372028351}, {"id": 392, "seek": 130236, "start": 1328.24, "end": 1329.6, "text": " I would disagree with that.", "tokens": [51658, 286, 576, 14091, 365, 300, 13, 51726], "temperature": 0.0, "avg_logprob": -0.15744217582370923, "compression_ratio": 1.6904024767801857, "no_speech_prob": 0.12451775372028351}, {"id": 393, "seek": 132960, "start": 1329.6, "end": 1334.36, "text": " I think you are, I mean, your position is very reasonable and actually, I would say", "tokens": [50364, 286, 519, 291, 366, 11, 286, 914, 11, 428, 2535, 307, 588, 10585, 293, 767, 11, 286, 576, 584, 50602], "temperature": 0.0, "avg_logprob": -0.17053984057518742, "compression_ratio": 1.6284722222222223, "no_speech_prob": 0.01908162422478199}, {"id": 394, "seek": 132960, "start": 1334.36, "end": 1339.8799999999999, "text": " probably the most common, but I think when you do that, you are giving us too much credit", "tokens": [50602, 1391, 264, 881, 2689, 11, 457, 286, 519, 562, 291, 360, 300, 11, 291, 366, 2902, 505, 886, 709, 5397, 50878], "temperature": 0.0, "avg_logprob": -0.17053984057518742, "compression_ratio": 1.6284722222222223, "no_speech_prob": 0.01908162422478199}, {"id": 395, "seek": 132960, "start": 1339.8799999999999, "end": 1342.9199999999998, "text": " and the large language models too little.", "tokens": [50878, 293, 264, 2416, 2856, 5245, 886, 707, 13, 51030], "temperature": 0.0, "avg_logprob": -0.17053984057518742, "compression_ratio": 1.6284722222222223, "no_speech_prob": 0.01908162422478199}, {"id": 396, "seek": 132960, "start": 1342.9199999999998, "end": 1347.84, "text": " We tend to have this notion that creativity is something magical.", "tokens": [51030, 492, 3928, 281, 362, 341, 10710, 300, 12915, 307, 746, 12066, 13, 51276], "temperature": 0.0, "avg_logprob": -0.17053984057518742, "compression_ratio": 1.6284722222222223, "no_speech_prob": 0.01908162422478199}, {"id": 397, "seek": 132960, "start": 1347.84, "end": 1352.24, "text": " In fact, I remember for many years, so quick parenthesis, in the previous life I was a", "tokens": [51276, 682, 1186, 11, 286, 1604, 337, 867, 924, 11, 370, 1702, 23350, 9374, 11, 294, 264, 3894, 993, 286, 390, 257, 51496], "temperature": 0.0, "avg_logprob": -0.17053984057518742, "compression_ratio": 1.6284722222222223, "no_speech_prob": 0.01908162422478199}, {"id": 398, "seek": 132960, "start": 1352.24, "end": 1353.24, "text": " musician.", "tokens": [51496, 19570, 13, 51546], "temperature": 0.0, "avg_logprob": -0.17053984057518742, "compression_ratio": 1.6284722222222223, "no_speech_prob": 0.01908162422478199}, {"id": 399, "seek": 132960, "start": 1353.24, "end": 1357.84, "text": " So, you know, I, in some sense know about, and a lot of my job was composing songs, right?", "tokens": [51546, 407, 11, 291, 458, 11, 286, 11, 294, 512, 2020, 458, 466, 11, 293, 257, 688, 295, 452, 1691, 390, 715, 6110, 5781, 11, 558, 30, 51776], "temperature": 0.0, "avg_logprob": -0.17053984057518742, "compression_ratio": 1.6284722222222223, "no_speech_prob": 0.01908162422478199}, {"id": 400, "seek": 135784, "start": 1357.84, "end": 1361.8799999999999, "text": " And I was always, at the same time I was already studying AI and I couldn't help but connect", "tokens": [50364, 400, 286, 390, 1009, 11, 412, 264, 912, 565, 286, 390, 1217, 7601, 7318, 293, 286, 2809, 380, 854, 457, 1745, 50566], "temperature": 0.0, "avg_logprob": -0.17915938718475566, "compression_ratio": 1.7849829351535835, "no_speech_prob": 0.052355583757162094}, {"id": 401, "seek": 135784, "start": 1361.8799999999999, "end": 1362.8799999999999, "text": " it too, right?", "tokens": [50566, 309, 886, 11, 558, 30, 50616], "temperature": 0.0, "avg_logprob": -0.17915938718475566, "compression_ratio": 1.7849829351535835, "no_speech_prob": 0.052355583757162094}, {"id": 402, "seek": 135784, "start": 1362.8799999999999, "end": 1368.56, "text": " And think about like, what would an AI look that was able to compose music, right?", "tokens": [50616, 400, 519, 466, 411, 11, 437, 576, 364, 7318, 574, 300, 390, 1075, 281, 35925, 1318, 11, 558, 30, 50900], "temperature": 0.0, "avg_logprob": -0.17915938718475566, "compression_ratio": 1.7849829351535835, "no_speech_prob": 0.052355583757162094}, {"id": 403, "seek": 135784, "start": 1368.56, "end": 1373.48, "text": " And talking to late people who are not musicians, they think that composing songs is some kind", "tokens": [50900, 400, 1417, 281, 3469, 561, 567, 366, 406, 16916, 11, 436, 519, 300, 715, 6110, 5781, 307, 512, 733, 51146], "temperature": 0.0, "avg_logprob": -0.17915938718475566, "compression_ratio": 1.7849829351535835, "no_speech_prob": 0.052355583757162094}, {"id": 404, "seek": 135784, "start": 1373.48, "end": 1378.6, "text": " of magic thing that comes from, you know, whatever the great beyond, and it's not.", "tokens": [51146, 295, 5585, 551, 300, 1487, 490, 11, 291, 458, 11, 2035, 264, 869, 4399, 11, 293, 309, 311, 406, 13, 51402], "temperature": 0.0, "avg_logprob": -0.17915938718475566, "compression_ratio": 1.7849829351535835, "no_speech_prob": 0.052355583757162094}, {"id": 405, "seek": 135784, "start": 1378.6, "end": 1382.28, "text": " It's a very human enterprise and it can very well be automated.", "tokens": [51402, 467, 311, 257, 588, 1952, 14132, 293, 309, 393, 588, 731, 312, 18473, 13, 51586], "temperature": 0.0, "avg_logprob": -0.17915938718475566, "compression_ratio": 1.7849829351535835, "no_speech_prob": 0.052355583757162094}, {"id": 406, "seek": 135784, "start": 1382.28, "end": 1386.6, "text": " It's actually now, you know, people, I used to say to people like, people always say like,", "tokens": [51586, 467, 311, 767, 586, 11, 291, 458, 11, 561, 11, 286, 1143, 281, 584, 281, 561, 411, 11, 561, 1009, 584, 411, 11, 51802], "temperature": 0.0, "avg_logprob": -0.17915938718475566, "compression_ratio": 1.7849829351535835, "no_speech_prob": 0.052355583757162094}, {"id": 407, "seek": 138660, "start": 1386.6, "end": 1390.12, "text": " well, creativity will be the last thing that we automate because we humans can do it and", "tokens": [50364, 731, 11, 12915, 486, 312, 264, 1036, 551, 300, 321, 31605, 570, 321, 6255, 393, 360, 309, 293, 50540], "temperature": 0.0, "avg_logprob": -0.18382528383437902, "compression_ratio": 1.7821782178217822, "no_speech_prob": 0.1334572583436966}, {"id": 408, "seek": 138660, "start": 1390.12, "end": 1392.9199999999998, "text": " there's no machine school and be like, no, it's going to be the opposite.", "tokens": [50540, 456, 311, 572, 3479, 1395, 293, 312, 411, 11, 572, 11, 309, 311, 516, 281, 312, 264, 6182, 13, 50680], "temperature": 0.0, "avg_logprob": -0.18382528383437902, "compression_ratio": 1.7821782178217822, "no_speech_prob": 0.1334572583436966}, {"id": 409, "seek": 138660, "start": 1392.9199999999998, "end": 1396.9199999999998, "text": " You automate creativity long before many other things and we're there now, right?", "tokens": [50680, 509, 31605, 12915, 938, 949, 867, 661, 721, 293, 321, 434, 456, 586, 11, 558, 30, 50880], "temperature": 0.0, "avg_logprob": -0.18382528383437902, "compression_ratio": 1.7821782178217822, "no_speech_prob": 0.1334572583436966}, {"id": 410, "seek": 138660, "start": 1396.9199999999998, "end": 1403.6799999999998, "text": " In just the last, so I think when you, let me put it this way, your prompt to the LLM,", "tokens": [50880, 682, 445, 264, 1036, 11, 370, 286, 519, 562, 291, 11, 718, 385, 829, 309, 341, 636, 11, 428, 12391, 281, 264, 441, 43, 44, 11, 51218], "temperature": 0.0, "avg_logprob": -0.18382528383437902, "compression_ratio": 1.7821782178217822, "no_speech_prob": 0.1334572583436966}, {"id": 411, "seek": 138660, "start": 1403.6799999999998, "end": 1408.1999999999998, "text": " let's say, is like the grain of sand to the oyster, right?", "tokens": [51218, 718, 311, 584, 11, 307, 411, 264, 12837, 295, 4932, 281, 264, 32005, 11, 558, 30, 51444], "temperature": 0.0, "avg_logprob": -0.18382528383437902, "compression_ratio": 1.7821782178217822, "no_speech_prob": 0.1334572583436966}, {"id": 412, "seek": 138660, "start": 1408.1999999999998, "end": 1411.6799999999998, "text": " You should not give yourself credit for having made the pearl because it put the grain of", "tokens": [51444, 509, 820, 406, 976, 1803, 5397, 337, 1419, 1027, 264, 20287, 570, 309, 829, 264, 12837, 295, 51618], "temperature": 0.0, "avg_logprob": -0.18382528383437902, "compression_ratio": 1.7821782178217822, "no_speech_prob": 0.1334572583436966}, {"id": 413, "seek": 138660, "start": 1411.6799999999998, "end": 1412.6799999999998, "text": " sand in there.", "tokens": [51618, 4932, 294, 456, 13, 51668], "temperature": 0.0, "avg_logprob": -0.18382528383437902, "compression_ratio": 1.7821782178217822, "no_speech_prob": 0.1334572583436966}, {"id": 414, "seek": 138660, "start": 1412.6799999999998, "end": 1414.9599999999998, "text": " That's a, that's a brilliant analogy, right?", "tokens": [51668, 663, 311, 257, 11, 300, 311, 257, 10248, 21663, 11, 558, 30, 51782], "temperature": 0.0, "avg_logprob": -0.18382528383437902, "compression_ratio": 1.7821782178217822, "no_speech_prob": 0.1334572583436966}, {"id": 415, "seek": 141496, "start": 1414.96, "end": 1420.44, "text": " So it is still the LLM, we need to, we can critique how creative it is or not and there's", "tokens": [50364, 407, 309, 307, 920, 264, 441, 43, 44, 11, 321, 643, 281, 11, 321, 393, 25673, 577, 5880, 309, 307, 420, 406, 293, 456, 311, 50638], "temperature": 0.0, "avg_logprob": -0.15018744902177292, "compression_ratio": 1.806201550387597, "no_speech_prob": 0.008806074969470501}, {"id": 416, "seek": 141496, "start": 1420.44, "end": 1424.2, "text": " a lot to be said there and a lot of progress to be made, but we need to give it credit", "tokens": [50638, 257, 688, 281, 312, 848, 456, 293, 257, 688, 295, 4205, 281, 312, 1027, 11, 457, 321, 643, 281, 976, 309, 5397, 50826], "temperature": 0.0, "avg_logprob": -0.15018744902177292, "compression_ratio": 1.806201550387597, "no_speech_prob": 0.008806074969470501}, {"id": 417, "seek": 141496, "start": 1424.2, "end": 1425.6000000000001, "text": " for what it does, right?", "tokens": [50826, 337, 437, 309, 775, 11, 558, 30, 50896], "temperature": 0.0, "avg_logprob": -0.15018744902177292, "compression_ratio": 1.806201550387597, "no_speech_prob": 0.008806074969470501}, {"id": 418, "seek": 141496, "start": 1425.6000000000001, "end": 1427.96, "text": " It is well or not so well, right?", "tokens": [50896, 467, 307, 731, 420, 406, 370, 731, 11, 558, 30, 51014], "temperature": 0.0, "avg_logprob": -0.15018744902177292, "compression_ratio": 1.806201550387597, "no_speech_prob": 0.008806074969470501}, {"id": 419, "seek": 141496, "start": 1427.96, "end": 1432.68, "text": " Maybe it's more of an illusion that we're giving credit for and whatnot, but that text", "tokens": [51014, 2704, 309, 311, 544, 295, 364, 18854, 300, 321, 434, 2902, 5397, 337, 293, 25882, 11, 457, 300, 2487, 51250], "temperature": 0.0, "avg_logprob": -0.15018744902177292, "compression_ratio": 1.806201550387597, "no_speech_prob": 0.008806074969470501}, {"id": 420, "seek": 141496, "start": 1432.68, "end": 1437.76, "text": " or that image or whatever, they were created by the AI.", "tokens": [51250, 420, 300, 3256, 420, 2035, 11, 436, 645, 2942, 538, 264, 7318, 13, 51504], "temperature": 0.0, "avg_logprob": -0.15018744902177292, "compression_ratio": 1.806201550387597, "no_speech_prob": 0.008806074969470501}, {"id": 421, "seek": 141496, "start": 1437.76, "end": 1441.44, "text": " And in many ways, the thing that was created by the AI is no worse than what would have", "tokens": [51504, 400, 294, 867, 2098, 11, 264, 551, 300, 390, 2942, 538, 264, 7318, 307, 572, 5324, 813, 437, 576, 362, 51688], "temperature": 0.0, "avg_logprob": -0.15018744902177292, "compression_ratio": 1.806201550387597, "no_speech_prob": 0.008806074969470501}, {"id": 422, "seek": 144144, "start": 1441.44, "end": 1445.24, "text": " been created by an artist if I gave them the prompt.", "tokens": [50364, 668, 2942, 538, 364, 5748, 498, 286, 2729, 552, 264, 12391, 13, 50554], "temperature": 0.0, "avg_logprob": -0.18879469338949625, "compression_ratio": 1.6735905044510386, "no_speech_prob": 0.2774219214916229}, {"id": 423, "seek": 144144, "start": 1445.24, "end": 1446.24, "text": " No, okay.", "tokens": [50554, 883, 11, 1392, 13, 50604], "temperature": 0.0, "avg_logprob": -0.18879469338949625, "compression_ratio": 1.6735905044510386, "no_speech_prob": 0.2774219214916229}, {"id": 424, "seek": 144144, "start": 1446.24, "end": 1447.24, "text": " Well, on that, I agree with you.", "tokens": [50604, 1042, 11, 322, 300, 11, 286, 3986, 365, 291, 13, 50654], "temperature": 0.0, "avg_logprob": -0.18879469338949625, "compression_ratio": 1.6735905044510386, "no_speech_prob": 0.2774219214916229}, {"id": 425, "seek": 144144, "start": 1447.24, "end": 1450.56, "text": " I mean, Melanie Mitchell had this wonderful anecdote from the Google Plex when she was", "tokens": [50654, 286, 914, 11, 42798, 27582, 632, 341, 3715, 49845, 490, 264, 3329, 430, 2021, 562, 750, 390, 50820], "temperature": 0.0, "avg_logprob": -0.18879469338949625, "compression_ratio": 1.6735905044510386, "no_speech_prob": 0.2774219214916229}, {"id": 426, "seek": 144144, "start": 1450.56, "end": 1454.0800000000002, "text": " with Douglas Hofstadter and he was talking at the time about, you know, how he would", "tokens": [50820, 365, 23010, 37379, 48299, 391, 293, 415, 390, 1417, 412, 264, 565, 466, 11, 291, 458, 11, 577, 415, 576, 50996], "temperature": 0.0, "avg_logprob": -0.18879469338949625, "compression_ratio": 1.6735905044510386, "no_speech_prob": 0.2774219214916229}, {"id": 427, "seek": 144144, "start": 1454.0800000000002, "end": 1458.92, "text": " be devastated if an AI could produce a Chopin piece, you know, which was indistinguishable", "tokens": [50996, 312, 34880, 498, 364, 7318, 727, 5258, 257, 25615, 259, 2522, 11, 291, 458, 11, 597, 390, 1016, 468, 7050, 742, 712, 51238], "temperature": 0.0, "avg_logprob": -0.18879469338949625, "compression_ratio": 1.6735905044510386, "no_speech_prob": 0.2774219214916229}, {"id": 428, "seek": 144144, "start": 1458.92, "end": 1464.52, "text": " from one which he actually created and of course, that did happen, but then we get into", "tokens": [51238, 490, 472, 597, 415, 767, 2942, 293, 295, 1164, 11, 300, 630, 1051, 11, 457, 550, 321, 483, 666, 51518], "temperature": 0.0, "avg_logprob": -0.18879469338949625, "compression_ratio": 1.6735905044510386, "no_speech_prob": 0.2774219214916229}, {"id": 429, "seek": 144144, "start": 1464.52, "end": 1467.3600000000001, "text": " this discussion of where does it start, right?", "tokens": [51518, 341, 5017, 295, 689, 775, 309, 722, 11, 558, 30, 51660], "temperature": 0.0, "avg_logprob": -0.18879469338949625, "compression_ratio": 1.6735905044510386, "no_speech_prob": 0.2774219214916229}, {"id": 430, "seek": 144144, "start": 1467.3600000000001, "end": 1469.04, "text": " Where does it start?", "tokens": [51660, 2305, 775, 309, 722, 30, 51744], "temperature": 0.0, "avg_logprob": -0.18879469338949625, "compression_ratio": 1.6735905044510386, "no_speech_prob": 0.2774219214916229}, {"id": 431, "seek": 144144, "start": 1469.04, "end": 1470.92, "text": " Computers only do what we tell them to do, right?", "tokens": [51744, 37804, 433, 787, 360, 437, 321, 980, 552, 281, 360, 11, 558, 30, 51838], "temperature": 0.0, "avg_logprob": -0.18879469338949625, "compression_ratio": 1.6735905044510386, "no_speech_prob": 0.2774219214916229}, {"id": 432, "seek": 147092, "start": 1470.92, "end": 1475.16, "text": " They've been trained and actually I was speaking to Sep about this the other day that, you", "tokens": [50364, 814, 600, 668, 8895, 293, 767, 286, 390, 4124, 281, 22012, 466, 341, 264, 661, 786, 300, 11, 291, 50576], "temperature": 0.0, "avg_logprob": -0.19050373674249974, "compression_ratio": 1.8443708609271523, "no_speech_prob": 0.06624897569417953}, {"id": 433, "seek": 147092, "start": 1475.16, "end": 1478.5600000000002, "text": " know, all of the abstractions, all of the things that the computers and the models do,", "tokens": [50576, 458, 11, 439, 295, 264, 12649, 626, 11, 439, 295, 264, 721, 300, 264, 10807, 293, 264, 5245, 360, 11, 50746], "temperature": 0.0, "avg_logprob": -0.19050373674249974, "compression_ratio": 1.8443708609271523, "no_speech_prob": 0.06624897569417953}, {"id": 434, "seek": 147092, "start": 1478.5600000000002, "end": 1482.68, "text": " they are crystallized snapshots of things that humans have previously done and we've", "tokens": [50746, 436, 366, 31924, 1602, 19206, 27495, 295, 721, 300, 6255, 362, 8046, 1096, 293, 321, 600, 50952], "temperature": 0.0, "avg_logprob": -0.19050373674249974, "compression_ratio": 1.8443708609271523, "no_speech_prob": 0.06624897569417953}, {"id": 435, "seek": 147092, "start": 1482.68, "end": 1484.92, "text": " written the computer code.", "tokens": [50952, 3720, 264, 3820, 3089, 13, 51064], "temperature": 0.0, "avg_logprob": -0.19050373674249974, "compression_ratio": 1.8443708609271523, "no_speech_prob": 0.06624897569417953}, {"id": 436, "seek": 147092, "start": 1484.92, "end": 1486.72, "text": " So where does the creativity start?", "tokens": [51064, 407, 689, 775, 264, 12915, 722, 30, 51154], "temperature": 0.0, "avg_logprob": -0.19050373674249974, "compression_ratio": 1.8443708609271523, "no_speech_prob": 0.06624897569417953}, {"id": 437, "seek": 147092, "start": 1486.72, "end": 1493.88, "text": " Well, but we, by that standard, we humans also only do what we're told to do.", "tokens": [51154, 1042, 11, 457, 321, 11, 538, 300, 3832, 11, 321, 6255, 611, 787, 360, 437, 321, 434, 1907, 281, 360, 13, 51512], "temperature": 0.0, "avg_logprob": -0.19050373674249974, "compression_ratio": 1.8443708609271523, "no_speech_prob": 0.06624897569417953}, {"id": 438, "seek": 147092, "start": 1493.88, "end": 1495.64, "text": " We do what we're told to do by our genes.", "tokens": [51512, 492, 360, 437, 321, 434, 1907, 281, 360, 538, 527, 14424, 13, 51600], "temperature": 0.0, "avg_logprob": -0.19050373674249974, "compression_ratio": 1.8443708609271523, "no_speech_prob": 0.06624897569417953}, {"id": 439, "seek": 147092, "start": 1495.64, "end": 1499.04, "text": " Our genes do what they're told to do by evolution, which does what is told to do by the laws", "tokens": [51600, 2621, 14424, 360, 437, 436, 434, 1907, 281, 360, 538, 9303, 11, 597, 775, 437, 307, 1907, 281, 360, 538, 264, 6064, 51770], "temperature": 0.0, "avg_logprob": -0.19050373674249974, "compression_ratio": 1.8443708609271523, "no_speech_prob": 0.06624897569417953}, {"id": 440, "seek": 147092, "start": 1499.04, "end": 1500.04, "text": " of physics, right?", "tokens": [51770, 295, 10649, 11, 558, 30, 51820], "temperature": 0.0, "avg_logprob": -0.19050373674249974, "compression_ratio": 1.8443708609271523, "no_speech_prob": 0.06624897569417953}, {"id": 441, "seek": 150004, "start": 1500.1599999999999, "end": 1501.1599999999999, "text": " Right.", "tokens": [50370, 1779, 13, 50420], "temperature": 0.0, "avg_logprob": -0.1881981677696353, "compression_ratio": 1.6611295681063123, "no_speech_prob": 0.034940462559461594}, {"id": 442, "seek": 150004, "start": 1501.1599999999999, "end": 1505.68, "text": " And now, again, this gets back to this notion that there's nothing magical about creativity.", "tokens": [50420, 400, 586, 11, 797, 11, 341, 2170, 646, 281, 341, 10710, 300, 456, 311, 1825, 12066, 466, 12915, 13, 50646], "temperature": 0.0, "avg_logprob": -0.1881981677696353, "compression_ratio": 1.6611295681063123, "no_speech_prob": 0.034940462559461594}, {"id": 443, "seek": 150004, "start": 1505.68, "end": 1510.92, "text": " Creativity really is, to a large extent, cutting and pasting stuff and satisfying consistency", "tokens": [50646, 11972, 4253, 534, 307, 11, 281, 257, 2416, 8396, 11, 6492, 293, 1791, 278, 1507, 293, 18348, 14416, 50908], "temperature": 0.0, "avg_logprob": -0.1881981677696353, "compression_ratio": 1.6611295681063123, "no_speech_prob": 0.034940462559461594}, {"id": 444, "seek": 150004, "start": 1510.92, "end": 1512.32, "text": " constraints between them.", "tokens": [50908, 18491, 1296, 552, 13, 50978], "temperature": 0.0, "avg_logprob": -0.1881981677696353, "compression_ratio": 1.6611295681063123, "no_speech_prob": 0.034940462559461594}, {"id": 445, "seek": 150004, "start": 1512.32, "end": 1516.72, "text": " And I'm not just saying this in the abstract, like long before the modern era, there's this", "tokens": [50978, 400, 286, 478, 406, 445, 1566, 341, 294, 264, 12649, 11, 411, 938, 949, 264, 4363, 4249, 11, 456, 311, 341, 51198], "temperature": 0.0, "avg_logprob": -0.1881981677696353, "compression_ratio": 1.6611295681063123, "no_speech_prob": 0.034940462559461594}, {"id": 446, "seek": 150004, "start": 1516.72, "end": 1523.12, "text": " guy called David Cope, you know, a composer and professor of music at UC Santa Cruz who", "tokens": [51198, 2146, 1219, 4389, 383, 1114, 11, 291, 458, 11, 257, 26003, 293, 8304, 295, 1318, 412, 14079, 9933, 23008, 567, 51518], "temperature": 0.0, "avg_logprob": -0.1881981677696353, "compression_ratio": 1.6611295681063123, "no_speech_prob": 0.034940462559461594}, {"id": 447, "seek": 150004, "start": 1523.12, "end": 1528.76, "text": " created these programs that exactly they would write, they can write, this was pre-machine", "tokens": [51518, 2942, 613, 4268, 300, 2293, 436, 576, 2464, 11, 436, 393, 2464, 11, 341, 390, 659, 12, 46061, 51800], "temperature": 0.0, "avg_logprob": -0.1881981677696353, "compression_ratio": 1.6611295681063123, "no_speech_prob": 0.034940462559461594}, {"id": 448, "seek": 150004, "start": 1528.76, "end": 1529.76, "text": " learning.", "tokens": [51800, 2539, 13, 51850], "temperature": 0.0, "avg_logprob": -0.1881981677696353, "compression_ratio": 1.6611295681063123, "no_speech_prob": 0.034940462559461594}, {"id": 449, "seek": 152976, "start": 1529.76, "end": 1534.52, "text": " It was list code that what it did was basically have rules about how music should be.", "tokens": [50364, 467, 390, 1329, 3089, 300, 437, 309, 630, 390, 1936, 362, 4474, 466, 577, 1318, 820, 312, 13, 50602], "temperature": 0.0, "avg_logprob": -0.12167622601544416, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.00883148517459631}, {"id": 450, "seek": 152976, "start": 1534.52, "end": 1537.2, "text": " And then it takes snippets and combines them, right?", "tokens": [50602, 400, 550, 309, 2516, 35623, 1385, 293, 29520, 552, 11, 558, 30, 50736], "temperature": 0.0, "avg_logprob": -0.12167622601544416, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.00883148517459631}, {"id": 451, "seek": 152976, "start": 1537.2, "end": 1540.72, "text": " You could say it's just parroting those bits, but the truth is at the end of the day and", "tokens": [50736, 509, 727, 584, 309, 311, 445, 42462, 278, 729, 9239, 11, 457, 264, 3494, 307, 412, 264, 917, 295, 264, 786, 293, 50912], "temperature": 0.0, "avg_logprob": -0.12167622601544416, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.00883148517459631}, {"id": 452, "seek": 152976, "start": 1540.72, "end": 1541.72, "text": " you can choose.", "tokens": [50912, 291, 393, 2826, 13, 50962], "temperature": 0.0, "avg_logprob": -0.12167622601544416, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.00883148517459631}, {"id": 453, "seek": 152976, "start": 1541.72, "end": 1544.08, "text": " You say, like, give me something in the style of Mozart.", "tokens": [50962, 509, 584, 11, 411, 11, 976, 385, 746, 294, 264, 3758, 295, 42653, 13, 51080], "temperature": 0.0, "avg_logprob": -0.12167622601544416, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.00883148517459631}, {"id": 454, "seek": 152976, "start": 1544.08, "end": 1550.04, "text": " And it creates something that looks indistinguishable from what Mozart did, but all it's doing", "tokens": [51080, 400, 309, 7829, 746, 300, 1542, 1016, 468, 7050, 742, 712, 490, 437, 42653, 630, 11, 457, 439, 309, 311, 884, 51378], "temperature": 0.0, "avg_logprob": -0.12167622601544416, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.00883148517459631}, {"id": 455, "seek": 152976, "start": 1550.04, "end": 1552.64, "text": " is this kind of recombination of pieces.", "tokens": [51378, 307, 341, 733, 295, 850, 3548, 2486, 295, 3755, 13, 51508], "temperature": 0.0, "avg_logprob": -0.12167622601544416, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.00883148517459631}, {"id": 456, "seek": 152976, "start": 1552.64, "end": 1559.44, "text": " So we humans, we have too much respect for appreciation of our own intelligence.", "tokens": [51508, 407, 321, 6255, 11, 321, 362, 886, 709, 3104, 337, 18909, 295, 527, 1065, 7599, 13, 51848], "temperature": 0.0, "avg_logprob": -0.12167622601544416, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.00883148517459631}, {"id": 457, "seek": 155944, "start": 1559.44, "end": 1561.0, "text": " That's also what we're doing.", "tokens": [50364, 663, 311, 611, 437, 321, 434, 884, 13, 50442], "temperature": 0.0, "avg_logprob": -0.21420851018693712, "compression_ratio": 1.75, "no_speech_prob": 0.0707736685872078}, {"id": 458, "seek": 155944, "start": 1561.0, "end": 1562.76, "text": " Yeah, I think I agree with you.", "tokens": [50442, 865, 11, 286, 519, 286, 3986, 365, 291, 13, 50530], "temperature": 0.0, "avg_logprob": -0.21420851018693712, "compression_ratio": 1.75, "no_speech_prob": 0.0707736685872078}, {"id": 459, "seek": 155944, "start": 1562.76, "end": 1566.76, "text": " I mean, first of all, intelligence is a receding horizon and there's the McCorduck effect.", "tokens": [50530, 286, 914, 11, 700, 295, 439, 11, 7599, 307, 257, 850, 9794, 18046, 293, 456, 311, 264, 12061, 765, 1134, 1802, 13, 50730], "temperature": 0.0, "avg_logprob": -0.21420851018693712, "compression_ratio": 1.75, "no_speech_prob": 0.0707736685872078}, {"id": 460, "seek": 155944, "start": 1566.76, "end": 1568.16, "text": " I agree with all of that.", "tokens": [50730, 286, 3986, 365, 439, 295, 300, 13, 50800], "temperature": 0.0, "avg_logprob": -0.21420851018693712, "compression_ratio": 1.75, "no_speech_prob": 0.0707736685872078}, {"id": 461, "seek": 155944, "start": 1568.16, "end": 1574.18, "text": " But yeah, I think it's a similar thing to how we anthropomorphise large language models", "tokens": [50800, 583, 1338, 11, 286, 519, 309, 311, 257, 2531, 551, 281, 577, 321, 22727, 32702, 908, 2416, 2856, 5245, 51101], "temperature": 0.0, "avg_logprob": -0.21420851018693712, "compression_ratio": 1.75, "no_speech_prob": 0.0707736685872078}, {"id": 462, "seek": 155944, "start": 1574.18, "end": 1577.3200000000002, "text": " and even, you know, it's tempting to say large language models are slightly conscious", "tokens": [51101, 293, 754, 11, 291, 458, 11, 309, 311, 37900, 281, 584, 2416, 2856, 5245, 366, 4748, 6648, 51258], "temperature": 0.0, "avg_logprob": -0.21420851018693712, "compression_ratio": 1.75, "no_speech_prob": 0.0707736685872078}, {"id": 463, "seek": 155944, "start": 1577.3200000000002, "end": 1581.76, "text": " and we'll talk about that in a minute, but maybe like we also anthropomorphise our own", "tokens": [51258, 293, 321, 603, 751, 466, 300, 294, 257, 3456, 11, 457, 1310, 411, 321, 611, 22727, 32702, 908, 527, 1065, 51480], "temperature": 0.0, "avg_logprob": -0.21420851018693712, "compression_ratio": 1.75, "no_speech_prob": 0.0707736685872078}, {"id": 464, "seek": 155944, "start": 1581.76, "end": 1582.76, "text": " agency, right?", "tokens": [51480, 7934, 11, 558, 30, 51530], "temperature": 0.0, "avg_logprob": -0.21420851018693712, "compression_ratio": 1.75, "no_speech_prob": 0.0707736685872078}, {"id": 465, "seek": 155944, "start": 1582.76, "end": 1586.48, "text": " We have like a little bubble around ourselves and we kind of delude ourselves that we exist", "tokens": [51530, 492, 362, 411, 257, 707, 12212, 926, 4175, 293, 321, 733, 295, 1103, 2303, 4175, 300, 321, 2514, 51716], "temperature": 0.0, "avg_logprob": -0.21420851018693712, "compression_ratio": 1.75, "no_speech_prob": 0.0707736685872078}, {"id": 466, "seek": 158648, "start": 1586.48, "end": 1591.32, "text": " as an individual unit with agency disconnected from the rest of the world.", "tokens": [50364, 382, 364, 2609, 4985, 365, 7934, 29426, 490, 264, 1472, 295, 264, 1002, 13, 50606], "temperature": 0.0, "avg_logprob": -0.16153268054523298, "compression_ratio": 1.6883561643835616, "no_speech_prob": 0.04309140518307686}, {"id": 467, "seek": 158648, "start": 1591.32, "end": 1597.4, "text": " Well, precisely the problem with how we largely take AI today, this has always been the case,", "tokens": [50606, 1042, 11, 13402, 264, 1154, 365, 577, 321, 11611, 747, 7318, 965, 11, 341, 575, 1009, 668, 264, 1389, 11, 50910], "temperature": 0.0, "avg_logprob": -0.16153268054523298, "compression_ratio": 1.6883561643835616, "no_speech_prob": 0.04309140518307686}, {"id": 468, "seek": 158648, "start": 1597.4, "end": 1602.76, "text": " by the way, is that we have a new resistible notion to anthropomorphise anything that behaves", "tokens": [50910, 538, 264, 636, 11, 307, 300, 321, 362, 257, 777, 4597, 964, 10710, 281, 22727, 32702, 908, 1340, 300, 36896, 51178], "temperature": 0.0, "avg_logprob": -0.16153268054523298, "compression_ratio": 1.6883561643835616, "no_speech_prob": 0.04309140518307686}, {"id": 469, "seek": 158648, "start": 1602.76, "end": 1604.2, "text": " even remotely like us.", "tokens": [51178, 754, 20824, 411, 505, 13, 51250], "temperature": 0.0, "avg_logprob": -0.16153268054523298, "compression_ratio": 1.6883561643835616, "no_speech_prob": 0.04309140518307686}, {"id": 470, "seek": 158648, "start": 1604.2, "end": 1608.8, "text": " We're the only intelligent things that we know, so if something starts behaving intelligently,", "tokens": [51250, 492, 434, 264, 787, 13232, 721, 300, 321, 458, 11, 370, 498, 746, 3719, 35263, 5613, 2276, 11, 51480], "temperature": 0.0, "avg_logprob": -0.16153268054523298, "compression_ratio": 1.6883561643835616, "no_speech_prob": 0.04309140518307686}, {"id": 471, "seek": 158648, "start": 1608.8, "end": 1613.24, "text": " then we project onto it all of these other human characteristics.", "tokens": [51480, 550, 321, 1716, 3911, 309, 439, 295, 613, 661, 1952, 10891, 13, 51702], "temperature": 0.0, "avg_logprob": -0.16153268054523298, "compression_ratio": 1.6883561643835616, "no_speech_prob": 0.04309140518307686}, {"id": 472, "seek": 158648, "start": 1613.24, "end": 1615.4, "text": " Same with consciousness, same with creativity.", "tokens": [51702, 10635, 365, 10081, 11, 912, 365, 12915, 13, 51810], "temperature": 0.0, "avg_logprob": -0.16153268054523298, "compression_ratio": 1.6883561643835616, "no_speech_prob": 0.04309140518307686}, {"id": 473, "seek": 161540, "start": 1615.4, "end": 1617.6000000000001, "text": " We don't know anything else that's creative besides us.", "tokens": [50364, 492, 500, 380, 458, 1340, 1646, 300, 311, 5880, 11868, 505, 13, 50474], "temperature": 0.0, "avg_logprob": -0.1628447352228938, "compression_ratio": 1.7641509433962264, "no_speech_prob": 0.11555109173059464}, {"id": 474, "seek": 161540, "start": 1617.6000000000001, "end": 1621.8400000000001, "text": " So once a machine starts behaving creatively, we cannot help but project a lot of things", "tokens": [50474, 407, 1564, 257, 3479, 3719, 35263, 43750, 11, 321, 2644, 854, 457, 1716, 257, 688, 295, 721, 50686], "temperature": 0.0, "avg_logprob": -0.1628447352228938, "compression_ratio": 1.7641509433962264, "no_speech_prob": 0.11555109173059464}, {"id": 475, "seek": 161540, "start": 1621.8400000000001, "end": 1622.8400000000001, "text": " onto it.", "tokens": [50686, 3911, 309, 13, 50736], "temperature": 0.0, "avg_logprob": -0.1628447352228938, "compression_ratio": 1.7641509433962264, "no_speech_prob": 0.11555109173059464}, {"id": 476, "seek": 161540, "start": 1622.8400000000001, "end": 1624.8400000000001, "text": " It's just reasoning by analogy, right?", "tokens": [50736, 467, 311, 445, 21577, 538, 21663, 11, 558, 30, 50836], "temperature": 0.0, "avg_logprob": -0.1628447352228938, "compression_ratio": 1.7641509433962264, "no_speech_prob": 0.11555109173059464}, {"id": 477, "seek": 161540, "start": 1624.8400000000001, "end": 1629.3200000000002, "text": " So it's a kind of analogical, so like you're like me in this respect, so you probably are", "tokens": [50836, 407, 309, 311, 257, 733, 295, 16660, 804, 11, 370, 411, 291, 434, 411, 385, 294, 341, 3104, 11, 370, 291, 1391, 366, 51060], "temperature": 0.0, "avg_logprob": -0.1628447352228938, "compression_ratio": 1.7641509433962264, "no_speech_prob": 0.11555109173059464}, {"id": 478, "seek": 161540, "start": 1629.3200000000002, "end": 1630.3200000000002, "text": " in this other spec.", "tokens": [51060, 294, 341, 661, 1608, 13, 51110], "temperature": 0.0, "avg_logprob": -0.1628447352228938, "compression_ratio": 1.7641509433962264, "no_speech_prob": 0.11555109173059464}, {"id": 479, "seek": 161540, "start": 1630.3200000000002, "end": 1633.76, "text": " Now, the good news is that we always start out with this kind of very good reasoning", "tokens": [51110, 823, 11, 264, 665, 2583, 307, 300, 321, 1009, 722, 484, 365, 341, 733, 295, 588, 665, 21577, 51282], "temperature": 0.0, "avg_logprob": -0.1628447352228938, "compression_ratio": 1.7641509433962264, "no_speech_prob": 0.11555109173059464}, {"id": 480, "seek": 161540, "start": 1633.76, "end": 1637.92, "text": " by analogy, but after a while, we actually start to build a model of the real thing.", "tokens": [51282, 538, 21663, 11, 457, 934, 257, 1339, 11, 321, 767, 722, 281, 1322, 257, 2316, 295, 264, 957, 551, 13, 51490], "temperature": 0.0, "avg_logprob": -0.1628447352228938, "compression_ratio": 1.7641509433962264, "no_speech_prob": 0.11555109173059464}, {"id": 481, "seek": 161540, "start": 1637.92, "end": 1643.3200000000002, "text": " So AI for the public at large right now is very new, but gradually we'll come to a point", "tokens": [51490, 407, 7318, 337, 264, 1908, 412, 2416, 558, 586, 307, 588, 777, 11, 457, 13145, 321, 603, 808, 281, 257, 935, 51760], "temperature": 0.0, "avg_logprob": -0.1628447352228938, "compression_ratio": 1.7641509433962264, "no_speech_prob": 0.11555109173059464}, {"id": 482, "seek": 164332, "start": 1643.32, "end": 1649.12, "text": " where we zero in on what AI really is rather than just the shallow analogies that we initially", "tokens": [50364, 689, 321, 4018, 294, 322, 437, 7318, 534, 307, 2831, 813, 445, 264, 20488, 16660, 530, 300, 321, 9105, 50654], "temperature": 0.0, "avg_logprob": -0.23115758659425845, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.05709587782621384}, {"id": 483, "seek": 164332, "start": 1649.12, "end": 1650.12, "text": " used to try to understand.", "tokens": [50654, 1143, 281, 853, 281, 1223, 13, 50704], "temperature": 0.0, "avg_logprob": -0.23115758659425845, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.05709587782621384}, {"id": 484, "seek": 164332, "start": 1650.12, "end": 1651.12, "text": " Okay.", "tokens": [50704, 1033, 13, 50754], "temperature": 0.0, "avg_logprob": -0.23115758659425845, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.05709587782621384}, {"id": 485, "seek": 164332, "start": 1651.12, "end": 1652.56, "text": " Well, I'll try it from a slightly different angle.", "tokens": [50754, 1042, 11, 286, 603, 853, 309, 490, 257, 4748, 819, 5802, 13, 50826], "temperature": 0.0, "avg_logprob": -0.23115758659425845, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.05709587782621384}, {"id": 486, "seek": 164332, "start": 1652.56, "end": 1656.04, "text": " So we were just saying Seoul makes the argument that it's a biological property and that's", "tokens": [50826, 407, 321, 645, 445, 1566, 17100, 1669, 264, 6770, 300, 309, 311, 257, 13910, 4707, 293, 300, 311, 51000], "temperature": 0.0, "avg_logprob": -0.23115758659425845, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.05709587782621384}, {"id": 487, "seek": 164332, "start": 1656.04, "end": 1660.48, "text": " where intentionality and consciousness comes from and it's a requisite, but we'll leave", "tokens": [51000, 689, 7789, 1860, 293, 10081, 1487, 490, 293, 309, 311, 257, 49878, 642, 11, 457, 321, 603, 1856, 51222], "temperature": 0.0, "avg_logprob": -0.23115758659425845, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.05709587782621384}, {"id": 488, "seek": 164332, "start": 1660.48, "end": 1662.1599999999999, "text": " that for the time being.", "tokens": [51222, 300, 337, 264, 565, 885, 13, 51306], "temperature": 0.0, "avg_logprob": -0.23115758659425845, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.05709587782621384}, {"id": 489, "seek": 164332, "start": 1662.1599999999999, "end": 1667.72, "text": " Let's go the Fodor and the Gary Marcus and the Chomsky group, and they would argue that", "tokens": [51306, 961, 311, 352, 264, 479, 34024, 293, 264, 13788, 26574, 293, 264, 761, 4785, 4133, 1594, 11, 293, 436, 576, 9695, 300, 51584], "temperature": 0.0, "avg_logprob": -0.23115758659425845, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.05709587782621384}, {"id": 490, "seek": 166772, "start": 1667.72, "end": 1673.4, "text": " creativity is basically this notion of, or even analogy making by extension, is this", "tokens": [50364, 12915, 307, 1936, 341, 10710, 295, 11, 420, 754, 21663, 1455, 538, 10320, 11, 307, 341, 50648], "temperature": 0.0, "avg_logprob": -0.1738313797417037, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.43578487634658813}, {"id": 491, "seek": 166772, "start": 1673.4, "end": 1678.44, "text": " notion of being able to select from a set which has an infinite cardinality.", "tokens": [50648, 10710, 295, 885, 1075, 281, 3048, 490, 257, 992, 597, 575, 364, 13785, 2920, 259, 1860, 13, 50900], "temperature": 0.0, "avg_logprob": -0.1738313797417037, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.43578487634658813}, {"id": 492, "seek": 166772, "start": 1678.44, "end": 1682.84, "text": " And as you know, neural networks can't represent infinite sets because they're finite state", "tokens": [50900, 400, 382, 291, 458, 11, 18161, 9590, 393, 380, 2906, 13785, 6352, 570, 436, 434, 19362, 1785, 51120], "temperature": 0.0, "avg_logprob": -0.1738313797417037, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.43578487634658813}, {"id": 493, "seek": 166772, "start": 1682.84, "end": 1686.8, "text": " automators, therefore they make the move we need to have this compositionality.", "tokens": [51120, 3553, 3391, 11, 4412, 436, 652, 264, 1286, 321, 643, 281, 362, 341, 12686, 1860, 13, 51318], "temperature": 0.0, "avg_logprob": -0.1738313797417037, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.43578487634658813}, {"id": 494, "seek": 166772, "start": 1686.8, "end": 1687.8, "text": " What do you say to that?", "tokens": [51318, 708, 360, 291, 584, 281, 300, 30, 51368], "temperature": 0.0, "avg_logprob": -0.1738313797417037, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.43578487634658813}, {"id": 495, "seek": 166772, "start": 1687.8, "end": 1689.92, "text": " Well, there's a lot to unpack there.", "tokens": [51368, 1042, 11, 456, 311, 257, 688, 281, 26699, 456, 13, 51474], "temperature": 0.0, "avg_logprob": -0.1738313797417037, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.43578487634658813}, {"id": 496, "seek": 166772, "start": 1689.92, "end": 1693.04, "text": " I think we definitely need compositionality, right?", "tokens": [51474, 286, 519, 321, 2138, 643, 12686, 1860, 11, 558, 30, 51630], "temperature": 0.0, "avg_logprob": -0.1738313797417037, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.43578487634658813}, {"id": 497, "seek": 169304, "start": 1693.04, "end": 1696.84, "text": " If somebody asked me, make a list of how there's some things that are actually essential", "tokens": [50364, 759, 2618, 2351, 385, 11, 652, 257, 1329, 295, 577, 456, 311, 512, 721, 300, 366, 767, 7115, 50554], "temperature": 0.0, "avg_logprob": -0.19964421012184835, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.005380076821893454}, {"id": 498, "seek": 169304, "start": 1696.84, "end": 1700.3999999999999, "text": " for intelligence, compositionality would be one of them, right?", "tokens": [50554, 337, 7599, 11, 12686, 1860, 576, 312, 472, 295, 552, 11, 558, 30, 50732], "temperature": 0.0, "avg_logprob": -0.19964421012184835, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.005380076821893454}, {"id": 499, "seek": 169304, "start": 1700.3999999999999, "end": 1705.04, "text": " And this, of course, is the thing that people like Chomsky and Gary are not really care", "tokens": [50732, 400, 341, 11, 295, 1164, 11, 307, 264, 551, 300, 561, 411, 761, 4785, 4133, 293, 13788, 366, 406, 534, 1127, 50964], "temperature": 0.0, "avg_logprob": -0.19964421012184835, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.005380076821893454}, {"id": 500, "seek": 169304, "start": 1705.04, "end": 1706.04, "text": " about, right?", "tokens": [50964, 466, 11, 558, 30, 51014], "temperature": 0.0, "avg_logprob": -0.19964421012184835, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.005380076821893454}, {"id": 501, "seek": 169304, "start": 1706.04, "end": 1711.56, "text": " Having said that, I think first of all, there is no such thing as an infinite set, right?", "tokens": [51014, 10222, 848, 300, 11, 286, 519, 700, 295, 439, 11, 456, 307, 572, 1270, 551, 382, 364, 13785, 992, 11, 558, 30, 51290], "temperature": 0.0, "avg_logprob": -0.19964421012184835, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.005380076821893454}, {"id": 502, "seek": 169304, "start": 1711.56, "end": 1720.32, "text": " Like infinite set is a useful but extremely dangerous and confusing mathematical tool,", "tokens": [51290, 1743, 13785, 992, 307, 257, 4420, 457, 4664, 5795, 293, 13181, 18894, 2290, 11, 51728], "temperature": 0.0, "avg_logprob": -0.19964421012184835, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.005380076821893454}, {"id": 503, "seek": 169304, "start": 1720.32, "end": 1721.32, "text": " right?", "tokens": [51728, 558, 30, 51778], "temperature": 0.0, "avg_logprob": -0.19964421012184835, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.005380076821893454}, {"id": 504, "seek": 172132, "start": 1721.96, "end": 1726.52, "text": " There is no such thing as an infinite anything and there never will be.", "tokens": [50396, 821, 307, 572, 1270, 551, 382, 364, 13785, 1340, 293, 456, 1128, 486, 312, 13, 50624], "temperature": 0.0, "avg_logprob": -0.18553493136451357, "compression_ratio": 1.6724137931034482, "no_speech_prob": 0.39691272377967834}, {"id": 505, "seek": 172132, "start": 1726.52, "end": 1730.8799999999999, "text": " So I would just raise this at, well, yes, creativity and almost anything we can do in", "tokens": [50624, 407, 286, 576, 445, 5300, 341, 412, 11, 731, 11, 2086, 11, 12915, 293, 1920, 1340, 321, 393, 360, 294, 50842], "temperature": 0.0, "avg_logprob": -0.18553493136451357, "compression_ratio": 1.6724137931034482, "no_speech_prob": 0.39691272377967834}, {"id": 506, "seek": 172132, "start": 1730.8799999999999, "end": 1736.6799999999998, "text": " AI is selecting from a very large set, not infinite, but very large, right?", "tokens": [50842, 7318, 307, 18182, 490, 257, 588, 2416, 992, 11, 406, 13785, 11, 457, 588, 2416, 11, 558, 30, 51132], "temperature": 0.0, "avg_logprob": -0.18553493136451357, "compression_ratio": 1.6724137931034482, "no_speech_prob": 0.39691272377967834}, {"id": 507, "seek": 172132, "start": 1736.6799999999998, "end": 1740.48, "text": " And now, but now we don't just select like one full element at a time.", "tokens": [51132, 400, 586, 11, 457, 586, 321, 500, 380, 445, 3048, 411, 472, 1577, 4478, 412, 257, 565, 13, 51322], "temperature": 0.0, "avg_logprob": -0.18553493136451357, "compression_ratio": 1.6724137931034482, "no_speech_prob": 0.39691272377967834}, {"id": 508, "seek": 172132, "start": 1740.48, "end": 1744.28, "text": " We compose it out of pieces and that's actually where the intelligence comes in.", "tokens": [51322, 492, 35925, 309, 484, 295, 3755, 293, 300, 311, 767, 689, 264, 7599, 1487, 294, 13, 51512], "temperature": 0.0, "avg_logprob": -0.18553493136451357, "compression_ratio": 1.6724137931034482, "no_speech_prob": 0.39691272377967834}, {"id": 509, "seek": 172132, "start": 1744.28, "end": 1745.28, "text": " Interesting.", "tokens": [51512, 14711, 13, 51562], "temperature": 0.0, "avg_logprob": -0.18553493136451357, "compression_ratio": 1.6724137931034482, "no_speech_prob": 0.39691272377967834}, {"id": 510, "seek": 172132, "start": 1745.28, "end": 1747.76, "text": " I don't want to go too far down the digital physics route, but we did just have Yoshua", "tokens": [51562, 286, 500, 380, 528, 281, 352, 886, 1400, 760, 264, 4562, 10649, 7955, 11, 457, 321, 630, 445, 362, 38949, 4398, 51686], "temperature": 0.0, "avg_logprob": -0.18553493136451357, "compression_ratio": 1.6724137931034482, "no_speech_prob": 0.39691272377967834}, {"id": 511, "seek": 174776, "start": 1747.84, "end": 1752.48, "text": " Barkon and I mean, just to reclamify on that, would you place yourself in that camp that", "tokens": [50368, 36275, 266, 293, 286, 914, 11, 445, 281, 850, 4326, 2505, 322, 300, 11, 576, 291, 1081, 1803, 294, 300, 2255, 300, 50600], "temperature": 0.0, "avg_logprob": -0.27149319889569523, "compression_ratio": 1.6697247706422018, "no_speech_prob": 0.04654664546251297}, {"id": 512, "seek": 174776, "start": 1752.48, "end": 1755.04, "text": " the universe is digital and made of information?", "tokens": [50600, 264, 6445, 307, 4562, 293, 1027, 295, 1589, 30, 50728], "temperature": 0.0, "avg_logprob": -0.27149319889569523, "compression_ratio": 1.6697247706422018, "no_speech_prob": 0.04654664546251297}, {"id": 513, "seek": 174776, "start": 1755.04, "end": 1757.12, "text": " Valid question.", "tokens": [50728, 7188, 327, 1168, 13, 50832], "temperature": 0.0, "avg_logprob": -0.27149319889569523, "compression_ratio": 1.6697247706422018, "no_speech_prob": 0.04654664546251297}, {"id": 514, "seek": 174776, "start": 1757.12, "end": 1760.28, "text": " I certainly think the universe is finite.", "tokens": [50832, 286, 3297, 519, 264, 6445, 307, 19362, 13, 50990], "temperature": 0.0, "avg_logprob": -0.27149319889569523, "compression_ratio": 1.6697247706422018, "no_speech_prob": 0.04654664546251297}, {"id": 515, "seek": 174776, "start": 1760.28, "end": 1767.92, "text": " I think, I mean, like Seth Lloyd says, the universe is a computer, right?", "tokens": [50990, 286, 519, 11, 286, 914, 11, 411, 25353, 31401, 1619, 11, 264, 6445, 307, 257, 3820, 11, 558, 30, 51372], "temperature": 0.0, "avg_logprob": -0.27149319889569523, "compression_ratio": 1.6697247706422018, "no_speech_prob": 0.04654664546251297}, {"id": 516, "seek": 174776, "start": 1767.92, "end": 1774.44, "text": " And I think that is true or false depending on what you take the word computer to mean,", "tokens": [51372, 400, 286, 519, 300, 307, 2074, 420, 7908, 5413, 322, 437, 291, 747, 264, 1349, 3820, 281, 914, 11, 51698], "temperature": 0.0, "avg_logprob": -0.27149319889569523, "compression_ratio": 1.6697247706422018, "no_speech_prob": 0.04654664546251297}, {"id": 517, "seek": 174776, "start": 1774.44, "end": 1775.44, "text": " right?", "tokens": [51698, 558, 30, 51748], "temperature": 0.0, "avg_logprob": -0.27149319889569523, "compression_ratio": 1.6697247706422018, "no_speech_prob": 0.04654664546251297}, {"id": 518, "seek": 177544, "start": 1776.44, "end": 1782.92, "text": " So if you say that the universe is digital or is a computer as kind of like an analogy", "tokens": [50414, 407, 498, 291, 584, 300, 264, 6445, 307, 4562, 420, 307, 257, 3820, 382, 733, 295, 411, 364, 21663, 50738], "temperature": 0.0, "avg_logprob": -0.18502235412597656, "compression_ratio": 1.8448275862068966, "no_speech_prob": 0.1639173924922943}, {"id": 519, "seek": 177544, "start": 1782.92, "end": 1786.1200000000001, "text": " that lets us understand it better, I'm all for that.", "tokens": [50738, 300, 6653, 505, 1223, 309, 1101, 11, 286, 478, 439, 337, 300, 13, 50898], "temperature": 0.0, "avg_logprob": -0.18502235412597656, "compression_ratio": 1.8448275862068966, "no_speech_prob": 0.1639173924922943}, {"id": 520, "seek": 177544, "start": 1786.1200000000001, "end": 1789.28, "text": " I don't think the universe is little, you know, here's the way to put this.", "tokens": [50898, 286, 500, 380, 519, 264, 6445, 307, 707, 11, 291, 458, 11, 510, 311, 264, 636, 281, 829, 341, 13, 51056], "temperature": 0.0, "avg_logprob": -0.18502235412597656, "compression_ratio": 1.8448275862068966, "no_speech_prob": 0.1639173924922943}, {"id": 521, "seek": 177544, "start": 1789.28, "end": 1791.0800000000002, "text": " The universe is a computation.", "tokens": [51056, 440, 6445, 307, 257, 24903, 13, 51146], "temperature": 0.0, "avg_logprob": -0.18502235412597656, "compression_ratio": 1.8448275862068966, "no_speech_prob": 0.1639173924922943}, {"id": 522, "seek": 177544, "start": 1791.0800000000002, "end": 1795.1200000000001, "text": " Like, I don't know what the computer is or if there is one.", "tokens": [51146, 1743, 11, 286, 500, 380, 458, 437, 264, 3820, 307, 420, 498, 456, 307, 472, 13, 51348], "temperature": 0.0, "avg_logprob": -0.18502235412597656, "compression_ratio": 1.8448275862068966, "no_speech_prob": 0.1639173924922943}, {"id": 523, "seek": 177544, "start": 1795.1200000000001, "end": 1800.16, "text": " Now the universe is digital in the sense that deep down at the most basic level, the universe", "tokens": [51348, 823, 264, 6445, 307, 4562, 294, 264, 2020, 300, 2452, 760, 412, 264, 881, 3875, 1496, 11, 264, 6445, 51600], "temperature": 0.0, "avg_logprob": -0.18502235412597656, "compression_ratio": 1.8448275862068966, "no_speech_prob": 0.1639173924922943}, {"id": 524, "seek": 177544, "start": 1800.16, "end": 1802.1200000000001, "text": " is made of discrete things.", "tokens": [51600, 307, 1027, 295, 27706, 721, 13, 51698], "temperature": 0.0, "avg_logprob": -0.18502235412597656, "compression_ratio": 1.8448275862068966, "no_speech_prob": 0.1639173924922943}, {"id": 525, "seek": 180212, "start": 1802.36, "end": 1805.8799999999999, "text": " OK, is this like the it from bit, the John Wheeler type hypothesis?", "tokens": [50376, 2264, 11, 307, 341, 411, 264, 309, 490, 857, 11, 264, 2619, 17040, 6185, 2010, 17291, 30, 50552], "temperature": 0.0, "avg_logprob": -0.28248393535614014, "compression_ratio": 1.5770609318996416, "no_speech_prob": 0.04176665097475052}, {"id": 526, "seek": 180212, "start": 1806.9599999999998, "end": 1808.4399999999998, "text": " Yes.", "tokens": [50606, 1079, 13, 50680], "temperature": 0.0, "avg_logprob": -0.28248393535614014, "compression_ratio": 1.5770609318996416, "no_speech_prob": 0.04176665097475052}, {"id": 527, "seek": 180212, "start": 1808.4399999999998, "end": 1813.36, "text": " I mean, if you read that paper, it is, I mean, John Wheeler was a brilliant person.", "tokens": [50680, 286, 914, 11, 498, 291, 1401, 300, 3035, 11, 309, 307, 11, 286, 914, 11, 2619, 17040, 6185, 390, 257, 10248, 954, 13, 50926], "temperature": 0.0, "avg_logprob": -0.28248393535614014, "compression_ratio": 1.5770609318996416, "no_speech_prob": 0.04176665097475052}, {"id": 528, "seek": 180212, "start": 1814.28, "end": 1819.7199999999998, "text": " Again, very, you know, to get back to Fran\u00e7ois Chalice's tweet, he was very good at coming", "tokens": [50972, 3764, 11, 588, 11, 291, 458, 11, 281, 483, 646, 281, 1526, 12368, 7376, 761, 304, 573, 311, 15258, 11, 415, 390, 588, 665, 412, 1348, 51244], "temperature": 0.0, "avg_logprob": -0.28248393535614014, "compression_ratio": 1.5770609318996416, "no_speech_prob": 0.04176665097475052}, {"id": 529, "seek": 180212, "start": 1819.7199999999998, "end": 1821.76, "text": " up with his provocative notions, right?", "tokens": [51244, 493, 365, 702, 47663, 35799, 11, 558, 30, 51346], "temperature": 0.0, "avg_logprob": -0.28248393535614014, "compression_ratio": 1.5770609318996416, "no_speech_prob": 0.04176665097475052}, {"id": 530, "seek": 180212, "start": 1821.76, "end": 1825.04, "text": " And the it from the thing, of course, is like newly unveiled today.", "tokens": [51346, 400, 264, 309, 490, 264, 551, 11, 295, 1164, 11, 307, 411, 15109, 47430, 965, 13, 51510], "temperature": 0.0, "avg_logprob": -0.28248393535614014, "compression_ratio": 1.5770609318996416, "no_speech_prob": 0.04176665097475052}, {"id": 531, "seek": 180212, "start": 1825.4399999999998, "end": 1830.76, "text": " And I do so at that level, I do agree that looking at the universe is being made of", "tokens": [51530, 400, 286, 360, 370, 412, 300, 1496, 11, 286, 360, 3986, 300, 1237, 412, 264, 6445, 307, 885, 1027, 295, 51796], "temperature": 0.0, "avg_logprob": -0.28248393535614014, "compression_ratio": 1.5770609318996416, "no_speech_prob": 0.04176665097475052}, {"id": 532, "seek": 183076, "start": 1830.76, "end": 1832.96, "text": " information is very useful.", "tokens": [50364, 1589, 307, 588, 4420, 13, 50474], "temperature": 0.0, "avg_logprob": -0.1757376699736624, "compression_ratio": 1.7876106194690264, "no_speech_prob": 0.02575707621872425}, {"id": 533, "seek": 183076, "start": 1833.04, "end": 1838.52, "text": " And in particular, if you want a grand unified master algorithm, in some sense, the only", "tokens": [50478, 400, 294, 1729, 11, 498, 291, 528, 257, 2697, 26787, 4505, 9284, 11, 294, 512, 2020, 11, 264, 787, 50752], "temperature": 0.0, "avg_logprob": -0.1757376699736624, "compression_ratio": 1.7876106194690264, "no_speech_prob": 0.02575707621872425}, {"id": 534, "seek": 183076, "start": 1838.52, "end": 1843.12, "text": " way that I at least can see of doing that is by seeing everything as information.", "tokens": [50752, 636, 300, 286, 412, 1935, 393, 536, 295, 884, 300, 307, 538, 2577, 1203, 382, 1589, 13, 50982], "temperature": 0.0, "avg_logprob": -0.1757376699736624, "compression_ratio": 1.7876106194690264, "no_speech_prob": 0.02575707621872425}, {"id": 535, "seek": 183076, "start": 1843.68, "end": 1848.24, "text": " So I think, and if I do something that I am working on that, looking at everything as", "tokens": [51010, 407, 286, 519, 11, 293, 498, 286, 360, 746, 300, 286, 669, 1364, 322, 300, 11, 1237, 412, 1203, 382, 51238], "temperature": 0.0, "avg_logprob": -0.1757376699736624, "compression_ratio": 1.7876106194690264, "no_speech_prob": 0.02575707621872425}, {"id": 536, "seek": 183076, "start": 1848.24, "end": 1851.0, "text": " information is a very productive thing to do.", "tokens": [51238, 1589, 307, 257, 588, 13304, 551, 281, 360, 13, 51376], "temperature": 0.0, "avg_logprob": -0.1757376699736624, "compression_ratio": 1.7876106194690264, "no_speech_prob": 0.02575707621872425}, {"id": 537, "seek": 183076, "start": 1851.28, "end": 1857.04, "text": " Yeah, but but my caution is that information is one aspect of everything.", "tokens": [51390, 865, 11, 457, 457, 452, 23585, 307, 300, 1589, 307, 472, 4171, 295, 1203, 13, 51678], "temperature": 0.0, "avg_logprob": -0.1757376699736624, "compression_ratio": 1.7876106194690264, "no_speech_prob": 0.02575707621872425}, {"id": 538, "seek": 185704, "start": 1857.68, "end": 1860.96, "text": " So I can give you a theory of everything that's based on information.", "tokens": [50396, 407, 286, 393, 976, 291, 257, 5261, 295, 1203, 300, 311, 2361, 322, 1589, 13, 50560], "temperature": 0.0, "avg_logprob": -0.15113786441176685, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.03472353518009186}, {"id": 539, "seek": 185704, "start": 1861.3999999999999, "end": 1863.56, "text": " But it's not truly a theory of everything.", "tokens": [50582, 583, 309, 311, 406, 4908, 257, 5261, 295, 1203, 13, 50690], "temperature": 0.0, "avg_logprob": -0.15113786441176685, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.03472353518009186}, {"id": 540, "seek": 185704, "start": 1863.56, "end": 1865.52, "text": " It's a theory of one aspect of everything.", "tokens": [50690, 467, 311, 257, 5261, 295, 472, 4171, 295, 1203, 13, 50788], "temperature": 0.0, "avg_logprob": -0.15113786441176685, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.03472353518009186}, {"id": 541, "seek": 185704, "start": 1866.08, "end": 1867.52, "text": " And I think there's a lot to be done there.", "tokens": [50816, 400, 286, 519, 456, 311, 257, 688, 281, 312, 1096, 456, 13, 50888], "temperature": 0.0, "avg_logprob": -0.15113786441176685, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.03472353518009186}, {"id": 542, "seek": 185704, "start": 1867.52, "end": 1871.28, "text": " But again, we shouldn't forget what we're living out when we focus on that aspect.", "tokens": [50888, 583, 797, 11, 321, 4659, 380, 2870, 437, 321, 434, 2647, 484, 562, 321, 1879, 322, 300, 4171, 13, 51076], "temperature": 0.0, "avg_logprob": -0.15113786441176685, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.03472353518009186}, {"id": 543, "seek": 185704, "start": 1871.6399999999999, "end": 1873.92, "text": " Yeah, I mean, we've spoken a lot on the show about, you know,", "tokens": [51094, 865, 11, 286, 914, 11, 321, 600, 10759, 257, 688, 322, 264, 855, 466, 11, 291, 458, 11, 51208], "temperature": 0.0, "avg_logprob": -0.15113786441176685, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.03472353518009186}, {"id": 544, "seek": 185704, "start": 1874.48, "end": 1878.72, "text": " Penrose's view and obviously Sal's view that arises from from biology.", "tokens": [51236, 10571, 37841, 311, 1910, 293, 2745, 5996, 311, 1910, 300, 27388, 490, 490, 14956, 13, 51448], "temperature": 0.0, "avg_logprob": -0.15113786441176685, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.03472353518009186}, {"id": 545, "seek": 185704, "start": 1878.72, "end": 1882.68, "text": " And I know if Keith was here, he would argue strongly that he believes in in", "tokens": [51448, 400, 286, 458, 498, 20613, 390, 510, 11, 415, 576, 9695, 10613, 300, 415, 12307, 294, 294, 51646], "temperature": 0.0, "avg_logprob": -0.15113786441176685, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.03472353518009186}, {"id": 546, "seek": 188268, "start": 1882.68, "end": 1887.8400000000001, "text": " continuum, and therefore we would need, you know, hyper computation to have this", "tokens": [50364, 36120, 11, 293, 4412, 321, 576, 643, 11, 291, 458, 11, 9848, 24903, 281, 362, 341, 50622], "temperature": 0.0, "avg_logprob": -0.1751643235121316, "compression_ratio": 1.761437908496732, "no_speech_prob": 0.05905814468860626}, {"id": 547, "seek": 188268, "start": 1887.8400000000001, "end": 1891.16, "text": " universe. That would be an interesting discussion to have, because I really don't", "tokens": [50622, 6445, 13, 663, 576, 312, 364, 1880, 5017, 281, 362, 11, 570, 286, 534, 500, 380, 50788], "temperature": 0.0, "avg_logprob": -0.1751643235121316, "compression_ratio": 1.761437908496732, "no_speech_prob": 0.05905814468860626}, {"id": 548, "seek": 188268, "start": 1891.16, "end": 1895.44, "text": " see where there is physical or any evidence for continuum of any kind.", "tokens": [50788, 536, 689, 456, 307, 4001, 420, 604, 4467, 337, 36120, 295, 604, 733, 13, 51002], "temperature": 0.0, "avg_logprob": -0.1751643235121316, "compression_ratio": 1.761437908496732, "no_speech_prob": 0.05905814468860626}, {"id": 549, "seek": 188268, "start": 1895.68, "end": 1899.88, "text": " The evidence is always that continuum are a useful approximation, but always", "tokens": [51014, 440, 4467, 307, 1009, 300, 36120, 366, 257, 4420, 28023, 11, 457, 1009, 51224], "temperature": 0.0, "avg_logprob": -0.1751643235121316, "compression_ratio": 1.761437908496732, "no_speech_prob": 0.05905814468860626}, {"id": 550, "seek": 188268, "start": 1899.88, "end": 1902.0, "text": " underlying the continuum is a discrete reality.", "tokens": [51224, 14217, 264, 36120, 307, 257, 27706, 4103, 13, 51330], "temperature": 0.0, "avg_logprob": -0.1751643235121316, "compression_ratio": 1.761437908496732, "no_speech_prob": 0.05905814468860626}, {"id": 551, "seek": 188268, "start": 1902.24, "end": 1904.88, "text": " You take a sensor of anything, right?", "tokens": [51342, 509, 747, 257, 10200, 295, 1340, 11, 558, 30, 51474], "temperature": 0.0, "avg_logprob": -0.1751643235121316, "compression_ratio": 1.761437908496732, "no_speech_prob": 0.05905814468860626}, {"id": 552, "seek": 188268, "start": 1904.88, "end": 1908.0800000000002, "text": " You know, quantum mechanics is like the quintessential example of this, right?", "tokens": [51474, 509, 458, 11, 13018, 12939, 307, 411, 264, 40006, 48143, 1365, 295, 341, 11, 558, 30, 51634], "temperature": 0.0, "avg_logprob": -0.1751643235121316, "compression_ratio": 1.761437908496732, "no_speech_prob": 0.05905814468860626}, {"id": 553, "seek": 188268, "start": 1908.52, "end": 1912.24, "text": " What do we measure at the end that it's always discrete events?", "tokens": [51656, 708, 360, 321, 3481, 412, 264, 917, 300, 309, 311, 1009, 27706, 3931, 30, 51842], "temperature": 0.0, "avg_logprob": -0.1751643235121316, "compression_ratio": 1.761437908496732, "no_speech_prob": 0.05905814468860626}, {"id": 554, "seek": 191268, "start": 1912.68, "end": 1918.96, "text": " Right? Like it's the detection of a photon by, you know, by whatever detector, right?", "tokens": [50364, 1779, 30, 1743, 309, 311, 264, 17784, 295, 257, 37443, 538, 11, 291, 458, 11, 538, 2035, 25712, 11, 558, 30, 50678], "temperature": 0.0, "avg_logprob": -0.2221592630658831, "compression_ratio": 1.6342281879194631, "no_speech_prob": 0.001801521284505725}, {"id": 555, "seek": 191268, "start": 1918.96, "end": 1921.5600000000002, "text": " Could be a model of Dobson or a CCD or whatever.", "tokens": [50678, 7497, 312, 257, 2316, 295, 1144, 929, 266, 420, 257, 12630, 35, 420, 2035, 13, 50808], "temperature": 0.0, "avg_logprob": -0.2221592630658831, "compression_ratio": 1.6342281879194631, "no_speech_prob": 0.001801521284505725}, {"id": 556, "seek": 191268, "start": 1921.8, "end": 1923.64, "text": " But it's a it's a it's a change of state.", "tokens": [50820, 583, 309, 311, 257, 309, 311, 257, 309, 311, 257, 1319, 295, 1785, 13, 50912], "temperature": 0.0, "avg_logprob": -0.2221592630658831, "compression_ratio": 1.6342281879194631, "no_speech_prob": 0.001801521284505725}, {"id": 557, "seek": 191268, "start": 1923.64, "end": 1924.68, "text": " It really is a bit.", "tokens": [50912, 467, 534, 307, 257, 857, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2221592630658831, "compression_ratio": 1.6342281879194631, "no_speech_prob": 0.001801521284505725}, {"id": 558, "seek": 191268, "start": 1925.3200000000002, "end": 1927.0800000000002, "text": " Oh, interesting. Well, how would you contrast that?", "tokens": [50996, 876, 11, 1880, 13, 1042, 11, 577, 576, 291, 8712, 300, 30, 51084], "temperature": 0.0, "avg_logprob": -0.2221592630658831, "compression_ratio": 1.6342281879194631, "no_speech_prob": 0.001801521284505725}, {"id": 559, "seek": 191268, "start": 1927.0800000000002, "end": 1930.96, "text": " You know, Stephen Wolfram has got this idea of of digital physics and, you know,", "tokens": [51084, 509, 458, 11, 13391, 16634, 2356, 575, 658, 341, 1558, 295, 295, 4562, 10649, 293, 11, 291, 458, 11, 51278], "temperature": 0.0, "avg_logprob": -0.2221592630658831, "compression_ratio": 1.6342281879194631, "no_speech_prob": 0.001801521284505725}, {"id": 560, "seek": 191268, "start": 1931.28, "end": 1935.72, "text": " maybe and again, unfortunately, we have to use arguments from behavior, you know,", "tokens": [51294, 1310, 293, 797, 11, 7015, 11, 321, 362, 281, 764, 12869, 490, 5223, 11, 291, 458, 11, 51516], "temperature": 0.0, "avg_logprob": -0.2221592630658831, "compression_ratio": 1.6342281879194631, "no_speech_prob": 0.001801521284505725}, {"id": 561, "seek": 191268, "start": 1935.72, "end": 1939.44, "text": " to kind of say, well, we've we've got potentially a graph cellular automata", "tokens": [51516, 281, 733, 295, 584, 11, 731, 11, 321, 600, 321, 600, 658, 7263, 257, 4295, 29267, 3553, 3274, 51702], "temperature": 0.0, "avg_logprob": -0.2221592630658831, "compression_ratio": 1.6342281879194631, "no_speech_prob": 0.001801521284505725}, {"id": 562, "seek": 193944, "start": 1939.68, "end": 1943.28, "text": " and it creates this beautiful emergent structure, which is very much like the universe.", "tokens": [50376, 293, 309, 7829, 341, 2238, 4345, 6930, 3877, 11, 597, 307, 588, 709, 411, 264, 6445, 13, 50556], "temperature": 0.0, "avg_logprob": -0.1406469673945986, "compression_ratio": 1.64, "no_speech_prob": 0.004179434850811958}, {"id": 563, "seek": 193944, "start": 1944.1200000000001, "end": 1948.76, "text": " But, you know, Scott Aronson would make the argument that he's discounting quantum mechanics.", "tokens": [50598, 583, 11, 291, 458, 11, 6659, 1587, 892, 266, 576, 652, 264, 6770, 300, 415, 311, 11635, 278, 13018, 12939, 13, 50830], "temperature": 0.0, "avg_logprob": -0.1406469673945986, "compression_ratio": 1.64, "no_speech_prob": 0.004179434850811958}, {"id": 564, "seek": 193944, "start": 1948.76, "end": 1951.24, "text": " I mean, what would you say to that?", "tokens": [50830, 286, 914, 11, 437, 576, 291, 584, 281, 300, 30, 50954], "temperature": 0.0, "avg_logprob": -0.1406469673945986, "compression_ratio": 1.64, "no_speech_prob": 0.004179434850811958}, {"id": 565, "seek": 193944, "start": 1951.24, "end": 1955.8, "text": " So I think Steve Wolfram's theory is very interesting.", "tokens": [50954, 407, 286, 519, 7466, 16634, 2356, 311, 5261, 307, 588, 1880, 13, 51182], "temperature": 0.0, "avg_logprob": -0.1406469673945986, "compression_ratio": 1.64, "no_speech_prob": 0.004179434850811958}, {"id": 566, "seek": 193944, "start": 1956.28, "end": 1959.56, "text": " And he gets some things right that a lot of other physicists don't,", "tokens": [51206, 400, 415, 2170, 512, 721, 558, 300, 257, 688, 295, 661, 48716, 500, 380, 11, 51370], "temperature": 0.0, "avg_logprob": -0.1406469673945986, "compression_ratio": 1.64, "no_speech_prob": 0.004179434850811958}, {"id": 567, "seek": 193944, "start": 1960.44, "end": 1963.6000000000001, "text": " in particular, that the universe at heart is discrete.", "tokens": [51414, 294, 1729, 11, 300, 264, 6445, 412, 1917, 307, 27706, 13, 51572], "temperature": 0.0, "avg_logprob": -0.1406469673945986, "compression_ratio": 1.64, "no_speech_prob": 0.004179434850811958}, {"id": 568, "seek": 193944, "start": 1964.3600000000001, "end": 1967.3200000000002, "text": " So I'm very much with him on that aspect of his agenda.", "tokens": [51610, 407, 286, 478, 588, 709, 365, 796, 322, 300, 4171, 295, 702, 9829, 13, 51758], "temperature": 0.0, "avg_logprob": -0.1406469673945986, "compression_ratio": 1.64, "no_speech_prob": 0.004179434850811958}, {"id": 569, "seek": 196732, "start": 1968.32, "end": 1971.24, "text": " And thank God there's someone like him and a number of others,", "tokens": [50414, 400, 1309, 1265, 456, 311, 1580, 411, 796, 293, 257, 1230, 295, 2357, 11, 50560], "temperature": 0.0, "avg_logprob": -0.19900805609566824, "compression_ratio": 1.7348993288590604, "no_speech_prob": 0.0022485728841274977}, {"id": 570, "seek": 196732, "start": 1971.96, "end": 1973.6399999999999, "text": " you know, going that route, right?", "tokens": [50596, 291, 458, 11, 516, 300, 7955, 11, 558, 30, 50680], "temperature": 0.0, "avg_logprob": -0.19900805609566824, "compression_ratio": 1.7348993288590604, "no_speech_prob": 0.0022485728841274977}, {"id": 571, "seek": 196732, "start": 1973.6399999999999, "end": 1975.24, "text": " They're the minority in physics.", "tokens": [50680, 814, 434, 264, 16166, 294, 10649, 13, 50760], "temperature": 0.0, "avg_logprob": -0.19900805609566824, "compression_ratio": 1.7348993288590604, "no_speech_prob": 0.0022485728841274977}, {"id": 572, "seek": 196732, "start": 1975.24, "end": 1978.12, "text": " But actually, I think if you look at just what has happened in the last 10 years,", "tokens": [50760, 583, 767, 11, 286, 519, 498, 291, 574, 412, 445, 437, 575, 2011, 294, 264, 1036, 1266, 924, 11, 50904], "temperature": 0.0, "avg_logprob": -0.19900805609566824, "compression_ratio": 1.7348993288590604, "no_speech_prob": 0.0022485728841274977}, {"id": 573, "seek": 196732, "start": 1978.32, "end": 1980.1599999999999, "text": " things are very much moving in this direction.", "tokens": [50914, 721, 366, 588, 709, 2684, 294, 341, 3513, 13, 51006], "temperature": 0.0, "avg_logprob": -0.19900805609566824, "compression_ratio": 1.7348993288590604, "no_speech_prob": 0.0022485728841274977}, {"id": 574, "seek": 196732, "start": 1980.28, "end": 1982.3999999999999, "text": " And I think they're going to move more, right?", "tokens": [51012, 400, 286, 519, 436, 434, 516, 281, 1286, 544, 11, 558, 30, 51118], "temperature": 0.0, "avg_logprob": -0.19900805609566824, "compression_ratio": 1.7348993288590604, "no_speech_prob": 0.0022485728841274977}, {"id": 575, "seek": 196732, "start": 1982.72, "end": 1987.6799999999998, "text": " Now, having said that, his specific theory, I think has a lot of shortcomings.", "tokens": [51134, 823, 11, 1419, 848, 300, 11, 702, 2685, 5261, 11, 286, 519, 575, 257, 688, 295, 2099, 49886, 13, 51382], "temperature": 0.0, "avg_logprob": -0.19900805609566824, "compression_ratio": 1.7348993288590604, "no_speech_prob": 0.0022485728841274977}, {"id": 576, "seek": 196732, "start": 1988.52, "end": 1993.84, "text": " And I don't think it's the ultimate theory or maybe even the best path to a theory,", "tokens": [51424, 400, 286, 500, 380, 519, 309, 311, 264, 9705, 5261, 420, 1310, 754, 264, 1151, 3100, 281, 257, 5261, 11, 51690], "temperature": 0.0, "avg_logprob": -0.19900805609566824, "compression_ratio": 1.7348993288590604, "no_speech_prob": 0.0022485728841274977}, {"id": 577, "seek": 196732, "start": 1994.6, "end": 1996.2, "text": " you know, to a discrete theory of the universe.", "tokens": [51728, 291, 458, 11, 281, 257, 27706, 5261, 295, 264, 6445, 13, 51808], "temperature": 0.0, "avg_logprob": -0.19900805609566824, "compression_ratio": 1.7348993288590604, "no_speech_prob": 0.0022485728841274977}, {"id": 578, "seek": 199620, "start": 1996.64, "end": 2002.1200000000001, "text": " Scott Aaronson's critique in that regard, I think misses the point, right?", "tokens": [50386, 6659, 316, 289, 892, 266, 311, 25673, 294, 300, 3843, 11, 286, 519, 29394, 264, 935, 11, 558, 30, 50660], "temperature": 0.0, "avg_logprob": -0.18902763763031402, "compression_ratio": 1.840255591054313, "no_speech_prob": 0.012967068701982498}, {"id": 579, "seek": 199620, "start": 2002.44, "end": 2004.8400000000001, "text": " It's interesting because it's interesting that you should like pair those two", "tokens": [50676, 467, 311, 1880, 570, 309, 311, 1880, 300, 291, 820, 411, 6119, 729, 732, 50796], "temperature": 0.0, "avg_logprob": -0.18902763763031402, "compression_ratio": 1.840255591054313, "no_speech_prob": 0.012967068701982498}, {"id": 580, "seek": 199620, "start": 2004.8400000000001, "end": 2008.8, "text": " because Steve Wolfram, in a way, is a physicist to become a computer scientist.", "tokens": [50796, 570, 7466, 16634, 2356, 11, 294, 257, 636, 11, 307, 257, 42466, 281, 1813, 257, 3820, 12662, 13, 50994], "temperature": 0.0, "avg_logprob": -0.18902763763031402, "compression_ratio": 1.840255591054313, "no_speech_prob": 0.012967068701982498}, {"id": 581, "seek": 199620, "start": 2008.8, "end": 2010.64, "text": " And Scott is the other way around, right?", "tokens": [50994, 400, 6659, 307, 264, 661, 636, 926, 11, 558, 30, 51086], "temperature": 0.0, "avg_logprob": -0.18902763763031402, "compression_ratio": 1.840255591054313, "no_speech_prob": 0.012967068701982498}, {"id": 582, "seek": 199620, "start": 2010.8400000000001, "end": 2012.92, "text": " And I think, you know, like I greatly admire both of them", "tokens": [51096, 400, 286, 519, 11, 291, 458, 11, 411, 286, 14147, 21951, 1293, 295, 552, 51200], "temperature": 0.0, "avg_logprob": -0.18902763763031402, "compression_ratio": 1.840255591054313, "no_speech_prob": 0.012967068701982498}, {"id": 583, "seek": 199620, "start": 2012.92, "end": 2014.4, "text": " and I'm friends with both of them.", "tokens": [51200, 293, 286, 478, 1855, 365, 1293, 295, 552, 13, 51274], "temperature": 0.0, "avg_logprob": -0.18902763763031402, "compression_ratio": 1.840255591054313, "no_speech_prob": 0.012967068701982498}, {"id": 584, "seek": 199620, "start": 2014.4, "end": 2016.4, "text": " I've had many discussions with them.", "tokens": [51274, 286, 600, 632, 867, 11088, 365, 552, 13, 51374], "temperature": 0.0, "avg_logprob": -0.18902763763031402, "compression_ratio": 1.840255591054313, "no_speech_prob": 0.012967068701982498}, {"id": 585, "seek": 199620, "start": 2016.4, "end": 2020.8, "text": " I think, you know, just to very, you know, cruelly caricature things in a way,", "tokens": [51374, 286, 519, 11, 291, 458, 11, 445, 281, 588, 11, 291, 458, 11, 941, 622, 13020, 45732, 1503, 721, 294, 257, 636, 11, 51594], "temperature": 0.0, "avg_logprob": -0.18902763763031402, "compression_ratio": 1.840255591054313, "no_speech_prob": 0.012967068701982498}, {"id": 586, "seek": 199620, "start": 2020.8, "end": 2024.32, "text": " the problem with Steve is that he has bought into the computer science", "tokens": [51594, 264, 1154, 365, 7466, 307, 300, 415, 575, 4243, 666, 264, 3820, 3497, 51770], "temperature": 0.0, "avg_logprob": -0.18902763763031402, "compression_ratio": 1.840255591054313, "no_speech_prob": 0.012967068701982498}, {"id": 587, "seek": 199620, "start": 2024.32, "end": 2025.96, "text": " assumptions too much.", "tokens": [51770, 17695, 886, 709, 13, 51852], "temperature": 0.0, "avg_logprob": -0.18902763763031402, "compression_ratio": 1.840255591054313, "no_speech_prob": 0.012967068701982498}, {"id": 588, "seek": 202596, "start": 2025.96, "end": 2029.4, "text": " And the problem with Scott is that he has bought into the quantum physics", "tokens": [50364, 400, 264, 1154, 365, 6659, 307, 300, 415, 575, 4243, 666, 264, 13018, 10649, 50536], "temperature": 0.0, "avg_logprob": -0.12115800191485693, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.0012619824847206473}, {"id": 589, "seek": 202596, "start": 2029.4, "end": 2030.76, "text": " assumptions too much, right?", "tokens": [50536, 17695, 886, 709, 11, 558, 30, 50604], "temperature": 0.0, "avg_logprob": -0.12115800191485693, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.0012619824847206473}, {"id": 590, "seek": 202596, "start": 2030.76, "end": 2034.2, "text": " So if you really think carefully and rigorously about quantum mechanics,", "tokens": [50604, 407, 498, 291, 534, 519, 7500, 293, 42191, 5098, 466, 13018, 12939, 11, 50776], "temperature": 0.0, "avg_logprob": -0.12115800191485693, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.0012619824847206473}, {"id": 591, "seek": 202596, "start": 2034.48, "end": 2039.48, "text": " all that continuous mathematics is there just to make discrete predictions.", "tokens": [50790, 439, 300, 10957, 18666, 307, 456, 445, 281, 652, 27706, 21264, 13, 51040], "temperature": 0.0, "avg_logprob": -0.12115800191485693, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.0012619824847206473}, {"id": 592, "seek": 202596, "start": 2040.28, "end": 2041.76, "text": " So the continuity may be useful.", "tokens": [51080, 407, 264, 23807, 815, 312, 4420, 13, 51154], "temperature": 0.0, "avg_logprob": -0.12115800191485693, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.0012619824847206473}, {"id": 593, "seek": 202596, "start": 2041.76, "end": 2042.52, "text": " It is useful.", "tokens": [51154, 467, 307, 4420, 13, 51192], "temperature": 0.0, "avg_logprob": -0.12115800191485693, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.0012619824847206473}, {"id": 594, "seek": 202596, "start": 2042.52, "end": 2045.64, "text": " I'm not arguing against the use of continuity and infinity in our mathematics.", "tokens": [51192, 286, 478, 406, 19697, 1970, 264, 764, 295, 23807, 293, 13202, 294, 527, 18666, 13, 51348], "temperature": 0.0, "avg_logprob": -0.12115800191485693, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.0012619824847206473}, {"id": 595, "seek": 202596, "start": 2045.64, "end": 2047.52, "text": " In fact, we'd be nowhere if we didn't have it.", "tokens": [51348, 682, 1186, 11, 321, 1116, 312, 11159, 498, 321, 994, 380, 362, 309, 13, 51442], "temperature": 0.0, "avg_logprob": -0.12115800191485693, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.0012619824847206473}, {"id": 596, "seek": 202596, "start": 2047.76, "end": 2050.12, "text": " We just have to remember that it's an approximation.", "tokens": [51454, 492, 445, 362, 281, 1604, 300, 309, 311, 364, 28023, 13, 51572], "temperature": 0.0, "avg_logprob": -0.12115800191485693, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.0012619824847206473}, {"id": 597, "seek": 202596, "start": 2050.12, "end": 2051.88, "text": " It's a useful fiction, right?", "tokens": [51572, 467, 311, 257, 4420, 13266, 11, 558, 30, 51660], "temperature": 0.0, "avg_logprob": -0.12115800191485693, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.0012619824847206473}, {"id": 598, "seek": 205188, "start": 2051.92, "end": 2058.7200000000003, "text": " So quantum mechanics in no way invalidates Steve Wolf from theories, right?", "tokens": [50366, 407, 13018, 12939, 294, 572, 636, 34702, 1024, 7466, 16634, 490, 13667, 11, 558, 30, 50706], "temperature": 0.0, "avg_logprob": -0.17652577461956218, "compression_ratio": 1.7804054054054055, "no_speech_prob": 0.0016727152979001403}, {"id": 599, "seek": 205188, "start": 2059.28, "end": 2062.0, "text": " The problem, however, is that he has not entirely, you know,", "tokens": [50734, 440, 1154, 11, 4461, 11, 307, 300, 415, 575, 406, 7696, 11, 291, 458, 11, 50870], "temperature": 0.0, "avg_logprob": -0.17652577461956218, "compression_ratio": 1.7804054054054055, "no_speech_prob": 0.0016727152979001403}, {"id": 600, "seek": 205188, "start": 2062.36, "end": 2064.32, "text": " ever since cellular automata days, right?", "tokens": [50888, 1562, 1670, 29267, 3553, 3274, 1708, 11, 558, 30, 50986], "temperature": 0.0, "avg_logprob": -0.17652577461956218, "compression_ratio": 1.7804054054054055, "no_speech_prob": 0.0016727152979001403}, {"id": 601, "seek": 205188, "start": 2064.32, "end": 2066.8, "text": " He was always saying like, oh, you know, the laws of physics will come out", "tokens": [50986, 634, 390, 1009, 1566, 411, 11, 1954, 11, 291, 458, 11, 264, 6064, 295, 10649, 486, 808, 484, 51110], "temperature": 0.0, "avg_logprob": -0.17652577461956218, "compression_ratio": 1.7804054054054055, "no_speech_prob": 0.0016727152979001403}, {"id": 602, "seek": 205188, "start": 2066.8, "end": 2068.08, "text": " of this cellular automata, right?", "tokens": [51110, 295, 341, 29267, 3553, 3274, 11, 558, 30, 51174], "temperature": 0.0, "avg_logprob": -0.17652577461956218, "compression_ratio": 1.7804054054054055, "no_speech_prob": 0.0016727152979001403}, {"id": 603, "seek": 205188, "start": 2068.08, "end": 2070.44, "text": " And people had these objections and, and, you know,", "tokens": [51174, 400, 561, 632, 613, 44649, 293, 11, 293, 11, 291, 458, 11, 51292], "temperature": 0.0, "avg_logprob": -0.17652577461956218, "compression_ratio": 1.7804054054054055, "no_speech_prob": 0.0016727152979001403}, {"id": 604, "seek": 205188, "start": 2070.44, "end": 2072.56, "text": " now he and others have partly answered some of them.", "tokens": [51292, 586, 415, 293, 2357, 362, 17031, 10103, 512, 295, 552, 13, 51398], "temperature": 0.0, "avg_logprob": -0.17652577461956218, "compression_ratio": 1.7804054054054055, "no_speech_prob": 0.0016727152979001403}, {"id": 605, "seek": 205188, "start": 2072.56, "end": 2075.96, "text": " But the truth is at the end of the day, he the only way to answer", "tokens": [51398, 583, 264, 3494, 307, 412, 264, 917, 295, 264, 786, 11, 415, 264, 787, 636, 281, 1867, 51568], "temperature": 0.0, "avg_logprob": -0.17652577461956218, "compression_ratio": 1.7804054054054055, "no_speech_prob": 0.0016727152979001403}, {"id": 606, "seek": 205188, "start": 2075.96, "end": 2079.6800000000003, "text": " that objection is to say, look, here is how quantum mechanics arises", "tokens": [51568, 300, 35756, 307, 281, 584, 11, 574, 11, 510, 307, 577, 13018, 12939, 27388, 51754], "temperature": 0.0, "avg_logprob": -0.17652577461956218, "compression_ratio": 1.7804054054054055, "no_speech_prob": 0.0016727152979001403}, {"id": 607, "seek": 207968, "start": 2079.68, "end": 2081.7999999999997, "text": " from my discrete model of the world.", "tokens": [50364, 490, 452, 27706, 2316, 295, 264, 1002, 13, 50470], "temperature": 0.0, "avg_logprob": -0.15618321719585648, "compression_ratio": 1.6196319018404908, "no_speech_prob": 0.013777678832411766}, {"id": 608, "seek": 207968, "start": 2081.7999999999997, "end": 2085.04, "text": " And I think this will happen, but it hasn't happened yet.", "tokens": [50470, 400, 286, 519, 341, 486, 1051, 11, 457, 309, 6132, 380, 2011, 1939, 13, 50632], "temperature": 0.0, "avg_logprob": -0.15618321719585648, "compression_ratio": 1.6196319018404908, "no_speech_prob": 0.013777678832411766}, {"id": 609, "seek": 207968, "start": 2085.24, "end": 2087.3999999999996, "text": " Interesting. OK, we'd love to get Steven on the show.", "tokens": [50642, 14711, 13, 2264, 11, 321, 1116, 959, 281, 483, 12754, 322, 264, 855, 13, 50750], "temperature": 0.0, "avg_logprob": -0.15618321719585648, "compression_ratio": 1.6196319018404908, "no_speech_prob": 0.013777678832411766}, {"id": 610, "seek": 207968, "start": 2087.3999999999996, "end": 2089.72, "text": " Actually, he's got a he's got a new book out now,", "tokens": [50750, 5135, 11, 415, 311, 658, 257, 415, 311, 658, 257, 777, 1446, 484, 586, 11, 50866], "temperature": 0.0, "avg_logprob": -0.15618321719585648, "compression_ratio": 1.6196319018404908, "no_speech_prob": 0.013777678832411766}, {"id": 611, "seek": 207968, "start": 2089.72, "end": 2092.2, "text": " which is kind of like expanding on his previous work.", "tokens": [50866, 597, 307, 733, 295, 411, 14702, 322, 702, 3894, 589, 13, 50990], "temperature": 0.0, "avg_logprob": -0.15618321719585648, "compression_ratio": 1.6196319018404908, "no_speech_prob": 0.013777678832411766}, {"id": 612, "seek": 207968, "start": 2092.6, "end": 2097.16, "text": " But OK, I was having a chat with some alignment folks yesterday.", "tokens": [51010, 583, 2264, 11, 286, 390, 1419, 257, 5081, 365, 512, 18515, 4024, 5186, 13, 51238], "temperature": 0.0, "avg_logprob": -0.15618321719585648, "compression_ratio": 1.6196319018404908, "no_speech_prob": 0.013777678832411766}, {"id": 613, "seek": 207968, "start": 2097.2, "end": 2101.0, "text": " And it's something that I'm a bit naive to, but as I said, I've just read a book.", "tokens": [51240, 400, 309, 311, 746, 300, 286, 478, 257, 857, 29052, 281, 11, 457, 382, 286, 848, 11, 286, 600, 445, 1401, 257, 1446, 13, 51430], "temperature": 0.0, "avg_logprob": -0.15618321719585648, "compression_ratio": 1.6196319018404908, "no_speech_prob": 0.013777678832411766}, {"id": 614, "seek": 207968, "start": 2101.3599999999997, "end": 2104.52, "text": " I think it's called The Rationalists Guide to the to the Universe.", "tokens": [51448, 286, 519, 309, 311, 1219, 440, 497, 1478, 1751, 18727, 281, 264, 281, 264, 18307, 13, 51606], "temperature": 0.0, "avg_logprob": -0.15618321719585648, "compression_ratio": 1.6196319018404908, "no_speech_prob": 0.013777678832411766}, {"id": 615, "seek": 207968, "start": 2104.8399999999997, "end": 2107.64, "text": " And it kind of talks all about the the early embryonic stages", "tokens": [51622, 400, 309, 733, 295, 6686, 439, 466, 264, 264, 2440, 31588, 11630, 10232, 51762], "temperature": 0.0, "avg_logprob": -0.15618321719585648, "compression_ratio": 1.6196319018404908, "no_speech_prob": 0.013777678832411766}, {"id": 616, "seek": 210764, "start": 2107.64, "end": 2110.96, "text": " of Robin Hansen and Nick Bostrom and Eliezer Yuckowski", "tokens": [50364, 295, 16533, 17926, 268, 293, 9449, 363, 555, 4397, 293, 2699, 414, 4527, 398, 1134, 21866, 50530], "temperature": 0.0, "avg_logprob": -0.24423949471835432, "compression_ratio": 1.583969465648855, "no_speech_prob": 0.0030460080597549677}, {"id": 617, "seek": 210764, "start": 2110.96, "end": 2113.72, "text": " and the Les Ron community and, you know, the info hazards.", "tokens": [50530, 293, 264, 6965, 9949, 1768, 293, 11, 291, 458, 11, 264, 13614, 34516, 13, 50668], "temperature": 0.0, "avg_logprob": -0.24423949471835432, "compression_ratio": 1.583969465648855, "no_speech_prob": 0.0030460080597549677}, {"id": 618, "seek": 210764, "start": 2113.72, "end": 2116.7999999999997, "text": " And, you know, I don't know if you've heard of Rocco's Basilicist", "tokens": [50668, 400, 11, 291, 458, 11, 286, 500, 380, 458, 498, 291, 600, 2198, 295, 32661, 1291, 311, 43175, 299, 468, 50822], "temperature": 0.0, "avg_logprob": -0.24423949471835432, "compression_ratio": 1.583969465648855, "no_speech_prob": 0.0030460080597549677}, {"id": 619, "seek": 210764, "start": 2116.7999999999997, "end": 2118.96, "text": " and all of this line of thought, basically.", "tokens": [50822, 293, 439, 295, 341, 1622, 295, 1194, 11, 1936, 13, 50930], "temperature": 0.0, "avg_logprob": -0.24423949471835432, "compression_ratio": 1.583969465648855, "no_speech_prob": 0.0030460080597549677}, {"id": 620, "seek": 210764, "start": 2119.3199999999997, "end": 2122.08, "text": " And yeah, so where to go with this?", "tokens": [50948, 400, 1338, 11, 370, 689, 281, 352, 365, 341, 30, 51086], "temperature": 0.0, "avg_logprob": -0.24423949471835432, "compression_ratio": 1.583969465648855, "no_speech_prob": 0.0030460080597549677}, {"id": 621, "seek": 210764, "start": 2122.08, "end": 2127.72, "text": " Now, I kind of put forward that part of my problem with their conception", "tokens": [51086, 823, 11, 286, 733, 295, 829, 2128, 300, 644, 295, 452, 1154, 365, 641, 30698, 51368], "temperature": 0.0, "avg_logprob": -0.24423949471835432, "compression_ratio": 1.583969465648855, "no_speech_prob": 0.0030460080597549677}, {"id": 622, "seek": 210764, "start": 2127.72, "end": 2133.48, "text": " is that it relies on this rational agent making trajectories of optimal decisions.", "tokens": [51368, 307, 300, 309, 30910, 322, 341, 15090, 9461, 1455, 18257, 2083, 295, 16252, 5327, 13, 51656], "temperature": 0.0, "avg_logprob": -0.24423949471835432, "compression_ratio": 1.583969465648855, "no_speech_prob": 0.0030460080597549677}, {"id": 623, "seek": 213348, "start": 2133.88, "end": 2137.72, "text": " And also, they they tend to be utilitarianism", "tokens": [50384, 400, 611, 11, 436, 436, 3928, 281, 312, 4976, 13707, 1434, 50576], "temperature": 0.0, "avg_logprob": -0.20940770705540976, "compression_ratio": 1.5942028985507246, "no_speech_prob": 0.005543328355997801}, {"id": 624, "seek": 213348, "start": 2137.72, "end": 2140.72, "text": " and utilitarianists and consequentialists.", "tokens": [50576, 293, 4976, 13707, 1751, 293, 7242, 2549, 1751, 13, 50726], "temperature": 0.0, "avg_logprob": -0.20940770705540976, "compression_ratio": 1.5942028985507246, "no_speech_prob": 0.005543328355997801}, {"id": 625, "seek": 213348, "start": 2141.12, "end": 2144.72, "text": " And yeah, I just wondered, what's your kind of like high level take on this?", "tokens": [50746, 400, 1338, 11, 286, 445, 17055, 11, 437, 311, 428, 733, 295, 411, 1090, 1496, 747, 322, 341, 30, 50926], "temperature": 0.0, "avg_logprob": -0.20940770705540976, "compression_ratio": 1.5942028985507246, "no_speech_prob": 0.005543328355997801}, {"id": 626, "seek": 213348, "start": 2146.16, "end": 2148.88, "text": " Well, there's many aspects to this, right?", "tokens": [50998, 1042, 11, 456, 311, 867, 7270, 281, 341, 11, 558, 30, 51134], "temperature": 0.0, "avg_logprob": -0.20940770705540976, "compression_ratio": 1.5942028985507246, "no_speech_prob": 0.005543328355997801}, {"id": 627, "seek": 213348, "start": 2148.88, "end": 2151.76, "text": " I think let me put it this way.", "tokens": [51134, 286, 519, 718, 385, 829, 309, 341, 636, 13, 51278], "temperature": 0.0, "avg_logprob": -0.20940770705540976, "compression_ratio": 1.5942028985507246, "no_speech_prob": 0.005543328355997801}, {"id": 628, "seek": 213348, "start": 2151.76, "end": 2157.16, "text": " I. A rational agent, right, is an agent that maximizes", "tokens": [51278, 286, 13, 316, 15090, 9461, 11, 558, 11, 307, 364, 9461, 300, 5138, 5660, 51548], "temperature": 0.0, "avg_logprob": -0.20940770705540976, "compression_ratio": 1.5942028985507246, "no_speech_prob": 0.005543328355997801}, {"id": 629, "seek": 213348, "start": 2157.88, "end": 2159.92, "text": " maximizes expected utility, right?", "tokens": [51584, 5138, 5660, 5176, 14877, 11, 558, 30, 51686], "temperature": 0.0, "avg_logprob": -0.20940770705540976, "compression_ratio": 1.5942028985507246, "no_speech_prob": 0.005543328355997801}, {"id": 630, "seek": 215992, "start": 2159.96, "end": 2163.36, "text": " The definition of rationality is that it's, you know,", "tokens": [50366, 440, 7123, 295, 15090, 507, 307, 300, 309, 311, 11, 291, 458, 11, 50536], "temperature": 0.0, "avg_logprob": -0.19749543364618866, "compression_ratio": 1.9128787878787878, "no_speech_prob": 0.003212836803868413}, {"id": 631, "seek": 215992, "start": 2163.36, "end": 2165.6800000000003, "text": " expected utility maximization, right?", "tokens": [50536, 5176, 14877, 5138, 2144, 11, 558, 30, 50652], "temperature": 0.0, "avg_logprob": -0.19749543364618866, "compression_ratio": 1.9128787878787878, "no_speech_prob": 0.003212836803868413}, {"id": 632, "seek": 215992, "start": 2165.92, "end": 2168.4, "text": " And there is a lot of content to this, right?", "tokens": [50664, 400, 456, 307, 257, 688, 295, 2701, 281, 341, 11, 558, 30, 50788], "temperature": 0.0, "avg_logprob": -0.19749543364618866, "compression_ratio": 1.9128787878787878, "no_speech_prob": 0.003212836803868413}, {"id": 633, "seek": 215992, "start": 2168.4, "end": 2172.4, "text": " And, you know, people in many fields like economics and and and, you know, AI, right?", "tokens": [50788, 400, 11, 291, 458, 11, 561, 294, 867, 7909, 411, 14564, 293, 293, 293, 11, 291, 458, 11, 7318, 11, 558, 30, 50988], "temperature": 0.0, "avg_logprob": -0.19749543364618866, "compression_ratio": 1.9128787878787878, "no_speech_prob": 0.003212836803868413}, {"id": 634, "seek": 215992, "start": 2172.84, "end": 2174.4, "text": " They make good use of it.", "tokens": [51010, 814, 652, 665, 764, 295, 309, 13, 51088], "temperature": 0.0, "avg_logprob": -0.19749543364618866, "compression_ratio": 1.9128787878787878, "no_speech_prob": 0.003212836803868413}, {"id": 635, "seek": 215992, "start": 2174.4, "end": 2178.76, "text": " It doesn't answer the question of what is the utility that you're maximizing, right?", "tokens": [51088, 467, 1177, 380, 1867, 264, 1168, 295, 437, 307, 264, 14877, 300, 291, 434, 5138, 3319, 11, 558, 30, 51306], "temperature": 0.0, "avg_logprob": -0.19749543364618866, "compression_ratio": 1.9128787878787878, "no_speech_prob": 0.003212836803868413}, {"id": 636, "seek": 215992, "start": 2178.76, "end": 2181.64, "text": " So if you give me utility function, right?", "tokens": [51306, 407, 498, 291, 976, 385, 14877, 2445, 11, 558, 30, 51450], "temperature": 0.0, "avg_logprob": -0.19749543364618866, "compression_ratio": 1.9128787878787878, "no_speech_prob": 0.003212836803868413}, {"id": 637, "seek": 215992, "start": 2181.64, "end": 2184.4, "text": " Now, if you maximize it, you're rational.", "tokens": [51450, 823, 11, 498, 291, 19874, 309, 11, 291, 434, 15090, 13, 51588], "temperature": 0.0, "avg_logprob": -0.19749543364618866, "compression_ratio": 1.9128787878787878, "no_speech_prob": 0.003212836803868413}, {"id": 638, "seek": 215992, "start": 2184.84, "end": 2186.0, "text": " You can it can be bound.", "tokens": [51610, 509, 393, 309, 393, 312, 5472, 13, 51668], "temperature": 0.0, "avg_logprob": -0.19749543364618866, "compression_ratio": 1.9128787878787878, "no_speech_prob": 0.003212836803868413}, {"id": 639, "seek": 215992, "start": 2186.0, "end": 2188.64, "text": " You can be boundedly rational because you're and indeed this", "tokens": [51668, 509, 393, 312, 37498, 356, 15090, 570, 291, 434, 293, 6451, 341, 51800], "temperature": 0.0, "avg_logprob": -0.19749543364618866, "compression_ratio": 1.9128787878787878, "no_speech_prob": 0.003212836803868413}, {"id": 640, "seek": 218864, "start": 2188.64, "end": 2191.8799999999997, "text": " this is the interesting and prevalent cases that you can only maximize it", "tokens": [50364, 341, 307, 264, 1880, 293, 30652, 3331, 300, 291, 393, 787, 19874, 309, 50526], "temperature": 0.0, "avg_logprob": -0.15038789285195842, "compression_ratio": 1.7108433734939759, "no_speech_prob": 0.0029241389129310846}, {"id": 641, "seek": 218864, "start": 2191.8799999999997, "end": 2194.8399999999997, "text": " within bounds and you have to make compromises, says this fast and what not.", "tokens": [50526, 1951, 29905, 293, 291, 362, 281, 652, 11482, 3598, 11, 1619, 341, 2370, 293, 437, 406, 13, 50674], "temperature": 0.0, "avg_logprob": -0.15038789285195842, "compression_ratio": 1.7108433734939759, "no_speech_prob": 0.0029241389129310846}, {"id": 642, "seek": 218864, "start": 2194.8399999999997, "end": 2196.7599999999998, "text": " But still, you're rational.", "tokens": [50674, 583, 920, 11, 291, 434, 15090, 13, 50770], "temperature": 0.0, "avg_logprob": -0.15038789285195842, "compression_ratio": 1.7108433734939759, "no_speech_prob": 0.0029241389129310846}, {"id": 643, "seek": 218864, "start": 2196.7599999999998, "end": 2199.16, "text": " If you don't do that, you are irrational, right?", "tokens": [50770, 759, 291, 500, 380, 360, 300, 11, 291, 366, 39914, 11, 558, 30, 50890], "temperature": 0.0, "avg_logprob": -0.15038789285195842, "compression_ratio": 1.7108433734939759, "no_speech_prob": 0.0029241389129310846}, {"id": 644, "seek": 218864, "start": 2199.48, "end": 2203.2, "text": " So rational is a very, you know, like so many mistakes that we make", "tokens": [50906, 407, 15090, 307, 257, 588, 11, 291, 458, 11, 411, 370, 867, 8038, 300, 321, 652, 51092], "temperature": 0.0, "avg_logprob": -0.15038789285195842, "compression_ratio": 1.7108433734939759, "no_speech_prob": 0.0029241389129310846}, {"id": 645, "seek": 218864, "start": 2203.2, "end": 2207.68, "text": " as a society as individuals would be avoided if only we were rational in that sense.", "tokens": [51092, 382, 257, 4086, 382, 5346, 576, 312, 24890, 498, 787, 321, 645, 15090, 294, 300, 2020, 13, 51316], "temperature": 0.0, "avg_logprob": -0.15038789285195842, "compression_ratio": 1.7108433734939759, "no_speech_prob": 0.0029241389129310846}, {"id": 646, "seek": 218864, "start": 2208.08, "end": 2210.7599999999998, "text": " So at that level, I sympathize very much with that view of the world.", "tokens": [51336, 407, 412, 300, 1496, 11, 286, 22276, 1125, 588, 709, 365, 300, 1910, 295, 264, 1002, 13, 51470], "temperature": 0.0, "avg_logprob": -0.15038789285195842, "compression_ratio": 1.7108433734939759, "no_speech_prob": 0.0029241389129310846}, {"id": 647, "seek": 218864, "start": 2210.7599999999998, "end": 2214.68, "text": " Having said that, there's a huge gaping hole in the middle of this, which is like,", "tokens": [51470, 10222, 848, 300, 11, 456, 311, 257, 2603, 7417, 278, 5458, 294, 264, 2808, 295, 341, 11, 597, 307, 411, 11, 51666], "temperature": 0.0, "avg_logprob": -0.15038789285195842, "compression_ratio": 1.7108433734939759, "no_speech_prob": 0.0029241389129310846}, {"id": 648, "seek": 218864, "start": 2214.8799999999997, "end": 2216.6, "text": " but what is your utility function?", "tokens": [51676, 457, 437, 307, 428, 14877, 2445, 30, 51762], "temperature": 0.0, "avg_logprob": -0.15038789285195842, "compression_ratio": 1.7108433734939759, "no_speech_prob": 0.0029241389129310846}, {"id": 649, "seek": 221660, "start": 2216.64, "end": 2220.12, "text": " Right. And and, you know, one attitude is like, oh, that's for you to decide.", "tokens": [50366, 1779, 13, 400, 293, 11, 291, 458, 11, 472, 10157, 307, 411, 11, 1954, 11, 300, 311, 337, 291, 281, 4536, 13, 50540], "temperature": 0.0, "avg_logprob": -0.2355369285300926, "compression_ratio": 1.961661341853035, "no_speech_prob": 0.0022150366567075253}, {"id": 650, "seek": 221660, "start": 2220.16, "end": 2222.56, "text": " You know, you you tell what me or your utility function is.", "tokens": [50542, 509, 458, 11, 291, 291, 980, 437, 385, 420, 428, 14877, 2445, 307, 13, 50662], "temperature": 0.0, "avg_logprob": -0.2355369285300926, "compression_ratio": 1.961661341853035, "no_speech_prob": 0.0022150366567075253}, {"id": 651, "seek": 221660, "start": 2222.56, "end": 2225.3199999999997, "text": " But but then you you you're you're entitled to sell what like.", "tokens": [50662, 583, 457, 550, 291, 291, 291, 434, 291, 434, 17838, 281, 3607, 437, 411, 13, 50800], "temperature": 0.0, "avg_logprob": -0.2355369285300926, "compression_ratio": 1.961661341853035, "no_speech_prob": 0.0022150366567075253}, {"id": 652, "seek": 221660, "start": 2225.3199999999997, "end": 2228.48, "text": " But like my whole problem is that I want to figure out what my", "tokens": [50800, 583, 411, 452, 1379, 1154, 307, 300, 286, 528, 281, 2573, 484, 437, 452, 50958], "temperature": 0.0, "avg_logprob": -0.2355369285300926, "compression_ratio": 1.961661341853035, "no_speech_prob": 0.0022150366567075253}, {"id": 653, "seek": 221660, "start": 2228.48, "end": 2229.68, "text": " utility function should be.", "tokens": [50958, 14877, 2445, 820, 312, 13, 51018], "temperature": 0.0, "avg_logprob": -0.2355369285300926, "compression_ratio": 1.961661341853035, "no_speech_prob": 0.0022150366567075253}, {"id": 654, "seek": 221660, "start": 2229.68, "end": 2233.56, "text": " And at that point, this whole theory of rationality just doesn't help you at all.", "tokens": [51018, 400, 412, 300, 935, 11, 341, 1379, 5261, 295, 15090, 507, 445, 1177, 380, 854, 291, 412, 439, 13, 51212], "temperature": 0.0, "avg_logprob": -0.2355369285300926, "compression_ratio": 1.961661341853035, "no_speech_prob": 0.0022150366567075253}, {"id": 655, "seek": 221660, "start": 2233.96, "end": 2236.04, "text": " The utility function is an input, right?", "tokens": [51232, 440, 14877, 2445, 307, 364, 4846, 11, 558, 30, 51336], "temperature": 0.0, "avg_logprob": -0.2355369285300926, "compression_ratio": 1.961661341853035, "no_speech_prob": 0.0022150366567075253}, {"id": 656, "seek": 221660, "start": 2236.04, "end": 2238.7599999999998, "text": " So another question becomes what is your utility function, right?", "tokens": [51336, 407, 1071, 1168, 3643, 437, 307, 428, 14877, 2445, 11, 558, 30, 51472], "temperature": 0.0, "avg_logprob": -0.2355369285300926, "compression_ratio": 1.961661341853035, "no_speech_prob": 0.0022150366567075253}, {"id": 657, "seek": 221660, "start": 2238.92, "end": 2242.08, "text": " And then there's a very related, but as Hume said, very different question,", "tokens": [51480, 400, 550, 456, 311, 257, 588, 4077, 11, 457, 382, 389, 2540, 848, 11, 588, 819, 1168, 11, 51638], "temperature": 0.0, "avg_logprob": -0.2355369285300926, "compression_ratio": 1.961661341853035, "no_speech_prob": 0.0022150366567075253}, {"id": 658, "seek": 221660, "start": 2242.08, "end": 2245.16, "text": " which is like, what should your utility function be like?", "tokens": [51638, 597, 307, 411, 11, 437, 820, 428, 14877, 2445, 312, 411, 30, 51792], "temperature": 0.0, "avg_logprob": -0.2355369285300926, "compression_ratio": 1.961661341853035, "no_speech_prob": 0.0022150366567075253}, {"id": 659, "seek": 224516, "start": 2245.2, "end": 2248.2799999999997, "text": " Should is a very loaded worth here, right?", "tokens": [50366, 6454, 307, 257, 588, 13210, 3163, 510, 11, 558, 30, 50520], "temperature": 0.0, "avg_logprob": -0.15522900223731995, "compression_ratio": 1.8303886925795052, "no_speech_prob": 0.008435064926743507}, {"id": 660, "seek": 224516, "start": 2248.64, "end": 2251.48, "text": " And then what what usually happens is things like this is that our", "tokens": [50538, 400, 550, 437, 437, 2673, 2314, 307, 721, 411, 341, 307, 300, 527, 50680], "temperature": 0.0, "avg_logprob": -0.15522900223731995, "compression_ratio": 1.8303886925795052, "no_speech_prob": 0.008435064926743507}, {"id": 661, "seek": 224516, "start": 2251.48, "end": 2255.8799999999997, "text": " notions of morality and so on are trying to impose a should on you,", "tokens": [50680, 35799, 295, 29106, 293, 370, 322, 366, 1382, 281, 26952, 257, 820, 322, 291, 11, 50900], "temperature": 0.0, "avg_logprob": -0.15522900223731995, "compression_ratio": 1.8303886925795052, "no_speech_prob": 0.008435064926743507}, {"id": 662, "seek": 224516, "start": 2256.2, "end": 2261.2, "text": " a utility function that you should have because it serves the utility of the society.", "tokens": [50916, 257, 14877, 2445, 300, 291, 820, 362, 570, 309, 13451, 264, 14877, 295, 264, 4086, 13, 51166], "temperature": 0.0, "avg_logprob": -0.15522900223731995, "compression_ratio": 1.8303886925795052, "no_speech_prob": 0.008435064926743507}, {"id": 663, "seek": 224516, "start": 2261.96, "end": 2264.8399999999997, "text": " Now, from the point of view, the society, this is good, right?", "tokens": [51204, 823, 11, 490, 264, 935, 295, 1910, 11, 264, 4086, 11, 341, 307, 665, 11, 558, 30, 51348], "temperature": 0.0, "avg_logprob": -0.15522900223731995, "compression_ratio": 1.8303886925795052, "no_speech_prob": 0.008435064926743507}, {"id": 664, "seek": 224516, "start": 2265.08, "end": 2267.7599999999998, "text": " But from the point of view, because the society hopefully will live", "tokens": [51360, 583, 490, 264, 935, 295, 1910, 11, 570, 264, 4086, 4696, 486, 1621, 51494], "temperature": 0.0, "avg_logprob": -0.15522900223731995, "compression_ratio": 1.8303886925795052, "no_speech_prob": 0.008435064926743507}, {"id": 665, "seek": 224516, "start": 2267.7599999999998, "end": 2271.68, "text": " and prosper if its elements contribute to its utility, not just their own, right?", "tokens": [51494, 293, 14381, 498, 1080, 4959, 10586, 281, 1080, 14877, 11, 406, 445, 641, 1065, 11, 558, 30, 51690], "temperature": 0.0, "avg_logprob": -0.15522900223731995, "compression_ratio": 1.8303886925795052, "no_speech_prob": 0.008435064926743507}, {"id": 666, "seek": 224516, "start": 2271.8799999999997, "end": 2273.64, "text": " But it still doesn't answer the question.", "tokens": [51700, 583, 309, 920, 1177, 380, 1867, 264, 1168, 13, 51788], "temperature": 0.0, "avg_logprob": -0.15522900223731995, "compression_ratio": 1.8303886925795052, "no_speech_prob": 0.008435064926743507}, {"id": 667, "seek": 227364, "start": 2273.64, "end": 2275.2799999999997, "text": " So you can you're entitled to ask.", "tokens": [50364, 407, 291, 393, 291, 434, 17838, 281, 1029, 13, 50446], "temperature": 0.0, "avg_logprob": -0.2145786454192305, "compression_ratio": 1.668, "no_speech_prob": 0.0038148059975355864}, {"id": 668, "seek": 227364, "start": 2275.2799999999997, "end": 2276.7599999999998, "text": " So what does answer the question?", "tokens": [50446, 407, 437, 775, 1867, 264, 1168, 30, 50520], "temperature": 0.0, "avg_logprob": -0.2145786454192305, "compression_ratio": 1.668, "no_speech_prob": 0.0038148059975355864}, {"id": 669, "seek": 227364, "start": 2276.7599999999998, "end": 2282.08, "text": " Right. And my view on this is that none of these people and these people", "tokens": [50520, 1779, 13, 400, 452, 1910, 322, 341, 307, 300, 6022, 295, 613, 561, 293, 613, 561, 50786], "temperature": 0.0, "avg_logprob": -0.2145786454192305, "compression_ratio": 1.668, "no_speech_prob": 0.0038148059975355864}, {"id": 670, "seek": 227364, "start": 2282.08, "end": 2285.4, "text": " include Kant and Bentham and, you know, Plato and everybody, right?", "tokens": [50786, 4090, 40927, 293, 28894, 4822, 293, 11, 291, 458, 11, 43027, 293, 2201, 11, 558, 30, 50952], "temperature": 0.0, "avg_logprob": -0.2145786454192305, "compression_ratio": 1.668, "no_speech_prob": 0.0038148059975355864}, {"id": 671, "seek": 227364, "start": 2285.92, "end": 2288.12, "text": " They you can't do that, right?", "tokens": [50978, 814, 291, 393, 380, 360, 300, 11, 558, 30, 51088], "temperature": 0.0, "avg_logprob": -0.2145786454192305, "compression_ratio": 1.668, "no_speech_prob": 0.0038148059975355864}, {"id": 672, "seek": 227364, "start": 2288.12, "end": 2294.2, "text": " The the the so to me, the supreme reality of life, Supreme", "tokens": [51088, 440, 264, 264, 370, 281, 385, 11, 264, 27756, 4103, 295, 993, 11, 11032, 51392], "temperature": 0.0, "avg_logprob": -0.2145786454192305, "compression_ratio": 1.668, "no_speech_prob": 0.0038148059975355864}, {"id": 673, "seek": 227364, "start": 2294.2, "end": 2298.52, "text": " maybe is a bad word, but like the overarching reality is evolution, right?", "tokens": [51392, 1310, 307, 257, 1578, 1349, 11, 457, 411, 264, 45501, 4103, 307, 9303, 11, 558, 30, 51608], "temperature": 0.0, "avg_logprob": -0.2145786454192305, "compression_ratio": 1.668, "no_speech_prob": 0.0038148059975355864}, {"id": 674, "seek": 227364, "start": 2299.12, "end": 2301.3599999999997, "text": " Everything we are is created by evolution.", "tokens": [51638, 5471, 321, 366, 307, 2942, 538, 9303, 13, 51750], "temperature": 0.0, "avg_logprob": -0.2145786454192305, "compression_ratio": 1.668, "no_speech_prob": 0.0038148059975355864}, {"id": 675, "seek": 230136, "start": 2301.36, "end": 2304.36, "text": " And as somebody famously said, nothing in biology makes sense,", "tokens": [50364, 400, 382, 2618, 34360, 848, 11, 1825, 294, 14956, 1669, 2020, 11, 50514], "temperature": 0.0, "avg_logprob": -0.14417724120311248, "compression_ratio": 1.8470948012232415, "no_speech_prob": 0.06993933767080307}, {"id": 676, "seek": 230136, "start": 2304.36, "end": 2307.96, "text": " except in light of evolution, nothing in morality makes sense,", "tokens": [50514, 3993, 294, 1442, 295, 9303, 11, 1825, 294, 29106, 1669, 2020, 11, 50694], "temperature": 0.0, "avg_logprob": -0.14417724120311248, "compression_ratio": 1.8470948012232415, "no_speech_prob": 0.06993933767080307}, {"id": 677, "seek": 230136, "start": 2307.96, "end": 2310.92, "text": " except in light of evolution, not just biological evolution, even though", "tokens": [50694, 3993, 294, 1442, 295, 9303, 11, 406, 445, 13910, 9303, 11, 754, 1673, 50842], "temperature": 0.0, "avg_logprob": -0.14417724120311248, "compression_ratio": 1.8470948012232415, "no_speech_prob": 0.06993933767080307}, {"id": 678, "seek": 230136, "start": 2310.92, "end": 2313.56, "text": " that's part of it, but also social and cultural evolution.", "tokens": [50842, 300, 311, 644, 295, 309, 11, 457, 611, 2093, 293, 6988, 9303, 13, 50974], "temperature": 0.0, "avg_logprob": -0.14417724120311248, "compression_ratio": 1.8470948012232415, "no_speech_prob": 0.06993933767080307}, {"id": 679, "seek": 230136, "start": 2313.56, "end": 2316.8, "text": " So at the end of the day, the question that you need to ask yourself is like,", "tokens": [50974, 407, 412, 264, 917, 295, 264, 786, 11, 264, 1168, 300, 291, 643, 281, 1029, 1803, 307, 411, 11, 51136], "temperature": 0.0, "avg_logprob": -0.14417724120311248, "compression_ratio": 1.8470948012232415, "no_speech_prob": 0.06993933767080307}, {"id": 680, "seek": 230136, "start": 2316.8, "end": 2319.44, "text": " is which utility functions are fitter?", "tokens": [51136, 307, 597, 14877, 6828, 366, 3318, 391, 30, 51268], "temperature": 0.0, "avg_logprob": -0.14417724120311248, "compression_ratio": 1.8470948012232415, "no_speech_prob": 0.06993933767080307}, {"id": 681, "seek": 230136, "start": 2319.76, "end": 2321.44, "text": " And those are the ones that will prevail.", "tokens": [51284, 400, 729, 366, 264, 2306, 300, 486, 46059, 13, 51368], "temperature": 0.0, "avg_logprob": -0.14417724120311248, "compression_ratio": 1.8470948012232415, "no_speech_prob": 0.06993933767080307}, {"id": 682, "seek": 230136, "start": 2321.44, "end": 2322.92, "text": " So so let's let's go there.", "tokens": [51368, 407, 370, 718, 311, 718, 311, 352, 456, 13, 51442], "temperature": 0.0, "avg_logprob": -0.14417724120311248, "compression_ratio": 1.8470948012232415, "no_speech_prob": 0.06993933767080307}, {"id": 683, "seek": 230136, "start": 2322.92, "end": 2323.6, "text": " That's really interesting.", "tokens": [51442, 663, 311, 534, 1880, 13, 51476], "temperature": 0.0, "avg_logprob": -0.14417724120311248, "compression_ratio": 1.8470948012232415, "no_speech_prob": 0.06993933767080307}, {"id": 684, "seek": 230136, "start": 2323.6, "end": 2328.4, "text": " Now, you're known as a skeptic of collectivist thought, right?", "tokens": [51476, 823, 11, 291, 434, 2570, 382, 257, 19128, 299, 295, 2500, 592, 468, 1194, 11, 558, 30, 51716], "temperature": 0.0, "avg_logprob": -0.14417724120311248, "compression_ratio": 1.8470948012232415, "no_speech_prob": 0.06993933767080307}, {"id": 685, "seek": 230136, "start": 2328.4, "end": 2331.04, "text": " We know, and there's this interesting dichotomy we were talking about", "tokens": [51716, 492, 458, 11, 293, 456, 311, 341, 1880, 10390, 310, 8488, 321, 645, 1417, 466, 51848], "temperature": 0.0, "avg_logprob": -0.14417724120311248, "compression_ratio": 1.8470948012232415, "no_speech_prob": 0.06993933767080307}, {"id": 686, "seek": 233104, "start": 2331.04, "end": 2335.52, "text": " of, you know, monolithic truth, but the utility functions interesting as well.", "tokens": [50364, 295, 11, 291, 458, 11, 1108, 42878, 3494, 11, 457, 264, 14877, 6828, 1880, 382, 731, 13, 50588], "temperature": 0.0, "avg_logprob": -0.16715390838845803, "compression_ratio": 1.7679180887372015, "no_speech_prob": 0.0005506561719812453}, {"id": 687, "seek": 233104, "start": 2335.52, "end": 2338.44, "text": " Because in a sense, I mean, I know these folks are consequentialists,", "tokens": [50588, 1436, 294, 257, 2020, 11, 286, 914, 11, 286, 458, 613, 4024, 366, 7242, 2549, 1751, 11, 50734], "temperature": 0.0, "avg_logprob": -0.16715390838845803, "compression_ratio": 1.7679180887372015, "no_speech_prob": 0.0005506561719812453}, {"id": 688, "seek": 233104, "start": 2338.44, "end": 2341.12, "text": " but in a sense, that's more leaning towards deontology.", "tokens": [50734, 457, 294, 257, 2020, 11, 300, 311, 544, 23390, 3030, 368, 896, 1793, 13, 50868], "temperature": 0.0, "avg_logprob": -0.16715390838845803, "compression_ratio": 1.7679180887372015, "no_speech_prob": 0.0005506561719812453}, {"id": 689, "seek": 233104, "start": 2341.84, "end": 2345.8, "text": " I did it again, deontology, you know, which is this idea that", "tokens": [50904, 286, 630, 309, 797, 11, 368, 896, 1793, 11, 291, 458, 11, 597, 307, 341, 1558, 300, 51102], "temperature": 0.0, "avg_logprob": -0.16715390838845803, "compression_ratio": 1.7679180887372015, "no_speech_prob": 0.0005506561719812453}, {"id": 690, "seek": 233104, "start": 2345.8, "end": 2349.52, "text": " we have kind of like a principled approach to to morality.", "tokens": [51102, 321, 362, 733, 295, 411, 257, 3681, 15551, 3109, 281, 281, 29106, 13, 51288], "temperature": 0.0, "avg_logprob": -0.16715390838845803, "compression_ratio": 1.7679180887372015, "no_speech_prob": 0.0005506561719812453}, {"id": 691, "seek": 233104, "start": 2349.7599999999998, "end": 2353.36, "text": " And I'm skeptical as well that it's possible to create such a utility", "tokens": [51300, 400, 286, 478, 28601, 382, 731, 300, 309, 311, 1944, 281, 1884, 1270, 257, 14877, 51480], "temperature": 0.0, "avg_logprob": -0.16715390838845803, "compression_ratio": 1.7679180887372015, "no_speech_prob": 0.0005506561719812453}, {"id": 692, "seek": 233104, "start": 2353.36, "end": 2355.36, "text": " function because it wouldn't really be parsimonious.", "tokens": [51480, 2445, 570, 309, 2759, 380, 534, 312, 21156, 25098, 851, 13, 51580], "temperature": 0.0, "avg_logprob": -0.16715390838845803, "compression_ratio": 1.7679180887372015, "no_speech_prob": 0.0005506561719812453}, {"id": 693, "seek": 233104, "start": 2355.36, "end": 2359.44, "text": " But how do you wrestle that, that you have a simple utility function,", "tokens": [51580, 583, 577, 360, 291, 43251, 300, 11, 300, 291, 362, 257, 2199, 14877, 2445, 11, 51784], "temperature": 0.0, "avg_logprob": -0.16715390838845803, "compression_ratio": 1.7679180887372015, "no_speech_prob": 0.0005506561719812453}, {"id": 694, "seek": 235944, "start": 2359.44, "end": 2361.88, "text": " even though you believe in diversity of ideas?", "tokens": [50364, 754, 1673, 291, 1697, 294, 8811, 295, 3487, 30, 50486], "temperature": 0.0, "avg_logprob": -0.18828044977403224, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.01079877745360136}, {"id": 695, "seek": 235944, "start": 2361.88, "end": 2364.2400000000002, "text": " Oh, no, I didn't say simple.", "tokens": [50486, 876, 11, 572, 11, 286, 994, 380, 584, 2199, 13, 50604], "temperature": 0.0, "avg_logprob": -0.18828044977403224, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.01079877745360136}, {"id": 696, "seek": 235944, "start": 2364.2400000000002, "end": 2364.56, "text": " Go on.", "tokens": [50604, 1037, 322, 13, 50620], "temperature": 0.0, "avg_logprob": -0.18828044977403224, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.01079877745360136}, {"id": 697, "seek": 235944, "start": 2364.56, "end": 2367.92, "text": " Crucial point, the utility function could be extremely complex.", "tokens": [50620, 13586, 1013, 935, 11, 264, 14877, 2445, 727, 312, 4664, 3997, 13, 50788], "temperature": 0.0, "avg_logprob": -0.18828044977403224, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.01079877745360136}, {"id": 698, "seek": 235944, "start": 2368.88, "end": 2370.48, "text": " And in fact, the utility function.", "tokens": [50836, 400, 294, 1186, 11, 264, 14877, 2445, 13, 50916], "temperature": 0.0, "avg_logprob": -0.18828044977403224, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.01079877745360136}, {"id": 699, "seek": 235944, "start": 2370.48, "end": 2373.6, "text": " So first of all, there's there's more than one level to this.", "tokens": [50916, 407, 700, 295, 439, 11, 456, 311, 456, 311, 544, 813, 472, 1496, 281, 341, 13, 51072], "temperature": 0.0, "avg_logprob": -0.18828044977403224, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.01079877745360136}, {"id": 700, "seek": 235944, "start": 2374.7200000000003, "end": 2378.56, "text": " You to let's say you believe in utilitarianism, right, which I don't,", "tokens": [51128, 509, 281, 718, 311, 584, 291, 1697, 294, 4976, 13707, 1434, 11, 558, 11, 597, 286, 500, 380, 11, 51320], "temperature": 0.0, "avg_logprob": -0.18828044977403224, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.01079877745360136}, {"id": 701, "seek": 235944, "start": 2378.56, "end": 2381.76, "text": " but have, you know, compared to the others, it's probably the least bad.", "tokens": [51320, 457, 362, 11, 291, 458, 11, 5347, 281, 264, 2357, 11, 309, 311, 1391, 264, 1935, 1578, 13, 51480], "temperature": 0.0, "avg_logprob": -0.18828044977403224, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.01079877745360136}, {"id": 702, "seek": 235944, "start": 2381.76, "end": 2383.04, "text": " Right. Yeah.", "tokens": [51480, 1779, 13, 865, 13, 51544], "temperature": 0.0, "avg_logprob": -0.18828044977403224, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.01079877745360136}, {"id": 703, "seek": 235944, "start": 2383.04, "end": 2387.44, "text": " Believing you tell if you believe in maximizing utility function", "tokens": [51544, 6248, 30244, 291, 980, 498, 291, 1697, 294, 5138, 3319, 14877, 2445, 51764], "temperature": 0.0, "avg_logprob": -0.18828044977403224, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.01079877745360136}, {"id": 704, "seek": 238744, "start": 2387.44, "end": 2391.12, "text": " that in no way sanctions collectivism.", "tokens": [50364, 300, 294, 572, 636, 21342, 2500, 592, 1434, 13, 50548], "temperature": 0.0, "avg_logprob": -0.13344803794485624, "compression_ratio": 1.6738351254480286, "no_speech_prob": 0.003023461438715458}, {"id": 705, "seek": 238744, "start": 2392.32, "end": 2396.56, "text": " Collectivism is one particular strength that historically came out of that.", "tokens": [50608, 31896, 592, 1434, 307, 472, 1729, 3800, 300, 16180, 1361, 484, 295, 300, 13, 50820], "temperature": 0.0, "avg_logprob": -0.13344803794485624, "compression_ratio": 1.6738351254480286, "no_speech_prob": 0.003023461438715458}, {"id": 706, "seek": 238744, "start": 2396.56, "end": 2397.28, "text": " Right.", "tokens": [50820, 1779, 13, 50856], "temperature": 0.0, "avg_logprob": -0.13344803794485624, "compression_ratio": 1.6738351254480286, "no_speech_prob": 0.003023461438715458}, {"id": 707, "seek": 238744, "start": 2397.28, "end": 2400.64, "text": " And, and, and, you know, again, and Bentham is responsible for it.", "tokens": [50856, 400, 11, 293, 11, 293, 11, 291, 458, 11, 797, 11, 293, 28894, 4822, 307, 6250, 337, 309, 13, 51024], "temperature": 0.0, "avg_logprob": -0.13344803794485624, "compression_ratio": 1.6738351254480286, "no_speech_prob": 0.003023461438715458}, {"id": 708, "seek": 238744, "start": 2400.64, "end": 2404.56, "text": " But it's this notion that you should have a utility function", "tokens": [51024, 583, 309, 311, 341, 10710, 300, 291, 820, 362, 257, 14877, 2445, 51220], "temperature": 0.0, "avg_logprob": -0.13344803794485624, "compression_ratio": 1.6738351254480286, "no_speech_prob": 0.003023461438715458}, {"id": 709, "seek": 238744, "start": 2404.56, "end": 2406.2400000000002, "text": " in which everybody counts equally.", "tokens": [51220, 294, 597, 2201, 14893, 12309, 13, 51304], "temperature": 0.0, "avg_logprob": -0.13344803794485624, "compression_ratio": 1.6738351254480286, "no_speech_prob": 0.003023461438715458}, {"id": 710, "seek": 238744, "start": 2407.44, "end": 2409.68, "text": " This is now making a choice of utility function,", "tokens": [51364, 639, 307, 586, 1455, 257, 3922, 295, 14877, 2445, 11, 51476], "temperature": 0.0, "avg_logprob": -0.13344803794485624, "compression_ratio": 1.6738351254480286, "no_speech_prob": 0.003023461438715458}, {"id": 711, "seek": 238744, "start": 2409.68, "end": 2411.28, "text": " which is different from having one.", "tokens": [51476, 597, 307, 819, 490, 1419, 472, 13, 51556], "temperature": 0.0, "avg_logprob": -0.13344803794485624, "compression_ratio": 1.6738351254480286, "no_speech_prob": 0.003023461438715458}, {"id": 712, "seek": 238744, "start": 2411.28, "end": 2413.36, "text": " Okay, but I think you're saying something quite interesting as well,", "tokens": [51556, 1033, 11, 457, 286, 519, 291, 434, 1566, 746, 1596, 1880, 382, 731, 11, 51660], "temperature": 0.0, "avg_logprob": -0.13344803794485624, "compression_ratio": 1.6738351254480286, "no_speech_prob": 0.003023461438715458}, {"id": 713, "seek": 238744, "start": 2413.36, "end": 2414.88, "text": " which is that at the moment,", "tokens": [51660, 597, 307, 300, 412, 264, 1623, 11, 51736], "temperature": 0.0, "avg_logprob": -0.13344803794485624, "compression_ratio": 1.6738351254480286, "no_speech_prob": 0.003023461438715458}, {"id": 714, "seek": 241488, "start": 2415.6, "end": 2417.76, "text": " the utility is a function of market value,", "tokens": [50400, 264, 14877, 307, 257, 2445, 295, 2142, 2158, 11, 50508], "temperature": 0.0, "avg_logprob": -0.13391706369219036, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.002248159609735012}, {"id": 715, "seek": 241488, "start": 2417.76, "end": 2422.08, "text": " which is very much inspired by Adam Smith's hidden hand of the market.", "tokens": [50508, 597, 307, 588, 709, 7547, 538, 7938, 8538, 311, 7633, 1011, 295, 264, 2142, 13, 50724], "temperature": 0.0, "avg_logprob": -0.13391706369219036, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.002248159609735012}, {"id": 716, "seek": 241488, "start": 2422.08, "end": 2425.92, "text": " But I think your views against collectivism is very much against", "tokens": [50724, 583, 286, 519, 428, 6809, 1970, 2500, 592, 1434, 307, 588, 709, 1970, 50916], "temperature": 0.0, "avg_logprob": -0.13391706369219036, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.002248159609735012}, {"id": 717, "seek": 241488, "start": 2425.92, "end": 2427.92, "text": " this idea of equality of outcome.", "tokens": [50916, 341, 1558, 295, 14949, 295, 9700, 13, 51016], "temperature": 0.0, "avg_logprob": -0.13391706369219036, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.002248159609735012}, {"id": 718, "seek": 241488, "start": 2427.92, "end": 2429.2000000000003, "text": " And that's definitely not what you're saying.", "tokens": [51016, 400, 300, 311, 2138, 406, 437, 291, 434, 1566, 13, 51080], "temperature": 0.0, "avg_logprob": -0.13391706369219036, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.002248159609735012}, {"id": 719, "seek": 241488, "start": 2429.2000000000003, "end": 2431.12, "text": " No, I mean, that's even going beyond that, right?", "tokens": [51080, 883, 11, 286, 914, 11, 300, 311, 754, 516, 4399, 300, 11, 558, 30, 51176], "temperature": 0.0, "avg_logprob": -0.13391706369219036, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.002248159609735012}, {"id": 720, "seek": 241488, "start": 2431.12, "end": 2435.6, "text": " Equality of outcome is actually irrational, frankly, to we could go into that.", "tokens": [51176, 462, 11286, 295, 9700, 307, 767, 39914, 11, 11939, 11, 281, 321, 727, 352, 666, 300, 13, 51400], "temperature": 0.0, "avg_logprob": -0.13391706369219036, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.002248159609735012}, {"id": 721, "seek": 241488, "start": 2435.6, "end": 2437.28, "text": " But, you know, you mentioned the market, right?", "tokens": [51400, 583, 11, 291, 458, 11, 291, 2835, 264, 2142, 11, 558, 30, 51484], "temperature": 0.0, "avg_logprob": -0.13391706369219036, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.002248159609735012}, {"id": 722, "seek": 241488, "start": 2437.28, "end": 2439.2000000000003, "text": " And the market is the size utility.", "tokens": [51484, 400, 264, 2142, 307, 264, 2744, 14877, 13, 51580], "temperature": 0.0, "avg_logprob": -0.13391706369219036, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.002248159609735012}, {"id": 723, "seek": 241488, "start": 2439.2000000000003, "end": 2442.32, "text": " Again, that is a one way to decide.", "tokens": [51580, 3764, 11, 300, 307, 257, 472, 636, 281, 4536, 13, 51736], "temperature": 0.0, "avg_logprob": -0.13391706369219036, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.002248159609735012}, {"id": 724, "seek": 244232, "start": 2442.32, "end": 2446.48, "text": " I mean, that is also a very critical approximation to what you really want.", "tokens": [50364, 286, 914, 11, 300, 307, 611, 257, 588, 4924, 28023, 281, 437, 291, 534, 528, 13, 50572], "temperature": 0.0, "avg_logprob": -0.13850675310407365, "compression_ratio": 1.667870036101083, "no_speech_prob": 0.002248839708045125}, {"id": 725, "seek": 244232, "start": 2446.48, "end": 2449.92, "text": " So actually, all we have with capitalism or carnimism at this point,", "tokens": [50572, 407, 767, 11, 439, 321, 362, 365, 19704, 420, 23796, 332, 1434, 412, 341, 935, 11, 50744], "temperature": 0.0, "avg_logprob": -0.13850675310407365, "compression_ratio": 1.667870036101083, "no_speech_prob": 0.002248839708045125}, {"id": 726, "seek": 244232, "start": 2449.92, "end": 2453.36, "text": " in terms of utility function, are very imperfect, right?", "tokens": [50744, 294, 2115, 295, 14877, 2445, 11, 366, 588, 26714, 11, 558, 30, 50916], "temperature": 0.0, "avg_logprob": -0.13850675310407365, "compression_ratio": 1.667870036101083, "no_speech_prob": 0.002248839708045125}, {"id": 727, "seek": 244232, "start": 2454.1600000000003, "end": 2456.0800000000004, "text": " And that's even saying it generously.", "tokens": [50956, 400, 300, 311, 754, 1566, 309, 48983, 13, 51052], "temperature": 0.0, "avg_logprob": -0.13850675310407365, "compression_ratio": 1.667870036101083, "no_speech_prob": 0.002248839708045125}, {"id": 728, "seek": 244232, "start": 2456.0800000000004, "end": 2458.6400000000003, "text": " And really, our job is to try to come up with something better,", "tokens": [51052, 400, 534, 11, 527, 1691, 307, 281, 853, 281, 808, 493, 365, 746, 1101, 11, 51180], "temperature": 0.0, "avg_logprob": -0.13850675310407365, "compression_ratio": 1.667870036101083, "no_speech_prob": 0.002248839708045125}, {"id": 729, "seek": 244232, "start": 2458.6400000000003, "end": 2460.8, "text": " which I totally think we can, right?", "tokens": [51180, 597, 286, 3879, 519, 321, 393, 11, 558, 30, 51288], "temperature": 0.0, "avg_logprob": -0.13850675310407365, "compression_ratio": 1.667870036101083, "no_speech_prob": 0.002248839708045125}, {"id": 730, "seek": 244232, "start": 2460.8, "end": 2463.6000000000004, "text": " And by the way, one very salient question here,", "tokens": [51288, 400, 538, 264, 636, 11, 472, 588, 1845, 1196, 1168, 510, 11, 51428], "temperature": 0.0, "avg_logprob": -0.13850675310407365, "compression_ratio": 1.667870036101083, "no_speech_prob": 0.002248839708045125}, {"id": 731, "seek": 244232, "start": 2463.6000000000004, "end": 2466.7200000000003, "text": " which again, for economists, it's very salient,", "tokens": [51428, 597, 797, 11, 337, 32431, 11, 309, 311, 588, 1845, 1196, 11, 51584], "temperature": 0.0, "avg_logprob": -0.13850675310407365, "compression_ratio": 1.667870036101083, "no_speech_prob": 0.002248839708045125}, {"id": 732, "seek": 244232, "start": 2466.7200000000003, "end": 2468.56, "text": " is this question of like,", "tokens": [51584, 307, 341, 1168, 295, 411, 11, 51676], "temperature": 0.0, "avg_logprob": -0.13850675310407365, "compression_ratio": 1.667870036101083, "no_speech_prob": 0.002248839708045125}, {"id": 733, "seek": 246856, "start": 2468.56, "end": 2472.72, "text": " should you have one utility function overarching, controlling everything,", "tokens": [50364, 820, 291, 362, 472, 14877, 2445, 45501, 11, 14905, 1203, 11, 50572], "temperature": 0.0, "avg_logprob": -0.0988164132879686, "compression_ratio": 1.7638888888888888, "no_speech_prob": 0.009545546025037766}, {"id": 734, "seek": 246856, "start": 2472.72, "end": 2474.56, "text": " even if it's complex, right?", "tokens": [50572, 754, 498, 309, 311, 3997, 11, 558, 30, 50664], "temperature": 0.0, "avg_logprob": -0.0988164132879686, "compression_ratio": 1.7638888888888888, "no_speech_prob": 0.009545546025037766}, {"id": 735, "seek": 246856, "start": 2474.56, "end": 2476.48, "text": " Or should you not, right?", "tokens": [50664, 1610, 820, 291, 406, 11, 558, 30, 50760], "temperature": 0.0, "avg_logprob": -0.0988164132879686, "compression_ratio": 1.7638888888888888, "no_speech_prob": 0.009545546025037766}, {"id": 736, "seek": 246856, "start": 2476.48, "end": 2479.68, "text": " And that I think is a very interesting question, right?", "tokens": [50760, 400, 300, 286, 519, 307, 257, 588, 1880, 1168, 11, 558, 30, 50920], "temperature": 0.0, "avg_logprob": -0.0988164132879686, "compression_ratio": 1.7638888888888888, "no_speech_prob": 0.009545546025037766}, {"id": 737, "seek": 246856, "start": 2479.68, "end": 2482.24, "text": " And there are good arguments in both directions, right?", "tokens": [50920, 400, 456, 366, 665, 12869, 294, 1293, 11095, 11, 558, 30, 51048], "temperature": 0.0, "avg_logprob": -0.0988164132879686, "compression_ratio": 1.7638888888888888, "no_speech_prob": 0.009545546025037766}, {"id": 738, "seek": 246856, "start": 2482.24, "end": 2484.4, "text": " So let me just give you one silly example,", "tokens": [51048, 407, 718, 385, 445, 976, 291, 472, 11774, 1365, 11, 51156], "temperature": 0.0, "avg_logprob": -0.0988164132879686, "compression_ratio": 1.7638888888888888, "no_speech_prob": 0.009545546025037766}, {"id": 739, "seek": 246856, "start": 2484.4, "end": 2486.64, "text": " which then I think also generalizes two other things.", "tokens": [51156, 597, 550, 286, 519, 611, 2674, 5660, 732, 661, 721, 13, 51268], "temperature": 0.0, "avg_logprob": -0.0988164132879686, "compression_ratio": 1.7638888888888888, "no_speech_prob": 0.009545546025037766}, {"id": 740, "seek": 246856, "start": 2486.64, "end": 2489.52, "text": " Does your brain have a singular utility function?", "tokens": [51268, 4402, 428, 3567, 362, 257, 20010, 14877, 2445, 30, 51412], "temperature": 0.0, "avg_logprob": -0.0988164132879686, "compression_ratio": 1.7638888888888888, "no_speech_prob": 0.009545546025037766}, {"id": 741, "seek": 246856, "start": 2489.52, "end": 2491.44, "text": " And I think the answer is no.", "tokens": [51412, 400, 286, 519, 264, 1867, 307, 572, 13, 51508], "temperature": 0.0, "avg_logprob": -0.0988164132879686, "compression_ratio": 1.7638888888888888, "no_speech_prob": 0.009545546025037766}, {"id": 742, "seek": 246856, "start": 2491.44, "end": 2494.0, "text": " Now, you could say from an evolutionary point of view,", "tokens": [51508, 823, 11, 291, 727, 584, 490, 364, 27567, 935, 295, 1910, 11, 51636], "temperature": 0.0, "avg_logprob": -0.0988164132879686, "compression_ratio": 1.7638888888888888, "no_speech_prob": 0.009545546025037766}, {"id": 743, "seek": 246856, "start": 2494.0, "end": 2496.0, "text": " the overarching utility is fitness.", "tokens": [51636, 264, 45501, 14877, 307, 15303, 13, 51736], "temperature": 0.0, "avg_logprob": -0.0988164132879686, "compression_ratio": 1.7638888888888888, "no_speech_prob": 0.009545546025037766}, {"id": 744, "seek": 249600, "start": 2496.64, "end": 2498.8, "text": " But then the way that cashes out in your brain", "tokens": [50396, 583, 550, 264, 636, 300, 6388, 279, 484, 294, 428, 3567, 50504], "temperature": 0.0, "avg_logprob": -0.10032833156301015, "compression_ratio": 1.8257575757575757, "no_speech_prob": 0.014237812720239162}, {"id": 745, "seek": 249600, "start": 2498.8, "end": 2503.76, "text": " is that your genes need to control this adaptive machine, right?", "tokens": [50504, 307, 300, 428, 14424, 643, 281, 1969, 341, 27912, 3479, 11, 558, 30, 50752], "temperature": 0.0, "avg_logprob": -0.10032833156301015, "compression_ratio": 1.8257575757575757, "no_speech_prob": 0.014237812720239162}, {"id": 746, "seek": 249600, "start": 2504.4, "end": 2509.44, "text": " In such a way that you give the machine freedom, right?", "tokens": [50784, 682, 1270, 257, 636, 300, 291, 976, 264, 3479, 5645, 11, 558, 30, 51036], "temperature": 0.0, "avg_logprob": -0.10032833156301015, "compression_ratio": 1.8257575757575757, "no_speech_prob": 0.014237812720239162}, {"id": 747, "seek": 249600, "start": 2509.44, "end": 2511.52, "text": " To do things that the genes by themselves couldn't.", "tokens": [51036, 1407, 360, 721, 300, 264, 14424, 538, 2969, 2809, 380, 13, 51140], "temperature": 0.0, "avg_logprob": -0.10032833156301015, "compression_ratio": 1.8257575757575757, "no_speech_prob": 0.014237812720239162}, {"id": 748, "seek": 249600, "start": 2511.52, "end": 2513.28, "text": " But at the same time, at the end of the day,", "tokens": [51140, 583, 412, 264, 912, 565, 11, 412, 264, 917, 295, 264, 786, 11, 51228], "temperature": 0.0, "avg_logprob": -0.10032833156301015, "compression_ratio": 1.8257575757575757, "no_speech_prob": 0.014237812720239162}, {"id": 749, "seek": 249600, "start": 2513.28, "end": 2517.04, "text": " that machine has to subserve the propagation of those genes.", "tokens": [51228, 300, 3479, 575, 281, 2090, 3768, 264, 38377, 295, 729, 14424, 13, 51416], "temperature": 0.0, "avg_logprob": -0.10032833156301015, "compression_ratio": 1.8257575757575757, "no_speech_prob": 0.014237812720239162}, {"id": 750, "seek": 249600, "start": 2517.04, "end": 2518.48, "text": " And the way you do this, right,", "tokens": [51416, 400, 264, 636, 291, 360, 341, 11, 558, 11, 51488], "temperature": 0.0, "avg_logprob": -0.10032833156301015, "compression_ratio": 1.8257575757575757, "no_speech_prob": 0.014237812720239162}, {"id": 751, "seek": 249600, "start": 2518.48, "end": 2520.0, "text": " at least the way evolution seems to have done,", "tokens": [51488, 412, 1935, 264, 636, 9303, 2544, 281, 362, 1096, 11, 51564], "temperature": 0.0, "avg_logprob": -0.10032833156301015, "compression_ratio": 1.8257575757575757, "no_speech_prob": 0.014237812720239162}, {"id": 752, "seek": 249600, "start": 2520.0, "end": 2521.36, "text": " and I think it makes a lot of sense,", "tokens": [51564, 293, 286, 519, 309, 1669, 257, 688, 295, 2020, 11, 51632], "temperature": 0.0, "avg_logprob": -0.10032833156301015, "compression_ratio": 1.8257575757575757, "no_speech_prob": 0.014237812720239162}, {"id": 753, "seek": 249600, "start": 2521.36, "end": 2523.6, "text": " is that you don't just have one utility.", "tokens": [51632, 307, 300, 291, 500, 380, 445, 362, 472, 14877, 13, 51744], "temperature": 0.0, "avg_logprob": -0.10032833156301015, "compression_ratio": 1.8257575757575757, "no_speech_prob": 0.014237812720239162}, {"id": 754, "seek": 252360, "start": 2523.6, "end": 2526.88, "text": " You have several ones which correspond to your emotions.", "tokens": [50364, 509, 362, 2940, 2306, 597, 6805, 281, 428, 8462, 13, 50528], "temperature": 0.0, "avg_logprob": -0.08589232245156932, "compression_ratio": 1.8103448275862069, "no_speech_prob": 0.0069971648044884205}, {"id": 755, "seek": 252360, "start": 2527.8399999999997, "end": 2529.04, "text": " And then they fight it out.", "tokens": [50576, 400, 550, 436, 2092, 309, 484, 13, 50636], "temperature": 0.0, "avg_logprob": -0.08589232245156932, "compression_ratio": 1.8103448275862069, "no_speech_prob": 0.0069971648044884205}, {"id": 756, "seek": 252360, "start": 2529.7599999999998, "end": 2531.2799999999997, "text": " So I actually think there's this connection", "tokens": [50672, 407, 286, 767, 519, 456, 311, 341, 4984, 50748], "temperature": 0.0, "avg_logprob": -0.08589232245156932, "compression_ratio": 1.8103448275862069, "no_speech_prob": 0.0069971648044884205}, {"id": 757, "seek": 252360, "start": 2531.2799999999997, "end": 2533.52, "text": " between rationality and the emotion that people don't make,", "tokens": [50748, 1296, 15090, 507, 293, 264, 8913, 300, 561, 500, 380, 652, 11, 50860], "temperature": 0.0, "avg_logprob": -0.08589232245156932, "compression_ratio": 1.8103448275862069, "no_speech_prob": 0.0069971648044884205}, {"id": 758, "seek": 252360, "start": 2533.52, "end": 2537.36, "text": " which is that your emotions are really your utility functions.", "tokens": [50860, 597, 307, 300, 428, 8462, 366, 534, 428, 14877, 6828, 13, 51052], "temperature": 0.0, "avg_logprob": -0.08589232245156932, "compression_ratio": 1.8103448275862069, "no_speech_prob": 0.0069971648044884205}, {"id": 759, "seek": 252360, "start": 2537.36, "end": 2541.36, "text": " You just have different ones that cater to different things, right?", "tokens": [51052, 509, 445, 362, 819, 2306, 300, 21557, 281, 819, 721, 11, 558, 30, 51252], "temperature": 0.0, "avg_logprob": -0.08589232245156932, "compression_ratio": 1.8103448275862069, "no_speech_prob": 0.0069971648044884205}, {"id": 760, "seek": 252360, "start": 2541.36, "end": 2543.8399999999997, "text": " You know, fear and anger and so on.", "tokens": [51252, 509, 458, 11, 4240, 293, 10240, 293, 370, 322, 13, 51376], "temperature": 0.0, "avg_logprob": -0.08589232245156932, "compression_ratio": 1.8103448275862069, "no_speech_prob": 0.0069971648044884205}, {"id": 761, "seek": 252360, "start": 2543.8399999999997, "end": 2545.52, "text": " And so I think in reality,", "tokens": [51376, 400, 370, 286, 519, 294, 4103, 11, 51460], "temperature": 0.0, "avg_logprob": -0.08589232245156932, "compression_ratio": 1.8103448275862069, "no_speech_prob": 0.0069971648044884205}, {"id": 762, "seek": 252360, "start": 2545.52, "end": 2547.6, "text": " we actually have multiple utility functions.", "tokens": [51460, 321, 767, 362, 3866, 14877, 6828, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08589232245156932, "compression_ratio": 1.8103448275862069, "no_speech_prob": 0.0069971648044884205}, {"id": 763, "seek": 252360, "start": 2547.6, "end": 2550.16, "text": " But because, again, it gets to this problem that", "tokens": [51564, 583, 570, 11, 797, 11, 309, 2170, 281, 341, 1154, 300, 51692], "temperature": 0.0, "avg_logprob": -0.08589232245156932, "compression_ratio": 1.8103448275862069, "no_speech_prob": 0.0069971648044884205}, {"id": 764, "seek": 252360, "start": 2550.16, "end": 2551.92, "text": " what we're trying to do is approximate something", "tokens": [51692, 437, 321, 434, 1382, 281, 360, 307, 30874, 746, 51780], "temperature": 0.0, "avg_logprob": -0.08589232245156932, "compression_ratio": 1.8103448275862069, "no_speech_prob": 0.0069971648044884205}, {"id": 765, "seek": 255192, "start": 2551.92, "end": 2554.08, "text": " that is very complex and difficult to get at,", "tokens": [50364, 300, 307, 588, 3997, 293, 2252, 281, 483, 412, 11, 50472], "temperature": 0.0, "avg_logprob": -0.09713547666307906, "compression_ratio": 1.7662337662337662, "no_speech_prob": 0.0065762875601649284}, {"id": 766, "seek": 255192, "start": 2554.08, "end": 2555.44, "text": " maybe it is just one,", "tokens": [50472, 1310, 309, 307, 445, 472, 11, 50540], "temperature": 0.0, "avg_logprob": -0.09713547666307906, "compression_ratio": 1.7662337662337662, "no_speech_prob": 0.0065762875601649284}, {"id": 767, "seek": 255192, "start": 2555.44, "end": 2557.28, "text": " but we're better off trying to approximate it", "tokens": [50540, 457, 321, 434, 1101, 766, 1382, 281, 30874, 309, 50632], "temperature": 0.0, "avg_logprob": -0.09713547666307906, "compression_ratio": 1.7662337662337662, "no_speech_prob": 0.0065762875601649284}, {"id": 768, "seek": 255192, "start": 2557.28, "end": 2558.56, "text": " with 10 or 20 different things", "tokens": [50632, 365, 1266, 420, 945, 819, 721, 50696], "temperature": 0.0, "avg_logprob": -0.09713547666307906, "compression_ratio": 1.7662337662337662, "no_speech_prob": 0.0065762875601649284}, {"id": 769, "seek": 255192, "start": 2558.56, "end": 2560.56, "text": " than just trying to nail that one thing.", "tokens": [50696, 813, 445, 1382, 281, 10173, 300, 472, 551, 13, 50796], "temperature": 0.0, "avg_logprob": -0.09713547666307906, "compression_ratio": 1.7662337662337662, "no_speech_prob": 0.0065762875601649284}, {"id": 770, "seek": 255192, "start": 2561.2000000000003, "end": 2562.0, "text": " That's really interesting.", "tokens": [50828, 663, 311, 534, 1880, 13, 50868], "temperature": 0.0, "avg_logprob": -0.09713547666307906, "compression_ratio": 1.7662337662337662, "no_speech_prob": 0.0065762875601649284}, {"id": 771, "seek": 255192, "start": 2562.0, "end": 2564.88, "text": " And is your view then on having this diversity", "tokens": [50868, 400, 307, 428, 1910, 550, 322, 1419, 341, 8811, 51012], "temperature": 0.0, "avg_logprob": -0.09713547666307906, "compression_ratio": 1.7662337662337662, "no_speech_prob": 0.0065762875601649284}, {"id": 772, "seek": 255192, "start": 2564.88, "end": 2567.6, "text": " of utility functions analogous to your views", "tokens": [51012, 295, 14877, 6828, 16660, 563, 281, 428, 6809, 51148], "temperature": 0.0, "avg_logprob": -0.09713547666307906, "compression_ratio": 1.7662337662337662, "no_speech_prob": 0.0065762875601649284}, {"id": 773, "seek": 255192, "start": 2567.6, "end": 2568.96, "text": " on the master algorithm?", "tokens": [51148, 322, 264, 4505, 9284, 30, 51216], "temperature": 0.0, "avg_logprob": -0.09713547666307906, "compression_ratio": 1.7662337662337662, "no_speech_prob": 0.0065762875601649284}, {"id": 774, "seek": 255192, "start": 2569.6800000000003, "end": 2571.6800000000003, "text": " Huh. It's analogous,", "tokens": [51252, 8063, 13, 467, 311, 16660, 563, 11, 51352], "temperature": 0.0, "avg_logprob": -0.09713547666307906, "compression_ratio": 1.7662337662337662, "no_speech_prob": 0.0065762875601649284}, {"id": 775, "seek": 255192, "start": 2571.6800000000003, "end": 2573.76, "text": " but you're actually talking about different dimensions, right?", "tokens": [51352, 457, 291, 434, 767, 1417, 466, 819, 12819, 11, 558, 30, 51456], "temperature": 0.0, "avg_logprob": -0.09713547666307906, "compression_ratio": 1.7662337662337662, "no_speech_prob": 0.0065762875601649284}, {"id": 776, "seek": 255192, "start": 2573.76, "end": 2575.84, "text": " You could make a table where on one side", "tokens": [51456, 509, 727, 652, 257, 3199, 689, 322, 472, 1252, 51560], "temperature": 0.0, "avg_logprob": -0.09713547666307906, "compression_ratio": 1.7662337662337662, "no_speech_prob": 0.0065762875601649284}, {"id": 777, "seek": 255192, "start": 2575.84, "end": 2577.84, "text": " you have all the different utilities,", "tokens": [51560, 291, 362, 439, 264, 819, 30482, 11, 51660], "temperature": 0.0, "avg_logprob": -0.09713547666307906, "compression_ratio": 1.7662337662337662, "no_speech_prob": 0.0065762875601649284}, {"id": 778, "seek": 255192, "start": 2577.84, "end": 2579.92, "text": " and then on the other side you have the algorithms.", "tokens": [51660, 293, 550, 322, 264, 661, 1252, 291, 362, 264, 14642, 13, 51764], "temperature": 0.0, "avg_logprob": -0.09713547666307906, "compression_ratio": 1.7662337662337662, "no_speech_prob": 0.0065762875601649284}, {"id": 779, "seek": 257992, "start": 2579.92, "end": 2582.08, "text": " And now you can pair off any one of them.", "tokens": [50364, 400, 586, 291, 393, 6119, 766, 604, 472, 295, 552, 13, 50472], "temperature": 0.0, "avg_logprob": -0.15587756508275083, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.008152447640895844}, {"id": 780, "seek": 257992, "start": 2582.08, "end": 2584.48, "text": " I can say, I'm going to pursue this,", "tokens": [50472, 286, 393, 584, 11, 286, 478, 516, 281, 12392, 341, 11, 50592], "temperature": 0.0, "avg_logprob": -0.15587756508275083, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.008152447640895844}, {"id": 781, "seek": 257992, "start": 2584.48, "end": 2588.4, "text": " you know, minimize your fear using symbolism or minimum.", "tokens": [50592, 291, 458, 11, 17522, 428, 4240, 1228, 47061, 420, 7285, 13, 50788], "temperature": 0.0, "avg_logprob": -0.15587756508275083, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.008152447640895844}, {"id": 782, "seek": 257992, "start": 2588.4, "end": 2589.6800000000003, "text": " So any combination is valid.", "tokens": [50788, 407, 604, 6562, 307, 7363, 13, 50852], "temperature": 0.0, "avg_logprob": -0.15587756508275083, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.008152447640895844}, {"id": 783, "seek": 257992, "start": 2591.04, "end": 2592.16, "text": " Really, really interesting.", "tokens": [50920, 4083, 11, 534, 1880, 13, 50976], "temperature": 0.0, "avg_logprob": -0.15587756508275083, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.008152447640895844}, {"id": 784, "seek": 257992, "start": 2592.16, "end": 2595.52, "text": " Okay. And then let's get into meritocracy, for example.", "tokens": [50976, 1033, 13, 400, 550, 718, 311, 483, 666, 24527, 38186, 11, 337, 1365, 13, 51144], "temperature": 0.0, "avg_logprob": -0.15587756508275083, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.008152447640895844}, {"id": 785, "seek": 257992, "start": 2595.52, "end": 2597.52, "text": " So at the moment, we do have the market system.", "tokens": [51144, 407, 412, 264, 1623, 11, 321, 360, 362, 264, 2142, 1185, 13, 51244], "temperature": 0.0, "avg_logprob": -0.15587756508275083, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.008152447640895844}, {"id": 786, "seek": 257992, "start": 2597.52, "end": 2599.6800000000003, "text": " And presumably you think that some people", "tokens": [51244, 400, 26742, 291, 519, 300, 512, 561, 51352], "temperature": 0.0, "avg_logprob": -0.15587756508275083, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.008152447640895844}, {"id": 787, "seek": 257992, "start": 2599.6800000000003, "end": 2601.76, "text": " do genuinely have more market value than others.", "tokens": [51352, 360, 17839, 362, 544, 2142, 2158, 813, 2357, 13, 51456], "temperature": 0.0, "avg_logprob": -0.15587756508275083, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.008152447640895844}, {"id": 788, "seek": 257992, "start": 2602.56, "end": 2604.7200000000003, "text": " For sure. No. And by the way, I think,", "tokens": [51496, 1171, 988, 13, 883, 13, 400, 538, 264, 636, 11, 286, 519, 11, 51604], "temperature": 0.0, "avg_logprob": -0.15587756508275083, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.008152447640895844}, {"id": 789, "seek": 257992, "start": 2605.36, "end": 2608.32, "text": " I'm definitely a big believer in meritocracy.", "tokens": [51636, 286, 478, 2138, 257, 955, 23892, 294, 24527, 38186, 13, 51784], "temperature": 0.0, "avg_logprob": -0.15587756508275083, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.008152447640895844}, {"id": 790, "seek": 260832, "start": 2608.32, "end": 2611.2000000000003, "text": " I think. But what does it mean to you?", "tokens": [50364, 286, 519, 13, 583, 437, 775, 309, 914, 281, 291, 30, 50508], "temperature": 0.0, "avg_logprob": -0.12840152349997694, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0017504239222034812}, {"id": 791, "seek": 260832, "start": 2611.2000000000003, "end": 2614.0, "text": " Right. Very good. So let's get that down first, right?", "tokens": [50508, 1779, 13, 4372, 665, 13, 407, 718, 311, 483, 300, 760, 700, 11, 558, 30, 50648], "temperature": 0.0, "avg_logprob": -0.12840152349997694, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0017504239222034812}, {"id": 792, "seek": 260832, "start": 2614.0, "end": 2618.2400000000002, "text": " Meritocracy, so our goal is to have the society", "tokens": [50648, 6124, 270, 38186, 11, 370, 527, 3387, 307, 281, 362, 264, 4086, 50860], "temperature": 0.0, "avg_logprob": -0.12840152349997694, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0017504239222034812}, {"id": 793, "seek": 260832, "start": 2618.2400000000002, "end": 2622.48, "text": " that functions best and provides best for everybody, right?", "tokens": [50860, 300, 6828, 1151, 293, 6417, 1151, 337, 2201, 11, 558, 30, 51072], "temperature": 0.0, "avg_logprob": -0.12840152349997694, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0017504239222034812}, {"id": 794, "seek": 260832, "start": 2623.28, "end": 2625.2000000000003, "text": " And I mean, we could refine even that,", "tokens": [51112, 400, 286, 914, 11, 321, 727, 33906, 754, 300, 11, 51208], "temperature": 0.0, "avg_logprob": -0.12840152349997694, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0017504239222034812}, {"id": 795, "seek": 260832, "start": 2625.2000000000003, "end": 2627.6800000000003, "text": " but let's just take that for now as our assumption, right?", "tokens": [51208, 457, 718, 311, 445, 747, 300, 337, 586, 382, 527, 15302, 11, 558, 30, 51332], "temperature": 0.0, "avg_logprob": -0.12840152349997694, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0017504239222034812}, {"id": 796, "seek": 260832, "start": 2627.6800000000003, "end": 2629.2000000000003, "text": " But then if that is the case,", "tokens": [51332, 583, 550, 498, 300, 307, 264, 1389, 11, 51408], "temperature": 0.0, "avg_logprob": -0.12840152349997694, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0017504239222034812}, {"id": 797, "seek": 260832, "start": 2629.2000000000003, "end": 2632.32, "text": " one of our primary goals, maybe even the most important one,", "tokens": [51408, 472, 295, 527, 6194, 5493, 11, 1310, 754, 264, 881, 1021, 472, 11, 51564], "temperature": 0.0, "avg_logprob": -0.12840152349997694, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0017504239222034812}, {"id": 798, "seek": 260832, "start": 2632.32, "end": 2636.6400000000003, "text": " is to get everybody to contribute the most they can, right?", "tokens": [51564, 307, 281, 483, 2201, 281, 10586, 264, 881, 436, 393, 11, 558, 30, 51780], "temperature": 0.0, "avg_logprob": -0.12840152349997694, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0017504239222034812}, {"id": 799, "seek": 263664, "start": 2636.64, "end": 2638.8799999999997, "text": " Meritocracy is often seen as like,", "tokens": [50364, 6124, 270, 38186, 307, 2049, 1612, 382, 411, 11, 50476], "temperature": 0.0, "avg_logprob": -0.11022427924593589, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.005372393410652876}, {"id": 800, "seek": 263664, "start": 2638.8799999999997, "end": 2640.3199999999997, "text": " I'm going to rank all the people,", "tokens": [50476, 286, 478, 516, 281, 6181, 439, 264, 561, 11, 50548], "temperature": 0.0, "avg_logprob": -0.11022427924593589, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.005372393410652876}, {"id": 801, "seek": 263664, "start": 2640.3199999999997, "end": 2642.4, "text": " and at the top is the greatest genius,", "tokens": [50548, 293, 412, 264, 1192, 307, 264, 6636, 14017, 11, 50652], "temperature": 0.0, "avg_logprob": -0.11022427924593589, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.005372393410652876}, {"id": 802, "seek": 263664, "start": 2642.4, "end": 2644.3199999999997, "text": " and at the bottom is the most useless person,", "tokens": [50652, 293, 412, 264, 2767, 307, 264, 881, 14115, 954, 11, 50748], "temperature": 0.0, "avg_logprob": -0.11022427924593589, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.005372393410652876}, {"id": 803, "seek": 263664, "start": 2644.3199999999997, "end": 2646.08, "text": " and this is wrong, right?", "tokens": [50748, 293, 341, 307, 2085, 11, 558, 30, 50836], "temperature": 0.0, "avg_logprob": -0.11022427924593589, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.005372393410652876}, {"id": 804, "seek": 263664, "start": 2646.08, "end": 2649.52, "text": " Meritocracy is a many-dimension thing, right?", "tokens": [50836, 6124, 270, 38186, 307, 257, 867, 12, 13595, 3378, 551, 11, 558, 30, 51008], "temperature": 0.0, "avg_logprob": -0.11022427924593589, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.005372393410652876}, {"id": 805, "seek": 263664, "start": 2649.52, "end": 2652.16, "text": " The goal of meritocracy is to find for everybody", "tokens": [51008, 440, 3387, 295, 24527, 38186, 307, 281, 915, 337, 2201, 51140], "temperature": 0.0, "avg_logprob": -0.11022427924593589, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.005372393410652876}, {"id": 806, "seek": 263664, "start": 2652.16, "end": 2654.72, "text": " what they're best at doing so that they can do it,", "tokens": [51140, 437, 436, 434, 1151, 412, 884, 370, 300, 436, 393, 360, 309, 11, 51268], "temperature": 0.0, "avg_logprob": -0.11022427924593589, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.005372393410652876}, {"id": 807, "seek": 263664, "start": 2655.2799999999997, "end": 2658.0, "text": " maximize everybody's contribution to society, right?", "tokens": [51296, 19874, 2201, 311, 13150, 281, 4086, 11, 558, 30, 51432], "temperature": 0.0, "avg_logprob": -0.11022427924593589, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.005372393410652876}, {"id": 808, "seek": 263664, "start": 2659.12, "end": 2660.96, "text": " And this is a very complicated process.", "tokens": [51488, 400, 341, 307, 257, 588, 6179, 1399, 13, 51580], "temperature": 0.0, "avg_logprob": -0.11022427924593589, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.005372393410652876}, {"id": 809, "seek": 263664, "start": 2660.96, "end": 2663.52, "text": " There isn't a single scale of intelligence or anything else.", "tokens": [51580, 821, 1943, 380, 257, 2167, 4373, 295, 7599, 420, 1340, 1646, 13, 51708], "temperature": 0.0, "avg_logprob": -0.11022427924593589, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.005372393410652876}, {"id": 810, "seek": 266352, "start": 2664.08, "end": 2667.04, "text": " Having said that, it very much is the case", "tokens": [50392, 10222, 848, 300, 11, 309, 588, 709, 307, 264, 1389, 50540], "temperature": 0.0, "avg_logprob": -0.08521750457304761, "compression_ratio": 1.68259385665529, "no_speech_prob": 0.056488748639822006}, {"id": 811, "seek": 266352, "start": 2667.04, "end": 2670.72, "text": " that some people are better for some things than others, right?", "tokens": [50540, 300, 512, 561, 366, 1101, 337, 512, 721, 813, 2357, 11, 558, 30, 50724], "temperature": 0.0, "avg_logprob": -0.08521750457304761, "compression_ratio": 1.68259385665529, "no_speech_prob": 0.056488748639822006}, {"id": 812, "seek": 266352, "start": 2670.72, "end": 2671.92, "text": " And if you deny that,", "tokens": [50724, 400, 498, 291, 15744, 300, 11, 50784], "temperature": 0.0, "avg_logprob": -0.08521750457304761, "compression_ratio": 1.68259385665529, "no_speech_prob": 0.056488748639822006}, {"id": 813, "seek": 266352, "start": 2671.92, "end": 2674.32, "text": " you are actually in the process of destroying the society", "tokens": [50784, 291, 366, 767, 294, 264, 1399, 295, 19926, 264, 4086, 50904], "temperature": 0.0, "avg_logprob": -0.08521750457304761, "compression_ratio": 1.68259385665529, "no_speech_prob": 0.056488748639822006}, {"id": 814, "seek": 266352, "start": 2674.32, "end": 2675.44, "text": " and making it dysfunctional.", "tokens": [50904, 293, 1455, 309, 32002, 304, 13, 50960], "temperature": 0.0, "avg_logprob": -0.08521750457304761, "compression_ratio": 1.68259385665529, "no_speech_prob": 0.056488748639822006}, {"id": 815, "seek": 266352, "start": 2675.44, "end": 2681.12, "text": " So I find the attacks on meritocracy extremely disturbing, right?", "tokens": [50960, 407, 286, 915, 264, 8122, 322, 24527, 38186, 4664, 21903, 11, 558, 30, 51244], "temperature": 0.0, "avg_logprob": -0.08521750457304761, "compression_ratio": 1.68259385665529, "no_speech_prob": 0.056488748639822006}, {"id": 816, "seek": 266352, "start": 2681.12, "end": 2682.48, "text": " And a lot of them are,", "tokens": [51244, 400, 257, 688, 295, 552, 366, 11, 51312], "temperature": 0.0, "avg_logprob": -0.08521750457304761, "compression_ratio": 1.68259385665529, "no_speech_prob": 0.056488748639822006}, {"id": 817, "seek": 266352, "start": 2682.48, "end": 2685.04, "text": " I've talked with many people who have those beliefs, right?", "tokens": [51312, 286, 600, 2825, 365, 867, 561, 567, 362, 729, 13585, 11, 558, 30, 51440], "temperature": 0.0, "avg_logprob": -0.08521750457304761, "compression_ratio": 1.68259385665529, "no_speech_prob": 0.056488748639822006}, {"id": 818, "seek": 266352, "start": 2685.04, "end": 2686.88, "text": " And the number one thing that they say is,", "tokens": [51440, 400, 264, 1230, 472, 551, 300, 436, 584, 307, 11, 51532], "temperature": 0.0, "avg_logprob": -0.08521750457304761, "compression_ratio": 1.68259385665529, "no_speech_prob": 0.056488748639822006}, {"id": 819, "seek": 266352, "start": 2686.88, "end": 2688.32, "text": " it basically boils down to like,", "tokens": [51532, 309, 1936, 35049, 760, 281, 411, 11, 51604], "temperature": 0.0, "avg_logprob": -0.08521750457304761, "compression_ratio": 1.68259385665529, "no_speech_prob": 0.056488748639822006}, {"id": 820, "seek": 266352, "start": 2688.32, "end": 2691.12, "text": " oh, meritocracy isn't perfect, so we should junk it.", "tokens": [51604, 1954, 11, 24527, 38186, 1943, 380, 2176, 11, 370, 321, 820, 19109, 309, 13, 51744], "temperature": 0.0, "avg_logprob": -0.08521750457304761, "compression_ratio": 1.68259385665529, "no_speech_prob": 0.056488748639822006}, {"id": 821, "seek": 269112, "start": 2691.92, "end": 2694.88, "text": " Something not being perfect has never been a reason to junk it.", "tokens": [50404, 6595, 406, 885, 2176, 575, 1128, 668, 257, 1778, 281, 19109, 309, 13, 50552], "temperature": 0.0, "avg_logprob": -0.09423419407435826, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.0038154807407408953}, {"id": 822, "seek": 269112, "start": 2694.88, "end": 2696.0, "text": " It's a reason to improve it.", "tokens": [50552, 467, 311, 257, 1778, 281, 3470, 309, 13, 50608], "temperature": 0.0, "avg_logprob": -0.09423419407435826, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.0038154807407408953}, {"id": 823, "seek": 269112, "start": 2696.0, "end": 2699.2, "text": " So there's a lot of room to improve in meritocracy,", "tokens": [50608, 407, 456, 311, 257, 688, 295, 1808, 281, 3470, 294, 24527, 38186, 11, 50768], "temperature": 0.0, "avg_logprob": -0.09423419407435826, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.0038154807407408953}, {"id": 824, "seek": 269112, "start": 2699.2, "end": 2701.68, "text": " but if you throw it away, you are destroying society.", "tokens": [50768, 457, 498, 291, 3507, 309, 1314, 11, 291, 366, 19926, 4086, 13, 50892], "temperature": 0.0, "avg_logprob": -0.09423419407435826, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.0038154807407408953}, {"id": 825, "seek": 269112, "start": 2702.24, "end": 2706.64, "text": " Well, I mean, you can trace this back to our argument about utility.", "tokens": [50920, 1042, 11, 286, 914, 11, 291, 393, 13508, 341, 646, 281, 527, 6770, 466, 14877, 13, 51140], "temperature": 0.0, "avg_logprob": -0.09423419407435826, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.0038154807407408953}, {"id": 826, "seek": 269112, "start": 2706.64, "end": 2711.8399999999997, "text": " But the thing is though, if we had a value function", "tokens": [51140, 583, 264, 551, 307, 1673, 11, 498, 321, 632, 257, 2158, 2445, 51400], "temperature": 0.0, "avg_logprob": -0.09423419407435826, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.0038154807407408953}, {"id": 827, "seek": 269112, "start": 2711.8399999999997, "end": 2714.16, "text": " which represented actual market contributions", "tokens": [51400, 597, 10379, 3539, 2142, 15725, 51516], "temperature": 0.0, "avg_logprob": -0.09423419407435826, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.0038154807407408953}, {"id": 828, "seek": 269112, "start": 2714.16, "end": 2716.56, "text": " or even societal contributions, that would be one thing.", "tokens": [51516, 420, 754, 33472, 15725, 11, 300, 576, 312, 472, 551, 13, 51636], "temperature": 0.0, "avg_logprob": -0.09423419407435826, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.0038154807407408953}, {"id": 829, "seek": 269112, "start": 2716.56, "end": 2720.48, "text": " But would you agree that we have a lot of game playing at the moment?", "tokens": [51636, 583, 576, 291, 3986, 300, 321, 362, 257, 688, 295, 1216, 2433, 412, 264, 1623, 30, 51832], "temperature": 0.0, "avg_logprob": -0.09423419407435826, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.0038154807407408953}, {"id": 830, "seek": 272048, "start": 2720.48, "end": 2723.36, "text": " So utility is based on playing the success game", "tokens": [50364, 407, 14877, 307, 2361, 322, 2433, 264, 2245, 1216, 50508], "temperature": 0.0, "avg_logprob": -0.11623275937057856, "compression_ratio": 1.7306273062730628, "no_speech_prob": 0.00999218039214611}, {"id": 831, "seek": 272048, "start": 2723.36, "end": 2725.12, "text": " or the dominance game or the virtue game,", "tokens": [50508, 420, 264, 34987, 1216, 420, 264, 20816, 1216, 11, 50596], "temperature": 0.0, "avg_logprob": -0.11623275937057856, "compression_ratio": 1.7306273062730628, "no_speech_prob": 0.00999218039214611}, {"id": 832, "seek": 272048, "start": 2725.12, "end": 2726.56, "text": " as Will Stor said in his book.", "tokens": [50596, 382, 3099, 745, 284, 848, 294, 702, 1446, 13, 50668], "temperature": 0.0, "avg_logprob": -0.11623275937057856, "compression_ratio": 1.7306273062730628, "no_speech_prob": 0.00999218039214611}, {"id": 833, "seek": 272048, "start": 2726.56, "end": 2728.8, "text": " So we've got these kind of emerging games", "tokens": [50668, 407, 321, 600, 658, 613, 733, 295, 14989, 2813, 50780], "temperature": 0.0, "avg_logprob": -0.11623275937057856, "compression_ratio": 1.7306273062730628, "no_speech_prob": 0.00999218039214611}, {"id": 834, "seek": 272048, "start": 2728.8, "end": 2732.96, "text": " and it's not really representing utility.", "tokens": [50780, 293, 309, 311, 406, 534, 13460, 14877, 13, 50988], "temperature": 0.0, "avg_logprob": -0.11623275937057856, "compression_ratio": 1.7306273062730628, "no_speech_prob": 0.00999218039214611}, {"id": 835, "seek": 272048, "start": 2733.6, "end": 2734.56, "text": " Well, absolutely.", "tokens": [51020, 1042, 11, 3122, 13, 51068], "temperature": 0.0, "avg_logprob": -0.11623275937057856, "compression_ratio": 1.7306273062730628, "no_speech_prob": 0.00999218039214611}, {"id": 836, "seek": 272048, "start": 2734.56, "end": 2738.32, "text": " So far we've been talking about utility, right?", "tokens": [51068, 407, 1400, 321, 600, 668, 1417, 466, 14877, 11, 558, 30, 51256], "temperature": 0.0, "avg_logprob": -0.11623275937057856, "compression_ratio": 1.7306273062730628, "no_speech_prob": 0.00999218039214611}, {"id": 837, "seek": 272048, "start": 2738.32, "end": 2739.76, "text": " But what happens in the real world", "tokens": [51256, 583, 437, 2314, 294, 264, 957, 1002, 51328], "temperature": 0.0, "avg_logprob": -0.11623275937057856, "compression_ratio": 1.7306273062730628, "no_speech_prob": 0.00999218039214611}, {"id": 838, "seek": 272048, "start": 2739.76, "end": 2741.76, "text": " is that there are multiple agents,", "tokens": [51328, 307, 300, 456, 366, 3866, 12554, 11, 51428], "temperature": 0.0, "avg_logprob": -0.11623275937057856, "compression_ratio": 1.7306273062730628, "no_speech_prob": 0.00999218039214611}, {"id": 839, "seek": 272048, "start": 2741.76, "end": 2743.36, "text": " each with their own different utility.", "tokens": [51428, 1184, 365, 641, 1065, 819, 14877, 13, 51508], "temperature": 0.0, "avg_logprob": -0.11623275937057856, "compression_ratio": 1.7306273062730628, "no_speech_prob": 0.00999218039214611}, {"id": 840, "seek": 272048, "start": 2744.16, "end": 2747.12, "text": " And at this point, what you have is game theory, right?", "tokens": [51548, 400, 412, 341, 935, 11, 437, 291, 362, 307, 1216, 5261, 11, 558, 30, 51696], "temperature": 0.0, "avg_logprob": -0.11623275937057856, "compression_ratio": 1.7306273062730628, "no_speech_prob": 0.00999218039214611}, {"id": 841, "seek": 272048, "start": 2747.12, "end": 2748.4, "text": " Game theory is just what you have", "tokens": [51696, 7522, 5261, 307, 445, 437, 291, 362, 51760], "temperature": 0.0, "avg_logprob": -0.11623275937057856, "compression_ratio": 1.7306273062730628, "no_speech_prob": 0.00999218039214611}, {"id": 842, "seek": 274840, "start": 2748.4, "end": 2750.96, "text": " when there's not a single optimization going on,", "tokens": [50364, 562, 456, 311, 406, 257, 2167, 19618, 516, 322, 11, 50492], "temperature": 0.0, "avg_logprob": -0.08465131123860677, "compression_ratio": 1.7041198501872659, "no_speech_prob": 0.004445514176040888}, {"id": 843, "seek": 274840, "start": 2750.96, "end": 2752.4, "text": " but multiple optimizations", "tokens": [50492, 457, 3866, 5028, 14455, 50564], "temperature": 0.0, "avg_logprob": -0.08465131123860677, "compression_ratio": 1.7041198501872659, "no_speech_prob": 0.004445514176040888}, {"id": 844, "seek": 274840, "start": 2752.4, "end": 2755.12, "text": " which are partly contradictory, maybe partly not.", "tokens": [50564, 597, 366, 17031, 49555, 11, 1310, 17031, 406, 13, 50700], "temperature": 0.0, "avg_logprob": -0.08465131123860677, "compression_ratio": 1.7041198501872659, "no_speech_prob": 0.004445514176040888}, {"id": 845, "seek": 274840, "start": 2755.12, "end": 2757.28, "text": " So the best way to understand everything", "tokens": [50700, 407, 264, 1151, 636, 281, 1223, 1203, 50808], "temperature": 0.0, "avg_logprob": -0.08465131123860677, "compression_ratio": 1.7041198501872659, "no_speech_prob": 0.004445514176040888}, {"id": 846, "seek": 274840, "start": 2757.28, "end": 2760.4, "text": " that we've been talking about, including society and evolution", "tokens": [50808, 300, 321, 600, 668, 1417, 466, 11, 3009, 4086, 293, 9303, 50964], "temperature": 0.0, "avg_logprob": -0.08465131123860677, "compression_ratio": 1.7041198501872659, "no_speech_prob": 0.004445514176040888}, {"id": 847, "seek": 274840, "start": 2760.4, "end": 2763.52, "text": " and even what happens inside your brain is as a big game.", "tokens": [50964, 293, 754, 437, 2314, 1854, 428, 3567, 307, 382, 257, 955, 1216, 13, 51120], "temperature": 0.0, "avg_logprob": -0.08465131123860677, "compression_ratio": 1.7041198501872659, "no_speech_prob": 0.004445514176040888}, {"id": 848, "seek": 274840, "start": 2764.2400000000002, "end": 2766.32, "text": " A much bigger and more complex game", "tokens": [51156, 316, 709, 3801, 293, 544, 3997, 1216, 51260], "temperature": 0.0, "avg_logprob": -0.08465131123860677, "compression_ratio": 1.7041198501872659, "no_speech_prob": 0.004445514176040888}, {"id": 849, "seek": 274840, "start": 2766.32, "end": 2768.88, "text": " than game theorists and economists and so on", "tokens": [51260, 813, 1216, 27423, 1751, 293, 32431, 293, 370, 322, 51388], "temperature": 0.0, "avg_logprob": -0.08465131123860677, "compression_ratio": 1.7041198501872659, "no_speech_prob": 0.004445514176040888}, {"id": 850, "seek": 274840, "start": 2768.88, "end": 2772.48, "text": " and evolutionary biologists, right, prominently,", "tokens": [51388, 293, 27567, 3228, 12256, 11, 558, 11, 39225, 2276, 11, 51568], "temperature": 0.0, "avg_logprob": -0.08465131123860677, "compression_ratio": 1.7041198501872659, "no_speech_prob": 0.004445514176040888}, {"id": 851, "seek": 274840, "start": 2772.48, "end": 2774.96, "text": " have been able to handle in the past.", "tokens": [51568, 362, 668, 1075, 281, 4813, 294, 264, 1791, 13, 51692], "temperature": 0.0, "avg_logprob": -0.08465131123860677, "compression_ratio": 1.7041198501872659, "no_speech_prob": 0.004445514176040888}, {"id": 852, "seek": 277496, "start": 2774.96, "end": 2778.7200000000003, "text": " But I think they are very much in the right track", "tokens": [50364, 583, 286, 519, 436, 366, 588, 709, 294, 264, 558, 2837, 50552], "temperature": 0.0, "avg_logprob": -0.13114295100534198, "compression_ratio": 1.8724137931034484, "no_speech_prob": 0.03486531600356102}, {"id": 853, "seek": 277496, "start": 2778.7200000000003, "end": 2781.04, "text": " and we can understand a lot of these phenomena", "tokens": [50552, 293, 321, 393, 1223, 257, 688, 295, 613, 22004, 50668], "temperature": 0.0, "avg_logprob": -0.13114295100534198, "compression_ratio": 1.8724137931034484, "no_speech_prob": 0.03486531600356102}, {"id": 854, "seek": 277496, "start": 2781.04, "end": 2784.48, "text": " that you're referring to as they are games being played", "tokens": [50668, 300, 291, 434, 13761, 281, 382, 436, 366, 2813, 885, 3737, 50840], "temperature": 0.0, "avg_logprob": -0.13114295100534198, "compression_ratio": 1.8724137931034484, "no_speech_prob": 0.03486531600356102}, {"id": 855, "seek": 277496, "start": 2784.48, "end": 2786.88, "text": " by people that have certain utilities, right?", "tokens": [50840, 538, 561, 300, 362, 1629, 30482, 11, 558, 30, 50960], "temperature": 0.0, "avg_logprob": -0.13114295100534198, "compression_ratio": 1.8724137931034484, "no_speech_prob": 0.03486531600356102}, {"id": 856, "seek": 277496, "start": 2787.44, "end": 2789.84, "text": " And now you are going to impose your, you know, like,", "tokens": [50988, 400, 586, 291, 366, 516, 281, 26952, 428, 11, 291, 458, 11, 411, 11, 51108], "temperature": 0.0, "avg_logprob": -0.13114295100534198, "compression_ratio": 1.8724137931034484, "no_speech_prob": 0.03486531600356102}, {"id": 857, "seek": 277496, "start": 2789.84, "end": 2791.12, "text": " and it's a game, right?", "tokens": [51108, 293, 309, 311, 257, 1216, 11, 558, 30, 51172], "temperature": 0.0, "avg_logprob": -0.13114295100534198, "compression_ratio": 1.8724137931034484, "no_speech_prob": 0.03486531600356102}, {"id": 858, "seek": 277496, "start": 2791.12, "end": 2792.96, "text": " I don't, you don't know who's going to win", "tokens": [51172, 286, 500, 380, 11, 291, 500, 380, 458, 567, 311, 516, 281, 1942, 51264], "temperature": 0.0, "avg_logprob": -0.13114295100534198, "compression_ratio": 1.8724137931034484, "no_speech_prob": 0.03486531600356102}, {"id": 859, "seek": 277496, "start": 2792.96, "end": 2795.36, "text": " until you actually do the linear program", "tokens": [51264, 1826, 291, 767, 360, 264, 8213, 1461, 51384], "temperature": 0.0, "avg_logprob": -0.13114295100534198, "compression_ratio": 1.8724137931034484, "no_speech_prob": 0.03486531600356102}, {"id": 860, "seek": 277496, "start": 2795.36, "end": 2797.44, "text": " and figure out how this is going to, you know,", "tokens": [51384, 293, 2573, 484, 577, 341, 307, 516, 281, 11, 291, 458, 11, 51488], "temperature": 0.0, "avg_logprob": -0.13114295100534198, "compression_ratio": 1.8724137931034484, "no_speech_prob": 0.03486531600356102}, {"id": 861, "seek": 277496, "start": 2798.0, "end": 2800.7200000000003, "text": " and of course games are, you know, in reality,", "tokens": [51516, 293, 295, 1164, 2813, 366, 11, 291, 458, 11, 294, 4103, 11, 51652], "temperature": 0.0, "avg_logprob": -0.13114295100534198, "compression_ratio": 1.8724137931034484, "no_speech_prob": 0.03486531600356102}, {"id": 862, "seek": 277496, "start": 2800.7200000000003, "end": 2803.04, "text": " you know, most games are not single round games, right?", "tokens": [51652, 291, 458, 11, 881, 2813, 366, 406, 2167, 3098, 2813, 11, 558, 30, 51768], "temperature": 0.0, "avg_logprob": -0.13114295100534198, "compression_ratio": 1.8724137931034484, "no_speech_prob": 0.03486531600356102}, {"id": 863, "seek": 277496, "start": 2803.04, "end": 2804.7200000000003, "text": " They're continuing games, right?", "tokens": [51768, 814, 434, 9289, 2813, 11, 558, 30, 51852], "temperature": 0.0, "avg_logprob": -0.13114295100534198, "compression_ratio": 1.8724137931034484, "no_speech_prob": 0.03486531600356102}, {"id": 864, "seek": 280496, "start": 2804.96, "end": 2806.88, "text": " So things get very, very interesting,", "tokens": [50364, 407, 721, 483, 588, 11, 588, 1880, 11, 50460], "temperature": 0.0, "avg_logprob": -0.0863067134734123, "compression_ratio": 1.8125, "no_speech_prob": 0.002123510930687189}, {"id": 865, "seek": 280496, "start": 2806.88, "end": 2810.08, "text": " but this I think is the most productive way", "tokens": [50460, 457, 341, 286, 519, 307, 264, 881, 13304, 636, 50620], "temperature": 0.0, "avg_logprob": -0.0863067134734123, "compression_ratio": 1.8125, "no_speech_prob": 0.002123510930687189}, {"id": 866, "seek": 280496, "start": 2810.08, "end": 2811.2, "text": " to look at all of this.", "tokens": [50620, 281, 574, 412, 439, 295, 341, 13, 50676], "temperature": 0.0, "avg_logprob": -0.0863067134734123, "compression_ratio": 1.8125, "no_speech_prob": 0.002123510930687189}, {"id": 867, "seek": 280496, "start": 2811.2, "end": 2812.16, "text": " Okay, good, good.", "tokens": [50676, 1033, 11, 665, 11, 665, 13, 50724], "temperature": 0.0, "avg_logprob": -0.0863067134734123, "compression_ratio": 1.8125, "no_speech_prob": 0.002123510930687189}, {"id": 868, "seek": 280496, "start": 2812.16, "end": 2815.6, "text": " But then some might say that this is a platonic way", "tokens": [50724, 583, 550, 512, 1062, 584, 300, 341, 307, 257, 3403, 11630, 636, 50896], "temperature": 0.0, "avg_logprob": -0.0863067134734123, "compression_ratio": 1.8125, "no_speech_prob": 0.002123510930687189}, {"id": 869, "seek": 280496, "start": 2815.6, "end": 2817.28, "text": " of looking at the world", "tokens": [50896, 295, 1237, 412, 264, 1002, 50980], "temperature": 0.0, "avg_logprob": -0.0863067134734123, "compression_ratio": 1.8125, "no_speech_prob": 0.002123510930687189}, {"id": 870, "seek": 280496, "start": 2817.28, "end": 2819.6, "text": " and the world is actually much more complicated than that.", "tokens": [50980, 293, 264, 1002, 307, 767, 709, 544, 6179, 813, 300, 13, 51096], "temperature": 0.0, "avg_logprob": -0.0863067134734123, "compression_ratio": 1.8125, "no_speech_prob": 0.002123510930687189}, {"id": 871, "seek": 280496, "start": 2819.6, "end": 2821.92, "text": " And again, we're kind of fooled by randomness", "tokens": [51096, 400, 797, 11, 321, 434, 733, 295, 33372, 538, 4974, 1287, 51212], "temperature": 0.0, "avg_logprob": -0.0863067134734123, "compression_ratio": 1.8125, "no_speech_prob": 0.002123510930687189}, {"id": 872, "seek": 280496, "start": 2821.92, "end": 2823.76, "text": " because we're anthropomorphizing the world", "tokens": [51212, 570, 321, 434, 22727, 32702, 3319, 264, 1002, 51304], "temperature": 0.0, "avg_logprob": -0.0863067134734123, "compression_ratio": 1.8125, "no_speech_prob": 0.002123510930687189}, {"id": 873, "seek": 280496, "start": 2823.76, "end": 2825.52, "text": " and we're kind of framing it as a game.", "tokens": [51304, 293, 321, 434, 733, 295, 28971, 309, 382, 257, 1216, 13, 51392], "temperature": 0.0, "avg_logprob": -0.0863067134734123, "compression_ratio": 1.8125, "no_speech_prob": 0.002123510930687189}, {"id": 874, "seek": 280496, "start": 2825.52, "end": 2827.6, "text": " It might be much more complicated than that.", "tokens": [51392, 467, 1062, 312, 709, 544, 6179, 813, 300, 13, 51496], "temperature": 0.0, "avg_logprob": -0.0863067134734123, "compression_ratio": 1.8125, "no_speech_prob": 0.002123510930687189}, {"id": 875, "seek": 280496, "start": 2827.6, "end": 2829.44, "text": " And I've already said this a couple of times,", "tokens": [51496, 400, 286, 600, 1217, 848, 341, 257, 1916, 295, 1413, 11, 51588], "temperature": 0.0, "avg_logprob": -0.0863067134734123, "compression_ratio": 1.8125, "no_speech_prob": 0.002123510930687189}, {"id": 876, "seek": 280496, "start": 2829.44, "end": 2831.44, "text": " but you know, the concept of power, for example,", "tokens": [51588, 457, 291, 458, 11, 264, 3410, 295, 1347, 11, 337, 1365, 11, 51688], "temperature": 0.0, "avg_logprob": -0.0863067134734123, "compression_ratio": 1.8125, "no_speech_prob": 0.002123510930687189}, {"id": 877, "seek": 280496, "start": 2831.44, "end": 2833.2, "text": " did when Napoleon said,", "tokens": [51688, 630, 562, 31694, 848, 11, 51776], "temperature": 0.0, "avg_logprob": -0.0863067134734123, "compression_ratio": 1.8125, "no_speech_prob": 0.002123510930687189}, {"id": 878, "seek": 283320, "start": 2833.2, "end": 2836.0, "text": " I want the men to march into this country,", "tokens": [50364, 286, 528, 264, 1706, 281, 8368, 666, 341, 1941, 11, 50504], "temperature": 0.0, "avg_logprob": -0.10391659819321826, "compression_ratio": 1.8173374613003095, "no_speech_prob": 0.008949637413024902}, {"id": 879, "seek": 283320, "start": 2836.0, "end": 2838.8799999999997, "text": " is it just a simple kind of chain of command that goes down?", "tokens": [50504, 307, 309, 445, 257, 2199, 733, 295, 5021, 295, 5622, 300, 1709, 760, 30, 50648], "temperature": 0.0, "avg_logprob": -0.10391659819321826, "compression_ratio": 1.8173374613003095, "no_speech_prob": 0.008949637413024902}, {"id": 880, "seek": 283320, "start": 2838.8799999999997, "end": 2839.4399999999996, "text": " No, it's not.", "tokens": [50648, 883, 11, 309, 311, 406, 13, 50676], "temperature": 0.0, "avg_logprob": -0.10391659819321826, "compression_ratio": 1.8173374613003095, "no_speech_prob": 0.008949637413024902}, {"id": 881, "seek": 283320, "start": 2839.4399999999996, "end": 2840.8799999999997, "text": " It's so much more complicated than that.", "tokens": [50676, 467, 311, 370, 709, 544, 6179, 813, 300, 13, 50748], "temperature": 0.0, "avg_logprob": -0.10391659819321826, "compression_ratio": 1.8173374613003095, "no_speech_prob": 0.008949637413024902}, {"id": 882, "seek": 283320, "start": 2840.8799999999997, "end": 2842.7999999999997, "text": " Well, yes, but that's, actually,", "tokens": [50748, 1042, 11, 2086, 11, 457, 300, 311, 11, 767, 11, 50844], "temperature": 0.0, "avg_logprob": -0.10391659819321826, "compression_ratio": 1.8173374613003095, "no_speech_prob": 0.008949637413024902}, {"id": 883, "seek": 283320, "start": 2842.7999999999997, "end": 2843.9199999999996, "text": " I'm not even sure what you mean", "tokens": [50844, 286, 478, 406, 754, 988, 437, 291, 914, 50900], "temperature": 0.0, "avg_logprob": -0.10391659819321826, "compression_ratio": 1.8173374613003095, "no_speech_prob": 0.008949637413024902}, {"id": 884, "seek": 283320, "start": 2843.9199999999996, "end": 2846.48, "text": " by when you say it's much more complicated than a game.", "tokens": [50900, 538, 562, 291, 584, 309, 311, 709, 544, 6179, 813, 257, 1216, 13, 51028], "temperature": 0.0, "avg_logprob": -0.10391659819321826, "compression_ratio": 1.8173374613003095, "no_speech_prob": 0.008949637413024902}, {"id": 885, "seek": 283320, "start": 2846.48, "end": 2847.8399999999997, "text": " Again, when I say a game,", "tokens": [51028, 3764, 11, 562, 286, 584, 257, 1216, 11, 51096], "temperature": 0.0, "avg_logprob": -0.10391659819321826, "compression_ratio": 1.8173374613003095, "no_speech_prob": 0.008949637413024902}, {"id": 886, "seek": 283320, "start": 2848.7999999999997, "end": 2850.72, "text": " maybe what comes to your mind is something simple,", "tokens": [51144, 1310, 437, 1487, 281, 428, 1575, 307, 746, 2199, 11, 51240], "temperature": 0.0, "avg_logprob": -0.10391659819321826, "compression_ratio": 1.8173374613003095, "no_speech_prob": 0.008949637413024902}, {"id": 887, "seek": 283320, "start": 2850.72, "end": 2853.9199999999996, "text": " like in a prisoner's dilemma, two players, two moves.", "tokens": [51240, 411, 294, 257, 28114, 311, 34312, 11, 732, 4150, 11, 732, 6067, 13, 51400], "temperature": 0.0, "avg_logprob": -0.10391659819321826, "compression_ratio": 1.8173374613003095, "no_speech_prob": 0.008949637413024902}, {"id": 888, "seek": 283320, "start": 2853.9199999999996, "end": 2856.7999999999997, "text": " It's a game with, you know, with a vast number of players,", "tokens": [51400, 467, 311, 257, 1216, 365, 11, 291, 458, 11, 365, 257, 8369, 1230, 295, 4150, 11, 51544], "temperature": 0.0, "avg_logprob": -0.10391659819321826, "compression_ratio": 1.8173374613003095, "no_speech_prob": 0.008949637413024902}, {"id": 889, "seek": 283320, "start": 2856.7999999999997, "end": 2858.3999999999996, "text": " each with a vast number of moves.", "tokens": [51544, 1184, 365, 257, 8369, 1230, 295, 6067, 13, 51624], "temperature": 0.0, "avg_logprob": -0.10391659819321826, "compression_ratio": 1.8173374613003095, "no_speech_prob": 0.008949637413024902}, {"id": 890, "seek": 283320, "start": 2859.2799999999997, "end": 2861.12, "text": " Interesting, but I think this gets to the core", "tokens": [51668, 14711, 11, 457, 286, 519, 341, 2170, 281, 264, 4965, 51760], "temperature": 0.0, "avg_logprob": -0.10391659819321826, "compression_ratio": 1.8173374613003095, "no_speech_prob": 0.008949637413024902}, {"id": 891, "seek": 283320, "start": 2861.12, "end": 2862.48, "text": " of what the rationalists talk about.", "tokens": [51760, 295, 437, 264, 15090, 1751, 751, 466, 13, 51828], "temperature": 0.0, "avg_logprob": -0.10391659819321826, "compression_ratio": 1.8173374613003095, "no_speech_prob": 0.008949637413024902}, {"id": 892, "seek": 286248, "start": 2862.8, "end": 2864.0, "text": " They have these thought experiments.", "tokens": [50380, 814, 362, 613, 1194, 12050, 13, 50440], "temperature": 0.0, "avg_logprob": -0.12501087803994457, "compression_ratio": 1.7177914110429449, "no_speech_prob": 0.0034035255666822195}, {"id": 893, "seek": 286248, "start": 2864.0, "end": 2865.6, "text": " They talk about prisoners dilemma.", "tokens": [50440, 814, 751, 466, 20417, 34312, 13, 50520], "temperature": 0.0, "avg_logprob": -0.12501087803994457, "compression_ratio": 1.7177914110429449, "no_speech_prob": 0.0034035255666822195}, {"id": 894, "seek": 286248, "start": 2865.6, "end": 2867.44, "text": " They have that, I forget the name of that game", "tokens": [50520, 814, 362, 300, 11, 286, 2870, 264, 1315, 295, 300, 1216, 50612], "temperature": 0.0, "avg_logprob": -0.12501087803994457, "compression_ratio": 1.7177914110429449, "no_speech_prob": 0.0034035255666822195}, {"id": 895, "seek": 286248, "start": 2867.44, "end": 2868.64, "text": " where there's the two boxes,", "tokens": [50612, 689, 456, 311, 264, 732, 9002, 11, 50672], "temperature": 0.0, "avg_logprob": -0.12501087803994457, "compression_ratio": 1.7177914110429449, "no_speech_prob": 0.0034035255666822195}, {"id": 896, "seek": 286248, "start": 2868.64, "end": 2871.04, "text": " and you have to choose the box, I forget that.", "tokens": [50672, 293, 291, 362, 281, 2826, 264, 2424, 11, 286, 2870, 300, 13, 50792], "temperature": 0.0, "avg_logprob": -0.12501087803994457, "compression_ratio": 1.7177914110429449, "no_speech_prob": 0.0034035255666822195}, {"id": 897, "seek": 286248, "start": 2871.04, "end": 2872.64, "text": " But I guess what I'm saying is that", "tokens": [50792, 583, 286, 2041, 437, 286, 478, 1566, 307, 300, 50872], "temperature": 0.0, "avg_logprob": -0.12501087803994457, "compression_ratio": 1.7177914110429449, "no_speech_prob": 0.0034035255666822195}, {"id": 898, "seek": 286248, "start": 2873.28, "end": 2875.28, "text": " if you do have this rationalist conception of the world,", "tokens": [50904, 498, 291, 360, 362, 341, 15090, 468, 30698, 295, 264, 1002, 11, 51004], "temperature": 0.0, "avg_logprob": -0.12501087803994457, "compression_ratio": 1.7177914110429449, "no_speech_prob": 0.0034035255666822195}, {"id": 899, "seek": 286248, "start": 2875.28, "end": 2878.16, "text": " and think about it in terms of game theory,", "tokens": [51004, 293, 519, 466, 309, 294, 2115, 295, 1216, 5261, 11, 51148], "temperature": 0.0, "avg_logprob": -0.12501087803994457, "compression_ratio": 1.7177914110429449, "no_speech_prob": 0.0034035255666822195}, {"id": 900, "seek": 286248, "start": 2878.16, "end": 2879.92, "text": " just like the symbolists do,", "tokens": [51148, 445, 411, 264, 5986, 1751, 360, 11, 51236], "temperature": 0.0, "avg_logprob": -0.12501087803994457, "compression_ratio": 1.7177914110429449, "no_speech_prob": 0.0034035255666822195}, {"id": 901, "seek": 286248, "start": 2879.92, "end": 2882.48, "text": " and the people who handcraft cognitive architectures do,", "tokens": [51236, 293, 264, 561, 567, 1011, 5611, 15605, 6331, 1303, 360, 11, 51364], "temperature": 0.0, "avg_logprob": -0.12501087803994457, "compression_ratio": 1.7177914110429449, "no_speech_prob": 0.0034035255666822195}, {"id": 902, "seek": 286248, "start": 2882.48, "end": 2884.16, "text": " or even with causality, for example,", "tokens": [51364, 420, 754, 365, 3302, 1860, 11, 337, 1365, 11, 51448], "temperature": 0.0, "avg_logprob": -0.12501087803994457, "compression_ratio": 1.7177914110429449, "no_speech_prob": 0.0034035255666822195}, {"id": 903, "seek": 286248, "start": 2884.16, "end": 2886.96, "text": " we create these variables, it's all anthropomorphic.", "tokens": [51448, 321, 1884, 613, 9102, 11, 309, 311, 439, 22727, 32702, 299, 13, 51588], "temperature": 0.0, "avg_logprob": -0.12501087803994457, "compression_ratio": 1.7177914110429449, "no_speech_prob": 0.0034035255666822195}, {"id": 904, "seek": 286248, "start": 2887.6, "end": 2892.16, "text": " Well, I would not, so let me put it this way, right?", "tokens": [51620, 1042, 11, 286, 576, 406, 11, 370, 718, 385, 829, 309, 341, 636, 11, 558, 30, 51848], "temperature": 0.0, "avg_logprob": -0.12501087803994457, "compression_ratio": 1.7177914110429449, "no_speech_prob": 0.0034035255666822195}, {"id": 905, "seek": 289248, "start": 2892.96, "end": 2895.12, "text": " You can model almost anything,", "tokens": [50388, 509, 393, 2316, 1920, 1340, 11, 50496], "temperature": 0.0, "avg_logprob": -0.10964617729187012, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.002245419891551137}, {"id": 906, "seek": 289248, "start": 2896.08, "end": 2897.76, "text": " can is an important word here.", "tokens": [50544, 393, 307, 364, 1021, 1349, 510, 13, 50628], "temperature": 0.0, "avg_logprob": -0.10964617729187012, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.002245419891551137}, {"id": 907, "seek": 289248, "start": 2897.76, "end": 2900.4, "text": " You can model almost anything in the world,", "tokens": [50628, 509, 393, 2316, 1920, 1340, 294, 264, 1002, 11, 50760], "temperature": 0.0, "avg_logprob": -0.10964617729187012, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.002245419891551137}, {"id": 908, "seek": 289248, "start": 2900.4, "end": 2902.96, "text": " in any domain, from physics to psychology", "tokens": [50760, 294, 604, 9274, 11, 490, 10649, 281, 15105, 50888], "temperature": 0.0, "avg_logprob": -0.10964617729187012, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.002245419891551137}, {"id": 909, "seek": 289248, "start": 2902.96, "end": 2905.92, "text": " to sociology, name it, as optimizing a function.", "tokens": [50888, 281, 41744, 11, 1315, 309, 11, 382, 40425, 257, 2445, 13, 51036], "temperature": 0.0, "avg_logprob": -0.10964617729187012, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.002245419891551137}, {"id": 910, "seek": 289248, "start": 2906.88, "end": 2909.52, "text": " Whether you should is a debatable question,", "tokens": [51084, 8503, 291, 820, 307, 257, 3001, 31415, 1168, 11, 51216], "temperature": 0.0, "avg_logprob": -0.10964617729187012, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.002245419891551137}, {"id": 911, "seek": 289248, "start": 2909.52, "end": 2911.36, "text": " but you can, right?", "tokens": [51216, 457, 291, 393, 11, 558, 30, 51308], "temperature": 0.0, "avg_logprob": -0.10964617729187012, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.002245419891551137}, {"id": 912, "seek": 289248, "start": 2911.36, "end": 2913.36, "text": " But now, what really happens is that", "tokens": [51308, 583, 586, 11, 437, 534, 2314, 307, 300, 51408], "temperature": 0.0, "avg_logprob": -0.10964617729187012, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.002245419891551137}, {"id": 913, "seek": 289248, "start": 2913.36, "end": 2915.04, "text": " there are many different optimizations", "tokens": [51408, 456, 366, 867, 819, 5028, 14455, 51492], "temperature": 0.0, "avg_logprob": -0.10964617729187012, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.002245419891551137}, {"id": 914, "seek": 289248, "start": 2915.04, "end": 2916.56, "text": " going on at the same time,", "tokens": [51492, 516, 322, 412, 264, 912, 565, 11, 51568], "temperature": 0.0, "avg_logprob": -0.10964617729187012, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.002245419891551137}, {"id": 915, "seek": 289248, "start": 2916.56, "end": 2918.56, "text": " all the way from maximizing entropy", "tokens": [51568, 439, 264, 636, 490, 5138, 3319, 30867, 51668], "temperature": 0.0, "avg_logprob": -0.10964617729187012, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.002245419891551137}, {"id": 916, "seek": 289248, "start": 2918.56, "end": 2920.48, "text": " to me deciding what I have for lunch today.", "tokens": [51668, 281, 385, 17990, 437, 286, 362, 337, 6349, 965, 13, 51764], "temperature": 0.0, "avg_logprob": -0.10964617729187012, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.002245419891551137}, {"id": 917, "seek": 292048, "start": 2920.96, "end": 2924.0, "text": " And now what you have is all of these interlocking optimizations,", "tokens": [50388, 400, 586, 437, 291, 362, 307, 439, 295, 613, 728, 4102, 278, 5028, 14455, 11, 50540], "temperature": 0.0, "avg_logprob": -0.10769280280856137, "compression_ratio": 1.8299711815561959, "no_speech_prob": 0.034800440073013306}, {"id": 918, "seek": 292048, "start": 2924.0, "end": 2926.32, "text": " and that's what I'm calling game theory, right?", "tokens": [50540, 293, 300, 311, 437, 286, 478, 5141, 1216, 5261, 11, 558, 30, 50656], "temperature": 0.0, "avg_logprob": -0.10769280280856137, "compression_ratio": 1.8299711815561959, "no_speech_prob": 0.034800440073013306}, {"id": 919, "seek": 292048, "start": 2926.32, "end": 2928.32, "text": " One of those optimizations is I'm Napoleon,", "tokens": [50656, 1485, 295, 729, 5028, 14455, 307, 286, 478, 31694, 11, 50756], "temperature": 0.0, "avg_logprob": -0.10769280280856137, "compression_ratio": 1.8299711815561959, "no_speech_prob": 0.034800440073013306}, {"id": 920, "seek": 292048, "start": 2928.32, "end": 2929.6, "text": " I want to conquer Russia,", "tokens": [50756, 286, 528, 281, 24136, 6797, 11, 50820], "temperature": 0.0, "avg_logprob": -0.10769280280856137, "compression_ratio": 1.8299711815561959, "no_speech_prob": 0.034800440073013306}, {"id": 921, "seek": 292048, "start": 2929.6, "end": 2932.08, "text": " you're the Tsar of Russia, you don't want to be conquered, right?", "tokens": [50820, 291, 434, 264, 16518, 289, 295, 6797, 11, 291, 500, 380, 528, 281, 312, 32695, 11, 558, 30, 50944], "temperature": 0.0, "avg_logprob": -0.10769280280856137, "compression_ratio": 1.8299711815561959, "no_speech_prob": 0.034800440073013306}, {"id": 922, "seek": 292048, "start": 2932.08, "end": 2933.68, "text": " And then we play a very complicated game,", "tokens": [50944, 400, 550, 321, 862, 257, 588, 6179, 1216, 11, 51024], "temperature": 0.0, "avg_logprob": -0.10769280280856137, "compression_ratio": 1.8299711815561959, "no_speech_prob": 0.034800440073013306}, {"id": 923, "seek": 292048, "start": 2933.68, "end": 2936.16, "text": " which includes other agents, like your soldiers,", "tokens": [51024, 597, 5974, 661, 12554, 11, 411, 428, 8892, 11, 51148], "temperature": 0.0, "avg_logprob": -0.10769280280856137, "compression_ratio": 1.8299711815561959, "no_speech_prob": 0.034800440073013306}, {"id": 924, "seek": 292048, "start": 2936.16, "end": 2938.96, "text": " which maybe, you know, I, a French soldier,", "tokens": [51148, 597, 1310, 11, 291, 458, 11, 286, 11, 257, 5522, 15632, 11, 51288], "temperature": 0.0, "avg_logprob": -0.10769280280856137, "compression_ratio": 1.8299711815561959, "no_speech_prob": 0.034800440073013306}, {"id": 925, "seek": 292048, "start": 2938.96, "end": 2940.16, "text": " you know, want to conquer Russia,", "tokens": [51288, 291, 458, 11, 528, 281, 24136, 6797, 11, 51348], "temperature": 0.0, "avg_logprob": -0.10769280280856137, "compression_ratio": 1.8299711815561959, "no_speech_prob": 0.034800440073013306}, {"id": 926, "seek": 292048, "start": 2940.16, "end": 2941.6, "text": " but I also want to stay alive,", "tokens": [51348, 457, 286, 611, 528, 281, 1754, 5465, 11, 51420], "temperature": 0.0, "avg_logprob": -0.10769280280856137, "compression_ratio": 1.8299711815561959, "no_speech_prob": 0.034800440073013306}, {"id": 927, "seek": 292048, "start": 2941.6, "end": 2943.12, "text": " whereas an opponent really couldn't care less", "tokens": [51420, 9735, 364, 10620, 534, 2809, 380, 1127, 1570, 51496], "temperature": 0.0, "avg_logprob": -0.10769280280856137, "compression_ratio": 1.8299711815561959, "no_speech_prob": 0.034800440073013306}, {"id": 928, "seek": 292048, "start": 2943.12, "end": 2945.2, "text": " whether I, in particular, stay alive or not,", "tokens": [51496, 1968, 286, 11, 294, 1729, 11, 1754, 5465, 420, 406, 11, 51600], "temperature": 0.0, "avg_logprob": -0.10769280280856137, "compression_ratio": 1.8299711815561959, "no_speech_prob": 0.034800440073013306}, {"id": 929, "seek": 292048, "start": 2945.2, "end": 2946.72, "text": " as long as he conquers Russia in the end.", "tokens": [51600, 382, 938, 382, 415, 15592, 433, 6797, 294, 264, 917, 13, 51676], "temperature": 0.0, "avg_logprob": -0.10769280280856137, "compression_ratio": 1.8299711815561959, "no_speech_prob": 0.034800440073013306}, {"id": 930, "seek": 292048, "start": 2946.72, "end": 2950.08, "text": " So this very complex game, I think, is what goes on.", "tokens": [51676, 407, 341, 588, 3997, 1216, 11, 286, 519, 11, 307, 437, 1709, 322, 13, 51844], "temperature": 0.0, "avg_logprob": -0.10769280280856137, "compression_ratio": 1.8299711815561959, "no_speech_prob": 0.034800440073013306}, {"id": 931, "seek": 295008, "start": 2950.16, "end": 2952.64, "text": " I don't think framing things in this way", "tokens": [50368, 286, 500, 380, 519, 28971, 721, 294, 341, 636, 50492], "temperature": 0.0, "avg_logprob": -0.06765106320381165, "compression_ratio": 1.8306188925081432, "no_speech_prob": 0.009484884329140186}, {"id": 932, "seek": 295008, "start": 2952.64, "end": 2954.0, "text": " is anthropomorphizing them.", "tokens": [50492, 307, 22727, 32702, 3319, 552, 13, 50560], "temperature": 0.0, "avg_logprob": -0.06765106320381165, "compression_ratio": 1.8306188925081432, "no_speech_prob": 0.009484884329140186}, {"id": 933, "seek": 295008, "start": 2954.0, "end": 2956.08, "text": " In fact, I think this is our best hope", "tokens": [50560, 682, 1186, 11, 286, 519, 341, 307, 527, 1151, 1454, 50664], "temperature": 0.0, "avg_logprob": -0.06765106320381165, "compression_ratio": 1.8306188925081432, "no_speech_prob": 0.009484884329140186}, {"id": 934, "seek": 295008, "start": 2956.08, "end": 2957.7599999999998, "text": " to not anthropomorphize things,", "tokens": [50664, 281, 406, 22727, 32702, 1125, 721, 11, 50748], "temperature": 0.0, "avg_logprob": -0.06765106320381165, "compression_ratio": 1.8306188925081432, "no_speech_prob": 0.009484884329140186}, {"id": 935, "seek": 295008, "start": 2957.7599999999998, "end": 2959.2, "text": " although at the end of the day,", "tokens": [50748, 4878, 412, 264, 917, 295, 264, 786, 11, 50820], "temperature": 0.0, "avg_logprob": -0.06765106320381165, "compression_ratio": 1.8306188925081432, "no_speech_prob": 0.009484884329140186}, {"id": 936, "seek": 295008, "start": 2959.2, "end": 2961.52, "text": " I think you can look at almost anything", "tokens": [50820, 286, 519, 291, 393, 574, 412, 1920, 1340, 50936], "temperature": 0.0, "avg_logprob": -0.06765106320381165, "compression_ratio": 1.8306188925081432, "no_speech_prob": 0.009484884329140186}, {"id": 937, "seek": 295008, "start": 2961.52, "end": 2965.2799999999997, "text": " and see a ghost of anthropomorphization there.", "tokens": [50936, 293, 536, 257, 8359, 295, 22727, 32702, 2144, 456, 13, 51124], "temperature": 0.0, "avg_logprob": -0.06765106320381165, "compression_ratio": 1.8306188925081432, "no_speech_prob": 0.009484884329140186}, {"id": 938, "seek": 295008, "start": 2965.2799999999997, "end": 2968.0, "text": " But if there's a less anthropomorphic way", "tokens": [51124, 583, 498, 456, 311, 257, 1570, 22727, 32702, 299, 636, 51260], "temperature": 0.0, "avg_logprob": -0.06765106320381165, "compression_ratio": 1.8306188925081432, "no_speech_prob": 0.009484884329140186}, {"id": 939, "seek": 295008, "start": 2968.0, "end": 2970.0, "text": " to look at the universe than through this lens,", "tokens": [51260, 281, 574, 412, 264, 6445, 813, 807, 341, 6765, 11, 51360], "temperature": 0.0, "avg_logprob": -0.06765106320381165, "compression_ratio": 1.8306188925081432, "no_speech_prob": 0.009484884329140186}, {"id": 940, "seek": 295008, "start": 2970.0, "end": 2971.6, "text": " I'd be interested to see what it is.", "tokens": [51360, 286, 1116, 312, 3102, 281, 536, 437, 309, 307, 13, 51440], "temperature": 0.0, "avg_logprob": -0.06765106320381165, "compression_ratio": 1.8306188925081432, "no_speech_prob": 0.009484884329140186}, {"id": 941, "seek": 295008, "start": 2971.6, "end": 2973.04, "text": " Well, the only reason I'm saying this is,", "tokens": [51440, 1042, 11, 264, 787, 1778, 286, 478, 1566, 341, 307, 11, 51512], "temperature": 0.0, "avg_logprob": -0.06765106320381165, "compression_ratio": 1.8306188925081432, "no_speech_prob": 0.009484884329140186}, {"id": 942, "seek": 295008, "start": 2973.04, "end": 2975.36, "text": " first of all, I want to play devil's advocate a little bit,", "tokens": [51512, 700, 295, 439, 11, 286, 528, 281, 862, 13297, 311, 14608, 257, 707, 857, 11, 51628], "temperature": 0.0, "avg_logprob": -0.06765106320381165, "compression_ratio": 1.8306188925081432, "no_speech_prob": 0.009484884329140186}, {"id": 943, "seek": 295008, "start": 2975.36, "end": 2977.84, "text": " and we even spoke about the blind men", "tokens": [51628, 293, 321, 754, 7179, 466, 264, 6865, 1706, 51752], "temperature": 0.0, "avg_logprob": -0.06765106320381165, "compression_ratio": 1.8306188925081432, "no_speech_prob": 0.009484884329140186}, {"id": 944, "seek": 295008, "start": 2977.84, "end": 2979.36, "text": " and the elephant a little while ago,", "tokens": [51752, 293, 264, 19791, 257, 707, 1339, 2057, 11, 51828], "temperature": 0.0, "avg_logprob": -0.06765106320381165, "compression_ratio": 1.8306188925081432, "no_speech_prob": 0.009484884329140186}, {"id": 945, "seek": 297936, "start": 2979.36, "end": 2982.48, "text": " and I'm sure folks on the left, as they did,", "tokens": [50364, 293, 286, 478, 988, 4024, 322, 264, 1411, 11, 382, 436, 630, 11, 50520], "temperature": 0.0, "avg_logprob": -0.10884708980862186, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.0020074492786079645}, {"id": 946, "seek": 297936, "start": 2982.48, "end": 2984.48, "text": " they criticized Ayan Ran, for example,", "tokens": [50520, 436, 28011, 316, 6277, 27948, 11, 337, 1365, 11, 50620], "temperature": 0.0, "avg_logprob": -0.10884708980862186, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.0020074492786079645}, {"id": 947, "seek": 297936, "start": 2984.48, "end": 2986.7200000000003, "text": " and they said that she had this very transactional way", "tokens": [50620, 293, 436, 848, 300, 750, 632, 341, 588, 46688, 1966, 636, 50732], "temperature": 0.0, "avg_logprob": -0.10884708980862186, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.0020074492786079645}, {"id": 948, "seek": 297936, "start": 2986.7200000000003, "end": 2988.7200000000003, "text": " of viewing the world as this kind of", "tokens": [50732, 295, 17480, 264, 1002, 382, 341, 733, 295, 50832], "temperature": 0.0, "avg_logprob": -0.10884708980862186, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.0020074492786079645}, {"id": 949, "seek": 297936, "start": 2988.7200000000003, "end": 2991.6800000000003, "text": " Nash equilibrium of self-interested actors.", "tokens": [50832, 25012, 15625, 295, 2698, 12, 5106, 21885, 10037, 13, 50980], "temperature": 0.0, "avg_logprob": -0.10884708980862186, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.0020074492786079645}, {"id": 950, "seek": 297936, "start": 2991.6800000000003, "end": 2993.1200000000003, "text": " And are we guilty of doing that?", "tokens": [50980, 400, 366, 321, 12341, 295, 884, 300, 30, 51052], "temperature": 0.0, "avg_logprob": -0.10884708980862186, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.0020074492786079645}, {"id": 951, "seek": 297936, "start": 2993.1200000000003, "end": 2995.76, "text": " Are we kind of cutting off many aspects of the truth", "tokens": [51052, 2014, 321, 733, 295, 6492, 766, 867, 7270, 295, 264, 3494, 51184], "temperature": 0.0, "avg_logprob": -0.10884708980862186, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.0020074492786079645}, {"id": 952, "seek": 297936, "start": 2995.76, "end": 2997.04, "text": " by doing this? I guess that's what I'm saying.", "tokens": [51184, 538, 884, 341, 30, 286, 2041, 300, 311, 437, 286, 478, 1566, 13, 51248], "temperature": 0.0, "avg_logprob": -0.10884708980862186, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.0020074492786079645}, {"id": 953, "seek": 297936, "start": 2997.92, "end": 3001.6, "text": " So we are always cutting off some aspect of the truth", "tokens": [51292, 407, 321, 366, 1009, 6492, 766, 512, 4171, 295, 264, 3494, 51476], "temperature": 0.0, "avg_logprob": -0.10884708980862186, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.0020074492786079645}, {"id": 954, "seek": 297936, "start": 3001.6, "end": 3003.92, "text": " when we look at anything in any way,", "tokens": [51476, 562, 321, 574, 412, 1340, 294, 604, 636, 11, 51592], "temperature": 0.0, "avg_logprob": -0.10884708980862186, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.0020074492786079645}, {"id": 955, "seek": 297936, "start": 3003.92, "end": 3006.6400000000003, "text": " which is not a reason to look at nothing in no way.", "tokens": [51592, 597, 307, 406, 257, 1778, 281, 574, 412, 1825, 294, 572, 636, 13, 51728], "temperature": 0.0, "avg_logprob": -0.10884708980862186, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.0020074492786079645}, {"id": 956, "seek": 300664, "start": 3007.2799999999997, "end": 3010.8799999999997, "text": " So I think this is a very productive way to look at things,", "tokens": [50396, 407, 286, 519, 341, 307, 257, 588, 13304, 636, 281, 574, 412, 721, 11, 50576], "temperature": 0.0, "avg_logprob": -0.11158526493952825, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.020906925201416016}, {"id": 957, "seek": 300664, "start": 3010.8799999999997, "end": 3012.08, "text": " but not the only one.", "tokens": [50576, 457, 406, 264, 787, 472, 13, 50636], "temperature": 0.0, "avg_logprob": -0.11158526493952825, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.020906925201416016}, {"id": 958, "seek": 300664, "start": 3012.08, "end": 3013.7599999999998, "text": " It doesn't exhaust what there is to be said,", "tokens": [50636, 467, 1177, 380, 14687, 437, 456, 307, 281, 312, 848, 11, 50720], "temperature": 0.0, "avg_logprob": -0.11158526493952825, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.020906925201416016}, {"id": 959, "seek": 300664, "start": 3013.7599999999998, "end": 3015.44, "text": " but I personally feel like it's the one", "tokens": [50720, 457, 286, 5665, 841, 411, 309, 311, 264, 472, 50804], "temperature": 0.0, "avg_logprob": -0.11158526493952825, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.020906925201416016}, {"id": 960, "seek": 300664, "start": 3015.44, "end": 3017.6, "text": " where the most progress can come from.", "tokens": [50804, 689, 264, 881, 4205, 393, 808, 490, 13, 50912], "temperature": 0.0, "avg_logprob": -0.11158526493952825, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.020906925201416016}, {"id": 961, "seek": 300664, "start": 3017.6, "end": 3018.64, "text": " Interesting.", "tokens": [50912, 14711, 13, 50964], "temperature": 0.0, "avg_logprob": -0.11158526493952825, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.020906925201416016}, {"id": 962, "seek": 300664, "start": 3018.64, "end": 3022.0, "text": " Now, that's sort of like Ayan Randian", "tokens": [50964, 823, 11, 300, 311, 1333, 295, 411, 316, 6277, 23614, 952, 51132], "temperature": 0.0, "avg_logprob": -0.11158526493952825, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.020906925201416016}, {"id": 963, "seek": 300664, "start": 3022.0, "end": 3023.2799999999997, "text": " simplification of the world.", "tokens": [51132, 6883, 3774, 295, 264, 1002, 13, 51196], "temperature": 0.0, "avg_logprob": -0.11158526493952825, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.020906925201416016}, {"id": 964, "seek": 300664, "start": 3025.2, "end": 3029.2799999999997, "text": " Looking at things this way does not imply over-simplifying them.", "tokens": [51292, 11053, 412, 721, 341, 636, 775, 406, 33616, 670, 12, 30937, 564, 5489, 552, 13, 51496], "temperature": 0.0, "avg_logprob": -0.11158526493952825, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.020906925201416016}, {"id": 965, "seek": 300664, "start": 3029.2799999999997, "end": 3032.24, "text": " On the contrary, I would actually say it gives us a handle", "tokens": [51496, 1282, 264, 19506, 11, 286, 576, 767, 584, 309, 2709, 505, 257, 4813, 51644], "temperature": 0.0, "avg_logprob": -0.11158526493952825, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.020906925201416016}, {"id": 966, "seek": 300664, "start": 3032.24, "end": 3034.96, "text": " on how to go into the complexity and not get lost", "tokens": [51644, 322, 577, 281, 352, 666, 264, 14024, 293, 406, 483, 2731, 51780], "temperature": 0.0, "avg_logprob": -0.11158526493952825, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.020906925201416016}, {"id": 967, "seek": 303496, "start": 3035.44, "end": 3037.44, "text": " and not devolve into like platitudes", "tokens": [50388, 293, 406, 1905, 37361, 666, 411, 3403, 16451, 50488], "temperature": 0.0, "avg_logprob": -0.10315291086832683, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.011834842152893543}, {"id": 968, "seek": 303496, "start": 3037.44, "end": 3039.12, "text": " or over-simplifying ideologies.", "tokens": [50488, 420, 670, 12, 30937, 564, 5489, 1153, 6204, 13, 50572], "temperature": 0.0, "avg_logprob": -0.10315291086832683, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.011834842152893543}, {"id": 969, "seek": 303496, "start": 3039.92, "end": 3042.32, "text": " The fact that there's a mathematical component to this", "tokens": [50612, 440, 1186, 300, 456, 311, 257, 18894, 6542, 281, 341, 50732], "temperature": 0.0, "avg_logprob": -0.10315291086832683, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.011834842152893543}, {"id": 970, "seek": 303496, "start": 3042.32, "end": 3043.12, "text": " is very important.", "tokens": [50732, 307, 588, 1021, 13, 50772], "temperature": 0.0, "avg_logprob": -0.10315291086832683, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.011834842152893543}, {"id": 971, "seek": 303496, "start": 3044.08, "end": 3045.6, "text": " Mathematics, when you can apply it,", "tokens": [50820, 15776, 37541, 11, 562, 291, 393, 3079, 309, 11, 50896], "temperature": 0.0, "avg_logprob": -0.10315291086832683, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.011834842152893543}, {"id": 972, "seek": 303496, "start": 3045.6, "end": 3047.84, "text": " gives you a very solid handle on things.", "tokens": [50896, 2709, 291, 257, 588, 5100, 4813, 322, 721, 13, 51008], "temperature": 0.0, "avg_logprob": -0.10315291086832683, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.011834842152893543}, {"id": 973, "seek": 303496, "start": 3047.84, "end": 3050.88, "text": " We are now at the point where we can handle", "tokens": [51008, 492, 366, 586, 412, 264, 935, 689, 321, 393, 4813, 51160], "temperature": 0.0, "avg_logprob": -0.10315291086832683, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.011834842152893543}, {"id": 974, "seek": 303496, "start": 3050.88, "end": 3053.84, "text": " a lot of things mathematically slash computationally", "tokens": [51160, 257, 688, 295, 721, 44003, 17330, 24903, 379, 51308], "temperature": 0.0, "avg_logprob": -0.10315291086832683, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.011834842152893543}, {"id": 975, "seek": 303496, "start": 3053.84, "end": 3054.8, "text": " that we couldn't before.", "tokens": [51308, 300, 321, 2809, 380, 949, 13, 51356], "temperature": 0.0, "avg_logprob": -0.10315291086832683, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.011834842152893543}, {"id": 976, "seek": 303496, "start": 3054.8, "end": 3057.76, "text": " So when von Neumann invented game theory,", "tokens": [51356, 407, 562, 2957, 1734, 449, 969, 14479, 1216, 5261, 11, 51504], "temperature": 0.0, "avg_logprob": -0.10315291086832683, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.011834842152893543}, {"id": 977, "seek": 303496, "start": 3057.76, "end": 3060.8, "text": " he said, this is the future of the social sciences.", "tokens": [51504, 415, 848, 11, 341, 307, 264, 2027, 295, 264, 2093, 17677, 13, 51656], "temperature": 0.0, "avg_logprob": -0.10315291086832683, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.011834842152893543}, {"id": 978, "seek": 303496, "start": 3060.8, "end": 3062.64, "text": " And so far it hasn't been,", "tokens": [51656, 400, 370, 1400, 309, 6132, 380, 668, 11, 51748], "temperature": 0.0, "avg_logprob": -0.10315291086832683, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.011834842152893543}, {"id": 979, "seek": 303496, "start": 3062.64, "end": 3064.2400000000002, "text": " but I think we're actually now at the point", "tokens": [51748, 457, 286, 519, 321, 434, 767, 586, 412, 264, 935, 51828], "temperature": 0.0, "avg_logprob": -0.10315291086832683, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.011834842152893543}, {"id": 980, "seek": 306424, "start": 3064.7999999999997, "end": 3066.16, "text": " partly because we have the data.", "tokens": [50392, 17031, 570, 321, 362, 264, 1412, 13, 50460], "temperature": 0.0, "avg_logprob": -0.08154481252034505, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.0019828954245895147}, {"id": 981, "seek": 306424, "start": 3067.2799999999997, "end": 3069.68, "text": " We actually can now usefully apply this point of view", "tokens": [50516, 492, 767, 393, 586, 764, 2277, 3079, 341, 935, 295, 1910, 50636], "temperature": 0.0, "avg_logprob": -0.08154481252034505, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.0019828954245895147}, {"id": 982, "seek": 306424, "start": 3069.68, "end": 3071.2, "text": " in a way that we couldn't before.", "tokens": [50636, 294, 257, 636, 300, 321, 2809, 380, 949, 13, 50712], "temperature": 0.0, "avg_logprob": -0.08154481252034505, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.0019828954245895147}, {"id": 983, "seek": 306424, "start": 3071.2, "end": 3073.12, "text": " How far it takes us, we'll see.", "tokens": [50712, 1012, 1400, 309, 2516, 505, 11, 321, 603, 536, 13, 50808], "temperature": 0.0, "avg_logprob": -0.08154481252034505, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.0019828954245895147}, {"id": 984, "seek": 306424, "start": 3073.8399999999997, "end": 3075.7599999999998, "text": " It's not the only possible to look at things,", "tokens": [50844, 467, 311, 406, 264, 787, 1944, 281, 574, 412, 721, 11, 50940], "temperature": 0.0, "avg_logprob": -0.08154481252034505, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.0019828954245895147}, {"id": 985, "seek": 306424, "start": 3075.7599999999998, "end": 3078.72, "text": " but I do think it's probably the most productive at this point.", "tokens": [50940, 457, 286, 360, 519, 309, 311, 1391, 264, 881, 13304, 412, 341, 935, 13, 51088], "temperature": 0.0, "avg_logprob": -0.08154481252034505, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.0019828954245895147}, {"id": 986, "seek": 306424, "start": 3078.72, "end": 3079.3599999999997, "text": " Interesting.", "tokens": [51088, 14711, 13, 51120], "temperature": 0.0, "avg_logprob": -0.08154481252034505, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.0019828954245895147}, {"id": 987, "seek": 306424, "start": 3079.3599999999997, "end": 3080.0, "text": " Okay.", "tokens": [51120, 1033, 13, 51152], "temperature": 0.0, "avg_logprob": -0.08154481252034505, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.0019828954245895147}, {"id": 988, "seek": 306424, "start": 3080.0, "end": 3082.24, "text": " So coming back to this rationalist school of thought,", "tokens": [51152, 407, 1348, 646, 281, 341, 15090, 468, 1395, 295, 1194, 11, 51264], "temperature": 0.0, "avg_logprob": -0.08154481252034505, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.0019828954245895147}, {"id": 989, "seek": 306424, "start": 3082.24, "end": 3085.68, "text": " one thing that I'm interested in is morality.", "tokens": [51264, 472, 551, 300, 286, 478, 3102, 294, 307, 29106, 13, 51436], "temperature": 0.0, "avg_logprob": -0.08154481252034505, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.0019828954245895147}, {"id": 990, "seek": 306424, "start": 3085.68, "end": 3087.52, "text": " But let's go one step at a time.", "tokens": [51436, 583, 718, 311, 352, 472, 1823, 412, 257, 565, 13, 51528], "temperature": 0.0, "avg_logprob": -0.08154481252034505, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.0019828954245895147}, {"id": 991, "seek": 306424, "start": 3087.52, "end": 3089.6, "text": " So I think Bostrom came up with this idea", "tokens": [51528, 407, 286, 519, 363, 555, 4397, 1361, 493, 365, 341, 1558, 51632], "temperature": 0.0, "avg_logprob": -0.08154481252034505, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.0019828954245895147}, {"id": 992, "seek": 306424, "start": 3089.6, "end": 3091.2799999999997, "text": " of instrumental convergence,", "tokens": [51632, 295, 17388, 32181, 11, 51716], "temperature": 0.0, "avg_logprob": -0.08154481252034505, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.0019828954245895147}, {"id": 993, "seek": 306424, "start": 3091.2799999999997, "end": 3093.04, "text": " which is this notion that in the pursuit", "tokens": [51716, 597, 307, 341, 10710, 300, 294, 264, 23365, 51804], "temperature": 0.0, "avg_logprob": -0.08154481252034505, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.0019828954245895147}, {"id": 994, "seek": 309304, "start": 3093.04, "end": 3094.48, "text": " of doing a particular task,", "tokens": [50364, 295, 884, 257, 1729, 5633, 11, 50436], "temperature": 0.0, "avg_logprob": -0.0870971118702608, "compression_ratio": 1.8515901060070672, "no_speech_prob": 0.007084172684699297}, {"id": 995, "seek": 309304, "start": 3094.48, "end": 3097.7599999999998, "text": " the intelligence system might actually potentially kill", "tokens": [50436, 264, 7599, 1185, 1062, 767, 7263, 1961, 50600], "temperature": 0.0, "avg_logprob": -0.0870971118702608, "compression_ratio": 1.8515901060070672, "no_speech_prob": 0.007084172684699297}, {"id": 996, "seek": 309304, "start": 3097.7599999999998, "end": 3100.08, "text": " everyone on the planet or do adjacent.", "tokens": [50600, 1518, 322, 264, 5054, 420, 360, 24441, 13, 50716], "temperature": 0.0, "avg_logprob": -0.0870971118702608, "compression_ratio": 1.8515901060070672, "no_speech_prob": 0.007084172684699297}, {"id": 997, "seek": 309304, "start": 3100.08, "end": 3101.84, "text": " And this is where the interesting thing comes from.", "tokens": [50716, 400, 341, 307, 689, 264, 1880, 551, 1487, 490, 13, 50804], "temperature": 0.0, "avg_logprob": -0.0870971118702608, "compression_ratio": 1.8515901060070672, "no_speech_prob": 0.007084172684699297}, {"id": 998, "seek": 309304, "start": 3101.84, "end": 3105.2, "text": " So one task, but adjacent multitask ability", "tokens": [50804, 407, 472, 5633, 11, 457, 24441, 42338, 3863, 3485, 50972], "temperature": 0.0, "avg_logprob": -0.0870971118702608, "compression_ratio": 1.8515901060070672, "no_speech_prob": 0.007084172684699297}, {"id": 999, "seek": 309304, "start": 3105.2, "end": 3108.24, "text": " and potential intelligence and so on.", "tokens": [50972, 293, 3995, 7599, 293, 370, 322, 13, 51124], "temperature": 0.0, "avg_logprob": -0.0870971118702608, "compression_ratio": 1.8515901060070672, "no_speech_prob": 0.007084172684699297}, {"id": 1000, "seek": 309304, "start": 3108.24, "end": 3110.24, "text": " So there was an example of a cauldron.", "tokens": [51124, 407, 456, 390, 364, 1365, 295, 257, 1335, 13432, 2044, 13, 51224], "temperature": 0.0, "avg_logprob": -0.0870971118702608, "compression_ratio": 1.8515901060070672, "no_speech_prob": 0.007084172684699297}, {"id": 1001, "seek": 309304, "start": 3110.24, "end": 3113.44, "text": " So you've got someone filling up a cauldron", "tokens": [51224, 407, 291, 600, 658, 1580, 10623, 493, 257, 1335, 13432, 2044, 51384], "temperature": 0.0, "avg_logprob": -0.0870971118702608, "compression_ratio": 1.8515901060070672, "no_speech_prob": 0.007084172684699297}, {"id": 1002, "seek": 309304, "start": 3113.44, "end": 3115.44, "text": " and in the pursuit of filling up the cauldron", "tokens": [51384, 293, 294, 264, 23365, 295, 10623, 493, 264, 1335, 13432, 2044, 51484], "temperature": 0.0, "avg_logprob": -0.0870971118702608, "compression_ratio": 1.8515901060070672, "no_speech_prob": 0.007084172684699297}, {"id": 1003, "seek": 309304, "start": 3115.44, "end": 3116.32, "text": " to just the right level,", "tokens": [51484, 281, 445, 264, 558, 1496, 11, 51528], "temperature": 0.0, "avg_logprob": -0.0870971118702608, "compression_ratio": 1.8515901060070672, "no_speech_prob": 0.007084172684699297}, {"id": 1004, "seek": 309304, "start": 3116.32, "end": 3119.12, "text": " they might kill the person who looks after the cauldron room", "tokens": [51528, 436, 1062, 1961, 264, 954, 567, 1542, 934, 264, 1335, 13432, 2044, 1808, 51668], "temperature": 0.0, "avg_logprob": -0.0870971118702608, "compression_ratio": 1.8515901060070672, "no_speech_prob": 0.007084172684699297}, {"id": 1005, "seek": 309304, "start": 3119.12, "end": 3121.84, "text": " just so that the agent could do it more efficiently.", "tokens": [51668, 445, 370, 300, 264, 9461, 727, 360, 309, 544, 19621, 13, 51804], "temperature": 0.0, "avg_logprob": -0.0870971118702608, "compression_ratio": 1.8515901060070672, "no_speech_prob": 0.007084172684699297}, {"id": 1006, "seek": 312184, "start": 3122.8, "end": 3125.2000000000003, "text": " Are you cynical about that or what do you think?", "tokens": [50412, 2014, 291, 46345, 466, 300, 420, 437, 360, 291, 519, 30, 50532], "temperature": 0.0, "avg_logprob": -0.14773302811842698, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.006572525482624769}, {"id": 1007, "seek": 312184, "start": 3126.0, "end": 3127.76, "text": " No, I'm not cynical about that,", "tokens": [50572, 883, 11, 286, 478, 406, 46345, 466, 300, 11, 50660], "temperature": 0.0, "avg_logprob": -0.14773302811842698, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.006572525482624769}, {"id": 1008, "seek": 312184, "start": 3127.76, "end": 3129.04, "text": " but let me put it this way.", "tokens": [50660, 457, 718, 385, 829, 309, 341, 636, 13, 50724], "temperature": 0.0, "avg_logprob": -0.14773302811842698, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.006572525482624769}, {"id": 1009, "seek": 312184, "start": 3129.6800000000003, "end": 3133.92, "text": " I don't lose any sleep worrying about the paperclip factory", "tokens": [50756, 286, 500, 380, 3624, 604, 2817, 18788, 466, 264, 3035, 21614, 9265, 50968], "temperature": 0.0, "avg_logprob": -0.14773302811842698, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.006572525482624769}, {"id": 1010, "seek": 312184, "start": 3133.92, "end": 3135.36, "text": " that's going to take over the world.", "tokens": [50968, 300, 311, 516, 281, 747, 670, 264, 1002, 13, 51040], "temperature": 0.0, "avg_logprob": -0.14773302811842698, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.006572525482624769}, {"id": 1011, "seek": 312184, "start": 3136.4, "end": 3139.6000000000004, "text": " I think you have to take that as a philosopher's thought experiment.", "tokens": [51092, 286, 519, 291, 362, 281, 747, 300, 382, 257, 29805, 311, 1194, 5120, 13, 51252], "temperature": 0.0, "avg_logprob": -0.14773302811842698, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.006572525482624769}, {"id": 1012, "seek": 312184, "start": 3141.1200000000003, "end": 3143.2000000000003, "text": " The philosopher being Nick in this case.", "tokens": [51328, 440, 29805, 885, 9449, 294, 341, 1389, 13, 51432], "temperature": 0.0, "avg_logprob": -0.14773302811842698, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.006572525482624769}, {"id": 1013, "seek": 312184, "start": 3144.32, "end": 3149.6800000000003, "text": " I think there's a real danger that there's putting its finger on,", "tokens": [51488, 286, 519, 456, 311, 257, 957, 4330, 300, 456, 311, 3372, 1080, 5984, 322, 11, 51756], "temperature": 0.0, "avg_logprob": -0.14773302811842698, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.006572525482624769}, {"id": 1014, "seek": 314968, "start": 3150.3999999999996, "end": 3154.8799999999997, "text": " but it's also mistaking reality for something else.", "tokens": [50400, 457, 309, 311, 611, 3544, 2456, 4103, 337, 746, 1646, 13, 50624], "temperature": 0.0, "avg_logprob": -0.13032078515915643, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.008823905140161514}, {"id": 1015, "seek": 314968, "start": 3154.8799999999997, "end": 3156.16, "text": " So let's look at both parts of that.", "tokens": [50624, 407, 718, 311, 574, 412, 1293, 3166, 295, 300, 13, 50688], "temperature": 0.0, "avg_logprob": -0.13032078515915643, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.008823905140161514}, {"id": 1016, "seek": 314968, "start": 3156.8799999999997, "end": 3162.0, "text": " The real danger is that if you give an AI", "tokens": [50724, 440, 957, 4330, 307, 300, 498, 291, 976, 364, 7318, 50980], "temperature": 0.0, "avg_logprob": -0.13032078515915643, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.008823905140161514}, {"id": 1017, "seek": 314968, "start": 3163.6, "end": 3167.52, "text": " an oversimplified, a hugely oversimplified objective function,", "tokens": [51060, 364, 15488, 332, 564, 2587, 11, 257, 27417, 15488, 332, 564, 2587, 10024, 2445, 11, 51256], "temperature": 0.0, "avg_logprob": -0.13032078515915643, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.008823905140161514}, {"id": 1018, "seek": 314968, "start": 3167.52, "end": 3170.16, "text": " and at the same time a very large amount of power,", "tokens": [51256, 293, 412, 264, 912, 565, 257, 588, 2416, 2372, 295, 1347, 11, 51388], "temperature": 0.0, "avg_logprob": -0.13032078515915643, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.008823905140161514}, {"id": 1019, "seek": 314968, "start": 3170.16, "end": 3173.04, "text": " bad things will happen and we need to worry about that.", "tokens": [51388, 1578, 721, 486, 1051, 293, 321, 643, 281, 3292, 466, 300, 13, 51532], "temperature": 0.0, "avg_logprob": -0.13032078515915643, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.008823905140161514}, {"id": 1020, "seek": 314968, "start": 3175.3599999999997, "end": 3177.04, "text": " By the way, this is already a problem today", "tokens": [51648, 3146, 264, 636, 11, 341, 307, 1217, 257, 1154, 965, 51732], "temperature": 0.0, "avg_logprob": -0.13032078515915643, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.008823905140161514}, {"id": 1021, "seek": 314968, "start": 3177.04, "end": 3178.7999999999997, "text": " in many maybe more modest ways,", "tokens": [51732, 294, 867, 1310, 544, 25403, 2098, 11, 51820], "temperature": 0.0, "avg_logprob": -0.13032078515915643, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.008823905140161514}, {"id": 1022, "seek": 317880, "start": 3179.52, "end": 3181.04, "text": " but also more relevant, frankly.", "tokens": [50400, 457, 611, 544, 7340, 11, 11939, 13, 50476], "temperature": 0.0, "avg_logprob": -0.1410876974767568, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.005800221581012011}, {"id": 1023, "seek": 317880, "start": 3181.6000000000004, "end": 3182.6400000000003, "text": " So what do you do?", "tokens": [50504, 407, 437, 360, 291, 360, 30, 50556], "temperature": 0.0, "avg_logprob": -0.1410876974767568, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.005800221581012011}, {"id": 1024, "seek": 317880, "start": 3182.6400000000003, "end": 3186.48, "text": " First of all, the utility function needs to be as rich", "tokens": [50556, 2386, 295, 439, 11, 264, 14877, 2445, 2203, 281, 312, 382, 4593, 50748], "temperature": 0.0, "avg_logprob": -0.1410876974767568, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.005800221581012011}, {"id": 1025, "seek": 317880, "start": 3187.28, "end": 3191.6800000000003, "text": " and as complex and as subtle as the people that it's trying to serve.", "tokens": [50788, 293, 382, 3997, 293, 382, 13743, 382, 264, 561, 300, 309, 311, 1382, 281, 4596, 13, 51008], "temperature": 0.0, "avg_logprob": -0.1410876974767568, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.005800221581012011}, {"id": 1026, "seek": 317880, "start": 3193.6800000000003, "end": 3197.1200000000003, "text": " As long as what you have to take a really world example today,", "tokens": [51108, 1018, 938, 382, 437, 291, 362, 281, 747, 257, 534, 1002, 1365, 965, 11, 51280], "temperature": 0.0, "avg_logprob": -0.1410876974767568, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.005800221581012011}, {"id": 1027, "seek": 317880, "start": 3197.1200000000003, "end": 3201.52, "text": " social media, who are all designed to just maximize engagement,", "tokens": [51280, 2093, 3021, 11, 567, 366, 439, 4761, 281, 445, 19874, 8742, 11, 51500], "temperature": 0.0, "avg_logprob": -0.1410876974767568, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.005800221581012011}, {"id": 1028, "seek": 317880, "start": 3202.88, "end": 3206.4, "text": " you have an enormous amount of AI at the service of maximizing engagement.", "tokens": [51568, 291, 362, 364, 11322, 2372, 295, 7318, 412, 264, 2643, 295, 5138, 3319, 8742, 13, 51744], "temperature": 0.0, "avg_logprob": -0.1410876974767568, "compression_ratio": 1.5684647302904564, "no_speech_prob": 0.005800221581012011}, {"id": 1029, "seek": 320640, "start": 3206.88, "end": 3211.76, "text": " I understand why companies do it and partly they have the right to.", "tokens": [50388, 286, 1223, 983, 3431, 360, 309, 293, 17031, 436, 362, 264, 558, 281, 13, 50632], "temperature": 0.0, "avg_logprob": -0.21376639752348592, "compression_ratio": 1.6654275092936803, "no_speech_prob": 0.02673077955842018}, {"id": 1030, "seek": 320640, "start": 3211.76, "end": 3212.88, "text": " We can get into that.", "tokens": [50632, 492, 393, 483, 666, 300, 13, 50688], "temperature": 0.0, "avg_logprob": -0.21376639752348592, "compression_ratio": 1.6654275092936803, "no_speech_prob": 0.02673077955842018}, {"id": 1031, "seek": 320640, "start": 3212.88, "end": 3216.56, "text": " But the point is, it's ignoring too many things.", "tokens": [50688, 583, 264, 935, 307, 11, 309, 311, 26258, 886, 867, 721, 13, 50872], "temperature": 0.0, "avg_logprob": -0.21376639752348592, "compression_ratio": 1.6654275092936803, "no_speech_prob": 0.02673077955842018}, {"id": 1032, "seek": 320640, "start": 3216.56, "end": 3221.36, "text": " So one line of defense against is that you have to enrich your utility function", "tokens": [50872, 407, 472, 1622, 295, 7654, 1970, 307, 300, 291, 362, 281, 18849, 428, 14877, 2445, 51112], "temperature": 0.0, "avg_logprob": -0.21376639752348592, "compression_ratio": 1.6654275092936803, "no_speech_prob": 0.02673077955842018}, {"id": 1033, "seek": 320640, "start": 3221.36, "end": 3224.64, "text": " until it's like a bit, and then this is an open-ended problem.", "tokens": [51112, 1826, 309, 311, 411, 257, 857, 11, 293, 550, 341, 307, 364, 1269, 12, 3502, 1154, 13, 51276], "temperature": 0.0, "avg_logprob": -0.21376639752348592, "compression_ratio": 1.6654275092936803, "no_speech_prob": 0.02673077955842018}, {"id": 1034, "seek": 320640, "start": 3225.6, "end": 3227.76, "text": " We're never going to have the final utility function.", "tokens": [51324, 492, 434, 1128, 516, 281, 362, 264, 2572, 14877, 2445, 13, 51432], "temperature": 0.0, "avg_logprob": -0.21376639752348592, "compression_ratio": 1.6654275092936803, "no_speech_prob": 0.02673077955842018}, {"id": 1035, "seek": 320640, "start": 3227.76, "end": 3230.2400000000002, "text": " It's something that the AIs have to be continually,", "tokens": [51432, 467, 311, 746, 300, 264, 316, 6802, 362, 281, 312, 22277, 11, 51556], "temperature": 0.0, "avg_logprob": -0.21376639752348592, "compression_ratio": 1.6654275092936803, "no_speech_prob": 0.02673077955842018}, {"id": 1036, "seek": 320640, "start": 3230.2400000000002, "end": 3232.96, "text": " you know, AIs, I think Stuart Russell said this and I agree,", "tokens": [51556, 291, 458, 11, 316, 6802, 11, 286, 519, 36236, 20937, 848, 341, 293, 286, 3986, 11, 51692], "temperature": 0.0, "avg_logprob": -0.21376639752348592, "compression_ratio": 1.6654275092936803, "no_speech_prob": 0.02673077955842018}, {"id": 1037, "seek": 323296, "start": 3232.96, "end": 3237.44, "text": " like they should spend half their time figuring out what the utility function is", "tokens": [50364, 411, 436, 820, 3496, 1922, 641, 565, 15213, 484, 437, 264, 14877, 2445, 307, 50588], "temperature": 0.0, "avg_logprob": -0.11459510222725246, "compression_ratio": 1.9285714285714286, "no_speech_prob": 0.014498786069452763}, {"id": 1038, "seek": 323296, "start": 3237.44, "end": 3239.12, "text": " and then the other half maximizing it.", "tokens": [50588, 293, 550, 264, 661, 1922, 5138, 3319, 309, 13, 50672], "temperature": 0.0, "avg_logprob": -0.11459510222725246, "compression_ratio": 1.9285714285714286, "no_speech_prob": 0.014498786069452763}, {"id": 1039, "seek": 323296, "start": 3239.12, "end": 3242.48, "text": " Whereas today it's like I wrote down my utility function in one line", "tokens": [50672, 13813, 965, 309, 311, 411, 286, 4114, 760, 452, 14877, 2445, 294, 472, 1622, 50840], "temperature": 0.0, "avg_logprob": -0.11459510222725246, "compression_ratio": 1.9285714285714286, "no_speech_prob": 0.014498786069452763}, {"id": 1040, "seek": 323296, "start": 3242.48, "end": 3245.92, "text": " and now I spend this enormous amount of power maximizing it.", "tokens": [50840, 293, 586, 286, 3496, 341, 11322, 2372, 295, 1347, 5138, 3319, 309, 13, 51012], "temperature": 0.0, "avg_logprob": -0.11459510222725246, "compression_ratio": 1.9285714285714286, "no_speech_prob": 0.014498786069452763}, {"id": 1041, "seek": 323296, "start": 3245.92, "end": 3247.12, "text": " So that's one line.", "tokens": [51012, 407, 300, 311, 472, 1622, 13, 51072], "temperature": 0.0, "avg_logprob": -0.11459510222725246, "compression_ratio": 1.9285714285714286, "no_speech_prob": 0.014498786069452763}, {"id": 1042, "seek": 323296, "start": 3247.12, "end": 3251.84, "text": " The other line or like one other line is you have to put constraints on the machine.", "tokens": [51072, 440, 661, 1622, 420, 411, 472, 661, 1622, 307, 291, 362, 281, 829, 18491, 322, 264, 3479, 13, 51308], "temperature": 0.0, "avg_logprob": -0.11459510222725246, "compression_ratio": 1.9285714285714286, "no_speech_prob": 0.014498786069452763}, {"id": 1043, "seek": 323296, "start": 3251.84, "end": 3252.96, "text": " Hard constraints.", "tokens": [51308, 11817, 18491, 13, 51364], "temperature": 0.0, "avg_logprob": -0.11459510222725246, "compression_ratio": 1.9285714285714286, "no_speech_prob": 0.014498786069452763}, {"id": 1044, "seek": 323296, "start": 3252.96, "end": 3255.84, "text": " You can win the pursuit of this utility function.", "tokens": [51364, 509, 393, 1942, 264, 23365, 295, 341, 14877, 2445, 13, 51508], "temperature": 0.0, "avg_logprob": -0.11459510222725246, "compression_ratio": 1.9285714285714286, "no_speech_prob": 0.014498786069452763}, {"id": 1045, "seek": 323296, "start": 3255.84, "end": 3257.28, "text": " You can think of it as like, you know,", "tokens": [51508, 509, 393, 519, 295, 309, 382, 411, 11, 291, 458, 11, 51580], "temperature": 0.0, "avg_logprob": -0.11459510222725246, "compression_ratio": 1.9285714285714286, "no_speech_prob": 0.014498786069452763}, {"id": 1046, "seek": 323296, "start": 3257.28, "end": 3259.28, "text": " terms with infinite weight in the utility function.", "tokens": [51580, 2115, 365, 13785, 3364, 294, 264, 14877, 2445, 13, 51680], "temperature": 0.0, "avg_logprob": -0.11459510222725246, "compression_ratio": 1.9285714285714286, "no_speech_prob": 0.014498786069452763}, {"id": 1047, "seek": 323296, "start": 3259.28, "end": 3260.48, "text": " You can't go outside this.", "tokens": [51680, 509, 393, 380, 352, 2380, 341, 13, 51740], "temperature": 0.0, "avg_logprob": -0.11459510222725246, "compression_ratio": 1.9285714285714286, "no_speech_prob": 0.014498786069452763}, {"id": 1048, "seek": 326048, "start": 3260.48, "end": 3264.2400000000002, "text": " And then the other one is the single biggest reason why I sort of like", "tokens": [50364, 400, 550, 264, 661, 472, 307, 264, 2167, 3880, 1778, 983, 286, 1333, 295, 411, 50552], "temperature": 0.0, "avg_logprob": -0.0855598175268379, "compression_ratio": 1.7451612903225806, "no_speech_prob": 0.0035788859240710735}, {"id": 1049, "seek": 326048, "start": 3264.2400000000002, "end": 3268.0, "text": " this paperclip experiment is silly is that, you know,", "tokens": [50552, 341, 3035, 21614, 5120, 307, 11774, 307, 300, 11, 291, 458, 11, 50740], "temperature": 0.0, "avg_logprob": -0.0855598175268379, "compression_ratio": 1.7451612903225806, "no_speech_prob": 0.0035788859240710735}, {"id": 1050, "seek": 326048, "start": 3268.0, "end": 3269.92, "text": " along with that paperclip factoring the world,", "tokens": [50740, 2051, 365, 300, 3035, 21614, 1186, 3662, 264, 1002, 11, 50836], "temperature": 0.0, "avg_logprob": -0.0855598175268379, "compression_ratio": 1.7451612903225806, "no_speech_prob": 0.0035788859240710735}, {"id": 1051, "seek": 326048, "start": 3269.92, "end": 3272.48, "text": " there are going to be a million other AIs, you know,", "tokens": [50836, 456, 366, 516, 281, 312, 257, 2459, 661, 316, 6802, 11, 291, 458, 11, 50964], "temperature": 0.0, "avg_logprob": -0.0855598175268379, "compression_ratio": 1.7451612903225806, "no_speech_prob": 0.0035788859240710735}, {"id": 1052, "seek": 326048, "start": 3272.48, "end": 3273.92, "text": " each of which is doing the same thing.", "tokens": [50964, 1184, 295, 597, 307, 884, 264, 912, 551, 13, 51036], "temperature": 0.0, "avg_logprob": -0.0855598175268379, "compression_ratio": 1.7451612903225806, "no_speech_prob": 0.0035788859240710735}, {"id": 1053, "seek": 326048, "start": 3273.92, "end": 3278.4, "text": " So none of them is ever going to acquire the power to cause that damage", "tokens": [51036, 407, 6022, 295, 552, 307, 1562, 516, 281, 20001, 264, 1347, 281, 3082, 300, 4344, 51260], "temperature": 0.0, "avg_logprob": -0.0855598175268379, "compression_ratio": 1.7451612903225806, "no_speech_prob": 0.0035788859240710735}, {"id": 1054, "seek": 326048, "start": 3278.4, "end": 3281.36, "text": " unless it's doing something very different from just trying to make paperclips.", "tokens": [51260, 5969, 309, 311, 884, 746, 588, 819, 490, 445, 1382, 281, 652, 3035, 3474, 2600, 13, 51408], "temperature": 0.0, "avg_logprob": -0.0855598175268379, "compression_ratio": 1.7451612903225806, "no_speech_prob": 0.0035788859240710735}, {"id": 1055, "seek": 326048, "start": 3281.36, "end": 3284.96, "text": " So at some level that example is extremely unrealistic", "tokens": [51408, 407, 412, 512, 1496, 300, 1365, 307, 4664, 42867, 51588], "temperature": 0.0, "avg_logprob": -0.0855598175268379, "compression_ratio": 1.7451612903225806, "no_speech_prob": 0.0035788859240710735}, {"id": 1056, "seek": 326048, "start": 3284.96, "end": 3286.72, "text": " and leads us down the wrong track.", "tokens": [51588, 293, 6689, 505, 760, 264, 2085, 2837, 13, 51676], "temperature": 0.0, "avg_logprob": -0.0855598175268379, "compression_ratio": 1.7451612903225806, "no_speech_prob": 0.0035788859240710735}, {"id": 1057, "seek": 326048, "start": 3286.72, "end": 3288.16, "text": " Right, loads of places to go there.", "tokens": [51676, 1779, 11, 12668, 295, 3190, 281, 352, 456, 13, 51748], "temperature": 0.0, "avg_logprob": -0.0855598175268379, "compression_ratio": 1.7451612903225806, "no_speech_prob": 0.0035788859240710735}, {"id": 1058, "seek": 328816, "start": 3288.16, "end": 3292.3199999999997, "text": " But first of all, I think you do believe in AI alignment then", "tokens": [50364, 583, 700, 295, 439, 11, 286, 519, 291, 360, 1697, 294, 7318, 18515, 550, 50572], "temperature": 0.0, "avg_logprob": -0.11713686606866851, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.0036352891474962234}, {"id": 1059, "seek": 328816, "start": 3292.3199999999997, "end": 3294.24, "text": " because you're saying exactly the same as what they do,", "tokens": [50572, 570, 291, 434, 1566, 2293, 264, 912, 382, 437, 436, 360, 11, 50668], "temperature": 0.0, "avg_logprob": -0.11713686606866851, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.0036352891474962234}, {"id": 1060, "seek": 328816, "start": 3294.24, "end": 3296.7999999999997, "text": " which is that we need to have the utility function", "tokens": [50668, 597, 307, 300, 321, 643, 281, 362, 264, 14877, 2445, 50796], "temperature": 0.0, "avg_logprob": -0.11713686606866851, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.0036352891474962234}, {"id": 1061, "seek": 328816, "start": 3296.7999999999997, "end": 3299.92, "text": " that represents the richness of the human condition.", "tokens": [50796, 300, 8855, 264, 44506, 295, 264, 1952, 4188, 13, 50952], "temperature": 0.0, "avg_logprob": -0.11713686606866851, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.0036352891474962234}, {"id": 1062, "seek": 328816, "start": 3299.92, "end": 3300.8799999999997, "text": " So that's the first thing.", "tokens": [50952, 407, 300, 311, 264, 700, 551, 13, 51000], "temperature": 0.0, "avg_logprob": -0.11713686606866851, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.0036352891474962234}, {"id": 1063, "seek": 328816, "start": 3300.8799999999997, "end": 3303.68, "text": " So essentially you're all on board of alignment.", "tokens": [51000, 407, 4476, 291, 434, 439, 322, 3150, 295, 18515, 13, 51140], "temperature": 0.0, "avg_logprob": -0.11713686606866851, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.0036352891474962234}, {"id": 1064, "seek": 328816, "start": 3303.68, "end": 3307.68, "text": " Well, I believe in AI alignment in one sense of it.", "tokens": [51140, 1042, 11, 286, 1697, 294, 7318, 18515, 294, 472, 2020, 295, 309, 13, 51340], "temperature": 0.0, "avg_logprob": -0.11713686606866851, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.0036352891474962234}, {"id": 1065, "seek": 328816, "start": 3308.3199999999997, "end": 3311.3599999999997, "text": " Many different things get go under that umbrella of AI alignment.", "tokens": [51372, 5126, 819, 721, 483, 352, 833, 300, 21925, 295, 7318, 18515, 13, 51524], "temperature": 0.0, "avg_logprob": -0.11713686606866851, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.0036352891474962234}, {"id": 1066, "seek": 328816, "start": 3311.3599999999997, "end": 3312.08, "text": " Right.", "tokens": [51524, 1779, 13, 51560], "temperature": 0.0, "avg_logprob": -0.11713686606866851, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.0036352891474962234}, {"id": 1067, "seek": 328816, "start": 3312.08, "end": 3315.2, "text": " I think in the near term, thinking of things into,", "tokens": [51560, 286, 519, 294, 264, 2651, 1433, 11, 1953, 295, 721, 666, 11, 51716], "temperature": 0.0, "avg_logprob": -0.11713686606866851, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.0036352891474962234}, {"id": 1068, "seek": 328816, "start": 3315.2, "end": 3317.6, "text": " I mean, if I like, let me put it this way.", "tokens": [51716, 286, 914, 11, 498, 286, 411, 11, 718, 385, 829, 309, 341, 636, 13, 51836], "temperature": 0.0, "avg_logprob": -0.11713686606866851, "compression_ratio": 1.7731958762886597, "no_speech_prob": 0.0036352891474962234}, {"id": 1069, "seek": 331760, "start": 3317.6, "end": 3322.88, "text": " If AI alignment is just trying to have a really accurate utility function,", "tokens": [50364, 759, 7318, 18515, 307, 445, 1382, 281, 362, 257, 534, 8559, 14877, 2445, 11, 50628], "temperature": 0.0, "avg_logprob": -0.10622684708957014, "compression_ratio": 1.7113821138211383, "no_speech_prob": 0.0014038499211892486}, {"id": 1070, "seek": 331760, "start": 3322.88, "end": 3323.8399999999997, "text": " then yes.", "tokens": [50628, 550, 2086, 13, 50676], "temperature": 0.0, "avg_logprob": -0.10622684708957014, "compression_ratio": 1.7113821138211383, "no_speech_prob": 0.0014038499211892486}, {"id": 1071, "seek": 331760, "start": 3323.8399999999997, "end": 3326.0, "text": " And then the machines are optimizing that function.", "tokens": [50676, 400, 550, 264, 8379, 366, 40425, 300, 2445, 13, 50784], "temperature": 0.0, "avg_logprob": -0.10622684708957014, "compression_ratio": 1.7113821138211383, "no_speech_prob": 0.0014038499211892486}, {"id": 1072, "seek": 331760, "start": 3326.0, "end": 3326.64, "text": " Absolutely.", "tokens": [50784, 7021, 13, 50816], "temperature": 0.0, "avg_logprob": -0.10622684708957014, "compression_ratio": 1.7113821138211383, "no_speech_prob": 0.0014038499211892486}, {"id": 1073, "seek": 331760, "start": 3326.64, "end": 3327.12, "text": " Right.", "tokens": [50816, 1779, 13, 50840], "temperature": 0.0, "avg_logprob": -0.10622684708957014, "compression_ratio": 1.7113821138211383, "no_speech_prob": 0.0014038499211892486}, {"id": 1074, "seek": 331760, "start": 3327.12, "end": 3327.6, "text": " Yeah.", "tokens": [50840, 865, 13, 50864], "temperature": 0.0, "avg_logprob": -0.10622684708957014, "compression_ratio": 1.7113821138211383, "no_speech_prob": 0.0014038499211892486}, {"id": 1075, "seek": 331760, "start": 3327.6, "end": 3331.52, "text": " And in the near term, I think talking about AI alignment is a little,", "tokens": [50864, 400, 294, 264, 2651, 1433, 11, 286, 519, 1417, 466, 7318, 18515, 307, 257, 707, 11, 51060], "temperature": 0.0, "avg_logprob": -0.10622684708957014, "compression_ratio": 1.7113821138211383, "no_speech_prob": 0.0014038499211892486}, {"id": 1076, "seek": 331760, "start": 3331.52, "end": 3335.2799999999997, "text": " I mean, the problem that I have with the concept of alignment", "tokens": [51060, 286, 914, 11, 264, 1154, 300, 286, 362, 365, 264, 3410, 295, 18515, 51248], "temperature": 0.0, "avg_logprob": -0.10622684708957014, "compression_ratio": 1.7113821138211383, "no_speech_prob": 0.0014038499211892486}, {"id": 1077, "seek": 331760, "start": 3335.2799999999997, "end": 3337.2, "text": " is that goes far beyond that.", "tokens": [51248, 307, 300, 1709, 1400, 4399, 300, 13, 51344], "temperature": 0.0, "avg_logprob": -0.10622684708957014, "compression_ratio": 1.7113821138211383, "no_speech_prob": 0.0014038499211892486}, {"id": 1078, "seek": 331760, "start": 3337.2, "end": 3341.8399999999997, "text": " It tends to see AIs as these independent agents", "tokens": [51344, 467, 12258, 281, 536, 316, 6802, 382, 613, 6695, 12554, 51576], "temperature": 0.0, "avg_logprob": -0.10622684708957014, "compression_ratio": 1.7113821138211383, "no_speech_prob": 0.0014038499211892486}, {"id": 1079, "seek": 331760, "start": 3342.64, "end": 3346.7999999999997, "text": " that we have to align their goals to ours.", "tokens": [51616, 300, 321, 362, 281, 7975, 641, 5493, 281, 11896, 13, 51824], "temperature": 0.0, "avg_logprob": -0.10622684708957014, "compression_ratio": 1.7113821138211383, "no_speech_prob": 0.0014038499211892486}, {"id": 1080, "seek": 331760, "start": 3346.7999999999997, "end": 3347.2799999999997, "text": " Right.", "tokens": [51824, 1779, 13, 51848], "temperature": 0.0, "avg_logprob": -0.10622684708957014, "compression_ratio": 1.7113821138211383, "no_speech_prob": 0.0014038499211892486}, {"id": 1081, "seek": 334728, "start": 3347.76, "end": 3350.4, "text": " And if that just caches out as like,", "tokens": [50388, 400, 498, 300, 445, 269, 13272, 484, 382, 411, 11, 50520], "temperature": 0.0, "avg_logprob": -0.11625761538743973, "compression_ratio": 1.6258741258741258, "no_speech_prob": 0.000907637644559145}, {"id": 1082, "seek": 334728, "start": 3350.4, "end": 3351.84, "text": " here's the utility function, that's fine.", "tokens": [50520, 510, 311, 264, 14877, 2445, 11, 300, 311, 2489, 13, 50592], "temperature": 0.0, "avg_logprob": -0.11625761538743973, "compression_ratio": 1.6258741258741258, "no_speech_prob": 0.000907637644559145}, {"id": 1083, "seek": 334728, "start": 3351.84, "end": 3354.32, "text": " But the problem is AIs are not independent agents.", "tokens": [50592, 583, 264, 1154, 307, 316, 6802, 366, 406, 6695, 12554, 13, 50716], "temperature": 0.0, "avg_logprob": -0.11625761538743973, "compression_ratio": 1.6258741258741258, "no_speech_prob": 0.000907637644559145}, {"id": 1084, "seek": 334728, "start": 3354.32, "end": 3355.6000000000004, "text": " AIs are our tools.", "tokens": [50716, 316, 6802, 366, 527, 3873, 13, 50780], "temperature": 0.0, "avg_logprob": -0.11625761538743973, "compression_ratio": 1.6258741258741258, "no_speech_prob": 0.000907637644559145}, {"id": 1085, "seek": 334728, "start": 3356.6400000000003, "end": 3358.32, "text": " Just to push back on that a little bit,", "tokens": [50832, 1449, 281, 2944, 646, 322, 300, 257, 707, 857, 11, 50916], "temperature": 0.0, "avg_logprob": -0.11625761538743973, "compression_ratio": 1.6258741258741258, "no_speech_prob": 0.000907637644559145}, {"id": 1086, "seek": 334728, "start": 3358.32, "end": 3360.88, "text": " because I always had that conception of these folks.", "tokens": [50916, 570, 286, 1009, 632, 300, 30698, 295, 613, 4024, 13, 51044], "temperature": 0.0, "avg_logprob": -0.11625761538743973, "compression_ratio": 1.6258741258741258, "no_speech_prob": 0.000907637644559145}, {"id": 1087, "seek": 334728, "start": 3360.88, "end": 3363.1200000000003, "text": " I thought I was arguing against people who believed", "tokens": [51044, 286, 1194, 286, 390, 19697, 1970, 561, 567, 7847, 51156], "temperature": 0.0, "avg_logprob": -0.11625761538743973, "compression_ratio": 1.6258741258741258, "no_speech_prob": 0.000907637644559145}, {"id": 1088, "seek": 334728, "start": 3363.1200000000003, "end": 3364.96, "text": " in a pure monolithic intelligence.", "tokens": [51156, 294, 257, 6075, 1108, 42878, 7599, 13, 51248], "temperature": 0.0, "avg_logprob": -0.11625761538743973, "compression_ratio": 1.6258741258741258, "no_speech_prob": 0.000907637644559145}, {"id": 1089, "seek": 334728, "start": 3364.96, "end": 3367.52, "text": " And a lot of them are transhumanists actually,", "tokens": [51248, 400, 257, 688, 295, 552, 366, 1145, 18796, 1751, 767, 11, 51376], "temperature": 0.0, "avg_logprob": -0.11625761538743973, "compression_ratio": 1.6258741258741258, "no_speech_prob": 0.000907637644559145}, {"id": 1090, "seek": 334728, "start": 3367.52, "end": 3371.6800000000003, "text": " and they say that they want to ensure human flourishing", "tokens": [51376, 293, 436, 584, 300, 436, 528, 281, 5586, 1952, 7693, 3807, 51584], "temperature": 0.0, "avg_logprob": -0.11625761538743973, "compression_ratio": 1.6258741258741258, "no_speech_prob": 0.000907637644559145}, {"id": 1091, "seek": 334728, "start": 3371.6800000000003, "end": 3374.96, "text": " through the use of AIs in tandem,", "tokens": [51584, 807, 264, 764, 295, 316, 6802, 294, 48120, 11, 51748], "temperature": 0.0, "avg_logprob": -0.11625761538743973, "compression_ratio": 1.6258741258741258, "no_speech_prob": 0.000907637644559145}, {"id": 1092, "seek": 337496, "start": 3374.96, "end": 3378.16, "text": " almost as a kind of extended mind from David Chalmers.", "tokens": [50364, 1920, 382, 257, 733, 295, 10913, 1575, 490, 4389, 761, 304, 18552, 13, 50524], "temperature": 0.0, "avg_logprob": -0.09045086507722148, "compression_ratio": 1.71, "no_speech_prob": 0.0069601754657924175}, {"id": 1093, "seek": 337496, "start": 3378.16, "end": 3381.76, "text": " But then I really wanted to get into their fears", "tokens": [50524, 583, 550, 286, 534, 1415, 281, 483, 666, 641, 15649, 50704], "temperature": 0.0, "avg_logprob": -0.09045086507722148, "compression_ratio": 1.71, "no_speech_prob": 0.0069601754657924175}, {"id": 1094, "seek": 337496, "start": 3381.76, "end": 3384.4, "text": " of recursive self-improving intelligence", "tokens": [50704, 295, 20560, 488, 2698, 12, 332, 4318, 798, 7599, 50836], "temperature": 0.0, "avg_logprob": -0.09045086507722148, "compression_ratio": 1.71, "no_speech_prob": 0.0069601754657924175}, {"id": 1095, "seek": 337496, "start": 3384.4, "end": 3385.36, "text": " and superintelligence.", "tokens": [50836, 293, 1687, 20761, 17644, 13, 50884], "temperature": 0.0, "avg_logprob": -0.09045086507722148, "compression_ratio": 1.71, "no_speech_prob": 0.0069601754657924175}, {"id": 1096, "seek": 337496, "start": 3385.36, "end": 3389.36, "text": " Because when you do have this kind of heterogeneous approach", "tokens": [50884, 1436, 562, 291, 360, 362, 341, 733, 295, 20789, 31112, 3109, 51084], "temperature": 0.0, "avg_logprob": -0.09045086507722148, "compression_ratio": 1.71, "no_speech_prob": 0.0069601754657924175}, {"id": 1097, "seek": 337496, "start": 3389.36, "end": 3391.12, "text": " to humans and machines,", "tokens": [51084, 281, 6255, 293, 8379, 11, 51172], "temperature": 0.0, "avg_logprob": -0.09045086507722148, "compression_ratio": 1.71, "no_speech_prob": 0.0069601754657924175}, {"id": 1098, "seek": 337496, "start": 3391.12, "end": 3393.04, "text": " there are going to be bottlenecks everywhere.", "tokens": [51172, 456, 366, 516, 281, 312, 44641, 2761, 5315, 13, 51268], "temperature": 0.0, "avg_logprob": -0.09045086507722148, "compression_ratio": 1.71, "no_speech_prob": 0.0069601754657924175}, {"id": 1099, "seek": 337496, "start": 3393.04, "end": 3395.92, "text": " Now, I like to think of it a bit like the market efficiency", "tokens": [51268, 823, 11, 286, 411, 281, 519, 295, 309, 257, 857, 411, 264, 2142, 10493, 51412], "temperature": 0.0, "avg_logprob": -0.09045086507722148, "compression_ratio": 1.71, "no_speech_prob": 0.0069601754657924175}, {"id": 1100, "seek": 337496, "start": 3395.92, "end": 3398.8, "text": " hypothesis, which is that you reach an equilibria", "tokens": [51412, 17291, 11, 597, 307, 300, 291, 2524, 364, 14204, 4668, 51556], "temperature": 0.0, "avg_logprob": -0.09045086507722148, "compression_ratio": 1.71, "no_speech_prob": 0.0069601754657924175}, {"id": 1101, "seek": 337496, "start": 3398.8, "end": 3403.12, "text": " where the individual actors in the market become more efficient,", "tokens": [51556, 689, 264, 2609, 10037, 294, 264, 2142, 1813, 544, 7148, 11, 51772], "temperature": 0.0, "avg_logprob": -0.09045086507722148, "compression_ratio": 1.71, "no_speech_prob": 0.0069601754657924175}, {"id": 1102, "seek": 337496, "start": 3403.12, "end": 3404.64, "text": " will become more efficient programmers.", "tokens": [51772, 486, 1813, 544, 7148, 41504, 13, 51848], "temperature": 0.0, "avg_logprob": -0.09045086507722148, "compression_ratio": 1.71, "no_speech_prob": 0.0069601754657924175}, {"id": 1103, "seek": 340464, "start": 3404.64, "end": 3406.0, "text": " Because we're using codecs.", "tokens": [50364, 1436, 321, 434, 1228, 3089, 14368, 13, 50432], "temperature": 0.0, "avg_logprob": -0.1245184326171875, "compression_ratio": 1.5924528301886793, "no_speech_prob": 0.010796167887747288}, {"id": 1104, "seek": 340464, "start": 3406.0, "end": 3407.8399999999997, "text": " But we will reach a limit, surely.", "tokens": [50432, 583, 321, 486, 2524, 257, 4948, 11, 11468, 13, 50524], "temperature": 0.0, "avg_logprob": -0.1245184326171875, "compression_ratio": 1.5924528301886793, "no_speech_prob": 0.010796167887747288}, {"id": 1105, "seek": 340464, "start": 3408.72, "end": 3413.04, "text": " Well, to touch on transhumanism for just a second,", "tokens": [50568, 1042, 11, 281, 2557, 322, 1145, 18796, 1434, 337, 445, 257, 1150, 11, 50784], "temperature": 0.0, "avg_logprob": -0.1245184326171875, "compression_ratio": 1.5924528301886793, "no_speech_prob": 0.010796167887747288}, {"id": 1106, "seek": 340464, "start": 3413.04, "end": 3415.7599999999998, "text": " because I do agree, at least sociologically,", "tokens": [50784, 570, 286, 360, 3986, 11, 412, 1935, 3075, 17157, 11, 50920], "temperature": 0.0, "avg_logprob": -0.1245184326171875, "compression_ratio": 1.5924528301886793, "no_speech_prob": 0.010796167887747288}, {"id": 1107, "seek": 340464, "start": 3415.7599999999998, "end": 3417.2799999999997, "text": " a lot of that crowd is the same.", "tokens": [50920, 257, 688, 295, 300, 6919, 307, 264, 912, 13, 50996], "temperature": 0.0, "avg_logprob": -0.1245184326171875, "compression_ratio": 1.5924528301886793, "no_speech_prob": 0.010796167887747288}, {"id": 1108, "seek": 340464, "start": 3418.72, "end": 3419.8399999999997, "text": " Let me put it this way.", "tokens": [51068, 961, 385, 829, 309, 341, 636, 13, 51124], "temperature": 0.0, "avg_logprob": -0.1245184326171875, "compression_ratio": 1.5924528301886793, "no_speech_prob": 0.010796167887747288}, {"id": 1109, "seek": 340464, "start": 3419.8399999999997, "end": 3421.92, "text": " And I'm sure this is a controversial statement.", "tokens": [51124, 400, 286, 478, 988, 341, 307, 257, 17323, 5629, 13, 51228], "temperature": 0.0, "avg_logprob": -0.1245184326171875, "compression_ratio": 1.5924528301886793, "no_speech_prob": 0.010796167887747288}, {"id": 1110, "seek": 340464, "start": 3421.92, "end": 3425.6, "text": " But maybe in the long run, the AIs should take over the world.", "tokens": [51228, 583, 1310, 294, 264, 938, 1190, 11, 264, 316, 6802, 820, 747, 670, 264, 1002, 13, 51412], "temperature": 0.0, "avg_logprob": -0.1245184326171875, "compression_ratio": 1.5924528301886793, "no_speech_prob": 0.010796167887747288}, {"id": 1111, "seek": 340464, "start": 3426.48, "end": 3429.92, "text": " Why are we so arrogant that we think whatever the AI is,", "tokens": [51456, 1545, 366, 321, 370, 30467, 300, 321, 519, 2035, 264, 7318, 307, 11, 51628], "temperature": 0.0, "avg_logprob": -0.1245184326171875, "compression_ratio": 1.5924528301886793, "no_speech_prob": 0.010796167887747288}, {"id": 1112, "seek": 340464, "start": 3429.92, "end": 3431.44, "text": " it should always be there to serve us.", "tokens": [51628, 309, 820, 1009, 312, 456, 281, 4596, 505, 13, 51704], "temperature": 0.0, "avg_logprob": -0.1245184326171875, "compression_ratio": 1.5924528301886793, "no_speech_prob": 0.010796167887747288}, {"id": 1113, "seek": 343144, "start": 3432.2400000000002, "end": 3433.28, "text": " We are a step.", "tokens": [50404, 492, 366, 257, 1823, 13, 50456], "temperature": 0.0, "avg_logprob": -0.16379996708461217, "compression_ratio": 1.6546184738955823, "no_speech_prob": 0.026235193014144897}, {"id": 1114, "seek": 343144, "start": 3433.28, "end": 3436.48, "text": " If you take the long view of this, we're a step in evolution.", "tokens": [50456, 759, 291, 747, 264, 938, 1910, 295, 341, 11, 321, 434, 257, 1823, 294, 9303, 13, 50616], "temperature": 0.0, "avg_logprob": -0.16379996708461217, "compression_ratio": 1.6546184738955823, "no_speech_prob": 0.026235193014144897}, {"id": 1115, "seek": 343144, "start": 3437.28, "end": 3437.92, "text": " We're amazing.", "tokens": [50656, 492, 434, 2243, 13, 50688], "temperature": 0.0, "avg_logprob": -0.16379996708461217, "compression_ratio": 1.6546184738955823, "no_speech_prob": 0.026235193014144897}, {"id": 1116, "seek": 343144, "start": 3437.92, "end": 3440.56, "text": " Maybe I'm a human chauvinist, but I do think we are amazing.", "tokens": [50688, 2704, 286, 478, 257, 1952, 417, 1459, 4796, 468, 11, 457, 286, 360, 519, 321, 366, 2243, 13, 50820], "temperature": 0.0, "avg_logprob": -0.16379996708461217, "compression_ratio": 1.6546184738955823, "no_speech_prob": 0.026235193014144897}, {"id": 1117, "seek": 343144, "start": 3440.56, "end": 3441.92, "text": " But we're not the last word.", "tokens": [50820, 583, 321, 434, 406, 264, 1036, 1349, 13, 50888], "temperature": 0.0, "avg_logprob": -0.16379996708461217, "compression_ratio": 1.6546184738955823, "no_speech_prob": 0.026235193014144897}, {"id": 1118, "seek": 343144, "start": 3443.68, "end": 3448.16, "text": " So the other day, I tweeted something that is maybe provocative,", "tokens": [50976, 407, 264, 661, 786, 11, 286, 25646, 746, 300, 307, 1310, 47663, 11, 51200], "temperature": 0.0, "avg_logprob": -0.16379996708461217, "compression_ratio": 1.6546184738955823, "no_speech_prob": 0.026235193014144897}, {"id": 1119, "seek": 343144, "start": 3448.16, "end": 3451.6, "text": " but it's like, I think in Gemswich, which is,", "tokens": [51200, 457, 309, 311, 411, 11, 286, 519, 294, 460, 9097, 9669, 11, 597, 307, 11, 51372], "temperature": 0.0, "avg_logprob": -0.16379996708461217, "compression_ratio": 1.6546184738955823, "no_speech_prob": 0.026235193014144897}, {"id": 1120, "seek": 343144, "start": 3452.2400000000002, "end": 3456.0, "text": " I said that the killer app of humans is producing AI.", "tokens": [51404, 286, 848, 300, 264, 13364, 724, 295, 6255, 307, 10501, 7318, 13, 51592], "temperature": 0.0, "avg_logprob": -0.16379996708461217, "compression_ratio": 1.6546184738955823, "no_speech_prob": 0.026235193014144897}, {"id": 1121, "seek": 343144, "start": 3457.04, "end": 3460.32, "text": " Maybe our role in evolution is that we're going to produce an AI.", "tokens": [51644, 2704, 527, 3090, 294, 9303, 307, 300, 321, 434, 516, 281, 5258, 364, 7318, 13, 51808], "temperature": 0.0, "avg_logprob": -0.16379996708461217, "compression_ratio": 1.6546184738955823, "no_speech_prob": 0.026235193014144897}, {"id": 1122, "seek": 346032, "start": 3461.04, "end": 3463.92, "text": " That is the next level of whatever you like.", "tokens": [50400, 663, 307, 264, 958, 1496, 295, 2035, 291, 411, 13, 50544], "temperature": 0.0, "avg_logprob": -0.22604385902141702, "compression_ratio": 1.665551839464883, "no_speech_prob": 0.00765873771160841}, {"id": 1123, "seek": 346032, "start": 3463.92, "end": 3466.88, "text": " Consciousness, intelligence, et cetera, et cetera.", "tokens": [50544, 6923, 4139, 1287, 11, 7599, 11, 1030, 11458, 11, 1030, 11458, 13, 50692], "temperature": 0.0, "avg_logprob": -0.22604385902141702, "compression_ratio": 1.665551839464883, "no_speech_prob": 0.00765873771160841}, {"id": 1124, "seek": 346032, "start": 3466.88, "end": 3469.52, "text": " And so the notion that in the very long term,", "tokens": [50692, 400, 370, 264, 10710, 300, 294, 264, 588, 938, 1433, 11, 50824], "temperature": 0.0, "avg_logprob": -0.22604385902141702, "compression_ratio": 1.665551839464883, "no_speech_prob": 0.00765873771160841}, {"id": 1125, "seek": 346032, "start": 3469.52, "end": 3471.76, "text": " the AIs should still be there to serve us,", "tokens": [50824, 264, 316, 6802, 820, 920, 312, 456, 281, 4596, 505, 11, 50936], "temperature": 0.0, "avg_logprob": -0.22604385902141702, "compression_ratio": 1.665551839464883, "no_speech_prob": 0.00765873771160841}, {"id": 1126, "seek": 346032, "start": 3472.32, "end": 3474.2400000000002, "text": " by this point of view, is actually silly.", "tokens": [50964, 538, 341, 935, 295, 1910, 11, 307, 767, 11774, 13, 51060], "temperature": 0.0, "avg_logprob": -0.22604385902141702, "compression_ratio": 1.665551839464883, "no_speech_prob": 0.00765873771160841}, {"id": 1127, "seek": 346032, "start": 3475.28, "end": 3479.04, "text": " Right, but a lot of folks, let's say the ethics folks,", "tokens": [51112, 1779, 11, 457, 257, 688, 295, 4024, 11, 718, 311, 584, 264, 19769, 4024, 11, 51300], "temperature": 0.0, "avg_logprob": -0.22604385902141702, "compression_ratio": 1.665551839464883, "no_speech_prob": 0.00765873771160841}, {"id": 1128, "seek": 346032, "start": 3479.04, "end": 3480.1600000000003, "text": " would find it horrifying.", "tokens": [51300, 576, 915, 309, 40227, 13, 51356], "temperature": 0.0, "avg_logprob": -0.22604385902141702, "compression_ratio": 1.665551839464883, "no_speech_prob": 0.00765873771160841}, {"id": 1129, "seek": 346032, "start": 3480.96, "end": 3483.04, "text": " And I was speaking to Irina actually yesterday,", "tokens": [51396, 400, 286, 390, 4124, 281, 9151, 1426, 767, 5186, 11, 51500], "temperature": 0.0, "avg_logprob": -0.22604385902141702, "compression_ratio": 1.665551839464883, "no_speech_prob": 0.00765873771160841}, {"id": 1130, "seek": 346032, "start": 3483.04, "end": 3485.6000000000004, "text": " and she said something a little bit tongue in cheek,", "tokens": [51500, 293, 750, 848, 746, 257, 707, 857, 10601, 294, 12839, 11, 51628], "temperature": 0.0, "avg_logprob": -0.22604385902141702, "compression_ratio": 1.665551839464883, "no_speech_prob": 0.00765873771160841}, {"id": 1131, "seek": 346032, "start": 3485.6000000000004, "end": 3486.4, "text": " which is that which is actually...", "tokens": [51628, 597, 307, 300, 597, 307, 767, 485, 51668], "temperature": 0.0, "avg_logprob": -0.22604385902141702, "compression_ratio": 1.665551839464883, "no_speech_prob": 0.00765873771160841}, {"id": 1132, "seek": 346032, "start": 3486.4, "end": 3487.36, "text": " Who, sorry?", "tokens": [51668, 2102, 11, 2597, 30, 51716], "temperature": 0.0, "avg_logprob": -0.22604385902141702, "compression_ratio": 1.665551839464883, "no_speech_prob": 0.00765873771160841}, {"id": 1133, "seek": 346032, "start": 3487.36, "end": 3490.2400000000002, "text": " Irina from Montreal, Mila, and Irina Rich.", "tokens": [51716, 9151, 1426, 490, 34180, 11, 7036, 64, 11, 293, 9151, 1426, 6781, 13, 51860], "temperature": 0.0, "avg_logprob": -0.22604385902141702, "compression_ratio": 1.665551839464883, "no_speech_prob": 0.00765873771160841}, {"id": 1134, "seek": 349024, "start": 3490.3999999999996, "end": 3491.4399999999996, "text": " Oh yeah, I know her, yeah.", "tokens": [50372, 876, 1338, 11, 286, 458, 720, 11, 1338, 13, 50424], "temperature": 0.0, "avg_logprob": -0.17540540414697983, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.003866352140903473}, {"id": 1135, "seek": 349024, "start": 3491.4399999999996, "end": 3493.3599999999997, "text": " We were classmates at UC Irvine.", "tokens": [50424, 492, 645, 24964, 412, 14079, 9151, 41243, 13, 50520], "temperature": 0.0, "avg_logprob": -0.17540540414697983, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.003866352140903473}, {"id": 1136, "seek": 349024, "start": 3493.3599999999997, "end": 3495.2799999999997, "text": " Amazing, yeah, I really love her.", "tokens": [50520, 14165, 11, 1338, 11, 286, 534, 959, 720, 13, 50616], "temperature": 0.0, "avg_logprob": -0.17540540414697983, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.003866352140903473}, {"id": 1137, "seek": 349024, "start": 3495.2799999999997, "end": 3496.9599999999996, "text": " But no, she was kind of joking", "tokens": [50616, 583, 572, 11, 750, 390, 733, 295, 17396, 50700], "temperature": 0.0, "avg_logprob": -0.17540540414697983, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.003866352140903473}, {"id": 1138, "seek": 349024, "start": 3496.9599999999996, "end": 3500.3999999999996, "text": " that we should almost align human values to the AGI values.", "tokens": [50700, 300, 321, 820, 1920, 7975, 1952, 4190, 281, 264, 316, 26252, 4190, 13, 50872], "temperature": 0.0, "avg_logprob": -0.17540540414697983, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.003866352140903473}, {"id": 1139, "seek": 349024, "start": 3501.2, "end": 3502.8799999999997, "text": " Well, that I find alarming.", "tokens": [50912, 1042, 11, 300, 286, 915, 44043, 13, 50996], "temperature": 0.0, "avg_logprob": -0.17540540414697983, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.003866352140903473}, {"id": 1140, "seek": 349024, "start": 3503.4399999999996, "end": 3505.8399999999997, "text": " Well, I think she was saying it tongue in cheek.", "tokens": [51024, 1042, 11, 286, 519, 750, 390, 1566, 309, 10601, 294, 12839, 13, 51144], "temperature": 0.0, "avg_logprob": -0.17540540414697983, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.003866352140903473}, {"id": 1141, "seek": 349024, "start": 3505.8399999999997, "end": 3507.68, "text": " I'm not alarmed by a lot of things, but yeah.", "tokens": [51144, 286, 478, 406, 27597, 1912, 538, 257, 688, 295, 721, 11, 457, 1338, 13, 51236], "temperature": 0.0, "avg_logprob": -0.17540540414697983, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.003866352140903473}, {"id": 1142, "seek": 349024, "start": 3508.24, "end": 3512.8799999999997, "text": " But what do you think about this ethical concern", "tokens": [51264, 583, 437, 360, 291, 519, 466, 341, 18890, 3136, 51496], "temperature": 0.0, "avg_logprob": -0.17540540414697983, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.003866352140903473}, {"id": 1143, "seek": 349024, "start": 3512.8799999999997, "end": 3515.2799999999997, "text": " that if it is the case that you believe", "tokens": [51496, 300, 498, 309, 307, 264, 1389, 300, 291, 1697, 51616], "temperature": 0.0, "avg_logprob": -0.17540540414697983, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.003866352140903473}, {"id": 1144, "seek": 349024, "start": 3515.2799999999997, "end": 3518.8799999999997, "text": " that we're just one rung on the ladder and transhumanism", "tokens": [51616, 300, 321, 434, 445, 472, 367, 1063, 322, 264, 18325, 293, 1145, 18796, 1434, 51796], "temperature": 0.0, "avg_logprob": -0.17540540414697983, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.003866352140903473}, {"id": 1145, "seek": 351888, "start": 3518.96, "end": 3520.88, "text": " is more AI than it is human?", "tokens": [50368, 307, 544, 7318, 813, 309, 307, 1952, 30, 50464], "temperature": 0.0, "avg_logprob": -0.11440281714162519, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.008398858830332756}, {"id": 1146, "seek": 351888, "start": 3521.52, "end": 3522.8, "text": " People would find that horrifying.", "tokens": [50496, 3432, 576, 915, 300, 40227, 13, 50560], "temperature": 0.0, "avg_logprob": -0.11440281714162519, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.008398858830332756}, {"id": 1147, "seek": 351888, "start": 3523.6, "end": 3527.84, "text": " Well, I understand why people would find that horrifying.", "tokens": [50600, 1042, 11, 286, 1223, 983, 561, 576, 915, 300, 40227, 13, 50812], "temperature": 0.0, "avg_logprob": -0.11440281714162519, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.008398858830332756}, {"id": 1148, "seek": 351888, "start": 3527.84, "end": 3529.6, "text": " And I mean, again, we have to distinguish", "tokens": [50812, 400, 286, 914, 11, 797, 11, 321, 362, 281, 20206, 50900], "temperature": 0.0, "avg_logprob": -0.11440281714162519, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.008398858830332756}, {"id": 1149, "seek": 351888, "start": 3529.6, "end": 3531.76, "text": " the short from the meaning from the long term.", "tokens": [50900, 264, 2099, 490, 264, 3620, 490, 264, 938, 1433, 13, 51008], "temperature": 0.0, "avg_logprob": -0.11440281714162519, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.008398858830332756}, {"id": 1150, "seek": 351888, "start": 3531.76, "end": 3532.88, "text": " When I say something like this,", "tokens": [51008, 1133, 286, 584, 746, 411, 341, 11, 51064], "temperature": 0.0, "avg_logprob": -0.11440281714162519, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.008398858830332756}, {"id": 1151, "seek": 351888, "start": 3532.88, "end": 3535.2000000000003, "text": " I'm talking about the very long term, right?", "tokens": [51064, 286, 478, 1417, 466, 264, 588, 938, 1433, 11, 558, 30, 51180], "temperature": 0.0, "avg_logprob": -0.11440281714162519, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.008398858830332756}, {"id": 1152, "seek": 351888, "start": 3535.2000000000003, "end": 3538.4, "text": " Trying to make humans subservient to AI today", "tokens": [51180, 20180, 281, 652, 6255, 2090, 1978, 1196, 281, 7318, 965, 51340], "temperature": 0.0, "avg_logprob": -0.11440281714162519, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.008398858830332756}, {"id": 1153, "seek": 351888, "start": 3538.4, "end": 3540.2400000000002, "text": " is a horrifying idea, right?", "tokens": [51340, 307, 257, 40227, 1558, 11, 558, 30, 51432], "temperature": 0.0, "avg_logprob": -0.11440281714162519, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.008398858830332756}, {"id": 1154, "seek": 351888, "start": 3540.2400000000002, "end": 3541.92, "text": " Now, I think the reason a lot of people", "tokens": [51432, 823, 11, 286, 519, 264, 1778, 257, 688, 295, 561, 51516], "temperature": 0.0, "avg_logprob": -0.11440281714162519, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.008398858830332756}, {"id": 1155, "seek": 351888, "start": 3541.92, "end": 3544.56, "text": " are horrified with this idea period, right?", "tokens": [51516, 366, 17582, 2587, 365, 341, 1558, 2896, 11, 558, 30, 51648], "temperature": 0.0, "avg_logprob": -0.11440281714162519, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.008398858830332756}, {"id": 1156, "seek": 354456, "start": 3544.64, "end": 3548.24, "text": " Is natural, but in my view, naive is just,", "tokens": [50368, 1119, 3303, 11, 457, 294, 452, 1910, 11, 29052, 307, 445, 11, 50548], "temperature": 0.0, "avg_logprob": -0.1266011854188632, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.014224844053387642}, {"id": 1157, "seek": 354456, "start": 3548.88, "end": 3552.32, "text": " they are seeing humans as the end goal.", "tokens": [50580, 436, 366, 2577, 6255, 382, 264, 917, 3387, 13, 50752], "temperature": 0.0, "avg_logprob": -0.1266011854188632, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.014224844053387642}, {"id": 1158, "seek": 354456, "start": 3554.0, "end": 3555.36, "text": " If humans are the end goal,", "tokens": [50836, 759, 6255, 366, 264, 917, 3387, 11, 50904], "temperature": 0.0, "avg_logprob": -0.1266011854188632, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.014224844053387642}, {"id": 1159, "seek": 354456, "start": 3555.36, "end": 3557.2, "text": " then the idea that they should be subservient", "tokens": [50904, 550, 264, 1558, 300, 436, 820, 312, 2090, 1978, 1196, 50996], "temperature": 0.0, "avg_logprob": -0.1266011854188632, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.014224844053387642}, {"id": 1160, "seek": 354456, "start": 3557.2, "end": 3560.72, "text": " to developing the next level of AI is horrifying.", "tokens": [50996, 281, 6416, 264, 958, 1496, 295, 7318, 307, 40227, 13, 51172], "temperature": 0.0, "avg_logprob": -0.1266011854188632, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.014224844053387642}, {"id": 1161, "seek": 354456, "start": 3560.72, "end": 3565.6, "text": " If you have a moral system where humans are the be all", "tokens": [51172, 759, 291, 362, 257, 9723, 1185, 689, 6255, 366, 264, 312, 439, 51416], "temperature": 0.0, "avg_logprob": -0.1266011854188632, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.014224844053387642}, {"id": 1162, "seek": 354456, "start": 3565.6, "end": 3567.7599999999998, "text": " and end all, then all of this is horrifying.", "tokens": [51416, 293, 917, 439, 11, 550, 439, 295, 341, 307, 40227, 13, 51524], "temperature": 0.0, "avg_logprob": -0.1266011854188632, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.014224844053387642}, {"id": 1163, "seek": 354456, "start": 3567.7599999999998, "end": 3570.56, "text": " But again, if you take the long view of evolution,", "tokens": [51524, 583, 797, 11, 498, 291, 747, 264, 938, 1910, 295, 9303, 11, 51664], "temperature": 0.0, "avg_logprob": -0.1266011854188632, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.014224844053387642}, {"id": 1164, "seek": 354456, "start": 3571.84, "end": 3573.6, "text": " humans are not the be all and end all.", "tokens": [51728, 6255, 366, 406, 264, 312, 439, 293, 917, 439, 13, 51816], "temperature": 0.0, "avg_logprob": -0.1266011854188632, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.014224844053387642}, {"id": 1165, "seek": 357360, "start": 3574.24, "end": 3576.08, "text": " Okay, I mean, eventually this might take us", "tokens": [50396, 1033, 11, 286, 914, 11, 4728, 341, 1062, 747, 505, 50488], "temperature": 0.0, "avg_logprob": -0.09720869242034344, "compression_ratio": 1.7353846153846153, "no_speech_prob": 0.004025248344987631}, {"id": 1166, "seek": 357360, "start": 3576.08, "end": 3577.7599999999998, "text": " to the effective altruism discussion.", "tokens": [50488, 281, 264, 4942, 4955, 894, 1434, 5017, 13, 50572], "temperature": 0.0, "avg_logprob": -0.09720869242034344, "compression_ratio": 1.7353846153846153, "no_speech_prob": 0.004025248344987631}, {"id": 1167, "seek": 357360, "start": 3577.7599999999998, "end": 3579.92, "text": " But I think, as we were saying,", "tokens": [50572, 583, 286, 519, 11, 382, 321, 645, 1566, 11, 50680], "temperature": 0.0, "avg_logprob": -0.09720869242034344, "compression_ratio": 1.7353846153846153, "no_speech_prob": 0.004025248344987631}, {"id": 1168, "seek": 357360, "start": 3579.92, "end": 3581.68, "text": " Sam Harris recently had a podcast", "tokens": [50680, 4832, 17426, 3938, 632, 257, 7367, 50768], "temperature": 0.0, "avg_logprob": -0.09720869242034344, "compression_ratio": 1.7353846153846153, "no_speech_prob": 0.004025248344987631}, {"id": 1169, "seek": 357360, "start": 3581.68, "end": 3583.12, "text": " talking about the FTX disaster.", "tokens": [50768, 1417, 466, 264, 46675, 55, 11293, 13, 50840], "temperature": 0.0, "avg_logprob": -0.09720869242034344, "compression_ratio": 1.7353846153846153, "no_speech_prob": 0.004025248344987631}, {"id": 1170, "seek": 357360, "start": 3583.12, "end": 3584.48, "text": " And he was kind of making the argument", "tokens": [50840, 400, 415, 390, 733, 295, 1455, 264, 6770, 50908], "temperature": 0.0, "avg_logprob": -0.09720869242034344, "compression_ratio": 1.7353846153846153, "no_speech_prob": 0.004025248344987631}, {"id": 1171, "seek": 357360, "start": 3584.48, "end": 3585.8399999999997, "text": " that we're all consequentialists,", "tokens": [50908, 300, 321, 434, 439, 7242, 2549, 1751, 11, 50976], "temperature": 0.0, "avg_logprob": -0.09720869242034344, "compression_ratio": 1.7353846153846153, "no_speech_prob": 0.004025248344987631}, {"id": 1172, "seek": 357360, "start": 3585.8399999999997, "end": 3587.12, "text": " even if we don't realize it,", "tokens": [50976, 754, 498, 321, 500, 380, 4325, 309, 11, 51040], "temperature": 0.0, "avg_logprob": -0.09720869242034344, "compression_ratio": 1.7353846153846153, "no_speech_prob": 0.004025248344987631}, {"id": 1173, "seek": 357360, "start": 3587.12, "end": 3589.2799999999997, "text": " but there are different degrees of consequentialism.", "tokens": [51040, 457, 456, 366, 819, 5310, 295, 7242, 2549, 1434, 13, 51148], "temperature": 0.0, "avg_logprob": -0.09720869242034344, "compression_ratio": 1.7353846153846153, "no_speech_prob": 0.004025248344987631}, {"id": 1174, "seek": 357360, "start": 3589.2799999999997, "end": 3592.56, "text": " And I think a lot of the ethics folks at the moment,", "tokens": [51148, 400, 286, 519, 257, 688, 295, 264, 19769, 4024, 412, 264, 1623, 11, 51312], "temperature": 0.0, "avg_logprob": -0.09720869242034344, "compression_ratio": 1.7353846153846153, "no_speech_prob": 0.004025248344987631}, {"id": 1175, "seek": 357360, "start": 3592.56, "end": 3594.48, "text": " they really, really don't like what's going on", "tokens": [51312, 436, 534, 11, 534, 500, 380, 411, 437, 311, 516, 322, 51408], "temperature": 0.0, "avg_logprob": -0.09720869242034344, "compression_ratio": 1.7353846153846153, "no_speech_prob": 0.004025248344987631}, {"id": 1176, "seek": 357360, "start": 3594.48, "end": 3595.8399999999997, "text": " with long termism.", "tokens": [51408, 365, 938, 1433, 1434, 13, 51476], "temperature": 0.0, "avg_logprob": -0.09720869242034344, "compression_ratio": 1.7353846153846153, "no_speech_prob": 0.004025248344987631}, {"id": 1177, "seek": 357360, "start": 3595.8399999999997, "end": 3598.3199999999997, "text": " And it's because there's this slippery slope", "tokens": [51476, 400, 309, 311, 570, 456, 311, 341, 28100, 13525, 51600], "temperature": 0.0, "avg_logprob": -0.09720869242034344, "compression_ratio": 1.7353846153846153, "no_speech_prob": 0.004025248344987631}, {"id": 1178, "seek": 357360, "start": 3598.3199999999997, "end": 3600.88, "text": " of the kind of horizon of consequentialism.", "tokens": [51600, 295, 264, 733, 295, 18046, 295, 7242, 2549, 1434, 13, 51728], "temperature": 0.0, "avg_logprob": -0.09720869242034344, "compression_ratio": 1.7353846153846153, "no_speech_prob": 0.004025248344987631}, {"id": 1179, "seek": 357360, "start": 3600.88, "end": 3602.0, "text": " So with Nick Bostrom,", "tokens": [51728, 407, 365, 9449, 363, 555, 4397, 11, 51784], "temperature": 0.0, "avg_logprob": -0.09720869242034344, "compression_ratio": 1.7353846153846153, "no_speech_prob": 0.004025248344987631}, {"id": 1180, "seek": 360200, "start": 3602.0, "end": 3603.6, "text": " he came up with this number", "tokens": [50364, 415, 1361, 493, 365, 341, 1230, 50444], "temperature": 0.0, "avg_logprob": -0.11296379118037403, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0039967321790754795}, {"id": 1181, "seek": 360200, "start": 3603.6, "end": 3605.92, "text": " that there could be simulated humans", "tokens": [50444, 300, 456, 727, 312, 41713, 6255, 50560], "temperature": 0.0, "avg_logprob": -0.11296379118037403, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0039967321790754795}, {"id": 1182, "seek": 360200, "start": 3606.64, "end": 3608.48, "text": " living on other planets in the future.", "tokens": [50596, 2647, 322, 661, 15126, 294, 264, 2027, 13, 50688], "temperature": 0.0, "avg_logprob": -0.11296379118037403, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0039967321790754795}, {"id": 1183, "seek": 360200, "start": 3608.48, "end": 3609.44, "text": " It's a very big number.", "tokens": [50688, 467, 311, 257, 588, 955, 1230, 13, 50736], "temperature": 0.0, "avg_logprob": -0.11296379118037403, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0039967321790754795}, {"id": 1184, "seek": 360200, "start": 3609.44, "end": 3612.16, "text": " I think it's got a lot of zeros on it.", "tokens": [50736, 286, 519, 309, 311, 658, 257, 688, 295, 35193, 322, 309, 13, 50872], "temperature": 0.0, "avg_logprob": -0.11296379118037403, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0039967321790754795}, {"id": 1185, "seek": 360200, "start": 3612.16, "end": 3615.6, "text": " And what's to stop us from just making the argument", "tokens": [50872, 400, 437, 311, 281, 1590, 505, 490, 445, 1455, 264, 6770, 51044], "temperature": 0.0, "avg_logprob": -0.11296379118037403, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0039967321790754795}, {"id": 1186, "seek": 360200, "start": 3615.6, "end": 3618.08, "text": " and what's to stop AIs from making the argument", "tokens": [51044, 293, 437, 311, 281, 1590, 316, 6802, 490, 1455, 264, 6770, 51168], "temperature": 0.0, "avg_logprob": -0.11296379118037403, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0039967321790754795}, {"id": 1187, "seek": 360200, "start": 3618.08, "end": 3620.72, "text": " that those simulated lives have more value than our lives?", "tokens": [51168, 300, 729, 41713, 2909, 362, 544, 2158, 813, 527, 2909, 30, 51300], "temperature": 0.0, "avg_logprob": -0.11296379118037403, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0039967321790754795}, {"id": 1188, "seek": 360200, "start": 3622.16, "end": 3623.84, "text": " Okay, there's a lot to unpack there.", "tokens": [51372, 1033, 11, 456, 311, 257, 688, 281, 26699, 456, 13, 51456], "temperature": 0.0, "avg_logprob": -0.11296379118037403, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0039967321790754795}, {"id": 1189, "seek": 360200, "start": 3624.72, "end": 3626.48, "text": " So, but let's take this one step at a time.", "tokens": [51500, 407, 11, 457, 718, 311, 747, 341, 472, 1823, 412, 257, 565, 13, 51588], "temperature": 0.0, "avg_logprob": -0.11296379118037403, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0039967321790754795}, {"id": 1190, "seek": 360200, "start": 3627.28, "end": 3630.72, "text": " I very much by the idea of effective altruism on principle.", "tokens": [51628, 286, 588, 709, 538, 264, 1558, 295, 4942, 4955, 894, 1434, 322, 8665, 13, 51800], "temperature": 0.0, "avg_logprob": -0.11296379118037403, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.0039967321790754795}, {"id": 1191, "seek": 363072, "start": 3630.72, "end": 3633.2799999999997, "text": " I think that is the way to go about a lot of things.", "tokens": [50364, 286, 519, 300, 307, 264, 636, 281, 352, 466, 257, 688, 295, 721, 13, 50492], "temperature": 0.0, "avg_logprob": -0.1185006959097726, "compression_ratio": 1.8451882845188285, "no_speech_prob": 0.008964707143604755}, {"id": 1192, "seek": 363072, "start": 3633.2799999999997, "end": 3634.3199999999997, "text": " I think in some ways,", "tokens": [50492, 286, 519, 294, 512, 2098, 11, 50544], "temperature": 0.0, "avg_logprob": -0.1185006959097726, "compression_ratio": 1.8451882845188285, "no_speech_prob": 0.008964707143604755}, {"id": 1193, "seek": 363072, "start": 3635.52, "end": 3638.24, "text": " if you are not an effective altruist,", "tokens": [50604, 498, 291, 366, 406, 364, 4942, 4955, 894, 468, 11, 50740], "temperature": 0.0, "avg_logprob": -0.1185006959097726, "compression_ratio": 1.8451882845188285, "no_speech_prob": 0.008964707143604755}, {"id": 1194, "seek": 363072, "start": 3638.24, "end": 3641.9199999999996, "text": " maybe unconsciously, you are being irrational", "tokens": [50740, 1310, 18900, 356, 11, 291, 366, 885, 39914, 50924], "temperature": 0.0, "avg_logprob": -0.1185006959097726, "compression_ratio": 1.8451882845188285, "no_speech_prob": 0.008964707143604755}, {"id": 1195, "seek": 363072, "start": 3641.9199999999996, "end": 3643.8399999999997, "text": " or maybe evil, right?", "tokens": [50924, 420, 1310, 6724, 11, 558, 30, 51020], "temperature": 0.0, "avg_logprob": -0.1185006959097726, "compression_ratio": 1.8451882845188285, "no_speech_prob": 0.008964707143604755}, {"id": 1196, "seek": 363072, "start": 3643.8399999999997, "end": 3645.12, "text": " If you believe in altruism,", "tokens": [51020, 759, 291, 1697, 294, 4955, 894, 1434, 11, 51084], "temperature": 0.0, "avg_logprob": -0.1185006959097726, "compression_ratio": 1.8451882845188285, "no_speech_prob": 0.008964707143604755}, {"id": 1197, "seek": 363072, "start": 3645.12, "end": 3647.4399999999996, "text": " I mean, think about both parts of that, right?", "tokens": [51084, 286, 914, 11, 519, 466, 1293, 3166, 295, 300, 11, 558, 30, 51200], "temperature": 0.0, "avg_logprob": -0.1185006959097726, "compression_ratio": 1.8451882845188285, "no_speech_prob": 0.008964707143604755}, {"id": 1198, "seek": 363072, "start": 3647.4399999999996, "end": 3650.7999999999997, "text": " If altruism is good, then let's say we take that, right?", "tokens": [51200, 759, 4955, 894, 1434, 307, 665, 11, 550, 718, 311, 584, 321, 747, 300, 11, 558, 30, 51368], "temperature": 0.0, "avg_logprob": -0.1185006959097726, "compression_ratio": 1.8451882845188285, "no_speech_prob": 0.008964707143604755}, {"id": 1199, "seek": 363072, "start": 3650.7999999999997, "end": 3653.12, "text": " And then why should you be in favor", "tokens": [51368, 400, 550, 983, 820, 291, 312, 294, 2294, 51484], "temperature": 0.0, "avg_logprob": -0.1185006959097726, "compression_ratio": 1.8451882845188285, "no_speech_prob": 0.008964707143604755}, {"id": 1200, "seek": 363072, "start": 3653.12, "end": 3655.52, "text": " of ineffective altruism, right?", "tokens": [51484, 295, 48836, 4955, 894, 1434, 11, 558, 30, 51604], "temperature": 0.0, "avg_logprob": -0.1185006959097726, "compression_ratio": 1.8451882845188285, "no_speech_prob": 0.008964707143604755}, {"id": 1201, "seek": 363072, "start": 3655.52, "end": 3656.7999999999997, "text": " If you're an altruist,", "tokens": [51604, 759, 291, 434, 364, 4955, 894, 468, 11, 51668], "temperature": 0.0, "avg_logprob": -0.1185006959097726, "compression_ratio": 1.8451882845188285, "no_speech_prob": 0.008964707143604755}, {"id": 1202, "seek": 363072, "start": 3656.7999999999997, "end": 3658.3199999999997, "text": " if you want the good of other people,", "tokens": [51668, 498, 291, 528, 264, 665, 295, 661, 561, 11, 51744], "temperature": 0.0, "avg_logprob": -0.1185006959097726, "compression_ratio": 1.8451882845188285, "no_speech_prob": 0.008964707143604755}, {"id": 1203, "seek": 365832, "start": 3658.32, "end": 3660.96, "text": " you should try to do the best you can, right?", "tokens": [50364, 291, 820, 853, 281, 360, 264, 1151, 291, 393, 11, 558, 30, 50496], "temperature": 0.0, "avg_logprob": -0.09151554107666016, "compression_ratio": 1.806020066889632, "no_speech_prob": 0.003998161293566227}, {"id": 1204, "seek": 365832, "start": 3660.96, "end": 3663.6000000000004, "text": " And so, for example, I very much by the notion that like,", "tokens": [50496, 400, 370, 11, 337, 1365, 11, 286, 588, 709, 538, 264, 10710, 300, 411, 11, 50628], "temperature": 0.0, "avg_logprob": -0.09151554107666016, "compression_ratio": 1.806020066889632, "no_speech_prob": 0.003998161293566227}, {"id": 1205, "seek": 365832, "start": 3663.6000000000004, "end": 3666.6400000000003, "text": " you want to make the most money you can,", "tokens": [50628, 291, 528, 281, 652, 264, 881, 1460, 291, 393, 11, 50780], "temperature": 0.0, "avg_logprob": -0.09151554107666016, "compression_ratio": 1.806020066889632, "no_speech_prob": 0.003998161293566227}, {"id": 1206, "seek": 365832, "start": 3666.6400000000003, "end": 3668.32, "text": " so then you can give away that money", "tokens": [50780, 370, 550, 291, 393, 976, 1314, 300, 1460, 50864], "temperature": 0.0, "avg_logprob": -0.09151554107666016, "compression_ratio": 1.806020066889632, "no_speech_prob": 0.003998161293566227}, {"id": 1207, "seek": 365832, "start": 3668.32, "end": 3670.7200000000003, "text": " as opposed to volunteering at the soup kitchen.", "tokens": [50864, 382, 8851, 281, 33237, 412, 264, 7884, 6525, 13, 50984], "temperature": 0.0, "avg_logprob": -0.09151554107666016, "compression_ratio": 1.806020066889632, "no_speech_prob": 0.003998161293566227}, {"id": 1208, "seek": 365832, "start": 3670.7200000000003, "end": 3672.4, "text": " Volunteering at the soup kitchen for, say,", "tokens": [50984, 46698, 1794, 412, 264, 7884, 6525, 337, 11, 584, 11, 51068], "temperature": 0.0, "avg_logprob": -0.09151554107666016, "compression_ratio": 1.806020066889632, "no_speech_prob": 0.003998161293566227}, {"id": 1209, "seek": 365832, "start": 3672.4, "end": 3674.1600000000003, "text": " someone with a PhD in machine learning", "tokens": [51068, 1580, 365, 257, 14476, 294, 3479, 2539, 51156], "temperature": 0.0, "avg_logprob": -0.09151554107666016, "compression_ratio": 1.806020066889632, "no_speech_prob": 0.003998161293566227}, {"id": 1210, "seek": 365832, "start": 3674.1600000000003, "end": 3676.48, "text": " is an ineffective form of altruism.", "tokens": [51156, 307, 364, 48836, 1254, 295, 4955, 894, 1434, 13, 51272], "temperature": 0.0, "avg_logprob": -0.09151554107666016, "compression_ratio": 1.806020066889632, "no_speech_prob": 0.003998161293566227}, {"id": 1211, "seek": 365832, "start": 3676.48, "end": 3678.2400000000002, "text": " Now, having said that,", "tokens": [51272, 823, 11, 1419, 848, 300, 11, 51360], "temperature": 0.0, "avg_logprob": -0.09151554107666016, "compression_ratio": 1.806020066889632, "no_speech_prob": 0.003998161293566227}, {"id": 1212, "seek": 365832, "start": 3678.2400000000002, "end": 3682.2400000000002, "text": " I think the focus on the long term has been in many ways,", "tokens": [51360, 286, 519, 264, 1879, 322, 264, 938, 1433, 575, 668, 294, 867, 2098, 11, 51560], "temperature": 0.0, "avg_logprob": -0.09151554107666016, "compression_ratio": 1.806020066889632, "no_speech_prob": 0.003998161293566227}, {"id": 1213, "seek": 365832, "start": 3682.2400000000002, "end": 3685.1200000000003, "text": " I mean, certainly the long term is important, right?", "tokens": [51560, 286, 914, 11, 3297, 264, 938, 1433, 307, 1021, 11, 558, 30, 51704], "temperature": 0.0, "avg_logprob": -0.09151554107666016, "compression_ratio": 1.806020066889632, "no_speech_prob": 0.003998161293566227}, {"id": 1214, "seek": 365832, "start": 3685.1200000000003, "end": 3687.84, "text": " But the problem with the whole effective altruism movement", "tokens": [51704, 583, 264, 1154, 365, 264, 1379, 4942, 4955, 894, 1434, 3963, 51840], "temperature": 0.0, "avg_logprob": -0.09151554107666016, "compression_ratio": 1.806020066889632, "no_speech_prob": 0.003998161293566227}, {"id": 1215, "seek": 368784, "start": 3687.84, "end": 3690.2400000000002, "text": " is that it got overly focused on that,", "tokens": [50364, 307, 300, 309, 658, 24324, 5178, 322, 300, 11, 50484], "temperature": 0.0, "avg_logprob": -0.11453026444164675, "compression_ratio": 1.906614785992218, "no_speech_prob": 0.0038732881657779217}, {"id": 1216, "seek": 368784, "start": 3690.2400000000002, "end": 3691.76, "text": " and we can talk about why.", "tokens": [50484, 293, 321, 393, 751, 466, 983, 13, 50560], "temperature": 0.0, "avg_logprob": -0.11453026444164675, "compression_ratio": 1.906614785992218, "no_speech_prob": 0.0038732881657779217}, {"id": 1217, "seek": 368784, "start": 3691.76, "end": 3694.4, "text": " And then even, and then a further mistake", "tokens": [50560, 400, 550, 754, 11, 293, 550, 257, 3052, 6146, 50692], "temperature": 0.0, "avg_logprob": -0.11453026444164675, "compression_ratio": 1.906614785992218, "no_speech_prob": 0.0038732881657779217}, {"id": 1218, "seek": 368784, "start": 3694.4, "end": 3695.76, "text": " is that it got overly focused", "tokens": [50692, 307, 300, 309, 658, 24324, 5178, 50760], "temperature": 0.0, "avg_logprob": -0.11453026444164675, "compression_ratio": 1.906614785992218, "no_speech_prob": 0.0038732881657779217}, {"id": 1219, "seek": 368784, "start": 3695.76, "end": 3697.92, "text": " on these supposedly existential dangers", "tokens": [50760, 322, 613, 20581, 37133, 27701, 50868], "temperature": 0.0, "avg_logprob": -0.11453026444164675, "compression_ratio": 1.906614785992218, "no_speech_prob": 0.0038732881657779217}, {"id": 1220, "seek": 368784, "start": 3697.92, "end": 3701.1200000000003, "text": " that are much less of a big deal than people think like AI.", "tokens": [50868, 300, 366, 709, 1570, 295, 257, 955, 2028, 813, 561, 519, 411, 7318, 13, 51028], "temperature": 0.0, "avg_logprob": -0.11453026444164675, "compression_ratio": 1.906614785992218, "no_speech_prob": 0.0038732881657779217}, {"id": 1221, "seek": 368784, "start": 3701.1200000000003, "end": 3704.1600000000003, "text": " So between effective altruism and fixating on AI", "tokens": [51028, 407, 1296, 4942, 4955, 894, 1434, 293, 3191, 990, 322, 7318, 51180], "temperature": 0.0, "avg_logprob": -0.11453026444164675, "compression_ratio": 1.906614785992218, "no_speech_prob": 0.0038732881657779217}, {"id": 1222, "seek": 368784, "start": 3704.1600000000003, "end": 3706.7200000000003, "text": " as an existential danger lies a huge gulf.", "tokens": [51180, 382, 364, 37133, 4330, 9134, 257, 2603, 290, 5757, 13, 51308], "temperature": 0.0, "avg_logprob": -0.11453026444164675, "compression_ratio": 1.906614785992218, "no_speech_prob": 0.0038732881657779217}, {"id": 1223, "seek": 368784, "start": 3706.7200000000003, "end": 3709.2000000000003, "text": " I'm for effective altruism, I think, you know,", "tokens": [51308, 286, 478, 337, 4942, 4955, 894, 1434, 11, 286, 519, 11, 291, 458, 11, 51432], "temperature": 0.0, "avg_logprob": -0.11453026444164675, "compression_ratio": 1.906614785992218, "no_speech_prob": 0.0038732881657779217}, {"id": 1224, "seek": 368784, "start": 3709.2000000000003, "end": 3713.28, "text": " the long term, you know, there's ins and outs there, right?", "tokens": [51432, 264, 938, 1433, 11, 291, 458, 11, 456, 311, 1028, 293, 14758, 456, 11, 558, 30, 51636], "temperature": 0.0, "avg_logprob": -0.11453026444164675, "compression_ratio": 1.906614785992218, "no_speech_prob": 0.0038732881657779217}, {"id": 1225, "seek": 368784, "start": 3713.28, "end": 3715.84, "text": " And then this focus on like these existential dangers", "tokens": [51636, 400, 550, 341, 1879, 322, 411, 613, 37133, 27701, 51764], "temperature": 0.0, "avg_logprob": -0.11453026444164675, "compression_ratio": 1.906614785992218, "no_speech_prob": 0.0038732881657779217}, {"id": 1226, "seek": 371584, "start": 3716.4, "end": 3717.84, "text": " is very problematic.", "tokens": [50392, 307, 588, 19011, 13, 50464], "temperature": 0.0, "avg_logprob": -0.13271458066742994, "compression_ratio": 1.900369003690037, "no_speech_prob": 0.030535660684108734}, {"id": 1227, "seek": 371584, "start": 3717.84, "end": 3720.08, "text": " You know, for example, you know, to get back to the,", "tokens": [50464, 509, 458, 11, 337, 1365, 11, 291, 458, 11, 281, 483, 646, 281, 264, 11, 50576], "temperature": 0.0, "avg_logprob": -0.13271458066742994, "compression_ratio": 1.900369003690037, "no_speech_prob": 0.030535660684108734}, {"id": 1228, "seek": 371584, "start": 3720.08, "end": 3722.2400000000002, "text": " you know, Bostromian notion of like all these minds", "tokens": [50576, 291, 458, 11, 363, 555, 4397, 952, 10710, 295, 411, 439, 613, 9634, 50684], "temperature": 0.0, "avg_logprob": -0.13271458066742994, "compression_ratio": 1.900369003690037, "no_speech_prob": 0.030535660684108734}, {"id": 1229, "seek": 371584, "start": 3722.2400000000002, "end": 3724.08, "text": " that matter more than us and whatnot,", "tokens": [50684, 300, 1871, 544, 813, 505, 293, 25882, 11, 50776], "temperature": 0.0, "avg_logprob": -0.13271458066742994, "compression_ratio": 1.900369003690037, "no_speech_prob": 0.030535660684108734}, {"id": 1230, "seek": 371584, "start": 3724.08, "end": 3725.6000000000004, "text": " there is a basic idea, right,", "tokens": [50776, 456, 307, 257, 3875, 1558, 11, 558, 11, 50852], "temperature": 0.0, "avg_logprob": -0.13271458066742994, "compression_ratio": 1.900369003690037, "no_speech_prob": 0.030535660684108734}, {"id": 1231, "seek": 371584, "start": 3725.6000000000004, "end": 3727.44, "text": " that like any economist knows,", "tokens": [50852, 300, 411, 604, 36696, 3255, 11, 50944], "temperature": 0.0, "avg_logprob": -0.13271458066742994, "compression_ratio": 1.900369003690037, "no_speech_prob": 0.030535660684108734}, {"id": 1232, "seek": 371584, "start": 3727.44, "end": 3729.6000000000004, "text": " which is that you have to discount the future.", "tokens": [50944, 597, 307, 300, 291, 362, 281, 11635, 264, 2027, 13, 51052], "temperature": 0.0, "avg_logprob": -0.13271458066742994, "compression_ratio": 1.900369003690037, "no_speech_prob": 0.030535660684108734}, {"id": 1233, "seek": 371584, "start": 3729.6000000000004, "end": 3732.56, "text": " And the question is what your discount rate is, right?", "tokens": [51052, 400, 264, 1168, 307, 437, 428, 11635, 3314, 307, 11, 558, 30, 51200], "temperature": 0.0, "avg_logprob": -0.13271458066742994, "compression_ratio": 1.900369003690037, "no_speech_prob": 0.030535660684108734}, {"id": 1234, "seek": 371584, "start": 3732.56, "end": 3734.96, "text": " And if your discount rate is high, right,", "tokens": [51200, 400, 498, 428, 11635, 3314, 307, 1090, 11, 558, 11, 51320], "temperature": 0.0, "avg_logprob": -0.13271458066742994, "compression_ratio": 1.900369003690037, "no_speech_prob": 0.030535660684108734}, {"id": 1235, "seek": 371584, "start": 3734.96, "end": 3737.2000000000003, "text": " those minds matter not at all.", "tokens": [51320, 729, 9634, 1871, 406, 412, 439, 13, 51432], "temperature": 0.0, "avg_logprob": -0.13271458066742994, "compression_ratio": 1.900369003690037, "no_speech_prob": 0.030535660684108734}, {"id": 1236, "seek": 371584, "start": 3737.2000000000003, "end": 3739.28, "text": " And now why do you have that discount rate?", "tokens": [51432, 400, 586, 983, 360, 291, 362, 300, 11635, 3314, 30, 51536], "temperature": 0.0, "avg_logprob": -0.13271458066742994, "compression_ratio": 1.900369003690037, "no_speech_prob": 0.030535660684108734}, {"id": 1237, "seek": 371584, "start": 3739.28, "end": 3740.32, "text": " The primary reason is that", "tokens": [51536, 440, 6194, 1778, 307, 300, 51588], "temperature": 0.0, "avg_logprob": -0.13271458066742994, "compression_ratio": 1.900369003690037, "no_speech_prob": 0.030535660684108734}, {"id": 1238, "seek": 371584, "start": 3740.32, "end": 3742.48, "text": " there's uncertainty about the future, right?", "tokens": [51588, 456, 311, 15697, 466, 264, 2027, 11, 558, 30, 51696], "temperature": 0.0, "avg_logprob": -0.13271458066742994, "compression_ratio": 1.900369003690037, "no_speech_prob": 0.030535660684108734}, {"id": 1239, "seek": 374248, "start": 3742.48, "end": 3747.2, "text": " I have to weigh the certain benefit of helping you today", "tokens": [50364, 286, 362, 281, 13843, 264, 1629, 5121, 295, 4315, 291, 965, 50600], "temperature": 0.0, "avg_logprob": -0.08322776573291724, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0003394634695723653}, {"id": 1240, "seek": 374248, "start": 3747.2, "end": 3749.2, "text": " with the increasingly hypothetical benefit", "tokens": [50600, 365, 264, 12980, 33053, 5121, 50700], "temperature": 0.0, "avg_logprob": -0.08322776573291724, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0003394634695723653}, {"id": 1241, "seek": 374248, "start": 3749.2, "end": 3750.0, "text": " of helping your mind.", "tokens": [50700, 295, 4315, 428, 1575, 13, 50740], "temperature": 0.0, "avg_logprob": -0.08322776573291724, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0003394634695723653}, {"id": 1242, "seek": 374248, "start": 3750.0, "end": 3752.16, "text": " There's less and less likely to exist in the future.", "tokens": [50740, 821, 311, 1570, 293, 1570, 3700, 281, 2514, 294, 264, 2027, 13, 50848], "temperature": 0.0, "avg_logprob": -0.08322776573291724, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0003394634695723653}, {"id": 1243, "seek": 374248, "start": 3752.16, "end": 3753.68, "text": " So in many of those cases,", "tokens": [50848, 407, 294, 867, 295, 729, 3331, 11, 50924], "temperature": 0.0, "avg_logprob": -0.08322776573291724, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0003394634695723653}, {"id": 1244, "seek": 374248, "start": 3753.68, "end": 3756.2400000000002, "text": " the present and the short-term do win.", "tokens": [50924, 264, 1974, 293, 264, 2099, 12, 7039, 360, 1942, 13, 51052], "temperature": 0.0, "avg_logprob": -0.08322776573291724, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0003394634695723653}, {"id": 1245, "seek": 374248, "start": 3756.2400000000002, "end": 3758.08, "text": " Okay, but a couple of things to contrast that.", "tokens": [51052, 1033, 11, 457, 257, 1916, 295, 721, 281, 8712, 300, 13, 51144], "temperature": 0.0, "avg_logprob": -0.08322776573291724, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0003394634695723653}, {"id": 1246, "seek": 374248, "start": 3758.08, "end": 3760.88, "text": " So a lot of effective altruism is this idea", "tokens": [51144, 407, 257, 688, 295, 4942, 4955, 894, 1434, 307, 341, 1558, 51284], "temperature": 0.0, "avg_logprob": -0.08322776573291724, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0003394634695723653}, {"id": 1247, "seek": 374248, "start": 3760.88, "end": 3762.8, "text": " that we're born with faulty programming, right?", "tokens": [51284, 300, 321, 434, 4232, 365, 2050, 5773, 9410, 11, 558, 30, 51380], "temperature": 0.0, "avg_logprob": -0.08322776573291724, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0003394634695723653}, {"id": 1248, "seek": 374248, "start": 3762.8, "end": 3765.2, "text": " So we have these views, you know,", "tokens": [51380, 407, 321, 362, 613, 6809, 11, 291, 458, 11, 51500], "temperature": 0.0, "avg_logprob": -0.08322776573291724, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0003394634695723653}, {"id": 1249, "seek": 374248, "start": 3765.2, "end": 3768.4, "text": " like we have this concept of moral value", "tokens": [51500, 411, 321, 362, 341, 3410, 295, 9723, 2158, 51660], "temperature": 0.0, "avg_logprob": -0.08322776573291724, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0003394634695723653}, {"id": 1250, "seek": 374248, "start": 3768.4, "end": 3771.2, "text": " and it gets discounted in space and time, right?", "tokens": [51660, 293, 309, 2170, 11635, 292, 294, 1901, 293, 565, 11, 558, 30, 51800], "temperature": 0.0, "avg_logprob": -0.08322776573291724, "compression_ratio": 1.6993243243243243, "no_speech_prob": 0.0003394634695723653}, {"id": 1251, "seek": 377120, "start": 3771.2, "end": 3773.4399999999996, "text": " So we need ways of overcoming our programming.", "tokens": [50364, 407, 321, 643, 2098, 295, 38047, 527, 9410, 13, 50476], "temperature": 0.0, "avg_logprob": -0.10155153649998462, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.001139768399298191}, {"id": 1252, "seek": 377120, "start": 3773.4399999999996, "end": 3776.56, "text": " But you were saying that we should be thinking about this,", "tokens": [50476, 583, 291, 645, 1566, 300, 321, 820, 312, 1953, 466, 341, 11, 50632], "temperature": 0.0, "avg_logprob": -0.10155153649998462, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.001139768399298191}, {"id": 1253, "seek": 377120, "start": 3776.56, "end": 3778.8799999999997, "text": " but contrast that with your, you know,", "tokens": [50632, 457, 8712, 300, 365, 428, 11, 291, 458, 11, 50748], "temperature": 0.0, "avg_logprob": -0.10155153649998462, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.001139768399298191}, {"id": 1254, "seek": 377120, "start": 3778.8799999999997, "end": 3781.7599999999998, "text": " with your statement about Ayan Rand earlier, right?", "tokens": [50748, 365, 428, 5629, 466, 316, 6277, 23614, 3071, 11, 558, 30, 50892], "temperature": 0.0, "avg_logprob": -0.10155153649998462, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.001139768399298191}, {"id": 1255, "seek": 377120, "start": 3781.7599999999998, "end": 3784.48, "text": " So Ayan Rand was very, very transactional", "tokens": [50892, 407, 316, 6277, 23614, 390, 588, 11, 588, 46688, 1966, 51028], "temperature": 0.0, "avg_logprob": -0.10155153649998462, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.001139768399298191}, {"id": 1256, "seek": 377120, "start": 3784.48, "end": 3787.6, "text": " because I think the folks that criticize this movement", "tokens": [51028, 570, 286, 519, 264, 4024, 300, 31010, 341, 3963, 51184], "temperature": 0.0, "avg_logprob": -0.10155153649998462, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.001139768399298191}, {"id": 1257, "seek": 377120, "start": 3787.6, "end": 3790.08, "text": " are suspicious that we are actually being", "tokens": [51184, 366, 17931, 300, 321, 366, 767, 885, 51308], "temperature": 0.0, "avg_logprob": -0.10155153649998462, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.001139768399298191}, {"id": 1258, "seek": 377120, "start": 3790.08, "end": 3792.24, "text": " a bit more like Ayan Rand,", "tokens": [51308, 257, 857, 544, 411, 316, 6277, 23614, 11, 51416], "temperature": 0.0, "avg_logprob": -0.10155153649998462, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.001139768399298191}, {"id": 1259, "seek": 377120, "start": 3792.24, "end": 3794.96, "text": " but with the guise of altruism.", "tokens": [51416, 457, 365, 264, 695, 908, 295, 4955, 894, 1434, 13, 51552], "temperature": 0.0, "avg_logprob": -0.10155153649998462, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.001139768399298191}, {"id": 1260, "seek": 377120, "start": 3794.96, "end": 3798.72, "text": " And I think they think of the FTX disaster", "tokens": [51552, 400, 286, 519, 436, 519, 295, 264, 46675, 55, 11293, 51740], "temperature": 0.0, "avg_logprob": -0.10155153649998462, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.001139768399298191}, {"id": 1261, "seek": 377120, "start": 3798.72, "end": 3800.64, "text": " as being kind of like evidence of that.", "tokens": [51740, 382, 885, 733, 295, 411, 4467, 295, 300, 13, 51836], "temperature": 0.0, "avg_logprob": -0.10155153649998462, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.001139768399298191}, {"id": 1262, "seek": 380120, "start": 3801.9199999999996, "end": 3803.8399999999997, "text": " A lot of different points there.", "tokens": [50400, 316, 688, 295, 819, 2793, 456, 13, 50496], "temperature": 0.0, "avg_logprob": -0.1282636202298678, "compression_ratio": 1.742671009771987, "no_speech_prob": 0.0011508428724482656}, {"id": 1263, "seek": 380120, "start": 3803.8399999999997, "end": 3806.3999999999996, "text": " The FTX disaster actually has nothing whatsoever", "tokens": [50496, 440, 46675, 55, 11293, 767, 575, 1825, 17076, 50624], "temperature": 0.0, "avg_logprob": -0.1282636202298678, "compression_ratio": 1.742671009771987, "no_speech_prob": 0.0011508428724482656}, {"id": 1264, "seek": 380120, "start": 3806.3999999999996, "end": 3808.24, "text": " to do with any of this, right?", "tokens": [50624, 281, 360, 365, 604, 295, 341, 11, 558, 30, 50716], "temperature": 0.0, "avg_logprob": -0.1282636202298678, "compression_ratio": 1.742671009771987, "no_speech_prob": 0.0011508428724482656}, {"id": 1265, "seek": 380120, "start": 3808.24, "end": 3810.72, "text": " Sam Beckman Fried was one guy or is one guy,", "tokens": [50716, 4832, 19184, 1601, 17605, 390, 472, 2146, 420, 307, 472, 2146, 11, 50840], "temperature": 0.0, "avg_logprob": -0.1282636202298678, "compression_ratio": 1.742671009771987, "no_speech_prob": 0.0011508428724482656}, {"id": 1266, "seek": 380120, "start": 3810.72, "end": 3812.24, "text": " funny that I used the past tense.", "tokens": [50840, 4074, 300, 286, 1143, 264, 1791, 18760, 13, 50916], "temperature": 0.0, "avg_logprob": -0.1282636202298678, "compression_ratio": 1.742671009771987, "no_speech_prob": 0.0011508428724482656}, {"id": 1267, "seek": 380120, "start": 3812.24, "end": 3815.52, "text": " He's one guy who believed in effective altruism,", "tokens": [50916, 634, 311, 472, 2146, 567, 7847, 294, 4942, 4955, 894, 1434, 11, 51080], "temperature": 0.0, "avg_logprob": -0.1282636202298678, "compression_ratio": 1.742671009771987, "no_speech_prob": 0.0011508428724482656}, {"id": 1268, "seek": 380120, "start": 3815.52, "end": 3816.56, "text": " good for him, right?", "tokens": [51080, 665, 337, 796, 11, 558, 30, 51132], "temperature": 0.0, "avg_logprob": -0.1282636202298678, "compression_ratio": 1.742671009771987, "no_speech_prob": 0.0011508428724482656}, {"id": 1269, "seek": 380120, "start": 3816.56, "end": 3819.3599999999997, "text": " He was, I mean, the whole FTX thing was also obviously,", "tokens": [51132, 634, 390, 11, 286, 914, 11, 264, 1379, 46675, 55, 551, 390, 611, 2745, 11, 51272], "temperature": 0.0, "avg_logprob": -0.1282636202298678, "compression_ratio": 1.742671009771987, "no_speech_prob": 0.0011508428724482656}, {"id": 1270, "seek": 380120, "start": 3819.3599999999997, "end": 3820.96, "text": " I mean, yeah, we could get into that,", "tokens": [51272, 286, 914, 11, 1338, 11, 321, 727, 483, 666, 300, 11, 51352], "temperature": 0.0, "avg_logprob": -0.1282636202298678, "compression_ratio": 1.742671009771987, "no_speech_prob": 0.0011508428724482656}, {"id": 1271, "seek": 380120, "start": 3820.96, "end": 3823.3599999999997, "text": " but the point is you should not,", "tokens": [51352, 457, 264, 935, 307, 291, 820, 406, 11, 51472], "temperature": 0.0, "avg_logprob": -0.1282636202298678, "compression_ratio": 1.742671009771987, "no_speech_prob": 0.0011508428724482656}, {"id": 1272, "seek": 380120, "start": 3824.08, "end": 3827.2799999999997, "text": " I understand why people's image of effective altruism", "tokens": [51508, 286, 1223, 983, 561, 311, 3256, 295, 4942, 4955, 894, 1434, 51668], "temperature": 0.0, "avg_logprob": -0.1282636202298678, "compression_ratio": 1.742671009771987, "no_speech_prob": 0.0011508428724482656}, {"id": 1273, "seek": 380120, "start": 3827.2799999999997, "end": 3829.4399999999996, "text": " would be tainted by what happened with Sam Beckman Fried,", "tokens": [51668, 576, 312, 256, 26278, 538, 437, 2011, 365, 4832, 19184, 1601, 17605, 11, 51776], "temperature": 0.0, "avg_logprob": -0.1282636202298678, "compression_ratio": 1.742671009771987, "no_speech_prob": 0.0011508428724482656}, {"id": 1274, "seek": 380120, "start": 3829.4399999999996, "end": 3830.8799999999997, "text": " but really it shouldn't be, right?", "tokens": [51776, 457, 534, 309, 4659, 380, 312, 11, 558, 30, 51848], "temperature": 0.0, "avg_logprob": -0.1282636202298678, "compression_ratio": 1.742671009771987, "no_speech_prob": 0.0011508428724482656}, {"id": 1275, "seek": 383120, "start": 3831.3599999999997, "end": 3834.48, "text": " An idea is not responsible for the mistakes", "tokens": [50372, 1107, 1558, 307, 406, 6250, 337, 264, 8038, 50528], "temperature": 0.0, "avg_logprob": -0.14512866412022318, "compression_ratio": 1.7167832167832169, "no_speech_prob": 0.001522835693322122}, {"id": 1276, "seek": 383120, "start": 3834.48, "end": 3837.2799999999997, "text": " that its believers make in unrelated domains,", "tokens": [50528, 300, 1080, 23125, 652, 294, 38967, 25514, 11, 50668], "temperature": 0.0, "avg_logprob": -0.14512866412022318, "compression_ratio": 1.7167832167832169, "no_speech_prob": 0.001522835693322122}, {"id": 1277, "seek": 383120, "start": 3837.2799999999997, "end": 3840.16, "text": " point one, point two, transactionalism.", "tokens": [50668, 935, 472, 11, 935, 732, 11, 46688, 1966, 1434, 13, 50812], "temperature": 0.0, "avg_logprob": -0.14512866412022318, "compression_ratio": 1.7167832167832169, "no_speech_prob": 0.001522835693322122}, {"id": 1278, "seek": 383120, "start": 3840.16, "end": 3842.48, "text": " There is nothing in what I've said whatsoever", "tokens": [50812, 821, 307, 1825, 294, 437, 286, 600, 848, 17076, 50928], "temperature": 0.0, "avg_logprob": -0.14512866412022318, "compression_ratio": 1.7167832167832169, "no_speech_prob": 0.001522835693322122}, {"id": 1279, "seek": 383120, "start": 3842.48, "end": 3845.4399999999996, "text": " that implies transactionalism, in fact, the opposite, right?", "tokens": [50928, 300, 18779, 46688, 1966, 1434, 11, 294, 1186, 11, 264, 6182, 11, 558, 30, 51076], "temperature": 0.0, "avg_logprob": -0.14512866412022318, "compression_ratio": 1.7167832167832169, "no_speech_prob": 0.001522835693322122}, {"id": 1280, "seek": 383120, "start": 3845.4399999999996, "end": 3849.04, "text": " I think relationalism is actually the key concept.", "tokens": [51076, 286, 519, 38444, 1434, 307, 767, 264, 2141, 3410, 13, 51256], "temperature": 0.0, "avg_logprob": -0.14512866412022318, "compression_ratio": 1.7167832167832169, "no_speech_prob": 0.001522835693322122}, {"id": 1281, "seek": 383120, "start": 3849.04, "end": 3852.64, "text": " And part of this is that games are not one shot.", "tokens": [51256, 400, 644, 295, 341, 307, 300, 2813, 366, 406, 472, 3347, 13, 51436], "temperature": 0.0, "avg_logprob": -0.14512866412022318, "compression_ratio": 1.7167832167832169, "no_speech_prob": 0.001522835693322122}, {"id": 1282, "seek": 383120, "start": 3852.64, "end": 3854.3999999999996, "text": " Your games are played in a repeated way.", "tokens": [51436, 2260, 2813, 366, 3737, 294, 257, 10477, 636, 13, 51524], "temperature": 0.0, "avg_logprob": -0.14512866412022318, "compression_ratio": 1.7167832167832169, "no_speech_prob": 0.001522835693322122}, {"id": 1283, "seek": 383120, "start": 3854.3999999999996, "end": 3855.68, "text": " And famously, for example,", "tokens": [51524, 400, 34360, 11, 337, 1365, 11, 51588], "temperature": 0.0, "avg_logprob": -0.14512866412022318, "compression_ratio": 1.7167832167832169, "no_speech_prob": 0.001522835693322122}, {"id": 1284, "seek": 383120, "start": 3855.68, "end": 3857.52, "text": " if you play things like Prisoners of the Lemon", "tokens": [51588, 498, 291, 862, 721, 411, 38888, 433, 295, 264, 35404, 51680], "temperature": 0.0, "avg_logprob": -0.14512866412022318, "compression_ratio": 1.7167832167832169, "no_speech_prob": 0.001522835693322122}, {"id": 1285, "seek": 383120, "start": 3857.52, "end": 3859.68, "text": " and whatnot repeated, like you're like,", "tokens": [51680, 293, 25882, 10477, 11, 411, 291, 434, 411, 11, 51788], "temperature": 0.0, "avg_logprob": -0.14512866412022318, "compression_ratio": 1.7167832167832169, "no_speech_prob": 0.001522835693322122}, {"id": 1286, "seek": 385968, "start": 3859.7599999999998, "end": 3861.6, "text": " cooperate, defect and whatnot,", "tokens": [50368, 26667, 11, 16445, 293, 25882, 11, 50460], "temperature": 0.0, "avg_logprob": -0.10959044308729575, "compression_ratio": 1.8327526132404182, "no_speech_prob": 0.008304052986204624}, {"id": 1287, "seek": 385968, "start": 3861.6, "end": 3863.68, "text": " as soon as you start bringing in these other things,", "tokens": [50460, 382, 2321, 382, 291, 722, 5062, 294, 613, 661, 721, 11, 50564], "temperature": 0.0, "avg_logprob": -0.10959044308729575, "compression_ratio": 1.8327526132404182, "no_speech_prob": 0.008304052986204624}, {"id": 1288, "seek": 385968, "start": 3863.68, "end": 3865.44, "text": " like that make things more realistic,", "tokens": [50564, 411, 300, 652, 721, 544, 12465, 11, 50652], "temperature": 0.0, "avg_logprob": -0.10959044308729575, "compression_ratio": 1.8327526132404182, "no_speech_prob": 0.008304052986204624}, {"id": 1289, "seek": 385968, "start": 3865.44, "end": 3866.7999999999997, "text": " you actually start to get behavior", "tokens": [50652, 291, 767, 722, 281, 483, 5223, 50720], "temperature": 0.0, "avg_logprob": -0.10959044308729575, "compression_ratio": 1.8327526132404182, "no_speech_prob": 0.008304052986204624}, {"id": 1290, "seek": 385968, "start": 3866.7999999999997, "end": 3869.3599999999997, "text": " that is much more, what's the way to put it,", "tokens": [50720, 300, 307, 709, 544, 11, 437, 311, 264, 636, 281, 829, 309, 11, 50848], "temperature": 0.0, "avg_logprob": -0.10959044308729575, "compression_ratio": 1.8327526132404182, "no_speech_prob": 0.008304052986204624}, {"id": 1291, "seek": 385968, "start": 3869.3599999999997, "end": 3872.08, "text": " rational in some ways and human and whatnot, right?", "tokens": [50848, 15090, 294, 512, 2098, 293, 1952, 293, 25882, 11, 558, 30, 50984], "temperature": 0.0, "avg_logprob": -0.10959044308729575, "compression_ratio": 1.8327526132404182, "no_speech_prob": 0.008304052986204624}, {"id": 1292, "seek": 385968, "start": 3872.08, "end": 3874.3999999999996, "text": " Another one is that traditional economics,", "tokens": [50984, 3996, 472, 307, 300, 5164, 14564, 11, 51100], "temperature": 0.0, "avg_logprob": -0.10959044308729575, "compression_ratio": 1.8327526132404182, "no_speech_prob": 0.008304052986204624}, {"id": 1293, "seek": 385968, "start": 3874.3999999999996, "end": 3876.56, "text": " which I think Ayn Rand was influenced by,", "tokens": [51100, 597, 286, 519, 316, 2534, 23614, 390, 15269, 538, 11, 51208], "temperature": 0.0, "avg_logprob": -0.10959044308729575, "compression_ratio": 1.8327526132404182, "no_speech_prob": 0.008304052986204624}, {"id": 1294, "seek": 385968, "start": 3876.56, "end": 3878.64, "text": " viewed and still views the world as linear,", "tokens": [51208, 19174, 293, 920, 6809, 264, 1002, 382, 8213, 11, 51312], "temperature": 0.0, "avg_logprob": -0.10959044308729575, "compression_ratio": 1.8327526132404182, "no_speech_prob": 0.008304052986204624}, {"id": 1295, "seek": 385968, "start": 3879.3599999999997, "end": 3880.64, "text": " but the world is non-linear.", "tokens": [51348, 457, 264, 1002, 307, 2107, 12, 28263, 13, 51412], "temperature": 0.0, "avg_logprob": -0.10959044308729575, "compression_ratio": 1.8327526132404182, "no_speech_prob": 0.008304052986204624}, {"id": 1296, "seek": 385968, "start": 3881.2, "end": 3883.68, "text": " Once you start seeing the world as non-linear,", "tokens": [51440, 3443, 291, 722, 2577, 264, 1002, 382, 2107, 12, 28263, 11, 51564], "temperature": 0.0, "avg_logprob": -0.10959044308729575, "compression_ratio": 1.8327526132404182, "no_speech_prob": 0.008304052986204624}, {"id": 1297, "seek": 385968, "start": 3883.68, "end": 3885.6, "text": " all of these things really change,", "tokens": [51564, 439, 295, 613, 721, 534, 1319, 11, 51660], "temperature": 0.0, "avg_logprob": -0.10959044308729575, "compression_ratio": 1.8327526132404182, "no_speech_prob": 0.008304052986204624}, {"id": 1298, "seek": 385968, "start": 3885.6, "end": 3887.6, "text": " the face of them changes, right?", "tokens": [51660, 264, 1851, 295, 552, 2962, 11, 558, 30, 51760], "temperature": 0.0, "avg_logprob": -0.10959044308729575, "compression_ratio": 1.8327526132404182, "no_speech_prob": 0.008304052986204624}, {"id": 1299, "seek": 388760, "start": 3887.68, "end": 3889.8399999999997, "text": " So I think we have to look at all these concepts", "tokens": [50368, 407, 286, 519, 321, 362, 281, 574, 412, 439, 613, 10392, 50476], "temperature": 0.0, "avg_logprob": -0.17557644453205046, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.007102651987224817}, {"id": 1300, "seek": 388760, "start": 3889.8399999999997, "end": 3891.8399999999997, "text": " in this view, right?", "tokens": [50476, 294, 341, 1910, 11, 558, 30, 50576], "temperature": 0.0, "avg_logprob": -0.17557644453205046, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.007102651987224817}, {"id": 1301, "seek": 388760, "start": 3891.8399999999997, "end": 3894.48, "text": " And we want to focus on the long, so...", "tokens": [50576, 400, 321, 528, 281, 1879, 322, 264, 938, 11, 370, 485, 50708], "temperature": 0.0, "avg_logprob": -0.17557644453205046, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.007102651987224817}, {"id": 1302, "seek": 388760, "start": 3896.64, "end": 3899.6, "text": " So to get back to your first point, right?", "tokens": [50816, 407, 281, 483, 646, 281, 428, 700, 935, 11, 558, 30, 50964], "temperature": 0.0, "avg_logprob": -0.17557644453205046, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.007102651987224817}, {"id": 1303, "seek": 388760, "start": 3900.16, "end": 3901.7599999999998, "text": " We are born with faulty programming.", "tokens": [50992, 492, 366, 4232, 365, 2050, 5773, 9410, 13, 51072], "temperature": 0.0, "avg_logprob": -0.17557644453205046, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.007102651987224817}, {"id": 1304, "seek": 388760, "start": 3902.7999999999997, "end": 3903.52, "text": " Part of our fa...", "tokens": [51124, 4100, 295, 527, 2050, 485, 51160], "temperature": 0.0, "avg_logprob": -0.17557644453205046, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.007102651987224817}, {"id": 1305, "seek": 388760, "start": 3903.52, "end": 3906.24, "text": " And that's what if effective alteration", "tokens": [51160, 400, 300, 311, 437, 498, 4942, 11337, 399, 51296], "temperature": 0.0, "avg_logprob": -0.17557644453205046, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.007102651987224817}, {"id": 1306, "seek": 388760, "start": 3906.24, "end": 3907.7599999999998, "text": " is there to overcome, right?", "tokens": [51296, 307, 456, 281, 10473, 11, 558, 30, 51372], "temperature": 0.0, "avg_logprob": -0.17557644453205046, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.007102651987224817}, {"id": 1307, "seek": 388760, "start": 3908.3199999999997, "end": 3909.8399999999997, "text": " Part of our faulty programming", "tokens": [51400, 4100, 295, 527, 2050, 5773, 9410, 51476], "temperature": 0.0, "avg_logprob": -0.17557644453205046, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.007102651987224817}, {"id": 1308, "seek": 388760, "start": 3909.8399999999997, "end": 3912.0, "text": " is that our discount rate is too high,", "tokens": [51476, 307, 300, 527, 11635, 3314, 307, 886, 1090, 11, 51584], "temperature": 0.0, "avg_logprob": -0.17557644453205046, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.007102651987224817}, {"id": 1309, "seek": 388760, "start": 3913.12, "end": 3914.64, "text": " because we evolved in a world", "tokens": [51640, 570, 321, 14178, 294, 257, 1002, 51716], "temperature": 0.0, "avg_logprob": -0.17557644453205046, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.007102651987224817}, {"id": 1310, "seek": 388760, "start": 3914.64, "end": 3916.4, "text": " where your time horizon was very short.", "tokens": [51716, 689, 428, 565, 18046, 390, 588, 2099, 13, 51804], "temperature": 0.0, "avg_logprob": -0.17557644453205046, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.007102651987224817}, {"id": 1311, "seek": 391640, "start": 3917.36, "end": 3918.64, "text": " The fact that it's too high", "tokens": [50412, 440, 1186, 300, 309, 311, 886, 1090, 50476], "temperature": 0.0, "avg_logprob": -0.14484565908258612, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.004516431596130133}, {"id": 1312, "seek": 391640, "start": 3918.64, "end": 3920.4, "text": " doesn't mean that we should make it zero", "tokens": [50476, 1177, 380, 914, 300, 321, 820, 652, 309, 4018, 50564], "temperature": 0.0, "avg_logprob": -0.14484565908258612, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.004516431596130133}, {"id": 1313, "seek": 391640, "start": 3921.6, "end": 3923.04, "text": " and care only about the future.", "tokens": [50624, 293, 1127, 787, 466, 264, 2027, 13, 50696], "temperature": 0.0, "avg_logprob": -0.14484565908258612, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.004516431596130133}, {"id": 1314, "seek": 391640, "start": 3923.6, "end": 3924.4, "text": " But what would...", "tokens": [50724, 583, 437, 576, 485, 50764], "temperature": 0.0, "avg_logprob": -0.14484565908258612, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.004516431596130133}, {"id": 1315, "seek": 391640, "start": 3924.4, "end": 3926.56, "text": " You know, the ethics folks who advocate", "tokens": [50764, 509, 458, 11, 264, 19769, 4024, 567, 14608, 50872], "temperature": 0.0, "avg_logprob": -0.14484565908258612, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.004516431596130133}, {"id": 1316, "seek": 391640, "start": 3926.56, "end": 3928.1600000000003, "text": " for gatekeeping and paternalism,", "tokens": [50872, 337, 8539, 25769, 293, 42302, 4660, 1434, 11, 50952], "temperature": 0.0, "avg_logprob": -0.14484565908258612, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.004516431596130133}, {"id": 1317, "seek": 391640, "start": 3929.12, "end": 3930.96, "text": " couldn't you just say that they're doing the same thing?", "tokens": [51000, 2809, 380, 291, 445, 584, 300, 436, 434, 884, 264, 912, 551, 30, 51092], "temperature": 0.0, "avg_logprob": -0.14484565908258612, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.004516431596130133}, {"id": 1318, "seek": 391640, "start": 3932.48, "end": 3934.1600000000003, "text": " Well, you should ask them, right?", "tokens": [51168, 1042, 11, 291, 820, 1029, 552, 11, 558, 30, 51252], "temperature": 0.0, "avg_logprob": -0.14484565908258612, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.004516431596130133}, {"id": 1319, "seek": 391640, "start": 3934.1600000000003, "end": 3938.0, "text": " Wouldn't they lead by saying our programming is faulty", "tokens": [51252, 26291, 380, 436, 1477, 538, 1566, 527, 9410, 307, 2050, 5773, 51444], "temperature": 0.0, "avg_logprob": -0.14484565908258612, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.004516431596130133}, {"id": 1320, "seek": 391640, "start": 3938.0, "end": 3940.08, "text": " and therefore, you know, we need to...", "tokens": [51444, 293, 4412, 11, 291, 458, 11, 321, 643, 281, 485, 51548], "temperature": 0.0, "avg_logprob": -0.14484565908258612, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.004516431596130133}, {"id": 1321, "seek": 391640, "start": 3940.08, "end": 3942.8, "text": " No, I mean, look, we can...", "tokens": [51548, 883, 11, 286, 914, 11, 574, 11, 321, 393, 485, 51684], "temperature": 0.0, "avg_logprob": -0.14484565908258612, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.004516431596130133}, {"id": 1322, "seek": 391640, "start": 3942.8, "end": 3945.76, "text": " So part one, we can debate whether our programming", "tokens": [51684, 407, 644, 472, 11, 321, 393, 7958, 1968, 527, 9410, 51832], "temperature": 0.0, "avg_logprob": -0.14484565908258612, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.004516431596130133}, {"id": 1323, "seek": 394576, "start": 3945.76, "end": 3947.5200000000004, "text": " is faulty or not and why.", "tokens": [50364, 307, 2050, 5773, 420, 406, 293, 983, 13, 50452], "temperature": 0.0, "avg_logprob": -0.08456348419189454, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.005436498671770096}, {"id": 1324, "seek": 394576, "start": 3947.5200000000004, "end": 3950.5600000000004, "text": " And so to just start by touching on that,", "tokens": [50452, 400, 370, 281, 445, 722, 538, 11175, 322, 300, 11, 50604], "temperature": 0.0, "avg_logprob": -0.08456348419189454, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.005436498671770096}, {"id": 1325, "seek": 394576, "start": 3950.5600000000004, "end": 3952.2400000000002, "text": " our programming is faulty.", "tokens": [50604, 527, 9410, 307, 2050, 5773, 13, 50688], "temperature": 0.0, "avg_logprob": -0.08456348419189454, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.005436498671770096}, {"id": 1326, "seek": 394576, "start": 3952.2400000000002, "end": 3954.48, "text": " So our programming is not faulty", "tokens": [50688, 407, 527, 9410, 307, 406, 2050, 5773, 50800], "temperature": 0.0, "avg_logprob": -0.08456348419189454, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.005436498671770096}, {"id": 1327, "seek": 394576, "start": 3954.48, "end": 3956.4, "text": " in the sense that we evolved", "tokens": [50800, 294, 264, 2020, 300, 321, 14178, 50896], "temperature": 0.0, "avg_logprob": -0.08456348419189454, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.005436498671770096}, {"id": 1328, "seek": 394576, "start": 3957.0400000000004, "end": 3959.6800000000003, "text": " for a particular set of conditions, right?", "tokens": [50928, 337, 257, 1729, 992, 295, 4487, 11, 558, 30, 51060], "temperature": 0.0, "avg_logprob": -0.08456348419189454, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.005436498671770096}, {"id": 1329, "seek": 394576, "start": 3959.6800000000003, "end": 3961.36, "text": " And that evolution may not be complete", "tokens": [51060, 400, 300, 9303, 815, 406, 312, 3566, 51144], "temperature": 0.0, "avg_logprob": -0.08456348419189454, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.005436498671770096}, {"id": 1330, "seek": 394576, "start": 3961.36, "end": 3962.6400000000003, "text": " or optimal, et cetera, et cetera.", "tokens": [51144, 420, 16252, 11, 1030, 11458, 11, 1030, 11458, 13, 51208], "temperature": 0.0, "avg_logprob": -0.08456348419189454, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.005436498671770096}, {"id": 1331, "seek": 394576, "start": 3962.6400000000003, "end": 3965.84, "text": " But roughly speaking, we are not faulty in that sense.", "tokens": [51208, 583, 9810, 4124, 11, 321, 366, 406, 2050, 5773, 294, 300, 2020, 13, 51368], "temperature": 0.0, "avg_logprob": -0.08456348419189454, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.005436498671770096}, {"id": 1332, "seek": 394576, "start": 3965.84, "end": 3966.4, "text": " The reason...", "tokens": [51368, 440, 1778, 485, 51396], "temperature": 0.0, "avg_logprob": -0.08456348419189454, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.005436498671770096}, {"id": 1333, "seek": 394576, "start": 3966.4, "end": 3968.4, "text": " Because evolution is doing its job, right?", "tokens": [51396, 1436, 9303, 307, 884, 1080, 1691, 11, 558, 30, 51496], "temperature": 0.0, "avg_logprob": -0.08456348419189454, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.005436498671770096}, {"id": 1334, "seek": 394576, "start": 3968.4, "end": 3971.44, "text": " We have all those impulses for a reason, right?", "tokens": [51496, 492, 362, 439, 729, 41767, 6196, 337, 257, 1778, 11, 558, 30, 51648], "temperature": 0.0, "avg_logprob": -0.08456348419189454, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.005436498671770096}, {"id": 1335, "seek": 397144, "start": 3971.44, "end": 3976.2400000000002, "text": " Now, the problem is that we, unlike any other species,", "tokens": [50364, 823, 11, 264, 1154, 307, 300, 321, 11, 8343, 604, 661, 6172, 11, 50604], "temperature": 0.0, "avg_logprob": -0.06438002014160156, "compression_ratio": 1.7870722433460076, "no_speech_prob": 0.0033209568355232477}, {"id": 1336, "seek": 397144, "start": 3976.2400000000002, "end": 3979.12, "text": " we actually have actually succeeded in creating a world", "tokens": [50604, 321, 767, 362, 767, 20263, 294, 4084, 257, 1002, 50748], "temperature": 0.0, "avg_logprob": -0.06438002014160156, "compression_ratio": 1.7870722433460076, "no_speech_prob": 0.0033209568355232477}, {"id": 1337, "seek": 397144, "start": 3980.2400000000002, "end": 3981.44, "text": " that is better for us.", "tokens": [50804, 300, 307, 1101, 337, 505, 13, 50864], "temperature": 0.0, "avg_logprob": -0.06438002014160156, "compression_ratio": 1.7870722433460076, "no_speech_prob": 0.0033209568355232477}, {"id": 1338, "seek": 397144, "start": 3982.16, "end": 3984.32, "text": " But at the same time, and this is the problem,", "tokens": [50900, 583, 412, 264, 912, 565, 11, 293, 341, 307, 264, 1154, 11, 51008], "temperature": 0.0, "avg_logprob": -0.06438002014160156, "compression_ratio": 1.7870722433460076, "no_speech_prob": 0.0033209568355232477}, {"id": 1339, "seek": 397144, "start": 3984.32, "end": 3986.64, "text": " we're actually now adapted to a different world", "tokens": [51008, 321, 434, 767, 586, 20871, 281, 257, 819, 1002, 51124], "temperature": 0.0, "avg_logprob": -0.06438002014160156, "compression_ratio": 1.7870722433460076, "no_speech_prob": 0.0033209568355232477}, {"id": 1340, "seek": 397144, "start": 3986.64, "end": 3987.76, "text": " from the one that we live in.", "tokens": [51124, 490, 264, 472, 300, 321, 1621, 294, 13, 51180], "temperature": 0.0, "avg_logprob": -0.06438002014160156, "compression_ratio": 1.7870722433460076, "no_speech_prob": 0.0033209568355232477}, {"id": 1341, "seek": 397144, "start": 3988.56, "end": 3990.48, "text": " So the faulty program just comes from the fact", "tokens": [51220, 407, 264, 2050, 5773, 1461, 445, 1487, 490, 264, 1186, 51316], "temperature": 0.0, "avg_logprob": -0.06438002014160156, "compression_ratio": 1.7870722433460076, "no_speech_prob": 0.0033209568355232477}, {"id": 1342, "seek": 397144, "start": 3990.48, "end": 3992.64, "text": " that we evolved for one set of conditions.", "tokens": [51316, 300, 321, 14178, 337, 472, 992, 295, 4487, 13, 51424], "temperature": 0.0, "avg_logprob": -0.06438002014160156, "compression_ratio": 1.7870722433460076, "no_speech_prob": 0.0033209568355232477}, {"id": 1343, "seek": 397144, "start": 3992.64, "end": 3994.8, "text": " For example, among many other examples", "tokens": [51424, 1171, 1365, 11, 3654, 867, 661, 5110, 51532], "temperature": 0.0, "avg_logprob": -0.06438002014160156, "compression_ratio": 1.7870722433460076, "no_speech_prob": 0.0033209568355232477}, {"id": 1344, "seek": 397144, "start": 3994.8, "end": 3996.96, "text": " where your time horizon was very short,", "tokens": [51532, 689, 428, 565, 18046, 390, 588, 2099, 11, 51640], "temperature": 0.0, "avg_logprob": -0.06438002014160156, "compression_ratio": 1.7870722433460076, "no_speech_prob": 0.0033209568355232477}, {"id": 1345, "seek": 397144, "start": 3996.96, "end": 3998.96, "text": " and now we live in a very different world.", "tokens": [51640, 293, 586, 321, 1621, 294, 257, 588, 819, 1002, 13, 51740], "temperature": 0.0, "avg_logprob": -0.06438002014160156, "compression_ratio": 1.7870722433460076, "no_speech_prob": 0.0033209568355232477}, {"id": 1346, "seek": 399896, "start": 3998.96, "end": 4001.36, "text": " And so our job as rational people,", "tokens": [50364, 400, 370, 527, 1691, 382, 15090, 561, 11, 50484], "temperature": 0.0, "avg_logprob": -0.07617546319961548, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0023173470981419086}, {"id": 1347, "seek": 399896, "start": 4001.36, "end": 4002.96, "text": " that's what our rational minds are for,", "tokens": [50484, 300, 311, 437, 527, 15090, 9634, 366, 337, 11, 50564], "temperature": 0.0, "avg_logprob": -0.07617546319961548, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0023173470981419086}, {"id": 1348, "seek": 399896, "start": 4002.96, "end": 4005.52, "text": " among other things, is to now adapt ourselves", "tokens": [50564, 3654, 661, 721, 11, 307, 281, 586, 6231, 4175, 50692], "temperature": 0.0, "avg_logprob": -0.07617546319961548, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0023173470981419086}, {"id": 1349, "seek": 399896, "start": 4005.52, "end": 4007.36, "text": " to the world that we really are in", "tokens": [50692, 281, 264, 1002, 300, 321, 534, 366, 294, 50784], "temperature": 0.0, "avg_logprob": -0.07617546319961548, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0023173470981419086}, {"id": 1350, "seek": 399896, "start": 4007.36, "end": 4008.88, "text": " so that we do things that are rational", "tokens": [50784, 370, 300, 321, 360, 721, 300, 366, 15090, 50860], "temperature": 0.0, "avg_logprob": -0.07617546319961548, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0023173470981419086}, {"id": 1351, "seek": 399896, "start": 4008.88, "end": 4010.0, "text": " in the world that we're in, right?", "tokens": [50860, 294, 264, 1002, 300, 321, 434, 294, 11, 558, 30, 50916], "temperature": 0.0, "avg_logprob": -0.07617546319961548, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0023173470981419086}, {"id": 1352, "seek": 399896, "start": 4010.0, "end": 4013.12, "text": " So now, the fact that our programming is faulty", "tokens": [50916, 407, 586, 11, 264, 1186, 300, 527, 9410, 307, 2050, 5773, 51072], "temperature": 0.0, "avg_logprob": -0.07617546319961548, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0023173470981419086}, {"id": 1353, "seek": 399896, "start": 4013.12, "end": 4015.84, "text": " does not see anything about what are the faults", "tokens": [51072, 775, 406, 536, 1340, 466, 437, 366, 264, 36090, 51208], "temperature": 0.0, "avg_logprob": -0.07617546319961548, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0023173470981419086}, {"id": 1354, "seek": 399896, "start": 4015.84, "end": 4016.8, "text": " and how you fix them.", "tokens": [51208, 293, 577, 291, 3191, 552, 13, 51256], "temperature": 0.0, "avg_logprob": -0.07617546319961548, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0023173470981419086}, {"id": 1355, "seek": 399896, "start": 4016.8, "end": 4018.2400000000002, "text": " And what these people have, I think,", "tokens": [51256, 400, 437, 613, 561, 362, 11, 286, 519, 11, 51328], "temperature": 0.0, "avg_logprob": -0.07617546319961548, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0023173470981419086}, {"id": 1356, "seek": 399896, "start": 4018.2400000000002, "end": 4021.2, "text": " is first of all, the wrong notion of what our faults are", "tokens": [51328, 307, 700, 295, 439, 11, 264, 2085, 10710, 295, 437, 527, 36090, 366, 51476], "temperature": 0.0, "avg_logprob": -0.07617546319961548, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0023173470981419086}, {"id": 1357, "seek": 399896, "start": 4021.2, "end": 4022.2400000000002, "text": " and then on top of that,", "tokens": [51476, 293, 550, 322, 1192, 295, 300, 11, 51528], "temperature": 0.0, "avg_logprob": -0.07617546319961548, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0023173470981419086}, {"id": 1358, "seek": 399896, "start": 4022.2400000000002, "end": 4023.76, "text": " the wrong notion of how to fix them.", "tokens": [51528, 264, 2085, 10710, 295, 577, 281, 3191, 552, 13, 51604], "temperature": 0.0, "avg_logprob": -0.07617546319961548, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0023173470981419086}, {"id": 1359, "seek": 399896, "start": 4024.8, "end": 4028.2400000000002, "text": " Okay, now, I want to get into the utility function again.", "tokens": [51656, 1033, 11, 586, 11, 286, 528, 281, 483, 666, 264, 14877, 2445, 797, 13, 51828], "temperature": 0.0, "avg_logprob": -0.07617546319961548, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0023173470981419086}, {"id": 1360, "seek": 402824, "start": 4028.72, "end": 4030.8799999999997, "text": " Again, one of the things that makes me skeptical", "tokens": [50388, 3764, 11, 472, 295, 264, 721, 300, 1669, 385, 28601, 50496], "temperature": 0.0, "avg_logprob": -0.08361554613300398, "compression_ratio": 1.7284345047923322, "no_speech_prob": 0.0050318315625190735}, {"id": 1361, "seek": 402824, "start": 4030.8799999999997, "end": 4034.3199999999997, "text": " is this notion of immutability, both of what we're doing", "tokens": [50496, 307, 341, 10710, 295, 3397, 325, 2310, 11, 1293, 295, 437, 321, 434, 884, 50668], "temperature": 0.0, "avg_logprob": -0.08361554613300398, "compression_ratio": 1.7284345047923322, "no_speech_prob": 0.0050318315625190735}, {"id": 1362, "seek": 402824, "start": 4034.3199999999997, "end": 4036.56, "text": " and in the case of what we've been speaking about", "tokens": [50668, 293, 294, 264, 1389, 295, 437, 321, 600, 668, 4124, 466, 50780], "temperature": 0.0, "avg_logprob": -0.08361554613300398, "compression_ratio": 1.7284345047923322, "no_speech_prob": 0.0050318315625190735}, {"id": 1363, "seek": 402824, "start": 4036.56, "end": 4039.68, "text": " with utilitarianism, what the utility function is.", "tokens": [50780, 365, 4976, 13707, 1434, 11, 437, 264, 14877, 2445, 307, 13, 50936], "temperature": 0.0, "avg_logprob": -0.08361554613300398, "compression_ratio": 1.7284345047923322, "no_speech_prob": 0.0050318315625190735}, {"id": 1364, "seek": 402824, "start": 4039.68, "end": 4041.68, "text": " Now, you were kind of hinting to something interesting before,", "tokens": [50936, 823, 11, 291, 645, 733, 295, 12075, 278, 281, 746, 1880, 949, 11, 51036], "temperature": 0.0, "avg_logprob": -0.08361554613300398, "compression_ratio": 1.7284345047923322, "no_speech_prob": 0.0050318315625190735}, {"id": 1365, "seek": 402824, "start": 4041.68, "end": 4043.2799999999997, "text": " which is that it might be diverse", "tokens": [51036, 597, 307, 300, 309, 1062, 312, 9521, 51116], "temperature": 0.0, "avg_logprob": -0.08361554613300398, "compression_ratio": 1.7284345047923322, "no_speech_prob": 0.0050318315625190735}, {"id": 1366, "seek": 402824, "start": 4043.2799999999997, "end": 4045.3599999999997, "text": " and it might also be self-updating.", "tokens": [51116, 293, 309, 1062, 611, 312, 2698, 12, 1010, 67, 990, 13, 51220], "temperature": 0.0, "avg_logprob": -0.08361554613300398, "compression_ratio": 1.7284345047923322, "no_speech_prob": 0.0050318315625190735}, {"id": 1367, "seek": 402824, "start": 4045.3599999999997, "end": 4047.8399999999997, "text": " But I'm constantly asking myself the question,", "tokens": [51220, 583, 286, 478, 6460, 3365, 2059, 264, 1168, 11, 51344], "temperature": 0.0, "avg_logprob": -0.08361554613300398, "compression_ratio": 1.7284345047923322, "no_speech_prob": 0.0050318315625190735}, {"id": 1368, "seek": 402824, "start": 4047.8399999999997, "end": 4049.52, "text": " how does that work and who gets to say?", "tokens": [51344, 577, 775, 300, 589, 293, 567, 2170, 281, 584, 30, 51428], "temperature": 0.0, "avg_logprob": -0.08361554613300398, "compression_ratio": 1.7284345047923322, "no_speech_prob": 0.0050318315625190735}, {"id": 1369, "seek": 402824, "start": 4050.56, "end": 4053.3599999999997, "text": " Well, so very much, I think it's complex", "tokens": [51480, 1042, 11, 370, 588, 709, 11, 286, 519, 309, 311, 3997, 51620], "temperature": 0.0, "avg_logprob": -0.08361554613300398, "compression_ratio": 1.7284345047923322, "no_speech_prob": 0.0050318315625190735}, {"id": 1370, "seek": 402824, "start": 4053.3599999999997, "end": 4054.7999999999997, "text": " and it should be self-updating, right?", "tokens": [51620, 293, 309, 820, 312, 2698, 12, 1010, 67, 990, 11, 558, 30, 51692], "temperature": 0.0, "avg_logprob": -0.08361554613300398, "compression_ratio": 1.7284345047923322, "no_speech_prob": 0.0050318315625190735}, {"id": 1371, "seek": 402824, "start": 4054.7999999999997, "end": 4056.3999999999996, "text": " We're never going to final itself.", "tokens": [51692, 492, 434, 1128, 516, 281, 2572, 2564, 13, 51772], "temperature": 0.0, "avg_logprob": -0.08361554613300398, "compression_ratio": 1.7284345047923322, "no_speech_prob": 0.0050318315625190735}, {"id": 1372, "seek": 405640, "start": 4057.36, "end": 4060.64, "text": " If you buy this notion that the ultimate arbiter is evolution,", "tokens": [50412, 759, 291, 2256, 341, 10710, 300, 264, 9705, 25613, 1681, 307, 9303, 11, 50576], "temperature": 0.0, "avg_logprob": -0.1582339310846409, "compression_ratio": 1.8661087866108788, "no_speech_prob": 0.001095828483812511}, {"id": 1373, "seek": 405640, "start": 4061.2000000000003, "end": 4064.32, "text": " then utility functions are subject to evolution.", "tokens": [50604, 550, 14877, 6828, 366, 3983, 281, 9303, 13, 50760], "temperature": 0.0, "avg_logprob": -0.1582339310846409, "compression_ratio": 1.8661087866108788, "no_speech_prob": 0.001095828483812511}, {"id": 1374, "seek": 405640, "start": 4065.6800000000003, "end": 4067.36, "text": " Right, so you think about it", "tokens": [50828, 1779, 11, 370, 291, 519, 466, 309, 50912], "temperature": 0.0, "avg_logprob": -0.1582339310846409, "compression_ratio": 1.8661087866108788, "no_speech_prob": 0.001095828483812511}, {"id": 1375, "seek": 405640, "start": 4067.36, "end": 4068.56, "text": " or you can't think about it.", "tokens": [50912, 420, 291, 393, 380, 519, 466, 309, 13, 50972], "temperature": 0.0, "avg_logprob": -0.1582339310846409, "compression_ratio": 1.8661087866108788, "no_speech_prob": 0.001095828483812511}, {"id": 1376, "seek": 405640, "start": 4068.56, "end": 4070.88, "text": " It's a wrong world.", "tokens": [50972, 467, 311, 257, 2085, 1002, 13, 51088], "temperature": 0.0, "avg_logprob": -0.1582339310846409, "compression_ratio": 1.8661087866108788, "no_speech_prob": 0.001095828483812511}, {"id": 1377, "seek": 405640, "start": 4070.88, "end": 4072.08, "text": " You can't think about this", "tokens": [51088, 509, 393, 380, 519, 466, 341, 51148], "temperature": 0.0, "avg_logprob": -0.1582339310846409, "compression_ratio": 1.8661087866108788, "no_speech_prob": 0.001095828483812511}, {"id": 1378, "seek": 405640, "start": 4072.08, "end": 4074.32, "text": " and it's useful to think about this in the following ways.", "tokens": [51148, 293, 309, 311, 4420, 281, 519, 466, 341, 294, 264, 3480, 2098, 13, 51260], "temperature": 0.0, "avg_logprob": -0.1582339310846409, "compression_ratio": 1.8661087866108788, "no_speech_prob": 0.001095828483812511}, {"id": 1379, "seek": 405640, "start": 4074.96, "end": 4076.2400000000002, "text": " To a first approximation,", "tokens": [51292, 1407, 257, 700, 28023, 11, 51356], "temperature": 0.0, "avg_logprob": -0.1582339310846409, "compression_ratio": 1.8661087866108788, "no_speech_prob": 0.001095828483812511}, {"id": 1380, "seek": 405640, "start": 4076.2400000000002, "end": 4079.36, "text": " the number one entity that's evolving is utility functions.", "tokens": [51356, 264, 1230, 472, 13977, 300, 311, 21085, 307, 14877, 6828, 13, 51512], "temperature": 0.0, "avg_logprob": -0.1582339310846409, "compression_ratio": 1.8661087866108788, "no_speech_prob": 0.001095828483812511}, {"id": 1381, "seek": 405640, "start": 4079.36, "end": 4081.04, "text": " What you have in the world at any point", "tokens": [51512, 708, 291, 362, 294, 264, 1002, 412, 604, 935, 51596], "temperature": 0.0, "avg_logprob": -0.1582339310846409, "compression_ratio": 1.8661087866108788, "no_speech_prob": 0.001095828483812511}, {"id": 1382, "seek": 405640, "start": 4081.04, "end": 4083.84, "text": " is a population of utility functions, right?", "tokens": [51596, 307, 257, 4415, 295, 14877, 6828, 11, 558, 30, 51736], "temperature": 0.0, "avg_logprob": -0.1582339310846409, "compression_ratio": 1.8661087866108788, "no_speech_prob": 0.001095828483812511}, {"id": 1383, "seek": 408384, "start": 4083.92, "end": 4086.32, "text": " And now they combine, they evolve,", "tokens": [50368, 400, 586, 436, 10432, 11, 436, 16693, 11, 50488], "temperature": 0.0, "avg_logprob": -0.11914491294918203, "compression_ratio": 1.862190812720848, "no_speech_prob": 0.004457999020814896}, {"id": 1384, "seek": 408384, "start": 4086.32, "end": 4088.08, "text": " you have next generation of utility functions.", "tokens": [50488, 291, 362, 958, 5125, 295, 14877, 6828, 13, 50576], "temperature": 0.0, "avg_logprob": -0.11914491294918203, "compression_ratio": 1.862190812720848, "no_speech_prob": 0.004457999020814896}, {"id": 1385, "seek": 408384, "start": 4088.08, "end": 4092.56, "text": " And then there's also how the utility function gets optimized.", "tokens": [50576, 400, 550, 456, 311, 611, 577, 264, 14877, 2445, 2170, 26941, 13, 50800], "temperature": 0.0, "avg_logprob": -0.11914491294918203, "compression_ratio": 1.862190812720848, "no_speech_prob": 0.004457999020814896}, {"id": 1386, "seek": 408384, "start": 4092.56, "end": 4094.88, "text": " That is also subject to evolution, right?", "tokens": [50800, 663, 307, 611, 3983, 281, 9303, 11, 558, 30, 50916], "temperature": 0.0, "avg_logprob": -0.11914491294918203, "compression_ratio": 1.862190812720848, "no_speech_prob": 0.004457999020814896}, {"id": 1387, "seek": 408384, "start": 4094.88, "end": 4097.4400000000005, "text": " And now how the utility function is optimized", "tokens": [50916, 400, 586, 577, 264, 14877, 2445, 307, 26941, 51044], "temperature": 0.0, "avg_logprob": -0.11914491294918203, "compression_ratio": 1.862190812720848, "no_speech_prob": 0.004457999020814896}, {"id": 1388, "seek": 408384, "start": 4097.4400000000005, "end": 4098.56, "text": " changes a lot faster", "tokens": [51044, 2962, 257, 688, 4663, 51100], "temperature": 0.0, "avg_logprob": -0.11914491294918203, "compression_ratio": 1.862190812720848, "no_speech_prob": 0.004457999020814896}, {"id": 1389, "seek": 408384, "start": 4098.56, "end": 4101.2, "text": " and this is a lot more complex than the utility function itself,", "tokens": [51100, 293, 341, 307, 257, 688, 544, 3997, 813, 264, 14877, 2445, 2564, 11, 51232], "temperature": 0.0, "avg_logprob": -0.11914491294918203, "compression_ratio": 1.862190812720848, "no_speech_prob": 0.004457999020814896}, {"id": 1390, "seek": 408384, "start": 4101.2, "end": 4102.8, "text": " which is the point, right?", "tokens": [51232, 597, 307, 264, 935, 11, 558, 30, 51312], "temperature": 0.0, "avg_logprob": -0.11914491294918203, "compression_ratio": 1.862190812720848, "no_speech_prob": 0.004457999020814896}, {"id": 1391, "seek": 408384, "start": 4102.8, "end": 4104.4800000000005, "text": " So at a certain time horizon,", "tokens": [51312, 407, 412, 257, 1629, 565, 18046, 11, 51396], "temperature": 0.0, "avg_logprob": -0.11914491294918203, "compression_ratio": 1.862190812720848, "no_speech_prob": 0.004457999020814896}, {"id": 1392, "seek": 408384, "start": 4104.4800000000005, "end": 4106.88, "text": " it's reasonable to approximate utilities as being fixed.", "tokens": [51396, 309, 311, 10585, 281, 30874, 30482, 382, 885, 6806, 13, 51516], "temperature": 0.0, "avg_logprob": -0.11914491294918203, "compression_ratio": 1.862190812720848, "no_speech_prob": 0.004457999020814896}, {"id": 1393, "seek": 408384, "start": 4106.88, "end": 4110.24, "text": " Like for example, the utilities that are encoded in your brain", "tokens": [51516, 1743, 337, 1365, 11, 264, 30482, 300, 366, 2058, 12340, 294, 428, 3567, 51684], "temperature": 0.0, "avg_logprob": -0.11914491294918203, "compression_ratio": 1.862190812720848, "no_speech_prob": 0.004457999020814896}, {"id": 1394, "seek": 408384, "start": 4110.24, "end": 4113.360000000001, "text": " are fixed by your genes, right?", "tokens": [51684, 366, 6806, 538, 428, 14424, 11, 558, 30, 51840], "temperature": 0.0, "avg_logprob": -0.11914491294918203, "compression_ratio": 1.862190812720848, "no_speech_prob": 0.004457999020814896}, {"id": 1395, "seek": 411336, "start": 4113.36, "end": 4115.759999999999, "text": " So in the context of our present human moment", "tokens": [50364, 407, 294, 264, 4319, 295, 527, 1974, 1952, 1623, 50484], "temperature": 0.0, "avg_logprob": -0.127584248563669, "compression_ratio": 1.6936026936026936, "no_speech_prob": 0.001566638587974012}, {"id": 1396, "seek": 411336, "start": 4115.759999999999, "end": 4117.36, "text": " and effective ultramism or not,", "tokens": [50484, 293, 4942, 3725, 2356, 1434, 420, 406, 11, 50564], "temperature": 0.0, "avg_logprob": -0.127584248563669, "compression_ratio": 1.6936026936026936, "no_speech_prob": 0.001566638587974012}, {"id": 1397, "seek": 411336, "start": 4117.36, "end": 4119.759999999999, "text": " it makes perfect sense to think of utilities fixed.", "tokens": [50564, 309, 1669, 2176, 2020, 281, 519, 295, 30482, 6806, 13, 50684], "temperature": 0.0, "avg_logprob": -0.127584248563669, "compression_ratio": 1.6936026936026936, "no_speech_prob": 0.001566638587974012}, {"id": 1398, "seek": 411336, "start": 4119.759999999999, "end": 4122.24, "text": " But it is evolving and not just on", "tokens": [50684, 583, 309, 307, 21085, 293, 406, 445, 322, 50808], "temperature": 0.0, "avg_logprob": -0.127584248563669, "compression_ratio": 1.6936026936026936, "no_speech_prob": 0.001566638587974012}, {"id": 1399, "seek": 411336, "start": 4122.24, "end": 4125.5199999999995, "text": " eon time scales, but by the generation, right?", "tokens": [50808, 308, 266, 565, 17408, 11, 457, 538, 264, 5125, 11, 558, 30, 50972], "temperature": 0.0, "avg_logprob": -0.127584248563669, "compression_ratio": 1.6936026936026936, "no_speech_prob": 0.001566638587974012}, {"id": 1400, "seek": 411336, "start": 4125.5199999999995, "end": 4126.96, "text": " Things evolve by the generation.", "tokens": [50972, 9514, 16693, 538, 264, 5125, 13, 51044], "temperature": 0.0, "avg_logprob": -0.127584248563669, "compression_ratio": 1.6936026936026936, "no_speech_prob": 0.001566638587974012}, {"id": 1401, "seek": 411336, "start": 4126.96, "end": 4128.96, "text": " Okay, but it's still relatively glacial", "tokens": [51044, 1033, 11, 457, 309, 311, 920, 7226, 1563, 25980, 51144], "temperature": 0.0, "avg_logprob": -0.127584248563669, "compression_ratio": 1.6936026936026936, "no_speech_prob": 0.001566638587974012}, {"id": 1402, "seek": 411336, "start": 4128.96, "end": 4132.0, "text": " and I take your point that there's a kind of divergence", "tokens": [51144, 293, 286, 747, 428, 935, 300, 456, 311, 257, 733, 295, 47387, 51296], "temperature": 0.0, "avg_logprob": -0.127584248563669, "compression_ratio": 1.6936026936026936, "no_speech_prob": 0.001566638587974012}, {"id": 1403, "seek": 411336, "start": 4132.0, "end": 4132.96, "text": " between the world we live in", "tokens": [51296, 1296, 264, 1002, 321, 1621, 294, 51344], "temperature": 0.0, "avg_logprob": -0.127584248563669, "compression_ratio": 1.6936026936026936, "no_speech_prob": 0.001566638587974012}, {"id": 1404, "seek": 411336, "start": 4132.96, "end": 4134.48, "text": " and the programming that we've got.", "tokens": [51344, 293, 264, 9410, 300, 321, 600, 658, 13, 51420], "temperature": 0.0, "avg_logprob": -0.127584248563669, "compression_ratio": 1.6936026936026936, "no_speech_prob": 0.001566638587974012}, {"id": 1405, "seek": 411336, "start": 4134.48, "end": 4138.24, "text": " But then, okay, let's imagine that we create a new population", "tokens": [51420, 583, 550, 11, 1392, 11, 718, 311, 3811, 300, 321, 1884, 257, 777, 4415, 51608], "temperature": 0.0, "avg_logprob": -0.127584248563669, "compression_ratio": 1.6936026936026936, "no_speech_prob": 0.001566638587974012}, {"id": 1406, "seek": 411336, "start": 4138.24, "end": 4140.96, "text": " and I guess what I'm saying is that", "tokens": [51608, 293, 286, 2041, 437, 286, 478, 1566, 307, 300, 51744], "temperature": 0.0, "avg_logprob": -0.127584248563669, "compression_ratio": 1.6936026936026936, "no_speech_prob": 0.001566638587974012}, {"id": 1407, "seek": 414096, "start": 4141.04, "end": 4144.8, "text": " you think that the utility function should emerge and evolve,", "tokens": [50368, 291, 519, 300, 264, 14877, 2445, 820, 21511, 293, 16693, 11, 50556], "temperature": 0.0, "avg_logprob": -0.10155528366186056, "compression_ratio": 1.763975155279503, "no_speech_prob": 0.007209434174001217}, {"id": 1408, "seek": 414096, "start": 4144.8, "end": 4148.56, "text": " but I would argue for some kind of morphogenetic engineering", "tokens": [50556, 457, 286, 576, 9695, 337, 512, 733, 295, 25778, 8799, 3532, 7043, 50744], "temperature": 0.0, "avg_logprob": -0.10155528366186056, "compression_ratio": 1.763975155279503, "no_speech_prob": 0.007209434174001217}, {"id": 1409, "seek": 414096, "start": 4148.56, "end": 4151.28, "text": " where it's a kind of hybrid between something which is emergent", "tokens": [50744, 689, 309, 311, 257, 733, 295, 13051, 1296, 746, 597, 307, 4345, 6930, 50880], "temperature": 0.0, "avg_logprob": -0.10155528366186056, "compression_ratio": 1.763975155279503, "no_speech_prob": 0.007209434174001217}, {"id": 1410, "seek": 414096, "start": 4151.28, "end": 4153.12, "text": " but something which we can nudge.", "tokens": [50880, 457, 746, 597, 321, 393, 297, 16032, 13, 50972], "temperature": 0.0, "avg_logprob": -0.10155528366186056, "compression_ratio": 1.763975155279503, "no_speech_prob": 0.007209434174001217}, {"id": 1411, "seek": 414096, "start": 4153.12, "end": 4155.92, "text": " Oh, I mean, I'm glad you brought that up.", "tokens": [50972, 876, 11, 286, 914, 11, 286, 478, 5404, 291, 3038, 300, 493, 13, 51112], "temperature": 0.0, "avg_logprob": -0.10155528366186056, "compression_ratio": 1.763975155279503, "no_speech_prob": 0.007209434174001217}, {"id": 1412, "seek": 414096, "start": 4156.8, "end": 4158.4, "text": " Nudging is a form of emergence.", "tokens": [51156, 426, 532, 3249, 307, 257, 1254, 295, 36211, 13, 51236], "temperature": 0.0, "avg_logprob": -0.10155528366186056, "compression_ratio": 1.763975155279503, "no_speech_prob": 0.007209434174001217}, {"id": 1413, "seek": 414096, "start": 4159.12, "end": 4160.4, "text": " You yourself are emergent", "tokens": [51272, 509, 1803, 366, 4345, 6930, 51336], "temperature": 0.0, "avg_logprob": -0.10155528366186056, "compression_ratio": 1.763975155279503, "no_speech_prob": 0.007209434174001217}, {"id": 1414, "seek": 414096, "start": 4160.4, "end": 4162.16, "text": " and the things that you do are emergent as well.", "tokens": [51336, 293, 264, 721, 300, 291, 360, 366, 4345, 6930, 382, 731, 13, 51424], "temperature": 0.0, "avg_logprob": -0.10155528366186056, "compression_ratio": 1.763975155279503, "no_speech_prob": 0.007209434174001217}, {"id": 1415, "seek": 414096, "start": 4162.16, "end": 4163.52, "text": " Everything is emergent, right?", "tokens": [51424, 5471, 307, 4345, 6930, 11, 558, 30, 51492], "temperature": 0.0, "avg_logprob": -0.10155528366186056, "compression_ratio": 1.763975155279503, "no_speech_prob": 0.007209434174001217}, {"id": 1416, "seek": 414096, "start": 4163.52, "end": 4165.04, "text": " Utilities are emergent.", "tokens": [51492, 12555, 3064, 366, 4345, 6930, 13, 51568], "temperature": 0.0, "avg_logprob": -0.10155528366186056, "compression_ratio": 1.763975155279503, "no_speech_prob": 0.007209434174001217}, {"id": 1417, "seek": 414096, "start": 4165.04, "end": 4166.8, "text": " Maybe the laws of physics aren't emergent.", "tokens": [51568, 2704, 264, 6064, 295, 10649, 3212, 380, 4345, 6930, 13, 51656], "temperature": 0.0, "avg_logprob": -0.10155528366186056, "compression_ratio": 1.763975155279503, "no_speech_prob": 0.007209434174001217}, {"id": 1418, "seek": 414096, "start": 4166.8, "end": 4168.32, "text": " Some people will say even those are, right?", "tokens": [51656, 2188, 561, 486, 584, 754, 729, 366, 11, 558, 30, 51732], "temperature": 0.0, "avg_logprob": -0.10155528366186056, "compression_ratio": 1.763975155279503, "no_speech_prob": 0.007209434174001217}, {"id": 1419, "seek": 414096, "start": 4168.32, "end": 4170.64, "text": " Like, you know, we live in a universe with this constant", "tokens": [51732, 1743, 11, 291, 458, 11, 321, 1621, 294, 257, 6445, 365, 341, 5754, 51848], "temperature": 0.0, "avg_logprob": -0.10155528366186056, "compression_ratio": 1.763975155279503, "no_speech_prob": 0.007209434174001217}, {"id": 1420, "seek": 417064, "start": 4170.72, "end": 4171.76, "text": " because blah, blah, blah, right?", "tokens": [50368, 570, 12288, 11, 12288, 11, 12288, 11, 558, 30, 50420], "temperature": 0.0, "avg_logprob": -0.11758282979329428, "compression_ratio": 1.8664495114006514, "no_speech_prob": 0.00571384746581316}, {"id": 1421, "seek": 417064, "start": 4171.76, "end": 4173.84, "text": " So, but to first approximation,", "tokens": [50420, 407, 11, 457, 281, 700, 28023, 11, 50524], "temperature": 0.0, "avg_logprob": -0.11758282979329428, "compression_ratio": 1.8664495114006514, "no_speech_prob": 0.00571384746581316}, {"id": 1422, "seek": 417064, "start": 4173.84, "end": 4176.64, "text": " every single thing that we've been talking about is emergent.", "tokens": [50524, 633, 2167, 551, 300, 321, 600, 668, 1417, 466, 307, 4345, 6930, 13, 50664], "temperature": 0.0, "avg_logprob": -0.11758282979329428, "compression_ratio": 1.8664495114006514, "no_speech_prob": 0.00571384746581316}, {"id": 1423, "seek": 417064, "start": 4176.64, "end": 4180.400000000001, "text": " We make a distinction between emergent and designed", "tokens": [50664, 492, 652, 257, 16844, 1296, 4345, 6930, 293, 4761, 50852], "temperature": 0.0, "avg_logprob": -0.11758282979329428, "compression_ratio": 1.8664495114006514, "no_speech_prob": 0.00571384746581316}, {"id": 1424, "seek": 417064, "start": 4180.400000000001, "end": 4182.72, "text": " because that is anthropomorphic, right?", "tokens": [50852, 570, 300, 307, 22727, 32702, 299, 11, 558, 30, 50968], "temperature": 0.0, "avg_logprob": -0.11758282979329428, "compression_ratio": 1.8664495114006514, "no_speech_prob": 0.00571384746581316}, {"id": 1425, "seek": 417064, "start": 4182.72, "end": 4184.88, "text": " Is this things that we do are not emergent?", "tokens": [50968, 1119, 341, 721, 300, 321, 360, 366, 406, 4345, 6930, 30, 51076], "temperature": 0.0, "avg_logprob": -0.11758282979329428, "compression_ratio": 1.8664495114006514, "no_speech_prob": 0.00571384746581316}, {"id": 1426, "seek": 417064, "start": 4184.88, "end": 4186.4800000000005, "text": " Actually, no, when you nudge something", "tokens": [51076, 5135, 11, 572, 11, 562, 291, 297, 16032, 746, 51156], "temperature": 0.0, "avg_logprob": -0.11758282979329428, "compression_ratio": 1.8664495114006514, "no_speech_prob": 0.00571384746581316}, {"id": 1427, "seek": 417064, "start": 4186.4800000000005, "end": 4188.160000000001, "text": " that is an emergent behavior, right?", "tokens": [51156, 300, 307, 364, 4345, 6930, 5223, 11, 558, 30, 51240], "temperature": 0.0, "avg_logprob": -0.11758282979329428, "compression_ratio": 1.8664495114006514, "no_speech_prob": 0.00571384746581316}, {"id": 1428, "seek": 417064, "start": 4188.160000000001, "end": 4189.92, "text": " We are emergent as well, right?", "tokens": [51240, 492, 366, 4345, 6930, 382, 731, 11, 558, 30, 51328], "temperature": 0.0, "avg_logprob": -0.11758282979329428, "compression_ratio": 1.8664495114006514, "no_speech_prob": 0.00571384746581316}, {"id": 1429, "seek": 417064, "start": 4189.92, "end": 4191.52, "text": " So everything that is human, you know,", "tokens": [51328, 407, 1203, 300, 307, 1952, 11, 291, 458, 11, 51408], "temperature": 0.0, "avg_logprob": -0.11758282979329428, "compression_ratio": 1.8664495114006514, "no_speech_prob": 0.00571384746581316}, {"id": 1430, "seek": 417064, "start": 4191.52, "end": 4193.84, "text": " so here's a very good way, I think,", "tokens": [51408, 370, 510, 311, 257, 588, 665, 636, 11, 286, 519, 11, 51524], "temperature": 0.0, "avg_logprob": -0.11758282979329428, "compression_ratio": 1.8664495114006514, "no_speech_prob": 0.00571384746581316}, {"id": 1431, "seek": 417064, "start": 4193.84, "end": 4194.96, "text": " to think about a lot of things", "tokens": [51524, 281, 519, 466, 257, 688, 295, 721, 51580], "temperature": 0.0, "avg_logprob": -0.11758282979329428, "compression_ratio": 1.8664495114006514, "no_speech_prob": 0.00571384746581316}, {"id": 1432, "seek": 417064, "start": 4194.96, "end": 4197.360000000001, "text": " which I first saw, you know, in Richard Dawkins,", "tokens": [51580, 597, 286, 700, 1866, 11, 291, 458, 11, 294, 9809, 28407, 10277, 11, 51700], "temperature": 0.0, "avg_logprob": -0.11758282979329428, "compression_ratio": 1.8664495114006514, "no_speech_prob": 0.00571384746581316}, {"id": 1433, "seek": 417064, "start": 4197.360000000001, "end": 4199.6, "text": " which is although he really didn't go into this", "tokens": [51700, 597, 307, 4878, 415, 534, 994, 380, 352, 666, 341, 51812], "temperature": 0.0, "avg_logprob": -0.11758282979329428, "compression_ratio": 1.8664495114006514, "no_speech_prob": 0.00571384746581316}, {"id": 1434, "seek": 419960, "start": 4199.6, "end": 4201.360000000001, "text": " and I wish he had like this notion", "tokens": [50364, 293, 286, 3172, 415, 632, 411, 341, 10710, 50452], "temperature": 0.0, "avg_logprob": -0.11520110385518678, "compression_ratio": 1.8872727272727272, "no_speech_prob": 0.005284263286739588}, {"id": 1435, "seek": 419960, "start": 4201.360000000001, "end": 4203.4400000000005, "text": " of the extended phenotype, right?", "tokens": [50452, 295, 264, 10913, 7279, 13108, 11, 558, 30, 50556], "temperature": 0.0, "avg_logprob": -0.11520110385518678, "compression_ratio": 1.8872727272727272, "no_speech_prob": 0.005284263286739588}, {"id": 1436, "seek": 419960, "start": 4204.08, "end": 4206.96, "text": " Technology is our extended phenotype.", "tokens": [50588, 15037, 307, 527, 10913, 7279, 13108, 13, 50732], "temperature": 0.0, "avg_logprob": -0.11520110385518678, "compression_ratio": 1.8872727272727272, "no_speech_prob": 0.005284263286739588}, {"id": 1437, "seek": 419960, "start": 4206.96, "end": 4208.8, "text": " So all these things that we do, right?", "tokens": [50732, 407, 439, 613, 721, 300, 321, 360, 11, 558, 30, 50824], "temperature": 0.0, "avg_logprob": -0.11520110385518678, "compression_ratio": 1.8872727272727272, "no_speech_prob": 0.005284263286739588}, {"id": 1438, "seek": 419960, "start": 4208.8, "end": 4209.84, "text": " All these things that we build,", "tokens": [50824, 1057, 613, 721, 300, 321, 1322, 11, 50876], "temperature": 0.0, "avg_logprob": -0.11520110385518678, "compression_ratio": 1.8872727272727272, "no_speech_prob": 0.005284263286739588}, {"id": 1439, "seek": 419960, "start": 4209.84, "end": 4211.200000000001, "text": " including AS and whatnot,", "tokens": [50876, 3009, 7469, 293, 25882, 11, 50944], "temperature": 0.0, "avg_logprob": -0.11520110385518678, "compression_ratio": 1.8872727272727272, "no_speech_prob": 0.005284263286739588}, {"id": 1440, "seek": 419960, "start": 4211.200000000001, "end": 4213.4400000000005, "text": " they are extensions of our phenotype.", "tokens": [50944, 436, 366, 25129, 295, 527, 7279, 13108, 13, 51056], "temperature": 0.0, "avg_logprob": -0.11520110385518678, "compression_ratio": 1.8872727272727272, "no_speech_prob": 0.005284263286739588}, {"id": 1441, "seek": 419960, "start": 4213.4400000000005, "end": 4215.84, "text": " So if you take the long view, all of, you know,", "tokens": [51056, 407, 498, 291, 747, 264, 938, 1910, 11, 439, 295, 11, 291, 458, 11, 51176], "temperature": 0.0, "avg_logprob": -0.11520110385518678, "compression_ratio": 1.8872727272727272, "no_speech_prob": 0.005284263286739588}, {"id": 1442, "seek": 419960, "start": 4215.84, "end": 4219.360000000001, "text": " technology is the continuation of biology by another means.", "tokens": [51176, 2899, 307, 264, 29357, 295, 14956, 538, 1071, 1355, 13, 51352], "temperature": 0.0, "avg_logprob": -0.11520110385518678, "compression_ratio": 1.8872727272727272, "no_speech_prob": 0.005284263286739588}, {"id": 1443, "seek": 419960, "start": 4219.92, "end": 4221.120000000001, "text": " So when you make this distinction", "tokens": [51380, 407, 562, 291, 652, 341, 16844, 51440], "temperature": 0.0, "avg_logprob": -0.11520110385518678, "compression_ratio": 1.8872727272727272, "no_speech_prob": 0.005284263286739588}, {"id": 1444, "seek": 419960, "start": 4221.120000000001, "end": 4222.64, "text": " between emergent and not emergent", "tokens": [51440, 1296, 4345, 6930, 293, 406, 4345, 6930, 51516], "temperature": 0.0, "avg_logprob": -0.11520110385518678, "compression_ratio": 1.8872727272727272, "no_speech_prob": 0.005284263286739588}, {"id": 1445, "seek": 419960, "start": 4222.64, "end": 4225.200000000001, "text": " and top down and bottom up, it's all emergent.", "tokens": [51516, 293, 1192, 760, 293, 2767, 493, 11, 309, 311, 439, 4345, 6930, 13, 51644], "temperature": 0.0, "avg_logprob": -0.11520110385518678, "compression_ratio": 1.8872727272727272, "no_speech_prob": 0.005284263286739588}, {"id": 1446, "seek": 419960, "start": 4225.200000000001, "end": 4227.6, "text": " Interesting. Well, we recently did a show on emergence", "tokens": [51644, 14711, 13, 1042, 11, 321, 3938, 630, 257, 855, 322, 36211, 51764], "temperature": 0.0, "avg_logprob": -0.11520110385518678, "compression_ratio": 1.8872727272727272, "no_speech_prob": 0.005284263286739588}, {"id": 1447, "seek": 422760, "start": 4227.6, "end": 4229.84, "text": " and it's a topic of interest to me personally", "tokens": [50364, 293, 309, 311, 257, 4829, 295, 1179, 281, 385, 5665, 50476], "temperature": 0.0, "avg_logprob": -0.1163443895726422, "compression_ratio": 1.904153354632588, "no_speech_prob": 0.01889183558523655}, {"id": 1448, "seek": 422760, "start": 4229.84, "end": 4232.400000000001, "text": " and there's weak emergence and strong emergence", "tokens": [50476, 293, 456, 311, 5336, 36211, 293, 2068, 36211, 50604], "temperature": 0.0, "avg_logprob": -0.1163443895726422, "compression_ratio": 1.904153354632588, "no_speech_prob": 0.01889183558523655}, {"id": 1449, "seek": 422760, "start": 4232.400000000001, "end": 4234.240000000001, "text": " and there's, you know, like the view of weak emergence,", "tokens": [50604, 293, 456, 311, 11, 291, 458, 11, 411, 264, 1910, 295, 5336, 36211, 11, 50696], "temperature": 0.0, "avg_logprob": -0.1163443895726422, "compression_ratio": 1.904153354632588, "no_speech_prob": 0.01889183558523655}, {"id": 1450, "seek": 422760, "start": 4234.240000000001, "end": 4237.360000000001, "text": " so there's some, you know, surprising macroscopic phenomena,", "tokens": [50696, 370, 456, 311, 512, 11, 291, 458, 11, 8830, 7912, 38006, 299, 22004, 11, 50852], "temperature": 0.0, "avg_logprob": -0.1163443895726422, "compression_ratio": 1.904153354632588, "no_speech_prob": 0.01889183558523655}, {"id": 1451, "seek": 422760, "start": 4237.360000000001, "end": 4239.200000000001, "text": " maybe something which transiently emerges", "tokens": [50852, 1310, 746, 597, 41998, 356, 38965, 50944], "temperature": 0.0, "avg_logprob": -0.1163443895726422, "compression_ratio": 1.904153354632588, "no_speech_prob": 0.01889183558523655}, {"id": 1452, "seek": 422760, "start": 4239.200000000001, "end": 4241.200000000001, "text": " and Wolfram would add in the whole, you know,", "tokens": [50944, 293, 16634, 2356, 576, 909, 294, 264, 1379, 11, 291, 458, 11, 51044], "temperature": 0.0, "avg_logprob": -0.1163443895726422, "compression_ratio": 1.904153354632588, "no_speech_prob": 0.01889183558523655}, {"id": 1453, "seek": 422760, "start": 4241.200000000001, "end": 4243.200000000001, "text": " computational irreducibility angle.", "tokens": [51044, 28270, 16014, 769, 537, 39802, 5802, 13, 51144], "temperature": 0.0, "avg_logprob": -0.1163443895726422, "compression_ratio": 1.904153354632588, "no_speech_prob": 0.01889183558523655}, {"id": 1454, "seek": 422760, "start": 4243.200000000001, "end": 4244.56, "text": " And then with the strong emergence,", "tokens": [51144, 400, 550, 365, 264, 2068, 36211, 11, 51212], "temperature": 0.0, "avg_logprob": -0.1163443895726422, "compression_ratio": 1.904153354632588, "no_speech_prob": 0.01889183558523655}, {"id": 1455, "seek": 422760, "start": 4244.56, "end": 4245.84, "text": " Chalmers would say it's something", "tokens": [51212, 761, 304, 18552, 576, 584, 309, 311, 746, 51276], "temperature": 0.0, "avg_logprob": -0.1163443895726422, "compression_ratio": 1.904153354632588, "no_speech_prob": 0.01889183558523655}, {"id": 1456, "seek": 422760, "start": 4245.84, "end": 4247.6, "text": " which is paradigmatically surprising.", "tokens": [51276, 597, 307, 24709, 5030, 8830, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1163443895726422, "compression_ratio": 1.904153354632588, "no_speech_prob": 0.01889183558523655}, {"id": 1457, "seek": 422760, "start": 4247.6, "end": 4249.360000000001, "text": " It's something which is not deducible", "tokens": [51364, 467, 311, 746, 597, 307, 406, 4172, 84, 32128, 51452], "temperature": 0.0, "avg_logprob": -0.1163443895726422, "compression_ratio": 1.904153354632588, "no_speech_prob": 0.01889183558523655}, {"id": 1458, "seek": 422760, "start": 4249.360000000001, "end": 4251.4400000000005, "text": " for many fundamental truths in the lower level domain.", "tokens": [51452, 337, 867, 8088, 30079, 294, 264, 3126, 1496, 9274, 13, 51556], "temperature": 0.0, "avg_logprob": -0.1163443895726422, "compression_ratio": 1.904153354632588, "no_speech_prob": 0.01889183558523655}, {"id": 1459, "seek": 422760, "start": 4251.4400000000005, "end": 4254.72, "text": " But I just wondered, like, how do you think about emergence?", "tokens": [51556, 583, 286, 445, 17055, 11, 411, 11, 577, 360, 291, 519, 466, 36211, 30, 51720], "temperature": 0.0, "avg_logprob": -0.1163443895726422, "compression_ratio": 1.904153354632588, "no_speech_prob": 0.01889183558523655}, {"id": 1460, "seek": 425472, "start": 4254.72, "end": 4256.88, "text": " Well, I think that is a very, the distinction", "tokens": [50364, 1042, 11, 286, 519, 300, 307, 257, 588, 11, 264, 16844, 50472], "temperature": 0.0, "avg_logprob": -0.14467880643647293, "compression_ratio": 1.6728624535315986, "no_speech_prob": 0.002541568363085389}, {"id": 1461, "seek": 425472, "start": 4256.88, "end": 4259.52, "text": " between weak and strong immersion is a very useful one.", "tokens": [50472, 1296, 5336, 293, 2068, 40348, 307, 257, 588, 4420, 472, 13, 50604], "temperature": 0.0, "avg_logprob": -0.14467880643647293, "compression_ratio": 1.6728624535315986, "no_speech_prob": 0.002541568363085389}, {"id": 1462, "seek": 425472, "start": 4259.52, "end": 4260.320000000001, "text": " Right.", "tokens": [50604, 1779, 13, 50644], "temperature": 0.0, "avg_logprob": -0.14467880643647293, "compression_ratio": 1.6728624535315986, "no_speech_prob": 0.002541568363085389}, {"id": 1463, "seek": 425472, "start": 4260.320000000001, "end": 4263.84, "text": " And I would actually phrase it in slightly different terms,", "tokens": [50644, 400, 286, 576, 767, 9535, 309, 294, 4748, 819, 2115, 11, 50820], "temperature": 0.0, "avg_logprob": -0.14467880643647293, "compression_ratio": 1.6728624535315986, "no_speech_prob": 0.002541568363085389}, {"id": 1464, "seek": 425472, "start": 4263.84, "end": 4266.320000000001, "text": " which is starting from physics, right?", "tokens": [50820, 597, 307, 2891, 490, 10649, 11, 558, 30, 50944], "temperature": 0.0, "avg_logprob": -0.14467880643647293, "compression_ratio": 1.6728624535315986, "no_speech_prob": 0.002541568363085389}, {"id": 1465, "seek": 425472, "start": 4267.280000000001, "end": 4274.0, "text": " I think most physicists and scientists believe in weak emergence.", "tokens": [50992, 286, 519, 881, 48716, 293, 7708, 1697, 294, 5336, 36211, 13, 51328], "temperature": 0.0, "avg_logprob": -0.14467880643647293, "compression_ratio": 1.6728624535315986, "no_speech_prob": 0.002541568363085389}, {"id": 1466, "seek": 425472, "start": 4274.0, "end": 4276.16, "text": " Well, could I, could I add that Sabine Hossenfelder", "tokens": [51328, 1042, 11, 727, 286, 11, 727, 286, 909, 300, 13915, 533, 389, 22573, 29874, 1068, 51436], "temperature": 0.0, "avg_logprob": -0.14467880643647293, "compression_ratio": 1.6728624535315986, "no_speech_prob": 0.002541568363085389}, {"id": 1467, "seek": 425472, "start": 4276.16, "end": 4278.88, "text": " had a paper and she frames it with this idea", "tokens": [51436, 632, 257, 3035, 293, 750, 12083, 309, 365, 341, 1558, 51572], "temperature": 0.0, "avg_logprob": -0.14467880643647293, "compression_ratio": 1.6728624535315986, "no_speech_prob": 0.002541568363085389}, {"id": 1468, "seek": 425472, "start": 4278.88, "end": 4281.4400000000005, "text": " of the resolution of physical theories.", "tokens": [51572, 295, 264, 8669, 295, 4001, 13667, 13, 51700], "temperature": 0.0, "avg_logprob": -0.14467880643647293, "compression_ratio": 1.6728624535315986, "no_speech_prob": 0.002541568363085389}, {"id": 1469, "seek": 425472, "start": 4281.4400000000005, "end": 4283.360000000001, "text": " So like, like a lower resolution theory", "tokens": [51700, 407, 411, 11, 411, 257, 3126, 8669, 5261, 51796], "temperature": 0.0, "avg_logprob": -0.14467880643647293, "compression_ratio": 1.6728624535315986, "no_speech_prob": 0.002541568363085389}, {"id": 1470, "seek": 428336, "start": 4283.36, "end": 4285.759999999999, "text": " as weakly emergent from a high resolution theory.", "tokens": [50364, 382, 5336, 356, 4345, 6930, 490, 257, 1090, 8669, 5261, 13, 50484], "temperature": 0.0, "avg_logprob": -0.12094352411669354, "compression_ratio": 1.8296529968454258, "no_speech_prob": 0.004810551647096872}, {"id": 1471, "seek": 428336, "start": 4285.759999999999, "end": 4286.4, "text": " Well, exactly.", "tokens": [50484, 1042, 11, 2293, 13, 50516], "temperature": 0.0, "avg_logprob": -0.12094352411669354, "compression_ratio": 1.8296529968454258, "no_speech_prob": 0.004810551647096872}, {"id": 1472, "seek": 428336, "start": 4286.4, "end": 4288.0, "text": " And, you know, like, I like Sabine,", "tokens": [50516, 400, 11, 291, 458, 11, 411, 11, 286, 411, 13915, 533, 11, 50596], "temperature": 0.0, "avg_logprob": -0.12094352411669354, "compression_ratio": 1.8296529968454258, "no_speech_prob": 0.004810551647096872}, {"id": 1473, "seek": 428336, "start": 4288.0, "end": 4289.679999999999, "text": " but this is not her idea, right?", "tokens": [50596, 457, 341, 307, 406, 720, 1558, 11, 558, 30, 50680], "temperature": 0.0, "avg_logprob": -0.12094352411669354, "compression_ratio": 1.8296529968454258, "no_speech_prob": 0.004810551647096872}, {"id": 1474, "seek": 428336, "start": 4289.679999999999, "end": 4291.759999999999, "text": " This far predates all of us here, right?", "tokens": [50680, 639, 1400, 3852, 1024, 439, 295, 505, 510, 11, 558, 30, 50784], "temperature": 0.0, "avg_logprob": -0.12094352411669354, "compression_ratio": 1.8296529968454258, "no_speech_prob": 0.004810551647096872}, {"id": 1475, "seek": 428336, "start": 4291.759999999999, "end": 4292.32, "text": " Yeah.", "tokens": [50784, 865, 13, 50812], "temperature": 0.0, "avg_logprob": -0.12094352411669354, "compression_ratio": 1.8296529968454258, "no_speech_prob": 0.004810551647096872}, {"id": 1476, "seek": 428336, "start": 4292.32, "end": 4294.5599999999995, "text": " And again, it's, it's a very interesting history", "tokens": [50812, 400, 797, 11, 309, 311, 11, 309, 311, 257, 588, 1880, 2503, 50924], "temperature": 0.0, "avg_logprob": -0.12094352411669354, "compression_ratio": 1.8296529968454258, "no_speech_prob": 0.004810551647096872}, {"id": 1477, "seek": 428336, "start": 4294.5599999999995, "end": 4296.0, "text": " and a very important concept.", "tokens": [50924, 293, 257, 588, 1021, 3410, 13, 50996], "temperature": 0.0, "avg_logprob": -0.12094352411669354, "compression_ratio": 1.8296529968454258, "no_speech_prob": 0.004810551647096872}, {"id": 1478, "seek": 428336, "start": 4296.0, "end": 4300.96, "text": " Now, so my point was that I think few people have a quarrel", "tokens": [50996, 823, 11, 370, 452, 935, 390, 300, 286, 519, 1326, 561, 362, 257, 4723, 4419, 51244], "temperature": 0.0, "avg_logprob": -0.12094352411669354, "compression_ratio": 1.8296529968454258, "no_speech_prob": 0.004810551647096872}, {"id": 1479, "seek": 428336, "start": 4300.96, "end": 4302.4, "text": " with the notion of weak emergence", "tokens": [51244, 365, 264, 10710, 295, 5336, 36211, 51316], "temperature": 0.0, "avg_logprob": -0.12094352411669354, "compression_ratio": 1.8296529968454258, "no_speech_prob": 0.004810551647096872}, {"id": 1480, "seek": 428336, "start": 4302.4, "end": 4303.92, "text": " in the sense that, you know,", "tokens": [51316, 294, 264, 2020, 300, 11, 291, 458, 11, 51392], "temperature": 0.0, "avg_logprob": -0.12094352411669354, "compression_ratio": 1.8296529968454258, "no_speech_prob": 0.004810551647096872}, {"id": 1481, "seek": 428336, "start": 4303.92, "end": 4305.36, "text": " I can give you a theory of everything", "tokens": [51392, 286, 393, 976, 291, 257, 5261, 295, 1203, 51464], "temperature": 0.0, "avg_logprob": -0.12094352411669354, "compression_ratio": 1.8296529968454258, "no_speech_prob": 0.004810551647096872}, {"id": 1482, "seek": 428336, "start": 4305.36, "end": 4307.04, "text": " in the form of whatever string theory", "tokens": [51464, 294, 264, 1254, 295, 2035, 6798, 5261, 51548], "temperature": 0.0, "avg_logprob": -0.12094352411669354, "compression_ratio": 1.8296529968454258, "no_speech_prob": 0.004810551647096872}, {"id": 1483, "seek": 428336, "start": 4307.04, "end": 4308.639999999999, "text": " let's take a candidate, right?", "tokens": [51548, 718, 311, 747, 257, 11532, 11, 558, 30, 51628], "temperature": 0.0, "avg_logprob": -0.12094352411669354, "compression_ratio": 1.8296529968454258, "no_speech_prob": 0.004810551647096872}, {"id": 1484, "seek": 428336, "start": 4308.639999999999, "end": 4310.88, "text": " But no string theory claims that that's a theory", "tokens": [51628, 583, 572, 6798, 5261, 9441, 300, 300, 311, 257, 5261, 51740], "temperature": 0.0, "avg_logprob": -0.12094352411669354, "compression_ratio": 1.8296529968454258, "no_speech_prob": 0.004810551647096872}, {"id": 1485, "seek": 428336, "start": 4310.88, "end": 4312.799999999999, "text": " of everything in the sense that like now,", "tokens": [51740, 295, 1203, 294, 264, 2020, 300, 411, 586, 11, 51836], "temperature": 0.0, "avg_logprob": -0.12094352411669354, "compression_ratio": 1.8296529968454258, "no_speech_prob": 0.004810551647096872}, {"id": 1486, "seek": 431280, "start": 4312.8, "end": 4314.96, "text": " to study biology or psychology or sociology,", "tokens": [50364, 281, 2979, 14956, 420, 15105, 420, 41744, 11, 50472], "temperature": 0.0, "avg_logprob": -0.11575888332567717, "compression_ratio": 1.8929765886287626, "no_speech_prob": 0.0034173675812780857}, {"id": 1487, "seek": 431280, "start": 4314.96, "end": 4316.08, "text": " you should just study string theory.", "tokens": [50472, 291, 820, 445, 2979, 6798, 5261, 13, 50528], "temperature": 0.0, "avg_logprob": -0.11575888332567717, "compression_ratio": 1.8929765886287626, "no_speech_prob": 0.0034173675812780857}, {"id": 1488, "seek": 431280, "start": 4316.08, "end": 4317.6, "text": " No one believes that, right?", "tokens": [50528, 883, 472, 12307, 300, 11, 558, 30, 50604], "temperature": 0.0, "avg_logprob": -0.11575888332567717, "compression_ratio": 1.8929765886287626, "no_speech_prob": 0.0034173675812780857}, {"id": 1489, "seek": 431280, "start": 4317.6, "end": 4319.4400000000005, "text": " There's actually interesting things to be said there,", "tokens": [50604, 821, 311, 767, 1880, 721, 281, 312, 848, 456, 11, 50696], "temperature": 0.0, "avg_logprob": -0.11575888332567717, "compression_ratio": 1.8929765886287626, "no_speech_prob": 0.0034173675812780857}, {"id": 1490, "seek": 431280, "start": 4319.4400000000005, "end": 4321.12, "text": " but, but let's not, let's look at,", "tokens": [50696, 457, 11, 457, 718, 311, 406, 11, 718, 311, 574, 412, 11, 50780], "temperature": 0.0, "avg_logprob": -0.11575888332567717, "compression_ratio": 1.8929765886287626, "no_speech_prob": 0.0034173675812780857}, {"id": 1491, "seek": 431280, "start": 4321.12, "end": 4322.88, "text": " let's not go there for a second, right?", "tokens": [50780, 718, 311, 406, 352, 456, 337, 257, 1150, 11, 558, 30, 50868], "temperature": 0.0, "avg_logprob": -0.11575888332567717, "compression_ratio": 1.8929765886287626, "no_speech_prob": 0.0034173675812780857}, {"id": 1492, "seek": 431280, "start": 4322.88, "end": 4326.56, "text": " There are these levels that emerge weakly", "tokens": [50868, 821, 366, 613, 4358, 300, 21511, 5336, 356, 51052], "temperature": 0.0, "avg_logprob": -0.11575888332567717, "compression_ratio": 1.8929765886287626, "no_speech_prob": 0.0034173675812780857}, {"id": 1493, "seek": 431280, "start": 4326.56, "end": 4329.76, "text": " in the sense that they are determined by the lower levels.", "tokens": [51052, 294, 264, 2020, 300, 436, 366, 9540, 538, 264, 3126, 4358, 13, 51212], "temperature": 0.0, "avg_logprob": -0.11575888332567717, "compression_ratio": 1.8929765886287626, "no_speech_prob": 0.0034173675812780857}, {"id": 1494, "seek": 431280, "start": 4330.400000000001, "end": 4331.84, "text": " They're just so much more complex", "tokens": [51244, 814, 434, 445, 370, 709, 544, 3997, 51316], "temperature": 0.0, "avg_logprob": -0.11575888332567717, "compression_ratio": 1.8929765886287626, "no_speech_prob": 0.0034173675812780857}, {"id": 1495, "seek": 431280, "start": 4331.84, "end": 4334.0, "text": " that you're better off focusing on the menu.", "tokens": [51316, 300, 291, 434, 1101, 766, 8416, 322, 264, 6510, 13, 51424], "temperature": 0.0, "avg_logprob": -0.11575888332567717, "compression_ratio": 1.8929765886287626, "no_speech_prob": 0.0034173675812780857}, {"id": 1496, "seek": 431280, "start": 4334.0, "end": 4335.52, "text": " Now there's this other notion which to me", "tokens": [51424, 823, 456, 311, 341, 661, 10710, 597, 281, 385, 51500], "temperature": 0.0, "avg_logprob": -0.11575888332567717, "compression_ratio": 1.8929765886287626, "no_speech_prob": 0.0034173675812780857}, {"id": 1497, "seek": 431280, "start": 4335.52, "end": 4337.360000000001, "text": " is the really interesting one,", "tokens": [51500, 307, 264, 534, 1880, 472, 11, 51592], "temperature": 0.0, "avg_logprob": -0.11575888332567717, "compression_ratio": 1.8929765886287626, "no_speech_prob": 0.0034173675812780857}, {"id": 1498, "seek": 431280, "start": 4337.360000000001, "end": 4340.4800000000005, "text": " which is that there is, there are phenomena", "tokens": [51592, 597, 307, 300, 456, 307, 11, 456, 366, 22004, 51748], "temperature": 0.0, "avg_logprob": -0.11575888332567717, "compression_ratio": 1.8929765886287626, "no_speech_prob": 0.0034173675812780857}, {"id": 1499, "seek": 431280, "start": 4340.4800000000005, "end": 4342.0, "text": " that are at the higher levels", "tokens": [51748, 300, 366, 412, 264, 2946, 4358, 51824], "temperature": 0.0, "avg_logprob": -0.11575888332567717, "compression_ratio": 1.8929765886287626, "no_speech_prob": 0.0034173675812780857}, {"id": 1500, "seek": 434200, "start": 4342.0, "end": 4346.16, "text": " that are just not reducible to the lower levels, right?", "tokens": [50364, 300, 366, 445, 406, 2783, 32128, 281, 264, 3126, 4358, 11, 558, 30, 50572], "temperature": 0.0, "avg_logprob": -0.12023887634277344, "compression_ratio": 1.7508896797153024, "no_speech_prob": 0.001752055250108242}, {"id": 1501, "seek": 434200, "start": 4346.16, "end": 4347.84, "text": " So the true emergent is in some sense", "tokens": [50572, 407, 264, 2074, 4345, 6930, 307, 294, 512, 2020, 50656], "temperature": 0.0, "avg_logprob": -0.12023887634277344, "compression_ratio": 1.7508896797153024, "no_speech_prob": 0.001752055250108242}, {"id": 1502, "seek": 434200, "start": 4347.84, "end": 4349.44, "text": " is someone who believes the latter.", "tokens": [50656, 307, 1580, 567, 12307, 264, 18481, 13, 50736], "temperature": 0.0, "avg_logprob": -0.12023887634277344, "compression_ratio": 1.7508896797153024, "no_speech_prob": 0.001752055250108242}, {"id": 1503, "seek": 434200, "start": 4349.44, "end": 4350.64, "text": " And now you can ask the question,", "tokens": [50736, 400, 586, 291, 393, 1029, 264, 1168, 11, 50796], "temperature": 0.0, "avg_logprob": -0.12023887634277344, "compression_ratio": 1.7508896797153024, "no_speech_prob": 0.001752055250108242}, {"id": 1504, "seek": 434200, "start": 4350.64, "end": 4353.04, "text": " like do you believe in that or not, right?", "tokens": [50796, 411, 360, 291, 1697, 294, 300, 420, 406, 11, 558, 30, 50916], "temperature": 0.0, "avg_logprob": -0.12023887634277344, "compression_ratio": 1.7508896797153024, "no_speech_prob": 0.001752055250108242}, {"id": 1505, "seek": 434200, "start": 4353.04, "end": 4357.36, "text": " And I think to give the very short answer first", "tokens": [50916, 400, 286, 519, 281, 976, 264, 588, 2099, 1867, 700, 51132], "temperature": 0.0, "avg_logprob": -0.12023887634277344, "compression_ratio": 1.7508896797153024, "no_speech_prob": 0.001752055250108242}, {"id": 1506, "seek": 434200, "start": 4357.36, "end": 4359.92, "text": " is that ultimately there's probably no way of knowing.", "tokens": [51132, 307, 300, 6284, 456, 311, 1391, 572, 636, 295, 5276, 13, 51260], "temperature": 0.0, "avg_logprob": -0.12023887634277344, "compression_ratio": 1.7508896797153024, "no_speech_prob": 0.001752055250108242}, {"id": 1507, "seek": 434200, "start": 4361.12, "end": 4364.96, "text": " But pragmatically, you're actually probably better off", "tokens": [51320, 583, 33394, 76, 5030, 11, 291, 434, 767, 1391, 1101, 766, 51512], "temperature": 0.0, "avg_logprob": -0.12023887634277344, "compression_ratio": 1.7508896797153024, "no_speech_prob": 0.001752055250108242}, {"id": 1508, "seek": 434200, "start": 4364.96, "end": 4367.6, "text": " treating the world as if it has strong emergence.", "tokens": [51512, 15083, 264, 1002, 382, 498, 309, 575, 2068, 36211, 13, 51644], "temperature": 0.0, "avg_logprob": -0.12023887634277344, "compression_ratio": 1.7508896797153024, "no_speech_prob": 0.001752055250108242}, {"id": 1509, "seek": 434200, "start": 4367.6, "end": 4369.28, "text": " And now strong emergence is actually", "tokens": [51644, 400, 586, 2068, 36211, 307, 767, 51728], "temperature": 0.0, "avg_logprob": -0.12023887634277344, "compression_ratio": 1.7508896797153024, "no_speech_prob": 0.001752055250108242}, {"id": 1510, "seek": 434200, "start": 4369.28, "end": 4370.96, "text": " a very strong segment to make is to say,", "tokens": [51728, 257, 588, 2068, 9469, 281, 652, 307, 281, 584, 11, 51812], "temperature": 0.0, "avg_logprob": -0.12023887634277344, "compression_ratio": 1.7508896797153024, "no_speech_prob": 0.001752055250108242}, {"id": 1511, "seek": 437096, "start": 4370.96, "end": 4373.2, "text": " and by the way, going down to the lowest levels", "tokens": [50364, 293, 538, 264, 636, 11, 516, 760, 281, 264, 12437, 4358, 50476], "temperature": 0.0, "avg_logprob": -0.11298377558870136, "compression_ratio": 1.9260450160771705, "no_speech_prob": 0.009695935063064098}, {"id": 1512, "seek": 437096, "start": 4373.2, "end": 4374.56, "text": " to make things very clear,", "tokens": [50476, 281, 652, 721, 588, 1850, 11, 50544], "temperature": 0.0, "avg_logprob": -0.11298377558870136, "compression_ratio": 1.9260450160771705, "no_speech_prob": 0.009695935063064098}, {"id": 1513, "seek": 437096, "start": 4374.56, "end": 4376.64, "text": " you don't need to think about biology or society", "tokens": [50544, 291, 500, 380, 643, 281, 519, 466, 14956, 420, 4086, 50648], "temperature": 0.0, "avg_logprob": -0.11298377558870136, "compression_ratio": 1.9260450160771705, "no_speech_prob": 0.009695935063064098}, {"id": 1514, "seek": 437096, "start": 4376.64, "end": 4378.4800000000005, "text": " or consciousness or anything.", "tokens": [50648, 420, 10081, 420, 1340, 13, 50740], "temperature": 0.0, "avg_logprob": -0.11298377558870136, "compression_ratio": 1.9260450160771705, "no_speech_prob": 0.009695935063064098}, {"id": 1515, "seek": 437096, "start": 4378.4800000000005, "end": 4380.72, "text": " Condensed metaphysics, right?", "tokens": [50740, 21793, 16332, 30946, 41732, 11, 558, 30, 50852], "temperature": 0.0, "avg_logprob": -0.11298377558870136, "compression_ratio": 1.9260450160771705, "no_speech_prob": 0.009695935063064098}, {"id": 1516, "seek": 437096, "start": 4381.28, "end": 4383.36, "text": " The particle physicists tend to believe", "tokens": [50880, 440, 12359, 48716, 3928, 281, 1697, 50984], "temperature": 0.0, "avg_logprob": -0.11298377558870136, "compression_ratio": 1.9260450160771705, "no_speech_prob": 0.009695935063064098}, {"id": 1517, "seek": 437096, "start": 4383.36, "end": 4386.4, "text": " that what they do is what everything reduces to.", "tokens": [50984, 300, 437, 436, 360, 307, 437, 1203, 18081, 281, 13, 51136], "temperature": 0.0, "avg_logprob": -0.11298377558870136, "compression_ratio": 1.9260450160771705, "no_speech_prob": 0.009695935063064098}, {"id": 1518, "seek": 437096, "start": 4386.4, "end": 4388.8, "text": " You talk to the condensed metaphysicists.", "tokens": [51136, 509, 751, 281, 264, 36398, 30946, 749, 299, 1751, 13, 51256], "temperature": 0.0, "avg_logprob": -0.11298377558870136, "compression_ratio": 1.9260450160771705, "no_speech_prob": 0.009695935063064098}, {"id": 1519, "seek": 437096, "start": 4388.8, "end": 4390.24, "text": " This was actually an interesting discussion", "tokens": [51256, 639, 390, 767, 364, 1880, 5017, 51328], "temperature": 0.0, "avg_logprob": -0.11298377558870136, "compression_ratio": 1.9260450160771705, "no_speech_prob": 0.009695935063064098}, {"id": 1520, "seek": 437096, "start": 4390.24, "end": 4392.0, "text": " that I had with Scott, you know, Aronson,", "tokens": [51328, 300, 286, 632, 365, 6659, 11, 291, 458, 11, 1587, 892, 266, 11, 51416], "temperature": 0.0, "avg_logprob": -0.11298377558870136, "compression_ratio": 1.9260450160771705, "no_speech_prob": 0.009695935063064098}, {"id": 1521, "seek": 437096, "start": 4392.0, "end": 4393.52, "text": " because like he was very much on the,", "tokens": [51416, 570, 411, 415, 390, 588, 709, 322, 264, 11, 51492], "temperature": 0.0, "avg_logprob": -0.11298377558870136, "compression_ratio": 1.9260450160771705, "no_speech_prob": 0.009695935063064098}, {"id": 1522, "seek": 437096, "start": 4393.52, "end": 4395.04, "text": " we're both computer scientists,", "tokens": [51492, 321, 434, 1293, 3820, 7708, 11, 51568], "temperature": 0.0, "avg_logprob": -0.11298377558870136, "compression_ratio": 1.9260450160771705, "no_speech_prob": 0.009695935063064098}, {"id": 1523, "seek": 437096, "start": 4395.04, "end": 4397.12, "text": " but he was very much on the side of the particle physicists,", "tokens": [51568, 457, 415, 390, 588, 709, 322, 264, 1252, 295, 264, 12359, 48716, 11, 51672], "temperature": 0.0, "avg_logprob": -0.11298377558870136, "compression_ratio": 1.9260450160771705, "no_speech_prob": 0.009695935063064098}, {"id": 1524, "seek": 437096, "start": 4397.12, "end": 4400.08, "text": " I don't know very much on the side of the condensed metaphysicists.", "tokens": [51672, 286, 500, 380, 458, 588, 709, 322, 264, 1252, 295, 264, 36398, 30946, 749, 299, 1751, 13, 51820], "temperature": 0.0, "avg_logprob": -0.11298377558870136, "compression_ratio": 1.9260450160771705, "no_speech_prob": 0.009695935063064098}, {"id": 1525, "seek": 440008, "start": 4400.08, "end": 4402.5599999999995, "text": " What they will tell you over and over again,", "tokens": [50364, 708, 436, 486, 980, 291, 670, 293, 670, 797, 11, 50488], "temperature": 0.0, "avg_logprob": -0.09189964377361795, "compression_ratio": 1.8338983050847457, "no_speech_prob": 0.005048722494393587}, {"id": 1526, "seek": 440008, "start": 4402.5599999999995, "end": 4406.08, "text": " they see is things that you cannot explain", "tokens": [50488, 436, 536, 307, 721, 300, 291, 2644, 2903, 50664], "temperature": 0.0, "avg_logprob": -0.09189964377361795, "compression_ratio": 1.8338983050847457, "no_speech_prob": 0.005048722494393587}, {"id": 1527, "seek": 440008, "start": 4406.08, "end": 4407.68, "text": " using quantum mechanics.", "tokens": [50664, 1228, 13018, 12939, 13, 50744], "temperature": 0.0, "avg_logprob": -0.09189964377361795, "compression_ratio": 1.8338983050847457, "no_speech_prob": 0.005048722494393587}, {"id": 1528, "seek": 440008, "start": 4407.68, "end": 4409.2, "text": " And now people say like,", "tokens": [50744, 400, 586, 561, 584, 411, 11, 50820], "temperature": 0.0, "avg_logprob": -0.09189964377361795, "compression_ratio": 1.8338983050847457, "no_speech_prob": 0.005048722494393587}, {"id": 1529, "seek": 440008, "start": 4409.2, "end": 4411.44, "text": " oh, but you can always explain things in quantum mechanics.", "tokens": [50820, 1954, 11, 457, 291, 393, 1009, 2903, 721, 294, 13018, 12939, 13, 50932], "temperature": 0.0, "avg_logprob": -0.09189964377361795, "compression_ratio": 1.8338983050847457, "no_speech_prob": 0.005048722494393587}, {"id": 1530, "seek": 440008, "start": 4411.44, "end": 4413.12, "text": " You just haven't done the calculations.", "tokens": [50932, 509, 445, 2378, 380, 1096, 264, 20448, 13, 51016], "temperature": 0.0, "avg_logprob": -0.09189964377361795, "compression_ratio": 1.8338983050847457, "no_speech_prob": 0.005048722494393587}, {"id": 1531, "seek": 440008, "start": 4413.12, "end": 4416.32, "text": " But the point is precisely that you can't do the calculations, right?", "tokens": [51016, 583, 264, 935, 307, 13402, 300, 291, 393, 380, 360, 264, 20448, 11, 558, 30, 51176], "temperature": 0.0, "avg_logprob": -0.09189964377361795, "compression_ratio": 1.8338983050847457, "no_speech_prob": 0.005048722494393587}, {"id": 1532, "seek": 440008, "start": 4416.32, "end": 4417.84, "text": " The calculations are chaotic.", "tokens": [51176, 440, 20448, 366, 27013, 13, 51252], "temperature": 0.0, "avg_logprob": -0.09189964377361795, "compression_ratio": 1.8338983050847457, "no_speech_prob": 0.005048722494393587}, {"id": 1533, "seek": 440008, "start": 4418.64, "end": 4421.28, "text": " I have a theory, I can come up with 500 theories", "tokens": [51292, 286, 362, 257, 5261, 11, 286, 393, 808, 493, 365, 5923, 13667, 51424], "temperature": 0.0, "avg_logprob": -0.09189964377361795, "compression_ratio": 1.8338983050847457, "no_speech_prob": 0.005048722494393587}, {"id": 1534, "seek": 440008, "start": 4421.28, "end": 4423.84, "text": " of these phenomena and semiconductors and whatnot.", "tokens": [51424, 295, 613, 22004, 293, 36924, 5547, 293, 25882, 13, 51552], "temperature": 0.0, "avg_logprob": -0.09189964377361795, "compression_ratio": 1.8338983050847457, "no_speech_prob": 0.005048722494393587}, {"id": 1535, "seek": 440008, "start": 4423.84, "end": 4425.84, "text": " And like, I never actually get to test them", "tokens": [51552, 400, 411, 11, 286, 1128, 767, 483, 281, 1500, 552, 51652], "temperature": 0.0, "avg_logprob": -0.09189964377361795, "compression_ratio": 1.8338983050847457, "no_speech_prob": 0.005048722494393587}, {"id": 1536, "seek": 440008, "start": 4425.84, "end": 4428.5599999999995, "text": " because the computations diverge before I get to test them.", "tokens": [51652, 570, 264, 2807, 763, 18558, 432, 949, 286, 483, 281, 1500, 552, 13, 51788], "temperature": 0.0, "avg_logprob": -0.09189964377361795, "compression_ratio": 1.8338983050847457, "no_speech_prob": 0.005048722494393587}, {"id": 1537, "seek": 442856, "start": 4428.56, "end": 4432.64, "text": " So for all intents and purposes, it is strong emergence.", "tokens": [50364, 407, 337, 439, 560, 791, 293, 9932, 11, 309, 307, 2068, 36211, 13, 50568], "temperature": 0.0, "avg_logprob": -0.10431274245767032, "compression_ratio": 1.7582781456953642, "no_speech_prob": 0.0021348604932427406}, {"id": 1538, "seek": 442856, "start": 4432.64, "end": 4435.52, "text": " Whether truly that came from below is unanswerable", "tokens": [50568, 8503, 4908, 300, 1361, 490, 2507, 307, 517, 43904, 712, 50712], "temperature": 0.0, "avg_logprob": -0.10431274245767032, "compression_ratio": 1.7582781456953642, "no_speech_prob": 0.0021348604932427406}, {"id": 1539, "seek": 442856, "start": 4435.52, "end": 4437.280000000001, "text": " because you can't compute the predictions.", "tokens": [50712, 570, 291, 393, 380, 14722, 264, 21264, 13, 50800], "temperature": 0.0, "avg_logprob": -0.10431274245767032, "compression_ratio": 1.7582781456953642, "no_speech_prob": 0.0021348604932427406}, {"id": 1540, "seek": 442856, "start": 4437.280000000001, "end": 4438.320000000001, "text": " Well, we spoke about that.", "tokens": [50800, 1042, 11, 321, 7179, 466, 300, 13, 50852], "temperature": 0.0, "avg_logprob": -0.10431274245767032, "compression_ratio": 1.7582781456953642, "no_speech_prob": 0.0021348604932427406}, {"id": 1541, "seek": 442856, "start": 4438.320000000001, "end": 4441.120000000001, "text": " So I think Keith would call that semi-strong emergence,", "tokens": [50852, 407, 286, 519, 20613, 576, 818, 300, 12909, 12, 28063, 36211, 11, 50992], "temperature": 0.0, "avg_logprob": -0.10431274245767032, "compression_ratio": 1.7582781456953642, "no_speech_prob": 0.0021348604932427406}, {"id": 1542, "seek": 442856, "start": 4441.120000000001, "end": 4443.360000000001, "text": " which is like, you know, whether it's computationally reachable", "tokens": [50992, 597, 307, 411, 11, 291, 458, 11, 1968, 309, 311, 24903, 379, 2524, 712, 51104], "temperature": 0.0, "avg_logprob": -0.10431274245767032, "compression_ratio": 1.7582781456953642, "no_speech_prob": 0.0021348604932427406}, {"id": 1543, "seek": 442856, "start": 4443.360000000001, "end": 4446.400000000001, "text": " from the lower resolution to the high resolution", "tokens": [51104, 490, 264, 3126, 8669, 281, 264, 1090, 8669, 51256], "temperature": 0.0, "avg_logprob": -0.10431274245767032, "compression_ratio": 1.7582781456953642, "no_speech_prob": 0.0021348604932427406}, {"id": 1544, "seek": 442856, "start": 4446.400000000001, "end": 4447.76, "text": " to the lower resolution.", "tokens": [51256, 281, 264, 3126, 8669, 13, 51324], "temperature": 0.0, "avg_logprob": -0.10431274245767032, "compression_ratio": 1.7582781456953642, "no_speech_prob": 0.0021348604932427406}, {"id": 1545, "seek": 442856, "start": 4447.76, "end": 4451.120000000001, "text": " But no, Sabine in her paper, A Case for Strong Emergence,", "tokens": [51324, 583, 572, 11, 13915, 533, 294, 720, 3035, 11, 316, 17791, 337, 22792, 18477, 15260, 11, 51492], "temperature": 0.0, "avg_logprob": -0.10431274245767032, "compression_ratio": 1.7582781456953642, "no_speech_prob": 0.0021348604932427406}, {"id": 1546, "seek": 442856, "start": 4451.120000000001, "end": 4452.64, "text": " she was talking about singularities", "tokens": [51492, 750, 390, 1417, 466, 20010, 1088, 51568], "temperature": 0.0, "avg_logprob": -0.10431274245767032, "compression_ratio": 1.7582781456953642, "no_speech_prob": 0.0021348604932427406}, {"id": 1547, "seek": 442856, "start": 4452.64, "end": 4456.080000000001, "text": " as being a really good example of what might be strong emergence.", "tokens": [51568, 382, 885, 257, 534, 665, 1365, 295, 437, 1062, 312, 2068, 36211, 13, 51740], "temperature": 0.0, "avg_logprob": -0.10431274245767032, "compression_ratio": 1.7582781456953642, "no_speech_prob": 0.0021348604932427406}, {"id": 1548, "seek": 445608, "start": 4456.08, "end": 4459.44, "text": " And the philosopher Mark Badau, I think, said that", "tokens": [50364, 400, 264, 29805, 3934, 363, 1538, 84, 11, 286, 519, 11, 848, 300, 50532], "temperature": 0.0, "avg_logprob": -0.155920900617327, "compression_ratio": 1.8876404494382022, "no_speech_prob": 0.0044490802101790905}, {"id": 1549, "seek": 445608, "start": 4459.44, "end": 4461.36, "text": " strong emergence is ridiculous.", "tokens": [50532, 2068, 36211, 307, 11083, 13, 50628], "temperature": 0.0, "avg_logprob": -0.155920900617327, "compression_ratio": 1.8876404494382022, "no_speech_prob": 0.0044490802101790905}, {"id": 1550, "seek": 445608, "start": 4461.36, "end": 4463.76, "text": " It's basically an affront on physicalism.", "tokens": [50628, 467, 311, 1936, 364, 2096, 10001, 322, 4001, 1434, 13, 50748], "temperature": 0.0, "avg_logprob": -0.155920900617327, "compression_ratio": 1.8876404494382022, "no_speech_prob": 0.0044490802101790905}, {"id": 1551, "seek": 445608, "start": 4464.64, "end": 4467.6, "text": " Well, certainly, you know, strong emergence and physicalism,", "tokens": [50792, 1042, 11, 3297, 11, 291, 458, 11, 2068, 36211, 293, 4001, 1434, 11, 50940], "temperature": 0.0, "avg_logprob": -0.155920900617327, "compression_ratio": 1.8876404494382022, "no_speech_prob": 0.0044490802101790905}, {"id": 1552, "seek": 445608, "start": 4467.6, "end": 4469.44, "text": " or let's just call it reductionism, right?", "tokens": [50940, 420, 718, 311, 445, 818, 309, 11004, 1434, 11, 558, 30, 51032], "temperature": 0.0, "avg_logprob": -0.155920900617327, "compression_ratio": 1.8876404494382022, "no_speech_prob": 0.0044490802101790905}, {"id": 1553, "seek": 445608, "start": 4469.44, "end": 4470.16, "text": " Reductionism, yeah.", "tokens": [51032, 4477, 27549, 1434, 11, 1338, 13, 51068], "temperature": 0.0, "avg_logprob": -0.155920900617327, "compression_ratio": 1.8876404494382022, "no_speech_prob": 0.0044490802101790905}, {"id": 1554, "seek": 445608, "start": 4470.16, "end": 4473.04, "text": " Strong emergence and reductionism are incompatible.", "tokens": [51068, 22792, 36211, 293, 11004, 1434, 366, 40393, 267, 964, 13, 51212], "temperature": 0.0, "avg_logprob": -0.155920900617327, "compression_ratio": 1.8876404494382022, "no_speech_prob": 0.0044490802101790905}, {"id": 1555, "seek": 445608, "start": 4473.04, "end": 4473.68, "text": " Yeah.", "tokens": [51212, 865, 13, 51244], "temperature": 0.0, "avg_logprob": -0.155920900617327, "compression_ratio": 1.8876404494382022, "no_speech_prob": 0.0044490802101790905}, {"id": 1556, "seek": 445608, "start": 4473.68, "end": 4477.5199999999995, "text": " And we scientists tend to be reductionists, right?", "tokens": [51244, 400, 321, 7708, 3928, 281, 312, 11004, 1751, 11, 558, 30, 51436], "temperature": 0.0, "avg_logprob": -0.155920900617327, "compression_ratio": 1.8876404494382022, "no_speech_prob": 0.0044490802101790905}, {"id": 1557, "seek": 445608, "start": 4477.5199999999995, "end": 4481.04, "text": " Now, at some level, I'm both a reductionist", "tokens": [51436, 823, 11, 412, 512, 1496, 11, 286, 478, 1293, 257, 11004, 468, 51612], "temperature": 0.0, "avg_logprob": -0.155920900617327, "compression_ratio": 1.8876404494382022, "no_speech_prob": 0.0044490802101790905}, {"id": 1558, "seek": 445608, "start": 4481.04, "end": 4483.28, "text": " and someone who is willing to believe in strong emergence.", "tokens": [51612, 293, 1580, 567, 307, 4950, 281, 1697, 294, 2068, 36211, 13, 51724], "temperature": 0.0, "avg_logprob": -0.155920900617327, "compression_ratio": 1.8876404494382022, "no_speech_prob": 0.0044490802101790905}, {"id": 1559, "seek": 445608, "start": 4483.28, "end": 4485.84, "text": " Again, I don't believe in strong emergence.", "tokens": [51724, 3764, 11, 286, 500, 380, 1697, 294, 2068, 36211, 13, 51852], "temperature": 0.0, "avg_logprob": -0.155920900617327, "compression_ratio": 1.8876404494382022, "no_speech_prob": 0.0044490802101790905}, {"id": 1560, "seek": 448584, "start": 4485.84, "end": 4489.4400000000005, "text": " I just don't see a way to disprove it, right?", "tokens": [50364, 286, 445, 500, 380, 536, 257, 636, 281, 717, 46955, 309, 11, 558, 30, 50544], "temperature": 0.0, "avg_logprob": -0.08299972008967745, "compression_ratio": 1.7758007117437722, "no_speech_prob": 0.001777987228706479}, {"id": 1561, "seek": 448584, "start": 4489.4400000000005, "end": 4492.32, "text": " And like, you know, if there's an empirical way", "tokens": [50544, 400, 411, 11, 291, 458, 11, 498, 456, 311, 364, 31886, 636, 50688], "temperature": 0.0, "avg_logprob": -0.08299972008967745, "compression_ratio": 1.7758007117437722, "no_speech_prob": 0.001777987228706479}, {"id": 1562, "seek": 448584, "start": 4492.32, "end": 4494.8, "text": " to distinguish semi-strong from strong emergence,", "tokens": [50688, 281, 20206, 12909, 12, 28063, 490, 2068, 36211, 11, 50812], "temperature": 0.0, "avg_logprob": -0.08299972008967745, "compression_ratio": 1.7758007117437722, "no_speech_prob": 0.001777987228706479}, {"id": 1563, "seek": 448584, "start": 4494.8, "end": 4496.8, "text": " I'd be very interested to know what it is.", "tokens": [50812, 286, 1116, 312, 588, 3102, 281, 458, 437, 309, 307, 13, 50912], "temperature": 0.0, "avg_logprob": -0.08299972008967745, "compression_ratio": 1.7758007117437722, "no_speech_prob": 0.001777987228706479}, {"id": 1564, "seek": 448584, "start": 4496.8, "end": 4499.04, "text": " But now, I think the thing that is very important", "tokens": [50912, 583, 586, 11, 286, 519, 264, 551, 300, 307, 588, 1021, 51024], "temperature": 0.0, "avg_logprob": -0.08299972008967745, "compression_ratio": 1.7758007117437722, "no_speech_prob": 0.001777987228706479}, {"id": 1565, "seek": 448584, "start": 4499.04, "end": 4501.4400000000005, "text": " that a lot of people, including a lot of physicists", "tokens": [51024, 300, 257, 688, 295, 561, 11, 3009, 257, 688, 295, 48716, 51144], "temperature": 0.0, "avg_logprob": -0.08299972008967745, "compression_ratio": 1.7758007117437722, "no_speech_prob": 0.001777987228706479}, {"id": 1566, "seek": 448584, "start": 4501.4400000000005, "end": 4505.76, "text": " and scientists don't see is that we have this hypothesis", "tokens": [51144, 293, 7708, 500, 380, 536, 307, 300, 321, 362, 341, 17291, 51360], "temperature": 0.0, "avg_logprob": -0.08299972008967745, "compression_ratio": 1.7758007117437722, "no_speech_prob": 0.001777987228706479}, {"id": 1567, "seek": 448584, "start": 4505.76, "end": 4508.08, "text": " that everything can be reduced to the laws of physics", "tokens": [51360, 300, 1203, 393, 312, 9212, 281, 264, 6064, 295, 10649, 51476], "temperature": 0.0, "avg_logprob": -0.08299972008967745, "compression_ratio": 1.7758007117437722, "no_speech_prob": 0.001777987228706479}, {"id": 1568, "seek": 448584, "start": 4508.08, "end": 4508.96, "text": " as we know it.", "tokens": [51476, 382, 321, 458, 309, 13, 51520], "temperature": 0.0, "avg_logprob": -0.08299972008967745, "compression_ratio": 1.7758007117437722, "no_speech_prob": 0.001777987228706479}, {"id": 1569, "seek": 448584, "start": 4508.96, "end": 4512.08, "text": " We should not forget that it's just a hypothesis.", "tokens": [51520, 492, 820, 406, 2870, 300, 309, 311, 445, 257, 17291, 13, 51676], "temperature": 0.0, "avg_logprob": -0.08299972008967745, "compression_ratio": 1.7758007117437722, "no_speech_prob": 0.001777987228706479}, {"id": 1570, "seek": 448584, "start": 4512.08, "end": 4513.76, "text": " And it's a hypothesis that, again,", "tokens": [51676, 400, 309, 311, 257, 17291, 300, 11, 797, 11, 51760], "temperature": 0.0, "avg_logprob": -0.08299972008967745, "compression_ratio": 1.7758007117437722, "no_speech_prob": 0.001777987228706479}, {"id": 1571, "seek": 451376, "start": 4513.84, "end": 4515.6, "text": " counter to a lot of people's say,", "tokens": [50368, 5682, 281, 257, 688, 295, 561, 311, 584, 11, 50456], "temperature": 0.0, "avg_logprob": -0.16145950639751597, "compression_ratio": 1.712837837837838, "no_speech_prob": 0.021563606336712837}, {"id": 1572, "seek": 451376, "start": 4515.6, "end": 4518.72, "text": " is very, very, very, very far from established.", "tokens": [50456, 307, 588, 11, 588, 11, 588, 11, 588, 1400, 490, 7545, 13, 50612], "temperature": 0.0, "avg_logprob": -0.16145950639751597, "compression_ratio": 1.712837837837838, "no_speech_prob": 0.021563606336712837}, {"id": 1573, "seek": 451376, "start": 4518.72, "end": 4520.8, "text": " And usually, people say like, oh, but, you know,", "tokens": [50612, 400, 2673, 11, 561, 584, 411, 11, 1954, 11, 457, 11, 291, 458, 11, 50716], "temperature": 0.0, "avg_logprob": -0.16145950639751597, "compression_ratio": 1.712837837837838, "no_speech_prob": 0.021563606336712837}, {"id": 1574, "seek": 451376, "start": 4520.8, "end": 4524.0, "text": " look at all the successes of the laws of physics and blah, blah.", "tokens": [50716, 574, 412, 439, 264, 26101, 295, 264, 6064, 295, 10649, 293, 12288, 11, 12288, 13, 50876], "temperature": 0.0, "avg_logprob": -0.16145950639751597, "compression_ratio": 1.712837837837838, "no_speech_prob": 0.021563606336712837}, {"id": 1575, "seek": 451376, "start": 4524.0, "end": 4524.96, "text": " And then I say, like, you know,", "tokens": [50876, 400, 550, 286, 584, 11, 411, 11, 291, 458, 11, 50924], "temperature": 0.0, "avg_logprob": -0.16145950639751597, "compression_ratio": 1.712837837837838, "no_speech_prob": 0.021563606336712837}, {"id": 1576, "seek": 451376, "start": 4524.96, "end": 4526.56, "text": " putting on my machine learning hat,", "tokens": [50924, 3372, 322, 452, 3479, 2539, 2385, 11, 51004], "temperature": 0.0, "avg_logprob": -0.16145950639751597, "compression_ratio": 1.712837837837838, "no_speech_prob": 0.021563606336712837}, {"id": 1577, "seek": 451376, "start": 4526.56, "end": 4530.0, "text": " the sample that you've used to validate the laws of physics", "tokens": [51004, 264, 6889, 300, 291, 600, 1143, 281, 29562, 264, 6064, 295, 10649, 51176], "temperature": 0.0, "avg_logprob": -0.16145950639751597, "compression_ratio": 1.712837837837838, "no_speech_prob": 0.021563606336712837}, {"id": 1578, "seek": 451376, "start": 4530.0, "end": 4536.16, "text": " is extraordinarily biased in the direction of simple systems.", "tokens": [51176, 307, 34557, 28035, 294, 264, 3513, 295, 2199, 3652, 13, 51484], "temperature": 0.0, "avg_logprob": -0.16145950639751597, "compression_ratio": 1.712837837837838, "no_speech_prob": 0.021563606336712837}, {"id": 1579, "seek": 451376, "start": 4536.16, "end": 4539.360000000001, "text": " OK, so you can't make this claim of if the data was IID,", "tokens": [51484, 2264, 11, 370, 291, 393, 380, 652, 341, 3932, 295, 498, 264, 1412, 390, 286, 2777, 11, 51644], "temperature": 0.0, "avg_logprob": -0.16145950639751597, "compression_ratio": 1.712837837837838, "no_speech_prob": 0.021563606336712837}, {"id": 1580, "seek": 451376, "start": 4539.360000000001, "end": 4541.320000000001, "text": " I could say with great confidence,", "tokens": [51644, 286, 727, 584, 365, 869, 6687, 11, 51742], "temperature": 0.0, "avg_logprob": -0.16145950639751597, "compression_ratio": 1.712837837837838, "no_speech_prob": 0.021563606336712837}, {"id": 1581, "seek": 451376, "start": 4541.320000000001, "end": 4542.8, "text": " these laws apply universally.", "tokens": [51742, 613, 6064, 3079, 43995, 13, 51816], "temperature": 0.0, "avg_logprob": -0.16145950639751597, "compression_ratio": 1.712837837837838, "no_speech_prob": 0.021563606336712837}, {"id": 1582, "seek": 454280, "start": 4542.8, "end": 4543.92, "text": " But I haven't done it.", "tokens": [50364, 583, 286, 2378, 380, 1096, 309, 13, 50420], "temperature": 0.0, "avg_logprob": -0.15421832383737055, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.0037026607897132635}, {"id": 1583, "seek": 454280, "start": 4543.92, "end": 4547.28, "text": " It's more like I've just landed in a new continent", "tokens": [50420, 467, 311, 544, 411, 286, 600, 445, 15336, 294, 257, 777, 18932, 50588], "temperature": 0.0, "avg_logprob": -0.15421832383737055, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.0037026607897132635}, {"id": 1584, "seek": 454280, "start": 4547.28, "end": 4549.2, "text": " and I've sealed up all the rivers.", "tokens": [50588, 293, 286, 600, 21514, 493, 439, 264, 18361, 13, 50684], "temperature": 0.0, "avg_logprob": -0.15421832383737055, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.0037026607897132635}, {"id": 1585, "seek": 454280, "start": 4549.2, "end": 4551.76, "text": " And I say, I know what this continent looks like.", "tokens": [50684, 400, 286, 584, 11, 286, 458, 437, 341, 18932, 1542, 411, 13, 50812], "temperature": 0.0, "avg_logprob": -0.15421832383737055, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.0037026607897132635}, {"id": 1586, "seek": 454280, "start": 4551.76, "end": 4553.2, "text": " You've never climbed the mountains.", "tokens": [50812, 509, 600, 1128, 28691, 264, 10233, 13, 50884], "temperature": 0.0, "avg_logprob": -0.15421832383737055, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.0037026607897132635}, {"id": 1587, "seek": 454280, "start": 4553.2, "end": 4554.56, "text": " You've never gone in the jungle.", "tokens": [50884, 509, 600, 1128, 2780, 294, 264, 18228, 13, 50952], "temperature": 0.0, "avg_logprob": -0.15421832383737055, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.0037026607897132635}, {"id": 1588, "seek": 454280, "start": 4554.56, "end": 4556.64, "text": " So like this notion that the laws of physics", "tokens": [50952, 407, 411, 341, 10710, 300, 264, 6064, 295, 10649, 51056], "temperature": 0.0, "avg_logprob": -0.15421832383737055, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.0037026607897132635}, {"id": 1589, "seek": 454280, "start": 4556.64, "end": 4558.64, "text": " capture everything about daily life,", "tokens": [51056, 7983, 1203, 466, 5212, 993, 11, 51156], "temperature": 0.0, "avg_logprob": -0.15421832383737055, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.0037026607897132635}, {"id": 1590, "seek": 454280, "start": 4558.64, "end": 4560.320000000001, "text": " we just don't know how exactly.", "tokens": [51156, 321, 445, 500, 380, 458, 577, 2293, 13, 51240], "temperature": 0.0, "avg_logprob": -0.15421832383737055, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.0037026607897132635}, {"id": 1591, "seek": 454280, "start": 4560.320000000001, "end": 4562.16, "text": " Maybe it's true, but it could also", "tokens": [51240, 2704, 309, 311, 2074, 11, 457, 309, 727, 611, 51332], "temperature": 0.0, "avg_logprob": -0.15421832383737055, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.0037026607897132635}, {"id": 1592, "seek": 454280, "start": 4562.16, "end": 4563.6, "text": " equally well be completely false.", "tokens": [51332, 12309, 731, 312, 2584, 7908, 13, 51404], "temperature": 0.0, "avg_logprob": -0.15421832383737055, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.0037026607897132635}, {"id": 1593, "seek": 454280, "start": 4564.56, "end": 4564.88, "text": " Brilliant.", "tokens": [51452, 34007, 13, 51468], "temperature": 0.0, "avg_logprob": -0.15421832383737055, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.0037026607897132635}, {"id": 1594, "seek": 454280, "start": 4564.88, "end": 4566.88, "text": " Well, you gave a bit of a hint to this earlier, actually,", "tokens": [51468, 1042, 11, 291, 2729, 257, 857, 295, 257, 12075, 281, 341, 3071, 11, 767, 11, 51568], "temperature": 0.0, "avg_logprob": -0.15421832383737055, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.0037026607897132635}, {"id": 1595, "seek": 454280, "start": 4566.88, "end": 4569.2, "text": " because you used the word relationism, right?", "tokens": [51568, 570, 291, 1143, 264, 1349, 9721, 1434, 11, 558, 30, 51684], "temperature": 0.0, "avg_logprob": -0.15421832383737055, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.0037026607897132635}, {"id": 1596, "seek": 454280, "start": 4569.2, "end": 4570.24, "text": " Which is basically the...", "tokens": [51684, 3013, 307, 1936, 264, 485, 51736], "temperature": 0.0, "avg_logprob": -0.15421832383737055, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.0037026607897132635}, {"id": 1597, "seek": 454280, "start": 4570.24, "end": 4571.6, "text": " Or relationalism.", "tokens": [51736, 1610, 38444, 1434, 13, 51804], "temperature": 0.0, "avg_logprob": -0.15421832383737055, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.0037026607897132635}, {"id": 1598, "seek": 454280, "start": 4571.6, "end": 4572.0, "text": " Relationalism.", "tokens": [51804, 8738, 1478, 1434, 13, 51824], "temperature": 0.0, "avg_logprob": -0.15421832383737055, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.0037026607897132635}, {"id": 1599, "seek": 457200, "start": 4572.08, "end": 4574.0, "text": " Maybe it should be shortened to relationalism.", "tokens": [50368, 2704, 309, 820, 312, 45183, 281, 38444, 1434, 13, 50464], "temperature": 0.0, "avg_logprob": -0.16979138056437174, "compression_ratio": 1.6062717770034842, "no_speech_prob": 0.002307087881490588}, {"id": 1600, "seek": 457200, "start": 4574.0, "end": 4574.8, "text": " Relationalism.", "tokens": [50464, 8738, 1478, 1434, 13, 50504], "temperature": 0.0, "avg_logprob": -0.16979138056437174, "compression_ratio": 1.6062717770034842, "no_speech_prob": 0.002307087881490588}, {"id": 1601, "seek": 457200, "start": 4575.68, "end": 4578.72, "text": " But yeah, I think Rosen is a great advocate of this,", "tokens": [50548, 583, 1338, 11, 286, 519, 33630, 307, 257, 869, 14608, 295, 341, 11, 50700], "temperature": 0.0, "avg_logprob": -0.16979138056437174, "compression_ratio": 1.6062717770034842, "no_speech_prob": 0.002307087881490588}, {"id": 1602, "seek": 457200, "start": 4578.72, "end": 4582.24, "text": " and he has a whole category theory calculus", "tokens": [50700, 293, 415, 575, 257, 1379, 7719, 5261, 33400, 50876], "temperature": 0.0, "avg_logprob": -0.16979138056437174, "compression_ratio": 1.6062717770034842, "no_speech_prob": 0.002307087881490588}, {"id": 1603, "seek": 457200, "start": 4582.24, "end": 4584.48, "text": " for describing living systems.", "tokens": [50876, 337, 16141, 2647, 3652, 13, 50988], "temperature": 0.0, "avg_logprob": -0.16979138056437174, "compression_ratio": 1.6062717770034842, "no_speech_prob": 0.002307087881490588}, {"id": 1604, "seek": 457200, "start": 4585.04, "end": 4586.88, "text": " And also we spoke to Bob Koek,", "tokens": [51016, 400, 611, 321, 7179, 281, 6085, 10509, 916, 11, 51108], "temperature": 0.0, "avg_logprob": -0.16979138056437174, "compression_ratio": 1.6062717770034842, "no_speech_prob": 0.002307087881490588}, {"id": 1605, "seek": 457200, "start": 4586.88, "end": 4589.76, "text": " the quantum physics professor from Cambridge,", "tokens": [51108, 264, 13018, 10649, 8304, 490, 24876, 11, 51252], "temperature": 0.0, "avg_logprob": -0.16979138056437174, "compression_ratio": 1.6062717770034842, "no_speech_prob": 0.002307087881490588}, {"id": 1606, "seek": 457200, "start": 4589.76, "end": 4592.72, "text": " and he was talking about this concept of Cartesian togetherness,", "tokens": [51252, 293, 415, 390, 1417, 466, 341, 3410, 295, 22478, 42434, 1214, 1287, 11, 51400], "temperature": 0.0, "avg_logprob": -0.16979138056437174, "compression_ratio": 1.6062717770034842, "no_speech_prob": 0.002307087881490588}, {"id": 1607, "seek": 457200, "start": 4592.72, "end": 4594.4, "text": " which is another category or framework.", "tokens": [51400, 597, 307, 1071, 7719, 420, 8388, 13, 51484], "temperature": 0.0, "avg_logprob": -0.16979138056437174, "compression_ratio": 1.6062717770034842, "no_speech_prob": 0.002307087881490588}, {"id": 1608, "seek": 457200, "start": 4594.4, "end": 4597.28, "text": " But I just wondered, does that inform your view?", "tokens": [51484, 583, 286, 445, 17055, 11, 775, 300, 1356, 428, 1910, 30, 51628], "temperature": 0.0, "avg_logprob": -0.16979138056437174, "compression_ratio": 1.6062717770034842, "no_speech_prob": 0.002307087881490588}, {"id": 1609, "seek": 457200, "start": 4598.16, "end": 4601.2, "text": " Well, relationalism, at least in one way", "tokens": [51672, 1042, 11, 38444, 1434, 11, 412, 1935, 294, 472, 636, 51824], "temperature": 0.0, "avg_logprob": -0.16979138056437174, "compression_ratio": 1.6062717770034842, "no_speech_prob": 0.002307087881490588}, {"id": 1610, "seek": 460120, "start": 4601.2, "end": 4604.24, "text": " of defining the term, very much informs my view, right?", "tokens": [50364, 295, 17827, 264, 1433, 11, 588, 709, 45320, 452, 1910, 11, 558, 30, 50516], "temperature": 0.0, "avg_logprob": -0.08332719673981538, "compression_ratio": 1.8310810810810811, "no_speech_prob": 0.0032537002116441727}, {"id": 1611, "seek": 460120, "start": 4604.24, "end": 4606.5599999999995, "text": " And one way to come at this is to say,", "tokens": [50516, 400, 472, 636, 281, 808, 412, 341, 307, 281, 584, 11, 50632], "temperature": 0.0, "avg_logprob": -0.08332719673981538, "compression_ratio": 1.8310810810810811, "no_speech_prob": 0.0032537002116441727}, {"id": 1612, "seek": 460120, "start": 4607.2, "end": 4609.679999999999, "text": " the world is not made of independent entities.", "tokens": [50664, 264, 1002, 307, 406, 1027, 295, 6695, 16667, 13, 50788], "temperature": 0.0, "avg_logprob": -0.08332719673981538, "compression_ratio": 1.8310810810810811, "no_speech_prob": 0.0032537002116441727}, {"id": 1613, "seek": 460120, "start": 4609.679999999999, "end": 4611.04, "text": " Actually, let's just start with machine learning,", "tokens": [50788, 5135, 11, 718, 311, 445, 722, 365, 3479, 2539, 11, 50856], "temperature": 0.0, "avg_logprob": -0.08332719673981538, "compression_ratio": 1.8310810810810811, "no_speech_prob": 0.0032537002116441727}, {"id": 1614, "seek": 460120, "start": 4611.04, "end": 4612.8, "text": " which is a very concrete way to look at this.", "tokens": [50856, 597, 307, 257, 588, 9859, 636, 281, 574, 412, 341, 13, 50944], "temperature": 0.0, "avg_logprob": -0.08332719673981538, "compression_ratio": 1.8310810810810811, "no_speech_prob": 0.0032537002116441727}, {"id": 1615, "seek": 460120, "start": 4613.36, "end": 4615.84, "text": " A very large part, maybe even the largest part", "tokens": [50972, 316, 588, 2416, 644, 11, 1310, 754, 264, 6443, 644, 51096], "temperature": 0.0, "avg_logprob": -0.08332719673981538, "compression_ratio": 1.8310810810810811, "no_speech_prob": 0.0032537002116441727}, {"id": 1616, "seek": 460120, "start": 4615.84, "end": 4617.679999999999, "text": " of my research in the last 20 years,", "tokens": [51096, 295, 452, 2132, 294, 264, 1036, 945, 924, 11, 51188], "temperature": 0.0, "avg_logprob": -0.08332719673981538, "compression_ratio": 1.8310810810810811, "no_speech_prob": 0.0032537002116441727}, {"id": 1617, "seek": 460120, "start": 4617.679999999999, "end": 4621.84, "text": " has been to do away with the assumption of IID data, right?", "tokens": [51188, 575, 668, 281, 360, 1314, 365, 264, 15302, 295, 286, 2777, 1412, 11, 558, 30, 51396], "temperature": 0.0, "avg_logprob": -0.08332719673981538, "compression_ratio": 1.8310810810810811, "no_speech_prob": 0.0032537002116441727}, {"id": 1618, "seek": 460120, "start": 4621.84, "end": 4623.84, "text": " That the world is made of independent entities,", "tokens": [51396, 663, 264, 1002, 307, 1027, 295, 6695, 16667, 11, 51496], "temperature": 0.0, "avg_logprob": -0.08332719673981538, "compression_ratio": 1.8310810810810811, "no_speech_prob": 0.0032537002116441727}, {"id": 1619, "seek": 460120, "start": 4623.84, "end": 4626.5599999999995, "text": " in particular, society is made of independent agents,", "tokens": [51496, 294, 1729, 11, 4086, 307, 1027, 295, 6695, 12554, 11, 51632], "temperature": 0.0, "avg_logprob": -0.08332719673981538, "compression_ratio": 1.8310810810810811, "no_speech_prob": 0.0032537002116441727}, {"id": 1620, "seek": 460120, "start": 4626.5599999999995, "end": 4627.84, "text": " et cetera, et cetera, right?", "tokens": [51632, 1030, 11458, 11, 1030, 11458, 11, 558, 30, 51696], "temperature": 0.0, "avg_logprob": -0.08332719673981538, "compression_ratio": 1.8310810810810811, "no_speech_prob": 0.0032537002116441727}, {"id": 1621, "seek": 460120, "start": 4627.84, "end": 4629.599999999999, "text": " Now, we make this assumption,", "tokens": [51696, 823, 11, 321, 652, 341, 15302, 11, 51784], "temperature": 0.0, "avg_logprob": -0.08332719673981538, "compression_ratio": 1.8310810810810811, "no_speech_prob": 0.0032537002116441727}, {"id": 1622, "seek": 462960, "start": 4629.6, "end": 4632.400000000001, "text": " both as human beings, to some extent,", "tokens": [50364, 1293, 382, 1952, 8958, 11, 281, 512, 8396, 11, 50504], "temperature": 0.0, "avg_logprob": -0.07260838845618685, "compression_ratio": 1.6778523489932886, "no_speech_prob": 0.008144350722432137}, {"id": 1623, "seek": 462960, "start": 4632.400000000001, "end": 4634.400000000001, "text": " and certainly very much so in science,", "tokens": [50504, 293, 3297, 588, 709, 370, 294, 3497, 11, 50604], "temperature": 0.0, "avg_logprob": -0.07260838845618685, "compression_ratio": 1.6778523489932886, "no_speech_prob": 0.008144350722432137}, {"id": 1624, "seek": 462960, "start": 4634.400000000001, "end": 4635.84, "text": " because it makes life easier.", "tokens": [50604, 570, 309, 1669, 993, 3571, 13, 50676], "temperature": 0.0, "avg_logprob": -0.07260838845618685, "compression_ratio": 1.6778523489932886, "no_speech_prob": 0.008144350722432137}, {"id": 1625, "seek": 462960, "start": 4636.72, "end": 4639.68, "text": " The math is way, way, way easier when you assume independence.", "tokens": [50720, 440, 5221, 307, 636, 11, 636, 11, 636, 3571, 562, 291, 6552, 14640, 13, 50868], "temperature": 0.0, "avg_logprob": -0.07260838845618685, "compression_ratio": 1.6778523489932886, "no_speech_prob": 0.008144350722432137}, {"id": 1626, "seek": 462960, "start": 4639.68, "end": 4642.88, "text": " But it's a blatantly false assumption, right?", "tokens": [50868, 583, 309, 311, 257, 42780, 3627, 7908, 15302, 11, 558, 30, 51028], "temperature": 0.0, "avg_logprob": -0.07260838845618685, "compression_ratio": 1.6778523489932886, "no_speech_prob": 0.008144350722432137}, {"id": 1627, "seek": 462960, "start": 4642.88, "end": 4644.320000000001, "text": " Unfortunately, a lot of, for example,", "tokens": [51028, 8590, 11, 257, 688, 295, 11, 337, 1365, 11, 51100], "temperature": 0.0, "avg_logprob": -0.07260838845618685, "compression_ratio": 1.6778523489932886, "no_speech_prob": 0.008144350722432137}, {"id": 1628, "seek": 462960, "start": 4644.320000000001, "end": 4647.6, "text": " economics prominently has embedded in it this notion", "tokens": [51100, 14564, 39225, 2276, 575, 16741, 294, 309, 341, 10710, 51264], "temperature": 0.0, "avg_logprob": -0.07260838845618685, "compression_ratio": 1.6778523489932886, "no_speech_prob": 0.008144350722432137}, {"id": 1629, "seek": 462960, "start": 4647.6, "end": 4649.68, "text": " that the world is a bunch of independent agents,", "tokens": [51264, 300, 264, 1002, 307, 257, 3840, 295, 6695, 12554, 11, 51368], "temperature": 0.0, "avg_logprob": -0.07260838845618685, "compression_ratio": 1.6778523489932886, "no_speech_prob": 0.008144350722432137}, {"id": 1630, "seek": 462960, "start": 4649.68, "end": 4651.52, "text": " and it just doesn't work like that.", "tokens": [51368, 293, 309, 445, 1177, 380, 589, 411, 300, 13, 51460], "temperature": 0.0, "avg_logprob": -0.07260838845618685, "compression_ratio": 1.6778523489932886, "no_speech_prob": 0.008144350722432137}, {"id": 1631, "seek": 462960, "start": 4651.52, "end": 4654.72, "text": " And moreover, it's a distinction that is full of consequences.", "tokens": [51460, 400, 544, 3570, 11, 309, 311, 257, 16844, 300, 307, 1577, 295, 10098, 13, 51620], "temperature": 0.0, "avg_logprob": -0.07260838845618685, "compression_ratio": 1.6778523489932886, "no_speech_prob": 0.008144350722432137}, {"id": 1632, "seek": 462960, "start": 4654.72, "end": 4658.400000000001, "text": " A society and economy is a network of agents,", "tokens": [51620, 316, 4086, 293, 5010, 307, 257, 3209, 295, 12554, 11, 51804], "temperature": 0.0, "avg_logprob": -0.07260838845618685, "compression_ratio": 1.6778523489932886, "no_speech_prob": 0.008144350722432137}, {"id": 1633, "seek": 465840, "start": 4658.4, "end": 4660.96, "text": " and almost all the action is in their interactions.", "tokens": [50364, 293, 1920, 439, 264, 3069, 307, 294, 641, 13280, 13, 50492], "temperature": 0.0, "avg_logprob": -0.09406391678342393, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.0034137920010834932}, {"id": 1634, "seek": 465840, "start": 4661.679999999999, "end": 4663.759999999999, "text": " Until you really start taking that seriously,", "tokens": [50528, 9088, 291, 534, 722, 1940, 300, 6638, 11, 50632], "temperature": 0.0, "avg_logprob": -0.09406391678342393, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.0034137920010834932}, {"id": 1635, "seek": 465840, "start": 4663.759999999999, "end": 4665.04, "text": " you really don't understand the world.", "tokens": [50632, 291, 534, 500, 380, 1223, 264, 1002, 13, 50696], "temperature": 0.0, "avg_logprob": -0.09406391678342393, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.0034137920010834932}, {"id": 1636, "seek": 465840, "start": 4665.04, "end": 4667.44, "text": " Again, I have no quarrel with classic economics", "tokens": [50696, 3764, 11, 286, 362, 572, 4723, 4419, 365, 7230, 14564, 50816], "temperature": 0.0, "avg_logprob": -0.09406391678342393, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.0034137920010834932}, {"id": 1637, "seek": 465840, "start": 4667.44, "end": 4668.639999999999, "text": " as a first approximation.", "tokens": [50816, 382, 257, 700, 28023, 13, 50876], "temperature": 0.0, "avg_logprob": -0.09406391678342393, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.0034137920010834932}, {"id": 1638, "seek": 465840, "start": 4668.639999999999, "end": 4670.16, "text": " It's exactly what it should be, right?", "tokens": [50876, 467, 311, 2293, 437, 309, 820, 312, 11, 558, 30, 50952], "temperature": 0.0, "avg_logprob": -0.09406391678342393, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.0034137920010834932}, {"id": 1639, "seek": 465840, "start": 4670.719999999999, "end": 4671.759999999999, "text": " But then, and by the way,", "tokens": [50980, 583, 550, 11, 293, 538, 264, 636, 11, 51032], "temperature": 0.0, "avg_logprob": -0.09406391678342393, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.0034137920010834932}, {"id": 1640, "seek": 465840, "start": 4671.759999999999, "end": 4673.44, "text": " you should also not just throw it away and say,", "tokens": [51032, 291, 820, 611, 406, 445, 3507, 309, 1314, 293, 584, 11, 51116], "temperature": 0.0, "avg_logprob": -0.09406391678342393, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.0034137920010834932}, {"id": 1641, "seek": 465840, "start": 4673.44, "end": 4675.28, "text": " like, oh, this is garbage, like some people say.", "tokens": [51116, 411, 11, 1954, 11, 341, 307, 14150, 11, 411, 512, 561, 584, 13, 51208], "temperature": 0.0, "avg_logprob": -0.09406391678342393, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.0034137920010834932}, {"id": 1642, "seek": 465840, "start": 4675.28, "end": 4676.4, "text": " You have to go the next stage.", "tokens": [51208, 509, 362, 281, 352, 264, 958, 3233, 13, 51264], "temperature": 0.0, "avg_logprob": -0.09406391678342393, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.0034137920010834932}, {"id": 1643, "seek": 465840, "start": 4676.4, "end": 4678.719999999999, "text": " It's actually now we have the mathematical", "tokens": [51264, 467, 311, 767, 586, 321, 362, 264, 18894, 51380], "temperature": 0.0, "avg_logprob": -0.09406391678342393, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.0034137920010834932}, {"id": 1644, "seek": 465840, "start": 4678.719999999999, "end": 4680.32, "text": " and computational tools to do,", "tokens": [51380, 293, 28270, 3873, 281, 360, 11, 51460], "temperature": 0.0, "avg_logprob": -0.09406391678342393, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.0034137920010834932}, {"id": 1645, "seek": 465840, "start": 4680.32, "end": 4683.28, "text": " and understand it as being a system of interacting agents.", "tokens": [51460, 293, 1223, 309, 382, 885, 257, 1185, 295, 18017, 12554, 13, 51608], "temperature": 0.0, "avg_logprob": -0.09406391678342393, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.0034137920010834932}, {"id": 1646, "seek": 465840, "start": 4683.839999999999, "end": 4685.839999999999, "text": " And all of the questions that we are talking about,", "tokens": [51636, 400, 439, 295, 264, 1651, 300, 321, 366, 1417, 466, 11, 51736], "temperature": 0.0, "avg_logprob": -0.09406391678342393, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.0034137920010834932}, {"id": 1647, "seek": 468584, "start": 4685.84, "end": 4690.08, "text": " including in evolution, even in physics, right?", "tokens": [50364, 3009, 294, 9303, 11, 754, 294, 10649, 11, 558, 30, 50576], "temperature": 0.0, "avg_logprob": -0.10067283130082928, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.019949784502387047}, {"id": 1648, "seek": 468584, "start": 4691.2, "end": 4694.72, "text": " A piece of condensed matter is a network of interacting,", "tokens": [50632, 316, 2522, 295, 36398, 1871, 307, 257, 3209, 295, 18017, 11, 50808], "temperature": 0.0, "avg_logprob": -0.10067283130082928, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.019949784502387047}, {"id": 1649, "seek": 468584, "start": 4694.72, "end": 4696.24, "text": " spins, et cetera, et cetera, you name it.", "tokens": [50808, 31587, 11, 1030, 11458, 11, 1030, 11458, 11, 291, 1315, 309, 13, 50884], "temperature": 0.0, "avg_logprob": -0.10067283130082928, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.019949784502387047}, {"id": 1650, "seek": 468584, "start": 4696.24, "end": 4698.8, "text": " So the relations are at the heart of it,", "tokens": [50884, 407, 264, 2299, 366, 412, 264, 1917, 295, 309, 11, 51012], "temperature": 0.0, "avg_logprob": -0.10067283130082928, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.019949784502387047}, {"id": 1651, "seek": 468584, "start": 4698.8, "end": 4700.56, "text": " and moreover, like as I said,", "tokens": [51012, 293, 544, 3570, 11, 411, 382, 286, 848, 11, 51100], "temperature": 0.0, "avg_logprob": -0.10067283130082928, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.019949784502387047}, {"id": 1652, "seek": 468584, "start": 4700.56, "end": 4703.4400000000005, "text": " a lot of my work is we now have the representations,", "tokens": [51100, 257, 688, 295, 452, 589, 307, 321, 586, 362, 264, 33358, 11, 51244], "temperature": 0.0, "avg_logprob": -0.10067283130082928, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.019949784502387047}, {"id": 1653, "seek": 468584, "start": 4703.4400000000005, "end": 4705.4400000000005, "text": " the learning inference algorithms to handle things", "tokens": [51244, 264, 2539, 38253, 14642, 281, 4813, 721, 51344], "temperature": 0.0, "avg_logprob": -0.10067283130082928, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.019949784502387047}, {"id": 1654, "seek": 468584, "start": 4705.4400000000005, "end": 4707.52, "text": " that are big piles of relations,", "tokens": [51344, 300, 366, 955, 34861, 295, 2299, 11, 51448], "temperature": 0.0, "avg_logprob": -0.10067283130082928, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.019949784502387047}, {"id": 1655, "seek": 468584, "start": 4707.52, "end": 4710.08, "text": " and the whole world is better understood in those terms,", "tokens": [51448, 293, 264, 1379, 1002, 307, 1101, 7320, 294, 729, 2115, 11, 51576], "temperature": 0.0, "avg_logprob": -0.10067283130082928, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.019949784502387047}, {"id": 1656, "seek": 468584, "start": 4710.08, "end": 4712.08, "text": " and we just need people to catch up with that.", "tokens": [51576, 293, 321, 445, 643, 561, 281, 3745, 493, 365, 300, 13, 51676], "temperature": 0.0, "avg_logprob": -0.10067283130082928, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.019949784502387047}, {"id": 1657, "seek": 471208, "start": 4712.8, "end": 4714.24, "text": " You know, once you do that,", "tokens": [50400, 509, 458, 11, 1564, 291, 360, 300, 11, 50472], "temperature": 0.0, "avg_logprob": -0.11051551273890904, "compression_ratio": 1.7231833910034602, "no_speech_prob": 0.02872496470808983}, {"id": 1658, "seek": 471208, "start": 4714.24, "end": 4716.08, "text": " you get into things that can easily be", "tokens": [50472, 291, 483, 666, 721, 300, 393, 3612, 312, 50564], "temperature": 0.0, "avg_logprob": -0.11051551273890904, "compression_ratio": 1.7231833910034602, "no_speech_prob": 0.02872496470808983}, {"id": 1659, "seek": 471208, "start": 4716.08, "end": 4718.0, "text": " computational, intractable, and so on and so forth.", "tokens": [50564, 28270, 11, 560, 1897, 712, 11, 293, 370, 322, 293, 370, 5220, 13, 50660], "temperature": 0.0, "avg_logprob": -0.11051551273890904, "compression_ratio": 1.7231833910034602, "no_speech_prob": 0.02872496470808983}, {"id": 1660, "seek": 471208, "start": 4718.0, "end": 4720.16, "text": " But there's a lot of things that we can do there", "tokens": [50660, 583, 456, 311, 257, 688, 295, 721, 300, 321, 393, 360, 456, 50768], "temperature": 0.0, "avg_logprob": -0.11051551273890904, "compression_ratio": 1.7231833910034602, "no_speech_prob": 0.02872496470808983}, {"id": 1661, "seek": 471208, "start": 4720.16, "end": 4721.44, "text": " and a lot more that we'll do.", "tokens": [50768, 293, 257, 688, 544, 300, 321, 603, 360, 13, 50832], "temperature": 0.0, "avg_logprob": -0.11051551273890904, "compression_ratio": 1.7231833910034602, "no_speech_prob": 0.02872496470808983}, {"id": 1662, "seek": 471208, "start": 4721.44, "end": 4724.16, "text": " So at this level, I think relationalism", "tokens": [50832, 407, 412, 341, 1496, 11, 286, 519, 38444, 1434, 50968], "temperature": 0.0, "avg_logprob": -0.11051551273890904, "compression_ratio": 1.7231833910034602, "no_speech_prob": 0.02872496470808983}, {"id": 1663, "seek": 471208, "start": 4724.16, "end": 4726.5599999999995, "text": " is really should be a cornerstone", "tokens": [50968, 307, 534, 820, 312, 257, 4538, 11243, 51088], "temperature": 0.0, "avg_logprob": -0.11051551273890904, "compression_ratio": 1.7231833910034602, "no_speech_prob": 0.02872496470808983}, {"id": 1664, "seek": 471208, "start": 4726.5599999999995, "end": 4728.16, "text": " of our understanding of the world", "tokens": [51088, 295, 527, 3701, 295, 264, 1002, 51168], "temperature": 0.0, "avg_logprob": -0.11051551273890904, "compression_ratio": 1.7231833910034602, "no_speech_prob": 0.02872496470808983}, {"id": 1665, "seek": 471208, "start": 4728.16, "end": 4729.92, "text": " in a way that it hasn't been in the past.", "tokens": [51168, 294, 257, 636, 300, 309, 6132, 380, 668, 294, 264, 1791, 13, 51256], "temperature": 0.0, "avg_logprob": -0.11051551273890904, "compression_ratio": 1.7231833910034602, "no_speech_prob": 0.02872496470808983}, {"id": 1666, "seek": 471208, "start": 4730.48, "end": 4733.6, "text": " Okay, and which existing complexity science brings to mind?", "tokens": [51284, 1033, 11, 293, 597, 6741, 14024, 3497, 5607, 281, 1575, 30, 51440], "temperature": 0.0, "avg_logprob": -0.11051551273890904, "compression_ratio": 1.7231833910034602, "no_speech_prob": 0.02872496470808983}, {"id": 1667, "seek": 471208, "start": 4733.6, "end": 4737.44, "text": " But I mean, which existing techniques and areas", "tokens": [51440, 583, 286, 914, 11, 597, 6741, 7512, 293, 3179, 51632], "temperature": 0.0, "avg_logprob": -0.11051551273890904, "compression_ratio": 1.7231833910034602, "no_speech_prob": 0.02872496470808983}, {"id": 1668, "seek": 471208, "start": 4737.44, "end": 4740.5599999999995, "text": " can folks look into to take that on board?", "tokens": [51632, 393, 4024, 574, 666, 281, 747, 300, 322, 3150, 30, 51788], "temperature": 0.0, "avg_logprob": -0.11051551273890904, "compression_ratio": 1.7231833910034602, "no_speech_prob": 0.02872496470808983}, {"id": 1669, "seek": 474056, "start": 4740.64, "end": 4742.400000000001, "text": " Well, you know, Markov logic,", "tokens": [50368, 1042, 11, 291, 458, 11, 3934, 5179, 9952, 11, 50456], "temperature": 0.0, "avg_logprob": -0.1091171762217646, "compression_ratio": 1.6971830985915493, "no_speech_prob": 0.007780703250318766}, {"id": 1670, "seek": 474056, "start": 4742.400000000001, "end": 4745.120000000001, "text": " which is what I developed for this purpose essentially,", "tokens": [50456, 597, 307, 437, 286, 4743, 337, 341, 4334, 4476, 11, 50592], "temperature": 0.0, "avg_logprob": -0.1091171762217646, "compression_ratio": 1.6971830985915493, "no_speech_prob": 0.007780703250318766}, {"id": 1671, "seek": 474056, "start": 4745.120000000001, "end": 4747.280000000001, "text": " and I do think, you know,", "tokens": [50592, 293, 286, 360, 519, 11, 291, 458, 11, 50700], "temperature": 0.0, "avg_logprob": -0.1091171762217646, "compression_ratio": 1.6971830985915493, "no_speech_prob": 0.007780703250318766}, {"id": 1672, "seek": 474056, "start": 4747.280000000001, "end": 4748.8, "text": " this is my talking about my work,", "tokens": [50700, 341, 307, 452, 1417, 466, 452, 589, 11, 50776], "temperature": 0.0, "avg_logprob": -0.1091171762217646, "compression_ratio": 1.6971830985915493, "no_speech_prob": 0.007780703250318766}, {"id": 1673, "seek": 474056, "start": 4748.8, "end": 4750.320000000001, "text": " so you should naturally be suspicious,", "tokens": [50776, 370, 291, 820, 8195, 312, 17931, 11, 50852], "temperature": 0.0, "avg_logprob": -0.1091171762217646, "compression_ratio": 1.6971830985915493, "no_speech_prob": 0.007780703250318766}, {"id": 1674, "seek": 474056, "start": 4750.320000000001, "end": 4752.96, "text": " but I think it's the best that we have,", "tokens": [50852, 457, 286, 519, 309, 311, 264, 1151, 300, 321, 362, 11, 50984], "temperature": 0.0, "avg_logprob": -0.1091171762217646, "compression_ratio": 1.6971830985915493, "no_speech_prob": 0.007780703250318766}, {"id": 1675, "seek": 474056, "start": 4752.96, "end": 4755.120000000001, "text": " and I think by a wide measure,", "tokens": [50984, 293, 286, 519, 538, 257, 4874, 3481, 11, 51092], "temperature": 0.0, "avg_logprob": -0.1091171762217646, "compression_ratio": 1.6971830985915493, "no_speech_prob": 0.007780703250318766}, {"id": 1676, "seek": 474056, "start": 4755.120000000001, "end": 4757.120000000001, "text": " compared to anything else that we have so far.", "tokens": [51092, 5347, 281, 1340, 1646, 300, 321, 362, 370, 1400, 13, 51192], "temperature": 0.0, "avg_logprob": -0.1091171762217646, "compression_ratio": 1.6971830985915493, "no_speech_prob": 0.007780703250318766}, {"id": 1677, "seek": 474056, "start": 4757.120000000001, "end": 4758.56, "text": " Okay, and can you sketch it out?", "tokens": [51192, 1033, 11, 293, 393, 291, 12325, 309, 484, 30, 51264], "temperature": 0.0, "avg_logprob": -0.1091171762217646, "compression_ratio": 1.6971830985915493, "no_speech_prob": 0.007780703250318766}, {"id": 1678, "seek": 474056, "start": 4758.56, "end": 4762.88, "text": " Yeah, so to sketch it out in the simplest terms, right,", "tokens": [51264, 865, 11, 370, 281, 12325, 309, 484, 294, 264, 22811, 2115, 11, 558, 11, 51480], "temperature": 0.0, "avg_logprob": -0.1091171762217646, "compression_ratio": 1.6971830985915493, "no_speech_prob": 0.007780703250318766}, {"id": 1679, "seek": 474056, "start": 4762.88, "end": 4766.240000000001, "text": " we want to combine all the traditional goodies", "tokens": [51480, 321, 528, 281, 10432, 439, 264, 5164, 44072, 51648], "temperature": 0.0, "avg_logprob": -0.1091171762217646, "compression_ratio": 1.6971830985915493, "no_speech_prob": 0.007780703250318766}, {"id": 1680, "seek": 474056, "start": 4766.240000000001, "end": 4768.400000000001, "text": " that we have from assuming the world is IID", "tokens": [51648, 300, 321, 362, 490, 11926, 264, 1002, 307, 286, 2777, 51756], "temperature": 0.0, "avg_logprob": -0.1091171762217646, "compression_ratio": 1.6971830985915493, "no_speech_prob": 0.007780703250318766}, {"id": 1681, "seek": 476840, "start": 4768.4, "end": 4770.48, "text": " with the power to model, you know, relationships,", "tokens": [50364, 365, 264, 1347, 281, 2316, 11, 291, 458, 11, 6159, 11, 50468], "temperature": 0.0, "avg_logprob": -0.11165894117931392, "compression_ratio": 1.8501628664495113, "no_speech_prob": 0.008037938736379147}, {"id": 1682, "seek": 476840, "start": 4770.48, "end": 4772.639999999999, "text": " there are themselves potentially very complicated.", "tokens": [50468, 456, 366, 2969, 7263, 588, 6179, 13, 50576], "temperature": 0.0, "avg_logprob": -0.11165894117931392, "compression_ratio": 1.8501628664495113, "no_speech_prob": 0.008037938736379147}, {"id": 1683, "seek": 476840, "start": 4772.639999999999, "end": 4774.719999999999, "text": " The way we do the Markov logic is,", "tokens": [50576, 440, 636, 321, 360, 264, 3934, 5179, 9952, 307, 11, 50680], "temperature": 0.0, "avg_logprob": -0.11165894117931392, "compression_ratio": 1.8501628664495113, "no_speech_prob": 0.008037938736379147}, {"id": 1684, "seek": 476840, "start": 4774.719999999999, "end": 4775.839999999999, "text": " there's the logical part.", "tokens": [50680, 456, 311, 264, 14978, 644, 13, 50736], "temperature": 0.0, "avg_logprob": -0.11165894117931392, "compression_ratio": 1.8501628664495113, "no_speech_prob": 0.008037938736379147}, {"id": 1685, "seek": 476840, "start": 4776.639999999999, "end": 4779.839999999999, "text": " We actually do not need to solve a new,", "tokens": [50776, 492, 767, 360, 406, 643, 281, 5039, 257, 777, 11, 50936], "temperature": 0.0, "avg_logprob": -0.11165894117931392, "compression_ratio": 1.8501628664495113, "no_speech_prob": 0.008037938736379147}, {"id": 1686, "seek": 476840, "start": 4779.839999999999, "end": 4781.679999999999, "text": " the problem of how to represent", "tokens": [50936, 264, 1154, 295, 577, 281, 2906, 51028], "temperature": 0.0, "avg_logprob": -0.11165894117931392, "compression_ratio": 1.8501628664495113, "no_speech_prob": 0.008037938736379147}, {"id": 1687, "seek": 476840, "start": 4781.679999999999, "end": 4783.12, "text": " and do inference with relations.", "tokens": [51028, 293, 360, 38253, 365, 2299, 13, 51100], "temperature": 0.0, "avg_logprob": -0.11165894117931392, "compression_ratio": 1.8501628664495113, "no_speech_prob": 0.008037938736379147}, {"id": 1688, "seek": 476840, "start": 4783.12, "end": 4785.2, "text": " We have first order logic for that.", "tokens": [51100, 492, 362, 700, 1668, 9952, 337, 300, 13, 51204], "temperature": 0.0, "avg_logprob": -0.11165894117931392, "compression_ratio": 1.8501628664495113, "no_speech_prob": 0.008037938736379147}, {"id": 1689, "seek": 476840, "start": 4785.759999999999, "end": 4788.24, "text": " First order logic is the language of relations.", "tokens": [51232, 2386, 1668, 9952, 307, 264, 2856, 295, 2299, 13, 51356], "temperature": 0.0, "avg_logprob": -0.11165894117931392, "compression_ratio": 1.8501628664495113, "no_speech_prob": 0.008037938736379147}, {"id": 1690, "seek": 476840, "start": 4788.24, "end": 4790.32, "text": " That's actually the term that is used, right,", "tokens": [51356, 663, 311, 767, 264, 1433, 300, 307, 1143, 11, 558, 11, 51460], "temperature": 0.0, "avg_logprob": -0.11165894117931392, "compression_ratio": 1.8501628664495113, "no_speech_prob": 0.008037938736379147}, {"id": 1691, "seek": 476840, "start": 4790.32, "end": 4792.08, "text": " and how the relations depend predicates.", "tokens": [51460, 293, 577, 264, 2299, 5672, 47336, 1024, 13, 51548], "temperature": 0.0, "avg_logprob": -0.11165894117931392, "compression_ratio": 1.8501628664495113, "no_speech_prob": 0.008037938736379147}, {"id": 1692, "seek": 476840, "start": 4792.08, "end": 4793.28, "text": " Sometimes they're called predicates,", "tokens": [51548, 4803, 436, 434, 1219, 47336, 1024, 11, 51608], "temperature": 0.0, "avg_logprob": -0.11165894117931392, "compression_ratio": 1.8501628664495113, "no_speech_prob": 0.008037938736379147}, {"id": 1693, "seek": 476840, "start": 4793.28, "end": 4795.44, "text": " but let's just call them relations, right?", "tokens": [51608, 457, 718, 311, 445, 818, 552, 2299, 11, 558, 30, 51716], "temperature": 0.0, "avg_logprob": -0.11165894117931392, "compression_ratio": 1.8501628664495113, "no_speech_prob": 0.008037938736379147}, {"id": 1694, "seek": 476840, "start": 4795.44, "end": 4797.759999999999, "text": " We have a formal language to talk about relations.", "tokens": [51716, 492, 362, 257, 9860, 2856, 281, 751, 466, 2299, 13, 51832], "temperature": 0.0, "avg_logprob": -0.11165894117931392, "compression_ratio": 1.8501628664495113, "no_speech_prob": 0.008037938736379147}, {"id": 1695, "seek": 479776, "start": 4797.76, "end": 4800.08, "text": " And by the way, essentially all of computer science", "tokens": [50364, 400, 538, 264, 636, 11, 4476, 439, 295, 3820, 3497, 50480], "temperature": 0.0, "avg_logprob": -0.102850711508973, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.001924622687511146}, {"id": 1696, "seek": 479776, "start": 4800.08, "end": 4800.96, "text": " can be reduced to that.", "tokens": [50480, 393, 312, 9212, 281, 300, 13, 50524], "temperature": 0.0, "avg_logprob": -0.102850711508973, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.001924622687511146}, {"id": 1697, "seek": 479776, "start": 4800.96, "end": 4803.12, "text": " You give me your favorite, you know, whatever,", "tokens": [50524, 509, 976, 385, 428, 2954, 11, 291, 458, 11, 2035, 11, 50632], "temperature": 0.0, "avg_logprob": -0.102850711508973, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.001924622687511146}, {"id": 1698, "seek": 479776, "start": 4803.12, "end": 4806.400000000001, "text": " knowledge representation, data structure, et cetera, et cetera.", "tokens": [50632, 3601, 10290, 11, 1412, 3877, 11, 1030, 11458, 11, 1030, 11458, 13, 50796], "temperature": 0.0, "avg_logprob": -0.102850711508973, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.001924622687511146}, {"id": 1699, "seek": 479776, "start": 4806.400000000001, "end": 4809.68, "text": " And I, anybody who knows can immediately say", "tokens": [50796, 400, 286, 11, 4472, 567, 3255, 393, 4258, 584, 50960], "temperature": 0.0, "avg_logprob": -0.102850711508973, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.001924622687511146}, {"id": 1700, "seek": 479776, "start": 4809.68, "end": 4810.72, "text": " how to do that in logic.", "tokens": [50960, 577, 281, 360, 300, 294, 9952, 13, 51012], "temperature": 0.0, "avg_logprob": -0.102850711508973, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.001924622687511146}, {"id": 1701, "seek": 479776, "start": 4810.72, "end": 4811.92, "text": " So that's one part.", "tokens": [51012, 407, 300, 311, 472, 644, 13, 51072], "temperature": 0.0, "avg_logprob": -0.102850711508973, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.001924622687511146}, {"id": 1702, "seek": 479776, "start": 4811.92, "end": 4814.72, "text": " The other part is the statistical, you know,", "tokens": [51072, 440, 661, 644, 307, 264, 22820, 11, 291, 458, 11, 51212], "temperature": 0.0, "avg_logprob": -0.102850711508973, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.001924622687511146}, {"id": 1703, "seek": 479776, "start": 4814.72, "end": 4817.280000000001, "text": " machine learning probabilistic aspect of the world, right?", "tokens": [51212, 3479, 2539, 31959, 3142, 4171, 295, 264, 1002, 11, 558, 30, 51340], "temperature": 0.0, "avg_logprob": -0.102850711508973, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.001924622687511146}, {"id": 1704, "seek": 479776, "start": 4817.280000000001, "end": 4820.08, "text": " And then again, going all the way back to physics, right?", "tokens": [51340, 400, 550, 797, 11, 516, 439, 264, 636, 646, 281, 10649, 11, 558, 30, 51480], "temperature": 0.0, "avg_logprob": -0.102850711508973, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.001924622687511146}, {"id": 1705, "seek": 479776, "start": 4820.8, "end": 4822.16, "text": " All of these things that we deal with", "tokens": [51516, 1057, 295, 613, 721, 300, 321, 2028, 365, 51584], "temperature": 0.0, "avg_logprob": -0.102850711508973, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.001924622687511146}, {"id": 1706, "seek": 479776, "start": 4822.16, "end": 4824.16, "text": " are essentially special cases of what are", "tokens": [51584, 366, 4476, 2121, 3331, 295, 437, 366, 51684], "temperature": 0.0, "avg_logprob": -0.102850711508973, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.001924622687511146}, {"id": 1707, "seek": 479776, "start": 4824.16, "end": 4826.0, "text": " variously called Markov networks,", "tokens": [51684, 3683, 356, 1219, 3934, 5179, 9590, 11, 51776], "temperature": 0.0, "avg_logprob": -0.102850711508973, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.001924622687511146}, {"id": 1708, "seek": 482600, "start": 4826.0, "end": 4828.08, "text": " which is where the name Markov comes from.", "tokens": [50364, 597, 307, 689, 264, 1315, 3934, 5179, 1487, 490, 13, 50468], "temperature": 0.0, "avg_logprob": -0.11246812343597412, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.008299242705106735}, {"id": 1709, "seek": 482600, "start": 4828.08, "end": 4830.96, "text": " Or graphical models, or log linear models,", "tokens": [50468, 1610, 35942, 5245, 11, 420, 3565, 8213, 5245, 11, 50612], "temperature": 0.0, "avg_logprob": -0.11246812343597412, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.008299242705106735}, {"id": 1710, "seek": 482600, "start": 4830.96, "end": 4834.16, "text": " Gibbs distributions, Boltzmann machines, right?", "tokens": [50612, 30199, 37870, 11, 37884, 89, 14912, 8379, 11, 558, 30, 50772], "temperature": 0.0, "avg_logprob": -0.11246812343597412, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.008299242705106735}, {"id": 1711, "seek": 482600, "start": 4834.16, "end": 4836.48, "text": " All of these things are essentially the same, right?", "tokens": [50772, 1057, 295, 613, 721, 366, 4476, 264, 912, 11, 558, 30, 50888], "temperature": 0.0, "avg_logprob": -0.11246812343597412, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.008299242705106735}, {"id": 1712, "seek": 482600, "start": 4836.48, "end": 4839.44, "text": " That whole neck of the woods is captured by Markov networks.", "tokens": [50888, 663, 1379, 6189, 295, 264, 15296, 307, 11828, 538, 3934, 5179, 9590, 13, 51036], "temperature": 0.0, "avg_logprob": -0.11246812343597412, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.008299242705106735}, {"id": 1713, "seek": 482600, "start": 4839.44, "end": 4840.24, "text": " Let's call them that.", "tokens": [51036, 961, 311, 818, 552, 300, 13, 51076], "temperature": 0.0, "avg_logprob": -0.11246812343597412, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.008299242705106735}, {"id": 1714, "seek": 482600, "start": 4841.2, "end": 4843.84, "text": " And Markov logic is combining Markov networks", "tokens": [51124, 400, 3934, 5179, 9952, 307, 21928, 3934, 5179, 9590, 51256], "temperature": 0.0, "avg_logprob": -0.11246812343597412, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.008299242705106735}, {"id": 1715, "seek": 482600, "start": 4843.84, "end": 4845.92, "text": " with first order logic in a single language,", "tokens": [51256, 365, 700, 1668, 9952, 294, 257, 2167, 2856, 11, 51360], "temperature": 0.0, "avg_logprob": -0.11246812343597412, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.008299242705106735}, {"id": 1716, "seek": 482600, "start": 4845.92, "end": 4847.84, "text": " which you can now do everything with.", "tokens": [51360, 597, 291, 393, 586, 360, 1203, 365, 13, 51456], "temperature": 0.0, "avg_logprob": -0.11246812343597412, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.008299242705106735}, {"id": 1717, "seek": 482600, "start": 4847.84, "end": 4848.48, "text": " Okay, okay.", "tokens": [51456, 1033, 11, 1392, 13, 51488], "temperature": 0.0, "avg_logprob": -0.11246812343597412, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.008299242705106735}, {"id": 1718, "seek": 482600, "start": 4848.48, "end": 4850.96, "text": " So just to like push back a tiny bit.", "tokens": [51488, 407, 445, 281, 411, 2944, 646, 257, 5870, 857, 13, 51612], "temperature": 0.0, "avg_logprob": -0.11246812343597412, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.008299242705106735}, {"id": 1719, "seek": 482600, "start": 4850.96, "end": 4853.76, "text": " So in the past, we've tried to create,", "tokens": [51612, 407, 294, 264, 1791, 11, 321, 600, 3031, 281, 1884, 11, 51752], "temperature": 0.0, "avg_logprob": -0.11246812343597412, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.008299242705106735}, {"id": 1720, "seek": 485376, "start": 4854.72, "end": 4856.0, "text": " let's say things like psych,", "tokens": [50412, 718, 311, 584, 721, 411, 4681, 11, 50476], "temperature": 0.0, "avg_logprob": -0.1205885750906808, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.004211603198200464}, {"id": 1721, "seek": 485376, "start": 4856.0, "end": 4858.72, "text": " which is a knowledge representation of the world.", "tokens": [50476, 597, 307, 257, 3601, 10290, 295, 264, 1002, 13, 50612], "temperature": 0.0, "avg_logprob": -0.1205885750906808, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.004211603198200464}, {"id": 1722, "seek": 485376, "start": 4858.72, "end": 4861.12, "text": " Folks like Montague have tried to do semantics", "tokens": [50612, 39275, 411, 7947, 4918, 362, 3031, 281, 360, 4361, 45298, 50732], "temperature": 0.0, "avg_logprob": -0.1205885750906808, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.004211603198200464}, {"id": 1723, "seek": 485376, "start": 4861.12, "end": 4863.76, "text": " using first order logic to set some,", "tokens": [50732, 1228, 700, 1668, 9952, 281, 992, 512, 11, 50864], "temperature": 0.0, "avg_logprob": -0.1205885750906808, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.004211603198200464}, {"id": 1724, "seek": 485376, "start": 4863.76, "end": 4865.76, "text": " you know, varying degrees of success.", "tokens": [50864, 291, 458, 11, 22984, 5310, 295, 2245, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1205885750906808, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.004211603198200464}, {"id": 1725, "seek": 485376, "start": 4865.76, "end": 4867.12, "text": " And then we have the grounding problem", "tokens": [50964, 400, 550, 321, 362, 264, 46727, 1154, 51032], "temperature": 0.0, "avg_logprob": -0.1205885750906808, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.004211603198200464}, {"id": 1726, "seek": 485376, "start": 4867.12, "end": 4869.4400000000005, "text": " we were just talking before about, you know,", "tokens": [51032, 321, 645, 445, 1417, 949, 466, 11, 291, 458, 11, 51148], "temperature": 0.0, "avg_logprob": -0.1205885750906808, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.004211603198200464}, {"id": 1727, "seek": 485376, "start": 4869.4400000000005, "end": 4870.4800000000005, "text": " like even Searle said this,", "tokens": [51148, 411, 754, 1100, 36153, 848, 341, 11, 51200], "temperature": 0.0, "avg_logprob": -0.1205885750906808, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.004211603198200464}, {"id": 1728, "seek": 485376, "start": 4870.4800000000005, "end": 4873.84, "text": " that you have kind of epistemic objectivity", "tokens": [51200, 300, 291, 362, 733, 295, 2388, 468, 3438, 2657, 4253, 51368], "temperature": 0.0, "avg_logprob": -0.1205885750906808, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.004211603198200464}, {"id": 1729, "seek": 485376, "start": 4873.84, "end": 4876.320000000001, "text": " and subjectivity and some things are observer relative,", "tokens": [51368, 293, 3983, 4253, 293, 512, 721, 366, 27878, 4972, 11, 51492], "temperature": 0.0, "avg_logprob": -0.1205885750906808, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.004211603198200464}, {"id": 1730, "seek": 485376, "start": 4876.320000000001, "end": 4878.56, "text": " like even economics is observer relative.", "tokens": [51492, 411, 754, 14564, 307, 27878, 4972, 13, 51604], "temperature": 0.0, "avg_logprob": -0.1205885750906808, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.004211603198200464}, {"id": 1731, "seek": 485376, "start": 4878.56, "end": 4882.08, "text": " So with this kind of formalism, how would that work?", "tokens": [51604, 407, 365, 341, 733, 295, 9860, 1434, 11, 577, 576, 300, 589, 30, 51780], "temperature": 0.0, "avg_logprob": -0.1205885750906808, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.004211603198200464}, {"id": 1732, "seek": 485376, "start": 4882.08, "end": 4883.280000000001, "text": " That's so very good.", "tokens": [51780, 663, 311, 370, 588, 665, 13, 51840], "temperature": 0.0, "avg_logprob": -0.1205885750906808, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.004211603198200464}, {"id": 1733, "seek": 488328, "start": 4883.28, "end": 4885.599999999999, "text": " The problem with or the main problem", "tokens": [50364, 440, 1154, 365, 420, 264, 2135, 1154, 50480], "temperature": 0.0, "avg_logprob": -0.10911094441133387, "compression_ratio": 1.7824561403508772, "no_speech_prob": 0.0014760963385924697}, {"id": 1734, "seek": 488328, "start": 4885.599999999999, "end": 4887.5199999999995, "text": " with a lot of these things that you mentioned,", "tokens": [50480, 365, 257, 688, 295, 613, 721, 300, 291, 2835, 11, 50576], "temperature": 0.0, "avg_logprob": -0.10911094441133387, "compression_ratio": 1.7824561403508772, "no_speech_prob": 0.0014760963385924697}, {"id": 1735, "seek": 488328, "start": 4887.5199999999995, "end": 4889.92, "text": " like, you know, certain types of semantics and whatnot,", "tokens": [50576, 411, 11, 291, 458, 11, 1629, 3467, 295, 4361, 45298, 293, 25882, 11, 50696], "temperature": 0.0, "avg_logprob": -0.10911094441133387, "compression_ratio": 1.7824561403508772, "no_speech_prob": 0.0014760963385924697}, {"id": 1736, "seek": 488328, "start": 4889.92, "end": 4892.24, "text": " that are based essentially on first order logic, right?", "tokens": [50696, 300, 366, 2361, 4476, 322, 700, 1668, 9952, 11, 558, 30, 50812], "temperature": 0.0, "avg_logprob": -0.10911094441133387, "compression_ratio": 1.7824561403508772, "no_speech_prob": 0.0014760963385924697}, {"id": 1737, "seek": 488328, "start": 4892.24, "end": 4893.36, "text": " Is that they're too brittle.", "tokens": [50812, 1119, 300, 436, 434, 886, 49325, 13, 50868], "temperature": 0.0, "avg_logprob": -0.10911094441133387, "compression_ratio": 1.7824561403508772, "no_speech_prob": 0.0014760963385924697}, {"id": 1738, "seek": 488328, "start": 4894.0, "end": 4897.599999999999, "text": " In fact, the problem with symbolic AI is that it's too brittle.", "tokens": [50900, 682, 1186, 11, 264, 1154, 365, 25755, 7318, 307, 300, 309, 311, 886, 49325, 13, 51080], "temperature": 0.0, "avg_logprob": -0.10911094441133387, "compression_ratio": 1.7824561403508772, "no_speech_prob": 0.0014760963385924697}, {"id": 1739, "seek": 488328, "start": 4898.16, "end": 4901.04, "text": " And this is exactly what Markov logic fixes.", "tokens": [51108, 400, 341, 307, 2293, 437, 3934, 5179, 9952, 32539, 13, 51252], "temperature": 0.0, "avg_logprob": -0.10911094441133387, "compression_ratio": 1.7824561403508772, "no_speech_prob": 0.0014760963385924697}, {"id": 1740, "seek": 488328, "start": 4901.04, "end": 4903.44, "text": " It fixes it by making it statistical.", "tokens": [51252, 467, 32539, 309, 538, 1455, 309, 22820, 13, 51372], "temperature": 0.0, "avg_logprob": -0.10911094441133387, "compression_ratio": 1.7824561403508772, "no_speech_prob": 0.0014760963385924697}, {"id": 1741, "seek": 488328, "start": 4903.44, "end": 4905.28, "text": " When I give you a logical statement now,", "tokens": [51372, 1133, 286, 976, 291, 257, 14978, 5629, 586, 11, 51464], "temperature": 0.0, "avg_logprob": -0.10911094441133387, "compression_ratio": 1.7824561403508772, "no_speech_prob": 0.0014760963385924697}, {"id": 1742, "seek": 488328, "start": 4905.28, "end": 4907.44, "text": " I'm no longer, for example, simple logical statement,", "tokens": [51464, 286, 478, 572, 2854, 11, 337, 1365, 11, 2199, 14978, 5629, 11, 51572], "temperature": 0.0, "avg_logprob": -0.10911094441133387, "compression_ratio": 1.7824561403508772, "no_speech_prob": 0.0014760963385924697}, {"id": 1743, "seek": 488328, "start": 4908.24, "end": 4910.96, "text": " you know, a smoking causes cancer, right?", "tokens": [51612, 291, 458, 11, 257, 14055, 7700, 5592, 11, 558, 30, 51748], "temperature": 0.0, "avg_logprob": -0.10911094441133387, "compression_ratio": 1.7824561403508772, "no_speech_prob": 0.0014760963385924697}, {"id": 1744, "seek": 491096, "start": 4911.68, "end": 4913.52, "text": " In English, this is a valid statement.", "tokens": [50400, 682, 3669, 11, 341, 307, 257, 7363, 5629, 13, 50492], "temperature": 0.0, "avg_logprob": -0.10977205053552405, "compression_ratio": 1.752411575562701, "no_speech_prob": 0.0031213865149766207}, {"id": 1745, "seek": 491096, "start": 4913.52, "end": 4914.88, "text": " Smoking does cause cancer.", "tokens": [50492, 3915, 5953, 775, 3082, 5592, 13, 50560], "temperature": 0.0, "avg_logprob": -0.10977205053552405, "compression_ratio": 1.752411575562701, "no_speech_prob": 0.0031213865149766207}, {"id": 1746, "seek": 491096, "start": 4914.88, "end": 4916.64, "text": " But actually, once you translate it to logic", "tokens": [50560, 583, 767, 11, 1564, 291, 13799, 309, 281, 9952, 50648], "temperature": 0.0, "avg_logprob": -0.10977205053552405, "compression_ratio": 1.752411575562701, "no_speech_prob": 0.0031213865149766207}, {"id": 1747, "seek": 491096, "start": 4916.64, "end": 4919.28, "text": " for every x, smokes of x implies cancer of x,", "tokens": [50648, 337, 633, 2031, 11, 49592, 295, 2031, 18779, 5592, 295, 2031, 11, 50780], "temperature": 0.0, "avg_logprob": -0.10977205053552405, "compression_ratio": 1.752411575562701, "no_speech_prob": 0.0031213865149766207}, {"id": 1748, "seek": 491096, "start": 4919.28, "end": 4922.32, "text": " it's false because some smokers don't get cancer, right?", "tokens": [50780, 309, 311, 7908, 570, 512, 32073, 433, 500, 380, 483, 5592, 11, 558, 30, 50932], "temperature": 0.0, "avg_logprob": -0.10977205053552405, "compression_ratio": 1.752411575562701, "no_speech_prob": 0.0031213865149766207}, {"id": 1749, "seek": 491096, "start": 4922.32, "end": 4924.16, "text": " What this really was meant to be all along", "tokens": [50932, 708, 341, 534, 390, 4140, 281, 312, 439, 2051, 51024], "temperature": 0.0, "avg_logprob": -0.10977205053552405, "compression_ratio": 1.752411575562701, "no_speech_prob": 0.0031213865149766207}, {"id": 1750, "seek": 491096, "start": 4924.16, "end": 4926.24, "text": " is a statistical statement that says,", "tokens": [51024, 307, 257, 22820, 5629, 300, 1619, 11, 51128], "temperature": 0.0, "avg_logprob": -0.10977205053552405, "compression_ratio": 1.752411575562701, "no_speech_prob": 0.0031213865149766207}, {"id": 1751, "seek": 491096, "start": 4926.24, "end": 4928.24, "text": " smokers are more likely to get cancer.", "tokens": [51128, 32073, 433, 366, 544, 3700, 281, 483, 5592, 13, 51228], "temperature": 0.0, "avg_logprob": -0.10977205053552405, "compression_ratio": 1.752411575562701, "no_speech_prob": 0.0031213865149766207}, {"id": 1752, "seek": 491096, "start": 4929.12, "end": 4931.52, "text": " So the way we overcome a lot of those problems", "tokens": [51272, 407, 264, 636, 321, 10473, 257, 688, 295, 729, 2740, 51392], "temperature": 0.0, "avg_logprob": -0.10977205053552405, "compression_ratio": 1.752411575562701, "no_speech_prob": 0.0031213865149766207}, {"id": 1753, "seek": 491096, "start": 4931.52, "end": 4934.56, "text": " is precisely that we take all of this logic,", "tokens": [51392, 307, 13402, 300, 321, 747, 439, 295, 341, 9952, 11, 51544], "temperature": 0.0, "avg_logprob": -0.10977205053552405, "compression_ratio": 1.752411575562701, "no_speech_prob": 0.0031213865149766207}, {"id": 1754, "seek": 491096, "start": 4934.56, "end": 4935.92, "text": " which again, the language exists,", "tokens": [51544, 597, 797, 11, 264, 2856, 8198, 11, 51612], "temperature": 0.0, "avg_logprob": -0.10977205053552405, "compression_ratio": 1.752411575562701, "no_speech_prob": 0.0031213865149766207}, {"id": 1755, "seek": 491096, "start": 4935.92, "end": 4938.4800000000005, "text": " we don't have to change it, we can, but we don't have to.", "tokens": [51612, 321, 500, 380, 362, 281, 1319, 309, 11, 321, 393, 11, 457, 321, 500, 380, 362, 281, 13, 51740], "temperature": 0.0, "avg_logprob": -0.10977205053552405, "compression_ratio": 1.752411575562701, "no_speech_prob": 0.0031213865149766207}, {"id": 1756, "seek": 491096, "start": 4938.4800000000005, "end": 4939.92, "text": " And we make it statistical.", "tokens": [51740, 400, 321, 652, 309, 22820, 13, 51812], "temperature": 0.0, "avg_logprob": -0.10977205053552405, "compression_ratio": 1.752411575562701, "no_speech_prob": 0.0031213865149766207}, {"id": 1757, "seek": 493992, "start": 4940.4800000000005, "end": 4942.8, "text": " As a result of which, it's no longer brittle.", "tokens": [50392, 1018, 257, 1874, 295, 597, 11, 309, 311, 572, 2854, 49325, 13, 50508], "temperature": 0.0, "avg_logprob": -0.14599994946551578, "compression_ratio": 1.7320441988950277, "no_speech_prob": 0.015601320192217827}, {"id": 1758, "seek": 493992, "start": 4942.8, "end": 4944.24, "text": " Or at least now it's only as brittle", "tokens": [50508, 1610, 412, 1935, 586, 309, 311, 787, 382, 49325, 50580], "temperature": 0.0, "avg_logprob": -0.14599994946551578, "compression_ratio": 1.7320441988950277, "no_speech_prob": 0.015601320192217827}, {"id": 1759, "seek": 493992, "start": 4944.24, "end": 4946.32, "text": " as machine learning and graphical model or not.", "tokens": [50580, 382, 3479, 2539, 293, 35942, 2316, 420, 406, 13, 50684], "temperature": 0.0, "avg_logprob": -0.14599994946551578, "compression_ratio": 1.7320441988950277, "no_speech_prob": 0.015601320192217827}, {"id": 1760, "seek": 493992, "start": 4946.32, "end": 4949.4400000000005, "text": " It's not as brittle as, you know, traditional symbolic AI.", "tokens": [50684, 467, 311, 406, 382, 49325, 382, 11, 291, 458, 11, 5164, 25755, 7318, 13, 50840], "temperature": 0.0, "avg_logprob": -0.14599994946551578, "compression_ratio": 1.7320441988950277, "no_speech_prob": 0.015601320192217827}, {"id": 1761, "seek": 493992, "start": 4949.4400000000005, "end": 4951.52, "text": " Okay. And so we speak into a lot of Go-Fi people", "tokens": [50840, 1033, 13, 400, 370, 321, 1710, 666, 257, 688, 295, 1037, 12, 13229, 561, 50944], "temperature": 0.0, "avg_logprob": -0.14599994946551578, "compression_ratio": 1.7320441988950277, "no_speech_prob": 0.015601320192217827}, {"id": 1762, "seek": 493992, "start": 4951.52, "end": 4953.68, "text": " and I mean, Wally Subba, for example, he's a rationalist", "tokens": [50944, 293, 286, 914, 11, 343, 379, 8511, 4231, 11, 337, 1365, 11, 415, 311, 257, 15090, 468, 51052], "temperature": 0.0, "avg_logprob": -0.14599994946551578, "compression_ratio": 1.7320441988950277, "no_speech_prob": 0.015601320192217827}, {"id": 1763, "seek": 493992, "start": 4953.68, "end": 4955.04, "text": " and what's interesting about the rationalist", "tokens": [51052, 293, 437, 311, 1880, 466, 264, 15090, 468, 51120], "temperature": 0.0, "avg_logprob": -0.14599994946551578, "compression_ratio": 1.7320441988950277, "no_speech_prob": 0.015601320192217827}, {"id": 1764, "seek": 493992, "start": 4955.04, "end": 4957.92, "text": " is they hate any form of uncertainty, right?", "tokens": [51120, 307, 436, 4700, 604, 1254, 295, 15697, 11, 558, 30, 51264], "temperature": 0.0, "avg_logprob": -0.14599994946551578, "compression_ratio": 1.7320441988950277, "no_speech_prob": 0.015601320192217827}, {"id": 1765, "seek": 493992, "start": 4957.92, "end": 4959.36, "text": " They think in absolute binaries.", "tokens": [51264, 814, 519, 294, 8236, 5171, 4889, 13, 51336], "temperature": 0.0, "avg_logprob": -0.14599994946551578, "compression_ratio": 1.7320441988950277, "no_speech_prob": 0.015601320192217827}, {"id": 1766, "seek": 493992, "start": 4959.36, "end": 4960.4, "text": " You either know it or you don't.", "tokens": [51336, 509, 2139, 458, 309, 420, 291, 500, 380, 13, 51388], "temperature": 0.0, "avg_logprob": -0.14599994946551578, "compression_ratio": 1.7320441988950277, "no_speech_prob": 0.015601320192217827}, {"id": 1767, "seek": 493992, "start": 4960.4, "end": 4962.16, "text": " No, I mean, let me push back on that.", "tokens": [51388, 883, 11, 286, 914, 11, 718, 385, 2944, 646, 322, 300, 13, 51476], "temperature": 0.0, "avg_logprob": -0.14599994946551578, "compression_ratio": 1.7320441988950277, "no_speech_prob": 0.015601320192217827}, {"id": 1768, "seek": 493992, "start": 4962.16, "end": 4964.4800000000005, "text": " There's this, again, you need to distinguish, you know,", "tokens": [51476, 821, 311, 341, 11, 797, 11, 291, 643, 281, 20206, 11, 291, 458, 11, 51592], "temperature": 0.0, "avg_logprob": -0.14599994946551578, "compression_ratio": 1.7320441988950277, "no_speech_prob": 0.015601320192217827}, {"id": 1769, "seek": 493992, "start": 4964.4800000000005, "end": 4967.76, "text": " a general field or idea from its subtypes, right?", "tokens": [51592, 257, 2674, 2519, 420, 1558, 490, 1080, 1422, 874, 5190, 11, 558, 30, 51756], "temperature": 0.0, "avg_logprob": -0.14599994946551578, "compression_ratio": 1.7320441988950277, "no_speech_prob": 0.015601320192217827}, {"id": 1770, "seek": 493992, "start": 4967.76, "end": 4969.68, "text": " There is a type of rationalist.", "tokens": [51756, 821, 307, 257, 2010, 295, 15090, 468, 13, 51852], "temperature": 0.0, "avg_logprob": -0.14599994946551578, "compression_ratio": 1.7320441988950277, "no_speech_prob": 0.015601320192217827}, {"id": 1771, "seek": 496968, "start": 4969.76, "end": 4973.280000000001, "text": " That hits uncertainty, big mistake, big, big mistake.", "tokens": [50368, 663, 8664, 15697, 11, 955, 6146, 11, 955, 11, 955, 6146, 13, 50544], "temperature": 0.0, "avg_logprob": -0.13007653144098097, "compression_ratio": 1.909871244635193, "no_speech_prob": 0.0013445140793919563}, {"id": 1772, "seek": 496968, "start": 4973.280000000001, "end": 4975.200000000001, "text": " There's a type of rationalist that, you know,", "tokens": [50544, 821, 311, 257, 2010, 295, 15090, 468, 300, 11, 291, 458, 11, 50640], "temperature": 0.0, "avg_logprob": -0.13007653144098097, "compression_ratio": 1.909871244635193, "no_speech_prob": 0.0013445140793919563}, {"id": 1773, "seek": 496968, "start": 4975.200000000001, "end": 4977.200000000001, "text": " uncertainty is what they, you know, like,", "tokens": [50640, 15697, 307, 437, 436, 11, 291, 458, 11, 411, 11, 50740], "temperature": 0.0, "avg_logprob": -0.13007653144098097, "compression_ratio": 1.909871244635193, "no_speech_prob": 0.0013445140793919563}, {"id": 1774, "seek": 496968, "start": 4978.72, "end": 4981.84, "text": " an uncertainty calculus is a type of rationalism.", "tokens": [50816, 364, 15697, 33400, 307, 257, 2010, 295, 15090, 1434, 13, 50972], "temperature": 0.0, "avg_logprob": -0.13007653144098097, "compression_ratio": 1.909871244635193, "no_speech_prob": 0.0013445140793919563}, {"id": 1775, "seek": 496968, "start": 4981.84, "end": 4984.64, "text": " And some of the best, you know, AI, philosophy, etc.", "tokens": [50972, 400, 512, 295, 264, 1151, 11, 291, 458, 11, 7318, 11, 10675, 11, 5183, 13, 51112], "temperature": 0.0, "avg_logprob": -0.13007653144098097, "compression_ratio": 1.909871244635193, "no_speech_prob": 0.0013445140793919563}, {"id": 1776, "seek": 496968, "start": 4984.64, "end": 4985.280000000001, "text": " is just that.", "tokens": [51112, 307, 445, 300, 13, 51144], "temperature": 0.0, "avg_logprob": -0.13007653144098097, "compression_ratio": 1.909871244635193, "no_speech_prob": 0.0013445140793919563}, {"id": 1777, "seek": 496968, "start": 4985.280000000001, "end": 4987.92, "text": " So there is no incompatibility at all", "tokens": [51144, 407, 456, 307, 572, 40393, 267, 2841, 412, 439, 51276], "temperature": 0.0, "avg_logprob": -0.13007653144098097, "compression_ratio": 1.909871244635193, "no_speech_prob": 0.0013445140793919563}, {"id": 1778, "seek": 496968, "start": 4987.92, "end": 4989.52, "text": " between rationalism and uncertainty.", "tokens": [51276, 1296, 15090, 1434, 293, 15697, 13, 51356], "temperature": 0.0, "avg_logprob": -0.13007653144098097, "compression_ratio": 1.909871244635193, "no_speech_prob": 0.0013445140793919563}, {"id": 1779, "seek": 496968, "start": 4989.52, "end": 4993.6, "text": " In fact, if rationalism, if being rational is maximizing", "tokens": [51356, 682, 1186, 11, 498, 15090, 1434, 11, 498, 885, 15090, 307, 5138, 3319, 51560], "temperature": 0.0, "avg_logprob": -0.13007653144098097, "compression_ratio": 1.909871244635193, "no_speech_prob": 0.0013445140793919563}, {"id": 1780, "seek": 496968, "start": 4993.6, "end": 4997.12, "text": " expected utility, notice the expected in there, right?", "tokens": [51560, 5176, 14877, 11, 3449, 264, 5176, 294, 456, 11, 558, 30, 51736], "temperature": 0.0, "avg_logprob": -0.13007653144098097, "compression_ratio": 1.909871244635193, "no_speech_prob": 0.0013445140793919563}, {"id": 1781, "seek": 499712, "start": 4997.12, "end": 5000.16, "text": " You cannot be rational if you ignore the uncertainty.", "tokens": [50364, 509, 2644, 312, 15090, 498, 291, 11200, 264, 15697, 13, 50516], "temperature": 0.0, "avg_logprob": -0.10752825115038, "compression_ratio": 1.6996805111821087, "no_speech_prob": 0.0020638357382267714}, {"id": 1782, "seek": 499712, "start": 5000.16, "end": 5000.8, "text": " Interesting.", "tokens": [50516, 14711, 13, 50548], "temperature": 0.0, "avg_logprob": -0.10752825115038, "compression_ratio": 1.6996805111821087, "no_speech_prob": 0.0020638357382267714}, {"id": 1783, "seek": 499712, "start": 5000.8, "end": 5003.68, "text": " Okay, but then what about the resolution of modeling?", "tokens": [50548, 1033, 11, 457, 550, 437, 466, 264, 8669, 295, 15983, 30, 50692], "temperature": 0.0, "avg_logprob": -0.10752825115038, "compression_ratio": 1.6996805111821087, "no_speech_prob": 0.0020638357382267714}, {"id": 1784, "seek": 499712, "start": 5003.68, "end": 5005.68, "text": " I mean, smoking is a really good one.", "tokens": [50692, 286, 914, 11, 14055, 307, 257, 534, 665, 472, 13, 50792], "temperature": 0.0, "avg_logprob": -0.10752825115038, "compression_ratio": 1.6996805111821087, "no_speech_prob": 0.0020638357382267714}, {"id": 1785, "seek": 499712, "start": 5005.68, "end": 5008.32, "text": " So us humans, we anthropomorphize things.", "tokens": [50792, 407, 505, 6255, 11, 321, 22727, 32702, 1125, 721, 13, 50924], "temperature": 0.0, "avg_logprob": -0.10752825115038, "compression_ratio": 1.6996805111821087, "no_speech_prob": 0.0020638357382267714}, {"id": 1786, "seek": 499712, "start": 5008.32, "end": 5010.64, "text": " We understand the world in macroscopic terms", "tokens": [50924, 492, 1223, 264, 1002, 294, 7912, 38006, 299, 2115, 51040], "temperature": 0.0, "avg_logprob": -0.10752825115038, "compression_ratio": 1.6996805111821087, "no_speech_prob": 0.0020638357382267714}, {"id": 1787, "seek": 499712, "start": 5010.64, "end": 5013.36, "text": " using macroscopic ideas that we understand.", "tokens": [51040, 1228, 7912, 38006, 299, 3487, 300, 321, 1223, 13, 51176], "temperature": 0.0, "avg_logprob": -0.10752825115038, "compression_ratio": 1.6996805111821087, "no_speech_prob": 0.0020638357382267714}, {"id": 1788, "seek": 499712, "start": 5013.36, "end": 5015.76, "text": " And that kind of leads to a certain type of modeling.", "tokens": [51176, 400, 300, 733, 295, 6689, 281, 257, 1629, 2010, 295, 15983, 13, 51296], "temperature": 0.0, "avg_logprob": -0.10752825115038, "compression_ratio": 1.6996805111821087, "no_speech_prob": 0.0020638357382267714}, {"id": 1789, "seek": 499712, "start": 5015.76, "end": 5017.84, "text": " And that modeling presumably would be represented", "tokens": [51296, 400, 300, 15983, 26742, 576, 312, 10379, 51400], "temperature": 0.0, "avg_logprob": -0.10752825115038, "compression_ratio": 1.6996805111821087, "no_speech_prob": 0.0020638357382267714}, {"id": 1790, "seek": 499712, "start": 5017.84, "end": 5020.32, "text": " at that resolution, you know, using this formalism.", "tokens": [51400, 412, 300, 8669, 11, 291, 458, 11, 1228, 341, 9860, 1434, 13, 51524], "temperature": 0.0, "avg_logprob": -0.10752825115038, "compression_ratio": 1.6996805111821087, "no_speech_prob": 0.0020638357382267714}, {"id": 1791, "seek": 499712, "start": 5021.36, "end": 5022.8, "text": " Sure. And what's the question?", "tokens": [51576, 4894, 13, 400, 437, 311, 264, 1168, 30, 51648], "temperature": 0.0, "avg_logprob": -0.10752825115038, "compression_ratio": 1.6996805111821087, "no_speech_prob": 0.0020638357382267714}, {"id": 1792, "seek": 499712, "start": 5022.8, "end": 5026.16, "text": " Well, it seemed, again, like I'm intuitively suspicious", "tokens": [51648, 1042, 11, 309, 6576, 11, 797, 11, 411, 286, 478, 46506, 17931, 51816], "temperature": 0.0, "avg_logprob": -0.10752825115038, "compression_ratio": 1.6996805111821087, "no_speech_prob": 0.0020638357382267714}, {"id": 1793, "seek": 502616, "start": 5026.16, "end": 5028.48, "text": " that we were just saying the world is a complex place.", "tokens": [50364, 300, 321, 645, 445, 1566, 264, 1002, 307, 257, 3997, 1081, 13, 50480], "temperature": 0.0, "avg_logprob": -0.09222049077351888, "compression_ratio": 1.8365384615384615, "no_speech_prob": 0.005627221893519163}, {"id": 1794, "seek": 502616, "start": 5028.48, "end": 5030.96, "text": " And with a lot of causal modeling, for example,", "tokens": [50480, 400, 365, 257, 688, 295, 38755, 15983, 11, 337, 1365, 11, 50604], "temperature": 0.0, "avg_logprob": -0.09222049077351888, "compression_ratio": 1.8365384615384615, "no_speech_prob": 0.005627221893519163}, {"id": 1795, "seek": 502616, "start": 5030.96, "end": 5033.44, "text": " a lot of the art is understanding what is relevant", "tokens": [50604, 257, 688, 295, 264, 1523, 307, 3701, 437, 307, 7340, 50728], "temperature": 0.0, "avg_logprob": -0.09222049077351888, "compression_ratio": 1.8365384615384615, "no_speech_prob": 0.005627221893519163}, {"id": 1796, "seek": 502616, "start": 5033.44, "end": 5034.88, "text": " and what is not relevant.", "tokens": [50728, 293, 437, 307, 406, 7340, 13, 50800], "temperature": 0.0, "avg_logprob": -0.09222049077351888, "compression_ratio": 1.8365384615384615, "no_speech_prob": 0.005627221893519163}, {"id": 1797, "seek": 502616, "start": 5034.88, "end": 5038.08, "text": " What is relevant might just be kind of, you know, relevant to us.", "tokens": [50800, 708, 307, 7340, 1062, 445, 312, 733, 295, 11, 291, 458, 11, 7340, 281, 505, 13, 50960], "temperature": 0.0, "avg_logprob": -0.09222049077351888, "compression_ratio": 1.8365384615384615, "no_speech_prob": 0.005627221893519163}, {"id": 1798, "seek": 502616, "start": 5038.639999999999, "end": 5041.12, "text": " No, well, what is relevant is what is relevant", "tokens": [50988, 883, 11, 731, 11, 437, 307, 7340, 307, 437, 307, 7340, 51112], "temperature": 0.0, "avg_logprob": -0.09222049077351888, "compression_ratio": 1.8365384615384615, "no_speech_prob": 0.005627221893519163}, {"id": 1799, "seek": 502616, "start": 5041.12, "end": 5042.8, "text": " relative to your utility function.", "tokens": [51112, 4972, 281, 428, 14877, 2445, 13, 51196], "temperature": 0.0, "avg_logprob": -0.09222049077351888, "compression_ratio": 1.8365384615384615, "no_speech_prob": 0.005627221893519163}, {"id": 1800, "seek": 502616, "start": 5043.5199999999995, "end": 5046.48, "text": " Okay, again, it gets back to that precisely.", "tokens": [51232, 1033, 11, 797, 11, 309, 2170, 646, 281, 300, 13402, 13, 51380], "temperature": 0.0, "avg_logprob": -0.09222049077351888, "compression_ratio": 1.8365384615384615, "no_speech_prob": 0.005627221893519163}, {"id": 1801, "seek": 502616, "start": 5047.68, "end": 5049.92, "text": " The whole problem is that the world is infinitely complex", "tokens": [51440, 440, 1379, 1154, 307, 300, 264, 1002, 307, 36227, 3997, 51552], "temperature": 0.0, "avg_logprob": -0.09222049077351888, "compression_ratio": 1.8365384615384615, "no_speech_prob": 0.005627221893519163}, {"id": 1802, "seek": 502616, "start": 5049.92, "end": 5051.92, "text": " and we have only finite computational resources,", "tokens": [51552, 293, 321, 362, 787, 19362, 28270, 3593, 11, 51652], "temperature": 0.0, "avg_logprob": -0.09222049077351888, "compression_ratio": 1.8365384615384615, "no_speech_prob": 0.005627221893519163}, {"id": 1803, "seek": 502616, "start": 5051.92, "end": 5054.08, "text": " whether it's in our brains or our computers or whatever, right?", "tokens": [51652, 1968, 309, 311, 294, 527, 15442, 420, 527, 10807, 420, 2035, 11, 558, 30, 51760], "temperature": 0.0, "avg_logprob": -0.09222049077351888, "compression_ratio": 1.8365384615384615, "no_speech_prob": 0.005627221893519163}, {"id": 1804, "seek": 502616, "start": 5054.08, "end": 5055.28, "text": " So now what do you do, right?", "tokens": [51760, 407, 586, 437, 360, 291, 360, 11, 558, 30, 51820], "temperature": 0.0, "avg_logprob": -0.09222049077351888, "compression_ratio": 1.8365384615384615, "no_speech_prob": 0.005627221893519163}, {"id": 1805, "seek": 505528, "start": 5055.36, "end": 5058.16, "text": " You are forced to oversimplify the world,", "tokens": [50368, 509, 366, 7579, 281, 15488, 332, 564, 2505, 264, 1002, 11, 50508], "temperature": 0.0, "avg_logprob": -0.10214482820951022, "compression_ratio": 1.7633587786259541, "no_speech_prob": 0.016892677173018456}, {"id": 1806, "seek": 505528, "start": 5058.16, "end": 5060.8, "text": " not just simplify, but oversimplify, right?", "tokens": [50508, 406, 445, 20460, 11, 457, 15488, 332, 564, 2505, 11, 558, 30, 50640], "temperature": 0.0, "avg_logprob": -0.10214482820951022, "compression_ratio": 1.7633587786259541, "no_speech_prob": 0.016892677173018456}, {"id": 1807, "seek": 505528, "start": 5060.8, "end": 5063.2, "text": " But now the whole art, that's actually a good word to use,", "tokens": [50640, 583, 586, 264, 1379, 1523, 11, 300, 311, 767, 257, 665, 1349, 281, 764, 11, 50760], "temperature": 0.0, "avg_logprob": -0.10214482820951022, "compression_ratio": 1.7633587786259541, "no_speech_prob": 0.016892677173018456}, {"id": 1808, "seek": 505528, "start": 5063.2, "end": 5064.48, "text": " even if it's done with computers,", "tokens": [50760, 754, 498, 309, 311, 1096, 365, 10807, 11, 50824], "temperature": 0.0, "avg_logprob": -0.10214482820951022, "compression_ratio": 1.7633587786259541, "no_speech_prob": 0.016892677173018456}, {"id": 1809, "seek": 505528, "start": 5064.48, "end": 5068.96, "text": " is how do you not only oversimplify as little as you can,", "tokens": [50824, 307, 577, 360, 291, 406, 787, 15488, 332, 564, 2505, 382, 707, 382, 291, 393, 11, 51048], "temperature": 0.0, "avg_logprob": -0.10214482820951022, "compression_ratio": 1.7633587786259541, "no_speech_prob": 0.016892677173018456}, {"id": 1810, "seek": 505528, "start": 5069.5199999999995, "end": 5075.2, "text": " but pick out the simplifications that are least harmful to your objective.", "tokens": [51076, 457, 1888, 484, 264, 6883, 7833, 300, 366, 1935, 19727, 281, 428, 10024, 13, 51360], "temperature": 0.0, "avg_logprob": -0.10214482820951022, "compression_ratio": 1.7633587786259541, "no_speech_prob": 0.016892677173018456}, {"id": 1811, "seek": 505528, "start": 5075.2, "end": 5077.5199999999995, "text": " By the way, the art of the physicist,", "tokens": [51360, 3146, 264, 636, 11, 264, 1523, 295, 264, 42466, 11, 51476], "temperature": 0.0, "avg_logprob": -0.10214482820951022, "compression_ratio": 1.7633587786259541, "no_speech_prob": 0.016892677173018456}, {"id": 1812, "seek": 505528, "start": 5077.5199999999995, "end": 5080.96, "text": " physicist would tell you, is precisely doing this, right?", "tokens": [51476, 42466, 576, 980, 291, 11, 307, 13402, 884, 341, 11, 558, 30, 51648], "temperature": 0.0, "avg_logprob": -0.10214482820951022, "compression_ratio": 1.7633587786259541, "no_speech_prob": 0.016892677173018456}, {"id": 1813, "seek": 505528, "start": 5080.96, "end": 5083.84, "text": " Physicists are very good at deciding what to simplify.", "tokens": [51648, 15542, 299, 1751, 366, 588, 665, 412, 17990, 437, 281, 20460, 13, 51792], "temperature": 0.0, "avg_logprob": -0.10214482820951022, "compression_ratio": 1.7633587786259541, "no_speech_prob": 0.016892677173018456}, {"id": 1814, "seek": 508384, "start": 5083.84, "end": 5085.6, "text": " And in fact, almost, I think at some level,", "tokens": [50364, 400, 294, 1186, 11, 1920, 11, 286, 519, 412, 512, 1496, 11, 50452], "temperature": 0.0, "avg_logprob": -0.1062324341029337, "compression_ratio": 1.7375415282392026, "no_speech_prob": 0.010635252110660076}, {"id": 1815, "seek": 508384, "start": 5085.6, "end": 5087.76, "text": " almost any good scientist, this is what they do, right?", "tokens": [50452, 1920, 604, 665, 12662, 11, 341, 307, 437, 436, 360, 11, 558, 30, 50560], "temperature": 0.0, "avg_logprob": -0.1062324341029337, "compression_ratio": 1.7375415282392026, "no_speech_prob": 0.010635252110660076}, {"id": 1816, "seek": 508384, "start": 5087.76, "end": 5091.68, "text": " So, and now how do I decide what and how to simplify", "tokens": [50560, 407, 11, 293, 586, 577, 360, 286, 4536, 437, 293, 577, 281, 20460, 50756], "temperature": 0.0, "avg_logprob": -0.1062324341029337, "compression_ratio": 1.7375415282392026, "no_speech_prob": 0.010635252110660076}, {"id": 1817, "seek": 508384, "start": 5091.68, "end": 5094.64, "text": " is by relevance to my utility function, right?", "tokens": [50756, 307, 538, 32684, 281, 452, 14877, 2445, 11, 558, 30, 50904], "temperature": 0.0, "avg_logprob": -0.1062324341029337, "compression_ratio": 1.7375415282392026, "no_speech_prob": 0.010635252110660076}, {"id": 1818, "seek": 508384, "start": 5095.28, "end": 5097.28, "text": " I want to ignore parts of the world", "tokens": [50936, 286, 528, 281, 11200, 3166, 295, 264, 1002, 51036], "temperature": 0.0, "avg_logprob": -0.1062324341029337, "compression_ratio": 1.7375415282392026, "no_speech_prob": 0.010635252110660076}, {"id": 1819, "seek": 508384, "start": 5097.28, "end": 5100.8, "text": " that do not affect my utility function, number one, right?", "tokens": [51036, 300, 360, 406, 3345, 452, 14877, 2445, 11, 1230, 472, 11, 558, 30, 51212], "temperature": 0.0, "avg_logprob": -0.1062324341029337, "compression_ratio": 1.7375415282392026, "no_speech_prob": 0.010635252110660076}, {"id": 1820, "seek": 508384, "start": 5100.8, "end": 5103.04, "text": " And for example, the notion of conditional independence,", "tokens": [51212, 400, 337, 1365, 11, 264, 10710, 295, 27708, 14640, 11, 51324], "temperature": 0.0, "avg_logprob": -0.1062324341029337, "compression_ratio": 1.7375415282392026, "no_speech_prob": 0.010635252110660076}, {"id": 1821, "seek": 508384, "start": 5103.04, "end": 5105.4400000000005, "text": " which is the foundation of graphical models,", "tokens": [51324, 597, 307, 264, 7030, 295, 35942, 5245, 11, 51444], "temperature": 0.0, "avg_logprob": -0.1062324341029337, "compression_ratio": 1.7375415282392026, "no_speech_prob": 0.010635252110660076}, {"id": 1822, "seek": 508384, "start": 5105.4400000000005, "end": 5106.72, "text": " that's what the whole idea is.", "tokens": [51444, 300, 311, 437, 264, 1379, 1558, 307, 13, 51508], "temperature": 0.0, "avg_logprob": -0.1062324341029337, "compression_ratio": 1.7375415282392026, "no_speech_prob": 0.010635252110660076}, {"id": 1823, "seek": 508384, "start": 5106.72, "end": 5108.64, "text": " It's like, once I know these things,", "tokens": [51508, 467, 311, 411, 11, 1564, 286, 458, 613, 721, 11, 51604], "temperature": 0.0, "avg_logprob": -0.1062324341029337, "compression_ratio": 1.7375415282392026, "no_speech_prob": 0.010635252110660076}, {"id": 1824, "seek": 508384, "start": 5108.64, "end": 5110.32, "text": " I don't have to know about those others.", "tokens": [51604, 286, 500, 380, 362, 281, 458, 466, 729, 2357, 13, 51688], "temperature": 0.0, "avg_logprob": -0.1062324341029337, "compression_ratio": 1.7375415282392026, "no_speech_prob": 0.010635252110660076}, {"id": 1825, "seek": 508384, "start": 5110.32, "end": 5112.08, "text": " Thank God, right?", "tokens": [51688, 1044, 1265, 11, 558, 30, 51776], "temperature": 0.0, "avg_logprob": -0.1062324341029337, "compression_ratio": 1.7375415282392026, "no_speech_prob": 0.010635252110660076}, {"id": 1826, "seek": 511208, "start": 5112.08, "end": 5114.08, "text": " Okay, but if Ken Stanley was here,", "tokens": [50364, 1033, 11, 457, 498, 8273, 28329, 390, 510, 11, 50464], "temperature": 0.0, "avg_logprob": -0.11378580815083272, "compression_ratio": 1.7327044025157232, "no_speech_prob": 0.00646575540304184}, {"id": 1827, "seek": 511208, "start": 5114.08, "end": 5116.64, "text": " he says that the great thing about evolution is it's divergent,", "tokens": [50464, 415, 1619, 300, 264, 869, 551, 466, 9303, 307, 309, 311, 18558, 6930, 11, 50592], "temperature": 0.0, "avg_logprob": -0.11378580815083272, "compression_ratio": 1.7327044025157232, "no_speech_prob": 0.00646575540304184}, {"id": 1828, "seek": 511208, "start": 5116.64, "end": 5119.68, "text": " it's not convergent, it's discovering new information.", "tokens": [50592, 309, 311, 406, 9652, 6930, 11, 309, 311, 24773, 777, 1589, 13, 50744], "temperature": 0.0, "avg_logprob": -0.11378580815083272, "compression_ratio": 1.7327044025157232, "no_speech_prob": 0.00646575540304184}, {"id": 1829, "seek": 511208, "start": 5119.68, "end": 5121.6, "text": " And my worry is with a system like this,", "tokens": [50744, 400, 452, 3292, 307, 365, 257, 1185, 411, 341, 11, 50840], "temperature": 0.0, "avg_logprob": -0.11378580815083272, "compression_ratio": 1.7327044025157232, "no_speech_prob": 0.00646575540304184}, {"id": 1830, "seek": 511208, "start": 5121.6, "end": 5123.92, "text": " with any form of anthropomorphic design,", "tokens": [50840, 365, 604, 1254, 295, 22727, 32702, 299, 1715, 11, 50956], "temperature": 0.0, "avg_logprob": -0.11378580815083272, "compression_ratio": 1.7327044025157232, "no_speech_prob": 0.00646575540304184}, {"id": 1831, "seek": 511208, "start": 5123.92, "end": 5125.84, "text": " would inevitably become convergent.", "tokens": [50956, 576, 28171, 1813, 9652, 6930, 13, 51052], "temperature": 0.0, "avg_logprob": -0.11378580815083272, "compression_ratio": 1.7327044025157232, "no_speech_prob": 0.00646575540304184}, {"id": 1832, "seek": 511208, "start": 5125.84, "end": 5128.64, "text": " And it might look like, oh, those things over there", "tokens": [51052, 400, 309, 1062, 574, 411, 11, 1954, 11, 729, 721, 670, 456, 51192], "temperature": 0.0, "avg_logprob": -0.11378580815083272, "compression_ratio": 1.7327044025157232, "no_speech_prob": 0.00646575540304184}, {"id": 1833, "seek": 511208, "start": 5128.64, "end": 5129.84, "text": " that we're ignoring don't matter,", "tokens": [51192, 300, 321, 434, 26258, 500, 380, 1871, 11, 51252], "temperature": 0.0, "avg_logprob": -0.11378580815083272, "compression_ratio": 1.7327044025157232, "no_speech_prob": 0.00646575540304184}, {"id": 1834, "seek": 511208, "start": 5129.84, "end": 5131.6, "text": " but actually they might really matter", "tokens": [51252, 457, 767, 436, 1062, 534, 1871, 51340], "temperature": 0.0, "avg_logprob": -0.11378580815083272, "compression_ratio": 1.7327044025157232, "no_speech_prob": 0.00646575540304184}, {"id": 1835, "seek": 511208, "start": 5131.6, "end": 5132.88, "text": " if they got introduced into the utility.", "tokens": [51340, 498, 436, 658, 7268, 666, 264, 14877, 13, 51404], "temperature": 0.0, "avg_logprob": -0.11378580815083272, "compression_ratio": 1.7327044025157232, "no_speech_prob": 0.00646575540304184}, {"id": 1836, "seek": 511208, "start": 5132.88, "end": 5138.8, "text": " Well, I wouldn't say that maximizing expected utility is anthropomorphic, right?", "tokens": [51404, 1042, 11, 286, 2759, 380, 584, 300, 5138, 3319, 5176, 14877, 307, 22727, 32702, 299, 11, 558, 30, 51700], "temperature": 0.0, "avg_logprob": -0.11378580815083272, "compression_ratio": 1.7327044025157232, "no_speech_prob": 0.00646575540304184}, {"id": 1837, "seek": 511208, "start": 5138.8, "end": 5140.08, "text": " In fact, it's one of the least...", "tokens": [51700, 682, 1186, 11, 309, 311, 472, 295, 264, 1935, 485, 51764], "temperature": 0.0, "avg_logprob": -0.11378580815083272, "compression_ratio": 1.7327044025157232, "no_speech_prob": 0.00646575540304184}, {"id": 1838, "seek": 514008, "start": 5141.04, "end": 5143.68, "text": " I think maybe there's some degree of anthropomorphism", "tokens": [50412, 286, 519, 1310, 456, 311, 512, 4314, 295, 22727, 32702, 1434, 50544], "temperature": 0.0, "avg_logprob": -0.08578776556348043, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0027503466699272394}, {"id": 1839, "seek": 514008, "start": 5143.68, "end": 5145.12, "text": " is almost anything we do,", "tokens": [50544, 307, 1920, 1340, 321, 360, 11, 50616], "temperature": 0.0, "avg_logprob": -0.08578776556348043, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0027503466699272394}, {"id": 1840, "seek": 514008, "start": 5145.12, "end": 5149.04, "text": " and the progress of science is becoming less and less anthropomorphic,", "tokens": [50616, 293, 264, 4205, 295, 3497, 307, 5617, 1570, 293, 1570, 22727, 32702, 299, 11, 50812], "temperature": 0.0, "avg_logprob": -0.08578776556348043, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0027503466699272394}, {"id": 1841, "seek": 514008, "start": 5149.04, "end": 5150.8, "text": " and we should keep pushing on that.", "tokens": [50812, 293, 321, 820, 1066, 7380, 322, 300, 13, 50900], "temperature": 0.0, "avg_logprob": -0.08578776556348043, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0027503466699272394}, {"id": 1842, "seek": 514008, "start": 5150.8, "end": 5153.76, "text": " But I would say that maximizing expected utility", "tokens": [50900, 583, 286, 576, 584, 300, 5138, 3319, 5176, 14877, 51048], "temperature": 0.0, "avg_logprob": -0.08578776556348043, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0027503466699272394}, {"id": 1843, "seek": 514008, "start": 5153.76, "end": 5156.48, "text": " is one of the least anthropomorphic things we can do.", "tokens": [51048, 307, 472, 295, 264, 1935, 22727, 32702, 299, 721, 321, 393, 360, 13, 51184], "temperature": 0.0, "avg_logprob": -0.08578776556348043, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0027503466699272394}, {"id": 1844, "seek": 514008, "start": 5156.48, "end": 5158.24, "text": " Well, this is actually a really interesting point,", "tokens": [51184, 1042, 11, 341, 307, 767, 257, 534, 1880, 935, 11, 51272], "temperature": 0.0, "avg_logprob": -0.08578776556348043, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0027503466699272394}, {"id": 1845, "seek": 514008, "start": 5158.24, "end": 5160.72, "text": " because one of the key tenets of the rationalist movement", "tokens": [51272, 570, 472, 295, 264, 2141, 2064, 1385, 295, 264, 15090, 468, 3963, 51396], "temperature": 0.0, "avg_logprob": -0.08578776556348043, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0027503466699272394}, {"id": 1846, "seek": 514008, "start": 5160.72, "end": 5162.0, "text": " and their conception of intelligence,", "tokens": [51396, 293, 641, 30698, 295, 7599, 11, 51460], "temperature": 0.0, "avg_logprob": -0.08578776556348043, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0027503466699272394}, {"id": 1847, "seek": 514008, "start": 5162.0, "end": 5165.2, "text": " because all of the other definitions of intelligence", "tokens": [51460, 570, 439, 295, 264, 661, 21988, 295, 7599, 51620], "temperature": 0.0, "avg_logprob": -0.08578776556348043, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0027503466699272394}, {"id": 1848, "seek": 514008, "start": 5165.2, "end": 5166.88, "text": " are anthropomorphic.", "tokens": [51620, 366, 22727, 32702, 299, 13, 51704], "temperature": 0.0, "avg_logprob": -0.08578776556348043, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0027503466699272394}, {"id": 1849, "seek": 516688, "start": 5166.88, "end": 5169.6, "text": " So, you know, there's based on behavior, capability, AI,", "tokens": [50364, 407, 11, 291, 458, 11, 456, 311, 2361, 322, 5223, 11, 13759, 11, 7318, 11, 50500], "temperature": 0.0, "avg_logprob": -0.17421918869018554, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.01183092687278986}, {"id": 1850, "seek": 516688, "start": 5170.32, "end": 5175.28, "text": " principal function is a big one, you know, from Norvig.", "tokens": [50536, 9716, 2445, 307, 257, 955, 472, 11, 291, 458, 11, 490, 6966, 85, 328, 13, 50784], "temperature": 0.0, "avg_logprob": -0.17421918869018554, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.01183092687278986}, {"id": 1851, "seek": 516688, "start": 5175.28, "end": 5178.16, "text": " And this is the principal based AI,", "tokens": [50784, 400, 341, 307, 264, 9716, 2361, 7318, 11, 50928], "temperature": 0.0, "avg_logprob": -0.17421918869018554, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.01183092687278986}, {"id": 1852, "seek": 516688, "start": 5178.16, "end": 5181.28, "text": " which is just making rational moves.", "tokens": [50928, 597, 307, 445, 1455, 15090, 6067, 13, 51084], "temperature": 0.0, "avg_logprob": -0.17421918869018554, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.01183092687278986}, {"id": 1853, "seek": 516688, "start": 5181.28, "end": 5186.16, "text": " So why is there such a push to be as, you know,", "tokens": [51084, 407, 983, 307, 456, 1270, 257, 2944, 281, 312, 382, 11, 291, 458, 11, 51328], "temperature": 0.0, "avg_logprob": -0.17421918869018554, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.01183092687278986}, {"id": 1854, "seek": 516688, "start": 5186.16, "end": 5189.84, "text": " to be as the least amount anthropomorphic?", "tokens": [51328, 281, 312, 382, 264, 1935, 2372, 22727, 32702, 299, 30, 51512], "temperature": 0.0, "avg_logprob": -0.17421918869018554, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.01183092687278986}, {"id": 1855, "seek": 516688, "start": 5190.4800000000005, "end": 5194.0, "text": " Oh, the push is not to be, at least in my view,", "tokens": [51544, 876, 11, 264, 2944, 307, 406, 281, 312, 11, 412, 1935, 294, 452, 1910, 11, 51720], "temperature": 0.0, "avg_logprob": -0.17421918869018554, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.01183092687278986}, {"id": 1856, "seek": 519400, "start": 5194.48, "end": 5196.96, "text": " being less anthropomorphic is not a goal.", "tokens": [50388, 885, 1570, 22727, 32702, 299, 307, 406, 257, 3387, 13, 50512], "temperature": 0.0, "avg_logprob": -0.10833546447753906, "compression_ratio": 1.8174273858921162, "no_speech_prob": 0.019359497353434563}, {"id": 1857, "seek": 519400, "start": 5197.6, "end": 5199.04, "text": " That's not the goal.", "tokens": [50544, 663, 311, 406, 264, 3387, 13, 50616], "temperature": 0.0, "avg_logprob": -0.10833546447753906, "compression_ratio": 1.8174273858921162, "no_speech_prob": 0.019359497353434563}, {"id": 1858, "seek": 519400, "start": 5199.04, "end": 5202.72, "text": " The goal is to be as accurate and complete as we can", "tokens": [50616, 440, 3387, 307, 281, 312, 382, 8559, 293, 3566, 382, 321, 393, 50800], "temperature": 0.0, "avg_logprob": -0.10833546447753906, "compression_ratio": 1.8174273858921162, "no_speech_prob": 0.019359497353434563}, {"id": 1859, "seek": 519400, "start": 5202.72, "end": 5204.88, "text": " in modeling the world, right?", "tokens": [50800, 294, 15983, 264, 1002, 11, 558, 30, 50908], "temperature": 0.0, "avg_logprob": -0.10833546447753906, "compression_ratio": 1.8174273858921162, "no_speech_prob": 0.019359497353434563}, {"id": 1860, "seek": 519400, "start": 5204.88, "end": 5207.68, "text": " We're just trying to understand the world better, right?", "tokens": [50908, 492, 434, 445, 1382, 281, 1223, 264, 1002, 1101, 11, 558, 30, 51048], "temperature": 0.0, "avg_logprob": -0.10833546447753906, "compression_ratio": 1.8174273858921162, "no_speech_prob": 0.019359497353434563}, {"id": 1861, "seek": 519400, "start": 5208.32, "end": 5210.4, "text": " For whatever purpose, maybe for its own sake,", "tokens": [51080, 1171, 2035, 4334, 11, 1310, 337, 1080, 1065, 9717, 11, 51184], "temperature": 0.0, "avg_logprob": -0.10833546447753906, "compression_ratio": 1.8174273858921162, "no_speech_prob": 0.019359497353434563}, {"id": 1862, "seek": 519400, "start": 5210.4, "end": 5214.08, "text": " maybe for the purpose of the utility and the evolution and so on, right?", "tokens": [51184, 1310, 337, 264, 4334, 295, 264, 14877, 293, 264, 9303, 293, 370, 322, 11, 558, 30, 51368], "temperature": 0.0, "avg_logprob": -0.10833546447753906, "compression_ratio": 1.8174273858921162, "no_speech_prob": 0.019359497353434563}, {"id": 1863, "seek": 519400, "start": 5214.08, "end": 5214.96, "text": " But that's the goal.", "tokens": [51368, 583, 300, 311, 264, 3387, 13, 51412], "temperature": 0.0, "avg_logprob": -0.10833546447753906, "compression_ratio": 1.8174273858921162, "no_speech_prob": 0.019359497353434563}, {"id": 1864, "seek": 519400, "start": 5214.96, "end": 5217.04, "text": " The problem is that,", "tokens": [51412, 440, 1154, 307, 300, 11, 51516], "temperature": 0.0, "avg_logprob": -0.10833546447753906, "compression_ratio": 1.8174273858921162, "no_speech_prob": 0.019359497353434563}, {"id": 1865, "seek": 519400, "start": 5217.04, "end": 5219.6, "text": " and this has been the problem since they won, right?", "tokens": [51516, 293, 341, 575, 668, 264, 1154, 1670, 436, 1582, 11, 558, 30, 51644], "temperature": 0.0, "avg_logprob": -0.10833546447753906, "compression_ratio": 1.8174273858921162, "no_speech_prob": 0.019359497353434563}, {"id": 1866, "seek": 519400, "start": 5219.6, "end": 5221.2, "text": " They won of humanity,", "tokens": [51644, 814, 1582, 295, 10243, 11, 51724], "temperature": 0.0, "avg_logprob": -0.10833546447753906, "compression_ratio": 1.8174273858921162, "no_speech_prob": 0.019359497353434563}, {"id": 1867, "seek": 522120, "start": 5221.2, "end": 5223.84, "text": " is that because we anthropomorphize the world,", "tokens": [50364, 307, 300, 570, 321, 22727, 32702, 1125, 264, 1002, 11, 50496], "temperature": 0.0, "avg_logprob": -0.1064150275253668, "compression_ratio": 1.889589905362776, "no_speech_prob": 0.012944361194968224}, {"id": 1868, "seek": 522120, "start": 5223.84, "end": 5227.36, "text": " that gets in the way of understanding how it really works, right?", "tokens": [50496, 300, 2170, 294, 264, 636, 295, 3701, 577, 309, 534, 1985, 11, 558, 30, 50672], "temperature": 0.0, "avg_logprob": -0.1064150275253668, "compression_ratio": 1.889589905362776, "no_speech_prob": 0.012944361194968224}, {"id": 1869, "seek": 522120, "start": 5227.36, "end": 5230.5599999999995, "text": " If I say the wind is some God blowing, right?", "tokens": [50672, 759, 286, 584, 264, 2468, 307, 512, 1265, 15068, 11, 558, 30, 50832], "temperature": 0.0, "avg_logprob": -0.1064150275253668, "compression_ratio": 1.889589905362776, "no_speech_prob": 0.012944361194968224}, {"id": 1870, "seek": 522120, "start": 5230.5599999999995, "end": 5231.599999999999, "text": " I understand, right?", "tokens": [50832, 286, 1223, 11, 558, 30, 50884], "temperature": 0.0, "avg_logprob": -0.1064150275253668, "compression_ratio": 1.889589905362776, "no_speech_prob": 0.012944361194968224}, {"id": 1871, "seek": 522120, "start": 5231.599999999999, "end": 5233.04, "text": " That's all they could think of.", "tokens": [50884, 663, 311, 439, 436, 727, 519, 295, 13, 50956], "temperature": 0.0, "avg_logprob": -0.1064150275253668, "compression_ratio": 1.889589905362776, "no_speech_prob": 0.012944361194968224}, {"id": 1872, "seek": 522120, "start": 5233.04, "end": 5235.599999999999, "text": " But it's a big obstacle to understanding what the wind really is,", "tokens": [50956, 583, 309, 311, 257, 955, 23112, 281, 3701, 437, 264, 2468, 534, 307, 11, 51084], "temperature": 0.0, "avg_logprob": -0.1064150275253668, "compression_ratio": 1.889589905362776, "no_speech_prob": 0.012944361194968224}, {"id": 1873, "seek": 522120, "start": 5235.599999999999, "end": 5238.5599999999995, "text": " like there's a pressure difference, et cetera, et cetera, right?", "tokens": [51084, 411, 456, 311, 257, 3321, 2649, 11, 1030, 11458, 11, 1030, 11458, 11, 558, 30, 51232], "temperature": 0.0, "avg_logprob": -0.1064150275253668, "compression_ratio": 1.889589905362776, "no_speech_prob": 0.012944361194968224}, {"id": 1874, "seek": 522120, "start": 5238.5599999999995, "end": 5241.44, "text": " And we've done away with a lot of anthropomorphism.", "tokens": [51232, 400, 321, 600, 1096, 1314, 365, 257, 688, 295, 22727, 32702, 1434, 13, 51376], "temperature": 0.0, "avg_logprob": -0.1064150275253668, "compression_ratio": 1.889589905362776, "no_speech_prob": 0.012944361194968224}, {"id": 1875, "seek": 522120, "start": 5241.44, "end": 5243.2, "text": " By the way, one of the problems that we're always having", "tokens": [51376, 3146, 264, 636, 11, 472, 295, 264, 2740, 300, 321, 434, 1009, 1419, 51464], "temperature": 0.0, "avg_logprob": -0.1064150275253668, "compression_ratio": 1.889589905362776, "no_speech_prob": 0.012944361194968224}, {"id": 1876, "seek": 522120, "start": 5243.2, "end": 5245.76, "text": " is that it's always pushing back, right?", "tokens": [51464, 307, 300, 309, 311, 1009, 7380, 646, 11, 558, 30, 51592], "temperature": 0.0, "avg_logprob": -0.1064150275253668, "compression_ratio": 1.889589905362776, "no_speech_prob": 0.012944361194968224}, {"id": 1877, "seek": 522120, "start": 5245.76, "end": 5247.12, "text": " You know, there's always, you know, again,", "tokens": [51592, 509, 458, 11, 456, 311, 1009, 11, 291, 458, 11, 797, 11, 51660], "temperature": 0.0, "avg_logprob": -0.1064150275253668, "compression_ratio": 1.889589905362776, "no_speech_prob": 0.012944361194968224}, {"id": 1878, "seek": 522120, "start": 5247.12, "end": 5250.5599999999995, "text": " intuitively we have a very strong tendency to anthropomorphism,", "tokens": [51660, 46506, 321, 362, 257, 588, 2068, 18187, 281, 22727, 32702, 1434, 11, 51832], "temperature": 0.0, "avg_logprob": -0.1064150275253668, "compression_ratio": 1.889589905362776, "no_speech_prob": 0.012944361194968224}, {"id": 1879, "seek": 525056, "start": 5251.04, "end": 5253.6, "text": " as much as science broadly construed as a great victory,", "tokens": [50388, 382, 709, 382, 3497, 19511, 12946, 292, 382, 257, 869, 9812, 11, 50516], "temperature": 0.0, "avg_logprob": -0.13837758145591086, "compression_ratio": 1.8007380073800738, "no_speech_prob": 0.003015073947608471}, {"id": 1880, "seek": 525056, "start": 5253.6, "end": 5255.360000000001, "text": " it's always in danger from this, right?", "tokens": [50516, 309, 311, 1009, 294, 4330, 490, 341, 11, 558, 30, 50604], "temperature": 0.0, "avg_logprob": -0.13837758145591086, "compression_ratio": 1.8007380073800738, "no_speech_prob": 0.003015073947608471}, {"id": 1881, "seek": 525056, "start": 5255.360000000001, "end": 5257.200000000001, "text": " But even within science,", "tokens": [50604, 583, 754, 1951, 3497, 11, 50696], "temperature": 0.0, "avg_logprob": -0.13837758145591086, "compression_ratio": 1.8007380073800738, "no_speech_prob": 0.003015073947608471}, {"id": 1882, "seek": 525056, "start": 5257.200000000001, "end": 5262.160000000001, "text": " we've gone from doing away with the obvious forms of anthropomorphism", "tokens": [50696, 321, 600, 2780, 490, 884, 1314, 365, 264, 6322, 6422, 295, 22727, 32702, 1434, 50944], "temperature": 0.0, "avg_logprob": -0.13837758145591086, "compression_ratio": 1.8007380073800738, "no_speech_prob": 0.003015073947608471}, {"id": 1883, "seek": 525056, "start": 5262.160000000001, "end": 5263.6, "text": " and anthropomorphism", "tokens": [50944, 293, 22727, 32702, 1434, 51016], "temperature": 0.0, "avg_logprob": -0.13837758145591086, "compression_ratio": 1.8007380073800738, "no_speech_prob": 0.003015073947608471}, {"id": 1884, "seek": 525056, "start": 5263.6, "end": 5266.400000000001, "text": " to having many things that are still there", "tokens": [51016, 281, 1419, 867, 721, 300, 366, 920, 456, 51156], "temperature": 0.0, "avg_logprob": -0.13837758145591086, "compression_ratio": 1.8007380073800738, "no_speech_prob": 0.003015073947608471}, {"id": 1885, "seek": 525056, "start": 5266.400000000001, "end": 5270.4800000000005, "text": " that are less obviously anthropomorphic, but still are, right?", "tokens": [51156, 300, 366, 1570, 2745, 22727, 32702, 299, 11, 457, 920, 366, 11, 558, 30, 51360], "temperature": 0.0, "avg_logprob": -0.13837758145591086, "compression_ratio": 1.8007380073800738, "no_speech_prob": 0.003015073947608471}, {"id": 1886, "seek": 525056, "start": 5270.4800000000005, "end": 5273.120000000001, "text": " But if there's something anthropomorphic that's actually is accurate,", "tokens": [51360, 583, 498, 456, 311, 746, 22727, 32702, 299, 300, 311, 767, 307, 8559, 11, 51492], "temperature": 0.0, "avg_logprob": -0.13837758145591086, "compression_ratio": 1.8007380073800738, "no_speech_prob": 0.003015073947608471}, {"id": 1887, "seek": 525056, "start": 5273.120000000001, "end": 5274.4800000000005, "text": " then more power to it.", "tokens": [51492, 550, 544, 1347, 281, 309, 13, 51560], "temperature": 0.0, "avg_logprob": -0.13837758145591086, "compression_ratio": 1.8007380073800738, "no_speech_prob": 0.003015073947608471}, {"id": 1888, "seek": 525056, "start": 5274.4800000000005, "end": 5275.120000000001, "text": " Interesting, yeah.", "tokens": [51560, 14711, 11, 1338, 13, 51592], "temperature": 0.0, "avg_logprob": -0.13837758145591086, "compression_ratio": 1.8007380073800738, "no_speech_prob": 0.003015073947608471}, {"id": 1889, "seek": 525056, "start": 5275.120000000001, "end": 5277.92, "text": " And then I guess we have so many cognitive priors, right?", "tokens": [51592, 400, 550, 286, 2041, 321, 362, 370, 867, 15605, 1790, 830, 11, 558, 30, 51732], "temperature": 0.0, "avg_logprob": -0.13837758145591086, "compression_ratio": 1.8007380073800738, "no_speech_prob": 0.003015073947608471}, {"id": 1890, "seek": 527792, "start": 5278.16, "end": 5280.4800000000005, "text": " In our brains that give us a cone of attention,", "tokens": [50376, 682, 527, 15442, 300, 976, 505, 257, 19749, 295, 3202, 11, 50492], "temperature": 0.0, "avg_logprob": -0.1085444493080253, "compression_ratio": 1.7954545454545454, "no_speech_prob": 0.01611982099711895}, {"id": 1891, "seek": 527792, "start": 5280.4800000000005, "end": 5283.28, "text": " which is completely anthropocentric.", "tokens": [50492, 597, 307, 2584, 22727, 905, 32939, 13, 50632], "temperature": 0.0, "avg_logprob": -0.1085444493080253, "compression_ratio": 1.7954545454545454, "no_speech_prob": 0.01611982099711895}, {"id": 1892, "seek": 527792, "start": 5283.28, "end": 5285.12, "text": " Well, very good.", "tokens": [50632, 1042, 11, 588, 665, 13, 50724], "temperature": 0.0, "avg_logprob": -0.1085444493080253, "compression_ratio": 1.7954545454545454, "no_speech_prob": 0.01611982099711895}, {"id": 1893, "seek": 527792, "start": 5285.12, "end": 5289.04, "text": " So those priors, and maybe a better term is heuristics, right?", "tokens": [50724, 407, 729, 1790, 830, 11, 293, 1310, 257, 1101, 1433, 307, 415, 374, 6006, 11, 558, 30, 50920], "temperature": 0.0, "avg_logprob": -0.1085444493080253, "compression_ratio": 1.7954545454545454, "no_speech_prob": 0.01611982099711895}, {"id": 1894, "seek": 527792, "start": 5289.04, "end": 5293.04, "text": " Our brains are full of heuristics that evolution put there", "tokens": [50920, 2621, 15442, 366, 1577, 295, 415, 374, 6006, 300, 9303, 829, 456, 51120], "temperature": 0.0, "avg_logprob": -0.1085444493080253, "compression_ratio": 1.7954545454545454, "no_speech_prob": 0.01611982099711895}, {"id": 1895, "seek": 527792, "start": 5293.04, "end": 5296.24, "text": " for a good reason, because those heuristics work, right?", "tokens": [51120, 337, 257, 665, 1778, 11, 570, 729, 415, 374, 6006, 589, 11, 558, 30, 51280], "temperature": 0.0, "avg_logprob": -0.1085444493080253, "compression_ratio": 1.7954545454545454, "no_speech_prob": 0.01611982099711895}, {"id": 1896, "seek": 527792, "start": 5296.24, "end": 5297.84, "text": " But they are heuristics.", "tokens": [51280, 583, 436, 366, 415, 374, 6006, 13, 51360], "temperature": 0.0, "avg_logprob": -0.1085444493080253, "compression_ratio": 1.7954545454545454, "no_speech_prob": 0.01611982099711895}, {"id": 1897, "seek": 527792, "start": 5297.84, "end": 5299.76, "text": " So they have failure modes, right?", "tokens": [51360, 407, 436, 362, 7763, 14068, 11, 558, 30, 51456], "temperature": 0.0, "avg_logprob": -0.1085444493080253, "compression_ratio": 1.7954545454545454, "no_speech_prob": 0.01611982099711895}, {"id": 1898, "seek": 527792, "start": 5299.76, "end": 5304.16, "text": " And we need to understand what is that those heuristics really are getting at", "tokens": [51456, 400, 321, 643, 281, 1223, 437, 307, 300, 729, 415, 374, 6006, 534, 366, 1242, 412, 51676], "temperature": 0.0, "avg_logprob": -0.1085444493080253, "compression_ratio": 1.7954545454545454, "no_speech_prob": 0.01611982099711895}, {"id": 1899, "seek": 527792, "start": 5304.16, "end": 5307.76, "text": " so that we also, so that we use them when they're good.", "tokens": [51676, 370, 300, 321, 611, 11, 370, 300, 321, 764, 552, 562, 436, 434, 665, 13, 51856], "temperature": 0.0, "avg_logprob": -0.1085444493080253, "compression_ratio": 1.7954545454545454, "no_speech_prob": 0.01611982099711895}, {"id": 1900, "seek": 530776, "start": 5307.76, "end": 5309.76, "text": " But then when they're not good, we use something else.", "tokens": [50364, 583, 550, 562, 436, 434, 406, 665, 11, 321, 764, 746, 1646, 13, 50464], "temperature": 0.0, "avg_logprob": -0.12726634656879263, "compression_ratio": 1.7360594795539033, "no_speech_prob": 0.003676546737551689}, {"id": 1901, "seek": 530776, "start": 5310.64, "end": 5311.92, "text": " Brilliant, brilliant.", "tokens": [50508, 34007, 11, 10248, 13, 50572], "temperature": 0.0, "avg_logprob": -0.12726634656879263, "compression_ratio": 1.7360594795539033, "no_speech_prob": 0.003676546737551689}, {"id": 1902, "seek": 530776, "start": 5311.92, "end": 5314.0, "text": " So Pedro, we're here at NeurIPS this week.", "tokens": [50572, 407, 26662, 11, 321, 434, 510, 412, 1734, 374, 40, 6273, 341, 1243, 13, 50676], "temperature": 0.0, "avg_logprob": -0.12726634656879263, "compression_ratio": 1.7360594795539033, "no_speech_prob": 0.003676546737551689}, {"id": 1903, "seek": 530776, "start": 5314.0, "end": 5318.08, "text": " And could you just like sketch out some of the some of the things you've seen?", "tokens": [50676, 400, 727, 291, 445, 411, 12325, 484, 512, 295, 264, 512, 295, 264, 721, 291, 600, 1612, 30, 50880], "temperature": 0.0, "avg_logprob": -0.12726634656879263, "compression_ratio": 1.7360594795539033, "no_speech_prob": 0.003676546737551689}, {"id": 1904, "seek": 530776, "start": 5318.08, "end": 5322.64, "text": " And I also know that you're a huge fan in that there's a Neurosymbolic algorithm", "tokens": [50880, 400, 286, 611, 458, 300, 291, 434, 257, 2603, 3429, 294, 300, 456, 311, 257, 1734, 8977, 88, 5612, 299, 9284, 51108], "temperature": 0.0, "avg_logprob": -0.12726634656879263, "compression_ratio": 1.7360594795539033, "no_speech_prob": 0.003676546737551689}, {"id": 1905, "seek": 530776, "start": 5322.64, "end": 5323.68, "text": " that you want to tell us about.", "tokens": [51108, 300, 291, 528, 281, 980, 505, 466, 13, 51160], "temperature": 0.0, "avg_logprob": -0.12726634656879263, "compression_ratio": 1.7360594795539033, "no_speech_prob": 0.003676546737551689}, {"id": 1906, "seek": 530776, "start": 5323.68, "end": 5325.360000000001, "text": " So let's let's hear it.", "tokens": [51160, 407, 718, 311, 718, 311, 1568, 309, 13, 51244], "temperature": 0.0, "avg_logprob": -0.12726634656879263, "compression_ratio": 1.7360594795539033, "no_speech_prob": 0.003676546737551689}, {"id": 1907, "seek": 530776, "start": 5325.360000000001, "end": 5329.4400000000005, "text": " So I indeed, I've been enjoying NeurIPS this week.", "tokens": [51244, 407, 286, 6451, 11, 286, 600, 668, 9929, 1734, 374, 40, 6273, 341, 1243, 13, 51448], "temperature": 0.0, "avg_logprob": -0.12726634656879263, "compression_ratio": 1.7360594795539033, "no_speech_prob": 0.003676546737551689}, {"id": 1908, "seek": 530776, "start": 5329.4400000000005, "end": 5334.64, "text": " One of the big things in AI in the last several years has been Neurosymbolic AI,", "tokens": [51448, 1485, 295, 264, 955, 721, 294, 7318, 294, 264, 1036, 2940, 924, 575, 668, 1734, 8977, 88, 5612, 299, 7318, 11, 51708], "temperature": 0.0, "avg_logprob": -0.12726634656879263, "compression_ratio": 1.7360594795539033, "no_speech_prob": 0.003676546737551689}, {"id": 1909, "seek": 533464, "start": 5335.6, "end": 5340.240000000001, "text": " which you probably will not surprise by the fact that I very much believe in.", "tokens": [50412, 597, 291, 1391, 486, 406, 6365, 538, 264, 1186, 300, 286, 588, 709, 1697, 294, 13, 50644], "temperature": 0.0, "avg_logprob": -0.11519466746937145, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.013998349197208881}, {"id": 1910, "seek": 533464, "start": 5340.240000000001, "end": 5342.96, "text": " So and I believe this since I was a grad student", "tokens": [50644, 407, 293, 286, 1697, 341, 1670, 286, 390, 257, 2771, 3107, 50780], "temperature": 0.0, "avg_logprob": -0.11519466746937145, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.013998349197208881}, {"id": 1911, "seek": 533464, "start": 5342.96, "end": 5346.64, "text": " and the whole idea of Neurosymbolic AI was something that nobody was interested in, right?", "tokens": [50780, 293, 264, 1379, 1558, 295, 1734, 8977, 88, 5612, 299, 7318, 390, 746, 300, 5079, 390, 3102, 294, 11, 558, 30, 50964], "temperature": 0.0, "avg_logprob": -0.11519466746937145, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.013998349197208881}, {"id": 1912, "seek": 533464, "start": 5346.64, "end": 5349.360000000001, "text": " And now suddenly everybody is, which I think is a good development.", "tokens": [50964, 400, 586, 5800, 2201, 307, 11, 597, 286, 519, 307, 257, 665, 3250, 13, 51100], "temperature": 0.0, "avg_logprob": -0.11519466746937145, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.013998349197208881}, {"id": 1913, "seek": 533464, "start": 5349.360000000001, "end": 5353.280000000001, "text": " And this is the idea that if we really want to solve AI by some definite,", "tokens": [51100, 400, 341, 307, 264, 1558, 300, 498, 321, 534, 528, 281, 5039, 7318, 538, 512, 25131, 11, 51296], "temperature": 0.0, "avg_logprob": -0.11519466746937145, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.013998349197208881}, {"id": 1914, "seek": 533464, "start": 5353.280000000001, "end": 5358.8, "text": " if we want to get to like human level intelligence, etc, etc, we need to have both,", "tokens": [51296, 498, 321, 528, 281, 483, 281, 411, 1952, 1496, 7599, 11, 5183, 11, 5183, 11, 321, 643, 281, 362, 1293, 11, 51572], "temperature": 0.0, "avg_logprob": -0.11519466746937145, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.013998349197208881}, {"id": 1915, "seek": 533464, "start": 5360.320000000001, "end": 5364.160000000001, "text": " you know, like, for example, deep learning is not enough, right?", "tokens": [51648, 291, 458, 11, 411, 11, 337, 1365, 11, 2452, 2539, 307, 406, 1547, 11, 558, 30, 51840], "temperature": 0.0, "avg_logprob": -0.11519466746937145, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.013998349197208881}, {"id": 1916, "seek": 536416, "start": 5364.16, "end": 5367.92, "text": " There are symbolic reasoning capabilities that we have and that are essential.", "tokens": [50364, 821, 366, 25755, 21577, 10862, 300, 321, 362, 293, 300, 366, 7115, 13, 50552], "temperature": 0.0, "avg_logprob": -0.20137846939207063, "compression_ratio": 1.6797153024911031, "no_speech_prob": 0.0033104189205914736}, {"id": 1917, "seek": 536416, "start": 5368.639999999999, "end": 5369.84, "text": " And we need to get them.", "tokens": [50588, 400, 321, 643, 281, 483, 552, 13, 50648], "temperature": 0.0, "avg_logprob": -0.20137846939207063, "compression_ratio": 1.6797153024911031, "no_speech_prob": 0.0033104189205914736}, {"id": 1918, "seek": 536416, "start": 5369.84, "end": 5373.28, "text": " And I think, you know, intelligent connection is like, I don't know,", "tokens": [50648, 400, 286, 519, 11, 291, 458, 11, 13232, 4984, 307, 411, 11, 286, 500, 380, 458, 11, 50820], "temperature": 0.0, "avg_logprob": -0.20137846939207063, "compression_ratio": 1.6797153024911031, "no_speech_prob": 0.0033104189205914736}, {"id": 1919, "seek": 536416, "start": 5373.28, "end": 5376.96, "text": " Yoshua Ben-Joe, you know, Yanle Kunase, they don't disagree with this.", "tokens": [50820, 38949, 4398, 3964, 12, 41, 7921, 11, 291, 458, 11, 13633, 306, 19089, 651, 11, 436, 500, 380, 14091, 365, 341, 13, 51004], "temperature": 0.0, "avg_logprob": -0.20137846939207063, "compression_ratio": 1.6797153024911031, "no_speech_prob": 0.0033104189205914736}, {"id": 1920, "seek": 536416, "start": 5377.5199999999995, "end": 5381.12, "text": " But one way to look at this is say, we're just going to realize those,", "tokens": [51032, 583, 472, 636, 281, 574, 412, 341, 307, 584, 11, 321, 434, 445, 516, 281, 4325, 729, 11, 51212], "temperature": 0.0, "avg_logprob": -0.20137846939207063, "compression_ratio": 1.6797153024911031, "no_speech_prob": 0.0033104189205914736}, {"id": 1921, "seek": 536416, "start": 5381.12, "end": 5384.88, "text": " you know, capabilities using purely connectionist means, right?", "tokens": [51212, 291, 458, 11, 10862, 1228, 17491, 4984, 468, 1355, 11, 558, 30, 51400], "temperature": 0.0, "avg_logprob": -0.20137846939207063, "compression_ratio": 1.6797153024911031, "no_speech_prob": 0.0033104189205914736}, {"id": 1922, "seek": 536416, "start": 5385.5199999999995, "end": 5388.16, "text": " And what I see happening in that direction,", "tokens": [51432, 400, 437, 286, 536, 2737, 294, 300, 3513, 11, 51564], "temperature": 0.0, "avg_logprob": -0.20137846939207063, "compression_ratio": 1.6797153024911031, "no_speech_prob": 0.0033104189205914736}, {"id": 1923, "seek": 536416, "start": 5388.16, "end": 5390.48, "text": " unfortunately, is a lot of reinventing the wheel.", "tokens": [51564, 7015, 11, 307, 257, 688, 295, 33477, 278, 264, 5589, 13, 51680], "temperature": 0.0, "avg_logprob": -0.20137846939207063, "compression_ratio": 1.6797153024911031, "no_speech_prob": 0.0033104189205914736}, {"id": 1924, "seek": 539048, "start": 5390.48, "end": 5395.679999999999, "text": " So I do think, you know, symbolic AI got wedged for some reasons, including brittleness.", "tokens": [50364, 407, 286, 360, 519, 11, 291, 458, 11, 25755, 7318, 658, 6393, 3004, 337, 512, 4112, 11, 3009, 738, 593, 45887, 13, 50624], "temperature": 0.0, "avg_logprob": -0.11022582224437169, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.010632768273353577}, {"id": 1925, "seek": 539048, "start": 5396.799999999999, "end": 5399.919999999999, "text": " And, you know, and we have learned from that at the same time,", "tokens": [50680, 400, 11, 291, 458, 11, 293, 321, 362, 3264, 490, 300, 412, 264, 912, 565, 11, 50836], "temperature": 0.0, "avg_logprob": -0.11022582224437169, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.010632768273353577}, {"id": 1926, "seek": 539048, "start": 5399.919999999999, "end": 5404.32, "text": " they did discover and understand a lot of things that are extremely relevant.", "tokens": [50836, 436, 630, 4411, 293, 1223, 257, 688, 295, 721, 300, 366, 4664, 7340, 13, 51056], "temperature": 0.0, "avg_logprob": -0.11022582224437169, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.010632768273353577}, {"id": 1927, "seek": 539048, "start": 5404.32, "end": 5406.879999999999, "text": " So it's just not good science to ignore it.", "tokens": [51056, 407, 309, 311, 445, 406, 665, 3497, 281, 11200, 309, 13, 51184], "temperature": 0.0, "avg_logprob": -0.11022582224437169, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.010632768273353577}, {"id": 1928, "seek": 539048, "start": 5406.879999999999, "end": 5412.959999999999, "text": " So I'm working on an approach to combine, you know, symbolic AI with deep learning.", "tokens": [51184, 407, 286, 478, 1364, 322, 364, 3109, 281, 10432, 11, 291, 458, 11, 25755, 7318, 365, 2452, 2539, 13, 51488], "temperature": 0.0, "avg_logprob": -0.11022582224437169, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.010632768273353577}, {"id": 1929, "seek": 539048, "start": 5412.959999999999, "end": 5417.44, "text": " Again, this is a popular exercise, there are many interesting approaches out there.", "tokens": [51488, 3764, 11, 341, 307, 257, 3743, 5380, 11, 456, 366, 867, 1880, 11587, 484, 456, 13, 51712], "temperature": 0.0, "avg_logprob": -0.11022582224437169, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.010632768273353577}, {"id": 1930, "seek": 541744, "start": 5417.5199999999995, "end": 5418.96, "text": " As much as I sympathize with them,", "tokens": [50368, 1018, 709, 382, 286, 22276, 1125, 365, 552, 11, 50440], "temperature": 0.0, "avg_logprob": -0.10959959763746996, "compression_ratio": 1.662162162162162, "no_speech_prob": 0.016125747933983803}, {"id": 1931, "seek": 541744, "start": 5418.96, "end": 5420.879999999999, "text": " I think they're all very far from solving the problem.", "tokens": [50440, 286, 519, 436, 434, 439, 588, 1400, 490, 12606, 264, 1154, 13, 50536], "temperature": 0.0, "avg_logprob": -0.10959959763746996, "compression_ratio": 1.662162162162162, "no_speech_prob": 0.016125747933983803}, {"id": 1932, "seek": 541744, "start": 5420.879999999999, "end": 5424.08, "text": " They are over complicated and not powerful enough.", "tokens": [50536, 814, 366, 670, 6179, 293, 406, 4005, 1547, 13, 50696], "temperature": 0.0, "avg_logprob": -0.10959959763746996, "compression_ratio": 1.662162162162162, "no_speech_prob": 0.016125747933983803}, {"id": 1933, "seek": 541744, "start": 5424.08, "end": 5426.96, "text": " So, you know, I've been working on an approach called TensorFlow logic", "tokens": [50696, 407, 11, 291, 458, 11, 286, 600, 668, 1364, 322, 364, 3109, 1219, 37624, 9952, 50840], "temperature": 0.0, "avg_logprob": -0.10959959763746996, "compression_ratio": 1.662162162162162, "no_speech_prob": 0.016125747933983803}, {"id": 1934, "seek": 541744, "start": 5426.96, "end": 5433.2, "text": " that I do believe is as simple as it can be and as general as it can or needs to be.", "tokens": [50840, 300, 286, 360, 1697, 307, 382, 2199, 382, 309, 393, 312, 293, 382, 2674, 382, 309, 393, 420, 2203, 281, 312, 13, 51152], "temperature": 0.0, "avg_logprob": -0.10959959763746996, "compression_ratio": 1.662162162162162, "no_speech_prob": 0.016125747933983803}, {"id": 1935, "seek": 541744, "start": 5433.759999999999, "end": 5438.24, "text": " And this, you know, it really is a deep unification of the two things", "tokens": [51180, 400, 341, 11, 291, 458, 11, 309, 534, 307, 257, 2452, 517, 3774, 295, 264, 732, 721, 51404], "temperature": 0.0, "avg_logprob": -0.10959959763746996, "compression_ratio": 1.662162162162162, "no_speech_prob": 0.016125747933983803}, {"id": 1936, "seek": 541744, "start": 5438.24, "end": 5442.32, "text": " in the sense that it's not just that you combine them using, you know,", "tokens": [51404, 294, 264, 2020, 300, 309, 311, 406, 445, 300, 291, 10432, 552, 1228, 11, 291, 458, 11, 51608], "temperature": 0.0, "avg_logprob": -0.10959959763746996, "compression_ratio": 1.662162162162162, "no_speech_prob": 0.016125747933983803}, {"id": 1937, "seek": 541744, "start": 5442.32, "end": 5445.04, "text": " a neural model that causes symbolic one or vice versa,", "tokens": [51608, 257, 18161, 2316, 300, 7700, 25755, 472, 420, 11964, 25650, 11, 51744], "temperature": 0.0, "avg_logprob": -0.10959959763746996, "compression_ratio": 1.662162162162162, "no_speech_prob": 0.016125747933983803}, {"id": 1938, "seek": 544504, "start": 5445.04, "end": 5447.5199999999995, "text": " which is a lot of what these things that you have today do.", "tokens": [50364, 597, 307, 257, 688, 295, 437, 613, 721, 300, 291, 362, 965, 360, 13, 50488], "temperature": 0.0, "avg_logprob": -0.12477797792668928, "compression_ratio": 1.6875, "no_speech_prob": 0.011824692599475384}, {"id": 1939, "seek": 544504, "start": 5447.5199999999995, "end": 5451.68, "text": " And a lot of the claims that like, oh, this system is neuro symbolic, which it is.", "tokens": [50488, 400, 257, 688, 295, 264, 9441, 300, 411, 11, 1954, 11, 341, 1185, 307, 16499, 25755, 11, 597, 309, 307, 13, 50696], "temperature": 0.0, "avg_logprob": -0.12477797792668928, "compression_ratio": 1.6875, "no_speech_prob": 0.011824692599475384}, {"id": 1940, "seek": 544504, "start": 5451.68, "end": 5455.6, "text": " It's like, you know, AlphaGo is neuro symbolic because some of what it does is symbolic.", "tokens": [50696, 467, 311, 411, 11, 291, 458, 11, 20588, 12104, 307, 16499, 25755, 570, 512, 295, 437, 309, 775, 307, 25755, 13, 50892], "temperature": 0.0, "avg_logprob": -0.12477797792668928, "compression_ratio": 1.6875, "no_speech_prob": 0.011824692599475384}, {"id": 1941, "seek": 544504, "start": 5455.6, "end": 5460.96, "text": " But I'm talking about something much deeper, which is once you start doing AI,", "tokens": [50892, 583, 286, 478, 1417, 466, 746, 709, 7731, 11, 597, 307, 1564, 291, 722, 884, 7318, 11, 51160], "temperature": 0.0, "avg_logprob": -0.12477797792668928, "compression_ratio": 1.6875, "no_speech_prob": 0.011824692599475384}, {"id": 1942, "seek": 544504, "start": 5460.96, "end": 5463.44, "text": " learning inference representation in TensorFlow logic,", "tokens": [51160, 2539, 38253, 10290, 294, 37624, 9952, 11, 51284], "temperature": 0.0, "avg_logprob": -0.12477797792668928, "compression_ratio": 1.6875, "no_speech_prob": 0.011824692599475384}, {"id": 1943, "seek": 544504, "start": 5463.44, "end": 5468.72, "text": " there's just no distinction between symbolic and neural at all anymore.", "tokens": [51284, 456, 311, 445, 572, 16844, 1296, 25755, 293, 18161, 412, 439, 3602, 13, 51548], "temperature": 0.0, "avg_logprob": -0.12477797792668928, "compression_ratio": 1.6875, "no_speech_prob": 0.011824692599475384}, {"id": 1944, "seek": 544504, "start": 5469.84, "end": 5470.96, "text": " Can you explain that?", "tokens": [51604, 1664, 291, 2903, 300, 30, 51660], "temperature": 0.0, "avg_logprob": -0.12477797792668928, "compression_ratio": 1.6875, "no_speech_prob": 0.011824692599475384}, {"id": 1945, "seek": 547096, "start": 5470.96, "end": 5476.0, "text": " So TensorFlow logic, I'm just inferring from that that the primary representation", "tokens": [50364, 407, 37624, 9952, 11, 286, 478, 445, 13596, 2937, 490, 300, 300, 264, 6194, 10290, 50616], "temperature": 0.0, "avg_logprob": -0.13331198504590613, "compression_ratio": 1.8356643356643356, "no_speech_prob": 0.002929369919002056}, {"id": 1946, "seek": 547096, "start": 5476.0, "end": 5478.64, "text": " of substrate is a continuous vector space. Is that right?", "tokens": [50616, 295, 27585, 307, 257, 10957, 8062, 1901, 13, 1119, 300, 558, 30, 50748], "temperature": 0.0, "avg_logprob": -0.13331198504590613, "compression_ratio": 1.8356643356643356, "no_speech_prob": 0.002929369919002056}, {"id": 1947, "seek": 547096, "start": 5478.64, "end": 5481.2, "text": " Are you encoding discrete information into the vector space?", "tokens": [50748, 2014, 291, 43430, 27706, 1589, 666, 264, 8062, 1901, 30, 50876], "temperature": 0.0, "avg_logprob": -0.13331198504590613, "compression_ratio": 1.8356643356643356, "no_speech_prob": 0.002929369919002056}, {"id": 1948, "seek": 547096, "start": 5481.2, "end": 5483.28, "text": " So it's a vector space. Yeah.", "tokens": [50876, 407, 309, 311, 257, 8062, 1901, 13, 865, 13, 50980], "temperature": 0.0, "avg_logprob": -0.13331198504590613, "compression_ratio": 1.8356643356643356, "no_speech_prob": 0.002929369919002056}, {"id": 1949, "seek": 547096, "start": 5483.28, "end": 5488.08, "text": " Right. In fact, this was the original term that we had for this was vector space logic.", "tokens": [50980, 1779, 13, 682, 1186, 11, 341, 390, 264, 3380, 1433, 300, 321, 632, 337, 341, 390, 8062, 1901, 9952, 13, 51220], "temperature": 0.0, "avg_logprob": -0.13331198504590613, "compression_ratio": 1.8356643356643356, "no_speech_prob": 0.002929369919002056}, {"id": 1950, "seek": 547096, "start": 5488.08, "end": 5490.88, "text": " But then we changed it to TensorFlow logic because it's much more appropriate.", "tokens": [51220, 583, 550, 321, 3105, 309, 281, 37624, 9952, 570, 309, 311, 709, 544, 6854, 13, 51360], "temperature": 0.0, "avg_logprob": -0.13331198504590613, "compression_ratio": 1.8356643356643356, "no_speech_prob": 0.002929369919002056}, {"id": 1951, "seek": 547096, "start": 5490.88, "end": 5494.96, "text": " But it's it's vector space in the abstract algebra sense of vector space,", "tokens": [51360, 583, 309, 311, 309, 311, 8062, 1901, 294, 264, 12649, 21989, 2020, 295, 8062, 1901, 11, 51564], "temperature": 0.0, "avg_logprob": -0.13331198504590613, "compression_ratio": 1.8356643356643356, "no_speech_prob": 0.002929369919002056}, {"id": 1952, "seek": 547096, "start": 5494.96, "end": 5497.2, "text": " not in the traditional, you know, vectors of numbers.", "tokens": [51564, 406, 294, 264, 5164, 11, 291, 458, 11, 18875, 295, 3547, 13, 51676], "temperature": 0.0, "avg_logprob": -0.13331198504590613, "compression_ratio": 1.8356643356643356, "no_speech_prob": 0.002929369919002056}, {"id": 1953, "seek": 549720, "start": 5497.76, "end": 5506.0, "text": " But anyway, so as the name implies, right, TensorFlow logic is a combination or unification", "tokens": [50392, 583, 4033, 11, 370, 382, 264, 1315, 18779, 11, 558, 11, 37624, 9952, 307, 257, 6562, 420, 517, 3774, 50804], "temperature": 0.0, "avg_logprob": -0.14706304884448493, "compression_ratio": 1.5269709543568464, "no_speech_prob": 0.007800151128321886}, {"id": 1954, "seek": 549720, "start": 5506.0, "end": 5510.8, "text": " of tensor algebra on the one hand and logic programming on the other.", "tokens": [50804, 295, 40863, 21989, 322, 264, 472, 1011, 293, 9952, 9410, 322, 264, 661, 13, 51044], "temperature": 0.0, "avg_logprob": -0.14706304884448493, "compression_ratio": 1.5269709543568464, "no_speech_prob": 0.007800151128321886}, {"id": 1955, "seek": 549720, "start": 5510.8, "end": 5515.2, "text": " So is it similar because Bob Koeck had a similar idea using like tensor outer products?", "tokens": [51044, 407, 307, 309, 2531, 570, 6085, 591, 7921, 547, 632, 257, 2531, 1558, 1228, 411, 40863, 10847, 3383, 30, 51264], "temperature": 0.0, "avg_logprob": -0.14706304884448493, "compression_ratio": 1.5269709543568464, "no_speech_prob": 0.007800151128321886}, {"id": 1956, "seek": 549720, "start": 5516.0, "end": 5517.04, "text": " Is it that kind of?", "tokens": [51304, 1119, 309, 300, 733, 295, 30, 51356], "temperature": 0.0, "avg_logprob": -0.14706304884448493, "compression_ratio": 1.5269709543568464, "no_speech_prob": 0.007800151128321886}, {"id": 1957, "seek": 549720, "start": 5517.04, "end": 5519.5199999999995, "text": " It's related, but I think it goes well beyond.", "tokens": [51356, 467, 311, 4077, 11, 457, 286, 519, 309, 1709, 731, 4399, 13, 51480], "temperature": 0.0, "avg_logprob": -0.14706304884448493, "compression_ratio": 1.5269709543568464, "no_speech_prob": 0.007800151128321886}, {"id": 1958, "seek": 549720, "start": 5519.5199999999995, "end": 5520.16, "text": " Okay.", "tokens": [51480, 1033, 13, 51512], "temperature": 0.0, "avg_logprob": -0.14706304884448493, "compression_ratio": 1.5269709543568464, "no_speech_prob": 0.007800151128321886}, {"id": 1959, "seek": 549720, "start": 5520.16, "end": 5523.12, "text": " And the basic idea is actually pretty simple.", "tokens": [51512, 400, 264, 3875, 1558, 307, 767, 1238, 2199, 13, 51660], "temperature": 0.0, "avg_logprob": -0.14706304884448493, "compression_ratio": 1.5269709543568464, "no_speech_prob": 0.007800151128321886}, {"id": 1960, "seek": 552312, "start": 5523.12, "end": 5528.16, "text": " And it's just the following, right, without going into too much, you know, technical detail.", "tokens": [50364, 400, 309, 311, 445, 264, 3480, 11, 558, 11, 1553, 516, 666, 886, 709, 11, 291, 458, 11, 6191, 2607, 13, 50616], "temperature": 0.0, "avg_logprob": -0.13763202193879734, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.007336123380810022}, {"id": 1961, "seek": 552312, "start": 5529.2, "end": 5532.32, "text": " All of deep learning can be done using tensor algebra.", "tokens": [50668, 1057, 295, 2452, 2539, 393, 312, 1096, 1228, 40863, 21989, 13, 50824], "temperature": 0.0, "avg_logprob": -0.13763202193879734, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.007336123380810022}, {"id": 1962, "seek": 552312, "start": 5532.32, "end": 5536.32, "text": " Yeah, you know, plus univariate nonlinearities.", "tokens": [50824, 865, 11, 291, 458, 11, 1804, 517, 592, 3504, 473, 2107, 28263, 1088, 13, 51024], "temperature": 0.0, "avg_logprob": -0.13763202193879734, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.007336123380810022}, {"id": 1963, "seek": 552312, "start": 5536.32, "end": 5538.88, "text": " Right. So we've got the tensor algebra to do that.", "tokens": [51024, 1779, 13, 407, 321, 600, 658, 264, 40863, 21989, 281, 360, 300, 13, 51152], "temperature": 0.0, "avg_logprob": -0.13763202193879734, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.007336123380810022}, {"id": 1964, "seek": 552312, "start": 5538.88, "end": 5541.68, "text": " All of symbolic AI can be done using logic programming.", "tokens": [51152, 1057, 295, 25755, 7318, 393, 312, 1096, 1228, 9952, 9410, 13, 51292], "temperature": 0.0, "avg_logprob": -0.13763202193879734, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.007336123380810022}, {"id": 1965, "seek": 552312, "start": 5541.68, "end": 5543.92, "text": " And moreover, it has been done using logic program.", "tokens": [51292, 400, 544, 3570, 11, 309, 575, 668, 1096, 1228, 9952, 1461, 13, 51404], "temperature": 0.0, "avg_logprob": -0.13763202193879734, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.007336123380810022}, {"id": 1966, "seek": 552312, "start": 5543.92, "end": 5547.12, "text": " So if you can unify these two things, this part of the job is done.", "tokens": [51404, 407, 498, 291, 393, 517, 2505, 613, 732, 721, 11, 341, 644, 295, 264, 1691, 307, 1096, 13, 51564], "temperature": 0.0, "avg_logprob": -0.13763202193879734, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.007336123380810022}, {"id": 1967, "seek": 552312, "start": 5547.12, "end": 5552.72, "text": " Right. And as it turns out, you can unify them shockingly easily because a tensor", "tokens": [51564, 1779, 13, 400, 382, 309, 4523, 484, 11, 291, 393, 517, 2505, 552, 5588, 12163, 3612, 570, 257, 40863, 51844], "temperature": 0.0, "avg_logprob": -0.13763202193879734, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.007336123380810022}, {"id": 1968, "seek": 555272, "start": 5553.2, "end": 5559.12, "text": " so tensor algebra is operating on tensors, you know, in that logic, so logic programming,", "tokens": [50388, 370, 40863, 21989, 307, 7447, 322, 10688, 830, 11, 291, 458, 11, 294, 300, 9952, 11, 370, 9952, 9410, 11, 50684], "temperature": 0.0, "avg_logprob": -0.1607255560206616, "compression_ratio": 1.886120996441281, "no_speech_prob": 0.0014994373777881265}, {"id": 1969, "seek": 555272, "start": 5559.12, "end": 5563.84, "text": " and then for learning in that logic program and symbolic AI, they are all operating on relations.", "tokens": [50684, 293, 550, 337, 2539, 294, 300, 9952, 1461, 293, 25755, 7318, 11, 436, 366, 439, 7447, 322, 2299, 13, 50920], "temperature": 0.0, "avg_logprob": -0.1607255560206616, "compression_ratio": 1.886120996441281, "no_speech_prob": 0.0014994373777881265}, {"id": 1970, "seek": 555272, "start": 5563.84, "end": 5564.16, "text": " Yeah.", "tokens": [50920, 865, 13, 50936], "temperature": 0.0, "avg_logprob": -0.1607255560206616, "compression_ratio": 1.886120996441281, "no_speech_prob": 0.0014994373777881265}, {"id": 1971, "seek": 555272, "start": 5564.16, "end": 5567.68, "text": " Right. So what is the relationship between the tensor and the relation?", "tokens": [50936, 1779, 13, 407, 437, 307, 264, 2480, 1296, 264, 40863, 293, 264, 9721, 30, 51112], "temperature": 0.0, "avg_logprob": -0.1607255560206616, "compression_ratio": 1.886120996441281, "no_speech_prob": 0.0014994373777881265}, {"id": 1972, "seek": 555272, "start": 5567.68, "end": 5572.56, "text": " Right. A relation is just this and efficiently represented sparse Boolean tensor.", "tokens": [51112, 1779, 13, 316, 9721, 307, 445, 341, 293, 19621, 10379, 637, 11668, 23351, 28499, 40863, 13, 51356], "temperature": 0.0, "avg_logprob": -0.1607255560206616, "compression_ratio": 1.886120996441281, "no_speech_prob": 0.0014994373777881265}, {"id": 1973, "seek": 555272, "start": 5573.52, "end": 5577.2, "text": " So at this point, we actually know that the foundation of these two things is actually the", "tokens": [51404, 407, 412, 341, 935, 11, 321, 767, 458, 300, 264, 7030, 295, 613, 732, 721, 307, 767, 264, 51588], "temperature": 0.0, "avg_logprob": -0.1607255560206616, "compression_ratio": 1.886120996441281, "no_speech_prob": 0.0014994373777881265}, {"id": 1974, "seek": 555272, "start": 5577.2, "end": 5582.4800000000005, "text": " same. If your tensor is Boolean and is very sparse, now I'm better off representing it with", "tokens": [51588, 912, 13, 759, 428, 40863, 307, 23351, 28499, 293, 307, 588, 637, 11668, 11, 586, 286, 478, 1101, 766, 13460, 309, 365, 51852], "temperature": 0.0, "avg_logprob": -0.1607255560206616, "compression_ratio": 1.886120996441281, "no_speech_prob": 0.0014994373777881265}, {"id": 1975, "seek": 558248, "start": 5582.48, "end": 5586.0, "text": " a relation, but at a certain level of abstraction, nothing has changed.", "tokens": [50364, 257, 9721, 11, 457, 412, 257, 1629, 1496, 295, 37765, 11, 1825, 575, 3105, 13, 50540], "temperature": 0.0, "avg_logprob": -0.11410195236906, "compression_ratio": 1.6750902527075813, "no_speech_prob": 0.0009383417782373726}, {"id": 1976, "seek": 558248, "start": 5586.0, "end": 5591.28, "text": " Right. So by this prism, you can look at logic programming and logic programming is doing tensor", "tokens": [50540, 1779, 13, 407, 538, 341, 582, 1434, 11, 291, 393, 574, 412, 9952, 9410, 293, 9952, 9410, 307, 884, 40863, 50804], "temperature": 0.0, "avg_logprob": -0.11410195236906, "compression_ratio": 1.6750902527075813, "no_speech_prob": 0.0009383417782373726}, {"id": 1977, "seek": 558248, "start": 5591.28, "end": 5591.759999999999, "text": " algebra.", "tokens": [50804, 21989, 13, 50828], "temperature": 0.0, "avg_logprob": -0.11410195236906, "compression_ratio": 1.6750902527075813, "no_speech_prob": 0.0009383417782373726}, {"id": 1978, "seek": 558248, "start": 5592.719999999999, "end": 5598.0, "text": " Okay. Just help me understand this a little bit. So, you know, the main criticism of using a neural", "tokens": [50876, 1033, 13, 1449, 854, 385, 1223, 341, 257, 707, 857, 13, 407, 11, 291, 458, 11, 264, 2135, 15835, 295, 1228, 257, 18161, 51140], "temperature": 0.0, "avg_logprob": -0.11410195236906, "compression_ratio": 1.6750902527075813, "no_speech_prob": 0.0009383417782373726}, {"id": 1979, "seek": 558248, "start": 5598.0, "end": 5604.48, "text": " network as a combined computational and memory substrate is that it's a finite state automator.", "tokens": [51140, 3209, 382, 257, 9354, 28270, 293, 4675, 27585, 307, 300, 309, 311, 257, 19362, 1785, 3553, 1639, 13, 51464], "temperature": 0.0, "avg_logprob": -0.11410195236906, "compression_ratio": 1.6750902527075813, "no_speech_prob": 0.0009383417782373726}, {"id": 1980, "seek": 558248, "start": 5604.48, "end": 5609.2, "text": " So without having the augmented memory like a Turing machine, you can't represent infinite", "tokens": [51464, 407, 1553, 1419, 264, 36155, 4675, 411, 257, 314, 1345, 3479, 11, 291, 393, 380, 2906, 13785, 51700], "temperature": 0.0, "avg_logprob": -0.11410195236906, "compression_ratio": 1.6750902527075813, "no_speech_prob": 0.0009383417782373726}, {"id": 1981, "seek": 560920, "start": 5609.2, "end": 5612.5599999999995, "text": " objects. That's the main reason the symbol is, you know, that's the main argument I used.", "tokens": [50364, 6565, 13, 663, 311, 264, 2135, 1778, 264, 5986, 307, 11, 291, 458, 11, 300, 311, 264, 2135, 6770, 286, 1143, 13, 50532], "temperature": 0.0, "avg_logprob": -0.12120866775512695, "compression_ratio": 1.806228373702422, "no_speech_prob": 0.016363969072699547}, {"id": 1982, "seek": 560920, "start": 5612.5599999999995, "end": 5615.5199999999995, "text": " So wouldn't that argument still be leveled against you?", "tokens": [50532, 407, 2759, 380, 300, 6770, 920, 312, 1496, 292, 1970, 291, 30, 50680], "temperature": 0.0, "avg_logprob": -0.12120866775512695, "compression_ratio": 1.806228373702422, "no_speech_prob": 0.016363969072699547}, {"id": 1983, "seek": 560920, "start": 5615.5199999999995, "end": 5620.5599999999995, "text": " Well, no, because I'm glad you brought that up because there is a very common misconception.", "tokens": [50680, 1042, 11, 572, 11, 570, 286, 478, 5404, 291, 3038, 300, 493, 570, 456, 307, 257, 588, 2689, 41350, 13, 50932], "temperature": 0.0, "avg_logprob": -0.12120866775512695, "compression_ratio": 1.806228373702422, "no_speech_prob": 0.016363969072699547}, {"id": 1984, "seek": 560920, "start": 5620.5599999999995, "end": 5624.8, "text": " If you realize that there is no such thing as infinity, right? And in particular, there is no", "tokens": [50932, 759, 291, 4325, 300, 456, 307, 572, 1270, 551, 382, 13202, 11, 558, 30, 400, 294, 1729, 11, 456, 307, 572, 51144], "temperature": 0.0, "avg_logprob": -0.12120866775512695, "compression_ratio": 1.806228373702422, "no_speech_prob": 0.016363969072699547}, {"id": 1985, "seek": 560920, "start": 5624.8, "end": 5630.96, "text": " such thing as an infinite memory. That problem doesn't arise. So there's the, so the, unfortunately,", "tokens": [51144, 1270, 551, 382, 364, 13785, 4675, 13, 663, 1154, 1177, 380, 20288, 13, 407, 456, 311, 264, 11, 370, 264, 11, 7015, 11, 51452], "temperature": 0.0, "avg_logprob": -0.12120866775512695, "compression_ratio": 1.806228373702422, "no_speech_prob": 0.016363969072699547}, {"id": 1986, "seek": 560920, "start": 5630.96, "end": 5636.639999999999, "text": " a lot of theorists, including computer theorists, they foster this misconception, right?", "tokens": [51452, 257, 688, 295, 27423, 1751, 11, 3009, 3820, 27423, 1751, 11, 436, 17114, 341, 41350, 11, 558, 30, 51736], "temperature": 0.0, "avg_logprob": -0.12120866775512695, "compression_ratio": 1.806228373702422, "no_speech_prob": 0.016363969072699547}, {"id": 1987, "seek": 563664, "start": 5636.64, "end": 5641.68, "text": " There's the Chomsky hierarchy, right? With finite automata at the bottom and Turing complete,", "tokens": [50364, 821, 311, 264, 761, 4785, 4133, 22333, 11, 558, 30, 2022, 19362, 3553, 3274, 412, 264, 2767, 293, 314, 1345, 3566, 11, 50616], "temperature": 0.0, "avg_logprob": -0.10275434836363181, "compression_ratio": 1.8693877551020408, "no_speech_prob": 0.005381210241466761}, {"id": 1988, "seek": 563664, "start": 5641.68, "end": 5646.0, "text": " you know, Turing machines bubble at the top, right? If your Turing machine has only a finite", "tokens": [50616, 291, 458, 11, 314, 1345, 8379, 12212, 412, 264, 1192, 11, 558, 30, 759, 428, 314, 1345, 3479, 575, 787, 257, 19362, 50832], "temperature": 0.0, "avg_logprob": -0.10275434836363181, "compression_ratio": 1.8693877551020408, "no_speech_prob": 0.005381210241466761}, {"id": 1989, "seek": 563664, "start": 5646.0, "end": 5651.92, "text": " tape, it's a finite automata. So everything is just finite automata. Let's get that out of the way,", "tokens": [50832, 7314, 11, 309, 311, 257, 19362, 3553, 3274, 13, 407, 1203, 307, 445, 19362, 3553, 3274, 13, 961, 311, 483, 300, 484, 295, 264, 636, 11, 51128], "temperature": 0.0, "avg_logprob": -0.10275434836363181, "compression_ratio": 1.8693877551020408, "no_speech_prob": 0.005381210241466761}, {"id": 1990, "seek": 563664, "start": 5651.92, "end": 5656.160000000001, "text": " right? A lot of what people do is like completely mistaken because of that. Now,", "tokens": [51128, 558, 30, 316, 688, 295, 437, 561, 360, 307, 411, 2584, 21333, 570, 295, 300, 13, 823, 11, 51340], "temperature": 0.0, "avg_logprob": -0.10275434836363181, "compression_ratio": 1.8693877551020408, "no_speech_prob": 0.005381210241466761}, {"id": 1991, "seek": 563664, "start": 5656.88, "end": 5661.360000000001, "text": " the fact that everything is finite automata does not mean that everything is equally good.", "tokens": [51376, 264, 1186, 300, 1203, 307, 19362, 3553, 3274, 775, 406, 914, 300, 1203, 307, 12309, 665, 13, 51600], "temperature": 0.0, "avg_logprob": -0.10275434836363181, "compression_ratio": 1.8693877551020408, "no_speech_prob": 0.005381210241466761}, {"id": 1992, "seek": 566136, "start": 5661.36, "end": 5667.04, "text": " Some representations are far more efficient, compact, etc., etc., for certain purposes than", "tokens": [50364, 2188, 33358, 366, 1400, 544, 7148, 11, 14679, 11, 5183, 7933, 5183, 7933, 337, 1629, 9932, 813, 50648], "temperature": 0.0, "avg_logprob": -0.12254778979575798, "compression_ratio": 1.6946107784431137, "no_speech_prob": 0.03304072842001915}, {"id": 1993, "seek": 566136, "start": 5667.04, "end": 5671.599999999999, "text": " others. And the whole game here is that like, I'm not going to solve a finite automata. The question", "tokens": [50648, 2357, 13, 400, 264, 1379, 1216, 510, 307, 300, 411, 11, 286, 478, 406, 516, 281, 5039, 257, 19362, 3553, 3274, 13, 440, 1168, 50876], "temperature": 0.0, "avg_logprob": -0.12254778979575798, "compression_ratio": 1.6946107784431137, "no_speech_prob": 0.03304072842001915}, {"id": 1994, "seek": 566136, "start": 5671.599999999999, "end": 5676.0, "text": " is like, what do I need to do? Not because I need to go to a higher level of Chomsky hierarchy,", "tokens": [50876, 307, 411, 11, 437, 360, 286, 643, 281, 360, 30, 1726, 570, 286, 643, 281, 352, 281, 257, 2946, 1496, 295, 761, 4785, 4133, 22333, 11, 51096], "temperature": 0.0, "avg_logprob": -0.12254778979575798, "compression_ratio": 1.6946107784431137, "no_speech_prob": 0.03304072842001915}, {"id": 1995, "seek": 566136, "start": 5676.0, "end": 5681.839999999999, "text": " because in reality, they don't exist. But because, you know, I mean, if you have infinite resources,", "tokens": [51096, 570, 294, 4103, 11, 436, 500, 380, 2514, 13, 583, 570, 11, 291, 458, 11, 286, 914, 11, 498, 291, 362, 13785, 3593, 11, 51388], "temperature": 0.0, "avg_logprob": -0.12254778979575798, "compression_ratio": 1.6946107784431137, "no_speech_prob": 0.03304072842001915}, {"id": 1996, "seek": 566136, "start": 5681.839999999999, "end": 5686.0, "text": " you could solve a gap with a lookup table. But would you, would you not? I mean, for example,", "tokens": [51388, 291, 727, 5039, 257, 7417, 365, 257, 574, 1010, 3199, 13, 583, 576, 291, 11, 576, 291, 406, 30, 286, 914, 11, 337, 1365, 11, 51596], "temperature": 0.0, "avg_logprob": -0.12254778979575798, "compression_ratio": 1.6946107784431137, "no_speech_prob": 0.03304072842001915}, {"id": 1997, "seek": 566136, "start": 5686.0, "end": 5689.28, "text": " there was this DeepMind paper that mapped architectures to different levels of the", "tokens": [51596, 456, 390, 341, 14895, 44, 471, 3035, 300, 33318, 6331, 1303, 281, 819, 4358, 295, 264, 51760], "temperature": 0.0, "avg_logprob": -0.12254778979575798, "compression_ratio": 1.6946107784431137, "no_speech_prob": 0.03304072842001915}, {"id": 1998, "seek": 568928, "start": 5689.28, "end": 5695.599999999999, "text": " Chomsky hierarchy transformers, I think were, you know, FSAs, RNNs actually were one step higher.", "tokens": [50364, 761, 4785, 4133, 22333, 4088, 433, 11, 286, 519, 645, 11, 291, 458, 11, 479, 8886, 82, 11, 45702, 45, 82, 767, 645, 472, 1823, 2946, 13, 50680], "temperature": 0.0, "avg_logprob": -0.11662356781237053, "compression_ratio": 1.729559748427673, "no_speech_prob": 0.0038795366417616606}, {"id": 1999, "seek": 568928, "start": 5695.599999999999, "end": 5699.2, "text": " They could represent regular languages and they got context-free languages. I mean,", "tokens": [50680, 814, 727, 2906, 3890, 8650, 293, 436, 658, 4319, 12, 10792, 8650, 13, 286, 914, 11, 50860], "temperature": 0.0, "avg_logprob": -0.11662356781237053, "compression_ratio": 1.729559748427673, "no_speech_prob": 0.0038795366417616606}, {"id": 2000, "seek": 568928, "start": 5699.2, "end": 5702.639999999999, "text": " do you think there's any meaningful distinction between those language levels?", "tokens": [50860, 360, 291, 519, 456, 311, 604, 10995, 16844, 1296, 729, 2856, 4358, 30, 51032], "temperature": 0.0, "avg_logprob": -0.11662356781237053, "compression_ratio": 1.729559748427673, "no_speech_prob": 0.0038795366417616606}, {"id": 2001, "seek": 568928, "start": 5702.639999999999, "end": 5707.12, "text": " As I said, there is a meaningful distinction, but it's not the distinction that people usually make,", "tokens": [51032, 1018, 286, 848, 11, 456, 307, 257, 10995, 16844, 11, 457, 309, 311, 406, 264, 16844, 300, 561, 2673, 652, 11, 51256], "temperature": 0.0, "avg_logprob": -0.11662356781237053, "compression_ratio": 1.729559748427673, "no_speech_prob": 0.0038795366417616606}, {"id": 2002, "seek": 568928, "start": 5707.12, "end": 5712.16, "text": " because once you, I mean, you can debate whether the universe is finite, but certainly computers", "tokens": [51256, 570, 1564, 291, 11, 286, 914, 11, 291, 393, 7958, 1968, 264, 6445, 307, 19362, 11, 457, 3297, 10807, 51508], "temperature": 0.0, "avg_logprob": -0.11662356781237053, "compression_ratio": 1.729559748427673, "no_speech_prob": 0.0038795366417616606}, {"id": 2003, "seek": 568928, "start": 5712.16, "end": 5716.0, "text": " are finite. So as far as anything that you're going to run on a computer, there truly is no", "tokens": [51508, 366, 19362, 13, 407, 382, 1400, 382, 1340, 300, 291, 434, 516, 281, 1190, 322, 257, 3820, 11, 456, 4908, 307, 572, 51700], "temperature": 0.0, "avg_logprob": -0.11662356781237053, "compression_ratio": 1.729559748427673, "no_speech_prob": 0.0038795366417616606}, {"id": 2004, "seek": 571600, "start": 5716.0, "end": 5721.12, "text": " distinction at this theoretical level between a Turing machine and a finite automata. That does,", "tokens": [50364, 16844, 412, 341, 20864, 1496, 1296, 257, 314, 1345, 3479, 293, 257, 19362, 3553, 3274, 13, 663, 775, 11, 50620], "temperature": 0.0, "avg_logprob": -0.12529298994276258, "compression_ratio": 1.7784615384615385, "no_speech_prob": 0.03254982456564903}, {"id": 2005, "seek": 571600, "start": 5721.12, "end": 5725.52, "text": " so like, I can reduce and people have, there are papers reducing, you know, any of these things to", "tokens": [50620, 370, 411, 11, 286, 393, 5407, 293, 561, 362, 11, 456, 366, 10577, 12245, 11, 291, 458, 11, 604, 295, 613, 721, 281, 50840], "temperature": 0.0, "avg_logprob": -0.12529298994276258, "compression_ratio": 1.7784615384615385, "no_speech_prob": 0.03254982456564903}, {"id": 2006, "seek": 571600, "start": 5725.52, "end": 5730.32, "text": " any of the others, right? It's like it's a fairly trivial exercise. So at that level, those distinctions", "tokens": [50840, 604, 295, 264, 2357, 11, 558, 30, 467, 311, 411, 309, 311, 257, 6457, 26703, 5380, 13, 407, 412, 300, 1496, 11, 729, 1483, 49798, 51080], "temperature": 0.0, "avg_logprob": -0.12529298994276258, "compression_ratio": 1.7784615384615385, "no_speech_prob": 0.03254982456564903}, {"id": 2007, "seek": 571600, "start": 5730.32, "end": 5735.04, "text": " are completely meaningless. However, they are meaningful in the sense that for many purposes,", "tokens": [51080, 366, 2584, 33232, 13, 2908, 11, 436, 366, 10995, 294, 264, 2020, 300, 337, 867, 9932, 11, 51316], "temperature": 0.0, "avg_logprob": -0.12529298994276258, "compression_ratio": 1.7784615384615385, "no_speech_prob": 0.03254982456564903}, {"id": 2008, "seek": 571600, "start": 5735.04, "end": 5740.32, "text": " I am better off having an RNN than having, you know, a transformer. And for many purposes,", "tokens": [51316, 286, 669, 1101, 766, 1419, 364, 45702, 45, 813, 1419, 11, 291, 458, 11, 257, 31782, 13, 400, 337, 867, 9932, 11, 51580], "temperature": 0.0, "avg_logprob": -0.12529298994276258, "compression_ratio": 1.7784615384615385, "no_speech_prob": 0.03254982456564903}, {"id": 2009, "seek": 571600, "start": 5740.32, "end": 5744.96, "text": " I'm better off. So like, let's take, you know, propositional logic versus first-order logic,", "tokens": [51580, 286, 478, 1101, 766, 13, 407, 411, 11, 718, 311, 747, 11, 291, 458, 11, 7532, 2628, 9952, 5717, 700, 12, 4687, 9952, 11, 51812], "temperature": 0.0, "avg_logprob": -0.12529298994276258, "compression_ratio": 1.7784615384615385, "no_speech_prob": 0.03254982456564903}, {"id": 2010, "seek": 574496, "start": 5744.96, "end": 5750.08, "text": " right? If there's no such thing as infinity, first-order logic is reducible to propositional", "tokens": [50364, 558, 30, 759, 456, 311, 572, 1270, 551, 382, 13202, 11, 700, 12, 4687, 9952, 307, 2783, 32128, 281, 7532, 2628, 50620], "temperature": 0.0, "avg_logprob": -0.0996317247144219, "compression_ratio": 1.891089108910891, "no_speech_prob": 0.005881445948034525}, {"id": 2011, "seek": 574496, "start": 5750.08, "end": 5755.28, "text": " logic. But that does not mean that it's useless because it can represent a lot of things exponentially", "tokens": [50620, 9952, 13, 583, 300, 775, 406, 914, 300, 309, 311, 14115, 570, 309, 393, 2906, 257, 688, 295, 721, 37330, 50880], "temperature": 0.0, "avg_logprob": -0.0996317247144219, "compression_ratio": 1.891089108910891, "no_speech_prob": 0.005881445948034525}, {"id": 2012, "seek": 574496, "start": 5755.28, "end": 5760.16, "text": " more compactly than propositional logic. If I want to represent the rules of chess in first-order", "tokens": [50880, 544, 14679, 356, 813, 7532, 2628, 9952, 13, 759, 286, 528, 281, 2906, 264, 4474, 295, 24122, 294, 700, 12, 4687, 51124], "temperature": 0.0, "avg_logprob": -0.0996317247144219, "compression_ratio": 1.891089108910891, "no_speech_prob": 0.005881445948034525}, {"id": 2013, "seek": 574496, "start": 5760.16, "end": 5765.04, "text": " logic, it's a page, right? If I want to represent them in propositional logic, it's more pages that", "tokens": [51124, 9952, 11, 309, 311, 257, 3028, 11, 558, 30, 759, 286, 528, 281, 2906, 552, 294, 7532, 2628, 9952, 11, 309, 311, 544, 7183, 300, 51368], "temperature": 0.0, "avg_logprob": -0.0996317247144219, "compression_ratio": 1.891089108910891, "no_speech_prob": 0.005881445948034525}, {"id": 2014, "seek": 574496, "start": 5765.04, "end": 5768.4800000000005, "text": " you can have. Okay, well, I think that that's a very, very good point. But I mean, just, just", "tokens": [51368, 291, 393, 362, 13, 1033, 11, 731, 11, 286, 519, 300, 300, 311, 257, 588, 11, 588, 665, 935, 13, 583, 286, 914, 11, 445, 11, 445, 51540], "temperature": 0.0, "avg_logprob": -0.0996317247144219, "compression_ratio": 1.891089108910891, "no_speech_prob": 0.005881445948034525}, {"id": 2015, "seek": 574496, "start": 5768.4800000000005, "end": 5771.76, "text": " a devil's advocate from the psychologist, you know, do you remember that, that photo,", "tokens": [51540, 257, 13297, 311, 14608, 490, 264, 29514, 11, 291, 458, 11, 360, 291, 1604, 300, 11, 300, 5052, 11, 51704], "temperature": 0.0, "avg_logprob": -0.0996317247144219, "compression_ratio": 1.891089108910891, "no_speech_prob": 0.005881445948034525}, {"id": 2016, "seek": 577176, "start": 5771.76, "end": 5776.64, "text": " Felician Connectionism critique paper, arguing productivity and systematicity? Productivity", "tokens": [50364, 13298, 9027, 11653, 313, 1434, 25673, 3035, 11, 19697, 15604, 293, 27249, 507, 30, 22005, 4253, 50608], "temperature": 0.0, "avg_logprob": -0.1440026513461409, "compression_ratio": 1.7173144876325088, "no_speech_prob": 0.05999558046460152}, {"id": 2017, "seek": 577176, "start": 5776.64, "end": 5780.0, "text": " is all about the infinite cardinality of language. I mean, presumably you would agree that language", "tokens": [50608, 307, 439, 466, 264, 13785, 2920, 259, 1860, 295, 2856, 13, 286, 914, 11, 26742, 291, 576, 3986, 300, 2856, 50776], "temperature": 0.0, "avg_logprob": -0.1440026513461409, "compression_ratio": 1.7173144876325088, "no_speech_prob": 0.05999558046460152}, {"id": 2018, "seek": 577176, "start": 5780.0, "end": 5784.16, "text": " has an infinite cardinality. No, well, again, another instance of the same problem. Productivity", "tokens": [50776, 575, 364, 13785, 2920, 259, 1860, 13, 883, 11, 731, 11, 797, 11, 1071, 5197, 295, 264, 912, 1154, 13, 22005, 4253, 50984], "temperature": 0.0, "avg_logprob": -0.1440026513461409, "compression_ratio": 1.7173144876325088, "no_speech_prob": 0.05999558046460152}, {"id": 2019, "seek": 577176, "start": 5784.16, "end": 5789.280000000001, "text": " is very important. But the point to just be a little precisely for a second is, is to be able to", "tokens": [50984, 307, 588, 1021, 13, 583, 264, 935, 281, 445, 312, 257, 707, 13402, 337, 257, 1150, 307, 11, 307, 281, 312, 1075, 281, 51240], "temperature": 0.0, "avg_logprob": -0.1440026513461409, "compression_ratio": 1.7173144876325088, "no_speech_prob": 0.05999558046460152}, {"id": 2020, "seek": 577176, "start": 5789.280000000001, "end": 5796.320000000001, "text": " generate a vast number of things beyond the ones that you started with. Vast, not infinite. In fact,", "tokens": [51240, 8460, 257, 8369, 1230, 295, 721, 4399, 264, 2306, 300, 291, 1409, 365, 13, 691, 525, 11, 406, 13785, 13, 682, 1186, 11, 51592], "temperature": 0.0, "avg_logprob": -0.1440026513461409, "compression_ratio": 1.7173144876325088, "no_speech_prob": 0.05999558046460152}, {"id": 2021, "seek": 579632, "start": 5796.32, "end": 5803.36, "text": " mathematically, infinity is not a number. Infinity is just a shorthand for something that is so", "tokens": [50364, 44003, 11, 13202, 307, 406, 257, 1230, 13, 34762, 307, 445, 257, 402, 2652, 474, 337, 746, 300, 307, 370, 50716], "temperature": 0.0, "avg_logprob": -0.10211382971869574, "compression_ratio": 1.75, "no_speech_prob": 0.0033731400035321712}, {"id": 2022, "seek": 579632, "start": 5803.36, "end": 5809.36, "text": " large that it doesn't matter how large it is. Okay. I mean, at the end of the day, I'm not a", "tokens": [50716, 2416, 300, 309, 1177, 380, 1871, 577, 2416, 309, 307, 13, 1033, 13, 286, 914, 11, 412, 264, 917, 295, 264, 786, 11, 286, 478, 406, 257, 51016], "temperature": 0.0, "avg_logprob": -0.10211382971869574, "compression_ratio": 1.75, "no_speech_prob": 0.0033731400035321712}, {"id": 2023, "seek": 579632, "start": 5809.36, "end": 5813.759999999999, "text": " mathematician, but surely mathematicians would push back on this because, you know, infinity is,", "tokens": [51016, 48281, 11, 457, 11468, 32811, 2567, 576, 2944, 646, 322, 341, 570, 11, 291, 458, 11, 13202, 307, 11, 51236], "temperature": 0.0, "avg_logprob": -0.10211382971869574, "compression_ratio": 1.75, "no_speech_prob": 0.0033731400035321712}, {"id": 2024, "seek": 579632, "start": 5813.759999999999, "end": 5820.799999999999, "text": " is a quantity in mathematics. No, I mean, again, people in every field, mathematicians, physicists,", "tokens": [51236, 307, 257, 11275, 294, 18666, 13, 883, 11, 286, 914, 11, 797, 11, 561, 294, 633, 2519, 11, 32811, 2567, 11, 48716, 11, 51588], "temperature": 0.0, "avg_logprob": -0.10211382971869574, "compression_ratio": 1.75, "no_speech_prob": 0.0033731400035321712}, {"id": 2025, "seek": 582080, "start": 5820.8, "end": 5826.8, "text": " computer scientists are all are often guilty of they, they, they, they have this notational shorthand", "tokens": [50364, 3820, 7708, 366, 439, 366, 2049, 12341, 295, 436, 11, 436, 11, 436, 11, 436, 362, 341, 406, 1478, 402, 2652, 474, 50664], "temperature": 0.0, "avg_logprob": -0.10411586905970718, "compression_ratio": 1.7864077669902914, "no_speech_prob": 0.039024464786052704}, {"id": 2026, "seek": 582080, "start": 5826.8, "end": 5832.08, "text": " or like, you know, this terminological shorthand that serves them well. But then they, and then", "tokens": [50664, 420, 411, 11, 291, 458, 11, 341, 10761, 4383, 402, 2652, 474, 300, 13451, 552, 731, 13, 583, 550, 436, 11, 293, 550, 50928], "temperature": 0.0, "avg_logprob": -0.10411586905970718, "compression_ratio": 1.7864077669902914, "no_speech_prob": 0.039024464786052704}, {"id": 2027, "seek": 582080, "start": 5832.08, "end": 5836.72, "text": " they use that and then the newer generations come along and the, and the public also, right,", "tokens": [50928, 436, 764, 300, 293, 550, 264, 17628, 10593, 808, 2051, 293, 264, 11, 293, 264, 1908, 611, 11, 558, 11, 51160], "temperature": 0.0, "avg_logprob": -0.10411586905970718, "compression_ratio": 1.7864077669902914, "no_speech_prob": 0.039024464786052704}, {"id": 2028, "seek": 582080, "start": 5836.72, "end": 5841.04, "text": " they don't even realize that what's being talked about is a little bit different.", "tokens": [51160, 436, 500, 380, 754, 4325, 300, 437, 311, 885, 2825, 466, 307, 257, 707, 857, 819, 13, 51376], "temperature": 0.0, "avg_logprob": -0.10411586905970718, "compression_ratio": 1.7864077669902914, "no_speech_prob": 0.039024464786052704}, {"id": 2029, "seek": 582080, "start": 5841.04, "end": 5845.92, "text": " Infinity is a perfect example. Any serious mathematician will tell you that infinity does", "tokens": [51376, 34762, 307, 257, 2176, 1365, 13, 2639, 3156, 48281, 486, 980, 291, 300, 13202, 775, 51620], "temperature": 0.0, "avg_logprob": -0.10411586905970718, "compression_ratio": 1.7864077669902914, "no_speech_prob": 0.039024464786052704}, {"id": 2030, "seek": 582080, "start": 5845.92, "end": 5850.08, "text": " not have the properties of a number. So for example, if I multiply infinity by 2, I still", "tokens": [51620, 406, 362, 264, 7221, 295, 257, 1230, 13, 407, 337, 1365, 11, 498, 286, 12972, 13202, 538, 568, 11, 286, 920, 51828], "temperature": 0.0, "avg_logprob": -0.10411586905970718, "compression_ratio": 1.7864077669902914, "no_speech_prob": 0.039024464786052704}, {"id": 2031, "seek": 585008, "start": 5850.08, "end": 5856.0, "text": " get infinity. There's no number that that happens to, right? So infinity is, is not a number, right?", "tokens": [50364, 483, 13202, 13, 821, 311, 572, 1230, 300, 300, 2314, 281, 11, 558, 30, 407, 13202, 307, 11, 307, 406, 257, 1230, 11, 558, 30, 50660], "temperature": 0.0, "avg_logprob": -0.10942402007473502, "compression_ratio": 1.8973509933774835, "no_speech_prob": 0.02401341125369072}, {"id": 2032, "seek": 585008, "start": 5856.0, "end": 5860.32, "text": " When I say infinity is not a number, mathematicians might quibble about the way I'm stating it,", "tokens": [50660, 1133, 286, 584, 13202, 307, 406, 257, 1230, 11, 32811, 2567, 1062, 421, 897, 638, 466, 264, 636, 286, 478, 26688, 309, 11, 50876], "temperature": 0.0, "avg_logprob": -0.10942402007473502, "compression_ratio": 1.8973509933774835, "no_speech_prob": 0.02401341125369072}, {"id": 2033, "seek": 585008, "start": 5860.32, "end": 5865.44, "text": " but this is a, this is a mathematical truth, right? Infinity truly isn't, I'm being colloquial,", "tokens": [50876, 457, 341, 307, 257, 11, 341, 307, 257, 18894, 3494, 11, 558, 30, 34762, 4908, 1943, 380, 11, 286, 478, 885, 1263, 29826, 831, 11, 51132], "temperature": 0.0, "avg_logprob": -0.10942402007473502, "compression_ratio": 1.8973509933774835, "no_speech_prob": 0.02401341125369072}, {"id": 2034, "seek": 585008, "start": 5865.44, "end": 5868.88, "text": " of course, when I say that it's a shorthand for something that is so large that it doesn't", "tokens": [51132, 295, 1164, 11, 562, 286, 584, 300, 309, 311, 257, 402, 2652, 474, 337, 746, 300, 307, 370, 2416, 300, 309, 1177, 380, 51304], "temperature": 0.0, "avg_logprob": -0.10942402007473502, "compression_ratio": 1.8973509933774835, "no_speech_prob": 0.02401341125369072}, {"id": 2035, "seek": 585008, "start": 5868.88, "end": 5873.68, "text": " matter how large it is. When you take limits, you know, in calculus in anything and the limit of", "tokens": [51304, 1871, 577, 2416, 309, 307, 13, 1133, 291, 747, 10406, 11, 291, 458, 11, 294, 33400, 294, 1340, 293, 264, 4948, 295, 51544], "temperature": 0.0, "avg_logprob": -0.10942402007473502, "compression_ratio": 1.8973509933774835, "no_speech_prob": 0.02401341125369072}, {"id": 2036, "seek": 585008, "start": 5873.68, "end": 5878.32, "text": " this blah, blah, as I go to infinity, this is exactly what I'm doing. I'm going to the point", "tokens": [51544, 341, 12288, 11, 12288, 11, 382, 286, 352, 281, 13202, 11, 341, 307, 2293, 437, 286, 478, 884, 13, 286, 478, 516, 281, 264, 935, 51776], "temperature": 0.0, "avg_logprob": -0.10942402007473502, "compression_ratio": 1.8973509933774835, "no_speech_prob": 0.02401341125369072}, {"id": 2037, "seek": 587832, "start": 5878.32, "end": 5882.16, "text": " where I'm saying like, at this point, it doesn't matter how large the number is, the result will", "tokens": [50364, 689, 286, 478, 1566, 411, 11, 412, 341, 935, 11, 309, 1177, 380, 1871, 577, 2416, 264, 1230, 307, 11, 264, 1874, 486, 50556], "temperature": 0.0, "avg_logprob": -0.07837500647893028, "compression_ratio": 1.6308724832214765, "no_speech_prob": 0.06925289332866669}, {"id": 2038, "seek": 587832, "start": 5882.16, "end": 5888.799999999999, "text": " be the same. And in this way, infinitely is an extraordinarily useful concept. So I'm not here", "tokens": [50556, 312, 264, 912, 13, 400, 294, 341, 636, 11, 36227, 307, 364, 34557, 4420, 3410, 13, 407, 286, 478, 406, 510, 50888], "temperature": 0.0, "avg_logprob": -0.07837500647893028, "compression_ratio": 1.6308724832214765, "no_speech_prob": 0.06925289332866669}, {"id": 2039, "seek": 587832, "start": 5888.799999999999, "end": 5892.639999999999, "text": " to rail against infinity. I'm just saying like, we really need to understand, I mean, like, let me", "tokens": [50888, 281, 8765, 1970, 13202, 13, 286, 478, 445, 1566, 411, 11, 321, 534, 643, 281, 1223, 11, 286, 914, 11, 411, 11, 718, 385, 51080], "temperature": 0.0, "avg_logprob": -0.07837500647893028, "compression_ratio": 1.6308724832214765, "no_speech_prob": 0.06925289332866669}, {"id": 2040, "seek": 587832, "start": 5892.639999999999, "end": 5898.96, "text": " give you a very banal example, right? From the point of view of, you know, what to have for lunch,", "tokens": [51080, 976, 291, 257, 588, 5643, 304, 1365, 11, 558, 30, 3358, 264, 935, 295, 1910, 295, 11, 291, 458, 11, 437, 281, 362, 337, 6349, 11, 51396], "temperature": 0.0, "avg_logprob": -0.07837500647893028, "compression_ratio": 1.6308724832214765, "no_speech_prob": 0.06925289332866669}, {"id": 2041, "seek": 587832, "start": 5898.96, "end": 5905.599999999999, "text": " right? Because some things cost more than others. Elon Musk is infinitely rich. He does not have", "tokens": [51396, 558, 30, 1436, 512, 721, 2063, 544, 813, 2357, 13, 28498, 26019, 307, 36227, 4593, 13, 634, 775, 406, 362, 51728], "temperature": 0.0, "avg_logprob": -0.07837500647893028, "compression_ratio": 1.6308724832214765, "no_speech_prob": 0.06925289332866669}, {"id": 2042, "seek": 590560, "start": 5905.6, "end": 5910.4800000000005, "text": " infinite money. But it makes no difference whatsoever whether he has whatever 100 billion", "tokens": [50364, 13785, 1460, 13, 583, 309, 1669, 572, 2649, 17076, 1968, 415, 575, 2035, 2319, 5218, 50608], "temperature": 0.0, "avg_logprob": -0.10642496744791667, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.1840067207813263}, {"id": 2043, "seek": 590560, "start": 5910.4800000000005, "end": 5916.08, "text": " or 200 billion to what he's going to have for lunch. You know, like a street person who has", "tokens": [50608, 420, 2331, 5218, 281, 437, 415, 311, 516, 281, 362, 337, 6349, 13, 509, 458, 11, 411, 257, 4838, 954, 567, 575, 50888], "temperature": 0.0, "avg_logprob": -0.10642496744791667, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.1840067207813263}, {"id": 2044, "seek": 590560, "start": 5916.08, "end": 5921.360000000001, "text": " $5 to them, like their fortune is not infinite, because it very much matters what lunch costs,", "tokens": [50888, 1848, 20, 281, 552, 11, 411, 641, 16531, 307, 406, 13785, 11, 570, 309, 588, 709, 7001, 437, 6349, 5497, 11, 51152], "temperature": 0.0, "avg_logprob": -0.10642496744791667, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.1840067207813263}, {"id": 2045, "seek": 590560, "start": 5921.360000000001, "end": 5925.68, "text": " right? So this is the real sense of infinity, which we can and should use, but we shouldn't", "tokens": [51152, 558, 30, 407, 341, 307, 264, 957, 2020, 295, 13202, 11, 597, 321, 393, 293, 820, 764, 11, 457, 321, 4659, 380, 51368], "temperature": 0.0, "avg_logprob": -0.10642496744791667, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.1840067207813263}, {"id": 2046, "seek": 590560, "start": 5925.68, "end": 5931.200000000001, "text": " confuse it with like, oh, but then your, you know, like your formalism is incomplete because it", "tokens": [51368, 28584, 309, 365, 411, 11, 1954, 11, 457, 550, 428, 11, 291, 458, 11, 411, 428, 9860, 1434, 307, 31709, 570, 309, 51644], "temperature": 0.0, "avg_logprob": -0.10642496744791667, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.1840067207813263}, {"id": 2047, "seek": 593120, "start": 5931.28, "end": 5935.76, "text": " doesn't encompass infinity. Yeah, it doesn't need to infinity doesn't exist.", "tokens": [50368, 1177, 380, 28268, 13202, 13, 865, 11, 309, 1177, 380, 643, 281, 13202, 1177, 380, 2514, 13, 50592], "temperature": 0.0, "avg_logprob": -0.1271328742687519, "compression_ratio": 1.8770491803278688, "no_speech_prob": 0.0076749795116484165}, {"id": 2048, "seek": 593120, "start": 5935.76, "end": 5939.44, "text": " Okay, okay. Well, let's come at it from the other from the composition, you know,", "tokens": [50592, 1033, 11, 1392, 13, 1042, 11, 718, 311, 808, 412, 309, 490, 264, 661, 490, 264, 12686, 11, 291, 458, 11, 50776], "temperature": 0.0, "avg_logprob": -0.1271328742687519, "compression_ratio": 1.8770491803278688, "no_speech_prob": 0.0076749795116484165}, {"id": 2049, "seek": 593120, "start": 5939.44, "end": 5946.0, "text": " compositionality and systematicity. So that's all about being able to do, you know, like their main", "tokens": [50776, 12686, 1860, 293, 27249, 507, 13, 407, 300, 311, 439, 466, 885, 1075, 281, 360, 11, 291, 458, 11, 411, 641, 2135, 51104], "temperature": 0.0, "avg_logprob": -0.1271328742687519, "compression_ratio": 1.8770491803278688, "no_speech_prob": 0.0076749795116484165}, {"id": 2050, "seek": 593120, "start": 5946.0, "end": 5951.5199999999995, "text": " argument was when you have a symbolic representation, you can kind of reuse the previous representations", "tokens": [51104, 6770, 390, 562, 291, 362, 257, 25755, 10290, 11, 291, 393, 733, 295, 26225, 264, 3894, 33358, 51380], "temperature": 0.0, "avg_logprob": -0.1271328742687519, "compression_ratio": 1.8770491803278688, "no_speech_prob": 0.0076749795116484165}, {"id": 2051, "seek": 593120, "start": 5951.5199999999995, "end": 5957.04, "text": " downstream composition, compositionally. And when you take a discrete symbolic representation,", "tokens": [51380, 30621, 12686, 11, 12686, 379, 13, 400, 562, 291, 747, 257, 27706, 25755, 10290, 11, 51656], "temperature": 0.0, "avg_logprob": -0.1271328742687519, "compression_ratio": 1.8770491803278688, "no_speech_prob": 0.0076749795116484165}, {"id": 2052, "seek": 595704, "start": 5957.04, "end": 5961.5199999999995, "text": " and you kind of encode it in the envelope of a vector space, you have a real problem doing that", "tokens": [50364, 293, 291, 733, 295, 2058, 1429, 309, 294, 264, 19989, 295, 257, 8062, 1901, 11, 291, 362, 257, 957, 1154, 884, 300, 50588], "temperature": 0.0, "avg_logprob": -0.10250764233725411, "compression_ratio": 1.8045977011494252, "no_speech_prob": 0.03672582656145096}, {"id": 2053, "seek": 595704, "start": 5961.5199999999995, "end": 5966.32, "text": " because it's now like, it's irreversible that transformation, right? You can't go back to the", "tokens": [50588, 570, 309, 311, 586, 411, 11, 309, 311, 16014, 840, 964, 300, 9887, 11, 558, 30, 509, 393, 380, 352, 646, 281, 264, 50828], "temperature": 0.0, "avg_logprob": -0.10250764233725411, "compression_ratio": 1.8045977011494252, "no_speech_prob": 0.03672582656145096}, {"id": 2054, "seek": 595704, "start": 5966.96, "end": 5972.56, "text": " original variables. Well, it is reversible if you realize that all those real numbers are actually", "tokens": [50860, 3380, 9102, 13, 1042, 11, 309, 307, 44788, 498, 291, 4325, 300, 439, 729, 957, 3547, 366, 767, 51140], "temperature": 0.0, "avg_logprob": -0.10250764233725411, "compression_ratio": 1.8045977011494252, "no_speech_prob": 0.03672582656145096}, {"id": 2055, "seek": 595704, "start": 5972.56, "end": 5978.8, "text": " finite. Right? So notice that real number, there's nothing less real than a real number,", "tokens": [51140, 19362, 13, 1779, 30, 407, 3449, 300, 957, 1230, 11, 456, 311, 1825, 1570, 957, 813, 257, 957, 1230, 11, 51452], "temperature": 0.0, "avg_logprob": -0.10250764233725411, "compression_ratio": 1.8045977011494252, "no_speech_prob": 0.03672582656145096}, {"id": 2056, "seek": 595704, "start": 5978.8, "end": 5983.28, "text": " real numbers are imaginary, right? Real numbers are numbers with infinite precision, which is", "tokens": [51452, 957, 3547, 366, 26164, 11, 558, 30, 8467, 3547, 366, 3547, 365, 13785, 18356, 11, 597, 307, 51676], "temperature": 0.0, "avg_logprob": -0.10250764233725411, "compression_ratio": 1.8045977011494252, "no_speech_prob": 0.03672582656145096}, {"id": 2057, "seek": 598328, "start": 5983.28, "end": 5988.08, "text": " a monstrosity. And many people have said this, including mathematicians and physicists, right?", "tokens": [50364, 257, 1108, 372, 2635, 507, 13, 400, 867, 561, 362, 848, 341, 11, 3009, 32811, 2567, 293, 48716, 11, 558, 30, 50604], "temperature": 0.0, "avg_logprob": -0.10759788647032621, "compression_ratio": 1.6843971631205674, "no_speech_prob": 0.012231556698679924}, {"id": 2058, "seek": 598328, "start": 5988.08, "end": 5992.719999999999, "text": " The notion of an infinite, of a number with an infinite number of digits is just monstrous.", "tokens": [50604, 440, 10710, 295, 364, 13785, 11, 295, 257, 1230, 365, 364, 13785, 1230, 295, 27011, 307, 445, 47137, 563, 13, 50836], "temperature": 0.0, "avg_logprob": -0.10759788647032621, "compression_ratio": 1.6843971631205674, "no_speech_prob": 0.012231556698679924}, {"id": 2059, "seek": 598328, "start": 5992.719999999999, "end": 5998.719999999999, "text": " And again, in particular on a computer, even if you use, you know, you know, like numbers with", "tokens": [50836, 400, 797, 11, 294, 1729, 322, 257, 3820, 11, 754, 498, 291, 764, 11, 291, 458, 11, 291, 458, 11, 411, 3547, 365, 51136], "temperature": 0.0, "avg_logprob": -0.10759788647032621, "compression_ratio": 1.6843971631205674, "no_speech_prob": 0.012231556698679924}, {"id": 2060, "seek": 598328, "start": 5998.719999999999, "end": 6004.5599999999995, "text": " unlimited floating point precision, right? It's limited by the size of your memory. So this transfer", "tokens": [51136, 21950, 12607, 935, 18356, 11, 558, 30, 467, 311, 5567, 538, 264, 2744, 295, 428, 4675, 13, 407, 341, 5003, 51428], "temperature": 0.0, "avg_logprob": -0.10759788647032621, "compression_ratio": 1.6843971631205674, "no_speech_prob": 0.012231556698679924}, {"id": 2061, "seek": 598328, "start": 6004.5599999999995, "end": 6008.24, "text": " from which is actually very important that again, that's what tensor logic largely is about,", "tokens": [51428, 490, 597, 307, 767, 588, 1021, 300, 797, 11, 300, 311, 437, 40863, 9952, 11611, 307, 466, 11, 51612], "temperature": 0.0, "avg_logprob": -0.10759788647032621, "compression_ratio": 1.6843971631205674, "no_speech_prob": 0.012231556698679924}, {"id": 2062, "seek": 600824, "start": 6008.32, "end": 6013.5199999999995, "text": " from purely symbolic structures to embeddings in a vector space, right? That vector space", "tokens": [50368, 490, 17491, 25755, 9227, 281, 12240, 29432, 294, 257, 8062, 1901, 11, 558, 30, 663, 8062, 1901, 50628], "temperature": 0.0, "avg_logprob": -0.1000987109758996, "compression_ratio": 1.7577464788732395, "no_speech_prob": 0.0465710386633873}, {"id": 2063, "seek": 600824, "start": 6013.5199999999995, "end": 6017.2, "text": " is still finite. So there's actually nothing irreversible about what happened there.", "tokens": [50628, 307, 920, 19362, 13, 407, 456, 311, 767, 1825, 16014, 840, 964, 466, 437, 2011, 456, 13, 50812], "temperature": 0.0, "avg_logprob": -0.1000987109758996, "compression_ratio": 1.7577464788732395, "no_speech_prob": 0.0465710386633873}, {"id": 2064, "seek": 600824, "start": 6017.2, "end": 6021.92, "text": " Interesting. Okay. So how can people, you know, find out more information about this? And can you", "tokens": [50812, 14711, 13, 1033, 13, 407, 577, 393, 561, 11, 291, 458, 11, 915, 484, 544, 1589, 466, 341, 30, 400, 393, 291, 51048], "temperature": 0.0, "avg_logprob": -0.1000987109758996, "compression_ratio": 1.7577464788732395, "no_speech_prob": 0.0465710386633873}, {"id": 2065, "seek": 600824, "start": 6021.92, "end": 6026.16, "text": " just sketch out, you know, just, just to bring it home to people where they could actually use it", "tokens": [51048, 445, 12325, 484, 11, 291, 458, 11, 445, 11, 445, 281, 1565, 309, 1280, 281, 561, 689, 436, 727, 767, 764, 309, 51260], "temperature": 0.0, "avg_logprob": -0.1000987109758996, "compression_ratio": 1.7577464788732395, "no_speech_prob": 0.0465710386633873}, {"id": 2066, "seek": 600824, "start": 6026.16, "end": 6028.88, "text": " and how it would be, you know, better than what they can currently do?", "tokens": [51260, 293, 577, 309, 576, 312, 11, 291, 458, 11, 1101, 813, 437, 436, 393, 4362, 360, 30, 51396], "temperature": 0.0, "avg_logprob": -0.1000987109758996, "compression_ratio": 1.7577464788732395, "no_speech_prob": 0.0465710386633873}, {"id": 2067, "seek": 600824, "start": 6028.88, "end": 6032.4, "text": " Right. The answer to the first question, unfortunately, is this is not published yet,", "tokens": [51396, 1779, 13, 440, 1867, 281, 264, 700, 1168, 11, 7015, 11, 307, 341, 307, 406, 6572, 1939, 11, 51572], "temperature": 0.0, "avg_logprob": -0.1000987109758996, "compression_ratio": 1.7577464788732395, "no_speech_prob": 0.0465710386633873}, {"id": 2068, "seek": 600824, "start": 6032.4, "end": 6037.92, "text": " but hopefully it will be soon. So for the moment, there is no very good place to point people to", "tokens": [51572, 457, 4696, 309, 486, 312, 2321, 13, 407, 337, 264, 1623, 11, 456, 307, 572, 588, 665, 1081, 281, 935, 561, 281, 51848], "temperature": 0.0, "avg_logprob": -0.1000987109758996, "compression_ratio": 1.7577464788732395, "no_speech_prob": 0.0465710386633873}, {"id": 2069, "seek": 603792, "start": 6038.0, "end": 6045.84, "text": " unfortunately, but that hopefully will be fixed soon. The question of where to apply it is,", "tokens": [50368, 7015, 11, 457, 300, 4696, 486, 312, 6806, 2321, 13, 440, 1168, 295, 689, 281, 3079, 309, 307, 11, 50760], "temperature": 0.0, "avg_logprob": -0.11232457244605348, "compression_ratio": 1.744360902255639, "no_speech_prob": 0.0024308515712618828}, {"id": 2070, "seek": 603792, "start": 6046.4800000000005, "end": 6051.68, "text": " our goal for this is that this should become the language or hope, I should say our hope,", "tokens": [50792, 527, 3387, 337, 341, 307, 300, 341, 820, 1813, 264, 2856, 420, 1454, 11, 286, 820, 584, 527, 1454, 11, 51052], "temperature": 0.0, "avg_logprob": -0.11232457244605348, "compression_ratio": 1.744360902255639, "no_speech_prob": 0.0024308515712618828}, {"id": 2071, "seek": 603792, "start": 6051.68, "end": 6056.56, "text": " is that this will become the language we're doing just about anything in AI. So for example,", "tokens": [51052, 307, 300, 341, 486, 1813, 264, 2856, 321, 434, 884, 445, 466, 1340, 294, 7318, 13, 407, 337, 1365, 11, 51296], "temperature": 0.0, "avg_logprob": -0.11232457244605348, "compression_ratio": 1.744360902255639, "no_speech_prob": 0.0024308515712618828}, {"id": 2072, "seek": 603792, "start": 6056.56, "end": 6061.12, "text": " if what you want to do is actually nothing symbolic, but you just want to build a convent,", "tokens": [51296, 498, 437, 291, 528, 281, 360, 307, 767, 1825, 25755, 11, 457, 291, 445, 528, 281, 1322, 257, 416, 2475, 11, 51524], "temperature": 0.0, "avg_logprob": -0.11232457244605348, "compression_ratio": 1.744360902255639, "no_speech_prob": 0.0024308515712618828}, {"id": 2073, "seek": 603792, "start": 6062.0, "end": 6067.76, "text": " you can express a convent incredibly elegantly in tensor logic. Like if you think of, for example,", "tokens": [51568, 291, 393, 5109, 257, 416, 2475, 6252, 14459, 3627, 294, 40863, 9952, 13, 1743, 498, 291, 519, 295, 11, 337, 1365, 11, 51856], "temperature": 0.0, "avg_logprob": -0.11232457244605348, "compression_ratio": 1.744360902255639, "no_speech_prob": 0.0024308515712618828}, {"id": 2074, "seek": 606776, "start": 6067.76, "end": 6073.92, "text": " tensor floor or PyTorch versus NumPy, right, they allow that thing to be said much more compactly,", "tokens": [50364, 40863, 4123, 420, 9953, 51, 284, 339, 5717, 22592, 47, 88, 11, 558, 11, 436, 2089, 300, 551, 281, 312, 848, 709, 544, 14679, 356, 11, 50672], "temperature": 0.0, "avg_logprob": -0.13443245254196487, "compression_ratio": 1.7638036809815951, "no_speech_prob": 0.002710494212806225}, {"id": 2075, "seek": 606776, "start": 6073.92, "end": 6078.88, "text": " compared to tensor logic, they are as bad as NumPy is compared to them. Right. Same thing on the", "tokens": [50672, 5347, 281, 40863, 9952, 11, 436, 366, 382, 1578, 382, 22592, 47, 88, 307, 5347, 281, 552, 13, 1779, 13, 10635, 551, 322, 264, 50920], "temperature": 0.0, "avg_logprob": -0.13443245254196487, "compression_ratio": 1.7638036809815951, "no_speech_prob": 0.002710494212806225}, {"id": 2076, "seek": 606776, "start": 6078.88, "end": 6082.88, "text": " symbolic side. But of course, the real action comes in all the problems where you have both", "tokens": [50920, 25755, 1252, 13, 583, 295, 1164, 11, 264, 957, 3069, 1487, 294, 439, 264, 2740, 689, 291, 362, 1293, 51120], "temperature": 0.0, "avg_logprob": -0.13443245254196487, "compression_ratio": 1.7638036809815951, "no_speech_prob": 0.002710494212806225}, {"id": 2077, "seek": 606776, "start": 6082.88, "end": 6088.64, "text": " components, the problem with all those problems, which ultimately is every problem in AI, right.", "tokens": [51120, 6677, 11, 264, 1154, 365, 439, 729, 2740, 11, 597, 6284, 307, 633, 1154, 294, 7318, 11, 558, 13, 51408], "temperature": 0.0, "avg_logprob": -0.13443245254196487, "compression_ratio": 1.7638036809815951, "no_speech_prob": 0.002710494212806225}, {"id": 2078, "seek": 606776, "start": 6088.64, "end": 6092.0, "text": " You're always like, what happens today that is very frustrating. And that's what we're trying to", "tokens": [51408, 509, 434, 1009, 411, 11, 437, 2314, 965, 300, 307, 588, 16522, 13, 400, 300, 311, 437, 321, 434, 1382, 281, 51576], "temperature": 0.0, "avg_logprob": -0.13443245254196487, "compression_ratio": 1.7638036809815951, "no_speech_prob": 0.002710494212806225}, {"id": 2079, "seek": 606776, "start": 6092.0, "end": 6096.4800000000005, "text": " overcome is like, you start from one of these sides these days, mainly the connectionist one,", "tokens": [51576, 10473, 307, 411, 11, 291, 722, 490, 472, 295, 613, 4881, 613, 1708, 11, 8704, 264, 4984, 468, 472, 11, 51800], "temperature": 0.0, "avg_logprob": -0.13443245254196487, "compression_ratio": 1.7638036809815951, "no_speech_prob": 0.002710494212806225}, {"id": 2080, "seek": 609648, "start": 6096.5599999999995, "end": 6100.639999999999, "text": " which you have a good mastery of. And then the other side, for example, the symbolic one,", "tokens": [50368, 597, 291, 362, 257, 665, 37951, 295, 13, 400, 550, 264, 661, 1252, 11, 337, 1365, 11, 264, 25755, 472, 11, 50572], "temperature": 0.0, "avg_logprob": -0.08725777205887374, "compression_ratio": 1.7868852459016393, "no_speech_prob": 0.004128368105739355}, {"id": 2081, "seek": 609648, "start": 6100.639999999999, "end": 6105.5199999999995, "text": " the knowledge representation, the reasoning, the composability, you just hack. Yeah. And your", "tokens": [50572, 264, 3601, 10290, 11, 264, 21577, 11, 264, 10199, 2310, 11, 291, 445, 10339, 13, 865, 13, 400, 428, 50816], "temperature": 0.0, "avg_logprob": -0.08725777205887374, "compression_ratio": 1.7868852459016393, "no_speech_prob": 0.004128368105739355}, {"id": 2082, "seek": 609648, "start": 6105.5199999999995, "end": 6109.759999999999, "text": " hack solution is terrible. You're like, you're inventing the wheel, you're making it square,", "tokens": [50816, 10339, 3827, 307, 6237, 13, 509, 434, 411, 11, 291, 434, 7962, 278, 264, 5589, 11, 291, 434, 1455, 309, 3732, 11, 51028], "temperature": 0.0, "avg_logprob": -0.08725777205887374, "compression_ratio": 1.7868852459016393, "no_speech_prob": 0.004128368105739355}, {"id": 2083, "seek": 609648, "start": 6109.759999999999, "end": 6114.24, "text": " you're trying to make it turn, but it's square, right. It's just, you know, it's a disaster.", "tokens": [51028, 291, 434, 1382, 281, 652, 309, 1261, 11, 457, 309, 311, 3732, 11, 558, 13, 467, 311, 445, 11, 291, 458, 11, 309, 311, 257, 11293, 13, 51252], "temperature": 0.0, "avg_logprob": -0.08725777205887374, "compression_ratio": 1.7868852459016393, "no_speech_prob": 0.004128368105739355}, {"id": 2084, "seek": 609648, "start": 6114.24, "end": 6118.5599999999995, "text": " And with tensor logic, you can actually have a very well founded, very well understood", "tokens": [51252, 400, 365, 40863, 9952, 11, 291, 393, 767, 362, 257, 588, 731, 13234, 11, 588, 731, 7320, 51468], "temperature": 0.0, "avg_logprob": -0.08725777205887374, "compression_ratio": 1.7868852459016393, "no_speech_prob": 0.004128368105739355}, {"id": 2085, "seek": 609648, "start": 6119.2, "end": 6123.36, "text": " basis on either side. So now you don't have to hack either side. Now there's, of course,", "tokens": [51500, 5143, 322, 2139, 1252, 13, 407, 586, 291, 500, 380, 362, 281, 10339, 2139, 1252, 13, 823, 456, 311, 11, 295, 1164, 11, 51708], "temperature": 0.0, "avg_logprob": -0.08725777205887374, "compression_ratio": 1.7868852459016393, "no_speech_prob": 0.004128368105739355}, {"id": 2086, "seek": 612336, "start": 6123.36, "end": 6126.5599999999995, "text": " still things that you're going to have to hack at the end of the day, because at the end of the day,", "tokens": [50364, 920, 721, 300, 291, 434, 516, 281, 362, 281, 10339, 412, 264, 917, 295, 264, 786, 11, 570, 412, 264, 917, 295, 264, 786, 11, 50524], "temperature": 0.0, "avg_logprob": -0.11695158971499091, "compression_ratio": 1.842809364548495, "no_speech_prob": 0.007338293362408876}, {"id": 2087, "seek": 612336, "start": 6126.5599999999995, "end": 6129.839999999999, "text": " you know, AI is intractable and things are heuristic. But this, you know, is,", "tokens": [50524, 291, 458, 11, 7318, 307, 560, 1897, 712, 293, 721, 366, 415, 374, 3142, 13, 583, 341, 11, 291, 458, 11, 307, 11, 50688], "temperature": 0.0, "avg_logprob": -0.11695158971499091, "compression_ratio": 1.842809364548495, "no_speech_prob": 0.007338293362408876}, {"id": 2088, "seek": 612336, "start": 6130.96, "end": 6134.32, "text": " you know, you know, this notion of a tradeoff that is very important in engineering. Like,", "tokens": [50744, 291, 458, 11, 291, 458, 11, 341, 10710, 295, 257, 4923, 4506, 300, 307, 588, 1021, 294, 7043, 13, 1743, 11, 50912], "temperature": 0.0, "avg_logprob": -0.11695158971499091, "compression_ratio": 1.842809364548495, "no_speech_prob": 0.007338293362408876}, {"id": 2089, "seek": 612336, "start": 6134.32, "end": 6139.759999999999, "text": " people have been exploring different points on this tradeoff curve. The point of tensor logic is", "tokens": [50912, 561, 362, 668, 12736, 819, 2793, 322, 341, 4923, 4506, 7605, 13, 440, 935, 295, 40863, 9952, 307, 51184], "temperature": 0.0, "avg_logprob": -0.11695158971499091, "compression_ratio": 1.842809364548495, "no_speech_prob": 0.007338293362408876}, {"id": 2090, "seek": 612336, "start": 6139.759999999999, "end": 6147.12, "text": " that whatever your application is, we're moving you to a better tradeoff curve. It's still a", "tokens": [51184, 300, 2035, 428, 3861, 307, 11, 321, 434, 2684, 291, 281, 257, 1101, 4923, 4506, 7605, 13, 467, 311, 920, 257, 51552], "temperature": 0.0, "avg_logprob": -0.11695158971499091, "compression_ratio": 1.842809364548495, "no_speech_prob": 0.007338293362408876}, {"id": 2091, "seek": 612336, "start": 6147.12, "end": 6152.48, "text": " tradeoff curve, but it dominates the old one. For any given X, you have a better Y and vice", "tokens": [51552, 4923, 4506, 7605, 11, 457, 309, 8859, 1024, 264, 1331, 472, 13, 1171, 604, 2212, 1783, 11, 291, 362, 257, 1101, 398, 293, 11964, 51820], "temperature": 0.0, "avg_logprob": -0.11695158971499091, "compression_ratio": 1.842809364548495, "no_speech_prob": 0.007338293362408876}, {"id": 2092, "seek": 615248, "start": 6152.48, "end": 6157.36, "text": " versa. Okay. And just help me understand, because we'll move over to, you know, the discrete program", "tokens": [50364, 25650, 13, 1033, 13, 400, 445, 854, 385, 1223, 11, 570, 321, 603, 1286, 670, 281, 11, 291, 458, 11, 264, 27706, 1461, 50608], "temperature": 0.0, "avg_logprob": -0.13156156611621828, "compression_ratio": 1.7570093457943925, "no_speech_prob": 0.004173506051301956}, {"id": 2093, "seek": 615248, "start": 6157.36, "end": 6161.599999999999, "text": " search and some of Josh Tannenbaum's work in a moment. But there are two schools of thought,", "tokens": [50608, 3164, 293, 512, 295, 9785, 314, 44792, 46641, 311, 589, 294, 257, 1623, 13, 583, 456, 366, 732, 4656, 295, 1194, 11, 50820], "temperature": 0.0, "avg_logprob": -0.13156156611621828, "compression_ratio": 1.7570093457943925, "no_speech_prob": 0.004173506051301956}, {"id": 2094, "seek": 615248, "start": 6161.599999999999, "end": 6165.2, "text": " right? There's discrete first and there's continuous first, you're on the continuous", "tokens": [50820, 558, 30, 821, 311, 27706, 700, 293, 456, 311, 10957, 700, 11, 291, 434, 322, 264, 10957, 51000], "temperature": 0.0, "avg_logprob": -0.13156156611621828, "compression_ratio": 1.7570093457943925, "no_speech_prob": 0.004173506051301956}, {"id": 2095, "seek": 615248, "start": 6165.2, "end": 6170.16, "text": " substrate. But usually the reason for the continuous substrate is stochastic gradient descent,", "tokens": [51000, 27585, 13, 583, 2673, 264, 1778, 337, 264, 10957, 27585, 307, 342, 8997, 2750, 16235, 23475, 11, 51248], "temperature": 0.0, "avg_logprob": -0.13156156611621828, "compression_ratio": 1.7570093457943925, "no_speech_prob": 0.004173506051301956}, {"id": 2096, "seek": 615248, "start": 6170.16, "end": 6174.48, "text": " learnability, et cetera, et cetera. And like, help me understand. So are you saying we start", "tokens": [51248, 1466, 2310, 11, 1030, 11458, 11, 1030, 11458, 13, 400, 411, 11, 854, 385, 1223, 13, 407, 366, 291, 1566, 321, 722, 51464], "temperature": 0.0, "avg_logprob": -0.13156156611621828, "compression_ratio": 1.7570093457943925, "no_speech_prob": 0.004173506051301956}, {"id": 2097, "seek": 615248, "start": 6174.48, "end": 6178.48, "text": " with symbolic representation and then we encode it into the envelope? So where does learning come", "tokens": [51464, 365, 25755, 10290, 293, 550, 321, 2058, 1429, 309, 666, 264, 19989, 30, 407, 689, 775, 2539, 808, 51664], "temperature": 0.0, "avg_logprob": -0.13156156611621828, "compression_ratio": 1.7570093457943925, "no_speech_prob": 0.004173506051301956}, {"id": 2098, "seek": 617848, "start": 6178.48, "end": 6183.2, "text": " into it? No, very good. So in tensor logic, you can do broadly speaking, two kinds of learning.", "tokens": [50364, 666, 309, 30, 883, 11, 588, 665, 13, 407, 294, 40863, 9952, 11, 291, 393, 360, 19511, 4124, 11, 732, 3685, 295, 2539, 13, 50600], "temperature": 0.0, "avg_logprob": -0.1177048310637474, "compression_ratio": 1.8603896103896105, "no_speech_prob": 0.02713986486196518}, {"id": 2099, "seek": 617848, "start": 6183.2, "end": 6187.759999999999, "text": " You can learn the structure of these tensor equations, as we call them, using inductive logic", "tokens": [50600, 509, 393, 1466, 264, 3877, 295, 613, 40863, 11787, 11, 382, 321, 818, 552, 11, 1228, 31612, 488, 9952, 50828], "temperature": 0.0, "avg_logprob": -0.1177048310637474, "compression_ratio": 1.8603896103896105, "no_speech_prob": 0.02713986486196518}, {"id": 2100, "seek": 617848, "start": 6187.759999999999, "end": 6192.08, "text": " programming techniques. Again, that whole technology is there. And then once you have that, you can", "tokens": [50828, 9410, 7512, 13, 3764, 11, 300, 1379, 2899, 307, 456, 13, 400, 550, 1564, 291, 362, 300, 11, 291, 393, 51044], "temperature": 0.0, "avg_logprob": -0.1177048310637474, "compression_ratio": 1.8603896103896105, "no_speech_prob": 0.02713986486196518}, {"id": 2101, "seek": 617848, "start": 6192.08, "end": 6197.04, "text": " learn the numbers by the back prop in particular ways called back propagation through structure,", "tokens": [51044, 1466, 264, 3547, 538, 264, 646, 2365, 294, 1729, 2098, 1219, 646, 38377, 807, 3877, 11, 51292], "temperature": 0.0, "avg_logprob": -0.1177048310637474, "compression_ratio": 1.8603896103896105, "no_speech_prob": 0.02713986486196518}, {"id": 2102, "seek": 617848, "start": 6197.04, "end": 6201.12, "text": " because the structure can vary from example to example, but we know what the type parameters", "tokens": [51292, 570, 264, 3877, 393, 10559, 490, 1365, 281, 1365, 11, 457, 321, 458, 437, 264, 2010, 9834, 51496], "temperature": 0.0, "avg_logprob": -0.1177048310637474, "compression_ratio": 1.8603896103896105, "no_speech_prob": 0.02713986486196518}, {"id": 2103, "seek": 617848, "start": 6201.12, "end": 6205.679999999999, "text": " are. So all of the machinery of inductive logic programming and all the machinery of gradient", "tokens": [51496, 366, 13, 407, 439, 295, 264, 27302, 295, 31612, 488, 9952, 9410, 293, 439, 264, 27302, 295, 16235, 51724], "temperature": 0.0, "avg_logprob": -0.1177048310637474, "compression_ratio": 1.8603896103896105, "no_speech_prob": 0.02713986486196518}, {"id": 2104, "seek": 620568, "start": 6205.76, "end": 6210.400000000001, "text": " descent and deep learning or not, they're both there available to be used as you traditionally", "tokens": [50368, 23475, 293, 2452, 2539, 420, 406, 11, 436, 434, 1293, 456, 2435, 281, 312, 1143, 382, 291, 19067, 50600], "temperature": 0.0, "avg_logprob": -0.1309258778889974, "compression_ratio": 1.7038123167155426, "no_speech_prob": 0.01877719722688198}, {"id": 2105, "seek": 620568, "start": 6210.400000000001, "end": 6215.280000000001, "text": " have. Okay, what if I made the argument, though, that it's almost like the inductive logic, you", "tokens": [50600, 362, 13, 1033, 11, 437, 498, 286, 1027, 264, 6770, 11, 1673, 11, 300, 309, 311, 1920, 411, 264, 31612, 488, 9952, 11, 291, 50844], "temperature": 0.0, "avg_logprob": -0.1309258778889974, "compression_ratio": 1.7038123167155426, "no_speech_prob": 0.01877719722688198}, {"id": 2106, "seek": 620568, "start": 6215.280000000001, "end": 6219.4400000000005, "text": " know, like the program search, that's the hard bit. So if you've already got the program, why do I", "tokens": [50844, 458, 11, 411, 264, 1461, 3164, 11, 300, 311, 264, 1152, 857, 13, 407, 498, 291, 600, 1217, 658, 264, 1461, 11, 983, 360, 286, 51052], "temperature": 0.0, "avg_logprob": -0.1309258778889974, "compression_ratio": 1.7038123167155426, "no_speech_prob": 0.01877719722688198}, {"id": 2107, "seek": 620568, "start": 6219.4400000000005, "end": 6222.8, "text": " then need to put it into a vector space? No, actually, these are also at the end of the day,", "tokens": [51052, 550, 643, 281, 829, 309, 666, 257, 8062, 1901, 30, 883, 11, 767, 11, 613, 366, 611, 412, 264, 917, 295, 264, 786, 11, 51220], "temperature": 0.0, "avg_logprob": -0.1309258778889974, "compression_ratio": 1.7038123167155426, "no_speech_prob": 0.01877719722688198}, {"id": 2108, "seek": 620568, "start": 6222.8, "end": 6226.88, "text": " in machine learning, we're always trying to learn a program of some kind, right? The question is like,", "tokens": [51220, 294, 3479, 2539, 11, 321, 434, 1009, 1382, 281, 1466, 257, 1461, 295, 512, 733, 11, 558, 30, 440, 1168, 307, 411, 11, 51424], "temperature": 0.0, "avg_logprob": -0.1309258778889974, "compression_ratio": 1.7038123167155426, "no_speech_prob": 0.01877719722688198}, {"id": 2109, "seek": 620568, "start": 6226.88, "end": 6231.6, "text": " what is the easiest way to do that? And precisely the problem with ILPS with symbolic logic is,", "tokens": [51424, 437, 307, 264, 12889, 636, 281, 360, 300, 30, 400, 13402, 264, 1154, 365, 286, 43, 6273, 365, 25755, 9952, 307, 11, 51660], "temperature": 0.0, "avg_logprob": -0.1309258778889974, "compression_ratio": 1.7038123167155426, "no_speech_prob": 0.01877719722688198}, {"id": 2110, "seek": 623160, "start": 6231.6, "end": 6235.84, "text": " that's really a couple of problems. One is that if all that you do, you learn programs that are", "tokens": [50364, 300, 311, 534, 257, 1916, 295, 2740, 13, 1485, 307, 300, 498, 439, 300, 291, 360, 11, 291, 1466, 4268, 300, 366, 50576], "temperature": 0.0, "avg_logprob": -0.0974464185776249, "compression_ratio": 1.686206896551724, "no_speech_prob": 0.024395065382122993}, {"id": 2111, "seek": 623160, "start": 6235.84, "end": 6241.4400000000005, "text": " too brittle, and we don't want them to be brittle, right? And the other one is that each type of", "tokens": [50576, 886, 49325, 11, 293, 321, 500, 380, 528, 552, 281, 312, 49325, 11, 558, 30, 400, 264, 661, 472, 307, 300, 1184, 2010, 295, 50856], "temperature": 0.0, "avg_logprob": -0.0974464185776249, "compression_ratio": 1.686206896551724, "no_speech_prob": 0.024395065382122993}, {"id": 2112, "seek": 623160, "start": 6241.4400000000005, "end": 6248.08, "text": " search has its limitations. So in particular, in symbolic AI, including ILP, we tend to use a lot", "tokens": [50856, 3164, 575, 1080, 15705, 13, 407, 294, 1729, 11, 294, 25755, 7318, 11, 3009, 40413, 47, 11, 321, 3928, 281, 764, 257, 688, 51188], "temperature": 0.0, "avg_logprob": -0.0974464185776249, "compression_ratio": 1.686206896551724, "no_speech_prob": 0.024395065382122993}, {"id": 2113, "seek": 623160, "start": 6248.08, "end": 6253.04, "text": " of combinatorial optimization types of search, right? What we in AI call search is discrete search.", "tokens": [51188, 295, 2512, 31927, 831, 19618, 3467, 295, 3164, 11, 558, 30, 708, 321, 294, 7318, 818, 3164, 307, 27706, 3164, 13, 51436], "temperature": 0.0, "avg_logprob": -0.0974464185776249, "compression_ratio": 1.686206896551724, "no_speech_prob": 0.024395065382122993}, {"id": 2114, "seek": 623160, "start": 6253.04, "end": 6257.120000000001, "text": " And that is good in some ways, but also very limited in others. The same thing is true of gradient", "tokens": [51436, 400, 300, 307, 665, 294, 512, 2098, 11, 457, 611, 588, 5567, 294, 2357, 13, 440, 912, 551, 307, 2074, 295, 16235, 51640], "temperature": 0.0, "avg_logprob": -0.0974464185776249, "compression_ratio": 1.686206896551724, "no_speech_prob": 0.024395065382122993}, {"id": 2115, "seek": 625712, "start": 6257.12, "end": 6263.84, "text": " descent, right? And now to go to that for just a second. Gradient descent is not a continuous", "tokens": [50364, 23475, 11, 558, 30, 400, 586, 281, 352, 281, 300, 337, 445, 257, 1150, 13, 16710, 1196, 23475, 307, 406, 257, 10957, 50700], "temperature": 0.0, "avg_logprob": -0.128725533438201, "compression_ratio": 1.8611111111111112, "no_speech_prob": 0.15982374548912048}, {"id": 2116, "seek": 625712, "start": 6263.84, "end": 6270.4, "text": " optimization algorithm. It's not, right? Again, those real numbers are not infinite precision.", "tokens": [50700, 19618, 9284, 13, 467, 311, 406, 11, 558, 30, 3764, 11, 729, 957, 3547, 366, 406, 13785, 18356, 13, 51028], "temperature": 0.0, "avg_logprob": -0.128725533438201, "compression_ratio": 1.8611111111111112, "no_speech_prob": 0.15982374548912048}, {"id": 2117, "seek": 625712, "start": 6270.4, "end": 6274.96, "text": " There's actually nothing continuous going on in the computer. Gradient descent truly literally", "tokens": [51028, 821, 311, 767, 1825, 10957, 516, 322, 294, 264, 3820, 13, 16710, 1196, 23475, 4908, 3736, 51256], "temperature": 0.0, "avg_logprob": -0.128725533438201, "compression_ratio": 1.8611111111111112, "no_speech_prob": 0.15982374548912048}, {"id": 2118, "seek": 625712, "start": 6274.96, "end": 6279.36, "text": " rigorously mathematically is a discrete optimization algorithm. It takes discrete steps.", "tokens": [51256, 42191, 5098, 44003, 307, 257, 27706, 19618, 9284, 13, 467, 2516, 27706, 4439, 13, 51476], "temperature": 0.0, "avg_logprob": -0.128725533438201, "compression_ratio": 1.8611111111111112, "no_speech_prob": 0.15982374548912048}, {"id": 2119, "seek": 625712, "start": 6280.08, "end": 6284.96, "text": " The assumption that gradient descent depends on, which is that the infinitesimally small updates", "tokens": [51512, 440, 15302, 300, 16235, 23475, 5946, 322, 11, 597, 307, 300, 264, 7193, 3324, 332, 379, 1359, 9205, 51756], "temperature": 0.0, "avg_logprob": -0.128725533438201, "compression_ratio": 1.8611111111111112, "no_speech_prob": 0.15982374548912048}, {"id": 2120, "seek": 628496, "start": 6284.96, "end": 6290.96, "text": " do not hold. And moreover, in machine learning, as a numerical analysis, we are constantly dealing", "tokens": [50364, 360, 406, 1797, 13, 400, 544, 3570, 11, 294, 3479, 2539, 11, 382, 257, 29054, 5215, 11, 321, 366, 6460, 6260, 50664], "temperature": 0.0, "avg_logprob": -0.090136188091618, "compression_ratio": 1.675, "no_speech_prob": 0.0023950431495904922}, {"id": 2121, "seek": 628496, "start": 6290.96, "end": 6295.44, "text": " with this fact that there's a mismatch between our mathematical conceptual model of the space", "tokens": [50664, 365, 341, 1186, 300, 456, 311, 257, 23220, 852, 1296, 527, 18894, 24106, 2316, 295, 264, 1901, 50888], "temperature": 0.0, "avg_logprob": -0.090136188091618, "compression_ratio": 1.675, "no_speech_prob": 0.0023950431495904922}, {"id": 2122, "seek": 628496, "start": 6295.44, "end": 6300.16, "text": " that we're working with as continuous with the reality of the computer that is not continuous.", "tokens": [50888, 300, 321, 434, 1364, 365, 382, 10957, 365, 264, 4103, 295, 264, 3820, 300, 307, 406, 10957, 13, 51124], "temperature": 0.0, "avg_logprob": -0.090136188091618, "compression_ratio": 1.675, "no_speech_prob": 0.0023950431495904922}, {"id": 2123, "seek": 628496, "start": 6300.16, "end": 6306.16, "text": " So now this is not, but gradient descent still is a different optimization technique", "tokens": [51124, 407, 586, 341, 307, 406, 11, 457, 16235, 23475, 920, 307, 257, 819, 19618, 6532, 51424], "temperature": 0.0, "avg_logprob": -0.090136188091618, "compression_ratio": 1.675, "no_speech_prob": 0.0023950431495904922}, {"id": 2124, "seek": 628496, "start": 6306.16, "end": 6311.44, "text": " with some very important advantages, in particular the key, right? The power of gradient descent", "tokens": [51424, 365, 512, 588, 1021, 14906, 11, 294, 1729, 264, 2141, 11, 558, 30, 440, 1347, 295, 16235, 23475, 51688], "temperature": 0.0, "avg_logprob": -0.090136188091618, "compression_ratio": 1.675, "no_speech_prob": 0.0023950431495904922}, {"id": 2125, "seek": 631144, "start": 6311.44, "end": 6316.4, "text": " comes from the fact that to move from my current point to a better one, I don't need to try out", "tokens": [50364, 1487, 490, 264, 1186, 300, 281, 1286, 490, 452, 2190, 935, 281, 257, 1101, 472, 11, 286, 500, 380, 643, 281, 853, 484, 50612], "temperature": 0.0, "avg_logprob": -0.08383173908261086, "compression_ratio": 1.8486842105263157, "no_speech_prob": 0.028416359797120094}, {"id": 2126, "seek": 631144, "start": 6316.4, "end": 6320.48, "text": " all the neighboring points because that takes order of the time of the neighboring points.", "tokens": [50612, 439, 264, 31521, 2793, 570, 300, 2516, 1668, 295, 264, 565, 295, 264, 31521, 2793, 13, 50816], "temperature": 0.0, "avg_logprob": -0.08383173908261086, "compression_ratio": 1.8486842105263157, "no_speech_prob": 0.028416359797120094}, {"id": 2127, "seek": 631144, "start": 6320.48, "end": 6326.16, "text": " I have a closed form way to compute what is the best one, right? And then I move there.", "tokens": [50816, 286, 362, 257, 5395, 1254, 636, 281, 14722, 437, 307, 264, 1151, 472, 11, 558, 30, 400, 550, 286, 1286, 456, 13, 51100], "temperature": 0.0, "avg_logprob": -0.08383173908261086, "compression_ratio": 1.8486842105263157, "no_speech_prob": 0.028416359797120094}, {"id": 2128, "seek": 631144, "start": 6326.16, "end": 6329.679999999999, "text": " And this is absolutely brilliant, right? Like we don't want to let go of that, right? This is,", "tokens": [51100, 400, 341, 307, 3122, 10248, 11, 558, 30, 1743, 321, 500, 380, 528, 281, 718, 352, 295, 300, 11, 558, 30, 639, 307, 11, 51276], "temperature": 0.0, "avg_logprob": -0.08383173908261086, "compression_ratio": 1.8486842105263157, "no_speech_prob": 0.028416359797120094}, {"id": 2129, "seek": 631144, "start": 6329.679999999999, "end": 6334.96, "text": " you know, Newton's enlightenment is bright idea, right? The price of that is that in order to do", "tokens": [51276, 291, 458, 11, 19541, 311, 34661, 307, 4730, 1558, 11, 558, 30, 440, 3218, 295, 300, 307, 300, 294, 1668, 281, 360, 51540], "temperature": 0.0, "avg_logprob": -0.08383173908261086, "compression_ratio": 1.8486842105263157, "no_speech_prob": 0.028416359797120094}, {"id": 2130, "seek": 631144, "start": 6334.96, "end": 6340.879999999999, "text": " that you have to make this approximation, which again, calculus is an approximation. It assumes", "tokens": [51540, 300, 291, 362, 281, 652, 341, 28023, 11, 597, 797, 11, 33400, 307, 364, 28023, 13, 467, 37808, 51836], "temperature": 0.0, "avg_logprob": -0.08383173908261086, "compression_ratio": 1.8486842105263157, "no_speech_prob": 0.028416359797120094}, {"id": 2131, "seek": 634088, "start": 6340.88, "end": 6346.32, "text": " that certain effects are second order and can be ignored. Now, ironically, when you learn a large", "tokens": [50364, 300, 1629, 5065, 366, 1150, 1668, 293, 393, 312, 19735, 13, 823, 11, 41082, 11, 562, 291, 1466, 257, 2416, 50636], "temperature": 0.0, "avg_logprob": -0.06955761614099013, "compression_ratio": 1.7765957446808511, "no_speech_prob": 0.0022501684725284576}, {"id": 2132, "seek": 634088, "start": 6346.32, "end": 6350.8, "text": " deep network these days, you're actually in a regime where they cannot be ignored, right? Because", "tokens": [50636, 2452, 3209, 613, 1708, 11, 291, 434, 767, 294, 257, 13120, 689, 436, 2644, 312, 19735, 11, 558, 30, 1436, 50860], "temperature": 0.0, "avg_logprob": -0.06955761614099013, "compression_ratio": 1.7765957446808511, "no_speech_prob": 0.0022501684725284576}, {"id": 2133, "seek": 634088, "start": 6350.8, "end": 6356.88, "text": " these infinitesimal changes are not that infinitesimal because you take a finite step, right? The gradient", "tokens": [50860, 613, 7193, 3324, 10650, 2962, 366, 406, 300, 7193, 3324, 10650, 570, 291, 747, 257, 19362, 1823, 11, 558, 30, 440, 16235, 51164], "temperature": 0.0, "avg_logprob": -0.06955761614099013, "compression_ratio": 1.7765957446808511, "no_speech_prob": 0.0022501684725284576}, {"id": 2134, "seek": 634088, "start": 6356.88, "end": 6361.2, "text": " descent is always taking finite steps, which is why it's a discrete algorithm. And once you take", "tokens": [51164, 23475, 307, 1009, 1940, 19362, 4439, 11, 597, 307, 983, 309, 311, 257, 27706, 9284, 13, 400, 1564, 291, 747, 51380], "temperature": 0.0, "avg_logprob": -0.06955761614099013, "compression_ratio": 1.7765957446808511, "no_speech_prob": 0.0022501684725284576}, {"id": 2135, "seek": 634088, "start": 6361.2, "end": 6366.24, "text": " that finite step for any reasonable learning rate, the total effect of the approximations that you've", "tokens": [51380, 300, 19362, 1823, 337, 604, 10585, 2539, 3314, 11, 264, 3217, 1802, 295, 264, 8542, 763, 300, 291, 600, 51632], "temperature": 0.0, "avg_logprob": -0.06955761614099013, "compression_ratio": 1.7765957446808511, "no_speech_prob": 0.0022501684725284576}, {"id": 2136, "seek": 636624, "start": 6366.24, "end": 6372.5599999999995, "text": " made typically swamps the step that you're taking. So the assumption of calculus that", "tokens": [50364, 1027, 5850, 1693, 23150, 264, 1823, 300, 291, 434, 1940, 13, 407, 264, 15302, 295, 33400, 300, 50680], "temperature": 0.0, "avg_logprob": -0.11479381863161814, "compression_ratio": 1.7223880597014924, "no_speech_prob": 0.12401223182678223}, {"id": 2137, "seek": 636624, "start": 6372.5599999999995, "end": 6377.599999999999, "text": " gradient descent is founded on is actually false. Now, in some ways this invalidates a lot of our", "tokens": [50680, 16235, 23475, 307, 13234, 322, 307, 767, 7908, 13, 823, 11, 294, 512, 2098, 341, 34702, 1024, 257, 688, 295, 527, 50932], "temperature": 0.0, "avg_logprob": -0.11479381863161814, "compression_ratio": 1.7223880597014924, "no_speech_prob": 0.12401223182678223}, {"id": 2138, "seek": 636624, "start": 6377.599999999999, "end": 6383.28, "text": " intuitions. In many ways, and again, this remains to be resolved, a lot of why gradient descent works", "tokens": [50932, 16224, 626, 13, 682, 867, 2098, 11, 293, 797, 11, 341, 7023, 281, 312, 20772, 11, 257, 688, 295, 983, 16235, 23475, 1985, 51216], "temperature": 0.0, "avg_logprob": -0.11479381863161814, "compression_ratio": 1.7223880597014924, "no_speech_prob": 0.12401223182678223}, {"id": 2139, "seek": 636624, "start": 6383.28, "end": 6387.599999999999, "text": " better than people expected to is in fact that it's doing something else. It's doing stochastic", "tokens": [51216, 1101, 813, 561, 5176, 281, 307, 294, 1186, 300, 309, 311, 884, 746, 1646, 13, 467, 311, 884, 342, 8997, 2750, 51432], "temperature": 0.0, "avg_logprob": -0.11479381863161814, "compression_ratio": 1.7223880597014924, "no_speech_prob": 0.12401223182678223}, {"id": 2140, "seek": 636624, "start": 6387.599999999999, "end": 6391.92, "text": " search partly because of the SGD as opposed to being matched partly because of things like this.", "tokens": [51432, 3164, 17031, 570, 295, 264, 34520, 35, 382, 8851, 281, 885, 21447, 17031, 570, 295, 721, 411, 341, 13, 51648], "temperature": 0.0, "avg_logprob": -0.11479381863161814, "compression_ratio": 1.7223880597014924, "no_speech_prob": 0.12401223182678223}, {"id": 2141, "seek": 636624, "start": 6391.92, "end": 6395.5199999999995, "text": " Okay, well, this is really interesting. A couple of places we can go. But first of all, I remember", "tokens": [51648, 1033, 11, 731, 11, 341, 307, 534, 1880, 13, 316, 1916, 295, 3190, 321, 393, 352, 13, 583, 700, 295, 439, 11, 286, 1604, 51828], "temperature": 0.0, "avg_logprob": -0.11479381863161814, "compression_ratio": 1.7223880597014924, "no_speech_prob": 0.12401223182678223}, {"id": 2142, "seek": 639552, "start": 6395.52, "end": 6401.280000000001, "text": " you did the paper and that introduced elements of NTK theory as well, which might be an argument", "tokens": [50364, 291, 630, 264, 3035, 293, 300, 7268, 4959, 295, 43452, 42, 5261, 382, 731, 11, 597, 1062, 312, 364, 6770, 50652], "temperature": 0.0, "avg_logprob": -0.15083201272147043, "compression_ratio": 1.9350180505415162, "no_speech_prob": 0.022222286090254784}, {"id": 2143, "seek": 639552, "start": 6401.280000000001, "end": 6405.76, "text": " against the discreteness of the optimization. But also, I wanted to trade off the two types.", "tokens": [50652, 1970, 264, 2983, 35383, 442, 295, 264, 19618, 13, 583, 611, 11, 286, 1415, 281, 4923, 766, 264, 732, 3467, 13, 50876], "temperature": 0.0, "avg_logprob": -0.15083201272147043, "compression_ratio": 1.9350180505415162, "no_speech_prob": 0.022222286090254784}, {"id": 2144, "seek": 639552, "start": 6405.76, "end": 6407.4400000000005, "text": " Well, why is there an argument against the discreteness?", "tokens": [50876, 1042, 11, 983, 307, 456, 364, 6770, 1970, 264, 2983, 35383, 442, 30, 50960], "temperature": 0.0, "avg_logprob": -0.15083201272147043, "compression_ratio": 1.9350180505415162, "no_speech_prob": 0.022222286090254784}, {"id": 2145, "seek": 639552, "start": 6407.4400000000005, "end": 6411.040000000001, "text": " Well, isn't there a, with NTK, isn't there like a closed form solution? Doesn't that kind of like", "tokens": [50960, 1042, 11, 1943, 380, 456, 257, 11, 365, 43452, 42, 11, 1943, 380, 456, 411, 257, 5395, 1254, 3827, 30, 12955, 380, 300, 733, 295, 411, 51140], "temperature": 0.0, "avg_logprob": -0.15083201272147043, "compression_ratio": 1.9350180505415162, "no_speech_prob": 0.022222286090254784}, {"id": 2146, "seek": 639552, "start": 6411.040000000001, "end": 6416.0, "text": " erode the discreteness of the optimization? No, I mean, so there's several things here. But like,", "tokens": [51140, 1189, 1429, 264, 2983, 35383, 442, 295, 264, 19618, 30, 883, 11, 286, 914, 11, 370, 456, 311, 2940, 721, 510, 13, 583, 411, 11, 51388], "temperature": 0.0, "avg_logprob": -0.15083201272147043, "compression_ratio": 1.9350180505415162, "no_speech_prob": 0.022222286090254784}, {"id": 2147, "seek": 639552, "start": 6416.56, "end": 6421.280000000001, "text": " if you have a closed form solution, absolutely brilliantly go for it, right? There's nothing,", "tokens": [51416, 498, 291, 362, 257, 5395, 1254, 3827, 11, 3122, 8695, 42580, 352, 337, 309, 11, 558, 30, 821, 311, 1825, 11, 51652], "temperature": 0.0, "avg_logprob": -0.15083201272147043, "compression_ratio": 1.9350180505415162, "no_speech_prob": 0.022222286090254784}, {"id": 2148, "seek": 642128, "start": 6421.92, "end": 6426.4, "text": " having a closed form solution in no implies that it's continuous or discrete or any other thing,", "tokens": [50396, 1419, 257, 5395, 1254, 3827, 294, 572, 18779, 300, 309, 311, 10957, 420, 27706, 420, 604, 661, 551, 11, 50620], "temperature": 0.0, "avg_logprob": -0.15364881444860387, "compression_ratio": 1.7548387096774194, "no_speech_prob": 0.00657534459605813}, {"id": 2149, "seek": 642128, "start": 6426.4, "end": 6432.0, "text": " right? So, let's say there was a closed form solution and it was like an infinite kernel when", "tokens": [50620, 558, 30, 407, 11, 718, 311, 584, 456, 390, 257, 5395, 1254, 3827, 293, 309, 390, 411, 364, 13785, 28256, 562, 50900], "temperature": 0.0, "avg_logprob": -0.15364881444860387, "compression_ratio": 1.7548387096774194, "no_speech_prob": 0.00657534459605813}, {"id": 2150, "seek": 642128, "start": 6432.0, "end": 6436.88, "text": " it represented some neural network, doesn't that erode the argument? Well, so first, okay, so first", "tokens": [50900, 309, 10379, 512, 18161, 3209, 11, 1177, 380, 300, 1189, 1429, 264, 6770, 30, 1042, 11, 370, 700, 11, 1392, 11, 370, 700, 51144], "temperature": 0.0, "avg_logprob": -0.15364881444860387, "compression_ratio": 1.7548387096774194, "no_speech_prob": 0.00657534459605813}, {"id": 2151, "seek": 642128, "start": 6436.88, "end": 6440.32, "text": " of all, in the work that, so the work that I've done that I think you're referring to is like,", "tokens": [51144, 295, 439, 11, 294, 264, 589, 300, 11, 370, 264, 589, 300, 286, 600, 1096, 300, 286, 519, 291, 434, 13761, 281, 307, 411, 11, 51316], "temperature": 0.0, "avg_logprob": -0.15364881444860387, "compression_ratio": 1.7548387096774194, "no_speech_prob": 0.00657534459605813}, {"id": 2152, "seek": 642128, "start": 6440.32, "end": 6444.96, "text": " I have a proof that every model learned by gradient descent is a kernel machine.", "tokens": [51316, 286, 362, 257, 8177, 300, 633, 2316, 3264, 538, 16235, 23475, 307, 257, 28256, 3479, 13, 51548], "temperature": 0.0, "avg_logprob": -0.15364881444860387, "compression_ratio": 1.7548387096774194, "no_speech_prob": 0.00657534459605813}, {"id": 2153, "seek": 642128, "start": 6444.96, "end": 6448.639999999999, "text": " Yeah, right. And it's something called the path kernel, which is the integral", "tokens": [51548, 865, 11, 558, 13, 400, 309, 311, 746, 1219, 264, 3100, 28256, 11, 597, 307, 264, 11573, 51732], "temperature": 0.0, "avg_logprob": -0.15364881444860387, "compression_ratio": 1.7548387096774194, "no_speech_prob": 0.00657534459605813}, {"id": 2154, "seek": 644864, "start": 6448.64, "end": 6454.320000000001, "text": " of the neural tangent kernel over the overgraded descent, right? Yeah. And now the neural tangent", "tokens": [50364, 295, 264, 18161, 27747, 28256, 670, 264, 670, 7165, 292, 23475, 11, 558, 30, 865, 13, 400, 586, 264, 18161, 27747, 50648], "temperature": 0.0, "avg_logprob": -0.12249012822690217, "compression_ratio": 1.87109375, "no_speech_prob": 0.002975697861984372}, {"id": 2155, "seek": 644864, "start": 6454.320000000001, "end": 6459.92, "text": " kernel does not assume that your network is infinite. Most of the theory that people have done", "tokens": [50648, 28256, 775, 406, 6552, 300, 428, 3209, 307, 13785, 13, 4534, 295, 264, 5261, 300, 561, 362, 1096, 50928], "temperature": 0.0, "avg_logprob": -0.12249012822690217, "compression_ratio": 1.87109375, "no_speech_prob": 0.002975697861984372}, {"id": 2156, "seek": 644864, "start": 6459.92, "end": 6465.6, "text": " with it assumes that the network is infinitely wide, but the definition absolutely does not", "tokens": [50928, 365, 309, 37808, 300, 264, 3209, 307, 36227, 4874, 11, 457, 264, 7123, 3122, 775, 406, 51212], "temperature": 0.0, "avg_logprob": -0.12249012822690217, "compression_ratio": 1.87109375, "no_speech_prob": 0.002975697861984372}, {"id": 2157, "seek": 644864, "start": 6465.6, "end": 6470.320000000001, "text": " require that. And none of what I do, and in fact, that's part of why, you know, of its part is that", "tokens": [51212, 3651, 300, 13, 400, 6022, 295, 437, 286, 360, 11, 293, 294, 1186, 11, 300, 311, 644, 295, 983, 11, 291, 458, 11, 295, 1080, 644, 307, 300, 51448], "temperature": 0.0, "avg_logprob": -0.12249012822690217, "compression_ratio": 1.87109375, "no_speech_prob": 0.002975697861984372}, {"id": 2158, "seek": 644864, "start": 6470.320000000001, "end": 6476.160000000001, "text": " it assumes no infinity of anything. It's for any architecture that you use, and in particular,", "tokens": [51448, 309, 37808, 572, 13202, 295, 1340, 13, 467, 311, 337, 604, 9482, 300, 291, 764, 11, 293, 294, 1729, 11, 51740], "temperature": 0.0, "avg_logprob": -0.12249012822690217, "compression_ratio": 1.87109375, "no_speech_prob": 0.002975697861984372}, {"id": 2159, "seek": 647616, "start": 6476.16, "end": 6480.96, "text": " you know, finite architectures. Okay, interesting. Okay, so hence the discreteness, but can we come", "tokens": [50364, 291, 458, 11, 19362, 6331, 1303, 13, 1033, 11, 1880, 13, 1033, 11, 370, 16678, 264, 2983, 35383, 442, 11, 457, 393, 321, 808, 50604], "temperature": 0.0, "avg_logprob": -0.12887703104222076, "compression_ratio": 1.820754716981132, "no_speech_prob": 0.01080227829515934}, {"id": 2160, "seek": 647616, "start": 6480.96, "end": 6485.36, "text": " back to this contrasting of the discrete program search and the, you know, stochastic gradient", "tokens": [50604, 646, 281, 341, 8712, 278, 295, 264, 27706, 1461, 3164, 293, 264, 11, 291, 458, 11, 342, 8997, 2750, 16235, 50824], "temperature": 0.0, "avg_logprob": -0.12887703104222076, "compression_ratio": 1.820754716981132, "no_speech_prob": 0.01080227829515934}, {"id": 2161, "seek": 647616, "start": 6485.36, "end": 6491.2, "text": " descent on a vector space? Now, in the vector space, there are certain characteristics, you know,", "tokens": [50824, 23475, 322, 257, 8062, 1901, 30, 823, 11, 294, 264, 8062, 1901, 11, 456, 366, 1629, 10891, 11, 291, 458, 11, 51116], "temperature": 0.0, "avg_logprob": -0.12887703104222076, "compression_ratio": 1.820754716981132, "no_speech_prob": 0.01080227829515934}, {"id": 2162, "seek": 647616, "start": 6491.2, "end": 6494.88, "text": " there are certain symmetries, and even though it's a discrete search through the space, I would argue", "tokens": [51116, 456, 366, 1629, 14232, 302, 2244, 11, 293, 754, 1673, 309, 311, 257, 27706, 3164, 807, 264, 1901, 11, 286, 576, 9695, 51300], "temperature": 0.0, "avg_logprob": -0.12887703104222076, "compression_ratio": 1.820754716981132, "no_speech_prob": 0.01080227829515934}, {"id": 2163, "seek": 647616, "start": 6494.88, "end": 6500.16, "text": " that it's still continuous in nature, it has certain characteristics. So contrast those two", "tokens": [51300, 300, 309, 311, 920, 10957, 294, 3687, 11, 309, 575, 1629, 10891, 13, 407, 8712, 729, 732, 51564], "temperature": 0.0, "avg_logprob": -0.12887703104222076, "compression_ratio": 1.820754716981132, "no_speech_prob": 0.01080227829515934}, {"id": 2164, "seek": 647616, "start": 6500.16, "end": 6505.28, "text": " forms of optimization. Precisely so. Exactly. I mean, I think you've put your finger in now.", "tokens": [51564, 6422, 295, 19618, 13, 48746, 736, 370, 13, 7587, 13, 286, 914, 11, 286, 519, 291, 600, 829, 428, 5984, 294, 586, 13, 51820], "temperature": 0.0, "avg_logprob": -0.12887703104222076, "compression_ratio": 1.820754716981132, "no_speech_prob": 0.01080227829515934}, {"id": 2165, "seek": 650528, "start": 6505.28, "end": 6509.84, "text": " The whole point of these continuous spaces, right, is not that they're continuous, because again,", "tokens": [50364, 440, 1379, 935, 295, 613, 10957, 7673, 11, 558, 11, 307, 406, 300, 436, 434, 10957, 11, 570, 797, 11, 50592], "temperature": 0.0, "avg_logprob": -0.13089887431410493, "compression_ratio": 1.8141263940520447, "no_speech_prob": 0.0012833065120503306}, {"id": 2166, "seek": 650528, "start": 6509.84, "end": 6515.2, "text": " that's, that's a fiction, is that they have a certain locality structure, yeah, that you can", "tokens": [50592, 300, 311, 11, 300, 311, 257, 13266, 11, 307, 300, 436, 362, 257, 1629, 1628, 1860, 3877, 11, 1338, 11, 300, 291, 393, 50860], "temperature": 0.0, "avg_logprob": -0.13089887431410493, "compression_ratio": 1.8141263940520447, "no_speech_prob": 0.0012833065120503306}, {"id": 2167, "seek": 650528, "start": 6515.2, "end": 6521.28, "text": " exploit to very good effect. And this is exactly what we're going to send us, right? Now, that", "tokens": [50860, 25924, 281, 588, 665, 1802, 13, 400, 341, 307, 2293, 437, 321, 434, 516, 281, 2845, 505, 11, 558, 30, 823, 11, 300, 51164], "temperature": 0.0, "avg_logprob": -0.13089887431410493, "compression_ratio": 1.8141263940520447, "no_speech_prob": 0.0012833065120503306}, {"id": 2168, "seek": 650528, "start": 6521.28, "end": 6526.88, "text": " locality structure doesn't have to be infinitesimal, right? You don't need points to be infinitely close", "tokens": [51164, 1628, 1860, 3877, 1177, 380, 362, 281, 312, 7193, 3324, 10650, 11, 558, 30, 509, 500, 380, 643, 2793, 281, 312, 36227, 1998, 51444], "temperature": 0.0, "avg_logprob": -0.13089887431410493, "compression_ratio": 1.8141263940520447, "no_speech_prob": 0.0012833065120503306}, {"id": 2169, "seek": 650528, "start": 6526.88, "end": 6531.04, "text": " for all this to apply approximately. And again, they never are, and it's always an approximation.", "tokens": [51444, 337, 439, 341, 281, 3079, 10447, 13, 400, 797, 11, 436, 1128, 366, 11, 293, 309, 311, 1009, 364, 28023, 13, 51652], "temperature": 0.0, "avg_logprob": -0.13089887431410493, "compression_ratio": 1.8141263940520447, "no_speech_prob": 0.0012833065120503306}, {"id": 2170, "seek": 653104, "start": 6531.04, "end": 6537.84, "text": " Now, the question is, do you want to make these locality assumptions or not, right? Making them", "tokens": [50364, 823, 11, 264, 1168, 307, 11, 360, 291, 528, 281, 652, 613, 1628, 1860, 17695, 420, 406, 11, 558, 30, 14595, 552, 50704], "temperature": 0.0, "avg_logprob": -0.09239672832801694, "compression_ratio": 1.7689530685920578, "no_speech_prob": 0.002710371743887663}, {"id": 2171, "seek": 653104, "start": 6537.84, "end": 6542.96, "text": " buys you certain things, right? But it's also potentially unrealistic in some ways, right? Now,", "tokens": [50704, 28153, 291, 1629, 721, 11, 558, 30, 583, 309, 311, 611, 7263, 42867, 294, 512, 2098, 11, 558, 30, 823, 11, 50960], "temperature": 0.0, "avg_logprob": -0.09239672832801694, "compression_ratio": 1.7689530685920578, "no_speech_prob": 0.002710371743887663}, {"id": 2172, "seek": 653104, "start": 6542.96, "end": 6548.56, "text": " this actually, to take a very concrete instance of this, think of space, right? We model space in", "tokens": [50960, 341, 767, 11, 281, 747, 257, 588, 9859, 5197, 295, 341, 11, 519, 295, 1901, 11, 558, 30, 492, 2316, 1901, 294, 51240], "temperature": 0.0, "avg_logprob": -0.09239672832801694, "compression_ratio": 1.7689530685920578, "no_speech_prob": 0.002710371743887663}, {"id": 2173, "seek": 653104, "start": 6548.56, "end": 6554.72, "text": " science and physics and in anything as a continuous thing, which it is not, right? Which is not to", "tokens": [51240, 3497, 293, 10649, 293, 294, 1340, 382, 257, 10957, 551, 11, 597, 309, 307, 406, 11, 558, 30, 3013, 307, 406, 281, 51548], "temperature": 0.0, "avg_logprob": -0.09239672832801694, "compression_ratio": 1.7689530685920578, "no_speech_prob": 0.002710371743887663}, {"id": 2174, "seek": 653104, "start": 6554.72, "end": 6559.28, "text": " say that, and by the way, physicists are coming to this conclusion, right? These days, the prevailing", "tokens": [51548, 584, 300, 11, 293, 538, 264, 636, 11, 48716, 366, 1348, 281, 341, 10063, 11, 558, 30, 1981, 1708, 11, 264, 12642, 23315, 51776], "temperature": 0.0, "avg_logprob": -0.09239672832801694, "compression_ratio": 1.7689530685920578, "no_speech_prob": 0.002710371743887663}, {"id": 2175, "seek": 655928, "start": 6559.28, "end": 6563.5199999999995, "text": " views is that it's from big thing, is that like, it's, you know, space arises from entanglement,", "tokens": [50364, 6809, 307, 300, 309, 311, 490, 955, 551, 11, 307, 300, 411, 11, 309, 311, 11, 291, 458, 11, 1901, 27388, 490, 948, 656, 3054, 11, 50576], "temperature": 0.0, "avg_logprob": -0.1719898288532839, "compression_ratio": 1.8549019607843138, "no_speech_prob": 0.020297687500715256}, {"id": 2176, "seek": 655928, "start": 6563.5199999999995, "end": 6568.0, "text": " et cetera, et cetera, like space is not the fundamental reality, right? And now, I think", "tokens": [50576, 1030, 11458, 11, 1030, 11458, 11, 411, 1901, 307, 406, 264, 8088, 4103, 11, 558, 30, 400, 586, 11, 286, 519, 50800], "temperature": 0.0, "avg_logprob": -0.1719898288532839, "compression_ratio": 1.8549019607843138, "no_speech_prob": 0.020297687500715256}, {"id": 2177, "seek": 655928, "start": 6568.0, "end": 6572.4, "text": " that where this is inevitably going one way or another is that we realize that space is discrete,", "tokens": [50800, 300, 689, 341, 307, 28171, 516, 472, 636, 420, 1071, 307, 300, 321, 4325, 300, 1901, 307, 27706, 11, 51020], "temperature": 0.0, "avg_logprob": -0.1719898288532839, "compression_ratio": 1.8549019607843138, "no_speech_prob": 0.020297687500715256}, {"id": 2178, "seek": 655928, "start": 6572.4, "end": 6578.88, "text": " right? But, and this is key, it has certain properties, including symmetries like translations", "tokens": [51020, 558, 30, 583, 11, 293, 341, 307, 2141, 11, 309, 575, 1629, 7221, 11, 3009, 14232, 302, 2244, 411, 37578, 51344], "temperature": 0.0, "avg_logprob": -0.1719898288532839, "compression_ratio": 1.8549019607843138, "no_speech_prob": 0.020297687500715256}, {"id": 2179, "seek": 655928, "start": 6578.88, "end": 6583.759999999999, "text": " in variance, rotation in variance, et cetera, et cetera, that whole, approximately or exactly,", "tokens": [51344, 294, 21977, 11, 12447, 294, 21977, 11, 1030, 11458, 11, 1030, 11458, 11, 300, 1379, 11, 10447, 420, 2293, 11, 51588], "temperature": 0.0, "avg_logprob": -0.1719898288532839, "compression_ratio": 1.8549019607843138, "no_speech_prob": 0.020297687500715256}, {"id": 2180, "seek": 658376, "start": 6583.76, "end": 6590.400000000001, "text": " but if those hold a whole bunch of things like that, then you have, you know, your latent variable", "tokens": [50364, 457, 498, 729, 1797, 257, 1379, 3840, 295, 721, 411, 300, 11, 550, 291, 362, 11, 291, 458, 11, 428, 48994, 7006, 50696], "temperature": 0.0, "avg_logprob": -0.06529882802801618, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.04737432673573494}, {"id": 2181, "seek": 658376, "start": 6590.400000000001, "end": 6595.6, "text": " structure, right, is very well approximated by our notion of continuous space, in which case,", "tokens": [50696, 3877, 11, 558, 11, 307, 588, 731, 8542, 770, 538, 527, 10710, 295, 10957, 1901, 11, 294, 597, 1389, 11, 50956], "temperature": 0.0, "avg_logprob": -0.06529882802801618, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.04737432673573494}, {"id": 2182, "seek": 658376, "start": 6595.6, "end": 6600.16, "text": " it would be foolish to not use it, right? To formulate the laws of physics and to do computer", "tokens": [50956, 309, 576, 312, 23478, 281, 406, 764, 309, 11, 558, 30, 1407, 47881, 264, 6064, 295, 10649, 293, 281, 360, 3820, 51184], "temperature": 0.0, "avg_logprob": -0.06529882802801618, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.04737432673573494}, {"id": 2183, "seek": 658376, "start": 6600.16, "end": 6606.0, "text": " vision and so on and so forth. But at the same time, right, if we believe in it too literally,", "tokens": [51184, 5201, 293, 370, 322, 293, 370, 5220, 13, 583, 412, 264, 912, 565, 11, 558, 11, 498, 321, 1697, 294, 309, 886, 3736, 11, 51476], "temperature": 0.0, "avg_logprob": -0.06529882802801618, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.04737432673573494}, {"id": 2184, "seek": 658376, "start": 6606.0, "end": 6610.56, "text": " we walk ourselves into a blind alley. So concretely, look at computer vision, right?", "tokens": [51476, 321, 1792, 4175, 666, 257, 6865, 26660, 13, 407, 39481, 736, 11, 574, 412, 3820, 5201, 11, 558, 30, 51704], "temperature": 0.0, "avg_logprob": -0.06529882802801618, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.04737432673573494}, {"id": 2185, "seek": 661056, "start": 6610.56, "end": 6614.240000000001, "text": " People in the universities of computer vision started out trying to do it with differential", "tokens": [50364, 3432, 294, 264, 11779, 295, 3820, 5201, 1409, 484, 1382, 281, 360, 309, 365, 15756, 50548], "temperature": 0.0, "avg_logprob": -0.11308735840080321, "compression_ratio": 1.7453416149068324, "no_speech_prob": 0.008980980142951012}, {"id": 2186, "seek": 661056, "start": 6614.240000000001, "end": 6619.280000000001, "text": " equations and Fourier analysis and all of that could continue with stuff, right? Because that", "tokens": [50548, 11787, 293, 36810, 5215, 293, 439, 295, 300, 727, 2354, 365, 1507, 11, 558, 30, 1436, 300, 50800], "temperature": 0.0, "avg_logprob": -0.11308735840080321, "compression_ratio": 1.7453416149068324, "no_speech_prob": 0.008980980142951012}, {"id": 2187, "seek": 661056, "start": 6619.280000000001, "end": 6624.88, "text": " was the obvious thing to do, right? And it failed. That doesn't work. That's why we need things like", "tokens": [50800, 390, 264, 6322, 551, 281, 360, 11, 558, 30, 400, 309, 7612, 13, 663, 1177, 380, 589, 13, 663, 311, 983, 321, 643, 721, 411, 51080], "temperature": 0.0, "avg_logprob": -0.11308735840080321, "compression_ratio": 1.7453416149068324, "no_speech_prob": 0.008980980142951012}, {"id": 2188, "seek": 661056, "start": 6624.88, "end": 6629.76, "text": " deep learning and, you know, Markov random fields that are discrete grids that use, you know,", "tokens": [51080, 2452, 2539, 293, 11, 291, 458, 11, 3934, 5179, 4974, 7909, 300, 366, 27706, 677, 3742, 300, 764, 11, 291, 458, 11, 51324], "temperature": 0.0, "avg_logprob": -0.11308735840080321, "compression_ratio": 1.7453416149068324, "no_speech_prob": 0.008980980142951012}, {"id": 2189, "seek": 661056, "start": 6629.76, "end": 6634.080000000001, "text": " to model the images and whatnot, because you are, along with the approximate continuity,", "tokens": [51324, 281, 2316, 264, 5267, 293, 25882, 11, 570, 291, 366, 11, 2051, 365, 264, 30874, 23807, 11, 51540], "temperature": 0.0, "avg_logprob": -0.11308735840080321, "compression_ratio": 1.7453416149068324, "no_speech_prob": 0.008980980142951012}, {"id": 2190, "seek": 661056, "start": 6634.080000000001, "end": 6639.360000000001, "text": " you also often have large discontinuities. And if you can only model the world continuously,", "tokens": [51540, 291, 611, 2049, 362, 2416, 31420, 84, 1088, 13, 400, 498, 291, 393, 787, 2316, 264, 1002, 15684, 11, 51804], "temperature": 0.0, "avg_logprob": -0.11308735840080321, "compression_ratio": 1.7453416149068324, "no_speech_prob": 0.008980980142951012}, {"id": 2191, "seek": 663936, "start": 6639.92, "end": 6643.36, "text": " you don't know what to do. And the problem precisely is that you have all these phenomena", "tokens": [50392, 291, 500, 380, 458, 437, 281, 360, 13, 400, 264, 1154, 13402, 307, 300, 291, 362, 439, 613, 22004, 50564], "temperature": 0.0, "avg_logprob": -0.13320510429248475, "compression_ratio": 1.6319444444444444, "no_speech_prob": 0.014026076532900333}, {"id": 2192, "seek": 663936, "start": 6643.36, "end": 6647.759999999999, "text": " that are like this, including, you know, in vision, but also in, in turbulence and condensed", "tokens": [50564, 300, 366, 411, 341, 11, 3009, 11, 291, 458, 11, 294, 5201, 11, 457, 611, 294, 11, 294, 48612, 293, 36398, 50784], "temperature": 0.0, "avg_logprob": -0.13320510429248475, "compression_ratio": 1.6319444444444444, "no_speech_prob": 0.014026076532900333}, {"id": 2193, "seek": 663936, "start": 6647.759999999999, "end": 6652.799999999999, "text": " metaphysics and so on, you've got to realize that there are discontinues and not try to shoehorn", "tokens": [50784, 30946, 41732, 293, 370, 322, 11, 291, 600, 658, 281, 4325, 300, 456, 366, 31420, 1247, 293, 406, 853, 281, 12796, 31990, 51036], "temperature": 0.0, "avg_logprob": -0.13320510429248475, "compression_ratio": 1.6319444444444444, "no_speech_prob": 0.014026076532900333}, {"id": 2194, "seek": 663936, "start": 6652.799999999999, "end": 6657.36, "text": " them into continuity when that's no longer appropriate. Interesting. Okay. Well, can we bring", "tokens": [51036, 552, 666, 23807, 562, 300, 311, 572, 2854, 6854, 13, 14711, 13, 1033, 13, 1042, 11, 393, 321, 1565, 51264], "temperature": 0.0, "avg_logprob": -0.13320510429248475, "compression_ratio": 1.6319444444444444, "no_speech_prob": 0.014026076532900333}, {"id": 2195, "seek": 663936, "start": 6657.36, "end": 6663.679999999999, "text": " in ILP and can you contrast like the kind of function spaces that are learnable in both methods?", "tokens": [51264, 294, 40413, 47, 293, 393, 291, 8712, 411, 264, 733, 295, 2445, 7673, 300, 366, 1466, 712, 294, 1293, 7150, 30, 51580], "temperature": 0.0, "avg_logprob": -0.13320510429248475, "compression_ratio": 1.6319444444444444, "no_speech_prob": 0.014026076532900333}, {"id": 2196, "seek": 666368, "start": 6663.68, "end": 6669.68, "text": " Yeah. So ILP, so let me actually preface this with the following. People in every one of these", "tokens": [50364, 865, 13, 407, 40413, 47, 11, 370, 718, 385, 767, 659, 2868, 341, 365, 264, 3480, 13, 3432, 294, 633, 472, 295, 613, 50664], "temperature": 0.0, "avg_logprob": -0.10467556762695313, "compression_ratio": 1.7482517482517483, "no_speech_prob": 0.016902048140764236}, {"id": 2197, "seek": 666368, "start": 6669.68, "end": 6676.88, "text": " schools of AI tend to have this view that I can represent everything in the world using my approach.", "tokens": [50664, 4656, 295, 7318, 3928, 281, 362, 341, 1910, 300, 286, 393, 2906, 1203, 294, 264, 1002, 1228, 452, 3109, 13, 51024], "temperature": 0.0, "avg_logprob": -0.10467556762695313, "compression_ratio": 1.7482517482517483, "no_speech_prob": 0.016902048140764236}, {"id": 2198, "seek": 666368, "start": 6677.68, "end": 6682.64, "text": " So I can like, look, prologue is too incomplete. So why do you need neural networks? But I can also", "tokens": [51064, 407, 286, 393, 411, 11, 574, 11, 447, 4987, 622, 307, 886, 31709, 13, 407, 983, 360, 291, 643, 18161, 9590, 30, 583, 286, 393, 611, 51312], "temperature": 0.0, "avg_logprob": -0.10467556762695313, "compression_ratio": 1.7482517482517483, "no_speech_prob": 0.016902048140764236}, {"id": 2199, "seek": 666368, "start": 6682.64, "end": 6687.6, "text": " say neural networks are too incomplete. So why do I need prologue? And in fact, kernel machines have", "tokens": [51312, 584, 18161, 9590, 366, 886, 31709, 13, 407, 983, 360, 286, 643, 447, 4987, 622, 30, 400, 294, 1186, 11, 28256, 8379, 362, 51560], "temperature": 0.0, "avg_logprob": -0.10467556762695313, "compression_ratio": 1.7482517482517483, "no_speech_prob": 0.016902048140764236}, {"id": 2200, "seek": 666368, "start": 6687.6, "end": 6691.76, "text": " a represented theorem that says you can approximate any function, blah, blah, blah, right? So everybody", "tokens": [51560, 257, 10379, 20904, 300, 1619, 291, 393, 30874, 604, 2445, 11, 12288, 11, 12288, 11, 12288, 11, 558, 30, 407, 2201, 51768], "temperature": 0.0, "avg_logprob": -0.10467556762695313, "compression_ratio": 1.7482517482517483, "no_speech_prob": 0.016902048140764236}, {"id": 2201, "seek": 669176, "start": 6691.76, "end": 6696.08, "text": " has one of these represent their theorems, right? That says, I can represent anything, right? So in", "tokens": [50364, 575, 472, 295, 613, 2906, 641, 10299, 2592, 11, 558, 30, 663, 1619, 11, 286, 393, 2906, 1340, 11, 558, 30, 407, 294, 50580], "temperature": 0.0, "avg_logprob": -0.20158687233924866, "compression_ratio": 1.7906137184115523, "no_speech_prob": 0.018525945022702217}, {"id": 2202, "seek": 669176, "start": 6696.08, "end": 6702.16, "text": " particular, you can do, right? I mean, look, first, our logic was invented by, by Frege, essentially,", "tokens": [50580, 1729, 11, 291, 393, 360, 11, 558, 30, 286, 914, 11, 574, 11, 700, 11, 527, 9952, 390, 14479, 538, 11, 538, 6142, 432, 11, 4476, 11, 50884], "temperature": 0.0, "avg_logprob": -0.20158687233924866, "compression_ratio": 1.7906137184115523, "no_speech_prob": 0.018525945022702217}, {"id": 2203, "seek": 669176, "start": 6702.16, "end": 6708.08, "text": " to, to model the real numbers. So it can almost by definition model real numbers, right? Anything", "tokens": [50884, 281, 11, 281, 2316, 264, 957, 3547, 13, 407, 309, 393, 1920, 538, 7123, 2316, 957, 3547, 11, 558, 30, 11998, 51180], "temperature": 0.0, "avg_logprob": -0.20158687233924866, "compression_ratio": 1.7906137184115523, "no_speech_prob": 0.018525945022702217}, {"id": 2204, "seek": 669176, "start": 6708.08, "end": 6712.16, "text": " you might want to say about real numbers and, and weight and descent and neural networks. And in", "tokens": [51180, 291, 1062, 528, 281, 584, 466, 957, 3547, 293, 11, 293, 3364, 293, 23475, 293, 18161, 9590, 13, 400, 294, 51384], "temperature": 0.0, "avg_logprob": -0.20158687233924866, "compression_ratio": 1.7906137184115523, "no_speech_prob": 0.018525945022702217}, {"id": 2205, "seek": 669176, "start": 6712.16, "end": 6718.400000000001, "text": " fact, people have even done this. So you can say it all in, in logic programming, right? So why not", "tokens": [51384, 1186, 11, 561, 362, 754, 1096, 341, 13, 407, 291, 393, 584, 309, 439, 294, 11, 294, 9952, 9410, 11, 558, 30, 407, 983, 406, 51696], "temperature": 0.0, "avg_logprob": -0.20158687233924866, "compression_ratio": 1.7906137184115523, "no_speech_prob": 0.018525945022702217}, {"id": 2206, "seek": 671840, "start": 6718.4, "end": 6722.719999999999, "text": " just do that? Well, precisely because certain things are much more easily done in other ways,", "tokens": [50364, 445, 360, 300, 30, 1042, 11, 13402, 570, 1629, 721, 366, 709, 544, 3612, 1096, 294, 661, 2098, 11, 50580], "temperature": 0.0, "avg_logprob": -0.13551407160721426, "compression_ratio": 1.9094076655052266, "no_speech_prob": 0.08993271738290787}, {"id": 2207, "seek": 671840, "start": 6722.719999999999, "end": 6726.719999999999, "text": " right? So what you have to ask about anything, but then about, you know, not the logic", "tokens": [50580, 558, 30, 407, 437, 291, 362, 281, 1029, 466, 1340, 11, 457, 550, 466, 11, 291, 458, 11, 406, 264, 9952, 50780], "temperature": 0.0, "avg_logprob": -0.13551407160721426, "compression_ratio": 1.9094076655052266, "no_speech_prob": 0.08993271738290787}, {"id": 2208, "seek": 671840, "start": 6726.719999999999, "end": 6731.28, "text": " program in particular, like, what things are well represented in this way, like compactly", "tokens": [50780, 1461, 294, 1729, 11, 411, 11, 437, 721, 366, 731, 10379, 294, 341, 636, 11, 411, 14679, 356, 51008], "temperature": 0.0, "avg_logprob": -0.13551407160721426, "compression_ratio": 1.9094076655052266, "no_speech_prob": 0.08993271738290787}, {"id": 2209, "seek": 671840, "start": 6731.28, "end": 6737.44, "text": " represented, and then in such a way that learning them and doing inference with them is easy, right?", "tokens": [51008, 10379, 11, 293, 550, 294, 1270, 257, 636, 300, 2539, 552, 293, 884, 38253, 365, 552, 307, 1858, 11, 558, 30, 51316], "temperature": 0.0, "avg_logprob": -0.13551407160721426, "compression_ratio": 1.9094076655052266, "no_speech_prob": 0.08993271738290787}, {"id": 2210, "seek": 671840, "start": 6737.44, "end": 6741.12, "text": " And those things are different for logic programming and for things like deep learning,", "tokens": [51316, 400, 729, 721, 366, 819, 337, 9952, 9410, 293, 337, 721, 411, 2452, 2539, 11, 51500], "temperature": 0.0, "avg_logprob": -0.13551407160721426, "compression_ratio": 1.9094076655052266, "no_speech_prob": 0.08993271738290787}, {"id": 2211, "seek": 671840, "start": 6741.12, "end": 6745.679999999999, "text": " which is why we need a unification of both. So what is things like logic programming and", "tokens": [51500, 597, 307, 983, 321, 643, 257, 517, 3774, 295, 1293, 13, 407, 437, 307, 721, 411, 9952, 9410, 293, 51728], "temperature": 0.0, "avg_logprob": -0.13551407160721426, "compression_ratio": 1.9094076655052266, "no_speech_prob": 0.08993271738290787}, {"id": 2212, "seek": 674568, "start": 6745.68, "end": 6750.4800000000005, "text": " ILP good for, right? It's precisely, I mean, it's many things, but the key thing is,", "tokens": [50364, 40413, 47, 665, 337, 11, 558, 30, 467, 311, 13402, 11, 286, 914, 11, 309, 311, 867, 721, 11, 457, 264, 2141, 551, 307, 11, 50604], "temperature": 0.0, "avg_logprob": -0.12169584177308164, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.11419712752103806}, {"id": 2213, "seek": 674568, "start": 6750.4800000000005, "end": 6756.56, "text": " it's precisely for learning pieces of knowledge that can then be reused and composed in arbitrary", "tokens": [50604, 309, 311, 13402, 337, 2539, 3755, 295, 3601, 300, 393, 550, 312, 319, 4717, 293, 18204, 294, 23211, 50908], "temperature": 0.0, "avg_logprob": -0.12169584177308164, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.11419712752103806}, {"id": 2214, "seek": 674568, "start": 6756.56, "end": 6764.240000000001, "text": " ways. This is the huge power symbolic AI that connectionism does not have, right? It's like,", "tokens": [50908, 2098, 13, 639, 307, 264, 2603, 1347, 25755, 7318, 300, 4984, 1434, 775, 406, 362, 11, 558, 30, 467, 311, 411, 11, 51292], "temperature": 0.0, "avg_logprob": -0.12169584177308164, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.11419712752103806}, {"id": 2215, "seek": 674568, "start": 6764.240000000001, "end": 6769.04, "text": " I learned the fact here, I learned a rule there. And tomorrow you ask me a question,", "tokens": [51292, 286, 3264, 264, 1186, 510, 11, 286, 3264, 257, 4978, 456, 13, 400, 4153, 291, 1029, 385, 257, 1168, 11, 51532], "temperature": 0.0, "avg_logprob": -0.12169584177308164, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.11419712752103806}, {"id": 2216, "seek": 674568, "start": 6769.04, "end": 6773.04, "text": " and I combine that fact, actually, several rules by rule changing, right? There's a whole proof", "tokens": [51532, 293, 286, 10432, 300, 1186, 11, 767, 11, 2940, 4474, 538, 4978, 4473, 11, 558, 30, 821, 311, 257, 1379, 8177, 51732], "temperature": 0.0, "avg_logprob": -0.12169584177308164, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.11419712752103806}, {"id": 2217, "seek": 677304, "start": 6773.04, "end": 6777.36, "text": " tree of rules that could have come from very different places. And I do a completely novel", "tokens": [50364, 4230, 295, 4474, 300, 727, 362, 808, 490, 588, 819, 3190, 13, 400, 286, 360, 257, 2584, 7613, 50580], "temperature": 0.0, "avg_logprob": -0.15404657636369978, "compression_ratio": 1.7366771159874608, "no_speech_prob": 0.22437402606010437}, {"id": 2218, "seek": 677304, "start": 6777.36, "end": 6782.24, "text": " chain of inference that answers your question. This is spectacular, right? And this is surely", "tokens": [50580, 5021, 295, 38253, 300, 6338, 428, 1168, 13, 639, 307, 18149, 11, 558, 30, 400, 341, 307, 11468, 50824], "temperature": 0.0, "avg_logprob": -0.15404657636369978, "compression_ratio": 1.7366771159874608, "no_speech_prob": 0.22437402606010437}, {"id": 2219, "seek": 677304, "start": 6782.24, "end": 6787.76, "text": " court-wide intelligence is all about. And the symbolists know how to do it. The connectionists", "tokens": [50824, 4753, 12, 7990, 7599, 307, 439, 466, 13, 400, 264, 5986, 1751, 458, 577, 281, 360, 309, 13, 440, 4984, 1751, 51100], "temperature": 0.0, "avg_logprob": -0.15404657636369978, "compression_ratio": 1.7366771159874608, "no_speech_prob": 0.22437402606010437}, {"id": 2220, "seek": 677304, "start": 6787.76, "end": 6791.04, "text": " don't. But if I was a connectionist, I'd be like, you know, I know if it was a good one,", "tokens": [51100, 500, 380, 13, 583, 498, 286, 390, 257, 4984, 468, 11, 286, 1116, 312, 411, 11, 291, 458, 11, 286, 458, 498, 309, 390, 257, 665, 472, 11, 51264], "temperature": 0.0, "avg_logprob": -0.15404657636369978, "compression_ratio": 1.7366771159874608, "no_speech_prob": 0.22437402606010437}, {"id": 2221, "seek": 677304, "start": 6791.04, "end": 6795.68, "text": " and the better ones like Yoshio Benji are doing this, right? It's like, go and try to understand", "tokens": [51264, 293, 264, 1101, 2306, 411, 38949, 1004, 3964, 4013, 366, 884, 341, 11, 558, 30, 467, 311, 411, 11, 352, 293, 853, 281, 1223, 51496], "temperature": 0.0, "avg_logprob": -0.15404657636369978, "compression_ratio": 1.7366771159874608, "no_speech_prob": 0.22437402606010437}, {"id": 2222, "seek": 677304, "start": 6795.68, "end": 6799.12, "text": " what those people understand so that you can then not combine it with those other ideas.", "tokens": [51496, 437, 729, 561, 1223, 370, 300, 291, 393, 550, 406, 10432, 309, 365, 729, 661, 3487, 13, 51668], "temperature": 0.0, "avg_logprob": -0.15404657636369978, "compression_ratio": 1.7366771159874608, "no_speech_prob": 0.22437402606010437}, {"id": 2223, "seek": 679912, "start": 6799.12, "end": 6804.5599999999995, "text": " Yes. Yeah. Yeah, I completely agree. So a huge part of intelligence is this symbolic,", "tokens": [50364, 1079, 13, 865, 13, 865, 11, 286, 2584, 3986, 13, 407, 257, 2603, 644, 295, 7599, 307, 341, 25755, 11, 50636], "temperature": 0.0, "avg_logprob": -0.10430283589406056, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.006775062531232834}, {"id": 2224, "seek": 679912, "start": 6804.5599999999995, "end": 6811.599999999999, "text": " you know, extrapolation. Yeah. So how do you bring abstraction into this? Because the thing", "tokens": [50636, 291, 458, 11, 48224, 399, 13, 865, 13, 407, 577, 360, 291, 1565, 37765, 666, 341, 30, 1436, 264, 551, 50988], "temperature": 0.0, "avg_logprob": -0.10430283589406056, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.006775062531232834}, {"id": 2225, "seek": 679912, "start": 6811.599999999999, "end": 6816.8, "text": " that I always get caught on is that the traditional go fi vision was to, you know, handcraft the", "tokens": [50988, 300, 286, 1009, 483, 5415, 322, 307, 300, 264, 5164, 352, 15848, 5201, 390, 281, 11, 291, 458, 11, 1011, 5611, 264, 51248], "temperature": 0.0, "avg_logprob": -0.10430283589406056, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.006775062531232834}, {"id": 2226, "seek": 679912, "start": 6816.8, "end": 6821.5199999999995, "text": " knowledge. And actually, what we need is dynamic knowledge acquisition. And we need the ability", "tokens": [51248, 3601, 13, 400, 767, 11, 437, 321, 643, 307, 8546, 3601, 21668, 13, 400, 321, 643, 264, 3485, 51484], "temperature": 0.0, "avg_logprob": -0.10430283589406056, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.006775062531232834}, {"id": 2227, "seek": 679912, "start": 6821.5199999999995, "end": 6826.16, "text": " to create abstractions on the fly rather than just what we do now, which is crystallizing", "tokens": [51484, 281, 1884, 12649, 626, 322, 264, 3603, 2831, 813, 445, 437, 321, 360, 586, 11, 597, 307, 31924, 3319, 51716], "temperature": 0.0, "avg_logprob": -0.10430283589406056, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.006775062531232834}, {"id": 2228, "seek": 682616, "start": 6826.24, "end": 6831.12, "text": " existing human abstraction. How could we do that bit? Well, abstraction traditionally was and", "tokens": [50368, 6741, 1952, 37765, 13, 1012, 727, 321, 360, 300, 857, 30, 1042, 11, 37765, 19067, 390, 293, 50612], "temperature": 0.0, "avg_logprob": -0.10955005884170532, "compression_ratio": 1.7295373665480427, "no_speech_prob": 0.013416977599263191}, {"id": 2229, "seek": 682616, "start": 6831.12, "end": 6837.84, "text": " still is a central topic in symbolic AI, right? Like be precise. I mean, I think nobody questions", "tokens": [50612, 920, 307, 257, 5777, 4829, 294, 25755, 7318, 11, 558, 30, 1743, 312, 13600, 13, 286, 914, 11, 286, 519, 5079, 1651, 50948], "temperature": 0.0, "avg_logprob": -0.10955005884170532, "compression_ratio": 1.7295373665480427, "no_speech_prob": 0.013416977599263191}, {"id": 2230, "seek": 682616, "start": 6837.84, "end": 6842.8, "text": " that having levels of abstraction, someone is very important. The only question is how. So if you", "tokens": [50948, 300, 1419, 4358, 295, 37765, 11, 1580, 307, 588, 1021, 13, 440, 787, 1168, 307, 577, 13, 407, 498, 291, 51196], "temperature": 0.0, "avg_logprob": -0.10955005884170532, "compression_ratio": 1.7295373665480427, "no_speech_prob": 0.013416977599263191}, {"id": 2231, "seek": 682616, "start": 6842.8, "end": 6848.08, "text": " look at classic knowledge representation, planning, et cetera, et cetera, abstraction is all over", "tokens": [51196, 574, 412, 7230, 3601, 10290, 11, 5038, 11, 1030, 11458, 11, 1030, 11458, 11, 37765, 307, 439, 670, 51460], "temperature": 0.0, "avg_logprob": -0.10955005884170532, "compression_ratio": 1.7295373665480427, "no_speech_prob": 0.013416977599263191}, {"id": 2232, "seek": 682616, "start": 6848.08, "end": 6852.639999999999, "text": " the place. If you look at things like reinforcement learning, and I mean, even like, you know, the", "tokens": [51460, 264, 1081, 13, 759, 291, 574, 412, 721, 411, 29280, 2539, 11, 293, 286, 914, 11, 754, 411, 11, 291, 458, 11, 264, 51688], "temperature": 0.0, "avg_logprob": -0.10955005884170532, "compression_ratio": 1.7295373665480427, "no_speech_prob": 0.013416977599263191}, {"id": 2233, "seek": 685264, "start": 6852.64, "end": 6857.92, "text": " whole idea or hope of a convent is that it captures objects at multiple levels of abstraction,", "tokens": [50364, 1379, 1558, 420, 1454, 295, 257, 416, 2475, 307, 300, 309, 27986, 6565, 412, 3866, 4358, 295, 37765, 11, 50628], "temperature": 0.0, "avg_logprob": -0.15651377420576792, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0018339816015213728}, {"id": 2234, "seek": 685264, "start": 6857.92, "end": 6862.320000000001, "text": " at least to some degree. In reality, it doesn't, right? But that's what people are trying to do", "tokens": [50628, 412, 1935, 281, 512, 4314, 13, 682, 4103, 11, 309, 1177, 380, 11, 558, 30, 583, 300, 311, 437, 561, 366, 1382, 281, 360, 50848], "temperature": 0.0, "avg_logprob": -0.15651377420576792, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0018339816015213728}, {"id": 2235, "seek": 685264, "start": 6862.320000000001, "end": 6867.4400000000005, "text": " and not quite doing, right? Well, good. Let's touch on that then. So I mean, certainly in", "tokens": [50848, 293, 406, 1596, 884, 11, 558, 30, 1042, 11, 665, 13, 961, 311, 2557, 322, 300, 550, 13, 407, 286, 914, 11, 3297, 294, 51104], "temperature": 0.0, "avg_logprob": -0.15651377420576792, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0018339816015213728}, {"id": 2236, "seek": 685264, "start": 6867.4400000000005, "end": 6872.56, "text": " Jan McCoon's view, I spoke with Jan the other day, he's got this autonomous path, a paper. And,", "tokens": [51104, 4956, 12061, 4106, 311, 1910, 11, 286, 7179, 365, 4956, 264, 661, 786, 11, 415, 311, 658, 341, 23797, 3100, 11, 257, 3035, 13, 400, 11, 51360], "temperature": 0.0, "avg_logprob": -0.15651377420576792, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0018339816015213728}, {"id": 2237, "seek": 685264, "start": 6873.4400000000005, "end": 6877.12, "text": " you know, his system is learning abstractions, but they're abstractions which are deducible from", "tokens": [51404, 291, 458, 11, 702, 1185, 307, 2539, 12649, 626, 11, 457, 436, 434, 12649, 626, 597, 366, 4172, 84, 32128, 490, 51588], "temperature": 0.0, "avg_logprob": -0.15651377420576792, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0018339816015213728}, {"id": 2238, "seek": 687712, "start": 6877.12, "end": 6882.64, "text": " base abstraction priors, like objectness and, you know, basic visual priors. And so there's this", "tokens": [50364, 3096, 37765, 1790, 830, 11, 411, 2657, 1287, 293, 11, 291, 458, 11, 3875, 5056, 1790, 830, 13, 400, 370, 456, 311, 341, 50640], "temperature": 0.0, "avg_logprob": -0.07945787111918132, "compression_ratio": 1.8438661710037174, "no_speech_prob": 0.009548073634505272}, {"id": 2239, "seek": 687712, "start": 6882.64, "end": 6887.28, "text": " assumption that everything is deducible from the priors that we put into the model. But I have this", "tokens": [50640, 15302, 300, 1203, 307, 4172, 84, 32128, 490, 264, 1790, 830, 300, 321, 829, 666, 264, 2316, 13, 583, 286, 362, 341, 50872], "temperature": 0.0, "avg_logprob": -0.07945787111918132, "compression_ratio": 1.8438661710037174, "no_speech_prob": 0.009548073634505272}, {"id": 2240, "seek": 687712, "start": 6887.28, "end": 6893.36, "text": " kind of intuition that abstraction space is much larger than that. Yeah. I mean, so I would even", "tokens": [50872, 733, 295, 24002, 300, 37765, 1901, 307, 709, 4833, 813, 300, 13, 865, 13, 286, 914, 11, 370, 286, 576, 754, 51176], "temperature": 0.0, "avg_logprob": -0.07945787111918132, "compression_ratio": 1.8438661710037174, "no_speech_prob": 0.009548073634505272}, {"id": 2241, "seek": 687712, "start": 6893.36, "end": 6898.96, "text": " say that if you arrive at your abstractions solely by deduction, you have a very impoverished notion", "tokens": [51176, 584, 300, 498, 291, 8881, 412, 428, 12649, 626, 23309, 538, 46385, 11, 291, 362, 257, 588, 704, 3570, 4729, 10710, 51456], "temperature": 0.0, "avg_logprob": -0.07945787111918132, "compression_ratio": 1.8438661710037174, "no_speech_prob": 0.009548073634505272}, {"id": 2242, "seek": 687712, "start": 6898.96, "end": 6905.12, "text": " of abstraction. In fact, most of inductive learning is forming abstractions. And form abstractions at", "tokens": [51456, 295, 37765, 13, 682, 1186, 11, 881, 295, 31612, 488, 2539, 307, 15745, 12649, 626, 13, 400, 1254, 12649, 626, 412, 51764], "temperature": 0.0, "avg_logprob": -0.07945787111918132, "compression_ratio": 1.8438661710037174, "no_speech_prob": 0.009548073634505272}, {"id": 2243, "seek": 690512, "start": 6905.12, "end": 6909.5199999999995, "text": " the most basic level is something very trivial. It's like, I have an example described by a thousand", "tokens": [50364, 264, 881, 3875, 1496, 307, 746, 588, 26703, 13, 467, 311, 411, 11, 286, 362, 364, 1365, 7619, 538, 257, 4714, 50584], "temperature": 0.0, "avg_logprob": -0.1359462411994608, "compression_ratio": 1.6372881355932203, "no_speech_prob": 0.011480143293738365}, {"id": 2244, "seek": 690512, "start": 6909.5199999999995, "end": 6915.5199999999995, "text": " attributes. If from that I induce a rule that uses only 10, I've abstracted the way the other 990,", "tokens": [50584, 17212, 13, 759, 490, 300, 286, 41263, 257, 4978, 300, 4960, 787, 1266, 11, 286, 600, 12649, 292, 264, 636, 264, 661, 1722, 7771, 11, 50884], "temperature": 0.0, "avg_logprob": -0.1359462411994608, "compression_ratio": 1.6372881355932203, "no_speech_prob": 0.011480143293738365}, {"id": 2245, "seek": 690512, "start": 6916.24, "end": 6921.36, "text": " right? But if a symbolist was here, they would talk about intention versus extension, and they", "tokens": [50920, 558, 30, 583, 498, 257, 5986, 468, 390, 510, 11, 436, 576, 751, 466, 7789, 5717, 10320, 11, 293, 436, 51176], "temperature": 0.0, "avg_logprob": -0.1359462411994608, "compression_ratio": 1.6372881355932203, "no_speech_prob": 0.011480143293738365}, {"id": 2246, "seek": 690512, "start": 6921.36, "end": 6924.64, "text": " would say that, you know, you're selecting from this infinite set of possible attributes. You", "tokens": [51176, 576, 584, 300, 11, 291, 458, 11, 291, 434, 18182, 490, 341, 13785, 992, 295, 1944, 17212, 13, 509, 51340], "temperature": 0.0, "avg_logprob": -0.1359462411994608, "compression_ratio": 1.6372881355932203, "no_speech_prob": 0.011480143293738365}, {"id": 2247, "seek": 690512, "start": 6924.64, "end": 6928.4, "text": " couldn't possibly represent all of the attributes in this. I mean, just to give you a concrete", "tokens": [51340, 2809, 380, 6264, 2906, 439, 295, 264, 17212, 294, 341, 13, 286, 914, 11, 445, 281, 976, 291, 257, 9859, 51528], "temperature": 0.0, "avg_logprob": -0.1359462411994608, "compression_ratio": 1.6372881355932203, "no_speech_prob": 0.011480143293738365}, {"id": 2248, "seek": 692840, "start": 6928.4, "end": 6934.0, "text": " example, you know, you could have a, a, a, a, a, a, a, you know what I mean? You can have like this.", "tokens": [50364, 1365, 11, 291, 458, 11, 291, 727, 362, 257, 11, 257, 11, 257, 11, 257, 11, 257, 11, 257, 11, 257, 11, 291, 458, 437, 286, 914, 30, 509, 393, 362, 411, 341, 13, 50644], "temperature": 0.0, "avg_logprob": -0.16922855377197266, "compression_ratio": 1.80859375, "no_speech_prob": 0.14561307430267334}, {"id": 2249, "seek": 692840, "start": 6934.0, "end": 6939.12, "text": " Again, I hate to bring up infinity again, because that's always what these folks bring up. But", "tokens": [50644, 3764, 11, 286, 4700, 281, 1565, 493, 13202, 797, 11, 570, 300, 311, 1009, 437, 613, 4024, 1565, 493, 13, 583, 50900], "temperature": 0.0, "avg_logprob": -0.16922855377197266, "compression_ratio": 1.80859375, "no_speech_prob": 0.14561307430267334}, {"id": 2250, "seek": 692840, "start": 6939.12, "end": 6944.24, "text": " how could you select from a set that large? Well, I don't need to because it is finite.", "tokens": [50900, 577, 727, 291, 3048, 490, 257, 992, 300, 2416, 30, 1042, 11, 286, 500, 380, 643, 281, 570, 309, 307, 19362, 13, 51156], "temperature": 0.0, "avg_logprob": -0.16922855377197266, "compression_ratio": 1.80859375, "no_speech_prob": 0.14561307430267334}, {"id": 2251, "seek": 692840, "start": 6944.24, "end": 6948.4, "text": " But what I need to do is so, so, but there is actually a good example. And, you know,", "tokens": [51156, 583, 437, 286, 643, 281, 360, 307, 370, 11, 370, 11, 457, 456, 307, 767, 257, 665, 1365, 13, 400, 11, 291, 458, 11, 51364], "temperature": 0.0, "avg_logprob": -0.16922855377197266, "compression_ratio": 1.80859375, "no_speech_prob": 0.14561307430267334}, {"id": 2252, "seek": 692840, "start": 6948.4, "end": 6954.08, "text": " infinity does not bother us at all, at all there, because what it's like, if my training set,", "tokens": [51364, 13202, 775, 406, 8677, 505, 412, 439, 11, 412, 439, 456, 11, 570, 437, 309, 311, 411, 11, 498, 452, 3097, 992, 11, 51648], "temperature": 0.0, "avg_logprob": -0.16922855377197266, "compression_ratio": 1.80859375, "no_speech_prob": 0.14561307430267334}, {"id": 2253, "seek": 695408, "start": 6954.08, "end": 6959.28, "text": " right, is a set of strings, and those strings are a, a, a, a, a, a, a, right? Going up to", "tokens": [50364, 558, 11, 307, 257, 992, 295, 13985, 11, 293, 729, 13985, 366, 257, 11, 257, 11, 257, 11, 257, 11, 257, 11, 257, 11, 257, 11, 558, 30, 10963, 493, 281, 50624], "temperature": 0.0, "avg_logprob": -0.10720041470649914, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.053338970988988876}, {"id": 2254, "seek": 695408, "start": 6959.28, "end": 6962.72, "text": " whatever number you want to pick, like, you know, a million or a quid drill in, you know,", "tokens": [50624, 2035, 1230, 291, 528, 281, 1888, 11, 411, 11, 291, 458, 11, 257, 2459, 420, 257, 421, 327, 11392, 294, 11, 291, 458, 11, 50796], "temperature": 0.0, "avg_logprob": -0.10720041470649914, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.053338970988988876}, {"id": 2255, "seek": 695408, "start": 6962.72, "end": 6968.48, "text": " or a Google, right? Then R is your learning algorithm able to induce that the, the language", "tokens": [50796, 420, 257, 3329, 11, 558, 30, 1396, 497, 307, 428, 2539, 9284, 1075, 281, 41263, 300, 264, 11, 264, 2856, 51084], "temperature": 0.0, "avg_logprob": -0.10720041470649914, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.053338970988988876}, {"id": 2256, "seek": 695408, "start": 6968.48, "end": 6972.96, "text": " that these rules come out of, right? The grammar is, you know, it's a series of A's, right? You", "tokens": [51084, 300, 613, 4474, 808, 484, 295, 11, 558, 30, 440, 22317, 307, 11, 291, 458, 11, 309, 311, 257, 2638, 295, 316, 311, 11, 558, 30, 509, 51308], "temperature": 0.0, "avg_logprob": -0.10720041470649914, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.053338970988988876}, {"id": 2257, "seek": 695408, "start": 6972.96, "end": 6977.6, "text": " and I can do that immediately. You know, most deep networks have no end of trouble doing that,", "tokens": [51308, 293, 286, 393, 360, 300, 4258, 13, 509, 458, 11, 881, 2452, 9590, 362, 572, 917, 295, 5253, 884, 300, 11, 51540], "temperature": 0.0, "avg_logprob": -0.10720041470649914, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.053338970988988876}, {"id": 2258, "seek": 695408, "start": 6977.6, "end": 6982.08, "text": " even though it's that basic. So it is a very good example of what symbolic learning and", "tokens": [51540, 754, 1673, 309, 311, 300, 3875, 13, 407, 309, 307, 257, 588, 665, 1365, 295, 437, 25755, 2539, 293, 51764], "temperature": 0.0, "avg_logprob": -0.10720041470649914, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.053338970988988876}, {"id": 2259, "seek": 698208, "start": 6982.08, "end": 6986.0, "text": " reasoning can do versus connection is you don't need to go anywhere near infinity to actually", "tokens": [50364, 21577, 393, 360, 5717, 4984, 307, 291, 500, 380, 643, 281, 352, 4992, 2651, 13202, 281, 767, 50560], "temperature": 0.0, "avg_logprob": -0.10462613657218259, "compression_ratio": 1.7002967359050445, "no_speech_prob": 0.04453825578093529}, {"id": 2260, "seek": 698208, "start": 6986.0, "end": 6990.24, "text": " have that be a very elegant example. Well, let me bring up just one other, we've touched on a", "tokens": [50560, 362, 300, 312, 257, 588, 21117, 1365, 13, 1042, 11, 718, 385, 1565, 493, 445, 472, 661, 11, 321, 600, 9828, 322, 257, 50772], "temperature": 0.0, "avg_logprob": -0.10462613657218259, "compression_ratio": 1.7002967359050445, "no_speech_prob": 0.04453825578093529}, {"id": 2261, "seek": 698208, "start": 6990.24, "end": 6994.0, "text": " lot of great things, right? There's one in this space of things that we've been talking about,", "tokens": [50772, 688, 295, 869, 721, 11, 558, 30, 821, 311, 472, 294, 341, 1901, 295, 721, 300, 321, 600, 668, 1417, 466, 11, 50960], "temperature": 0.0, "avg_logprob": -0.10462613657218259, "compression_ratio": 1.7002967359050445, "no_speech_prob": 0.04453825578093529}, {"id": 2262, "seek": 698208, "start": 6994.0, "end": 6998.64, "text": " there's one that I think is very important, which I believe you're also a fan of. And I very much", "tokens": [50960, 456, 311, 472, 300, 286, 519, 307, 588, 1021, 11, 597, 286, 1697, 291, 434, 611, 257, 3429, 295, 13, 400, 286, 588, 709, 51192], "temperature": 0.0, "avg_logprob": -0.10462613657218259, "compression_ratio": 1.7002967359050445, "no_speech_prob": 0.04453825578093529}, {"id": 2263, "seek": 698208, "start": 6998.64, "end": 7002.4, "text": " am. And I think it's going to, you know, maybe you're going back to the question of what I'm", "tokens": [51192, 669, 13, 400, 286, 519, 309, 311, 516, 281, 11, 291, 458, 11, 1310, 291, 434, 516, 646, 281, 264, 1168, 295, 437, 286, 478, 51380], "temperature": 0.0, "avg_logprob": -0.10462613657218259, "compression_ratio": 1.7002967359050445, "no_speech_prob": 0.04453825578093529}, {"id": 2264, "seek": 698208, "start": 7002.4, "end": 7007.04, "text": " interested in that's happening at, at new reps right now or not. So new symbolic AI is definitely a", "tokens": [51380, 3102, 294, 300, 311, 2737, 412, 11, 412, 777, 27007, 558, 586, 420, 406, 13, 407, 777, 25755, 7318, 307, 2138, 257, 51612], "temperature": 0.0, "avg_logprob": -0.10462613657218259, "compression_ratio": 1.7002967359050445, "no_speech_prob": 0.04453825578093529}, {"id": 2265, "seek": 700704, "start": 7007.04, "end": 7013.28, "text": " big one. Another big one. And to my mind, maybe these are the two biggest ones are most interesting", "tokens": [50364, 955, 472, 13, 3996, 955, 472, 13, 400, 281, 452, 1575, 11, 1310, 613, 366, 264, 732, 3880, 2306, 366, 881, 1880, 50676], "temperature": 0.0, "avg_logprob": -0.12205736861269698, "compression_ratio": 1.8658536585365855, "no_speech_prob": 0.05899841710925102}, {"id": 2266, "seek": 700704, "start": 7013.28, "end": 7019.04, "text": " is, is what I call symmetry based learning. And these days is more popular known by the,", "tokens": [50676, 307, 11, 307, 437, 286, 818, 25440, 2361, 2539, 13, 400, 613, 1708, 307, 544, 3743, 2570, 538, 264, 11, 50964], "temperature": 0.0, "avg_logprob": -0.12205736861269698, "compression_ratio": 1.8658536585365855, "no_speech_prob": 0.05899841710925102}, {"id": 2267, "seek": 700704, "start": 7019.04, "end": 7022.88, "text": " by the, by the name of like geometric deep learning and things like that. I tend to view", "tokens": [50964, 538, 264, 11, 538, 264, 1315, 295, 411, 33246, 2452, 2539, 293, 721, 411, 300, 13, 286, 3928, 281, 1910, 51156], "temperature": 0.0, "avg_logprob": -0.12205736861269698, "compression_ratio": 1.8658536585365855, "no_speech_prob": 0.05899841710925102}, {"id": 2268, "seek": 700704, "start": 7022.88, "end": 7027.68, "text": " geometric deep learning as a special case of symmetry based learning. But this idea of,", "tokens": [51156, 33246, 2452, 2539, 382, 257, 2121, 1389, 295, 25440, 2361, 2539, 13, 583, 341, 1558, 295, 11, 51396], "temperature": 0.0, "avg_logprob": -0.12205736861269698, "compression_ratio": 1.8658536585365855, "no_speech_prob": 0.05899841710925102}, {"id": 2269, "seek": 700704, "start": 7028.72, "end": 7034.0, "text": " I think, let me, you know, to go straight to the punchline, we know that, for example, AI and", "tokens": [51448, 286, 519, 11, 718, 385, 11, 291, 458, 11, 281, 352, 2997, 281, 264, 8135, 1889, 11, 321, 458, 300, 11, 337, 1365, 11, 7318, 293, 51712], "temperature": 0.0, "avg_logprob": -0.12205736861269698, "compression_ratio": 1.8658536585365855, "no_speech_prob": 0.05899841710925102}, {"id": 2270, "seek": 703400, "start": 7034.32, "end": 7038.96, "text": " machine learning in particular, have as foundations, things like, you know, logic,", "tokens": [50380, 3479, 2539, 294, 1729, 11, 362, 382, 22467, 11, 721, 411, 11, 291, 458, 11, 9952, 11, 50612], "temperature": 0.0, "avg_logprob": -0.16027594613028573, "compression_ratio": 1.7571884984025559, "no_speech_prob": 0.007431142032146454}, {"id": 2271, "seek": 703400, "start": 7038.96, "end": 7044.0, "text": " probability optimization. And I think another foundation is symmetry group theory. In fact,", "tokens": [50612, 8482, 19618, 13, 400, 286, 519, 1071, 7030, 307, 25440, 1594, 5261, 13, 682, 1186, 11, 50864], "temperature": 0.0, "avg_logprob": -0.16027594613028573, "compression_ratio": 1.7571884984025559, "no_speech_prob": 0.007431142032146454}, {"id": 2272, "seek": 703400, "start": 7044.0, "end": 7048.08, "text": " I was having, you know, dinner with, with Max Welling just the other day, who, who, of course,", "tokens": [50864, 286, 390, 1419, 11, 291, 458, 11, 6148, 365, 11, 365, 7402, 1042, 278, 445, 264, 661, 786, 11, 567, 11, 567, 11, 295, 1164, 11, 51068], "temperature": 0.0, "avg_logprob": -0.16027594613028573, "compression_ratio": 1.7571884984025559, "no_speech_prob": 0.007431142032146454}, {"id": 2273, "seek": 703400, "start": 7048.08, "end": 7052.32, "text": " have also interviewed and is, you know, like a great, you know, person in this area. And we,", "tokens": [51068, 362, 611, 19770, 293, 307, 11, 291, 458, 11, 411, 257, 869, 11, 291, 458, 11, 954, 294, 341, 1859, 13, 400, 321, 11, 51280], "temperature": 0.0, "avg_logprob": -0.16027594613028573, "compression_ratio": 1.7571884984025559, "no_speech_prob": 0.007431142032146454}, {"id": 2274, "seek": 703400, "start": 7052.32, "end": 7057.28, "text": " you know, I think we have very similar views on this. Well, Pedro, yesterday, and Taka Kohen", "tokens": [51280, 291, 458, 11, 286, 519, 321, 362, 588, 2531, 6809, 322, 341, 13, 1042, 11, 26662, 11, 5186, 11, 293, 314, 7849, 30861, 268, 51528], "temperature": 0.0, "avg_logprob": -0.16027594613028573, "compression_ratio": 1.7571884984025559, "no_speech_prob": 0.007431142032146454}, {"id": 2275, "seek": 703400, "start": 7057.28, "end": 7061.76, "text": " was sitting where you were sitting. So there you go. Yeah. Again, I remember talking with Taka", "tokens": [51528, 390, 3798, 689, 291, 645, 3798, 13, 407, 456, 291, 352, 13, 865, 13, 3764, 11, 286, 1604, 1417, 365, 314, 7849, 51752], "temperature": 0.0, "avg_logprob": -0.16027594613028573, "compression_ratio": 1.7571884984025559, "no_speech_prob": 0.007431142032146454}, {"id": 2276, "seek": 706176, "start": 7062.0, "end": 7065.52, "text": " Kohen, some ICML many years ago, where he published one of the first papers on this.", "tokens": [50376, 30861, 268, 11, 512, 14360, 12683, 867, 924, 2057, 11, 689, 415, 6572, 472, 295, 264, 700, 10577, 322, 341, 13, 50552], "temperature": 0.0, "avg_logprob": -0.1158449286656664, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.07785700261592865}, {"id": 2277, "seek": 706176, "start": 7065.52, "end": 7071.04, "text": " And I was like, and he seemed a little disheartened by the lack of interest that people had. And I", "tokens": [50552, 400, 286, 390, 411, 11, 293, 415, 6576, 257, 707, 717, 12864, 5320, 538, 264, 5011, 295, 1179, 300, 561, 632, 13, 400, 286, 50828], "temperature": 0.0, "avg_logprob": -0.1158449286656664, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.07785700261592865}, {"id": 2278, "seek": 706176, "start": 7071.04, "end": 7075.4400000000005, "text": " said to him, just wait, this is going to be big and we're there now, right? And it's going to be", "tokens": [50828, 848, 281, 796, 11, 445, 1699, 11, 341, 307, 516, 281, 312, 955, 293, 321, 434, 456, 586, 11, 558, 30, 400, 309, 311, 516, 281, 312, 51048], "temperature": 0.0, "avg_logprob": -0.1158449286656664, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.07785700261592865}, {"id": 2279, "seek": 706176, "start": 7075.4400000000005, "end": 7079.52, "text": " even bigger, I think. But also, I think to become bigger and again, to jump straight to the punch", "tokens": [51048, 754, 3801, 11, 286, 519, 13, 583, 611, 11, 286, 519, 281, 1813, 3801, 293, 797, 11, 281, 3012, 2997, 281, 264, 8135, 51252], "temperature": 0.0, "avg_logprob": -0.1158449286656664, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.07785700261592865}, {"id": 2280, "seek": 706176, "start": 7079.52, "end": 7085.360000000001, "text": " line, most of the work, including me, that people have done to date has been exploiting known", "tokens": [51252, 1622, 11, 881, 295, 264, 589, 11, 3009, 385, 11, 300, 561, 362, 1096, 281, 4002, 575, 668, 12382, 1748, 2570, 51544], "temperature": 0.0, "avg_logprob": -0.1158449286656664, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.07785700261592865}, {"id": 2281, "seek": 706176, "start": 7085.360000000001, "end": 7089.4400000000005, "text": " symmetries, like, you know, translation invariance is the quintessential example. For example,", "tokens": [51544, 14232, 302, 2244, 11, 411, 11, 291, 458, 11, 12853, 33270, 719, 307, 264, 40006, 48143, 1365, 13, 1171, 1365, 11, 51748], "temperature": 0.0, "avg_logprob": -0.1158449286656664, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.07785700261592865}, {"id": 2282, "seek": 708944, "start": 7089.44, "end": 7093.839999999999, "text": " we have something called deep affine networks that generalize coordinates to, you know,", "tokens": [50364, 321, 362, 746, 1219, 2452, 2096, 533, 9590, 300, 2674, 1125, 21056, 281, 11, 291, 458, 11, 50584], "temperature": 0.0, "avg_logprob": -0.1648151754475326, "compression_ratio": 1.7266881028938907, "no_speech_prob": 0.2645276188850403}, {"id": 2283, "seek": 708944, "start": 7093.839999999999, "end": 7098.4, "text": " rotation, you know, scaling, et cetera, et cetera. This is all well and good. But I think", "tokens": [50584, 12447, 11, 291, 458, 11, 21589, 11, 1030, 11458, 11, 1030, 11458, 13, 639, 307, 439, 731, 293, 665, 13, 583, 286, 519, 50812], "temperature": 0.0, "avg_logprob": -0.1648151754475326, "compression_ratio": 1.7266881028938907, "no_speech_prob": 0.2645276188850403}, {"id": 2284, "seek": 708944, "start": 7098.4, "end": 7103.44, "text": " if this is, and if you look at New York's today, for example, most is in that vein.", "tokens": [50812, 498, 341, 307, 11, 293, 498, 291, 574, 412, 1873, 3609, 311, 965, 11, 337, 1365, 11, 881, 307, 294, 300, 30669, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1648151754475326, "compression_ratio": 1.7266881028938907, "no_speech_prob": 0.2645276188850403}, {"id": 2285, "seek": 708944, "start": 7103.44, "end": 7107.12, "text": " And there's a lot of good work to be done there. But if that's all we ever do, we will always", "tokens": [51064, 400, 456, 311, 257, 688, 295, 665, 589, 281, 312, 1096, 456, 13, 583, 498, 300, 311, 439, 321, 1562, 360, 11, 321, 486, 1009, 51248], "temperature": 0.0, "avg_logprob": -0.1648151754475326, "compression_ratio": 1.7266881028938907, "no_speech_prob": 0.2645276188850403}, {"id": 2286, "seek": 708944, "start": 7107.12, "end": 7112.0, "text": " remain a niche in AI with certain very good applications, like science applications,", "tokens": [51248, 6222, 257, 19956, 294, 7318, 365, 1629, 588, 665, 5821, 11, 411, 3497, 5821, 11, 51492], "temperature": 0.0, "avg_logprob": -0.1648151754475326, "compression_ratio": 1.7266881028938907, "no_speech_prob": 0.2645276188850403}, {"id": 2287, "seek": 708944, "start": 7112.0, "end": 7116.24, "text": " where we know that certain symmetries hold and whatnot. Max and Taka are doing things like that.", "tokens": [51492, 689, 321, 458, 300, 1629, 14232, 302, 2244, 1797, 293, 25882, 13, 7402, 293, 314, 7849, 366, 884, 721, 411, 300, 13, 51704], "temperature": 0.0, "avg_logprob": -0.1648151754475326, "compression_ratio": 1.7266881028938907, "no_speech_prob": 0.2645276188850403}, {"id": 2288, "seek": 711624, "start": 7116.24, "end": 7119.679999999999, "text": " But I don't want to just do that. I really, you know, I'm trying to make progress towards", "tokens": [50364, 583, 286, 500, 380, 528, 281, 445, 360, 300, 13, 286, 534, 11, 291, 458, 11, 286, 478, 1382, 281, 652, 4205, 3030, 50536], "temperature": 0.0, "avg_logprob": -0.07012706833916742, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.004750282969325781}, {"id": 2289, "seek": 711624, "start": 7119.679999999999, "end": 7124.0, "text": " human level AI. And I think the key there is to discover symmetries from data.", "tokens": [50536, 1952, 1496, 7318, 13, 400, 286, 519, 264, 2141, 456, 307, 281, 4411, 14232, 302, 2244, 490, 1412, 13, 50752], "temperature": 0.0, "avg_logprob": -0.07012706833916742, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.004750282969325781}, {"id": 2290, "seek": 711624, "start": 7124.5599999999995, "end": 7129.04, "text": " Yeah. And I think most of us agree with this. It's a hard problem, right? But that's what we're", "tokens": [50780, 865, 13, 400, 286, 519, 881, 295, 505, 3986, 365, 341, 13, 467, 311, 257, 1152, 1154, 11, 558, 30, 583, 300, 311, 437, 321, 434, 51004], "temperature": 0.0, "avg_logprob": -0.07012706833916742, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.004750282969325781}, {"id": 2291, "seek": 711624, "start": 7129.04, "end": 7134.0, "text": " here for. We want to discover symmetries from data. And, you know, there's an interesting,", "tokens": [51004, 510, 337, 13, 492, 528, 281, 4411, 14232, 302, 2244, 490, 1412, 13, 400, 11, 291, 458, 11, 456, 311, 364, 1880, 11, 51252], "temperature": 0.0, "avg_logprob": -0.07012706833916742, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.004750282969325781}, {"id": 2292, "seek": 711624, "start": 7134.0, "end": 7137.5199999999995, "text": " you know, discussion of how to do that, you know, I have a number of ideas and a number of people", "tokens": [51252, 291, 458, 11, 5017, 295, 577, 281, 360, 300, 11, 291, 458, 11, 286, 362, 257, 1230, 295, 3487, 293, 257, 1230, 295, 561, 51428], "temperature": 0.0, "avg_logprob": -0.07012706833916742, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.004750282969325781}, {"id": 2293, "seek": 711624, "start": 7137.5199999999995, "end": 7142.16, "text": " have, then the power of discovering symmetries, right, connecting back to our early conversation", "tokens": [51428, 362, 11, 550, 264, 1347, 295, 24773, 14232, 302, 2244, 11, 558, 11, 11015, 646, 281, 527, 2440, 3761, 51660], "temperature": 0.0, "avg_logprob": -0.07012706833916742, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.004750282969325781}, {"id": 2294, "seek": 714216, "start": 7142.16, "end": 7147.2, "text": " is that symmetries can, individual symmetries can be very easy to discover because they're", "tokens": [50364, 307, 300, 14232, 302, 2244, 393, 11, 2609, 14232, 302, 2244, 393, 312, 588, 1858, 281, 4411, 570, 436, 434, 50616], "temperature": 0.0, "avg_logprob": -0.08696475199290685, "compression_ratio": 1.804, "no_speech_prob": 0.04192487150430679}, {"id": 2295, "seek": 714216, "start": 7147.2, "end": 7152.88, "text": " often very simple. But then, right, by the group axioms, axioms, you can compose them arbitrarily.", "tokens": [50616, 2049, 588, 2199, 13, 583, 550, 11, 558, 11, 538, 264, 1594, 6360, 72, 4785, 11, 6360, 72, 4785, 11, 291, 393, 35925, 552, 19071, 3289, 13, 50900], "temperature": 0.0, "avg_logprob": -0.08696475199290685, "compression_ratio": 1.804, "no_speech_prob": 0.04192487150430679}, {"id": 2296, "seek": 714216, "start": 7152.88, "end": 7157.84, "text": " Yeah. Which means I can, for example, by learning 100 different symmetries of a cat", "tokens": [50900, 865, 13, 3013, 1355, 286, 393, 11, 337, 1365, 11, 538, 2539, 2319, 819, 14232, 302, 2244, 295, 257, 3857, 51148], "temperature": 0.0, "avg_logprob": -0.08696475199290685, "compression_ratio": 1.804, "no_speech_prob": 0.04192487150430679}, {"id": 2297, "seek": 714216, "start": 7157.84, "end": 7162.639999999999, "text": " from 100 different examples, then I can compose them and correctly recognize as a cat", "tokens": [51148, 490, 2319, 819, 5110, 11, 550, 286, 393, 35925, 552, 293, 8944, 5521, 382, 257, 3857, 51388], "temperature": 0.0, "avg_logprob": -0.08696475199290685, "compression_ratio": 1.804, "no_speech_prob": 0.04192487150430679}, {"id": 2298, "seek": 714216, "start": 7163.44, "end": 7168.0, "text": " something that is extremely different from any concrete example of a cat that I saw before.", "tokens": [51428, 746, 300, 307, 4664, 819, 490, 604, 9859, 1365, 295, 257, 3857, 300, 286, 1866, 949, 13, 51656], "temperature": 0.0, "avg_logprob": -0.08696475199290685, "compression_ratio": 1.804, "no_speech_prob": 0.04192487150430679}, {"id": 2299, "seek": 716800, "start": 7168.96, "end": 7172.48, "text": " Could I push back on a tiny bit? So, I mean, in the geometric deep learning prototype book,", "tokens": [50412, 7497, 286, 2944, 646, 322, 257, 5870, 857, 30, 407, 11, 286, 914, 11, 294, 264, 33246, 2452, 2539, 19475, 1446, 11, 50588], "temperature": 0.0, "avg_logprob": -0.15222155794184258, "compression_ratio": 1.7088607594936709, "no_speech_prob": 0.00627692649140954}, {"id": 2300, "seek": 716800, "start": 7172.48, "end": 7177.2, "text": " I mean, they spoke about, you know, the various symmetries of groups like SO3, you know, preserves", "tokens": [50588, 286, 914, 11, 436, 7179, 466, 11, 291, 458, 11, 264, 3683, 14232, 302, 2244, 295, 3935, 411, 10621, 18, 11, 291, 458, 11, 1183, 9054, 50824], "temperature": 0.0, "avg_logprob": -0.15222155794184258, "compression_ratio": 1.7088607594936709, "no_speech_prob": 0.00627692649140954}, {"id": 2301, "seek": 716800, "start": 7177.2, "end": 7182.96, "text": " translations and angles, you know, like how primitive and how platonic are these symmetries?", "tokens": [50824, 37578, 293, 14708, 11, 291, 458, 11, 411, 577, 28540, 293, 577, 3403, 11630, 366, 613, 14232, 302, 2244, 30, 51112], "temperature": 0.0, "avg_logprob": -0.15222155794184258, "compression_ratio": 1.7088607594936709, "no_speech_prob": 0.00627692649140954}, {"id": 2302, "seek": 716800, "start": 7182.96, "end": 7186.64, "text": " And aren't they just like obvious in respect of the domain that you're in?", "tokens": [51112, 400, 3212, 380, 436, 445, 411, 6322, 294, 3104, 295, 264, 9274, 300, 291, 434, 294, 30, 51296], "temperature": 0.0, "avg_logprob": -0.15222155794184258, "compression_ratio": 1.7088607594936709, "no_speech_prob": 0.00627692649140954}, {"id": 2303, "seek": 716800, "start": 7186.64, "end": 7191.68, "text": " No, very good. So this is actually a key question. Symmetry group theory is one of them.", "tokens": [51296, 883, 11, 588, 665, 13, 407, 341, 307, 767, 257, 2141, 1168, 13, 3902, 2174, 9889, 1594, 5261, 307, 472, 295, 552, 13, 51548], "temperature": 0.0, "avg_logprob": -0.15222155794184258, "compression_ratio": 1.7088607594936709, "no_speech_prob": 0.00627692649140954}, {"id": 2304, "seek": 716800, "start": 7191.68, "end": 7196.24, "text": " It's a central area in mathematics that it's a very highly developed and it's the foundation", "tokens": [51548, 467, 311, 257, 5777, 1859, 294, 18666, 300, 309, 311, 257, 588, 5405, 4743, 293, 309, 311, 264, 7030, 51776], "temperature": 0.0, "avg_logprob": -0.15222155794184258, "compression_ratio": 1.7088607594936709, "no_speech_prob": 0.00627692649140954}, {"id": 2305, "seek": 719624, "start": 7196.24, "end": 7201.44, "text": " of modern physics, like the standard model is a bunch of symmetries and so on. But the way,", "tokens": [50364, 295, 4363, 10649, 11, 411, 264, 3832, 2316, 307, 257, 3840, 295, 14232, 302, 2244, 293, 370, 322, 13, 583, 264, 636, 11, 50624], "temperature": 0.0, "avg_logprob": -0.12382221221923828, "compression_ratio": 1.625531914893617, "no_speech_prob": 0.003581263590604067}, {"id": 2306, "seek": 719624, "start": 7201.44, "end": 7208.0, "text": " and there is an exhaustive listing of what all the possible symmetry groups are, discrete ones,", "tokens": [50624, 293, 456, 307, 364, 14687, 488, 22161, 295, 437, 439, 264, 1944, 25440, 3935, 366, 11, 27706, 2306, 11, 50952], "temperature": 0.0, "avg_logprob": -0.12382221221923828, "compression_ratio": 1.625531914893617, "no_speech_prob": 0.003581263590604067}, {"id": 2307, "seek": 719624, "start": 7208.0, "end": 7213.76, "text": " you know, continuous ones, you know, so-called lead groups, etc., etc. So at that level, this is", "tokens": [50952, 291, 458, 11, 10957, 2306, 11, 291, 458, 11, 370, 12, 11880, 1477, 3935, 11, 5183, 7933, 5183, 13, 407, 412, 300, 1496, 11, 341, 307, 51240], "temperature": 0.0, "avg_logprob": -0.12382221221923828, "compression_ratio": 1.625531914893617, "no_speech_prob": 0.003581263590604067}, {"id": 2308, "seek": 719624, "start": 7213.76, "end": 7219.599999999999, "text": " not naive because people already have a handle on what the space is, right? But crucially for our", "tokens": [51240, 406, 29052, 570, 561, 1217, 362, 257, 4813, 322, 437, 264, 1901, 307, 11, 558, 30, 583, 5140, 1909, 337, 527, 51532], "temperature": 0.0, "avg_logprob": -0.12382221221923828, "compression_ratio": 1.625531914893617, "no_speech_prob": 0.003581263590604067}, {"id": 2309, "seek": 721960, "start": 7219.6, "end": 7226.4800000000005, "text": " purpose is for AI, that's not enough because precisely because those, again, the analogy", "tokens": [50364, 4334, 307, 337, 7318, 11, 300, 311, 406, 1547, 570, 13402, 570, 729, 11, 797, 11, 264, 21663, 50708], "temperature": 0.0, "avg_logprob": -0.17172064736624745, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.3762339949607849}, {"id": 2310, "seek": 721960, "start": 7226.4800000000005, "end": 7231.4400000000005, "text": " with logic is actually a very good one here. First of all, the logic is to brittle, right?", "tokens": [50708, 365, 9952, 307, 767, 257, 588, 665, 472, 510, 13, 2386, 295, 439, 11, 264, 9952, 307, 281, 49325, 11, 558, 30, 50956], "temperature": 0.0, "avg_logprob": -0.17172064736624745, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.3762339949607849}, {"id": 2311, "seek": 721960, "start": 7231.4400000000005, "end": 7235.04, "text": " And plain symmetry group theory, the way people have mostly applied so far,", "tokens": [50956, 400, 11121, 25440, 1594, 5261, 11, 264, 636, 561, 362, 5240, 6456, 370, 1400, 11, 51136], "temperature": 0.0, "avg_logprob": -0.17172064736624745, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.3762339949607849}, {"id": 2312, "seek": 721960, "start": 7235.04, "end": 7240.08, "text": " is also too brilliant for the same reason. So for example, right? Something like, you know,", "tokens": [51136, 307, 611, 886, 10248, 337, 264, 912, 1778, 13, 407, 337, 1365, 11, 558, 30, 6595, 411, 11, 291, 458, 11, 51388], "temperature": 0.0, "avg_logprob": -0.17172064736624745, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.3762339949607849}, {"id": 2313, "seek": 721960, "start": 7240.08, "end": 7244.08, "text": " people almost always immediately come up with, so like, oh, I understand, you know,", "tokens": [51388, 561, 1920, 1009, 4258, 808, 493, 365, 11, 370, 411, 11, 1954, 11, 286, 1223, 11, 291, 458, 11, 51588], "temperature": 0.0, "avg_logprob": -0.17172064736624745, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.3762339949607849}, {"id": 2314, "seek": 724408, "start": 7244.08, "end": 7248.5599999999995, "text": " I like symmetries with the light to recognize, you know, perturbed digits, but a 6 is not a 9.", "tokens": [50364, 286, 411, 14232, 302, 2244, 365, 264, 1442, 281, 5521, 11, 291, 458, 11, 13269, 374, 2883, 27011, 11, 457, 257, 1386, 307, 406, 257, 1722, 13, 50588], "temperature": 0.0, "avg_logprob": -0.15970125332684584, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.12054134160280228}, {"id": 2315, "seek": 724408, "start": 7249.5199999999995, "end": 7253.28, "text": " So some, like, if you just take naive symmetry group theory and you say, like, well, arbitrary", "tokens": [50636, 407, 512, 11, 411, 11, 498, 291, 445, 747, 29052, 25440, 1594, 5261, 293, 291, 584, 11, 411, 11, 731, 11, 23211, 50824], "temperature": 0.0, "avg_logprob": -0.15970125332684584, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.12054134160280228}, {"id": 2316, "seek": 724408, "start": 7253.28, "end": 7256.88, "text": " composability, as I was just talking about, I was like, well, now you've just said that a 6,", "tokens": [50824, 10199, 2310, 11, 382, 286, 390, 445, 1417, 466, 11, 286, 390, 411, 11, 731, 11, 586, 291, 600, 445, 848, 300, 257, 1386, 11, 51004], "temperature": 0.0, "avg_logprob": -0.15970125332684584, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.12054134160280228}, {"id": 2317, "seek": 724408, "start": 7256.88, "end": 7261.68, "text": " you've lost the ability to distinguish a 6 from a 9, right? Now, what we need precisely is to", "tokens": [51004, 291, 600, 2731, 264, 3485, 281, 20206, 257, 1386, 490, 257, 1722, 11, 558, 30, 823, 11, 437, 321, 643, 13402, 307, 281, 51244], "temperature": 0.0, "avg_logprob": -0.15970125332684584, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.12054134160280228}, {"id": 2318, "seek": 724408, "start": 7261.68, "end": 7265.5199999999995, "text": " combine symmetry group theory with the other things like statistics and optimization and", "tokens": [51244, 10432, 25440, 1594, 5261, 365, 264, 661, 721, 411, 12523, 293, 19618, 293, 51436], "temperature": 0.0, "avg_logprob": -0.15970125332684584, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.12054134160280228}, {"id": 2319, "seek": 724408, "start": 7265.5199999999995, "end": 7270.72, "text": " say something like the following. The space of things that you can compose is unlimited. You", "tokens": [51436, 584, 746, 411, 264, 3480, 13, 440, 1901, 295, 721, 300, 291, 393, 35925, 307, 21950, 13, 509, 51696], "temperature": 0.0, "avg_logprob": -0.15970125332684584, "compression_ratio": 1.7884615384615385, "no_speech_prob": 0.12054134160280228}, {"id": 2320, "seek": 727072, "start": 7270.72, "end": 7275.6, "text": " can have, you know, unlimited compositions, but for example, you pay a cost for composing more", "tokens": [50364, 393, 362, 11, 291, 458, 11, 21950, 43401, 11, 457, 337, 1365, 11, 291, 1689, 257, 2063, 337, 715, 6110, 544, 50608], "temperature": 0.0, "avg_logprob": -0.08625860736794667, "compression_ratio": 1.835483870967742, "no_speech_prob": 0.01081121526658535}, {"id": 2321, "seek": 727072, "start": 7275.6, "end": 7280.240000000001, "text": " symmetries. And now when you find the least cost path, and that's how you're going to match things,", "tokens": [50608, 14232, 302, 2244, 13, 400, 586, 562, 291, 915, 264, 1935, 2063, 3100, 11, 293, 300, 311, 577, 291, 434, 516, 281, 2995, 721, 11, 50840], "temperature": 0.0, "avg_logprob": -0.08625860736794667, "compression_ratio": 1.835483870967742, "no_speech_prob": 0.01081121526658535}, {"id": 2322, "seek": 727072, "start": 7280.240000000001, "end": 7285.360000000001, "text": " or, you know, your digit becomes less and less probable to be in 6, the more you've rotated", "tokens": [50840, 420, 11, 291, 458, 11, 428, 14293, 3643, 1570, 293, 1570, 21759, 281, 312, 294, 1386, 11, 264, 544, 291, 600, 42146, 51096], "temperature": 0.0, "avg_logprob": -0.08625860736794667, "compression_ratio": 1.835483870967742, "no_speech_prob": 0.01081121526658535}, {"id": 2323, "seek": 727072, "start": 7285.360000000001, "end": 7290.0, "text": " it, right? So now we know how to do all of that very well. So we know symmetry group theory very", "tokens": [51096, 309, 11, 558, 30, 407, 586, 321, 458, 577, 281, 360, 439, 295, 300, 588, 731, 13, 407, 321, 458, 25440, 1594, 5261, 588, 51328], "temperature": 0.0, "avg_logprob": -0.08625860736794667, "compression_ratio": 1.835483870967742, "no_speech_prob": 0.01081121526658535}, {"id": 2324, "seek": 727072, "start": 7290.0, "end": 7294.240000000001, "text": " well. We know how to do all these probabilistic costs, minimizing blah, blah, blah things,", "tokens": [51328, 731, 13, 492, 458, 577, 281, 360, 439, 613, 31959, 3142, 5497, 11, 46608, 12288, 11, 12288, 11, 12288, 721, 11, 51540], "temperature": 0.0, "avg_logprob": -0.08625860736794667, "compression_ratio": 1.835483870967742, "no_speech_prob": 0.01081121526658535}, {"id": 2325, "seek": 727072, "start": 7294.240000000001, "end": 7298.88, "text": " machine learning very well. We just need to combine it to the same way that we have previously", "tokens": [51540, 3479, 2539, 588, 731, 13, 492, 445, 643, 281, 10432, 309, 281, 264, 912, 636, 300, 321, 362, 8046, 51772], "temperature": 0.0, "avg_logprob": -0.08625860736794667, "compression_ratio": 1.835483870967742, "no_speech_prob": 0.01081121526658535}, {"id": 2326, "seek": 729888, "start": 7298.88, "end": 7302.96, "text": " combined these things with first order logic. So I'm glad you brought in the cost that that was", "tokens": [50364, 9354, 613, 721, 365, 700, 1668, 9952, 13, 407, 286, 478, 5404, 291, 3038, 294, 264, 2063, 300, 300, 390, 50568], "temperature": 0.0, "avg_logprob": -0.09666846180690154, "compression_ratio": 1.975177304964539, "no_speech_prob": 0.005457412451505661}, {"id": 2327, "seek": 729888, "start": 7302.96, "end": 7306.88, "text": " really, really good. So there were trade offs everywhere. I mean, for example, if you want to", "tokens": [50568, 534, 11, 534, 665, 13, 407, 456, 645, 4923, 39457, 5315, 13, 286, 914, 11, 337, 1365, 11, 498, 291, 528, 281, 50764], "temperature": 0.0, "avg_logprob": -0.09666846180690154, "compression_ratio": 1.975177304964539, "no_speech_prob": 0.005457412451505661}, {"id": 2328, "seek": 729888, "start": 7306.88, "end": 7312.16, "text": " make the models more fair and, you know, prioritize the low frequency attributes on the long tail,", "tokens": [50764, 652, 264, 5245, 544, 3143, 293, 11, 291, 458, 11, 25164, 264, 2295, 7893, 17212, 322, 264, 938, 6838, 11, 51028], "temperature": 0.0, "avg_logprob": -0.09666846180690154, "compression_ratio": 1.975177304964539, "no_speech_prob": 0.005457412451505661}, {"id": 2329, "seek": 729888, "start": 7312.16, "end": 7316.08, "text": " the headline accuracy goes down. Same thing with robustness. If you robustify a model,", "tokens": [51028, 264, 28380, 14170, 1709, 760, 13, 10635, 551, 365, 13956, 1287, 13, 759, 291, 13956, 2505, 257, 2316, 11, 51224], "temperature": 0.0, "avg_logprob": -0.09666846180690154, "compression_ratio": 1.975177304964539, "no_speech_prob": 0.005457412451505661}, {"id": 2330, "seek": 729888, "start": 7316.08, "end": 7319.76, "text": " the headline accuracy goes down. Same thing with symmetry groups. If you introduce other", "tokens": [51224, 264, 28380, 14170, 1709, 760, 13, 10635, 551, 365, 25440, 3935, 13, 759, 291, 5366, 661, 51408], "temperature": 0.0, "avg_logprob": -0.09666846180690154, "compression_ratio": 1.975177304964539, "no_speech_prob": 0.005457412451505661}, {"id": 2331, "seek": 729888, "start": 7319.76, "end": 7324.4800000000005, "text": " symmetry groups, you know, that the headline accuracy goes down. So it all comes back to the", "tokens": [51408, 25440, 3935, 11, 291, 458, 11, 300, 264, 28380, 14170, 1709, 760, 13, 407, 309, 439, 1487, 646, 281, 264, 51644], "temperature": 0.0, "avg_logprob": -0.09666846180690154, "compression_ratio": 1.975177304964539, "no_speech_prob": 0.005457412451505661}, {"id": 2332, "seek": 732448, "start": 7324.48, "end": 7329.44, "text": " bias variance trade off at the end of the day. And, you know, where is the limit here? How much", "tokens": [50364, 12577, 21977, 4923, 766, 412, 264, 917, 295, 264, 786, 13, 400, 11, 291, 458, 11, 689, 307, 264, 4948, 510, 30, 1012, 709, 50612], "temperature": 0.0, "avg_logprob": -0.11382731314628355, "compression_ratio": 1.7598566308243728, "no_speech_prob": 0.007458222098648548}, {"id": 2333, "seek": 732448, "start": 7329.44, "end": 7335.2, "text": " can we optimize these models and what does good look like? The bias variance trade off is a very", "tokens": [50612, 393, 321, 19719, 613, 5245, 293, 437, 775, 665, 574, 411, 30, 440, 12577, 21977, 4923, 766, 307, 257, 588, 50900], "temperature": 0.0, "avg_logprob": -0.11382731314628355, "compression_ratio": 1.7598566308243728, "no_speech_prob": 0.007458222098648548}, {"id": 2334, "seek": 732448, "start": 7335.2, "end": 7342.719999999999, "text": " useful tool, right? But it's not the deepest reality, right? The way to think about bias variance is", "tokens": [50900, 4420, 2290, 11, 558, 30, 583, 309, 311, 406, 264, 28288, 4103, 11, 558, 30, 440, 636, 281, 519, 466, 12577, 21977, 307, 51276], "temperature": 0.0, "avg_logprob": -0.11382731314628355, "compression_ratio": 1.7598566308243728, "no_speech_prob": 0.007458222098648548}, {"id": 2335, "seek": 732448, "start": 7342.719999999999, "end": 7347.12, "text": " that, again, talking about this notion of a trade off curve, there's a trade off between bias and", "tokens": [51276, 300, 11, 797, 11, 1417, 466, 341, 10710, 295, 257, 4923, 766, 7605, 11, 456, 311, 257, 4923, 766, 1296, 12577, 293, 51496], "temperature": 0.0, "avg_logprob": -0.11382731314628355, "compression_ratio": 1.7598566308243728, "no_speech_prob": 0.007458222098648548}, {"id": 2336, "seek": 732448, "start": 7347.12, "end": 7351.2, "text": " variance, right, which is in some sense unavoidable, right? In machine learning, if you have finite", "tokens": [51496, 21977, 11, 558, 11, 597, 307, 294, 512, 2020, 36541, 17079, 712, 11, 558, 30, 682, 3479, 2539, 11, 498, 291, 362, 19362, 51700], "temperature": 0.0, "avg_logprob": -0.11382731314628355, "compression_ratio": 1.7598566308243728, "no_speech_prob": 0.007458222098648548}, {"id": 2337, "seek": 735120, "start": 7351.2, "end": 7355.599999999999, "text": " data, you're trying to learn powerful models, bias variance is a trade off. And it's a very", "tokens": [50364, 1412, 11, 291, 434, 1382, 281, 1466, 4005, 5245, 11, 12577, 21977, 307, 257, 4923, 766, 13, 400, 309, 311, 257, 588, 50584], "temperature": 0.0, "avg_logprob": -0.08988468647003174, "compression_ratio": 1.8917378917378918, "no_speech_prob": 0.012813454493880272}, {"id": 2338, "seek": 735120, "start": 7355.599999999999, "end": 7359.44, "text": " consequential trade off in the sense that, for example, the things that work best with small", "tokens": [50584, 7242, 2549, 4923, 766, 294, 264, 2020, 300, 11, 337, 1365, 11, 264, 721, 300, 589, 1151, 365, 1359, 50776], "temperature": 0.0, "avg_logprob": -0.08988468647003174, "compression_ratio": 1.8917378917378918, "no_speech_prob": 0.012813454493880272}, {"id": 2339, "seek": 735120, "start": 7359.44, "end": 7362.96, "text": " amounts of data tend not to work best with large amounts of data, right? This is something that we", "tokens": [50776, 11663, 295, 1412, 3928, 406, 281, 589, 1151, 365, 2416, 11663, 295, 1412, 11, 558, 30, 639, 307, 746, 300, 321, 50952], "temperature": 0.0, "avg_logprob": -0.08988468647003174, "compression_ratio": 1.8917378917378918, "no_speech_prob": 0.012813454493880272}, {"id": 2340, "seek": 735120, "start": 7362.96, "end": 7367.04, "text": " should all, you know, grow up knowing in machine learning. But so many mistakes have been done", "tokens": [50952, 820, 439, 11, 291, 458, 11, 1852, 493, 5276, 294, 3479, 2539, 13, 583, 370, 867, 8038, 362, 668, 1096, 51156], "temperature": 0.0, "avg_logprob": -0.08988468647003174, "compression_ratio": 1.8917378917378918, "no_speech_prob": 0.012813454493880272}, {"id": 2341, "seek": 735120, "start": 7367.04, "end": 7371.2, "text": " because of that, because people study things in the easy or historically, that's all they had,", "tokens": [51156, 570, 295, 300, 11, 570, 561, 2979, 721, 294, 264, 1858, 420, 16180, 11, 300, 311, 439, 436, 632, 11, 51364], "temperature": 0.0, "avg_logprob": -0.08988468647003174, "compression_ratio": 1.8917378917378918, "no_speech_prob": 0.012813454493880272}, {"id": 2342, "seek": 735120, "start": 7371.2, "end": 7374.88, "text": " right? And then they're very surprised when something that seemed not very good, like, say,", "tokens": [51364, 558, 30, 400, 550, 436, 434, 588, 6100, 562, 746, 300, 6576, 406, 588, 665, 11, 411, 11, 584, 11, 51548], "temperature": 0.0, "avg_logprob": -0.08988468647003174, "compression_ratio": 1.8917378917378918, "no_speech_prob": 0.012813454493880272}, {"id": 2343, "seek": 735120, "start": 7374.88, "end": 7378.8, "text": " deep learning, right, turns out to be better when you have a large amount of data, or they believe", "tokens": [51548, 2452, 2539, 11, 558, 11, 4523, 484, 281, 312, 1101, 562, 291, 362, 257, 2416, 2372, 295, 1412, 11, 420, 436, 1697, 51744], "temperature": 0.0, "avg_logprob": -0.08988468647003174, "compression_ratio": 1.8917378917378918, "no_speech_prob": 0.012813454493880272}, {"id": 2344, "seek": 737880, "start": 7378.8, "end": 7383.6, "text": " in, like, silly things like, you know, Occam's razor version that, you know, accurate, you know,", "tokens": [50364, 294, 11, 411, 11, 11774, 721, 411, 11, 291, 458, 11, 26191, 335, 311, 30478, 3037, 300, 11, 291, 458, 11, 8559, 11, 291, 458, 11, 50604], "temperature": 0.0, "avg_logprob": -0.09384450045498935, "compression_ratio": 1.7194244604316546, "no_speech_prob": 0.03842753544449806}, {"id": 2345, "seek": 737880, "start": 7383.6, "end": 7388.24, "text": " simply is more accurate and whatnot. So a lot of mistakes have been made because of lack of", "tokens": [50604, 2935, 307, 544, 8559, 293, 25882, 13, 407, 257, 688, 295, 8038, 362, 668, 1027, 570, 295, 5011, 295, 50836], "temperature": 0.0, "avg_logprob": -0.09384450045498935, "compression_ratio": 1.7194244604316546, "no_speech_prob": 0.03842753544449806}, {"id": 2346, "seek": 737880, "start": 7388.24, "end": 7393.84, "text": " understanding of this. Having said that, what you really want is to move to a better trade off", "tokens": [50836, 3701, 295, 341, 13, 10222, 848, 300, 11, 437, 291, 534, 528, 307, 281, 1286, 281, 257, 1101, 4923, 766, 51116], "temperature": 0.0, "avg_logprob": -0.09384450045498935, "compression_ratio": 1.7194244604316546, "no_speech_prob": 0.03842753544449806}, {"id": 2347, "seek": 737880, "start": 7393.84, "end": 7399.76, "text": " curve between bias and variance, which you can, if you get at what the reality is, right? So the", "tokens": [51116, 7605, 1296, 12577, 293, 21977, 11, 597, 291, 393, 11, 498, 291, 483, 412, 437, 264, 4103, 307, 11, 558, 30, 407, 264, 51412], "temperature": 0.0, "avg_logprob": -0.09384450045498935, "compression_ratio": 1.7194244604316546, "no_speech_prob": 0.03842753544449806}, {"id": 2348, "seek": 737880, "start": 7399.76, "end": 7404.08, "text": " real game in machine, once you're evaluating your learner and figuring out, you're like, how much", "tokens": [51412, 957, 1216, 294, 3479, 11, 1564, 291, 434, 27479, 428, 33347, 293, 15213, 484, 11, 291, 434, 411, 11, 577, 709, 51628], "temperature": 0.0, "avg_logprob": -0.09384450045498935, "compression_ratio": 1.7194244604316546, "no_speech_prob": 0.03842753544449806}, {"id": 2349, "seek": 740408, "start": 7404.08, "end": 7409.04, "text": " to prune and whatnot, or how much to regulate bias variance is very important. But before that,", "tokens": [50364, 281, 582, 2613, 293, 25882, 11, 420, 577, 709, 281, 24475, 12577, 21977, 307, 588, 1021, 13, 583, 949, 300, 11, 50612], "temperature": 0.0, "avg_logprob": -0.09118130910310814, "compression_ratio": 1.7603833865814698, "no_speech_prob": 0.19384397566318512}, {"id": 2350, "seek": 740408, "start": 7409.04, "end": 7413.2, "text": " the most important question is like, what we're trying to do here is figure out what are the", "tokens": [50612, 264, 881, 1021, 1168, 307, 411, 11, 437, 321, 434, 1382, 281, 360, 510, 307, 2573, 484, 437, 366, 264, 50820], "temperature": 0.0, "avg_logprob": -0.09118130910310814, "compression_ratio": 1.7603833865814698, "no_speech_prob": 0.19384397566318512}, {"id": 2351, "seek": 740408, "start": 7413.2, "end": 7418.72, "text": " inductive biases? What are the regularities that the world really has, at least approximately,", "tokens": [50820, 31612, 488, 32152, 30, 708, 366, 264, 3890, 1088, 300, 264, 1002, 534, 575, 11, 412, 1935, 10447, 11, 51096], "temperature": 0.0, "avg_logprob": -0.09118130910310814, "compression_ratio": 1.7603833865814698, "no_speech_prob": 0.19384397566318512}, {"id": 2352, "seek": 740408, "start": 7418.72, "end": 7423.5199999999995, "text": " that we build our algorithms on top of that? And then if you give me a better one than I have now,", "tokens": [51096, 300, 321, 1322, 527, 14642, 322, 1192, 295, 300, 30, 400, 550, 498, 291, 976, 385, 257, 1101, 472, 813, 286, 362, 586, 11, 51336], "temperature": 0.0, "avg_logprob": -0.09118130910310814, "compression_ratio": 1.7603833865814698, "no_speech_prob": 0.19384397566318512}, {"id": 2353, "seek": 740408, "start": 7423.5199999999995, "end": 7427.84, "text": " I'll still have a bias variance trade off, but I'll be in a curve where for the same variance,", "tokens": [51336, 286, 603, 920, 362, 257, 12577, 21977, 4923, 766, 11, 457, 286, 603, 312, 294, 257, 7605, 689, 337, 264, 912, 21977, 11, 51552], "temperature": 0.0, "avg_logprob": -0.09118130910310814, "compression_ratio": 1.7603833865814698, "no_speech_prob": 0.19384397566318512}, {"id": 2354, "seek": 740408, "start": 7427.84, "end": 7431.5199999999995, "text": " I can have less bias and vice versa. And that's where the real action is.", "tokens": [51552, 286, 393, 362, 1570, 12577, 293, 11964, 25650, 13, 400, 300, 311, 689, 264, 957, 3069, 307, 13, 51736], "temperature": 0.0, "avg_logprob": -0.09118130910310814, "compression_ratio": 1.7603833865814698, "no_speech_prob": 0.19384397566318512}, {"id": 2355, "seek": 743152, "start": 7431.6, "end": 7434.64, "text": " Oh, interesting. Well, I didn't quite understand that because bias and variance,", "tokens": [50368, 876, 11, 1880, 13, 1042, 11, 286, 994, 380, 1596, 1223, 300, 570, 12577, 293, 21977, 11, 50520], "temperature": 0.0, "avg_logprob": -0.11790789145010488, "compression_ratio": 1.7432835820895523, "no_speech_prob": 0.010788638144731522}, {"id": 2356, "seek": 743152, "start": 7434.64, "end": 7439.120000000001, "text": " they are mutually exclusive. And I thought at first you were saying, well, if we understand", "tokens": [50520, 436, 366, 39144, 13005, 13, 400, 286, 1194, 412, 700, 291, 645, 1566, 11, 731, 11, 498, 321, 1223, 50744], "temperature": 0.0, "avg_logprob": -0.11790789145010488, "compression_ratio": 1.7432835820895523, "no_speech_prob": 0.010788638144731522}, {"id": 2357, "seek": 743152, "start": 7439.120000000001, "end": 7443.84, "text": " what the biases are better, the prototypical symmetries of the world we live in, then we", "tokens": [50744, 437, 264, 32152, 366, 1101, 11, 264, 46219, 34061, 14232, 302, 2244, 295, 264, 1002, 321, 1621, 294, 11, 550, 321, 50980], "temperature": 0.0, "avg_logprob": -0.11790789145010488, "compression_ratio": 1.7432835820895523, "no_speech_prob": 0.010788638144731522}, {"id": 2358, "seek": 743152, "start": 7443.84, "end": 7447.280000000001, "text": " can have more bias without having an approximation error, basically.", "tokens": [50980, 393, 362, 544, 12577, 1553, 1419, 364, 28023, 6713, 11, 1936, 13, 51152], "temperature": 0.0, "avg_logprob": -0.11790789145010488, "compression_ratio": 1.7432835820895523, "no_speech_prob": 0.010788638144731522}, {"id": 2359, "seek": 743152, "start": 7447.280000000001, "end": 7451.360000000001, "text": " The confusion arises because bias is a very unfortunately overloaded term.", "tokens": [51152, 440, 15075, 27388, 570, 12577, 307, 257, 588, 7015, 28777, 292, 1433, 13, 51356], "temperature": 0.0, "avg_logprob": -0.11790789145010488, "compression_ratio": 1.7432835820895523, "no_speech_prob": 0.010788638144731522}, {"id": 2360, "seek": 743152, "start": 7451.360000000001, "end": 7455.52, "text": " Right. This is not even getting into the psychological notion of bias like in Danny", "tokens": [51356, 1779, 13, 639, 307, 406, 754, 1242, 666, 264, 14346, 10710, 295, 12577, 411, 294, 16682, 51564], "temperature": 0.0, "avg_logprob": -0.11790789145010488, "compression_ratio": 1.7432835820895523, "no_speech_prob": 0.010788638144731522}, {"id": 2361, "seek": 743152, "start": 7455.52, "end": 7460.240000000001, "text": " Kahneman's work, or even the sociological notion of bias like racial biases, gender biases and", "tokens": [51564, 591, 12140, 15023, 311, 589, 11, 420, 754, 264, 3075, 4383, 10710, 295, 12577, 411, 12131, 32152, 11, 7898, 32152, 293, 51800], "temperature": 0.0, "avg_logprob": -0.11790789145010488, "compression_ratio": 1.7432835820895523, "no_speech_prob": 0.010788638144731522}, {"id": 2362, "seek": 746024, "start": 7460.24, "end": 7465.599999999999, "text": " whatnot. So we need to distinguish. I just used my bad, the word bias into completely", "tokens": [50364, 25882, 13, 407, 321, 643, 281, 20206, 13, 286, 445, 1143, 452, 1578, 11, 264, 1349, 12577, 666, 2584, 50632], "temperature": 0.0, "avg_logprob": -0.10631892510822841, "compression_ratio": 1.748091603053435, "no_speech_prob": 0.004670717753469944}, {"id": 2363, "seek": 746024, "start": 7465.599999999999, "end": 7470.08, "text": " different senses, completely but not unrelated. That's the thing. One of them is the statistical", "tokens": [50632, 819, 17057, 11, 2584, 457, 406, 38967, 13, 663, 311, 264, 551, 13, 1485, 295, 552, 307, 264, 22820, 50856], "temperature": 0.0, "avg_logprob": -0.10631892510822841, "compression_ratio": 1.748091603053435, "no_speech_prob": 0.004670717753469944}, {"id": 2364, "seek": 746024, "start": 7470.08, "end": 7475.92, "text": " notion of bias. There really is a trade off between the two. There's a sum of squares,", "tokens": [50856, 10710, 295, 12577, 13, 821, 534, 307, 257, 4923, 766, 1296, 264, 732, 13, 821, 311, 257, 2408, 295, 19368, 11, 51148], "temperature": 0.0, "avg_logprob": -0.10631892510822841, "compression_ratio": 1.748091603053435, "no_speech_prob": 0.004670717753469944}, {"id": 2365, "seek": 746024, "start": 7475.92, "end": 7481.599999999999, "text": " blah, blah, blah. The machine learning notion of inductive bias, it's the preference that you", "tokens": [51148, 12288, 11, 12288, 11, 12288, 13, 440, 3479, 2539, 10710, 295, 31612, 488, 12577, 11, 309, 311, 264, 17502, 300, 291, 51432], "temperature": 0.0, "avg_logprob": -0.10631892510822841, "compression_ratio": 1.748091603053435, "no_speech_prob": 0.004670717753469944}, {"id": 2366, "seek": 746024, "start": 7481.599999999999, "end": 7486.4, "text": " have for certain models of our others, which is really just another way of saying your priors,", "tokens": [51432, 362, 337, 1629, 5245, 295, 527, 2357, 11, 597, 307, 534, 445, 1071, 636, 295, 1566, 428, 1790, 830, 11, 51672], "temperature": 0.0, "avg_logprob": -0.10631892510822841, "compression_ratio": 1.748091603053435, "no_speech_prob": 0.004670717753469944}, {"id": 2367, "seek": 748640, "start": 7487.36, "end": 7493.2, "text": " whether they are assumptions or knowledge. Maybe actually instead of bias, they're like,", "tokens": [50412, 1968, 436, 366, 17695, 420, 3601, 13, 2704, 767, 2602, 295, 12577, 11, 436, 434, 411, 11, 50704], "temperature": 0.0, "avg_logprob": -0.15957346329322228, "compression_ratio": 1.6816479400749065, "no_speech_prob": 0.019034523516893387}, {"id": 2368, "seek": 748640, "start": 7493.2, "end": 7496.879999999999, "text": " what you really want to do is figure out what are the priors? What are the model classes?", "tokens": [50704, 437, 291, 534, 528, 281, 360, 307, 2573, 484, 437, 366, 264, 1790, 830, 30, 708, 366, 264, 2316, 5359, 30, 50888], "temperature": 0.0, "avg_logprob": -0.15957346329322228, "compression_ratio": 1.6816479400749065, "no_speech_prob": 0.019034523516893387}, {"id": 2369, "seek": 748640, "start": 7496.879999999999, "end": 7502.08, "text": " What are the preferences? The bias is a kind of preference that really line up with the world", "tokens": [50888, 708, 366, 264, 21910, 30, 440, 12577, 307, 257, 733, 295, 17502, 300, 534, 1622, 493, 365, 264, 1002, 51148], "temperature": 0.0, "avg_logprob": -0.15957346329322228, "compression_ratio": 1.6816479400749065, "no_speech_prob": 0.019034523516893387}, {"id": 2370, "seek": 748640, "start": 7502.08, "end": 7506.4, "text": " in reality or the domain and therefore let you move to a better trade off curve", "tokens": [51148, 294, 4103, 420, 264, 9274, 293, 4412, 718, 291, 1286, 281, 257, 1101, 4923, 766, 7605, 51364], "temperature": 0.0, "avg_logprob": -0.15957346329322228, "compression_ratio": 1.6816479400749065, "no_speech_prob": 0.019034523516893387}, {"id": 2371, "seek": 748640, "start": 7506.4, "end": 7513.599999999999, "text": " among statistical bias and statistical variance. Amazing. Well, Pedro, just tell us a little bit", "tokens": [51364, 3654, 22820, 12577, 293, 22820, 21977, 13, 14165, 13, 1042, 11, 26662, 11, 445, 980, 505, 257, 707, 857, 51724], "temperature": 0.0, "avg_logprob": -0.15957346329322228, "compression_ratio": 1.6816479400749065, "no_speech_prob": 0.019034523516893387}, {"id": 2372, "seek": 751360, "start": 7513.6, "end": 7517.04, "text": " about what have you seen at NeurIPS and how's the week been for you?", "tokens": [50364, 466, 437, 362, 291, 1612, 412, 1734, 374, 40, 6273, 293, 577, 311, 264, 1243, 668, 337, 291, 30, 50536], "temperature": 0.0, "avg_logprob": -0.14605398911696213, "compression_ratio": 1.7, "no_speech_prob": 0.030030034482479095}, {"id": 2373, "seek": 751360, "start": 7518.400000000001, "end": 7520.88, "text": " We've already touched on some of the interesting things that I saw,", "tokens": [50604, 492, 600, 1217, 9828, 322, 512, 295, 264, 1880, 721, 300, 286, 1866, 11, 50728], "temperature": 0.0, "avg_logprob": -0.14605398911696213, "compression_ratio": 1.7, "no_speech_prob": 0.030030034482479095}, {"id": 2374, "seek": 751360, "start": 7522.240000000001, "end": 7526.56, "text": " in particular some of the areas that I'm interested in. The thing about NeurIPS is this,", "tokens": [50796, 294, 1729, 512, 295, 264, 3179, 300, 286, 478, 3102, 294, 13, 440, 551, 466, 1734, 374, 40, 6273, 307, 341, 11, 51012], "temperature": 0.0, "avg_logprob": -0.14605398911696213, "compression_ratio": 1.7, "no_speech_prob": 0.030030034482479095}, {"id": 2375, "seek": 751360, "start": 7526.56, "end": 7530.8, "text": " of course, is that it's a vast conference. In the early days, I used to at least go through", "tokens": [51012, 295, 1164, 11, 307, 300, 309, 311, 257, 8369, 7586, 13, 682, 264, 2440, 1708, 11, 286, 1143, 281, 412, 1935, 352, 807, 51224], "temperature": 0.0, "avg_logprob": -0.14605398911696213, "compression_ratio": 1.7, "no_speech_prob": 0.030030034482479095}, {"id": 2376, "seek": 751360, "start": 7530.8, "end": 7536.240000000001, "text": " the proceedings and look at the title and maybe the abstract of every paper. This is now impossible.", "tokens": [51224, 264, 37254, 293, 574, 412, 264, 4876, 293, 1310, 264, 12649, 295, 633, 3035, 13, 639, 307, 586, 6243, 13, 51496], "temperature": 0.0, "avg_logprob": -0.14605398911696213, "compression_ratio": 1.7, "no_speech_prob": 0.030030034482479095}, {"id": 2377, "seek": 751360, "start": 7537.04, "end": 7541.200000000001, "text": " Now, these days, if all you do is try to walk through the poster sessions,", "tokens": [51536, 823, 11, 613, 1708, 11, 498, 439, 291, 360, 307, 853, 281, 1792, 807, 264, 17171, 11081, 11, 51744], "temperature": 0.0, "avg_logprob": -0.14605398911696213, "compression_ratio": 1.7, "no_speech_prob": 0.030030034482479095}, {"id": 2378, "seek": 754120, "start": 7541.28, "end": 7546.48, "text": " you never get to the end. I haven't been to a single poster session in this NeurIPS", "tokens": [50368, 291, 1128, 483, 281, 264, 917, 13, 286, 2378, 380, 668, 281, 257, 2167, 17171, 5481, 294, 341, 1734, 374, 40, 6273, 50628], "temperature": 0.0, "avg_logprob": -0.10824136173023897, "compression_ratio": 1.8169934640522876, "no_speech_prob": 0.0531964972615242}, {"id": 2379, "seek": 754120, "start": 7546.48, "end": 7550.96, "text": " where I actually got through all. I like to go through the poster sessions quickly once", "tokens": [50628, 689, 286, 767, 658, 807, 439, 13, 286, 411, 281, 352, 807, 264, 17171, 11081, 2661, 1564, 50852], "temperature": 0.0, "avg_logprob": -0.10824136173023897, "compression_ratio": 1.8169934640522876, "no_speech_prob": 0.0531964972615242}, {"id": 2380, "seek": 754120, "start": 7551.679999999999, "end": 7556.08, "text": " and then just to see what's there and then go back to the ones that I found really interesting.", "tokens": [50888, 293, 550, 445, 281, 536, 437, 311, 456, 293, 550, 352, 646, 281, 264, 2306, 300, 286, 1352, 534, 1880, 13, 51108], "temperature": 0.0, "avg_logprob": -0.10824136173023897, "compression_ratio": 1.8169934640522876, "no_speech_prob": 0.0531964972615242}, {"id": 2381, "seek": 754120, "start": 7556.08, "end": 7561.92, "text": " I haven't actually been able to even finish that walk through because they're so vast. You're also", "tokens": [51108, 286, 2378, 380, 767, 668, 1075, 281, 754, 2413, 300, 1792, 807, 570, 436, 434, 370, 8369, 13, 509, 434, 611, 51400], "temperature": 0.0, "avg_logprob": -0.10824136173023897, "compression_ratio": 1.8169934640522876, "no_speech_prob": 0.0531964972615242}, {"id": 2382, "seek": 754120, "start": 7561.92, "end": 7566.88, "text": " running to people which is part of the point and talk and whatnot, but when there's 500 posters in", "tokens": [51400, 2614, 281, 561, 597, 307, 644, 295, 264, 935, 293, 751, 293, 25882, 11, 457, 562, 456, 311, 5923, 28172, 294, 51648], "temperature": 0.0, "avg_logprob": -0.10824136173023897, "compression_ratio": 1.8169934640522876, "no_speech_prob": 0.0531964972615242}, {"id": 2383, "seek": 754120, "start": 7566.88, "end": 7570.639999999999, "text": " every session and there's 3,000 papers in the conference, it becomes very hard to find the", "tokens": [51648, 633, 5481, 293, 456, 311, 805, 11, 1360, 10577, 294, 264, 7586, 11, 309, 3643, 588, 1152, 281, 915, 264, 51836], "temperature": 0.0, "avg_logprob": -0.10824136173023897, "compression_ratio": 1.8169934640522876, "no_speech_prob": 0.0531964972615242}, {"id": 2384, "seek": 757064, "start": 7570.64, "end": 7575.12, "text": " ones that are most relevant. Of course, an easy thing to do is look at what they, I mean,", "tokens": [50364, 2306, 300, 366, 881, 7340, 13, 2720, 1164, 11, 364, 1858, 551, 281, 360, 307, 574, 412, 437, 436, 11, 286, 914, 11, 50588], "temperature": 0.0, "avg_logprob": -0.15889210360390799, "compression_ratio": 1.6879699248120301, "no_speech_prob": 0.005443257745355368}, {"id": 2385, "seek": 757064, "start": 7576.400000000001, "end": 7580.160000000001, "text": " something about NeurIPS this year that I honestly thought was absolutely terrible,", "tokens": [50652, 746, 466, 1734, 374, 40, 6273, 341, 1064, 300, 286, 6095, 1194, 390, 3122, 6237, 11, 50840], "temperature": 0.0, "avg_logprob": -0.15889210360390799, "compression_ratio": 1.6879699248120301, "no_speech_prob": 0.005443257745355368}, {"id": 2386, "seek": 757064, "start": 7580.160000000001, "end": 7587.76, "text": " like a really, really terrible idea is that it's a hybrid conference and their idea of", "tokens": [50840, 411, 257, 534, 11, 534, 6237, 1558, 307, 300, 309, 311, 257, 13051, 7586, 293, 641, 1558, 295, 51220], "temperature": 0.0, "avg_logprob": -0.15889210360390799, "compression_ratio": 1.6879699248120301, "no_speech_prob": 0.005443257745355368}, {"id": 2387, "seek": 757064, "start": 7587.76, "end": 7594.08, "text": " a hybrid conference is that there are no talks. The talks are all virtual next week. Nips this", "tokens": [51220, 257, 13051, 7586, 307, 300, 456, 366, 572, 6686, 13, 440, 6686, 366, 439, 6374, 958, 1243, 13, 426, 2600, 341, 51536], "temperature": 0.0, "avg_logprob": -0.15889210360390799, "compression_ratio": 1.6879699248120301, "no_speech_prob": 0.005443257745355368}, {"id": 2388, "seek": 757064, "start": 7594.08, "end": 7600.160000000001, "text": " year to a first approximation was one big poster session, which I mean, to me, this is just an", "tokens": [51536, 1064, 281, 257, 700, 28023, 390, 472, 955, 17171, 5481, 11, 597, 286, 914, 11, 281, 385, 11, 341, 307, 445, 364, 51840], "temperature": 0.0, "avg_logprob": -0.15889210360390799, "compression_ratio": 1.6879699248120301, "no_speech_prob": 0.005443257745355368}, {"id": 2389, "seek": 760016, "start": 7600.16, "end": 7606.08, "text": " incredibly bad idea. In that sense, I haven't gotten as much out of Nips by this point of the", "tokens": [50364, 6252, 1578, 1558, 13, 682, 300, 2020, 11, 286, 2378, 380, 5768, 382, 709, 484, 295, 426, 2600, 538, 341, 935, 295, 264, 50660], "temperature": 0.0, "avg_logprob": -0.0888278291032121, "compression_ratio": 1.6537102473498233, "no_speech_prob": 0.011838599108159542}, {"id": 2390, "seek": 760016, "start": 7606.08, "end": 7611.84, "text": " conference as I would have in most years. There's also looking at the papers that were usually", "tokens": [50660, 7586, 382, 286, 576, 362, 294, 881, 924, 13, 821, 311, 611, 1237, 412, 264, 10577, 300, 645, 2673, 50948], "temperature": 0.0, "avg_logprob": -0.0888278291032121, "compression_ratio": 1.6537102473498233, "no_speech_prob": 0.011838599108159542}, {"id": 2391, "seek": 760016, "start": 7611.84, "end": 7616.88, "text": " selected as oral, but this time they call them oral equivalent because there are no oral papers,", "tokens": [50948, 8209, 382, 19338, 11, 457, 341, 565, 436, 818, 552, 19338, 10344, 570, 456, 366, 572, 19338, 10577, 11, 51200], "temperature": 0.0, "avg_logprob": -0.0888278291032121, "compression_ratio": 1.6537102473498233, "no_speech_prob": 0.011838599108159542}, {"id": 2392, "seek": 760016, "start": 7616.88, "end": 7623.2, "text": " but they still want to have that distinction. The number of those papers these days is 160 or", "tokens": [51200, 457, 436, 920, 528, 281, 362, 300, 16844, 13, 440, 1230, 295, 729, 10577, 613, 1708, 307, 21243, 420, 51516], "temperature": 0.0, "avg_logprob": -0.0888278291032121, "compression_ratio": 1.6537102473498233, "no_speech_prob": 0.011838599108159542}, {"id": 2393, "seek": 760016, "start": 7623.2, "end": 7630.08, "text": " something, which is bigger than Nips and ICML some years ago. Usually from those papers,", "tokens": [51516, 746, 11, 597, 307, 3801, 813, 426, 2600, 293, 14360, 12683, 512, 924, 2057, 13, 11419, 490, 729, 10577, 11, 51860], "temperature": 0.0, "avg_logprob": -0.0888278291032121, "compression_ratio": 1.6537102473498233, "no_speech_prob": 0.011838599108159542}, {"id": 2394, "seek": 763016, "start": 7630.48, "end": 7635.68, "text": " some of them kind of like jump out at you as being great and very relevant. I've only looked at", "tokens": [50380, 512, 295, 552, 733, 295, 411, 3012, 484, 412, 291, 382, 885, 869, 293, 588, 7340, 13, 286, 600, 787, 2956, 412, 50640], "temperature": 0.0, "avg_logprob": -0.11747414503640276, "compression_ratio": 1.7047970479704797, "no_speech_prob": 0.006460217293351889}, {"id": 2395, "seek": 763016, "start": 7635.68, "end": 7643.44, "text": " them briefly, so don't quote me on this, if you will, but none of those have jumped out to me", "tokens": [50640, 552, 10515, 11, 370, 500, 380, 6513, 385, 322, 341, 11, 498, 291, 486, 11, 457, 6022, 295, 729, 362, 13864, 484, 281, 385, 51028], "temperature": 0.0, "avg_logprob": -0.11747414503640276, "compression_ratio": 1.7047970479704797, "no_speech_prob": 0.006460217293351889}, {"id": 2396, "seek": 763016, "start": 7645.12, "end": 7648.5599999999995, "text": " as like, oh, yeah, this sounds like something really brilliant and that I want to dig into,", "tokens": [51112, 382, 411, 11, 1954, 11, 1338, 11, 341, 3263, 411, 746, 534, 10248, 293, 300, 286, 528, 281, 2528, 666, 11, 51284], "temperature": 0.0, "avg_logprob": -0.11747414503640276, "compression_ratio": 1.7047970479704797, "no_speech_prob": 0.006460217293351889}, {"id": 2397, "seek": 763016, "start": 7648.5599999999995, "end": 7652.639999999999, "text": " but there probably are many. I just haven't really had a chance to look at them yet.", "tokens": [51284, 457, 456, 1391, 366, 867, 13, 286, 445, 2378, 380, 534, 632, 257, 2931, 281, 574, 412, 552, 1939, 13, 51488], "temperature": 0.0, "avg_logprob": -0.11747414503640276, "compression_ratio": 1.7047970479704797, "no_speech_prob": 0.006460217293351889}, {"id": 2398, "seek": 763016, "start": 7652.639999999999, "end": 7657.76, "text": " Yeah. I mean, I have a similar reaction. I mean, it feels like we're at the point of saturation", "tokens": [51488, 865, 13, 286, 914, 11, 286, 362, 257, 2531, 5480, 13, 286, 914, 11, 309, 3417, 411, 321, 434, 412, 264, 935, 295, 27090, 51744], "temperature": 0.0, "avg_logprob": -0.11747414503640276, "compression_ratio": 1.7047970479704797, "no_speech_prob": 0.006460217293351889}, {"id": 2399, "seek": 765776, "start": 7657.76, "end": 7662.64, "text": " and there are loads and loads of microvariations on the same idea. It's completely overwhelming,", "tokens": [50364, 293, 456, 366, 12668, 293, 12668, 295, 4532, 34033, 763, 322, 264, 912, 1558, 13, 467, 311, 2584, 13373, 11, 50608], "temperature": 0.0, "avg_logprob": -0.11186795234680176, "compression_ratio": 1.8284789644012944, "no_speech_prob": 0.005454527214169502}, {"id": 2400, "seek": 765776, "start": 7662.64, "end": 7666.8, "text": " but what I find is that it's a very social experience. When I walk through the posters,", "tokens": [50608, 457, 437, 286, 915, 307, 300, 309, 311, 257, 588, 2093, 1752, 13, 1133, 286, 1792, 807, 264, 28172, 11, 50816], "temperature": 0.0, "avg_logprob": -0.11186795234680176, "compression_ratio": 1.8284789644012944, "no_speech_prob": 0.005454527214169502}, {"id": 2401, "seek": 765776, "start": 7666.8, "end": 7671.04, "text": " I just immediately become engrossed in conversation and hours go by and I just think, oh my God,", "tokens": [50816, 286, 445, 4258, 1813, 465, 861, 772, 292, 294, 3761, 293, 2496, 352, 538, 293, 286, 445, 519, 11, 1954, 452, 1265, 11, 51028], "temperature": 0.0, "avg_logprob": -0.11186795234680176, "compression_ratio": 1.8284789644012944, "no_speech_prob": 0.005454527214169502}, {"id": 2402, "seek": 765776, "start": 7671.04, "end": 7675.68, "text": " what have I just been doing for the last year? That's the real point. The posters are very good.", "tokens": [51028, 437, 362, 286, 445, 668, 884, 337, 264, 1036, 1064, 30, 663, 311, 264, 957, 935, 13, 440, 28172, 366, 588, 665, 13, 51260], "temperature": 0.0, "avg_logprob": -0.11186795234680176, "compression_ratio": 1.8284789644012944, "no_speech_prob": 0.005454527214169502}, {"id": 2403, "seek": 765776, "start": 7677.280000000001, "end": 7680.88, "text": " It's like the grain of sand and the oyster. The poster is the grain of sand. The oyster is the", "tokens": [51340, 467, 311, 411, 264, 12837, 295, 4932, 293, 264, 32005, 13, 440, 17171, 307, 264, 12837, 295, 4932, 13, 440, 32005, 307, 264, 51520], "temperature": 0.0, "avg_logprob": -0.11186795234680176, "compression_ratio": 1.8284789644012944, "no_speech_prob": 0.005454527214169502}, {"id": 2404, "seek": 765776, "start": 7680.88, "end": 7685.360000000001, "text": " conversation that you have with the person at the poster or with other people around there.", "tokens": [51520, 3761, 300, 291, 362, 365, 264, 954, 412, 264, 17171, 420, 365, 661, 561, 926, 456, 13, 51744], "temperature": 0.0, "avg_logprob": -0.11186795234680176, "compression_ratio": 1.8284789644012944, "no_speech_prob": 0.005454527214169502}, {"id": 2405, "seek": 768536, "start": 7685.36, "end": 7688.16, "text": " To touch on another point that you made that I think is actually important.", "tokens": [50364, 1407, 2557, 322, 1071, 935, 300, 291, 1027, 300, 286, 519, 307, 767, 1021, 13, 50504], "temperature": 0.0, "avg_logprob": -0.17600138370807356, "compression_ratio": 1.5830258302583027, "no_speech_prob": 0.03720397129654884}, {"id": 2406, "seek": 768536, "start": 7689.5199999999995, "end": 7693.679999999999, "text": " New Europe's and ICML and so on are bigger today than they've ever been. Actually,", "tokens": [50572, 1873, 3315, 311, 293, 14360, 12683, 293, 370, 322, 366, 3801, 965, 813, 436, 600, 1562, 668, 13, 5135, 11, 50780], "temperature": 0.0, "avg_logprob": -0.17600138370807356, "compression_ratio": 1.5830258302583027, "no_speech_prob": 0.03720397129654884}, {"id": 2407, "seek": 768536, "start": 7693.679999999999, "end": 7697.36, "text": " not strictly true because these recent lips, surprisingly, they tend to have gone down a", "tokens": [50780, 406, 20792, 2074, 570, 613, 5162, 10118, 11, 17600, 11, 436, 3928, 281, 362, 2780, 760, 257, 50964], "temperature": 0.0, "avg_logprob": -0.17600138370807356, "compression_ratio": 1.5830258302583027, "no_speech_prob": 0.03720397129654884}, {"id": 2408, "seek": 768536, "start": 7697.36, "end": 7706.719999999999, "text": " lot. We can and should ask why, but we need to scale. There are bigger conferences,", "tokens": [50964, 688, 13, 492, 393, 293, 820, 1029, 983, 11, 457, 321, 643, 281, 4373, 13, 821, 366, 3801, 22032, 11, 51432], "temperature": 0.0, "avg_logprob": -0.17600138370807356, "compression_ratio": 1.5830258302583027, "no_speech_prob": 0.03720397129654884}, {"id": 2409, "seek": 768536, "start": 7706.719999999999, "end": 7711.28, "text": " like the New Science Conference is one conference and it's 35,000 people every year and they make", "tokens": [51432, 411, 264, 1873, 8976, 22131, 307, 472, 7586, 293, 309, 311, 6976, 11, 1360, 561, 633, 1064, 293, 436, 652, 51660], "temperature": 0.0, "avg_logprob": -0.17600138370807356, "compression_ratio": 1.5830258302583027, "no_speech_prob": 0.03720397129654884}, {"id": 2410, "seek": 771128, "start": 7711.28, "end": 7717.36, "text": " it work. It's good to experiment. I think New Europe's at the scale that it is today can work,", "tokens": [50364, 309, 589, 13, 467, 311, 665, 281, 5120, 13, 286, 519, 1873, 3315, 311, 412, 264, 4373, 300, 309, 307, 965, 393, 589, 11, 50668], "temperature": 0.0, "avg_logprob": -0.12545194244384766, "compression_ratio": 1.7686567164179106, "no_speech_prob": 0.130532369017601}, {"id": 2411, "seek": 771128, "start": 7717.36, "end": 7722.0, "text": " but it is not working very well. One of the ways in which it's not working very well is that", "tokens": [50668, 457, 309, 307, 406, 1364, 588, 731, 13, 1485, 295, 264, 2098, 294, 597, 309, 311, 406, 1364, 588, 731, 307, 300, 50900], "temperature": 0.0, "avg_logprob": -0.12545194244384766, "compression_ratio": 1.7686567164179106, "no_speech_prob": 0.130532369017601}, {"id": 2412, "seek": 771128, "start": 7722.5599999999995, "end": 7726.24, "text": " we need to think a lot more. I don't understand this is working. It's hard and people have day", "tokens": [50928, 321, 643, 281, 519, 257, 688, 544, 13, 286, 500, 380, 1223, 341, 307, 1364, 13, 467, 311, 1152, 293, 561, 362, 786, 51112], "temperature": 0.0, "avg_logprob": -0.12545194244384766, "compression_ratio": 1.7686567164179106, "no_speech_prob": 0.130532369017601}, {"id": 2413, "seek": 771128, "start": 7726.24, "end": 7731.5199999999995, "text": " jobs or not, so this is not a criticism in that sense. We need to really work on making it easy", "tokens": [51112, 4782, 420, 406, 11, 370, 341, 307, 406, 257, 15835, 294, 300, 2020, 13, 492, 643, 281, 534, 589, 322, 1455, 309, 1858, 51376], "temperature": 0.0, "avg_logprob": -0.12545194244384766, "compression_ratio": 1.7686567164179106, "no_speech_prob": 0.130532369017601}, {"id": 2414, "seek": 771128, "start": 7731.5199999999995, "end": 7736.639999999999, "text": " for people to find the papers that are relevant to them. Number one, number two, and maybe even", "tokens": [51376, 337, 561, 281, 915, 264, 10577, 300, 366, 7340, 281, 552, 13, 5118, 472, 11, 1230, 732, 11, 293, 1310, 754, 51632], "temperature": 0.0, "avg_logprob": -0.12545194244384766, "compression_ratio": 1.7686567164179106, "no_speech_prob": 0.130532369017601}, {"id": 2415, "seek": 773664, "start": 7736.64, "end": 7741.76, "text": " more important, there is more machine learning research today than ever, but in some sense the", "tokens": [50364, 544, 1021, 11, 456, 307, 544, 3479, 2539, 2132, 965, 813, 1562, 11, 457, 294, 512, 2020, 264, 50620], "temperature": 0.0, "avg_logprob": -0.09215530502461941, "compression_ratio": 1.8631178707224334, "no_speech_prob": 0.011668737046420574}, {"id": 2416, "seek": 773664, "start": 7741.76, "end": 7746.88, "text": " diversity of that research is in some ways lower than ever. Another point that you brought up and", "tokens": [50620, 8811, 295, 300, 2132, 307, 294, 512, 2098, 3126, 813, 1562, 13, 3996, 935, 300, 291, 3038, 493, 293, 50876], "temperature": 0.0, "avg_logprob": -0.09215530502461941, "compression_ratio": 1.8631178707224334, "no_speech_prob": 0.011668737046420574}, {"id": 2417, "seek": 773664, "start": 7746.88, "end": 7751.280000000001, "text": " I think is very important to do with the scaling of New Europe's and the machine learning communities", "tokens": [50876, 286, 519, 307, 588, 1021, 281, 360, 365, 264, 21589, 295, 1873, 3315, 311, 293, 264, 3479, 2539, 4456, 51096], "temperature": 0.0, "avg_logprob": -0.09215530502461941, "compression_ratio": 1.8631178707224334, "no_speech_prob": 0.011668737046420574}, {"id": 2418, "seek": 773664, "start": 7751.280000000001, "end": 7757.68, "text": " that we have in just raw numbers, more machine learning and AI research going on today than ever", "tokens": [51096, 300, 321, 362, 294, 445, 8936, 3547, 11, 544, 3479, 2539, 293, 7318, 2132, 516, 322, 965, 813, 1562, 51416], "temperature": 0.0, "avg_logprob": -0.09215530502461941, "compression_ratio": 1.8631178707224334, "no_speech_prob": 0.011668737046420574}, {"id": 2419, "seek": 773664, "start": 7757.68, "end": 7762.72, "text": " before by an order of magnitude. But in terms of diversity, there's probably less diversity in the", "tokens": [51416, 949, 538, 364, 1668, 295, 15668, 13, 583, 294, 2115, 295, 8811, 11, 456, 311, 1391, 1570, 8811, 294, 264, 51668], "temperature": 0.0, "avg_logprob": -0.09215530502461941, "compression_ratio": 1.8631178707224334, "no_speech_prob": 0.011668737046420574}, {"id": 2420, "seek": 776272, "start": 7762.72, "end": 7768.16, "text": " research now than there was before, which is a tragedy. I understand why people have kind of", "tokens": [50364, 2132, 586, 813, 456, 390, 949, 11, 597, 307, 257, 18563, 13, 286, 1223, 983, 561, 362, 733, 295, 50636], "temperature": 0.0, "avg_logprob": -0.1229801260906717, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.040099695324897766}, {"id": 2421, "seek": 776272, "start": 7768.16, "end": 7772.240000000001, "text": " like converged to deep learning. I'm a huge fan of deep learning. I was doing it before it was", "tokens": [50636, 411, 9652, 3004, 281, 2452, 2539, 13, 286, 478, 257, 2603, 3429, 295, 2452, 2539, 13, 286, 390, 884, 309, 949, 309, 390, 50840], "temperature": 0.0, "avg_logprob": -0.1229801260906717, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.040099695324897766}, {"id": 2422, "seek": 776272, "start": 7772.240000000001, "end": 7777.52, "text": " cool as they say and whatnot, but the extent to which 90% of the community, not just in machine", "tokens": [50840, 1627, 382, 436, 584, 293, 25882, 11, 457, 264, 8396, 281, 597, 4289, 4, 295, 264, 1768, 11, 406, 445, 294, 3479, 51104], "temperature": 0.0, "avg_logprob": -0.1229801260906717, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.040099695324897766}, {"id": 2423, "seek": 776272, "start": 7777.52, "end": 7783.280000000001, "text": " learning but AI, is not just pursuing and not even deep learning, but a special type of deep", "tokens": [51104, 2539, 457, 7318, 11, 307, 406, 445, 20222, 293, 406, 754, 2452, 2539, 11, 457, 257, 2121, 2010, 295, 2452, 51392], "temperature": 0.0, "avg_logprob": -0.1229801260906717, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.040099695324897766}, {"id": 2424, "seek": 776272, "start": 7783.280000000001, "end": 7791.12, "text": " learning, which you might call applications of backprop, is extremely undesirable. We have", "tokens": [51392, 2539, 11, 597, 291, 1062, 818, 5821, 295, 646, 79, 1513, 11, 307, 4664, 45667, 21493, 13, 492, 362, 51784], "temperature": 0.0, "avg_logprob": -0.1229801260906717, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.040099695324897766}, {"id": 2425, "seek": 779112, "start": 7792.08, "end": 7797.12, "text": " an infinite number of micro-improvement papers along a particular direction that is almost", "tokens": [50412, 364, 13785, 1230, 295, 4532, 12, 332, 46955, 518, 10577, 2051, 257, 1729, 3513, 300, 307, 1920, 50664], "temperature": 0.0, "avg_logprob": -0.15625244589412915, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.015629781410098076}, {"id": 2426, "seek": 779112, "start": 7797.12, "end": 7802.0, "text": " certainly a local optimum, and we're just digging into that local optimum with ever more papers and", "tokens": [50664, 3297, 257, 2654, 39326, 11, 293, 321, 434, 445, 17343, 666, 300, 2654, 39326, 365, 1562, 544, 10577, 293, 50908], "temperature": 0.0, "avg_logprob": -0.15625244589412915, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.015629781410098076}, {"id": 2427, "seek": 779112, "start": 7802.0, "end": 7808.08, "text": " never more, you know, minimal publishable units when this large amount of manpower that has come", "tokens": [50908, 1128, 544, 11, 291, 458, 11, 13206, 11374, 712, 6815, 562, 341, 2416, 2372, 295, 587, 9513, 300, 575, 808, 51212], "temperature": 0.0, "avg_logprob": -0.15625244589412915, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.015629781410098076}, {"id": 2428, "seek": 779112, "start": 7808.08, "end": 7814.4, "text": " into the field or is moving around, we really need to have a greater diversity of research in", "tokens": [51212, 666, 264, 2519, 420, 307, 2684, 926, 11, 321, 534, 643, 281, 362, 257, 5044, 8811, 295, 2132, 294, 51528], "temperature": 0.0, "avg_logprob": -0.15625244589412915, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.015629781410098076}, {"id": 2429, "seek": 781440, "start": 7814.4, "end": 7821.679999999999, "text": " machine learning, within deep learning, within AI, and so like we are making very poor use of our", "tokens": [50364, 3479, 2539, 11, 1951, 2452, 2539, 11, 1951, 7318, 11, 293, 370, 411, 321, 366, 1455, 588, 4716, 764, 295, 527, 50728], "temperature": 0.0, "avg_logprob": -0.16561037785298116, "compression_ratio": 1.728395061728395, "no_speech_prob": 0.3578752279281616}, {"id": 2430, "seek": 781440, "start": 7821.679999999999, "end": 7826.32, "text": " research, you know, manpower right now, and we see that very much at NeurIPS today.", "tokens": [50728, 2132, 11, 291, 458, 11, 587, 9513, 558, 586, 11, 293, 321, 536, 300, 588, 709, 412, 1734, 374, 40, 6273, 965, 13, 50960], "temperature": 0.0, "avg_logprob": -0.16561037785298116, "compression_ratio": 1.728395061728395, "no_speech_prob": 0.3578752279281616}, {"id": 2431, "seek": 781440, "start": 7826.32, "end": 7829.2, "text": " Yeah, I mean, Sarah Hooker talked about the hardware lottery, you know, being stuck in a", "tokens": [50960, 865, 11, 286, 914, 11, 9519, 33132, 260, 2825, 466, 264, 8837, 27391, 11, 291, 458, 11, 885, 5541, 294, 257, 51104], "temperature": 0.0, "avg_logprob": -0.16561037785298116, "compression_ratio": 1.728395061728395, "no_speech_prob": 0.3578752279281616}, {"id": 2432, "seek": 781440, "start": 7829.2, "end": 7833.599999999999, "text": " basin of attraction determined by hardware, but there's also an idea lottery. It might just be", "tokens": [51104, 34863, 295, 17672, 9540, 538, 8837, 11, 457, 456, 311, 611, 364, 1558, 27391, 13, 467, 1062, 445, 312, 51324], "temperature": 0.0, "avg_logprob": -0.16561037785298116, "compression_ratio": 1.728395061728395, "no_speech_prob": 0.3578752279281616}, {"id": 2433, "seek": 781440, "start": 7833.599999999999, "end": 7838.32, "text": " the case that NeurIPS historically has always been very connectionist anyway. I mean, maybe it", "tokens": [51324, 264, 1389, 300, 1734, 374, 40, 6273, 16180, 575, 1009, 668, 588, 4984, 468, 4033, 13, 286, 914, 11, 1310, 309, 51560], "temperature": 0.0, "avg_logprob": -0.16561037785298116, "compression_ratio": 1.728395061728395, "no_speech_prob": 0.3578752279281616}, {"id": 2434, "seek": 781440, "start": 7838.32, "end": 7841.5199999999995, "text": " hasn't, right? That's one of the ironies, but it's something as well. I wasn't aware of that. Okay.", "tokens": [51560, 6132, 380, 11, 558, 30, 663, 311, 472, 295, 264, 6497, 530, 11, 457, 309, 311, 746, 382, 731, 13, 286, 2067, 380, 3650, 295, 300, 13, 1033, 13, 51720], "temperature": 0.0, "avg_logprob": -0.16561037785298116, "compression_ratio": 1.728395061728395, "no_speech_prob": 0.3578752279281616}, {"id": 2435, "seek": 784152, "start": 7841.52, "end": 7847.92, "text": " Oh, absolutely not. I mean, in fact, the joke is, right, that NeurIPS started in the 80s,", "tokens": [50364, 876, 11, 3122, 406, 13, 286, 914, 11, 294, 1186, 11, 264, 7647, 307, 11, 558, 11, 300, 1734, 374, 40, 6273, 1409, 294, 264, 4688, 82, 11, 50684], "temperature": 0.0, "avg_logprob": -0.12031803611947708, "compression_ratio": 1.701818181818182, "no_speech_prob": 0.003878433257341385}, {"id": 2436, "seek": 784152, "start": 7847.92, "end": 7852.400000000001, "text": " it was called Neural Information Processing Systems, and by the 90s, it should have become", "tokens": [50684, 309, 390, 1219, 1734, 1807, 15357, 31093, 278, 27059, 11, 293, 538, 264, 4289, 82, 11, 309, 820, 362, 1813, 50908], "temperature": 0.0, "avg_logprob": -0.12031803611947708, "compression_ratio": 1.701818181818182, "no_speech_prob": 0.003878433257341385}, {"id": 2437, "seek": 784152, "start": 7853.040000000001, "end": 7857.6, "text": " BIPs for Patient Information Processing Systems, right? There was this study that they did at one", "tokens": [50940, 363, 9139, 82, 337, 25173, 15357, 31093, 278, 27059, 11, 558, 30, 821, 390, 341, 2979, 300, 436, 630, 412, 472, 51168], "temperature": 0.0, "avg_logprob": -0.12031803611947708, "compression_ratio": 1.701818181818182, "no_speech_prob": 0.003878433257341385}, {"id": 2438, "seek": 784152, "start": 7857.6, "end": 7862.320000000001, "text": " point of predictors of acceptance and rejection among words in the title, and the biggest predictor", "tokens": [51168, 935, 295, 6069, 830, 295, 20351, 293, 26044, 3654, 2283, 294, 264, 4876, 11, 293, 264, 3880, 6069, 284, 51404], "temperature": 0.0, "avg_logprob": -0.12031803611947708, "compression_ratio": 1.701818181818182, "no_speech_prob": 0.003878433257341385}, {"id": 2439, "seek": 784152, "start": 7862.320000000001, "end": 7867.120000000001, "text": " of rejection was the world neural. Really? And this was very famous in the field, because", "tokens": [51404, 295, 26044, 390, 264, 1002, 18161, 13, 4083, 30, 400, 341, 390, 588, 4618, 294, 264, 2519, 11, 570, 51644], "temperature": 0.0, "avg_logprob": -0.12031803611947708, "compression_ratio": 1.701818181818182, "no_speech_prob": 0.003878433257341385}, {"id": 2440, "seek": 786712, "start": 7867.2, "end": 7872.24, "text": " indeed, if you could, you know, 1990 something, you were submitting papers to NIPs with the", "tokens": [50368, 6451, 11, 498, 291, 727, 11, 291, 458, 11, 13384, 746, 11, 291, 645, 31836, 10577, 281, 426, 9139, 82, 365, 264, 50620], "temperature": 0.0, "avg_logprob": -0.14267433873864988, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.021905120462179184}, {"id": 2441, "seek": 786712, "start": 7872.24, "end": 7876.8, "text": " world neural in the title, you didn't know what you were doing. And then in the 2000s, right,", "tokens": [50620, 1002, 18161, 294, 264, 4876, 11, 291, 994, 380, 458, 437, 291, 645, 884, 13, 400, 550, 294, 264, 8132, 82, 11, 558, 11, 50848], "temperature": 0.0, "avg_logprob": -0.14267433873864988, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.021905120462179184}, {"id": 2442, "seek": 786712, "start": 7876.8, "end": 7882.24, "text": " it became BIPs, or should have become BIPs, sorry, KIPs, Kernal Information Processing Systems.", "tokens": [50848, 309, 3062, 363, 9139, 82, 11, 420, 820, 362, 1813, 363, 9139, 82, 11, 2597, 11, 591, 9139, 82, 11, 40224, 304, 15357, 31093, 278, 27059, 13, 51120], "temperature": 0.0, "avg_logprob": -0.14267433873864988, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.021905120462179184}, {"id": 2443, "seek": 786712, "start": 7882.24, "end": 7887.2, "text": " And in fact, I remember having lunch with Yoshio Bingo at the ICML in Montreal in 2009,", "tokens": [51120, 400, 294, 1186, 11, 286, 1604, 1419, 6349, 365, 38949, 1004, 363, 18459, 412, 264, 14360, 12683, 294, 34180, 294, 11453, 11, 51368], "temperature": 0.0, "avg_logprob": -0.14267433873864988, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.021905120462179184}, {"id": 2444, "seek": 786712, "start": 7887.2, "end": 7891.44, "text": " and we were talking about this, right? The fact that every day kid, and, you know,", "tokens": [51368, 293, 321, 645, 1417, 466, 341, 11, 558, 30, 440, 1186, 300, 633, 786, 1636, 11, 293, 11, 291, 458, 11, 51580], "temperature": 0.0, "avg_logprob": -0.14267433873864988, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.021905120462179184}, {"id": 2445, "seek": 786712, "start": 7891.44, "end": 7895.68, "text": " not a new paradigm, but another one of the same paradigm seems to now be on top, right?", "tokens": [51580, 406, 257, 777, 24709, 11, 457, 1071, 472, 295, 264, 912, 24709, 2544, 281, 586, 312, 322, 1192, 11, 558, 30, 51792], "temperature": 0.0, "avg_logprob": -0.14267433873864988, "compression_ratio": 1.6615384615384616, "no_speech_prob": 0.021905120462179184}, {"id": 2446, "seek": 789568, "start": 7895.68, "end": 7899.52, "text": " And, you know, he asked, like, so what is the next decade going to be? And I said,", "tokens": [50364, 400, 11, 291, 458, 11, 415, 2351, 11, 411, 11, 370, 437, 307, 264, 958, 10378, 516, 281, 312, 30, 400, 286, 848, 11, 50556], "temperature": 0.0, "avg_logprob": -0.11822116851806641, "compression_ratio": 1.7269736842105263, "no_speech_prob": 0.006679817568510771}, {"id": 2447, "seek": 789568, "start": 7899.52, "end": 7904.72, "text": " it's going to be DIPs, Deep Information Processing Systems. And then we both laughed,", "tokens": [50556, 309, 311, 516, 281, 312, 413, 9139, 82, 11, 14895, 15357, 31093, 278, 27059, 13, 400, 550, 321, 1293, 20881, 11, 50816], "temperature": 0.0, "avg_logprob": -0.11822116851806641, "compression_ratio": 1.7269736842105263, "no_speech_prob": 0.006679817568510771}, {"id": 2448, "seek": 789568, "start": 7904.72, "end": 7909.280000000001, "text": " and I could tell that I believe this, but he, Yoshio Bingo, was actually skeptical of this.", "tokens": [50816, 293, 286, 727, 980, 300, 286, 1697, 341, 11, 457, 415, 11, 38949, 1004, 363, 18459, 11, 390, 767, 28601, 295, 341, 13, 51044], "temperature": 0.0, "avg_logprob": -0.11822116851806641, "compression_ratio": 1.7269736842105263, "no_speech_prob": 0.006679817568510771}, {"id": 2449, "seek": 789568, "start": 7909.280000000001, "end": 7913.92, "text": " So, you know, the deep, little did we know, right? If somebody told us that, you know,", "tokens": [51044, 407, 11, 291, 458, 11, 264, 2452, 11, 707, 630, 321, 458, 11, 558, 30, 759, 2618, 1907, 505, 300, 11, 291, 458, 11, 51276], "temperature": 0.0, "avg_logprob": -0.11822116851806641, "compression_ratio": 1.7269736842105263, "no_speech_prob": 0.006679817568510771}, {"id": 2450, "seek": 789568, "start": 7913.92, "end": 7916.96, "text": " this is going to be on the page of the, on the front page of the New York Times,", "tokens": [51276, 341, 307, 516, 281, 312, 322, 264, 3028, 295, 264, 11, 322, 264, 1868, 3028, 295, 264, 1873, 3609, 11366, 11, 51428], "temperature": 0.0, "avg_logprob": -0.11822116851806641, "compression_ratio": 1.7269736842105263, "no_speech_prob": 0.006679817568510771}, {"id": 2451, "seek": 789568, "start": 7916.96, "end": 7921.360000000001, "text": " in a couple of years would be like, what are you smoking, right? So the way to which this decade", "tokens": [51428, 294, 257, 1916, 295, 924, 576, 312, 411, 11, 437, 366, 291, 14055, 11, 558, 30, 407, 264, 636, 281, 597, 341, 10378, 51648], "temperature": 0.0, "avg_logprob": -0.11822116851806641, "compression_ratio": 1.7269736842105263, "no_speech_prob": 0.006679817568510771}, {"id": 2452, "seek": 792136, "start": 7921.36, "end": 7926.32, "text": " has been DIPs is just mind-blowing, but looking forward, right? And to this point of, you know,", "tokens": [50364, 575, 668, 413, 9139, 82, 307, 445, 1575, 12, 43788, 11, 457, 1237, 2128, 11, 558, 30, 400, 281, 341, 935, 295, 11, 291, 458, 11, 50612], "temperature": 0.0, "avg_logprob": -0.11926034345465192, "compression_ratio": 1.5683453237410072, "no_speech_prob": 0.07574837654829025}, {"id": 2453, "seek": 792136, "start": 7926.32, "end": 7931.28, "text": " diversity in research approaches, I think if you extrapolate naively from the past,", "tokens": [50612, 8811, 294, 2132, 11587, 11, 286, 519, 498, 291, 48224, 473, 1667, 3413, 490, 264, 1791, 11, 50860], "temperature": 0.0, "avg_logprob": -0.11926034345465192, "compression_ratio": 1.5683453237410072, "no_speech_prob": 0.07574837654829025}, {"id": 2454, "seek": 792136, "start": 7931.28, "end": 7935.599999999999, "text": " the next decade will be about something else. And the trillion-dollar question", "tokens": [50860, 264, 958, 10378, 486, 312, 466, 746, 1646, 13, 400, 264, 18723, 12, 40485, 1168, 51076], "temperature": 0.0, "avg_logprob": -0.11926034345465192, "compression_ratio": 1.5683453237410072, "no_speech_prob": 0.07574837654829025}, {"id": 2455, "seek": 792136, "start": 7935.599999999999, "end": 7941.839999999999, "text": " is what, what is that else going to be? Amazing. Okay. You watched Charma's talk, right?", "tokens": [51076, 307, 437, 11, 437, 307, 300, 1646, 516, 281, 312, 30, 14165, 13, 1033, 13, 509, 6337, 4327, 1696, 311, 751, 11, 558, 30, 51388], "temperature": 0.0, "avg_logprob": -0.11926034345465192, "compression_ratio": 1.5683453237410072, "no_speech_prob": 0.07574837654829025}, {"id": 2456, "seek": 792136, "start": 7941.839999999999, "end": 7946.4, "text": " Yeah. What's your high-level view? I thought it was a nice talk. I thought it was a very", "tokens": [51388, 865, 13, 708, 311, 428, 1090, 12, 12418, 1910, 30, 286, 1194, 309, 390, 257, 1481, 751, 13, 286, 1194, 309, 390, 257, 588, 51616], "temperature": 0.0, "avg_logprob": -0.11926034345465192, "compression_ratio": 1.5683453237410072, "no_speech_prob": 0.07574837654829025}, {"id": 2457, "seek": 794640, "start": 7946.4, "end": 7950.719999999999, "text": " appropriate talk for an opening talk at the conference. Actually, if New Europe's had,", "tokens": [50364, 6854, 751, 337, 364, 5193, 751, 412, 264, 7586, 13, 5135, 11, 498, 1873, 3315, 311, 632, 11, 50580], "temperature": 0.0, "avg_logprob": -0.13295281519655322, "compression_ratio": 1.6967509025270757, "no_speech_prob": 0.08493467420339584}, {"id": 2458, "seek": 794640, "start": 7950.719999999999, "end": 7956.24, "text": " like, some conferences, a dinner talk, right? Which is supposed to be interesting, but not as,", "tokens": [50580, 411, 11, 512, 22032, 11, 257, 6148, 751, 11, 558, 30, 3013, 307, 3442, 281, 312, 1880, 11, 457, 406, 382, 11, 50856], "temperature": 0.0, "avg_logprob": -0.13295281519655322, "compression_ratio": 1.6967509025270757, "no_speech_prob": 0.08493467420339584}, {"id": 2459, "seek": 794640, "start": 7956.24, "end": 7959.839999999999, "text": " you know, deep or as technical as other. This would have been the perfect dinner talk for", "tokens": [50856, 291, 458, 11, 2452, 420, 382, 6191, 382, 661, 13, 639, 576, 362, 668, 264, 2176, 6148, 751, 337, 51036], "temperature": 0.0, "avg_logprob": -0.13295281519655322, "compression_ratio": 1.6967509025270757, "no_speech_prob": 0.08493467420339584}, {"id": 2460, "seek": 794640, "start": 7959.839999999999, "end": 7965.5199999999995, "text": " New Europe's, because the topic is very current, right? Our machine's sentient. And, you know,", "tokens": [51036, 1873, 3315, 311, 11, 570, 264, 4829, 307, 588, 2190, 11, 558, 30, 2621, 3479, 311, 2279, 1196, 13, 400, 11, 291, 458, 11, 51320], "temperature": 0.0, "avg_logprob": -0.13295281519655322, "compression_ratio": 1.6967509025270757, "no_speech_prob": 0.08493467420339584}, {"id": 2461, "seek": 794640, "start": 7965.5199999999995, "end": 7970.879999999999, "text": " who better to talk about it than Dave Chalmers, right? The world's expert on, on, on, on consciousness,", "tokens": [51320, 567, 1101, 281, 751, 466, 309, 813, 11017, 761, 304, 18552, 11, 558, 30, 440, 1002, 311, 5844, 322, 11, 322, 11, 322, 11, 322, 10081, 11, 51588], "temperature": 0.0, "avg_logprob": -0.13295281519655322, "compression_ratio": 1.6967509025270757, "no_speech_prob": 0.08493467420339584}, {"id": 2462, "seek": 797088, "start": 7970.88, "end": 7977.12, "text": " right? And by and large, I thought the talk was excellent. In fact, you know, when journalists", "tokens": [50364, 558, 30, 400, 538, 293, 2416, 11, 286, 1194, 264, 751, 390, 7103, 13, 682, 1186, 11, 291, 458, 11, 562, 19535, 50676], "temperature": 0.0, "avg_logprob": -0.0963112561757328, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.01204445119947195}, {"id": 2463, "seek": 797088, "start": 7977.12, "end": 7981.36, "text": " ask me questions, you know, consciousness is like one of their top three, right? Along with", "tokens": [50676, 1029, 385, 1651, 11, 291, 458, 11, 10081, 307, 411, 472, 295, 641, 1192, 1045, 11, 558, 30, 17457, 365, 50888], "temperature": 0.0, "avg_logprob": -0.0963112561757328, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.01204445119947195}, {"id": 2464, "seek": 797088, "start": 7981.36, "end": 7986.08, "text": " Terminator and, you know, Unfairness or something like that, right? And I will point them to this", "tokens": [50888, 19835, 31927, 293, 11, 291, 458, 11, 8170, 1246, 1287, 420, 746, 411, 300, 11, 558, 30, 400, 286, 486, 935, 552, 281, 341, 51124], "temperature": 0.0, "avg_logprob": -0.0963112561757328, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.01204445119947195}, {"id": 2465, "seek": 797088, "start": 7986.08, "end": 7992.88, "text": " talk because it kind of like lays out, you know, the, you know, the ground. And, you know, it's good", "tokens": [51124, 751, 570, 309, 733, 295, 411, 32714, 484, 11, 291, 458, 11, 264, 11, 291, 458, 11, 264, 2727, 13, 400, 11, 291, 458, 11, 309, 311, 665, 51464], "temperature": 0.0, "avg_logprob": -0.0963112561757328, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.01204445119947195}, {"id": 2466, "seek": 797088, "start": 7992.88, "end": 7998.88, "text": " for people to at least have those things in mind. At the end of the day, so I think, of course,", "tokens": [51464, 337, 561, 281, 412, 1935, 362, 729, 721, 294, 1575, 13, 1711, 264, 917, 295, 264, 786, 11, 370, 286, 519, 11, 295, 1164, 11, 51764], "temperature": 0.0, "avg_logprob": -0.0963112561757328, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.01204445119947195}, {"id": 2467, "seek": 799888, "start": 7998.88, "end": 8004.56, "text": " the notion that Lambda was sentient is, you know, ridiculous, as, as most of us do.", "tokens": [50364, 264, 10710, 300, 45691, 390, 2279, 1196, 307, 11, 291, 458, 11, 11083, 11, 382, 11, 382, 881, 295, 505, 360, 13, 50648], "temperature": 0.0, "avg_logprob": -0.11970599285967938, "compression_ratio": 1.8278145695364238, "no_speech_prob": 0.011312499642372131}, {"id": 2468, "seek": 799888, "start": 8005.28, "end": 8010.4800000000005, "text": " You could ask a slightly more fine-going question was if, if, if, if, if consciousness is on a", "tokens": [50684, 509, 727, 1029, 257, 4748, 544, 2489, 12, 8102, 1168, 390, 498, 11, 498, 11, 498, 11, 498, 11, 498, 10081, 307, 322, 257, 50944], "temperature": 0.0, "avg_logprob": -0.11970599285967938, "compression_ratio": 1.8278145695364238, "no_speech_prob": 0.011312499642372131}, {"id": 2469, "seek": 799888, "start": 8010.4800000000005, "end": 8015.68, "text": " continuum, right? Which I think Dave believes in. And if you believe in like this, you know,", "tokens": [50944, 36120, 11, 558, 30, 3013, 286, 519, 11017, 12307, 294, 13, 400, 498, 291, 1697, 294, 411, 341, 11, 291, 458, 11, 51204], "temperature": 0.0, "avg_logprob": -0.11970599285967938, "compression_ratio": 1.8278145695364238, "no_speech_prob": 0.011312499642372131}, {"id": 2470, "seek": 799888, "start": 8015.68, "end": 8020.0, "text": " IT theory and phi and whatnot, you know, like, phi is never zero, right? So there's always some", "tokens": [51204, 6783, 5261, 293, 13107, 293, 25882, 11, 291, 458, 11, 411, 11, 13107, 307, 1128, 4018, 11, 558, 30, 407, 456, 311, 1009, 512, 51420], "temperature": 0.0, "avg_logprob": -0.11970599285967938, "compression_ratio": 1.8278145695364238, "no_speech_prob": 0.011312499642372131}, {"id": 2471, "seek": 799888, "start": 8020.0, "end": 8024.64, "text": " consciousness, right? Pensychism and whatnot. I'm not saying I believe in that. We could,", "tokens": [51420, 10081, 11, 558, 30, 45035, 16384, 1434, 293, 25882, 13, 286, 478, 406, 1566, 286, 1697, 294, 300, 13, 492, 727, 11, 51652], "temperature": 0.0, "avg_logprob": -0.11970599285967938, "compression_ratio": 1.8278145695364238, "no_speech_prob": 0.011312499642372131}, {"id": 2472, "seek": 799888, "start": 8024.64, "end": 8028.4800000000005, "text": " we could go into the, but like, if you believe in that, then you can ask, well, on that scale,", "tokens": [51652, 321, 727, 352, 666, 264, 11, 457, 411, 11, 498, 291, 1697, 294, 300, 11, 550, 291, 393, 1029, 11, 731, 11, 322, 300, 4373, 11, 51844], "temperature": 0.0, "avg_logprob": -0.11970599285967938, "compression_ratio": 1.8278145695364238, "no_speech_prob": 0.011312499642372131}, {"id": 2473, "seek": 802848, "start": 8028.48, "end": 8034.879999999999, "text": " you know, where is Lambda? Where are these large language models? And, and, and surely higher than", "tokens": [50364, 291, 458, 11, 689, 307, 45691, 30, 2305, 366, 613, 2416, 2856, 5245, 30, 400, 11, 293, 11, 293, 11468, 2946, 813, 50684], "temperature": 0.0, "avg_logprob": -0.10052089033455684, "compression_ratio": 1.6937269372693726, "no_speech_prob": 0.007219754625111818}, {"id": 2474, "seek": 802848, "start": 8034.879999999999, "end": 8040.959999999999, "text": " previous AI systems, right? But in my view, still very, very, very far. And I think what you want", "tokens": [50684, 3894, 7318, 3652, 11, 558, 30, 583, 294, 452, 1910, 11, 920, 588, 11, 588, 11, 588, 1400, 13, 400, 286, 519, 437, 291, 528, 50988], "temperature": 0.0, "avg_logprob": -0.10052089033455684, "compression_ratio": 1.6937269372693726, "no_speech_prob": 0.007219754625111818}, {"id": 2475, "seek": 802848, "start": 8040.959999999999, "end": 8045.839999999999, "text": " to keep in mind is that consciousness does not, does not increase continuously. Precisely,", "tokens": [50988, 281, 1066, 294, 1575, 307, 300, 10081, 775, 406, 11, 775, 406, 3488, 15684, 13, 48746, 736, 11, 51232], "temperature": 0.0, "avg_logprob": -0.10052089033455684, "compression_ratio": 1.6937269372693726, "no_speech_prob": 0.007219754625111818}, {"id": 2476, "seek": 802848, "start": 8045.839999999999, "end": 8051.2, "text": " there's these transitions where you go, you know, more is different is the, is the famous,", "tokens": [51232, 456, 311, 613, 23767, 689, 291, 352, 11, 291, 458, 11, 544, 307, 819, 307, 264, 11, 307, 264, 4618, 11, 51500], "temperature": 0.0, "avg_logprob": -0.10052089033455684, "compression_ratio": 1.6937269372693726, "no_speech_prob": 0.007219754625111818}, {"id": 2477, "seek": 802848, "start": 8051.2, "end": 8055.5199999999995, "text": " you know, phrase about emergence, right? Consciousness is very much an emerging,", "tokens": [51500, 291, 458, 11, 9535, 466, 36211, 11, 558, 30, 6923, 4139, 1287, 307, 588, 709, 364, 14989, 11, 51716], "temperature": 0.0, "avg_logprob": -0.10052089033455684, "compression_ratio": 1.6937269372693726, "no_speech_prob": 0.007219754625111818}, {"id": 2478, "seek": 805552, "start": 8055.6, "end": 8059.84, "text": " you know, phenomenon. And I think what happens is that there are points at which your", "tokens": [50368, 291, 458, 11, 14029, 13, 400, 286, 519, 437, 2314, 307, 300, 456, 366, 2793, 412, 597, 428, 50580], "temperature": 0.0, "avg_logprob": -0.11800524166652135, "compression_ratio": 1.8032128514056225, "no_speech_prob": 0.043945979326963425}, {"id": 2479, "seek": 805552, "start": 8059.84, "end": 8064.160000000001, "text": " consciousness will leap. Maybe a thermostat does have consciousness, like, you know,", "tokens": [50580, 10081, 486, 19438, 13, 2704, 257, 8810, 39036, 775, 362, 10081, 11, 411, 11, 291, 458, 11, 50796], "temperature": 0.0, "avg_logprob": -0.11800524166652135, "compression_ratio": 1.8032128514056225, "no_speech_prob": 0.043945979326963425}, {"id": 2480, "seek": 805552, "start": 8064.96, "end": 8069.360000000001, "text": " or, you know, or purpose or whatever, right? Like, like people in, like people like McCarthy,", "tokens": [50836, 420, 11, 291, 458, 11, 420, 4334, 420, 2035, 11, 558, 30, 1743, 11, 411, 561, 294, 11, 411, 561, 411, 44085, 11, 51056], "temperature": 0.0, "avg_logprob": -0.11800524166652135, "compression_ratio": 1.8032128514056225, "no_speech_prob": 0.043945979326963425}, {"id": 2481, "seek": 805552, "start": 8069.360000000001, "end": 8074.4800000000005, "text": " for example, had had had that as an example. But the amount of consciousness is minuscule.", "tokens": [51056, 337, 1365, 11, 632, 632, 632, 300, 382, 364, 1365, 13, 583, 264, 2372, 295, 10081, 307, 3175, 66, 2271, 13, 51312], "temperature": 0.0, "avg_logprob": -0.11800524166652135, "compression_ratio": 1.8032128514056225, "no_speech_prob": 0.043945979326963425}, {"id": 2482, "seek": 805552, "start": 8074.4800000000005, "end": 8080.64, "text": " And, and that, and the way I will put that is that these large language models still have not", "tokens": [51312, 400, 11, 293, 300, 11, 293, 264, 636, 286, 486, 829, 300, 307, 300, 613, 2416, 2856, 5245, 920, 362, 406, 51620], "temperature": 0.0, "avg_logprob": -0.11800524166652135, "compression_ratio": 1.8032128514056225, "no_speech_prob": 0.043945979326963425}, {"id": 2483, "seek": 808064, "start": 8080.64, "end": 8085.360000000001, "text": " passed that first threshold. Interesting. So, so in a similar way to some of the discussion", "tokens": [50364, 4678, 300, 700, 14678, 13, 14711, 13, 407, 11, 370, 294, 257, 2531, 636, 281, 512, 295, 264, 5017, 50600], "temperature": 0.0, "avg_logprob": -0.15006463667925665, "compression_ratio": 1.7097791798107256, "no_speech_prob": 0.05569960176944733}, {"id": 2484, "seek": 808064, "start": 8085.360000000001, "end": 8090.160000000001, "text": " about large language models, there are kind of scaling breaks in the levels of consciousness.", "tokens": [50600, 466, 2416, 2856, 5245, 11, 456, 366, 733, 295, 21589, 9857, 294, 264, 4358, 295, 10081, 13, 50840], "temperature": 0.0, "avg_logprob": -0.15006463667925665, "compression_ratio": 1.7097791798107256, "no_speech_prob": 0.05569960176944733}, {"id": 2485, "seek": 808064, "start": 8090.160000000001, "end": 8093.92, "text": " I mean, Chalmers made the comment, though, that rather than it being a pure continuum,", "tokens": [50840, 286, 914, 11, 761, 304, 18552, 1027, 264, 2871, 11, 1673, 11, 300, 2831, 813, 309, 885, 257, 6075, 36120, 11, 51028], "temperature": 0.0, "avg_logprob": -0.15006463667925665, "compression_ratio": 1.7097791798107256, "no_speech_prob": 0.05569960176944733}, {"id": 2486, "seek": 808064, "start": 8093.92, "end": 8098.160000000001, "text": " he said that a bottle was not conscious, but then there was a kind of. No, yes. So very key", "tokens": [51028, 415, 848, 300, 257, 7817, 390, 406, 6648, 11, 457, 550, 456, 390, 257, 733, 295, 13, 883, 11, 2086, 13, 407, 588, 2141, 51240], "temperature": 0.0, "avg_logprob": -0.15006463667925665, "compression_ratio": 1.7097791798107256, "no_speech_prob": 0.05569960176944733}, {"id": 2487, "seek": 808064, "start": 8098.160000000001, "end": 8104.56, "text": " point. Scaling is part of it, but not only. It's not just that. So your cortex to first", "tokens": [51240, 935, 13, 2747, 4270, 307, 644, 295, 309, 11, 457, 406, 787, 13, 467, 311, 406, 445, 300, 13, 407, 428, 33312, 281, 700, 51560], "temperature": 0.0, "avg_logprob": -0.15006463667925665, "compression_ratio": 1.7097791798107256, "no_speech_prob": 0.05569960176944733}, {"id": 2488, "seek": 808064, "start": 8104.56, "end": 8110.160000000001, "text": " approximation is a monkey brain scaled up, right? There was a module there that evolution", "tokens": [51560, 28023, 307, 257, 17847, 3567, 36039, 493, 11, 558, 30, 821, 390, 257, 10088, 456, 300, 9303, 51840], "temperature": 0.0, "avg_logprob": -0.15006463667925665, "compression_ratio": 1.7097791798107256, "no_speech_prob": 0.05569960176944733}, {"id": 2489, "seek": 811016, "start": 8110.16, "end": 8114.96, "text": " discovered, and it really paid to keep making more and more of it. And we can easily speculate why.", "tokens": [50364, 6941, 11, 293, 309, 534, 4835, 281, 1066, 1455, 544, 293, 544, 295, 309, 13, 400, 321, 393, 3612, 40775, 983, 13, 50604], "temperature": 0.0, "avg_logprob": -0.13949083161834103, "compression_ratio": 1.7032640949554896, "no_speech_prob": 0.006282852031290531}, {"id": 2490, "seek": 811016, "start": 8114.96, "end": 8120.32, "text": " But the point is, so let me contrast two things, right? Which is true for consciousness, but also", "tokens": [50604, 583, 264, 935, 307, 11, 370, 718, 385, 8712, 732, 721, 11, 558, 30, 3013, 307, 2074, 337, 10081, 11, 457, 611, 50872], "temperature": 0.0, "avg_logprob": -0.13949083161834103, "compression_ratio": 1.7032640949554896, "no_speech_prob": 0.006282852031290531}, {"id": 2491, "seek": 811016, "start": 8120.32, "end": 8125.92, "text": " for just AI in general. A lot of people are scaling believers and like open AI is the poster child", "tokens": [50872, 337, 445, 7318, 294, 2674, 13, 316, 688, 295, 561, 366, 21589, 23125, 293, 411, 1269, 7318, 307, 264, 17171, 1440, 51152], "temperature": 0.0, "avg_logprob": -0.13949083161834103, "compression_ratio": 1.7032640949554896, "no_speech_prob": 0.006282852031290531}, {"id": 2492, "seek": 811016, "start": 8125.92, "end": 8129.92, "text": " of this in a quite conscious ways. Like, we're just going to scale the heck out of things.", "tokens": [51152, 295, 341, 294, 257, 1596, 6648, 2098, 13, 1743, 11, 321, 434, 445, 516, 281, 4373, 264, 12872, 484, 295, 721, 13, 51352], "temperature": 0.0, "avg_logprob": -0.13949083161834103, "compression_ratio": 1.7032640949554896, "no_speech_prob": 0.006282852031290531}, {"id": 2493, "seek": 811016, "start": 8129.92, "end": 8133.28, "text": " And then a lot of people, like, you know, Gary Marcus being a good example, they just", "tokens": [51352, 400, 550, 257, 688, 295, 561, 11, 411, 11, 291, 458, 11, 13788, 26574, 885, 257, 665, 1365, 11, 436, 445, 51520], "temperature": 0.0, "avg_logprob": -0.13949083161834103, "compression_ratio": 1.7032640949554896, "no_speech_prob": 0.006282852031290531}, {"id": 2494, "seek": 811016, "start": 8133.28, "end": 8137.84, "text": " completely poo poo that they say, like, oh, no, this is a joke. Right. And I think the truth is that", "tokens": [51520, 2584, 36743, 36743, 300, 436, 584, 11, 411, 11, 1954, 11, 572, 11, 341, 307, 257, 7647, 13, 1779, 13, 400, 286, 519, 264, 3494, 307, 300, 51748], "temperature": 0.0, "avg_logprob": -0.13949083161834103, "compression_ratio": 1.7032640949554896, "no_speech_prob": 0.006282852031290531}, {"id": 2495, "seek": 813784, "start": 8138.4800000000005, "end": 8143.12, "text": " scaling is good, right? Again, you know, part of what we are, our intelligence is scaling.", "tokens": [50396, 21589, 307, 665, 11, 558, 30, 3764, 11, 291, 458, 11, 644, 295, 437, 321, 366, 11, 527, 7599, 307, 21589, 13, 50628], "temperature": 0.0, "avg_logprob": -0.135456250408503, "compression_ratio": 1.9087719298245613, "no_speech_prob": 0.007809922099113464}, {"id": 2496, "seek": 813784, "start": 8143.12, "end": 8148.24, "text": " But the question is, what are you scaling? And the things that we're scaling today,", "tokens": [50628, 583, 264, 1168, 307, 11, 437, 366, 291, 21589, 30, 400, 264, 721, 300, 321, 434, 21589, 965, 11, 50884], "temperature": 0.0, "avg_logprob": -0.135456250408503, "compression_ratio": 1.9087719298245613, "no_speech_prob": 0.007809922099113464}, {"id": 2497, "seek": 813784, "start": 8148.24, "end": 8153.360000000001, "text": " it doesn't matter how much we scale them, we never get to human level intelligence or consciousness.", "tokens": [50884, 309, 1177, 380, 1871, 577, 709, 321, 4373, 552, 11, 321, 1128, 483, 281, 1952, 1496, 7599, 420, 10081, 13, 51140], "temperature": 0.0, "avg_logprob": -0.135456250408503, "compression_ratio": 1.9087719298245613, "no_speech_prob": 0.007809922099113464}, {"id": 2498, "seek": 813784, "start": 8153.360000000001, "end": 8158.08, "text": " So I think we need some fundamentally different algorithms, if you want to think at the level", "tokens": [51140, 407, 286, 519, 321, 643, 512, 17879, 819, 14642, 11, 498, 291, 528, 281, 519, 412, 264, 1496, 51376], "temperature": 0.0, "avg_logprob": -0.135456250408503, "compression_ratio": 1.9087719298245613, "no_speech_prob": 0.007809922099113464}, {"id": 2499, "seek": 813784, "start": 8158.08, "end": 8162.32, "text": " of algorithms, or fundamentally different architect architectures, if you want to think", "tokens": [51376, 295, 14642, 11, 420, 17879, 819, 6331, 6331, 1303, 11, 498, 291, 528, 281, 519, 51588], "temperature": 0.0, "avg_logprob": -0.135456250408503, "compression_ratio": 1.9087719298245613, "no_speech_prob": 0.007809922099113464}, {"id": 2500, "seek": 813784, "start": 8162.32, "end": 8167.04, "text": " about it in a way, and then scaling those up at some point will give us consciousness.", "tokens": [51588, 466, 309, 294, 257, 636, 11, 293, 550, 21589, 729, 493, 412, 512, 935, 486, 976, 505, 10081, 13, 51824], "temperature": 0.0, "avg_logprob": -0.135456250408503, "compression_ratio": 1.9087719298245613, "no_speech_prob": 0.007809922099113464}, {"id": 2501, "seek": 816704, "start": 8167.04, "end": 8170.88, "text": " If you live that it's possible for a computer to be conscious, but we're not there yet,", "tokens": [50364, 759, 291, 1621, 300, 309, 311, 1944, 337, 257, 3820, 281, 312, 6648, 11, 457, 321, 434, 406, 456, 1939, 11, 50556], "temperature": 0.0, "avg_logprob": -0.10389110316400943, "compression_ratio": 1.770440251572327, "no_speech_prob": 0.006476142909377813}, {"id": 2502, "seek": 816704, "start": 8170.88, "end": 8175.12, "text": " either in terms of the scaling, although actually scaling is actually the easier part of this way,", "tokens": [50556, 2139, 294, 2115, 295, 264, 21589, 11, 4878, 767, 21589, 307, 767, 264, 3571, 644, 295, 341, 636, 11, 50768], "temperature": 0.0, "avg_logprob": -0.10389110316400943, "compression_ratio": 1.770440251572327, "no_speech_prob": 0.006476142909377813}, {"id": 2503, "seek": 816704, "start": 8175.12, "end": 8179.2, "text": " we're actually at the point where a computer can have the same amount of computing power that", "tokens": [50768, 321, 434, 767, 412, 264, 935, 689, 257, 3820, 393, 362, 264, 912, 2372, 295, 15866, 1347, 300, 50972], "temperature": 0.0, "avg_logprob": -0.10389110316400943, "compression_ratio": 1.770440251572327, "no_speech_prob": 0.006476142909377813}, {"id": 2504, "seek": 816704, "start": 8179.84, "end": 8184.88, "text": " your brain does, which was not the case before. But the bigger deeper problem, and the more", "tokens": [51004, 428, 3567, 775, 11, 597, 390, 406, 264, 1389, 949, 13, 583, 264, 3801, 7731, 1154, 11, 293, 264, 544, 51256], "temperature": 0.0, "avg_logprob": -0.10389110316400943, "compression_ratio": 1.770440251572327, "no_speech_prob": 0.006476142909377813}, {"id": 2505, "seek": 816704, "start": 8184.88, "end": 8189.6, "text": " fundamental one is like, we need the architecture to scale. Right. And this is where I sympathize,", "tokens": [51256, 8088, 472, 307, 411, 11, 321, 643, 264, 9482, 281, 4373, 13, 1779, 13, 400, 341, 307, 689, 286, 22276, 1125, 11, 51492], "temperature": 0.0, "avg_logprob": -0.10389110316400943, "compression_ratio": 1.770440251572327, "no_speech_prob": 0.006476142909377813}, {"id": 2506, "seek": 816704, "start": 8189.6, "end": 8194.4, "text": " you know, with people like Jeff Hinton, who's just, you know, playing with, you know, ideas", "tokens": [51492, 291, 458, 11, 365, 561, 411, 7506, 389, 12442, 11, 567, 311, 445, 11, 291, 458, 11, 2433, 365, 11, 291, 458, 11, 3487, 51732], "temperature": 0.0, "avg_logprob": -0.10389110316400943, "compression_ratio": 1.770440251572327, "no_speech_prob": 0.006476142909377813}, {"id": 2507, "seek": 819440, "start": 8194.4, "end": 8199.279999999999, "text": " using Mathematica and very small examples, which in some ways, sounds very underpowered,", "tokens": [50364, 1228, 15776, 8615, 2262, 293, 588, 1359, 5110, 11, 597, 294, 512, 2098, 11, 3263, 588, 833, 27178, 11, 50608], "temperature": 0.0, "avg_logprob": -0.1541287307198166, "compression_ratio": 1.7320261437908497, "no_speech_prob": 0.029728978872299194}, {"id": 2508, "seek": 819440, "start": 8199.279999999999, "end": 8204.24, "text": " but I think it's people like that, they are going to come up with the things that we then scale.", "tokens": [50608, 457, 286, 519, 309, 311, 561, 411, 300, 11, 436, 366, 516, 281, 808, 493, 365, 264, 721, 300, 321, 550, 4373, 13, 50856], "temperature": 0.0, "avg_logprob": -0.1541287307198166, "compression_ratio": 1.7320261437908497, "no_speech_prob": 0.029728978872299194}, {"id": 2509, "seek": 819440, "start": 8204.24, "end": 8208.32, "text": " As in fact, it was David Roemmerhardt doing that kind of work that invented backprop.", "tokens": [50856, 1018, 294, 1186, 11, 309, 390, 4389, 3101, 443, 936, 21491, 83, 884, 300, 733, 295, 589, 300, 14479, 646, 79, 1513, 13, 51060], "temperature": 0.0, "avg_logprob": -0.1541287307198166, "compression_ratio": 1.7320261437908497, "no_speech_prob": 0.029728978872299194}, {"id": 2510, "seek": 819440, "start": 8209.199999999999, "end": 8213.119999999999, "text": " Right. If he hadn't invented backprop, this whole industry would not exist. So", "tokens": [51104, 1779, 13, 759, 415, 8782, 380, 14479, 646, 79, 1513, 11, 341, 1379, 3518, 576, 406, 2514, 13, 407, 51300], "temperature": 0.0, "avg_logprob": -0.1541287307198166, "compression_ratio": 1.7320261437908497, "no_speech_prob": 0.029728978872299194}, {"id": 2511, "seek": 819440, "start": 8213.119999999999, "end": 8217.92, "text": " what I think is that the real backprop, the real master algorithm is not there yet,", "tokens": [51300, 437, 286, 519, 307, 300, 264, 957, 646, 79, 1513, 11, 264, 957, 4505, 9284, 307, 406, 456, 1939, 11, 51540], "temperature": 0.0, "avg_logprob": -0.1541287307198166, "compression_ratio": 1.7320261437908497, "no_speech_prob": 0.029728978872299194}, {"id": 2512, "seek": 819440, "start": 8217.92, "end": 8223.6, "text": " and we need to discover that first. And then we, and then when we scale that up, which will not", "tokens": [51540, 293, 321, 643, 281, 4411, 300, 700, 13, 400, 550, 321, 11, 293, 550, 562, 321, 4373, 300, 493, 11, 597, 486, 406, 51824], "temperature": 0.0, "avg_logprob": -0.1541287307198166, "compression_ratio": 1.7320261437908497, "no_speech_prob": 0.029728978872299194}, {"id": 2513, "seek": 822360, "start": 8223.6, "end": 8228.960000000001, "text": " be trivial, but will be much easier by comparison, then we'll have, you know, human level, intelligence,", "tokens": [50364, 312, 26703, 11, 457, 486, 312, 709, 3571, 538, 9660, 11, 550, 321, 603, 362, 11, 291, 458, 11, 1952, 1496, 11, 7599, 11, 50632], "temperature": 0.0, "avg_logprob": -0.12610811345717488, "compression_ratio": 1.5991902834008098, "no_speech_prob": 0.006271276623010635}, {"id": 2514, "seek": 822360, "start": 8228.960000000001, "end": 8234.800000000001, "text": " consciousness, et cetera. Interesting. Okay. And so Charmes is a structuralist computationalist.", "tokens": [50632, 10081, 11, 1030, 11458, 13, 14711, 13, 1033, 13, 400, 370, 4327, 5814, 307, 257, 15067, 468, 28270, 468, 13, 50924], "temperature": 0.0, "avg_logprob": -0.12610811345717488, "compression_ratio": 1.5991902834008098, "no_speech_prob": 0.006271276623010635}, {"id": 2515, "seek": 822360, "start": 8234.800000000001, "end": 8242.720000000001, "text": " So, you know, he thinks information, not biology. And he's also a functionalist, right? So, you", "tokens": [50924, 407, 11, 291, 458, 11, 415, 7309, 1589, 11, 406, 14956, 13, 400, 415, 311, 611, 257, 11745, 468, 11, 558, 30, 407, 11, 291, 51320], "temperature": 0.0, "avg_logprob": -0.12610811345717488, "compression_ratio": 1.5991902834008098, "no_speech_prob": 0.006271276623010635}, {"id": 2516, "seek": 822360, "start": 8242.720000000001, "end": 8248.720000000001, "text": " know, which is very similar to behavior. And, you know, Hillary Putnam made the move that you can", "tokens": [51320, 458, 11, 597, 307, 588, 2531, 281, 5223, 13, 400, 11, 291, 458, 11, 23284, 4935, 5378, 1027, 264, 1286, 300, 291, 393, 51620], "temperature": 0.0, "avg_logprob": -0.12610811345717488, "compression_ratio": 1.5991902834008098, "no_speech_prob": 0.006271276623010635}, {"id": 2517, "seek": 824872, "start": 8248.8, "end": 8253.599999999999, "text": " kind of like represent a computation in any open physical system. And he kind of like used that", "tokens": [50368, 733, 295, 411, 2906, 257, 24903, 294, 604, 1269, 4001, 1185, 13, 400, 415, 733, 295, 411, 1143, 300, 50608], "temperature": 0.0, "avg_logprob": -0.08652318269014359, "compression_ratio": 1.752442996742671, "no_speech_prob": 0.005296955816447735}, {"id": 2518, "seek": 824872, "start": 8253.599999999999, "end": 8258.16, "text": " on, you know, if you follow that line of thought, it almost trivializes computationalism because,", "tokens": [50608, 322, 11, 291, 458, 11, 498, 291, 1524, 300, 1622, 295, 1194, 11, 309, 1920, 26703, 5660, 28270, 1434, 570, 11, 50836], "temperature": 0.0, "avg_logprob": -0.08652318269014359, "compression_ratio": 1.752442996742671, "no_speech_prob": 0.005296955816447735}, {"id": 2519, "seek": 824872, "start": 8258.16, "end": 8262.8, "text": " you know, it leads to panpsychism very, very quickly. So, first of all, I mean, what's your", "tokens": [50836, 291, 458, 11, 309, 6689, 281, 2462, 1878, 16384, 1434, 588, 11, 588, 2661, 13, 407, 11, 700, 295, 439, 11, 286, 914, 11, 437, 311, 428, 51068], "temperature": 0.0, "avg_logprob": -0.08652318269014359, "compression_ratio": 1.752442996742671, "no_speech_prob": 0.005296955816447735}, {"id": 2520, "seek": 824872, "start": 8262.8, "end": 8266.8, "text": " take on this idea that information could give rise to intelligence and consciousness?", "tokens": [51068, 747, 322, 341, 1558, 300, 1589, 727, 976, 6272, 281, 7599, 293, 10081, 30, 51268], "temperature": 0.0, "avg_logprob": -0.08652318269014359, "compression_ratio": 1.752442996742671, "no_speech_prob": 0.005296955816447735}, {"id": 2521, "seek": 824872, "start": 8266.8, "end": 8271.439999999999, "text": " So I agree, like most scientists, and I think in particular most computer scientists, that", "tokens": [51268, 407, 286, 3986, 11, 411, 881, 7708, 11, 293, 286, 519, 294, 1729, 881, 3820, 7708, 11, 300, 51500], "temperature": 0.0, "avg_logprob": -0.08652318269014359, "compression_ratio": 1.752442996742671, "no_speech_prob": 0.005296955816447735}, {"id": 2522, "seek": 824872, "start": 8272.16, "end": 8276.88, "text": " to a first approximation, the substrate does not matter. And in particular,", "tokens": [51536, 281, 257, 700, 28023, 11, 264, 27585, 775, 406, 1871, 13, 400, 294, 1729, 11, 51772], "temperature": 0.0, "avg_logprob": -0.08652318269014359, "compression_ratio": 1.752442996742671, "no_speech_prob": 0.005296955816447735}, {"id": 2523, "seek": 827688, "start": 8276.88, "end": 8281.679999999998, "text": " you're not going to convince me that something is not conscious just because it's not biological.", "tokens": [50364, 291, 434, 406, 516, 281, 13447, 385, 300, 746, 307, 406, 6648, 445, 570, 309, 311, 406, 13910, 13, 50604], "temperature": 0.0, "avg_logprob": -0.12134852267727994, "compression_ratio": 1.752, "no_speech_prob": 0.00881680753082037}, {"id": 2524, "seek": 827688, "start": 8282.32, "end": 8286.32, "text": " There is no reason to think that only biological things can have consciousness. Now,", "tokens": [50636, 821, 307, 572, 1778, 281, 519, 300, 787, 13910, 721, 393, 362, 10081, 13, 823, 11, 50836], "temperature": 0.0, "avg_logprob": -0.12134852267727994, "compression_ratio": 1.752, "no_speech_prob": 0.00881680753082037}, {"id": 2525, "seek": 827688, "start": 8286.32, "end": 8292.0, "text": " the deeper problem, and you know, indeed the hard problem, is that so as Dave Chalmers defined it,", "tokens": [50836, 264, 7731, 1154, 11, 293, 291, 458, 11, 6451, 264, 1152, 1154, 11, 307, 300, 370, 382, 11017, 761, 304, 18552, 7642, 309, 11, 51120], "temperature": 0.0, "avg_logprob": -0.12134852267727994, "compression_ratio": 1.752, "no_speech_prob": 0.00881680753082037}, {"id": 2526, "seek": 827688, "start": 8293.039999999999, "end": 8296.16, "text": " so there's a basic fork here, which you've alluded to, which is,", "tokens": [51172, 370, 456, 311, 257, 3875, 17716, 510, 11, 597, 291, 600, 33919, 281, 11, 597, 307, 11, 51328], "temperature": 0.0, "avg_logprob": -0.12134852267727994, "compression_ratio": 1.752, "no_speech_prob": 0.00881680753082037}, {"id": 2527, "seek": 827688, "start": 8297.279999999999, "end": 8303.199999999999, "text": " if consciousness is subjective experience, then all these questions about consciousness are", "tokens": [51384, 498, 10081, 307, 25972, 1752, 11, 550, 439, 613, 1651, 466, 10081, 366, 51680], "temperature": 0.0, "avg_logprob": -0.12134852267727994, "compression_ratio": 1.752, "no_speech_prob": 0.00881680753082037}, {"id": 2528, "seek": 830320, "start": 8303.2, "end": 8309.6, "text": " ultimately unresolvable, because only I have my subjective experience. I know that I'm conscious,", "tokens": [50364, 6284, 517, 495, 401, 17915, 11, 570, 787, 286, 362, 452, 25972, 1752, 13, 286, 458, 300, 286, 478, 6648, 11, 50684], "temperature": 0.0, "avg_logprob": -0.09984144100472947, "compression_ratio": 1.6804123711340206, "no_speech_prob": 0.009542311541736126}, {"id": 2529, "seek": 830320, "start": 8310.16, "end": 8315.12, "text": " no one can persuade me of the contrary. I don't even know if you are conscious, let alone some machine.", "tokens": [50712, 572, 472, 393, 31781, 385, 295, 264, 19506, 13, 286, 500, 380, 754, 458, 498, 291, 366, 6648, 11, 718, 3312, 512, 3479, 13, 50960], "temperature": 0.0, "avg_logprob": -0.09984144100472947, "compression_ratio": 1.6804123711340206, "no_speech_prob": 0.009542311541736126}, {"id": 2530, "seek": 830320, "start": 8315.68, "end": 8321.12, "text": " Right? So if consciousness is an intrinsic property of something that cannot be evaluated", "tokens": [50988, 1779, 30, 407, 498, 10081, 307, 364, 35698, 4707, 295, 746, 300, 2644, 312, 25509, 51260], "temperature": 0.0, "avg_logprob": -0.09984144100472947, "compression_ratio": 1.6804123711340206, "no_speech_prob": 0.009542311541736126}, {"id": 2531, "seek": 830320, "start": 8321.12, "end": 8325.92, "text": " from the outside, then we're doomed. We're never going to answer this question. And maybe that is", "tokens": [51260, 490, 264, 2380, 11, 550, 321, 434, 33847, 13, 492, 434, 1128, 516, 281, 1867, 341, 1168, 13, 400, 1310, 300, 307, 51500], "temperature": 0.0, "avg_logprob": -0.09984144100472947, "compression_ratio": 1.6804123711340206, "no_speech_prob": 0.009542311541736126}, {"id": 2532, "seek": 830320, "start": 8325.92, "end": 8330.320000000002, "text": " the case. Right? So I'm not saying that's false, and you need to always keep that in mind. But now,", "tokens": [51500, 264, 1389, 13, 1779, 30, 407, 286, 478, 406, 1566, 300, 311, 7908, 11, 293, 291, 643, 281, 1009, 1066, 300, 294, 1575, 13, 583, 586, 11, 51720], "temperature": 0.0, "avg_logprob": -0.09984144100472947, "compression_ratio": 1.6804123711340206, "no_speech_prob": 0.009542311541736126}, {"id": 2533, "seek": 833032, "start": 8330.4, "end": 8335.84, "text": " if we're going to make any kind of progress, right, we need to look at what are, to generalize a well", "tokens": [50368, 498, 321, 434, 516, 281, 652, 604, 733, 295, 4205, 11, 558, 11, 321, 643, 281, 574, 412, 437, 366, 11, 281, 2674, 1125, 257, 731, 50640], "temperature": 0.0, "avg_logprob": -0.10798180898030599, "compression_ratio": 1.875, "no_speech_prob": 0.007917966693639755}, {"id": 2534, "seek": 833032, "start": 8335.84, "end": 8341.119999999999, "text": " known term, the external correlates of consciousness. Right? One of those which has been well studied by", "tokens": [50640, 2570, 1433, 11, 264, 8320, 13983, 1024, 295, 10081, 13, 1779, 30, 1485, 295, 729, 597, 575, 668, 731, 9454, 538, 50904], "temperature": 0.0, "avg_logprob": -0.10798180898030599, "compression_ratio": 1.875, "no_speech_prob": 0.007917966693639755}, {"id": 2535, "seek": 833032, "start": 8341.119999999999, "end": 8345.76, "text": " people like Christoph Koch and so on, and I think that's a very good direction, is the neural", "tokens": [50904, 561, 411, 2040, 5317, 40401, 293, 370, 322, 11, 293, 286, 519, 300, 311, 257, 588, 665, 3513, 11, 307, 264, 18161, 51136], "temperature": 0.0, "avg_logprob": -0.10798180898030599, "compression_ratio": 1.875, "no_speech_prob": 0.007917966693639755}, {"id": 2536, "seek": 833032, "start": 8345.76, "end": 8350.0, "text": " correlates of consciousness. Right? What goes on in your brain that correlates with consciousness?", "tokens": [51136, 13983, 1024, 295, 10081, 13, 1779, 30, 708, 1709, 322, 294, 428, 3567, 300, 13983, 1024, 365, 10081, 30, 51348], "temperature": 0.0, "avg_logprob": -0.10798180898030599, "compression_ratio": 1.875, "no_speech_prob": 0.007917966693639755}, {"id": 2537, "seek": 833032, "start": 8350.0, "end": 8354.08, "text": " And we've made a lot of progress with that. You can also talk about what are sort of like the", "tokens": [51348, 400, 321, 600, 1027, 257, 688, 295, 4205, 365, 300, 13, 509, 393, 611, 751, 466, 437, 366, 1333, 295, 411, 264, 51552], "temperature": 0.0, "avg_logprob": -0.10798180898030599, "compression_ratio": 1.875, "no_speech_prob": 0.007917966693639755}, {"id": 2538, "seek": 833032, "start": 8354.08, "end": 8359.76, "text": " informational computational correlates of consciousness. Are there computational structures", "tokens": [51552, 49391, 28270, 13983, 1024, 295, 10081, 13, 2014, 456, 28270, 9227, 51836], "temperature": 0.0, "avg_logprob": -0.10798180898030599, "compression_ratio": 1.875, "no_speech_prob": 0.007917966693639755}, {"id": 2539, "seek": 835976, "start": 8359.76, "end": 8364.64, "text": " that support consciousness and the ones that don't? I think that is also a useful thing to do.", "tokens": [50364, 300, 1406, 10081, 293, 264, 2306, 300, 500, 380, 30, 286, 519, 300, 307, 611, 257, 4420, 551, 281, 360, 13, 50608], "temperature": 0.0, "avg_logprob": -0.11801317003038195, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.008834419772028923}, {"id": 2540, "seek": 835976, "start": 8364.64, "end": 8370.0, "text": " Let's develop. It actually interests this panpsychism because it's not like everything is", "tokens": [50608, 961, 311, 1499, 13, 467, 767, 8847, 341, 2462, 1878, 16384, 1434, 570, 309, 311, 406, 411, 1203, 307, 50876], "temperature": 0.0, "avg_logprob": -0.11801317003038195, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.008834419772028923}, {"id": 2541, "seek": 835976, "start": 8370.0, "end": 8375.2, "text": " consciousness just because it can compute. Some computations after this emergence and these,", "tokens": [50876, 10081, 445, 570, 309, 393, 14722, 13, 2188, 2807, 763, 934, 341, 36211, 293, 613, 11, 51136], "temperature": 0.0, "avg_logprob": -0.11801317003038195, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.008834419772028923}, {"id": 2542, "seek": 835976, "start": 8375.2, "end": 8380.880000000001, "text": " you know, phase transitions may give rise to consciousness. Whereas others, it doesn't matter", "tokens": [51136, 291, 458, 11, 5574, 23767, 815, 976, 6272, 281, 10081, 13, 13813, 2357, 11, 309, 1177, 380, 1871, 51420], "temperature": 0.0, "avg_logprob": -0.11801317003038195, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.008834419772028923}, {"id": 2543, "seek": 835976, "start": 8380.880000000001, "end": 8384.880000000001, "text": " how much of them you have, they will never be conscious. So I think this is also a very useful", "tokens": [51420, 577, 709, 295, 552, 291, 362, 11, 436, 486, 1128, 312, 6648, 13, 407, 286, 519, 341, 307, 611, 257, 588, 4420, 51620], "temperature": 0.0, "avg_logprob": -0.11801317003038195, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.008834419772028923}, {"id": 2544, "seek": 838488, "start": 8384.88, "end": 8391.119999999999, "text": " way to make progress on this question and one to which AI versus, you know, a neuroscience or", "tokens": [50364, 636, 281, 652, 4205, 322, 341, 1168, 293, 472, 281, 597, 7318, 5717, 11, 291, 458, 11, 257, 42762, 420, 50676], "temperature": 0.0, "avg_logprob": -0.1263795159079812, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.011956081725656986}, {"id": 2545, "seek": 838488, "start": 8391.119999999999, "end": 8396.4, "text": " psychology is very well suited to. Interesting. So on the functionalism point, and I think", "tokens": [50676, 15105, 307, 588, 731, 24736, 281, 13, 14711, 13, 407, 322, 264, 11745, 1434, 935, 11, 293, 286, 519, 50940], "temperature": 0.0, "avg_logprob": -0.1263795159079812, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.011956081725656986}, {"id": 2546, "seek": 838488, "start": 8396.4, "end": 8402.08, "text": " Chalmers has been very, very consistent. He uses this kind of calculi to reason about", "tokens": [50940, 761, 304, 18552, 575, 668, 588, 11, 588, 8398, 13, 634, 4960, 341, 733, 295, 4322, 72, 281, 1778, 466, 51224], "temperature": 0.0, "avg_logprob": -0.1263795159079812, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.011956081725656986}, {"id": 2547, "seek": 838488, "start": 8402.08, "end": 8407.759999999998, "text": " intelligence as well. So a system is intelligent if it can perform reasoning, if it can perform", "tokens": [51224, 7599, 382, 731, 13, 407, 257, 1185, 307, 13232, 498, 309, 393, 2042, 21577, 11, 498, 309, 393, 2042, 51508], "temperature": 0.0, "avg_logprob": -0.1263795159079812, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.011956081725656986}, {"id": 2548, "seek": 838488, "start": 8407.759999999998, "end": 8412.32, "text": " planning, if it has sensing and so on. So we have this collection of functions. And then", "tokens": [51508, 5038, 11, 498, 309, 575, 30654, 293, 370, 322, 13, 407, 321, 362, 341, 5765, 295, 6828, 13, 400, 550, 51736], "temperature": 0.0, "avg_logprob": -0.1263795159079812, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.011956081725656986}, {"id": 2549, "seek": 841232, "start": 8412.4, "end": 8416.48, "text": " he's kind of like moved this over to the domain of consciousness. So similarly,", "tokens": [50368, 415, 311, 733, 295, 411, 4259, 341, 670, 281, 264, 9274, 295, 10081, 13, 407, 14138, 11, 50572], "temperature": 0.0, "avg_logprob": -0.10589595194216128, "compression_ratio": 1.8975409836065573, "no_speech_prob": 0.006179210264235735}, {"id": 2550, "seek": 841232, "start": 8416.48, "end": 8423.039999999999, "text": " if a system performs these functions and is used in a positive and a negative way. So some", "tokens": [50572, 498, 257, 1185, 26213, 613, 6828, 293, 307, 1143, 294, 257, 3353, 293, 257, 3671, 636, 13, 407, 512, 50900], "temperature": 0.0, "avg_logprob": -0.10589595194216128, "compression_ratio": 1.8975409836065573, "no_speech_prob": 0.006179210264235735}, {"id": 2551, "seek": 841232, "start": 8423.039999999999, "end": 8428.32, "text": " functions would indicate an absence of consciousness and some functions would, you know, lead to the", "tokens": [50900, 6828, 576, 13330, 364, 17145, 295, 10081, 293, 512, 6828, 576, 11, 291, 458, 11, 1477, 281, 264, 51164], "temperature": 0.0, "avg_logprob": -0.10589595194216128, "compression_ratio": 1.8975409836065573, "no_speech_prob": 0.006179210264235735}, {"id": 2552, "seek": 841232, "start": 8428.32, "end": 8433.76, "text": " presence of consciousness. And it's kind of like leading towards a, you know, touring test for", "tokens": [51164, 6814, 295, 10081, 13, 400, 309, 311, 733, 295, 411, 5775, 3030, 257, 11, 291, 458, 11, 32487, 1500, 337, 51436], "temperature": 0.0, "avg_logprob": -0.10589595194216128, "compression_ratio": 1.8975409836065573, "no_speech_prob": 0.006179210264235735}, {"id": 2553, "seek": 841232, "start": 8433.76, "end": 8438.8, "text": " consciousness. I mean, do you kind of support that? That's a very interesting question. In fact,", "tokens": [51436, 10081, 13, 286, 914, 11, 360, 291, 733, 295, 1406, 300, 30, 663, 311, 257, 588, 1880, 1168, 13, 682, 1186, 11, 51688], "temperature": 0.0, "avg_logprob": -0.10589595194216128, "compression_ratio": 1.8975409836065573, "no_speech_prob": 0.006179210264235735}, {"id": 2554, "seek": 843880, "start": 8438.8, "end": 8443.759999999998, "text": " you know, I was having dinner with Dave after his talk and I actually brought this up because it", "tokens": [50364, 291, 458, 11, 286, 390, 1419, 6148, 365, 11017, 934, 702, 751, 293, 286, 767, 3038, 341, 493, 570, 309, 50612], "temperature": 0.0, "avg_logprob": -0.13481981892231082, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.059956133365631104}, {"id": 2555, "seek": 843880, "start": 8443.759999999998, "end": 8450.16, "text": " wasn't clear from his talk. And I said, look, this is the answer that I usually give to journalists", "tokens": [50612, 2067, 380, 1850, 490, 702, 751, 13, 400, 286, 848, 11, 574, 11, 341, 307, 264, 1867, 300, 286, 2673, 976, 281, 19535, 50932], "temperature": 0.0, "avg_logprob": -0.13481981892231082, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.059956133365631104}, {"id": 2556, "seek": 843880, "start": 8450.16, "end": 8454.08, "text": " when they ask me, you know, will machines ever be conscious and whatnot? And asked me a few,", "tokens": [50932, 562, 436, 1029, 385, 11, 291, 458, 11, 486, 8379, 1562, 312, 6648, 293, 25882, 30, 400, 2351, 385, 257, 1326, 11, 51128], "temperature": 0.0, "avg_logprob": -0.13481981892231082, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.059956133365631104}, {"id": 2557, "seek": 843880, "start": 8454.08, "end": 8458.8, "text": " and asked me if he agreed with it and actually expected him to disagree. But I think again,", "tokens": [51128, 293, 2351, 385, 498, 415, 9166, 365, 309, 293, 767, 5176, 796, 281, 14091, 13, 583, 286, 519, 797, 11, 51364], "temperature": 0.0, "avg_logprob": -0.13481981892231082, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.059956133365631104}, {"id": 2558, "seek": 843880, "start": 8458.8, "end": 8463.519999999999, "text": " don't want to put words in his mouth, but that he agreed, right? And the answer is the following,", "tokens": [51364, 500, 380, 528, 281, 829, 2283, 294, 702, 4525, 11, 457, 300, 415, 9166, 11, 558, 30, 400, 264, 1867, 307, 264, 3480, 11, 51600], "temperature": 0.0, "avg_logprob": -0.13481981892231082, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.059956133365631104}, {"id": 2559, "seek": 846352, "start": 8463.52, "end": 8468.48, "text": " is that human beings, right? As we've discussed, have an amazing tendency to", "tokens": [50364, 307, 300, 1952, 8958, 11, 558, 30, 1018, 321, 600, 7152, 11, 362, 364, 2243, 18187, 281, 50612], "temperature": 0.0, "avg_logprob": -0.10016550584272906, "compression_ratio": 1.6377358490566039, "no_speech_prob": 0.12406357377767563}, {"id": 2560, "seek": 846352, "start": 8468.48, "end": 8473.2, "text": " anthropoformize things. It's reasoning by analogy. And what happens, I used to say,", "tokens": [50612, 22727, 78, 837, 1125, 721, 13, 467, 311, 21577, 538, 21663, 13, 400, 437, 2314, 11, 286, 1143, 281, 584, 11, 50848], "temperature": 0.0, "avg_logprob": -0.10016550584272906, "compression_ratio": 1.6377358490566039, "no_speech_prob": 0.12406357377767563}, {"id": 2561, "seek": 846352, "start": 8473.2, "end": 8477.28, "text": " this is what's going to happen at this point is this is what is already happening is that", "tokens": [50848, 341, 307, 437, 311, 516, 281, 1051, 412, 341, 935, 307, 341, 307, 437, 307, 1217, 2737, 307, 300, 51052], "temperature": 0.0, "avg_logprob": -0.10016550584272906, "compression_ratio": 1.6377358490566039, "no_speech_prob": 0.12406357377767563}, {"id": 2562, "seek": 846352, "start": 8477.28, "end": 8484.0, "text": " as soon as a machine behaves externally, even vaguely like it's consciousness, we immediately", "tokens": [51052, 382, 2321, 382, 257, 3479, 36896, 40899, 11, 754, 13501, 48863, 411, 309, 311, 10081, 11, 321, 4258, 51388], "temperature": 0.0, "avg_logprob": -0.10016550584272906, "compression_ratio": 1.6377358490566039, "no_speech_prob": 0.12406357377767563}, {"id": 2563, "seek": 846352, "start": 8484.0, "end": 8489.28, "text": " start treating it as if it's consciousness. So if you look for 10, 20, 50 years from now,", "tokens": [51388, 722, 15083, 309, 382, 498, 309, 311, 10081, 13, 407, 498, 291, 574, 337, 1266, 11, 945, 11, 2625, 924, 490, 586, 11, 51652], "temperature": 0.0, "avg_logprob": -0.10016550584272906, "compression_ratio": 1.6377358490566039, "no_speech_prob": 0.12406357377767563}, {"id": 2564, "seek": 848928, "start": 8489.28, "end": 8493.92, "text": " we will just treat AI's as if they're consciousness and people won't even ask that question.", "tokens": [50364, 321, 486, 445, 2387, 7318, 311, 382, 498, 436, 434, 10081, 293, 561, 1582, 380, 754, 1029, 300, 1168, 13, 50596], "temperature": 0.0, "avg_logprob": -0.14061710039774578, "compression_ratio": 1.813953488372093, "no_speech_prob": 0.01080260705202818}, {"id": 2565, "seek": 848928, "start": 8493.92, "end": 8498.320000000002, "text": " They will assume AI's are conscious in the same way that we assume that each other,", "tokens": [50596, 814, 486, 6552, 7318, 311, 366, 6648, 294, 264, 912, 636, 300, 321, 6552, 300, 1184, 661, 11, 50816], "temperature": 0.0, "avg_logprob": -0.14061710039774578, "compression_ratio": 1.813953488372093, "no_speech_prob": 0.01080260705202818}, {"id": 2566, "seek": 848928, "start": 8498.320000000002, "end": 8504.16, "text": " that we're conscious, right? But then, and so like from that pragmatic external point of view,", "tokens": [50816, 300, 321, 434, 6648, 11, 558, 30, 583, 550, 11, 293, 370, 411, 490, 300, 46904, 8320, 935, 295, 1910, 11, 51108], "temperature": 0.0, "avg_logprob": -0.14061710039774578, "compression_ratio": 1.813953488372093, "no_speech_prob": 0.01080260705202818}, {"id": 2567, "seek": 848928, "start": 8504.16, "end": 8509.52, "text": " maybe the question is answered, right? But you could be a philosopher or like sort of like a very,", "tokens": [51108, 1310, 264, 1168, 307, 10103, 11, 558, 30, 583, 291, 727, 312, 257, 29805, 420, 411, 1333, 295, 411, 257, 588, 11, 51376], "temperature": 0.0, "avg_logprob": -0.14061710039774578, "compression_ratio": 1.813953488372093, "no_speech_prob": 0.01080260705202818}, {"id": 2568, "seek": 848928, "start": 8509.52, "end": 8514.960000000001, "text": " you know, rigorous, you know, technical person and so like, no, no, no, no, I really want to know", "tokens": [51376, 291, 458, 11, 29882, 11, 291, 458, 11, 6191, 954, 293, 370, 411, 11, 572, 11, 572, 11, 572, 11, 572, 11, 286, 534, 528, 281, 458, 51648], "temperature": 0.0, "avg_logprob": -0.14061710039774578, "compression_ratio": 1.813953488372093, "no_speech_prob": 0.01080260705202818}, {"id": 2569, "seek": 851496, "start": 8514.96, "end": 8519.759999999998, "text": " if things, they may look, you know, conscious from the outside, but are they really, right?", "tokens": [50364, 498, 721, 11, 436, 815, 574, 11, 291, 458, 11, 6648, 490, 264, 2380, 11, 457, 366, 436, 534, 11, 558, 30, 50604], "temperature": 0.0, "avg_logprob": -0.1445752613580049, "compression_ratio": 1.7756410256410255, "no_speech_prob": 0.03671063482761383}, {"id": 2570, "seek": 851496, "start": 8520.32, "end": 8524.72, "text": " But that question, as far as I can tell, unfortunately, at the end of the day is probably", "tokens": [50632, 583, 300, 1168, 11, 382, 1400, 382, 286, 393, 980, 11, 7015, 11, 412, 264, 917, 295, 264, 786, 307, 1391, 50852], "temperature": 0.0, "avg_logprob": -0.1445752613580049, "compression_ratio": 1.7756410256410255, "no_speech_prob": 0.03671063482761383}, {"id": 2571, "seek": 851496, "start": 8524.72, "end": 8529.599999999999, "text": " unanswerable. Now, there's a middle ground between these two things that maybe is where", "tokens": [50852, 517, 43904, 712, 13, 823, 11, 456, 311, 257, 2808, 2727, 1296, 613, 732, 721, 300, 1310, 307, 689, 51096], "temperature": 0.0, "avg_logprob": -0.1445752613580049, "compression_ratio": 1.7756410256410255, "no_speech_prob": 0.03671063482761383}, {"id": 2572, "seek": 851496, "start": 8529.599999999999, "end": 8533.919999999998, "text": " we'll wind up. And to me, sounds like probably the best thing that we're going to be able to do,", "tokens": [51096, 321, 603, 2468, 493, 13, 400, 281, 385, 11, 3263, 411, 1391, 264, 1151, 551, 300, 321, 434, 516, 281, 312, 1075, 281, 360, 11, 51312], "temperature": 0.0, "avg_logprob": -0.1445752613580049, "compression_ratio": 1.7756410256410255, "no_speech_prob": 0.03671063482761383}, {"id": 2573, "seek": 851496, "start": 8533.919999999998, "end": 8538.8, "text": " which is that like, our understanding of the neural informational, et cetera, correlates", "tokens": [51312, 597, 307, 300, 411, 11, 527, 3701, 295, 264, 18161, 49391, 11, 1030, 11458, 11, 13983, 1024, 51556], "temperature": 0.0, "avg_logprob": -0.1445752613580049, "compression_ratio": 1.7756410256410255, "no_speech_prob": 0.03671063482761383}, {"id": 2574, "seek": 851496, "start": 8538.8, "end": 8544.64, "text": " of consciousness evolves to a point where we have the feeling that we do understand consciousness.", "tokens": [51556, 295, 10081, 43737, 281, 257, 935, 689, 321, 362, 264, 2633, 300, 321, 360, 1223, 10081, 13, 51848], "temperature": 0.0, "avg_logprob": -0.1445752613580049, "compression_ratio": 1.7756410256410255, "no_speech_prob": 0.03671063482761383}, {"id": 2575, "seek": 854496, "start": 8544.96, "end": 8548.56, "text": " It's not just the late person calls this consciousness even though haha, it's not like", "tokens": [50364, 467, 311, 406, 445, 264, 3469, 954, 5498, 341, 10081, 754, 1673, 17236, 11, 309, 311, 406, 411, 50544], "temperature": 0.0, "avg_logprob": -0.15012853745131466, "compression_ratio": 1.8514285714285714, "no_speech_prob": 0.002145585836842656}, {"id": 2576, "seek": 854496, "start": 8548.56, "end": 8551.679999999998, "text": " lambda is not conscious, you know, poor bozo, et cetera, et cetera. It's like,", "tokens": [50544, 13607, 307, 406, 6648, 11, 291, 458, 11, 4716, 748, 4765, 11, 1030, 11458, 11, 1030, 11458, 13, 467, 311, 411, 11, 50700], "temperature": 0.0, "avg_logprob": -0.15012853745131466, "compression_ratio": 1.8514285714285714, "no_speech_prob": 0.002145585836842656}, {"id": 2577, "seek": 854496, "start": 8552.4, "end": 8555.839999999998, "text": " you know, there are many analogies to that in the history of science. There used to be a lot of", "tokens": [50736, 291, 458, 11, 456, 366, 867, 16660, 530, 281, 300, 294, 264, 2503, 295, 3497, 13, 821, 1143, 281, 312, 257, 688, 295, 50908], "temperature": 0.0, "avg_logprob": -0.15012853745131466, "compression_ratio": 1.8514285714285714, "no_speech_prob": 0.002145585836842656}, {"id": 2578, "seek": 854496, "start": 8555.839999999998, "end": 8561.279999999999, "text": " things that were like magical, right? And we were like, oh, we're never going to stand like life was", "tokens": [50908, 721, 300, 645, 411, 12066, 11, 558, 30, 400, 321, 645, 411, 11, 1954, 11, 321, 434, 1128, 516, 281, 1463, 411, 993, 390, 51180], "temperature": 0.0, "avg_logprob": -0.15012853745131466, "compression_ratio": 1.8514285714285714, "no_speech_prob": 0.002145585836842656}, {"id": 2579, "seek": 854496, "start": 8561.279999999999, "end": 8565.919999999998, "text": " magical, right? Life did not obey the laws of physics. It's just something else, right? This", "tokens": [51180, 12066, 11, 558, 30, 7720, 630, 406, 19297, 264, 6064, 295, 10649, 13, 467, 311, 445, 746, 1646, 11, 558, 30, 639, 51412], "temperature": 0.0, "avg_logprob": -0.15012853745131466, "compression_ratio": 1.8514285714285714, "no_speech_prob": 0.002145585836842656}, {"id": 2580, "seek": 854496, "start": 8565.919999999998, "end": 8570.24, "text": " sounds laughable right now, but it wasn't laughable at all then, right? And now, it's not like we've", "tokens": [51412, 3263, 5801, 712, 558, 586, 11, 457, 309, 2067, 380, 5801, 712, 412, 439, 550, 11, 558, 30, 400, 586, 11, 309, 311, 406, 411, 321, 600, 51628], "temperature": 0.0, "avg_logprob": -0.15012853745131466, "compression_ratio": 1.8514285714285714, "no_speech_prob": 0.002145585836842656}, {"id": 2581, "seek": 854496, "start": 8570.24, "end": 8574.64, "text": " understood everything about life very far from it. When you say like, there's DNA and their", "tokens": [51628, 7320, 1203, 466, 993, 588, 1400, 490, 309, 13, 1133, 291, 584, 411, 11, 456, 311, 8272, 293, 641, 51848], "temperature": 0.0, "avg_logprob": -0.15012853745131466, "compression_ratio": 1.8514285714285714, "no_speech_prob": 0.002145585836842656}, {"id": 2582, "seek": 857464, "start": 8574.64, "end": 8579.119999999999, "text": " cells and then this is how it all arises, right? And I think we're at the point in consciousness", "tokens": [50364, 5438, 293, 550, 341, 307, 577, 309, 439, 27388, 11, 558, 30, 400, 286, 519, 321, 434, 412, 264, 935, 294, 10081, 50588], "temperature": 0.0, "avg_logprob": -0.13931050020105698, "compression_ratio": 1.7734375, "no_speech_prob": 0.007109206635504961}, {"id": 2583, "seek": 857464, "start": 8579.119999999999, "end": 8584.32, "text": " where it's to like, oh, consciousness is some so beyond us, right? I think we will get, you know,", "tokens": [50588, 689, 309, 311, 281, 411, 11, 1954, 11, 10081, 307, 512, 370, 4399, 505, 11, 558, 30, 286, 519, 321, 486, 483, 11, 291, 458, 11, 50848], "temperature": 0.0, "avg_logprob": -0.13931050020105698, "compression_ratio": 1.7734375, "no_speech_prob": 0.007109206635504961}, {"id": 2584, "seek": 857464, "start": 8584.32, "end": 8589.359999999999, "text": " there will be a structure of DNA moment in the history of the study of consciousness.", "tokens": [50848, 456, 486, 312, 257, 3877, 295, 8272, 1623, 294, 264, 2503, 295, 264, 2979, 295, 10081, 13, 51100], "temperature": 0.0, "avg_logprob": -0.13931050020105698, "compression_ratio": 1.7734375, "no_speech_prob": 0.007109206635504961}, {"id": 2585, "seek": 857464, "start": 8589.359999999999, "end": 8593.599999999999, "text": " And I think, yeah, I think things like Phi and this, you know, IT3 and whatnot,", "tokens": [51100, 400, 286, 519, 11, 1338, 11, 286, 519, 721, 411, 41435, 293, 341, 11, 291, 458, 11, 6783, 18, 293, 25882, 11, 51312], "temperature": 0.0, "avg_logprob": -0.13931050020105698, "compression_ratio": 1.7734375, "no_speech_prob": 0.007109206635504961}, {"id": 2586, "seek": 857464, "start": 8593.599999999999, "end": 8598.4, "text": " they're very brave attempts to make progress in this direction. I think, you know, like Julia", "tokens": [51312, 436, 434, 588, 12653, 15257, 281, 652, 4205, 294, 341, 3513, 13, 286, 519, 11, 291, 458, 11, 411, 18551, 51552], "temperature": 0.0, "avg_logprob": -0.13931050020105698, "compression_ratio": 1.7734375, "no_speech_prob": 0.007109206635504961}, {"id": 2587, "seek": 859840, "start": 8598.88, "end": 8604.4, "text": " Tononi in a way is, you know, very deluded in thinking that he has nailed what consciousness", "tokens": [50388, 11385, 17049, 294, 257, 636, 307, 11, 291, 458, 11, 588, 1103, 23285, 294, 1953, 300, 415, 575, 30790, 437, 10081, 50664], "temperature": 0.0, "avg_logprob": -0.09356877184289647, "compression_ratio": 1.7833935018050542, "no_speech_prob": 0.1035359650850296}, {"id": 2588, "seek": 859840, "start": 8604.4, "end": 8610.4, "text": " is, right? I think, you know, Phi maybe is an upper bound on consciousness, but with steps like this,", "tokens": [50664, 307, 11, 558, 30, 286, 519, 11, 291, 458, 11, 41435, 1310, 307, 364, 6597, 5472, 322, 10081, 11, 457, 365, 4439, 411, 341, 11, 50964], "temperature": 0.0, "avg_logprob": -0.09356877184289647, "compression_ratio": 1.7833935018050542, "no_speech_prob": 0.1035359650850296}, {"id": 2589, "seek": 859840, "start": 8610.4, "end": 8615.039999999999, "text": " hopefully at some point, and very much with the help of AI, right? AI is really useful for this,", "tokens": [50964, 4696, 412, 512, 935, 11, 293, 588, 709, 365, 264, 854, 295, 7318, 11, 558, 30, 7318, 307, 534, 4420, 337, 341, 11, 51196], "temperature": 0.0, "avg_logprob": -0.09356877184289647, "compression_ratio": 1.7833935018050542, "no_speech_prob": 0.1035359650850296}, {"id": 2590, "seek": 859840, "start": 8615.039999999999, "end": 8620.24, "text": " because it's a brain that might be consciousness that we have a lot of control of. And you can do", "tokens": [51196, 570, 309, 311, 257, 3567, 300, 1062, 312, 10081, 300, 321, 362, 257, 688, 295, 1969, 295, 13, 400, 291, 393, 360, 51456], "temperature": 0.0, "avg_logprob": -0.09356877184289647, "compression_ratio": 1.7833935018050542, "no_speech_prob": 0.1035359650850296}, {"id": 2591, "seek": 859840, "start": 8620.24, "end": 8625.92, "text": " experiments that you can't, you know, with people, right? So I think we will make at least some progress", "tokens": [51456, 12050, 300, 291, 393, 380, 11, 291, 458, 11, 365, 561, 11, 558, 30, 407, 286, 519, 321, 486, 652, 412, 1935, 512, 4205, 51740], "temperature": 0.0, "avg_logprob": -0.09356877184289647, "compression_ratio": 1.7833935018050542, "no_speech_prob": 0.1035359650850296}, {"id": 2592, "seek": 862592, "start": 8625.92, "end": 8630.8, "text": " in that direction for sure. Maybe to the point where we feel that, yes, we do understand what", "tokens": [50364, 294, 300, 3513, 337, 988, 13, 2704, 281, 264, 935, 689, 321, 841, 300, 11, 2086, 11, 321, 360, 1223, 437, 50608], "temperature": 0.0, "avg_logprob": -0.09956632443328402, "compression_ratio": 1.8429487179487178, "no_speech_prob": 0.03199449181556702}, {"id": 2593, "seek": 862592, "start": 8630.8, "end": 8635.2, "text": " consciousness is, we're not asking ourselves that question anymore. And then we can point to things", "tokens": [50608, 10081, 307, 11, 321, 434, 406, 3365, 4175, 300, 1168, 3602, 13, 400, 550, 321, 393, 935, 281, 721, 50828], "temperature": 0.0, "avg_logprob": -0.09956632443328402, "compression_ratio": 1.8429487179487178, "no_speech_prob": 0.03199449181556702}, {"id": 2594, "seek": 862592, "start": 8635.2, "end": 8639.6, "text": " and say, this is consciousness, this is that kind of consciousness, that amount of consciousness,", "tokens": [50828, 293, 584, 11, 341, 307, 10081, 11, 341, 307, 300, 733, 295, 10081, 11, 300, 2372, 295, 10081, 11, 51048], "temperature": 0.0, "avg_logprob": -0.09956632443328402, "compression_ratio": 1.8429487179487178, "no_speech_prob": 0.03199449181556702}, {"id": 2595, "seek": 862592, "start": 8639.6, "end": 8643.44, "text": " and so on. Yeah, that's really interesting. I agree, we're making a lot of progress in getting", "tokens": [51048, 293, 370, 322, 13, 865, 11, 300, 311, 534, 1880, 13, 286, 3986, 11, 321, 434, 1455, 257, 688, 295, 4205, 294, 1242, 51240], "temperature": 0.0, "avg_logprob": -0.09956632443328402, "compression_ratio": 1.8429487179487178, "no_speech_prob": 0.03199449181556702}, {"id": 2596, "seek": 862592, "start": 8643.44, "end": 8648.0, "text": " a handle on this. And although the biggest game in town is still the computationalism game. And", "tokens": [51240, 257, 4813, 322, 341, 13, 400, 4878, 264, 3880, 1216, 294, 3954, 307, 920, 264, 28270, 1434, 1216, 13, 400, 51468], "temperature": 0.0, "avg_logprob": -0.09956632443328402, "compression_ratio": 1.8429487179487178, "no_speech_prob": 0.03199449181556702}, {"id": 2597, "seek": 862592, "start": 8648.0, "end": 8653.04, "text": " as you say, historically, the only alternative was mysterious. And my friend, Professor Mark", "tokens": [51468, 382, 291, 584, 11, 16180, 11, 264, 787, 8535, 390, 13831, 13, 400, 452, 1277, 11, 8419, 3934, 51720], "temperature": 0.0, "avg_logprob": -0.09956632443328402, "compression_ratio": 1.8429487179487178, "no_speech_prob": 0.03199449181556702}, {"id": 2598, "seek": 865304, "start": 8653.12, "end": 8657.2, "text": " Bishop, that he said that that's one of the reasons why he's become interested in the", "tokens": [50368, 30113, 11, 300, 415, 848, 300, 300, 311, 472, 295, 264, 4112, 983, 415, 311, 1813, 3102, 294, 264, 50572], "temperature": 0.0, "avg_logprob": -0.1641689328586354, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.023141594603657722}, {"id": 2599, "seek": 865304, "start": 8657.2, "end": 8661.12, "text": " forays in cognitive science, because for the first time, it's given him a kind of robust", "tokens": [50572, 337, 3772, 294, 15605, 3497, 11, 570, 337, 264, 700, 565, 11, 309, 311, 2212, 796, 257, 733, 295, 13956, 50768], "temperature": 0.0, "avg_logprob": -0.1641689328586354, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.023141594603657722}, {"id": 2600, "seek": 865304, "start": 8661.12, "end": 8665.52, "text": " alternative to computationalism. But just coming back quickly, you know, as Charlie's", "tokens": [50768, 8535, 281, 28270, 1434, 13, 583, 445, 1348, 646, 2661, 11, 291, 458, 11, 382, 13754, 311, 50988], "temperature": 0.0, "avg_logprob": -0.1641689328586354, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.023141594603657722}, {"id": 2601, "seek": 865304, "start": 8665.52, "end": 8669.92, "text": " reference, Thomas Nagel, you know, which is that it is something it is like to be a bat.", "tokens": [50988, 6408, 11, 8500, 18913, 338, 11, 291, 458, 11, 597, 307, 300, 309, 307, 746, 309, 307, 411, 281, 312, 257, 7362, 13, 51208], "temperature": 0.0, "avg_logprob": -0.1641689328586354, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.023141594603657722}, {"id": 2602, "seek": 865304, "start": 8670.560000000001, "end": 8676.0, "text": " What do you think about that? So I'm not sure your question is, but let me check.", "tokens": [51240, 708, 360, 291, 519, 466, 300, 30, 407, 286, 478, 406, 988, 428, 1168, 307, 11, 457, 718, 385, 1520, 13, 51512], "temperature": 0.0, "avg_logprob": -0.1641689328586354, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.023141594603657722}, {"id": 2603, "seek": 865304, "start": 8676.0, "end": 8679.84, "text": " Well, what do you mean? Do you agree that there is something it is like to be a bat?", "tokens": [51512, 1042, 11, 437, 360, 291, 914, 30, 1144, 291, 3986, 300, 456, 307, 746, 309, 307, 411, 281, 312, 257, 7362, 30, 51704], "temperature": 0.0, "avg_logprob": -0.1641689328586354, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.023141594603657722}, {"id": 2604, "seek": 867984, "start": 8679.84, "end": 8685.76, "text": " Oh, absolutely. Right. So there is more and more than that, right? There is something that it's", "tokens": [50364, 876, 11, 3122, 13, 1779, 13, 407, 456, 307, 544, 293, 544, 813, 300, 11, 558, 30, 821, 307, 746, 300, 309, 311, 50660], "temperature": 0.0, "avg_logprob": -0.11292378957034978, "compression_ratio": 1.7723880597014925, "no_speech_prob": 0.030123118311166763}, {"id": 2605, "seek": 867984, "start": 8685.76, "end": 8692.32, "text": " like to be a bat. And it's very different from being a human, right? And we grossly underestimate,", "tokens": [50660, 411, 281, 312, 257, 7362, 13, 400, 309, 311, 588, 819, 490, 885, 257, 1952, 11, 558, 30, 400, 321, 11367, 356, 35826, 11, 50988], "temperature": 0.0, "avg_logprob": -0.11292378957034978, "compression_ratio": 1.7723880597014925, "no_speech_prob": 0.030123118311166763}, {"id": 2606, "seek": 867984, "start": 8692.32, "end": 8696.960000000001, "text": " right? Again, we do this thing that again, it's a heuristic, it works very well as like,", "tokens": [50988, 558, 30, 3764, 11, 321, 360, 341, 551, 300, 797, 11, 309, 311, 257, 415, 374, 3142, 11, 309, 1985, 588, 731, 382, 411, 11, 51220], "temperature": 0.0, "avg_logprob": -0.11292378957034978, "compression_ratio": 1.7723880597014925, "no_speech_prob": 0.030123118311166763}, {"id": 2607, "seek": 867984, "start": 8696.960000000001, "end": 8701.12, "text": " we project ourselves into the bat, because what else could we do, right? But then what you see", "tokens": [51220, 321, 1716, 4175, 666, 264, 7362, 11, 570, 437, 1646, 727, 321, 360, 11, 558, 30, 583, 550, 437, 291, 536, 51428], "temperature": 0.0, "avg_logprob": -0.11292378957034978, "compression_ratio": 1.7723880597014925, "no_speech_prob": 0.030123118311166763}, {"id": 2608, "seek": 867984, "start": 8701.12, "end": 8706.16, "text": " is a bat seen through the mind of a human, right? And in fact, there's this famous, I would say,", "tokens": [51428, 307, 257, 7362, 1612, 807, 264, 1575, 295, 257, 1952, 11, 558, 30, 400, 294, 1186, 11, 456, 311, 341, 4618, 11, 286, 576, 584, 11, 51680], "temperature": 0.0, "avg_logprob": -0.11292378957034978, "compression_ratio": 1.7723880597014925, "no_speech_prob": 0.030123118311166763}, {"id": 2609, "seek": 870616, "start": 8706.16, "end": 8711.76, "text": " even more famous, you know, you know, notion from, from Wittgenstein, right? That if the", "tokens": [50364, 754, 544, 4618, 11, 291, 458, 11, 291, 458, 11, 10710, 490, 11, 490, 343, 593, 1766, 9089, 11, 558, 30, 663, 498, 264, 50644], "temperature": 0.0, "avg_logprob": -0.12082230660223192, "compression_ratio": 1.768939393939394, "no_speech_prob": 0.015156215988099575}, {"id": 2610, "seek": 870616, "start": 8711.76, "end": 8718.72, "text": " lion could talk, I would not understand anything that the lion was saying. Because his world is", "tokens": [50644, 17226, 727, 751, 11, 286, 576, 406, 1223, 1340, 300, 264, 17226, 390, 1566, 13, 1436, 702, 1002, 307, 50992], "temperature": 0.0, "avg_logprob": -0.12082230660223192, "compression_ratio": 1.768939393939394, "no_speech_prob": 0.015156215988099575}, {"id": 2611, "seek": 870616, "start": 8718.72, "end": 8724.56, "text": " so different from mine. Now, I actually think, I think this is a very important position to,", "tokens": [50992, 370, 819, 490, 3892, 13, 823, 11, 286, 767, 519, 11, 286, 519, 341, 307, 257, 588, 1021, 2535, 281, 11, 51284], "temperature": 0.0, "avg_logprob": -0.12082230660223192, "compression_ratio": 1.768939393939394, "no_speech_prob": 0.015156215988099575}, {"id": 2612, "seek": 870616, "start": 8724.56, "end": 8728.88, "text": " as a reference point, right? Certainly a defensible one. And, you know, Wittgenstein was a good", "tokens": [51284, 382, 257, 6408, 935, 11, 558, 30, 16628, 257, 1060, 30633, 472, 13, 400, 11, 291, 458, 11, 343, 593, 1766, 9089, 390, 257, 665, 51500], "temperature": 0.0, "avg_logprob": -0.12082230660223192, "compression_ratio": 1.768939393939394, "no_speech_prob": 0.015156215988099575}, {"id": 2613, "seek": 870616, "start": 8728.88, "end": 8734.4, "text": " defender of it. But I actually think that this is going too far. I think, ultimately, I mean,", "tokens": [51500, 26537, 295, 309, 13, 583, 286, 767, 519, 300, 341, 307, 516, 886, 1400, 13, 286, 519, 11, 6284, 11, 286, 914, 11, 51776], "temperature": 0.0, "avg_logprob": -0.12082230660223192, "compression_ratio": 1.768939393939394, "no_speech_prob": 0.015156215988099575}, {"id": 2614, "seek": 873440, "start": 8734.4, "end": 8738.96, "text": " never be able to completely know what it's like to be a lion. But we can make a lot,", "tokens": [50364, 1128, 312, 1075, 281, 2584, 458, 437, 309, 311, 411, 281, 312, 257, 17226, 13, 583, 321, 393, 652, 257, 688, 11, 50592], "temperature": 0.0, "avg_logprob": -0.09957877903768461, "compression_ratio": 1.9014084507042253, "no_speech_prob": 0.08818135410547256}, {"id": 2615, "seek": 873440, "start": 8738.96, "end": 8742.64, "text": " don't underestimate us either, right? We can make a lot of inwards into understanding what", "tokens": [50592, 500, 380, 35826, 505, 2139, 11, 558, 30, 492, 393, 652, 257, 688, 295, 294, 2015, 666, 3701, 437, 50776], "temperature": 0.0, "avg_logprob": -0.09957877903768461, "compression_ratio": 1.9014084507042253, "no_speech_prob": 0.08818135410547256}, {"id": 2616, "seek": 873440, "start": 8742.64, "end": 8748.32, "text": " it's like to be a lion, much more than we understand today. Same thing for a bat. And,", "tokens": [50776, 309, 311, 411, 281, 312, 257, 17226, 11, 709, 544, 813, 321, 1223, 965, 13, 10635, 551, 337, 257, 7362, 13, 400, 11, 51060], "temperature": 0.0, "avg_logprob": -0.09957877903768461, "compression_ratio": 1.9014084507042253, "no_speech_prob": 0.08818135410547256}, {"id": 2617, "seek": 873440, "start": 8748.32, "end": 8753.279999999999, "text": " you know, you could also ask that for a fruit fly, right? In a way, a fruit fly is more different", "tokens": [51060, 291, 458, 11, 291, 727, 611, 1029, 300, 337, 257, 6773, 3603, 11, 558, 30, 682, 257, 636, 11, 257, 6773, 3603, 307, 544, 819, 51308], "temperature": 0.0, "avg_logprob": -0.09957877903768461, "compression_ratio": 1.9014084507042253, "no_speech_prob": 0.08818135410547256}, {"id": 2618, "seek": 873440, "start": 8753.279999999999, "end": 8758.0, "text": " from us than a lion, but it's easy to understand, right? Because at some level, that thing is so", "tokens": [51308, 490, 505, 813, 257, 17226, 11, 457, 309, 311, 1858, 281, 1223, 11, 558, 30, 1436, 412, 512, 1496, 11, 300, 551, 307, 370, 51544], "temperature": 0.0, "avg_logprob": -0.09957877903768461, "compression_ratio": 1.9014084507042253, "no_speech_prob": 0.08818135410547256}, {"id": 2619, "seek": 873440, "start": 8758.0, "end": 8761.52, "text": " simple that we can understand what's going on with it, because it's not that deep.", "tokens": [51544, 2199, 300, 321, 393, 1223, 437, 311, 516, 322, 365, 309, 11, 570, 309, 311, 406, 300, 2452, 13, 51720], "temperature": 0.0, "avg_logprob": -0.09957877903768461, "compression_ratio": 1.9014084507042253, "no_speech_prob": 0.08818135410547256}, {"id": 2620, "seek": 876152, "start": 8761.6, "end": 8765.68, "text": " Yeah, that's a beautiful quote, actually. So, closing this off, do you think that large", "tokens": [50368, 865, 11, 300, 311, 257, 2238, 6513, 11, 767, 13, 407, 11, 10377, 341, 766, 11, 360, 291, 519, 300, 2416, 50572], "temperature": 0.0, "avg_logprob": -0.1374072578009658, "compression_ratio": 1.9388489208633093, "no_speech_prob": 0.01850006729364395}, {"id": 2621, "seek": 876152, "start": 8765.68, "end": 8768.16, "text": " language models are slightly conscious or will be in the near future?", "tokens": [50572, 2856, 5245, 366, 4748, 6648, 420, 486, 312, 294, 264, 2651, 2027, 30, 50696], "temperature": 0.0, "avg_logprob": -0.1374072578009658, "compression_ratio": 1.9388489208633093, "no_speech_prob": 0.01850006729364395}, {"id": 2622, "seek": 876152, "start": 8768.800000000001, "end": 8774.16, "text": " I think language, I think large language models are not slightly conscious by the reasonable,", "tokens": [50728, 286, 519, 2856, 11, 286, 519, 2416, 2856, 5245, 366, 406, 4748, 6648, 538, 264, 10585, 11, 50996], "temperature": 0.0, "avg_logprob": -0.1374072578009658, "compression_ratio": 1.9388489208633093, "no_speech_prob": 0.01850006729364395}, {"id": 2623, "seek": 876152, "start": 8774.16, "end": 8778.560000000001, "text": " you know, everyday definition of the world slightly, meaning that their consciousness,", "tokens": [50996, 291, 458, 11, 7429, 7123, 295, 264, 1002, 4748, 11, 3620, 300, 641, 10081, 11, 51216], "temperature": 0.0, "avg_logprob": -0.1374072578009658, "compression_ratio": 1.9388489208633093, "no_speech_prob": 0.01850006729364395}, {"id": 2624, "seek": 876152, "start": 8778.560000000001, "end": 8785.76, "text": " so I think that either their consciousness is just zero, right? If somebody asked me, like, you know,", "tokens": [51216, 370, 286, 519, 300, 2139, 641, 10081, 307, 445, 4018, 11, 558, 30, 759, 2618, 2351, 385, 11, 411, 11, 291, 458, 11, 51576], "temperature": 0.0, "avg_logprob": -0.1374072578009658, "compression_ratio": 1.9388489208633093, "no_speech_prob": 0.01850006729364395}, {"id": 2625, "seek": 876152, "start": 8785.76, "end": 8789.52, "text": " how much, you know, consciousness does, you know, lambda half, tell me in one word, and the answer", "tokens": [51576, 577, 709, 11, 291, 458, 11, 10081, 775, 11, 291, 458, 11, 13607, 1922, 11, 980, 385, 294, 472, 1349, 11, 293, 264, 1867, 51764], "temperature": 0.0, "avg_logprob": -0.1374072578009658, "compression_ratio": 1.9388489208633093, "no_speech_prob": 0.01850006729364395}, {"id": 2626, "seek": 878952, "start": 8789.52, "end": 8795.6, "text": " would be zero, right? But another answer which is hard to distinguish from the first one is epsilon,", "tokens": [50364, 576, 312, 4018, 11, 558, 30, 583, 1071, 1867, 597, 307, 1152, 281, 20206, 490, 264, 700, 472, 307, 17889, 11, 50668], "temperature": 0.0, "avg_logprob": -0.11184756820266312, "compression_ratio": 1.65, "no_speech_prob": 0.025085441768169403}, {"id": 2627, "seek": 878952, "start": 8795.6, "end": 8801.36, "text": " right? Maybe it has a very tiny amount of consciousness, but it's so tiny that it doesn't", "tokens": [50668, 558, 30, 2704, 309, 575, 257, 588, 5870, 2372, 295, 10081, 11, 457, 309, 311, 370, 5870, 300, 309, 1177, 380, 50956], "temperature": 0.0, "avg_logprob": -0.11184756820266312, "compression_ratio": 1.65, "no_speech_prob": 0.025085441768169403}, {"id": 2628, "seek": 878952, "start": 8801.36, "end": 8806.32, "text": " even qualify as slightly. Again, this gets back to what its architecture is. It actually gets", "tokens": [50956, 754, 20276, 382, 4748, 13, 3764, 11, 341, 2170, 646, 281, 437, 1080, 9482, 307, 13, 467, 767, 2170, 51204], "temperature": 0.0, "avg_logprob": -0.11184756820266312, "compression_ratio": 1.65, "no_speech_prob": 0.025085441768169403}, {"id": 2629, "seek": 878952, "start": 8806.32, "end": 8811.6, "text": " too lot of things, but for purposes of this discussion, right, lambda and these large", "tokens": [51204, 886, 688, 295, 721, 11, 457, 337, 9932, 295, 341, 5017, 11, 558, 11, 13607, 293, 613, 2416, 51468], "temperature": 0.0, "avg_logprob": -0.11184756820266312, "compression_ratio": 1.65, "no_speech_prob": 0.025085441768169403}, {"id": 2630, "seek": 878952, "start": 8811.6, "end": 8816.48, "text": " language models are not very different from a big lookup table. Any big lookup table is not", "tokens": [51468, 2856, 5245, 366, 406, 588, 819, 490, 257, 955, 574, 1010, 3199, 13, 2639, 955, 574, 1010, 3199, 307, 406, 51712], "temperature": 0.0, "avg_logprob": -0.11184756820266312, "compression_ratio": 1.65, "no_speech_prob": 0.025085441768169403}, {"id": 2631, "seek": 881648, "start": 8816.48, "end": 8820.96, "text": " conscious. Now, I mean, there are a lot of interesting distinctions that you can make it well.", "tokens": [50364, 6648, 13, 823, 11, 286, 914, 11, 456, 366, 257, 688, 295, 1880, 1483, 49798, 300, 291, 393, 652, 309, 731, 13, 50588], "temperature": 0.0, "avg_logprob": -0.10636913776397705, "compression_ratio": 1.8258064516129033, "no_speech_prob": 0.037237733602523804}, {"id": 2632, "seek": 881648, "start": 8820.96, "end": 8825.039999999999, "text": " What if what I have is an efficient approximation to a lookup table? Isn't that what your brain is,", "tokens": [50588, 708, 498, 437, 286, 362, 307, 364, 7148, 28023, 281, 257, 574, 1010, 3199, 30, 6998, 380, 300, 437, 428, 3567, 307, 11, 50792], "temperature": 0.0, "avg_logprob": -0.10636913776397705, "compression_ratio": 1.8258064516129033, "no_speech_prob": 0.037237733602523804}, {"id": 2633, "seek": 881648, "start": 8825.039999999999, "end": 8829.52, "text": " right? And I would say yes, and then people say, well, but then why is your brain conscious", "tokens": [50792, 558, 30, 400, 286, 576, 584, 2086, 11, 293, 550, 561, 584, 11, 731, 11, 457, 550, 983, 307, 428, 3567, 6648, 51016], "temperature": 0.0, "avg_logprob": -0.10636913776397705, "compression_ratio": 1.8258064516129033, "no_speech_prob": 0.037237733602523804}, {"id": 2634, "seek": 881648, "start": 8829.52, "end": 8834.4, "text": " but not the lookup table, right? And precisely the interesting question is that the consciousness", "tokens": [51016, 457, 406, 264, 574, 1010, 3199, 11, 558, 30, 400, 13402, 264, 1880, 1168, 307, 300, 264, 10081, 51260], "temperature": 0.0, "avg_logprob": -0.10636913776397705, "compression_ratio": 1.8258064516129033, "no_speech_prob": 0.037237733602523804}, {"id": 2635, "seek": 881648, "start": 8834.4, "end": 8840.24, "text": " comes about from the fact that you have to concentrate all of this information, you know,", "tokens": [51260, 1487, 466, 490, 264, 1186, 300, 291, 362, 281, 18089, 439, 295, 341, 1589, 11, 291, 458, 11, 51552], "temperature": 0.0, "avg_logprob": -0.10636913776397705, "compression_ratio": 1.8258064516129033, "no_speech_prob": 0.037237733602523804}, {"id": 2636, "seek": 881648, "start": 8840.24, "end": 8845.359999999999, "text": " in real time, into something, you know, very compact and that leads to action continuously,", "tokens": [51552, 294, 957, 565, 11, 666, 746, 11, 291, 458, 11, 588, 14679, 293, 300, 6689, 281, 3069, 15684, 11, 51808], "temperature": 0.0, "avg_logprob": -0.10636913776397705, "compression_ratio": 1.8258064516129033, "no_speech_prob": 0.037237733602523804}, {"id": 2637, "seek": 884536, "start": 8845.36, "end": 8850.960000000001, "text": " right? So to put this in another way, maybe God is unconscious because he doesn't need to be,", "tokens": [50364, 558, 30, 407, 281, 829, 341, 294, 1071, 636, 11, 1310, 1265, 307, 18900, 570, 415, 1177, 380, 643, 281, 312, 11, 50644], "temperature": 0.0, "avg_logprob": -0.11786968199933162, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.00775012606754899}, {"id": 2638, "seek": 884536, "start": 8850.960000000001, "end": 8855.52, "text": " right? If you're omnipotent and omniscient, you don't need to be conscious. You are effectively", "tokens": [50644, 558, 30, 759, 291, 434, 36874, 647, 310, 317, 293, 3406, 10661, 5412, 11, 291, 500, 380, 643, 281, 312, 6648, 13, 509, 366, 8659, 50872], "temperature": 0.0, "avg_logprob": -0.11786968199933162, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.00775012606754899}, {"id": 2639, "seek": 884536, "start": 8855.52, "end": 8860.24, "text": " just a lookup table. Exactly. And I loved your response earlier about the grain of sand and", "tokens": [50872, 445, 257, 574, 1010, 3199, 13, 7587, 13, 400, 286, 4333, 428, 4134, 3071, 466, 264, 12837, 295, 4932, 293, 51108], "temperature": 0.0, "avg_logprob": -0.11786968199933162, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.00775012606754899}, {"id": 2640, "seek": 884536, "start": 8860.24, "end": 8863.92, "text": " the oyster. I thought that was a beautiful way of looking at it. And having recently studied", "tokens": [51108, 264, 32005, 13, 286, 1194, 300, 390, 257, 2238, 636, 295, 1237, 412, 309, 13, 400, 1419, 3938, 9454, 51292], "temperature": 0.0, "avg_logprob": -0.11786968199933162, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.00775012606754899}, {"id": 2641, "seek": 884536, "start": 8863.92, "end": 8869.2, "text": " so, I mean, personally, I think it's a lot to do with intentionality and agency, but I remember", "tokens": [51292, 370, 11, 286, 914, 11, 5665, 11, 286, 519, 309, 311, 257, 688, 281, 360, 365, 7789, 1860, 293, 7934, 11, 457, 286, 1604, 51556], "temperature": 0.0, "avg_logprob": -0.11786968199933162, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.00775012606754899}, {"id": 2642, "seek": 886920, "start": 8869.2, "end": 8876.16, "text": " you responded to that. Just final quick question. What's your definition of intelligence?", "tokens": [50364, 291, 15806, 281, 300, 13, 1449, 2572, 1702, 1168, 13, 708, 311, 428, 7123, 295, 7599, 30, 50712], "temperature": 0.0, "avg_logprob": -0.08846284661974226, "compression_ratio": 1.5625, "no_speech_prob": 0.15982858836650848}, {"id": 2643, "seek": 886920, "start": 8877.92, "end": 8882.560000000001, "text": " So let me start with the technical definition, which is unfortunately not widely known enough", "tokens": [50800, 407, 718, 385, 722, 365, 264, 6191, 7123, 11, 597, 307, 7015, 406, 13371, 2570, 1547, 51032], "temperature": 0.0, "avg_logprob": -0.08846284661974226, "compression_ratio": 1.5625, "no_speech_prob": 0.15982858836650848}, {"id": 2644, "seek": 886920, "start": 8882.560000000001, "end": 8887.92, "text": " and not appreciated enough. But I think it's a really important one to have, right? Intelligence", "tokens": [51032, 293, 406, 17169, 1547, 13, 583, 286, 519, 309, 311, 257, 534, 1021, 472, 281, 362, 11, 558, 30, 27274, 51300], "temperature": 0.0, "avg_logprob": -0.08846284661974226, "compression_ratio": 1.5625, "no_speech_prob": 0.15982858836650848}, {"id": 2645, "seek": 886920, "start": 8887.92, "end": 8894.880000000001, "text": " is solving NP-complete problems using heuristics. This is the real technical definition of AI,", "tokens": [51300, 307, 12606, 38611, 12, 1112, 17220, 2740, 1228, 415, 374, 6006, 13, 639, 307, 264, 957, 6191, 7123, 295, 7318, 11, 51648], "temperature": 0.0, "avg_logprob": -0.08846284661974226, "compression_ratio": 1.5625, "no_speech_prob": 0.15982858836650848}, {"id": 2646, "seek": 889488, "start": 8894.88, "end": 8899.439999999999, "text": " right? And there's a lot packed into that, right? The fact that it's NP-complete problems and the", "tokens": [50364, 558, 30, 400, 456, 311, 257, 688, 13265, 666, 300, 11, 558, 30, 440, 1186, 300, 309, 311, 38611, 12, 1112, 17220, 2740, 293, 264, 50592], "temperature": 0.0, "avg_logprob": -0.06111034408944552, "compression_ratio": 1.9307692307692308, "no_speech_prob": 0.006089415866881609}, {"id": 2647, "seek": 889488, "start": 8899.439999999999, "end": 8904.4, "text": " fact that it's using heuristics. If your problem is solvable with a lookup table with polynomial", "tokens": [50592, 1186, 300, 309, 311, 1228, 415, 374, 6006, 13, 759, 428, 1154, 307, 1404, 17915, 365, 257, 574, 1010, 3199, 365, 26110, 50840], "temperature": 0.0, "avg_logprob": -0.06111034408944552, "compression_ratio": 1.9307692307692308, "no_speech_prob": 0.006089415866881609}, {"id": 2648, "seek": 889488, "start": 8904.4, "end": 8908.96, "text": " algorithms, you don't need intelligence and there's no intelligence there. It's when you start solving", "tokens": [50840, 14642, 11, 291, 500, 380, 643, 7599, 293, 456, 311, 572, 7599, 456, 13, 467, 311, 562, 291, 722, 12606, 51068], "temperature": 0.0, "avg_logprob": -0.06111034408944552, "compression_ratio": 1.9307692307692308, "no_speech_prob": 0.006089415866881609}, {"id": 2649, "seek": 889488, "start": 8908.96, "end": 8916.32, "text": " hard problems using heuristics that you're getting into the realm of intelligence. Moreover, NP-complete", "tokens": [51068, 1152, 2740, 1228, 415, 374, 6006, 300, 291, 434, 1242, 666, 264, 15355, 295, 7599, 13, 19838, 11, 38611, 12, 1112, 17220, 51436], "temperature": 0.0, "avg_logprob": -0.06111034408944552, "compression_ratio": 1.9307692307692308, "no_speech_prob": 0.006089415866881609}, {"id": 2650, "seek": 889488, "start": 8916.32, "end": 8922.16, "text": " is not the same as exponential, right? The crucial thing about an NP-complete problem that connects", "tokens": [51436, 307, 406, 264, 912, 382, 21510, 11, 558, 30, 440, 11462, 551, 466, 364, 38611, 12, 1112, 17220, 1154, 300, 16967, 51728], "temperature": 0.0, "avg_logprob": -0.06111034408944552, "compression_ratio": 1.9307692307692308, "no_speech_prob": 0.006089415866881609}, {"id": 2651, "seek": 892216, "start": 8922.16, "end": 8927.119999999999, "text": " very directly to our entire discussion of utility and whatnot is that the solution is easy to check.", "tokens": [50364, 588, 3838, 281, 527, 2302, 5017, 295, 14877, 293, 25882, 307, 300, 264, 3827, 307, 1858, 281, 1520, 13, 50612], "temperature": 0.0, "avg_logprob": -0.13569535928614, "compression_ratio": 1.8770226537216828, "no_speech_prob": 0.033933330327272415}, {"id": 2652, "seek": 892216, "start": 8928.0, "end": 8933.44, "text": " This is the key. If you're working on problems whose solution is impossible to check effectively,", "tokens": [50656, 639, 307, 264, 2141, 13, 759, 291, 434, 1364, 322, 2740, 6104, 3827, 307, 6243, 281, 1520, 8659, 11, 50928], "temperature": 0.0, "avg_logprob": -0.13569535928614, "compression_ratio": 1.8770226537216828, "no_speech_prob": 0.033933330327272415}, {"id": 2653, "seek": 892216, "start": 8933.44, "end": 8937.92, "text": " I can't even tell if you're intelligent or not. The whole thing about intelligence in humans and", "tokens": [50928, 286, 393, 380, 754, 980, 498, 291, 434, 13232, 420, 406, 13, 440, 1379, 551, 466, 7599, 294, 6255, 293, 51152], "temperature": 0.0, "avg_logprob": -0.13569535928614, "compression_ratio": 1.8770226537216828, "no_speech_prob": 0.033933330327272415}, {"id": 2654, "seek": 892216, "start": 8937.92, "end": 8942.96, "text": " machines is that how you solve the problem requires a lot of intelligence, a lot of computing power", "tokens": [51152, 8379, 307, 300, 577, 291, 5039, 264, 1154, 7029, 257, 688, 295, 7599, 11, 257, 688, 295, 15866, 1347, 51404], "temperature": 0.0, "avg_logprob": -0.13569535928614, "compression_ratio": 1.8770226537216828, "no_speech_prob": 0.033933330327272415}, {"id": 2655, "seek": 892216, "start": 8942.96, "end": 8946.72, "text": " and whatnot, but then I can easily check the solution. Now, hang on a minute, could that", "tokens": [51404, 293, 25882, 11, 457, 550, 286, 393, 3612, 1520, 264, 3827, 13, 823, 11, 3967, 322, 257, 3456, 11, 727, 300, 51592], "temperature": 0.0, "avg_logprob": -0.13569535928614, "compression_ratio": 1.8770226537216828, "no_speech_prob": 0.033933330327272415}, {"id": 2656, "seek": 892216, "start": 8946.72, "end": 8951.44, "text": " say a step away from behavior then if you're saying that, you know, like you have the percepts,", "tokens": [51592, 584, 257, 1823, 1314, 490, 5223, 550, 498, 291, 434, 1566, 300, 11, 291, 458, 11, 411, 291, 362, 264, 680, 1336, 82, 11, 51828], "temperature": 0.0, "avg_logprob": -0.13569535928614, "compression_ratio": 1.8770226537216828, "no_speech_prob": 0.033933330327272415}, {"id": 2657, "seek": 895144, "start": 8951.44, "end": 8954.720000000001, "text": " the state and the action and you're saying the state is also important?", "tokens": [50364, 264, 1785, 293, 264, 3069, 293, 291, 434, 1566, 264, 1785, 307, 611, 1021, 30, 50528], "temperature": 0.0, "avg_logprob": -0.10870603929486192, "compression_ratio": 1.6989247311827957, "no_speech_prob": 0.004127866122871637}, {"id": 2658, "seek": 895144, "start": 8954.720000000001, "end": 8962.24, "text": " No, so to answer that head on, intelligence is not behavior, right? Intelligence to give a slightly", "tokens": [50528, 883, 11, 370, 281, 1867, 300, 1378, 322, 11, 7599, 307, 406, 5223, 11, 558, 30, 27274, 281, 976, 257, 4748, 50904], "temperature": 0.0, "avg_logprob": -0.10870603929486192, "compression_ratio": 1.6989247311827957, "no_speech_prob": 0.004127866122871637}, {"id": 2659, "seek": 895144, "start": 8962.24, "end": 8966.24, "text": " more general definition and then there's several and they all have their merits. Intelligence is the", "tokens": [50904, 544, 2674, 7123, 293, 550, 456, 311, 2940, 293, 436, 439, 362, 641, 40923, 13, 27274, 307, 264, 51104], "temperature": 0.0, "avg_logprob": -0.10870603929486192, "compression_ratio": 1.6989247311827957, "no_speech_prob": 0.004127866122871637}, {"id": 2660, "seek": 895144, "start": 8966.24, "end": 8971.2, "text": " ability to solve hard problems. Then more concretely, it's NP-complete problems and using heuristics,", "tokens": [51104, 3485, 281, 5039, 1152, 2740, 13, 1396, 544, 39481, 736, 11, 309, 311, 38611, 12, 1112, 17220, 2740, 293, 1228, 415, 374, 6006, 11, 51352], "temperature": 0.0, "avg_logprob": -0.10870603929486192, "compression_ratio": 1.6989247311827957, "no_speech_prob": 0.004127866122871637}, {"id": 2661, "seek": 895144, "start": 8971.2, "end": 8978.0, "text": " but like, for example, if you create an AI system that cures cancer, it doesn't behave in the sense", "tokens": [51352, 457, 411, 11, 337, 1365, 11, 498, 291, 1884, 364, 7318, 1185, 300, 269, 1303, 5592, 11, 309, 1177, 380, 15158, 294, 264, 2020, 51692], "temperature": 0.0, "avg_logprob": -0.10870603929486192, "compression_ratio": 1.6989247311827957, "no_speech_prob": 0.004127866122871637}, {"id": 2662, "seek": 897800, "start": 8978.0, "end": 8982.72, "text": " that a human and a robot behave, but, you know, it's damn intelligence, it's more intelligent", "tokens": [50364, 300, 257, 1952, 293, 257, 7881, 15158, 11, 457, 11, 291, 458, 11, 309, 311, 8151, 7599, 11, 309, 311, 544, 13232, 50600], "temperature": 0.0, "avg_logprob": -0.11652609397625101, "compression_ratio": 1.7992565055762082, "no_speech_prob": 0.019699128344655037}, {"id": 2663, "seek": 897800, "start": 8982.72, "end": 8988.08, "text": " than we are, right? It would be childish to deny intelligence to that system, no matter how it solves", "tokens": [50600, 813, 321, 366, 11, 558, 30, 467, 576, 312, 42203, 281, 15744, 7599, 281, 300, 1185, 11, 572, 1871, 577, 309, 39890, 50868], "temperature": 0.0, "avg_logprob": -0.11652609397625101, "compression_ratio": 1.7992565055762082, "no_speech_prob": 0.019699128344655037}, {"id": 2664, "seek": 897800, "start": 8988.08, "end": 8994.72, "text": " cancer. If it finds a ridiculously simple way to solve cancer, then it's even more brilliant,", "tokens": [50868, 5592, 13, 759, 309, 10704, 257, 41358, 2199, 636, 281, 5039, 5592, 11, 550, 309, 311, 754, 544, 10248, 11, 51200], "temperature": 0.0, "avg_logprob": -0.11652609397625101, "compression_ratio": 1.7992565055762082, "no_speech_prob": 0.019699128344655037}, {"id": 2665, "seek": 897800, "start": 8994.72, "end": 8999.36, "text": " right? In fact, the simpler your outcome, the more intelligent you are, right? It takes intelligence", "tokens": [51200, 558, 30, 682, 1186, 11, 264, 18587, 428, 9700, 11, 264, 544, 13232, 291, 366, 11, 558, 30, 467, 2516, 7599, 51432], "temperature": 0.0, "avg_logprob": -0.11652609397625101, "compression_ratio": 1.7992565055762082, "no_speech_prob": 0.019699128344655037}, {"id": 2666, "seek": 897800, "start": 8999.36, "end": 9004.8, "text": " to produce something simple. Wow. Concretely, in many circumstances, in particular evolution,", "tokens": [51432, 281, 5258, 746, 2199, 13, 3153, 13, 18200, 1505, 736, 11, 294, 867, 9121, 11, 294, 1729, 9303, 11, 51704], "temperature": 0.0, "avg_logprob": -0.11652609397625101, "compression_ratio": 1.7992565055762082, "no_speech_prob": 0.019699128344655037}, {"id": 2667, "seek": 900480, "start": 9004.8, "end": 9009.84, "text": " right? Intelligence manifests itself as behavior. There's a sequential decision making problem,", "tokens": [50364, 558, 30, 27274, 50252, 2564, 382, 5223, 13, 821, 311, 257, 42881, 3537, 1455, 1154, 11, 50616], "temperature": 0.0, "avg_logprob": -0.17838488884691922, "compression_ratio": 1.6042402826855124, "no_speech_prob": 0.019600898027420044}, {"id": 2668, "seek": 900480, "start": 9009.84, "end": 9013.84, "text": " there's an agent in the world that said a certain stuff, being a stochastic parrot.", "tokens": [50616, 456, 311, 364, 9461, 294, 264, 1002, 300, 848, 257, 1629, 1507, 11, 885, 257, 342, 8997, 2750, 42462, 13, 50816], "temperature": 0.0, "avg_logprob": -0.17838488884691922, "compression_ratio": 1.6042402826855124, "no_speech_prob": 0.019600898027420044}, {"id": 2669, "seek": 900480, "start": 9013.84, "end": 9018.64, "text": " And I think also from, you know, theoretical reasons, by analyzing what a transformer can", "tokens": [50816, 400, 286, 519, 611, 490, 11, 291, 458, 11, 20864, 4112, 11, 538, 23663, 437, 257, 31782, 393, 51056], "temperature": 0.0, "avg_logprob": -0.17838488884691922, "compression_ratio": 1.6042402826855124, "no_speech_prob": 0.019600898027420044}, {"id": 2670, "seek": 900480, "start": 9018.64, "end": 9023.359999999999, "text": " represent and how it can learn, my best guess, which could be wrong again, I don't think anybody", "tokens": [51056, 2906, 293, 577, 309, 393, 1466, 11, 452, 1151, 2041, 11, 597, 727, 312, 2085, 797, 11, 286, 500, 380, 519, 4472, 51292], "temperature": 0.0, "avg_logprob": -0.17838488884691922, "compression_ratio": 1.6042402826855124, "no_speech_prob": 0.019600898027420044}, {"id": 2671, "seek": 900480, "start": 9023.359999999999, "end": 9028.88, "text": " has the answer to this and it's interesting question is that those transformers, right,", "tokens": [51292, 575, 264, 1867, 281, 341, 293, 309, 311, 1880, 1168, 307, 300, 729, 4088, 433, 11, 558, 11, 51568], "temperature": 0.0, "avg_logprob": -0.17838488884691922, "compression_ratio": 1.6042402826855124, "no_speech_prob": 0.019600898027420044}, {"id": 2672, "seek": 902888, "start": 9028.88, "end": 9033.679999999998, "text": " not LLM scholars, that means more of like a task rather than the, you know, than the architecture.", "tokens": [50364, 406, 441, 43, 44, 8553, 11, 300, 1355, 544, 295, 411, 257, 5633, 2831, 813, 264, 11, 291, 458, 11, 813, 264, 9482, 13, 50604], "temperature": 0.0, "avg_logprob": -0.17040768894580527, "compression_ratio": 1.6425992779783394, "no_speech_prob": 0.1061549112200737}, {"id": 2673, "seek": 902888, "start": 9034.32, "end": 9038.0, "text": " Transformers have a certain limited ability to do compositionality,", "tokens": [50636, 27938, 433, 362, 257, 1629, 5567, 3485, 281, 360, 12686, 1860, 11, 50820], "temperature": 0.0, "avg_logprob": -0.17040768894580527, "compression_ratio": 1.6425992779783394, "no_speech_prob": 0.1061549112200737}, {"id": 2674, "seek": 902888, "start": 9038.56, "end": 9044.48, "text": " very limited to compare to full logic programming, etc., but exponentially better than something like", "tokens": [50848, 588, 5567, 281, 6794, 281, 1577, 9952, 9410, 11, 5183, 7933, 457, 37330, 1101, 813, 746, 411, 51144], "temperature": 0.0, "avg_logprob": -0.17040768894580527, "compression_ratio": 1.6425992779783394, "no_speech_prob": 0.1061549112200737}, {"id": 2675, "seek": 902888, "start": 9044.48, "end": 9049.92, "text": " an ordinary multilayer perceptron. And if you just, I mean, even a multilayer perceptron or any", "tokens": [51144, 364, 10547, 2120, 388, 11167, 43276, 2044, 13, 400, 498, 291, 445, 11, 286, 914, 11, 754, 257, 2120, 388, 11167, 43276, 2044, 420, 604, 51416], "temperature": 0.0, "avg_logprob": -0.17040768894580527, "compression_ratio": 1.6425992779783394, "no_speech_prob": 0.1061549112200737}, {"id": 2676, "seek": 902888, "start": 9049.92, "end": 9055.759999999998, "text": " learning algorithm is more than a stochastic parrot, because it's general, the whole point", "tokens": [51416, 2539, 9284, 307, 544, 813, 257, 342, 8997, 2750, 42462, 11, 570, 309, 311, 2674, 11, 264, 1379, 935, 51708], "temperature": 0.0, "avg_logprob": -0.17040768894580527, "compression_ratio": 1.6425992779783394, "no_speech_prob": 0.1061549112200737}, {"id": 2677, "seek": 905576, "start": 9055.84, "end": 9060.32, "text": " of machine learning is to generalize beyond the data. If you generalize correctly beyond", "tokens": [50368, 295, 3479, 2539, 307, 281, 2674, 1125, 4399, 264, 1412, 13, 759, 291, 2674, 1125, 8944, 4399, 50592], "temperature": 0.0, "avg_logprob": -0.10991396020959925, "compression_ratio": 1.8847457627118644, "no_speech_prob": 0.41400662064552307}, {"id": 2678, "seek": 905576, "start": 9060.32, "end": 9064.880000000001, "text": " the data, you're not just a parrot anymore. And, you know, I think it's not an accident that that", "tokens": [50592, 264, 1412, 11, 291, 434, 406, 445, 257, 42462, 3602, 13, 400, 11, 291, 458, 11, 286, 519, 309, 311, 406, 364, 6398, 300, 300, 50820], "temperature": 0.0, "avg_logprob": -0.10991396020959925, "compression_ratio": 1.8847457627118644, "no_speech_prob": 0.41400662064552307}, {"id": 2679, "seek": 905576, "start": 9064.880000000001, "end": 9069.84, "text": " term stochastic parrot came from Emily Bender, my linguistics colleague at UW, who does not", "tokens": [50820, 1433, 342, 8997, 2750, 42462, 1361, 490, 15034, 363, 3216, 11, 452, 21766, 6006, 13532, 412, 35691, 11, 567, 775, 406, 51068], "temperature": 0.0, "avg_logprob": -0.10991396020959925, "compression_ratio": 1.8847457627118644, "no_speech_prob": 0.41400662064552307}, {"id": 2680, "seek": 905576, "start": 9069.84, "end": 9075.36, "text": " understand machine learning. She's a classic linguist of the Chomsky and Variety, who does,", "tokens": [51068, 1223, 3479, 2539, 13, 1240, 311, 257, 7230, 21766, 468, 295, 264, 761, 4785, 4133, 293, 14662, 4014, 11, 567, 775, 11, 51344], "temperature": 0.0, "avg_logprob": -0.10991396020959925, "compression_ratio": 1.8847457627118644, "no_speech_prob": 0.41400662064552307}, {"id": 2681, "seek": 905576, "start": 9075.36, "end": 9079.44, "text": " you know, does not fundamentally understand what I think, you know, she might disagree,", "tokens": [51344, 291, 458, 11, 775, 406, 17879, 1223, 437, 286, 519, 11, 291, 458, 11, 750, 1062, 14091, 11, 51548], "temperature": 0.0, "avg_logprob": -0.10991396020959925, "compression_ratio": 1.8847457627118644, "no_speech_prob": 0.41400662064552307}, {"id": 2682, "seek": 905576, "start": 9079.44, "end": 9083.04, "text": " what machine learning is all about. And she would probably look at any learning algorithm and say", "tokens": [51548, 437, 3479, 2539, 307, 439, 466, 13, 400, 750, 576, 1391, 574, 412, 604, 2539, 9284, 293, 584, 51728], "temperature": 0.0, "avg_logprob": -0.10991396020959925, "compression_ratio": 1.8847457627118644, "no_speech_prob": 0.41400662064552307}, {"id": 2683, "seek": 908304, "start": 9083.04, "end": 9087.76, "text": " that it's a stochastic parrot, missing the fact that the whole point of machine learning and the", "tokens": [50364, 300, 309, 311, 257, 342, 8997, 2750, 42462, 11, 5361, 264, 1186, 300, 264, 1379, 935, 295, 3479, 2539, 293, 264, 50600], "temperature": 0.0, "avg_logprob": -0.0817753812100025, "compression_ratio": 1.7413249211356467, "no_speech_prob": 0.02512013539671898}, {"id": 2684, "seek": 908304, "start": 9087.76, "end": 9092.800000000001, "text": " thing that we focus on from, you know, beginning to end is generalizing. And as soon as you're", "tokens": [50600, 551, 300, 321, 1879, 322, 490, 11, 291, 458, 11, 2863, 281, 917, 307, 2674, 3319, 13, 400, 382, 2321, 382, 291, 434, 50852], "temperature": 0.0, "avg_logprob": -0.0817753812100025, "compression_ratio": 1.7413249211356467, "no_speech_prob": 0.02512013539671898}, {"id": 2685, "seek": 908304, "start": 9092.800000000001, "end": 9097.68, "text": " generalizing correctly, even if you have no compositionality, you're already doing something", "tokens": [50852, 2674, 3319, 8944, 11, 754, 498, 291, 362, 572, 12686, 1860, 11, 291, 434, 1217, 884, 746, 51096], "temperature": 0.0, "avg_logprob": -0.0817753812100025, "compression_ratio": 1.7413249211356467, "no_speech_prob": 0.02512013539671898}, {"id": 2686, "seek": 908304, "start": 9097.68, "end": 9102.320000000002, "text": " that has a little bit of intelligence, and that's beyond what a parrot would do.", "tokens": [51096, 300, 575, 257, 707, 857, 295, 7599, 11, 293, 300, 311, 4399, 437, 257, 42462, 576, 360, 13, 51328], "temperature": 0.0, "avg_logprob": -0.0817753812100025, "compression_ratio": 1.7413249211356467, "no_speech_prob": 0.02512013539671898}, {"id": 2687, "seek": 908304, "start": 9102.320000000002, "end": 9106.480000000001, "text": " Yeah, I mean, to be fair, it's not a binary. And at the time, I thought they were stochastic", "tokens": [51328, 865, 11, 286, 914, 11, 281, 312, 3143, 11, 309, 311, 406, 257, 17434, 13, 400, 412, 264, 565, 11, 286, 1194, 436, 645, 342, 8997, 2750, 51536], "temperature": 0.0, "avg_logprob": -0.0817753812100025, "compression_ratio": 1.7413249211356467, "no_speech_prob": 0.02512013539671898}, {"id": 2688, "seek": 908304, "start": 9106.480000000001, "end": 9111.2, "text": " parents as well. I've updated my view. And you were talking as well about creativity. There's", "tokens": [51536, 3152, 382, 731, 13, 286, 600, 10588, 452, 1910, 13, 400, 291, 645, 1417, 382, 731, 466, 12915, 13, 821, 311, 51772], "temperature": 0.0, "avg_logprob": -0.0817753812100025, "compression_ratio": 1.7413249211356467, "no_speech_prob": 0.02512013539671898}, {"id": 2689, "seek": 911120, "start": 9111.2, "end": 9115.28, "text": " a kind of blurred hyperplane of creativity. And we discussed, you know, where that hyperplane", "tokens": [50364, 257, 733, 295, 43525, 9848, 36390, 295, 12915, 13, 400, 321, 7152, 11, 291, 458, 11, 689, 300, 9848, 36390, 50568], "temperature": 0.0, "avg_logprob": -0.07462760443999389, "compression_ratio": 1.82421875, "no_speech_prob": 0.009640039876103401}, {"id": 2690, "seek": 911120, "start": 9116.0, "end": 9120.240000000002, "text": " sits. But, you know, what's really interested me, I've interviewed quite a few people that are", "tokens": [50604, 12696, 13, 583, 11, 291, 458, 11, 437, 311, 534, 3102, 385, 11, 286, 600, 19770, 1596, 257, 1326, 561, 300, 366, 50816], "temperature": 0.0, "avg_logprob": -0.07462760443999389, "compression_ratio": 1.82421875, "no_speech_prob": 0.009640039876103401}, {"id": 2691, "seek": 911120, "start": 9120.240000000002, "end": 9124.800000000001, "text": " working on working on in context learning in these language models. And it seems like these", "tokens": [50816, 1364, 322, 1364, 322, 294, 4319, 2539, 294, 613, 2856, 5245, 13, 400, 309, 2544, 411, 613, 51044], "temperature": 0.0, "avg_logprob": -0.07462760443999389, "compression_ratio": 1.82421875, "no_speech_prob": 0.009640039876103401}, {"id": 2692, "seek": 911120, "start": 9124.800000000001, "end": 9131.12, "text": " language models are almost almost like a new type of compiler, you know, you're writing a program", "tokens": [51044, 2856, 5245, 366, 1920, 1920, 411, 257, 777, 2010, 295, 31958, 11, 291, 458, 11, 291, 434, 3579, 257, 1461, 51360], "temperature": 0.0, "avg_logprob": -0.07462760443999389, "compression_ratio": 1.82421875, "no_speech_prob": 0.009640039876103401}, {"id": 2693, "seek": 911120, "start": 9131.12, "end": 9137.12, "text": " inside the language prompt. And they seem to work extremely well outside of the training", "tokens": [51360, 1854, 264, 2856, 12391, 13, 400, 436, 1643, 281, 589, 4664, 731, 2380, 295, 264, 3097, 51660], "temperature": 0.0, "avg_logprob": -0.07462760443999389, "compression_ratio": 1.82421875, "no_speech_prob": 0.009640039876103401}, {"id": 2694, "seek": 913712, "start": 9137.12, "end": 9140.0, "text": " range if you're doing like basic multiplication tasks.", "tokens": [50364, 3613, 498, 291, 434, 884, 411, 3875, 27290, 9608, 13, 50508], "temperature": 0.0, "avg_logprob": -0.0941214968067731, "compression_ratio": 1.7433333333333334, "no_speech_prob": 0.038375791162252426}, {"id": 2695, "seek": 913712, "start": 9140.0, "end": 9143.84, "text": " I think it is useful to look at them as a new type of compiler. In fact, I've been saying for a", "tokens": [50508, 286, 519, 309, 307, 4420, 281, 574, 412, 552, 382, 257, 777, 2010, 295, 31958, 13, 682, 1186, 11, 286, 600, 668, 1566, 337, 257, 50700], "temperature": 0.0, "avg_logprob": -0.0941214968067731, "compression_ratio": 1.7433333333333334, "no_speech_prob": 0.038375791162252426}, {"id": 2696, "seek": 913712, "start": 9143.84, "end": 9149.28, "text": " long time that, you know, like, there's this continuum from programming an assembly code to", "tokens": [50700, 938, 565, 300, 11, 291, 458, 11, 411, 11, 456, 311, 341, 36120, 490, 9410, 364, 12103, 3089, 281, 50972], "temperature": 0.0, "avg_logprob": -0.0941214968067731, "compression_ratio": 1.7433333333333334, "no_speech_prob": 0.038375791162252426}, {"id": 2697, "seek": 913712, "start": 9149.28, "end": 9154.880000000001, "text": " high level languages to doing AI, right? The point of AI is to continue along that path", "tokens": [50972, 1090, 1496, 8650, 281, 884, 7318, 11, 558, 30, 440, 935, 295, 7318, 307, 281, 2354, 2051, 300, 3100, 51252], "temperature": 0.0, "avg_logprob": -0.0941214968067731, "compression_ratio": 1.7433333333333334, "no_speech_prob": 0.038375791162252426}, {"id": 2698, "seek": 913712, "start": 9154.880000000001, "end": 9160.0, "text": " to making the language that computers speak ever closer to ours, so that we can just program them", "tokens": [51252, 281, 1455, 264, 2856, 300, 10807, 1710, 1562, 4966, 281, 11896, 11, 370, 300, 321, 393, 445, 1461, 552, 51508], "temperature": 0.0, "avg_logprob": -0.0941214968067731, "compression_ratio": 1.7433333333333334, "no_speech_prob": 0.038375791162252426}, {"id": 2699, "seek": 913712, "start": 9160.0, "end": 9164.640000000001, "text": " by talking to them or writing things at them, right? Having said that, I think that, you know,", "tokens": [51508, 538, 1417, 281, 552, 420, 3579, 721, 412, 552, 11, 558, 30, 10222, 848, 300, 11, 286, 519, 300, 11, 291, 458, 11, 51740], "temperature": 0.0, "avg_logprob": -0.0941214968067731, "compression_ratio": 1.7433333333333334, "no_speech_prob": 0.038375791162252426}, {"id": 2700, "seek": 916464, "start": 9165.599999999999, "end": 9171.359999999999, "text": " what goes on in the innards of a transformer, right, is actually still", "tokens": [50412, 437, 1709, 322, 294, 264, 7714, 2287, 295, 257, 31782, 11, 558, 11, 307, 767, 920, 50700], "temperature": 0.0, "avg_logprob": -0.1389123096800687, "compression_ratio": 1.6900369003690037, "no_speech_prob": 0.001323084463365376}, {"id": 2701, "seek": 916464, "start": 9173.92, "end": 9179.92, "text": " very primitive, for lack of a better word, right? There's a lot of, so something I tweeted that", "tokens": [50828, 588, 28540, 11, 337, 5011, 295, 257, 1101, 1349, 11, 558, 30, 821, 311, 257, 688, 295, 11, 370, 746, 286, 25646, 300, 51128], "temperature": 0.0, "avg_logprob": -0.1389123096800687, "compression_ratio": 1.6900369003690037, "no_speech_prob": 0.001323084463365376}, {"id": 2702, "seek": 916464, "start": 9179.92, "end": 9184.4, "text": " got a lot of follow up from people like Yan and Gary and who the pro because they were all bringing", "tokens": [51128, 658, 257, 688, 295, 1524, 493, 490, 561, 411, 13633, 293, 13788, 293, 567, 264, 447, 570, 436, 645, 439, 5062, 51352], "temperature": 0.0, "avg_logprob": -0.1389123096800687, "compression_ratio": 1.6900369003690037, "no_speech_prob": 0.001323084463365376}, {"id": 2703, "seek": 916464, "start": 9184.4, "end": 9188.72, "text": " in their own angles. So this was like, I said, and I think this is an interesting question. It's", "tokens": [51352, 294, 641, 1065, 14708, 13, 407, 341, 390, 411, 11, 286, 848, 11, 293, 286, 519, 341, 307, 364, 1880, 1168, 13, 467, 311, 51568], "temperature": 0.0, "avg_logprob": -0.1389123096800687, "compression_ratio": 1.6900369003690037, "no_speech_prob": 0.001323084463365376}, {"id": 2704, "seek": 916464, "start": 9188.72, "end": 9193.519999999999, "text": " like the interesting question about transformers is what needs to be added to them to get real", "tokens": [51568, 411, 264, 1880, 1168, 466, 4088, 433, 307, 437, 2203, 281, 312, 3869, 281, 552, 281, 483, 957, 51808], "temperature": 0.0, "avg_logprob": -0.1389123096800687, "compression_ratio": 1.6900369003690037, "no_speech_prob": 0.001323084463365376}, {"id": 2705, "seek": 919352, "start": 9193.52, "end": 9198.640000000001, "text": " intelligence. So we should not deny what they have, like the attention mechanism in particular,", "tokens": [50364, 7599, 13, 407, 321, 820, 406, 15744, 437, 436, 362, 11, 411, 264, 3202, 7513, 294, 1729, 11, 50620], "temperature": 0.0, "avg_logprob": -0.12547383614636343, "compression_ratio": 1.762081784386617, "no_speech_prob": 0.023995421826839447}, {"id": 2706, "seek": 919352, "start": 9198.640000000001, "end": 9203.2, "text": " right? And the embeddings and the context. So like, there are two very important things in", "tokens": [50620, 558, 30, 400, 264, 12240, 29432, 293, 264, 4319, 13, 407, 411, 11, 456, 366, 732, 588, 1021, 721, 294, 50848], "temperature": 0.0, "avg_logprob": -0.12547383614636343, "compression_ratio": 1.762081784386617, "no_speech_prob": 0.023995421826839447}, {"id": 2707, "seek": 919352, "start": 9203.2, "end": 9208.24, "text": " transformers that are beyond what was in neural networks 10 years ago and are key. One of them", "tokens": [50848, 4088, 433, 300, 366, 4399, 437, 390, 294, 18161, 9590, 1266, 924, 2057, 293, 366, 2141, 13, 1485, 295, 552, 51100], "temperature": 0.0, "avg_logprob": -0.12547383614636343, "compression_ratio": 1.762081784386617, "no_speech_prob": 0.023995421826839447}, {"id": 2708, "seek": 919352, "start": 9208.24, "end": 9214.720000000001, "text": " is attention, right? Attention is a real advance. And the other one is context specific embeddings,", "tokens": [51100, 307, 3202, 11, 558, 30, 31858, 307, 257, 957, 7295, 13, 400, 264, 661, 472, 307, 4319, 2685, 12240, 29432, 11, 51424], "temperature": 0.0, "avg_logprob": -0.12547383614636343, "compression_ratio": 1.762081784386617, "no_speech_prob": 0.023995421826839447}, {"id": 2709, "seek": 919352, "start": 9214.720000000001, "end": 9218.720000000001, "text": " right? Each of these ideas is important in its own right and combining them together is very", "tokens": [51424, 558, 30, 6947, 295, 613, 3487, 307, 1021, 294, 1080, 1065, 558, 293, 21928, 552, 1214, 307, 588, 51624], "temperature": 0.0, "avg_logprob": -0.12547383614636343, "compression_ratio": 1.762081784386617, "no_speech_prob": 0.023995421826839447}, {"id": 2710, "seek": 921872, "start": 9218.72, "end": 9223.439999999999, "text": " powerful, right? Again, because the context sensitive embeddings get that the similarity", "tokens": [50364, 4005, 11, 558, 30, 3764, 11, 570, 264, 4319, 9477, 12240, 29432, 483, 300, 264, 32194, 50600], "temperature": 0.0, "avg_logprob": -0.12754330706240527, "compression_ratio": 1.8388157894736843, "no_speech_prob": 0.020305726677179337}, {"id": 2711, "seek": 921872, "start": 9223.439999999999, "end": 9227.84, "text": " part of intelligence, the attention combined with the context sensitivity of the embeddings", "tokens": [50600, 644, 295, 7599, 11, 264, 3202, 9354, 365, 264, 4319, 19392, 295, 264, 12240, 29432, 50820], "temperature": 0.0, "avg_logprob": -0.12754330706240527, "compression_ratio": 1.8388157894736843, "no_speech_prob": 0.020305726677179337}, {"id": 2712, "seek": 921872, "start": 9227.84, "end": 9233.439999999999, "text": " gets at the compositionality part. So they do have, so there are a couple of steps forward on", "tokens": [50820, 2170, 412, 264, 12686, 1860, 644, 13, 407, 436, 360, 362, 11, 370, 456, 366, 257, 1916, 295, 4439, 2128, 322, 51100], "temperature": 0.0, "avg_logprob": -0.12754330706240527, "compression_ratio": 1.8388157894736843, "no_speech_prob": 0.020305726677179337}, {"id": 2713, "seek": 921872, "start": 9233.439999999999, "end": 9238.4, "text": " the road to human level intelligence, but there are many more. And rather than either saying like,", "tokens": [51100, 264, 3060, 281, 1952, 1496, 7599, 11, 457, 456, 366, 867, 544, 13, 400, 2831, 813, 2139, 1566, 411, 11, 51348], "temperature": 0.0, "avg_logprob": -0.12754330706240527, "compression_ratio": 1.8388157894736843, "no_speech_prob": 0.020305726677179337}, {"id": 2714, "seek": 921872, "start": 9238.4, "end": 9242.64, "text": " oh, they're just parrots, they don't do anything, we're saying like, we've almost solved the eye,", "tokens": [51348, 1954, 11, 436, 434, 445, 971, 81, 1971, 11, 436, 500, 380, 360, 1340, 11, 321, 434, 1566, 411, 11, 321, 600, 1920, 13041, 264, 3313, 11, 51560], "temperature": 0.0, "avg_logprob": -0.12754330706240527, "compression_ratio": 1.8388157894736843, "no_speech_prob": 0.020305726677179337}, {"id": 2715, "seek": 921872, "start": 9242.64, "end": 9247.359999999999, "text": " what we really should, we should try to understand better, you know, how the, you know,", "tokens": [51560, 437, 321, 534, 820, 11, 321, 820, 853, 281, 1223, 1101, 11, 291, 458, 11, 577, 264, 11, 291, 458, 11, 51796], "temperature": 0.0, "avg_logprob": -0.12754330706240527, "compression_ratio": 1.8388157894736843, "no_speech_prob": 0.020305726677179337}, {"id": 2716, "seek": 924736, "start": 9247.36, "end": 9252.560000000001, "text": " the attention and the context is dependent embeddings work, which we don't. But we also need", "tokens": [50364, 264, 3202, 293, 264, 4319, 307, 12334, 12240, 29432, 589, 11, 597, 321, 500, 380, 13, 583, 321, 611, 643, 50624], "temperature": 0.0, "avg_logprob": -0.15740091660443475, "compression_ratio": 1.7341772151898733, "no_speech_prob": 0.010073981247842312}, {"id": 2717, "seek": 924736, "start": 9252.560000000001, "end": 9257.04, "text": " to focus like, now, what are we still missing? Because we definitely are. And that's really", "tokens": [50624, 281, 1879, 411, 11, 586, 11, 437, 366, 321, 920, 5361, 30, 1436, 321, 2138, 366, 13, 400, 300, 311, 534, 50848], "temperature": 0.0, "avg_logprob": -0.15740091660443475, "compression_ratio": 1.7341772151898733, "no_speech_prob": 0.010073981247842312}, {"id": 2718, "seek": 924736, "start": 9257.04, "end": 9260.960000000001, "text": " where most of our focus should be. Yeah, I completely agree. And also just in defense", "tokens": [50848, 689, 881, 295, 527, 1879, 820, 312, 13, 865, 11, 286, 2584, 3986, 13, 400, 611, 445, 294, 7654, 51044], "temperature": 0.0, "avg_logprob": -0.15740091660443475, "compression_ratio": 1.7341772151898733, "no_speech_prob": 0.010073981247842312}, {"id": 2719, "seek": 924736, "start": 9260.960000000001, "end": 9265.76, "text": " of Bender, I mean, I think she's a brilliant linguist. And I personally think having that", "tokens": [51044, 295, 363, 3216, 11, 286, 914, 11, 286, 519, 750, 311, 257, 10248, 21766, 468, 13, 400, 286, 5665, 519, 1419, 300, 51284], "temperature": 0.0, "avg_logprob": -0.15740091660443475, "compression_ratio": 1.7341772151898733, "no_speech_prob": 0.010073981247842312}, {"id": 2720, "seek": 924736, "start": 9265.76, "end": 9272.960000000001, "text": " diversity of views from different people is useful. No, I mean, so I very much think that having a", "tokens": [51284, 8811, 295, 6809, 490, 819, 561, 307, 4420, 13, 883, 11, 286, 914, 11, 370, 286, 588, 709, 519, 300, 1419, 257, 51644], "temperature": 0.0, "avg_logprob": -0.15740091660443475, "compression_ratio": 1.7341772151898733, "no_speech_prob": 0.010073981247842312}, {"id": 2721, "seek": 924736, "start": 9272.960000000001, "end": 9276.560000000001, "text": " diversity of views is very important. And I think something that I'm always saying to my", "tokens": [51644, 8811, 295, 6809, 307, 588, 1021, 13, 400, 286, 519, 746, 300, 286, 478, 1009, 1566, 281, 452, 51824], "temperature": 0.0, "avg_logprob": -0.15740091660443475, "compression_ratio": 1.7341772151898733, "no_speech_prob": 0.010073981247842312}, {"id": 2722, "seek": 927656, "start": 9276.56, "end": 9281.199999999999, "text": " deep learning friends who can't stand, you know, who hate the guts of Gary Marcus is", "tokens": [50364, 2452, 2539, 1855, 567, 393, 380, 1463, 11, 291, 458, 11, 567, 4700, 264, 28560, 295, 13788, 26574, 307, 50596], "temperature": 0.0, "avg_logprob": -0.10402623089877042, "compression_ratio": 1.6996336996336996, "no_speech_prob": 0.013190589845180511}, {"id": 2723, "seek": 927656, "start": 9281.92, "end": 9288.56, "text": " we really, really need informed critics. Yeah. And very typically, your informed critics are not", "tokens": [50632, 321, 534, 11, 534, 643, 11740, 22503, 13, 865, 13, 400, 588, 5850, 11, 428, 11740, 22503, 366, 406, 50964], "temperature": 0.0, "avg_logprob": -0.10402623089877042, "compression_ratio": 1.6996336996336996, "no_speech_prob": 0.013190589845180511}, {"id": 2724, "seek": 927656, "start": 9288.56, "end": 9294.24, "text": " people in the field. We are experts, but then we also suffer from the distortion of being experts.", "tokens": [50964, 561, 294, 264, 2519, 13, 492, 366, 8572, 11, 457, 550, 321, 611, 9753, 490, 264, 28426, 295, 885, 8572, 13, 51248], "temperature": 0.0, "avg_logprob": -0.10402623089877042, "compression_ratio": 1.6996336996336996, "no_speech_prob": 0.013190589845180511}, {"id": 2725, "seek": 927656, "start": 9294.24, "end": 9300.08, "text": " It's people in adjacent areas. And people like linguists and psychologists are very much those", "tokens": [51248, 467, 311, 561, 294, 24441, 3179, 13, 400, 561, 411, 21766, 1751, 293, 41562, 366, 588, 709, 729, 51540], "temperature": 0.0, "avg_logprob": -0.10402623089877042, "compression_ratio": 1.6996336996336996, "no_speech_prob": 0.013190589845180511}, {"id": 2726, "seek": 927656, "start": 9300.08, "end": 9305.279999999999, "text": " people, they're in adjacent areas, enough to have a good critique of AI. So for example,", "tokens": [51540, 561, 11, 436, 434, 294, 24441, 3179, 11, 1547, 281, 362, 257, 665, 25673, 295, 7318, 13, 407, 337, 1365, 11, 51800], "temperature": 0.0, "avg_logprob": -0.10402623089877042, "compression_ratio": 1.6996336996336996, "no_speech_prob": 0.013190589845180511}, {"id": 2727, "seek": 930528, "start": 9305.28, "end": 9311.2, "text": " something that Jan is always throwing at Gary Marcus, that kind of doesn't sit well with me,", "tokens": [50364, 746, 300, 4956, 307, 1009, 10238, 412, 13788, 26574, 11, 300, 733, 295, 1177, 380, 1394, 731, 365, 385, 11, 50660], "temperature": 0.0, "avg_logprob": -0.14656864513050427, "compression_ratio": 1.7400611620795108, "no_speech_prob": 0.005991433281451464}, {"id": 2728, "seek": 930528, "start": 9311.2, "end": 9315.04, "text": " says like, well, you should try building a real system sometime, and you can criticize this until", "tokens": [50660, 1619, 411, 11, 731, 11, 291, 820, 853, 2390, 257, 957, 1185, 15053, 11, 293, 291, 393, 31010, 341, 1826, 50852], "temperature": 0.0, "avg_logprob": -0.14656864513050427, "compression_ratio": 1.7400611620795108, "no_speech_prob": 0.005991433281451464}, {"id": 2729, "seek": 930528, "start": 9315.04, "end": 9319.2, "text": " we do. If we take the attitude that only engineers can criticize engineers, we're doomed.", "tokens": [50852, 321, 360, 13, 759, 321, 747, 264, 10157, 300, 787, 11955, 393, 31010, 11955, 11, 321, 434, 33847, 13, 51060], "temperature": 0.0, "avg_logprob": -0.14656864513050427, "compression_ratio": 1.7400611620795108, "no_speech_prob": 0.005991433281451464}, {"id": 2730, "seek": 930528, "start": 9320.24, "end": 9324.560000000001, "text": " Having said that, there is a very big distinction between the knowledgeable informed critics like", "tokens": [51112, 10222, 848, 300, 11, 456, 307, 257, 588, 955, 16844, 1296, 264, 33800, 11740, 22503, 411, 51328], "temperature": 0.0, "avg_logprob": -0.14656864513050427, "compression_ratio": 1.7400611620795108, "no_speech_prob": 0.005991433281451464}, {"id": 2731, "seek": 930528, "start": 9324.560000000001, "end": 9329.28, "text": " Gary Marcus, and the not so knowledgeable, not so well informed ones, which unfortunately,", "tokens": [51328, 13788, 26574, 11, 293, 264, 406, 370, 33800, 11, 406, 370, 731, 11740, 2306, 11, 597, 7015, 11, 51564], "temperature": 0.0, "avg_logprob": -0.14656864513050427, "compression_ratio": 1.7400611620795108, "no_speech_prob": 0.005991433281451464}, {"id": 2732, "seek": 930528, "start": 9329.28, "end": 9333.68, "text": " Emily is an example. I mean, she's my colleague at UW. And I've talked with her about some of these", "tokens": [51564, 15034, 307, 364, 1365, 13, 286, 914, 11, 750, 311, 452, 13532, 412, 35691, 13, 400, 286, 600, 2825, 365, 720, 466, 512, 295, 613, 51784], "temperature": 0.0, "avg_logprob": -0.14656864513050427, "compression_ratio": 1.7400611620795108, "no_speech_prob": 0.005991433281451464}, {"id": 2733, "seek": 933368, "start": 9333.68, "end": 9338.32, "text": " things. And her criticism of machine learning, unfortunately, like a lot of people, comes from", "tokens": [50364, 721, 13, 400, 720, 15835, 295, 3479, 2539, 11, 7015, 11, 411, 257, 688, 295, 561, 11, 1487, 490, 50596], "temperature": 0.0, "avg_logprob": -0.11177162538494981, "compression_ratio": 1.7472118959107807, "no_speech_prob": 0.019331878051161766}, {"id": 2734, "seek": 933368, "start": 9338.32, "end": 9343.84, "text": " a place of actually not fundamental understanding it very well. But people do say that Gary isn't", "tokens": [50596, 257, 1081, 295, 767, 406, 8088, 3701, 309, 588, 731, 13, 583, 561, 360, 584, 300, 13788, 1943, 380, 50872], "temperature": 0.0, "avg_logprob": -0.11177162538494981, "compression_ratio": 1.7472118959107807, "no_speech_prob": 0.019331878051161766}, {"id": 2735, "seek": 933368, "start": 9343.84, "end": 9348.48, "text": " an expert in deep learning and that he's, you know, attention seeking. What would you say to that?", "tokens": [50872, 364, 5844, 294, 2452, 2539, 293, 300, 415, 311, 11, 291, 458, 11, 3202, 11670, 13, 708, 576, 291, 584, 281, 300, 30, 51104], "temperature": 0.0, "avg_logprob": -0.11177162538494981, "compression_ratio": 1.7472118959107807, "no_speech_prob": 0.019331878051161766}, {"id": 2736, "seek": 933368, "start": 9348.48, "end": 9357.36, "text": " No, he's not an expert in deep learning. And so like, I agree with some of his criticisms,", "tokens": [51104, 883, 11, 415, 311, 406, 364, 5844, 294, 2452, 2539, 13, 400, 370, 411, 11, 286, 3986, 365, 512, 295, 702, 48519, 11, 51548], "temperature": 0.0, "avg_logprob": -0.11177162538494981, "compression_ratio": 1.7472118959107807, "no_speech_prob": 0.019331878051161766}, {"id": 2737, "seek": 933368, "start": 9357.36, "end": 9363.04, "text": " I disagree with others. Probably on balance, I disagree more with him than I agree. But", "tokens": [51548, 286, 14091, 365, 2357, 13, 9210, 322, 4772, 11, 286, 14091, 544, 365, 796, 813, 286, 3986, 13, 583, 51832], "temperature": 0.0, "avg_logprob": -0.11177162538494981, "compression_ratio": 1.7472118959107807, "no_speech_prob": 0.019331878051161766}, {"id": 2738, "seek": 936368, "start": 9363.68, "end": 9367.84, "text": " first of all, there is a value to having critics like that, number one. But then number two,", "tokens": [50364, 700, 295, 439, 11, 456, 307, 257, 2158, 281, 1419, 22503, 411, 300, 11, 1230, 472, 13, 583, 550, 1230, 732, 11, 50572], "temperature": 0.0, "avg_logprob": -0.1044682374237277, "compression_ratio": 1.84640522875817, "no_speech_prob": 0.002545198192819953}, {"id": 2739, "seek": 936368, "start": 9368.800000000001, "end": 9372.880000000001, "text": " the reason his criticism, I mean, it would be better if he was also an expert in deep learning", "tokens": [50620, 264, 1778, 702, 15835, 11, 286, 914, 11, 309, 576, 312, 1101, 498, 415, 390, 611, 364, 5844, 294, 2452, 2539, 50824], "temperature": 0.0, "avg_logprob": -0.1044682374237277, "compression_ratio": 1.84640522875817, "no_speech_prob": 0.002545198192819953}, {"id": 2740, "seek": 936368, "start": 9372.880000000001, "end": 9377.44, "text": " and made the same criticisms. And then the problem is that often his criticisms are wrong", "tokens": [50824, 293, 1027, 264, 912, 48519, 13, 400, 550, 264, 1154, 307, 300, 2049, 702, 48519, 366, 2085, 51052], "temperature": 0.0, "avg_logprob": -0.1044682374237277, "compression_ratio": 1.84640522875817, "no_speech_prob": 0.002545198192819953}, {"id": 2741, "seek": 936368, "start": 9377.44, "end": 9382.800000000001, "text": " because he has a mental model of deep learning that is already outdated, or is oversimplified,", "tokens": [51052, 570, 415, 575, 257, 4973, 2316, 295, 2452, 2539, 300, 307, 1217, 36313, 11, 420, 307, 15488, 332, 564, 2587, 11, 51320], "temperature": 0.0, "avg_logprob": -0.1044682374237277, "compression_ratio": 1.84640522875817, "no_speech_prob": 0.002545198192819953}, {"id": 2742, "seek": 936368, "start": 9382.800000000001, "end": 9387.44, "text": " right? But that to some degree is unavoidable. But the thing that makes his criticism valuable", "tokens": [51320, 558, 30, 583, 300, 281, 512, 4314, 307, 36541, 17079, 712, 13, 583, 264, 551, 300, 1669, 702, 15835, 8263, 51552], "temperature": 0.0, "avg_logprob": -0.1044682374237277, "compression_ratio": 1.84640522875817, "no_speech_prob": 0.002545198192819953}, {"id": 2743, "seek": 936368, "start": 9387.44, "end": 9392.800000000001, "text": " is that he's doing it at a level where on a good day, on a bad day, his criticisms miss the mark.", "tokens": [51552, 307, 300, 415, 311, 884, 309, 412, 257, 1496, 689, 322, 257, 665, 786, 11, 322, 257, 1578, 786, 11, 702, 48519, 1713, 264, 1491, 13, 51820], "temperature": 0.0, "avg_logprob": -0.1044682374237277, "compression_ratio": 1.84640522875817, "no_speech_prob": 0.002545198192819953}, {"id": 2744, "seek": 939280, "start": 9392.8, "end": 9397.199999999999, "text": " But on a good day, which is the ones that matter, his criticism is actually useful because it's", "tokens": [50364, 583, 322, 257, 665, 786, 11, 597, 307, 264, 2306, 300, 1871, 11, 702, 15835, 307, 767, 4420, 570, 309, 311, 50584], "temperature": 0.0, "avg_logprob": -0.09606051931575853, "compression_ratio": 1.723529411764706, "no_speech_prob": 0.005128154065459967}, {"id": 2745, "seek": 939280, "start": 9397.199999999999, "end": 9401.92, "text": " at a level where you don't need to understand the details. It's like, you claim to be producing", "tokens": [50584, 412, 257, 1496, 689, 291, 500, 380, 643, 281, 1223, 264, 4365, 13, 467, 311, 411, 11, 291, 3932, 281, 312, 10501, 50820], "temperature": 0.0, "avg_logprob": -0.09606051931575853, "compression_ratio": 1.723529411764706, "no_speech_prob": 0.005128154065459967}, {"id": 2746, "seek": 939280, "start": 9401.92, "end": 9407.439999999999, "text": " intelligence. I as a psychologist know a lot about intelligence. That's what I study for a living,", "tokens": [50820, 7599, 13, 286, 382, 257, 29514, 458, 257, 688, 466, 7599, 13, 663, 311, 437, 286, 2979, 337, 257, 2647, 11, 51096], "temperature": 0.0, "avg_logprob": -0.09606051931575853, "compression_ratio": 1.723529411764706, "no_speech_prob": 0.005128154065459967}, {"id": 2747, "seek": 939280, "start": 9407.439999999999, "end": 9412.8, "text": " right? He knows more about aspects of intelligence than I do. Yeah. And from that point of view,", "tokens": [51096, 558, 30, 634, 3255, 544, 466, 7270, 295, 7599, 813, 286, 360, 13, 865, 13, 400, 490, 300, 935, 295, 1910, 11, 51364], "temperature": 0.0, "avg_logprob": -0.09606051931575853, "compression_ratio": 1.723529411764706, "no_speech_prob": 0.005128154065459967}, {"id": 2748, "seek": 939280, "start": 9412.8, "end": 9417.84, "text": " what you're doing is lacking. And that I mean, like, he's written the whole books about, you know,", "tokens": [51364, 437, 291, 434, 884, 307, 20889, 13, 400, 300, 286, 914, 11, 411, 11, 415, 311, 3720, 264, 1379, 3642, 466, 11, 291, 458, 11, 51616], "temperature": 0.0, "avg_logprob": -0.09606051931575853, "compression_ratio": 1.723529411764706, "no_speech_prob": 0.005128154065459967}, {"id": 2749, "seek": 939280, "start": 9417.84, "end": 9422.0, "text": " again, because this goes back to when he was a PhD student and, you know, and symbolic learning and", "tokens": [51616, 797, 11, 570, 341, 1709, 646, 281, 562, 415, 390, 257, 14476, 3107, 293, 11, 291, 458, 11, 293, 25755, 2539, 293, 51824], "temperature": 0.0, "avg_logprob": -0.09606051931575853, "compression_ratio": 1.723529411764706, "no_speech_prob": 0.005128154065459967}, {"id": 2750, "seek": 942200, "start": 9422.0, "end": 9428.48, "text": " whatnot, there are very, you know, the deep learning folks have repeatedly underestimated", "tokens": [50364, 25882, 11, 456, 366, 588, 11, 291, 458, 11, 264, 2452, 2539, 4024, 362, 18227, 24612, 33008, 50688], "temperature": 0.0, "avg_logprob": -0.14212719461192255, "compression_ratio": 1.6456140350877193, "no_speech_prob": 0.01297466829419136}, {"id": 2751, "seek": 942200, "start": 9428.48, "end": 9433.2, "text": " how well he understands some of these problems. Because as a psychologist in particular interested", "tokens": [50688, 577, 731, 415, 15146, 512, 295, 613, 2740, 13, 1436, 382, 257, 29514, 294, 1729, 3102, 50924], "temperature": 0.0, "avg_logprob": -0.14212719461192255, "compression_ratio": 1.6456140350877193, "no_speech_prob": 0.01297466829419136}, {"id": 2752, "seek": 942200, "start": 9433.2, "end": 9438.56, "text": " in language learning, he's actually thought very long and hard about them. Oh, I know. So I've", "tokens": [50924, 294, 2856, 2539, 11, 415, 311, 767, 1194, 588, 938, 293, 1152, 466, 552, 13, 876, 11, 286, 458, 13, 407, 286, 600, 51192], "temperature": 0.0, "avg_logprob": -0.14212719461192255, "compression_ratio": 1.6456140350877193, "no_speech_prob": 0.01297466829419136}, {"id": 2753, "seek": 942200, "start": 9438.56, "end": 9443.52, "text": " read his book and we've had him on the show three times. Which book? The algebraic mind.", "tokens": [51192, 1401, 702, 1446, 293, 321, 600, 632, 796, 322, 264, 855, 1045, 1413, 13, 3013, 1446, 30, 440, 21989, 299, 1575, 13, 51440], "temperature": 0.0, "avg_logprob": -0.14212719461192255, "compression_ratio": 1.6456140350877193, "no_speech_prob": 0.01297466829419136}, {"id": 2754, "seek": 942200, "start": 9443.52, "end": 9447.28, "text": " Yeah. So that's the most relevant one here. Yeah. As a psychologist, you know, he spent a lot of", "tokens": [51440, 865, 13, 407, 300, 311, 264, 881, 7340, 472, 510, 13, 865, 13, 1018, 257, 29514, 11, 291, 458, 11, 415, 4418, 257, 688, 295, 51628], "temperature": 0.0, "avg_logprob": -0.14212719461192255, "compression_ratio": 1.6456140350877193, "no_speech_prob": 0.01297466829419136}, {"id": 2755, "seek": 944728, "start": 9447.28, "end": 9451.6, "text": " time studying how children learn rules. Right. And he talks very elegantly about a", "tokens": [50364, 565, 7601, 577, 2227, 1466, 4474, 13, 1779, 13, 400, 415, 6686, 588, 14459, 3627, 466, 257, 50580], "temperature": 0.0, "avg_logprob": -0.09046530920611925, "compression_ratio": 1.859437751004016, "no_speech_prob": 0.07777795940637589}, {"id": 2756, "seek": 944728, "start": 9451.6, "end": 9455.76, "text": " compositionality. And we've spoken about this. It's irrefutable. And I agree with him and we've", "tokens": [50580, 12686, 1860, 13, 400, 321, 600, 10759, 466, 341, 13, 467, 311, 16014, 69, 32148, 13, 400, 286, 3986, 365, 796, 293, 321, 600, 50788], "temperature": 0.0, "avg_logprob": -0.09046530920611925, "compression_ratio": 1.859437751004016, "no_speech_prob": 0.07777795940637589}, {"id": 2757, "seek": 944728, "start": 9455.76, "end": 9462.400000000001, "text": " supported him. I guess some of the things he argues are based on ethics, politics and virtue.", "tokens": [50788, 8104, 796, 13, 286, 2041, 512, 295, 264, 721, 415, 38218, 366, 2361, 322, 19769, 11, 7341, 293, 20816, 13, 51120], "temperature": 0.0, "avg_logprob": -0.09046530920611925, "compression_ratio": 1.859437751004016, "no_speech_prob": 0.07777795940637589}, {"id": 2758, "seek": 944728, "start": 9462.400000000001, "end": 9468.320000000002, "text": " And some of the things like compositionality, I think are irrefutable. I mean, I think irrefutable", "tokens": [51120, 400, 512, 295, 264, 721, 411, 12686, 1860, 11, 286, 519, 366, 16014, 69, 32148, 13, 286, 914, 11, 286, 519, 16014, 69, 32148, 51416], "temperature": 0.0, "avg_logprob": -0.09046530920611925, "compression_ratio": 1.859437751004016, "no_speech_prob": 0.07777795940637589}, {"id": 2759, "seek": 944728, "start": 9468.320000000002, "end": 9472.480000000001, "text": " is a very strong word. I wouldn't say that they're irrefutable. I would say that they have,", "tokens": [51416, 307, 257, 588, 2068, 1349, 13, 286, 2759, 380, 584, 300, 436, 434, 16014, 69, 32148, 13, 286, 576, 584, 300, 436, 362, 11, 51624], "temperature": 0.0, "avg_logprob": -0.09046530920611925, "compression_ratio": 1.859437751004016, "no_speech_prob": 0.07777795940637589}, {"id": 2760, "seek": 947248, "start": 9473.439999999999, "end": 9479.119999999999, "text": " they have very strong backing, which the connectionists have not been able to effectively", "tokens": [50412, 436, 362, 588, 2068, 19373, 11, 597, 264, 4984, 1751, 362, 406, 668, 1075, 281, 8659, 50696], "temperature": 0.0, "avg_logprob": -0.09809439635473835, "compression_ratio": 1.70863309352518, "no_speech_prob": 0.014487790875136852}, {"id": 2761, "seek": 947248, "start": 9479.119999999999, "end": 9484.88, "text": " refute. But some of the criticisms that they have, you know, meaning people like Pinker and Prince", "tokens": [50696, 1895, 1169, 13, 583, 512, 295, 264, 48519, 300, 436, 362, 11, 291, 458, 11, 3620, 561, 411, 17118, 260, 293, 9821, 50984], "temperature": 0.0, "avg_logprob": -0.09809439635473835, "compression_ratio": 1.70863309352518, "no_speech_prob": 0.014487790875136852}, {"id": 2762, "seek": 947248, "start": 9484.88, "end": 9490.32, "text": " and whatnot, famously of connectionists in the 80s, some of them are still valid, which is very", "tokens": [50984, 293, 25882, 11, 34360, 295, 4984, 1751, 294, 264, 4688, 82, 11, 512, 295, 552, 366, 920, 7363, 11, 597, 307, 588, 51256], "temperature": 0.0, "avg_logprob": -0.09809439635473835, "compression_ratio": 1.70863309352518, "no_speech_prob": 0.014487790875136852}, {"id": 2763, "seek": 947248, "start": 9490.32, "end": 9495.439999999999, "text": " salient. But some of them not really. And again, to go back to the daddy of this whole school of", "tokens": [51256, 1845, 1196, 13, 583, 512, 295, 552, 406, 534, 13, 400, 797, 11, 281, 352, 646, 281, 264, 16785, 295, 341, 1379, 1395, 295, 51512], "temperature": 0.0, "avg_logprob": -0.09809439635473835, "compression_ratio": 1.70863309352518, "no_speech_prob": 0.014487790875136852}, {"id": 2764, "seek": 947248, "start": 9495.439999999999, "end": 9500.88, "text": " thought, who's Chomsky, right? His, you know, he made his name basically panning things like,", "tokens": [51512, 1194, 11, 567, 311, 761, 4785, 4133, 11, 558, 30, 2812, 11, 291, 458, 11, 415, 1027, 702, 1315, 1936, 2462, 773, 721, 411, 11, 51784], "temperature": 0.0, "avg_logprob": -0.09809439635473835, "compression_ratio": 1.70863309352518, "no_speech_prob": 0.014487790875136852}, {"id": 2765, "seek": 950088, "start": 9500.96, "end": 9505.92, "text": " you know, Markov models of language in Graham models, which he could say large language models", "tokens": [50368, 291, 458, 11, 3934, 5179, 5245, 295, 2856, 294, 22691, 5245, 11, 597, 415, 727, 584, 2416, 2856, 5245, 50616], "temperature": 0.0, "avg_logprob": -0.17712099487717087, "compression_ratio": 1.9212328767123288, "no_speech_prob": 0.028334658592939377}, {"id": 2766, "seek": 950088, "start": 9505.92, "end": 9511.439999999999, "text": " are just a very glorified version of, right? But and at the time, you could, that criticism was", "tokens": [50616, 366, 445, 257, 588, 26623, 2587, 3037, 295, 11, 558, 30, 583, 293, 412, 264, 565, 11, 291, 727, 11, 300, 15835, 390, 50892], "temperature": 0.0, "avg_logprob": -0.17712099487717087, "compression_ratio": 1.9212328767123288, "no_speech_prob": 0.028334658592939377}, {"id": 2767, "seek": 950088, "start": 9511.439999999999, "end": 9517.119999999999, "text": " very apt and, you know, and timely and it was useful, right? But, but, but, and famously, it's", "tokens": [50892, 588, 29427, 293, 11, 291, 458, 11, 293, 25150, 293, 309, 390, 4420, 11, 558, 30, 583, 11, 457, 11, 457, 11, 293, 34360, 11, 309, 311, 51176], "temperature": 0.0, "avg_logprob": -0.17712099487717087, "compression_ratio": 1.9212328767123288, "no_speech_prob": 0.028334658592939377}, {"id": 2768, "seek": 950088, "start": 9517.119999999999, "end": 9520.88, "text": " like, it's like, you can't learn a context free grammar, but context free grammar is what you", "tokens": [51176, 411, 11, 309, 311, 411, 11, 291, 393, 380, 1466, 257, 4319, 1737, 22317, 11, 457, 4319, 1737, 22317, 307, 437, 291, 51364], "temperature": 0.0, "avg_logprob": -0.17712099487717087, "compression_ratio": 1.9212328767123288, "no_speech_prob": 0.028334658592939377}, {"id": 2769, "seek": 950088, "start": 9520.88, "end": 9526.16, "text": " do. Well, actually, now we know formally that you can learn a context free grammar. And, and,", "tokens": [51364, 360, 13, 1042, 11, 767, 11, 586, 321, 458, 25983, 300, 291, 393, 1466, 257, 4319, 1737, 22317, 13, 400, 11, 293, 11, 51628], "temperature": 0.0, "avg_logprob": -0.17712099487717087, "compression_ratio": 1.9212328767123288, "no_speech_prob": 0.028334658592939377}, {"id": 2770, "seek": 950088, "start": 9526.16, "end": 9530.08, "text": " you know, because you only have to learn it probabilistically, which is what we do. And", "tokens": [51628, 291, 458, 11, 570, 291, 787, 362, 281, 1466, 309, 31959, 20458, 11, 597, 307, 437, 321, 360, 13, 400, 51824], "temperature": 0.0, "avg_logprob": -0.17712099487717087, "compression_ratio": 1.9212328767123288, "no_speech_prob": 0.028334658592939377}, {"id": 2771, "seek": 953008, "start": 9530.16, "end": 9535.92, "text": " what our systems do. So his criticism was just, you know, mathematically off the mark. But also,", "tokens": [50368, 437, 527, 3652, 360, 13, 407, 702, 15835, 390, 445, 11, 291, 458, 11, 44003, 766, 264, 1491, 13, 583, 611, 11, 50656], "temperature": 0.0, "avg_logprob": -0.09698414398451984, "compression_ratio": 1.667832167832168, "no_speech_prob": 0.012208404950797558}, {"id": 2772, "seek": 953008, "start": 9535.92, "end": 9541.36, "text": " when you look at systems that do speech language, et cetera, et cetera, it is that statistical", "tokens": [50656, 562, 291, 574, 412, 3652, 300, 360, 6218, 2856, 11, 1030, 11458, 11, 1030, 11458, 11, 309, 307, 300, 22820, 50928], "temperature": 0.0, "avg_logprob": -0.09698414398451984, "compression_ratio": 1.667832167832168, "no_speech_prob": 0.012208404950797558}, {"id": 2773, "seek": 953008, "start": 9541.36, "end": 9546.32, "text": " approach that he made his name panning that has prevailed. And for reasons that we understand", "tokens": [50928, 3109, 300, 415, 1027, 702, 1315, 2462, 773, 300, 575, 12642, 24731, 13, 400, 337, 4112, 300, 321, 1223, 51176], "temperature": 0.0, "avg_logprob": -0.09698414398451984, "compression_ratio": 1.667832167832168, "no_speech_prob": 0.012208404950797558}, {"id": 2774, "seek": 953008, "start": 9546.32, "end": 9551.039999999999, "text": " very well, and large language models are just the latest greatest expression of that. So at that", "tokens": [51176, 588, 731, 11, 293, 2416, 2856, 5245, 366, 445, 264, 6792, 6636, 6114, 295, 300, 13, 407, 412, 300, 51412], "temperature": 0.0, "avg_logprob": -0.09698414398451984, "compression_ratio": 1.667832167832168, "no_speech_prob": 0.012208404950797558}, {"id": 2775, "seek": 953008, "start": 9551.039999999999, "end": 9556.88, "text": " level, a whole Chomsky and Pinker, Gary Marcus view of things, not only is it not irrefutable,", "tokens": [51412, 1496, 11, 257, 1379, 761, 4785, 4133, 293, 17118, 260, 11, 13788, 26574, 1910, 295, 721, 11, 406, 787, 307, 309, 406, 16014, 69, 32148, 11, 51704], "temperature": 0.0, "avg_logprob": -0.09698414398451984, "compression_ratio": 1.667832167832168, "no_speech_prob": 0.012208404950797558}, {"id": 2776, "seek": 955688, "start": 9556.88, "end": 9563.599999999999, "text": " it has been refuted. Okay. Let's just quickly come back to your definition of intelligence. So", "tokens": [50364, 309, 575, 668, 1895, 4866, 13, 1033, 13, 961, 311, 445, 2661, 808, 646, 281, 428, 7123, 295, 7599, 13, 407, 50700], "temperature": 0.0, "avg_logprob": -0.12753095018102767, "compression_ratio": 1.5708154506437768, "no_speech_prob": 0.011326909065246582}, {"id": 2777, "seek": 955688, "start": 9563.599999999999, "end": 9569.519999999999, "text": " solving NP hard problems, I assume you would zoom out a little bit and, you know, it's more of a", "tokens": [50700, 12606, 38611, 1152, 2740, 11, 286, 6552, 291, 576, 8863, 484, 257, 707, 857, 293, 11, 291, 458, 11, 309, 311, 544, 295, 257, 50996], "temperature": 0.0, "avg_logprob": -0.12753095018102767, "compression_ratio": 1.5708154506437768, "no_speech_prob": 0.011326909065246582}, {"id": 2778, "seek": 955688, "start": 9569.519999999999, "end": 9573.759999999998, "text": " meta learning algorithm. So the ability to sell to sell different problems.", "tokens": [50996, 19616, 2539, 9284, 13, 407, 264, 3485, 281, 3607, 281, 3607, 819, 2740, 13, 51208], "temperature": 0.0, "avg_logprob": -0.12753095018102767, "compression_ratio": 1.5708154506437768, "no_speech_prob": 0.011326909065246582}, {"id": 2779, "seek": 955688, "start": 9576.16, "end": 9583.92, "text": " Yes. So it's, if very good point, if all you have is the ability to solve one NP complete problem,", "tokens": [51328, 1079, 13, 407, 309, 311, 11, 498, 588, 665, 935, 11, 498, 439, 291, 362, 307, 264, 3485, 281, 5039, 472, 38611, 3566, 1154, 11, 51716], "temperature": 0.0, "avg_logprob": -0.12753095018102767, "compression_ratio": 1.5708154506437768, "no_speech_prob": 0.011326909065246582}, {"id": 2780, "seek": 958392, "start": 9583.92, "end": 9588.88, "text": " that does not qualify as general intelligence, right? There's like, these days, this is a common", "tokens": [50364, 300, 775, 406, 20276, 382, 2674, 7599, 11, 558, 30, 821, 311, 411, 11, 613, 1708, 11, 341, 307, 257, 2689, 50612], "temperature": 0.0, "avg_logprob": -0.11240931503645336, "compression_ratio": 1.8842443729903537, "no_speech_prob": 0.013207247480750084}, {"id": 2781, "seek": 958392, "start": 9588.88, "end": 9593.92, "text": " definition to make this different difference between, you know, narrow intelligence and general", "tokens": [50612, 7123, 281, 652, 341, 819, 2649, 1296, 11, 291, 458, 11, 9432, 7599, 293, 2674, 50864], "temperature": 0.0, "avg_logprob": -0.11240931503645336, "compression_ratio": 1.8842443729903537, "no_speech_prob": 0.013207247480750084}, {"id": 2782, "seek": 958392, "start": 9593.92, "end": 9598.72, "text": " intelligence and AGI and whatnot, right? And if you only solve one NP complete problem very well,", "tokens": [50864, 7599, 293, 316, 26252, 293, 25882, 11, 558, 30, 400, 498, 291, 787, 5039, 472, 38611, 3566, 1154, 588, 731, 11, 51104], "temperature": 0.0, "avg_logprob": -0.11240931503645336, "compression_ratio": 1.8842443729903537, "no_speech_prob": 0.013207247480750084}, {"id": 2783, "seek": 958392, "start": 9598.72, "end": 9602.8, "text": " you have narrow intelligence is the way I would put it, but you do not have general intelligence.", "tokens": [51104, 291, 362, 9432, 7599, 307, 264, 636, 286, 576, 829, 309, 11, 457, 291, 360, 406, 362, 2674, 7599, 13, 51308], "temperature": 0.0, "avg_logprob": -0.11240931503645336, "compression_ratio": 1.8842443729903537, "no_speech_prob": 0.013207247480750084}, {"id": 2784, "seek": 958392, "start": 9602.8, "end": 9608.32, "text": " General intelligence is precisely the ability to solve a limitless variety of problems, all that", "tokens": [51308, 6996, 7599, 307, 13402, 264, 3485, 281, 5039, 257, 4948, 1832, 5673, 295, 2740, 11, 439, 300, 51584], "temperature": 0.0, "avg_logprob": -0.11240931503645336, "compression_ratio": 1.8842443729903537, "no_speech_prob": 0.013207247480750084}, {"id": 2785, "seek": 958392, "start": 9608.32, "end": 9613.6, "text": " have this characteristic of they're hard to solve, but the solution is easy to check. Right? I mean,", "tokens": [51584, 362, 341, 16282, 295, 436, 434, 1152, 281, 5039, 11, 457, 264, 3827, 307, 1858, 281, 1520, 13, 1779, 30, 286, 914, 11, 51848], "temperature": 0.0, "avg_logprob": -0.11240931503645336, "compression_ratio": 1.8842443729903537, "no_speech_prob": 0.013207247480750084}, {"id": 2786, "seek": 961360, "start": 9613.6, "end": 9617.36, "text": " if you have the ability to solve problems, whose solution isn't easy to check, then maybe you're", "tokens": [50364, 498, 291, 362, 264, 3485, 281, 5039, 2740, 11, 6104, 3827, 1943, 380, 1858, 281, 1520, 11, 550, 1310, 291, 434, 50552], "temperature": 0.0, "avg_logprob": -0.11078545073388328, "compression_ratio": 1.6647727272727273, "no_speech_prob": 0.000965110317338258}, {"id": 2787, "seek": 961360, "start": 9617.36, "end": 9623.36, "text": " intelligent, but I can't decide whether intelligent or not. Interesting. Okay. And actually, Gary did,", "tokens": [50552, 13232, 11, 457, 286, 393, 380, 4536, 1968, 13232, 420, 406, 13, 14711, 13, 1033, 13, 400, 767, 11, 13788, 630, 11, 50852], "temperature": 0.0, "avg_logprob": -0.11078545073388328, "compression_ratio": 1.6647727272727273, "no_speech_prob": 0.000965110317338258}, {"id": 2788, "seek": 961360, "start": 9623.36, "end": 9627.44, "text": " he put a paper about 20 years ago talking about how neural networks can't extrapolate. I think it", "tokens": [50852, 415, 829, 257, 3035, 466, 945, 924, 2057, 1417, 466, 577, 18161, 9590, 393, 380, 48224, 473, 13, 286, 519, 309, 51056], "temperature": 0.0, "avg_logprob": -0.11078545073388328, "compression_ratio": 1.6647727272727273, "no_speech_prob": 0.000965110317338258}, {"id": 2789, "seek": 961360, "start": 9627.44, "end": 9633.04, "text": " was when he encoded numbers with a binary encoding or whatever. And we've been on a bit of a journey", "tokens": [51056, 390, 562, 415, 2058, 12340, 3547, 365, 257, 17434, 43430, 420, 2035, 13, 400, 321, 600, 668, 322, 257, 857, 295, 257, 4671, 51336], "temperature": 0.0, "avg_logprob": -0.11078545073388328, "compression_ratio": 1.6647727272727273, "no_speech_prob": 0.000965110317338258}, {"id": 2790, "seek": 961360, "start": 9633.04, "end": 9637.36, "text": " on this. So we had Randall Bellistrier, I've interviewed him yesterday, he's got this paper", "tokens": [51336, 322, 341, 13, 407, 321, 632, 23614, 336, 11485, 468, 7326, 11, 286, 600, 19770, 796, 5186, 11, 415, 311, 658, 341, 3035, 51552], "temperature": 0.0, "avg_logprob": -0.11078545073388328, "compression_ratio": 1.6647727272727273, "no_speech_prob": 0.000965110317338258}, {"id": 2791, "seek": 961360, "start": 9637.36, "end": 9642.640000000001, "text": " called the spline theory of neural networks. It basically says that a neural network decomposes", "tokens": [51552, 1219, 264, 4732, 533, 5261, 295, 18161, 9590, 13, 467, 1936, 1619, 300, 257, 18161, 3209, 22867, 4201, 51816], "temperature": 0.0, "avg_logprob": -0.11078545073388328, "compression_ratio": 1.6647727272727273, "no_speech_prob": 0.000965110317338258}, {"id": 2792, "seek": 964264, "start": 9642.72, "end": 9646.96, "text": " an input space into these input activated polyhedra. And when we first read that,", "tokens": [50368, 364, 4846, 1901, 666, 613, 4846, 18157, 6754, 27096, 424, 13, 400, 562, 321, 700, 1401, 300, 11, 50580], "temperature": 0.0, "avg_logprob": -0.1097132754775713, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0031520246993750334}, {"id": 2793, "seek": 964264, "start": 9646.96, "end": 9652.64, "text": " we felt that it kind of indicated Francois Chollet's assertion that neural networks are", "tokens": [50580, 321, 2762, 300, 309, 733, 295, 16176, 34695, 271, 761, 1833, 302, 311, 19810, 313, 300, 18161, 9590, 366, 50864], "temperature": 0.0, "avg_logprob": -0.1097132754775713, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0031520246993750334}, {"id": 2794, "seek": 964264, "start": 9652.64, "end": 9657.599999999999, "text": " locality sensitive hashing tables, and they only generalize within, you know, these tiny", "tokens": [50864, 1628, 1860, 9477, 575, 571, 8020, 11, 293, 436, 787, 2674, 1125, 1951, 11, 291, 458, 11, 613, 5870, 51112], "temperature": 0.0, "avg_logprob": -0.1097132754775713, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0031520246993750334}, {"id": 2795, "seek": 964264, "start": 9657.599999999999, "end": 9663.359999999999, "text": " polyhedra. And Randall's now updated this view to say in contrast to decision trees, these", "tokens": [51112, 6754, 27096, 424, 13, 400, 23614, 336, 311, 586, 10588, 341, 1910, 281, 584, 294, 8712, 281, 3537, 5852, 11, 613, 51400], "temperature": 0.0, "avg_logprob": -0.1097132754775713, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0031520246993750334}, {"id": 2796, "seek": 964264, "start": 9663.359999999999, "end": 9668.48, "text": " hyperplanes, they actually inform a lot of information in the extrapolative regime outside", "tokens": [51400, 9848, 564, 12779, 11, 436, 767, 1356, 257, 688, 295, 1589, 294, 264, 48224, 1166, 13120, 2380, 51656], "temperature": 0.0, "avg_logprob": -0.1097132754775713, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0031520246993750334}, {"id": 2797, "seek": 966848, "start": 9668.48, "end": 9673.279999999999, "text": " of the training range. So I always thought it was the inductive priors that gave the extrapolative", "tokens": [50364, 295, 264, 3097, 3613, 13, 407, 286, 1009, 1194, 309, 390, 264, 31612, 488, 1790, 830, 300, 2729, 264, 48224, 1166, 50604], "temperature": 0.0, "avg_logprob": -0.10019344195984957, "compression_ratio": 1.6480836236933798, "no_speech_prob": 0.008433413691818714}, {"id": 2798, "seek": 966848, "start": 9673.279999999999, "end": 9678.48, "text": " performance on neural networks by photocopying the information everywhere. And so like, you know,", "tokens": [50604, 3389, 322, 18161, 9590, 538, 2409, 905, 404, 1840, 264, 1589, 5315, 13, 400, 370, 411, 11, 291, 458, 11, 50864], "temperature": 0.0, "avg_logprob": -0.10019344195984957, "compression_ratio": 1.6480836236933798, "no_speech_prob": 0.008433413691818714}, {"id": 2799, "seek": 966848, "start": 9678.48, "end": 9683.039999999999, "text": " this is a great example of where, you know, Gary might update his views because even basic MLPs", "tokens": [50864, 341, 307, 257, 869, 1365, 295, 689, 11, 291, 458, 11, 13788, 1062, 5623, 702, 6809, 570, 754, 3875, 21601, 23043, 51092], "temperature": 0.0, "avg_logprob": -0.10019344195984957, "compression_ratio": 1.6480836236933798, "no_speech_prob": 0.008433413691818714}, {"id": 2800, "seek": 966848, "start": 9683.039999999999, "end": 9688.72, "text": " are far more extrapolative than anyone realized. This is a very interesting question. But the", "tokens": [51092, 366, 1400, 544, 48224, 1166, 813, 2878, 5334, 13, 639, 307, 257, 588, 1880, 1168, 13, 583, 264, 51376], "temperature": 0.0, "avg_logprob": -0.10019344195984957, "compression_ratio": 1.6480836236933798, "no_speech_prob": 0.008433413691818714}, {"id": 2801, "seek": 966848, "start": 9688.72, "end": 9694.16, "text": " way I would put it is that in that regard, in some sense, both of the sides are right.", "tokens": [51376, 636, 286, 576, 829, 309, 307, 300, 294, 300, 3843, 11, 294, 512, 2020, 11, 1293, 295, 264, 4881, 366, 558, 13, 51648], "temperature": 0.0, "avg_logprob": -0.10019344195984957, "compression_ratio": 1.6480836236933798, "no_speech_prob": 0.008433413691818714}, {"id": 2802, "seek": 969416, "start": 9694.88, "end": 9698.4, "text": " And the reason they're both right is that we're in very high dimensional spaces.", "tokens": [50400, 400, 264, 1778, 436, 434, 1293, 558, 307, 300, 321, 434, 294, 588, 1090, 18795, 7673, 13, 50576], "temperature": 0.0, "avg_logprob": -0.08065670414974815, "compression_ratio": 1.7769230769230768, "no_speech_prob": 0.09387877583503723}, {"id": 2803, "seek": 969416, "start": 9698.4, "end": 9702.8, "text": " Yeah. And we're in a very high dimensional space. The follow thing can happen, which is,", "tokens": [50576, 865, 13, 400, 321, 434, 294, 257, 588, 1090, 18795, 1901, 13, 440, 1524, 551, 393, 1051, 11, 597, 307, 11, 50796], "temperature": 0.0, "avg_logprob": -0.08065670414974815, "compression_ratio": 1.7769230769230768, "no_speech_prob": 0.09387877583503723}, {"id": 2804, "seek": 969416, "start": 9702.8, "end": 9708.88, "text": " you know, you have a data point, and you generalize to a vast region around that data point. And it's", "tokens": [50796, 291, 458, 11, 291, 362, 257, 1412, 935, 11, 293, 291, 2674, 1125, 281, 257, 8369, 4458, 926, 300, 1412, 935, 13, 400, 309, 311, 51100], "temperature": 0.0, "avg_logprob": -0.08065670414974815, "compression_ratio": 1.7769230769230768, "no_speech_prob": 0.09387877583503723}, {"id": 2805, "seek": 969416, "start": 9708.88, "end": 9714.0, "text": " unfair to characterize these things as saying they just interpolate. In some sense, they really do", "tokens": [51100, 17019, 281, 38463, 613, 721, 382, 1566, 436, 445, 44902, 473, 13, 682, 512, 2020, 11, 436, 534, 360, 51356], "temperature": 0.0, "avg_logprob": -0.08065670414974815, "compression_ratio": 1.7769230769230768, "no_speech_prob": 0.09387877583503723}, {"id": 2806, "seek": 969416, "start": 9714.0, "end": 9720.08, "text": " extrapolate. But at the same time, that vast region that they generalize correctly to is an", "tokens": [51356, 48224, 473, 13, 583, 412, 264, 912, 565, 11, 300, 8369, 4458, 300, 436, 2674, 1125, 8944, 281, 307, 364, 51660], "temperature": 0.0, "avg_logprob": -0.08065670414974815, "compression_ratio": 1.7769230769230768, "no_speech_prob": 0.09387877583503723}, {"id": 2807, "seek": 972008, "start": 9720.08, "end": 9725.039999999999, "text": " infinitesimal fraction of the much, much vaster reason that they have not generalized to but you", "tokens": [50364, 7193, 3324, 10650, 14135, 295, 264, 709, 11, 709, 371, 1727, 1778, 300, 436, 362, 406, 2674, 1602, 281, 457, 291, 50612], "temperature": 0.0, "avg_logprob": -0.14923697402796796, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.004818959627300501}, {"id": 2808, "seek": 972008, "start": 9725.039999999999, "end": 9731.28, "text": " and I can. So you got to keep that distinction in mind. And then in particular, right, I like to", "tokens": [50612, 293, 286, 393, 13, 407, 291, 658, 281, 1066, 300, 16844, 294, 1575, 13, 400, 550, 294, 1729, 11, 558, 11, 286, 411, 281, 50924], "temperature": 0.0, "avg_logprob": -0.14923697402796796, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.004818959627300501}, {"id": 2809, "seek": 972008, "start": 9731.28, "end": 9737.76, "text": " say that deep learning is nearest neighbor in curved space. And both parts of that are very", "tokens": [50924, 584, 300, 2452, 2539, 307, 23831, 5987, 294, 24991, 1901, 13, 400, 1293, 3166, 295, 300, 366, 588, 51248], "temperature": 0.0, "avg_logprob": -0.14923697402796796, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.004818959627300501}, {"id": 2810, "seek": 972008, "start": 9737.76, "end": 9745.52, "text": " important, right? So, you know, Jan Lacoon was famous, you know, during the glory days of kernel", "tokens": [51248, 1021, 11, 558, 30, 407, 11, 291, 458, 11, 4956, 40113, 4106, 390, 4618, 11, 291, 458, 11, 1830, 264, 11924, 1708, 295, 28256, 51636], "temperature": 0.0, "avg_logprob": -0.14923697402796796, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.004818959627300501}, {"id": 2811, "seek": 974552, "start": 9745.52, "end": 9751.04, "text": " machines for saying that kernel machines are just glorified template matches. Right. And of", "tokens": [50364, 8379, 337, 1566, 300, 28256, 8379, 366, 445, 26623, 2587, 12379, 10676, 13, 1779, 13, 400, 295, 50640], "temperature": 0.0, "avg_logprob": -0.1709910739551891, "compression_ratio": 1.928082191780822, "no_speech_prob": 0.14017413556575775}, {"id": 2812, "seek": 974552, "start": 9751.04, "end": 9754.720000000001, "text": " course, they didn't earn him any friends, but he was right. They really are just glorified template", "tokens": [50640, 1164, 11, 436, 994, 380, 6012, 796, 604, 1855, 11, 457, 415, 390, 558, 13, 814, 534, 366, 445, 26623, 2587, 12379, 50824], "temperature": 0.0, "avg_logprob": -0.1709910739551891, "compression_ratio": 1.928082191780822, "no_speech_prob": 0.14017413556575775}, {"id": 2813, "seek": 974552, "start": 9754.720000000001, "end": 9759.44, "text": " matches. Kernel machine is really a souped up, more mathematically elegant and blah, blah,", "tokens": [50824, 10676, 13, 40224, 338, 3479, 307, 534, 257, 7884, 292, 493, 11, 544, 44003, 21117, 293, 12288, 11, 12288, 11, 51060], "temperature": 0.0, "avg_logprob": -0.1709910739551891, "compression_ratio": 1.928082191780822, "no_speech_prob": 0.14017413556575775}, {"id": 2814, "seek": 974552, "start": 9759.44, "end": 9763.84, "text": " blah version of nearest neighbor. Right. And the nearest neighbor is just a template matcher.", "tokens": [51060, 12288, 3037, 295, 23831, 5987, 13, 1779, 13, 400, 264, 23831, 5987, 307, 445, 257, 12379, 2995, 260, 13, 51280], "temperature": 0.0, "avg_logprob": -0.1709910739551891, "compression_ratio": 1.928082191780822, "no_speech_prob": 0.14017413556575775}, {"id": 2815, "seek": 974552, "start": 9764.4, "end": 9768.4, "text": " The beauty in the power of nearest neighbor, though, is that there is a neighborhood within", "tokens": [51308, 440, 6643, 294, 264, 1347, 295, 23831, 5987, 11, 1673, 11, 307, 300, 456, 307, 257, 7630, 1951, 51508], "temperature": 0.0, "avg_logprob": -0.1709910739551891, "compression_ratio": 1.928082191780822, "no_speech_prob": 0.14017413556575775}, {"id": 2816, "seek": 974552, "start": 9768.4, "end": 9774.08, "text": " which often it generalizes very well. Right. Now, I think what Jan was missing, and I probably", "tokens": [51508, 597, 2049, 309, 2674, 5660, 588, 731, 13, 1779, 13, 823, 11, 286, 519, 437, 4956, 390, 5361, 11, 293, 286, 1391, 51792], "temperature": 0.0, "avg_logprob": -0.1709910739551891, "compression_ratio": 1.928082191780822, "no_speech_prob": 0.14017413556575775}, {"id": 2817, "seek": 977408, "start": 9774.08, "end": 9780.96, "text": " still is, is that coordinates and deep learning, they are still just a glory. They are also glorified", "tokens": [50364, 920, 307, 11, 307, 300, 21056, 293, 2452, 2539, 11, 436, 366, 920, 445, 257, 11924, 13, 814, 366, 611, 26623, 2587, 50708], "temperature": 0.0, "avg_logprob": -0.14252470173966994, "compression_ratio": 1.874015748031496, "no_speech_prob": 0.0188047643750906}, {"id": 2818, "seek": 977408, "start": 9780.96, "end": 9786.4, "text": " nearest neighbor, except more glorified. And the way in which they're more glorified, which is", "tokens": [50708, 23831, 5987, 11, 3993, 544, 26623, 2587, 13, 400, 264, 636, 294, 597, 436, 434, 544, 26623, 2587, 11, 597, 307, 50980], "temperature": 0.0, "avg_logprob": -0.14252470173966994, "compression_ratio": 1.874015748031496, "no_speech_prob": 0.0188047643750906}, {"id": 2819, "seek": 977408, "start": 9786.4, "end": 9790.96, "text": " very important is that they are doing nearest neighbor in curved space. They are still just", "tokens": [50980, 588, 1021, 307, 300, 436, 366, 884, 23831, 5987, 294, 24991, 1901, 13, 814, 366, 920, 445, 51208], "temperature": 0.0, "avg_logprob": -0.14252470173966994, "compression_ratio": 1.874015748031496, "no_speech_prob": 0.0188047643750906}, {"id": 2820, "seek": 977408, "start": 9790.96, "end": 9795.76, "text": " doing, you know, generalization by similarity, which you could argue is all that machine learning", "tokens": [51208, 884, 11, 291, 458, 11, 2674, 2144, 538, 32194, 11, 597, 291, 727, 9695, 307, 439, 300, 3479, 2539, 51448], "temperature": 0.0, "avg_logprob": -0.14252470173966994, "compression_ratio": 1.874015748031496, "no_speech_prob": 0.0188047643750906}, {"id": 2821, "seek": 977408, "start": 9795.76, "end": 9800.8, "text": " does is generalizing by similarity. Another notion of similarity can vary. Right. But the", "tokens": [51448, 775, 307, 2674, 3319, 538, 32194, 13, 3996, 10710, 295, 32194, 393, 10559, 13, 1779, 13, 583, 264, 51700], "temperature": 0.0, "avg_logprob": -0.14252470173966994, "compression_ratio": 1.874015748031496, "no_speech_prob": 0.0188047643750906}, {"id": 2822, "seek": 980080, "start": 9800.8, "end": 9804.08, "text": " important thing that they've done is that nearest neighbor just uses some distance", "tokens": [50364, 1021, 551, 300, 436, 600, 1096, 307, 300, 23831, 5987, 445, 4960, 512, 4560, 50528], "temperature": 0.0, "avg_logprob": -0.1388206954829949, "compression_ratio": 1.7541528239202657, "no_speech_prob": 0.004645319655537605}, {"id": 2823, "seek": 980080, "start": 9804.08, "end": 9809.119999999999, "text": " measured in the original space, whereas the neural networks are warping the space to make", "tokens": [50528, 12690, 294, 264, 3380, 1901, 11, 9735, 264, 18161, 9590, 366, 1516, 3381, 264, 1901, 281, 652, 50780], "temperature": 0.0, "avg_logprob": -0.1388206954829949, "compression_ratio": 1.7541528239202657, "no_speech_prob": 0.004645319655537605}, {"id": 2824, "seek": 980080, "start": 9809.119999999999, "end": 9814.88, "text": " the problem easier for the nearest neighbor, you know, essentially dot product based similarity", "tokens": [50780, 264, 1154, 3571, 337, 264, 23831, 5987, 11, 291, 458, 11, 4476, 5893, 1674, 2361, 32194, 51068], "temperature": 0.0, "avg_logprob": -0.1388206954829949, "compression_ratio": 1.7541528239202657, "no_speech_prob": 0.004645319655537605}, {"id": 2825, "seek": 980080, "start": 9816.16, "end": 9820.08, "text": " computation that they're actually doing. Oh, sure. But you're very much arguing,", "tokens": [51132, 24903, 300, 436, 434, 767, 884, 13, 876, 11, 988, 13, 583, 291, 434, 588, 709, 19697, 11, 51328], "temperature": 0.0, "avg_logprob": -0.1388206954829949, "compression_ratio": 1.7541528239202657, "no_speech_prob": 0.004645319655537605}, {"id": 2826, "seek": 980080, "start": 9820.08, "end": 9823.119999999999, "text": " this is the way Francois Chouelet puts it, that, you know, you have all of these", "tokens": [51328, 341, 307, 264, 636, 34695, 271, 761, 263, 15966, 8137, 309, 11, 300, 11, 291, 458, 11, 291, 362, 439, 295, 613, 51480], "temperature": 0.0, "avg_logprob": -0.1388206954829949, "compression_ratio": 1.7541528239202657, "no_speech_prob": 0.004645319655537605}, {"id": 2827, "seek": 980080, "start": 9824.08, "end": 9830.08, "text": " transformations and you kind of distort the space, you know, to represent the data manifold. And,", "tokens": [51528, 34852, 293, 291, 733, 295, 37555, 264, 1901, 11, 291, 458, 11, 281, 2906, 264, 1412, 47138, 13, 400, 11, 51828], "temperature": 0.0, "avg_logprob": -0.1388206954829949, "compression_ratio": 1.7541528239202657, "no_speech_prob": 0.004645319655537605}, {"id": 2828, "seek": 983008, "start": 9830.08, "end": 9834.72, "text": " you know, you want it to, you stop SGD at the right time so that you approximate the data", "tokens": [50364, 291, 458, 11, 291, 528, 309, 281, 11, 291, 1590, 34520, 35, 412, 264, 558, 565, 370, 300, 291, 30874, 264, 1412, 50596], "temperature": 0.0, "avg_logprob": -0.06998832051346941, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.00036789485602639616}, {"id": 2829, "seek": 983008, "start": 9834.72, "end": 9839.6, "text": " manifold and you can do this kind of latent space, you know, interpolation on the geodesic of that", "tokens": [50596, 47138, 293, 291, 393, 360, 341, 733, 295, 48994, 1901, 11, 291, 458, 11, 44902, 399, 322, 264, 1519, 4789, 299, 295, 300, 50840], "temperature": 0.0, "avg_logprob": -0.06998832051346941, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.00036789485602639616}, {"id": 2830, "seek": 983008, "start": 9839.6, "end": 9844.8, "text": " manifold. But, you know, Randall's idea is completely away from that idea of, you know,", "tokens": [50840, 47138, 13, 583, 11, 291, 458, 11, 23614, 336, 311, 1558, 307, 2584, 1314, 490, 300, 1558, 295, 11, 291, 458, 11, 51100], "temperature": 0.0, "avg_logprob": -0.06998832051346941, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.00036789485602639616}, {"id": 2831, "seek": 983008, "start": 9844.8, "end": 9852.16, "text": " these models learning this curved space. And so if you do slice the space up with these hyperplanes,", "tokens": [51100, 613, 5245, 2539, 341, 24991, 1901, 13, 400, 370, 498, 291, 360, 13153, 264, 1901, 493, 365, 613, 9848, 564, 12779, 11, 51468], "temperature": 0.0, "avg_logprob": -0.06998832051346941, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.00036789485602639616}, {"id": 2832, "seek": 983008, "start": 9852.16, "end": 9856.16, "text": " rather than it being a locality prior, which is what you're talking about, these hyperplanes give", "tokens": [51468, 2831, 813, 309, 885, 257, 1628, 1860, 4059, 11, 597, 307, 437, 291, 434, 1417, 466, 11, 613, 9848, 564, 12779, 976, 51668], "temperature": 0.0, "avg_logprob": -0.06998832051346941, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.00036789485602639616}, {"id": 2833, "seek": 985616, "start": 9856.16, "end": 9861.36, "text": " you globally relevant information to things that are, you know, miles away from the training data.", "tokens": [50364, 291, 18958, 7340, 1589, 281, 721, 300, 366, 11, 291, 458, 11, 6193, 1314, 490, 264, 3097, 1412, 13, 50624], "temperature": 0.0, "avg_logprob": -0.15060888982452122, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.013003574684262276}, {"id": 2834, "seek": 985616, "start": 9861.36, "end": 9869.039999999999, "text": " Yeah, so, but these two perspectives are more similar than you might think, because I can take", "tokens": [50624, 865, 11, 370, 11, 457, 613, 732, 16766, 366, 544, 2531, 813, 291, 1062, 519, 11, 570, 286, 393, 747, 51008], "temperature": 0.0, "avg_logprob": -0.15060888982452122, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.013003574684262276}, {"id": 2835, "seek": 985616, "start": 9869.68, "end": 9875.68, "text": " a distorted version of space and decompose it into polyhedron, right? And one or the other might", "tokens": [51040, 257, 33431, 3037, 295, 1901, 293, 22867, 541, 309, 666, 6754, 27096, 2044, 11, 558, 30, 400, 472, 420, 264, 661, 1062, 51340], "temperature": 0.0, "avg_logprob": -0.15060888982452122, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.013003574684262276}, {"id": 2836, "seek": 985616, "start": 9875.68, "end": 9879.92, "text": " approximate what's really going on better. I mean, these neural networks do form curved spaces,", "tokens": [51340, 30874, 437, 311, 534, 516, 322, 1101, 13, 286, 914, 11, 613, 18161, 9590, 360, 1254, 24991, 7673, 11, 51552], "temperature": 0.0, "avg_logprob": -0.15060888982452122, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.013003574684262276}, {"id": 2837, "seek": 985616, "start": 9879.92, "end": 9883.84, "text": " except they're in practice, they're not curved because they find it, but ignoring that, right?", "tokens": [51552, 3993, 436, 434, 294, 3124, 11, 436, 434, 406, 24991, 570, 436, 915, 309, 11, 457, 26258, 300, 11, 558, 30, 51748], "temperature": 0.0, "avg_logprob": -0.15060888982452122, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.013003574684262276}, {"id": 2838, "seek": 988384, "start": 9884.8, "end": 9892.08, "text": " When, let me put it this way, an eloquent example of this is if you look back at the original space,", "tokens": [50412, 1133, 11, 718, 385, 829, 309, 341, 636, 11, 364, 38682, 28842, 1365, 295, 341, 307, 498, 291, 574, 646, 412, 264, 3380, 1901, 11, 50776], "temperature": 0.0, "avg_logprob": -0.147237548828125, "compression_ratio": 1.7808219178082192, "no_speech_prob": 0.0027555213309824467}, {"id": 2839, "seek": 988384, "start": 9892.08, "end": 9898.0, "text": " right? Again, treat this thing as a black box. Where does it generalize to? Does it generalize", "tokens": [50776, 558, 30, 3764, 11, 2387, 341, 551, 382, 257, 2211, 2424, 13, 2305, 775, 309, 2674, 1125, 281, 30, 4402, 309, 2674, 1125, 51072], "temperature": 0.0, "avg_logprob": -0.147237548828125, "compression_ratio": 1.7808219178082192, "no_speech_prob": 0.0027555213309824467}, {"id": 2840, "seek": 988384, "start": 9898.0, "end": 9903.28, "text": " only to things, neural networks as we have them today? Does it generalize correctly only to things", "tokens": [51072, 787, 281, 721, 11, 18161, 9590, 382, 321, 362, 552, 965, 30, 4402, 309, 2674, 1125, 8944, 787, 281, 721, 51336], "temperature": 0.0, "avg_logprob": -0.147237548828125, "compression_ratio": 1.7808219178082192, "no_speech_prob": 0.0027555213309824467}, {"id": 2841, "seek": 988384, "start": 9903.28, "end": 9910.64, "text": " that are locally near the data point, or you can generalize well to things that are far, right?", "tokens": [51336, 300, 366, 16143, 2651, 264, 1412, 935, 11, 420, 291, 393, 2674, 1125, 731, 281, 721, 300, 366, 1400, 11, 558, 30, 51704], "temperature": 0.0, "avg_logprob": -0.147237548828125, "compression_ratio": 1.7808219178082192, "no_speech_prob": 0.0027555213309824467}, {"id": 2842, "seek": 991064, "start": 9910.64, "end": 9915.76, "text": " And the thing is that with nearest neighbor, you buy, you know, almost intrinsically, you only", "tokens": [50364, 400, 264, 551, 307, 300, 365, 23831, 5987, 11, 291, 2256, 11, 291, 458, 11, 1920, 28621, 984, 11, 291, 787, 50620], "temperature": 0.0, "avg_logprob": -0.09066254128026598, "compression_ratio": 1.8847457627118644, "no_speech_prob": 0.010310402140021324}, {"id": 2843, "seek": 991064, "start": 9915.76, "end": 9921.84, "text": " generalize period at all to things that are local. The beauty of deep learning and of the", "tokens": [50620, 2674, 1125, 2896, 412, 439, 281, 721, 300, 366, 2654, 13, 440, 6643, 295, 2452, 2539, 293, 295, 264, 50924], "temperature": 0.0, "avg_logprob": -0.09066254128026598, "compression_ratio": 1.8847457627118644, "no_speech_prob": 0.010310402140021324}, {"id": 2844, "seek": 991064, "start": 9921.84, "end": 9926.0, "text": " space swapping that's going on is, again, going back to this notion of the path kernel is that", "tokens": [50924, 1901, 1693, 10534, 300, 311, 516, 322, 307, 11, 797, 11, 516, 646, 281, 341, 10710, 295, 264, 3100, 28256, 307, 300, 51132], "temperature": 0.0, "avg_logprob": -0.09066254128026598, "compression_ratio": 1.8847457627118644, "no_speech_prob": 0.010310402140021324}, {"id": 2845, "seek": 991064, "start": 9926.0, "end": 9930.16, "text": " you're actually doing a nearest neighbor computation, not just in a space that's swapped,", "tokens": [51132, 291, 434, 767, 884, 257, 23831, 5987, 24903, 11, 406, 445, 294, 257, 1901, 300, 311, 50011, 11, 51340], "temperature": 0.0, "avg_logprob": -0.09066254128026598, "compression_ratio": 1.8847457627118644, "no_speech_prob": 0.010310402140021324}, {"id": 2846, "seek": 991064, "start": 9930.16, "end": 9934.24, "text": " but you're doing it in the space of gradients, which actually means that you can generalize", "tokens": [51340, 457, 291, 434, 884, 309, 294, 264, 1901, 295, 2771, 2448, 11, 597, 767, 1355, 300, 291, 393, 2674, 1125, 51544], "temperature": 0.0, "avg_logprob": -0.09066254128026598, "compression_ratio": 1.8847457627118644, "no_speech_prob": 0.010310402140021324}, {"id": 2847, "seek": 991064, "start": 9934.24, "end": 9939.68, "text": " correctly to things that are very far from your examples, except they look similar in gradient", "tokens": [51544, 8944, 281, 721, 300, 366, 588, 1400, 490, 428, 5110, 11, 3993, 436, 574, 2531, 294, 16235, 51816], "temperature": 0.0, "avg_logprob": -0.09066254128026598, "compression_ratio": 1.8847457627118644, "no_speech_prob": 0.010310402140021324}, {"id": 2848, "seek": 993968, "start": 9939.68, "end": 9945.6, "text": " space. A very simple example of this is a sine wave, right? If I try to learn a sine wave using", "tokens": [50364, 1901, 13, 316, 588, 2199, 1365, 295, 341, 307, 257, 18609, 5772, 11, 558, 30, 759, 286, 853, 281, 1466, 257, 18609, 5772, 1228, 50660], "temperature": 0.0, "avg_logprob": -0.08447622101882409, "compression_ratio": 1.7962382445141065, "no_speech_prob": 0.025919627398252487}, {"id": 2849, "seek": 993968, "start": 9945.6, "end": 9950.880000000001, "text": " nearest neighbor, I need an infinite number of examples, right? Because, you know, like what", "tokens": [50660, 23831, 5987, 11, 286, 643, 364, 13785, 1230, 295, 5110, 11, 558, 30, 1436, 11, 291, 458, 11, 411, 437, 50924], "temperature": 0.0, "avg_logprob": -0.08447622101882409, "compression_ratio": 1.7962382445141065, "no_speech_prob": 0.025919627398252487}, {"id": 2850, "seek": 993968, "start": 9950.880000000001, "end": 9955.84, "text": " I've learned over here helps me not at all with the next turn of the sine wave, like that continuous", "tokens": [50924, 286, 600, 3264, 670, 510, 3665, 385, 406, 412, 439, 365, 264, 958, 1261, 295, 264, 18609, 5772, 11, 411, 300, 10957, 51172], "temperature": 0.0, "avg_logprob": -0.08447622101882409, "compression_ratio": 1.7962382445141065, "no_speech_prob": 0.025919627398252487}, {"id": 2851, "seek": 993968, "start": 9955.84, "end": 9960.4, "text": " extrapolation, right? At some point, there's this disaster where if the last piece of the", "tokens": [51172, 48224, 399, 11, 558, 30, 1711, 512, 935, 11, 456, 311, 341, 11293, 689, 498, 264, 1036, 2522, 295, 264, 51400], "temperature": 0.0, "avg_logprob": -0.08447622101882409, "compression_ratio": 1.7962382445141065, "no_speech_prob": 0.025919627398252487}, {"id": 2852, "seek": 993968, "start": 9960.4, "end": 9965.04, "text": " sine was going up, I just keep going up and getting more and more wrong, right? And in fact,", "tokens": [51400, 18609, 390, 516, 493, 11, 286, 445, 1066, 516, 493, 293, 1242, 544, 293, 544, 2085, 11, 558, 30, 400, 294, 1186, 11, 51632], "temperature": 0.0, "avg_logprob": -0.08447622101882409, "compression_ratio": 1.7962382445141065, "no_speech_prob": 0.025919627398252487}, {"id": 2853, "seek": 993968, "start": 9965.04, "end": 9969.52, "text": " this kind of thing does happen in neural networks, but they also have the part to say like, and this", "tokens": [51632, 341, 733, 295, 551, 775, 1051, 294, 18161, 9590, 11, 457, 436, 611, 362, 264, 644, 281, 584, 411, 11, 293, 341, 51856], "temperature": 0.0, "avg_logprob": -0.08447622101882409, "compression_ratio": 1.7962382445141065, "no_speech_prob": 0.025919627398252487}, {"id": 2854, "seek": 996952, "start": 9969.6, "end": 9975.76, "text": " again, this also happens, which is I'm going to transform this space more into a more intelligent", "tokens": [50368, 797, 11, 341, 611, 2314, 11, 597, 307, 286, 478, 516, 281, 4088, 341, 1901, 544, 666, 257, 544, 13232, 50676], "temperature": 0.0, "avg_logprob": -0.06459257913672406, "compression_ratio": 1.6652173913043478, "no_speech_prob": 0.0023198071867227554}, {"id": 2855, "seek": 996952, "start": 9975.76, "end": 9982.32, "text": " one, which is the space of the slopes, right? And now if I've seen one cycle of the sine wave", "tokens": [50676, 472, 11, 597, 307, 264, 1901, 295, 264, 37725, 11, 558, 30, 400, 586, 498, 286, 600, 1612, 472, 6586, 295, 264, 18609, 5772, 51004], "temperature": 0.0, "avg_logprob": -0.06459257913672406, "compression_ratio": 1.6652173913043478, "no_speech_prob": 0.0023198071867227554}, {"id": 2856, "seek": 996952, "start": 9983.12, "end": 9989.68, "text": " with some density of examples, by similarity in that transformed space, I generalize correctly", "tokens": [51044, 365, 512, 10305, 295, 5110, 11, 538, 32194, 294, 300, 16894, 1901, 11, 286, 2674, 1125, 8944, 51372], "temperature": 0.0, "avg_logprob": -0.06459257913672406, "compression_ratio": 1.6652173913043478, "no_speech_prob": 0.0023198071867227554}, {"id": 2857, "seek": 996952, "start": 9989.68, "end": 9995.76, "text": " and trivially to every other turn of the sine wave. So there's a very big fundamental difference", "tokens": [51372, 293, 1376, 85, 2270, 281, 633, 661, 1261, 295, 264, 18609, 5772, 13, 407, 456, 311, 257, 588, 955, 8088, 2649, 51676], "temperature": 0.0, "avg_logprob": -0.06459257913672406, "compression_ratio": 1.6652173913043478, "no_speech_prob": 0.0023198071867227554}, {"id": 2858, "seek": 999576, "start": 9995.84, "end": 9999.6, "text": " between the two. Interesting. And you think with an MLP, it would be possible to have that kind", "tokens": [50368, 1296, 264, 732, 13, 14711, 13, 400, 291, 519, 365, 364, 21601, 47, 11, 309, 576, 312, 1944, 281, 362, 300, 733, 50556], "temperature": 0.0, "avg_logprob": -0.12270315028419179, "compression_ratio": 1.651567944250871, "no_speech_prob": 0.05020318180322647}, {"id": 2859, "seek": 999576, "start": 9999.6, "end": 10004.24, "text": " of extrapolative generalization on a sine wave? Well, so people have studied this in multiple", "tokens": [50556, 295, 48224, 1166, 2674, 2144, 322, 257, 18609, 5772, 30, 1042, 11, 370, 561, 362, 9454, 341, 294, 3866, 50788], "temperature": 0.0, "avg_logprob": -0.12270315028419179, "compression_ratio": 1.651567944250871, "no_speech_prob": 0.05020318180322647}, {"id": 2860, "seek": 999576, "start": 10004.24, "end": 10011.84, "text": " ways. And the problem, so the question is, it depends on what are the basis functions that it's", "tokens": [50788, 2098, 13, 400, 264, 1154, 11, 370, 264, 1168, 307, 11, 309, 5946, 322, 437, 366, 264, 5143, 6828, 300, 309, 311, 51168], "temperature": 0.0, "avg_logprob": -0.12270315028419179, "compression_ratio": 1.651567944250871, "no_speech_prob": 0.05020318180322647}, {"id": 2861, "seek": 999576, "start": 10011.84, "end": 10017.52, "text": " using. Yes. So something that we didn't allude to at all in this conversation, but analyze all of", "tokens": [51168, 1228, 13, 1079, 13, 407, 746, 300, 321, 994, 380, 439, 2303, 281, 412, 439, 294, 341, 3761, 11, 457, 12477, 439, 295, 51452], "temperature": 0.0, "avg_logprob": -0.12270315028419179, "compression_ratio": 1.651567944250871, "no_speech_prob": 0.05020318180322647}, {"id": 2862, "seek": 999576, "start": 10017.52, "end": 10021.84, "text": " this is like, what is your choice of basis functions, right? And the thing is, an MLP with", "tokens": [51452, 341, 307, 411, 11, 437, 307, 428, 3922, 295, 5143, 6828, 11, 558, 30, 400, 264, 551, 307, 11, 364, 21601, 47, 365, 51668], "temperature": 0.0, "avg_logprob": -0.12270315028419179, "compression_ratio": 1.651567944250871, "no_speech_prob": 0.05020318180322647}, {"id": 2863, "seek": 1002184, "start": 10021.92, "end": 10026.56, "text": " the traditional, say, sigmoid or allude basis functions will not learn this, no matter, for", "tokens": [50368, 264, 5164, 11, 584, 11, 4556, 3280, 327, 420, 439, 2303, 5143, 6828, 486, 406, 1466, 341, 11, 572, 1871, 11, 337, 50600], "temperature": 0.0, "avg_logprob": -0.12851711168681104, "compression_ratio": 1.8184713375796178, "no_speech_prob": 0.02632358856499195}, {"id": 2864, "seek": 1002184, "start": 10026.56, "end": 10031.04, "text": " obvious reasons, right? And again, you can represent it, right? The representative theorem is there,", "tokens": [50600, 6322, 4112, 11, 558, 30, 400, 797, 11, 291, 393, 2906, 309, 11, 558, 30, 440, 12424, 20904, 307, 456, 11, 50824], "temperature": 0.0, "avg_logprob": -0.12851711168681104, "compression_ratio": 1.8184713375796178, "no_speech_prob": 0.02632358856499195}, {"id": 2865, "seek": 1002184, "start": 10031.04, "end": 10035.12, "text": " like the sine wave is just one sigmoid and then another one, you know, with a minus sign and", "tokens": [50824, 411, 264, 18609, 5772, 307, 445, 472, 4556, 3280, 327, 293, 550, 1071, 472, 11, 291, 458, 11, 365, 257, 3175, 1465, 293, 51028], "temperature": 0.0, "avg_logprob": -0.12851711168681104, "compression_ratio": 1.8184713375796178, "no_speech_prob": 0.02632358856499195}, {"id": 2866, "seek": 1002184, "start": 10035.12, "end": 10041.12, "text": " then another one, but the data doesn't let you learn it. If as a basis function, you have sine", "tokens": [51028, 550, 1071, 472, 11, 457, 264, 1412, 1177, 380, 718, 291, 1466, 309, 13, 759, 382, 257, 5143, 2445, 11, 291, 362, 18609, 51328], "temperature": 0.0, "avg_logprob": -0.12851711168681104, "compression_ratio": 1.8184713375796178, "no_speech_prob": 0.02632358856499195}, {"id": 2867, "seek": 1002184, "start": 10041.12, "end": 10044.960000000001, "text": " waves, which is nothing unimaginable, that's what a Fourier transform is then, then you can learn", "tokens": [51328, 9417, 11, 597, 307, 1825, 517, 44976, 712, 11, 300, 311, 437, 257, 36810, 4088, 307, 550, 11, 550, 291, 393, 1466, 51520], "temperature": 0.0, "avg_logprob": -0.12851711168681104, "compression_ratio": 1.8184713375796178, "no_speech_prob": 0.02632358856499195}, {"id": 2868, "seek": 1002184, "start": 10044.960000000001, "end": 10050.64, "text": " it so easily, it's not even funny. So it depends dramatically on the basis function. And the", "tokens": [51520, 309, 370, 3612, 11, 309, 311, 406, 754, 4074, 13, 407, 309, 5946, 17548, 322, 264, 5143, 2445, 13, 400, 264, 51804], "temperature": 0.0, "avg_logprob": -0.12851711168681104, "compression_ratio": 1.8184713375796178, "no_speech_prob": 0.02632358856499195}, {"id": 2869, "seek": 1005064, "start": 10050.64, "end": 10055.359999999999, "text": " question really becomes, what are the basis functions and the architect that let me generalize", "tokens": [50364, 1168, 534, 3643, 11, 437, 366, 264, 5143, 6828, 293, 264, 6331, 300, 718, 385, 2674, 1125, 50600], "temperature": 0.0, "avg_logprob": -0.14464324794403494, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.0007090153521858156}, {"id": 2870, "seek": 1005064, "start": 10055.359999999999, "end": 10060.24, "text": " correctly to a lot of things, including this, such that, for example, and this is a very simple test,", "tokens": [50600, 8944, 281, 257, 688, 295, 721, 11, 3009, 341, 11, 1270, 300, 11, 337, 1365, 11, 293, 341, 307, 257, 588, 2199, 1500, 11, 50844], "temperature": 0.0, "avg_logprob": -0.14464324794403494, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.0007090153521858156}, {"id": 2871, "seek": 1005064, "start": 10060.24, "end": 10066.16, "text": " is like, I can nail a sine wave with a small number of examples without it being one of my basis", "tokens": [50844, 307, 411, 11, 286, 393, 10173, 257, 18609, 5772, 365, 257, 1359, 1230, 295, 5110, 1553, 309, 885, 472, 295, 452, 5143, 51140], "temperature": 0.0, "avg_logprob": -0.14464324794403494, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.0007090153521858156}, {"id": 2872, "seek": 1005064, "start": 10066.16, "end": 10070.08, "text": " functions. Yeah, exactly. And then this all comes back to, you know, we're talking about inductive", "tokens": [51140, 6828, 13, 865, 11, 2293, 13, 400, 550, 341, 439, 1487, 646, 281, 11, 291, 458, 11, 321, 434, 1417, 466, 31612, 488, 51336], "temperature": 0.0, "avg_logprob": -0.14464324794403494, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.0007090153521858156}, {"id": 2873, "seek": 1005064, "start": 10070.08, "end": 10074.16, "text": " prize and the bias variance trade off and even symmetries, actually. I mean, the Taco Cohen once", "tokens": [51336, 12818, 293, 264, 12577, 21977, 4923, 766, 293, 754, 14232, 302, 2244, 11, 767, 13, 286, 914, 11, 264, 37992, 32968, 1564, 51540], "temperature": 0.0, "avg_logprob": -0.14464324794403494, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.0007090153521858156}, {"id": 2874, "seek": 1005064, "start": 10074.16, "end": 10079.68, "text": " said that, you know, if you encode all of the symmetries into the label function, then you would", "tokens": [51540, 848, 300, 11, 291, 458, 11, 498, 291, 2058, 1429, 439, 295, 264, 14232, 302, 2244, 666, 264, 7645, 2445, 11, 550, 291, 576, 51816], "temperature": 0.0, "avg_logprob": -0.14464324794403494, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.0007090153521858156}, {"id": 2875, "seek": 1007968, "start": 10079.68, "end": 10084.48, "text": " only need one labeled example. So it's always a trade off between how much induction are you doing?", "tokens": [50364, 787, 643, 472, 21335, 1365, 13, 407, 309, 311, 1009, 257, 4923, 766, 1296, 577, 709, 33371, 366, 291, 884, 30, 50604], "temperature": 0.0, "avg_logprob": -0.20222991307576496, "compression_ratio": 1.6734693877551021, "no_speech_prob": 0.0043209027498960495}, {"id": 2876, "seek": 1007968, "start": 10084.48, "end": 10089.68, "text": " Well, interesting, you should say that I understand why he says that and it's, and it's not technically", "tokens": [50604, 1042, 11, 1880, 11, 291, 820, 584, 300, 286, 1223, 983, 415, 1619, 300, 293, 309, 311, 11, 293, 309, 311, 406, 12120, 50864], "temperature": 0.0, "avg_logprob": -0.20222991307576496, "compression_ratio": 1.6734693877551021, "no_speech_prob": 0.0043209027498960495}, {"id": 2877, "seek": 1007968, "start": 10089.68, "end": 10095.76, "text": " wrong. But I would say that practically what you need is such a set of symmetries per region of", "tokens": [50864, 2085, 13, 583, 286, 576, 584, 300, 15667, 437, 291, 643, 307, 1270, 257, 992, 295, 14232, 302, 2244, 680, 4458, 295, 51168], "temperature": 0.0, "avg_logprob": -0.20222991307576496, "compression_ratio": 1.6734693877551021, "no_speech_prob": 0.0043209027498960495}, {"id": 2878, "seek": 1007968, "start": 10095.76, "end": 10102.16, "text": " the space, per cluster, right? But, you know, in another way, I would actually make an even", "tokens": [51168, 264, 1901, 11, 680, 13630, 11, 558, 30, 583, 11, 291, 458, 11, 294, 1071, 636, 11, 286, 576, 767, 652, 364, 754, 51488], "temperature": 0.0, "avg_logprob": -0.20222991307576496, "compression_ratio": 1.6734693877551021, "no_speech_prob": 0.0043209027498960495}, {"id": 2879, "seek": 1007968, "start": 10102.16, "end": 10108.08, "text": " stronger statement, which again, is very perfectly mathematical, sounds same when you say, an object", "tokens": [51488, 7249, 5629, 11, 597, 797, 11, 307, 588, 6239, 18894, 11, 3263, 912, 562, 291, 584, 11, 364, 2657, 51784], "temperature": 0.0, "avg_logprob": -0.20222991307576496, "compression_ratio": 1.6734693877551021, "no_speech_prob": 0.0043209027498960495}, {"id": 2880, "seek": 1010808, "start": 10108.08, "end": 10114.24, "text": " is just the sum of its symmetries or a function. If you tell me all the symmetries, every last one", "tokens": [50364, 307, 445, 264, 2408, 295, 1080, 14232, 302, 2244, 420, 257, 2445, 13, 759, 291, 980, 385, 439, 264, 14232, 302, 2244, 11, 633, 1036, 472, 50672], "temperature": 0.0, "avg_logprob": -0.0857088015629695, "compression_ratio": 1.8604651162790697, "no_speech_prob": 0.006482183001935482}, {"id": 2881, "seek": 1010808, "start": 10114.24, "end": 10120.32, "text": " of an object, you've defined the object. So if I can learn the symmetries at that level, I don't", "tokens": [50672, 295, 364, 2657, 11, 291, 600, 7642, 264, 2657, 13, 407, 498, 286, 393, 1466, 264, 14232, 302, 2244, 412, 300, 1496, 11, 286, 500, 380, 50976], "temperature": 0.0, "avg_logprob": -0.0857088015629695, "compression_ratio": 1.8604651162790697, "no_speech_prob": 0.006482183001935482}, {"id": 2882, "seek": 1010808, "start": 10120.32, "end": 10124.64, "text": " need anything else. Of course, as we already discussed, that's not the whole answer. Likewise,", "tokens": [50976, 643, 1340, 1646, 13, 2720, 1164, 11, 382, 321, 1217, 7152, 11, 300, 311, 406, 264, 1379, 1867, 13, 30269, 11, 51192], "temperature": 0.0, "avg_logprob": -0.0857088015629695, "compression_ratio": 1.8604651162790697, "no_speech_prob": 0.006482183001935482}, {"id": 2883, "seek": 1010808, "start": 10124.64, "end": 10130.0, "text": " with any function, if you tell me all the properties of the function, there are there, you know,", "tokens": [51192, 365, 604, 2445, 11, 498, 291, 980, 385, 439, 264, 7221, 295, 264, 2445, 11, 456, 366, 456, 11, 291, 458, 11, 51460], "temperature": 0.0, "avg_logprob": -0.0857088015629695, "compression_ratio": 1.8604651162790697, "no_speech_prob": 0.006482183001935482}, {"id": 2884, "seek": 1010808, "start": 10130.56, "end": 10134.16, "text": " to be more precise, all the symmetries of a function at some point, you've told me the whole", "tokens": [51488, 281, 312, 544, 13600, 11, 439, 264, 14232, 302, 2244, 295, 257, 2445, 412, 512, 935, 11, 291, 600, 1907, 385, 264, 1379, 51668], "temperature": 0.0, "avg_logprob": -0.0857088015629695, "compression_ratio": 1.8604651162790697, "no_speech_prob": 0.006482183001935482}, {"id": 2885, "seek": 1013416, "start": 10134.16, "end": 10138.64, "text": " function. And vice versa, from the function, I can, you know, I can read out all the symmetries", "tokens": [50364, 2445, 13, 400, 11964, 25650, 11, 490, 264, 2445, 11, 286, 393, 11, 291, 458, 11, 286, 393, 1401, 484, 439, 264, 14232, 302, 2244, 50588], "temperature": 0.0, "avg_logprob": -0.10156900742474724, "compression_ratio": 1.6539923954372624, "no_speech_prob": 0.024336323142051697}, {"id": 2886, "seek": 1013416, "start": 10138.64, "end": 10142.96, "text": " that it has. In principle, doing that in practice can be, you know, a very difficult and subtle", "tokens": [50588, 300, 309, 575, 13, 682, 8665, 11, 884, 300, 294, 3124, 393, 312, 11, 291, 458, 11, 257, 588, 2252, 293, 13743, 50804], "temperature": 0.0, "avg_logprob": -0.10156900742474724, "compression_ratio": 1.6539923954372624, "no_speech_prob": 0.024336323142051697}, {"id": 2887, "seek": 1013416, "start": 10142.96, "end": 10147.119999999999, "text": " thing to do. That's a beautiful thing to say. You give me the symmetries and I'll give you the", "tokens": [50804, 551, 281, 360, 13, 663, 311, 257, 2238, 551, 281, 584, 13, 509, 976, 385, 264, 14232, 302, 2244, 293, 286, 603, 976, 291, 264, 51012], "temperature": 0.0, "avg_logprob": -0.10156900742474724, "compression_ratio": 1.6539923954372624, "no_speech_prob": 0.024336323142051697}, {"id": 2888, "seek": 1013416, "start": 10147.119999999999, "end": 10151.44, "text": " object. Yeah, exactly. Amazing. Professor Pedro Domingos, thank you so much for joining us today.", "tokens": [51012, 2657, 13, 865, 11, 2293, 13, 14165, 13, 8419, 26662, 413, 10539, 329, 11, 1309, 291, 370, 709, 337, 5549, 505, 965, 13, 51228], "temperature": 0.0, "avg_logprob": -0.10156900742474724, "compression_ratio": 1.6539923954372624, "no_speech_prob": 0.024336323142051697}, {"id": 2889, "seek": 1013416, "start": 10151.44, "end": 10153.84, "text": " It's been an honor. Thanks for having me. Amazing.", "tokens": [51228, 467, 311, 668, 364, 5968, 13, 2561, 337, 1419, 385, 13, 14165, 13, 51348], "temperature": 0.0, "avg_logprob": -0.10156900742474724, "compression_ratio": 1.6539923954372624, "no_speech_prob": 0.024336323142051697}], "language": "en"}