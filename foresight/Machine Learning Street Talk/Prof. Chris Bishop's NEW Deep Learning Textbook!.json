{"text": " Today we have the privilege of speaking with Professor Chris Bishop, a luminary in the field of artificial intelligence and machine learning. Chris is a technical fellow and director at Microsoft Research, AI for Science, in Cambridge. He's also honorary professor of computer science at the University of Edinburgh and fellow of Darwin College, Cambridge. Hi, nice to meet you Tim. This is the new book on Deep Learning Foundations and Concepts published with my son Hugh. What proper have you got? Ethanol. I don't know if I'll use it but we're going to talk about invariance. That's wonderful, that's wonderful. Because you ought to get a little bit techy at some point. Oh yeah, our audience loves that. In 2004 he was elected fellow of the Royal Academy of Engineering, in 2007 he was elected fellow of the Royal Society of Edinburgh and in 2017 he was elected fellow of the Royal Society. Chris was a founding member of the UK AI Council and in 2019 he was appointed to the Prime Minister's Council for Science and Technology. At Microsoft Research, Chris oversees a global portfolio of industrial research and development with a strong focus on machine learning and the natural sciences. Chris obtained a BA in physics from Oxford and a PhD in theoretical physics from the University of Edinburgh with a thesis on quantum field theory. Chris's contributions to the field of machine learning have been truly remarkable. He's authored one of the main textbooks in the field which is Pattern Recognition and Machine Learning or PRML. It has served as an essential reference for countless students and researchers around the world. Chris explained in the interview how it steered the field towards a more probabilistic perspective at the time and he also mentioned his first textbook Neural Networks for Pattern Recognition and its role in promoting neural networks as a powerful tool for machine learning. So this is the new textbook, Deep Learning, Foundations and Concepts and one of the things that we're proud of with this book is the production values. We really worked with the publisher to ensure the book would be produced to a high physical quality and in particular it's produced with what are called stitched signatures. So if you look down the edge there you'll see the pages are not simply glued in. Instead this uses an offset printing technique where 16 pages are printed on a big sheet of paper on both sides. Some of the pages are turned upside down and then the page of the paper is folded and then folded and then folded again and trimmed and the resulting set is called a signature and actually stitched in with cord. And the point about that is it allows the book to open flat so it means that the book is easy to read and it means it should last a long time. What are your favourite figures in the book Chris? Well the ones produced by my son of course are the best. I mean here's a nice picture of the transformer architecture which is this is GPT so you could say it's one of the most important figures in the book I suppose and I just love the way he's done this. How did you do the research for this? So that's a great question. I think you know one of the big challenges with writing a book like this is knowing what to include and what not to include and with literally thousands of papers being published every month it can be overwhelming for the authors never mind the readers. So I think the value we add in the book is trying to distill out what we think of as the core concept. So part of this was really looking at key papers in the field seeing what relatively recent ideas there are but also trying to focus down on techniques and ideas that we believe will actually stand the test of time. We don't have this book to go out of date in a year or two we want it to have have lasting value and of course it's quite possible there'll be a breakthrough next week and that it will turn out to be a very important new architecture but for the most part many of the core concepts actually go back a long way and so what we've really done is taken some some of the foundations of the field and brought them into the modern deep learning era but the idea of probabilities the idea of gradient based methods and so on those have been around for decades and they're just as applicable today as they ever were. One of the things I really like actually is the chapter on convolutional networks. My son Hugh did a lot of this chapter he works on using techniques like convolutional neural nets as part of his work on autonomous vehicles and I think there's a really nice description here of convolutional networks really from the ground up explaining the the basic concepts and but also motivating them not just saying this is how a convolutional network is built but why is it built this way how do we actually motivate it so that's one of my favorite chapters as well. Yeah it's been a very interesting career and at this stage of the career I can now finally look back and make sense of it but at the time it felt like a bit of a random walk so actually when I was a teenager I went to see 2001 A Space Odyssey it was actually very inspired by that rather abstract concept of an artificial intelligence very different from the usual sort of Hollywood the trail of robots so I was very interested in the idea of artificial intelligence from a young age but I was very uninspired by the field of AI at the time which was very much sort of rule based and and didn't seem to be on a path through intelligence and then I did a PhD in quantum field theory which is a very hot field at the time gauge field theory at Edinburgh University had a wonderful time at the end of my PhD though I wanted to do something a bit more practical a bit more useful and so I went into the fusion program I'm a big fan of nuclear fusion it was sort of 30 years away then and it's kind of still 30 years away now but I'm still a big believer but I went to work on talk about physics essentially theoretical physics of of plasmas trying to trying to understand the instabilities and control them so I was working very happily as a theoretical physicist having a having a great time and after about 10 years or so as a theoretical physicist Jeff Hinton published the backprop paper and it came to my attention and I found that very inspiring because there I saw a very very different approach to towards intelligence and so I started by applying neural networks to data from the fusion program because it was big data in its day I was I was working there to the the jet tokamak and they had many many high resolution diagnostics I had lots of data to play with and I became more and more fascinated by neural networks and then I did a sort of completely crazy thing I walked away from a very respectable career as a theoretical physicist and went full-time into the field of neural nets which at the time was not really a respectable field I would say it's not wasn't mainstream computer science it certainly wasn't physics it wasn't really anything but I just found it very inspiring and I was particularly inspired by the work of Jeff Hinton and so I've been in that field for you know three and a half decades now and of course recent history suggests that was probably a good career move and now most recently I've brought the two ends of my career together because I'm now very excited about the impact that neural nets and machine learning are having on the natural sciences including physics. Hinton is a famous connectionist so he believes that knowledge is sub-symbolic and I speaking with Nick Chater the other week he had a book called The Mind is Flat which is talking about the inscrutability of our brains. How do you feel that things have changed? I mean you were talking about a convergence of these different ideas in AI. I think one thing that's very interesting is that there has been a lot of discussion let's say from 2012 onwards when deep learning was clearly being very successful a lot of discussion that it was missing the sort of symbolic approach that we somehow to find a way to combine this connectionist approach to use that sort of probably rather dated term now but that sort of you know that neural net approach with the more traditional symbolic approach and I think what we've seen with models like GPT-4 for example that it's perfectly capable of reasoning at a more symbolic level not at the level of a human being of course but it can do that that kind of more abstract higher level reasoning and so I think what we're seeing with neural nets is rather like the human brain. The human brain doesn't have a connectionist neural net piece then some other machinery that does symbolic reasoning that that that same substrate is capable of all of these different kinds of reasoning and these different kinds of intelligence and we're starting to see that emerge now with neural net so I think I think for me the discussion of should we somehow combine symbolic reasoning with with connectionism no that that to me that's a piece of history it's about how can we how can we expand on the capabilities of neural nets. Yeah that's so interesting I remember there was a paper by Polition I think it was the the connectionist critique in 1988 and I was quite sold on this idea of you know systematicity and productivity and so on and even now folks from that school of thought think that our brains are Turing machines this ability to address potential infinity and I guess what I'm getting from what you're saying is that the distinction isn't really there anymore you can do that kind of reasoning with neural networks. Well I take a very simple view which is that neural nets in that since 2012 in particular have been shown to be spectacularly capable and there's no end in sight the rate of progress is faster now than ever so it seems very straight nobody imagines that that machine learning and deep learning has suddenly ended at you know whatever the time is today you know this is this is this is the beginning of an S-curve so the idea that we would worry so much about the limitations of neural networks and what they can't do I think we just you put the word yet at the end of it your neural networks can't do x y and z yet but but I don't think any sense we've hit the buffers of of what neural nets can do and it's by far the most successful of the most rapidly advancing technology we have so to me you should look for the keys under the lamppost we have this powerful technology that's getting better by the week why would we not see how far we can push it rather than worry about its limitations. Absolutely now Professor Bishop you are incredibly famous for your book PRML but of course it wasn't your first book as you were just speaking to but what was I mean could you just tell us about your your motivations and just the thought process behind that book? Yes so as you said it wasn't my first book my first book is published in 1995 Neural Networks for Pattern Recognition and that book had a very specific motivation which is that I was a newcomer to the field I mentioned earlier that I got excited about backprop and and sort of transition from theoretical physics into machine learning. That was my way of learning about the field you know if you're a university professor a great way to learn about something is to teach a course on it because it forces you to think about it very carefully you're going to get tricky questions from smart students and you're very motivated to to really understand it and so for me the analogue of that was was writing a book. PRML was rather different by the time we got to published in 2006 and by then the field was much larger its sense it was much more mature as a much more established and respected field there were many courses on machine learning the goal there was very different I simply wanted to write the as it were the book that everybody would use to learn about the field so it was trying to be comprehensive but trying to be to explain the concepts as clearly as possible and so really that was the goal the goal was to in a sense you know replace the earlier neural nets for pattern recognition book which was which serves an important role in its day I think but really try to produce a single coherent text where people could learn about the different topics in you know with a shared notation and hopefully trying to explain things as clearly as I could. We know in theoretical physics you know you can you can write down an equation but solving it may be extremely difficult you have to resort to approximations but it's still nice to have that that north star that compass that guides you and so for me I try to think of machine learning in similar terms there are some some foundations that that really don't change much over time that are that are very good guiding principles and we're dealing with data we're dealing with uncertainty we want to be quantitative so you're led very naturally indeed uniquely into probability theory and if you apply probability theory consistently that is the Bayesian framework so for me the Bayesian framework is a very natural bedrock on which you can build and think about machine learning now just as with theoretical physics you can't often just solve things exactly and certainly the Bayesian paradigm calls for integration or marginalization of all possible values of the parameters in your neural network well you always operate with a fixed computational budget right it may be a huge one but it be always constrained by by computational budget and should you spend that budget doing a very thorough Bayesian marginalization over a small neural network or should you take the same number of compute cycles and train a very much larger network and if you have plenty of data to train the larger network then the latter seems to be much more effective in a practical sense so while from a practical point of view the Bayesian approach still has certain applications in in various domains for the most part it's not the framework we'd want to use in in sort of mainstream machine learning today we're much more interested in scale and making point estimates in using stagastic gradient send and so on so I still think that students should learn the basic ideas of of Bayesian inference because really they have to learn you have to learn about probability I don't think you can be in machine learning and not understand probability and then once you understand probability and you apply it uniformly that that really is the Bayesian framework so I think it's the foundation but then you're led to make approximations and in particular you make point estimates so in practice you don't actually execute the full Bayesian paradigm yeah I agree that um Bayesian reasoning is it's beautiful and it's the continuation even of sort of propositional logic in the domain of uncertainty it's fundamental but there is this question of the world is a very gnarly place and folks argue that the brain is a kind of Bayesian inference machine but it can't it can't possibly be solving the intractable Bayesian problem and therein lies the question so there are many hybrids or even deep learning approaches could be seen as some kind of a continuation or somewhere on the spectrum between maximum likelihood point estimation and Bayesian models I mean how do you think about that spectrum I think that's a great that's a great question I think you're spot on there if you look back to a time when there are a lot of competitions here's a data set we're going to hold out the test set you've got to score as high as you can on the test set and what approach should you use the winner always is an ensemble you should try 10 different things preferably diverse and then combine them suitably maybe taking an average or some smarter combination and that ensemble will always outperform any one single model so if you're not constrained by compute and in some of those competitions you weren't then the ensemble always wins and you can think about that ensemble is like as you say a sort of rough and ready approximation to a full marginalization of all of the uncertainty in the predictions that you might make and so I think there's a little glimmer of sort of Bayesian approaches coming through there but again you know in the modern era you're probably better off training one single large model than 10 smaller ones and averaging so it's so I think knowing about the Bayesian paradigm and understanding where you can learn from it is still valuable today but nevertheless it's unlikely in most applications that you're going to want to apply the full Bayesian machinery because it's just so computational expensive fascinating I mean just one more thing on this do you think of large you know let's say large language models but large deep learning models do you think of them as one model or do you think of them as an inscrutable bundle of models because we're kind of getting into the no-free lunch theorem here coming from the Bayesian world we design models you know using principles and with neural networks we just train these big black boxes so do you think of them as one model or lots of models I certainly I always think of them as a single model I've never thought thought of them as separate models unless you unless you explicitly construct a mixture of experts or something like that you have an internal an internal structure I guess everything is sort of very distributed and somehow sort of holographic and overlapping and you know a remarkable thing about GPT-4 is that you know you often see people when they first they first use it they'll ask some question how tall is the Eiffel Tower and it probably gets the right answer and you know it's like oh that's kind of interesting and you're sort of a little bit disappointed in this technology but it's like being given the keys to a very expensive sports car and you notice the cup holders and you notice that it can can support a cup rather nicely you don't realize you need to start the engine and and drive off in it to really get the full experience and so until you realize that actually you can you can have a conversation it can it can write poetry it can explain jokes it can write code it can do so many many different things and that all those capabilities embedded in the same model and and what is I think a really interesting lesson of the last few years is that models like GPT-4 outperform the specialist models so for example in my lab we had a project for many years which essentially said the following it said well you know this is Microsoft world's biggest software company we have lots of source code we could use source code as training data for machine learning we've added all sorts of things you know spot bugs do water complete you know all kinds of things you could do if you had a good model of source code and the project was reasonably successful it was you know it worked reasonably well but what we've learned is that when you build one gigantic model that that yes it sees source code it sees scientific papers it sees wikipedia it sees many many different things in some way it becomes better at writing source code than a model specifically for writing source code and there are even even in ablation studies where people have a model that's trained to solve maths problems and it does reasonably well and now you give it some apparently irrelevant information let's say from wikipedia but with anything to do with maths stripped out and you find it actually does better at the maths so I think there are things here that we don't really understand but the general lesson I think is fairly clear that when you have a larger very general model it can outperform a specific model which I think is very interesting I guess the reason I was talking about the no free lunch theorem is it feels to me as you say that models behave quite differently in an input sensitive way so you ask them about this particular thing and it's almost like it's a different model because different parts of the model get activated and then there's this question of well is the no free lunch theorem violated can there be such a thing as a general foundational agent that could in robotics just do really well in any game or any environment or do you think do you think there's still some need for specialization another great question so I think these really open research questions honestly I'm not sure anybody really knows but I think one of the lessons is that the general can be more powerful than the specific so clearly one of the research frontiers we should push on is greater and greater and see so you know GBT4 can't ride a bicycle but if we have models that can can do robotics should they be separate and distinct models or if we somehow combined everything into a single model would it be more powerful and there's a decent chance that the latter would be true that it would be more powerful so certainly that's one research frontier we should push on an area I'm very interested in these days is is deep learning for for science for scientific discovery and science amongst other things involves very precise detailed numerical calculations now if you want to multiply some numbers together GBT4 would be a terrible way of doing it it might give you the wrong answer and even if it gets the right answer you're burning a tremendous amount of compute cycles to do something you could do with the far fewer compute cycles so there will still as far as I can see in certain domains be a role for specialist models but even then I can see them being integrated with things like large language models partly to provide human interface because one of the one of the things about language models is they they're so easy to interact with you don't have to be a computer program you just have a a natural conversation with them but also the other remarkable thing about the large language models I think there are two remarkable things the first of all is that they're so good at human language maybe that's not too surprising because they're sort of designed to do that but by virtue of being forced to effectively compress human language they become reasoning engines and that's a remarkable discovery right that is a big surprise certainly to me I think to many people perhaps to everybody in the field that they can function as reasoning engines and so even if you're let's say doing some specialist scientific calculations you might still think about a large language model as as a kind of a co-pilot for the scientist helping the scientist reason over what increasingly consists of massive massively complex spaces very high dimensionality many different modalities of data it's harder and harder for humans to sort of wrap their head around this and this is where I think a large language model can can can be valuable but I still see it calling on specialist tools in the foreseeable future because you were talking about statistical generalization but you could argue that language models can't do let's say they can't compute the nth digit of pi because they don't have an expandable memory they're not Turing machine so that that's a computational limitation but but they might be able to do this statistical generalization as we were talking about even though it might in fact be a weird form of specialization in terms of an ensemble of methods of models inside a large language model but on the on the language thing and the reasoning this this is fascinating so I think that language is a bunch of memetically embedded programs so we we play the language game and we establish cognitive categories we embed them and share them socially and it's like there's a little simulation out there and I'm using that to think but the question always is to what extent and is that that's a bunch of processing that previous humans have done and we can use it but can the language model create new programs like that this is I think part of a fascinating and broader discussion so I do hear a lot of oh it can't do x y and z often that's true and I've always put the word yet at the end of it because I don't know any law or physics and it can't do certain there are some things which perhaps the current architectures provably can't do but but there's lots of exploration in different architectures there's a lot of scope for for for expanding and generalizing neural net so I always think of it can't do a certain thing yet but a lot of the questions or a lot of the comments about the limitations of models I have a have a hypothesis on this I mean let me test this out on you I may be I may be way shorter the mark on this one but a lot of the a lot of the critique of what models seemingly can't do or especially when it's oh they will never be able to do this they cannot be creative or they cannot reason or they cannot whatever I wonder if a lot of this comes to to a much more fundamental point that's not actually a technical one it's really to do with the human the human journey over the last few thousand years because we've you know a few thousand years ago I guess most humans would have perceived humanity as the center of the universe they were the earth's center of the universe the universe was created for the benefit of humanity we had this very arrogant view of our own importance and what we've learned over the centuries especially from fields like astronomy is of course you know that the the entirety of humanity's existence is a brief blink of the eye compared to the distance of the the whole universe and and our physical place in the universe in terms of length scale we're on a little speck of dust orbiting an insignificant star in a rather boring galaxy in this colossal universe and and so I think it's natural for us as humans to sort of continue to cling to the things that we feel make us special and we're certainly not the fastest creatures on earth we're not the strongest but it's our brains that seem to make us unique we are the most intelligent creatures by far on earth and so we think of our of our intelligence as being the very special thing yes okay we get it that we're just living in a sporing corner of the universe but nevertheless it's our brains that make us special so let me tell you a little story which is because I work for Microsoft I was very privileged to have early access to GPT-4 and it was still a highly-tented highly-secret project and so I was exposed to GPT-4 at a time when I could only discuss it with a very small number of very specific colleagues and for everybody else I couldn't couldn't even talk about it and it was quite a shocking moment the the ability to understand and generate language sort of didn't come as so much of a surprise because of course I'd been following GPT-2 and GPT-3 and you know knew this technically was getting better but this ability to reason there was a sort of visceral reaction I had which took me right back to that film 2001 that sense of I was engaging with something which you know my colleague Sebastian Bubeck called it the sparks of artificial intelligence so nobody in that nobody's claiming GPT-4 is anywhere close to human intelligence or anything like that but there was just the first glimpse of something it was the first time in my life that I'd interacted with something that wasn't a human being that had a glimmer of this this higher level of intelligence and and realizing this may be the dawn of a of a new era that may be even more significant than the 2012 moment of the dawn of deep learning there was something very special going on and I wonder if part of the reaction that we have to these models is a little bit of that sense of that threat to the specialness that we feel as humans now maybe completely wrong this is purely speculation but you know it's interesting that we talk about people use phrases like stochastic parody it's just regurgitating stuff that it that it's seen before some people claim or you know of course it hallucinates sometimes it comes up with stuff that's just wrong or doesn't make sense but but think about the following imagine there was a very very smart physics student went to you went to a top university worked really hard for four years what would they do they would they would read books they would read papers listen to lectures have discussions with their professors and with other students and then they sit their final exam and they get 95% in their final exam and they come top of the year we don't say huh well 95% of the time there are stochastic parrot regurgitating Einstein and Maxwell and the other 5% of the time they're hallucinating no we say congratulations you have a first-class honors degree you've graduated with honors this is this is a you know a wonderful achievement so it's interesting that we do seem to view the the capabilities of of neural nets with it with almost a different ruler to that of humans and while nobody's suggesting that current models are anywhere close to humans on many axes of intelligence nevertheless i see the first sparks of of artificial intelligence and just one final comment the term AI artificial intelligence has been very popular for many years i used to hate it i used to always say that's machine learning none of these systems are intelligent they're very good at recognizing cats and images there's nothing really intelligent about this in in in in one sense and yet now i find for the first time i feel comfortable talking about artificial intelligence because i think we've taken the first baby steps towards what i think of as true artificial intelligence i still think that agency and creativity are the distinguishing feature not necessarily that we are and biological beings it's more to do with we are independent agents and we are sampling random things from our local worlds and we're combining them together in in interesting ways and in doing so intelligence is about the process of building models and sharing models and embedding models in in our culture so it feels to me that gpt was building models at the time it was trained and and and that's all it's doing i can imagine a world where there were lots of gpt's we all had gpt in our pockets and maybe then it would be much more like biomimetic intelligence i think there are lots of interesting points that you touched on there tim so i think one thing is in terms of creativity you know are these systems creative it's certainly true they only exist because of humans they're created by humans and and we should acknowledge that but i don't think it means they're intrinsically not creative if i asked an artist to paint me a picture of some people walking on the beach with a sunset or whatever and they came back a few days later with some beautiful picture i might hate it they may have used very vivid colors i might like pale pastel colors but that's a matter of opinion but i wouldn't deny that there was creativity there but their expertise came because well they went they perhaps had some intrinsic ability in some sense but they went to art school they study the work of other artists they practice they got better and and and that creativity owes a lot to what went before but i don't think it diminishes that in the same way a physics student who can explain the theory of relativity you have to say well you didn't invent the theory of relativity you know einstein invented that you only learned it from einstein but it doesn't diminish the the fact that they have understanding the fact that they convey it and the fact they can potentially think in new ways and be creative so i'm i'm less convinced about discussions about the limitations of of of the technology in general of where it can go i don't particularly see any limitations the brain is a machine that uses this a term used earlier connectionist approach it uses these fine-grained neural nets and and so there are similarities to the technology that we have now there are also huge differences some of those differences point to the artificial neural nets being much more powerful than biological neural nets and hinted made a strong point of this lately and i think it's a very interesting perspective so i would be the first to say yes the technologies we have on many axes are a long way short of humans on many axes the much better gbt4 can create text much better than any human i mean to produce a page of coherent text that's correctly punctuated in good grammar and so on in a few seconds there aren't any people that can do that i think so on an increasing number of axes systems clearly outperform humans and on others there's still a very long way to go but i think one of the nice things about technologies like this generative ai technologies whether it's you know saura for creating videos or gbt4 or whatever it might be is they do rely on the prompt there is a clear role they are co-pilots as we say they they they sit there and do nothing and you use them as a sort of a cognitive amplifier you have an idea sort of half-baked and then you can engage in a conversation and sure enough it can come up with a different way of thinking say hey that's really good i like that idea now let's take that work that back in try again and so it becomes now a companion a co-pilot something that enhances your your cognitive ability but the human is still very much in the loop and playing a key part and actually initiating the process and of course finally at the end of the day you're the one that selects the you know the 10 video clips you pick the one that you like and so the human is very much involved in the loop throughout so i think that's a very nice feature of this technology i completely agree with that so at the moment a is are embedded in the cognitive nexus of humans so we have the agency and we drive these things and and they help us think and also i agree with you that it doesn't make sense to think of these things as limited forms of computation we should think of the collective intelligence so we are touring machines and we are driving these things and we are sharing information so when you look at the entire system it is a new type of memetic intelligence in fact you know to a certain extent GPT-4 isn't running on Microsoft servers it's in all of us right and that's that's a wonderful way um to think about it but to me the extent to which it is constraining our agency and creativity is what i'm fascinated by so GPT says unraveling the mysteries and you know the intricate dance of x y z and all of these weird motifs and constructions and maybe that's just the way that our LHF has constrained the model or maybe it speaks to the constraining forces in general of having these low entropy models that kind of you know snip off a lot of the interesting pathways so we are very creative GPT-4 resists creativity a little bit is it a problem well i think there's some design choices there so you talked about reinforcement learning through human feedback is part of that alignment process we ought to create this technology in a way that does good to minimize harm and so naturally we do constrain it so for sure it's true that our constrained GPT-4 behave in you might say less creative ways but perhaps in more helpful and beneficial ways and it's appropriate that we should do that and perhaps we lose a little bit of the creativity in the process and so there's there's a balance there's a there's a there's a choice to be made a design choice in how we want to create the technology and we should be very deliberate about that and not not apologetic for that i think it's good that we are that we are making those design choices but people sometimes have an intuition that it's not creative and contrast that to i'm using DaVinci Resolve and i'm using all of these nodes and i have all of these filters and processing transforms the difference seems to be that i'm designing the architecture so i'm using cognitive primitives and i'm composing them together in a new way and by tweaking the parameters on the filters i'm going off-peast a little bit i'm doing i'm creating the structure myself whereas in neural networks the structure is implicit i don't know what the structure is well i think you're talking about you're contrasting two different kinds of tools there so the video editing tool is designed so that it follows your instructions very precisely and you prefer one tool over another perhaps because the interface is easier to use you get the results faster but you have in your you've done the creativity you've designed this to video edit that you want that you want to have and now the tool is to try to get you to that as fast as possible as accurately as possible but sometimes we need more than that sometimes you know if you've got right as block and you don't know where to begin having a tool like GPT-4 could be very powerful you're not you're not delegating the entire process to the technology you're working with it as a as a co-pilot as an assistant that can for sure help you with that creative process it will come up with with crazy things and most of them you may not like but maybe one of them you don't like it either but it causes you to think about something that you would otherwise not have thought of and so the two working together can surely be more creative so i think certainly as a working in unison with humans it certainly enhances creativity so that's certainly my experience i think there's no doubt about that but also if you think about let's take a simple example that i think most people relate to which is which is image generation you're giving a talk and you want some image to illustrate the talk and you know you could go to stock images and you know it's a fixed set and you know you can't easily adjust it or you or you go to editing images yourself that's a sort of slow and painful process but now you can just with a simple prompt you know you can get a a bunch of examples and if one of those isn't quite what you like you can alter the prompt and and fine tune it and it now becomes that that process which is a creative process and you can still say the human is in the driving seat but the overall creativity is certainly enhanced and when you take a text prompt and and the machine produces this beautiful photorealistic image i mean how many of us weren't absolutely blown away by the incredible advances in generative AI of the last you know the last decade why would you not call that creative if a human being did it you would call it creative why why are we not allowing the machine to be described as creative that's the piece that i don't that i don't quite understand so you could argue that creativity is just pure novelty of the artifact so it's just how much entropy is in the artifact but you could you could think of GPT4 pros as being a kind of category so there's a lot of variants in there but there are also certain motifs and and now when people see the motifs they say oh i've seen that a million times before so i did think it was novel and interesting and now i don't and but this is the thing so now when i'm writing blog posts and stuff like that i'm deliberately trying to do something genuinely creative to me you know it's it's almost like the intrinsic creativity isn't important i don't want people to think that i use GPT4 so that's driving it do you see what i mean yeah so in clearly creativity is about novelty and novelty is you know what we desire here but whether that novelty has value or not that's a subjective opinion in your case it's whether it's achieving the the goals that you desire so i think there is no doubt that it's even if you say we're just taking existing ideas and combining them in new ways everything that humans do or i think builds on the work of their own previous experience and on the work of others and i think that's absolutely fine that's a wonderful thing about the humanity is that we from generation to generation we build upon the work of what's gone before and the machines that we build now are heavily dependent on the creativity and the work of humans before because they learn from humans they're designed by humans and i think that's absolutely fine it's a wonderful thing and they add to the sum total of human creativity and that that's a wonderful thing Chris you wrote a really beautiful book and you wrote it with your son Hugh and there was a picture of Hugh i think in the introduction of of PRML and i guess part of what i want to understand is is deep learning is a huge field i mean what was the thought process and how did you decide what to tackle and what not to tackle great questions there's an interesting story behind the the new deep learning book which is that PRML was written in 2006 it predates the deep learning revolution and what has constantly surprised me is just how popular it's remained in spite of the fact that in one sense it's massively out of date because it does has no mention of the most important thing in the field of machine learning and so i've long felt it was time to update the book produce the second edition add some material on deep learning but life is busy and you know anybody who's ever written a book will tell you that it takes way more effort than you can possibly imagine if you've not actually had that experience and so i never really got around to doing it and along came the covid pandemic and we all went into lockdown and i feel like it was one of the very privileged people in that lockdown we were we were locked down together as a family in in Cambridge and you know when you're locked down at home for several months you kind of need a project and and i thought this would be a great time to think about a second edition of the PRML book because you know what what else you're going to do in lockdown and it became a project with my son because he was he was with me by this time he he'd gained a lot of experience master's degree in machine learning and been working in autonomous vehicle technology and in a sense he had a lot more practical hands-on experience with deep learning than than i did at that point and so we started this as a joint project but we very quickly realized that what was needed was not a couple of extra chapters on PRML but rather the whole field had changed so much and also we didn't want to write a book we were just accumulated more and more material it would just become a huge a huge tome the value of a book i think is is in the distillation is in the way it draws your attention to a subset of specific things this is the small set of things that you really need to understand and then you're quick to go off into the field so what we omitted was almost as important as what we what we added and we very quickly realized this was a this was a new book so we we we called the book deep learning foundations and concepts and we made a lot of progress but then of course the the lockdowns ended i started a new team called ai for science at microsoft hu started at wave technologies building the the core machine learning technology for their autonomous vehicles and we were all just far too busy and then the next thing that happened was the chat gpt moment we're you know in a space of a few weeks a hundred million people were using this and suddenly ai machine learning was in the in the consciousness of the the general public and we realized that if ever there was a time to finish this book it had to be now and so we had a just a really big push to to get the book finished and available for for new eurips in 2023 and we made it just you know at the last minute as you do and the book was on display at new eurips there and hu and i spent the week going around the conference together talking to folks at posters and and just had a great time so it was actually a huge privilege to to be able to write the book with my son yeah that's fantastic um what was your favorite chapter and i mean are there any um things that you felt were remissions that you would have liked to do but you just had to draw a line under it yeah in terms of uh favorite chapters i mean of course the things the the the more recent architectures were particularly interesting i very much enjoyed writing the the diffusion chapter and hu had a lot of input into that chapter of course transformers as well and just understanding how to how to integrate the the sort of the different generative frameworks how to bring think about gans and how to think about variational order encoders and you know how to think about normalizing flows and so on how to think about those under one umbrella and present them in a more coherent way so that was that was part of the interesting free the learning experience i always enjoy learning new things i learned things writing that book and that and i think you did as well and so in a sense that was that was the favorite part of the book the things where i where i learned new things or new ways of looking at things i already knew about the real decision process is what to put in what not to put in while keeping the size of the book under control because i think it's something like it's thousands of papers a month now published in machine learning uh it's overwhelming for the beginner so really the goal of the book is to still out those few core concepts which means there are always things oh should we have added this should we have added that what we wanted to do was to avoid adding the latest sort of architecture that might be very hot at the minute that could easily disappear three months down the line so i hope we've resisted that that temptation but there are areas where you know perhaps when we at some point if we get around to a second edition we might think about including reinforcement learning is something which is of growing importance and would be lovely to have a chapter on reinforcement learning that integrates well with the rest of the book there are books on reinforcement learning there are review articles there's plenty of place to go learn about them there's something that sort of integrated with the book i think could be could be valuable so that is something we might we might visit in the future but for the moment we've just focused on what we think are the core principles that any any newcomer to the field whether a master student whether they're somebody who's self-taught a practitioner coming into the field wanting to understand the basics of the field and so the goal was to try to keep the book as it were as short as possible but no shorter looking back on on your last couple of books as well in in retrospect which bits are you are you most kind of proud of and which bits do you do you kind of feel that when you did make the decision at the time perhaps you've you've you've mispredicted how successful something might be very interesting so the thing i'm most proud of actually is the very first book called neural networks for pattern recognition and the reason is because i think that the book was quite influential in steering the field towards a more probabilistic more statistical perspective of machine learning it perhaps hard for people to appreciate today but it wasn't always that way when i first went into machine learning a lot of it was inspired by neurobiology which is which is fine but it lacked sort of mathematical rigor it lacked any mathematical foundation and so there was a lot of trying to learn a bit more about the brain and then try to copy that in the algorithms and see if that worked better or not and there was a lot of trial and error still a lot of empirical trial and error in machine learning of course but at least we have that that sort of bedrock of probability theory and so i think that the book was the first one to really address machine learning and neural networks from a statistical from a probabilistic perspective and i think in that respect the book was very influential the field was much smaller than today we take we take that as obvious but i think in terms of the thing i'm most proud of it's probably the influence of that that first book back in back in 1995 in terms of things i look back on that i might do differently i suppose when i look at if i look at prml for example and i look at the trajectory of the field we've seen that neural networks were were all the rage in the mid mid 1980s to mid 1990s and then they kind of got overtaken by other techniques and then we had this sort of Cambrian explosion of you know support vector machines and Gaussian process and Bayesian methods and graphical models and and all the rest of it and and i think one thing that one thing that i think Jeff Hinton really got right is we really understood that neural networks were the way the way forward and he really stuck to that perspective sort of through thick and thin i got kind of distracted particularly we talked earlier about Bayesian methods and how beautiful and how elegant they are and a theoretical physicist it's very appealing to think of everything from a Bayesian perspective but really what we've seen today is that the the practical tool that's giving us these extraordinary advances is neural networks and most of those ideas go back to the to the mid 1980s to the idea of gradient descent and and so on a few new a few new tweaks you know we have GPUs we have reluers we have a few but essentially most of the ideas were were were were still were around back in the back in the late 1980s we didn't really understand the incredible scale at which you need to use them but they only really work when you have this gargantuan scale of data and compute and of course we didn't really have GPUs or know how to use them back then so there were some key developments that sort of unlocked this and made it possible but i think perhaps if i did something differently with the amazing benefit of hindsight other than sort of investing in certain stocks and whatever and all the other things you could do if you had perfect hindsight i think the other thing i would do is probably just stay really focused on neural networks because eventually there that's the technology that came good but i always come back to probability theory it's very much a unifying idea so for let me just give you a specific example from prml actually there were two different technologies one called hidden markoff models that were all the rage and speech recognition back then another technique called kalman filters that have been used for many years to to guide spacecraft track aircraft on radar and all sorts of things it turns out they're essentially the same algorithm and not only are they the same algorithm but they can be derived from the most beautifully simple principle you just take the sum and product rule of probabilities and then you take the idea that a joint probability distribution has a factorization described by a directed graph and if you want to so when i was preparing prml i looked over a bunch of books called kalman filters an introduction to kalman filters and they become chapter after chapter at the forward and then chapter after chapter at the reverse equations and so on it very very complex and very very heavy going but you can derive the kalman filter and get the hidden markoff model for free in almost a few lines of of algebra just starting from probability theory and this idea of factorization it's sort of deep mathematical principle that operates there and you discover the message passing algorithm and if it's a tree structure graph it's exact and you have two passes it's very beautiful very elegant so i love the fact we're exploring all these many different frontiers but i love the fact we have some at least some compass to guide us as we as we engage in the exploration of this combinatorially vast space yeah it's so interesting my co-host Dr Keith Duggar he always says that he doesn't need to remember all of the different statistical quantities because he can re-derive them from first principles it's that nice but we should move on to AI for science so you're leading this initiative at Microsoft Research can you tell us about that yes so at a personal level of course this brings back my my earlier interest in theoretical physics and chemistry and and biology and that brings it together with with machine learning and what many people realized a few years ago was that of the many areas that machine learning would impact the scientific the area of scientific discovery would be i think in my view the most important the reason i say that is because it's actually scientific discovery that really has allowed humans to go on that trajectory the last few thousand years not just understanding our place in the universe but to be much more in control of our own destiny to double our lifespan to cure many diseases to give us much higher standards of living to give us a much brighter outlook for the future than humans humans have traditionally enjoyed and and that's come through scientific discovery and then the application of that knowledge and understanding of the world in the form of technologies agriculture industrial and so on and so i can't think of any more important application for AI but what's really interesting is it's very clear that many areas of scientific discovery are being disrupted and when i say disrupted i'll just give you one simple example the ability of neural nets machine learning models to act as emulators for previously were very expensive numerical stimulators very often gives you a factor of a thousand acceleration you know we can forecast the weather a thousand times faster with the same accuracy than we could a few years ago prior to the use of deep learning now if that were the only thing that was happening that alone would be a disruption that alone would be worth setting up a team on AI for science i think actually it's only scratching the surface but anytime something that's very core very important gets a thousand times faster it means you can do things that would take years in a few tens of hours it that really is a disruption it really is transformational so a couple of years ago i pitched to our chief technology officer to say look this is a really important field i'm happy to step down from my role as the lab director of MSR in in europe and instead i'd like to lead a new team focusing on AI for science and met with enormous enthusiasm and so we've been growing and building that team it's very interesting team it's very multinational we have people on on many different continents in different countries we've opened new labs in in in in amsterdam and in in berlin we have teams in in beijing and in shanghai and folks in in seattle as well and so very very multidisciplinary very multinational but with with one thing in common this real excitement and passion for what machine learning and AI is going to do to really transform and accelerate our ability to do scientific discovery you were talking about inductive priors just a second ago and i guess i first learned about this with the art of you know designing inductive priors and machine learning from max welling's group they were saying that you know the remarkable thing is that you can using principles let's say from physics we can design these inductive priors and we can reduce the size of the hypothesis class that that we're approximating and because we know the target function is inside that class we are not introducing any approximation error and we we are kind of overcoming some of the curses in in in machine learning by making the problem tractable which which is amazing but that's speaking to this kind of principled approach of imbuing domain knowledge into these systems it's really interesting actually max and i have a similar trajectory you both did phd's in theoretical physics and then moved into machine learning and i think we both feel there's a very important role for inductive bias to play in the use of machine learning in the scientific domain i think i'm sure everybody is familiar with the the blog called the bitter lesson by rich sudden and if any if anybody watching this is is not familiar they should immediately after this video go and read that blog it's a very short blog and without giving too much of a spoiler he essentially says that every attempt by people to improve the performance of machine learning by building in prior knowledge building in what we call inductive biases into the models it produces some improvement and then but very quickly it's overtaken by somebody else who just has more data and and that indeed is a bitter lesson and and it's a wonderful blog and people should i i've read it many times i think people should you know probably read that once a month and and it's it's very inspiring but i think there may be exceptions and i think the scientific domain is one where inductive biases for the foreseeable future will be extremely important sort of almost contrary to the bitter lesson and a couple of reasons for this one is that the the inductive biases we have a not not of the kind let's say let's say linguistics or something which is any domain where which is based on human expertise acquired through experience because a person who's had a lot of experience over a number of years and formulated some sort of rules of thumb that guide them that's exactly what machine learning is very good at processing very large amounts of data and and inducing the the the rules as it were the patterns within that data so i think that kind of inductive bias is typically harmful and and i think the bitter lesson will certainly apply there but in the scientific domain it's rather different first of all the inductive biases we have are very rigorous we have the idea of conservation of energy conservation of momentum we have symmetries if i have a molecule in a vacuum it has a certain energy if i rotate the molecule the representation of the coordinates of all the atoms changes wildly in the computer but the energy is the same so we have this very rigorous inductive bias we also know that the world at the atomic level is described exquisitely well by by Schrodinger's equation sprinkling a few relativistic effects and you've got an amazingly accurate description of the world but it's way too complex to just solve it directly or is exponentially costly in the number of electrons but nevertheless we have this bedrock of of really understanding the laws that govern the universe and so and so i think that's the first the first thing we have very rigorous priors that we believe in deeply it's not that we think conservation of energy doesn't work we know that we know that it's true the second thing is that we're operating in a data scarce regime so large language models are able to use very large quantities of internet scale quantities of human created data whether it's in the form of you know whether it's wikipedia or whether it's just scientific papers or any of the output of humans almost is potentially material on which which large models can feed they're in a very data rich regime and can go to scale and and so the bitter lesson i think really kicks in there in the scientific domain the data might come from simulations which are computational and expensive or it might come from lab experiments which are which are expensive and the data is is limited so we're operating usually in a data scarce regime so we have relatively limited data and we have very rigorous prior knowledge and so the balance between the data and the inductive bias is very different because of course the no free lunch theorem says you can't learn purely from data you have to have some form of inductive bias and in the case of a transformer it's a very lightweight form of inductive bias we believe there's a there's a deep hierarchy there's some you know data dependent self-attention but but really that's it and the rest is determined from the data in science there's much more scope for bringing in these inductive biases there's much more need to bring in the inductive biases and that also incidentally again in my personal very biased opinion makes the application of machine learning and ai to the sciences the most exciting frontier of AI machine learning because it's the one that's richest in terms of the creativity and also in terms of the need to bring in some of that beautiful mathematics that that underpins the universe yeah so so fascinating I mean could we just linger just just for a second on that so rich Sutton in his bitter lesson essay he explicitly called out symmetries as being you know he was warning against human designed artifacts in in these models and I mean max welling as you say famously built these gauge equivariant neural networks bringing in his physics knowledge and so I'm just trying to understand the spectrum between high-resolution physical priors and the kind of macroscopic human knowledge that that we learn which is presumably brittle is it just that we think that these physical priors are fundamental and that's that's a that's a perfectly acceptable way to constrain the search space but these high-level priors are brittle yes I think I think the the the prior knowledge that comes from human experience is is is more of that brittle kind because the machine can see far more examples than a human can in a lifetime and can can do a more systematic job of looking across all of that data we're not not subject to say recency bias and those sorts of things so I think that kind of prior knowledge is is one where where scale and data will will win whereas the the prior knowledge that we have from the physical laws in a sense is much more rigorous and symmetry is is is very powerful it's sometimes said that physics more or less is symmetry that's almost yes right so conservation conservation laws arise from symmetry you know translation in variance in spacetime gives you conservation of energy and momentum and you know gauge symmetry of the electromagnetic field gives you charge conservation and so on and and so these are very very rigorous laws that apply from symmetry but you know even if you take a data-driven approach people often use data augmentation if you know that an object doesn't depend his identity doesn't depend on where it is in the image you might you know make lots of random translations of your data to augment your data so data augmentation can be a data-driven way of building in those symmetries but now when we have very rich prior knowledge I'll come back to Schrodinger's equation it describes the world with exquisite precision at the atomic level but solving it is very very expensive and so what we can do is we can cache those computations we call it the fifth paradigm of scientific discovery which is a rather fancy term but the idea is very simple is that instead of taking a conventional numerical solver and using it to solve something like Schrodinger's equation or something called density functional theory instead of solving that directly to solve your problem instead you use that simulator to generate training data and use that training data to train a machine learning emulator and then that machine learning emulator can now emulate the simulator but typically three or four orders of magnitude faster so provided you use it a lot and you amortize the one off cost of generating the training data and doing the training if you're going to use it many many times overall it becomes dramatically faster dramatically more efficient than using the simulator and that that's just one of the breakthroughs we're seeing in this space so first of all um there's there's a spectrum as you say of we could just train on lots of data or we could augment the data or we could make a simulator for the data and then we can train a machine learning model and as we were just speaking to these inductive priors they are so high resolution that we are not restricting the target function that that that we want to learn and we can make quite a principled argument about that but the one question to me is there's a kind of I don't know whether it's best to frame it as exploration versus exploitation but there needs to be some amount of going off-piste so we define the structure and we we essentially build a generative model and we can generate a whole bunch of trajectories but could it ever be the case that we wouldn't have enough variance to find something interesting there's a very interesting question about the the overall scientific method of formulating hypotheses running tests evaluating those hypotheses refining the hypotheses running more experiments and so on that that scientific loop I think machine learning will have an important role to play there because data is becoming very high dimensional very high throughput humans can't analyze this data anymore a human can't directly look at the output of the large hadron collider with its you know petabytes a second or whatever it is pouring off we we need machines to help us but again I think the human rises to the level of the conductor of the orchestra as it were they no longer have to do things by hand machines are helping to accelerate that and and I think the machines can help accelerate the creative process potentially by pointing to anomalies or highlighting patterns in the data and so on but very much with the human scientist in the loop but but even coming down from those sort of lofty more sort of philosophical considerations just to the the practicalities when we talk about discovery we're also interested just the very practical method of how we how do we discover a new drug or how do we discover a new material so scientific discovery also means that that that that that very pragmatic near-term approach and there we're seeing really dramatic acceleration through the the concept of this emulator inner ability to explore the combinatorically vast space of new molecules and new materials exploring those spaces efficiently to find potential candidates that might be new drugs or new new materials for batteries or other other forms of green energy so that that alone is a very exciting frontier I think it's so interesting so searching these space I mean drug discovery is an interesting one I think you spoke about sustainability as well as another application you can speak to but how do you identify an interesting drug so the drug discovery process starts first of all with the disease and trying to first of all deciding we want to go tackle a particular disease and then finding a suitable target so the the standard so-called small molecule paradigm which is where most drugs are today they're small synthetic organic molecules that bind with a particular protein so pharma companies will will will spend a lot of time identifying targets so say a protein that has a particular region with a molecule combined can combined to and therefore can influence the behavior of that protein switching on or switching off some part of that disease pathway and breaking the chain of disease so the challenge then is to find a small molecule that first of all has the property that it binds with the target protein that's the first step but there are many other things that it has to do it has to be absorbed into the body it has to be metabolized and excreted it mustn't and particularly mustn't be toxic it mustn't bind to anything many other proteins in the body and cause bad things to happen so what you have is a very large space of molecules usually estimated around 10 to the power 60 potential drug-like molecules and out of that enormous space of 10 to the 60 you're trying to find an example that meets all of these many many criteria and so one approach is to generate a lot of candidates but in computationally and then screen them one by one for different properties that screening process the more that can be done in silico rather than in a wet lab the faster it can be done and the the larger the search space can be and therefore the bigger the fraction of that space of possibilities you can explore hopefully thereby increasing the chances of finding a good candidate because many attempts to find a drug for a disease simply fail nothing nothing eventually comes of it so increasing the probability of success increasing the speed of that discovery process so in all of that there are many places where machine learning could could be disruptive so on that process of I guess you're describing you generate candidates and then you almost discriminate interesting ones and then you rinse and repeat in a kind of iterative process let me give you a concrete example so we've done some work looking at tuberculosis so tuberculosis kills something like 1.3 million people very sadly back in 2022 which is the last year we have we have data and I might seem surprising because we have we have antibiotics we have drugs for tuberculosis why are so many people dying and one core reason is that the the bacterium is evolving to develop drug resistance and so there's a search on for new for new drugs so maybe I'll just take a moment to explain some of the architecture and get into a little bit of the sort of the techie details of this so we wanted a way of finding we know what the target is we've been told what the target protein is the target has a region called a pocket and we're looking for molecules that are bind tightly with that pocket region on the protein and and so the way the way we approached this was first of all build a language model but not a language model for human language but for the language of molecules so we first of all take there's a representation representation called smiles it's a way of taking a it's an acronym but just a way of taking a molecule and describing as a one-dimensional string and so you first of all take a large database of I don't know 10 million molecules it represented the smile strings and you treat them like the tokens for a for a transformer model and by getting it to predict the next token the next element of the smile string you build a transformer based language model that can speak the language of molecules so it can it can run generatively and it can create new create new molecules as output so you can think of that as kind of like a foundation language model but speaking the language of molecules now we want to generate molecules but not just any molecules we want molecules which bind with a particular target protein so we have the target protein in particular it's the pocket region that we're interested in so we can give it the amino acid sequence of the protein as input but we need more than that we need the geometry of the of the pocket and this is where some of those inductive biases come in so we we need to have representations of the geometry of the atoms in that form that pocket but a way that represents these equivalences and so they're encoded as input to a transformer model that learns a representation for the protein pocket and the final piece we need as you said we want to do this iteratively we want to take a good molecule and make it a better molecule rather than just searching blindly across a space of 10 to the 60 possibilities and so the other thing we want to provide as input is a molecule a descriptor of a a known small molecule that does bind with the pocket already and but we want to do this in a way that creates variability and we actually use a variational autoencoder to create that representation and that's the an encoder that trun translates the molecule into a latent space and we can sample from that latent space and then the this language model the smiles language model can attend to both the output of the variational autoencoder and the output of the protein encoder using cross-attention and so what we've done there is I think rather tastefully combined some elements from you know states of the arts at modern deep learning the result then can be can be trained end to end using a database of known other proteins that are known to bind efficiently to small molecules and once the system is trained we can now provide as input the known target for tuberculosis and some known molecules that bind with this and then we can iteratively refine those molecules at the output we get molecules that have better binding efficiency and we're able to increase the binding effectiveness by two orders of magnitude and so we now have states of the art molecules in terms of binding efficiency to this to this target protein of course we can't do the wet lab experiments ourselves we partner with an organization called giddy the global health drug discovery institute they've synthesized the molecules that we've we've generated and measured their their binding efficacy and so we're very very excited about this and of course the next stage now is to take that as a starting point and further refine and optimize those molecules and and try to address all those other requirements that we have for before a drug can actually be tested on humans in terms of its toxicity and metabolism and all and all the other things but i think it's just a a very a very nice example of almost like a first step in using modern deep learning architecture to accelerate the process of drug discovery and already we have i think really quite a spectacular success given that we're we're kind of newcomers to this to this field partnering with experts domain experts with the wet lab experience and the wet lab capability to me this is the beginning of a very exciting journey that sounds incredible is there any kind of representational transfer between the the models so for example you're talking about this this geometric prior model and generating tokens to go into the language model because just using language models by the way is a fascinating approach i spoke with christian sogeddy and he was doing mathematical conjecturing just using language models you know just just taking mathematical constructions and putting them into language and they used to use graph neural networks for this and so i guess the question is could you kind of bootstrap it with a you know with an inductive principled model and then kind of just train using the language model afterwards i think i think the general principle there's a very powerful one so the idea of borrowing strength from other domains and i think we're seeing this time and time again in deep learning that that the machine learning models are able to extract some general patterns from even from one domain and translate them into completely different domain we talked earlier about large language models being getting better at writing code if they've also got exposure to to poetry or something is seemingly quite irrelevant there's some there's something quite deep and subtle going on there but perhaps in a less subtle way it's clear there's a sort of a language of molecules there's a language of materials and that by building models that have a broader exposure to that language they almost invariably will become better at the specific tasks that we want to to apply them to so i think there is a general principle at heart there yeah it's so interesting because i i used to think that that perhaps the drawback of these inductive prior models is that it was one inductive prior per model but this ability potentially to bootstrap a foundational model that can do all of the things that's really interesting i think the most powerful inductive biases and the ones we focus on are really those very general ones where symmetry says just very fundamental properties of the universe and we want we want those really baked into the models i think the the the sort of intuitions we have about more specific domains i think they can perhaps lead us astray because they're based on our experience of much more limited domains i think this is where the machines can be can be much better at processing and interpreting large volumes of data and drawing regularities out of that out of data in a more systematic way okay okay and just before we we leave this this is a bit of a galaxy brain question and and that that's parlance that all the kids are using these days by the way but how fundamental is is our physical knowledge you know the question is like we are we're designing these inductive priors as if they are fundamental but folks like Steven Wolfram for example argue that there's there's a deeper ontological reality you know might be a graph cellular automaton or something like that and is that something you think about the kind of the gap between our models and what reality is so i think first of all one of the greatest scientific discoveries of all time is the fact the universe can be described by simple laws that that is not obvious a priori that itself is perhaps the most profound discovery you know really going back to Newton but we found it time and time again what we've also found is that the our understanding of the universe as it exists today has has it's almost like onions we're peeling way layers of onions you know Newton if you want to navigate a spacecraft to Jupiter you still use Newton's laws of motion and Newton's law of gravity it's just fine it doesn't mean we believe it's exact description of nature we've now got deeper descriptions of nature we understand relativity for example general relativity tells us that actually Newton's second law of motion or Newton's Newton's law of gravity rather is just an approximation the inverse square law is a pretty good approximation but we've got a much better description now but but it's it's it's hard to say that we've we've found the ultimate answer it's rather that human knowledge is or just always stands on that that edge of what we don't understand and scientific discovery is always about exploring the things we don't understand working out whether you know whether the laws actually do hold and the anomaly we see in the data is is because of some phenomenon that we haven't yet observed I mean this is how Neptune was discovered by by seeing that the planets were not behaving as they should do according to Newton's laws Newton's laws were just fine there's just another planet perturbing them or is the procession of the perihelion of Mercury because because there's another no it's because actually Newton's law of gravity isn't quite right we need relativity to understand that so I think scientific exploration as far as I can tell has no particular end in sight it's rather that we have things that we understand and there are new frontiers you know when I was when I was a teenager getting excited by physics I love reading about relativity and quantum physics but it's kind of depressing because I thought you know it's kind of born you know 50 years too late or whatever you know all the exciting stuff happened at the beginning of the 20th century it's kind of all been done but now we have you know dark matter and dark energy and we realize that most of the universe isn't sitting on the periodic table that I learned about in schools and actually I needn't have worried you know I think it was at Vannevar Bush who called it the endless frontier the you know science is an endless frontier there is just there is always more to explore and always more to learn so whether the particular ideas you alluded to have substance I don't know at the end of the day the scientific method will tell us if they have predictive capabilities they can predict new phenomena that we weren't aware of before then you know then they have they have credence as far as a scientist is concerned but ultimately you know we still stick to the scientific method it's about our ability to make predictions that are testable experimentally and if they stand up to the test of experiment then we give more weight to those to those hypotheses and eventually they're elevated to the stages of theory I often wonder about the horizon of our cognition you know what we are capable of understanding and we tend to understand things using high-level metaphors information is a great example of that so a lot of people talk about the universe as information this agential view is quite interesting so modeling everything as agents and it might well be possible that the universe is just so strange and alien that we could never possibly understand it so there's a bit of an interplay between our kind of intelligibility and and our models and what it is the universe clearly is completely unintelligible in the sense of nobody can really think about quantum physics it completely defies our everyday intuitions that we learn at this sort of macroscopic level so I think we have to accept already that the universe is described mathematically that's our precise description and then we have kind of metaphors about waves and particles and so on but they none of them none of them really work properly they're just crutches to lean on but ultimately it's a mathematical description but that that is that is also very interesting the fact that the world is described by mathematics that by making little marks on a piece of paper you can discover a new planet that's quite incredible shifting over to deep learning a little bit more more broadly and we were touching on this already but the landscape is dominated by transformers architectures what what are your broad thoughts about that like any field I think machine learning has its sort of its fads and its waves something works really well and then everybody latches onto that and makes use of that and that that's all well and good I'd be kind of surprised if the transformer is the last word in deep learning if that's the the the the the architecture we use forever more but it clearly works very well and we haven't reached the end of its capabilities by any means so it makes a lot of sense to exploit the transformer architecture in applications and see how much we can gain from that at the same time there's clearly opportunities to think about the limitations of transformers the computational costs can we do the same thing you know with better scaling if you want longer context windows and all the rest so there's plenty of interesting research I think to be done in in new architectures as well so I think we need both so you know here's another galaxy brain question why does deep learning work you know because on on the face of it it shouldn't work it shouldn't train it shouldn't generalize and they've been an absolutely remarkable success why is that so I think first of all at one level you could say well we understand why they work we're fitting nonlinear functions we're kind of doing curve fitting in high-dimensional space we need some some generalization and it comes out to no free lunch theorems of inductive biases perhaps it's smoothness continuity perhaps it's something more more constraining than that so at one level it's sort of not surprising I can I can fit a polynomial to a bunch of data points and by gradient methods and I can make good predictions for sort of intermediate points just we're just generalizing that to more data and higher dimensions so so one level I say no it's not at all surprising they work at a different level of course the fact they work so well is remarkable but the way in which they work is very interesting so one thing which if we go back to the earlier years of machine learning and certainly back to the world of statistics the idea that you would fit models that have way more parameters than the number of data points would be clearly insane to any self-respecting statistician we never would have and perhaps that's nobody why nobody really tried it very much and yet we have these odd phenomena whereby you know the training error goes to zero and yet the test error continues to come down even though the training error is already at zero something about stochastic gradient descent the actual training process clearly is important there it's not just here's a cost function we find the global minimum it's a property of the global minimum no there are many many global minimum that all have zero error some solutions will clearly overfit others generalize well and so there's something about the training process that we need to understand so I think there's a lot of research to be to be done in why do they work so well I think it's an open question we can describe the model we can say lots of things about the model we can say because it has this and this and that number of layers therefore the structure of the space has this and that properties and it divides it up into such and such regions and so on those are true I don't know whether that gives us real insights into why it's working I think there are some some very much open questions there it strikes me a little bit like neuroscience you know we have the human brain it does these amazing things and we can get more and more and richer and richer data about which neurons are firing and when and how the firings are correlated we can learn something about the the underlying machinery this is a bit like neuroscience except we can put a probe in every neuron in the you know artificial brain and gather very very rich information so again I think there's a very interesting research frontier of getting better understanding of why are they able to generalize so well and why do we have these strange phenomena with these seemingly over parameterized models that don't overfit but rather have very good generalization lots of research to be done and just to linger on that that observation you made that you can train a deep learning model and after the training error has converged the test loss continues to improve I mean that just seems it just doesn't make sense I mean how and that there's grocking as well which is another it's almost like we were saying with physics that outside of the the machinations of the optimization algorithm stuff is happening that we don't understand well you can tell stories right you can say there's a there's a big space each point of the space is setting for all the parameters of the model so the sort of the weight space of the model and maybe you started off somewhere near the origin with some little random initialization and you follow some trajectory that's defined by stochastic gradient descent and there are lots and lots of places in this space all of which have zero training error so and they're connected so there's some sort of manifold of zero training error and you're starting off at the origin and stochastic gradient descent is somehow not taking you at a random way maybe it's taking you to something like you know the nearest point on this manifold or something and that maybe that's some kind of regularization and maybe that place has certain smoothness properties that lead to good generalization so you can kind of tell these stories I think the challenge is to take the stories and make them predictive so I think when we have a theory of what's going on we'll know we have a theory because it can predict new things not just tell stories about what we've already discovered empirically but really become predictive I think that's still a very much an open question so what do you think about the intelligibility of neural networks in terms of things like bias and fairness and safety because you could just think of these things as inscrutable bags of neurons and but we need to have some guardrails don't we well we absolutely need to create technology that's beneficial to humanity there's no question about that and there are mechanisms for doing that to align the systems whether it's through you know human feedback whether it's external guardrails that are providing more conventional sort of checks on how things are being used that's clearly necessary and I find it very encouraging that so much energy and effort is going into this and yes there'll be bumps in the road and missteps on the way for sure but overall we seem to be heading in a very good direction but I think the fact that there is a lot of attention being paid to the potential risks associated with this very powerful and very general new technology gives me hope that we will avoid most of the the biggest risks. Can you give me a specific example of an emulator? Yes I can so one very nice example actually it was the final project I worked on when I was working in the fusion program so I was using fusion as a sort of springboard to get into machine learning and we wanted to do real-time feedback control of a fusion experiment I think called a tokamak very high-temperature plasma we wanted to use neural nets to do non-linear feedback so the challenge there was to take a plasma it's like a donut shaped ring of hot plasma and it was known that if you could change the cross-sectional shape you could improve its performance so there's an experiment called a compass compact assembly at Cullum in in Oxfordshire and the experiment's designed to produce very interesting exotic cross-sectional shapes to to explore the performance so we wanted to use a neural net to do that feedback control. Now the good news is we had a great piece of inductive bias I think called the grad shafranoff equation it's a second-order elliptic partial differential equation but the point is it describes the boundary of the plasma very accurately right so you make a bunch of measurements from hundreds of little pickup coils around the plasma and those are boundary conditions you solve the grad shafranoff equation you know the shape of the plasma and the goal was to decide ahead of the time that you wanted to create a circular plasma and then change its shape and and and then make corrections if the shape wasn't quite the one you wanted you would change the the big control coil currents and an alternate shape. The problem was the grad shafranoff equation on a state-of-the-art workstation of the day would take two or three minutes to solve whereas we had to do feedback on a sort of 20 kilohertz frequency or something it was about something like six orders of magnitude too slow so what we did instead was we we solved the grad shafranoff equation many times on the on the workstation over a period of you know days and weeks until we built up a large database of known solutions along with their magnetic measurements and then we trained a neural network just a simple two-layer neural network back in the day with probably only a few thousand parameters i mean miniscule by modern standards but it was trained to take the magnetic measurements and predict the shape and we could put that into a standard feedback loop and and we're in a bit of a race with another organization that was doing a similar thing a different fusion lab that was working on the same project and so that was very motivating and i'm pleased to say we got there first and we did the world's first ever real-time feedback control of a tokamak plasma using a neural network but as a beautiful example of a of an emulator we could get five or six orders of magnitude speed up not by solving the equation directly to do feedback control but by using the numerical solver to generate training data and using the training data to train the emulator and then the emulator and even then it was still quite demanding for the silicon of the day there was no processor fast enough so we actually built a physical implementation of the neural net believe it or not so it was a hybrid analog digital system had an analog signal pathway with analog sigmoidal units but the weights were set using digitally set resistors so we could take the numerical output of the the emulator downloaded into this bespoke hardware physical neural network and do real-time feedback control so i was pretty pretty excited about that project that's fascinating what do you think about control now do you have any opinions on you know model predictive control and control is a super important area different both the both the control problem and the overall planning problem i think despite all the remarkable advances in gbt4 the world of instantiated ai and robotics and so on is still a very very wide open frontier we don't we don't really have robots that can even yet drive a car through central london that's still a a major challenge that we're seeing some very remarkable progress recently yeah i mean more broadly i've been speaking with some neuroscientists and they say that we have the matrix in in our heads so we're always running simulations and presumably in the future this will be a principled way of building agents so the agents will run counterfactual simulations and select trajectories which look like good ones and then the process will will iterate i think this is this is very powerful i mean the the idea of sort of type one and type two fast learning slow learning the idea that we simulate the world and we compare the simulation with the reality and we can learn from our own simulators and so on we don't we don't quite know what best to do with that but it feels such a powerful and compelling concept and we we think something like that is going on in the brain that again that feels like a an area that's ripe for exploration and i think in some form some kind of you know model prediction and simulation of the world feels like it will be increasingly a part of ai systems as we go forward i mean for me the takeaway in all of this is just what an amazing time to be in this field there are so many fascinating things to work on professor bishop it's been an honor to have you on mlst thank you so much well thank you i've enjoyed it thank you amazing", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 4.4, "text": " Today we have the privilege of speaking with Professor Chris Bishop,", "tokens": [50364, 2692, 321, 362, 264, 12122, 295, 4124, 365, 8419, 6688, 30113, 11, 50584], "temperature": 0.0, "avg_logprob": -0.12243673649240047, "compression_ratio": 1.5378787878787878, "no_speech_prob": 0.005869119428098202}, {"id": 1, "seek": 0, "start": 4.4, "end": 7.92, "text": " a luminary in the field of artificial intelligence", "tokens": [50584, 257, 24635, 4066, 294, 264, 2519, 295, 11677, 7599, 50760], "temperature": 0.0, "avg_logprob": -0.12243673649240047, "compression_ratio": 1.5378787878787878, "no_speech_prob": 0.005869119428098202}, {"id": 2, "seek": 0, "start": 7.92, "end": 11.76, "text": " and machine learning. Chris is a technical fellow", "tokens": [50760, 293, 3479, 2539, 13, 6688, 307, 257, 6191, 7177, 50952], "temperature": 0.0, "avg_logprob": -0.12243673649240047, "compression_ratio": 1.5378787878787878, "no_speech_prob": 0.005869119428098202}, {"id": 3, "seek": 0, "start": 11.76, "end": 15.6, "text": " and director at Microsoft Research, AI for Science,", "tokens": [50952, 293, 5391, 412, 8116, 10303, 11, 7318, 337, 8976, 11, 51144], "temperature": 0.0, "avg_logprob": -0.12243673649240047, "compression_ratio": 1.5378787878787878, "no_speech_prob": 0.005869119428098202}, {"id": 4, "seek": 0, "start": 15.6, "end": 20.16, "text": " in Cambridge. He's also honorary professor of computer science", "tokens": [51144, 294, 24876, 13, 634, 311, 611, 49365, 8304, 295, 3820, 3497, 51372], "temperature": 0.0, "avg_logprob": -0.12243673649240047, "compression_ratio": 1.5378787878787878, "no_speech_prob": 0.005869119428098202}, {"id": 5, "seek": 0, "start": 20.16, "end": 24.560000000000002, "text": " at the University of Edinburgh and fellow of Darwin College,", "tokens": [51372, 412, 264, 3535, 295, 41215, 293, 7177, 295, 30233, 6745, 11, 51592], "temperature": 0.0, "avg_logprob": -0.12243673649240047, "compression_ratio": 1.5378787878787878, "no_speech_prob": 0.005869119428098202}, {"id": 6, "seek": 0, "start": 24.560000000000002, "end": 28.8, "text": " Cambridge. Hi, nice to meet you Tim. This is the new book on", "tokens": [51592, 24876, 13, 2421, 11, 1481, 281, 1677, 291, 7172, 13, 639, 307, 264, 777, 1446, 322, 51804], "temperature": 0.0, "avg_logprob": -0.12243673649240047, "compression_ratio": 1.5378787878787878, "no_speech_prob": 0.005869119428098202}, {"id": 7, "seek": 2880, "start": 28.8, "end": 32.96, "text": " Deep Learning Foundations and Concepts published with my son Hugh.", "tokens": [50364, 14895, 15205, 8207, 763, 293, 47482, 82, 6572, 365, 452, 1872, 25893, 13, 50572], "temperature": 0.0, "avg_logprob": -0.1898050308227539, "compression_ratio": 1.7087719298245614, "no_speech_prob": 0.00641985610127449}, {"id": 8, "seek": 2880, "start": 32.96, "end": 36.56, "text": " What proper have you got? Ethanol. I don't know if I'll use it but", "tokens": [50572, 708, 2296, 362, 291, 658, 30, 23984, 401, 13, 286, 500, 380, 458, 498, 286, 603, 764, 309, 457, 50752], "temperature": 0.0, "avg_logprob": -0.1898050308227539, "compression_ratio": 1.7087719298245614, "no_speech_prob": 0.00641985610127449}, {"id": 9, "seek": 2880, "start": 36.56, "end": 39.36, "text": " we're going to talk about invariance. That's wonderful, that's wonderful.", "tokens": [50752, 321, 434, 516, 281, 751, 466, 33270, 719, 13, 663, 311, 3715, 11, 300, 311, 3715, 13, 50892], "temperature": 0.0, "avg_logprob": -0.1898050308227539, "compression_ratio": 1.7087719298245614, "no_speech_prob": 0.00641985610127449}, {"id": 10, "seek": 2880, "start": 39.36, "end": 43.52, "text": " Because you ought to get a little bit techy at some point. Oh yeah, our audience loves that.", "tokens": [50892, 1436, 291, 13416, 281, 483, 257, 707, 857, 7553, 88, 412, 512, 935, 13, 876, 1338, 11, 527, 4034, 6752, 300, 13, 51100], "temperature": 0.0, "avg_logprob": -0.1898050308227539, "compression_ratio": 1.7087719298245614, "no_speech_prob": 0.00641985610127449}, {"id": 11, "seek": 2880, "start": 43.52, "end": 47.6, "text": " In 2004 he was elected fellow of the Royal Academy of Engineering,", "tokens": [51100, 682, 15817, 415, 390, 11776, 7177, 295, 264, 12717, 11735, 295, 16215, 11, 51304], "temperature": 0.0, "avg_logprob": -0.1898050308227539, "compression_ratio": 1.7087719298245614, "no_speech_prob": 0.00641985610127449}, {"id": 12, "seek": 2880, "start": 47.6, "end": 52.32, "text": " in 2007 he was elected fellow of the Royal Society of Edinburgh", "tokens": [51304, 294, 12656, 415, 390, 11776, 7177, 295, 264, 12717, 13742, 295, 41215, 51540], "temperature": 0.0, "avg_logprob": -0.1898050308227539, "compression_ratio": 1.7087719298245614, "no_speech_prob": 0.00641985610127449}, {"id": 13, "seek": 2880, "start": 52.32, "end": 57.6, "text": " and in 2017 he was elected fellow of the Royal Society.", "tokens": [51540, 293, 294, 6591, 415, 390, 11776, 7177, 295, 264, 12717, 13742, 13, 51804], "temperature": 0.0, "avg_logprob": -0.1898050308227539, "compression_ratio": 1.7087719298245614, "no_speech_prob": 0.00641985610127449}, {"id": 14, "seek": 5760, "start": 57.6, "end": 61.2, "text": " Chris was a founding member of the UK AI Council", "tokens": [50364, 6688, 390, 257, 22223, 4006, 295, 264, 7051, 7318, 7076, 50544], "temperature": 0.0, "avg_logprob": -0.06953400030903432, "compression_ratio": 1.5513307984790874, "no_speech_prob": 0.0004079313366673887}, {"id": 15, "seek": 5760, "start": 61.2, "end": 65.68, "text": " and in 2019 he was appointed to the Prime Minister's Council", "tokens": [50544, 293, 294, 6071, 415, 390, 17653, 281, 264, 9655, 6506, 311, 7076, 50768], "temperature": 0.0, "avg_logprob": -0.06953400030903432, "compression_ratio": 1.5513307984790874, "no_speech_prob": 0.0004079313366673887}, {"id": 16, "seek": 5760, "start": 65.68, "end": 72.08, "text": " for Science and Technology. At Microsoft Research, Chris oversees a global portfolio", "tokens": [50768, 337, 8976, 293, 15037, 13, 1711, 8116, 10303, 11, 6688, 11916, 279, 257, 4338, 12583, 51088], "temperature": 0.0, "avg_logprob": -0.06953400030903432, "compression_ratio": 1.5513307984790874, "no_speech_prob": 0.0004079313366673887}, {"id": 17, "seek": 5760, "start": 72.08, "end": 76.88, "text": " of industrial research and development with a strong focus on machine learning", "tokens": [51088, 295, 9987, 2132, 293, 3250, 365, 257, 2068, 1879, 322, 3479, 2539, 51328], "temperature": 0.0, "avg_logprob": -0.06953400030903432, "compression_ratio": 1.5513307984790874, "no_speech_prob": 0.0004079313366673887}, {"id": 18, "seek": 5760, "start": 76.88, "end": 81.84, "text": " and the natural sciences. Chris obtained a BA in physics from Oxford", "tokens": [51328, 293, 264, 3303, 17677, 13, 6688, 14879, 257, 21050, 294, 10649, 490, 24786, 51576], "temperature": 0.0, "avg_logprob": -0.06953400030903432, "compression_ratio": 1.5513307984790874, "no_speech_prob": 0.0004079313366673887}, {"id": 19, "seek": 5760, "start": 81.84, "end": 85.84, "text": " and a PhD in theoretical physics from the University of Edinburgh", "tokens": [51576, 293, 257, 14476, 294, 20864, 10649, 490, 264, 3535, 295, 41215, 51776], "temperature": 0.0, "avg_logprob": -0.06953400030903432, "compression_ratio": 1.5513307984790874, "no_speech_prob": 0.0004079313366673887}, {"id": 20, "seek": 8584, "start": 85.84, "end": 90.72, "text": " with a thesis on quantum field theory. Chris's contributions to the field of", "tokens": [50364, 365, 257, 22288, 322, 13018, 2519, 5261, 13, 6688, 311, 15725, 281, 264, 2519, 295, 50608], "temperature": 0.0, "avg_logprob": -0.07656715728424407, "compression_ratio": 1.5992063492063493, "no_speech_prob": 0.0012426000321283937}, {"id": 21, "seek": 8584, "start": 90.72, "end": 96.56, "text": " machine learning have been truly remarkable. He's authored one of the main", "tokens": [50608, 3479, 2539, 362, 668, 4908, 12802, 13, 634, 311, 6979, 2769, 472, 295, 264, 2135, 50900], "temperature": 0.0, "avg_logprob": -0.07656715728424407, "compression_ratio": 1.5992063492063493, "no_speech_prob": 0.0012426000321283937}, {"id": 22, "seek": 8584, "start": 96.56, "end": 100.4, "text": " textbooks in the field which is Pattern Recognition and Machine Learning", "tokens": [50900, 33587, 294, 264, 2519, 597, 307, 34367, 77, 44682, 849, 293, 22155, 15205, 51092], "temperature": 0.0, "avg_logprob": -0.07656715728424407, "compression_ratio": 1.5992063492063493, "no_speech_prob": 0.0012426000321283937}, {"id": 23, "seek": 8584, "start": 100.4, "end": 105.36, "text": " or PRML. It has served as an essential reference for", "tokens": [51092, 420, 11568, 12683, 13, 467, 575, 7584, 382, 364, 7115, 6408, 337, 51340], "temperature": 0.0, "avg_logprob": -0.07656715728424407, "compression_ratio": 1.5992063492063493, "no_speech_prob": 0.0012426000321283937}, {"id": 24, "seek": 8584, "start": 105.36, "end": 108.48, "text": " countless students and researchers around the world.", "tokens": [51340, 19223, 1731, 293, 10309, 926, 264, 1002, 13, 51496], "temperature": 0.0, "avg_logprob": -0.07656715728424407, "compression_ratio": 1.5992063492063493, "no_speech_prob": 0.0012426000321283937}, {"id": 25, "seek": 8584, "start": 108.48, "end": 112.16, "text": " Chris explained in the interview how it steered the field towards a more", "tokens": [51496, 6688, 8825, 294, 264, 4049, 577, 309, 2126, 4073, 264, 2519, 3030, 257, 544, 51680], "temperature": 0.0, "avg_logprob": -0.07656715728424407, "compression_ratio": 1.5992063492063493, "no_speech_prob": 0.0012426000321283937}, {"id": 26, "seek": 11216, "start": 112.16, "end": 117.28, "text": " probabilistic perspective at the time and he also mentioned his first textbook", "tokens": [50364, 31959, 3142, 4585, 412, 264, 565, 293, 415, 611, 2835, 702, 700, 25591, 50620], "temperature": 0.0, "avg_logprob": -0.11614789281572614, "compression_ratio": 1.6779661016949152, "no_speech_prob": 0.005907515529543161}, {"id": 27, "seek": 11216, "start": 117.28, "end": 121.6, "text": " Neural Networks for Pattern Recognition and its role in promoting neural", "tokens": [50620, 1734, 1807, 12640, 82, 337, 34367, 77, 44682, 849, 293, 1080, 3090, 294, 16383, 18161, 50836], "temperature": 0.0, "avg_logprob": -0.11614789281572614, "compression_ratio": 1.6779661016949152, "no_speech_prob": 0.005907515529543161}, {"id": 28, "seek": 11216, "start": 121.6, "end": 125.03999999999999, "text": " networks as a powerful tool for machine learning.", "tokens": [50836, 9590, 382, 257, 4005, 2290, 337, 3479, 2539, 13, 51008], "temperature": 0.0, "avg_logprob": -0.11614789281572614, "compression_ratio": 1.6779661016949152, "no_speech_prob": 0.005907515529543161}, {"id": 29, "seek": 11216, "start": 125.03999999999999, "end": 129.04, "text": " So this is the new textbook, Deep Learning, Foundations and Concepts", "tokens": [51008, 407, 341, 307, 264, 777, 25591, 11, 14895, 15205, 11, 8207, 763, 293, 47482, 82, 51208], "temperature": 0.0, "avg_logprob": -0.11614789281572614, "compression_ratio": 1.6779661016949152, "no_speech_prob": 0.005907515529543161}, {"id": 30, "seek": 11216, "start": 129.04, "end": 132.8, "text": " and one of the things that we're proud of with this book is the production values.", "tokens": [51208, 293, 472, 295, 264, 721, 300, 321, 434, 4570, 295, 365, 341, 1446, 307, 264, 4265, 4190, 13, 51396], "temperature": 0.0, "avg_logprob": -0.11614789281572614, "compression_ratio": 1.6779661016949152, "no_speech_prob": 0.005907515529543161}, {"id": 31, "seek": 11216, "start": 132.8, "end": 136.32, "text": " We really worked with the publisher to ensure the book would be", "tokens": [51396, 492, 534, 2732, 365, 264, 25088, 281, 5586, 264, 1446, 576, 312, 51572], "temperature": 0.0, "avg_logprob": -0.11614789281572614, "compression_ratio": 1.6779661016949152, "no_speech_prob": 0.005907515529543161}, {"id": 32, "seek": 11216, "start": 136.32, "end": 139.44, "text": " produced to a high physical quality and in particular it's produced with what", "tokens": [51572, 7126, 281, 257, 1090, 4001, 3125, 293, 294, 1729, 309, 311, 7126, 365, 437, 51728], "temperature": 0.0, "avg_logprob": -0.11614789281572614, "compression_ratio": 1.6779661016949152, "no_speech_prob": 0.005907515529543161}, {"id": 33, "seek": 13944, "start": 139.44, "end": 142.07999999999998, "text": " are called stitched signatures. So if you look down the edge there you'll see the", "tokens": [50364, 366, 1219, 48992, 32322, 13, 407, 498, 291, 574, 760, 264, 4691, 456, 291, 603, 536, 264, 50496], "temperature": 0.0, "avg_logprob": -0.12156348843728343, "compression_ratio": 1.930909090909091, "no_speech_prob": 0.05454156920313835}, {"id": 34, "seek": 13944, "start": 142.07999999999998, "end": 147.12, "text": " pages are not simply glued in. Instead this uses an offset printing", "tokens": [50496, 7183, 366, 406, 2935, 28008, 294, 13, 7156, 341, 4960, 364, 18687, 14699, 50748], "temperature": 0.0, "avg_logprob": -0.12156348843728343, "compression_ratio": 1.930909090909091, "no_speech_prob": 0.05454156920313835}, {"id": 35, "seek": 13944, "start": 147.12, "end": 151.35999999999999, "text": " technique where 16 pages are printed on a big sheet of paper on both sides.", "tokens": [50748, 6532, 689, 3165, 7183, 366, 13567, 322, 257, 955, 8193, 295, 3035, 322, 1293, 4881, 13, 50960], "temperature": 0.0, "avg_logprob": -0.12156348843728343, "compression_ratio": 1.930909090909091, "no_speech_prob": 0.05454156920313835}, {"id": 36, "seek": 13944, "start": 151.35999999999999, "end": 155.12, "text": " Some of the pages are turned upside down and then the page of the paper is", "tokens": [50960, 2188, 295, 264, 7183, 366, 3574, 14119, 760, 293, 550, 264, 3028, 295, 264, 3035, 307, 51148], "temperature": 0.0, "avg_logprob": -0.12156348843728343, "compression_ratio": 1.930909090909091, "no_speech_prob": 0.05454156920313835}, {"id": 37, "seek": 13944, "start": 155.12, "end": 158.72, "text": " folded and then folded and then folded again and trimmed and the resulting", "tokens": [51148, 23940, 293, 550, 23940, 293, 550, 23940, 797, 293, 44563, 293, 264, 16505, 51328], "temperature": 0.0, "avg_logprob": -0.12156348843728343, "compression_ratio": 1.930909090909091, "no_speech_prob": 0.05454156920313835}, {"id": 38, "seek": 13944, "start": 158.72, "end": 162.32, "text": " set is called a signature and actually stitched in with cord. And the point", "tokens": [51328, 992, 307, 1219, 257, 13397, 293, 767, 48992, 294, 365, 12250, 13, 400, 264, 935, 51508], "temperature": 0.0, "avg_logprob": -0.12156348843728343, "compression_ratio": 1.930909090909091, "no_speech_prob": 0.05454156920313835}, {"id": 39, "seek": 13944, "start": 162.32, "end": 166.56, "text": " about that is it allows the book to open flat so it means that the book is easy", "tokens": [51508, 466, 300, 307, 309, 4045, 264, 1446, 281, 1269, 4962, 370, 309, 1355, 300, 264, 1446, 307, 1858, 51720], "temperature": 0.0, "avg_logprob": -0.12156348843728343, "compression_ratio": 1.930909090909091, "no_speech_prob": 0.05454156920313835}, {"id": 40, "seek": 16656, "start": 166.56, "end": 169.92000000000002, "text": " to read and it means it should last a long time.", "tokens": [50364, 281, 1401, 293, 309, 1355, 309, 820, 1036, 257, 938, 565, 13, 50532], "temperature": 0.0, "avg_logprob": -0.13810998885357967, "compression_ratio": 1.6509090909090909, "no_speech_prob": 0.003574848873540759}, {"id": 41, "seek": 16656, "start": 169.92000000000002, "end": 172.32, "text": " What are your favourite figures in the book Chris?", "tokens": [50532, 708, 366, 428, 10696, 9624, 294, 264, 1446, 6688, 30, 50652], "temperature": 0.0, "avg_logprob": -0.13810998885357967, "compression_ratio": 1.6509090909090909, "no_speech_prob": 0.003574848873540759}, {"id": 42, "seek": 16656, "start": 172.32, "end": 175.44, "text": " Well the ones produced by my son of course are the best. I mean here's a nice", "tokens": [50652, 1042, 264, 2306, 7126, 538, 452, 1872, 295, 1164, 366, 264, 1151, 13, 286, 914, 510, 311, 257, 1481, 50808], "temperature": 0.0, "avg_logprob": -0.13810998885357967, "compression_ratio": 1.6509090909090909, "no_speech_prob": 0.003574848873540759}, {"id": 43, "seek": 16656, "start": 175.44, "end": 179.76, "text": " picture of the transformer architecture which is this is GPT so", "tokens": [50808, 3036, 295, 264, 31782, 9482, 597, 307, 341, 307, 26039, 51, 370, 51024], "temperature": 0.0, "avg_logprob": -0.13810998885357967, "compression_ratio": 1.6509090909090909, "no_speech_prob": 0.003574848873540759}, {"id": 44, "seek": 16656, "start": 179.76, "end": 182.72, "text": " you could say it's one of the most important figures in the book I suppose", "tokens": [51024, 291, 727, 584, 309, 311, 472, 295, 264, 881, 1021, 9624, 294, 264, 1446, 286, 7297, 51172], "temperature": 0.0, "avg_logprob": -0.13810998885357967, "compression_ratio": 1.6509090909090909, "no_speech_prob": 0.003574848873540759}, {"id": 45, "seek": 16656, "start": 182.72, "end": 185.84, "text": " and I just love the way he's done this.", "tokens": [51172, 293, 286, 445, 959, 264, 636, 415, 311, 1096, 341, 13, 51328], "temperature": 0.0, "avg_logprob": -0.13810998885357967, "compression_ratio": 1.6509090909090909, "no_speech_prob": 0.003574848873540759}, {"id": 46, "seek": 16656, "start": 185.84, "end": 188.96, "text": " How did you do the research for this?", "tokens": [51328, 1012, 630, 291, 360, 264, 2132, 337, 341, 30, 51484], "temperature": 0.0, "avg_logprob": -0.13810998885357967, "compression_ratio": 1.6509090909090909, "no_speech_prob": 0.003574848873540759}, {"id": 47, "seek": 16656, "start": 188.96, "end": 194.24, "text": " So that's a great question. I think you know one of the big", "tokens": [51484, 407, 300, 311, 257, 869, 1168, 13, 286, 519, 291, 458, 472, 295, 264, 955, 51748], "temperature": 0.0, "avg_logprob": -0.13810998885357967, "compression_ratio": 1.6509090909090909, "no_speech_prob": 0.003574848873540759}, {"id": 48, "seek": 19424, "start": 194.24, "end": 196.8, "text": " challenges with writing a book like this is knowing what to include and", "tokens": [50364, 4759, 365, 3579, 257, 1446, 411, 341, 307, 5276, 437, 281, 4090, 293, 50492], "temperature": 0.0, "avg_logprob": -0.10057302381171555, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.000518293003551662}, {"id": 49, "seek": 19424, "start": 196.8, "end": 200.08, "text": " what not to include and with literally thousands of papers being", "tokens": [50492, 437, 406, 281, 4090, 293, 365, 3736, 5383, 295, 10577, 885, 50656], "temperature": 0.0, "avg_logprob": -0.10057302381171555, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.000518293003551662}, {"id": 50, "seek": 19424, "start": 200.08, "end": 203.12, "text": " published every month it can be overwhelming for the authors never", "tokens": [50656, 6572, 633, 1618, 309, 393, 312, 13373, 337, 264, 16552, 1128, 50808], "temperature": 0.0, "avg_logprob": -0.10057302381171555, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.000518293003551662}, {"id": 51, "seek": 19424, "start": 203.12, "end": 205.76000000000002, "text": " mind the readers. So I think the value we add in the book", "tokens": [50808, 1575, 264, 17147, 13, 407, 286, 519, 264, 2158, 321, 909, 294, 264, 1446, 50940], "temperature": 0.0, "avg_logprob": -0.10057302381171555, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.000518293003551662}, {"id": 52, "seek": 19424, "start": 205.76000000000002, "end": 209.12, "text": " is trying to distill out what we think of as the core concept.", "tokens": [50940, 307, 1382, 281, 42923, 484, 437, 321, 519, 295, 382, 264, 4965, 3410, 13, 51108], "temperature": 0.0, "avg_logprob": -0.10057302381171555, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.000518293003551662}, {"id": 53, "seek": 19424, "start": 209.12, "end": 213.60000000000002, "text": " So part of this was really looking at key papers in the field", "tokens": [51108, 407, 644, 295, 341, 390, 534, 1237, 412, 2141, 10577, 294, 264, 2519, 51332], "temperature": 0.0, "avg_logprob": -0.10057302381171555, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.000518293003551662}, {"id": 54, "seek": 19424, "start": 213.60000000000002, "end": 219.04000000000002, "text": " seeing what relatively recent ideas there are but also trying to focus down on", "tokens": [51332, 2577, 437, 7226, 5162, 3487, 456, 366, 457, 611, 1382, 281, 1879, 760, 322, 51604], "temperature": 0.0, "avg_logprob": -0.10057302381171555, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.000518293003551662}, {"id": 55, "seek": 19424, "start": 219.04000000000002, "end": 222.08, "text": " techniques and ideas that we believe will actually stand the test of time.", "tokens": [51604, 7512, 293, 3487, 300, 321, 1697, 486, 767, 1463, 264, 1500, 295, 565, 13, 51756], "temperature": 0.0, "avg_logprob": -0.10057302381171555, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.000518293003551662}, {"id": 56, "seek": 22208, "start": 222.08, "end": 225.44000000000003, "text": " We don't have this book to go out of date in a year or two we want it to have", "tokens": [50364, 492, 500, 380, 362, 341, 1446, 281, 352, 484, 295, 4002, 294, 257, 1064, 420, 732, 321, 528, 309, 281, 362, 50532], "temperature": 0.0, "avg_logprob": -0.09678157971059675, "compression_ratio": 1.7801204819277108, "no_speech_prob": 0.0009250443545170128}, {"id": 57, "seek": 22208, "start": 225.44000000000003, "end": 229.44000000000003, "text": " have lasting value and of course it's quite possible there'll be a breakthrough", "tokens": [50532, 362, 20714, 2158, 293, 295, 1164, 309, 311, 1596, 1944, 456, 603, 312, 257, 22397, 50732], "temperature": 0.0, "avg_logprob": -0.09678157971059675, "compression_ratio": 1.7801204819277108, "no_speech_prob": 0.0009250443545170128}, {"id": 58, "seek": 22208, "start": 229.44000000000003, "end": 232.08, "text": " next week and that it will turn out to be a very important", "tokens": [50732, 958, 1243, 293, 300, 309, 486, 1261, 484, 281, 312, 257, 588, 1021, 50864], "temperature": 0.0, "avg_logprob": -0.09678157971059675, "compression_ratio": 1.7801204819277108, "no_speech_prob": 0.0009250443545170128}, {"id": 59, "seek": 22208, "start": 232.08, "end": 236.4, "text": " new architecture but for the most part many of the core concepts actually go", "tokens": [50864, 777, 9482, 457, 337, 264, 881, 644, 867, 295, 264, 4965, 10392, 767, 352, 51080], "temperature": 0.0, "avg_logprob": -0.09678157971059675, "compression_ratio": 1.7801204819277108, "no_speech_prob": 0.0009250443545170128}, {"id": 60, "seek": 22208, "start": 236.4, "end": 239.76000000000002, "text": " back a long way and so what we've really done is taken some", "tokens": [51080, 646, 257, 938, 636, 293, 370, 437, 321, 600, 534, 1096, 307, 2726, 512, 51248], "temperature": 0.0, "avg_logprob": -0.09678157971059675, "compression_ratio": 1.7801204819277108, "no_speech_prob": 0.0009250443545170128}, {"id": 61, "seek": 22208, "start": 239.76000000000002, "end": 242.96, "text": " some of the foundations of the field and brought them into the modern deep learning", "tokens": [51248, 512, 295, 264, 22467, 295, 264, 2519, 293, 3038, 552, 666, 264, 4363, 2452, 2539, 51408], "temperature": 0.0, "avg_logprob": -0.09678157971059675, "compression_ratio": 1.7801204819277108, "no_speech_prob": 0.0009250443545170128}, {"id": 62, "seek": 22208, "start": 242.96, "end": 246.8, "text": " era but the idea of probabilities the idea of gradient based methods and so on", "tokens": [51408, 4249, 457, 264, 1558, 295, 33783, 264, 1558, 295, 16235, 2361, 7150, 293, 370, 322, 51600], "temperature": 0.0, "avg_logprob": -0.09678157971059675, "compression_ratio": 1.7801204819277108, "no_speech_prob": 0.0009250443545170128}, {"id": 63, "seek": 22208, "start": 246.8, "end": 249.44, "text": " those have been around for decades and they're just as applicable today as", "tokens": [51600, 729, 362, 668, 926, 337, 7878, 293, 436, 434, 445, 382, 21142, 965, 382, 51732], "temperature": 0.0, "avg_logprob": -0.09678157971059675, "compression_ratio": 1.7801204819277108, "no_speech_prob": 0.0009250443545170128}, {"id": 64, "seek": 24944, "start": 249.76, "end": 252.56, "text": " they ever were. One of the things I really like actually is the", "tokens": [50380, 436, 1562, 645, 13, 1485, 295, 264, 721, 286, 534, 411, 767, 307, 264, 50520], "temperature": 0.0, "avg_logprob": -0.13703946598240588, "compression_ratio": 1.900709219858156, "no_speech_prob": 0.0014746009837836027}, {"id": 65, "seek": 24944, "start": 252.56, "end": 256.56, "text": " chapter on convolutional networks. My son Hugh did a lot of this", "tokens": [50520, 7187, 322, 45216, 304, 9590, 13, 1222, 1872, 25893, 630, 257, 688, 295, 341, 50720], "temperature": 0.0, "avg_logprob": -0.13703946598240588, "compression_ratio": 1.900709219858156, "no_speech_prob": 0.0014746009837836027}, {"id": 66, "seek": 24944, "start": 256.56, "end": 260.56, "text": " chapter he works on using techniques like convolutional neural", "tokens": [50720, 7187, 415, 1985, 322, 1228, 7512, 411, 45216, 304, 18161, 50920], "temperature": 0.0, "avg_logprob": -0.13703946598240588, "compression_ratio": 1.900709219858156, "no_speech_prob": 0.0014746009837836027}, {"id": 67, "seek": 24944, "start": 260.56, "end": 264.32, "text": " nets as part of his work on autonomous vehicles and I think there's a really", "tokens": [50920, 36170, 382, 644, 295, 702, 589, 322, 23797, 8948, 293, 286, 519, 456, 311, 257, 534, 51108], "temperature": 0.0, "avg_logprob": -0.13703946598240588, "compression_ratio": 1.900709219858156, "no_speech_prob": 0.0014746009837836027}, {"id": 68, "seek": 24944, "start": 264.32, "end": 267.68, "text": " nice description here of convolutional networks", "tokens": [51108, 1481, 3855, 510, 295, 45216, 304, 9590, 51276], "temperature": 0.0, "avg_logprob": -0.13703946598240588, "compression_ratio": 1.900709219858156, "no_speech_prob": 0.0014746009837836027}, {"id": 69, "seek": 24944, "start": 267.68, "end": 271.04, "text": " really from the ground up explaining the the basic concepts and", "tokens": [51276, 534, 490, 264, 2727, 493, 13468, 264, 264, 3875, 10392, 293, 51444], "temperature": 0.0, "avg_logprob": -0.13703946598240588, "compression_ratio": 1.900709219858156, "no_speech_prob": 0.0014746009837836027}, {"id": 70, "seek": 24944, "start": 271.04, "end": 274.96, "text": " but also motivating them not just saying this is how a convolutional network is", "tokens": [51444, 457, 611, 41066, 552, 406, 445, 1566, 341, 307, 577, 257, 45216, 304, 3209, 307, 51640], "temperature": 0.0, "avg_logprob": -0.13703946598240588, "compression_ratio": 1.900709219858156, "no_speech_prob": 0.0014746009837836027}, {"id": 71, "seek": 24944, "start": 274.96, "end": 278.32, "text": " built but why is it built this way how do we actually motivate it so that's", "tokens": [51640, 3094, 457, 983, 307, 309, 3094, 341, 636, 577, 360, 321, 767, 28497, 309, 370, 300, 311, 51808], "temperature": 0.0, "avg_logprob": -0.13703946598240588, "compression_ratio": 1.900709219858156, "no_speech_prob": 0.0014746009837836027}, {"id": 72, "seek": 27832, "start": 278.32, "end": 281.28, "text": " one of my favorite chapters as well. Yeah it's been a very interesting career", "tokens": [50364, 472, 295, 452, 2954, 20013, 382, 731, 13, 865, 309, 311, 668, 257, 588, 1880, 3988, 50512], "temperature": 0.0, "avg_logprob": -0.08640413356006593, "compression_ratio": 1.7879746835443038, "no_speech_prob": 0.002228024648502469}, {"id": 73, "seek": 27832, "start": 281.28, "end": 285.28, "text": " and at this stage of the career I can now finally look back and make sense of it", "tokens": [50512, 293, 412, 341, 3233, 295, 264, 3988, 286, 393, 586, 2721, 574, 646, 293, 652, 2020, 295, 309, 50712], "temperature": 0.0, "avg_logprob": -0.08640413356006593, "compression_ratio": 1.7879746835443038, "no_speech_prob": 0.002228024648502469}, {"id": 74, "seek": 27832, "start": 285.28, "end": 287.68, "text": " but at the time it felt like a bit of a random walk", "tokens": [50712, 457, 412, 264, 565, 309, 2762, 411, 257, 857, 295, 257, 4974, 1792, 50832], "temperature": 0.0, "avg_logprob": -0.08640413356006593, "compression_ratio": 1.7879746835443038, "no_speech_prob": 0.002228024648502469}, {"id": 75, "seek": 27832, "start": 287.68, "end": 292.48, "text": " so actually when I was a teenager I went to see 2001 A Space Odyssey it was", "tokens": [50832, 370, 767, 562, 286, 390, 257, 21440, 286, 1437, 281, 536, 16382, 316, 8705, 38385, 309, 390, 51072], "temperature": 0.0, "avg_logprob": -0.08640413356006593, "compression_ratio": 1.7879746835443038, "no_speech_prob": 0.002228024648502469}, {"id": 76, "seek": 27832, "start": 292.48, "end": 295.76, "text": " actually very inspired by that rather abstract concept of an", "tokens": [51072, 767, 588, 7547, 538, 300, 2831, 12649, 3410, 295, 364, 51236], "temperature": 0.0, "avg_logprob": -0.08640413356006593, "compression_ratio": 1.7879746835443038, "no_speech_prob": 0.002228024648502469}, {"id": 77, "seek": 27832, "start": 295.76, "end": 298.71999999999997, "text": " artificial intelligence very different from the usual sort of Hollywood", "tokens": [51236, 11677, 7599, 588, 819, 490, 264, 7713, 1333, 295, 11628, 51384], "temperature": 0.0, "avg_logprob": -0.08640413356006593, "compression_ratio": 1.7879746835443038, "no_speech_prob": 0.002228024648502469}, {"id": 78, "seek": 27832, "start": 298.71999999999997, "end": 302.0, "text": " the trail of robots so I was very interested in the idea of artificial", "tokens": [51384, 264, 9924, 295, 14733, 370, 286, 390, 588, 3102, 294, 264, 1558, 295, 11677, 51548], "temperature": 0.0, "avg_logprob": -0.08640413356006593, "compression_ratio": 1.7879746835443038, "no_speech_prob": 0.002228024648502469}, {"id": 79, "seek": 27832, "start": 302.0, "end": 306.32, "text": " intelligence from a young age but I was very uninspired by the field of AI", "tokens": [51548, 7599, 490, 257, 2037, 3205, 457, 286, 390, 588, 517, 31637, 1824, 538, 264, 2519, 295, 7318, 51764], "temperature": 0.0, "avg_logprob": -0.08640413356006593, "compression_ratio": 1.7879746835443038, "no_speech_prob": 0.002228024648502469}, {"id": 80, "seek": 30632, "start": 306.32, "end": 309.44, "text": " at the time which was very much sort of rule based and and didn't seem to be on", "tokens": [50364, 412, 264, 565, 597, 390, 588, 709, 1333, 295, 4978, 2361, 293, 293, 994, 380, 1643, 281, 312, 322, 50520], "temperature": 0.0, "avg_logprob": -0.08630156691056969, "compression_ratio": 1.8127090301003344, "no_speech_prob": 0.008994038216769695}, {"id": 81, "seek": 30632, "start": 309.44, "end": 312.48, "text": " a path through intelligence and then I did a PhD in quantum field theory which", "tokens": [50520, 257, 3100, 807, 7599, 293, 550, 286, 630, 257, 14476, 294, 13018, 2519, 5261, 597, 50672], "temperature": 0.0, "avg_logprob": -0.08630156691056969, "compression_ratio": 1.8127090301003344, "no_speech_prob": 0.008994038216769695}, {"id": 82, "seek": 30632, "start": 312.48, "end": 315.76, "text": " is a very hot field at the time gauge field theory", "tokens": [50672, 307, 257, 588, 2368, 2519, 412, 264, 565, 17924, 2519, 5261, 50836], "temperature": 0.0, "avg_logprob": -0.08630156691056969, "compression_ratio": 1.8127090301003344, "no_speech_prob": 0.008994038216769695}, {"id": 83, "seek": 30632, "start": 315.76, "end": 319.92, "text": " at Edinburgh University had a wonderful time at the end of my PhD though I wanted", "tokens": [50836, 412, 41215, 3535, 632, 257, 3715, 565, 412, 264, 917, 295, 452, 14476, 1673, 286, 1415, 51044], "temperature": 0.0, "avg_logprob": -0.08630156691056969, "compression_ratio": 1.8127090301003344, "no_speech_prob": 0.008994038216769695}, {"id": 84, "seek": 30632, "start": 319.92, "end": 322.56, "text": " to do something a bit more practical a bit more useful", "tokens": [51044, 281, 360, 746, 257, 857, 544, 8496, 257, 857, 544, 4420, 51176], "temperature": 0.0, "avg_logprob": -0.08630156691056969, "compression_ratio": 1.8127090301003344, "no_speech_prob": 0.008994038216769695}, {"id": 85, "seek": 30632, "start": 322.56, "end": 326.48, "text": " and so I went into the fusion program I'm a big fan of nuclear fusion", "tokens": [51176, 293, 370, 286, 1437, 666, 264, 23100, 1461, 286, 478, 257, 955, 3429, 295, 8179, 23100, 51372], "temperature": 0.0, "avg_logprob": -0.08630156691056969, "compression_ratio": 1.8127090301003344, "no_speech_prob": 0.008994038216769695}, {"id": 86, "seek": 30632, "start": 326.48, "end": 329.84, "text": " it was sort of 30 years away then and it's kind of still 30 years away now but", "tokens": [51372, 309, 390, 1333, 295, 2217, 924, 1314, 550, 293, 309, 311, 733, 295, 920, 2217, 924, 1314, 586, 457, 51540], "temperature": 0.0, "avg_logprob": -0.08630156691056969, "compression_ratio": 1.8127090301003344, "no_speech_prob": 0.008994038216769695}, {"id": 87, "seek": 30632, "start": 329.84, "end": 333.12, "text": " I'm still a big believer but I went to work on", "tokens": [51540, 286, 478, 920, 257, 955, 23892, 457, 286, 1437, 281, 589, 322, 51704], "temperature": 0.0, "avg_logprob": -0.08630156691056969, "compression_ratio": 1.8127090301003344, "no_speech_prob": 0.008994038216769695}, {"id": 88, "seek": 33312, "start": 333.92, "end": 337.92, "text": " talk about physics essentially theoretical physics of of plasmas trying to", "tokens": [50404, 751, 466, 10649, 4476, 20864, 10649, 295, 295, 499, 296, 3799, 1382, 281, 50604], "temperature": 0.0, "avg_logprob": -0.1277065186273484, "compression_ratio": 1.8339622641509434, "no_speech_prob": 0.0059024980291724205}, {"id": 89, "seek": 33312, "start": 337.92, "end": 341.04, "text": " trying to understand the instabilities and control them", "tokens": [50604, 1382, 281, 1223, 264, 1058, 6167, 293, 1969, 552, 50760], "temperature": 0.0, "avg_logprob": -0.1277065186273484, "compression_ratio": 1.8339622641509434, "no_speech_prob": 0.0059024980291724205}, {"id": 90, "seek": 33312, "start": 341.04, "end": 344.4, "text": " so I was working very happily as a theoretical physicist having a having a", "tokens": [50760, 370, 286, 390, 1364, 588, 19909, 382, 257, 20864, 42466, 1419, 257, 1419, 257, 50928], "temperature": 0.0, "avg_logprob": -0.1277065186273484, "compression_ratio": 1.8339622641509434, "no_speech_prob": 0.0059024980291724205}, {"id": 91, "seek": 33312, "start": 344.4, "end": 348.08, "text": " great time and after about 10 years or so as a theoretical physicist", "tokens": [50928, 869, 565, 293, 934, 466, 1266, 924, 420, 370, 382, 257, 20864, 42466, 51112], "temperature": 0.0, "avg_logprob": -0.1277065186273484, "compression_ratio": 1.8339622641509434, "no_speech_prob": 0.0059024980291724205}, {"id": 92, "seek": 33312, "start": 348.08, "end": 352.08, "text": " Jeff Hinton published the backprop paper and it came to my attention", "tokens": [51112, 7506, 389, 12442, 6572, 264, 646, 79, 1513, 3035, 293, 309, 1361, 281, 452, 3202, 51312], "temperature": 0.0, "avg_logprob": -0.1277065186273484, "compression_ratio": 1.8339622641509434, "no_speech_prob": 0.0059024980291724205}, {"id": 93, "seek": 33312, "start": 352.08, "end": 355.92, "text": " and I found that very inspiring because there I saw a very very different", "tokens": [51312, 293, 286, 1352, 300, 588, 15883, 570, 456, 286, 1866, 257, 588, 588, 819, 51504], "temperature": 0.0, "avg_logprob": -0.1277065186273484, "compression_ratio": 1.8339622641509434, "no_speech_prob": 0.0059024980291724205}, {"id": 94, "seek": 33312, "start": 355.92, "end": 361.6, "text": " approach to towards intelligence and so I started by applying neural", "tokens": [51504, 3109, 281, 3030, 7599, 293, 370, 286, 1409, 538, 9275, 18161, 51788], "temperature": 0.0, "avg_logprob": -0.1277065186273484, "compression_ratio": 1.8339622641509434, "no_speech_prob": 0.0059024980291724205}, {"id": 95, "seek": 36160, "start": 361.68, "end": 365.36, "text": " networks to data from the fusion program because it was big data", "tokens": [50368, 9590, 281, 1412, 490, 264, 23100, 1461, 570, 309, 390, 955, 1412, 50552], "temperature": 0.0, "avg_logprob": -0.089012893841421, "compression_ratio": 1.8395061728395061, "no_speech_prob": 0.0053774029947817326}, {"id": 96, "seek": 36160, "start": 365.36, "end": 368.56, "text": " in its day I was I was working there to the the jet", "tokens": [50552, 294, 1080, 786, 286, 390, 286, 390, 1364, 456, 281, 264, 264, 14452, 50712], "temperature": 0.0, "avg_logprob": -0.089012893841421, "compression_ratio": 1.8395061728395061, "no_speech_prob": 0.0053774029947817326}, {"id": 97, "seek": 36160, "start": 368.56, "end": 372.08000000000004, "text": " tokamak and they had many many high resolution diagnostics I had lots of", "tokens": [50712, 19164, 335, 514, 293, 436, 632, 867, 867, 1090, 8669, 43215, 1167, 286, 632, 3195, 295, 50888], "temperature": 0.0, "avg_logprob": -0.089012893841421, "compression_ratio": 1.8395061728395061, "no_speech_prob": 0.0053774029947817326}, {"id": 98, "seek": 36160, "start": 372.08000000000004, "end": 374.8, "text": " data to play with and I became more and more fascinated by", "tokens": [50888, 1412, 281, 862, 365, 293, 286, 3062, 544, 293, 544, 24597, 538, 51024], "temperature": 0.0, "avg_logprob": -0.089012893841421, "compression_ratio": 1.8395061728395061, "no_speech_prob": 0.0053774029947817326}, {"id": 99, "seek": 36160, "start": 374.8, "end": 378.40000000000003, "text": " neural networks and then I did a sort of completely crazy thing I walked away", "tokens": [51024, 18161, 9590, 293, 550, 286, 630, 257, 1333, 295, 2584, 3219, 551, 286, 7628, 1314, 51204], "temperature": 0.0, "avg_logprob": -0.089012893841421, "compression_ratio": 1.8395061728395061, "no_speech_prob": 0.0053774029947817326}, {"id": 100, "seek": 36160, "start": 378.40000000000003, "end": 381.44, "text": " from a very respectable career as a theoretical physicist", "tokens": [51204, 490, 257, 588, 44279, 3988, 382, 257, 20864, 42466, 51356], "temperature": 0.0, "avg_logprob": -0.089012893841421, "compression_ratio": 1.8395061728395061, "no_speech_prob": 0.0053774029947817326}, {"id": 101, "seek": 36160, "start": 381.44, "end": 384.72, "text": " and went full-time into the field of neural nets which at the time was not", "tokens": [51356, 293, 1437, 1577, 12, 3766, 666, 264, 2519, 295, 18161, 36170, 597, 412, 264, 565, 390, 406, 51520], "temperature": 0.0, "avg_logprob": -0.089012893841421, "compression_ratio": 1.8395061728395061, "no_speech_prob": 0.0053774029947817326}, {"id": 102, "seek": 36160, "start": 384.72, "end": 387.76000000000005, "text": " really a respectable field I would say it's not wasn't mainstream computer", "tokens": [51520, 534, 257, 44279, 2519, 286, 576, 584, 309, 311, 406, 2067, 380, 15960, 3820, 51672], "temperature": 0.0, "avg_logprob": -0.089012893841421, "compression_ratio": 1.8395061728395061, "no_speech_prob": 0.0053774029947817326}, {"id": 103, "seek": 36160, "start": 387.76000000000005, "end": 390.56, "text": " science it certainly wasn't physics it wasn't really anything", "tokens": [51672, 3497, 309, 3297, 2067, 380, 10649, 309, 2067, 380, 534, 1340, 51812], "temperature": 0.0, "avg_logprob": -0.089012893841421, "compression_ratio": 1.8395061728395061, "no_speech_prob": 0.0053774029947817326}, {"id": 104, "seek": 39056, "start": 390.56, "end": 393.6, "text": " but I just found it very inspiring and I was particularly inspired by the work", "tokens": [50364, 457, 286, 445, 1352, 309, 588, 15883, 293, 286, 390, 4098, 7547, 538, 264, 589, 50516], "temperature": 0.0, "avg_logprob": -0.07105564667006671, "compression_ratio": 1.7109634551495017, "no_speech_prob": 0.0009563741041347384}, {"id": 105, "seek": 39056, "start": 393.6, "end": 396.72, "text": " of Jeff Hinton and so I've been in that field for", "tokens": [50516, 295, 7506, 389, 12442, 293, 370, 286, 600, 668, 294, 300, 2519, 337, 50672], "temperature": 0.0, "avg_logprob": -0.07105564667006671, "compression_ratio": 1.7109634551495017, "no_speech_prob": 0.0009563741041347384}, {"id": 106, "seek": 39056, "start": 396.72, "end": 400.16, "text": " you know three and a half decades now and of course", "tokens": [50672, 291, 458, 1045, 293, 257, 1922, 7878, 586, 293, 295, 1164, 50844], "temperature": 0.0, "avg_logprob": -0.07105564667006671, "compression_ratio": 1.7109634551495017, "no_speech_prob": 0.0009563741041347384}, {"id": 107, "seek": 39056, "start": 400.16, "end": 403.6, "text": " recent history suggests that was probably a good career move", "tokens": [50844, 5162, 2503, 13409, 300, 390, 1391, 257, 665, 3988, 1286, 51016], "temperature": 0.0, "avg_logprob": -0.07105564667006671, "compression_ratio": 1.7109634551495017, "no_speech_prob": 0.0009563741041347384}, {"id": 108, "seek": 39056, "start": 403.6, "end": 407.36, "text": " and now most recently I've brought the two ends of my career together because", "tokens": [51016, 293, 586, 881, 3938, 286, 600, 3038, 264, 732, 5314, 295, 452, 3988, 1214, 570, 51204], "temperature": 0.0, "avg_logprob": -0.07105564667006671, "compression_ratio": 1.7109634551495017, "no_speech_prob": 0.0009563741041347384}, {"id": 109, "seek": 39056, "start": 407.36, "end": 410.72, "text": " I'm now very excited about the impact that neural nets and machine learning", "tokens": [51204, 286, 478, 586, 588, 2919, 466, 264, 2712, 300, 18161, 36170, 293, 3479, 2539, 51372], "temperature": 0.0, "avg_logprob": -0.07105564667006671, "compression_ratio": 1.7109634551495017, "no_speech_prob": 0.0009563741041347384}, {"id": 110, "seek": 39056, "start": 410.72, "end": 413.28, "text": " are having on the natural sciences including physics.", "tokens": [51372, 366, 1419, 322, 264, 3303, 17677, 3009, 10649, 13, 51500], "temperature": 0.0, "avg_logprob": -0.07105564667006671, "compression_ratio": 1.7109634551495017, "no_speech_prob": 0.0009563741041347384}, {"id": 111, "seek": 39056, "start": 413.28, "end": 417.6, "text": " Hinton is a famous connectionist so he believes that knowledge is", "tokens": [51500, 389, 12442, 307, 257, 4618, 4984, 468, 370, 415, 12307, 300, 3601, 307, 51716], "temperature": 0.0, "avg_logprob": -0.07105564667006671, "compression_ratio": 1.7109634551495017, "no_speech_prob": 0.0009563741041347384}, {"id": 112, "seek": 41760, "start": 417.6, "end": 422.16, "text": " sub-symbolic and I speaking with Nick Chater the other week he had a", "tokens": [50364, 1422, 12, 3187, 5612, 299, 293, 286, 4124, 365, 9449, 761, 771, 264, 661, 1243, 415, 632, 257, 50592], "temperature": 0.0, "avg_logprob": -0.14242065314090613, "compression_ratio": 1.6996904024767803, "no_speech_prob": 0.010344869457185268}, {"id": 113, "seek": 41760, "start": 422.16, "end": 425.6, "text": " book called The Mind is Flat which is talking about the inscrutability of", "tokens": [50592, 1446, 1219, 440, 13719, 307, 36172, 597, 307, 1417, 466, 264, 1028, 10757, 325, 2310, 295, 50764], "temperature": 0.0, "avg_logprob": -0.14242065314090613, "compression_ratio": 1.6996904024767803, "no_speech_prob": 0.010344869457185268}, {"id": 114, "seek": 41760, "start": 425.6, "end": 429.12, "text": " our brains. How do you feel that things have changed?", "tokens": [50764, 527, 15442, 13, 1012, 360, 291, 841, 300, 721, 362, 3105, 30, 50940], "temperature": 0.0, "avg_logprob": -0.14242065314090613, "compression_ratio": 1.6996904024767803, "no_speech_prob": 0.010344869457185268}, {"id": 115, "seek": 41760, "start": 429.12, "end": 432.88, "text": " I mean you were talking about a convergence of these different ideas in AI.", "tokens": [50940, 286, 914, 291, 645, 1417, 466, 257, 32181, 295, 613, 819, 3487, 294, 7318, 13, 51128], "temperature": 0.0, "avg_logprob": -0.14242065314090613, "compression_ratio": 1.6996904024767803, "no_speech_prob": 0.010344869457185268}, {"id": 116, "seek": 41760, "start": 432.88, "end": 435.52000000000004, "text": " I think one thing that's very interesting is that there has been a lot of", "tokens": [51128, 286, 519, 472, 551, 300, 311, 588, 1880, 307, 300, 456, 575, 668, 257, 688, 295, 51260], "temperature": 0.0, "avg_logprob": -0.14242065314090613, "compression_ratio": 1.6996904024767803, "no_speech_prob": 0.010344869457185268}, {"id": 117, "seek": 41760, "start": 435.52000000000004, "end": 438.56, "text": " discussion let's say from 2012 onwards when deep", "tokens": [51260, 5017, 718, 311, 584, 490, 9125, 34230, 562, 2452, 51412], "temperature": 0.0, "avg_logprob": -0.14242065314090613, "compression_ratio": 1.6996904024767803, "no_speech_prob": 0.010344869457185268}, {"id": 118, "seek": 41760, "start": 438.56, "end": 442.32000000000005, "text": " learning was clearly being very successful a lot of discussion that it was", "tokens": [51412, 2539, 390, 4448, 885, 588, 4406, 257, 688, 295, 5017, 300, 309, 390, 51600], "temperature": 0.0, "avg_logprob": -0.14242065314090613, "compression_ratio": 1.6996904024767803, "no_speech_prob": 0.010344869457185268}, {"id": 119, "seek": 41760, "start": 442.32000000000005, "end": 446.08000000000004, "text": " missing the sort of symbolic approach that we somehow to find a way to combine", "tokens": [51600, 5361, 264, 1333, 295, 25755, 3109, 300, 321, 6063, 281, 915, 257, 636, 281, 10432, 51788], "temperature": 0.0, "avg_logprob": -0.14242065314090613, "compression_ratio": 1.6996904024767803, "no_speech_prob": 0.010344869457185268}, {"id": 120, "seek": 44608, "start": 446.08, "end": 449.35999999999996, "text": " this connectionist approach to use that sort of probably rather dated term now", "tokens": [50364, 341, 4984, 468, 3109, 281, 764, 300, 1333, 295, 1391, 2831, 23804, 1433, 586, 50528], "temperature": 0.0, "avg_logprob": -0.09112462444581847, "compression_ratio": 1.935897435897436, "no_speech_prob": 0.005651738494634628}, {"id": 121, "seek": 44608, "start": 449.35999999999996, "end": 451.76, "text": " but that sort of you know that neural net approach", "tokens": [50528, 457, 300, 1333, 295, 291, 458, 300, 18161, 2533, 3109, 50648], "temperature": 0.0, "avg_logprob": -0.09112462444581847, "compression_ratio": 1.935897435897436, "no_speech_prob": 0.005651738494634628}, {"id": 122, "seek": 44608, "start": 451.76, "end": 455.03999999999996, "text": " with the more traditional symbolic approach and I think what we've seen", "tokens": [50648, 365, 264, 544, 5164, 25755, 3109, 293, 286, 519, 437, 321, 600, 1612, 50812], "temperature": 0.0, "avg_logprob": -0.09112462444581847, "compression_ratio": 1.935897435897436, "no_speech_prob": 0.005651738494634628}, {"id": 123, "seek": 44608, "start": 455.03999999999996, "end": 458.15999999999997, "text": " with models like GPT-4 for example that it's perfectly capable of", "tokens": [50812, 365, 5245, 411, 26039, 51, 12, 19, 337, 1365, 300, 309, 311, 6239, 8189, 295, 50968], "temperature": 0.0, "avg_logprob": -0.09112462444581847, "compression_ratio": 1.935897435897436, "no_speech_prob": 0.005651738494634628}, {"id": 124, "seek": 44608, "start": 458.15999999999997, "end": 461.52, "text": " reasoning at a more symbolic level not at the level of a human being of course", "tokens": [50968, 21577, 412, 257, 544, 25755, 1496, 406, 412, 264, 1496, 295, 257, 1952, 885, 295, 1164, 51136], "temperature": 0.0, "avg_logprob": -0.09112462444581847, "compression_ratio": 1.935897435897436, "no_speech_prob": 0.005651738494634628}, {"id": 125, "seek": 44608, "start": 461.52, "end": 465.03999999999996, "text": " but it can do that that kind of more abstract higher level", "tokens": [51136, 457, 309, 393, 360, 300, 300, 733, 295, 544, 12649, 2946, 1496, 51312], "temperature": 0.0, "avg_logprob": -0.09112462444581847, "compression_ratio": 1.935897435897436, "no_speech_prob": 0.005651738494634628}, {"id": 126, "seek": 44608, "start": 465.03999999999996, "end": 468.15999999999997, "text": " reasoning and so I think what we're seeing with neural", "tokens": [51312, 21577, 293, 370, 286, 519, 437, 321, 434, 2577, 365, 18161, 51468], "temperature": 0.0, "avg_logprob": -0.09112462444581847, "compression_ratio": 1.935897435897436, "no_speech_prob": 0.005651738494634628}, {"id": 127, "seek": 44608, "start": 468.15999999999997, "end": 470.88, "text": " nets is rather like the human brain. The human brain doesn't have a", "tokens": [51468, 36170, 307, 2831, 411, 264, 1952, 3567, 13, 440, 1952, 3567, 1177, 380, 362, 257, 51604], "temperature": 0.0, "avg_logprob": -0.09112462444581847, "compression_ratio": 1.935897435897436, "no_speech_prob": 0.005651738494634628}, {"id": 128, "seek": 44608, "start": 470.88, "end": 474.96, "text": " connectionist neural net piece then some other machinery that does symbolic", "tokens": [51604, 4984, 468, 18161, 2533, 2522, 550, 512, 661, 27302, 300, 775, 25755, 51808], "temperature": 0.0, "avg_logprob": -0.09112462444581847, "compression_ratio": 1.935897435897436, "no_speech_prob": 0.005651738494634628}, {"id": 129, "seek": 47496, "start": 474.96, "end": 478.47999999999996, "text": " reasoning that that that same substrate is capable of all of these", "tokens": [50364, 21577, 300, 300, 300, 912, 27585, 307, 8189, 295, 439, 295, 613, 50540], "temperature": 0.0, "avg_logprob": -0.12419129180908203, "compression_ratio": 1.9131944444444444, "no_speech_prob": 0.0010955400066450238}, {"id": 130, "seek": 47496, "start": 478.47999999999996, "end": 481.28, "text": " different kinds of reasoning and these different kinds of intelligence", "tokens": [50540, 819, 3685, 295, 21577, 293, 613, 819, 3685, 295, 7599, 50680], "temperature": 0.0, "avg_logprob": -0.12419129180908203, "compression_ratio": 1.9131944444444444, "no_speech_prob": 0.0010955400066450238}, {"id": 131, "seek": 47496, "start": 481.28, "end": 484.08, "text": " and we're starting to see that emerge now with neural net so I think", "tokens": [50680, 293, 321, 434, 2891, 281, 536, 300, 21511, 586, 365, 18161, 2533, 370, 286, 519, 50820], "temperature": 0.0, "avg_logprob": -0.12419129180908203, "compression_ratio": 1.9131944444444444, "no_speech_prob": 0.0010955400066450238}, {"id": 132, "seek": 47496, "start": 484.08, "end": 488.08, "text": " I think for me the discussion of should we somehow combine symbolic reasoning", "tokens": [50820, 286, 519, 337, 385, 264, 5017, 295, 820, 321, 6063, 10432, 25755, 21577, 51020], "temperature": 0.0, "avg_logprob": -0.12419129180908203, "compression_ratio": 1.9131944444444444, "no_speech_prob": 0.0010955400066450238}, {"id": 133, "seek": 47496, "start": 488.08, "end": 491.52, "text": " with with connectionism no that that to me that's a piece of history", "tokens": [51020, 365, 365, 4984, 1434, 572, 300, 300, 281, 385, 300, 311, 257, 2522, 295, 2503, 51192], "temperature": 0.0, "avg_logprob": -0.12419129180908203, "compression_ratio": 1.9131944444444444, "no_speech_prob": 0.0010955400066450238}, {"id": 134, "seek": 47496, "start": 491.52, "end": 494.96, "text": " it's about how can we how can we expand on the capabilities of neural nets.", "tokens": [51192, 309, 311, 466, 577, 393, 321, 577, 393, 321, 5268, 322, 264, 10862, 295, 18161, 36170, 13, 51364], "temperature": 0.0, "avg_logprob": -0.12419129180908203, "compression_ratio": 1.9131944444444444, "no_speech_prob": 0.0010955400066450238}, {"id": 135, "seek": 47496, "start": 494.96, "end": 498.15999999999997, "text": " Yeah that's so interesting I remember there was a paper by Polition I think it", "tokens": [51364, 865, 300, 311, 370, 1880, 286, 1604, 456, 390, 257, 3035, 538, 3635, 849, 286, 519, 309, 51524], "temperature": 0.0, "avg_logprob": -0.12419129180908203, "compression_ratio": 1.9131944444444444, "no_speech_prob": 0.0010955400066450238}, {"id": 136, "seek": 47496, "start": 498.15999999999997, "end": 502.0, "text": " was the the connectionist critique in 1988", "tokens": [51524, 390, 264, 264, 4984, 468, 25673, 294, 27816, 51716], "temperature": 0.0, "avg_logprob": -0.12419129180908203, "compression_ratio": 1.9131944444444444, "no_speech_prob": 0.0010955400066450238}, {"id": 137, "seek": 50200, "start": 502.0, "end": 505.52, "text": " and I was quite sold on this idea of you know systematicity and", "tokens": [50364, 293, 286, 390, 1596, 3718, 322, 341, 1558, 295, 291, 458, 27249, 507, 293, 50540], "temperature": 0.0, "avg_logprob": -0.12143440735645783, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.0006620955537073314}, {"id": 138, "seek": 50200, "start": 505.52, "end": 510.08, "text": " productivity and so on and even now folks from that school of thought", "tokens": [50540, 15604, 293, 370, 322, 293, 754, 586, 4024, 490, 300, 1395, 295, 1194, 50768], "temperature": 0.0, "avg_logprob": -0.12143440735645783, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.0006620955537073314}, {"id": 139, "seek": 50200, "start": 510.08, "end": 513.68, "text": " think that our brains are Turing machines this ability to address", "tokens": [50768, 519, 300, 527, 15442, 366, 314, 1345, 8379, 341, 3485, 281, 2985, 50948], "temperature": 0.0, "avg_logprob": -0.12143440735645783, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.0006620955537073314}, {"id": 140, "seek": 50200, "start": 513.68, "end": 518.4, "text": " potential infinity and I guess what I'm getting from", "tokens": [50948, 3995, 13202, 293, 286, 2041, 437, 286, 478, 1242, 490, 51184], "temperature": 0.0, "avg_logprob": -0.12143440735645783, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.0006620955537073314}, {"id": 141, "seek": 50200, "start": 518.4, "end": 521.12, "text": " what you're saying is that the distinction isn't really there anymore you", "tokens": [51184, 437, 291, 434, 1566, 307, 300, 264, 16844, 1943, 380, 534, 456, 3602, 291, 51320], "temperature": 0.0, "avg_logprob": -0.12143440735645783, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.0006620955537073314}, {"id": 142, "seek": 50200, "start": 521.12, "end": 524.08, "text": " can do that kind of reasoning with neural networks.", "tokens": [51320, 393, 360, 300, 733, 295, 21577, 365, 18161, 9590, 13, 51468], "temperature": 0.0, "avg_logprob": -0.12143440735645783, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.0006620955537073314}, {"id": 143, "seek": 50200, "start": 524.08, "end": 527.76, "text": " Well I take a very simple view which is that neural nets in that since 2012 in", "tokens": [51468, 1042, 286, 747, 257, 588, 2199, 1910, 597, 307, 300, 18161, 36170, 294, 300, 1670, 9125, 294, 51652], "temperature": 0.0, "avg_logprob": -0.12143440735645783, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.0006620955537073314}, {"id": 144, "seek": 50200, "start": 527.76, "end": 531.28, "text": " particular have been shown to be spectacularly capable", "tokens": [51652, 1729, 362, 668, 4898, 281, 312, 18149, 356, 8189, 51828], "temperature": 0.0, "avg_logprob": -0.12143440735645783, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.0006620955537073314}, {"id": 145, "seek": 53128, "start": 531.28, "end": 534.72, "text": " and there's no end in sight the rate of progress is faster now than ever", "tokens": [50364, 293, 456, 311, 572, 917, 294, 7860, 264, 3314, 295, 4205, 307, 4663, 586, 813, 1562, 50536], "temperature": 0.0, "avg_logprob": -0.10299962880660077, "compression_ratio": 1.9136212624584719, "no_speech_prob": 0.0012172925053164363}, {"id": 146, "seek": 53128, "start": 534.72, "end": 538.16, "text": " so it seems very straight nobody imagines that that machine learning and", "tokens": [50536, 370, 309, 2544, 588, 2997, 5079, 2576, 1652, 300, 300, 3479, 2539, 293, 50708], "temperature": 0.0, "avg_logprob": -0.10299962880660077, "compression_ratio": 1.9136212624584719, "no_speech_prob": 0.0012172925053164363}, {"id": 147, "seek": 53128, "start": 538.16, "end": 541.04, "text": " deep learning has suddenly ended at you know whatever the time is today you", "tokens": [50708, 2452, 2539, 575, 5800, 4590, 412, 291, 458, 2035, 264, 565, 307, 965, 291, 50852], "temperature": 0.0, "avg_logprob": -0.10299962880660077, "compression_ratio": 1.9136212624584719, "no_speech_prob": 0.0012172925053164363}, {"id": 148, "seek": 53128, "start": 541.04, "end": 543.8399999999999, "text": " know this is this is this is the beginning of an S-curve", "tokens": [50852, 458, 341, 307, 341, 307, 341, 307, 264, 2863, 295, 364, 318, 12, 14112, 303, 50992], "temperature": 0.0, "avg_logprob": -0.10299962880660077, "compression_ratio": 1.9136212624584719, "no_speech_prob": 0.0012172925053164363}, {"id": 149, "seek": 53128, "start": 543.8399999999999, "end": 547.8399999999999, "text": " so the idea that we would worry so much about the limitations of neural", "tokens": [50992, 370, 264, 1558, 300, 321, 576, 3292, 370, 709, 466, 264, 15705, 295, 18161, 51192], "temperature": 0.0, "avg_logprob": -0.10299962880660077, "compression_ratio": 1.9136212624584719, "no_speech_prob": 0.0012172925053164363}, {"id": 150, "seek": 53128, "start": 547.8399999999999, "end": 550.8, "text": " networks and what they can't do I think we just you put the word yet at the end", "tokens": [51192, 9590, 293, 437, 436, 393, 380, 360, 286, 519, 321, 445, 291, 829, 264, 1349, 1939, 412, 264, 917, 51340], "temperature": 0.0, "avg_logprob": -0.10299962880660077, "compression_ratio": 1.9136212624584719, "no_speech_prob": 0.0012172925053164363}, {"id": 151, "seek": 53128, "start": 550.8, "end": 554.48, "text": " of it your neural networks can't do x y and z yet but but I don't think", "tokens": [51340, 295, 309, 428, 18161, 9590, 393, 380, 360, 2031, 288, 293, 710, 1939, 457, 457, 286, 500, 380, 519, 51524], "temperature": 0.0, "avg_logprob": -0.10299962880660077, "compression_ratio": 1.9136212624584719, "no_speech_prob": 0.0012172925053164363}, {"id": 152, "seek": 53128, "start": 554.48, "end": 558.4, "text": " any sense we've hit the buffers of of what neural nets can do and it's by", "tokens": [51524, 604, 2020, 321, 600, 2045, 264, 9204, 433, 295, 295, 437, 18161, 36170, 393, 360, 293, 309, 311, 538, 51720], "temperature": 0.0, "avg_logprob": -0.10299962880660077, "compression_ratio": 1.9136212624584719, "no_speech_prob": 0.0012172925053164363}, {"id": 153, "seek": 55840, "start": 558.4, "end": 561.92, "text": " far the most successful of the most rapidly advancing technology we have", "tokens": [50364, 1400, 264, 881, 4406, 295, 264, 881, 12910, 27267, 2899, 321, 362, 50540], "temperature": 0.0, "avg_logprob": -0.11776216888427735, "compression_ratio": 1.703125, "no_speech_prob": 0.010643959045410156}, {"id": 154, "seek": 55840, "start": 561.92, "end": 565.36, "text": " so to me you should look for the keys under the lamppost we have this powerful", "tokens": [50540, 370, 281, 385, 291, 820, 574, 337, 264, 9317, 833, 264, 24688, 427, 555, 321, 362, 341, 4005, 50712], "temperature": 0.0, "avg_logprob": -0.11776216888427735, "compression_ratio": 1.703125, "no_speech_prob": 0.010643959045410156}, {"id": 155, "seek": 55840, "start": 565.36, "end": 569.04, "text": " technology that's getting better by the week why would we not see how far we", "tokens": [50712, 2899, 300, 311, 1242, 1101, 538, 264, 1243, 983, 576, 321, 406, 536, 577, 1400, 321, 50896], "temperature": 0.0, "avg_logprob": -0.11776216888427735, "compression_ratio": 1.703125, "no_speech_prob": 0.010643959045410156}, {"id": 156, "seek": 55840, "start": 569.04, "end": 571.36, "text": " can push it rather than worry about its limitations.", "tokens": [50896, 393, 2944, 309, 2831, 813, 3292, 466, 1080, 15705, 13, 51012], "temperature": 0.0, "avg_logprob": -0.11776216888427735, "compression_ratio": 1.703125, "no_speech_prob": 0.010643959045410156}, {"id": 157, "seek": 55840, "start": 571.36, "end": 575.6, "text": " Absolutely now Professor Bishop you are incredibly famous", "tokens": [51012, 7021, 586, 8419, 30113, 291, 366, 6252, 4618, 51224], "temperature": 0.0, "avg_logprob": -0.11776216888427735, "compression_ratio": 1.703125, "no_speech_prob": 0.010643959045410156}, {"id": 158, "seek": 55840, "start": 575.6, "end": 579.04, "text": " for your book PRML but of course it wasn't your first book as you were just", "tokens": [51224, 337, 428, 1446, 11568, 12683, 457, 295, 1164, 309, 2067, 380, 428, 700, 1446, 382, 291, 645, 445, 51396], "temperature": 0.0, "avg_logprob": -0.11776216888427735, "compression_ratio": 1.703125, "no_speech_prob": 0.010643959045410156}, {"id": 159, "seek": 55840, "start": 579.04, "end": 582.16, "text": " speaking to but what was I mean could you just tell us about your your", "tokens": [51396, 4124, 281, 457, 437, 390, 286, 914, 727, 291, 445, 980, 505, 466, 428, 428, 51552], "temperature": 0.0, "avg_logprob": -0.11776216888427735, "compression_ratio": 1.703125, "no_speech_prob": 0.010643959045410156}, {"id": 160, "seek": 55840, "start": 582.16, "end": 585.36, "text": " motivations and just the thought process behind that book?", "tokens": [51552, 39034, 293, 445, 264, 1194, 1399, 2261, 300, 1446, 30, 51712], "temperature": 0.0, "avg_logprob": -0.11776216888427735, "compression_ratio": 1.703125, "no_speech_prob": 0.010643959045410156}, {"id": 161, "seek": 58536, "start": 585.36, "end": 588.88, "text": " Yes so as you said it wasn't my first book my first book is published in 1995", "tokens": [50364, 1079, 370, 382, 291, 848, 309, 2067, 380, 452, 700, 1446, 452, 700, 1446, 307, 6572, 294, 22601, 50540], "temperature": 0.0, "avg_logprob": -0.09208382786931218, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.00019406533101573586}, {"id": 162, "seek": 58536, "start": 588.88, "end": 592.16, "text": " Neural Networks for Pattern Recognition and that book had a very specific", "tokens": [50540, 1734, 1807, 12640, 82, 337, 34367, 77, 44682, 849, 293, 300, 1446, 632, 257, 588, 2685, 50704], "temperature": 0.0, "avg_logprob": -0.09208382786931218, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.00019406533101573586}, {"id": 163, "seek": 58536, "start": 592.16, "end": 595.44, "text": " motivation which is that I was a newcomer to the field I mentioned earlier", "tokens": [50704, 12335, 597, 307, 300, 286, 390, 257, 40014, 260, 281, 264, 2519, 286, 2835, 3071, 50868], "temperature": 0.0, "avg_logprob": -0.09208382786931218, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.00019406533101573586}, {"id": 164, "seek": 58536, "start": 595.44, "end": 597.76, "text": " that I got excited about backprop and and sort of", "tokens": [50868, 300, 286, 658, 2919, 466, 646, 79, 1513, 293, 293, 1333, 295, 50984], "temperature": 0.0, "avg_logprob": -0.09208382786931218, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.00019406533101573586}, {"id": 165, "seek": 58536, "start": 597.76, "end": 600.5600000000001, "text": " transition from theoretical physics into machine learning.", "tokens": [50984, 6034, 490, 20864, 10649, 666, 3479, 2539, 13, 51124], "temperature": 0.0, "avg_logprob": -0.09208382786931218, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.00019406533101573586}, {"id": 166, "seek": 58536, "start": 600.5600000000001, "end": 603.52, "text": " That was my way of learning about the field you know if you're a university", "tokens": [51124, 663, 390, 452, 636, 295, 2539, 466, 264, 2519, 291, 458, 498, 291, 434, 257, 5454, 51272], "temperature": 0.0, "avg_logprob": -0.09208382786931218, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.00019406533101573586}, {"id": 167, "seek": 58536, "start": 603.52, "end": 606.88, "text": " professor a great way to learn about something is to teach a course on it", "tokens": [51272, 8304, 257, 869, 636, 281, 1466, 466, 746, 307, 281, 2924, 257, 1164, 322, 309, 51440], "temperature": 0.0, "avg_logprob": -0.09208382786931218, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.00019406533101573586}, {"id": 168, "seek": 58536, "start": 606.88, "end": 609.52, "text": " because it forces you to think about it very carefully you're going to get", "tokens": [51440, 570, 309, 5874, 291, 281, 519, 466, 309, 588, 7500, 291, 434, 516, 281, 483, 51572], "temperature": 0.0, "avg_logprob": -0.09208382786931218, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.00019406533101573586}, {"id": 169, "seek": 58536, "start": 609.52, "end": 613.28, "text": " tricky questions from smart students and you're very motivated to to really", "tokens": [51572, 12414, 1651, 490, 4069, 1731, 293, 291, 434, 588, 14515, 281, 281, 534, 51760], "temperature": 0.0, "avg_logprob": -0.09208382786931218, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.00019406533101573586}, {"id": 170, "seek": 61328, "start": 613.28, "end": 617.28, "text": " understand it and so for me the analogue of that was was writing a book.", "tokens": [50364, 1223, 309, 293, 370, 337, 385, 264, 2624, 7213, 295, 300, 390, 390, 3579, 257, 1446, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1353631610712729, "compression_ratio": 1.8263888888888888, "no_speech_prob": 0.002971969312056899}, {"id": 171, "seek": 61328, "start": 617.28, "end": 621.76, "text": " PRML was rather different by the time we got to published in 2006 and by then", "tokens": [50564, 11568, 12683, 390, 2831, 819, 538, 264, 565, 321, 658, 281, 6572, 294, 14062, 293, 538, 550, 50788], "temperature": 0.0, "avg_logprob": -0.1353631610712729, "compression_ratio": 1.8263888888888888, "no_speech_prob": 0.002971969312056899}, {"id": 172, "seek": 61328, "start": 621.76, "end": 625.12, "text": " the field was much larger its sense it was much more mature as a much more", "tokens": [50788, 264, 2519, 390, 709, 4833, 1080, 2020, 309, 390, 709, 544, 14442, 382, 257, 709, 544, 50956], "temperature": 0.0, "avg_logprob": -0.1353631610712729, "compression_ratio": 1.8263888888888888, "no_speech_prob": 0.002971969312056899}, {"id": 173, "seek": 61328, "start": 625.12, "end": 628.88, "text": " established and respected field there were many courses on machine learning", "tokens": [50956, 7545, 293, 20020, 2519, 456, 645, 867, 7712, 322, 3479, 2539, 51144], "temperature": 0.0, "avg_logprob": -0.1353631610712729, "compression_ratio": 1.8263888888888888, "no_speech_prob": 0.002971969312056899}, {"id": 174, "seek": 61328, "start": 628.88, "end": 632.56, "text": " the goal there was very different I simply wanted to write the as it were", "tokens": [51144, 264, 3387, 456, 390, 588, 819, 286, 2935, 1415, 281, 2464, 264, 382, 309, 645, 51328], "temperature": 0.0, "avg_logprob": -0.1353631610712729, "compression_ratio": 1.8263888888888888, "no_speech_prob": 0.002971969312056899}, {"id": 175, "seek": 61328, "start": 632.56, "end": 635.4399999999999, "text": " the book that everybody would use to learn about the field so it was trying to", "tokens": [51328, 264, 1446, 300, 2201, 576, 764, 281, 1466, 466, 264, 2519, 370, 309, 390, 1382, 281, 51472], "temperature": 0.0, "avg_logprob": -0.1353631610712729, "compression_ratio": 1.8263888888888888, "no_speech_prob": 0.002971969312056899}, {"id": 176, "seek": 61328, "start": 635.4399999999999, "end": 639.92, "text": " be comprehensive but trying to be to explain the concepts as clearly as", "tokens": [51472, 312, 13914, 457, 1382, 281, 312, 281, 2903, 264, 10392, 382, 4448, 382, 51696], "temperature": 0.0, "avg_logprob": -0.1353631610712729, "compression_ratio": 1.8263888888888888, "no_speech_prob": 0.002971969312056899}, {"id": 177, "seek": 63992, "start": 639.92, "end": 645.4399999999999, "text": " possible and so really that was the goal the goal was to in a sense you know", "tokens": [50364, 1944, 293, 370, 534, 300, 390, 264, 3387, 264, 3387, 390, 281, 294, 257, 2020, 291, 458, 50640], "temperature": 0.0, "avg_logprob": -0.09934792151817909, "compression_ratio": 1.8073394495412844, "no_speech_prob": 0.005052465014159679}, {"id": 178, "seek": 63992, "start": 645.4399999999999, "end": 648.8, "text": " replace the earlier neural nets for pattern recognition book which was", "tokens": [50640, 7406, 264, 3071, 18161, 36170, 337, 5102, 11150, 1446, 597, 390, 50808], "temperature": 0.0, "avg_logprob": -0.09934792151817909, "compression_ratio": 1.8073394495412844, "no_speech_prob": 0.005052465014159679}, {"id": 179, "seek": 63992, "start": 648.8, "end": 652.8, "text": " which serves an important role in its day I think but really try to produce a", "tokens": [50808, 597, 13451, 364, 1021, 3090, 294, 1080, 786, 286, 519, 457, 534, 853, 281, 5258, 257, 51008], "temperature": 0.0, "avg_logprob": -0.09934792151817909, "compression_ratio": 1.8073394495412844, "no_speech_prob": 0.005052465014159679}, {"id": 180, "seek": 63992, "start": 652.8, "end": 656.64, "text": " single coherent text where people could learn about the different topics in", "tokens": [51008, 2167, 36239, 2487, 689, 561, 727, 1466, 466, 264, 819, 8378, 294, 51200], "temperature": 0.0, "avg_logprob": -0.09934792151817909, "compression_ratio": 1.8073394495412844, "no_speech_prob": 0.005052465014159679}, {"id": 181, "seek": 63992, "start": 656.64, "end": 659.5999999999999, "text": " you know with a shared notation and hopefully trying to explain things as", "tokens": [51200, 291, 458, 365, 257, 5507, 24657, 293, 4696, 1382, 281, 2903, 721, 382, 51348], "temperature": 0.0, "avg_logprob": -0.09934792151817909, "compression_ratio": 1.8073394495412844, "no_speech_prob": 0.005052465014159679}, {"id": 182, "seek": 63992, "start": 659.5999999999999, "end": 662.3199999999999, "text": " clearly as I could. We know in theoretical physics you know you can", "tokens": [51348, 4448, 382, 286, 727, 13, 492, 458, 294, 20864, 10649, 291, 458, 291, 393, 51484], "temperature": 0.0, "avg_logprob": -0.09934792151817909, "compression_ratio": 1.8073394495412844, "no_speech_prob": 0.005052465014159679}, {"id": 183, "seek": 63992, "start": 662.3199999999999, "end": 665.1999999999999, "text": " you can write down an equation but solving it may be extremely difficult", "tokens": [51484, 291, 393, 2464, 760, 364, 5367, 457, 12606, 309, 815, 312, 4664, 2252, 51628], "temperature": 0.0, "avg_logprob": -0.09934792151817909, "compression_ratio": 1.8073394495412844, "no_speech_prob": 0.005052465014159679}, {"id": 184, "seek": 63992, "start": 665.1999999999999, "end": 668.8, "text": " you have to resort to approximations but it's still nice to have that that", "tokens": [51628, 291, 362, 281, 19606, 281, 8542, 763, 457, 309, 311, 920, 1481, 281, 362, 300, 300, 51808], "temperature": 0.0, "avg_logprob": -0.09934792151817909, "compression_ratio": 1.8073394495412844, "no_speech_prob": 0.005052465014159679}, {"id": 185, "seek": 66880, "start": 668.8, "end": 673.3599999999999, "text": " north star that compass that guides you and so for me I try to think of machine", "tokens": [50364, 6830, 3543, 300, 10707, 300, 17007, 291, 293, 370, 337, 385, 286, 853, 281, 519, 295, 3479, 50592], "temperature": 0.0, "avg_logprob": -0.10046864422884855, "compression_ratio": 1.9074074074074074, "no_speech_prob": 0.0019636473152786493}, {"id": 186, "seek": 66880, "start": 673.3599999999999, "end": 677.04, "text": " learning in similar terms there are some some foundations that that really", "tokens": [50592, 2539, 294, 2531, 2115, 456, 366, 512, 512, 22467, 300, 300, 534, 50776], "temperature": 0.0, "avg_logprob": -0.10046864422884855, "compression_ratio": 1.9074074074074074, "no_speech_prob": 0.0019636473152786493}, {"id": 187, "seek": 66880, "start": 677.04, "end": 681.4399999999999, "text": " don't change much over time that are that are very good guiding principles and", "tokens": [50776, 500, 380, 1319, 709, 670, 565, 300, 366, 300, 366, 588, 665, 25061, 9156, 293, 50996], "temperature": 0.0, "avg_logprob": -0.10046864422884855, "compression_ratio": 1.9074074074074074, "no_speech_prob": 0.0019636473152786493}, {"id": 188, "seek": 66880, "start": 681.4399999999999, "end": 684.56, "text": " we're dealing with data we're dealing with uncertainty we want to be", "tokens": [50996, 321, 434, 6260, 365, 1412, 321, 434, 6260, 365, 15697, 321, 528, 281, 312, 51152], "temperature": 0.0, "avg_logprob": -0.10046864422884855, "compression_ratio": 1.9074074074074074, "no_speech_prob": 0.0019636473152786493}, {"id": 189, "seek": 66880, "start": 684.56, "end": 689.04, "text": " quantitative so you're led very naturally indeed uniquely into probability theory", "tokens": [51152, 27778, 370, 291, 434, 4684, 588, 8195, 6451, 31474, 666, 8482, 5261, 51376], "temperature": 0.0, "avg_logprob": -0.10046864422884855, "compression_ratio": 1.9074074074074074, "no_speech_prob": 0.0019636473152786493}, {"id": 190, "seek": 66880, "start": 689.04, "end": 692.16, "text": " and if you apply probability theory consistently that is the Bayesian", "tokens": [51376, 293, 498, 291, 3079, 8482, 5261, 14961, 300, 307, 264, 7840, 42434, 51532], "temperature": 0.0, "avg_logprob": -0.10046864422884855, "compression_ratio": 1.9074074074074074, "no_speech_prob": 0.0019636473152786493}, {"id": 191, "seek": 66880, "start": 692.16, "end": 696.16, "text": " framework so for me the Bayesian framework is a very natural", "tokens": [51532, 8388, 370, 337, 385, 264, 7840, 42434, 8388, 307, 257, 588, 3303, 51732], "temperature": 0.0, "avg_logprob": -0.10046864422884855, "compression_ratio": 1.9074074074074074, "no_speech_prob": 0.0019636473152786493}, {"id": 192, "seek": 69616, "start": 696.16, "end": 699.6, "text": " bedrock on which you can build and think about machine learning now just as", "tokens": [50364, 2901, 17799, 322, 597, 291, 393, 1322, 293, 519, 466, 3479, 2539, 586, 445, 382, 50536], "temperature": 0.0, "avg_logprob": -0.07426803176467484, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.005715396720916033}, {"id": 193, "seek": 69616, "start": 699.6, "end": 702.64, "text": " with theoretical physics you can't often just solve things exactly and", "tokens": [50536, 365, 20864, 10649, 291, 393, 380, 2049, 445, 5039, 721, 2293, 293, 50688], "temperature": 0.0, "avg_logprob": -0.07426803176467484, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.005715396720916033}, {"id": 194, "seek": 69616, "start": 702.64, "end": 706.0799999999999, "text": " certainly the Bayesian paradigm calls for", "tokens": [50688, 3297, 264, 7840, 42434, 24709, 5498, 337, 50860], "temperature": 0.0, "avg_logprob": -0.07426803176467484, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.005715396720916033}, {"id": 195, "seek": 69616, "start": 706.0799999999999, "end": 709.92, "text": " integration or marginalization of all possible values of the parameters in", "tokens": [50860, 10980, 420, 16885, 2144, 295, 439, 1944, 4190, 295, 264, 9834, 294, 51052], "temperature": 0.0, "avg_logprob": -0.07426803176467484, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.005715396720916033}, {"id": 196, "seek": 69616, "start": 709.92, "end": 712.9599999999999, "text": " your neural network well you always operate with a fixed", "tokens": [51052, 428, 18161, 3209, 731, 291, 1009, 9651, 365, 257, 6806, 51204], "temperature": 0.0, "avg_logprob": -0.07426803176467484, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.005715396720916033}, {"id": 197, "seek": 69616, "start": 712.9599999999999, "end": 716.4, "text": " computational budget right it may be a huge one but it be always constrained", "tokens": [51204, 28270, 4706, 558, 309, 815, 312, 257, 2603, 472, 457, 309, 312, 1009, 38901, 51376], "temperature": 0.0, "avg_logprob": -0.07426803176467484, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.005715396720916033}, {"id": 198, "seek": 69616, "start": 716.4, "end": 720.3199999999999, "text": " by by computational budget and should you spend that budget doing a very", "tokens": [51376, 538, 538, 28270, 4706, 293, 820, 291, 3496, 300, 4706, 884, 257, 588, 51572], "temperature": 0.0, "avg_logprob": -0.07426803176467484, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.005715396720916033}, {"id": 199, "seek": 69616, "start": 720.3199999999999, "end": 723.68, "text": " thorough Bayesian marginalization over a small neural network", "tokens": [51572, 12934, 7840, 42434, 16885, 2144, 670, 257, 1359, 18161, 3209, 51740], "temperature": 0.0, "avg_logprob": -0.07426803176467484, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.005715396720916033}, {"id": 200, "seek": 72368, "start": 723.68, "end": 726.9599999999999, "text": " or should you take the same number of compute cycles and train a very much", "tokens": [50364, 420, 820, 291, 747, 264, 912, 1230, 295, 14722, 17796, 293, 3847, 257, 588, 709, 50528], "temperature": 0.0, "avg_logprob": -0.0736255267309764, "compression_ratio": 1.8137254901960784, "no_speech_prob": 0.0006756769143976271}, {"id": 201, "seek": 72368, "start": 726.9599999999999, "end": 730.3199999999999, "text": " larger network and if you have plenty of data to train the larger network then", "tokens": [50528, 4833, 3209, 293, 498, 291, 362, 7140, 295, 1412, 281, 3847, 264, 4833, 3209, 550, 50696], "temperature": 0.0, "avg_logprob": -0.0736255267309764, "compression_ratio": 1.8137254901960784, "no_speech_prob": 0.0006756769143976271}, {"id": 202, "seek": 72368, "start": 730.3199999999999, "end": 733.5999999999999, "text": " the latter seems to be much more effective in a practical sense", "tokens": [50696, 264, 18481, 2544, 281, 312, 709, 544, 4942, 294, 257, 8496, 2020, 50860], "temperature": 0.0, "avg_logprob": -0.0736255267309764, "compression_ratio": 1.8137254901960784, "no_speech_prob": 0.0006756769143976271}, {"id": 203, "seek": 72368, "start": 733.5999999999999, "end": 737.28, "text": " so while from a practical point of view the Bayesian approach still has", "tokens": [50860, 370, 1339, 490, 257, 8496, 935, 295, 1910, 264, 7840, 42434, 3109, 920, 575, 51044], "temperature": 0.0, "avg_logprob": -0.0736255267309764, "compression_ratio": 1.8137254901960784, "no_speech_prob": 0.0006756769143976271}, {"id": 204, "seek": 72368, "start": 737.28, "end": 741.92, "text": " certain applications in in various domains for the most part it's not the", "tokens": [51044, 1629, 5821, 294, 294, 3683, 25514, 337, 264, 881, 644, 309, 311, 406, 264, 51276], "temperature": 0.0, "avg_logprob": -0.0736255267309764, "compression_ratio": 1.8137254901960784, "no_speech_prob": 0.0006756769143976271}, {"id": 205, "seek": 72368, "start": 741.92, "end": 745.52, "text": " framework we'd want to use in in sort of mainstream", "tokens": [51276, 8388, 321, 1116, 528, 281, 764, 294, 294, 1333, 295, 15960, 51456], "temperature": 0.0, "avg_logprob": -0.0736255267309764, "compression_ratio": 1.8137254901960784, "no_speech_prob": 0.0006756769143976271}, {"id": 206, "seek": 72368, "start": 745.52, "end": 749.1999999999999, "text": " machine learning today we're much more interested in scale and making point", "tokens": [51456, 3479, 2539, 965, 321, 434, 709, 544, 3102, 294, 4373, 293, 1455, 935, 51640], "temperature": 0.0, "avg_logprob": -0.0736255267309764, "compression_ratio": 1.8137254901960784, "no_speech_prob": 0.0006756769143976271}, {"id": 207, "seek": 72368, "start": 749.1999999999999, "end": 753.04, "text": " estimates in using stagastic gradient send and so on so I still", "tokens": [51640, 20561, 294, 1228, 342, 559, 2750, 16235, 2845, 293, 370, 322, 370, 286, 920, 51832], "temperature": 0.0, "avg_logprob": -0.0736255267309764, "compression_ratio": 1.8137254901960784, "no_speech_prob": 0.0006756769143976271}, {"id": 208, "seek": 75304, "start": 753.04, "end": 756.7199999999999, "text": " think that students should learn the basic ideas of of Bayesian inference", "tokens": [50364, 519, 300, 1731, 820, 1466, 264, 3875, 3487, 295, 295, 7840, 42434, 38253, 50548], "temperature": 0.0, "avg_logprob": -0.09444440888964441, "compression_ratio": 1.9409722222222223, "no_speech_prob": 0.0034391223452985287}, {"id": 209, "seek": 75304, "start": 756.7199999999999, "end": 759.36, "text": " because really they have to learn you have to learn about probability I don't", "tokens": [50548, 570, 534, 436, 362, 281, 1466, 291, 362, 281, 1466, 466, 8482, 286, 500, 380, 50680], "temperature": 0.0, "avg_logprob": -0.09444440888964441, "compression_ratio": 1.9409722222222223, "no_speech_prob": 0.0034391223452985287}, {"id": 210, "seek": 75304, "start": 759.36, "end": 762.4, "text": " think you can be in machine learning and not understand probability", "tokens": [50680, 519, 291, 393, 312, 294, 3479, 2539, 293, 406, 1223, 8482, 50832], "temperature": 0.0, "avg_logprob": -0.09444440888964441, "compression_ratio": 1.9409722222222223, "no_speech_prob": 0.0034391223452985287}, {"id": 211, "seek": 75304, "start": 762.4, "end": 765.52, "text": " and then once you understand probability and you apply it uniformly that", "tokens": [50832, 293, 550, 1564, 291, 1223, 8482, 293, 291, 3079, 309, 48806, 300, 50988], "temperature": 0.0, "avg_logprob": -0.09444440888964441, "compression_ratio": 1.9409722222222223, "no_speech_prob": 0.0034391223452985287}, {"id": 212, "seek": 75304, "start": 765.52, "end": 769.5999999999999, "text": " that really is the Bayesian framework so I think it's the foundation", "tokens": [50988, 300, 534, 307, 264, 7840, 42434, 8388, 370, 286, 519, 309, 311, 264, 7030, 51192], "temperature": 0.0, "avg_logprob": -0.09444440888964441, "compression_ratio": 1.9409722222222223, "no_speech_prob": 0.0034391223452985287}, {"id": 213, "seek": 75304, "start": 769.5999999999999, "end": 773.12, "text": " but then you're led to make approximations and in particular you make", "tokens": [51192, 457, 550, 291, 434, 4684, 281, 652, 8542, 763, 293, 294, 1729, 291, 652, 51368], "temperature": 0.0, "avg_logprob": -0.09444440888964441, "compression_ratio": 1.9409722222222223, "no_speech_prob": 0.0034391223452985287}, {"id": 214, "seek": 75304, "start": 773.12, "end": 776.4, "text": " point estimates so in practice you don't actually execute the full Bayesian", "tokens": [51368, 935, 20561, 370, 294, 3124, 291, 500, 380, 767, 14483, 264, 1577, 7840, 42434, 51532], "temperature": 0.0, "avg_logprob": -0.09444440888964441, "compression_ratio": 1.9409722222222223, "no_speech_prob": 0.0034391223452985287}, {"id": 215, "seek": 75304, "start": 776.4, "end": 780.56, "text": " paradigm yeah I agree that um Bayesian reasoning is", "tokens": [51532, 24709, 1338, 286, 3986, 300, 1105, 7840, 42434, 21577, 307, 51740], "temperature": 0.0, "avg_logprob": -0.09444440888964441, "compression_ratio": 1.9409722222222223, "no_speech_prob": 0.0034391223452985287}, {"id": 216, "seek": 78056, "start": 780.56, "end": 784.4, "text": " it's beautiful and it's the continuation even of sort of propositional", "tokens": [50364, 309, 311, 2238, 293, 309, 311, 264, 29357, 754, 295, 1333, 295, 7532, 2628, 50556], "temperature": 0.0, "avg_logprob": -0.06723428405491652, "compression_ratio": 1.821011673151751, "no_speech_prob": 0.006596466526389122}, {"id": 217, "seek": 78056, "start": 784.4, "end": 787.52, "text": " logic in the domain of uncertainty it's fundamental", "tokens": [50556, 9952, 294, 264, 9274, 295, 15697, 309, 311, 8088, 50712], "temperature": 0.0, "avg_logprob": -0.06723428405491652, "compression_ratio": 1.821011673151751, "no_speech_prob": 0.006596466526389122}, {"id": 218, "seek": 78056, "start": 787.52, "end": 792.4, "text": " but there is this question of the world is a very gnarly place", "tokens": [50712, 457, 456, 307, 341, 1168, 295, 264, 1002, 307, 257, 588, 290, 20062, 356, 1081, 50956], "temperature": 0.0, "avg_logprob": -0.06723428405491652, "compression_ratio": 1.821011673151751, "no_speech_prob": 0.006596466526389122}, {"id": 219, "seek": 78056, "start": 792.4, "end": 797.1999999999999, "text": " and folks argue that the brain is a kind of Bayesian inference machine", "tokens": [50956, 293, 4024, 9695, 300, 264, 3567, 307, 257, 733, 295, 7840, 42434, 38253, 3479, 51196], "temperature": 0.0, "avg_logprob": -0.06723428405491652, "compression_ratio": 1.821011673151751, "no_speech_prob": 0.006596466526389122}, {"id": 220, "seek": 78056, "start": 797.1999999999999, "end": 802.56, "text": " but it can't it can't possibly be solving the intractable Bayesian problem", "tokens": [51196, 457, 309, 393, 380, 309, 393, 380, 6264, 312, 12606, 264, 560, 1897, 712, 7840, 42434, 1154, 51464], "temperature": 0.0, "avg_logprob": -0.06723428405491652, "compression_ratio": 1.821011673151751, "no_speech_prob": 0.006596466526389122}, {"id": 221, "seek": 78056, "start": 802.56, "end": 806.4, "text": " and therein lies the question so there are many hybrids or", "tokens": [51464, 293, 456, 259, 9134, 264, 1168, 370, 456, 366, 867, 2477, 1443, 3742, 420, 51656], "temperature": 0.0, "avg_logprob": -0.06723428405491652, "compression_ratio": 1.821011673151751, "no_speech_prob": 0.006596466526389122}, {"id": 222, "seek": 78056, "start": 806.4, "end": 810.0799999999999, "text": " even deep learning approaches could be seen as some kind of a continuation or", "tokens": [51656, 754, 2452, 2539, 11587, 727, 312, 1612, 382, 512, 733, 295, 257, 29357, 420, 51840], "temperature": 0.0, "avg_logprob": -0.06723428405491652, "compression_ratio": 1.821011673151751, "no_speech_prob": 0.006596466526389122}, {"id": 223, "seek": 81008, "start": 810.08, "end": 814.48, "text": " somewhere on the spectrum between maximum likelihood point estimation and", "tokens": [50364, 4079, 322, 264, 11143, 1296, 6674, 22119, 935, 35701, 293, 50584], "temperature": 0.0, "avg_logprob": -0.09027042233847021, "compression_ratio": 1.7993079584775087, "no_speech_prob": 0.0006999039324000478}, {"id": 224, "seek": 81008, "start": 814.48, "end": 818.1600000000001, "text": " Bayesian models I mean how do you think about that", "tokens": [50584, 7840, 42434, 5245, 286, 914, 577, 360, 291, 519, 466, 300, 50768], "temperature": 0.0, "avg_logprob": -0.09027042233847021, "compression_ratio": 1.7993079584775087, "no_speech_prob": 0.0006999039324000478}, {"id": 225, "seek": 81008, "start": 818.1600000000001, "end": 820.5600000000001, "text": " spectrum I think that's a great that's a great question I", "tokens": [50768, 11143, 286, 519, 300, 311, 257, 869, 300, 311, 257, 869, 1168, 286, 50888], "temperature": 0.0, "avg_logprob": -0.09027042233847021, "compression_ratio": 1.7993079584775087, "no_speech_prob": 0.0006999039324000478}, {"id": 226, "seek": 81008, "start": 820.5600000000001, "end": 823.9200000000001, "text": " think you're spot on there if you look back to a time when", "tokens": [50888, 519, 291, 434, 4008, 322, 456, 498, 291, 574, 646, 281, 257, 565, 562, 51056], "temperature": 0.0, "avg_logprob": -0.09027042233847021, "compression_ratio": 1.7993079584775087, "no_speech_prob": 0.0006999039324000478}, {"id": 227, "seek": 81008, "start": 823.9200000000001, "end": 826.72, "text": " there are a lot of competitions here's a data set we're going to hold out the", "tokens": [51056, 456, 366, 257, 688, 295, 26185, 510, 311, 257, 1412, 992, 321, 434, 516, 281, 1797, 484, 264, 51196], "temperature": 0.0, "avg_logprob": -0.09027042233847021, "compression_ratio": 1.7993079584775087, "no_speech_prob": 0.0006999039324000478}, {"id": 228, "seek": 81008, "start": 826.72, "end": 829.5200000000001, "text": " test set you've got to score as high as you can on the test set", "tokens": [51196, 1500, 992, 291, 600, 658, 281, 6175, 382, 1090, 382, 291, 393, 322, 264, 1500, 992, 51336], "temperature": 0.0, "avg_logprob": -0.09027042233847021, "compression_ratio": 1.7993079584775087, "no_speech_prob": 0.0006999039324000478}, {"id": 229, "seek": 81008, "start": 829.5200000000001, "end": 834.0, "text": " and what approach should you use the winner always is an ensemble you", "tokens": [51336, 293, 437, 3109, 820, 291, 764, 264, 8507, 1009, 307, 364, 19492, 291, 51560], "temperature": 0.0, "avg_logprob": -0.09027042233847021, "compression_ratio": 1.7993079584775087, "no_speech_prob": 0.0006999039324000478}, {"id": 230, "seek": 81008, "start": 834.0, "end": 837.5200000000001, "text": " should try 10 different things preferably diverse and then combine", "tokens": [51560, 820, 853, 1266, 819, 721, 45916, 9521, 293, 550, 10432, 51736], "temperature": 0.0, "avg_logprob": -0.09027042233847021, "compression_ratio": 1.7993079584775087, "no_speech_prob": 0.0006999039324000478}, {"id": 231, "seek": 83752, "start": 837.52, "end": 841.12, "text": " them suitably maybe taking an average or some smarter combination", "tokens": [50364, 552, 5722, 1188, 1310, 1940, 364, 4274, 420, 512, 20294, 6562, 50544], "temperature": 0.0, "avg_logprob": -0.06603779912996693, "compression_ratio": 1.7766666666666666, "no_speech_prob": 0.0020459587685763836}, {"id": 232, "seek": 83752, "start": 841.12, "end": 845.28, "text": " and that ensemble will always outperform any one single model", "tokens": [50544, 293, 300, 19492, 486, 1009, 484, 26765, 604, 472, 2167, 2316, 50752], "temperature": 0.0, "avg_logprob": -0.06603779912996693, "compression_ratio": 1.7766666666666666, "no_speech_prob": 0.0020459587685763836}, {"id": 233, "seek": 83752, "start": 845.28, "end": 848.48, "text": " so if you're not constrained by compute and in some of those competitions you", "tokens": [50752, 370, 498, 291, 434, 406, 38901, 538, 14722, 293, 294, 512, 295, 729, 26185, 291, 50912], "temperature": 0.0, "avg_logprob": -0.06603779912996693, "compression_ratio": 1.7766666666666666, "no_speech_prob": 0.0020459587685763836}, {"id": 234, "seek": 83752, "start": 848.48, "end": 852.0799999999999, "text": " weren't then the ensemble always wins and you can think about that ensemble is", "tokens": [50912, 4999, 380, 550, 264, 19492, 1009, 10641, 293, 291, 393, 519, 466, 300, 19492, 307, 51092], "temperature": 0.0, "avg_logprob": -0.06603779912996693, "compression_ratio": 1.7766666666666666, "no_speech_prob": 0.0020459587685763836}, {"id": 235, "seek": 83752, "start": 852.0799999999999, "end": 855.1999999999999, "text": " like as you say a sort of rough and ready approximation", "tokens": [51092, 411, 382, 291, 584, 257, 1333, 295, 5903, 293, 1919, 28023, 51248], "temperature": 0.0, "avg_logprob": -0.06603779912996693, "compression_ratio": 1.7766666666666666, "no_speech_prob": 0.0020459587685763836}, {"id": 236, "seek": 83752, "start": 855.1999999999999, "end": 859.6, "text": " to a full marginalization of all of the uncertainty in the predictions that you", "tokens": [51248, 281, 257, 1577, 16885, 2144, 295, 439, 295, 264, 15697, 294, 264, 21264, 300, 291, 51468], "temperature": 0.0, "avg_logprob": -0.06603779912996693, "compression_ratio": 1.7766666666666666, "no_speech_prob": 0.0020459587685763836}, {"id": 237, "seek": 83752, "start": 859.6, "end": 862.0799999999999, "text": " might make and so I think there's a little glimmer of", "tokens": [51468, 1062, 652, 293, 370, 286, 519, 456, 311, 257, 707, 1563, 14477, 295, 51592], "temperature": 0.0, "avg_logprob": -0.06603779912996693, "compression_ratio": 1.7766666666666666, "no_speech_prob": 0.0020459587685763836}, {"id": 238, "seek": 83752, "start": 862.0799999999999, "end": 864.8, "text": " sort of Bayesian approaches coming through there but again", "tokens": [51592, 1333, 295, 7840, 42434, 11587, 1348, 807, 456, 457, 797, 51728], "temperature": 0.0, "avg_logprob": -0.06603779912996693, "compression_ratio": 1.7766666666666666, "no_speech_prob": 0.0020459587685763836}, {"id": 239, "seek": 86480, "start": 864.8, "end": 868.0799999999999, "text": " you know in the modern era you're probably better off training one single", "tokens": [50364, 291, 458, 294, 264, 4363, 4249, 291, 434, 1391, 1101, 766, 3097, 472, 2167, 50528], "temperature": 0.0, "avg_logprob": -0.10514239775828826, "compression_ratio": 1.760797342192691, "no_speech_prob": 0.002159945433959365}, {"id": 240, "seek": 86480, "start": 868.0799999999999, "end": 871.12, "text": " large model than 10 smaller ones and averaging", "tokens": [50528, 2416, 2316, 813, 1266, 4356, 2306, 293, 47308, 50680], "temperature": 0.0, "avg_logprob": -0.10514239775828826, "compression_ratio": 1.760797342192691, "no_speech_prob": 0.002159945433959365}, {"id": 241, "seek": 86480, "start": 871.12, "end": 875.68, "text": " so it's so I think knowing about the Bayesian paradigm and understanding", "tokens": [50680, 370, 309, 311, 370, 286, 519, 5276, 466, 264, 7840, 42434, 24709, 293, 3701, 50908], "temperature": 0.0, "avg_logprob": -0.10514239775828826, "compression_ratio": 1.760797342192691, "no_speech_prob": 0.002159945433959365}, {"id": 242, "seek": 86480, "start": 875.68, "end": 879.04, "text": " where you can learn from it is still valuable today", "tokens": [50908, 689, 291, 393, 1466, 490, 309, 307, 920, 8263, 965, 51076], "temperature": 0.0, "avg_logprob": -0.10514239775828826, "compression_ratio": 1.760797342192691, "no_speech_prob": 0.002159945433959365}, {"id": 243, "seek": 86480, "start": 879.04, "end": 883.8399999999999, "text": " but nevertheless it's unlikely in most applications that you're going to want", "tokens": [51076, 457, 26924, 309, 311, 17518, 294, 881, 5821, 300, 291, 434, 516, 281, 528, 51316], "temperature": 0.0, "avg_logprob": -0.10514239775828826, "compression_ratio": 1.760797342192691, "no_speech_prob": 0.002159945433959365}, {"id": 244, "seek": 86480, "start": 883.8399999999999, "end": 886.9599999999999, "text": " to apply the full Bayesian machinery because it's just so computational", "tokens": [51316, 281, 3079, 264, 1577, 7840, 42434, 27302, 570, 309, 311, 445, 370, 28270, 51472], "temperature": 0.0, "avg_logprob": -0.10514239775828826, "compression_ratio": 1.760797342192691, "no_speech_prob": 0.002159945433959365}, {"id": 245, "seek": 86480, "start": 886.9599999999999, "end": 890.4, "text": " expensive fascinating I mean just one more thing on this", "tokens": [51472, 5124, 10343, 286, 914, 445, 472, 544, 551, 322, 341, 51644], "temperature": 0.0, "avg_logprob": -0.10514239775828826, "compression_ratio": 1.760797342192691, "no_speech_prob": 0.002159945433959365}, {"id": 246, "seek": 86480, "start": 890.4, "end": 894.3199999999999, "text": " do you think of large you know let's say large language models but large deep", "tokens": [51644, 360, 291, 519, 295, 2416, 291, 458, 718, 311, 584, 2416, 2856, 5245, 457, 2416, 2452, 51840], "temperature": 0.0, "avg_logprob": -0.10514239775828826, "compression_ratio": 1.760797342192691, "no_speech_prob": 0.002159945433959365}, {"id": 247, "seek": 89432, "start": 894.32, "end": 897.6800000000001, "text": " learning models do you think of them as one model or do you think of", "tokens": [50364, 2539, 5245, 360, 291, 519, 295, 552, 382, 472, 2316, 420, 360, 291, 519, 295, 50532], "temperature": 0.0, "avg_logprob": -0.11505331099033356, "compression_ratio": 1.9787234042553192, "no_speech_prob": 0.0016836455324664712}, {"id": 248, "seek": 89432, "start": 897.6800000000001, "end": 901.2, "text": " them as an inscrutable bundle of models because we're kind of getting into the", "tokens": [50532, 552, 382, 364, 1028, 10757, 32148, 24438, 295, 5245, 570, 321, 434, 733, 295, 1242, 666, 264, 50708], "temperature": 0.0, "avg_logprob": -0.11505331099033356, "compression_ratio": 1.9787234042553192, "no_speech_prob": 0.0016836455324664712}, {"id": 249, "seek": 89432, "start": 901.2, "end": 905.2800000000001, "text": " no-free lunch theorem here coming from the Bayesian world we", "tokens": [50708, 572, 12, 10792, 6349, 20904, 510, 1348, 490, 264, 7840, 42434, 1002, 321, 50912], "temperature": 0.0, "avg_logprob": -0.11505331099033356, "compression_ratio": 1.9787234042553192, "no_speech_prob": 0.0016836455324664712}, {"id": 250, "seek": 89432, "start": 905.2800000000001, "end": 909.5200000000001, "text": " design models you know using principles and with neural networks we just", "tokens": [50912, 1715, 5245, 291, 458, 1228, 9156, 293, 365, 18161, 9590, 321, 445, 51124], "temperature": 0.0, "avg_logprob": -0.11505331099033356, "compression_ratio": 1.9787234042553192, "no_speech_prob": 0.0016836455324664712}, {"id": 251, "seek": 89432, "start": 909.5200000000001, "end": 912.96, "text": " train these big black boxes so do you think of them as one model or lots of", "tokens": [51124, 3847, 613, 955, 2211, 9002, 370, 360, 291, 519, 295, 552, 382, 472, 2316, 420, 3195, 295, 51296], "temperature": 0.0, "avg_logprob": -0.11505331099033356, "compression_ratio": 1.9787234042553192, "no_speech_prob": 0.0016836455324664712}, {"id": 252, "seek": 89432, "start": 912.96, "end": 916.0, "text": " models I certainly I always think of them as a", "tokens": [51296, 5245, 286, 3297, 286, 1009, 519, 295, 552, 382, 257, 51448], "temperature": 0.0, "avg_logprob": -0.11505331099033356, "compression_ratio": 1.9787234042553192, "no_speech_prob": 0.0016836455324664712}, {"id": 253, "seek": 89432, "start": 916.0, "end": 918.96, "text": " single model I've never thought thought of them as separate models unless you", "tokens": [51448, 2167, 2316, 286, 600, 1128, 1194, 1194, 295, 552, 382, 4994, 5245, 5969, 291, 51596], "temperature": 0.0, "avg_logprob": -0.11505331099033356, "compression_ratio": 1.9787234042553192, "no_speech_prob": 0.0016836455324664712}, {"id": 254, "seek": 89432, "start": 918.96, "end": 921.5200000000001, "text": " unless you explicitly construct a mixture of experts or something like that", "tokens": [51596, 5969, 291, 20803, 7690, 257, 9925, 295, 8572, 420, 746, 411, 300, 51724], "temperature": 0.0, "avg_logprob": -0.11505331099033356, "compression_ratio": 1.9787234042553192, "no_speech_prob": 0.0016836455324664712}, {"id": 255, "seek": 92152, "start": 921.6, "end": 925.28, "text": " you have an internal an internal structure I guess", "tokens": [50368, 291, 362, 364, 6920, 364, 6920, 3877, 286, 2041, 50552], "temperature": 0.0, "avg_logprob": -0.13133949633465697, "compression_ratio": 1.868804664723032, "no_speech_prob": 0.005911329761147499}, {"id": 256, "seek": 92152, "start": 925.28, "end": 928.0799999999999, "text": " everything is sort of very distributed and somehow sort of holographic and", "tokens": [50552, 1203, 307, 1333, 295, 588, 12631, 293, 6063, 1333, 295, 38541, 2662, 299, 293, 50692], "temperature": 0.0, "avg_logprob": -0.13133949633465697, "compression_ratio": 1.868804664723032, "no_speech_prob": 0.005911329761147499}, {"id": 257, "seek": 92152, "start": 928.0799999999999, "end": 932.24, "text": " overlapping and you know a remarkable thing about GPT-4 is that", "tokens": [50692, 33535, 293, 291, 458, 257, 12802, 551, 466, 26039, 51, 12, 19, 307, 300, 50900], "temperature": 0.0, "avg_logprob": -0.13133949633465697, "compression_ratio": 1.868804664723032, "no_speech_prob": 0.005911329761147499}, {"id": 258, "seek": 92152, "start": 932.24, "end": 936.16, "text": " you know you often see people when they first they first use it they'll ask", "tokens": [50900, 291, 458, 291, 2049, 536, 561, 562, 436, 700, 436, 700, 764, 309, 436, 603, 1029, 51096], "temperature": 0.0, "avg_logprob": -0.13133949633465697, "compression_ratio": 1.868804664723032, "no_speech_prob": 0.005911329761147499}, {"id": 259, "seek": 92152, "start": 936.16, "end": 938.4, "text": " some question how tall is the Eiffel Tower and it probably gets the right", "tokens": [51096, 512, 1168, 577, 6764, 307, 264, 462, 3661, 338, 17877, 293, 309, 1391, 2170, 264, 558, 51208], "temperature": 0.0, "avg_logprob": -0.13133949633465697, "compression_ratio": 1.868804664723032, "no_speech_prob": 0.005911329761147499}, {"id": 260, "seek": 92152, "start": 938.4, "end": 941.6, "text": " answer and you know it's like oh that's kind of interesting and you're sort of", "tokens": [51208, 1867, 293, 291, 458, 309, 311, 411, 1954, 300, 311, 733, 295, 1880, 293, 291, 434, 1333, 295, 51368], "temperature": 0.0, "avg_logprob": -0.13133949633465697, "compression_ratio": 1.868804664723032, "no_speech_prob": 0.005911329761147499}, {"id": 261, "seek": 92152, "start": 941.6, "end": 944.48, "text": " a little bit disappointed in this technology but it's like being given", "tokens": [51368, 257, 707, 857, 13856, 294, 341, 2899, 457, 309, 311, 411, 885, 2212, 51512], "temperature": 0.0, "avg_logprob": -0.13133949633465697, "compression_ratio": 1.868804664723032, "no_speech_prob": 0.005911329761147499}, {"id": 262, "seek": 92152, "start": 944.48, "end": 948.0, "text": " the keys to a very expensive sports car and you notice the cup holders and you", "tokens": [51512, 264, 9317, 281, 257, 588, 5124, 6573, 1032, 293, 291, 3449, 264, 4414, 29274, 293, 291, 51688], "temperature": 0.0, "avg_logprob": -0.13133949633465697, "compression_ratio": 1.868804664723032, "no_speech_prob": 0.005911329761147499}, {"id": 263, "seek": 92152, "start": 948.0, "end": 950.8, "text": " notice that it can can support a cup rather nicely you don't realize you", "tokens": [51688, 3449, 300, 309, 393, 393, 1406, 257, 4414, 2831, 9594, 291, 500, 380, 4325, 291, 51828], "temperature": 0.0, "avg_logprob": -0.13133949633465697, "compression_ratio": 1.868804664723032, "no_speech_prob": 0.005911329761147499}, {"id": 264, "seek": 95080, "start": 950.8, "end": 953.68, "text": " need to start the engine and and drive off in it to really get the full", "tokens": [50364, 643, 281, 722, 264, 2848, 293, 293, 3332, 766, 294, 309, 281, 534, 483, 264, 1577, 50508], "temperature": 0.0, "avg_logprob": -0.08092717064751519, "compression_ratio": 1.8123076923076924, "no_speech_prob": 0.0005905429134145379}, {"id": 265, "seek": 95080, "start": 953.68, "end": 956.3199999999999, "text": " experience and so until you realize that actually you can you can have a", "tokens": [50508, 1752, 293, 370, 1826, 291, 4325, 300, 767, 291, 393, 291, 393, 362, 257, 50640], "temperature": 0.0, "avg_logprob": -0.08092717064751519, "compression_ratio": 1.8123076923076924, "no_speech_prob": 0.0005905429134145379}, {"id": 266, "seek": 95080, "start": 956.3199999999999, "end": 959.8399999999999, "text": " conversation it can it can write poetry it can explain jokes it can write code", "tokens": [50640, 3761, 309, 393, 309, 393, 2464, 15155, 309, 393, 2903, 14439, 309, 393, 2464, 3089, 50816], "temperature": 0.0, "avg_logprob": -0.08092717064751519, "compression_ratio": 1.8123076923076924, "no_speech_prob": 0.0005905429134145379}, {"id": 267, "seek": 95080, "start": 959.8399999999999, "end": 962.88, "text": " it can do so many many different things and that all those capabilities", "tokens": [50816, 309, 393, 360, 370, 867, 867, 819, 721, 293, 300, 439, 729, 10862, 50968], "temperature": 0.0, "avg_logprob": -0.08092717064751519, "compression_ratio": 1.8123076923076924, "no_speech_prob": 0.0005905429134145379}, {"id": 268, "seek": 95080, "start": 962.88, "end": 966.4, "text": " embedded in the same model and and what is I think a really interesting", "tokens": [50968, 16741, 294, 264, 912, 2316, 293, 293, 437, 307, 286, 519, 257, 534, 1880, 51144], "temperature": 0.0, "avg_logprob": -0.08092717064751519, "compression_ratio": 1.8123076923076924, "no_speech_prob": 0.0005905429134145379}, {"id": 269, "seek": 95080, "start": 966.4, "end": 970.9599999999999, "text": " lesson of the last few years is that models like GPT-4 outperform the", "tokens": [51144, 6898, 295, 264, 1036, 1326, 924, 307, 300, 5245, 411, 26039, 51, 12, 19, 484, 26765, 264, 51372], "temperature": 0.0, "avg_logprob": -0.08092717064751519, "compression_ratio": 1.8123076923076924, "no_speech_prob": 0.0005905429134145379}, {"id": 270, "seek": 95080, "start": 970.9599999999999, "end": 974.7199999999999, "text": " specialist models so for example in my lab we had a project for many years which", "tokens": [51372, 17008, 5245, 370, 337, 1365, 294, 452, 2715, 321, 632, 257, 1716, 337, 867, 924, 597, 51560], "temperature": 0.0, "avg_logprob": -0.08092717064751519, "compression_ratio": 1.8123076923076924, "no_speech_prob": 0.0005905429134145379}, {"id": 271, "seek": 95080, "start": 974.7199999999999, "end": 978.16, "text": " essentially said the following it said well you know this is Microsoft", "tokens": [51560, 4476, 848, 264, 3480, 309, 848, 731, 291, 458, 341, 307, 8116, 51732], "temperature": 0.0, "avg_logprob": -0.08092717064751519, "compression_ratio": 1.8123076923076924, "no_speech_prob": 0.0005905429134145379}, {"id": 272, "seek": 97816, "start": 978.24, "end": 981.4399999999999, "text": " world's biggest software company we have lots of source code we could use source", "tokens": [50368, 1002, 311, 3880, 4722, 2237, 321, 362, 3195, 295, 4009, 3089, 321, 727, 764, 4009, 50528], "temperature": 0.0, "avg_logprob": -0.09854050768100149, "compression_ratio": 1.9855595667870036, "no_speech_prob": 0.006721917074173689}, {"id": 273, "seek": 97816, "start": 981.4399999999999, "end": 984.88, "text": " code as training data for machine learning we've added all sorts of things you", "tokens": [50528, 3089, 382, 3097, 1412, 337, 3479, 2539, 321, 600, 3869, 439, 7527, 295, 721, 291, 50700], "temperature": 0.0, "avg_logprob": -0.09854050768100149, "compression_ratio": 1.9855595667870036, "no_speech_prob": 0.006721917074173689}, {"id": 274, "seek": 97816, "start": 984.88, "end": 988.56, "text": " know spot bugs do water complete you know all kinds of things you could do if", "tokens": [50700, 458, 4008, 15120, 360, 1281, 3566, 291, 458, 439, 3685, 295, 721, 291, 727, 360, 498, 50884], "temperature": 0.0, "avg_logprob": -0.09854050768100149, "compression_ratio": 1.9855595667870036, "no_speech_prob": 0.006721917074173689}, {"id": 275, "seek": 97816, "start": 988.56, "end": 992.3199999999999, "text": " you had a good model of source code and the project was reasonably successful it", "tokens": [50884, 291, 632, 257, 665, 2316, 295, 4009, 3089, 293, 264, 1716, 390, 23551, 4406, 309, 51072], "temperature": 0.0, "avg_logprob": -0.09854050768100149, "compression_ratio": 1.9855595667870036, "no_speech_prob": 0.006721917074173689}, {"id": 276, "seek": 97816, "start": 992.3199999999999, "end": 995.76, "text": " was you know it worked reasonably well but what we've learned is that when you", "tokens": [51072, 390, 291, 458, 309, 2732, 23551, 731, 457, 437, 321, 600, 3264, 307, 300, 562, 291, 51244], "temperature": 0.0, "avg_logprob": -0.09854050768100149, "compression_ratio": 1.9855595667870036, "no_speech_prob": 0.006721917074173689}, {"id": 277, "seek": 97816, "start": 995.76, "end": 1000.64, "text": " build one gigantic model that that yes it sees source code it sees scientific", "tokens": [51244, 1322, 472, 26800, 2316, 300, 300, 2086, 309, 8194, 4009, 3089, 309, 8194, 8134, 51488], "temperature": 0.0, "avg_logprob": -0.09854050768100149, "compression_ratio": 1.9855595667870036, "no_speech_prob": 0.006721917074173689}, {"id": 278, "seek": 97816, "start": 1000.64, "end": 1004.4, "text": " papers it sees wikipedia it sees many many different things in some way it", "tokens": [51488, 10577, 309, 8194, 261, 1035, 26633, 309, 8194, 867, 867, 819, 721, 294, 512, 636, 309, 51676], "temperature": 0.0, "avg_logprob": -0.09854050768100149, "compression_ratio": 1.9855595667870036, "no_speech_prob": 0.006721917074173689}, {"id": 279, "seek": 100440, "start": 1004.4, "end": 1008.48, "text": " becomes better at writing source code than a model specifically for writing", "tokens": [50364, 3643, 1101, 412, 3579, 4009, 3089, 813, 257, 2316, 4682, 337, 3579, 50568], "temperature": 0.0, "avg_logprob": -0.05973201245069504, "compression_ratio": 1.8745980707395498, "no_speech_prob": 0.0032475546468049288}, {"id": 280, "seek": 100440, "start": 1008.48, "end": 1012.4, "text": " source code and there are even even in ablation studies where people have a", "tokens": [50568, 4009, 3089, 293, 456, 366, 754, 754, 294, 410, 24278, 5313, 689, 561, 362, 257, 50764], "temperature": 0.0, "avg_logprob": -0.05973201245069504, "compression_ratio": 1.8745980707395498, "no_speech_prob": 0.0032475546468049288}, {"id": 281, "seek": 100440, "start": 1012.4, "end": 1015.52, "text": " model that's trained to solve maths problems and it does reasonably well", "tokens": [50764, 2316, 300, 311, 8895, 281, 5039, 36287, 2740, 293, 309, 775, 23551, 731, 50920], "temperature": 0.0, "avg_logprob": -0.05973201245069504, "compression_ratio": 1.8745980707395498, "no_speech_prob": 0.0032475546468049288}, {"id": 282, "seek": 100440, "start": 1015.52, "end": 1019.04, "text": " and now you give it some apparently irrelevant information let's say from", "tokens": [50920, 293, 586, 291, 976, 309, 512, 7970, 28682, 1589, 718, 311, 584, 490, 51096], "temperature": 0.0, "avg_logprob": -0.05973201245069504, "compression_ratio": 1.8745980707395498, "no_speech_prob": 0.0032475546468049288}, {"id": 283, "seek": 100440, "start": 1019.04, "end": 1022.4, "text": " wikipedia but with anything to do with maths stripped out and you find it", "tokens": [51096, 261, 1035, 26633, 457, 365, 1340, 281, 360, 365, 36287, 33221, 484, 293, 291, 915, 309, 51264], "temperature": 0.0, "avg_logprob": -0.05973201245069504, "compression_ratio": 1.8745980707395498, "no_speech_prob": 0.0032475546468049288}, {"id": 284, "seek": 100440, "start": 1022.4, "end": 1025.12, "text": " actually does better at the maths so I think there are things here that we", "tokens": [51264, 767, 775, 1101, 412, 264, 36287, 370, 286, 519, 456, 366, 721, 510, 300, 321, 51400], "temperature": 0.0, "avg_logprob": -0.05973201245069504, "compression_ratio": 1.8745980707395498, "no_speech_prob": 0.0032475546468049288}, {"id": 285, "seek": 100440, "start": 1025.12, "end": 1028.96, "text": " don't really understand but the general lesson I think is fairly clear", "tokens": [51400, 500, 380, 534, 1223, 457, 264, 2674, 6898, 286, 519, 307, 6457, 1850, 51592], "temperature": 0.0, "avg_logprob": -0.05973201245069504, "compression_ratio": 1.8745980707395498, "no_speech_prob": 0.0032475546468049288}, {"id": 286, "seek": 100440, "start": 1028.96, "end": 1032.72, "text": " that when you have a larger very general model it can outperform", "tokens": [51592, 300, 562, 291, 362, 257, 4833, 588, 2674, 2316, 309, 393, 484, 26765, 51780], "temperature": 0.0, "avg_logprob": -0.05973201245069504, "compression_ratio": 1.8745980707395498, "no_speech_prob": 0.0032475546468049288}, {"id": 287, "seek": 103272, "start": 1032.72, "end": 1036.32, "text": " a specific model which I think is very interesting I guess the reason I was", "tokens": [50364, 257, 2685, 2316, 597, 286, 519, 307, 588, 1880, 286, 2041, 264, 1778, 286, 390, 50544], "temperature": 0.0, "avg_logprob": -0.0702977357087312, "compression_ratio": 1.842911877394636, "no_speech_prob": 0.001087000360712409}, {"id": 288, "seek": 103272, "start": 1036.32, "end": 1040.32, "text": " talking about the no free lunch theorem is it feels to me as you say that", "tokens": [50544, 1417, 466, 264, 572, 1737, 6349, 20904, 307, 309, 3417, 281, 385, 382, 291, 584, 300, 50744], "temperature": 0.0, "avg_logprob": -0.0702977357087312, "compression_ratio": 1.842911877394636, "no_speech_prob": 0.001087000360712409}, {"id": 289, "seek": 103272, "start": 1040.32, "end": 1044.8, "text": " models behave quite differently in an input sensitive way", "tokens": [50744, 5245, 15158, 1596, 7614, 294, 364, 4846, 9477, 636, 50968], "temperature": 0.0, "avg_logprob": -0.0702977357087312, "compression_ratio": 1.842911877394636, "no_speech_prob": 0.001087000360712409}, {"id": 290, "seek": 103272, "start": 1044.8, "end": 1047.52, "text": " so you ask them about this particular thing and it's almost like it's a", "tokens": [50968, 370, 291, 1029, 552, 466, 341, 1729, 551, 293, 309, 311, 1920, 411, 309, 311, 257, 51104], "temperature": 0.0, "avg_logprob": -0.0702977357087312, "compression_ratio": 1.842911877394636, "no_speech_prob": 0.001087000360712409}, {"id": 291, "seek": 103272, "start": 1047.52, "end": 1051.2, "text": " different model because different parts of the model get activated", "tokens": [51104, 819, 2316, 570, 819, 3166, 295, 264, 2316, 483, 18157, 51288], "temperature": 0.0, "avg_logprob": -0.0702977357087312, "compression_ratio": 1.842911877394636, "no_speech_prob": 0.001087000360712409}, {"id": 292, "seek": 103272, "start": 1051.2, "end": 1055.92, "text": " and then there's this question of well is the no free lunch theorem violated", "tokens": [51288, 293, 550, 456, 311, 341, 1168, 295, 731, 307, 264, 572, 1737, 6349, 20904, 33239, 51524], "temperature": 0.0, "avg_logprob": -0.0702977357087312, "compression_ratio": 1.842911877394636, "no_speech_prob": 0.001087000360712409}, {"id": 293, "seek": 103272, "start": 1055.92, "end": 1059.84, "text": " can there be such a thing as a general foundational agent", "tokens": [51524, 393, 456, 312, 1270, 257, 551, 382, 257, 2674, 32195, 9461, 51720], "temperature": 0.0, "avg_logprob": -0.0702977357087312, "compression_ratio": 1.842911877394636, "no_speech_prob": 0.001087000360712409}, {"id": 294, "seek": 105984, "start": 1059.84, "end": 1064.56, "text": " that could in robotics just do really well in any game or any environment", "tokens": [50364, 300, 727, 294, 34145, 445, 360, 534, 731, 294, 604, 1216, 420, 604, 2823, 50600], "temperature": 0.0, "avg_logprob": -0.0915708343187968, "compression_ratio": 1.826271186440678, "no_speech_prob": 0.0028332718648016453}, {"id": 295, "seek": 105984, "start": 1064.56, "end": 1069.1999999999998, "text": " or do you think do you think there's still some need for specialization", "tokens": [50600, 420, 360, 291, 519, 360, 291, 519, 456, 311, 920, 512, 643, 337, 2121, 2144, 50832], "temperature": 0.0, "avg_logprob": -0.0915708343187968, "compression_ratio": 1.826271186440678, "no_speech_prob": 0.0028332718648016453}, {"id": 296, "seek": 105984, "start": 1069.1999999999998, "end": 1074.6399999999999, "text": " another great question so I think these really open research questions honestly", "tokens": [50832, 1071, 869, 1168, 370, 286, 519, 613, 534, 1269, 2132, 1651, 6095, 51104], "temperature": 0.0, "avg_logprob": -0.0915708343187968, "compression_ratio": 1.826271186440678, "no_speech_prob": 0.0028332718648016453}, {"id": 297, "seek": 105984, "start": 1074.6399999999999, "end": 1078.56, "text": " I'm not sure anybody really knows but I think one of the lessons is that the", "tokens": [51104, 286, 478, 406, 988, 4472, 534, 3255, 457, 286, 519, 472, 295, 264, 8820, 307, 300, 264, 51300], "temperature": 0.0, "avg_logprob": -0.0915708343187968, "compression_ratio": 1.826271186440678, "no_speech_prob": 0.0028332718648016453}, {"id": 298, "seek": 105984, "start": 1078.56, "end": 1082.1599999999999, "text": " general can be more powerful than the specific so clearly one of the research", "tokens": [51300, 2674, 393, 312, 544, 4005, 813, 264, 2685, 370, 4448, 472, 295, 264, 2132, 51480], "temperature": 0.0, "avg_logprob": -0.0915708343187968, "compression_ratio": 1.826271186440678, "no_speech_prob": 0.0028332718648016453}, {"id": 299, "seek": 105984, "start": 1082.1599999999999, "end": 1084.56, "text": " frontiers we should push on is greater and greater", "tokens": [51480, 1868, 4890, 321, 820, 2944, 322, 307, 5044, 293, 5044, 51600], "temperature": 0.0, "avg_logprob": -0.0915708343187968, "compression_ratio": 1.826271186440678, "no_speech_prob": 0.0028332718648016453}, {"id": 300, "seek": 108456, "start": 1085.52, "end": 1089.84, "text": " and see so you know GBT4 can't ride a bicycle but if we have models that can", "tokens": [50412, 293, 536, 370, 291, 458, 26809, 51, 19, 393, 380, 5077, 257, 20888, 457, 498, 321, 362, 5245, 300, 393, 50628], "temperature": 0.0, "avg_logprob": -0.11249363226968734, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.029120922088623047}, {"id": 301, "seek": 108456, "start": 1089.84, "end": 1093.04, "text": " can do robotics should they be separate and distinct models or if we somehow", "tokens": [50628, 393, 360, 34145, 820, 436, 312, 4994, 293, 10644, 5245, 420, 498, 321, 6063, 50788], "temperature": 0.0, "avg_logprob": -0.11249363226968734, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.029120922088623047}, {"id": 302, "seek": 108456, "start": 1093.04, "end": 1095.84, "text": " combined everything into a single model would it be more powerful", "tokens": [50788, 9354, 1203, 666, 257, 2167, 2316, 576, 309, 312, 544, 4005, 50928], "temperature": 0.0, "avg_logprob": -0.11249363226968734, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.029120922088623047}, {"id": 303, "seek": 108456, "start": 1095.84, "end": 1098.6399999999999, "text": " and there's a decent chance that the latter would be true that it would be", "tokens": [50928, 293, 456, 311, 257, 8681, 2931, 300, 264, 18481, 576, 312, 2074, 300, 309, 576, 312, 51068], "temperature": 0.0, "avg_logprob": -0.11249363226968734, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.029120922088623047}, {"id": 304, "seek": 108456, "start": 1098.6399999999999, "end": 1100.96, "text": " more powerful so certainly that's one research frontier", "tokens": [51068, 544, 4005, 370, 3297, 300, 311, 472, 2132, 35853, 51184], "temperature": 0.0, "avg_logprob": -0.11249363226968734, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.029120922088623047}, {"id": 305, "seek": 108456, "start": 1100.96, "end": 1104.6399999999999, "text": " we should push on an area I'm very interested in these days is", "tokens": [51184, 321, 820, 2944, 322, 364, 1859, 286, 478, 588, 3102, 294, 613, 1708, 307, 51368], "temperature": 0.0, "avg_logprob": -0.11249363226968734, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.029120922088623047}, {"id": 306, "seek": 108456, "start": 1104.6399999999999, "end": 1108.3999999999999, "text": " is deep learning for for science for scientific discovery and science", "tokens": [51368, 307, 2452, 2539, 337, 337, 3497, 337, 8134, 12114, 293, 3497, 51556], "temperature": 0.0, "avg_logprob": -0.11249363226968734, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.029120922088623047}, {"id": 307, "seek": 108456, "start": 1108.3999999999999, "end": 1112.48, "text": " amongst other things involves very precise detailed numerical calculations", "tokens": [51556, 12918, 661, 721, 11626, 588, 13600, 9942, 29054, 20448, 51760], "temperature": 0.0, "avg_logprob": -0.11249363226968734, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.029120922088623047}, {"id": 308, "seek": 111248, "start": 1112.48, "end": 1116.0, "text": " now if you want to multiply some numbers together GBT4 would be a terrible way of", "tokens": [50364, 586, 498, 291, 528, 281, 12972, 512, 3547, 1214, 26809, 51, 19, 576, 312, 257, 6237, 636, 295, 50540], "temperature": 0.0, "avg_logprob": -0.07769293081564982, "compression_ratio": 1.7641196013289036, "no_speech_prob": 0.0016599076334387064}, {"id": 309, "seek": 111248, "start": 1116.0, "end": 1118.56, "text": " doing it it might give you the wrong answer and even if it gets the right", "tokens": [50540, 884, 309, 309, 1062, 976, 291, 264, 2085, 1867, 293, 754, 498, 309, 2170, 264, 558, 50668], "temperature": 0.0, "avg_logprob": -0.07769293081564982, "compression_ratio": 1.7641196013289036, "no_speech_prob": 0.0016599076334387064}, {"id": 310, "seek": 111248, "start": 1118.56, "end": 1122.16, "text": " answer you're burning a tremendous amount of compute cycles to do something you", "tokens": [50668, 1867, 291, 434, 9488, 257, 10048, 2372, 295, 14722, 17796, 281, 360, 746, 291, 50848], "temperature": 0.0, "avg_logprob": -0.07769293081564982, "compression_ratio": 1.7641196013289036, "no_speech_prob": 0.0016599076334387064}, {"id": 311, "seek": 111248, "start": 1122.16, "end": 1124.96, "text": " could do with the far fewer compute cycles", "tokens": [50848, 727, 360, 365, 264, 1400, 13366, 14722, 17796, 50988], "temperature": 0.0, "avg_logprob": -0.07769293081564982, "compression_ratio": 1.7641196013289036, "no_speech_prob": 0.0016599076334387064}, {"id": 312, "seek": 111248, "start": 1124.96, "end": 1129.44, "text": " so there will still as far as I can see in certain domains be a role for", "tokens": [50988, 370, 456, 486, 920, 382, 1400, 382, 286, 393, 536, 294, 1629, 25514, 312, 257, 3090, 337, 51212], "temperature": 0.0, "avg_logprob": -0.07769293081564982, "compression_ratio": 1.7641196013289036, "no_speech_prob": 0.0016599076334387064}, {"id": 313, "seek": 111248, "start": 1129.44, "end": 1132.64, "text": " specialist models but even then I can see them being", "tokens": [51212, 17008, 5245, 457, 754, 550, 286, 393, 536, 552, 885, 51372], "temperature": 0.0, "avg_logprob": -0.07769293081564982, "compression_ratio": 1.7641196013289036, "no_speech_prob": 0.0016599076334387064}, {"id": 314, "seek": 111248, "start": 1132.64, "end": 1135.28, "text": " integrated with things like large language models", "tokens": [51372, 10919, 365, 721, 411, 2416, 2856, 5245, 51504], "temperature": 0.0, "avg_logprob": -0.07769293081564982, "compression_ratio": 1.7641196013289036, "no_speech_prob": 0.0016599076334387064}, {"id": 315, "seek": 111248, "start": 1135.28, "end": 1140.32, "text": " partly to provide human interface because one of the one of the things about", "tokens": [51504, 17031, 281, 2893, 1952, 9226, 570, 472, 295, 264, 472, 295, 264, 721, 466, 51756], "temperature": 0.0, "avg_logprob": -0.07769293081564982, "compression_ratio": 1.7641196013289036, "no_speech_prob": 0.0016599076334387064}, {"id": 316, "seek": 114032, "start": 1140.32, "end": 1143.36, "text": " language models is they they're so easy to interact with you don't have to be a", "tokens": [50364, 2856, 5245, 307, 436, 436, 434, 370, 1858, 281, 4648, 365, 291, 500, 380, 362, 281, 312, 257, 50516], "temperature": 0.0, "avg_logprob": -0.07748361556760726, "compression_ratio": 1.9319727891156462, "no_speech_prob": 0.001739677507430315}, {"id": 317, "seek": 114032, "start": 1143.36, "end": 1146.48, "text": " computer program you just have a a natural conversation with them", "tokens": [50516, 3820, 1461, 291, 445, 362, 257, 257, 3303, 3761, 365, 552, 50672], "temperature": 0.0, "avg_logprob": -0.07748361556760726, "compression_ratio": 1.9319727891156462, "no_speech_prob": 0.001739677507430315}, {"id": 318, "seek": 114032, "start": 1146.48, "end": 1150.72, "text": " but also the other remarkable thing about the large language models", "tokens": [50672, 457, 611, 264, 661, 12802, 551, 466, 264, 2416, 2856, 5245, 50884], "temperature": 0.0, "avg_logprob": -0.07748361556760726, "compression_ratio": 1.9319727891156462, "no_speech_prob": 0.001739677507430315}, {"id": 319, "seek": 114032, "start": 1150.72, "end": 1153.52, "text": " I think there are two remarkable things the first of all is that they're so good", "tokens": [50884, 286, 519, 456, 366, 732, 12802, 721, 264, 700, 295, 439, 307, 300, 436, 434, 370, 665, 51024], "temperature": 0.0, "avg_logprob": -0.07748361556760726, "compression_ratio": 1.9319727891156462, "no_speech_prob": 0.001739677507430315}, {"id": 320, "seek": 114032, "start": 1153.52, "end": 1156.8, "text": " at human language maybe that's not too surprising because they're sort of", "tokens": [51024, 412, 1952, 2856, 1310, 300, 311, 406, 886, 8830, 570, 436, 434, 1333, 295, 51188], "temperature": 0.0, "avg_logprob": -0.07748361556760726, "compression_ratio": 1.9319727891156462, "no_speech_prob": 0.001739677507430315}, {"id": 321, "seek": 114032, "start": 1156.8, "end": 1161.84, "text": " designed to do that but by virtue of being forced to", "tokens": [51188, 4761, 281, 360, 300, 457, 538, 20816, 295, 885, 7579, 281, 51440], "temperature": 0.0, "avg_logprob": -0.07748361556760726, "compression_ratio": 1.9319727891156462, "no_speech_prob": 0.001739677507430315}, {"id": 322, "seek": 114032, "start": 1161.84, "end": 1165.9199999999998, "text": " effectively compress human language they become reasoning engines and that's a", "tokens": [51440, 8659, 14778, 1952, 2856, 436, 1813, 21577, 12982, 293, 300, 311, 257, 51644], "temperature": 0.0, "avg_logprob": -0.07748361556760726, "compression_ratio": 1.9319727891156462, "no_speech_prob": 0.001739677507430315}, {"id": 323, "seek": 114032, "start": 1165.9199999999998, "end": 1169.6, "text": " remarkable discovery right that is a big surprise certainly to me I", "tokens": [51644, 12802, 12114, 558, 300, 307, 257, 955, 6365, 3297, 281, 385, 286, 51828], "temperature": 0.0, "avg_logprob": -0.07748361556760726, "compression_ratio": 1.9319727891156462, "no_speech_prob": 0.001739677507430315}, {"id": 324, "seek": 116960, "start": 1169.6, "end": 1172.0, "text": " think to many people perhaps to everybody in the field", "tokens": [50364, 519, 281, 867, 561, 4317, 281, 2201, 294, 264, 2519, 50484], "temperature": 0.0, "avg_logprob": -0.09457152598613017, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0005260143079794943}, {"id": 325, "seek": 116960, "start": 1172.0, "end": 1175.6, "text": " that they can function as reasoning engines and so even if you're", "tokens": [50484, 300, 436, 393, 2445, 382, 21577, 12982, 293, 370, 754, 498, 291, 434, 50664], "temperature": 0.0, "avg_logprob": -0.09457152598613017, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0005260143079794943}, {"id": 326, "seek": 116960, "start": 1175.6, "end": 1178.9599999999998, "text": " let's say doing some specialist scientific calculations you might still", "tokens": [50664, 718, 311, 584, 884, 512, 17008, 8134, 20448, 291, 1062, 920, 50832], "temperature": 0.0, "avg_logprob": -0.09457152598613017, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0005260143079794943}, {"id": 327, "seek": 116960, "start": 1178.9599999999998, "end": 1183.12, "text": " think about a large language model as as a kind of a", "tokens": [50832, 519, 466, 257, 2416, 2856, 2316, 382, 382, 257, 733, 295, 257, 51040], "temperature": 0.0, "avg_logprob": -0.09457152598613017, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0005260143079794943}, {"id": 328, "seek": 116960, "start": 1183.12, "end": 1186.56, "text": " co-pilot for the scientist helping the scientist reason over", "tokens": [51040, 598, 12, 79, 31516, 337, 264, 12662, 4315, 264, 12662, 1778, 670, 51212], "temperature": 0.0, "avg_logprob": -0.09457152598613017, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0005260143079794943}, {"id": 329, "seek": 116960, "start": 1186.56, "end": 1191.12, "text": " what increasingly consists of massive massively complex spaces", "tokens": [51212, 437, 12980, 14689, 295, 5994, 29379, 3997, 7673, 51440], "temperature": 0.0, "avg_logprob": -0.09457152598613017, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0005260143079794943}, {"id": 330, "seek": 116960, "start": 1191.12, "end": 1194.08, "text": " very high dimensionality many different modalities of data", "tokens": [51440, 588, 1090, 10139, 1860, 867, 819, 1072, 16110, 295, 1412, 51588], "temperature": 0.0, "avg_logprob": -0.09457152598613017, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0005260143079794943}, {"id": 331, "seek": 116960, "start": 1194.08, "end": 1196.9599999999998, "text": " it's harder and harder for humans to sort of wrap their head around this and this", "tokens": [51588, 309, 311, 6081, 293, 6081, 337, 6255, 281, 1333, 295, 7019, 641, 1378, 926, 341, 293, 341, 51732], "temperature": 0.0, "avg_logprob": -0.09457152598613017, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0005260143079794943}, {"id": 332, "seek": 119696, "start": 1196.96, "end": 1200.48, "text": " is where I think a large language model can can can be valuable", "tokens": [50364, 307, 689, 286, 519, 257, 2416, 2856, 2316, 393, 393, 393, 312, 8263, 50540], "temperature": 0.0, "avg_logprob": -0.09105721731034536, "compression_ratio": 1.9055944055944056, "no_speech_prob": 0.0008896931540220976}, {"id": 333, "seek": 119696, "start": 1200.48, "end": 1203.68, "text": " but I still see it calling on specialist tools in the foreseeable future", "tokens": [50540, 457, 286, 920, 536, 309, 5141, 322, 17008, 3873, 294, 264, 38736, 712, 2027, 50700], "temperature": 0.0, "avg_logprob": -0.09105721731034536, "compression_ratio": 1.9055944055944056, "no_speech_prob": 0.0008896931540220976}, {"id": 334, "seek": 119696, "start": 1203.68, "end": 1206.8, "text": " because you were talking about statistical generalization but you could", "tokens": [50700, 570, 291, 645, 1417, 466, 22820, 2674, 2144, 457, 291, 727, 50856], "temperature": 0.0, "avg_logprob": -0.09105721731034536, "compression_ratio": 1.9055944055944056, "no_speech_prob": 0.0008896931540220976}, {"id": 335, "seek": 119696, "start": 1206.8, "end": 1210.8, "text": " argue that language models can't do let's say they can't compute the", "tokens": [50856, 9695, 300, 2856, 5245, 393, 380, 360, 718, 311, 584, 436, 393, 380, 14722, 264, 51056], "temperature": 0.0, "avg_logprob": -0.09105721731034536, "compression_ratio": 1.9055944055944056, "no_speech_prob": 0.0008896931540220976}, {"id": 336, "seek": 119696, "start": 1210.8, "end": 1213.92, "text": " nth digit of pi because they don't have an expandable memory they're not", "tokens": [51056, 297, 392, 14293, 295, 3895, 570, 436, 500, 380, 362, 364, 5268, 712, 4675, 436, 434, 406, 51212], "temperature": 0.0, "avg_logprob": -0.09105721731034536, "compression_ratio": 1.9055944055944056, "no_speech_prob": 0.0008896931540220976}, {"id": 337, "seek": 119696, "start": 1213.92, "end": 1216.56, "text": " Turing machine so that that's a computational limitation but", "tokens": [51212, 314, 1345, 3479, 370, 300, 300, 311, 257, 28270, 27432, 457, 51344], "temperature": 0.0, "avg_logprob": -0.09105721731034536, "compression_ratio": 1.9055944055944056, "no_speech_prob": 0.0008896931540220976}, {"id": 338, "seek": 119696, "start": 1216.56, "end": 1219.68, "text": " but they might be able to do this statistical generalization", "tokens": [51344, 457, 436, 1062, 312, 1075, 281, 360, 341, 22820, 2674, 2144, 51500], "temperature": 0.0, "avg_logprob": -0.09105721731034536, "compression_ratio": 1.9055944055944056, "no_speech_prob": 0.0008896931540220976}, {"id": 339, "seek": 119696, "start": 1219.68, "end": 1223.44, "text": " as we were talking about even though it might in fact be a weird form of", "tokens": [51500, 382, 321, 645, 1417, 466, 754, 1673, 309, 1062, 294, 1186, 312, 257, 3657, 1254, 295, 51688], "temperature": 0.0, "avg_logprob": -0.09105721731034536, "compression_ratio": 1.9055944055944056, "no_speech_prob": 0.0008896931540220976}, {"id": 340, "seek": 122344, "start": 1223.44, "end": 1228.24, "text": " specialization in terms of an ensemble of methods of models inside", "tokens": [50364, 2121, 2144, 294, 2115, 295, 364, 19492, 295, 7150, 295, 5245, 1854, 50604], "temperature": 0.0, "avg_logprob": -0.10588024059931438, "compression_ratio": 1.8111587982832618, "no_speech_prob": 0.003949995618313551}, {"id": 341, "seek": 122344, "start": 1228.24, "end": 1231.3600000000001, "text": " a large language model but on the on the language thing and the reasoning this", "tokens": [50604, 257, 2416, 2856, 2316, 457, 322, 264, 322, 264, 2856, 551, 293, 264, 21577, 341, 50760], "temperature": 0.0, "avg_logprob": -0.10588024059931438, "compression_ratio": 1.8111587982832618, "no_speech_prob": 0.003949995618313551}, {"id": 342, "seek": 122344, "start": 1231.3600000000001, "end": 1235.1200000000001, "text": " this is fascinating so I think that language", "tokens": [50760, 341, 307, 10343, 370, 286, 519, 300, 2856, 50948], "temperature": 0.0, "avg_logprob": -0.10588024059931438, "compression_ratio": 1.8111587982832618, "no_speech_prob": 0.003949995618313551}, {"id": 343, "seek": 122344, "start": 1235.1200000000001, "end": 1239.1200000000001, "text": " is a bunch of memetically embedded programs", "tokens": [50948, 307, 257, 3840, 295, 1334, 22652, 16741, 4268, 51148], "temperature": 0.0, "avg_logprob": -0.10588024059931438, "compression_ratio": 1.8111587982832618, "no_speech_prob": 0.003949995618313551}, {"id": 344, "seek": 122344, "start": 1239.1200000000001, "end": 1244.48, "text": " so we we play the language game and we establish cognitive categories we", "tokens": [51148, 370, 321, 321, 862, 264, 2856, 1216, 293, 321, 8327, 15605, 10479, 321, 51416], "temperature": 0.0, "avg_logprob": -0.10588024059931438, "compression_ratio": 1.8111587982832618, "no_speech_prob": 0.003949995618313551}, {"id": 345, "seek": 122344, "start": 1244.48, "end": 1246.56, "text": " embed them and share them socially and it's like", "tokens": [51416, 12240, 552, 293, 2073, 552, 21397, 293, 309, 311, 411, 51520], "temperature": 0.0, "avg_logprob": -0.10588024059931438, "compression_ratio": 1.8111587982832618, "no_speech_prob": 0.003949995618313551}, {"id": 346, "seek": 122344, "start": 1246.56, "end": 1249.68, "text": " there's a little simulation out there and I'm using that to think", "tokens": [51520, 456, 311, 257, 707, 16575, 484, 456, 293, 286, 478, 1228, 300, 281, 519, 51676], "temperature": 0.0, "avg_logprob": -0.10588024059931438, "compression_ratio": 1.8111587982832618, "no_speech_prob": 0.003949995618313551}, {"id": 347, "seek": 124968, "start": 1249.68, "end": 1252.64, "text": " but the question always is to what extent", "tokens": [50364, 457, 264, 1168, 1009, 307, 281, 437, 8396, 50512], "temperature": 0.0, "avg_logprob": -0.0945597084201112, "compression_ratio": 1.8432601880877744, "no_speech_prob": 0.001942325267009437}, {"id": 348, "seek": 124968, "start": 1252.64, "end": 1256.96, "text": " and is that that's a bunch of processing that previous humans have done", "tokens": [50512, 293, 307, 300, 300, 311, 257, 3840, 295, 9007, 300, 3894, 6255, 362, 1096, 50728], "temperature": 0.0, "avg_logprob": -0.0945597084201112, "compression_ratio": 1.8432601880877744, "no_speech_prob": 0.001942325267009437}, {"id": 349, "seek": 124968, "start": 1256.96, "end": 1260.48, "text": " and we can use it but can the language model create", "tokens": [50728, 293, 321, 393, 764, 309, 457, 393, 264, 2856, 2316, 1884, 50904], "temperature": 0.0, "avg_logprob": -0.0945597084201112, "compression_ratio": 1.8432601880877744, "no_speech_prob": 0.001942325267009437}, {"id": 350, "seek": 124968, "start": 1260.48, "end": 1264.4, "text": " new programs like that this is I think part of a fascinating and broader", "tokens": [50904, 777, 4268, 411, 300, 341, 307, 286, 519, 644, 295, 257, 10343, 293, 13227, 51100], "temperature": 0.0, "avg_logprob": -0.0945597084201112, "compression_ratio": 1.8432601880877744, "no_speech_prob": 0.001942325267009437}, {"id": 351, "seek": 124968, "start": 1264.4, "end": 1268.16, "text": " discussion so I do hear a lot of oh it can't do x y and z", "tokens": [51100, 5017, 370, 286, 360, 1568, 257, 688, 295, 1954, 309, 393, 380, 360, 2031, 288, 293, 710, 51288], "temperature": 0.0, "avg_logprob": -0.0945597084201112, "compression_ratio": 1.8432601880877744, "no_speech_prob": 0.001942325267009437}, {"id": 352, "seek": 124968, "start": 1268.16, "end": 1271.1200000000001, "text": " often that's true and I've always put the word yet at the end of it because I", "tokens": [51288, 2049, 300, 311, 2074, 293, 286, 600, 1009, 829, 264, 1349, 1939, 412, 264, 917, 295, 309, 570, 286, 51436], "temperature": 0.0, "avg_logprob": -0.0945597084201112, "compression_ratio": 1.8432601880877744, "no_speech_prob": 0.001942325267009437}, {"id": 353, "seek": 124968, "start": 1271.1200000000001, "end": 1273.6000000000001, "text": " don't know any law or physics and it can't do certain there are some things", "tokens": [51436, 500, 380, 458, 604, 2101, 420, 10649, 293, 309, 393, 380, 360, 1629, 456, 366, 512, 721, 51560], "temperature": 0.0, "avg_logprob": -0.0945597084201112, "compression_ratio": 1.8432601880877744, "no_speech_prob": 0.001942325267009437}, {"id": 354, "seek": 124968, "start": 1273.6000000000001, "end": 1276.3200000000002, "text": " which perhaps the current architectures provably can't do", "tokens": [51560, 597, 4317, 264, 2190, 6331, 1303, 1439, 1188, 393, 380, 360, 51696], "temperature": 0.0, "avg_logprob": -0.0945597084201112, "compression_ratio": 1.8432601880877744, "no_speech_prob": 0.001942325267009437}, {"id": 355, "seek": 124968, "start": 1276.3200000000002, "end": 1279.3600000000001, "text": " but but there's lots of exploration in different architectures there's a lot of", "tokens": [51696, 457, 457, 456, 311, 3195, 295, 16197, 294, 819, 6331, 1303, 456, 311, 257, 688, 295, 51848], "temperature": 0.0, "avg_logprob": -0.0945597084201112, "compression_ratio": 1.8432601880877744, "no_speech_prob": 0.001942325267009437}, {"id": 356, "seek": 127936, "start": 1279.36, "end": 1282.3999999999999, "text": " scope for for for expanding and generalizing neural net so I", "tokens": [50364, 11923, 337, 337, 337, 14702, 293, 2674, 3319, 18161, 2533, 370, 286, 50516], "temperature": 0.0, "avg_logprob": -0.10379631100720121, "compression_ratio": 1.9770992366412214, "no_speech_prob": 0.0016619852976873517}, {"id": 357, "seek": 127936, "start": 1282.3999999999999, "end": 1284.8, "text": " always think of it can't do a certain thing yet", "tokens": [50516, 1009, 519, 295, 309, 393, 380, 360, 257, 1629, 551, 1939, 50636], "temperature": 0.0, "avg_logprob": -0.10379631100720121, "compression_ratio": 1.9770992366412214, "no_speech_prob": 0.0016619852976873517}, {"id": 358, "seek": 127936, "start": 1284.8, "end": 1288.4799999999998, "text": " but a lot of the questions or a lot of the comments about", "tokens": [50636, 457, 257, 688, 295, 264, 1651, 420, 257, 688, 295, 264, 3053, 466, 50820], "temperature": 0.0, "avg_logprob": -0.10379631100720121, "compression_ratio": 1.9770992366412214, "no_speech_prob": 0.0016619852976873517}, {"id": 359, "seek": 127936, "start": 1288.4799999999998, "end": 1292.6399999999999, "text": " the limitations of models I have a have a hypothesis on this I mean", "tokens": [50820, 264, 15705, 295, 5245, 286, 362, 257, 362, 257, 17291, 322, 341, 286, 914, 51028], "temperature": 0.0, "avg_logprob": -0.10379631100720121, "compression_ratio": 1.9770992366412214, "no_speech_prob": 0.0016619852976873517}, {"id": 360, "seek": 127936, "start": 1292.6399999999999, "end": 1296.0, "text": " let me test this out on you I may be I may be way shorter the mark on this one", "tokens": [51028, 718, 385, 1500, 341, 484, 322, 291, 286, 815, 312, 286, 815, 312, 636, 11639, 264, 1491, 322, 341, 472, 51196], "temperature": 0.0, "avg_logprob": -0.10379631100720121, "compression_ratio": 1.9770992366412214, "no_speech_prob": 0.0016619852976873517}, {"id": 361, "seek": 127936, "start": 1296.0, "end": 1299.52, "text": " but a lot of the a lot of the critique of what models", "tokens": [51196, 457, 257, 688, 295, 264, 257, 688, 295, 264, 25673, 295, 437, 5245, 51372], "temperature": 0.0, "avg_logprob": -0.10379631100720121, "compression_ratio": 1.9770992366412214, "no_speech_prob": 0.0016619852976873517}, {"id": 362, "seek": 127936, "start": 1299.52, "end": 1303.6, "text": " seemingly can't do or especially when it's oh they will never be able to do this", "tokens": [51372, 18709, 393, 380, 360, 420, 2318, 562, 309, 311, 1954, 436, 486, 1128, 312, 1075, 281, 360, 341, 51576], "temperature": 0.0, "avg_logprob": -0.10379631100720121, "compression_ratio": 1.9770992366412214, "no_speech_prob": 0.0016619852976873517}, {"id": 363, "seek": 127936, "start": 1303.6, "end": 1307.12, "text": " they cannot be creative or they cannot reason or they cannot whatever", "tokens": [51576, 436, 2644, 312, 5880, 420, 436, 2644, 1778, 420, 436, 2644, 2035, 51752], "temperature": 0.0, "avg_logprob": -0.10379631100720121, "compression_ratio": 1.9770992366412214, "no_speech_prob": 0.0016619852976873517}, {"id": 364, "seek": 130712, "start": 1307.1999999999998, "end": 1311.36, "text": " I wonder if a lot of this comes to to a much more fundamental point that's not", "tokens": [50368, 286, 2441, 498, 257, 688, 295, 341, 1487, 281, 281, 257, 709, 544, 8088, 935, 300, 311, 406, 50576], "temperature": 0.0, "avg_logprob": -0.10521413984089872, "compression_ratio": 1.8950617283950617, "no_speech_prob": 0.0008209405350498855}, {"id": 365, "seek": 130712, "start": 1311.36, "end": 1313.6, "text": " actually a technical one it's really to do with the human", "tokens": [50576, 767, 257, 6191, 472, 309, 311, 534, 281, 360, 365, 264, 1952, 50688], "temperature": 0.0, "avg_logprob": -0.10521413984089872, "compression_ratio": 1.8950617283950617, "no_speech_prob": 0.0008209405350498855}, {"id": 366, "seek": 130712, "start": 1313.6, "end": 1316.7199999999998, "text": " the human journey over the last few thousand years because we've", "tokens": [50688, 264, 1952, 4671, 670, 264, 1036, 1326, 4714, 924, 570, 321, 600, 50844], "temperature": 0.0, "avg_logprob": -0.10521413984089872, "compression_ratio": 1.8950617283950617, "no_speech_prob": 0.0008209405350498855}, {"id": 367, "seek": 130712, "start": 1316.7199999999998, "end": 1320.08, "text": " you know a few thousand years ago I guess most humans would have perceived", "tokens": [50844, 291, 458, 257, 1326, 4714, 924, 2057, 286, 2041, 881, 6255, 576, 362, 19049, 51012], "temperature": 0.0, "avg_logprob": -0.10521413984089872, "compression_ratio": 1.8950617283950617, "no_speech_prob": 0.0008209405350498855}, {"id": 368, "seek": 130712, "start": 1320.08, "end": 1322.6399999999999, "text": " humanity as the center of the universe they were the earth's center of the", "tokens": [51012, 10243, 382, 264, 3056, 295, 264, 6445, 436, 645, 264, 4120, 311, 3056, 295, 264, 51140], "temperature": 0.0, "avg_logprob": -0.10521413984089872, "compression_ratio": 1.8950617283950617, "no_speech_prob": 0.0008209405350498855}, {"id": 369, "seek": 130712, "start": 1322.6399999999999, "end": 1326.0, "text": " universe the universe was created for the benefit of humanity", "tokens": [51140, 6445, 264, 6445, 390, 2942, 337, 264, 5121, 295, 10243, 51308], "temperature": 0.0, "avg_logprob": -0.10521413984089872, "compression_ratio": 1.8950617283950617, "no_speech_prob": 0.0008209405350498855}, {"id": 370, "seek": 130712, "start": 1326.0, "end": 1329.1999999999998, "text": " we had this very arrogant view of our own importance and what we've learned over", "tokens": [51308, 321, 632, 341, 588, 30467, 1910, 295, 527, 1065, 7379, 293, 437, 321, 600, 3264, 670, 51468], "temperature": 0.0, "avg_logprob": -0.10521413984089872, "compression_ratio": 1.8950617283950617, "no_speech_prob": 0.0008209405350498855}, {"id": 371, "seek": 130712, "start": 1329.1999999999998, "end": 1331.6799999999998, "text": " the centuries especially from fields like astronomy", "tokens": [51468, 264, 13926, 2318, 490, 7909, 411, 37844, 51592], "temperature": 0.0, "avg_logprob": -0.10521413984089872, "compression_ratio": 1.8950617283950617, "no_speech_prob": 0.0008209405350498855}, {"id": 372, "seek": 130712, "start": 1331.6799999999998, "end": 1335.52, "text": " is of course you know that the the entirety of humanity's existence", "tokens": [51592, 307, 295, 1164, 291, 458, 300, 264, 264, 31557, 295, 10243, 311, 9123, 51784], "temperature": 0.0, "avg_logprob": -0.10521413984089872, "compression_ratio": 1.8950617283950617, "no_speech_prob": 0.0008209405350498855}, {"id": 373, "seek": 133552, "start": 1335.52, "end": 1339.76, "text": " is a brief blink of the eye compared to the distance of the the whole universe", "tokens": [50364, 307, 257, 5353, 24667, 295, 264, 3313, 5347, 281, 264, 4560, 295, 264, 264, 1379, 6445, 50576], "temperature": 0.0, "avg_logprob": -0.09067435013620477, "compression_ratio": 1.8642384105960266, "no_speech_prob": 0.0017915028147399426}, {"id": 374, "seek": 133552, "start": 1339.76, "end": 1342.96, "text": " and and our physical place in the universe in terms of length scale we're on a", "tokens": [50576, 293, 293, 527, 4001, 1081, 294, 264, 6445, 294, 2115, 295, 4641, 4373, 321, 434, 322, 257, 50736], "temperature": 0.0, "avg_logprob": -0.09067435013620477, "compression_ratio": 1.8642384105960266, "no_speech_prob": 0.0017915028147399426}, {"id": 375, "seek": 133552, "start": 1342.96, "end": 1345.76, "text": " little speck of dust orbiting an insignificant star in a rather boring", "tokens": [50736, 707, 768, 547, 295, 8634, 48985, 364, 43685, 3543, 294, 257, 2831, 9989, 50876], "temperature": 0.0, "avg_logprob": -0.09067435013620477, "compression_ratio": 1.8642384105960266, "no_speech_prob": 0.0017915028147399426}, {"id": 376, "seek": 133552, "start": 1345.76, "end": 1350.16, "text": " galaxy in this colossal universe and and so I think it's natural for us as", "tokens": [50876, 17639, 294, 341, 48683, 304, 6445, 293, 293, 370, 286, 519, 309, 311, 3303, 337, 505, 382, 51096], "temperature": 0.0, "avg_logprob": -0.09067435013620477, "compression_ratio": 1.8642384105960266, "no_speech_prob": 0.0017915028147399426}, {"id": 377, "seek": 133552, "start": 1350.16, "end": 1353.84, "text": " humans to sort of continue to cling to the things that we feel make us special", "tokens": [51096, 6255, 281, 1333, 295, 2354, 281, 35986, 281, 264, 721, 300, 321, 841, 652, 505, 2121, 51280], "temperature": 0.0, "avg_logprob": -0.09067435013620477, "compression_ratio": 1.8642384105960266, "no_speech_prob": 0.0017915028147399426}, {"id": 378, "seek": 133552, "start": 1353.84, "end": 1356.08, "text": " and we're certainly not the fastest creatures on earth we're not the", "tokens": [51280, 293, 321, 434, 3297, 406, 264, 14573, 12281, 322, 4120, 321, 434, 406, 264, 51392], "temperature": 0.0, "avg_logprob": -0.09067435013620477, "compression_ratio": 1.8642384105960266, "no_speech_prob": 0.0017915028147399426}, {"id": 379, "seek": 133552, "start": 1356.08, "end": 1358.72, "text": " strongest but it's our brains that seem to make us", "tokens": [51392, 16595, 457, 309, 311, 527, 15442, 300, 1643, 281, 652, 505, 51524], "temperature": 0.0, "avg_logprob": -0.09067435013620477, "compression_ratio": 1.8642384105960266, "no_speech_prob": 0.0017915028147399426}, {"id": 380, "seek": 133552, "start": 1358.72, "end": 1362.08, "text": " unique we are the most intelligent creatures by far on earth", "tokens": [51524, 3845, 321, 366, 264, 881, 13232, 12281, 538, 1400, 322, 4120, 51692], "temperature": 0.0, "avg_logprob": -0.09067435013620477, "compression_ratio": 1.8642384105960266, "no_speech_prob": 0.0017915028147399426}, {"id": 381, "seek": 136208, "start": 1362.08, "end": 1365.4399999999998, "text": " and so we think of our of our intelligence as being the very special", "tokens": [50364, 293, 370, 321, 519, 295, 527, 295, 527, 7599, 382, 885, 264, 588, 2121, 50532], "temperature": 0.0, "avg_logprob": -0.09234116353145262, "compression_ratio": 1.7087087087087087, "no_speech_prob": 0.0006809884798713028}, {"id": 382, "seek": 136208, "start": 1365.4399999999998, "end": 1367.84, "text": " thing yes okay we get it that we're just living in a", "tokens": [50532, 551, 2086, 1392, 321, 483, 309, 300, 321, 434, 445, 2647, 294, 257, 50652], "temperature": 0.0, "avg_logprob": -0.09234116353145262, "compression_ratio": 1.7087087087087087, "no_speech_prob": 0.0006809884798713028}, {"id": 383, "seek": 136208, "start": 1367.84, "end": 1370.8, "text": " sporing corner of the universe but nevertheless it's our brains that make", "tokens": [50652, 637, 3662, 4538, 295, 264, 6445, 457, 26924, 309, 311, 527, 15442, 300, 652, 50800], "temperature": 0.0, "avg_logprob": -0.09234116353145262, "compression_ratio": 1.7087087087087087, "no_speech_prob": 0.0006809884798713028}, {"id": 384, "seek": 136208, "start": 1370.8, "end": 1374.08, "text": " us special so let me tell you a little story which is", "tokens": [50800, 505, 2121, 370, 718, 385, 980, 291, 257, 707, 1657, 597, 307, 50964], "temperature": 0.0, "avg_logprob": -0.09234116353145262, "compression_ratio": 1.7087087087087087, "no_speech_prob": 0.0006809884798713028}, {"id": 385, "seek": 136208, "start": 1374.08, "end": 1377.04, "text": " because I work for Microsoft I was very privileged to have early access to", "tokens": [50964, 570, 286, 589, 337, 8116, 286, 390, 588, 25293, 281, 362, 2440, 2105, 281, 51112], "temperature": 0.0, "avg_logprob": -0.09234116353145262, "compression_ratio": 1.7087087087087087, "no_speech_prob": 0.0006809884798713028}, {"id": 386, "seek": 136208, "start": 1377.04, "end": 1380.3999999999999, "text": " GPT-4 and it was still a highly-tented highly-secret", "tokens": [51112, 26039, 51, 12, 19, 293, 309, 390, 920, 257, 5405, 12, 83, 317, 292, 5405, 12, 8159, 1505, 51280], "temperature": 0.0, "avg_logprob": -0.09234116353145262, "compression_ratio": 1.7087087087087087, "no_speech_prob": 0.0006809884798713028}, {"id": 387, "seek": 136208, "start": 1380.3999999999999, "end": 1384.8799999999999, "text": " project and so I was exposed to GPT-4 at a time when", "tokens": [51280, 1716, 293, 370, 286, 390, 9495, 281, 26039, 51, 12, 19, 412, 257, 565, 562, 51504], "temperature": 0.0, "avg_logprob": -0.09234116353145262, "compression_ratio": 1.7087087087087087, "no_speech_prob": 0.0006809884798713028}, {"id": 388, "seek": 136208, "start": 1384.8799999999999, "end": 1388.1599999999999, "text": " I could only discuss it with a very small number of very specific colleagues", "tokens": [51504, 286, 727, 787, 2248, 309, 365, 257, 588, 1359, 1230, 295, 588, 2685, 7734, 51668], "temperature": 0.0, "avg_logprob": -0.09234116353145262, "compression_ratio": 1.7087087087087087, "no_speech_prob": 0.0006809884798713028}, {"id": 389, "seek": 136208, "start": 1388.1599999999999, "end": 1390.8799999999999, "text": " and for everybody else I couldn't couldn't even talk about it", "tokens": [51668, 293, 337, 2201, 1646, 286, 2809, 380, 2809, 380, 754, 751, 466, 309, 51804], "temperature": 0.0, "avg_logprob": -0.09234116353145262, "compression_ratio": 1.7087087087087087, "no_speech_prob": 0.0006809884798713028}, {"id": 390, "seek": 139088, "start": 1390.88, "end": 1396.0800000000002, "text": " and it was quite a shocking moment the the ability to", "tokens": [50364, 293, 309, 390, 1596, 257, 18776, 1623, 264, 264, 3485, 281, 50624], "temperature": 0.0, "avg_logprob": -0.11849888350612434, "compression_ratio": 1.66875, "no_speech_prob": 0.001897014444693923}, {"id": 391, "seek": 139088, "start": 1396.0800000000002, "end": 1399.68, "text": " understand and generate language sort of didn't come as so much of a surprise", "tokens": [50624, 1223, 293, 8460, 2856, 1333, 295, 994, 380, 808, 382, 370, 709, 295, 257, 6365, 50804], "temperature": 0.0, "avg_logprob": -0.11849888350612434, "compression_ratio": 1.66875, "no_speech_prob": 0.001897014444693923}, {"id": 392, "seek": 139088, "start": 1399.68, "end": 1402.72, "text": " because of course I'd been following GPT-2 and GPT-3 and", "tokens": [50804, 570, 295, 1164, 286, 1116, 668, 3480, 26039, 51, 12, 17, 293, 26039, 51, 12, 18, 293, 50956], "temperature": 0.0, "avg_logprob": -0.11849888350612434, "compression_ratio": 1.66875, "no_speech_prob": 0.001897014444693923}, {"id": 393, "seek": 139088, "start": 1402.72, "end": 1405.2800000000002, "text": " you know knew this technically was getting better", "tokens": [50956, 291, 458, 2586, 341, 12120, 390, 1242, 1101, 51084], "temperature": 0.0, "avg_logprob": -0.11849888350612434, "compression_ratio": 1.66875, "no_speech_prob": 0.001897014444693923}, {"id": 394, "seek": 139088, "start": 1405.2800000000002, "end": 1409.6000000000001, "text": " but this ability to reason there was a sort of visceral reaction I had which", "tokens": [51084, 457, 341, 3485, 281, 1778, 456, 390, 257, 1333, 295, 1452, 47879, 5480, 286, 632, 597, 51300], "temperature": 0.0, "avg_logprob": -0.11849888350612434, "compression_ratio": 1.66875, "no_speech_prob": 0.001897014444693923}, {"id": 395, "seek": 139088, "start": 1409.6000000000001, "end": 1414.0, "text": " took me right back to that film 2001 that sense of I was engaging with something", "tokens": [51300, 1890, 385, 558, 646, 281, 300, 2007, 16382, 300, 2020, 295, 286, 390, 11268, 365, 746, 51520], "temperature": 0.0, "avg_logprob": -0.11849888350612434, "compression_ratio": 1.66875, "no_speech_prob": 0.001897014444693923}, {"id": 396, "seek": 139088, "start": 1414.0, "end": 1416.96, "text": " which you know my colleague Sebastian Bubeck called it the sparks of", "tokens": [51520, 597, 291, 458, 452, 13532, 31102, 4078, 650, 547, 1219, 309, 264, 44102, 295, 51668], "temperature": 0.0, "avg_logprob": -0.11849888350612434, "compression_ratio": 1.66875, "no_speech_prob": 0.001897014444693923}, {"id": 397, "seek": 139088, "start": 1416.96, "end": 1420.16, "text": " artificial intelligence so nobody in that nobody's claiming GPT-4 is", "tokens": [51668, 11677, 7599, 370, 5079, 294, 300, 5079, 311, 19232, 26039, 51, 12, 19, 307, 51828], "temperature": 0.0, "avg_logprob": -0.11849888350612434, "compression_ratio": 1.66875, "no_speech_prob": 0.001897014444693923}, {"id": 398, "seek": 142016, "start": 1420.16, "end": 1423.0400000000002, "text": " anywhere close to human intelligence or anything like that but there was just", "tokens": [50364, 4992, 1998, 281, 1952, 7599, 420, 1340, 411, 300, 457, 456, 390, 445, 50508], "temperature": 0.0, "avg_logprob": -0.09642905157965583, "compression_ratio": 1.872093023255814, "no_speech_prob": 0.0018768112640827894}, {"id": 399, "seek": 142016, "start": 1423.0400000000002, "end": 1426.8000000000002, "text": " the first glimpse of something it was the first time in my life that I'd", "tokens": [50508, 264, 700, 25838, 295, 746, 309, 390, 264, 700, 565, 294, 452, 993, 300, 286, 1116, 50696], "temperature": 0.0, "avg_logprob": -0.09642905157965583, "compression_ratio": 1.872093023255814, "no_speech_prob": 0.0018768112640827894}, {"id": 400, "seek": 142016, "start": 1426.8000000000002, "end": 1429.68, "text": " interacted with something that wasn't a human being", "tokens": [50696, 49621, 365, 746, 300, 2067, 380, 257, 1952, 885, 50840], "temperature": 0.0, "avg_logprob": -0.09642905157965583, "compression_ratio": 1.872093023255814, "no_speech_prob": 0.0018768112640827894}, {"id": 401, "seek": 142016, "start": 1429.68, "end": 1434.24, "text": " that had a glimmer of this this higher level of intelligence", "tokens": [50840, 300, 632, 257, 1563, 14477, 295, 341, 341, 2946, 1496, 295, 7599, 51068], "temperature": 0.0, "avg_logprob": -0.09642905157965583, "compression_ratio": 1.872093023255814, "no_speech_prob": 0.0018768112640827894}, {"id": 402, "seek": 142016, "start": 1434.24, "end": 1440.0800000000002, "text": " and and realizing this may be the dawn of a of a new era that may be", "tokens": [51068, 293, 293, 16734, 341, 815, 312, 264, 18192, 295, 257, 295, 257, 777, 4249, 300, 815, 312, 51360], "temperature": 0.0, "avg_logprob": -0.09642905157965583, "compression_ratio": 1.872093023255814, "no_speech_prob": 0.0018768112640827894}, {"id": 403, "seek": 142016, "start": 1440.0800000000002, "end": 1443.6000000000001, "text": " even more significant than the 2012 moment of the dawn of deep learning", "tokens": [51360, 754, 544, 4776, 813, 264, 9125, 1623, 295, 264, 18192, 295, 2452, 2539, 51536], "temperature": 0.0, "avg_logprob": -0.09642905157965583, "compression_ratio": 1.872093023255814, "no_speech_prob": 0.0018768112640827894}, {"id": 404, "seek": 142016, "start": 1443.6000000000001, "end": 1447.8400000000001, "text": " there was something very special going on and I wonder if part of the reaction", "tokens": [51536, 456, 390, 746, 588, 2121, 516, 322, 293, 286, 2441, 498, 644, 295, 264, 5480, 51748], "temperature": 0.0, "avg_logprob": -0.09642905157965583, "compression_ratio": 1.872093023255814, "no_speech_prob": 0.0018768112640827894}, {"id": 405, "seek": 144784, "start": 1447.9199999999998, "end": 1451.84, "text": " that we have to these models is a little bit of that sense of that threat to", "tokens": [50368, 300, 321, 362, 281, 613, 5245, 307, 257, 707, 857, 295, 300, 2020, 295, 300, 4734, 281, 50564], "temperature": 0.0, "avg_logprob": -0.09957010377713335, "compression_ratio": 1.8210526315789475, "no_speech_prob": 0.009361532516777515}, {"id": 406, "seek": 144784, "start": 1451.84, "end": 1455.12, "text": " the specialness that we feel as humans now maybe completely wrong this is purely", "tokens": [50564, 264, 2121, 1287, 300, 321, 841, 382, 6255, 586, 1310, 2584, 2085, 341, 307, 17491, 50728], "temperature": 0.0, "avg_logprob": -0.09957010377713335, "compression_ratio": 1.8210526315789475, "no_speech_prob": 0.009361532516777515}, {"id": 407, "seek": 144784, "start": 1455.12, "end": 1458.9599999999998, "text": " speculation but you know it's interesting that we", "tokens": [50728, 27696, 457, 291, 458, 309, 311, 1880, 300, 321, 50920], "temperature": 0.0, "avg_logprob": -0.09957010377713335, "compression_ratio": 1.8210526315789475, "no_speech_prob": 0.009361532516777515}, {"id": 408, "seek": 144784, "start": 1458.9599999999998, "end": 1461.36, "text": " talk about people use phrases like stochastic", "tokens": [50920, 751, 466, 561, 764, 20312, 411, 342, 8997, 2750, 51040], "temperature": 0.0, "avg_logprob": -0.09957010377713335, "compression_ratio": 1.8210526315789475, "no_speech_prob": 0.009361532516777515}, {"id": 409, "seek": 144784, "start": 1461.36, "end": 1464.3999999999999, "text": " parody it's just regurgitating stuff that it that it's seen before", "tokens": [51040, 43386, 309, 311, 445, 1121, 5476, 16350, 1507, 300, 309, 300, 309, 311, 1612, 949, 51192], "temperature": 0.0, "avg_logprob": -0.09957010377713335, "compression_ratio": 1.8210526315789475, "no_speech_prob": 0.009361532516777515}, {"id": 410, "seek": 144784, "start": 1464.3999999999999, "end": 1467.12, "text": " some people claim or you know of course it hallucinates sometimes it comes up", "tokens": [51192, 512, 561, 3932, 420, 291, 458, 295, 1164, 309, 35212, 259, 1024, 2171, 309, 1487, 493, 51328], "temperature": 0.0, "avg_logprob": -0.09957010377713335, "compression_ratio": 1.8210526315789475, "no_speech_prob": 0.009361532516777515}, {"id": 411, "seek": 144784, "start": 1467.12, "end": 1470.32, "text": " with stuff that's just wrong or doesn't make sense", "tokens": [51328, 365, 1507, 300, 311, 445, 2085, 420, 1177, 380, 652, 2020, 51488], "temperature": 0.0, "avg_logprob": -0.09957010377713335, "compression_ratio": 1.8210526315789475, "no_speech_prob": 0.009361532516777515}, {"id": 412, "seek": 144784, "start": 1470.32, "end": 1474.48, "text": " but but think about the following imagine there was a very very smart", "tokens": [51488, 457, 457, 519, 466, 264, 3480, 3811, 456, 390, 257, 588, 588, 4069, 51696], "temperature": 0.0, "avg_logprob": -0.09957010377713335, "compression_ratio": 1.8210526315789475, "no_speech_prob": 0.009361532516777515}, {"id": 413, "seek": 147448, "start": 1474.48, "end": 1478.16, "text": " physics student went to you went to a top university worked really hard for", "tokens": [50364, 10649, 3107, 1437, 281, 291, 1437, 281, 257, 1192, 5454, 2732, 534, 1152, 337, 50548], "temperature": 0.0, "avg_logprob": -0.10434349822998047, "compression_ratio": 1.900355871886121, "no_speech_prob": 0.040191903710365295}, {"id": 414, "seek": 147448, "start": 1478.16, "end": 1481.68, "text": " four years what would they do they would they would read books they would", "tokens": [50548, 1451, 924, 437, 576, 436, 360, 436, 576, 436, 576, 1401, 3642, 436, 576, 50724], "temperature": 0.0, "avg_logprob": -0.10434349822998047, "compression_ratio": 1.900355871886121, "no_speech_prob": 0.040191903710365295}, {"id": 415, "seek": 147448, "start": 1481.68, "end": 1484.96, "text": " read papers listen to lectures have discussions with their professors and", "tokens": [50724, 1401, 10577, 2140, 281, 16564, 362, 11088, 365, 641, 15924, 293, 50888], "temperature": 0.0, "avg_logprob": -0.10434349822998047, "compression_ratio": 1.900355871886121, "no_speech_prob": 0.040191903710365295}, {"id": 416, "seek": 147448, "start": 1484.96, "end": 1487.52, "text": " with other students and then they sit their final exam", "tokens": [50888, 365, 661, 1731, 293, 550, 436, 1394, 641, 2572, 1139, 51016], "temperature": 0.0, "avg_logprob": -0.10434349822998047, "compression_ratio": 1.900355871886121, "no_speech_prob": 0.040191903710365295}, {"id": 417, "seek": 147448, "start": 1487.52, "end": 1491.76, "text": " and they get 95% in their final exam and they come top of the year", "tokens": [51016, 293, 436, 483, 13420, 4, 294, 641, 2572, 1139, 293, 436, 808, 1192, 295, 264, 1064, 51228], "temperature": 0.0, "avg_logprob": -0.10434349822998047, "compression_ratio": 1.900355871886121, "no_speech_prob": 0.040191903710365295}, {"id": 418, "seek": 147448, "start": 1491.76, "end": 1496.0, "text": " we don't say huh well 95% of the time there are stochastic parrot", "tokens": [51228, 321, 500, 380, 584, 7020, 731, 13420, 4, 295, 264, 565, 456, 366, 342, 8997, 2750, 42462, 51440], "temperature": 0.0, "avg_logprob": -0.10434349822998047, "compression_ratio": 1.900355871886121, "no_speech_prob": 0.040191903710365295}, {"id": 419, "seek": 147448, "start": 1496.0, "end": 1499.6, "text": " regurgitating Einstein and Maxwell and the other 5% of the time they're", "tokens": [51440, 1121, 5476, 16350, 23486, 293, 39594, 293, 264, 661, 1025, 4, 295, 264, 565, 436, 434, 51620], "temperature": 0.0, "avg_logprob": -0.10434349822998047, "compression_ratio": 1.900355871886121, "no_speech_prob": 0.040191903710365295}, {"id": 420, "seek": 147448, "start": 1499.6, "end": 1502.08, "text": " hallucinating no we say congratulations you have a", "tokens": [51620, 35212, 8205, 572, 321, 584, 13568, 291, 362, 257, 51744], "temperature": 0.0, "avg_logprob": -0.10434349822998047, "compression_ratio": 1.900355871886121, "no_speech_prob": 0.040191903710365295}, {"id": 421, "seek": 150208, "start": 1502.08, "end": 1505.52, "text": " first-class honors degree you've graduated with honors this is this is a", "tokens": [50364, 700, 12, 11665, 26884, 4314, 291, 600, 13693, 365, 26884, 341, 307, 341, 307, 257, 50536], "temperature": 0.0, "avg_logprob": -0.10938405536469958, "compression_ratio": 1.8, "no_speech_prob": 0.0022121535148471594}, {"id": 422, "seek": 150208, "start": 1505.52, "end": 1511.1999999999998, "text": " you know a wonderful achievement so it's interesting that we do seem to view", "tokens": [50536, 291, 458, 257, 3715, 15838, 370, 309, 311, 1880, 300, 321, 360, 1643, 281, 1910, 50820], "temperature": 0.0, "avg_logprob": -0.10938405536469958, "compression_ratio": 1.8, "no_speech_prob": 0.0022121535148471594}, {"id": 423, "seek": 150208, "start": 1511.1999999999998, "end": 1515.28, "text": " the the capabilities of of neural nets with it with almost a different ruler", "tokens": [50820, 264, 264, 10862, 295, 295, 18161, 36170, 365, 309, 365, 1920, 257, 819, 19661, 51024], "temperature": 0.0, "avg_logprob": -0.10938405536469958, "compression_ratio": 1.8, "no_speech_prob": 0.0022121535148471594}, {"id": 424, "seek": 150208, "start": 1515.28, "end": 1518.96, "text": " to that of humans and while nobody's suggesting that current models are", "tokens": [51024, 281, 300, 295, 6255, 293, 1339, 5079, 311, 18094, 300, 2190, 5245, 366, 51208], "temperature": 0.0, "avg_logprob": -0.10938405536469958, "compression_ratio": 1.8, "no_speech_prob": 0.0022121535148471594}, {"id": 425, "seek": 150208, "start": 1518.96, "end": 1522.48, "text": " anywhere close to humans on many axes of intelligence", "tokens": [51208, 4992, 1998, 281, 6255, 322, 867, 35387, 295, 7599, 51384], "temperature": 0.0, "avg_logprob": -0.10938405536469958, "compression_ratio": 1.8, "no_speech_prob": 0.0022121535148471594}, {"id": 426, "seek": 150208, "start": 1522.48, "end": 1526.56, "text": " nevertheless i see the first sparks of of artificial intelligence", "tokens": [51384, 26924, 741, 536, 264, 700, 44102, 295, 295, 11677, 7599, 51588], "temperature": 0.0, "avg_logprob": -0.10938405536469958, "compression_ratio": 1.8, "no_speech_prob": 0.0022121535148471594}, {"id": 427, "seek": 150208, "start": 1526.56, "end": 1531.04, "text": " and just one final comment the term AI artificial intelligence has been very", "tokens": [51588, 293, 445, 472, 2572, 2871, 264, 1433, 7318, 11677, 7599, 575, 668, 588, 51812], "temperature": 0.0, "avg_logprob": -0.10938405536469958, "compression_ratio": 1.8, "no_speech_prob": 0.0022121535148471594}, {"id": 428, "seek": 153104, "start": 1531.04, "end": 1534.32, "text": " popular for many years i used to hate it i used to always say that's machine", "tokens": [50364, 3743, 337, 867, 924, 741, 1143, 281, 4700, 309, 741, 1143, 281, 1009, 584, 300, 311, 3479, 50528], "temperature": 0.0, "avg_logprob": -0.09225752546980574, "compression_ratio": 1.8754578754578755, "no_speech_prob": 0.0020728856325149536}, {"id": 429, "seek": 153104, "start": 1534.32, "end": 1536.6399999999999, "text": " learning none of these systems are intelligent they're very good at", "tokens": [50528, 2539, 6022, 295, 613, 3652, 366, 13232, 436, 434, 588, 665, 412, 50644], "temperature": 0.0, "avg_logprob": -0.09225752546980574, "compression_ratio": 1.8754578754578755, "no_speech_prob": 0.0020728856325149536}, {"id": 430, "seek": 153104, "start": 1536.6399999999999, "end": 1540.08, "text": " recognizing cats and images there's nothing really intelligent about this", "tokens": [50644, 18538, 11111, 293, 5267, 456, 311, 1825, 534, 13232, 466, 341, 50816], "temperature": 0.0, "avg_logprob": -0.09225752546980574, "compression_ratio": 1.8754578754578755, "no_speech_prob": 0.0020728856325149536}, {"id": 431, "seek": 153104, "start": 1540.08, "end": 1544.48, "text": " in in in in one sense and yet now i find for the first", "tokens": [50816, 294, 294, 294, 294, 472, 2020, 293, 1939, 586, 741, 915, 337, 264, 700, 51036], "temperature": 0.0, "avg_logprob": -0.09225752546980574, "compression_ratio": 1.8754578754578755, "no_speech_prob": 0.0020728856325149536}, {"id": 432, "seek": 153104, "start": 1544.48, "end": 1546.48, "text": " time i feel comfortable talking about artificial", "tokens": [51036, 565, 741, 841, 4619, 1417, 466, 11677, 51136], "temperature": 0.0, "avg_logprob": -0.09225752546980574, "compression_ratio": 1.8754578754578755, "no_speech_prob": 0.0020728856325149536}, {"id": 433, "seek": 153104, "start": 1546.48, "end": 1549.6, "text": " intelligence because i think we've taken the first baby steps towards what i", "tokens": [51136, 7599, 570, 741, 519, 321, 600, 2726, 264, 700, 3186, 4439, 3030, 437, 741, 51292], "temperature": 0.0, "avg_logprob": -0.09225752546980574, "compression_ratio": 1.8754578754578755, "no_speech_prob": 0.0020728856325149536}, {"id": 434, "seek": 153104, "start": 1549.6, "end": 1552.96, "text": " think of as true artificial intelligence i still think that", "tokens": [51292, 519, 295, 382, 2074, 11677, 7599, 741, 920, 519, 300, 51460], "temperature": 0.0, "avg_logprob": -0.09225752546980574, "compression_ratio": 1.8754578754578755, "no_speech_prob": 0.0020728856325149536}, {"id": 435, "seek": 153104, "start": 1552.96, "end": 1556.8, "text": " agency and creativity are the distinguishing feature", "tokens": [51460, 7934, 293, 12915, 366, 264, 11365, 3807, 4111, 51652], "temperature": 0.0, "avg_logprob": -0.09225752546980574, "compression_ratio": 1.8754578754578755, "no_speech_prob": 0.0020728856325149536}, {"id": 436, "seek": 155680, "start": 1556.8, "end": 1560.3999999999999, "text": " not necessarily that we are and biological beings", "tokens": [50364, 406, 4725, 300, 321, 366, 293, 13910, 8958, 50544], "temperature": 0.0, "avg_logprob": -0.058368547396226364, "compression_ratio": 1.8502415458937198, "no_speech_prob": 0.00980016216635704}, {"id": 437, "seek": 155680, "start": 1560.3999999999999, "end": 1564.6399999999999, "text": " it's more to do with we are independent agents and we are", "tokens": [50544, 309, 311, 544, 281, 360, 365, 321, 366, 6695, 12554, 293, 321, 366, 50756], "temperature": 0.0, "avg_logprob": -0.058368547396226364, "compression_ratio": 1.8502415458937198, "no_speech_prob": 0.00980016216635704}, {"id": 438, "seek": 155680, "start": 1564.6399999999999, "end": 1568.32, "text": " sampling random things from our local worlds and we're combining them", "tokens": [50756, 21179, 4974, 721, 490, 527, 2654, 13401, 293, 321, 434, 21928, 552, 50940], "temperature": 0.0, "avg_logprob": -0.058368547396226364, "compression_ratio": 1.8502415458937198, "no_speech_prob": 0.00980016216635704}, {"id": 439, "seek": 155680, "start": 1568.32, "end": 1572.08, "text": " together in in interesting ways and in doing so", "tokens": [50940, 1214, 294, 294, 1880, 2098, 293, 294, 884, 370, 51128], "temperature": 0.0, "avg_logprob": -0.058368547396226364, "compression_ratio": 1.8502415458937198, "no_speech_prob": 0.00980016216635704}, {"id": 440, "seek": 155680, "start": 1572.08, "end": 1575.76, "text": " intelligence is about the process of building models", "tokens": [51128, 7599, 307, 466, 264, 1399, 295, 2390, 5245, 51312], "temperature": 0.0, "avg_logprob": -0.058368547396226364, "compression_ratio": 1.8502415458937198, "no_speech_prob": 0.00980016216635704}, {"id": 441, "seek": 155680, "start": 1575.76, "end": 1579.52, "text": " and sharing models and embedding models in in our culture", "tokens": [51312, 293, 5414, 5245, 293, 12240, 3584, 5245, 294, 294, 527, 3713, 51500], "temperature": 0.0, "avg_logprob": -0.058368547396226364, "compression_ratio": 1.8502415458937198, "no_speech_prob": 0.00980016216635704}, {"id": 442, "seek": 155680, "start": 1579.52, "end": 1582.72, "text": " so it feels to me that gpt was building models", "tokens": [51500, 370, 309, 3417, 281, 385, 300, 290, 662, 390, 2390, 5245, 51660], "temperature": 0.0, "avg_logprob": -0.058368547396226364, "compression_ratio": 1.8502415458937198, "no_speech_prob": 0.00980016216635704}, {"id": 443, "seek": 158272, "start": 1582.72, "end": 1587.84, "text": " at the time it was trained and and and that's all it's doing", "tokens": [50364, 412, 264, 565, 309, 390, 8895, 293, 293, 293, 300, 311, 439, 309, 311, 884, 50620], "temperature": 0.0, "avg_logprob": -0.06076798439025879, "compression_ratio": 1.8097165991902835, "no_speech_prob": 0.0023976564407348633}, {"id": 444, "seek": 158272, "start": 1587.84, "end": 1590.88, "text": " i can imagine a world where there were lots of gpt's", "tokens": [50620, 741, 393, 3811, 257, 1002, 689, 456, 645, 3195, 295, 290, 662, 311, 50772], "temperature": 0.0, "avg_logprob": -0.06076798439025879, "compression_ratio": 1.8097165991902835, "no_speech_prob": 0.0023976564407348633}, {"id": 445, "seek": 158272, "start": 1590.88, "end": 1595.1200000000001, "text": " we all had gpt in our pockets and maybe then it would be much more like", "tokens": [50772, 321, 439, 632, 290, 662, 294, 527, 16491, 293, 1310, 550, 309, 576, 312, 709, 544, 411, 50984], "temperature": 0.0, "avg_logprob": -0.06076798439025879, "compression_ratio": 1.8097165991902835, "no_speech_prob": 0.0023976564407348633}, {"id": 446, "seek": 158272, "start": 1595.1200000000001, "end": 1598.64, "text": " biomimetic intelligence i think there are lots of interesting", "tokens": [50984, 27450, 332, 3532, 7599, 741, 519, 456, 366, 3195, 295, 1880, 51160], "temperature": 0.0, "avg_logprob": -0.06076798439025879, "compression_ratio": 1.8097165991902835, "no_speech_prob": 0.0023976564407348633}, {"id": 447, "seek": 158272, "start": 1598.64, "end": 1603.68, "text": " points that you touched on there tim so i think one thing is in terms of", "tokens": [51160, 2793, 300, 291, 9828, 322, 456, 524, 370, 741, 519, 472, 551, 307, 294, 2115, 295, 51412], "temperature": 0.0, "avg_logprob": -0.06076798439025879, "compression_ratio": 1.8097165991902835, "no_speech_prob": 0.0023976564407348633}, {"id": 448, "seek": 158272, "start": 1603.68, "end": 1607.04, "text": " creativity you know are these systems creative it's certainly true they only", "tokens": [51412, 12915, 291, 458, 366, 613, 3652, 5880, 309, 311, 3297, 2074, 436, 787, 51580], "temperature": 0.0, "avg_logprob": -0.06076798439025879, "compression_ratio": 1.8097165991902835, "no_speech_prob": 0.0023976564407348633}, {"id": 449, "seek": 158272, "start": 1607.04, "end": 1610.08, "text": " exist because of humans they're created by humans", "tokens": [51580, 2514, 570, 295, 6255, 436, 434, 2942, 538, 6255, 51732], "temperature": 0.0, "avg_logprob": -0.06076798439025879, "compression_ratio": 1.8097165991902835, "no_speech_prob": 0.0023976564407348633}, {"id": 450, "seek": 161008, "start": 1610.08, "end": 1613.1999999999998, "text": " and and we should acknowledge that but i don't think it means they're", "tokens": [50364, 293, 293, 321, 820, 10692, 300, 457, 741, 500, 380, 519, 309, 1355, 436, 434, 50520], "temperature": 0.0, "avg_logprob": -0.09806627259218603, "compression_ratio": 1.864516129032258, "no_speech_prob": 0.00649476982653141}, {"id": 451, "seek": 161008, "start": 1613.1999999999998, "end": 1617.52, "text": " intrinsically not creative if i asked an artist to", "tokens": [50520, 28621, 984, 406, 5880, 498, 741, 2351, 364, 5748, 281, 50736], "temperature": 0.0, "avg_logprob": -0.09806627259218603, "compression_ratio": 1.864516129032258, "no_speech_prob": 0.00649476982653141}, {"id": 452, "seek": 161008, "start": 1617.52, "end": 1620.8, "text": " paint me a picture of some people walking on the beach with a sunset or", "tokens": [50736, 4225, 385, 257, 3036, 295, 512, 561, 4494, 322, 264, 7534, 365, 257, 20142, 420, 50900], "temperature": 0.0, "avg_logprob": -0.09806627259218603, "compression_ratio": 1.864516129032258, "no_speech_prob": 0.00649476982653141}, {"id": 453, "seek": 161008, "start": 1620.8, "end": 1623.28, "text": " whatever and they came back a few days later with some", "tokens": [50900, 2035, 293, 436, 1361, 646, 257, 1326, 1708, 1780, 365, 512, 51024], "temperature": 0.0, "avg_logprob": -0.09806627259218603, "compression_ratio": 1.864516129032258, "no_speech_prob": 0.00649476982653141}, {"id": 454, "seek": 161008, "start": 1623.28, "end": 1626.48, "text": " beautiful picture i might hate it they may have used very vivid", "tokens": [51024, 2238, 3036, 741, 1062, 4700, 309, 436, 815, 362, 1143, 588, 23603, 51184], "temperature": 0.0, "avg_logprob": -0.09806627259218603, "compression_ratio": 1.864516129032258, "no_speech_prob": 0.00649476982653141}, {"id": 455, "seek": 161008, "start": 1626.48, "end": 1629.84, "text": " colors i might like pale pastel colors but that's a matter of opinion", "tokens": [51184, 4577, 741, 1062, 411, 19546, 38100, 4577, 457, 300, 311, 257, 1871, 295, 4800, 51352], "temperature": 0.0, "avg_logprob": -0.09806627259218603, "compression_ratio": 1.864516129032258, "no_speech_prob": 0.00649476982653141}, {"id": 456, "seek": 161008, "start": 1629.84, "end": 1632.8, "text": " but i wouldn't deny that there was creativity there", "tokens": [51352, 457, 741, 2759, 380, 15744, 300, 456, 390, 12915, 456, 51500], "temperature": 0.0, "avg_logprob": -0.09806627259218603, "compression_ratio": 1.864516129032258, "no_speech_prob": 0.00649476982653141}, {"id": 457, "seek": 161008, "start": 1632.8, "end": 1636.56, "text": " but their expertise came because well they went they perhaps had some", "tokens": [51500, 457, 641, 11769, 1361, 570, 731, 436, 1437, 436, 4317, 632, 512, 51688], "temperature": 0.0, "avg_logprob": -0.09806627259218603, "compression_ratio": 1.864516129032258, "no_speech_prob": 0.00649476982653141}, {"id": 458, "seek": 161008, "start": 1636.56, "end": 1640.0, "text": " intrinsic ability in some sense but they went to art school they study the", "tokens": [51688, 35698, 3485, 294, 512, 2020, 457, 436, 1437, 281, 1523, 1395, 436, 2979, 264, 51860], "temperature": 0.0, "avg_logprob": -0.09806627259218603, "compression_ratio": 1.864516129032258, "no_speech_prob": 0.00649476982653141}, {"id": 459, "seek": 164000, "start": 1640.0, "end": 1642.64, "text": " work of other artists they practice they got better", "tokens": [50364, 589, 295, 661, 6910, 436, 3124, 436, 658, 1101, 50496], "temperature": 0.0, "avg_logprob": -0.05956343242100307, "compression_ratio": 1.996124031007752, "no_speech_prob": 0.0009647443657740951}, {"id": 460, "seek": 164000, "start": 1642.64, "end": 1647.52, "text": " and and and that creativity owes a lot to what went before but i don't think it", "tokens": [50496, 293, 293, 293, 300, 12915, 50028, 257, 688, 281, 437, 1437, 949, 457, 741, 500, 380, 519, 309, 50740], "temperature": 0.0, "avg_logprob": -0.05956343242100307, "compression_ratio": 1.996124031007752, "no_speech_prob": 0.0009647443657740951}, {"id": 461, "seek": 164000, "start": 1647.52, "end": 1650.24, "text": " diminishes that in the same way a physics student who can", "tokens": [50740, 15739, 16423, 300, 294, 264, 912, 636, 257, 10649, 3107, 567, 393, 50876], "temperature": 0.0, "avg_logprob": -0.05956343242100307, "compression_ratio": 1.996124031007752, "no_speech_prob": 0.0009647443657740951}, {"id": 462, "seek": 164000, "start": 1650.24, "end": 1653.2, "text": " explain the theory of relativity you have to say well you didn't invent the", "tokens": [50876, 2903, 264, 5261, 295, 45675, 291, 362, 281, 584, 731, 291, 994, 380, 7962, 264, 51024], "temperature": 0.0, "avg_logprob": -0.05956343242100307, "compression_ratio": 1.996124031007752, "no_speech_prob": 0.0009647443657740951}, {"id": 463, "seek": 164000, "start": 1653.2, "end": 1656.08, "text": " theory of relativity you know einstein invented that you only learned it from", "tokens": [51024, 5261, 295, 45675, 291, 458, 1343, 9089, 14479, 300, 291, 787, 3264, 309, 490, 51168], "temperature": 0.0, "avg_logprob": -0.05956343242100307, "compression_ratio": 1.996124031007752, "no_speech_prob": 0.0009647443657740951}, {"id": 464, "seek": 164000, "start": 1656.08, "end": 1659.76, "text": " einstein but it doesn't diminish the the fact", "tokens": [51168, 1343, 9089, 457, 309, 1177, 380, 48696, 264, 264, 1186, 51352], "temperature": 0.0, "avg_logprob": -0.05956343242100307, "compression_ratio": 1.996124031007752, "no_speech_prob": 0.0009647443657740951}, {"id": 465, "seek": 164000, "start": 1659.76, "end": 1662.4, "text": " that they have understanding the fact that they convey it and the fact they", "tokens": [51352, 300, 436, 362, 3701, 264, 1186, 300, 436, 16965, 309, 293, 264, 1186, 436, 51484], "temperature": 0.0, "avg_logprob": -0.05956343242100307, "compression_ratio": 1.996124031007752, "no_speech_prob": 0.0009647443657740951}, {"id": 466, "seek": 164000, "start": 1662.4, "end": 1665.2, "text": " can potentially think in new ways and be creative", "tokens": [51484, 393, 7263, 519, 294, 777, 2098, 293, 312, 5880, 51624], "temperature": 0.0, "avg_logprob": -0.05956343242100307, "compression_ratio": 1.996124031007752, "no_speech_prob": 0.0009647443657740951}, {"id": 467, "seek": 166520, "start": 1665.2, "end": 1671.68, "text": " so i'm i'm less convinced about discussions about the limitations of", "tokens": [50364, 370, 741, 478, 741, 478, 1570, 12561, 466, 11088, 466, 264, 15705, 295, 50688], "temperature": 0.0, "avg_logprob": -0.11932979252027429, "compression_ratio": 1.9296296296296296, "no_speech_prob": 0.001888966653496027}, {"id": 468, "seek": 166520, "start": 1671.68, "end": 1675.6000000000001, "text": " of of the technology in general of where it can go i don't particularly see any", "tokens": [50688, 295, 295, 264, 2899, 294, 2674, 295, 689, 309, 393, 352, 741, 500, 380, 4098, 536, 604, 50884], "temperature": 0.0, "avg_logprob": -0.11932979252027429, "compression_ratio": 1.9296296296296296, "no_speech_prob": 0.001888966653496027}, {"id": 469, "seek": 166520, "start": 1675.6000000000001, "end": 1678.96, "text": " limitations the brain is a machine that uses this", "tokens": [50884, 15705, 264, 3567, 307, 257, 3479, 300, 4960, 341, 51052], "temperature": 0.0, "avg_logprob": -0.11932979252027429, "compression_ratio": 1.9296296296296296, "no_speech_prob": 0.001888966653496027}, {"id": 470, "seek": 166520, "start": 1678.96, "end": 1681.8400000000001, "text": " a term used earlier connectionist approach it uses these fine-grained", "tokens": [51052, 257, 1433, 1143, 3071, 4984, 468, 3109, 309, 4960, 613, 2489, 12, 20735, 2001, 51196], "temperature": 0.0, "avg_logprob": -0.11932979252027429, "compression_ratio": 1.9296296296296296, "no_speech_prob": 0.001888966653496027}, {"id": 471, "seek": 166520, "start": 1681.8400000000001, "end": 1685.04, "text": " neural nets and and so there are similarities to the", "tokens": [51196, 18161, 36170, 293, 293, 370, 456, 366, 24197, 281, 264, 51356], "temperature": 0.0, "avg_logprob": -0.11932979252027429, "compression_ratio": 1.9296296296296296, "no_speech_prob": 0.001888966653496027}, {"id": 472, "seek": 166520, "start": 1685.04, "end": 1687.92, "text": " technology that we have now there are also huge differences", "tokens": [51356, 2899, 300, 321, 362, 586, 456, 366, 611, 2603, 7300, 51500], "temperature": 0.0, "avg_logprob": -0.11932979252027429, "compression_ratio": 1.9296296296296296, "no_speech_prob": 0.001888966653496027}, {"id": 473, "seek": 166520, "start": 1687.92, "end": 1691.1200000000001, "text": " some of those differences point to the artificial neural nets being much more", "tokens": [51500, 512, 295, 729, 7300, 935, 281, 264, 11677, 18161, 36170, 885, 709, 544, 51660], "temperature": 0.0, "avg_logprob": -0.11932979252027429, "compression_ratio": 1.9296296296296296, "no_speech_prob": 0.001888966653496027}, {"id": 474, "seek": 166520, "start": 1691.1200000000001, "end": 1694.0, "text": " powerful than biological neural nets and hinted made a strong", "tokens": [51660, 4005, 813, 13910, 18161, 36170, 293, 12075, 292, 1027, 257, 2068, 51804], "temperature": 0.0, "avg_logprob": -0.11932979252027429, "compression_ratio": 1.9296296296296296, "no_speech_prob": 0.001888966653496027}, {"id": 475, "seek": 169400, "start": 1694.0, "end": 1696.32, "text": " point of this lately and i think it's a very interesting", "tokens": [50364, 935, 295, 341, 12881, 293, 741, 519, 309, 311, 257, 588, 1880, 50480], "temperature": 0.0, "avg_logprob": -0.09316225877897007, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.011428387835621834}, {"id": 476, "seek": 169400, "start": 1696.32, "end": 1700.88, "text": " perspective so i would be the first to say", "tokens": [50480, 4585, 370, 741, 576, 312, 264, 700, 281, 584, 50708], "temperature": 0.0, "avg_logprob": -0.09316225877897007, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.011428387835621834}, {"id": 477, "seek": 169400, "start": 1700.88, "end": 1705.12, "text": " yes the technologies we have on many axes are a long way short of humans on", "tokens": [50708, 2086, 264, 7943, 321, 362, 322, 867, 35387, 366, 257, 938, 636, 2099, 295, 6255, 322, 50920], "temperature": 0.0, "avg_logprob": -0.09316225877897007, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.011428387835621834}, {"id": 478, "seek": 169400, "start": 1705.12, "end": 1708.32, "text": " many axes the much better gbt4 can create text", "tokens": [50920, 867, 35387, 264, 709, 1101, 290, 4517, 19, 393, 1884, 2487, 51080], "temperature": 0.0, "avg_logprob": -0.09316225877897007, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.011428387835621834}, {"id": 479, "seek": 169400, "start": 1708.32, "end": 1712.48, "text": " much better than any human i mean to produce a page of coherent text that's", "tokens": [51080, 709, 1101, 813, 604, 1952, 741, 914, 281, 5258, 257, 3028, 295, 36239, 2487, 300, 311, 51288], "temperature": 0.0, "avg_logprob": -0.09316225877897007, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.011428387835621834}, {"id": 480, "seek": 169400, "start": 1712.48, "end": 1715.76, "text": " correctly punctuated in good grammar and so on in a few seconds there aren't", "tokens": [51288, 8944, 27006, 27275, 294, 665, 22317, 293, 370, 322, 294, 257, 1326, 3949, 456, 3212, 380, 51452], "temperature": 0.0, "avg_logprob": -0.09316225877897007, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.011428387835621834}, {"id": 481, "seek": 169400, "start": 1715.76, "end": 1720.0, "text": " any people that can do that i think so on an increasing number of axes", "tokens": [51452, 604, 561, 300, 393, 360, 300, 741, 519, 370, 322, 364, 5662, 1230, 295, 35387, 51664], "temperature": 0.0, "avg_logprob": -0.09316225877897007, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.011428387835621834}, {"id": 482, "seek": 169400, "start": 1720.0, "end": 1723.84, "text": " systems clearly outperform humans and on others there's still a very long", "tokens": [51664, 3652, 4448, 484, 26765, 6255, 293, 322, 2357, 456, 311, 920, 257, 588, 938, 51856], "temperature": 0.0, "avg_logprob": -0.09316225877897007, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.011428387835621834}, {"id": 483, "seek": 172384, "start": 1723.84, "end": 1727.84, "text": " way to go but i think one of the nice things about technologies like this", "tokens": [50364, 636, 281, 352, 457, 741, 519, 472, 295, 264, 1481, 721, 466, 7943, 411, 341, 50564], "temperature": 0.0, "avg_logprob": -0.10445692355816182, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00357434363104403}, {"id": 484, "seek": 172384, "start": 1727.84, "end": 1731.6799999999998, "text": " generative ai technologies whether it's you know saura for creating videos or", "tokens": [50564, 1337, 1166, 9783, 7943, 1968, 309, 311, 291, 458, 601, 2991, 337, 4084, 2145, 420, 50756], "temperature": 0.0, "avg_logprob": -0.10445692355816182, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00357434363104403}, {"id": 485, "seek": 172384, "start": 1731.6799999999998, "end": 1735.9199999999998, "text": " gbt4 or whatever it might be is they do rely on the prompt there is a clear", "tokens": [50756, 290, 4517, 19, 420, 2035, 309, 1062, 312, 307, 436, 360, 10687, 322, 264, 12391, 456, 307, 257, 1850, 50968], "temperature": 0.0, "avg_logprob": -0.10445692355816182, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00357434363104403}, {"id": 486, "seek": 172384, "start": 1735.9199999999998, "end": 1740.48, "text": " role they are co-pilots as we say they they they sit there and do nothing", "tokens": [50968, 3090, 436, 366, 598, 12, 79, 388, 1971, 382, 321, 584, 436, 436, 436, 1394, 456, 293, 360, 1825, 51196], "temperature": 0.0, "avg_logprob": -0.10445692355816182, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00357434363104403}, {"id": 487, "seek": 172384, "start": 1740.48, "end": 1745.04, "text": " and you use them as a sort of a cognitive amplifier you have an idea", "tokens": [51196, 293, 291, 764, 552, 382, 257, 1333, 295, 257, 15605, 27439, 291, 362, 364, 1558, 51424], "temperature": 0.0, "avg_logprob": -0.10445692355816182, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00357434363104403}, {"id": 488, "seek": 172384, "start": 1745.04, "end": 1748.3999999999999, "text": " sort of half-baked and then you can engage in a conversation and", "tokens": [51424, 1333, 295, 1922, 12, 65, 7301, 293, 550, 291, 393, 4683, 294, 257, 3761, 293, 51592], "temperature": 0.0, "avg_logprob": -0.10445692355816182, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00357434363104403}, {"id": 489, "seek": 172384, "start": 1748.3999999999999, "end": 1751.52, "text": " sure enough it can come up with a different way of thinking say hey that's", "tokens": [51592, 988, 1547, 309, 393, 808, 493, 365, 257, 819, 636, 295, 1953, 584, 4177, 300, 311, 51748], "temperature": 0.0, "avg_logprob": -0.10445692355816182, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00357434363104403}, {"id": 490, "seek": 175152, "start": 1751.52, "end": 1755.68, "text": " really good i like that idea now let's take that work that back in try again", "tokens": [50364, 534, 665, 741, 411, 300, 1558, 586, 718, 311, 747, 300, 589, 300, 646, 294, 853, 797, 50572], "temperature": 0.0, "avg_logprob": -0.0715869665145874, "compression_ratio": 1.9084745762711866, "no_speech_prob": 0.01875264011323452}, {"id": 491, "seek": 175152, "start": 1755.68, "end": 1759.12, "text": " and so it becomes now a companion a co-pilot something that", "tokens": [50572, 293, 370, 309, 3643, 586, 257, 22363, 257, 598, 12, 79, 31516, 746, 300, 50744], "temperature": 0.0, "avg_logprob": -0.0715869665145874, "compression_ratio": 1.9084745762711866, "no_speech_prob": 0.01875264011323452}, {"id": 492, "seek": 175152, "start": 1759.12, "end": 1762.8799999999999, "text": " enhances your your cognitive ability but the human is still very much in the", "tokens": [50744, 46628, 428, 428, 15605, 3485, 457, 264, 1952, 307, 920, 588, 709, 294, 264, 50932], "temperature": 0.0, "avg_logprob": -0.0715869665145874, "compression_ratio": 1.9084745762711866, "no_speech_prob": 0.01875264011323452}, {"id": 493, "seek": 175152, "start": 1762.8799999999999, "end": 1765.92, "text": " loop and playing a key part and actually initiating the process", "tokens": [50932, 6367, 293, 2433, 257, 2141, 644, 293, 767, 6265, 990, 264, 1399, 51084], "temperature": 0.0, "avg_logprob": -0.0715869665145874, "compression_ratio": 1.9084745762711866, "no_speech_prob": 0.01875264011323452}, {"id": 494, "seek": 175152, "start": 1765.92, "end": 1768.8, "text": " and of course finally at the end of the day you're the one that selects the", "tokens": [51084, 293, 295, 1164, 2721, 412, 264, 917, 295, 264, 786, 291, 434, 264, 472, 300, 3048, 82, 264, 51228], "temperature": 0.0, "avg_logprob": -0.0715869665145874, "compression_ratio": 1.9084745762711866, "no_speech_prob": 0.01875264011323452}, {"id": 495, "seek": 175152, "start": 1768.8, "end": 1772.24, "text": " you know the 10 video clips you pick the one that you like and so the human is", "tokens": [51228, 291, 458, 264, 1266, 960, 13117, 291, 1888, 264, 472, 300, 291, 411, 293, 370, 264, 1952, 307, 51400], "temperature": 0.0, "avg_logprob": -0.0715869665145874, "compression_ratio": 1.9084745762711866, "no_speech_prob": 0.01875264011323452}, {"id": 496, "seek": 175152, "start": 1772.24, "end": 1774.8, "text": " very much involved in the loop throughout so i think that's a very nice", "tokens": [51400, 588, 709, 3288, 294, 264, 6367, 3710, 370, 741, 519, 300, 311, 257, 588, 1481, 51528], "temperature": 0.0, "avg_logprob": -0.0715869665145874, "compression_ratio": 1.9084745762711866, "no_speech_prob": 0.01875264011323452}, {"id": 497, "seek": 175152, "start": 1774.8, "end": 1778.4, "text": " feature of this technology i completely agree with that so", "tokens": [51528, 4111, 295, 341, 2899, 741, 2584, 3986, 365, 300, 370, 51708], "temperature": 0.0, "avg_logprob": -0.0715869665145874, "compression_ratio": 1.9084745762711866, "no_speech_prob": 0.01875264011323452}, {"id": 498, "seek": 177840, "start": 1778.4, "end": 1783.44, "text": " at the moment a is are embedded in the cognitive nexus of humans so we have the", "tokens": [50364, 412, 264, 1623, 257, 307, 366, 16741, 294, 264, 15605, 408, 32618, 295, 6255, 370, 321, 362, 264, 50616], "temperature": 0.0, "avg_logprob": -0.0839410435069691, "compression_ratio": 1.9306122448979592, "no_speech_prob": 0.008348140865564346}, {"id": 499, "seek": 177840, "start": 1783.44, "end": 1786.72, "text": " agency and we drive these things and and they", "tokens": [50616, 7934, 293, 321, 3332, 613, 721, 293, 293, 436, 50780], "temperature": 0.0, "avg_logprob": -0.0839410435069691, "compression_ratio": 1.9306122448979592, "no_speech_prob": 0.008348140865564346}, {"id": 500, "seek": 177840, "start": 1786.72, "end": 1790.24, "text": " help us think and also i agree with you that it doesn't", "tokens": [50780, 854, 505, 519, 293, 611, 741, 3986, 365, 291, 300, 309, 1177, 380, 50956], "temperature": 0.0, "avg_logprob": -0.0839410435069691, "compression_ratio": 1.9306122448979592, "no_speech_prob": 0.008348140865564346}, {"id": 501, "seek": 177840, "start": 1790.24, "end": 1793.1200000000001, "text": " make sense to think of these things as limited forms of computation we should", "tokens": [50956, 652, 2020, 281, 519, 295, 613, 721, 382, 5567, 6422, 295, 24903, 321, 820, 51100], "temperature": 0.0, "avg_logprob": -0.0839410435069691, "compression_ratio": 1.9306122448979592, "no_speech_prob": 0.008348140865564346}, {"id": 502, "seek": 177840, "start": 1793.1200000000001, "end": 1796.88, "text": " think of the collective intelligence so we are touring machines and we are", "tokens": [51100, 519, 295, 264, 12590, 7599, 370, 321, 366, 32487, 8379, 293, 321, 366, 51288], "temperature": 0.0, "avg_logprob": -0.0839410435069691, "compression_ratio": 1.9306122448979592, "no_speech_prob": 0.008348140865564346}, {"id": 503, "seek": 177840, "start": 1796.88, "end": 1799.8400000000001, "text": " driving these things and we are sharing information so when you look at", "tokens": [51288, 4840, 613, 721, 293, 321, 366, 5414, 1589, 370, 562, 291, 574, 412, 51436], "temperature": 0.0, "avg_logprob": -0.0839410435069691, "compression_ratio": 1.9306122448979592, "no_speech_prob": 0.008348140865564346}, {"id": 504, "seek": 177840, "start": 1799.8400000000001, "end": 1804.88, "text": " the entire system it is a new type of memetic intelligence in fact", "tokens": [51436, 264, 2302, 1185, 309, 307, 257, 777, 2010, 295, 1334, 3532, 7599, 294, 1186, 51688], "temperature": 0.0, "avg_logprob": -0.0839410435069691, "compression_ratio": 1.9306122448979592, "no_speech_prob": 0.008348140865564346}, {"id": 505, "seek": 180488, "start": 1804.96, "end": 1809.0400000000002, "text": " you know to a certain extent GPT-4 isn't running on Microsoft servers", "tokens": [50368, 291, 458, 281, 257, 1629, 8396, 26039, 51, 12, 19, 1943, 380, 2614, 322, 8116, 15909, 50572], "temperature": 0.0, "avg_logprob": -0.10691502168006503, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.0036637471057474613}, {"id": 506, "seek": 180488, "start": 1809.0400000000002, "end": 1812.64, "text": " it's in all of us right and that's that's a wonderful way", "tokens": [50572, 309, 311, 294, 439, 295, 505, 558, 293, 300, 311, 300, 311, 257, 3715, 636, 50752], "temperature": 0.0, "avg_logprob": -0.10691502168006503, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.0036637471057474613}, {"id": 507, "seek": 180488, "start": 1812.64, "end": 1819.1200000000001, "text": " um to think about it but to me the extent to which it is constraining our", "tokens": [50752, 1105, 281, 519, 466, 309, 457, 281, 385, 264, 8396, 281, 597, 309, 307, 11525, 1760, 527, 51076], "temperature": 0.0, "avg_logprob": -0.10691502168006503, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.0036637471057474613}, {"id": 508, "seek": 180488, "start": 1819.1200000000001, "end": 1824.0, "text": " agency and creativity is what i'm fascinated by so GPT says unraveling", "tokens": [51076, 7934, 293, 12915, 307, 437, 741, 478, 24597, 538, 370, 26039, 51, 1619, 40507, 278, 51320], "temperature": 0.0, "avg_logprob": -0.10691502168006503, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.0036637471057474613}, {"id": 509, "seek": 180488, "start": 1824.0, "end": 1826.8000000000002, "text": " the mysteries and you know the intricate", "tokens": [51320, 264, 30785, 293, 291, 458, 264, 38015, 51460], "temperature": 0.0, "avg_logprob": -0.10691502168006503, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.0036637471057474613}, {"id": 510, "seek": 180488, "start": 1826.8000000000002, "end": 1830.24, "text": " dance of x y z and all of these weird motifs and", "tokens": [51460, 4489, 295, 2031, 288, 710, 293, 439, 295, 613, 3657, 2184, 18290, 293, 51632], "temperature": 0.0, "avg_logprob": -0.10691502168006503, "compression_ratio": 1.587719298245614, "no_speech_prob": 0.0036637471057474613}, {"id": 511, "seek": 183024, "start": 1830.24, "end": 1834.72, "text": " constructions and maybe that's just the way that our", "tokens": [50364, 7690, 626, 293, 1310, 300, 311, 445, 264, 636, 300, 527, 50588], "temperature": 0.0, "avg_logprob": -0.13534320484508167, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.011516116559505463}, {"id": 512, "seek": 183024, "start": 1834.72, "end": 1840.0, "text": " LHF has constrained the model or maybe it speaks to the constraining", "tokens": [50588, 441, 39, 37, 575, 38901, 264, 2316, 420, 1310, 309, 10789, 281, 264, 11525, 1760, 50852], "temperature": 0.0, "avg_logprob": -0.13534320484508167, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.011516116559505463}, {"id": 513, "seek": 183024, "start": 1840.0, "end": 1843.2, "text": " forces in general of having these low entropy models that kind of you know", "tokens": [50852, 5874, 294, 2674, 295, 1419, 613, 2295, 30867, 5245, 300, 733, 295, 291, 458, 51012], "temperature": 0.0, "avg_logprob": -0.13534320484508167, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.011516116559505463}, {"id": 514, "seek": 183024, "start": 1843.2, "end": 1846.56, "text": " snip off a lot of the interesting pathways so", "tokens": [51012, 37482, 766, 257, 688, 295, 264, 1880, 22988, 370, 51180], "temperature": 0.0, "avg_logprob": -0.13534320484508167, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.011516116559505463}, {"id": 515, "seek": 183024, "start": 1846.56, "end": 1852.0, "text": " we are very creative GPT-4 resists creativity a little bit is it a problem", "tokens": [51180, 321, 366, 588, 5880, 26039, 51, 12, 19, 725, 1751, 12915, 257, 707, 857, 307, 309, 257, 1154, 51452], "temperature": 0.0, "avg_logprob": -0.13534320484508167, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.011516116559505463}, {"id": 516, "seek": 183024, "start": 1852.0, "end": 1855.2, "text": " well i think there's some design choices there so you talked about reinforcement", "tokens": [51452, 731, 741, 519, 456, 311, 512, 1715, 7994, 456, 370, 291, 2825, 466, 29280, 51612], "temperature": 0.0, "avg_logprob": -0.13534320484508167, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.011516116559505463}, {"id": 517, "seek": 183024, "start": 1855.2, "end": 1858.0, "text": " learning through human feedback is part of that alignment process we ought to", "tokens": [51612, 2539, 807, 1952, 5824, 307, 644, 295, 300, 18515, 1399, 321, 13416, 281, 51752], "temperature": 0.0, "avg_logprob": -0.13534320484508167, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.011516116559505463}, {"id": 518, "seek": 185800, "start": 1858.0, "end": 1861.76, "text": " create this technology in a way that does good to minimize harm", "tokens": [50364, 1884, 341, 2899, 294, 257, 636, 300, 775, 665, 281, 17522, 6491, 50552], "temperature": 0.0, "avg_logprob": -0.10024654001429462, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.004170711152255535}, {"id": 519, "seek": 185800, "start": 1861.76, "end": 1866.16, "text": " and so naturally we do constrain it so for sure it's true that our constrained", "tokens": [50552, 293, 370, 8195, 321, 360, 1817, 7146, 309, 370, 337, 988, 309, 311, 2074, 300, 527, 38901, 50772], "temperature": 0.0, "avg_logprob": -0.10024654001429462, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.004170711152255535}, {"id": 520, "seek": 185800, "start": 1866.16, "end": 1870.0, "text": " GPT-4 behave in you might say less creative ways but perhaps in more", "tokens": [50772, 26039, 51, 12, 19, 15158, 294, 291, 1062, 584, 1570, 5880, 2098, 457, 4317, 294, 544, 50964], "temperature": 0.0, "avg_logprob": -0.10024654001429462, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.004170711152255535}, {"id": 521, "seek": 185800, "start": 1870.0, "end": 1873.2, "text": " helpful and beneficial ways and it's appropriate that we should do that", "tokens": [50964, 4961, 293, 14072, 2098, 293, 309, 311, 6854, 300, 321, 820, 360, 300, 51124], "temperature": 0.0, "avg_logprob": -0.10024654001429462, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.004170711152255535}, {"id": 522, "seek": 185800, "start": 1873.2, "end": 1876.72, "text": " and perhaps we lose a little bit of the creativity", "tokens": [51124, 293, 4317, 321, 3624, 257, 707, 857, 295, 264, 12915, 51300], "temperature": 0.0, "avg_logprob": -0.10024654001429462, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.004170711152255535}, {"id": 523, "seek": 185800, "start": 1876.72, "end": 1880.8, "text": " in the process and so there's there's a balance there's a there's a there's a", "tokens": [51300, 294, 264, 1399, 293, 370, 456, 311, 456, 311, 257, 4772, 456, 311, 257, 456, 311, 257, 456, 311, 257, 51504], "temperature": 0.0, "avg_logprob": -0.10024654001429462, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.004170711152255535}, {"id": 524, "seek": 185800, "start": 1880.8, "end": 1884.56, "text": " choice to be made a design choice in how we want to create the technology and", "tokens": [51504, 3922, 281, 312, 1027, 257, 1715, 3922, 294, 577, 321, 528, 281, 1884, 264, 2899, 293, 51692], "temperature": 0.0, "avg_logprob": -0.10024654001429462, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.004170711152255535}, {"id": 525, "seek": 185800, "start": 1884.56, "end": 1887.44, "text": " we should be very deliberate about that and not not apologetic for that i think", "tokens": [51692, 321, 820, 312, 588, 30515, 466, 300, 293, 406, 406, 9472, 3532, 337, 300, 741, 519, 51836], "temperature": 0.0, "avg_logprob": -0.10024654001429462, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.004170711152255535}, {"id": 526, "seek": 188744, "start": 1887.44, "end": 1890.48, "text": " it's good that we are that we are making those design choices", "tokens": [50364, 309, 311, 665, 300, 321, 366, 300, 321, 366, 1455, 729, 1715, 7994, 50516], "temperature": 0.0, "avg_logprob": -0.07165885421465028, "compression_ratio": 1.8675213675213675, "no_speech_prob": 0.0006325923604890704}, {"id": 527, "seek": 188744, "start": 1890.48, "end": 1894.88, "text": " but people sometimes have an intuition that it's not creative", "tokens": [50516, 457, 561, 2171, 362, 364, 24002, 300, 309, 311, 406, 5880, 50736], "temperature": 0.0, "avg_logprob": -0.07165885421465028, "compression_ratio": 1.8675213675213675, "no_speech_prob": 0.0006325923604890704}, {"id": 528, "seek": 188744, "start": 1894.88, "end": 1898.24, "text": " and contrast that to i'm using DaVinci Resolve", "tokens": [50736, 293, 8712, 300, 281, 741, 478, 1228, 3933, 53, 21961, 5015, 37361, 50904], "temperature": 0.0, "avg_logprob": -0.07165885421465028, "compression_ratio": 1.8675213675213675, "no_speech_prob": 0.0006325923604890704}, {"id": 529, "seek": 188744, "start": 1898.24, "end": 1902.16, "text": " and i'm using all of these nodes and i have all of these filters and", "tokens": [50904, 293, 741, 478, 1228, 439, 295, 613, 13891, 293, 741, 362, 439, 295, 613, 15995, 293, 51100], "temperature": 0.0, "avg_logprob": -0.07165885421465028, "compression_ratio": 1.8675213675213675, "no_speech_prob": 0.0006325923604890704}, {"id": 530, "seek": 188744, "start": 1902.16, "end": 1906.0800000000002, "text": " processing transforms the difference seems to be that", "tokens": [51100, 9007, 35592, 264, 2649, 2544, 281, 312, 300, 51296], "temperature": 0.0, "avg_logprob": -0.07165885421465028, "compression_ratio": 1.8675213675213675, "no_speech_prob": 0.0006325923604890704}, {"id": 531, "seek": 188744, "start": 1906.0800000000002, "end": 1910.72, "text": " i'm designing the architecture so i'm using cognitive primitives", "tokens": [51296, 741, 478, 14685, 264, 9482, 370, 741, 478, 1228, 15605, 2886, 38970, 51528], "temperature": 0.0, "avg_logprob": -0.07165885421465028, "compression_ratio": 1.8675213675213675, "no_speech_prob": 0.0006325923604890704}, {"id": 532, "seek": 188744, "start": 1910.72, "end": 1914.88, "text": " and i'm composing them together in a new way and by tweaking the parameters on", "tokens": [51528, 293, 741, 478, 715, 6110, 552, 1214, 294, 257, 777, 636, 293, 538, 6986, 2456, 264, 9834, 322, 51736], "temperature": 0.0, "avg_logprob": -0.07165885421465028, "compression_ratio": 1.8675213675213675, "no_speech_prob": 0.0006325923604890704}, {"id": 533, "seek": 191488, "start": 1914.88, "end": 1917.7600000000002, "text": " the filters i'm going off-peast a little bit i'm", "tokens": [50364, 264, 15995, 741, 478, 516, 766, 12, 494, 525, 257, 707, 857, 741, 478, 50508], "temperature": 0.0, "avg_logprob": -0.1025030183010414, "compression_ratio": 1.8517241379310345, "no_speech_prob": 0.0077915554866194725}, {"id": 534, "seek": 191488, "start": 1917.7600000000002, "end": 1922.16, "text": " doing i'm creating the structure myself whereas in neural networks the", "tokens": [50508, 884, 741, 478, 4084, 264, 3877, 2059, 9735, 294, 18161, 9590, 264, 50728], "temperature": 0.0, "avg_logprob": -0.1025030183010414, "compression_ratio": 1.8517241379310345, "no_speech_prob": 0.0077915554866194725}, {"id": 535, "seek": 191488, "start": 1922.16, "end": 1925.2800000000002, "text": " structure is implicit i don't know what the structure is", "tokens": [50728, 3877, 307, 26947, 741, 500, 380, 458, 437, 264, 3877, 307, 50884], "temperature": 0.0, "avg_logprob": -0.1025030183010414, "compression_ratio": 1.8517241379310345, "no_speech_prob": 0.0077915554866194725}, {"id": 536, "seek": 191488, "start": 1925.2800000000002, "end": 1927.92, "text": " well i think you're talking about you're contrasting two different kinds of tools", "tokens": [50884, 731, 741, 519, 291, 434, 1417, 466, 291, 434, 8712, 278, 732, 819, 3685, 295, 3873, 51016], "temperature": 0.0, "avg_logprob": -0.1025030183010414, "compression_ratio": 1.8517241379310345, "no_speech_prob": 0.0077915554866194725}, {"id": 537, "seek": 191488, "start": 1927.92, "end": 1931.6000000000001, "text": " there so the video editing tool is designed so that it follows your", "tokens": [51016, 456, 370, 264, 960, 10000, 2290, 307, 4761, 370, 300, 309, 10002, 428, 51200], "temperature": 0.0, "avg_logprob": -0.1025030183010414, "compression_ratio": 1.8517241379310345, "no_speech_prob": 0.0077915554866194725}, {"id": 538, "seek": 191488, "start": 1931.6000000000001, "end": 1935.2, "text": " instructions very precisely and you prefer one tool over another", "tokens": [51200, 9415, 588, 13402, 293, 291, 4382, 472, 2290, 670, 1071, 51380], "temperature": 0.0, "avg_logprob": -0.1025030183010414, "compression_ratio": 1.8517241379310345, "no_speech_prob": 0.0077915554866194725}, {"id": 539, "seek": 191488, "start": 1935.2, "end": 1938.72, "text": " perhaps because the interface is easier to use you get the results faster but", "tokens": [51380, 4317, 570, 264, 9226, 307, 3571, 281, 764, 291, 483, 264, 3542, 4663, 457, 51556], "temperature": 0.0, "avg_logprob": -0.1025030183010414, "compression_ratio": 1.8517241379310345, "no_speech_prob": 0.0077915554866194725}, {"id": 540, "seek": 191488, "start": 1938.72, "end": 1941.8400000000001, "text": " you have in your you've done the creativity you've designed this to", "tokens": [51556, 291, 362, 294, 428, 291, 600, 1096, 264, 12915, 291, 600, 4761, 341, 281, 51712], "temperature": 0.0, "avg_logprob": -0.1025030183010414, "compression_ratio": 1.8517241379310345, "no_speech_prob": 0.0077915554866194725}, {"id": 541, "seek": 194184, "start": 1941.84, "end": 1945.6, "text": " video edit that you want that you want to have and now the tool is to try to get", "tokens": [50364, 960, 8129, 300, 291, 528, 300, 291, 528, 281, 362, 293, 586, 264, 2290, 307, 281, 853, 281, 483, 50552], "temperature": 0.0, "avg_logprob": -0.06618862538724332, "compression_ratio": 1.8896103896103895, "no_speech_prob": 0.012557923793792725}, {"id": 542, "seek": 194184, "start": 1945.6, "end": 1948.56, "text": " you to that as fast as possible as accurately as possible", "tokens": [50552, 291, 281, 300, 382, 2370, 382, 1944, 382, 20095, 382, 1944, 50700], "temperature": 0.0, "avg_logprob": -0.06618862538724332, "compression_ratio": 1.8896103896103895, "no_speech_prob": 0.012557923793792725}, {"id": 543, "seek": 194184, "start": 1948.56, "end": 1951.52, "text": " but sometimes we need more than that sometimes you know if you've got right", "tokens": [50700, 457, 2171, 321, 643, 544, 813, 300, 2171, 291, 458, 498, 291, 600, 658, 558, 50848], "temperature": 0.0, "avg_logprob": -0.06618862538724332, "compression_ratio": 1.8896103896103895, "no_speech_prob": 0.012557923793792725}, {"id": 544, "seek": 194184, "start": 1951.52, "end": 1953.28, "text": " as block and you don't know where to begin", "tokens": [50848, 382, 3461, 293, 291, 500, 380, 458, 689, 281, 1841, 50936], "temperature": 0.0, "avg_logprob": -0.06618862538724332, "compression_ratio": 1.8896103896103895, "no_speech_prob": 0.012557923793792725}, {"id": 545, "seek": 194184, "start": 1953.28, "end": 1956.9599999999998, "text": " having a tool like GPT-4 could be very powerful you're not you're not", "tokens": [50936, 1419, 257, 2290, 411, 26039, 51, 12, 19, 727, 312, 588, 4005, 291, 434, 406, 291, 434, 406, 51120], "temperature": 0.0, "avg_logprob": -0.06618862538724332, "compression_ratio": 1.8896103896103895, "no_speech_prob": 0.012557923793792725}, {"id": 546, "seek": 194184, "start": 1956.9599999999998, "end": 1960.3999999999999, "text": " delegating the entire process to the technology you're working", "tokens": [51120, 15824, 990, 264, 2302, 1399, 281, 264, 2899, 291, 434, 1364, 51292], "temperature": 0.0, "avg_logprob": -0.06618862538724332, "compression_ratio": 1.8896103896103895, "no_speech_prob": 0.012557923793792725}, {"id": 547, "seek": 194184, "start": 1960.3999999999999, "end": 1963.6, "text": " with it as a as a co-pilot as an assistant", "tokens": [51292, 365, 309, 382, 257, 382, 257, 598, 12, 79, 31516, 382, 364, 10994, 51452], "temperature": 0.0, "avg_logprob": -0.06618862538724332, "compression_ratio": 1.8896103896103895, "no_speech_prob": 0.012557923793792725}, {"id": 548, "seek": 194184, "start": 1963.6, "end": 1967.4399999999998, "text": " that can for sure help you with that creative process it will come up with", "tokens": [51452, 300, 393, 337, 988, 854, 291, 365, 300, 5880, 1399, 309, 486, 808, 493, 365, 51644], "temperature": 0.0, "avg_logprob": -0.06618862538724332, "compression_ratio": 1.8896103896103895, "no_speech_prob": 0.012557923793792725}, {"id": 549, "seek": 194184, "start": 1967.4399999999998, "end": 1970.8, "text": " with crazy things and most of them you may not like but maybe one of them", "tokens": [51644, 365, 3219, 721, 293, 881, 295, 552, 291, 815, 406, 411, 457, 1310, 472, 295, 552, 51812], "temperature": 0.0, "avg_logprob": -0.06618862538724332, "compression_ratio": 1.8896103896103895, "no_speech_prob": 0.012557923793792725}, {"id": 550, "seek": 197080, "start": 1970.8, "end": 1973.68, "text": " you don't like it either but it causes you to think about something that you", "tokens": [50364, 291, 500, 380, 411, 309, 2139, 457, 309, 7700, 291, 281, 519, 466, 746, 300, 291, 50508], "temperature": 0.0, "avg_logprob": -0.0866072287926307, "compression_ratio": 1.9421768707482994, "no_speech_prob": 0.00377610488794744}, {"id": 551, "seek": 197080, "start": 1973.68, "end": 1977.52, "text": " would otherwise not have thought of and so the two working together", "tokens": [50508, 576, 5911, 406, 362, 1194, 295, 293, 370, 264, 732, 1364, 1214, 50700], "temperature": 0.0, "avg_logprob": -0.0866072287926307, "compression_ratio": 1.9421768707482994, "no_speech_prob": 0.00377610488794744}, {"id": 552, "seek": 197080, "start": 1977.52, "end": 1981.76, "text": " can surely be more creative so i think certainly as a working in unison with", "tokens": [50700, 393, 11468, 312, 544, 5880, 370, 741, 519, 3297, 382, 257, 1364, 294, 517, 2770, 365, 50912], "temperature": 0.0, "avg_logprob": -0.0866072287926307, "compression_ratio": 1.9421768707482994, "no_speech_prob": 0.00377610488794744}, {"id": 553, "seek": 197080, "start": 1981.76, "end": 1984.24, "text": " humans it certainly enhances creativity so that's", "tokens": [50912, 6255, 309, 3297, 46628, 12915, 370, 300, 311, 51036], "temperature": 0.0, "avg_logprob": -0.0866072287926307, "compression_ratio": 1.9421768707482994, "no_speech_prob": 0.00377610488794744}, {"id": 554, "seek": 197080, "start": 1984.24, "end": 1987.68, "text": " certainly my experience i think there's no doubt about that but also if you", "tokens": [51036, 3297, 452, 1752, 741, 519, 456, 311, 572, 6385, 466, 300, 457, 611, 498, 291, 51208], "temperature": 0.0, "avg_logprob": -0.0866072287926307, "compression_ratio": 1.9421768707482994, "no_speech_prob": 0.00377610488794744}, {"id": 555, "seek": 197080, "start": 1987.68, "end": 1990.6399999999999, "text": " think about let's take a simple example that i think most people relate to which", "tokens": [51208, 519, 466, 718, 311, 747, 257, 2199, 1365, 300, 741, 519, 881, 561, 10961, 281, 597, 51356], "temperature": 0.0, "avg_logprob": -0.0866072287926307, "compression_ratio": 1.9421768707482994, "no_speech_prob": 0.00377610488794744}, {"id": 556, "seek": 197080, "start": 1990.6399999999999, "end": 1993.84, "text": " is which is image generation you're giving a talk and you want some", "tokens": [51356, 307, 597, 307, 3256, 5125, 291, 434, 2902, 257, 751, 293, 291, 528, 512, 51516], "temperature": 0.0, "avg_logprob": -0.0866072287926307, "compression_ratio": 1.9421768707482994, "no_speech_prob": 0.00377610488794744}, {"id": 557, "seek": 197080, "start": 1993.84, "end": 1998.6399999999999, "text": " image to illustrate the talk and you know you could go to stock images and", "tokens": [51516, 3256, 281, 23221, 264, 751, 293, 291, 458, 291, 727, 352, 281, 4127, 5267, 293, 51756], "temperature": 0.0, "avg_logprob": -0.0866072287926307, "compression_ratio": 1.9421768707482994, "no_speech_prob": 0.00377610488794744}, {"id": 558, "seek": 199864, "start": 1998.72, "end": 2003.2, "text": " you know it's a fixed set and you know you can't easily adjust it or you", "tokens": [50368, 291, 458, 309, 311, 257, 6806, 992, 293, 291, 458, 291, 393, 380, 3612, 4369, 309, 420, 291, 50592], "temperature": 0.0, "avg_logprob": -0.11194810788493512, "compression_ratio": 1.9042145593869733, "no_speech_prob": 0.00632046815007925}, {"id": 559, "seek": 199864, "start": 2003.2, "end": 2007.5200000000002, "text": " or you go to editing images yourself that's a sort of slow and painful process", "tokens": [50592, 420, 291, 352, 281, 10000, 5267, 1803, 300, 311, 257, 1333, 295, 2964, 293, 11697, 1399, 50808], "temperature": 0.0, "avg_logprob": -0.11194810788493512, "compression_ratio": 1.9042145593869733, "no_speech_prob": 0.00632046815007925}, {"id": 560, "seek": 199864, "start": 2007.5200000000002, "end": 2011.1200000000001, "text": " but now you can just with a simple prompt you know you can get a a bunch of", "tokens": [50808, 457, 586, 291, 393, 445, 365, 257, 2199, 12391, 291, 458, 291, 393, 483, 257, 257, 3840, 295, 50988], "temperature": 0.0, "avg_logprob": -0.11194810788493512, "compression_ratio": 1.9042145593869733, "no_speech_prob": 0.00632046815007925}, {"id": 561, "seek": 199864, "start": 2011.1200000000001, "end": 2014.0800000000002, "text": " examples and if one of those isn't quite what you like you can", "tokens": [50988, 5110, 293, 498, 472, 295, 729, 1943, 380, 1596, 437, 291, 411, 291, 393, 51136], "temperature": 0.0, "avg_logprob": -0.11194810788493512, "compression_ratio": 1.9042145593869733, "no_speech_prob": 0.00632046815007925}, {"id": 562, "seek": 199864, "start": 2014.0800000000002, "end": 2017.92, "text": " alter the prompt and and fine tune it and it now becomes that", "tokens": [51136, 11337, 264, 12391, 293, 293, 2489, 10864, 309, 293, 309, 586, 3643, 300, 51328], "temperature": 0.0, "avg_logprob": -0.11194810788493512, "compression_ratio": 1.9042145593869733, "no_speech_prob": 0.00632046815007925}, {"id": 563, "seek": 199864, "start": 2017.92, "end": 2022.16, "text": " that process which is a creative process and you can still say the human is in", "tokens": [51328, 300, 1399, 597, 307, 257, 5880, 1399, 293, 291, 393, 920, 584, 264, 1952, 307, 294, 51540], "temperature": 0.0, "avg_logprob": -0.11194810788493512, "compression_ratio": 1.9042145593869733, "no_speech_prob": 0.00632046815007925}, {"id": 564, "seek": 199864, "start": 2022.16, "end": 2026.0, "text": " the driving seat but the overall creativity is certainly enhanced", "tokens": [51540, 264, 4840, 6121, 457, 264, 4787, 12915, 307, 3297, 21191, 51732], "temperature": 0.0, "avg_logprob": -0.11194810788493512, "compression_ratio": 1.9042145593869733, "no_speech_prob": 0.00632046815007925}, {"id": 565, "seek": 202600, "start": 2026.0, "end": 2030.0, "text": " and when you take a text prompt and and the machine produces this beautiful", "tokens": [50364, 293, 562, 291, 747, 257, 2487, 12391, 293, 293, 264, 3479, 14725, 341, 2238, 50564], "temperature": 0.0, "avg_logprob": -0.08294901326924813, "compression_ratio": 1.8078291814946619, "no_speech_prob": 0.001942819799296558}, {"id": 566, "seek": 202600, "start": 2030.0, "end": 2034.56, "text": " photorealistic image i mean how many of us weren't absolutely blown away", "tokens": [50564, 2409, 418, 304, 3142, 3256, 741, 914, 577, 867, 295, 505, 4999, 380, 3122, 16479, 1314, 50792], "temperature": 0.0, "avg_logprob": -0.08294901326924813, "compression_ratio": 1.8078291814946619, "no_speech_prob": 0.001942819799296558}, {"id": 567, "seek": 202600, "start": 2034.56, "end": 2037.76, "text": " by the incredible advances in generative AI of the last", "tokens": [50792, 538, 264, 4651, 25297, 294, 1337, 1166, 7318, 295, 264, 1036, 50952], "temperature": 0.0, "avg_logprob": -0.08294901326924813, "compression_ratio": 1.8078291814946619, "no_speech_prob": 0.001942819799296558}, {"id": 568, "seek": 202600, "start": 2037.76, "end": 2042.56, "text": " you know the last decade why would you not call that creative if a human being", "tokens": [50952, 291, 458, 264, 1036, 10378, 983, 576, 291, 406, 818, 300, 5880, 498, 257, 1952, 885, 51192], "temperature": 0.0, "avg_logprob": -0.08294901326924813, "compression_ratio": 1.8078291814946619, "no_speech_prob": 0.001942819799296558}, {"id": 569, "seek": 202600, "start": 2042.56, "end": 2046.16, "text": " did it you would call it creative why why are we not allowing the machine", "tokens": [51192, 630, 309, 291, 576, 818, 309, 5880, 983, 983, 366, 321, 406, 8293, 264, 3479, 51372], "temperature": 0.0, "avg_logprob": -0.08294901326924813, "compression_ratio": 1.8078291814946619, "no_speech_prob": 0.001942819799296558}, {"id": 570, "seek": 202600, "start": 2046.16, "end": 2049.52, "text": " to be described as creative that's the piece that i don't that i don't quite", "tokens": [51372, 281, 312, 7619, 382, 5880, 300, 311, 264, 2522, 300, 741, 500, 380, 300, 741, 500, 380, 1596, 51540], "temperature": 0.0, "avg_logprob": -0.08294901326924813, "compression_ratio": 1.8078291814946619, "no_speech_prob": 0.001942819799296558}, {"id": 571, "seek": 202600, "start": 2049.52, "end": 2053.28, "text": " understand so you could argue that creativity is just pure novelty of the", "tokens": [51540, 1223, 370, 291, 727, 9695, 300, 12915, 307, 445, 6075, 44805, 295, 264, 51728], "temperature": 0.0, "avg_logprob": -0.08294901326924813, "compression_ratio": 1.8078291814946619, "no_speech_prob": 0.001942819799296558}, {"id": 572, "seek": 205328, "start": 2053.28, "end": 2056.1600000000003, "text": " artifact so it's just how much entropy is in the artifact", "tokens": [50364, 34806, 370, 309, 311, 445, 577, 709, 30867, 307, 294, 264, 34806, 50508], "temperature": 0.0, "avg_logprob": -0.10981542269388835, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.010568884201347828}, {"id": 573, "seek": 205328, "start": 2056.1600000000003, "end": 2060.96, "text": " but you could you could think of GPT4 pros as being a kind of", "tokens": [50508, 457, 291, 727, 291, 727, 519, 295, 26039, 51, 19, 6267, 382, 885, 257, 733, 295, 50748], "temperature": 0.0, "avg_logprob": -0.10981542269388835, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.010568884201347828}, {"id": 574, "seek": 205328, "start": 2060.96, "end": 2063.84, "text": " category so there's a lot of variants in there", "tokens": [50748, 7719, 370, 456, 311, 257, 688, 295, 21669, 294, 456, 50892], "temperature": 0.0, "avg_logprob": -0.10981542269388835, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.010568884201347828}, {"id": 575, "seek": 205328, "start": 2063.84, "end": 2067.76, "text": " but there are also certain motifs and and now when people see the motifs they", "tokens": [50892, 457, 456, 366, 611, 1629, 2184, 18290, 293, 293, 586, 562, 561, 536, 264, 2184, 18290, 436, 51088], "temperature": 0.0, "avg_logprob": -0.10981542269388835, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.010568884201347828}, {"id": 576, "seek": 205328, "start": 2067.76, "end": 2071.0400000000004, "text": " say oh i've seen that a million times before so i did think it was novel and", "tokens": [51088, 584, 1954, 741, 600, 1612, 300, 257, 2459, 1413, 949, 370, 741, 630, 519, 309, 390, 7613, 293, 51252], "temperature": 0.0, "avg_logprob": -0.10981542269388835, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.010568884201347828}, {"id": 577, "seek": 205328, "start": 2071.0400000000004, "end": 2075.6800000000003, "text": " interesting and now i don't and but this is the thing so now when i'm", "tokens": [51252, 1880, 293, 586, 741, 500, 380, 293, 457, 341, 307, 264, 551, 370, 586, 562, 741, 478, 51484], "temperature": 0.0, "avg_logprob": -0.10981542269388835, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.010568884201347828}, {"id": 578, "seek": 205328, "start": 2075.6800000000003, "end": 2079.6000000000004, "text": " writing blog posts and stuff like that i'm deliberately trying to do something", "tokens": [51484, 3579, 6968, 12300, 293, 1507, 411, 300, 741, 478, 23506, 1382, 281, 360, 746, 51680], "temperature": 0.0, "avg_logprob": -0.10981542269388835, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.010568884201347828}, {"id": 579, "seek": 207960, "start": 2079.6, "end": 2083.04, "text": " genuinely creative to me you know it's it's almost like the intrinsic", "tokens": [50364, 17839, 5880, 281, 385, 291, 458, 309, 311, 309, 311, 1920, 411, 264, 35698, 50536], "temperature": 0.0, "avg_logprob": -0.1141972175011268, "compression_ratio": 1.8365758754863812, "no_speech_prob": 0.007961644791066647}, {"id": 580, "seek": 207960, "start": 2083.04, "end": 2087.04, "text": " creativity isn't important i don't want people to think that i use GPT4", "tokens": [50536, 12915, 1943, 380, 1021, 741, 500, 380, 528, 561, 281, 519, 300, 741, 764, 26039, 51, 19, 50736], "temperature": 0.0, "avg_logprob": -0.1141972175011268, "compression_ratio": 1.8365758754863812, "no_speech_prob": 0.007961644791066647}, {"id": 581, "seek": 207960, "start": 2087.04, "end": 2091.36, "text": " so that's driving it do you see what i mean yeah so in clearly creativity is", "tokens": [50736, 370, 300, 311, 4840, 309, 360, 291, 536, 437, 741, 914, 1338, 370, 294, 4448, 12915, 307, 50952], "temperature": 0.0, "avg_logprob": -0.1141972175011268, "compression_ratio": 1.8365758754863812, "no_speech_prob": 0.007961644791066647}, {"id": 582, "seek": 207960, "start": 2091.36, "end": 2095.68, "text": " about novelty and novelty is you know what we desire here", "tokens": [50952, 466, 44805, 293, 44805, 307, 291, 458, 437, 321, 7516, 510, 51168], "temperature": 0.0, "avg_logprob": -0.1141972175011268, "compression_ratio": 1.8365758754863812, "no_speech_prob": 0.007961644791066647}, {"id": 583, "seek": 207960, "start": 2095.68, "end": 2101.44, "text": " but whether that novelty has value or not that's a subjective opinion in your", "tokens": [51168, 457, 1968, 300, 44805, 575, 2158, 420, 406, 300, 311, 257, 25972, 4800, 294, 428, 51456], "temperature": 0.0, "avg_logprob": -0.1141972175011268, "compression_ratio": 1.8365758754863812, "no_speech_prob": 0.007961644791066647}, {"id": 584, "seek": 207960, "start": 2101.44, "end": 2104.7999999999997, "text": " case it's whether it's achieving the the goals that you desire", "tokens": [51456, 1389, 309, 311, 1968, 309, 311, 19626, 264, 264, 5493, 300, 291, 7516, 51624], "temperature": 0.0, "avg_logprob": -0.1141972175011268, "compression_ratio": 1.8365758754863812, "no_speech_prob": 0.007961644791066647}, {"id": 585, "seek": 207960, "start": 2104.7999999999997, "end": 2108.0, "text": " so i think there is no doubt that it's even if you say", "tokens": [51624, 370, 741, 519, 456, 307, 572, 6385, 300, 309, 311, 754, 498, 291, 584, 51784], "temperature": 0.0, "avg_logprob": -0.1141972175011268, "compression_ratio": 1.8365758754863812, "no_speech_prob": 0.007961644791066647}, {"id": 586, "seek": 210800, "start": 2108.0, "end": 2110.96, "text": " we're just taking existing ideas and combining them in new ways", "tokens": [50364, 321, 434, 445, 1940, 6741, 3487, 293, 21928, 552, 294, 777, 2098, 50512], "temperature": 0.0, "avg_logprob": -0.051210639922599485, "compression_ratio": 2.0757575757575757, "no_speech_prob": 0.0077478764578700066}, {"id": 587, "seek": 210800, "start": 2110.96, "end": 2114.4, "text": " everything that humans do or i think builds on the work of", "tokens": [50512, 1203, 300, 6255, 360, 420, 741, 519, 15182, 322, 264, 589, 295, 50684], "temperature": 0.0, "avg_logprob": -0.051210639922599485, "compression_ratio": 2.0757575757575757, "no_speech_prob": 0.0077478764578700066}, {"id": 588, "seek": 210800, "start": 2114.4, "end": 2118.0, "text": " their own previous experience and on the work of others and i think that's", "tokens": [50684, 641, 1065, 3894, 1752, 293, 322, 264, 589, 295, 2357, 293, 741, 519, 300, 311, 50864], "temperature": 0.0, "avg_logprob": -0.051210639922599485, "compression_ratio": 2.0757575757575757, "no_speech_prob": 0.0077478764578700066}, {"id": 589, "seek": 210800, "start": 2118.0, "end": 2121.36, "text": " absolutely fine that's a wonderful thing about the humanity is that we", "tokens": [50864, 3122, 2489, 300, 311, 257, 3715, 551, 466, 264, 10243, 307, 300, 321, 51032], "temperature": 0.0, "avg_logprob": -0.051210639922599485, "compression_ratio": 2.0757575757575757, "no_speech_prob": 0.0077478764578700066}, {"id": 590, "seek": 210800, "start": 2121.36, "end": 2124.88, "text": " from generation to generation we build upon the work of what's gone before", "tokens": [51032, 490, 5125, 281, 5125, 321, 1322, 3564, 264, 589, 295, 437, 311, 2780, 949, 51208], "temperature": 0.0, "avg_logprob": -0.051210639922599485, "compression_ratio": 2.0757575757575757, "no_speech_prob": 0.0077478764578700066}, {"id": 591, "seek": 210800, "start": 2124.88, "end": 2128.4, "text": " and the machines that we build now are heavily dependent on", "tokens": [51208, 293, 264, 8379, 300, 321, 1322, 586, 366, 10950, 12334, 322, 51384], "temperature": 0.0, "avg_logprob": -0.051210639922599485, "compression_ratio": 2.0757575757575757, "no_speech_prob": 0.0077478764578700066}, {"id": 592, "seek": 210800, "start": 2128.4, "end": 2131.76, "text": " the creativity and the work of humans before because they learn from humans", "tokens": [51384, 264, 12915, 293, 264, 589, 295, 6255, 949, 570, 436, 1466, 490, 6255, 51552], "temperature": 0.0, "avg_logprob": -0.051210639922599485, "compression_ratio": 2.0757575757575757, "no_speech_prob": 0.0077478764578700066}, {"id": 593, "seek": 210800, "start": 2131.76, "end": 2134.64, "text": " they're designed by humans and i think that's absolutely fine it's a", "tokens": [51552, 436, 434, 4761, 538, 6255, 293, 741, 519, 300, 311, 3122, 2489, 309, 311, 257, 51696], "temperature": 0.0, "avg_logprob": -0.051210639922599485, "compression_ratio": 2.0757575757575757, "no_speech_prob": 0.0077478764578700066}, {"id": 594, "seek": 213464, "start": 2134.64, "end": 2137.2799999999997, "text": " wonderful thing and they add to the sum total of human", "tokens": [50364, 3715, 551, 293, 436, 909, 281, 264, 2408, 3217, 295, 1952, 50496], "temperature": 0.0, "avg_logprob": -0.14689212578993577, "compression_ratio": 1.7634854771784232, "no_speech_prob": 0.012477723881602287}, {"id": 595, "seek": 213464, "start": 2137.2799999999997, "end": 2139.3599999999997, "text": " creativity and that that's a wonderful thing", "tokens": [50496, 12915, 293, 300, 300, 311, 257, 3715, 551, 50600], "temperature": 0.0, "avg_logprob": -0.14689212578993577, "compression_ratio": 1.7634854771784232, "no_speech_prob": 0.012477723881602287}, {"id": 596, "seek": 213464, "start": 2139.3599999999997, "end": 2145.92, "text": " Chris you wrote a really beautiful book and you wrote it with your son", "tokens": [50600, 6688, 291, 4114, 257, 534, 2238, 1446, 293, 291, 4114, 309, 365, 428, 1872, 50928], "temperature": 0.0, "avg_logprob": -0.14689212578993577, "compression_ratio": 1.7634854771784232, "no_speech_prob": 0.012477723881602287}, {"id": 597, "seek": 213464, "start": 2145.92, "end": 2151.12, "text": " Hugh and there was a picture of Hugh i think in the introduction of of PRML", "tokens": [50928, 25893, 293, 456, 390, 257, 3036, 295, 25893, 741, 519, 294, 264, 9339, 295, 295, 11568, 12683, 51188], "temperature": 0.0, "avg_logprob": -0.14689212578993577, "compression_ratio": 1.7634854771784232, "no_speech_prob": 0.012477723881602287}, {"id": 598, "seek": 213464, "start": 2151.12, "end": 2155.2, "text": " and i guess part of what i want to understand is is deep learning is a", "tokens": [51188, 293, 741, 2041, 644, 295, 437, 741, 528, 281, 1223, 307, 307, 2452, 2539, 307, 257, 51392], "temperature": 0.0, "avg_logprob": -0.14689212578993577, "compression_ratio": 1.7634854771784232, "no_speech_prob": 0.012477723881602287}, {"id": 599, "seek": 213464, "start": 2155.2, "end": 2158.4, "text": " huge field i mean what was the thought process and", "tokens": [51392, 2603, 2519, 741, 914, 437, 390, 264, 1194, 1399, 293, 51552], "temperature": 0.0, "avg_logprob": -0.14689212578993577, "compression_ratio": 1.7634854771784232, "no_speech_prob": 0.012477723881602287}, {"id": 600, "seek": 213464, "start": 2158.4, "end": 2162.4, "text": " how did you decide what to tackle and what not to tackle", "tokens": [51552, 577, 630, 291, 4536, 437, 281, 14896, 293, 437, 406, 281, 14896, 51752], "temperature": 0.0, "avg_logprob": -0.14689212578993577, "compression_ratio": 1.7634854771784232, "no_speech_prob": 0.012477723881602287}, {"id": 601, "seek": 216240, "start": 2162.4, "end": 2165.84, "text": " great questions there's an interesting story behind the the new deep learning", "tokens": [50364, 869, 1651, 456, 311, 364, 1880, 1657, 2261, 264, 264, 777, 2452, 2539, 50536], "temperature": 0.0, "avg_logprob": -0.08231634660200639, "compression_ratio": 1.708185053380783, "no_speech_prob": 0.0033447600435465574}, {"id": 602, "seek": 216240, "start": 2165.84, "end": 2170.8, "text": " book which is that PRML was written in 2006", "tokens": [50536, 1446, 597, 307, 300, 11568, 12683, 390, 3720, 294, 14062, 50784], "temperature": 0.0, "avg_logprob": -0.08231634660200639, "compression_ratio": 1.708185053380783, "no_speech_prob": 0.0033447600435465574}, {"id": 603, "seek": 216240, "start": 2170.8, "end": 2174.4, "text": " it predates the deep learning revolution and what has constantly surprised", "tokens": [50784, 309, 3852, 1024, 264, 2452, 2539, 8894, 293, 437, 575, 6460, 6100, 50964], "temperature": 0.0, "avg_logprob": -0.08231634660200639, "compression_ratio": 1.708185053380783, "no_speech_prob": 0.0033447600435465574}, {"id": 604, "seek": 216240, "start": 2174.4, "end": 2178.48, "text": " me is just how popular it's remained in spite of the fact that in one sense it's", "tokens": [50964, 385, 307, 445, 577, 3743, 309, 311, 12780, 294, 22794, 295, 264, 1186, 300, 294, 472, 2020, 309, 311, 51168], "temperature": 0.0, "avg_logprob": -0.08231634660200639, "compression_ratio": 1.708185053380783, "no_speech_prob": 0.0033447600435465574}, {"id": 605, "seek": 216240, "start": 2178.48, "end": 2181.28, "text": " massively out of date because it does has no mention", "tokens": [51168, 29379, 484, 295, 4002, 570, 309, 775, 575, 572, 2152, 51308], "temperature": 0.0, "avg_logprob": -0.08231634660200639, "compression_ratio": 1.708185053380783, "no_speech_prob": 0.0033447600435465574}, {"id": 606, "seek": 216240, "start": 2181.28, "end": 2184.7200000000003, "text": " of the most important thing in the field of machine learning and so i've long", "tokens": [51308, 295, 264, 881, 1021, 551, 294, 264, 2519, 295, 3479, 2539, 293, 370, 741, 600, 938, 51480], "temperature": 0.0, "avg_logprob": -0.08231634660200639, "compression_ratio": 1.708185053380783, "no_speech_prob": 0.0033447600435465574}, {"id": 607, "seek": 216240, "start": 2184.7200000000003, "end": 2188.08, "text": " felt it was time to update the book produce the second edition add some", "tokens": [51480, 2762, 309, 390, 565, 281, 5623, 264, 1446, 5258, 264, 1150, 11377, 909, 512, 51648], "temperature": 0.0, "avg_logprob": -0.08231634660200639, "compression_ratio": 1.708185053380783, "no_speech_prob": 0.0033447600435465574}, {"id": 608, "seek": 218808, "start": 2188.08, "end": 2192.4, "text": " material on deep learning but life is busy and you know", "tokens": [50364, 2527, 322, 2452, 2539, 457, 993, 307, 5856, 293, 291, 458, 50580], "temperature": 0.0, "avg_logprob": -0.0875938960484096, "compression_ratio": 1.7355072463768115, "no_speech_prob": 0.006193881388753653}, {"id": 609, "seek": 218808, "start": 2192.4, "end": 2196.0, "text": " anybody who's ever written a book will tell you that it takes way more effort", "tokens": [50580, 4472, 567, 311, 1562, 3720, 257, 1446, 486, 980, 291, 300, 309, 2516, 636, 544, 4630, 50760], "temperature": 0.0, "avg_logprob": -0.0875938960484096, "compression_ratio": 1.7355072463768115, "no_speech_prob": 0.006193881388753653}, {"id": 610, "seek": 218808, "start": 2196.0, "end": 2199.2, "text": " than you can possibly imagine if you've not actually had that experience", "tokens": [50760, 813, 291, 393, 6264, 3811, 498, 291, 600, 406, 767, 632, 300, 1752, 50920], "temperature": 0.0, "avg_logprob": -0.0875938960484096, "compression_ratio": 1.7355072463768115, "no_speech_prob": 0.006193881388753653}, {"id": 611, "seek": 218808, "start": 2199.2, "end": 2203.36, "text": " and so i never really got around to doing it and along came the covid pandemic", "tokens": [50920, 293, 370, 741, 1128, 534, 658, 926, 281, 884, 309, 293, 2051, 1361, 264, 25616, 5388, 51128], "temperature": 0.0, "avg_logprob": -0.0875938960484096, "compression_ratio": 1.7355072463768115, "no_speech_prob": 0.006193881388753653}, {"id": 612, "seek": 218808, "start": 2203.36, "end": 2207.12, "text": " and we all went into lockdown and i feel like it was one of the very", "tokens": [51128, 293, 321, 439, 1437, 666, 17267, 293, 741, 841, 411, 309, 390, 472, 295, 264, 588, 51316], "temperature": 0.0, "avg_logprob": -0.0875938960484096, "compression_ratio": 1.7355072463768115, "no_speech_prob": 0.006193881388753653}, {"id": 613, "seek": 218808, "start": 2207.12, "end": 2210.3199999999997, "text": " privileged people in that lockdown we were we were locked down together as a", "tokens": [51316, 25293, 561, 294, 300, 17267, 321, 645, 321, 645, 9376, 760, 1214, 382, 257, 51476], "temperature": 0.0, "avg_logprob": -0.0875938960484096, "compression_ratio": 1.7355072463768115, "no_speech_prob": 0.006193881388753653}, {"id": 614, "seek": 218808, "start": 2210.3199999999997, "end": 2214.96, "text": " family in in Cambridge and you know when you're", "tokens": [51476, 1605, 294, 294, 24876, 293, 291, 458, 562, 291, 434, 51708], "temperature": 0.0, "avg_logprob": -0.0875938960484096, "compression_ratio": 1.7355072463768115, "no_speech_prob": 0.006193881388753653}, {"id": 615, "seek": 221496, "start": 2214.96, "end": 2218.48, "text": " locked down at home for several months you kind of need a project and", "tokens": [50364, 9376, 760, 412, 1280, 337, 2940, 2493, 291, 733, 295, 643, 257, 1716, 293, 50540], "temperature": 0.0, "avg_logprob": -0.09958119252148796, "compression_ratio": 1.7861635220125787, "no_speech_prob": 0.0026522234547883272}, {"id": 616, "seek": 221496, "start": 2218.48, "end": 2221.12, "text": " and i thought this would be a great time to think about a second edition of the", "tokens": [50540, 293, 741, 1194, 341, 576, 312, 257, 869, 565, 281, 519, 466, 257, 1150, 11377, 295, 264, 50672], "temperature": 0.0, "avg_logprob": -0.09958119252148796, "compression_ratio": 1.7861635220125787, "no_speech_prob": 0.0026522234547883272}, {"id": 617, "seek": 221496, "start": 2221.12, "end": 2224.48, "text": " PRML book because you know what what else you're going to do in lockdown and it", "tokens": [50672, 11568, 12683, 1446, 570, 291, 458, 437, 437, 1646, 291, 434, 516, 281, 360, 294, 17267, 293, 309, 50840], "temperature": 0.0, "avg_logprob": -0.09958119252148796, "compression_ratio": 1.7861635220125787, "no_speech_prob": 0.0026522234547883272}, {"id": 618, "seek": 221496, "start": 2224.48, "end": 2227.76, "text": " became a project with my son because he was he was with me", "tokens": [50840, 3062, 257, 1716, 365, 452, 1872, 570, 415, 390, 415, 390, 365, 385, 51004], "temperature": 0.0, "avg_logprob": -0.09958119252148796, "compression_ratio": 1.7861635220125787, "no_speech_prob": 0.0026522234547883272}, {"id": 619, "seek": 221496, "start": 2227.76, "end": 2232.32, "text": " by this time he he'd gained a lot of experience master's degree in machine", "tokens": [51004, 538, 341, 565, 415, 415, 1116, 12634, 257, 688, 295, 1752, 4505, 311, 4314, 294, 3479, 51232], "temperature": 0.0, "avg_logprob": -0.09958119252148796, "compression_ratio": 1.7861635220125787, "no_speech_prob": 0.0026522234547883272}, {"id": 620, "seek": 221496, "start": 2232.32, "end": 2235.52, "text": " learning and been working in autonomous vehicle technology", "tokens": [51232, 2539, 293, 668, 1364, 294, 23797, 5864, 2899, 51392], "temperature": 0.0, "avg_logprob": -0.09958119252148796, "compression_ratio": 1.7861635220125787, "no_speech_prob": 0.0026522234547883272}, {"id": 621, "seek": 221496, "start": 2235.52, "end": 2238.16, "text": " and in a sense he had a lot more practical hands-on experience with deep", "tokens": [51392, 293, 294, 257, 2020, 415, 632, 257, 688, 544, 8496, 2377, 12, 266, 1752, 365, 2452, 51524], "temperature": 0.0, "avg_logprob": -0.09958119252148796, "compression_ratio": 1.7861635220125787, "no_speech_prob": 0.0026522234547883272}, {"id": 622, "seek": 221496, "start": 2238.16, "end": 2242.16, "text": " learning than than i did at that point and so we started this as a joint", "tokens": [51524, 2539, 813, 813, 741, 630, 412, 300, 935, 293, 370, 321, 1409, 341, 382, 257, 7225, 51724], "temperature": 0.0, "avg_logprob": -0.09958119252148796, "compression_ratio": 1.7861635220125787, "no_speech_prob": 0.0026522234547883272}, {"id": 623, "seek": 224216, "start": 2242.16, "end": 2246.0, "text": " project but we very quickly realized that what was needed was not", "tokens": [50364, 1716, 457, 321, 588, 2661, 5334, 300, 437, 390, 2978, 390, 406, 50556], "temperature": 0.0, "avg_logprob": -0.08206511300707621, "compression_ratio": 1.7594501718213058, "no_speech_prob": 0.020959656685590744}, {"id": 624, "seek": 224216, "start": 2246.0, "end": 2250.24, "text": " a couple of extra chapters on PRML but rather the whole field had changed so", "tokens": [50556, 257, 1916, 295, 2857, 20013, 322, 11568, 12683, 457, 2831, 264, 1379, 2519, 632, 3105, 370, 50768], "temperature": 0.0, "avg_logprob": -0.08206511300707621, "compression_ratio": 1.7594501718213058, "no_speech_prob": 0.020959656685590744}, {"id": 625, "seek": 224216, "start": 2250.24, "end": 2253.44, "text": " much and also we didn't want to write a book we", "tokens": [50768, 709, 293, 611, 321, 994, 380, 528, 281, 2464, 257, 1446, 321, 50928], "temperature": 0.0, "avg_logprob": -0.08206511300707621, "compression_ratio": 1.7594501718213058, "no_speech_prob": 0.020959656685590744}, {"id": 626, "seek": 224216, "start": 2253.44, "end": 2256.7999999999997, "text": " were just accumulated more and more material it would just become a huge", "tokens": [50928, 645, 445, 31346, 544, 293, 544, 2527, 309, 576, 445, 1813, 257, 2603, 51096], "temperature": 0.0, "avg_logprob": -0.08206511300707621, "compression_ratio": 1.7594501718213058, "no_speech_prob": 0.020959656685590744}, {"id": 627, "seek": 224216, "start": 2256.7999999999997, "end": 2260.96, "text": " a huge tome the value of a book i think is", "tokens": [51096, 257, 2603, 281, 1398, 264, 2158, 295, 257, 1446, 741, 519, 307, 51304], "temperature": 0.0, "avg_logprob": -0.08206511300707621, "compression_ratio": 1.7594501718213058, "no_speech_prob": 0.020959656685590744}, {"id": 628, "seek": 224216, "start": 2260.96, "end": 2265.3599999999997, "text": " is in the distillation is in the way it draws your attention to a subset of", "tokens": [51304, 307, 294, 264, 42923, 399, 307, 294, 264, 636, 309, 20045, 428, 3202, 281, 257, 25993, 295, 51524], "temperature": 0.0, "avg_logprob": -0.08206511300707621, "compression_ratio": 1.7594501718213058, "no_speech_prob": 0.020959656685590744}, {"id": 629, "seek": 224216, "start": 2265.3599999999997, "end": 2268.16, "text": " specific things this is the small set of things that you really need to", "tokens": [51524, 2685, 721, 341, 307, 264, 1359, 992, 295, 721, 300, 291, 534, 643, 281, 51664], "temperature": 0.0, "avg_logprob": -0.08206511300707621, "compression_ratio": 1.7594501718213058, "no_speech_prob": 0.020959656685590744}, {"id": 630, "seek": 224216, "start": 2268.16, "end": 2271.2, "text": " understand and then you're quick to go off into the field", "tokens": [51664, 1223, 293, 550, 291, 434, 1702, 281, 352, 766, 666, 264, 2519, 51816], "temperature": 0.0, "avg_logprob": -0.08206511300707621, "compression_ratio": 1.7594501718213058, "no_speech_prob": 0.020959656685590744}, {"id": 631, "seek": 227120, "start": 2271.2, "end": 2274.72, "text": " so what we omitted was almost as important as what we what we added", "tokens": [50364, 370, 437, 321, 3406, 3944, 390, 1920, 382, 1021, 382, 437, 321, 437, 321, 3869, 50540], "temperature": 0.0, "avg_logprob": -0.1080452678649406, "compression_ratio": 1.903225806451613, "no_speech_prob": 0.0008138999692164361}, {"id": 632, "seek": 227120, "start": 2274.72, "end": 2278.7999999999997, "text": " and we very quickly realized this was a this was a new book so we we we called", "tokens": [50540, 293, 321, 588, 2661, 5334, 341, 390, 257, 341, 390, 257, 777, 1446, 370, 321, 321, 321, 1219, 50744], "temperature": 0.0, "avg_logprob": -0.1080452678649406, "compression_ratio": 1.903225806451613, "no_speech_prob": 0.0008138999692164361}, {"id": 633, "seek": 227120, "start": 2278.7999999999997, "end": 2281.68, "text": " the book deep learning foundations and concepts", "tokens": [50744, 264, 1446, 2452, 2539, 22467, 293, 10392, 50888], "temperature": 0.0, "avg_logprob": -0.1080452678649406, "compression_ratio": 1.903225806451613, "no_speech_prob": 0.0008138999692164361}, {"id": 634, "seek": 227120, "start": 2281.68, "end": 2285.12, "text": " and we made a lot of progress but then of course the the lockdowns", "tokens": [50888, 293, 321, 1027, 257, 688, 295, 4205, 457, 550, 295, 1164, 264, 264, 17267, 82, 51060], "temperature": 0.0, "avg_logprob": -0.1080452678649406, "compression_ratio": 1.903225806451613, "no_speech_prob": 0.0008138999692164361}, {"id": 635, "seek": 227120, "start": 2285.12, "end": 2289.6, "text": " ended i started a new team called ai for science at microsoft", "tokens": [51060, 4590, 741, 1409, 257, 777, 1469, 1219, 9783, 337, 3497, 412, 3123, 7856, 51284], "temperature": 0.0, "avg_logprob": -0.1080452678649406, "compression_ratio": 1.903225806451613, "no_speech_prob": 0.0008138999692164361}, {"id": 636, "seek": 227120, "start": 2289.6, "end": 2293.4399999999996, "text": " hu started at wave technologies building the the core machine learning", "tokens": [51284, 2137, 1409, 412, 5772, 7943, 2390, 264, 264, 4965, 3479, 2539, 51476], "temperature": 0.0, "avg_logprob": -0.1080452678649406, "compression_ratio": 1.903225806451613, "no_speech_prob": 0.0008138999692164361}, {"id": 637, "seek": 227120, "start": 2293.4399999999996, "end": 2297.4399999999996, "text": " technology for their autonomous vehicles and we were all just far too busy", "tokens": [51476, 2899, 337, 641, 23797, 8948, 293, 321, 645, 439, 445, 1400, 886, 5856, 51676], "temperature": 0.0, "avg_logprob": -0.1080452678649406, "compression_ratio": 1.903225806451613, "no_speech_prob": 0.0008138999692164361}, {"id": 638, "seek": 227120, "start": 2297.4399999999996, "end": 2300.8799999999997, "text": " and then the next thing that happened was the chat gpt moment", "tokens": [51676, 293, 550, 264, 958, 551, 300, 2011, 390, 264, 5081, 290, 662, 1623, 51848], "temperature": 0.0, "avg_logprob": -0.1080452678649406, "compression_ratio": 1.903225806451613, "no_speech_prob": 0.0008138999692164361}, {"id": 639, "seek": 230088, "start": 2300.88, "end": 2304.0, "text": " we're you know in a space of a few weeks a hundred million people were using", "tokens": [50364, 321, 434, 291, 458, 294, 257, 1901, 295, 257, 1326, 3259, 257, 3262, 2459, 561, 645, 1228, 50520], "temperature": 0.0, "avg_logprob": -0.11760471713158392, "compression_ratio": 1.7715355805243447, "no_speech_prob": 0.002166733145713806}, {"id": 640, "seek": 230088, "start": 2304.0, "end": 2307.44, "text": " this and suddenly ai machine learning was in the", "tokens": [50520, 341, 293, 5800, 9783, 3479, 2539, 390, 294, 264, 50692], "temperature": 0.0, "avg_logprob": -0.11760471713158392, "compression_ratio": 1.7715355805243447, "no_speech_prob": 0.002166733145713806}, {"id": 641, "seek": 230088, "start": 2307.44, "end": 2310.4, "text": " in the consciousness of the the general public", "tokens": [50692, 294, 264, 10081, 295, 264, 264, 2674, 1908, 50840], "temperature": 0.0, "avg_logprob": -0.11760471713158392, "compression_ratio": 1.7715355805243447, "no_speech_prob": 0.002166733145713806}, {"id": 642, "seek": 230088, "start": 2310.4, "end": 2314.32, "text": " and we realized that if ever there was a time to finish this book it had to be", "tokens": [50840, 293, 321, 5334, 300, 498, 1562, 456, 390, 257, 565, 281, 2413, 341, 1446, 309, 632, 281, 312, 51036], "temperature": 0.0, "avg_logprob": -0.11760471713158392, "compression_ratio": 1.7715355805243447, "no_speech_prob": 0.002166733145713806}, {"id": 643, "seek": 230088, "start": 2314.32, "end": 2318.48, "text": " now and so we had a just a really big push to", "tokens": [51036, 586, 293, 370, 321, 632, 257, 445, 257, 534, 955, 2944, 281, 51244], "temperature": 0.0, "avg_logprob": -0.11760471713158392, "compression_ratio": 1.7715355805243447, "no_speech_prob": 0.002166733145713806}, {"id": 644, "seek": 230088, "start": 2318.48, "end": 2322.8, "text": " to get the book finished and available for for new eurips in 2023", "tokens": [51244, 281, 483, 264, 1446, 4335, 293, 2435, 337, 337, 777, 308, 374, 2600, 294, 44377, 51460], "temperature": 0.0, "avg_logprob": -0.11760471713158392, "compression_ratio": 1.7715355805243447, "no_speech_prob": 0.002166733145713806}, {"id": 645, "seek": 230088, "start": 2322.8, "end": 2326.7200000000003, "text": " and we made it just you know at the last minute as you do", "tokens": [51460, 293, 321, 1027, 309, 445, 291, 458, 412, 264, 1036, 3456, 382, 291, 360, 51656], "temperature": 0.0, "avg_logprob": -0.11760471713158392, "compression_ratio": 1.7715355805243447, "no_speech_prob": 0.002166733145713806}, {"id": 646, "seek": 230088, "start": 2326.7200000000003, "end": 2329.6800000000003, "text": " and the book was on display at new eurips there and", "tokens": [51656, 293, 264, 1446, 390, 322, 4674, 412, 777, 308, 374, 2600, 456, 293, 51804], "temperature": 0.0, "avg_logprob": -0.11760471713158392, "compression_ratio": 1.7715355805243447, "no_speech_prob": 0.002166733145713806}, {"id": 647, "seek": 232968, "start": 2329.68, "end": 2333.6, "text": " hu and i spent the week going around the conference together", "tokens": [50364, 2137, 293, 741, 4418, 264, 1243, 516, 926, 264, 7586, 1214, 50560], "temperature": 0.0, "avg_logprob": -0.08926062150435014, "compression_ratio": 1.8284671532846715, "no_speech_prob": 0.0020622978918254375}, {"id": 648, "seek": 232968, "start": 2333.6, "end": 2337.6, "text": " talking to folks at posters and and just had a great time so it was actually a", "tokens": [50560, 1417, 281, 4024, 412, 28172, 293, 293, 445, 632, 257, 869, 565, 370, 309, 390, 767, 257, 50760], "temperature": 0.0, "avg_logprob": -0.08926062150435014, "compression_ratio": 1.8284671532846715, "no_speech_prob": 0.0020622978918254375}, {"id": 649, "seek": 232968, "start": 2337.6, "end": 2340.7999999999997, "text": " huge privilege to to be able to write the book with my son", "tokens": [50760, 2603, 12122, 281, 281, 312, 1075, 281, 2464, 264, 1446, 365, 452, 1872, 50920], "temperature": 0.0, "avg_logprob": -0.08926062150435014, "compression_ratio": 1.8284671532846715, "no_speech_prob": 0.0020622978918254375}, {"id": 650, "seek": 232968, "start": 2340.7999999999997, "end": 2344.48, "text": " yeah that's fantastic um what was your favorite chapter", "tokens": [50920, 1338, 300, 311, 5456, 1105, 437, 390, 428, 2954, 7187, 51104], "temperature": 0.0, "avg_logprob": -0.08926062150435014, "compression_ratio": 1.8284671532846715, "no_speech_prob": 0.0020622978918254375}, {"id": 651, "seek": 232968, "start": 2344.48, "end": 2347.9199999999996, "text": " and i mean are there any um things that you felt were", "tokens": [51104, 293, 741, 914, 366, 456, 604, 1105, 721, 300, 291, 2762, 645, 51276], "temperature": 0.0, "avg_logprob": -0.08926062150435014, "compression_ratio": 1.8284671532846715, "no_speech_prob": 0.0020622978918254375}, {"id": 652, "seek": 232968, "start": 2347.9199999999996, "end": 2351.3599999999997, "text": " remissions that you would have liked to do but you just had to draw a line under", "tokens": [51276, 890, 7922, 300, 291, 576, 362, 4501, 281, 360, 457, 291, 445, 632, 281, 2642, 257, 1622, 833, 51448], "temperature": 0.0, "avg_logprob": -0.08926062150435014, "compression_ratio": 1.8284671532846715, "no_speech_prob": 0.0020622978918254375}, {"id": 653, "seek": 232968, "start": 2351.3599999999997, "end": 2354.0, "text": " it yeah in terms of uh favorite chapters i mean", "tokens": [51448, 309, 1338, 294, 2115, 295, 2232, 2954, 20013, 741, 914, 51580], "temperature": 0.0, "avg_logprob": -0.08926062150435014, "compression_ratio": 1.8284671532846715, "no_speech_prob": 0.0020622978918254375}, {"id": 654, "seek": 232968, "start": 2354.0, "end": 2357.2, "text": " of course the things the the the more recent architectures were", "tokens": [51580, 295, 1164, 264, 721, 264, 264, 264, 544, 5162, 6331, 1303, 645, 51740], "temperature": 0.0, "avg_logprob": -0.08926062150435014, "compression_ratio": 1.8284671532846715, "no_speech_prob": 0.0020622978918254375}, {"id": 655, "seek": 235720, "start": 2357.2, "end": 2360.08, "text": " particularly interesting i very much enjoyed writing the the diffusion", "tokens": [50364, 4098, 1880, 741, 588, 709, 4626, 3579, 264, 264, 25242, 50508], "temperature": 0.0, "avg_logprob": -0.11752787123631386, "compression_ratio": 2.0129032258064514, "no_speech_prob": 0.007188101764768362}, {"id": 656, "seek": 235720, "start": 2360.08, "end": 2364.08, "text": " chapter and hu had a lot of input into that chapter of course transformers as", "tokens": [50508, 7187, 293, 2137, 632, 257, 688, 295, 4846, 666, 300, 7187, 295, 1164, 4088, 433, 382, 50708], "temperature": 0.0, "avg_logprob": -0.11752787123631386, "compression_ratio": 2.0129032258064514, "no_speech_prob": 0.007188101764768362}, {"id": 657, "seek": 235720, "start": 2364.08, "end": 2368.56, "text": " well and just understanding how to how to", "tokens": [50708, 731, 293, 445, 3701, 577, 281, 577, 281, 50932], "temperature": 0.0, "avg_logprob": -0.11752787123631386, "compression_ratio": 2.0129032258064514, "no_speech_prob": 0.007188101764768362}, {"id": 658, "seek": 235720, "start": 2368.56, "end": 2372.3199999999997, "text": " integrate the the sort of the different generative frameworks how to bring", "tokens": [50932, 13365, 264, 264, 1333, 295, 264, 819, 1337, 1166, 29834, 577, 281, 1565, 51120], "temperature": 0.0, "avg_logprob": -0.11752787123631386, "compression_ratio": 2.0129032258064514, "no_speech_prob": 0.007188101764768362}, {"id": 659, "seek": 235720, "start": 2372.3199999999997, "end": 2375.12, "text": " think about gans and how to think about variational order encoders and you know", "tokens": [51120, 519, 466, 290, 599, 293, 577, 281, 519, 466, 3034, 1478, 1668, 2058, 378, 433, 293, 291, 458, 51260], "temperature": 0.0, "avg_logprob": -0.11752787123631386, "compression_ratio": 2.0129032258064514, "no_speech_prob": 0.007188101764768362}, {"id": 660, "seek": 235720, "start": 2375.12, "end": 2377.8399999999997, "text": " how to think about normalizing flows and so on how to think about those under", "tokens": [51260, 577, 281, 519, 466, 2710, 3319, 12867, 293, 370, 322, 577, 281, 519, 466, 729, 833, 51396], "temperature": 0.0, "avg_logprob": -0.11752787123631386, "compression_ratio": 2.0129032258064514, "no_speech_prob": 0.007188101764768362}, {"id": 661, "seek": 235720, "start": 2377.8399999999997, "end": 2380.64, "text": " one umbrella and present them in a more coherent way", "tokens": [51396, 472, 21925, 293, 1974, 552, 294, 257, 544, 36239, 636, 51536], "temperature": 0.0, "avg_logprob": -0.11752787123631386, "compression_ratio": 2.0129032258064514, "no_speech_prob": 0.007188101764768362}, {"id": 662, "seek": 235720, "start": 2380.64, "end": 2384.0, "text": " so that was that was part of the interesting free the learning experience", "tokens": [51536, 370, 300, 390, 300, 390, 644, 295, 264, 1880, 1737, 264, 2539, 1752, 51704], "temperature": 0.0, "avg_logprob": -0.11752787123631386, "compression_ratio": 2.0129032258064514, "no_speech_prob": 0.007188101764768362}, {"id": 663, "seek": 235720, "start": 2384.0, "end": 2386.7999999999997, "text": " i always enjoy learning new things i learned things writing that book and", "tokens": [51704, 741, 1009, 2103, 2539, 777, 721, 741, 3264, 721, 3579, 300, 1446, 293, 51844], "temperature": 0.0, "avg_logprob": -0.11752787123631386, "compression_ratio": 2.0129032258064514, "no_speech_prob": 0.007188101764768362}, {"id": 664, "seek": 238680, "start": 2386.8, "end": 2390.7200000000003, "text": " that and i think you did as well and so in a sense that was that was the", "tokens": [50364, 300, 293, 741, 519, 291, 630, 382, 731, 293, 370, 294, 257, 2020, 300, 390, 300, 390, 264, 50560], "temperature": 0.0, "avg_logprob": -0.08066055808268802, "compression_ratio": 1.946031746031746, "no_speech_prob": 0.0031963149085640907}, {"id": 665, "seek": 238680, "start": 2390.7200000000003, "end": 2393.6800000000003, "text": " favorite part of the book the things where i where i learned new things or", "tokens": [50560, 2954, 644, 295, 264, 1446, 264, 721, 689, 741, 689, 741, 3264, 777, 721, 420, 50708], "temperature": 0.0, "avg_logprob": -0.08066055808268802, "compression_ratio": 1.946031746031746, "no_speech_prob": 0.0031963149085640907}, {"id": 666, "seek": 238680, "start": 2393.6800000000003, "end": 2397.1200000000003, "text": " new ways of looking at things i already knew about the real decision process is", "tokens": [50708, 777, 2098, 295, 1237, 412, 721, 741, 1217, 2586, 466, 264, 957, 3537, 1399, 307, 50880], "temperature": 0.0, "avg_logprob": -0.08066055808268802, "compression_ratio": 1.946031746031746, "no_speech_prob": 0.0031963149085640907}, {"id": 667, "seek": 238680, "start": 2397.1200000000003, "end": 2400.0800000000004, "text": " what to put in what not to put in while keeping the size of the book under", "tokens": [50880, 437, 281, 829, 294, 437, 406, 281, 829, 294, 1339, 5145, 264, 2744, 295, 264, 1446, 833, 51028], "temperature": 0.0, "avg_logprob": -0.08066055808268802, "compression_ratio": 1.946031746031746, "no_speech_prob": 0.0031963149085640907}, {"id": 668, "seek": 238680, "start": 2400.0800000000004, "end": 2403.04, "text": " control because i think it's something like it's thousands of papers a month", "tokens": [51028, 1969, 570, 741, 519, 309, 311, 746, 411, 309, 311, 5383, 295, 10577, 257, 1618, 51176], "temperature": 0.0, "avg_logprob": -0.08066055808268802, "compression_ratio": 1.946031746031746, "no_speech_prob": 0.0031963149085640907}, {"id": 669, "seek": 238680, "start": 2403.04, "end": 2406.7200000000003, "text": " now published in machine learning uh it's overwhelming for the beginner so", "tokens": [51176, 586, 6572, 294, 3479, 2539, 2232, 309, 311, 13373, 337, 264, 22080, 370, 51360], "temperature": 0.0, "avg_logprob": -0.08066055808268802, "compression_ratio": 1.946031746031746, "no_speech_prob": 0.0031963149085640907}, {"id": 670, "seek": 238680, "start": 2406.7200000000003, "end": 2410.2400000000002, "text": " really the goal of the book is to still out those few core concepts which means", "tokens": [51360, 534, 264, 3387, 295, 264, 1446, 307, 281, 920, 484, 729, 1326, 4965, 10392, 597, 1355, 51536], "temperature": 0.0, "avg_logprob": -0.08066055808268802, "compression_ratio": 1.946031746031746, "no_speech_prob": 0.0031963149085640907}, {"id": 671, "seek": 238680, "start": 2410.2400000000002, "end": 2413.6000000000004, "text": " there are always things oh should we have added this should we have added that", "tokens": [51536, 456, 366, 1009, 721, 1954, 820, 321, 362, 3869, 341, 820, 321, 362, 3869, 300, 51704], "temperature": 0.0, "avg_logprob": -0.08066055808268802, "compression_ratio": 1.946031746031746, "no_speech_prob": 0.0031963149085640907}, {"id": 672, "seek": 241360, "start": 2413.6, "end": 2416.7999999999997, "text": " what we wanted to do was to avoid adding the latest sort of", "tokens": [50364, 437, 321, 1415, 281, 360, 390, 281, 5042, 5127, 264, 6792, 1333, 295, 50524], "temperature": 0.0, "avg_logprob": -0.048426457565196236, "compression_ratio": 1.9272727272727272, "no_speech_prob": 0.00586545467376709}, {"id": 673, "seek": 241360, "start": 2416.7999999999997, "end": 2420.08, "text": " architecture that might be very hot at the minute that could easily disappear", "tokens": [50524, 9482, 300, 1062, 312, 588, 2368, 412, 264, 3456, 300, 727, 3612, 11596, 50688], "temperature": 0.0, "avg_logprob": -0.048426457565196236, "compression_ratio": 1.9272727272727272, "no_speech_prob": 0.00586545467376709}, {"id": 674, "seek": 241360, "start": 2420.08, "end": 2424.16, "text": " three months down the line so i hope we've resisted that that temptation", "tokens": [50688, 1045, 2493, 760, 264, 1622, 370, 741, 1454, 321, 600, 4597, 292, 300, 300, 30423, 50892], "temperature": 0.0, "avg_logprob": -0.048426457565196236, "compression_ratio": 1.9272727272727272, "no_speech_prob": 0.00586545467376709}, {"id": 675, "seek": 241360, "start": 2424.16, "end": 2427.68, "text": " but there are areas where you know perhaps when we at some point if we get", "tokens": [50892, 457, 456, 366, 3179, 689, 291, 458, 4317, 562, 321, 412, 512, 935, 498, 321, 483, 51068], "temperature": 0.0, "avg_logprob": -0.048426457565196236, "compression_ratio": 1.9272727272727272, "no_speech_prob": 0.00586545467376709}, {"id": 676, "seek": 241360, "start": 2427.68, "end": 2430.48, "text": " around to a second edition we might think about including reinforcement", "tokens": [51068, 926, 281, 257, 1150, 11377, 321, 1062, 519, 466, 3009, 29280, 51208], "temperature": 0.0, "avg_logprob": -0.048426457565196236, "compression_ratio": 1.9272727272727272, "no_speech_prob": 0.00586545467376709}, {"id": 677, "seek": 241360, "start": 2430.48, "end": 2433.7599999999998, "text": " learning is something which is of growing importance and", "tokens": [51208, 2539, 307, 746, 597, 307, 295, 4194, 7379, 293, 51372], "temperature": 0.0, "avg_logprob": -0.048426457565196236, "compression_ratio": 1.9272727272727272, "no_speech_prob": 0.00586545467376709}, {"id": 678, "seek": 241360, "start": 2433.7599999999998, "end": 2436.96, "text": " would be lovely to have a chapter on reinforcement learning that integrates", "tokens": [51372, 576, 312, 7496, 281, 362, 257, 7187, 322, 29280, 2539, 300, 3572, 1024, 51532], "temperature": 0.0, "avg_logprob": -0.048426457565196236, "compression_ratio": 1.9272727272727272, "no_speech_prob": 0.00586545467376709}, {"id": 679, "seek": 241360, "start": 2436.96, "end": 2439.52, "text": " well with the rest of the book there are books on reinforcement learning there", "tokens": [51532, 731, 365, 264, 1472, 295, 264, 1446, 456, 366, 3642, 322, 29280, 2539, 456, 51660], "temperature": 0.0, "avg_logprob": -0.048426457565196236, "compression_ratio": 1.9272727272727272, "no_speech_prob": 0.00586545467376709}, {"id": 680, "seek": 241360, "start": 2439.52, "end": 2442.0, "text": " are review articles there's plenty of place to go learn about them", "tokens": [51660, 366, 3131, 11290, 456, 311, 7140, 295, 1081, 281, 352, 1466, 466, 552, 51784], "temperature": 0.0, "avg_logprob": -0.048426457565196236, "compression_ratio": 1.9272727272727272, "no_speech_prob": 0.00586545467376709}, {"id": 681, "seek": 244200, "start": 2442.0, "end": 2445.12, "text": " there's something that sort of integrated with the book i think could be", "tokens": [50364, 456, 311, 746, 300, 1333, 295, 10919, 365, 264, 1446, 741, 519, 727, 312, 50520], "temperature": 0.0, "avg_logprob": -0.0961498360135662, "compression_ratio": 1.8976897689768977, "no_speech_prob": 0.000997815397568047}, {"id": 682, "seek": 244200, "start": 2445.12, "end": 2449.68, "text": " could be valuable so that is something we might we might visit in the future", "tokens": [50520, 727, 312, 8263, 370, 300, 307, 746, 321, 1062, 321, 1062, 3441, 294, 264, 2027, 50748], "temperature": 0.0, "avg_logprob": -0.0961498360135662, "compression_ratio": 1.8976897689768977, "no_speech_prob": 0.000997815397568047}, {"id": 683, "seek": 244200, "start": 2449.68, "end": 2453.04, "text": " but for the moment we've just focused on what we think are the", "tokens": [50748, 457, 337, 264, 1623, 321, 600, 445, 5178, 322, 437, 321, 519, 366, 264, 50916], "temperature": 0.0, "avg_logprob": -0.0961498360135662, "compression_ratio": 1.8976897689768977, "no_speech_prob": 0.000997815397568047}, {"id": 684, "seek": 244200, "start": 2453.04, "end": 2457.28, "text": " core principles that any any newcomer to the field whether a master student", "tokens": [50916, 4965, 9156, 300, 604, 604, 40014, 260, 281, 264, 2519, 1968, 257, 4505, 3107, 51128], "temperature": 0.0, "avg_logprob": -0.0961498360135662, "compression_ratio": 1.8976897689768977, "no_speech_prob": 0.000997815397568047}, {"id": 685, "seek": 244200, "start": 2457.28, "end": 2460.16, "text": " whether they're somebody who's self-taught a practitioner coming into", "tokens": [51128, 1968, 436, 434, 2618, 567, 311, 2698, 12, 1328, 1599, 257, 32125, 1348, 666, 51272], "temperature": 0.0, "avg_logprob": -0.0961498360135662, "compression_ratio": 1.8976897689768977, "no_speech_prob": 0.000997815397568047}, {"id": 686, "seek": 244200, "start": 2460.16, "end": 2463.44, "text": " the field wanting to understand the basics of the field and so the goal was", "tokens": [51272, 264, 2519, 7935, 281, 1223, 264, 14688, 295, 264, 2519, 293, 370, 264, 3387, 390, 51436], "temperature": 0.0, "avg_logprob": -0.0961498360135662, "compression_ratio": 1.8976897689768977, "no_speech_prob": 0.000997815397568047}, {"id": 687, "seek": 244200, "start": 2463.44, "end": 2466.72, "text": " to try to keep the book as it were as short as possible but no shorter", "tokens": [51436, 281, 853, 281, 1066, 264, 1446, 382, 309, 645, 382, 2099, 382, 1944, 457, 572, 11639, 51600], "temperature": 0.0, "avg_logprob": -0.0961498360135662, "compression_ratio": 1.8976897689768977, "no_speech_prob": 0.000997815397568047}, {"id": 688, "seek": 244200, "start": 2466.72, "end": 2470.08, "text": " looking back on on your last couple of books as well in in retrospect", "tokens": [51600, 1237, 646, 322, 322, 428, 1036, 1916, 295, 3642, 382, 731, 294, 294, 34997, 51768], "temperature": 0.0, "avg_logprob": -0.0961498360135662, "compression_ratio": 1.8976897689768977, "no_speech_prob": 0.000997815397568047}, {"id": 689, "seek": 247008, "start": 2470.64, "end": 2473.36, "text": " which bits are you are you most kind of proud of and", "tokens": [50392, 597, 9239, 366, 291, 366, 291, 881, 733, 295, 4570, 295, 293, 50528], "temperature": 0.0, "avg_logprob": -0.11069726943969727, "compression_ratio": 1.8585858585858586, "no_speech_prob": 0.0017433485481888056}, {"id": 690, "seek": 247008, "start": 2473.36, "end": 2476.72, "text": " which bits do you do you kind of feel that when you did make the decision at", "tokens": [50528, 597, 9239, 360, 291, 360, 291, 733, 295, 841, 300, 562, 291, 630, 652, 264, 3537, 412, 50696], "temperature": 0.0, "avg_logprob": -0.11069726943969727, "compression_ratio": 1.8585858585858586, "no_speech_prob": 0.0017433485481888056}, {"id": 691, "seek": 247008, "start": 2476.72, "end": 2480.48, "text": " the time perhaps you've you've you've mispredicted how successful something", "tokens": [50696, 264, 565, 4317, 291, 600, 291, 600, 291, 600, 3346, 79, 986, 11254, 577, 4406, 746, 50884], "temperature": 0.0, "avg_logprob": -0.11069726943969727, "compression_ratio": 1.8585858585858586, "no_speech_prob": 0.0017433485481888056}, {"id": 692, "seek": 247008, "start": 2480.48, "end": 2484.3199999999997, "text": " might be very interesting so the thing i'm most proud of actually", "tokens": [50884, 1062, 312, 588, 1880, 370, 264, 551, 741, 478, 881, 4570, 295, 767, 51076], "temperature": 0.0, "avg_logprob": -0.11069726943969727, "compression_ratio": 1.8585858585858586, "no_speech_prob": 0.0017433485481888056}, {"id": 693, "seek": 247008, "start": 2484.3199999999997, "end": 2488.0, "text": " is the very first book called neural networks for pattern recognition", "tokens": [51076, 307, 264, 588, 700, 1446, 1219, 18161, 9590, 337, 5102, 11150, 51260], "temperature": 0.0, "avg_logprob": -0.11069726943969727, "compression_ratio": 1.8585858585858586, "no_speech_prob": 0.0017433485481888056}, {"id": 694, "seek": 247008, "start": 2488.0, "end": 2491.7599999999998, "text": " and the reason is because i think that the book was quite influential in", "tokens": [51260, 293, 264, 1778, 307, 570, 741, 519, 300, 264, 1446, 390, 1596, 22215, 294, 51448], "temperature": 0.0, "avg_logprob": -0.11069726943969727, "compression_ratio": 1.8585858585858586, "no_speech_prob": 0.0017433485481888056}, {"id": 695, "seek": 247008, "start": 2491.7599999999998, "end": 2494.7999999999997, "text": " steering the field towards a more probabilistic more statistical", "tokens": [51448, 14823, 264, 2519, 3030, 257, 544, 31959, 3142, 544, 22820, 51600], "temperature": 0.0, "avg_logprob": -0.11069726943969727, "compression_ratio": 1.8585858585858586, "no_speech_prob": 0.0017433485481888056}, {"id": 696, "seek": 247008, "start": 2494.7999999999997, "end": 2498.3199999999997, "text": " perspective of machine learning it perhaps hard for people to appreciate", "tokens": [51600, 4585, 295, 3479, 2539, 309, 4317, 1152, 337, 561, 281, 4449, 51776], "temperature": 0.0, "avg_logprob": -0.11069726943969727, "compression_ratio": 1.8585858585858586, "no_speech_prob": 0.0017433485481888056}, {"id": 697, "seek": 249832, "start": 2498.32, "end": 2502.96, "text": " today but it wasn't always that way when i first went into machine learning", "tokens": [50364, 965, 457, 309, 2067, 380, 1009, 300, 636, 562, 741, 700, 1437, 666, 3479, 2539, 50596], "temperature": 0.0, "avg_logprob": -0.07564741565335181, "compression_ratio": 2.027027027027027, "no_speech_prob": 0.0009217652259394526}, {"id": 698, "seek": 249832, "start": 2502.96, "end": 2506.48, "text": " a lot of it was inspired by neurobiology which is which is fine", "tokens": [50596, 257, 688, 295, 309, 390, 7547, 538, 16499, 5614, 1793, 597, 307, 597, 307, 2489, 50772], "temperature": 0.0, "avg_logprob": -0.07564741565335181, "compression_ratio": 2.027027027027027, "no_speech_prob": 0.0009217652259394526}, {"id": 699, "seek": 249832, "start": 2506.48, "end": 2510.1600000000003, "text": " but it lacked sort of mathematical rigor it lacked any mathematical foundation", "tokens": [50772, 457, 309, 41481, 1333, 295, 18894, 42191, 309, 41481, 604, 18894, 7030, 50956], "temperature": 0.0, "avg_logprob": -0.07564741565335181, "compression_ratio": 2.027027027027027, "no_speech_prob": 0.0009217652259394526}, {"id": 700, "seek": 249832, "start": 2510.1600000000003, "end": 2513.52, "text": " and so there was a lot of trying to learn a bit more about the brain and then", "tokens": [50956, 293, 370, 456, 390, 257, 688, 295, 1382, 281, 1466, 257, 857, 544, 466, 264, 3567, 293, 550, 51124], "temperature": 0.0, "avg_logprob": -0.07564741565335181, "compression_ratio": 2.027027027027027, "no_speech_prob": 0.0009217652259394526}, {"id": 701, "seek": 249832, "start": 2513.52, "end": 2517.1200000000003, "text": " try to copy that in the algorithms and see if that worked better or not", "tokens": [51124, 853, 281, 5055, 300, 294, 264, 14642, 293, 536, 498, 300, 2732, 1101, 420, 406, 51304], "temperature": 0.0, "avg_logprob": -0.07564741565335181, "compression_ratio": 2.027027027027027, "no_speech_prob": 0.0009217652259394526}, {"id": 702, "seek": 249832, "start": 2517.1200000000003, "end": 2521.2000000000003, "text": " and there was a lot of trial and error still a lot of empirical trial and error", "tokens": [51304, 293, 456, 390, 257, 688, 295, 7308, 293, 6713, 920, 257, 688, 295, 31886, 7308, 293, 6713, 51508], "temperature": 0.0, "avg_logprob": -0.07564741565335181, "compression_ratio": 2.027027027027027, "no_speech_prob": 0.0009217652259394526}, {"id": 703, "seek": 249832, "start": 2521.2000000000003, "end": 2524.2400000000002, "text": " in machine learning of course but at least we have that that sort of bedrock", "tokens": [51508, 294, 3479, 2539, 295, 1164, 457, 412, 1935, 321, 362, 300, 300, 1333, 295, 2901, 17799, 51660], "temperature": 0.0, "avg_logprob": -0.07564741565335181, "compression_ratio": 2.027027027027027, "no_speech_prob": 0.0009217652259394526}, {"id": 704, "seek": 252424, "start": 2524.24, "end": 2527.8399999999997, "text": " of probability theory and so i think that the book was the first one to", "tokens": [50364, 295, 8482, 5261, 293, 370, 741, 519, 300, 264, 1446, 390, 264, 700, 472, 281, 50544], "temperature": 0.0, "avg_logprob": -0.07610779238822765, "compression_ratio": 1.961672473867596, "no_speech_prob": 0.006468767765909433}, {"id": 705, "seek": 252424, "start": 2527.8399999999997, "end": 2531.12, "text": " really address machine learning and neural networks from a statistical from", "tokens": [50544, 534, 2985, 3479, 2539, 293, 18161, 9590, 490, 257, 22820, 490, 50708], "temperature": 0.0, "avg_logprob": -0.07610779238822765, "compression_ratio": 1.961672473867596, "no_speech_prob": 0.006468767765909433}, {"id": 706, "seek": 252424, "start": 2531.12, "end": 2534.16, "text": " a probabilistic perspective and i think in that respect the book was very", "tokens": [50708, 257, 31959, 3142, 4585, 293, 741, 519, 294, 300, 3104, 264, 1446, 390, 588, 50860], "temperature": 0.0, "avg_logprob": -0.07610779238822765, "compression_ratio": 1.961672473867596, "no_speech_prob": 0.006468767765909433}, {"id": 707, "seek": 252424, "start": 2534.16, "end": 2537.9199999999996, "text": " influential the field was much smaller than today we take we take that as", "tokens": [50860, 22215, 264, 2519, 390, 709, 4356, 813, 965, 321, 747, 321, 747, 300, 382, 51048], "temperature": 0.0, "avg_logprob": -0.07610779238822765, "compression_ratio": 1.961672473867596, "no_speech_prob": 0.006468767765909433}, {"id": 708, "seek": 252424, "start": 2537.9199999999996, "end": 2541.2, "text": " obvious but i think in terms of the thing i'm most proud of it's probably", "tokens": [51048, 6322, 457, 741, 519, 294, 2115, 295, 264, 551, 741, 478, 881, 4570, 295, 309, 311, 1391, 51212], "temperature": 0.0, "avg_logprob": -0.07610779238822765, "compression_ratio": 1.961672473867596, "no_speech_prob": 0.006468767765909433}, {"id": 709, "seek": 252424, "start": 2541.2, "end": 2545.2799999999997, "text": " the influence of that that first book back in back in 1995", "tokens": [51212, 264, 6503, 295, 300, 300, 700, 1446, 646, 294, 646, 294, 22601, 51416], "temperature": 0.0, "avg_logprob": -0.07610779238822765, "compression_ratio": 1.961672473867596, "no_speech_prob": 0.006468767765909433}, {"id": 710, "seek": 252424, "start": 2545.2799999999997, "end": 2548.9599999999996, "text": " in terms of things i look back on that i might do differently", "tokens": [51416, 294, 2115, 295, 721, 741, 574, 646, 322, 300, 741, 1062, 360, 7614, 51600], "temperature": 0.0, "avg_logprob": -0.07610779238822765, "compression_ratio": 1.961672473867596, "no_speech_prob": 0.006468767765909433}, {"id": 711, "seek": 252424, "start": 2548.9599999999996, "end": 2552.9599999999996, "text": " i suppose when i look at if i look at prml for example and i look at the", "tokens": [51600, 741, 7297, 562, 741, 574, 412, 498, 741, 574, 412, 582, 15480, 337, 1365, 293, 741, 574, 412, 264, 51800], "temperature": 0.0, "avg_logprob": -0.07610779238822765, "compression_ratio": 1.961672473867596, "no_speech_prob": 0.006468767765909433}, {"id": 712, "seek": 255296, "start": 2552.96, "end": 2556.32, "text": " trajectory of the field we've seen that neural networks were", "tokens": [50364, 21512, 295, 264, 2519, 321, 600, 1612, 300, 18161, 9590, 645, 50532], "temperature": 0.0, "avg_logprob": -0.09563592172438098, "compression_ratio": 1.89568345323741, "no_speech_prob": 0.0021790701430290937}, {"id": 713, "seek": 255296, "start": 2556.32, "end": 2560.48, "text": " were all the rage in the mid mid 1980s to mid 1990s", "tokens": [50532, 645, 439, 264, 20133, 294, 264, 2062, 2062, 13626, 82, 281, 2062, 13384, 82, 50740], "temperature": 0.0, "avg_logprob": -0.09563592172438098, "compression_ratio": 1.89568345323741, "no_speech_prob": 0.0021790701430290937}, {"id": 714, "seek": 255296, "start": 2560.48, "end": 2563.68, "text": " and then they kind of got overtaken by other techniques and then we had this", "tokens": [50740, 293, 550, 436, 733, 295, 658, 17038, 9846, 538, 661, 7512, 293, 550, 321, 632, 341, 50900], "temperature": 0.0, "avg_logprob": -0.09563592172438098, "compression_ratio": 1.89568345323741, "no_speech_prob": 0.0021790701430290937}, {"id": 715, "seek": 255296, "start": 2563.68, "end": 2566.96, "text": " sort of Cambrian explosion of you know support vector machines and", "tokens": [50900, 1333, 295, 29287, 5501, 15673, 295, 291, 458, 1406, 8062, 8379, 293, 51064], "temperature": 0.0, "avg_logprob": -0.09563592172438098, "compression_ratio": 1.89568345323741, "no_speech_prob": 0.0021790701430290937}, {"id": 716, "seek": 255296, "start": 2566.96, "end": 2569.84, "text": " Gaussian process and Bayesian methods and graphical models and", "tokens": [51064, 39148, 1399, 293, 7840, 42434, 7150, 293, 35942, 5245, 293, 51208], "temperature": 0.0, "avg_logprob": -0.09563592172438098, "compression_ratio": 1.89568345323741, "no_speech_prob": 0.0021790701430290937}, {"id": 717, "seek": 255296, "start": 2569.84, "end": 2573.68, "text": " and all the rest of it and and i think one thing that one thing that i think", "tokens": [51208, 293, 439, 264, 1472, 295, 309, 293, 293, 741, 519, 472, 551, 300, 472, 551, 300, 741, 519, 51400], "temperature": 0.0, "avg_logprob": -0.09563592172438098, "compression_ratio": 1.89568345323741, "no_speech_prob": 0.0021790701430290937}, {"id": 718, "seek": 255296, "start": 2573.68, "end": 2577.04, "text": " Jeff Hinton really got right is we really understood that neural networks", "tokens": [51400, 7506, 389, 12442, 534, 658, 558, 307, 321, 534, 7320, 300, 18161, 9590, 51568], "temperature": 0.0, "avg_logprob": -0.09563592172438098, "compression_ratio": 1.89568345323741, "no_speech_prob": 0.0021790701430290937}, {"id": 719, "seek": 255296, "start": 2577.04, "end": 2579.92, "text": " were the way the way forward and he really stuck to that", "tokens": [51568, 645, 264, 636, 264, 636, 2128, 293, 415, 534, 5541, 281, 300, 51712], "temperature": 0.0, "avg_logprob": -0.09563592172438098, "compression_ratio": 1.89568345323741, "no_speech_prob": 0.0021790701430290937}, {"id": 720, "seek": 257992, "start": 2580.0, "end": 2584.2400000000002, "text": " perspective sort of through thick and thin i got kind of distracted", "tokens": [50368, 4585, 1333, 295, 807, 5060, 293, 5862, 741, 658, 733, 295, 21658, 50580], "temperature": 0.0, "avg_logprob": -0.08067686898367746, "compression_ratio": 1.7285714285714286, "no_speech_prob": 0.01227136142551899}, {"id": 721, "seek": 257992, "start": 2584.2400000000002, "end": 2587.2000000000003, "text": " particularly we talked earlier about Bayesian methods and how beautiful and", "tokens": [50580, 4098, 321, 2825, 3071, 466, 7840, 42434, 7150, 293, 577, 2238, 293, 50728], "temperature": 0.0, "avg_logprob": -0.08067686898367746, "compression_ratio": 1.7285714285714286, "no_speech_prob": 0.01227136142551899}, {"id": 722, "seek": 257992, "start": 2587.2000000000003, "end": 2590.96, "text": " how elegant they are and a theoretical physicist it's very appealing to think", "tokens": [50728, 577, 21117, 436, 366, 293, 257, 20864, 42466, 309, 311, 588, 23842, 281, 519, 50916], "temperature": 0.0, "avg_logprob": -0.08067686898367746, "compression_ratio": 1.7285714285714286, "no_speech_prob": 0.01227136142551899}, {"id": 723, "seek": 257992, "start": 2590.96, "end": 2594.32, "text": " of everything from a Bayesian perspective but really what we've seen", "tokens": [50916, 295, 1203, 490, 257, 7840, 42434, 4585, 457, 534, 437, 321, 600, 1612, 51084], "temperature": 0.0, "avg_logprob": -0.08067686898367746, "compression_ratio": 1.7285714285714286, "no_speech_prob": 0.01227136142551899}, {"id": 724, "seek": 257992, "start": 2594.32, "end": 2598.48, "text": " today is that the the practical tool that's giving us these", "tokens": [51084, 965, 307, 300, 264, 264, 8496, 2290, 300, 311, 2902, 505, 613, 51292], "temperature": 0.0, "avg_logprob": -0.08067686898367746, "compression_ratio": 1.7285714285714286, "no_speech_prob": 0.01227136142551899}, {"id": 725, "seek": 257992, "start": 2598.48, "end": 2602.48, "text": " extraordinary advances is neural networks and most of those ideas", "tokens": [51292, 10581, 25297, 307, 18161, 9590, 293, 881, 295, 729, 3487, 51492], "temperature": 0.0, "avg_logprob": -0.08067686898367746, "compression_ratio": 1.7285714285714286, "no_speech_prob": 0.01227136142551899}, {"id": 726, "seek": 257992, "start": 2602.48, "end": 2606.32, "text": " go back to the to the mid 1980s to the idea of gradient descent and", "tokens": [51492, 352, 646, 281, 264, 281, 264, 2062, 13626, 82, 281, 264, 1558, 295, 16235, 23475, 293, 51684], "temperature": 0.0, "avg_logprob": -0.08067686898367746, "compression_ratio": 1.7285714285714286, "no_speech_prob": 0.01227136142551899}, {"id": 727, "seek": 260632, "start": 2606.32, "end": 2609.6000000000004, "text": " and so on a few new a few new tweaks you know we have GPUs we have", "tokens": [50364, 293, 370, 322, 257, 1326, 777, 257, 1326, 777, 46664, 291, 458, 321, 362, 18407, 82, 321, 362, 50528], "temperature": 0.0, "avg_logprob": -0.13055171966552734, "compression_ratio": 1.895131086142322, "no_speech_prob": 0.003855278482660651}, {"id": 728, "seek": 260632, "start": 2609.6000000000004, "end": 2612.88, "text": " reluers we have a few but essentially most of the ideas were", "tokens": [50528, 1039, 84, 433, 321, 362, 257, 1326, 457, 4476, 881, 295, 264, 3487, 645, 50692], "temperature": 0.0, "avg_logprob": -0.13055171966552734, "compression_ratio": 1.895131086142322, "no_speech_prob": 0.003855278482660651}, {"id": 729, "seek": 260632, "start": 2612.88, "end": 2616.2400000000002, "text": " were were were still were around back in the", "tokens": [50692, 645, 645, 645, 920, 645, 926, 646, 294, 264, 50860], "temperature": 0.0, "avg_logprob": -0.13055171966552734, "compression_ratio": 1.895131086142322, "no_speech_prob": 0.003855278482660651}, {"id": 730, "seek": 260632, "start": 2616.2400000000002, "end": 2620.0800000000004, "text": " back in the late 1980s we didn't really understand", "tokens": [50860, 646, 294, 264, 3469, 13626, 82, 321, 994, 380, 534, 1223, 51052], "temperature": 0.0, "avg_logprob": -0.13055171966552734, "compression_ratio": 1.895131086142322, "no_speech_prob": 0.003855278482660651}, {"id": 731, "seek": 260632, "start": 2620.0800000000004, "end": 2623.76, "text": " the incredible scale at which you need to use them but they only really work", "tokens": [51052, 264, 4651, 4373, 412, 597, 291, 643, 281, 764, 552, 457, 436, 787, 534, 589, 51236], "temperature": 0.0, "avg_logprob": -0.13055171966552734, "compression_ratio": 1.895131086142322, "no_speech_prob": 0.003855278482660651}, {"id": 732, "seek": 260632, "start": 2623.76, "end": 2627.1200000000003, "text": " when you have this gargantuan scale of data and compute", "tokens": [51236, 562, 291, 362, 341, 3691, 70, 394, 6139, 4373, 295, 1412, 293, 14722, 51404], "temperature": 0.0, "avg_logprob": -0.13055171966552734, "compression_ratio": 1.895131086142322, "no_speech_prob": 0.003855278482660651}, {"id": 733, "seek": 260632, "start": 2627.1200000000003, "end": 2630.2400000000002, "text": " and of course we didn't really have GPUs or know how to use them back then", "tokens": [51404, 293, 295, 1164, 321, 994, 380, 534, 362, 18407, 82, 420, 458, 577, 281, 764, 552, 646, 550, 51560], "temperature": 0.0, "avg_logprob": -0.13055171966552734, "compression_ratio": 1.895131086142322, "no_speech_prob": 0.003855278482660651}, {"id": 734, "seek": 260632, "start": 2630.2400000000002, "end": 2633.6800000000003, "text": " so there were some key developments that sort of unlocked this and made it", "tokens": [51560, 370, 456, 645, 512, 2141, 20862, 300, 1333, 295, 30180, 341, 293, 1027, 309, 51732], "temperature": 0.0, "avg_logprob": -0.13055171966552734, "compression_ratio": 1.895131086142322, "no_speech_prob": 0.003855278482660651}, {"id": 735, "seek": 263368, "start": 2633.68, "end": 2636.16, "text": " possible but i think perhaps if i did something", "tokens": [50364, 1944, 457, 741, 519, 4317, 498, 741, 630, 746, 50488], "temperature": 0.0, "avg_logprob": -0.09665561592491874, "compression_ratio": 1.8670520231213872, "no_speech_prob": 0.012584739364683628}, {"id": 736, "seek": 263368, "start": 2636.16, "end": 2639.2799999999997, "text": " differently with the amazing benefit of hindsight other than sort of", "tokens": [50488, 7614, 365, 264, 2243, 5121, 295, 44357, 661, 813, 1333, 295, 50644], "temperature": 0.0, "avg_logprob": -0.09665561592491874, "compression_ratio": 1.8670520231213872, "no_speech_prob": 0.012584739364683628}, {"id": 737, "seek": 263368, "start": 2639.2799999999997, "end": 2642.48, "text": " investing in certain stocks and whatever and all the other things you could do", "tokens": [50644, 10978, 294, 1629, 12966, 293, 2035, 293, 439, 264, 661, 721, 291, 727, 360, 50804], "temperature": 0.0, "avg_logprob": -0.09665561592491874, "compression_ratio": 1.8670520231213872, "no_speech_prob": 0.012584739364683628}, {"id": 738, "seek": 263368, "start": 2642.48, "end": 2645.52, "text": " if you had perfect hindsight i think the other thing i would do is probably", "tokens": [50804, 498, 291, 632, 2176, 44357, 741, 519, 264, 661, 551, 741, 576, 360, 307, 1391, 50956], "temperature": 0.0, "avg_logprob": -0.09665561592491874, "compression_ratio": 1.8670520231213872, "no_speech_prob": 0.012584739364683628}, {"id": 739, "seek": 263368, "start": 2645.52, "end": 2648.48, "text": " just stay really focused on neural networks because eventually there", "tokens": [50956, 445, 1754, 534, 5178, 322, 18161, 9590, 570, 4728, 456, 51104], "temperature": 0.0, "avg_logprob": -0.09665561592491874, "compression_ratio": 1.8670520231213872, "no_speech_prob": 0.012584739364683628}, {"id": 740, "seek": 263368, "start": 2648.48, "end": 2651.7599999999998, "text": " that's the technology that came good but i always come back to probability", "tokens": [51104, 300, 311, 264, 2899, 300, 1361, 665, 457, 741, 1009, 808, 646, 281, 8482, 51268], "temperature": 0.0, "avg_logprob": -0.09665561592491874, "compression_ratio": 1.8670520231213872, "no_speech_prob": 0.012584739364683628}, {"id": 741, "seek": 263368, "start": 2651.7599999999998, "end": 2655.52, "text": " theory it's very much a unifying idea so for let me just give you a specific", "tokens": [51268, 5261, 309, 311, 588, 709, 257, 517, 5489, 1558, 370, 337, 718, 385, 445, 976, 291, 257, 2685, 51456], "temperature": 0.0, "avg_logprob": -0.09665561592491874, "compression_ratio": 1.8670520231213872, "no_speech_prob": 0.012584739364683628}, {"id": 742, "seek": 263368, "start": 2655.52, "end": 2658.8799999999997, "text": " example from prml actually there were two different technologies one called", "tokens": [51456, 1365, 490, 582, 15480, 767, 456, 645, 732, 819, 7943, 472, 1219, 51624], "temperature": 0.0, "avg_logprob": -0.09665561592491874, "compression_ratio": 1.8670520231213872, "no_speech_prob": 0.012584739364683628}, {"id": 743, "seek": 263368, "start": 2658.8799999999997, "end": 2662.3999999999996, "text": " hidden markoff models that were all the rage and speech recognition back then", "tokens": [51624, 7633, 1491, 4506, 5245, 300, 645, 439, 264, 20133, 293, 6218, 11150, 646, 550, 51800], "temperature": 0.0, "avg_logprob": -0.09665561592491874, "compression_ratio": 1.8670520231213872, "no_speech_prob": 0.012584739364683628}, {"id": 744, "seek": 266240, "start": 2662.4, "end": 2665.52, "text": " another technique called kalman filters that have been used for many years to", "tokens": [50364, 1071, 6532, 1219, 7788, 1601, 15995, 300, 362, 668, 1143, 337, 867, 924, 281, 50520], "temperature": 0.0, "avg_logprob": -0.10744846076296087, "compression_ratio": 1.78839590443686, "no_speech_prob": 0.0019838870503008366}, {"id": 745, "seek": 266240, "start": 2665.52, "end": 2670.1600000000003, "text": " to guide spacecraft track aircraft on radar and all sorts of things", "tokens": [50520, 281, 5934, 22910, 2837, 9465, 322, 16544, 293, 439, 7527, 295, 721, 50752], "temperature": 0.0, "avg_logprob": -0.10744846076296087, "compression_ratio": 1.78839590443686, "no_speech_prob": 0.0019838870503008366}, {"id": 746, "seek": 266240, "start": 2670.1600000000003, "end": 2672.88, "text": " it turns out they're essentially the same algorithm", "tokens": [50752, 309, 4523, 484, 436, 434, 4476, 264, 912, 9284, 50888], "temperature": 0.0, "avg_logprob": -0.10744846076296087, "compression_ratio": 1.78839590443686, "no_speech_prob": 0.0019838870503008366}, {"id": 747, "seek": 266240, "start": 2672.88, "end": 2677.28, "text": " and not only are they the same algorithm but they can be derived from the most", "tokens": [50888, 293, 406, 787, 366, 436, 264, 912, 9284, 457, 436, 393, 312, 18949, 490, 264, 881, 51108], "temperature": 0.0, "avg_logprob": -0.10744846076296087, "compression_ratio": 1.78839590443686, "no_speech_prob": 0.0019838870503008366}, {"id": 748, "seek": 266240, "start": 2677.28, "end": 2680.1600000000003, "text": " beautifully simple principle you just take the sum and product rule of", "tokens": [51108, 16525, 2199, 8665, 291, 445, 747, 264, 2408, 293, 1674, 4978, 295, 51252], "temperature": 0.0, "avg_logprob": -0.10744846076296087, "compression_ratio": 1.78839590443686, "no_speech_prob": 0.0019838870503008366}, {"id": 749, "seek": 266240, "start": 2680.1600000000003, "end": 2683.44, "text": " probabilities and then you take the idea that a joint probability distribution", "tokens": [51252, 33783, 293, 550, 291, 747, 264, 1558, 300, 257, 7225, 8482, 7316, 51416], "temperature": 0.0, "avg_logprob": -0.10744846076296087, "compression_ratio": 1.78839590443686, "no_speech_prob": 0.0019838870503008366}, {"id": 750, "seek": 266240, "start": 2683.44, "end": 2686.64, "text": " has a factorization described by a directed graph", "tokens": [51416, 575, 257, 5952, 2144, 7619, 538, 257, 12898, 4295, 51576], "temperature": 0.0, "avg_logprob": -0.10744846076296087, "compression_ratio": 1.78839590443686, "no_speech_prob": 0.0019838870503008366}, {"id": 751, "seek": 266240, "start": 2686.64, "end": 2690.1600000000003, "text": " and if you want to so when i was preparing prml", "tokens": [51576, 293, 498, 291, 528, 281, 370, 562, 741, 390, 10075, 582, 15480, 51752], "temperature": 0.0, "avg_logprob": -0.10744846076296087, "compression_ratio": 1.78839590443686, "no_speech_prob": 0.0019838870503008366}, {"id": 752, "seek": 269016, "start": 2690.24, "end": 2693.12, "text": " i looked over a bunch of books called kalman filters an introduction to", "tokens": [50368, 741, 2956, 670, 257, 3840, 295, 3642, 1219, 7788, 1601, 15995, 364, 9339, 281, 50512], "temperature": 0.0, "avg_logprob": -0.11384518707499784, "compression_ratio": 1.91875, "no_speech_prob": 0.0031331805512309074}, {"id": 753, "seek": 269016, "start": 2693.12, "end": 2696.16, "text": " kalman filters and they become chapter after chapter at the", "tokens": [50512, 7788, 1601, 15995, 293, 436, 1813, 7187, 934, 7187, 412, 264, 50664], "temperature": 0.0, "avg_logprob": -0.11384518707499784, "compression_ratio": 1.91875, "no_speech_prob": 0.0031331805512309074}, {"id": 754, "seek": 269016, "start": 2696.16, "end": 2699.12, "text": " forward and then chapter after chapter at the reverse equations and so on it", "tokens": [50664, 2128, 293, 550, 7187, 934, 7187, 412, 264, 9943, 11787, 293, 370, 322, 309, 50812], "temperature": 0.0, "avg_logprob": -0.11384518707499784, "compression_ratio": 1.91875, "no_speech_prob": 0.0031331805512309074}, {"id": 755, "seek": 269016, "start": 2699.12, "end": 2703.2, "text": " very very complex and very very heavy going but you can derive", "tokens": [50812, 588, 588, 3997, 293, 588, 588, 4676, 516, 457, 291, 393, 28446, 51016], "temperature": 0.0, "avg_logprob": -0.11384518707499784, "compression_ratio": 1.91875, "no_speech_prob": 0.0031331805512309074}, {"id": 756, "seek": 269016, "start": 2703.2, "end": 2707.04, "text": " the kalman filter and get the hidden markoff model for free in almost a few", "tokens": [51016, 264, 7788, 1601, 6608, 293, 483, 264, 7633, 1491, 4506, 2316, 337, 1737, 294, 1920, 257, 1326, 51208], "temperature": 0.0, "avg_logprob": -0.11384518707499784, "compression_ratio": 1.91875, "no_speech_prob": 0.0031331805512309074}, {"id": 757, "seek": 269016, "start": 2707.04, "end": 2710.0, "text": " lines of of algebra just starting from probability theory", "tokens": [51208, 3876, 295, 295, 21989, 445, 2891, 490, 8482, 5261, 51356], "temperature": 0.0, "avg_logprob": -0.11384518707499784, "compression_ratio": 1.91875, "no_speech_prob": 0.0031331805512309074}, {"id": 758, "seek": 269016, "start": 2710.0, "end": 2713.3599999999997, "text": " and this idea of factorization it's sort of deep mathematical principle that", "tokens": [51356, 293, 341, 1558, 295, 5952, 2144, 309, 311, 1333, 295, 2452, 18894, 8665, 300, 51524], "temperature": 0.0, "avg_logprob": -0.11384518707499784, "compression_ratio": 1.91875, "no_speech_prob": 0.0031331805512309074}, {"id": 759, "seek": 269016, "start": 2713.3599999999997, "end": 2716.3999999999996, "text": " operates there and you discover the message passing algorithm and if it's a", "tokens": [51524, 22577, 456, 293, 291, 4411, 264, 3636, 8437, 9284, 293, 498, 309, 311, 257, 51676], "temperature": 0.0, "avg_logprob": -0.11384518707499784, "compression_ratio": 1.91875, "no_speech_prob": 0.0031331805512309074}, {"id": 760, "seek": 269016, "start": 2716.3999999999996, "end": 2718.96, "text": " tree structure graph it's exact and you have two passes", "tokens": [51676, 4230, 3877, 4295, 309, 311, 1900, 293, 291, 362, 732, 11335, 51804], "temperature": 0.0, "avg_logprob": -0.11384518707499784, "compression_ratio": 1.91875, "no_speech_prob": 0.0031331805512309074}, {"id": 761, "seek": 271896, "start": 2719.28, "end": 2723.28, "text": " it's very beautiful very elegant so i love the fact we're exploring", "tokens": [50380, 309, 311, 588, 2238, 588, 21117, 370, 741, 959, 264, 1186, 321, 434, 12736, 50580], "temperature": 0.0, "avg_logprob": -0.13515554743705036, "compression_ratio": 1.7091988130563798, "no_speech_prob": 0.001511633861809969}, {"id": 762, "seek": 271896, "start": 2723.28, "end": 2726.48, "text": " all these many different frontiers but i love the fact we have some at least", "tokens": [50580, 439, 613, 867, 819, 1868, 4890, 457, 741, 959, 264, 1186, 321, 362, 512, 412, 1935, 50740], "temperature": 0.0, "avg_logprob": -0.13515554743705036, "compression_ratio": 1.7091988130563798, "no_speech_prob": 0.001511633861809969}, {"id": 763, "seek": 271896, "start": 2726.48, "end": 2729.36, "text": " some compass to guide us as we as we engage in the", "tokens": [50740, 512, 10707, 281, 5934, 505, 382, 321, 382, 321, 4683, 294, 264, 50884], "temperature": 0.0, "avg_logprob": -0.13515554743705036, "compression_ratio": 1.7091988130563798, "no_speech_prob": 0.001511633861809969}, {"id": 764, "seek": 271896, "start": 2729.36, "end": 2732.08, "text": " exploration of this combinatorially vast space", "tokens": [50884, 16197, 295, 341, 2512, 31927, 2270, 8369, 1901, 51020], "temperature": 0.0, "avg_logprob": -0.13515554743705036, "compression_ratio": 1.7091988130563798, "no_speech_prob": 0.001511633861809969}, {"id": 765, "seek": 271896, "start": 2732.08, "end": 2735.84, "text": " yeah it's so interesting my co-host Dr Keith Duggar he always says that he", "tokens": [51020, 1338, 309, 311, 370, 1880, 452, 598, 12, 6037, 2491, 20613, 413, 697, 2976, 415, 1009, 1619, 300, 415, 51208], "temperature": 0.0, "avg_logprob": -0.13515554743705036, "compression_ratio": 1.7091988130563798, "no_speech_prob": 0.001511633861809969}, {"id": 766, "seek": 271896, "start": 2735.84, "end": 2738.2400000000002, "text": " doesn't need to remember all of the different statistical quantities", "tokens": [51208, 1177, 380, 643, 281, 1604, 439, 295, 264, 819, 22820, 22927, 51328], "temperature": 0.0, "avg_logprob": -0.13515554743705036, "compression_ratio": 1.7091988130563798, "no_speech_prob": 0.001511633861809969}, {"id": 767, "seek": 271896, "start": 2738.2400000000002, "end": 2741.92, "text": " because he can re-derive them from first principles it's that nice", "tokens": [51328, 570, 415, 393, 319, 12, 1068, 488, 552, 490, 700, 9156, 309, 311, 300, 1481, 51512], "temperature": 0.0, "avg_logprob": -0.13515554743705036, "compression_ratio": 1.7091988130563798, "no_speech_prob": 0.001511633861809969}, {"id": 768, "seek": 271896, "start": 2741.92, "end": 2745.68, "text": " but we should move on to AI for science so you're leading this", "tokens": [51512, 457, 321, 820, 1286, 322, 281, 7318, 337, 3497, 370, 291, 434, 5775, 341, 51700], "temperature": 0.0, "avg_logprob": -0.13515554743705036, "compression_ratio": 1.7091988130563798, "no_speech_prob": 0.001511633861809969}, {"id": 769, "seek": 271896, "start": 2745.68, "end": 2748.32, "text": " initiative at Microsoft Research can you tell us about that", "tokens": [51700, 11552, 412, 8116, 10303, 393, 291, 980, 505, 466, 300, 51832], "temperature": 0.0, "avg_logprob": -0.13515554743705036, "compression_ratio": 1.7091988130563798, "no_speech_prob": 0.001511633861809969}, {"id": 770, "seek": 274832, "start": 2748.32, "end": 2751.28, "text": " yes so at a personal level of course this brings back my", "tokens": [50364, 2086, 370, 412, 257, 2973, 1496, 295, 1164, 341, 5607, 646, 452, 50512], "temperature": 0.0, "avg_logprob": -0.08888744078960616, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.00046145395026542246}, {"id": 771, "seek": 274832, "start": 2751.28, "end": 2756.8, "text": " my earlier interest in theoretical physics and chemistry and and biology", "tokens": [50512, 452, 3071, 1179, 294, 20864, 10649, 293, 12558, 293, 293, 14956, 50788], "temperature": 0.0, "avg_logprob": -0.08888744078960616, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.00046145395026542246}, {"id": 772, "seek": 274832, "start": 2756.8, "end": 2759.44, "text": " and that brings it together with with machine learning", "tokens": [50788, 293, 300, 5607, 309, 1214, 365, 365, 3479, 2539, 50920], "temperature": 0.0, "avg_logprob": -0.08888744078960616, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.00046145395026542246}, {"id": 773, "seek": 274832, "start": 2759.44, "end": 2763.6000000000004, "text": " and what many people realized a few years ago", "tokens": [50920, 293, 437, 867, 561, 5334, 257, 1326, 924, 2057, 51128], "temperature": 0.0, "avg_logprob": -0.08888744078960616, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.00046145395026542246}, {"id": 774, "seek": 274832, "start": 2763.6000000000004, "end": 2769.28, "text": " was that of the many areas that machine learning would impact the scientific", "tokens": [51128, 390, 300, 295, 264, 867, 3179, 300, 3479, 2539, 576, 2712, 264, 8134, 51412], "temperature": 0.0, "avg_logprob": -0.08888744078960616, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.00046145395026542246}, {"id": 775, "seek": 274832, "start": 2769.28, "end": 2773.2000000000003, "text": " the area of scientific discovery would be i think in my view the most important", "tokens": [51412, 264, 1859, 295, 8134, 12114, 576, 312, 741, 519, 294, 452, 1910, 264, 881, 1021, 51608], "temperature": 0.0, "avg_logprob": -0.08888744078960616, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.00046145395026542246}, {"id": 776, "seek": 274832, "start": 2773.2000000000003, "end": 2777.76, "text": " the reason i say that is because it's actually scientific discovery", "tokens": [51608, 264, 1778, 741, 584, 300, 307, 570, 309, 311, 767, 8134, 12114, 51836], "temperature": 0.0, "avg_logprob": -0.08888744078960616, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.00046145395026542246}, {"id": 777, "seek": 277776, "start": 2777.76, "end": 2781.76, "text": " that really has allowed humans to go on that trajectory the last few thousand", "tokens": [50364, 300, 534, 575, 4350, 6255, 281, 352, 322, 300, 21512, 264, 1036, 1326, 4714, 50564], "temperature": 0.0, "avg_logprob": -0.09145754192947247, "compression_ratio": 1.8140350877192983, "no_speech_prob": 0.0010393724078312516}, {"id": 778, "seek": 277776, "start": 2781.76, "end": 2784.88, "text": " years not just understanding our place in the universe but to be much more in", "tokens": [50564, 924, 406, 445, 3701, 527, 1081, 294, 264, 6445, 457, 281, 312, 709, 544, 294, 50720], "temperature": 0.0, "avg_logprob": -0.09145754192947247, "compression_ratio": 1.8140350877192983, "no_speech_prob": 0.0010393724078312516}, {"id": 779, "seek": 277776, "start": 2784.88, "end": 2788.5600000000004, "text": " control of our own destiny to double our lifespan to cure many", "tokens": [50720, 1969, 295, 527, 1065, 17893, 281, 3834, 527, 40361, 281, 13698, 867, 50904], "temperature": 0.0, "avg_logprob": -0.09145754192947247, "compression_ratio": 1.8140350877192983, "no_speech_prob": 0.0010393724078312516}, {"id": 780, "seek": 277776, "start": 2788.5600000000004, "end": 2790.6400000000003, "text": " diseases to give us much higher standards of", "tokens": [50904, 11044, 281, 976, 505, 709, 2946, 7787, 295, 51008], "temperature": 0.0, "avg_logprob": -0.09145754192947247, "compression_ratio": 1.8140350877192983, "no_speech_prob": 0.0010393724078312516}, {"id": 781, "seek": 277776, "start": 2790.6400000000003, "end": 2793.84, "text": " living to give us a much brighter outlook for the", "tokens": [51008, 2647, 281, 976, 505, 257, 709, 19764, 26650, 337, 264, 51168], "temperature": 0.0, "avg_logprob": -0.09145754192947247, "compression_ratio": 1.8140350877192983, "no_speech_prob": 0.0010393724078312516}, {"id": 782, "seek": 277776, "start": 2793.84, "end": 2796.96, "text": " future than humans humans have traditionally enjoyed", "tokens": [51168, 2027, 813, 6255, 6255, 362, 19067, 4626, 51324], "temperature": 0.0, "avg_logprob": -0.09145754192947247, "compression_ratio": 1.8140350877192983, "no_speech_prob": 0.0010393724078312516}, {"id": 783, "seek": 277776, "start": 2796.96, "end": 2800.88, "text": " and and that's come through scientific discovery and then the application", "tokens": [51324, 293, 293, 300, 311, 808, 807, 8134, 12114, 293, 550, 264, 3861, 51520], "temperature": 0.0, "avg_logprob": -0.09145754192947247, "compression_ratio": 1.8140350877192983, "no_speech_prob": 0.0010393724078312516}, {"id": 784, "seek": 277776, "start": 2800.88, "end": 2803.92, "text": " of that knowledge and understanding of the world in the form of technologies", "tokens": [51520, 295, 300, 3601, 293, 3701, 295, 264, 1002, 294, 264, 1254, 295, 7943, 51672], "temperature": 0.0, "avg_logprob": -0.09145754192947247, "compression_ratio": 1.8140350877192983, "no_speech_prob": 0.0010393724078312516}, {"id": 785, "seek": 280392, "start": 2804.0, "end": 2808.56, "text": " agriculture industrial and so on and so i can't think of any more", "tokens": [50368, 14837, 9987, 293, 370, 322, 293, 370, 741, 393, 380, 519, 295, 604, 544, 50596], "temperature": 0.0, "avg_logprob": -0.09002898894634444, "compression_ratio": 1.6765799256505576, "no_speech_prob": 0.0030932079534977674}, {"id": 786, "seek": 280392, "start": 2808.56, "end": 2813.36, "text": " important application for AI but what's really interesting is it's very clear", "tokens": [50596, 1021, 3861, 337, 7318, 457, 437, 311, 534, 1880, 307, 309, 311, 588, 1850, 50836], "temperature": 0.0, "avg_logprob": -0.09002898894634444, "compression_ratio": 1.6765799256505576, "no_speech_prob": 0.0030932079534977674}, {"id": 787, "seek": 280392, "start": 2813.36, "end": 2816.8, "text": " that many areas of scientific discovery are being disrupted and when i say", "tokens": [50836, 300, 867, 3179, 295, 8134, 12114, 366, 885, 42271, 293, 562, 741, 584, 51008], "temperature": 0.0, "avg_logprob": -0.09002898894634444, "compression_ratio": 1.6765799256505576, "no_speech_prob": 0.0030932079534977674}, {"id": 788, "seek": 280392, "start": 2816.8, "end": 2819.6, "text": " disrupted i'll just give you one simple example", "tokens": [51008, 42271, 741, 603, 445, 976, 291, 472, 2199, 1365, 51148], "temperature": 0.0, "avg_logprob": -0.09002898894634444, "compression_ratio": 1.6765799256505576, "no_speech_prob": 0.0030932079534977674}, {"id": 789, "seek": 280392, "start": 2819.6, "end": 2823.28, "text": " the ability of neural nets machine learning models to", "tokens": [51148, 264, 3485, 295, 18161, 36170, 3479, 2539, 5245, 281, 51332], "temperature": 0.0, "avg_logprob": -0.09002898894634444, "compression_ratio": 1.6765799256505576, "no_speech_prob": 0.0030932079534977674}, {"id": 790, "seek": 280392, "start": 2823.28, "end": 2828.0, "text": " act as emulators for previously were very expensive numerical stimulators", "tokens": [51332, 605, 382, 846, 39265, 337, 8046, 645, 588, 5124, 29054, 14572, 3391, 51568], "temperature": 0.0, "avg_logprob": -0.09002898894634444, "compression_ratio": 1.6765799256505576, "no_speech_prob": 0.0030932079534977674}, {"id": 791, "seek": 280392, "start": 2828.0, "end": 2831.6, "text": " very often gives you a factor of a thousand acceleration", "tokens": [51568, 588, 2049, 2709, 291, 257, 5952, 295, 257, 4714, 17162, 51748], "temperature": 0.0, "avg_logprob": -0.09002898894634444, "compression_ratio": 1.6765799256505576, "no_speech_prob": 0.0030932079534977674}, {"id": 792, "seek": 283160, "start": 2831.6, "end": 2834.24, "text": " you know we can forecast the weather a thousand times faster with the same", "tokens": [50364, 291, 458, 321, 393, 14330, 264, 5503, 257, 4714, 1413, 4663, 365, 264, 912, 50496], "temperature": 0.0, "avg_logprob": -0.06131790530297064, "compression_ratio": 1.9288256227758007, "no_speech_prob": 0.004645551089197397}, {"id": 793, "seek": 283160, "start": 2834.24, "end": 2837.6, "text": " accuracy than we could a few years ago prior to the use of deep learning", "tokens": [50496, 14170, 813, 321, 727, 257, 1326, 924, 2057, 4059, 281, 264, 764, 295, 2452, 2539, 50664], "temperature": 0.0, "avg_logprob": -0.06131790530297064, "compression_ratio": 1.9288256227758007, "no_speech_prob": 0.004645551089197397}, {"id": 794, "seek": 283160, "start": 2837.6, "end": 2840.56, "text": " now if that were the only thing that was happening", "tokens": [50664, 586, 498, 300, 645, 264, 787, 551, 300, 390, 2737, 50812], "temperature": 0.0, "avg_logprob": -0.06131790530297064, "compression_ratio": 1.9288256227758007, "no_speech_prob": 0.004645551089197397}, {"id": 795, "seek": 283160, "start": 2840.56, "end": 2843.6, "text": " that alone would be a disruption that alone would be worth setting up a team", "tokens": [50812, 300, 3312, 576, 312, 257, 28751, 300, 3312, 576, 312, 3163, 3287, 493, 257, 1469, 50964], "temperature": 0.0, "avg_logprob": -0.06131790530297064, "compression_ratio": 1.9288256227758007, "no_speech_prob": 0.004645551089197397}, {"id": 796, "seek": 283160, "start": 2843.6, "end": 2846.56, "text": " on AI for science i think actually it's only scratching the surface", "tokens": [50964, 322, 7318, 337, 3497, 741, 519, 767, 309, 311, 787, 29699, 264, 3753, 51112], "temperature": 0.0, "avg_logprob": -0.06131790530297064, "compression_ratio": 1.9288256227758007, "no_speech_prob": 0.004645551089197397}, {"id": 797, "seek": 283160, "start": 2846.56, "end": 2850.72, "text": " but anytime something that's very core very important gets a thousand times", "tokens": [51112, 457, 13038, 746, 300, 311, 588, 4965, 588, 1021, 2170, 257, 4714, 1413, 51320], "temperature": 0.0, "avg_logprob": -0.06131790530297064, "compression_ratio": 1.9288256227758007, "no_speech_prob": 0.004645551089197397}, {"id": 798, "seek": 283160, "start": 2850.72, "end": 2854.16, "text": " faster it means you can do things that would take", "tokens": [51320, 4663, 309, 1355, 291, 393, 360, 721, 300, 576, 747, 51492], "temperature": 0.0, "avg_logprob": -0.06131790530297064, "compression_ratio": 1.9288256227758007, "no_speech_prob": 0.004645551089197397}, {"id": 799, "seek": 283160, "start": 2854.16, "end": 2858.3199999999997, "text": " years in a few tens of hours it that really is a disruption it really is", "tokens": [51492, 924, 294, 257, 1326, 10688, 295, 2496, 309, 300, 534, 307, 257, 28751, 309, 534, 307, 51700], "temperature": 0.0, "avg_logprob": -0.06131790530297064, "compression_ratio": 1.9288256227758007, "no_speech_prob": 0.004645551089197397}, {"id": 800, "seek": 285832, "start": 2858.32, "end": 2862.4, "text": " transformational so a couple of years ago i pitched to", "tokens": [50364, 4088, 1478, 370, 257, 1916, 295, 924, 2057, 741, 32994, 281, 50568], "temperature": 0.0, "avg_logprob": -0.1085201899210612, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.013165057636797428}, {"id": 801, "seek": 285832, "start": 2862.4, "end": 2866.8, "text": " our chief technology officer to say look this is a really important field", "tokens": [50568, 527, 9588, 2899, 8456, 281, 584, 574, 341, 307, 257, 534, 1021, 2519, 50788], "temperature": 0.0, "avg_logprob": -0.1085201899210612, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.013165057636797428}, {"id": 802, "seek": 285832, "start": 2866.8, "end": 2870.56, "text": " i'm happy to step down from my role as the lab director of MSR", "tokens": [50788, 741, 478, 2055, 281, 1823, 760, 490, 452, 3090, 382, 264, 2715, 5391, 295, 7395, 49, 50976], "temperature": 0.0, "avg_logprob": -0.1085201899210612, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.013165057636797428}, {"id": 803, "seek": 285832, "start": 2870.56, "end": 2874.2400000000002, "text": " in in europe and instead i'd like to lead a new team", "tokens": [50976, 294, 294, 27207, 293, 2602, 741, 1116, 411, 281, 1477, 257, 777, 1469, 51160], "temperature": 0.0, "avg_logprob": -0.1085201899210612, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.013165057636797428}, {"id": 804, "seek": 285832, "start": 2874.2400000000002, "end": 2878.0, "text": " focusing on AI for science and met with enormous enthusiasm", "tokens": [51160, 8416, 322, 7318, 337, 3497, 293, 1131, 365, 11322, 23417, 51348], "temperature": 0.0, "avg_logprob": -0.1085201899210612, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.013165057636797428}, {"id": 805, "seek": 285832, "start": 2878.0, "end": 2881.2000000000003, "text": " and so we've been growing and building that team it's very interesting team", "tokens": [51348, 293, 370, 321, 600, 668, 4194, 293, 2390, 300, 1469, 309, 311, 588, 1880, 1469, 51508], "temperature": 0.0, "avg_logprob": -0.1085201899210612, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.013165057636797428}, {"id": 806, "seek": 285832, "start": 2881.2000000000003, "end": 2884.2400000000002, "text": " it's very multinational we have people on on many different continents in", "tokens": [51508, 309, 311, 588, 45872, 1478, 321, 362, 561, 322, 322, 867, 819, 38598, 294, 51660], "temperature": 0.0, "avg_logprob": -0.1085201899210612, "compression_ratio": 1.6389891696750902, "no_speech_prob": 0.013165057636797428}, {"id": 807, "seek": 288424, "start": 2884.24, "end": 2887.4399999999996, "text": " different countries we've opened new labs in in in", "tokens": [50364, 819, 3517, 321, 600, 5625, 777, 20339, 294, 294, 294, 50524], "temperature": 0.0, "avg_logprob": -0.11697116264930138, "compression_ratio": 1.7560975609756098, "no_speech_prob": 0.005597451236099005}, {"id": 808, "seek": 288424, "start": 2887.4399999999996, "end": 2890.4799999999996, "text": " in amsterdam and in in berlin we have teams in", "tokens": [50524, 294, 669, 27608, 293, 294, 294, 5948, 5045, 321, 362, 5491, 294, 50676], "temperature": 0.0, "avg_logprob": -0.11697116264930138, "compression_ratio": 1.7560975609756098, "no_speech_prob": 0.005597451236099005}, {"id": 809, "seek": 288424, "start": 2890.4799999999996, "end": 2894.7999999999997, "text": " in beijing and in shanghai and folks in in seattle as well", "tokens": [50676, 294, 312, 1718, 278, 293, 294, 402, 656, 18230, 293, 4024, 294, 294, 369, 3327, 382, 731, 50892], "temperature": 0.0, "avg_logprob": -0.11697116264930138, "compression_ratio": 1.7560975609756098, "no_speech_prob": 0.005597451236099005}, {"id": 810, "seek": 288424, "start": 2894.7999999999997, "end": 2899.6, "text": " and so very very multidisciplinary very multinational", "tokens": [50892, 293, 370, 588, 588, 2120, 40920, 24560, 588, 45872, 1478, 51132], "temperature": 0.0, "avg_logprob": -0.11697116264930138, "compression_ratio": 1.7560975609756098, "no_speech_prob": 0.005597451236099005}, {"id": 811, "seek": 288424, "start": 2899.6, "end": 2904.16, "text": " but with with one thing in common this real excitement and passion for what", "tokens": [51132, 457, 365, 365, 472, 551, 294, 2689, 341, 957, 14755, 293, 5418, 337, 437, 51360], "temperature": 0.0, "avg_logprob": -0.11697116264930138, "compression_ratio": 1.7560975609756098, "no_speech_prob": 0.005597451236099005}, {"id": 812, "seek": 288424, "start": 2904.16, "end": 2908.4799999999996, "text": " machine learning and AI is going to do to really transform and accelerate our", "tokens": [51360, 3479, 2539, 293, 7318, 307, 516, 281, 360, 281, 534, 4088, 293, 21341, 527, 51576], "temperature": 0.0, "avg_logprob": -0.11697116264930138, "compression_ratio": 1.7560975609756098, "no_speech_prob": 0.005597451236099005}, {"id": 813, "seek": 288424, "start": 2908.4799999999996, "end": 2911.68, "text": " ability to do scientific discovery you were talking about inductive", "tokens": [51576, 3485, 281, 360, 8134, 12114, 291, 645, 1417, 466, 31612, 488, 51736], "temperature": 0.0, "avg_logprob": -0.11697116264930138, "compression_ratio": 1.7560975609756098, "no_speech_prob": 0.005597451236099005}, {"id": 814, "seek": 291168, "start": 2911.68, "end": 2915.44, "text": " priors just a second ago and i guess i first learned about this", "tokens": [50364, 1790, 830, 445, 257, 1150, 2057, 293, 741, 2041, 741, 700, 3264, 466, 341, 50552], "temperature": 0.0, "avg_logprob": -0.09781785668997929, "compression_ratio": 1.8943396226415095, "no_speech_prob": 0.049435149878263474}, {"id": 815, "seek": 291168, "start": 2915.44, "end": 2918.3999999999996, "text": " with the art of you know designing inductive priors and machine learning", "tokens": [50552, 365, 264, 1523, 295, 291, 458, 14685, 31612, 488, 1790, 830, 293, 3479, 2539, 50700], "temperature": 0.0, "avg_logprob": -0.09781785668997929, "compression_ratio": 1.8943396226415095, "no_speech_prob": 0.049435149878263474}, {"id": 816, "seek": 291168, "start": 2918.3999999999996, "end": 2921.2799999999997, "text": " from max welling's group they were saying that you know the", "tokens": [50700, 490, 11469, 731, 278, 311, 1594, 436, 645, 1566, 300, 291, 458, 264, 50844], "temperature": 0.0, "avg_logprob": -0.09781785668997929, "compression_ratio": 1.8943396226415095, "no_speech_prob": 0.049435149878263474}, {"id": 817, "seek": 291168, "start": 2921.2799999999997, "end": 2927.04, "text": " remarkable thing is that you can using principles let's say from physics", "tokens": [50844, 12802, 551, 307, 300, 291, 393, 1228, 9156, 718, 311, 584, 490, 10649, 51132], "temperature": 0.0, "avg_logprob": -0.09781785668997929, "compression_ratio": 1.8943396226415095, "no_speech_prob": 0.049435149878263474}, {"id": 818, "seek": 291168, "start": 2927.04, "end": 2930.7999999999997, "text": " we can design these inductive priors and we can reduce the size of the", "tokens": [51132, 321, 393, 1715, 613, 31612, 488, 1790, 830, 293, 321, 393, 5407, 264, 2744, 295, 264, 51320], "temperature": 0.0, "avg_logprob": -0.09781785668997929, "compression_ratio": 1.8943396226415095, "no_speech_prob": 0.049435149878263474}, {"id": 819, "seek": 291168, "start": 2930.7999999999997, "end": 2933.52, "text": " hypothesis class that that we're approximating", "tokens": [51320, 17291, 1508, 300, 300, 321, 434, 8542, 990, 51456], "temperature": 0.0, "avg_logprob": -0.09781785668997929, "compression_ratio": 1.8943396226415095, "no_speech_prob": 0.049435149878263474}, {"id": 820, "seek": 291168, "start": 2933.52, "end": 2937.12, "text": " and because we know the target function is inside that class we are not", "tokens": [51456, 293, 570, 321, 458, 264, 3779, 2445, 307, 1854, 300, 1508, 321, 366, 406, 51636], "temperature": 0.0, "avg_logprob": -0.09781785668997929, "compression_ratio": 1.8943396226415095, "no_speech_prob": 0.049435149878263474}, {"id": 821, "seek": 291168, "start": 2937.12, "end": 2939.3599999999997, "text": " introducing any approximation error and we", "tokens": [51636, 15424, 604, 28023, 6713, 293, 321, 51748], "temperature": 0.0, "avg_logprob": -0.09781785668997929, "compression_ratio": 1.8943396226415095, "no_speech_prob": 0.049435149878263474}, {"id": 822, "seek": 293936, "start": 2939.36, "end": 2942.88, "text": " we are kind of overcoming some of the curses in in in machine learning by", "tokens": [50364, 321, 366, 733, 295, 38047, 512, 295, 264, 1262, 6196, 294, 294, 294, 3479, 2539, 538, 50540], "temperature": 0.0, "avg_logprob": -0.10423396301269532, "compression_ratio": 1.8440677966101695, "no_speech_prob": 0.0007836155127733946}, {"id": 823, "seek": 293936, "start": 2942.88, "end": 2946.08, "text": " making the problem tractable which which is amazing but", "tokens": [50540, 1455, 264, 1154, 24207, 712, 597, 597, 307, 2243, 457, 50700], "temperature": 0.0, "avg_logprob": -0.10423396301269532, "compression_ratio": 1.8440677966101695, "no_speech_prob": 0.0007836155127733946}, {"id": 824, "seek": 293936, "start": 2946.08, "end": 2949.84, "text": " that's speaking to this kind of principled approach of imbuing", "tokens": [50700, 300, 311, 4124, 281, 341, 733, 295, 3681, 15551, 3109, 295, 566, 6021, 278, 50888], "temperature": 0.0, "avg_logprob": -0.10423396301269532, "compression_ratio": 1.8440677966101695, "no_speech_prob": 0.0007836155127733946}, {"id": 825, "seek": 293936, "start": 2949.84, "end": 2953.36, "text": " domain knowledge into these systems it's really interesting actually max and i", "tokens": [50888, 9274, 3601, 666, 613, 3652, 309, 311, 534, 1880, 767, 11469, 293, 741, 51064], "temperature": 0.0, "avg_logprob": -0.10423396301269532, "compression_ratio": 1.8440677966101695, "no_speech_prob": 0.0007836155127733946}, {"id": 826, "seek": 293936, "start": 2953.36, "end": 2956.1600000000003, "text": " have a similar trajectory you both did phd's in theoretical physics and then", "tokens": [51064, 362, 257, 2531, 21512, 291, 1293, 630, 903, 67, 311, 294, 20864, 10649, 293, 550, 51204], "temperature": 0.0, "avg_logprob": -0.10423396301269532, "compression_ratio": 1.8440677966101695, "no_speech_prob": 0.0007836155127733946}, {"id": 827, "seek": 293936, "start": 2956.1600000000003, "end": 2959.6800000000003, "text": " moved into machine learning and i think we both feel there's a very", "tokens": [51204, 4259, 666, 3479, 2539, 293, 741, 519, 321, 1293, 841, 456, 311, 257, 588, 51380], "temperature": 0.0, "avg_logprob": -0.10423396301269532, "compression_ratio": 1.8440677966101695, "no_speech_prob": 0.0007836155127733946}, {"id": 828, "seek": 293936, "start": 2959.6800000000003, "end": 2963.44, "text": " important role for inductive bias to play in the use of", "tokens": [51380, 1021, 3090, 337, 31612, 488, 12577, 281, 862, 294, 264, 764, 295, 51568], "temperature": 0.0, "avg_logprob": -0.10423396301269532, "compression_ratio": 1.8440677966101695, "no_speech_prob": 0.0007836155127733946}, {"id": 829, "seek": 293936, "start": 2963.44, "end": 2966.88, "text": " machine learning in the scientific domain i think i'm sure everybody is", "tokens": [51568, 3479, 2539, 294, 264, 8134, 9274, 741, 519, 741, 478, 988, 2201, 307, 51740], "temperature": 0.0, "avg_logprob": -0.10423396301269532, "compression_ratio": 1.8440677966101695, "no_speech_prob": 0.0007836155127733946}, {"id": 830, "seek": 296688, "start": 2966.88, "end": 2970.7200000000003, "text": " familiar with the the blog called the bitter lesson by rich sudden", "tokens": [50364, 4963, 365, 264, 264, 6968, 1219, 264, 13871, 6898, 538, 4593, 3990, 50556], "temperature": 0.0, "avg_logprob": -0.07584617097499007, "compression_ratio": 1.81, "no_speech_prob": 0.011873203329741955}, {"id": 831, "seek": 296688, "start": 2970.7200000000003, "end": 2974.2400000000002, "text": " and if any if anybody watching this is is not familiar they should", "tokens": [50556, 293, 498, 604, 498, 4472, 1976, 341, 307, 307, 406, 4963, 436, 820, 50732], "temperature": 0.0, "avg_logprob": -0.07584617097499007, "compression_ratio": 1.81, "no_speech_prob": 0.011873203329741955}, {"id": 832, "seek": 296688, "start": 2974.2400000000002, "end": 2977.52, "text": " immediately after this video go and read that blog it's a very short blog", "tokens": [50732, 4258, 934, 341, 960, 352, 293, 1401, 300, 6968, 309, 311, 257, 588, 2099, 6968, 50896], "temperature": 0.0, "avg_logprob": -0.07584617097499007, "compression_ratio": 1.81, "no_speech_prob": 0.011873203329741955}, {"id": 833, "seek": 296688, "start": 2977.52, "end": 2980.96, "text": " and without giving too much of a spoiler he essentially says that", "tokens": [50896, 293, 1553, 2902, 886, 709, 295, 257, 26927, 415, 4476, 1619, 300, 51068], "temperature": 0.0, "avg_logprob": -0.07584617097499007, "compression_ratio": 1.81, "no_speech_prob": 0.011873203329741955}, {"id": 834, "seek": 296688, "start": 2980.96, "end": 2985.12, "text": " every attempt by people to improve the performance of machine learning by", "tokens": [51068, 633, 5217, 538, 561, 281, 3470, 264, 3389, 295, 3479, 2539, 538, 51276], "temperature": 0.0, "avg_logprob": -0.07584617097499007, "compression_ratio": 1.81, "no_speech_prob": 0.011873203329741955}, {"id": 835, "seek": 296688, "start": 2985.12, "end": 2988.96, "text": " building in prior knowledge building in what we call inductive biases", "tokens": [51276, 2390, 294, 4059, 3601, 2390, 294, 437, 321, 818, 31612, 488, 32152, 51468], "temperature": 0.0, "avg_logprob": -0.07584617097499007, "compression_ratio": 1.81, "no_speech_prob": 0.011873203329741955}, {"id": 836, "seek": 296688, "start": 2988.96, "end": 2992.6400000000003, "text": " into the models it produces some improvement and then but very quickly", "tokens": [51468, 666, 264, 5245, 309, 14725, 512, 10444, 293, 550, 457, 588, 2661, 51652], "temperature": 0.0, "avg_logprob": -0.07584617097499007, "compression_ratio": 1.81, "no_speech_prob": 0.011873203329741955}, {"id": 837, "seek": 296688, "start": 2992.6400000000003, "end": 2995.52, "text": " it's overtaken by somebody else who just has more data", "tokens": [51652, 309, 311, 17038, 9846, 538, 2618, 1646, 567, 445, 575, 544, 1412, 51796], "temperature": 0.0, "avg_logprob": -0.07584617097499007, "compression_ratio": 1.81, "no_speech_prob": 0.011873203329741955}, {"id": 838, "seek": 299552, "start": 2995.52, "end": 2999.2, "text": " and and that indeed is a bitter lesson and and it's a wonderful blog and", "tokens": [50364, 293, 293, 300, 6451, 307, 257, 13871, 6898, 293, 293, 309, 311, 257, 3715, 6968, 293, 50548], "temperature": 0.0, "avg_logprob": -0.08543623027516835, "compression_ratio": 1.9513888888888888, "no_speech_prob": 0.0002614067052491009}, {"id": 839, "seek": 299552, "start": 2999.2, "end": 3002.16, "text": " people should i i've read it many times i think people should you know probably", "tokens": [50548, 561, 820, 741, 741, 600, 1401, 309, 867, 1413, 741, 519, 561, 820, 291, 458, 1391, 50696], "temperature": 0.0, "avg_logprob": -0.08543623027516835, "compression_ratio": 1.9513888888888888, "no_speech_prob": 0.0002614067052491009}, {"id": 840, "seek": 299552, "start": 3002.16, "end": 3005.6, "text": " read that once a month and and it's it's very inspiring", "tokens": [50696, 1401, 300, 1564, 257, 1618, 293, 293, 309, 311, 309, 311, 588, 15883, 50868], "temperature": 0.0, "avg_logprob": -0.08543623027516835, "compression_ratio": 1.9513888888888888, "no_speech_prob": 0.0002614067052491009}, {"id": 841, "seek": 299552, "start": 3005.6, "end": 3008.64, "text": " but i think there may be exceptions and i think the scientific domain", "tokens": [50868, 457, 741, 519, 456, 815, 312, 22847, 293, 741, 519, 264, 8134, 9274, 51020], "temperature": 0.0, "avg_logprob": -0.08543623027516835, "compression_ratio": 1.9513888888888888, "no_speech_prob": 0.0002614067052491009}, {"id": 842, "seek": 299552, "start": 3008.64, "end": 3012.4, "text": " is one where inductive biases for the foreseeable future will be", "tokens": [51020, 307, 472, 689, 31612, 488, 32152, 337, 264, 38736, 712, 2027, 486, 312, 51208], "temperature": 0.0, "avg_logprob": -0.08543623027516835, "compression_ratio": 1.9513888888888888, "no_speech_prob": 0.0002614067052491009}, {"id": 843, "seek": 299552, "start": 3012.4, "end": 3015.28, "text": " extremely important sort of almost contrary to the bitter lesson", "tokens": [51208, 4664, 1021, 1333, 295, 1920, 19506, 281, 264, 13871, 6898, 51352], "temperature": 0.0, "avg_logprob": -0.08543623027516835, "compression_ratio": 1.9513888888888888, "no_speech_prob": 0.0002614067052491009}, {"id": 844, "seek": 299552, "start": 3015.28, "end": 3019.28, "text": " and a couple of reasons for this one is that the the inductive biases we have", "tokens": [51352, 293, 257, 1916, 295, 4112, 337, 341, 472, 307, 300, 264, 264, 31612, 488, 32152, 321, 362, 51552], "temperature": 0.0, "avg_logprob": -0.08543623027516835, "compression_ratio": 1.9513888888888888, "no_speech_prob": 0.0002614067052491009}, {"id": 845, "seek": 299552, "start": 3019.28, "end": 3024.64, "text": " a not not of the kind let's say let's say linguistics or something which is", "tokens": [51552, 257, 406, 406, 295, 264, 733, 718, 311, 584, 718, 311, 584, 21766, 6006, 420, 746, 597, 307, 51820], "temperature": 0.0, "avg_logprob": -0.08543623027516835, "compression_ratio": 1.9513888888888888, "no_speech_prob": 0.0002614067052491009}, {"id": 846, "seek": 302464, "start": 3024.72, "end": 3029.6, "text": " any domain where which is based on human expertise acquired through experience", "tokens": [50368, 604, 9274, 689, 597, 307, 2361, 322, 1952, 11769, 17554, 807, 1752, 50612], "temperature": 0.0, "avg_logprob": -0.08902168273925781, "compression_ratio": 1.7977941176470589, "no_speech_prob": 0.0003451744560152292}, {"id": 847, "seek": 302464, "start": 3029.6, "end": 3033.68, "text": " because a person who's had a lot of experience over a number of years and", "tokens": [50612, 570, 257, 954, 567, 311, 632, 257, 688, 295, 1752, 670, 257, 1230, 295, 924, 293, 50816], "temperature": 0.0, "avg_logprob": -0.08902168273925781, "compression_ratio": 1.7977941176470589, "no_speech_prob": 0.0003451744560152292}, {"id": 848, "seek": 302464, "start": 3033.68, "end": 3038.16, "text": " formulated some sort of rules of thumb that guide them that's exactly what", "tokens": [50816, 48936, 512, 1333, 295, 4474, 295, 9298, 300, 5934, 552, 300, 311, 2293, 437, 51040], "temperature": 0.0, "avg_logprob": -0.08902168273925781, "compression_ratio": 1.7977941176470589, "no_speech_prob": 0.0003451744560152292}, {"id": 849, "seek": 302464, "start": 3038.16, "end": 3042.0, "text": " machine learning is very good at processing very large amounts of data", "tokens": [51040, 3479, 2539, 307, 588, 665, 412, 9007, 588, 2416, 11663, 295, 1412, 51232], "temperature": 0.0, "avg_logprob": -0.08902168273925781, "compression_ratio": 1.7977941176470589, "no_speech_prob": 0.0003451744560152292}, {"id": 850, "seek": 302464, "start": 3042.0, "end": 3045.8399999999997, "text": " and and inducing the the the rules as it were the patterns", "tokens": [51232, 293, 293, 13716, 2175, 264, 264, 264, 4474, 382, 309, 645, 264, 8294, 51424], "temperature": 0.0, "avg_logprob": -0.08902168273925781, "compression_ratio": 1.7977941176470589, "no_speech_prob": 0.0003451744560152292}, {"id": 851, "seek": 302464, "start": 3045.8399999999997, "end": 3050.16, "text": " within that data so i think that kind of inductive bias is", "tokens": [51424, 1951, 300, 1412, 370, 741, 519, 300, 733, 295, 31612, 488, 12577, 307, 51640], "temperature": 0.0, "avg_logprob": -0.08902168273925781, "compression_ratio": 1.7977941176470589, "no_speech_prob": 0.0003451744560152292}, {"id": 852, "seek": 302464, "start": 3050.16, "end": 3053.44, "text": " typically harmful and and i think the bitter lesson will certainly apply", "tokens": [51640, 5850, 19727, 293, 293, 741, 519, 264, 13871, 6898, 486, 3297, 3079, 51804], "temperature": 0.0, "avg_logprob": -0.08902168273925781, "compression_ratio": 1.7977941176470589, "no_speech_prob": 0.0003451744560152292}, {"id": 853, "seek": 305344, "start": 3053.44, "end": 3056.56, "text": " there but in the scientific domain it's rather different first of all the", "tokens": [50364, 456, 457, 294, 264, 8134, 9274, 309, 311, 2831, 819, 700, 295, 439, 264, 50520], "temperature": 0.0, "avg_logprob": -0.07984219949076495, "compression_ratio": 1.9572953736654803, "no_speech_prob": 0.001961751841008663}, {"id": 854, "seek": 305344, "start": 3056.56, "end": 3059.36, "text": " inductive biases we have are very rigorous we have", "tokens": [50520, 31612, 488, 32152, 321, 362, 366, 588, 29882, 321, 362, 50660], "temperature": 0.0, "avg_logprob": -0.07984219949076495, "compression_ratio": 1.9572953736654803, "no_speech_prob": 0.001961751841008663}, {"id": 855, "seek": 305344, "start": 3059.36, "end": 3062.96, "text": " the idea of conservation of energy conservation of momentum we have", "tokens": [50660, 264, 1558, 295, 16185, 295, 2281, 16185, 295, 11244, 321, 362, 50840], "temperature": 0.0, "avg_logprob": -0.07984219949076495, "compression_ratio": 1.9572953736654803, "no_speech_prob": 0.001961751841008663}, {"id": 856, "seek": 305344, "start": 3062.96, "end": 3067.04, "text": " symmetries if i have a molecule in a vacuum it has a certain energy", "tokens": [50840, 14232, 302, 2244, 498, 741, 362, 257, 15582, 294, 257, 14224, 309, 575, 257, 1629, 2281, 51044], "temperature": 0.0, "avg_logprob": -0.07984219949076495, "compression_ratio": 1.9572953736654803, "no_speech_prob": 0.001961751841008663}, {"id": 857, "seek": 305344, "start": 3067.04, "end": 3070.08, "text": " if i rotate the molecule the representation of the coordinates of all the", "tokens": [51044, 498, 741, 13121, 264, 15582, 264, 10290, 295, 264, 21056, 295, 439, 264, 51196], "temperature": 0.0, "avg_logprob": -0.07984219949076495, "compression_ratio": 1.9572953736654803, "no_speech_prob": 0.001961751841008663}, {"id": 858, "seek": 305344, "start": 3070.08, "end": 3073.52, "text": " atoms changes wildly in the computer but the energy is the same", "tokens": [51196, 16871, 2962, 34731, 294, 264, 3820, 457, 264, 2281, 307, 264, 912, 51368], "temperature": 0.0, "avg_logprob": -0.07984219949076495, "compression_ratio": 1.9572953736654803, "no_speech_prob": 0.001961751841008663}, {"id": 859, "seek": 305344, "start": 3073.52, "end": 3077.44, "text": " so we have this very rigorous inductive bias we also know that the world at the", "tokens": [51368, 370, 321, 362, 341, 588, 29882, 31612, 488, 12577, 321, 611, 458, 300, 264, 1002, 412, 264, 51564], "temperature": 0.0, "avg_logprob": -0.07984219949076495, "compression_ratio": 1.9572953736654803, "no_speech_prob": 0.001961751841008663}, {"id": 860, "seek": 305344, "start": 3077.44, "end": 3081.28, "text": " atomic level is described exquisitely well by by Schrodinger's equation", "tokens": [51564, 22275, 1496, 307, 7619, 454, 15398, 1959, 731, 538, 538, 2065, 340, 3584, 260, 311, 5367, 51756], "temperature": 0.0, "avg_logprob": -0.07984219949076495, "compression_ratio": 1.9572953736654803, "no_speech_prob": 0.001961751841008663}, {"id": 861, "seek": 308128, "start": 3081.44, "end": 3084.32, "text": " sprinkling a few relativistic effects and you've got an amazingly accurate", "tokens": [50372, 30885, 1688, 257, 1326, 21960, 3142, 5065, 293, 291, 600, 658, 364, 31762, 8559, 50516], "temperature": 0.0, "avg_logprob": -0.08914648500600256, "compression_ratio": 1.83596214511041, "no_speech_prob": 0.004661051090806723}, {"id": 862, "seek": 308128, "start": 3084.32, "end": 3088.1600000000003, "text": " description of the world but it's way too complex to just solve it directly", "tokens": [50516, 3855, 295, 264, 1002, 457, 309, 311, 636, 886, 3997, 281, 445, 5039, 309, 3838, 50708], "temperature": 0.0, "avg_logprob": -0.08914648500600256, "compression_ratio": 1.83596214511041, "no_speech_prob": 0.004661051090806723}, {"id": 863, "seek": 308128, "start": 3088.1600000000003, "end": 3091.84, "text": " or is exponentially costly in the number of electrons but nevertheless we have", "tokens": [50708, 420, 307, 37330, 28328, 294, 264, 1230, 295, 14265, 457, 26924, 321, 362, 50892], "temperature": 0.0, "avg_logprob": -0.08914648500600256, "compression_ratio": 1.83596214511041, "no_speech_prob": 0.004661051090806723}, {"id": 864, "seek": 308128, "start": 3091.84, "end": 3097.0400000000004, "text": " this bedrock of of really understanding the laws that govern the universe", "tokens": [50892, 341, 2901, 17799, 295, 295, 534, 3701, 264, 6064, 300, 1980, 264, 6445, 51152], "temperature": 0.0, "avg_logprob": -0.08914648500600256, "compression_ratio": 1.83596214511041, "no_speech_prob": 0.004661051090806723}, {"id": 865, "seek": 308128, "start": 3097.0400000000004, "end": 3100.88, "text": " and so and so i think that's the first the first thing we have very rigorous", "tokens": [51152, 293, 370, 293, 370, 741, 519, 300, 311, 264, 700, 264, 700, 551, 321, 362, 588, 29882, 51344], "temperature": 0.0, "avg_logprob": -0.08914648500600256, "compression_ratio": 1.83596214511041, "no_speech_prob": 0.004661051090806723}, {"id": 866, "seek": 308128, "start": 3100.88, "end": 3104.1600000000003, "text": " priors that we believe in deeply it's not that we think conservation of energy", "tokens": [51344, 1790, 830, 300, 321, 1697, 294, 8760, 309, 311, 406, 300, 321, 519, 16185, 295, 2281, 51508], "temperature": 0.0, "avg_logprob": -0.08914648500600256, "compression_ratio": 1.83596214511041, "no_speech_prob": 0.004661051090806723}, {"id": 867, "seek": 308128, "start": 3104.1600000000003, "end": 3106.5600000000004, "text": " doesn't work we know that we know that it's true", "tokens": [51508, 1177, 380, 589, 321, 458, 300, 321, 458, 300, 309, 311, 2074, 51628], "temperature": 0.0, "avg_logprob": -0.08914648500600256, "compression_ratio": 1.83596214511041, "no_speech_prob": 0.004661051090806723}, {"id": 868, "seek": 308128, "start": 3106.5600000000004, "end": 3110.0, "text": " the second thing is that we're operating in a data scarce regime so large", "tokens": [51628, 264, 1150, 551, 307, 300, 321, 434, 7447, 294, 257, 1412, 41340, 13120, 370, 2416, 51800], "temperature": 0.0, "avg_logprob": -0.08914648500600256, "compression_ratio": 1.83596214511041, "no_speech_prob": 0.004661051090806723}, {"id": 869, "seek": 311000, "start": 3110.0, "end": 3113.92, "text": " language models are able to use very large quantities of internet scale", "tokens": [50364, 2856, 5245, 366, 1075, 281, 764, 588, 2416, 22927, 295, 4705, 4373, 50560], "temperature": 0.0, "avg_logprob": -0.09595485167069868, "compression_ratio": 1.876923076923077, "no_speech_prob": 0.0018331981264054775}, {"id": 870, "seek": 311000, "start": 3113.92, "end": 3117.76, "text": " quantities of human created data whether it's in the form of you know", "tokens": [50560, 22927, 295, 1952, 2942, 1412, 1968, 309, 311, 294, 264, 1254, 295, 291, 458, 50752], "temperature": 0.0, "avg_logprob": -0.09595485167069868, "compression_ratio": 1.876923076923077, "no_speech_prob": 0.0018331981264054775}, {"id": 871, "seek": 311000, "start": 3117.76, "end": 3122.32, "text": " whether it's wikipedia or whether it's just scientific papers or any of the", "tokens": [50752, 1968, 309, 311, 261, 1035, 26633, 420, 1968, 309, 311, 445, 8134, 10577, 420, 604, 295, 264, 50980], "temperature": 0.0, "avg_logprob": -0.09595485167069868, "compression_ratio": 1.876923076923077, "no_speech_prob": 0.0018331981264054775}, {"id": 872, "seek": 311000, "start": 3122.32, "end": 3126.24, "text": " output of humans almost is potentially material on which which large models", "tokens": [50980, 5598, 295, 6255, 1920, 307, 7263, 2527, 322, 597, 597, 2416, 5245, 51176], "temperature": 0.0, "avg_logprob": -0.09595485167069868, "compression_ratio": 1.876923076923077, "no_speech_prob": 0.0018331981264054775}, {"id": 873, "seek": 311000, "start": 3126.24, "end": 3130.64, "text": " can feed they're in a very data rich regime and can go to scale", "tokens": [51176, 393, 3154, 436, 434, 294, 257, 588, 1412, 4593, 13120, 293, 393, 352, 281, 4373, 51396], "temperature": 0.0, "avg_logprob": -0.09595485167069868, "compression_ratio": 1.876923076923077, "no_speech_prob": 0.0018331981264054775}, {"id": 874, "seek": 311000, "start": 3130.64, "end": 3134.48, "text": " and and so the bitter lesson i think really kicks in there in the scientific", "tokens": [51396, 293, 293, 370, 264, 13871, 6898, 741, 519, 534, 21293, 294, 456, 294, 264, 8134, 51588], "temperature": 0.0, "avg_logprob": -0.09595485167069868, "compression_ratio": 1.876923076923077, "no_speech_prob": 0.0018331981264054775}, {"id": 875, "seek": 311000, "start": 3134.48, "end": 3137.92, "text": " domain the data might come from simulations which are", "tokens": [51588, 9274, 264, 1412, 1062, 808, 490, 35138, 597, 366, 51760], "temperature": 0.0, "avg_logprob": -0.09595485167069868, "compression_ratio": 1.876923076923077, "no_speech_prob": 0.0018331981264054775}, {"id": 876, "seek": 313792, "start": 3137.92, "end": 3141.84, "text": " computational and expensive or it might come from lab experiments which are", "tokens": [50364, 28270, 293, 5124, 420, 309, 1062, 808, 490, 2715, 12050, 597, 366, 50560], "temperature": 0.0, "avg_logprob": -0.0517345548750044, "compression_ratio": 1.871212121212121, "no_speech_prob": 0.00385325588285923}, {"id": 877, "seek": 313792, "start": 3141.84, "end": 3146.2400000000002, "text": " which are expensive and the data is is limited so we're operating", "tokens": [50560, 597, 366, 5124, 293, 264, 1412, 307, 307, 5567, 370, 321, 434, 7447, 50780], "temperature": 0.0, "avg_logprob": -0.0517345548750044, "compression_ratio": 1.871212121212121, "no_speech_prob": 0.00385325588285923}, {"id": 878, "seek": 313792, "start": 3146.2400000000002, "end": 3149.84, "text": " usually in a data scarce regime so we have relatively limited data", "tokens": [50780, 2673, 294, 257, 1412, 41340, 13120, 370, 321, 362, 7226, 5567, 1412, 50960], "temperature": 0.0, "avg_logprob": -0.0517345548750044, "compression_ratio": 1.871212121212121, "no_speech_prob": 0.00385325588285923}, {"id": 879, "seek": 313792, "start": 3149.84, "end": 3153.04, "text": " and we have very rigorous prior knowledge and so the balance between", "tokens": [50960, 293, 321, 362, 588, 29882, 4059, 3601, 293, 370, 264, 4772, 1296, 51120], "temperature": 0.0, "avg_logprob": -0.0517345548750044, "compression_ratio": 1.871212121212121, "no_speech_prob": 0.00385325588285923}, {"id": 880, "seek": 313792, "start": 3153.04, "end": 3157.52, "text": " the data and the inductive bias is very different because of course the no", "tokens": [51120, 264, 1412, 293, 264, 31612, 488, 12577, 307, 588, 819, 570, 295, 1164, 264, 572, 51344], "temperature": 0.0, "avg_logprob": -0.0517345548750044, "compression_ratio": 1.871212121212121, "no_speech_prob": 0.00385325588285923}, {"id": 881, "seek": 313792, "start": 3157.52, "end": 3161.28, "text": " free lunch theorem says you can't learn purely from data you have to have some", "tokens": [51344, 1737, 6349, 20904, 1619, 291, 393, 380, 1466, 17491, 490, 1412, 291, 362, 281, 362, 512, 51532], "temperature": 0.0, "avg_logprob": -0.0517345548750044, "compression_ratio": 1.871212121212121, "no_speech_prob": 0.00385325588285923}, {"id": 882, "seek": 313792, "start": 3161.28, "end": 3165.6800000000003, "text": " form of inductive bias and in the case of a transformer it's a", "tokens": [51532, 1254, 295, 31612, 488, 12577, 293, 294, 264, 1389, 295, 257, 31782, 309, 311, 257, 51752], "temperature": 0.0, "avg_logprob": -0.0517345548750044, "compression_ratio": 1.871212121212121, "no_speech_prob": 0.00385325588285923}, {"id": 883, "seek": 316568, "start": 3165.68, "end": 3168.96, "text": " very lightweight form of inductive bias we believe there's a there's a deep", "tokens": [50364, 588, 22052, 1254, 295, 31612, 488, 12577, 321, 1697, 456, 311, 257, 456, 311, 257, 2452, 50528], "temperature": 0.0, "avg_logprob": -0.09186466390436346, "compression_ratio": 1.905511811023622, "no_speech_prob": 0.0027879669796675444}, {"id": 884, "seek": 316568, "start": 3168.96, "end": 3172.3999999999996, "text": " hierarchy there's some you know data dependent", "tokens": [50528, 22333, 456, 311, 512, 291, 458, 1412, 12334, 50700], "temperature": 0.0, "avg_logprob": -0.09186466390436346, "compression_ratio": 1.905511811023622, "no_speech_prob": 0.0027879669796675444}, {"id": 885, "seek": 316568, "start": 3172.3999999999996, "end": 3177.12, "text": " self-attention but but really that's it and the rest is determined from the data", "tokens": [50700, 2698, 12, 1591, 1251, 457, 457, 534, 300, 311, 309, 293, 264, 1472, 307, 9540, 490, 264, 1412, 50936], "temperature": 0.0, "avg_logprob": -0.09186466390436346, "compression_ratio": 1.905511811023622, "no_speech_prob": 0.0027879669796675444}, {"id": 886, "seek": 316568, "start": 3177.12, "end": 3181.04, "text": " in science there's much more scope for bringing in these inductive biases there's", "tokens": [50936, 294, 3497, 456, 311, 709, 544, 11923, 337, 5062, 294, 613, 31612, 488, 32152, 456, 311, 51132], "temperature": 0.0, "avg_logprob": -0.09186466390436346, "compression_ratio": 1.905511811023622, "no_speech_prob": 0.0027879669796675444}, {"id": 887, "seek": 316568, "start": 3181.04, "end": 3184.3999999999996, "text": " much more need to bring in the inductive biases and that also", "tokens": [51132, 709, 544, 643, 281, 1565, 294, 264, 31612, 488, 32152, 293, 300, 611, 51300], "temperature": 0.0, "avg_logprob": -0.09186466390436346, "compression_ratio": 1.905511811023622, "no_speech_prob": 0.0027879669796675444}, {"id": 888, "seek": 316568, "start": 3184.3999999999996, "end": 3188.96, "text": " incidentally again in my personal very biased opinion makes the", "tokens": [51300, 9348, 379, 797, 294, 452, 2973, 588, 28035, 4800, 1669, 264, 51528], "temperature": 0.0, "avg_logprob": -0.09186466390436346, "compression_ratio": 1.905511811023622, "no_speech_prob": 0.0027879669796675444}, {"id": 889, "seek": 316568, "start": 3188.96, "end": 3192.7999999999997, "text": " application of machine learning and ai to the sciences the most exciting", "tokens": [51528, 3861, 295, 3479, 2539, 293, 9783, 281, 264, 17677, 264, 881, 4670, 51720], "temperature": 0.0, "avg_logprob": -0.09186466390436346, "compression_ratio": 1.905511811023622, "no_speech_prob": 0.0027879669796675444}, {"id": 890, "seek": 319280, "start": 3192.8, "end": 3195.92, "text": " frontier of AI machine learning because it's the one that's", "tokens": [50364, 35853, 295, 7318, 3479, 2539, 570, 309, 311, 264, 472, 300, 311, 50520], "temperature": 0.0, "avg_logprob": -0.12337335787321392, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.007859491743147373}, {"id": 891, "seek": 319280, "start": 3195.92, "end": 3200.32, "text": " richest in terms of the creativity and also in terms of the need to bring in", "tokens": [50520, 35098, 294, 2115, 295, 264, 12915, 293, 611, 294, 2115, 295, 264, 643, 281, 1565, 294, 50740], "temperature": 0.0, "avg_logprob": -0.12337335787321392, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.007859491743147373}, {"id": 892, "seek": 319280, "start": 3200.32, "end": 3204.1600000000003, "text": " some of that beautiful mathematics that that underpins the universe", "tokens": [50740, 512, 295, 300, 2238, 18666, 300, 300, 833, 79, 1292, 264, 6445, 50932], "temperature": 0.0, "avg_logprob": -0.12337335787321392, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.007859491743147373}, {"id": 893, "seek": 319280, "start": 3204.1600000000003, "end": 3207.6800000000003, "text": " yeah so so fascinating I mean could we just linger just just for a second on", "tokens": [50932, 1338, 370, 370, 10343, 286, 914, 727, 321, 445, 45657, 445, 445, 337, 257, 1150, 322, 51108], "temperature": 0.0, "avg_logprob": -0.12337335787321392, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.007859491743147373}, {"id": 894, "seek": 319280, "start": 3207.6800000000003, "end": 3211.92, "text": " that so rich Sutton in his bitter lesson essay he explicitly called out", "tokens": [51108, 300, 370, 4593, 40492, 1756, 294, 702, 13871, 6898, 16238, 415, 20803, 1219, 484, 51320], "temperature": 0.0, "avg_logprob": -0.12337335787321392, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.007859491743147373}, {"id": 895, "seek": 319280, "start": 3211.92, "end": 3215.84, "text": " symmetries as being you know he was warning against human designed", "tokens": [51320, 14232, 302, 2244, 382, 885, 291, 458, 415, 390, 9164, 1970, 1952, 4761, 51516], "temperature": 0.0, "avg_logprob": -0.12337335787321392, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.007859491743147373}, {"id": 896, "seek": 319280, "start": 3215.84, "end": 3220.8, "text": " artifacts in in these models and I mean max welling as you say famously", "tokens": [51516, 24617, 294, 294, 613, 5245, 293, 286, 914, 11469, 731, 278, 382, 291, 584, 34360, 51764], "temperature": 0.0, "avg_logprob": -0.12337335787321392, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.007859491743147373}, {"id": 897, "seek": 322080, "start": 3220.8, "end": 3224.5600000000004, "text": " built these gauge equivariant neural networks bringing in his", "tokens": [50364, 3094, 613, 17924, 1267, 592, 3504, 394, 18161, 9590, 5062, 294, 702, 50552], "temperature": 0.0, "avg_logprob": -0.11938195001511347, "compression_ratio": 1.800796812749004, "no_speech_prob": 0.009506740607321262}, {"id": 898, "seek": 322080, "start": 3224.5600000000004, "end": 3228.96, "text": " physics knowledge and so I'm just trying to understand the spectrum between", "tokens": [50552, 10649, 3601, 293, 370, 286, 478, 445, 1382, 281, 1223, 264, 11143, 1296, 50772], "temperature": 0.0, "avg_logprob": -0.11938195001511347, "compression_ratio": 1.800796812749004, "no_speech_prob": 0.009506740607321262}, {"id": 899, "seek": 322080, "start": 3228.96, "end": 3233.92, "text": " high-resolution physical priors and the kind of macroscopic human knowledge", "tokens": [50772, 1090, 12, 495, 3386, 4001, 1790, 830, 293, 264, 733, 295, 7912, 38006, 299, 1952, 3601, 51020], "temperature": 0.0, "avg_logprob": -0.11938195001511347, "compression_ratio": 1.800796812749004, "no_speech_prob": 0.009506740607321262}, {"id": 900, "seek": 322080, "start": 3233.92, "end": 3236.96, "text": " that that we learn which is presumably brittle", "tokens": [51020, 300, 300, 321, 1466, 597, 307, 26742, 49325, 51172], "temperature": 0.0, "avg_logprob": -0.11938195001511347, "compression_ratio": 1.800796812749004, "no_speech_prob": 0.009506740607321262}, {"id": 901, "seek": 322080, "start": 3236.96, "end": 3241.52, "text": " is it just that we think that these physical priors are fundamental", "tokens": [51172, 307, 309, 445, 300, 321, 519, 300, 613, 4001, 1790, 830, 366, 8088, 51400], "temperature": 0.0, "avg_logprob": -0.11938195001511347, "compression_ratio": 1.800796812749004, "no_speech_prob": 0.009506740607321262}, {"id": 902, "seek": 322080, "start": 3241.52, "end": 3245.44, "text": " and that's that's a that's a perfectly acceptable way to constrain", "tokens": [51400, 293, 300, 311, 300, 311, 257, 300, 311, 257, 6239, 15513, 636, 281, 1817, 7146, 51596], "temperature": 0.0, "avg_logprob": -0.11938195001511347, "compression_ratio": 1.800796812749004, "no_speech_prob": 0.009506740607321262}, {"id": 903, "seek": 322080, "start": 3245.44, "end": 3249.44, "text": " the search space but these high-level priors are brittle", "tokens": [51596, 264, 3164, 1901, 457, 613, 1090, 12, 12418, 1790, 830, 366, 49325, 51796], "temperature": 0.0, "avg_logprob": -0.11938195001511347, "compression_ratio": 1.800796812749004, "no_speech_prob": 0.009506740607321262}, {"id": 904, "seek": 324944, "start": 3249.44, "end": 3252.64, "text": " yes I think I think the the the prior knowledge that comes from human", "tokens": [50364, 2086, 286, 519, 286, 519, 264, 264, 264, 4059, 3601, 300, 1487, 490, 1952, 50524], "temperature": 0.0, "avg_logprob": -0.10050297634942192, "compression_ratio": 1.9618644067796611, "no_speech_prob": 0.0008013664046302438}, {"id": 905, "seek": 324944, "start": 3252.64, "end": 3256.56, "text": " experience is is is more of that brittle kind", "tokens": [50524, 1752, 307, 307, 307, 544, 295, 300, 49325, 733, 50720], "temperature": 0.0, "avg_logprob": -0.10050297634942192, "compression_ratio": 1.9618644067796611, "no_speech_prob": 0.0008013664046302438}, {"id": 906, "seek": 324944, "start": 3256.56, "end": 3260.08, "text": " because the machine can see far more examples than a human can in a", "tokens": [50720, 570, 264, 3479, 393, 536, 1400, 544, 5110, 813, 257, 1952, 393, 294, 257, 50896], "temperature": 0.0, "avg_logprob": -0.10050297634942192, "compression_ratio": 1.9618644067796611, "no_speech_prob": 0.0008013664046302438}, {"id": 907, "seek": 324944, "start": 3260.08, "end": 3264.16, "text": " lifetime and can can do a more systematic job", "tokens": [50896, 11364, 293, 393, 393, 360, 257, 544, 27249, 1691, 51100], "temperature": 0.0, "avg_logprob": -0.10050297634942192, "compression_ratio": 1.9618644067796611, "no_speech_prob": 0.0008013664046302438}, {"id": 908, "seek": 324944, "start": 3264.16, "end": 3267.6, "text": " of looking across all of that data we're not", "tokens": [51100, 295, 1237, 2108, 439, 295, 300, 1412, 321, 434, 406, 51272], "temperature": 0.0, "avg_logprob": -0.10050297634942192, "compression_ratio": 1.9618644067796611, "no_speech_prob": 0.0008013664046302438}, {"id": 909, "seek": 324944, "start": 3267.6, "end": 3270.7200000000003, "text": " not subject to say recency bias and those sorts of things", "tokens": [51272, 406, 3983, 281, 584, 850, 3020, 12577, 293, 729, 7527, 295, 721, 51428], "temperature": 0.0, "avg_logprob": -0.10050297634942192, "compression_ratio": 1.9618644067796611, "no_speech_prob": 0.0008013664046302438}, {"id": 910, "seek": 324944, "start": 3270.7200000000003, "end": 3273.76, "text": " so I think that kind of prior knowledge is is one where", "tokens": [51428, 370, 286, 519, 300, 733, 295, 4059, 3601, 307, 307, 472, 689, 51580], "temperature": 0.0, "avg_logprob": -0.10050297634942192, "compression_ratio": 1.9618644067796611, "no_speech_prob": 0.0008013664046302438}, {"id": 911, "seek": 324944, "start": 3273.76, "end": 3278.64, "text": " where scale and data will will win whereas the the prior knowledge that we", "tokens": [51580, 689, 4373, 293, 1412, 486, 486, 1942, 9735, 264, 264, 4059, 3601, 300, 321, 51824], "temperature": 0.0, "avg_logprob": -0.10050297634942192, "compression_ratio": 1.9618644067796611, "no_speech_prob": 0.0008013664046302438}, {"id": 912, "seek": 327864, "start": 3278.64, "end": 3282.0, "text": " have from the physical laws in a sense is much more rigorous and symmetry", "tokens": [50364, 362, 490, 264, 4001, 6064, 294, 257, 2020, 307, 709, 544, 29882, 293, 25440, 50532], "temperature": 0.0, "avg_logprob": -0.12407684326171875, "compression_ratio": 1.99581589958159, "no_speech_prob": 0.000940702564548701}, {"id": 913, "seek": 327864, "start": 3282.0, "end": 3285.04, "text": " is is is very powerful it's sometimes said that", "tokens": [50532, 307, 307, 307, 588, 4005, 309, 311, 2171, 848, 300, 50684], "temperature": 0.0, "avg_logprob": -0.12407684326171875, "compression_ratio": 1.99581589958159, "no_speech_prob": 0.000940702564548701}, {"id": 914, "seek": 327864, "start": 3285.04, "end": 3287.7599999999998, "text": " physics more or less is symmetry that's almost", "tokens": [50684, 10649, 544, 420, 1570, 307, 25440, 300, 311, 1920, 50820], "temperature": 0.0, "avg_logprob": -0.12407684326171875, "compression_ratio": 1.99581589958159, "no_speech_prob": 0.000940702564548701}, {"id": 915, "seek": 327864, "start": 3287.7599999999998, "end": 3291.44, "text": " yes right so conservation conservation laws arise from", "tokens": [50820, 2086, 558, 370, 16185, 16185, 6064, 20288, 490, 51004], "temperature": 0.0, "avg_logprob": -0.12407684326171875, "compression_ratio": 1.99581589958159, "no_speech_prob": 0.000940702564548701}, {"id": 916, "seek": 327864, "start": 3291.44, "end": 3294.16, "text": " symmetry you know translation in variance in", "tokens": [51004, 25440, 291, 458, 12853, 294, 21977, 294, 51140], "temperature": 0.0, "avg_logprob": -0.12407684326171875, "compression_ratio": 1.99581589958159, "no_speech_prob": 0.000940702564548701}, {"id": 917, "seek": 327864, "start": 3294.16, "end": 3297.8399999999997, "text": " spacetime gives you conservation of energy and momentum", "tokens": [51140, 39404, 9764, 2709, 291, 16185, 295, 2281, 293, 11244, 51324], "temperature": 0.0, "avg_logprob": -0.12407684326171875, "compression_ratio": 1.99581589958159, "no_speech_prob": 0.000940702564548701}, {"id": 918, "seek": 327864, "start": 3297.8399999999997, "end": 3301.7599999999998, "text": " and you know gauge symmetry of the electromagnetic field gives you charge", "tokens": [51324, 293, 291, 458, 17924, 25440, 295, 264, 32214, 2519, 2709, 291, 4602, 51520], "temperature": 0.0, "avg_logprob": -0.12407684326171875, "compression_ratio": 1.99581589958159, "no_speech_prob": 0.000940702564548701}, {"id": 919, "seek": 327864, "start": 3301.7599999999998, "end": 3306.16, "text": " conservation and so on and and so these are very very rigorous laws that apply", "tokens": [51520, 16185, 293, 370, 322, 293, 293, 370, 613, 366, 588, 588, 29882, 6064, 300, 3079, 51740], "temperature": 0.0, "avg_logprob": -0.12407684326171875, "compression_ratio": 1.99581589958159, "no_speech_prob": 0.000940702564548701}, {"id": 920, "seek": 330616, "start": 3306.16, "end": 3309.2, "text": " from symmetry but you know even if you take a data-driven approach", "tokens": [50364, 490, 25440, 457, 291, 458, 754, 498, 291, 747, 257, 1412, 12, 25456, 3109, 50516], "temperature": 0.0, "avg_logprob": -0.07140926938307912, "compression_ratio": 1.8955223880597014, "no_speech_prob": 0.019688714295625687}, {"id": 921, "seek": 330616, "start": 3309.2, "end": 3312.3199999999997, "text": " people often use data augmentation if you know that an object doesn't depend", "tokens": [50516, 561, 2049, 764, 1412, 14501, 19631, 498, 291, 458, 300, 364, 2657, 1177, 380, 5672, 50672], "temperature": 0.0, "avg_logprob": -0.07140926938307912, "compression_ratio": 1.8955223880597014, "no_speech_prob": 0.019688714295625687}, {"id": 922, "seek": 330616, "start": 3312.3199999999997, "end": 3314.72, "text": " his identity doesn't depend on where it is in the image you might", "tokens": [50672, 702, 6575, 1177, 380, 5672, 322, 689, 309, 307, 294, 264, 3256, 291, 1062, 50792], "temperature": 0.0, "avg_logprob": -0.07140926938307912, "compression_ratio": 1.8955223880597014, "no_speech_prob": 0.019688714295625687}, {"id": 923, "seek": 330616, "start": 3314.72, "end": 3317.6, "text": " you know make lots of random translations of your data to augment", "tokens": [50792, 291, 458, 652, 3195, 295, 4974, 37578, 295, 428, 1412, 281, 29919, 50936], "temperature": 0.0, "avg_logprob": -0.07140926938307912, "compression_ratio": 1.8955223880597014, "no_speech_prob": 0.019688714295625687}, {"id": 924, "seek": 330616, "start": 3317.6, "end": 3321.68, "text": " your data so data augmentation can be a data-driven way of building in those", "tokens": [50936, 428, 1412, 370, 1412, 14501, 19631, 393, 312, 257, 1412, 12, 25456, 636, 295, 2390, 294, 729, 51140], "temperature": 0.0, "avg_logprob": -0.07140926938307912, "compression_ratio": 1.8955223880597014, "no_speech_prob": 0.019688714295625687}, {"id": 925, "seek": 330616, "start": 3321.68, "end": 3324.3199999999997, "text": " symmetries but now when we have very rich prior", "tokens": [51140, 14232, 302, 2244, 457, 586, 562, 321, 362, 588, 4593, 4059, 51272], "temperature": 0.0, "avg_logprob": -0.07140926938307912, "compression_ratio": 1.8955223880597014, "no_speech_prob": 0.019688714295625687}, {"id": 926, "seek": 330616, "start": 3324.3199999999997, "end": 3327.3599999999997, "text": " knowledge I'll come back to Schrodinger's equation it describes the world with", "tokens": [51272, 3601, 286, 603, 808, 646, 281, 2065, 340, 3584, 260, 311, 5367, 309, 15626, 264, 1002, 365, 51424], "temperature": 0.0, "avg_logprob": -0.07140926938307912, "compression_ratio": 1.8955223880597014, "no_speech_prob": 0.019688714295625687}, {"id": 927, "seek": 330616, "start": 3327.3599999999997, "end": 3331.2799999999997, "text": " exquisite precision at the atomic level but solving it is very very expensive", "tokens": [51424, 454, 34152, 18356, 412, 264, 22275, 1496, 457, 12606, 309, 307, 588, 588, 5124, 51620], "temperature": 0.0, "avg_logprob": -0.07140926938307912, "compression_ratio": 1.8955223880597014, "no_speech_prob": 0.019688714295625687}, {"id": 928, "seek": 330616, "start": 3331.2799999999997, "end": 3335.2799999999997, "text": " and so what we can do is we can cache those computations we call it the fifth", "tokens": [51620, 293, 370, 437, 321, 393, 360, 307, 321, 393, 19459, 729, 2807, 763, 321, 818, 309, 264, 9266, 51820], "temperature": 0.0, "avg_logprob": -0.07140926938307912, "compression_ratio": 1.8955223880597014, "no_speech_prob": 0.019688714295625687}, {"id": 929, "seek": 333528, "start": 3335.28, "end": 3338.48, "text": " paradigm of scientific discovery which is a rather fancy term but the idea is", "tokens": [50364, 24709, 295, 8134, 12114, 597, 307, 257, 2831, 10247, 1433, 457, 264, 1558, 307, 50524], "temperature": 0.0, "avg_logprob": -0.07818118875676935, "compression_ratio": 1.9591078066914498, "no_speech_prob": 0.0021399979013949633}, {"id": 930, "seek": 333528, "start": 3338.48, "end": 3342.96, "text": " very simple is that instead of taking a conventional numerical", "tokens": [50524, 588, 2199, 307, 300, 2602, 295, 1940, 257, 16011, 29054, 50748], "temperature": 0.0, "avg_logprob": -0.07818118875676935, "compression_ratio": 1.9591078066914498, "no_speech_prob": 0.0021399979013949633}, {"id": 931, "seek": 333528, "start": 3342.96, "end": 3346.5600000000004, "text": " solver and using it to solve something like Schrodinger's equation or something", "tokens": [50748, 1404, 331, 293, 1228, 309, 281, 5039, 746, 411, 2065, 340, 3584, 260, 311, 5367, 420, 746, 50928], "temperature": 0.0, "avg_logprob": -0.07818118875676935, "compression_ratio": 1.9591078066914498, "no_speech_prob": 0.0021399979013949633}, {"id": 932, "seek": 333528, "start": 3346.5600000000004, "end": 3350.0, "text": " called density functional theory instead of solving that directly to solve your", "tokens": [50928, 1219, 10305, 11745, 5261, 2602, 295, 12606, 300, 3838, 281, 5039, 428, 51100], "temperature": 0.0, "avg_logprob": -0.07818118875676935, "compression_ratio": 1.9591078066914498, "no_speech_prob": 0.0021399979013949633}, {"id": 933, "seek": 333528, "start": 3350.0, "end": 3353.84, "text": " problem instead you use that simulator to", "tokens": [51100, 1154, 2602, 291, 764, 300, 32974, 281, 51292], "temperature": 0.0, "avg_logprob": -0.07818118875676935, "compression_ratio": 1.9591078066914498, "no_speech_prob": 0.0021399979013949633}, {"id": 934, "seek": 333528, "start": 3353.84, "end": 3356.96, "text": " generate training data and use that training data to train a", "tokens": [51292, 8460, 3097, 1412, 293, 764, 300, 3097, 1412, 281, 3847, 257, 51448], "temperature": 0.0, "avg_logprob": -0.07818118875676935, "compression_ratio": 1.9591078066914498, "no_speech_prob": 0.0021399979013949633}, {"id": 935, "seek": 333528, "start": 3356.96, "end": 3360.88, "text": " machine learning emulator and then that machine learning emulator", "tokens": [51448, 3479, 2539, 846, 16381, 293, 550, 300, 3479, 2539, 846, 16381, 51644], "temperature": 0.0, "avg_logprob": -0.07818118875676935, "compression_ratio": 1.9591078066914498, "no_speech_prob": 0.0021399979013949633}, {"id": 936, "seek": 333528, "start": 3360.88, "end": 3364.4, "text": " can now emulate the simulator but typically three or four", "tokens": [51644, 393, 586, 45497, 264, 32974, 457, 5850, 1045, 420, 1451, 51820], "temperature": 0.0, "avg_logprob": -0.07818118875676935, "compression_ratio": 1.9591078066914498, "no_speech_prob": 0.0021399979013949633}, {"id": 937, "seek": 336440, "start": 3364.4, "end": 3368.8, "text": " orders of magnitude faster so provided you use it a lot and you amortize the one", "tokens": [50364, 9470, 295, 15668, 4663, 370, 5649, 291, 764, 309, 257, 688, 293, 291, 669, 477, 1125, 264, 472, 50584], "temperature": 0.0, "avg_logprob": -0.09901554870605468, "compression_ratio": 2.007518796992481, "no_speech_prob": 0.0024952625390142202}, {"id": 938, "seek": 336440, "start": 3368.8, "end": 3372.08, "text": " off cost of generating the training data and doing the training if you're going", "tokens": [50584, 766, 2063, 295, 17746, 264, 3097, 1412, 293, 884, 264, 3097, 498, 291, 434, 516, 50748], "temperature": 0.0, "avg_logprob": -0.09901554870605468, "compression_ratio": 2.007518796992481, "no_speech_prob": 0.0024952625390142202}, {"id": 939, "seek": 336440, "start": 3372.08, "end": 3376.96, "text": " to use it many many times overall it becomes dramatically faster dramatically", "tokens": [50748, 281, 764, 309, 867, 867, 1413, 4787, 309, 3643, 17548, 4663, 17548, 50992], "temperature": 0.0, "avg_logprob": -0.09901554870605468, "compression_ratio": 2.007518796992481, "no_speech_prob": 0.0024952625390142202}, {"id": 940, "seek": 336440, "start": 3376.96, "end": 3380.56, "text": " more efficient than using the simulator and that that's just one of the", "tokens": [50992, 544, 7148, 813, 1228, 264, 32974, 293, 300, 300, 311, 445, 472, 295, 264, 51172], "temperature": 0.0, "avg_logprob": -0.09901554870605468, "compression_ratio": 2.007518796992481, "no_speech_prob": 0.0024952625390142202}, {"id": 941, "seek": 336440, "start": 3380.56, "end": 3384.08, "text": " breakthroughs we're seeing in this space so first of all um there's there's a", "tokens": [51172, 22397, 82, 321, 434, 2577, 294, 341, 1901, 370, 700, 295, 439, 1105, 456, 311, 456, 311, 257, 51348], "temperature": 0.0, "avg_logprob": -0.09901554870605468, "compression_ratio": 2.007518796992481, "no_speech_prob": 0.0024952625390142202}, {"id": 942, "seek": 336440, "start": 3384.08, "end": 3387.6800000000003, "text": " spectrum as you say of we could just train on lots of data or we could", "tokens": [51348, 11143, 382, 291, 584, 295, 321, 727, 445, 3847, 322, 3195, 295, 1412, 420, 321, 727, 51528], "temperature": 0.0, "avg_logprob": -0.09901554870605468, "compression_ratio": 2.007518796992481, "no_speech_prob": 0.0024952625390142202}, {"id": 943, "seek": 336440, "start": 3387.6800000000003, "end": 3392.2400000000002, "text": " augment the data or we could make a simulator for the data and then we can", "tokens": [51528, 29919, 264, 1412, 420, 321, 727, 652, 257, 32974, 337, 264, 1412, 293, 550, 321, 393, 51756], "temperature": 0.0, "avg_logprob": -0.09901554870605468, "compression_ratio": 2.007518796992481, "no_speech_prob": 0.0024952625390142202}, {"id": 944, "seek": 339224, "start": 3392.24, "end": 3396.0, "text": " train a machine learning model and as we were just speaking to", "tokens": [50364, 3847, 257, 3479, 2539, 2316, 293, 382, 321, 645, 445, 4124, 281, 50552], "temperature": 0.0, "avg_logprob": -0.09841076987130301, "compression_ratio": 1.7357723577235773, "no_speech_prob": 0.014293867163360119}, {"id": 945, "seek": 339224, "start": 3396.0, "end": 3399.12, "text": " these inductive priors they are so high resolution", "tokens": [50552, 613, 31612, 488, 1790, 830, 436, 366, 370, 1090, 8669, 50708], "temperature": 0.0, "avg_logprob": -0.09841076987130301, "compression_ratio": 1.7357723577235773, "no_speech_prob": 0.014293867163360119}, {"id": 946, "seek": 339224, "start": 3399.12, "end": 3404.08, "text": " that we are not restricting the target function that that that we want to", "tokens": [50708, 300, 321, 366, 406, 1472, 37714, 264, 3779, 2445, 300, 300, 300, 321, 528, 281, 50956], "temperature": 0.0, "avg_logprob": -0.09841076987130301, "compression_ratio": 1.7357723577235773, "no_speech_prob": 0.014293867163360119}, {"id": 947, "seek": 339224, "start": 3404.08, "end": 3406.9599999999996, "text": " learn and we can make quite a principled argument about that", "tokens": [50956, 1466, 293, 321, 393, 652, 1596, 257, 3681, 15551, 6770, 466, 300, 51100], "temperature": 0.0, "avg_logprob": -0.09841076987130301, "compression_ratio": 1.7357723577235773, "no_speech_prob": 0.014293867163360119}, {"id": 948, "seek": 339224, "start": 3406.9599999999996, "end": 3410.8799999999997, "text": " but the one question to me is there's a kind of", "tokens": [51100, 457, 264, 472, 1168, 281, 385, 307, 456, 311, 257, 733, 295, 51296], "temperature": 0.0, "avg_logprob": -0.09841076987130301, "compression_ratio": 1.7357723577235773, "no_speech_prob": 0.014293867163360119}, {"id": 949, "seek": 339224, "start": 3410.8799999999997, "end": 3414.7999999999997, "text": " I don't know whether it's best to frame it as exploration versus exploitation but", "tokens": [51296, 286, 500, 380, 458, 1968, 309, 311, 1151, 281, 3920, 309, 382, 16197, 5717, 33122, 457, 51492], "temperature": 0.0, "avg_logprob": -0.09841076987130301, "compression_ratio": 1.7357723577235773, "no_speech_prob": 0.014293867163360119}, {"id": 950, "seek": 339224, "start": 3414.7999999999997, "end": 3418.0, "text": " there needs to be some amount of going off-piste", "tokens": [51492, 456, 2203, 281, 312, 512, 2372, 295, 516, 766, 12, 79, 8375, 51652], "temperature": 0.0, "avg_logprob": -0.09841076987130301, "compression_ratio": 1.7357723577235773, "no_speech_prob": 0.014293867163360119}, {"id": 951, "seek": 341800, "start": 3418.0, "end": 3422.64, "text": " so we define the structure and we we essentially build a generative model", "tokens": [50364, 370, 321, 6964, 264, 3877, 293, 321, 321, 4476, 1322, 257, 1337, 1166, 2316, 50596], "temperature": 0.0, "avg_logprob": -0.07190530829959446, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.00021736268536187708}, {"id": 952, "seek": 341800, "start": 3422.64, "end": 3425.2, "text": " and we can generate a whole bunch of trajectories", "tokens": [50596, 293, 321, 393, 8460, 257, 1379, 3840, 295, 18257, 2083, 50724], "temperature": 0.0, "avg_logprob": -0.07190530829959446, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.00021736268536187708}, {"id": 953, "seek": 341800, "start": 3425.2, "end": 3428.88, "text": " but could it ever be the case that we wouldn't have enough", "tokens": [50724, 457, 727, 309, 1562, 312, 264, 1389, 300, 321, 2759, 380, 362, 1547, 50908], "temperature": 0.0, "avg_logprob": -0.07190530829959446, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.00021736268536187708}, {"id": 954, "seek": 341800, "start": 3428.88, "end": 3433.28, "text": " variance to find something interesting there's a very interesting question", "tokens": [50908, 21977, 281, 915, 746, 1880, 456, 311, 257, 588, 1880, 1168, 51128], "temperature": 0.0, "avg_logprob": -0.07190530829959446, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.00021736268536187708}, {"id": 955, "seek": 341800, "start": 3433.28, "end": 3437.2, "text": " about the the overall scientific method of formulating hypotheses running", "tokens": [51128, 466, 264, 264, 4787, 8134, 3170, 295, 1254, 12162, 49969, 2614, 51324], "temperature": 0.0, "avg_logprob": -0.07190530829959446, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.00021736268536187708}, {"id": 956, "seek": 341800, "start": 3437.2, "end": 3440.4, "text": " tests evaluating those hypotheses refining the hypotheses running more", "tokens": [51324, 6921, 27479, 729, 49969, 1895, 1760, 264, 49969, 2614, 544, 51484], "temperature": 0.0, "avg_logprob": -0.07190530829959446, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.00021736268536187708}, {"id": 957, "seek": 341800, "start": 3440.4, "end": 3443.04, "text": " experiments and so on that that scientific loop", "tokens": [51484, 12050, 293, 370, 322, 300, 300, 8134, 6367, 51616], "temperature": 0.0, "avg_logprob": -0.07190530829959446, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.00021736268536187708}, {"id": 958, "seek": 341800, "start": 3443.04, "end": 3446.16, "text": " I think machine learning will have an important role to play there because", "tokens": [51616, 286, 519, 3479, 2539, 486, 362, 364, 1021, 3090, 281, 862, 456, 570, 51772], "temperature": 0.0, "avg_logprob": -0.07190530829959446, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.00021736268536187708}, {"id": 959, "seek": 344616, "start": 3446.16, "end": 3449.7599999999998, "text": " data is becoming very high dimensional very high throughput humans can't", "tokens": [50364, 1412, 307, 5617, 588, 1090, 18795, 588, 1090, 44629, 6255, 393, 380, 50544], "temperature": 0.0, "avg_logprob": -0.09174905923696665, "compression_ratio": 1.849056603773585, "no_speech_prob": 0.004955607000738382}, {"id": 960, "seek": 344616, "start": 3449.7599999999998, "end": 3452.72, "text": " analyze this data anymore a human can't directly look at the output of the", "tokens": [50544, 12477, 341, 1412, 3602, 257, 1952, 393, 380, 3838, 574, 412, 264, 5598, 295, 264, 50692], "temperature": 0.0, "avg_logprob": -0.09174905923696665, "compression_ratio": 1.849056603773585, "no_speech_prob": 0.004955607000738382}, {"id": 961, "seek": 344616, "start": 3452.72, "end": 3456.16, "text": " large hadron collider with its you know petabytes a second or whatever it is", "tokens": [50692, 2416, 632, 2044, 1263, 1438, 365, 1080, 291, 458, 3817, 24538, 257, 1150, 420, 2035, 309, 307, 50864], "temperature": 0.0, "avg_logprob": -0.09174905923696665, "compression_ratio": 1.849056603773585, "no_speech_prob": 0.004955607000738382}, {"id": 962, "seek": 344616, "start": 3456.16, "end": 3461.12, "text": " pouring off we we need machines to help us but again I think the human", "tokens": [50864, 20450, 766, 321, 321, 643, 8379, 281, 854, 505, 457, 797, 286, 519, 264, 1952, 51112], "temperature": 0.0, "avg_logprob": -0.09174905923696665, "compression_ratio": 1.849056603773585, "no_speech_prob": 0.004955607000738382}, {"id": 963, "seek": 344616, "start": 3461.12, "end": 3464.48, "text": " rises to the level of the conductor of the orchestra as it were they no longer", "tokens": [51112, 21373, 281, 264, 1496, 295, 264, 29957, 295, 264, 25280, 382, 309, 645, 436, 572, 2854, 51280], "temperature": 0.0, "avg_logprob": -0.09174905923696665, "compression_ratio": 1.849056603773585, "no_speech_prob": 0.004955607000738382}, {"id": 964, "seek": 344616, "start": 3464.48, "end": 3468.16, "text": " have to do things by hand machines are helping to accelerate that", "tokens": [51280, 362, 281, 360, 721, 538, 1011, 8379, 366, 4315, 281, 21341, 300, 51464], "temperature": 0.0, "avg_logprob": -0.09174905923696665, "compression_ratio": 1.849056603773585, "no_speech_prob": 0.004955607000738382}, {"id": 965, "seek": 344616, "start": 3468.16, "end": 3471.2, "text": " and and I think the machines can help accelerate the creative process", "tokens": [51464, 293, 293, 286, 519, 264, 8379, 393, 854, 21341, 264, 5880, 1399, 51616], "temperature": 0.0, "avg_logprob": -0.09174905923696665, "compression_ratio": 1.849056603773585, "no_speech_prob": 0.004955607000738382}, {"id": 966, "seek": 344616, "start": 3471.2, "end": 3475.2, "text": " potentially by pointing to anomalies or highlighting patterns in the data and", "tokens": [51616, 7263, 538, 12166, 281, 24769, 48872, 420, 26551, 8294, 294, 264, 1412, 293, 51816], "temperature": 0.0, "avg_logprob": -0.09174905923696665, "compression_ratio": 1.849056603773585, "no_speech_prob": 0.004955607000738382}, {"id": 967, "seek": 347520, "start": 3475.2, "end": 3478.48, "text": " so on but very much with the human scientist in the loop", "tokens": [50364, 370, 322, 457, 588, 709, 365, 264, 1952, 12662, 294, 264, 6367, 50528], "temperature": 0.0, "avg_logprob": -0.10996705088122137, "compression_ratio": 1.9444444444444444, "no_speech_prob": 0.0023239802103489637}, {"id": 968, "seek": 347520, "start": 3478.48, "end": 3481.52, "text": " but but even coming down from those sort of lofty more sort of philosophical", "tokens": [50528, 457, 457, 754, 1348, 760, 490, 729, 1333, 295, 34419, 88, 544, 1333, 295, 25066, 50680], "temperature": 0.0, "avg_logprob": -0.10996705088122137, "compression_ratio": 1.9444444444444444, "no_speech_prob": 0.0023239802103489637}, {"id": 969, "seek": 347520, "start": 3481.52, "end": 3485.2799999999997, "text": " considerations just to the the practicalities when we talk about discovery", "tokens": [50680, 24070, 445, 281, 264, 264, 8496, 1088, 562, 321, 751, 466, 12114, 50868], "temperature": 0.0, "avg_logprob": -0.10996705088122137, "compression_ratio": 1.9444444444444444, "no_speech_prob": 0.0023239802103489637}, {"id": 970, "seek": 347520, "start": 3485.2799999999997, "end": 3487.8399999999997, "text": " we're also interested just the very practical method of how we how do we", "tokens": [50868, 321, 434, 611, 3102, 445, 264, 588, 8496, 3170, 295, 577, 321, 577, 360, 321, 50996], "temperature": 0.0, "avg_logprob": -0.10996705088122137, "compression_ratio": 1.9444444444444444, "no_speech_prob": 0.0023239802103489637}, {"id": 971, "seek": 347520, "start": 3487.8399999999997, "end": 3490.8799999999997, "text": " discover a new drug or how do we discover a new material", "tokens": [50996, 4411, 257, 777, 4110, 420, 577, 360, 321, 4411, 257, 777, 2527, 51148], "temperature": 0.0, "avg_logprob": -0.10996705088122137, "compression_ratio": 1.9444444444444444, "no_speech_prob": 0.0023239802103489637}, {"id": 972, "seek": 347520, "start": 3490.8799999999997, "end": 3494.56, "text": " so scientific discovery also means that that that that that very pragmatic", "tokens": [51148, 370, 8134, 12114, 611, 1355, 300, 300, 300, 300, 300, 588, 46904, 51332], "temperature": 0.0, "avg_logprob": -0.10996705088122137, "compression_ratio": 1.9444444444444444, "no_speech_prob": 0.0023239802103489637}, {"id": 973, "seek": 347520, "start": 3494.56, "end": 3498.08, "text": " near-term approach and there we're seeing really dramatic", "tokens": [51332, 2651, 12, 7039, 3109, 293, 456, 321, 434, 2577, 534, 12023, 51508], "temperature": 0.0, "avg_logprob": -0.10996705088122137, "compression_ratio": 1.9444444444444444, "no_speech_prob": 0.0023239802103489637}, {"id": 974, "seek": 347520, "start": 3498.08, "end": 3501.68, "text": " acceleration through the the concept of this emulator", "tokens": [51508, 17162, 807, 264, 264, 3410, 295, 341, 846, 16381, 51688], "temperature": 0.0, "avg_logprob": -0.10996705088122137, "compression_ratio": 1.9444444444444444, "no_speech_prob": 0.0023239802103489637}, {"id": 975, "seek": 350168, "start": 3501.68, "end": 3505.12, "text": " inner ability to explore the combinatorically vast space of new", "tokens": [50364, 7284, 3485, 281, 6839, 264, 2512, 31927, 984, 8369, 1901, 295, 777, 50536], "temperature": 0.0, "avg_logprob": -0.1290346105047997, "compression_ratio": 1.8237704918032787, "no_speech_prob": 0.004277817439287901}, {"id": 976, "seek": 350168, "start": 3505.12, "end": 3509.12, "text": " molecules and new materials exploring those spaces efficiently to find", "tokens": [50536, 13093, 293, 777, 5319, 12736, 729, 7673, 19621, 281, 915, 50736], "temperature": 0.0, "avg_logprob": -0.1290346105047997, "compression_ratio": 1.8237704918032787, "no_speech_prob": 0.004277817439287901}, {"id": 977, "seek": 350168, "start": 3509.12, "end": 3513.52, "text": " potential candidates that might be new drugs or new", "tokens": [50736, 3995, 11255, 300, 1062, 312, 777, 7766, 420, 777, 50956], "temperature": 0.0, "avg_logprob": -0.1290346105047997, "compression_ratio": 1.8237704918032787, "no_speech_prob": 0.004277817439287901}, {"id": 978, "seek": 350168, "start": 3513.52, "end": 3516.7999999999997, "text": " new materials for batteries or other other forms of green energy", "tokens": [50956, 777, 5319, 337, 13070, 420, 661, 661, 6422, 295, 3092, 2281, 51120], "temperature": 0.0, "avg_logprob": -0.1290346105047997, "compression_ratio": 1.8237704918032787, "no_speech_prob": 0.004277817439287901}, {"id": 979, "seek": 350168, "start": 3516.7999999999997, "end": 3520.8799999999997, "text": " so that that alone is a very exciting frontier I think", "tokens": [51120, 370, 300, 300, 3312, 307, 257, 588, 4670, 35853, 286, 519, 51324], "temperature": 0.0, "avg_logprob": -0.1290346105047997, "compression_ratio": 1.8237704918032787, "no_speech_prob": 0.004277817439287901}, {"id": 980, "seek": 350168, "start": 3520.8799999999997, "end": 3525.44, "text": " it's so interesting so searching these space I mean drug discovery is an", "tokens": [51324, 309, 311, 370, 1880, 370, 10808, 613, 1901, 286, 914, 4110, 12114, 307, 364, 51552], "temperature": 0.0, "avg_logprob": -0.1290346105047997, "compression_ratio": 1.8237704918032787, "no_speech_prob": 0.004277817439287901}, {"id": 981, "seek": 350168, "start": 3525.44, "end": 3528.72, "text": " interesting one I think you spoke about sustainability as well as", "tokens": [51552, 1880, 472, 286, 519, 291, 7179, 466, 16360, 382, 731, 382, 51716], "temperature": 0.0, "avg_logprob": -0.1290346105047997, "compression_ratio": 1.8237704918032787, "no_speech_prob": 0.004277817439287901}, {"id": 982, "seek": 352872, "start": 3528.72, "end": 3532.9599999999996, "text": " another application you can speak to but how do you identify an", "tokens": [50364, 1071, 3861, 291, 393, 1710, 281, 457, 577, 360, 291, 5876, 364, 50576], "temperature": 0.0, "avg_logprob": -0.094317625064661, "compression_ratio": 1.7945736434108528, "no_speech_prob": 0.0007459860644303262}, {"id": 983, "seek": 352872, "start": 3532.9599999999996, "end": 3537.12, "text": " interesting drug so the drug discovery process", "tokens": [50576, 1880, 4110, 370, 264, 4110, 12114, 1399, 50784], "temperature": 0.0, "avg_logprob": -0.094317625064661, "compression_ratio": 1.7945736434108528, "no_speech_prob": 0.0007459860644303262}, {"id": 984, "seek": 352872, "start": 3537.12, "end": 3540.48, "text": " starts first of all with the disease and trying to", "tokens": [50784, 3719, 700, 295, 439, 365, 264, 4752, 293, 1382, 281, 50952], "temperature": 0.0, "avg_logprob": -0.094317625064661, "compression_ratio": 1.7945736434108528, "no_speech_prob": 0.0007459860644303262}, {"id": 985, "seek": 352872, "start": 3540.48, "end": 3543.3599999999997, "text": " first of all deciding we want to go tackle a particular disease", "tokens": [50952, 700, 295, 439, 17990, 321, 528, 281, 352, 14896, 257, 1729, 4752, 51096], "temperature": 0.0, "avg_logprob": -0.094317625064661, "compression_ratio": 1.7945736434108528, "no_speech_prob": 0.0007459860644303262}, {"id": 986, "seek": 352872, "start": 3543.3599999999997, "end": 3547.6, "text": " and then finding a suitable target so the the standard so-called small molecule", "tokens": [51096, 293, 550, 5006, 257, 12873, 3779, 370, 264, 264, 3832, 370, 12, 11880, 1359, 15582, 51308], "temperature": 0.0, "avg_logprob": -0.094317625064661, "compression_ratio": 1.7945736434108528, "no_speech_prob": 0.0007459860644303262}, {"id": 987, "seek": 352872, "start": 3547.6, "end": 3550.3999999999996, "text": " paradigm which is where most drugs are today", "tokens": [51308, 24709, 597, 307, 689, 881, 7766, 366, 965, 51448], "temperature": 0.0, "avg_logprob": -0.094317625064661, "compression_ratio": 1.7945736434108528, "no_speech_prob": 0.0007459860644303262}, {"id": 988, "seek": 352872, "start": 3550.3999999999996, "end": 3554.64, "text": " they're small synthetic organic molecules that bind with a particular", "tokens": [51448, 436, 434, 1359, 23420, 10220, 13093, 300, 14786, 365, 257, 1729, 51660], "temperature": 0.0, "avg_logprob": -0.094317625064661, "compression_ratio": 1.7945736434108528, "no_speech_prob": 0.0007459860644303262}, {"id": 989, "seek": 352872, "start": 3554.64, "end": 3557.6, "text": " protein so pharma companies will will will", "tokens": [51660, 7944, 370, 903, 36159, 3431, 486, 486, 486, 51808], "temperature": 0.0, "avg_logprob": -0.094317625064661, "compression_ratio": 1.7945736434108528, "no_speech_prob": 0.0007459860644303262}, {"id": 990, "seek": 355760, "start": 3557.6, "end": 3561.36, "text": " spend a lot of time identifying targets so say a protein that has a particular", "tokens": [50364, 3496, 257, 688, 295, 565, 16696, 12911, 370, 584, 257, 7944, 300, 575, 257, 1729, 50552], "temperature": 0.0, "avg_logprob": -0.09949083176870195, "compression_ratio": 1.9963898916967509, "no_speech_prob": 0.0006013751844875515}, {"id": 991, "seek": 355760, "start": 3561.36, "end": 3565.36, "text": " region with a molecule combined can combined to", "tokens": [50552, 4458, 365, 257, 15582, 9354, 393, 9354, 281, 50752], "temperature": 0.0, "avg_logprob": -0.09949083176870195, "compression_ratio": 1.9963898916967509, "no_speech_prob": 0.0006013751844875515}, {"id": 992, "seek": 355760, "start": 3565.36, "end": 3568.3199999999997, "text": " and therefore can influence the behavior of that protein switching on or", "tokens": [50752, 293, 4412, 393, 6503, 264, 5223, 295, 300, 7944, 16493, 322, 420, 50900], "temperature": 0.0, "avg_logprob": -0.09949083176870195, "compression_ratio": 1.9963898916967509, "no_speech_prob": 0.0006013751844875515}, {"id": 993, "seek": 355760, "start": 3568.3199999999997, "end": 3571.68, "text": " switching off some part of that disease pathway and breaking the chain of", "tokens": [50900, 16493, 766, 512, 644, 295, 300, 4752, 18590, 293, 7697, 264, 5021, 295, 51068], "temperature": 0.0, "avg_logprob": -0.09949083176870195, "compression_ratio": 1.9963898916967509, "no_speech_prob": 0.0006013751844875515}, {"id": 994, "seek": 355760, "start": 3571.68, "end": 3575.04, "text": " disease so the challenge then is to find a small", "tokens": [51068, 4752, 370, 264, 3430, 550, 307, 281, 915, 257, 1359, 51236], "temperature": 0.0, "avg_logprob": -0.09949083176870195, "compression_ratio": 1.9963898916967509, "no_speech_prob": 0.0006013751844875515}, {"id": 995, "seek": 355760, "start": 3575.04, "end": 3577.8399999999997, "text": " molecule that first of all has the property that it binds with the target", "tokens": [51236, 15582, 300, 700, 295, 439, 575, 264, 4707, 300, 309, 41515, 365, 264, 3779, 51376], "temperature": 0.0, "avg_logprob": -0.09949083176870195, "compression_ratio": 1.9963898916967509, "no_speech_prob": 0.0006013751844875515}, {"id": 996, "seek": 355760, "start": 3577.8399999999997, "end": 3581.52, "text": " protein that's the first step but there are many other things that it has to do", "tokens": [51376, 7944, 300, 311, 264, 700, 1823, 457, 456, 366, 867, 661, 721, 300, 309, 575, 281, 360, 51560], "temperature": 0.0, "avg_logprob": -0.09949083176870195, "compression_ratio": 1.9963898916967509, "no_speech_prob": 0.0006013751844875515}, {"id": 997, "seek": 355760, "start": 3581.52, "end": 3585.52, "text": " it has to be absorbed into the body it has to be metabolized and excreted it", "tokens": [51560, 309, 575, 281, 312, 20799, 666, 264, 1772, 309, 575, 281, 312, 19110, 1602, 293, 1624, 1505, 292, 309, 51760], "temperature": 0.0, "avg_logprob": -0.09949083176870195, "compression_ratio": 1.9963898916967509, "no_speech_prob": 0.0006013751844875515}, {"id": 998, "seek": 358552, "start": 3585.52, "end": 3588.4, "text": " mustn't and particularly mustn't be toxic it mustn't bind to anything", "tokens": [50364, 42818, 380, 293, 4098, 42818, 380, 312, 12786, 309, 42818, 380, 14786, 281, 1340, 50508], "temperature": 0.0, "avg_logprob": -0.05836160517921132, "compression_ratio": 1.7582781456953642, "no_speech_prob": 0.0019422718323767185}, {"id": 999, "seek": 358552, "start": 3588.4, "end": 3591.52, "text": " many other proteins in the body and cause bad things to happen", "tokens": [50508, 867, 661, 15577, 294, 264, 1772, 293, 3082, 1578, 721, 281, 1051, 50664], "temperature": 0.0, "avg_logprob": -0.05836160517921132, "compression_ratio": 1.7582781456953642, "no_speech_prob": 0.0019422718323767185}, {"id": 1000, "seek": 358552, "start": 3591.52, "end": 3595.12, "text": " so what you have is a very large space of molecules usually estimated around", "tokens": [50664, 370, 437, 291, 362, 307, 257, 588, 2416, 1901, 295, 13093, 2673, 14109, 926, 50844], "temperature": 0.0, "avg_logprob": -0.05836160517921132, "compression_ratio": 1.7582781456953642, "no_speech_prob": 0.0019422718323767185}, {"id": 1001, "seek": 358552, "start": 3595.12, "end": 3599.28, "text": " 10 to the power 60 potential drug-like molecules", "tokens": [50844, 1266, 281, 264, 1347, 4060, 3995, 4110, 12, 4092, 13093, 51052], "temperature": 0.0, "avg_logprob": -0.05836160517921132, "compression_ratio": 1.7582781456953642, "no_speech_prob": 0.0019422718323767185}, {"id": 1002, "seek": 358552, "start": 3599.28, "end": 3602.4, "text": " and out of that enormous space of 10 to the 60 you're trying to find", "tokens": [51052, 293, 484, 295, 300, 11322, 1901, 295, 1266, 281, 264, 4060, 291, 434, 1382, 281, 915, 51208], "temperature": 0.0, "avg_logprob": -0.05836160517921132, "compression_ratio": 1.7582781456953642, "no_speech_prob": 0.0019422718323767185}, {"id": 1003, "seek": 358552, "start": 3602.4, "end": 3605.68, "text": " an example that meets all of these many many criteria", "tokens": [51208, 364, 1365, 300, 13961, 439, 295, 613, 867, 867, 11101, 51372], "temperature": 0.0, "avg_logprob": -0.05836160517921132, "compression_ratio": 1.7582781456953642, "no_speech_prob": 0.0019422718323767185}, {"id": 1004, "seek": 358552, "start": 3605.68, "end": 3610.08, "text": " and so one approach is to generate a lot of candidates but in computationally", "tokens": [51372, 293, 370, 472, 3109, 307, 281, 8460, 257, 688, 295, 11255, 457, 294, 24903, 379, 51592], "temperature": 0.0, "avg_logprob": -0.05836160517921132, "compression_ratio": 1.7582781456953642, "no_speech_prob": 0.0019422718323767185}, {"id": 1005, "seek": 358552, "start": 3610.08, "end": 3613.52, "text": " and then screen them one by one for different properties that screening", "tokens": [51592, 293, 550, 2568, 552, 472, 538, 472, 337, 819, 7221, 300, 17732, 51764], "temperature": 0.0, "avg_logprob": -0.05836160517921132, "compression_ratio": 1.7582781456953642, "no_speech_prob": 0.0019422718323767185}, {"id": 1006, "seek": 361352, "start": 3613.52, "end": 3617.68, "text": " process the more that can be done in silico rather than", "tokens": [50364, 1399, 264, 544, 300, 393, 312, 1096, 294, 3425, 2789, 2831, 813, 50572], "temperature": 0.0, "avg_logprob": -0.07925339926660588, "compression_ratio": 1.9660377358490566, "no_speech_prob": 0.0020096690859645605}, {"id": 1007, "seek": 361352, "start": 3617.68, "end": 3620.96, "text": " in a wet lab the faster it can be done and the", "tokens": [50572, 294, 257, 6630, 2715, 264, 4663, 309, 393, 312, 1096, 293, 264, 50736], "temperature": 0.0, "avg_logprob": -0.07925339926660588, "compression_ratio": 1.9660377358490566, "no_speech_prob": 0.0020096690859645605}, {"id": 1008, "seek": 361352, "start": 3620.96, "end": 3624.96, "text": " the larger the search space can be and therefore the bigger the fraction of", "tokens": [50736, 264, 4833, 264, 3164, 1901, 393, 312, 293, 4412, 264, 3801, 264, 14135, 295, 50936], "temperature": 0.0, "avg_logprob": -0.07925339926660588, "compression_ratio": 1.9660377358490566, "no_speech_prob": 0.0020096690859645605}, {"id": 1009, "seek": 361352, "start": 3624.96, "end": 3628.96, "text": " that space of possibilities you can explore hopefully thereby increasing", "tokens": [50936, 300, 1901, 295, 12178, 291, 393, 6839, 4696, 28281, 5662, 51136], "temperature": 0.0, "avg_logprob": -0.07925339926660588, "compression_ratio": 1.9660377358490566, "no_speech_prob": 0.0020096690859645605}, {"id": 1010, "seek": 361352, "start": 3628.96, "end": 3632.08, "text": " the chances of finding a good candidate because many attempts to find a drug for", "tokens": [51136, 264, 10486, 295, 5006, 257, 665, 11532, 570, 867, 15257, 281, 915, 257, 4110, 337, 51292], "temperature": 0.0, "avg_logprob": -0.07925339926660588, "compression_ratio": 1.9660377358490566, "no_speech_prob": 0.0020096690859645605}, {"id": 1011, "seek": 361352, "start": 3632.08, "end": 3635.6, "text": " a disease simply fail nothing nothing eventually comes of it", "tokens": [51292, 257, 4752, 2935, 3061, 1825, 1825, 4728, 1487, 295, 309, 51468], "temperature": 0.0, "avg_logprob": -0.07925339926660588, "compression_ratio": 1.9660377358490566, "no_speech_prob": 0.0020096690859645605}, {"id": 1012, "seek": 361352, "start": 3635.6, "end": 3638.32, "text": " so increasing the probability of success increasing the speed of that", "tokens": [51468, 370, 5662, 264, 8482, 295, 2245, 5662, 264, 3073, 295, 300, 51604], "temperature": 0.0, "avg_logprob": -0.07925339926660588, "compression_ratio": 1.9660377358490566, "no_speech_prob": 0.0020096690859645605}, {"id": 1013, "seek": 361352, "start": 3638.32, "end": 3641.44, "text": " discovery process so in all of that there are many places", "tokens": [51604, 12114, 1399, 370, 294, 439, 295, 300, 456, 366, 867, 3190, 51760], "temperature": 0.0, "avg_logprob": -0.07925339926660588, "compression_ratio": 1.9660377358490566, "no_speech_prob": 0.0020096690859645605}, {"id": 1014, "seek": 364144, "start": 3641.52, "end": 3644.64, "text": " where machine learning could could be disruptive", "tokens": [50368, 689, 3479, 2539, 727, 727, 312, 37865, 50524], "temperature": 0.0, "avg_logprob": -0.11603210911606297, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.0011388508137315512}, {"id": 1015, "seek": 364144, "start": 3644.64, "end": 3648.88, "text": " so on that process of I guess you're describing", "tokens": [50524, 370, 322, 300, 1399, 295, 286, 2041, 291, 434, 16141, 50736], "temperature": 0.0, "avg_logprob": -0.11603210911606297, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.0011388508137315512}, {"id": 1016, "seek": 364144, "start": 3648.88, "end": 3653.12, "text": " you generate candidates and then you almost discriminate interesting ones", "tokens": [50736, 291, 8460, 11255, 293, 550, 291, 1920, 47833, 1880, 2306, 50948], "temperature": 0.0, "avg_logprob": -0.11603210911606297, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.0011388508137315512}, {"id": 1017, "seek": 364144, "start": 3653.12, "end": 3657.84, "text": " and then you rinse and repeat in a kind of iterative process", "tokens": [50948, 293, 550, 291, 27026, 293, 7149, 294, 257, 733, 295, 17138, 1166, 1399, 51184], "temperature": 0.0, "avg_logprob": -0.11603210911606297, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.0011388508137315512}, {"id": 1018, "seek": 364144, "start": 3657.84, "end": 3661.84, "text": " let me give you a concrete example so we've done some work looking at", "tokens": [51184, 718, 385, 976, 291, 257, 9859, 1365, 370, 321, 600, 1096, 512, 589, 1237, 412, 51384], "temperature": 0.0, "avg_logprob": -0.11603210911606297, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.0011388508137315512}, {"id": 1019, "seek": 364144, "start": 3661.84, "end": 3666.0, "text": " tuberculosis so tuberculosis kills something like 1.3 million people very", "tokens": [51384, 39847, 49379, 370, 39847, 49379, 14563, 746, 411, 502, 13, 18, 2459, 561, 588, 51592], "temperature": 0.0, "avg_logprob": -0.11603210911606297, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.0011388508137315512}, {"id": 1020, "seek": 364144, "start": 3666.0, "end": 3669.52, "text": " sadly back in 2022 which is the last year we have we have data", "tokens": [51592, 22023, 646, 294, 20229, 597, 307, 264, 1036, 1064, 321, 362, 321, 362, 1412, 51768], "temperature": 0.0, "avg_logprob": -0.11603210911606297, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.0011388508137315512}, {"id": 1021, "seek": 366952, "start": 3669.52, "end": 3672.32, "text": " and I might seem surprising because we have we have antibiotics we have drugs", "tokens": [50364, 293, 286, 1062, 1643, 8830, 570, 321, 362, 321, 362, 26922, 321, 362, 7766, 50504], "temperature": 0.0, "avg_logprob": -0.07117804702447385, "compression_ratio": 1.8700906344410877, "no_speech_prob": 0.00026338931638747454}, {"id": 1022, "seek": 366952, "start": 3672.32, "end": 3674.88, "text": " for tuberculosis why are so many people dying", "tokens": [50504, 337, 39847, 49379, 983, 366, 370, 867, 561, 8639, 50632], "temperature": 0.0, "avg_logprob": -0.07117804702447385, "compression_ratio": 1.8700906344410877, "no_speech_prob": 0.00026338931638747454}, {"id": 1023, "seek": 366952, "start": 3674.88, "end": 3678.56, "text": " and one core reason is that the the bacterium is evolving to develop drug", "tokens": [50632, 293, 472, 4965, 1778, 307, 300, 264, 264, 9755, 2197, 307, 21085, 281, 1499, 4110, 50816], "temperature": 0.0, "avg_logprob": -0.07117804702447385, "compression_ratio": 1.8700906344410877, "no_speech_prob": 0.00026338931638747454}, {"id": 1024, "seek": 366952, "start": 3678.56, "end": 3681.84, "text": " resistance and so there's a search on for new for new drugs", "tokens": [50816, 7335, 293, 370, 456, 311, 257, 3164, 322, 337, 777, 337, 777, 7766, 50980], "temperature": 0.0, "avg_logprob": -0.07117804702447385, "compression_ratio": 1.8700906344410877, "no_speech_prob": 0.00026338931638747454}, {"id": 1025, "seek": 366952, "start": 3681.84, "end": 3684.96, "text": " so maybe I'll just take a moment to explain some of the architecture and", "tokens": [50980, 370, 1310, 286, 603, 445, 747, 257, 1623, 281, 2903, 512, 295, 264, 9482, 293, 51136], "temperature": 0.0, "avg_logprob": -0.07117804702447385, "compression_ratio": 1.8700906344410877, "no_speech_prob": 0.00026338931638747454}, {"id": 1026, "seek": 366952, "start": 3684.96, "end": 3688.4, "text": " get into a little bit of the sort of the techie details of this", "tokens": [51136, 483, 666, 257, 707, 857, 295, 264, 1333, 295, 264, 7553, 414, 4365, 295, 341, 51308], "temperature": 0.0, "avg_logprob": -0.07117804702447385, "compression_ratio": 1.8700906344410877, "no_speech_prob": 0.00026338931638747454}, {"id": 1027, "seek": 366952, "start": 3688.4, "end": 3692.32, "text": " so we wanted a way of finding we know what the target is we've been told what", "tokens": [51308, 370, 321, 1415, 257, 636, 295, 5006, 321, 458, 437, 264, 3779, 307, 321, 600, 668, 1907, 437, 51504], "temperature": 0.0, "avg_logprob": -0.07117804702447385, "compression_ratio": 1.8700906344410877, "no_speech_prob": 0.00026338931638747454}, {"id": 1028, "seek": 366952, "start": 3692.32, "end": 3695.28, "text": " the target protein is the target has a region called a pocket and we're", "tokens": [51504, 264, 3779, 7944, 307, 264, 3779, 575, 257, 4458, 1219, 257, 8963, 293, 321, 434, 51652], "temperature": 0.0, "avg_logprob": -0.07117804702447385, "compression_ratio": 1.8700906344410877, "no_speech_prob": 0.00026338931638747454}, {"id": 1029, "seek": 366952, "start": 3695.28, "end": 3698.32, "text": " looking for molecules that are bind tightly with that pocket region on the", "tokens": [51652, 1237, 337, 13093, 300, 366, 14786, 21952, 365, 300, 8963, 4458, 322, 264, 51804], "temperature": 0.0, "avg_logprob": -0.07117804702447385, "compression_ratio": 1.8700906344410877, "no_speech_prob": 0.00026338931638747454}, {"id": 1030, "seek": 369832, "start": 3698.32, "end": 3702.2400000000002, "text": " protein and and so the way the way we approached", "tokens": [50364, 7944, 293, 293, 370, 264, 636, 264, 636, 321, 17247, 50560], "temperature": 0.0, "avg_logprob": -0.10657852283422498, "compression_ratio": 2.062717770034843, "no_speech_prob": 0.0017413792666047812}, {"id": 1031, "seek": 369832, "start": 3702.2400000000002, "end": 3705.76, "text": " this was first of all build a language model but not a language model", "tokens": [50560, 341, 390, 700, 295, 439, 1322, 257, 2856, 2316, 457, 406, 257, 2856, 2316, 50736], "temperature": 0.0, "avg_logprob": -0.10657852283422498, "compression_ratio": 2.062717770034843, "no_speech_prob": 0.0017413792666047812}, {"id": 1032, "seek": 369832, "start": 3705.76, "end": 3708.56, "text": " for human language but for the language of molecules", "tokens": [50736, 337, 1952, 2856, 457, 337, 264, 2856, 295, 13093, 50876], "temperature": 0.0, "avg_logprob": -0.10657852283422498, "compression_ratio": 2.062717770034843, "no_speech_prob": 0.0017413792666047812}, {"id": 1033, "seek": 369832, "start": 3708.56, "end": 3711.44, "text": " so we first of all take there's a representation representation called", "tokens": [50876, 370, 321, 700, 295, 439, 747, 456, 311, 257, 10290, 10290, 1219, 51020], "temperature": 0.0, "avg_logprob": -0.10657852283422498, "compression_ratio": 2.062717770034843, "no_speech_prob": 0.0017413792666047812}, {"id": 1034, "seek": 369832, "start": 3711.44, "end": 3714.48, "text": " smiles it's a way of taking a it's an acronym but just a way of", "tokens": [51020, 28083, 309, 311, 257, 636, 295, 1940, 257, 309, 311, 364, 39195, 457, 445, 257, 636, 295, 51172], "temperature": 0.0, "avg_logprob": -0.10657852283422498, "compression_ratio": 2.062717770034843, "no_speech_prob": 0.0017413792666047812}, {"id": 1035, "seek": 369832, "start": 3714.48, "end": 3717.6000000000004, "text": " taking a molecule and describing as a one-dimensional string", "tokens": [51172, 1940, 257, 15582, 293, 16141, 382, 257, 472, 12, 18759, 6798, 51328], "temperature": 0.0, "avg_logprob": -0.10657852283422498, "compression_ratio": 2.062717770034843, "no_speech_prob": 0.0017413792666047812}, {"id": 1036, "seek": 369832, "start": 3717.6000000000004, "end": 3720.56, "text": " and so you first of all take a large database of I don't know 10 million", "tokens": [51328, 293, 370, 291, 700, 295, 439, 747, 257, 2416, 8149, 295, 286, 500, 380, 458, 1266, 2459, 51476], "temperature": 0.0, "avg_logprob": -0.10657852283422498, "compression_ratio": 2.062717770034843, "no_speech_prob": 0.0017413792666047812}, {"id": 1037, "seek": 369832, "start": 3720.56, "end": 3723.92, "text": " molecules it represented the smile strings and you treat them like the", "tokens": [51476, 13093, 309, 10379, 264, 7563, 13985, 293, 291, 2387, 552, 411, 264, 51644], "temperature": 0.0, "avg_logprob": -0.10657852283422498, "compression_ratio": 2.062717770034843, "no_speech_prob": 0.0017413792666047812}, {"id": 1038, "seek": 369832, "start": 3723.92, "end": 3727.84, "text": " tokens for a for a transformer model and by getting it to predict the next token", "tokens": [51644, 22667, 337, 257, 337, 257, 31782, 2316, 293, 538, 1242, 309, 281, 6069, 264, 958, 14862, 51840], "temperature": 0.0, "avg_logprob": -0.10657852283422498, "compression_ratio": 2.062717770034843, "no_speech_prob": 0.0017413792666047812}, {"id": 1039, "seek": 372784, "start": 3727.84, "end": 3732.2400000000002, "text": " the next element of the smile string you build a transformer based language", "tokens": [50364, 264, 958, 4478, 295, 264, 7563, 6798, 291, 1322, 257, 31782, 2361, 2856, 50584], "temperature": 0.0, "avg_logprob": -0.07057125815029802, "compression_ratio": 2.030534351145038, "no_speech_prob": 0.00031177804339677095}, {"id": 1040, "seek": 372784, "start": 3732.2400000000002, "end": 3734.7200000000003, "text": " model that can speak the language of molecules", "tokens": [50584, 2316, 300, 393, 1710, 264, 2856, 295, 13093, 50708], "temperature": 0.0, "avg_logprob": -0.07057125815029802, "compression_ratio": 2.030534351145038, "no_speech_prob": 0.00031177804339677095}, {"id": 1041, "seek": 372784, "start": 3734.7200000000003, "end": 3738.1600000000003, "text": " so it can it can run generatively and it can create new", "tokens": [50708, 370, 309, 393, 309, 393, 1190, 1337, 19020, 293, 309, 393, 1884, 777, 50880], "temperature": 0.0, "avg_logprob": -0.07057125815029802, "compression_ratio": 2.030534351145038, "no_speech_prob": 0.00031177804339677095}, {"id": 1042, "seek": 372784, "start": 3738.1600000000003, "end": 3742.08, "text": " create new molecules as output so you can think of that as kind of like a", "tokens": [50880, 1884, 777, 13093, 382, 5598, 370, 291, 393, 519, 295, 300, 382, 733, 295, 411, 257, 51076], "temperature": 0.0, "avg_logprob": -0.07057125815029802, "compression_ratio": 2.030534351145038, "no_speech_prob": 0.00031177804339677095}, {"id": 1043, "seek": 372784, "start": 3742.08, "end": 3745.6000000000004, "text": " foundation language model but speaking the language of molecules", "tokens": [51076, 7030, 2856, 2316, 457, 4124, 264, 2856, 295, 13093, 51252], "temperature": 0.0, "avg_logprob": -0.07057125815029802, "compression_ratio": 2.030534351145038, "no_speech_prob": 0.00031177804339677095}, {"id": 1044, "seek": 372784, "start": 3745.6000000000004, "end": 3749.1200000000003, "text": " now we want to generate molecules but not just any molecules we want molecules", "tokens": [51252, 586, 321, 528, 281, 8460, 13093, 457, 406, 445, 604, 13093, 321, 528, 13093, 51428], "temperature": 0.0, "avg_logprob": -0.07057125815029802, "compression_ratio": 2.030534351145038, "no_speech_prob": 0.00031177804339677095}, {"id": 1045, "seek": 372784, "start": 3749.1200000000003, "end": 3752.8, "text": " which bind with a particular target protein so we have the target protein", "tokens": [51428, 597, 14786, 365, 257, 1729, 3779, 7944, 370, 321, 362, 264, 3779, 7944, 51612], "temperature": 0.0, "avg_logprob": -0.07057125815029802, "compression_ratio": 2.030534351145038, "no_speech_prob": 0.00031177804339677095}, {"id": 1046, "seek": 372784, "start": 3752.8, "end": 3755.28, "text": " in particular it's the pocket region that we're interested in", "tokens": [51612, 294, 1729, 309, 311, 264, 8963, 4458, 300, 321, 434, 3102, 294, 51736], "temperature": 0.0, "avg_logprob": -0.07057125815029802, "compression_ratio": 2.030534351145038, "no_speech_prob": 0.00031177804339677095}, {"id": 1047, "seek": 375528, "start": 3755.28, "end": 3758.48, "text": " so we can give it the amino acid sequence of the protein as input", "tokens": [50364, 370, 321, 393, 976, 309, 264, 24674, 8258, 8310, 295, 264, 7944, 382, 4846, 50524], "temperature": 0.0, "avg_logprob": -0.08478234030983665, "compression_ratio": 2.03690036900369, "no_speech_prob": 0.0001464144152123481}, {"id": 1048, "seek": 375528, "start": 3758.48, "end": 3762.0800000000004, "text": " but we need more than that we need the geometry of the of the pocket and this", "tokens": [50524, 457, 321, 643, 544, 813, 300, 321, 643, 264, 18426, 295, 264, 295, 264, 8963, 293, 341, 50704], "temperature": 0.0, "avg_logprob": -0.08478234030983665, "compression_ratio": 2.03690036900369, "no_speech_prob": 0.0001464144152123481}, {"id": 1049, "seek": 375528, "start": 3762.0800000000004, "end": 3764.5600000000004, "text": " is where some of those inductive biases come in so we", "tokens": [50704, 307, 689, 512, 295, 729, 31612, 488, 32152, 808, 294, 370, 321, 50828], "temperature": 0.0, "avg_logprob": -0.08478234030983665, "compression_ratio": 2.03690036900369, "no_speech_prob": 0.0001464144152123481}, {"id": 1050, "seek": 375528, "start": 3764.5600000000004, "end": 3768.4, "text": " we need to have representations of the geometry of the atoms in that form that", "tokens": [50828, 321, 643, 281, 362, 33358, 295, 264, 18426, 295, 264, 16871, 294, 300, 1254, 300, 51020], "temperature": 0.0, "avg_logprob": -0.08478234030983665, "compression_ratio": 2.03690036900369, "no_speech_prob": 0.0001464144152123481}, {"id": 1051, "seek": 375528, "start": 3768.4, "end": 3770.96, "text": " pocket but a way that represents these", "tokens": [51020, 8963, 457, 257, 636, 300, 8855, 613, 51148], "temperature": 0.0, "avg_logprob": -0.08478234030983665, "compression_ratio": 2.03690036900369, "no_speech_prob": 0.0001464144152123481}, {"id": 1052, "seek": 375528, "start": 3770.96, "end": 3775.1200000000003, "text": " equivalences and so they're encoded as input to a transformer model that learns", "tokens": [51148, 9052, 2667, 293, 370, 436, 434, 2058, 12340, 382, 4846, 281, 257, 31782, 2316, 300, 27152, 51356], "temperature": 0.0, "avg_logprob": -0.08478234030983665, "compression_ratio": 2.03690036900369, "no_speech_prob": 0.0001464144152123481}, {"id": 1053, "seek": 375528, "start": 3775.1200000000003, "end": 3779.0400000000004, "text": " a representation for the protein pocket and the final piece we need as you said", "tokens": [51356, 257, 10290, 337, 264, 7944, 8963, 293, 264, 2572, 2522, 321, 643, 382, 291, 848, 51552], "temperature": 0.0, "avg_logprob": -0.08478234030983665, "compression_ratio": 2.03690036900369, "no_speech_prob": 0.0001464144152123481}, {"id": 1054, "seek": 375528, "start": 3779.0400000000004, "end": 3782.1600000000003, "text": " we want to do this iteratively we want to take a good molecule and make it a", "tokens": [51552, 321, 528, 281, 360, 341, 17138, 19020, 321, 528, 281, 747, 257, 665, 15582, 293, 652, 309, 257, 51708], "temperature": 0.0, "avg_logprob": -0.08478234030983665, "compression_ratio": 2.03690036900369, "no_speech_prob": 0.0001464144152123481}, {"id": 1055, "seek": 378216, "start": 3782.16, "end": 3785.52, "text": " better molecule rather than just searching blindly across a space of", "tokens": [50364, 1101, 15582, 2831, 813, 445, 10808, 47744, 2108, 257, 1901, 295, 50532], "temperature": 0.0, "avg_logprob": -0.11855523339633284, "compression_ratio": 1.8582089552238805, "no_speech_prob": 0.0017175829270854592}, {"id": 1056, "seek": 378216, "start": 3785.52, "end": 3788.48, "text": " 10 to the 60 possibilities and so the other thing we want to", "tokens": [50532, 1266, 281, 264, 4060, 12178, 293, 370, 264, 661, 551, 321, 528, 281, 50680], "temperature": 0.0, "avg_logprob": -0.11855523339633284, "compression_ratio": 1.8582089552238805, "no_speech_prob": 0.0017175829270854592}, {"id": 1057, "seek": 378216, "start": 3788.48, "end": 3792.72, "text": " provide as input is a molecule a descriptor of a", "tokens": [50680, 2893, 382, 4846, 307, 257, 15582, 257, 31280, 284, 295, 257, 50892], "temperature": 0.0, "avg_logprob": -0.11855523339633284, "compression_ratio": 1.8582089552238805, "no_speech_prob": 0.0017175829270854592}, {"id": 1058, "seek": 378216, "start": 3792.72, "end": 3796.8799999999997, "text": " a known small molecule that does bind with the pocket already", "tokens": [50892, 257, 2570, 1359, 15582, 300, 775, 14786, 365, 264, 8963, 1217, 51100], "temperature": 0.0, "avg_logprob": -0.11855523339633284, "compression_ratio": 1.8582089552238805, "no_speech_prob": 0.0017175829270854592}, {"id": 1059, "seek": 378216, "start": 3796.8799999999997, "end": 3800.3999999999996, "text": " and but we want to do this in a way that creates variability and we actually use", "tokens": [51100, 293, 457, 321, 528, 281, 360, 341, 294, 257, 636, 300, 7829, 35709, 293, 321, 767, 764, 51276], "temperature": 0.0, "avg_logprob": -0.11855523339633284, "compression_ratio": 1.8582089552238805, "no_speech_prob": 0.0017175829270854592}, {"id": 1060, "seek": 378216, "start": 3800.3999999999996, "end": 3803.8399999999997, "text": " a variational autoencoder to create that representation and", "tokens": [51276, 257, 3034, 1478, 8399, 22660, 19866, 281, 1884, 300, 10290, 293, 51448], "temperature": 0.0, "avg_logprob": -0.11855523339633284, "compression_ratio": 1.8582089552238805, "no_speech_prob": 0.0017175829270854592}, {"id": 1061, "seek": 378216, "start": 3803.8399999999997, "end": 3807.6, "text": " that's the an encoder that trun translates the molecule into a latent", "tokens": [51448, 300, 311, 264, 364, 2058, 19866, 300, 504, 409, 28468, 264, 15582, 666, 257, 48994, 51636], "temperature": 0.0, "avg_logprob": -0.11855523339633284, "compression_ratio": 1.8582089552238805, "no_speech_prob": 0.0017175829270854592}, {"id": 1062, "seek": 378216, "start": 3807.6, "end": 3810.48, "text": " space and we can sample from that latent space", "tokens": [51636, 1901, 293, 321, 393, 6889, 490, 300, 48994, 1901, 51780], "temperature": 0.0, "avg_logprob": -0.11855523339633284, "compression_ratio": 1.8582089552238805, "no_speech_prob": 0.0017175829270854592}, {"id": 1063, "seek": 381048, "start": 3810.48, "end": 3813.84, "text": " and then the this language model the smiles", "tokens": [50364, 293, 550, 264, 341, 2856, 2316, 264, 28083, 50532], "temperature": 0.0, "avg_logprob": -0.08063167792100173, "compression_ratio": 1.8464730290456433, "no_speech_prob": 0.00023522242554463446}, {"id": 1064, "seek": 381048, "start": 3813.84, "end": 3817.68, "text": " language model can attend to both the output of the variational autoencoder", "tokens": [50532, 2856, 2316, 393, 6888, 281, 1293, 264, 5598, 295, 264, 3034, 1478, 8399, 22660, 19866, 50724], "temperature": 0.0, "avg_logprob": -0.08063167792100173, "compression_ratio": 1.8464730290456433, "no_speech_prob": 0.00023522242554463446}, {"id": 1065, "seek": 381048, "start": 3817.68, "end": 3820.64, "text": " and the output of the protein encoder using cross-attention", "tokens": [50724, 293, 264, 5598, 295, 264, 7944, 2058, 19866, 1228, 3278, 12, 1591, 1251, 50872], "temperature": 0.0, "avg_logprob": -0.08063167792100173, "compression_ratio": 1.8464730290456433, "no_speech_prob": 0.00023522242554463446}, {"id": 1066, "seek": 381048, "start": 3820.64, "end": 3824.16, "text": " and so what we've done there is I think rather tastefully combined", "tokens": [50872, 293, 370, 437, 321, 600, 1096, 456, 307, 286, 519, 2831, 3939, 2277, 9354, 51048], "temperature": 0.0, "avg_logprob": -0.08063167792100173, "compression_ratio": 1.8464730290456433, "no_speech_prob": 0.00023522242554463446}, {"id": 1067, "seek": 381048, "start": 3824.16, "end": 3828.72, "text": " some elements from you know states of the arts at modern deep learning", "tokens": [51048, 512, 4959, 490, 291, 458, 4368, 295, 264, 8609, 412, 4363, 2452, 2539, 51276], "temperature": 0.0, "avg_logprob": -0.08063167792100173, "compression_ratio": 1.8464730290456433, "no_speech_prob": 0.00023522242554463446}, {"id": 1068, "seek": 381048, "start": 3828.72, "end": 3832.8, "text": " the result then can be can be trained end to end using a database", "tokens": [51276, 264, 1874, 550, 393, 312, 393, 312, 8895, 917, 281, 917, 1228, 257, 8149, 51480], "temperature": 0.0, "avg_logprob": -0.08063167792100173, "compression_ratio": 1.8464730290456433, "no_speech_prob": 0.00023522242554463446}, {"id": 1069, "seek": 381048, "start": 3832.8, "end": 3836.4, "text": " of known other proteins that are known to bind efficiently to", "tokens": [51480, 295, 2570, 661, 15577, 300, 366, 2570, 281, 14786, 19621, 281, 51660], "temperature": 0.0, "avg_logprob": -0.08063167792100173, "compression_ratio": 1.8464730290456433, "no_speech_prob": 0.00023522242554463446}, {"id": 1070, "seek": 383640, "start": 3836.56, "end": 3840.48, "text": " small molecules and once the system is trained we can now", "tokens": [50372, 1359, 13093, 293, 1564, 264, 1185, 307, 8895, 321, 393, 586, 50568], "temperature": 0.0, "avg_logprob": -0.09202920539038521, "compression_ratio": 1.9471698113207547, "no_speech_prob": 0.0030887762550264597}, {"id": 1071, "seek": 383640, "start": 3840.48, "end": 3843.84, "text": " provide as input the known target for tuberculosis", "tokens": [50568, 2893, 382, 4846, 264, 2570, 3779, 337, 39847, 49379, 50736], "temperature": 0.0, "avg_logprob": -0.09202920539038521, "compression_ratio": 1.9471698113207547, "no_speech_prob": 0.0030887762550264597}, {"id": 1072, "seek": 383640, "start": 3843.84, "end": 3847.6, "text": " and some known molecules that bind with this and then we can", "tokens": [50736, 293, 512, 2570, 13093, 300, 14786, 365, 341, 293, 550, 321, 393, 50924], "temperature": 0.0, "avg_logprob": -0.09202920539038521, "compression_ratio": 1.9471698113207547, "no_speech_prob": 0.0030887762550264597}, {"id": 1073, "seek": 383640, "start": 3847.6, "end": 3850.7200000000003, "text": " iteratively refine those molecules at the output we get molecules that have", "tokens": [50924, 17138, 19020, 33906, 729, 13093, 412, 264, 5598, 321, 483, 13093, 300, 362, 51080], "temperature": 0.0, "avg_logprob": -0.09202920539038521, "compression_ratio": 1.9471698113207547, "no_speech_prob": 0.0030887762550264597}, {"id": 1074, "seek": 383640, "start": 3850.7200000000003, "end": 3853.6, "text": " better binding efficiency and we're able to increase the binding", "tokens": [51080, 1101, 17359, 10493, 293, 321, 434, 1075, 281, 3488, 264, 17359, 51224], "temperature": 0.0, "avg_logprob": -0.09202920539038521, "compression_ratio": 1.9471698113207547, "no_speech_prob": 0.0030887762550264597}, {"id": 1075, "seek": 383640, "start": 3853.6, "end": 3857.6, "text": " effectiveness by two orders of magnitude and so we now have states of the art", "tokens": [51224, 21208, 538, 732, 9470, 295, 15668, 293, 370, 321, 586, 362, 4368, 295, 264, 1523, 51424], "temperature": 0.0, "avg_logprob": -0.09202920539038521, "compression_ratio": 1.9471698113207547, "no_speech_prob": 0.0030887762550264597}, {"id": 1076, "seek": 383640, "start": 3857.6, "end": 3861.2000000000003, "text": " molecules in terms of binding efficiency to this", "tokens": [51424, 13093, 294, 2115, 295, 17359, 10493, 281, 341, 51604], "temperature": 0.0, "avg_logprob": -0.09202920539038521, "compression_ratio": 1.9471698113207547, "no_speech_prob": 0.0030887762550264597}, {"id": 1077, "seek": 383640, "start": 3861.2000000000003, "end": 3865.84, "text": " to this target protein of course we can't do the wet lab experiments ourselves", "tokens": [51604, 281, 341, 3779, 7944, 295, 1164, 321, 393, 380, 360, 264, 6630, 2715, 12050, 4175, 51836], "temperature": 0.0, "avg_logprob": -0.09202920539038521, "compression_ratio": 1.9471698113207547, "no_speech_prob": 0.0030887762550264597}, {"id": 1078, "seek": 386584, "start": 3865.84, "end": 3869.44, "text": " we partner with an organization called giddy the global health drug discovery", "tokens": [50364, 321, 4975, 365, 364, 4475, 1219, 19805, 3173, 264, 4338, 1585, 4110, 12114, 50544], "temperature": 0.0, "avg_logprob": -0.11099126603868273, "compression_ratio": 1.8175675675675675, "no_speech_prob": 0.0006945610512048006}, {"id": 1079, "seek": 386584, "start": 3869.44, "end": 3872.88, "text": " institute they've synthesized the molecules that we've we've", "tokens": [50544, 26860, 436, 600, 26617, 1602, 264, 13093, 300, 321, 600, 321, 600, 50716], "temperature": 0.0, "avg_logprob": -0.11099126603868273, "compression_ratio": 1.8175675675675675, "no_speech_prob": 0.0006945610512048006}, {"id": 1080, "seek": 386584, "start": 3872.88, "end": 3876.4, "text": " generated and measured their their binding efficacy", "tokens": [50716, 10833, 293, 12690, 641, 641, 17359, 33492, 50892], "temperature": 0.0, "avg_logprob": -0.11099126603868273, "compression_ratio": 1.8175675675675675, "no_speech_prob": 0.0006945610512048006}, {"id": 1081, "seek": 386584, "start": 3876.4, "end": 3880.56, "text": " and so we're very very excited about this and of course the next stage now is to", "tokens": [50892, 293, 370, 321, 434, 588, 588, 2919, 466, 341, 293, 295, 1164, 264, 958, 3233, 586, 307, 281, 51100], "temperature": 0.0, "avg_logprob": -0.11099126603868273, "compression_ratio": 1.8175675675675675, "no_speech_prob": 0.0006945610512048006}, {"id": 1082, "seek": 386584, "start": 3880.56, "end": 3884.4, "text": " take that as a starting point and further refine and optimize those molecules and", "tokens": [51100, 747, 300, 382, 257, 2891, 935, 293, 3052, 33906, 293, 19719, 729, 13093, 293, 51292], "temperature": 0.0, "avg_logprob": -0.11099126603868273, "compression_ratio": 1.8175675675675675, "no_speech_prob": 0.0006945610512048006}, {"id": 1083, "seek": 386584, "start": 3884.4, "end": 3887.36, "text": " and try to address all those other requirements that we have for before a", "tokens": [51292, 293, 853, 281, 2985, 439, 729, 661, 7728, 300, 321, 362, 337, 949, 257, 51440], "temperature": 0.0, "avg_logprob": -0.11099126603868273, "compression_ratio": 1.8175675675675675, "no_speech_prob": 0.0006945610512048006}, {"id": 1084, "seek": 386584, "start": 3887.36, "end": 3890.08, "text": " drug can actually be tested on humans in terms of its", "tokens": [51440, 4110, 393, 767, 312, 8246, 322, 6255, 294, 2115, 295, 1080, 51576], "temperature": 0.0, "avg_logprob": -0.11099126603868273, "compression_ratio": 1.8175675675675675, "no_speech_prob": 0.0006945610512048006}, {"id": 1085, "seek": 386584, "start": 3890.08, "end": 3892.7200000000003, "text": " toxicity and metabolism and all and all the other things", "tokens": [51576, 45866, 293, 31190, 293, 439, 293, 439, 264, 661, 721, 51708], "temperature": 0.0, "avg_logprob": -0.11099126603868273, "compression_ratio": 1.8175675675675675, "no_speech_prob": 0.0006945610512048006}, {"id": 1086, "seek": 389272, "start": 3892.72, "end": 3897.4399999999996, "text": " but i think it's just a a very a very nice example of almost like a first step", "tokens": [50364, 457, 741, 519, 309, 311, 445, 257, 257, 588, 257, 588, 1481, 1365, 295, 1920, 411, 257, 700, 1823, 50600], "temperature": 0.0, "avg_logprob": -0.114139492071948, "compression_ratio": 1.753787878787879, "no_speech_prob": 0.0002289833064423874}, {"id": 1087, "seek": 389272, "start": 3897.4399999999996, "end": 3901.3599999999997, "text": " in using modern deep learning architecture to accelerate the process of drug", "tokens": [50600, 294, 1228, 4363, 2452, 2539, 9482, 281, 21341, 264, 1399, 295, 4110, 50796], "temperature": 0.0, "avg_logprob": -0.114139492071948, "compression_ratio": 1.753787878787879, "no_speech_prob": 0.0002289833064423874}, {"id": 1088, "seek": 389272, "start": 3901.3599999999997, "end": 3904.64, "text": " discovery and already we have i think really quite a", "tokens": [50796, 12114, 293, 1217, 321, 362, 741, 519, 534, 1596, 257, 50960], "temperature": 0.0, "avg_logprob": -0.114139492071948, "compression_ratio": 1.753787878787879, "no_speech_prob": 0.0002289833064423874}, {"id": 1089, "seek": 389272, "start": 3904.64, "end": 3908.3999999999996, "text": " spectacular success given that we're we're kind of newcomers to this", "tokens": [50960, 18149, 2245, 2212, 300, 321, 434, 321, 434, 733, 295, 40014, 433, 281, 341, 51148], "temperature": 0.0, "avg_logprob": -0.114139492071948, "compression_ratio": 1.753787878787879, "no_speech_prob": 0.0002289833064423874}, {"id": 1090, "seek": 389272, "start": 3908.3999999999996, "end": 3912.08, "text": " to this field partnering with experts domain experts with the wet lab", "tokens": [51148, 281, 341, 2519, 31290, 365, 8572, 9274, 8572, 365, 264, 6630, 2715, 51332], "temperature": 0.0, "avg_logprob": -0.114139492071948, "compression_ratio": 1.753787878787879, "no_speech_prob": 0.0002289833064423874}, {"id": 1091, "seek": 389272, "start": 3912.08, "end": 3916.24, "text": " experience and the wet lab capability to me this is the beginning of a very", "tokens": [51332, 1752, 293, 264, 6630, 2715, 13759, 281, 385, 341, 307, 264, 2863, 295, 257, 588, 51540], "temperature": 0.0, "avg_logprob": -0.114139492071948, "compression_ratio": 1.753787878787879, "no_speech_prob": 0.0002289833064423874}, {"id": 1092, "seek": 389272, "start": 3916.24, "end": 3919.2799999999997, "text": " exciting journey that sounds incredible", "tokens": [51540, 4670, 4671, 300, 3263, 4651, 51692], "temperature": 0.0, "avg_logprob": -0.114139492071948, "compression_ratio": 1.753787878787879, "no_speech_prob": 0.0002289833064423874}, {"id": 1093, "seek": 391928, "start": 3919.28, "end": 3923.36, "text": " is there any kind of representational transfer between the the models so for", "tokens": [50364, 307, 456, 604, 733, 295, 2906, 1478, 5003, 1296, 264, 264, 5245, 370, 337, 50568], "temperature": 0.0, "avg_logprob": -0.1458468012290426, "compression_ratio": 1.8972332015810276, "no_speech_prob": 0.008086925372481346}, {"id": 1094, "seek": 391928, "start": 3923.36, "end": 3927.84, "text": " example you're talking about this this geometric", "tokens": [50568, 1365, 291, 434, 1417, 466, 341, 341, 33246, 50792], "temperature": 0.0, "avg_logprob": -0.1458468012290426, "compression_ratio": 1.8972332015810276, "no_speech_prob": 0.008086925372481346}, {"id": 1095, "seek": 391928, "start": 3927.84, "end": 3932.2400000000002, "text": " prior model and generating tokens to go into the language model", "tokens": [50792, 4059, 2316, 293, 17746, 22667, 281, 352, 666, 264, 2856, 2316, 51012], "temperature": 0.0, "avg_logprob": -0.1458468012290426, "compression_ratio": 1.8972332015810276, "no_speech_prob": 0.008086925372481346}, {"id": 1096, "seek": 391928, "start": 3932.2400000000002, "end": 3935.6000000000004, "text": " because just using language models by the way is a fascinating approach i", "tokens": [51012, 570, 445, 1228, 2856, 5245, 538, 264, 636, 307, 257, 10343, 3109, 741, 51180], "temperature": 0.0, "avg_logprob": -0.1458468012290426, "compression_ratio": 1.8972332015810276, "no_speech_prob": 0.008086925372481346}, {"id": 1097, "seek": 391928, "start": 3935.6000000000004, "end": 3939.76, "text": " spoke with christian sogeddy and he was doing mathematical conjecturing", "tokens": [51180, 7179, 365, 26586, 952, 370, 3004, 3173, 293, 415, 390, 884, 18894, 416, 1020, 1345, 51388], "temperature": 0.0, "avg_logprob": -0.1458468012290426, "compression_ratio": 1.8972332015810276, "no_speech_prob": 0.008086925372481346}, {"id": 1098, "seek": 391928, "start": 3939.76, "end": 3943.6000000000004, "text": " just using language models you know just just taking mathematical", "tokens": [51388, 445, 1228, 2856, 5245, 291, 458, 445, 445, 1940, 18894, 51580], "temperature": 0.0, "avg_logprob": -0.1458468012290426, "compression_ratio": 1.8972332015810276, "no_speech_prob": 0.008086925372481346}, {"id": 1099, "seek": 391928, "start": 3943.6000000000004, "end": 3947.1200000000003, "text": " constructions and putting them into language and they used to use graph neural", "tokens": [51580, 7690, 626, 293, 3372, 552, 666, 2856, 293, 436, 1143, 281, 764, 4295, 18161, 51756], "temperature": 0.0, "avg_logprob": -0.1458468012290426, "compression_ratio": 1.8972332015810276, "no_speech_prob": 0.008086925372481346}, {"id": 1100, "seek": 394712, "start": 3947.12, "end": 3950.48, "text": " networks for this and so i guess the question is", "tokens": [50364, 9590, 337, 341, 293, 370, 741, 2041, 264, 1168, 307, 50532], "temperature": 0.0, "avg_logprob": -0.08648091031793963, "compression_ratio": 1.8681318681318682, "no_speech_prob": 0.0036097357515245676}, {"id": 1101, "seek": 394712, "start": 3950.48, "end": 3954.7999999999997, "text": " could you kind of bootstrap it with a you know with an inductive", "tokens": [50532, 727, 291, 733, 295, 11450, 372, 4007, 309, 365, 257, 291, 458, 365, 364, 31612, 488, 50748], "temperature": 0.0, "avg_logprob": -0.08648091031793963, "compression_ratio": 1.8681318681318682, "no_speech_prob": 0.0036097357515245676}, {"id": 1102, "seek": 394712, "start": 3954.7999999999997, "end": 3960.72, "text": " principled model and then kind of just train using the language model afterwards", "tokens": [50748, 3681, 15551, 2316, 293, 550, 733, 295, 445, 3847, 1228, 264, 2856, 2316, 10543, 51044], "temperature": 0.0, "avg_logprob": -0.08648091031793963, "compression_ratio": 1.8681318681318682, "no_speech_prob": 0.0036097357515245676}, {"id": 1103, "seek": 394712, "start": 3960.72, "end": 3963.44, "text": " i think i think the general principle there's a very powerful one so the idea", "tokens": [51044, 741, 519, 741, 519, 264, 2674, 8665, 456, 311, 257, 588, 4005, 472, 370, 264, 1558, 51180], "temperature": 0.0, "avg_logprob": -0.08648091031793963, "compression_ratio": 1.8681318681318682, "no_speech_prob": 0.0036097357515245676}, {"id": 1104, "seek": 394712, "start": 3963.44, "end": 3966.4, "text": " of borrowing strength from other domains and i think we're seeing this time and", "tokens": [51180, 295, 35024, 3800, 490, 661, 25514, 293, 741, 519, 321, 434, 2577, 341, 565, 293, 51328], "temperature": 0.0, "avg_logprob": -0.08648091031793963, "compression_ratio": 1.8681318681318682, "no_speech_prob": 0.0036097357515245676}, {"id": 1105, "seek": 394712, "start": 3966.4, "end": 3971.04, "text": " time again in deep learning that that the machine learning models are able to", "tokens": [51328, 565, 797, 294, 2452, 2539, 300, 300, 264, 3479, 2539, 5245, 366, 1075, 281, 51560], "temperature": 0.0, "avg_logprob": -0.08648091031793963, "compression_ratio": 1.8681318681318682, "no_speech_prob": 0.0036097357515245676}, {"id": 1106, "seek": 394712, "start": 3971.04, "end": 3974.72, "text": " extract some general patterns from even from one domain and translate them into", "tokens": [51560, 8947, 512, 2674, 8294, 490, 754, 490, 472, 9274, 293, 13799, 552, 666, 51744], "temperature": 0.0, "avg_logprob": -0.08648091031793963, "compression_ratio": 1.8681318681318682, "no_speech_prob": 0.0036097357515245676}, {"id": 1107, "seek": 397472, "start": 3974.72, "end": 3977.68, "text": " completely different domain we talked earlier about large language models", "tokens": [50364, 2584, 819, 9274, 321, 2825, 3071, 466, 2416, 2856, 5245, 50512], "temperature": 0.0, "avg_logprob": -0.08261335621709409, "compression_ratio": 1.8706293706293706, "no_speech_prob": 0.008872944861650467}, {"id": 1108, "seek": 397472, "start": 3977.68, "end": 3981.6, "text": " being getting better at writing code if they've also got exposure to", "tokens": [50512, 885, 1242, 1101, 412, 3579, 3089, 498, 436, 600, 611, 658, 10420, 281, 50708], "temperature": 0.0, "avg_logprob": -0.08261335621709409, "compression_ratio": 1.8706293706293706, "no_speech_prob": 0.008872944861650467}, {"id": 1109, "seek": 397472, "start": 3981.6, "end": 3984.8799999999997, "text": " to poetry or something is seemingly quite irrelevant there's some", "tokens": [50708, 281, 15155, 420, 746, 307, 18709, 1596, 28682, 456, 311, 512, 50872], "temperature": 0.0, "avg_logprob": -0.08261335621709409, "compression_ratio": 1.8706293706293706, "no_speech_prob": 0.008872944861650467}, {"id": 1110, "seek": 397472, "start": 3984.8799999999997, "end": 3988.0, "text": " there's something quite deep and subtle going on there but perhaps in a less", "tokens": [50872, 456, 311, 746, 1596, 2452, 293, 13743, 516, 322, 456, 457, 4317, 294, 257, 1570, 51028], "temperature": 0.0, "avg_logprob": -0.08261335621709409, "compression_ratio": 1.8706293706293706, "no_speech_prob": 0.008872944861650467}, {"id": 1111, "seek": 397472, "start": 3988.0, "end": 3990.9599999999996, "text": " subtle way it's clear there's a sort of a language of", "tokens": [51028, 13743, 636, 309, 311, 1850, 456, 311, 257, 1333, 295, 257, 2856, 295, 51176], "temperature": 0.0, "avg_logprob": -0.08261335621709409, "compression_ratio": 1.8706293706293706, "no_speech_prob": 0.008872944861650467}, {"id": 1112, "seek": 397472, "start": 3990.9599999999996, "end": 3995.04, "text": " molecules there's a language of materials and that by", "tokens": [51176, 13093, 456, 311, 257, 2856, 295, 5319, 293, 300, 538, 51380], "temperature": 0.0, "avg_logprob": -0.08261335621709409, "compression_ratio": 1.8706293706293706, "no_speech_prob": 0.008872944861650467}, {"id": 1113, "seek": 397472, "start": 3995.04, "end": 3998.64, "text": " building models that have a broader exposure to that language", "tokens": [51380, 2390, 5245, 300, 362, 257, 13227, 10420, 281, 300, 2856, 51560], "temperature": 0.0, "avg_logprob": -0.08261335621709409, "compression_ratio": 1.8706293706293706, "no_speech_prob": 0.008872944861650467}, {"id": 1114, "seek": 397472, "start": 3998.64, "end": 4003.04, "text": " they almost invariably will become better at the specific tasks that we want to", "tokens": [51560, 436, 1920, 33270, 1188, 486, 1813, 1101, 412, 264, 2685, 9608, 300, 321, 528, 281, 51780], "temperature": 0.0, "avg_logprob": -0.08261335621709409, "compression_ratio": 1.8706293706293706, "no_speech_prob": 0.008872944861650467}, {"id": 1115, "seek": 400304, "start": 4003.04, "end": 4006.16, "text": " to apply them to so i think there is a general principle at heart there", "tokens": [50364, 281, 3079, 552, 281, 370, 741, 519, 456, 307, 257, 2674, 8665, 412, 1917, 456, 50520], "temperature": 0.0, "avg_logprob": -0.10790615876515706, "compression_ratio": 1.8992805755395683, "no_speech_prob": 0.002881635446101427}, {"id": 1116, "seek": 400304, "start": 4006.16, "end": 4009.6, "text": " yeah it's so interesting because i i used to think that", "tokens": [50520, 1338, 309, 311, 370, 1880, 570, 741, 741, 1143, 281, 519, 300, 50692], "temperature": 0.0, "avg_logprob": -0.10790615876515706, "compression_ratio": 1.8992805755395683, "no_speech_prob": 0.002881635446101427}, {"id": 1117, "seek": 400304, "start": 4009.6, "end": 4012.88, "text": " that perhaps the drawback of these inductive prior models is that", "tokens": [50692, 300, 4317, 264, 2642, 3207, 295, 613, 31612, 488, 4059, 5245, 307, 300, 50856], "temperature": 0.0, "avg_logprob": -0.10790615876515706, "compression_ratio": 1.8992805755395683, "no_speech_prob": 0.002881635446101427}, {"id": 1118, "seek": 400304, "start": 4012.88, "end": 4017.52, "text": " it was one inductive prior per model but this ability potentially to", "tokens": [50856, 309, 390, 472, 31612, 488, 4059, 680, 2316, 457, 341, 3485, 7263, 281, 51088], "temperature": 0.0, "avg_logprob": -0.10790615876515706, "compression_ratio": 1.8992805755395683, "no_speech_prob": 0.002881635446101427}, {"id": 1119, "seek": 400304, "start": 4017.52, "end": 4021.68, "text": " bootstrap a foundational model that can do all of the things", "tokens": [51088, 11450, 372, 4007, 257, 32195, 2316, 300, 393, 360, 439, 295, 264, 721, 51296], "temperature": 0.0, "avg_logprob": -0.10790615876515706, "compression_ratio": 1.8992805755395683, "no_speech_prob": 0.002881635446101427}, {"id": 1120, "seek": 400304, "start": 4021.68, "end": 4025.04, "text": " that's really interesting i think the most powerful inductive biases and the", "tokens": [51296, 300, 311, 534, 1880, 741, 519, 264, 881, 4005, 31612, 488, 32152, 293, 264, 51464], "temperature": 0.0, "avg_logprob": -0.10790615876515706, "compression_ratio": 1.8992805755395683, "no_speech_prob": 0.002881635446101427}, {"id": 1121, "seek": 400304, "start": 4025.04, "end": 4027.92, "text": " ones we focus on are really those very general ones where", "tokens": [51464, 2306, 321, 1879, 322, 366, 534, 729, 588, 2674, 2306, 689, 51608], "temperature": 0.0, "avg_logprob": -0.10790615876515706, "compression_ratio": 1.8992805755395683, "no_speech_prob": 0.002881635446101427}, {"id": 1122, "seek": 400304, "start": 4027.92, "end": 4031.92, "text": " symmetry says just very fundamental properties of the universe and we", "tokens": [51608, 25440, 1619, 445, 588, 8088, 7221, 295, 264, 6445, 293, 321, 51808], "temperature": 0.0, "avg_logprob": -0.10790615876515706, "compression_ratio": 1.8992805755395683, "no_speech_prob": 0.002881635446101427}, {"id": 1123, "seek": 403192, "start": 4032.08, "end": 4035.04, "text": " want we want those really baked into the models i think", "tokens": [50372, 528, 321, 528, 729, 534, 19453, 666, 264, 5245, 741, 519, 50520], "temperature": 0.0, "avg_logprob": -0.0894320011138916, "compression_ratio": 1.8364312267657992, "no_speech_prob": 0.0011243345215916634}, {"id": 1124, "seek": 403192, "start": 4035.04, "end": 4039.6, "text": " the the the sort of intuitions we have about more specific domains i think", "tokens": [50520, 264, 264, 264, 1333, 295, 16224, 626, 321, 362, 466, 544, 2685, 25514, 741, 519, 50748], "temperature": 0.0, "avg_logprob": -0.0894320011138916, "compression_ratio": 1.8364312267657992, "no_speech_prob": 0.0011243345215916634}, {"id": 1125, "seek": 403192, "start": 4039.6, "end": 4042.56, "text": " they can perhaps lead us astray because they're based on", "tokens": [50748, 436, 393, 4317, 1477, 505, 5357, 3458, 570, 436, 434, 2361, 322, 50896], "temperature": 0.0, "avg_logprob": -0.0894320011138916, "compression_ratio": 1.8364312267657992, "no_speech_prob": 0.0011243345215916634}, {"id": 1126, "seek": 403192, "start": 4042.56, "end": 4045.44, "text": " our experience of much more limited domains i think this is where the", "tokens": [50896, 527, 1752, 295, 709, 544, 5567, 25514, 741, 519, 341, 307, 689, 264, 51040], "temperature": 0.0, "avg_logprob": -0.0894320011138916, "compression_ratio": 1.8364312267657992, "no_speech_prob": 0.0011243345215916634}, {"id": 1127, "seek": 403192, "start": 4045.44, "end": 4048.4, "text": " machines can be can be much better at", "tokens": [51040, 8379, 393, 312, 393, 312, 709, 1101, 412, 51188], "temperature": 0.0, "avg_logprob": -0.0894320011138916, "compression_ratio": 1.8364312267657992, "no_speech_prob": 0.0011243345215916634}, {"id": 1128, "seek": 403192, "start": 4048.4, "end": 4052.2400000000002, "text": " processing and interpreting large volumes of data and drawing regularities", "tokens": [51188, 9007, 293, 37395, 2416, 22219, 295, 1412, 293, 6316, 3890, 1088, 51380], "temperature": 0.0, "avg_logprob": -0.0894320011138916, "compression_ratio": 1.8364312267657992, "no_speech_prob": 0.0011243345215916634}, {"id": 1129, "seek": 403192, "start": 4052.2400000000002, "end": 4055.2000000000003, "text": " out of that out of data in a more systematic way", "tokens": [51380, 484, 295, 300, 484, 295, 1412, 294, 257, 544, 27249, 636, 51528], "temperature": 0.0, "avg_logprob": -0.0894320011138916, "compression_ratio": 1.8364312267657992, "no_speech_prob": 0.0011243345215916634}, {"id": 1130, "seek": 403192, "start": 4055.2000000000003, "end": 4059.84, "text": " okay okay and just before we we leave this this is a bit of a galaxy brain", "tokens": [51528, 1392, 1392, 293, 445, 949, 321, 321, 1856, 341, 341, 307, 257, 857, 295, 257, 17639, 3567, 51760], "temperature": 0.0, "avg_logprob": -0.0894320011138916, "compression_ratio": 1.8364312267657992, "no_speech_prob": 0.0011243345215916634}, {"id": 1131, "seek": 405984, "start": 4059.84, "end": 4063.04, "text": " question and and that that's parlance that all the kids are using these days", "tokens": [50364, 1168, 293, 293, 300, 300, 311, 13734, 719, 300, 439, 264, 2301, 366, 1228, 613, 1708, 50524], "temperature": 0.0, "avg_logprob": -0.1076296129797259, "compression_ratio": 1.832116788321168, "no_speech_prob": 0.00857846811413765}, {"id": 1132, "seek": 405984, "start": 4063.04, "end": 4067.52, "text": " by the way but how fundamental is is our physical", "tokens": [50524, 538, 264, 636, 457, 577, 8088, 307, 307, 527, 4001, 50748], "temperature": 0.0, "avg_logprob": -0.1076296129797259, "compression_ratio": 1.832116788321168, "no_speech_prob": 0.00857846811413765}, {"id": 1133, "seek": 405984, "start": 4067.52, "end": 4070.96, "text": " knowledge you know the question is like we are we're designing these inductive", "tokens": [50748, 3601, 291, 458, 264, 1168, 307, 411, 321, 366, 321, 434, 14685, 613, 31612, 488, 50920], "temperature": 0.0, "avg_logprob": -0.1076296129797259, "compression_ratio": 1.832116788321168, "no_speech_prob": 0.00857846811413765}, {"id": 1134, "seek": 405984, "start": 4070.96, "end": 4074.8, "text": " priors as if they are fundamental but folks like Steven Wolfram for", "tokens": [50920, 1790, 830, 382, 498, 436, 366, 8088, 457, 4024, 411, 12754, 16634, 2356, 337, 51112], "temperature": 0.0, "avg_logprob": -0.1076296129797259, "compression_ratio": 1.832116788321168, "no_speech_prob": 0.00857846811413765}, {"id": 1135, "seek": 405984, "start": 4074.8, "end": 4077.84, "text": " example argue that there's there's a deeper", "tokens": [51112, 1365, 9695, 300, 456, 311, 456, 311, 257, 7731, 51264], "temperature": 0.0, "avg_logprob": -0.1076296129797259, "compression_ratio": 1.832116788321168, "no_speech_prob": 0.00857846811413765}, {"id": 1136, "seek": 405984, "start": 4077.84, "end": 4081.04, "text": " ontological reality you know might be a graph cellular automaton or something", "tokens": [51264, 6592, 4383, 4103, 291, 458, 1062, 312, 257, 4295, 29267, 3553, 25781, 420, 746, 51424], "temperature": 0.0, "avg_logprob": -0.1076296129797259, "compression_ratio": 1.832116788321168, "no_speech_prob": 0.00857846811413765}, {"id": 1137, "seek": 405984, "start": 4081.04, "end": 4084.08, "text": " like that and is that something you think", "tokens": [51424, 411, 300, 293, 307, 300, 746, 291, 519, 51576], "temperature": 0.0, "avg_logprob": -0.1076296129797259, "compression_ratio": 1.832116788321168, "no_speech_prob": 0.00857846811413765}, {"id": 1138, "seek": 405984, "start": 4084.08, "end": 4087.6800000000003, "text": " about the kind of the gap between our models and what reality is", "tokens": [51576, 466, 264, 733, 295, 264, 7417, 1296, 527, 5245, 293, 437, 4103, 307, 51756], "temperature": 0.0, "avg_logprob": -0.1076296129797259, "compression_ratio": 1.832116788321168, "no_speech_prob": 0.00857846811413765}, {"id": 1139, "seek": 408768, "start": 4087.68, "end": 4090.64, "text": " so i think first of all one of the greatest scientific discoveries of all", "tokens": [50364, 370, 741, 519, 700, 295, 439, 472, 295, 264, 6636, 8134, 28400, 295, 439, 50512], "temperature": 0.0, "avg_logprob": -0.1008949901746667, "compression_ratio": 1.8616352201257862, "no_speech_prob": 0.0017036523204296827}, {"id": 1140, "seek": 408768, "start": 4090.64, "end": 4094.0, "text": " time is the fact the universe can be described by simple laws that that is", "tokens": [50512, 565, 307, 264, 1186, 264, 6445, 393, 312, 7619, 538, 2199, 6064, 300, 300, 307, 50680], "temperature": 0.0, "avg_logprob": -0.1008949901746667, "compression_ratio": 1.8616352201257862, "no_speech_prob": 0.0017036523204296827}, {"id": 1141, "seek": 408768, "start": 4094.0, "end": 4096.639999999999, "text": " not obvious a priori that itself is perhaps the most", "tokens": [50680, 406, 6322, 257, 4059, 72, 300, 2564, 307, 4317, 264, 881, 50812], "temperature": 0.0, "avg_logprob": -0.1008949901746667, "compression_ratio": 1.8616352201257862, "no_speech_prob": 0.0017036523204296827}, {"id": 1142, "seek": 408768, "start": 4096.639999999999, "end": 4099.76, "text": " profound discovery you know really going back to Newton but we found it time", "tokens": [50812, 14382, 12114, 291, 458, 534, 516, 646, 281, 19541, 457, 321, 1352, 309, 565, 50968], "temperature": 0.0, "avg_logprob": -0.1008949901746667, "compression_ratio": 1.8616352201257862, "no_speech_prob": 0.0017036523204296827}, {"id": 1143, "seek": 408768, "start": 4099.76, "end": 4102.72, "text": " and time again what we've also found is that the", "tokens": [50968, 293, 565, 797, 437, 321, 600, 611, 1352, 307, 300, 264, 51116], "temperature": 0.0, "avg_logprob": -0.1008949901746667, "compression_ratio": 1.8616352201257862, "no_speech_prob": 0.0017036523204296827}, {"id": 1144, "seek": 408768, "start": 4102.72, "end": 4105.2, "text": " our understanding of the universe as it exists today", "tokens": [51116, 527, 3701, 295, 264, 6445, 382, 309, 8198, 965, 51240], "temperature": 0.0, "avg_logprob": -0.1008949901746667, "compression_ratio": 1.8616352201257862, "no_speech_prob": 0.0017036523204296827}, {"id": 1145, "seek": 408768, "start": 4105.2, "end": 4108.8, "text": " has has it's almost like onions we're peeling way layers of onions", "tokens": [51240, 575, 575, 309, 311, 1920, 411, 13146, 321, 434, 39926, 636, 7914, 295, 13146, 51420], "temperature": 0.0, "avg_logprob": -0.1008949901746667, "compression_ratio": 1.8616352201257862, "no_speech_prob": 0.0017036523204296827}, {"id": 1146, "seek": 408768, "start": 4108.8, "end": 4112.0, "text": " you know Newton if you want to navigate a spacecraft to Jupiter you still use", "tokens": [51420, 291, 458, 19541, 498, 291, 528, 281, 12350, 257, 22910, 281, 24567, 291, 920, 764, 51580], "temperature": 0.0, "avg_logprob": -0.1008949901746667, "compression_ratio": 1.8616352201257862, "no_speech_prob": 0.0017036523204296827}, {"id": 1147, "seek": 408768, "start": 4112.0, "end": 4115.92, "text": " Newton's laws of motion and Newton's law of gravity it's just fine", "tokens": [51580, 19541, 311, 6064, 295, 5394, 293, 19541, 311, 2101, 295, 12110, 309, 311, 445, 2489, 51776], "temperature": 0.0, "avg_logprob": -0.1008949901746667, "compression_ratio": 1.8616352201257862, "no_speech_prob": 0.0017036523204296827}, {"id": 1148, "seek": 411592, "start": 4115.92, "end": 4119.04, "text": " it doesn't mean we believe it's exact description of nature we've now got", "tokens": [50364, 309, 1177, 380, 914, 321, 1697, 309, 311, 1900, 3855, 295, 3687, 321, 600, 586, 658, 50520], "temperature": 0.0, "avg_logprob": -0.09105317520372795, "compression_ratio": 1.9565217391304348, "no_speech_prob": 0.00203837756998837}, {"id": 1149, "seek": 411592, "start": 4119.04, "end": 4122.4, "text": " deeper descriptions of nature we understand relativity for example", "tokens": [50520, 7731, 24406, 295, 3687, 321, 1223, 45675, 337, 1365, 50688], "temperature": 0.0, "avg_logprob": -0.09105317520372795, "compression_ratio": 1.9565217391304348, "no_speech_prob": 0.00203837756998837}, {"id": 1150, "seek": 411592, "start": 4122.4, "end": 4125.6, "text": " general relativity tells us that actually Newton's second law of", "tokens": [50688, 2674, 45675, 5112, 505, 300, 767, 19541, 311, 1150, 2101, 295, 50848], "temperature": 0.0, "avg_logprob": -0.09105317520372795, "compression_ratio": 1.9565217391304348, "no_speech_prob": 0.00203837756998837}, {"id": 1151, "seek": 411592, "start": 4125.6, "end": 4128.24, "text": " motion or Newton's Newton's law of gravity rather is just an", "tokens": [50848, 5394, 420, 19541, 311, 19541, 311, 2101, 295, 12110, 2831, 307, 445, 364, 50980], "temperature": 0.0, "avg_logprob": -0.09105317520372795, "compression_ratio": 1.9565217391304348, "no_speech_prob": 0.00203837756998837}, {"id": 1152, "seek": 411592, "start": 4128.24, "end": 4130.08, "text": " approximation the inverse square law is a pretty good", "tokens": [50980, 28023, 264, 17340, 3732, 2101, 307, 257, 1238, 665, 51072], "temperature": 0.0, "avg_logprob": -0.09105317520372795, "compression_ratio": 1.9565217391304348, "no_speech_prob": 0.00203837756998837}, {"id": 1153, "seek": 411592, "start": 4130.08, "end": 4133.36, "text": " approximation but we've got a much better description now", "tokens": [51072, 28023, 457, 321, 600, 658, 257, 709, 1101, 3855, 586, 51236], "temperature": 0.0, "avg_logprob": -0.09105317520372795, "compression_ratio": 1.9565217391304348, "no_speech_prob": 0.00203837756998837}, {"id": 1154, "seek": 411592, "start": 4133.36, "end": 4138.08, "text": " but but it's it's it's hard to say that we've we've found the ultimate answer", "tokens": [51236, 457, 457, 309, 311, 309, 311, 309, 311, 1152, 281, 584, 300, 321, 600, 321, 600, 1352, 264, 9705, 1867, 51472], "temperature": 0.0, "avg_logprob": -0.09105317520372795, "compression_ratio": 1.9565217391304348, "no_speech_prob": 0.00203837756998837}, {"id": 1155, "seek": 411592, "start": 4138.08, "end": 4141.12, "text": " it's rather that human knowledge is or just always", "tokens": [51472, 309, 311, 2831, 300, 1952, 3601, 307, 420, 445, 1009, 51624], "temperature": 0.0, "avg_logprob": -0.09105317520372795, "compression_ratio": 1.9565217391304348, "no_speech_prob": 0.00203837756998837}, {"id": 1156, "seek": 411592, "start": 4141.12, "end": 4144.8, "text": " stands on that that edge of what we don't understand and scientific discovery", "tokens": [51624, 7382, 322, 300, 300, 4691, 295, 437, 321, 500, 380, 1223, 293, 8134, 12114, 51808], "temperature": 0.0, "avg_logprob": -0.09105317520372795, "compression_ratio": 1.9565217391304348, "no_speech_prob": 0.00203837756998837}, {"id": 1157, "seek": 414480, "start": 4144.8, "end": 4147.76, "text": " is always about exploring the things we don't understand", "tokens": [50364, 307, 1009, 466, 12736, 264, 721, 321, 500, 380, 1223, 50512], "temperature": 0.0, "avg_logprob": -0.10214355343677958, "compression_ratio": 1.8380281690140845, "no_speech_prob": 0.0016364023322239518}, {"id": 1158, "seek": 414480, "start": 4147.76, "end": 4152.16, "text": " working out whether you know whether the laws actually do hold", "tokens": [50512, 1364, 484, 1968, 291, 458, 1968, 264, 6064, 767, 360, 1797, 50732], "temperature": 0.0, "avg_logprob": -0.10214355343677958, "compression_ratio": 1.8380281690140845, "no_speech_prob": 0.0016364023322239518}, {"id": 1159, "seek": 414480, "start": 4152.16, "end": 4155.4400000000005, "text": " and the anomaly we see in the data is is because of some", "tokens": [50732, 293, 264, 42737, 321, 536, 294, 264, 1412, 307, 307, 570, 295, 512, 50896], "temperature": 0.0, "avg_logprob": -0.10214355343677958, "compression_ratio": 1.8380281690140845, "no_speech_prob": 0.0016364023322239518}, {"id": 1160, "seek": 414480, "start": 4155.4400000000005, "end": 4158.4800000000005, "text": " phenomenon that we haven't yet observed I mean this is how Neptune was", "tokens": [50896, 14029, 300, 321, 2378, 380, 1939, 13095, 286, 914, 341, 307, 577, 49527, 390, 51048], "temperature": 0.0, "avg_logprob": -0.10214355343677958, "compression_ratio": 1.8380281690140845, "no_speech_prob": 0.0016364023322239518}, {"id": 1161, "seek": 414480, "start": 4158.4800000000005, "end": 4161.84, "text": " discovered by by seeing that the planets were not behaving as they", "tokens": [51048, 6941, 538, 538, 2577, 300, 264, 15126, 645, 406, 35263, 382, 436, 51216], "temperature": 0.0, "avg_logprob": -0.10214355343677958, "compression_ratio": 1.8380281690140845, "no_speech_prob": 0.0016364023322239518}, {"id": 1162, "seek": 414480, "start": 4161.84, "end": 4164.4800000000005, "text": " should do according to Newton's laws Newton's laws were just fine there's", "tokens": [51216, 820, 360, 4650, 281, 19541, 311, 6064, 19541, 311, 6064, 645, 445, 2489, 456, 311, 51348], "temperature": 0.0, "avg_logprob": -0.10214355343677958, "compression_ratio": 1.8380281690140845, "no_speech_prob": 0.0016364023322239518}, {"id": 1163, "seek": 414480, "start": 4164.4800000000005, "end": 4168.88, "text": " just another planet perturbing them or is the procession of the perihelion of", "tokens": [51348, 445, 1071, 5054, 13269, 374, 4324, 552, 420, 307, 264, 1399, 313, 295, 264, 680, 4247, 338, 313, 295, 51568], "temperature": 0.0, "avg_logprob": -0.10214355343677958, "compression_ratio": 1.8380281690140845, "no_speech_prob": 0.0016364023322239518}, {"id": 1164, "seek": 414480, "start": 4168.88, "end": 4171.68, "text": " Mercury because because there's another no it's because", "tokens": [51568, 31780, 570, 570, 456, 311, 1071, 572, 309, 311, 570, 51708], "temperature": 0.0, "avg_logprob": -0.10214355343677958, "compression_ratio": 1.8380281690140845, "no_speech_prob": 0.0016364023322239518}, {"id": 1165, "seek": 417168, "start": 4171.68, "end": 4174.320000000001, "text": " actually Newton's law of gravity isn't quite right we need", "tokens": [50364, 767, 19541, 311, 2101, 295, 12110, 1943, 380, 1596, 558, 321, 643, 50496], "temperature": 0.0, "avg_logprob": -0.11142222086588542, "compression_ratio": 1.7925170068027212, "no_speech_prob": 0.001632006955333054}, {"id": 1166, "seek": 417168, "start": 4174.320000000001, "end": 4178.16, "text": " relativity to understand that so I think scientific", "tokens": [50496, 45675, 281, 1223, 300, 370, 286, 519, 8134, 50688], "temperature": 0.0, "avg_logprob": -0.11142222086588542, "compression_ratio": 1.7925170068027212, "no_speech_prob": 0.001632006955333054}, {"id": 1167, "seek": 417168, "start": 4178.16, "end": 4182.64, "text": " exploration as far as I can tell has no particular end in sight it's", "tokens": [50688, 16197, 382, 1400, 382, 286, 393, 980, 575, 572, 1729, 917, 294, 7860, 309, 311, 50912], "temperature": 0.0, "avg_logprob": -0.11142222086588542, "compression_ratio": 1.7925170068027212, "no_speech_prob": 0.001632006955333054}, {"id": 1168, "seek": 417168, "start": 4182.64, "end": 4186.08, "text": " rather that we have things that we understand and there are new frontiers", "tokens": [50912, 2831, 300, 321, 362, 721, 300, 321, 1223, 293, 456, 366, 777, 1868, 4890, 51084], "temperature": 0.0, "avg_logprob": -0.11142222086588542, "compression_ratio": 1.7925170068027212, "no_speech_prob": 0.001632006955333054}, {"id": 1169, "seek": 417168, "start": 4186.08, "end": 4188.56, "text": " you know when I was when I was a teenager getting", "tokens": [51084, 291, 458, 562, 286, 390, 562, 286, 390, 257, 21440, 1242, 51208], "temperature": 0.0, "avg_logprob": -0.11142222086588542, "compression_ratio": 1.7925170068027212, "no_speech_prob": 0.001632006955333054}, {"id": 1170, "seek": 417168, "start": 4188.56, "end": 4192.88, "text": " excited by physics I love reading about relativity and quantum physics but it's", "tokens": [51208, 2919, 538, 10649, 286, 959, 3760, 466, 45675, 293, 13018, 10649, 457, 309, 311, 51424], "temperature": 0.0, "avg_logprob": -0.11142222086588542, "compression_ratio": 1.7925170068027212, "no_speech_prob": 0.001632006955333054}, {"id": 1171, "seek": 417168, "start": 4192.88, "end": 4195.52, "text": " kind of depressing because I thought you know it's kind of born", "tokens": [51424, 733, 295, 36355, 570, 286, 1194, 291, 458, 309, 311, 733, 295, 4232, 51556], "temperature": 0.0, "avg_logprob": -0.11142222086588542, "compression_ratio": 1.7925170068027212, "no_speech_prob": 0.001632006955333054}, {"id": 1172, "seek": 417168, "start": 4195.52, "end": 4198.72, "text": " you know 50 years too late or whatever you know all the exciting stuff happened", "tokens": [51556, 291, 458, 2625, 924, 886, 3469, 420, 2035, 291, 458, 439, 264, 4670, 1507, 2011, 51716], "temperature": 0.0, "avg_logprob": -0.11142222086588542, "compression_ratio": 1.7925170068027212, "no_speech_prob": 0.001632006955333054}, {"id": 1173, "seek": 419872, "start": 4198.72, "end": 4202.400000000001, "text": " at the beginning of the 20th century it's kind of all been done", "tokens": [50364, 412, 264, 2863, 295, 264, 945, 392, 4901, 309, 311, 733, 295, 439, 668, 1096, 50548], "temperature": 0.0, "avg_logprob": -0.10936438859398685, "compression_ratio": 1.8431372549019607, "no_speech_prob": 0.002921617589890957}, {"id": 1174, "seek": 419872, "start": 4202.400000000001, "end": 4205.92, "text": " but now we have you know dark matter and dark energy and we realize that most of", "tokens": [50548, 457, 586, 321, 362, 291, 458, 2877, 1871, 293, 2877, 2281, 293, 321, 4325, 300, 881, 295, 50724], "temperature": 0.0, "avg_logprob": -0.10936438859398685, "compression_ratio": 1.8431372549019607, "no_speech_prob": 0.002921617589890957}, {"id": 1175, "seek": 419872, "start": 4205.92, "end": 4208.72, "text": " the universe isn't sitting on the periodic table that I learned about in", "tokens": [50724, 264, 6445, 1943, 380, 3798, 322, 264, 27790, 3199, 300, 286, 3264, 466, 294, 50864], "temperature": 0.0, "avg_logprob": -0.10936438859398685, "compression_ratio": 1.8431372549019607, "no_speech_prob": 0.002921617589890957}, {"id": 1176, "seek": 419872, "start": 4208.72, "end": 4212.72, "text": " schools and actually I needn't have worried you know", "tokens": [50864, 4656, 293, 767, 286, 643, 77, 380, 362, 5804, 291, 458, 51064], "temperature": 0.0, "avg_logprob": -0.10936438859398685, "compression_ratio": 1.8431372549019607, "no_speech_prob": 0.002921617589890957}, {"id": 1177, "seek": 419872, "start": 4212.72, "end": 4217.52, "text": " I think it was at Vannevar Bush who called it the endless frontier", "tokens": [51064, 286, 519, 309, 390, 412, 8979, 716, 8517, 15782, 567, 1219, 309, 264, 16144, 35853, 51304], "temperature": 0.0, "avg_logprob": -0.10936438859398685, "compression_ratio": 1.8431372549019607, "no_speech_prob": 0.002921617589890957}, {"id": 1178, "seek": 419872, "start": 4217.52, "end": 4220.72, "text": " the you know science is an endless frontier there is just there is", "tokens": [51304, 264, 291, 458, 3497, 307, 364, 16144, 35853, 456, 307, 445, 456, 307, 51464], "temperature": 0.0, "avg_logprob": -0.10936438859398685, "compression_ratio": 1.8431372549019607, "no_speech_prob": 0.002921617589890957}, {"id": 1179, "seek": 419872, "start": 4220.72, "end": 4224.56, "text": " always more to explore and always more to learn so whether the particular ideas", "tokens": [51464, 1009, 544, 281, 6839, 293, 1009, 544, 281, 1466, 370, 1968, 264, 1729, 3487, 51656], "temperature": 0.0, "avg_logprob": -0.10936438859398685, "compression_ratio": 1.8431372549019607, "no_speech_prob": 0.002921617589890957}, {"id": 1180, "seek": 419872, "start": 4224.56, "end": 4227.52, "text": " you alluded to have substance I don't know at the end of the day the scientific", "tokens": [51656, 291, 33919, 281, 362, 12961, 286, 500, 380, 458, 412, 264, 917, 295, 264, 786, 264, 8134, 51804], "temperature": 0.0, "avg_logprob": -0.10936438859398685, "compression_ratio": 1.8431372549019607, "no_speech_prob": 0.002921617589890957}, {"id": 1181, "seek": 422752, "start": 4227.52, "end": 4230.56, "text": " method will tell us if they have predictive capabilities they can predict", "tokens": [50364, 3170, 486, 980, 505, 498, 436, 362, 35521, 10862, 436, 393, 6069, 50516], "temperature": 0.0, "avg_logprob": -0.11349294224723441, "compression_ratio": 1.90625, "no_speech_prob": 0.0025642127729952335}, {"id": 1182, "seek": 422752, "start": 4230.56, "end": 4232.72, "text": " new phenomena that we weren't aware of before", "tokens": [50516, 777, 22004, 300, 321, 4999, 380, 3650, 295, 949, 50624], "temperature": 0.0, "avg_logprob": -0.11349294224723441, "compression_ratio": 1.90625, "no_speech_prob": 0.0025642127729952335}, {"id": 1183, "seek": 422752, "start": 4232.72, "end": 4238.240000000001, "text": " then you know then they have they have credence as far as a scientist", "tokens": [50624, 550, 291, 458, 550, 436, 362, 436, 362, 3864, 655, 382, 1400, 382, 257, 12662, 50900], "temperature": 0.0, "avg_logprob": -0.11349294224723441, "compression_ratio": 1.90625, "no_speech_prob": 0.0025642127729952335}, {"id": 1184, "seek": 422752, "start": 4238.240000000001, "end": 4241.6, "text": " is concerned but ultimately you know we still stick to the", "tokens": [50900, 307, 5922, 457, 6284, 291, 458, 321, 920, 2897, 281, 264, 51068], "temperature": 0.0, "avg_logprob": -0.11349294224723441, "compression_ratio": 1.90625, "no_speech_prob": 0.0025642127729952335}, {"id": 1185, "seek": 422752, "start": 4241.6, "end": 4244.64, "text": " scientific method it's about our ability to make predictions that are", "tokens": [51068, 8134, 3170, 309, 311, 466, 527, 3485, 281, 652, 21264, 300, 366, 51220], "temperature": 0.0, "avg_logprob": -0.11349294224723441, "compression_ratio": 1.90625, "no_speech_prob": 0.0025642127729952335}, {"id": 1186, "seek": 422752, "start": 4244.64, "end": 4247.52, "text": " testable experimentally and if they stand up to the test of", "tokens": [51220, 1500, 712, 5120, 379, 293, 498, 436, 1463, 493, 281, 264, 1500, 295, 51364], "temperature": 0.0, "avg_logprob": -0.11349294224723441, "compression_ratio": 1.90625, "no_speech_prob": 0.0025642127729952335}, {"id": 1187, "seek": 422752, "start": 4247.52, "end": 4250.56, "text": " experiment then we give more weight to those to those hypotheses and", "tokens": [51364, 5120, 550, 321, 976, 544, 3364, 281, 729, 281, 729, 49969, 293, 51516], "temperature": 0.0, "avg_logprob": -0.11349294224723441, "compression_ratio": 1.90625, "no_speech_prob": 0.0025642127729952335}, {"id": 1188, "seek": 422752, "start": 4250.56, "end": 4253.120000000001, "text": " eventually they're elevated to the stages of theory", "tokens": [51516, 4728, 436, 434, 23457, 281, 264, 10232, 295, 5261, 51644], "temperature": 0.0, "avg_logprob": -0.11349294224723441, "compression_ratio": 1.90625, "no_speech_prob": 0.0025642127729952335}, {"id": 1189, "seek": 422752, "start": 4253.120000000001, "end": 4257.120000000001, "text": " I often wonder about the horizon of our cognition", "tokens": [51644, 286, 2049, 2441, 466, 264, 18046, 295, 527, 46905, 51844], "temperature": 0.0, "avg_logprob": -0.11349294224723441, "compression_ratio": 1.90625, "no_speech_prob": 0.0025642127729952335}, {"id": 1190, "seek": 425712, "start": 4257.12, "end": 4261.44, "text": " you know what we are capable of understanding and we tend to understand", "tokens": [50364, 291, 458, 437, 321, 366, 8189, 295, 3701, 293, 321, 3928, 281, 1223, 50580], "temperature": 0.0, "avg_logprob": -0.10321484779825016, "compression_ratio": 1.8091286307053942, "no_speech_prob": 0.0014366422547027469}, {"id": 1191, "seek": 425712, "start": 4261.44, "end": 4265.5199999999995, "text": " things using high-level metaphors information is a great example of that", "tokens": [50580, 721, 1228, 1090, 12, 12418, 30946, 830, 1589, 307, 257, 869, 1365, 295, 300, 50784], "temperature": 0.0, "avg_logprob": -0.10321484779825016, "compression_ratio": 1.8091286307053942, "no_speech_prob": 0.0014366422547027469}, {"id": 1192, "seek": 425712, "start": 4265.5199999999995, "end": 4268.08, "text": " so a lot of people talk about the universe as", "tokens": [50784, 370, 257, 688, 295, 561, 751, 466, 264, 6445, 382, 50912], "temperature": 0.0, "avg_logprob": -0.10321484779825016, "compression_ratio": 1.8091286307053942, "no_speech_prob": 0.0014366422547027469}, {"id": 1193, "seek": 425712, "start": 4268.08, "end": 4271.84, "text": " information this agential view is quite interesting so", "tokens": [50912, 1589, 341, 623, 2549, 1910, 307, 1596, 1880, 370, 51100], "temperature": 0.0, "avg_logprob": -0.10321484779825016, "compression_ratio": 1.8091286307053942, "no_speech_prob": 0.0014366422547027469}, {"id": 1194, "seek": 425712, "start": 4271.84, "end": 4276.48, "text": " modeling everything as agents and it might well be possible that the", "tokens": [51100, 15983, 1203, 382, 12554, 293, 309, 1062, 731, 312, 1944, 300, 264, 51332], "temperature": 0.0, "avg_logprob": -0.10321484779825016, "compression_ratio": 1.8091286307053942, "no_speech_prob": 0.0014366422547027469}, {"id": 1195, "seek": 425712, "start": 4276.48, "end": 4279.92, "text": " universe is just so strange and alien that we could never possibly", "tokens": [51332, 6445, 307, 445, 370, 5861, 293, 12319, 300, 321, 727, 1128, 6264, 51504], "temperature": 0.0, "avg_logprob": -0.10321484779825016, "compression_ratio": 1.8091286307053942, "no_speech_prob": 0.0014366422547027469}, {"id": 1196, "seek": 425712, "start": 4279.92, "end": 4282.72, "text": " understand it so there's a bit of an interplay between", "tokens": [51504, 1223, 309, 370, 456, 311, 257, 857, 295, 364, 728, 2858, 1296, 51644], "temperature": 0.0, "avg_logprob": -0.10321484779825016, "compression_ratio": 1.8091286307053942, "no_speech_prob": 0.0014366422547027469}, {"id": 1197, "seek": 428272, "start": 4282.72, "end": 4287.84, "text": " our kind of intelligibility and and our models and what it is", "tokens": [50364, 527, 733, 295, 5613, 2841, 293, 293, 527, 5245, 293, 437, 309, 307, 50620], "temperature": 0.0, "avg_logprob": -0.09164202624353869, "compression_ratio": 1.8505338078291815, "no_speech_prob": 0.0016623061383143067}, {"id": 1198, "seek": 428272, "start": 4287.84, "end": 4291.360000000001, "text": " the universe clearly is completely unintelligible in the sense of", "tokens": [50620, 264, 6445, 4448, 307, 2584, 517, 27356, 294, 264, 2020, 295, 50796], "temperature": 0.0, "avg_logprob": -0.09164202624353869, "compression_ratio": 1.8505338078291815, "no_speech_prob": 0.0016623061383143067}, {"id": 1199, "seek": 428272, "start": 4291.360000000001, "end": 4295.04, "text": " nobody can really think about quantum physics", "tokens": [50796, 5079, 393, 534, 519, 466, 13018, 10649, 50980], "temperature": 0.0, "avg_logprob": -0.09164202624353869, "compression_ratio": 1.8505338078291815, "no_speech_prob": 0.0016623061383143067}, {"id": 1200, "seek": 428272, "start": 4295.04, "end": 4297.92, "text": " it completely defies our everyday intuitions that we learn at this sort", "tokens": [50980, 309, 2584, 1060, 530, 527, 7429, 16224, 626, 300, 321, 1466, 412, 341, 1333, 51124], "temperature": 0.0, "avg_logprob": -0.09164202624353869, "compression_ratio": 1.8505338078291815, "no_speech_prob": 0.0016623061383143067}, {"id": 1201, "seek": 428272, "start": 4297.92, "end": 4301.4400000000005, "text": " of macroscopic level so I think we have to accept already that the", "tokens": [51124, 295, 7912, 38006, 299, 1496, 370, 286, 519, 321, 362, 281, 3241, 1217, 300, 264, 51300], "temperature": 0.0, "avg_logprob": -0.09164202624353869, "compression_ratio": 1.8505338078291815, "no_speech_prob": 0.0016623061383143067}, {"id": 1202, "seek": 428272, "start": 4301.4400000000005, "end": 4304.8, "text": " universe is described mathematically that's our precise description", "tokens": [51300, 6445, 307, 7619, 44003, 300, 311, 527, 13600, 3855, 51468], "temperature": 0.0, "avg_logprob": -0.09164202624353869, "compression_ratio": 1.8505338078291815, "no_speech_prob": 0.0016623061383143067}, {"id": 1203, "seek": 428272, "start": 4304.8, "end": 4307.76, "text": " and then we have kind of metaphors about waves and particles and so on but", "tokens": [51468, 293, 550, 321, 362, 733, 295, 30946, 830, 466, 9417, 293, 10007, 293, 370, 322, 457, 51616], "temperature": 0.0, "avg_logprob": -0.09164202624353869, "compression_ratio": 1.8505338078291815, "no_speech_prob": 0.0016623061383143067}, {"id": 1204, "seek": 428272, "start": 4307.76, "end": 4310.4800000000005, "text": " they none of them none of them really work properly they're just", "tokens": [51616, 436, 6022, 295, 552, 6022, 295, 552, 534, 589, 6108, 436, 434, 445, 51752], "temperature": 0.0, "avg_logprob": -0.09164202624353869, "compression_ratio": 1.8505338078291815, "no_speech_prob": 0.0016623061383143067}, {"id": 1205, "seek": 431048, "start": 4310.879999999999, "end": 4314.4, "text": " crutches to lean on but ultimately it's a mathematical description", "tokens": [50384, 941, 49307, 281, 11659, 322, 457, 6284, 309, 311, 257, 18894, 3855, 50560], "temperature": 0.0, "avg_logprob": -0.12927397420583678, "compression_ratio": 1.842809364548495, "no_speech_prob": 0.002086140913888812}, {"id": 1206, "seek": 431048, "start": 4314.4, "end": 4317.919999999999, "text": " but that that is that is also very interesting the fact that the world is", "tokens": [50560, 457, 300, 300, 307, 300, 307, 611, 588, 1880, 264, 1186, 300, 264, 1002, 307, 50736], "temperature": 0.0, "avg_logprob": -0.12927397420583678, "compression_ratio": 1.842809364548495, "no_speech_prob": 0.002086140913888812}, {"id": 1207, "seek": 431048, "start": 4317.919999999999, "end": 4321.28, "text": " described by mathematics that by making little marks on a piece of paper you", "tokens": [50736, 7619, 538, 18666, 300, 538, 1455, 707, 10640, 322, 257, 2522, 295, 3035, 291, 50904], "temperature": 0.0, "avg_logprob": -0.12927397420583678, "compression_ratio": 1.842809364548495, "no_speech_prob": 0.002086140913888812}, {"id": 1208, "seek": 431048, "start": 4321.28, "end": 4323.759999999999, "text": " can discover a new planet that's quite incredible", "tokens": [50904, 393, 4411, 257, 777, 5054, 300, 311, 1596, 4651, 51028], "temperature": 0.0, "avg_logprob": -0.12927397420583678, "compression_ratio": 1.842809364548495, "no_speech_prob": 0.002086140913888812}, {"id": 1209, "seek": 431048, "start": 4323.759999999999, "end": 4327.44, "text": " shifting over to deep learning a little bit more more broadly", "tokens": [51028, 17573, 670, 281, 2452, 2539, 257, 707, 857, 544, 544, 19511, 51212], "temperature": 0.0, "avg_logprob": -0.12927397420583678, "compression_ratio": 1.842809364548495, "no_speech_prob": 0.002086140913888812}, {"id": 1210, "seek": 431048, "start": 4327.44, "end": 4331.2, "text": " and we were touching on this already but the landscape is dominated by", "tokens": [51212, 293, 321, 645, 11175, 322, 341, 1217, 457, 264, 9661, 307, 23755, 538, 51400], "temperature": 0.0, "avg_logprob": -0.12927397420583678, "compression_ratio": 1.842809364548495, "no_speech_prob": 0.002086140913888812}, {"id": 1211, "seek": 431048, "start": 4331.2, "end": 4335.679999999999, "text": " transformers architectures what what are your broad thoughts about that", "tokens": [51400, 4088, 433, 6331, 1303, 437, 437, 366, 428, 4152, 4598, 466, 300, 51624], "temperature": 0.0, "avg_logprob": -0.12927397420583678, "compression_ratio": 1.842809364548495, "no_speech_prob": 0.002086140913888812}, {"id": 1212, "seek": 431048, "start": 4335.679999999999, "end": 4339.599999999999, "text": " like any field I think machine learning has its sort of its fads and its waves", "tokens": [51624, 411, 604, 2519, 286, 519, 3479, 2539, 575, 1080, 1333, 295, 1080, 283, 5834, 293, 1080, 9417, 51820], "temperature": 0.0, "avg_logprob": -0.12927397420583678, "compression_ratio": 1.842809364548495, "no_speech_prob": 0.002086140913888812}, {"id": 1213, "seek": 433960, "start": 4339.6, "end": 4342.64, "text": " something works really well and then everybody latches onto that and makes", "tokens": [50364, 746, 1985, 534, 731, 293, 550, 2201, 31837, 279, 3911, 300, 293, 1669, 50516], "temperature": 0.0, "avg_logprob": -0.09752506832424686, "compression_ratio": 1.9523809523809523, "no_speech_prob": 0.0006001210422255099}, {"id": 1214, "seek": 433960, "start": 4342.64, "end": 4344.72, "text": " use of that and that that's all well and good", "tokens": [50516, 764, 295, 300, 293, 300, 300, 311, 439, 731, 293, 665, 50620], "temperature": 0.0, "avg_logprob": -0.09752506832424686, "compression_ratio": 1.9523809523809523, "no_speech_prob": 0.0006001210422255099}, {"id": 1215, "seek": 433960, "start": 4344.72, "end": 4348.4800000000005, "text": " I'd be kind of surprised if the transformer is the last word in deep", "tokens": [50620, 286, 1116, 312, 733, 295, 6100, 498, 264, 31782, 307, 264, 1036, 1349, 294, 2452, 50808], "temperature": 0.0, "avg_logprob": -0.09752506832424686, "compression_ratio": 1.9523809523809523, "no_speech_prob": 0.0006001210422255099}, {"id": 1216, "seek": 433960, "start": 4348.4800000000005, "end": 4352.64, "text": " learning if that's the the the the the architecture we use forever more", "tokens": [50808, 2539, 498, 300, 311, 264, 264, 264, 264, 264, 9482, 321, 764, 5680, 544, 51016], "temperature": 0.0, "avg_logprob": -0.09752506832424686, "compression_ratio": 1.9523809523809523, "no_speech_prob": 0.0006001210422255099}, {"id": 1217, "seek": 433960, "start": 4352.64, "end": 4355.360000000001, "text": " but it clearly works very well and we haven't reached the end of its", "tokens": [51016, 457, 309, 4448, 1985, 588, 731, 293, 321, 2378, 380, 6488, 264, 917, 295, 1080, 51152], "temperature": 0.0, "avg_logprob": -0.09752506832424686, "compression_ratio": 1.9523809523809523, "no_speech_prob": 0.0006001210422255099}, {"id": 1218, "seek": 433960, "start": 4355.360000000001, "end": 4358.320000000001, "text": " capabilities by any means so it makes a lot of sense to", "tokens": [51152, 10862, 538, 604, 1355, 370, 309, 1669, 257, 688, 295, 2020, 281, 51300], "temperature": 0.0, "avg_logprob": -0.09752506832424686, "compression_ratio": 1.9523809523809523, "no_speech_prob": 0.0006001210422255099}, {"id": 1219, "seek": 433960, "start": 4358.320000000001, "end": 4362.320000000001, "text": " exploit the transformer architecture in applications and see how much we can", "tokens": [51300, 25924, 264, 31782, 9482, 294, 5821, 293, 536, 577, 709, 321, 393, 51500], "temperature": 0.0, "avg_logprob": -0.09752506832424686, "compression_ratio": 1.9523809523809523, "no_speech_prob": 0.0006001210422255099}, {"id": 1220, "seek": 433960, "start": 4362.320000000001, "end": 4365.6, "text": " gain from that at the same time there's clearly opportunities to think about", "tokens": [51500, 6052, 490, 300, 412, 264, 912, 565, 456, 311, 4448, 4786, 281, 519, 466, 51664], "temperature": 0.0, "avg_logprob": -0.09752506832424686, "compression_ratio": 1.9523809523809523, "no_speech_prob": 0.0006001210422255099}, {"id": 1221, "seek": 433960, "start": 4365.6, "end": 4368.88, "text": " the limitations of transformers the computational costs can we do the same", "tokens": [51664, 264, 15705, 295, 4088, 433, 264, 28270, 5497, 393, 321, 360, 264, 912, 51828], "temperature": 0.0, "avg_logprob": -0.09752506832424686, "compression_ratio": 1.9523809523809523, "no_speech_prob": 0.0006001210422255099}, {"id": 1222, "seek": 436888, "start": 4368.88, "end": 4372.56, "text": " thing you know with better scaling if you want longer context windows and all", "tokens": [50364, 551, 291, 458, 365, 1101, 21589, 498, 291, 528, 2854, 4319, 9309, 293, 439, 50548], "temperature": 0.0, "avg_logprob": -0.09792344401201863, "compression_ratio": 1.8271186440677967, "no_speech_prob": 0.0013418723829090595}, {"id": 1223, "seek": 436888, "start": 4372.56, "end": 4375.6, "text": " the rest so there's plenty of interesting research I think to be done in", "tokens": [50548, 264, 1472, 370, 456, 311, 7140, 295, 1880, 2132, 286, 519, 281, 312, 1096, 294, 50700], "temperature": 0.0, "avg_logprob": -0.09792344401201863, "compression_ratio": 1.8271186440677967, "no_speech_prob": 0.0013418723829090595}, {"id": 1224, "seek": 436888, "start": 4375.6, "end": 4378.08, "text": " in new architectures as well so I think we need both", "tokens": [50700, 294, 777, 6331, 1303, 382, 731, 370, 286, 519, 321, 643, 1293, 50824], "temperature": 0.0, "avg_logprob": -0.09792344401201863, "compression_ratio": 1.8271186440677967, "no_speech_prob": 0.0013418723829090595}, {"id": 1225, "seek": 436888, "start": 4378.08, "end": 4381.92, "text": " so you know here's another galaxy brain question why does deep learning work", "tokens": [50824, 370, 291, 458, 510, 311, 1071, 17639, 3567, 1168, 983, 775, 2452, 2539, 589, 51016], "temperature": 0.0, "avg_logprob": -0.09792344401201863, "compression_ratio": 1.8271186440677967, "no_speech_prob": 0.0013418723829090595}, {"id": 1226, "seek": 436888, "start": 4381.92, "end": 4385.12, "text": " you know because on on the face of it it shouldn't work it shouldn't train it", "tokens": [51016, 291, 458, 570, 322, 322, 264, 1851, 295, 309, 309, 4659, 380, 589, 309, 4659, 380, 3847, 309, 51176], "temperature": 0.0, "avg_logprob": -0.09792344401201863, "compression_ratio": 1.8271186440677967, "no_speech_prob": 0.0013418723829090595}, {"id": 1227, "seek": 436888, "start": 4385.12, "end": 4388.72, "text": " shouldn't generalize and they've been an absolutely", "tokens": [51176, 4659, 380, 2674, 1125, 293, 436, 600, 668, 364, 3122, 51356], "temperature": 0.0, "avg_logprob": -0.09792344401201863, "compression_ratio": 1.8271186440677967, "no_speech_prob": 0.0013418723829090595}, {"id": 1228, "seek": 436888, "start": 4388.72, "end": 4393.76, "text": " remarkable success why is that so I think first of all at one level you", "tokens": [51356, 12802, 2245, 983, 307, 300, 370, 286, 519, 700, 295, 439, 412, 472, 1496, 291, 51608], "temperature": 0.0, "avg_logprob": -0.09792344401201863, "compression_ratio": 1.8271186440677967, "no_speech_prob": 0.0013418723829090595}, {"id": 1229, "seek": 436888, "start": 4393.76, "end": 4396.24, "text": " could say well we understand why they work we're fitting", "tokens": [51608, 727, 584, 731, 321, 1223, 983, 436, 589, 321, 434, 15669, 51732], "temperature": 0.0, "avg_logprob": -0.09792344401201863, "compression_ratio": 1.8271186440677967, "no_speech_prob": 0.0013418723829090595}, {"id": 1230, "seek": 439624, "start": 4396.24, "end": 4399.44, "text": " nonlinear functions we're kind of doing curve fitting in high-dimensional space", "tokens": [50364, 2107, 28263, 6828, 321, 434, 733, 295, 884, 7605, 15669, 294, 1090, 12, 18759, 1901, 50524], "temperature": 0.0, "avg_logprob": -0.12441849885163483, "compression_ratio": 1.8717948717948718, "no_speech_prob": 0.002041338011622429}, {"id": 1231, "seek": 439624, "start": 4399.44, "end": 4403.2, "text": " we need some some generalization and it comes out to no free lunch theorems of", "tokens": [50524, 321, 643, 512, 512, 2674, 2144, 293, 309, 1487, 484, 281, 572, 1737, 6349, 10299, 2592, 295, 50712], "temperature": 0.0, "avg_logprob": -0.12441849885163483, "compression_ratio": 1.8717948717948718, "no_speech_prob": 0.002041338011622429}, {"id": 1232, "seek": 439624, "start": 4403.2, "end": 4406.32, "text": " inductive biases perhaps it's smoothness continuity perhaps it's something", "tokens": [50712, 31612, 488, 32152, 4317, 309, 311, 5508, 1287, 23807, 4317, 309, 311, 746, 50868], "temperature": 0.0, "avg_logprob": -0.12441849885163483, "compression_ratio": 1.8717948717948718, "no_speech_prob": 0.002041338011622429}, {"id": 1233, "seek": 439624, "start": 4406.32, "end": 4410.639999999999, "text": " more more constraining than that so at one level it's sort of not surprising I", "tokens": [50868, 544, 544, 11525, 1760, 813, 300, 370, 412, 472, 1496, 309, 311, 1333, 295, 406, 8830, 286, 51084], "temperature": 0.0, "avg_logprob": -0.12441849885163483, "compression_ratio": 1.8717948717948718, "no_speech_prob": 0.002041338011622429}, {"id": 1234, "seek": 439624, "start": 4410.639999999999, "end": 4414.0, "text": " can I can fit a polynomial to a bunch of data points and by gradient", "tokens": [51084, 393, 286, 393, 3318, 257, 26110, 281, 257, 3840, 295, 1412, 2793, 293, 538, 16235, 51252], "temperature": 0.0, "avg_logprob": -0.12441849885163483, "compression_ratio": 1.8717948717948718, "no_speech_prob": 0.002041338011622429}, {"id": 1235, "seek": 439624, "start": 4414.0, "end": 4417.36, "text": " methods and I can make good predictions for sort of intermediate points", "tokens": [51252, 7150, 293, 286, 393, 652, 665, 21264, 337, 1333, 295, 19376, 2793, 51420], "temperature": 0.0, "avg_logprob": -0.12441849885163483, "compression_ratio": 1.8717948717948718, "no_speech_prob": 0.002041338011622429}, {"id": 1236, "seek": 439624, "start": 4417.36, "end": 4420.32, "text": " just we're just generalizing that to more data and higher dimensions", "tokens": [51420, 445, 321, 434, 445, 2674, 3319, 300, 281, 544, 1412, 293, 2946, 12819, 51568], "temperature": 0.0, "avg_logprob": -0.12441849885163483, "compression_ratio": 1.8717948717948718, "no_speech_prob": 0.002041338011622429}, {"id": 1237, "seek": 439624, "start": 4420.32, "end": 4423.599999999999, "text": " so so one level I say no it's not at all surprising they work", "tokens": [51568, 370, 370, 472, 1496, 286, 584, 572, 309, 311, 406, 412, 439, 8830, 436, 589, 51732], "temperature": 0.0, "avg_logprob": -0.12441849885163483, "compression_ratio": 1.8717948717948718, "no_speech_prob": 0.002041338011622429}, {"id": 1238, "seek": 442360, "start": 4423.6, "end": 4427.04, "text": " at a different level of course the fact they work so well is remarkable", "tokens": [50364, 412, 257, 819, 1496, 295, 1164, 264, 1186, 436, 589, 370, 731, 307, 12802, 50536], "temperature": 0.0, "avg_logprob": -0.08415828117957481, "compression_ratio": 1.8291139240506329, "no_speech_prob": 0.0008734642760828137}, {"id": 1239, "seek": 442360, "start": 4427.04, "end": 4430.96, "text": " but the way in which they work is very interesting so one thing which", "tokens": [50536, 457, 264, 636, 294, 597, 436, 589, 307, 588, 1880, 370, 472, 551, 597, 50732], "temperature": 0.0, "avg_logprob": -0.08415828117957481, "compression_ratio": 1.8291139240506329, "no_speech_prob": 0.0008734642760828137}, {"id": 1240, "seek": 442360, "start": 4430.96, "end": 4435.6, "text": " if we go back to the earlier years of machine learning and certainly back to", "tokens": [50732, 498, 321, 352, 646, 281, 264, 3071, 924, 295, 3479, 2539, 293, 3297, 646, 281, 50964], "temperature": 0.0, "avg_logprob": -0.08415828117957481, "compression_ratio": 1.8291139240506329, "no_speech_prob": 0.0008734642760828137}, {"id": 1241, "seek": 442360, "start": 4435.6, "end": 4438.320000000001, "text": " the world of statistics the idea that you would fit models that", "tokens": [50964, 264, 1002, 295, 12523, 264, 1558, 300, 291, 576, 3318, 5245, 300, 51100], "temperature": 0.0, "avg_logprob": -0.08415828117957481, "compression_ratio": 1.8291139240506329, "no_speech_prob": 0.0008734642760828137}, {"id": 1242, "seek": 442360, "start": 4438.320000000001, "end": 4441.280000000001, "text": " have way more parameters than the number of data points would be", "tokens": [51100, 362, 636, 544, 9834, 813, 264, 1230, 295, 1412, 2793, 576, 312, 51248], "temperature": 0.0, "avg_logprob": -0.08415828117957481, "compression_ratio": 1.8291139240506329, "no_speech_prob": 0.0008734642760828137}, {"id": 1243, "seek": 442360, "start": 4441.280000000001, "end": 4444.88, "text": " clearly insane to any self-respecting statistician we never would have and", "tokens": [51248, 4448, 10838, 281, 604, 2698, 12, 19575, 278, 29588, 952, 321, 1128, 576, 362, 293, 51428], "temperature": 0.0, "avg_logprob": -0.08415828117957481, "compression_ratio": 1.8291139240506329, "no_speech_prob": 0.0008734642760828137}, {"id": 1244, "seek": 442360, "start": 4444.88, "end": 4448.8, "text": " perhaps that's nobody why nobody really tried it very much and yet we have", "tokens": [51428, 4317, 300, 311, 5079, 983, 5079, 534, 3031, 309, 588, 709, 293, 1939, 321, 362, 51624], "temperature": 0.0, "avg_logprob": -0.08415828117957481, "compression_ratio": 1.8291139240506329, "no_speech_prob": 0.0008734642760828137}, {"id": 1245, "seek": 442360, "start": 4448.8, "end": 4452.4800000000005, "text": " these odd phenomena whereby you know the training error goes to zero and yet the", "tokens": [51624, 613, 7401, 22004, 36998, 291, 458, 264, 3097, 6713, 1709, 281, 4018, 293, 1939, 264, 51808], "temperature": 0.0, "avg_logprob": -0.08415828117957481, "compression_ratio": 1.8291139240506329, "no_speech_prob": 0.0008734642760828137}, {"id": 1246, "seek": 445248, "start": 4452.48, "end": 4455.44, "text": " test error continues to come down even though the training error is already", "tokens": [50364, 1500, 6713, 6515, 281, 808, 760, 754, 1673, 264, 3097, 6713, 307, 1217, 50512], "temperature": 0.0, "avg_logprob": -0.07966255440431483, "compression_ratio": 1.9509803921568627, "no_speech_prob": 0.0005103698931634426}, {"id": 1247, "seek": 445248, "start": 4455.44, "end": 4460.0, "text": " at zero something about stochastic gradient descent", "tokens": [50512, 412, 4018, 746, 466, 342, 8997, 2750, 16235, 23475, 50740], "temperature": 0.0, "avg_logprob": -0.07966255440431483, "compression_ratio": 1.9509803921568627, "no_speech_prob": 0.0005103698931634426}, {"id": 1248, "seek": 445248, "start": 4460.0, "end": 4462.879999999999, "text": " the actual training process clearly is important there it's not just", "tokens": [50740, 264, 3539, 3097, 1399, 4448, 307, 1021, 456, 309, 311, 406, 445, 50884], "temperature": 0.0, "avg_logprob": -0.07966255440431483, "compression_ratio": 1.9509803921568627, "no_speech_prob": 0.0005103698931634426}, {"id": 1249, "seek": 445248, "start": 4462.879999999999, "end": 4465.44, "text": " here's a cost function we find the global minimum it's a property of the", "tokens": [50884, 510, 311, 257, 2063, 2445, 321, 915, 264, 4338, 7285, 309, 311, 257, 4707, 295, 264, 51012], "temperature": 0.0, "avg_logprob": -0.07966255440431483, "compression_ratio": 1.9509803921568627, "no_speech_prob": 0.0005103698931634426}, {"id": 1250, "seek": 445248, "start": 4465.44, "end": 4468.639999999999, "text": " global minimum no there are many many global minimum that all", "tokens": [51012, 4338, 7285, 572, 456, 366, 867, 867, 4338, 7285, 300, 439, 51172], "temperature": 0.0, "avg_logprob": -0.07966255440431483, "compression_ratio": 1.9509803921568627, "no_speech_prob": 0.0005103698931634426}, {"id": 1251, "seek": 445248, "start": 4468.639999999999, "end": 4472.48, "text": " have zero error some solutions will clearly overfit others generalize", "tokens": [51172, 362, 4018, 6713, 512, 6547, 486, 4448, 670, 6845, 2357, 2674, 1125, 51364], "temperature": 0.0, "avg_logprob": -0.07966255440431483, "compression_ratio": 1.9509803921568627, "no_speech_prob": 0.0005103698931634426}, {"id": 1252, "seek": 445248, "start": 4472.48, "end": 4474.639999999999, "text": " well and so there's something about the training", "tokens": [51364, 731, 293, 370, 456, 311, 746, 466, 264, 3097, 51472], "temperature": 0.0, "avg_logprob": -0.07966255440431483, "compression_ratio": 1.9509803921568627, "no_speech_prob": 0.0005103698931634426}, {"id": 1253, "seek": 445248, "start": 4474.639999999999, "end": 4478.16, "text": " process that we need to understand so I think there's a lot of research to be", "tokens": [51472, 1399, 300, 321, 643, 281, 1223, 370, 286, 519, 456, 311, 257, 688, 295, 2132, 281, 312, 51648], "temperature": 0.0, "avg_logprob": -0.07966255440431483, "compression_ratio": 1.9509803921568627, "no_speech_prob": 0.0005103698931634426}, {"id": 1254, "seek": 445248, "start": 4478.16, "end": 4481.36, "text": " to be done in why do they work so well I think it's an open question", "tokens": [51648, 281, 312, 1096, 294, 983, 360, 436, 589, 370, 731, 286, 519, 309, 311, 364, 1269, 1168, 51808], "temperature": 0.0, "avg_logprob": -0.07966255440431483, "compression_ratio": 1.9509803921568627, "no_speech_prob": 0.0005103698931634426}, {"id": 1255, "seek": 448136, "start": 4481.36, "end": 4484.4, "text": " we can describe the model we can say lots of things about the model we can", "tokens": [50364, 321, 393, 6786, 264, 2316, 321, 393, 584, 3195, 295, 721, 466, 264, 2316, 321, 393, 50516], "temperature": 0.0, "avg_logprob": -0.06613481294858706, "compression_ratio": 1.9341692789968652, "no_speech_prob": 0.005332321859896183}, {"id": 1256, "seek": 448136, "start": 4484.4, "end": 4487.599999999999, "text": " say because it has this and this and that number of layers", "tokens": [50516, 584, 570, 309, 575, 341, 293, 341, 293, 300, 1230, 295, 7914, 50676], "temperature": 0.0, "avg_logprob": -0.06613481294858706, "compression_ratio": 1.9341692789968652, "no_speech_prob": 0.005332321859896183}, {"id": 1257, "seek": 448136, "start": 4487.599999999999, "end": 4491.2, "text": " therefore the structure of the space has this and that properties and it divides", "tokens": [50676, 4412, 264, 3877, 295, 264, 1901, 575, 341, 293, 300, 7221, 293, 309, 41347, 50856], "temperature": 0.0, "avg_logprob": -0.06613481294858706, "compression_ratio": 1.9341692789968652, "no_speech_prob": 0.005332321859896183}, {"id": 1258, "seek": 448136, "start": 4491.2, "end": 4493.759999999999, "text": " it up into such and such regions and so on", "tokens": [50856, 309, 493, 666, 1270, 293, 1270, 10682, 293, 370, 322, 50984], "temperature": 0.0, "avg_logprob": -0.06613481294858706, "compression_ratio": 1.9341692789968652, "no_speech_prob": 0.005332321859896183}, {"id": 1259, "seek": 448136, "start": 4493.759999999999, "end": 4497.28, "text": " those are true I don't know whether that gives us real insights into why it's", "tokens": [50984, 729, 366, 2074, 286, 500, 380, 458, 1968, 300, 2709, 505, 957, 14310, 666, 983, 309, 311, 51160], "temperature": 0.0, "avg_logprob": -0.06613481294858706, "compression_ratio": 1.9341692789968652, "no_speech_prob": 0.005332321859896183}, {"id": 1260, "seek": 448136, "start": 4497.28, "end": 4500.639999999999, "text": " working I think there are some some very much open questions there it strikes", "tokens": [51160, 1364, 286, 519, 456, 366, 512, 512, 588, 709, 1269, 1651, 456, 309, 16750, 51328], "temperature": 0.0, "avg_logprob": -0.06613481294858706, "compression_ratio": 1.9341692789968652, "no_speech_prob": 0.005332321859896183}, {"id": 1261, "seek": 448136, "start": 4500.639999999999, "end": 4503.599999999999, "text": " me a little bit like neuroscience you know we have the human brain it does", "tokens": [51328, 385, 257, 707, 857, 411, 42762, 291, 458, 321, 362, 264, 1952, 3567, 309, 775, 51476], "temperature": 0.0, "avg_logprob": -0.06613481294858706, "compression_ratio": 1.9341692789968652, "no_speech_prob": 0.005332321859896183}, {"id": 1262, "seek": 448136, "start": 4503.599999999999, "end": 4506.639999999999, "text": " these amazing things and we can get more and more and", "tokens": [51476, 613, 2243, 721, 293, 321, 393, 483, 544, 293, 544, 293, 51628], "temperature": 0.0, "avg_logprob": -0.06613481294858706, "compression_ratio": 1.9341692789968652, "no_speech_prob": 0.005332321859896183}, {"id": 1263, "seek": 448136, "start": 4506.639999999999, "end": 4509.759999999999, "text": " richer and richer data about which neurons are firing and when and how the", "tokens": [51628, 29021, 293, 29021, 1412, 466, 597, 22027, 366, 16045, 293, 562, 293, 577, 264, 51784], "temperature": 0.0, "avg_logprob": -0.06613481294858706, "compression_ratio": 1.9341692789968652, "no_speech_prob": 0.005332321859896183}, {"id": 1264, "seek": 450976, "start": 4509.76, "end": 4512.24, "text": " firings are correlated we can learn something about the", "tokens": [50364, 12159, 1109, 366, 38574, 321, 393, 1466, 746, 466, 264, 50488], "temperature": 0.0, "avg_logprob": -0.11346240410437951, "compression_ratio": 1.8353658536585367, "no_speech_prob": 0.0010789015796035528}, {"id": 1265, "seek": 450976, "start": 4512.24, "end": 4515.76, "text": " the underlying machinery this is a bit like neuroscience except we can put a", "tokens": [50488, 264, 14217, 27302, 341, 307, 257, 857, 411, 42762, 3993, 321, 393, 829, 257, 50664], "temperature": 0.0, "avg_logprob": -0.11346240410437951, "compression_ratio": 1.8353658536585367, "no_speech_prob": 0.0010789015796035528}, {"id": 1266, "seek": 450976, "start": 4515.76, "end": 4519.52, "text": " probe in every neuron in the you know artificial brain and gather very very", "tokens": [50664, 22715, 294, 633, 34090, 294, 264, 291, 458, 11677, 3567, 293, 5448, 588, 588, 50852], "temperature": 0.0, "avg_logprob": -0.11346240410437951, "compression_ratio": 1.8353658536585367, "no_speech_prob": 0.0010789015796035528}, {"id": 1267, "seek": 450976, "start": 4519.52, "end": 4522.0, "text": " rich information so again I think there's a very", "tokens": [50852, 4593, 1589, 370, 797, 286, 519, 456, 311, 257, 588, 50976], "temperature": 0.0, "avg_logprob": -0.11346240410437951, "compression_ratio": 1.8353658536585367, "no_speech_prob": 0.0010789015796035528}, {"id": 1268, "seek": 450976, "start": 4522.0, "end": 4525.52, "text": " interesting research frontier of getting better understanding of why are", "tokens": [50976, 1880, 2132, 35853, 295, 1242, 1101, 3701, 295, 983, 366, 51152], "temperature": 0.0, "avg_logprob": -0.11346240410437951, "compression_ratio": 1.8353658536585367, "no_speech_prob": 0.0010789015796035528}, {"id": 1269, "seek": 450976, "start": 4525.52, "end": 4528.88, "text": " they able to generalize so well and why do we have these", "tokens": [51152, 436, 1075, 281, 2674, 1125, 370, 731, 293, 983, 360, 321, 362, 613, 51320], "temperature": 0.0, "avg_logprob": -0.11346240410437951, "compression_ratio": 1.8353658536585367, "no_speech_prob": 0.0010789015796035528}, {"id": 1270, "seek": 450976, "start": 4528.88, "end": 4532.4800000000005, "text": " strange phenomena with these seemingly over parameterized models that don't", "tokens": [51320, 5861, 22004, 365, 613, 18709, 670, 13075, 1602, 5245, 300, 500, 380, 51500], "temperature": 0.0, "avg_logprob": -0.11346240410437951, "compression_ratio": 1.8353658536585367, "no_speech_prob": 0.0010789015796035528}, {"id": 1271, "seek": 450976, "start": 4532.4800000000005, "end": 4535.52, "text": " overfit but rather have very good generalization lots of research to be", "tokens": [51500, 670, 6845, 457, 2831, 362, 588, 665, 2674, 2144, 3195, 295, 2132, 281, 312, 51652], "temperature": 0.0, "avg_logprob": -0.11346240410437951, "compression_ratio": 1.8353658536585367, "no_speech_prob": 0.0010789015796035528}, {"id": 1272, "seek": 450976, "start": 4535.52, "end": 4539.04, "text": " done and just to linger on that that observation you made that you", "tokens": [51652, 1096, 293, 445, 281, 45657, 322, 300, 300, 14816, 291, 1027, 300, 291, 51828], "temperature": 0.0, "avg_logprob": -0.11346240410437951, "compression_ratio": 1.8353658536585367, "no_speech_prob": 0.0010789015796035528}, {"id": 1273, "seek": 453904, "start": 4539.04, "end": 4542.8, "text": " can train a deep learning model and after the", "tokens": [50364, 393, 3847, 257, 2452, 2539, 2316, 293, 934, 264, 50552], "temperature": 0.0, "avg_logprob": -0.1256952891274104, "compression_ratio": 1.843205574912892, "no_speech_prob": 0.0005489892791956663}, {"id": 1274, "seek": 453904, "start": 4542.8, "end": 4547.6, "text": " training error has converged the test loss continues to improve I mean that", "tokens": [50552, 3097, 6713, 575, 9652, 3004, 264, 1500, 4470, 6515, 281, 3470, 286, 914, 300, 50792], "temperature": 0.0, "avg_logprob": -0.1256952891274104, "compression_ratio": 1.843205574912892, "no_speech_prob": 0.0005489892791956663}, {"id": 1275, "seek": 453904, "start": 4547.6, "end": 4550.56, "text": " just seems it just doesn't make sense", "tokens": [50792, 445, 2544, 309, 445, 1177, 380, 652, 2020, 50940], "temperature": 0.0, "avg_logprob": -0.1256952891274104, "compression_ratio": 1.843205574912892, "no_speech_prob": 0.0005489892791956663}, {"id": 1276, "seek": 453904, "start": 4550.56, "end": 4554.16, "text": " I mean how and that there's grocking as well which is another", "tokens": [50940, 286, 914, 577, 293, 300, 456, 311, 4634, 25723, 382, 731, 597, 307, 1071, 51120], "temperature": 0.0, "avg_logprob": -0.1256952891274104, "compression_ratio": 1.843205574912892, "no_speech_prob": 0.0005489892791956663}, {"id": 1277, "seek": 453904, "start": 4554.16, "end": 4557.44, "text": " it's almost like we were saying with physics that outside of the", "tokens": [51120, 309, 311, 1920, 411, 321, 645, 1566, 365, 10649, 300, 2380, 295, 264, 51284], "temperature": 0.0, "avg_logprob": -0.1256952891274104, "compression_ratio": 1.843205574912892, "no_speech_prob": 0.0005489892791956663}, {"id": 1278, "seek": 453904, "start": 4557.44, "end": 4560.32, "text": " the machinations of the optimization algorithm", "tokens": [51284, 264, 2246, 10325, 295, 264, 19618, 9284, 51428], "temperature": 0.0, "avg_logprob": -0.1256952891274104, "compression_ratio": 1.843205574912892, "no_speech_prob": 0.0005489892791956663}, {"id": 1279, "seek": 453904, "start": 4560.32, "end": 4563.36, "text": " stuff is happening that we don't understand well you can tell stories", "tokens": [51428, 1507, 307, 2737, 300, 321, 500, 380, 1223, 731, 291, 393, 980, 3676, 51580], "temperature": 0.0, "avg_logprob": -0.1256952891274104, "compression_ratio": 1.843205574912892, "no_speech_prob": 0.0005489892791956663}, {"id": 1280, "seek": 453904, "start": 4563.36, "end": 4565.36, "text": " right you can say there's a there's a big space", "tokens": [51580, 558, 291, 393, 584, 456, 311, 257, 456, 311, 257, 955, 1901, 51680], "temperature": 0.0, "avg_logprob": -0.1256952891274104, "compression_ratio": 1.843205574912892, "no_speech_prob": 0.0005489892791956663}, {"id": 1281, "seek": 453904, "start": 4565.36, "end": 4568.0, "text": " each point of the space is setting for all the parameters of the model so the", "tokens": [51680, 1184, 935, 295, 264, 1901, 307, 3287, 337, 439, 264, 9834, 295, 264, 2316, 370, 264, 51812], "temperature": 0.0, "avg_logprob": -0.1256952891274104, "compression_ratio": 1.843205574912892, "no_speech_prob": 0.0005489892791956663}, {"id": 1282, "seek": 456800, "start": 4568.0, "end": 4570.88, "text": " sort of the weight space of the model and maybe you started off somewhere near", "tokens": [50364, 1333, 295, 264, 3364, 1901, 295, 264, 2316, 293, 1310, 291, 1409, 766, 4079, 2651, 50508], "temperature": 0.0, "avg_logprob": -0.08305820737566266, "compression_ratio": 2.052980132450331, "no_speech_prob": 0.0007247270550578833}, {"id": 1283, "seek": 456800, "start": 4570.88, "end": 4573.68, "text": " the origin with some little random initialization and you follow some", "tokens": [50508, 264, 4957, 365, 512, 707, 4974, 5883, 2144, 293, 291, 1524, 512, 50648], "temperature": 0.0, "avg_logprob": -0.08305820737566266, "compression_ratio": 2.052980132450331, "no_speech_prob": 0.0007247270550578833}, {"id": 1284, "seek": 456800, "start": 4573.68, "end": 4576.48, "text": " trajectory that's defined by stochastic gradient descent", "tokens": [50648, 21512, 300, 311, 7642, 538, 342, 8997, 2750, 16235, 23475, 50788], "temperature": 0.0, "avg_logprob": -0.08305820737566266, "compression_ratio": 2.052980132450331, "no_speech_prob": 0.0007247270550578833}, {"id": 1285, "seek": 456800, "start": 4576.48, "end": 4579.92, "text": " and there are lots and lots of places in this space all of which have zero", "tokens": [50788, 293, 456, 366, 3195, 293, 3195, 295, 3190, 294, 341, 1901, 439, 295, 597, 362, 4018, 50960], "temperature": 0.0, "avg_logprob": -0.08305820737566266, "compression_ratio": 2.052980132450331, "no_speech_prob": 0.0007247270550578833}, {"id": 1286, "seek": 456800, "start": 4579.92, "end": 4582.48, "text": " training error so and they're connected so there's some", "tokens": [50960, 3097, 6713, 370, 293, 436, 434, 4582, 370, 456, 311, 512, 51088], "temperature": 0.0, "avg_logprob": -0.08305820737566266, "compression_ratio": 2.052980132450331, "no_speech_prob": 0.0007247270550578833}, {"id": 1287, "seek": 456800, "start": 4582.48, "end": 4585.36, "text": " sort of manifold of zero training error and you're starting off at the origin", "tokens": [51088, 1333, 295, 47138, 295, 4018, 3097, 6713, 293, 291, 434, 2891, 766, 412, 264, 4957, 51232], "temperature": 0.0, "avg_logprob": -0.08305820737566266, "compression_ratio": 2.052980132450331, "no_speech_prob": 0.0007247270550578833}, {"id": 1288, "seek": 456800, "start": 4585.36, "end": 4588.8, "text": " and stochastic gradient descent is somehow not taking you at a random way", "tokens": [51232, 293, 342, 8997, 2750, 16235, 23475, 307, 6063, 406, 1940, 291, 412, 257, 4974, 636, 51404], "temperature": 0.0, "avg_logprob": -0.08305820737566266, "compression_ratio": 2.052980132450331, "no_speech_prob": 0.0007247270550578833}, {"id": 1289, "seek": 456800, "start": 4588.8, "end": 4591.36, "text": " maybe it's taking you to something like you know the nearest", "tokens": [51404, 1310, 309, 311, 1940, 291, 281, 746, 411, 291, 458, 264, 23831, 51532], "temperature": 0.0, "avg_logprob": -0.08305820737566266, "compression_ratio": 2.052980132450331, "no_speech_prob": 0.0007247270550578833}, {"id": 1290, "seek": 456800, "start": 4591.36, "end": 4593.92, "text": " point on this manifold or something and that maybe that's some kind of", "tokens": [51532, 935, 322, 341, 47138, 420, 746, 293, 300, 1310, 300, 311, 512, 733, 295, 51660], "temperature": 0.0, "avg_logprob": -0.08305820737566266, "compression_ratio": 2.052980132450331, "no_speech_prob": 0.0007247270550578833}, {"id": 1291, "seek": 459392, "start": 4594.0, "end": 4597.6, "text": " regularization and maybe that place has", "tokens": [50368, 3890, 2144, 293, 1310, 300, 1081, 575, 50548], "temperature": 0.0, "avg_logprob": -0.10133463437439966, "compression_ratio": 1.8754325259515572, "no_speech_prob": 0.0030835415236651897}, {"id": 1292, "seek": 459392, "start": 4597.6, "end": 4600.4800000000005, "text": " certain smoothness properties that lead to good generalization", "tokens": [50548, 1629, 5508, 1287, 7221, 300, 1477, 281, 665, 2674, 2144, 50692], "temperature": 0.0, "avg_logprob": -0.10133463437439966, "compression_ratio": 1.8754325259515572, "no_speech_prob": 0.0030835415236651897}, {"id": 1293, "seek": 459392, "start": 4600.4800000000005, "end": 4603.36, "text": " so you can kind of tell these stories I think the challenge is to take the", "tokens": [50692, 370, 291, 393, 733, 295, 980, 613, 3676, 286, 519, 264, 3430, 307, 281, 747, 264, 50836], "temperature": 0.0, "avg_logprob": -0.10133463437439966, "compression_ratio": 1.8754325259515572, "no_speech_prob": 0.0030835415236651897}, {"id": 1294, "seek": 459392, "start": 4603.36, "end": 4607.12, "text": " stories and make them predictive so I think when we have a theory of", "tokens": [50836, 3676, 293, 652, 552, 35521, 370, 286, 519, 562, 321, 362, 257, 5261, 295, 51024], "temperature": 0.0, "avg_logprob": -0.10133463437439966, "compression_ratio": 1.8754325259515572, "no_speech_prob": 0.0030835415236651897}, {"id": 1295, "seek": 459392, "start": 4607.12, "end": 4610.0, "text": " what's going on we'll know we have a theory because it can predict new", "tokens": [51024, 437, 311, 516, 322, 321, 603, 458, 321, 362, 257, 5261, 570, 309, 393, 6069, 777, 51168], "temperature": 0.0, "avg_logprob": -0.10133463437439966, "compression_ratio": 1.8754325259515572, "no_speech_prob": 0.0030835415236651897}, {"id": 1296, "seek": 459392, "start": 4610.0, "end": 4613.12, "text": " things not just tell stories about what we've already discovered empirically", "tokens": [51168, 721, 406, 445, 980, 3676, 466, 437, 321, 600, 1217, 6941, 25790, 984, 51324], "temperature": 0.0, "avg_logprob": -0.10133463437439966, "compression_ratio": 1.8754325259515572, "no_speech_prob": 0.0030835415236651897}, {"id": 1297, "seek": 459392, "start": 4613.12, "end": 4618.0, "text": " but really become predictive I think that's still a very much an open question", "tokens": [51324, 457, 534, 1813, 35521, 286, 519, 300, 311, 920, 257, 588, 709, 364, 1269, 1168, 51568], "temperature": 0.0, "avg_logprob": -0.10133463437439966, "compression_ratio": 1.8754325259515572, "no_speech_prob": 0.0030835415236651897}, {"id": 1298, "seek": 459392, "start": 4618.0, "end": 4623.12, "text": " so what do you think about the intelligibility of neural networks in", "tokens": [51568, 370, 437, 360, 291, 519, 466, 264, 5613, 2841, 295, 18161, 9590, 294, 51824], "temperature": 0.0, "avg_logprob": -0.10133463437439966, "compression_ratio": 1.8754325259515572, "no_speech_prob": 0.0030835415236651897}, {"id": 1299, "seek": 462312, "start": 4623.2, "end": 4626.96, "text": " terms of things like bias and fairness and safety", "tokens": [50368, 2115, 295, 721, 411, 12577, 293, 29765, 293, 4514, 50556], "temperature": 0.0, "avg_logprob": -0.10711223345536453, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0005898739909753203}, {"id": 1300, "seek": 462312, "start": 4626.96, "end": 4632.24, "text": " because you could just think of these things as inscrutable", "tokens": [50556, 570, 291, 727, 445, 519, 295, 613, 721, 382, 1028, 10757, 32148, 50820], "temperature": 0.0, "avg_logprob": -0.10711223345536453, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0005898739909753203}, {"id": 1301, "seek": 462312, "start": 4632.24, "end": 4637.44, "text": " bags of neurons and but we need to have some guardrails don't we", "tokens": [50820, 10405, 295, 22027, 293, 457, 321, 643, 281, 362, 512, 6290, 424, 4174, 500, 380, 321, 51080], "temperature": 0.0, "avg_logprob": -0.10711223345536453, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0005898739909753203}, {"id": 1302, "seek": 462312, "start": 4637.44, "end": 4640.8, "text": " well we absolutely need to create technology that's beneficial to humanity", "tokens": [51080, 731, 321, 3122, 643, 281, 1884, 2899, 300, 311, 14072, 281, 10243, 51248], "temperature": 0.0, "avg_logprob": -0.10711223345536453, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0005898739909753203}, {"id": 1303, "seek": 462312, "start": 4640.8, "end": 4643.76, "text": " there's no question about that and there are mechanisms for doing that to", "tokens": [51248, 456, 311, 572, 1168, 466, 300, 293, 456, 366, 15902, 337, 884, 300, 281, 51396], "temperature": 0.0, "avg_logprob": -0.10711223345536453, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0005898739909753203}, {"id": 1304, "seek": 462312, "start": 4643.76, "end": 4647.44, "text": " align the systems whether it's through you know human feedback", "tokens": [51396, 7975, 264, 3652, 1968, 309, 311, 807, 291, 458, 1952, 5824, 51580], "temperature": 0.0, "avg_logprob": -0.10711223345536453, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0005898739909753203}, {"id": 1305, "seek": 462312, "start": 4647.44, "end": 4650.8, "text": " whether it's external guardrails that are providing more conventional sort of", "tokens": [51580, 1968, 309, 311, 8320, 6290, 424, 4174, 300, 366, 6530, 544, 16011, 1333, 295, 51748], "temperature": 0.0, "avg_logprob": -0.10711223345536453, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0005898739909753203}, {"id": 1306, "seek": 465080, "start": 4650.8, "end": 4654.72, "text": " checks on how things are being used that's", "tokens": [50364, 13834, 322, 577, 721, 366, 885, 1143, 300, 311, 50560], "temperature": 0.0, "avg_logprob": -0.10011932085145195, "compression_ratio": 1.755813953488372, "no_speech_prob": 0.0024589626118540764}, {"id": 1307, "seek": 465080, "start": 4654.72, "end": 4658.08, "text": " clearly necessary and I find it very encouraging that so much", "tokens": [50560, 4448, 4818, 293, 286, 915, 309, 588, 14580, 300, 370, 709, 50728], "temperature": 0.0, "avg_logprob": -0.10011932085145195, "compression_ratio": 1.755813953488372, "no_speech_prob": 0.0024589626118540764}, {"id": 1308, "seek": 465080, "start": 4658.08, "end": 4661.68, "text": " energy and effort is going into this and yes there'll be bumps in the", "tokens": [50728, 2281, 293, 4630, 307, 516, 666, 341, 293, 2086, 456, 603, 312, 27719, 294, 264, 50908], "temperature": 0.0, "avg_logprob": -0.10011932085145195, "compression_ratio": 1.755813953488372, "no_speech_prob": 0.0024589626118540764}, {"id": 1309, "seek": 465080, "start": 4661.68, "end": 4665.84, "text": " road and missteps on the way for sure but overall we seem to be heading in a", "tokens": [50908, 3060, 293, 3346, 20413, 322, 264, 636, 337, 988, 457, 4787, 321, 1643, 281, 312, 9864, 294, 257, 51116], "temperature": 0.0, "avg_logprob": -0.10011932085145195, "compression_ratio": 1.755813953488372, "no_speech_prob": 0.0024589626118540764}, {"id": 1310, "seek": 465080, "start": 4665.84, "end": 4668.96, "text": " very good direction but I think the fact that there is a lot of attention", "tokens": [51116, 588, 665, 3513, 457, 286, 519, 264, 1186, 300, 456, 307, 257, 688, 295, 3202, 51272], "temperature": 0.0, "avg_logprob": -0.10011932085145195, "compression_ratio": 1.755813953488372, "no_speech_prob": 0.0024589626118540764}, {"id": 1311, "seek": 465080, "start": 4668.96, "end": 4672.16, "text": " being paid to the potential risks associated with this", "tokens": [51272, 885, 4835, 281, 264, 3995, 10888, 6615, 365, 341, 51432], "temperature": 0.0, "avg_logprob": -0.10011932085145195, "compression_ratio": 1.755813953488372, "no_speech_prob": 0.0024589626118540764}, {"id": 1312, "seek": 465080, "start": 4672.16, "end": 4676.400000000001, "text": " very powerful and very general new technology gives me hope that we will", "tokens": [51432, 588, 4005, 293, 588, 2674, 777, 2899, 2709, 385, 1454, 300, 321, 486, 51644], "temperature": 0.0, "avg_logprob": -0.10011932085145195, "compression_ratio": 1.755813953488372, "no_speech_prob": 0.0024589626118540764}, {"id": 1313, "seek": 467640, "start": 4676.4, "end": 4681.44, "text": " avoid most of the the biggest risks. Can you give me a specific example of an", "tokens": [50364, 5042, 881, 295, 264, 264, 3880, 10888, 13, 1664, 291, 976, 385, 257, 2685, 1365, 295, 364, 50616], "temperature": 0.0, "avg_logprob": -0.1365108020970079, "compression_ratio": 1.7048611111111112, "no_speech_prob": 0.00576260918751359}, {"id": 1314, "seek": 467640, "start": 4681.44, "end": 4685.2, "text": " emulator? Yes I can so one very nice example actually", "tokens": [50616, 846, 16381, 30, 1079, 286, 393, 370, 472, 588, 1481, 1365, 767, 50804], "temperature": 0.0, "avg_logprob": -0.1365108020970079, "compression_ratio": 1.7048611111111112, "no_speech_prob": 0.00576260918751359}, {"id": 1315, "seek": 467640, "start": 4685.2, "end": 4689.36, "text": " it was the final project I worked on when I was working in the fusion program so I", "tokens": [50804, 309, 390, 264, 2572, 1716, 286, 2732, 322, 562, 286, 390, 1364, 294, 264, 23100, 1461, 370, 286, 51012], "temperature": 0.0, "avg_logprob": -0.1365108020970079, "compression_ratio": 1.7048611111111112, "no_speech_prob": 0.00576260918751359}, {"id": 1316, "seek": 467640, "start": 4689.36, "end": 4692.799999999999, "text": " was using fusion as a sort of springboard to get into machine learning", "tokens": [51012, 390, 1228, 23100, 382, 257, 1333, 295, 5587, 3787, 281, 483, 666, 3479, 2539, 51184], "temperature": 0.0, "avg_logprob": -0.1365108020970079, "compression_ratio": 1.7048611111111112, "no_speech_prob": 0.00576260918751359}, {"id": 1317, "seek": 467640, "start": 4692.799999999999, "end": 4696.719999999999, "text": " and we wanted to do real-time feedback control of a fusion experiment", "tokens": [51184, 293, 321, 1415, 281, 360, 957, 12, 3766, 5824, 1969, 295, 257, 23100, 5120, 51380], "temperature": 0.0, "avg_logprob": -0.1365108020970079, "compression_ratio": 1.7048611111111112, "no_speech_prob": 0.00576260918751359}, {"id": 1318, "seek": 467640, "start": 4696.719999999999, "end": 4699.5199999999995, "text": " I think called a tokamak very high-temperature plasma we wanted to", "tokens": [51380, 286, 519, 1219, 257, 19164, 335, 514, 588, 1090, 12, 18275, 610, 1503, 22564, 321, 1415, 281, 51520], "temperature": 0.0, "avg_logprob": -0.1365108020970079, "compression_ratio": 1.7048611111111112, "no_speech_prob": 0.00576260918751359}, {"id": 1319, "seek": 467640, "start": 4699.5199999999995, "end": 4704.48, "text": " use neural nets to do non-linear feedback so the challenge there was", "tokens": [51520, 764, 18161, 36170, 281, 360, 2107, 12, 28263, 5824, 370, 264, 3430, 456, 390, 51768], "temperature": 0.0, "avg_logprob": -0.1365108020970079, "compression_ratio": 1.7048611111111112, "no_speech_prob": 0.00576260918751359}, {"id": 1320, "seek": 470448, "start": 4704.48, "end": 4709.04, "text": " to take a plasma it's like a donut shaped ring of hot plasma", "tokens": [50364, 281, 747, 257, 22564, 309, 311, 411, 257, 33782, 13475, 4875, 295, 2368, 22564, 50592], "temperature": 0.0, "avg_logprob": -0.11147393407048406, "compression_ratio": 1.7790697674418605, "no_speech_prob": 0.0009709051228128374}, {"id": 1321, "seek": 470448, "start": 4709.04, "end": 4711.599999999999, "text": " and it was known that if you could change the cross-sectional shape you could", "tokens": [50592, 293, 309, 390, 2570, 300, 498, 291, 727, 1319, 264, 3278, 12, 11963, 304, 3909, 291, 727, 50720], "temperature": 0.0, "avg_logprob": -0.11147393407048406, "compression_ratio": 1.7790697674418605, "no_speech_prob": 0.0009709051228128374}, {"id": 1322, "seek": 470448, "start": 4711.599999999999, "end": 4714.639999999999, "text": " improve its performance so there's an experiment called a compass compact", "tokens": [50720, 3470, 1080, 3389, 370, 456, 311, 364, 5120, 1219, 257, 10707, 14679, 50872], "temperature": 0.0, "avg_logprob": -0.11147393407048406, "compression_ratio": 1.7790697674418605, "no_speech_prob": 0.0009709051228128374}, {"id": 1323, "seek": 470448, "start": 4714.639999999999, "end": 4717.12, "text": " assembly at Cullum in in Oxfordshire and the", "tokens": [50872, 12103, 412, 383, 858, 449, 294, 294, 24786, 22294, 293, 264, 50996], "temperature": 0.0, "avg_logprob": -0.11147393407048406, "compression_ratio": 1.7790697674418605, "no_speech_prob": 0.0009709051228128374}, {"id": 1324, "seek": 470448, "start": 4717.12, "end": 4721.12, "text": " experiment's designed to produce very interesting exotic cross-sectional", "tokens": [50996, 5120, 311, 4761, 281, 5258, 588, 1880, 27063, 3278, 12, 11963, 304, 51196], "temperature": 0.0, "avg_logprob": -0.11147393407048406, "compression_ratio": 1.7790697674418605, "no_speech_prob": 0.0009709051228128374}, {"id": 1325, "seek": 470448, "start": 4721.12, "end": 4724.32, "text": " shapes to to explore the performance so we wanted to use a neural net to do that", "tokens": [51196, 10854, 281, 281, 6839, 264, 3389, 370, 321, 1415, 281, 764, 257, 18161, 2533, 281, 360, 300, 51356], "temperature": 0.0, "avg_logprob": -0.11147393407048406, "compression_ratio": 1.7790697674418605, "no_speech_prob": 0.0009709051228128374}, {"id": 1326, "seek": 470448, "start": 4724.32, "end": 4727.36, "text": " feedback control. Now the good news is we had a great", "tokens": [51356, 5824, 1969, 13, 823, 264, 665, 2583, 307, 321, 632, 257, 869, 51508], "temperature": 0.0, "avg_logprob": -0.11147393407048406, "compression_ratio": 1.7790697674418605, "no_speech_prob": 0.0009709051228128374}, {"id": 1327, "seek": 470448, "start": 4727.36, "end": 4730.5599999999995, "text": " piece of inductive bias I think called the grad shafranoff equation it's a", "tokens": [51508, 2522, 295, 31612, 488, 12577, 286, 519, 1219, 264, 2771, 402, 2792, 81, 3730, 602, 5367, 309, 311, 257, 51668], "temperature": 0.0, "avg_logprob": -0.11147393407048406, "compression_ratio": 1.7790697674418605, "no_speech_prob": 0.0009709051228128374}, {"id": 1328, "seek": 470448, "start": 4730.5599999999995, "end": 4733.599999999999, "text": " second-order elliptic partial differential equation but the point is it", "tokens": [51668, 1150, 12, 4687, 8284, 22439, 299, 14641, 15756, 5367, 457, 264, 935, 307, 309, 51820], "temperature": 0.0, "avg_logprob": -0.11147393407048406, "compression_ratio": 1.7790697674418605, "no_speech_prob": 0.0009709051228128374}, {"id": 1329, "seek": 473360, "start": 4733.6, "end": 4738.320000000001, "text": " describes the boundary of the plasma very accurately right so you make a bunch", "tokens": [50364, 15626, 264, 12866, 295, 264, 22564, 588, 20095, 558, 370, 291, 652, 257, 3840, 50600], "temperature": 0.0, "avg_logprob": -0.08398276242342863, "compression_ratio": 1.9407114624505928, "no_speech_prob": 0.00046181867946870625}, {"id": 1330, "seek": 473360, "start": 4738.320000000001, "end": 4741.52, "text": " of measurements from hundreds of little pickup coils around the plasma", "tokens": [50600, 295, 15383, 490, 6779, 295, 707, 25328, 43639, 926, 264, 22564, 50760], "temperature": 0.0, "avg_logprob": -0.08398276242342863, "compression_ratio": 1.9407114624505928, "no_speech_prob": 0.00046181867946870625}, {"id": 1331, "seek": 473360, "start": 4741.52, "end": 4744.56, "text": " and those are boundary conditions you solve the grad shafranoff equation you", "tokens": [50760, 293, 729, 366, 12866, 4487, 291, 5039, 264, 2771, 402, 2792, 81, 3730, 602, 5367, 291, 50912], "temperature": 0.0, "avg_logprob": -0.08398276242342863, "compression_ratio": 1.9407114624505928, "no_speech_prob": 0.00046181867946870625}, {"id": 1332, "seek": 473360, "start": 4744.56, "end": 4747.4400000000005, "text": " know the shape of the plasma and the goal was to", "tokens": [50912, 458, 264, 3909, 295, 264, 22564, 293, 264, 3387, 390, 281, 51056], "temperature": 0.0, "avg_logprob": -0.08398276242342863, "compression_ratio": 1.9407114624505928, "no_speech_prob": 0.00046181867946870625}, {"id": 1333, "seek": 473360, "start": 4747.4400000000005, "end": 4751.120000000001, "text": " decide ahead of the time that you wanted to create a circular plasma", "tokens": [51056, 4536, 2286, 295, 264, 565, 300, 291, 1415, 281, 1884, 257, 16476, 22564, 51240], "temperature": 0.0, "avg_logprob": -0.08398276242342863, "compression_ratio": 1.9407114624505928, "no_speech_prob": 0.00046181867946870625}, {"id": 1334, "seek": 473360, "start": 4751.120000000001, "end": 4756.64, "text": " and then change its shape and and and then make corrections if the shape", "tokens": [51240, 293, 550, 1319, 1080, 3909, 293, 293, 293, 550, 652, 36406, 498, 264, 3909, 51516], "temperature": 0.0, "avg_logprob": -0.08398276242342863, "compression_ratio": 1.9407114624505928, "no_speech_prob": 0.00046181867946870625}, {"id": 1335, "seek": 473360, "start": 4756.64, "end": 4759.84, "text": " wasn't quite the one you wanted you would change the the big control coil", "tokens": [51516, 2067, 380, 1596, 264, 472, 291, 1415, 291, 576, 1319, 264, 264, 955, 1969, 22225, 51676], "temperature": 0.0, "avg_logprob": -0.08398276242342863, "compression_ratio": 1.9407114624505928, "no_speech_prob": 0.00046181867946870625}, {"id": 1336, "seek": 475984, "start": 4759.84, "end": 4764.400000000001, "text": " currents and an alternate shape. The problem was the grad shafranoff equation", "tokens": [50364, 30110, 293, 364, 18873, 3909, 13, 440, 1154, 390, 264, 2771, 402, 2792, 81, 3730, 602, 5367, 50592], "temperature": 0.0, "avg_logprob": -0.1297219785532557, "compression_ratio": 1.7629870129870129, "no_speech_prob": 0.0009477624553255737}, {"id": 1337, "seek": 475984, "start": 4764.400000000001, "end": 4767.84, "text": " on a state-of-the-art workstation of the day would take two or three minutes to", "tokens": [50592, 322, 257, 1785, 12, 2670, 12, 3322, 12, 446, 589, 19159, 295, 264, 786, 576, 747, 732, 420, 1045, 2077, 281, 50764], "temperature": 0.0, "avg_logprob": -0.1297219785532557, "compression_ratio": 1.7629870129870129, "no_speech_prob": 0.0009477624553255737}, {"id": 1338, "seek": 475984, "start": 4767.84, "end": 4770.96, "text": " solve whereas we had to do feedback on a sort of 20", "tokens": [50764, 5039, 9735, 321, 632, 281, 360, 5824, 322, 257, 1333, 295, 945, 50920], "temperature": 0.0, "avg_logprob": -0.1297219785532557, "compression_ratio": 1.7629870129870129, "no_speech_prob": 0.0009477624553255737}, {"id": 1339, "seek": 475984, "start": 4770.96, "end": 4774.0, "text": " kilohertz frequency or something it was about something like six orders of", "tokens": [50920, 21112, 35655, 7893, 420, 746, 309, 390, 466, 746, 411, 2309, 9470, 295, 51072], "temperature": 0.0, "avg_logprob": -0.1297219785532557, "compression_ratio": 1.7629870129870129, "no_speech_prob": 0.0009477624553255737}, {"id": 1340, "seek": 475984, "start": 4774.0, "end": 4777.92, "text": " magnitude too slow so what we did instead was we we solved the", "tokens": [51072, 15668, 886, 2964, 370, 437, 321, 630, 2602, 390, 321, 321, 13041, 264, 51268], "temperature": 0.0, "avg_logprob": -0.1297219785532557, "compression_ratio": 1.7629870129870129, "no_speech_prob": 0.0009477624553255737}, {"id": 1341, "seek": 475984, "start": 4777.92, "end": 4782.0, "text": " grad shafranoff equation many times on the on the workstation", "tokens": [51268, 2771, 402, 2792, 81, 3730, 602, 5367, 867, 1413, 322, 264, 322, 264, 589, 19159, 51472], "temperature": 0.0, "avg_logprob": -0.1297219785532557, "compression_ratio": 1.7629870129870129, "no_speech_prob": 0.0009477624553255737}, {"id": 1342, "seek": 475984, "start": 4782.0, "end": 4786.0, "text": " over a period of you know days and weeks until we built up a large database", "tokens": [51472, 670, 257, 2896, 295, 291, 458, 1708, 293, 3259, 1826, 321, 3094, 493, 257, 2416, 8149, 51672], "temperature": 0.0, "avg_logprob": -0.1297219785532557, "compression_ratio": 1.7629870129870129, "no_speech_prob": 0.0009477624553255737}, {"id": 1343, "seek": 475984, "start": 4786.0, "end": 4789.52, "text": " of known solutions along with their magnetic measurements", "tokens": [51672, 295, 2570, 6547, 2051, 365, 641, 12688, 15383, 51848], "temperature": 0.0, "avg_logprob": -0.1297219785532557, "compression_ratio": 1.7629870129870129, "no_speech_prob": 0.0009477624553255737}, {"id": 1344, "seek": 478952, "start": 4789.52, "end": 4792.64, "text": " and then we trained a neural network just a simple two-layer neural network", "tokens": [50364, 293, 550, 321, 8895, 257, 18161, 3209, 445, 257, 2199, 732, 12, 8376, 260, 18161, 3209, 50520], "temperature": 0.0, "avg_logprob": -0.08964395164547109, "compression_ratio": 1.838187702265372, "no_speech_prob": 0.0003391097125131637}, {"id": 1345, "seek": 478952, "start": 4792.64, "end": 4796.240000000001, "text": " back in the day with probably only a few thousand parameters i mean", "tokens": [50520, 646, 294, 264, 786, 365, 1391, 787, 257, 1326, 4714, 9834, 741, 914, 50700], "temperature": 0.0, "avg_logprob": -0.08964395164547109, "compression_ratio": 1.838187702265372, "no_speech_prob": 0.0003391097125131637}, {"id": 1346, "seek": 478952, "start": 4796.240000000001, "end": 4799.4400000000005, "text": " miniscule by modern standards but it was trained to take the magnetic", "tokens": [50700, 923, 5606, 2271, 538, 4363, 7787, 457, 309, 390, 8895, 281, 747, 264, 12688, 50860], "temperature": 0.0, "avg_logprob": -0.08964395164547109, "compression_ratio": 1.838187702265372, "no_speech_prob": 0.0003391097125131637}, {"id": 1347, "seek": 478952, "start": 4799.4400000000005, "end": 4802.240000000001, "text": " measurements and predict the shape and we could put that into a standard", "tokens": [50860, 15383, 293, 6069, 264, 3909, 293, 321, 727, 829, 300, 666, 257, 3832, 51000], "temperature": 0.0, "avg_logprob": -0.08964395164547109, "compression_ratio": 1.838187702265372, "no_speech_prob": 0.0003391097125131637}, {"id": 1348, "seek": 478952, "start": 4802.240000000001, "end": 4806.0, "text": " feedback loop and and we're in a bit of a race with", "tokens": [51000, 5824, 6367, 293, 293, 321, 434, 294, 257, 857, 295, 257, 4569, 365, 51188], "temperature": 0.0, "avg_logprob": -0.08964395164547109, "compression_ratio": 1.838187702265372, "no_speech_prob": 0.0003391097125131637}, {"id": 1349, "seek": 478952, "start": 4806.0, "end": 4809.120000000001, "text": " another organization that was doing a similar thing a different fusion lab", "tokens": [51188, 1071, 4475, 300, 390, 884, 257, 2531, 551, 257, 819, 23100, 2715, 51344], "temperature": 0.0, "avg_logprob": -0.08964395164547109, "compression_ratio": 1.838187702265372, "no_speech_prob": 0.0003391097125131637}, {"id": 1350, "seek": 478952, "start": 4809.120000000001, "end": 4813.120000000001, "text": " that was working on the same project and so that was very motivating and i'm", "tokens": [51344, 300, 390, 1364, 322, 264, 912, 1716, 293, 370, 300, 390, 588, 41066, 293, 741, 478, 51544], "temperature": 0.0, "avg_logprob": -0.08964395164547109, "compression_ratio": 1.838187702265372, "no_speech_prob": 0.0003391097125131637}, {"id": 1351, "seek": 478952, "start": 4813.120000000001, "end": 4816.160000000001, "text": " pleased to say we got there first and we did the world's first ever real-time", "tokens": [51544, 10587, 281, 584, 321, 658, 456, 700, 293, 321, 630, 264, 1002, 311, 700, 1562, 957, 12, 3766, 51696], "temperature": 0.0, "avg_logprob": -0.08964395164547109, "compression_ratio": 1.838187702265372, "no_speech_prob": 0.0003391097125131637}, {"id": 1352, "seek": 481616, "start": 4816.24, "end": 4820.16, "text": " feedback control of a tokamak plasma using a neural network", "tokens": [50368, 5824, 1969, 295, 257, 19164, 335, 514, 22564, 1228, 257, 18161, 3209, 50564], "temperature": 0.0, "avg_logprob": -0.07622955001403238, "compression_ratio": 1.84, "no_speech_prob": 0.005295572802424431}, {"id": 1353, "seek": 481616, "start": 4820.16, "end": 4823.92, "text": " but as a beautiful example of a of an emulator we could get five or six orders", "tokens": [50564, 457, 382, 257, 2238, 1365, 295, 257, 295, 364, 846, 16381, 321, 727, 483, 1732, 420, 2309, 9470, 50752], "temperature": 0.0, "avg_logprob": -0.07622955001403238, "compression_ratio": 1.84, "no_speech_prob": 0.005295572802424431}, {"id": 1354, "seek": 481616, "start": 4823.92, "end": 4827.92, "text": " of magnitude speed up not by solving the equation directly", "tokens": [50752, 295, 15668, 3073, 493, 406, 538, 12606, 264, 5367, 3838, 50952], "temperature": 0.0, "avg_logprob": -0.07622955001403238, "compression_ratio": 1.84, "no_speech_prob": 0.005295572802424431}, {"id": 1355, "seek": 481616, "start": 4827.92, "end": 4832.639999999999, "text": " to do feedback control but by using the numerical solver to generate training", "tokens": [50952, 281, 360, 5824, 1969, 457, 538, 1228, 264, 29054, 1404, 331, 281, 8460, 3097, 51188], "temperature": 0.0, "avg_logprob": -0.07622955001403238, "compression_ratio": 1.84, "no_speech_prob": 0.005295572802424431}, {"id": 1356, "seek": 481616, "start": 4832.639999999999, "end": 4835.36, "text": " data and using the training data to train the emulator", "tokens": [51188, 1412, 293, 1228, 264, 3097, 1412, 281, 3847, 264, 846, 16381, 51324], "temperature": 0.0, "avg_logprob": -0.07622955001403238, "compression_ratio": 1.84, "no_speech_prob": 0.005295572802424431}, {"id": 1357, "seek": 481616, "start": 4835.36, "end": 4838.5599999999995, "text": " and then the emulator and even then it was still", "tokens": [51324, 293, 550, 264, 846, 16381, 293, 754, 550, 309, 390, 920, 51484], "temperature": 0.0, "avg_logprob": -0.07622955001403238, "compression_ratio": 1.84, "no_speech_prob": 0.005295572802424431}, {"id": 1358, "seek": 481616, "start": 4838.5599999999995, "end": 4842.96, "text": " quite demanding for the silicon of the day there was no processor fast enough so", "tokens": [51484, 1596, 19960, 337, 264, 22848, 295, 264, 786, 456, 390, 572, 15321, 2370, 1547, 370, 51704], "temperature": 0.0, "avg_logprob": -0.07622955001403238, "compression_ratio": 1.84, "no_speech_prob": 0.005295572802424431}, {"id": 1359, "seek": 484296, "start": 4842.96, "end": 4846.56, "text": " we actually built a physical implementation of the", "tokens": [50364, 321, 767, 3094, 257, 4001, 11420, 295, 264, 50544], "temperature": 0.0, "avg_logprob": -0.10018614103209297, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.000473781896289438}, {"id": 1360, "seek": 484296, "start": 4846.56, "end": 4850.08, "text": " neural net believe it or not so it was a hybrid", "tokens": [50544, 18161, 2533, 1697, 309, 420, 406, 370, 309, 390, 257, 13051, 50720], "temperature": 0.0, "avg_logprob": -0.10018614103209297, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.000473781896289438}, {"id": 1361, "seek": 484296, "start": 4850.08, "end": 4854.0, "text": " analog digital system had an analog signal pathway with analog", "tokens": [50720, 16660, 4562, 1185, 632, 364, 16660, 6358, 18590, 365, 16660, 50916], "temperature": 0.0, "avg_logprob": -0.10018614103209297, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.000473781896289438}, {"id": 1362, "seek": 484296, "start": 4854.0, "end": 4857.52, "text": " sigmoidal units but the weights were set using digitally set", "tokens": [50916, 4556, 3280, 22151, 6815, 457, 264, 17443, 645, 992, 1228, 36938, 992, 51092], "temperature": 0.0, "avg_logprob": -0.10018614103209297, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.000473781896289438}, {"id": 1363, "seek": 484296, "start": 4857.52, "end": 4860.4, "text": " resistors so we could take the numerical output of the the emulator", "tokens": [51092, 4597, 830, 370, 321, 727, 747, 264, 29054, 5598, 295, 264, 264, 846, 16381, 51236], "temperature": 0.0, "avg_logprob": -0.10018614103209297, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.000473781896289438}, {"id": 1364, "seek": 484296, "start": 4860.4, "end": 4864.96, "text": " downloaded into this bespoke hardware physical neural network", "tokens": [51236, 21748, 666, 341, 4097, 48776, 8837, 4001, 18161, 3209, 51464], "temperature": 0.0, "avg_logprob": -0.10018614103209297, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.000473781896289438}, {"id": 1365, "seek": 484296, "start": 4864.96, "end": 4867.92, "text": " and do real-time feedback control so i was pretty pretty excited about that", "tokens": [51464, 293, 360, 957, 12, 3766, 5824, 1969, 370, 741, 390, 1238, 1238, 2919, 466, 300, 51612], "temperature": 0.0, "avg_logprob": -0.10018614103209297, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.000473781896289438}, {"id": 1366, "seek": 484296, "start": 4867.92, "end": 4871.44, "text": " project that's fascinating what do you think about", "tokens": [51612, 1716, 300, 311, 10343, 437, 360, 291, 519, 466, 51788], "temperature": 0.0, "avg_logprob": -0.10018614103209297, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.000473781896289438}, {"id": 1367, "seek": 487144, "start": 4871.44, "end": 4875.5199999999995, "text": " control now do you have any opinions on you know model predictive control and", "tokens": [50364, 1969, 586, 360, 291, 362, 604, 11819, 322, 291, 458, 2316, 35521, 1969, 293, 50568], "temperature": 0.0, "avg_logprob": -0.12557742330763075, "compression_ratio": 1.796875, "no_speech_prob": 0.0038846118841320276}, {"id": 1368, "seek": 487144, "start": 4875.5199999999995, "end": 4879.28, "text": " control is a super important area different both the both the control", "tokens": [50568, 1969, 307, 257, 1687, 1021, 1859, 819, 1293, 264, 1293, 264, 1969, 50756], "temperature": 0.0, "avg_logprob": -0.12557742330763075, "compression_ratio": 1.796875, "no_speech_prob": 0.0038846118841320276}, {"id": 1369, "seek": 487144, "start": 4879.28, "end": 4882.5599999999995, "text": " problem and the overall planning problem i think", "tokens": [50756, 1154, 293, 264, 4787, 5038, 1154, 741, 519, 50920], "temperature": 0.0, "avg_logprob": -0.12557742330763075, "compression_ratio": 1.796875, "no_speech_prob": 0.0038846118841320276}, {"id": 1370, "seek": 487144, "start": 4882.5599999999995, "end": 4886.4, "text": " despite all the remarkable advances in gbt4 the world of instantiated", "tokens": [50920, 7228, 439, 264, 12802, 25297, 294, 290, 4517, 19, 264, 1002, 295, 9836, 72, 770, 51112], "temperature": 0.0, "avg_logprob": -0.12557742330763075, "compression_ratio": 1.796875, "no_speech_prob": 0.0038846118841320276}, {"id": 1371, "seek": 487144, "start": 4886.4, "end": 4890.96, "text": " ai and robotics and so on is still a very very wide open frontier", "tokens": [51112, 9783, 293, 34145, 293, 370, 322, 307, 920, 257, 588, 588, 4874, 1269, 35853, 51340], "temperature": 0.0, "avg_logprob": -0.12557742330763075, "compression_ratio": 1.796875, "no_speech_prob": 0.0038846118841320276}, {"id": 1372, "seek": 487144, "start": 4890.96, "end": 4895.04, "text": " we don't we don't really have robots that can even yet drive a car through", "tokens": [51340, 321, 500, 380, 321, 500, 380, 534, 362, 14733, 300, 393, 754, 1939, 3332, 257, 1032, 807, 51544], "temperature": 0.0, "avg_logprob": -0.12557742330763075, "compression_ratio": 1.796875, "no_speech_prob": 0.0038846118841320276}, {"id": 1373, "seek": 487144, "start": 4895.04, "end": 4898.719999999999, "text": " central london that's still a a major challenge that", "tokens": [51544, 5777, 287, 684, 266, 300, 311, 920, 257, 257, 2563, 3430, 300, 51728], "temperature": 0.0, "avg_logprob": -0.12557742330763075, "compression_ratio": 1.796875, "no_speech_prob": 0.0038846118841320276}, {"id": 1374, "seek": 489872, "start": 4898.72, "end": 4901.280000000001, "text": " we're seeing some very remarkable progress recently", "tokens": [50364, 321, 434, 2577, 512, 588, 12802, 4205, 3938, 50492], "temperature": 0.0, "avg_logprob": -0.08541831349938865, "compression_ratio": 1.826086956521739, "no_speech_prob": 0.006211362779140472}, {"id": 1375, "seek": 489872, "start": 4901.280000000001, "end": 4905.12, "text": " yeah i mean more broadly i've been speaking with some neuroscientists and", "tokens": [50492, 1338, 741, 914, 544, 19511, 741, 600, 668, 4124, 365, 512, 28813, 5412, 1751, 293, 50684], "temperature": 0.0, "avg_logprob": -0.08541831349938865, "compression_ratio": 1.826086956521739, "no_speech_prob": 0.006211362779140472}, {"id": 1376, "seek": 489872, "start": 4905.12, "end": 4908.320000000001, "text": " they say that we have the matrix in in our heads so we're always running", "tokens": [50684, 436, 584, 300, 321, 362, 264, 8141, 294, 294, 527, 8050, 370, 321, 434, 1009, 2614, 50844], "temperature": 0.0, "avg_logprob": -0.08541831349938865, "compression_ratio": 1.826086956521739, "no_speech_prob": 0.006211362779140472}, {"id": 1377, "seek": 489872, "start": 4908.320000000001, "end": 4912.16, "text": " simulations and presumably in the future this will be a", "tokens": [50844, 35138, 293, 26742, 294, 264, 2027, 341, 486, 312, 257, 51036], "temperature": 0.0, "avg_logprob": -0.08541831349938865, "compression_ratio": 1.826086956521739, "no_speech_prob": 0.006211362779140472}, {"id": 1378, "seek": 489872, "start": 4912.16, "end": 4915.68, "text": " principled way of building agents so the agents will run", "tokens": [51036, 3681, 15551, 636, 295, 2390, 12554, 370, 264, 12554, 486, 1190, 51212], "temperature": 0.0, "avg_logprob": -0.08541831349938865, "compression_ratio": 1.826086956521739, "no_speech_prob": 0.006211362779140472}, {"id": 1379, "seek": 489872, "start": 4915.68, "end": 4919.76, "text": " counterfactual simulations and select trajectories which look like good ones", "tokens": [51212, 5682, 44919, 901, 35138, 293, 3048, 18257, 2083, 597, 574, 411, 665, 2306, 51416], "temperature": 0.0, "avg_logprob": -0.08541831349938865, "compression_ratio": 1.826086956521739, "no_speech_prob": 0.006211362779140472}, {"id": 1380, "seek": 489872, "start": 4919.76, "end": 4923.6, "text": " and then the process will will iterate i think this is this is very powerful i", "tokens": [51416, 293, 550, 264, 1399, 486, 486, 44497, 741, 519, 341, 307, 341, 307, 588, 4005, 741, 51608], "temperature": 0.0, "avg_logprob": -0.08541831349938865, "compression_ratio": 1.826086956521739, "no_speech_prob": 0.006211362779140472}, {"id": 1381, "seek": 489872, "start": 4923.6, "end": 4927.04, "text": " mean the the idea of sort of type one and type two fast learning slow learning", "tokens": [51608, 914, 264, 264, 1558, 295, 1333, 295, 2010, 472, 293, 2010, 732, 2370, 2539, 2964, 2539, 51780], "temperature": 0.0, "avg_logprob": -0.08541831349938865, "compression_ratio": 1.826086956521739, "no_speech_prob": 0.006211362779140472}, {"id": 1382, "seek": 492704, "start": 4927.04, "end": 4929.84, "text": " the idea that we simulate the world and we compare the simulation with the", "tokens": [50364, 264, 1558, 300, 321, 27817, 264, 1002, 293, 321, 6794, 264, 16575, 365, 264, 50504], "temperature": 0.0, "avg_logprob": -0.05269825458526611, "compression_ratio": 1.9646302250803858, "no_speech_prob": 0.00679810019209981}, {"id": 1383, "seek": 492704, "start": 4929.84, "end": 4932.56, "text": " reality and we can learn from our own simulators and so on", "tokens": [50504, 4103, 293, 321, 393, 1466, 490, 527, 1065, 1034, 39265, 293, 370, 322, 50640], "temperature": 0.0, "avg_logprob": -0.05269825458526611, "compression_ratio": 1.9646302250803858, "no_speech_prob": 0.00679810019209981}, {"id": 1384, "seek": 492704, "start": 4932.56, "end": 4936.0, "text": " we don't we don't quite know what best to do with that but it feels such a", "tokens": [50640, 321, 500, 380, 321, 500, 380, 1596, 458, 437, 1151, 281, 360, 365, 300, 457, 309, 3417, 1270, 257, 50812], "temperature": 0.0, "avg_logprob": -0.05269825458526611, "compression_ratio": 1.9646302250803858, "no_speech_prob": 0.00679810019209981}, {"id": 1385, "seek": 492704, "start": 4936.0, "end": 4939.36, "text": " powerful and compelling concept and we we think something like that is going on", "tokens": [50812, 4005, 293, 20050, 3410, 293, 321, 321, 519, 746, 411, 300, 307, 516, 322, 50980], "temperature": 0.0, "avg_logprob": -0.05269825458526611, "compression_ratio": 1.9646302250803858, "no_speech_prob": 0.00679810019209981}, {"id": 1386, "seek": 492704, "start": 4939.36, "end": 4941.76, "text": " in the brain that again that feels like a", "tokens": [50980, 294, 264, 3567, 300, 797, 300, 3417, 411, 257, 51100], "temperature": 0.0, "avg_logprob": -0.05269825458526611, "compression_ratio": 1.9646302250803858, "no_speech_prob": 0.00679810019209981}, {"id": 1387, "seek": 492704, "start": 4941.76, "end": 4945.36, "text": " an area that's ripe for exploration and i think in some form", "tokens": [51100, 364, 1859, 300, 311, 31421, 337, 16197, 293, 741, 519, 294, 512, 1254, 51280], "temperature": 0.0, "avg_logprob": -0.05269825458526611, "compression_ratio": 1.9646302250803858, "no_speech_prob": 0.00679810019209981}, {"id": 1388, "seek": 492704, "start": 4945.36, "end": 4949.12, "text": " some kind of you know model prediction and simulation of the world feels like", "tokens": [51280, 512, 733, 295, 291, 458, 2316, 17630, 293, 16575, 295, 264, 1002, 3417, 411, 51468], "temperature": 0.0, "avg_logprob": -0.05269825458526611, "compression_ratio": 1.9646302250803858, "no_speech_prob": 0.00679810019209981}, {"id": 1389, "seek": 492704, "start": 4949.12, "end": 4953.12, "text": " it will be increasingly a part of ai systems as we go forward", "tokens": [51468, 309, 486, 312, 12980, 257, 644, 295, 9783, 3652, 382, 321, 352, 2128, 51668], "temperature": 0.0, "avg_logprob": -0.05269825458526611, "compression_ratio": 1.9646302250803858, "no_speech_prob": 0.00679810019209981}, {"id": 1390, "seek": 492704, "start": 4953.12, "end": 4956.48, "text": " i mean for me the takeaway in all of this is just what an amazing time to be in", "tokens": [51668, 741, 914, 337, 385, 264, 30681, 294, 439, 295, 341, 307, 445, 437, 364, 2243, 565, 281, 312, 294, 51836], "temperature": 0.0, "avg_logprob": -0.05269825458526611, "compression_ratio": 1.9646302250803858, "no_speech_prob": 0.00679810019209981}, {"id": 1391, "seek": 495648, "start": 4956.48, "end": 4959.04, "text": " this field there are so many fascinating things to work on", "tokens": [50364, 341, 2519, 456, 366, 370, 867, 10343, 721, 281, 589, 322, 50492], "temperature": 0.0, "avg_logprob": -0.19484763675265843, "compression_ratio": 1.4596774193548387, "no_speech_prob": 0.02297591045498848}, {"id": 1392, "seek": 495648, "start": 4959.04, "end": 4962.08, "text": " professor bishop it's been an honor to have you on mlst thank you so much", "tokens": [50492, 8304, 34470, 309, 311, 668, 364, 5968, 281, 362, 291, 322, 23271, 372, 1309, 291, 370, 709, 50644], "temperature": 0.0, "avg_logprob": -0.19484763675265843, "compression_ratio": 1.4596774193548387, "no_speech_prob": 0.02297591045498848}, {"id": 1393, "seek": 495648, "start": 4962.08, "end": 4966.48, "text": " well thank you i've enjoyed it thank you amazing", "tokens": [50644, 731, 1309, 291, 741, 600, 4626, 309, 1309, 291, 2243, 50864], "temperature": 0.0, "avg_logprob": -0.19484763675265843, "compression_ratio": 1.4596774193548387, "no_speech_prob": 0.02297591045498848}], "language": "en"}