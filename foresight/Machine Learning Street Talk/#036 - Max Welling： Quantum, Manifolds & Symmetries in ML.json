{"text": " Qualcomm AI Research is hiring for several machine learning openings, so please check out their careers website if you're excited about solving the biggest problems with cutting edge AI research and improving the lives of billions of people. Today we got to speak with one of our heroes in machine learning, Professor Max Welling. It was good, the questions were really fantastic actually and I've never done this with the three of you but having a team of three people asking questions is really, it's a good idea and of course you're really smart people knowing what you're talking about so that went really well I think. Needs three brains to match yours. We asked Max some of your favorite questions from Reddit. Hi Max, when will you be changing your last name to pooling? Max has pioneered the discipline of non-euclidean geometric deep learning. So what is actually geometric deep learning? It's the idea of performing deep learning or machine learning more generally but let's say deep learning on data that is not euclidean in some sense so not a nice chain structure for audio or a planar structure for images but perhaps a sphere or graph or something more exotic like some kind of manifold with arbitrary curvature. You might want to model weather patterns or social interaction data. There are many types of data out there that are non-euclidean. Actually if you've been playing with graph neural networks then you've already been doing non-euclidean or geometric deep learning. So to make this work you just need to abstract some concepts so the euclidean distance or your neighborhood it becomes a function of connectedness just like on a social graph. Am I connected to John? Does John know Bob? Simple as that. Actually this kind of abstraction works in many areas of mathematics which Max will get into today as well as making neural networks work on non-euclidean data. The other thing that Max has really pioneered is this idea of recognizing symmetries in different manifolds. So in this blank slate paradigm that we have now in neural networks we're essentially wasting the representational capacity of the neural network because we're just learning the same thing again and again. For example in a fully connected neural network we would have to learn the dog in the top right corner and the top left corner because there's no translational symmetry. And it was exactly this reason why convolutional neural networks were so powerful because they introduced this concept of translational weight sharing. So you had this filter that you could shine over the entire planar manifold and it meant that those parameters could be reused and you could learn concepts in different parts of the visual field. It was an incredible breakthrough. Imputing this kind of knowledge into a deep learning model this is called an inductive prior. It means that we can take some prior knowledge about how things in the world works and we can impute them into our models. It makes our models more sample efficient and it makes them generalize better. When it comes to sophisticated inductive priors Max Welling is the king. When we think about AI and its capability to actually help us to enrich our lives we know we need to first help machines see and understand like humans do. Take this drone collecting data in 3D or this autonomous vehicle with cameras covering a 360 degrees view. Current deep learning technology can analyze 2D images very well. But how can we teach a machine to make sense of image data from a curved object like a sphere? And because we want this processing to happen on the device itself for reliability, immediacy and privacy reasons how can we achieve this in a power efficient manner? It turns out we can do this by applying the mathematics behind general relativity and quantum field theory to deep learning. Our neural network takes in data on virtually any kind of curved object and applies a new type of convolution to it. We can move the shape around and the AI will still recognize it. This is just one example of the exciting research we're doing at Falkamea research to shape AI in the near future. Anyway it turns out that these symmetries are absolutely everywhere. If you wanted any further proof of how useful these kind of equivariants and symmetries and manifolds can be, look no further than the recent announcement from DeepMind AlphaFold. It will change everything. DeepMind solves 50 year old grand challenge. The game has changed. So proteins are the structures that fold in a given way. The result of this year's competition came out and they looked something like this. Namely every entry here you see is a team participating in that competition of protein folding prediction and there is one team which is DeepMind's system AlphaFold 2 which completely dominates all the others to the point where the problem is now considered to be solved. By the way if this is not a great meme template I don't know what is. Just saying. Just saying. They say a folded protein can be thought of as a spatial graph. This here attention-based okay. So I'm going to guess for sure that they've replaced this convet with a transformer style with an attention layer or multiple attention layers. I would guess this is a big transformer right here. So there was a really interesting article that came out called AlphaFold and Equivariance by Justas Duparas and Fabian Fuchs. I'm so sorry Fabian I don't know how to pronounce your name but it does sound like a swear word. Justas and Fabian Etow comment on the announcement from DeepMind and they said in short this module is a neural network that iteratively refines the structure predictions while respecting and leveraging an important symmetry of the problem. Namely that of rototranslations. At this point DeepMind has not yet published a paper so we don't know exactly how they address this. However from their presentations it seems possible that part of their architecture is similar to the SE3 transformer. What's the SE3 transformer? Lo and behold our friend Max Welling has had his hands all over it. So in the abstract it says the SE3 transformer a variant of the self-attention module for 3d point clouds and graphs which is equivariant under continuous 3d rototranslations. Equivariant is important to ensure stable and predictable performance in the presence of nuisance transformations of the data input. Right by the way you might be wondering what SE3 is. Let's have a quick look at the Wikipedia page. We are getting into group theory which is quite an abstract concept in mathematics but the Euclidean group which is SE3 it talks about all of the symmetries or the group transformations that can be applied to Euclidean data to preserve certain properties. Namely let's say the Euclidean distance between two points. Well these are things like translations and rotations and reflections. Very interesting that you can kind of abstract one level up in mathematics and that's what group theory is. The other comment I want to make is that all of these folks are independently amazing. I've watched presentations by most of them so that there's Fabian Fuchs, Daniel Worrell, Volker Fischer, fantastic. By the way when we look at Fabian's About Me page he's a machine learning PhD student at Oxford University. His research topic is learning invariant representations. Simply put where most of deep learning is concerned with finding the important information in an input he focuses on ignoring harmful or irrelevant parts of information. This can be important to counteract biases or to better leverage structure in the data. Structure in the data that's interesting. That's quite a cool point actually because if you think about it you could naively if you're doing a vision classifier you could naively just look at all of the pixels and what they are or if you're being smart about it you go one level up and you look for the hidden structure in the data and that is precisely what he's talking about things like the symmetries that are inherent in pretty much every type of data. Okay so one last thing DeepMind released an official PowerPoint deck on Alpha Fold 2 and it talks about they're on a long term mission to advance scientific progress. Now here are some of the protein examples. Now they specifically call out inductive biases for deep learning models where this is exactly what we're talking about so clearly convolutional neural networks are one such bias which has the translational weight sharing. It talks about graph networks and recurrent networks and indeed attention networks which is very much a generalisation of pretty much all of the others. They say that they are putting their protein knowledge into the model so physical insights are built into the network structure not just the process around it and these biases reflected their knowledge of protein physics and geometry and you can see here that there are residues in a protein so they're modelling topologically which residues are connected to which other residues in this kind of 3d space. They specifically call out here on the structure model page that they are building a 3d equivariant transformer architecture so anyway if this doesn't motivate you that symmetries and manifolds are an exciting idea in deep learning I don't know what will. So clearly Max has been in this game for a long time now back in 2004 with Kingma he invented the variational Bayes auto encoder. It's only recently that well relatively recently that Max has been focusing in on deep learning. Clearly like any other field also machine learning is subject to fashion right and so if there is a five to ten year cycles where people get really excited about a certain topic either because the theory is very beautiful or it just works really well. I started in biographical models and independent components analysis was the talk of the day and the support vector machines and basically non-parametric methods and then came Bayesian methods and non-parametric Bayesian methods and now it's all about deep learning. So what you see is that the field is subject to these sort of fashions and I think it's fine because we zoom in a new very promising tool and then we work it out and we get the most out of it. Max is a vice president at Qualcomm so clearly he thinks that computation is going to be absolutely critical for the future of artificial intelligence but having said that he also thinks that we need to be more efficient with our hardware tomorrow than we are today. That's just a reality that we all have to accept. So the more compute we throw at it the bigger we make our models somehow the better they perform and we don't know precisely why that is but we do know that they will use increasingly more energy to do the computations for us and at some point that's just not a viable economic model anymore. We'll see a continuation in making deep learning and machine learning more energy efficient. So there's a really interesting interplay between priors, experience and generalization. We want to have machine learning models that generalize really well to things that they haven't seen during training. If you move them into a new orientation or in a new situation in the context and that's what we think of when we say artificial general AI which means like not just something you train on one specific topic and then you ask it to do that and it does it very well but if you then move it into a new context it just completely fails as narrow AI. So humans are clearly much more flexible if you learn something in one context and then when you get put into a new context that we've never seen before suddenly we can still do very well and so we want our agents our artificial agents also to have this property. Max is also a huge proponent of generative models. He thinks that generative models might be the future of artificial intelligence so funnily enough I think Max and Carl Friston that we had on a couple of episodes ago I think they would see eye to eye. Basically what everybody else in the scientific community does which is write down a model of the world which we call a generative model which is how do I imagine that the world that I'm seeing in my measurement apparatus could have been generated by nature. We all have the matrix going on inside our heads. We are running simulations of reality and we're kind of integrating over the expected value of those simulations. This is just something that we do all the time. That seems to be the real trick for intelligence at least in humans so our ability to generate the world. Max also thinks that we need to be learning causal relationships in our models. Causal relationships have this really interesting property that they generalize better so Max comes up with this wonderful example of a certain color of car in the Netherlands might be associated with a higher accident rate but that probably wouldn't generalize very well to other countries because it's just a colloquialism whereas male testosterone levels that's a causal factor and that's going to generalize far better to other countries. So try to figure out what the true physics of the world is what causes what and if you have this causal structure of the world you understand much more about the actual world and then if you move it to a new context you can generalize a lot better in this new context. At this stage Max has bet on so many winning horses that you've got to wonder how the hell does he do it so we ask him what his secret is. It's incredibly hard to predict what will become well known. Sometimes you just happen to be working on something that takes off like a rocket. When we did things like the VAE or graph neural nets it didn't feel at all like this was going to be a big hit. When we read some of the research from Max's students we were just blown away it sometimes we've got to just remind ourselves that these are fairly young folks that are in their early 20s that you know they've just come out of university. How is this even possible? I've been very blessed with being able even with my industry funding to provide this level of freedom to the students and I think this is really key. So one of the things we asked Max was how does he select his research directions? One of the interesting things is that he's a physicist right so many of the things that he's been doing are straight out of his operating playbook from the physics world. So things like symmetries and manifolds and even quantum. Like symmetries have this this deep feeling right? Symmetries pervade basically all theories of physics and they have this profound impact on how you formulate the mathematics of a theory especially when it becomes almost mysterious right? Quantum mechanics is almost mysterious. How on earth is quantum mechanics possible? The fascinating thing here as we discussed on our GPT3 episode is that many of these roads actually lead back to computation itself. How does the brain compute things also feels like a very deep question right? How do we even compute things? What is computation even and does the universe compute its solution? What does it mean to be predictable? Can you compute faster than the universe can compute? One of the key concepts that we talk about in the show this evening is the bias variance trade-off. Nothing comes for free. There is no machine learning without assumptions. You have to interpolate between the dots and to interpolate means that you have to make assumptions on smoothness or something like that. These prior assumptions will help you transfer from one domain to another domain. One of the topics we've been discussing a lot on machine learning street talk recently is this notion of how far can we take data-driven approaches? Will they take us all the way to AGI or is it just like building a tower and trying to get closer to the moon? Perhaps we could generate more data with data augmentation or even a simulator. Perhaps we could use data more efficiently with machine teaching or active learning or some kind of controller on how we train the model but ultimately how far can we really go? The big question in some sense over time is can we simply take the data-driven approach and extend it all the way to AGI? So Max tells us about all the different schools of thoughts in the AI community and of course one interesting school of thought is the likes of Gary Marcus and Wallyed Subba that we had on the show a few weeks ago. These people think that we need to have an explicit model of the world. And then on the other side we just want a classical AI sort of community which is no, no, no, that's going to be ridiculous. You will never be able to do that. You really need to imbue these models with the structure of the world. In the show, Max tells us where he's placing his bets but we're not going to spoil the surprise. So as we said before, Max is extremely well known for creating these inductive priors and putting them into machine learning models, helping them generalize better and be more sample efficient. The whole endeavor of machine learning is defining the right inductive biases and leaving whatever you don't know to the data. If you put the wrong inductive bias into things we'll, things can actually deteriorate. We talk about Hinton's capsule networks. They tell you well we'll just keep the abstract nature of what we want which is some stack of things that transform in some way that we can vaguely specify and then we ask it to learn all these things. We talk about Professor Kenneth Stanley's Greatness Can't Be Planned book and also Sarah Hooker's The Lottery Paper. The thing that both of these ideas have in common is that they posit that we are locked in by the decisions of our past. And I do feel very strongly that as a field we need to open up. So we shoot value original ideas much more than we currently do. So Professor Kenneth Stanley has a fascinating take on this. He thinks that we should be treasure hunters. We should find interesting and novel stepping stones that might lead us somewhere interesting. He thinks we should do this in all aspects of our lives. So we all want to monotonically increase our objectives and what we should be is treasure hunters. Science should be about exploration not exploitation. How do we extend this to peer review in science? Ironically having a consensus peer review encourages groupthink and convergent behavior. If we genuinely want to have an exploratory divergent process we should almost optimize for people disagreeing with each other in the peer review process. I think the reviewing in our community is far too grumpy. I'm continuously amazed when I read these old papers from let's say Schmidhuber and like the first RL papers that just came up with a bit of an idea and then they had a bit of toy data and right and that's a paper and it's cool. There's a dichotomy between on the one hand having a stamp of approval having a paper published and presenting about it and on the other hand having a continuous stream of research which is peer reviewed online and with some accountability. Yeah I think we really need to disrupt the field a little bit. Quantum machine learning is a bit of a mystery to most people I feel including myself and even though I learned something in this conversation paradoxically it's more of a mystery than before the conversation. Crucially Max thinks that quantum computing will hugely impact the machine learning world in the future. So you can think of quantum mechanics as another theory of statistics in some sense right. Essentially quantum neural networks have nothing to do with particles necessarily or physics. It's applying the math behind quantum mechanics to machine learning and building neural networks as layers of functions of these quantum operations that forward propagate some signal as Max describes really nicely in this conversation. This is the counterintuitive part which is you can have a probability for an event or an amplitude for an event and then you have an amplitude for another event and you would think that if there's two probabilities for that event to happen then the probability of that event should grow but in quantum mechanics they can cancel and then the probability is suddenly zero that the event happens. So this seems bizarre but nature has chosen this theory of statistics anyway. I really felt like an ELI 5 here. Instead of calculating with probabilities you calculate with something like the square root of probabilities and thus events that can only stack in classical probability theory can all of a sudden cancel each other out and that gives rise to really interesting math. We talk about Max's recent quantum paper that just got released and so that was a paper that we recently pushed on the archive which is quantum deformed neural networks which we basically first say okay what if we would take a normal neural net and implement it on a quantum computer and then we slightly deform it into something where states get entangled. So by doing it in this particular way we could still run it efficiently on a classical computer. What this paper here did was to build a particular type of neural network of quantum neural network that can under the correct assumptions be simulated efficiently on a classical computer but also once we have a quantum computer it can release its full power basically. If you want to do classical predictions does it actually help to build a neural network that can run efficiently on a quantum computer that can do these predictions much better. Can you write down maybe even normal classical problems more conveniently in this quantum statistics. I found the conversation with Max to be extremely helpful here and he does a great job of explaining what's going on. Max has another exciting paper out. Probabilistic numeric convolutional neural networks it's a paper by Mark Finzi, Roberto Bondeson and of course Max Welling and it looks at what you can do with computer vision models if you move away from the assumption of discreetly sampled pixel grids and move to a continuous representation that's more like what an actual object in the real world projected on a screen behaves like. The observation is when we write down a deep learning algorithm let's say on for an image then we sort of treat the image as pixels and we think that's the real signal that we are looking at but you can also ask yourself what if I remove every second pixel now actually I have a very different neural network but should I have a very different neural network or what if the pixels are actually quite randomly distributed in the plane it's just some random places where I do measurements maybe more on the left upper corner and and fear on the left lower corner what the predictor should behave in a certain consistent way and so of course then you come to realize that really what you're doing is with a pixel grid is sampling an underlying continuous signal. So to get away from this assumption of this discreet even sampling they use these objects called Gaussian processes to model the data and a Gaussian process it's basically a universal function approximated like in your own network but it gives you a measure of uncertainty and the reason you might want to do this are many but in short it allows you to average over every possible model that describes your data and gives you a better result. In doing so you can start to do really interesting things like subpixel sampling or work with very sparse locations but in order to do that you need to re-conceptualize a lot of the familiar operators that work on our linear algebra representations such as like the the convolutional translation operation of our weights. The way they got around this was super interesting. So there's a very interesting tool which is called the Gaussian process it's basically interpolates between dots but in places where you don't have a lot of data you create uncertainty because you don't know what the real signal is. What does it mean to do a convolution on this space? The most interesting way to describe that is by looking at it as a partial differential equation. So they reframe this transformation as a differential equation that could just be parameterized calculated out in a closed form and directly applied to the parameters of the model that means you don't need to like do any sampling or anything like that you literally just calculate this thing apply it. It would be worth going into the differential equation stuff by itself but it gets very complicated very quickly needless to say it generalizes not just translation but also things like rotations and scaling but the way that they really did this was by finding very clever representations. It boiled everything down to normal distributions or almost everything could just be done in closed form which things have been done with the Gaussian processes in the past but they're typically computationally expensive so if you can do all these updates without constant re-computation then that's a huge computation and an advantage. The paper does some really cool things. Some of the benefits are now that first of all of course you cannot work on a unstructured set of points doesn't have to be a grid and you can even learn the positions of those points so you cannot direct the observations in places where you really need to do your observations in order to improve your prediction. So it turns out that all of this can be remapped back onto the quantum paradigm. I must admit I'm almost gutted that I didn't study physics at university. Physics seems to be one of the most robust scientific disciplines and the folks are just so smart because it's really really difficult and what I notice is that it's very very difficult for external folks to get anything published in the physics world but there's an asymmetry the reverse isn't true loads of these physicists are coming into the machine learning world and they're just implementing all of these things whether it's symmetries manifold topology chaos it's really really interesting to see this unfold. We also get a take from Max about GPT-3 and so you say GPT-3 isn't very good maybe but it's a receding horizon right. I had a chat with my old colleague from Microsoft Ilya Karmanov about 18 months ago he introduced me to Max Welling's work it absolutely fascinated me ever since and guess what Ilya left Microsoft and he went to Qualcomm. Hey Tim how's it going? Ilya is going great how are you? I'm good different country different job different universe it seems but I'm doing pretty well. Ilya and I used to be work colleagues at Microsoft UK and I left Microsoft about a year ago and actually you left as well didn't you Ilya? Yeah we have a joint pact it was like you have to keep both of us or we leave. Indeed now Ilya and I made a YouTube video just over a year ago and it was all about Max Welling's work with Tako Kohen all about symmetries and manifolds and this work was hugely inspiring for me how did you discover it? I discovered it because my colleague Matthew and I whom you also interviewed and you should follow up with that. We were at Ilya and we saw Tako's talk about spherical CNNs which was a bit late already into his work which started with group equilibrium convolutions and I think both of us just thought it was really cool it was our favorite talk for the day because it was so different and it felt like it was setting up a different stream of research it wasn't necessarily about chasing SOTA it was just about really improving taking what makes convolutions great and making them even better and that was awesome. Oh amazing well we made that video together on Machine Learning Dojo and I must admit it was hugely inspiring for me and I reached out to Max Welling about two months ago and he actually came onto our podcast we interviewed him yesterday but yeah it all came from you and you know you introduced all of this stuff to me and I've been going through some of Max's work with some of his recent students and it's just incredible it's because he came from the physics world and all of this knowledge that he has around quantum and symmetries and topologies and manifolds that's his operating playbook and he's just taken it into the machine learning world and he's just been executing on it. Max is involved in a lot of papers as you would expect and a fair few of them are really fascinating. Yeah one of the things we spoke about was just how he nurtures his PhD students because some of these papers are just incredible and presumably these students have gone from nothing to producing that level of research in a very short period of time but presumably this was one of the reasons why you decided to apply for Qualcomm. Yeah I was chasing something that was publishing papers in the field of computer vision and it's one of the places in Europe, perhaps Zurich is another location when you have this kind of research. I thought it was extremely different and a super interesting research area so to speak to get into. Fantastic and what are you working on at the moment? We have just submitted actually our paper to CVPR this morning, the deadlines in a few days so that's pretty good I think and then maybe after that as well we have a few more topics and video basically self-training, how to improve representation learning, it's a mix of knowledge distillation and self-training and then also we have some interesting work with radio signals so it's like video in the sense that it's from that we extract the spatial and temporal signal but it's extremely different to video and that also makes it super fun. Amazing when I was discussing machine learning with Ilya at Microsoft we were fascinated by 3d convolution on your networks and i3d and video action detection and I know you are working on a 3d segmentation and a whole bunch of cool things like that but anyway I would love to get you on the show in the next few weeks to talk about some of your research and for those of you in the comments if you want to have more from Ilya let us know are you going to give us a demonstration of your front lever? Okay single leg. When Ilya comes on the show properly we're going to be doing a front lever competition that's pretty good so not only is Ilya a specialist in machine learning he also absolutely smashes it in the body weight game. No that wasn't smashing it that was after a climbing session it's actually really cool I met this guy here who's a calisthenics instructor called Soli and he just started climbing and yeah so we met up and we went climbing this morning and he was crazy good as you would expect and he gave me some tips on my front lever as well he was saying I should work more on the tuck instead of the single leg so hopefully you'll see much better than that in the future. Amazing Ilya thank you so much for coming on the show we look forward to interviewing you in a few weeks time. Thanks for helping me and thanks a lot for interviewing Max I'm like super excited to see that in a few days. Anyway I really hope you've enjoyed the show today this has been such a special episode for us because Max Welling is literally one of my heroes so anyway remember to like comment and subscribe we love reading your comments we really do actually we're getting so many amazing comments in the comment section so keep them coming and we will see you back next week. Welcome back to the Machine Learning Street Talk YouTube channel and podcast with my two compadres Alex Stenlake and Yannick Kiltcher and today we have someone who doesn't really need any introduction at all clearly one of the most impactful researchers in the ML world and has as near as makes no difference 40 000 citations he's on the executive board at NeurIPS he's a research chair and full professor at the AMLAB University of Amsterdam and co-director of the CUVA lab and Delta lab Max Welling. Max is a strong believer in the power of computation and its relevance to machine learning which is one of the reasons why he holds a vice president position at Qualcomm. He thinks the fastest way to make progress in artificial intelligence is to make specialized hardware for AI computation. He wrote a response to Rich Sutton's The Bitter Lesson but essentially agrees with him in the sense that one should work on scalable methods that maximally leverage compute but Max thinks that data is the fundamental ingredient of deep learning and you can't always generate it yourself like an AlphaGo which amounts to an interpolation problem. Much of Max's research portfolio is currently based on deep learning. He thinks it's the biggest hammer that we've produced thus far and we witness its impact every single day. He thinks that AGI is a possibility and it will manifest in a forward generative and causal direction. There's a really interesting cross pollination story here Max has a physics background he did a PhD in physics he knows all about manifolds and topologies and symmetries and quantum and actually this has been his operating playbook he's brought all of these incredible concepts in from the physics world to machine learning. Now there's a fundamental blank slate paradigm in machine learning experience and data currently rule the roost but Max wants to build a house on top of that blank slate. Max thinks that there are no predictions without assumptions no generalization without inductive bias. The bias variance trade-off tells us that we need to use additional human knowledge when data is insufficient. I think it's fair to say that Max Welling has pioneered many of the most sophisticated inductive priors and deep learning models developed in recent years. An example of an inductive prior is the CNN which means we can model local connectivity, weight sharing and equivalence to translational symmetries in gridded vision data. This is imputing human domain knowledge into the architecture it makes the model significantly more robust and sample efficient. Assumptions are everywhere even fully connected networks assume that there is a hierarchical organization of concepts and even further assumptions about the smoothness of the underlying function we're estimating. Max and many of his collaborators for example Tako Kohen took this idea so much further they introduced rotational equivalence and then they built models which would work extremely efficiently on non-geometric curved manifolds meshes or even graphs. Max wants to reduce the need for data in deep learning models increasing the representational fidelity of neural networks subject to discretization and sampling errors and improving the computational techniques to process them more efficiently. Max has recently put out two new papers Quantum Deformed Neural Networks and Probabilistic Numeric Convolutional Neural Networks which we'll be talking about today. Anyway Max it's an absolute pleasure welcome to the show. Thank you very much Tim for a very nice introduction it almost sounded like it's not me but it was a lot. Do you feel that this it describes you not maybe accurately but do you feel like there's a parts of your work that are overly well known and there may be parts of your work that you wish would be more well known? It's hard to say it's overly well known because of course it's very enjoyable when you can make a big impact but what I can say is that it's incredibly hard to predict what will become well known of course if you could predict that you would only write papers with like gazillions of citations. When we did things like the VAE or graph neural nets it didn't feel at all like this was going to be a big hit and some of these things are being singled out and they fly and precisely what makes these papers fly is in a way that's a big puzzle in a way and some other papers you can be very proud of and it takes so much time to actually get published it's a huge uphill battle you think why do the reviewers not understand better but we really want to do here and then yeah and so they I guess there's a lot of good work which disappears into oblivion and from many people and yeah it's mysterious but anyway. Your hits definitely seem to be more than your misses you're a prolific researcher yourself but you've nurtured some of the best and brightest minds across in not just deep learning but like the wider machine learning field how do you consistently do that is it fantastic mentorship or is it more finding the right spark in a student and nurturing that and that's a really good question and I should say that I've been extremely blessed by all these fantastic students right from the beginning but I do think there is something to nurturing talent so I think what doesn't work is to basically tell to be very constrained to a particular topic sometimes you see this happen if you write a grant proposal and then the grant proposal is about topic A and then really the student starts at topic A but figures out after a couple of months that they don't really like topic A and they want to move on to B and it's just very painful then to say no no no you cannot do that you have to be doing A and so I've been very blessed with being able even with my industry funding to provide this level of freedom to the students and I think this is really key so the other thing which I find really key is that the relationship you have with the student is very important first of all it changes over the years which is also very beautiful so you start off with much more guidance and towards the end you should actually not be doing any supervision you should just having a conversation at that point on equal footing and you see about halfway through a phd like it's like a flower that opens and then it's now they get it suddenly right now they get it and they go and they have a while huge interesting ideas in all directions and they can write all these papers and stuff so that's a beautiful moment when that happens and the other thing I think is that I think of supervision as nudging in the sense that I have a big a lot of experience and where is where is the interesting stuff to be found right where is the next wave that we can get people enthusiastic about what are the important questions to address in the community and things like that so that's where my experience lies now I'm not doing a lot of coding myself in fact I'm just all doing almost zero coding which I regret for this life and the other thing is that even in terms of math it's limited right now right but most maybe two pages of math to verify something or to compute something quickly but not like a lot of math anymore I just try to keep up with literature mostly and the students do though so they do the hard work literally so they really should they should do all that work and it's this interesting relationship where you have a discussion where you say I think you know this is an important direction an interesting direction and here are some other things which are connected to it very intuitively right so you may want to look there and then a good student will just pick up these ideas and we'll run with it and then come up with new ideas and then you could say it is maybe be careful about this direction don't go too deep or maybe this is more an interesting direction stuff like that but even there I've learned to be very careful and if a student comes up with a good idea and intuitively I think that's actually not a great idea this is going to be a dead end that I'm not going to tell the student that very soon so I'm just going to certainly leave the student about a month to explore that idea for sure and I've been surprised right I've been surprised and basically it turned out it was a great idea and I was wrong and so I've been very careful with these things too so I feel it's a very careful dance between the student and the supervisor with not too much direction also it's a very personal so some students like more direction and other students like less direction but I think it is a bit of an art that I've learned to appreciate it is a little bit of an art to have the right type of relationship with students yeah but of course it's all about them they are the ones that need to shine in in the end after four years and they need to get the good jobs and become famous in terms of that guidance and specifically what you said with respect to this direction might be interesting these are the interesting research directions is this something that you just have to develop or do you have some general can you give some high level patterns that you've observed throughout the years where you see recurring things and and you say oh that's another one of those probably like short term hypes or yeah have you observed some general patterns there yeah so there's two things right so there's some things where I think why what is the big deal why is everybody chasing this particular direction so that's can you predict what the crowd will follow that's one thing seems pretty hard the other one is to find directions which may be on longer time scales are impactful and interesting and for the second one it is deeply intuitive and it's very hard to figure out precisely what it is what features there are but for me I have to get a sense that there is some something very deep going on that I want to pursue like for instance so I clearly in physics so if you can think about gauge symmetry like symmetries have this this deep feeling right symmetries pervade basically all theories of physics and they have this profound impact on how you formulate the mathematics of a theory and so there's something very deep about symmetries and and about sort of manifolds and doing things on curved spaces and so that's I could sort of naturally drawn into this thing not now it's more quantum mechanics and there's something very deep and especially when it becomes almost mysterious right quantum mechanics is almost mysterious how on earth is quantum mechanics possible if you dive a little bit into this phenomenon of there's a two slit experiment where you have these individual photons which which go over two paths and if it's a wave that's perfectly fine they can interfere with each other but now these photons can go one by one and somehow they have to be aware of this other possibility that they could have taken to interfere with that other possibility I just think that's crazy what's going on here and so I'm naturally drawn into sort of these kinds of mysteries in some sense yeah and there's plenty more and the other one is also computation clearly right how does the brain computing also feels like a very deep question right how do we even compute things what is computation even and does the universe compute its solution what does it mean to be predictable can you predict can you compute faster than the universe can compute and so there's all these very deep questions about computation as well that you can ask but there's a mixture between things that are attractive in that sort of mysterious sense there's something very deep that needs to be pursued and things which are also highly practical which is sometimes it's also a lot of fun to work on something that where you can actually make a big impact for instance speed up MRI imaging with a factor of 10 so now suddenly you can actually both image and radiate cancer at the same time which could have a huge impact in the future and feeling that level of impact is also quite exciting I think amazing so I wanted to frame up some of the work that you've done around symmetries and manifolds it's absolutely fascinating that prevailing idea is that we are wasting the representational capacity of neural networks because we're essentially learning the same thing many times and your work absolutely pioneered this starting with sort of rotational equivariance on on CNNs and then moving on to meshes and graphs and different types of topology it's absolutely fascinating but philosophically the modus operandi in deep learning is this blank slate idea this idea that if we look at data and nothing else then we can learn everything we need to presumably not in a very sample efficient way transformers seems to be going in this direction in the natural language processing world that we just ingest infinite amounts of data and we can learn everything we need to and we spoke to a good old-fashioned AI person while it's over last week and and his argument was that the information is not in the data he was arguing that we have a kind of ontology or knowledge built into us which we can use to disambiguate information that we receive so fundamentally speaking do you believe that we can be data-driven and can you introduce some of the work you've done with some of these priors in deep learning yes so this is a very fundamental debate clearly but i think it's not all that black and white right so there is a basically at the core of machine learning there is basically trade-offs the the buy is very in straight-off for instance it clearly expresses this right the first thing i want to say there is no machine learning without assumptions it just basically you have to interpolate between the dots and to interpolate means that you have to make assumptions on smoothness or something like that so the machine learning doesn't exist without assumptions i think that's very clear clearly it's a dial right so you can have on the one end you can have problems with a huge amount of data it has to be available clearly and there you can dial down your inductive biases you can basically say let that the data do most of the work in some sense and let me make my prior assumptions quite minimal and with minimal i think i'm interested in a smooth mapping right the mapping needs to be smooth like that's a very minimal assumption but the disadvantage of that is if you don't put any prior assumptions is that if you need to take whatever you've learned into a new domain where this model wasn't learned it will very quickly break down because these prior assumptions will help you transfer from one domain to another domain and causality does play a big role here but we can talk about this later and then on the other hand there is basically what everybody else in the scientific community does which is write down a model of the world which we call a generative model which is how do i imagine that the world that i'm seeing in my measurement apparatus could have been generated by nature and and that's that you can put a lot of intuitive knowledge there because you could think the world is described by a PDE or some kind of generative model so the people in our community often call this probabilistic programming models created by probabilistic programs or graphical models but they are highly intuitive highly interpretable and because they describe the generative process they are often also causal because you can think of these variables and one causes the other variable to happen etc and because they are causal they really generalize very well which means that if i train you know and someone in one context i say i learn to drive in the Netherlands i'm driving on the right side on the road i have particular kind of traffic signs etc so now i can take whatever i've learned sort of these rules or whatever i've learned and now i can move to another country where you drive on the left hand side of the road completely different traffic signs and i can still survive so this is typically something that the the the purity data driven methods have a much harder time doing this sort of generalization so i think this is basically a trade of now it's it's the big question in some sense over time is can we simply take the data driven approach and extended all the way to agi but there are people on one side of the fence that are claiming that this is possible of course we also need to amplify computation right so we're just going to build faster and faster computers that can digest more and more data and at some point we'll just have agi emerge out of this kind of process and then on the other side we just want a classical ai sort of community which is no no no that's going to be ridiculous you will never be able to do that you really need to imbue these models with the structure of the world which which i take as how does physics work how does the world work can i tell you something about how data really gets generated in this work this will cut down the number of parameters to learn dramatically and because i'm following causality i can now basically generalize and create agi in this way and so this is going to be very interesting how this is going to play out and you know to be honest so i feel that i'm slightly in the camp of you really need to put generative information into your models but i've been continually surprised by what's happening on the other side of course lots of my work is also on the other side in the sense that gpt3 you know is completely 100 data driven and did we expect that it would do so well no so he is another big surprise right and so that's i think that's the fun part but it kind of doesn't do well though it doesn't have any reversibility so if you ask it how many feet fit in a shoe or we did the example last week so the corner table wants another beer it doesn't know that the corner table is a person because that's missing information we would fill in those gaps but it does raise the question though of the dichotomy between memorization and compute and the guy we were speaking to last week just said that even if you had an infinite amount of memory and the data is just not there you couldn't do it when you were responding to rich sutton and you actually spoke about all the different schools of thought in machine learning so you said compute driven versus knowledge and model driven or data driven and symbolic or statistical and white box or black box and generative and discriminative the generative thing is fascinating because our brains it's a bit like we've got the matrix or we've got a simulation going on behind the scenes haven't we we're always thinking about all these potential situations and possibly integrating between them yes i i do agree that seems to be the real trick for intelligence at least in humans so our ability to generate the world at least at a symbolic level we don't generate like high resolution videos in our brain but we do generate objects and interactions between objects and sort of how things will play out and this will also help us imagine things like what would have happened if i would have done this so now i can play out this alternative world and say that was bad let let me not do this now so i think that is going to be a key so that's the generative part of the modeling because you can generate you understand how the world works the physics of the world works and so you can generate possible futures to me i feel that's going to be a really important part of intelligence and i do agree that it's for me also very hard to see that you can generate enough data to cover all corner cases it's just very tough if you do it in the wrong direction which is the discriminative direction but again i have been surprised by how good these models really are and so you say gpt3 isn't very good maybe but it's a receding horizon right people may have not thought this was true or bet on something like gpt3 before it appeared and then it appeared and people were extremely impressed and then of course some people poke it and say but it doesn't understand this and this and then excitement goes away again a little bit but it is a bit of a receding horizon but i have generally be very impressed also with for instance the fact that we cannot generate faces of people that that don't exist we can create billions of faces that that don't exist on this planet and that look absolutely realistic would i have expected this no probably not so no and then of course there's alpha go and things like this which we also wouldn't have expected right before it happens let me play a bit of devil's advocate with respect to building priors into models it's of course like some of the easiest priors we can think of are let's say translation invariance in a cnn you can also extend this to rotational invariance and so but if we look at a true practical problem we say yes it makes sense that there is a rotational invariance in the world however on the image net dataset like for a real practical problem the sky is usually up and the object is usually in the center it's not like to the side it's it's usually in the center so in a way it seems like if we actually hit the true invariance that the world adheres to it's certainly beneficial but if we even slightly deviate if we build in a different invariance it seems like there is a level of accuracy and if we want to get past that these invariance seems to be hurting do you have a sense of can it be counterproductive or when is it counterproductive to build in such invariances it's a very good question and so this goes to the point of the bias variance decomposition again so if you hit the right bias then it can be beneficial if you you know impose the wrong bias then it's going to hurt you and this is a well-known trade off so of course the whole endeavor of machine earning is defining the right inductive biases and leaving whatever you don't know to the data and then basically learning to focus your models on the data that you're actually seeing but I agree if you put the wrong inductive bias in it things will be things can actually deteriorate now I should say here that for the rotation invariance or equivariance things are not as bad as you might think so you said if you just have slightly wrong inductive bias then it hurts but that happens to be not so much the case because there's objects inside images that do have if you turn a cat upside down or a tree upside down we still recognize it as a tree in some sense and it does give you a sort of robustness to to certain transformations on these objects that you would otherwise maybe try to model by data augmentation and stuff like that now for the sky maybe you're right that similarly in the digits a six and a nine you know you will start to confuse a six and a nine if you build in rotation and equivariance right and so there it will actually hurt but it's been surprisingly robust actually because basically because you also cut down on a number of parameters and by cutting down on the number of parameters you will you can actually help the system generalize better so the inductive bias doesn't have to be perfect and it can still help could we touch on the dichotomy between the work you've done and capsule networks for example as well as the sample efficiency thing for example with translational equivariance it means that you can you can move the dog and then the response map the dog has moved as well and much of that is about allowing neural networks to learn patterns more easily because they can map in every single layer so with capsule networks that's still a blank slate philosophy so you don't explicitly say what the capsules are whereas with with your approaches you explicitly define the priors with capsules it seems to be defined by the data you give it so if you train a capsule network on MNIST data it might inadvertently learn that one of the capsules is how bendy the stroke width is on the seven or it might learn that there's a rotation on the car because you've given it lots of rotated versions of the same car but it seems quite arbitrary and the algorithm is hideously inefficient and what's much more exciting to me is the kind of baked-in priors that you've designed in the encoder stage so could you draw the dots up between those two approaches yeah i think you actually you said it quite right so one is a much more constrained system than the other one but the actual representations that we put in our hidden layers in both cases are very similar they are stacks vectors and these vectors transform under certain operations so if i rotate the input then there is some operation on this stack of vectors which is they do rotate in the x y plane but they also permute in the sort of vector dimension and so that we tell it very explicitly how to transform we just say under these transformations you have to transform like this and we can do this because these these geometric transformations we know them that they appear in the real world but so it's also constraining because there is many other transformations that either we don't know precisely what the mathematics for the representations looks like or for instance like groups that are that are not compact maybe maybe we have looked at scaling but it's already a more of a stretch but there's of course you can do many other types of transformations that don't even have to be groups there could be other types of transformations like lighting changes or whatever if you wanted to incorporate all of these you would have to build the mathematical representation theory for each of them and then it would actually also explode in a number of feature maps that you would have to maintain and it's not a very practical approach so this works up to the transformation groups that we understand and that are everywhere around us if we want to go beyond it then basically something like capsules are very nice because they tell you well we'll just keep the abstract nature of what we want which is some stack of things that transform in some way that we can vaguely specify and then we ask it to learn all these things and we are actually ourselves also looking at these sort of more relaxed notions of equivariance where we don't tell the system precisely how to change we just want this to emerge automatically and again here the connection with the brain is very interesting in the brain we do seem to have all sorts of filters which are related by not only by rotations but all sorts of other transformations and they are topographically organized so they are right the ones that are related like a slightly rotated version is sitting right next to the other one in your brain and so presumably your brain have figured this out by just looking into the world for a long time and it's organized all these filters that way and it's known that if you prevent let's say a cat from seeing then it will not come up with this nice organization so you really have to get that by looking into the world a lot and that's super fascinating and I think that's where some of our research is being directed now can we learn from how this happens in the brain is there a connection between these topographic maps and equivariance somehow and between capsules and all of these things and I believe that it is a good strategy to to take the general ideas equivariance and then slowly relax it and let the system learn more and more so these capsule networks they've been a bit hyped when they were not really developed named first by Jeff Hinton and he has this concept or at least had it at the beginning that it's some sort of like an inverse rendering pipeline so the sort of the capsule networks do some sort of they take in the world and they inverse render it into these capsules how much do you agree with that type of formulation it seems what you've described is more of a forward way of looking at capsules where we have these invariances yeah yeah so I don't I very much agree with this idea that you have smaller things and they can be used in multiple ways but you have to align them in a particular way so that they build something at the higher level and obviously you can invert that idea too in order to start at something very abstract and then generate certain things this way and there is a lot of work now actually going into equivariant generative models for instance equivariant flows a prime example is for instance in physics and what's called quantum quorum or dynamics there is there's a theory that has a huge number of symmetries called gauge symmetries and if you transform these quarks in a way in a particular way the physics doesn't change you will have exactly the same observations right but still you need these all these symmetries to conveniently describe this model and so now when you generate you if you want to generate quark fields or something like this right then gauge fields then you can generate all these symmetries and it's not very helpful because you generate one configuration but you then if you generate all these sort of equivalent things which are only you know different by symmetry then you haven't really done much so understanding how to generate with these equivalents in it is actually a big topic of research in many groups I think you know Danilo Rosenda and this friend in DeepMind has done a lot of work and there's physicists at MIT and who don't work and we are with a group of students and physicists at Amsterdam we're also looking at these types of questions so that's I guess the inverse problem where also equivalents is playing an increasingly important role not many people are working on capsules I feel they've fallen out of the favor of the public because I don't know they're maybe hard to implement or they don't really work as advertised let's say do you have general thoughts about capsule networks I think with many of these things there is an underlying intuition which is correct so I haven't really worked myself in trying to implement them and so what's what you often see in this field is that there is an intuition about how something should work and often that's that is the correct intuition especially when it's coming from Jeff Hinton it is very likely to be the correct intuition now then there's the next step which is how do you make something practically implementable and these days that means that you have to run it super fast right you have to be able to implement it in GPUs all these kinds of constraints otherwise you will be so much slower than just an ordinary cnn and you will basically not be able to train as long as a cnn and you cannot train as many parameters as an ordinary cnn and you will not beat it and if you don't have the bold numbers hard to publish and so that might impede progress in something like this but then what happens is you wait and then for five or ten years and then the computers have become faster and then people go back to these ideas and then they think oh that was actually very interesting let me try again and then suddenly things start to work now that's of course the story of deep learning more generally speaking right because we had you know neural networks like a long time ago right in the 80s it was actually quite popular to work on these things but they didn't quite take off because we didn't have the compute power and maybe also not the the data to really train them well and it's only when we took them out of the the closet again and said hey man this thing actually works if you throw a whole bunch of GPUs at it that's when people then became popular again and so something like this might well happen again with with capsules or it is something like capsules in then by five to ten years do you have any other than capsule networks are there things that right now we are not looking back on but that would you know be worthy of of a revisit oh yeah that's very tough but i'm personally looking at things like ICA and topographic ICA so i think there's an interesting body of ideas there of course i risk now to mow away the grass before my own feet but okay let me let me entertain that and then probably marker random fields and things like this will probably make a comeback at some point or graphical models more generally will probably make a comeback or maybe that integrated with deep learning and some people have already attempted going in that direction energy based models have made a comeback already so yeah it is often going back to older ideas and there's probably a lot more that other people can sort of name i do have a prediction maybe for the future that people really haven't looked at yet in my opinion it's going to be quantum things so i think many people don't actually know understand the language of quantum mechanics or mathematics and i do think that first of all that language is very interesting it's a bit different than our normal probabilities it's like square roots of probabilities and with the advent of quantum computers which at some point will come we as a community will have to dive into that and maybe make it part of our curriculum and in university and then i think that will become that will start to boom could i just quickly introduce before we get to quantum i don't know if you read sarah hookers the hardware lottery paper and this is fascinating for you of course working at qualcomm but her idea was that there are certain things that cause a inertia or friction in the marketplace of ideas so is it a meritocracy of ideas or do the previous kind of hardware decisions and hardware landscape does it enslave us you know ideas succeed if they're compatible with the hardware and the software at the time and this is what she called a hardware lottery and she says the machine learning community is exceptional because the pace of innovation is so fast it's not like in the hardware world which you all know so well where it costs so much money to develop new hardware and the cost of being scooped is so high but i wanted to just come at this from i don't know how you see this right so with capsule networks the reason they're so slow is because it's a kind of sequential computing paradigm and no amount of hardware is going to solve that but there are entirely different paradigms of hardware like quantum which could potentially change the game but how much could they change the game is there still some limit on it there's always a limit clearly but i think the the situation is maybe slightly more subtle which is that working in a hardware company i can also see the other side of the coin a little bit so there is also a race in the hardware companies to build ASIC designs like which is specialized hardware to run the latest and the greatest machine learning algorithms which are being developed so it's not just rich machine learning algorithms work well on the current hardware that us being enslaved to the hardware there is actually a feedback which where now the companies are trying to build ASIC to first of all run the confolutions very efficiently and soon we'll have probably transformers run very efficiently and so that's the fascinating thing of course it's hard to get your paper published perhaps if if you're ahead of the game too much which i see a little bit in the machine learning community which is if you look at the papers which are published in the physics community they work with images of four by four pixels that's what they can do because otherwise you need a quantum computer obviously to run your algorithm and it's being looked down upon a lot by the machine learners basically saying what do we you know what why is that interesting and i do feel very strongly that as a field we need to open up so we we should value original ideas much more than we currently do and i don't know you know you can probably have a whole conversation on where this is coming from i think the reviewing in our community is far too grumpy i think people if it's not completely finished polished paper then you know they'll find a hole somewhere and they start pushing on it and i think you should look also at a sort of more holistic how original is this idea right can you be excited about the originality and the creativity of the idea that went into that and trust that maybe it takes the community a couple of years to further develop this and and and some things will die and that's fine but let all these flowers grow in a way and yeah so i i do feel a little bit that sometimes is a bit negative and i and that's maybe where some of that friction is coming from that yeah just on that it's fascinating we're talking to Kenneth Stanley on monday and he wrote a book greatness can't be planned and his big thing is exactly what you've just said that we have this convergent behavior in so many of our systems whether it's science or academia and it's because of this objective obsession so we all want to monotonically increase our objectives and what we should be is treasure hunters yes science should be about exploration not exploitation exploitation is one step away you already know how to build the bridge we don't seem to have this paradigm at the moment even when you submit your paper to be reviewed there's a consensus mechanism isn't there because you need to have multiple accepts from people and science advances one funeral at a time yes do you think this is a huge problem yeah i think it is a big problem but i think also we will probably i think it's a big problem because it will hold us back and it will also hold very brilliant students back so what do i advise my students now i advise them to have a mixed model a mixed sort of policy which is on the one hand you work on some papers which are easy to score on things that are very popular in the community and then on the other hand you work on things which might be you know huge innovations that are much more uncertain they might fail but then they might also be really big innovations and that way you get your papers and you can become famous but at least also you work on things which are highly risky but in fact it's a bit cynical to have to do that it would be much nicer if there would be much more appreciation for just originality and but i do also believe there is a solution to this so i think we are in a sort of a local minimum as a community in this sense but i think there's a way out and one way out which is basically and this has been already proposed a long time ago i think young mcconn and yasha benji were also talking about this and we are actually trying to implement this for a beige and deep learning workshop is to sort of to throw papers on the archive and not necessarily submit to conferences and to have a open reviewing of that and to give people reputation indices so if you do if you give a good review you can publish your own review or state it in your cv and people can rate your review and if you do poorer reviews you'll get horrible ratings and then your reputation will come down so there is some kind of way that you can probably design is that people are incentivized to give good reviews and to actually use these reviews as a half a paper that you can also be proud of and then good things will come up right they will at some point people will point to interesting ideas maybe we need some kind of recommender to make sure it's a bit unbiased in the sense that it's not only the famous people that will get their papers exposed but also less famous people so we need to have sort of maybe build a recommender around something like that every so now and then a conference comes by and it sort of harvests in this field of sort of papers and say that one you're all reviewed they have great reviews i'll take one or two more reviews anonymously and i'll then publish and then i invite you to present your paper in our conference that to me sounds like a much more natural way to proceed i also find it very demotivating for my students who have these ideas maybe this is the worst part so you're a student you're working on this thing which is not completely mainstream and then you get rejected two or three times from a conference right this is so demotivating for a student to then continue right at this case at least you just you push us on the archive and you engage with the community around your paper and that's a much more it's much less demotivating than these constant rejections from the big prizes right the NERIAPS paper or the ICML paper that everybody wants is like guys the idea at the moment a lot of people are talking about this how can we improve peer review like in every field people are moving towards this open review model but collectively as a research community we don't really have the collaboration tools at this point in time to take advantage of it open review is willing to implement this actually so yeah i think it will happen yeah it it's a good system to pivot back into new ideas and sort of exciting concepts that are coming out machine learning at the moment you mentioned quantum computing is this paradigm that's really critical that's not really well understood by the machine learning community would you be able to give our listeners like the five-minute spiel about quantum probability how it differs from the probabilities that we're used to yeah so you can think of quantum mechanics as another theory of statistics in some sense right so in AI for everything we can't totally observe we write down probabilities of things happening but of course underlying there is processes but we just don't observe everything and so we describe it by probability now in quantum mechanics it's very similar to taking the square root of a negative number in some sense it's like you let me put another way so it's very much like taking the square root of a probability which can actually become negative so minus one squared is one right okay or let's say minus two squared is four four is your probability and minus two could be your quantum amplitude this thing can be negative and the bizarre thing is that if you describe a system by these quantum amplitude these square roots then they can cancel which is this this is the counter intuitive part which is you can have a probability for an event or an amplitude for an event and then for you have an amplitude for another event and you would think that if there's two probabilities for that event to happen then the probability of that event should grow but in quantum mechanics they can cancel and then the probability is suddenly zero that the event happens so this seems bizarre but nature has chosen this theory of statistics anyway and so it behooves us to look into this more so first question is can you write down maybe even normal classical problems more conveniently in this quantum statistics and here I always remind myself when I first learned complex numbers when you learn to solve the damped oscillator equation you can do it in a complicated way or you can go to complex numbers and then suddenly it gets very easy to do it and so you can imagine that there is things to compute in classical statistics that are actually either shortcuts by using quantum mechanics somehow and and so the first thing that we've tried to do with quantum mechanics in deep learning is to say can we just design an architecture that would be naturally a natural fit to this quantum mechanical description of the world but we still want to be able to run it on a classical computer so we just want to describe this we just want to harvest this new degrees of freedom that we have from quantum mechanics and so that was a paper that we recently pushed on the archive which is quantum deformed neural networks which we basically first say okay what if we would take a normal neural net and implement it on a quantum computer and then we slightly deform it into something where states get entangled and this entanglement is another strange phenomenon in quantum mechanics where you can create states which you cannot really create classically superpositions of states and and so by doing it in this particular way we could still run it efficiently on a classical computer but it's just a very different beast than a normal neural network so that's already to me very interesting and then of course the big prize the big bonus is that if you adhere to this way of describing what's happening is that there is the opportunity to be able to run things very efficiently on a quantum computer so now you can design your neural network in such a way that classically actually it will be very hard to simulate it but then on a quantum computer you could potentially simulate it very efficiently and and of course we don't have quantum computer so it's very hard to actually prove your point but that also what makes it somewhat exciting in that paper specifically you make you make lots of references and connections to the Bayesian way of doing machine learning could you what's the connection there because it seems different both are I agree both are statistics and you already mentioned the square roots of probabilities but how do you connect the sort of uncertainty quantification in the Bayesian way with how particles move quantum mechanics is not necessarily about particles so you can just you can write quantum mechanics on just like states you can just write down a number of classical states like I say a sequence of zeros and ones and there's an exponential number of these states and then you can say classically I can only be in one of these states but in quantum mechanics I can be in any linear combination of these states which should have is a bigger space now what we did in that paper was to say we can treat both the world state as well as the parameter state as a quantum we describe it by a quantum wave function and then we entangle these different states which is similar to saying that I take my state classical state x I multiply it by a matrix of parameters and I get a new state out so here the analogy would be I have my quantum superposition of classical states I have a quantum superposition of parameter states and then there are some processes where we get entangled together and then I do a measurement which is now a function of both the parameters as well as the inputs and you train it to give you measurements that with high probability give you the answer that you want so that would be the training process now there is actually a very precise way in which you can relate Bayesian posterior inference in quantum mechanics but that's a fairly technical story but there is a using density matrices there is a fairly precise way in which you can say I have a state described by a density matrix and if I do a measurement I condition on something and a renormalize and stuff like that so that's possible so there are two things like first of all the quantum neural network formulation can be very slow on a classic computer but fast on a quantum computer on the other hand people do run like Bayesian inference on classical computers what makes the quantum neural networks that much harder to compute yeah it's this entanglement issue yeah so in so classically I agree there is an analogy in classical statistics where this looks very similar which is for instance if I have a exponentially large state space and I write down a probability distribution over all of these possible states where they have a number a positive number that sums to one for each one of these exponentially large states and if I ask you now compute an average of a function over this probability distribution you can't do it because there's an exponentially large number of things that you would have to sum and so we have ways to deal with it which is sampling from these distributions or variational approximations and anyway we have to approximate this state of affairs now in quantum that's fairly similar so there's you you face a similar exponential problem and you can also do approximations to get around that and but the interesting part is that in quantum mechanics you can for instance do a measurement and a measurement is something that you know that is it gets a physical thing and it's not very hard to do but it will be an operation which looks like sampling something down to a particular classical state again and it does look like the sampling operation that we do in sort of artificially in probability theory but it's also true that quantum computers can in principle compute things that classical computers can't compute and they can actually compute it much faster whether that actually maps to the things that we are interested in is not so clear so that's it's not at all clear right now that we will actually build quantum neural networks that are generalizing a lot better on classical problems right if you want to do classical predictions does it actually help to build a neural network that can run efficiently on a quantum computer that can do these predictions much better that's not known but that's what makes it exciting in my opinion because you can try to do it now there's also functions that you can't even do classically you have to do quantum mechanically but I don't know how relevant they are for AI fascinating can we conceivably say that at least one let's say applications are way for these neural networks or for the quantum neural networks to come in is in in the place where right now we have these renormalization problems let's say big word embeddings or yeah as you mentioned things like variational inference any anywhere where you have a partition function that you let's say have to sample to compute now we potentially introduce this new way of doing this yeah so I would say that is a different set of problems so there is some sampling algorithms which can be sped up by quantum sampling algorithms but I think the maximum speed up is like a square root so it's not insignificant but it's also not exponential okay right you can do something in square root time of what a normal classical computer could do and then there is these very interesting stories where people thought that they could do things much faster on a quantum computer but then somebody's thought really hard about it and they then invented actually a quantum inspired classical random algorithm which would do about the same speed or close close at least so it's very uncertain precisely what we can speed up but that what makes it interesting right especially if you can predict what's going to happen in some sense it's just a matter of executing right but if you don't know if they're what they're what the low hanging fruit is and if there is low hanging fruit and what the possible benefits in benefits are the possible bonus that you can get by doing these things then it gets really interesting in my opinion amazing now might be a good time to talk about your other paper that's just come out Max which is probabilistic numeric convolutional neural networks and this was also with Mark Finsey who we just discovered this morning just brought out a really interesting paper about equivalents on light groups so that might be a potential digression later but this works really fascinating because it's in the setting of irregularly sample data and we use these Gaussian processes to represent that and we can continuously interpolate between them in this convolutional setting absolutely fascinating could you give us the the elevator pitch yeah first let me say again that Mark Finsey was an intern at Qualcomm and and Roberto Bondeson was is the other person who was also working with me on the quantum stuff so those of my collaborators in this project and of course Mark did the bulk of the work for this paper so he should deserve much of the credit for it but here's the observation that we had the observation is when we write down a deep learning algorithm let's say on for an image then we sort of treat the image as pixels and we think that's the real signal that we are looking at but you can also ask yourself what if I remove every second pixel now actually I have a very different neural network but should I have a very different neural network or what if the pixels are actually quite randomly distributed in the plane it's just some random places where I do measurements maybe more on the left upper corner and and fear on the left lower corner what the predictor should behave in a certain consistent way and so of course then you come to realize that really what you're doing is with a pixel grid is sampling an underlying continuous signal so then we just started thinking how do you best deal with this so how do you how can you build this in and so there's a very interesting tool which is called the Gaussian process it's basically interpolates between dots but in places where you don't have a lot of data you create uncertainty because you don't know what the real signal is so you basically get some kind of interval which says okay I think the signal is somewhere in this interval with 95 percent you know certainty but I don't know precisely where now the mean function is a smooth actual continuous function and then the next step was say okay what what does it mean to do a convolution on this space this is the new Gaussian process interpolated space and what we found is that the most interesting way to describe that is by looking at it as a partial differential equation and so this ties back into another really interesting line of work which was started by David Duvenaux and authors on thinking of a neural network as an OD as an ordinary differential equation so here we're talking about a PDE basically because we have spatial extent and so we are looking at sort of derivatives and second-order derivatives in in the plane basically which which we apply on the continuous function so this is literally what people do when they solve a PDE is that they have some operator which is consists of derivatives which they apply to the function and then they have a time component which evolves this thing forward in time basically and it turns out that's a very natural way to describe a convolution you can also add symmetries in a very natural way by looking at that operator that sort of moves things forward and making sure it's invariant under certain transformations we had a bit of trouble really handling the nonlinearity that falls that happens then so we had to then project it back onto something that would then again easily handle by a Gaussian process etc so we had to do some work there but in the end this thing was now actually very general and interesting tool which is apply a Gaussian process apply PDE apply nonlinearity repeat and then in the end collect all your information and make a prediction and it so some of the benefits are now that first of all of course you cannot work on a unstructured set of points doesn't have to be a grid and you can even learn the positions of those points so you can now direct the observations in places where you really need to do observations in order to improve your prediction so it basically becomes a numerical integration procedure where you can learn where to move your integration points and what I also found very is fascinating is that this same paradigm can be mapped on again onto a quantum paradigm where you can think of that PDE that evolves now as a Schrodinger equation that sort of evolves like a wave function so it maps very nicely also again to a quantum problem and that's what we are working on now something that's really fascinating that keeps coming up again and again and these sorts of research programs is the matrix exponential like it's our connection to groups and algebras or like group representations and algebras and of course we use it to evolve our ODEs and PDEs I guess as a physicist you've probably got a deeper appreciation of this particular object but it's something that's still quite alien to a lot of people I know that work in applied machine learning what's the significance of the matrix exponential why does it connect all these really fundamental objects to things like Lie groups and stuff like that yeah so it's interesting that we actually just got a paper accepted in noreps on this and it's called the convolution exponential and you can look it up and Emil Hogebaum is the sort of the main author and generator of that idea and yeah so I guess it because it is the solution to the ODE or the PDE right so if you write down something that's very fundamental that is the first order differential equation which is d dt the derivative with respect to t of a state is some operator times that state then the solution of that thing will be the state over time is the matrix exponential times t times the state so that's I think where it comes from and so one other way to look at it is that in physics it's called the Green's function so it's basically the solution to this ODE so you can think of a neural net as basically we tend to describe it as a discrete you know map from one point to another point but if you think of it as a continuous process which is what we learned from the ODE description of a neural net if you think of it as a continuous process then it's really you can just think of that convolution this map you can just think of it as the matrix exponential solution to this to this ODE in math literature you call this the Green's function so you can think of a convolution basically as the Green's function of a partial differential equation I think that's where the word where this feels like a very fundamental object in some sense so in in a talk you gave recently on the future of graph neural networks you were talking about a number of ideas from physics that hadn't really made it into machine learning among them things like renormalization chaos and holography would you care to unpack these ideas a little bit and tell us where you see the future is in these ideas yeah so the reason I mentioned these because I think there's a lot of really cool ideas in physics which are still remain unexplored but there is more and more physicists who are moving into the field and some of these ideas are actually you know being worked out as we speak so I recently saw about two papers on renormalization so renormalization is something in in physics which basically you start with a system with a whole lot of degrees of freedom like say particles moving around or something like this and then coarse grain the system slowly and what means is that by coarse graining you zoom out and you build an effective theory of the underlying theory in the same sense as thermodynamics is an effective theory of statistical mechanics where basically all the particles are now removed but you now have an effective sort of description of your world this is the same as what happens in neural nets right the neural nets we talk about pixels at the bottom layer and maybe edge detectors and things at the very top of it we're talking about objects and relations between objects which are aggregated emergent properties from this neural net and ideas from renormalization theory might very nicely apply to this particular problem and indeed have already been applied with some success the other one which you mentioned was chaos and I think there is a very nice connection actually with chaos theory going back to work I did a long time ago which are called herding in particular you can think of sampling from a particular distribution you can do it either by the typical way is first of all you can think of it as a dynamical system as a stochastic dynamical system and you think of it as there's a you're at a particular point and then you propose to go somewhere and then you accept or reject a particular point and then you just jump through the space and you collect your the points that you jumped to then you look at that collection and that collection should then actually distribute according to the probability distribution that you're sampling from now that's a stochastic process but if you think very hard about that in fact it's a deterministic process even if you try to make it stochastic and the reason is that every you know you're doing a whole bunch of calculations and so now and then you call a random number generator but the random number generator really is a pseudo random number generator it is also a deterministic calculation that you're doing so the whole thing end to end is just a a deterministic calculation but because you're calling the pseudo random number generator it looks very stochastic but truly it is a chaotic process and so you should really be able to describe the system by chaos theory and the theory of nonlinear dynamical systems now what I've been working on with my postdoc and Roberto we've been working on is thinking about let's make it a little bit less chaotic so let's make this actually a deterministic system which is maybe at the edge of chaos and again this is one of these very deep questions that's in my head so I think so there's there is something very interesting and deep here which is if you do if you try to do a computation on the one hand you want to store information things that you've calculated and for that things need to be stable on the other hand you want to transform information because that's what a calculation is right and so there you want to be in this sort of more chaotic domain and it turns out that the best place to be is at the edge of two things where you can go to the right a little bit and be more stable and go to the left a little bit and you can transform things and compute things and so I also think that when you're trying to sample or in you know sampling can be equated with learning if you're Bayesian about things because in learning is basically sampling from the posterior distribution and that's same as learning you can if you can design samplers that are not completely chaotic as the ones that we describe now but they're more structured and less chaotic and more deterministic moving through the space you can learn a lot faster and I find that and then you can actually start to map it onto sort of complexity theory notions if you think of this sampling from a discrete set of states what kind of properties do the sequences that I generate have what is the entropy of the sequences that I'm generating for instance or what kind of substructures is it for instance going to be periodic or are there periodic substructures inside of it or all these things and these are studied by the theory of chaos and nonlinear dynamical systems so connecting these two fields feels to me like a very fundamental thing to try and do and some people have tried a few things people have looked at well if you look at a neural net there's an iterated map you map things to hidden layers in later if you think of that iterated map and think of it as is that map chaotic being on the edge of chaos is the best thing you shouldn't be completely or nonmovable because then everything you put in is going to be mapped to the same point very uninteresting you also shouldn't be super chaotic because or whatever you put in you're going to some random point in space and that's not very predictive so you need to be at this intersection space between chaos and non- chaos and then you can do interesting computations so this is the same idea right so to me that's exciting because now suddenly a whole field of exciting mathematics is cracked open and you can start to use all these tools in machine learning awesome thank you fantastic now might be a good time to go over to reddit we asked reddit for questions and the top rated question is by tsa hi max when will you be changing your last name to pooling so actually there is a paper that a colleague of mine wrote and i think they had an operator instead of pooling you could you could do a a welling operator so and instead of changing my name i i propose that we just change the operators that we use and change to welling operators that's wonderful in the thread on reddit there were a few variations as well so maybe max power and someone asserted that pooling is your brother but anyway red portal says the conventional approach for analyzing continuous convolution would be Fourier analysis what was the rationale behind the investigating continuous convolutions using probabilistic numerics that's a good question so to me Fourier analysis it's true that you can i guess i could still do a Fourier analysis right because a Gaussian process you can decompose in terms of its Fourier waves and then it's the primal versus the dual view of a sort of any sort of kernel method so i could certainly go to the Fourier domain and do my calculations in the Fourier domain the quantum mechanics this is just another basis you just think of this as another basis you know not only quantum mechanics in any signal processing sense and it's true that a convolution is easier there because just multiplication on the other hand convolutions are very efficient in modern software packages for gpu so sometimes it's also not necessarily faster to do that but it's a good suggestion and maybe something nice happens when you go to Fourier space and i just didn't explore that fantastic we've also got jimmy the ant lion says hi max i notice your co-authors come from a physics background can you explain why there are so many x physicists in deep learning yeah so that's interesting i think there's just a lot of physicists and a fraction of those physicists is looking for other for greener pastures and i'm myself on one of those that i was looking for greener pastures and they bring a really good toolbox so if you're done physics you're you have just a very good mathematical toolbox but also very good intuition about PDEs and other world works and symmetries and all these kinds of things you bring and i think in some sense physics is also a bit of a container right if you do physics you can still do anything else afterwards in some sense and i think just there's just people who are naturally interested in in ai of course ai became very popular at some point and so you have automatically people flock into that into that field but yeah in general they're smart people so i guess it's nice to work with them maybe just circle back and close the loop to the beginning and we were talking about the research community and kind of the machine learning research field i i loved what you suggested and as i understand this is not fully your suggestion but the suggestion of let's say having a more open review kind of system where a review could be as powerful as a paper itself i've been screaming for this for a few years now and could i ask if you if you ever have the chance to propagate this what do you think of the idea of having a continuous research like this paper notion that we have now i think it's so outdated and once my paper is published i have no incentive to update that thing what what if we do research in in this much more continuous way and then there's comments and then in response to the comments everything changes and so on yeah no it's very good point it's it's so this is indeed exactly part of this idea that we are trying open review to implement yeah but it's the idea is that in open review you have a conversation with your reviewers and it's nice if the reviewers are not anonymous and just you just have your conversation and other people can even contribute to the project in a more open science way but it is also nice for now and then to present your work and so that's why i say so now and then a conference might come in and harvest papers and just invite people to present their work in sort of slightly more formal way and maybe put a stamp of approval on it and say this conference has published or this particular paper with some independent reviews and we think it's a great paper and so you get that stamp so it and i guess there should also be a way to close off a particular project to move on to a new project but i also have the same view as you have as this being a far more continuous process where you know if you didn't get picked this time next time somebody some conference will come by and pick you out this it's much more like a marketplace where ideas go around conferences come in and ask you to publish things and it's just you then present it and then you can just continue with your research or stop and then go to a new piece of work or something like this so yeah i i share that vision basically that's it's amazing i'm continuously amazed when i read these old papers from let's say schmid uber and like the first rl papers that just came up with a bit of an idea and then they had a bit of toy data and right and that's a paper and and it's cool do you have any do you have any kind of thoughts about or recommendations for the new generation of researchers that are now flooding the fields of how can we get to a better field what kind of tips would you give the yeah we i think we really need to disrupt the field a little bit and so i think we i think the new i think it's particularly tough for new researchers because it's the acceptance rates for these conferences are very low and it feels like much of your future career depends on getting papers in there and it's a fairly random process as well so i think we just need to disrupt the field and there's enough people with influence who want that so it's just a matter of actually executing on it and so that's what we do it now for the bayesian deep learning workshop that we are organizing this we want this to be a an off-split from new rips it was a very popular workshop there and somehow we got rejected this year and we thought okay we'll just do it ourselves we do have actually a meet-up but then next year we want to be our standalone conference but for that conference we want to implement this plan and so we are working with open review to actually implement this for us and jaren gall is working hard to try to actually roll this out we're talking to yashua benjo about it and he's very supportive and there's a whole lot of people who are supportive about it but so if this can help to make this a popular model then that will be a fantastic result of this interview but i think people should just push for it and just say okay i'm just fed up with the current way of doing things we should really change things and just a shout out and say this is what we want and let's go for it awesome amazing professor max welling it's been an absolute honor and a pleasure to have you on the show thank you so much for joining us today it was great with the three of you asking questions that works really well fantastic thank you so much thank you amazing it was good the questions were really fantastic actually and i've never done this with the three of you but having a team of three people asking questions is really it's a good idea and of course you're really smart people knowing what you're talking about so that went really well i think needs three brains to match yours anyway i really hope you've enjoyed the show today this has been such a special episode for us because max welling is is literally one one of my heroes so anyway remember to like comment and subscribe we love reading your comments we really do actually we're getting so many amazing comments in the comment section so keep them coming and we will see you back next week", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 19.92, "text": " Qualcomm AI Research is hiring for several machine learning openings, so please check", "tokens": [50364, 13616, 13278, 7318, 10303, 307, 15335, 337, 2940, 3479, 2539, 35941, 11, 370, 1767, 1520, 51360], "temperature": 0.0, "avg_logprob": -0.21716303295559353, "compression_ratio": 1.330827067669173, "no_speech_prob": 0.04002644494175911}, {"id": 1, "seek": 0, "start": 19.92, "end": 25.2, "text": " out their careers website if you're excited about solving the biggest problems with cutting", "tokens": [51360, 484, 641, 16409, 3144, 498, 291, 434, 2919, 466, 12606, 264, 3880, 2740, 365, 6492, 51624], "temperature": 0.0, "avg_logprob": -0.21716303295559353, "compression_ratio": 1.330827067669173, "no_speech_prob": 0.04002644494175911}, {"id": 2, "seek": 2520, "start": 25.2, "end": 34.96, "text": " edge AI research and improving the lives of billions of people.", "tokens": [50364, 4691, 7318, 2132, 293, 11470, 264, 2909, 295, 17375, 295, 561, 13, 50852], "temperature": 0.0, "avg_logprob": -0.20804200991235597, "compression_ratio": 1.6705426356589148, "no_speech_prob": 0.3230529725551605}, {"id": 3, "seek": 2520, "start": 34.96, "end": 40.879999999999995, "text": " Today we got to speak with one of our heroes in machine learning, Professor Max Welling.", "tokens": [50852, 2692, 321, 658, 281, 1710, 365, 472, 295, 527, 12332, 294, 3479, 2539, 11, 8419, 7402, 1042, 278, 13, 51148], "temperature": 0.0, "avg_logprob": -0.20804200991235597, "compression_ratio": 1.6705426356589148, "no_speech_prob": 0.3230529725551605}, {"id": 4, "seek": 2520, "start": 40.879999999999995, "end": 45.6, "text": " It was good, the questions were really fantastic actually and I've never done this with the", "tokens": [51148, 467, 390, 665, 11, 264, 1651, 645, 534, 5456, 767, 293, 286, 600, 1128, 1096, 341, 365, 264, 51384], "temperature": 0.0, "avg_logprob": -0.20804200991235597, "compression_ratio": 1.6705426356589148, "no_speech_prob": 0.3230529725551605}, {"id": 5, "seek": 2520, "start": 45.6, "end": 50.0, "text": " three of you but having a team of three people asking questions is really, it's a good idea", "tokens": [51384, 1045, 295, 291, 457, 1419, 257, 1469, 295, 1045, 561, 3365, 1651, 307, 534, 11, 309, 311, 257, 665, 1558, 51604], "temperature": 0.0, "avg_logprob": -0.20804200991235597, "compression_ratio": 1.6705426356589148, "no_speech_prob": 0.3230529725551605}, {"id": 6, "seek": 2520, "start": 50.0, "end": 53.92, "text": " and of course you're really smart people knowing what you're talking about so that went really", "tokens": [51604, 293, 295, 1164, 291, 434, 534, 4069, 561, 5276, 437, 291, 434, 1417, 466, 370, 300, 1437, 534, 51800], "temperature": 0.0, "avg_logprob": -0.20804200991235597, "compression_ratio": 1.6705426356589148, "no_speech_prob": 0.3230529725551605}, {"id": 7, "seek": 5392, "start": 54.72, "end": 59.6, "text": " well I think. Needs three brains to match yours. We asked Max some of your favorite questions", "tokens": [50404, 731, 286, 519, 13, 1734, 5147, 1045, 15442, 281, 2995, 6342, 13, 492, 2351, 7402, 512, 295, 428, 2954, 1651, 50648], "temperature": 0.0, "avg_logprob": -0.13258592514764694, "compression_ratio": 1.7131474103585658, "no_speech_prob": 0.01281432993710041}, {"id": 8, "seek": 5392, "start": 59.6, "end": 63.760000000000005, "text": " from Reddit. Hi Max, when will you be changing your last name to pooling?", "tokens": [50648, 490, 32210, 13, 2421, 7402, 11, 562, 486, 291, 312, 4473, 428, 1036, 1315, 281, 7005, 278, 30, 50856], "temperature": 0.0, "avg_logprob": -0.13258592514764694, "compression_ratio": 1.7131474103585658, "no_speech_prob": 0.01281432993710041}, {"id": 9, "seek": 5392, "start": 65.92, "end": 71.36, "text": " Max has pioneered the discipline of non-euclidean geometric deep learning.", "tokens": [50964, 7402, 575, 19761, 4073, 264, 13635, 295, 2107, 12, 68, 1311, 31264, 282, 33246, 2452, 2539, 13, 51236], "temperature": 0.0, "avg_logprob": -0.13258592514764694, "compression_ratio": 1.7131474103585658, "no_speech_prob": 0.01281432993710041}, {"id": 10, "seek": 5392, "start": 71.36, "end": 77.6, "text": " So what is actually geometric deep learning? It's the idea of performing deep learning or", "tokens": [51236, 407, 437, 307, 767, 33246, 2452, 2539, 30, 467, 311, 264, 1558, 295, 10205, 2452, 2539, 420, 51548], "temperature": 0.0, "avg_logprob": -0.13258592514764694, "compression_ratio": 1.7131474103585658, "no_speech_prob": 0.01281432993710041}, {"id": 11, "seek": 5392, "start": 77.6, "end": 82.8, "text": " machine learning more generally but let's say deep learning on data that is not euclidean in some", "tokens": [51548, 3479, 2539, 544, 5101, 457, 718, 311, 584, 2452, 2539, 322, 1412, 300, 307, 406, 308, 1311, 31264, 282, 294, 512, 51808], "temperature": 0.0, "avg_logprob": -0.13258592514764694, "compression_ratio": 1.7131474103585658, "no_speech_prob": 0.01281432993710041}, {"id": 12, "seek": 8280, "start": 82.8, "end": 92.47999999999999, "text": " sense so not a nice chain structure for audio or a planar structure for images but perhaps a sphere", "tokens": [50364, 2020, 370, 406, 257, 1481, 5021, 3877, 337, 6278, 420, 257, 1393, 289, 3877, 337, 5267, 457, 4317, 257, 16687, 50848], "temperature": 0.0, "avg_logprob": -0.08161019711267381, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.0017004819819703698}, {"id": 13, "seek": 8280, "start": 92.47999999999999, "end": 98.0, "text": " or graph or something more exotic like some kind of manifold with arbitrary curvature.", "tokens": [50848, 420, 4295, 420, 746, 544, 27063, 411, 512, 733, 295, 47138, 365, 23211, 37638, 13, 51124], "temperature": 0.0, "avg_logprob": -0.08161019711267381, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.0017004819819703698}, {"id": 14, "seek": 8280, "start": 98.72, "end": 102.96, "text": " You might want to model weather patterns or social interaction data. There are many types", "tokens": [51160, 509, 1062, 528, 281, 2316, 5503, 8294, 420, 2093, 9285, 1412, 13, 821, 366, 867, 3467, 51372], "temperature": 0.0, "avg_logprob": -0.08161019711267381, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.0017004819819703698}, {"id": 15, "seek": 8280, "start": 102.96, "end": 108.72, "text": " of data out there that are non-euclidean. Actually if you've been playing with graph neural networks", "tokens": [51372, 295, 1412, 484, 456, 300, 366, 2107, 12, 68, 1311, 31264, 282, 13, 5135, 498, 291, 600, 668, 2433, 365, 4295, 18161, 9590, 51660], "temperature": 0.0, "avg_logprob": -0.08161019711267381, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.0017004819819703698}, {"id": 16, "seek": 10872, "start": 108.72, "end": 114.08, "text": " then you've already been doing non-euclidean or geometric deep learning. So to make this work", "tokens": [50364, 550, 291, 600, 1217, 668, 884, 2107, 12, 68, 1311, 31264, 282, 420, 33246, 2452, 2539, 13, 407, 281, 652, 341, 589, 50632], "temperature": 0.0, "avg_logprob": -0.0685304034072741, "compression_ratio": 1.6341463414634145, "no_speech_prob": 0.00145478337071836}, {"id": 17, "seek": 10872, "start": 114.08, "end": 119.68, "text": " you just need to abstract some concepts so the euclidean distance or your neighborhood", "tokens": [50632, 291, 445, 643, 281, 12649, 512, 10392, 370, 264, 308, 1311, 31264, 282, 4560, 420, 428, 7630, 50912], "temperature": 0.0, "avg_logprob": -0.0685304034072741, "compression_ratio": 1.6341463414634145, "no_speech_prob": 0.00145478337071836}, {"id": 18, "seek": 10872, "start": 119.68, "end": 125.36, "text": " it becomes a function of connectedness just like on a social graph. Am I connected to John? Does John", "tokens": [50912, 309, 3643, 257, 2445, 295, 4582, 1287, 445, 411, 322, 257, 2093, 4295, 13, 2012, 286, 4582, 281, 2619, 30, 4402, 2619, 51196], "temperature": 0.0, "avg_logprob": -0.0685304034072741, "compression_ratio": 1.6341463414634145, "no_speech_prob": 0.00145478337071836}, {"id": 19, "seek": 10872, "start": 125.36, "end": 131.76, "text": " know Bob? Simple as that. Actually this kind of abstraction works in many areas of mathematics", "tokens": [51196, 458, 6085, 30, 21532, 382, 300, 13, 5135, 341, 733, 295, 37765, 1985, 294, 867, 3179, 295, 18666, 51516], "temperature": 0.0, "avg_logprob": -0.0685304034072741, "compression_ratio": 1.6341463414634145, "no_speech_prob": 0.00145478337071836}, {"id": 20, "seek": 10872, "start": 131.76, "end": 136.72, "text": " which Max will get into today as well as making neural networks work on non-euclidean data.", "tokens": [51516, 597, 7402, 486, 483, 666, 965, 382, 731, 382, 1455, 18161, 9590, 589, 322, 2107, 12, 68, 1311, 31264, 282, 1412, 13, 51764], "temperature": 0.0, "avg_logprob": -0.0685304034072741, "compression_ratio": 1.6341463414634145, "no_speech_prob": 0.00145478337071836}, {"id": 21, "seek": 13672, "start": 136.72, "end": 142.0, "text": " The other thing that Max has really pioneered is this idea of recognizing symmetries", "tokens": [50364, 440, 661, 551, 300, 7402, 575, 534, 19761, 4073, 307, 341, 1558, 295, 18538, 14232, 302, 2244, 50628], "temperature": 0.0, "avg_logprob": -0.04344630963874586, "compression_ratio": 1.7509578544061302, "no_speech_prob": 0.0009677076013758779}, {"id": 22, "seek": 13672, "start": 142.0, "end": 147.44, "text": " in different manifolds. So in this blank slate paradigm that we have now in neural networks", "tokens": [50628, 294, 819, 8173, 31518, 13, 407, 294, 341, 8247, 39118, 24709, 300, 321, 362, 586, 294, 18161, 9590, 50900], "temperature": 0.0, "avg_logprob": -0.04344630963874586, "compression_ratio": 1.7509578544061302, "no_speech_prob": 0.0009677076013758779}, {"id": 23, "seek": 13672, "start": 147.44, "end": 152.64, "text": " we're essentially wasting the representational capacity of the neural network because we're", "tokens": [50900, 321, 434, 4476, 20457, 264, 2906, 1478, 6042, 295, 264, 18161, 3209, 570, 321, 434, 51160], "temperature": 0.0, "avg_logprob": -0.04344630963874586, "compression_ratio": 1.7509578544061302, "no_speech_prob": 0.0009677076013758779}, {"id": 24, "seek": 13672, "start": 152.64, "end": 158.56, "text": " just learning the same thing again and again. For example in a fully connected neural network", "tokens": [51160, 445, 2539, 264, 912, 551, 797, 293, 797, 13, 1171, 1365, 294, 257, 4498, 4582, 18161, 3209, 51456], "temperature": 0.0, "avg_logprob": -0.04344630963874586, "compression_ratio": 1.7509578544061302, "no_speech_prob": 0.0009677076013758779}, {"id": 25, "seek": 13672, "start": 158.56, "end": 163.76, "text": " we would have to learn the dog in the top right corner and the top left corner because there's", "tokens": [51456, 321, 576, 362, 281, 1466, 264, 3000, 294, 264, 1192, 558, 4538, 293, 264, 1192, 1411, 4538, 570, 456, 311, 51716], "temperature": 0.0, "avg_logprob": -0.04344630963874586, "compression_ratio": 1.7509578544061302, "no_speech_prob": 0.0009677076013758779}, {"id": 26, "seek": 16376, "start": 163.76, "end": 169.2, "text": " no translational symmetry. And it was exactly this reason why convolutional neural networks were so", "tokens": [50364, 572, 5105, 1478, 25440, 13, 400, 309, 390, 2293, 341, 1778, 983, 45216, 304, 18161, 9590, 645, 370, 50636], "temperature": 0.0, "avg_logprob": -0.06539604923512676, "compression_ratio": 1.7295373665480427, "no_speech_prob": 0.0015002739382907748}, {"id": 27, "seek": 16376, "start": 169.2, "end": 175.2, "text": " powerful because they introduced this concept of translational weight sharing. So you had this", "tokens": [50636, 4005, 570, 436, 7268, 341, 3410, 295, 5105, 1478, 3364, 5414, 13, 407, 291, 632, 341, 50936], "temperature": 0.0, "avg_logprob": -0.06539604923512676, "compression_ratio": 1.7295373665480427, "no_speech_prob": 0.0015002739382907748}, {"id": 28, "seek": 16376, "start": 175.2, "end": 181.51999999999998, "text": " filter that you could shine over the entire planar manifold and it meant that those parameters could", "tokens": [50936, 6608, 300, 291, 727, 12207, 670, 264, 2302, 1393, 289, 47138, 293, 309, 4140, 300, 729, 9834, 727, 51252], "temperature": 0.0, "avg_logprob": -0.06539604923512676, "compression_ratio": 1.7295373665480427, "no_speech_prob": 0.0015002739382907748}, {"id": 29, "seek": 16376, "start": 181.51999999999998, "end": 187.28, "text": " be reused and you could learn concepts in different parts of the visual field. It was an incredible", "tokens": [51252, 312, 319, 4717, 293, 291, 727, 1466, 10392, 294, 819, 3166, 295, 264, 5056, 2519, 13, 467, 390, 364, 4651, 51540], "temperature": 0.0, "avg_logprob": -0.06539604923512676, "compression_ratio": 1.7295373665480427, "no_speech_prob": 0.0015002739382907748}, {"id": 30, "seek": 16376, "start": 187.28, "end": 192.79999999999998, "text": " breakthrough. Imputing this kind of knowledge into a deep learning model this is called an", "tokens": [51540, 22397, 13, 8270, 10861, 341, 733, 295, 3601, 666, 257, 2452, 2539, 2316, 341, 307, 1219, 364, 51816], "temperature": 0.0, "avg_logprob": -0.06539604923512676, "compression_ratio": 1.7295373665480427, "no_speech_prob": 0.0015002739382907748}, {"id": 31, "seek": 19280, "start": 192.8, "end": 197.84, "text": " inductive prior. It means that we can take some prior knowledge about how things in the world", "tokens": [50364, 31612, 488, 4059, 13, 467, 1355, 300, 321, 393, 747, 512, 4059, 3601, 466, 577, 721, 294, 264, 1002, 50616], "temperature": 0.0, "avg_logprob": -0.050429103571340575, "compression_ratio": 1.723021582733813, "no_speech_prob": 0.001500584534369409}, {"id": 32, "seek": 19280, "start": 197.84, "end": 203.36, "text": " works and we can impute them into our models. It makes our models more sample efficient and it", "tokens": [50616, 1985, 293, 321, 393, 704, 1169, 552, 666, 527, 5245, 13, 467, 1669, 527, 5245, 544, 6889, 7148, 293, 309, 50892], "temperature": 0.0, "avg_logprob": -0.050429103571340575, "compression_ratio": 1.723021582733813, "no_speech_prob": 0.001500584534369409}, {"id": 33, "seek": 19280, "start": 203.36, "end": 209.44, "text": " makes them generalize better. When it comes to sophisticated inductive priors Max Welling is the", "tokens": [50892, 1669, 552, 2674, 1125, 1101, 13, 1133, 309, 1487, 281, 16950, 31612, 488, 1790, 830, 7402, 1042, 278, 307, 264, 51196], "temperature": 0.0, "avg_logprob": -0.050429103571340575, "compression_ratio": 1.723021582733813, "no_speech_prob": 0.001500584534369409}, {"id": 34, "seek": 19280, "start": 209.44, "end": 215.92000000000002, "text": " king. When we think about AI and its capability to actually help us to enrich our lives we know", "tokens": [51196, 4867, 13, 1133, 321, 519, 466, 7318, 293, 1080, 13759, 281, 767, 854, 505, 281, 18849, 527, 2909, 321, 458, 51520], "temperature": 0.0, "avg_logprob": -0.050429103571340575, "compression_ratio": 1.723021582733813, "no_speech_prob": 0.001500584534369409}, {"id": 35, "seek": 19280, "start": 215.92000000000002, "end": 222.16000000000003, "text": " we need to first help machines see and understand like humans do. Take this drone collecting data", "tokens": [51520, 321, 643, 281, 700, 854, 8379, 536, 293, 1223, 411, 6255, 360, 13, 3664, 341, 13852, 12510, 1412, 51832], "temperature": 0.0, "avg_logprob": -0.050429103571340575, "compression_ratio": 1.723021582733813, "no_speech_prob": 0.001500584534369409}, {"id": 36, "seek": 22216, "start": 222.16, "end": 229.92, "text": " in 3D or this autonomous vehicle with cameras covering a 360 degrees view. Current deep learning", "tokens": [50364, 294, 805, 35, 420, 341, 23797, 5864, 365, 8622, 10322, 257, 13898, 5310, 1910, 13, 15629, 2452, 2539, 50752], "temperature": 0.0, "avg_logprob": -0.09226690741146312, "compression_ratio": 1.5303643724696356, "no_speech_prob": 0.006190994754433632}, {"id": 37, "seek": 22216, "start": 229.92, "end": 235.68, "text": " technology can analyze 2D images very well. But how can we teach a machine to make sense of image", "tokens": [50752, 2899, 393, 12477, 568, 35, 5267, 588, 731, 13, 583, 577, 393, 321, 2924, 257, 3479, 281, 652, 2020, 295, 3256, 51040], "temperature": 0.0, "avg_logprob": -0.09226690741146312, "compression_ratio": 1.5303643724696356, "no_speech_prob": 0.006190994754433632}, {"id": 38, "seek": 22216, "start": 235.68, "end": 241.6, "text": " data from a curved object like a sphere? And because we want this processing to happen on the", "tokens": [51040, 1412, 490, 257, 24991, 2657, 411, 257, 16687, 30, 400, 570, 321, 528, 341, 9007, 281, 1051, 322, 264, 51336], "temperature": 0.0, "avg_logprob": -0.09226690741146312, "compression_ratio": 1.5303643724696356, "no_speech_prob": 0.006190994754433632}, {"id": 39, "seek": 22216, "start": 241.6, "end": 247.76, "text": " device itself for reliability, immediacy and privacy reasons how can we achieve this in a", "tokens": [51336, 4302, 2564, 337, 24550, 11, 3640, 2551, 293, 11427, 4112, 577, 393, 321, 4584, 341, 294, 257, 51644], "temperature": 0.0, "avg_logprob": -0.09226690741146312, "compression_ratio": 1.5303643724696356, "no_speech_prob": 0.006190994754433632}, {"id": 40, "seek": 24776, "start": 247.76, "end": 253.28, "text": " power efficient manner? It turns out we can do this by applying the mathematics behind general", "tokens": [50364, 1347, 7148, 9060, 30, 467, 4523, 484, 321, 393, 360, 341, 538, 9275, 264, 18666, 2261, 2674, 50640], "temperature": 0.0, "avg_logprob": -0.0878360338300188, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.11584145575761795}, {"id": 41, "seek": 24776, "start": 253.28, "end": 258.88, "text": " relativity and quantum field theory to deep learning. Our neural network takes in data on", "tokens": [50640, 45675, 293, 13018, 2519, 5261, 281, 2452, 2539, 13, 2621, 18161, 3209, 2516, 294, 1412, 322, 50920], "temperature": 0.0, "avg_logprob": -0.0878360338300188, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.11584145575761795}, {"id": 42, "seek": 24776, "start": 258.88, "end": 264.56, "text": " virtually any kind of curved object and applies a new type of convolution to it. We can move the", "tokens": [50920, 14103, 604, 733, 295, 24991, 2657, 293, 13165, 257, 777, 2010, 295, 45216, 281, 309, 13, 492, 393, 1286, 264, 51204], "temperature": 0.0, "avg_logprob": -0.0878360338300188, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.11584145575761795}, {"id": 43, "seek": 24776, "start": 264.56, "end": 270.32, "text": " shape around and the AI will still recognize it. This is just one example of the exciting research", "tokens": [51204, 3909, 926, 293, 264, 7318, 486, 920, 5521, 309, 13, 639, 307, 445, 472, 1365, 295, 264, 4670, 2132, 51492], "temperature": 0.0, "avg_logprob": -0.0878360338300188, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.11584145575761795}, {"id": 44, "seek": 24776, "start": 270.32, "end": 276.48, "text": " we're doing at Falkamea research to shape AI in the near future. Anyway it turns out that these", "tokens": [51492, 321, 434, 884, 412, 479, 667, 529, 64, 2132, 281, 3909, 7318, 294, 264, 2651, 2027, 13, 5684, 309, 4523, 484, 300, 613, 51800], "temperature": 0.0, "avg_logprob": -0.0878360338300188, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.11584145575761795}, {"id": 45, "seek": 27648, "start": 276.48, "end": 282.16, "text": " symmetries are absolutely everywhere. If you wanted any further proof of how useful these kind", "tokens": [50364, 14232, 302, 2244, 366, 3122, 5315, 13, 759, 291, 1415, 604, 3052, 8177, 295, 577, 4420, 613, 733, 50648], "temperature": 0.0, "avg_logprob": -0.10980838278065556, "compression_ratio": 1.5661157024793388, "no_speech_prob": 0.0011159186251461506}, {"id": 46, "seek": 27648, "start": 282.16, "end": 288.0, "text": " of equivariants and symmetries and manifolds can be, look no further than the recent announcement", "tokens": [50648, 295, 1267, 592, 3504, 1719, 293, 14232, 302, 2244, 293, 8173, 31518, 393, 312, 11, 574, 572, 3052, 813, 264, 5162, 12847, 50940], "temperature": 0.0, "avg_logprob": -0.10980838278065556, "compression_ratio": 1.5661157024793388, "no_speech_prob": 0.0011159186251461506}, {"id": 47, "seek": 27648, "start": 288.0, "end": 298.48, "text": " from DeepMind AlphaFold. It will change everything. DeepMind solves 50 year old grand challenge.", "tokens": [50940, 490, 14895, 44, 471, 20588, 37, 2641, 13, 467, 486, 1319, 1203, 13, 14895, 44, 471, 39890, 2625, 1064, 1331, 2697, 3430, 13, 51464], "temperature": 0.0, "avg_logprob": -0.10980838278065556, "compression_ratio": 1.5661157024793388, "no_speech_prob": 0.0011159186251461506}, {"id": 48, "seek": 27648, "start": 298.48, "end": 306.16, "text": " The game has changed. So proteins are the structures that fold in a given way. The result", "tokens": [51464, 440, 1216, 575, 3105, 13, 407, 15577, 366, 264, 9227, 300, 4860, 294, 257, 2212, 636, 13, 440, 1874, 51848], "temperature": 0.0, "avg_logprob": -0.10980838278065556, "compression_ratio": 1.5661157024793388, "no_speech_prob": 0.0011159186251461506}, {"id": 49, "seek": 30616, "start": 306.16, "end": 313.52000000000004, "text": " of this year's competition came out and they looked something like this. Namely every entry here you", "tokens": [50364, 295, 341, 1064, 311, 6211, 1361, 484, 293, 436, 2956, 746, 411, 341, 13, 10684, 736, 633, 8729, 510, 291, 50732], "temperature": 0.0, "avg_logprob": -0.0930598649111661, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.011325472965836525}, {"id": 50, "seek": 30616, "start": 313.52000000000004, "end": 321.84000000000003, "text": " see is a team participating in that competition of protein folding prediction and there is one team", "tokens": [50732, 536, 307, 257, 1469, 13950, 294, 300, 6211, 295, 7944, 25335, 17630, 293, 456, 307, 472, 1469, 51148], "temperature": 0.0, "avg_logprob": -0.0930598649111661, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.011325472965836525}, {"id": 51, "seek": 30616, "start": 321.84000000000003, "end": 331.12, "text": " which is DeepMind's system AlphaFold 2 which completely dominates all the others to the point", "tokens": [51148, 597, 307, 14895, 44, 471, 311, 1185, 20588, 37, 2641, 568, 597, 2584, 8859, 1024, 439, 264, 2357, 281, 264, 935, 51612], "temperature": 0.0, "avg_logprob": -0.0930598649111661, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.011325472965836525}, {"id": 52, "seek": 33112, "start": 331.12, "end": 338.16, "text": " where the problem is now considered to be solved. By the way if this is not a great meme template", "tokens": [50364, 689, 264, 1154, 307, 586, 4888, 281, 312, 13041, 13, 3146, 264, 636, 498, 341, 307, 406, 257, 869, 21701, 12379, 50716], "temperature": 0.0, "avg_logprob": -0.12594745085411466, "compression_ratio": 1.662551440329218, "no_speech_prob": 0.06848867237567902}, {"id": 53, "seek": 33112, "start": 338.16, "end": 345.04, "text": " I don't know what is. Just saying. Just saying. They say a folded protein can be thought of as a spatial", "tokens": [50716, 286, 500, 380, 458, 437, 307, 13, 1449, 1566, 13, 1449, 1566, 13, 814, 584, 257, 23940, 7944, 393, 312, 1194, 295, 382, 257, 23598, 51060], "temperature": 0.0, "avg_logprob": -0.12594745085411466, "compression_ratio": 1.662551440329218, "no_speech_prob": 0.06848867237567902}, {"id": 54, "seek": 33112, "start": 345.04, "end": 353.92, "text": " graph. This here attention-based okay. So I'm going to guess for sure that they've replaced this convet", "tokens": [51060, 4295, 13, 639, 510, 3202, 12, 6032, 1392, 13, 407, 286, 478, 516, 281, 2041, 337, 988, 300, 436, 600, 10772, 341, 416, 9771, 51504], "temperature": 0.0, "avg_logprob": -0.12594745085411466, "compression_ratio": 1.662551440329218, "no_speech_prob": 0.06848867237567902}, {"id": 55, "seek": 33112, "start": 353.92, "end": 360.48, "text": " with a transformer style with an attention layer or multiple attention layers. I would guess this", "tokens": [51504, 365, 257, 31782, 3758, 365, 364, 3202, 4583, 420, 3866, 3202, 7914, 13, 286, 576, 2041, 341, 51832], "temperature": 0.0, "avg_logprob": -0.12594745085411466, "compression_ratio": 1.662551440329218, "no_speech_prob": 0.06848867237567902}, {"id": 56, "seek": 36048, "start": 360.48, "end": 364.96000000000004, "text": " is a big transformer right here. So there was a really interesting article that came out called", "tokens": [50364, 307, 257, 955, 31782, 558, 510, 13, 407, 456, 390, 257, 534, 1880, 7222, 300, 1361, 484, 1219, 50588], "temperature": 0.0, "avg_logprob": -0.1258544155529567, "compression_ratio": 1.5902777777777777, "no_speech_prob": 0.0025478757452219725}, {"id": 57, "seek": 36048, "start": 364.96000000000004, "end": 371.6, "text": " AlphaFold and Equivariance by Justas Duparas and Fabian Fuchs. I'm so sorry Fabian I don't", "tokens": [50588, 20588, 37, 2641, 293, 15624, 592, 3504, 719, 538, 1449, 296, 413, 1010, 35867, 293, 17440, 952, 479, 37503, 13, 286, 478, 370, 2597, 17440, 952, 286, 500, 380, 50920], "temperature": 0.0, "avg_logprob": -0.1258544155529567, "compression_ratio": 1.5902777777777777, "no_speech_prob": 0.0025478757452219725}, {"id": 58, "seek": 36048, "start": 371.6, "end": 376.8, "text": " know how to pronounce your name but it does sound like a swear word. Justas and Fabian Etow", "tokens": [50920, 458, 577, 281, 19567, 428, 1315, 457, 309, 775, 1626, 411, 257, 11902, 1349, 13, 1449, 296, 293, 17440, 952, 3790, 305, 51180], "temperature": 0.0, "avg_logprob": -0.1258544155529567, "compression_ratio": 1.5902777777777777, "no_speech_prob": 0.0025478757452219725}, {"id": 59, "seek": 36048, "start": 376.8, "end": 383.12, "text": " comment on the announcement from DeepMind and they said in short this module is a neural network", "tokens": [51180, 2871, 322, 264, 12847, 490, 14895, 44, 471, 293, 436, 848, 294, 2099, 341, 10088, 307, 257, 18161, 3209, 51496], "temperature": 0.0, "avg_logprob": -0.1258544155529567, "compression_ratio": 1.5902777777777777, "no_speech_prob": 0.0025478757452219725}, {"id": 60, "seek": 36048, "start": 383.12, "end": 388.40000000000003, "text": " that iteratively refines the structure predictions while respecting and leveraging", "tokens": [51496, 300, 17138, 19020, 1895, 1652, 264, 3877, 21264, 1339, 41968, 293, 32666, 51760], "temperature": 0.0, "avg_logprob": -0.1258544155529567, "compression_ratio": 1.5902777777777777, "no_speech_prob": 0.0025478757452219725}, {"id": 61, "seek": 38840, "start": 388.47999999999996, "end": 394.88, "text": " an important symmetry of the problem. Namely that of rototranslations. At this point DeepMind has not", "tokens": [50368, 364, 1021, 25440, 295, 264, 1154, 13, 10684, 736, 300, 295, 4297, 310, 25392, 75, 763, 13, 1711, 341, 935, 14895, 44, 471, 575, 406, 50688], "temperature": 0.0, "avg_logprob": -0.08832763396587569, "compression_ratio": 1.5719844357976653, "no_speech_prob": 0.011667545884847641}, {"id": 62, "seek": 38840, "start": 394.88, "end": 400.23999999999995, "text": " yet published a paper so we don't know exactly how they address this. However from their presentations", "tokens": [50688, 1939, 6572, 257, 3035, 370, 321, 500, 380, 458, 2293, 577, 436, 2985, 341, 13, 2908, 490, 641, 18964, 50956], "temperature": 0.0, "avg_logprob": -0.08832763396587569, "compression_ratio": 1.5719844357976653, "no_speech_prob": 0.011667545884847641}, {"id": 63, "seek": 38840, "start": 400.23999999999995, "end": 408.4, "text": " it seems possible that part of their architecture is similar to the SE3 transformer. What's the SE3", "tokens": [50956, 309, 2544, 1944, 300, 644, 295, 641, 9482, 307, 2531, 281, 264, 10269, 18, 31782, 13, 708, 311, 264, 10269, 18, 51364], "temperature": 0.0, "avg_logprob": -0.08832763396587569, "compression_ratio": 1.5719844357976653, "no_speech_prob": 0.011667545884847641}, {"id": 64, "seek": 38840, "start": 408.4, "end": 417.44, "text": " transformer? Lo and behold our friend Max Welling has had his hands all over it. So in the abstract", "tokens": [51364, 31782, 30, 6130, 293, 27234, 527, 1277, 7402, 1042, 278, 575, 632, 702, 2377, 439, 670, 309, 13, 407, 294, 264, 12649, 51816], "temperature": 0.0, "avg_logprob": -0.08832763396587569, "compression_ratio": 1.5719844357976653, "no_speech_prob": 0.011667545884847641}, {"id": 65, "seek": 41744, "start": 417.44, "end": 423.36, "text": " it says the SE3 transformer a variant of the self-attention module for 3d point clouds and graphs", "tokens": [50364, 309, 1619, 264, 10269, 18, 31782, 257, 17501, 295, 264, 2698, 12, 1591, 1251, 10088, 337, 805, 67, 935, 12193, 293, 24877, 50660], "temperature": 0.0, "avg_logprob": -0.07599996043517526, "compression_ratio": 1.6879432624113475, "no_speech_prob": 0.0003796689270529896}, {"id": 66, "seek": 41744, "start": 423.36, "end": 430.08, "text": " which is equivariant under continuous 3d rototranslations. Equivariant is important to ensure", "tokens": [50660, 597, 307, 1267, 592, 3504, 394, 833, 10957, 805, 67, 4297, 310, 25392, 75, 763, 13, 15624, 592, 3504, 394, 307, 1021, 281, 5586, 50996], "temperature": 0.0, "avg_logprob": -0.07599996043517526, "compression_ratio": 1.6879432624113475, "no_speech_prob": 0.0003796689270529896}, {"id": 67, "seek": 41744, "start": 430.08, "end": 435.28, "text": " stable and predictable performance in the presence of nuisance transformations of the data input.", "tokens": [50996, 8351, 293, 27737, 3389, 294, 264, 6814, 295, 3822, 46852, 34852, 295, 264, 1412, 4846, 13, 51256], "temperature": 0.0, "avg_logprob": -0.07599996043517526, "compression_ratio": 1.6879432624113475, "no_speech_prob": 0.0003796689270529896}, {"id": 68, "seek": 41744, "start": 435.28, "end": 440.0, "text": " Right by the way you might be wondering what SE3 is. Let's have a quick look at the Wikipedia", "tokens": [51256, 1779, 538, 264, 636, 291, 1062, 312, 6359, 437, 10269, 18, 307, 13, 961, 311, 362, 257, 1702, 574, 412, 264, 28999, 51492], "temperature": 0.0, "avg_logprob": -0.07599996043517526, "compression_ratio": 1.6879432624113475, "no_speech_prob": 0.0003796689270529896}, {"id": 69, "seek": 41744, "start": 440.0, "end": 444.96, "text": " page. We are getting into group theory which is quite an abstract concept in mathematics but", "tokens": [51492, 3028, 13, 492, 366, 1242, 666, 1594, 5261, 597, 307, 1596, 364, 12649, 3410, 294, 18666, 457, 51740], "temperature": 0.0, "avg_logprob": -0.07599996043517526, "compression_ratio": 1.6879432624113475, "no_speech_prob": 0.0003796689270529896}, {"id": 70, "seek": 44496, "start": 444.96, "end": 451.84, "text": " the Euclidean group which is SE3 it talks about all of the symmetries or the group transformations", "tokens": [50364, 264, 462, 1311, 31264, 282, 1594, 597, 307, 10269, 18, 309, 6686, 466, 439, 295, 264, 14232, 302, 2244, 420, 264, 1594, 34852, 50708], "temperature": 0.0, "avg_logprob": -0.060101368597575595, "compression_ratio": 1.7198581560283688, "no_speech_prob": 0.0026217172853648663}, {"id": 71, "seek": 44496, "start": 451.84, "end": 459.44, "text": " that can be applied to Euclidean data to preserve certain properties. Namely let's say the Euclidean", "tokens": [50708, 300, 393, 312, 6456, 281, 462, 1311, 31264, 282, 1412, 281, 15665, 1629, 7221, 13, 10684, 736, 718, 311, 584, 264, 462, 1311, 31264, 282, 51088], "temperature": 0.0, "avg_logprob": -0.060101368597575595, "compression_ratio": 1.7198581560283688, "no_speech_prob": 0.0026217172853648663}, {"id": 72, "seek": 44496, "start": 459.44, "end": 463.84, "text": " distance between two points. Well these are things like translations and rotations and", "tokens": [51088, 4560, 1296, 732, 2793, 13, 1042, 613, 366, 721, 411, 37578, 293, 44796, 293, 51308], "temperature": 0.0, "avg_logprob": -0.060101368597575595, "compression_ratio": 1.7198581560283688, "no_speech_prob": 0.0026217172853648663}, {"id": 73, "seek": 44496, "start": 463.84, "end": 469.2, "text": " reflections. Very interesting that you can kind of abstract one level up in mathematics and that's", "tokens": [51308, 30679, 13, 4372, 1880, 300, 291, 393, 733, 295, 12649, 472, 1496, 493, 294, 18666, 293, 300, 311, 51576], "temperature": 0.0, "avg_logprob": -0.060101368597575595, "compression_ratio": 1.7198581560283688, "no_speech_prob": 0.0026217172853648663}, {"id": 74, "seek": 44496, "start": 469.2, "end": 473.35999999999996, "text": " what group theory is. The other comment I want to make is that all of these folks are independently", "tokens": [51576, 437, 1594, 5261, 307, 13, 440, 661, 2871, 286, 528, 281, 652, 307, 300, 439, 295, 613, 4024, 366, 21761, 51784], "temperature": 0.0, "avg_logprob": -0.060101368597575595, "compression_ratio": 1.7198581560283688, "no_speech_prob": 0.0026217172853648663}, {"id": 75, "seek": 47336, "start": 473.44, "end": 477.2, "text": " amazing. I've watched presentations by most of them so that there's Fabian Fuchs,", "tokens": [50368, 2243, 13, 286, 600, 6337, 18964, 538, 881, 295, 552, 370, 300, 456, 311, 17440, 952, 479, 37503, 11, 50556], "temperature": 0.0, "avg_logprob": -0.1203222182190534, "compression_ratio": 1.602787456445993, "no_speech_prob": 0.01969113200902939}, {"id": 76, "seek": 47336, "start": 477.2, "end": 484.40000000000003, "text": " Daniel Worrell, Volker Fischer, fantastic. By the way when we look at Fabian's About Me page", "tokens": [50556, 8033, 26363, 19771, 11, 8911, 5767, 479, 19674, 11, 5456, 13, 3146, 264, 636, 562, 321, 574, 412, 17440, 952, 311, 7769, 1923, 3028, 50916], "temperature": 0.0, "avg_logprob": -0.1203222182190534, "compression_ratio": 1.602787456445993, "no_speech_prob": 0.01969113200902939}, {"id": 77, "seek": 47336, "start": 484.40000000000003, "end": 489.2, "text": " he's a machine learning PhD student at Oxford University. His research topic is learning", "tokens": [50916, 415, 311, 257, 3479, 2539, 14476, 3107, 412, 24786, 3535, 13, 2812, 2132, 4829, 307, 2539, 51156], "temperature": 0.0, "avg_logprob": -0.1203222182190534, "compression_ratio": 1.602787456445993, "no_speech_prob": 0.01969113200902939}, {"id": 78, "seek": 47336, "start": 489.2, "end": 494.16, "text": " invariant representations. Simply put where most of deep learning is concerned with finding the", "tokens": [51156, 33270, 394, 33358, 13, 19596, 829, 689, 881, 295, 2452, 2539, 307, 5922, 365, 5006, 264, 51404], "temperature": 0.0, "avg_logprob": -0.1203222182190534, "compression_ratio": 1.602787456445993, "no_speech_prob": 0.01969113200902939}, {"id": 79, "seek": 47336, "start": 494.16, "end": 500.56, "text": " important information in an input he focuses on ignoring harmful or irrelevant parts of information.", "tokens": [51404, 1021, 1589, 294, 364, 4846, 415, 16109, 322, 26258, 19727, 420, 28682, 3166, 295, 1589, 13, 51724], "temperature": 0.0, "avg_logprob": -0.1203222182190534, "compression_ratio": 1.602787456445993, "no_speech_prob": 0.01969113200902939}, {"id": 80, "seek": 50056, "start": 500.56, "end": 505.84, "text": " This can be important to counteract biases or to better leverage structure in the data.", "tokens": [50364, 639, 393, 312, 1021, 281, 5682, 578, 32152, 420, 281, 1101, 13982, 3877, 294, 264, 1412, 13, 50628], "temperature": 0.0, "avg_logprob": -0.06754784085857335, "compression_ratio": 1.880794701986755, "no_speech_prob": 0.010060646571218967}, {"id": 81, "seek": 50056, "start": 505.84, "end": 509.76, "text": " Structure in the data that's interesting. That's quite a cool point actually because if you think", "tokens": [50628, 745, 2885, 294, 264, 1412, 300, 311, 1880, 13, 663, 311, 1596, 257, 1627, 935, 767, 570, 498, 291, 519, 50824], "temperature": 0.0, "avg_logprob": -0.06754784085857335, "compression_ratio": 1.880794701986755, "no_speech_prob": 0.010060646571218967}, {"id": 82, "seek": 50056, "start": 509.76, "end": 515.2, "text": " about it you could naively if you're doing a vision classifier you could naively just look at", "tokens": [50824, 466, 309, 291, 727, 1667, 3413, 498, 291, 434, 884, 257, 5201, 1508, 9902, 291, 727, 1667, 3413, 445, 574, 412, 51096], "temperature": 0.0, "avg_logprob": -0.06754784085857335, "compression_ratio": 1.880794701986755, "no_speech_prob": 0.010060646571218967}, {"id": 83, "seek": 50056, "start": 515.2, "end": 519.36, "text": " all of the pixels and what they are or if you're being smart about it you go one level up and you", "tokens": [51096, 439, 295, 264, 18668, 293, 437, 436, 366, 420, 498, 291, 434, 885, 4069, 466, 309, 291, 352, 472, 1496, 493, 293, 291, 51304], "temperature": 0.0, "avg_logprob": -0.06754784085857335, "compression_ratio": 1.880794701986755, "no_speech_prob": 0.010060646571218967}, {"id": 84, "seek": 50056, "start": 519.36, "end": 524.48, "text": " look for the hidden structure in the data and that is precisely what he's talking about things like", "tokens": [51304, 574, 337, 264, 7633, 3877, 294, 264, 1412, 293, 300, 307, 13402, 437, 415, 311, 1417, 466, 721, 411, 51560], "temperature": 0.0, "avg_logprob": -0.06754784085857335, "compression_ratio": 1.880794701986755, "no_speech_prob": 0.010060646571218967}, {"id": 85, "seek": 50056, "start": 524.48, "end": 530.32, "text": " the symmetries that are inherent in pretty much every type of data. Okay so one last thing", "tokens": [51560, 264, 14232, 302, 2244, 300, 366, 26387, 294, 1238, 709, 633, 2010, 295, 1412, 13, 1033, 370, 472, 1036, 551, 51852], "temperature": 0.0, "avg_logprob": -0.06754784085857335, "compression_ratio": 1.880794701986755, "no_speech_prob": 0.010060646571218967}, {"id": 86, "seek": 53032, "start": 530.32, "end": 536.88, "text": " DeepMind released an official PowerPoint deck on Alpha Fold 2 and it talks about they're on a long", "tokens": [50364, 14895, 44, 471, 4736, 364, 4783, 25584, 9341, 322, 20588, 24609, 568, 293, 309, 6686, 466, 436, 434, 322, 257, 938, 50692], "temperature": 0.0, "avg_logprob": -0.07958436720442064, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.0012348286109045148}, {"id": 87, "seek": 53032, "start": 536.88, "end": 542.72, "text": " term mission to advance scientific progress. Now here are some of the protein examples. Now they", "tokens": [50692, 1433, 4447, 281, 7295, 8134, 4205, 13, 823, 510, 366, 512, 295, 264, 7944, 5110, 13, 823, 436, 50984], "temperature": 0.0, "avg_logprob": -0.07958436720442064, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.0012348286109045148}, {"id": 88, "seek": 53032, "start": 542.72, "end": 547.2, "text": " specifically call out inductive biases for deep learning models where this is exactly what we're", "tokens": [50984, 4682, 818, 484, 31612, 488, 32152, 337, 2452, 2539, 5245, 689, 341, 307, 2293, 437, 321, 434, 51208], "temperature": 0.0, "avg_logprob": -0.07958436720442064, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.0012348286109045148}, {"id": 89, "seek": 53032, "start": 547.2, "end": 553.0400000000001, "text": " talking about so clearly convolutional neural networks are one such bias which has the translational", "tokens": [51208, 1417, 466, 370, 4448, 45216, 304, 18161, 9590, 366, 472, 1270, 12577, 597, 575, 264, 5105, 1478, 51500], "temperature": 0.0, "avg_logprob": -0.07958436720442064, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.0012348286109045148}, {"id": 90, "seek": 53032, "start": 553.0400000000001, "end": 558.8000000000001, "text": " weight sharing. It talks about graph networks and recurrent networks and indeed attention networks", "tokens": [51500, 3364, 5414, 13, 467, 6686, 466, 4295, 9590, 293, 18680, 1753, 9590, 293, 6451, 3202, 9590, 51788], "temperature": 0.0, "avg_logprob": -0.07958436720442064, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.0012348286109045148}, {"id": 91, "seek": 55880, "start": 558.8, "end": 564.0, "text": " which is very much a generalisation of pretty much all of the others. They say that they are", "tokens": [50364, 597, 307, 588, 709, 257, 2674, 7623, 295, 1238, 709, 439, 295, 264, 2357, 13, 814, 584, 300, 436, 366, 50624], "temperature": 0.0, "avg_logprob": -0.056172838398054536, "compression_ratio": 1.8269230769230769, "no_speech_prob": 0.0013327153865247965}, {"id": 92, "seek": 55880, "start": 564.0, "end": 569.52, "text": " putting their protein knowledge into the model so physical insights are built into the network", "tokens": [50624, 3372, 641, 7944, 3601, 666, 264, 2316, 370, 4001, 14310, 366, 3094, 666, 264, 3209, 50900], "temperature": 0.0, "avg_logprob": -0.056172838398054536, "compression_ratio": 1.8269230769230769, "no_speech_prob": 0.0013327153865247965}, {"id": 93, "seek": 55880, "start": 569.52, "end": 576.16, "text": " structure not just the process around it and these biases reflected their knowledge of protein", "tokens": [50900, 3877, 406, 445, 264, 1399, 926, 309, 293, 613, 32152, 15502, 641, 3601, 295, 7944, 51232], "temperature": 0.0, "avg_logprob": -0.056172838398054536, "compression_ratio": 1.8269230769230769, "no_speech_prob": 0.0013327153865247965}, {"id": 94, "seek": 55880, "start": 576.16, "end": 581.28, "text": " physics and geometry and you can see here that there are residues in a protein so they're modelling", "tokens": [51232, 10649, 293, 18426, 293, 291, 393, 536, 510, 300, 456, 366, 13141, 1247, 294, 257, 7944, 370, 436, 434, 42253, 51488], "temperature": 0.0, "avg_logprob": -0.056172838398054536, "compression_ratio": 1.8269230769230769, "no_speech_prob": 0.0013327153865247965}, {"id": 95, "seek": 55880, "start": 581.28, "end": 587.04, "text": " topologically which residues are connected to which other residues in this kind of 3d space.", "tokens": [51488, 1192, 17157, 597, 13141, 1247, 366, 4582, 281, 597, 661, 13141, 1247, 294, 341, 733, 295, 805, 67, 1901, 13, 51776], "temperature": 0.0, "avg_logprob": -0.056172838398054536, "compression_ratio": 1.8269230769230769, "no_speech_prob": 0.0013327153865247965}, {"id": 96, "seek": 58704, "start": 587.04, "end": 591.76, "text": " They specifically call out here on the structure model page that they are building a 3d", "tokens": [50364, 814, 4682, 818, 484, 510, 322, 264, 3877, 2316, 3028, 300, 436, 366, 2390, 257, 805, 67, 50600], "temperature": 0.0, "avg_logprob": -0.09487077539617365, "compression_ratio": 1.6332179930795847, "no_speech_prob": 0.0006762949633412063}, {"id": 97, "seek": 58704, "start": 591.76, "end": 597.52, "text": " equivariant transformer architecture so anyway if this doesn't motivate you that symmetries", "tokens": [50600, 1267, 592, 3504, 394, 31782, 9482, 370, 4033, 498, 341, 1177, 380, 28497, 291, 300, 14232, 302, 2244, 50888], "temperature": 0.0, "avg_logprob": -0.09487077539617365, "compression_ratio": 1.6332179930795847, "no_speech_prob": 0.0006762949633412063}, {"id": 98, "seek": 58704, "start": 597.52, "end": 602.64, "text": " and manifolds are an exciting idea in deep learning I don't know what will. So clearly Max has been in", "tokens": [50888, 293, 8173, 31518, 366, 364, 4670, 1558, 294, 2452, 2539, 286, 500, 380, 458, 437, 486, 13, 407, 4448, 7402, 575, 668, 294, 51144], "temperature": 0.0, "avg_logprob": -0.09487077539617365, "compression_ratio": 1.6332179930795847, "no_speech_prob": 0.0006762949633412063}, {"id": 99, "seek": 58704, "start": 602.64, "end": 609.4399999999999, "text": " this game for a long time now back in 2004 with Kingma he invented the variational Bayes auto", "tokens": [51144, 341, 1216, 337, 257, 938, 565, 586, 646, 294, 15817, 365, 3819, 1696, 415, 14479, 264, 3034, 1478, 7840, 279, 8399, 51484], "temperature": 0.0, "avg_logprob": -0.09487077539617365, "compression_ratio": 1.6332179930795847, "no_speech_prob": 0.0006762949633412063}, {"id": 100, "seek": 58704, "start": 609.4399999999999, "end": 616.3199999999999, "text": " encoder. It's only recently that well relatively recently that Max has been focusing in on deep", "tokens": [51484, 2058, 19866, 13, 467, 311, 787, 3938, 300, 731, 7226, 3938, 300, 7402, 575, 668, 8416, 294, 322, 2452, 51828], "temperature": 0.0, "avg_logprob": -0.09487077539617365, "compression_ratio": 1.6332179930795847, "no_speech_prob": 0.0006762949633412063}, {"id": 101, "seek": 61632, "start": 616.32, "end": 623.2800000000001, "text": " learning. Clearly like any other field also machine learning is subject to fashion right and so if", "tokens": [50364, 2539, 13, 24120, 411, 604, 661, 2519, 611, 3479, 2539, 307, 3983, 281, 6700, 558, 293, 370, 498, 50712], "temperature": 0.0, "avg_logprob": -0.12359964111704885, "compression_ratio": 1.6317991631799162, "no_speech_prob": 0.00267020077444613}, {"id": 102, "seek": 61632, "start": 623.2800000000001, "end": 629.12, "text": " there is a five to ten year cycles where people get really excited about a certain topic either", "tokens": [50712, 456, 307, 257, 1732, 281, 2064, 1064, 17796, 689, 561, 483, 534, 2919, 466, 257, 1629, 4829, 2139, 51004], "temperature": 0.0, "avg_logprob": -0.12359964111704885, "compression_ratio": 1.6317991631799162, "no_speech_prob": 0.00267020077444613}, {"id": 103, "seek": 61632, "start": 629.12, "end": 636.8000000000001, "text": " because the theory is very beautiful or it just works really well. I started in biographical models", "tokens": [51004, 570, 264, 5261, 307, 588, 2238, 420, 309, 445, 1985, 534, 731, 13, 286, 1409, 294, 3228, 48434, 5245, 51388], "temperature": 0.0, "avg_logprob": -0.12359964111704885, "compression_ratio": 1.6317991631799162, "no_speech_prob": 0.00267020077444613}, {"id": 104, "seek": 61632, "start": 636.8000000000001, "end": 642.8000000000001, "text": " and independent components analysis was the talk of the day and the support vector machines and", "tokens": [51388, 293, 6695, 6677, 5215, 390, 264, 751, 295, 264, 786, 293, 264, 1406, 8062, 8379, 293, 51688], "temperature": 0.0, "avg_logprob": -0.12359964111704885, "compression_ratio": 1.6317991631799162, "no_speech_prob": 0.00267020077444613}, {"id": 105, "seek": 64280, "start": 642.88, "end": 648.3199999999999, "text": " basically non-parametric methods and then came Bayesian methods and non-parametric Bayesian", "tokens": [50368, 1936, 2107, 12, 2181, 335, 17475, 7150, 293, 550, 1361, 7840, 42434, 7150, 293, 2107, 12, 2181, 335, 17475, 7840, 42434, 50640], "temperature": 0.0, "avg_logprob": -0.08446674511350434, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.00027796116773970425}, {"id": 106, "seek": 64280, "start": 648.3199999999999, "end": 653.5999999999999, "text": " methods and now it's all about deep learning. So what you see is that the field is subject to these", "tokens": [50640, 7150, 293, 586, 309, 311, 439, 466, 2452, 2539, 13, 407, 437, 291, 536, 307, 300, 264, 2519, 307, 3983, 281, 613, 50904], "temperature": 0.0, "avg_logprob": -0.08446674511350434, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.00027796116773970425}, {"id": 107, "seek": 64280, "start": 653.5999999999999, "end": 660.4, "text": " sort of fashions and I think it's fine because we zoom in a new very promising tool and then we", "tokens": [50904, 1333, 295, 283, 1299, 626, 293, 286, 519, 309, 311, 2489, 570, 321, 8863, 294, 257, 777, 588, 20257, 2290, 293, 550, 321, 51244], "temperature": 0.0, "avg_logprob": -0.08446674511350434, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.00027796116773970425}, {"id": 108, "seek": 64280, "start": 660.4, "end": 666.16, "text": " work it out and we get the most out of it. Max is a vice president at Qualcomm so clearly he", "tokens": [51244, 589, 309, 484, 293, 321, 483, 264, 881, 484, 295, 309, 13, 7402, 307, 257, 11964, 3868, 412, 13616, 13278, 370, 4448, 415, 51532], "temperature": 0.0, "avg_logprob": -0.08446674511350434, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.00027796116773970425}, {"id": 109, "seek": 64280, "start": 666.16, "end": 671.52, "text": " thinks that computation is going to be absolutely critical for the future of artificial intelligence", "tokens": [51532, 7309, 300, 24903, 307, 516, 281, 312, 3122, 4924, 337, 264, 2027, 295, 11677, 7599, 51800], "temperature": 0.0, "avg_logprob": -0.08446674511350434, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.00027796116773970425}, {"id": 110, "seek": 67152, "start": 671.52, "end": 675.84, "text": " but having said that he also thinks that we need to be more efficient with our hardware", "tokens": [50364, 457, 1419, 848, 300, 415, 611, 7309, 300, 321, 643, 281, 312, 544, 7148, 365, 527, 8837, 50580], "temperature": 0.0, "avg_logprob": -0.05329421189454225, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.0016989207360893488}, {"id": 111, "seek": 67152, "start": 675.84, "end": 681.92, "text": " tomorrow than we are today. That's just a reality that we all have to accept. So the more compute", "tokens": [50580, 4153, 813, 321, 366, 965, 13, 663, 311, 445, 257, 4103, 300, 321, 439, 362, 281, 3241, 13, 407, 264, 544, 14722, 50884], "temperature": 0.0, "avg_logprob": -0.05329421189454225, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.0016989207360893488}, {"id": 112, "seek": 67152, "start": 681.92, "end": 687.84, "text": " we throw at it the bigger we make our models somehow the better they perform and we don't know", "tokens": [50884, 321, 3507, 412, 309, 264, 3801, 321, 652, 527, 5245, 6063, 264, 1101, 436, 2042, 293, 321, 500, 380, 458, 51180], "temperature": 0.0, "avg_logprob": -0.05329421189454225, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.0016989207360893488}, {"id": 113, "seek": 67152, "start": 687.84, "end": 693.1999999999999, "text": " precisely why that is but we do know that they will use increasingly more energy to do the", "tokens": [51180, 13402, 983, 300, 307, 457, 321, 360, 458, 300, 436, 486, 764, 12980, 544, 2281, 281, 360, 264, 51448], "temperature": 0.0, "avg_logprob": -0.05329421189454225, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.0016989207360893488}, {"id": 114, "seek": 67152, "start": 693.1999999999999, "end": 698.0799999999999, "text": " computations for us and at some point that's just not a viable economic model anymore. We'll see a", "tokens": [51448, 2807, 763, 337, 505, 293, 412, 512, 935, 300, 311, 445, 406, 257, 22024, 4836, 2316, 3602, 13, 492, 603, 536, 257, 51692], "temperature": 0.0, "avg_logprob": -0.05329421189454225, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.0016989207360893488}, {"id": 115, "seek": 69808, "start": 698.08, "end": 704.08, "text": " continuation in making deep learning and machine learning more energy efficient. So there's a really", "tokens": [50364, 29357, 294, 1455, 2452, 2539, 293, 3479, 2539, 544, 2281, 7148, 13, 407, 456, 311, 257, 534, 50664], "temperature": 0.0, "avg_logprob": -0.07436011851519003, "compression_ratio": 1.7413793103448276, "no_speech_prob": 0.001344513613730669}, {"id": 116, "seek": 69808, "start": 704.08, "end": 711.2, "text": " interesting interplay between priors, experience and generalization. We want to have machine learning", "tokens": [50664, 1880, 728, 2858, 1296, 1790, 830, 11, 1752, 293, 2674, 2144, 13, 492, 528, 281, 362, 3479, 2539, 51020], "temperature": 0.0, "avg_logprob": -0.07436011851519003, "compression_ratio": 1.7413793103448276, "no_speech_prob": 0.001344513613730669}, {"id": 117, "seek": 69808, "start": 711.2, "end": 717.44, "text": " models that generalize really well to things that they haven't seen during training. If you move them", "tokens": [51020, 5245, 300, 2674, 1125, 534, 731, 281, 721, 300, 436, 2378, 380, 1612, 1830, 3097, 13, 759, 291, 1286, 552, 51332], "temperature": 0.0, "avg_logprob": -0.07436011851519003, "compression_ratio": 1.7413793103448276, "no_speech_prob": 0.001344513613730669}, {"id": 118, "seek": 69808, "start": 717.44, "end": 723.44, "text": " into a new orientation or in a new situation in the context and that's what we think of when we say", "tokens": [51332, 666, 257, 777, 14764, 420, 294, 257, 777, 2590, 294, 264, 4319, 293, 300, 311, 437, 321, 519, 295, 562, 321, 584, 51632], "temperature": 0.0, "avg_logprob": -0.07436011851519003, "compression_ratio": 1.7413793103448276, "no_speech_prob": 0.001344513613730669}, {"id": 119, "seek": 72344, "start": 724.32, "end": 728.48, "text": " artificial general AI which means like not just something you train on one specific topic and", "tokens": [50408, 11677, 2674, 7318, 597, 1355, 411, 406, 445, 746, 291, 3847, 322, 472, 2685, 4829, 293, 50616], "temperature": 0.0, "avg_logprob": -0.09081366255476668, "compression_ratio": 1.7919708029197081, "no_speech_prob": 0.0128104193136096}, {"id": 120, "seek": 72344, "start": 728.48, "end": 732.72, "text": " then you ask it to do that and it does it very well but if you then move it into a new context", "tokens": [50616, 550, 291, 1029, 309, 281, 360, 300, 293, 309, 775, 309, 588, 731, 457, 498, 291, 550, 1286, 309, 666, 257, 777, 4319, 50828], "temperature": 0.0, "avg_logprob": -0.09081366255476668, "compression_ratio": 1.7919708029197081, "no_speech_prob": 0.0128104193136096}, {"id": 121, "seek": 72344, "start": 732.72, "end": 737.7600000000001, "text": " it just completely fails as narrow AI. So humans are clearly much more flexible if you learn something", "tokens": [50828, 309, 445, 2584, 18199, 382, 9432, 7318, 13, 407, 6255, 366, 4448, 709, 544, 11358, 498, 291, 1466, 746, 51080], "temperature": 0.0, "avg_logprob": -0.09081366255476668, "compression_ratio": 1.7919708029197081, "no_speech_prob": 0.0128104193136096}, {"id": 122, "seek": 72344, "start": 737.7600000000001, "end": 742.08, "text": " in one context and then when you get put into a new context that we've never seen before suddenly", "tokens": [51080, 294, 472, 4319, 293, 550, 562, 291, 483, 829, 666, 257, 777, 4319, 300, 321, 600, 1128, 1612, 949, 5800, 51296], "temperature": 0.0, "avg_logprob": -0.09081366255476668, "compression_ratio": 1.7919708029197081, "no_speech_prob": 0.0128104193136096}, {"id": 123, "seek": 72344, "start": 742.08, "end": 748.48, "text": " we can still do very well and so we want our agents our artificial agents also to have this property.", "tokens": [51296, 321, 393, 920, 360, 588, 731, 293, 370, 321, 528, 527, 12554, 527, 11677, 12554, 611, 281, 362, 341, 4707, 13, 51616], "temperature": 0.0, "avg_logprob": -0.09081366255476668, "compression_ratio": 1.7919708029197081, "no_speech_prob": 0.0128104193136096}, {"id": 124, "seek": 74848, "start": 748.48, "end": 753.84, "text": " Max is also a huge proponent of generative models. He thinks that generative models might be the", "tokens": [50364, 7402, 307, 611, 257, 2603, 2365, 30365, 295, 1337, 1166, 5245, 13, 634, 7309, 300, 1337, 1166, 5245, 1062, 312, 264, 50632], "temperature": 0.0, "avg_logprob": -0.07636679736050693, "compression_ratio": 1.7266187050359711, "no_speech_prob": 0.002509140642359853}, {"id": 125, "seek": 74848, "start": 753.84, "end": 759.44, "text": " future of artificial intelligence so funnily enough I think Max and Carl Friston that we had on a", "tokens": [50632, 2027, 295, 11677, 7599, 370, 1019, 77, 953, 1547, 286, 519, 7402, 293, 14256, 1526, 47345, 300, 321, 632, 322, 257, 50912], "temperature": 0.0, "avg_logprob": -0.07636679736050693, "compression_ratio": 1.7266187050359711, "no_speech_prob": 0.002509140642359853}, {"id": 126, "seek": 74848, "start": 759.44, "end": 765.04, "text": " couple of episodes ago I think they would see eye to eye. Basically what everybody else in the", "tokens": [50912, 1916, 295, 9313, 2057, 286, 519, 436, 576, 536, 3313, 281, 3313, 13, 8537, 437, 2201, 1646, 294, 264, 51192], "temperature": 0.0, "avg_logprob": -0.07636679736050693, "compression_ratio": 1.7266187050359711, "no_speech_prob": 0.002509140642359853}, {"id": 127, "seek": 74848, "start": 765.04, "end": 769.36, "text": " scientific community does which is write down a model of the world which we call a generative", "tokens": [51192, 8134, 1768, 775, 597, 307, 2464, 760, 257, 2316, 295, 264, 1002, 597, 321, 818, 257, 1337, 1166, 51408], "temperature": 0.0, "avg_logprob": -0.07636679736050693, "compression_ratio": 1.7266187050359711, "no_speech_prob": 0.002509140642359853}, {"id": 128, "seek": 74848, "start": 769.36, "end": 775.44, "text": " model which is how do I imagine that the world that I'm seeing in my measurement apparatus could", "tokens": [51408, 2316, 597, 307, 577, 360, 286, 3811, 300, 264, 1002, 300, 286, 478, 2577, 294, 452, 13160, 38573, 727, 51712], "temperature": 0.0, "avg_logprob": -0.07636679736050693, "compression_ratio": 1.7266187050359711, "no_speech_prob": 0.002509140642359853}, {"id": 129, "seek": 77544, "start": 775.44, "end": 781.6800000000001, "text": " have been generated by nature. We all have the matrix going on inside our heads. We are running", "tokens": [50364, 362, 668, 10833, 538, 3687, 13, 492, 439, 362, 264, 8141, 516, 322, 1854, 527, 8050, 13, 492, 366, 2614, 50676], "temperature": 0.0, "avg_logprob": -0.06155532056635076, "compression_ratio": 1.6610169491525424, "no_speech_prob": 0.004197424743324518}, {"id": 130, "seek": 77544, "start": 781.6800000000001, "end": 788.6400000000001, "text": " simulations of reality and we're kind of integrating over the expected value of those simulations.", "tokens": [50676, 35138, 295, 4103, 293, 321, 434, 733, 295, 26889, 670, 264, 5176, 2158, 295, 729, 35138, 13, 51024], "temperature": 0.0, "avg_logprob": -0.06155532056635076, "compression_ratio": 1.6610169491525424, "no_speech_prob": 0.004197424743324518}, {"id": 131, "seek": 77544, "start": 788.6400000000001, "end": 794.08, "text": " This is just something that we do all the time. That seems to be the real trick for intelligence", "tokens": [51024, 639, 307, 445, 746, 300, 321, 360, 439, 264, 565, 13, 663, 2544, 281, 312, 264, 957, 4282, 337, 7599, 51296], "temperature": 0.0, "avg_logprob": -0.06155532056635076, "compression_ratio": 1.6610169491525424, "no_speech_prob": 0.004197424743324518}, {"id": 132, "seek": 77544, "start": 794.08, "end": 801.0400000000001, "text": " at least in humans so our ability to generate the world. Max also thinks that we need to be learning", "tokens": [51296, 412, 1935, 294, 6255, 370, 527, 3485, 281, 8460, 264, 1002, 13, 7402, 611, 7309, 300, 321, 643, 281, 312, 2539, 51644], "temperature": 0.0, "avg_logprob": -0.06155532056635076, "compression_ratio": 1.6610169491525424, "no_speech_prob": 0.004197424743324518}, {"id": 133, "seek": 80104, "start": 801.12, "end": 805.92, "text": " causal relationships in our models. Causal relationships have this really interesting", "tokens": [50368, 38755, 6159, 294, 527, 5245, 13, 7544, 11765, 6159, 362, 341, 534, 1880, 50608], "temperature": 0.0, "avg_logprob": -0.055928903756682406, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.01585393212735653}, {"id": 134, "seek": 80104, "start": 805.92, "end": 812.64, "text": " property that they generalize better so Max comes up with this wonderful example of a certain color", "tokens": [50608, 4707, 300, 436, 2674, 1125, 1101, 370, 7402, 1487, 493, 365, 341, 3715, 1365, 295, 257, 1629, 2017, 50944], "temperature": 0.0, "avg_logprob": -0.055928903756682406, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.01585393212735653}, {"id": 135, "seek": 80104, "start": 812.64, "end": 818.88, "text": " of car in the Netherlands might be associated with a higher accident rate but that probably", "tokens": [50944, 295, 1032, 294, 264, 20873, 1062, 312, 6615, 365, 257, 2946, 6398, 3314, 457, 300, 1391, 51256], "temperature": 0.0, "avg_logprob": -0.055928903756682406, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.01585393212735653}, {"id": 136, "seek": 80104, "start": 818.88, "end": 824.16, "text": " wouldn't generalize very well to other countries because it's just a colloquialism whereas male", "tokens": [51256, 2759, 380, 2674, 1125, 588, 731, 281, 661, 3517, 570, 309, 311, 445, 257, 1263, 29826, 831, 1434, 9735, 7133, 51520], "temperature": 0.0, "avg_logprob": -0.055928903756682406, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.01585393212735653}, {"id": 137, "seek": 80104, "start": 824.16, "end": 829.4399999999999, "text": " testosterone levels that's a causal factor and that's going to generalize far better to other", "tokens": [51520, 33417, 4358, 300, 311, 257, 38755, 5952, 293, 300, 311, 516, 281, 2674, 1125, 1400, 1101, 281, 661, 51784], "temperature": 0.0, "avg_logprob": -0.055928903756682406, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.01585393212735653}, {"id": 138, "seek": 82944, "start": 829.44, "end": 836.1600000000001, "text": " countries. So try to figure out what the true physics of the world is what causes what and if", "tokens": [50364, 3517, 13, 407, 853, 281, 2573, 484, 437, 264, 2074, 10649, 295, 264, 1002, 307, 437, 7700, 437, 293, 498, 50700], "temperature": 0.0, "avg_logprob": -0.05495451603616987, "compression_ratio": 1.7360594795539033, "no_speech_prob": 0.0034819617867469788}, {"id": 139, "seek": 82944, "start": 836.1600000000001, "end": 841.9200000000001, "text": " you have this causal structure of the world you understand much more about the actual world", "tokens": [50700, 291, 362, 341, 38755, 3877, 295, 264, 1002, 291, 1223, 709, 544, 466, 264, 3539, 1002, 50988], "temperature": 0.0, "avg_logprob": -0.05495451603616987, "compression_ratio": 1.7360594795539033, "no_speech_prob": 0.0034819617867469788}, {"id": 140, "seek": 82944, "start": 841.9200000000001, "end": 846.5600000000001, "text": " and then if you move it to a new context you can generalize a lot better in this new context.", "tokens": [50988, 293, 550, 498, 291, 1286, 309, 281, 257, 777, 4319, 291, 393, 2674, 1125, 257, 688, 1101, 294, 341, 777, 4319, 13, 51220], "temperature": 0.0, "avg_logprob": -0.05495451603616987, "compression_ratio": 1.7360594795539033, "no_speech_prob": 0.0034819617867469788}, {"id": 141, "seek": 82944, "start": 846.5600000000001, "end": 851.6800000000001, "text": " At this stage Max has bet on so many winning horses that you've got to wonder how the hell", "tokens": [51220, 1711, 341, 3233, 7402, 575, 778, 322, 370, 867, 8224, 13112, 300, 291, 600, 658, 281, 2441, 577, 264, 4921, 51476], "temperature": 0.0, "avg_logprob": -0.05495451603616987, "compression_ratio": 1.7360594795539033, "no_speech_prob": 0.0034819617867469788}, {"id": 142, "seek": 82944, "start": 851.6800000000001, "end": 858.08, "text": " does he do it so we ask him what his secret is. It's incredibly hard to predict what will become", "tokens": [51476, 775, 415, 360, 309, 370, 321, 1029, 796, 437, 702, 4054, 307, 13, 467, 311, 6252, 1152, 281, 6069, 437, 486, 1813, 51796], "temperature": 0.0, "avg_logprob": -0.05495451603616987, "compression_ratio": 1.7360594795539033, "no_speech_prob": 0.0034819617867469788}, {"id": 143, "seek": 85808, "start": 858.08, "end": 862.88, "text": " well known. Sometimes you just happen to be working on something that takes off like a rocket.", "tokens": [50364, 731, 2570, 13, 4803, 291, 445, 1051, 281, 312, 1364, 322, 746, 300, 2516, 766, 411, 257, 13012, 13, 50604], "temperature": 0.0, "avg_logprob": -0.07374510848731325, "compression_ratio": 1.6445993031358885, "no_speech_prob": 0.01064910925924778}, {"id": 144, "seek": 85808, "start": 862.88, "end": 868.8000000000001, "text": " When we did things like the VAE or graph neural nets it didn't feel at all like this was going", "tokens": [50604, 1133, 321, 630, 721, 411, 264, 18527, 36, 420, 4295, 18161, 36170, 309, 994, 380, 841, 412, 439, 411, 341, 390, 516, 50900], "temperature": 0.0, "avg_logprob": -0.07374510848731325, "compression_ratio": 1.6445993031358885, "no_speech_prob": 0.01064910925924778}, {"id": 145, "seek": 85808, "start": 868.8000000000001, "end": 875.2, "text": " to be a big hit. When we read some of the research from Max's students we were just blown away it", "tokens": [50900, 281, 312, 257, 955, 2045, 13, 1133, 321, 1401, 512, 295, 264, 2132, 490, 7402, 311, 1731, 321, 645, 445, 16479, 1314, 309, 51220], "temperature": 0.0, "avg_logprob": -0.07374510848731325, "compression_ratio": 1.6445993031358885, "no_speech_prob": 0.01064910925924778}, {"id": 146, "seek": 85808, "start": 875.2, "end": 880.88, "text": " sometimes we've got to just remind ourselves that these are fairly young folks that are in their", "tokens": [51220, 2171, 321, 600, 658, 281, 445, 4160, 4175, 300, 613, 366, 6457, 2037, 4024, 300, 366, 294, 641, 51504], "temperature": 0.0, "avg_logprob": -0.07374510848731325, "compression_ratio": 1.6445993031358885, "no_speech_prob": 0.01064910925924778}, {"id": 147, "seek": 85808, "start": 880.88, "end": 886.48, "text": " early 20s that you know they've just come out of university. How is this even possible?", "tokens": [51504, 2440, 945, 82, 300, 291, 458, 436, 600, 445, 808, 484, 295, 5454, 13, 1012, 307, 341, 754, 1944, 30, 51784], "temperature": 0.0, "avg_logprob": -0.07374510848731325, "compression_ratio": 1.6445993031358885, "no_speech_prob": 0.01064910925924778}, {"id": 148, "seek": 88648, "start": 886.5600000000001, "end": 891.28, "text": " I've been very blessed with being able even with my industry funding to", "tokens": [50368, 286, 600, 668, 588, 12351, 365, 885, 1075, 754, 365, 452, 3518, 6137, 281, 50604], "temperature": 0.0, "avg_logprob": -0.06394521468276278, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.00016859536117408425}, {"id": 149, "seek": 88648, "start": 891.28, "end": 896.64, "text": " provide this level of freedom to the students and I think this is really key.", "tokens": [50604, 2893, 341, 1496, 295, 5645, 281, 264, 1731, 293, 286, 519, 341, 307, 534, 2141, 13, 50872], "temperature": 0.0, "avg_logprob": -0.06394521468276278, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.00016859536117408425}, {"id": 150, "seek": 88648, "start": 896.64, "end": 901.44, "text": " So one of the things we asked Max was how does he select his research directions?", "tokens": [50872, 407, 472, 295, 264, 721, 321, 2351, 7402, 390, 577, 775, 415, 3048, 702, 2132, 11095, 30, 51112], "temperature": 0.0, "avg_logprob": -0.06394521468276278, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.00016859536117408425}, {"id": 151, "seek": 88648, "start": 901.44, "end": 905.44, "text": " One of the interesting things is that he's a physicist right so many of the things", "tokens": [51112, 1485, 295, 264, 1880, 721, 307, 300, 415, 311, 257, 42466, 558, 370, 867, 295, 264, 721, 51312], "temperature": 0.0, "avg_logprob": -0.06394521468276278, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.00016859536117408425}, {"id": 152, "seek": 88648, "start": 905.44, "end": 909.84, "text": " that he's been doing are straight out of his operating playbook from the physics world.", "tokens": [51312, 300, 415, 311, 668, 884, 366, 2997, 484, 295, 702, 7447, 862, 2939, 490, 264, 10649, 1002, 13, 51532], "temperature": 0.0, "avg_logprob": -0.06394521468276278, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.00016859536117408425}, {"id": 153, "seek": 88648, "start": 909.84, "end": 913.6800000000001, "text": " So things like symmetries and manifolds and even quantum.", "tokens": [51532, 407, 721, 411, 14232, 302, 2244, 293, 8173, 31518, 293, 754, 13018, 13, 51724], "temperature": 0.0, "avg_logprob": -0.06394521468276278, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.00016859536117408425}, {"id": 154, "seek": 91368, "start": 913.76, "end": 919.04, "text": " Like symmetries have this this deep feeling right? Symmetries pervade basically all theories", "tokens": [50368, 1743, 14232, 302, 2244, 362, 341, 341, 2452, 2633, 558, 30, 3902, 2174, 302, 2244, 680, 85, 762, 1936, 439, 13667, 50632], "temperature": 0.0, "avg_logprob": -0.09520820695526745, "compression_ratio": 1.695167286245353, "no_speech_prob": 0.0012839882401749492}, {"id": 155, "seek": 91368, "start": 919.04, "end": 924.16, "text": " of physics and they have this profound impact on how you formulate the mathematics of a theory", "tokens": [50632, 295, 10649, 293, 436, 362, 341, 14382, 2712, 322, 577, 291, 47881, 264, 18666, 295, 257, 5261, 50888], "temperature": 0.0, "avg_logprob": -0.09520820695526745, "compression_ratio": 1.695167286245353, "no_speech_prob": 0.0012839882401749492}, {"id": 156, "seek": 91368, "start": 924.9599999999999, "end": 929.8399999999999, "text": " especially when it becomes almost mysterious right? Quantum mechanics is almost mysterious.", "tokens": [50928, 2318, 562, 309, 3643, 1920, 13831, 558, 30, 44964, 12939, 307, 1920, 13831, 13, 51172], "temperature": 0.0, "avg_logprob": -0.09520820695526745, "compression_ratio": 1.695167286245353, "no_speech_prob": 0.0012839882401749492}, {"id": 157, "seek": 91368, "start": 929.8399999999999, "end": 934.16, "text": " How on earth is quantum mechanics possible? The fascinating thing here as we discussed on our", "tokens": [51172, 1012, 322, 4120, 307, 13018, 12939, 1944, 30, 440, 10343, 551, 510, 382, 321, 7152, 322, 527, 51388], "temperature": 0.0, "avg_logprob": -0.09520820695526745, "compression_ratio": 1.695167286245353, "no_speech_prob": 0.0012839882401749492}, {"id": 158, "seek": 91368, "start": 934.16, "end": 940.8, "text": " GPT3 episode is that many of these roads actually lead back to computation itself.", "tokens": [51388, 26039, 51, 18, 3500, 307, 300, 867, 295, 613, 11344, 767, 1477, 646, 281, 24903, 2564, 13, 51720], "temperature": 0.0, "avg_logprob": -0.09520820695526745, "compression_ratio": 1.695167286245353, "no_speech_prob": 0.0012839882401749492}, {"id": 159, "seek": 94080, "start": 940.8, "end": 945.04, "text": " How does the brain compute things also feels like a very deep question right? How do we even", "tokens": [50364, 1012, 775, 264, 3567, 14722, 721, 611, 3417, 411, 257, 588, 2452, 1168, 558, 30, 1012, 360, 321, 754, 50576], "temperature": 0.0, "avg_logprob": -0.0832052698322371, "compression_ratio": 1.739463601532567, "no_speech_prob": 0.0032217693515121937}, {"id": 160, "seek": 94080, "start": 945.04, "end": 950.4, "text": " compute things? What is computation even and does the universe compute its solution?", "tokens": [50576, 14722, 721, 30, 708, 307, 24903, 754, 293, 775, 264, 6445, 14722, 1080, 3827, 30, 50844], "temperature": 0.0, "avg_logprob": -0.0832052698322371, "compression_ratio": 1.739463601532567, "no_speech_prob": 0.0032217693515121937}, {"id": 161, "seek": 94080, "start": 950.4, "end": 956.56, "text": " What does it mean to be predictable? Can you compute faster than the universe can compute?", "tokens": [50844, 708, 775, 309, 914, 281, 312, 27737, 30, 1664, 291, 14722, 4663, 813, 264, 6445, 393, 14722, 30, 51152], "temperature": 0.0, "avg_logprob": -0.0832052698322371, "compression_ratio": 1.739463601532567, "no_speech_prob": 0.0032217693515121937}, {"id": 162, "seek": 94080, "start": 956.56, "end": 961.5999999999999, "text": " One of the key concepts that we talk about in the show this evening is the bias variance trade-off.", "tokens": [51152, 1485, 295, 264, 2141, 10392, 300, 321, 751, 466, 294, 264, 855, 341, 5634, 307, 264, 12577, 21977, 4923, 12, 4506, 13, 51404], "temperature": 0.0, "avg_logprob": -0.0832052698322371, "compression_ratio": 1.739463601532567, "no_speech_prob": 0.0032217693515121937}, {"id": 163, "seek": 94080, "start": 961.5999999999999, "end": 966.16, "text": " Nothing comes for free. There is no machine learning without assumptions. You have to", "tokens": [51404, 6693, 1487, 337, 1737, 13, 821, 307, 572, 3479, 2539, 1553, 17695, 13, 509, 362, 281, 51632], "temperature": 0.0, "avg_logprob": -0.0832052698322371, "compression_ratio": 1.739463601532567, "no_speech_prob": 0.0032217693515121937}, {"id": 164, "seek": 96616, "start": 966.16, "end": 970.64, "text": " interpolate between the dots and to interpolate means that you have to make assumptions on", "tokens": [50364, 44902, 473, 1296, 264, 15026, 293, 281, 44902, 473, 1355, 300, 291, 362, 281, 652, 17695, 322, 50588], "temperature": 0.0, "avg_logprob": -0.048600930793612614, "compression_ratio": 1.6373626373626373, "no_speech_prob": 0.0029807211831212044}, {"id": 165, "seek": 96616, "start": 970.64, "end": 976.88, "text": " smoothness or something like that. These prior assumptions will help you transfer from one", "tokens": [50588, 5508, 1287, 420, 746, 411, 300, 13, 1981, 4059, 17695, 486, 854, 291, 5003, 490, 472, 50900], "temperature": 0.0, "avg_logprob": -0.048600930793612614, "compression_ratio": 1.6373626373626373, "no_speech_prob": 0.0029807211831212044}, {"id": 166, "seek": 96616, "start": 976.88, "end": 980.9599999999999, "text": " domain to another domain. One of the topics we've been discussing a lot on machine learning", "tokens": [50900, 9274, 281, 1071, 9274, 13, 1485, 295, 264, 8378, 321, 600, 668, 10850, 257, 688, 322, 3479, 2539, 51104], "temperature": 0.0, "avg_logprob": -0.048600930793612614, "compression_ratio": 1.6373626373626373, "no_speech_prob": 0.0029807211831212044}, {"id": 167, "seek": 96616, "start": 980.9599999999999, "end": 986.7199999999999, "text": " street talk recently is this notion of how far can we take data-driven approaches?", "tokens": [51104, 4838, 751, 3938, 307, 341, 10710, 295, 577, 1400, 393, 321, 747, 1412, 12, 25456, 11587, 30, 51392], "temperature": 0.0, "avg_logprob": -0.048600930793612614, "compression_ratio": 1.6373626373626373, "no_speech_prob": 0.0029807211831212044}, {"id": 168, "seek": 96616, "start": 986.7199999999999, "end": 992.56, "text": " Will they take us all the way to AGI or is it just like building a tower and trying to get", "tokens": [51392, 3099, 436, 747, 505, 439, 264, 636, 281, 316, 26252, 420, 307, 309, 445, 411, 2390, 257, 10567, 293, 1382, 281, 483, 51684], "temperature": 0.0, "avg_logprob": -0.048600930793612614, "compression_ratio": 1.6373626373626373, "no_speech_prob": 0.0029807211831212044}, {"id": 169, "seek": 99256, "start": 992.56, "end": 998.88, "text": " closer to the moon? Perhaps we could generate more data with data augmentation or even a simulator.", "tokens": [50364, 4966, 281, 264, 7135, 30, 10517, 321, 727, 8460, 544, 1412, 365, 1412, 14501, 19631, 420, 754, 257, 32974, 13, 50680], "temperature": 0.0, "avg_logprob": -0.07530795792002737, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0015009177150204778}, {"id": 170, "seek": 99256, "start": 998.88, "end": 1003.4399999999999, "text": " Perhaps we could use data more efficiently with machine teaching or active learning or some kind", "tokens": [50680, 10517, 321, 727, 764, 1412, 544, 19621, 365, 3479, 4571, 420, 4967, 2539, 420, 512, 733, 50908], "temperature": 0.0, "avg_logprob": -0.07530795792002737, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0015009177150204778}, {"id": 171, "seek": 99256, "start": 1003.4399999999999, "end": 1010.4799999999999, "text": " of controller on how we train the model but ultimately how far can we really go?", "tokens": [50908, 295, 10561, 322, 577, 321, 3847, 264, 2316, 457, 6284, 577, 1400, 393, 321, 534, 352, 30, 51260], "temperature": 0.0, "avg_logprob": -0.07530795792002737, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0015009177150204778}, {"id": 172, "seek": 99256, "start": 1010.4799999999999, "end": 1016.4, "text": " The big question in some sense over time is can we simply take the data-driven approach", "tokens": [51260, 440, 955, 1168, 294, 512, 2020, 670, 565, 307, 393, 321, 2935, 747, 264, 1412, 12, 25456, 3109, 51556], "temperature": 0.0, "avg_logprob": -0.07530795792002737, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0015009177150204778}, {"id": 173, "seek": 101640, "start": 1017.1999999999999, "end": 1023.84, "text": " and extend it all the way to AGI? So Max tells us about all the different schools of thoughts", "tokens": [50404, 293, 10101, 309, 439, 264, 636, 281, 316, 26252, 30, 407, 7402, 5112, 505, 466, 439, 264, 819, 4656, 295, 4598, 50736], "temperature": 0.0, "avg_logprob": -0.14093355405128608, "compression_ratio": 1.625, "no_speech_prob": 0.034544847905635834}, {"id": 174, "seek": 101640, "start": 1023.84, "end": 1029.84, "text": " in the AI community and of course one interesting school of thought is the likes of Gary Marcus", "tokens": [50736, 294, 264, 7318, 1768, 293, 295, 1164, 472, 1880, 1395, 295, 1194, 307, 264, 5902, 295, 13788, 26574, 51036], "temperature": 0.0, "avg_logprob": -0.14093355405128608, "compression_ratio": 1.625, "no_speech_prob": 0.034544847905635834}, {"id": 175, "seek": 101640, "start": 1029.84, "end": 1034.32, "text": " and Wallyed Subba that we had on the show a few weeks ago. These people think that we need to", "tokens": [51036, 293, 343, 379, 292, 8511, 4231, 300, 321, 632, 322, 264, 855, 257, 1326, 3259, 2057, 13, 1981, 561, 519, 300, 321, 643, 281, 51260], "temperature": 0.0, "avg_logprob": -0.14093355405128608, "compression_ratio": 1.625, "no_speech_prob": 0.034544847905635834}, {"id": 176, "seek": 101640, "start": 1034.32, "end": 1039.36, "text": " have an explicit model of the world. And then on the other side we just want a classical AI", "tokens": [51260, 362, 364, 13691, 2316, 295, 264, 1002, 13, 400, 550, 322, 264, 661, 1252, 321, 445, 528, 257, 13735, 7318, 51512], "temperature": 0.0, "avg_logprob": -0.14093355405128608, "compression_ratio": 1.625, "no_speech_prob": 0.034544847905635834}, {"id": 177, "seek": 101640, "start": 1039.92, "end": 1043.04, "text": " sort of community which is no, no, no, that's going to be ridiculous. You will never be able", "tokens": [51540, 1333, 295, 1768, 597, 307, 572, 11, 572, 11, 572, 11, 300, 311, 516, 281, 312, 11083, 13, 509, 486, 1128, 312, 1075, 51696], "temperature": 0.0, "avg_logprob": -0.14093355405128608, "compression_ratio": 1.625, "no_speech_prob": 0.034544847905635834}, {"id": 178, "seek": 104304, "start": 1043.04, "end": 1048.24, "text": " to do that. You really need to imbue these models with the structure of the world.", "tokens": [50364, 281, 360, 300, 13, 509, 534, 643, 281, 566, 65, 622, 613, 5245, 365, 264, 3877, 295, 264, 1002, 13, 50624], "temperature": 0.0, "avg_logprob": -0.069717348189581, "compression_ratio": 1.6891385767790261, "no_speech_prob": 0.007230028975754976}, {"id": 179, "seek": 104304, "start": 1048.24, "end": 1054.1599999999999, "text": " In the show, Max tells us where he's placing his bets but we're not going to spoil the surprise.", "tokens": [50624, 682, 264, 855, 11, 7402, 5112, 505, 689, 415, 311, 17221, 702, 39922, 457, 321, 434, 406, 516, 281, 18630, 264, 6365, 13, 50920], "temperature": 0.0, "avg_logprob": -0.069717348189581, "compression_ratio": 1.6891385767790261, "no_speech_prob": 0.007230028975754976}, {"id": 180, "seek": 104304, "start": 1054.1599999999999, "end": 1059.52, "text": " So as we said before, Max is extremely well known for creating these inductive priors and", "tokens": [50920, 407, 382, 321, 848, 949, 11, 7402, 307, 4664, 731, 2570, 337, 4084, 613, 31612, 488, 1790, 830, 293, 51188], "temperature": 0.0, "avg_logprob": -0.069717348189581, "compression_ratio": 1.6891385767790261, "no_speech_prob": 0.007230028975754976}, {"id": 181, "seek": 104304, "start": 1059.52, "end": 1063.76, "text": " putting them into machine learning models, helping them generalize better and be more", "tokens": [51188, 3372, 552, 666, 3479, 2539, 5245, 11, 4315, 552, 2674, 1125, 1101, 293, 312, 544, 51400], "temperature": 0.0, "avg_logprob": -0.069717348189581, "compression_ratio": 1.6891385767790261, "no_speech_prob": 0.007230028975754976}, {"id": 182, "seek": 104304, "start": 1063.76, "end": 1070.32, "text": " sample efficient. The whole endeavor of machine learning is defining the right inductive biases", "tokens": [51400, 6889, 7148, 13, 440, 1379, 34975, 295, 3479, 2539, 307, 17827, 264, 558, 31612, 488, 32152, 51728], "temperature": 0.0, "avg_logprob": -0.069717348189581, "compression_ratio": 1.6891385767790261, "no_speech_prob": 0.007230028975754976}, {"id": 183, "seek": 107032, "start": 1071.12, "end": 1076.8, "text": " and leaving whatever you don't know to the data. If you put the wrong inductive bias into things", "tokens": [50404, 293, 5012, 2035, 291, 500, 380, 458, 281, 264, 1412, 13, 759, 291, 829, 264, 2085, 31612, 488, 12577, 666, 721, 50688], "temperature": 0.0, "avg_logprob": -0.10354588342749554, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.009839720092713833}, {"id": 184, "seek": 107032, "start": 1076.8, "end": 1083.6, "text": " we'll, things can actually deteriorate. We talk about Hinton's capsule networks. They tell you", "tokens": [50688, 321, 603, 11, 721, 393, 767, 26431, 473, 13, 492, 751, 466, 389, 12442, 311, 29247, 9590, 13, 814, 980, 291, 51028], "temperature": 0.0, "avg_logprob": -0.10354588342749554, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.009839720092713833}, {"id": 185, "seek": 107032, "start": 1083.6, "end": 1091.52, "text": " well we'll just keep the abstract nature of what we want which is some stack of things that transform", "tokens": [51028, 731, 321, 603, 445, 1066, 264, 12649, 3687, 295, 437, 321, 528, 597, 307, 512, 8630, 295, 721, 300, 4088, 51424], "temperature": 0.0, "avg_logprob": -0.10354588342749554, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.009839720092713833}, {"id": 186, "seek": 107032, "start": 1091.52, "end": 1096.48, "text": " in some way that we can vaguely specify and then we ask it to learn all these things.", "tokens": [51424, 294, 512, 636, 300, 321, 393, 13501, 48863, 16500, 293, 550, 321, 1029, 309, 281, 1466, 439, 613, 721, 13, 51672], "temperature": 0.0, "avg_logprob": -0.10354588342749554, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.009839720092713833}, {"id": 187, "seek": 109648, "start": 1097.3600000000001, "end": 1102.24, "text": " We talk about Professor Kenneth Stanley's Greatness Can't Be Planned book and also", "tokens": [50408, 492, 751, 466, 8419, 33735, 28329, 311, 3769, 1287, 1664, 380, 879, 2149, 5943, 1446, 293, 611, 50652], "temperature": 0.0, "avg_logprob": -0.09748195320047358, "compression_ratio": 1.5061728395061729, "no_speech_prob": 0.005218516103923321}, {"id": 188, "seek": 109648, "start": 1102.24, "end": 1108.08, "text": " Sarah Hooker's The Lottery Paper. The thing that both of these ideas have in common is that", "tokens": [50652, 9519, 33132, 260, 311, 440, 20131, 12733, 24990, 13, 440, 551, 300, 1293, 295, 613, 3487, 362, 294, 2689, 307, 300, 50944], "temperature": 0.0, "avg_logprob": -0.09748195320047358, "compression_ratio": 1.5061728395061729, "no_speech_prob": 0.005218516103923321}, {"id": 189, "seek": 109648, "start": 1108.08, "end": 1112.4, "text": " they posit that we are locked in by the decisions of our past.", "tokens": [50944, 436, 11218, 300, 321, 366, 9376, 294, 538, 264, 5327, 295, 527, 1791, 13, 51160], "temperature": 0.0, "avg_logprob": -0.09748195320047358, "compression_ratio": 1.5061728395061729, "no_speech_prob": 0.005218516103923321}, {"id": 190, "seek": 109648, "start": 1112.4, "end": 1117.84, "text": " And I do feel very strongly that as a field we need to open up. So we shoot value", "tokens": [51160, 400, 286, 360, 841, 588, 10613, 300, 382, 257, 2519, 321, 643, 281, 1269, 493, 13, 407, 321, 3076, 2158, 51432], "temperature": 0.0, "avg_logprob": -0.09748195320047358, "compression_ratio": 1.5061728395061729, "no_speech_prob": 0.005218516103923321}, {"id": 191, "seek": 109648, "start": 1118.56, "end": 1121.44, "text": " original ideas much more than we currently do.", "tokens": [51468, 3380, 3487, 709, 544, 813, 321, 4362, 360, 13, 51612], "temperature": 0.0, "avg_logprob": -0.09748195320047358, "compression_ratio": 1.5061728395061729, "no_speech_prob": 0.005218516103923321}, {"id": 192, "seek": 112144, "start": 1122.3200000000002, "end": 1127.28, "text": " So Professor Kenneth Stanley has a fascinating take on this. He thinks that we should be", "tokens": [50408, 407, 8419, 33735, 28329, 575, 257, 10343, 747, 322, 341, 13, 634, 7309, 300, 321, 820, 312, 50656], "temperature": 0.0, "avg_logprob": -0.07548760484766077, "compression_ratio": 1.873134328358209, "no_speech_prob": 0.0009105840581469238}, {"id": 193, "seek": 112144, "start": 1127.28, "end": 1132.4, "text": " treasure hunters. We should find interesting and novel stepping stones that might lead us", "tokens": [50656, 12985, 29509, 13, 492, 820, 915, 1880, 293, 7613, 16821, 14083, 300, 1062, 1477, 505, 50912], "temperature": 0.0, "avg_logprob": -0.07548760484766077, "compression_ratio": 1.873134328358209, "no_speech_prob": 0.0009105840581469238}, {"id": 194, "seek": 112144, "start": 1132.4, "end": 1137.1200000000001, "text": " somewhere interesting. He thinks we should do this in all aspects of our lives.", "tokens": [50912, 4079, 1880, 13, 634, 7309, 321, 820, 360, 341, 294, 439, 7270, 295, 527, 2909, 13, 51148], "temperature": 0.0, "avg_logprob": -0.07548760484766077, "compression_ratio": 1.873134328358209, "no_speech_prob": 0.0009105840581469238}, {"id": 195, "seek": 112144, "start": 1137.1200000000001, "end": 1141.28, "text": " So we all want to monotonically increase our objectives and what we should be is treasure", "tokens": [51148, 407, 321, 439, 528, 281, 1108, 27794, 984, 3488, 527, 15961, 293, 437, 321, 820, 312, 307, 12985, 51356], "temperature": 0.0, "avg_logprob": -0.07548760484766077, "compression_ratio": 1.873134328358209, "no_speech_prob": 0.0009105840581469238}, {"id": 196, "seek": 112144, "start": 1141.28, "end": 1145.3600000000001, "text": " hunters. Science should be about exploration not exploitation.", "tokens": [51356, 29509, 13, 8976, 820, 312, 466, 16197, 406, 33122, 13, 51560], "temperature": 0.0, "avg_logprob": -0.07548760484766077, "compression_ratio": 1.873134328358209, "no_speech_prob": 0.0009105840581469238}, {"id": 197, "seek": 112144, "start": 1145.3600000000001, "end": 1150.88, "text": " How do we extend this to peer review in science? Ironically having a consensus peer review", "tokens": [51560, 1012, 360, 321, 10101, 341, 281, 15108, 3131, 294, 3497, 30, 13720, 984, 1419, 257, 19115, 15108, 3131, 51836], "temperature": 0.0, "avg_logprob": -0.07548760484766077, "compression_ratio": 1.873134328358209, "no_speech_prob": 0.0009105840581469238}, {"id": 198, "seek": 115088, "start": 1150.88, "end": 1156.64, "text": " encourages groupthink and convergent behavior. If we genuinely want to have an exploratory", "tokens": [50364, 28071, 1594, 21074, 293, 9652, 6930, 5223, 13, 759, 321, 17839, 528, 281, 362, 364, 24765, 4745, 50652], "temperature": 0.0, "avg_logprob": -0.07000830463159864, "compression_ratio": 1.635036496350365, "no_speech_prob": 0.0007431129342876375}, {"id": 199, "seek": 115088, "start": 1156.64, "end": 1161.2800000000002, "text": " divergent process we should almost optimize for people disagreeing with each other in the", "tokens": [50652, 18558, 6930, 1399, 321, 820, 1920, 19719, 337, 561, 14091, 278, 365, 1184, 661, 294, 264, 50884], "temperature": 0.0, "avg_logprob": -0.07000830463159864, "compression_ratio": 1.635036496350365, "no_speech_prob": 0.0007431129342876375}, {"id": 200, "seek": 115088, "start": 1161.2800000000002, "end": 1167.68, "text": " peer review process. I think the reviewing in our community is far too grumpy.", "tokens": [50884, 15108, 3131, 1399, 13, 286, 519, 264, 19576, 294, 527, 1768, 307, 1400, 886, 677, 36142, 13, 51204], "temperature": 0.0, "avg_logprob": -0.07000830463159864, "compression_ratio": 1.635036496350365, "no_speech_prob": 0.0007431129342876375}, {"id": 201, "seek": 115088, "start": 1167.68, "end": 1173.3600000000001, "text": " I'm continuously amazed when I read these old papers from let's say Schmidhuber and like the", "tokens": [51204, 286, 478, 15684, 20507, 562, 286, 1401, 613, 1331, 10577, 490, 718, 311, 584, 2065, 25394, 71, 10261, 293, 411, 264, 51488], "temperature": 0.0, "avg_logprob": -0.07000830463159864, "compression_ratio": 1.635036496350365, "no_speech_prob": 0.0007431129342876375}, {"id": 202, "seek": 115088, "start": 1173.3600000000001, "end": 1179.0400000000002, "text": " first RL papers that just came up with a bit of an idea and then they had a bit of toy data and", "tokens": [51488, 700, 497, 43, 10577, 300, 445, 1361, 493, 365, 257, 857, 295, 364, 1558, 293, 550, 436, 632, 257, 857, 295, 12058, 1412, 293, 51772], "temperature": 0.0, "avg_logprob": -0.07000830463159864, "compression_ratio": 1.635036496350365, "no_speech_prob": 0.0007431129342876375}, {"id": 203, "seek": 117904, "start": 1179.04, "end": 1183.52, "text": " right and that's a paper and it's cool. There's a dichotomy between on the one hand", "tokens": [50364, 558, 293, 300, 311, 257, 3035, 293, 309, 311, 1627, 13, 821, 311, 257, 10390, 310, 8488, 1296, 322, 264, 472, 1011, 50588], "temperature": 0.0, "avg_logprob": -0.08805726295293764, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.0019724213052541018}, {"id": 204, "seek": 117904, "start": 1183.52, "end": 1188.96, "text": " having a stamp of approval having a paper published and presenting about it and on the other hand", "tokens": [50588, 1419, 257, 9921, 295, 13317, 1419, 257, 3035, 6572, 293, 15578, 466, 309, 293, 322, 264, 661, 1011, 50860], "temperature": 0.0, "avg_logprob": -0.08805726295293764, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.0019724213052541018}, {"id": 205, "seek": 117904, "start": 1188.96, "end": 1195.84, "text": " having a continuous stream of research which is peer reviewed online and with some accountability.", "tokens": [50860, 1419, 257, 10957, 4309, 295, 2132, 597, 307, 15108, 18429, 2950, 293, 365, 512, 19380, 13, 51204], "temperature": 0.0, "avg_logprob": -0.08805726295293764, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.0019724213052541018}, {"id": 206, "seek": 117904, "start": 1196.3999999999999, "end": 1202.6399999999999, "text": " Yeah I think we really need to disrupt the field a little bit. Quantum machine learning is a bit", "tokens": [51232, 865, 286, 519, 321, 534, 643, 281, 14124, 264, 2519, 257, 707, 857, 13, 44964, 3479, 2539, 307, 257, 857, 51544], "temperature": 0.0, "avg_logprob": -0.08805726295293764, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.0019724213052541018}, {"id": 207, "seek": 120264, "start": 1202.64, "end": 1209.8400000000001, "text": " of a mystery to most people I feel including myself and even though I learned something in", "tokens": [50364, 295, 257, 11422, 281, 881, 561, 286, 841, 3009, 2059, 293, 754, 1673, 286, 3264, 746, 294, 50724], "temperature": 0.0, "avg_logprob": -0.06257773064947747, "compression_ratio": 1.6415929203539823, "no_speech_prob": 0.031123653054237366}, {"id": 208, "seek": 120264, "start": 1209.8400000000001, "end": 1215.68, "text": " this conversation paradoxically it's more of a mystery than before the conversation.", "tokens": [50724, 341, 3761, 26221, 984, 309, 311, 544, 295, 257, 11422, 813, 949, 264, 3761, 13, 51016], "temperature": 0.0, "avg_logprob": -0.06257773064947747, "compression_ratio": 1.6415929203539823, "no_speech_prob": 0.031123653054237366}, {"id": 209, "seek": 120264, "start": 1216.4, "end": 1222.96, "text": " Crucially Max thinks that quantum computing will hugely impact the machine learning world in the", "tokens": [51052, 13586, 1909, 7402, 7309, 300, 13018, 15866, 486, 27417, 2712, 264, 3479, 2539, 1002, 294, 264, 51380], "temperature": 0.0, "avg_logprob": -0.06257773064947747, "compression_ratio": 1.6415929203539823, "no_speech_prob": 0.031123653054237366}, {"id": 210, "seek": 120264, "start": 1222.96, "end": 1229.5200000000002, "text": " future. So you can think of quantum mechanics as another theory of statistics in some sense right.", "tokens": [51380, 2027, 13, 407, 291, 393, 519, 295, 13018, 12939, 382, 1071, 5261, 295, 12523, 294, 512, 2020, 558, 13, 51708], "temperature": 0.0, "avg_logprob": -0.06257773064947747, "compression_ratio": 1.6415929203539823, "no_speech_prob": 0.031123653054237366}, {"id": 211, "seek": 122952, "start": 1229.52, "end": 1236.8799999999999, "text": " Essentially quantum neural networks have nothing to do with particles necessarily or physics.", "tokens": [50364, 23596, 13018, 18161, 9590, 362, 1825, 281, 360, 365, 10007, 4725, 420, 10649, 13, 50732], "temperature": 0.0, "avg_logprob": -0.08015484128679548, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.0006067330250516534}, {"id": 212, "seek": 122952, "start": 1236.8799999999999, "end": 1244.72, "text": " It's applying the math behind quantum mechanics to machine learning and building neural networks", "tokens": [50732, 467, 311, 9275, 264, 5221, 2261, 13018, 12939, 281, 3479, 2539, 293, 2390, 18161, 9590, 51124], "temperature": 0.0, "avg_logprob": -0.08015484128679548, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.0006067330250516534}, {"id": 213, "seek": 122952, "start": 1244.72, "end": 1251.52, "text": " as layers of functions of these quantum operations that forward propagate some signal", "tokens": [51124, 382, 7914, 295, 6828, 295, 613, 13018, 7705, 300, 2128, 48256, 512, 6358, 51464], "temperature": 0.0, "avg_logprob": -0.08015484128679548, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.0006067330250516534}, {"id": 214, "seek": 122952, "start": 1252.48, "end": 1258.32, "text": " as Max describes really nicely in this conversation. This is the counterintuitive part which is", "tokens": [51512, 382, 7402, 15626, 534, 9594, 294, 341, 3761, 13, 639, 307, 264, 5682, 686, 48314, 644, 597, 307, 51804], "temperature": 0.0, "avg_logprob": -0.08015484128679548, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.0006067330250516534}, {"id": 215, "seek": 125832, "start": 1258.32, "end": 1262.32, "text": " you can have a probability for an event or an amplitude for an event and then you have an", "tokens": [50364, 291, 393, 362, 257, 8482, 337, 364, 2280, 420, 364, 27433, 337, 364, 2280, 293, 550, 291, 362, 364, 50564], "temperature": 0.0, "avg_logprob": -0.07732529687409354, "compression_ratio": 1.9012345679012346, "no_speech_prob": 0.0027932224329560995}, {"id": 216, "seek": 125832, "start": 1262.32, "end": 1266.72, "text": " amplitude for another event and you would think that if there's two probabilities for that event", "tokens": [50564, 27433, 337, 1071, 2280, 293, 291, 576, 519, 300, 498, 456, 311, 732, 33783, 337, 300, 2280, 50784], "temperature": 0.0, "avg_logprob": -0.07732529687409354, "compression_ratio": 1.9012345679012346, "no_speech_prob": 0.0027932224329560995}, {"id": 217, "seek": 125832, "start": 1266.72, "end": 1271.36, "text": " to happen then the probability of that event should grow but in quantum mechanics they can", "tokens": [50784, 281, 1051, 550, 264, 8482, 295, 300, 2280, 820, 1852, 457, 294, 13018, 12939, 436, 393, 51016], "temperature": 0.0, "avg_logprob": -0.07732529687409354, "compression_ratio": 1.9012345679012346, "no_speech_prob": 0.0027932224329560995}, {"id": 218, "seek": 125832, "start": 1271.36, "end": 1276.56, "text": " cancel and then the probability is suddenly zero that the event happens. So this seems bizarre but", "tokens": [51016, 10373, 293, 550, 264, 8482, 307, 5800, 4018, 300, 264, 2280, 2314, 13, 407, 341, 2544, 18265, 457, 51276], "temperature": 0.0, "avg_logprob": -0.07732529687409354, "compression_ratio": 1.9012345679012346, "no_speech_prob": 0.0027932224329560995}, {"id": 219, "seek": 125832, "start": 1276.56, "end": 1284.1599999999999, "text": " nature has chosen this theory of statistics anyway. I really felt like an ELI 5 here.", "tokens": [51276, 3687, 575, 8614, 341, 5261, 295, 12523, 4033, 13, 286, 534, 2762, 411, 364, 14426, 40, 1025, 510, 13, 51656], "temperature": 0.0, "avg_logprob": -0.07732529687409354, "compression_ratio": 1.9012345679012346, "no_speech_prob": 0.0027932224329560995}, {"id": 220, "seek": 128416, "start": 1284.16, "end": 1290.3200000000002, "text": " Instead of calculating with probabilities you calculate with something like the square root", "tokens": [50364, 7156, 295, 28258, 365, 33783, 291, 8873, 365, 746, 411, 264, 3732, 5593, 50672], "temperature": 0.0, "avg_logprob": -0.07288682138597644, "compression_ratio": 1.6837209302325582, "no_speech_prob": 0.0004582683613989502}, {"id": 221, "seek": 128416, "start": 1290.3200000000002, "end": 1297.52, "text": " of probabilities and thus events that can only stack in classical probability theory", "tokens": [50672, 295, 33783, 293, 8807, 3931, 300, 393, 787, 8630, 294, 13735, 8482, 5261, 51032], "temperature": 0.0, "avg_logprob": -0.07288682138597644, "compression_ratio": 1.6837209302325582, "no_speech_prob": 0.0004582683613989502}, {"id": 222, "seek": 128416, "start": 1297.52, "end": 1303.8400000000001, "text": " can all of a sudden cancel each other out and that gives rise to really interesting math.", "tokens": [51032, 393, 439, 295, 257, 3990, 10373, 1184, 661, 484, 293, 300, 2709, 6272, 281, 534, 1880, 5221, 13, 51348], "temperature": 0.0, "avg_logprob": -0.07288682138597644, "compression_ratio": 1.6837209302325582, "no_speech_prob": 0.0004582683613989502}, {"id": 223, "seek": 128416, "start": 1303.8400000000001, "end": 1308.4, "text": " We talk about Max's recent quantum paper that just got released and so that was a paper that we", "tokens": [51348, 492, 751, 466, 7402, 311, 5162, 13018, 3035, 300, 445, 658, 4736, 293, 370, 300, 390, 257, 3035, 300, 321, 51576], "temperature": 0.0, "avg_logprob": -0.07288682138597644, "compression_ratio": 1.6837209302325582, "no_speech_prob": 0.0004582683613989502}, {"id": 224, "seek": 130840, "start": 1309.1200000000001, "end": 1314.24, "text": " recently pushed on the archive which is quantum deformed neural networks which we basically", "tokens": [50400, 3938, 9152, 322, 264, 23507, 597, 307, 13018, 368, 22892, 18161, 9590, 597, 321, 1936, 50656], "temperature": 0.0, "avg_logprob": -0.06847890381960525, "compression_ratio": 1.8102766798418972, "no_speech_prob": 0.012614510953426361}, {"id": 225, "seek": 130840, "start": 1314.24, "end": 1318.96, "text": " first say okay what if we would take a normal neural net and implement it on a quantum computer", "tokens": [50656, 700, 584, 1392, 437, 498, 321, 576, 747, 257, 2710, 18161, 2533, 293, 4445, 309, 322, 257, 13018, 3820, 50892], "temperature": 0.0, "avg_logprob": -0.06847890381960525, "compression_ratio": 1.8102766798418972, "no_speech_prob": 0.012614510953426361}, {"id": 226, "seek": 130840, "start": 1318.96, "end": 1325.2, "text": " and then we slightly deform it into something where states get entangled. So by doing it in", "tokens": [50892, 293, 550, 321, 4748, 36094, 309, 666, 746, 689, 4368, 483, 948, 39101, 13, 407, 538, 884, 309, 294, 51204], "temperature": 0.0, "avg_logprob": -0.06847890381960525, "compression_ratio": 1.8102766798418972, "no_speech_prob": 0.012614510953426361}, {"id": 227, "seek": 130840, "start": 1325.2, "end": 1329.6000000000001, "text": " this particular way we could still run it efficiently on a classical computer. What this", "tokens": [51204, 341, 1729, 636, 321, 727, 920, 1190, 309, 19621, 322, 257, 13735, 3820, 13, 708, 341, 51424], "temperature": 0.0, "avg_logprob": -0.06847890381960525, "compression_ratio": 1.8102766798418972, "no_speech_prob": 0.012614510953426361}, {"id": 228, "seek": 130840, "start": 1329.6000000000001, "end": 1336.24, "text": " paper here did was to build a particular type of neural network of quantum neural network", "tokens": [51424, 3035, 510, 630, 390, 281, 1322, 257, 1729, 2010, 295, 18161, 3209, 295, 13018, 18161, 3209, 51756], "temperature": 0.0, "avg_logprob": -0.06847890381960525, "compression_ratio": 1.8102766798418972, "no_speech_prob": 0.012614510953426361}, {"id": 229, "seek": 133624, "start": 1336.72, "end": 1344.72, "text": " that can under the correct assumptions be simulated efficiently on a classical computer", "tokens": [50388, 300, 393, 833, 264, 3006, 17695, 312, 41713, 19621, 322, 257, 13735, 3820, 50788], "temperature": 0.0, "avg_logprob": -0.07235300699869791, "compression_ratio": 1.7766990291262137, "no_speech_prob": 0.0016733015654608607}, {"id": 230, "seek": 133624, "start": 1344.72, "end": 1350.48, "text": " but also once we have a quantum computer it can release its full power basically.", "tokens": [50788, 457, 611, 1564, 321, 362, 257, 13018, 3820, 309, 393, 4374, 1080, 1577, 1347, 1936, 13, 51076], "temperature": 0.0, "avg_logprob": -0.07235300699869791, "compression_ratio": 1.7766990291262137, "no_speech_prob": 0.0016733015654608607}, {"id": 231, "seek": 133624, "start": 1351.1200000000001, "end": 1356.96, "text": " If you want to do classical predictions does it actually help to build a neural network that", "tokens": [51108, 759, 291, 528, 281, 360, 13735, 21264, 775, 309, 767, 854, 281, 1322, 257, 18161, 3209, 300, 51400], "temperature": 0.0, "avg_logprob": -0.07235300699869791, "compression_ratio": 1.7766990291262137, "no_speech_prob": 0.0016733015654608607}, {"id": 232, "seek": 133624, "start": 1356.96, "end": 1362.48, "text": " can run efficiently on a quantum computer that can do these predictions much better. Can you write down", "tokens": [51400, 393, 1190, 19621, 322, 257, 13018, 3820, 300, 393, 360, 613, 21264, 709, 1101, 13, 1664, 291, 2464, 760, 51676], "temperature": 0.0, "avg_logprob": -0.07235300699869791, "compression_ratio": 1.7766990291262137, "no_speech_prob": 0.0016733015654608607}, {"id": 233, "seek": 136248, "start": 1362.72, "end": 1370.56, "text": " maybe even normal classical problems more conveniently in this quantum statistics.", "tokens": [50376, 1310, 754, 2710, 13735, 2740, 544, 44375, 294, 341, 13018, 12523, 13, 50768], "temperature": 0.0, "avg_logprob": -0.1807160618329289, "compression_ratio": 1.5571428571428572, "no_speech_prob": 0.0017545189475640655}, {"id": 234, "seek": 136248, "start": 1370.56, "end": 1375.52, "text": " I found the conversation with Max to be extremely helpful here and he does a great", "tokens": [50768, 286, 1352, 264, 3761, 365, 7402, 281, 312, 4664, 4961, 510, 293, 415, 775, 257, 869, 51016], "temperature": 0.0, "avg_logprob": -0.1807160618329289, "compression_ratio": 1.5571428571428572, "no_speech_prob": 0.0017545189475640655}, {"id": 235, "seek": 136248, "start": 1375.52, "end": 1381.52, "text": " job of explaining what's going on. Max has another exciting paper out. Probabilistic", "tokens": [51016, 1691, 295, 13468, 437, 311, 516, 322, 13, 7402, 575, 1071, 4670, 3035, 484, 13, 8736, 5177, 3142, 51316], "temperature": 0.0, "avg_logprob": -0.1807160618329289, "compression_ratio": 1.5571428571428572, "no_speech_prob": 0.0017545189475640655}, {"id": 236, "seek": 136248, "start": 1381.52, "end": 1386.48, "text": " numeric convolutional neural networks it's a paper by Mark Finzi, Roberto Bondeson and of", "tokens": [51316, 7866, 299, 45216, 304, 18161, 9590, 309, 311, 257, 3035, 538, 3934, 3773, 3992, 11, 40354, 23604, 279, 266, 293, 295, 51564], "temperature": 0.0, "avg_logprob": -0.1807160618329289, "compression_ratio": 1.5571428571428572, "no_speech_prob": 0.0017545189475640655}, {"id": 237, "seek": 136248, "start": 1386.48, "end": 1390.72, "text": " course Max Welling and it looks at what you can do with computer vision models if you move away", "tokens": [51564, 1164, 7402, 1042, 278, 293, 309, 1542, 412, 437, 291, 393, 360, 365, 3820, 5201, 5245, 498, 291, 1286, 1314, 51776], "temperature": 0.0, "avg_logprob": -0.1807160618329289, "compression_ratio": 1.5571428571428572, "no_speech_prob": 0.0017545189475640655}, {"id": 238, "seek": 139072, "start": 1390.72, "end": 1395.92, "text": " from the assumption of discreetly sampled pixel grids and move to a continuous representation", "tokens": [50364, 490, 264, 15302, 295, 2983, 4751, 356, 3247, 15551, 19261, 677, 3742, 293, 1286, 281, 257, 10957, 10290, 50624], "temperature": 0.0, "avg_logprob": -0.0625224334222299, "compression_ratio": 1.7216117216117217, "no_speech_prob": 0.0037640740629285574}, {"id": 239, "seek": 139072, "start": 1395.92, "end": 1401.1200000000001, "text": " that's more like what an actual object in the real world projected on a screen behaves like.", "tokens": [50624, 300, 311, 544, 411, 437, 364, 3539, 2657, 294, 264, 957, 1002, 26231, 322, 257, 2568, 36896, 411, 13, 50884], "temperature": 0.0, "avg_logprob": -0.0625224334222299, "compression_ratio": 1.7216117216117217, "no_speech_prob": 0.0037640740629285574}, {"id": 240, "seek": 139072, "start": 1401.1200000000001, "end": 1407.92, "text": " The observation is when we write down a deep learning algorithm let's say on for an image", "tokens": [50884, 440, 14816, 307, 562, 321, 2464, 760, 257, 2452, 2539, 9284, 718, 311, 584, 322, 337, 364, 3256, 51224], "temperature": 0.0, "avg_logprob": -0.0625224334222299, "compression_ratio": 1.7216117216117217, "no_speech_prob": 0.0037640740629285574}, {"id": 241, "seek": 139072, "start": 1408.56, "end": 1413.44, "text": " then we sort of treat the image as pixels and we think that's the real signal that we are looking", "tokens": [51256, 550, 321, 1333, 295, 2387, 264, 3256, 382, 18668, 293, 321, 519, 300, 311, 264, 957, 6358, 300, 321, 366, 1237, 51500], "temperature": 0.0, "avg_logprob": -0.0625224334222299, "compression_ratio": 1.7216117216117217, "no_speech_prob": 0.0037640740629285574}, {"id": 242, "seek": 139072, "start": 1413.44, "end": 1419.28, "text": " at but you can also ask yourself what if I remove every second pixel now actually I have a very", "tokens": [51500, 412, 457, 291, 393, 611, 1029, 1803, 437, 498, 286, 4159, 633, 1150, 19261, 586, 767, 286, 362, 257, 588, 51792], "temperature": 0.0, "avg_logprob": -0.0625224334222299, "compression_ratio": 1.7216117216117217, "no_speech_prob": 0.0037640740629285574}, {"id": 243, "seek": 141928, "start": 1419.28, "end": 1423.44, "text": " different neural network but should I have a very different neural network or what if the pixels are", "tokens": [50364, 819, 18161, 3209, 457, 820, 286, 362, 257, 588, 819, 18161, 3209, 420, 437, 498, 264, 18668, 366, 50572], "temperature": 0.0, "avg_logprob": -0.0939274659523597, "compression_ratio": 1.7625899280575539, "no_speech_prob": 0.005382496863603592}, {"id": 244, "seek": 141928, "start": 1423.44, "end": 1430.24, "text": " actually quite randomly distributed in the plane it's just some random places where I do measurements", "tokens": [50572, 767, 1596, 16979, 12631, 294, 264, 5720, 309, 311, 445, 512, 4974, 3190, 689, 286, 360, 15383, 50912], "temperature": 0.0, "avg_logprob": -0.0939274659523597, "compression_ratio": 1.7625899280575539, "no_speech_prob": 0.005382496863603592}, {"id": 245, "seek": 141928, "start": 1430.24, "end": 1435.52, "text": " maybe more on the left upper corner and and fear on the left lower corner what the predictor should", "tokens": [50912, 1310, 544, 322, 264, 1411, 6597, 4538, 293, 293, 4240, 322, 264, 1411, 3126, 4538, 437, 264, 6069, 284, 820, 51176], "temperature": 0.0, "avg_logprob": -0.0939274659523597, "compression_ratio": 1.7625899280575539, "no_speech_prob": 0.005382496863603592}, {"id": 246, "seek": 141928, "start": 1435.52, "end": 1440.72, "text": " behave in a certain consistent way and so of course then you come to realize that really what", "tokens": [51176, 15158, 294, 257, 1629, 8398, 636, 293, 370, 295, 1164, 550, 291, 808, 281, 4325, 300, 534, 437, 51436], "temperature": 0.0, "avg_logprob": -0.0939274659523597, "compression_ratio": 1.7625899280575539, "no_speech_prob": 0.005382496863603592}, {"id": 247, "seek": 141928, "start": 1440.72, "end": 1446.72, "text": " you're doing is with a pixel grid is sampling an underlying continuous signal. So to get away", "tokens": [51436, 291, 434, 884, 307, 365, 257, 19261, 10748, 307, 21179, 364, 14217, 10957, 6358, 13, 407, 281, 483, 1314, 51736], "temperature": 0.0, "avg_logprob": -0.0939274659523597, "compression_ratio": 1.7625899280575539, "no_speech_prob": 0.005382496863603592}, {"id": 248, "seek": 144672, "start": 1446.72, "end": 1451.3600000000001, "text": " from this assumption of this discreet even sampling they use these objects called Gaussian", "tokens": [50364, 490, 341, 15302, 295, 341, 2983, 4751, 754, 21179, 436, 764, 613, 6565, 1219, 39148, 50596], "temperature": 0.0, "avg_logprob": -0.09605303764343262, "compression_ratio": 1.7453183520599251, "no_speech_prob": 0.002714486327022314}, {"id": 249, "seek": 144672, "start": 1451.3600000000001, "end": 1456.48, "text": " processes to model the data and a Gaussian process it's basically a universal function", "tokens": [50596, 7555, 281, 2316, 264, 1412, 293, 257, 39148, 1399, 309, 311, 1936, 257, 11455, 2445, 50852], "temperature": 0.0, "avg_logprob": -0.09605303764343262, "compression_ratio": 1.7453183520599251, "no_speech_prob": 0.002714486327022314}, {"id": 250, "seek": 144672, "start": 1456.48, "end": 1462.08, "text": " approximated like in your own network but it gives you a measure of uncertainty and the reason you", "tokens": [50852, 8542, 770, 411, 294, 428, 1065, 3209, 457, 309, 2709, 291, 257, 3481, 295, 15697, 293, 264, 1778, 291, 51132], "temperature": 0.0, "avg_logprob": -0.09605303764343262, "compression_ratio": 1.7453183520599251, "no_speech_prob": 0.002714486327022314}, {"id": 251, "seek": 144672, "start": 1462.08, "end": 1466.4, "text": " might want to do this are many but in short it allows you to average over every possible model", "tokens": [51132, 1062, 528, 281, 360, 341, 366, 867, 457, 294, 2099, 309, 4045, 291, 281, 4274, 670, 633, 1944, 2316, 51348], "temperature": 0.0, "avg_logprob": -0.09605303764343262, "compression_ratio": 1.7453183520599251, "no_speech_prob": 0.002714486327022314}, {"id": 252, "seek": 144672, "start": 1466.4, "end": 1471.84, "text": " that describes your data and gives you a better result. In doing so you can start to do really", "tokens": [51348, 300, 15626, 428, 1412, 293, 2709, 291, 257, 1101, 1874, 13, 682, 884, 370, 291, 393, 722, 281, 360, 534, 51620], "temperature": 0.0, "avg_logprob": -0.09605303764343262, "compression_ratio": 1.7453183520599251, "no_speech_prob": 0.002714486327022314}, {"id": 253, "seek": 147184, "start": 1471.84, "end": 1477.76, "text": " interesting things like subpixel sampling or work with very sparse locations but in order to do that", "tokens": [50364, 1880, 721, 411, 1422, 79, 34599, 21179, 420, 589, 365, 588, 637, 11668, 9253, 457, 294, 1668, 281, 360, 300, 50660], "temperature": 0.0, "avg_logprob": -0.0814978735787528, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.007344077806919813}, {"id": 254, "seek": 147184, "start": 1477.76, "end": 1482.32, "text": " you need to re-conceptualize a lot of the familiar operators that work on our linear algebra", "tokens": [50660, 291, 643, 281, 319, 12, 1671, 1336, 901, 1125, 257, 688, 295, 264, 4963, 19077, 300, 589, 322, 527, 8213, 21989, 50888], "temperature": 0.0, "avg_logprob": -0.0814978735787528, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.007344077806919813}, {"id": 255, "seek": 147184, "start": 1482.32, "end": 1488.1599999999999, "text": " representations such as like the the convolutional translation operation of our weights. The way", "tokens": [50888, 33358, 1270, 382, 411, 264, 264, 45216, 304, 12853, 6916, 295, 527, 17443, 13, 440, 636, 51180], "temperature": 0.0, "avg_logprob": -0.0814978735787528, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.007344077806919813}, {"id": 256, "seek": 147184, "start": 1488.1599999999999, "end": 1493.12, "text": " they got around this was super interesting. So there's a very interesting tool which is called", "tokens": [51180, 436, 658, 926, 341, 390, 1687, 1880, 13, 407, 456, 311, 257, 588, 1880, 2290, 597, 307, 1219, 51428], "temperature": 0.0, "avg_logprob": -0.0814978735787528, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.007344077806919813}, {"id": 257, "seek": 147184, "start": 1493.12, "end": 1499.28, "text": " the Gaussian process it's basically interpolates between dots but in places where you don't have", "tokens": [51428, 264, 39148, 1399, 309, 311, 1936, 44902, 1024, 1296, 15026, 457, 294, 3190, 689, 291, 500, 380, 362, 51736], "temperature": 0.0, "avg_logprob": -0.0814978735787528, "compression_ratio": 1.7031802120141342, "no_speech_prob": 0.007344077806919813}, {"id": 258, "seek": 149928, "start": 1499.28, "end": 1505.68, "text": " a lot of data you create uncertainty because you don't know what the real signal is. What does it mean", "tokens": [50364, 257, 688, 295, 1412, 291, 1884, 15697, 570, 291, 500, 380, 458, 437, 264, 957, 6358, 307, 13, 708, 775, 309, 914, 50684], "temperature": 0.0, "avg_logprob": -0.06176575789084801, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.0007096429471857846}, {"id": 259, "seek": 149928, "start": 1505.68, "end": 1511.92, "text": " to do a convolution on this space? The most interesting way to describe that is by looking", "tokens": [50684, 281, 360, 257, 45216, 322, 341, 1901, 30, 440, 881, 1880, 636, 281, 6786, 300, 307, 538, 1237, 50996], "temperature": 0.0, "avg_logprob": -0.06176575789084801, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.0007096429471857846}, {"id": 260, "seek": 149928, "start": 1511.92, "end": 1517.6, "text": " at it as a partial differential equation. So they reframe this transformation as a differential", "tokens": [50996, 412, 309, 382, 257, 14641, 15756, 5367, 13, 407, 436, 13334, 529, 341, 9887, 382, 257, 15756, 51280], "temperature": 0.0, "avg_logprob": -0.06176575789084801, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.0007096429471857846}, {"id": 261, "seek": 149928, "start": 1517.6, "end": 1522.8799999999999, "text": " equation that could just be parameterized calculated out in a closed form and directly", "tokens": [51280, 5367, 300, 727, 445, 312, 13075, 1602, 15598, 484, 294, 257, 5395, 1254, 293, 3838, 51544], "temperature": 0.0, "avg_logprob": -0.06176575789084801, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.0007096429471857846}, {"id": 262, "seek": 149928, "start": 1522.8799999999999, "end": 1526.56, "text": " applied to the parameters of the model that means you don't need to like do any sampling or anything", "tokens": [51544, 6456, 281, 264, 9834, 295, 264, 2316, 300, 1355, 291, 500, 380, 643, 281, 411, 360, 604, 21179, 420, 1340, 51728], "temperature": 0.0, "avg_logprob": -0.06176575789084801, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.0007096429471857846}, {"id": 263, "seek": 152656, "start": 1526.56, "end": 1530.0, "text": " like that you literally just calculate this thing apply it. It would be worth going into the", "tokens": [50364, 411, 300, 291, 3736, 445, 8873, 341, 551, 3079, 309, 13, 467, 576, 312, 3163, 516, 666, 264, 50536], "temperature": 0.0, "avg_logprob": -0.10134238527532209, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.025950515642762184}, {"id": 264, "seek": 152656, "start": 1530.0, "end": 1535.6, "text": " differential equation stuff by itself but it gets very complicated very quickly needless to say it", "tokens": [50536, 15756, 5367, 1507, 538, 2564, 457, 309, 2170, 588, 6179, 588, 2661, 643, 1832, 281, 584, 309, 50816], "temperature": 0.0, "avg_logprob": -0.10134238527532209, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.025950515642762184}, {"id": 265, "seek": 152656, "start": 1535.6, "end": 1541.04, "text": " generalizes not just translation but also things like rotations and scaling but the way that they", "tokens": [50816, 2674, 5660, 406, 445, 12853, 457, 611, 721, 411, 44796, 293, 21589, 457, 264, 636, 300, 436, 51088], "temperature": 0.0, "avg_logprob": -0.10134238527532209, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.025950515642762184}, {"id": 266, "seek": 152656, "start": 1541.04, "end": 1545.28, "text": " really did this was by finding very clever representations. It boiled everything down to", "tokens": [51088, 534, 630, 341, 390, 538, 5006, 588, 13494, 33358, 13, 467, 21058, 1203, 760, 281, 51300], "temperature": 0.0, "avg_logprob": -0.10134238527532209, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.025950515642762184}, {"id": 267, "seek": 152656, "start": 1545.28, "end": 1549.84, "text": " normal distributions or almost everything could just be done in closed form which things have been", "tokens": [51300, 2710, 37870, 420, 1920, 1203, 727, 445, 312, 1096, 294, 5395, 1254, 597, 721, 362, 668, 51528], "temperature": 0.0, "avg_logprob": -0.10134238527532209, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.025950515642762184}, {"id": 268, "seek": 152656, "start": 1549.84, "end": 1554.1599999999999, "text": " done with the Gaussian processes in the past but they're typically computationally expensive so if", "tokens": [51528, 1096, 365, 264, 39148, 7555, 294, 264, 1791, 457, 436, 434, 5850, 24903, 379, 5124, 370, 498, 51744], "temperature": 0.0, "avg_logprob": -0.10134238527532209, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.025950515642762184}, {"id": 269, "seek": 155416, "start": 1554.16, "end": 1560.0, "text": " you can do all these updates without constant re-computation then that's a huge computation", "tokens": [50364, 291, 393, 360, 439, 613, 9205, 1553, 5754, 319, 12, 1112, 2582, 399, 550, 300, 311, 257, 2603, 24903, 50656], "temperature": 0.0, "avg_logprob": -0.09663500104631696, "compression_ratio": 1.7915057915057915, "no_speech_prob": 0.0026314817368984222}, {"id": 270, "seek": 155416, "start": 1560.0, "end": 1564.48, "text": " and an advantage. The paper does some really cool things. Some of the benefits are now that", "tokens": [50656, 293, 364, 5002, 13, 440, 3035, 775, 512, 534, 1627, 721, 13, 2188, 295, 264, 5311, 366, 586, 300, 50880], "temperature": 0.0, "avg_logprob": -0.09663500104631696, "compression_ratio": 1.7915057915057915, "no_speech_prob": 0.0026314817368984222}, {"id": 271, "seek": 155416, "start": 1564.48, "end": 1569.28, "text": " first of all of course you cannot work on a unstructured set of points doesn't have to be a", "tokens": [50880, 700, 295, 439, 295, 1164, 291, 2644, 589, 322, 257, 18799, 46847, 992, 295, 2793, 1177, 380, 362, 281, 312, 257, 51120], "temperature": 0.0, "avg_logprob": -0.09663500104631696, "compression_ratio": 1.7915057915057915, "no_speech_prob": 0.0026314817368984222}, {"id": 272, "seek": 155416, "start": 1569.28, "end": 1574.96, "text": " grid and you can even learn the positions of those points so you cannot direct the observations", "tokens": [51120, 10748, 293, 291, 393, 754, 1466, 264, 8432, 295, 729, 2793, 370, 291, 2644, 2047, 264, 18163, 51404], "temperature": 0.0, "avg_logprob": -0.09663500104631696, "compression_ratio": 1.7915057915057915, "no_speech_prob": 0.0026314817368984222}, {"id": 273, "seek": 155416, "start": 1575.76, "end": 1580.72, "text": " in places where you really need to do your observations in order to improve your prediction.", "tokens": [51444, 294, 3190, 689, 291, 534, 643, 281, 360, 428, 18163, 294, 1668, 281, 3470, 428, 17630, 13, 51692], "temperature": 0.0, "avg_logprob": -0.09663500104631696, "compression_ratio": 1.7915057915057915, "no_speech_prob": 0.0026314817368984222}, {"id": 274, "seek": 158072, "start": 1580.72, "end": 1586.64, "text": " So it turns out that all of this can be remapped back onto the quantum paradigm. I must admit I'm", "tokens": [50364, 407, 309, 4523, 484, 300, 439, 295, 341, 393, 312, 890, 20780, 646, 3911, 264, 13018, 24709, 13, 286, 1633, 9796, 286, 478, 50660], "temperature": 0.0, "avg_logprob": -0.057630300521850586, "compression_ratio": 1.708185053380783, "no_speech_prob": 0.0007546411361545324}, {"id": 275, "seek": 158072, "start": 1586.64, "end": 1591.68, "text": " almost gutted that I didn't study physics at university. Physics seems to be one of the most", "tokens": [50660, 1920, 5228, 14727, 300, 286, 994, 380, 2979, 10649, 412, 5454, 13, 38355, 2544, 281, 312, 472, 295, 264, 881, 50912], "temperature": 0.0, "avg_logprob": -0.057630300521850586, "compression_ratio": 1.708185053380783, "no_speech_prob": 0.0007546411361545324}, {"id": 276, "seek": 158072, "start": 1591.68, "end": 1597.6000000000001, "text": " robust scientific disciplines and the folks are just so smart because it's really really difficult", "tokens": [50912, 13956, 8134, 21919, 293, 264, 4024, 366, 445, 370, 4069, 570, 309, 311, 534, 534, 2252, 51208], "temperature": 0.0, "avg_logprob": -0.057630300521850586, "compression_ratio": 1.708185053380783, "no_speech_prob": 0.0007546411361545324}, {"id": 277, "seek": 158072, "start": 1597.6000000000001, "end": 1602.56, "text": " and what I notice is that it's very very difficult for external folks to get anything published in", "tokens": [51208, 293, 437, 286, 3449, 307, 300, 309, 311, 588, 588, 2252, 337, 8320, 4024, 281, 483, 1340, 6572, 294, 51456], "temperature": 0.0, "avg_logprob": -0.057630300521850586, "compression_ratio": 1.708185053380783, "no_speech_prob": 0.0007546411361545324}, {"id": 278, "seek": 158072, "start": 1602.56, "end": 1607.52, "text": " the physics world but there's an asymmetry the reverse isn't true loads of these physicists", "tokens": [51456, 264, 10649, 1002, 457, 456, 311, 364, 37277, 9889, 264, 9943, 1943, 380, 2074, 12668, 295, 613, 48716, 51704], "temperature": 0.0, "avg_logprob": -0.057630300521850586, "compression_ratio": 1.708185053380783, "no_speech_prob": 0.0007546411361545324}, {"id": 279, "seek": 160752, "start": 1607.52, "end": 1611.6, "text": " are coming into the machine learning world and they're just implementing all of these things", "tokens": [50364, 366, 1348, 666, 264, 3479, 2539, 1002, 293, 436, 434, 445, 18114, 439, 295, 613, 721, 50568], "temperature": 0.0, "avg_logprob": -0.11523205472021988, "compression_ratio": 1.528, "no_speech_prob": 0.002887323033064604}, {"id": 280, "seek": 160752, "start": 1611.6, "end": 1617.92, "text": " whether it's symmetries manifold topology chaos it's really really interesting to see this unfold.", "tokens": [50568, 1968, 309, 311, 14232, 302, 2244, 47138, 1192, 1793, 14158, 309, 311, 534, 534, 1880, 281, 536, 341, 17980, 13, 50884], "temperature": 0.0, "avg_logprob": -0.11523205472021988, "compression_ratio": 1.528, "no_speech_prob": 0.002887323033064604}, {"id": 281, "seek": 160752, "start": 1617.92, "end": 1625.04, "text": " We also get a take from Max about GPT-3 and so you say GPT-3 isn't very good maybe but it's a", "tokens": [50884, 492, 611, 483, 257, 747, 490, 7402, 466, 26039, 51, 12, 18, 293, 370, 291, 584, 26039, 51, 12, 18, 1943, 380, 588, 665, 1310, 457, 309, 311, 257, 51240], "temperature": 0.0, "avg_logprob": -0.11523205472021988, "compression_ratio": 1.528, "no_speech_prob": 0.002887323033064604}, {"id": 282, "seek": 160752, "start": 1625.04, "end": 1631.12, "text": " receding horizon right. I had a chat with my old colleague from Microsoft Ilya Karmanov about 18", "tokens": [51240, 850, 9794, 18046, 558, 13, 286, 632, 257, 5081, 365, 452, 1331, 13532, 490, 8116, 286, 45106, 591, 4452, 38990, 466, 2443, 51544], "temperature": 0.0, "avg_logprob": -0.11523205472021988, "compression_ratio": 1.528, "no_speech_prob": 0.002887323033064604}, {"id": 283, "seek": 163112, "start": 1631.12, "end": 1637.4399999999998, "text": " months ago he introduced me to Max Welling's work it absolutely fascinated me ever since", "tokens": [50364, 2493, 2057, 415, 7268, 385, 281, 7402, 1042, 278, 311, 589, 309, 3122, 24597, 385, 1562, 1670, 50680], "temperature": 0.0, "avg_logprob": -0.10606082455142514, "compression_ratio": 1.6347826086956523, "no_speech_prob": 0.04632722958922386}, {"id": 284, "seek": 163112, "start": 1637.4399999999998, "end": 1643.36, "text": " and guess what Ilya left Microsoft and he went to Qualcomm. Hey Tim how's it going? Ilya is going", "tokens": [50680, 293, 2041, 437, 286, 45106, 1411, 8116, 293, 415, 1437, 281, 13616, 13278, 13, 1911, 7172, 577, 311, 309, 516, 30, 286, 45106, 307, 516, 50976], "temperature": 0.0, "avg_logprob": -0.10606082455142514, "compression_ratio": 1.6347826086956523, "no_speech_prob": 0.04632722958922386}, {"id": 285, "seek": 163112, "start": 1643.36, "end": 1650.6399999999999, "text": " great how are you? I'm good different country different job different universe it seems but", "tokens": [50976, 869, 577, 366, 291, 30, 286, 478, 665, 819, 1941, 819, 1691, 819, 6445, 309, 2544, 457, 51340], "temperature": 0.0, "avg_logprob": -0.10606082455142514, "compression_ratio": 1.6347826086956523, "no_speech_prob": 0.04632722958922386}, {"id": 286, "seek": 163112, "start": 1650.6399999999999, "end": 1657.04, "text": " I'm doing pretty well. Ilya and I used to be work colleagues at Microsoft UK and I left Microsoft", "tokens": [51340, 286, 478, 884, 1238, 731, 13, 286, 45106, 293, 286, 1143, 281, 312, 589, 7734, 412, 8116, 7051, 293, 286, 1411, 8116, 51660], "temperature": 0.0, "avg_logprob": -0.10606082455142514, "compression_ratio": 1.6347826086956523, "no_speech_prob": 0.04632722958922386}, {"id": 287, "seek": 165704, "start": 1657.04, "end": 1661.76, "text": " about a year ago and actually you left as well didn't you Ilya? Yeah we have a joint pact it was", "tokens": [50364, 466, 257, 1064, 2057, 293, 767, 291, 1411, 382, 731, 994, 380, 291, 286, 45106, 30, 865, 321, 362, 257, 7225, 38104, 309, 390, 50600], "temperature": 0.0, "avg_logprob": -0.07337116594074153, "compression_ratio": 1.6821428571428572, "no_speech_prob": 0.07991290092468262}, {"id": 288, "seek": 165704, "start": 1661.76, "end": 1668.56, "text": " like you have to keep both of us or we leave. Indeed now Ilya and I made a YouTube video", "tokens": [50600, 411, 291, 362, 281, 1066, 1293, 295, 505, 420, 321, 1856, 13, 15061, 586, 286, 45106, 293, 286, 1027, 257, 3088, 960, 50940], "temperature": 0.0, "avg_logprob": -0.07337116594074153, "compression_ratio": 1.6821428571428572, "no_speech_prob": 0.07991290092468262}, {"id": 289, "seek": 165704, "start": 1668.56, "end": 1674.1599999999999, "text": " just over a year ago and it was all about Max Welling's work with Tako Kohen all about symmetries", "tokens": [50940, 445, 670, 257, 1064, 2057, 293, 309, 390, 439, 466, 7402, 1042, 278, 311, 589, 365, 9118, 78, 30861, 268, 439, 466, 14232, 302, 2244, 51220], "temperature": 0.0, "avg_logprob": -0.07337116594074153, "compression_ratio": 1.6821428571428572, "no_speech_prob": 0.07991290092468262}, {"id": 290, "seek": 165704, "start": 1674.1599999999999, "end": 1680.6399999999999, "text": " and manifolds and this work was hugely inspiring for me how did you discover it? I discovered it", "tokens": [51220, 293, 8173, 31518, 293, 341, 589, 390, 27417, 15883, 337, 385, 577, 630, 291, 4411, 309, 30, 286, 6941, 309, 51544], "temperature": 0.0, "avg_logprob": -0.07337116594074153, "compression_ratio": 1.6821428571428572, "no_speech_prob": 0.07991290092468262}, {"id": 291, "seek": 165704, "start": 1680.6399999999999, "end": 1685.84, "text": " because my colleague Matthew and I whom you also interviewed and you should follow up with", "tokens": [51544, 570, 452, 13532, 12434, 293, 286, 7101, 291, 611, 19770, 293, 291, 820, 1524, 493, 365, 51804], "temperature": 0.0, "avg_logprob": -0.07337116594074153, "compression_ratio": 1.6821428571428572, "no_speech_prob": 0.07991290092468262}, {"id": 292, "seek": 168584, "start": 1685.84, "end": 1692.9599999999998, "text": " that. We were at Ilya and we saw Tako's talk about spherical CNNs which was a bit late already into", "tokens": [50364, 300, 13, 492, 645, 412, 286, 45106, 293, 321, 1866, 9118, 78, 311, 751, 466, 37300, 24859, 82, 597, 390, 257, 857, 3469, 1217, 666, 50720], "temperature": 0.0, "avg_logprob": -0.12398654167805243, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.015022764913737774}, {"id": 293, "seek": 168584, "start": 1692.9599999999998, "end": 1697.36, "text": " his work which started with group equilibrium convolutions and I think both of us just thought", "tokens": [50720, 702, 589, 597, 1409, 365, 1594, 15625, 3754, 15892, 293, 286, 519, 1293, 295, 505, 445, 1194, 50940], "temperature": 0.0, "avg_logprob": -0.12398654167805243, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.015022764913737774}, {"id": 294, "seek": 168584, "start": 1697.36, "end": 1701.6799999999998, "text": " it was really cool it was our favorite talk for the day because it was so different and it felt", "tokens": [50940, 309, 390, 534, 1627, 309, 390, 527, 2954, 751, 337, 264, 786, 570, 309, 390, 370, 819, 293, 309, 2762, 51156], "temperature": 0.0, "avg_logprob": -0.12398654167805243, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.015022764913737774}, {"id": 295, "seek": 168584, "start": 1701.6799999999998, "end": 1706.72, "text": " like it was setting up a different stream of research it wasn't necessarily about chasing", "tokens": [51156, 411, 309, 390, 3287, 493, 257, 819, 4309, 295, 2132, 309, 2067, 380, 4725, 466, 17876, 51408], "temperature": 0.0, "avg_logprob": -0.12398654167805243, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.015022764913737774}, {"id": 296, "seek": 168584, "start": 1706.72, "end": 1712.0, "text": " SOTA it was just about really improving taking what makes convolutions great and making them even", "tokens": [51408, 318, 5068, 32, 309, 390, 445, 466, 534, 11470, 1940, 437, 1669, 3754, 15892, 869, 293, 1455, 552, 754, 51672], "temperature": 0.0, "avg_logprob": -0.12398654167805243, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.015022764913737774}, {"id": 297, "seek": 171200, "start": 1712.0, "end": 1717.44, "text": " better and that was awesome. Oh amazing well we made that video together on Machine Learning Dojo", "tokens": [50364, 1101, 293, 300, 390, 3476, 13, 876, 2243, 731, 321, 1027, 300, 960, 1214, 322, 22155, 15205, 1144, 5134, 50636], "temperature": 0.0, "avg_logprob": -0.07705096331509677, "compression_ratio": 1.6807017543859648, "no_speech_prob": 0.052171315997838974}, {"id": 298, "seek": 171200, "start": 1717.44, "end": 1723.04, "text": " and I must admit it was hugely inspiring for me and I reached out to Max Welling about two months", "tokens": [50636, 293, 286, 1633, 9796, 309, 390, 27417, 15883, 337, 385, 293, 286, 6488, 484, 281, 7402, 1042, 278, 466, 732, 2493, 50916], "temperature": 0.0, "avg_logprob": -0.07705096331509677, "compression_ratio": 1.6807017543859648, "no_speech_prob": 0.052171315997838974}, {"id": 299, "seek": 171200, "start": 1723.04, "end": 1727.76, "text": " ago and he actually came onto our podcast we interviewed him yesterday but yeah it all came", "tokens": [50916, 2057, 293, 415, 767, 1361, 3911, 527, 7367, 321, 19770, 796, 5186, 457, 1338, 309, 439, 1361, 51152], "temperature": 0.0, "avg_logprob": -0.07705096331509677, "compression_ratio": 1.6807017543859648, "no_speech_prob": 0.052171315997838974}, {"id": 300, "seek": 171200, "start": 1727.76, "end": 1731.92, "text": " from you and you know you introduced all of this stuff to me and I've been going through some of", "tokens": [51152, 490, 291, 293, 291, 458, 291, 7268, 439, 295, 341, 1507, 281, 385, 293, 286, 600, 668, 516, 807, 512, 295, 51360], "temperature": 0.0, "avg_logprob": -0.07705096331509677, "compression_ratio": 1.6807017543859648, "no_speech_prob": 0.052171315997838974}, {"id": 301, "seek": 171200, "start": 1731.92, "end": 1737.36, "text": " Max's work with some of his recent students and it's just incredible it's because he came from", "tokens": [51360, 7402, 311, 589, 365, 512, 295, 702, 5162, 1731, 293, 309, 311, 445, 4651, 309, 311, 570, 415, 1361, 490, 51632], "temperature": 0.0, "avg_logprob": -0.07705096331509677, "compression_ratio": 1.6807017543859648, "no_speech_prob": 0.052171315997838974}, {"id": 302, "seek": 173736, "start": 1737.36, "end": 1742.3999999999999, "text": " the physics world and all of this knowledge that he has around quantum and symmetries and", "tokens": [50364, 264, 10649, 1002, 293, 439, 295, 341, 3601, 300, 415, 575, 926, 13018, 293, 14232, 302, 2244, 293, 50616], "temperature": 0.0, "avg_logprob": -0.03675967891041825, "compression_ratio": 1.7388535031847134, "no_speech_prob": 0.08648897707462311}, {"id": 303, "seek": 173736, "start": 1742.3999999999999, "end": 1746.8799999999999, "text": " topologies and manifolds that's his operating playbook and he's just taken it into the machine", "tokens": [50616, 1192, 6204, 293, 8173, 31518, 300, 311, 702, 7447, 862, 2939, 293, 415, 311, 445, 2726, 309, 666, 264, 3479, 50840], "temperature": 0.0, "avg_logprob": -0.03675967891041825, "compression_ratio": 1.7388535031847134, "no_speech_prob": 0.08648897707462311}, {"id": 304, "seek": 173736, "start": 1746.8799999999999, "end": 1751.04, "text": " learning world and he's just been executing on it. Max is involved in a lot of papers", "tokens": [50840, 2539, 1002, 293, 415, 311, 445, 668, 32368, 322, 309, 13, 7402, 307, 3288, 294, 257, 688, 295, 10577, 51048], "temperature": 0.0, "avg_logprob": -0.03675967891041825, "compression_ratio": 1.7388535031847134, "no_speech_prob": 0.08648897707462311}, {"id": 305, "seek": 173736, "start": 1752.1599999999999, "end": 1756.6399999999999, "text": " as you would expect and a fair few of them are really fascinating. Yeah one of the things we", "tokens": [51104, 382, 291, 576, 2066, 293, 257, 3143, 1326, 295, 552, 366, 534, 10343, 13, 865, 472, 295, 264, 721, 321, 51328], "temperature": 0.0, "avg_logprob": -0.03675967891041825, "compression_ratio": 1.7388535031847134, "no_speech_prob": 0.08648897707462311}, {"id": 306, "seek": 173736, "start": 1756.6399999999999, "end": 1762.08, "text": " spoke about was just how he nurtures his PhD students because some of these papers are just", "tokens": [51328, 7179, 466, 390, 445, 577, 415, 23705, 1303, 702, 14476, 1731, 570, 512, 295, 613, 10577, 366, 445, 51600], "temperature": 0.0, "avg_logprob": -0.03675967891041825, "compression_ratio": 1.7388535031847134, "no_speech_prob": 0.08648897707462311}, {"id": 307, "seek": 173736, "start": 1762.08, "end": 1766.8799999999999, "text": " incredible and presumably these students have gone from nothing to producing that level of", "tokens": [51600, 4651, 293, 26742, 613, 1731, 362, 2780, 490, 1825, 281, 10501, 300, 1496, 295, 51840], "temperature": 0.0, "avg_logprob": -0.03675967891041825, "compression_ratio": 1.7388535031847134, "no_speech_prob": 0.08648897707462311}, {"id": 308, "seek": 176688, "start": 1766.88, "end": 1770.16, "text": " research in a very short period of time but presumably this was one of the reasons why you", "tokens": [50364, 2132, 294, 257, 588, 2099, 2896, 295, 565, 457, 26742, 341, 390, 472, 295, 264, 4112, 983, 291, 50528], "temperature": 0.0, "avg_logprob": -0.08349262993290739, "compression_ratio": 1.656140350877193, "no_speech_prob": 0.002683134749531746}, {"id": 309, "seek": 176688, "start": 1770.16, "end": 1776.96, "text": " decided to apply for Qualcomm. Yeah I was chasing something that was publishing papers in the field", "tokens": [50528, 3047, 281, 3079, 337, 13616, 13278, 13, 865, 286, 390, 17876, 746, 300, 390, 17832, 10577, 294, 264, 2519, 50868], "temperature": 0.0, "avg_logprob": -0.08349262993290739, "compression_ratio": 1.656140350877193, "no_speech_prob": 0.002683134749531746}, {"id": 310, "seek": 176688, "start": 1776.96, "end": 1782.64, "text": " of computer vision and it's one of the places in Europe, perhaps Zurich is another location", "tokens": [50868, 295, 3820, 5201, 293, 309, 311, 472, 295, 264, 3190, 294, 3315, 11, 4317, 30518, 480, 307, 1071, 4914, 51152], "temperature": 0.0, "avg_logprob": -0.08349262993290739, "compression_ratio": 1.656140350877193, "no_speech_prob": 0.002683134749531746}, {"id": 311, "seek": 176688, "start": 1782.64, "end": 1787.1200000000001, "text": " when you have this kind of research. I thought it was extremely different and a super interesting", "tokens": [51152, 562, 291, 362, 341, 733, 295, 2132, 13, 286, 1194, 309, 390, 4664, 819, 293, 257, 1687, 1880, 51376], "temperature": 0.0, "avg_logprob": -0.08349262993290739, "compression_ratio": 1.656140350877193, "no_speech_prob": 0.002683134749531746}, {"id": 312, "seek": 176688, "start": 1787.7600000000002, "end": 1793.3600000000001, "text": " research area so to speak to get into. Fantastic and what are you working on at the moment?", "tokens": [51408, 2132, 1859, 370, 281, 1710, 281, 483, 666, 13, 21320, 293, 437, 366, 291, 1364, 322, 412, 264, 1623, 30, 51688], "temperature": 0.0, "avg_logprob": -0.08349262993290739, "compression_ratio": 1.656140350877193, "no_speech_prob": 0.002683134749531746}, {"id": 313, "seek": 179336, "start": 1793.36, "end": 1798.6399999999999, "text": " We have just submitted actually our paper to CVPR this morning, the deadlines in a few days so", "tokens": [50364, 492, 362, 445, 14405, 767, 527, 3035, 281, 22995, 15958, 341, 2446, 11, 264, 37548, 294, 257, 1326, 1708, 370, 50628], "temperature": 0.0, "avg_logprob": -0.095882958228435, "compression_ratio": 1.7054545454545456, "no_speech_prob": 0.20061035454273224}, {"id": 314, "seek": 179336, "start": 1798.6399999999999, "end": 1803.52, "text": " that's pretty good I think and then maybe after that as well we have a few more topics and video", "tokens": [50628, 300, 311, 1238, 665, 286, 519, 293, 550, 1310, 934, 300, 382, 731, 321, 362, 257, 1326, 544, 8378, 293, 960, 50872], "temperature": 0.0, "avg_logprob": -0.095882958228435, "compression_ratio": 1.7054545454545456, "no_speech_prob": 0.20061035454273224}, {"id": 315, "seek": 179336, "start": 1803.52, "end": 1808.56, "text": " basically self-training, how to improve representation learning, it's a mix of knowledge", "tokens": [50872, 1936, 2698, 12, 17227, 1760, 11, 577, 281, 3470, 10290, 2539, 11, 309, 311, 257, 2890, 295, 3601, 51124], "temperature": 0.0, "avg_logprob": -0.095882958228435, "compression_ratio": 1.7054545454545456, "no_speech_prob": 0.20061035454273224}, {"id": 316, "seek": 179336, "start": 1808.56, "end": 1815.04, "text": " distillation and self-training and then also we have some interesting work with radio signals so", "tokens": [51124, 42923, 399, 293, 2698, 12, 17227, 1760, 293, 550, 611, 321, 362, 512, 1880, 589, 365, 6477, 12354, 370, 51448], "temperature": 0.0, "avg_logprob": -0.095882958228435, "compression_ratio": 1.7054545454545456, "no_speech_prob": 0.20061035454273224}, {"id": 317, "seek": 179336, "start": 1815.04, "end": 1820.7199999999998, "text": " it's like video in the sense that it's from that we extract the spatial and temporal signal", "tokens": [51448, 309, 311, 411, 960, 294, 264, 2020, 300, 309, 311, 490, 300, 321, 8947, 264, 23598, 293, 30881, 6358, 51732], "temperature": 0.0, "avg_logprob": -0.095882958228435, "compression_ratio": 1.7054545454545456, "no_speech_prob": 0.20061035454273224}, {"id": 318, "seek": 182072, "start": 1820.8, "end": 1826.08, "text": " but it's extremely different to video and that also makes it super fun. Amazing when I was", "tokens": [50368, 457, 309, 311, 4664, 819, 281, 960, 293, 300, 611, 1669, 309, 1687, 1019, 13, 14165, 562, 286, 390, 50632], "temperature": 0.0, "avg_logprob": -0.08104258643256293, "compression_ratio": 1.7280966767371602, "no_speech_prob": 0.00799466110765934}, {"id": 319, "seek": 182072, "start": 1826.08, "end": 1831.1200000000001, "text": " discussing machine learning with Ilya at Microsoft we were fascinated by 3d convolution on your", "tokens": [50632, 10850, 3479, 2539, 365, 286, 45106, 412, 8116, 321, 645, 24597, 538, 805, 67, 45216, 322, 428, 50884], "temperature": 0.0, "avg_logprob": -0.08104258643256293, "compression_ratio": 1.7280966767371602, "no_speech_prob": 0.00799466110765934}, {"id": 320, "seek": 182072, "start": 1831.1200000000001, "end": 1836.72, "text": " networks and i3d and video action detection and I know you are working on a 3d segmentation and a", "tokens": [50884, 9590, 293, 741, 18, 67, 293, 960, 3069, 17784, 293, 286, 458, 291, 366, 1364, 322, 257, 805, 67, 9469, 399, 293, 257, 51164], "temperature": 0.0, "avg_logprob": -0.08104258643256293, "compression_ratio": 1.7280966767371602, "no_speech_prob": 0.00799466110765934}, {"id": 321, "seek": 182072, "start": 1836.72, "end": 1841.3600000000001, "text": " whole bunch of cool things like that but anyway I would love to get you on the show in the next", "tokens": [51164, 1379, 3840, 295, 1627, 721, 411, 300, 457, 4033, 286, 576, 959, 281, 483, 291, 322, 264, 855, 294, 264, 958, 51396], "temperature": 0.0, "avg_logprob": -0.08104258643256293, "compression_ratio": 1.7280966767371602, "no_speech_prob": 0.00799466110765934}, {"id": 322, "seek": 182072, "start": 1841.3600000000001, "end": 1844.96, "text": " few weeks to talk about some of your research and for those of you in the comments if you want to", "tokens": [51396, 1326, 3259, 281, 751, 466, 512, 295, 428, 2132, 293, 337, 729, 295, 291, 294, 264, 3053, 498, 291, 528, 281, 51576], "temperature": 0.0, "avg_logprob": -0.08104258643256293, "compression_ratio": 1.7280966767371602, "no_speech_prob": 0.00799466110765934}, {"id": 323, "seek": 182072, "start": 1844.96, "end": 1849.92, "text": " have more from Ilya let us know are you going to give us a demonstration of your front lever?", "tokens": [51576, 362, 544, 490, 286, 45106, 718, 505, 458, 366, 291, 516, 281, 976, 505, 257, 16520, 295, 428, 1868, 12451, 30, 51824], "temperature": 0.0, "avg_logprob": -0.08104258643256293, "compression_ratio": 1.7280966767371602, "no_speech_prob": 0.00799466110765934}, {"id": 324, "seek": 185072, "start": 1850.72, "end": 1855.84, "text": " Okay single leg. When Ilya comes on the show properly we're going to be doing a front lever", "tokens": [50364, 1033, 2167, 1676, 13, 1133, 286, 45106, 1487, 322, 264, 855, 6108, 321, 434, 516, 281, 312, 884, 257, 1868, 12451, 50620], "temperature": 0.0, "avg_logprob": -0.11649740923632372, "compression_ratio": 1.6945454545454546, "no_speech_prob": 0.002125776605680585}, {"id": 325, "seek": 185072, "start": 1855.84, "end": 1864.08, "text": " competition that's pretty good so not only is Ilya a specialist in machine learning", "tokens": [50620, 6211, 300, 311, 1238, 665, 370, 406, 787, 307, 286, 45106, 257, 17008, 294, 3479, 2539, 51032], "temperature": 0.0, "avg_logprob": -0.11649740923632372, "compression_ratio": 1.6945454545454546, "no_speech_prob": 0.002125776605680585}, {"id": 326, "seek": 185072, "start": 1864.08, "end": 1869.3600000000001, "text": " he also absolutely smashes it in the body weight game. No that wasn't smashing it that was after", "tokens": [51032, 415, 611, 3122, 899, 12808, 309, 294, 264, 1772, 3364, 1216, 13, 883, 300, 2067, 380, 43316, 309, 300, 390, 934, 51296], "temperature": 0.0, "avg_logprob": -0.11649740923632372, "compression_ratio": 1.6945454545454546, "no_speech_prob": 0.002125776605680585}, {"id": 327, "seek": 185072, "start": 1869.3600000000001, "end": 1874.32, "text": " a climbing session it's actually really cool I met this guy here who's a calisthenics instructor", "tokens": [51296, 257, 14780, 5481, 309, 311, 767, 534, 1627, 286, 1131, 341, 2146, 510, 567, 311, 257, 2104, 271, 19096, 1167, 18499, 51544], "temperature": 0.0, "avg_logprob": -0.11649740923632372, "compression_ratio": 1.6945454545454546, "no_speech_prob": 0.002125776605680585}, {"id": 328, "seek": 185072, "start": 1874.32, "end": 1880.24, "text": " called Soli and he just started climbing and yeah so we met up and we went climbing this morning", "tokens": [51544, 1219, 7026, 72, 293, 415, 445, 1409, 14780, 293, 1338, 370, 321, 1131, 493, 293, 321, 1437, 14780, 341, 2446, 51840], "temperature": 0.0, "avg_logprob": -0.11649740923632372, "compression_ratio": 1.6945454545454546, "no_speech_prob": 0.002125776605680585}, {"id": 329, "seek": 188024, "start": 1880.24, "end": 1884.56, "text": " and he was crazy good as you would expect and he gave me some tips on my front lever as well", "tokens": [50364, 293, 415, 390, 3219, 665, 382, 291, 576, 2066, 293, 415, 2729, 385, 512, 6082, 322, 452, 1868, 12451, 382, 731, 50580], "temperature": 0.0, "avg_logprob": -0.07199624379475912, "compression_ratio": 1.743034055727554, "no_speech_prob": 0.003574480302631855}, {"id": 330, "seek": 188024, "start": 1884.56, "end": 1888.64, "text": " he was saying I should work more on the tuck instead of the single leg so hopefully you'll", "tokens": [50580, 415, 390, 1566, 286, 820, 589, 544, 322, 264, 18457, 2602, 295, 264, 2167, 1676, 370, 4696, 291, 603, 50784], "temperature": 0.0, "avg_logprob": -0.07199624379475912, "compression_ratio": 1.743034055727554, "no_speech_prob": 0.003574480302631855}, {"id": 331, "seek": 188024, "start": 1888.64, "end": 1893.68, "text": " see much better than that in the future. Amazing Ilya thank you so much for coming on the show we", "tokens": [50784, 536, 709, 1101, 813, 300, 294, 264, 2027, 13, 14165, 286, 45106, 1309, 291, 370, 709, 337, 1348, 322, 264, 855, 321, 51036], "temperature": 0.0, "avg_logprob": -0.07199624379475912, "compression_ratio": 1.743034055727554, "no_speech_prob": 0.003574480302631855}, {"id": 332, "seek": 188024, "start": 1893.68, "end": 1899.2, "text": " look forward to interviewing you in a few weeks time. Thanks for helping me and thanks a lot for", "tokens": [51036, 574, 2128, 281, 26524, 291, 294, 257, 1326, 3259, 565, 13, 2561, 337, 4315, 385, 293, 3231, 257, 688, 337, 51312], "temperature": 0.0, "avg_logprob": -0.07199624379475912, "compression_ratio": 1.743034055727554, "no_speech_prob": 0.003574480302631855}, {"id": 333, "seek": 188024, "start": 1899.2, "end": 1903.6, "text": " interviewing Max I'm like super excited to see that in a few days. Anyway I really hope you've", "tokens": [51312, 26524, 7402, 286, 478, 411, 1687, 2919, 281, 536, 300, 294, 257, 1326, 1708, 13, 5684, 286, 534, 1454, 291, 600, 51532], "temperature": 0.0, "avg_logprob": -0.07199624379475912, "compression_ratio": 1.743034055727554, "no_speech_prob": 0.003574480302631855}, {"id": 334, "seek": 188024, "start": 1903.6, "end": 1908.64, "text": " enjoyed the show today this has been such a special episode for us because Max Welling is", "tokens": [51532, 4626, 264, 855, 965, 341, 575, 668, 1270, 257, 2121, 3500, 337, 505, 570, 7402, 1042, 278, 307, 51784], "temperature": 0.0, "avg_logprob": -0.07199624379475912, "compression_ratio": 1.743034055727554, "no_speech_prob": 0.003574480302631855}, {"id": 335, "seek": 190864, "start": 1908.64, "end": 1915.44, "text": " literally one of my heroes so anyway remember to like comment and subscribe we love reading", "tokens": [50364, 3736, 472, 295, 452, 12332, 370, 4033, 1604, 281, 411, 2871, 293, 3022, 321, 959, 3760, 50704], "temperature": 0.0, "avg_logprob": -0.09521424493124318, "compression_ratio": 1.59915611814346, "no_speech_prob": 0.02116505615413189}, {"id": 336, "seek": 190864, "start": 1915.44, "end": 1920.4, "text": " your comments we really do actually we're getting so many amazing comments in the comment section", "tokens": [50704, 428, 3053, 321, 534, 360, 767, 321, 434, 1242, 370, 867, 2243, 3053, 294, 264, 2871, 3541, 50952], "temperature": 0.0, "avg_logprob": -0.09521424493124318, "compression_ratio": 1.59915611814346, "no_speech_prob": 0.02116505615413189}, {"id": 337, "seek": 190864, "start": 1920.4, "end": 1929.2800000000002, "text": " so keep them coming and we will see you back next week. Welcome back to the Machine Learning", "tokens": [50952, 370, 1066, 552, 1348, 293, 321, 486, 536, 291, 646, 958, 1243, 13, 4027, 646, 281, 264, 22155, 15205, 51396], "temperature": 0.0, "avg_logprob": -0.09521424493124318, "compression_ratio": 1.59915611814346, "no_speech_prob": 0.02116505615413189}, {"id": 338, "seek": 190864, "start": 1929.2800000000002, "end": 1935.92, "text": " Street Talk YouTube channel and podcast with my two compadres Alex Stenlake and Yannick Kiltcher", "tokens": [51396, 7638, 8780, 3088, 2269, 293, 7367, 365, 452, 732, 715, 345, 495, 5202, 745, 268, 75, 619, 293, 398, 969, 618, 591, 2352, 6759, 51728], "temperature": 0.0, "avg_logprob": -0.09521424493124318, "compression_ratio": 1.59915611814346, "no_speech_prob": 0.02116505615413189}, {"id": 339, "seek": 193592, "start": 1935.92, "end": 1941.68, "text": " and today we have someone who doesn't really need any introduction at all clearly one of the most", "tokens": [50364, 293, 965, 321, 362, 1580, 567, 1177, 380, 534, 643, 604, 9339, 412, 439, 4448, 472, 295, 264, 881, 50652], "temperature": 0.0, "avg_logprob": -0.11380846310505825, "compression_ratio": 1.585284280936455, "no_speech_prob": 0.01706632412970066}, {"id": 340, "seek": 193592, "start": 1941.68, "end": 1947.76, "text": " impactful researchers in the ML world and has as near as makes no difference 40 000 citations", "tokens": [50652, 30842, 10309, 294, 264, 21601, 1002, 293, 575, 382, 2651, 382, 1669, 572, 2649, 3356, 13711, 4814, 763, 50956], "temperature": 0.0, "avg_logprob": -0.11380846310505825, "compression_ratio": 1.585284280936455, "no_speech_prob": 0.01706632412970066}, {"id": 341, "seek": 193592, "start": 1947.76, "end": 1952.64, "text": " he's on the executive board at NeurIPS he's a research chair and full professor at the AMLAB", "tokens": [50956, 415, 311, 322, 264, 10140, 3150, 412, 1734, 374, 40, 6273, 415, 311, 257, 2132, 6090, 293, 1577, 8304, 412, 264, 6475, 11435, 33, 51200], "temperature": 0.0, "avg_logprob": -0.11380846310505825, "compression_ratio": 1.585284280936455, "no_speech_prob": 0.01706632412970066}, {"id": 342, "seek": 193592, "start": 1952.64, "end": 1959.28, "text": " University of Amsterdam and co-director of the CUVA lab and Delta lab Max Welling. Max is a strong", "tokens": [51200, 3535, 295, 28291, 293, 598, 12, 18267, 1672, 295, 264, 29777, 20914, 2715, 293, 18183, 2715, 7402, 1042, 278, 13, 7402, 307, 257, 2068, 51532], "temperature": 0.0, "avg_logprob": -0.11380846310505825, "compression_ratio": 1.585284280936455, "no_speech_prob": 0.01706632412970066}, {"id": 343, "seek": 193592, "start": 1959.28, "end": 1963.6000000000001, "text": " believer in the power of computation and its relevance to machine learning which is one of", "tokens": [51532, 23892, 294, 264, 1347, 295, 24903, 293, 1080, 32684, 281, 3479, 2539, 597, 307, 472, 295, 51748], "temperature": 0.0, "avg_logprob": -0.11380846310505825, "compression_ratio": 1.585284280936455, "no_speech_prob": 0.01706632412970066}, {"id": 344, "seek": 196360, "start": 1963.6, "end": 1968.24, "text": " the reasons why he holds a vice president position at Qualcomm. He thinks the fastest way to make", "tokens": [50364, 264, 4112, 983, 415, 9190, 257, 11964, 3868, 2535, 412, 13616, 13278, 13, 634, 7309, 264, 14573, 636, 281, 652, 50596], "temperature": 0.0, "avg_logprob": -0.06994637576016513, "compression_ratio": 1.6345609065155808, "no_speech_prob": 0.021365655586123466}, {"id": 345, "seek": 196360, "start": 1968.24, "end": 1973.52, "text": " progress in artificial intelligence is to make specialized hardware for AI computation. He wrote", "tokens": [50596, 4205, 294, 11677, 7599, 307, 281, 652, 19813, 8837, 337, 7318, 24903, 13, 634, 4114, 50860], "temperature": 0.0, "avg_logprob": -0.06994637576016513, "compression_ratio": 1.6345609065155808, "no_speech_prob": 0.021365655586123466}, {"id": 346, "seek": 196360, "start": 1973.52, "end": 1978.0, "text": " a response to Rich Sutton's The Bitter Lesson but essentially agrees with him in the sense that one", "tokens": [50860, 257, 4134, 281, 6781, 40492, 1756, 311, 440, 363, 3904, 18649, 266, 457, 4476, 26383, 365, 796, 294, 264, 2020, 300, 472, 51084], "temperature": 0.0, "avg_logprob": -0.06994637576016513, "compression_ratio": 1.6345609065155808, "no_speech_prob": 0.021365655586123466}, {"id": 347, "seek": 196360, "start": 1978.0, "end": 1983.12, "text": " should work on scalable methods that maximally leverage compute but Max thinks that data is", "tokens": [51084, 820, 589, 322, 38481, 7150, 300, 5138, 379, 13982, 14722, 457, 7402, 7309, 300, 1412, 307, 51340], "temperature": 0.0, "avg_logprob": -0.06994637576016513, "compression_ratio": 1.6345609065155808, "no_speech_prob": 0.021365655586123466}, {"id": 348, "seek": 196360, "start": 1983.12, "end": 1987.52, "text": " the fundamental ingredient of deep learning and you can't always generate it yourself like an", "tokens": [51340, 264, 8088, 14751, 295, 2452, 2539, 293, 291, 393, 380, 1009, 8460, 309, 1803, 411, 364, 51560], "temperature": 0.0, "avg_logprob": -0.06994637576016513, "compression_ratio": 1.6345609065155808, "no_speech_prob": 0.021365655586123466}, {"id": 349, "seek": 196360, "start": 1987.52, "end": 1992.7199999999998, "text": " AlphaGo which amounts to an interpolation problem. Much of Max's research portfolio is currently", "tokens": [51560, 20588, 12104, 597, 11663, 281, 364, 44902, 399, 1154, 13, 12313, 295, 7402, 311, 2132, 12583, 307, 4362, 51820], "temperature": 0.0, "avg_logprob": -0.06994637576016513, "compression_ratio": 1.6345609065155808, "no_speech_prob": 0.021365655586123466}, {"id": 350, "seek": 199272, "start": 1992.72, "end": 1996.48, "text": " based on deep learning. He thinks it's the biggest hammer that we've produced thus far", "tokens": [50364, 2361, 322, 2452, 2539, 13, 634, 7309, 309, 311, 264, 3880, 13017, 300, 321, 600, 7126, 8807, 1400, 50552], "temperature": 0.0, "avg_logprob": -0.04527649332265385, "compression_ratio": 1.6506024096385543, "no_speech_prob": 0.01742161065340042}, {"id": 351, "seek": 199272, "start": 1996.48, "end": 2001.1200000000001, "text": " and we witness its impact every single day. He thinks that AGI is a possibility and it will", "tokens": [50552, 293, 321, 7286, 1080, 2712, 633, 2167, 786, 13, 634, 7309, 300, 316, 26252, 307, 257, 7959, 293, 309, 486, 50784], "temperature": 0.0, "avg_logprob": -0.04527649332265385, "compression_ratio": 1.6506024096385543, "no_speech_prob": 0.01742161065340042}, {"id": 352, "seek": 199272, "start": 2001.1200000000001, "end": 2006.24, "text": " manifest in a forward generative and causal direction. There's a really interesting cross", "tokens": [50784, 10067, 294, 257, 2128, 1337, 1166, 293, 38755, 3513, 13, 821, 311, 257, 534, 1880, 3278, 51040], "temperature": 0.0, "avg_logprob": -0.04527649332265385, "compression_ratio": 1.6506024096385543, "no_speech_prob": 0.01742161065340042}, {"id": 353, "seek": 199272, "start": 2006.24, "end": 2011.1200000000001, "text": " pollination story here Max has a physics background he did a PhD in physics he knows all about", "tokens": [51040, 6418, 2486, 1657, 510, 7402, 575, 257, 10649, 3678, 415, 630, 257, 14476, 294, 10649, 415, 3255, 439, 466, 51284], "temperature": 0.0, "avg_logprob": -0.04527649332265385, "compression_ratio": 1.6506024096385543, "no_speech_prob": 0.01742161065340042}, {"id": 354, "seek": 199272, "start": 2011.1200000000001, "end": 2016.08, "text": " manifolds and topologies and symmetries and quantum and actually this has been his operating", "tokens": [51284, 8173, 31518, 293, 1192, 6204, 293, 14232, 302, 2244, 293, 13018, 293, 767, 341, 575, 668, 702, 7447, 51532], "temperature": 0.0, "avg_logprob": -0.04527649332265385, "compression_ratio": 1.6506024096385543, "no_speech_prob": 0.01742161065340042}, {"id": 355, "seek": 199272, "start": 2016.08, "end": 2020.08, "text": " playbook he's brought all of these incredible concepts in from the physics world to machine", "tokens": [51532, 862, 2939, 415, 311, 3038, 439, 295, 613, 4651, 10392, 294, 490, 264, 10649, 1002, 281, 3479, 51732], "temperature": 0.0, "avg_logprob": -0.04527649332265385, "compression_ratio": 1.6506024096385543, "no_speech_prob": 0.01742161065340042}, {"id": 356, "seek": 202008, "start": 2020.08, "end": 2025.1999999999998, "text": " learning. Now there's a fundamental blank slate paradigm in machine learning experience and data", "tokens": [50364, 2539, 13, 823, 456, 311, 257, 8088, 8247, 39118, 24709, 294, 3479, 2539, 1752, 293, 1412, 50620], "temperature": 0.0, "avg_logprob": -0.06097163851298983, "compression_ratio": 1.7455089820359282, "no_speech_prob": 0.014220294542610645}, {"id": 357, "seek": 202008, "start": 2025.1999999999998, "end": 2030.72, "text": " currently rule the roost but Max wants to build a house on top of that blank slate. Max thinks", "tokens": [50620, 4362, 4978, 264, 744, 555, 457, 7402, 2738, 281, 1322, 257, 1782, 322, 1192, 295, 300, 8247, 39118, 13, 7402, 7309, 50896], "temperature": 0.0, "avg_logprob": -0.06097163851298983, "compression_ratio": 1.7455089820359282, "no_speech_prob": 0.014220294542610645}, {"id": 358, "seek": 202008, "start": 2030.72, "end": 2035.76, "text": " that there are no predictions without assumptions no generalization without inductive bias. The", "tokens": [50896, 300, 456, 366, 572, 21264, 1553, 17695, 572, 2674, 2144, 1553, 31612, 488, 12577, 13, 440, 51148], "temperature": 0.0, "avg_logprob": -0.06097163851298983, "compression_ratio": 1.7455089820359282, "no_speech_prob": 0.014220294542610645}, {"id": 359, "seek": 202008, "start": 2035.76, "end": 2040.08, "text": " bias variance trade-off tells us that we need to use additional human knowledge when data is", "tokens": [51148, 12577, 21977, 4923, 12, 4506, 5112, 505, 300, 321, 643, 281, 764, 4497, 1952, 3601, 562, 1412, 307, 51364], "temperature": 0.0, "avg_logprob": -0.06097163851298983, "compression_ratio": 1.7455089820359282, "no_speech_prob": 0.014220294542610645}, {"id": 360, "seek": 202008, "start": 2040.08, "end": 2044.72, "text": " insufficient. I think it's fair to say that Max Welling has pioneered many of the most sophisticated", "tokens": [51364, 41709, 13, 286, 519, 309, 311, 3143, 281, 584, 300, 7402, 1042, 278, 575, 19761, 4073, 867, 295, 264, 881, 16950, 51596], "temperature": 0.0, "avg_logprob": -0.06097163851298983, "compression_ratio": 1.7455089820359282, "no_speech_prob": 0.014220294542610645}, {"id": 361, "seek": 202008, "start": 2044.72, "end": 2049.7599999999998, "text": " inductive priors and deep learning models developed in recent years. An example of an inductive prior", "tokens": [51596, 31612, 488, 1790, 830, 293, 2452, 2539, 5245, 4743, 294, 5162, 924, 13, 1107, 1365, 295, 364, 31612, 488, 4059, 51848], "temperature": 0.0, "avg_logprob": -0.06097163851298983, "compression_ratio": 1.7455089820359282, "no_speech_prob": 0.014220294542610645}, {"id": 362, "seek": 204976, "start": 2049.76, "end": 2054.8, "text": " is the CNN which means we can model local connectivity, weight sharing and equivalence to", "tokens": [50364, 307, 264, 24859, 597, 1355, 321, 393, 2316, 2654, 21095, 11, 3364, 5414, 293, 9052, 655, 281, 50616], "temperature": 0.0, "avg_logprob": -0.08957525009804583, "compression_ratio": 1.6421052631578947, "no_speech_prob": 0.004038389306515455}, {"id": 363, "seek": 204976, "start": 2054.8, "end": 2060.1600000000003, "text": " translational symmetries in gridded vision data. This is imputing human domain knowledge into the", "tokens": [50616, 5105, 1478, 14232, 302, 2244, 294, 10748, 9207, 5201, 1412, 13, 639, 307, 704, 10861, 1952, 9274, 3601, 666, 264, 50884], "temperature": 0.0, "avg_logprob": -0.08957525009804583, "compression_ratio": 1.6421052631578947, "no_speech_prob": 0.004038389306515455}, {"id": 364, "seek": 204976, "start": 2060.1600000000003, "end": 2066.0800000000004, "text": " architecture it makes the model significantly more robust and sample efficient. Assumptions are", "tokens": [50884, 9482, 309, 1669, 264, 2316, 10591, 544, 13956, 293, 6889, 7148, 13, 6281, 449, 9799, 366, 51180], "temperature": 0.0, "avg_logprob": -0.08957525009804583, "compression_ratio": 1.6421052631578947, "no_speech_prob": 0.004038389306515455}, {"id": 365, "seek": 204976, "start": 2066.0800000000004, "end": 2070.32, "text": " everywhere even fully connected networks assume that there is a hierarchical organization of", "tokens": [51180, 5315, 754, 4498, 4582, 9590, 6552, 300, 456, 307, 257, 35250, 804, 4475, 295, 51392], "temperature": 0.0, "avg_logprob": -0.08957525009804583, "compression_ratio": 1.6421052631578947, "no_speech_prob": 0.004038389306515455}, {"id": 366, "seek": 204976, "start": 2070.32, "end": 2074.48, "text": " concepts and even further assumptions about the smoothness of the underlying function we're", "tokens": [51392, 10392, 293, 754, 3052, 17695, 466, 264, 5508, 1287, 295, 264, 14217, 2445, 321, 434, 51600], "temperature": 0.0, "avg_logprob": -0.08957525009804583, "compression_ratio": 1.6421052631578947, "no_speech_prob": 0.004038389306515455}, {"id": 367, "seek": 207448, "start": 2074.48, "end": 2080.4, "text": " estimating. Max and many of his collaborators for example Tako Kohen took this idea so much", "tokens": [50364, 8017, 990, 13, 7402, 293, 867, 295, 702, 39789, 337, 1365, 9118, 78, 30861, 268, 1890, 341, 1558, 370, 709, 50660], "temperature": 0.0, "avg_logprob": -0.07926119134781208, "compression_ratio": 1.6503496503496504, "no_speech_prob": 0.04466729983687401}, {"id": 368, "seek": 207448, "start": 2080.4, "end": 2084.56, "text": " further they introduced rotational equivalence and then they built models which would work", "tokens": [50660, 3052, 436, 7268, 45420, 9052, 655, 293, 550, 436, 3094, 5245, 597, 576, 589, 50868], "temperature": 0.0, "avg_logprob": -0.07926119134781208, "compression_ratio": 1.6503496503496504, "no_speech_prob": 0.04466729983687401}, {"id": 369, "seek": 207448, "start": 2084.56, "end": 2091.12, "text": " extremely efficiently on non-geometric curved manifolds meshes or even graphs. Max wants to", "tokens": [50868, 4664, 19621, 322, 2107, 12, 432, 29470, 24991, 8173, 31518, 3813, 8076, 420, 754, 24877, 13, 7402, 2738, 281, 51196], "temperature": 0.0, "avg_logprob": -0.07926119134781208, "compression_ratio": 1.6503496503496504, "no_speech_prob": 0.04466729983687401}, {"id": 370, "seek": 207448, "start": 2091.12, "end": 2095.92, "text": " reduce the need for data in deep learning models increasing the representational fidelity of neural", "tokens": [51196, 5407, 264, 643, 337, 1412, 294, 2452, 2539, 5245, 5662, 264, 2906, 1478, 46404, 295, 18161, 51436], "temperature": 0.0, "avg_logprob": -0.07926119134781208, "compression_ratio": 1.6503496503496504, "no_speech_prob": 0.04466729983687401}, {"id": 371, "seek": 207448, "start": 2095.92, "end": 2100.72, "text": " networks subject to discretization and sampling errors and improving the computational techniques", "tokens": [51436, 9590, 3983, 281, 25656, 2144, 293, 21179, 13603, 293, 11470, 264, 28270, 7512, 51676], "temperature": 0.0, "avg_logprob": -0.07926119134781208, "compression_ratio": 1.6503496503496504, "no_speech_prob": 0.04466729983687401}, {"id": 372, "seek": 210072, "start": 2100.72, "end": 2106.64, "text": " to process them more efficiently. Max has recently put out two new papers Quantum Deformed Neural", "tokens": [50364, 281, 1399, 552, 544, 19621, 13, 7402, 575, 3938, 829, 484, 732, 777, 10577, 44964, 1346, 22892, 1734, 1807, 50660], "temperature": 0.0, "avg_logprob": -0.1271948964972245, "compression_ratio": 1.536, "no_speech_prob": 0.009194973856210709}, {"id": 373, "seek": 210072, "start": 2106.64, "end": 2111.3599999999997, "text": " Networks and Probabilistic Numeric Convolutional Neural Networks which we'll be talking about", "tokens": [50660, 12640, 82, 293, 8736, 5177, 3142, 426, 15583, 299, 2656, 85, 3386, 304, 1734, 1807, 12640, 82, 597, 321, 603, 312, 1417, 466, 50896], "temperature": 0.0, "avg_logprob": -0.1271948964972245, "compression_ratio": 1.536, "no_speech_prob": 0.009194973856210709}, {"id": 374, "seek": 210072, "start": 2111.3599999999997, "end": 2116.72, "text": " today. Anyway Max it's an absolute pleasure welcome to the show. Thank you very much Tim for a very", "tokens": [50896, 965, 13, 5684, 7402, 309, 311, 364, 8236, 6834, 2928, 281, 264, 855, 13, 1044, 291, 588, 709, 7172, 337, 257, 588, 51164], "temperature": 0.0, "avg_logprob": -0.1271948964972245, "compression_ratio": 1.536, "no_speech_prob": 0.009194973856210709}, {"id": 375, "seek": 210072, "start": 2116.72, "end": 2125.52, "text": " nice introduction it almost sounded like it's not me but it was a lot. Do you feel that this", "tokens": [51164, 1481, 9339, 309, 1920, 17714, 411, 309, 311, 406, 385, 457, 309, 390, 257, 688, 13, 1144, 291, 841, 300, 341, 51604], "temperature": 0.0, "avg_logprob": -0.1271948964972245, "compression_ratio": 1.536, "no_speech_prob": 0.009194973856210709}, {"id": 376, "seek": 212552, "start": 2126.16, "end": 2131.92, "text": " it describes you not maybe accurately but do you feel like there's a parts of your work that are", "tokens": [50396, 309, 15626, 291, 406, 1310, 20095, 457, 360, 291, 841, 411, 456, 311, 257, 3166, 295, 428, 589, 300, 366, 50684], "temperature": 0.0, "avg_logprob": -0.07114575459406926, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.014225253835320473}, {"id": 377, "seek": 212552, "start": 2131.92, "end": 2138.32, "text": " overly well known and there may be parts of your work that you wish would be more well known?", "tokens": [50684, 24324, 731, 2570, 293, 456, 815, 312, 3166, 295, 428, 589, 300, 291, 3172, 576, 312, 544, 731, 2570, 30, 51004], "temperature": 0.0, "avg_logprob": -0.07114575459406926, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.014225253835320473}, {"id": 378, "seek": 212552, "start": 2140.08, "end": 2145.04, "text": " It's hard to say it's overly well known because of course it's very enjoyable when you can make a", "tokens": [51092, 467, 311, 1152, 281, 584, 309, 311, 24324, 731, 2570, 570, 295, 1164, 309, 311, 588, 20305, 562, 291, 393, 652, 257, 51340], "temperature": 0.0, "avg_logprob": -0.07114575459406926, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.014225253835320473}, {"id": 379, "seek": 212552, "start": 2145.04, "end": 2151.12, "text": " big impact but what I can say is that it's incredibly hard to predict what will become well", "tokens": [51340, 955, 2712, 457, 437, 286, 393, 584, 307, 300, 309, 311, 6252, 1152, 281, 6069, 437, 486, 1813, 731, 51644], "temperature": 0.0, "avg_logprob": -0.07114575459406926, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.014225253835320473}, {"id": 380, "seek": 215112, "start": 2151.12, "end": 2155.12, "text": " known of course if you could predict that you would only write papers with like gazillions of", "tokens": [50364, 2570, 295, 1164, 498, 291, 727, 6069, 300, 291, 576, 787, 2464, 10577, 365, 411, 26232, 46279, 295, 50564], "temperature": 0.0, "avg_logprob": -0.08617193416013556, "compression_ratio": 1.75, "no_speech_prob": 0.0212656669318676}, {"id": 381, "seek": 215112, "start": 2155.12, "end": 2161.52, "text": " citations. When we did things like the VAE or graph neural nets it didn't feel at all like this was", "tokens": [50564, 4814, 763, 13, 1133, 321, 630, 721, 411, 264, 18527, 36, 420, 4295, 18161, 36170, 309, 994, 380, 841, 412, 439, 411, 341, 390, 50884], "temperature": 0.0, "avg_logprob": -0.08617193416013556, "compression_ratio": 1.75, "no_speech_prob": 0.0212656669318676}, {"id": 382, "seek": 215112, "start": 2161.52, "end": 2168.72, "text": " going to be a big hit and some of these things are being singled out and they fly and precisely what", "tokens": [50884, 516, 281, 312, 257, 955, 2045, 293, 512, 295, 613, 721, 366, 885, 1522, 1493, 484, 293, 436, 3603, 293, 13402, 437, 51244], "temperature": 0.0, "avg_logprob": -0.08617193416013556, "compression_ratio": 1.75, "no_speech_prob": 0.0212656669318676}, {"id": 383, "seek": 215112, "start": 2168.72, "end": 2174.96, "text": " makes these papers fly is in a way that's a big puzzle in a way and some other papers you can be", "tokens": [51244, 1669, 613, 10577, 3603, 307, 294, 257, 636, 300, 311, 257, 955, 12805, 294, 257, 636, 293, 512, 661, 10577, 291, 393, 312, 51556], "temperature": 0.0, "avg_logprob": -0.08617193416013556, "compression_ratio": 1.75, "no_speech_prob": 0.0212656669318676}, {"id": 384, "seek": 215112, "start": 2174.96, "end": 2180.72, "text": " very proud of and it takes so much time to actually get published it's a huge uphill battle", "tokens": [51556, 588, 4570, 295, 293, 309, 2516, 370, 709, 565, 281, 767, 483, 6572, 309, 311, 257, 2603, 39132, 4635, 51844], "temperature": 0.0, "avg_logprob": -0.08617193416013556, "compression_ratio": 1.75, "no_speech_prob": 0.0212656669318676}, {"id": 385, "seek": 218072, "start": 2180.72, "end": 2184.7999999999997, "text": " you think why do the reviewers not understand better but we really want to do here and then", "tokens": [50364, 291, 519, 983, 360, 264, 45837, 406, 1223, 1101, 457, 321, 534, 528, 281, 360, 510, 293, 550, 50568], "temperature": 0.0, "avg_logprob": -0.09914363599291035, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.0027561415918171406}, {"id": 386, "seek": 218072, "start": 2184.7999999999997, "end": 2189.3599999999997, "text": " yeah and so they I guess there's a lot of good work which disappears into oblivion", "tokens": [50568, 1338, 293, 370, 436, 286, 2041, 456, 311, 257, 688, 295, 665, 589, 597, 25527, 666, 47039, 313, 50796], "temperature": 0.0, "avg_logprob": -0.09914363599291035, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.0027561415918171406}, {"id": 387, "seek": 218072, "start": 2189.3599999999997, "end": 2196.48, "text": " and from many people and yeah it's mysterious but anyway. Your hits definitely seem to be", "tokens": [50796, 293, 490, 867, 561, 293, 1338, 309, 311, 13831, 457, 4033, 13, 2260, 8664, 2138, 1643, 281, 312, 51152], "temperature": 0.0, "avg_logprob": -0.09914363599291035, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.0027561415918171406}, {"id": 388, "seek": 218072, "start": 2196.48, "end": 2201.7599999999998, "text": " more than your misses you're a prolific researcher yourself but you've nurtured some of the best", "tokens": [51152, 544, 813, 428, 29394, 291, 434, 257, 24398, 1089, 21751, 1803, 457, 291, 600, 23705, 3831, 512, 295, 264, 1151, 51416], "temperature": 0.0, "avg_logprob": -0.09914363599291035, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.0027561415918171406}, {"id": 389, "seek": 218072, "start": 2201.7599999999998, "end": 2206.3999999999996, "text": " and brightest minds across in not just deep learning but like the wider machine learning field", "tokens": [51416, 293, 36271, 9634, 2108, 294, 406, 445, 2452, 2539, 457, 411, 264, 11842, 3479, 2539, 2519, 51648], "temperature": 0.0, "avg_logprob": -0.09914363599291035, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.0027561415918171406}, {"id": 390, "seek": 220640, "start": 2207.12, "end": 2210.8, "text": " how do you consistently do that is it fantastic mentorship or is it more", "tokens": [50400, 577, 360, 291, 14961, 360, 300, 307, 309, 5456, 40422, 420, 307, 309, 544, 50584], "temperature": 0.0, "avg_logprob": -0.08350286483764649, "compression_ratio": 1.7807692307692307, "no_speech_prob": 0.017687855288386345}, {"id": 391, "seek": 220640, "start": 2210.8, "end": 2216.0, "text": " finding the right spark in a student and nurturing that and that's a really good question and I should", "tokens": [50584, 5006, 264, 558, 9908, 294, 257, 3107, 293, 48116, 300, 293, 300, 311, 257, 534, 665, 1168, 293, 286, 820, 50844], "temperature": 0.0, "avg_logprob": -0.08350286483764649, "compression_ratio": 1.7807692307692307, "no_speech_prob": 0.017687855288386345}, {"id": 392, "seek": 220640, "start": 2216.0, "end": 2220.7200000000003, "text": " say that I've been extremely blessed by all these fantastic students right from the beginning", "tokens": [50844, 584, 300, 286, 600, 668, 4664, 12351, 538, 439, 613, 5456, 1731, 558, 490, 264, 2863, 51080], "temperature": 0.0, "avg_logprob": -0.08350286483764649, "compression_ratio": 1.7807692307692307, "no_speech_prob": 0.017687855288386345}, {"id": 393, "seek": 220640, "start": 2221.52, "end": 2227.76, "text": " but I do think there is something to nurturing talent so I think what doesn't work is to basically", "tokens": [51120, 457, 286, 360, 519, 456, 307, 746, 281, 48116, 8301, 370, 286, 519, 437, 1177, 380, 589, 307, 281, 1936, 51432], "temperature": 0.0, "avg_logprob": -0.08350286483764649, "compression_ratio": 1.7807692307692307, "no_speech_prob": 0.017687855288386345}, {"id": 394, "seek": 220640, "start": 2228.7200000000003, "end": 2232.96, "text": " tell to be very constrained to a particular topic sometimes you see this happen if you write a", "tokens": [51480, 980, 281, 312, 588, 38901, 281, 257, 1729, 4829, 2171, 291, 536, 341, 1051, 498, 291, 2464, 257, 51692], "temperature": 0.0, "avg_logprob": -0.08350286483764649, "compression_ratio": 1.7807692307692307, "no_speech_prob": 0.017687855288386345}, {"id": 395, "seek": 223296, "start": 2232.96, "end": 2238.16, "text": " grant proposal and then the grant proposal is about topic A and then really the student", "tokens": [50364, 6386, 11494, 293, 550, 264, 6386, 11494, 307, 466, 4829, 316, 293, 550, 534, 264, 3107, 50624], "temperature": 0.0, "avg_logprob": -0.06769022211298212, "compression_ratio": 1.8379446640316206, "no_speech_prob": 0.0032667797058820724}, {"id": 396, "seek": 223296, "start": 2238.88, "end": 2242.8, "text": " starts at topic A but figures out after a couple of months that they don't really like", "tokens": [50660, 3719, 412, 4829, 316, 457, 9624, 484, 934, 257, 1916, 295, 2493, 300, 436, 500, 380, 534, 411, 50856], "temperature": 0.0, "avg_logprob": -0.06769022211298212, "compression_ratio": 1.8379446640316206, "no_speech_prob": 0.0032667797058820724}, {"id": 397, "seek": 223296, "start": 2242.8, "end": 2247.44, "text": " topic A and they want to move on to B and it's just very painful then to say no no no you cannot", "tokens": [50856, 4829, 316, 293, 436, 528, 281, 1286, 322, 281, 363, 293, 309, 311, 445, 588, 11697, 550, 281, 584, 572, 572, 572, 291, 2644, 51088], "temperature": 0.0, "avg_logprob": -0.06769022211298212, "compression_ratio": 1.8379446640316206, "no_speech_prob": 0.0032667797058820724}, {"id": 398, "seek": 223296, "start": 2247.44, "end": 2254.08, "text": " do that you have to be doing A and so I've been very blessed with being able even with my industry", "tokens": [51088, 360, 300, 291, 362, 281, 312, 884, 316, 293, 370, 286, 600, 668, 588, 12351, 365, 885, 1075, 754, 365, 452, 3518, 51420], "temperature": 0.0, "avg_logprob": -0.06769022211298212, "compression_ratio": 1.8379446640316206, "no_speech_prob": 0.0032667797058820724}, {"id": 399, "seek": 223296, "start": 2254.08, "end": 2261.2, "text": " funding to provide this level of freedom to the students and I think this is really key so the", "tokens": [51420, 6137, 281, 2893, 341, 1496, 295, 5645, 281, 264, 1731, 293, 286, 519, 341, 307, 534, 2141, 370, 264, 51776], "temperature": 0.0, "avg_logprob": -0.06769022211298212, "compression_ratio": 1.8379446640316206, "no_speech_prob": 0.0032667797058820724}, {"id": 400, "seek": 226120, "start": 2261.2, "end": 2265.52, "text": " other thing which I find really key is that the relationship you have with the student is", "tokens": [50364, 661, 551, 597, 286, 915, 534, 2141, 307, 300, 264, 2480, 291, 362, 365, 264, 3107, 307, 50580], "temperature": 0.0, "avg_logprob": -0.05760843937213604, "compression_ratio": 1.73992673992674, "no_speech_prob": 0.0011685882927849889}, {"id": 401, "seek": 226120, "start": 2265.52, "end": 2269.8399999999997, "text": " very important first of all it changes over the years which is also very beautiful so you start", "tokens": [50580, 588, 1021, 700, 295, 439, 309, 2962, 670, 264, 924, 597, 307, 611, 588, 2238, 370, 291, 722, 50796], "temperature": 0.0, "avg_logprob": -0.05760843937213604, "compression_ratio": 1.73992673992674, "no_speech_prob": 0.0011685882927849889}, {"id": 402, "seek": 226120, "start": 2269.8399999999997, "end": 2276.0, "text": " off with much more guidance and towards the end you should actually not be doing any supervision", "tokens": [50796, 766, 365, 709, 544, 10056, 293, 3030, 264, 917, 291, 820, 767, 406, 312, 884, 604, 32675, 51104], "temperature": 0.0, "avg_logprob": -0.05760843937213604, "compression_ratio": 1.73992673992674, "no_speech_prob": 0.0011685882927849889}, {"id": 403, "seek": 226120, "start": 2276.0, "end": 2281.4399999999996, "text": " you should just having a conversation at that point on equal footing and you see about halfway", "tokens": [51104, 291, 820, 445, 1419, 257, 3761, 412, 300, 935, 322, 2681, 45959, 293, 291, 536, 466, 15461, 51376], "temperature": 0.0, "avg_logprob": -0.05760843937213604, "compression_ratio": 1.73992673992674, "no_speech_prob": 0.0011685882927849889}, {"id": 404, "seek": 226120, "start": 2281.4399999999996, "end": 2286.7999999999997, "text": " through a phd like it's like a flower that opens and then it's now they get it suddenly right now", "tokens": [51376, 807, 257, 903, 67, 411, 309, 311, 411, 257, 8617, 300, 9870, 293, 550, 309, 311, 586, 436, 483, 309, 5800, 558, 586, 51644], "temperature": 0.0, "avg_logprob": -0.05760843937213604, "compression_ratio": 1.73992673992674, "no_speech_prob": 0.0011685882927849889}, {"id": 405, "seek": 228680, "start": 2286.8, "end": 2292.0, "text": " they get it and they go and they have a while huge interesting ideas in all directions and they", "tokens": [50364, 436, 483, 309, 293, 436, 352, 293, 436, 362, 257, 1339, 2603, 1880, 3487, 294, 439, 11095, 293, 436, 50624], "temperature": 0.0, "avg_logprob": -0.07027257045852804, "compression_ratio": 1.904382470119522, "no_speech_prob": 0.007338447961956263}, {"id": 406, "seek": 228680, "start": 2292.0, "end": 2297.28, "text": " can write all these papers and stuff so that's a beautiful moment when that happens and the other", "tokens": [50624, 393, 2464, 439, 613, 10577, 293, 1507, 370, 300, 311, 257, 2238, 1623, 562, 300, 2314, 293, 264, 661, 50888], "temperature": 0.0, "avg_logprob": -0.07027257045852804, "compression_ratio": 1.904382470119522, "no_speech_prob": 0.007338447961956263}, {"id": 407, "seek": 228680, "start": 2297.28, "end": 2303.84, "text": " thing I think is that I think of supervision as nudging in the sense that I have a big a lot of", "tokens": [50888, 551, 286, 519, 307, 300, 286, 519, 295, 32675, 382, 40045, 3249, 294, 264, 2020, 300, 286, 362, 257, 955, 257, 688, 295, 51216], "temperature": 0.0, "avg_logprob": -0.07027257045852804, "compression_ratio": 1.904382470119522, "no_speech_prob": 0.007338447961956263}, {"id": 408, "seek": 228680, "start": 2304.5600000000004, "end": 2311.28, "text": " experience and where is where is the interesting stuff to be found right where is the next wave", "tokens": [51252, 1752, 293, 689, 307, 689, 307, 264, 1880, 1507, 281, 312, 1352, 558, 689, 307, 264, 958, 5772, 51588], "temperature": 0.0, "avg_logprob": -0.07027257045852804, "compression_ratio": 1.904382470119522, "no_speech_prob": 0.007338447961956263}, {"id": 409, "seek": 228680, "start": 2311.28, "end": 2315.84, "text": " that we can get people enthusiastic about what are the important questions to address in the", "tokens": [51588, 300, 321, 393, 483, 561, 28574, 466, 437, 366, 264, 1021, 1651, 281, 2985, 294, 264, 51816], "temperature": 0.0, "avg_logprob": -0.07027257045852804, "compression_ratio": 1.904382470119522, "no_speech_prob": 0.007338447961956263}, {"id": 410, "seek": 231584, "start": 2315.84, "end": 2321.28, "text": " community and things like that so that's where my experience lies now I'm not doing a lot of", "tokens": [50364, 1768, 293, 721, 411, 300, 370, 300, 311, 689, 452, 1752, 9134, 586, 286, 478, 406, 884, 257, 688, 295, 50636], "temperature": 0.0, "avg_logprob": -0.07244400111111728, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.007573278620839119}, {"id": 411, "seek": 231584, "start": 2321.28, "end": 2326.56, "text": " coding myself in fact I'm just all doing almost zero coding which I regret for this life and the", "tokens": [50636, 17720, 2059, 294, 1186, 286, 478, 445, 439, 884, 1920, 4018, 17720, 597, 286, 10879, 337, 341, 993, 293, 264, 50900], "temperature": 0.0, "avg_logprob": -0.07244400111111728, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.007573278620839119}, {"id": 412, "seek": 231584, "start": 2326.56, "end": 2332.1600000000003, "text": " other thing is that even in terms of math it's limited right now right but most maybe two pages", "tokens": [50900, 661, 551, 307, 300, 754, 294, 2115, 295, 5221, 309, 311, 5567, 558, 586, 558, 457, 881, 1310, 732, 7183, 51180], "temperature": 0.0, "avg_logprob": -0.07244400111111728, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.007573278620839119}, {"id": 413, "seek": 231584, "start": 2332.1600000000003, "end": 2338.32, "text": " of math to verify something or to compute something quickly but not like a lot of math anymore I just", "tokens": [51180, 295, 5221, 281, 16888, 746, 420, 281, 14722, 746, 2661, 457, 406, 411, 257, 688, 295, 5221, 3602, 286, 445, 51488], "temperature": 0.0, "avg_logprob": -0.07244400111111728, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.007573278620839119}, {"id": 414, "seek": 231584, "start": 2338.32, "end": 2344.1600000000003, "text": " try to keep up with literature mostly and the students do though so they do the hard work", "tokens": [51488, 853, 281, 1066, 493, 365, 10394, 5240, 293, 264, 1731, 360, 1673, 370, 436, 360, 264, 1152, 589, 51780], "temperature": 0.0, "avg_logprob": -0.07244400111111728, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.007573278620839119}, {"id": 415, "seek": 234416, "start": 2344.16, "end": 2348.3999999999996, "text": " literally so they really should they should do all that work and it's this interesting", "tokens": [50364, 3736, 370, 436, 534, 820, 436, 820, 360, 439, 300, 589, 293, 309, 311, 341, 1880, 50576], "temperature": 0.0, "avg_logprob": -0.06253089719605677, "compression_ratio": 1.8431372549019607, "no_speech_prob": 0.013608927838504314}, {"id": 416, "seek": 234416, "start": 2348.3999999999996, "end": 2353.8399999999997, "text": " relationship where you have a discussion where you say I think you know this is an important", "tokens": [50576, 2480, 689, 291, 362, 257, 5017, 689, 291, 584, 286, 519, 291, 458, 341, 307, 364, 1021, 50848], "temperature": 0.0, "avg_logprob": -0.06253089719605677, "compression_ratio": 1.8431372549019607, "no_speech_prob": 0.013608927838504314}, {"id": 417, "seek": 234416, "start": 2353.8399999999997, "end": 2358.72, "text": " direction an interesting direction and here are some other things which are connected to it very", "tokens": [50848, 3513, 364, 1880, 3513, 293, 510, 366, 512, 661, 721, 597, 366, 4582, 281, 309, 588, 51092], "temperature": 0.0, "avg_logprob": -0.06253089719605677, "compression_ratio": 1.8431372549019607, "no_speech_prob": 0.013608927838504314}, {"id": 418, "seek": 234416, "start": 2358.72, "end": 2363.44, "text": " intuitively right so you may want to look there and then a good student will just pick up these", "tokens": [51092, 46506, 558, 370, 291, 815, 528, 281, 574, 456, 293, 550, 257, 665, 3107, 486, 445, 1888, 493, 613, 51328], "temperature": 0.0, "avg_logprob": -0.06253089719605677, "compression_ratio": 1.8431372549019607, "no_speech_prob": 0.013608927838504314}, {"id": 419, "seek": 234416, "start": 2363.44, "end": 2370.16, "text": " ideas and we'll run with it and then come up with new ideas and then you could say it is maybe be", "tokens": [51328, 3487, 293, 321, 603, 1190, 365, 309, 293, 550, 808, 493, 365, 777, 3487, 293, 550, 291, 727, 584, 309, 307, 1310, 312, 51664], "temperature": 0.0, "avg_logprob": -0.06253089719605677, "compression_ratio": 1.8431372549019607, "no_speech_prob": 0.013608927838504314}, {"id": 420, "seek": 237016, "start": 2370.16, "end": 2374.16, "text": " careful about this direction don't go too deep or maybe this is more an interesting direction", "tokens": [50364, 5026, 466, 341, 3513, 500, 380, 352, 886, 2452, 420, 1310, 341, 307, 544, 364, 1880, 3513, 50564], "temperature": 0.0, "avg_logprob": -0.05373182382669535, "compression_ratio": 1.8515625, "no_speech_prob": 0.026732148602604866}, {"id": 421, "seek": 237016, "start": 2374.16, "end": 2380.3999999999996, "text": " stuff like that but even there I've learned to be very careful and if a student comes up with a", "tokens": [50564, 1507, 411, 300, 457, 754, 456, 286, 600, 3264, 281, 312, 588, 5026, 293, 498, 257, 3107, 1487, 493, 365, 257, 50876], "temperature": 0.0, "avg_logprob": -0.05373182382669535, "compression_ratio": 1.8515625, "no_speech_prob": 0.026732148602604866}, {"id": 422, "seek": 237016, "start": 2380.3999999999996, "end": 2385.68, "text": " good idea and intuitively I think that's actually not a great idea this is going to be a dead end", "tokens": [50876, 665, 1558, 293, 46506, 286, 519, 300, 311, 767, 406, 257, 869, 1558, 341, 307, 516, 281, 312, 257, 3116, 917, 51140], "temperature": 0.0, "avg_logprob": -0.05373182382669535, "compression_ratio": 1.8515625, "no_speech_prob": 0.026732148602604866}, {"id": 423, "seek": 237016, "start": 2386.56, "end": 2391.7599999999998, "text": " that I'm not going to tell the student that very soon so I'm just going to certainly leave the", "tokens": [51184, 300, 286, 478, 406, 516, 281, 980, 264, 3107, 300, 588, 2321, 370, 286, 478, 445, 516, 281, 3297, 1856, 264, 51444], "temperature": 0.0, "avg_logprob": -0.05373182382669535, "compression_ratio": 1.8515625, "no_speech_prob": 0.026732148602604866}, {"id": 424, "seek": 237016, "start": 2391.7599999999998, "end": 2398.0, "text": " student about a month to explore that idea for sure and I've been surprised right I've been", "tokens": [51444, 3107, 466, 257, 1618, 281, 6839, 300, 1558, 337, 988, 293, 286, 600, 668, 6100, 558, 286, 600, 668, 51756], "temperature": 0.0, "avg_logprob": -0.05373182382669535, "compression_ratio": 1.8515625, "no_speech_prob": 0.026732148602604866}, {"id": 425, "seek": 239800, "start": 2398.0, "end": 2402.56, "text": " surprised and basically it turned out it was a great idea and I was wrong and so I've been very", "tokens": [50364, 6100, 293, 1936, 309, 3574, 484, 309, 390, 257, 869, 1558, 293, 286, 390, 2085, 293, 370, 286, 600, 668, 588, 50592], "temperature": 0.0, "avg_logprob": -0.06602091745499077, "compression_ratio": 1.9510204081632654, "no_speech_prob": 0.0025896572042256594}, {"id": 426, "seek": 239800, "start": 2402.56, "end": 2408.16, "text": " careful with these things too so I feel it's a very careful dance between the student and the", "tokens": [50592, 5026, 365, 613, 721, 886, 370, 286, 841, 309, 311, 257, 588, 5026, 4489, 1296, 264, 3107, 293, 264, 50872], "temperature": 0.0, "avg_logprob": -0.06602091745499077, "compression_ratio": 1.9510204081632654, "no_speech_prob": 0.0025896572042256594}, {"id": 427, "seek": 239800, "start": 2408.16, "end": 2414.48, "text": " supervisor with not too much direction also it's a very personal so some students like more direction", "tokens": [50872, 24610, 365, 406, 886, 709, 3513, 611, 309, 311, 257, 588, 2973, 370, 512, 1731, 411, 544, 3513, 51188], "temperature": 0.0, "avg_logprob": -0.06602091745499077, "compression_ratio": 1.9510204081632654, "no_speech_prob": 0.0025896572042256594}, {"id": 428, "seek": 239800, "start": 2414.48, "end": 2419.36, "text": " and other students like less direction but I think it is a bit of an art that I've learned", "tokens": [51188, 293, 661, 1731, 411, 1570, 3513, 457, 286, 519, 309, 307, 257, 857, 295, 364, 1523, 300, 286, 600, 3264, 51432], "temperature": 0.0, "avg_logprob": -0.06602091745499077, "compression_ratio": 1.9510204081632654, "no_speech_prob": 0.0025896572042256594}, {"id": 429, "seek": 239800, "start": 2420.08, "end": 2424.88, "text": " to appreciate it is a little bit of an art to have the right type of relationship with students", "tokens": [51468, 281, 4449, 309, 307, 257, 707, 857, 295, 364, 1523, 281, 362, 264, 558, 2010, 295, 2480, 365, 1731, 51708], "temperature": 0.0, "avg_logprob": -0.06602091745499077, "compression_ratio": 1.9510204081632654, "no_speech_prob": 0.0025896572042256594}, {"id": 430, "seek": 242488, "start": 2424.88, "end": 2429.44, "text": " yeah but of course it's all about them they are the ones that need to shine in in the end", "tokens": [50364, 1338, 457, 295, 1164, 309, 311, 439, 466, 552, 436, 366, 264, 2306, 300, 643, 281, 12207, 294, 294, 264, 917, 50592], "temperature": 0.0, "avg_logprob": -0.06975629329681396, "compression_ratio": 1.8449612403100775, "no_speech_prob": 0.0013835541903972626}, {"id": 431, "seek": 242488, "start": 2429.44, "end": 2435.6800000000003, "text": " after four years and they need to get the good jobs and become famous in terms of that guidance and", "tokens": [50592, 934, 1451, 924, 293, 436, 643, 281, 483, 264, 665, 4782, 293, 1813, 4618, 294, 2115, 295, 300, 10056, 293, 50904], "temperature": 0.0, "avg_logprob": -0.06975629329681396, "compression_ratio": 1.8449612403100775, "no_speech_prob": 0.0013835541903972626}, {"id": 432, "seek": 242488, "start": 2435.6800000000003, "end": 2440.56, "text": " specifically what you said with respect to this direction might be interesting these are the", "tokens": [50904, 4682, 437, 291, 848, 365, 3104, 281, 341, 3513, 1062, 312, 1880, 613, 366, 264, 51148], "temperature": 0.0, "avg_logprob": -0.06975629329681396, "compression_ratio": 1.8449612403100775, "no_speech_prob": 0.0013835541903972626}, {"id": 433, "seek": 242488, "start": 2440.56, "end": 2447.6, "text": " interesting research directions is this something that you just have to develop or do you have some", "tokens": [51148, 1880, 2132, 11095, 307, 341, 746, 300, 291, 445, 362, 281, 1499, 420, 360, 291, 362, 512, 51500], "temperature": 0.0, "avg_logprob": -0.06975629329681396, "compression_ratio": 1.8449612403100775, "no_speech_prob": 0.0013835541903972626}, {"id": 434, "seek": 242488, "start": 2447.6, "end": 2454.2400000000002, "text": " general can you give some high level patterns that you've observed throughout the years where", "tokens": [51500, 2674, 393, 291, 976, 512, 1090, 1496, 8294, 300, 291, 600, 13095, 3710, 264, 924, 689, 51832], "temperature": 0.0, "avg_logprob": -0.06975629329681396, "compression_ratio": 1.8449612403100775, "no_speech_prob": 0.0013835541903972626}, {"id": 435, "seek": 245488, "start": 2454.88, "end": 2461.12, "text": " you see recurring things and and you say oh that's another one of those probably like short term", "tokens": [50364, 291, 536, 32279, 721, 293, 293, 291, 584, 1954, 300, 311, 1071, 472, 295, 729, 1391, 411, 2099, 1433, 50676], "temperature": 0.0, "avg_logprob": -0.08874465698419615, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.002080964157357812}, {"id": 436, "seek": 245488, "start": 2461.12, "end": 2466.4, "text": " hypes or yeah have you observed some general patterns there yeah so there's two things right so", "tokens": [50676, 2477, 5190, 420, 1338, 362, 291, 13095, 512, 2674, 8294, 456, 1338, 370, 456, 311, 732, 721, 558, 370, 50940], "temperature": 0.0, "avg_logprob": -0.08874465698419615, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.002080964157357812}, {"id": 437, "seek": 245488, "start": 2466.4, "end": 2472.2400000000002, "text": " there's some things where I think why what is the big deal why is everybody chasing this particular", "tokens": [50940, 456, 311, 512, 721, 689, 286, 519, 983, 437, 307, 264, 955, 2028, 983, 307, 2201, 17876, 341, 1729, 51232], "temperature": 0.0, "avg_logprob": -0.08874465698419615, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.002080964157357812}, {"id": 438, "seek": 245488, "start": 2472.2400000000002, "end": 2479.28, "text": " direction so that's can you predict what the crowd will follow that's one thing seems pretty hard", "tokens": [51232, 3513, 370, 300, 311, 393, 291, 6069, 437, 264, 6919, 486, 1524, 300, 311, 472, 551, 2544, 1238, 1152, 51584], "temperature": 0.0, "avg_logprob": -0.08874465698419615, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.002080964157357812}, {"id": 439, "seek": 247928, "start": 2480.0, "end": 2485.92, "text": " the other one is to find directions which may be on longer time scales", "tokens": [50400, 264, 661, 472, 307, 281, 915, 11095, 597, 815, 312, 322, 2854, 565, 17408, 50696], "temperature": 0.0, "avg_logprob": -0.04963620403144933, "compression_ratio": 1.674757281553398, "no_speech_prob": 0.03728380799293518}, {"id": 440, "seek": 247928, "start": 2486.96, "end": 2493.52, "text": " are impactful and interesting and for the second one it is deeply intuitive and it's very hard to", "tokens": [50748, 366, 30842, 293, 1880, 293, 337, 264, 1150, 472, 309, 307, 8760, 21769, 293, 309, 311, 588, 1152, 281, 51076], "temperature": 0.0, "avg_logprob": -0.04963620403144933, "compression_ratio": 1.674757281553398, "no_speech_prob": 0.03728380799293518}, {"id": 441, "seek": 247928, "start": 2493.52, "end": 2499.76, "text": " figure out precisely what it is what features there are but for me I have to get a sense that", "tokens": [51076, 2573, 484, 13402, 437, 309, 307, 437, 4122, 456, 366, 457, 337, 385, 286, 362, 281, 483, 257, 2020, 300, 51388], "temperature": 0.0, "avg_logprob": -0.04963620403144933, "compression_ratio": 1.674757281553398, "no_speech_prob": 0.03728380799293518}, {"id": 442, "seek": 247928, "start": 2500.6400000000003, "end": 2505.6800000000003, "text": " there is some something very deep going on that I want to pursue like for instance", "tokens": [51432, 456, 307, 512, 746, 588, 2452, 516, 322, 300, 286, 528, 281, 12392, 411, 337, 5197, 51684], "temperature": 0.0, "avg_logprob": -0.04963620403144933, "compression_ratio": 1.674757281553398, "no_speech_prob": 0.03728380799293518}, {"id": 443, "seek": 250568, "start": 2506.64, "end": 2512.0, "text": " so I clearly in physics so if you can think about gauge symmetry like symmetries have this this", "tokens": [50412, 370, 286, 4448, 294, 10649, 370, 498, 291, 393, 519, 466, 17924, 25440, 411, 14232, 302, 2244, 362, 341, 341, 50680], "temperature": 0.0, "avg_logprob": -0.07562522534970884, "compression_ratio": 1.8858267716535433, "no_speech_prob": 0.0026714459527283907}, {"id": 444, "seek": 250568, "start": 2512.0, "end": 2517.2, "text": " deep feeling right symmetries pervade basically all theories of physics and they have this", "tokens": [50680, 2452, 2633, 558, 14232, 302, 2244, 680, 85, 762, 1936, 439, 13667, 295, 10649, 293, 436, 362, 341, 50940], "temperature": 0.0, "avg_logprob": -0.07562522534970884, "compression_ratio": 1.8858267716535433, "no_speech_prob": 0.0026714459527283907}, {"id": 445, "seek": 250568, "start": 2517.2, "end": 2522.72, "text": " profound impact on how you formulate the mathematics of a theory and so there's something very deep", "tokens": [50940, 14382, 2712, 322, 577, 291, 47881, 264, 18666, 295, 257, 5261, 293, 370, 456, 311, 746, 588, 2452, 51216], "temperature": 0.0, "avg_logprob": -0.07562522534970884, "compression_ratio": 1.8858267716535433, "no_speech_prob": 0.0026714459527283907}, {"id": 446, "seek": 250568, "start": 2522.72, "end": 2528.7999999999997, "text": " about symmetries and and about sort of manifolds and doing things on curved spaces and so that's", "tokens": [51216, 466, 14232, 302, 2244, 293, 293, 466, 1333, 295, 8173, 31518, 293, 884, 721, 322, 24991, 7673, 293, 370, 300, 311, 51520], "temperature": 0.0, "avg_logprob": -0.07562522534970884, "compression_ratio": 1.8858267716535433, "no_speech_prob": 0.0026714459527283907}, {"id": 447, "seek": 250568, "start": 2528.7999999999997, "end": 2533.2, "text": " I could sort of naturally drawn into this thing not now it's more quantum mechanics and there's", "tokens": [51520, 286, 727, 1333, 295, 8195, 10117, 666, 341, 551, 406, 586, 309, 311, 544, 13018, 12939, 293, 456, 311, 51740], "temperature": 0.0, "avg_logprob": -0.07562522534970884, "compression_ratio": 1.8858267716535433, "no_speech_prob": 0.0026714459527283907}, {"id": 448, "seek": 253320, "start": 2533.2, "end": 2538.48, "text": " something very deep and especially when it becomes almost mysterious right quantum mechanics is", "tokens": [50364, 746, 588, 2452, 293, 2318, 562, 309, 3643, 1920, 13831, 558, 13018, 12939, 307, 50628], "temperature": 0.0, "avg_logprob": -0.05856959342956543, "compression_ratio": 1.8549618320610688, "no_speech_prob": 0.006577465683221817}, {"id": 449, "seek": 253320, "start": 2538.48, "end": 2542.8799999999997, "text": " almost mysterious how on earth is quantum mechanics possible if you dive a little bit into this", "tokens": [50628, 1920, 13831, 577, 322, 4120, 307, 13018, 12939, 1944, 498, 291, 9192, 257, 707, 857, 666, 341, 50848], "temperature": 0.0, "avg_logprob": -0.05856959342956543, "compression_ratio": 1.8549618320610688, "no_speech_prob": 0.006577465683221817}, {"id": 450, "seek": 253320, "start": 2542.8799999999997, "end": 2548.3999999999996, "text": " phenomenon of there's a two slit experiment where you have these individual photons which which go", "tokens": [50848, 14029, 295, 456, 311, 257, 732, 43182, 5120, 689, 291, 362, 613, 2609, 40209, 597, 597, 352, 51124], "temperature": 0.0, "avg_logprob": -0.05856959342956543, "compression_ratio": 1.8549618320610688, "no_speech_prob": 0.006577465683221817}, {"id": 451, "seek": 253320, "start": 2548.3999999999996, "end": 2553.52, "text": " over two paths and if it's a wave that's perfectly fine they can interfere with each other but now", "tokens": [51124, 670, 732, 14518, 293, 498, 309, 311, 257, 5772, 300, 311, 6239, 2489, 436, 393, 23946, 365, 1184, 661, 457, 586, 51380], "temperature": 0.0, "avg_logprob": -0.05856959342956543, "compression_ratio": 1.8549618320610688, "no_speech_prob": 0.006577465683221817}, {"id": 452, "seek": 253320, "start": 2553.52, "end": 2558.64, "text": " these photons can go one by one and somehow they have to be aware of this other possibility that", "tokens": [51380, 613, 40209, 393, 352, 472, 538, 472, 293, 6063, 436, 362, 281, 312, 3650, 295, 341, 661, 7959, 300, 51636], "temperature": 0.0, "avg_logprob": -0.05856959342956543, "compression_ratio": 1.8549618320610688, "no_speech_prob": 0.006577465683221817}, {"id": 453, "seek": 255864, "start": 2558.64, "end": 2563.6, "text": " they could have taken to interfere with that other possibility I just think that's crazy what's", "tokens": [50364, 436, 727, 362, 2726, 281, 23946, 365, 300, 661, 7959, 286, 445, 519, 300, 311, 3219, 437, 311, 50612], "temperature": 0.0, "avg_logprob": -0.05543120234620338, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.011671077460050583}, {"id": 454, "seek": 255864, "start": 2563.6, "end": 2568.24, "text": " going on here and so I'm naturally drawn into sort of these kinds of mysteries in some sense", "tokens": [50612, 516, 322, 510, 293, 370, 286, 478, 8195, 10117, 666, 1333, 295, 613, 3685, 295, 30785, 294, 512, 2020, 50844], "temperature": 0.0, "avg_logprob": -0.05543120234620338, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.011671077460050583}, {"id": 455, "seek": 255864, "start": 2568.96, "end": 2573.2, "text": " yeah and there's plenty more and the other one is also computation clearly right how does the brain", "tokens": [50880, 1338, 293, 456, 311, 7140, 544, 293, 264, 661, 472, 307, 611, 24903, 4448, 558, 577, 775, 264, 3567, 51092], "temperature": 0.0, "avg_logprob": -0.05543120234620338, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.011671077460050583}, {"id": 456, "seek": 255864, "start": 2573.2, "end": 2577.6, "text": " computing also feels like a very deep question right how do we even compute things what is", "tokens": [51092, 15866, 611, 3417, 411, 257, 588, 2452, 1168, 558, 577, 360, 321, 754, 14722, 721, 437, 307, 51312], "temperature": 0.0, "avg_logprob": -0.05543120234620338, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.011671077460050583}, {"id": 457, "seek": 255864, "start": 2577.6, "end": 2583.68, "text": " computation even and does the universe compute its solution what does it mean to be predictable can", "tokens": [51312, 24903, 754, 293, 775, 264, 6445, 14722, 1080, 3827, 437, 775, 309, 914, 281, 312, 27737, 393, 51616], "temperature": 0.0, "avg_logprob": -0.05543120234620338, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.011671077460050583}, {"id": 458, "seek": 258368, "start": 2583.68, "end": 2589.2799999999997, "text": " you predict can you compute faster than the universe can compute and so there's all these very", "tokens": [50364, 291, 6069, 393, 291, 14722, 4663, 813, 264, 6445, 393, 14722, 293, 370, 456, 311, 439, 613, 588, 50644], "temperature": 0.0, "avg_logprob": -0.05023158326440928, "compression_ratio": 1.8699186991869918, "no_speech_prob": 0.008840258233249187}, {"id": 459, "seek": 258368, "start": 2589.2799999999997, "end": 2594.08, "text": " deep questions about computation as well that you can ask but there's a mixture between", "tokens": [50644, 2452, 1651, 466, 24903, 382, 731, 300, 291, 393, 1029, 457, 456, 311, 257, 9925, 1296, 50884], "temperature": 0.0, "avg_logprob": -0.05023158326440928, "compression_ratio": 1.8699186991869918, "no_speech_prob": 0.008840258233249187}, {"id": 460, "seek": 258368, "start": 2595.04, "end": 2599.68, "text": " things that are attractive in that sort of mysterious sense there's something very deep", "tokens": [50932, 721, 300, 366, 12609, 294, 300, 1333, 295, 13831, 2020, 456, 311, 746, 588, 2452, 51164], "temperature": 0.0, "avg_logprob": -0.05023158326440928, "compression_ratio": 1.8699186991869918, "no_speech_prob": 0.008840258233249187}, {"id": 461, "seek": 258368, "start": 2599.68, "end": 2604.8799999999997, "text": " that needs to be pursued and things which are also highly practical which is sometimes it's also", "tokens": [51164, 300, 2203, 281, 312, 34893, 293, 721, 597, 366, 611, 5405, 8496, 597, 307, 2171, 309, 311, 611, 51424], "temperature": 0.0, "avg_logprob": -0.05023158326440928, "compression_ratio": 1.8699186991869918, "no_speech_prob": 0.008840258233249187}, {"id": 462, "seek": 258368, "start": 2604.8799999999997, "end": 2609.3599999999997, "text": " a lot of fun to work on something that where you can actually make a big impact for instance", "tokens": [51424, 257, 688, 295, 1019, 281, 589, 322, 746, 300, 689, 291, 393, 767, 652, 257, 955, 2712, 337, 5197, 51648], "temperature": 0.0, "avg_logprob": -0.05023158326440928, "compression_ratio": 1.8699186991869918, "no_speech_prob": 0.008840258233249187}, {"id": 463, "seek": 260936, "start": 2609.36, "end": 2617.1200000000003, "text": " speed up MRI imaging with a factor of 10 so now suddenly you can actually both image and", "tokens": [50364, 3073, 493, 32812, 25036, 365, 257, 5952, 295, 1266, 370, 586, 5800, 291, 393, 767, 1293, 3256, 293, 50752], "temperature": 0.0, "avg_logprob": -0.06524791807498571, "compression_ratio": 1.6564625850340136, "no_speech_prob": 0.004236169159412384}, {"id": 464, "seek": 260936, "start": 2617.1200000000003, "end": 2622.32, "text": " radiate cancer at the same time which could have a huge impact in the future and feeling that level", "tokens": [50752, 2843, 13024, 5592, 412, 264, 912, 565, 597, 727, 362, 257, 2603, 2712, 294, 264, 2027, 293, 2633, 300, 1496, 51012], "temperature": 0.0, "avg_logprob": -0.06524791807498571, "compression_ratio": 1.6564625850340136, "no_speech_prob": 0.004236169159412384}, {"id": 465, "seek": 260936, "start": 2622.32, "end": 2628.48, "text": " of impact is also quite exciting I think amazing so I wanted to frame up some of the work that you've", "tokens": [51012, 295, 2712, 307, 611, 1596, 4670, 286, 519, 2243, 370, 286, 1415, 281, 3920, 493, 512, 295, 264, 589, 300, 291, 600, 51320], "temperature": 0.0, "avg_logprob": -0.06524791807498571, "compression_ratio": 1.6564625850340136, "no_speech_prob": 0.004236169159412384}, {"id": 466, "seek": 260936, "start": 2628.48, "end": 2634.2400000000002, "text": " done around symmetries and manifolds it's absolutely fascinating that prevailing idea is that we are", "tokens": [51320, 1096, 926, 14232, 302, 2244, 293, 8173, 31518, 309, 311, 3122, 10343, 300, 12642, 23315, 1558, 307, 300, 321, 366, 51608], "temperature": 0.0, "avg_logprob": -0.06524791807498571, "compression_ratio": 1.6564625850340136, "no_speech_prob": 0.004236169159412384}, {"id": 467, "seek": 260936, "start": 2634.2400000000002, "end": 2637.84, "text": " wasting the representational capacity of neural networks because we're essentially learning the", "tokens": [51608, 20457, 264, 2906, 1478, 6042, 295, 18161, 9590, 570, 321, 434, 4476, 2539, 264, 51788], "temperature": 0.0, "avg_logprob": -0.06524791807498571, "compression_ratio": 1.6564625850340136, "no_speech_prob": 0.004236169159412384}, {"id": 468, "seek": 263784, "start": 2637.92, "end": 2644.4, "text": " same thing many times and your work absolutely pioneered this starting with sort of rotational", "tokens": [50368, 912, 551, 867, 1413, 293, 428, 589, 3122, 19761, 4073, 341, 2891, 365, 1333, 295, 45420, 50692], "temperature": 0.0, "avg_logprob": -0.09160942897618374, "compression_ratio": 1.7198581560283688, "no_speech_prob": 0.011382519267499447}, {"id": 469, "seek": 263784, "start": 2644.4, "end": 2650.2400000000002, "text": " equivariance on on CNNs and then moving on to meshes and graphs and different types of topology", "tokens": [50692, 1267, 592, 3504, 719, 322, 322, 24859, 82, 293, 550, 2684, 322, 281, 3813, 8076, 293, 24877, 293, 819, 3467, 295, 1192, 1793, 50984], "temperature": 0.0, "avg_logprob": -0.09160942897618374, "compression_ratio": 1.7198581560283688, "no_speech_prob": 0.011382519267499447}, {"id": 470, "seek": 263784, "start": 2650.2400000000002, "end": 2655.76, "text": " it's absolutely fascinating but philosophically the modus operandi in deep learning is this blank", "tokens": [50984, 309, 311, 3122, 10343, 457, 14529, 984, 264, 1072, 301, 2208, 49460, 294, 2452, 2539, 307, 341, 8247, 51260], "temperature": 0.0, "avg_logprob": -0.09160942897618374, "compression_ratio": 1.7198581560283688, "no_speech_prob": 0.011382519267499447}, {"id": 471, "seek": 263784, "start": 2655.76, "end": 2662.0, "text": " slate idea this idea that if we look at data and nothing else then we can learn everything we need", "tokens": [51260, 39118, 1558, 341, 1558, 300, 498, 321, 574, 412, 1412, 293, 1825, 1646, 550, 321, 393, 1466, 1203, 321, 643, 51572], "temperature": 0.0, "avg_logprob": -0.09160942897618374, "compression_ratio": 1.7198581560283688, "no_speech_prob": 0.011382519267499447}, {"id": 472, "seek": 263784, "start": 2662.0, "end": 2667.1200000000003, "text": " to presumably not in a very sample efficient way transformers seems to be going in this direction", "tokens": [51572, 281, 26742, 406, 294, 257, 588, 6889, 7148, 636, 4088, 433, 2544, 281, 312, 516, 294, 341, 3513, 51828], "temperature": 0.0, "avg_logprob": -0.09160942897618374, "compression_ratio": 1.7198581560283688, "no_speech_prob": 0.011382519267499447}, {"id": 473, "seek": 266712, "start": 2667.12, "end": 2671.7599999999998, "text": " in the natural language processing world that we just ingest infinite amounts of data and we can", "tokens": [50364, 294, 264, 3303, 2856, 9007, 1002, 300, 321, 445, 3957, 377, 13785, 11663, 295, 1412, 293, 321, 393, 50596], "temperature": 0.0, "avg_logprob": -0.08930723243784681, "compression_ratio": 1.7350746268656716, "no_speech_prob": 0.007744309026747942}, {"id": 474, "seek": 266712, "start": 2671.7599999999998, "end": 2677.44, "text": " learn everything we need to and we spoke to a good old-fashioned AI person while it's over", "tokens": [50596, 1466, 1203, 321, 643, 281, 293, 321, 7179, 281, 257, 665, 1331, 12, 37998, 7318, 954, 1339, 309, 311, 670, 50880], "temperature": 0.0, "avg_logprob": -0.08930723243784681, "compression_ratio": 1.7350746268656716, "no_speech_prob": 0.007744309026747942}, {"id": 475, "seek": 266712, "start": 2677.44, "end": 2682.16, "text": " last week and and his argument was that the information is not in the data he was arguing", "tokens": [50880, 1036, 1243, 293, 293, 702, 6770, 390, 300, 264, 1589, 307, 406, 294, 264, 1412, 415, 390, 19697, 51116], "temperature": 0.0, "avg_logprob": -0.08930723243784681, "compression_ratio": 1.7350746268656716, "no_speech_prob": 0.007744309026747942}, {"id": 476, "seek": 266712, "start": 2682.16, "end": 2688.08, "text": " that we have a kind of ontology or knowledge built into us which we can use to disambiguate", "tokens": [51116, 300, 321, 362, 257, 733, 295, 6592, 1793, 420, 3601, 3094, 666, 505, 597, 321, 393, 764, 281, 717, 2173, 328, 10107, 51412], "temperature": 0.0, "avg_logprob": -0.08930723243784681, "compression_ratio": 1.7350746268656716, "no_speech_prob": 0.007744309026747942}, {"id": 477, "seek": 266712, "start": 2688.08, "end": 2693.7599999999998, "text": " information that we receive so fundamentally speaking do you believe that we can be data-driven", "tokens": [51412, 1589, 300, 321, 4774, 370, 17879, 4124, 360, 291, 1697, 300, 321, 393, 312, 1412, 12, 25456, 51696], "temperature": 0.0, "avg_logprob": -0.08930723243784681, "compression_ratio": 1.7350746268656716, "no_speech_prob": 0.007744309026747942}, {"id": 478, "seek": 269376, "start": 2693.76, "end": 2698.0800000000004, "text": " and can you introduce some of the work you've done with some of these priors in deep learning", "tokens": [50364, 293, 393, 291, 5366, 512, 295, 264, 589, 291, 600, 1096, 365, 512, 295, 613, 1790, 830, 294, 2452, 2539, 50580], "temperature": 0.0, "avg_logprob": -0.10424870307292414, "compression_ratio": 1.856060606060606, "no_speech_prob": 0.022221587598323822}, {"id": 479, "seek": 269376, "start": 2698.6400000000003, "end": 2704.1600000000003, "text": " yes so this is a very fundamental debate clearly but i think it's not all that black and white right", "tokens": [50608, 2086, 370, 341, 307, 257, 588, 8088, 7958, 4448, 457, 741, 519, 309, 311, 406, 439, 300, 2211, 293, 2418, 558, 50884], "temperature": 0.0, "avg_logprob": -0.10424870307292414, "compression_ratio": 1.856060606060606, "no_speech_prob": 0.022221587598323822}, {"id": 480, "seek": 269376, "start": 2704.1600000000003, "end": 2709.84, "text": " so there is a basically at the core of machine learning there is basically trade-offs the the", "tokens": [50884, 370, 456, 307, 257, 1936, 412, 264, 4965, 295, 3479, 2539, 456, 307, 1936, 4923, 12, 19231, 264, 264, 51168], "temperature": 0.0, "avg_logprob": -0.10424870307292414, "compression_ratio": 1.856060606060606, "no_speech_prob": 0.022221587598323822}, {"id": 481, "seek": 269376, "start": 2709.84, "end": 2714.5600000000004, "text": " buy is very in straight-off for instance it clearly expresses this right the first thing i want to", "tokens": [51168, 2256, 307, 588, 294, 2997, 12, 4506, 337, 5197, 309, 4448, 39204, 341, 558, 264, 700, 551, 741, 528, 281, 51404], "temperature": 0.0, "avg_logprob": -0.10424870307292414, "compression_ratio": 1.856060606060606, "no_speech_prob": 0.022221587598323822}, {"id": 482, "seek": 269376, "start": 2714.5600000000004, "end": 2719.92, "text": " say there is no machine learning without assumptions it just basically you have to interpolate between", "tokens": [51404, 584, 456, 307, 572, 3479, 2539, 1553, 17695, 309, 445, 1936, 291, 362, 281, 44902, 473, 1296, 51672], "temperature": 0.0, "avg_logprob": -0.10424870307292414, "compression_ratio": 1.856060606060606, "no_speech_prob": 0.022221587598323822}, {"id": 483, "seek": 271992, "start": 2719.92, "end": 2724.56, "text": " the dots and to interpolate means that you have to make assumptions on smoothness or something", "tokens": [50364, 264, 15026, 293, 281, 44902, 473, 1355, 300, 291, 362, 281, 652, 17695, 322, 5508, 1287, 420, 746, 50596], "temperature": 0.0, "avg_logprob": -0.037068540399724785, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.022940272465348244}, {"id": 484, "seek": 271992, "start": 2724.56, "end": 2728.96, "text": " like that so the machine learning doesn't exist without assumptions i think that's very clear", "tokens": [50596, 411, 300, 370, 264, 3479, 2539, 1177, 380, 2514, 1553, 17695, 741, 519, 300, 311, 588, 1850, 50816], "temperature": 0.0, "avg_logprob": -0.037068540399724785, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.022940272465348244}, {"id": 485, "seek": 271992, "start": 2728.96, "end": 2734.4, "text": " clearly it's a dial right so you can have on the one end you can have problems with a huge amount", "tokens": [50816, 4448, 309, 311, 257, 5502, 558, 370, 291, 393, 362, 322, 264, 472, 917, 291, 393, 362, 2740, 365, 257, 2603, 2372, 51088], "temperature": 0.0, "avg_logprob": -0.037068540399724785, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.022940272465348244}, {"id": 486, "seek": 271992, "start": 2734.4, "end": 2740.7200000000003, "text": " of data it has to be available clearly and there you can dial down your inductive biases you can", "tokens": [51088, 295, 1412, 309, 575, 281, 312, 2435, 4448, 293, 456, 291, 393, 5502, 760, 428, 31612, 488, 32152, 291, 393, 51404], "temperature": 0.0, "avg_logprob": -0.037068540399724785, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.022940272465348244}, {"id": 487, "seek": 271992, "start": 2740.7200000000003, "end": 2748.0, "text": " basically say let that the data do most of the work in some sense and let me make my prior assumptions", "tokens": [51404, 1936, 584, 718, 300, 264, 1412, 360, 881, 295, 264, 589, 294, 512, 2020, 293, 718, 385, 652, 452, 4059, 17695, 51768], "temperature": 0.0, "avg_logprob": -0.037068540399724785, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.022940272465348244}, {"id": 488, "seek": 274800, "start": 2748.08, "end": 2753.28, "text": " quite minimal and with minimal i think i'm interested in a smooth mapping right the mapping", "tokens": [50368, 1596, 13206, 293, 365, 13206, 741, 519, 741, 478, 3102, 294, 257, 5508, 18350, 558, 264, 18350, 50628], "temperature": 0.0, "avg_logprob": -0.05481186257787498, "compression_ratio": 1.7906976744186047, "no_speech_prob": 0.004677166230976582}, {"id": 489, "seek": 274800, "start": 2753.28, "end": 2758.32, "text": " needs to be smooth like that's a very minimal assumption but the disadvantage of that is if", "tokens": [50628, 2203, 281, 312, 5508, 411, 300, 311, 257, 588, 13206, 15302, 457, 264, 24292, 295, 300, 307, 498, 50880], "temperature": 0.0, "avg_logprob": -0.05481186257787498, "compression_ratio": 1.7906976744186047, "no_speech_prob": 0.004677166230976582}, {"id": 490, "seek": 274800, "start": 2758.32, "end": 2765.44, "text": " you don't put any prior assumptions is that if you need to take whatever you've learned into a new", "tokens": [50880, 291, 500, 380, 829, 604, 4059, 17695, 307, 300, 498, 291, 643, 281, 747, 2035, 291, 600, 3264, 666, 257, 777, 51236], "temperature": 0.0, "avg_logprob": -0.05481186257787498, "compression_ratio": 1.7906976744186047, "no_speech_prob": 0.004677166230976582}, {"id": 491, "seek": 274800, "start": 2765.44, "end": 2772.08, "text": " domain where this model wasn't learned it will very quickly break down because these prior assumptions", "tokens": [51236, 9274, 689, 341, 2316, 2067, 380, 3264, 309, 486, 588, 2661, 1821, 760, 570, 613, 4059, 17695, 51568], "temperature": 0.0, "avg_logprob": -0.05481186257787498, "compression_ratio": 1.7906976744186047, "no_speech_prob": 0.004677166230976582}, {"id": 492, "seek": 277208, "start": 2772.08, "end": 2779.04, "text": " will help you transfer from one domain to another domain and causality does play a big", "tokens": [50364, 486, 854, 291, 5003, 490, 472, 9274, 281, 1071, 9274, 293, 3302, 1860, 775, 862, 257, 955, 50712], "temperature": 0.0, "avg_logprob": -0.06218481972104027, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.009699863381683826}, {"id": 493, "seek": 277208, "start": 2779.04, "end": 2783.7599999999998, "text": " role here but we can talk about this later and then on the other hand there is basically what", "tokens": [50712, 3090, 510, 457, 321, 393, 751, 466, 341, 1780, 293, 550, 322, 264, 661, 1011, 456, 307, 1936, 437, 50948], "temperature": 0.0, "avg_logprob": -0.06218481972104027, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.009699863381683826}, {"id": 494, "seek": 277208, "start": 2783.7599999999998, "end": 2788.3199999999997, "text": " everybody else in the scientific community does which is write down a model of the world which", "tokens": [50948, 2201, 1646, 294, 264, 8134, 1768, 775, 597, 307, 2464, 760, 257, 2316, 295, 264, 1002, 597, 51176], "temperature": 0.0, "avg_logprob": -0.06218481972104027, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.009699863381683826}, {"id": 495, "seek": 277208, "start": 2788.3199999999997, "end": 2793.6, "text": " we call a generative model which is how do i imagine that the world that i'm seeing in my", "tokens": [51176, 321, 818, 257, 1337, 1166, 2316, 597, 307, 577, 360, 741, 3811, 300, 264, 1002, 300, 741, 478, 2577, 294, 452, 51440], "temperature": 0.0, "avg_logprob": -0.06218481972104027, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.009699863381683826}, {"id": 496, "seek": 277208, "start": 2793.6, "end": 2799.68, "text": " measurement apparatus could have been generated by nature and and that's that you can put a lot of", "tokens": [51440, 13160, 38573, 727, 362, 668, 10833, 538, 3687, 293, 293, 300, 311, 300, 291, 393, 829, 257, 688, 295, 51744], "temperature": 0.0, "avg_logprob": -0.06218481972104027, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.009699863381683826}, {"id": 497, "seek": 279968, "start": 2800.24, "end": 2805.8399999999997, "text": " intuitive knowledge there because you could think the world is described by a PDE or some kind of", "tokens": [50392, 21769, 3601, 456, 570, 291, 727, 519, 264, 1002, 307, 7619, 538, 257, 10464, 36, 420, 512, 733, 295, 50672], "temperature": 0.0, "avg_logprob": -0.06121130093284275, "compression_ratio": 1.9094650205761317, "no_speech_prob": 0.003119342029094696}, {"id": 498, "seek": 279968, "start": 2805.8399999999997, "end": 2811.7599999999998, "text": " generative model so the people in our community often call this probabilistic programming models", "tokens": [50672, 1337, 1166, 2316, 370, 264, 561, 294, 527, 1768, 2049, 818, 341, 31959, 3142, 9410, 5245, 50968], "temperature": 0.0, "avg_logprob": -0.06121130093284275, "compression_ratio": 1.9094650205761317, "no_speech_prob": 0.003119342029094696}, {"id": 499, "seek": 279968, "start": 2811.7599999999998, "end": 2816.96, "text": " created by probabilistic programs or graphical models but they are highly intuitive highly", "tokens": [50968, 2942, 538, 31959, 3142, 4268, 420, 35942, 5245, 457, 436, 366, 5405, 21769, 5405, 51228], "temperature": 0.0, "avg_logprob": -0.06121130093284275, "compression_ratio": 1.9094650205761317, "no_speech_prob": 0.003119342029094696}, {"id": 500, "seek": 279968, "start": 2816.96, "end": 2822.64, "text": " interpretable and because they describe the generative process they are often also causal", "tokens": [51228, 7302, 712, 293, 570, 436, 6786, 264, 1337, 1166, 1399, 436, 366, 2049, 611, 38755, 51512], "temperature": 0.0, "avg_logprob": -0.06121130093284275, "compression_ratio": 1.9094650205761317, "no_speech_prob": 0.003119342029094696}, {"id": 501, "seek": 279968, "start": 2822.64, "end": 2826.48, "text": " because you can think of these variables and one causes the other variable to happen etc", "tokens": [51512, 570, 291, 393, 519, 295, 613, 9102, 293, 472, 7700, 264, 661, 7006, 281, 1051, 5183, 51704], "temperature": 0.0, "avg_logprob": -0.06121130093284275, "compression_ratio": 1.9094650205761317, "no_speech_prob": 0.003119342029094696}, {"id": 502, "seek": 282648, "start": 2827.2, "end": 2833.6, "text": " and because they are causal they really generalize very well which means that if i train you know", "tokens": [50400, 293, 570, 436, 366, 38755, 436, 534, 2674, 1125, 588, 731, 597, 1355, 300, 498, 741, 3847, 291, 458, 50720], "temperature": 0.0, "avg_logprob": -0.10659977274203519, "compression_ratio": 1.8264150943396227, "no_speech_prob": 0.008838898502290249}, {"id": 503, "seek": 282648, "start": 2833.6, "end": 2839.92, "text": " and someone in one context i say i learn to drive in the Netherlands i'm driving on the right side", "tokens": [50720, 293, 1580, 294, 472, 4319, 741, 584, 741, 1466, 281, 3332, 294, 264, 20873, 741, 478, 4840, 322, 264, 558, 1252, 51036], "temperature": 0.0, "avg_logprob": -0.10659977274203519, "compression_ratio": 1.8264150943396227, "no_speech_prob": 0.008838898502290249}, {"id": 504, "seek": 282648, "start": 2839.92, "end": 2846.64, "text": " on the road i have particular kind of traffic signs etc so now i can take whatever i've learned", "tokens": [51036, 322, 264, 3060, 741, 362, 1729, 733, 295, 6419, 7880, 5183, 370, 586, 741, 393, 747, 2035, 741, 600, 3264, 51372], "temperature": 0.0, "avg_logprob": -0.10659977274203519, "compression_ratio": 1.8264150943396227, "no_speech_prob": 0.008838898502290249}, {"id": 505, "seek": 282648, "start": 2846.64, "end": 2851.12, "text": " sort of these rules or whatever i've learned and now i can move to another country where you", "tokens": [51372, 1333, 295, 613, 4474, 420, 2035, 741, 600, 3264, 293, 586, 741, 393, 1286, 281, 1071, 1941, 689, 291, 51596], "temperature": 0.0, "avg_logprob": -0.10659977274203519, "compression_ratio": 1.8264150943396227, "no_speech_prob": 0.008838898502290249}, {"id": 506, "seek": 282648, "start": 2851.12, "end": 2854.96, "text": " drive on the left hand side of the road completely different traffic signs and i can still survive", "tokens": [51596, 3332, 322, 264, 1411, 1011, 1252, 295, 264, 3060, 2584, 819, 6419, 7880, 293, 741, 393, 920, 7867, 51788], "temperature": 0.0, "avg_logprob": -0.10659977274203519, "compression_ratio": 1.8264150943396227, "no_speech_prob": 0.008838898502290249}, {"id": 507, "seek": 285496, "start": 2854.96, "end": 2860.32, "text": " so this is typically something that the the the purity data driven methods have a much harder", "tokens": [50364, 370, 341, 307, 5850, 746, 300, 264, 264, 264, 34382, 1412, 9555, 7150, 362, 257, 709, 6081, 50632], "temperature": 0.0, "avg_logprob": -0.11527690887451172, "compression_ratio": 1.7899543378995433, "no_speech_prob": 0.0022490008268505335}, {"id": 508, "seek": 285496, "start": 2861.04, "end": 2867.92, "text": " time doing this sort of generalization so i think this is basically a trade of now it's it's the big", "tokens": [50668, 565, 884, 341, 1333, 295, 2674, 2144, 370, 741, 519, 341, 307, 1936, 257, 4923, 295, 586, 309, 311, 309, 311, 264, 955, 51012], "temperature": 0.0, "avg_logprob": -0.11527690887451172, "compression_ratio": 1.7899543378995433, "no_speech_prob": 0.0022490008268505335}, {"id": 509, "seek": 285496, "start": 2867.92, "end": 2875.92, "text": " question in some sense over time is can we simply take the data driven approach and extended all", "tokens": [51012, 1168, 294, 512, 2020, 670, 565, 307, 393, 321, 2935, 747, 264, 1412, 9555, 3109, 293, 10913, 439, 51412], "temperature": 0.0, "avg_logprob": -0.11527690887451172, "compression_ratio": 1.7899543378995433, "no_speech_prob": 0.0022490008268505335}, {"id": 510, "seek": 285496, "start": 2875.92, "end": 2882.56, "text": " the way to agi but there are people on one side of the fence that are claiming that this is possible", "tokens": [51412, 264, 636, 281, 623, 72, 457, 456, 366, 561, 322, 472, 1252, 295, 264, 15422, 300, 366, 19232, 300, 341, 307, 1944, 51744], "temperature": 0.0, "avg_logprob": -0.11527690887451172, "compression_ratio": 1.7899543378995433, "no_speech_prob": 0.0022490008268505335}, {"id": 511, "seek": 288256, "start": 2882.7999999999997, "end": 2888.08, "text": " of course we also need to amplify computation right so we're just going to build faster and", "tokens": [50376, 295, 1164, 321, 611, 643, 281, 41174, 24903, 558, 370, 321, 434, 445, 516, 281, 1322, 4663, 293, 50640], "temperature": 0.0, "avg_logprob": -0.07925399981046978, "compression_ratio": 1.77007299270073, "no_speech_prob": 0.0025481542106717825}, {"id": 512, "seek": 288256, "start": 2888.08, "end": 2895.44, "text": " faster computers that can digest more and more data and at some point we'll just have agi emerge", "tokens": [50640, 4663, 10807, 300, 393, 13884, 544, 293, 544, 1412, 293, 412, 512, 935, 321, 603, 445, 362, 623, 72, 21511, 51008], "temperature": 0.0, "avg_logprob": -0.07925399981046978, "compression_ratio": 1.77007299270073, "no_speech_prob": 0.0025481542106717825}, {"id": 513, "seek": 288256, "start": 2895.44, "end": 2900.96, "text": " out of this kind of process and then on the other side we just want a classical ai sort of community", "tokens": [51008, 484, 295, 341, 733, 295, 1399, 293, 550, 322, 264, 661, 1252, 321, 445, 528, 257, 13735, 9783, 1333, 295, 1768, 51284], "temperature": 0.0, "avg_logprob": -0.07925399981046978, "compression_ratio": 1.77007299270073, "no_speech_prob": 0.0025481542106717825}, {"id": 514, "seek": 288256, "start": 2900.96, "end": 2904.96, "text": " which is no no no that's going to be ridiculous you will never be able to do that you really need", "tokens": [51284, 597, 307, 572, 572, 572, 300, 311, 516, 281, 312, 11083, 291, 486, 1128, 312, 1075, 281, 360, 300, 291, 534, 643, 51484], "temperature": 0.0, "avg_logprob": -0.07925399981046978, "compression_ratio": 1.77007299270073, "no_speech_prob": 0.0025481542106717825}, {"id": 515, "seek": 288256, "start": 2904.96, "end": 2911.84, "text": " to imbue these models with the structure of the world which which i take as how does physics work", "tokens": [51484, 281, 566, 65, 622, 613, 5245, 365, 264, 3877, 295, 264, 1002, 597, 597, 741, 747, 382, 577, 775, 10649, 589, 51828], "temperature": 0.0, "avg_logprob": -0.07925399981046978, "compression_ratio": 1.77007299270073, "no_speech_prob": 0.0025481542106717825}, {"id": 516, "seek": 291184, "start": 2911.84, "end": 2916.8, "text": " how does the world work can i tell you something about how data really gets generated in this work", "tokens": [50364, 577, 775, 264, 1002, 589, 393, 741, 980, 291, 746, 466, 577, 1412, 534, 2170, 10833, 294, 341, 589, 50612], "temperature": 0.0, "avg_logprob": -0.04938213674871771, "compression_ratio": 1.849056603773585, "no_speech_prob": 0.0038226114120334387}, {"id": 517, "seek": 291184, "start": 2916.8, "end": 2922.0, "text": " this will cut down the number of parameters to learn dramatically and because i'm following", "tokens": [50612, 341, 486, 1723, 760, 264, 1230, 295, 9834, 281, 1466, 17548, 293, 570, 741, 478, 3480, 50872], "temperature": 0.0, "avg_logprob": -0.04938213674871771, "compression_ratio": 1.849056603773585, "no_speech_prob": 0.0038226114120334387}, {"id": 518, "seek": 291184, "start": 2922.0, "end": 2928.96, "text": " causality i can now basically generalize and create agi in this way and so this is going to be", "tokens": [50872, 3302, 1860, 741, 393, 586, 1936, 2674, 1125, 293, 1884, 623, 72, 294, 341, 636, 293, 370, 341, 307, 516, 281, 312, 51220], "temperature": 0.0, "avg_logprob": -0.04938213674871771, "compression_ratio": 1.849056603773585, "no_speech_prob": 0.0038226114120334387}, {"id": 519, "seek": 291184, "start": 2928.96, "end": 2933.76, "text": " very interesting how this is going to play out and you know to be honest so i feel that i'm slightly", "tokens": [51220, 588, 1880, 577, 341, 307, 516, 281, 862, 484, 293, 291, 458, 281, 312, 3245, 370, 741, 841, 300, 741, 478, 4748, 51460], "temperature": 0.0, "avg_logprob": -0.04938213674871771, "compression_ratio": 1.849056603773585, "no_speech_prob": 0.0038226114120334387}, {"id": 520, "seek": 291184, "start": 2933.76, "end": 2939.44, "text": " in the camp of you really need to put generative information into your models but i've been continually", "tokens": [51460, 294, 264, 2255, 295, 291, 534, 643, 281, 829, 1337, 1166, 1589, 666, 428, 5245, 457, 741, 600, 668, 22277, 51744], "temperature": 0.0, "avg_logprob": -0.04938213674871771, "compression_ratio": 1.849056603773585, "no_speech_prob": 0.0038226114120334387}, {"id": 521, "seek": 293944, "start": 2939.44, "end": 2944.4, "text": " surprised by what's happening on the other side of course lots of my work is also on the other side", "tokens": [50364, 6100, 538, 437, 311, 2737, 322, 264, 661, 1252, 295, 1164, 3195, 295, 452, 589, 307, 611, 322, 264, 661, 1252, 50612], "temperature": 0.0, "avg_logprob": -0.049464745599715434, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.01629229262471199}, {"id": 522, "seek": 293944, "start": 2945.2000000000003, "end": 2951.6, "text": " in the sense that gpt3 you know is completely 100 data driven and did we expect that it would", "tokens": [50652, 294, 264, 2020, 300, 290, 662, 18, 291, 458, 307, 2584, 2319, 1412, 9555, 293, 630, 321, 2066, 300, 309, 576, 50972], "temperature": 0.0, "avg_logprob": -0.049464745599715434, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.01629229262471199}, {"id": 523, "seek": 293944, "start": 2951.6, "end": 2957.92, "text": " do so well no so he is another big surprise right and so that's i think that's the fun part but it", "tokens": [50972, 360, 370, 731, 572, 370, 415, 307, 1071, 955, 6365, 558, 293, 370, 300, 311, 741, 519, 300, 311, 264, 1019, 644, 457, 309, 51288], "temperature": 0.0, "avg_logprob": -0.049464745599715434, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.01629229262471199}, {"id": 524, "seek": 293944, "start": 2957.92, "end": 2962.8, "text": " kind of doesn't do well though it doesn't have any reversibility so if you ask it how many feet fit", "tokens": [51288, 733, 295, 1177, 380, 360, 731, 1673, 309, 1177, 380, 362, 604, 14582, 2841, 370, 498, 291, 1029, 309, 577, 867, 3521, 3318, 51532], "temperature": 0.0, "avg_logprob": -0.049464745599715434, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.01629229262471199}, {"id": 525, "seek": 293944, "start": 2962.8, "end": 2969.04, "text": " in a shoe or we did the example last week so the corner table wants another beer it doesn't know", "tokens": [51532, 294, 257, 12796, 420, 321, 630, 264, 1365, 1036, 1243, 370, 264, 4538, 3199, 2738, 1071, 8795, 309, 1177, 380, 458, 51844], "temperature": 0.0, "avg_logprob": -0.049464745599715434, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.01629229262471199}, {"id": 526, "seek": 296904, "start": 2969.04, "end": 2973.2, "text": " that the corner table is a person because that's missing information we would fill in those gaps", "tokens": [50364, 300, 264, 4538, 3199, 307, 257, 954, 570, 300, 311, 5361, 1589, 321, 576, 2836, 294, 729, 15031, 50572], "temperature": 0.0, "avg_logprob": -0.07437351989746094, "compression_ratio": 1.8296529968454258, "no_speech_prob": 0.00961462315171957}, {"id": 527, "seek": 296904, "start": 2973.2, "end": 2978.0, "text": " but it does raise the question though of the dichotomy between memorization and compute", "tokens": [50572, 457, 309, 775, 5300, 264, 1168, 1673, 295, 264, 10390, 310, 8488, 1296, 10560, 2144, 293, 14722, 50812], "temperature": 0.0, "avg_logprob": -0.07437351989746094, "compression_ratio": 1.8296529968454258, "no_speech_prob": 0.00961462315171957}, {"id": 528, "seek": 296904, "start": 2978.0, "end": 2983.12, "text": " and the guy we were speaking to last week just said that even if you had an infinite amount of", "tokens": [50812, 293, 264, 2146, 321, 645, 4124, 281, 1036, 1243, 445, 848, 300, 754, 498, 291, 632, 364, 13785, 2372, 295, 51068], "temperature": 0.0, "avg_logprob": -0.07437351989746094, "compression_ratio": 1.8296529968454258, "no_speech_prob": 0.00961462315171957}, {"id": 529, "seek": 296904, "start": 2983.12, "end": 2988.64, "text": " memory and the data is just not there you couldn't do it when you were responding to rich sutton and", "tokens": [51068, 4675, 293, 264, 1412, 307, 445, 406, 456, 291, 2809, 380, 360, 309, 562, 291, 645, 16670, 281, 4593, 262, 13478, 266, 293, 51344], "temperature": 0.0, "avg_logprob": -0.07437351989746094, "compression_ratio": 1.8296529968454258, "no_speech_prob": 0.00961462315171957}, {"id": 530, "seek": 296904, "start": 2988.64, "end": 2992.88, "text": " you actually spoke about all the different schools of thought in machine learning so you said compute", "tokens": [51344, 291, 767, 7179, 466, 439, 264, 819, 4656, 295, 1194, 294, 3479, 2539, 370, 291, 848, 14722, 51556], "temperature": 0.0, "avg_logprob": -0.07437351989746094, "compression_ratio": 1.8296529968454258, "no_speech_prob": 0.00961462315171957}, {"id": 531, "seek": 296904, "start": 2992.88, "end": 2998.64, "text": " driven versus knowledge and model driven or data driven and symbolic or statistical and white box", "tokens": [51556, 9555, 5717, 3601, 293, 2316, 9555, 420, 1412, 9555, 293, 25755, 420, 22820, 293, 2418, 2424, 51844], "temperature": 0.0, "avg_logprob": -0.07437351989746094, "compression_ratio": 1.8296529968454258, "no_speech_prob": 0.00961462315171957}, {"id": 532, "seek": 299864, "start": 2998.64, "end": 3003.2, "text": " or black box and generative and discriminative the generative thing is fascinating because our", "tokens": [50364, 420, 2211, 2424, 293, 1337, 1166, 293, 20828, 1166, 264, 1337, 1166, 551, 307, 10343, 570, 527, 50592], "temperature": 0.0, "avg_logprob": -0.049201461247035436, "compression_ratio": 1.8244274809160306, "no_speech_prob": 0.0035375580191612244}, {"id": 533, "seek": 299864, "start": 3003.2, "end": 3007.3599999999997, "text": " brains it's a bit like we've got the matrix or we've got a simulation going on behind the scenes", "tokens": [50592, 15442, 309, 311, 257, 857, 411, 321, 600, 658, 264, 8141, 420, 321, 600, 658, 257, 16575, 516, 322, 2261, 264, 8026, 50800], "temperature": 0.0, "avg_logprob": -0.049201461247035436, "compression_ratio": 1.8244274809160306, "no_speech_prob": 0.0035375580191612244}, {"id": 534, "seek": 299864, "start": 3007.3599999999997, "end": 3011.6, "text": " haven't we we're always thinking about all these potential situations and possibly integrating", "tokens": [50800, 2378, 380, 321, 321, 434, 1009, 1953, 466, 439, 613, 3995, 6851, 293, 6264, 26889, 51012], "temperature": 0.0, "avg_logprob": -0.049201461247035436, "compression_ratio": 1.8244274809160306, "no_speech_prob": 0.0035375580191612244}, {"id": 535, "seek": 299864, "start": 3011.6, "end": 3017.68, "text": " between them yes i i do agree that seems to be the real trick for intelligence at least in humans", "tokens": [51012, 1296, 552, 2086, 741, 741, 360, 3986, 300, 2544, 281, 312, 264, 957, 4282, 337, 7599, 412, 1935, 294, 6255, 51316], "temperature": 0.0, "avg_logprob": -0.049201461247035436, "compression_ratio": 1.8244274809160306, "no_speech_prob": 0.0035375580191612244}, {"id": 536, "seek": 299864, "start": 3017.68, "end": 3024.7999999999997, "text": " so our ability to generate the world at least at a symbolic level we don't generate like high", "tokens": [51316, 370, 527, 3485, 281, 8460, 264, 1002, 412, 1935, 412, 257, 25755, 1496, 321, 500, 380, 8460, 411, 1090, 51672], "temperature": 0.0, "avg_logprob": -0.049201461247035436, "compression_ratio": 1.8244274809160306, "no_speech_prob": 0.0035375580191612244}, {"id": 537, "seek": 302480, "start": 3024.8, "end": 3031.2000000000003, "text": " resolution videos in our brain but we do generate objects and interactions between objects and sort", "tokens": [50364, 8669, 2145, 294, 527, 3567, 457, 321, 360, 8460, 6565, 293, 13280, 1296, 6565, 293, 1333, 50684], "temperature": 0.0, "avg_logprob": -0.040933387929742986, "compression_ratio": 1.9143968871595332, "no_speech_prob": 0.05336245894432068}, {"id": 538, "seek": 302480, "start": 3031.2000000000003, "end": 3037.2000000000003, "text": " of how things will play out and this will also help us imagine things like what would have happened", "tokens": [50684, 295, 577, 721, 486, 862, 484, 293, 341, 486, 611, 854, 505, 3811, 721, 411, 437, 576, 362, 2011, 50984], "temperature": 0.0, "avg_logprob": -0.040933387929742986, "compression_ratio": 1.9143968871595332, "no_speech_prob": 0.05336245894432068}, {"id": 539, "seek": 302480, "start": 3037.2000000000003, "end": 3041.92, "text": " if i would have done this so now i can play out this alternative world and say that was bad let", "tokens": [50984, 498, 741, 576, 362, 1096, 341, 370, 586, 741, 393, 862, 484, 341, 8535, 1002, 293, 584, 300, 390, 1578, 718, 51220], "temperature": 0.0, "avg_logprob": -0.040933387929742986, "compression_ratio": 1.9143968871595332, "no_speech_prob": 0.05336245894432068}, {"id": 540, "seek": 302480, "start": 3041.92, "end": 3046.8, "text": " let me not do this now so i think that is going to be a key so that's the generative part of the", "tokens": [51220, 718, 385, 406, 360, 341, 586, 370, 741, 519, 300, 307, 516, 281, 312, 257, 2141, 370, 300, 311, 264, 1337, 1166, 644, 295, 264, 51464], "temperature": 0.0, "avg_logprob": -0.040933387929742986, "compression_ratio": 1.9143968871595332, "no_speech_prob": 0.05336245894432068}, {"id": 541, "seek": 302480, "start": 3046.8, "end": 3052.6400000000003, "text": " modeling because you can generate you understand how the world works the physics of the world works", "tokens": [51464, 15983, 570, 291, 393, 8460, 291, 1223, 577, 264, 1002, 1985, 264, 10649, 295, 264, 1002, 1985, 51756], "temperature": 0.0, "avg_logprob": -0.040933387929742986, "compression_ratio": 1.9143968871595332, "no_speech_prob": 0.05336245894432068}, {"id": 542, "seek": 305264, "start": 3052.64, "end": 3057.44, "text": " and so you can generate possible futures to me i feel that's going to be a really important part", "tokens": [50364, 293, 370, 291, 393, 8460, 1944, 26071, 281, 385, 741, 841, 300, 311, 516, 281, 312, 257, 534, 1021, 644, 50604], "temperature": 0.0, "avg_logprob": -0.03680276602841495, "compression_ratio": 1.728888888888889, "no_speech_prob": 0.00359137449413538}, {"id": 543, "seek": 305264, "start": 3057.44, "end": 3064.72, "text": " of intelligence and i do agree that it's for me also very hard to see that you can generate enough", "tokens": [50604, 295, 7599, 293, 741, 360, 3986, 300, 309, 311, 337, 385, 611, 588, 1152, 281, 536, 300, 291, 393, 8460, 1547, 50968], "temperature": 0.0, "avg_logprob": -0.03680276602841495, "compression_ratio": 1.728888888888889, "no_speech_prob": 0.00359137449413538}, {"id": 544, "seek": 305264, "start": 3064.72, "end": 3070.72, "text": " data to cover all corner cases it's just very tough if you do it in the wrong direction which is the", "tokens": [50968, 1412, 281, 2060, 439, 4538, 3331, 309, 311, 445, 588, 4930, 498, 291, 360, 309, 294, 264, 2085, 3513, 597, 307, 264, 51268], "temperature": 0.0, "avg_logprob": -0.03680276602841495, "compression_ratio": 1.728888888888889, "no_speech_prob": 0.00359137449413538}, {"id": 545, "seek": 305264, "start": 3070.72, "end": 3076.56, "text": " discriminative direction but again i have been surprised by how good these models really are", "tokens": [51268, 20828, 1166, 3513, 457, 797, 741, 362, 668, 6100, 538, 577, 665, 613, 5245, 534, 366, 51560], "temperature": 0.0, "avg_logprob": -0.03680276602841495, "compression_ratio": 1.728888888888889, "no_speech_prob": 0.00359137449413538}, {"id": 546, "seek": 307656, "start": 3076.56, "end": 3083.68, "text": " and so you say gpt3 isn't very good maybe but it's a receding horizon right people may have not", "tokens": [50364, 293, 370, 291, 584, 290, 662, 18, 1943, 380, 588, 665, 1310, 457, 309, 311, 257, 850, 9794, 18046, 558, 561, 815, 362, 406, 50720], "temperature": 0.0, "avg_logprob": -0.05388633624927418, "compression_ratio": 1.8622047244094488, "no_speech_prob": 0.09927788376808167}, {"id": 547, "seek": 307656, "start": 3083.68, "end": 3088.88, "text": " thought this was true or bet on something like gpt3 before it appeared and then it appeared and", "tokens": [50720, 1194, 341, 390, 2074, 420, 778, 322, 746, 411, 290, 662, 18, 949, 309, 8516, 293, 550, 309, 8516, 293, 50980], "temperature": 0.0, "avg_logprob": -0.05388633624927418, "compression_ratio": 1.8622047244094488, "no_speech_prob": 0.09927788376808167}, {"id": 548, "seek": 307656, "start": 3088.88, "end": 3092.7999999999997, "text": " people were extremely impressed and then of course some people poke it and say but it doesn't", "tokens": [50980, 561, 645, 4664, 11679, 293, 550, 295, 1164, 512, 561, 19712, 309, 293, 584, 457, 309, 1177, 380, 51176], "temperature": 0.0, "avg_logprob": -0.05388633624927418, "compression_ratio": 1.8622047244094488, "no_speech_prob": 0.09927788376808167}, {"id": 549, "seek": 307656, "start": 3092.7999999999997, "end": 3097.84, "text": " understand this and this and then excitement goes away again a little bit but it is a bit of a", "tokens": [51176, 1223, 341, 293, 341, 293, 550, 14755, 1709, 1314, 797, 257, 707, 857, 457, 309, 307, 257, 857, 295, 257, 51428], "temperature": 0.0, "avg_logprob": -0.05388633624927418, "compression_ratio": 1.8622047244094488, "no_speech_prob": 0.09927788376808167}, {"id": 550, "seek": 307656, "start": 3097.84, "end": 3101.92, "text": " receding horizon but i have generally be very impressed also with for instance the fact that", "tokens": [51428, 850, 9794, 18046, 457, 741, 362, 5101, 312, 588, 11679, 611, 365, 337, 5197, 264, 1186, 300, 51632], "temperature": 0.0, "avg_logprob": -0.05388633624927418, "compression_ratio": 1.8622047244094488, "no_speech_prob": 0.09927788376808167}, {"id": 551, "seek": 310192, "start": 3101.92, "end": 3108.32, "text": " we cannot generate faces of people that that don't exist we can create billions of faces that", "tokens": [50364, 321, 2644, 8460, 8475, 295, 561, 300, 300, 500, 380, 2514, 321, 393, 1884, 17375, 295, 8475, 300, 50684], "temperature": 0.0, "avg_logprob": -0.07485572497049968, "compression_ratio": 1.8449612403100775, "no_speech_prob": 0.029729345813393593}, {"id": 552, "seek": 310192, "start": 3108.32, "end": 3113.6800000000003, "text": " that don't exist on this planet and that look absolutely realistic would i have expected this", "tokens": [50684, 300, 500, 380, 2514, 322, 341, 5054, 293, 300, 574, 3122, 12465, 576, 741, 362, 5176, 341, 50952], "temperature": 0.0, "avg_logprob": -0.07485572497049968, "compression_ratio": 1.8449612403100775, "no_speech_prob": 0.029729345813393593}, {"id": 553, "seek": 310192, "start": 3113.6800000000003, "end": 3118.48, "text": " no probably not so no and then of course there's alpha go and things like this which we also wouldn't", "tokens": [50952, 572, 1391, 406, 370, 572, 293, 550, 295, 1164, 456, 311, 8961, 352, 293, 721, 411, 341, 597, 321, 611, 2759, 380, 51192], "temperature": 0.0, "avg_logprob": -0.07485572497049968, "compression_ratio": 1.8449612403100775, "no_speech_prob": 0.029729345813393593}, {"id": 554, "seek": 310192, "start": 3118.48, "end": 3123.76, "text": " have expected right before it happens let me play a bit of devil's advocate with respect to", "tokens": [51192, 362, 5176, 558, 949, 309, 2314, 718, 385, 862, 257, 857, 295, 13297, 311, 14608, 365, 3104, 281, 51456], "temperature": 0.0, "avg_logprob": -0.07485572497049968, "compression_ratio": 1.8449612403100775, "no_speech_prob": 0.029729345813393593}, {"id": 555, "seek": 310192, "start": 3124.32, "end": 3131.76, "text": " building priors into models it's of course like some of the easiest priors we can think of are", "tokens": [51484, 2390, 1790, 830, 666, 5245, 309, 311, 295, 1164, 411, 512, 295, 264, 12889, 1790, 830, 321, 393, 519, 295, 366, 51856], "temperature": 0.0, "avg_logprob": -0.07485572497049968, "compression_ratio": 1.8449612403100775, "no_speech_prob": 0.029729345813393593}, {"id": 556, "seek": 313176, "start": 3131.76, "end": 3138.0, "text": " let's say translation invariance in a cnn you can also extend this to rotational invariance and so", "tokens": [50364, 718, 311, 584, 12853, 33270, 719, 294, 257, 269, 26384, 291, 393, 611, 10101, 341, 281, 45420, 33270, 719, 293, 370, 50676], "temperature": 0.0, "avg_logprob": -0.06282914582119194, "compression_ratio": 1.8708133971291867, "no_speech_prob": 0.0027201292105019093}, {"id": 557, "seek": 313176, "start": 3138.0, "end": 3145.2000000000003, "text": " but if we look at a true practical problem we say yes it makes sense that there is a rotational", "tokens": [50676, 457, 498, 321, 574, 412, 257, 2074, 8496, 1154, 321, 584, 2086, 309, 1669, 2020, 300, 456, 307, 257, 45420, 51036], "temperature": 0.0, "avg_logprob": -0.06282914582119194, "compression_ratio": 1.8708133971291867, "no_speech_prob": 0.0027201292105019093}, {"id": 558, "seek": 313176, "start": 3145.2000000000003, "end": 3152.96, "text": " invariance in the world however on the image net dataset like for a real practical problem the sky", "tokens": [51036, 33270, 719, 294, 264, 1002, 4461, 322, 264, 3256, 2533, 28872, 411, 337, 257, 957, 8496, 1154, 264, 5443, 51424], "temperature": 0.0, "avg_logprob": -0.06282914582119194, "compression_ratio": 1.8708133971291867, "no_speech_prob": 0.0027201292105019093}, {"id": 559, "seek": 313176, "start": 3152.96, "end": 3159.2000000000003, "text": " is usually up and the object is usually in the center it's not like to the side it's it's usually", "tokens": [51424, 307, 2673, 493, 293, 264, 2657, 307, 2673, 294, 264, 3056, 309, 311, 406, 411, 281, 264, 1252, 309, 311, 309, 311, 2673, 51736], "temperature": 0.0, "avg_logprob": -0.06282914582119194, "compression_ratio": 1.8708133971291867, "no_speech_prob": 0.0027201292105019093}, {"id": 560, "seek": 315920, "start": 3159.2, "end": 3166.96, "text": " in the center so in a way it seems like if we actually hit the true invariance that the world", "tokens": [50364, 294, 264, 3056, 370, 294, 257, 636, 309, 2544, 411, 498, 321, 767, 2045, 264, 2074, 33270, 719, 300, 264, 1002, 50752], "temperature": 0.0, "avg_logprob": -0.04722052748485278, "compression_ratio": 1.7699530516431925, "no_speech_prob": 0.00570082338526845}, {"id": 561, "seek": 315920, "start": 3167.52, "end": 3174.3999999999996, "text": " adheres to it's certainly beneficial but if we even slightly deviate if we build in a different", "tokens": [50780, 614, 19464, 281, 309, 311, 3297, 14072, 457, 498, 321, 754, 4748, 1905, 13024, 498, 321, 1322, 294, 257, 819, 51124], "temperature": 0.0, "avg_logprob": -0.04722052748485278, "compression_ratio": 1.7699530516431925, "no_speech_prob": 0.00570082338526845}, {"id": 562, "seek": 315920, "start": 3174.3999999999996, "end": 3180.48, "text": " invariance it seems like there is a level of accuracy and if we want to get past that these", "tokens": [51124, 33270, 719, 309, 2544, 411, 456, 307, 257, 1496, 295, 14170, 293, 498, 321, 528, 281, 483, 1791, 300, 613, 51428], "temperature": 0.0, "avg_logprob": -0.04722052748485278, "compression_ratio": 1.7699530516431925, "no_speech_prob": 0.00570082338526845}, {"id": 563, "seek": 315920, "start": 3180.48, "end": 3186.3999999999996, "text": " invariance seems to be hurting do you have a sense of can it be counterproductive or when is it", "tokens": [51428, 33270, 719, 2544, 281, 312, 17744, 360, 291, 362, 257, 2020, 295, 393, 309, 312, 5682, 14314, 20221, 420, 562, 307, 309, 51724], "temperature": 0.0, "avg_logprob": -0.04722052748485278, "compression_ratio": 1.7699530516431925, "no_speech_prob": 0.00570082338526845}, {"id": 564, "seek": 318640, "start": 3186.4, "end": 3192.8, "text": " counterproductive to build in such invariances it's a very good question and so this goes to the", "tokens": [50364, 5682, 14314, 20221, 281, 1322, 294, 1270, 33270, 2676, 309, 311, 257, 588, 665, 1168, 293, 370, 341, 1709, 281, 264, 50684], "temperature": 0.0, "avg_logprob": -0.06486973232693143, "compression_ratio": 1.760180995475113, "no_speech_prob": 0.0023579506669193506}, {"id": 565, "seek": 318640, "start": 3192.8, "end": 3199.76, "text": " point of the bias variance decomposition again so if you hit the right bias then it can be beneficial", "tokens": [50684, 935, 295, 264, 12577, 21977, 48356, 797, 370, 498, 291, 2045, 264, 558, 12577, 550, 309, 393, 312, 14072, 51032], "temperature": 0.0, "avg_logprob": -0.06486973232693143, "compression_ratio": 1.760180995475113, "no_speech_prob": 0.0023579506669193506}, {"id": 566, "seek": 318640, "start": 3200.48, "end": 3206.1600000000003, "text": " if you you know impose the wrong bias then it's going to hurt you and this is a well-known trade", "tokens": [51068, 498, 291, 291, 458, 26952, 264, 2085, 12577, 550, 309, 311, 516, 281, 4607, 291, 293, 341, 307, 257, 731, 12, 6861, 4923, 51352], "temperature": 0.0, "avg_logprob": -0.06486973232693143, "compression_ratio": 1.760180995475113, "no_speech_prob": 0.0023579506669193506}, {"id": 567, "seek": 318640, "start": 3206.1600000000003, "end": 3212.48, "text": " off so of course the whole endeavor of machine earning is defining the right inductive biases", "tokens": [51352, 766, 370, 295, 1164, 264, 1379, 34975, 295, 3479, 12353, 307, 17827, 264, 558, 31612, 488, 32152, 51668], "temperature": 0.0, "avg_logprob": -0.06486973232693143, "compression_ratio": 1.760180995475113, "no_speech_prob": 0.0023579506669193506}, {"id": 568, "seek": 321248, "start": 3213.28, "end": 3219.76, "text": " and leaving whatever you don't know to the data and then basically learning to focus your models", "tokens": [50404, 293, 5012, 2035, 291, 500, 380, 458, 281, 264, 1412, 293, 550, 1936, 2539, 281, 1879, 428, 5245, 50728], "temperature": 0.0, "avg_logprob": -0.06713275695114992, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.009555378928780556}, {"id": 569, "seek": 321248, "start": 3219.76, "end": 3224.56, "text": " on the data that you're actually seeing but I agree if you put the wrong inductive bias in it", "tokens": [50728, 322, 264, 1412, 300, 291, 434, 767, 2577, 457, 286, 3986, 498, 291, 829, 264, 2085, 31612, 488, 12577, 294, 309, 50968], "temperature": 0.0, "avg_logprob": -0.06713275695114992, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.009555378928780556}, {"id": 570, "seek": 321248, "start": 3224.56, "end": 3231.84, "text": " things will be things can actually deteriorate now I should say here that for the rotation", "tokens": [50968, 721, 486, 312, 721, 393, 767, 26431, 473, 586, 286, 820, 584, 510, 300, 337, 264, 12447, 51332], "temperature": 0.0, "avg_logprob": -0.06713275695114992, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.009555378928780556}, {"id": 571, "seek": 321248, "start": 3231.84, "end": 3236.56, "text": " invariance or equivariance things are not as bad as you might think so you said if you just have", "tokens": [51332, 33270, 719, 420, 1267, 592, 3504, 719, 721, 366, 406, 382, 1578, 382, 291, 1062, 519, 370, 291, 848, 498, 291, 445, 362, 51568], "temperature": 0.0, "avg_logprob": -0.06713275695114992, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.009555378928780556}, {"id": 572, "seek": 323656, "start": 3236.56, "end": 3243.12, "text": " slightly wrong inductive bias then it hurts but that happens to be not so much the case because", "tokens": [50364, 4748, 2085, 31612, 488, 12577, 550, 309, 11051, 457, 300, 2314, 281, 312, 406, 370, 709, 264, 1389, 570, 50692], "temperature": 0.0, "avg_logprob": -0.03901847926053134, "compression_ratio": 1.6738197424892705, "no_speech_prob": 0.009262675419449806}, {"id": 573, "seek": 323656, "start": 3243.12, "end": 3250.7999999999997, "text": " there's objects inside images that do have if you turn a cat upside down or a tree upside down we", "tokens": [50692, 456, 311, 6565, 1854, 5267, 300, 360, 362, 498, 291, 1261, 257, 3857, 14119, 760, 420, 257, 4230, 14119, 760, 321, 51076], "temperature": 0.0, "avg_logprob": -0.03901847926053134, "compression_ratio": 1.6738197424892705, "no_speech_prob": 0.009262675419449806}, {"id": 574, "seek": 323656, "start": 3250.7999999999997, "end": 3256.56, "text": " still recognize it as a tree in some sense and it does give you a sort of robustness to to certain", "tokens": [51076, 920, 5521, 309, 382, 257, 4230, 294, 512, 2020, 293, 309, 775, 976, 291, 257, 1333, 295, 13956, 1287, 281, 281, 1629, 51364], "temperature": 0.0, "avg_logprob": -0.03901847926053134, "compression_ratio": 1.6738197424892705, "no_speech_prob": 0.009262675419449806}, {"id": 575, "seek": 323656, "start": 3256.56, "end": 3261.92, "text": " transformations on these objects that you would otherwise maybe try to model by data augmentation", "tokens": [51364, 34852, 322, 613, 6565, 300, 291, 576, 5911, 1310, 853, 281, 2316, 538, 1412, 14501, 19631, 51632], "temperature": 0.0, "avg_logprob": -0.03901847926053134, "compression_ratio": 1.6738197424892705, "no_speech_prob": 0.009262675419449806}, {"id": 576, "seek": 326192, "start": 3262.0, "end": 3267.76, "text": " and stuff like that now for the sky maybe you're right that similarly in the digits a six and a", "tokens": [50368, 293, 1507, 411, 300, 586, 337, 264, 5443, 1310, 291, 434, 558, 300, 14138, 294, 264, 27011, 257, 2309, 293, 257, 50656], "temperature": 0.0, "avg_logprob": -0.10401857340777362, "compression_ratio": 1.8968253968253967, "no_speech_prob": 0.03356165066361427}, {"id": 577, "seek": 326192, "start": 3267.76, "end": 3273.04, "text": " nine you know you will start to confuse a six and a nine if you build in rotation and equivariance", "tokens": [50656, 4949, 291, 458, 291, 486, 722, 281, 28584, 257, 2309, 293, 257, 4949, 498, 291, 1322, 294, 12447, 293, 1267, 592, 3504, 719, 50920], "temperature": 0.0, "avg_logprob": -0.10401857340777362, "compression_ratio": 1.8968253968253967, "no_speech_prob": 0.03356165066361427}, {"id": 578, "seek": 326192, "start": 3273.04, "end": 3277.6800000000003, "text": " right and so there it will actually hurt but it's been surprisingly robust actually because", "tokens": [50920, 558, 293, 370, 456, 309, 486, 767, 4607, 457, 309, 311, 668, 17600, 13956, 767, 570, 51152], "temperature": 0.0, "avg_logprob": -0.10401857340777362, "compression_ratio": 1.8968253968253967, "no_speech_prob": 0.03356165066361427}, {"id": 579, "seek": 326192, "start": 3277.6800000000003, "end": 3281.92, "text": " basically because you also cut down on a number of parameters and by cutting down on the number of", "tokens": [51152, 1936, 570, 291, 611, 1723, 760, 322, 257, 1230, 295, 9834, 293, 538, 6492, 760, 322, 264, 1230, 295, 51364], "temperature": 0.0, "avg_logprob": -0.10401857340777362, "compression_ratio": 1.8968253968253967, "no_speech_prob": 0.03356165066361427}, {"id": 580, "seek": 326192, "start": 3281.92, "end": 3288.48, "text": " parameters you will you can actually help the system generalize better so the inductive bias", "tokens": [51364, 9834, 291, 486, 291, 393, 767, 854, 264, 1185, 2674, 1125, 1101, 370, 264, 31612, 488, 12577, 51692], "temperature": 0.0, "avg_logprob": -0.10401857340777362, "compression_ratio": 1.8968253968253967, "no_speech_prob": 0.03356165066361427}, {"id": 581, "seek": 328848, "start": 3288.48, "end": 3293.76, "text": " doesn't have to be perfect and it can still help could we touch on the dichotomy between the work", "tokens": [50364, 1177, 380, 362, 281, 312, 2176, 293, 309, 393, 920, 854, 727, 321, 2557, 322, 264, 10390, 310, 8488, 1296, 264, 589, 50628], "temperature": 0.0, "avg_logprob": -0.048677233962325366, "compression_ratio": 1.830258302583026, "no_speech_prob": 0.0057028718292713165}, {"id": 582, "seek": 328848, "start": 3293.76, "end": 3298.4, "text": " you've done and capsule networks for example as well as the sample efficiency thing for example", "tokens": [50628, 291, 600, 1096, 293, 29247, 9590, 337, 1365, 382, 731, 382, 264, 6889, 10493, 551, 337, 1365, 50860], "temperature": 0.0, "avg_logprob": -0.048677233962325366, "compression_ratio": 1.830258302583026, "no_speech_prob": 0.0057028718292713165}, {"id": 583, "seek": 328848, "start": 3298.4, "end": 3304.72, "text": " with translational equivariance it means that you can you can move the dog and then the response map", "tokens": [50860, 365, 5105, 1478, 1267, 592, 3504, 719, 309, 1355, 300, 291, 393, 291, 393, 1286, 264, 3000, 293, 550, 264, 4134, 4471, 51176], "temperature": 0.0, "avg_logprob": -0.048677233962325366, "compression_ratio": 1.830258302583026, "no_speech_prob": 0.0057028718292713165}, {"id": 584, "seek": 328848, "start": 3304.72, "end": 3308.64, "text": " the dog has moved as well and much of that is about allowing neural networks to learn patterns more", "tokens": [51176, 264, 3000, 575, 4259, 382, 731, 293, 709, 295, 300, 307, 466, 8293, 18161, 9590, 281, 1466, 8294, 544, 51372], "temperature": 0.0, "avg_logprob": -0.048677233962325366, "compression_ratio": 1.830258302583026, "no_speech_prob": 0.0057028718292713165}, {"id": 585, "seek": 328848, "start": 3308.64, "end": 3313.76, "text": " easily because they can map in every single layer so with capsule networks that's still a blank slate", "tokens": [51372, 3612, 570, 436, 393, 4471, 294, 633, 2167, 4583, 370, 365, 29247, 9590, 300, 311, 920, 257, 8247, 39118, 51628], "temperature": 0.0, "avg_logprob": -0.048677233962325366, "compression_ratio": 1.830258302583026, "no_speech_prob": 0.0057028718292713165}, {"id": 586, "seek": 331376, "start": 3313.84, "end": 3316.6400000000003, "text": " philosophy so you don't explicitly say what the capsules are", "tokens": [50368, 10675, 370, 291, 500, 380, 20803, 584, 437, 264, 13855, 3473, 366, 50508], "temperature": 0.0, "avg_logprob": -0.055632324669304796, "compression_ratio": 1.8417508417508417, "no_speech_prob": 0.07005193084478378}, {"id": 587, "seek": 331376, "start": 3317.36, "end": 3322.4, "text": " whereas with with your approaches you explicitly define the priors with capsules it seems to be", "tokens": [50544, 9735, 365, 365, 428, 11587, 291, 20803, 6964, 264, 1790, 830, 365, 13855, 3473, 309, 2544, 281, 312, 50796], "temperature": 0.0, "avg_logprob": -0.055632324669304796, "compression_ratio": 1.8417508417508417, "no_speech_prob": 0.07005193084478378}, {"id": 588, "seek": 331376, "start": 3322.4, "end": 3327.84, "text": " defined by the data you give it so if you train a capsule network on MNIST data it might inadvertently", "tokens": [50796, 7642, 538, 264, 1412, 291, 976, 309, 370, 498, 291, 3847, 257, 29247, 3209, 322, 376, 45, 19756, 1412, 309, 1062, 49152, 2276, 51068], "temperature": 0.0, "avg_logprob": -0.055632324669304796, "compression_ratio": 1.8417508417508417, "no_speech_prob": 0.07005193084478378}, {"id": 589, "seek": 331376, "start": 3327.84, "end": 3332.5600000000004, "text": " learn that one of the capsules is how bendy the stroke width is on the seven or it might learn", "tokens": [51068, 1466, 300, 472, 295, 264, 13855, 3473, 307, 577, 11229, 88, 264, 12403, 11402, 307, 322, 264, 3407, 420, 309, 1062, 1466, 51304], "temperature": 0.0, "avg_logprob": -0.055632324669304796, "compression_ratio": 1.8417508417508417, "no_speech_prob": 0.07005193084478378}, {"id": 590, "seek": 331376, "start": 3332.5600000000004, "end": 3337.76, "text": " that there's a rotation on the car because you've given it lots of rotated versions of the same car", "tokens": [51304, 300, 456, 311, 257, 12447, 322, 264, 1032, 570, 291, 600, 2212, 309, 3195, 295, 42146, 9606, 295, 264, 912, 1032, 51564], "temperature": 0.0, "avg_logprob": -0.055632324669304796, "compression_ratio": 1.8417508417508417, "no_speech_prob": 0.07005193084478378}, {"id": 591, "seek": 331376, "start": 3337.76, "end": 3342.6400000000003, "text": " but it seems quite arbitrary and the algorithm is hideously inefficient and what's much more", "tokens": [51564, 457, 309, 2544, 1596, 23211, 293, 264, 9284, 307, 6479, 5098, 43495, 293, 437, 311, 709, 544, 51808], "temperature": 0.0, "avg_logprob": -0.055632324669304796, "compression_ratio": 1.8417508417508417, "no_speech_prob": 0.07005193084478378}, {"id": 592, "seek": 334264, "start": 3342.64, "end": 3348.08, "text": " exciting to me is the kind of baked-in priors that you've designed in the encoder stage so could", "tokens": [50364, 4670, 281, 385, 307, 264, 733, 295, 19453, 12, 259, 1790, 830, 300, 291, 600, 4761, 294, 264, 2058, 19866, 3233, 370, 727, 50636], "temperature": 0.0, "avg_logprob": -0.07048036835410378, "compression_ratio": 1.672340425531915, "no_speech_prob": 0.001776733435690403}, {"id": 593, "seek": 334264, "start": 3348.08, "end": 3353.04, "text": " you draw the dots up between those two approaches yeah i think you actually you said it quite right", "tokens": [50636, 291, 2642, 264, 15026, 493, 1296, 729, 732, 11587, 1338, 741, 519, 291, 767, 291, 848, 309, 1596, 558, 50884], "temperature": 0.0, "avg_logprob": -0.07048036835410378, "compression_ratio": 1.672340425531915, "no_speech_prob": 0.001776733435690403}, {"id": 594, "seek": 334264, "start": 3353.04, "end": 3358.8799999999997, "text": " so one is a much more constrained system than the other one but the actual representations that we", "tokens": [50884, 370, 472, 307, 257, 709, 544, 38901, 1185, 813, 264, 661, 472, 457, 264, 3539, 33358, 300, 321, 51176], "temperature": 0.0, "avg_logprob": -0.07048036835410378, "compression_ratio": 1.672340425531915, "no_speech_prob": 0.001776733435690403}, {"id": 595, "seek": 334264, "start": 3358.8799999999997, "end": 3366.96, "text": " put in our hidden layers in both cases are very similar they are stacks vectors and these vectors", "tokens": [51176, 829, 294, 527, 7633, 7914, 294, 1293, 3331, 366, 588, 2531, 436, 366, 30792, 18875, 293, 613, 18875, 51580], "temperature": 0.0, "avg_logprob": -0.07048036835410378, "compression_ratio": 1.672340425531915, "no_speech_prob": 0.001776733435690403}, {"id": 596, "seek": 336696, "start": 3366.96, "end": 3373.52, "text": " transform under certain operations so if i rotate the input then there is some operation on this", "tokens": [50364, 4088, 833, 1629, 7705, 370, 498, 741, 13121, 264, 4846, 550, 456, 307, 512, 6916, 322, 341, 50692], "temperature": 0.0, "avg_logprob": -0.0738725030278585, "compression_ratio": 1.8780487804878048, "no_speech_prob": 0.034588102251291275}, {"id": 597, "seek": 336696, "start": 3373.52, "end": 3380.16, "text": " stack of vectors which is they do rotate in the x y plane but they also permute in the sort of", "tokens": [50692, 8630, 295, 18875, 597, 307, 436, 360, 13121, 294, 264, 2031, 288, 5720, 457, 436, 611, 4784, 1169, 294, 264, 1333, 295, 51024], "temperature": 0.0, "avg_logprob": -0.0738725030278585, "compression_ratio": 1.8780487804878048, "no_speech_prob": 0.034588102251291275}, {"id": 598, "seek": 336696, "start": 3380.16, "end": 3386.88, "text": " vector dimension and so that we tell it very explicitly how to transform we just say under", "tokens": [51024, 8062, 10139, 293, 370, 300, 321, 980, 309, 588, 20803, 577, 281, 4088, 321, 445, 584, 833, 51360], "temperature": 0.0, "avg_logprob": -0.0738725030278585, "compression_ratio": 1.8780487804878048, "no_speech_prob": 0.034588102251291275}, {"id": 599, "seek": 336696, "start": 3386.88, "end": 3391.92, "text": " these transformations you have to transform like this and we can do this because these these geometric", "tokens": [51360, 613, 34852, 291, 362, 281, 4088, 411, 341, 293, 321, 393, 360, 341, 570, 613, 613, 33246, 51612], "temperature": 0.0, "avg_logprob": -0.0738725030278585, "compression_ratio": 1.8780487804878048, "no_speech_prob": 0.034588102251291275}, {"id": 600, "seek": 339192, "start": 3392.56, "end": 3398.32, "text": " transformations we know them that they appear in the real world but so it's also constraining", "tokens": [50396, 34852, 321, 458, 552, 300, 436, 4204, 294, 264, 957, 1002, 457, 370, 309, 311, 611, 11525, 1760, 50684], "temperature": 0.0, "avg_logprob": -0.05843600104836857, "compression_ratio": 1.94331983805668, "no_speech_prob": 0.05101199820637703}, {"id": 601, "seek": 339192, "start": 3398.32, "end": 3403.52, "text": " because there is many other transformations that either we don't know precisely what the", "tokens": [50684, 570, 456, 307, 867, 661, 34852, 300, 2139, 321, 500, 380, 458, 13402, 437, 264, 50944], "temperature": 0.0, "avg_logprob": -0.05843600104836857, "compression_ratio": 1.94331983805668, "no_speech_prob": 0.05101199820637703}, {"id": 602, "seek": 339192, "start": 3403.52, "end": 3410.64, "text": " mathematics for the representations looks like or for instance like groups that are that are not", "tokens": [50944, 18666, 337, 264, 33358, 1542, 411, 420, 337, 5197, 411, 3935, 300, 366, 300, 366, 406, 51300], "temperature": 0.0, "avg_logprob": -0.05843600104836857, "compression_ratio": 1.94331983805668, "no_speech_prob": 0.05101199820637703}, {"id": 603, "seek": 339192, "start": 3410.64, "end": 3415.44, "text": " compact maybe maybe we have looked at scaling but it's already a more of a stretch but there's of", "tokens": [51300, 14679, 1310, 1310, 321, 362, 2956, 412, 21589, 457, 309, 311, 1217, 257, 544, 295, 257, 5985, 457, 456, 311, 295, 51540], "temperature": 0.0, "avg_logprob": -0.05843600104836857, "compression_ratio": 1.94331983805668, "no_speech_prob": 0.05101199820637703}, {"id": 604, "seek": 339192, "start": 3415.44, "end": 3420.2400000000002, "text": " course you can do many other types of transformations that don't even have to be groups there could be", "tokens": [51540, 1164, 291, 393, 360, 867, 661, 3467, 295, 34852, 300, 500, 380, 754, 362, 281, 312, 3935, 456, 727, 312, 51780], "temperature": 0.0, "avg_logprob": -0.05843600104836857, "compression_ratio": 1.94331983805668, "no_speech_prob": 0.05101199820637703}, {"id": 605, "seek": 342024, "start": 3420.24, "end": 3425.8399999999997, "text": " other types of transformations like lighting changes or whatever if you wanted to incorporate", "tokens": [50364, 661, 3467, 295, 34852, 411, 9577, 2962, 420, 2035, 498, 291, 1415, 281, 16091, 50644], "temperature": 0.0, "avg_logprob": -0.051139697432518005, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.005299355834722519}, {"id": 606, "seek": 342024, "start": 3425.8399999999997, "end": 3430.16, "text": " all of these you would have to build the mathematical representation theory for each of them and then", "tokens": [50644, 439, 295, 613, 291, 576, 362, 281, 1322, 264, 18894, 10290, 5261, 337, 1184, 295, 552, 293, 550, 50860], "temperature": 0.0, "avg_logprob": -0.051139697432518005, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.005299355834722519}, {"id": 607, "seek": 342024, "start": 3430.16, "end": 3434.3199999999997, "text": " it would actually also explode in a number of feature maps that you would have to maintain", "tokens": [50860, 309, 576, 767, 611, 21411, 294, 257, 1230, 295, 4111, 11317, 300, 291, 576, 362, 281, 6909, 51068], "temperature": 0.0, "avg_logprob": -0.051139697432518005, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.005299355834722519}, {"id": 608, "seek": 342024, "start": 3434.3199999999997, "end": 3440.08, "text": " and it's not a very practical approach so this works up to the transformation groups that we", "tokens": [51068, 293, 309, 311, 406, 257, 588, 8496, 3109, 370, 341, 1985, 493, 281, 264, 9887, 3935, 300, 321, 51356], "temperature": 0.0, "avg_logprob": -0.051139697432518005, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.005299355834722519}, {"id": 609, "seek": 342024, "start": 3440.08, "end": 3445.04, "text": " understand and that are everywhere around us if we want to go beyond it then basically something", "tokens": [51356, 1223, 293, 300, 366, 5315, 926, 505, 498, 321, 528, 281, 352, 4399, 309, 550, 1936, 746, 51604], "temperature": 0.0, "avg_logprob": -0.051139697432518005, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.005299355834722519}, {"id": 610, "seek": 344504, "start": 3445.04, "end": 3450.64, "text": " like capsules are very nice because they tell you well we'll just keep the abstract nature", "tokens": [50364, 411, 13855, 3473, 366, 588, 1481, 570, 436, 980, 291, 731, 321, 603, 445, 1066, 264, 12649, 3687, 50644], "temperature": 0.0, "avg_logprob": -0.05158040102790384, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.132793128490448}, {"id": 611, "seek": 344504, "start": 3450.64, "end": 3457.04, "text": " of what we want which is some stack of things that transform in some way that we can vaguely", "tokens": [50644, 295, 437, 321, 528, 597, 307, 512, 8630, 295, 721, 300, 4088, 294, 512, 636, 300, 321, 393, 13501, 48863, 50964], "temperature": 0.0, "avg_logprob": -0.05158040102790384, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.132793128490448}, {"id": 612, "seek": 344504, "start": 3457.04, "end": 3462.72, "text": " specify and then we ask it to learn all these things and we are actually ourselves also looking", "tokens": [50964, 16500, 293, 550, 321, 1029, 309, 281, 1466, 439, 613, 721, 293, 321, 366, 767, 4175, 611, 1237, 51248], "temperature": 0.0, "avg_logprob": -0.05158040102790384, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.132793128490448}, {"id": 613, "seek": 344504, "start": 3462.72, "end": 3468.16, "text": " at these sort of more relaxed notions of equivariance where we don't tell the system precisely", "tokens": [51248, 412, 613, 1333, 295, 544, 14628, 35799, 295, 48726, 3504, 719, 689, 321, 500, 380, 980, 264, 1185, 13402, 51520], "temperature": 0.0, "avg_logprob": -0.05158040102790384, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.132793128490448}, {"id": 614, "seek": 344504, "start": 3468.16, "end": 3472.96, "text": " how to change we just want this to emerge automatically and again here the connection", "tokens": [51520, 577, 281, 1319, 321, 445, 528, 341, 281, 21511, 6772, 293, 797, 510, 264, 4984, 51760], "temperature": 0.0, "avg_logprob": -0.05158040102790384, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.132793128490448}, {"id": 615, "seek": 347296, "start": 3472.96, "end": 3479.04, "text": " with the brain is very interesting in the brain we do seem to have all sorts of filters which are", "tokens": [50364, 365, 264, 3567, 307, 588, 1880, 294, 264, 3567, 321, 360, 1643, 281, 362, 439, 7527, 295, 15995, 597, 366, 50668], "temperature": 0.0, "avg_logprob": -0.05731787131382869, "compression_ratio": 1.8937007874015748, "no_speech_prob": 0.022591648623347282}, {"id": 616, "seek": 347296, "start": 3479.04, "end": 3484.64, "text": " related by not only by rotations but all sorts of other transformations and they are topographically", "tokens": [50668, 4077, 538, 406, 787, 538, 44796, 457, 439, 7527, 295, 661, 34852, 293, 436, 366, 1192, 3108, 984, 50948], "temperature": 0.0, "avg_logprob": -0.05731787131382869, "compression_ratio": 1.8937007874015748, "no_speech_prob": 0.022591648623347282}, {"id": 617, "seek": 347296, "start": 3484.64, "end": 3490.64, "text": " organized so they are right the ones that are related like a slightly rotated version is sitting", "tokens": [50948, 9983, 370, 436, 366, 558, 264, 2306, 300, 366, 4077, 411, 257, 4748, 42146, 3037, 307, 3798, 51248], "temperature": 0.0, "avg_logprob": -0.05731787131382869, "compression_ratio": 1.8937007874015748, "no_speech_prob": 0.022591648623347282}, {"id": 618, "seek": 347296, "start": 3490.64, "end": 3497.2, "text": " right next to the other one in your brain and so presumably your brain have figured this out by", "tokens": [51248, 558, 958, 281, 264, 661, 472, 294, 428, 3567, 293, 370, 26742, 428, 3567, 362, 8932, 341, 484, 538, 51576], "temperature": 0.0, "avg_logprob": -0.05731787131382869, "compression_ratio": 1.8937007874015748, "no_speech_prob": 0.022591648623347282}, {"id": 619, "seek": 347296, "start": 3497.2, "end": 3501.68, "text": " just looking into the world for a long time and it's organized all these filters that way", "tokens": [51576, 445, 1237, 666, 264, 1002, 337, 257, 938, 565, 293, 309, 311, 9983, 439, 613, 15995, 300, 636, 51800], "temperature": 0.0, "avg_logprob": -0.05731787131382869, "compression_ratio": 1.8937007874015748, "no_speech_prob": 0.022591648623347282}, {"id": 620, "seek": 350168, "start": 3502.3199999999997, "end": 3508.16, "text": " and it's known that if you prevent let's say a cat from seeing then it will not come up with", "tokens": [50396, 293, 309, 311, 2570, 300, 498, 291, 4871, 718, 311, 584, 257, 3857, 490, 2577, 550, 309, 486, 406, 808, 493, 365, 50688], "temperature": 0.0, "avg_logprob": -0.060435376725755295, "compression_ratio": 1.7381818181818183, "no_speech_prob": 0.002469846047461033}, {"id": 621, "seek": 350168, "start": 3508.16, "end": 3513.3599999999997, "text": " this nice organization so you really have to get that by looking into the world a lot and that's", "tokens": [50688, 341, 1481, 4475, 370, 291, 534, 362, 281, 483, 300, 538, 1237, 666, 264, 1002, 257, 688, 293, 300, 311, 50948], "temperature": 0.0, "avg_logprob": -0.060435376725755295, "compression_ratio": 1.7381818181818183, "no_speech_prob": 0.002469846047461033}, {"id": 622, "seek": 350168, "start": 3513.3599999999997, "end": 3518.48, "text": " super fascinating and I think that's where some of our research is being directed now can we learn", "tokens": [50948, 1687, 10343, 293, 286, 519, 300, 311, 689, 512, 295, 527, 2132, 307, 885, 12898, 586, 393, 321, 1466, 51204], "temperature": 0.0, "avg_logprob": -0.060435376725755295, "compression_ratio": 1.7381818181818183, "no_speech_prob": 0.002469846047461033}, {"id": 623, "seek": 350168, "start": 3518.48, "end": 3522.8799999999997, "text": " from how this happens in the brain is there a connection between these topographic maps and", "tokens": [51204, 490, 577, 341, 2314, 294, 264, 3567, 307, 456, 257, 4984, 1296, 613, 1192, 12295, 11317, 293, 51424], "temperature": 0.0, "avg_logprob": -0.060435376725755295, "compression_ratio": 1.7381818181818183, "no_speech_prob": 0.002469846047461033}, {"id": 624, "seek": 350168, "start": 3522.8799999999997, "end": 3528.7999999999997, "text": " equivariance somehow and between capsules and all of these things and I believe that it is a good", "tokens": [51424, 48726, 3504, 719, 6063, 293, 1296, 13855, 3473, 293, 439, 295, 613, 721, 293, 286, 1697, 300, 309, 307, 257, 665, 51720], "temperature": 0.0, "avg_logprob": -0.060435376725755295, "compression_ratio": 1.7381818181818183, "no_speech_prob": 0.002469846047461033}, {"id": 625, "seek": 352880, "start": 3528.88, "end": 3534.88, "text": " strategy to to take the general ideas equivariance and then slowly relax it and let the system learn", "tokens": [50368, 5206, 281, 281, 747, 264, 2674, 3487, 48726, 3504, 719, 293, 550, 5692, 5789, 309, 293, 718, 264, 1185, 1466, 50668], "temperature": 0.0, "avg_logprob": -0.05176613065931532, "compression_ratio": 1.7456140350877194, "no_speech_prob": 0.003319256007671356}, {"id": 626, "seek": 352880, "start": 3534.88, "end": 3543.28, "text": " more and more so these capsule networks they've been a bit hyped when they were not really developed", "tokens": [50668, 544, 293, 544, 370, 613, 29247, 9590, 436, 600, 668, 257, 857, 43172, 562, 436, 645, 406, 534, 4743, 51088], "temperature": 0.0, "avg_logprob": -0.05176613065931532, "compression_ratio": 1.7456140350877194, "no_speech_prob": 0.003319256007671356}, {"id": 627, "seek": 352880, "start": 3543.28, "end": 3551.44, "text": " named first by Jeff Hinton and he has this concept or at least had it at the beginning that it's some", "tokens": [51088, 4926, 700, 538, 7506, 389, 12442, 293, 415, 575, 341, 3410, 420, 412, 1935, 632, 309, 412, 264, 2863, 300, 309, 311, 512, 51496], "temperature": 0.0, "avg_logprob": -0.05176613065931532, "compression_ratio": 1.7456140350877194, "no_speech_prob": 0.003319256007671356}, {"id": 628, "seek": 352880, "start": 3551.44, "end": 3558.0800000000004, "text": " sort of like an inverse rendering pipeline so the sort of the capsule networks do some sort of", "tokens": [51496, 1333, 295, 411, 364, 17340, 22407, 15517, 370, 264, 1333, 295, 264, 29247, 9590, 360, 512, 1333, 295, 51828], "temperature": 0.0, "avg_logprob": -0.05176613065931532, "compression_ratio": 1.7456140350877194, "no_speech_prob": 0.003319256007671356}, {"id": 629, "seek": 355808, "start": 3558.16, "end": 3565.2, "text": " they take in the world and they inverse render it into these capsules how much do you agree with", "tokens": [50368, 436, 747, 294, 264, 1002, 293, 436, 17340, 15529, 309, 666, 613, 13855, 3473, 577, 709, 360, 291, 3986, 365, 50720], "temperature": 0.0, "avg_logprob": -0.056746624611519476, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.0008151308284141123}, {"id": 630, "seek": 355808, "start": 3565.2, "end": 3570.0, "text": " that type of formulation it seems what you've described is more of a forward way of looking at", "tokens": [50720, 300, 2010, 295, 37642, 309, 2544, 437, 291, 600, 7619, 307, 544, 295, 257, 2128, 636, 295, 1237, 412, 50960], "temperature": 0.0, "avg_logprob": -0.056746624611519476, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.0008151308284141123}, {"id": 631, "seek": 355808, "start": 3570.0, "end": 3576.0, "text": " capsules where we have these invariances yeah yeah so I don't I very much agree with this idea that", "tokens": [50960, 13855, 3473, 689, 321, 362, 613, 1048, 10652, 887, 1338, 1338, 370, 286, 500, 380, 286, 588, 709, 3986, 365, 341, 1558, 300, 51260], "temperature": 0.0, "avg_logprob": -0.056746624611519476, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.0008151308284141123}, {"id": 632, "seek": 355808, "start": 3576.0, "end": 3581.36, "text": " you have smaller things and they can be used in multiple ways but you have to align them in a", "tokens": [51260, 291, 362, 4356, 721, 293, 436, 393, 312, 1143, 294, 3866, 2098, 457, 291, 362, 281, 7975, 552, 294, 257, 51528], "temperature": 0.0, "avg_logprob": -0.056746624611519476, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.0008151308284141123}, {"id": 633, "seek": 355808, "start": 3581.36, "end": 3586.7999999999997, "text": " particular way so that they build something at the higher level and obviously you can invert that", "tokens": [51528, 1729, 636, 370, 300, 436, 1322, 746, 412, 264, 2946, 1496, 293, 2745, 291, 393, 33966, 300, 51800], "temperature": 0.0, "avg_logprob": -0.056746624611519476, "compression_ratio": 1.788888888888889, "no_speech_prob": 0.0008151308284141123}, {"id": 634, "seek": 358680, "start": 3586.8, "end": 3593.2000000000003, "text": " idea too in order to start at something very abstract and then generate certain things this way", "tokens": [50364, 1558, 886, 294, 1668, 281, 722, 412, 746, 588, 12649, 293, 550, 8460, 1629, 721, 341, 636, 50684], "temperature": 0.0, "avg_logprob": -0.09934930347260974, "compression_ratio": 1.8207171314741035, "no_speech_prob": 0.005298599600791931}, {"id": 635, "seek": 358680, "start": 3593.92, "end": 3600.96, "text": " and there is a lot of work now actually going into equivariant generative models for instance", "tokens": [50720, 293, 456, 307, 257, 688, 295, 589, 586, 767, 516, 666, 48726, 3504, 394, 1337, 1166, 5245, 337, 5197, 51072], "temperature": 0.0, "avg_logprob": -0.09934930347260974, "compression_ratio": 1.8207171314741035, "no_speech_prob": 0.005298599600791931}, {"id": 636, "seek": 358680, "start": 3600.96, "end": 3605.44, "text": " equivariant flows a prime example is for instance in physics and what's called quantum", "tokens": [51072, 48726, 3504, 394, 12867, 257, 5835, 1365, 307, 337, 5197, 294, 10649, 293, 437, 311, 1219, 13018, 51296], "temperature": 0.0, "avg_logprob": -0.09934930347260974, "compression_ratio": 1.8207171314741035, "no_speech_prob": 0.005298599600791931}, {"id": 637, "seek": 358680, "start": 3605.44, "end": 3609.36, "text": " quorum or dynamics there is there's a theory that has a huge number of symmetries called", "tokens": [51296, 421, 36543, 420, 15679, 456, 307, 456, 311, 257, 5261, 300, 575, 257, 2603, 1230, 295, 14232, 302, 2244, 1219, 51492], "temperature": 0.0, "avg_logprob": -0.09934930347260974, "compression_ratio": 1.8207171314741035, "no_speech_prob": 0.005298599600791931}, {"id": 638, "seek": 358680, "start": 3609.36, "end": 3616.4, "text": " gauge symmetries and if you transform these quarks in a way in a particular way the physics", "tokens": [51492, 17924, 14232, 302, 2244, 293, 498, 291, 4088, 613, 421, 20851, 294, 257, 636, 294, 257, 1729, 636, 264, 10649, 51844], "temperature": 0.0, "avg_logprob": -0.09934930347260974, "compression_ratio": 1.8207171314741035, "no_speech_prob": 0.005298599600791931}, {"id": 639, "seek": 361640, "start": 3616.4, "end": 3620.8, "text": " doesn't change you will have exactly the same observations right but still you need these", "tokens": [50364, 1177, 380, 1319, 291, 486, 362, 2293, 264, 912, 18163, 558, 457, 920, 291, 643, 613, 50584], "temperature": 0.0, "avg_logprob": -0.06088637361432066, "compression_ratio": 1.9126984126984128, "no_speech_prob": 0.004262336064130068}, {"id": 640, "seek": 361640, "start": 3620.8, "end": 3627.04, "text": " all these symmetries to conveniently describe this model and so now when you generate you if you", "tokens": [50584, 439, 613, 14232, 302, 2244, 281, 44375, 6786, 341, 2316, 293, 370, 586, 562, 291, 8460, 291, 498, 291, 50896], "temperature": 0.0, "avg_logprob": -0.06088637361432066, "compression_ratio": 1.9126984126984128, "no_speech_prob": 0.004262336064130068}, {"id": 641, "seek": 361640, "start": 3627.04, "end": 3632.1600000000003, "text": " want to generate quark fields or something like this right then gauge fields then you can generate", "tokens": [50896, 528, 281, 8460, 421, 809, 7909, 420, 746, 411, 341, 558, 550, 17924, 7909, 550, 291, 393, 8460, 51152], "temperature": 0.0, "avg_logprob": -0.06088637361432066, "compression_ratio": 1.9126984126984128, "no_speech_prob": 0.004262336064130068}, {"id": 642, "seek": 361640, "start": 3632.1600000000003, "end": 3636.32, "text": " all these symmetries and it's not very helpful because you generate one configuration but you", "tokens": [51152, 439, 613, 14232, 302, 2244, 293, 309, 311, 406, 588, 4961, 570, 291, 8460, 472, 11694, 457, 291, 51360], "temperature": 0.0, "avg_logprob": -0.06088637361432066, "compression_ratio": 1.9126984126984128, "no_speech_prob": 0.004262336064130068}, {"id": 643, "seek": 361640, "start": 3636.32, "end": 3642.1600000000003, "text": " then if you generate all these sort of equivalent things which are only you know different by symmetry", "tokens": [51360, 550, 498, 291, 8460, 439, 613, 1333, 295, 10344, 721, 597, 366, 787, 291, 458, 819, 538, 25440, 51652], "temperature": 0.0, "avg_logprob": -0.06088637361432066, "compression_ratio": 1.9126984126984128, "no_speech_prob": 0.004262336064130068}, {"id": 644, "seek": 364216, "start": 3642.16, "end": 3645.68, "text": " then you haven't really done much so understanding how to generate with these", "tokens": [50364, 550, 291, 2378, 380, 534, 1096, 709, 370, 3701, 577, 281, 8460, 365, 613, 50540], "temperature": 0.0, "avg_logprob": -0.1463262505001492, "compression_ratio": 1.7121771217712176, "no_speech_prob": 0.11222394555807114}, {"id": 645, "seek": 364216, "start": 3645.68, "end": 3651.2799999999997, "text": " equivalents in it is actually a big topic of research in many groups I think you know Danilo", "tokens": [50540, 9052, 791, 294, 309, 307, 767, 257, 955, 4829, 295, 2132, 294, 867, 3935, 286, 519, 291, 458, 3394, 10720, 50820], "temperature": 0.0, "avg_logprob": -0.1463262505001492, "compression_ratio": 1.7121771217712176, "no_speech_prob": 0.11222394555807114}, {"id": 646, "seek": 364216, "start": 3651.2799999999997, "end": 3656.7999999999997, "text": " Rosenda and this friend in DeepMind has done a lot of work and there's physicists at MIT and who", "tokens": [50820, 11144, 7639, 293, 341, 1277, 294, 14895, 44, 471, 575, 1096, 257, 688, 295, 589, 293, 456, 311, 48716, 412, 13100, 293, 567, 51096], "temperature": 0.0, "avg_logprob": -0.1463262505001492, "compression_ratio": 1.7121771217712176, "no_speech_prob": 0.11222394555807114}, {"id": 647, "seek": 364216, "start": 3656.7999999999997, "end": 3662.3999999999996, "text": " don't work and we are with a group of students and physicists at Amsterdam we're also looking at these", "tokens": [51096, 500, 380, 589, 293, 321, 366, 365, 257, 1594, 295, 1731, 293, 48716, 412, 28291, 321, 434, 611, 1237, 412, 613, 51376], "temperature": 0.0, "avg_logprob": -0.1463262505001492, "compression_ratio": 1.7121771217712176, "no_speech_prob": 0.11222394555807114}, {"id": 648, "seek": 364216, "start": 3662.3999999999996, "end": 3668.72, "text": " types of questions so that's I guess the inverse problem where also equivalents is playing an", "tokens": [51376, 3467, 295, 1651, 370, 300, 311, 286, 2041, 264, 17340, 1154, 689, 611, 9052, 791, 307, 2433, 364, 51692], "temperature": 0.0, "avg_logprob": -0.1463262505001492, "compression_ratio": 1.7121771217712176, "no_speech_prob": 0.11222394555807114}, {"id": 649, "seek": 366872, "start": 3668.72, "end": 3674.3999999999996, "text": " increasingly important role not many people are working on capsules I feel they've fallen", "tokens": [50364, 12980, 1021, 3090, 406, 867, 561, 366, 1364, 322, 13855, 3473, 286, 841, 436, 600, 11547, 50648], "temperature": 0.0, "avg_logprob": -0.0631368706025273, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.01636996492743492}, {"id": 650, "seek": 366872, "start": 3674.3999999999996, "end": 3682.24, "text": " out of the favor of the public because I don't know they're maybe hard to implement or they don't", "tokens": [50648, 484, 295, 264, 2294, 295, 264, 1908, 570, 286, 500, 380, 458, 436, 434, 1310, 1152, 281, 4445, 420, 436, 500, 380, 51040], "temperature": 0.0, "avg_logprob": -0.0631368706025273, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.01636996492743492}, {"id": 651, "seek": 366872, "start": 3682.24, "end": 3688.16, "text": " really work as advertised let's say do you have general thoughts about capsule networks I think", "tokens": [51040, 534, 589, 382, 42310, 718, 311, 584, 360, 291, 362, 2674, 4598, 466, 29247, 9590, 286, 519, 51336], "temperature": 0.0, "avg_logprob": -0.0631368706025273, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.01636996492743492}, {"id": 652, "seek": 366872, "start": 3688.16, "end": 3693.3599999999997, "text": " with many of these things there is an underlying intuition which is correct so I haven't really", "tokens": [51336, 365, 867, 295, 613, 721, 456, 307, 364, 14217, 24002, 597, 307, 3006, 370, 286, 2378, 380, 534, 51596], "temperature": 0.0, "avg_logprob": -0.0631368706025273, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.01636996492743492}, {"id": 653, "seek": 369336, "start": 3693.36, "end": 3699.44, "text": " worked myself in trying to implement them and so what's what you often see in this field is that", "tokens": [50364, 2732, 2059, 294, 1382, 281, 4445, 552, 293, 370, 437, 311, 437, 291, 2049, 536, 294, 341, 2519, 307, 300, 50668], "temperature": 0.0, "avg_logprob": -0.058846068832109556, "compression_ratio": 1.889763779527559, "no_speech_prob": 0.0861571729183197}, {"id": 654, "seek": 369336, "start": 3699.44, "end": 3705.44, "text": " there is an intuition about how something should work and often that's that is the correct intuition", "tokens": [50668, 456, 307, 364, 24002, 466, 577, 746, 820, 589, 293, 2049, 300, 311, 300, 307, 264, 3006, 24002, 50968], "temperature": 0.0, "avg_logprob": -0.058846068832109556, "compression_ratio": 1.889763779527559, "no_speech_prob": 0.0861571729183197}, {"id": 655, "seek": 369336, "start": 3705.44, "end": 3709.04, "text": " especially when it's coming from Jeff Hinton it is very likely to be the correct intuition", "tokens": [50968, 2318, 562, 309, 311, 1348, 490, 7506, 389, 12442, 309, 307, 588, 3700, 281, 312, 264, 3006, 24002, 51148], "temperature": 0.0, "avg_logprob": -0.058846068832109556, "compression_ratio": 1.889763779527559, "no_speech_prob": 0.0861571729183197}, {"id": 656, "seek": 369336, "start": 3709.6, "end": 3714.96, "text": " now then there's the next step which is how do you make something practically implementable", "tokens": [51176, 586, 550, 456, 311, 264, 958, 1823, 597, 307, 577, 360, 291, 652, 746, 15667, 4445, 712, 51444], "temperature": 0.0, "avg_logprob": -0.058846068832109556, "compression_ratio": 1.889763779527559, "no_speech_prob": 0.0861571729183197}, {"id": 657, "seek": 369336, "start": 3714.96, "end": 3719.6, "text": " and these days that means that you have to run it super fast right you have to be able to implement", "tokens": [51444, 293, 613, 1708, 300, 1355, 300, 291, 362, 281, 1190, 309, 1687, 2370, 558, 291, 362, 281, 312, 1075, 281, 4445, 51676], "temperature": 0.0, "avg_logprob": -0.058846068832109556, "compression_ratio": 1.889763779527559, "no_speech_prob": 0.0861571729183197}, {"id": 658, "seek": 371960, "start": 3719.6, "end": 3726.3199999999997, "text": " it in GPUs all these kinds of constraints otherwise you will be so much slower than just an ordinary", "tokens": [50364, 309, 294, 18407, 82, 439, 613, 3685, 295, 18491, 5911, 291, 486, 312, 370, 709, 14009, 813, 445, 364, 10547, 50700], "temperature": 0.0, "avg_logprob": -0.05776651282059519, "compression_ratio": 1.8544061302681993, "no_speech_prob": 0.3803721070289612}, {"id": 659, "seek": 371960, "start": 3726.3199999999997, "end": 3732.16, "text": " cnn and you will basically not be able to train as long as a cnn and you cannot train as many", "tokens": [50700, 269, 26384, 293, 291, 486, 1936, 406, 312, 1075, 281, 3847, 382, 938, 382, 257, 269, 26384, 293, 291, 2644, 3847, 382, 867, 50992], "temperature": 0.0, "avg_logprob": -0.05776651282059519, "compression_ratio": 1.8544061302681993, "no_speech_prob": 0.3803721070289612}, {"id": 660, "seek": 371960, "start": 3732.16, "end": 3736.16, "text": " parameters as an ordinary cnn and you will not beat it and if you don't have the bold numbers", "tokens": [50992, 9834, 382, 364, 10547, 269, 26384, 293, 291, 486, 406, 4224, 309, 293, 498, 291, 500, 380, 362, 264, 11928, 3547, 51192], "temperature": 0.0, "avg_logprob": -0.05776651282059519, "compression_ratio": 1.8544061302681993, "no_speech_prob": 0.3803721070289612}, {"id": 661, "seek": 371960, "start": 3736.72, "end": 3741.6, "text": " hard to publish and so that might impede progress in something like this but then what happens is", "tokens": [51220, 1152, 281, 11374, 293, 370, 300, 1062, 704, 4858, 4205, 294, 746, 411, 341, 457, 550, 437, 2314, 307, 51464], "temperature": 0.0, "avg_logprob": -0.05776651282059519, "compression_ratio": 1.8544061302681993, "no_speech_prob": 0.3803721070289612}, {"id": 662, "seek": 371960, "start": 3741.6, "end": 3746.7999999999997, "text": " you wait and then for five or ten years and then the computers have become faster and then people", "tokens": [51464, 291, 1699, 293, 550, 337, 1732, 420, 2064, 924, 293, 550, 264, 10807, 362, 1813, 4663, 293, 550, 561, 51724], "temperature": 0.0, "avg_logprob": -0.05776651282059519, "compression_ratio": 1.8544061302681993, "no_speech_prob": 0.3803721070289612}, {"id": 663, "seek": 374680, "start": 3746.8, "end": 3750.2400000000002, "text": " go back to these ideas and then they think oh that was actually very interesting let me try again", "tokens": [50364, 352, 646, 281, 613, 3487, 293, 550, 436, 519, 1954, 300, 390, 767, 588, 1880, 718, 385, 853, 797, 50536], "temperature": 0.0, "avg_logprob": -0.07540615246846126, "compression_ratio": 1.8203125, "no_speech_prob": 0.034581322222948074}, {"id": 664, "seek": 374680, "start": 3750.8, "end": 3756.1600000000003, "text": " and then suddenly things start to work now that's of course the story of deep learning", "tokens": [50564, 293, 550, 5800, 721, 722, 281, 589, 586, 300, 311, 295, 1164, 264, 1657, 295, 2452, 2539, 50832], "temperature": 0.0, "avg_logprob": -0.07540615246846126, "compression_ratio": 1.8203125, "no_speech_prob": 0.034581322222948074}, {"id": 665, "seek": 374680, "start": 3756.1600000000003, "end": 3761.28, "text": " more generally speaking right because we had you know neural networks like a long time ago", "tokens": [50832, 544, 5101, 4124, 558, 570, 321, 632, 291, 458, 18161, 9590, 411, 257, 938, 565, 2057, 51088], "temperature": 0.0, "avg_logprob": -0.07540615246846126, "compression_ratio": 1.8203125, "no_speech_prob": 0.034581322222948074}, {"id": 666, "seek": 374680, "start": 3761.92, "end": 3767.92, "text": " right in the 80s it was actually quite popular to work on these things but they didn't quite", "tokens": [51120, 558, 294, 264, 4688, 82, 309, 390, 767, 1596, 3743, 281, 589, 322, 613, 721, 457, 436, 994, 380, 1596, 51420], "temperature": 0.0, "avg_logprob": -0.07540615246846126, "compression_ratio": 1.8203125, "no_speech_prob": 0.034581322222948074}, {"id": 667, "seek": 374680, "start": 3767.92, "end": 3772.8, "text": " take off because we didn't have the compute power and maybe also not the the data to really train", "tokens": [51420, 747, 766, 570, 321, 994, 380, 362, 264, 14722, 1347, 293, 1310, 611, 406, 264, 264, 1412, 281, 534, 3847, 51664], "temperature": 0.0, "avg_logprob": -0.07540615246846126, "compression_ratio": 1.8203125, "no_speech_prob": 0.034581322222948074}, {"id": 668, "seek": 377280, "start": 3772.8, "end": 3779.2000000000003, "text": " them well and it's only when we took them out of the the closet again and said hey man this thing", "tokens": [50364, 552, 731, 293, 309, 311, 787, 562, 321, 1890, 552, 484, 295, 264, 264, 16669, 797, 293, 848, 4177, 587, 341, 551, 50684], "temperature": 0.0, "avg_logprob": -0.1029950032191994, "compression_ratio": 1.8089887640449438, "no_speech_prob": 0.03668080270290375}, {"id": 669, "seek": 377280, "start": 3779.2000000000003, "end": 3784.4, "text": " actually works if you throw a whole bunch of GPUs at it that's when people then became popular again", "tokens": [50684, 767, 1985, 498, 291, 3507, 257, 1379, 3840, 295, 18407, 82, 412, 309, 300, 311, 562, 561, 550, 3062, 3743, 797, 50944], "temperature": 0.0, "avg_logprob": -0.1029950032191994, "compression_ratio": 1.8089887640449438, "no_speech_prob": 0.03668080270290375}, {"id": 670, "seek": 377280, "start": 3784.4, "end": 3789.28, "text": " and so something like this might well happen again with with capsules or it is something like", "tokens": [50944, 293, 370, 746, 411, 341, 1062, 731, 1051, 797, 365, 365, 13855, 3473, 420, 309, 307, 746, 411, 51188], "temperature": 0.0, "avg_logprob": -0.1029950032191994, "compression_ratio": 1.8089887640449438, "no_speech_prob": 0.03668080270290375}, {"id": 671, "seek": 377280, "start": 3789.28, "end": 3794.7200000000003, "text": " capsules in then by five to ten years do you have any other than capsule networks are there", "tokens": [51188, 13855, 3473, 294, 550, 538, 1732, 281, 2064, 924, 360, 291, 362, 604, 661, 813, 29247, 9590, 366, 456, 51460], "temperature": 0.0, "avg_logprob": -0.1029950032191994, "compression_ratio": 1.8089887640449438, "no_speech_prob": 0.03668080270290375}, {"id": 672, "seek": 377280, "start": 3794.7200000000003, "end": 3800.48, "text": " things that right now we are not looking back on but that would you know be worthy of of a revisit", "tokens": [51460, 721, 300, 558, 586, 321, 366, 406, 1237, 646, 322, 457, 300, 576, 291, 458, 312, 14829, 295, 295, 257, 32676, 51748], "temperature": 0.0, "avg_logprob": -0.1029950032191994, "compression_ratio": 1.8089887640449438, "no_speech_prob": 0.03668080270290375}, {"id": 673, "seek": 380048, "start": 3801.12, "end": 3808.16, "text": " oh yeah that's very tough but i'm personally looking at things like ICA and topographic ICA", "tokens": [50396, 1954, 1338, 300, 311, 588, 4930, 457, 741, 478, 5665, 1237, 412, 721, 411, 14360, 32, 293, 1192, 12295, 14360, 32, 50748], "temperature": 0.0, "avg_logprob": -0.11354101535885833, "compression_ratio": 1.669683257918552, "no_speech_prob": 0.004388476721942425}, {"id": 674, "seek": 380048, "start": 3808.16, "end": 3814.32, "text": " so i think there's an interesting body of ideas there of course i risk now to mow away the grass", "tokens": [50748, 370, 741, 519, 456, 311, 364, 1880, 1772, 295, 3487, 456, 295, 1164, 741, 3148, 586, 281, 275, 305, 1314, 264, 8054, 51056], "temperature": 0.0, "avg_logprob": -0.11354101535885833, "compression_ratio": 1.669683257918552, "no_speech_prob": 0.004388476721942425}, {"id": 675, "seek": 380048, "start": 3814.32, "end": 3820.56, "text": " before my own feet but okay let me let me entertain that and then probably marker", "tokens": [51056, 949, 452, 1065, 3521, 457, 1392, 718, 385, 718, 385, 7655, 300, 293, 550, 1391, 15247, 51368], "temperature": 0.0, "avg_logprob": -0.11354101535885833, "compression_ratio": 1.669683257918552, "no_speech_prob": 0.004388476721942425}, {"id": 676, "seek": 380048, "start": 3820.56, "end": 3825.12, "text": " random fields and things like this will probably make a comeback at some point or graphical models", "tokens": [51368, 4974, 7909, 293, 721, 411, 341, 486, 1391, 652, 257, 23464, 412, 512, 935, 420, 35942, 5245, 51596], "temperature": 0.0, "avg_logprob": -0.11354101535885833, "compression_ratio": 1.669683257918552, "no_speech_prob": 0.004388476721942425}, {"id": 677, "seek": 382512, "start": 3825.2, "end": 3830.7999999999997, "text": " more generally will probably make a comeback or maybe that integrated with deep learning and", "tokens": [50368, 544, 5101, 486, 1391, 652, 257, 23464, 420, 1310, 300, 10919, 365, 2452, 2539, 293, 50648], "temperature": 0.0, "avg_logprob": -0.06625727111218023, "compression_ratio": 1.8404669260700388, "no_speech_prob": 0.19413094222545624}, {"id": 678, "seek": 382512, "start": 3830.7999999999997, "end": 3834.96, "text": " some people have already attempted going in that direction energy based models have made a comeback", "tokens": [50648, 512, 561, 362, 1217, 18997, 516, 294, 300, 3513, 2281, 2361, 5245, 362, 1027, 257, 23464, 50856], "temperature": 0.0, "avg_logprob": -0.06625727111218023, "compression_ratio": 1.8404669260700388, "no_speech_prob": 0.19413094222545624}, {"id": 679, "seek": 382512, "start": 3834.96, "end": 3841.2799999999997, "text": " already so yeah it is often going back to older ideas and there's probably a lot more that other", "tokens": [50856, 1217, 370, 1338, 309, 307, 2049, 516, 646, 281, 4906, 3487, 293, 456, 311, 1391, 257, 688, 544, 300, 661, 51172], "temperature": 0.0, "avg_logprob": -0.06625727111218023, "compression_ratio": 1.8404669260700388, "no_speech_prob": 0.19413094222545624}, {"id": 680, "seek": 382512, "start": 3841.2799999999997, "end": 3846.7999999999997, "text": " people can sort of name i do have a prediction maybe for the future that people really haven't", "tokens": [51172, 561, 393, 1333, 295, 1315, 741, 360, 362, 257, 17630, 1310, 337, 264, 2027, 300, 561, 534, 2378, 380, 51448], "temperature": 0.0, "avg_logprob": -0.06625727111218023, "compression_ratio": 1.8404669260700388, "no_speech_prob": 0.19413094222545624}, {"id": 681, "seek": 382512, "start": 3846.7999999999997, "end": 3851.52, "text": " looked at yet in my opinion it's going to be quantum things so i think many people don't", "tokens": [51448, 2956, 412, 1939, 294, 452, 4800, 309, 311, 516, 281, 312, 13018, 721, 370, 741, 519, 867, 561, 500, 380, 51684], "temperature": 0.0, "avg_logprob": -0.06625727111218023, "compression_ratio": 1.8404669260700388, "no_speech_prob": 0.19413094222545624}, {"id": 682, "seek": 385152, "start": 3851.52, "end": 3858.48, "text": " actually know understand the language of quantum mechanics or mathematics and i do think that first", "tokens": [50364, 767, 458, 1223, 264, 2856, 295, 13018, 12939, 420, 18666, 293, 741, 360, 519, 300, 700, 50712], "temperature": 0.0, "avg_logprob": -0.07031187534332276, "compression_ratio": 1.8244274809160306, "no_speech_prob": 0.03661873936653137}, {"id": 683, "seek": 385152, "start": 3858.48, "end": 3862.08, "text": " of all that language is very interesting it's a bit different than our normal probabilities it's", "tokens": [50712, 295, 439, 300, 2856, 307, 588, 1880, 309, 311, 257, 857, 819, 813, 527, 2710, 33783, 309, 311, 50892], "temperature": 0.0, "avg_logprob": -0.07031187534332276, "compression_ratio": 1.8244274809160306, "no_speech_prob": 0.03661873936653137}, {"id": 684, "seek": 385152, "start": 3862.08, "end": 3866.8, "text": " like square roots of probabilities and with the advent of quantum computers which at some point", "tokens": [50892, 411, 3732, 10669, 295, 33783, 293, 365, 264, 7045, 295, 13018, 10807, 597, 412, 512, 935, 51128], "temperature": 0.0, "avg_logprob": -0.07031187534332276, "compression_ratio": 1.8244274809160306, "no_speech_prob": 0.03661873936653137}, {"id": 685, "seek": 385152, "start": 3866.8, "end": 3874.08, "text": " will come we as a community will have to dive into that and maybe make it part of our curriculum", "tokens": [51128, 486, 808, 321, 382, 257, 1768, 486, 362, 281, 9192, 666, 300, 293, 1310, 652, 309, 644, 295, 527, 14302, 51492], "temperature": 0.0, "avg_logprob": -0.07031187534332276, "compression_ratio": 1.8244274809160306, "no_speech_prob": 0.03661873936653137}, {"id": 686, "seek": 385152, "start": 3874.08, "end": 3880.0, "text": " and in university and then i think that will become that will start to boom could i just", "tokens": [51492, 293, 294, 5454, 293, 550, 741, 519, 300, 486, 1813, 300, 486, 722, 281, 9351, 727, 741, 445, 51788], "temperature": 0.0, "avg_logprob": -0.07031187534332276, "compression_ratio": 1.8244274809160306, "no_speech_prob": 0.03661873936653137}, {"id": 687, "seek": 388000, "start": 3880.0, "end": 3884.72, "text": " quickly introduce before we get to quantum i don't know if you read sarah hookers the hardware", "tokens": [50364, 2661, 5366, 949, 321, 483, 281, 13018, 741, 500, 380, 458, 498, 291, 1401, 13782, 545, 6328, 433, 264, 8837, 50600], "temperature": 0.0, "avg_logprob": -0.07206793754331527, "compression_ratio": 1.8660130718954249, "no_speech_prob": 0.05815906450152397}, {"id": 688, "seek": 388000, "start": 3884.72, "end": 3890.32, "text": " lottery paper and this is fascinating for you of course working at qualcomm but her idea was that", "tokens": [50600, 27391, 3035, 293, 341, 307, 10343, 337, 291, 295, 1164, 1364, 412, 4101, 13278, 457, 720, 1558, 390, 300, 50880], "temperature": 0.0, "avg_logprob": -0.07206793754331527, "compression_ratio": 1.8660130718954249, "no_speech_prob": 0.05815906450152397}, {"id": 689, "seek": 388000, "start": 3890.32, "end": 3894.72, "text": " there are certain things that cause a inertia or friction in the marketplace of ideas so is it a", "tokens": [50880, 456, 366, 1629, 721, 300, 3082, 257, 37234, 420, 17710, 294, 264, 19455, 295, 3487, 370, 307, 309, 257, 51100], "temperature": 0.0, "avg_logprob": -0.07206793754331527, "compression_ratio": 1.8660130718954249, "no_speech_prob": 0.05815906450152397}, {"id": 690, "seek": 388000, "start": 3894.72, "end": 3900.08, "text": " meritocracy of ideas or do the previous kind of hardware decisions and hardware landscape", "tokens": [51100, 24527, 38186, 295, 3487, 420, 360, 264, 3894, 733, 295, 8837, 5327, 293, 8837, 9661, 51368], "temperature": 0.0, "avg_logprob": -0.07206793754331527, "compression_ratio": 1.8660130718954249, "no_speech_prob": 0.05815906450152397}, {"id": 691, "seek": 388000, "start": 3900.08, "end": 3904.24, "text": " does it enslave us you know ideas succeed if they're compatible with the hardware and the", "tokens": [51368, 775, 309, 3489, 27995, 505, 291, 458, 3487, 7754, 498, 436, 434, 18218, 365, 264, 8837, 293, 264, 51576], "temperature": 0.0, "avg_logprob": -0.07206793754331527, "compression_ratio": 1.8660130718954249, "no_speech_prob": 0.05815906450152397}, {"id": 692, "seek": 388000, "start": 3904.24, "end": 3908.8, "text": " software at the time and this is what she called a hardware lottery and she says the machine learning", "tokens": [51576, 4722, 412, 264, 565, 293, 341, 307, 437, 750, 1219, 257, 8837, 27391, 293, 750, 1619, 264, 3479, 2539, 51804], "temperature": 0.0, "avg_logprob": -0.07206793754331527, "compression_ratio": 1.8660130718954249, "no_speech_prob": 0.05815906450152397}, {"id": 693, "seek": 390880, "start": 3908.8, "end": 3912.6400000000003, "text": " community is exceptional because the pace of innovation is so fast it's not like in the", "tokens": [50364, 1768, 307, 19279, 570, 264, 11638, 295, 8504, 307, 370, 2370, 309, 311, 406, 411, 294, 264, 50556], "temperature": 0.0, "avg_logprob": -0.028560726165771485, "compression_ratio": 1.7987220447284344, "no_speech_prob": 0.022833500057458878}, {"id": 694, "seek": 390880, "start": 3912.6400000000003, "end": 3917.1200000000003, "text": " hardware world which you all know so well where it costs so much money to develop new hardware", "tokens": [50556, 8837, 1002, 597, 291, 439, 458, 370, 731, 689, 309, 5497, 370, 709, 1460, 281, 1499, 777, 8837, 50780], "temperature": 0.0, "avg_logprob": -0.028560726165771485, "compression_ratio": 1.7987220447284344, "no_speech_prob": 0.022833500057458878}, {"id": 695, "seek": 390880, "start": 3917.1200000000003, "end": 3922.8, "text": " and the cost of being scooped is so high but i wanted to just come at this from i don't know", "tokens": [50780, 293, 264, 2063, 295, 885, 19555, 292, 307, 370, 1090, 457, 741, 1415, 281, 445, 808, 412, 341, 490, 741, 500, 380, 458, 51064], "temperature": 0.0, "avg_logprob": -0.028560726165771485, "compression_ratio": 1.7987220447284344, "no_speech_prob": 0.022833500057458878}, {"id": 696, "seek": 390880, "start": 3922.8, "end": 3927.36, "text": " how you see this right so with capsule networks the reason they're so slow is because it's a kind", "tokens": [51064, 577, 291, 536, 341, 558, 370, 365, 29247, 9590, 264, 1778, 436, 434, 370, 2964, 307, 570, 309, 311, 257, 733, 51292], "temperature": 0.0, "avg_logprob": -0.028560726165771485, "compression_ratio": 1.7987220447284344, "no_speech_prob": 0.022833500057458878}, {"id": 697, "seek": 390880, "start": 3927.36, "end": 3932.5600000000004, "text": " of sequential computing paradigm and no amount of hardware is going to solve that but there are", "tokens": [51292, 295, 42881, 15866, 24709, 293, 572, 2372, 295, 8837, 307, 516, 281, 5039, 300, 457, 456, 366, 51552], "temperature": 0.0, "avg_logprob": -0.028560726165771485, "compression_ratio": 1.7987220447284344, "no_speech_prob": 0.022833500057458878}, {"id": 698, "seek": 390880, "start": 3932.5600000000004, "end": 3936.8, "text": " entirely different paradigms of hardware like quantum which could potentially change the game", "tokens": [51552, 7696, 819, 13480, 328, 2592, 295, 8837, 411, 13018, 597, 727, 7263, 1319, 264, 1216, 51764], "temperature": 0.0, "avg_logprob": -0.028560726165771485, "compression_ratio": 1.7987220447284344, "no_speech_prob": 0.022833500057458878}, {"id": 699, "seek": 393680, "start": 3936.8, "end": 3941.52, "text": " but how much could they change the game is there still some limit on it there's always a limit", "tokens": [50364, 457, 577, 709, 727, 436, 1319, 264, 1216, 307, 456, 920, 512, 4948, 322, 309, 456, 311, 1009, 257, 4948, 50600], "temperature": 0.0, "avg_logprob": -0.051598126547677176, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.009974559769034386}, {"id": 700, "seek": 393680, "start": 3941.52, "end": 3947.2000000000003, "text": " clearly but i think the the situation is maybe slightly more subtle which is that working in a", "tokens": [50600, 4448, 457, 741, 519, 264, 264, 2590, 307, 1310, 4748, 544, 13743, 597, 307, 300, 1364, 294, 257, 50884], "temperature": 0.0, "avg_logprob": -0.051598126547677176, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.009974559769034386}, {"id": 701, "seek": 393680, "start": 3947.2000000000003, "end": 3953.92, "text": " hardware company i can also see the other side of the coin a little bit so there is also a race", "tokens": [50884, 8837, 2237, 741, 393, 611, 536, 264, 661, 1252, 295, 264, 11464, 257, 707, 857, 370, 456, 307, 611, 257, 4569, 51220], "temperature": 0.0, "avg_logprob": -0.051598126547677176, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.009974559769034386}, {"id": 702, "seek": 393680, "start": 3953.92, "end": 3960.7200000000003, "text": " in the hardware companies to build ASIC designs like which is specialized hardware to run the", "tokens": [51220, 294, 264, 8837, 3431, 281, 1322, 7469, 2532, 11347, 411, 597, 307, 19813, 8837, 281, 1190, 264, 51560], "temperature": 0.0, "avg_logprob": -0.051598126547677176, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.009974559769034386}, {"id": 703, "seek": 393680, "start": 3960.7200000000003, "end": 3965.76, "text": " latest and the greatest machine learning algorithms which are being developed so it's not just rich", "tokens": [51560, 6792, 293, 264, 6636, 3479, 2539, 14642, 597, 366, 885, 4743, 370, 309, 311, 406, 445, 4593, 51812], "temperature": 0.0, "avg_logprob": -0.051598126547677176, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.009974559769034386}, {"id": 704, "seek": 396576, "start": 3965.76, "end": 3970.5600000000004, "text": " machine learning algorithms work well on the current hardware that us being enslaved to the", "tokens": [50364, 3479, 2539, 14642, 589, 731, 322, 264, 2190, 8837, 300, 505, 885, 32119, 281, 264, 50604], "temperature": 0.0, "avg_logprob": -0.06174252797098993, "compression_ratio": 1.740072202166065, "no_speech_prob": 0.00235570571385324}, {"id": 705, "seek": 396576, "start": 3970.5600000000004, "end": 3976.5600000000004, "text": " hardware there is actually a feedback which where now the companies are trying to build ASIC to first", "tokens": [50604, 8837, 456, 307, 767, 257, 5824, 597, 689, 586, 264, 3431, 366, 1382, 281, 1322, 7469, 2532, 281, 700, 50904], "temperature": 0.0, "avg_logprob": -0.06174252797098993, "compression_ratio": 1.740072202166065, "no_speech_prob": 0.00235570571385324}, {"id": 706, "seek": 396576, "start": 3976.5600000000004, "end": 3984.8, "text": " of all run the confolutions very efficiently and soon we'll have probably transformers run very", "tokens": [50904, 295, 439, 1190, 264, 1497, 15892, 588, 19621, 293, 2321, 321, 603, 362, 1391, 4088, 433, 1190, 588, 51316], "temperature": 0.0, "avg_logprob": -0.06174252797098993, "compression_ratio": 1.740072202166065, "no_speech_prob": 0.00235570571385324}, {"id": 707, "seek": 396576, "start": 3984.8, "end": 3990.0, "text": " efficiently and so that's the fascinating thing of course it's hard to get your paper published", "tokens": [51316, 19621, 293, 370, 300, 311, 264, 10343, 551, 295, 1164, 309, 311, 1152, 281, 483, 428, 3035, 6572, 51576], "temperature": 0.0, "avg_logprob": -0.06174252797098993, "compression_ratio": 1.740072202166065, "no_speech_prob": 0.00235570571385324}, {"id": 708, "seek": 396576, "start": 3990.0, "end": 3995.0400000000004, "text": " perhaps if if you're ahead of the game too much which i see a little bit in the machine learning", "tokens": [51576, 4317, 498, 498, 291, 434, 2286, 295, 264, 1216, 886, 709, 597, 741, 536, 257, 707, 857, 294, 264, 3479, 2539, 51828], "temperature": 0.0, "avg_logprob": -0.06174252797098993, "compression_ratio": 1.740072202166065, "no_speech_prob": 0.00235570571385324}, {"id": 709, "seek": 399504, "start": 3995.04, "end": 4000.0, "text": " community which is if you look at the papers which are published in the physics community they work", "tokens": [50364, 1768, 597, 307, 498, 291, 574, 412, 264, 10577, 597, 366, 6572, 294, 264, 10649, 1768, 436, 589, 50612], "temperature": 0.0, "avg_logprob": -0.051474227355076715, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.007933353073894978}, {"id": 710, "seek": 399504, "start": 4000.0, "end": 4005.44, "text": " with images of four by four pixels that's what they can do because otherwise you need a quantum", "tokens": [50612, 365, 5267, 295, 1451, 538, 1451, 18668, 300, 311, 437, 436, 393, 360, 570, 5911, 291, 643, 257, 13018, 50884], "temperature": 0.0, "avg_logprob": -0.051474227355076715, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.007933353073894978}, {"id": 711, "seek": 399504, "start": 4005.44, "end": 4011.2799999999997, "text": " computer obviously to run your algorithm and it's being looked down upon a lot by the machine", "tokens": [50884, 3820, 2745, 281, 1190, 428, 9284, 293, 309, 311, 885, 2956, 760, 3564, 257, 688, 538, 264, 3479, 51176], "temperature": 0.0, "avg_logprob": -0.051474227355076715, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.007933353073894978}, {"id": 712, "seek": 399504, "start": 4011.2799999999997, "end": 4016.32, "text": " learners basically saying what do we you know what why is that interesting and i do feel very", "tokens": [51176, 23655, 1936, 1566, 437, 360, 321, 291, 458, 437, 983, 307, 300, 1880, 293, 741, 360, 841, 588, 51428], "temperature": 0.0, "avg_logprob": -0.051474227355076715, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.007933353073894978}, {"id": 713, "seek": 399504, "start": 4016.32, "end": 4023.2, "text": " strongly that as a field we need to open up so we we should value original ideas much more", "tokens": [51428, 10613, 300, 382, 257, 2519, 321, 643, 281, 1269, 493, 370, 321, 321, 820, 2158, 3380, 3487, 709, 544, 51772], "temperature": 0.0, "avg_logprob": -0.051474227355076715, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.007933353073894978}, {"id": 714, "seek": 402320, "start": 4023.2, "end": 4027.4399999999996, "text": " than we currently do and i don't know you know you can probably have a whole conversation on", "tokens": [50364, 813, 321, 4362, 360, 293, 741, 500, 380, 458, 291, 458, 291, 393, 1391, 362, 257, 1379, 3761, 322, 50576], "temperature": 0.0, "avg_logprob": -0.04181616836123996, "compression_ratio": 1.787313432835821, "no_speech_prob": 0.014932732097804546}, {"id": 715, "seek": 402320, "start": 4027.4399999999996, "end": 4034.8799999999997, "text": " where this is coming from i think the reviewing in our community is far too grumpy i think people", "tokens": [50576, 689, 341, 307, 1348, 490, 741, 519, 264, 19576, 294, 527, 1768, 307, 1400, 886, 677, 36142, 741, 519, 561, 50948], "temperature": 0.0, "avg_logprob": -0.04181616836123996, "compression_ratio": 1.787313432835821, "no_speech_prob": 0.014932732097804546}, {"id": 716, "seek": 402320, "start": 4034.8799999999997, "end": 4040.72, "text": " if it's not completely finished polished paper then you know they'll find a hole somewhere and", "tokens": [50948, 498, 309, 311, 406, 2584, 4335, 29079, 3035, 550, 291, 458, 436, 603, 915, 257, 5458, 4079, 293, 51240], "temperature": 0.0, "avg_logprob": -0.04181616836123996, "compression_ratio": 1.787313432835821, "no_speech_prob": 0.014932732097804546}, {"id": 717, "seek": 402320, "start": 4040.72, "end": 4047.2, "text": " they start pushing on it and i think you should look also at a sort of more holistic how original", "tokens": [51240, 436, 722, 7380, 322, 309, 293, 741, 519, 291, 820, 574, 611, 412, 257, 1333, 295, 544, 30334, 577, 3380, 51564], "temperature": 0.0, "avg_logprob": -0.04181616836123996, "compression_ratio": 1.787313432835821, "no_speech_prob": 0.014932732097804546}, {"id": 718, "seek": 402320, "start": 4047.2, "end": 4052.64, "text": " is this idea right can you be excited about the originality and the creativity of the idea that", "tokens": [51564, 307, 341, 1558, 558, 393, 291, 312, 2919, 466, 264, 4957, 1860, 293, 264, 12915, 295, 264, 1558, 300, 51836], "temperature": 0.0, "avg_logprob": -0.04181616836123996, "compression_ratio": 1.787313432835821, "no_speech_prob": 0.014932732097804546}, {"id": 719, "seek": 405264, "start": 4052.64, "end": 4059.6, "text": " went into that and trust that maybe it takes the community a couple of years to further develop this", "tokens": [50364, 1437, 666, 300, 293, 3361, 300, 1310, 309, 2516, 264, 1768, 257, 1916, 295, 924, 281, 3052, 1499, 341, 50712], "temperature": 0.0, "avg_logprob": -0.09515236564304518, "compression_ratio": 1.7846715328467153, "no_speech_prob": 0.002351039554923773}, {"id": 720, "seek": 405264, "start": 4059.6, "end": 4065.6, "text": " and and and some things will die and that's fine but let all these flowers grow in a way and yeah so", "tokens": [50712, 293, 293, 293, 512, 721, 486, 978, 293, 300, 311, 2489, 457, 718, 439, 613, 8085, 1852, 294, 257, 636, 293, 1338, 370, 51012], "temperature": 0.0, "avg_logprob": -0.09515236564304518, "compression_ratio": 1.7846715328467153, "no_speech_prob": 0.002351039554923773}, {"id": 721, "seek": 405264, "start": 4065.6, "end": 4070.4, "text": " i i do feel a little bit that sometimes is a bit negative and i and that's maybe where some of", "tokens": [51012, 741, 741, 360, 841, 257, 707, 857, 300, 2171, 307, 257, 857, 3671, 293, 741, 293, 300, 311, 1310, 689, 512, 295, 51252], "temperature": 0.0, "avg_logprob": -0.09515236564304518, "compression_ratio": 1.7846715328467153, "no_speech_prob": 0.002351039554923773}, {"id": 722, "seek": 405264, "start": 4070.4, "end": 4075.3599999999997, "text": " that friction is coming from that yeah just on that it's fascinating we're talking to Kenneth", "tokens": [51252, 300, 17710, 307, 1348, 490, 300, 1338, 445, 322, 300, 309, 311, 10343, 321, 434, 1417, 281, 33735, 51500], "temperature": 0.0, "avg_logprob": -0.09515236564304518, "compression_ratio": 1.7846715328467153, "no_speech_prob": 0.002351039554923773}, {"id": 723, "seek": 405264, "start": 4075.3599999999997, "end": 4080.4, "text": " Stanley on monday and he wrote a book greatness can't be planned and his big thing is exactly what", "tokens": [51500, 28329, 322, 17606, 320, 293, 415, 4114, 257, 1446, 31196, 393, 380, 312, 8589, 293, 702, 955, 551, 307, 2293, 437, 51752], "temperature": 0.0, "avg_logprob": -0.09515236564304518, "compression_ratio": 1.7846715328467153, "no_speech_prob": 0.002351039554923773}, {"id": 724, "seek": 408040, "start": 4080.4, "end": 4084.88, "text": " you've just said that we have this convergent behavior in so many of our systems whether it's", "tokens": [50364, 291, 600, 445, 848, 300, 321, 362, 341, 9652, 6930, 5223, 294, 370, 867, 295, 527, 3652, 1968, 309, 311, 50588], "temperature": 0.0, "avg_logprob": -0.04453932660297283, "compression_ratio": 1.7749077490774907, "no_speech_prob": 0.02842785231769085}, {"id": 725, "seek": 408040, "start": 4084.88, "end": 4091.12, "text": " science or academia and it's because of this objective obsession so we all want to monotonically", "tokens": [50588, 3497, 420, 28937, 293, 309, 311, 570, 295, 341, 10024, 30521, 370, 321, 439, 528, 281, 1108, 27794, 984, 50900], "temperature": 0.0, "avg_logprob": -0.04453932660297283, "compression_ratio": 1.7749077490774907, "no_speech_prob": 0.02842785231769085}, {"id": 726, "seek": 408040, "start": 4091.12, "end": 4095.52, "text": " increase our objectives and what we should be is treasure hunters yes science should be about", "tokens": [50900, 3488, 527, 15961, 293, 437, 321, 820, 312, 307, 12985, 29509, 2086, 3497, 820, 312, 466, 51120], "temperature": 0.0, "avg_logprob": -0.04453932660297283, "compression_ratio": 1.7749077490774907, "no_speech_prob": 0.02842785231769085}, {"id": 727, "seek": 408040, "start": 4095.52, "end": 4100.96, "text": " exploration not exploitation exploitation is one step away you already know how to build the bridge", "tokens": [51120, 16197, 406, 33122, 33122, 307, 472, 1823, 1314, 291, 1217, 458, 577, 281, 1322, 264, 7283, 51392], "temperature": 0.0, "avg_logprob": -0.04453932660297283, "compression_ratio": 1.7749077490774907, "no_speech_prob": 0.02842785231769085}, {"id": 728, "seek": 408040, "start": 4100.96, "end": 4106.8, "text": " we don't seem to have this paradigm at the moment even when you submit your paper to be reviewed", "tokens": [51392, 321, 500, 380, 1643, 281, 362, 341, 24709, 412, 264, 1623, 754, 562, 291, 10315, 428, 3035, 281, 312, 18429, 51684], "temperature": 0.0, "avg_logprob": -0.04453932660297283, "compression_ratio": 1.7749077490774907, "no_speech_prob": 0.02842785231769085}, {"id": 729, "seek": 410680, "start": 4106.8, "end": 4111.68, "text": " there's a consensus mechanism isn't there because you need to have multiple accepts from people and", "tokens": [50364, 456, 311, 257, 19115, 7513, 1943, 380, 456, 570, 291, 643, 281, 362, 3866, 33538, 490, 561, 293, 50608], "temperature": 0.0, "avg_logprob": -0.06701840110447095, "compression_ratio": 1.8931297709923665, "no_speech_prob": 0.020151691511273384}, {"id": 730, "seek": 410680, "start": 4111.68, "end": 4117.28, "text": " science advances one funeral at a time yes do you think this is a huge problem yeah i think it is a", "tokens": [50608, 3497, 25297, 472, 20231, 412, 257, 565, 2086, 360, 291, 519, 341, 307, 257, 2603, 1154, 1338, 741, 519, 309, 307, 257, 50888], "temperature": 0.0, "avg_logprob": -0.06701840110447095, "compression_ratio": 1.8931297709923665, "no_speech_prob": 0.020151691511273384}, {"id": 731, "seek": 410680, "start": 4117.28, "end": 4121.28, "text": " big problem but i think also we will probably i think it's a big problem because it will hold us", "tokens": [50888, 955, 1154, 457, 741, 519, 611, 321, 486, 1391, 741, 519, 309, 311, 257, 955, 1154, 570, 309, 486, 1797, 505, 51088], "temperature": 0.0, "avg_logprob": -0.06701840110447095, "compression_ratio": 1.8931297709923665, "no_speech_prob": 0.020151691511273384}, {"id": 732, "seek": 410680, "start": 4121.28, "end": 4126.96, "text": " back and it will also hold very brilliant students back so what do i advise my students now i advise", "tokens": [51088, 646, 293, 309, 486, 611, 1797, 588, 10248, 1731, 646, 370, 437, 360, 741, 18312, 452, 1731, 586, 741, 18312, 51372], "temperature": 0.0, "avg_logprob": -0.06701840110447095, "compression_ratio": 1.8931297709923665, "no_speech_prob": 0.020151691511273384}, {"id": 733, "seek": 410680, "start": 4126.96, "end": 4133.2, "text": " them to have a mixed model a mixed sort of policy which is on the one hand you work on some papers", "tokens": [51372, 552, 281, 362, 257, 7467, 2316, 257, 7467, 1333, 295, 3897, 597, 307, 322, 264, 472, 1011, 291, 589, 322, 512, 10577, 51684], "temperature": 0.0, "avg_logprob": -0.06701840110447095, "compression_ratio": 1.8931297709923665, "no_speech_prob": 0.020151691511273384}, {"id": 734, "seek": 413320, "start": 4133.2, "end": 4138.5599999999995, "text": " which are easy to score on things that are very popular in the community and then on the other", "tokens": [50364, 597, 366, 1858, 281, 6175, 322, 721, 300, 366, 588, 3743, 294, 264, 1768, 293, 550, 322, 264, 661, 50632], "temperature": 0.0, "avg_logprob": -0.03912794043164734, "compression_ratio": 1.983739837398374, "no_speech_prob": 0.0113214747980237}, {"id": 735, "seek": 413320, "start": 4138.5599999999995, "end": 4144.08, "text": " hand you work on things which might be you know huge innovations that are much more uncertain", "tokens": [50632, 1011, 291, 589, 322, 721, 597, 1062, 312, 291, 458, 2603, 24283, 300, 366, 709, 544, 11308, 50908], "temperature": 0.0, "avg_logprob": -0.03912794043164734, "compression_ratio": 1.983739837398374, "no_speech_prob": 0.0113214747980237}, {"id": 736, "seek": 413320, "start": 4144.08, "end": 4149.599999999999, "text": " they might fail but then they might also be really big innovations and that way you get your papers", "tokens": [50908, 436, 1062, 3061, 457, 550, 436, 1062, 611, 312, 534, 955, 24283, 293, 300, 636, 291, 483, 428, 10577, 51184], "temperature": 0.0, "avg_logprob": -0.03912794043164734, "compression_ratio": 1.983739837398374, "no_speech_prob": 0.0113214747980237}, {"id": 737, "seek": 413320, "start": 4149.599999999999, "end": 4154.08, "text": " and you can become famous but at least also you work on things which are highly risky but in fact", "tokens": [51184, 293, 291, 393, 1813, 4618, 457, 412, 1935, 611, 291, 589, 322, 721, 597, 366, 5405, 21137, 457, 294, 1186, 51408], "temperature": 0.0, "avg_logprob": -0.03912794043164734, "compression_ratio": 1.983739837398374, "no_speech_prob": 0.0113214747980237}, {"id": 738, "seek": 413320, "start": 4154.72, "end": 4159.84, "text": " it's a bit cynical to have to do that it would be much nicer if there would be much more appreciation", "tokens": [51440, 309, 311, 257, 857, 46345, 281, 362, 281, 360, 300, 309, 576, 312, 709, 22842, 498, 456, 576, 312, 709, 544, 18909, 51696], "temperature": 0.0, "avg_logprob": -0.03912794043164734, "compression_ratio": 1.983739837398374, "no_speech_prob": 0.0113214747980237}, {"id": 739, "seek": 415984, "start": 4159.84, "end": 4166.400000000001, "text": " for just originality and but i do also believe there is a solution to this so i think we are in", "tokens": [50364, 337, 445, 4957, 1860, 293, 457, 741, 360, 611, 1697, 456, 307, 257, 3827, 281, 341, 370, 741, 519, 321, 366, 294, 50692], "temperature": 0.0, "avg_logprob": -0.12212786181219693, "compression_ratio": 1.8082706766917294, "no_speech_prob": 0.023971254006028175}, {"id": 740, "seek": 415984, "start": 4166.400000000001, "end": 4171.04, "text": " a sort of a local minimum as a community in this sense but i think there's a way out and one way", "tokens": [50692, 257, 1333, 295, 257, 2654, 7285, 382, 257, 1768, 294, 341, 2020, 457, 741, 519, 456, 311, 257, 636, 484, 293, 472, 636, 50924], "temperature": 0.0, "avg_logprob": -0.12212786181219693, "compression_ratio": 1.8082706766917294, "no_speech_prob": 0.023971254006028175}, {"id": 741, "seek": 415984, "start": 4171.04, "end": 4176.72, "text": " out which is basically and this has been already proposed a long time ago i think young mcconn", "tokens": [50924, 484, 597, 307, 1936, 293, 341, 575, 668, 1217, 10348, 257, 938, 565, 2057, 741, 519, 2037, 275, 66, 1671, 77, 51208], "temperature": 0.0, "avg_logprob": -0.12212786181219693, "compression_ratio": 1.8082706766917294, "no_speech_prob": 0.023971254006028175}, {"id": 742, "seek": 415984, "start": 4176.72, "end": 4181.84, "text": " and yasha benji were also talking about this and we are actually trying to implement this for a", "tokens": [51208, 293, 288, 12137, 3271, 4013, 645, 611, 1417, 466, 341, 293, 321, 366, 767, 1382, 281, 4445, 341, 337, 257, 51464], "temperature": 0.0, "avg_logprob": -0.12212786181219693, "compression_ratio": 1.8082706766917294, "no_speech_prob": 0.023971254006028175}, {"id": 743, "seek": 415984, "start": 4181.84, "end": 4188.64, "text": " beige and deep learning workshop is to sort of to throw papers on the archive and not necessarily", "tokens": [51464, 40274, 293, 2452, 2539, 13541, 307, 281, 1333, 295, 281, 3507, 10577, 322, 264, 23507, 293, 406, 4725, 51804], "temperature": 0.0, "avg_logprob": -0.12212786181219693, "compression_ratio": 1.8082706766917294, "no_speech_prob": 0.023971254006028175}, {"id": 744, "seek": 418864, "start": 4188.64, "end": 4196.8, "text": " submit to conferences and to have a open reviewing of that and to give people reputation indices so if", "tokens": [50364, 10315, 281, 22032, 293, 281, 362, 257, 1269, 19576, 295, 300, 293, 281, 976, 561, 13061, 43840, 370, 498, 50772], "temperature": 0.0, "avg_logprob": -0.057258160217948585, "compression_ratio": 1.9023255813953488, "no_speech_prob": 0.025920843705534935}, {"id": 745, "seek": 418864, "start": 4196.8, "end": 4202.56, "text": " you do if you give a good review you can publish your own review or state it in your cv and people", "tokens": [50772, 291, 360, 498, 291, 976, 257, 665, 3131, 291, 393, 11374, 428, 1065, 3131, 420, 1785, 309, 294, 428, 269, 85, 293, 561, 51060], "temperature": 0.0, "avg_logprob": -0.057258160217948585, "compression_ratio": 1.9023255813953488, "no_speech_prob": 0.025920843705534935}, {"id": 746, "seek": 418864, "start": 4202.56, "end": 4208.96, "text": " can rate your review and if you do poorer reviews you'll get horrible ratings and then your reputation", "tokens": [51060, 393, 3314, 428, 3131, 293, 498, 291, 360, 49740, 10229, 291, 603, 483, 9263, 24603, 293, 550, 428, 13061, 51380], "temperature": 0.0, "avg_logprob": -0.057258160217948585, "compression_ratio": 1.9023255813953488, "no_speech_prob": 0.025920843705534935}, {"id": 747, "seek": 418864, "start": 4208.96, "end": 4214.0, "text": " will come down so there is some kind of way that you can probably design is that people are incentivized", "tokens": [51380, 486, 808, 760, 370, 456, 307, 512, 733, 295, 636, 300, 291, 393, 1391, 1715, 307, 300, 561, 366, 35328, 1602, 51632], "temperature": 0.0, "avg_logprob": -0.057258160217948585, "compression_ratio": 1.9023255813953488, "no_speech_prob": 0.025920843705534935}, {"id": 748, "seek": 421400, "start": 4214.0, "end": 4219.44, "text": " to give good reviews and to actually use these reviews as a half a paper that you can also be", "tokens": [50364, 281, 976, 665, 10229, 293, 281, 767, 764, 613, 10229, 382, 257, 1922, 257, 3035, 300, 291, 393, 611, 312, 50636], "temperature": 0.0, "avg_logprob": -0.044662346517233026, "compression_ratio": 1.9347079037800687, "no_speech_prob": 0.08371366560459137}, {"id": 749, "seek": 421400, "start": 4219.44, "end": 4224.32, "text": " proud of and then good things will come up right they will at some point people will point to", "tokens": [50636, 4570, 295, 293, 550, 665, 721, 486, 808, 493, 558, 436, 486, 412, 512, 935, 561, 486, 935, 281, 50880], "temperature": 0.0, "avg_logprob": -0.044662346517233026, "compression_ratio": 1.9347079037800687, "no_speech_prob": 0.08371366560459137}, {"id": 750, "seek": 421400, "start": 4224.32, "end": 4229.92, "text": " interesting ideas maybe we need some kind of recommender to make sure it's a bit unbiased in", "tokens": [50880, 1880, 3487, 1310, 321, 643, 512, 733, 295, 2748, 260, 281, 652, 988, 309, 311, 257, 857, 517, 5614, 1937, 294, 51160], "temperature": 0.0, "avg_logprob": -0.044662346517233026, "compression_ratio": 1.9347079037800687, "no_speech_prob": 0.08371366560459137}, {"id": 751, "seek": 421400, "start": 4229.92, "end": 4234.4, "text": " the sense that it's not only the famous people that will get their papers exposed but also less", "tokens": [51160, 264, 2020, 300, 309, 311, 406, 787, 264, 4618, 561, 300, 486, 483, 641, 10577, 9495, 457, 611, 1570, 51384], "temperature": 0.0, "avg_logprob": -0.044662346517233026, "compression_ratio": 1.9347079037800687, "no_speech_prob": 0.08371366560459137}, {"id": 752, "seek": 421400, "start": 4234.4, "end": 4237.92, "text": " famous people so we need to have sort of maybe build a recommender around something like that", "tokens": [51384, 4618, 561, 370, 321, 643, 281, 362, 1333, 295, 1310, 1322, 257, 2748, 260, 926, 746, 411, 300, 51560], "temperature": 0.0, "avg_logprob": -0.044662346517233026, "compression_ratio": 1.9347079037800687, "no_speech_prob": 0.08371366560459137}, {"id": 753, "seek": 421400, "start": 4238.64, "end": 4243.44, "text": " every so now and then a conference comes by and it sort of harvests in this field of sort of", "tokens": [51596, 633, 370, 586, 293, 550, 257, 7586, 1487, 538, 293, 309, 1333, 295, 2233, 85, 4409, 294, 341, 2519, 295, 1333, 295, 51836], "temperature": 0.0, "avg_logprob": -0.044662346517233026, "compression_ratio": 1.9347079037800687, "no_speech_prob": 0.08371366560459137}, {"id": 754, "seek": 424344, "start": 4243.44, "end": 4248.879999999999, "text": " papers and say that one you're all reviewed they have great reviews i'll take one or two more reviews", "tokens": [50364, 10577, 293, 584, 300, 472, 291, 434, 439, 18429, 436, 362, 869, 10229, 741, 603, 747, 472, 420, 732, 544, 10229, 50636], "temperature": 0.0, "avg_logprob": -0.044259539747660136, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.005465821363031864}, {"id": 755, "seek": 424344, "start": 4248.879999999999, "end": 4254.24, "text": " anonymously and i'll then publish and then i invite you to present your paper in our conference", "tokens": [50636, 37293, 5098, 293, 741, 603, 550, 11374, 293, 550, 741, 7980, 291, 281, 1974, 428, 3035, 294, 527, 7586, 50904], "temperature": 0.0, "avg_logprob": -0.044259539747660136, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.005465821363031864}, {"id": 756, "seek": 424344, "start": 4254.24, "end": 4261.12, "text": " that to me sounds like a much more natural way to proceed i also find it very demotivating for", "tokens": [50904, 300, 281, 385, 3263, 411, 257, 709, 544, 3303, 636, 281, 8991, 741, 611, 915, 309, 588, 1371, 310, 592, 990, 337, 51248], "temperature": 0.0, "avg_logprob": -0.044259539747660136, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.005465821363031864}, {"id": 757, "seek": 424344, "start": 4261.12, "end": 4265.839999999999, "text": " my students who have these ideas maybe this is the worst part so you're a student you're working on", "tokens": [51248, 452, 1731, 567, 362, 613, 3487, 1310, 341, 307, 264, 5855, 644, 370, 291, 434, 257, 3107, 291, 434, 1364, 322, 51484], "temperature": 0.0, "avg_logprob": -0.044259539747660136, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.005465821363031864}, {"id": 758, "seek": 424344, "start": 4265.839999999999, "end": 4270.719999999999, "text": " this thing which is not completely mainstream and then you get rejected two or three times from a", "tokens": [51484, 341, 551, 597, 307, 406, 2584, 15960, 293, 550, 291, 483, 15749, 732, 420, 1045, 1413, 490, 257, 51728], "temperature": 0.0, "avg_logprob": -0.044259539747660136, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.005465821363031864}, {"id": 759, "seek": 427072, "start": 4270.72, "end": 4276.72, "text": " conference right this is so demotivating for a student to then continue right at this case at", "tokens": [50364, 7586, 558, 341, 307, 370, 1371, 310, 592, 990, 337, 257, 3107, 281, 550, 2354, 558, 412, 341, 1389, 412, 50664], "temperature": 0.0, "avg_logprob": -0.16436268867702658, "compression_ratio": 1.6766917293233083, "no_speech_prob": 0.009120021015405655}, {"id": 760, "seek": 427072, "start": 4276.72, "end": 4281.04, "text": " least you just you push us on the archive and you engage with the community around your paper", "tokens": [50664, 1935, 291, 445, 291, 2944, 505, 322, 264, 23507, 293, 291, 4683, 365, 264, 1768, 926, 428, 3035, 50880], "temperature": 0.0, "avg_logprob": -0.16436268867702658, "compression_ratio": 1.6766917293233083, "no_speech_prob": 0.009120021015405655}, {"id": 761, "seek": 427072, "start": 4281.68, "end": 4285.84, "text": " and that's a much more it's much less demotivating than these constant rejections", "tokens": [50912, 293, 300, 311, 257, 709, 544, 309, 311, 709, 1570, 1371, 310, 592, 990, 813, 613, 5754, 8248, 626, 51120], "temperature": 0.0, "avg_logprob": -0.16436268867702658, "compression_ratio": 1.6766917293233083, "no_speech_prob": 0.009120021015405655}, {"id": 762, "seek": 427072, "start": 4286.400000000001, "end": 4291.4400000000005, "text": " from the big prizes right the NERIAPS paper or the ICML paper that everybody wants", "tokens": [51148, 490, 264, 955, 27350, 558, 264, 426, 1598, 40, 4715, 50, 3035, 420, 264, 14360, 12683, 3035, 300, 2201, 2738, 51400], "temperature": 0.0, "avg_logprob": -0.16436268867702658, "compression_ratio": 1.6766917293233083, "no_speech_prob": 0.009120021015405655}, {"id": 763, "seek": 427072, "start": 4291.4400000000005, "end": 4296.16, "text": " is like guys the idea at the moment a lot of people are talking about this how can we improve", "tokens": [51400, 307, 411, 1074, 264, 1558, 412, 264, 1623, 257, 688, 295, 561, 366, 1417, 466, 341, 577, 393, 321, 3470, 51636], "temperature": 0.0, "avg_logprob": -0.16436268867702658, "compression_ratio": 1.6766917293233083, "no_speech_prob": 0.009120021015405655}, {"id": 764, "seek": 429616, "start": 4296.16, "end": 4301.599999999999, "text": " peer review like in every field people are moving towards this open review model but", "tokens": [50364, 15108, 3131, 411, 294, 633, 2519, 561, 366, 2684, 3030, 341, 1269, 3131, 2316, 457, 50636], "temperature": 0.0, "avg_logprob": -0.08165331276095643, "compression_ratio": 1.7602996254681649, "no_speech_prob": 0.04020899161696434}, {"id": 765, "seek": 429616, "start": 4301.599999999999, "end": 4305.84, "text": " collectively as a research community we don't really have the collaboration tools at this", "tokens": [50636, 24341, 382, 257, 2132, 1768, 321, 500, 380, 534, 362, 264, 9363, 3873, 412, 341, 50848], "temperature": 0.0, "avg_logprob": -0.08165331276095643, "compression_ratio": 1.7602996254681649, "no_speech_prob": 0.04020899161696434}, {"id": 766, "seek": 429616, "start": 4305.84, "end": 4311.28, "text": " point in time to take advantage of it open review is willing to implement this actually so yeah i", "tokens": [50848, 935, 294, 565, 281, 747, 5002, 295, 309, 1269, 3131, 307, 4950, 281, 4445, 341, 767, 370, 1338, 741, 51120], "temperature": 0.0, "avg_logprob": -0.08165331276095643, "compression_ratio": 1.7602996254681649, "no_speech_prob": 0.04020899161696434}, {"id": 767, "seek": 429616, "start": 4311.28, "end": 4317.76, "text": " think it will happen yeah it it's a good system to pivot back into new ideas and sort of exciting", "tokens": [51120, 519, 309, 486, 1051, 1338, 309, 309, 311, 257, 665, 1185, 281, 14538, 646, 666, 777, 3487, 293, 1333, 295, 4670, 51444], "temperature": 0.0, "avg_logprob": -0.08165331276095643, "compression_ratio": 1.7602996254681649, "no_speech_prob": 0.04020899161696434}, {"id": 768, "seek": 429616, "start": 4317.76, "end": 4322.16, "text": " concepts that are coming out machine learning at the moment you mentioned quantum computing is this", "tokens": [51444, 10392, 300, 366, 1348, 484, 3479, 2539, 412, 264, 1623, 291, 2835, 13018, 15866, 307, 341, 51664], "temperature": 0.0, "avg_logprob": -0.08165331276095643, "compression_ratio": 1.7602996254681649, "no_speech_prob": 0.04020899161696434}, {"id": 769, "seek": 432216, "start": 4322.16, "end": 4326.16, "text": " paradigm that's really critical that's not really well understood by the machine learning", "tokens": [50364, 24709, 300, 311, 534, 4924, 300, 311, 406, 534, 731, 7320, 538, 264, 3479, 2539, 50564], "temperature": 0.0, "avg_logprob": -0.0587029555409225, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.007689230609685183}, {"id": 770, "seek": 432216, "start": 4326.16, "end": 4331.44, "text": " community would you be able to give our listeners like the five-minute spiel about quantum probability", "tokens": [50564, 1768, 576, 291, 312, 1075, 281, 976, 527, 23274, 411, 264, 1732, 12, 18256, 637, 1187, 466, 13018, 8482, 50828], "temperature": 0.0, "avg_logprob": -0.0587029555409225, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.007689230609685183}, {"id": 771, "seek": 432216, "start": 4331.44, "end": 4336.16, "text": " how it differs from the probabilities that we're used to yeah so you can think of quantum mechanics", "tokens": [50828, 577, 309, 37761, 490, 264, 33783, 300, 321, 434, 1143, 281, 1338, 370, 291, 393, 519, 295, 13018, 12939, 51064], "temperature": 0.0, "avg_logprob": -0.0587029555409225, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.007689230609685183}, {"id": 772, "seek": 432216, "start": 4336.16, "end": 4342.8, "text": " as another theory of statistics in some sense right so in AI for everything we can't totally", "tokens": [51064, 382, 1071, 5261, 295, 12523, 294, 512, 2020, 558, 370, 294, 7318, 337, 1203, 321, 393, 380, 3879, 51396], "temperature": 0.0, "avg_logprob": -0.0587029555409225, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.007689230609685183}, {"id": 773, "seek": 432216, "start": 4342.8, "end": 4348.0, "text": " observe we write down probabilities of things happening but of course underlying there is", "tokens": [51396, 11441, 321, 2464, 760, 33783, 295, 721, 2737, 457, 295, 1164, 14217, 456, 307, 51656], "temperature": 0.0, "avg_logprob": -0.0587029555409225, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.007689230609685183}, {"id": 774, "seek": 434800, "start": 4348.0, "end": 4352.96, "text": " processes but we just don't observe everything and so we describe it by probability now in quantum", "tokens": [50364, 7555, 457, 321, 445, 500, 380, 11441, 1203, 293, 370, 321, 6786, 309, 538, 8482, 586, 294, 13018, 50612], "temperature": 0.0, "avg_logprob": -0.05744550297561201, "compression_ratio": 1.9224489795918367, "no_speech_prob": 0.0070062056183815}, {"id": 775, "seek": 434800, "start": 4352.96, "end": 4358.56, "text": " mechanics it's very similar to taking the square root of a negative number in some sense it's like", "tokens": [50612, 12939, 309, 311, 588, 2531, 281, 1940, 264, 3732, 5593, 295, 257, 3671, 1230, 294, 512, 2020, 309, 311, 411, 50892], "temperature": 0.0, "avg_logprob": -0.05744550297561201, "compression_ratio": 1.9224489795918367, "no_speech_prob": 0.0070062056183815}, {"id": 776, "seek": 434800, "start": 4358.56, "end": 4363.76, "text": " you let me put another way so it's very much like taking the square root of a probability", "tokens": [50892, 291, 718, 385, 829, 1071, 636, 370, 309, 311, 588, 709, 411, 1940, 264, 3732, 5593, 295, 257, 8482, 51152], "temperature": 0.0, "avg_logprob": -0.05744550297561201, "compression_ratio": 1.9224489795918367, "no_speech_prob": 0.0070062056183815}, {"id": 777, "seek": 434800, "start": 4363.76, "end": 4369.6, "text": " which can actually become negative so minus one squared is one right okay or let's say", "tokens": [51152, 597, 393, 767, 1813, 3671, 370, 3175, 472, 8889, 307, 472, 558, 1392, 420, 718, 311, 584, 51444], "temperature": 0.0, "avg_logprob": -0.05744550297561201, "compression_ratio": 1.9224489795918367, "no_speech_prob": 0.0070062056183815}, {"id": 778, "seek": 434800, "start": 4369.6, "end": 4375.92, "text": " minus two squared is four four is your probability and minus two could be your quantum amplitude", "tokens": [51444, 3175, 732, 8889, 307, 1451, 1451, 307, 428, 8482, 293, 3175, 732, 727, 312, 428, 13018, 27433, 51760], "temperature": 0.0, "avg_logprob": -0.05744550297561201, "compression_ratio": 1.9224489795918367, "no_speech_prob": 0.0070062056183815}, {"id": 779, "seek": 437592, "start": 4376.0, "end": 4382.56, "text": " this thing can be negative and the bizarre thing is that if you describe a system by these", "tokens": [50368, 341, 551, 393, 312, 3671, 293, 264, 18265, 551, 307, 300, 498, 291, 6786, 257, 1185, 538, 613, 50696], "temperature": 0.0, "avg_logprob": -0.06369433544649936, "compression_ratio": 2.082608695652174, "no_speech_prob": 0.0022852288093417883}, {"id": 780, "seek": 437592, "start": 4382.56, "end": 4388.08, "text": " quantum amplitude these square roots then they can cancel which is this this is the counter", "tokens": [50696, 13018, 27433, 613, 3732, 10669, 550, 436, 393, 10373, 597, 307, 341, 341, 307, 264, 5682, 50972], "temperature": 0.0, "avg_logprob": -0.06369433544649936, "compression_ratio": 2.082608695652174, "no_speech_prob": 0.0022852288093417883}, {"id": 781, "seek": 437592, "start": 4388.08, "end": 4393.12, "text": " intuitive part which is you can have a probability for an event or an amplitude for an event and then", "tokens": [50972, 21769, 644, 597, 307, 291, 393, 362, 257, 8482, 337, 364, 2280, 420, 364, 27433, 337, 364, 2280, 293, 550, 51224], "temperature": 0.0, "avg_logprob": -0.06369433544649936, "compression_ratio": 2.082608695652174, "no_speech_prob": 0.0022852288093417883}, {"id": 782, "seek": 437592, "start": 4393.12, "end": 4397.52, "text": " for you have an amplitude for another event and you would think that if there's two probabilities", "tokens": [51224, 337, 291, 362, 364, 27433, 337, 1071, 2280, 293, 291, 576, 519, 300, 498, 456, 311, 732, 33783, 51444], "temperature": 0.0, "avg_logprob": -0.06369433544649936, "compression_ratio": 2.082608695652174, "no_speech_prob": 0.0022852288093417883}, {"id": 783, "seek": 437592, "start": 4397.52, "end": 4402.32, "text": " for that event to happen then the probability of that event should grow but in quantum mechanics", "tokens": [51444, 337, 300, 2280, 281, 1051, 550, 264, 8482, 295, 300, 2280, 820, 1852, 457, 294, 13018, 12939, 51684], "temperature": 0.0, "avg_logprob": -0.06369433544649936, "compression_ratio": 2.082608695652174, "no_speech_prob": 0.0022852288093417883}, {"id": 784, "seek": 440232, "start": 4402.32, "end": 4407.04, "text": " they can cancel and then the probability is suddenly zero that the event happens so this", "tokens": [50364, 436, 393, 10373, 293, 550, 264, 8482, 307, 5800, 4018, 300, 264, 2280, 2314, 370, 341, 50600], "temperature": 0.0, "avg_logprob": -0.051298996070762735, "compression_ratio": 1.669683257918552, "no_speech_prob": 0.009248157031834126}, {"id": 785, "seek": 440232, "start": 4407.04, "end": 4413.36, "text": " seems bizarre but nature has chosen this theory of statistics anyway and so it behooves us to", "tokens": [50600, 2544, 18265, 457, 3687, 575, 8614, 341, 5261, 295, 12523, 4033, 293, 370, 309, 312, 19069, 977, 505, 281, 50916], "temperature": 0.0, "avg_logprob": -0.051298996070762735, "compression_ratio": 1.669683257918552, "no_speech_prob": 0.009248157031834126}, {"id": 786, "seek": 440232, "start": 4413.36, "end": 4422.799999999999, "text": " look into this more so first question is can you write down maybe even normal classical problems", "tokens": [50916, 574, 666, 341, 544, 370, 700, 1168, 307, 393, 291, 2464, 760, 1310, 754, 2710, 13735, 2740, 51388], "temperature": 0.0, "avg_logprob": -0.051298996070762735, "compression_ratio": 1.669683257918552, "no_speech_prob": 0.009248157031834126}, {"id": 787, "seek": 440232, "start": 4422.799999999999, "end": 4428.32, "text": " more conveniently in this quantum statistics and here I always remind myself when I first", "tokens": [51388, 544, 44375, 294, 341, 13018, 12523, 293, 510, 286, 1009, 4160, 2059, 562, 286, 700, 51664], "temperature": 0.0, "avg_logprob": -0.051298996070762735, "compression_ratio": 1.669683257918552, "no_speech_prob": 0.009248157031834126}, {"id": 788, "seek": 442832, "start": 4428.32, "end": 4434.48, "text": " learned complex numbers when you learn to solve the damped oscillator equation you can do it in", "tokens": [50364, 3264, 3997, 3547, 562, 291, 1466, 281, 5039, 264, 19498, 292, 43859, 5367, 291, 393, 360, 309, 294, 50672], "temperature": 0.0, "avg_logprob": -0.056610634747673486, "compression_ratio": 1.7954545454545454, "no_speech_prob": 0.01715242490172386}, {"id": 789, "seek": 442832, "start": 4434.48, "end": 4440.5599999999995, "text": " a complicated way or you can go to complex numbers and then suddenly it gets very easy to do it and", "tokens": [50672, 257, 6179, 636, 420, 291, 393, 352, 281, 3997, 3547, 293, 550, 5800, 309, 2170, 588, 1858, 281, 360, 309, 293, 50976], "temperature": 0.0, "avg_logprob": -0.056610634747673486, "compression_ratio": 1.7954545454545454, "no_speech_prob": 0.01715242490172386}, {"id": 790, "seek": 442832, "start": 4440.5599999999995, "end": 4447.44, "text": " so you can imagine that there is things to compute in classical statistics that are actually either", "tokens": [50976, 370, 291, 393, 3811, 300, 456, 307, 721, 281, 14722, 294, 13735, 12523, 300, 366, 767, 2139, 51320], "temperature": 0.0, "avg_logprob": -0.056610634747673486, "compression_ratio": 1.7954545454545454, "no_speech_prob": 0.01715242490172386}, {"id": 791, "seek": 442832, "start": 4447.44, "end": 4453.679999999999, "text": " shortcuts by using quantum mechanics somehow and and so the first thing that we've tried to do with", "tokens": [51320, 34620, 538, 1228, 13018, 12939, 6063, 293, 293, 370, 264, 700, 551, 300, 321, 600, 3031, 281, 360, 365, 51632], "temperature": 0.0, "avg_logprob": -0.056610634747673486, "compression_ratio": 1.7954545454545454, "no_speech_prob": 0.01715242490172386}, {"id": 792, "seek": 445368, "start": 4453.76, "end": 4460.88, "text": " quantum mechanics in deep learning is to say can we just design an architecture that would be", "tokens": [50368, 13018, 12939, 294, 2452, 2539, 307, 281, 584, 393, 321, 445, 1715, 364, 9482, 300, 576, 312, 50724], "temperature": 0.0, "avg_logprob": -0.08389807896441724, "compression_ratio": 1.8725490196078431, "no_speech_prob": 0.03253159672021866}, {"id": 793, "seek": 445368, "start": 4460.88, "end": 4466.64, "text": " naturally a natural fit to this quantum mechanical description of the world but we still want to be", "tokens": [50724, 8195, 257, 3303, 3318, 281, 341, 13018, 12070, 3855, 295, 264, 1002, 457, 321, 920, 528, 281, 312, 51012], "temperature": 0.0, "avg_logprob": -0.08389807896441724, "compression_ratio": 1.8725490196078431, "no_speech_prob": 0.03253159672021866}, {"id": 794, "seek": 445368, "start": 4466.64, "end": 4471.84, "text": " able to run it on a classical computer so we just want to describe this we just want to", "tokens": [51012, 1075, 281, 1190, 309, 322, 257, 13735, 3820, 370, 321, 445, 528, 281, 6786, 341, 321, 445, 528, 281, 51272], "temperature": 0.0, "avg_logprob": -0.08389807896441724, "compression_ratio": 1.8725490196078431, "no_speech_prob": 0.03253159672021866}, {"id": 795, "seek": 445368, "start": 4472.4800000000005, "end": 4477.6, "text": " harvest this new degrees of freedom that we have from quantum mechanics and so that was a paper that", "tokens": [51304, 11917, 341, 777, 5310, 295, 5645, 300, 321, 362, 490, 13018, 12939, 293, 370, 300, 390, 257, 3035, 300, 51560], "temperature": 0.0, "avg_logprob": -0.08389807896441724, "compression_ratio": 1.8725490196078431, "no_speech_prob": 0.03253159672021866}, {"id": 796, "seek": 447760, "start": 4477.6, "end": 4483.52, "text": " we recently pushed on the archive which is quantum deformed neural networks which we basically", "tokens": [50364, 321, 3938, 9152, 322, 264, 23507, 597, 307, 13018, 368, 22892, 18161, 9590, 597, 321, 1936, 50660], "temperature": 0.0, "avg_logprob": -0.07854813758773033, "compression_ratio": 1.8527131782945736, "no_speech_prob": 0.005134879145771265}, {"id": 797, "seek": 447760, "start": 4483.52, "end": 4488.320000000001, "text": " first say okay what if we would take a normal neural net and implement it on a quantum computer", "tokens": [50660, 700, 584, 1392, 437, 498, 321, 576, 747, 257, 2710, 18161, 2533, 293, 4445, 309, 322, 257, 13018, 3820, 50900], "temperature": 0.0, "avg_logprob": -0.07854813758773033, "compression_ratio": 1.8527131782945736, "no_speech_prob": 0.005134879145771265}, {"id": 798, "seek": 447760, "start": 4488.320000000001, "end": 4494.56, "text": " and then we slightly deform it into something where states get entangled and this entanglement is", "tokens": [50900, 293, 550, 321, 4748, 36094, 309, 666, 746, 689, 4368, 483, 948, 39101, 293, 341, 948, 656, 3054, 307, 51212], "temperature": 0.0, "avg_logprob": -0.07854813758773033, "compression_ratio": 1.8527131782945736, "no_speech_prob": 0.005134879145771265}, {"id": 799, "seek": 447760, "start": 4494.56, "end": 4501.4400000000005, "text": " another strange phenomenon in quantum mechanics where you can create states which you cannot", "tokens": [51212, 1071, 5861, 14029, 294, 13018, 12939, 689, 291, 393, 1884, 4368, 597, 291, 2644, 51556], "temperature": 0.0, "avg_logprob": -0.07854813758773033, "compression_ratio": 1.8527131782945736, "no_speech_prob": 0.005134879145771265}, {"id": 800, "seek": 447760, "start": 4501.4400000000005, "end": 4507.360000000001, "text": " really create classically superpositions of states and and so by doing it in this particular way", "tokens": [51556, 534, 1884, 1508, 984, 1687, 30010, 2451, 295, 4368, 293, 293, 370, 538, 884, 309, 294, 341, 1729, 636, 51852], "temperature": 0.0, "avg_logprob": -0.07854813758773033, "compression_ratio": 1.8527131782945736, "no_speech_prob": 0.005134879145771265}, {"id": 801, "seek": 450736, "start": 4507.36, "end": 4512.0, "text": " we could still run it efficiently on a classical computer but it's just a very different beast", "tokens": [50364, 321, 727, 920, 1190, 309, 19621, 322, 257, 13735, 3820, 457, 309, 311, 445, 257, 588, 819, 13464, 50596], "temperature": 0.0, "avg_logprob": -0.030811465011452727, "compression_ratio": 1.8494208494208495, "no_speech_prob": 0.0015969584928825498}, {"id": 802, "seek": 450736, "start": 4512.0, "end": 4516.719999999999, "text": " than a normal neural network so that's already to me very interesting and then of course the big", "tokens": [50596, 813, 257, 2710, 18161, 3209, 370, 300, 311, 1217, 281, 385, 588, 1880, 293, 550, 295, 1164, 264, 955, 50832], "temperature": 0.0, "avg_logprob": -0.030811465011452727, "compression_ratio": 1.8494208494208495, "no_speech_prob": 0.0015969584928825498}, {"id": 803, "seek": 450736, "start": 4516.719999999999, "end": 4523.04, "text": " prize the big bonus is that if you adhere to this way of describing what's happening is that there", "tokens": [50832, 12818, 264, 955, 10882, 307, 300, 498, 291, 33584, 281, 341, 636, 295, 16141, 437, 311, 2737, 307, 300, 456, 51148], "temperature": 0.0, "avg_logprob": -0.030811465011452727, "compression_ratio": 1.8494208494208495, "no_speech_prob": 0.0015969584928825498}, {"id": 804, "seek": 450736, "start": 4523.04, "end": 4527.44, "text": " is the opportunity to be able to run things very efficiently on a quantum computer so now you can", "tokens": [51148, 307, 264, 2650, 281, 312, 1075, 281, 1190, 721, 588, 19621, 322, 257, 13018, 3820, 370, 586, 291, 393, 51368], "temperature": 0.0, "avg_logprob": -0.030811465011452727, "compression_ratio": 1.8494208494208495, "no_speech_prob": 0.0015969584928825498}, {"id": 805, "seek": 450736, "start": 4527.44, "end": 4533.12, "text": " design your neural network in such a way that classically actually it will be very hard to", "tokens": [51368, 1715, 428, 18161, 3209, 294, 1270, 257, 636, 300, 1508, 984, 767, 309, 486, 312, 588, 1152, 281, 51652], "temperature": 0.0, "avg_logprob": -0.030811465011452727, "compression_ratio": 1.8494208494208495, "no_speech_prob": 0.0015969584928825498}, {"id": 806, "seek": 453312, "start": 4533.12, "end": 4539.04, "text": " simulate it but then on a quantum computer you could potentially simulate it very efficiently", "tokens": [50364, 27817, 309, 457, 550, 322, 257, 13018, 3820, 291, 727, 7263, 27817, 309, 588, 19621, 50660], "temperature": 0.0, "avg_logprob": -0.08005570392219388, "compression_ratio": 1.8212927756653992, "no_speech_prob": 0.010961024090647697}, {"id": 807, "seek": 453312, "start": 4539.04, "end": 4543.76, "text": " and and of course we don't have quantum computer so it's very hard to actually prove your point", "tokens": [50660, 293, 293, 295, 1164, 321, 500, 380, 362, 13018, 3820, 370, 309, 311, 588, 1152, 281, 767, 7081, 428, 935, 50896], "temperature": 0.0, "avg_logprob": -0.08005570392219388, "compression_ratio": 1.8212927756653992, "no_speech_prob": 0.010961024090647697}, {"id": 808, "seek": 453312, "start": 4543.76, "end": 4548.96, "text": " but that also what makes it somewhat exciting in that paper specifically you make you make lots of", "tokens": [50896, 457, 300, 611, 437, 1669, 309, 8344, 4670, 294, 300, 3035, 4682, 291, 652, 291, 652, 3195, 295, 51156], "temperature": 0.0, "avg_logprob": -0.08005570392219388, "compression_ratio": 1.8212927756653992, "no_speech_prob": 0.010961024090647697}, {"id": 809, "seek": 453312, "start": 4548.96, "end": 4554.96, "text": " references and connections to the Bayesian way of doing machine learning could you what's the", "tokens": [51156, 15400, 293, 9271, 281, 264, 7840, 42434, 636, 295, 884, 3479, 2539, 727, 291, 437, 311, 264, 51456], "temperature": 0.0, "avg_logprob": -0.08005570392219388, "compression_ratio": 1.8212927756653992, "no_speech_prob": 0.010961024090647697}, {"id": 810, "seek": 453312, "start": 4554.96, "end": 4561.12, "text": " connection there because it seems different both are I agree both are statistics and you already", "tokens": [51456, 4984, 456, 570, 309, 2544, 819, 1293, 366, 286, 3986, 1293, 366, 12523, 293, 291, 1217, 51764], "temperature": 0.0, "avg_logprob": -0.08005570392219388, "compression_ratio": 1.8212927756653992, "no_speech_prob": 0.010961024090647697}, {"id": 811, "seek": 456112, "start": 4561.12, "end": 4566.72, "text": " mentioned the square roots of probabilities but how do you connect the sort of uncertainty", "tokens": [50364, 2835, 264, 3732, 10669, 295, 33783, 457, 577, 360, 291, 1745, 264, 1333, 295, 15697, 50644], "temperature": 0.0, "avg_logprob": -0.06589433211314527, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.001262184465304017}, {"id": 812, "seek": 456112, "start": 4566.72, "end": 4575.12, "text": " quantification in the Bayesian way with how particles move quantum mechanics is not necessarily", "tokens": [50644, 4426, 3774, 294, 264, 7840, 42434, 636, 365, 577, 10007, 1286, 13018, 12939, 307, 406, 4725, 51064], "temperature": 0.0, "avg_logprob": -0.06589433211314527, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.001262184465304017}, {"id": 813, "seek": 456112, "start": 4575.12, "end": 4582.48, "text": " about particles so you can just you can write quantum mechanics on just like states you can just", "tokens": [51064, 466, 10007, 370, 291, 393, 445, 291, 393, 2464, 13018, 12939, 322, 445, 411, 4368, 291, 393, 445, 51432], "temperature": 0.0, "avg_logprob": -0.06589433211314527, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.001262184465304017}, {"id": 814, "seek": 456112, "start": 4582.48, "end": 4588.72, "text": " write down a number of classical states like I say a sequence of zeros and ones and there's an", "tokens": [51432, 2464, 760, 257, 1230, 295, 13735, 4368, 411, 286, 584, 257, 8310, 295, 35193, 293, 2306, 293, 456, 311, 364, 51744], "temperature": 0.0, "avg_logprob": -0.06589433211314527, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.001262184465304017}, {"id": 815, "seek": 458872, "start": 4588.72, "end": 4594.0, "text": " exponential number of these states and then you can say classically I can only be in one of these", "tokens": [50364, 21510, 1230, 295, 613, 4368, 293, 550, 291, 393, 584, 1508, 984, 286, 393, 787, 312, 294, 472, 295, 613, 50628], "temperature": 0.0, "avg_logprob": -0.06511234153400768, "compression_ratio": 1.838095238095238, "no_speech_prob": 0.0007914030575193465}, {"id": 816, "seek": 458872, "start": 4594.0, "end": 4598.320000000001, "text": " states but in quantum mechanics I can be in any linear combination of these states which", "tokens": [50628, 4368, 457, 294, 13018, 12939, 286, 393, 312, 294, 604, 8213, 6562, 295, 613, 4368, 597, 50844], "temperature": 0.0, "avg_logprob": -0.06511234153400768, "compression_ratio": 1.838095238095238, "no_speech_prob": 0.0007914030575193465}, {"id": 817, "seek": 458872, "start": 4598.320000000001, "end": 4606.08, "text": " should have is a bigger space now what we did in that paper was to say we can treat both the world", "tokens": [50844, 820, 362, 307, 257, 3801, 1901, 586, 437, 321, 630, 294, 300, 3035, 390, 281, 584, 321, 393, 2387, 1293, 264, 1002, 51232], "temperature": 0.0, "avg_logprob": -0.06511234153400768, "compression_ratio": 1.838095238095238, "no_speech_prob": 0.0007914030575193465}, {"id": 818, "seek": 458872, "start": 4606.08, "end": 4613.2, "text": " state as well as the parameter state as a quantum we describe it by a quantum wave function and then", "tokens": [51232, 1785, 382, 731, 382, 264, 13075, 1785, 382, 257, 13018, 321, 6786, 309, 538, 257, 13018, 5772, 2445, 293, 550, 51588], "temperature": 0.0, "avg_logprob": -0.06511234153400768, "compression_ratio": 1.838095238095238, "no_speech_prob": 0.0007914030575193465}, {"id": 819, "seek": 461320, "start": 4613.28, "end": 4618.72, "text": " we entangle these different states which is similar to saying that I take my state classical", "tokens": [50368, 321, 948, 7846, 613, 819, 4368, 597, 307, 2531, 281, 1566, 300, 286, 747, 452, 1785, 13735, 50640], "temperature": 0.0, "avg_logprob": -0.07653808121634002, "compression_ratio": 1.9156118143459915, "no_speech_prob": 0.001727070426568389}, {"id": 820, "seek": 461320, "start": 4618.72, "end": 4625.44, "text": " state x I multiply it by a matrix of parameters and I get a new state out so here the analogy would", "tokens": [50640, 1785, 2031, 286, 12972, 309, 538, 257, 8141, 295, 9834, 293, 286, 483, 257, 777, 1785, 484, 370, 510, 264, 21663, 576, 50976], "temperature": 0.0, "avg_logprob": -0.07653808121634002, "compression_ratio": 1.9156118143459915, "no_speech_prob": 0.001727070426568389}, {"id": 821, "seek": 461320, "start": 4625.44, "end": 4631.04, "text": " be I have my quantum superposition of classical states I have a quantum superposition of", "tokens": [50976, 312, 286, 362, 452, 13018, 1687, 38078, 295, 13735, 4368, 286, 362, 257, 13018, 1687, 38078, 295, 51256], "temperature": 0.0, "avg_logprob": -0.07653808121634002, "compression_ratio": 1.9156118143459915, "no_speech_prob": 0.001727070426568389}, {"id": 822, "seek": 461320, "start": 4631.679999999999, "end": 4636.08, "text": " parameter states and then there are some processes where we get entangled together", "tokens": [51288, 13075, 4368, 293, 550, 456, 366, 512, 7555, 689, 321, 483, 948, 39101, 1214, 51508], "temperature": 0.0, "avg_logprob": -0.07653808121634002, "compression_ratio": 1.9156118143459915, "no_speech_prob": 0.001727070426568389}, {"id": 823, "seek": 461320, "start": 4636.72, "end": 4641.5199999999995, "text": " and then I do a measurement which is now a function of both the parameters as well as the", "tokens": [51540, 293, 550, 286, 360, 257, 13160, 597, 307, 586, 257, 2445, 295, 1293, 264, 9834, 382, 731, 382, 264, 51780], "temperature": 0.0, "avg_logprob": -0.07653808121634002, "compression_ratio": 1.9156118143459915, "no_speech_prob": 0.001727070426568389}, {"id": 824, "seek": 464152, "start": 4642.080000000001, "end": 4648.160000000001, "text": " inputs and you train it to give you measurements that with high probability give you the answer", "tokens": [50392, 15743, 293, 291, 3847, 309, 281, 976, 291, 15383, 300, 365, 1090, 8482, 976, 291, 264, 1867, 50696], "temperature": 0.0, "avg_logprob": -0.04796067873636881, "compression_ratio": 1.8622047244094488, "no_speech_prob": 0.004004405811429024}, {"id": 825, "seek": 464152, "start": 4648.160000000001, "end": 4652.160000000001, "text": " that you want so that would be the training process now there is actually a very precise", "tokens": [50696, 300, 291, 528, 370, 300, 576, 312, 264, 3097, 1399, 586, 456, 307, 767, 257, 588, 13600, 50896], "temperature": 0.0, "avg_logprob": -0.04796067873636881, "compression_ratio": 1.8622047244094488, "no_speech_prob": 0.004004405811429024}, {"id": 826, "seek": 464152, "start": 4652.160000000001, "end": 4658.88, "text": " way in which you can relate Bayesian posterior inference in quantum mechanics but that's a fairly", "tokens": [50896, 636, 294, 597, 291, 393, 10961, 7840, 42434, 33529, 38253, 294, 13018, 12939, 457, 300, 311, 257, 6457, 51232], "temperature": 0.0, "avg_logprob": -0.04796067873636881, "compression_ratio": 1.8622047244094488, "no_speech_prob": 0.004004405811429024}, {"id": 827, "seek": 464152, "start": 4658.88, "end": 4664.0, "text": " technical story but there is a using density matrices there is a fairly precise way in which", "tokens": [51232, 6191, 1657, 457, 456, 307, 257, 1228, 10305, 32284, 456, 307, 257, 6457, 13600, 636, 294, 597, 51488], "temperature": 0.0, "avg_logprob": -0.04796067873636881, "compression_ratio": 1.8622047244094488, "no_speech_prob": 0.004004405811429024}, {"id": 828, "seek": 464152, "start": 4664.0, "end": 4669.120000000001, "text": " you can say I have a state described by a density matrix and if I do a measurement I condition on", "tokens": [51488, 291, 393, 584, 286, 362, 257, 1785, 7619, 538, 257, 10305, 8141, 293, 498, 286, 360, 257, 13160, 286, 4188, 322, 51744], "temperature": 0.0, "avg_logprob": -0.04796067873636881, "compression_ratio": 1.8622047244094488, "no_speech_prob": 0.004004405811429024}, {"id": 829, "seek": 466912, "start": 4669.12, "end": 4674.64, "text": " something and a renormalize and stuff like that so that's possible so there are two things like", "tokens": [50364, 746, 293, 257, 8124, 24440, 1125, 293, 1507, 411, 300, 370, 300, 311, 1944, 370, 456, 366, 732, 721, 411, 50640], "temperature": 0.0, "avg_logprob": -0.06482394536336263, "compression_ratio": 1.7914691943127963, "no_speech_prob": 0.002419878961518407}, {"id": 830, "seek": 466912, "start": 4674.64, "end": 4681.92, "text": " first of all the quantum neural network formulation can be very slow on a classic computer but", "tokens": [50640, 700, 295, 439, 264, 13018, 18161, 3209, 37642, 393, 312, 588, 2964, 322, 257, 7230, 3820, 457, 51004], "temperature": 0.0, "avg_logprob": -0.06482394536336263, "compression_ratio": 1.7914691943127963, "no_speech_prob": 0.002419878961518407}, {"id": 831, "seek": 466912, "start": 4681.92, "end": 4688.32, "text": " fast on a quantum computer on the other hand people do run like Bayesian inference on classical", "tokens": [51004, 2370, 322, 257, 13018, 3820, 322, 264, 661, 1011, 561, 360, 1190, 411, 7840, 42434, 38253, 322, 13735, 51324], "temperature": 0.0, "avg_logprob": -0.06482394536336263, "compression_ratio": 1.7914691943127963, "no_speech_prob": 0.002419878961518407}, {"id": 832, "seek": 466912, "start": 4688.32, "end": 4696.4, "text": " computers what makes the quantum neural networks that much harder to compute yeah it's this", "tokens": [51324, 10807, 437, 1669, 264, 13018, 18161, 9590, 300, 709, 6081, 281, 14722, 1338, 309, 311, 341, 51728], "temperature": 0.0, "avg_logprob": -0.06482394536336263, "compression_ratio": 1.7914691943127963, "no_speech_prob": 0.002419878961518407}, {"id": 833, "seek": 469640, "start": 4696.48, "end": 4702.32, "text": " entanglement issue yeah so in so classically I agree there is an analogy in classical", "tokens": [50368, 948, 656, 3054, 2734, 1338, 370, 294, 370, 1508, 984, 286, 3986, 456, 307, 364, 21663, 294, 13735, 50660], "temperature": 0.0, "avg_logprob": -0.07476342717806499, "compression_ratio": 1.8724279835390947, "no_speech_prob": 0.01163127925246954}, {"id": 834, "seek": 469640, "start": 4703.2, "end": 4709.599999999999, "text": " statistics where this looks very similar which is for instance if I have a exponentially large", "tokens": [50704, 12523, 689, 341, 1542, 588, 2531, 597, 307, 337, 5197, 498, 286, 362, 257, 37330, 2416, 51024], "temperature": 0.0, "avg_logprob": -0.07476342717806499, "compression_ratio": 1.8724279835390947, "no_speech_prob": 0.01163127925246954}, {"id": 835, "seek": 469640, "start": 4709.599999999999, "end": 4715.36, "text": " state space and I write down a probability distribution over all of these possible states", "tokens": [51024, 1785, 1901, 293, 286, 2464, 760, 257, 8482, 7316, 670, 439, 295, 613, 1944, 4368, 51312], "temperature": 0.0, "avg_logprob": -0.07476342717806499, "compression_ratio": 1.8724279835390947, "no_speech_prob": 0.01163127925246954}, {"id": 836, "seek": 469640, "start": 4716.08, "end": 4720.5599999999995, "text": " where they have a number a positive number that sums to one for each one of these exponentially", "tokens": [51348, 689, 436, 362, 257, 1230, 257, 3353, 1230, 300, 34499, 281, 472, 337, 1184, 472, 295, 613, 37330, 51572], "temperature": 0.0, "avg_logprob": -0.07476342717806499, "compression_ratio": 1.8724279835390947, "no_speech_prob": 0.01163127925246954}, {"id": 837, "seek": 469640, "start": 4720.5599999999995, "end": 4725.44, "text": " large states and if I ask you now compute an average of a function over this probability", "tokens": [51572, 2416, 4368, 293, 498, 286, 1029, 291, 586, 14722, 364, 4274, 295, 257, 2445, 670, 341, 8482, 51816], "temperature": 0.0, "avg_logprob": -0.07476342717806499, "compression_ratio": 1.8724279835390947, "no_speech_prob": 0.01163127925246954}, {"id": 838, "seek": 472544, "start": 4725.44, "end": 4729.04, "text": " distribution you can't do it because there's an exponentially large number of things that you", "tokens": [50364, 7316, 291, 393, 380, 360, 309, 570, 456, 311, 364, 37330, 2416, 1230, 295, 721, 300, 291, 50544], "temperature": 0.0, "avg_logprob": -0.04537860945899888, "compression_ratio": 1.8784313725490196, "no_speech_prob": 0.010801567696034908}, {"id": 839, "seek": 472544, "start": 4729.04, "end": 4734.719999999999, "text": " would have to sum and so we have ways to deal with it which is sampling from these distributions or", "tokens": [50544, 576, 362, 281, 2408, 293, 370, 321, 362, 2098, 281, 2028, 365, 309, 597, 307, 21179, 490, 613, 37870, 420, 50828], "temperature": 0.0, "avg_logprob": -0.04537860945899888, "compression_ratio": 1.8784313725490196, "no_speech_prob": 0.010801567696034908}, {"id": 840, "seek": 472544, "start": 4734.719999999999, "end": 4741.28, "text": " variational approximations and anyway we have to approximate this state of affairs now in quantum", "tokens": [50828, 3034, 1478, 8542, 763, 293, 4033, 321, 362, 281, 30874, 341, 1785, 295, 17478, 586, 294, 13018, 51156], "temperature": 0.0, "avg_logprob": -0.04537860945899888, "compression_ratio": 1.8784313725490196, "no_speech_prob": 0.010801567696034908}, {"id": 841, "seek": 472544, "start": 4741.28, "end": 4747.759999999999, "text": " that's fairly similar so there's you you face a similar exponential problem and you can also do", "tokens": [51156, 300, 311, 6457, 2531, 370, 456, 311, 291, 291, 1851, 257, 2531, 21510, 1154, 293, 291, 393, 611, 360, 51480], "temperature": 0.0, "avg_logprob": -0.04537860945899888, "compression_ratio": 1.8784313725490196, "no_speech_prob": 0.010801567696034908}, {"id": 842, "seek": 472544, "start": 4747.759999999999, "end": 4753.5199999999995, "text": " approximations to get around that and but the interesting part is that in quantum mechanics", "tokens": [51480, 8542, 763, 281, 483, 926, 300, 293, 457, 264, 1880, 644, 307, 300, 294, 13018, 12939, 51768], "temperature": 0.0, "avg_logprob": -0.04537860945899888, "compression_ratio": 1.8784313725490196, "no_speech_prob": 0.010801567696034908}, {"id": 843, "seek": 475352, "start": 4753.6, "end": 4758.88, "text": " you can for instance do a measurement and a measurement is something that you know that is", "tokens": [50368, 291, 393, 337, 5197, 360, 257, 13160, 293, 257, 13160, 307, 746, 300, 291, 458, 300, 307, 50632], "temperature": 0.0, "avg_logprob": -0.0761627197265625, "compression_ratio": 1.9153225806451613, "no_speech_prob": 0.0014318497851490974}, {"id": 844, "seek": 475352, "start": 4759.52, "end": 4764.56, "text": " it gets a physical thing and it's not very hard to do but it will be an operation which looks", "tokens": [50664, 309, 2170, 257, 4001, 551, 293, 309, 311, 406, 588, 1152, 281, 360, 457, 309, 486, 312, 364, 6916, 597, 1542, 50916], "temperature": 0.0, "avg_logprob": -0.0761627197265625, "compression_ratio": 1.9153225806451613, "no_speech_prob": 0.0014318497851490974}, {"id": 845, "seek": 475352, "start": 4764.56, "end": 4769.52, "text": " like sampling something down to a particular classical state again and it does look like the", "tokens": [50916, 411, 21179, 746, 760, 281, 257, 1729, 13735, 1785, 797, 293, 309, 775, 574, 411, 264, 51164], "temperature": 0.0, "avg_logprob": -0.0761627197265625, "compression_ratio": 1.9153225806451613, "no_speech_prob": 0.0014318497851490974}, {"id": 846, "seek": 475352, "start": 4769.52, "end": 4775.52, "text": " sampling operation that we do in sort of artificially in probability theory but it's also true that", "tokens": [51164, 21179, 6916, 300, 321, 360, 294, 1333, 295, 39905, 2270, 294, 8482, 5261, 457, 309, 311, 611, 2074, 300, 51464], "temperature": 0.0, "avg_logprob": -0.0761627197265625, "compression_ratio": 1.9153225806451613, "no_speech_prob": 0.0014318497851490974}, {"id": 847, "seek": 475352, "start": 4775.52, "end": 4779.360000000001, "text": " quantum computers can in principle compute things that classical computers can't compute and they", "tokens": [51464, 13018, 10807, 393, 294, 8665, 14722, 721, 300, 13735, 10807, 393, 380, 14722, 293, 436, 51656], "temperature": 0.0, "avg_logprob": -0.0761627197265625, "compression_ratio": 1.9153225806451613, "no_speech_prob": 0.0014318497851490974}, {"id": 848, "seek": 477936, "start": 4779.839999999999, "end": 4784.0, "text": " can actually compute it much faster whether that actually maps to the things that we are", "tokens": [50388, 393, 767, 14722, 309, 709, 4663, 1968, 300, 767, 11317, 281, 264, 721, 300, 321, 366, 50596], "temperature": 0.0, "avg_logprob": -0.06073493186873619, "compression_ratio": 1.9623430962343096, "no_speech_prob": 0.023671865463256836}, {"id": 849, "seek": 477936, "start": 4784.0, "end": 4789.28, "text": " interested in is not so clear so that's it's not at all clear right now that we will actually build", "tokens": [50596, 3102, 294, 307, 406, 370, 1850, 370, 300, 311, 309, 311, 406, 412, 439, 1850, 558, 586, 300, 321, 486, 767, 1322, 50860], "temperature": 0.0, "avg_logprob": -0.06073493186873619, "compression_ratio": 1.9623430962343096, "no_speech_prob": 0.023671865463256836}, {"id": 850, "seek": 477936, "start": 4789.28, "end": 4797.92, "text": " quantum neural networks that are generalizing a lot better on classical problems right if you", "tokens": [50860, 13018, 18161, 9590, 300, 366, 2674, 3319, 257, 688, 1101, 322, 13735, 2740, 558, 498, 291, 51292], "temperature": 0.0, "avg_logprob": -0.06073493186873619, "compression_ratio": 1.9623430962343096, "no_speech_prob": 0.023671865463256836}, {"id": 851, "seek": 477936, "start": 4797.92, "end": 4804.24, "text": " want to do classical predictions does it actually help to build a neural network that can run", "tokens": [51292, 528, 281, 360, 13735, 21264, 775, 309, 767, 854, 281, 1322, 257, 18161, 3209, 300, 393, 1190, 51608], "temperature": 0.0, "avg_logprob": -0.06073493186873619, "compression_ratio": 1.9623430962343096, "no_speech_prob": 0.023671865463256836}, {"id": 852, "seek": 477936, "start": 4804.24, "end": 4808.88, "text": " efficiently on a quantum computer that can do these predictions much better that's not known", "tokens": [51608, 19621, 322, 257, 13018, 3820, 300, 393, 360, 613, 21264, 709, 1101, 300, 311, 406, 2570, 51840], "temperature": 0.0, "avg_logprob": -0.06073493186873619, "compression_ratio": 1.9623430962343096, "no_speech_prob": 0.023671865463256836}, {"id": 853, "seek": 480888, "start": 4808.88, "end": 4813.04, "text": " but that's what makes it exciting in my opinion because you can try to do it now there's also", "tokens": [50364, 457, 300, 311, 437, 1669, 309, 4670, 294, 452, 4800, 570, 291, 393, 853, 281, 360, 309, 586, 456, 311, 611, 50572], "temperature": 0.0, "avg_logprob": -0.07066822935033727, "compression_ratio": 1.776061776061776, "no_speech_prob": 0.0016152823809534311}, {"id": 854, "seek": 480888, "start": 4814.16, "end": 4818.64, "text": " functions that you can't even do classically you have to do quantum mechanically but I don't", "tokens": [50628, 6828, 300, 291, 393, 380, 754, 360, 1508, 984, 291, 362, 281, 360, 13018, 4236, 984, 457, 286, 500, 380, 50852], "temperature": 0.0, "avg_logprob": -0.07066822935033727, "compression_ratio": 1.776061776061776, "no_speech_prob": 0.0016152823809534311}, {"id": 855, "seek": 480888, "start": 4818.64, "end": 4825.6, "text": " know how relevant they are for AI fascinating can we conceivably say that at least one let's say", "tokens": [50852, 458, 577, 7340, 436, 366, 337, 7318, 10343, 393, 321, 10413, 592, 1188, 584, 300, 412, 1935, 472, 718, 311, 584, 51200], "temperature": 0.0, "avg_logprob": -0.07066822935033727, "compression_ratio": 1.776061776061776, "no_speech_prob": 0.0016152823809534311}, {"id": 856, "seek": 480888, "start": 4825.6, "end": 4831.4400000000005, "text": " applications are way for these neural networks or for the quantum neural networks to come in", "tokens": [51200, 5821, 366, 636, 337, 613, 18161, 9590, 420, 337, 264, 13018, 18161, 9590, 281, 808, 294, 51492], "temperature": 0.0, "avg_logprob": -0.07066822935033727, "compression_ratio": 1.776061776061776, "no_speech_prob": 0.0016152823809534311}, {"id": 857, "seek": 480888, "start": 4831.4400000000005, "end": 4837.04, "text": " is in in the place where right now we have these renormalization problems let's say", "tokens": [51492, 307, 294, 294, 264, 1081, 689, 558, 586, 321, 362, 613, 8124, 24440, 2144, 2740, 718, 311, 584, 51772], "temperature": 0.0, "avg_logprob": -0.07066822935033727, "compression_ratio": 1.776061776061776, "no_speech_prob": 0.0016152823809534311}, {"id": 858, "seek": 483704, "start": 4837.76, "end": 4843.28, "text": " big word embeddings or yeah as you mentioned things like variational inference any anywhere", "tokens": [50400, 955, 1349, 12240, 29432, 420, 1338, 382, 291, 2835, 721, 411, 3034, 1478, 38253, 604, 4992, 50676], "temperature": 0.0, "avg_logprob": -0.06104439999683794, "compression_ratio": 1.7342342342342343, "no_speech_prob": 0.0019248398020863533}, {"id": 859, "seek": 483704, "start": 4843.28, "end": 4851.84, "text": " where you have a partition function that you let's say have to sample to compute now we potentially", "tokens": [50676, 689, 291, 362, 257, 24808, 2445, 300, 291, 718, 311, 584, 362, 281, 6889, 281, 14722, 586, 321, 7263, 51104], "temperature": 0.0, "avg_logprob": -0.06104439999683794, "compression_ratio": 1.7342342342342343, "no_speech_prob": 0.0019248398020863533}, {"id": 860, "seek": 483704, "start": 4851.84, "end": 4857.28, "text": " introduce this new way of doing this yeah so I would say that is a different set of problems so", "tokens": [51104, 5366, 341, 777, 636, 295, 884, 341, 1338, 370, 286, 576, 584, 300, 307, 257, 819, 992, 295, 2740, 370, 51376], "temperature": 0.0, "avg_logprob": -0.06104439999683794, "compression_ratio": 1.7342342342342343, "no_speech_prob": 0.0019248398020863533}, {"id": 861, "seek": 483704, "start": 4857.28, "end": 4864.08, "text": " there is some sampling algorithms which can be sped up by quantum sampling algorithms but I think", "tokens": [51376, 456, 307, 512, 21179, 14642, 597, 393, 312, 637, 292, 493, 538, 13018, 21179, 14642, 457, 286, 519, 51716], "temperature": 0.0, "avg_logprob": -0.06104439999683794, "compression_ratio": 1.7342342342342343, "no_speech_prob": 0.0019248398020863533}, {"id": 862, "seek": 486408, "start": 4864.16, "end": 4869.84, "text": " the maximum speed up is like a square root so it's not insignificant but it's also not exponential", "tokens": [50368, 264, 6674, 3073, 493, 307, 411, 257, 3732, 5593, 370, 309, 311, 406, 43685, 457, 309, 311, 611, 406, 21510, 50652], "temperature": 0.0, "avg_logprob": -0.07061765670776367, "compression_ratio": 1.825278810408922, "no_speech_prob": 0.011318951845169067}, {"id": 863, "seek": 486408, "start": 4869.84, "end": 4873.84, "text": " okay right you can do something in square root time of what a normal classical computer could do", "tokens": [50652, 1392, 558, 291, 393, 360, 746, 294, 3732, 5593, 565, 295, 437, 257, 2710, 13735, 3820, 727, 360, 50852], "temperature": 0.0, "avg_logprob": -0.07061765670776367, "compression_ratio": 1.825278810408922, "no_speech_prob": 0.011318951845169067}, {"id": 864, "seek": 486408, "start": 4874.4, "end": 4880.72, "text": " and then there is these very interesting stories where people thought that they could do things much", "tokens": [50880, 293, 550, 456, 307, 613, 588, 1880, 3676, 689, 561, 1194, 300, 436, 727, 360, 721, 709, 51196], "temperature": 0.0, "avg_logprob": -0.07061765670776367, "compression_ratio": 1.825278810408922, "no_speech_prob": 0.011318951845169067}, {"id": 865, "seek": 486408, "start": 4880.72, "end": 4885.36, "text": " faster on a quantum computer but then somebody's thought really hard about it and they then invented", "tokens": [51196, 4663, 322, 257, 13018, 3820, 457, 550, 2618, 311, 1194, 534, 1152, 466, 309, 293, 436, 550, 14479, 51428], "temperature": 0.0, "avg_logprob": -0.07061765670776367, "compression_ratio": 1.825278810408922, "no_speech_prob": 0.011318951845169067}, {"id": 866, "seek": 486408, "start": 4885.36, "end": 4891.2, "text": " actually a quantum inspired classical random algorithm which would do about the same speed or", "tokens": [51428, 767, 257, 13018, 7547, 13735, 4974, 9284, 597, 576, 360, 466, 264, 912, 3073, 420, 51720], "temperature": 0.0, "avg_logprob": -0.07061765670776367, "compression_ratio": 1.825278810408922, "no_speech_prob": 0.011318951845169067}, {"id": 867, "seek": 489120, "start": 4892.08, "end": 4899.04, "text": " close close at least so it's very uncertain precisely what we can speed up but that what", "tokens": [50408, 1998, 1998, 412, 1935, 370, 309, 311, 588, 11308, 13402, 437, 321, 393, 3073, 493, 457, 300, 437, 50756], "temperature": 0.0, "avg_logprob": -0.09499034703334916, "compression_ratio": 1.9473684210526316, "no_speech_prob": 0.010626149363815784}, {"id": 868, "seek": 489120, "start": 4899.04, "end": 4904.0, "text": " makes it interesting right especially if you can predict what's going to happen in some sense", "tokens": [50756, 1669, 309, 1880, 558, 2318, 498, 291, 393, 6069, 437, 311, 516, 281, 1051, 294, 512, 2020, 51004], "temperature": 0.0, "avg_logprob": -0.09499034703334916, "compression_ratio": 1.9473684210526316, "no_speech_prob": 0.010626149363815784}, {"id": 869, "seek": 489120, "start": 4904.0, "end": 4909.76, "text": " it's just a matter of executing right but if you don't know if they're what they're what the low", "tokens": [51004, 309, 311, 445, 257, 1871, 295, 32368, 558, 457, 498, 291, 500, 380, 458, 498, 436, 434, 437, 436, 434, 437, 264, 2295, 51292], "temperature": 0.0, "avg_logprob": -0.09499034703334916, "compression_ratio": 1.9473684210526316, "no_speech_prob": 0.010626149363815784}, {"id": 870, "seek": 489120, "start": 4909.76, "end": 4914.8, "text": " hanging fruit is and if there is low hanging fruit and what the possible benefits in benefits are the", "tokens": [51292, 8345, 6773, 307, 293, 498, 456, 307, 2295, 8345, 6773, 293, 437, 264, 1944, 5311, 294, 5311, 366, 264, 51544], "temperature": 0.0, "avg_logprob": -0.09499034703334916, "compression_ratio": 1.9473684210526316, "no_speech_prob": 0.010626149363815784}, {"id": 871, "seek": 489120, "start": 4914.8, "end": 4919.04, "text": " possible bonus that you can get by doing these things then it gets really interesting in my opinion", "tokens": [51544, 1944, 10882, 300, 291, 393, 483, 538, 884, 613, 721, 550, 309, 2170, 534, 1880, 294, 452, 4800, 51756], "temperature": 0.0, "avg_logprob": -0.09499034703334916, "compression_ratio": 1.9473684210526316, "no_speech_prob": 0.010626149363815784}, {"id": 872, "seek": 491904, "start": 4919.84, "end": 4925.04, "text": " amazing now might be a good time to talk about your other paper that's just come out Max which", "tokens": [50404, 2243, 586, 1062, 312, 257, 665, 565, 281, 751, 466, 428, 661, 3035, 300, 311, 445, 808, 484, 7402, 597, 50664], "temperature": 0.0, "avg_logprob": -0.11997112177186094, "compression_ratio": 1.7919254658385093, "no_speech_prob": 0.012503190897405148}, {"id": 873, "seek": 491904, "start": 4925.04, "end": 4929.92, "text": " is probabilistic numeric convolutional neural networks and this was also with Mark Finsey who", "tokens": [50664, 307, 31959, 3142, 7866, 299, 45216, 304, 18161, 9590, 293, 341, 390, 611, 365, 3934, 3773, 7399, 567, 50908], "temperature": 0.0, "avg_logprob": -0.11997112177186094, "compression_ratio": 1.7919254658385093, "no_speech_prob": 0.012503190897405148}, {"id": 874, "seek": 491904, "start": 4929.92, "end": 4934.32, "text": " we just discovered this morning just brought out a really interesting paper about equivalents on", "tokens": [50908, 321, 445, 6941, 341, 2446, 445, 3038, 484, 257, 534, 1880, 3035, 466, 9052, 791, 322, 51128], "temperature": 0.0, "avg_logprob": -0.11997112177186094, "compression_ratio": 1.7919254658385093, "no_speech_prob": 0.012503190897405148}, {"id": 875, "seek": 491904, "start": 4934.32, "end": 4939.12, "text": " light groups so that might be a potential digression later but this works really fascinating because", "tokens": [51128, 1442, 3935, 370, 300, 1062, 312, 257, 3995, 2528, 2775, 1780, 457, 341, 1985, 534, 10343, 570, 51368], "temperature": 0.0, "avg_logprob": -0.11997112177186094, "compression_ratio": 1.7919254658385093, "no_speech_prob": 0.012503190897405148}, {"id": 876, "seek": 491904, "start": 4939.12, "end": 4944.56, "text": " it's in the setting of irregularly sample data and we use these Gaussian processes to represent", "tokens": [51368, 309, 311, 294, 264, 3287, 295, 29349, 356, 6889, 1412, 293, 321, 764, 613, 39148, 7555, 281, 2906, 51640], "temperature": 0.0, "avg_logprob": -0.11997112177186094, "compression_ratio": 1.7919254658385093, "no_speech_prob": 0.012503190897405148}, {"id": 877, "seek": 491904, "start": 4944.56, "end": 4948.88, "text": " that and we can continuously interpolate between them in this convolutional setting absolutely", "tokens": [51640, 300, 293, 321, 393, 15684, 44902, 473, 1296, 552, 294, 341, 45216, 304, 3287, 3122, 51856], "temperature": 0.0, "avg_logprob": -0.11997112177186094, "compression_ratio": 1.7919254658385093, "no_speech_prob": 0.012503190897405148}, {"id": 878, "seek": 494888, "start": 4948.88, "end": 4954.72, "text": " fascinating could you give us the the elevator pitch yeah first let me say again that Mark Finsey", "tokens": [50364, 10343, 727, 291, 976, 505, 264, 264, 18782, 7293, 1338, 700, 718, 385, 584, 797, 300, 3934, 3773, 7399, 50656], "temperature": 0.0, "avg_logprob": -0.09127445842908777, "compression_ratio": 1.646090534979424, "no_speech_prob": 0.0044411551207304}, {"id": 879, "seek": 494888, "start": 4954.72, "end": 4960.96, "text": " was an intern at Qualcomm and and Roberto Bondeson was is the other person who was also working with", "tokens": [50656, 390, 364, 2154, 412, 13616, 13278, 293, 293, 40354, 23604, 279, 266, 390, 307, 264, 661, 954, 567, 390, 611, 1364, 365, 50968], "temperature": 0.0, "avg_logprob": -0.09127445842908777, "compression_ratio": 1.646090534979424, "no_speech_prob": 0.0044411551207304}, {"id": 880, "seek": 494888, "start": 4960.96, "end": 4967.36, "text": " me on the quantum stuff so those of my collaborators in this project and of course Mark did the bulk", "tokens": [50968, 385, 322, 264, 13018, 1507, 370, 729, 295, 452, 39789, 294, 341, 1716, 293, 295, 1164, 3934, 630, 264, 16139, 51288], "temperature": 0.0, "avg_logprob": -0.09127445842908777, "compression_ratio": 1.646090534979424, "no_speech_prob": 0.0044411551207304}, {"id": 881, "seek": 494888, "start": 4967.36, "end": 4973.4400000000005, "text": " of the work for this paper so he should deserve much of the credit for it but here's the observation", "tokens": [51288, 295, 264, 589, 337, 341, 3035, 370, 415, 820, 9948, 709, 295, 264, 5397, 337, 309, 457, 510, 311, 264, 14816, 51592], "temperature": 0.0, "avg_logprob": -0.09127445842908777, "compression_ratio": 1.646090534979424, "no_speech_prob": 0.0044411551207304}, {"id": 882, "seek": 497344, "start": 4973.5199999999995, "end": 4980.879999999999, "text": " that we had the observation is when we write down a deep learning algorithm let's say on for an image", "tokens": [50368, 300, 321, 632, 264, 14816, 307, 562, 321, 2464, 760, 257, 2452, 2539, 9284, 718, 311, 584, 322, 337, 364, 3256, 50736], "temperature": 0.0, "avg_logprob": -0.05877229708050369, "compression_ratio": 1.8513011152416357, "no_speech_prob": 0.4294588267803192}, {"id": 883, "seek": 497344, "start": 4981.5199999999995, "end": 4986.5599999999995, "text": " then we sort of treat the image as pixels and we think that's the real signal that we are looking at", "tokens": [50768, 550, 321, 1333, 295, 2387, 264, 3256, 382, 18668, 293, 321, 519, 300, 311, 264, 957, 6358, 300, 321, 366, 1237, 412, 51020], "temperature": 0.0, "avg_logprob": -0.05877229708050369, "compression_ratio": 1.8513011152416357, "no_speech_prob": 0.4294588267803192}, {"id": 884, "seek": 497344, "start": 4987.2, "end": 4992.24, "text": " but you can also ask yourself what if I remove every second pixel now actually I have a very", "tokens": [51052, 457, 291, 393, 611, 1029, 1803, 437, 498, 286, 4159, 633, 1150, 19261, 586, 767, 286, 362, 257, 588, 51304], "temperature": 0.0, "avg_logprob": -0.05877229708050369, "compression_ratio": 1.8513011152416357, "no_speech_prob": 0.4294588267803192}, {"id": 885, "seek": 497344, "start": 4992.24, "end": 4996.4, "text": " different neural network but should I have a very different neural network or what if the pixels are", "tokens": [51304, 819, 18161, 3209, 457, 820, 286, 362, 257, 588, 819, 18161, 3209, 420, 437, 498, 264, 18668, 366, 51512], "temperature": 0.0, "avg_logprob": -0.05877229708050369, "compression_ratio": 1.8513011152416357, "no_speech_prob": 0.4294588267803192}, {"id": 886, "seek": 497344, "start": 4996.4, "end": 5003.2, "text": " actually quite randomly distributed in the plane it's just some random places where I do measurements", "tokens": [51512, 767, 1596, 16979, 12631, 294, 264, 5720, 309, 311, 445, 512, 4974, 3190, 689, 286, 360, 15383, 51852], "temperature": 0.0, "avg_logprob": -0.05877229708050369, "compression_ratio": 1.8513011152416357, "no_speech_prob": 0.4294588267803192}, {"id": 887, "seek": 500320, "start": 5003.2, "end": 5008.32, "text": " maybe more on the left upper corner and and fear on the left lower corner what the predictor", "tokens": [50364, 1310, 544, 322, 264, 1411, 6597, 4538, 293, 293, 4240, 322, 264, 1411, 3126, 4538, 437, 264, 6069, 284, 50620], "temperature": 0.0, "avg_logprob": -0.07774653943996986, "compression_ratio": 1.7606177606177607, "no_speech_prob": 0.0006162818754091859}, {"id": 888, "seek": 500320, "start": 5008.32, "end": 5013.5199999999995, "text": " should behave in a certain consistent way and so of course then you come to realize that really", "tokens": [50620, 820, 15158, 294, 257, 1629, 8398, 636, 293, 370, 295, 1164, 550, 291, 808, 281, 4325, 300, 534, 50880], "temperature": 0.0, "avg_logprob": -0.07774653943996986, "compression_ratio": 1.7606177606177607, "no_speech_prob": 0.0006162818754091859}, {"id": 889, "seek": 500320, "start": 5013.5199999999995, "end": 5017.84, "text": " what you're doing is with a pixel grid is sampling an underlying continuous signal", "tokens": [50880, 437, 291, 434, 884, 307, 365, 257, 19261, 10748, 307, 21179, 364, 14217, 10957, 6358, 51096], "temperature": 0.0, "avg_logprob": -0.07774653943996986, "compression_ratio": 1.7606177606177607, "no_speech_prob": 0.0006162818754091859}, {"id": 890, "seek": 500320, "start": 5018.72, "end": 5023.76, "text": " so then we just started thinking how do you best deal with this so how do you how can you", "tokens": [51140, 370, 550, 321, 445, 1409, 1953, 577, 360, 291, 1151, 2028, 365, 341, 370, 577, 360, 291, 577, 393, 291, 51392], "temperature": 0.0, "avg_logprob": -0.07774653943996986, "compression_ratio": 1.7606177606177607, "no_speech_prob": 0.0006162818754091859}, {"id": 891, "seek": 500320, "start": 5023.76, "end": 5029.28, "text": " build this in and so there's a very interesting tool which is called the Gaussian process it's", "tokens": [51392, 1322, 341, 294, 293, 370, 456, 311, 257, 588, 1880, 2290, 597, 307, 1219, 264, 39148, 1399, 309, 311, 51668], "temperature": 0.0, "avg_logprob": -0.07774653943996986, "compression_ratio": 1.7606177606177607, "no_speech_prob": 0.0006162818754091859}, {"id": 892, "seek": 502928, "start": 5029.28, "end": 5035.679999999999, "text": " basically interpolates between dots but in places where you don't have a lot of data you create", "tokens": [50364, 1936, 44902, 1024, 1296, 15026, 457, 294, 3190, 689, 291, 500, 380, 362, 257, 688, 295, 1412, 291, 1884, 50684], "temperature": 0.0, "avg_logprob": -0.06910220686211643, "compression_ratio": 1.7853881278538812, "no_speech_prob": 0.000896841986104846}, {"id": 893, "seek": 502928, "start": 5035.679999999999, "end": 5041.04, "text": " uncertainty because you don't know what the real signal is so you basically get some kind of interval", "tokens": [50684, 15697, 570, 291, 500, 380, 458, 437, 264, 957, 6358, 307, 370, 291, 1936, 483, 512, 733, 295, 15035, 50952], "temperature": 0.0, "avg_logprob": -0.06910220686211643, "compression_ratio": 1.7853881278538812, "no_speech_prob": 0.000896841986104846}, {"id": 894, "seek": 502928, "start": 5041.759999999999, "end": 5046.8, "text": " which says okay I think the signal is somewhere in this interval with 95 percent you know certainty", "tokens": [50988, 597, 1619, 1392, 286, 519, 264, 6358, 307, 4079, 294, 341, 15035, 365, 13420, 3043, 291, 458, 27022, 51240], "temperature": 0.0, "avg_logprob": -0.06910220686211643, "compression_ratio": 1.7853881278538812, "no_speech_prob": 0.000896841986104846}, {"id": 895, "seek": 502928, "start": 5046.8, "end": 5054.0, "text": " but I don't know precisely where now the mean function is a smooth actual continuous function", "tokens": [51240, 457, 286, 500, 380, 458, 13402, 689, 586, 264, 914, 2445, 307, 257, 5508, 3539, 10957, 2445, 51600], "temperature": 0.0, "avg_logprob": -0.06910220686211643, "compression_ratio": 1.7853881278538812, "no_speech_prob": 0.000896841986104846}, {"id": 896, "seek": 505400, "start": 5054.96, "end": 5059.6, "text": " and then the next step was say okay what what does it mean to do a convolution on this space", "tokens": [50412, 293, 550, 264, 958, 1823, 390, 584, 1392, 437, 437, 775, 309, 914, 281, 360, 257, 45216, 322, 341, 1901, 50644], "temperature": 0.0, "avg_logprob": -0.13053876786004928, "compression_ratio": 1.818867924528302, "no_speech_prob": 0.0011512323981150985}, {"id": 897, "seek": 505400, "start": 5059.6, "end": 5066.48, "text": " this is the new Gaussian process interpolated space and what we found is that the most interesting", "tokens": [50644, 341, 307, 264, 777, 39148, 1399, 44902, 770, 1901, 293, 437, 321, 1352, 307, 300, 264, 881, 1880, 50988], "temperature": 0.0, "avg_logprob": -0.13053876786004928, "compression_ratio": 1.818867924528302, "no_speech_prob": 0.0011512323981150985}, {"id": 898, "seek": 505400, "start": 5066.48, "end": 5072.16, "text": " way to describe that is by looking at it as a partial differential equation and so this ties", "tokens": [50988, 636, 281, 6786, 300, 307, 538, 1237, 412, 309, 382, 257, 14641, 15756, 5367, 293, 370, 341, 14039, 51272], "temperature": 0.0, "avg_logprob": -0.13053876786004928, "compression_ratio": 1.818867924528302, "no_speech_prob": 0.0011512323981150985}, {"id": 899, "seek": 505400, "start": 5072.16, "end": 5077.2, "text": " back into another really interesting line of work which was started by David Duvenaux and authors", "tokens": [51272, 646, 666, 1071, 534, 1880, 1622, 295, 589, 597, 390, 1409, 538, 4389, 5153, 553, 7511, 293, 16552, 51524], "temperature": 0.0, "avg_logprob": -0.13053876786004928, "compression_ratio": 1.818867924528302, "no_speech_prob": 0.0011512323981150985}, {"id": 900, "seek": 505400, "start": 5077.2, "end": 5083.52, "text": " on thinking of a neural network as an OD as an ordinary differential equation so here we're talking", "tokens": [51524, 322, 1953, 295, 257, 18161, 3209, 382, 364, 48447, 382, 364, 10547, 15756, 5367, 370, 510, 321, 434, 1417, 51840], "temperature": 0.0, "avg_logprob": -0.13053876786004928, "compression_ratio": 1.818867924528302, "no_speech_prob": 0.0011512323981150985}, {"id": 901, "seek": 508352, "start": 5083.52, "end": 5089.84, "text": " about a PDE basically because we have spatial extent and so we are looking at sort of derivatives", "tokens": [50364, 466, 257, 10464, 36, 1936, 570, 321, 362, 23598, 8396, 293, 370, 321, 366, 1237, 412, 1333, 295, 33733, 50680], "temperature": 0.0, "avg_logprob": -0.06574008578345888, "compression_ratio": 1.8735632183908046, "no_speech_prob": 0.002671539783477783}, {"id": 902, "seek": 508352, "start": 5089.84, "end": 5095.4400000000005, "text": " and second-order derivatives in in the plane basically which which we apply on the continuous", "tokens": [50680, 293, 1150, 12, 4687, 33733, 294, 294, 264, 5720, 1936, 597, 597, 321, 3079, 322, 264, 10957, 50960], "temperature": 0.0, "avg_logprob": -0.06574008578345888, "compression_ratio": 1.8735632183908046, "no_speech_prob": 0.002671539783477783}, {"id": 903, "seek": 508352, "start": 5095.4400000000005, "end": 5100.56, "text": " function so this is literally what people do when they solve a PDE is that they have some operator", "tokens": [50960, 2445, 370, 341, 307, 3736, 437, 561, 360, 562, 436, 5039, 257, 10464, 36, 307, 300, 436, 362, 512, 12973, 51216], "temperature": 0.0, "avg_logprob": -0.06574008578345888, "compression_ratio": 1.8735632183908046, "no_speech_prob": 0.002671539783477783}, {"id": 904, "seek": 508352, "start": 5100.56, "end": 5106.400000000001, "text": " which is consists of derivatives which they apply to the function and then they have a time component", "tokens": [51216, 597, 307, 14689, 295, 33733, 597, 436, 3079, 281, 264, 2445, 293, 550, 436, 362, 257, 565, 6542, 51508], "temperature": 0.0, "avg_logprob": -0.06574008578345888, "compression_ratio": 1.8735632183908046, "no_speech_prob": 0.002671539783477783}, {"id": 905, "seek": 508352, "start": 5106.400000000001, "end": 5112.320000000001, "text": " which evolves this thing forward in time basically and it turns out that's a very natural way to", "tokens": [51508, 597, 43737, 341, 551, 2128, 294, 565, 1936, 293, 309, 4523, 484, 300, 311, 257, 588, 3303, 636, 281, 51804], "temperature": 0.0, "avg_logprob": -0.06574008578345888, "compression_ratio": 1.8735632183908046, "no_speech_prob": 0.002671539783477783}, {"id": 906, "seek": 511232, "start": 5112.32, "end": 5117.92, "text": " describe a convolution you can also add symmetries in a very natural way by looking at that operator", "tokens": [50364, 6786, 257, 45216, 291, 393, 611, 909, 14232, 302, 2244, 294, 257, 588, 3303, 636, 538, 1237, 412, 300, 12973, 50644], "temperature": 0.0, "avg_logprob": -0.07190706162225632, "compression_ratio": 1.7518248175182483, "no_speech_prob": 0.0035923286341130733}, {"id": 907, "seek": 511232, "start": 5117.92, "end": 5122.16, "text": " that sort of moves things forward and making sure it's invariant under certain transformations", "tokens": [50644, 300, 1333, 295, 6067, 721, 2128, 293, 1455, 988, 309, 311, 33270, 394, 833, 1629, 34852, 50856], "temperature": 0.0, "avg_logprob": -0.07190706162225632, "compression_ratio": 1.7518248175182483, "no_speech_prob": 0.0035923286341130733}, {"id": 908, "seek": 511232, "start": 5122.96, "end": 5128.719999999999, "text": " we had a bit of trouble really handling the nonlinearity that falls that happens then so we", "tokens": [50896, 321, 632, 257, 857, 295, 5253, 534, 13175, 264, 2107, 1889, 17409, 300, 8804, 300, 2314, 550, 370, 321, 51184], "temperature": 0.0, "avg_logprob": -0.07190706162225632, "compression_ratio": 1.7518248175182483, "no_speech_prob": 0.0035923286341130733}, {"id": 909, "seek": 511232, "start": 5128.719999999999, "end": 5133.12, "text": " had to then project it back onto something that would then again easily handle by a Gaussian", "tokens": [51184, 632, 281, 550, 1716, 309, 646, 3911, 746, 300, 576, 550, 797, 3612, 4813, 538, 257, 39148, 51404], "temperature": 0.0, "avg_logprob": -0.07190706162225632, "compression_ratio": 1.7518248175182483, "no_speech_prob": 0.0035923286341130733}, {"id": 910, "seek": 511232, "start": 5133.12, "end": 5138.5599999999995, "text": " process etc so we had to do some work there but in the end this thing was now actually very general", "tokens": [51404, 1399, 5183, 370, 321, 632, 281, 360, 512, 589, 456, 457, 294, 264, 917, 341, 551, 390, 586, 767, 588, 2674, 51676], "temperature": 0.0, "avg_logprob": -0.07190706162225632, "compression_ratio": 1.7518248175182483, "no_speech_prob": 0.0035923286341130733}, {"id": 911, "seek": 513856, "start": 5138.56, "end": 5146.0, "text": " and interesting tool which is apply a Gaussian process apply PDE apply nonlinearity repeat", "tokens": [50364, 293, 1880, 2290, 597, 307, 3079, 257, 39148, 1399, 3079, 10464, 36, 3079, 2107, 1889, 17409, 7149, 50736], "temperature": 0.0, "avg_logprob": -0.08434280065389779, "compression_ratio": 1.7613636363636365, "no_speech_prob": 0.005998066160827875}, {"id": 912, "seek": 513856, "start": 5146.0, "end": 5152.0, "text": " and then in the end collect all your information and make a prediction and it so some of the benefits", "tokens": [50736, 293, 550, 294, 264, 917, 2500, 439, 428, 1589, 293, 652, 257, 17630, 293, 309, 370, 512, 295, 264, 5311, 51036], "temperature": 0.0, "avg_logprob": -0.08434280065389779, "compression_ratio": 1.7613636363636365, "no_speech_prob": 0.005998066160827875}, {"id": 913, "seek": 513856, "start": 5152.0, "end": 5157.04, "text": " are now that first of all of course you cannot work on a unstructured set of points doesn't", "tokens": [51036, 366, 586, 300, 700, 295, 439, 295, 1164, 291, 2644, 589, 322, 257, 18799, 46847, 992, 295, 2793, 1177, 380, 51288], "temperature": 0.0, "avg_logprob": -0.08434280065389779, "compression_ratio": 1.7613636363636365, "no_speech_prob": 0.005998066160827875}, {"id": 914, "seek": 513856, "start": 5157.04, "end": 5162.0, "text": " have to be a grid and you can even learn the positions of those points so you can now direct", "tokens": [51288, 362, 281, 312, 257, 10748, 293, 291, 393, 754, 1466, 264, 8432, 295, 729, 2793, 370, 291, 393, 586, 2047, 51536], "temperature": 0.0, "avg_logprob": -0.08434280065389779, "compression_ratio": 1.7613636363636365, "no_speech_prob": 0.005998066160827875}, {"id": 915, "seek": 513856, "start": 5162.0, "end": 5168.320000000001, "text": " the observations in places where you really need to do observations in order to improve", "tokens": [51536, 264, 18163, 294, 3190, 689, 291, 534, 643, 281, 360, 18163, 294, 1668, 281, 3470, 51852], "temperature": 0.0, "avg_logprob": -0.08434280065389779, "compression_ratio": 1.7613636363636365, "no_speech_prob": 0.005998066160827875}, {"id": 916, "seek": 516832, "start": 5168.32, "end": 5172.719999999999, "text": " your prediction so it basically becomes a numerical integration procedure where you can", "tokens": [50364, 428, 17630, 370, 309, 1936, 3643, 257, 29054, 10980, 10747, 689, 291, 393, 50584], "temperature": 0.0, "avg_logprob": -0.09140859246253967, "compression_ratio": 1.712962962962963, "no_speech_prob": 0.002510582096874714}, {"id": 917, "seek": 516832, "start": 5172.719999999999, "end": 5178.639999999999, "text": " learn where to move your integration points and what I also found very is fascinating is that", "tokens": [50584, 1466, 689, 281, 1286, 428, 10980, 2793, 293, 437, 286, 611, 1352, 588, 307, 10343, 307, 300, 50880], "temperature": 0.0, "avg_logprob": -0.09140859246253967, "compression_ratio": 1.712962962962963, "no_speech_prob": 0.002510582096874714}, {"id": 918, "seek": 516832, "start": 5178.639999999999, "end": 5185.679999999999, "text": " this same paradigm can be mapped on again onto a quantum paradigm where you can think of that", "tokens": [50880, 341, 912, 24709, 393, 312, 33318, 322, 797, 3911, 257, 13018, 24709, 689, 291, 393, 519, 295, 300, 51232], "temperature": 0.0, "avg_logprob": -0.09140859246253967, "compression_ratio": 1.712962962962963, "no_speech_prob": 0.002510582096874714}, {"id": 919, "seek": 516832, "start": 5186.24, "end": 5192.88, "text": " PDE that evolves now as a Schrodinger equation that sort of evolves like a wave function so it", "tokens": [51260, 10464, 36, 300, 43737, 586, 382, 257, 2065, 340, 3584, 260, 5367, 300, 1333, 295, 43737, 411, 257, 5772, 2445, 370, 309, 51592], "temperature": 0.0, "avg_logprob": -0.09140859246253967, "compression_ratio": 1.712962962962963, "no_speech_prob": 0.002510582096874714}, {"id": 920, "seek": 519288, "start": 5192.88, "end": 5197.68, "text": " maps very nicely also again to a quantum problem and that's what we are working on now", "tokens": [50364, 11317, 588, 9594, 611, 797, 281, 257, 13018, 1154, 293, 300, 311, 437, 321, 366, 1364, 322, 586, 50604], "temperature": 0.0, "avg_logprob": -0.06765843854092135, "compression_ratio": 1.6826568265682658, "no_speech_prob": 0.003537132404744625}, {"id": 921, "seek": 519288, "start": 5198.400000000001, "end": 5202.16, "text": " something that's really fascinating that keeps coming up again and again and these sorts of", "tokens": [50640, 746, 300, 311, 534, 10343, 300, 5965, 1348, 493, 797, 293, 797, 293, 613, 7527, 295, 50828], "temperature": 0.0, "avg_logprob": -0.06765843854092135, "compression_ratio": 1.6826568265682658, "no_speech_prob": 0.003537132404744625}, {"id": 922, "seek": 519288, "start": 5202.16, "end": 5207.36, "text": " research programs is the matrix exponential like it's our connection to groups and algebras or", "tokens": [50828, 2132, 4268, 307, 264, 8141, 21510, 411, 309, 311, 527, 4984, 281, 3935, 293, 419, 432, 38182, 420, 51088], "temperature": 0.0, "avg_logprob": -0.06765843854092135, "compression_ratio": 1.6826568265682658, "no_speech_prob": 0.003537132404744625}, {"id": 923, "seek": 519288, "start": 5207.36, "end": 5212.88, "text": " like group representations and algebras and of course we use it to evolve our ODEs and PDEs", "tokens": [51088, 411, 1594, 33358, 293, 419, 432, 38182, 293, 295, 1164, 321, 764, 309, 281, 16693, 527, 48447, 20442, 293, 10464, 20442, 51364], "temperature": 0.0, "avg_logprob": -0.06765843854092135, "compression_ratio": 1.6826568265682658, "no_speech_prob": 0.003537132404744625}, {"id": 924, "seek": 519288, "start": 5213.76, "end": 5218.32, "text": " I guess as a physicist you've probably got a deeper appreciation of this particular object", "tokens": [51408, 286, 2041, 382, 257, 42466, 291, 600, 1391, 658, 257, 7731, 18909, 295, 341, 1729, 2657, 51636], "temperature": 0.0, "avg_logprob": -0.06765843854092135, "compression_ratio": 1.6826568265682658, "no_speech_prob": 0.003537132404744625}, {"id": 925, "seek": 521832, "start": 5218.32, "end": 5223.599999999999, "text": " but it's something that's still quite alien to a lot of people I know that work in applied", "tokens": [50364, 457, 309, 311, 746, 300, 311, 920, 1596, 12319, 281, 257, 688, 295, 561, 286, 458, 300, 589, 294, 6456, 50628], "temperature": 0.0, "avg_logprob": -0.1287819090343657, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.004459308926016092}, {"id": 926, "seek": 521832, "start": 5223.599999999999, "end": 5228.719999999999, "text": " machine learning what's the significance of the matrix exponential why does it connect all these", "tokens": [50628, 3479, 2539, 437, 311, 264, 17687, 295, 264, 8141, 21510, 983, 775, 309, 1745, 439, 613, 50884], "temperature": 0.0, "avg_logprob": -0.1287819090343657, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.004459308926016092}, {"id": 927, "seek": 521832, "start": 5228.719999999999, "end": 5234.799999999999, "text": " really fundamental objects to things like Lie groups and stuff like that yeah so it's interesting", "tokens": [50884, 534, 8088, 6565, 281, 721, 411, 11197, 3935, 293, 1507, 411, 300, 1338, 370, 309, 311, 1880, 51188], "temperature": 0.0, "avg_logprob": -0.1287819090343657, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.004459308926016092}, {"id": 928, "seek": 521832, "start": 5234.799999999999, "end": 5239.92, "text": " that we actually just got a paper accepted in noreps on this and it's called the convolution", "tokens": [51188, 300, 321, 767, 445, 658, 257, 3035, 9035, 294, 297, 418, 1878, 322, 341, 293, 309, 311, 1219, 264, 45216, 51444], "temperature": 0.0, "avg_logprob": -0.1287819090343657, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.004459308926016092}, {"id": 929, "seek": 521832, "start": 5239.92, "end": 5246.0, "text": " exponential and you can look it up and Emil Hogebaum is the sort of the main author and", "tokens": [51444, 21510, 293, 291, 393, 574, 309, 493, 293, 36983, 3631, 432, 46641, 307, 264, 1333, 295, 264, 2135, 3793, 293, 51748], "temperature": 0.0, "avg_logprob": -0.1287819090343657, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.004459308926016092}, {"id": 930, "seek": 524600, "start": 5246.0, "end": 5253.92, "text": " generator of that idea and yeah so I guess it because it is the solution to the ODE or the PDE", "tokens": [50364, 19265, 295, 300, 1558, 293, 1338, 370, 286, 2041, 309, 570, 309, 307, 264, 3827, 281, 264, 422, 22296, 420, 264, 10464, 36, 50760], "temperature": 0.0, "avg_logprob": -0.09491362354972145, "compression_ratio": 1.751131221719457, "no_speech_prob": 0.0017818680498749018}, {"id": 931, "seek": 524600, "start": 5253.92, "end": 5260.0, "text": " right so if you write down something that's very fundamental that is the first order differential", "tokens": [50760, 558, 370, 498, 291, 2464, 760, 746, 300, 311, 588, 8088, 300, 307, 264, 700, 1668, 15756, 51064], "temperature": 0.0, "avg_logprob": -0.09491362354972145, "compression_ratio": 1.751131221719457, "no_speech_prob": 0.0017818680498749018}, {"id": 932, "seek": 524600, "start": 5260.0, "end": 5266.88, "text": " equation which is d dt the derivative with respect to t of a state is some operator times that state", "tokens": [51064, 5367, 597, 307, 274, 36423, 264, 13760, 365, 3104, 281, 256, 295, 257, 1785, 307, 512, 12973, 1413, 300, 1785, 51408], "temperature": 0.0, "avg_logprob": -0.09491362354972145, "compression_ratio": 1.751131221719457, "no_speech_prob": 0.0017818680498749018}, {"id": 933, "seek": 524600, "start": 5267.68, "end": 5274.32, "text": " then the solution of that thing will be the state over time is the matrix exponential times t", "tokens": [51448, 550, 264, 3827, 295, 300, 551, 486, 312, 264, 1785, 670, 565, 307, 264, 8141, 21510, 1413, 256, 51780], "temperature": 0.0, "avg_logprob": -0.09491362354972145, "compression_ratio": 1.751131221719457, "no_speech_prob": 0.0017818680498749018}, {"id": 934, "seek": 527432, "start": 5274.88, "end": 5280.16, "text": " times the state so that's I think where it comes from and so one other way to look at it is that", "tokens": [50392, 1413, 264, 1785, 370, 300, 311, 286, 519, 689, 309, 1487, 490, 293, 370, 472, 661, 636, 281, 574, 412, 309, 307, 300, 50656], "temperature": 0.0, "avg_logprob": -0.06248741651836195, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.01032268162816763}, {"id": 935, "seek": 527432, "start": 5280.88, "end": 5285.36, "text": " in physics it's called the Green's function so it's basically the solution to this ODE so you", "tokens": [50692, 294, 10649, 309, 311, 1219, 264, 6969, 311, 2445, 370, 309, 311, 1936, 264, 3827, 281, 341, 422, 22296, 370, 291, 50916], "temperature": 0.0, "avg_logprob": -0.06248741651836195, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.01032268162816763}, {"id": 936, "seek": 527432, "start": 5285.36, "end": 5293.759999999999, "text": " can think of a neural net as basically we tend to describe it as a discrete you know map from one", "tokens": [50916, 393, 519, 295, 257, 18161, 2533, 382, 1936, 321, 3928, 281, 6786, 309, 382, 257, 27706, 291, 458, 4471, 490, 472, 51336], "temperature": 0.0, "avg_logprob": -0.06248741651836195, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.01032268162816763}, {"id": 937, "seek": 527432, "start": 5293.759999999999, "end": 5298.32, "text": " point to another point but if you think of it as a continuous process which is what we learned from", "tokens": [51336, 935, 281, 1071, 935, 457, 498, 291, 519, 295, 309, 382, 257, 10957, 1399, 597, 307, 437, 321, 3264, 490, 51564], "temperature": 0.0, "avg_logprob": -0.06248741651836195, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.01032268162816763}, {"id": 938, "seek": 529832, "start": 5298.32, "end": 5305.12, "text": " the ODE description of a neural net if you think of it as a continuous process then it's really", "tokens": [50364, 264, 422, 22296, 3855, 295, 257, 18161, 2533, 498, 291, 519, 295, 309, 382, 257, 10957, 1399, 550, 309, 311, 534, 50704], "temperature": 0.0, "avg_logprob": -0.07677328863809275, "compression_ratio": 1.958974358974359, "no_speech_prob": 0.013841248117387295}, {"id": 939, "seek": 529832, "start": 5305.84, "end": 5311.599999999999, "text": " you can just think of that convolution this map you can just think of it as the matrix exponential", "tokens": [50740, 291, 393, 445, 519, 295, 300, 45216, 341, 4471, 291, 393, 445, 519, 295, 309, 382, 264, 8141, 21510, 51028], "temperature": 0.0, "avg_logprob": -0.07677328863809275, "compression_ratio": 1.958974358974359, "no_speech_prob": 0.013841248117387295}, {"id": 940, "seek": 529832, "start": 5311.599999999999, "end": 5317.04, "text": " solution to this to this ODE in math literature you call this the Green's function so you can", "tokens": [51028, 3827, 281, 341, 281, 341, 422, 22296, 294, 5221, 10394, 291, 818, 341, 264, 6969, 311, 2445, 370, 291, 393, 51300], "temperature": 0.0, "avg_logprob": -0.07677328863809275, "compression_ratio": 1.958974358974359, "no_speech_prob": 0.013841248117387295}, {"id": 941, "seek": 529832, "start": 5317.04, "end": 5322.24, "text": " think of a convolution basically as the Green's function of a partial differential equation I", "tokens": [51300, 519, 295, 257, 45216, 1936, 382, 264, 6969, 311, 2445, 295, 257, 14641, 15756, 5367, 286, 51560], "temperature": 0.0, "avg_logprob": -0.07677328863809275, "compression_ratio": 1.958974358974359, "no_speech_prob": 0.013841248117387295}, {"id": 942, "seek": 532224, "start": 5322.24, "end": 5326.5599999999995, "text": " think that's where the word where this feels like a very fundamental object in some sense", "tokens": [50364, 519, 300, 311, 689, 264, 1349, 689, 341, 3417, 411, 257, 588, 8088, 2657, 294, 512, 2020, 50580], "temperature": 0.0, "avg_logprob": -0.08614685850323371, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.01639610342681408}, {"id": 943, "seek": 532224, "start": 5327.36, "end": 5333.599999999999, "text": " so in in a talk you gave recently on the future of graph neural networks you were talking about a", "tokens": [50620, 370, 294, 294, 257, 751, 291, 2729, 3938, 322, 264, 2027, 295, 4295, 18161, 9590, 291, 645, 1417, 466, 257, 50932], "temperature": 0.0, "avg_logprob": -0.08614685850323371, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.01639610342681408}, {"id": 944, "seek": 532224, "start": 5333.599999999999, "end": 5339.2, "text": " number of ideas from physics that hadn't really made it into machine learning among them things", "tokens": [50932, 1230, 295, 3487, 490, 10649, 300, 8782, 380, 534, 1027, 309, 666, 3479, 2539, 3654, 552, 721, 51212], "temperature": 0.0, "avg_logprob": -0.08614685850323371, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.01639610342681408}, {"id": 945, "seek": 532224, "start": 5339.2, "end": 5345.04, "text": " like renormalization chaos and holography would you care to unpack these ideas a little bit and", "tokens": [51212, 411, 8124, 24440, 2144, 14158, 293, 38541, 2662, 88, 576, 291, 1127, 281, 26699, 613, 3487, 257, 707, 857, 293, 51504], "temperature": 0.0, "avg_logprob": -0.08614685850323371, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.01639610342681408}, {"id": 946, "seek": 532224, "start": 5345.04, "end": 5350.639999999999, "text": " tell us where you see the future is in these ideas yeah so the reason I mentioned these because I", "tokens": [51504, 980, 505, 689, 291, 536, 264, 2027, 307, 294, 613, 3487, 1338, 370, 264, 1778, 286, 2835, 613, 570, 286, 51784], "temperature": 0.0, "avg_logprob": -0.08614685850323371, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.01639610342681408}, {"id": 947, "seek": 535064, "start": 5350.64, "end": 5355.84, "text": " think there's a lot of really cool ideas in physics which are still remain unexplored but there", "tokens": [50364, 519, 456, 311, 257, 688, 295, 534, 1627, 3487, 294, 10649, 597, 366, 920, 6222, 11572, 564, 2769, 457, 456, 50624], "temperature": 0.0, "avg_logprob": -0.05718738299149733, "compression_ratio": 1.8365758754863812, "no_speech_prob": 0.0004043866356369108}, {"id": 948, "seek": 535064, "start": 5355.84, "end": 5359.76, "text": " is more and more physicists who are moving into the field and some of these ideas are actually", "tokens": [50624, 307, 544, 293, 544, 48716, 567, 366, 2684, 666, 264, 2519, 293, 512, 295, 613, 3487, 366, 767, 50820], "temperature": 0.0, "avg_logprob": -0.05718738299149733, "compression_ratio": 1.8365758754863812, "no_speech_prob": 0.0004043866356369108}, {"id": 949, "seek": 535064, "start": 5359.76, "end": 5365.04, "text": " you know being worked out as we speak so I recently saw about two papers on renormalization", "tokens": [50820, 291, 458, 885, 2732, 484, 382, 321, 1710, 370, 286, 3938, 1866, 466, 732, 10577, 322, 8124, 24440, 2144, 51084], "temperature": 0.0, "avg_logprob": -0.05718738299149733, "compression_ratio": 1.8365758754863812, "no_speech_prob": 0.0004043866356369108}, {"id": 950, "seek": 535064, "start": 5365.04, "end": 5371.04, "text": " so renormalization is something in in physics which basically you start with a system with a", "tokens": [51084, 370, 8124, 24440, 2144, 307, 746, 294, 294, 10649, 597, 1936, 291, 722, 365, 257, 1185, 365, 257, 51384], "temperature": 0.0, "avg_logprob": -0.05718738299149733, "compression_ratio": 1.8365758754863812, "no_speech_prob": 0.0004043866356369108}, {"id": 951, "seek": 535064, "start": 5371.04, "end": 5376.320000000001, "text": " whole lot of degrees of freedom like say particles moving around or something like this and then", "tokens": [51384, 1379, 688, 295, 5310, 295, 5645, 411, 584, 10007, 2684, 926, 420, 746, 411, 341, 293, 550, 51648], "temperature": 0.0, "avg_logprob": -0.05718738299149733, "compression_ratio": 1.8365758754863812, "no_speech_prob": 0.0004043866356369108}, {"id": 952, "seek": 537632, "start": 5376.639999999999, "end": 5384.0, "text": " coarse grain the system slowly and what means is that by coarse graining you zoom out and you", "tokens": [50380, 39312, 12837, 264, 1185, 5692, 293, 437, 1355, 307, 300, 538, 39312, 1295, 1760, 291, 8863, 484, 293, 291, 50748], "temperature": 0.0, "avg_logprob": -0.0713544750213623, "compression_ratio": 1.8682170542635659, "no_speech_prob": 0.00439463322982192}, {"id": 953, "seek": 537632, "start": 5384.0, "end": 5388.799999999999, "text": " build an effective theory of the underlying theory in the same sense as thermodynamics is an effective", "tokens": [50748, 1322, 364, 4942, 5261, 295, 264, 14217, 5261, 294, 264, 912, 2020, 382, 8810, 35483, 307, 364, 4942, 50988], "temperature": 0.0, "avg_logprob": -0.0713544750213623, "compression_ratio": 1.8682170542635659, "no_speech_prob": 0.00439463322982192}, {"id": 954, "seek": 537632, "start": 5388.799999999999, "end": 5394.0, "text": " theory of statistical mechanics where basically all the particles are now removed but you now", "tokens": [50988, 5261, 295, 22820, 12939, 689, 1936, 439, 264, 10007, 366, 586, 7261, 457, 291, 586, 51248], "temperature": 0.0, "avg_logprob": -0.0713544750213623, "compression_ratio": 1.8682170542635659, "no_speech_prob": 0.00439463322982192}, {"id": 955, "seek": 537632, "start": 5394.0, "end": 5398.4, "text": " have an effective sort of description of your world this is the same as what happens in neural", "tokens": [51248, 362, 364, 4942, 1333, 295, 3855, 295, 428, 1002, 341, 307, 264, 912, 382, 437, 2314, 294, 18161, 51468], "temperature": 0.0, "avg_logprob": -0.0713544750213623, "compression_ratio": 1.8682170542635659, "no_speech_prob": 0.00439463322982192}, {"id": 956, "seek": 537632, "start": 5398.4, "end": 5402.24, "text": " nets right the neural nets we talk about pixels at the bottom layer and maybe edge detectors and", "tokens": [51468, 36170, 558, 264, 18161, 36170, 321, 751, 466, 18668, 412, 264, 2767, 4583, 293, 1310, 4691, 46866, 293, 51660], "temperature": 0.0, "avg_logprob": -0.0713544750213623, "compression_ratio": 1.8682170542635659, "no_speech_prob": 0.00439463322982192}, {"id": 957, "seek": 540224, "start": 5402.24, "end": 5407.44, "text": " things at the very top of it we're talking about objects and relations between objects which are", "tokens": [50364, 721, 412, 264, 588, 1192, 295, 309, 321, 434, 1417, 466, 6565, 293, 2299, 1296, 6565, 597, 366, 50624], "temperature": 0.0, "avg_logprob": -0.06562234178374085, "compression_ratio": 1.6623931623931625, "no_speech_prob": 0.016377031803131104}, {"id": 958, "seek": 540224, "start": 5407.44, "end": 5414.48, "text": " aggregated emergent properties from this neural net and ideas from renormalization theory might", "tokens": [50624, 16743, 770, 4345, 6930, 7221, 490, 341, 18161, 2533, 293, 3487, 490, 8124, 24440, 2144, 5261, 1062, 50976], "temperature": 0.0, "avg_logprob": -0.06562234178374085, "compression_ratio": 1.6623931623931625, "no_speech_prob": 0.016377031803131104}, {"id": 959, "seek": 540224, "start": 5414.48, "end": 5420.4, "text": " very nicely apply to this particular problem and indeed have already been applied with some success", "tokens": [50976, 588, 9594, 3079, 281, 341, 1729, 1154, 293, 6451, 362, 1217, 668, 6456, 365, 512, 2245, 51272], "temperature": 0.0, "avg_logprob": -0.06562234178374085, "compression_ratio": 1.6623931623931625, "no_speech_prob": 0.016377031803131104}, {"id": 960, "seek": 540224, "start": 5420.4, "end": 5425.92, "text": " the other one which you mentioned was chaos and I think there is a very nice connection actually", "tokens": [51272, 264, 661, 472, 597, 291, 2835, 390, 14158, 293, 286, 519, 456, 307, 257, 588, 1481, 4984, 767, 51548], "temperature": 0.0, "avg_logprob": -0.06562234178374085, "compression_ratio": 1.6623931623931625, "no_speech_prob": 0.016377031803131104}, {"id": 961, "seek": 542592, "start": 5425.92, "end": 5432.64, "text": " with chaos theory going back to work I did a long time ago which are called herding in particular", "tokens": [50364, 365, 14158, 5261, 516, 646, 281, 589, 286, 630, 257, 938, 565, 2057, 597, 366, 1219, 720, 3584, 294, 1729, 50700], "temperature": 0.0, "avg_logprob": -0.08426758127475004, "compression_ratio": 2.0, "no_speech_prob": 0.057424113154411316}, {"id": 962, "seek": 542592, "start": 5432.64, "end": 5438.8, "text": " you can think of sampling from a particular distribution you can do it either by the typical", "tokens": [50700, 291, 393, 519, 295, 21179, 490, 257, 1729, 7316, 291, 393, 360, 309, 2139, 538, 264, 7476, 51008], "temperature": 0.0, "avg_logprob": -0.08426758127475004, "compression_ratio": 2.0, "no_speech_prob": 0.057424113154411316}, {"id": 963, "seek": 542592, "start": 5438.8, "end": 5443.2, "text": " way is first of all you can think of it as a dynamical system as a stochastic dynamical system", "tokens": [51008, 636, 307, 700, 295, 439, 291, 393, 519, 295, 309, 382, 257, 5999, 804, 1185, 382, 257, 342, 8997, 2750, 5999, 804, 1185, 51228], "temperature": 0.0, "avg_logprob": -0.08426758127475004, "compression_ratio": 2.0, "no_speech_prob": 0.057424113154411316}, {"id": 964, "seek": 542592, "start": 5443.2, "end": 5448.08, "text": " and you think of it as there's a you're at a particular point and then you propose to go", "tokens": [51228, 293, 291, 519, 295, 309, 382, 456, 311, 257, 291, 434, 412, 257, 1729, 935, 293, 550, 291, 17421, 281, 352, 51472], "temperature": 0.0, "avg_logprob": -0.08426758127475004, "compression_ratio": 2.0, "no_speech_prob": 0.057424113154411316}, {"id": 965, "seek": 542592, "start": 5448.08, "end": 5452.0, "text": " somewhere and then you accept or reject a particular point and then you just jump through", "tokens": [51472, 4079, 293, 550, 291, 3241, 420, 8248, 257, 1729, 935, 293, 550, 291, 445, 3012, 807, 51668], "temperature": 0.0, "avg_logprob": -0.08426758127475004, "compression_ratio": 2.0, "no_speech_prob": 0.057424113154411316}, {"id": 966, "seek": 545200, "start": 5452.0, "end": 5458.24, "text": " the space and you collect your the points that you jumped to then you look at that collection and", "tokens": [50364, 264, 1901, 293, 291, 2500, 428, 264, 2793, 300, 291, 13864, 281, 550, 291, 574, 412, 300, 5765, 293, 50676], "temperature": 0.0, "avg_logprob": -0.049263050442650204, "compression_ratio": 1.9341563786008231, "no_speech_prob": 0.0015480886213481426}, {"id": 967, "seek": 545200, "start": 5458.24, "end": 5462.64, "text": " that collection should then actually distribute according to the probability distribution that", "tokens": [50676, 300, 5765, 820, 550, 767, 20594, 4650, 281, 264, 8482, 7316, 300, 50896], "temperature": 0.0, "avg_logprob": -0.049263050442650204, "compression_ratio": 1.9341563786008231, "no_speech_prob": 0.0015480886213481426}, {"id": 968, "seek": 545200, "start": 5462.64, "end": 5468.08, "text": " you're sampling from now that's a stochastic process but if you think very hard about that", "tokens": [50896, 291, 434, 21179, 490, 586, 300, 311, 257, 342, 8997, 2750, 1399, 457, 498, 291, 519, 588, 1152, 466, 300, 51168], "temperature": 0.0, "avg_logprob": -0.049263050442650204, "compression_ratio": 1.9341563786008231, "no_speech_prob": 0.0015480886213481426}, {"id": 969, "seek": 545200, "start": 5468.8, "end": 5473.6, "text": " in fact it's a deterministic process even if you try to make it stochastic and the reason is that", "tokens": [51204, 294, 1186, 309, 311, 257, 15957, 3142, 1399, 754, 498, 291, 853, 281, 652, 309, 342, 8997, 2750, 293, 264, 1778, 307, 300, 51444], "temperature": 0.0, "avg_logprob": -0.049263050442650204, "compression_ratio": 1.9341563786008231, "no_speech_prob": 0.0015480886213481426}, {"id": 970, "seek": 545200, "start": 5473.6, "end": 5478.08, "text": " every you know you're doing a whole bunch of calculations and so now and then you call a", "tokens": [51444, 633, 291, 458, 291, 434, 884, 257, 1379, 3840, 295, 20448, 293, 370, 586, 293, 550, 291, 818, 257, 51668], "temperature": 0.0, "avg_logprob": -0.049263050442650204, "compression_ratio": 1.9341563786008231, "no_speech_prob": 0.0015480886213481426}, {"id": 971, "seek": 547808, "start": 5478.08, "end": 5483.2, "text": " random number generator but the random number generator really is a pseudo random number generator", "tokens": [50364, 4974, 1230, 19265, 457, 264, 4974, 1230, 19265, 534, 307, 257, 35899, 4974, 1230, 19265, 50620], "temperature": 0.0, "avg_logprob": -0.0698313944548079, "compression_ratio": 2.091304347826087, "no_speech_prob": 0.010634081438183784}, {"id": 972, "seek": 547808, "start": 5483.2, "end": 5487.68, "text": " it is also a deterministic calculation that you're doing so the whole thing end to end is just a", "tokens": [50620, 309, 307, 611, 257, 15957, 3142, 17108, 300, 291, 434, 884, 370, 264, 1379, 551, 917, 281, 917, 307, 445, 257, 50844], "temperature": 0.0, "avg_logprob": -0.0698313944548079, "compression_ratio": 2.091304347826087, "no_speech_prob": 0.010634081438183784}, {"id": 973, "seek": 547808, "start": 5488.4, "end": 5492.88, "text": " a deterministic calculation but because you're calling the pseudo random number generator it", "tokens": [50880, 257, 15957, 3142, 17108, 457, 570, 291, 434, 5141, 264, 35899, 4974, 1230, 19265, 309, 51104], "temperature": 0.0, "avg_logprob": -0.0698313944548079, "compression_ratio": 2.091304347826087, "no_speech_prob": 0.010634081438183784}, {"id": 974, "seek": 547808, "start": 5492.88, "end": 5498.8, "text": " looks very stochastic but truly it is a chaotic process and so you should really be able to describe", "tokens": [51104, 1542, 588, 342, 8997, 2750, 457, 4908, 309, 307, 257, 27013, 1399, 293, 370, 291, 820, 534, 312, 1075, 281, 6786, 51400], "temperature": 0.0, "avg_logprob": -0.0698313944548079, "compression_ratio": 2.091304347826087, "no_speech_prob": 0.010634081438183784}, {"id": 975, "seek": 547808, "start": 5498.8, "end": 5504.08, "text": " the system by chaos theory and the theory of nonlinear dynamical systems now what I've been", "tokens": [51400, 264, 1185, 538, 14158, 5261, 293, 264, 5261, 295, 2107, 28263, 5999, 804, 3652, 586, 437, 286, 600, 668, 51664], "temperature": 0.0, "avg_logprob": -0.0698313944548079, "compression_ratio": 2.091304347826087, "no_speech_prob": 0.010634081438183784}, {"id": 976, "seek": 550408, "start": 5504.08, "end": 5512.24, "text": " working on with my postdoc and Roberto we've been working on is thinking about let's make it a little", "tokens": [50364, 1364, 322, 365, 452, 2183, 39966, 293, 40354, 321, 600, 668, 1364, 322, 307, 1953, 466, 718, 311, 652, 309, 257, 707, 50772], "temperature": 0.0, "avg_logprob": -0.12485760908860427, "compression_ratio": 1.738532110091743, "no_speech_prob": 0.02060234732925892}, {"id": 977, "seek": 550408, "start": 5512.24, "end": 5518.48, "text": " bit less chaotic so let's make this actually a deterministic system which is maybe at the edge", "tokens": [50772, 857, 1570, 27013, 370, 718, 311, 652, 341, 767, 257, 15957, 3142, 1185, 597, 307, 1310, 412, 264, 4691, 51084], "temperature": 0.0, "avg_logprob": -0.12485760908860427, "compression_ratio": 1.738532110091743, "no_speech_prob": 0.02060234732925892}, {"id": 978, "seek": 550408, "start": 5518.48, "end": 5523.84, "text": " of chaos and again this is one of these very deep questions that's in my head so I think so there's", "tokens": [51084, 295, 14158, 293, 797, 341, 307, 472, 295, 613, 588, 2452, 1651, 300, 311, 294, 452, 1378, 370, 286, 519, 370, 456, 311, 51352], "temperature": 0.0, "avg_logprob": -0.12485760908860427, "compression_ratio": 1.738532110091743, "no_speech_prob": 0.02060234732925892}, {"id": 979, "seek": 550408, "start": 5524.48, "end": 5528.48, "text": " there is something very interesting and deep here which is if you do if you try to", "tokens": [51384, 456, 307, 746, 588, 1880, 293, 2452, 510, 597, 307, 498, 291, 360, 498, 291, 853, 281, 51584], "temperature": 0.0, "avg_logprob": -0.12485760908860427, "compression_ratio": 1.738532110091743, "no_speech_prob": 0.02060234732925892}, {"id": 980, "seek": 552848, "start": 5529.12, "end": 5535.919999999999, "text": " do a computation on the one hand you want to store information things that you've calculated", "tokens": [50396, 360, 257, 24903, 322, 264, 472, 1011, 291, 528, 281, 3531, 1589, 721, 300, 291, 600, 15598, 50736], "temperature": 0.0, "avg_logprob": -0.03933223385677159, "compression_ratio": 2.0681818181818183, "no_speech_prob": 0.025153109803795815}, {"id": 981, "seek": 552848, "start": 5535.919999999999, "end": 5541.839999999999, "text": " and for that things need to be stable on the other hand you want to transform information", "tokens": [50736, 293, 337, 300, 721, 643, 281, 312, 8351, 322, 264, 661, 1011, 291, 528, 281, 4088, 1589, 51032], "temperature": 0.0, "avg_logprob": -0.03933223385677159, "compression_ratio": 2.0681818181818183, "no_speech_prob": 0.025153109803795815}, {"id": 982, "seek": 552848, "start": 5541.839999999999, "end": 5546.24, "text": " because that's what a calculation is right and so there you want to be in this sort of", "tokens": [51032, 570, 300, 311, 437, 257, 17108, 307, 558, 293, 370, 456, 291, 528, 281, 312, 294, 341, 1333, 295, 51252], "temperature": 0.0, "avg_logprob": -0.03933223385677159, "compression_ratio": 2.0681818181818183, "no_speech_prob": 0.025153109803795815}, {"id": 983, "seek": 552848, "start": 5546.24, "end": 5551.36, "text": " more chaotic domain and it turns out that the best place to be is at the edge of two things", "tokens": [51252, 544, 27013, 9274, 293, 309, 4523, 484, 300, 264, 1151, 1081, 281, 312, 307, 412, 264, 4691, 295, 732, 721, 51508], "temperature": 0.0, "avg_logprob": -0.03933223385677159, "compression_ratio": 2.0681818181818183, "no_speech_prob": 0.025153109803795815}, {"id": 984, "seek": 552848, "start": 5551.36, "end": 5555.12, "text": " where you can go to the right a little bit and be more stable and go to the left a little bit", "tokens": [51508, 689, 291, 393, 352, 281, 264, 558, 257, 707, 857, 293, 312, 544, 8351, 293, 352, 281, 264, 1411, 257, 707, 857, 51696], "temperature": 0.0, "avg_logprob": -0.03933223385677159, "compression_ratio": 2.0681818181818183, "no_speech_prob": 0.025153109803795815}, {"id": 985, "seek": 555512, "start": 5555.12, "end": 5561.5199999999995, "text": " and you can transform things and compute things and so I also think that when you're trying to", "tokens": [50364, 293, 291, 393, 4088, 721, 293, 14722, 721, 293, 370, 286, 611, 519, 300, 562, 291, 434, 1382, 281, 50684], "temperature": 0.0, "avg_logprob": -0.07725080471594357, "compression_ratio": 1.87890625, "no_speech_prob": 0.003882993245497346}, {"id": 986, "seek": 555512, "start": 5561.5199999999995, "end": 5567.04, "text": " sample or in you know sampling can be equated with learning if you're Bayesian about things because", "tokens": [50684, 6889, 420, 294, 291, 458, 21179, 393, 312, 1267, 770, 365, 2539, 498, 291, 434, 7840, 42434, 466, 721, 570, 50960], "temperature": 0.0, "avg_logprob": -0.07725080471594357, "compression_ratio": 1.87890625, "no_speech_prob": 0.003882993245497346}, {"id": 987, "seek": 555512, "start": 5567.04, "end": 5571.36, "text": " in learning is basically sampling from the posterior distribution and that's same as learning", "tokens": [50960, 294, 2539, 307, 1936, 21179, 490, 264, 33529, 7316, 293, 300, 311, 912, 382, 2539, 51176], "temperature": 0.0, "avg_logprob": -0.07725080471594357, "compression_ratio": 1.87890625, "no_speech_prob": 0.003882993245497346}, {"id": 988, "seek": 555512, "start": 5572.4, "end": 5579.12, "text": " you can if you can design samplers that are not completely chaotic as the ones that we describe", "tokens": [51228, 291, 393, 498, 291, 393, 1715, 3247, 564, 433, 300, 366, 406, 2584, 27013, 382, 264, 2306, 300, 321, 6786, 51564], "temperature": 0.0, "avg_logprob": -0.07725080471594357, "compression_ratio": 1.87890625, "no_speech_prob": 0.003882993245497346}, {"id": 989, "seek": 555512, "start": 5579.12, "end": 5584.0, "text": " now but they're more structured and less chaotic and more deterministic moving through the space", "tokens": [51564, 586, 457, 436, 434, 544, 18519, 293, 1570, 27013, 293, 544, 15957, 3142, 2684, 807, 264, 1901, 51808], "temperature": 0.0, "avg_logprob": -0.07725080471594357, "compression_ratio": 1.87890625, "no_speech_prob": 0.003882993245497346}, {"id": 990, "seek": 558400, "start": 5584.0, "end": 5588.88, "text": " you can learn a lot faster and I find that and then you can actually start to map it", "tokens": [50364, 291, 393, 1466, 257, 688, 4663, 293, 286, 915, 300, 293, 550, 291, 393, 767, 722, 281, 4471, 309, 50608], "temperature": 0.0, "avg_logprob": -0.062188518857492985, "compression_ratio": 1.9024390243902438, "no_speech_prob": 0.004195025656372309}, {"id": 991, "seek": 558400, "start": 5588.88, "end": 5594.4, "text": " onto sort of complexity theory notions if you think of this sampling from a discrete set of", "tokens": [50608, 3911, 1333, 295, 14024, 5261, 35799, 498, 291, 519, 295, 341, 21179, 490, 257, 27706, 992, 295, 50884], "temperature": 0.0, "avg_logprob": -0.062188518857492985, "compression_ratio": 1.9024390243902438, "no_speech_prob": 0.004195025656372309}, {"id": 992, "seek": 558400, "start": 5594.4, "end": 5600.08, "text": " states what kind of properties do the sequences that I generate have what is the entropy of the", "tokens": [50884, 4368, 437, 733, 295, 7221, 360, 264, 22978, 300, 286, 8460, 362, 437, 307, 264, 30867, 295, 264, 51168], "temperature": 0.0, "avg_logprob": -0.062188518857492985, "compression_ratio": 1.9024390243902438, "no_speech_prob": 0.004195025656372309}, {"id": 993, "seek": 558400, "start": 5600.08, "end": 5605.28, "text": " sequences that I'm generating for instance or what kind of substructures is it for instance going to", "tokens": [51168, 22978, 300, 286, 478, 17746, 337, 5197, 420, 437, 733, 295, 4594, 44513, 307, 309, 337, 5197, 516, 281, 51428], "temperature": 0.0, "avg_logprob": -0.062188518857492985, "compression_ratio": 1.9024390243902438, "no_speech_prob": 0.004195025656372309}, {"id": 994, "seek": 558400, "start": 5605.28, "end": 5609.76, "text": " be periodic or are there periodic substructures inside of it or all these things and these are", "tokens": [51428, 312, 27790, 420, 366, 456, 27790, 4594, 44513, 1854, 295, 309, 420, 439, 613, 721, 293, 613, 366, 51652], "temperature": 0.0, "avg_logprob": -0.062188518857492985, "compression_ratio": 1.9024390243902438, "no_speech_prob": 0.004195025656372309}, {"id": 995, "seek": 560976, "start": 5609.76, "end": 5614.8, "text": " studied by the theory of chaos and nonlinear dynamical systems so connecting these two fields", "tokens": [50364, 9454, 538, 264, 5261, 295, 14158, 293, 2107, 28263, 5999, 804, 3652, 370, 11015, 613, 732, 7909, 50616], "temperature": 0.0, "avg_logprob": -0.09494775533676147, "compression_ratio": 1.8416988416988418, "no_speech_prob": 0.008704844862222672}, {"id": 996, "seek": 560976, "start": 5615.68, "end": 5621.280000000001, "text": " feels to me like a very fundamental thing to try and do and some people have tried a few things", "tokens": [50660, 3417, 281, 385, 411, 257, 588, 8088, 551, 281, 853, 293, 360, 293, 512, 561, 362, 3031, 257, 1326, 721, 50940], "temperature": 0.0, "avg_logprob": -0.09494775533676147, "compression_ratio": 1.8416988416988418, "no_speech_prob": 0.008704844862222672}, {"id": 997, "seek": 560976, "start": 5621.280000000001, "end": 5625.76, "text": " people have looked at well if you look at a neural net there's an iterated map you map things to", "tokens": [50940, 561, 362, 2956, 412, 731, 498, 291, 574, 412, 257, 18161, 2533, 456, 311, 364, 17138, 770, 4471, 291, 4471, 721, 281, 51164], "temperature": 0.0, "avg_logprob": -0.09494775533676147, "compression_ratio": 1.8416988416988418, "no_speech_prob": 0.008704844862222672}, {"id": 998, "seek": 560976, "start": 5625.76, "end": 5631.84, "text": " hidden layers in later if you think of that iterated map and think of it as is that map chaotic", "tokens": [51164, 7633, 7914, 294, 1780, 498, 291, 519, 295, 300, 17138, 770, 4471, 293, 519, 295, 309, 382, 307, 300, 4471, 27013, 51468], "temperature": 0.0, "avg_logprob": -0.09494775533676147, "compression_ratio": 1.8416988416988418, "no_speech_prob": 0.008704844862222672}, {"id": 999, "seek": 560976, "start": 5631.84, "end": 5638.08, "text": " being on the edge of chaos is the best thing you shouldn't be completely or nonmovable because", "tokens": [51468, 885, 322, 264, 4691, 295, 14158, 307, 264, 1151, 551, 291, 4659, 380, 312, 2584, 420, 2107, 3280, 17915, 570, 51780], "temperature": 0.0, "avg_logprob": -0.09494775533676147, "compression_ratio": 1.8416988416988418, "no_speech_prob": 0.008704844862222672}, {"id": 1000, "seek": 563808, "start": 5638.16, "end": 5642.72, "text": " then everything you put in is going to be mapped to the same point very uninteresting you also", "tokens": [50368, 550, 1203, 291, 829, 294, 307, 516, 281, 312, 33318, 281, 264, 912, 935, 588, 49234, 8714, 291, 611, 50596], "temperature": 0.0, "avg_logprob": -0.052192732139869975, "compression_ratio": 1.9137254901960785, "no_speech_prob": 0.002888103248551488}, {"id": 1001, "seek": 563808, "start": 5642.72, "end": 5647.76, "text": " shouldn't be super chaotic because or whatever you put in you're going to some random point in space", "tokens": [50596, 4659, 380, 312, 1687, 27013, 570, 420, 2035, 291, 829, 294, 291, 434, 516, 281, 512, 4974, 935, 294, 1901, 50848], "temperature": 0.0, "avg_logprob": -0.052192732139869975, "compression_ratio": 1.9137254901960785, "no_speech_prob": 0.002888103248551488}, {"id": 1002, "seek": 563808, "start": 5647.76, "end": 5652.8, "text": " and that's not very predictive so you need to be at this intersection space between chaos and non-", "tokens": [50848, 293, 300, 311, 406, 588, 35521, 370, 291, 643, 281, 312, 412, 341, 15236, 1901, 1296, 14158, 293, 2107, 12, 51100], "temperature": 0.0, "avg_logprob": -0.052192732139869975, "compression_ratio": 1.9137254901960785, "no_speech_prob": 0.002888103248551488}, {"id": 1003, "seek": 563808, "start": 5652.8, "end": 5657.84, "text": " chaos and then you can do interesting computations so this is the same idea right so to me that's", "tokens": [51100, 14158, 293, 550, 291, 393, 360, 1880, 2807, 763, 370, 341, 307, 264, 912, 1558, 558, 370, 281, 385, 300, 311, 51352], "temperature": 0.0, "avg_logprob": -0.052192732139869975, "compression_ratio": 1.9137254901960785, "no_speech_prob": 0.002888103248551488}, {"id": 1004, "seek": 563808, "start": 5657.84, "end": 5663.84, "text": " exciting because now suddenly a whole field of exciting mathematics is cracked open and you can", "tokens": [51352, 4670, 570, 586, 5800, 257, 1379, 2519, 295, 4670, 18666, 307, 25140, 1269, 293, 291, 393, 51652], "temperature": 0.0, "avg_logprob": -0.052192732139869975, "compression_ratio": 1.9137254901960785, "no_speech_prob": 0.002888103248551488}, {"id": 1005, "seek": 566384, "start": 5663.84, "end": 5669.4400000000005, "text": " start to use all these tools in machine learning awesome thank you fantastic now might be a good", "tokens": [50364, 722, 281, 764, 439, 613, 3873, 294, 3479, 2539, 3476, 1309, 291, 5456, 586, 1062, 312, 257, 665, 50644], "temperature": 0.0, "avg_logprob": -0.08092471448386587, "compression_ratio": 1.6553398058252426, "no_speech_prob": 0.028358150273561478}, {"id": 1006, "seek": 566384, "start": 5669.4400000000005, "end": 5676.72, "text": " time to go over to reddit we asked reddit for questions and the top rated question is by tsa", "tokens": [50644, 565, 281, 352, 670, 281, 2182, 17975, 321, 2351, 2182, 17975, 337, 1651, 293, 264, 1192, 22103, 1168, 307, 538, 256, 5790, 51008], "temperature": 0.0, "avg_logprob": -0.08092471448386587, "compression_ratio": 1.6553398058252426, "no_speech_prob": 0.028358150273561478}, {"id": 1007, "seek": 566384, "start": 5677.360000000001, "end": 5680.4800000000005, "text": " hi max when will you be changing your last name to pooling", "tokens": [51040, 4879, 11469, 562, 486, 291, 312, 4473, 428, 1036, 1315, 281, 7005, 278, 51196], "temperature": 0.0, "avg_logprob": -0.08092471448386587, "compression_ratio": 1.6553398058252426, "no_speech_prob": 0.028358150273561478}, {"id": 1008, "seek": 566384, "start": 5684.24, "end": 5690.16, "text": " so actually there is a paper that a colleague of mine wrote and i think they had an operator", "tokens": [51384, 370, 767, 456, 307, 257, 3035, 300, 257, 13532, 295, 3892, 4114, 293, 741, 519, 436, 632, 364, 12973, 51680], "temperature": 0.0, "avg_logprob": -0.08092471448386587, "compression_ratio": 1.6553398058252426, "no_speech_prob": 0.028358150273561478}, {"id": 1009, "seek": 569016, "start": 5690.96, "end": 5697.2, "text": " instead of pooling you could you could do a a welling operator so and instead of changing", "tokens": [50404, 2602, 295, 7005, 278, 291, 727, 291, 727, 360, 257, 257, 731, 278, 12973, 370, 293, 2602, 295, 4473, 50716], "temperature": 0.0, "avg_logprob": -0.07552626581475286, "compression_ratio": 1.873015873015873, "no_speech_prob": 0.013779399916529655}, {"id": 1010, "seek": 569016, "start": 5697.2, "end": 5701.92, "text": " my name i i propose that we just change the operators that we use and change to welling", "tokens": [50716, 452, 1315, 741, 741, 17421, 300, 321, 445, 1319, 264, 19077, 300, 321, 764, 293, 1319, 281, 731, 278, 50952], "temperature": 0.0, "avg_logprob": -0.07552626581475286, "compression_ratio": 1.873015873015873, "no_speech_prob": 0.013779399916529655}, {"id": 1011, "seek": 569016, "start": 5701.92, "end": 5707.76, "text": " operators that's wonderful in the thread on reddit there were a few variations as well so maybe max", "tokens": [50952, 19077, 300, 311, 3715, 294, 264, 7207, 322, 2182, 17975, 456, 645, 257, 1326, 17840, 382, 731, 370, 1310, 11469, 51244], "temperature": 0.0, "avg_logprob": -0.07552626581475286, "compression_ratio": 1.873015873015873, "no_speech_prob": 0.013779399916529655}, {"id": 1012, "seek": 569016, "start": 5707.76, "end": 5714.5599999999995, "text": " power and someone asserted that pooling is your brother but anyway red portal says the conventional", "tokens": [51244, 1347, 293, 1580, 19810, 292, 300, 7005, 278, 307, 428, 3708, 457, 4033, 2182, 14982, 1619, 264, 16011, 51584], "temperature": 0.0, "avg_logprob": -0.07552626581475286, "compression_ratio": 1.873015873015873, "no_speech_prob": 0.013779399916529655}, {"id": 1013, "seek": 569016, "start": 5714.5599999999995, "end": 5719.599999999999, "text": " approach for analyzing continuous convolution would be Fourier analysis what was the rationale", "tokens": [51584, 3109, 337, 23663, 10957, 45216, 576, 312, 36810, 5215, 437, 390, 264, 41989, 51836], "temperature": 0.0, "avg_logprob": -0.07552626581475286, "compression_ratio": 1.873015873015873, "no_speech_prob": 0.013779399916529655}, {"id": 1014, "seek": 571960, "start": 5719.6, "end": 5724.88, "text": " behind the investigating continuous convolutions using probabilistic numerics that's a good question", "tokens": [50364, 2261, 264, 22858, 10957, 3754, 15892, 1228, 31959, 3142, 7866, 1167, 300, 311, 257, 665, 1168, 50628], "temperature": 0.0, "avg_logprob": -0.07080000922793434, "compression_ratio": 1.83206106870229, "no_speech_prob": 0.0059721930883824825}, {"id": 1015, "seek": 571960, "start": 5724.88, "end": 5731.04, "text": " so to me Fourier analysis it's true that you can i guess i could still do a Fourier analysis", "tokens": [50628, 370, 281, 385, 36810, 5215, 309, 311, 2074, 300, 291, 393, 741, 2041, 741, 727, 920, 360, 257, 36810, 5215, 50936], "temperature": 0.0, "avg_logprob": -0.07080000922793434, "compression_ratio": 1.83206106870229, "no_speech_prob": 0.0059721930883824825}, {"id": 1016, "seek": 571960, "start": 5731.04, "end": 5736.88, "text": " right because a Gaussian process you can decompose in terms of its Fourier waves and then it's the", "tokens": [50936, 558, 570, 257, 39148, 1399, 291, 393, 22867, 541, 294, 2115, 295, 1080, 36810, 9417, 293, 550, 309, 311, 264, 51228], "temperature": 0.0, "avg_logprob": -0.07080000922793434, "compression_ratio": 1.83206106870229, "no_speech_prob": 0.0059721930883824825}, {"id": 1017, "seek": 571960, "start": 5736.88, "end": 5743.280000000001, "text": " primal versus the dual view of a sort of any sort of kernel method so i could certainly go to the", "tokens": [51228, 2886, 304, 5717, 264, 11848, 1910, 295, 257, 1333, 295, 604, 1333, 295, 28256, 3170, 370, 741, 727, 3297, 352, 281, 264, 51548], "temperature": 0.0, "avg_logprob": -0.07080000922793434, "compression_ratio": 1.83206106870229, "no_speech_prob": 0.0059721930883824825}, {"id": 1018, "seek": 571960, "start": 5743.84, "end": 5748.320000000001, "text": " Fourier domain and do my calculations in the Fourier domain the quantum mechanics this is", "tokens": [51576, 36810, 9274, 293, 360, 452, 20448, 294, 264, 36810, 9274, 264, 13018, 12939, 341, 307, 51800], "temperature": 0.0, "avg_logprob": -0.07080000922793434, "compression_ratio": 1.83206106870229, "no_speech_prob": 0.0059721930883824825}, {"id": 1019, "seek": 574832, "start": 5748.32, "end": 5752.48, "text": " just another basis you just think of this as another basis you know not only quantum", "tokens": [50364, 445, 1071, 5143, 291, 445, 519, 295, 341, 382, 1071, 5143, 291, 458, 406, 787, 13018, 50572], "temperature": 0.0, "avg_logprob": -0.053067320400906594, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.0058143846690654755}, {"id": 1020, "seek": 574832, "start": 5752.48, "end": 5757.599999999999, "text": " mechanics in any signal processing sense and it's true that a convolution is easier there", "tokens": [50572, 12939, 294, 604, 6358, 9007, 2020, 293, 309, 311, 2074, 300, 257, 45216, 307, 3571, 456, 50828], "temperature": 0.0, "avg_logprob": -0.053067320400906594, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.0058143846690654755}, {"id": 1021, "seek": 574832, "start": 5757.599999999999, "end": 5765.679999999999, "text": " because just multiplication on the other hand convolutions are very efficient in modern software", "tokens": [50828, 570, 445, 27290, 322, 264, 661, 1011, 3754, 15892, 366, 588, 7148, 294, 4363, 4722, 51232], "temperature": 0.0, "avg_logprob": -0.053067320400906594, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.0058143846690654755}, {"id": 1022, "seek": 574832, "start": 5765.679999999999, "end": 5772.799999999999, "text": " packages for gpu so sometimes it's also not necessarily faster to do that but it's a good", "tokens": [51232, 17401, 337, 290, 34859, 370, 2171, 309, 311, 611, 406, 4725, 4663, 281, 360, 300, 457, 309, 311, 257, 665, 51588], "temperature": 0.0, "avg_logprob": -0.053067320400906594, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.0058143846690654755}, {"id": 1023, "seek": 574832, "start": 5772.799999999999, "end": 5778.24, "text": " suggestion and maybe something nice happens when you go to Fourier space and i just didn't explore", "tokens": [51588, 16541, 293, 1310, 746, 1481, 2314, 562, 291, 352, 281, 36810, 1901, 293, 741, 445, 994, 380, 6839, 51860], "temperature": 0.0, "avg_logprob": -0.053067320400906594, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.0058143846690654755}, {"id": 1024, "seek": 577824, "start": 5778.24, "end": 5786.719999999999, "text": " that fantastic we've also got jimmy the ant lion says hi max i notice your co-authors come from a", "tokens": [50364, 300, 5456, 321, 600, 611, 658, 361, 332, 2226, 264, 2511, 17226, 1619, 4879, 11469, 741, 3449, 428, 598, 12, 40198, 830, 808, 490, 257, 50788], "temperature": 0.0, "avg_logprob": -0.09771362940470378, "compression_ratio": 1.7699115044247788, "no_speech_prob": 0.002709014108404517}, {"id": 1025, "seek": 577824, "start": 5786.719999999999, "end": 5792.8, "text": " physics background can you explain why there are so many x physicists in deep learning yeah so that's", "tokens": [50788, 10649, 3678, 393, 291, 2903, 983, 456, 366, 370, 867, 2031, 48716, 294, 2452, 2539, 1338, 370, 300, 311, 51092], "temperature": 0.0, "avg_logprob": -0.09771362940470378, "compression_ratio": 1.7699115044247788, "no_speech_prob": 0.002709014108404517}, {"id": 1026, "seek": 577824, "start": 5792.8, "end": 5798.48, "text": " interesting i think there's just a lot of physicists and a fraction of those physicists is looking for", "tokens": [51092, 1880, 741, 519, 456, 311, 445, 257, 688, 295, 48716, 293, 257, 14135, 295, 729, 48716, 307, 1237, 337, 51376], "temperature": 0.0, "avg_logprob": -0.09771362940470378, "compression_ratio": 1.7699115044247788, "no_speech_prob": 0.002709014108404517}, {"id": 1027, "seek": 577824, "start": 5798.48, "end": 5804.16, "text": " other for greener pastures and i'm myself on one of those that i was looking for greener pastures", "tokens": [51376, 661, 337, 3092, 260, 1791, 1303, 293, 741, 478, 2059, 322, 472, 295, 729, 300, 741, 390, 1237, 337, 3092, 260, 1791, 1303, 51660], "temperature": 0.0, "avg_logprob": -0.09771362940470378, "compression_ratio": 1.7699115044247788, "no_speech_prob": 0.002709014108404517}, {"id": 1028, "seek": 580416, "start": 5804.88, "end": 5810.48, "text": " and they bring a really good toolbox so if you're done physics you're you have just a very good", "tokens": [50400, 293, 436, 1565, 257, 534, 665, 44593, 370, 498, 291, 434, 1096, 10649, 291, 434, 291, 362, 445, 257, 588, 665, 50680], "temperature": 0.0, "avg_logprob": -0.11962538567658897, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.01470924261957407}, {"id": 1029, "seek": 580416, "start": 5811.04, "end": 5816.4, "text": " mathematical toolbox but also very good intuition about PDEs and other world works and", "tokens": [50708, 18894, 44593, 457, 611, 588, 665, 24002, 466, 10464, 20442, 293, 661, 1002, 1985, 293, 50976], "temperature": 0.0, "avg_logprob": -0.11962538567658897, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.01470924261957407}, {"id": 1030, "seek": 580416, "start": 5816.4, "end": 5821.76, "text": " symmetries and all these kinds of things you bring and i think in some sense physics is also a bit", "tokens": [50976, 14232, 302, 2244, 293, 439, 613, 3685, 295, 721, 291, 1565, 293, 741, 519, 294, 512, 2020, 10649, 307, 611, 257, 857, 51244], "temperature": 0.0, "avg_logprob": -0.11962538567658897, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.01470924261957407}, {"id": 1031, "seek": 580416, "start": 5821.76, "end": 5826.24, "text": " of a container right if you do physics you can still do anything else afterwards in some sense", "tokens": [51244, 295, 257, 10129, 558, 498, 291, 360, 10649, 291, 393, 920, 360, 1340, 1646, 10543, 294, 512, 2020, 51468], "temperature": 0.0, "avg_logprob": -0.11962538567658897, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.01470924261957407}, {"id": 1032, "seek": 580416, "start": 5826.8, "end": 5832.08, "text": " and i think just there's just people who are naturally interested in in ai of course ai became", "tokens": [51496, 293, 741, 519, 445, 456, 311, 445, 561, 567, 366, 8195, 3102, 294, 294, 9783, 295, 1164, 9783, 3062, 51760], "temperature": 0.0, "avg_logprob": -0.11962538567658897, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.01470924261957407}, {"id": 1033, "seek": 583208, "start": 5832.08, "end": 5837.28, "text": " very popular at some point and so you have automatically people flock into that into that", "tokens": [50364, 588, 3743, 412, 512, 935, 293, 370, 291, 362, 6772, 561, 34819, 666, 300, 666, 300, 50624], "temperature": 0.0, "avg_logprob": -0.05241899765454806, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.004174708854407072}, {"id": 1034, "seek": 583208, "start": 5837.28, "end": 5843.12, "text": " field but yeah in general they're smart people so i guess it's nice to work with them maybe just", "tokens": [50624, 2519, 457, 1338, 294, 2674, 436, 434, 4069, 561, 370, 741, 2041, 309, 311, 1481, 281, 589, 365, 552, 1310, 445, 50916], "temperature": 0.0, "avg_logprob": -0.05241899765454806, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.004174708854407072}, {"id": 1035, "seek": 583208, "start": 5843.12, "end": 5848.24, "text": " circle back and close the loop to the beginning and we were talking about the research community", "tokens": [50916, 6329, 646, 293, 1998, 264, 6367, 281, 264, 2863, 293, 321, 645, 1417, 466, 264, 2132, 1768, 51172], "temperature": 0.0, "avg_logprob": -0.05241899765454806, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.004174708854407072}, {"id": 1036, "seek": 583208, "start": 5848.24, "end": 5855.36, "text": " and kind of the machine learning research field i i loved what you suggested and as i understand", "tokens": [51172, 293, 733, 295, 264, 3479, 2539, 2132, 2519, 741, 741, 4333, 437, 291, 10945, 293, 382, 741, 1223, 51528], "temperature": 0.0, "avg_logprob": -0.05241899765454806, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.004174708854407072}, {"id": 1037, "seek": 583208, "start": 5855.36, "end": 5861.76, "text": " this is not fully your suggestion but the suggestion of let's say having a more open review kind of", "tokens": [51528, 341, 307, 406, 4498, 428, 16541, 457, 264, 16541, 295, 718, 311, 584, 1419, 257, 544, 1269, 3131, 733, 295, 51848], "temperature": 0.0, "avg_logprob": -0.05241899765454806, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.004174708854407072}, {"id": 1038, "seek": 586176, "start": 5861.76, "end": 5867.68, "text": " system where a review could be as powerful as a paper itself i've been screaming for this for", "tokens": [50364, 1185, 689, 257, 3131, 727, 312, 382, 4005, 382, 257, 3035, 2564, 741, 600, 668, 12636, 337, 341, 337, 50660], "temperature": 0.0, "avg_logprob": -0.04582743114895291, "compression_ratio": 1.7671232876712328, "no_speech_prob": 0.0026218495331704617}, {"id": 1039, "seek": 586176, "start": 5867.68, "end": 5874.96, "text": " a few years now and could i ask if you if you ever have the chance to propagate this what do you", "tokens": [50660, 257, 1326, 924, 586, 293, 727, 741, 1029, 498, 291, 498, 291, 1562, 362, 264, 2931, 281, 48256, 341, 437, 360, 291, 51024], "temperature": 0.0, "avg_logprob": -0.04582743114895291, "compression_ratio": 1.7671232876712328, "no_speech_prob": 0.0026218495331704617}, {"id": 1040, "seek": 586176, "start": 5874.96, "end": 5880.8, "text": " think of the idea of having a continuous research like this paper notion that we have now i think", "tokens": [51024, 519, 295, 264, 1558, 295, 1419, 257, 10957, 2132, 411, 341, 3035, 10710, 300, 321, 362, 586, 741, 519, 51316], "temperature": 0.0, "avg_logprob": -0.04582743114895291, "compression_ratio": 1.7671232876712328, "no_speech_prob": 0.0026218495331704617}, {"id": 1041, "seek": 586176, "start": 5880.8, "end": 5886.88, "text": " it's so outdated and once my paper is published i have no incentive to update that thing what what", "tokens": [51316, 309, 311, 370, 36313, 293, 1564, 452, 3035, 307, 6572, 741, 362, 572, 22346, 281, 5623, 300, 551, 437, 437, 51620], "temperature": 0.0, "avg_logprob": -0.04582743114895291, "compression_ratio": 1.7671232876712328, "no_speech_prob": 0.0026218495331704617}, {"id": 1042, "seek": 588688, "start": 5886.88, "end": 5892.64, "text": " if we do research in in this much more continuous way and then there's comments and then in response", "tokens": [50364, 498, 321, 360, 2132, 294, 294, 341, 709, 544, 10957, 636, 293, 550, 456, 311, 3053, 293, 550, 294, 4134, 50652], "temperature": 0.0, "avg_logprob": -0.04920120324407305, "compression_ratio": 1.945945945945946, "no_speech_prob": 0.0031667021103203297}, {"id": 1043, "seek": 588688, "start": 5892.64, "end": 5899.04, "text": " to the comments everything changes and so on yeah no it's very good point it's it's so this is indeed", "tokens": [50652, 281, 264, 3053, 1203, 2962, 293, 370, 322, 1338, 572, 309, 311, 588, 665, 935, 309, 311, 309, 311, 370, 341, 307, 6451, 50972], "temperature": 0.0, "avg_logprob": -0.04920120324407305, "compression_ratio": 1.945945945945946, "no_speech_prob": 0.0031667021103203297}, {"id": 1044, "seek": 588688, "start": 5899.04, "end": 5905.36, "text": " exactly part of this idea that we are trying open review to implement yeah but it's the idea is that", "tokens": [50972, 2293, 644, 295, 341, 1558, 300, 321, 366, 1382, 1269, 3131, 281, 4445, 1338, 457, 309, 311, 264, 1558, 307, 300, 51288], "temperature": 0.0, "avg_logprob": -0.04920120324407305, "compression_ratio": 1.945945945945946, "no_speech_prob": 0.0031667021103203297}, {"id": 1045, "seek": 588688, "start": 5905.36, "end": 5910.0, "text": " in open review you have a conversation with your reviewers and it's nice if the reviewers are not", "tokens": [51288, 294, 1269, 3131, 291, 362, 257, 3761, 365, 428, 45837, 293, 309, 311, 1481, 498, 264, 45837, 366, 406, 51520], "temperature": 0.0, "avg_logprob": -0.04920120324407305, "compression_ratio": 1.945945945945946, "no_speech_prob": 0.0031667021103203297}, {"id": 1046, "seek": 588688, "start": 5910.0, "end": 5914.56, "text": " anonymous and just you just have your conversation and other people can even contribute to the project", "tokens": [51520, 24932, 293, 445, 291, 445, 362, 428, 3761, 293, 661, 561, 393, 754, 10586, 281, 264, 1716, 51748], "temperature": 0.0, "avg_logprob": -0.04920120324407305, "compression_ratio": 1.945945945945946, "no_speech_prob": 0.0031667021103203297}, {"id": 1047, "seek": 591456, "start": 5914.56, "end": 5919.68, "text": " in a more open science way but it is also nice for now and then to present your work and so", "tokens": [50364, 294, 257, 544, 1269, 3497, 636, 457, 309, 307, 611, 1481, 337, 586, 293, 550, 281, 1974, 428, 589, 293, 370, 50620], "temperature": 0.0, "avg_logprob": -0.06599109513419014, "compression_ratio": 1.8295454545454546, "no_speech_prob": 0.0076841446571052074}, {"id": 1048, "seek": 591456, "start": 5919.68, "end": 5926.240000000001, "text": " that's why i say so now and then a conference might come in and harvest papers and just invite", "tokens": [50620, 300, 311, 983, 741, 584, 370, 586, 293, 550, 257, 7586, 1062, 808, 294, 293, 11917, 10577, 293, 445, 7980, 50948], "temperature": 0.0, "avg_logprob": -0.06599109513419014, "compression_ratio": 1.8295454545454546, "no_speech_prob": 0.0076841446571052074}, {"id": 1049, "seek": 591456, "start": 5926.240000000001, "end": 5930.96, "text": " people to present their work in sort of slightly more formal way and maybe put a stamp of approval", "tokens": [50948, 561, 281, 1974, 641, 589, 294, 1333, 295, 4748, 544, 9860, 636, 293, 1310, 829, 257, 9921, 295, 13317, 51184], "temperature": 0.0, "avg_logprob": -0.06599109513419014, "compression_ratio": 1.8295454545454546, "no_speech_prob": 0.0076841446571052074}, {"id": 1050, "seek": 591456, "start": 5930.96, "end": 5936.320000000001, "text": " on it and say this conference has published or this particular paper with some independent reviews", "tokens": [51184, 322, 309, 293, 584, 341, 7586, 575, 6572, 420, 341, 1729, 3035, 365, 512, 6695, 10229, 51452], "temperature": 0.0, "avg_logprob": -0.06599109513419014, "compression_ratio": 1.8295454545454546, "no_speech_prob": 0.0076841446571052074}, {"id": 1051, "seek": 591456, "start": 5936.320000000001, "end": 5941.360000000001, "text": " and we think it's a great paper and so you get that stamp so it and i guess there should also be a", "tokens": [51452, 293, 321, 519, 309, 311, 257, 869, 3035, 293, 370, 291, 483, 300, 9921, 370, 309, 293, 741, 2041, 456, 820, 611, 312, 257, 51704], "temperature": 0.0, "avg_logprob": -0.06599109513419014, "compression_ratio": 1.8295454545454546, "no_speech_prob": 0.0076841446571052074}, {"id": 1052, "seek": 594136, "start": 5941.36, "end": 5947.599999999999, "text": " way to close off a particular project to move on to a new project but i also have the same view as you", "tokens": [50364, 636, 281, 1998, 766, 257, 1729, 1716, 281, 1286, 322, 281, 257, 777, 1716, 457, 741, 611, 362, 264, 912, 1910, 382, 291, 50676], "temperature": 0.0, "avg_logprob": -0.08687892582105554, "compression_ratio": 1.8619402985074627, "no_speech_prob": 0.14587520062923431}, {"id": 1053, "seek": 594136, "start": 5947.599999999999, "end": 5954.719999999999, "text": " have as this being a far more continuous process where you know if you didn't get picked this time", "tokens": [50676, 362, 382, 341, 885, 257, 1400, 544, 10957, 1399, 689, 291, 458, 498, 291, 994, 380, 483, 6183, 341, 565, 51032], "temperature": 0.0, "avg_logprob": -0.08687892582105554, "compression_ratio": 1.8619402985074627, "no_speech_prob": 0.14587520062923431}, {"id": 1054, "seek": 594136, "start": 5954.719999999999, "end": 5959.679999999999, "text": " next time somebody some conference will come by and pick you out this it's much more like a marketplace", "tokens": [51032, 958, 565, 2618, 512, 7586, 486, 808, 538, 293, 1888, 291, 484, 341, 309, 311, 709, 544, 411, 257, 19455, 51280], "temperature": 0.0, "avg_logprob": -0.08687892582105554, "compression_ratio": 1.8619402985074627, "no_speech_prob": 0.14587520062923431}, {"id": 1055, "seek": 594136, "start": 5959.679999999999, "end": 5965.28, "text": " where ideas go around conferences come in and ask you to publish things and it's just you then", "tokens": [51280, 689, 3487, 352, 926, 22032, 808, 294, 293, 1029, 291, 281, 11374, 721, 293, 309, 311, 445, 291, 550, 51560], "temperature": 0.0, "avg_logprob": -0.08687892582105554, "compression_ratio": 1.8619402985074627, "no_speech_prob": 0.14587520062923431}, {"id": 1056, "seek": 594136, "start": 5965.28, "end": 5969.92, "text": " present it and then you can just continue with your research or stop and then go to a new piece of", "tokens": [51560, 1974, 309, 293, 550, 291, 393, 445, 2354, 365, 428, 2132, 420, 1590, 293, 550, 352, 281, 257, 777, 2522, 295, 51792], "temperature": 0.0, "avg_logprob": -0.08687892582105554, "compression_ratio": 1.8619402985074627, "no_speech_prob": 0.14587520062923431}, {"id": 1057, "seek": 596992, "start": 5969.92, "end": 5975.28, "text": " work or something like this so yeah i i share that vision basically that's it's amazing i'm", "tokens": [50364, 589, 420, 746, 411, 341, 370, 1338, 741, 741, 2073, 300, 5201, 1936, 300, 311, 309, 311, 2243, 741, 478, 50632], "temperature": 0.0, "avg_logprob": -0.06958108789780561, "compression_ratio": 1.8037037037037038, "no_speech_prob": 0.00445469468832016}, {"id": 1058, "seek": 596992, "start": 5975.28, "end": 5981.52, "text": " continuously amazed when i read these old papers from let's say schmid uber and like the first rl", "tokens": [50632, 15684, 20507, 562, 741, 1401, 613, 1331, 10577, 490, 718, 311, 584, 956, 25394, 344, 607, 293, 411, 264, 700, 367, 75, 50944], "temperature": 0.0, "avg_logprob": -0.06958108789780561, "compression_ratio": 1.8037037037037038, "no_speech_prob": 0.00445469468832016}, {"id": 1059, "seek": 596992, "start": 5981.52, "end": 5986.64, "text": " papers that just came up with a bit of an idea and then they had a bit of toy data and right and", "tokens": [50944, 10577, 300, 445, 1361, 493, 365, 257, 857, 295, 364, 1558, 293, 550, 436, 632, 257, 857, 295, 12058, 1412, 293, 558, 293, 51200], "temperature": 0.0, "avg_logprob": -0.06958108789780561, "compression_ratio": 1.8037037037037038, "no_speech_prob": 0.00445469468832016}, {"id": 1060, "seek": 596992, "start": 5986.64, "end": 5993.52, "text": " that's a paper and and it's cool do you have any do you have any kind of thoughts about or recommendations", "tokens": [51200, 300, 311, 257, 3035, 293, 293, 309, 311, 1627, 360, 291, 362, 604, 360, 291, 362, 604, 733, 295, 4598, 466, 420, 10434, 51544], "temperature": 0.0, "avg_logprob": -0.06958108789780561, "compression_ratio": 1.8037037037037038, "no_speech_prob": 0.00445469468832016}, {"id": 1061, "seek": 596992, "start": 5993.52, "end": 5998.88, "text": " for the new generation of researchers that are now flooding the fields of how can we get to a", "tokens": [51544, 337, 264, 777, 5125, 295, 10309, 300, 366, 586, 24132, 264, 7909, 295, 577, 393, 321, 483, 281, 257, 51812], "temperature": 0.0, "avg_logprob": -0.06958108789780561, "compression_ratio": 1.8037037037037038, "no_speech_prob": 0.00445469468832016}, {"id": 1062, "seek": 599888, "start": 5998.88, "end": 6005.36, "text": " better field what kind of tips would you give the yeah we i think we really need to disrupt the field", "tokens": [50364, 1101, 2519, 437, 733, 295, 6082, 576, 291, 976, 264, 1338, 321, 741, 519, 321, 534, 643, 281, 14124, 264, 2519, 50688], "temperature": 0.0, "avg_logprob": -0.04754638130014593, "compression_ratio": 1.703056768558952, "no_speech_prob": 0.0036424491554498672}, {"id": 1063, "seek": 599888, "start": 6005.36, "end": 6010.72, "text": " a little bit and so i think we i think the new i think it's particularly tough for new researchers", "tokens": [50688, 257, 707, 857, 293, 370, 741, 519, 321, 741, 519, 264, 777, 741, 519, 309, 311, 4098, 4930, 337, 777, 10309, 50956], "temperature": 0.0, "avg_logprob": -0.04754638130014593, "compression_ratio": 1.703056768558952, "no_speech_prob": 0.0036424491554498672}, {"id": 1064, "seek": 599888, "start": 6011.36, "end": 6017.2, "text": " because it's the acceptance rates for these conferences are very low and it feels like much", "tokens": [50988, 570, 309, 311, 264, 20351, 6846, 337, 613, 22032, 366, 588, 2295, 293, 309, 3417, 411, 709, 51280], "temperature": 0.0, "avg_logprob": -0.04754638130014593, "compression_ratio": 1.703056768558952, "no_speech_prob": 0.0036424491554498672}, {"id": 1065, "seek": 599888, "start": 6017.2, "end": 6022.64, "text": " of your future career depends on getting papers in there and it's a fairly random process as well", "tokens": [51280, 295, 428, 2027, 3988, 5946, 322, 1242, 10577, 294, 456, 293, 309, 311, 257, 6457, 4974, 1399, 382, 731, 51552], "temperature": 0.0, "avg_logprob": -0.04754638130014593, "compression_ratio": 1.703056768558952, "no_speech_prob": 0.0036424491554498672}, {"id": 1066, "seek": 602264, "start": 6023.52, "end": 6026.96, "text": " so i think we just need to disrupt the field and there's enough people", "tokens": [50408, 370, 741, 519, 321, 445, 643, 281, 14124, 264, 2519, 293, 456, 311, 1547, 561, 50580], "temperature": 0.0, "avg_logprob": -0.12771916121579288, "compression_ratio": 1.6380090497737556, "no_speech_prob": 0.030643610283732414}, {"id": 1067, "seek": 602264, "start": 6028.400000000001, "end": 6033.84, "text": " with influence who want that so it's just a matter of actually executing on it and so that's", "tokens": [50652, 365, 6503, 567, 528, 300, 370, 309, 311, 445, 257, 1871, 295, 767, 32368, 322, 309, 293, 370, 300, 311, 50924], "temperature": 0.0, "avg_logprob": -0.12771916121579288, "compression_ratio": 1.6380090497737556, "no_speech_prob": 0.030643610283732414}, {"id": 1068, "seek": 602264, "start": 6033.84, "end": 6039.92, "text": " what we do it now for the bayesian deep learning workshop that we are organizing this we want this", "tokens": [50924, 437, 321, 360, 309, 586, 337, 264, 13642, 42434, 2452, 2539, 13541, 300, 321, 366, 17608, 341, 321, 528, 341, 51228], "temperature": 0.0, "avg_logprob": -0.12771916121579288, "compression_ratio": 1.6380090497737556, "no_speech_prob": 0.030643610283732414}, {"id": 1069, "seek": 602264, "start": 6039.92, "end": 6048.160000000001, "text": " to be a an off-split from new rips it was a very popular workshop there and somehow we got rejected", "tokens": [51228, 281, 312, 257, 364, 766, 12, 46535, 270, 490, 777, 367, 2600, 309, 390, 257, 588, 3743, 13541, 456, 293, 6063, 321, 658, 15749, 51640], "temperature": 0.0, "avg_logprob": -0.12771916121579288, "compression_ratio": 1.6380090497737556, "no_speech_prob": 0.030643610283732414}, {"id": 1070, "seek": 604816, "start": 6048.16, "end": 6053.5199999999995, "text": " this year and we thought okay we'll just do it ourselves we do have actually a meet-up but then", "tokens": [50364, 341, 1064, 293, 321, 1194, 1392, 321, 603, 445, 360, 309, 4175, 321, 360, 362, 767, 257, 1677, 12, 1010, 457, 550, 50632], "temperature": 0.0, "avg_logprob": -0.09016636322284567, "compression_ratio": 1.873076923076923, "no_speech_prob": 0.10492201149463654}, {"id": 1071, "seek": 604816, "start": 6053.5199999999995, "end": 6058.48, "text": " next year we want to be our standalone conference but for that conference we want to implement this", "tokens": [50632, 958, 1064, 321, 528, 281, 312, 527, 37454, 7586, 457, 337, 300, 7586, 321, 528, 281, 4445, 341, 50880], "temperature": 0.0, "avg_logprob": -0.09016636322284567, "compression_ratio": 1.873076923076923, "no_speech_prob": 0.10492201149463654}, {"id": 1072, "seek": 604816, "start": 6058.48, "end": 6063.599999999999, "text": " plan and so we are working with open review to actually implement this for us and jaren gall is", "tokens": [50880, 1393, 293, 370, 321, 366, 1364, 365, 1269, 3131, 281, 767, 4445, 341, 337, 505, 293, 361, 4484, 8527, 307, 51136], "temperature": 0.0, "avg_logprob": -0.09016636322284567, "compression_ratio": 1.873076923076923, "no_speech_prob": 0.10492201149463654}, {"id": 1073, "seek": 604816, "start": 6063.599999999999, "end": 6069.5199999999995, "text": " working hard to try to actually roll this out we're talking to yashua benjo about it and he's", "tokens": [51136, 1364, 1152, 281, 853, 281, 767, 3373, 341, 484, 321, 434, 1417, 281, 288, 1299, 4398, 3271, 5134, 466, 309, 293, 415, 311, 51432], "temperature": 0.0, "avg_logprob": -0.09016636322284567, "compression_ratio": 1.873076923076923, "no_speech_prob": 0.10492201149463654}, {"id": 1074, "seek": 604816, "start": 6069.5199999999995, "end": 6073.76, "text": " very supportive and there's a whole lot of people who are supportive about it but so if this can help", "tokens": [51432, 588, 14435, 293, 456, 311, 257, 1379, 688, 295, 561, 567, 366, 14435, 466, 309, 457, 370, 498, 341, 393, 854, 51644], "temperature": 0.0, "avg_logprob": -0.09016636322284567, "compression_ratio": 1.873076923076923, "no_speech_prob": 0.10492201149463654}, {"id": 1075, "seek": 607376, "start": 6074.72, "end": 6079.280000000001, "text": " to make this a popular model then that will be a fantastic result of this interview", "tokens": [50412, 281, 652, 341, 257, 3743, 2316, 550, 300, 486, 312, 257, 5456, 1874, 295, 341, 4049, 50640], "temperature": 0.0, "avg_logprob": -0.0451124906539917, "compression_ratio": 1.7635658914728682, "no_speech_prob": 0.054768774658441544}, {"id": 1076, "seek": 607376, "start": 6079.280000000001, "end": 6083.12, "text": " but i think people should just push for it and just say okay i'm just fed up with the", "tokens": [50640, 457, 741, 519, 561, 820, 445, 2944, 337, 309, 293, 445, 584, 1392, 741, 478, 445, 4636, 493, 365, 264, 50832], "temperature": 0.0, "avg_logprob": -0.0451124906539917, "compression_ratio": 1.7635658914728682, "no_speech_prob": 0.054768774658441544}, {"id": 1077, "seek": 607376, "start": 6083.12, "end": 6088.16, "text": " current way of doing things we should really change things and just a shout out and say", "tokens": [50832, 2190, 636, 295, 884, 721, 321, 820, 534, 1319, 721, 293, 445, 257, 8043, 484, 293, 584, 51084], "temperature": 0.0, "avg_logprob": -0.0451124906539917, "compression_ratio": 1.7635658914728682, "no_speech_prob": 0.054768774658441544}, {"id": 1078, "seek": 607376, "start": 6088.16, "end": 6095.280000000001, "text": " this is what we want and let's go for it awesome amazing professor max welling it's been an absolute", "tokens": [51084, 341, 307, 437, 321, 528, 293, 718, 311, 352, 337, 309, 3476, 2243, 8304, 11469, 731, 278, 309, 311, 668, 364, 8236, 51440], "temperature": 0.0, "avg_logprob": -0.0451124906539917, "compression_ratio": 1.7635658914728682, "no_speech_prob": 0.054768774658441544}, {"id": 1079, "seek": 607376, "start": 6095.280000000001, "end": 6100.24, "text": " honor and a pleasure to have you on the show thank you so much for joining us today it was great", "tokens": [51440, 5968, 293, 257, 6834, 281, 362, 291, 322, 264, 855, 1309, 291, 370, 709, 337, 5549, 505, 965, 309, 390, 869, 51688], "temperature": 0.0, "avg_logprob": -0.0451124906539917, "compression_ratio": 1.7635658914728682, "no_speech_prob": 0.054768774658441544}, {"id": 1080, "seek": 610024, "start": 6100.24, "end": 6104.4, "text": " with the three of you asking questions that works really well fantastic thank you so much", "tokens": [50364, 365, 264, 1045, 295, 291, 3365, 1651, 300, 1985, 534, 731, 5456, 1309, 291, 370, 709, 50572], "temperature": 0.0, "avg_logprob": -0.05877229954936717, "compression_ratio": 1.9872340425531916, "no_speech_prob": 0.04387474060058594}, {"id": 1081, "seek": 610024, "start": 6104.4, "end": 6110.16, "text": " thank you amazing it was good the questions were really fantastic actually and i've never", "tokens": [50572, 1309, 291, 2243, 309, 390, 665, 264, 1651, 645, 534, 5456, 767, 293, 741, 600, 1128, 50860], "temperature": 0.0, "avg_logprob": -0.05877229954936717, "compression_ratio": 1.9872340425531916, "no_speech_prob": 0.04387474060058594}, {"id": 1082, "seek": 610024, "start": 6110.16, "end": 6114.4, "text": " done this with the three of you but having a team of three people asking questions is really", "tokens": [50860, 1096, 341, 365, 264, 1045, 295, 291, 457, 1419, 257, 1469, 295, 1045, 561, 3365, 1651, 307, 534, 51072], "temperature": 0.0, "avg_logprob": -0.05877229954936717, "compression_ratio": 1.9872340425531916, "no_speech_prob": 0.04387474060058594}, {"id": 1083, "seek": 610024, "start": 6114.4, "end": 6118.639999999999, "text": " it's a good idea and of course you're really smart people knowing what you're talking about so that", "tokens": [51072, 309, 311, 257, 665, 1558, 293, 295, 1164, 291, 434, 534, 4069, 561, 5276, 437, 291, 434, 1417, 466, 370, 300, 51284], "temperature": 0.0, "avg_logprob": -0.05877229954936717, "compression_ratio": 1.9872340425531916, "no_speech_prob": 0.04387474060058594}, {"id": 1084, "seek": 610024, "start": 6118.639999999999, "end": 6126.5599999999995, "text": " went really well i think needs three brains to match yours anyway i really hope you've enjoyed", "tokens": [51284, 1437, 534, 731, 741, 519, 2203, 1045, 15442, 281, 2995, 6342, 4033, 741, 534, 1454, 291, 600, 4626, 51680], "temperature": 0.0, "avg_logprob": -0.05877229954936717, "compression_ratio": 1.9872340425531916, "no_speech_prob": 0.04387474060058594}, {"id": 1085, "seek": 612656, "start": 6126.56, "end": 6132.080000000001, "text": " the show today this has been such a special episode for us because max welling is is literally one", "tokens": [50364, 264, 855, 965, 341, 575, 668, 1270, 257, 2121, 3500, 337, 505, 570, 11469, 731, 278, 307, 307, 3736, 472, 50640], "temperature": 0.0, "avg_logprob": -0.05554231268460633, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.08746404945850372}, {"id": 1086, "seek": 612656, "start": 6132.080000000001, "end": 6138.56, "text": " one of my heroes so anyway remember to like comment and subscribe we love reading your", "tokens": [50640, 472, 295, 452, 12332, 370, 4033, 1604, 281, 411, 2871, 293, 3022, 321, 959, 3760, 428, 50964], "temperature": 0.0, "avg_logprob": -0.05554231268460633, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.08746404945850372}, {"id": 1087, "seek": 612656, "start": 6138.56, "end": 6143.6, "text": " comments we really do actually we're getting so many amazing comments in the comment section so", "tokens": [50964, 3053, 321, 534, 360, 767, 321, 434, 1242, 370, 867, 2243, 3053, 294, 264, 2871, 3541, 370, 51216], "temperature": 0.0, "avg_logprob": -0.05554231268460633, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.08746404945850372}, {"id": 1088, "seek": 614360, "start": 6143.6, "end": 6151.4400000000005, "text": " keep them coming and we will see you back next week", "tokens": [50364, 1066, 552, 1348, 293, 321, 486, 536, 291, 646, 958, 1243, 50756], "temperature": 0.0, "avg_logprob": -0.25105927671704975, "compression_ratio": 0.9107142857142857, "no_speech_prob": 0.07747127115726471}], "language": "en"}