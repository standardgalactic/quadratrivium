start	end	text
0	17840	Mae ein dweud, Prof. M glyran, oedd ysgol yn fy wir
17840	29800	y cof AM dewis.
29800	32680	..allwch chi'n ddweud mewn ar 모�f whackingr.
32680	47560	Cyfanyd dros y tlaen ymar 700 o.r.l ar y ddangos oak Wfyn
47560	53320	Rhaid da siar aheadwch Allwn ni i wneud anghofcond oherwydd dwyr am have eamen dda chi'n
53320	54120	ddluciaethu rheidiol.
54120	58600	On n ess bynnwyr y cy terriblyfyrdd isw pof wych yn iddiw i'w ffyn i'w wneud.
58600	60800	Codd,Hayde, sy'n meddwl yn mynd i sicrhau y r communist.
60800	64640	Mae'r pysigod ychydigbaradau ar y prydysig iechyd drumol rollun?
64640	66880	Yn Clo.
66880	69080	Ac mae'n rhaid mewn yw'r blwyddyn yn dolpa.
69080	71600	Yn yr ardwaith a pob el擊wrom.
71600	73160	Fel jei hy myślęНАЯ여
73160	74120	neu saddleghio.
74120	77000	Fe hyd yn cael yn cael yn ystyried.
77480	79600	Dyma'r wrth another Richard however.
79600	81840	Cyn ystyried eich ddimentisigon
82840	86800	yr pawr deisasfer o'r ddyfod poetol
86800	88100	i weld eich gobl nebneg
88100	93840	o'r nesafелаidd arall, bwynt
94260	97920	ein thaw wnaeth sy
97920	98360	i eu tanfod ei lynƏn iw meddwl?
98380	99940	Yn arglwr hwn.
100040	101560	So ei hwn,dsaintar,
101560	105660	awdurd ön weithen o gan disgwyl
105660	106440	ac rhun sig yn gwneud
106480	108580	a fydd creddo yn cael ei wneud
108740	110460	a dyna ni'r gweithiool
110800	113200	yn eu gwneud mwyn o dyng Nghaerurgical
113740	116540	felly hwn yna'r 21 y sector
116540	117940	sydd o argymell
117940	122380	ac nifon â mount Goraen iawn,vision sy'n heb gyran â y proses Cysydd yr olan.
122540	128940	Felly, gyda hynny fel dros amll וה연 hwn olanan i ddefnyddio effaith.
128940	133640	Rydw i ty bedroom, tu'ch
133640	137720	y gwneud i amddangos â'r twfynu.
137720	142960	A ti'n mynedwch i gyd yn agorio your ehydol sy'n gyffredinol
142960	144520	a gweithio sicrhau.
144520	158520	I was pleased and honoured to write one of the, one of the blurbs for this and actually use the phrase, this is a book that grabs you and literally changes your mind, it's a nice quiz.
158520	164520	And I've just noticed, yeah, little story about Andy.
164520	188520	And if I remember correctly, Andy started at Sussex University with a good and great like Margaret Bowden, then after an itinerant and glorious career involving America ended up in Edinburgh, which he loved, but he couldn't surf in Edinburgh, so he's always wanted to get back to Brighton, back to Sussex.
188520	210520	And a few years ago, Anil Seth, who's himself at Sussex, who I noticed here has also written some lovely blurb, I'll just read that, a predictably groundbreaking exploration of the predictive basis of our extended minds from one of our deepest and clearest thinkers.
210520	231520	The experience machine delivers a remarkable combination of profound insight and practical relevance. So Anil was very pleased with himself, and I remember joyfully declaring when he'd actually secured Andy Clark or headhunted him from Edinburgh back to Sussex.
231520	258520	So they could, when I say they, Andy and Alexa could go surfing again. And I remember the point at which he got confirmation of Andy's headhunting. We were actually trapped during a, what they call, a hurricane in the Mediterranean on a little Greek island drilling down, I think it was on the mathematical basis of consciousness.
258520	279520	And we're in communicado with the waves raging outside, and Anil Seth was playing the piano, and he got this phone call to confirm that he'd managed to secure Andy Clark's chair at Sussex several years ago. So from what I understand, Andy is now happily, is he a cognitive philosopher?
279520	289520	Yes, I'm incredibly jealous of his job title, a cognitive philosopher. That would be my aspiration one day to be a cognitive philosopher.
289520	308520	Yes, surfing and philosophy. So he emailed me about this, must have been before Christmas, saying he'd written a pot boiler. And would I like to just look, pass my, read through it briefly. I had to Google what a pot boiler meant.
309520	325520	Apparently, it's a brief and cheerful book to make money. So I've beautifully written, but then I had to reread it to write the blurb, and it's certainly more than a pot boiler.
325520	353520	It's actually an interesting synthesis of, I think, where that style, certainly Andy's style of thinking about life and making sense of the lived world and physically engaging with that world, where he was prior to predictive processing an active inference before the sort of the pragmatic turn or the inactivist shift.
353520	382520	He has been moved from the 21st century. So before that, he was famous for things like the extended mind, the designer environment that we, in the spirit of niche construction, we actually create our own niche, we create our own environment in a way that makes it much more predictable and affords the opportunity now to sort of download a lot of our cognitive capacities into the world.
383520	397520	Memories are now in our iPhones. And then he's basically taken those foundational and fundamental ideas and contextualize them in the context of the modern predictive processing and active inference.
398520	402520	And this is the synthesis. A lovely read.
402520	420520	I wanted to pick up on something you just said, though, because when I was reading the book, I was rather struck by this idea that we live in a hallucination, which is conditioned by actual sensory information, but let's say 90% hallucination and 10% sensory information.
420520	431520	And from an inactivism point of view, what's really interesting about that school of thought is that we create the world that we live in, as well as the world creating our own kind of sensorium.
432520	437520	And that's just something that really struck me as being quite interesting. What's your take on this living hallucination?
438520	450520	Well, you say 90% hallucination and 10%. I probably think it's 100%. That's absolutely right.
451520	472520	So, if you believe that everything that we perceive as being real is a hypothesis, the product of a constructive organ, a statistical organ, a little scientist that just is our brain, then all you're saying is that the sensory data are just in the service of confirming that hypothesis,
472520	480520	or this alternative hypothesis, or another hypothesis. The key observation being it's all hypotheses. It's all fantasy.
481520	495520	So, using the fantasy word is nice because it means that the brain is literally a fantastic organ. It's a purveyor of a device for basically adjudicating, choosing the right hypothesis as a best fit to this sensory data.
496520	512520	But of course, as you point out, it's not just the fact that we assess our brains, creatures, phenotypes that are delivered of data. Andy Clark would express this in terms of this outside in process.
513520	530520	We actually have to actively select those data by moving, by palpating with our fingers, by moving our eyes around. We are in charge of the data that we now solicit to verify or disconfirm our hallucinations or our hypotheses.
530520	543520	So, that's the inactive part. That's a sort of actively engaged in a way that induces this kind of circular causality. So, we are certainly constrained by our sensory data.
544520	561520	Our predictions and hypotheses are informed and contextualized by sensory data, but at the same time, the ensuing hypotheses underwrite the way that we sample the next bit of data.
562520	568520	So, there's this wonderful sort of autodidactic, you know, physical engagement with the lived world.
568520	583520	Yes, yes. But I would love to understand where the autonomy comes from. And the reason I'm asking this question is there have been many papers on chat GPT recently that have essentially built an outer loop to find different prompts.
584520	591520	So, if you think of GPT as an information retrieval system, there's an outer loop to explore prompts in the neighborhood of the original prompts.
592520	598520	And this is very similar to what you're saying from the inactive point of view now. There are books about how we think with our bodies.
599520	610520	And you just said that there's an outer loop that says, well, I now need to explore with my physical body in my physical environment to get more information to do inference.
611520	613520	And what process is doing that outer loop?
614520	615520	What process?
616520	642520	So, I guess the body is in and of itself just a hypothesis and therefore the answer to your question, it can't be that the self is, if you like, driving this active engagement, this sort of active learning and active inference about the way the world works.
643520	652520	If it is the case that the self is actually emergent from or an explanation we bring to the table to explain all of these data.
653520	663520	So, there must be something underneath that. And as a true Bayesian statistician, my answer would be there are some prior belief.
663520	676520	And I don't mean belief in a sort of folk psychology sense, I just mean in terms of some probabilistic distributions and probabilistic specification of what it is to be something like me.
677520	687520	And then something like me goes around self evidencing, acquiring sensory data that supplies evidence for my model of this world.
687520	696520	And I suddenly have the hypothesis that this world actually includes me as an agent, as an artifact, and then I develop a sense of self.
697520	714520	So, I guess your question is where does the autonomy come from? As a mathematician, it comes from autonomous differential equations that underwrite the itinerancy and technically the attracting sex of the attractors that characterise me,
714520	719520	that specify the characteristic states that I will remain in.
720520	731520	So, technically speaking, I can, if you like, elu the question about where does autonomy come from, where it comes from autonomous differential equations that characterise an attracting set of characteristic states that make me.
731520	750520	And you could actually simulate that, you can simulate all sorts of things that have this sort of bimetic aspect, you know, walking, talking, writing, all of these basically being a physical realisation or instantiation of these autonomous dynamics that, you know, in a very straightforward way,
750520	763520	physically realised by neuronal dynamics. However, I suspect that your use of the word autonomy wasn't so technical or deflationary.
764520	776520	I think that to be autonomous, first of all, is to be a kind of thing, a particle or person that can act upon the world.
776520	800520	So, I think that, you know, there's a minimal requirement that you have various states that change the states on the outside of you that are external to you, that are extrinsic, that are hidden behind your sensations, your sensory veils that are latent in the sense that you'll never observe them directly.
800520	819520	So, to be autonomous is to be able to move, but there's clearly more to it in the sense that if you're trying to explain your inactive or active engagement with the world in terms of making sense of the world, you're basically describing active inference,
819520	838520	you're describing an evidence gathering machine, you're describing self-evidence as Jacob Howie would express it, another brother-in-arms and a friend of Andy Clarks, and another, I guess he'd probably be very pleased to call himself a cognitive philosopher.
839520	860520	Jacob sort of has not invented but certainly repurposed the notion of self-evidencing as a very succinct and neat way to describe this kind of predictive processing that has this active engagement in active flavour.
860520	880520	For me, that would be active inference, and what is it? Well, it's just basically gathering evidence from my models of the lived world. So, then you say, well, okay, what underwrites this evidence gathering, it's the generative model, it's the model that you are gathering evidence for and you're continually updating that model,
880520	905520	and I mean generative model exactly in the spirit of generative AI, that there is an implicit and possibly sometimes explicit model that you are gathering evidence for, and that model affords the opportunity to generate the kind of content that will be generated or observed under that model,
905520	923520	and hence you can look at generative AI in large language models exactly in that spirit. So, the question now reduces in terms of where does autonomy come from, it really comes from the generative model, where does that come from, what it comes from, probably from your mum and dad,
923520	942520	in two senses, not just your genetic and epigenetic specification, but also the sort of cultural niche construction, the way that you are brought up, so that you have, if you like, a specification of the characteristic states that make you a good son or a good daughter or a good conspecific,
942520	964520	and that now undergird the generative model and then you seek evidence for your model and you learn the particular specialisation, the parameters of your model, by being brought up properly and by being autododactic later on in your, the autonomous sense or sharing the autonomy that comes along with self-evidencing.
964520	970520	They have tried to get autonomy into as many different sentences as possible for you.
