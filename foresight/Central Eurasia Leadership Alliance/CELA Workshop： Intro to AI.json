{"text": " Thank you, Dina. And hello, everyone. Excited and very happy to be here. So today, we're going to spend about one and a half hours talking about generative AI and recent trends in artificial intelligence. Let me share my presentation. So I will skip my introduction because Dina did a great intro. But if you want to maybe get in touch with me, I will send the presentation afterwards. And it has my Twitter and Telegram account. So a bit of logistical logistics. So the session is being recorded. I will have a lot of links, useful links and materials and examples in the slides. And those are for you to access after the workshop. I hope it will be useful. And there will be a lot of links that I will not even have time to cover. So I hope that these materials will be useful. The lecture or the workshop itself will take about one hour. And then we will have about 30 minutes for Q&A. But it's Saturday, so I'm happy to maybe stay a little bit longer if there are more questions. And the plan for today is for us to talk a little bit about what is artificial intelligence? How is it changing recently? And how it does it impact the economics and different industries? Then we will talk about two very specific areas of application of artificial intelligence, which is personal. Sorry, I will unmute people for time being. We'll talk about how artificial intelligence can help you in your personal life, in your business, in your maybe arts, in different areas of life. And then how AI can help your business. And I will show a lot of practical tools. So the goal and the structure of today's workshop is to give a presentation, but most importantly is to show specific use cases, how this can be used in practice, because there's a lot of theoretical videos or podcasts or articles online. And I'm not here to re-shuffle and repeat what you can already find. I'm here to actually show some practical application and some use cases that I hope will be useful. And with that being said, we can start. So let's talk about why artificial intelligence is important and why everybody is talking about AI right now or at least for the last year since Georgia BT came out. In fact, artificial intelligence is quite old and quite old concept and technology. It has been around for at least as long as digital computing has been around. The first paper that mentioned the idea of building computation networks inspired by how biological systems work, specifically how human brain works was published in 1943. So it's been 80 years of development in artificial intelligence. And the most important, the first seminal paper that you probably heard about was published in 1950 by Alan Turing where he proposed this idea of thinking machines. And this is actually the paper where the concept of Turing test comes from. And over these 80 years, there's been a lot of ups and downs. There have been a lot of development, a lot of hopes, a lot of actually things that are now called AI winters, which were periods, prolonged periods for decades where people thought that there can be no progress made. And then it changed from this AI winter to period of a lot of hope and inspiration and new technological development. And right now we're witnessing one of those periods. And it seems like it's the biggest one since the invention of the concept of artificial intelligence. But actually, the whole idea of thinking machines or building something that is built by human but not, but has ability to think and complete tasks, it comes even from prehistoric times. For example, I found this quote, and you probably heard this concept of Golem, which is this machine made of clay that people can build and then it would help with different tasks. So I found one of mentions from some source from year 500. And I actually did a quick experiment. I asked chat GPT and Google Bart, which is one of the chatbots developed by Google, what do they think? Are they golems? And this is what I got. This is the response that I got from Google Bart. It says that in some sense, it is possible to view me as a golem. This is the response that Google artificial intelligence is giving. And it is actually giving a comparison between Bart and Golem and different areas. Can it learn? Can it grow? It actually outperforms this concept of mystical, magical creature of a Golem. And I have links to both chat GPT and Bart here if you want to ask them the same question or maybe continue that conversation. But today, artificial intelligence is a very practical thing. And it is being used across all different areas of economy. And the first important thing to understand about AI is that AI is GPT. GPT stands for general purpose technology, which means that artificial intelligence is one of those technologies similar to maybe steam engine or electricity, or internet, which powers all different areas of economics and all different areas of society. And there are a lot of applications in healthcare, in education, in business, in manufacturing, in any industry, you name it, arts, culture, and so on. And because artificial intelligence has been around, there are a lot of different branches and flavors of AI. And what most people are talking about today, which is GPT, chatbots, large language models, is relatively new. This area has been created maybe four or five years ago. It started in 2017 with the paper called, Attention is All You Need, but real products are actually being developed just for the past three or four years. And generative AI is relatively small. So for example, the other areas of artificial intelligence, something like supervised learning or reinforcement learning is used in very practical applications as well. For example, in digital advertising, Google and Facebook and Twitter, all their advertisement recommendation system works using AI or self-driving cars or maybe trading systems. So today, we're not going to talk about all of different applications of the AI because it takes a whole university course to study that. We're going to focus on actually generative AI, at least most recent and the fastest growing areas and branch of artificial intelligence. And generative AI is all these different products and technologies that you hear when you hear about chatbots, large language models. One of the most popular examples is chat GPT. There's also a lot of different chatbots, one by Facebook called Lama, one by Google, called Bart, one by Entropic, and then there's a few hundreds of products like this. In addition to large language models, there are also diffusion models, which are tools that allow us to, so large language models, how they work, they are creating text. You ask them question or you give them prompt and they generate text. So they're really the principle of how they work is very simple. They just generate a next word in the sentence. And because they're so complex and so smart and they use so much data when they've been trained, when they have been trained, in order to generate the next word in the sentence, they had to learn the whole world model. So if you ask chat GPT who is like, I don't know, 46 president of the United States of America, it will give you the correct answer. But to give that answer, in order to give that answer, it had to learn a lot of things. What is US? What is the president? What is politics? What is election cycle? And it knows all these concepts and those concepts are stored inside the model. And this is why it seems to be so smart and this is actually, and this is why it is actually useful in a lot of business and personal tasks. Diffusion models are models that are able to generate pictures and video. And one of the most popular examples of such products is mid-journey and also Dali tool or stable diffusion. Also a lot of products, all applications in app store or internet that can create you AI photo or AI stylization, most of them, they use this concept of diffusion. They're based on diffusion neural networks and diffusion models. But also in addition to language models and diffusion models, there's a lot of smaller but no less important applications such as speech recognition, voice synthesis, music generation, creation of 3D art or 3D objects for video games, and many more, including very, very, very narrow and very specific ones like generation of proteins for pharma companies or designing chips for computer chip manufacturing companies. So how is, I want to talk about economics of AI. So I will be using a few cited and popular and well done research papers to show just some of the statistics. So this one is a report created by McKinsey, published about four months ago. And what they came up with in that report is that generative AI could deliver a total value of 4.4 trillion dollars in economics from new use cases. So these are only new use cases that are being unlocked by this new technology. But also in addition to that, there's also eight trillion dollars annually. So we are talking about annual GDP growth that can be gained through productivity increase by workers that they use AI or businesses that they use AI in their existing tasks. And on the right, there are, this graph shows impact in terms of billions of dollars in different areas of business. So you can, as you can see, sales, marketing, software engineering, customer operations, products are areas that will benefit the most from implementation and use and leverage of artificial intelligence, but also all these other areas like legal or HR or procurement or finance, there's also quite a few of very practical applications and I will cover some of those later. And from the same report and another interesting piece of statistics, what they came up with is that current generative AI technologies have potential to automate work activities that absorb 60 to 80 percent of employees' time today. It doesn't apply to all existing occupations and professions, but for highly qualified office workers, this can be a huge time saving. And this is, this stats is based just on existing level of technology. It doesn't take into account that in the future, the technology will evolve. And we are seeing that the growth, the speed of growth and speed of development of AI is staggering. It's huge. Another report, and I also have a link down here below, from University of Pennsylvania, it shows that 80 percent of U.S. workforce will have at least 10 percent of their daily tasks exposed or automated by large language models. And this does not only apply to the United States, this generally applies to any work that is characteristic to developed economy, which is service and office workers. So that means that most of the economy, most of the developed economy will have at least some, at least 10 percent of exposure to large language models and that will lead to automation and economic boost, boosting economic productivity. Another report by Gartner where they say that 30 percent of outbound tasks, marketing messages will be generated by large language models, will be genetically, synthetically generated. And this is their prediction for year 2045. So basically just one year from now. And this is, this is a huge increase if we're talking about marketing industry globally. So why do we see these huge numbers? And these reports, these are not some sci-fi movies. These are very trusted, established and, and, and, and, and reputable organizations that are giving these very bold predictions. The reason for that is that generative AI is both intuitive to use and it is broad. What I mean by that, generative AI is very simple to use because you generally just need to learn linguistic interface, which is common, which is nature for us. Like we humans, by the age of two or three or four years old, we are pretty comfortable with linguistic interface. We learn to talk to our parents or our friends. And this is all you need to really start using tools like ChargeGPT. You can, even if you don't know how to type, if you don't know how to write, you can still do it because if you download ChargeGPT on your iPhone, you can just talk to it. It will reply you. And that's pretty much instantly useful and helpful to most of global population. But also in addition to ease of use, it is very broadly applicable. It can augment pretty much every cognitive task. And I will go into details. I will show examples of some of the, some of those tasks. It can also power embodiment in robotics so it can help a lot of automation and help growth of robotic systems so it can help robots to navigate environments or complete complex tasks. And at the end of the day, the use case and the outcome of the growth of artificial intelligence is the global explosion of intelligence on the planet. So this is maybe a little bit exaggerated picture, but it shows the idea that I'm trying to be here. So this is, the green line is the amount of human intelligence on Earth and maybe from prehistoric times to our days, it's been growing gradually. But then with the advent and with mass introduction of artificial intelligence, the total amount of intelligence on the Earth is exploding rapidly. It doesn't mean that these AI tools will replace humans or they will do exactly the same thing as humans do. I think the better way to think about it is as an augmentation or insistence to what we do. But because we have ability to leverage this vast amount of intelligence, we humans can achieve much, much more. We are spending less time and less energy. And that's great. So I, because we are relatively short on time, I will not go into details of inner workings of large language models and generative AI. I won't go, I will not go into technical details, but I recommend this video. This is a video by Andrew Carpati, who is research lead at OpenAI in the company that created ChatGPT. And this video is not very technical. I recommend you to, if you have one hour, maybe in the evening or at some point, to watch this video. The link is in the slide. And this video goes into exactly how the system work without too much technical detail, but it gives better idea. And it comes from one of the person responsible for actually development of this technology, who is much more knowledgeable and reputable in the space than I am, for example. And he's also a great speaker. So really, really enjoyable video. So yeah, we will not watch it right now, but let's go into specific AI use cases. So we'll start with application of artificial intelligence for personal life. There's a lot of very, I would say common and basic and maybe even boring stuff that you can do with tools like ChatGPT. You can ask it to help craft a letter. You can ask it to check spelling. You can learn new languages with it. You can translate the text. You can check your code. If you're a software engineer for bugs, you can ask it to write new code. You can even learn new programming languages with it. You can do any kind of text and language related tasks with tools like ChatGPT. But I thought that for today presentation, that would be boring if I would just show like, okay, now you can translate a letter into Chinese. Great, but this is not very exciting. Translation was possible before. So today, we're not going to talk about this basic and simple stuff. Today, we're going to talk about something maybe one level deeper or layer higher. Depends on how you want to put it. And I want to start with this notion of learning partner. So for me, for my personal use case, in my personal life, what I use large language models daily for is to learn new information and to digest and to understand new complex stuff. So I want to, you can use ChatGPT or other tools, and I will show different tools just to, again, to prove my point about the breasts and number of different tools that exist. You can use GPT or similar LLMs as a learning partner. You can ask it to explain complex information to you. You can ask it to be your tutor. You can even ask it to create tests for you to learn and remember and verify yourself. You can ask GPT to engage in Socratic dialogue with you. You can ask it to transcribe video or podcast. GPT directly cannot do it, but there are free services that allow to transcribe and then answer questions based on existing videos or existing podcasts. So for this first example, I want to show another chatbot, which is not ChatGPT. Maybe it's a little bit less known, but it is called Clot AI. It is free to use. So you can go to clot.ai, create an account. It might not work in some countries, but it definitely works in UK and US. So if it doesn't work for you, you probably, the solution here is to download VPN, choose either UK or US location, create an account, and then you don't need it. So you just need VPN once to create an account and it will work for you and it will be and it's completely free to use. So I will show one example, how I use Clot to work. So I have to learn information. So I have a white paper. This is Bitcoin white paper. It goes into details about how Bitcoin cryptocurrency network works. It is relatively technical. So what I would do, if I want to learn about how Bitcoin works, but maybe let's say I'm not a technical person, I don't understand too many things about cryptography, I would just upload a PDF here and it could be any kind of scientific paper. And I will ask a question. And the question, my question would be explain this paper as if I'm seven years old. So I will just ask Claude Chatbot to explain the complex paper for me in simple terms. And as you can see, it already starts giving me answers answer. And if you read it, I won't read the whole thing, but if you read it, you can see that it's really, really simple. Like I have a kid who is about that age, and I'm sure he will understand. So it just goes, sending money online is tricky, because you don't want one person spent the same amount of money twice. And this is how Bitcoin helps it. And yeah, it's just a simple way of explaining. I can also ask a follow up question, how new Bitcoins are created. So I can just chat with this article. And it will continue generating these answers in this very simple term. So it doesn't go into deep cryptography, it just calls it math puzzle. And that's easy to understand. So that's just one example and one application. And I have link, Claude here on this slide. Another example is to use large language models as your second brain, as a way to remember and way to reference complex information. So you can record a lot of things today with even free online tools, such as calls, for example, this call is being recorded, and Zoom is actually doing live transcribing of what I'm saying. You can record documents, download documents. You can download web pages. And then you can use one of these tools. And actually, each one of them is free to use, at least up to a certain point. This first one is open source and it's free to use forever. So if you want a free solution, I recommend this one. This last one is unreadable, is the one that I'm going to show right now. And it is more focused on students and the way to prepare, for example. And the way that second brain works is I just go to this website, I create a free account, and then I kind of upload some information, some documents here, and talk to those documents. So I'm just uploading a presentation, this presentation that I'm just showing. And I upload this presentation here. And the difference between the example that I just showed before with chatting with the paper, and this one is that here you can upload a lot of information. You can upload the whole book, or maybe multiple books. And then this information is stored, and you can use the same technique, you can just ask questions. So for example, I will ask, it actually prepares some questions that I can ask, but I will ask, what are AI use cases in marketing? And based on this presentation, it will give me answers. Personalized marketing, empathetic communication. And if we scroll to the slide that is still coming, so a little bit of unveil here. So this slide is AI marketing. And as you can see, it has actually found the right slide. And it gives me information, not based on what chat GPT knows about marketing, but based on this exact presentation. And if I were to upload a book here, I can just ask questions to the book, and it will give answers based on relevant information that it finds in that book. And that's very useful. This is also one of the applications that I'm using more or less daily for various use cases. Another very, very powerful application is to use GPT or any other large language model to be your thinking partner or brainstorm partner. Because GPT on its own might not completely and full autonomously solve any of the problems that you have, but it is great when you want to have someone to basically think with or discuss or brainstorm ideas, please. And I will show example of me creating a prompt. So this is the prompt that I did. I'm saying that I'm running webinars and lectures on how to use AI for work. And I'm asking chat GPT to use these six thinking hats methodology, which is just brainstorming methodology to help me generate ideas. And this is the response that I get from chat GPT. And this is actually very useful. Again, I'm not going to read everything here, but this link is public. And the value here is that it might not give me exact answer that I'm looking for, but it will give me suggestions that will spark some imagination creativity that will help me to actually come up with more creative answers. And this is also something that I'm using pretty much every day for different questions and problems and issues that I'm facing. You can use different methodology. So six thinking hats is completely optional. You can just go to chat GPT and type, help me brainstorm ideas for present, for marketing campaign, for help me write ideas for an article that I'm writing. And it will give you some ideas. And then you can ask to elaborate and basically continue that conversation to get more valuable results. One important thing here to note is that if you want to steer how chat GPT gives you answer, if you have GPT account, I suggest to setting up custom instructions. So if we go to chat GPT, you can, so first of all, if you don't have, I highly recommend to create an account in chat GPT, the product itself is free, but you can also subscribe and get a plus subscription, which gives you access to a more powerful model. But then when I'm talking to chat GPT, instead of getting generic answers, it is very useful to use this thing called custom instructions. So if you click on your profile, go to custom instructions, and you can add some information here. So I will share the custom instructions that I'm using on this slide. You can change it whatever way you want. But the value of this is you can steer how the answers are being generated. For example, for me, the important thing is for it to respond concisely and be blunt, because it usually likes to go into this very long and maybe descriptions of a lot of things. And you can read through this. In my experience, adding these custom instructions really increases the quality of response and increases the value that I'm getting from using chat GPT almost two times. So highly, highly recommend using it. And you can copy this from the slide and use in your own GPT. Next use case is communication. So I already mentioned that GPT is great for writing any kind of emails, posts, or translating information. But it is also, you can also ask GPT to write in a specific style. And one thing that I personally found very, very exciting and very useful is to use GPT to visualize conversation. So this small screenshot on the right is a small application that developed. So this is not part of chat GPT. It's not something you get when you sign up. But this is just like a product, that's very, very small product that I built to showcase what's possible. And I'm sure there will be or there probably are already similar products that you can find online. Maybe some of them are paid, but I think the value is very clear. So on the screenshot, what's happening is I'm using data from my Telegram group channel. And you can use it for Slack or Discord or email threads with a lot of people. And then in the screenshots, every square is a person and that's their name. Every star is a topic that is being discussed. And every line is a specific message regarding that topic coming from a specific user. So if I have a group channel in Telegram with maybe 100 people, and I didn't open it for a month, and there's thousands of messages, it would take me hours to read through that. But using something like this, using large language models to summarize and then visualize data will help me to understand what's being discussed in that group. And I can just skim and scan this image, spend five minutes, and I'm already up to date. And if I find something that is useful or interesting for me, I can click on this line and it will open the specific message. So this is one of the use cases that I kind of over many months I developed for myself. And this really saves hours because I have a lot of different communication channels, a lot of social media kind of comments, and it takes time, takes too much time if I try to read all of those. I just don't have time to do anything else. I will show another example is related to visualization. So one of the problems, one of the drawbacks of GPT and large language models that you will probably identify and realize very quickly when you start using it is that they're pretty bad at analytical and math tasks. So LLMs cannot really compute or count complex mathematical questions or problems. But what they can do, they can write code. And when they write and then execute computer code, this code is always giving you correct result because computer is basically just a, it is a computer, it computes. So whatever code you put, you always get the correct mathematical results. So if I ask GPT to solve me maybe like an integral, it will most likely fail. But if I ask it to write a computer program that solves the same problem, it will be, it will be correct. And solving integral may be not very useful or relevant for most of, most of you or at least I don't do it daily. But I find this feature very, very useful when it comes to data analysis. And I want to show an example. I have a spreadsheet, which is a sales data related to motorcycles and cars. And it goes into, there's a lot of, there's a lot of data. There's like sales number, customer name, address and country and all of that. So what if I want to create some kind of, what if I want to get insights from this data? For example, I can upload this file. I just upload this file to chat GPT. And I ask it, draw me a histogram showing where the goods are shipped, the city and also use different colors for different types of goods. And this is what I get. So it takes me, it really literally took me 30 seconds to wait until GPT completes it and gives me this picture. And this is actually, I can also see the code that it wrote. So this is actually what it did. And this is a Python code that analyzes the spreadsheet, takes specific data from it and draw draws a histogram. And if you if you look closely, it is, it is, it is doing exactly what I asked. So it has city name like Leo, New York city and so on. And it shows motorcycles in light green cars in dark green. And I can actually keep going. I can ask, follow up questions. So for example, I can ask it like, what was the average price for all of the goods? And it will do the same. It will, it will also, we can actually see how, how it's writing code. It will, it will make mistakes. It will write, it will do bugs, but then eventually it will correct itself. And this is the final result that I get. I mean, this is maybe a simple question. I can just do it in Excel, but I can ask it to do much more complex stuff. I can ask it to work on large files to do complex analysis. And the goal of this example is to show that whatever tasks that usually you have to hire a data analyst or ask a software engineer to do for you, now you can do just with charge EPT, you can just talk to it and ask it to complete this and you will get results. And this is very, very useful. Really, it saves thousands of dollars sometimes because, because data scientists are not, are not cheap and GPT costs 20 bucks a month. Okay. Moving, moving next. Another useful feature of GPT is that it can read and analyze visual data. And this example that I'm showing here on the right is I basically took a photo with my iPhone of the drawing that I made on my whiteboard here on the, on the, on the wall. So I just, I took a pencil, I draw something on, on, on the whiteboard. And then I asked GPT, please use this diagram and write me a structure outline for the presentation. So this is what I had just thinking on, on, on, with, with my pencil on the whiteboard. And this is what I, sorry. And this is what I got. So you can draw pictures, you can make photos, you can ask GPT to identify objects on the photo, you can ask GPT to translate some text that, that, that is on the photo, you can ask charge EPT to maybe extract information from the picture. And that's the value of visual vision models that are, these vision models are only available in the paid version of charge EPT, but if, but it's, it's really worth it. And there's also a free alternative, I will show it later. Another use case is browsing, browsing the web. And I want to recommend a few tools here, because one of the problems with another problem with large language models, in addition to them not being very good at math, is that they, by default, they don't have access to most recent information and news. So they don't have access to internet by default. But we can ask either charge EPT to use this web browsing. So I can ask, like, find me most recent news on AI on the web, and it will go and, and it will go and, it will go and do a Google or Bing search. Sometimes it's being slow. We'll come back to that. But there's also a specific and very specialized products that are free to use that allow to add this capability of browsing the internet and getting data from the internet to large language models. Two that I want to highlight specifically are Perplexity. Perplexity is really Google but better. It allows you to, when you're searching for something, it allows you, instead of getting a list of links, like you do on Google, it allows you to do a, to get a actual response. So for example, there's a news about new solar system in Milky Way. If I press this, I, I just get an answer saying that astronomers have, have discovered a new rare solar system in Milky Way and it goes on. But this data, it's not just generated by LLM. This is not hallucination. It comes from, from, from specific source. So I can read this. This is an answer for my question. Or I can go to the source website. And this is associated press article on the same topic. And I can, I can read the source. And I'm using Perplexity for a lot of things. Really, it is just in, every time when I want to get an answer, if I'm not looking for a website, but for an answer for the question, Perplexity works better than Google. For me, almost 100% of times. And it's free. And it has no ads at least right now, maybe in the future. It also has a paid version that has more features to it. But really, this is one of the, one of the best use cases and products built using artificial intelligence. By the way, GPT also finished. So as you can see, when I asked it to find more recent news on AI, what it did is it looked for, it did a Bing search. And it found these articles. So again, this information is not something that GPT hallucinated. It is actually coming from the source. It is coming from this generative AI tech branch section. So if you feel like your chatbot is not using most recent information, I recommend using Perplexity, web access for, for, for chat GPT or also Bing search. By the way, Bing has a free version of GPT for. So if you don't have chat GPT, for some reason, you can use Bing, which is free alternative or actually a free UI free version of charge GPT that anyone can use. It doesn't cost anything. It is same quality, same model, same thing. It has access to internet. And it also has a mobile app. So, so yeah, depending on your preferences, this might be this, this, this, this, this might be a solution or good great thing to, to, to use for you. And there's also GPTs. GPTs is something that was recently created by OpenAI by creator of, by the company that created charge GPT and GPTs is ability to create your own version of GPT that is using your own data. So I will not go into a lot of details here, but I just want to show that creating your own GPT is very simple. So if you have a GPT plus subscription, you can go to chat openAI.com slash GPTs and you can create your own GPT that can do anything you want. And building this application is easy. You don't need to be software engineer. You can just chat with it. Basically, there's a charge called GPT builder, and it will, it will, it will, it will generate GPT for you. So let's, let's try something. And this is where we actually going into, into business use cases, because this is both useful for personal, but also for business use cases. So for example, I want to build a GPT that converts that, that creates marketing slogan based, based on the logo. And this is all I need to know. So the, like the most stunning, the most mind blowing thing here is I'm right now, I'm doing software engineering. I'm creating a new product, a new product, a new application. And all I do is just typing. I'm just chatting with this thing. So I don't need to write any code. I don't need to, to know any programming languages. I just need to do it. So it asks me, it suggests me a name, which is slogan crafter. I say, yeah, it's a good name. Okay. So now it created me a logo. It created a name. And it also created a prompt. So if you want to be more specific to change something in the behavior of how this application works, you can go and edit this message. So let's test. We just created an application. It took me less than 60 seconds. It was never possible ever before in the history of humankind. So this is the logo that I have, Codex town, which is one of the projects that I run. And I want to create a slogan for this logo. It's actually doing, it's not doing the right thing. Sorry. I forgot to upload a picture. Write me a slogan. So this is the logo that we have. And then it will, it will create a slogan based, based on this, this logo, because it doesn't have any context about what the project is about. It's just using the colors, basically the style of the image to create the slogan. So this application might not be very useful. Goal for me is to show how easy, how simple it is to build. I also want to show a few applications that are actually useful that were created by, sorry, by other people and that I'm using daily. So for example, let's go into this one, for example. So Dr. Andrew Huberman is a neuroscientist and he has a lot of great podcasts. But the problem with his podcasts is that they're long and I didn't have time to listen to a lot of them, to a lot of those. So what I can do, or someone, what someone did, someone created, someone uploaded all the recordings of the podcasts by Andrew Huberman and created a GPT. And now I can chat with this GPT and it will answer to me based on the question, based on the data that is coming from those recordings. So I can ask for tips on staying focused over time. This GPT will first search its own knowledge base, which you can upload while creating a GPT. And then it will generate an answer based on, based on that. So I already used it. I actually asked the same question and I find it extremely useful, like I'm using most of those tips. And then this is just an example. Another example of GPT that I created is a sketch to code. So this GPT allows me to upload any picture. I don't have, I don't have right picture. Sorry, I didn't prepare. But basically, well, I won't show the demo, but you can actually use it. So it's public. It's free to use. And what it does is I can just create a simple image of the website, what I want to have on my website. And then I upload it here and it outputs the code of the website that I can immediately run. So that really saves time and almost replaces the work of website software engineer for, at least for simple stuff. So it won't help with something very complex, like huge e-commerce website. But if you want a simple page with a few elements, you can just draw it on a piece of paper. I can literally take a photo of what I draw on my whiteboard and it will convert it into a code. And that's amazing. And that's my blowing. So what I want to do next, I want to skim through a few slides. I won't stop into detail on each one of those. But these slides are for you to use and to explore later. On each of those slides, I have a list of different products and neural networks or AI models that are useful for different tasks. So I have a capability listed on the left and then links here. And there's a lot of those. We don't have time to see and to check every one of those. But I want to show that there is a bunch of models that allow to generate text. There's a bunch of models that are out to generate and help for software engineering with software engineering job. There's a lot of models that allow you to generate music and voice and also translate text to speech or speech to text. And there's a few models that actually a lot of models right here. I have a link to the website which has a huge collection of different image generation models. And most of those products, so on each one of those slides, important thing is at least one or actually at least half of all these models are completely free and open source. So you don't need to pay for anything to start using it. If you want to use it into maybe some enterprise production use case, yes, there are enterprise solutions, but to start to test to play with it, most of these things are actually free to use and that's great and that gives a lot of increases accessibility. And finally, these models are vision models. These are what I showed on one of the examples. These are models where you can upload a photo or upload a picture and then ask questions about that picture. For example, it is relatively good with actually medical diagnosis, although it is, I don't recommend it use instead of professional medical help, but it is also useful for identifying objects like safety requirements or maybe give recommendations regarding design or architecture or something like this. And we already touched some of the business use cases. I wanted to show a few more. So we have a few more minutes and let me go into some of the most interesting business use cases for generative AI. I will skip this. Important and maybe most important thing about use cases for AI in business is that business processes are not simple. Business processes are not just one action. It is usually some logic. And this logic is hard to achieve just by chatting with ChargeGPT. If you ask ChargeGPT to create something complex like, I don't know, promote my product, it doesn't know what to do. There's too many things that goes into that task. But if it is split into simple tasks and then we chain those tasks together, we can actually achieve very complex behavior. One of the examples is to use AI for nature language processing. Here on the right, on the example, I have an example of the user that has some kind of intent, or some kind of message on our, let's say, website. And then this message can be classified, depending on the intent. Is it an inquiry? Is it a price inquiry? Is it a complaint? Is it a gratitude for our product? Based on that, we can use different prompts or different AI models to generate a response. So one of the models will retrieve relevant data, for example, product specification. Another model or another instance of the model will write response to the customer. So use that product specification and answer to customer question. And then another model will generate a picture and attach it to email and then that can be sent. One, another example for business use case that a lot of companies are actually using today is to use large language models as a knowledge management system. You can take all the existing digital communication tools like Gmail, Zoom, Jobbox, LinkedIn, Office, Slack, and so on, then upload it to a LLM system and then have ability for anyone in the company to ask questions against this knowledge base. So if I have a list of product specifications, I upload it to this LLM and then anyone in the company, any sales agent, for example, sales representative, if they have a question, they can just ask, they can just type or even record a voice message and get answered to the question like, for example, product X, what is the price or what is the dimensions and this system will give instant response. So it saves a lot of communication overhead and saves a lot of time when we want to share knowledge within the organization. Another huge use case in the, if you remember the McKinsey report that I showed in the beginning, it is one of the primary use case for large language models today is in engineering and there's two applications of that. First of all, yes, AI is very, very helpful to software engineers. It can help write code, it can test code, it can help you fix bugs, it can help identify bugs, but it is also useful to people who are not engineers, but they need to complete some engineering tasks like the data analysis example that I showed, but it can be much more complex. It can be connected to CRM system, to databases, to existing websites, all different kinds of ERP and corporate systems. And one of the probably on par with engineering, one of the most widely used applications of AI is marketing. And in marketing, there's a lot of things how AI can help. And most of those are related to either content generation. So you can create articles, blog posts, you can create text that is search engine optimized, you can create graphics, you can even create videos, you can create personalized content, which is something that was never possible before the AI. So if your company has, let's say you have 100,000 customers and you know something about those customers and you want to say them a personalized Christmas message, it was never possible to send to manually write 100,000 messages to all of your customers. But now with AI, you can just upload some of the personal information that you know about the customers, like I don't know where they leave or what their interests or what do they like. And then have AI to generate 100,000 personalized messages. And this can be just fun, just to do something nice to your customers. But this is also valuable for the business. So if you're a business, let's say you are for financial organizations, for example, we have a customer who's a bank. And for them, what they do, they know like financial preferences of all their customers. And then the right messages that are digest on the news in the stock market, based on specific interests. So if someone is investing in high tech and another person is investing in, let's say sustainability companies, these two persons will receive very personal and individual and very different email marketing or email digest. And that is not just cool and fun. It is really increasing the conversion rate and click through rate. And at the end, it is beneficial for the bottom line for how much profit the company makes. And one more example here to show is customer operations. So the idea of using AI in customer operations is that you can actually use AI, not instead of sales representative, because sometimes you still need human to human interaction to close the sales. But you can have it as an assistant, as a co-pilot to sales agents. So AI can help sales agents and show them proactively show them some information that is relevant. What makes sense to say to the customer. And it can also handle some of the cases. So if there are simple questions, then AI can answer. If there's something more complex, or if the customer's clothes is ready to buy, then it can send it to a sales representative and allow to speak to a person. This is an example from legal. What I did here is it's very similar to the visualization example that I showed in the beginning. But this is applied to contracts. Sometimes you have very complex, very large legal contracts that are hard to understand, especially if you are not a lawyer. So AI and large language models can be used here to create a diagram based on the contract. So, for example, there's a 15-pages contract. And this is the diagram that only mentions most important things for me to maybe make a decision or to review this diagram. So it does not replace the work of the lawyer, but it is helpful for maybe executives or management to see what's going on without reading all these 15-pages of complex legal text. And that's just one of the examples. I'm skipping some things because we're close to the end of presentation. But on the left, I have more examples for use cases of AI in each one of those areas. One more area I want to highlight, I think it's very, very important, is people operations and HR. And the reason I think large language models and AI is very useful here is because trading and education is really the core of most businesses, like people are what makes business successful. And I'm really a big fan and I really believe in the fact that large language models will do a lot of, will enhance and improve and improve quality of education worldwide. Meaning that AI is helpful as a tutor, even for the startups that are building AI educational software for school children, for universities, and for corporate training programs as well. So AI can run, can explain complex information as shown. It can generate case studies. It can simulate some real work behavior. So for example, if you are training sales representatives, you can generate, you can ask AI to be a partner to train and to practice some sales skills. So you can ask AI to be an angry customer. And then it helps people who are new to the job to know what to say if somebody is angry. Or you can ask AI to to simulate a market situation. And that is useful for practicing maybe some management skills. Or you can ask AI to generate a code that has some bucks. And it's useful to upskill and train engineers. So this is, there's a lot of examples like this, or a lot of, I would say, a lot of products, a lot of companies. So when we go into enterprise use cases, those are mostly not free. Those are some big products or big companies doing this and also small startups. But I, my suggestion is to really to, to pay close attention to AI products in all of these areas. Because at the end of the day, what it gives, it gives economic efficiency. And it allows to save costs. And it also allows to find new market opportunities. And to wrap it up, I want to, I want to show one more slide here, which is regarding AI strategy. So if you, if you plan to use AI in your business, I have a specific, I would say, plan or, or, or, or suggestion how to approach this, because it might be overwhelming. There's a lot of products. There's a lot of people trying to sell all different kinds of things. Some of those might be great. Some of those might be great. Some of those might be very, very simple and too expensive. So in order to do it correctly and in order to do it, like not to rush things, but also not to wait until it's too late, I suggest starting with experiments with chat. So any simple business task can be validated and can be tested in chat GPT, even in the free version. And that gives you idea, overall idea, like, is it even possible and what would be the quality of the results? Some tasks they are possible to do, but the quality is too bad. It's still like AI is still not as smart to automate them. In some tasks, you will get good results. Once you have an experiment that you see is working well in the chat, the next step would be to create a co-pilot, a workflow, maybe connect a few chats with preset prompts. So one chat is, one prompt is responsible for writing a text, and the second prompt is responsible for proofreading a text. And then you combine these two together and you get to an agent. Agent is, when I show that slide with chains, agent is a system, is a application that takes result of one AI tool and passes it to the next tool and then passes it to the next tool. And those agents are relatively simple to develop. You can use either no-code platforms, you can use it, build it internally if you have software engineering team in your company, or you can find external developers. And this is not too expensive, like AI used to cost hundreds of thousands or even millions of dollars, like five, 10 years ago, like huge AI deploy the deployment projects. Right now, building agent for search engine optimization or sales or marketing, it can cost just a few thousand dollars, or you can do it, build it for free. And I will not show exactly, I will not do full tutorial, but I want to show a couple of tools. One of them is called Relevance AI. Another one is called Skate Pro. Let me just show their landing pages. And I have both links in the presentation. So this is just to show. So Relevance AI is a tool you can start using for free. They give you quite a lot of free credits that you can use on the platform. So if it's small business, you might even get away with free version. And then Skate Pro is also, they combine 1500 different AI tools in a cascade. So you can create these agents and create very, very simple, very, very, very powerful AI workflows. And maybe two last thing I want to say is that if something doesn't work, I want to encourage you to not give up. Because what is happening is that AI progress, progress in the AI space is stunningly fast. And we're moving at increasing and unprecedented speed. So if something is not working, if you feel like AI texts are maybe too dry, you don't like it. Or if you think that it is not helping you with sales process, or it only helps for a very small percentage of your potential customers, that is fine. But I really suggest you to keep, to just pay attention to the space. Because models and tools, these foundational models, they are improving very, very rapidly. And if something doesn't work today, it will likely change in the near future. And it is important to pay attention and to build processes and products that will evolve, will get better with more powerful tools and with more powerful underlying models. And that's it for my presentation. Thank you so much. I have my contact information here on this slide. And we have some time. If there are any questions, happy to answer, happy to discuss, happy to maybe show more, if you're interested in something. Dina, maybe a question to you. How do we want to manage the Q&A part? Stepan, thank you very much. I think it should be just an open floor, whoever wants to raise your hand or turn on your camera or write in the chat, if you don't want to show your face. Dimash has a question. Go ahead, Dimash. Dimash, we cannot hear you. You can also type in chat. Yeah, just type in chat. Okay, anybody else? I mean, can I ask this brief question, Stepan? How can we make this personalized AI solutions without compromising privacy and security, maybe? Mm-hmm. Yeah, great question. So I had this slide where I had a list of different AI models. And the one thing about OpenAI, ChargeGPT, is that that model is private, meaning that it belongs to OpenAI. And whatever data you send it, it will end up on their server, so they can potentially have access to it. So when you want to build an AI system that is 100% private, 100% working on your own computer or in your organization, I will give you very specific recommendation. Actually, I will just open it on my computer, but I suggest using LM Studio. So you can go to this website, LMStudio.ai. This is a completely free application that is available for Mac, Windows, Linux. And you can download this app. And then inside that app, you can download any of hundreds of existing free models. So this is an app that I have installed on my computer. And these are all the models that I have downloaded, but this is just part of them. So when I use any of these models, no data is ever leaving my computer. I can disconnect myself from the internet, and all of this will be working. And these models, most of them are not as good as GPT-4, but depending on your task, it can be good enough. And there's also a question I see in the chat about models that work well with Russian language. I can just show it here. So you can go to here. And there's a model called Saiga. And this is one of the models that works very well with specifically Russian language. But I think GPT-4 still outperforms in, I would say, in every language except for maybe Chinese. So GPT-4 is the best model today that working with any other language except for Chinese, because they have a lot of their own Russian language models in China. But GPT-4 is great for English and other languages. Okay. Any more questions? Can I ask the question? Yes. My name is Carla. I'm not technically aware. I'm not that in business, actually. But can you distinguish between the chat GPT-generated music and the human-generated music? How you do that? Yeah. Good question. I think... So first of all, chat GPT-4 does not generate music, but there's special tools specifically. It's called sueno.ai. So if anyone wants to generate music, there's also... I will send it in chat. It's called sueno.ai. And the problem of identifying if something was... if music, image, or text was created by AI or a human is quite hard. It is possible to identify if it is just, I don't know, robotic sounds music or the text is just very, very, very badly written. But as this model becomes better, it will be, in my opinion, so there's no technical way of 100% guarantee that something was created by an AI. So as these models get better, it becomes very almost impossible to distinguish. So this is a hard problem that I don't think anyone has an answer to, really. And does it mean that the old composers will lose the job eventually with this chat GPT-generation, generating music, or like the still will be some use of the human? I'm sure humans will always do music because AI doesn't... It can do something, it can help humans, but I don't think it can, at least at this point, can produce... It doesn't have subjective emotional experience. So I think that's the important part. That's the crucial part for generating art. But what is happening today, what I see a lot is people, artists, being writers and musicians and videographers and painters, they utilize AI tools in their work more and more. And that's great because when electric synthesizers were created, we got, or electric guitars were created, we got a whole new genre of music. So it's the same thing. We now get more tools to express ourselves. All right. Thank you. Thank you. Thank you. Thank you. Great question. There was a follow-up question, like what professions will be last to move with AI in the chat. There was this question. Yeah. Good question. Actually, paradoxically, things that are not being automated are things that are relatively low-paying jobs and physical jobs. So I don't know, a barber or a hairdresser or a plumber or someone who works in construction. It started at seven o'clock in the morning, I didn't realize. Let's try this one. This is an AI workshop. Yeah. Yeah. Sorry, Jim. I put you in mute for now. And yeah. So the jobs that are least prone to automation are those that are low-paying because there's less economic gain from that automation and also that are manual and requires a lot of manual work because robotics is much more expensive than software. Building a robot costs much more than building a software application. So office jobs like marketing or sales or finance or legal innovation in those spaces are happening much, much faster than, for example, robotic automation of cleaners or something like this. I see, I'll read a few questions from the chat. So there's one question about non-English-speaking languages. So I don't know about Mongolian. I don't know Mongolian, so I cannot test it. But I would suggest to start with charge EPT. And if you don't have an account, go to Bing chat and it will work exactly the same way as charge EPT. What I found is that charge EPT is really good on... So the quality of the text it produces is proportional to how much text on that language did it see during the training period when it was trained. And that is more or less roughly proportional to how much text in that language exists online. So obviously languages like English, Spanish, Chinese, French, German, they have... There's a lot of text in those languages online and therefore GPT is very good at those languages. Languages like Mongolian are not very... There's not too much of that data. There's not a lot of that data in the training set. But it can still be good enough. So I think GPT-4 would be the best benchmark. It's the best way to test how good models are today. But over time, I see there's a lot of companies, a lot of projects, a lot of open source projects that are building localized versions of LLMs. So I showed Saiga, which is a Russian version. It's actually not the only one. There's a few more models that are specifically trained in Russian. There's a lot of... I know a few companies in France doing the same. So this problem is slowly being solved. But right now English is... It's just because most of the internet is in English, that's why AI models speak English much, much better than other languages. So the question is, where can we find various AI websites? I'm not sure. Are you talking about AI models? If so, then this is the link I sent to chat. There was a question about why developers are limiting access of these models to internet. Oh, yeah. Yeah, I see now. Yes, great question. So one of the main reasons is it's a really legal question. So people, when ChargeGPT first released internet access, it was used, it was very widely used for scraping data from paywall content. So for example, Wall Street Journal is a paywall website. You cannot access it. I think you can see like three articles a month, and then you have to pay subscription. But people were using ChargeGPT to scrape articles from Wall Street Journal and other media. And that was just a copyright issue. So it's not really a technical question. It is a legal question. And legal questions tend to take longer to resolve than engineering questions, just because of how legal system works. It's slow. But there are alternatives. So today, ChargeGPT has access to the internet. It won't give you some paywall content, but it can, for example, read Reddit or some public data that is available. Okay, any more questions? So I want to reiterate that. I will, sorry. I have a last question, personal one. If the way to train my personal GPT, if I could upload, for example, my Facebook archive and emails, how it could help me in general, I mean, the private assistant? Good question. I think, I don't know. It's really, you really should test it, because it depends on what's in there and what data. And it's also like when you're uploading data to GPT, you need to keep in mind that this data is being stored on their servers. So maybe not, maybe not upload something very, very private information in there, like Gmail, it can have, I don't know, financial information, something like this. But the use cases for personal assistance is that you can use previous history of your communication to generate answers to maybe incoming communication messages. So if you have history of all your emails that you sent and you receive a similar email with a similar question, GPT will be very good at producing a new response or writing a new draft, email draft in a style and with the content that's very similar to what you sent in the past. GPT is one way to do it, maybe more technically advanced way to do this would be through fine tuning, but that requires a lot of technical expertise. So yeah, so this assistant can be a way of automating your own communication and helping you with producing email drafts or responses or maybe messenger responses, something like this. And it should also know my personality well if I upload the social media. This is what you, right? Yeah, this is what you have to explain and define in the instructions. So in GPT, when you create GPT, you have this instruction box for instructions and you cannot, it cannot learn your personality based on uploaded information, you need to explicitly type it and say like you need to answer in a friendly tone, use maybe these words, don't use these words, use like this kind of language presentation and so on. And then it will follow those instructions in order to actually take the tone of voice and teach GPT to reply in your tone of voice. For that, you have to do fine tuning. It's possible with GPT, but it requires more technical expertise. Probably need to find an engineer to help with that. All right. Yeah, so I see no more questions, but I will send recording and presentation to Dina, so you will get it soon. All the links, everything I've shown in the today are in the presentation. There's actually a bit more that I, a bit more slides, I skipped some of them. So, so yeah, I hope, I hope, I hope this is valuable. I hope this is useful and I hope that my sincere recommendation is to like just spend more time working with the systems and working with GPT, with AI, because the most important thing is to build intuition. That's what most useful. Thank you very much, Dipan. I think that was quite a comprehensive presentation, especially for the first slide, being an intro. Tamuna, you want to say something? I just wanted to say thank you. It was really one of the most useful and practical AI sessions I attended, and I attended several, so thank you. It was really good. Thank you very much.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.5200000000000005, "text": " Thank you, Dina. And hello, everyone. Excited and very happy to be here.", "tokens": [50364, 1044, 291, 11, 413, 1426, 13, 400, 7751, 11, 1518, 13, 9368, 1226, 293, 588, 2055, 281, 312, 510, 13, 50640], "temperature": 0.0, "avg_logprob": -0.18185806274414062, "compression_ratio": 1.4630541871921183, "no_speech_prob": 0.03466729074716568}, {"id": 1, "seek": 0, "start": 7.84, "end": 13.120000000000001, "text": " So today, we're going to spend about one and a half hours talking about", "tokens": [50756, 407, 965, 11, 321, 434, 516, 281, 3496, 466, 472, 293, 257, 1922, 2496, 1417, 466, 51020], "temperature": 0.0, "avg_logprob": -0.18185806274414062, "compression_ratio": 1.4630541871921183, "no_speech_prob": 0.03466729074716568}, {"id": 2, "seek": 0, "start": 13.120000000000001, "end": 19.6, "text": " generative AI and recent trends in artificial intelligence. Let me share my presentation.", "tokens": [51020, 1337, 1166, 7318, 293, 5162, 13892, 294, 11677, 7599, 13, 961, 385, 2073, 452, 5860, 13, 51344], "temperature": 0.0, "avg_logprob": -0.18185806274414062, "compression_ratio": 1.4630541871921183, "no_speech_prob": 0.03466729074716568}, {"id": 3, "seek": 0, "start": 21.76, "end": 27.92, "text": " So I will skip my introduction because Dina did a great intro.", "tokens": [51452, 407, 286, 486, 10023, 452, 9339, 570, 413, 1426, 630, 257, 869, 12897, 13, 51760], "temperature": 0.0, "avg_logprob": -0.18185806274414062, "compression_ratio": 1.4630541871921183, "no_speech_prob": 0.03466729074716568}, {"id": 4, "seek": 2792, "start": 28.32, "end": 34.72, "text": " But if you want to maybe get in touch with me, I will send the presentation afterwards.", "tokens": [50384, 583, 498, 291, 528, 281, 1310, 483, 294, 2557, 365, 385, 11, 286, 486, 2845, 264, 5860, 10543, 13, 50704], "temperature": 0.0, "avg_logprob": -0.14487352090723374, "compression_ratio": 1.5138121546961325, "no_speech_prob": 0.004442671779543161}, {"id": 5, "seek": 2792, "start": 34.72, "end": 46.160000000000004, "text": " And it has my Twitter and Telegram account. So a bit of logistical logistics. So the session", "tokens": [50704, 400, 309, 575, 452, 5794, 293, 14889, 1342, 2696, 13, 407, 257, 857, 295, 3565, 42686, 27420, 13, 407, 264, 5481, 51276], "temperature": 0.0, "avg_logprob": -0.14487352090723374, "compression_ratio": 1.5138121546961325, "no_speech_prob": 0.004442671779543161}, {"id": 6, "seek": 2792, "start": 46.160000000000004, "end": 54.24, "text": " is being recorded. I will have a lot of links, useful links and materials and examples in the", "tokens": [51276, 307, 885, 8287, 13, 286, 486, 362, 257, 688, 295, 6123, 11, 4420, 6123, 293, 5319, 293, 5110, 294, 264, 51680], "temperature": 0.0, "avg_logprob": -0.14487352090723374, "compression_ratio": 1.5138121546961325, "no_speech_prob": 0.004442671779543161}, {"id": 7, "seek": 5424, "start": 54.24, "end": 61.92, "text": " slides. And those are for you to access after the workshop. I hope it will be useful. And", "tokens": [50364, 9788, 13, 400, 729, 366, 337, 291, 281, 2105, 934, 264, 13541, 13, 286, 1454, 309, 486, 312, 4420, 13, 400, 50748], "temperature": 0.0, "avg_logprob": -0.08910618832236843, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.005456122569739819}, {"id": 8, "seek": 5424, "start": 61.92, "end": 67.36, "text": " there will be a lot of links that I will not even have time to cover. So I hope that these", "tokens": [50748, 456, 486, 312, 257, 688, 295, 6123, 300, 286, 486, 406, 754, 362, 565, 281, 2060, 13, 407, 286, 1454, 300, 613, 51020], "temperature": 0.0, "avg_logprob": -0.08910618832236843, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.005456122569739819}, {"id": 9, "seek": 5424, "start": 67.36, "end": 74.0, "text": " materials will be useful. The lecture or the workshop itself will take about one hour.", "tokens": [51020, 5319, 486, 312, 4420, 13, 440, 7991, 420, 264, 13541, 2564, 486, 747, 466, 472, 1773, 13, 51352], "temperature": 0.0, "avg_logprob": -0.08910618832236843, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.005456122569739819}, {"id": 10, "seek": 5424, "start": 74.56, "end": 81.52000000000001, "text": " And then we will have about 30 minutes for Q&A. But it's Saturday, so I'm happy to maybe stay", "tokens": [51380, 400, 550, 321, 486, 362, 466, 2217, 2077, 337, 1249, 5, 32, 13, 583, 309, 311, 8803, 11, 370, 286, 478, 2055, 281, 1310, 1754, 51728], "temperature": 0.0, "avg_logprob": -0.08910618832236843, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.005456122569739819}, {"id": 11, "seek": 8152, "start": 81.52, "end": 89.52, "text": " a little bit longer if there are more questions. And the plan for today is for us to talk a little", "tokens": [50364, 257, 707, 857, 2854, 498, 456, 366, 544, 1651, 13, 400, 264, 1393, 337, 965, 307, 337, 505, 281, 751, 257, 707, 50764], "temperature": 0.0, "avg_logprob": -0.09694957733154297, "compression_ratio": 1.5265957446808511, "no_speech_prob": 0.0055313510820269585}, {"id": 12, "seek": 8152, "start": 89.52, "end": 95.28, "text": " bit about what is artificial intelligence? How is it changing recently? And how it does it impact", "tokens": [50764, 857, 466, 437, 307, 11677, 7599, 30, 1012, 307, 309, 4473, 3938, 30, 400, 577, 309, 775, 309, 2712, 51052], "temperature": 0.0, "avg_logprob": -0.09694957733154297, "compression_ratio": 1.5265957446808511, "no_speech_prob": 0.0055313510820269585}, {"id": 13, "seek": 8152, "start": 95.28, "end": 102.72, "text": " the economics and different industries? Then we will talk about two very specific areas of", "tokens": [51052, 264, 14564, 293, 819, 13284, 30, 1396, 321, 486, 751, 466, 732, 588, 2685, 3179, 295, 51424], "temperature": 0.0, "avg_logprob": -0.09694957733154297, "compression_ratio": 1.5265957446808511, "no_speech_prob": 0.0055313510820269585}, {"id": 14, "seek": 10272, "start": 102.72, "end": 110.72, "text": " application of artificial intelligence, which is personal. Sorry, I will unmute people for", "tokens": [50364, 3861, 295, 11677, 7599, 11, 597, 307, 2973, 13, 4919, 11, 286, 486, 41445, 561, 337, 50764], "temperature": 0.0, "avg_logprob": -0.1538401880571919, "compression_ratio": 1.5730994152046784, "no_speech_prob": 0.016624752432107925}, {"id": 15, "seek": 10272, "start": 112.72, "end": 120.16, "text": " time being. We'll talk about how artificial intelligence can help you in your personal", "tokens": [50864, 565, 885, 13, 492, 603, 751, 466, 577, 11677, 7599, 393, 854, 291, 294, 428, 2973, 51236], "temperature": 0.0, "avg_logprob": -0.1538401880571919, "compression_ratio": 1.5730994152046784, "no_speech_prob": 0.016624752432107925}, {"id": 16, "seek": 10272, "start": 120.16, "end": 130.0, "text": " life, in your business, in your maybe arts, in different areas of life. And then how AI can", "tokens": [51236, 993, 11, 294, 428, 1606, 11, 294, 428, 1310, 8609, 11, 294, 819, 3179, 295, 993, 13, 400, 550, 577, 7318, 393, 51728], "temperature": 0.0, "avg_logprob": -0.1538401880571919, "compression_ratio": 1.5730994152046784, "no_speech_prob": 0.016624752432107925}, {"id": 17, "seek": 13000, "start": 130.0, "end": 136.64, "text": " help your business. And I will show a lot of practical tools. So the goal and the structure", "tokens": [50364, 854, 428, 1606, 13, 400, 286, 486, 855, 257, 688, 295, 8496, 3873, 13, 407, 264, 3387, 293, 264, 3877, 50696], "temperature": 0.0, "avg_logprob": -0.07736244100205442, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.014888838864862919}, {"id": 18, "seek": 13000, "start": 136.64, "end": 144.88, "text": " of today's workshop is to give a presentation, but most importantly is to show specific use cases,", "tokens": [50696, 295, 965, 311, 13541, 307, 281, 976, 257, 5860, 11, 457, 881, 8906, 307, 281, 855, 2685, 764, 3331, 11, 51108], "temperature": 0.0, "avg_logprob": -0.07736244100205442, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.014888838864862919}, {"id": 19, "seek": 13000, "start": 144.88, "end": 151.04, "text": " how this can be used in practice, because there's a lot of theoretical videos or podcasts or", "tokens": [51108, 577, 341, 393, 312, 1143, 294, 3124, 11, 570, 456, 311, 257, 688, 295, 20864, 2145, 420, 24045, 420, 51416], "temperature": 0.0, "avg_logprob": -0.07736244100205442, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.014888838864862919}, {"id": 20, "seek": 13000, "start": 151.04, "end": 159.12, "text": " articles online. And I'm not here to re-shuffle and repeat what you can already find. I'm here to", "tokens": [51416, 11290, 2950, 13, 400, 286, 478, 406, 510, 281, 319, 12, 2716, 21665, 293, 7149, 437, 291, 393, 1217, 915, 13, 286, 478, 510, 281, 51820], "temperature": 0.0, "avg_logprob": -0.07736244100205442, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.014888838864862919}, {"id": 21, "seek": 15912, "start": 159.12, "end": 166.64000000000001, "text": " actually show some practical application and some use cases that I hope will be useful.", "tokens": [50364, 767, 855, 512, 8496, 3861, 293, 512, 764, 3331, 300, 286, 1454, 486, 312, 4420, 13, 50740], "temperature": 0.0, "avg_logprob": -0.10215889039586802, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.004186579957604408}, {"id": 22, "seek": 15912, "start": 167.84, "end": 175.76, "text": " And with that being said, we can start. So let's talk about why artificial intelligence", "tokens": [50800, 400, 365, 300, 885, 848, 11, 321, 393, 722, 13, 407, 718, 311, 751, 466, 983, 11677, 7599, 51196], "temperature": 0.0, "avg_logprob": -0.10215889039586802, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.004186579957604408}, {"id": 23, "seek": 15912, "start": 175.76, "end": 181.92000000000002, "text": " is important and why everybody is talking about AI right now or at least for the last year since", "tokens": [51196, 307, 1021, 293, 983, 2201, 307, 1417, 466, 7318, 558, 586, 420, 412, 1935, 337, 264, 1036, 1064, 1670, 51504], "temperature": 0.0, "avg_logprob": -0.10215889039586802, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.004186579957604408}, {"id": 24, "seek": 18192, "start": 181.92, "end": 192.0, "text": " Georgia BT came out. In fact, artificial intelligence is quite old and quite old concept", "tokens": [50364, 11859, 31144, 1361, 484, 13, 682, 1186, 11, 11677, 7599, 307, 1596, 1331, 293, 1596, 1331, 3410, 50868], "temperature": 0.0, "avg_logprob": -0.14265811854395374, "compression_ratio": 1.5055555555555555, "no_speech_prob": 0.0625377893447876}, {"id": 25, "seek": 18192, "start": 192.0, "end": 199.51999999999998, "text": " and technology. It has been around for at least as long as digital computing has been around.", "tokens": [50868, 293, 2899, 13, 467, 575, 668, 926, 337, 412, 1935, 382, 938, 382, 4562, 15866, 575, 668, 926, 13, 51244], "temperature": 0.0, "avg_logprob": -0.14265811854395374, "compression_ratio": 1.5055555555555555, "no_speech_prob": 0.0625377893447876}, {"id": 26, "seek": 18192, "start": 199.51999999999998, "end": 206.07999999999998, "text": " The first paper that mentioned the idea of building computation networks inspired by how", "tokens": [51244, 440, 700, 3035, 300, 2835, 264, 1558, 295, 2390, 24903, 9590, 7547, 538, 577, 51572], "temperature": 0.0, "avg_logprob": -0.14265811854395374, "compression_ratio": 1.5055555555555555, "no_speech_prob": 0.0625377893447876}, {"id": 27, "seek": 20608, "start": 206.08, "end": 213.28, "text": " biological systems work, specifically how human brain works was published in 1943. So it's been", "tokens": [50364, 13910, 3652, 589, 11, 4682, 577, 1952, 3567, 1985, 390, 6572, 294, 40402, 13, 407, 309, 311, 668, 50724], "temperature": 0.0, "avg_logprob": -0.1068405650910877, "compression_ratio": 1.5772357723577235, "no_speech_prob": 0.002797722117975354}, {"id": 28, "seek": 20608, "start": 215.12, "end": 223.12, "text": " 80 years of development in artificial intelligence. And the most important, the first seminal paper", "tokens": [50816, 4688, 924, 295, 3250, 294, 11677, 7599, 13, 400, 264, 881, 1021, 11, 264, 700, 4361, 2071, 3035, 51216], "temperature": 0.0, "avg_logprob": -0.1068405650910877, "compression_ratio": 1.5772357723577235, "no_speech_prob": 0.002797722117975354}, {"id": 29, "seek": 20608, "start": 223.12, "end": 228.96, "text": " that you probably heard about was published in 1950 by Alan Turing where he proposed this idea", "tokens": [51216, 300, 291, 1391, 2198, 466, 390, 6572, 294, 18141, 538, 16442, 314, 1345, 689, 415, 10348, 341, 1558, 51508], "temperature": 0.0, "avg_logprob": -0.1068405650910877, "compression_ratio": 1.5772357723577235, "no_speech_prob": 0.002797722117975354}, {"id": 30, "seek": 20608, "start": 228.96, "end": 234.08, "text": " of thinking machines. And this is actually the paper where the concept of Turing test comes from.", "tokens": [51508, 295, 1953, 8379, 13, 400, 341, 307, 767, 264, 3035, 689, 264, 3410, 295, 314, 1345, 1500, 1487, 490, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1068405650910877, "compression_ratio": 1.5772357723577235, "no_speech_prob": 0.002797722117975354}, {"id": 31, "seek": 23408, "start": 234.96, "end": 238.88000000000002, "text": " And over these 80 years, there's been a lot of ups and downs. There have been a lot of", "tokens": [50408, 400, 670, 613, 4688, 924, 11, 456, 311, 668, 257, 688, 295, 15497, 293, 21554, 13, 821, 362, 668, 257, 688, 295, 50604], "temperature": 0.0, "avg_logprob": -0.10753591944662373, "compression_ratio": 1.7023255813953488, "no_speech_prob": 0.001475389115512371}, {"id": 32, "seek": 23408, "start": 238.88000000000002, "end": 246.0, "text": " development, a lot of hopes, a lot of actually things that are now called AI winters, which were", "tokens": [50604, 3250, 11, 257, 688, 295, 13681, 11, 257, 688, 295, 767, 721, 300, 366, 586, 1219, 7318, 1942, 1559, 11, 597, 645, 50960], "temperature": 0.0, "avg_logprob": -0.10753591944662373, "compression_ratio": 1.7023255813953488, "no_speech_prob": 0.001475389115512371}, {"id": 33, "seek": 23408, "start": 246.0, "end": 252.8, "text": " periods, prolonged periods for decades where people thought that there can be no progress made.", "tokens": [50960, 13804, 11, 41237, 13804, 337, 7878, 689, 561, 1194, 300, 456, 393, 312, 572, 4205, 1027, 13, 51300], "temperature": 0.0, "avg_logprob": -0.10753591944662373, "compression_ratio": 1.7023255813953488, "no_speech_prob": 0.001475389115512371}, {"id": 34, "seek": 23408, "start": 252.8, "end": 260.0, "text": " And then it changed from this AI winter to period of a lot of hope and inspiration and", "tokens": [51300, 400, 550, 309, 3105, 490, 341, 7318, 6355, 281, 2896, 295, 257, 688, 295, 1454, 293, 10249, 293, 51660], "temperature": 0.0, "avg_logprob": -0.10753591944662373, "compression_ratio": 1.7023255813953488, "no_speech_prob": 0.001475389115512371}, {"id": 35, "seek": 26000, "start": 260.0, "end": 265.84, "text": " new technological development. And right now we're witnessing one of those periods. And it", "tokens": [50364, 777, 18439, 3250, 13, 400, 558, 586, 321, 434, 39233, 472, 295, 729, 13804, 13, 400, 309, 50656], "temperature": 0.0, "avg_logprob": -0.1387100917537038, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.002750437008216977}, {"id": 36, "seek": 26000, "start": 265.84, "end": 270.16, "text": " seems like it's the biggest one since the invention of the concept of artificial intelligence.", "tokens": [50656, 2544, 411, 309, 311, 264, 3880, 472, 1670, 264, 22265, 295, 264, 3410, 295, 11677, 7599, 13, 50872], "temperature": 0.0, "avg_logprob": -0.1387100917537038, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.002750437008216977}, {"id": 37, "seek": 26000, "start": 270.8, "end": 277.2, "text": " But actually, the whole idea of thinking machines or building something that is built by human but", "tokens": [50904, 583, 767, 11, 264, 1379, 1558, 295, 1953, 8379, 420, 2390, 746, 300, 307, 3094, 538, 1952, 457, 51224], "temperature": 0.0, "avg_logprob": -0.1387100917537038, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.002750437008216977}, {"id": 38, "seek": 26000, "start": 277.2, "end": 287.36, "text": " not, but has ability to think and complete tasks, it comes even from prehistoric times.", "tokens": [51224, 406, 11, 457, 575, 3485, 281, 519, 293, 3566, 9608, 11, 309, 1487, 754, 490, 659, 33236, 16345, 1413, 13, 51732], "temperature": 0.0, "avg_logprob": -0.1387100917537038, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.002750437008216977}, {"id": 39, "seek": 28736, "start": 287.36, "end": 290.96000000000004, "text": " For example, I found this quote, and you probably heard this concept of Golem,", "tokens": [50364, 1171, 1365, 11, 286, 1352, 341, 6513, 11, 293, 291, 1391, 2198, 341, 3410, 295, 1037, 10386, 11, 50544], "temperature": 0.0, "avg_logprob": -0.12376769139216497, "compression_ratio": 1.4301075268817205, "no_speech_prob": 0.005371760576963425}, {"id": 40, "seek": 28736, "start": 290.96000000000004, "end": 298.72, "text": " which is this machine made of clay that people can build and then it would help with different", "tokens": [50544, 597, 307, 341, 3479, 1027, 295, 13517, 300, 561, 393, 1322, 293, 550, 309, 576, 854, 365, 819, 50932], "temperature": 0.0, "avg_logprob": -0.12376769139216497, "compression_ratio": 1.4301075268817205, "no_speech_prob": 0.005371760576963425}, {"id": 41, "seek": 28736, "start": 298.72, "end": 311.6, "text": " tasks. So I found one of mentions from some source from year 500. And I actually did a quick", "tokens": [50932, 9608, 13, 407, 286, 1352, 472, 295, 23844, 490, 512, 4009, 490, 1064, 5923, 13, 400, 286, 767, 630, 257, 1702, 51576], "temperature": 0.0, "avg_logprob": -0.12376769139216497, "compression_ratio": 1.4301075268817205, "no_speech_prob": 0.005371760576963425}, {"id": 42, "seek": 31160, "start": 311.6, "end": 317.68, "text": " experiment. I asked chat GPT and Google Bart, which is one of the chatbots developed by Google,", "tokens": [50364, 5120, 13, 286, 2351, 5081, 26039, 51, 293, 3329, 22338, 11, 597, 307, 472, 295, 264, 5081, 65, 1971, 4743, 538, 3329, 11, 50668], "temperature": 0.0, "avg_logprob": -0.12950831043476962, "compression_ratio": 1.7227272727272727, "no_speech_prob": 0.10051775723695755}, {"id": 43, "seek": 31160, "start": 318.24, "end": 323.12, "text": " what do they think? Are they golems? And this is what I got. This is the response that I got from", "tokens": [50696, 437, 360, 436, 519, 30, 2014, 436, 352, 306, 2592, 30, 400, 341, 307, 437, 286, 658, 13, 639, 307, 264, 4134, 300, 286, 658, 490, 50940], "temperature": 0.0, "avg_logprob": -0.12950831043476962, "compression_ratio": 1.7227272727272727, "no_speech_prob": 0.10051775723695755}, {"id": 44, "seek": 31160, "start": 323.76000000000005, "end": 328.40000000000003, "text": " Google Bart. It says that in some sense, it is possible to view me as a golem. This is the", "tokens": [50972, 3329, 22338, 13, 467, 1619, 300, 294, 512, 2020, 11, 309, 307, 1944, 281, 1910, 385, 382, 257, 352, 10386, 13, 639, 307, 264, 51204], "temperature": 0.0, "avg_logprob": -0.12950831043476962, "compression_ratio": 1.7227272727272727, "no_speech_prob": 0.10051775723695755}, {"id": 45, "seek": 31160, "start": 328.40000000000003, "end": 333.92, "text": " response that Google artificial intelligence is giving. And it is actually giving a comparison", "tokens": [51204, 4134, 300, 3329, 11677, 7599, 307, 2902, 13, 400, 309, 307, 767, 2902, 257, 9660, 51480], "temperature": 0.0, "avg_logprob": -0.12950831043476962, "compression_ratio": 1.7227272727272727, "no_speech_prob": 0.10051775723695755}, {"id": 46, "seek": 33392, "start": 334.88, "end": 344.88, "text": " between Bart and Golem and different areas. Can it learn? Can it grow? It actually outperforms", "tokens": [50412, 1296, 22338, 293, 1037, 10386, 293, 819, 3179, 13, 1664, 309, 1466, 30, 1664, 309, 1852, 30, 467, 767, 484, 26765, 82, 50912], "temperature": 0.0, "avg_logprob": -0.13854738594829172, "compression_ratio": 1.4300518134715026, "no_speech_prob": 0.015374819748103619}, {"id": 47, "seek": 33392, "start": 344.88, "end": 353.04, "text": " this concept of mystical, magical creature of a Golem. And I have links to both chat GPT and Bart", "tokens": [50912, 341, 3410, 295, 40565, 11, 12066, 12797, 295, 257, 1037, 10386, 13, 400, 286, 362, 6123, 281, 1293, 5081, 26039, 51, 293, 22338, 51320], "temperature": 0.0, "avg_logprob": -0.13854738594829172, "compression_ratio": 1.4300518134715026, "no_speech_prob": 0.015374819748103619}, {"id": 48, "seek": 33392, "start": 353.04, "end": 357.6, "text": " here if you want to ask them the same question or maybe continue that conversation.", "tokens": [51320, 510, 498, 291, 528, 281, 1029, 552, 264, 912, 1168, 420, 1310, 2354, 300, 3761, 13, 51548], "temperature": 0.0, "avg_logprob": -0.13854738594829172, "compression_ratio": 1.4300518134715026, "no_speech_prob": 0.015374819748103619}, {"id": 49, "seek": 35760, "start": 357.6, "end": 366.56, "text": " But today, artificial intelligence is a very practical thing. And it is being used across", "tokens": [50364, 583, 965, 11, 11677, 7599, 307, 257, 588, 8496, 551, 13, 400, 309, 307, 885, 1143, 2108, 50812], "temperature": 0.0, "avg_logprob": -0.13233473459879558, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.010955071076750755}, {"id": 50, "seek": 35760, "start": 366.56, "end": 374.40000000000003, "text": " all different areas of economy. And the first important thing to understand about AI is that", "tokens": [50812, 439, 819, 3179, 295, 5010, 13, 400, 264, 700, 1021, 551, 281, 1223, 466, 7318, 307, 300, 51204], "temperature": 0.0, "avg_logprob": -0.13233473459879558, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.010955071076750755}, {"id": 51, "seek": 35760, "start": 374.40000000000003, "end": 380.16, "text": " AI is GPT. GPT stands for general purpose technology, which means that artificial", "tokens": [51204, 7318, 307, 26039, 51, 13, 26039, 51, 7382, 337, 2674, 4334, 2899, 11, 597, 1355, 300, 11677, 51492], "temperature": 0.0, "avg_logprob": -0.13233473459879558, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.010955071076750755}, {"id": 52, "seek": 35760, "start": 380.16, "end": 386.08000000000004, "text": " intelligence is one of those technologies similar to maybe steam engine or electricity,", "tokens": [51492, 7599, 307, 472, 295, 729, 7943, 2531, 281, 1310, 11952, 2848, 420, 10356, 11, 51788], "temperature": 0.0, "avg_logprob": -0.13233473459879558, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.010955071076750755}, {"id": 53, "seek": 38608, "start": 386.47999999999996, "end": 392.24, "text": " or internet, which powers all different areas of economics and all different areas of society.", "tokens": [50384, 420, 4705, 11, 597, 8674, 439, 819, 3179, 295, 14564, 293, 439, 819, 3179, 295, 4086, 13, 50672], "temperature": 0.0, "avg_logprob": -0.12587429641129136, "compression_ratio": 1.7282051282051283, "no_speech_prob": 0.0021103029139339924}, {"id": 54, "seek": 38608, "start": 392.24, "end": 396.24, "text": " And there are a lot of applications in healthcare, in education, in business,", "tokens": [50672, 400, 456, 366, 257, 688, 295, 5821, 294, 8884, 11, 294, 3309, 11, 294, 1606, 11, 50872], "temperature": 0.0, "avg_logprob": -0.12587429641129136, "compression_ratio": 1.7282051282051283, "no_speech_prob": 0.0021103029139339924}, {"id": 55, "seek": 38608, "start": 396.24, "end": 401.84, "text": " in manufacturing, in any industry, you name it, arts, culture, and so on.", "tokens": [50872, 294, 11096, 11, 294, 604, 3518, 11, 291, 1315, 309, 11, 8609, 11, 3713, 11, 293, 370, 322, 13, 51152], "temperature": 0.0, "avg_logprob": -0.12587429641129136, "compression_ratio": 1.7282051282051283, "no_speech_prob": 0.0021103029139339924}, {"id": 56, "seek": 38608, "start": 403.36, "end": 409.36, "text": " And because artificial intelligence has been around, there are a lot of different branches", "tokens": [51228, 400, 570, 11677, 7599, 575, 668, 926, 11, 456, 366, 257, 688, 295, 819, 14770, 51528], "temperature": 0.0, "avg_logprob": -0.12587429641129136, "compression_ratio": 1.7282051282051283, "no_speech_prob": 0.0021103029139339924}, {"id": 57, "seek": 40936, "start": 409.36, "end": 416.24, "text": " and flavors of AI. And what most people are talking about today, which is GPT,", "tokens": [50364, 293, 16303, 295, 7318, 13, 400, 437, 881, 561, 366, 1417, 466, 965, 11, 597, 307, 26039, 51, 11, 50708], "temperature": 0.0, "avg_logprob": -0.12551066454719095, "compression_ratio": 1.453781512605042, "no_speech_prob": 0.018217284232378006}, {"id": 58, "seek": 40936, "start": 416.24, "end": 422.48, "text": " chatbots, large language models, is relatively new. This area has been created maybe four or", "tokens": [50708, 5081, 65, 1971, 11, 2416, 2856, 5245, 11, 307, 7226, 777, 13, 639, 1859, 575, 668, 2942, 1310, 1451, 420, 51020], "temperature": 0.0, "avg_logprob": -0.12551066454719095, "compression_ratio": 1.453781512605042, "no_speech_prob": 0.018217284232378006}, {"id": 59, "seek": 40936, "start": 422.48, "end": 430.72, "text": " five years ago. It started in 2017 with the paper called, Attention is All You Need,", "tokens": [51020, 1732, 924, 2057, 13, 467, 1409, 294, 6591, 365, 264, 3035, 1219, 11, 31858, 307, 1057, 509, 16984, 11, 51432], "temperature": 0.0, "avg_logprob": -0.12551066454719095, "compression_ratio": 1.453781512605042, "no_speech_prob": 0.018217284232378006}, {"id": 60, "seek": 40936, "start": 430.72, "end": 436.72, "text": " but real products are actually being developed just for the past three or four years. And", "tokens": [51432, 457, 957, 3383, 366, 767, 885, 4743, 445, 337, 264, 1791, 1045, 420, 1451, 924, 13, 400, 51732], "temperature": 0.0, "avg_logprob": -0.12551066454719095, "compression_ratio": 1.453781512605042, "no_speech_prob": 0.018217284232378006}, {"id": 61, "seek": 43672, "start": 436.72, "end": 442.24, "text": " generative AI is relatively small. So for example, the other areas of artificial intelligence,", "tokens": [50364, 1337, 1166, 7318, 307, 7226, 1359, 13, 407, 337, 1365, 11, 264, 661, 3179, 295, 11677, 7599, 11, 50640], "temperature": 0.0, "avg_logprob": -0.13881991969214547, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.0018045470351353288}, {"id": 62, "seek": 43672, "start": 443.20000000000005, "end": 448.88000000000005, "text": " something like supervised learning or reinforcement learning is used in very practical", "tokens": [50688, 746, 411, 46533, 2539, 420, 29280, 2539, 307, 1143, 294, 588, 8496, 50972], "temperature": 0.0, "avg_logprob": -0.13881991969214547, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.0018045470351353288}, {"id": 63, "seek": 43672, "start": 448.88000000000005, "end": 453.92, "text": " applications as well. For example, in digital advertising, Google and Facebook and Twitter,", "tokens": [50972, 5821, 382, 731, 13, 1171, 1365, 11, 294, 4562, 13097, 11, 3329, 293, 4384, 293, 5794, 11, 51224], "temperature": 0.0, "avg_logprob": -0.13881991969214547, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.0018045470351353288}, {"id": 64, "seek": 43672, "start": 453.92, "end": 460.88000000000005, "text": " all their advertisement recommendation system works using AI or self-driving cars or maybe", "tokens": [51224, 439, 641, 31370, 11879, 1185, 1985, 1228, 7318, 420, 2698, 12, 47094, 5163, 420, 1310, 51572], "temperature": 0.0, "avg_logprob": -0.13881991969214547, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.0018045470351353288}, {"id": 65, "seek": 46088, "start": 460.96, "end": 468.24, "text": " trading systems. So today, we're not going to talk about all of different applications of the AI", "tokens": [50368, 9529, 3652, 13, 407, 965, 11, 321, 434, 406, 516, 281, 751, 466, 439, 295, 819, 5821, 295, 264, 7318, 50732], "temperature": 0.0, "avg_logprob": -0.09710382532190394, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.001866776030510664}, {"id": 66, "seek": 46088, "start": 468.24, "end": 475.92, "text": " because it takes a whole university course to study that. We're going to focus on actually", "tokens": [50732, 570, 309, 2516, 257, 1379, 5454, 1164, 281, 2979, 300, 13, 492, 434, 516, 281, 1879, 322, 767, 51116], "temperature": 0.0, "avg_logprob": -0.09710382532190394, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.001866776030510664}, {"id": 67, "seek": 46088, "start": 475.92, "end": 482.24, "text": " generative AI, at least most recent and the fastest growing areas and branch of artificial", "tokens": [51116, 1337, 1166, 7318, 11, 412, 1935, 881, 5162, 293, 264, 14573, 4194, 3179, 293, 9819, 295, 11677, 51432], "temperature": 0.0, "avg_logprob": -0.09710382532190394, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.001866776030510664}, {"id": 68, "seek": 46088, "start": 482.24, "end": 489.68, "text": " intelligence. And generative AI is all these different products and technologies that you hear", "tokens": [51432, 7599, 13, 400, 1337, 1166, 7318, 307, 439, 613, 819, 3383, 293, 7943, 300, 291, 1568, 51804], "temperature": 0.0, "avg_logprob": -0.09710382532190394, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.001866776030510664}, {"id": 69, "seek": 48968, "start": 490.48, "end": 499.52, "text": " when you hear about chatbots, large language models. One of the most popular examples is", "tokens": [50404, 562, 291, 1568, 466, 5081, 65, 1971, 11, 2416, 2856, 5245, 13, 1485, 295, 264, 881, 3743, 5110, 307, 50856], "temperature": 0.0, "avg_logprob": -0.17853246976251472, "compression_ratio": 1.469945355191257, "no_speech_prob": 0.001263560843653977}, {"id": 70, "seek": 48968, "start": 499.52, "end": 506.0, "text": " chat GPT. There's also a lot of different chatbots, one by Facebook called Lama, one by Google,", "tokens": [50856, 5081, 26039, 51, 13, 821, 311, 611, 257, 688, 295, 819, 5081, 65, 1971, 11, 472, 538, 4384, 1219, 441, 2404, 11, 472, 538, 3329, 11, 51180], "temperature": 0.0, "avg_logprob": -0.17853246976251472, "compression_ratio": 1.469945355191257, "no_speech_prob": 0.001263560843653977}, {"id": 71, "seek": 48968, "start": 506.0, "end": 513.36, "text": " called Bart, one by Entropic, and then there's a few hundreds of products like this.", "tokens": [51180, 1219, 22338, 11, 472, 538, 3951, 39173, 11, 293, 550, 456, 311, 257, 1326, 6779, 295, 3383, 411, 341, 13, 51548], "temperature": 0.0, "avg_logprob": -0.17853246976251472, "compression_ratio": 1.469945355191257, "no_speech_prob": 0.001263560843653977}, {"id": 72, "seek": 51336, "start": 514.32, "end": 519.04, "text": " In addition to large language models, there are also diffusion models, which are", "tokens": [50412, 682, 4500, 281, 2416, 2856, 5245, 11, 456, 366, 611, 25242, 5245, 11, 597, 366, 50648], "temperature": 0.0, "avg_logprob": -0.13905663717360722, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.019711239263415337}, {"id": 73, "seek": 51336, "start": 519.92, "end": 526.88, "text": " tools that allow us to, so large language models, how they work, they are creating text.", "tokens": [50692, 3873, 300, 2089, 505, 281, 11, 370, 2416, 2856, 5245, 11, 577, 436, 589, 11, 436, 366, 4084, 2487, 13, 51040], "temperature": 0.0, "avg_logprob": -0.13905663717360722, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.019711239263415337}, {"id": 74, "seek": 51336, "start": 526.88, "end": 533.44, "text": " You ask them question or you give them prompt and they generate text. So they're really the", "tokens": [51040, 509, 1029, 552, 1168, 420, 291, 976, 552, 12391, 293, 436, 8460, 2487, 13, 407, 436, 434, 534, 264, 51368], "temperature": 0.0, "avg_logprob": -0.13905663717360722, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.019711239263415337}, {"id": 75, "seek": 51336, "start": 533.44, "end": 540.4, "text": " principle of how they work is very simple. They just generate a next word in the sentence. And", "tokens": [51368, 8665, 295, 577, 436, 589, 307, 588, 2199, 13, 814, 445, 8460, 257, 958, 1349, 294, 264, 8174, 13, 400, 51716], "temperature": 0.0, "avg_logprob": -0.13905663717360722, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.019711239263415337}, {"id": 76, "seek": 54040, "start": 541.28, "end": 547.6, "text": " because they're so complex and so smart and they use so much data when they've been trained,", "tokens": [50408, 570, 436, 434, 370, 3997, 293, 370, 4069, 293, 436, 764, 370, 709, 1412, 562, 436, 600, 668, 8895, 11, 50724], "temperature": 0.0, "avg_logprob": -0.14852013748683288, "compression_ratio": 1.599078341013825, "no_speech_prob": 0.0005701806512661278}, {"id": 77, "seek": 54040, "start": 548.4, "end": 553.36, "text": " when they have been trained, in order to generate the next word in the sentence,", "tokens": [50764, 562, 436, 362, 668, 8895, 11, 294, 1668, 281, 8460, 264, 958, 1349, 294, 264, 8174, 11, 51012], "temperature": 0.0, "avg_logprob": -0.14852013748683288, "compression_ratio": 1.599078341013825, "no_speech_prob": 0.0005701806512661278}, {"id": 78, "seek": 54040, "start": 553.36, "end": 562.3199999999999, "text": " they had to learn the whole world model. So if you ask chat GPT who is like, I don't know,", "tokens": [51012, 436, 632, 281, 1466, 264, 1379, 1002, 2316, 13, 407, 498, 291, 1029, 5081, 26039, 51, 567, 307, 411, 11, 286, 500, 380, 458, 11, 51460], "temperature": 0.0, "avg_logprob": -0.14852013748683288, "compression_ratio": 1.599078341013825, "no_speech_prob": 0.0005701806512661278}, {"id": 79, "seek": 54040, "start": 563.92, "end": 570.0799999999999, "text": " 46 president of the United States of America, it will give you the correct answer.", "tokens": [51540, 17835, 3868, 295, 264, 2824, 3040, 295, 3374, 11, 309, 486, 976, 291, 264, 3006, 1867, 13, 51848], "temperature": 0.0, "avg_logprob": -0.14852013748683288, "compression_ratio": 1.599078341013825, "no_speech_prob": 0.0005701806512661278}, {"id": 80, "seek": 57008, "start": 570.08, "end": 574.64, "text": " But to give that answer, in order to give that answer, it had to learn a lot of things. What", "tokens": [50364, 583, 281, 976, 300, 1867, 11, 294, 1668, 281, 976, 300, 1867, 11, 309, 632, 281, 1466, 257, 688, 295, 721, 13, 708, 50592], "temperature": 0.0, "avg_logprob": -0.07449734413017661, "compression_ratio": 1.880952380952381, "no_speech_prob": 0.0017257502768188715}, {"id": 81, "seek": 57008, "start": 574.64, "end": 579.2, "text": " is US? What is the president? What is politics? What is election cycle? And it knows all these", "tokens": [50592, 307, 2546, 30, 708, 307, 264, 3868, 30, 708, 307, 7341, 30, 708, 307, 6618, 6586, 30, 400, 309, 3255, 439, 613, 50820], "temperature": 0.0, "avg_logprob": -0.07449734413017661, "compression_ratio": 1.880952380952381, "no_speech_prob": 0.0017257502768188715}, {"id": 82, "seek": 57008, "start": 579.2, "end": 584.72, "text": " concepts and those concepts are stored inside the model. And this is why it seems to be so smart", "tokens": [50820, 10392, 293, 729, 10392, 366, 12187, 1854, 264, 2316, 13, 400, 341, 307, 983, 309, 2544, 281, 312, 370, 4069, 51096], "temperature": 0.0, "avg_logprob": -0.07449734413017661, "compression_ratio": 1.880952380952381, "no_speech_prob": 0.0017257502768188715}, {"id": 83, "seek": 57008, "start": 584.72, "end": 589.9200000000001, "text": " and this is actually, and this is why it is actually useful in a lot of business and personal", "tokens": [51096, 293, 341, 307, 767, 11, 293, 341, 307, 983, 309, 307, 767, 4420, 294, 257, 688, 295, 1606, 293, 2973, 51356], "temperature": 0.0, "avg_logprob": -0.07449734413017661, "compression_ratio": 1.880952380952381, "no_speech_prob": 0.0017257502768188715}, {"id": 84, "seek": 57008, "start": 589.9200000000001, "end": 598.5600000000001, "text": " tasks. Diffusion models are models that are able to generate pictures and video. And one of the", "tokens": [51356, 9608, 13, 413, 3661, 5704, 5245, 366, 5245, 300, 366, 1075, 281, 8460, 5242, 293, 960, 13, 400, 472, 295, 264, 51788], "temperature": 0.0, "avg_logprob": -0.07449734413017661, "compression_ratio": 1.880952380952381, "no_speech_prob": 0.0017257502768188715}, {"id": 85, "seek": 59856, "start": 598.56, "end": 606.7199999999999, "text": " most popular examples of such products is mid-journey and also Dali tool or stable diffusion.", "tokens": [50364, 881, 3743, 5110, 295, 1270, 3383, 307, 2062, 12, 8696, 2397, 293, 611, 413, 5103, 2290, 420, 8351, 25242, 13, 50772], "temperature": 0.0, "avg_logprob": -0.188466367267427, "compression_ratio": 1.6194690265486726, "no_speech_prob": 0.007333524525165558}, {"id": 86, "seek": 59856, "start": 606.7199999999999, "end": 613.3599999999999, "text": " Also a lot of products, all applications in app store or internet that can create you AI photo", "tokens": [50772, 2743, 257, 688, 295, 3383, 11, 439, 5821, 294, 724, 3531, 420, 4705, 300, 393, 1884, 291, 7318, 5052, 51104], "temperature": 0.0, "avg_logprob": -0.188466367267427, "compression_ratio": 1.6194690265486726, "no_speech_prob": 0.007333524525165558}, {"id": 87, "seek": 59856, "start": 613.3599999999999, "end": 621.5999999999999, "text": " or AI stylization, most of them, they use this concept of diffusion. They're based on", "tokens": [51104, 420, 7318, 23736, 2144, 11, 881, 295, 552, 11, 436, 764, 341, 3410, 295, 25242, 13, 814, 434, 2361, 322, 51516], "temperature": 0.0, "avg_logprob": -0.188466367267427, "compression_ratio": 1.6194690265486726, "no_speech_prob": 0.007333524525165558}, {"id": 88, "seek": 59856, "start": 621.5999999999999, "end": 627.1199999999999, "text": " diffusion neural networks and diffusion models. But also in addition to language models and", "tokens": [51516, 25242, 18161, 9590, 293, 25242, 5245, 13, 583, 611, 294, 4500, 281, 2856, 5245, 293, 51792], "temperature": 0.0, "avg_logprob": -0.188466367267427, "compression_ratio": 1.6194690265486726, "no_speech_prob": 0.007333524525165558}, {"id": 89, "seek": 62712, "start": 627.12, "end": 632.88, "text": " diffusion models, there's a lot of smaller but no less important applications such as speech", "tokens": [50364, 25242, 5245, 11, 456, 311, 257, 688, 295, 4356, 457, 572, 1570, 1021, 5821, 1270, 382, 6218, 50652], "temperature": 0.0, "avg_logprob": -0.11332296556042086, "compression_ratio": 1.5, "no_speech_prob": 0.002585663227364421}, {"id": 90, "seek": 62712, "start": 632.88, "end": 641.6, "text": " recognition, voice synthesis, music generation, creation of 3D art or 3D objects for video games,", "tokens": [50652, 11150, 11, 3177, 30252, 11, 1318, 5125, 11, 8016, 295, 805, 35, 1523, 420, 805, 35, 6565, 337, 960, 2813, 11, 51088], "temperature": 0.0, "avg_logprob": -0.11332296556042086, "compression_ratio": 1.5, "no_speech_prob": 0.002585663227364421}, {"id": 91, "seek": 62712, "start": 642.16, "end": 647.44, "text": " and many more, including very, very, very narrow and very specific ones like", "tokens": [51116, 293, 867, 544, 11, 3009, 588, 11, 588, 11, 588, 9432, 293, 588, 2685, 2306, 411, 51380], "temperature": 0.0, "avg_logprob": -0.11332296556042086, "compression_ratio": 1.5, "no_speech_prob": 0.002585663227364421}, {"id": 92, "seek": 64744, "start": 648.32, "end": 659.84, "text": " generation of proteins for pharma companies or designing chips for computer chip manufacturing", "tokens": [50408, 5125, 295, 15577, 337, 903, 36159, 3431, 420, 14685, 11583, 337, 3820, 11409, 11096, 50984], "temperature": 0.0, "avg_logprob": -0.1434014638264974, "compression_ratio": 1.3875968992248062, "no_speech_prob": 0.010956712998449802}, {"id": 93, "seek": 64744, "start": 659.84, "end": 671.6800000000001, "text": " companies. So how is, I want to talk about economics of AI. So I will be using a few", "tokens": [50984, 3431, 13, 407, 577, 307, 11, 286, 528, 281, 751, 466, 14564, 295, 7318, 13, 407, 286, 486, 312, 1228, 257, 1326, 51576], "temperature": 0.0, "avg_logprob": -0.1434014638264974, "compression_ratio": 1.3875968992248062, "no_speech_prob": 0.010956712998449802}, {"id": 94, "seek": 67168, "start": 671.92, "end": 682.7199999999999, "text": " cited and popular and well done research papers to show just some of the statistics.", "tokens": [50376, 30134, 293, 3743, 293, 731, 1096, 2132, 10577, 281, 855, 445, 512, 295, 264, 12523, 13, 50916], "temperature": 0.0, "avg_logprob": -0.18290808663439395, "compression_ratio": 1.4404145077720207, "no_speech_prob": 0.00924292579293251}, {"id": 95, "seek": 67168, "start": 683.28, "end": 690.2399999999999, "text": " So this one is a report created by McKinsey, published about four months ago. And what they", "tokens": [50944, 407, 341, 472, 307, 257, 2275, 2942, 538, 21765, 259, 7399, 11, 6572, 466, 1451, 2493, 2057, 13, 400, 437, 436, 51292], "temperature": 0.0, "avg_logprob": -0.18290808663439395, "compression_ratio": 1.4404145077720207, "no_speech_prob": 0.00924292579293251}, {"id": 96, "seek": 67168, "start": 690.9599999999999, "end": 699.1999999999999, "text": " came up with in that report is that generative AI could deliver a total value of 4.4 trillion dollars", "tokens": [51328, 1361, 493, 365, 294, 300, 2275, 307, 300, 1337, 1166, 7318, 727, 4239, 257, 3217, 2158, 295, 1017, 13, 19, 18723, 3808, 51740], "temperature": 0.0, "avg_logprob": -0.18290808663439395, "compression_ratio": 1.4404145077720207, "no_speech_prob": 0.00924292579293251}, {"id": 97, "seek": 69920, "start": 700.1600000000001, "end": 708.08, "text": " in economics from new use cases. So these are only new use cases that are being unlocked", "tokens": [50412, 294, 14564, 490, 777, 764, 3331, 13, 407, 613, 366, 787, 777, 764, 3331, 300, 366, 885, 30180, 50808], "temperature": 0.0, "avg_logprob": -0.1148148846913533, "compression_ratio": 1.6331877729257642, "no_speech_prob": 0.004321093671023846}, {"id": 98, "seek": 69920, "start": 708.08, "end": 713.6800000000001, "text": " by this new technology. But also in addition to that, there's also eight trillion dollars annually.", "tokens": [50808, 538, 341, 777, 2899, 13, 583, 611, 294, 4500, 281, 300, 11, 456, 311, 611, 3180, 18723, 3808, 29974, 13, 51088], "temperature": 0.0, "avg_logprob": -0.1148148846913533, "compression_ratio": 1.6331877729257642, "no_speech_prob": 0.004321093671023846}, {"id": 99, "seek": 69920, "start": 713.6800000000001, "end": 719.44, "text": " So we are talking about annual GDP growth that can be gained through productivity increase", "tokens": [51088, 407, 321, 366, 1417, 466, 9784, 19599, 4599, 300, 393, 312, 12634, 807, 15604, 3488, 51376], "temperature": 0.0, "avg_logprob": -0.1148148846913533, "compression_ratio": 1.6331877729257642, "no_speech_prob": 0.004321093671023846}, {"id": 100, "seek": 69920, "start": 719.44, "end": 725.6800000000001, "text": " by workers that they use AI or businesses that they use AI in their existing tasks. And on the", "tokens": [51376, 538, 5600, 300, 436, 764, 7318, 420, 6011, 300, 436, 764, 7318, 294, 641, 6741, 9608, 13, 400, 322, 264, 51688], "temperature": 0.0, "avg_logprob": -0.1148148846913533, "compression_ratio": 1.6331877729257642, "no_speech_prob": 0.004321093671023846}, {"id": 101, "seek": 72568, "start": 725.68, "end": 735.1999999999999, "text": " right, there are, this graph shows impact in terms of billions of dollars in different areas", "tokens": [50364, 558, 11, 456, 366, 11, 341, 4295, 3110, 2712, 294, 2115, 295, 17375, 295, 3808, 294, 819, 3179, 50840], "temperature": 0.0, "avg_logprob": -0.1309361630175487, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.003269978566095233}, {"id": 102, "seek": 72568, "start": 735.1999999999999, "end": 740.8, "text": " of business. So you can, as you can see, sales, marketing, software engineering, customer operations,", "tokens": [50840, 295, 1606, 13, 407, 291, 393, 11, 382, 291, 393, 536, 11, 5763, 11, 6370, 11, 4722, 7043, 11, 5474, 7705, 11, 51120], "temperature": 0.0, "avg_logprob": -0.1309361630175487, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.003269978566095233}, {"id": 103, "seek": 72568, "start": 740.8, "end": 747.92, "text": " products are areas that will benefit the most from implementation and use and leverage of", "tokens": [51120, 3383, 366, 3179, 300, 486, 5121, 264, 881, 490, 11420, 293, 764, 293, 13982, 295, 51476], "temperature": 0.0, "avg_logprob": -0.1309361630175487, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.003269978566095233}, {"id": 104, "seek": 72568, "start": 747.92, "end": 755.28, "text": " artificial intelligence, but also all these other areas like legal or HR or procurement or finance,", "tokens": [51476, 11677, 7599, 11, 457, 611, 439, 613, 661, 3179, 411, 5089, 420, 19460, 420, 35183, 420, 10719, 11, 51844], "temperature": 0.0, "avg_logprob": -0.1309361630175487, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.003269978566095233}, {"id": 105, "seek": 75528, "start": 755.28, "end": 761.36, "text": " there's also quite a few of very practical applications and I will cover some of those later.", "tokens": [50364, 456, 311, 611, 1596, 257, 1326, 295, 588, 8496, 5821, 293, 286, 486, 2060, 512, 295, 729, 1780, 13, 50668], "temperature": 0.0, "avg_logprob": -0.09663309485225355, "compression_ratio": 1.5106382978723405, "no_speech_prob": 0.0002777397457975894}, {"id": 106, "seek": 75528, "start": 764.3199999999999, "end": 772.72, "text": " And from the same report and another interesting piece of statistics, what they came up with", "tokens": [50816, 400, 490, 264, 912, 2275, 293, 1071, 1880, 2522, 295, 12523, 11, 437, 436, 1361, 493, 365, 51236], "temperature": 0.0, "avg_logprob": -0.09663309485225355, "compression_ratio": 1.5106382978723405, "no_speech_prob": 0.0002777397457975894}, {"id": 107, "seek": 75528, "start": 772.72, "end": 779.36, "text": " is that current generative AI technologies have potential to automate work activities that absorb", "tokens": [51236, 307, 300, 2190, 1337, 1166, 7318, 7943, 362, 3995, 281, 31605, 589, 5354, 300, 15631, 51568], "temperature": 0.0, "avg_logprob": -0.09663309485225355, "compression_ratio": 1.5106382978723405, "no_speech_prob": 0.0002777397457975894}, {"id": 108, "seek": 77936, "start": 779.36, "end": 785.04, "text": " 60 to 80 percent of employees' time today. It doesn't apply to all existing occupations and", "tokens": [50364, 4060, 281, 4688, 3043, 295, 6619, 6, 565, 965, 13, 467, 1177, 380, 3079, 281, 439, 6741, 8073, 763, 293, 50648], "temperature": 0.0, "avg_logprob": -0.14070468002490782, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.01638750731945038}, {"id": 109, "seek": 77936, "start": 785.04, "end": 792.4, "text": " professions, but for highly qualified office workers, this can be a huge time saving. And", "tokens": [50648, 38129, 11, 457, 337, 5405, 15904, 3398, 5600, 11, 341, 393, 312, 257, 2603, 565, 6816, 13, 400, 51016], "temperature": 0.0, "avg_logprob": -0.14070468002490782, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.01638750731945038}, {"id": 110, "seek": 77936, "start": 792.4, "end": 797.6800000000001, "text": " this is, this stats is based just on existing level of technology. It doesn't take into account", "tokens": [51016, 341, 307, 11, 341, 18152, 307, 2361, 445, 322, 6741, 1496, 295, 2899, 13, 467, 1177, 380, 747, 666, 2696, 51280], "temperature": 0.0, "avg_logprob": -0.14070468002490782, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.01638750731945038}, {"id": 111, "seek": 77936, "start": 797.6800000000001, "end": 803.04, "text": " that in the future, the technology will evolve. And we are seeing that the growth, the speed of", "tokens": [51280, 300, 294, 264, 2027, 11, 264, 2899, 486, 16693, 13, 400, 321, 366, 2577, 300, 264, 4599, 11, 264, 3073, 295, 51548], "temperature": 0.0, "avg_logprob": -0.14070468002490782, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.01638750731945038}, {"id": 112, "seek": 80304, "start": 803.04, "end": 811.8399999999999, "text": " growth and speed of development of AI is staggering. It's huge. Another report, and I also have a link", "tokens": [50364, 4599, 293, 3073, 295, 3250, 295, 7318, 307, 42974, 13, 467, 311, 2603, 13, 3996, 2275, 11, 293, 286, 611, 362, 257, 2113, 50804], "temperature": 0.0, "avg_logprob": -0.14096293666146018, "compression_ratio": 1.534412955465587, "no_speech_prob": 0.005815957672894001}, {"id": 113, "seek": 80304, "start": 811.8399999999999, "end": 820.0799999999999, "text": " down here below, from University of Pennsylvania, it shows that 80 percent of U.S. workforce will", "tokens": [50804, 760, 510, 2507, 11, 490, 3535, 295, 17963, 11, 309, 3110, 300, 4688, 3043, 295, 624, 13, 50, 13, 14201, 486, 51216], "temperature": 0.0, "avg_logprob": -0.14096293666146018, "compression_ratio": 1.534412955465587, "no_speech_prob": 0.005815957672894001}, {"id": 114, "seek": 80304, "start": 820.0799999999999, "end": 825.8399999999999, "text": " have at least 10 percent of their daily tasks exposed or automated by large language models.", "tokens": [51216, 362, 412, 1935, 1266, 3043, 295, 641, 5212, 9608, 9495, 420, 18473, 538, 2416, 2856, 5245, 13, 51504], "temperature": 0.0, "avg_logprob": -0.14096293666146018, "compression_ratio": 1.534412955465587, "no_speech_prob": 0.005815957672894001}, {"id": 115, "seek": 80304, "start": 826.4, "end": 832.56, "text": " And this does not only apply to the United States, this generally applies to any work", "tokens": [51532, 400, 341, 775, 406, 787, 3079, 281, 264, 2824, 3040, 11, 341, 5101, 13165, 281, 604, 589, 51840], "temperature": 0.0, "avg_logprob": -0.14096293666146018, "compression_ratio": 1.534412955465587, "no_speech_prob": 0.005815957672894001}, {"id": 116, "seek": 83256, "start": 832.56, "end": 841.8399999999999, "text": " that is characteristic to developed economy, which is service and office workers. So that means that", "tokens": [50364, 300, 307, 16282, 281, 4743, 5010, 11, 597, 307, 2643, 293, 3398, 5600, 13, 407, 300, 1355, 300, 50828], "temperature": 0.0, "avg_logprob": -0.1282822879744165, "compression_ratio": 1.7339449541284404, "no_speech_prob": 0.000587614020332694}, {"id": 117, "seek": 83256, "start": 841.8399999999999, "end": 848.0, "text": " most of the economy, most of the developed economy will have at least some, at least 10 percent", "tokens": [50828, 881, 295, 264, 5010, 11, 881, 295, 264, 4743, 5010, 486, 362, 412, 1935, 512, 11, 412, 1935, 1266, 3043, 51136], "temperature": 0.0, "avg_logprob": -0.1282822879744165, "compression_ratio": 1.7339449541284404, "no_speech_prob": 0.000587614020332694}, {"id": 118, "seek": 83256, "start": 848.7199999999999, "end": 854.7199999999999, "text": " of exposure to large language models and that will lead to automation and economic boost,", "tokens": [51172, 295, 10420, 281, 2416, 2856, 5245, 293, 300, 486, 1477, 281, 17769, 293, 4836, 9194, 11, 51472], "temperature": 0.0, "avg_logprob": -0.1282822879744165, "compression_ratio": 1.7339449541284404, "no_speech_prob": 0.000587614020332694}, {"id": 119, "seek": 83256, "start": 854.7199999999999, "end": 861.92, "text": " boosting economic productivity. Another report by Gartner where they say that 30 percent of", "tokens": [51472, 43117, 4836, 15604, 13, 3996, 2275, 538, 460, 446, 1193, 689, 436, 584, 300, 2217, 3043, 295, 51832], "temperature": 0.0, "avg_logprob": -0.1282822879744165, "compression_ratio": 1.7339449541284404, "no_speech_prob": 0.000587614020332694}, {"id": 120, "seek": 86192, "start": 861.92, "end": 868.88, "text": " outbound tasks, marketing messages will be generated by large language models, will be", "tokens": [50364, 484, 18767, 9608, 11, 6370, 7897, 486, 312, 10833, 538, 2416, 2856, 5245, 11, 486, 312, 50712], "temperature": 0.0, "avg_logprob": -0.13563603793873508, "compression_ratio": 1.6473214285714286, "no_speech_prob": 0.0020177054684609175}, {"id": 121, "seek": 86192, "start": 868.88, "end": 875.28, "text": " genetically, synthetically generated. And this is their prediction for year 2045. So basically", "tokens": [50712, 37582, 11, 10657, 22652, 10833, 13, 400, 341, 307, 641, 17630, 337, 1064, 945, 8465, 13, 407, 1936, 51032], "temperature": 0.0, "avg_logprob": -0.13563603793873508, "compression_ratio": 1.6473214285714286, "no_speech_prob": 0.0020177054684609175}, {"id": 122, "seek": 86192, "start": 875.28, "end": 880.0, "text": " just one year from now. And this is, this is a huge increase if we're talking about marketing", "tokens": [51032, 445, 472, 1064, 490, 586, 13, 400, 341, 307, 11, 341, 307, 257, 2603, 3488, 498, 321, 434, 1417, 466, 6370, 51268], "temperature": 0.0, "avg_logprob": -0.13563603793873508, "compression_ratio": 1.6473214285714286, "no_speech_prob": 0.0020177054684609175}, {"id": 123, "seek": 86192, "start": 880.7199999999999, "end": 888.48, "text": " industry globally. So why do we see these huge numbers? And these reports, these are not some", "tokens": [51304, 3518, 18958, 13, 407, 983, 360, 321, 536, 613, 2603, 3547, 30, 400, 613, 7122, 11, 613, 366, 406, 512, 51692], "temperature": 0.0, "avg_logprob": -0.13563603793873508, "compression_ratio": 1.6473214285714286, "no_speech_prob": 0.0020177054684609175}, {"id": 124, "seek": 88848, "start": 888.48, "end": 895.9200000000001, "text": " sci-fi movies. These are very trusted, established and, and, and, and, and reputable organizations", "tokens": [50364, 2180, 12, 13325, 6233, 13, 1981, 366, 588, 16034, 11, 7545, 293, 11, 293, 11, 293, 11, 293, 11, 293, 1085, 32148, 6150, 50736], "temperature": 0.0, "avg_logprob": -0.14095733476721722, "compression_ratio": 1.7219730941704037, "no_speech_prob": 0.00490340543910861}, {"id": 125, "seek": 88848, "start": 895.9200000000001, "end": 902.5600000000001, "text": " that are giving these very bold predictions. The reason for that is that generative AI is", "tokens": [50736, 300, 366, 2902, 613, 588, 11928, 21264, 13, 440, 1778, 337, 300, 307, 300, 1337, 1166, 7318, 307, 51068], "temperature": 0.0, "avg_logprob": -0.14095733476721722, "compression_ratio": 1.7219730941704037, "no_speech_prob": 0.00490340543910861}, {"id": 126, "seek": 88848, "start": 902.5600000000001, "end": 911.12, "text": " both intuitive to use and it is broad. What I mean by that, generative AI is very simple to use", "tokens": [51068, 1293, 21769, 281, 764, 293, 309, 307, 4152, 13, 708, 286, 914, 538, 300, 11, 1337, 1166, 7318, 307, 588, 2199, 281, 764, 51496], "temperature": 0.0, "avg_logprob": -0.14095733476721722, "compression_ratio": 1.7219730941704037, "no_speech_prob": 0.00490340543910861}, {"id": 127, "seek": 88848, "start": 911.12, "end": 917.6, "text": " because you generally just need to learn linguistic interface, which is common, which is nature for", "tokens": [51496, 570, 291, 5101, 445, 643, 281, 1466, 43002, 9226, 11, 597, 307, 2689, 11, 597, 307, 3687, 337, 51820], "temperature": 0.0, "avg_logprob": -0.14095733476721722, "compression_ratio": 1.7219730941704037, "no_speech_prob": 0.00490340543910861}, {"id": 128, "seek": 91760, "start": 917.6800000000001, "end": 924.08, "text": " us. Like we humans, by the age of two or three or four years old, we are pretty comfortable with", "tokens": [50368, 505, 13, 1743, 321, 6255, 11, 538, 264, 3205, 295, 732, 420, 1045, 420, 1451, 924, 1331, 11, 321, 366, 1238, 4619, 365, 50688], "temperature": 0.0, "avg_logprob": -0.09745472843207202, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.001987186726182699}, {"id": 129, "seek": 91760, "start": 924.08, "end": 930.24, "text": " linguistic interface. We learn to talk to our parents or our friends. And this is all you need", "tokens": [50688, 43002, 9226, 13, 492, 1466, 281, 751, 281, 527, 3152, 420, 527, 1855, 13, 400, 341, 307, 439, 291, 643, 50996], "temperature": 0.0, "avg_logprob": -0.09745472843207202, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.001987186726182699}, {"id": 130, "seek": 91760, "start": 930.24, "end": 935.76, "text": " to really start using tools like ChargeGPT. You can, even if you don't know how to type, if you", "tokens": [50996, 281, 534, 722, 1228, 3873, 411, 40546, 38, 47, 51, 13, 509, 393, 11, 754, 498, 291, 500, 380, 458, 577, 281, 2010, 11, 498, 291, 51272], "temperature": 0.0, "avg_logprob": -0.09745472843207202, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.001987186726182699}, {"id": 131, "seek": 91760, "start": 935.76, "end": 942.08, "text": " don't know how to write, you can still do it because if you download ChargeGPT on your iPhone,", "tokens": [51272, 500, 380, 458, 577, 281, 2464, 11, 291, 393, 920, 360, 309, 570, 498, 291, 5484, 40546, 38, 47, 51, 322, 428, 7252, 11, 51588], "temperature": 0.0, "avg_logprob": -0.09745472843207202, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.001987186726182699}, {"id": 132, "seek": 94208, "start": 942.08, "end": 948.4000000000001, "text": " you can just talk to it. It will reply you. And that's pretty much instantly useful and helpful to", "tokens": [50364, 291, 393, 445, 751, 281, 309, 13, 467, 486, 16972, 291, 13, 400, 300, 311, 1238, 709, 13518, 4420, 293, 4961, 281, 50680], "temperature": 0.0, "avg_logprob": -0.0847007467391643, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.004824962932616472}, {"id": 133, "seek": 94208, "start": 949.0400000000001, "end": 957.5200000000001, "text": " most of global population. But also in addition to ease of use, it is very broadly applicable.", "tokens": [50712, 881, 295, 4338, 4415, 13, 583, 611, 294, 4500, 281, 12708, 295, 764, 11, 309, 307, 588, 19511, 21142, 13, 51136], "temperature": 0.0, "avg_logprob": -0.0847007467391643, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.004824962932616472}, {"id": 134, "seek": 94208, "start": 957.5200000000001, "end": 963.84, "text": " It can augment pretty much every cognitive task. And I will go into details. I will show examples", "tokens": [51136, 467, 393, 29919, 1238, 709, 633, 15605, 5633, 13, 400, 286, 486, 352, 666, 4365, 13, 286, 486, 855, 5110, 51452], "temperature": 0.0, "avg_logprob": -0.0847007467391643, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.004824962932616472}, {"id": 135, "seek": 94208, "start": 963.84, "end": 969.2800000000001, "text": " of some of the, some of those tasks. It can also power embodiment in robotics so it can help", "tokens": [51452, 295, 512, 295, 264, 11, 512, 295, 729, 9608, 13, 467, 393, 611, 1347, 28935, 2328, 294, 34145, 370, 309, 393, 854, 51724], "temperature": 0.0, "avg_logprob": -0.0847007467391643, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.004824962932616472}, {"id": 136, "seek": 96928, "start": 969.36, "end": 975.68, "text": " a lot of automation and help growth of robotic systems so it can help robots to navigate", "tokens": [50368, 257, 688, 295, 17769, 293, 854, 4599, 295, 30468, 3652, 370, 309, 393, 854, 14733, 281, 12350, 50684], "temperature": 0.0, "avg_logprob": -0.10145475778235011, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.0019845289643853903}, {"id": 137, "seek": 96928, "start": 975.68, "end": 983.6, "text": " environments or complete complex tasks. And at the end of the day, the use case and the outcome", "tokens": [50684, 12388, 420, 3566, 3997, 9608, 13, 400, 412, 264, 917, 295, 264, 786, 11, 264, 764, 1389, 293, 264, 9700, 51080], "temperature": 0.0, "avg_logprob": -0.10145475778235011, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.0019845289643853903}, {"id": 138, "seek": 96928, "start": 983.6, "end": 989.8399999999999, "text": " of the growth of artificial intelligence is the global explosion of intelligence on the planet.", "tokens": [51080, 295, 264, 4599, 295, 11677, 7599, 307, 264, 4338, 15673, 295, 7599, 322, 264, 5054, 13, 51392], "temperature": 0.0, "avg_logprob": -0.10145475778235011, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.0019845289643853903}, {"id": 139, "seek": 96928, "start": 989.8399999999999, "end": 997.36, "text": " So this is maybe a little bit exaggerated picture, but it shows the idea that I'm trying to", "tokens": [51392, 407, 341, 307, 1310, 257, 707, 857, 36196, 3036, 11, 457, 309, 3110, 264, 1558, 300, 286, 478, 1382, 281, 51768], "temperature": 0.0, "avg_logprob": -0.10145475778235011, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.0019845289643853903}, {"id": 140, "seek": 99736, "start": 997.36, "end": 1004.72, "text": " be here. So this is, the green line is the amount of human intelligence on Earth and maybe from", "tokens": [50364, 312, 510, 13, 407, 341, 307, 11, 264, 3092, 1622, 307, 264, 2372, 295, 1952, 7599, 322, 4755, 293, 1310, 490, 50732], "temperature": 0.0, "avg_logprob": -0.16111296276713527, "compression_ratio": 1.6508620689655173, "no_speech_prob": 0.0059929657727479935}, {"id": 141, "seek": 99736, "start": 1004.72, "end": 1010.48, "text": " prehistoric times to our days, it's been growing gradually. But then with the advent and with", "tokens": [50732, 659, 33236, 16345, 1413, 281, 527, 1708, 11, 309, 311, 668, 4194, 13145, 13, 583, 550, 365, 264, 7045, 293, 365, 51020], "temperature": 0.0, "avg_logprob": -0.16111296276713527, "compression_ratio": 1.6508620689655173, "no_speech_prob": 0.0059929657727479935}, {"id": 142, "seek": 99736, "start": 1011.36, "end": 1017.6800000000001, "text": " mass introduction of artificial intelligence, the total amount of intelligence on the Earth", "tokens": [51064, 2758, 9339, 295, 11677, 7599, 11, 264, 3217, 2372, 295, 7599, 322, 264, 4755, 51380], "temperature": 0.0, "avg_logprob": -0.16111296276713527, "compression_ratio": 1.6508620689655173, "no_speech_prob": 0.0059929657727479935}, {"id": 143, "seek": 99736, "start": 1017.6800000000001, "end": 1023.84, "text": " is exploding rapidly. It doesn't mean that these AI tools will replace humans or they will do exactly", "tokens": [51380, 307, 35175, 12910, 13, 467, 1177, 380, 914, 300, 613, 7318, 3873, 486, 7406, 6255, 420, 436, 486, 360, 2293, 51688], "temperature": 0.0, "avg_logprob": -0.16111296276713527, "compression_ratio": 1.6508620689655173, "no_speech_prob": 0.0059929657727479935}, {"id": 144, "seek": 102384, "start": 1023.84, "end": 1031.6000000000001, "text": " the same thing as humans do. I think the better way to think about it is as an augmentation or", "tokens": [50364, 264, 912, 551, 382, 6255, 360, 13, 286, 519, 264, 1101, 636, 281, 519, 466, 309, 307, 382, 364, 14501, 19631, 420, 50752], "temperature": 0.0, "avg_logprob": -0.09195315584223321, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0038779620081186295}, {"id": 145, "seek": 102384, "start": 1031.6000000000001, "end": 1038.72, "text": " insistence to what we do. But because we have ability to leverage this vast amount of intelligence,", "tokens": [50752, 13466, 655, 281, 437, 321, 360, 13, 583, 570, 321, 362, 3485, 281, 13982, 341, 8369, 2372, 295, 7599, 11, 51108], "temperature": 0.0, "avg_logprob": -0.09195315584223321, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0038779620081186295}, {"id": 146, "seek": 102384, "start": 1038.72, "end": 1045.04, "text": " we humans can achieve much, much more. We are spending less time and less energy. And that's", "tokens": [51108, 321, 6255, 393, 4584, 709, 11, 709, 544, 13, 492, 366, 6434, 1570, 565, 293, 1570, 2281, 13, 400, 300, 311, 51424], "temperature": 0.0, "avg_logprob": -0.09195315584223321, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0038779620081186295}, {"id": 147, "seek": 102384, "start": 1045.04, "end": 1053.04, "text": " great. So I, because we are relatively short on time, I will not go into details of inner", "tokens": [51424, 869, 13, 407, 286, 11, 570, 321, 366, 7226, 2099, 322, 565, 11, 286, 486, 406, 352, 666, 4365, 295, 7284, 51824], "temperature": 0.0, "avg_logprob": -0.09195315584223321, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0038779620081186295}, {"id": 148, "seek": 105304, "start": 1053.04, "end": 1061.84, "text": " workings of large language models and generative AI. I won't go, I will not go into technical", "tokens": [50364, 589, 1109, 295, 2416, 2856, 5245, 293, 1337, 1166, 7318, 13, 286, 1582, 380, 352, 11, 286, 486, 406, 352, 666, 6191, 50804], "temperature": 0.0, "avg_logprob": -0.15510072206196032, "compression_ratio": 1.4870466321243523, "no_speech_prob": 0.005720841232687235}, {"id": 149, "seek": 105304, "start": 1061.84, "end": 1070.8, "text": " details, but I recommend this video. This is a video by Andrew Carpati, who is research lead", "tokens": [50804, 4365, 11, 457, 286, 2748, 341, 960, 13, 639, 307, 257, 960, 538, 10110, 2741, 79, 6908, 11, 567, 307, 2132, 1477, 51252], "temperature": 0.0, "avg_logprob": -0.15510072206196032, "compression_ratio": 1.4870466321243523, "no_speech_prob": 0.005720841232687235}, {"id": 150, "seek": 105304, "start": 1070.8, "end": 1076.6399999999999, "text": " at OpenAI in the company that created ChatGPT. And this video is not very technical. I recommend you", "tokens": [51252, 412, 7238, 48698, 294, 264, 2237, 300, 2942, 27503, 38, 47, 51, 13, 400, 341, 960, 307, 406, 588, 6191, 13, 286, 2748, 291, 51544], "temperature": 0.0, "avg_logprob": -0.15510072206196032, "compression_ratio": 1.4870466321243523, "no_speech_prob": 0.005720841232687235}, {"id": 151, "seek": 107664, "start": 1076.64, "end": 1084.0800000000002, "text": " to, if you have one hour, maybe in the evening or at some point, to watch this video. The link is", "tokens": [50364, 281, 11, 498, 291, 362, 472, 1773, 11, 1310, 294, 264, 5634, 420, 412, 512, 935, 11, 281, 1159, 341, 960, 13, 440, 2113, 307, 50736], "temperature": 0.0, "avg_logprob": -0.1341433842976888, "compression_ratio": 1.6092436974789917, "no_speech_prob": 0.07564947754144669}, {"id": 152, "seek": 107664, "start": 1084.0800000000002, "end": 1089.68, "text": " in the slide. And this video goes into exactly how the system work without too much technical detail,", "tokens": [50736, 294, 264, 4137, 13, 400, 341, 960, 1709, 666, 2293, 577, 264, 1185, 589, 1553, 886, 709, 6191, 2607, 11, 51016], "temperature": 0.0, "avg_logprob": -0.1341433842976888, "compression_ratio": 1.6092436974789917, "no_speech_prob": 0.07564947754144669}, {"id": 153, "seek": 107664, "start": 1089.68, "end": 1095.92, "text": " but it gives better idea. And it comes from one of the person responsible for actually", "tokens": [51016, 457, 309, 2709, 1101, 1558, 13, 400, 309, 1487, 490, 472, 295, 264, 954, 6250, 337, 767, 51328], "temperature": 0.0, "avg_logprob": -0.1341433842976888, "compression_ratio": 1.6092436974789917, "no_speech_prob": 0.07564947754144669}, {"id": 154, "seek": 107664, "start": 1095.92, "end": 1102.3200000000002, "text": " development of this technology, who is much more knowledgeable and reputable in the space than I", "tokens": [51328, 3250, 295, 341, 2899, 11, 567, 307, 709, 544, 33800, 293, 1085, 32148, 294, 264, 1901, 813, 286, 51648], "temperature": 0.0, "avg_logprob": -0.1341433842976888, "compression_ratio": 1.6092436974789917, "no_speech_prob": 0.07564947754144669}, {"id": 155, "seek": 110232, "start": 1102.32, "end": 1107.28, "text": " am, for example. And he's also a great speaker. So really, really enjoyable video.", "tokens": [50364, 669, 11, 337, 1365, 13, 400, 415, 311, 611, 257, 869, 8145, 13, 407, 534, 11, 534, 20305, 960, 13, 50612], "temperature": 0.0, "avg_logprob": -0.10780533817079332, "compression_ratio": 1.4427083333333333, "no_speech_prob": 0.007216533645987511}, {"id": 156, "seek": 110232, "start": 1109.52, "end": 1117.84, "text": " So yeah, we will not watch it right now, but let's go into specific AI use cases. So we'll start", "tokens": [50724, 407, 1338, 11, 321, 486, 406, 1159, 309, 558, 586, 11, 457, 718, 311, 352, 666, 2685, 7318, 764, 3331, 13, 407, 321, 603, 722, 51140], "temperature": 0.0, "avg_logprob": -0.10780533817079332, "compression_ratio": 1.4427083333333333, "no_speech_prob": 0.007216533645987511}, {"id": 157, "seek": 110232, "start": 1117.84, "end": 1125.4399999999998, "text": " with application of artificial intelligence for personal life. There's a lot of very, I would say", "tokens": [51140, 365, 3861, 295, 11677, 7599, 337, 2973, 993, 13, 821, 311, 257, 688, 295, 588, 11, 286, 576, 584, 51520], "temperature": 0.0, "avg_logprob": -0.10780533817079332, "compression_ratio": 1.4427083333333333, "no_speech_prob": 0.007216533645987511}, {"id": 158, "seek": 112544, "start": 1125.44, "end": 1132.16, "text": " common and basic and maybe even boring stuff that you can do with tools like ChatGPT.", "tokens": [50364, 2689, 293, 3875, 293, 1310, 754, 9989, 1507, 300, 291, 393, 360, 365, 3873, 411, 27503, 38, 47, 51, 13, 50700], "temperature": 0.0, "avg_logprob": -0.09508910621564413, "compression_ratio": 1.8009478672985781, "no_speech_prob": 0.2302524447441101}, {"id": 159, "seek": 112544, "start": 1132.96, "end": 1139.2, "text": " You can ask it to help craft a letter. You can ask it to check spelling. You can learn new languages", "tokens": [50740, 509, 393, 1029, 309, 281, 854, 8448, 257, 5063, 13, 509, 393, 1029, 309, 281, 1520, 22254, 13, 509, 393, 1466, 777, 8650, 51052], "temperature": 0.0, "avg_logprob": -0.09508910621564413, "compression_ratio": 1.8009478672985781, "no_speech_prob": 0.2302524447441101}, {"id": 160, "seek": 112544, "start": 1139.2, "end": 1144.88, "text": " with it. You can translate the text. You can check your code. If you're a software engineer for", "tokens": [51052, 365, 309, 13, 509, 393, 13799, 264, 2487, 13, 509, 393, 1520, 428, 3089, 13, 759, 291, 434, 257, 4722, 11403, 337, 51336], "temperature": 0.0, "avg_logprob": -0.09508910621564413, "compression_ratio": 1.8009478672985781, "no_speech_prob": 0.2302524447441101}, {"id": 161, "seek": 112544, "start": 1144.88, "end": 1151.2, "text": " bugs, you can ask it to write new code. You can even learn new programming languages with it. You", "tokens": [51336, 15120, 11, 291, 393, 1029, 309, 281, 2464, 777, 3089, 13, 509, 393, 754, 1466, 777, 9410, 8650, 365, 309, 13, 509, 51652], "temperature": 0.0, "avg_logprob": -0.09508910621564413, "compression_ratio": 1.8009478672985781, "no_speech_prob": 0.2302524447441101}, {"id": 162, "seek": 115120, "start": 1151.2, "end": 1160.56, "text": " can do any kind of text and language related tasks with tools like ChatGPT. But I thought that for", "tokens": [50364, 393, 360, 604, 733, 295, 2487, 293, 2856, 4077, 9608, 365, 3873, 411, 27503, 38, 47, 51, 13, 583, 286, 1194, 300, 337, 50832], "temperature": 0.0, "avg_logprob": -0.10060715429561655, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.001499910606071353}, {"id": 163, "seek": 115120, "start": 1160.56, "end": 1166.0, "text": " today presentation, that would be boring if I would just show like, okay, now you can translate", "tokens": [50832, 965, 5860, 11, 300, 576, 312, 9989, 498, 286, 576, 445, 855, 411, 11, 1392, 11, 586, 291, 393, 13799, 51104], "temperature": 0.0, "avg_logprob": -0.10060715429561655, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.001499910606071353}, {"id": 164, "seek": 115120, "start": 1166.0, "end": 1172.0, "text": " a letter into Chinese. Great, but this is not very exciting. Translation was possible before.", "tokens": [51104, 257, 5063, 666, 4649, 13, 3769, 11, 457, 341, 307, 406, 588, 4670, 13, 6531, 24278, 390, 1944, 949, 13, 51404], "temperature": 0.0, "avg_logprob": -0.10060715429561655, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.001499910606071353}, {"id": 165, "seek": 115120, "start": 1172.0, "end": 1178.88, "text": " So today, we're not going to talk about this basic and simple stuff. Today, we're going to talk about", "tokens": [51404, 407, 965, 11, 321, 434, 406, 516, 281, 751, 466, 341, 3875, 293, 2199, 1507, 13, 2692, 11, 321, 434, 516, 281, 751, 466, 51748], "temperature": 0.0, "avg_logprob": -0.10060715429561655, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.001499910606071353}, {"id": 166, "seek": 117888, "start": 1178.88, "end": 1187.1200000000001, "text": " something maybe one level deeper or layer higher. Depends on how you want to put it.", "tokens": [50364, 746, 1310, 472, 1496, 7731, 420, 4583, 2946, 13, 4056, 2581, 322, 577, 291, 528, 281, 829, 309, 13, 50776], "temperature": 0.0, "avg_logprob": -0.11197228218192484, "compression_ratio": 1.5224719101123596, "no_speech_prob": 0.0022860525641590357}, {"id": 167, "seek": 117888, "start": 1188.5600000000002, "end": 1196.5600000000002, "text": " And I want to start with this notion of learning partner. So for me, for my personal use case,", "tokens": [50848, 400, 286, 528, 281, 722, 365, 341, 10710, 295, 2539, 4975, 13, 407, 337, 385, 11, 337, 452, 2973, 764, 1389, 11, 51248], "temperature": 0.0, "avg_logprob": -0.11197228218192484, "compression_ratio": 1.5224719101123596, "no_speech_prob": 0.0022860525641590357}, {"id": 168, "seek": 117888, "start": 1196.5600000000002, "end": 1205.8400000000001, "text": " in my personal life, what I use large language models daily for is to learn new information", "tokens": [51248, 294, 452, 2973, 993, 11, 437, 286, 764, 2416, 2856, 5245, 5212, 337, 307, 281, 1466, 777, 1589, 51712], "temperature": 0.0, "avg_logprob": -0.11197228218192484, "compression_ratio": 1.5224719101123596, "no_speech_prob": 0.0022860525641590357}, {"id": 169, "seek": 120584, "start": 1205.9199999999998, "end": 1214.48, "text": " and to digest and to understand new complex stuff. So I want to, you can use ChatGPT or other tools,", "tokens": [50368, 293, 281, 13884, 293, 281, 1223, 777, 3997, 1507, 13, 407, 286, 528, 281, 11, 291, 393, 764, 27503, 38, 47, 51, 420, 661, 3873, 11, 50796], "temperature": 0.0, "avg_logprob": -0.11674837546773476, "compression_ratio": 1.696035242290749, "no_speech_prob": 0.0020813639275729656}, {"id": 170, "seek": 120584, "start": 1214.48, "end": 1220.8799999999999, "text": " and I will show different tools just to, again, to prove my point about the breasts and", "tokens": [50796, 293, 286, 486, 855, 819, 3873, 445, 281, 11, 797, 11, 281, 7081, 452, 935, 466, 264, 34331, 293, 51116], "temperature": 0.0, "avg_logprob": -0.11674837546773476, "compression_ratio": 1.696035242290749, "no_speech_prob": 0.0020813639275729656}, {"id": 171, "seek": 120584, "start": 1222.6399999999999, "end": 1228.0, "text": " number of different tools that exist. You can use GPT or similar LLMs as a learning partner. You", "tokens": [51204, 1230, 295, 819, 3873, 300, 2514, 13, 509, 393, 764, 26039, 51, 420, 2531, 441, 43, 26386, 382, 257, 2539, 4975, 13, 509, 51472], "temperature": 0.0, "avg_logprob": -0.11674837546773476, "compression_ratio": 1.696035242290749, "no_speech_prob": 0.0020813639275729656}, {"id": 172, "seek": 120584, "start": 1228.0, "end": 1233.52, "text": " can ask it to explain complex information to you. You can ask it to be your tutor. You can even ask", "tokens": [51472, 393, 1029, 309, 281, 2903, 3997, 1589, 281, 291, 13, 509, 393, 1029, 309, 281, 312, 428, 35613, 13, 509, 393, 754, 1029, 51748], "temperature": 0.0, "avg_logprob": -0.11674837546773476, "compression_ratio": 1.696035242290749, "no_speech_prob": 0.0020813639275729656}, {"id": 173, "seek": 123352, "start": 1233.52, "end": 1241.84, "text": " it to create tests for you to learn and remember and verify yourself. You can ask GPT to engage in", "tokens": [50364, 309, 281, 1884, 6921, 337, 291, 281, 1466, 293, 1604, 293, 16888, 1803, 13, 509, 393, 1029, 26039, 51, 281, 4683, 294, 50780], "temperature": 0.0, "avg_logprob": -0.08743345603514253, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.0029313983395695686}, {"id": 174, "seek": 123352, "start": 1241.84, "end": 1248.8, "text": " Socratic dialogue with you. You can ask it to transcribe video or podcast. GPT directly cannot", "tokens": [50780, 407, 10757, 2399, 10221, 365, 291, 13, 509, 393, 1029, 309, 281, 1145, 8056, 960, 420, 7367, 13, 26039, 51, 3838, 2644, 51128], "temperature": 0.0, "avg_logprob": -0.08743345603514253, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.0029313983395695686}, {"id": 175, "seek": 123352, "start": 1248.8, "end": 1254.72, "text": " do it, but there are free services that allow to transcribe and then answer questions based on", "tokens": [51128, 360, 309, 11, 457, 456, 366, 1737, 3328, 300, 2089, 281, 1145, 8056, 293, 550, 1867, 1651, 2361, 322, 51424], "temperature": 0.0, "avg_logprob": -0.08743345603514253, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.0029313983395695686}, {"id": 176, "seek": 123352, "start": 1255.44, "end": 1260.8, "text": " existing videos or existing podcasts. So for this first example, I want to show", "tokens": [51460, 6741, 2145, 420, 6741, 24045, 13, 407, 337, 341, 700, 1365, 11, 286, 528, 281, 855, 51728], "temperature": 0.0, "avg_logprob": -0.08743345603514253, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.0029313983395695686}, {"id": 177, "seek": 126080, "start": 1261.44, "end": 1268.24, "text": " another chatbot, which is not ChatGPT. Maybe it's a little bit less known, but it is called Clot AI.", "tokens": [50396, 1071, 5081, 18870, 11, 597, 307, 406, 27503, 38, 47, 51, 13, 2704, 309, 311, 257, 707, 857, 1570, 2570, 11, 457, 309, 307, 1219, 2033, 310, 7318, 13, 50736], "temperature": 0.0, "avg_logprob": -0.13992204449393533, "compression_ratio": 1.4776119402985075, "no_speech_prob": 0.001262341858819127}, {"id": 178, "seek": 126080, "start": 1269.9199999999998, "end": 1277.44, "text": " It is free to use. So you can go to clot.ai, create an account. It might not work in some countries,", "tokens": [50820, 467, 307, 1737, 281, 764, 13, 407, 291, 393, 352, 281, 596, 310, 13, 1301, 11, 1884, 364, 2696, 13, 467, 1062, 406, 589, 294, 512, 3517, 11, 51196], "temperature": 0.0, "avg_logprob": -0.13992204449393533, "compression_ratio": 1.4776119402985075, "no_speech_prob": 0.001262341858819127}, {"id": 179, "seek": 126080, "start": 1277.44, "end": 1285.44, "text": " but it definitely works in UK and US. So if it doesn't work for you, you probably, the solution", "tokens": [51196, 457, 309, 2138, 1985, 294, 7051, 293, 2546, 13, 407, 498, 309, 1177, 380, 589, 337, 291, 11, 291, 1391, 11, 264, 3827, 51596], "temperature": 0.0, "avg_logprob": -0.13992204449393533, "compression_ratio": 1.4776119402985075, "no_speech_prob": 0.001262341858819127}, {"id": 180, "seek": 128544, "start": 1285.44, "end": 1295.44, "text": " here is to download VPN, choose either UK or US location, create an account, and then you don't", "tokens": [50364, 510, 307, 281, 5484, 24512, 11, 2826, 2139, 7051, 420, 2546, 4914, 11, 1884, 364, 2696, 11, 293, 550, 291, 500, 380, 50864], "temperature": 0.0, "avg_logprob": -0.19567423228976094, "compression_ratio": 1.5977653631284916, "no_speech_prob": 0.013213178142905235}, {"id": 181, "seek": 128544, "start": 1295.44, "end": 1300.0, "text": " need it. So you just need VPN once to create an account and it will work for you and it will be", "tokens": [50864, 643, 309, 13, 407, 291, 445, 643, 24512, 1564, 281, 1884, 364, 2696, 293, 309, 486, 589, 337, 291, 293, 309, 486, 312, 51092], "temperature": 0.0, "avg_logprob": -0.19567423228976094, "compression_ratio": 1.5977653631284916, "no_speech_prob": 0.013213178142905235}, {"id": 182, "seek": 128544, "start": 1300.56, "end": 1308.96, "text": " and it's completely free to use. So I will show one example, how I use Clot to work. So I have", "tokens": [51120, 293, 309, 311, 2584, 1737, 281, 764, 13, 407, 286, 486, 855, 472, 1365, 11, 577, 286, 764, 2033, 310, 281, 589, 13, 407, 286, 362, 51540], "temperature": 0.0, "avg_logprob": -0.19567423228976094, "compression_ratio": 1.5977653631284916, "no_speech_prob": 0.013213178142905235}, {"id": 183, "seek": 130896, "start": 1309.28, "end": 1315.92, "text": " to learn information. So I have a white paper. This is Bitcoin white paper. It goes into details", "tokens": [50380, 281, 1466, 1589, 13, 407, 286, 362, 257, 2418, 3035, 13, 639, 307, 11414, 2418, 3035, 13, 467, 1709, 666, 4365, 50712], "temperature": 0.0, "avg_logprob": -0.11809864044189453, "compression_ratio": 1.6331877729257642, "no_speech_prob": 0.056561943143606186}, {"id": 184, "seek": 130896, "start": 1315.92, "end": 1323.52, "text": " about how Bitcoin cryptocurrency network works. It is relatively technical. So what I would do,", "tokens": [50712, 466, 577, 11414, 28809, 3209, 1985, 13, 467, 307, 7226, 6191, 13, 407, 437, 286, 576, 360, 11, 51092], "temperature": 0.0, "avg_logprob": -0.11809864044189453, "compression_ratio": 1.6331877729257642, "no_speech_prob": 0.056561943143606186}, {"id": 185, "seek": 130896, "start": 1323.52, "end": 1330.48, "text": " if I want to learn about how Bitcoin works, but maybe let's say I'm not a technical person,", "tokens": [51092, 498, 286, 528, 281, 1466, 466, 577, 11414, 1985, 11, 457, 1310, 718, 311, 584, 286, 478, 406, 257, 6191, 954, 11, 51440], "temperature": 0.0, "avg_logprob": -0.11809864044189453, "compression_ratio": 1.6331877729257642, "no_speech_prob": 0.056561943143606186}, {"id": 186, "seek": 130896, "start": 1330.48, "end": 1336.08, "text": " I don't understand too many things about cryptography, I would just upload a PDF here and", "tokens": [51440, 286, 500, 380, 1223, 886, 867, 721, 466, 9844, 5820, 11, 286, 576, 445, 6580, 257, 17752, 510, 293, 51720], "temperature": 0.0, "avg_logprob": -0.11809864044189453, "compression_ratio": 1.6331877729257642, "no_speech_prob": 0.056561943143606186}, {"id": 187, "seek": 133608, "start": 1336.08, "end": 1342.0, "text": " it could be any kind of scientific paper. And I will ask a question. And the question, my question", "tokens": [50364, 309, 727, 312, 604, 733, 295, 8134, 3035, 13, 400, 286, 486, 1029, 257, 1168, 13, 400, 264, 1168, 11, 452, 1168, 50660], "temperature": 0.0, "avg_logprob": -0.10538117544991629, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.005722702946513891}, {"id": 188, "seek": 133608, "start": 1342.0, "end": 1349.76, "text": " would be explain this paper as if I'm seven years old. So I will just ask Claude Chatbot to explain", "tokens": [50660, 576, 312, 2903, 341, 3035, 382, 498, 286, 478, 3407, 924, 1331, 13, 407, 286, 486, 445, 1029, 12947, 2303, 27503, 18870, 281, 2903, 51048], "temperature": 0.0, "avg_logprob": -0.10538117544991629, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.005722702946513891}, {"id": 189, "seek": 133608, "start": 1349.76, "end": 1356.72, "text": " the complex paper for me in simple terms. And as you can see, it already starts giving me answers", "tokens": [51048, 264, 3997, 3035, 337, 385, 294, 2199, 2115, 13, 400, 382, 291, 393, 536, 11, 309, 1217, 3719, 2902, 385, 6338, 51396], "temperature": 0.0, "avg_logprob": -0.10538117544991629, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.005722702946513891}, {"id": 190, "seek": 133608, "start": 1356.72, "end": 1363.9199999999998, "text": " answer. And if you read it, I won't read the whole thing, but if you read it, you can see that it's", "tokens": [51396, 1867, 13, 400, 498, 291, 1401, 309, 11, 286, 1582, 380, 1401, 264, 1379, 551, 11, 457, 498, 291, 1401, 309, 11, 291, 393, 536, 300, 309, 311, 51756], "temperature": 0.0, "avg_logprob": -0.10538117544991629, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.005722702946513891}, {"id": 191, "seek": 136392, "start": 1363.92, "end": 1371.1200000000001, "text": " really, really simple. Like I have a kid who is about that age, and I'm sure he will understand.", "tokens": [50364, 534, 11, 534, 2199, 13, 1743, 286, 362, 257, 1636, 567, 307, 466, 300, 3205, 11, 293, 286, 478, 988, 415, 486, 1223, 13, 50724], "temperature": 0.0, "avg_logprob": -0.13380724505374306, "compression_ratio": 1.4494949494949494, "no_speech_prob": 0.005295132286846638}, {"id": 192, "seek": 136392, "start": 1371.1200000000001, "end": 1378.5600000000002, "text": " So it just goes, sending money online is tricky, because you don't want one person spent the same", "tokens": [50724, 407, 309, 445, 1709, 11, 7750, 1460, 2950, 307, 12414, 11, 570, 291, 500, 380, 528, 472, 954, 4418, 264, 912, 51096], "temperature": 0.0, "avg_logprob": -0.13380724505374306, "compression_ratio": 1.4494949494949494, "no_speech_prob": 0.005295132286846638}, {"id": 193, "seek": 136392, "start": 1378.5600000000002, "end": 1387.1200000000001, "text": " amount of money twice. And this is how Bitcoin helps it. And yeah, it's just a simple way of", "tokens": [51096, 2372, 295, 1460, 6091, 13, 400, 341, 307, 577, 11414, 3665, 309, 13, 400, 1338, 11, 309, 311, 445, 257, 2199, 636, 295, 51524], "temperature": 0.0, "avg_logprob": -0.13380724505374306, "compression_ratio": 1.4494949494949494, "no_speech_prob": 0.005295132286846638}, {"id": 194, "seek": 138712, "start": 1387.12, "end": 1396.4799999999998, "text": " explaining. I can also ask a follow up question, how new Bitcoins are created. So I can just chat", "tokens": [50364, 13468, 13, 286, 393, 611, 1029, 257, 1524, 493, 1168, 11, 577, 777, 9101, 36989, 366, 2942, 13, 407, 286, 393, 445, 5081, 50832], "temperature": 0.0, "avg_logprob": -0.17397859361436632, "compression_ratio": 1.4795918367346939, "no_speech_prob": 0.014493029564619064}, {"id": 195, "seek": 138712, "start": 1396.4799999999998, "end": 1406.32, "text": " with this article. And it will continue generating these answers in this very simple term. So it", "tokens": [50832, 365, 341, 7222, 13, 400, 309, 486, 2354, 17746, 613, 6338, 294, 341, 588, 2199, 1433, 13, 407, 309, 51324], "temperature": 0.0, "avg_logprob": -0.17397859361436632, "compression_ratio": 1.4795918367346939, "no_speech_prob": 0.014493029564619064}, {"id": 196, "seek": 138712, "start": 1406.32, "end": 1413.6799999999998, "text": " doesn't go into deep cryptography, it just calls it math puzzle. And that's easy to understand.", "tokens": [51324, 1177, 380, 352, 666, 2452, 9844, 5820, 11, 309, 445, 5498, 309, 5221, 12805, 13, 400, 300, 311, 1858, 281, 1223, 13, 51692], "temperature": 0.0, "avg_logprob": -0.17397859361436632, "compression_ratio": 1.4795918367346939, "no_speech_prob": 0.014493029564619064}, {"id": 197, "seek": 141368, "start": 1413.68, "end": 1421.68, "text": " So that's just one example and one application. And I have link, Claude here on this slide.", "tokens": [50364, 407, 300, 311, 445, 472, 1365, 293, 472, 3861, 13, 400, 286, 362, 2113, 11, 12947, 2303, 510, 322, 341, 4137, 13, 50764], "temperature": 0.0, "avg_logprob": -0.12640508483437932, "compression_ratio": 1.5132275132275133, "no_speech_prob": 0.000939632416702807}, {"id": 198, "seek": 141368, "start": 1424.16, "end": 1433.04, "text": " Another example is to use large language models as your second brain, as a way to remember and", "tokens": [50888, 3996, 1365, 307, 281, 764, 2416, 2856, 5245, 382, 428, 1150, 3567, 11, 382, 257, 636, 281, 1604, 293, 51332], "temperature": 0.0, "avg_logprob": -0.12640508483437932, "compression_ratio": 1.5132275132275133, "no_speech_prob": 0.000939632416702807}, {"id": 199, "seek": 141368, "start": 1433.04, "end": 1441.6000000000001, "text": " way to reference complex information. So you can record a lot of things today with even free online", "tokens": [51332, 636, 281, 6408, 3997, 1589, 13, 407, 291, 393, 2136, 257, 688, 295, 721, 965, 365, 754, 1737, 2950, 51760], "temperature": 0.0, "avg_logprob": -0.12640508483437932, "compression_ratio": 1.5132275132275133, "no_speech_prob": 0.000939632416702807}, {"id": 200, "seek": 144160, "start": 1441.6, "end": 1447.52, "text": " tools, such as calls, for example, this call is being recorded, and Zoom is actually doing live", "tokens": [50364, 3873, 11, 1270, 382, 5498, 11, 337, 1365, 11, 341, 818, 307, 885, 8287, 11, 293, 13453, 307, 767, 884, 1621, 50660], "temperature": 0.0, "avg_logprob": -0.14592758490114796, "compression_ratio": 1.7035398230088497, "no_speech_prob": 0.009847777895629406}, {"id": 201, "seek": 144160, "start": 1448.8, "end": 1457.1999999999998, "text": " transcribing of what I'm saying. You can record documents, download documents. You can download", "tokens": [50724, 1145, 39541, 295, 437, 286, 478, 1566, 13, 509, 393, 2136, 8512, 11, 5484, 8512, 13, 509, 393, 5484, 51144], "temperature": 0.0, "avg_logprob": -0.14592758490114796, "compression_ratio": 1.7035398230088497, "no_speech_prob": 0.009847777895629406}, {"id": 202, "seek": 144160, "start": 1457.1999999999998, "end": 1464.3999999999999, "text": " web pages. And then you can use one of these tools. And actually, each one of them is free to use,", "tokens": [51144, 3670, 7183, 13, 400, 550, 291, 393, 764, 472, 295, 613, 3873, 13, 400, 767, 11, 1184, 472, 295, 552, 307, 1737, 281, 764, 11, 51504], "temperature": 0.0, "avg_logprob": -0.14592758490114796, "compression_ratio": 1.7035398230088497, "no_speech_prob": 0.009847777895629406}, {"id": 203, "seek": 144160, "start": 1464.3999999999999, "end": 1470.24, "text": " at least up to a certain point. This first one is open source and it's free to use forever. So", "tokens": [51504, 412, 1935, 493, 281, 257, 1629, 935, 13, 639, 700, 472, 307, 1269, 4009, 293, 309, 311, 1737, 281, 764, 5680, 13, 407, 51796], "temperature": 0.0, "avg_logprob": -0.14592758490114796, "compression_ratio": 1.7035398230088497, "no_speech_prob": 0.009847777895629406}, {"id": 204, "seek": 147024, "start": 1471.1200000000001, "end": 1478.24, "text": " if you want a free solution, I recommend this one. This last one is unreadable, is the one that I'm", "tokens": [50408, 498, 291, 528, 257, 1737, 3827, 11, 286, 2748, 341, 472, 13, 639, 1036, 472, 307, 517, 2538, 712, 11, 307, 264, 472, 300, 286, 478, 50764], "temperature": 0.0, "avg_logprob": -0.1291540443123161, "compression_ratio": 1.5105263157894737, "no_speech_prob": 0.00027791885077022016}, {"id": 205, "seek": 147024, "start": 1478.24, "end": 1486.16, "text": " going to show right now. And it is more focused on students and the way to prepare, for example.", "tokens": [50764, 516, 281, 855, 558, 586, 13, 400, 309, 307, 544, 5178, 322, 1731, 293, 264, 636, 281, 5940, 11, 337, 1365, 13, 51160], "temperature": 0.0, "avg_logprob": -0.1291540443123161, "compression_ratio": 1.5105263157894737, "no_speech_prob": 0.00027791885077022016}, {"id": 206, "seek": 147024, "start": 1486.88, "end": 1494.64, "text": " And the way that second brain works is I just go to this website, I create a free account,", "tokens": [51196, 400, 264, 636, 300, 1150, 3567, 1985, 307, 286, 445, 352, 281, 341, 3144, 11, 286, 1884, 257, 1737, 2696, 11, 51584], "temperature": 0.0, "avg_logprob": -0.1291540443123161, "compression_ratio": 1.5105263157894737, "no_speech_prob": 0.00027791885077022016}, {"id": 207, "seek": 149464, "start": 1494.64, "end": 1501.6000000000001, "text": " and then I kind of upload some information, some documents here, and talk to those documents.", "tokens": [50364, 293, 550, 286, 733, 295, 6580, 512, 1589, 11, 512, 8512, 510, 11, 293, 751, 281, 729, 8512, 13, 50712], "temperature": 0.0, "avg_logprob": -0.11536491348082761, "compression_ratio": 1.8535353535353536, "no_speech_prob": 0.0027140292804688215}, {"id": 208, "seek": 149464, "start": 1501.6000000000001, "end": 1509.0400000000002, "text": " So I'm just uploading a presentation, this presentation that I'm just showing. And I", "tokens": [50712, 407, 286, 478, 445, 27301, 257, 5860, 11, 341, 5860, 300, 286, 478, 445, 4099, 13, 400, 286, 51084], "temperature": 0.0, "avg_logprob": -0.11536491348082761, "compression_ratio": 1.8535353535353536, "no_speech_prob": 0.0027140292804688215}, {"id": 209, "seek": 149464, "start": 1509.0400000000002, "end": 1514.8000000000002, "text": " upload this presentation here. And the difference between the example that I just showed before", "tokens": [51084, 6580, 341, 5860, 510, 13, 400, 264, 2649, 1296, 264, 1365, 300, 286, 445, 4712, 949, 51372], "temperature": 0.0, "avg_logprob": -0.11536491348082761, "compression_ratio": 1.8535353535353536, "no_speech_prob": 0.0027140292804688215}, {"id": 210, "seek": 149464, "start": 1514.8000000000002, "end": 1522.4, "text": " with chatting with the paper, and this one is that here you can upload a lot of information.", "tokens": [51372, 365, 24654, 365, 264, 3035, 11, 293, 341, 472, 307, 300, 510, 291, 393, 6580, 257, 688, 295, 1589, 13, 51752], "temperature": 0.0, "avg_logprob": -0.11536491348082761, "compression_ratio": 1.8535353535353536, "no_speech_prob": 0.0027140292804688215}, {"id": 211, "seek": 152240, "start": 1522.4, "end": 1527.8400000000001, "text": " You can upload the whole book, or maybe multiple books. And then this information is stored,", "tokens": [50364, 509, 393, 6580, 264, 1379, 1446, 11, 420, 1310, 3866, 3642, 13, 400, 550, 341, 1589, 307, 12187, 11, 50636], "temperature": 0.0, "avg_logprob": -0.11172189712524414, "compression_ratio": 1.64, "no_speech_prob": 0.0031211806926876307}, {"id": 212, "seek": 152240, "start": 1527.8400000000001, "end": 1534.72, "text": " and you can use the same technique, you can just ask questions. So for example, I will ask,", "tokens": [50636, 293, 291, 393, 764, 264, 912, 6532, 11, 291, 393, 445, 1029, 1651, 13, 407, 337, 1365, 11, 286, 486, 1029, 11, 50980], "temperature": 0.0, "avg_logprob": -0.11172189712524414, "compression_ratio": 1.64, "no_speech_prob": 0.0031211806926876307}, {"id": 213, "seek": 152240, "start": 1536.8000000000002, "end": 1543.76, "text": " it actually prepares some questions that I can ask, but I will ask, what are AI use cases in", "tokens": [51084, 309, 767, 39418, 512, 1651, 300, 286, 393, 1029, 11, 457, 286, 486, 1029, 11, 437, 366, 7318, 764, 3331, 294, 51432], "temperature": 0.0, "avg_logprob": -0.11172189712524414, "compression_ratio": 1.64, "no_speech_prob": 0.0031211806926876307}, {"id": 214, "seek": 152240, "start": 1543.76, "end": 1551.6000000000001, "text": " marketing? And based on this presentation, it will give me answers. Personalized marketing,", "tokens": [51432, 6370, 30, 400, 2361, 322, 341, 5860, 11, 309, 486, 976, 385, 6338, 13, 25317, 1602, 6370, 11, 51824], "temperature": 0.0, "avg_logprob": -0.11172189712524414, "compression_ratio": 1.64, "no_speech_prob": 0.0031211806926876307}, {"id": 215, "seek": 155160, "start": 1551.6, "end": 1557.76, "text": " empathetic communication. And if we scroll to the slide that is still coming, so a little bit of", "tokens": [50364, 27155, 3532, 6101, 13, 400, 498, 321, 11369, 281, 264, 4137, 300, 307, 920, 1348, 11, 370, 257, 707, 857, 295, 50672], "temperature": 0.0, "avg_logprob": -0.1306108173571135, "compression_ratio": 1.5949367088607596, "no_speech_prob": 0.0020806880202144384}, {"id": 216, "seek": 155160, "start": 1560.24, "end": 1567.04, "text": " unveil here. So this slide is AI marketing. And as you can see, it has actually found the", "tokens": [50796, 31009, 388, 510, 13, 407, 341, 4137, 307, 7318, 6370, 13, 400, 382, 291, 393, 536, 11, 309, 575, 767, 1352, 264, 51136], "temperature": 0.0, "avg_logprob": -0.1306108173571135, "compression_ratio": 1.5949367088607596, "no_speech_prob": 0.0020806880202144384}, {"id": 217, "seek": 155160, "start": 1567.04, "end": 1573.76, "text": " right slide. And it gives me information, not based on what chat GPT knows about marketing,", "tokens": [51136, 558, 4137, 13, 400, 309, 2709, 385, 1589, 11, 406, 2361, 322, 437, 5081, 26039, 51, 3255, 466, 6370, 11, 51472], "temperature": 0.0, "avg_logprob": -0.1306108173571135, "compression_ratio": 1.5949367088607596, "no_speech_prob": 0.0020806880202144384}, {"id": 218, "seek": 155160, "start": 1573.76, "end": 1579.6, "text": " but based on this exact presentation. And if I were to upload a book here, I can just ask questions", "tokens": [51472, 457, 2361, 322, 341, 1900, 5860, 13, 400, 498, 286, 645, 281, 6580, 257, 1446, 510, 11, 286, 393, 445, 1029, 1651, 51764], "temperature": 0.0, "avg_logprob": -0.1306108173571135, "compression_ratio": 1.5949367088607596, "no_speech_prob": 0.0020806880202144384}, {"id": 219, "seek": 157960, "start": 1580.1599999999999, "end": 1585.12, "text": " to the book, and it will give answers based on relevant information that it finds in that book.", "tokens": [50392, 281, 264, 1446, 11, 293, 309, 486, 976, 6338, 2361, 322, 7340, 1589, 300, 309, 10704, 294, 300, 1446, 13, 50640], "temperature": 0.0, "avg_logprob": -0.10621576449450325, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.0016732289223000407}, {"id": 220, "seek": 157960, "start": 1585.12, "end": 1590.08, "text": " And that's very useful. This is also one of the applications that I'm using more or less daily", "tokens": [50640, 400, 300, 311, 588, 4420, 13, 639, 307, 611, 472, 295, 264, 5821, 300, 286, 478, 1228, 544, 420, 1570, 5212, 50888], "temperature": 0.0, "avg_logprob": -0.10621576449450325, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.0016732289223000407}, {"id": 221, "seek": 157960, "start": 1590.7199999999998, "end": 1602.48, "text": " for various use cases. Another very, very powerful application is to use GPT or any other", "tokens": [50920, 337, 3683, 764, 3331, 13, 3996, 588, 11, 588, 4005, 3861, 307, 281, 764, 26039, 51, 420, 604, 661, 51508], "temperature": 0.0, "avg_logprob": -0.10621576449450325, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.0016732289223000407}, {"id": 222, "seek": 160248, "start": 1603.28, "end": 1608.64, "text": " large language model to be your thinking partner or brainstorm partner.", "tokens": [50404, 2416, 2856, 2316, 281, 312, 428, 1953, 4975, 420, 35245, 4975, 13, 50672], "temperature": 0.0, "avg_logprob": -0.1116151324773239, "compression_ratio": 1.4475138121546962, "no_speech_prob": 0.10661476105451584}, {"id": 223, "seek": 160248, "start": 1610.08, "end": 1617.52, "text": " Because GPT on its own might not completely and full autonomously solve any of the problems that", "tokens": [50744, 1436, 26039, 51, 322, 1080, 1065, 1062, 406, 2584, 293, 1577, 18203, 5098, 5039, 604, 295, 264, 2740, 300, 51116], "temperature": 0.0, "avg_logprob": -0.1116151324773239, "compression_ratio": 1.4475138121546962, "no_speech_prob": 0.10661476105451584}, {"id": 224, "seek": 160248, "start": 1617.52, "end": 1625.44, "text": " you have, but it is great when you want to have someone to basically think with or discuss or", "tokens": [51116, 291, 362, 11, 457, 309, 307, 869, 562, 291, 528, 281, 362, 1580, 281, 1936, 519, 365, 420, 2248, 420, 51512], "temperature": 0.0, "avg_logprob": -0.1116151324773239, "compression_ratio": 1.4475138121546962, "no_speech_prob": 0.10661476105451584}, {"id": 225, "seek": 162544, "start": 1625.44, "end": 1634.0800000000002, "text": " brainstorm ideas, please. And I will show example of me creating a prompt. So this is the prompt", "tokens": [50364, 35245, 3487, 11, 1767, 13, 400, 286, 486, 855, 1365, 295, 385, 4084, 257, 12391, 13, 407, 341, 307, 264, 12391, 50796], "temperature": 0.0, "avg_logprob": -0.09033012390136719, "compression_ratio": 1.5103092783505154, "no_speech_prob": 0.022614600136876106}, {"id": 226, "seek": 162544, "start": 1634.0800000000002, "end": 1644.3200000000002, "text": " that I did. I'm saying that I'm running webinars and lectures on how to use AI for work. And I'm", "tokens": [50796, 300, 286, 630, 13, 286, 478, 1566, 300, 286, 478, 2614, 26065, 293, 16564, 322, 577, 281, 764, 7318, 337, 589, 13, 400, 286, 478, 51308], "temperature": 0.0, "avg_logprob": -0.09033012390136719, "compression_ratio": 1.5103092783505154, "no_speech_prob": 0.022614600136876106}, {"id": 227, "seek": 162544, "start": 1644.3200000000002, "end": 1651.1200000000001, "text": " asking chat GPT to use these six thinking hats methodology, which is just brainstorming methodology", "tokens": [51308, 3365, 5081, 26039, 51, 281, 764, 613, 2309, 1953, 20549, 24850, 11, 597, 307, 445, 35245, 278, 24850, 51648], "temperature": 0.0, "avg_logprob": -0.09033012390136719, "compression_ratio": 1.5103092783505154, "no_speech_prob": 0.022614600136876106}, {"id": 228, "seek": 165112, "start": 1651.84, "end": 1658.2399999999998, "text": " to help me generate ideas. And this is the response that I get from chat GPT. And this is", "tokens": [50400, 281, 854, 385, 8460, 3487, 13, 400, 341, 307, 264, 4134, 300, 286, 483, 490, 5081, 26039, 51, 13, 400, 341, 307, 50720], "temperature": 0.0, "avg_logprob": -0.06108122401767307, "compression_ratio": 1.663677130044843, "no_speech_prob": 0.012231310829520226}, {"id": 229, "seek": 165112, "start": 1658.2399999999998, "end": 1663.9199999999998, "text": " actually very useful. Again, I'm not going to read everything here, but this link is public.", "tokens": [50720, 767, 588, 4420, 13, 3764, 11, 286, 478, 406, 516, 281, 1401, 1203, 510, 11, 457, 341, 2113, 307, 1908, 13, 51004], "temperature": 0.0, "avg_logprob": -0.06108122401767307, "compression_ratio": 1.663677130044843, "no_speech_prob": 0.012231310829520226}, {"id": 230, "seek": 165112, "start": 1663.9199999999998, "end": 1670.9599999999998, "text": " And the value here is that it might not give me exact answer that I'm looking for, but it will", "tokens": [51004, 400, 264, 2158, 510, 307, 300, 309, 1062, 406, 976, 385, 1900, 1867, 300, 286, 478, 1237, 337, 11, 457, 309, 486, 51356], "temperature": 0.0, "avg_logprob": -0.06108122401767307, "compression_ratio": 1.663677130044843, "no_speech_prob": 0.012231310829520226}, {"id": 231, "seek": 165112, "start": 1670.9599999999998, "end": 1677.28, "text": " give me suggestions that will spark some imagination creativity that will help me to actually", "tokens": [51356, 976, 385, 13396, 300, 486, 9908, 512, 12938, 12915, 300, 486, 854, 385, 281, 767, 51672], "temperature": 0.0, "avg_logprob": -0.06108122401767307, "compression_ratio": 1.663677130044843, "no_speech_prob": 0.012231310829520226}, {"id": 232, "seek": 167728, "start": 1678.08, "end": 1683.76, "text": " come up with more creative answers. And this is also something that I'm using pretty much every", "tokens": [50404, 808, 493, 365, 544, 5880, 6338, 13, 400, 341, 307, 611, 746, 300, 286, 478, 1228, 1238, 709, 633, 50688], "temperature": 0.0, "avg_logprob": -0.08325220254751352, "compression_ratio": 1.4842105263157894, "no_speech_prob": 0.00370448618195951}, {"id": 233, "seek": 167728, "start": 1683.76, "end": 1692.72, "text": " day for different questions and problems and issues that I'm facing. You can use different", "tokens": [50688, 786, 337, 819, 1651, 293, 2740, 293, 2663, 300, 286, 478, 7170, 13, 509, 393, 764, 819, 51136], "temperature": 0.0, "avg_logprob": -0.08325220254751352, "compression_ratio": 1.4842105263157894, "no_speech_prob": 0.00370448618195951}, {"id": 234, "seek": 167728, "start": 1692.72, "end": 1698.32, "text": " methodology. So six thinking hats is completely optional. You can just go to chat GPT and type,", "tokens": [51136, 24850, 13, 407, 2309, 1953, 20549, 307, 2584, 17312, 13, 509, 393, 445, 352, 281, 5081, 26039, 51, 293, 2010, 11, 51416], "temperature": 0.0, "avg_logprob": -0.08325220254751352, "compression_ratio": 1.4842105263157894, "no_speech_prob": 0.00370448618195951}, {"id": 235, "seek": 169832, "start": 1699.04, "end": 1706.0, "text": " help me brainstorm ideas for present, for marketing campaign, for help me write", "tokens": [50400, 854, 385, 35245, 3487, 337, 1974, 11, 337, 6370, 5129, 11, 337, 854, 385, 2464, 50748], "temperature": 0.0, "avg_logprob": -0.18220181300722318, "compression_ratio": 1.5421686746987953, "no_speech_prob": 0.010979664511978626}, {"id": 236, "seek": 169832, "start": 1709.76, "end": 1718.1599999999999, "text": " ideas for an article that I'm writing. And it will give you some ideas. And then you can ask", "tokens": [50936, 3487, 337, 364, 7222, 300, 286, 478, 3579, 13, 400, 309, 486, 976, 291, 512, 3487, 13, 400, 550, 291, 393, 1029, 51356], "temperature": 0.0, "avg_logprob": -0.18220181300722318, "compression_ratio": 1.5421686746987953, "no_speech_prob": 0.010979664511978626}, {"id": 237, "seek": 169832, "start": 1718.1599999999999, "end": 1724.24, "text": " to elaborate and basically continue that conversation to get more valuable results.", "tokens": [51356, 281, 20945, 293, 1936, 2354, 300, 3761, 281, 483, 544, 8263, 3542, 13, 51660], "temperature": 0.0, "avg_logprob": -0.18220181300722318, "compression_ratio": 1.5421686746987953, "no_speech_prob": 0.010979664511978626}, {"id": 238, "seek": 172424, "start": 1724.96, "end": 1733.52, "text": " One important thing here to note is that if you want to steer how chat GPT gives you answer,", "tokens": [50400, 1485, 1021, 551, 510, 281, 3637, 307, 300, 498, 291, 528, 281, 30814, 577, 5081, 26039, 51, 2709, 291, 1867, 11, 50828], "temperature": 0.0, "avg_logprob": -0.19056828816731772, "compression_ratio": 1.4274809160305344, "no_speech_prob": 0.0018097972497344017}, {"id": 239, "seek": 172424, "start": 1733.52, "end": 1745.44, "text": " if you have GPT account, I suggest to setting up custom instructions. So if we go to chat GPT,", "tokens": [50828, 498, 291, 362, 26039, 51, 2696, 11, 286, 3402, 281, 3287, 493, 2375, 9415, 13, 407, 498, 321, 352, 281, 5081, 26039, 51, 11, 51424], "temperature": 0.0, "avg_logprob": -0.19056828816731772, "compression_ratio": 1.4274809160305344, "no_speech_prob": 0.0018097972497344017}, {"id": 240, "seek": 174544, "start": 1745.44, "end": 1752.88, "text": " you can, so first of all, if you don't have, I highly recommend to create an account", "tokens": [50364, 291, 393, 11, 370, 700, 295, 439, 11, 498, 291, 500, 380, 362, 11, 286, 5405, 2748, 281, 1884, 364, 2696, 50736], "temperature": 0.0, "avg_logprob": -0.11543773568194846, "compression_ratio": 1.5375, "no_speech_prob": 0.01132731419056654}, {"id": 241, "seek": 174544, "start": 1752.88, "end": 1760.24, "text": " in chat GPT, the product itself is free, but you can also subscribe and get a plus subscription,", "tokens": [50736, 294, 5081, 26039, 51, 11, 264, 1674, 2564, 307, 1737, 11, 457, 291, 393, 611, 3022, 293, 483, 257, 1804, 17231, 11, 51104], "temperature": 0.0, "avg_logprob": -0.11543773568194846, "compression_ratio": 1.5375, "no_speech_prob": 0.01132731419056654}, {"id": 242, "seek": 174544, "start": 1760.24, "end": 1766.3200000000002, "text": " which gives you access to a more powerful model. But then when I'm talking to chat GPT,", "tokens": [51104, 597, 2709, 291, 2105, 281, 257, 544, 4005, 2316, 13, 583, 550, 562, 286, 478, 1417, 281, 5081, 26039, 51, 11, 51408], "temperature": 0.0, "avg_logprob": -0.11543773568194846, "compression_ratio": 1.5375, "no_speech_prob": 0.01132731419056654}, {"id": 243, "seek": 174544, "start": 1766.3200000000002, "end": 1772.16, "text": " instead of getting generic answers, it is very useful to use this thing called custom instructions.", "tokens": [51408, 2602, 295, 1242, 19577, 6338, 11, 309, 307, 588, 4420, 281, 764, 341, 551, 1219, 2375, 9415, 13, 51700], "temperature": 0.0, "avg_logprob": -0.11543773568194846, "compression_ratio": 1.5375, "no_speech_prob": 0.01132731419056654}, {"id": 244, "seek": 177216, "start": 1772.16, "end": 1778.3200000000002, "text": " So if you click on your profile, go to custom instructions, and you can add some information", "tokens": [50364, 407, 498, 291, 2052, 322, 428, 7964, 11, 352, 281, 2375, 9415, 11, 293, 291, 393, 909, 512, 1589, 50672], "temperature": 0.0, "avg_logprob": -0.0727956605994183, "compression_ratio": 1.5854700854700854, "no_speech_prob": 0.0033218127209693193}, {"id": 245, "seek": 177216, "start": 1778.3200000000002, "end": 1785.44, "text": " here. So I will share the custom instructions that I'm using on this slide. You can change it", "tokens": [50672, 510, 13, 407, 286, 486, 2073, 264, 2375, 9415, 300, 286, 478, 1228, 322, 341, 4137, 13, 509, 393, 1319, 309, 51028], "temperature": 0.0, "avg_logprob": -0.0727956605994183, "compression_ratio": 1.5854700854700854, "no_speech_prob": 0.0033218127209693193}, {"id": 246, "seek": 177216, "start": 1786.0, "end": 1792.5600000000002, "text": " whatever way you want. But the value of this is you can steer how the answers are being generated.", "tokens": [51056, 2035, 636, 291, 528, 13, 583, 264, 2158, 295, 341, 307, 291, 393, 30814, 577, 264, 6338, 366, 885, 10833, 13, 51384], "temperature": 0.0, "avg_logprob": -0.0727956605994183, "compression_ratio": 1.5854700854700854, "no_speech_prob": 0.0033218127209693193}, {"id": 247, "seek": 177216, "start": 1792.5600000000002, "end": 1798.0800000000002, "text": " For example, for me, the important thing is for it to respond concisely and be blunt,", "tokens": [51384, 1171, 1365, 11, 337, 385, 11, 264, 1021, 551, 307, 337, 309, 281, 4196, 1588, 271, 736, 293, 312, 32246, 11, 51660], "temperature": 0.0, "avg_logprob": -0.0727956605994183, "compression_ratio": 1.5854700854700854, "no_speech_prob": 0.0033218127209693193}, {"id": 248, "seek": 179808, "start": 1798.08, "end": 1808.24, "text": " because it usually likes to go into this very long and maybe descriptions of a lot of things.", "tokens": [50364, 570, 309, 2673, 5902, 281, 352, 666, 341, 588, 938, 293, 1310, 24406, 295, 257, 688, 295, 721, 13, 50872], "temperature": 0.0, "avg_logprob": -0.13288493234603133, "compression_ratio": 1.489247311827957, "no_speech_prob": 0.0022843286860734224}, {"id": 249, "seek": 179808, "start": 1808.24, "end": 1815.28, "text": " And you can read through this. In my experience, adding these custom instructions really increases", "tokens": [50872, 400, 291, 393, 1401, 807, 341, 13, 682, 452, 1752, 11, 5127, 613, 2375, 9415, 534, 8637, 51224], "temperature": 0.0, "avg_logprob": -0.13288493234603133, "compression_ratio": 1.489247311827957, "no_speech_prob": 0.0022843286860734224}, {"id": 250, "seek": 179808, "start": 1815.28, "end": 1820.6399999999999, "text": " the quality of response and increases the value that I'm getting from using chat GPT", "tokens": [51224, 264, 3125, 295, 4134, 293, 8637, 264, 2158, 300, 286, 478, 1242, 490, 1228, 5081, 26039, 51, 51492], "temperature": 0.0, "avg_logprob": -0.13288493234603133, "compression_ratio": 1.489247311827957, "no_speech_prob": 0.0022843286860734224}, {"id": 251, "seek": 182064, "start": 1821.6000000000001, "end": 1827.3600000000001, "text": " almost two times. So highly, highly recommend using it. And you can copy this from the slide", "tokens": [50412, 1920, 732, 1413, 13, 407, 5405, 11, 5405, 2748, 1228, 309, 13, 400, 291, 393, 5055, 341, 490, 264, 4137, 50700], "temperature": 0.0, "avg_logprob": -0.1362936600394871, "compression_ratio": 1.483695652173913, "no_speech_prob": 0.008571518585085869}, {"id": 252, "seek": 182064, "start": 1827.3600000000001, "end": 1839.2, "text": " and use in your own GPT. Next use case is communication. So I already mentioned that", "tokens": [50700, 293, 764, 294, 428, 1065, 26039, 51, 13, 3087, 764, 1389, 307, 6101, 13, 407, 286, 1217, 2835, 300, 51292], "temperature": 0.0, "avg_logprob": -0.1362936600394871, "compression_ratio": 1.483695652173913, "no_speech_prob": 0.008571518585085869}, {"id": 253, "seek": 182064, "start": 1839.2, "end": 1847.5200000000002, "text": " GPT is great for writing any kind of emails, posts, or translating information. But it is also,", "tokens": [51292, 26039, 51, 307, 869, 337, 3579, 604, 733, 295, 12524, 11, 12300, 11, 420, 35030, 1589, 13, 583, 309, 307, 611, 11, 51708], "temperature": 0.0, "avg_logprob": -0.1362936600394871, "compression_ratio": 1.483695652173913, "no_speech_prob": 0.008571518585085869}, {"id": 254, "seek": 184752, "start": 1847.52, "end": 1855.6, "text": " you can also ask GPT to write in a specific style. And one thing that I personally found very,", "tokens": [50364, 291, 393, 611, 1029, 26039, 51, 281, 2464, 294, 257, 2685, 3758, 13, 400, 472, 551, 300, 286, 5665, 1352, 588, 11, 50768], "temperature": 0.0, "avg_logprob": -0.11947691064131888, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0037040531169623137}, {"id": 255, "seek": 184752, "start": 1855.6, "end": 1864.56, "text": " very exciting and very useful is to use GPT to visualize conversation. So this small screenshot", "tokens": [50768, 588, 4670, 293, 588, 4420, 307, 281, 764, 26039, 51, 281, 23273, 3761, 13, 407, 341, 1359, 27712, 51216], "temperature": 0.0, "avg_logprob": -0.11947691064131888, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0037040531169623137}, {"id": 256, "seek": 184752, "start": 1864.56, "end": 1869.2, "text": " on the right is a small application that developed. So this is not part of chat GPT. It's not", "tokens": [51216, 322, 264, 558, 307, 257, 1359, 3861, 300, 4743, 13, 407, 341, 307, 406, 644, 295, 5081, 26039, 51, 13, 467, 311, 406, 51448], "temperature": 0.0, "avg_logprob": -0.11947691064131888, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0037040531169623137}, {"id": 257, "seek": 184752, "start": 1869.2, "end": 1876.16, "text": " something you get when you sign up. But this is just like a product, that's very, very small", "tokens": [51448, 746, 291, 483, 562, 291, 1465, 493, 13, 583, 341, 307, 445, 411, 257, 1674, 11, 300, 311, 588, 11, 588, 1359, 51796], "temperature": 0.0, "avg_logprob": -0.11947691064131888, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0037040531169623137}, {"id": 258, "seek": 187616, "start": 1876.16, "end": 1882.5600000000002, "text": " product that I built to showcase what's possible. And I'm sure there will be or there probably are", "tokens": [50364, 1674, 300, 286, 3094, 281, 20388, 437, 311, 1944, 13, 400, 286, 478, 988, 456, 486, 312, 420, 456, 1391, 366, 50684], "temperature": 0.0, "avg_logprob": -0.11757286646032847, "compression_ratio": 1.5506072874493928, "no_speech_prob": 0.0034283685963600874}, {"id": 259, "seek": 187616, "start": 1882.5600000000002, "end": 1889.1200000000001, "text": " already similar products that you can find online. Maybe some of them are paid, but I think the value", "tokens": [50684, 1217, 2531, 3383, 300, 291, 393, 915, 2950, 13, 2704, 512, 295, 552, 366, 4835, 11, 457, 286, 519, 264, 2158, 51012], "temperature": 0.0, "avg_logprob": -0.11757286646032847, "compression_ratio": 1.5506072874493928, "no_speech_prob": 0.0034283685963600874}, {"id": 260, "seek": 187616, "start": 1889.1200000000001, "end": 1899.8400000000001, "text": " is very clear. So on the screenshot, what's happening is I'm using data from my Telegram", "tokens": [51012, 307, 588, 1850, 13, 407, 322, 264, 27712, 11, 437, 311, 2737, 307, 286, 478, 1228, 1412, 490, 452, 14889, 1342, 51548], "temperature": 0.0, "avg_logprob": -0.11757286646032847, "compression_ratio": 1.5506072874493928, "no_speech_prob": 0.0034283685963600874}, {"id": 261, "seek": 187616, "start": 1899.8400000000001, "end": 1905.92, "text": " group channel. And you can use it for Slack or Discord or email threads with a lot of people.", "tokens": [51548, 1594, 2269, 13, 400, 291, 393, 764, 309, 337, 37211, 420, 32623, 420, 3796, 19314, 365, 257, 688, 295, 561, 13, 51852], "temperature": 0.0, "avg_logprob": -0.11757286646032847, "compression_ratio": 1.5506072874493928, "no_speech_prob": 0.0034283685963600874}, {"id": 262, "seek": 190616, "start": 1906.8000000000002, "end": 1914.8000000000002, "text": " And then in the screenshots, every square is a person and that's their name. Every star is a", "tokens": [50396, 400, 550, 294, 264, 40661, 11, 633, 3732, 307, 257, 954, 293, 300, 311, 641, 1315, 13, 2048, 3543, 307, 257, 50796], "temperature": 0.0, "avg_logprob": -0.11579026116265191, "compression_ratio": 1.5775862068965518, "no_speech_prob": 0.0003857521805912256}, {"id": 263, "seek": 190616, "start": 1914.8000000000002, "end": 1922.48, "text": " topic that is being discussed. And every line is a specific message regarding that topic coming", "tokens": [50796, 4829, 300, 307, 885, 7152, 13, 400, 633, 1622, 307, 257, 2685, 3636, 8595, 300, 4829, 1348, 51180], "temperature": 0.0, "avg_logprob": -0.11579026116265191, "compression_ratio": 1.5775862068965518, "no_speech_prob": 0.0003857521805912256}, {"id": 264, "seek": 190616, "start": 1922.48, "end": 1927.3600000000001, "text": " from a specific user. So if I have a group channel in Telegram with maybe 100 people,", "tokens": [51180, 490, 257, 2685, 4195, 13, 407, 498, 286, 362, 257, 1594, 2269, 294, 14889, 1342, 365, 1310, 2319, 561, 11, 51424], "temperature": 0.0, "avg_logprob": -0.11579026116265191, "compression_ratio": 1.5775862068965518, "no_speech_prob": 0.0003857521805912256}, {"id": 265, "seek": 190616, "start": 1927.3600000000001, "end": 1933.28, "text": " and I didn't open it for a month, and there's thousands of messages, it would take me hours", "tokens": [51424, 293, 286, 994, 380, 1269, 309, 337, 257, 1618, 11, 293, 456, 311, 5383, 295, 7897, 11, 309, 576, 747, 385, 2496, 51720], "temperature": 0.0, "avg_logprob": -0.11579026116265191, "compression_ratio": 1.5775862068965518, "no_speech_prob": 0.0003857521805912256}, {"id": 266, "seek": 193328, "start": 1933.28, "end": 1941.2, "text": " to read through that. But using something like this, using large language models to summarize", "tokens": [50364, 281, 1401, 807, 300, 13, 583, 1228, 746, 411, 341, 11, 1228, 2416, 2856, 5245, 281, 20858, 50760], "temperature": 0.0, "avg_logprob": -0.06903135015609417, "compression_ratio": 1.640495867768595, "no_speech_prob": 0.0035367778036743402}, {"id": 267, "seek": 193328, "start": 1941.2, "end": 1947.92, "text": " and then visualize data will help me to understand what's being discussed in that group. And I can", "tokens": [50760, 293, 550, 23273, 1412, 486, 854, 385, 281, 1223, 437, 311, 885, 7152, 294, 300, 1594, 13, 400, 286, 393, 51096], "temperature": 0.0, "avg_logprob": -0.06903135015609417, "compression_ratio": 1.640495867768595, "no_speech_prob": 0.0035367778036743402}, {"id": 268, "seek": 193328, "start": 1947.92, "end": 1955.76, "text": " just skim and scan this image, spend five minutes, and I'm already up to date. And if I find something", "tokens": [51096, 445, 1110, 332, 293, 11049, 341, 3256, 11, 3496, 1732, 2077, 11, 293, 286, 478, 1217, 493, 281, 4002, 13, 400, 498, 286, 915, 746, 51488], "temperature": 0.0, "avg_logprob": -0.06903135015609417, "compression_ratio": 1.640495867768595, "no_speech_prob": 0.0035367778036743402}, {"id": 269, "seek": 193328, "start": 1955.76, "end": 1961.84, "text": " that is useful or interesting for me, I can click on this line and it will open the specific message.", "tokens": [51488, 300, 307, 4420, 420, 1880, 337, 385, 11, 286, 393, 2052, 322, 341, 1622, 293, 309, 486, 1269, 264, 2685, 3636, 13, 51792], "temperature": 0.0, "avg_logprob": -0.06903135015609417, "compression_ratio": 1.640495867768595, "no_speech_prob": 0.0035367778036743402}, {"id": 270, "seek": 196184, "start": 1961.84, "end": 1967.04, "text": " So this is one of the use cases that I kind of over many months I developed for myself. And this", "tokens": [50364, 407, 341, 307, 472, 295, 264, 764, 3331, 300, 286, 733, 295, 670, 867, 2493, 286, 4743, 337, 2059, 13, 400, 341, 50624], "temperature": 0.0, "avg_logprob": -0.127228883596567, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.0005272254929877818}, {"id": 271, "seek": 196184, "start": 1967.04, "end": 1972.32, "text": " really saves hours because I have a lot of different communication channels, a lot of social media", "tokens": [50624, 534, 19155, 2496, 570, 286, 362, 257, 688, 295, 819, 6101, 9235, 11, 257, 688, 295, 2093, 3021, 50888], "temperature": 0.0, "avg_logprob": -0.127228883596567, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.0005272254929877818}, {"id": 272, "seek": 196184, "start": 1973.28, "end": 1979.4399999999998, "text": " kind of comments, and it takes time, takes too much time if I try to read all of those.", "tokens": [50936, 733, 295, 3053, 11, 293, 309, 2516, 565, 11, 2516, 886, 709, 565, 498, 286, 853, 281, 1401, 439, 295, 729, 13, 51244], "temperature": 0.0, "avg_logprob": -0.127228883596567, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.0005272254929877818}, {"id": 273, "seek": 196184, "start": 1979.4399999999998, "end": 1987.76, "text": " I just don't have time to do anything else. I will show another example is related to", "tokens": [51244, 286, 445, 500, 380, 362, 565, 281, 360, 1340, 1646, 13, 286, 486, 855, 1071, 1365, 307, 4077, 281, 51660], "temperature": 0.0, "avg_logprob": -0.127228883596567, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.0005272254929877818}, {"id": 274, "seek": 198776, "start": 1987.76, "end": 1995.52, "text": " visualization. So one of the problems, one of the drawbacks of GPT and large language models that", "tokens": [50364, 25801, 13, 407, 472, 295, 264, 2740, 11, 472, 295, 264, 2642, 17758, 295, 26039, 51, 293, 2416, 2856, 5245, 300, 50752], "temperature": 0.0, "avg_logprob": -0.08785311877727509, "compression_ratio": 1.4656084656084656, "no_speech_prob": 0.0024335896596312523}, {"id": 275, "seek": 198776, "start": 1995.52, "end": 2002.16, "text": " you will probably identify and realize very quickly when you start using it is that they're", "tokens": [50752, 291, 486, 1391, 5876, 293, 4325, 588, 2661, 562, 291, 722, 1228, 309, 307, 300, 436, 434, 51084], "temperature": 0.0, "avg_logprob": -0.08785311877727509, "compression_ratio": 1.4656084656084656, "no_speech_prob": 0.0024335896596312523}, {"id": 276, "seek": 198776, "start": 2002.16, "end": 2010.32, "text": " pretty bad at analytical and math tasks. So LLMs cannot really compute or count complex", "tokens": [51084, 1238, 1578, 412, 29579, 293, 5221, 9608, 13, 407, 441, 43, 26386, 2644, 534, 14722, 420, 1207, 3997, 51492], "temperature": 0.0, "avg_logprob": -0.08785311877727509, "compression_ratio": 1.4656084656084656, "no_speech_prob": 0.0024335896596312523}, {"id": 277, "seek": 201032, "start": 2011.04, "end": 2018.56, "text": " mathematical questions or problems. But what they can do, they can write code. And when they write", "tokens": [50400, 18894, 1651, 420, 2740, 13, 583, 437, 436, 393, 360, 11, 436, 393, 2464, 3089, 13, 400, 562, 436, 2464, 50776], "temperature": 0.0, "avg_logprob": -0.10266459782918294, "compression_ratio": 1.7431192660550459, "no_speech_prob": 0.02227717451751232}, {"id": 278, "seek": 201032, "start": 2018.56, "end": 2024.8799999999999, "text": " and then execute computer code, this code is always giving you correct result because computer is", "tokens": [50776, 293, 550, 14483, 3820, 3089, 11, 341, 3089, 307, 1009, 2902, 291, 3006, 1874, 570, 3820, 307, 51092], "temperature": 0.0, "avg_logprob": -0.10266459782918294, "compression_ratio": 1.7431192660550459, "no_speech_prob": 0.02227717451751232}, {"id": 279, "seek": 201032, "start": 2024.8799999999999, "end": 2030.08, "text": " basically just a, it is a computer, it computes. So whatever code you put, you always get the", "tokens": [51092, 1936, 445, 257, 11, 309, 307, 257, 3820, 11, 309, 715, 1819, 13, 407, 2035, 3089, 291, 829, 11, 291, 1009, 483, 264, 51352], "temperature": 0.0, "avg_logprob": -0.10266459782918294, "compression_ratio": 1.7431192660550459, "no_speech_prob": 0.02227717451751232}, {"id": 280, "seek": 201032, "start": 2030.08, "end": 2037.12, "text": " correct mathematical results. So if I ask GPT to solve me maybe like an integral, it will", "tokens": [51352, 3006, 18894, 3542, 13, 407, 498, 286, 1029, 26039, 51, 281, 5039, 385, 1310, 411, 364, 11573, 11, 309, 486, 51704], "temperature": 0.0, "avg_logprob": -0.10266459782918294, "compression_ratio": 1.7431192660550459, "no_speech_prob": 0.02227717451751232}, {"id": 281, "seek": 203712, "start": 2037.12, "end": 2042.0, "text": " most likely fail. But if I ask it to write a computer program that solves the same problem,", "tokens": [50364, 881, 3700, 3061, 13, 583, 498, 286, 1029, 309, 281, 2464, 257, 3820, 1461, 300, 39890, 264, 912, 1154, 11, 50608], "temperature": 0.0, "avg_logprob": -0.10858084938742897, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.0013880586484447122}, {"id": 282, "seek": 203712, "start": 2042.56, "end": 2049.68, "text": " it will be, it will be correct. And solving integral may be not very useful or relevant for most of,", "tokens": [50636, 309, 486, 312, 11, 309, 486, 312, 3006, 13, 400, 12606, 11573, 815, 312, 406, 588, 4420, 420, 7340, 337, 881, 295, 11, 50992], "temperature": 0.0, "avg_logprob": -0.10858084938742897, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.0013880586484447122}, {"id": 283, "seek": 203712, "start": 2050.72, "end": 2057.8399999999997, "text": " most of you or at least I don't do it daily. But I find this feature very, very useful when it", "tokens": [51044, 881, 295, 291, 420, 412, 1935, 286, 500, 380, 360, 309, 5212, 13, 583, 286, 915, 341, 4111, 588, 11, 588, 4420, 562, 309, 51400], "temperature": 0.0, "avg_logprob": -0.10858084938742897, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.0013880586484447122}, {"id": 284, "seek": 203712, "start": 2057.8399999999997, "end": 2065.2799999999997, "text": " comes to data analysis. And I want to show an example. I have a spreadsheet, which is a sales", "tokens": [51400, 1487, 281, 1412, 5215, 13, 400, 286, 528, 281, 855, 364, 1365, 13, 286, 362, 257, 27733, 11, 597, 307, 257, 5763, 51772], "temperature": 0.0, "avg_logprob": -0.10858084938742897, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.0013880586484447122}, {"id": 285, "seek": 206528, "start": 2065.28, "end": 2073.76, "text": " data related to motorcycles and cars. And it goes into, there's a lot of, there's a lot of", "tokens": [50364, 1412, 4077, 281, 46813, 293, 5163, 13, 400, 309, 1709, 666, 11, 456, 311, 257, 688, 295, 11, 456, 311, 257, 688, 295, 50788], "temperature": 0.0, "avg_logprob": -0.0942733817630344, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.0024721594527363777}, {"id": 286, "seek": 206528, "start": 2073.76, "end": 2082.1600000000003, "text": " data. There's like sales number, customer name, address and country and all of that.", "tokens": [50788, 1412, 13, 821, 311, 411, 5763, 1230, 11, 5474, 1315, 11, 2985, 293, 1941, 293, 439, 295, 300, 13, 51208], "temperature": 0.0, "avg_logprob": -0.0942733817630344, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.0024721594527363777}, {"id": 287, "seek": 206528, "start": 2082.7200000000003, "end": 2092.1600000000003, "text": " So what if I want to create some kind of, what if I want to get insights from this data?", "tokens": [51236, 407, 437, 498, 286, 528, 281, 1884, 512, 733, 295, 11, 437, 498, 286, 528, 281, 483, 14310, 490, 341, 1412, 30, 51708], "temperature": 0.0, "avg_logprob": -0.0942733817630344, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.0024721594527363777}, {"id": 288, "seek": 209216, "start": 2092.16, "end": 2099.7599999999998, "text": " For example, I can upload this file. I just upload this file to chat GPT. And I ask it,", "tokens": [50364, 1171, 1365, 11, 286, 393, 6580, 341, 3991, 13, 286, 445, 6580, 341, 3991, 281, 5081, 26039, 51, 13, 400, 286, 1029, 309, 11, 50744], "temperature": 0.0, "avg_logprob": -0.10177819101434005, "compression_ratio": 1.5965665236051503, "no_speech_prob": 0.0022864837665110826}, {"id": 289, "seek": 209216, "start": 2099.7599999999998, "end": 2105.92, "text": " draw me a histogram showing where the goods are shipped, the city and also use different colors", "tokens": [50744, 2642, 385, 257, 49816, 4099, 689, 264, 10179, 366, 25312, 11, 264, 2307, 293, 611, 764, 819, 4577, 51052], "temperature": 0.0, "avg_logprob": -0.10177819101434005, "compression_ratio": 1.5965665236051503, "no_speech_prob": 0.0022864837665110826}, {"id": 290, "seek": 209216, "start": 2105.92, "end": 2111.92, "text": " for different types of goods. And this is what I get. So it takes me, it really literally took me", "tokens": [51052, 337, 819, 3467, 295, 10179, 13, 400, 341, 307, 437, 286, 483, 13, 407, 309, 2516, 385, 11, 309, 534, 3736, 1890, 385, 51352], "temperature": 0.0, "avg_logprob": -0.10177819101434005, "compression_ratio": 1.5965665236051503, "no_speech_prob": 0.0022864837665110826}, {"id": 291, "seek": 209216, "start": 2112.56, "end": 2120.56, "text": " 30 seconds to wait until GPT completes it and gives me this picture. And this is actually,", "tokens": [51384, 2217, 3949, 281, 1699, 1826, 26039, 51, 36362, 309, 293, 2709, 385, 341, 3036, 13, 400, 341, 307, 767, 11, 51784], "temperature": 0.0, "avg_logprob": -0.10177819101434005, "compression_ratio": 1.5965665236051503, "no_speech_prob": 0.0022864837665110826}, {"id": 292, "seek": 212056, "start": 2120.56, "end": 2126.0, "text": " I can also see the code that it wrote. So this is actually what it did. And this is a Python code", "tokens": [50364, 286, 393, 611, 536, 264, 3089, 300, 309, 4114, 13, 407, 341, 307, 767, 437, 309, 630, 13, 400, 341, 307, 257, 15329, 3089, 50636], "temperature": 0.0, "avg_logprob": -0.16212177276611328, "compression_ratio": 1.6235955056179776, "no_speech_prob": 0.0016219589160755277}, {"id": 293, "seek": 212056, "start": 2126.0, "end": 2134.08, "text": " that analyzes the spreadsheet, takes specific data from it and draw draws a histogram. And if you", "tokens": [50636, 300, 6459, 12214, 264, 27733, 11, 2516, 2685, 1412, 490, 309, 293, 2642, 20045, 257, 49816, 13, 400, 498, 291, 51040], "temperature": 0.0, "avg_logprob": -0.16212177276611328, "compression_ratio": 1.6235955056179776, "no_speech_prob": 0.0016219589160755277}, {"id": 294, "seek": 212056, "start": 2134.08, "end": 2140.88, "text": " if you look closely, it is, it is, it is doing exactly what I asked. So it has city name like", "tokens": [51040, 498, 291, 574, 8185, 11, 309, 307, 11, 309, 307, 11, 309, 307, 884, 2293, 437, 286, 2351, 13, 407, 309, 575, 2307, 1315, 411, 51380], "temperature": 0.0, "avg_logprob": -0.16212177276611328, "compression_ratio": 1.6235955056179776, "no_speech_prob": 0.0016219589160755277}, {"id": 295, "seek": 214088, "start": 2140.88, "end": 2150.48, "text": " Leo, New York city and so on. And it shows motorcycles in light green cars in dark green.", "tokens": [50364, 19344, 11, 1873, 3609, 2307, 293, 370, 322, 13, 400, 309, 3110, 46813, 294, 1442, 3092, 5163, 294, 2877, 3092, 13, 50844], "temperature": 0.0, "avg_logprob": -0.14052103643547997, "compression_ratio": 1.4748603351955307, "no_speech_prob": 0.03673437610268593}, {"id": 296, "seek": 214088, "start": 2150.48, "end": 2156.7200000000003, "text": " And I can actually keep going. I can ask, follow up questions. So for example,", "tokens": [50844, 400, 286, 393, 767, 1066, 516, 13, 286, 393, 1029, 11, 1524, 493, 1651, 13, 407, 337, 1365, 11, 51156], "temperature": 0.0, "avg_logprob": -0.14052103643547997, "compression_ratio": 1.4748603351955307, "no_speech_prob": 0.03673437610268593}, {"id": 297, "seek": 214088, "start": 2158.1600000000003, "end": 2169.36, "text": " I can ask it like, what was the average price for all of the goods? And it will do the same. It", "tokens": [51228, 286, 393, 1029, 309, 411, 11, 437, 390, 264, 4274, 3218, 337, 439, 295, 264, 10179, 30, 400, 309, 486, 360, 264, 912, 13, 467, 51788], "temperature": 0.0, "avg_logprob": -0.14052103643547997, "compression_ratio": 1.4748603351955307, "no_speech_prob": 0.03673437610268593}, {"id": 298, "seek": 216936, "start": 2169.36, "end": 2177.36, "text": " will, it will also, we can actually see how, how it's writing code. It will, it will make mistakes.", "tokens": [50364, 486, 11, 309, 486, 611, 11, 321, 393, 767, 536, 577, 11, 577, 309, 311, 3579, 3089, 13, 467, 486, 11, 309, 486, 652, 8038, 13, 50764], "temperature": 0.0, "avg_logprob": -0.10204757262613172, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.0008554947562515736}, {"id": 299, "seek": 216936, "start": 2177.36, "end": 2183.84, "text": " It will write, it will do bugs, but then eventually it will correct itself. And this is the final", "tokens": [50764, 467, 486, 2464, 11, 309, 486, 360, 15120, 11, 457, 550, 4728, 309, 486, 3006, 2564, 13, 400, 341, 307, 264, 2572, 51088], "temperature": 0.0, "avg_logprob": -0.10204757262613172, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.0008554947562515736}, {"id": 300, "seek": 216936, "start": 2183.84, "end": 2188.8, "text": " result that I get. I mean, this is maybe a simple question. I can just do it in Excel, but I can", "tokens": [51088, 1874, 300, 286, 483, 13, 286, 914, 11, 341, 307, 1310, 257, 2199, 1168, 13, 286, 393, 445, 360, 309, 294, 19060, 11, 457, 286, 393, 51336], "temperature": 0.0, "avg_logprob": -0.10204757262613172, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.0008554947562515736}, {"id": 301, "seek": 216936, "start": 2188.8, "end": 2194.8, "text": " ask it to do much more complex stuff. I can ask it to work on large files to do complex analysis.", "tokens": [51336, 1029, 309, 281, 360, 709, 544, 3997, 1507, 13, 286, 393, 1029, 309, 281, 589, 322, 2416, 7098, 281, 360, 3997, 5215, 13, 51636], "temperature": 0.0, "avg_logprob": -0.10204757262613172, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.0008554947562515736}, {"id": 302, "seek": 219480, "start": 2194.8, "end": 2203.92, "text": " And the goal of this example is to show that whatever tasks that usually you have to hire a", "tokens": [50364, 400, 264, 3387, 295, 341, 1365, 307, 281, 855, 300, 2035, 9608, 300, 2673, 291, 362, 281, 11158, 257, 50820], "temperature": 0.0, "avg_logprob": -0.16267660294456043, "compression_ratio": 1.572072072072072, "no_speech_prob": 0.0010982603998854756}, {"id": 303, "seek": 219480, "start": 2203.92, "end": 2209.36, "text": " data analyst or ask a software engineer to do for you, now you can do just with", "tokens": [50820, 1412, 19085, 420, 1029, 257, 4722, 11403, 281, 360, 337, 291, 11, 586, 291, 393, 360, 445, 365, 51092], "temperature": 0.0, "avg_logprob": -0.16267660294456043, "compression_ratio": 1.572072072072072, "no_speech_prob": 0.0010982603998854756}, {"id": 304, "seek": 219480, "start": 2210.0, "end": 2215.04, "text": " charge EPT, you can just talk to it and ask it to complete this and you will get results. And this", "tokens": [51124, 4602, 25330, 51, 11, 291, 393, 445, 751, 281, 309, 293, 1029, 309, 281, 3566, 341, 293, 291, 486, 483, 3542, 13, 400, 341, 51376], "temperature": 0.0, "avg_logprob": -0.16267660294456043, "compression_ratio": 1.572072072072072, "no_speech_prob": 0.0010982603998854756}, {"id": 305, "seek": 219480, "start": 2215.04, "end": 2220.0800000000004, "text": " is very, very useful. Really, it saves thousands of dollars sometimes because,", "tokens": [51376, 307, 588, 11, 588, 4420, 13, 4083, 11, 309, 19155, 5383, 295, 3808, 2171, 570, 11, 51628], "temperature": 0.0, "avg_logprob": -0.16267660294456043, "compression_ratio": 1.572072072072072, "no_speech_prob": 0.0010982603998854756}, {"id": 306, "seek": 222008, "start": 2220.96, "end": 2227.2799999999997, "text": " because data scientists are not, are not cheap and GPT costs 20 bucks a month.", "tokens": [50408, 570, 1412, 7708, 366, 406, 11, 366, 406, 7084, 293, 26039, 51, 5497, 945, 11829, 257, 1618, 13, 50724], "temperature": 0.0, "avg_logprob": -0.14362287521362305, "compression_ratio": 1.3829787234042554, "no_speech_prob": 0.0004727146588265896}, {"id": 307, "seek": 222008, "start": 2230.48, "end": 2242.24, "text": " Okay. Moving, moving next. Another useful feature of GPT is that it can read and analyze", "tokens": [50884, 1033, 13, 14242, 11, 2684, 958, 13, 3996, 4420, 4111, 295, 26039, 51, 307, 300, 309, 393, 1401, 293, 12477, 51472], "temperature": 0.0, "avg_logprob": -0.14362287521362305, "compression_ratio": 1.3829787234042554, "no_speech_prob": 0.0004727146588265896}, {"id": 308, "seek": 222008, "start": 2242.24, "end": 2249.7599999999998, "text": " visual data. And this example that I'm showing here on the right is I basically took a photo", "tokens": [51472, 5056, 1412, 13, 400, 341, 1365, 300, 286, 478, 4099, 510, 322, 264, 558, 307, 286, 1936, 1890, 257, 5052, 51848], "temperature": 0.0, "avg_logprob": -0.14362287521362305, "compression_ratio": 1.3829787234042554, "no_speech_prob": 0.0004727146588265896}, {"id": 309, "seek": 224976, "start": 2249.76, "end": 2256.48, "text": " with my iPhone of the drawing that I made on my whiteboard here on the, on the, on the wall.", "tokens": [50364, 365, 452, 7252, 295, 264, 6316, 300, 286, 1027, 322, 452, 2418, 3787, 510, 322, 264, 11, 322, 264, 11, 322, 264, 2929, 13, 50700], "temperature": 0.0, "avg_logprob": -0.13352312865080657, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.002082239603623748}, {"id": 310, "seek": 224976, "start": 2256.48, "end": 2263.84, "text": " So I just, I took a pencil, I draw something on, on, on the whiteboard. And then I asked GPT,", "tokens": [50700, 407, 286, 445, 11, 286, 1890, 257, 10985, 11, 286, 2642, 746, 322, 11, 322, 11, 322, 264, 2418, 3787, 13, 400, 550, 286, 2351, 26039, 51, 11, 51068], "temperature": 0.0, "avg_logprob": -0.13352312865080657, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.002082239603623748}, {"id": 311, "seek": 224976, "start": 2263.84, "end": 2268.8, "text": " please use this diagram and write me a structure outline for the presentation. So this is what I", "tokens": [51068, 1767, 764, 341, 10686, 293, 2464, 385, 257, 3877, 16387, 337, 264, 5860, 13, 407, 341, 307, 437, 286, 51316], "temperature": 0.0, "avg_logprob": -0.13352312865080657, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.002082239603623748}, {"id": 312, "seek": 224976, "start": 2268.8, "end": 2275.5200000000004, "text": " had just thinking on, on, on, with, with my pencil on the whiteboard. And this is what I, sorry.", "tokens": [51316, 632, 445, 1953, 322, 11, 322, 11, 322, 11, 365, 11, 365, 452, 10985, 322, 264, 2418, 3787, 13, 400, 341, 307, 437, 286, 11, 2597, 13, 51652], "temperature": 0.0, "avg_logprob": -0.13352312865080657, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.002082239603623748}, {"id": 313, "seek": 227552, "start": 2276.24, "end": 2283.52, "text": " And this is what I got. So you can draw pictures, you can make photos, you can ask GPT to identify", "tokens": [50400, 400, 341, 307, 437, 286, 658, 13, 407, 291, 393, 2642, 5242, 11, 291, 393, 652, 5787, 11, 291, 393, 1029, 26039, 51, 281, 5876, 50764], "temperature": 0.0, "avg_logprob": -0.18169397052965666, "compression_ratio": 1.778301886792453, "no_speech_prob": 0.0004044176603201777}, {"id": 314, "seek": 227552, "start": 2283.52, "end": 2289.44, "text": " objects on the photo, you can ask GPT to translate some text that, that, that is on the photo,", "tokens": [50764, 6565, 322, 264, 5052, 11, 291, 393, 1029, 26039, 51, 281, 13799, 512, 2487, 300, 11, 300, 11, 300, 307, 322, 264, 5052, 11, 51060], "temperature": 0.0, "avg_logprob": -0.18169397052965666, "compression_ratio": 1.778301886792453, "no_speech_prob": 0.0004044176603201777}, {"id": 315, "seek": 227552, "start": 2289.44, "end": 2296.8, "text": " you can ask charge EPT to maybe extract information from the picture. And that's the value of", "tokens": [51060, 291, 393, 1029, 4602, 25330, 51, 281, 1310, 8947, 1589, 490, 264, 3036, 13, 400, 300, 311, 264, 2158, 295, 51428], "temperature": 0.0, "avg_logprob": -0.18169397052965666, "compression_ratio": 1.778301886792453, "no_speech_prob": 0.0004044176603201777}, {"id": 316, "seek": 227552, "start": 2296.8, "end": 2303.2, "text": " visual vision models that are, these vision models are only available in the paid version", "tokens": [51428, 5056, 5201, 5245, 300, 366, 11, 613, 5201, 5245, 366, 787, 2435, 294, 264, 4835, 3037, 51748], "temperature": 0.0, "avg_logprob": -0.18169397052965666, "compression_ratio": 1.778301886792453, "no_speech_prob": 0.0004044176603201777}, {"id": 317, "seek": 230320, "start": 2303.2, "end": 2310.3199999999997, "text": " of charge EPT, but if, but it's, it's really worth it. And there's also a free alternative,", "tokens": [50364, 295, 4602, 25330, 51, 11, 457, 498, 11, 457, 309, 311, 11, 309, 311, 534, 3163, 309, 13, 400, 456, 311, 611, 257, 1737, 8535, 11, 50720], "temperature": 0.0, "avg_logprob": -0.22304267883300782, "compression_ratio": 1.602803738317757, "no_speech_prob": 0.0005525132874026895}, {"id": 318, "seek": 230320, "start": 2310.3199999999997, "end": 2319.12, "text": " I will show it later. Another use case is browsing, browsing the web. And I want to recommend a few", "tokens": [50720, 286, 486, 855, 309, 1780, 13, 3996, 764, 1389, 307, 38602, 11, 38602, 264, 3670, 13, 400, 286, 528, 281, 2748, 257, 1326, 51160], "temperature": 0.0, "avg_logprob": -0.22304267883300782, "compression_ratio": 1.602803738317757, "no_speech_prob": 0.0005525132874026895}, {"id": 319, "seek": 230320, "start": 2319.12, "end": 2323.9199999999996, "text": " tools here, because one of the problems with another problem with large language models,", "tokens": [51160, 3873, 510, 11, 570, 472, 295, 264, 2740, 365, 1071, 1154, 365, 2416, 2856, 5245, 11, 51400], "temperature": 0.0, "avg_logprob": -0.22304267883300782, "compression_ratio": 1.602803738317757, "no_speech_prob": 0.0005525132874026895}, {"id": 320, "seek": 230320, "start": 2323.9199999999996, "end": 2328.8799999999997, "text": " in addition to them not being very good at math, is that they,", "tokens": [51400, 294, 4500, 281, 552, 406, 885, 588, 665, 412, 5221, 11, 307, 300, 436, 11, 51648], "temperature": 0.0, "avg_logprob": -0.22304267883300782, "compression_ratio": 1.602803738317757, "no_speech_prob": 0.0005525132874026895}, {"id": 321, "seek": 232888, "start": 2328.96, "end": 2335.36, "text": " by default, they don't have access to most recent information and news. So they don't have access", "tokens": [50368, 538, 7576, 11, 436, 500, 380, 362, 2105, 281, 881, 5162, 1589, 293, 2583, 13, 407, 436, 500, 380, 362, 2105, 50688], "temperature": 0.0, "avg_logprob": -0.3810752775610947, "compression_ratio": 1.7426900584795322, "no_speech_prob": 0.002589545678347349}, {"id": 322, "seek": 232888, "start": 2335.36, "end": 2343.76, "text": " to internet by default. But we can ask either charge EPT to use this web browsing. So I can ask, like,", "tokens": [50688, 281, 4705, 538, 7576, 13, 583, 321, 393, 1029, 2139, 4602, 25330, 51, 281, 764, 341, 3670, 38602, 13, 407, 286, 393, 1029, 11, 411, 11, 51108], "temperature": 0.0, "avg_logprob": -0.3810752775610947, "compression_ratio": 1.7426900584795322, "no_speech_prob": 0.002589545678347349}, {"id": 323, "seek": 232888, "start": 2343.76, "end": 2353.6, "text": " find me most recent news on AI on the web, and it will go and, and it will go and, it will go and", "tokens": [51108, 915, 385, 881, 5162, 2583, 322, 7318, 322, 264, 3670, 11, 293, 309, 486, 352, 293, 11, 293, 309, 486, 352, 293, 11, 309, 486, 352, 293, 51600], "temperature": 0.0, "avg_logprob": -0.3810752775610947, "compression_ratio": 1.7426900584795322, "no_speech_prob": 0.002589545678347349}, {"id": 324, "seek": 235360, "start": 2353.68, "end": 2369.68, "text": " do a Google or Bing search. Sometimes it's being slow. We'll come back to that. But there's also a", "tokens": [50368, 360, 257, 3329, 420, 30755, 3164, 13, 4803, 309, 311, 885, 2964, 13, 492, 603, 808, 646, 281, 300, 13, 583, 456, 311, 611, 257, 51168], "temperature": 0.0, "avg_logprob": -0.11282090346018474, "compression_ratio": 1.3732394366197183, "no_speech_prob": 0.0032720109447836876}, {"id": 325, "seek": 235360, "start": 2370.4, "end": 2380.4, "text": " specific and very specialized products that are free to use that allow to add this capability of", "tokens": [51204, 2685, 293, 588, 19813, 3383, 300, 366, 1737, 281, 764, 300, 2089, 281, 909, 341, 13759, 295, 51704], "temperature": 0.0, "avg_logprob": -0.11282090346018474, "compression_ratio": 1.3732394366197183, "no_speech_prob": 0.0032720109447836876}, {"id": 326, "seek": 238040, "start": 2380.4, "end": 2385.52, "text": " browsing the internet and getting data from the internet to large language models.", "tokens": [50364, 38602, 264, 4705, 293, 1242, 1412, 490, 264, 4705, 281, 2416, 2856, 5245, 13, 50620], "temperature": 0.0, "avg_logprob": -0.1166718628095544, "compression_ratio": 1.6771300448430493, "no_speech_prob": 0.004980531521141529}, {"id": 327, "seek": 238040, "start": 2385.52, "end": 2391.6800000000003, "text": " Two that I want to highlight specifically are Perplexity. Perplexity is really Google but better.", "tokens": [50620, 4453, 300, 286, 528, 281, 5078, 4682, 366, 3026, 18945, 507, 13, 3026, 18945, 507, 307, 534, 3329, 457, 1101, 13, 50928], "temperature": 0.0, "avg_logprob": -0.1166718628095544, "compression_ratio": 1.6771300448430493, "no_speech_prob": 0.004980531521141529}, {"id": 328, "seek": 238040, "start": 2391.6800000000003, "end": 2397.2000000000003, "text": " It allows you to, when you're searching for something, it allows you, instead of getting a list", "tokens": [50928, 467, 4045, 291, 281, 11, 562, 291, 434, 10808, 337, 746, 11, 309, 4045, 291, 11, 2602, 295, 1242, 257, 1329, 51204], "temperature": 0.0, "avg_logprob": -0.1166718628095544, "compression_ratio": 1.6771300448430493, "no_speech_prob": 0.004980531521141529}, {"id": 329, "seek": 238040, "start": 2397.2000000000003, "end": 2408.48, "text": " of links, like you do on Google, it allows you to do a, to get a actual response. So for example,", "tokens": [51204, 295, 6123, 11, 411, 291, 360, 322, 3329, 11, 309, 4045, 291, 281, 360, 257, 11, 281, 483, 257, 3539, 4134, 13, 407, 337, 1365, 11, 51768], "temperature": 0.0, "avg_logprob": -0.1166718628095544, "compression_ratio": 1.6771300448430493, "no_speech_prob": 0.004980531521141529}, {"id": 330, "seek": 240848, "start": 2408.56, "end": 2416.4, "text": " there's a news about new solar system in Milky Way. If I press this, I, I just get an answer", "tokens": [50368, 456, 311, 257, 2583, 466, 777, 7936, 1185, 294, 38465, 9558, 13, 759, 286, 1886, 341, 11, 286, 11, 286, 445, 483, 364, 1867, 50760], "temperature": 0.0, "avg_logprob": -0.09518849849700928, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.0021147760562598705}, {"id": 331, "seek": 240848, "start": 2417.2, "end": 2422.8, "text": " saying that astronomers have, have discovered a new rare solar system in Milky Way and it goes on.", "tokens": [50800, 1566, 300, 43151, 362, 11, 362, 6941, 257, 777, 5892, 7936, 1185, 294, 38465, 9558, 293, 309, 1709, 322, 13, 51080], "temperature": 0.0, "avg_logprob": -0.09518849849700928, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.0021147760562598705}, {"id": 332, "seek": 240848, "start": 2422.8, "end": 2429.6, "text": " But this data, it's not just generated by LLM. This is not hallucination. It comes from, from,", "tokens": [51080, 583, 341, 1412, 11, 309, 311, 406, 445, 10833, 538, 441, 43, 44, 13, 639, 307, 406, 35212, 2486, 13, 467, 1487, 490, 11, 490, 11, 51420], "temperature": 0.0, "avg_logprob": -0.09518849849700928, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.0021147760562598705}, {"id": 333, "seek": 240848, "start": 2429.6, "end": 2434.72, "text": " from specific source. So I can read this. This is an answer for my question. Or I can go to the", "tokens": [51420, 490, 2685, 4009, 13, 407, 286, 393, 1401, 341, 13, 639, 307, 364, 1867, 337, 452, 1168, 13, 1610, 286, 393, 352, 281, 264, 51676], "temperature": 0.0, "avg_logprob": -0.09518849849700928, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.0021147760562598705}, {"id": 334, "seek": 243472, "start": 2434.72, "end": 2439.9199999999996, "text": " source website. And this is associated press article on the same topic. And I can, I can read", "tokens": [50364, 4009, 3144, 13, 400, 341, 307, 6615, 1886, 7222, 322, 264, 912, 4829, 13, 400, 286, 393, 11, 286, 393, 1401, 50624], "temperature": 0.0, "avg_logprob": -0.11132883658775916, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.0026311655528843403}, {"id": 335, "seek": 243472, "start": 2439.9199999999996, "end": 2446.48, "text": " the source. And I'm using Perplexity for a lot of things. Really, it is just in, every time when", "tokens": [50624, 264, 4009, 13, 400, 286, 478, 1228, 3026, 18945, 507, 337, 257, 688, 295, 721, 13, 4083, 11, 309, 307, 445, 294, 11, 633, 565, 562, 50952], "temperature": 0.0, "avg_logprob": -0.11132883658775916, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.0026311655528843403}, {"id": 336, "seek": 243472, "start": 2446.48, "end": 2451.12, "text": " I want to get an answer, if I'm not looking for a website, but for an answer for the question,", "tokens": [50952, 286, 528, 281, 483, 364, 1867, 11, 498, 286, 478, 406, 1237, 337, 257, 3144, 11, 457, 337, 364, 1867, 337, 264, 1168, 11, 51184], "temperature": 0.0, "avg_logprob": -0.11132883658775916, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.0026311655528843403}, {"id": 337, "seek": 243472, "start": 2451.12, "end": 2458.16, "text": " Perplexity works better than Google. For me, almost 100% of times. And it's free. And it has no", "tokens": [51184, 3026, 18945, 507, 1985, 1101, 813, 3329, 13, 1171, 385, 11, 1920, 2319, 4, 295, 1413, 13, 400, 309, 311, 1737, 13, 400, 309, 575, 572, 51536], "temperature": 0.0, "avg_logprob": -0.11132883658775916, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.0026311655528843403}, {"id": 338, "seek": 243472, "start": 2458.16, "end": 2464.64, "text": " ads at least right now, maybe in the future. It also has a paid version that has more features", "tokens": [51536, 10342, 412, 1935, 558, 586, 11, 1310, 294, 264, 2027, 13, 467, 611, 575, 257, 4835, 3037, 300, 575, 544, 4122, 51860], "temperature": 0.0, "avg_logprob": -0.11132883658775916, "compression_ratio": 1.6585365853658536, "no_speech_prob": 0.0026311655528843403}, {"id": 339, "seek": 246464, "start": 2464.64, "end": 2473.04, "text": " to it. But really, this is one of the, one of the best use cases and products built", "tokens": [50364, 281, 309, 13, 583, 534, 11, 341, 307, 472, 295, 264, 11, 472, 295, 264, 1151, 764, 3331, 293, 3383, 3094, 50784], "temperature": 0.0, "avg_logprob": -0.10370901652744838, "compression_ratio": 1.481283422459893, "no_speech_prob": 0.0015710246516391635}, {"id": 340, "seek": 246464, "start": 2474.4, "end": 2481.04, "text": " using artificial intelligence. By the way, GPT also finished. So as you can see, when I asked it", "tokens": [50852, 1228, 11677, 7599, 13, 3146, 264, 636, 11, 26039, 51, 611, 4335, 13, 407, 382, 291, 393, 536, 11, 562, 286, 2351, 309, 51184], "temperature": 0.0, "avg_logprob": -0.10370901652744838, "compression_ratio": 1.481283422459893, "no_speech_prob": 0.0015710246516391635}, {"id": 341, "seek": 246464, "start": 2481.04, "end": 2490.0, "text": " to find more recent news on AI, what it did is it looked for, it did a Bing search. And it found", "tokens": [51184, 281, 915, 544, 5162, 2583, 322, 7318, 11, 437, 309, 630, 307, 309, 2956, 337, 11, 309, 630, 257, 30755, 3164, 13, 400, 309, 1352, 51632], "temperature": 0.0, "avg_logprob": -0.10370901652744838, "compression_ratio": 1.481283422459893, "no_speech_prob": 0.0015710246516391635}, {"id": 342, "seek": 249000, "start": 2490.0, "end": 2498.48, "text": " these articles. So again, this information is not something that GPT hallucinated. It is actually", "tokens": [50364, 613, 11290, 13, 407, 797, 11, 341, 1589, 307, 406, 746, 300, 26039, 51, 35212, 5410, 13, 467, 307, 767, 50788], "temperature": 0.0, "avg_logprob": -0.12059171875910972, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.015418516471982002}, {"id": 343, "seek": 249000, "start": 2498.48, "end": 2508.96, "text": " coming from the source. It is coming from this generative AI tech branch section. So if you feel", "tokens": [50788, 1348, 490, 264, 4009, 13, 467, 307, 1348, 490, 341, 1337, 1166, 7318, 7553, 9819, 3541, 13, 407, 498, 291, 841, 51312], "temperature": 0.0, "avg_logprob": -0.12059171875910972, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.015418516471982002}, {"id": 344, "seek": 249000, "start": 2508.96, "end": 2516.48, "text": " like your chatbot is not using most recent information, I recommend using Perplexity,", "tokens": [51312, 411, 428, 5081, 18870, 307, 406, 1228, 881, 5162, 1589, 11, 286, 2748, 1228, 3026, 18945, 507, 11, 51688], "temperature": 0.0, "avg_logprob": -0.12059171875910972, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.015418516471982002}, {"id": 345, "seek": 251648, "start": 2516.48, "end": 2525.52, "text": " web access for, for, for chat GPT or also Bing search. By the way, Bing has a free version of", "tokens": [50364, 3670, 2105, 337, 11, 337, 11, 337, 5081, 26039, 51, 420, 611, 30755, 3164, 13, 3146, 264, 636, 11, 30755, 575, 257, 1737, 3037, 295, 50816], "temperature": 0.0, "avg_logprob": -0.1855544099713316, "compression_ratio": 1.7109004739336493, "no_speech_prob": 0.012425960041582584}, {"id": 346, "seek": 251648, "start": 2525.52, "end": 2531.68, "text": " GPT for. So if you don't have chat GPT, for some reason, you can use Bing, which is free", "tokens": [50816, 26039, 51, 337, 13, 407, 498, 291, 500, 380, 362, 5081, 26039, 51, 11, 337, 512, 1778, 11, 291, 393, 764, 30755, 11, 597, 307, 1737, 51124], "temperature": 0.0, "avg_logprob": -0.1855544099713316, "compression_ratio": 1.7109004739336493, "no_speech_prob": 0.012425960041582584}, {"id": 347, "seek": 251648, "start": 2533.52, "end": 2539.28, "text": " alternative or actually a free UI free version of charge GPT that anyone can use.", "tokens": [51216, 8535, 420, 767, 257, 1737, 15682, 1737, 3037, 295, 4602, 26039, 51, 300, 2878, 393, 764, 13, 51504], "temperature": 0.0, "avg_logprob": -0.1855544099713316, "compression_ratio": 1.7109004739336493, "no_speech_prob": 0.012425960041582584}, {"id": 348, "seek": 251648, "start": 2539.92, "end": 2545.2, "text": " It doesn't cost anything. It is same quality, same model, same thing. It has access to internet.", "tokens": [51536, 467, 1177, 380, 2063, 1340, 13, 467, 307, 912, 3125, 11, 912, 2316, 11, 912, 551, 13, 467, 575, 2105, 281, 4705, 13, 51800], "temperature": 0.0, "avg_logprob": -0.1855544099713316, "compression_ratio": 1.7109004739336493, "no_speech_prob": 0.012425960041582584}, {"id": 349, "seek": 254520, "start": 2545.7599999999998, "end": 2553.9199999999996, "text": " And it also has a mobile app. So, so yeah, depending on your preferences, this might be", "tokens": [50392, 400, 309, 611, 575, 257, 6013, 724, 13, 407, 11, 370, 1338, 11, 5413, 322, 428, 21910, 11, 341, 1062, 312, 50800], "temperature": 0.0, "avg_logprob": -0.19882025037493026, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0008035941864363849}, {"id": 350, "seek": 254520, "start": 2556.08, "end": 2562.72, "text": " this, this, this, this, this might be a solution or good great thing to, to, to use for you.", "tokens": [50908, 341, 11, 341, 11, 341, 11, 341, 11, 341, 1062, 312, 257, 3827, 420, 665, 869, 551, 281, 11, 281, 11, 281, 764, 337, 291, 13, 51240], "temperature": 0.0, "avg_logprob": -0.19882025037493026, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0008035941864363849}, {"id": 351, "seek": 254520, "start": 2563.9199999999996, "end": 2572.3199999999997, "text": " And there's also GPTs. GPTs is something that was recently created by OpenAI by creator of,", "tokens": [51300, 400, 456, 311, 611, 26039, 33424, 13, 26039, 33424, 307, 746, 300, 390, 3938, 2942, 538, 7238, 48698, 538, 14181, 295, 11, 51720], "temperature": 0.0, "avg_logprob": -0.19882025037493026, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0008035941864363849}, {"id": 352, "seek": 257232, "start": 2572.32, "end": 2578.2400000000002, "text": " by the company that created charge GPT and GPTs is ability to create your own version of GPT", "tokens": [50364, 538, 264, 2237, 300, 2942, 4602, 26039, 51, 293, 26039, 33424, 307, 3485, 281, 1884, 428, 1065, 3037, 295, 26039, 51, 50660], "temperature": 0.0, "avg_logprob": -0.10330694972878636, "compression_ratio": 1.7175925925925926, "no_speech_prob": 0.011148804798722267}, {"id": 353, "seek": 257232, "start": 2578.2400000000002, "end": 2587.28, "text": " that is using your own data. So I will not go into a lot of details here, but I just want to show", "tokens": [50660, 300, 307, 1228, 428, 1065, 1412, 13, 407, 286, 486, 406, 352, 666, 257, 688, 295, 4365, 510, 11, 457, 286, 445, 528, 281, 855, 51112], "temperature": 0.0, "avg_logprob": -0.10330694972878636, "compression_ratio": 1.7175925925925926, "no_speech_prob": 0.011148804798722267}, {"id": 354, "seek": 257232, "start": 2587.28, "end": 2593.1200000000003, "text": " that creating your own GPT is very simple. So if you have a GPT plus subscription,", "tokens": [51112, 300, 4084, 428, 1065, 26039, 51, 307, 588, 2199, 13, 407, 498, 291, 362, 257, 26039, 51, 1804, 17231, 11, 51404], "temperature": 0.0, "avg_logprob": -0.10330694972878636, "compression_ratio": 1.7175925925925926, "no_speech_prob": 0.011148804798722267}, {"id": 355, "seek": 257232, "start": 2593.1200000000003, "end": 2600.1600000000003, "text": " you can go to chat openAI.com slash GPTs and you can create your own GPT that can do anything you", "tokens": [51404, 291, 393, 352, 281, 5081, 1269, 48698, 13, 1112, 17330, 26039, 33424, 293, 291, 393, 1884, 428, 1065, 26039, 51, 300, 393, 360, 1340, 291, 51756], "temperature": 0.0, "avg_logprob": -0.10330694972878636, "compression_ratio": 1.7175925925925926, "no_speech_prob": 0.011148804798722267}, {"id": 356, "seek": 260016, "start": 2600.16, "end": 2606.08, "text": " want. And building this application is easy. You don't need to be software engineer. You can", "tokens": [50364, 528, 13, 400, 2390, 341, 3861, 307, 1858, 13, 509, 500, 380, 643, 281, 312, 4722, 11403, 13, 509, 393, 50660], "temperature": 0.0, "avg_logprob": -0.13712153832117716, "compression_ratio": 1.6322869955156951, "no_speech_prob": 0.004752857144922018}, {"id": 357, "seek": 260016, "start": 2606.08, "end": 2611.3599999999997, "text": " just chat with it. Basically, there's a charge called GPT builder, and it will,", "tokens": [50660, 445, 5081, 365, 309, 13, 8537, 11, 456, 311, 257, 4602, 1219, 26039, 51, 27377, 11, 293, 309, 486, 11, 50924], "temperature": 0.0, "avg_logprob": -0.13712153832117716, "compression_ratio": 1.6322869955156951, "no_speech_prob": 0.004752857144922018}, {"id": 358, "seek": 260016, "start": 2614.24, "end": 2619.2799999999997, "text": " it will, it will, it will generate GPT for you. So let's, let's try something. And this is where", "tokens": [51068, 309, 486, 11, 309, 486, 11, 309, 486, 8460, 26039, 51, 337, 291, 13, 407, 718, 311, 11, 718, 311, 853, 746, 13, 400, 341, 307, 689, 51320], "temperature": 0.0, "avg_logprob": -0.13712153832117716, "compression_ratio": 1.6322869955156951, "no_speech_prob": 0.004752857144922018}, {"id": 359, "seek": 260016, "start": 2619.2799999999997, "end": 2625.68, "text": " we actually going into, into business use cases, because this is both useful for personal, but", "tokens": [51320, 321, 767, 516, 666, 11, 666, 1606, 764, 3331, 11, 570, 341, 307, 1293, 4420, 337, 2973, 11, 457, 51640], "temperature": 0.0, "avg_logprob": -0.13712153832117716, "compression_ratio": 1.6322869955156951, "no_speech_prob": 0.004752857144922018}, {"id": 360, "seek": 262568, "start": 2625.68, "end": 2632.48, "text": " also for business use cases. So for example, I want to build a GPT that converts that,", "tokens": [50364, 611, 337, 1606, 764, 3331, 13, 407, 337, 1365, 11, 286, 528, 281, 1322, 257, 26039, 51, 300, 38874, 300, 11, 50704], "temperature": 0.0, "avg_logprob": -0.10077045077369326, "compression_ratio": 1.484472049689441, "no_speech_prob": 0.0019561927765607834}, {"id": 361, "seek": 262568, "start": 2635.12, "end": 2642.3999999999996, "text": " that creates marketing slogan based, based on the logo.", "tokens": [50836, 300, 7829, 6370, 33052, 2361, 11, 2361, 322, 264, 9699, 13, 51200], "temperature": 0.0, "avg_logprob": -0.10077045077369326, "compression_ratio": 1.484472049689441, "no_speech_prob": 0.0019561927765607834}, {"id": 362, "seek": 262568, "start": 2645.8399999999997, "end": 2652.16, "text": " And this is all I need to know. So the, like the most stunning, the most mind blowing thing here", "tokens": [51372, 400, 341, 307, 439, 286, 643, 281, 458, 13, 407, 264, 11, 411, 264, 881, 18550, 11, 264, 881, 1575, 15068, 551, 510, 51688], "temperature": 0.0, "avg_logprob": -0.10077045077369326, "compression_ratio": 1.484472049689441, "no_speech_prob": 0.0019561927765607834}, {"id": 363, "seek": 265216, "start": 2652.16, "end": 2657.68, "text": " is I'm right now, I'm doing software engineering. I'm creating a new product, a new product,", "tokens": [50364, 307, 286, 478, 558, 586, 11, 286, 478, 884, 4722, 7043, 13, 286, 478, 4084, 257, 777, 1674, 11, 257, 777, 1674, 11, 50640], "temperature": 0.0, "avg_logprob": -0.09181066859852184, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.00658733956515789}, {"id": 364, "seek": 265216, "start": 2657.68, "end": 2663.52, "text": " a new application. And all I do is just typing. I'm just chatting with this thing. So I don't", "tokens": [50640, 257, 777, 3861, 13, 400, 439, 286, 360, 307, 445, 18444, 13, 286, 478, 445, 24654, 365, 341, 551, 13, 407, 286, 500, 380, 50932], "temperature": 0.0, "avg_logprob": -0.09181066859852184, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.00658733956515789}, {"id": 365, "seek": 265216, "start": 2663.52, "end": 2669.3599999999997, "text": " need to write any code. I don't need to, to know any programming languages. I just need to do it.", "tokens": [50932, 643, 281, 2464, 604, 3089, 13, 286, 500, 380, 643, 281, 11, 281, 458, 604, 9410, 8650, 13, 286, 445, 643, 281, 360, 309, 13, 51224], "temperature": 0.0, "avg_logprob": -0.09181066859852184, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.00658733956515789}, {"id": 366, "seek": 265216, "start": 2669.3599999999997, "end": 2677.04, "text": " So it asks me, it suggests me a name, which is slogan crafter. I say, yeah, it's a good name.", "tokens": [51224, 407, 309, 8962, 385, 11, 309, 13409, 385, 257, 1315, 11, 597, 307, 33052, 2094, 828, 13, 286, 584, 11, 1338, 11, 309, 311, 257, 665, 1315, 13, 51608], "temperature": 0.0, "avg_logprob": -0.09181066859852184, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.00658733956515789}, {"id": 367, "seek": 267704, "start": 2677.04, "end": 2685.84, "text": " Okay. So now it created me a logo. It created a name. And it also created a prompt. So if you", "tokens": [50364, 1033, 13, 407, 586, 309, 2942, 385, 257, 9699, 13, 467, 2942, 257, 1315, 13, 400, 309, 611, 2942, 257, 12391, 13, 407, 498, 291, 50804], "temperature": 0.0, "avg_logprob": -0.07932244914851777, "compression_ratio": 1.5754189944134078, "no_speech_prob": 0.0015971967950463295}, {"id": 368, "seek": 267704, "start": 2685.84, "end": 2692.08, "text": " want to be more specific to change something in the behavior of how this application works,", "tokens": [50804, 528, 281, 312, 544, 2685, 281, 1319, 746, 294, 264, 5223, 295, 577, 341, 3861, 1985, 11, 51116], "temperature": 0.0, "avg_logprob": -0.07932244914851777, "compression_ratio": 1.5754189944134078, "no_speech_prob": 0.0015971967950463295}, {"id": 369, "seek": 267704, "start": 2692.08, "end": 2699.68, "text": " you can go and edit this message. So let's test. We just created an application. It took me less", "tokens": [51116, 291, 393, 352, 293, 8129, 341, 3636, 13, 407, 718, 311, 1500, 13, 492, 445, 2942, 364, 3861, 13, 467, 1890, 385, 1570, 51496], "temperature": 0.0, "avg_logprob": -0.07932244914851777, "compression_ratio": 1.5754189944134078, "no_speech_prob": 0.0015971967950463295}, {"id": 370, "seek": 269968, "start": 2699.68, "end": 2706.08, "text": " than 60 seconds. It was never possible ever before in the history of humankind.", "tokens": [50364, 813, 4060, 3949, 13, 467, 390, 1128, 1944, 1562, 949, 294, 264, 2503, 295, 1484, 40588, 13, 50684], "temperature": 0.0, "avg_logprob": -0.13044774532318115, "compression_ratio": 1.4530386740331491, "no_speech_prob": 0.028844445943832397}, {"id": 371, "seek": 269968, "start": 2706.64, "end": 2716.48, "text": " So this is the logo that I have, Codex town, which is one of the projects that I run. And", "tokens": [50712, 407, 341, 307, 264, 9699, 300, 286, 362, 11, 15549, 87, 3954, 11, 597, 307, 472, 295, 264, 4455, 300, 286, 1190, 13, 400, 51204], "temperature": 0.0, "avg_logprob": -0.13044774532318115, "compression_ratio": 1.4530386740331491, "no_speech_prob": 0.028844445943832397}, {"id": 372, "seek": 269968, "start": 2716.48, "end": 2725.8399999999997, "text": " I want to create a slogan for this logo. It's actually doing, it's not doing the right thing.", "tokens": [51204, 286, 528, 281, 1884, 257, 33052, 337, 341, 9699, 13, 467, 311, 767, 884, 11, 309, 311, 406, 884, 264, 558, 551, 13, 51672], "temperature": 0.0, "avg_logprob": -0.13044774532318115, "compression_ratio": 1.4530386740331491, "no_speech_prob": 0.028844445943832397}, {"id": 373, "seek": 272584, "start": 2725.84, "end": 2732.0, "text": " Sorry. I forgot to upload a picture.", "tokens": [50364, 4919, 13, 286, 5298, 281, 6580, 257, 3036, 13, 50672], "temperature": 0.0, "avg_logprob": -0.1655182587473016, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.00020984640286769718}, {"id": 374, "seek": 272584, "start": 2735.76, "end": 2743.52, "text": " Write me a slogan. So this is the logo that we have. And then it will,", "tokens": [50860, 23499, 385, 257, 33052, 13, 407, 341, 307, 264, 9699, 300, 321, 362, 13, 400, 550, 309, 486, 11, 51248], "temperature": 0.0, "avg_logprob": -0.1655182587473016, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.00020984640286769718}, {"id": 375, "seek": 272584, "start": 2745.36, "end": 2751.52, "text": " it will create a slogan based, based on this, this logo, because it doesn't have any context", "tokens": [51340, 309, 486, 1884, 257, 33052, 2361, 11, 2361, 322, 341, 11, 341, 9699, 11, 570, 309, 1177, 380, 362, 604, 4319, 51648], "temperature": 0.0, "avg_logprob": -0.1655182587473016, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.00020984640286769718}, {"id": 376, "seek": 275152, "start": 2751.52, "end": 2756.08, "text": " about what the project is about. It's just using the colors, basically the style of the image to", "tokens": [50364, 466, 437, 264, 1716, 307, 466, 13, 467, 311, 445, 1228, 264, 4577, 11, 1936, 264, 3758, 295, 264, 3256, 281, 50592], "temperature": 0.0, "avg_logprob": -0.09184466017053482, "compression_ratio": 1.6460176991150441, "no_speech_prob": 0.006898525170981884}, {"id": 377, "seek": 275152, "start": 2756.08, "end": 2763.52, "text": " create the slogan. So this application might not be very useful. Goal for me is to show how easy,", "tokens": [50592, 1884, 264, 33052, 13, 407, 341, 3861, 1062, 406, 312, 588, 4420, 13, 1037, 304, 337, 385, 307, 281, 855, 577, 1858, 11, 50964], "temperature": 0.0, "avg_logprob": -0.09184466017053482, "compression_ratio": 1.6460176991150441, "no_speech_prob": 0.006898525170981884}, {"id": 378, "seek": 275152, "start": 2763.52, "end": 2768.56, "text": " how simple it is to build. I also want to show a few applications that are actually useful that", "tokens": [50964, 577, 2199, 309, 307, 281, 1322, 13, 286, 611, 528, 281, 855, 257, 1326, 5821, 300, 366, 767, 4420, 300, 51216], "temperature": 0.0, "avg_logprob": -0.09184466017053482, "compression_ratio": 1.6460176991150441, "no_speech_prob": 0.006898525170981884}, {"id": 379, "seek": 275152, "start": 2768.56, "end": 2775.28, "text": " were created by, sorry, by other people and that I'm using daily. So for example,", "tokens": [51216, 645, 2942, 538, 11, 2597, 11, 538, 661, 561, 293, 300, 286, 478, 1228, 5212, 13, 407, 337, 1365, 11, 51552], "temperature": 0.0, "avg_logprob": -0.09184466017053482, "compression_ratio": 1.6460176991150441, "no_speech_prob": 0.006898525170981884}, {"id": 380, "seek": 277528, "start": 2775.76, "end": 2787.36, "text": " let's go into this one, for example. So Dr. Andrew Huberman is a neuroscientist and he has a lot of", "tokens": [50388, 718, 311, 352, 666, 341, 472, 11, 337, 1365, 13, 407, 2491, 13, 10110, 389, 10261, 1601, 307, 257, 28813, 5412, 468, 293, 415, 575, 257, 688, 295, 50968], "temperature": 0.0, "avg_logprob": -0.150378870676799, "compression_ratio": 1.5567567567567568, "no_speech_prob": 0.02840390056371689}, {"id": 381, "seek": 277528, "start": 2787.36, "end": 2793.6000000000004, "text": " great podcasts. But the problem with his podcasts is that they're long and I didn't have time to", "tokens": [50968, 869, 24045, 13, 583, 264, 1154, 365, 702, 24045, 307, 300, 436, 434, 938, 293, 286, 994, 380, 362, 565, 281, 51280], "temperature": 0.0, "avg_logprob": -0.150378870676799, "compression_ratio": 1.5567567567567568, "no_speech_prob": 0.02840390056371689}, {"id": 382, "seek": 277528, "start": 2793.6000000000004, "end": 2799.76, "text": " listen to a lot of them, to a lot of those. So what I can do, or someone, what someone did,", "tokens": [51280, 2140, 281, 257, 688, 295, 552, 11, 281, 257, 688, 295, 729, 13, 407, 437, 286, 393, 360, 11, 420, 1580, 11, 437, 1580, 630, 11, 51588], "temperature": 0.0, "avg_logprob": -0.150378870676799, "compression_ratio": 1.5567567567567568, "no_speech_prob": 0.02840390056371689}, {"id": 383, "seek": 279976, "start": 2799.76, "end": 2805.2000000000003, "text": " someone created, someone uploaded all the recordings of the podcasts by Andrew Huberman", "tokens": [50364, 1580, 2942, 11, 1580, 17135, 439, 264, 25162, 295, 264, 24045, 538, 10110, 389, 10261, 1601, 50636], "temperature": 0.0, "avg_logprob": -0.07273537317911784, "compression_ratio": 1.6531531531531531, "no_speech_prob": 0.01016412116587162}, {"id": 384, "seek": 279976, "start": 2805.76, "end": 2813.76, "text": " and created a GPT. And now I can chat with this GPT and it will answer to me based on the question,", "tokens": [50664, 293, 2942, 257, 26039, 51, 13, 400, 586, 286, 393, 5081, 365, 341, 26039, 51, 293, 309, 486, 1867, 281, 385, 2361, 322, 264, 1168, 11, 51064], "temperature": 0.0, "avg_logprob": -0.07273537317911784, "compression_ratio": 1.6531531531531531, "no_speech_prob": 0.01016412116587162}, {"id": 385, "seek": 279976, "start": 2813.76, "end": 2821.36, "text": " based on the data that is coming from those recordings. So I can ask for tips on staying", "tokens": [51064, 2361, 322, 264, 1412, 300, 307, 1348, 490, 729, 25162, 13, 407, 286, 393, 1029, 337, 6082, 322, 7939, 51444], "temperature": 0.0, "avg_logprob": -0.07273537317911784, "compression_ratio": 1.6531531531531531, "no_speech_prob": 0.01016412116587162}, {"id": 386, "seek": 279976, "start": 2821.36, "end": 2829.0400000000004, "text": " focused over time. This GPT will first search its own knowledge base, which you can upload", "tokens": [51444, 5178, 670, 565, 13, 639, 26039, 51, 486, 700, 3164, 1080, 1065, 3601, 3096, 11, 597, 291, 393, 6580, 51828], "temperature": 0.0, "avg_logprob": -0.07273537317911784, "compression_ratio": 1.6531531531531531, "no_speech_prob": 0.01016412116587162}, {"id": 387, "seek": 282904, "start": 2829.04, "end": 2835.44, "text": " while creating a GPT. And then it will generate an answer based on, based on that.", "tokens": [50364, 1339, 4084, 257, 26039, 51, 13, 400, 550, 309, 486, 8460, 364, 1867, 2361, 322, 11, 2361, 322, 300, 13, 50684], "temperature": 0.0, "avg_logprob": -0.10038303647722517, "compression_ratio": 1.4806629834254144, "no_speech_prob": 0.0005440794047899544}, {"id": 388, "seek": 282904, "start": 2836.8, "end": 2843.44, "text": " So I already used it. I actually asked the same question and I find it extremely useful,", "tokens": [50752, 407, 286, 1217, 1143, 309, 13, 286, 767, 2351, 264, 912, 1168, 293, 286, 915, 309, 4664, 4420, 11, 51084], "temperature": 0.0, "avg_logprob": -0.10038303647722517, "compression_ratio": 1.4806629834254144, "no_speech_prob": 0.0005440794047899544}, {"id": 389, "seek": 282904, "start": 2843.44, "end": 2850.64, "text": " like I'm using most of those tips. And then this is just an example. Another example of GPT that", "tokens": [51084, 411, 286, 478, 1228, 881, 295, 729, 6082, 13, 400, 550, 341, 307, 445, 364, 1365, 13, 3996, 1365, 295, 26039, 51, 300, 51444], "temperature": 0.0, "avg_logprob": -0.10038303647722517, "compression_ratio": 1.4806629834254144, "no_speech_prob": 0.0005440794047899544}, {"id": 390, "seek": 285064, "start": 2850.64, "end": 2859.52, "text": " I created is a sketch to code. So this GPT allows me to upload any picture. I don't have,", "tokens": [50364, 286, 2942, 307, 257, 12325, 281, 3089, 13, 407, 341, 26039, 51, 4045, 385, 281, 6580, 604, 3036, 13, 286, 500, 380, 362, 11, 50808], "temperature": 0.0, "avg_logprob": -0.18812822412561486, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.0151823153719306}, {"id": 391, "seek": 285064, "start": 2863.04, "end": 2871.2, "text": " I don't have right picture. Sorry, I didn't prepare. But basically, well, I won't show the", "tokens": [50984, 286, 500, 380, 362, 558, 3036, 13, 4919, 11, 286, 994, 380, 5940, 13, 583, 1936, 11, 731, 11, 286, 1582, 380, 855, 264, 51392], "temperature": 0.0, "avg_logprob": -0.18812822412561486, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.0151823153719306}, {"id": 392, "seek": 287120, "start": 2871.2, "end": 2882.7999999999997, "text": " demo, but you can actually use it. So it's public. It's free to use. And what it does is I can just", "tokens": [50364, 10723, 11, 457, 291, 393, 767, 764, 309, 13, 407, 309, 311, 1908, 13, 467, 311, 1737, 281, 764, 13, 400, 437, 309, 775, 307, 286, 393, 445, 50944], "temperature": 0.0, "avg_logprob": -0.07532185542432568, "compression_ratio": 1.586021505376344, "no_speech_prob": 0.06001295521855354}, {"id": 393, "seek": 287120, "start": 2882.7999999999997, "end": 2889.52, "text": " create a simple image of the website, what I want to have on my website. And then I upload it here", "tokens": [50944, 1884, 257, 2199, 3256, 295, 264, 3144, 11, 437, 286, 528, 281, 362, 322, 452, 3144, 13, 400, 550, 286, 6580, 309, 510, 51280], "temperature": 0.0, "avg_logprob": -0.07532185542432568, "compression_ratio": 1.586021505376344, "no_speech_prob": 0.06001295521855354}, {"id": 394, "seek": 287120, "start": 2889.52, "end": 2896.72, "text": " and it outputs the code of the website that I can immediately run. So that really saves time and", "tokens": [51280, 293, 309, 23930, 264, 3089, 295, 264, 3144, 300, 286, 393, 4258, 1190, 13, 407, 300, 534, 19155, 565, 293, 51640], "temperature": 0.0, "avg_logprob": -0.07532185542432568, "compression_ratio": 1.586021505376344, "no_speech_prob": 0.06001295521855354}, {"id": 395, "seek": 289672, "start": 2897.4399999999996, "end": 2904.3999999999996, "text": " almost replaces the work of website software engineer for, at least for simple stuff. So", "tokens": [50400, 1920, 46734, 264, 589, 295, 3144, 4722, 11403, 337, 11, 412, 1935, 337, 2199, 1507, 13, 407, 50748], "temperature": 0.0, "avg_logprob": -0.11770027562191612, "compression_ratio": 1.5822784810126582, "no_speech_prob": 0.0018669385462999344}, {"id": 396, "seek": 289672, "start": 2905.68, "end": 2912.8799999999997, "text": " it won't help with something very complex, like huge e-commerce website. But if you want a simple", "tokens": [50812, 309, 1582, 380, 854, 365, 746, 588, 3997, 11, 411, 2603, 308, 12, 26926, 3144, 13, 583, 498, 291, 528, 257, 2199, 51172], "temperature": 0.0, "avg_logprob": -0.11770027562191612, "compression_ratio": 1.5822784810126582, "no_speech_prob": 0.0018669385462999344}, {"id": 397, "seek": 289672, "start": 2912.8799999999997, "end": 2918.16, "text": " page with a few elements, you can just draw it on a piece of paper. I can literally take a photo", "tokens": [51172, 3028, 365, 257, 1326, 4959, 11, 291, 393, 445, 2642, 309, 322, 257, 2522, 295, 3035, 13, 286, 393, 3736, 747, 257, 5052, 51436], "temperature": 0.0, "avg_logprob": -0.11770027562191612, "compression_ratio": 1.5822784810126582, "no_speech_prob": 0.0018669385462999344}, {"id": 398, "seek": 289672, "start": 2918.16, "end": 2926.0, "text": " of what I draw on my whiteboard and it will convert it into a code. And that's amazing. And", "tokens": [51436, 295, 437, 286, 2642, 322, 452, 2418, 3787, 293, 309, 486, 7620, 309, 666, 257, 3089, 13, 400, 300, 311, 2243, 13, 400, 51828], "temperature": 0.0, "avg_logprob": -0.11770027562191612, "compression_ratio": 1.5822784810126582, "no_speech_prob": 0.0018669385462999344}, {"id": 399, "seek": 292600, "start": 2926.0, "end": 2937.52, "text": " that's my blowing. So what I want to do next, I want to skim through a few slides. I won't stop", "tokens": [50364, 300, 311, 452, 15068, 13, 407, 437, 286, 528, 281, 360, 958, 11, 286, 528, 281, 1110, 332, 807, 257, 1326, 9788, 13, 286, 1582, 380, 1590, 50940], "temperature": 0.0, "avg_logprob": -0.11971054253754793, "compression_ratio": 1.385185185185185, "no_speech_prob": 0.0003459002182353288}, {"id": 400, "seek": 292600, "start": 2937.52, "end": 2946.16, "text": " into detail on each one of those. But these slides are for you to use and to explore later.", "tokens": [50940, 666, 2607, 322, 1184, 472, 295, 729, 13, 583, 613, 9788, 366, 337, 291, 281, 764, 293, 281, 6839, 1780, 13, 51372], "temperature": 0.0, "avg_logprob": -0.11971054253754793, "compression_ratio": 1.385185185185185, "no_speech_prob": 0.0003459002182353288}, {"id": 401, "seek": 294616, "start": 2946.72, "end": 2955.68, "text": " On each of those slides, I have a list of different products and neural networks or AI models", "tokens": [50392, 1282, 1184, 295, 729, 9788, 11, 286, 362, 257, 1329, 295, 819, 3383, 293, 18161, 9590, 420, 7318, 5245, 50840], "temperature": 0.0, "avg_logprob": -0.08193112762880997, "compression_ratio": 1.5642458100558658, "no_speech_prob": 0.027992496266961098}, {"id": 402, "seek": 294616, "start": 2956.3199999999997, "end": 2962.56, "text": " that are useful for different tasks. So I have a capability listed on the left and then links", "tokens": [50872, 300, 366, 4420, 337, 819, 9608, 13, 407, 286, 362, 257, 13759, 10052, 322, 264, 1411, 293, 550, 6123, 51184], "temperature": 0.0, "avg_logprob": -0.08193112762880997, "compression_ratio": 1.5642458100558658, "no_speech_prob": 0.027992496266961098}, {"id": 403, "seek": 294616, "start": 2962.56, "end": 2970.56, "text": " here. And there's a lot of those. We don't have time to see and to check every one of those.", "tokens": [51184, 510, 13, 400, 456, 311, 257, 688, 295, 729, 13, 492, 500, 380, 362, 565, 281, 536, 293, 281, 1520, 633, 472, 295, 729, 13, 51584], "temperature": 0.0, "avg_logprob": -0.08193112762880997, "compression_ratio": 1.5642458100558658, "no_speech_prob": 0.027992496266961098}, {"id": 404, "seek": 297056, "start": 2971.2799999999997, "end": 2977.2, "text": " But I want to show that there is a bunch of models that allow to generate text. There's a", "tokens": [50400, 583, 286, 528, 281, 855, 300, 456, 307, 257, 3840, 295, 5245, 300, 2089, 281, 8460, 2487, 13, 821, 311, 257, 50696], "temperature": 0.0, "avg_logprob": -0.09151211450266283, "compression_ratio": 2.102272727272727, "no_speech_prob": 0.04465365409851074}, {"id": 405, "seek": 297056, "start": 2977.2, "end": 2982.64, "text": " bunch of models that are out to generate and help for software engineering with software engineering", "tokens": [50696, 3840, 295, 5245, 300, 366, 484, 281, 8460, 293, 854, 337, 4722, 7043, 365, 4722, 7043, 50968], "temperature": 0.0, "avg_logprob": -0.09151211450266283, "compression_ratio": 2.102272727272727, "no_speech_prob": 0.04465365409851074}, {"id": 406, "seek": 297056, "start": 2982.64, "end": 2991.36, "text": " job. There's a lot of models that allow you to generate music and voice and also translate text", "tokens": [50968, 1691, 13, 821, 311, 257, 688, 295, 5245, 300, 2089, 291, 281, 8460, 1318, 293, 3177, 293, 611, 13799, 2487, 51404], "temperature": 0.0, "avg_logprob": -0.09151211450266283, "compression_ratio": 2.102272727272727, "no_speech_prob": 0.04465365409851074}, {"id": 407, "seek": 297056, "start": 2991.36, "end": 2998.32, "text": " to speech or speech to text. And there's a few models that actually a lot of models", "tokens": [51404, 281, 6218, 420, 6218, 281, 2487, 13, 400, 456, 311, 257, 1326, 5245, 300, 767, 257, 688, 295, 5245, 51752], "temperature": 0.0, "avg_logprob": -0.09151211450266283, "compression_ratio": 2.102272727272727, "no_speech_prob": 0.04465365409851074}, {"id": 408, "seek": 299832, "start": 2998.8, "end": 3004.48, "text": " right here. I have a link to the website which has a huge collection of different", "tokens": [50388, 558, 510, 13, 286, 362, 257, 2113, 281, 264, 3144, 597, 575, 257, 2603, 5765, 295, 819, 50672], "temperature": 0.0, "avg_logprob": -0.13652764114679075, "compression_ratio": 1.6953125, "no_speech_prob": 0.0037637390196323395}, {"id": 409, "seek": 299832, "start": 3004.48, "end": 3009.6000000000004, "text": " image generation models. And most of those products, so on each one of those slides,", "tokens": [50672, 3256, 5125, 5245, 13, 400, 881, 295, 729, 3383, 11, 370, 322, 1184, 472, 295, 729, 9788, 11, 50928], "temperature": 0.0, "avg_logprob": -0.13652764114679075, "compression_ratio": 1.6953125, "no_speech_prob": 0.0037637390196323395}, {"id": 410, "seek": 299832, "start": 3009.6000000000004, "end": 3016.32, "text": " important thing is at least one or actually at least half of all these models are completely", "tokens": [50928, 1021, 551, 307, 412, 1935, 472, 420, 767, 412, 1935, 1922, 295, 439, 613, 5245, 366, 2584, 51264], "temperature": 0.0, "avg_logprob": -0.13652764114679075, "compression_ratio": 1.6953125, "no_speech_prob": 0.0037637390196323395}, {"id": 411, "seek": 299832, "start": 3016.32, "end": 3021.6800000000003, "text": " free and open source. So you don't need to pay for anything to start using it.", "tokens": [51264, 1737, 293, 1269, 4009, 13, 407, 291, 500, 380, 643, 281, 1689, 337, 1340, 281, 722, 1228, 309, 13, 51532], "temperature": 0.0, "avg_logprob": -0.13652764114679075, "compression_ratio": 1.6953125, "no_speech_prob": 0.0037637390196323395}, {"id": 412, "seek": 299832, "start": 3021.6800000000003, "end": 3027.2000000000003, "text": " If you want to use it into maybe some enterprise production use case, yes, there are enterprise", "tokens": [51532, 759, 291, 528, 281, 764, 309, 666, 1310, 512, 14132, 4265, 764, 1389, 11, 2086, 11, 456, 366, 14132, 51808], "temperature": 0.0, "avg_logprob": -0.13652764114679075, "compression_ratio": 1.6953125, "no_speech_prob": 0.0037637390196323395}, {"id": 413, "seek": 302720, "start": 3027.2, "end": 3033.12, "text": " solutions, but to start to test to play with it, most of these things are actually free to use", "tokens": [50364, 6547, 11, 457, 281, 722, 281, 1500, 281, 862, 365, 309, 11, 881, 295, 613, 721, 366, 767, 1737, 281, 764, 50660], "temperature": 0.0, "avg_logprob": -0.11614152964423685, "compression_ratio": 1.632183908045977, "no_speech_prob": 0.0006459444994106889}, {"id": 414, "seek": 302720, "start": 3033.12, "end": 3044.7999999999997, "text": " and that's great and that gives a lot of increases accessibility. And finally, these models are", "tokens": [50660, 293, 300, 311, 869, 293, 300, 2709, 257, 688, 295, 8637, 15002, 13, 400, 2721, 11, 613, 5245, 366, 51244], "temperature": 0.0, "avg_logprob": -0.11614152964423685, "compression_ratio": 1.632183908045977, "no_speech_prob": 0.0006459444994106889}, {"id": 415, "seek": 302720, "start": 3044.7999999999997, "end": 3051.9199999999996, "text": " vision models. These are what I showed on one of the examples. These are models where you can", "tokens": [51244, 5201, 5245, 13, 1981, 366, 437, 286, 4712, 322, 472, 295, 264, 5110, 13, 1981, 366, 5245, 689, 291, 393, 51600], "temperature": 0.0, "avg_logprob": -0.11614152964423685, "compression_ratio": 1.632183908045977, "no_speech_prob": 0.0006459444994106889}, {"id": 416, "seek": 305192, "start": 3051.92, "end": 3057.6, "text": " upload a photo or upload a picture and then ask questions about that picture. For example, it is", "tokens": [50364, 6580, 257, 5052, 420, 6580, 257, 3036, 293, 550, 1029, 1651, 466, 300, 3036, 13, 1171, 1365, 11, 309, 307, 50648], "temperature": 0.0, "avg_logprob": -0.14621433654388824, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.02475585602223873}, {"id": 417, "seek": 305192, "start": 3057.6, "end": 3064.4, "text": " relatively good with actually medical diagnosis, although it is, I don't recommend it use instead", "tokens": [50648, 7226, 665, 365, 767, 4625, 15217, 11, 4878, 309, 307, 11, 286, 500, 380, 2748, 309, 764, 2602, 50988], "temperature": 0.0, "avg_logprob": -0.14621433654388824, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.02475585602223873}, {"id": 418, "seek": 305192, "start": 3064.4, "end": 3070.0, "text": " of professional medical help, but it is also useful for identifying objects like safety requirements", "tokens": [50988, 295, 4843, 4625, 854, 11, 457, 309, 307, 611, 4420, 337, 16696, 6565, 411, 4514, 7728, 51268], "temperature": 0.0, "avg_logprob": -0.14621433654388824, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.02475585602223873}, {"id": 419, "seek": 305192, "start": 3070.0, "end": 3076.48, "text": " or maybe give recommendations regarding design or architecture or something like this.", "tokens": [51268, 420, 1310, 976, 10434, 8595, 1715, 420, 9482, 420, 746, 411, 341, 13, 51592], "temperature": 0.0, "avg_logprob": -0.14621433654388824, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.02475585602223873}, {"id": 420, "seek": 307648, "start": 3076.48, "end": 3087.52, "text": " And we already touched some of the business use cases. I wanted to show a few more. So we have", "tokens": [50364, 400, 321, 1217, 9828, 512, 295, 264, 1606, 764, 3331, 13, 286, 1415, 281, 855, 257, 1326, 544, 13, 407, 321, 362, 50916], "temperature": 0.0, "avg_logprob": -0.16206572949886322, "compression_ratio": 1.639751552795031, "no_speech_prob": 0.001925719203427434}, {"id": 421, "seek": 307648, "start": 3087.52, "end": 3096.64, "text": " a few more minutes and let me go into some of the most interesting business use cases for", "tokens": [50916, 257, 1326, 544, 2077, 293, 718, 385, 352, 666, 512, 295, 264, 881, 1880, 1606, 764, 3331, 337, 51372], "temperature": 0.0, "avg_logprob": -0.16206572949886322, "compression_ratio": 1.639751552795031, "no_speech_prob": 0.001925719203427434}, {"id": 422, "seek": 307648, "start": 3096.64, "end": 3105.44, "text": " generative AI. I will skip this. Important and maybe most important thing about", "tokens": [51372, 1337, 1166, 7318, 13, 286, 486, 10023, 341, 13, 42908, 293, 1310, 881, 1021, 551, 466, 51812], "temperature": 0.0, "avg_logprob": -0.16206572949886322, "compression_ratio": 1.639751552795031, "no_speech_prob": 0.001925719203427434}, {"id": 423, "seek": 310544, "start": 3106.2400000000002, "end": 3111.76, "text": " use cases for AI in business is that business processes are not simple. Business processes are", "tokens": [50404, 764, 3331, 337, 7318, 294, 1606, 307, 300, 1606, 7555, 366, 406, 2199, 13, 10715, 7555, 366, 50680], "temperature": 0.0, "avg_logprob": -0.11733754475911458, "compression_ratio": 1.6478260869565218, "no_speech_prob": 0.003942267969250679}, {"id": 424, "seek": 310544, "start": 3111.76, "end": 3120.7200000000003, "text": " not just one action. It is usually some logic. And this logic is hard to achieve just by chatting", "tokens": [50680, 406, 445, 472, 3069, 13, 467, 307, 2673, 512, 9952, 13, 400, 341, 9952, 307, 1152, 281, 4584, 445, 538, 24654, 51128], "temperature": 0.0, "avg_logprob": -0.11733754475911458, "compression_ratio": 1.6478260869565218, "no_speech_prob": 0.003942267969250679}, {"id": 425, "seek": 310544, "start": 3120.7200000000003, "end": 3127.6, "text": " with ChargeGPT. If you ask ChargeGPT to create something complex like, I don't know, promote", "tokens": [51128, 365, 40546, 38, 47, 51, 13, 759, 291, 1029, 40546, 38, 47, 51, 281, 1884, 746, 3997, 411, 11, 286, 500, 380, 458, 11, 9773, 51472], "temperature": 0.0, "avg_logprob": -0.11733754475911458, "compression_ratio": 1.6478260869565218, "no_speech_prob": 0.003942267969250679}, {"id": 426, "seek": 310544, "start": 3127.6, "end": 3133.6, "text": " my product, it doesn't know what to do. There's too many things that goes into that task. But", "tokens": [51472, 452, 1674, 11, 309, 1177, 380, 458, 437, 281, 360, 13, 821, 311, 886, 867, 721, 300, 1709, 666, 300, 5633, 13, 583, 51772], "temperature": 0.0, "avg_logprob": -0.11733754475911458, "compression_ratio": 1.6478260869565218, "no_speech_prob": 0.003942267969250679}, {"id": 427, "seek": 313360, "start": 3133.6, "end": 3139.52, "text": " if it is split into simple tasks and then we chain those tasks together, we can actually achieve", "tokens": [50364, 498, 309, 307, 7472, 666, 2199, 9608, 293, 550, 321, 5021, 729, 9608, 1214, 11, 321, 393, 767, 4584, 50660], "temperature": 0.0, "avg_logprob": -0.15567679903400478, "compression_ratio": 1.558659217877095, "no_speech_prob": 0.000646021100692451}, {"id": 428, "seek": 313360, "start": 3139.52, "end": 3149.2799999999997, "text": " very complex behavior. One of the examples is to use AI for nature language processing.", "tokens": [50660, 588, 3997, 5223, 13, 1485, 295, 264, 5110, 307, 281, 764, 7318, 337, 3687, 2856, 9007, 13, 51148], "temperature": 0.0, "avg_logprob": -0.15567679903400478, "compression_ratio": 1.558659217877095, "no_speech_prob": 0.000646021100692451}, {"id": 429, "seek": 313360, "start": 3149.92, "end": 3155.36, "text": " Here on the right, on the example, I have an example of the user that has some kind of intent,", "tokens": [51180, 1692, 322, 264, 558, 11, 322, 264, 1365, 11, 286, 362, 364, 1365, 295, 264, 4195, 300, 575, 512, 733, 295, 8446, 11, 51452], "temperature": 0.0, "avg_logprob": -0.15567679903400478, "compression_ratio": 1.558659217877095, "no_speech_prob": 0.000646021100692451}, {"id": 430, "seek": 315536, "start": 3156.32, "end": 3164.1600000000003, "text": " or some kind of message on our, let's say, website. And then this message can be classified,", "tokens": [50412, 420, 512, 733, 295, 3636, 322, 527, 11, 718, 311, 584, 11, 3144, 13, 400, 550, 341, 3636, 393, 312, 20627, 11, 50804], "temperature": 0.0, "avg_logprob": -0.11534440645607569, "compression_ratio": 1.6622222222222223, "no_speech_prob": 0.11745210736989975}, {"id": 431, "seek": 315536, "start": 3164.1600000000003, "end": 3170.48, "text": " depending on the intent. Is it an inquiry? Is it a price inquiry? Is it a complaint? Is it a", "tokens": [50804, 5413, 322, 264, 8446, 13, 1119, 309, 364, 25736, 30, 1119, 309, 257, 3218, 25736, 30, 1119, 309, 257, 20100, 30, 1119, 309, 257, 51120], "temperature": 0.0, "avg_logprob": -0.11534440645607569, "compression_ratio": 1.6622222222222223, "no_speech_prob": 0.11745210736989975}, {"id": 432, "seek": 315536, "start": 3170.48, "end": 3178.56, "text": " gratitude for our product? Based on that, we can use different prompts or different AI models", "tokens": [51120, 16935, 337, 527, 1674, 30, 18785, 322, 300, 11, 321, 393, 764, 819, 41095, 420, 819, 7318, 5245, 51524], "temperature": 0.0, "avg_logprob": -0.11534440645607569, "compression_ratio": 1.6622222222222223, "no_speech_prob": 0.11745210736989975}, {"id": 433, "seek": 315536, "start": 3178.56, "end": 3183.84, "text": " to generate a response. So one of the models will retrieve relevant data, for example, product", "tokens": [51524, 281, 8460, 257, 4134, 13, 407, 472, 295, 264, 5245, 486, 30254, 7340, 1412, 11, 337, 1365, 11, 1674, 51788], "temperature": 0.0, "avg_logprob": -0.11534440645607569, "compression_ratio": 1.6622222222222223, "no_speech_prob": 0.11745210736989975}, {"id": 434, "seek": 318384, "start": 3183.92, "end": 3189.52, "text": " specification. Another model or another instance of the model will write response to the customer.", "tokens": [50368, 31256, 13, 3996, 2316, 420, 1071, 5197, 295, 264, 2316, 486, 2464, 4134, 281, 264, 5474, 13, 50648], "temperature": 0.0, "avg_logprob": -0.10115204228983297, "compression_ratio": 1.722488038277512, "no_speech_prob": 0.0006457233102992177}, {"id": 435, "seek": 318384, "start": 3189.52, "end": 3196.88, "text": " So use that product specification and answer to customer question. And then another model", "tokens": [50648, 407, 764, 300, 1674, 31256, 293, 1867, 281, 5474, 1168, 13, 400, 550, 1071, 2316, 51016], "temperature": 0.0, "avg_logprob": -0.10115204228983297, "compression_ratio": 1.722488038277512, "no_speech_prob": 0.0006457233102992177}, {"id": 436, "seek": 318384, "start": 3196.88, "end": 3201.28, "text": " will generate a picture and attach it to email and then that can be sent.", "tokens": [51016, 486, 8460, 257, 3036, 293, 5085, 309, 281, 3796, 293, 550, 300, 393, 312, 2279, 13, 51236], "temperature": 0.0, "avg_logprob": -0.10115204228983297, "compression_ratio": 1.722488038277512, "no_speech_prob": 0.0006457233102992177}, {"id": 437, "seek": 318384, "start": 3205.04, "end": 3211.28, "text": " One, another example for business use case that a lot of companies are actually using today is to", "tokens": [51424, 1485, 11, 1071, 1365, 337, 1606, 764, 1389, 300, 257, 688, 295, 3431, 366, 767, 1228, 965, 307, 281, 51736], "temperature": 0.0, "avg_logprob": -0.10115204228983297, "compression_ratio": 1.722488038277512, "no_speech_prob": 0.0006457233102992177}, {"id": 438, "seek": 321128, "start": 3211.28, "end": 3218.0800000000004, "text": " use large language models as a knowledge management system. You can take all the existing digital", "tokens": [50364, 764, 2416, 2856, 5245, 382, 257, 3601, 4592, 1185, 13, 509, 393, 747, 439, 264, 6741, 4562, 50704], "temperature": 0.0, "avg_logprob": -0.1000756165560554, "compression_ratio": 1.4328358208955223, "no_speech_prob": 0.0038211948703974485}, {"id": 439, "seek": 321128, "start": 3218.0800000000004, "end": 3227.28, "text": " communication tools like Gmail, Zoom, Jobbox, LinkedIn, Office, Slack, and so on, then upload it", "tokens": [50704, 6101, 3873, 411, 36732, 11, 13453, 11, 18602, 4995, 11, 20657, 11, 8935, 11, 37211, 11, 293, 370, 322, 11, 550, 6580, 309, 51164], "temperature": 0.0, "avg_logprob": -0.1000756165560554, "compression_ratio": 1.4328358208955223, "no_speech_prob": 0.0038211948703974485}, {"id": 440, "seek": 321128, "start": 3227.28, "end": 3237.84, "text": " to a LLM system and then have ability for anyone in the company to ask questions against this", "tokens": [51164, 281, 257, 441, 43, 44, 1185, 293, 550, 362, 3485, 337, 2878, 294, 264, 2237, 281, 1029, 1651, 1970, 341, 51692], "temperature": 0.0, "avg_logprob": -0.1000756165560554, "compression_ratio": 1.4328358208955223, "no_speech_prob": 0.0038211948703974485}, {"id": 441, "seek": 323784, "start": 3237.84, "end": 3244.08, "text": " knowledge base. So if I have a list of product specifications, I upload it to this LLM and then", "tokens": [50364, 3601, 3096, 13, 407, 498, 286, 362, 257, 1329, 295, 1674, 29448, 11, 286, 6580, 309, 281, 341, 441, 43, 44, 293, 550, 50676], "temperature": 0.0, "avg_logprob": -0.102429257268491, "compression_ratio": 1.7769516728624535, "no_speech_prob": 0.010159514844417572}, {"id": 442, "seek": 323784, "start": 3244.08, "end": 3248.88, "text": " anyone in the company, any sales agent, for example, sales representative, if they have a question,", "tokens": [50676, 2878, 294, 264, 2237, 11, 604, 5763, 9461, 11, 337, 1365, 11, 5763, 12424, 11, 498, 436, 362, 257, 1168, 11, 50916], "temperature": 0.0, "avg_logprob": -0.102429257268491, "compression_ratio": 1.7769516728624535, "no_speech_prob": 0.010159514844417572}, {"id": 443, "seek": 323784, "start": 3248.88, "end": 3256.48, "text": " they can just ask, they can just type or even record a voice message and get answered to the", "tokens": [50916, 436, 393, 445, 1029, 11, 436, 393, 445, 2010, 420, 754, 2136, 257, 3177, 3636, 293, 483, 10103, 281, 264, 51296], "temperature": 0.0, "avg_logprob": -0.102429257268491, "compression_ratio": 1.7769516728624535, "no_speech_prob": 0.010159514844417572}, {"id": 444, "seek": 323784, "start": 3256.48, "end": 3261.92, "text": " question like, for example, product X, what is the price or what is the dimensions and this", "tokens": [51296, 1168, 411, 11, 337, 1365, 11, 1674, 1783, 11, 437, 307, 264, 3218, 420, 437, 307, 264, 12819, 293, 341, 51568], "temperature": 0.0, "avg_logprob": -0.102429257268491, "compression_ratio": 1.7769516728624535, "no_speech_prob": 0.010159514844417572}, {"id": 445, "seek": 323784, "start": 3261.92, "end": 3267.44, "text": " system will give instant response. So it saves a lot of communication overhead and saves a lot of", "tokens": [51568, 1185, 486, 976, 9836, 4134, 13, 407, 309, 19155, 257, 688, 295, 6101, 19922, 293, 19155, 257, 688, 295, 51844], "temperature": 0.0, "avg_logprob": -0.102429257268491, "compression_ratio": 1.7769516728624535, "no_speech_prob": 0.010159514844417572}, {"id": 446, "seek": 326744, "start": 3267.44, "end": 3279.36, "text": " time when we want to share knowledge within the organization. Another huge use case in the,", "tokens": [50364, 565, 562, 321, 528, 281, 2073, 3601, 1951, 264, 4475, 13, 3996, 2603, 764, 1389, 294, 264, 11, 50960], "temperature": 0.0, "avg_logprob": -0.11884281451885517, "compression_ratio": 1.4867724867724867, "no_speech_prob": 0.0005974044324830174}, {"id": 447, "seek": 326744, "start": 3279.36, "end": 3284.88, "text": " if you remember the McKinsey report that I showed in the beginning, it is one of the primary use", "tokens": [50960, 498, 291, 1604, 264, 21765, 259, 7399, 2275, 300, 286, 4712, 294, 264, 2863, 11, 309, 307, 472, 295, 264, 6194, 764, 51236], "temperature": 0.0, "avg_logprob": -0.11884281451885517, "compression_ratio": 1.4867724867724867, "no_speech_prob": 0.0005974044324830174}, {"id": 448, "seek": 326744, "start": 3284.88, "end": 3291.12, "text": " case for large language models today is in engineering and there's two applications of that.", "tokens": [51236, 1389, 337, 2416, 2856, 5245, 965, 307, 294, 7043, 293, 456, 311, 732, 5821, 295, 300, 13, 51548], "temperature": 0.0, "avg_logprob": -0.11884281451885517, "compression_ratio": 1.4867724867724867, "no_speech_prob": 0.0005974044324830174}, {"id": 449, "seek": 329112, "start": 3291.12, "end": 3298.96, "text": " First of all, yes, AI is very, very helpful to software engineers. It can help write code, it can", "tokens": [50364, 2386, 295, 439, 11, 2086, 11, 7318, 307, 588, 11, 588, 4961, 281, 4722, 11955, 13, 467, 393, 854, 2464, 3089, 11, 309, 393, 50756], "temperature": 0.0, "avg_logprob": -0.08206017975954666, "compression_ratio": 1.7285067873303168, "no_speech_prob": 0.004327489994466305}, {"id": 450, "seek": 329112, "start": 3298.96, "end": 3304.72, "text": " test code, it can help you fix bugs, it can help identify bugs, but it is also useful to people", "tokens": [50756, 1500, 3089, 11, 309, 393, 854, 291, 3191, 15120, 11, 309, 393, 854, 5876, 15120, 11, 457, 309, 307, 611, 4420, 281, 561, 51044], "temperature": 0.0, "avg_logprob": -0.08206017975954666, "compression_ratio": 1.7285067873303168, "no_speech_prob": 0.004327489994466305}, {"id": 451, "seek": 329112, "start": 3304.72, "end": 3310.08, "text": " who are not engineers, but they need to complete some engineering tasks like the data analysis", "tokens": [51044, 567, 366, 406, 11955, 11, 457, 436, 643, 281, 3566, 512, 7043, 9608, 411, 264, 1412, 5215, 51312], "temperature": 0.0, "avg_logprob": -0.08206017975954666, "compression_ratio": 1.7285067873303168, "no_speech_prob": 0.004327489994466305}, {"id": 452, "seek": 329112, "start": 3310.08, "end": 3314.96, "text": " example that I showed, but it can be much more complex. It can be connected to CRM system, to", "tokens": [51312, 1365, 300, 286, 4712, 11, 457, 309, 393, 312, 709, 544, 3997, 13, 467, 393, 312, 4582, 281, 14123, 44, 1185, 11, 281, 51556], "temperature": 0.0, "avg_logprob": -0.08206017975954666, "compression_ratio": 1.7285067873303168, "no_speech_prob": 0.004327489994466305}, {"id": 453, "seek": 331496, "start": 3314.96, "end": 3323.04, "text": " databases, to existing websites, all different kinds of ERP and corporate systems.", "tokens": [50364, 22380, 11, 281, 6741, 12891, 11, 439, 819, 3685, 295, 14929, 47, 293, 10896, 3652, 13, 50768], "temperature": 0.0, "avg_logprob": -0.10739407888272913, "compression_ratio": 1.328358208955224, "no_speech_prob": 0.001925709075294435}, {"id": 454, "seek": 331496, "start": 3326.88, "end": 3337.12, "text": " And one of the probably on par with engineering, one of the most widely used applications of AI", "tokens": [50960, 400, 472, 295, 264, 1391, 322, 971, 365, 7043, 11, 472, 295, 264, 881, 13371, 1143, 5821, 295, 7318, 51472], "temperature": 0.0, "avg_logprob": -0.10739407888272913, "compression_ratio": 1.328358208955224, "no_speech_prob": 0.001925709075294435}, {"id": 455, "seek": 333712, "start": 3338.08, "end": 3347.12, "text": " is marketing. And in marketing, there's a lot of things how AI can help. And most of those are", "tokens": [50412, 307, 6370, 13, 400, 294, 6370, 11, 456, 311, 257, 688, 295, 721, 577, 7318, 393, 854, 13, 400, 881, 295, 729, 366, 50864], "temperature": 0.0, "avg_logprob": -0.12228817289525812, "compression_ratio": 1.7793427230046948, "no_speech_prob": 0.14009147882461548}, {"id": 456, "seek": 333712, "start": 3347.12, "end": 3353.52, "text": " related to either content generation. So you can create articles, blog posts, you can create text", "tokens": [50864, 4077, 281, 2139, 2701, 5125, 13, 407, 291, 393, 1884, 11290, 11, 6968, 12300, 11, 291, 393, 1884, 2487, 51184], "temperature": 0.0, "avg_logprob": -0.12228817289525812, "compression_ratio": 1.7793427230046948, "no_speech_prob": 0.14009147882461548}, {"id": 457, "seek": 333712, "start": 3353.52, "end": 3359.3599999999997, "text": " that is search engine optimized, you can create graphics, you can even create videos, you can", "tokens": [51184, 300, 307, 3164, 2848, 26941, 11, 291, 393, 1884, 11837, 11, 291, 393, 754, 1884, 2145, 11, 291, 393, 51476], "temperature": 0.0, "avg_logprob": -0.12228817289525812, "compression_ratio": 1.7793427230046948, "no_speech_prob": 0.14009147882461548}, {"id": 458, "seek": 333712, "start": 3359.3599999999997, "end": 3366.88, "text": " create personalized content, which is something that was never possible before the AI. So if", "tokens": [51476, 1884, 28415, 2701, 11, 597, 307, 746, 300, 390, 1128, 1944, 949, 264, 7318, 13, 407, 498, 51852], "temperature": 0.0, "avg_logprob": -0.12228817289525812, "compression_ratio": 1.7793427230046948, "no_speech_prob": 0.14009147882461548}, {"id": 459, "seek": 336688, "start": 3366.88, "end": 3372.8, "text": " your company has, let's say you have 100,000 customers and you know something about those", "tokens": [50364, 428, 2237, 575, 11, 718, 311, 584, 291, 362, 2319, 11, 1360, 4581, 293, 291, 458, 746, 466, 729, 50660], "temperature": 0.0, "avg_logprob": -0.08128698305650191, "compression_ratio": 1.6946902654867257, "no_speech_prob": 0.000767058227211237}, {"id": 460, "seek": 336688, "start": 3372.8, "end": 3381.76, "text": " customers and you want to say them a personalized Christmas message, it was never possible to send", "tokens": [50660, 4581, 293, 291, 528, 281, 584, 552, 257, 28415, 5272, 3636, 11, 309, 390, 1128, 1944, 281, 2845, 51108], "temperature": 0.0, "avg_logprob": -0.08128698305650191, "compression_ratio": 1.6946902654867257, "no_speech_prob": 0.000767058227211237}, {"id": 461, "seek": 336688, "start": 3381.76, "end": 3389.6800000000003, "text": " to manually write 100,000 messages to all of your customers. But now with AI, you can just upload", "tokens": [51108, 281, 16945, 2464, 2319, 11, 1360, 7897, 281, 439, 295, 428, 4581, 13, 583, 586, 365, 7318, 11, 291, 393, 445, 6580, 51504], "temperature": 0.0, "avg_logprob": -0.08128698305650191, "compression_ratio": 1.6946902654867257, "no_speech_prob": 0.000767058227211237}, {"id": 462, "seek": 336688, "start": 3389.6800000000003, "end": 3395.6800000000003, "text": " some of the personal information that you know about the customers, like I don't know where they", "tokens": [51504, 512, 295, 264, 2973, 1589, 300, 291, 458, 466, 264, 4581, 11, 411, 286, 500, 380, 458, 689, 436, 51804], "temperature": 0.0, "avg_logprob": -0.08128698305650191, "compression_ratio": 1.6946902654867257, "no_speech_prob": 0.000767058227211237}, {"id": 463, "seek": 339568, "start": 3395.68, "end": 3403.2, "text": " leave or what their interests or what do they like. And then have AI to generate 100,000 personalized", "tokens": [50364, 1856, 420, 437, 641, 8847, 420, 437, 360, 436, 411, 13, 400, 550, 362, 7318, 281, 8460, 2319, 11, 1360, 28415, 50740], "temperature": 0.0, "avg_logprob": -0.11947078506151836, "compression_ratio": 1.6394849785407726, "no_speech_prob": 0.0028870173264294863}, {"id": 464, "seek": 339568, "start": 3403.2, "end": 3411.3599999999997, "text": " messages. And this can be just fun, just to do something nice to your customers. But this is", "tokens": [50740, 7897, 13, 400, 341, 393, 312, 445, 1019, 11, 445, 281, 360, 746, 1481, 281, 428, 4581, 13, 583, 341, 307, 51148], "temperature": 0.0, "avg_logprob": -0.11947078506151836, "compression_ratio": 1.6394849785407726, "no_speech_prob": 0.0028870173264294863}, {"id": 465, "seek": 339568, "start": 3411.3599999999997, "end": 3415.68, "text": " also valuable for the business. So if you're a business, let's say you are for financial", "tokens": [51148, 611, 8263, 337, 264, 1606, 13, 407, 498, 291, 434, 257, 1606, 11, 718, 311, 584, 291, 366, 337, 4669, 51364], "temperature": 0.0, "avg_logprob": -0.11947078506151836, "compression_ratio": 1.6394849785407726, "no_speech_prob": 0.0028870173264294863}, {"id": 466, "seek": 339568, "start": 3415.68, "end": 3421.6, "text": " organizations, for example, we have a customer who's a bank. And for them, what they do, they know", "tokens": [51364, 6150, 11, 337, 1365, 11, 321, 362, 257, 5474, 567, 311, 257, 3765, 13, 400, 337, 552, 11, 437, 436, 360, 11, 436, 458, 51660], "temperature": 0.0, "avg_logprob": -0.11947078506151836, "compression_ratio": 1.6394849785407726, "no_speech_prob": 0.0028870173264294863}, {"id": 467, "seek": 342160, "start": 3422.3199999999997, "end": 3427.12, "text": " like financial preferences of all their customers. And then the right messages that", "tokens": [50400, 411, 4669, 21910, 295, 439, 641, 4581, 13, 400, 550, 264, 558, 7897, 300, 50640], "temperature": 0.0, "avg_logprob": -0.16311379001565177, "compression_ratio": 1.6425339366515836, "no_speech_prob": 0.0050576901994645596}, {"id": 468, "seek": 342160, "start": 3429.2799999999997, "end": 3435.7599999999998, "text": " are digest on the news in the stock market, based on specific interests. So if someone is", "tokens": [50748, 366, 13884, 322, 264, 2583, 294, 264, 4127, 2142, 11, 2361, 322, 2685, 8847, 13, 407, 498, 1580, 307, 51072], "temperature": 0.0, "avg_logprob": -0.16311379001565177, "compression_ratio": 1.6425339366515836, "no_speech_prob": 0.0050576901994645596}, {"id": 469, "seek": 342160, "start": 3435.7599999999998, "end": 3441.12, "text": " investing in high tech and another person is investing in, let's say sustainability companies,", "tokens": [51072, 10978, 294, 1090, 7553, 293, 1071, 954, 307, 10978, 294, 11, 718, 311, 584, 16360, 3431, 11, 51340], "temperature": 0.0, "avg_logprob": -0.16311379001565177, "compression_ratio": 1.6425339366515836, "no_speech_prob": 0.0050576901994645596}, {"id": 470, "seek": 342160, "start": 3442.16, "end": 3450.96, "text": " these two persons will receive very personal and individual and very different email marketing", "tokens": [51392, 613, 732, 14453, 486, 4774, 588, 2973, 293, 2609, 293, 588, 819, 3796, 6370, 51832], "temperature": 0.0, "avg_logprob": -0.16311379001565177, "compression_ratio": 1.6425339366515836, "no_speech_prob": 0.0050576901994645596}, {"id": 471, "seek": 345160, "start": 3451.6, "end": 3458.3199999999997, "text": " or email digest. And that is not just cool and fun. It is really increasing the conversion rate", "tokens": [50364, 420, 3796, 13884, 13, 400, 300, 307, 406, 445, 1627, 293, 1019, 13, 467, 307, 534, 5662, 264, 14298, 3314, 50700], "temperature": 0.0, "avg_logprob": -0.09617055352054425, "compression_ratio": 1.53551912568306, "no_speech_prob": 0.0010000927140936255}, {"id": 472, "seek": 345160, "start": 3458.3199999999997, "end": 3466.24, "text": " and click through rate. And at the end, it is beneficial for the bottom line for how much", "tokens": [50700, 293, 2052, 807, 3314, 13, 400, 412, 264, 917, 11, 309, 307, 14072, 337, 264, 2767, 1622, 337, 577, 709, 51096], "temperature": 0.0, "avg_logprob": -0.09617055352054425, "compression_ratio": 1.53551912568306, "no_speech_prob": 0.0010000927140936255}, {"id": 473, "seek": 345160, "start": 3466.24, "end": 3477.7599999999998, "text": " profit the company makes. And one more example here to show is customer operations. So the idea", "tokens": [51096, 7475, 264, 2237, 1669, 13, 400, 472, 544, 1365, 510, 281, 855, 307, 5474, 7705, 13, 407, 264, 1558, 51672], "temperature": 0.0, "avg_logprob": -0.09617055352054425, "compression_ratio": 1.53551912568306, "no_speech_prob": 0.0010000927140936255}, {"id": 474, "seek": 347776, "start": 3477.76, "end": 3485.1200000000003, "text": " of using AI in customer operations is that you can actually use AI, not instead of sales", "tokens": [50364, 295, 1228, 7318, 294, 5474, 7705, 307, 300, 291, 393, 767, 764, 7318, 11, 406, 2602, 295, 5763, 50732], "temperature": 0.0, "avg_logprob": -0.1311406284929758, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.005905626341700554}, {"id": 475, "seek": 347776, "start": 3485.1200000000003, "end": 3490.0800000000004, "text": " representative, because sometimes you still need human to human interaction to close the sales.", "tokens": [50732, 12424, 11, 570, 2171, 291, 920, 643, 1952, 281, 1952, 9285, 281, 1998, 264, 5763, 13, 50980], "temperature": 0.0, "avg_logprob": -0.1311406284929758, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.005905626341700554}, {"id": 476, "seek": 347776, "start": 3490.7200000000003, "end": 3499.2000000000003, "text": " But you can have it as an assistant, as a co-pilot to sales agents. So AI can help", "tokens": [51012, 583, 291, 393, 362, 309, 382, 364, 10994, 11, 382, 257, 598, 12, 79, 31516, 281, 5763, 12554, 13, 407, 7318, 393, 854, 51436], "temperature": 0.0, "avg_logprob": -0.1311406284929758, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.005905626341700554}, {"id": 477, "seek": 347776, "start": 3500.48, "end": 3505.84, "text": " sales agents and show them proactively show them some information that is relevant. What", "tokens": [51500, 5763, 12554, 293, 855, 552, 447, 45679, 855, 552, 512, 1589, 300, 307, 7340, 13, 708, 51768], "temperature": 0.0, "avg_logprob": -0.1311406284929758, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.005905626341700554}, {"id": 478, "seek": 350584, "start": 3505.84, "end": 3512.08, "text": " makes sense to say to the customer. And it can also handle some of the cases. So if there are", "tokens": [50364, 1669, 2020, 281, 584, 281, 264, 5474, 13, 400, 309, 393, 611, 4813, 512, 295, 264, 3331, 13, 407, 498, 456, 366, 50676], "temperature": 0.0, "avg_logprob": -0.12075335358920163, "compression_ratio": 1.5846994535519126, "no_speech_prob": 0.000356849777745083}, {"id": 479, "seek": 350584, "start": 3512.08, "end": 3516.96, "text": " simple questions, then AI can answer. If there's something more complex, or if the customer's", "tokens": [50676, 2199, 1651, 11, 550, 7318, 393, 1867, 13, 759, 456, 311, 746, 544, 3997, 11, 420, 498, 264, 5474, 311, 50920], "temperature": 0.0, "avg_logprob": -0.12075335358920163, "compression_ratio": 1.5846994535519126, "no_speech_prob": 0.000356849777745083}, {"id": 480, "seek": 350584, "start": 3516.96, "end": 3527.04, "text": " clothes is ready to buy, then it can send it to a sales representative and allow to speak to a person.", "tokens": [50920, 5534, 307, 1919, 281, 2256, 11, 550, 309, 393, 2845, 309, 281, 257, 5763, 12424, 293, 2089, 281, 1710, 281, 257, 954, 13, 51424], "temperature": 0.0, "avg_logprob": -0.12075335358920163, "compression_ratio": 1.5846994535519126, "no_speech_prob": 0.000356849777745083}, {"id": 481, "seek": 352704, "start": 3527.84, "end": 3535.36, "text": " This is an example from legal. What I did here is it's very similar to the visualization example", "tokens": [50404, 639, 307, 364, 1365, 490, 5089, 13, 708, 286, 630, 510, 307, 309, 311, 588, 2531, 281, 264, 25801, 1365, 50780], "temperature": 0.0, "avg_logprob": -0.18050147547866358, "compression_ratio": 1.53475935828877, "no_speech_prob": 0.008843849413096905}, {"id": 482, "seek": 352704, "start": 3535.36, "end": 3541.92, "text": " that I showed in the beginning. But this is applied to contracts. Sometimes you have very", "tokens": [50780, 300, 286, 4712, 294, 264, 2863, 13, 583, 341, 307, 6456, 281, 13952, 13, 4803, 291, 362, 588, 51108], "temperature": 0.0, "avg_logprob": -0.18050147547866358, "compression_ratio": 1.53475935828877, "no_speech_prob": 0.008843849413096905}, {"id": 483, "seek": 352704, "start": 3541.92, "end": 3548.0, "text": " complex, very large legal contracts that are hard to understand, especially if you are not a lawyer.", "tokens": [51108, 3997, 11, 588, 2416, 5089, 13952, 300, 366, 1152, 281, 1223, 11, 2318, 498, 291, 366, 406, 257, 11613, 13, 51412], "temperature": 0.0, "avg_logprob": -0.18050147547866358, "compression_ratio": 1.53475935828877, "no_speech_prob": 0.008843849413096905}, {"id": 484, "seek": 354800, "start": 3548.16, "end": 3555.68, "text": " So AI and large language models can be used here to create a diagram based on the contract. So,", "tokens": [50372, 407, 7318, 293, 2416, 2856, 5245, 393, 312, 1143, 510, 281, 1884, 257, 10686, 2361, 322, 264, 4364, 13, 407, 11, 50748], "temperature": 0.0, "avg_logprob": -0.21272922384327855, "compression_ratio": 1.5695652173913044, "no_speech_prob": 0.18691252171993256}, {"id": 485, "seek": 354800, "start": 3555.68, "end": 3561.6, "text": " for example, there's a 15-pages contract. And this is the diagram that only mentions", "tokens": [50748, 337, 1365, 11, 456, 311, 257, 2119, 12, 79, 1660, 4364, 13, 400, 341, 307, 264, 10686, 300, 787, 23844, 51044], "temperature": 0.0, "avg_logprob": -0.21272922384327855, "compression_ratio": 1.5695652173913044, "no_speech_prob": 0.18691252171993256}, {"id": 486, "seek": 354800, "start": 3562.24, "end": 3567.44, "text": " most important things for me to maybe make a decision or to review this diagram. So it does", "tokens": [51076, 881, 1021, 721, 337, 385, 281, 1310, 652, 257, 3537, 420, 281, 3131, 341, 10686, 13, 407, 309, 775, 51336], "temperature": 0.0, "avg_logprob": -0.21272922384327855, "compression_ratio": 1.5695652173913044, "no_speech_prob": 0.18691252171993256}, {"id": 487, "seek": 354800, "start": 3567.44, "end": 3573.68, "text": " not replace the work of the lawyer, but it is helpful for maybe executives or management", "tokens": [51336, 406, 7406, 264, 589, 295, 264, 11613, 11, 457, 309, 307, 4961, 337, 1310, 28485, 420, 4592, 51648], "temperature": 0.0, "avg_logprob": -0.21272922384327855, "compression_ratio": 1.5695652173913044, "no_speech_prob": 0.18691252171993256}, {"id": 488, "seek": 357368, "start": 3574.08, "end": 3579.2, "text": " to see what's going on without reading all these 15-pages of complex legal text.", "tokens": [50384, 281, 536, 437, 311, 516, 322, 1553, 3760, 439, 613, 2119, 12, 79, 1660, 295, 3997, 5089, 2487, 13, 50640], "temperature": 0.0, "avg_logprob": -0.27546119689941406, "compression_ratio": 1.5, "no_speech_prob": 0.0027137103024870157}, {"id": 489, "seek": 357368, "start": 3579.2, "end": 3586.08, "text": " And that's just one of the examples. I'm skipping some things because we're close to the end of", "tokens": [50640, 400, 300, 311, 445, 472, 295, 264, 5110, 13, 286, 478, 31533, 512, 721, 570, 321, 434, 1998, 281, 264, 917, 295, 50984], "temperature": 0.0, "avg_logprob": -0.27546119689941406, "compression_ratio": 1.5, "no_speech_prob": 0.0027137103024870157}, {"id": 490, "seek": 357368, "start": 3586.08, "end": 3597.04, "text": " presentation. But on the left, I have more examples for use cases of AI in each one of those areas.", "tokens": [50984, 5860, 13, 583, 322, 264, 1411, 11, 286, 362, 544, 5110, 337, 764, 3331, 295, 7318, 294, 1184, 472, 295, 729, 3179, 13, 51532], "temperature": 0.0, "avg_logprob": -0.27546119689941406, "compression_ratio": 1.5, "no_speech_prob": 0.0027137103024870157}, {"id": 491, "seek": 359704, "start": 3597.92, "end": 3607.44, "text": " One more area I want to highlight, I think it's very, very important, is people operations and HR.", "tokens": [50408, 1485, 544, 1859, 286, 528, 281, 5078, 11, 286, 519, 309, 311, 588, 11, 588, 1021, 11, 307, 561, 7705, 293, 19460, 13, 50884], "temperature": 0.0, "avg_logprob": -0.20489481723669803, "compression_ratio": 1.5183246073298429, "no_speech_prob": 0.020320480689406395}, {"id": 492, "seek": 359704, "start": 3607.44, "end": 3616.56, "text": " And the reason I think large language models and AI is very useful here is because trading and", "tokens": [50884, 400, 264, 1778, 286, 519, 2416, 2856, 5245, 293, 7318, 307, 588, 4420, 510, 307, 570, 9529, 293, 51340], "temperature": 0.0, "avg_logprob": -0.20489481723669803, "compression_ratio": 1.5183246073298429, "no_speech_prob": 0.020320480689406395}, {"id": 493, "seek": 359704, "start": 3616.56, "end": 3624.48, "text": " education is really the core of most businesses, like people are what makes business successful.", "tokens": [51340, 3309, 307, 534, 264, 4965, 295, 881, 6011, 11, 411, 561, 366, 437, 1669, 1606, 4406, 13, 51736], "temperature": 0.0, "avg_logprob": -0.20489481723669803, "compression_ratio": 1.5183246073298429, "no_speech_prob": 0.020320480689406395}, {"id": 494, "seek": 362448, "start": 3625.28, "end": 3637.6, "text": " And I'm really a big fan and I really believe in the fact that large language models will do a lot of,", "tokens": [50404, 400, 286, 478, 534, 257, 955, 3429, 293, 286, 534, 1697, 294, 264, 1186, 300, 2416, 2856, 5245, 486, 360, 257, 688, 295, 11, 51020], "temperature": 0.0, "avg_logprob": -0.2406088165614916, "compression_ratio": 1.4142857142857144, "no_speech_prob": 0.002357460791245103}, {"id": 495, "seek": 362448, "start": 3639.6, "end": 3649.12, "text": " will enhance and improve and improve quality of education worldwide. Meaning that AI is helpful", "tokens": [51120, 486, 11985, 293, 3470, 293, 3470, 3125, 295, 3309, 13485, 13, 19948, 300, 7318, 307, 4961, 51596], "temperature": 0.0, "avg_logprob": -0.2406088165614916, "compression_ratio": 1.4142857142857144, "no_speech_prob": 0.002357460791245103}, {"id": 496, "seek": 364912, "start": 3649.2799999999997, "end": 3656.48, "text": " as a tutor, even for the startups that are building AI educational software for", "tokens": [50372, 382, 257, 35613, 11, 754, 337, 264, 28041, 300, 366, 2390, 7318, 10189, 4722, 337, 50732], "temperature": 0.0, "avg_logprob": -0.183598844628585, "compression_ratio": 1.6018518518518519, "no_speech_prob": 0.007339601870626211}, {"id": 497, "seek": 364912, "start": 3657.2, "end": 3663.6, "text": " school children, for universities, and for corporate training programs as well. So AI can", "tokens": [50768, 1395, 2227, 11, 337, 11779, 11, 293, 337, 10896, 3097, 4268, 382, 731, 13, 407, 7318, 393, 51088], "temperature": 0.0, "avg_logprob": -0.183598844628585, "compression_ratio": 1.6018518518518519, "no_speech_prob": 0.007339601870626211}, {"id": 498, "seek": 364912, "start": 3664.3199999999997, "end": 3670.72, "text": " run, can explain complex information as shown. It can generate case studies. It can simulate", "tokens": [51124, 1190, 11, 393, 2903, 3997, 1589, 382, 4898, 13, 467, 393, 8460, 1389, 5313, 13, 467, 393, 27817, 51444], "temperature": 0.0, "avg_logprob": -0.183598844628585, "compression_ratio": 1.6018518518518519, "no_speech_prob": 0.007339601870626211}, {"id": 499, "seek": 364912, "start": 3670.72, "end": 3676.16, "text": " some real work behavior. So for example, if you are training sales representatives,", "tokens": [51444, 512, 957, 589, 5223, 13, 407, 337, 1365, 11, 498, 291, 366, 3097, 5763, 18628, 11, 51716], "temperature": 0.0, "avg_logprob": -0.183598844628585, "compression_ratio": 1.6018518518518519, "no_speech_prob": 0.007339601870626211}, {"id": 500, "seek": 367616, "start": 3676.16, "end": 3682.48, "text": " you can generate, you can ask AI to be a partner to train and to", "tokens": [50364, 291, 393, 8460, 11, 291, 393, 1029, 7318, 281, 312, 257, 4975, 281, 3847, 293, 281, 50680], "temperature": 0.0, "avg_logprob": -0.12686312376563227, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.0010807170765474439}, {"id": 501, "seek": 367616, "start": 3685.44, "end": 3691.52, "text": " practice some sales skills. So you can ask AI to be an angry customer. And then it helps", "tokens": [50828, 3124, 512, 5763, 3942, 13, 407, 291, 393, 1029, 7318, 281, 312, 364, 6884, 5474, 13, 400, 550, 309, 3665, 51132], "temperature": 0.0, "avg_logprob": -0.12686312376563227, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.0010807170765474439}, {"id": 502, "seek": 367616, "start": 3692.08, "end": 3700.3199999999997, "text": " people who are new to the job to know what to say if somebody is angry. Or you can ask AI to", "tokens": [51160, 561, 567, 366, 777, 281, 264, 1691, 281, 458, 437, 281, 584, 498, 2618, 307, 6884, 13, 1610, 291, 393, 1029, 7318, 281, 51572], "temperature": 0.0, "avg_logprob": -0.12686312376563227, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.0010807170765474439}, {"id": 503, "seek": 370032, "start": 3701.1200000000003, "end": 3706.2400000000002, "text": " to simulate a market situation. And that is useful for practicing", "tokens": [50404, 281, 27817, 257, 2142, 2590, 13, 400, 300, 307, 4420, 337, 11350, 50660], "temperature": 0.0, "avg_logprob": -0.12226475726117145, "compression_ratio": 1.5972222222222223, "no_speech_prob": 0.007337265647947788}, {"id": 504, "seek": 370032, "start": 3708.1600000000003, "end": 3713.44, "text": " maybe some management skills. Or you can ask AI to generate a code that has some bucks.", "tokens": [50756, 1310, 512, 4592, 3942, 13, 1610, 291, 393, 1029, 7318, 281, 8460, 257, 3089, 300, 575, 512, 11829, 13, 51020], "temperature": 0.0, "avg_logprob": -0.12226475726117145, "compression_ratio": 1.5972222222222223, "no_speech_prob": 0.007337265647947788}, {"id": 505, "seek": 370032, "start": 3713.44, "end": 3722.88, "text": " And it's useful to upskill and train engineers. So this is, there's a lot of examples like this,", "tokens": [51020, 400, 309, 311, 4420, 281, 493, 5161, 373, 293, 3847, 11955, 13, 407, 341, 307, 11, 456, 311, 257, 688, 295, 5110, 411, 341, 11, 51492], "temperature": 0.0, "avg_logprob": -0.12226475726117145, "compression_ratio": 1.5972222222222223, "no_speech_prob": 0.007337265647947788}, {"id": 506, "seek": 370032, "start": 3722.88, "end": 3728.48, "text": " or a lot of, I would say, a lot of products, a lot of companies. So when we go into enterprise", "tokens": [51492, 420, 257, 688, 295, 11, 286, 576, 584, 11, 257, 688, 295, 3383, 11, 257, 688, 295, 3431, 13, 407, 562, 321, 352, 666, 14132, 51772], "temperature": 0.0, "avg_logprob": -0.12226475726117145, "compression_ratio": 1.5972222222222223, "no_speech_prob": 0.007337265647947788}, {"id": 507, "seek": 372848, "start": 3728.48, "end": 3735.36, "text": " use cases, those are mostly not free. Those are some big products or big companies doing this", "tokens": [50364, 764, 3331, 11, 729, 366, 5240, 406, 1737, 13, 3950, 366, 512, 955, 3383, 420, 955, 3431, 884, 341, 50708], "temperature": 0.0, "avg_logprob": -0.0921734128679548, "compression_ratio": 1.5698324022346368, "no_speech_prob": 0.0036390742752701044}, {"id": 508, "seek": 372848, "start": 3735.36, "end": 3746.0, "text": " and also small startups. But I, my suggestion is to really to, to pay close attention to AI", "tokens": [50708, 293, 611, 1359, 28041, 13, 583, 286, 11, 452, 16541, 307, 281, 534, 281, 11, 281, 1689, 1998, 3202, 281, 7318, 51240], "temperature": 0.0, "avg_logprob": -0.0921734128679548, "compression_ratio": 1.5698324022346368, "no_speech_prob": 0.0036390742752701044}, {"id": 509, "seek": 372848, "start": 3746.0, "end": 3751.44, "text": " products in all of these areas. Because at the end of the day, what it gives, it gives economic", "tokens": [51240, 3383, 294, 439, 295, 613, 3179, 13, 1436, 412, 264, 917, 295, 264, 786, 11, 437, 309, 2709, 11, 309, 2709, 4836, 51512], "temperature": 0.0, "avg_logprob": -0.0921734128679548, "compression_ratio": 1.5698324022346368, "no_speech_prob": 0.0036390742752701044}, {"id": 510, "seek": 375144, "start": 3751.44, "end": 3759.6, "text": " efficiency. And it allows to save costs. And it also allows to find new market opportunities.", "tokens": [50364, 10493, 13, 400, 309, 4045, 281, 3155, 5497, 13, 400, 309, 611, 4045, 281, 915, 777, 2142, 4786, 13, 50772], "temperature": 0.0, "avg_logprob": -0.06615166187286377, "compression_ratio": 1.4921875, "no_speech_prob": 0.043288204818964005}, {"id": 511, "seek": 375144, "start": 3760.32, "end": 3769.68, "text": " And to wrap it up, I want to, I want to show one more slide here, which is regarding AI strategy.", "tokens": [50808, 400, 281, 7019, 309, 493, 11, 286, 528, 281, 11, 286, 528, 281, 855, 472, 544, 4137, 510, 11, 597, 307, 8595, 7318, 5206, 13, 51276], "temperature": 0.0, "avg_logprob": -0.06615166187286377, "compression_ratio": 1.4921875, "no_speech_prob": 0.043288204818964005}, {"id": 512, "seek": 376968, "start": 3770.24, "end": 3783.2, "text": " So if you, if you plan to use AI in your business, I have a specific, I would say, plan or, or, or,", "tokens": [50392, 407, 498, 291, 11, 498, 291, 1393, 281, 764, 7318, 294, 428, 1606, 11, 286, 362, 257, 2685, 11, 286, 576, 584, 11, 1393, 420, 11, 420, 11, 420, 11, 51040], "temperature": 0.0, "avg_logprob": -0.19208980798721315, "compression_ratio": 1.5828877005347595, "no_speech_prob": 0.0103216003626585}, {"id": 513, "seek": 376968, "start": 3783.2, "end": 3788.64, "text": " or suggestion how to approach this, because it might be overwhelming. There's a lot of products.", "tokens": [51040, 420, 16541, 577, 281, 3109, 341, 11, 570, 309, 1062, 312, 13373, 13, 821, 311, 257, 688, 295, 3383, 13, 51312], "temperature": 0.0, "avg_logprob": -0.19208980798721315, "compression_ratio": 1.5828877005347595, "no_speech_prob": 0.0103216003626585}, {"id": 514, "seek": 376968, "start": 3788.64, "end": 3793.2, "text": " There's a lot of people trying to sell all different kinds of things. Some of those might be great.", "tokens": [51312, 821, 311, 257, 688, 295, 561, 1382, 281, 3607, 439, 819, 3685, 295, 721, 13, 2188, 295, 729, 1062, 312, 869, 13, 51540], "temperature": 0.0, "avg_logprob": -0.19208980798721315, "compression_ratio": 1.5828877005347595, "no_speech_prob": 0.0103216003626585}, {"id": 515, "seek": 379320, "start": 3793.9199999999996, "end": 3798.48, "text": " Some of those might be great. Some of those might be very, very simple and too expensive.", "tokens": [50400, 2188, 295, 729, 1062, 312, 869, 13, 2188, 295, 729, 1062, 312, 588, 11, 588, 2199, 293, 886, 5124, 13, 50628], "temperature": 0.0, "avg_logprob": -0.10672049619713608, "compression_ratio": 1.6991150442477876, "no_speech_prob": 0.07363311201334}, {"id": 516, "seek": 379320, "start": 3799.04, "end": 3805.04, "text": " So in order to do it correctly and in order to do it, like not to rush things, but also not to", "tokens": [50656, 407, 294, 1668, 281, 360, 309, 8944, 293, 294, 1668, 281, 360, 309, 11, 411, 406, 281, 9300, 721, 11, 457, 611, 406, 281, 50956], "temperature": 0.0, "avg_logprob": -0.10672049619713608, "compression_ratio": 1.6991150442477876, "no_speech_prob": 0.07363311201334}, {"id": 517, "seek": 379320, "start": 3805.04, "end": 3813.6, "text": " wait until it's too late, I suggest starting with experiments with chat. So any simple business task", "tokens": [50956, 1699, 1826, 309, 311, 886, 3469, 11, 286, 3402, 2891, 365, 12050, 365, 5081, 13, 407, 604, 2199, 1606, 5633, 51384], "temperature": 0.0, "avg_logprob": -0.10672049619713608, "compression_ratio": 1.6991150442477876, "no_speech_prob": 0.07363311201334}, {"id": 518, "seek": 379320, "start": 3813.6, "end": 3820.72, "text": " can be validated and can be tested in chat GPT, even in the free version. And that gives you idea,", "tokens": [51384, 393, 312, 40693, 293, 393, 312, 8246, 294, 5081, 26039, 51, 11, 754, 294, 264, 1737, 3037, 13, 400, 300, 2709, 291, 1558, 11, 51740], "temperature": 0.0, "avg_logprob": -0.10672049619713608, "compression_ratio": 1.6991150442477876, "no_speech_prob": 0.07363311201334}, {"id": 519, "seek": 382072, "start": 3820.7999999999997, "end": 3825.9199999999996, "text": " overall idea, like, is it even possible and what would be the quality of the results? Some tasks", "tokens": [50368, 4787, 1558, 11, 411, 11, 307, 309, 754, 1944, 293, 437, 576, 312, 264, 3125, 295, 264, 3542, 30, 2188, 9608, 50624], "temperature": 0.0, "avg_logprob": -0.08459504760137879, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.001895853434689343}, {"id": 520, "seek": 382072, "start": 3825.9199999999996, "end": 3832.3999999999996, "text": " they are possible to do, but the quality is too bad. It's still like AI is still not as smart to", "tokens": [50624, 436, 366, 1944, 281, 360, 11, 457, 264, 3125, 307, 886, 1578, 13, 467, 311, 920, 411, 7318, 307, 920, 406, 382, 4069, 281, 50948], "temperature": 0.0, "avg_logprob": -0.08459504760137879, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.001895853434689343}, {"id": 521, "seek": 382072, "start": 3832.3999999999996, "end": 3838.9599999999996, "text": " automate them. In some tasks, you will get good results. Once you have an experiment that you see", "tokens": [50948, 31605, 552, 13, 682, 512, 9608, 11, 291, 486, 483, 665, 3542, 13, 3443, 291, 362, 364, 5120, 300, 291, 536, 51276], "temperature": 0.0, "avg_logprob": -0.08459504760137879, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.001895853434689343}, {"id": 522, "seek": 382072, "start": 3838.9599999999996, "end": 3846.64, "text": " is working well in the chat, the next step would be to create a co-pilot, a workflow, maybe connect", "tokens": [51276, 307, 1364, 731, 294, 264, 5081, 11, 264, 958, 1823, 576, 312, 281, 1884, 257, 598, 12, 79, 31516, 11, 257, 20993, 11, 1310, 1745, 51660], "temperature": 0.0, "avg_logprob": -0.08459504760137879, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.001895853434689343}, {"id": 523, "seek": 384664, "start": 3846.72, "end": 3854.48, "text": " a few chats with preset prompts. So one chat is, one prompt is responsible for writing a text,", "tokens": [50368, 257, 1326, 38057, 365, 32081, 41095, 13, 407, 472, 5081, 307, 11, 472, 12391, 307, 6250, 337, 3579, 257, 2487, 11, 50756], "temperature": 0.0, "avg_logprob": -0.17099376158280807, "compression_ratio": 1.66875, "no_speech_prob": 0.0015244041569530964}, {"id": 524, "seek": 384664, "start": 3854.48, "end": 3859.6, "text": " and the second prompt is responsible for proofreading a text. And then you combine these", "tokens": [50756, 293, 264, 1150, 12391, 307, 6250, 337, 8177, 35908, 257, 2487, 13, 400, 550, 291, 10432, 613, 51012], "temperature": 0.0, "avg_logprob": -0.17099376158280807, "compression_ratio": 1.66875, "no_speech_prob": 0.0015244041569530964}, {"id": 525, "seek": 384664, "start": 3859.6, "end": 3866.4, "text": " two together and you get to an agent. Agent is, when I show that slide with chains,", "tokens": [51012, 732, 1214, 293, 291, 483, 281, 364, 9461, 13, 27174, 307, 11, 562, 286, 855, 300, 4137, 365, 12626, 11, 51352], "temperature": 0.0, "avg_logprob": -0.17099376158280807, "compression_ratio": 1.66875, "no_speech_prob": 0.0015244041569530964}, {"id": 526, "seek": 386640, "start": 3866.4, "end": 3877.6, "text": " agent is a system, is a application that takes result of one AI tool and passes it to the next", "tokens": [50364, 9461, 307, 257, 1185, 11, 307, 257, 3861, 300, 2516, 1874, 295, 472, 7318, 2290, 293, 11335, 309, 281, 264, 958, 50924], "temperature": 0.0, "avg_logprob": -0.14195053394024187, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.0032717883586883545}, {"id": 527, "seek": 386640, "start": 3877.6, "end": 3882.32, "text": " tool and then passes it to the next tool. And those agents are relatively simple to develop.", "tokens": [50924, 2290, 293, 550, 11335, 309, 281, 264, 958, 2290, 13, 400, 729, 12554, 366, 7226, 2199, 281, 1499, 13, 51160], "temperature": 0.0, "avg_logprob": -0.14195053394024187, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.0032717883586883545}, {"id": 528, "seek": 386640, "start": 3882.32, "end": 3888.48, "text": " You can use either no-code platforms, you can use it, build it internally if you have software", "tokens": [51160, 509, 393, 764, 2139, 572, 12, 22332, 9473, 11, 291, 393, 764, 309, 11, 1322, 309, 19501, 498, 291, 362, 4722, 51468], "temperature": 0.0, "avg_logprob": -0.14195053394024187, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.0032717883586883545}, {"id": 529, "seek": 386640, "start": 3888.48, "end": 3893.92, "text": " engineering team in your company, or you can find external developers. And this is not too expensive,", "tokens": [51468, 7043, 1469, 294, 428, 2237, 11, 420, 291, 393, 915, 8320, 8849, 13, 400, 341, 307, 406, 886, 5124, 11, 51740], "temperature": 0.0, "avg_logprob": -0.14195053394024187, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.0032717883586883545}, {"id": 530, "seek": 389392, "start": 3893.92, "end": 3900.4, "text": " like AI used to cost hundreds of thousands or even millions of dollars, like five, 10 years ago,", "tokens": [50364, 411, 7318, 1143, 281, 2063, 6779, 295, 5383, 420, 754, 6803, 295, 3808, 11, 411, 1732, 11, 1266, 924, 2057, 11, 50688], "temperature": 0.0, "avg_logprob": -0.17144917405169943, "compression_ratio": 1.6277056277056277, "no_speech_prob": 0.0018961116438731551}, {"id": 531, "seek": 389392, "start": 3900.4, "end": 3905.84, "text": " like huge AI deploy the deployment projects. Right now, building agent for search engine", "tokens": [50688, 411, 2603, 7318, 7274, 264, 19317, 4455, 13, 1779, 586, 11, 2390, 9461, 337, 3164, 2848, 50960], "temperature": 0.0, "avg_logprob": -0.17144917405169943, "compression_ratio": 1.6277056277056277, "no_speech_prob": 0.0018961116438731551}, {"id": 532, "seek": 389392, "start": 3905.84, "end": 3911.52, "text": " optimization or sales or marketing, it can cost just a few thousand dollars, or you can do it,", "tokens": [50960, 19618, 420, 5763, 420, 6370, 11, 309, 393, 2063, 445, 257, 1326, 4714, 3808, 11, 420, 291, 393, 360, 309, 11, 51244], "temperature": 0.0, "avg_logprob": -0.17144917405169943, "compression_ratio": 1.6277056277056277, "no_speech_prob": 0.0018961116438731551}, {"id": 533, "seek": 389392, "start": 3911.52, "end": 3919.36, "text": " build it for free. And I will not show exactly, I will not do full tutorial, but I want to show", "tokens": [51244, 1322, 309, 337, 1737, 13, 400, 286, 486, 406, 855, 2293, 11, 286, 486, 406, 360, 1577, 7073, 11, 457, 286, 528, 281, 855, 51636], "temperature": 0.0, "avg_logprob": -0.17144917405169943, "compression_ratio": 1.6277056277056277, "no_speech_prob": 0.0018961116438731551}, {"id": 534, "seek": 391936, "start": 3919.6, "end": 3924.56, "text": " a couple of tools. One of them is called Relevance AI. Another one is called Skate Pro.", "tokens": [50376, 257, 1916, 295, 3873, 13, 1485, 295, 552, 307, 1219, 1300, 28316, 719, 7318, 13, 3996, 472, 307, 1219, 7324, 473, 1705, 13, 50624], "temperature": 0.0, "avg_logprob": -0.12113113204638164, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.029275942593812943}, {"id": 535, "seek": 391936, "start": 3925.84, "end": 3932.8, "text": " Let me just show their landing pages. And I have both links in the presentation. So", "tokens": [50688, 961, 385, 445, 855, 641, 11202, 7183, 13, 400, 286, 362, 1293, 6123, 294, 264, 5860, 13, 407, 51036], "temperature": 0.0, "avg_logprob": -0.12113113204638164, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.029275942593812943}, {"id": 536, "seek": 391936, "start": 3934.0, "end": 3942.0, "text": " this is just to show. So Relevance AI is a tool you can start using for free. They give you", "tokens": [51096, 341, 307, 445, 281, 855, 13, 407, 1300, 28316, 719, 7318, 307, 257, 2290, 291, 393, 722, 1228, 337, 1737, 13, 814, 976, 291, 51496], "temperature": 0.0, "avg_logprob": -0.12113113204638164, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.029275942593812943}, {"id": 537, "seek": 391936, "start": 3942.0, "end": 3946.96, "text": " quite a lot of free credits that you can use on the platform. So if it's small business,", "tokens": [51496, 1596, 257, 688, 295, 1737, 16816, 300, 291, 393, 764, 322, 264, 3663, 13, 407, 498, 309, 311, 1359, 1606, 11, 51744], "temperature": 0.0, "avg_logprob": -0.12113113204638164, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.029275942593812943}, {"id": 538, "seek": 394696, "start": 3946.96, "end": 3955.52, "text": " you might even get away with free version. And then Skate Pro is also, they combine 1500 different", "tokens": [50364, 291, 1062, 754, 483, 1314, 365, 1737, 3037, 13, 400, 550, 7324, 473, 1705, 307, 611, 11, 436, 10432, 22671, 819, 50792], "temperature": 0.0, "avg_logprob": -0.11329853534698486, "compression_ratio": 1.4572864321608041, "no_speech_prob": 0.0011875807540491223}, {"id": 539, "seek": 394696, "start": 3955.52, "end": 3963.12, "text": " AI tools in a cascade. So you can create these agents and create very, very simple, very, very,", "tokens": [50792, 7318, 3873, 294, 257, 50080, 13, 407, 291, 393, 1884, 613, 12554, 293, 1884, 588, 11, 588, 2199, 11, 588, 11, 588, 11, 51172], "temperature": 0.0, "avg_logprob": -0.11329853534698486, "compression_ratio": 1.4572864321608041, "no_speech_prob": 0.0011875807540491223}, {"id": 540, "seek": 394696, "start": 3963.12, "end": 3974.4, "text": " very powerful AI workflows. And maybe two last thing I want to say is that if something doesn't", "tokens": [51172, 588, 4005, 7318, 43461, 13, 400, 1310, 732, 1036, 551, 286, 528, 281, 584, 307, 300, 498, 746, 1177, 380, 51736], "temperature": 0.0, "avg_logprob": -0.11329853534698486, "compression_ratio": 1.4572864321608041, "no_speech_prob": 0.0011875807540491223}, {"id": 541, "seek": 397440, "start": 3974.4, "end": 3982.32, "text": " work, I want to encourage you to not give up. Because what is happening is that AI", "tokens": [50364, 589, 11, 286, 528, 281, 5373, 291, 281, 406, 976, 493, 13, 1436, 437, 307, 2737, 307, 300, 7318, 50760], "temperature": 0.0, "avg_logprob": -0.11717360814412435, "compression_ratio": 1.4666666666666666, "no_speech_prob": 0.013016589917242527}, {"id": 542, "seek": 397440, "start": 3984.0, "end": 3993.28, "text": " progress, progress in the AI space is stunningly fast. And we're moving at", "tokens": [50844, 4205, 11, 4205, 294, 264, 7318, 1901, 307, 18550, 356, 2370, 13, 400, 321, 434, 2684, 412, 51308], "temperature": 0.0, "avg_logprob": -0.11717360814412435, "compression_ratio": 1.4666666666666666, "no_speech_prob": 0.013016589917242527}, {"id": 543, "seek": 397440, "start": 3994.08, "end": 3999.92, "text": " increasing and unprecedented speed. So if something is not working, if you feel like", "tokens": [51348, 5662, 293, 21555, 3073, 13, 407, 498, 746, 307, 406, 1364, 11, 498, 291, 841, 411, 51640], "temperature": 0.0, "avg_logprob": -0.11717360814412435, "compression_ratio": 1.4666666666666666, "no_speech_prob": 0.013016589917242527}, {"id": 544, "seek": 399992, "start": 3999.92, "end": 4006.32, "text": " AI texts are maybe too dry, you don't like it. Or if you think that it is not helping you with", "tokens": [50364, 7318, 15765, 366, 1310, 886, 4016, 11, 291, 500, 380, 411, 309, 13, 1610, 498, 291, 519, 300, 309, 307, 406, 4315, 291, 365, 50684], "temperature": 0.0, "avg_logprob": -0.11011718917679, "compression_ratio": 1.6, "no_speech_prob": 0.0017537111416459084}, {"id": 545, "seek": 399992, "start": 4007.28, "end": 4012.08, "text": " sales process, or it only helps for a very small percentage of your potential customers,", "tokens": [50732, 5763, 1399, 11, 420, 309, 787, 3665, 337, 257, 588, 1359, 9668, 295, 428, 3995, 4581, 11, 50972], "temperature": 0.0, "avg_logprob": -0.11011718917679, "compression_ratio": 1.6, "no_speech_prob": 0.0017537111416459084}, {"id": 546, "seek": 399992, "start": 4012.88, "end": 4023.76, "text": " that is fine. But I really suggest you to keep, to just pay attention to the space. Because models", "tokens": [51012, 300, 307, 2489, 13, 583, 286, 534, 3402, 291, 281, 1066, 11, 281, 445, 1689, 3202, 281, 264, 1901, 13, 1436, 5245, 51556], "temperature": 0.0, "avg_logprob": -0.11011718917679, "compression_ratio": 1.6, "no_speech_prob": 0.0017537111416459084}, {"id": 547, "seek": 399992, "start": 4023.76, "end": 4028.2400000000002, "text": " and tools, these foundational models, they are improving very, very rapidly. And if something", "tokens": [51556, 293, 3873, 11, 613, 32195, 5245, 11, 436, 366, 11470, 588, 11, 588, 12910, 13, 400, 498, 746, 51780], "temperature": 0.0, "avg_logprob": -0.11011718917679, "compression_ratio": 1.6, "no_speech_prob": 0.0017537111416459084}, {"id": 548, "seek": 402824, "start": 4028.24, "end": 4036.24, "text": " doesn't work today, it will likely change in the near future. And it is important to pay attention", "tokens": [50364, 1177, 380, 589, 965, 11, 309, 486, 3700, 1319, 294, 264, 2651, 2027, 13, 400, 309, 307, 1021, 281, 1689, 3202, 50764], "temperature": 0.0, "avg_logprob": -0.0624259529691754, "compression_ratio": 1.553763440860215, "no_speech_prob": 0.004328154493123293}, {"id": 549, "seek": 402824, "start": 4036.24, "end": 4044.7999999999997, "text": " and to build processes and products that will evolve, will get better with more powerful tools", "tokens": [50764, 293, 281, 1322, 7555, 293, 3383, 300, 486, 16693, 11, 486, 483, 1101, 365, 544, 4005, 3873, 51192], "temperature": 0.0, "avg_logprob": -0.0624259529691754, "compression_ratio": 1.553763440860215, "no_speech_prob": 0.004328154493123293}, {"id": 550, "seek": 402824, "start": 4044.7999999999997, "end": 4054.9599999999996, "text": " and with more powerful underlying models. And that's it for my presentation. Thank you so much.", "tokens": [51192, 293, 365, 544, 4005, 14217, 5245, 13, 400, 300, 311, 309, 337, 452, 5860, 13, 1044, 291, 370, 709, 13, 51700], "temperature": 0.0, "avg_logprob": -0.0624259529691754, "compression_ratio": 1.553763440860215, "no_speech_prob": 0.004328154493123293}, {"id": 551, "seek": 405496, "start": 4055.92, "end": 4064.7200000000003, "text": " I have my contact information here on this slide. And we have some time. If there are any questions,", "tokens": [50412, 286, 362, 452, 3385, 1589, 510, 322, 341, 4137, 13, 400, 321, 362, 512, 565, 13, 759, 456, 366, 604, 1651, 11, 50852], "temperature": 0.0, "avg_logprob": -0.18201148509979248, "compression_ratio": 1.502824858757062, "no_speech_prob": 0.012770552188158035}, {"id": 552, "seek": 405496, "start": 4064.7200000000003, "end": 4070.16, "text": " happy to answer, happy to discuss, happy to maybe show more, if you're interested in something.", "tokens": [50852, 2055, 281, 1867, 11, 2055, 281, 2248, 11, 2055, 281, 1310, 855, 544, 11, 498, 291, 434, 3102, 294, 746, 13, 51124], "temperature": 0.0, "avg_logprob": -0.18201148509979248, "compression_ratio": 1.502824858757062, "no_speech_prob": 0.012770552188158035}, {"id": 553, "seek": 405496, "start": 4072.7200000000003, "end": 4079.2, "text": " Dina, maybe a question to you. How do we want to manage the Q&A part?", "tokens": [51252, 413, 1426, 11, 1310, 257, 1168, 281, 291, 13, 1012, 360, 321, 528, 281, 3067, 264, 1249, 5, 32, 644, 30, 51576], "temperature": 0.0, "avg_logprob": -0.18201148509979248, "compression_ratio": 1.502824858757062, "no_speech_prob": 0.012770552188158035}, {"id": 554, "seek": 407920, "start": 4079.2, "end": 4088.3199999999997, "text": " Stepan, thank you very much. I think it should be just an open floor,", "tokens": [50364, 5470, 282, 11, 1309, 291, 588, 709, 13, 286, 519, 309, 820, 312, 445, 364, 1269, 4123, 11, 50820], "temperature": 0.0, "avg_logprob": -0.20965514549842248, "compression_ratio": 1.4331210191082802, "no_speech_prob": 0.00830395519733429}, {"id": 555, "seek": 407920, "start": 4088.3199999999997, "end": 4094.0, "text": " whoever wants to raise your hand or turn on your camera or write in the chat,", "tokens": [50820, 11387, 2738, 281, 5300, 428, 1011, 420, 1261, 322, 428, 2799, 420, 2464, 294, 264, 5081, 11, 51104], "temperature": 0.0, "avg_logprob": -0.20965514549842248, "compression_ratio": 1.4331210191082802, "no_speech_prob": 0.00830395519733429}, {"id": 556, "seek": 407920, "start": 4094.72, "end": 4101.5199999999995, "text": " if you don't want to show your face. Dimash has a question. Go ahead, Dimash.", "tokens": [51140, 498, 291, 500, 380, 528, 281, 855, 428, 1851, 13, 20975, 1299, 575, 257, 1168, 13, 1037, 2286, 11, 20975, 1299, 13, 51480], "temperature": 0.0, "avg_logprob": -0.20965514549842248, "compression_ratio": 1.4331210191082802, "no_speech_prob": 0.00830395519733429}, {"id": 557, "seek": 410152, "start": 4101.76, "end": 4108.88, "text": " Dimash, we cannot hear you.", "tokens": [50376, 20975, 1299, 11, 321, 2644, 1568, 291, 13, 50732], "temperature": 0.0, "avg_logprob": -0.3465869903564453, "compression_ratio": 1.1285714285714286, "no_speech_prob": 0.022267431020736694}, {"id": 558, "seek": 410152, "start": 4112.88, "end": 4114.240000000001, "text": " You can also type in chat.", "tokens": [50932, 509, 393, 611, 2010, 294, 5081, 13, 51000], "temperature": 0.0, "avg_logprob": -0.3465869903564453, "compression_ratio": 1.1285714285714286, "no_speech_prob": 0.022267431020736694}, {"id": 559, "seek": 410152, "start": 4115.040000000001, "end": 4116.64, "text": " Yeah, just type in chat.", "tokens": [51040, 865, 11, 445, 2010, 294, 5081, 13, 51120], "temperature": 0.0, "avg_logprob": -0.3465869903564453, "compression_ratio": 1.1285714285714286, "no_speech_prob": 0.022267431020736694}, {"id": 560, "seek": 411664, "start": 4116.64, "end": 4125.360000000001, "text": " Okay, anybody else?", "tokens": [50364, 1033, 11, 4472, 1646, 30, 50800], "temperature": 0.0, "avg_logprob": -0.2529976201611896, "compression_ratio": 1.2164179104477613, "no_speech_prob": 0.01293153315782547}, {"id": 561, "seek": 411664, "start": 4129.6, "end": 4135.68, "text": " I mean, can I ask this brief question, Stepan? How can we make this personalized AI solutions", "tokens": [51012, 286, 914, 11, 393, 286, 1029, 341, 5353, 1168, 11, 5470, 282, 30, 1012, 393, 321, 652, 341, 28415, 7318, 6547, 51316], "temperature": 0.0, "avg_logprob": -0.2529976201611896, "compression_ratio": 1.2164179104477613, "no_speech_prob": 0.01293153315782547}, {"id": 562, "seek": 411664, "start": 4135.68, "end": 4139.84, "text": " without compromising privacy and security, maybe?", "tokens": [51316, 1553, 11482, 3436, 11427, 293, 3825, 11, 1310, 30, 51524], "temperature": 0.0, "avg_logprob": -0.2529976201611896, "compression_ratio": 1.2164179104477613, "no_speech_prob": 0.01293153315782547}, {"id": 563, "seek": 413984, "start": 4140.64, "end": 4150.8, "text": " Mm-hmm. Yeah, great question. So I had this slide where I had a list of different AI models.", "tokens": [50404, 8266, 12, 10250, 13, 865, 11, 869, 1168, 13, 407, 286, 632, 341, 4137, 689, 286, 632, 257, 1329, 295, 819, 7318, 5245, 13, 50912], "temperature": 0.0, "avg_logprob": -0.19543922424316407, "compression_ratio": 1.427027027027027, "no_speech_prob": 0.004322767723351717}, {"id": 564, "seek": 413984, "start": 4150.8, "end": 4158.88, "text": " And the one thing about OpenAI, ChargeGPT, is that that model is private, meaning that", "tokens": [50912, 400, 264, 472, 551, 466, 7238, 48698, 11, 40546, 38, 47, 51, 11, 307, 300, 300, 2316, 307, 4551, 11, 3620, 300, 51316], "temperature": 0.0, "avg_logprob": -0.19543922424316407, "compression_ratio": 1.427027027027027, "no_speech_prob": 0.004322767723351717}, {"id": 565, "seek": 413984, "start": 4160.16, "end": 4165.360000000001, "text": " it belongs to OpenAI. And whatever data you send it, it will end up on their server,", "tokens": [51380, 309, 12953, 281, 7238, 48698, 13, 400, 2035, 1412, 291, 2845, 309, 11, 309, 486, 917, 493, 322, 641, 7154, 11, 51640], "temperature": 0.0, "avg_logprob": -0.19543922424316407, "compression_ratio": 1.427027027027027, "no_speech_prob": 0.004322767723351717}, {"id": 566, "seek": 416536, "start": 4165.36, "end": 4174.48, "text": " so they can potentially have access to it. So when you want to build an AI system", "tokens": [50364, 370, 436, 393, 7263, 362, 2105, 281, 309, 13, 407, 562, 291, 528, 281, 1322, 364, 7318, 1185, 50820], "temperature": 0.0, "avg_logprob": -0.10643885284662247, "compression_ratio": 1.449438202247191, "no_speech_prob": 0.012211423367261887}, {"id": 567, "seek": 416536, "start": 4174.48, "end": 4180.24, "text": " that is 100% private, 100% working on your own computer or in your organization,", "tokens": [50820, 300, 307, 2319, 4, 4551, 11, 2319, 4, 1364, 322, 428, 1065, 3820, 420, 294, 428, 4475, 11, 51108], "temperature": 0.0, "avg_logprob": -0.10643885284662247, "compression_ratio": 1.449438202247191, "no_speech_prob": 0.012211423367261887}, {"id": 568, "seek": 416536, "start": 4180.88, "end": 4189.92, "text": " I will give you very specific recommendation. Actually, I will just open it on my computer, but", "tokens": [51140, 286, 486, 976, 291, 588, 2685, 11879, 13, 5135, 11, 286, 486, 445, 1269, 309, 322, 452, 3820, 11, 457, 51592], "temperature": 0.0, "avg_logprob": -0.10643885284662247, "compression_ratio": 1.449438202247191, "no_speech_prob": 0.012211423367261887}, {"id": 569, "seek": 418992, "start": 4190.88, "end": 4198.4, "text": " I suggest using LM Studio. So you can go to this website, LMStudio.ai. This is a completely free", "tokens": [50412, 286, 3402, 1228, 46529, 13500, 13, 407, 291, 393, 352, 281, 341, 3144, 11, 46529, 42665, 1004, 13, 1301, 13, 639, 307, 257, 2584, 1737, 50788], "temperature": 0.0, "avg_logprob": -0.1277185517388421, "compression_ratio": 1.5621621621621622, "no_speech_prob": 0.007571143563836813}, {"id": 570, "seek": 418992, "start": 4198.4, "end": 4205.28, "text": " application that is available for Mac, Windows, Linux. And you can download this app. And then", "tokens": [50788, 3861, 300, 307, 2435, 337, 5707, 11, 8591, 11, 18734, 13, 400, 291, 393, 5484, 341, 724, 13, 400, 550, 51132], "temperature": 0.0, "avg_logprob": -0.1277185517388421, "compression_ratio": 1.5621621621621622, "no_speech_prob": 0.007571143563836813}, {"id": 571, "seek": 418992, "start": 4205.28, "end": 4213.6, "text": " inside that app, you can download any of hundreds of existing free models. So this is an app that", "tokens": [51132, 1854, 300, 724, 11, 291, 393, 5484, 604, 295, 6779, 295, 6741, 1737, 5245, 13, 407, 341, 307, 364, 724, 300, 51548], "temperature": 0.0, "avg_logprob": -0.1277185517388421, "compression_ratio": 1.5621621621621622, "no_speech_prob": 0.007571143563836813}, {"id": 572, "seek": 421360, "start": 4213.68, "end": 4220.400000000001, "text": " I have installed on my computer. And these are all the models that I have downloaded, but this is", "tokens": [50368, 286, 362, 8899, 322, 452, 3820, 13, 400, 613, 366, 439, 264, 5245, 300, 286, 362, 21748, 11, 457, 341, 307, 50704], "temperature": 0.0, "avg_logprob": -0.07454902346771543, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.10082866251468658}, {"id": 573, "seek": 421360, "start": 4220.400000000001, "end": 4226.64, "text": " just part of them. So when I use any of these models, no data is ever leaving my computer. I can", "tokens": [50704, 445, 644, 295, 552, 13, 407, 562, 286, 764, 604, 295, 613, 5245, 11, 572, 1412, 307, 1562, 5012, 452, 3820, 13, 286, 393, 51016], "temperature": 0.0, "avg_logprob": -0.07454902346771543, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.10082866251468658}, {"id": 574, "seek": 421360, "start": 4226.64, "end": 4232.64, "text": " disconnect myself from the internet, and all of this will be working. And these models, most of", "tokens": [51016, 14299, 2059, 490, 264, 4705, 11, 293, 439, 295, 341, 486, 312, 1364, 13, 400, 613, 5245, 11, 881, 295, 51316], "temperature": 0.0, "avg_logprob": -0.07454902346771543, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.10082866251468658}, {"id": 575, "seek": 421360, "start": 4232.64, "end": 4239.280000000001, "text": " them are not as good as GPT-4, but depending on your task, it can be good enough. And there's", "tokens": [51316, 552, 366, 406, 382, 665, 382, 26039, 51, 12, 19, 11, 457, 5413, 322, 428, 5633, 11, 309, 393, 312, 665, 1547, 13, 400, 456, 311, 51648], "temperature": 0.0, "avg_logprob": -0.07454902346771543, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.10082866251468658}, {"id": 576, "seek": 423928, "start": 4239.28, "end": 4246.48, "text": " also a question I see in the chat about models that work well with Russian language. I can just", "tokens": [50364, 611, 257, 1168, 286, 536, 294, 264, 5081, 466, 5245, 300, 589, 731, 365, 7220, 2856, 13, 286, 393, 445, 50724], "temperature": 0.0, "avg_logprob": -0.11192933400472005, "compression_ratio": 1.5372340425531914, "no_speech_prob": 0.020614957436919212}, {"id": 577, "seek": 423928, "start": 4246.48, "end": 4255.92, "text": " show it here. So you can go to here. And there's a model called Saiga. And this is one of the models", "tokens": [50724, 855, 309, 510, 13, 407, 291, 393, 352, 281, 510, 13, 400, 456, 311, 257, 2316, 1219, 6299, 9900, 13, 400, 341, 307, 472, 295, 264, 5245, 51196], "temperature": 0.0, "avg_logprob": -0.11192933400472005, "compression_ratio": 1.5372340425531914, "no_speech_prob": 0.020614957436919212}, {"id": 578, "seek": 423928, "start": 4255.92, "end": 4262.32, "text": " that works very well with specifically Russian language. But I think GPT-4 still outperforms", "tokens": [51196, 300, 1985, 588, 731, 365, 4682, 7220, 2856, 13, 583, 286, 519, 26039, 51, 12, 19, 920, 484, 26765, 82, 51516], "temperature": 0.0, "avg_logprob": -0.11192933400472005, "compression_ratio": 1.5372340425531914, "no_speech_prob": 0.020614957436919212}, {"id": 579, "seek": 426232, "start": 4263.04, "end": 4271.759999999999, "text": " in, I would say, in every language except for maybe Chinese. So GPT-4 is the best model today", "tokens": [50400, 294, 11, 286, 576, 584, 11, 294, 633, 2856, 3993, 337, 1310, 4649, 13, 407, 26039, 51, 12, 19, 307, 264, 1151, 2316, 965, 50836], "temperature": 0.0, "avg_logprob": -0.13146758079528809, "compression_ratio": 1.364963503649635, "no_speech_prob": 0.02000710926949978}, {"id": 580, "seek": 426232, "start": 4272.4, "end": 4279.84, "text": " that working with any other language except for Chinese, because they have a lot of their own", "tokens": [50868, 300, 1364, 365, 604, 661, 2856, 3993, 337, 4649, 11, 570, 436, 362, 257, 688, 295, 641, 1065, 51240], "temperature": 0.0, "avg_logprob": -0.13146758079528809, "compression_ratio": 1.364963503649635, "no_speech_prob": 0.02000710926949978}, {"id": 581, "seek": 427984, "start": 4279.84, "end": 4286.72, "text": " Russian language models in China. But GPT-4 is great for English and other languages.", "tokens": [50364, 7220, 2856, 5245, 294, 3533, 13, 583, 26039, 51, 12, 19, 307, 869, 337, 3669, 293, 661, 8650, 13, 50708], "temperature": 0.0, "avg_logprob": -0.2301090955734253, "compression_ratio": 1.2714285714285714, "no_speech_prob": 0.020914047956466675}, {"id": 582, "seek": 427984, "start": 4295.04, "end": 4305.2, "text": " Okay. Any more questions? Can I ask the question? Yes. My name is Carla. I'm not technically", "tokens": [51124, 1033, 13, 2639, 544, 1651, 30, 1664, 286, 1029, 264, 1168, 30, 1079, 13, 1222, 1315, 307, 41325, 13, 286, 478, 406, 12120, 51632], "temperature": 0.0, "avg_logprob": -0.2301090955734253, "compression_ratio": 1.2714285714285714, "no_speech_prob": 0.020914047956466675}, {"id": 583, "seek": 430520, "start": 4305.2, "end": 4312.96, "text": " aware. I'm not that in business, actually. But can you distinguish between the", "tokens": [50364, 3650, 13, 286, 478, 406, 300, 294, 1606, 11, 767, 13, 583, 393, 291, 20206, 1296, 264, 50752], "temperature": 0.0, "avg_logprob": -0.19745337102831023, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.04926910623908043}, {"id": 584, "seek": 430520, "start": 4312.96, "end": 4317.76, "text": " chat GPT-generated music and the human-generated music? How you do that?", "tokens": [50752, 5081, 26039, 51, 12, 21848, 770, 1318, 293, 264, 1952, 12, 21848, 770, 1318, 30, 1012, 291, 360, 300, 30, 50992], "temperature": 0.0, "avg_logprob": -0.19745337102831023, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.04926910623908043}, {"id": 585, "seek": 430520, "start": 4319.76, "end": 4324.8, "text": " Yeah. Good question. I think... So first of all, chat GPT-4 does not generate music, but there's", "tokens": [51092, 865, 13, 2205, 1168, 13, 286, 519, 485, 407, 700, 295, 439, 11, 5081, 26039, 51, 12, 19, 775, 406, 8460, 1318, 11, 457, 456, 311, 51344], "temperature": 0.0, "avg_logprob": -0.19745337102831023, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.04926910623908043}, {"id": 586, "seek": 430520, "start": 4325.36, "end": 4332.8, "text": " special tools specifically. It's called sueno.ai. So if anyone wants to generate music, there's also...", "tokens": [51372, 2121, 3873, 4682, 13, 467, 311, 1219, 459, 5808, 13, 1301, 13, 407, 498, 2878, 2738, 281, 8460, 1318, 11, 456, 311, 611, 485, 51744], "temperature": 0.0, "avg_logprob": -0.19745337102831023, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.04926910623908043}, {"id": 587, "seek": 433280, "start": 4333.76, "end": 4344.96, "text": " I will send it in chat. It's called sueno.ai. And the problem of identifying if something was...", "tokens": [50412, 286, 486, 2845, 309, 294, 5081, 13, 467, 311, 1219, 459, 5808, 13, 1301, 13, 400, 264, 1154, 295, 16696, 498, 746, 390, 485, 50972], "temperature": 0.0, "avg_logprob": -0.133442167965871, "compression_ratio": 1.3714285714285714, "no_speech_prob": 0.0037561047356575727}, {"id": 588, "seek": 433280, "start": 4344.96, "end": 4358.0, "text": " if music, image, or text was created by AI or a human is quite hard. It is possible to identify", "tokens": [50972, 498, 1318, 11, 3256, 11, 420, 2487, 390, 2942, 538, 7318, 420, 257, 1952, 307, 1596, 1152, 13, 467, 307, 1944, 281, 5876, 51624], "temperature": 0.0, "avg_logprob": -0.133442167965871, "compression_ratio": 1.3714285714285714, "no_speech_prob": 0.0037561047356575727}, {"id": 589, "seek": 435800, "start": 4358.0, "end": 4366.08, "text": " if it is just, I don't know, robotic sounds music or the text is just very, very, very badly written.", "tokens": [50364, 498, 309, 307, 445, 11, 286, 500, 380, 458, 11, 30468, 3263, 1318, 420, 264, 2487, 307, 445, 588, 11, 588, 11, 588, 13425, 3720, 13, 50768], "temperature": 0.0, "avg_logprob": -0.10843319506258578, "compression_ratio": 1.4603174603174602, "no_speech_prob": 0.020000621676445007}, {"id": 590, "seek": 435800, "start": 4366.08, "end": 4373.2, "text": " But as this model becomes better, it will be, in my opinion, so there's no technical way of", "tokens": [50768, 583, 382, 341, 2316, 3643, 1101, 11, 309, 486, 312, 11, 294, 452, 4800, 11, 370, 456, 311, 572, 6191, 636, 295, 51124], "temperature": 0.0, "avg_logprob": -0.10843319506258578, "compression_ratio": 1.4603174603174602, "no_speech_prob": 0.020000621676445007}, {"id": 591, "seek": 435800, "start": 4374.16, "end": 4380.72, "text": " 100% guarantee that something was created by an AI. So as these models get better,", "tokens": [51172, 2319, 4, 10815, 300, 746, 390, 2942, 538, 364, 7318, 13, 407, 382, 613, 5245, 483, 1101, 11, 51500], "temperature": 0.0, "avg_logprob": -0.10843319506258578, "compression_ratio": 1.4603174603174602, "no_speech_prob": 0.020000621676445007}, {"id": 592, "seek": 438072, "start": 4381.360000000001, "end": 4389.280000000001, "text": " it becomes very almost impossible to distinguish. So this is a hard problem that I don't think anyone", "tokens": [50396, 309, 3643, 588, 1920, 6243, 281, 20206, 13, 407, 341, 307, 257, 1152, 1154, 300, 286, 500, 380, 519, 2878, 50792], "temperature": 0.0, "avg_logprob": -0.1457915104610819, "compression_ratio": 1.4554455445544554, "no_speech_prob": 0.008703267201781273}, {"id": 593, "seek": 438072, "start": 4389.280000000001, "end": 4396.16, "text": " has an answer to, really. And does it mean that the old composers will lose the job eventually", "tokens": [50792, 575, 364, 1867, 281, 11, 534, 13, 400, 775, 309, 914, 300, 264, 1331, 43872, 486, 3624, 264, 1691, 4728, 51136], "temperature": 0.0, "avg_logprob": -0.1457915104610819, "compression_ratio": 1.4554455445544554, "no_speech_prob": 0.008703267201781273}, {"id": 594, "seek": 438072, "start": 4396.16, "end": 4404.08, "text": " with this chat GPT-generation, generating music, or like the still will be some use of the human?", "tokens": [51136, 365, 341, 5081, 26039, 51, 12, 30372, 11, 17746, 1318, 11, 420, 411, 264, 920, 486, 312, 512, 764, 295, 264, 1952, 30, 51532], "temperature": 0.0, "avg_logprob": -0.1457915104610819, "compression_ratio": 1.4554455445544554, "no_speech_prob": 0.008703267201781273}, {"id": 595, "seek": 440408, "start": 4404.8, "end": 4415.84, "text": " I'm sure humans will always do music because AI doesn't... It can do something, it can help humans,", "tokens": [50400, 286, 478, 988, 6255, 486, 1009, 360, 1318, 570, 7318, 1177, 380, 485, 467, 393, 360, 746, 11, 309, 393, 854, 6255, 11, 50952], "temperature": 0.0, "avg_logprob": -0.20363551027634563, "compression_ratio": 1.5502958579881656, "no_speech_prob": 0.01939588226377964}, {"id": 596, "seek": 440408, "start": 4415.84, "end": 4420.88, "text": " but I don't think it can, at least at this point, can produce... It doesn't have", "tokens": [50952, 457, 286, 500, 380, 519, 309, 393, 11, 412, 1935, 412, 341, 935, 11, 393, 5258, 485, 467, 1177, 380, 362, 51204], "temperature": 0.0, "avg_logprob": -0.20363551027634563, "compression_ratio": 1.5502958579881656, "no_speech_prob": 0.01939588226377964}, {"id": 597, "seek": 440408, "start": 4423.36, "end": 4430.64, "text": " subjective emotional experience. So I think that's the important part. That's the", "tokens": [51328, 25972, 6863, 1752, 13, 407, 286, 519, 300, 311, 264, 1021, 644, 13, 663, 311, 264, 51692], "temperature": 0.0, "avg_logprob": -0.20363551027634563, "compression_ratio": 1.5502958579881656, "no_speech_prob": 0.01939588226377964}, {"id": 598, "seek": 443064, "start": 4430.64, "end": 4437.200000000001, "text": " crucial part for generating art. But what is happening today, what I see a lot is people,", "tokens": [50364, 11462, 644, 337, 17746, 1523, 13, 583, 437, 307, 2737, 965, 11, 437, 286, 536, 257, 688, 307, 561, 11, 50692], "temperature": 0.0, "avg_logprob": -0.09935905062963092, "compression_ratio": 1.510989010989011, "no_speech_prob": 0.008823821321129799}, {"id": 599, "seek": 443064, "start": 4437.200000000001, "end": 4446.72, "text": " artists, being writers and musicians and videographers and painters, they utilize AI tools", "tokens": [50692, 6910, 11, 885, 13491, 293, 16916, 293, 838, 47222, 293, 48643, 11, 436, 16117, 7318, 3873, 51168], "temperature": 0.0, "avg_logprob": -0.09935905062963092, "compression_ratio": 1.510989010989011, "no_speech_prob": 0.008823821321129799}, {"id": 600, "seek": 443064, "start": 4446.72, "end": 4455.04, "text": " in their work more and more. And that's great because when electric synthesizers were created,", "tokens": [51168, 294, 641, 589, 544, 293, 544, 13, 400, 300, 311, 869, 570, 562, 5210, 26617, 22525, 645, 2942, 11, 51584], "temperature": 0.0, "avg_logprob": -0.09935905062963092, "compression_ratio": 1.510989010989011, "no_speech_prob": 0.008823821321129799}, {"id": 601, "seek": 445504, "start": 4455.04, "end": 4461.5199999999995, "text": " we got, or electric guitars were created, we got a whole new genre of music. So it's the same thing.", "tokens": [50364, 321, 658, 11, 420, 5210, 36809, 645, 2942, 11, 321, 658, 257, 1379, 777, 11022, 295, 1318, 13, 407, 309, 311, 264, 912, 551, 13, 50688], "temperature": 0.0, "avg_logprob": -0.17818492498153296, "compression_ratio": 1.5851063829787233, "no_speech_prob": 0.0051955278031528}, {"id": 602, "seek": 445504, "start": 4461.5199999999995, "end": 4469.6, "text": " We now get more tools to express ourselves. All right. Thank you. Thank you. Thank you. Thank you.", "tokens": [50688, 492, 586, 483, 544, 3873, 281, 5109, 4175, 13, 1057, 558, 13, 1044, 291, 13, 1044, 291, 13, 1044, 291, 13, 1044, 291, 13, 51092], "temperature": 0.0, "avg_logprob": -0.17818492498153296, "compression_ratio": 1.5851063829787233, "no_speech_prob": 0.0051955278031528}, {"id": 603, "seek": 445504, "start": 4469.6, "end": 4477.28, "text": " Great question. There was a follow-up question, like what professions will be last to move with AI", "tokens": [51092, 3769, 1168, 13, 821, 390, 257, 1524, 12, 1010, 1168, 11, 411, 437, 38129, 486, 312, 1036, 281, 1286, 365, 7318, 51476], "temperature": 0.0, "avg_logprob": -0.17818492498153296, "compression_ratio": 1.5851063829787233, "no_speech_prob": 0.0051955278031528}, {"id": 604, "seek": 447728, "start": 4477.84, "end": 4487.92, "text": " in the chat. There was this question. Yeah. Good question. Actually, paradoxically,", "tokens": [50392, 294, 264, 5081, 13, 821, 390, 341, 1168, 13, 865, 13, 2205, 1168, 13, 5135, 11, 26221, 984, 11, 50896], "temperature": 0.0, "avg_logprob": -0.18488685096182475, "compression_ratio": 1.3833333333333333, "no_speech_prob": 0.026474855840206146}, {"id": 605, "seek": 447728, "start": 4489.36, "end": 4497.759999999999, "text": " things that are not being automated are things that are relatively low-paying jobs", "tokens": [50968, 721, 300, 366, 406, 885, 18473, 366, 721, 300, 366, 7226, 2295, 12, 22038, 278, 4782, 51388], "temperature": 0.0, "avg_logprob": -0.18488685096182475, "compression_ratio": 1.3833333333333333, "no_speech_prob": 0.026474855840206146}, {"id": 606, "seek": 449776, "start": 4498.72, "end": 4509.2, "text": " and physical jobs. So I don't know, a barber or a hairdresser or a plumber or", "tokens": [50412, 293, 4001, 4782, 13, 407, 286, 500, 380, 458, 11, 257, 49906, 420, 257, 41954, 37278, 420, 257, 499, 4182, 420, 50936], "temperature": 0.0, "avg_logprob": -0.27870019766000603, "compression_ratio": 1.3575757575757577, "no_speech_prob": 0.19375407695770264}, {"id": 607, "seek": 449776, "start": 4512.4800000000005, "end": 4516.24, "text": " someone who works in construction. It started at seven o'clock in the morning, I didn't realize.", "tokens": [51100, 1580, 567, 1985, 294, 6435, 13, 467, 1409, 412, 3407, 277, 6, 9023, 294, 264, 2446, 11, 286, 994, 380, 4325, 13, 51288], "temperature": 0.0, "avg_logprob": -0.27870019766000603, "compression_ratio": 1.3575757575757577, "no_speech_prob": 0.19375407695770264}, {"id": 608, "seek": 449776, "start": 4516.24, "end": 4520.56, "text": " Let's try this one. This is an AI workshop. Yeah.", "tokens": [51288, 961, 311, 853, 341, 472, 13, 639, 307, 364, 7318, 13541, 13, 865, 13, 51504], "temperature": 0.0, "avg_logprob": -0.27870019766000603, "compression_ratio": 1.3575757575757577, "no_speech_prob": 0.19375407695770264}, {"id": 609, "seek": 452056, "start": 4520.56, "end": 4527.280000000001, "text": " Yeah. Sorry, Jim. I put you in mute for now.", "tokens": [50364, 865, 13, 4919, 11, 6637, 13, 286, 829, 291, 294, 24523, 337, 586, 13, 50700], "temperature": 0.0, "avg_logprob": -0.21501426696777343, "compression_ratio": 1.4642857142857142, "no_speech_prob": 0.0065779597498476505}, {"id": 610, "seek": 452056, "start": 4530.080000000001, "end": 4539.04, "text": " And yeah. So the jobs that are least prone to automation are those that are", "tokens": [50840, 400, 1338, 13, 407, 264, 4782, 300, 366, 1935, 25806, 281, 17769, 366, 729, 300, 366, 51288], "temperature": 0.0, "avg_logprob": -0.21501426696777343, "compression_ratio": 1.4642857142857142, "no_speech_prob": 0.0065779597498476505}, {"id": 611, "seek": 452056, "start": 4540.240000000001, "end": 4546.240000000001, "text": " low-paying because there's less economic gain from that automation and also that are", "tokens": [51348, 2295, 12, 22038, 278, 570, 456, 311, 1570, 4836, 6052, 490, 300, 17769, 293, 611, 300, 366, 51648], "temperature": 0.0, "avg_logprob": -0.21501426696777343, "compression_ratio": 1.4642857142857142, "no_speech_prob": 0.0065779597498476505}, {"id": 612, "seek": 454624, "start": 4546.96, "end": 4553.04, "text": " manual and requires a lot of manual work because robotics is much more expensive than", "tokens": [50400, 9688, 293, 7029, 257, 688, 295, 9688, 589, 570, 34145, 307, 709, 544, 5124, 813, 50704], "temperature": 0.0, "avg_logprob": -0.08964061737060547, "compression_ratio": 1.6497695852534562, "no_speech_prob": 0.002319701947271824}, {"id": 613, "seek": 454624, "start": 4553.599999999999, "end": 4559.92, "text": " software. Building a robot costs much more than building a software application. So", "tokens": [50732, 4722, 13, 18974, 257, 7881, 5497, 709, 544, 813, 2390, 257, 4722, 3861, 13, 407, 51048], "temperature": 0.0, "avg_logprob": -0.08964061737060547, "compression_ratio": 1.6497695852534562, "no_speech_prob": 0.002319701947271824}, {"id": 614, "seek": 454624, "start": 4559.92, "end": 4566.48, "text": " office jobs like marketing or sales or finance or legal innovation in those spaces are happening", "tokens": [51048, 3398, 4782, 411, 6370, 420, 5763, 420, 10719, 420, 5089, 8504, 294, 729, 7673, 366, 2737, 51376], "temperature": 0.0, "avg_logprob": -0.08964061737060547, "compression_ratio": 1.6497695852534562, "no_speech_prob": 0.002319701947271824}, {"id": 615, "seek": 454624, "start": 4566.48, "end": 4574.96, "text": " much, much faster than, for example, robotic automation of cleaners or something like this.", "tokens": [51376, 709, 11, 709, 4663, 813, 11, 337, 1365, 11, 30468, 17769, 295, 2541, 433, 420, 746, 411, 341, 13, 51800], "temperature": 0.0, "avg_logprob": -0.08964061737060547, "compression_ratio": 1.6497695852534562, "no_speech_prob": 0.002319701947271824}, {"id": 616, "seek": 457624, "start": 4577.04, "end": 4584.8, "text": " I see, I'll read a few questions from the chat. So there's one question about", "tokens": [50404, 286, 536, 11, 286, 603, 1401, 257, 1326, 1651, 490, 264, 5081, 13, 407, 456, 311, 472, 1168, 466, 50792], "temperature": 0.0, "avg_logprob": -0.16865228677724864, "compression_ratio": 1.4916201117318435, "no_speech_prob": 0.0008163106394931674}, {"id": 617, "seek": 457624, "start": 4586.0, "end": 4593.5199999999995, "text": " non-English-speaking languages. So I don't know about Mongolian. I don't know Mongolian,", "tokens": [50852, 2107, 12, 31254, 1933, 12, 14579, 8650, 13, 407, 286, 500, 380, 458, 466, 43573, 952, 13, 286, 500, 380, 458, 43573, 952, 11, 51228], "temperature": 0.0, "avg_logprob": -0.16865228677724864, "compression_ratio": 1.4916201117318435, "no_speech_prob": 0.0008163106394931674}, {"id": 618, "seek": 457624, "start": 4593.5199999999995, "end": 4600.08, "text": " so I cannot test it. But I would suggest to start with charge EPT. And if you don't have an account,", "tokens": [51228, 370, 286, 2644, 1500, 309, 13, 583, 286, 576, 3402, 281, 722, 365, 4602, 25330, 51, 13, 400, 498, 291, 500, 380, 362, 364, 2696, 11, 51556], "temperature": 0.0, "avg_logprob": -0.16865228677724864, "compression_ratio": 1.4916201117318435, "no_speech_prob": 0.0008163106394931674}, {"id": 619, "seek": 460008, "start": 4600.08, "end": 4606.4, "text": " go to Bing chat and it will work exactly the same way as charge EPT.", "tokens": [50364, 352, 281, 30755, 5081, 293, 309, 486, 589, 2293, 264, 912, 636, 382, 4602, 25330, 51, 13, 50680], "temperature": 0.0, "avg_logprob": -0.10081039369106293, "compression_ratio": 1.4797687861271676, "no_speech_prob": 0.04081519693136215}, {"id": 620, "seek": 460008, "start": 4607.76, "end": 4616.32, "text": " What I found is that charge EPT is really good on... So the quality of the text it produces", "tokens": [50748, 708, 286, 1352, 307, 300, 4602, 25330, 51, 307, 534, 665, 322, 485, 407, 264, 3125, 295, 264, 2487, 309, 14725, 51176], "temperature": 0.0, "avg_logprob": -0.10081039369106293, "compression_ratio": 1.4797687861271676, "no_speech_prob": 0.04081519693136215}, {"id": 621, "seek": 460008, "start": 4616.88, "end": 4624.4, "text": " is proportional to how much text on that language did it see during the training period when it", "tokens": [51204, 307, 24969, 281, 577, 709, 2487, 322, 300, 2856, 630, 309, 536, 1830, 264, 3097, 2896, 562, 309, 51580], "temperature": 0.0, "avg_logprob": -0.10081039369106293, "compression_ratio": 1.4797687861271676, "no_speech_prob": 0.04081519693136215}, {"id": 622, "seek": 462440, "start": 4624.4, "end": 4630.96, "text": " was trained. And that is more or less roughly proportional to how much text in that language", "tokens": [50364, 390, 8895, 13, 400, 300, 307, 544, 420, 1570, 9810, 24969, 281, 577, 709, 2487, 294, 300, 2856, 50692], "temperature": 0.0, "avg_logprob": -0.11135460609613462, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.008181067183613777}, {"id": 623, "seek": 462440, "start": 4630.96, "end": 4638.0, "text": " exists online. So obviously languages like English, Spanish, Chinese, French, German,", "tokens": [50692, 8198, 2950, 13, 407, 2745, 8650, 411, 3669, 11, 8058, 11, 4649, 11, 5522, 11, 6521, 11, 51044], "temperature": 0.0, "avg_logprob": -0.11135460609613462, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.008181067183613777}, {"id": 624, "seek": 462440, "start": 4640.08, "end": 4646.48, "text": " they have... There's a lot of text in those languages online and therefore GPT is very good", "tokens": [51148, 436, 362, 485, 821, 311, 257, 688, 295, 2487, 294, 729, 8650, 2950, 293, 4412, 26039, 51, 307, 588, 665, 51468], "temperature": 0.0, "avg_logprob": -0.11135460609613462, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.008181067183613777}, {"id": 625, "seek": 462440, "start": 4647.44, "end": 4654.0, "text": " at those languages. Languages like Mongolian are not very... There's not too much of that", "tokens": [51516, 412, 729, 8650, 13, 13313, 84, 1660, 411, 43573, 952, 366, 406, 588, 485, 821, 311, 406, 886, 709, 295, 300, 51844], "temperature": 0.0, "avg_logprob": -0.11135460609613462, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.008181067183613777}, {"id": 626, "seek": 465400, "start": 4654.0, "end": 4660.24, "text": " data. There's not a lot of that data in the training set. But it can still be good enough.", "tokens": [50364, 1412, 13, 821, 311, 406, 257, 688, 295, 300, 1412, 294, 264, 3097, 992, 13, 583, 309, 393, 920, 312, 665, 1547, 13, 50676], "temperature": 0.0, "avg_logprob": -0.12300908454110689, "compression_ratio": 1.610878661087866, "no_speech_prob": 0.002431799191981554}, {"id": 627, "seek": 465400, "start": 4660.24, "end": 4668.16, "text": " So I think GPT-4 would be the best benchmark. It's the best way to test how good models are today.", "tokens": [50676, 407, 286, 519, 26039, 51, 12, 19, 576, 312, 264, 1151, 18927, 13, 467, 311, 264, 1151, 636, 281, 1500, 577, 665, 5245, 366, 965, 13, 51072], "temperature": 0.0, "avg_logprob": -0.12300908454110689, "compression_ratio": 1.610878661087866, "no_speech_prob": 0.002431799191981554}, {"id": 628, "seek": 465400, "start": 4670.72, "end": 4675.52, "text": " But over time, I see there's a lot of companies, a lot of projects, a lot of open source projects that", "tokens": [51200, 583, 670, 565, 11, 286, 536, 456, 311, 257, 688, 295, 3431, 11, 257, 688, 295, 4455, 11, 257, 688, 295, 1269, 4009, 4455, 300, 51440], "temperature": 0.0, "avg_logprob": -0.12300908454110689, "compression_ratio": 1.610878661087866, "no_speech_prob": 0.002431799191981554}, {"id": 629, "seek": 465400, "start": 4675.52, "end": 4682.72, "text": " are building localized versions of LLMs. So I showed Saiga, which is a Russian version. It's", "tokens": [51440, 366, 2390, 44574, 9606, 295, 441, 43, 26386, 13, 407, 286, 4712, 6299, 9900, 11, 597, 307, 257, 7220, 3037, 13, 467, 311, 51800], "temperature": 0.0, "avg_logprob": -0.12300908454110689, "compression_ratio": 1.610878661087866, "no_speech_prob": 0.002431799191981554}, {"id": 630, "seek": 468272, "start": 4682.8, "end": 4688.4800000000005, "text": " actually not the only one. There's a few more models that are specifically trained in Russian.", "tokens": [50368, 767, 406, 264, 787, 472, 13, 821, 311, 257, 1326, 544, 5245, 300, 366, 4682, 8895, 294, 7220, 13, 50652], "temperature": 0.0, "avg_logprob": -0.09543362329172533, "compression_ratio": 1.5859030837004404, "no_speech_prob": 0.0009097581496462226}, {"id": 631, "seek": 468272, "start": 4689.360000000001, "end": 4696.64, "text": " There's a lot of... I know a few companies in France doing the same. So this problem is slowly", "tokens": [50696, 821, 311, 257, 688, 295, 485, 286, 458, 257, 1326, 3431, 294, 6190, 884, 264, 912, 13, 407, 341, 1154, 307, 5692, 51060], "temperature": 0.0, "avg_logprob": -0.09543362329172533, "compression_ratio": 1.5859030837004404, "no_speech_prob": 0.0009097581496462226}, {"id": 632, "seek": 468272, "start": 4696.64, "end": 4704.96, "text": " being solved. But right now English is... It's just because most of the internet is in English,", "tokens": [51060, 885, 13041, 13, 583, 558, 586, 3669, 307, 485, 467, 311, 445, 570, 881, 295, 264, 4705, 307, 294, 3669, 11, 51476], "temperature": 0.0, "avg_logprob": -0.09543362329172533, "compression_ratio": 1.5859030837004404, "no_speech_prob": 0.0009097581496462226}, {"id": 633, "seek": 468272, "start": 4704.96, "end": 4712.4800000000005, "text": " that's why AI models speak English much, much better than other languages.", "tokens": [51476, 300, 311, 983, 7318, 5245, 1710, 3669, 709, 11, 709, 1101, 813, 661, 8650, 13, 51852], "temperature": 0.0, "avg_logprob": -0.09543362329172533, "compression_ratio": 1.5859030837004404, "no_speech_prob": 0.0009097581496462226}, {"id": 634, "seek": 471272, "start": 4713.68, "end": 4724.88, "text": " So the question is, where can we find various AI websites? I'm not sure. Are you talking about", "tokens": [50412, 407, 264, 1168, 307, 11, 689, 393, 321, 915, 3683, 7318, 12891, 30, 286, 478, 406, 988, 13, 2014, 291, 1417, 466, 50972], "temperature": 0.0, "avg_logprob": -0.14673591743816028, "compression_ratio": 1.2295081967213115, "no_speech_prob": 0.0014295396395027637}, {"id": 635, "seek": 471272, "start": 4724.88, "end": 4732.16, "text": " AI models? If so, then this is the link I sent to chat.", "tokens": [50972, 7318, 5245, 30, 759, 370, 11, 550, 341, 307, 264, 2113, 286, 2279, 281, 5081, 13, 51336], "temperature": 0.0, "avg_logprob": -0.14673591743816028, "compression_ratio": 1.2295081967213115, "no_speech_prob": 0.0014295396395027637}, {"id": 636, "seek": 473216, "start": 4732.16, "end": 4744.48, "text": " There was a question about why developers are limiting access of these models to internet.", "tokens": [50364, 821, 390, 257, 1168, 466, 983, 8849, 366, 22083, 2105, 295, 613, 5245, 281, 4705, 13, 50980], "temperature": 0.0, "avg_logprob": -0.2368205907393475, "compression_ratio": 1.3525179856115108, "no_speech_prob": 0.02152480185031891}, {"id": 637, "seek": 473216, "start": 4747.44, "end": 4757.5199999999995, "text": " Oh, yeah. Yeah, I see now. Yes, great question. So one of the main reasons is it's a really legal", "tokens": [51128, 876, 11, 1338, 13, 865, 11, 286, 536, 586, 13, 1079, 11, 869, 1168, 13, 407, 472, 295, 264, 2135, 4112, 307, 309, 311, 257, 534, 5089, 51632], "temperature": 0.0, "avg_logprob": -0.2368205907393475, "compression_ratio": 1.3525179856115108, "no_speech_prob": 0.02152480185031891}, {"id": 638, "seek": 475752, "start": 4757.52, "end": 4766.400000000001, "text": " question. So people, when ChargeGPT first released internet access, it was used, it was very widely", "tokens": [50364, 1168, 13, 407, 561, 11, 562, 40546, 38, 47, 51, 700, 4736, 4705, 2105, 11, 309, 390, 1143, 11, 309, 390, 588, 13371, 50808], "temperature": 0.0, "avg_logprob": -0.13455033809580702, "compression_ratio": 1.6652360515021458, "no_speech_prob": 0.020912976935505867}, {"id": 639, "seek": 475752, "start": 4766.400000000001, "end": 4773.76, "text": " used for scraping data from paywall content. So for example, Wall Street Journal is a paywall", "tokens": [50808, 1143, 337, 43738, 1412, 490, 1689, 16256, 2701, 13, 407, 337, 1365, 11, 9551, 7638, 16936, 307, 257, 1689, 16256, 51176], "temperature": 0.0, "avg_logprob": -0.13455033809580702, "compression_ratio": 1.6652360515021458, "no_speech_prob": 0.020912976935505867}, {"id": 640, "seek": 475752, "start": 4773.76, "end": 4778.72, "text": " website. You cannot access it. I think you can see like three articles a month, and then you", "tokens": [51176, 3144, 13, 509, 2644, 2105, 309, 13, 286, 519, 291, 393, 536, 411, 1045, 11290, 257, 1618, 11, 293, 550, 291, 51424], "temperature": 0.0, "avg_logprob": -0.13455033809580702, "compression_ratio": 1.6652360515021458, "no_speech_prob": 0.020912976935505867}, {"id": 641, "seek": 475752, "start": 4778.72, "end": 4785.52, "text": " have to pay subscription. But people were using ChargeGPT to scrape articles from Wall Street Journal", "tokens": [51424, 362, 281, 1689, 17231, 13, 583, 561, 645, 1228, 40546, 38, 47, 51, 281, 32827, 11290, 490, 9551, 7638, 16936, 51764], "temperature": 0.0, "avg_logprob": -0.13455033809580702, "compression_ratio": 1.6652360515021458, "no_speech_prob": 0.020912976935505867}, {"id": 642, "seek": 478552, "start": 4785.52, "end": 4794.72, "text": " and other media. And that was just a copyright issue. So it's not really a technical question.", "tokens": [50364, 293, 661, 3021, 13, 400, 300, 390, 445, 257, 17996, 2734, 13, 407, 309, 311, 406, 534, 257, 6191, 1168, 13, 50824], "temperature": 0.0, "avg_logprob": -0.10918456591092623, "compression_ratio": 1.550561797752809, "no_speech_prob": 0.001453625038266182}, {"id": 643, "seek": 478552, "start": 4794.72, "end": 4802.080000000001, "text": " It is a legal question. And legal questions tend to take longer to resolve than engineering", "tokens": [50824, 467, 307, 257, 5089, 1168, 13, 400, 5089, 1651, 3928, 281, 747, 2854, 281, 14151, 813, 7043, 51192], "temperature": 0.0, "avg_logprob": -0.10918456591092623, "compression_ratio": 1.550561797752809, "no_speech_prob": 0.001453625038266182}, {"id": 644, "seek": 478552, "start": 4802.080000000001, "end": 4811.040000000001, "text": " questions, just because of how legal system works. It's slow. But there are alternatives.", "tokens": [51192, 1651, 11, 445, 570, 295, 577, 5089, 1185, 1985, 13, 467, 311, 2964, 13, 583, 456, 366, 20478, 13, 51640], "temperature": 0.0, "avg_logprob": -0.10918456591092623, "compression_ratio": 1.550561797752809, "no_speech_prob": 0.001453625038266182}, {"id": 645, "seek": 481104, "start": 4811.04, "end": 4820.16, "text": " So today, ChargeGPT has access to the internet. It won't give you some paywall content, but it can,", "tokens": [50364, 407, 965, 11, 40546, 38, 47, 51, 575, 2105, 281, 264, 4705, 13, 467, 1582, 380, 976, 291, 512, 1689, 16256, 2701, 11, 457, 309, 393, 11, 50820], "temperature": 0.0, "avg_logprob": -0.1600727309351382, "compression_ratio": 1.2255639097744362, "no_speech_prob": 0.0005700135370716453}, {"id": 646, "seek": 481104, "start": 4820.16, "end": 4826.08, "text": " for example, read Reddit or some public data that is available.", "tokens": [50820, 337, 1365, 11, 1401, 32210, 420, 512, 1908, 1412, 300, 307, 2435, 13, 51116], "temperature": 0.0, "avg_logprob": -0.1600727309351382, "compression_ratio": 1.2255639097744362, "no_speech_prob": 0.0005700135370716453}, {"id": 647, "seek": 482608, "start": 4826.4, "end": 4835.36, "text": " Okay, any more questions?", "tokens": [50380, 1033, 11, 604, 544, 1651, 30, 50828], "temperature": 0.0, "avg_logprob": -0.2579106012980143, "compression_ratio": 1.2857142857142858, "no_speech_prob": 0.017401736229658127}, {"id": 648, "seek": 482608, "start": 4839.12, "end": 4845.2, "text": " So I want to reiterate that. I will, sorry.", "tokens": [51016, 407, 286, 528, 281, 33528, 300, 13, 286, 486, 11, 2597, 13, 51320], "temperature": 0.0, "avg_logprob": -0.2579106012980143, "compression_ratio": 1.2857142857142858, "no_speech_prob": 0.017401736229658127}, {"id": 649, "seek": 482608, "start": 4847.04, "end": 4854.16, "text": " I have a last question, personal one. If the way to train my personal GPT,", "tokens": [51412, 286, 362, 257, 1036, 1168, 11, 2973, 472, 13, 759, 264, 636, 281, 3847, 452, 2973, 26039, 51, 11, 51768], "temperature": 0.0, "avg_logprob": -0.2579106012980143, "compression_ratio": 1.2857142857142858, "no_speech_prob": 0.017401736229658127}, {"id": 650, "seek": 485416, "start": 4854.24, "end": 4861.44, "text": " if I could upload, for example, my Facebook archive and emails, how it could help me", "tokens": [50368, 498, 286, 727, 6580, 11, 337, 1365, 11, 452, 4384, 23507, 293, 12524, 11, 577, 309, 727, 854, 385, 50728], "temperature": 0.0, "avg_logprob": -0.18362420104270757, "compression_ratio": 1.4647887323943662, "no_speech_prob": 0.0025475439615547657}, {"id": 651, "seek": 485416, "start": 4862.16, "end": 4865.92, "text": " in general, I mean, the private assistant?", "tokens": [50764, 294, 2674, 11, 286, 914, 11, 264, 4551, 10994, 30, 50952], "temperature": 0.0, "avg_logprob": -0.18362420104270757, "compression_ratio": 1.4647887323943662, "no_speech_prob": 0.0025475439615547657}, {"id": 652, "seek": 485416, "start": 4868.0, "end": 4874.639999999999, "text": " Good question. I think, I don't know. It's really, you really should test it, because it depends", "tokens": [51056, 2205, 1168, 13, 286, 519, 11, 286, 500, 380, 458, 13, 467, 311, 534, 11, 291, 534, 820, 1500, 309, 11, 570, 309, 5946, 51388], "temperature": 0.0, "avg_logprob": -0.18362420104270757, "compression_ratio": 1.4647887323943662, "no_speech_prob": 0.0025475439615547657}, {"id": 653, "seek": 485416, "start": 4874.639999999999, "end": 4880.48, "text": " on what's in there and what data. And it's also like when you're uploading data to GPT,", "tokens": [51388, 322, 437, 311, 294, 456, 293, 437, 1412, 13, 400, 309, 311, 611, 411, 562, 291, 434, 27301, 1412, 281, 26039, 51, 11, 51680], "temperature": 0.0, "avg_logprob": -0.18362420104270757, "compression_ratio": 1.4647887323943662, "no_speech_prob": 0.0025475439615547657}, {"id": 654, "seek": 488048, "start": 4881.44, "end": 4886.719999999999, "text": " you need to keep in mind that this data is being stored on their servers. So", "tokens": [50412, 291, 643, 281, 1066, 294, 1575, 300, 341, 1412, 307, 885, 12187, 322, 641, 15909, 13, 407, 50676], "temperature": 0.0, "avg_logprob": -0.1670598116787997, "compression_ratio": 1.6066350710900474, "no_speech_prob": 0.0013876947341486812}, {"id": 655, "seek": 488048, "start": 4888.16, "end": 4894.08, "text": " maybe not, maybe not upload something very, very private information in there,", "tokens": [50748, 1310, 406, 11, 1310, 406, 6580, 746, 588, 11, 588, 4551, 1589, 294, 456, 11, 51044], "temperature": 0.0, "avg_logprob": -0.1670598116787997, "compression_ratio": 1.6066350710900474, "no_speech_prob": 0.0013876947341486812}, {"id": 656, "seek": 488048, "start": 4894.959999999999, "end": 4898.719999999999, "text": " like Gmail, it can have, I don't know, financial information, something like this.", "tokens": [51088, 411, 36732, 11, 309, 393, 362, 11, 286, 500, 380, 458, 11, 4669, 1589, 11, 746, 411, 341, 13, 51276], "temperature": 0.0, "avg_logprob": -0.1670598116787997, "compression_ratio": 1.6066350710900474, "no_speech_prob": 0.0013876947341486812}, {"id": 657, "seek": 488048, "start": 4899.28, "end": 4909.599999999999, "text": " But the use cases for personal assistance is that you can use previous history of your communication", "tokens": [51304, 583, 264, 764, 3331, 337, 2973, 9683, 307, 300, 291, 393, 764, 3894, 2503, 295, 428, 6101, 51820], "temperature": 0.0, "avg_logprob": -0.1670598116787997, "compression_ratio": 1.6066350710900474, "no_speech_prob": 0.0013876947341486812}, {"id": 658, "seek": 491048, "start": 4910.5599999999995, "end": 4917.12, "text": " to generate answers to maybe incoming communication messages. So if you have history of all your", "tokens": [50368, 281, 8460, 6338, 281, 1310, 22341, 6101, 7897, 13, 407, 498, 291, 362, 2503, 295, 439, 428, 50696], "temperature": 0.0, "avg_logprob": -0.10939802294192107, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.0010479588527232409}, {"id": 659, "seek": 491048, "start": 4917.12, "end": 4924.24, "text": " emails that you sent and you receive a similar email with a similar question, GPT will be very good", "tokens": [50696, 12524, 300, 291, 2279, 293, 291, 4774, 257, 2531, 3796, 365, 257, 2531, 1168, 11, 26039, 51, 486, 312, 588, 665, 51052], "temperature": 0.0, "avg_logprob": -0.10939802294192107, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.0010479588527232409}, {"id": 660, "seek": 491048, "start": 4924.24, "end": 4931.759999999999, "text": " at producing a new response or writing a new draft, email draft in a style and with the content", "tokens": [51052, 412, 10501, 257, 777, 4134, 420, 3579, 257, 777, 11206, 11, 3796, 11206, 294, 257, 3758, 293, 365, 264, 2701, 51428], "temperature": 0.0, "avg_logprob": -0.10939802294192107, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.0010479588527232409}, {"id": 661, "seek": 491048, "start": 4931.759999999999, "end": 4937.919999999999, "text": " that's very similar to what you sent in the past. GPT is one way to do it, maybe more technically", "tokens": [51428, 300, 311, 588, 2531, 281, 437, 291, 2279, 294, 264, 1791, 13, 26039, 51, 307, 472, 636, 281, 360, 309, 11, 1310, 544, 12120, 51736], "temperature": 0.0, "avg_logprob": -0.10939802294192107, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.0010479588527232409}, {"id": 662, "seek": 493792, "start": 4937.92, "end": 4944.32, "text": " advanced way to do this would be through fine tuning, but that requires a lot of technical", "tokens": [50364, 7339, 636, 281, 360, 341, 576, 312, 807, 2489, 15164, 11, 457, 300, 7029, 257, 688, 295, 6191, 50684], "temperature": 0.0, "avg_logprob": -0.12564714884353897, "compression_ratio": 1.5317919075144508, "no_speech_prob": 0.003164187539368868}, {"id": 663, "seek": 493792, "start": 4944.32, "end": 4955.52, "text": " expertise. So yeah, so this assistant can be a way of automating your own communication", "tokens": [50684, 11769, 13, 407, 1338, 11, 370, 341, 10994, 393, 312, 257, 636, 295, 3553, 990, 428, 1065, 6101, 51244], "temperature": 0.0, "avg_logprob": -0.12564714884353897, "compression_ratio": 1.5317919075144508, "no_speech_prob": 0.003164187539368868}, {"id": 664, "seek": 493792, "start": 4955.52, "end": 4964.16, "text": " and helping you with producing email drafts or responses or maybe messenger responses,", "tokens": [51244, 293, 4315, 291, 365, 10501, 3796, 11206, 82, 420, 13019, 420, 1310, 26599, 13019, 11, 51676], "temperature": 0.0, "avg_logprob": -0.12564714884353897, "compression_ratio": 1.5317919075144508, "no_speech_prob": 0.003164187539368868}, {"id": 665, "seek": 496416, "start": 4965.12, "end": 4972.48, "text": " something like this. And it should also know my personality well if I upload the social media.", "tokens": [50412, 746, 411, 341, 13, 400, 309, 820, 611, 458, 452, 9033, 731, 498, 286, 6580, 264, 2093, 3021, 13, 50780], "temperature": 0.0, "avg_logprob": -0.1912865996360779, "compression_ratio": 1.626865671641791, "no_speech_prob": 0.002322354121133685}, {"id": 666, "seek": 496416, "start": 4973.2, "end": 4979.84, "text": " This is what you, right? Yeah, this is what you have to explain and define in the instructions.", "tokens": [50816, 639, 307, 437, 291, 11, 558, 30, 865, 11, 341, 307, 437, 291, 362, 281, 2903, 293, 6964, 294, 264, 9415, 13, 51148], "temperature": 0.0, "avg_logprob": -0.1912865996360779, "compression_ratio": 1.626865671641791, "no_speech_prob": 0.002322354121133685}, {"id": 667, "seek": 496416, "start": 4979.84, "end": 4983.2, "text": " So in GPT, when you create GPT, you have this instruction", "tokens": [51148, 407, 294, 26039, 51, 11, 562, 291, 1884, 26039, 51, 11, 291, 362, 341, 10951, 51316], "temperature": 0.0, "avg_logprob": -0.1912865996360779, "compression_ratio": 1.626865671641791, "no_speech_prob": 0.002322354121133685}, {"id": 668, "seek": 496416, "start": 4985.36, "end": 4990.72, "text": " box for instructions and you cannot, it cannot learn your personality based on", "tokens": [51424, 2424, 337, 9415, 293, 291, 2644, 11, 309, 2644, 1466, 428, 9033, 2361, 322, 51692], "temperature": 0.0, "avg_logprob": -0.1912865996360779, "compression_ratio": 1.626865671641791, "no_speech_prob": 0.002322354121133685}, {"id": 669, "seek": 499072, "start": 4990.72, "end": 4997.84, "text": " uploaded information, you need to explicitly type it and say like you need to answer in a", "tokens": [50364, 17135, 1589, 11, 291, 643, 281, 20803, 2010, 309, 293, 584, 411, 291, 643, 281, 1867, 294, 257, 50720], "temperature": 0.0, "avg_logprob": -0.1306910514831543, "compression_ratio": 1.5917159763313609, "no_speech_prob": 0.005057178437709808}, {"id": 670, "seek": 499072, "start": 4997.84, "end": 5004.56, "text": " friendly tone, use maybe these words, don't use these words, use like this kind of language", "tokens": [50720, 9208, 8027, 11, 764, 1310, 613, 2283, 11, 500, 380, 764, 613, 2283, 11, 764, 411, 341, 733, 295, 2856, 51056], "temperature": 0.0, "avg_logprob": -0.1306910514831543, "compression_ratio": 1.5917159763313609, "no_speech_prob": 0.005057178437709808}, {"id": 671, "seek": 499072, "start": 5004.56, "end": 5011.2, "text": " presentation and so on. And then it will follow those instructions in order to actually", "tokens": [51056, 5860, 293, 370, 322, 13, 400, 550, 309, 486, 1524, 729, 9415, 294, 1668, 281, 767, 51388], "temperature": 0.0, "avg_logprob": -0.1306910514831543, "compression_ratio": 1.5917159763313609, "no_speech_prob": 0.005057178437709808}, {"id": 672, "seek": 501120, "start": 5011.44, "end": 5019.92, "text": " take the tone of voice and teach GPT to reply in your tone of voice. For that, you have to do", "tokens": [50376, 747, 264, 8027, 295, 3177, 293, 2924, 26039, 51, 281, 16972, 294, 428, 8027, 295, 3177, 13, 1171, 300, 11, 291, 362, 281, 360, 50800], "temperature": 0.0, "avg_logprob": -0.21105590521120557, "compression_ratio": 1.3472222222222223, "no_speech_prob": 0.013219424523413181}, {"id": 673, "seek": 501120, "start": 5019.92, "end": 5032.639999999999, "text": " fine tuning. It's possible with GPT, but it requires more technical expertise. Probably need to find", "tokens": [50800, 2489, 15164, 13, 467, 311, 1944, 365, 26039, 51, 11, 457, 309, 7029, 544, 6191, 11769, 13, 9210, 643, 281, 915, 51436], "temperature": 0.0, "avg_logprob": -0.21105590521120557, "compression_ratio": 1.3472222222222223, "no_speech_prob": 0.013219424523413181}, {"id": 674, "seek": 503264, "start": 5033.280000000001, "end": 5035.92, "text": " an engineer to help with that.", "tokens": [50396, 364, 11403, 281, 854, 365, 300, 13, 50528], "temperature": 0.0, "avg_logprob": -0.31616192393832737, "compression_ratio": 1.1981132075471699, "no_speech_prob": 0.003820468671619892}, {"id": 675, "seek": 503264, "start": 5044.08, "end": 5054.88, "text": " All right. Yeah, so I see no more questions, but I will send recording and presentation to Dina,", "tokens": [50936, 1057, 558, 13, 865, 11, 370, 286, 536, 572, 544, 1651, 11, 457, 286, 486, 2845, 6613, 293, 5860, 281, 413, 1426, 11, 51476], "temperature": 0.0, "avg_logprob": -0.31616192393832737, "compression_ratio": 1.1981132075471699, "no_speech_prob": 0.003820468671619892}, {"id": 676, "seek": 505488, "start": 5054.88, "end": 5062.16, "text": " so you will get it soon. All the links, everything I've shown in the today are in the", "tokens": [50364, 370, 291, 486, 483, 309, 2321, 13, 1057, 264, 6123, 11, 1203, 286, 600, 4898, 294, 264, 965, 366, 294, 264, 50728], "temperature": 0.0, "avg_logprob": -0.17623552099450843, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.12046952545642853}, {"id": 677, "seek": 505488, "start": 5062.16, "end": 5068.56, "text": " presentation. There's actually a bit more that I, a bit more slides, I skipped some of them.", "tokens": [50728, 5860, 13, 821, 311, 767, 257, 857, 544, 300, 286, 11, 257, 857, 544, 9788, 11, 286, 30193, 512, 295, 552, 13, 51048], "temperature": 0.0, "avg_logprob": -0.17623552099450843, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.12046952545642853}, {"id": 678, "seek": 505488, "start": 5069.76, "end": 5076.96, "text": " So, so yeah, I hope, I hope, I hope this is valuable. I hope this is useful and I hope that", "tokens": [51108, 407, 11, 370, 1338, 11, 286, 1454, 11, 286, 1454, 11, 286, 1454, 341, 307, 8263, 13, 286, 1454, 341, 307, 4420, 293, 286, 1454, 300, 51468], "temperature": 0.0, "avg_logprob": -0.17623552099450843, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.12046952545642853}, {"id": 679, "seek": 507696, "start": 5077.6, "end": 5085.28, "text": " my sincere recommendation is to like just spend more time working with the systems and working", "tokens": [50396, 452, 16941, 11879, 307, 281, 411, 445, 3496, 544, 565, 1364, 365, 264, 3652, 293, 1364, 50780], "temperature": 0.0, "avg_logprob": -0.21363597282996544, "compression_ratio": 1.4742268041237114, "no_speech_prob": 0.004323387518525124}, {"id": 680, "seek": 507696, "start": 5085.28, "end": 5095.04, "text": " with GPT, with AI, because the most important thing is to build intuition. That's what most useful.", "tokens": [50780, 365, 26039, 51, 11, 365, 7318, 11, 570, 264, 881, 1021, 551, 307, 281, 1322, 24002, 13, 663, 311, 437, 881, 4420, 13, 51268], "temperature": 0.0, "avg_logprob": -0.21363597282996544, "compression_ratio": 1.4742268041237114, "no_speech_prob": 0.004323387518525124}, {"id": 681, "seek": 507696, "start": 5097.76, "end": 5103.92, "text": " Thank you very much, Dipan. I think that was quite a comprehensive presentation, especially", "tokens": [51404, 1044, 291, 588, 709, 11, 33486, 282, 13, 286, 519, 300, 390, 1596, 257, 13914, 5860, 11, 2318, 51712], "temperature": 0.0, "avg_logprob": -0.21363597282996544, "compression_ratio": 1.4742268041237114, "no_speech_prob": 0.004323387518525124}, {"id": 682, "seek": 510392, "start": 5104.0, "end": 5108.24, "text": " for the first slide, being an intro. Tamuna, you want to say something?", "tokens": [50368, 337, 264, 700, 4137, 11, 885, 364, 12897, 13, 8540, 5051, 11, 291, 528, 281, 584, 746, 30, 50580], "temperature": 0.0, "avg_logprob": -0.2596723641922225, "compression_ratio": 1.5864197530864197, "no_speech_prob": 0.005579692777246237}, {"id": 683, "seek": 510392, "start": 5109.84, "end": 5115.68, "text": " I just wanted to say thank you. It was really one of the most useful and practical AI sessions", "tokens": [50660, 286, 445, 1415, 281, 584, 1309, 291, 13, 467, 390, 534, 472, 295, 264, 881, 4420, 293, 8496, 7318, 11081, 50952], "temperature": 0.0, "avg_logprob": -0.2596723641922225, "compression_ratio": 1.5864197530864197, "no_speech_prob": 0.005579692777246237}, {"id": 684, "seek": 510392, "start": 5115.68, "end": 5122.56, "text": " I attended, and I attended several, so thank you. It was really good. Thank you very much.", "tokens": [50952, 286, 15990, 11, 293, 286, 15990, 2940, 11, 370, 1309, 291, 13, 467, 390, 534, 665, 13, 1044, 291, 588, 709, 13, 51296], "temperature": 0.0, "avg_logprob": -0.2596723641922225, "compression_ratio": 1.5864197530864197, "no_speech_prob": 0.005579692777246237}], "language": "en"}