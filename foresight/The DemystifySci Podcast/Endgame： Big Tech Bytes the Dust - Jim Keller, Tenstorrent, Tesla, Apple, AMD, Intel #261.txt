Welcome back to Demystify Sci, where today we are exploring how to achieve the impossible.
For this conversation we have with us Jim Keller, who is a microprocessor engineer who's worked at
places like AMD, Apple, Tesla, and currently is working on a next generation of AI compatible chips
that are going to be a competitor with Nvidia for all the stuff that they're doing for artificial
intelligence and also has this wild idea for a startup which is already in progress for being
able to create a semiconductor fab that is tabletop size. He's also got the idea of being able to
3D print a car for $5,000 and so this is a guy who's worked for his entire life at these enormous
organizations that are able to achieve things that across the board people say are not possible.
And so we wanted to start with him to figure out what does that actually look like? What are the
things that go into making a successful company? What are the pieces of culture that are internal
to the company versus the pieces of culture that are internal to the humans within that company?
And how do they play together in order to let people achieve what seems on paper absolutely
not going to happen? Which is very improbable as a perspective considering he's actually
so cynical about the lifespan of institutions and of these companies. He recognizes there's a
cyclic nature to the boom and bust of the production in all of these different organizations.
And so he's pulled out these really fascinating trends for what it means for a company to reach
that pinnacle and why they can't stay there. And the same thing can be applied to our scientific
institutions, our government, and we go into all of this. So it's a really, really refreshing,
inspiring perspective that I don't think we've seen on this show so far.
And honestly, it's also just really cool to sit down with somebody who has worked on the chips
that have been in the technology that I've used my entire life and to discover that he's thinking
about physics and science and human nature and the fractal arc of reality in this way that actually
gives him the ability to come up with ideas that other people just seem to not have access to.
And so we get into all of that. It's a really good conversation. Hopefully we'll be able to
have him back to talk about some other stuff because he's been in contact with these titans of
the last 50 years, Elon Musk, Steve Jobs, and just has a wealth of experience in the world
that I think would be really interesting to talk more about. But in the meantime,
I want you to consider coming over to our Patreon. So we are a patron-sponsored podcast. We take no
ads, we have no commercial sponsors, and we really, really, really want to keep it that way
because that aligns with the way that we see the world functioning. We make something that is useful
to people and the people who like it support us and let us keep doing it. And so if you've watched
a couple episodes of the podcast and you enjoy it, then consider coming over to patreon.com
slash dmstify.com and joining us for just a couple dollars a month. A fistful of dollars if you like.
Indeed. However, many dollars fit into the fistful that you would like to take, happy to accept.
You can put different denominations in a fist, it turns out.
It's true. And also, something else that you can really do is if you're watching the podcast on
YouTube, leave a comment. If you're watching it on Spotify or any of the podcast stores,
perhaps rate the podcast. These are all things that help us boost ourselves algorithmically,
and they don't cost you anything except for a few minutes of your time.
And it helps us get better guests too, which is ultimately going to serve you guys. So do it.
All right. Hopefully, you will follow through. Hopefully, we will see you soon.
And for now, enjoy the conversation with Jim Keller.
I came across a quote that I think is an unfortunate article about you where they
said that you're really a fan of the Steve Jobs aphorism, which is that once you know what to do,
you shouldn't work on anything else. And I wonder about that in context of institutional longevity,
because it's really easy for an institution to continuously come up with a new thing to do
and keep trying to work on something different. And so in addition to knowing what to do and
then working exclusively on it, do you think that there has to be a sense of an expiration date?
Yes, probably definitely. So this is a, yeah, this is a really complicated question.
And then I was part of, you know, the demise of digital equipment,
which was a great company. And we went from growing and everybody there was excited.
A friend of mine's wife said, what do they put in the water? All you guys do is work or talk about
work. It's really fun. And then I've talked about this in a couple like financial analysts
seminars recently that like when I joined digital, they were very proud of building low-cost open
computers. And they were winning against IBM. And then IBM, and people said nobody went broke
by in IBM, home digital was building this lower cost, more open computer that people could buy
and do stuff with. And 10 years later, and only took 10 years, they're competing against sun and
silicon graphics, who are building lower cost, easier to use computers. And the digital sales guys,
some of the same people, I suspect, you know, poo pooed the sun systems as toys and cheap and
little and non-professional. And, you know, digital went through like a literal collapse.
Their best revenue year was on falling sales, rising prices. And then they just lost the
market. And it was also interestingly enough, we were going bankrupt at the same time we were
building the world's fastest computers. We were building a new generation of product that was
demonstratively be better than anything we'd ever made, better than sun by a lot, and went bankrupt
at the same time. And so. But seems impossible on some of them. Yeah, yeah, it's a miracle.
But there was all kinds of things. So, so you have to, yeah, I tell people sometimes ask me,
like, how do you manage a team? And how do you do something? And people simultaneously,
let's say, underthink it and underdo it. Like, people will read one management book. A frequent
question I get is, which book should I read? Because I say I read lots of books. I mostly
say all of them. And, you know, and I've been trolling some of my internet friends by releasing
lists of five books, but they're, they're relatively randomly arranged, you know, book on
management, a book on science fiction and the book on, I really like Katie Byron Katie's book,
Loving What Is, you know, and, you know, so. But now, as a book on management, that's not obvious,
but it's a great book on management. Same with the Five Love Languages, which is, I think,
a marital book. And, but it's complicated. You need lots of different frameworks to figure things
out. So, so digital equipment is a great example of that. The company could literally
revert almost everything that made it successful, then go bankrupt while building a great new product.
And mostly, I think that made it successful. Yeah. Yeah, so we were building alpha computers,
which had 64-bit addressing, and it was one of the better, better ones of the early 64-bit
computers. And one of its charms was we could adjust very large memories from some server
applications. That was important. But the memory group at digital had been making lots of money
for years and they'd been raising prices. They literally created an industry around
digital making plug-in memories that were cheaper when company EMC became very large and successful.
So, as digital brought alpha to market, the memory guys were raising money,
raising memory prices, and we didn't sell any memory. So, so that one of the virtues of the
computer was addressing more memory and memory prices were so high that our customers
were buying memory from a competitor. Like, like in the world of like, how dumb could it be?
And as engineers, we knew this was happening. And the memory group was working with us to
make it harder to plug in memory and the engineering team made it easier to plug in memory.
And there was no intermediary that could be like, hey, we're working against each other?
Well, so, so this is where you get it. So, Ken Olson was the founder and he was still there,
mostly, although he was replaced with Bob Palmer. So, Ken had this kind of do the right thing attitude
and, and, you know, let people go off and do their thing. But the problem is the memory business
was a business and the server business was a business. And the memory business made more money
by actually lowering the server business substantially. And that's where, you know,
the uncoordinated action kill them because usually, you know, you, you would think somebody would say,
hey, this doesn't make any sense. We're killing our business by not doing something.
But it's really hard and mostly not companies when they're non founder run,
you know, run the ground at some point, because they
founders optimized for the longevity of their baby. And
non founders frequently optimized for their own personal income.
So how many people were digital equipment at that point?
The peak was 110,000.
That is enormous.
Yeah, yeah. Yeah, back in the day, it was a Arctic cap was 14 billion.
I worked on a computer. We, you know, back to the 800, we sold $5 billion worth of
computers at a half a million a piece. It was, it was really amazing.
So I like, like I said, so you need a couple things. So there's the life cycle story, which is
you know, in human beings to the zero to 20 year, you're a kid learning stuff. And then 20 to 40,
you find your place in the world. And then 40 to 60, you should, that's a mobile, exploit your
expertise. And then 60 to, you know, death, you enjoy a retirement or your enlightenment or
if you're a sociopath, you might continue to operate at some high level
of manipulating reality, right? And so companies go through those cycles.
And a lot of companies fail long run because they just get old.
And some companies get restarted, like, you know, both Apple and Microsoft were
essentially rebooted, you know, Apple by the founder and Microsoft by
Satya Nardella, which is, which is amazing. Like nobody saw that coming because that company had
seemed to have gotten into the, you know, they had cash cow products and they were soaking the
customers for it. So it's very hard to, to reboot a company substantially, once you pass a certain
point. But anyway, it's a framework. And there's another framework, which is organizations tend
towards order and the order slowly, like a startup is very chaotic. And a friend of mine drew this
graph of, you know, the X axis is chaos at the origin and then order, and then the Y axis is
productivity. So for a while, as you increase organizational procedures and, and, and process,
you get more productive, but at some point you get less productive. And the trick isn't figuring
out where you should be on the curve, you should be at the top. It's like, you know, you curve,
right? The trick is staying there. Because once you start organizing for productivity,
more order always seems like the right answer. And then I know a lot of companies, the people who
are very good at organizing things, sort of outmaneuver politically, the people are good at
inventing things. And if there's nobody going, wait a minute, we need a new product. So it's
very difficult to escape that trap. And does the size of the company influence that as well?
Yes and no, you know, like there's many companies who go through, you know, never get very big,
but still become bureaucratic. But it's, it probably gets harder to avoid it as you get bigger.
Like, you know, a lot of the big tech companies that we think are, you know, great,
are famously bureaucratic, you know, like Google and Facebook. And then there's some companies
that are famously not like Amazon's run as a whole bunch of small silos that, you know,
compete with each other. And I'm not sure what the current lay of the land is at Microsoft.
Apple under Steve Jobs was mostly small teams and he didn't trust big teams. But since he
passed away, the company has become unbelievably large and successful and all the teams are huge.
What was the secret to the, to these reboots that actually worked out?
Well, Steve Jobs was in a very strong belief in product. So we, I had a friend who worked for
him at the time, and he said, we have 10 business groups, and they're all losing money. The company
is losing money, but on paper, all the groups are making money. And that's because they were doing
transfer costs, you know, bureaucratic shenanigans, like, I'll make something for you and sell it to
you as I have a profit, but then you sell it to somebody, you know, so it was just a mess.
And there's too many competing products. And if you have product A and product B,
the marketing guy will say, make product between them. And, you know, you'll have a better product
line, a better coverage. So Steve Jobs, he canceled apparently all the business units,
he canceled the products, he canceled, fired most of the managers. And he created the same as
two by two matrix, which was consumer pro mobile desktop. He said, we're going to make four products.
And everybody wants one of those. Like if you're a professional and you sit at your desk, you want
a desktop pro computer. If you're, you know, working, but you travel, you want a professional
mobile computer. That was the MacBook Pro, the Mac Pro. And then the iMac was the famous
translucent, you know, fun computer for the house. And so he created those. And then he said,
we'll make each one of them the best we possibly can, which means we won't get all the customers
because there'll be gaps and holes. But you could trust us that if you buy iMac, you'll be very happy.
And, and then when I was going really well, then they did the iPhone. And then he really believed
in the iPad. I was there during the, I guess the third iPhone chip in the start of the iPad.
And then he really believed in TV and he told us he'd cracked TV. But he passed away before he
built the product. And I don't know what he cracked because it wasn't the Apple TV product. He
didn't like that very much. But he was very focused on the next thing. And then he's, Steve famously said,
like, so technology is often what I call a cascade, instead of cascading and diminishing
return curves. So you go up and it plateaus, and then there's a new invention, you go up into plateaus.
So we went from rotary phones to button phones to touchscreen phones. And each one of them,
when it first started. So the first, you know, touchscreen phones weren't as good as the buttons.
Right. So black, blackberry users laughed at the touchscreen phone people. So the screen was
bigger, but your touch wasn't accurate. It was slow sometime. I had friends that would prove to me
they could type faster on blackberry than a touchscreen phone. And yet the blackberry died
because they were married to the old technology. So Steve's point was when you go from one technology
to the next one, you always go down that up. Right. You're, you're jump. You're, you're by
definition jumping from a highly refined endpoint to an unrefined starting point.
That depends on when you jump, right? Because the people who had
and that's the thing. As he said, any idiot can show you could wait until it starts to be refined.
Now you're behind. So the wind, if you wait for other people to do it, you're going to have a
business strategy of being a fast follower. That's actually a business term. But if you always wait,
you'll always be second. And when people create new markets, it's amazing.
The digital and phones, I mean, Apple and phones, we did 64 bits before anybody else. We did
high resolution displays before anybody else. We did get great cameras before anybody else.
We did thin phones before anybody else. And each time it took a couple of years for people to catch
up. So yeah, it's a, it's a funny thing. So was this, this was the reboot strategy?
Yeah. So this was after like Steve's got thrown out a digit out of Apple,
partly cause he couldn't work with people and partly he made a big back on the big bed on the
Lisa and then the factory for the Lisa and the original Macintosh and it didn't go well.
And he was famously hard to work with. And so when he came back, Apple bought next.
And next was Steve's company with a new operating system.
So like Apple at some point needed the new operating system they bought next. And then
for a bunch of reasons, I wasn't there. He maneuvered his way back into being CEO and then
you know, launched into a famous reboot of Apple, which, which by the way is relatively unprecedented.
He said that Microsoft managed to do it as well. What was the story there?
Yeah. And that's not a non-founder. Yeah. So Microsoft, everything was Windows. They had
Windows, you know, Windows phones, Windows PCs, Windows mouse. And the world was sort of shifting
away from Windows and Windows had a lot of problems. Like it was going mobile.
And they tried to build something called .NET, but everything they did was proprietary
early and the company was suffering. And Satya pivoted the company to being data first,
essentially. He got rid of all the Windows groups. We have, I suspect they actually let go a lot
of people, including senior management. So Microsoft built this beautiful tablet computer.
I know the people who made it, but the group that did Office Suite wouldn't port their software to it.
Right. And nobody could tell them to port. Like they ran a business and they said,
it doesn't make any business sense for us to port the software. So under Satya, that all changed.
What's that? Because it would be packaged with the tablet when it was sold and so it wasn't going
to make money. So this is where you guys have probably read Shakespeare, right?
Some, not with them.
It's good to read Shakespeare. Right. So Shakespeare is always the drama between the king,
the ministers, you know, the poor bastards and the hero.
Right. And so big companies, when they become bureaucratic, you know, if they're run by somebody
who then has some number of people running organizations, let's call them the conniving
ministers. Right. And they are, let's say, vying for favor from the king and benefits
by mostly messing with each other. And the king isn't king because he's stronger than all of them.
He's stronger because he plays them against each other and they play against each other.
But at some point there's, let's say, a real problem. Like Windows is going down or the
Macintosh is broken. And then the drama is, is how does it play out?
Because the king can't trust the hero because the hero will replace them. The poor bastards are all
rooting for that. And the ministers are trying to get the hero on their side because then they can
win. And it's very difficult in a lot of companies for anybody to, unless there's a really strong
founder and a really strong culture. The picture that you're painting makes it seem
almost miraculous that anything gets done. Oh yeah, that's actually true.
Now I read this funny, here's a funny one. So there was a study about the differential
growth between China and Vietnam. This is a 20, 25 years ago. And they basically said there was a
10% difference in corruption between the two countries. I forget the exact numbers.
And as a result, China was growing at 10% year over year and Vietnam was growing at zero.
And the corruption number was big, like 50%. Which was what were corrupt?
According to this study, I don't know if that, you know, it's true. But, you know, people look
at spectacular growths and think, wow, that's amazing. Like they must be all working really
hard and doing really good things. But it could be they're producing 4%, you know, real benefit
year over year, but compound growth of 4% actually over, you know, 10 years is a lot.
Right. And then in our big economy today with all the companies,
like there's lots of strategies. So new technologies are mostly exploited by new companies.
Like when Google was growing fast, some big companies had search engines, but they were all
terrible. And Google grew and, you know, for a while, for a long time, they profess, you know,
they do no evil and everything was the good of humanity. But the way they made money is
serving ads. And then what happens is they get really good at it. And the more ads they serve,
you know, the more money they make, and the more they get you to look at them, the better. And then
they go back to their, the people want to pay for ads. And they say, we can manipulate the
results to give you better responses. And now you have their company mission, which is to make
all the data available to everybody. But their business says we're going to make a lot of money.
But their advertisers, you know, would like, you know, differential benefits and the consumers
have options. Right. So that's a complicated thing. And then you could cast that as a Shakespeare
play and assign the, you know, the villains and heroes as you want. But it's really complicated.
And this happens all the time, like every company goes through these cycles.
Do you have any insight into the day that Google dropped its do no evil slogan?
Yeah, it's long after that was true.
You know, just so that there's cognizant. Well, companies go through this cognitive
dissonance phase, you know, they have a corporate vision about who they are and what they want to
be. And then they have a bottom line to attend to. And then the business practices that accomplish
that. And then I'm sure some engineers said, hey, we can't do X, Y and Z because of our vision.
And it was like, yeah, well, we haven't been doing that for years. And, you know, it's complicated.
You know, most people at Google want to do the right thing. And most businesses want to,
you know, be, you know, let's say as moral as they can be. And then the market
kind of does this interesting thing, which is as companies become monopolies and start like
squeezing their customers, essentially, you know, it's easy to cut your R&D and, you know, spend
more on sales and make more money. But then there's a competitive thing. Like the US car industry,
there was the big three, and they were all playing the same game and gaming each other.
And when Toyota showed up, they laughed. It was a shitty little car. And Toyota made a better
and better car. And all of a sudden, they're on the back foot, you know, trying to catch up with
Toyota. Like, who saw that happen? They actually went sun Pro and went bankrupt. And then the
government bailed them out because there's, you know, like the layers of complexity is they're
so high. It's amazing. Like, they can some change depending on that at some point.
Yeah, yeah, there's the politicians and the unions and the jobs and the states and distributed
manufacturers and, but they all going through these cycles of their internal growth of technology
cycles of, you know, competitive cycles. Yeah, it's quite amazing.
Hey, folks, quick interruption. I really need you to come over and check out our Patreon page.
You can give as little as a couple of dollars a month, or you can give us a fistful of dollars
The point is this program is entirely supported by people like you who are enjoying this program.
Don't have any sponsors. Don't have any ads. We want to keep it that way. So please consider
coming over and checking out how you can just give the tiniest amount to support this project
into the future. Thank you. I'll see you there. So do you think that you can tell when an organization
is starting to get to the place of decline early? Or do you think that it's always something that
you can only really tell once the decline is fulfilled and then you look back and kind of
match things? Like is there a predictable time length? Even is there a time scale? Is it size
dependent? I'm not even thinking necessarily about time scale. That would be interesting. I'm
thinking more about it. In terms of things that happen, like patterns that you start to see emerging
and people starting to behave in certain ways. Like you're talking about the drill equipment
where you have the the branch that's dealing with memory and the branch that's dealing with
servers completely operating at odds with each other. That serves as this harbinger of chaos
to come unless somebody can come in and you know make the vessels behave. So in retrospect,
it's way easier. Somebody said, you know, the past the banker, you know, they were going to
bankruptcy and they said it happened slowly at first and then all at once. And that's often
so digital went through this rising revenue on falling unit sales. That's a really good sign.
You see companies, I worked at a company that was basically capitalizing cost.
So if you build a product and you have to buy a component to put in that product, that's an
expense. But if you build a factory to build that component, that's capital.
Right. And so for financial accounting reasons, capital is deductible and viewed as a good thing.
Capital is an asset versus expenses are a problem. And so as companies get bigger and
mature, they get, let's say, sophisticated economic tools and some of those are really good
because we have complicated tax rules and international business rules
reporting roles and you have to know what they all are and you have to play the game.
Otherwise, you won't report making any money. But you know, the nominal timeline looks something
like the life cycle of a human being, which I said is 20 years, 20 years, 20 years, 20 years.
But some of that's accelerated, like the lots of startups go through five to 10 years of
figure finding their real place in the world and then ramping. Some companies ramp really quick,
like Google probably would be wandering around for five years.
Like they were making real progress and lots of people like them, but they weren't making any
money. And then they ramped pretty hard for over 10 years and 15. They still make lots of money.
To a lot of the AI companies right now, right? Like OpenAI and Anthropic, their ramps are
super big. Yeah, that's a, so there's another phenomenon. So independent of the business
cycle, there's kind of hype cycles. The AI is as a strong hype cycle, partly because there's a lot
of revenue and market cap, you know, based on it. So there's a little FOMO going there, which is,
you know, let's, let's get involved and do something.
How much of that, can you tell how much of it is hype and how much of it is real? Because, I mean,
you obviously can't really trust the representatives of a company to tell you accurately
what's happening or what will happen. Promise is these massively intelligent,
general intelligence machines that will one day outshine humans. Everybody's pointing to the
exponential curve and like, we're, it's going to continue forever. But anybody who looks at
exponential curves also knows that sometimes they're logarithmic and they just stable it.
Yeah, yeah. Yeah, they're, they're S-curves, not exponentials. Yeah, it's pretty.
Right. Yeah, it's hard to say. So the, in the internet boom, there was a whole bunch of companies
who clearly had to achieve some network effect to be successful. So two good examples.
One early was PayPal. So they were paying their customers to recommend them to other people.
So they spent hundreds of millions of dollars in customer acquisition
with actually no plan to make any money. But they got big enough and they started to make money.
And then there was other companies who said, Hey, we're going to do the same thing, web band. And
it was a pet company that was doing online stuff. So they were paid, they spent billions of dollars
in customer acquisition and then didn't keep any of them and just earned the money at all.
And Uber was the same way. Uber spent billions of dollars in customer acquisition.
And, you know, Uber used to be a really good deal compared to a taxi on price.
Like the convenience is a huge win, but the price was also better. But when they slowly
started working on making money, when they had acquired enough customers that the argument of
customer acquisition was kind of dumb, they started raising prices. And now it's not obvious
that they're cheaper than taxis. They're more convenient. Now we got used to them. And then
they're, you know, 10 years of spending money to get customers, you know, they put a lot of
taxi companies out of business. But, you know, it's, it's not always obvious which way it's
going to go. You know, there was a lot more web bands than there was PayPal's.
But these are, you know, business cycles, which are really interesting. The internal
dynamics. So humans are, you know, when we, when you build organizations, humans are very good
in groups of five to 10, because that's essentially a family group. And we're very good in groups of
like up to 100 or so. Because that's like a tribal group, like we can map them really well.
But when you want to grow past 100, suddenly you need a whole different level of infrastructure.
Because now you have one group working on something to deliver with another group where they don't
know anybody. And, and this is another one of those dynamics when, when you have a strong vision
and you're growing fast and there's too much to do, you know, sometimes those organizations
grow naturally, sometimes you really have to work on it. But then when a company slows down and you
have all these little groups of people who don't know each other very well, and they're exchanging,
you know, work for a boss or some reward, that stuff can get gained pretty hard.
And then companies become bureaucratic. And then there's a famous line about bureaucracy is like
bureaucracy is inevitable with human beings, apparently. And, you know, it's, it's not whether
you want one or not, it's how you manage it. Because at some point the bureaucracy will,
like somebody said, you know, imagine that bureaucracy is always run by your worst enemy.
And, and for a lot of companies, that's actually what ultimately does them in.
So you have business cycle dynamics, which is really interesting. And then you have
this organizational dynamic. And that's been studied pretty widely, you know, like there's a,
there's one line that which is 20% of the people do 80% of the work, which is fairly common.
And then there's another one, which is the output of an organization is the square root of the number
of people, which has, you know, been studied understated behind that. And then you might say,
well, then we should keep the group as a whole bunch of small teams. And some people do that,
but sometimes that's impossible. Like you're doing something really big and hard, and you
actually have to figure out, like, well, 1000 people isn't as efficient as 100 people.
You can get a lot more done with 1000 people than 100.
And is it just that the challenge with technology and large projects is that you can't break a
project down into small enough chunks that you can get people to work in these small groups?
Like I'm thinking for, you know, really,
No, that's actually that you put your finger right on it. Like one of the fundamental things
is humans aren't very smart. And we're not getting any smarter. So we don't solve harder problems
because we're smarter period. Like, well, I've been working engineering for 40 years,
I don't see any evidence that anybody's any smarter. Some of the tools we have are really good.
Do you see other people are dumbers?
No, not really. Okay, that's good. That's really no.
I'm sure the answer is going to be yes, but that's good.
I have an aunt who's very smart and very well read and she was complaining about young people.
So I, I found this letter and I read it to her and she said, that's just it.
People don't read enough anymore. They don't write, they don't do this, they don't do that.
And I said, that was written by Ben Franklin.
It's such a great, you can probably go Ben Franklin's letter about, you know,
the inadequacies of young people. So, so when you think that that mostly just tells you your age.
So all human beings around 50 years old or so starts to suspect that 20 year olds aren't very
smart. I've always been an old soul some early at that arrival.
So you might, yeah. So if you're, you're early, it really depends on where you go.
Like we hired college kids at Tesla. They were so smart and hardworking and ready to go.
And then I'm, you know, and I talked to friends at another big company and they're the people
they hired from college, to be honest, weren't very good. But that's because the students were
selecting based on the company. You know, the super smart ones wanted to go test their metal
at a place where they knew they'd be stressed. And the students that were sort of average and
wanted to go along with the get along and get a good paycheck were picking a company that was
literally easy to work for and do nothing. And I mean, I'm just thinking I was looking at,
yeah, that's a really funny drawing, hand drawing diagrams for, I think it was like
rocket propulsion systems before they had computers. And so it's this photograph of this
gigantic piece of paper. And there's like five engineers that are hand writing the calculations
and drawing trajectories. And I look at that. And to me, it seems objectively like a harder thing
to do. But if you have a computer that can do the same thing for you. And so it's like,
if the computers are picking up the slack, then you wouldn't be able to notice the difference.
But if you were to take the computers away, would we still be able to perform at that same level?
And that's, that's the part where I'm not 100% sure.
It really depends. So you could probably coast way, way further knowing a whole bunch of programs
and tools. But the Tesla rocket engines are way better than the ones that built in the 70s.
They're just way better. And you know, they produce them for 10x less money, 10x less hours,
they're reusable, they're more efficient. Like everything about them is better.
They're not even close. Modern cars are so good. Geez. You know, I was in the Hyundai factory
recently, you know, the time to go from like basically what comes into the factory is these
rolls of steel, you know, and they're, you know, random millimetres thick, depending on the parts.
And, you know, four hours later, there's a car. All stamping is done. They have a machine that
on rolls that cuts it, stamps it, knocks it out. They basically take every part and scan it with
laser beams and they, you can mark them up and correct them and tweak them. And then the robots
have put the pieces together and spot weld them all together. The damn things are near perfect.
Stamping machines are great, by the way. So they've been using stamping machines forever.
Like stamping machine is literally a car of a shape and a hard surface and then
put a big weight behind it and drop it on a piece of flat sheet metal and sheet metal.
Most of the number one cause of workplace accidents.
Yeah, the modern stamping machines, they're all operated by robots. They don't let people near
them. Yeah, stamping machines are tough. I got a funny question about donut factory and they're
always losing fingers that were there. It's the worst. Yeah, yeah, stamping donut. That's amazing.
Yeah, they've got to come from somewhere. Well, and then when you build a factory with robots,
then you wear it because the robots are so strong and they move so fast that they'll take people
apart. So then the, all the factories are like built with this is the people's zone and this is
the robots on the pretty soon robots will be smart enough not to whack people. Like all the robots
will see. But at that point, anyway, it's like the robot containment zone as well.
What's that? I said, but at that point, when they're smart enough, they can escape the robot
containment zone as well. So that's, that's a privilege sort of thing.
Were you freaked out about these possibilities when you were working on that system?
Yeah, so I ran the hardware, yeah, the autopilot ship hardware team. So we built a hardware
three, it's called hardware three chip and started hardware four chip. And then also started Dojo,
the Tesla super computer. And then for a while, they, the autopilot software team reported to me,
but that was sort of, you know, a random thing because Andre Carpathi mostly worked for Elon and
some of the software team worked for me and some of them worked for Andre and we missed around.
So that's a different question. That's a different question that might freak out that
robots or super intelligent computers will impact humanity.
No, just these Tesla's, these self-driving cars, right? It seems like whenever you introduce a
new technology, somebody's going to have to figure out what's wrong with it. Like airplanes are a
good example, right? They're, when they first build these jetliners, they're falling out on the
sky all the time, but now they're some of the safest ways to travel on the planet. And I remember
there was a few, maybe actually, I don't remember one really bad incident with the Tesla car,
but sticking an intersection, a truck pulling out for an intersection, an intersection for
white or gray sky or something like that. There's been a couple of problems.
No, we reviewed all the, all the fatals and many of the serious accidents every week,
literally. Okay, so, so you're familiar with the trolley problem, I presume.
Yeah, which is you have, you have a switch and then on one track, there's one person tied to
the tracks on the other side, there's five people tied to the tracks, you pull the switch.
Yeah, yeah. So Elon deeply believed you pulled the switch, right? Kill less people. So,
so he said, oh, he said this publicly, you know, we're going to make cars safer. The only way to
do that is autonomous driving and really good, you know, autonomous driving software and computers.
And, but, but as it develops, some people will die because of defects in that software,
but less people will die, I think. And then he also backed up that commitment by making Tesla,
like Tesla had some of the crash analysis software in the world. And then the way they built Tesla
was with the battery pack and the floor and the crush frames in the front and the back of the car
and made it really safe. And so they were one of the first a five star,
you know, crash certification, which is actually mostly a real thing, by the way,
like some certifications that I'm skeptical of, but crash safety people are really good.
And then the side impact crash and then, and then there's a really wild graph, which, you know, the
fatalities versus speed graph. So over 40 miles an hour, you mostly die and under 40 miles an hour,
you mostly don't. And so the mission was a, to raise the speed where you mostly don't die
and be lower the speed of the car really fast in the event of a detection of an accident.
Right. So, yeah, so was it, was it daunting building a safety product? Yes, definitely.
Did we analyze it a lot and worry about it? Oh, yeah. So one of the guys who worked for me,
there was a radar product we had that mistook a truck for a sign and rejected. So the problem
was radar, it's a relatively low resolution and a small object with a right geometry can look
like a very big object. And so the radar's problem is false positive. So they reject lots of false
positives and it rejected a truck and the person dies. And then when we took the software apart,
we figured out why, like the filters, the software using were very good. We rewrote the software so
that we would detect that truck properly and some other situations where the radar was not doing
that good. How safe are they at this point, these self-driving software as compared to the average
driver? I don't know. I don't, I see Waymo and Waymo driving around San Francisco with no people
in the cars. And I think they're relatively good. They overkill it really high on sensors and compute.
Tesla, Tesla's are not there yet. I have the newest version of self-driving software. It's
pretty good. I really like it, but I wouldn't let it, you know, drive to work. You wouldn't take
a nap in the backseat. No, I definitely would not take a nap. But it's, it's coming along. And then
like Elon's belief is it's going to go in every single car. So it can't cost 50 grand. So the
Waymo solution is really expensive. It has many, many sensors and lots and lots of computers and
looks like a fighter jet or something. It's got so much gear. But is it possible that the cost
of processors is going to go down to the degree that the Waymo system isn't $50,000 anymore in like
10 years? Yeah, yeah, 10 years, maybe. Yeah, so there's like two schools. So this is again one of
those, you know, technology trends. So sometimes you say, well, I'll build the computer or system
big enough to do what I want. And then I'll cost reduce it over time. And then the other is I'll
build the solution and the size that I want. Right. And then work to make it, you know, the
functionality fit the budget. Right. And if you look at computer technology over a long enough
span of time, it definitely started with, we'll build it enormously expensive and enormously
large, and then we'll scale it down. Is it just that we've gotten to be sufficiently
geared out that we can start working on technological problems from the standpoint of now I have
enough components that are small enough and advanced enough that I can build small from the
gecko? Yeah, well, so yeah, there's a there's a funny trend line. So like every 10 years, we went
from mainframe to mini computer to workstation to PC to mobile. So that was, you know, every 10 years
is about 100 times more computing. So on the transistors per year, about 10 x every five years,
it's pretty solid graph. And then what happened is, like, like a PC wasn't 100 times faster than
mini computer, it was more like 10 times faster, it traded some of the transistor, you know,
performance, or just having less of them in a different form factor. So, so if you look if you
look at the trends of how many transistors you have versus how many transistors were in the
new cheaper product, like the transistor count grew faster than you know, so the budget was slowly
going down, which modulated the transistor improvement. The problem is AI, the AI you really
want is like a million times more than we have. In terms of driving or just in general, what's that?
In terms of self driving technology or just in general? Yeah, for a lot of things. Like if you
look at, you know, the operations in a phone chip, like phone chips are 20 bucks, right? And, you know,
Nvidia's new GPU is 25,000, right? And some of that's marked up because of, you know, the market
position and some of it's a lot of transistors and a lot of heat and performance. So AI was an
interesting step function. Like when you went from workstations to PCs to, you know, mobile,
like, like the first PCs were obviously inadequate compared to workstations,
but the transistor count quickly, you know, sped them up. And then the original phones were
inadequate compared to PCs. But so then there's two funny things there. One is
whenever you start with a big software on a big computer, the software never gets simpler.
So when they went from workstation to software to PC software to mobile software,
each time they were rewritten, like PC software is written from scratch and borrowed very little
from workstation to your software, right? Now at some point, the PC got fast enough to run
workstation software, but there was an evolutionary bottleneck that caused our big rewrite.
And then same thing happened with mobile devices. Like the original mobile operating systems were
very lean compared to PC operating systems that caused a really big cleanup. So the problem with
the Waymo approach is once they write all that software, all those computers and everything,
the odds of them, you know, making a 10x simpler by rewriting is kind of low. They're sort of
stuck at a higher cost basis. So I'm a little skeptical of the build it big enough to do the
job and make it cheap later or hope that or hope that that happens.
Did you say that NVIDIA ship was $25,000? Yeah. Who are the customers for that?
You know, Microsoft and Google and Bank of America and lots of people.
What are they implementing it in? Just in their own software enterprise, like in their own
computation back at home base? Oh, yeah, yeah. Right now, like all the big tech companies are
in an arm race and they're all calling NVIDIA to get allocation for their new best,
but they currently have the best processors by, you know, like functionality and, you know, obvious
proof points. Again, Diddy is slowly becoming the IBM of the AI era, I think. And like, we'll see
how that goes. Is it general? I run an AI tech company, so I have opinions about it, but I want
to hear about that too. But is that generally the case that the first online technology is
bought by these enormous corporations? Like you mentioned at the beginning,
digitally you said was selling a half a million dollar computer. And I'm thinking who's buying that?
Yeah. Oh, like a lot of people. So when digital started, they made logic boards. So they made
little boards as big with transistors on them. And they had products called like AND gate and
OR gate and right. And then they worked themselves up to making, I forget the original number, but
you know, they were making computers in, you know, one to 10,000 zone that were,
you know, slower than IBM's, but, you know, 10 times cheaper. And people loved them. And then
they built the 1144, which is probably 10 to 50,000. And then the 1170, which is a little more
expensive. And then the Vax 80, 100, or the Vax 780 was a one million instruction per second
computer. It sold for like 100,000 to $200,000. And they sold, you know, for the time, a lot of them.
And then the Vax 80, 100 was faster. And the cheapest one was over like 150,000. And then the
high end was $5,600,000. And they sold them to banks, businesses, all kinds of people.
Was the military a customer as well? Yeah, the military bottom, it was all over the place.
But at the time, the half million, the high end Vax computer for half a million dollars was a great
deal compared to the IBM solutions. And, you know, they were selling a lot of them, but
then they were planning like a computer after that was even more expensive.
And so this is another anomaly that happens is if you like the high end technology trends
that you'll see in like Forbes or Business Review or something shows this falling price
of computer. But generally speaking, in each kind of epoch of computing, the leaders slowly get more
expensive. Like Sun started, you know, $3,000 workstation and when they went out of business,
they were selling $100,000 servers. So there's a funny thing, like it's sort of like the Ford
Mustang. When the Ford Mustang came out and was 65, it was this beautiful little sports car by 72,
it was just bloated, you know, because everything everybody's idea maybe a little bit bigger,
let's put a little bit bigger engine, a little bit bigger tire, we'll make the back seats a little
bigger, we'll make it a little wider. So elbow room and what they, you know, they killed what
they loved about it. And that's a very common phenomenon. So human beings are phenomenally
good at this kind of stuff. So interesting, though, because on some level from the consumer's
standpoint, the 65 Mustang might have been a perfect car. Yes, it didn't mean anything.
And you could still be selling 65 Mustangs today, and they would be going like hotcakes because they
have the aesthetics, the vibes, the feel, whatever. And so it seems like the process of technological
development in this market system works directly against the person who just wants a thing
that looks like the sweet spot that got hit. Because I'm like, is the iPhone 15
significantly better than the iPhone 6? No. Right? And because Shiloh is still
probably the owner of iPhone 6. So that's the division return curves. And then people,
though the designers, the marketing people are all looking for something different. Because they,
you know, somewhere in their pointy little heads are like, if we just keep making 65 Mustangs,
people will maintain them and nobody will buy a new one. But if there's a new thing you have to
have, so why do you buy a car, especially a sports car? It's partly for fun, partly transportation,
partly for status, partly for new, partly you got bored, partly who knows, it's a complicated
thing. So yeah, this is where I mean, like people like underanalyze everything. So
so we just described, you know, at least a dozen frameworks, right? And so just all 12 equations
with 12 unknowns, you need 12 equations. Like, you can't, you can't cherry pick a point and then
get anywhere. So if you want to make new technology yet, it's good to be aware of all
these different phenomena and then you have to think about it. But you can also overthink it
and be over constrained by the whole thing. Okay, so yeah, I would, I would have loved
to have much improved. Now, some of the Mustang growth was because they started rolling in new
crash standards, which the old Mustang couldn't do. And then there was all kinds of wild emission
stuff with which they tried to build emissions in the cars before they had the computer controls
and sensors to do it. So nowadays, you could make a Mustang that big, that's way safer because we
have the crash software and very efficient and relatively, you know, low on emissions because
we have the sensors and the computer control systems and the high pressure pumps to do fuel
injection properly. Like, it's a, you know, today we saw those problems with high end technology.
Like modern computer controlled motors are amazing. What's that? But like Ford's not making,
that's the thing that's really strange to me. Is that? Oh, yeah, yeah. So then the question is,
why not to go back and make the great car with all the technology they have?
I don't know.
Like it's hard to actually just do it. It's really actually a really funny trend right now. It's
like reissuing, you know, the 54 strad or something like that. And they're selling really well
actually, because they just couldn't improve. And they're literally rewinding all the coils
to spec and everything is like, exactly how it was. And people are just loving it.
Is it all exactly because
I mean, they're very, they're so expensive. They're high, like they're, you know,
high end American products with, compared to some of their cheaper lines and stuff.
I think that they really do go after the original as much as possible from what I can tell.
And so it's an interesting strategy. I think the problem is the safety standards on those
old Mustang searches. Like if you've ever driven an old 60s, 70s car, they're like the
suspension's horrible. They have no pickup compared to what you're used to. They're just not
actually good cars is the problem. Yeah, but you could make a car that looked and felt like
the old Mustang that actually was safe, but it would be the opposite of like a reissued fender.
You know, the reissued fender, you could make exactly the same guitar and somebody would love it.
Whereas the reissued Mustang wouldn't look like even the metallurgy of the steel would be
completely different and it would be so much better. And this is something that's really
interesting to me because I'm like, okay, so Ford, for whatever reason, doesn't reissue the 65
Mustang, like that's perplexing. But there are people that may smaller car manufacturers
that would be happy to reissue a 65 Mustang with all of the updates, but they can't because of
intellectual property. Like Ford in perpetuity owns the... No, they don't. It's mostly you could
probably copy it. There's a difference in copyright law and patent law on this one.
I don't know what's the intellectual property is. I was going to introduce a new car that's
you were talking to Warren Mosler, he tried to do that, right? He built this car that was
way better than all the competitors and it was just impossible to bring it to market.
He seemed perplexed by even what had happened to him, but it seemed like it was
really held down by a kind of old club. It's very difficult to edge into that.
Okay, so fine. Like I think that the way that trademark law works is that if
Ford owns the trademark to the Mustang and the design of the car is not functional,
then nobody else can copy the look of the car because the only things that aren't protected by
trademark are things that are not... That are functional. Yes, sorry, that's a double negative.
Trademark protects non-functional appearance-based things. So the look of a car is protected by
the trademark that they own over it unless somebody can prove that the look of the car is
functional in which case trade dress doesn't cover it. But let's think about something
that's more recent, like the iPhone, right? So Apple doesn't make iPhone 6 as big. So if you
want an iPhone 6, you have to get one that's old and they're manufactured in such a way that
they're hard to repair. And so by the time that you get an iPhone 6, like none of the operating
system works on it anymore, it's very slow, like it's buggy, you can't really repair the components
easily. Is there some space to separate out the companies that generate the ideas and then the
people that implement them so that somebody who like Apple comes up with the idea for the iPhone,
then allows other people to make iPhones because they've moved on from inventing the
iPhone to inventing something else? Or is that just a complete socialist type of dream?
Well, some of this just happens over time, but it's longer time frame. So
so this is just my belief from history. 100% of the current companies will all become defunct.
Somewhere in the next 10 to 50 years. Like there's like essentially zero companies left from 100
years ago. I think General Electric is one of the few. So all the fortune one. Yeah.
There's the biggest companies during the expansion westward were all windmill manufacturing
companies. Yeah. Yeah. And then there was the oil and oil steel railroads. They were the high tech.
They were the booming startups in the mid 1800s, early to mid 1800s. And then they were the
you know, all the copies that ran the United States and literally lent money to the U.S.
government to keep the float. And you can imagine how I was shifting that whole thing was, they
literally called them the robber parents, you know, but then their descendants created all
these foundations. So now people go to the Ford Foundation and Carnegie Mellon University. And
you know, but those companies are 100% gone. And that cycle will repeat
inevitably. And then some of that will create space for people to make new phones and stuff.
But some of those devices, some of the devices, you know, like nobody really wants an iPhone 6
because an iPhone, you know, 12 is good enough and cheap enough and serves the need. And, you know,
the we're transitioning to like a different kind of computer in 10 years will be AI computers that
we deal with. And the question is, you know, who owns and who controls it? How do you build them?
How many companies are there? Who are the players? And it's going to be kind of wild.
I don't think it'll be many of the current big players. And some of the current funded startups
may be the ones, but some of the numbers that lead to next generation, you might not have heard
yet. So this is again, this is another one. Sorry. I'm just curious if you think this is a
fixed law of the universe, the lifespan of these companies, because it seems like bureaucracies
can survive for a very long time. I know there's some Chinese bureaucracies that last almost a
thousand years. I think it's the Chao dynasty. But it doesn't seem like necessarily the organizational
structure is dated, right? It doesn't have an expiration date as much as something else about
their inability to adapt to the needs of new customers. What is that? Is it possible?
Well, I don't know if you want to, well, like the first step is understanding also, like,
like, so business bureaucracies have self limits, because these companies become bureaucratic,
they don't respond to the market, they consume all their revenue for, you know, nonsense. And
they go bankrupt, right? So then there's these quasi businesses like utilities, which are horribly
run, or big companies like Ford and Chrysler who have such big unions and political clout
that they got bailed out by the government despite the fact that they probably should have been
bankrupt. Now, they will tell you that they paid back the loans. And I'm again, I'm not an expert,
maybe they did, maybe it was great. And but then government bureaucracies are a little funnier,
because, you know, they're not funded by their success, they're funded by taxes and oddly enough,
the worst they do, the more they spend and the more they tax. And so until it starts,
it's having such a big impact that there's some either kind of internal political
blush, or in fact, they failed so badly that, you know, they lose a war, like historically big
corrupt countries, you know, didn't end well as it were. But those cycles can be longer. And then
there's some bureaucracies, like there's some Japanese companies that are hundreds of years old.
Some of them are successful. And but some of those are family businesses where the
families escaped, you know, then the in the Western world, like family money only lasts like
two or three generations. You know, like, like, you know, the up and comer guy who made the money,
his his descendants do very well, if they keep growing the business, but at some point, they
start dividing it up. And the children are raised in luxury, and they don't try very hard. And then
some of those families, families, they go bankrupt quickly. Like is that just a cultural
difference? East, West? Well, I suspect most rich families in Asia also go bankrupt the same way
as over time. So but these ones, I'm not enough of an expert by just like, there's some famous
families in Europe that are also hundreds of years old. That's true. That's true. And
but if I remember correctly, these Japanese companies are not like big tech companies. They're
like a pub that's been run by the same family for like 1000 years. Really? Yeah, like some of them
are. Yeah. Yeah, there's I think that the oldest company in that I know of continuously independent,
I think it's Nintendo. What's that? Nintendo? Yeah, I mean, yeah, yeah, Nintendo was definitely,
it was not a handheld game company like 300 years ago. So yeah. So I think it became very famous
for that. And then 1889. What's that? Nintendo was founded in 1889. Play cards. Yeah. And was it
Nokia was a rubber company. You know, they became famous for phones. So sometimes they
transition, but you know, it's so again, to the socialist point,
like, I don't know, people work really hard when they see personal benefit and
personal goals. Like most people don't work for money. I don't know anybody that works.
Like once you're successful in high tech, you're not working for money. You're working for goals,
for interest. You know, somebody said once you have $100 million, you know, you buy a couple
houses in a ranch and a boat and a plane. And after that, like, one of the really rich people
work for money. And most of them, you know, it's sort of like the money exists, but it's more
like stewardship of an asset, right? Like people who have assets invested or they make decisions
about it. They're, you know, it's a complicated thing. And then the question when you have assets,
who should use them? And what does it even mean? Like, if you're a big shareholder in Tesla today,
what do you own? Well, you own the production capacity of employees of 100,000 people around
the world making millions of cars. And you mostly don't just spend that money because it's, if you
sell your Tesla shares to spend the money, you don't own Tesla anymore. And if you own Tesla shares,
your money is in a factory that's making cars, you know, so it's a, you know, like what does asset
ownership mean? It's a complicated thing. And, you know, generally speaking, you know, there's
producers in the world and consumers, and the consumers mostly don't produce anything.
Seems like there's a flaw in the design of these corporations because the
arm of the corporation that's invested in making money and selling stuff,
sometimes works at odds with the department that is innovating and coming up with new ideas.
A new idea is always less profitable than an old idea that you could just iterate and sell a little
bit. Yeah, I know. And so it's called creative tension, I think that's flaw. Creative tension?
Yeah, the creative tension between should you produce what's making money now,
or should you invest in something new? And, and by the way, companies go bankrupt on both rails,
so they don't make the new product and then nobody cares about them, right? You know,
blockberry, like who cares about touchscreens? That didn't work out so well. And then other
people invest in all kinds of new stuff and it doesn't work out. And you kind of look back and
you think if they just kept making comfortable shoes, they'd been fine. And so the, you know,
it's sort of like the same graph of like what percentage of humans have descendants after
10 generations? The answer is not very many. What, what percentage of corporations are successful
after 100 years, you know, essentially 1% or something. But that's because we live in a very
experimental universe. Like the number of things that can go wrong is like essentially infinite.
And the percentage of things that could go right is relatively low and often very dependent on
luck in the current state. You know, so like the iPhone five years earlier have been done. As a
matter of fact, they tried it a couple of times and the technology wasn't there. But when they
finally did it, it was pretty good. And it seems like that might be what, and there's some inverse
of that, which is that when the winds shift and you have a model that works, you're kind of screwed.
Like we were talking earlier about Google being an ad serving business. At the end of the day,
the goal is to get you to look at ads and those ads are having like their money. But with generative
AI, you can go ask the same, the same question to chat with the tea or cloud or whoever it is
that you're using. And there's no mechanism for serving you ads through that. Oh, there already
is. There is. I have friends they're doing, they're sending me screenshots of they did a search and
the search said, Oh, you might be in this article in the Atlantic or so the, the AI models are fine
tuned with their advertisers data. So no, don't worry about that. Even worse, like movies and
everything. So when you're watching a movie, even worse, even better, hard to say comes in your
perspective. So you know how the, you know, Coca Cola famously paid, you know, Marvel Studios,
all this money to put a coke can on a table. Well, that only works for a certain segment of
the audience. Like some other segment, I guess, wants to see a can of, you know, pork and beans.
So all the AI generated video will, will gain the environment to affect your perceptions.
Also, like we'll be watching different movies, essentially. Yeah, yeah, everybody will be watching
different movies. Taylor to my interests, might, might have all those fun areas she gets. Well,
tell them some, some combination of your interest and what somebody wants you to think.
Oh, it's really interesting because I'm trying to think of like Iron Man and having a can of pork
and beans on his table instead of having a can of Coca Cola. And there's just something so strange
about that. But I suppose, yeah, there's a 7.4% target market that would have loved that pork and
beans. Like, you can't be, can't be cake, Coca Cola, you know, like bias, you have to,
have to be open, the pork and beans experience.
Okay, but so I have, I have like an overarching question about where this is all going.
Yeah, I'm curious about still about the lifespan feature. Do, how much
fallout is there in the death of a company? Like in the bankruptcy phase, how is that
devastating beyond just the people who are working there? And is there anything like an end of life
plan for companies? Or is this all sort of surprising when it happens, even though it's
completely inevitable? Finder that people pull out, which is like in case of the end, do this.
Yeah, yeah, for most companies, well, like I said, the, you know, the, the truism is they went
bankrupt slowly at first, but then all at once. And, and lots of times people are very surprised.
Now, so there's the question of what, what if anything should be done about that?
So like most companies pivoted, that used to be you work for a company for 30 years and retired
and got your pension from the company, right? And that like, now that's 100% over. All your
pensions are what's called portable pensions and earned 401ks or IRAs. And so as you work there,
you, you invest, and maybe the company is, but it's a great company invests in your retirement
fund, which you own. So that's good. And then depending on, you know, dumb luck and everything
else that may or may not grow at the stock market. So that's, that's a thing. Some companies get
propped up because it's like too big to fail. Like, but then, then you have the opposite effect,
which is what like, why do we prop up big banks and financial institutions? Because it didn't
make them better companies basically taught them the valuable lesson that financial management was,
you know, for babies and, and, you know, they can get away with anything. And so those, and that's
where you get into the, you know, complex relationship between investors and companies and
governments and regulators and revolving doors between regulators and companies. And, you know,
my personal view is it would be better if companies failed more often. And, you know,
you could imagine a regulation that say the life cycle of a government organization should be more
like 30 years, because then you could go through a 10 year growth phase and a 20 year, you know,
productivity phase and then get shut down before bureaucracy takes over 100% of your output.
Because, you know, to your question was like, if you just said what percentage of our output is
wasted on our bureaucracy, and it, it, it slowly grows. And then 100 years for most companies,
it's over 100%. So the bureaucracy taxes, you know, a minimum of a percent a year. And at
certain phases that goes up faster, and then occasionally gets reset, like Microsoft was
clearly, you know, reinvented for a whole bunch of resuppos, clearly.
Is that reset possible with the governments or with an academic institution? Because these
are the real big bureaucracies today, as far as I can tell. Yeah. So universities used to be reset
all the time because they were funded by their endowments, their patrons and their students,
but now they're funded by the government. So they're, you know, so they've been
detached from the market cycle at some level. Now some, some universities, I have a couple
of friends I've been teaching for a long time, and they get cuts every year to the professors.
And while the bureaucracy continues to grow, so they used to, their budgets used to be 10%
bureaucracy, 10% facilities, and 80% professor salaries. And now it's like 40% bureaucracy
and 30% facilities and 20% percent professor overhead, professor of overhead. And, you know,
like it's amazing. They take half those grants, right? Half those government grants that
I've been trying to set for this kind of grant, they get 50%. This kind of grant, they get 60%.
And then they can, and then, yeah.
So any hope there? I mean, you imagine a reset that's possible in such a
there's, there's a whole bunch of people trying to invent something outside the current
university structure. Alternative institutions. Yeah. So, but they still have an alternative
government though. Yeah. Well, now governments have gone through a really big reset. You know,
the United States government has gone through several major resets. Like the Civil War.
Oh, so you guys are too young. So I have a friend who's very worried about the current
government situation. So when I was a kid, you know, they were, they were taking young men
at essentially gunpoint and sending them to Vietnam to kill people for, you know, no good reason.
And then the National Guard shot students on campus. And then the police department beat up
protesters at the Democratic National Convention on television. Like these things happen.
And the Democratic Party lost brutally for multiple
elections until Bill Clinton basically reinvented the Democratic Party.
A really big reset. Like it happened. But then they became bureaucratic just the way,
you know, the modern parties are basically in the same boat they were. And the Reagan
revolution was somewhat real. You know, the, you know, Nixon, Nixon got taken out for a bunch
of complicated reasons. And Ford was a loser. And, you know, like it was quite a turnover in the 60s
and 70s. And then things have to get bad enough. And then the pendulum swing. Yeah. Yeah. And
there's lots of people who study like the 20 year cycles and 60 and 80, 100 and 200.
They were clearly going through one of those cycles. Like,
like it's hard to believe like who's running for president now.
The year without an election.
Yeah. Yeah. Something that, and that's probably what people will say. And then people look back
and go, well, how did they let that happen? But when I was kid, they taught us about yellow
journalism and the robber barons and the Great Depression. And, you know,
like we went through multiple cycles, like, literally since 1850, that I was taught in detail
about. And, you know, like we're in another one of those cycles, which will be in the history books.
And there'll be, you know, the great deficit and the great election, something or other,
who knows what they'll call it. And like these cycles keep happening.
So, so the big difference, and this, this took me a while.
I was talking to my friend, because he's very anxious, you know, he's younger,
you know, 30 something. And I think everybody has that, by the way.
What's that? I think every single person listening probably has at least one friend that's
in a similar position with respect to the government situation right now.
Yeah. Yeah. So it took me a lot of like, when, when I was going through that and watching television,
I was a young person. And, but, you know, there was a threat that I could be sent to
Vietnam. And my parents were anti-war protesters. And there was literally, you know,
also civil rights activists, which is why, because my father was a Reagan Republican,
but, but it was a moral statement, not a left wing statement. And he had friends that literally
got beat by police in Philadelphia. So, like, like there was a real threat. And we didn't know how
it was going to go. Like we sat around the kitchen table, and my parents would pray
that we would live through this. Like that was my childhood. But we did.
Now it could be, now I have a, well, you can live through almost anything attitude,
which would be wrong. It was, you know, that was pretty threatening. And, you know, it was,
you know, there was like, when we were kids, we used to train for atomic fallout by
halving under the desks. I was six years old, and we're, you know, we're seeing the six-year-old
desk at the top of the desk is about this big. And we would get underneath it to protect us
from fallout, which we had no idea what that was. But there was air raid sirens and, you know,
you know, running the classroom and hide under these little tiny desks.
That was fairly, fairly daunting.
But people have lived through so many hard things. Like my mom will tell me stories of
the arc of our family in the Soviet Union. And it's just insane, right? Like Russian Jews
in 1920 that are, that are running from the Red Army that are, you know, and then like her entire
branch of the family left St. Petersburg and they went into exile in Siberia. And then they ended
up joining one of these communes and the communes, they took all your passports so you could never
leave. And so like the husband of the family was either killed or arrested. And it was this
woman with eight children, no food. She can't leave because she doesn't have any of her papers.
And she manages like her dad would tell her stories of they would gather wild hemp seeds
and squeeze them for oil. And that was the only fat that they would be able to get.
And yet they made it, right? Like my parents live in California now. And the memories of
everything that they went through have kind of faded into the background. And so I developed
this feeling about the political shifts, which is like, yeah, they happen, but life exists
on the foreground. While all of that stuff happens sort of in some ways beyond our control,
like these are systems that run. And our task is to figure out how to do something meaningful
and worthwhile, despite the fact that the background is so insane.
So this gets to the philosophical point, which is, you know, these cycles exist.
So the, you know, the Nassim Talib is like, the harder you work to keep it frozen, the worse the
end is, you know, you know, the long tail event, like in the financial world, trying to regulate
the system to avoid crashes makes the crash worse. Now, may in fact put it off. And then there's,
you know, the creative tension between, should you crash early enough and, and then deal with it
all the time, but then you have smaller ones, or should you try to build a robust financial system
that, you know, avoids that. And the same with political systems, like
United States for the most part has had a pretty dynamic political system, but
you know, the current alternative seem, you know, there's a funny phenomena, like
in a negotiation between multiple parties with the stake in the outcome, you compromise towards
the middle, but in bubbles of, you know, like-minded people, it tends to, let's say,
negotiate towards the edges, you know, I'm the most virtuous, no, I'm the most virtuous, no, you
know, and, and so that's a, that's an interesting dynamic, which also plays out organizationally,
like when, when there's a proper negotiation of the parties, something interesting happens.
But when there's a, you know, autocratic ruler makes stupid decisions, or I got to describe
this business group, they were making so much money, nobody wanted to call them on it,
but their decisions were actually killing the company as a whole.
And, you know, these, these, these systems happen at multiple, like I have a belief that
these systems play out at multiple levels. So, you know, like how family dynamics work
with a small number of people, looks a whole lot like a small team dynamics work, which looks a
whole lot like extended family dynamics work. And that's because we're humans. Now, if we weren't
humans, say we were beings with a thousand life cycle and we didn't have families and,
you know, we, we could keep track of like a thousand numbers in our head instead of seven.
Would our dynamics play out differently? I think they'd be a lot different.
But our dynamics that we live and play out the way they do because of our biological,
you know, grounding and our evolutionary process. And we co-evolved with our culture,
which gave us mental capacities for a whole bunch of things. We co-evolved with our lifespan,
which gives us, you know, let's say expectations and pretty deeply ground ideas about what to do.
And you have to understand like 10 levels of that to make any sense out of anything.
And so there's something that's really crazy that's happening right now,
which I think has been a continuous project since the invention of the first computers,
which is to create a fundamental shift in the biology of humans. Like I don't necessarily
think that the first people who sat around and were asking how to build a computer had this in
line. But I see it as this emergent step in evolution, where we had the dream of being able
to make a machine that could think. And the first generations of those machines were only able to
think in very basic ways, according to the way that we programmed them. And then progressively,
we increase the speed with which they can think the number of complex processes that they can run.
But still, you're limited by the fact that it is, you know,
garbage in, garbage out. If you don't know how to work the machine, you can't make it go.
But as we develop tools that are intelligent, and we start to gradually mount the computational
power of computers with the computational power of humans, and then we also start to
manipulate the lifespan of humans in order to extend it, what effect is that going to have?
Because it seems like it's this project that we're running full throttle into. And obviously,
you do, right? We build tools, that's what humans do. But I feel like there's something
that's fundamentally different about the tool that is the steam engine and the tool that is AI
and bioengineering combined with AI.
Yeah. Let me try to take, yeah, there's about a couple of different ideas there that I think
it's interesting to take it apart. So starting with your last one. So we made a whole bunch of
tools which didn't really, or did only slowly re-engineer our biology, but they re-engineered
our culture. So all over the world, human beings live in, you know, aboriginal humans live in tribes
of 100 to 200 adults. And that's a human constant. As best I can tell, I've read a number of books
about it. And so our ape relatives Gibbons are famously monogamous, and orangutans are solitary
territorial with some really interesting sideshows, and gorillas are a dominant male with a harem,
and chimpanzees are a dominant group of adults, you know, three to five males and three to five
females in a group of 30 to 40. They can go from a solitary animal to a pair-bonded animal to a
harem animal to 30 to 40 to 100 to 200. So that's our organic basis. But with tools, you know,
you know, and who knows which one drove it? Was it farming? Was it herding? Was it bow and arrows?
Was it whatever? We used our tools to engineer culture and society. And then essentially,
the person that could keep the biggest village together could win against the other villages.
And then at some point, that also caused, let's say, a massive escalation or political abilities,
because if you want to trade with that village and get rich or go to war with them and get killed,
like there's, you know, so our tools, what we co-evolve with our tools and our culture, right?
And some cultures are way more effective than other ones that are making new tools. And but,
you know, that's also a very chaotic function. And so we're making new tools, which is going to
cause some additional cultural change. And it's already doing it in some of that good ways and
bad ways. Like the internet is full of people speculating about it. But, you know, we've gone
through a lot of evolution. Now, in computing, computers don't think, right? And there's a
funny thing. So the first computers, you know, executed sets of statements, which, you know,
you could do with a pencil and paper is just, you know, when they do a billion instructions a
second, it's a little faster than, you know, one a second. But that's a matter of quantity, right?
And then, like, so the statement kind of computer, and then we went into, you know,
there was the big data revolution and analysis, where you could run so many programs that cost
data, you could find signal where nobody could. And it's almost like we got into pattern recognition.
So you went from executing statements to something that seemed to do something different,
like pattern recognition. And then the early AI programs, you know, like the famous Alexnet,
which could recognize a cat in a photo. Like that's kind of a wild thing. But,
and it was way better than what's called classic vision, which attempted to find cats by correlation.
They would say a cat is a collection of pointy ears and round eyes and fuzzy hair,
and cute smile or something. And then you could have a database of when you see these parameters,
these features with these ratios, it's a cat versus these features, it's a dog versus,
you know, the problem is or something. So, so that, you know, the statements to, you know,
like analysis, and then recognition. And then the language model,
you know, people are very puzzled by this because they're sort of stupidly good at chit chat.
And summarizing things and predicting the next word. And they do something that seems almost
amazing. Like you can think of having multiple equations like, you know, x plus y plus 3z equals
five and two x plus seven y plus z squared equals seven. So those are equations. And then you can
do algebraic processes that to do something with, but you can't add the word cat and dog.
Like cat plus dog doesn't mean anything. Does that make sense? But you can translate
cat and dog into a space where you could add them up.
Right. And then you could query a statement against the words. And it turns out with enough
computation, you can create really called embedding. And then there's all kinds of transformations
you do on that data, where you essentially you've turned ideas into mathematical things. And I know
they're mathematical, but I can actually look inside the computer chip and look at the register
that has the bits in it that I'm adding. But there's no magic in AI computers.
They're just numbers being added up. But like the representation of the word cat and dog isn't
a very good representation for manipulation, let's say. So some modern computers, we can do
something really interesting, which is with a set of words, predict the next good word.
Or with two sets of ideas, put them together and then summarize that. It's kind of amazing.
And it seems relatively intelligent. Because in fact, the current state of play is
it's ability to write, summarize, analyze and talk to you is better than the average person.
But it's not clear it's thinking.
Yeah, I was going to say, how do you define intelligence and thought?
Yeah. So you know the joke, every time intelligence can do something, it stops being AI.
So like, surely it's AI when you can play chess. But then we wrote a program that clearly wasn't
intelligent play chess, but go. That's so hard. You have to be intelligent. No, that was just a
program to like to recognize generally any object in a picture, you must be intelligent.
No, that was easy. That happened 10 years ago. Right. To complete this sentence, that must be
intelligence. Nope. The turning test. I talked to you for 10 minutes and I can't tell it's
not a person. That's been passed. The bar exam. That must be artificial intelligence.
Now that was easy. Like so. So we don't, so what's happening is intelligence is being defined by
what it is, which is crazy. Right. And then today people say, well, the AI models are no smarter
than the input that they we've had it. Well, human beings aren't data and intelligence.
Like Christ, the average person barely gets 100 megabytes of data. And by the time they can talk
and do smart things, like work where I would call computational intelligence. So, and that
that means some of it's trained in a way that like builds these simple spaces and representational
things. But then we can experiment experimental, right? That's yeah, yeah, we can do variations on
that and combine them over and over. But it turns out the variations that are being done,
large magical, their variations in the representational space now turns out those
representational spaces have infinite variation possibilities or very large variation possibilities.
And we do a funny thing where we're very good at making small variations and then filtering
for some sensibility and then combining filters of those variations for something bigger. And
depending on how smart we are and what we learned and what, you know, let's say sense, you know,
make sense of the constructs we have, you could be more or less successful at this.
Like, have you ever watched like Richard Feynman lectures on math?
Like, you're super fun because he goes, well, this is obvious, this is obvious. And he's just
hopping across the the trail like 100 yards at a time because his ability to produce variations
were really good. And his ability to make sense out of the possibilities were amazing and really
well embedded in thinking. Right. And I go, well, I can spend an hour on each one of those,
you know, cognitive beliefs he made, but I can do the same thing that appears.
I can describe how come what's that?
I'm trying to separate out what humans do that's different than these artificial
intelligence programs. And it seems like something about our ability to compound
abstractions into new layers of abstraction that I'm not sure that computers are pulling off.
I actually think they're pretty good at that side. The programs are written yet to do the
variation. That's not just noise. So if you just do noise, like, like there's, I think the problem,
the crack is how to do variations that are interesting without just being noise. And I
don't have a good idea. Like chat GPT is, I don't know, I've been chit chatting with it about, you
know, physics and stuff. It's interesting how it puts it together. And then you can see places
where it just falls flat and other things is like, well, that's kind of interesting.
It's synthesis is me, I would say medium. So to pass the bar, because that's mostly factual
associations, they can play all the games. Those are mostly role based kind of things.
And you can see somewhere it starts to fall apart on idea synthesis. But it's not, it's not sitting
there cranking 24 seven doing variations. Like when you think about something hard,
like you guys are working on your physics problem, that's partly running as a background
program in your mind for what a year, two years, some of the years.
And well, 10 years, all right, so you have 10 years of background processing
with a pretty well refined sense of what makes sense. And which may in fact be your biggest
problem, you may be filtering out all the best ideas. Right? That's a, that's a real problem
for smart people. So it's kind of complicated. So I don't, I think the synthesis is getting
better pretty fast. And people keep saying, we see at the current level, it's terrible,
they'll never get better. And I think, well, compared to a year ago, it's unbelievable.
Like we're on some pretty steep curves here. But this, and then this mixture of experts thing
matches my personal model of, like there's a workspace, and many, many agents that we apply
to it. And then we have many tools of variation and combination or when we think, and they're
starting to build that platform of multiple experts and a common workspace. And then the
the ability to make variations and then test the variations for say some useful just before we
waste too much time thinking about it. Like you don't spend very much time thinking, well, what
if I could just invert gravity? Like that's not worth the years worth of thinking, it's worth
like a half a second worth of thinking. But what if there's a different way to look at, you know,
these field equations, and you're, you're good at a bunch of mathematics, then you can test
pretty fast those things. Now the problem is there might be five more variations of field
equations that you don't know. So one of those might have been good. So you have a filtering
problem. So you may have in fact had a good idea that you filtered it out, because you
didn't have an analysis, a good enough thing. Like I had a friend who's better at me than a
computer designer smarter, but I was more creative. He felt he he would run into a
problem's idea, put it down, and I would kind of go, well, this is pretty good, but it's got
these three problems. And then this is pretty good, but it's got these two problems. And then
this is pretty good, but it's got this problem. And then one day I would go, if I take this and
this and this and put it together, and I got something that works, and I would tell them,
and he would go, how do you stick that out? And I explained it to him, he says,
but we rejected all this ideas. And I said, you stop thinking about it.
And I didn't stop thinking about them.
That's the layer on the AI that I don't see yet, which is the ability to take
disparate concepts and smash them together in a way that's unlikely, but productive.
I just explained the whole program, we can write that in 10 minutes.
That program wasn't hard to write. And I'm not even going to write as the AI programs
go to write it. I think the sensibility filters are a bigger problem than the
combination of things that is pretty good. Synthesis is medium.
But we just started breaking that into problems.
Yeah, so I'm fairly, well, I don't think thinking is magical. I don't think it's quantum.
I think it's like we already built computers with more operations in a second.
They're like, biology is insanely efficient for computation compared to transistors.
But there's reasons for that. And I think we'll solve that problem, by the way.
Like, where do you think thoughts come from? Like, where do you have a thought?
You're like, oh, I thought I just thought of something.
Where does that come from inside of the human architecture?
Oh, we're, you know, like the base of, you know, what we think of thinking is, you know,
advanced planning systems. Well, I think so your brain grew in a bunch of layers,
like, you know, in a sensory cortex and a motor cortex. And, you know, we sense both the
external world and ourselves. At some point, you know, low level animals got good at that.
And then they started moving around. And then they started doing basic planning, which is,
you know, run towards food and run away from teas and, you know, all kinds of things.
And then we've been elaborating planning more and more and more. So when you're just sitting
there doing nothing, the various parts of your brain will be like sort of newling on what should
I do? What should I think? How should I get ahead? And it turns out we've elaborated that so far.
We can think, how do I plan ahead in mathematics? How do I plan ahead in art? How do I plan ahead
in engineering? How do I plan ahead in four dimensional political chaff? How do I plan ahead?
Like, we're really good at it. Just very strange how thoughts come at the most unlikely time. We
know you talk to people who have been had inventions or brilliant mathematical physicists,
and they'll just mention these strange occasions. You know, I was having dinner with my wife talking
about the opera, or I was in the shower. It seems to be a very common feature that people
think. Yeah, so yeah, as a computer architect, I don't think that's odd at all. So the voice in
your head is a postdoc narrative. This part of your planning review system. And your actual
thinking is in many, many, many layers of computation. And not very many of those are visible to you.
All right, so some of those layers are computing and being rejected and computing and being rejected
when you don't even know it. I have the sense I can feel myself thinking sometimes and I can't
access. And then sometimes that kind of breaks through to higher level things where you start
to label it like I'm having these thoughts and they have labels which are words which I can say,
or enough of it, go somewhere and then you can kind of go tell the story about your thinking.
Just the feeling of thinking before you said that sometimes you have the feeling that you're
thinking that you can't access. What does that feel like? There was a really good book about
this which they did a whole bunch of experiments which showed that your verbal thoughts are a half
second behind your actions, which at the time shook me up. And then I thought, well, of course,
that's how it always feels. And then there's advice I've given people which is if you want to
solve some hard problem, you have to spend a lot of time and effort putting the problem in your head.
And I also noticed as a college student, I was relatively bad at learning things quickly and
getting an A on the test. And I had some friends that did that. Like if I took an engineering
class, I started studying day one and I did all the problems. And I mostly didn't study for the
last week of the course before finals because I found it was better for me to stew on what I knew
than to inject some new thoughts so it would screw it all up. I've always been that kind of person
and I trust the thinking. But yeah, it's strange when you're thinking hard about something that
it's kind of boiling around. But again, so my model of it is there's many layers of it.
Might not be true, I couldn't tell you, I haven't put any probes in. And that much of your thinking
and computation isn't visible to what you think of your current working set of thoughts.
And so the fact that occasionally things work out and get signal to some simpler level of thinking,
and then you're surprised by it isn't surprising to me, I think that's obvious.
But I had a friend who was very freaked out about the fact that he could never figure out
where his good ideas came from. He literally dropped out of college for a year because he never
knew like halfway through a course if he was going to get it. He just felt really anxious
about it all the time and it's like, well, what did you do about it? Basically nothing. He said,
I just live with it. And I was like, well, you could spend more time meditating on that. Like,
I think you can have some more access to it. But you could also say that's part of our architecture.
I think that he was just freaked out that it would fail him at some point if he didn't understand.
I don't know where it comes from. So I don't know why it will happen again tomorrow.
Interesting. Yeah, it's a funny thing, but I'm not surprised about it because, well, like,
if you go look in neural networks, like, when they first started doing like the cat
recognizers, they would see as you went through these layers of convolution,
that, you know, you went from an image to components of an image. And then, you know,
essentially you would have a layer which would do size and variance and orientation and variance
and then associations of different things. And sometimes in layers, you could see what it was
doing. And sometimes in layers, you couldn't. So they would pull the layer out and say, well,
if I don't know what it is, what's it doing there, they pull it out and it wouldn't work anymore.
And that's probably because that was some computed association map that had no relevance to what you
think. Like, and there's also a thing called overfitting, which is kind of funny, where you can
train a network so good it can only recognize what you trained it with, right? Or there's another
when you have way more, say, parameters in the network and enough layers, you can
compute the associations in a way that they're not overfit, so it can recognize essentially
more than you've trained it with, which is not mathematically right description, but
like, that's how it feels. And then I think humans have very deep layers, because we do,
you can see them in your brain, like cortical columns or six layers of neuron stick with a
spectacular number of connections. And then the cortical columns talk to each other, and then
they fire each other, and then they run many, many times. And when you're thinking hard for 10 years,
like, the number of passes through your brain is unbelievable. And your brain is even coordinating
those passes, it's not your whole brain, you're doing all kinds of different things.
They send a beginning of this that computers don't think.
Yeah, so the computers we have today, so the AI we have today is not what I would call thinking.
But it's always to build one that does.
But yeah, it's going to happen pretty soon.
Oh, so I mean, it's like, yeah, they don't think, yeah.
What's that distinction look like?
Well, it's, you know, it's like the read, the endlessly redefined scoring test.
Yeah.
So Elon's version of his couldn't solve a novel physics problem was the high end of human thinking
is solving hard novel problems. And I think that's the differentiated from,
you know, producing lots of word salad. Like, like this is a interesting thing.
I have a friend who's a writer, and I threatened him with writing all his possible books and
copyrighting them before he was, he wrote them because he's a very good writer, but he has a style.
And, you know, and, and if he told me that 20 ideas of the book, we could, we can generate
much of the writing. Now, obviously, a really good book has a, as a mental journey to it that
solves some problem, like some, you know, your, like some people are interested in, you know,
like trip reports and, and, you know, travel dialogues and whatnot, which are predicted,
right? If you go to Thailand and then degrees and then Iceland, and you look around, you will see
things and you can literally take a camera and point it at those places and then give that chat
GPT, which would write you a nice travel book about what happened. Like that's not intelligence.
That's a scriby. Right. But if you went there and the cultural cons, you know, cultural differences
between Thailand and Greece, maybe you understand something new about humanity, that could be a
really interesting book because that's a novel idea. And today chat GPT wouldn't write that book,
but you might. Right. But at some point that GPT will write that book.
So with the, the solving the novel problem, wasn't Alpha fold solving a novel problem?
Right. If they basically figured out a way using AI to solve the protein folding problem,
which had, yeah, so this is a really good boundary. So that's still a computational problem.
Now, I don't, maybe human culture is a computational problem.
Yeah. So there was something.
So I talked to these guys that just, just cracked me up. So when you do finite element analysis
on an airplane, imagine have an airplane and you're blowing wind across and then the wind
is turbulent, of course, the air is turbulent. And then there's, there's both an analysis of
structure, of temperature, different nations. There's a whole bunch of really interesting
things. And so it turns out they have reasonable finite element analysis programs written in
Fortran, which is a little rusty. And, and they're computationally limited to analyze, you know,
airflow over planes and structural failure, all kinds of stuff. So then they were trained,
they were using the Fortran programs to train AI models. And now at one level,
if you want to analyze one element, you know, and it's a billion operations of elements,
you know, that's a lot. And to run the, that program on a variety of elements to train an AI
model that turns around and for the AI steps to do anything, it's a, you know, it's a, it's a
million trillion operations, which is a lot more than a billion. But here's the amazing thing is
when they train multiple very large AI models with these Fortran programs, the AI models are
really good at analyzing things and ignoring the things that don't matter and sending more
computation on things that did. And they analyze the whole airplane, it was less total computational
steps than the finite element analysis, which couldn't differentiate any element. They all
look the same. The Fortran program doesn't care that AI model had a deeper level of analysis.
Which could do something to look at the whole plane. Yeah. Yeah, well,
yeah, it did something interesting. I don't know exactly what it did. But people are using programs
to train AI models and then getting better results. Because the AI models wouldn't analyze it
as sort of this log, rhythmic, or maybe linear computational bed burden for scale,
whereas the finite elements just have some kind of exponential burden for scale. So the protein
folding thing is really interesting. It says, we're like really small atoms, they probably have
programs that can do stuff, but they scale it up and computationally explodes. And the AI models
probably don't computationally explode. So when the AI start thinking, do we have an ethical
issue on our hands? Like, are they alive essentially at that point? Do they have self-awareness?
Is that our real life? Yeah, I think you already have that problem. So this will make you think
about what thinking is. So AI is clearly making everybody think about what thinking is. Because
we've had 10 definitions of thinking, they all fell apart. Because as soon as AI did it, everybody
declared it's not thinking. Because it's obviously not thinking. And now we have ethics built around
the sanctity of the human life, which has the narrow definition of embodiment in a person
between two and eight feet tall and 500 pounds. So we have this definitional state in a person.
And we've mostly given most of those people at various points in time some kind of ethical standing.
So not what happens when we enable a trillion AIs who are smarter than us. Do they have ethical
standing? Do we have ethical standing in their mind? I don't know. It makes
conclude that we're paperclips or something. It's a curious phenomena.
This leads back to the question that...
I'm just curious how we can rush towards something like that before we figure out the answer to
that problem. Are you familiar with Ian Banks, the sci-fi writer? Yeah, that was one of his.
I think he's a pretty good writer because he imagined the universe where there was
a wide range from robots that were obviously not very smart to humans,
including some very smart humans to AIs which were human level intelligence to extremely past
that. And he created a world where it was sort of all interesting.
So 99.9% already live in that world.
You guys are pretty smart. You're already enough smarter than most people that
you're unintelligible to them when you actually talk seriously. 99% of people already live in
the world where they're not very smart. It's already a fact. We already live in the world
where there are cats and dogs and ants and mosquitoes and birds and trees and all kinds
of things and nobody wakes up in the morning trying to stomp out all the cats. It's not a thing.
And anything any smarter than us is seriously not resource bound. This thing where the robots
destroy their Earth because they need energy or something is just whack. The Sun is putting
not so much energy. It's unbelievable that energy and the material around us is startling.
Like our local consumption of energy is 0.0000001% of the available energy.
So this part doesn't necessarily guarantee that your ideas will take off either, right?
There's this whole marketing charisma element to having your idea. It's to be a kind of a
beloved person, at least in the realm of scientific ideas that we play in. It's like,
you can have a great idea, but that's just the start of your battle.
I actually think that it's... What's the battle? Like humans are very conflict-oriented. So we
have all these interesting priors. One of our biggest problems is humans for a million years
of evolution, whatever you believe, are essentially zero-sum game because it was a zero-sum game.
Like if you eat all the local deer and stuff, there aren't any deer.
But now we can produce an unlimited amount of food with energy,
probably, and there's an unlimited amount of energy. So we don't live in a zero-sum world.
Only by political... Yeah, yeah. There's only a couple kinds of shortages. There's something that's
in fact rare, and then there's another kind of shortage, which is it's new and they haven't made
enough for it. They're too expensive for everybody, but that's usually a transient.
And then there's shortages due to monopolies and there's shortages due to, let's say,
refreshing of production, right? And there's literally nothing rare. Like we can't run out
of aluminum because aluminum is a metal. Like you use it and you melt it down. Like there's no
shortage. I always love these things. They won't have enough copper to make the solar cells.
Oh, there's so much copper in there. It's very expensive at some point, right? It ends up in
landfills and you've got to process it. No, there's so much in the top 100 kilometers of the earth.
It's not funny. Oh, here's a funny story. It's like, so computers are made out of essentially
three atoms. Oxygen, silicon, aluminum, a little bit of copper. Some gold in there as well, right?
Yeah, it's really trace. So they use like 32 elements as trace elements, but you know, by bulk,
it's so it's by bulk, it's silicon and oxygen. So 70% of the earth's thrust down like 100 miles
is silicon, oxygen and aluminum, which looks like a setup to me, like
like carbon and hydrogen, like these are all trace elements. There's a lot of carbon and
hydrogen, but the big hitters are, for whatever reason, is silicon dioxide and aluminum oxides
and, you know, all kinds of iron. But iron, like the percentage of it goes up as you go further down
on the earth because of the, you know, melting or something. But there's like so much of everything
that's not funny. Like they did, there's a couple of processes. Just look up by weight how much like
copper and magnesium titanium is in like the ocean. Like there's really good processes they're
developing to like just in sea water. Yeah, just sea water. So there's a lot. I don't miss it. I
think that the idea that AI are going to show up and they're going to destroy the humans and
the paperclip maximizer means are, I think that they're deeply informed by dystopian science fiction.
And my
greater worry is that they'll will become stuck at some computed optimum.
And what I mean by that is if you have an, if you have a super intelligence and the super
intelligence is like, this is what should be done in this circumstance. And it has the ability
to inform what you do at every circumstance. That's kind of the ultimate centrally planned
economy in some ways. The most centrally planned culture.
Well, let's, well, I like Elon Musk's line about very important to train these things about the
truth. And you know, one of the truths are there's endless cycles and there's endless chaos and
chaos is very important to development as is randomization and maximizing the alternative frames.
Like, so I think that's true personally. But, you know, I think, and, and I have a theory that
like thinking and ideas are essentially infinite. I'm not sure why there's a limit to it. And so
if it was smart at all, you know, my, you know, my, my guess, my preference maybe or my hope
is that, you know, it goes in some interesting direction of more, more variation, more possibilities,
more explorations. And then you said, like, like humans, because of our biological grounding and
our competitive, like humans are hyper competitive, even when the act like they're not that's just a
good competitive strategy. Like you, you're both very nice. That's a winning strategy with a lot
of people who are going to make friends that way. Like, but, but we're hype no matter what we're
hyper competitive. We have a built in zero sum game, we're very oriented towards the world about
whether it's like one of the basis of company cycles of is it uncertain that enables
exploratory behaviors and growing that enables us to participate in growth? Is it steady state?
And then we start reacting with steady state means we're going to run out, by the way,
like, then you start exploiting what you have and trying to get your share.
And then there's inevitable collapse. And then, you know, we reset. And so, so we're very aware of
those states. And so AI that triggers fears of competition and running out in scarcity is very
different from technology. So like when technology has been a lot of fun, it's when this is like
the iPhone created a new possibility, the internet's a new possibility. You know, the thing I'm not
super happy about AI right now is, you know, only large companies heavily funded,
you know, big guys are doing it. And they're, they're using the language of establishment and
scarcity, which triggers people to fear it. As opposed to the language of the PC, the iPhone,
like some of those technology literally came out of small growing companies.
And they had the energy of growth, which stimulated the people around them to think,
by the way, I just, this just occurred to me. So it's not something I was doing on.
But anyway, it seems kind of obvious that
like if the environment says, Hey, there's only so much of stuff and we might run out,
which is the endless drama about resources, we're going to run out of resources.
You guys somewhere in you believe we're going to run out of copper or something.
I can prove to you that we won't run out of copper or aluminum or silicon dioxide.
It's literally what the planets made out of like, we can't run out of materials to make chips.
Right. It's actually suspicious how much computer technology is embedded in the near part of the
earth. Like I have a theory that this is the earth is the remnants of the previous supercomputer that
was, you know, somehow, in some sense for a planet like this, too. I often just think about us being
of the earth and just some sort of organ that the earth has produced. Yeah, there's just enough
carbon, carbon to give the book program is biologically, but the computational substrate
is silicon dioxide. So like, and there's a bunch of reasons like carbon is super good low temperature
chemistry and carbon chains and all kinds of stuff are silicon saster. It's 300 degrees C,
you know, get a melted 1000 degrees C. It's it's really sticky. You put an atom on a silicon
atom. It's stuck there. It's, you know, you can only manipulate the high enough temperatures
that you really don't want to. Whereas like carbon is fantastic, low temperature, relatively low
vibrational mode, you know, you know, chemistry is super good. But anyway, that idea about the
competition and the scarcity. Yeah, so so the the the the advertising guys would like you to think
there isn't enough to stop so FOMO and it's valuable. Like you may charge more about convincing
people there aren't very many of them and you have the good one. So the current, you know,
marketing and the consumer capitalism is all scarcity, you know, demonizing, like just scaring
the shit out of people. We're going to run out of oil. That's crazy. There's lots of oil. We're
going to run out of oxygen. We're going to run out of food. We're going to run out of carbon or
aluminum. Jesus Christ, like, there's 7% aluminum or something. We can't run out of aluminum.
But that puts you in the mindset of fear and running out. And so the technologies that were
exciting, when film first came out and airplanes came out, there was 40 airplane companies,
maybe 100 and cars, there was 100 car companies and PCs used to go there and there'd be 50 guys
making PCs, right? So today, the big AI is coming out, Nvidia makes the chip and Microsoft
open AI and Google make the AI models. And it's a there's a scarcity mindset to it and
unobtainium something to it, which is not good for technology and good for people. We're not
running out of air. We're not running out of aluminum. We're not running out of compute. We're
not running out of like we should be in a growth mindset. And humans are very fun to be with when
you're in a growth mindset. And we're very boring and let's say not great to be with when you're
in a scarcity mindset. Scarcity mindset means if you eat that apple, I don't get an apple and I'm
going to fight you for it. Gross mindset of there's so many apples that are falling from the trees
and we're planning different kinds of trees and you talk to friends and they've invented four
kinds of apple trees last week and you know, you can't wait to see what the next apple is,
you know, that that's that would be fantastic world to be in.
And what freaks people out about AI beyond just the scarcity is something that you mentioned
earlier, which is that you had product placements back in the day where everything was all the
Marvel movies had Coca-Cola cans and now you're going to have Marvel movies that have a unique
product based on all of the data that they've collected off of you off your cell phone or
whatever else. And that fractures reality just a little bit. And then you have all of these
subsequent fractures of reality where that shares if a shared reality is a limited commodity all of
the sudden, that's kind of the fundamental. That's the scariest thing at all, where you can go talk
to somebody across the street and they no longer live in the same universe as you because they have
consumed video and media that has nothing to do with what you've seen. And so that scarcity on the
back of AI is kind of baked into the way that the tools are going to be used because I can imagine
more AI startups. If the chip isn't $25,000
and you have people that are interested in building stuff on the back of it, then
it seems plausible that you could get that kind of ecosystem. But that ecosystem seems to feed
into a scarcity of shared reality. And that's really interesting.
Yeah. So, I mean, this cycle has happened, you know, with newspapers, with movies, with television,
with the internet, where when it's in the growth mindset, lots of people participate,
we develop a sense of trust with it. Like I remember when television broke thrust
in the 60s because they were lying about the war and lying about the peace march.
And then in the 70s, there was lots of cynical TV shows. And so that,
and I know that got gained as well, but there was kind of an era of cynicism about
something that had been trusted. Walter Conkret was the news. The New York Times was the news.
And these are institutions you can trust. And Walter Conkret died. And I don't think anybody
believes the New York Times anymore. Well, you know, some writers, yeah, so that, but here's the
thing is that healthy human beings form relationships with things and evaluate them with should they
trust them, right? And then periodically, like sometimes it's individuals stop trusting this.
Like, I don't know if I mentioned this, scientific American, like I used to read it a lot, but I
noticed the computer articles were lousy. But I thought it was just a computer articles. But
then I talked to a friend who was a mathematician and he said the math articles were lousy. And
then he called up a friend who was a chemist. He said, no, the chemistry. Oh, well, so shit.
You know, I thought this was trustworthy because now it's, it continued to be fun because the
scientific American was essentially entertainment at that point. But it wasn't, it wasn't a trusted
source as it were. Now, whether they know they're a trusted source, you're not idle.
Like these are complicated things. And then trusted at what level and to what impact to you.
So like, like the Marvel movies were a really interesting thing because the original stories
were really well grounded stories, like they were good archetypal stories. But then as they tried
to elaborate it and the bean counters took over, they started just making a whole bunch of blah,
blah, blah, you know, including whatever message of the week they were into. And then nobody
watches them. They're boring and repetitive. And so there's that kind of thing happens in like
the same thing happened on the internet. You know, like there was everybody was there,
there's all these forums and people talking and then they got into better technology,
but then they got curated and you know, most people don't believe that much about that.
But it's, but the relentless in this office is interesting. And I think the same thing will
happen with AI, like, like people get gained by it. But at the same point, people start to go,
let's say I generated, it's probably, you know, there's marginal utility in it. And then
there's been many attempts to have curated news and internet to media, like the internet you
can trust, but it's really hard because soon as they make any money, they got bought by somebody
doesn't feel that way. And so it's, it's pretty complicated, but most humans grow up in this world.
And then humans, humans sort their lives out depending on what they need to do.
You know, people who are trying to do geopolitical operations need to have
a way difference filter for, you know, let's say, you know, shenanigans and somebody who's running
a, you know, simple store and technologists is the same way. So
I think that there's something in there about an eternal
untrustworthiness that's been with us for a long time. Because if you go back to a model where
we're all just 100 person tribes, it's not like the tribes are living in harmony. There's probably
warfare. There's conflict. And the leader of your tribe might be telling you things about the other
tribe that aren't true, but are functional and necessary in order for you to be willing to go
on a raid or that. And so I think that we've, sometimes I think about this in the sense that
we've loaned ourselves into a false belief that there is something outside of our direct experience
with people that can be trusted, because we want so badly for that to be the case. Because if you
think about your own personal relationships, the people that you have relationships with
that are closest to the ones that you can trust them, right? If you have somebody that you look
at and you're like, well, I can't trust you, you're probably not going to be very good friends with
that person. And so we want to be able to generalize that outwards to systems. But then as you're
speaking, I'm sort of thinking maybe that's a false, maybe that's been an eternal false hope
where even Walter Cronkite, like he, he was the news, but the CIA had tons of people at all
these news organizations. Yeah, yeah, he was just reading the paper. So here's another way to think
about it is, you know, when, when you start to go into a scarcity system, the, the, you know,
everybody you deal with, you know, has some cost benefit with, you know, if they lie to you and
you catch them, that's a cost to them. But, and if the benefit, the line is really low,
they're probably not going to. So in a, again, in this frame of in a growth mindset,
where there's lots to do, the benefit of lying is relatively low because you can,
you can get what you need. But if you're convinced that, you know, things are tough,
the company has layoffs coming, you know, a company that's growing 10% a year,
it's pretty healthy. People generally help each other to get the job done.
There's an interesting book called stretch, which says if, if you have about 10% more to do than
you can, you stretch and if somebody offers to help you, you accept it, you appreciate it, right?
If it's 50% more, you get burnout because you can't achieve your goals.
If you have 10% less than you need to do and somebody offers to help you say, stay off my tariff.
Because if they do your work and there's a cut coming, the boss is going to go,
well, Jim only ever does 80% and, you know, Bob over here picked up the slack. And so
the stretch of the organization sets the trust level. It's almost sad how simple it is,
but it's actually true. Once you weed out them, the various characters, if your organization
stretch, they are incented to cooperate. And if, and if there's not enough to do and there's cuts
coming, they're incented to undermine each other. It's the same thing with product placement and
stuff. Like, you know, Coke is a weird thing because it's like a zero value product because,
you know, zero to make. It's entirely, you know, manufactured and sold on brand.
Nobody really cares what it tastes like. I don't think so. I sure don't.
But the brand has established something and humans have, you know, habits and stuff. So they
have a positive association with the brand, the image, the consumption, there's a flywheel of
that kind of thing. So I think, yeah, he's generically afraid of AI. Like, it's not helpful
because he can't solve any problem by being worried about it. Having some understanding of how
technology impacts society, how we use it to change our culture, what stage we're in is really
interesting. And then what's going on with the players? Like, because I think that's,
that's helpful. And then there's the, you know, the odds that humans with this technology aren't
going to develop intelligence is zero. Right? Like, we're either going to keep going up or,
you know, like, like, we're very dynamic, you know, we accumulate knowledge like mad,
there's eight billion of us. We're not super good with, you know, low stress environments,
humans do really well with some stress and some restrictions and stretch, I think,
the companies, you know, with real missions, you know, do real well because people work together
to solve the mission. And, you know, it's a very curious time because we're developing something
very new in a time when many, many people were think we're in a zero thumb game and possibly
going down, but, and the advertising to that effect is relentless.
You know, we're running out of like literally everything. Now, there are certain things that
are getting worse, like our ability to build roads, that's bureaucratically captured this poor
following the building to build airplanes, they laid off all the engineers apparently,
and it's run by, you know, the accountants like those things actually have.
So airplanes got unbelievably reliable. And then people took it for granted and then,
you know, but that just means it had something to do with their growth, too, because there's
a merger with the fellow Douglas and they laid off all these QA people. And yeah, yeah, it's
quite the shenanigans. They financial engineered it. Yeah, it's, you know, that's the kind of thing
it was like, if I had a magic wand, I wouldn't allow mergers of large companies because it'd be
better for them to grow or fail by themselves and create more small companies because I think more
small things is better than small numbers of large things. But I don't have that magic wand and
big companies lobby heavily a lot of those mergers because that's how they make money.
Like a lot of big companies essentially never have any new ideas. They just keep buying small
companies with ideas. You know, like Google, for example, has bought a large number of companies,
but there are only two money making assets are basically search and YouTube. And they
bought YouTube. Facebook famously did better. So they bought WhatsApp and Snapchat. I always
forget the list of them, but they bought a relative. They bought companies that actually had real
growth and value and continued to grow them. But it's not clear the world would have been better
off of those companies have been separate companies. And it does seem to be this tendency
towards agglomeration. Like there is, there doesn't appear to be an upper level of size,
like there is for something like a cell, right? Well, yeah, yeah, that's pretty funny. Well,
yeah, the cell, like in a company, essentially the cell is a small team of 10 to 20 people.
So all big companies like are made of cells, right? And so, yeah, but one company can acquire
another whole animal and then merge the cells together. And, you know, they'll do it for
some reason about synergy or efficiency or something. But it may in fact, because they
don't have any new products. So they have a lot of money, but they don't have any new products.
So some companies like, like big pharmaceutical companies, they invest piles of money in R&D,
but almost all their new products come from acquisitions. So
I wonder if there's the same sort of cycle like there is with the megalodons, right? So there's
megafauna. There's a period on earth where megafauna dominate, and then the conditions change,
and then all of a sudden, they're no longer the dominant biological paradigm. Do you think that
the same thing happens inside of corporate structures where there's just an era of huge
companies, and then the winds shift, and then it goes back towards smaller companies?
No, I think things just tend to get bigger. So when I was a kid, I was taught that
animals are really big either because it's really hot or because it's really cold.
You know, mammoths are big at the poles because it's cold, and dinosaurs are big because it was
hot. And I thought, actually, they probably just get bigger. And then something happens,
like a big rock falls on the earth and resets it, and then it kills all the big animals because
the infrastructure for big animals is really complicated. So my guess is companies just get
bigger, and then they occasionally fail hard. You know, some companies have actually failed
and gone bankrupt after they've been big. And some companies, especially with the
way government bureaucracies and companies work, they can continue to acquire companies.
But there will be some financial reset. Like during the PC boom, all the companies involved were
small. Like IBM messed around with Windows and PCs, but they gave the operating system to Microsoft,
and they had their own chip, but they decided to buy the chip from Intel. Both of those companies
were small. And then Dell and Gateway, all these companies were all small. And they were all actually
too small for the big guys to even care about. But then they grew so fast, you know, they avoided
getting acquired. Like that's an interesting phenomena that they grew. Whereas once, you know,
Google and Facebook and some other companies got big, they had grown so fast that they grew fast
enough not to be acquired. And Zuckerberg famously turned down a billion dollars for his toy startup.
But but then they turned around and they bought a lot of the small companies.
Well, we can business model at some point, I knew lots of people that were starting startups
exclusively with the goal of getting a profit Google. Yeah, like the network thing happened
the same way. There was like hundreds of small networking companies and the big ones got a
certain point. And then Cisco's business model was literally acquiring successful startups and
ramping their revenue. And sometimes that was real, like a small company couldn't build a
billion dollars worth of network switches. But Cisco could, they had the supply chain and
manufacturing and operations to do it. So sometimes the action creates value like Cisco,
like I think often did, but sometimes they just,
yeah, it's, it's hard to say. It makes somebody use some money. Hardware might be different than
software. Well, so there was a long time when hardware wasn't like that. There was in fact,
you know, 50 or 100 airplane companies and miles of motor companies. And then the big
companies in the US, they outsourced. There was a period of time when Ford made everything and
they slowly outsourced the seats and the transmissions and the tires and the shock absorbers
and all kinds of stuff. And so there's a, there's a pendulum swing they call vertical to horizontal
integration. Like you make everything in the stack or do you make your piece like PC world was
what's called horizontal structure. So Microsoft made the operating system until made the chip,
Dell made the computer, somebody else distributed the thing or somebody else made the network.
But now Apple is a vertically integrated company. They make every single thing.
So you said that one of the things that you would do if you could waive a wand was to prevent
large companies from buying little ones. What are the other things that you would do?
I'll govern the arc receipts that have time limits.
You know, obviously, you know, our represent representative should have time limits or
term limits. Like, imagine you wanted the most independent experiments happening
so that none of them that they failed would take out lots of people.
Like we have a, you know, the, you know, the, the, the NIMBY problem, right? So,
so people want to build new houses and they can't come to regulation. So they go somewhere and
start a town or some town allocates a whole bunch of land, which great. So they can build houses
and new roads and the new school, the new shopping center. And as everybody moves in,
they all join the town council and they pass regulations so they can't build any more houses.
Right. So like this, and again, this is, this is, this is biological. Like,
like we operate from zero sum games and limits to growth and in competitive nature.
So if you want to architect a world that creates, keeps creating possibility. And by the way,
I don't think it's bad. So, you know, you bought your house when you're 30 years old and, you know,
you raise your family or retire there and you don't want to build a new shopping center and
screw up the neighborhood. Like, sure, go ahead and do it. But then you can't complain that there's
no housing in the area. Like, like the United States is literally three, you know, three,
three million square miles of land. Most of it's empty. You know, there's like a good
support population of the trillion probably. Most of it's really bad. And I don't know if you've
spent a lot of time in the inner mountain west, but that's a harsh, harsh landscape.
Yeah, it's an energy problem. But the, my premise is more small independent things are better.
Like, and one reason we met was you had some scientists on that, you know, I quite like
and some of whom are literally actively suppressed by the scientific community.
And again, I don't know if they're right around at some level. Like, I'm interested in it. And I was,
you know, surprised. You know, borderline shocked, you know, when I first discovered that there were
scientists who couldn't get their papers published, not because they seemed obviously stupid, but
because they didn't go to the narrative. And, you know, at some level, you could think,
well, I know governments could craft and big companies get bureaucratic and stodgy. But at
least, you know, the scientists, you know, Einstein, Shirley Einstein is a good guy. And,
and, you know, the people who studied his work, and then you read these articles, it was Peter
Voigt, Peter Voigt, he wrote the book, not even wrong. That's what a few hours in his office one
day. I actually he was the reason I even went down this path in the first place. When I was a
little kid, he had one of the first blogs that was critical string theory. I was so excited to
meet him and everything. He just turns out to have a lot of crazy mathematical ideas too. So,
yeah, but he also is a very strong believer in some parts of particle physics, so other people
are wrong. And he's very dismissive of them. And to be in hospitals, or her book, Lost in the
Maths is great. But then she's very much a true believer in other things. So, you know,
but you run into this interesting phenomena that even people who, who seem outside the
canon in some places could still be true believers in other places. And I have a theory,
I have a theory that you can only have one out of the canon idea at a time. Like,
if you have an idea that you're championing, unless you're like Thomas Gold or something.
You mean you're only allowed to have one idea out of the canon? That's a strategy or you think
that's a human nature problem? I think that's a strategy. I think that people are basically like,
look, I know this is crazy. Yeah, yeah. I'm not crazy because I'm buying to all of these. Yeah,
I'll tell you, I believe it. And I kind of get that. But I don't know,
for some people, they probably have three crazes. And there's probably humans have a limit.
Our computational substrate has limits on how many non-conformist ideas we can have at a time.
And that's another kind of problem. It's really painful, right? Like, if you don't have any common
ground to stand on with other people, it gets really painful, I think. You have to surrender
to some common knowledge at some point. Yeah, and it's in this surprise. I told you guys, I
found this list of, you know, crazy things about the sun, which I thought was fun,
but I talked to a, you know, a sun scientist and he was quite mad about it. And I was a little
taken aback because I was like, man, this is amazing. Like, you know, like, there it is right
there. It's so hard and complicated. And so the polarity of ideas is, I think, really important.
And then, so the recognition of tendencies, like I told you, there's this, you know, chaos versus
order productivity graph. Everybody can tell you where you should be, but nobody knows how to stay
there. It's like, when they built the interstate highway system, they invented the road system,
the equipment to build the companies were created. Like everywhere they went, they had to build new
companies to build these new roads. And it was sort of like they were so excited about building new
roads, they didn't have time to think like we could literally steal half this money. And nowadays,
it costs literally 10 times as much money per mile to build a road. They're better engineered,
quote unquote, and better planned. And, you know, but the money disappears in bureaucracy. And so
you know, like the best thing would be a way to like really reinvent all kinds of things.
So like young people, everyone's like, people say stuff like, oh, you know, there's so much debt
and you screwed all this up. It's like, yeah, but we built all that. Why don't you build your own
stuff? Like, like the current cartists, companies are defunct. You know, and then Elon builds a
new car company, you can't build a car company, you definitely can't build a rocket ship company,
and you definitely can't build a New Orleans company. He's probably got a list of 100 things,
those things you can't build. Like, build new stuff. I'm involved with Atomic Semi to help
pound the company and we're building a semiconductor fab that's really small. And
like you explain it to people and they'll say, well, half that might work and half like it'll
never work. Obviously semiconductor companies cost $10 billion. Where are you going to get
$10 billion? It was like, well, I was going to build it for $10,000, like not $10 billion.
And we've developed so much science as that. So humans are,
Jordan Peterson told me this funny line is like, like, there's a high incentive to get used to
things. So the first time you drive somewhere, it takes a while, right? But if you drive there
10 times, you drive back and forth every day, you don't even notice the drive anymore.
And I've noticed even on like a hike, when you walk, like if you walk a hike and you walk there
and then you walk back, the walk there takes twice as long as the walk back. Because you've
already, you know, because it's your perception of time as novelty and bias, which is really curious.
But there's a couple of exceptions to this. Like you don't get used to your kids. Well,
if you do, they'll die. So, or it could be your perception of your children is highly influenced
by how important they are to you. So even small deltas are novel. Like there might be some,
like the nice way of saying this, if you love your children, they're always new.
But the other way that the economy argument of it is, we're not descended for people who didn't
pay attention to their children. So we pay attention to them. And we notice pretty small
differences where as you, you walk down the street, you don't really care very much whether your
neighbor mowed their grass or moved a car around this year, an idiot, right? So do we have this
kind of funny? So, but the problem with that is we get used to everything. We're used to the science
we have. We're used to how they make cars, you know, we're used to the things like when I first
went to the Tesla factory, like it was all new to me, right? And it would really warm me out. I
spend hours there, I go home, like, you know, flashing lights and moving equipment. And after
a year, I've been there so many times, like, I would, I would be walking to a meeting and
annoyed that I couldn't park my car. And I was five minutes late. So I was walking fast through
this factory of wonders. I was walking to a place that literally made me sleep an extra hour a day
for three months, because it was so novel and new. Right. And now I was walking by it all annoyed
that I was late. Like, and this happens to everything scientists, physicists, you know,
they're so used to string theory, everything is bullshit compared to that. And we're so good
at something like, I really love the line, the unreasonable effectiveness of mathematics.
Right. But there's a counterline to that, which is something like,
like physics isn't mathematical, because we know so much, it's mathematical, because we know so
little. Like, it's so wild. So, yes. So the people had a better understanding of, you know,
why should there be limits to size? Why should there be limits to duration? Why is it hard to
stay on the high point of the productivity curve? Why do we get so used to things that we ignore
them even when they're really important? Why do we accept that you can't build a better X, Y, or Z?
Why are you condensed by advertisers who have only their own interests in mind that we're running
out of everything, create scarcity, you know, like, like, these are hard things to get out.
These are mental traps. There's a lot of them. And some of them are like, we earned them. Like,
being a zero-sum person as a person member of a tribe after a million years of evolution,
that pretty smart strategy. Right. Now, being oriented towards spring, summer, or fall,
you know, that's also pretty smart, too. You know, like in the winter, you know,
you fight over the last apple in the summer, you know, that's great. So, but knowing these things
is important because we build politics around them. We build structures around people, build their
lives around them. I know people are going to spend their entire lives worried, you know,
it was peak oil and then peak this and peak that, you know, and none of it happened. Like, literally,
none of it happened. I think that that's so vital and it's really interesting because it
keeps coming up. It translates into your personal life, too, right, in terms of where you put your
attention. I had this mind-bending experience as an artist, as a musical artist, where I heard
something that Nigel Godrich, he's a producer, he worked with Radiohead for many years. He said
something like, in an interview one time, this blew my mind, where he was like, you need to stop
trying to make it sound good and start trying to make it sound interesting. And I was like, wow,
that's really profound because that's exactly as a musician who's been playing an instrument for 40
years or something. You're so obsessed with optimizing your technical ability and it's like,
nobody cares. Like, literally, everyone only hears technically perfect music all day, every day,
but it doesn't stand out because it's technically perfect. It actually blends into the background
and these artists just kind of decay into fade away into nothing. And so there's just something
really, really interesting there about following what's surprising and what actually grabs you as
opposed to what's perfect or what's, you know, the best version of what came before.
Yeah, I saw Crosby Stills and Nash, I guess, play and they played their top hits just exactly
like they played them 30 years before, which I thought was terrible. And then I, because they
were such a wild band, like they did like five albums in two years that were all knockouts and
then they, and then Jeff Beck did this live album. That was so much better and more interesting than
his early stuff. Like he never stopped experimenting with a guitar, he could make it sing and dance.
Like, like some of it you can clearly hear in his earlier stuff, but that was just amazing. I was
like the Jerry Garcia line and we asked him what his limitations were. He said, everything I learned,
everything I know, everything I've played, like that, like that's an amazing thing.
And he was like, I really like his guitar playing too. But he also had a style and then he killed
himself with Harrow and Jesus. I don't know.
Well, I wonder if like this, the drug side of things too, it's just some reaction to that
inability, that trying to get outside, to get out of your own way kind of thing.
Yeah, it could be, some of what made him great was also what he was playing with, was with
Lewis and Jennings and Harrow and God knows what. That's a tough road to hoe though.
I think technically it was diabetes. They killed him, but he apparently would live on ice cream for
a month at a time. Okay. Jerry Garcia. Yeah. Yeah, he sued him over that too. That was pretty
funny. He named it after him. He literally killed him. That's right, because there's a big Ben and
Jerry is at the corner of Hayden-Nashbury right now. Oh, you can't even make it up.
But you know, that kind of combinational complexity and insanity is just a beautiful thing.
Like you couldn't, that's as weird and deep as you could possibly get at some level.
I mean, it's been really, really fun talking to you. You know so much about the arc of this
technology that's shaping everything about the world right now, and you're working so deeply on
it. And you have a really subdued optimism about it, which I really like. Subdued optimism. My nephew
said I'm a cynical optimist. I haven't looked at too much cynicism up here. I think that you
call things as they are, but it's just, I want to see a world where people are optimistic again.
Yeah, that's a great goal. And humans are good at being optimistic, but we are so attuned to our
environment. You know, like it sounds dumb, but there's winter, spring, summer, and fall in winter
again. And you know, we were very optimistic towards the length of the day and the growing of
everything. And you know, logically pessimistic, you know, at the end of the year, where you start
to run under here and work run out of stuff, and our environment and our culture and everything
that we create influences people's attitudes and stuff. And getting like, like even like a company
culture, like how do you get to growth mindset? And one reason I love working Freelon is I watch
them create it. Because it's like, we're going to save our so we're going to go to get a backup
playing it and we're going to do 10 of possible things. And we're going to work our asses off
to do it. And there's so much space now that's all this space. Are we going to make a rocket
better? Well, one set of people say you have to write a stupid or requirements document and outsource
it through government contractors and, you know, get a rocket that sucks for a lot of money. And
the other one says we're going to build a rocket and we're going to be able to do it. We're going
to keep doing it every day and we're going to make the machines. So they quickly ran out of machines
to make the rocket. So they had to make some machines to make the rocket and, you know, and
then, you know, something magical happened because now they can land rockets that take off. It never
looks really watching them take off and land. It just feels like the future. We don't have flying
cars, but we have reusable rockets and I feel like that's a decent. We're going to build flying cars.
Don't worry about it. It's coming. Be optimistic. I was in a like, I was at Tesla the first time
they landed two rockets next to each other and they set up big TV screen with a couple hundred
people went there and everybody's milling around and they, we watched it take off and then, you
know, the cameras are following them up and then they separate and then they come back
and then they landed. The whole place jumped up and down, cheered people hugged each other.
There was people, there was grown people crying. It was so fantastic and I felt like it was so
great to be part of that. And here's the crazy thing. We could all be part of that every day.
And I have to ask yourself, why aren't you part of that every day? Like how many,
how many things have impacted you in a way that, you know, we're all getting negged by society
and people are interested in, you know, negging us for their advantage. It's a, it's a crazy thing.
I think I'm less cynical because maybe I'm more accepting like the solution to
cynicism isn't to ignore it to be bitter. So you figure things out and then, you know,
to things like humans go through lots of cycles. They're often absolutely horrible,
but they create wonders and people aiming at wonders are way more likely to do something
good than people aiming at, you know, terrible things or restrictions or
the whole degrowth thing is crazy. Like, I know where it comes from. If you think it's November,
it's going to be cold for six months. It's a pretty good mindset.
There's, I think that there's something about California, like you're talking about
environment, having a huge influence on mindset. And California is a place that doesn't really
have winter. It has, you know, like, it has a sunny and it has a slightly wet period,
but it's just this kind of flat experience. And it was really interesting moving to a
place like New York, where all of a sudden you're confronted viscerally with the fact
that the seasons come and they change. And winters are always around the corner,
even when it's peak of summer, you're already thinking about that biting wind
in the, in the canyons. And so I, I don't think that it's incidental.
I was worried about the swampy summer.
Summer a lot more for me. It's just, there were times where it would be so cold and windy in
Manhattan that you would round and the wind would blow along the avenues and you would
round the building and it would just literally take your breath away, it would hit you in the
face and you're just like, and then you reenter it and you keep going. But the optimism that
California offers in this place where there's sun and there's grass and there's ocean,
I think that it isn't an accident that so much of the technologies that shaped the future is
coming from California, because it is a place where it's easier to be optimistic than perhaps
anywhere else in the country. Yeah, but on the flip side, then it also creates the comfort
stuff that humans are also not very good at. So not like, it's a, we're, we're curious,
we're a curious species, you know, and, and you have to be knowledgeable about what that is.
You know, the, when I was in Intel, there had been a 10% layoff, which by, you know,
Silicon Valley standards and companies with troubles with nothing. And like four years
after it happened, they all still talked about it. And, and that's partly because it was viewed as
unfair and poorly executed, which might have been true. But there was also a presumption of
stability and comfort, right, that had grown into the culture. And, and, and that kind of thing
could have been, you know, a reset and a positive journey, but it caused people to kind of double
down on protecting their turf and security and really dysregulated quite a few people.
And so that seems weird, but like even big organizations need proper spiritual leadership to
to navigate, you know, stuff like that. You know, there was a need for
change and reorganization, but it had like almost everything needs to be done skillfully.
Now, sometimes you can't do it skillfully because you just don't know. And, you know,
the famous World War II study where they evaluated like the quality of decisions
based on the time contemplating the decision. No, no, they, and they found there was no correlation.
So there was decisions made in weeks, decisions make months, decision making years, but the decision
making time was not correlated with the quality of the outcome. And the big difference was the
faster you made decisions, if it was bad, you found out faster. And so again, this is great
attention. So you need to have some framework and some like, you know, sensible guidance when
you're doing change on the flip side, you know, change needs to move at a pace such that you
can evaluate the failures of it to move on. And again, that's like, and they're both true.
And so, like, how do you be, you know, and human beings need to be able to live in a world
where many, many, many things are true. And then we're navigating a line along some set of these
constraints. But, but some things, okay, have more positive outcomes than other ones.
I mean, like maintaining a clear line for how those cause and effects
folds together is also really important, right? Because the worst outcome is to make a decision
and then to not really understand what the effect of it was, so you can never evaluate if you made
the right decision. Yeah, you see that kind of stuff happen all the time. Yeah, yeah, yeah.
When you want to learn stuff and make decisions and do experiments and sometimes fail,
then you really have to be willing to look at what really happened and why. And some companies
are going, like, we're going to make more decisions and fail when we need to. And then
they all cover up what the failures were, assign blame to the political parties out of power,
and, you know, it doesn't work at all. Oh, yeah. I like companies where like,
like Tesla had this idea, like doing the normal thing was failure. Thinking a risk was good.
And if it worked out, that's really good. And if it didn't work out, if you learn something,
that's good. As opposed to most places, you judged on the outcome. You know, if it worked,
it's good. If it didn't work, it's a failure. And which makes a lot of sense, unless you're
trying to do new things, in which case doing the same thing has doomed you to not improving.
I heard that culture really broke a lot of people though.
Yeah. Oh, yeah, it's really hard on people.
Yeah, no, I saw people at Tesla, like after four years, a lot of people be burned out,
but I tell you, they're way better engineers when they started.
So they kind of give questions, what's your goal? To have a happy, comfortable life or to have a,
you know, population of people that can do things, pick stuff up and get to work?
It's your goal.
What's that?
I said, what's your goal?
Oh, I like to do stuff. Like, I'm really curious about things. Like,
I'm curious what's going to happen. I'm curious about what people are going to do.
Like, currently, I'm running a science project that my company about,
can we achieve a high level of creative and productive output with, you know,
independent autonomous teams doing stuff? Oh, I'm into it. It's fun to watch people.
It's just in every possible way, I think I could, I could jump in there and help out
what if they fail, they'll learn a lot more and then, you know, we'll see what happens.
Yeah, I played the fuck around to find out video for the whole company in all hands.
Super fun.
What's that?
I said, I don't know what that video is.
Oh, I'll send you the video. It's a little walkthrough of a graph about, you know,
what do you have to do to find out? It's pretty important.
All right, we'll keep it in mind.
Well, then, then some group did, one of my teams did something,
and then it was a complete mess. And they were like, well, Jim, you told us to do this.
Like, you played the video. Like, what did you expect would happen? Well, I was
hoping you'd iterate a couple of times faster and figure it out a little.
Are you, are you still hiring?
Yeah.
Who are you hiring?
Oh, yeah, over the last year and a half, we had some like, let's say leadership
voids and we did a bunch of reorganization and smaller teams.
And right now we're, we're mostly hiring for like skill sets. We're hiring programmers and,
you know, like computer design is complicated. There's so many different skill sets.
Like people don't realize how many disciplines there are.
Like, even if you're an electrical engineer, a computer engineer, a programmer,
underneath there's a lot of differentiation.
So yeah, we're going to probably hire 50 people relatively short order.
And, and then when you hire people, it's really the coolest thing is everybody hire
changes your group a little bit. So you make a plan and then hire some people.
And then the new people change what you're doing and why and there's new ideas.
And sometimes it causes a reshuffling of how the org works.
How many people do you have right now?
Um, yeah, 10 students, 450 people.
Oh, so if you're hiring 50, it's like a pretty significant.
Yeah, it's a big chunk. Yeah.
Tom Xeminy, we're close to 30.
Yeah, it's super fun.
Very cool.
Well, I think we should let you go.
There's a lot more left on the table to talk about,
but I'd prefer to just have you back then to keep rolling right now.
All right. Hey, great to chat.
I was very curious how this would go.
Yeah, thanks, Jim. You're a fascinating dude.
Oh yeah, you guys too.
Keep it up. I, uh, I enjoy your guys content too.
Appreciate it.
Thank you so much.
Have a great rest of your day.
All right.
Thanks.
Take care.
